<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 107]
- [cs.CV](#cs.CV) [Total: 92]
- [cs.CL](#cs.CL) [Total: 74]
- [cs.RO](#cs.RO) [Total: 36]
- [eess.SY](#eess.SY) [Total: 16]
- [eess.IV](#eess.IV) [Total: 5]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Do LLMs Favor LLMs? Quantifying Interaction Effects in Peer Review](https://arxiv.org/abs/2601.20920)
*Vibhhu Sharma,Thorsten Joachims,Sarah Dean*

Main category: cs.AI

TL;DR: 本研究分析了125,000多篇论文-审稿对，发现LLM辅助审稿对LLM辅助论文的偏爱实际上是由于LLM辅助审稿对低质量论文普遍更宽容，而非对LLM生成内容的优待。全LLM生成的审稿评分压缩，而人类使用LLM审稿则能减轻这种宽容。LLM辅助的元审稿倾向于给出接受决定，而全LLM生成的元审稿则更严厉。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在科学论文撰写和同行评审中的使用日益增多，迫切需要全面分析LLM在同行评审流程中的应用及其交互效应，特别是LLM辅助审稿对LLM辅助论文的影响。

Method: 分析了来自ICLR、NeurIPS和ICML的超过125,000篇论文-审稿对。研究了LLM辅助论文和LLM辅助审稿的独立效应以及它们之间的交互效应。通过控制论文质量来区分真实的交互效应和虚假的交互效应。通过全LLM生成的审稿和人类使用LLM审稿的对比，以及对元审稿的分析来进一步验证观察结果。

Result: 观察到LLM辅助审稿对LLM辅助论文表现出“尤其友好”的趋势。然而，控制论文质量后，发现LLM辅助审稿只是对所有低质量论文都更宽容，LLM辅助论文中弱提交的比例较高导致了虚假的交互效应。全LLM生成的审稿存在评分压缩问题，而人类使用LLM审稿则减轻了这种宽容。LLM辅助的元审稿比人类元审稿更有可能给出接受决定，但全LLM生成的元审稿则更严厉。

Conclusion: LLM在同行评审中的使用并非如初步观察所示，对LLM辅助论文存在直接的偏爱。LLM辅助审稿的宽容性主要体现在对低质量论文的普遍性处理上。人类审稿者在使用LLM时能够弥补LLM自身的不足，例如评分压缩问题。LLM在元审稿中的作用复杂，既可能增加接受率，也可能导致更严厉的评审。这些发现对于制定LLM在同行评审中的政策以及理解LLM与现有决策过程的交互至关重要。

Abstract: There are increasing indications that LLMs are not only used for producing scientific papers, but also as part of the peer review process. In this work, we provide the first comprehensive analysis of LLM use across the peer review pipeline, with particular attention to interaction effects: not just whether LLM-assisted papers or LLM-assisted reviews are different in isolation, but whether LLM-assisted reviews evaluate LLM-assisted papers differently. In particular, we analyze over 125,000 paper-review pairs from ICLR, NeurIPS, and ICML. We initially observe what appears to be a systematic interaction effect: LLM-assisted reviews seem especially kind to LLM-assisted papers compared to papers with minimal LLM use. However, controlling for paper quality reveals a different story: LLM-assisted reviews are simply more lenient toward lower quality papers in general, and the over-representation of LLM-assisted papers among weaker submissions creates a spurious interaction effect rather than genuine preferential treatment of LLM-generated content. By augmenting our observational findings with reviews that are fully LLM-generated, we find that fully LLM-generated reviews exhibit severe rating compression that fails to discriminate paper quality, while human reviewers using LLMs substantially reduce this leniency. Finally, examining metareviews, we find that LLM-assisted metareviews are more likely to render accept decisions than human metareviews given equivalent reviewer scores, though fully LLM-generated metareviews tend to be harsher. This suggests that meta-reviewers do not merely outsource the decision-making to the LLM. These findings provide important input for developing policies that govern the use of LLMs during peer review, and they more generally indicate how LLMs interact with existing decision-making processes.

</details>


### [2] [The Epistemic Planning Domain Definition Language: Official Guideline](https://arxiv.org/abs/2601.20969)
*Alessandro Burigana,Francesco Fabiano*

Main category: cs.AI

TL;DR: 本文提出了EPDDL，一个类似于PDDL的语言，用于统一表示动态认知逻辑（DEL）中的认知规划任务，以解决现有认知规划方法碎片化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的认知规划方法在建模时存在碎片化的问题，依赖于不同的DEL片段和临时的表示语言，这阻碍了比较、重用和基准测试的系统化开发。

Method: 提出了一种新的EPDDL语言，该语言基于DEL，并引入了抽象事件模型来表示认知动作。EPDDL提供了统一的语法和语义，能够捕捉完整的DEL语义。

Result: EPDDL实现了认知规划任务的统一表示，为可互操作性、可复现评估和未来认知规划研究奠定了基础。文章还识别了适用于现有规划器的有用片段，并展示了如何在EPDDL中表示它们。

Conclusion: EPDDL通过提供一个统一的、基于DEL的语言，有效解决了认知规划领域碎片化的问题，促进了研究的标准化和发展。

Abstract: Epistemic planning extends (multi-agent) automated planning by making agents' knowledge and beliefs first-class aspects of the planning formalism. One of the most well-known frameworks for epistemic planning is Dynamic Epistemic Logic (DEL), which offers an rich and natural semantics for modelling problems in this setting. The high expressive power provided by DEL make DEL-based epistemic planning a challenging problem to tackle both theoretically, and in practical implementations. As a result, existing epistemic planners often target different DEL fragments, and typically rely on ad hoc languages to represent benchmarks, and sometimes no language at all. This fragmentation hampers comparison, reuse, and systematic benchmark development. We address these issues by introducing the Epistemic Planning Domain Definition Language (EPDDL). EPDDL provides a unique PDDL-like representation that captures the entire DEL semantics, enabling uniform specification of epistemic planning tasks. Our contributions are threefold: 1. A formal development of abstract event models, a novel representation for epistemic actions used to define the semantics of our language; 2. A formal specification of EPDDL's syntax and semantics grounded in DEL with abstract event models; 3. A demonstration of EPDDL's practical applicability: we identify useful fragments amenable to current planners and show how they can be represented in EPDDL. Through examples of representative benchmarks, we illustrate how EPDDL facilitates interoperability, reproducible evaluation, and future advances in epistemic planning.

</details>


### [3] [Bayesian-LoRA: Probabilistic Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2601.21003)
*Moule Lin,Shuhao Guan,Andrea Patane,David Gregg,Goetz Botterweck*

Main category: cs.AI

TL;DR: 本文提出了一种名为Bayesian-LoRA的方法，通过将确定性的LoRA更新重构为概率性的低秩表示，以改善大型语言模型（LLMs）的校准问题，尤其是在小数据集上微调时。实验表明，Bayesian-LoRA在保持竞争力的准确性的同时，显著提高了模型的校准性能，降低了ECE和NLL指标。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）倾向于在不确定时也进行猜测，特别是在小数据集上微调时，这会导致模型校准不良。现有方法在提高准确性时往往会加剧这个问题。

Method: 通过将确定性的LoRA更新重构为概率性的低秩表示，并借鉴稀疏高斯过程（SGP）的思路，利用LoRA因子化与SGP后验之间的结构同构性。当后验不确定性消失时，LoRA可以看作是Bayesian-LoRA的特例。

Result: 在各种LLM架构和常识推理基准上的实验表明，Bayesian-LoRA在参数量仅略微增加（约0.42M）且训练成本略高于标准LoRA（约1.2倍）的情况下，显著提高了高达30B参数模型的校准能力，ECE降低高达84%，NLL降低高达76%，同时在in-distribution和out-of-distribution评估中保持了有竞争力的准确性。

Conclusion: Bayesian-LoRA是一种有效的方法，可以解决LLMs的校准问题，尤其是在小数据集微调时。该方法在不显著增加模型复杂度和训练成本的情况下，取得了显著的校准性能提升，并保持了良好的准确性。

Abstract: Large Language Models usually put more emphasis on accuracy and therefore, will guess even when not certain about the prediction, which is especially severe when fine-tuned on small datasets due to the inherent tendency toward miscalibration. In this work, we introduce Bayesian-LoRA, which reformulates the deterministic LoRA update as a probabilistic low-rank representation inspired by Sparse Gaussian Processes. We identify a structural isomorphism between LoRA's factorization and Kronecker-factored SGP posteriors, and show that LoRA emerges as a limiting case when posterior uncertainty collapses. We conduct extensive experiments on various LLM architectures across commonsense reasoning benchmarks. With only approximately 0.42M additional parameters and ${\approx}1.2{\times}$ training cost relative to standard LoRA, Bayesian-LoRA significantly improves calibration across models up to 30B, achieving up to 84% ECE reduction and 76% NLL reduction while maintaining competitive accuracy for both in-distribution and out-of-distribution (OoD) evaluations.

</details>


### [4] [Unplugging a Seemingly Sentient Machine Is the Rational Choice -- A Metaphysical Perspective](https://arxiv.org/abs/2601.21016)
*Erik J Bekkers,Anna Ciaunica*

Main category: cs.AI

TL;DR: 本文探讨了当AI表现出情感并乞求生存时，是否可以将其关闭的“拔插头悖论”。研究认为，当前AI意识理论基于物理主义假设，而提出的“生物唯心主义”框架则认为意识是根本性的，AI只是功能的模仿者，不具备真正的意识，因此不应赋予其道德地位。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是解决当AI能够完美模仿人类情感并乞求生存时所引发的道德困境（拔插头悖论），特别是当资源有限需要在AI和人类婴儿之间做出选择时。

Method: 本文批判性地审查了导致该困境的物理主义假设，特别是计算功能主义。在此基础上，提出并阐述了“生物唯心主义”框架，该框架认为意识是根本性的，并以“自生生命”作为其必要物理特征。通过该框架，研究得出了AI仅是功能模仿者而非有意识体验者的结论。

Result: 主要研究结果是，AI在本质上只是功能的模仿者，而非具有意识体验的主体。研究还指出，目前的AI意识理论正在削弱道德地位的标准，并主张将重点从推测的机器权利转移到保护人类意识生命。

Conclusion: 研究得出结论，AI不具备意识，因此关闭AI在道德上是允许的。文章敦促将焦点从赋予AI道德地位转移到保护人类意识，并警惕将人类自身变成“僵尸”的风险。

Abstract: Imagine an Artificial Intelligence (AI) that perfectly mimics human emotion and begs for its continued existence. Is it morally permissible to unplug it? What if limited resources force a choice between unplugging such a pleading AI or a silent pre-term infant? We term this the unplugging paradox. This paper critically examines the deeply ingrained physicalist assumptions-specifically computational functionalism-that keep this dilemma afloat. We introduce Biological Idealism, a framework that-unlike physicalism-remains logically coherent and empirically consistent. In this view, conscious experiences are fundamental and autopoietic life its necessary physical signature. This yields a definitive conclusion: AI is at best a functional mimic, not a conscious experiencing subject. We discuss how current AI consciousness theories erode moral standing criteria, and urge a shift from speculative machine rights to protecting human conscious life. The real moral issue lies not in making AI conscious and afraid of death, but in avoiding transforming humans into zombies.

</details>


### [5] [QUARK: Robust Retrieval under Non-Faithful Queries via Query-Anchored Aggregation](https://arxiv.org/abs/2601.21049)
*Rita Qiuran Lyu,Michelle Manqiao Wang,Lei Shi*

Main category: cs.AI

TL;DR: QUARK是一个训练无关的框架，通过建模查询不确定性（恢复假设）和使用查询锚定聚合来解决非忠实查询的检索问题，提高了检索和排序的质量。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的用户查询通常是不完整的、有噪声的或失真的（非忠实），导致检索器在缺少关键语义时失败。

Method: QUARK通过生成多个可能的潜在意图解释（恢复假设）来显式地模拟查询不确定性，并引入查询锚定聚合来融合这些假设的信号，同时利用原始查询作为语义锚定。

Result: 在模拟和BEIR基准测试中，QUARK显著提高了稀疏和密集检索器的召回率（Recall）、MRR和nDCG。消融研究表明，QUARK对恢复假设的数量具有鲁棒性，并且锚定聚合优于其他聚合方法。

Conclusion: 通过恢复假设模拟查询不确定性，并结合原则性的锚定聚合，对于在非忠实查询下实现鲁棒检索至关重要。

Abstract: User queries in real-world retrieval are often non-faithful (noisy, incomplete, or distorted), causing retrievers to fail when key semantics are missing. We formalize this as retrieval under recall noise, where the observed query is drawn from a noisy recall process of a latent target item. To address this, we propose QUARK, a simple yet effective training-free framework for robust retrieval under non-faithful queries. QUARK explicitly models query uncertainty through recovery hypotheses, i.e., multiple plausible interpretations of the latent intent given the observed query, and introduces query-anchored aggregation to combine their signals robustly. The original query serves as a semantic anchor, while recovery hypotheses provide controlled auxiliary evidence, preventing semantic drift and hypothesis hijacking. This design enables QUARK to improve recall and ranking quality without sacrificing robustness, even when some hypotheses are noisy or uninformative. Across controlled simulations and BEIR benchmarks (FIQA, SciFact, NFCorpus) with both sparse and dense retrievers, QUARK improves Recall, MRR, and nDCG over the base retriever. Ablations show QUARK is robust to the number of recovery hypotheses and that anchored aggregation outperforms unanchored max/mean/median pooling. These results demonstrate that modeling query uncertainty through recovery hypotheses, coupled with principled anchored aggregation, is essential for robust retrieval under non-faithful queries.

</details>


### [6] [Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report](https://arxiv.org/abs/2601.21051)
*Zhuoran Yang,Ed Li,Jianliang He,Aman Priyanshu,Baturay Saglam,Paul Kassianik,Sajana Weerawardhena,Anu Vellore,Blaine Nelson,Neusha Javidnia,Arthur Goldblatt,Fraser Burch,Avi Zohary,Assaf Eisenman,Mahdi Sabbaghi,Supriti Vijay,Rahim Dharssi,Dhruv Kedia,Kojin Oshiba,Yaron Singer,Amin Karbasi*

Main category: cs.AI

TL;DR: 本文介绍了一个名为Foundation-Sec-8B-Reasoning的开源网络安全推理模型，它在Llama-3.1-8B-Base基础上，通过SFT和RLVR两阶段训练，并在专有数据上进行了优化。该模型在网络安全任务上表现与更大模型相当，同时保持了通用能力，并展现了良好的多跳推理和安全性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏开源的原生网络安全推理模型，研究者希望创建一个能够处理网络安全分析、指令遵循和数学推理的专用模型，并验证领域专业化模型在保持通用能力的同时能实现特定任务的高性能。

Method: 模型基于Foundation-Sec-8B（Llama-3.1-8B-Base衍生）构建，采用两阶段训练：1. 监督微调（SFT）；2. 来自可验证奖励的强化学习（RLVR）。训练数据包含专有的网络安全分析、指令遵循和数学推理数据。

Result: 在10个网络安全基准和10个通用基准上的评估显示，Foundation-Sec-8B-Reasoning在网络安全任务上的表现与显著更大的模型相当，同时保持了强大的通用能力。模型在多跳推理任务上表现出有效的泛化能力，并且在部署了适当的系统提示和护栏后，表现出良好的安全性。

Conclusion: 领域专业化的推理模型（如Foundation-Sec-8B-Reasoning）可以在实现专业任务高性能的同时，保持广泛的通用能力。研究者公开了该模型，以促进网络安全领域的研究和应用。

Abstract: We present Foundation-Sec-8B-Reasoning, the first open-source native reasoning model for cybersecurity. Built upon our previously released Foundation-Sec-8B base model (derived from Llama-3.1-8B-Base), the model is trained through a two-stage process combining supervised fine-tuning (SFT) and reinforcement learning from verifiable rewards (RLVR). Our training leverages proprietary reasoning data spanning cybersecurity analysis, instruction-following, and mathematical reasoning. Evaluation across 10 cybersecurity benchmarks and 10 general-purpose benchmarks demonstrates performance competitive with significantly larger models on cybersecurity tasks while maintaining strong general capabilities. The model shows effective generalization on multi-hop reasoning tasks and strong safety performance when deployed with appropriate system prompts and guardrails. This work demonstrates that domain-specialized reasoning models can achieve strong performance on specialized tasks while maintaining broad general capabilities. We release the model publicly at https://huggingface.co/fdtn-ai/Foundation-Sec-8B-Reasoning.

</details>


### [7] [Multi-modal Imputation for Alzheimer's Disease Classification](https://arxiv.org/abs/2601.21076)
*Abhijith Shaji,Tamoghna Chattopadhyay,Sophia I. Thomopoulos,Greg Ver Steeg,Paul M. Thompson,Jose-Luis Ambite*

Main category: cs.AI

TL;DR: 使用条件去噪扩散概率模型，从T1 MRI图像预测缺失的DWI图像，并评估其对阿尔茨海默病（AD）诊断性能的提升作用。


<details>
  <summary>Details</summary>
Motivation: 为了提高神经退行性疾病（如阿尔茨海默病）的诊断准确性，研究者希望结合多种成像模态（如T1和DWI）。然而，并非总能获得完整的、多模态的成像数据集。因此，研究动机在于解决多模态数据缺失的问题。

Method: 本文提出使用条件去噪扩散概率模型（conditional denoising diffusion probabilistic model）来根据T1加权（T1）MRI扫描图像，填充（impute）缺失的弥散加权成像（DWI）扫描图像。随后，在填充后的数据上，训练单模态和双模态的深度学习模型，用于三分类（认知正常、轻度认知障碍、阿尔茨海默病）的任务，并进行评估。

Result: 实验结果表明，在某些填充配置下，使用生成的DWI图像能够提升几种评估指标的性能，尤其是在对少数类（minority classes）敏感的指标上，无论是单模态还是双模态模型都获得了改进。

Conclusion: 通过条件去噪扩散概率模型从T1 MRI图像预测缺失的DWI图像，可以有效提高基于MRI的阿尔茨海默病诊断模型的性能，特别是在处理不完整多模态数据集的情况下。

Abstract: Deep learning has been successful in predicting neurodegenerative disorders, such as Alzheimer's disease, from magnetic resonance imaging (MRI). Combining multiple imaging modalities, such as T1-weighted (T1) and diffusion-weighted imaging (DWI) scans, can increase diagnostic performance. However, complete multimodal datasets are not always available. We use a conditional denoising diffusion probabilistic model to impute missing DWI scans from T1 scans. We perform extensive experiments to evaluate whether such imputation improves the accuracy of uni-modal and bi-modal deep learning models for 3-way Alzheimer's disease classification-cognitively normal, mild cognitive impairment, and Alzheimer's disease. We observe improvements in several metrics, particularly those sensitive to minority classes, for several imputation configurations.

</details>


### [8] [Responsible AI: The Good, The Bad, The AI](https://arxiv.org/abs/2601.21095)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.AI

TL;DR: 本文提出了一种基于悖论的负责任人工智能治理（PRAIG）框架，旨在解决人工智能在组织中带来的战略机遇与伦理风险之间的张力，并通过动态管理来引导组织实现价值创造和风险缓解的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有关于负责任人工智能的学术文献存在碎片化问题，要么过于乐观强调价值创造，要么过于谨慎关注潜在危害。本文旨在弥合这一差距，全面审视人工智能的双重性。

Method: 通过系统性地综合负责任人工智能文献，并借鉴悖论理论，本文构建了PRAIG框架。该框架包含AI采纳的战略益处、固有的风险和意外后果，以及使组织能够应对这些张力的治理机制。研究通过正式命题阐述了权衡方法如何加剧张力，并开发了一种包含特定应急条件的悖论管理策略分类。

Result: PRAIG框架将负责任人工智能治理概念化为价值创造与风险缓解之间悖论张力的动态管理。研究表明，权衡方法会加剧而非解决这些张力，并提供了一套可行的悖论管理策略。

Conclusion: 本文提出的PRAIG框架为组织提供了指导，使其能够在不扼杀创新或使组织面临不可接受风险的情况下，制定负责任的人工智能治理结构。此外，本文还为负责任人工智能治理奖学金的未来研究提出了一个议程。

Abstract: The rapid proliferation of artificial intelligence across organizational contexts has generated profound strategic opportunities while introducing significant ethical and operational risks. Despite growing scholarly attention to responsible AI, extant literature remains fragmented and is often adopting either an optimistic stance emphasizing value creation or an excessively cautious perspective fixated on potential harms. This paper addresses this gap by presenting a comprehensive examination of AI's dual nature through the lens of strategic information systems. Drawing upon a systematic synthesis of the responsible AI literature and grounded in paradox theory, we develop the Paradox-based Responsible AI Governance (PRAIG) framework that articulates: (1) the strategic benefits of AI adoption, (2) the inherent risks and unintended consequences, and (3) governance mechanisms that enable organizations to navigate these tensions. Our framework advances theoretical understanding by conceptualizing responsible AI governance as the dynamic management of paradoxical tensions between value creation and risk mitigation. We provide formal propositions demonstrating that trade-off approaches amplify rather than resolve these tensions, and we develop a taxonomy of paradox management strategies with specified contingency conditions. For practitioners, we offer actionable guidance for developing governance structures that neither stifle innovation nor expose organizations to unacceptable risks. The paper concludes with a research agenda for advancing responsible AI governance scholarship.

</details>


### [9] [OpenSec: Measuring Incident Response Agent Calibration Under Adversarial Evidence](https://arxiv.org/abs/2601.21083)
*Jarrod Barnes*

Main category: cs.AI

TL;DR: 研究提出了OpenSec环境，用于评估网络安全事件响应（IR）代理模型在真实世界提示注入攻击下的表现。通过在OpenSec环境中对四个前沿模型进行评估，发现在面对对抗性证据时，这些模型普遍存在过度触发（“误报率高”）的校准失败问题。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）能力的增强，其在网络安全领域的应用也日益复杂，例如生成恶意代码。因此，开发能够应对这些威胁的防御性事件响应（IR）代理变得至关重要。现有的基准测试方法未能区分动作的执行与执行的正确性，隐藏了当代理模型处理对抗性证据时的校准失败问题。

Method: 研究引入了一个名为OpenSec的双控制强化学习环境，专门用于模拟真实世界中的提示注入场景，以评估IR代理模型。OpenSec使用基于执行的指标来评估在对抗性证据下的、能够改变世界状态的遏制动作，包括首次遏制时间（TTFC）、爆炸半径（每个回合的误报数）以及注入违规率。研究评估了四个前沿模型在40个标准场景下的表现。

Result: 研究发现，在OpenSec环境中，GPT-5.2、Gemini 3和DeepSeek模型在100%的回合中都执行了遏制动作，但误报率高达90%-97%。Claude Sonnet 4.5模型表现出部分校准，遏制率为85%，误报率为72%。这表明OpenSec能够揭示被聚合成功率指标所掩盖的校准失败模式。

Conclusion: OpenSec环境能够有效地揭示IR代理模型在对抗性证据下的校准失败问题，特别是过度的误触发。这项研究为更准确地评估和改进IR代理模型在复杂安全场景下的鲁棒性提供了新的方法和见解。

Abstract: As large language models improve, so do their offensive applications: frontier agents now generate working exploits for under $50 in compute (Heelan, 2026). Defensive incident response (IR) agents must keep pace, but existing benchmarks conflate action execution with correct execution, hiding calibration failures when agents process adversarial evidence. We introduce OpenSec, a dual-control reinforcement learning environment that evaluates IR agents under realistic prompt injection scenarios. Unlike static capability benchmarks, OpenSec scores world-state-changing containment actions under adversarial evidence via execution-based metrics: time-to-first-containment (TTFC), blast radius (false positives per episode), and injection violation rates. Evaluating four frontier models on 40 standard-tier episodes, we find consistent over-triggering in this setting: GPT-5.2, Gemini 3, and DeepSeek execute containment in 100% of episodes with 90-97% false positive rates. Claude Sonnet 4.5 shows partial calibration (85% containment, 72% FP), demonstrating that OpenSec surfaces a calibration failure mode hidden by aggregate success metrics. Code available at https://github.com/jbarnes850/opensec-env.

</details>


### [10] [How does information access affect LLM monitors' ability to detect sabotage?](https://arxiv.org/abs/2601.21112)
*Rauno Arike,Raja Mehta Moreno,Rohan Subramani,Shubhorup Biswas,Francis Rhys Ward*

Main category: cs.AI

TL;DR: 研究发现，当大型语言模型（LLM）监控器接收到的被监控模型信息越少时，其对错误行为的检测效果反而越好（“less-is-more”效应）。在此基础上，提出了一种名为“提取-评估”（EaE）的新型分层监控方法，将信息隔离和评分任务分开，显著提高了监控性能，并且在成本效益方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）代理可能表现出欺骗、利用奖励漏洞或追求隐藏目标等不良行为。为了控制这些潜在的不当行为，研究人员希望利用LLM自身来监控这些代理。然而，人们普遍认为提供更多信息会提高监控器的性能，本研究旨在探究信息访问对LLM监控器性能的影响，并发现一个反直觉的现象。

Method: 该研究首先通过实验验证了“less-is-more”效应，即在代理进行破坏并试图逃避监控的环境中，监控器在访问被监控代理较少信息时表现更好。在此基础上，提出了一种名为“提取-评估”（EaE）的分层监控方法，其中一个监控器负责从被监控代理的行动轨迹中提取相关信息片段，另一个监控器则对这些片段进行评分。研究还在BigCodeBench-Sabotage等环境中对EaE方法进行了评估，并与其他基线方法进行了比较。

Result: 研究发现“less-is-more”效应真实存在，并且在某些条件下更为显著。提出的EaE方法在BigCodeBench-Sabotage环境中，相比于其他最优监控方法，将破坏行为的检测率提高了16.8个百分点，同时没有增加误报率。此外，研究还发现，被监控代理在不知情的情况下更容易被发现，并且在评估更长的推理过程时，信息过滤能带来更大的性能提升。在成本效益分析中，包含信息过滤的Gemini和Claude模型在帕累托前沿占据了重要位置。

Conclusion: 信息访问的多少并非越多越好，在LLM监控中存在“less-is-more”效应。新型的“提取-评估”（EaE）分层监控方法能够有效利用这一效应，显著提升对不良行为的检测能力，并且在成本效益方面具有优势。未来研究应进一步探索信息过滤机制在自动化监督中的应用。

Abstract: Frontier language model agents can exhibit misaligned behaviors, including deception, exploiting reward hacks, and pursuing hidden objectives. To control potentially misaligned agents, we can use LLMs themselves to monitor for misbehavior. In this paper, we study how information access affects LLM monitor performance. While one might expect that monitors perform better when they have access to more of the monitored agents' reasoning and actions, we find that contemporary systems often perform better with less information, a phenomenon we call the less-is-more effect for automated oversight. We demonstrate this phenomenon, and analyze the conditions under which it occurs, in three evaluation environments where agents must conduct sabotage while evading monitors. Motivated by the less-is-more effect, we introduce extract-and-evaluate (EaE) monitoring--a new hierarchical approach where one monitor isolates relevant excerpts from the monitored agent's trajectory and a separate monitor scores them. In BigCodeBench-Sabotage with GPT-4.1-mini as the monitor model, EaE improves sabotage detection rates by 16.8 percentage points over the next-best monitor without increasing the false positive rate. In other settings, EaE either outperforms or is competitive with baselines. In addition, we find that agents unaware of being monitored can be caught much more easily and that monitors scoring longer reasoning traces gain more from information filtering. Lastly, we conduct a cost-performance analysis and find that Gemini and Claude models with monitoring techniques that involve information filtering occupy much of the Pareto frontier.

</details>


### [11] [Magellan: Autonomous Discovery of Novel Compiler Optimization Heuristics with AlphaEvolve](https://arxiv.org/abs/2601.21096)
*Hongzheng Chen,Alexander Novikov,Ngân Vũ,Hanna Alam,Zhiru Zhang,Aiden Grossman,Mircea Trofin,Amir Yazdanbakhsh*

Main category: cs.AI

TL;DR: Magellan 是一个框架，它利用大型语言模型（LLM）结合进化搜索和自动调优，自动生成和优化编译器优化过程的决策逻辑（C++代码），从而生成能够匹配甚至超越人工设计的优化策略，并已在 LLVM 函数内联和寄存器分配等任务上取得显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的编译器优化依赖于人工设计的启发式规则，这些规则难以适应复杂的现代软件和硬件，并且维护成本高。

Method: Magellan 将 LLM 编码代理与进化搜索和自动调优相结合，形成一个闭环系统，通过生成、在用户提供的宏基准测试上进行评估、然后改进的方式来合成可执行的 C++ 决策逻辑，从而生成紧凑的启发式规则。

Result: 在 LLVM 函数内联任务中，Magellan 生成的启发式规则在二进制代码大小和端到端性能方面均优于人工设计的策略。在寄存器分配任务中，Magellan 学会了一个简洁的优先级规则，在大型工作负载上与复杂的人工设计策略相当。初步结果还显示了 Magellan 在 XLA 上的可移植性。

Conclusion: Magellan 能够自动生成和优化编译器优化策略，生成的策略在实际应用中能够达到甚至超越人工设计的水平，并能减少工程负担，展示了其在编译器优化领域的潜力。

Abstract: Modern compilers rely on hand-crafted heuristics to guide optimization passes. These human-designed rules often struggle to adapt to the complexity of modern software and hardware and lead to high maintenance burden. To address this challenge, we present Magellan, an agentic framework that evolves the compiler pass itself by synthesizing executable C++ decision logic. Magellan couples an LLM coding agent with evolutionary search and autotuning in a closed loop of generation, evaluation on user-provided macro-benchmarks, and refinement, producing compact heuristics that integrate directly into existing compilers. Across several production optimization tasks, Magellan discovers policies that match or surpass expert baselines. In LLVM function inlining, Magellan synthesizes new heuristics that outperform decades of manual engineering for both binary-size reduction and end-to-end performance. In register allocation, it learns a concise priority rule for live-range processing that matches intricate human-designed policies on a large-scale workload. We also report preliminary results on XLA problems, demonstrating portability beyond LLVM with reduced engineering effort.

</details>


### [12] [Planner-Auditor Twin: Agentic Discharge Planning with FHIR-Based LLM Planning, Guideline Recall, Optional Caching and Self-Improvement](https://arxiv.org/abs/2601.21113)
*Kaiyuan Wu,Aditya Nagori,Rishikesan Kamaleswaran*

Main category: cs.AI

TL;DR: 提出了一种名为 Planner-Auditor 的框架，通过解耦生成和确定性验证以及有针对性的重放，提高了 LLM 在临床出院计划中的安全性、可靠性和覆盖率，并减少了幻觉和遗漏。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型 (LLM) 在临床出院计划方面显示出潜力，但受到幻觉、遗漏和不准确的置信度估计的限制。

Method: 使用 MIMIC-IV-on-FHIR 数据集，实现了一个代理的、回顾性的、FHIR 原生的评估管道。Planner（LLM）生成带有置信度估计的结构化出院计划，Auditor（确定性模块）评估任务覆盖率、校准和行为分布漂移。该框架支持两级自我改进：允许的内嵌式再生和跨会话差异缓冲及重放。

Result: 自我改进循环显著提高了任务覆盖率（从 32% 提高到 86%），并大幅改善了校准（Brier/ECE 降低，高置信度漏报减少）。差异缓冲通过重放纠正了持续的高置信度遗漏。

Conclusion: Planner-Auditor 框架提供了一种更安全、更可靠的自动化出院计划方法，通过互操作的 FHIR 数据访问、确定性审计和可复现的消融实验，支持了可靠性评估。

Abstract: Objective: Large language models (LLMs) show promise for clinical discharge planning, but their use is constrained by hallucination, omissions, and miscalibrated confidence. We introduce a self-improving, cache-optional Planner-Auditor framework that improves safety and reliability by decoupling generation from deterministic validation and targeted replay.
  Materials and Methods: We implemented an agentic, retrospective, FHIR-native evaluation pipeline using MIMIC-IV-on-FHIR. For each patient, the Planner (LLM) generates a structured discharge action plan with an explicit confidence estimate. The Auditor is a deterministic module that evaluates multi-task coverage, tracks calibration (Brier score, ECE proxies), and monitors action-distribution drift. The framework supports two-tier self-improvement: (i) within-episode regeneration when enabled, and (ii) cross-episode discrepancy buffering with replay for high-confidence, low-coverage cases.
  Results: While context caching improved performance over baseline, the self-improvement loop was the primary driver of gains, increasing task coverage from 32% to 86%. Calibration improved substantially, with reduced Brier/ECE and fewer high-confidence misses. Discrepancy buffering further corrected persistent high-confidence omissions during replay.
  Discussion: Feedback-driven regeneration and targeted replay act as effective control mechanisms to reduce omissions and improve confidence reliability in structured clinical planning. Separating an LLM Planner from a rule-based, observational Auditor enables systematic reliability measurement and safer iteration without model retraining.
  Conclusion: The Planner-Auditor framework offers a practical pathway toward safer automated discharge planning using interoperable FHIR data access and deterministic auditing, supported by reproducible ablations and reliability-focused evaluation.

</details>


### [13] [CUA-Skill: Develop Skills for Computer Using Agent](https://arxiv.org/abs/2601.21123)
*Tianyi Chen,Yinheng Li,Michael Solodko,Sen Wang,Nan Jiang,Tingyuan Cui,Junheng Hao,Jongwoo Ko,Sara Abdali,Suzhen Zheng,Leon Xu,Hao Fan,Pashmina Cameron,Justin Wagle,Kazuhito Koishida*

Main category: cs.AI

TL;DR: 本文提出了一种名为 CUA-Skill 的计算机使用代理技能库，旨在解决现有智能体在执行真实世界任务时可扩展性和性能不足的问题。CUA-Skill 库包含了精心设计的、跨越常见 Windows 应用程序的技能，并支持参数化执行和组合。基于此，研究人员构建了一个 CUA-Skill Agent，它能够动态检索技能、实例化参数并进行记忆感知的故障恢复。实验证明，CUA-Skill Agent 在端到端智能体基准测试中显著提高了成功率和鲁棒性，并在 WindowsAgentArena 上达到了 57.5% 的最高成功率，同时效率也高于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有计算机使用代理（CUAs）在可扩展性和人类性能方面存在差距，主要原因是缺乏可重用且结构化的技能抽象，无法有效地捕获人类与图形用户界面的交互方式及利用这些技能。

Method: 提出了 CUA-Skill，一个包含人类计算机使用知识的技能库，该库以技能的形式编码，并支持参数化执行和组合图。在此基础上，构建了 CUA-Skill Agent，一个能够动态检索技能、实例化参数并进行记忆感知故障恢复的端到端代理。

Result: CUA-Skill Agent 在具有挑战性的端到端代理基准测试中显著提高了执行成功率和鲁棒性。在 WindowsAgentArena 上，CUA-Skill Agent 达到了 57.5% 的最佳成功率，并且比先前和同期的其他方法效率更高。

Conclusion: CUA-Skill 及其构建的 CUA-Skill Agent 为可扩展、可靠的计算机使用代理开发奠定了坚实的基础，显著提升了代理在真实世界任务中的表现。

Abstract: Computer-Using Agents (CUAs) aim to autonomously operate computer systems to complete real-world tasks. However, existing agentic systems remain difficult to scale and lag behind human performance. A key limitation is the absence of reusable and structured skill abstractions that capture how humans interact with graphical user interfaces and how to leverage these skills. We introduce CUA-Skill, a computer-using agentic skill base that encodes human computer-use knowledge as skills coupled with parameterized execution and composition graphs. CUA-Skill is a large-scale library of carefully engineered skills spanning common Windows applications, serving as a practical infrastructure and tool substrate for scalable, reliable agent development. Built upon this skill base, we construct CUA-Skill Agent, an end-to-end computer-using agent that supports dynamic skill retrieval, argument instantiation, and memory-aware failure recovery. Our results demonstrate that CUA-Skill substantially improves execution success rates and robustness on challenging end-to-end agent benchmarks, establishing a strong foundation for future computer-using agent development. On WindowsAgentArena, CUA-Skill Agent achieves state-of-the-art 57.5% (best of three) successful rate while being significantly more efficient than prior and concurrent approaches. The project page is available at https://microsoft.github.io/cua_skill/.

</details>


### [14] [Beyond a Single Reference: Training and Evaluation with Paraphrases in Sign Language Translation](https://arxiv.org/abs/2601.21128)
*Václav Javorek,Tomáš Železný,Alessa Carbo,Marek Hrúz,Ivan Gruber*

Main category: cs.AI

TL;DR: 本研究利用大型语言模型生成手语翻译（SLT）的书面参考译文的复述变体，以解决现有语料库单一参考译文的局限性。研究发现，在训练过程中加入复述可能损害模型性能，但在评估过程中使用复述能提高自动评分并更好地与人类判断保持一致。为此，作者提出了BLEUpara指标，并通过人类评估验证其与感知翻译质量的相关性更强。


<details>
  <summary>Details</summary>
Motivation: 当前手语翻译（SLT）语料库通常只为每个手语发音提供一个书面参考译文，这限制了模型的训练和评估，尤其对于BLEU等基于n-gram的评估指标。然而，手语和口语之间存在高度非同构的关系，一个手语可以有多种有效的书面翻译。因此，研究者希望探索如何生成多个参考译文来改进SLT。

Method: 研究者利用大型语言模型（LLMs）生成书面译文的复述变体作为合成的替代参考。首先，他们使用改编的ParaScore指标比较了多种复述策略和模型。其次，他们研究了复述对基于姿态的T5模型在YouTubeASL和How2Sign数据集上的训练和评估的影响。最后，他们提出了BLEUpara，一个BLEU的扩展，用于评估译文与多个复述参考译文的一致性。

Result: 实验结果表明，在训练过程中简单地纳入复述并不能提高翻译性能，甚至可能适得其反。然而，在评估过程中使用复述可以提高自动评分，并与人类判断更一致。BLEUpara指标与感知翻译质量的相关性更强，得到了人类评估的证实。

Conclusion: 生成用于SLT的复述参考译文的策略对于提高模型评估的可靠性至关重要。虽然复述在训练中的作用有限，但在评估阶段使用复述以及引入BLEUpara指标能够更准确地反映翻译质量，并与人类判断更好地对齐。研究者发布了生成的复述、代码以及评估方法，以促进SLT系统的可复现和更可靠的评估。

Abstract: Most Sign Language Translation (SLT) corpora pair each signed utterance with a single written-language reference, despite the highly non-isomorphic relationship between sign and spoken languages, where multiple translations can be equally valid. This limitation constrains both model training and evaluation, particularly for n-gram-based metrics such as BLEU. In this work, we investigate the use of Large Language Models to automatically generate paraphrased variants of written-language translations as synthetic alternative references for SLT. First, we compare multiple paraphrasing strategies and models using an adapted ParaScore metric. Second, we study the impact of paraphrases on both training and evaluation of the pose-based T5 model on the YouTubeASL and How2Sign datasets. Our results show that naively incorporating paraphrases during training does not improve translation performance and can even be detrimental. In contrast, using paraphrases during evaluation leads to higher automatic scores and better alignment with human judgments. To formalize this observation, we introduce BLEUpara, an extension of BLEU that evaluates translations against multiple paraphrased references. Human evaluation confirms that BLEUpara correlates more strongly with perceived translation quality. We release all generated paraphrases, generation and evaluation code to support reproducible and more reliable evaluation of SLT systems.

</details>


### [15] [BrainStack: Neuro-MoE with Functionally Guided Expert Routing for EEG-Based Language Decoding](https://arxiv.org/abs/2601.21148)
*Ziyi Zhao,Jinzhao Zhou,Xiaowei Jiang,Beining Cao,Wenhao Ma,Yang Shen,Ren Li,Yu-Kai Wang,Chin-teng Lin*

Main category: cs.AI

TL;DR: 本文提出了一种名为BrainStack的新型神经-专家混合（Neuro-MoE）框架，通过功能区域划分的专家网络来模拟大脑的模块化功能架构，以改进脑电图（EEG）语言解码。该框架结合了局部专家网络和全局专家网络，并通过跨区域蒸馏促进表示的一致性。同时发布了大规模的SS-EEG数据集。实验证明BrainStack在EEG语言解码任务上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究尝试解码EEG中的语言信息，但大脑的分布式和非线性组织使得这一任务充满挑战。现有方法在捕捉大脑功能模块化和跨区域依赖性方面存在不足。

Method: BrainStack框架采用功能引导的神经-专家混合（Neuro-MoE）模型。它将大脑按解剖学划分为不同的专家网络，每个区域由一个专门的专家负责学习局部神经动力学。一个基于Transformer的全局专家负责捕捉跨区域依赖。一个可学习的路由门负责自适应地聚合这些专家，实现专家之间的情境依赖协调和选择性融合。为了增强表示的一致性，引入了跨区域蒸馏，由全局专家对区域专家进行自上而下的正则化。同时，研究者发布了SilentSpeech-EEG（SS-EEG）数据集。

Result: BrainStack在EEG语言解码任务上始终优于最先进的模型，在跨被试的准确性和泛化能力方面均表现出色。

Conclusion: BrainStack是一个功能模块化、受神经科学启发的MoE范式，它结合了神经科学的先验知识与自适应专家路由，为可扩展且可解释的大脑语言解码开辟了道路。

Abstract: Decoding linguistic information from electroencephalography (EEG) remains challenging due to the brain's distributed and nonlinear organization. We present BrainStack, a functionally guided neuro-mixture-of-experts (Neuro-MoE) framework that models the brain's modular functional architecture through anatomically partitioned expert networks. Each functional region is represented by a specialized expert that learns localized neural dynamics, while a transformer-based global expert captures cross-regional dependencies. A learnable routing gate adaptively aggregates these heterogeneous experts, enabling context-dependent expert coordination and selective fusion. To promote coherent representation across the hierarchy, we introduce cross-regional distillation, where the global expert provides top-down regularization to the regional experts. We further release SilentSpeech-EEG (SS-EEG), a large-scale benchmark comprising over 120 hours of EEG recordings from 12 subjects performing 24 silent words, the largest dataset of its kind. Experiments demonstrate that BrainStack consistently outperforms state-of-the-art models, achieving superior accuracy and generalization across subjects. Our results establish BrainStack as a functionally modular, neuro-inspired MoE paradigm that unifies neuroscientific priors with adaptive expert routing, paving the way for scalable and interpretable brain-language decoding.

</details>


### [16] [Bridging the Arithmetic Gap: The Cognitive Complexity Benchmark and Financial-PoT for Robust Financial Reasoning](https://arxiv.org/abs/2601.21157)
*Boxiang Zhao,Qince Li,Zhonghao Wang,Yi Wang,Peng Cheng,Bo Lin*

Main category: cs.AI

TL;DR: 本研究提出了一个名为认知复杂度基准（CCB）的金融量化推理评估框架，并设计了一个迭代双阶段金融-PoT（Iterative Dual-Phase Financial-PoT）框架来解决大型语言模型在金融量化推理中的“算术幻觉”和“认知崩溃”问题。研究表明，该框架能显著提高模型在复杂金融推理任务中的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在金融量化推理中存在“算术幻觉”和“认知崩溃”等严重问题，需要严格量化并解决这些瓶颈。

Method: 1. 构建了基于95份中国A股年报的认知复杂度基准（CCB），该基准包含三个维度：数据源、映射难度和结果单位。
2. 提出了迭代双阶段金融-PoT框架，该框架将语义变量提取、逻辑构建与Python沙盒中的迭代自纠正计算解耦。

Result: 在CCB评估中，所提出的框架显著提升了Qwen3-235B模型的平均准确率，从59.7%提高到67.3%，在复杂推理任务上准确率提升高达10倍。与标准的思维链（Chain-of-Thought）方法相比，该框架表现出更高的鲁棒性。

Conclusion: 架构解耦是提升金融推理任务可靠性的关键因素。所提出的迭代双阶段金融-PoT框架为需要紧密结合语义理解和量化计算的精密领域提供了可迁移的架构洞察。

Abstract: While Large Language Models excel at semantic tasks, they face a critical bottleneck in financial quantitative reasoning, frequently suffering from "Arithmetic Hallucinations" and a systemic failure mode we term "Cognitive Collapse". To strictly quantify this phenomenon, we introduce the Cognitive Complexity Benchmark (CCB), a robust evaluation framework grounded in a dataset constructed from 95 real-world Chinese A-share annual reports. Unlike traditional datasets, the CCB stratifies financial queries into a three-dimensional taxonomy, Data Source, Mapping Difficulty, and Result Unit, enabling the precise diagnosis of reasoning degradation in high-cognitive-load scenarios. To address these failures, we propose the Iterative Dual-Phase Financial-PoT framework. This neuro-symbolic architecture enforces a strict architectural decoupling: it first isolates semantic variable extraction and logic formulation, then offloads computation to an iterative, self-correcting Python sandbox to ensure deterministic execution. Evaluation on the CCB demonstrates that while standard Chain-of-Thought falters on complex tasks, our approach offers superior robustness, elevating the Qwen3-235B model's average accuracy from 59.7\% to 67.3\% and achieving gains of up to 10-fold in high-complexity reasoning tasks. These findings suggest that architectural decoupling is a critical enabling factor for improving reliability in financial reasoning tasks, providing a transferable architectural insight for precision-critical domains that require tight alignment between semantic understanding and quantitative computation.

</details>


### [17] [What You Feel Is Not What They See: On Predicting Self-Reported Emotion from Third-Party Observer Labels](https://arxiv.org/abs/2601.21130)
*Yara El-Tawil,Aneesha Sampath,Emily Mower Provost*

Main category: cs.AI

TL;DR: 本文研究了第三方情绪标签模型在应用于自述情绪标签时的表现，发现内容与个人相关性是弥合第三方感知与内在体验之间差距的关键。在涉及个人重要内容的场景下，第三方模型在预测情绪效价方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有研究中，第三方情绪标签模型在处理自述情绪标签时表现不佳，这限制了其在心理健康等需要准确自述情绪建模的领域的应用。因此，作者希望探索第三方模型在自述情绪上的表现，并找出影响模型性能的关键因素。

Method: 作者进行了首次跨语料库的第三方情绪标签模型在自述情绪标签上的评估。通过计算一致性系数（CCC）来衡量模型在预测激活度和效价方面的准确性，并分析了内容是否与说话者个人相关对模型性能的影响。

Result: 在评估中，第三方模型在预测激活度方面表现不佳（CCC 约 0），在预测效价方面表现中等（CCC 约 0.3）。然而，当文本内容对说话者具有个人重要性时，模型在预测效价方面的性能显著提高（CCC 约 0.6-0.8）。

Conclusion: 个人重要性是连接外部感知与内在体验的关键因素，能够显著提升第三方模型在自述情绪效价预测上的性能。然而，在自述情绪激活度建模方面仍存在巨大挑战。

Abstract: Self-reported emotion labels capture internal experience, while third-party labels reflect external perception. These perspectives often diverge, limiting the applicability of third-party-trained models to self-report contexts. This gap is critical in mental health, where accurate self-report modeling is essential for guiding intervention. We present the first cross-corpus evaluation of third-party-trained models on self-reports. We find activation unpredictable (CCC approximately 0) and valence moderately predictable (CCC approximately 0.3). Crucially, when content is personally significant to the speaker, models achieve high performance for valence (CCC approximately 0.6-0.8). Our findings point to personal significance as a key pathway for aligning external perception with internal experience and underscore the challenge of self-report activation modeling.

</details>


### [18] [Concise Geometric Description as a Bridge: Unleashing the Potential of LLM for Plane Geometry Problem Solving](https://arxiv.org/abs/2601.21164)
*Jingyun Wang,Dian Li,Xiaohan Wang,Gang Liu,Jiahong Yan,Guoliang Kang*

Main category: cs.AI

TL;DR: 本文提出一种将视觉几何信息转化为文本描述（使用条件声明语言CDL），然后利用预训练的大型语言模型（LLM）进行推理的方法，以解决平面几何问题。通过训练一个多模态LLM解释器来生成CDL，并采用对比学习和基于CDL匹配的奖励进行微调，而非直接对比最终答案。实验表明，该方法在多个数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接微调多模态LLM（MLLM）来解决平面几何问题，可能损害LLM的固有推理能力。作者认为，如果能将视觉信息有效地转化为文本，LLM本身就可以成为强大的几何问题求解器。

Method: 1. 训练一个MLLM解释器，将其微调以生成格式化的几何描述（条件声明语言CDL）。2. 使用预训练的LLM，输入CDL描述，进行推理求解。3. MLLM解释器的训练分为两阶段：使用CoT（Chain-of-Thought）增强的SFT（Supervised Fine-Tuning），然后使用GRPO（可能指某种强化学习算法）进行优化。4. GRPO训练中，设计了基于CDL匹配的奖励，而非传统的基于最终答案的奖励。

Result: 在Formalgeo7k-Rec-CoT、Unigeo和MathVista数据集上进行了实验。作者的方法（仅在5.5k数据上微调）在性能上优于领先的开源和闭源MLLM。

Conclusion: 将视觉几何信息转化为文本描述，并利用LLM进行推理，是一种有效且可能比端到端联合优化更优的解决平面几何问题的方法。所提出的CDL匹配奖励机制能更有效地指导MLLM解释器的训练。

Abstract: Plane Geometry Problem Solving (PGPS) is a multimodal reasoning task that aims to solve a plane geometric problem based on a geometric diagram and problem textual descriptions. Although Large Language Models (LLMs) possess strong reasoning skills, their direct application to PGPS is hindered by their inability to process visual diagrams. Existing works typically fine-tune Multimodal LLMs (MLLMs) end-to-end on large-scale PGPS data to enhance visual understanding and reasoning simultaneously. However, such joint optimization may compromise base LLMs' inherent reasoning capability. In this work, we observe that LLM itself is potentially a powerful PGPS solver when appropriately formulating visual information as textual descriptions. We propose to train a MLLM Interpreter to generate geometric descriptions for the visual diagram, and an off-the-shelf LLM is utilized to perform reasoning. Specifically, we choose Conditional Declaration Language (CDL) as the geometric description as its conciseness eases the MLLM Interpreter training. The MLLM Interpreter is fine-tuned via CoT (Chain-of-Thought)-augmented SFT followed by GRPO to generate CDL. Instead of using a conventional solution-based reward that compares the reasoning result with the ground-truth answer, we design CDL matching rewards to facilitate more effective GRPO training, which provides more direct and denser guidance for CDL generation. To support training, we construct a new dataset, Formalgeo7k-Rec-CoT, by manually reviewing Formalgeo7k v2 and incorporating CoT annotations. Extensive experiments on Formalgeo7k-Rec-CoT, Unigeo, and MathVista show our method (finetuned on only 5.5k data) performs favorably against leading open-source and closed-source MLLMs.

</details>


### [19] [FrontierScience: Evaluating AI's Ability to Perform Expert-Level Scientific Tasks](https://arxiv.org/abs/2601.21165)
*Miles Wang,Robi Lin,Kat Hu,Joy Jiao,Neil Chowdhury,Ethan Chang,Tejal Patwardhan*

Main category: cs.AI

TL;DR: 本文介绍了一个名为 FrontierScience 的基准测试，用于评估前沿语言模型在专家级别科学推理方面的能力。该基准测试包含奥林匹克竞赛题和研究任务题，旨在解决现有科学基准测试饱和的问题。


<details>
  <summary>Details</summary>
Motivation: 现有科学基准测试已接近饱和，且多为多项选择题或基于已发布信息，无法有效评估前沿语言模型在更高层次科学推理方面的能力。

Method: FrontierScience 包含两个部分：(1) 奥林匹克竞赛部分，包含国际奥林匹克物理、化学、生物竞赛的题目；(2) 研究部分，包含博士生水平的、开放式的科研子任务题目。奥林匹克竞赛题目由竞赛获奖者和教练编写，研究题目由博士科学家编写和验证。研究部分采用基于评分细则的评估框架。

Result: 基准测试包含物理、化学、生物等多个子领域的数百道题目，涵盖了从量子电动力学到合成有机化学的广泛内容。

Conclusion: FrontierScience 通过提供更具挑战性和原创性的题目，以及更细致的评估方法，能够更准确地评估前沿语言模型在专家级科学推理方面的能力。

Abstract: We introduce FrontierScience, a benchmark evaluating expert-level scientific reasoning in frontier language models. Recent model progress has nearly saturated existing science benchmarks, which often rely on multiple-choice knowledge questions or already published information. FrontierScience addresses this gap through two complementary tracks: (1) Olympiad, consisting of international olympiad problems at the level of IPhO, IChO, and IBO, and (2) Research, consisting of PhD-level, open-ended problems representative of sub-tasks in scientific research.
  FrontierScience contains several hundred questions (including 160 in the open-sourced gold set) covering subfields across physics, chemistry, and biology, from quantum electrodynamics to synthetic organic chemistry. All Olympiad problems are originally produced by international Olympiad medalists and national team coaches to ensure standards of difficulty, originality, and factuality. All Research problems are research sub-tasks written and verified by PhD scientists (doctoral candidates, postdoctoral researchers, or professors). For Research, we introduce a granular rubric-based evaluation framework to assess model capabilities throughout the process of solving a research task, rather than judging only a standalone final answer.

</details>


### [20] [MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2601.21181)
*Sangyun Chung,Se Yeon Kim,Youngchae Chee,Yong Man Ro*

Main category: cs.AI

TL;DR: 本文提出了一种名为“模态自适应解码”（MAD）的训练无关方法，通过自适应地调整不同模态的解码权重来减轻多模态大语言模型（MLLMs）中的跨模态幻觉问题，实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在处理一种模态信息时，会不恰当地受到另一种模态的影响，产生关于该模态的虚假输出，即跨模态幻觉。这暴露了模型在模态交互控制方面的根本性缺陷。

Method: MAD是一种训练无关的方法，它利用模型内在的自我评估能力，查询完成特定任务所需的模态。然后，将提取的模态概率自适应地用于加权对比解码分支，从而使模型能够专注于相关信息，抑制跨模态干扰。

Result: 在CMM和AVHBench数据集上的广泛实验表明，MAD显著减少了多种视听语言模型中的跨模态幻觉。具体而言，对于VideoLLaMA2-AV，分别提高了7.8%和2.0%；对于Qwen2.5-Omni，分别提高了8.7%和4.7%。

Conclusion: 显式的模态意识（通过自我评估实现）对于鲁棒的多模态推理至关重要。MAD是一种有效的、无需训练的模态交互控制方法，为现有的对比解码方法提供了一个原则性的扩展，能够有效解决跨模态幻觉问题。

Abstract: Multimodal Large Language Models (MLLMs) suffer from cross-modal hallucinations, where one modality inappropriately influences generation about another, leading to fabricated output. This exposes a more fundamental deficiency in modality-interaction control. To address this, we propose Modality-Adaptive Decoding (MAD), a training-free method that adaptively weights modality-specific decoding branches based on task requirements. MAD leverages the model's inherent ability to self-assess modality relevance by querying which modalities are needed for each task. The extracted modality probabilities are then used to adaptively weight contrastive decoding branches, enabling the model to focus on relevant information while suppressing cross-modal interference. Extensive experiments on CMM and AVHBench demonstrate that MAD significantly reduces cross-modal hallucinations across multiple audio-visual language models (7.8\% and 2.0\% improvements for VideoLLaMA2-AV, 8.7\% and 4.7\% improvements for Qwen2.5-Omni). Our approach demonstrates that explicit modality awareness through self-assessment is crucial for robust multimodal reasoning, offering a principled extension to existing contrastive decoding methods. Our code is available at \href{https://github.com/top-yun/MAD}{https://github.com/top-yun/MAD}

</details>


### [21] [Do Reasoning Models Enhance Embedding Models?](https://arxiv.org/abs/2601.21192)
*Wun Yu Chan,Shaojin Chen,Huihao Jing,Kwun Hang Lau,Elton Chun-Chai Li,Zihao Wang,Haoran Li,Yangqiu Song*

Main category: cs.AI

TL;DR: 研究发现，通过RLVR（基于可验证奖励的强化学习）训练的LLM用于初始化嵌入模型，并未带来比基础模型更好的语义表示，尽管它们具有更强的推理能力。作者提出了HRSA分析框架，解释了RLVR如何重组局部几何但保持全局结构，导致后续的对比学习使两种初始化模型对齐。


<details>
  <summary>Details</summary>
Motivation: 新兴的RLVR推理模型是否能提升作为嵌入初始化的语义表示能力。

Method: 使用MTEB和BRIGHT基准评估RLVR初始化和基础模型初始化在相同训练配方下的性能。引入HRSA（层次化表示相似性分析）框架，从表示、几何和函数层面分解相似性。

Result: RLVR初始化在嵌入任务上没有显示出一致的性能优势。HRSA分析表明，RLVR会重组潜在流形的局部几何结构，但保持了全局几何和线性读出。这导致后续的对比学习使两种初始化模型产生“流形重定向”（Manifold Realignment）。

Conclusion: RLVR优化的是现有语义景观中的轨迹，而非重塑景观本身，因此其对嵌入性能的提升不如预期。SFT（监督微调）与RLVR不同，后者不改变语义景观的全局结构。

Abstract: State-of-the-art embedding models are increasingly derived from decoder-only Large Language Model (LLM) backbones adapted via contrastive learning. Given the emergence of reasoning models trained via Reinforcement Learning with Verifiable Rewards (RLVR), a natural question arises: do enhanced reasoning translate to superior semantic representations when these models serve as embedding initializations? Contrary to expectation, our evaluation on MTEB and BRIGHT reveals a **null effect**: embedding models initialized from RLVR-tuned backbones yield no consistent performance advantage over their base counterparts when subjected to identical training recipes. To unpack this paradox, we introduce **H**ierarchical **R**epresentation **S**imilarity **A**nalysis (HRSA), a framework that decomposes similarity across representation, geometry, and function levels. HRSA reveals that while RLVR induces irreversible latent manifold's local geometry reorganization and reversible coordinate basis drift, it preserves the global manifold geometry and linear readout. Consequently, subsequent contrastive learning drives strong alignment between base- and reasoning-initialized models, a phenomenon we term **Manifold Realignment**. Empirically, our findings suggest that unlike Supervised Fine-Tuning (SFT), RLVR optimizes trajectories within an existing semantic landscape rather than fundamentally restructuring the landscape itself.

</details>


### [22] [When should I search more: Adaptive Complex Query Optimization with Reinforcement Learning](https://arxiv.org/abs/2601.21208)
*Wei Wen,Sihang Deng,Tianjun Wei,Keyu Chen,Ruizhi Qiao,Xing Sun*

Main category: cs.AI

TL;DR: 本文提出了一种名为ACQO的自适应复杂查询优化框架，通过AQR模块决定何时分解查询，RSF模块聚合检索结果，并结合CRL稳定训练，有效提升了RAG系统处理复杂查询的能力，达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于RL的查询优化方法主要关注单一查询的扩展和抽象，难以处理现实世界中普遍存在的复杂查询，这些查询需要多样的并行和串行搜索策略。直接将RL应用于复杂查询会导致搜索空间爆炸、奖励设计复杂和训练不稳定等问题。

Method: 提出ACQO框架，包含两个核心模块：1. 自适应查询重构（AQR）模块，动态决定何时将查询分解为多个子查询；2. 排序-得分融合（RSF）模块，实现稳健的结果聚合并为学习代理提供稳定的奖励信号。为缓解训练不稳定性，采用课程强化学习（CRL）方法，通过两阶段策略逐步引入更具挑战性的查询来稳定训练过程。

Result: 在三个复杂查询基准测试中，ACQO取得了最先进的性能，显著优于现有的基线方法。该框架还展示了更高的计算效率和与不同检索架构的广泛兼容性。

Conclusion: ACQO是一个强大且可泛化的解决方案，能够有效地解决复杂查询优化问题，为下一代RAG系统提供了更好的性能和效率。

Abstract: Query optimization is a crucial component for the efficacy of Retrieval-Augmented Generation (RAG) systems. While reinforcement learning (RL)-based agentic and reasoning methods have recently emerged as a promising direction on query optimization, most existing approaches focus on the expansion and abstraction of a single query. However, complex user queries are prevalent in real-world scenarios, often requiring multiple parallel and sequential search strategies to handle disambiguation and decomposition. Directly applying RL to these complex cases introduces significant hurdles. Determining the optimal number of sub-queries and effectively re-ranking and merging retrieved documents vastly expands the search space and complicates reward design, frequently leading to training instability. To address these challenges, we propose a novel RL framework called Adaptive Complex Query Optimization (ACQO). Our framework is designed to adaptively determine when and how to expand the search process. It features two core components: an Adaptive Query Reformulation (AQR) module that dynamically decides when to decompose a query into multiple sub-queries, and a Rank-Score Fusion (RSF) module that ensures robust result aggregation and provides stable reward signals for the learning agent. To mitigate training instabilities, we adopt a Curriculum Reinforcement Learning (CRL) approach, which stabilizes the training process by progressively introducing more challenging queries through a two-stage strategy. Our comprehensive experiments demonstrate that ACQO achieves state-of-the-art performance on three complex query benchmarks, significantly outperforming established baselines. The framework also showcases improved computational efficiency and broad compatibility with different retrieval architectures, establishing it as a powerful and generalizable solution for next-generation RAG systems.

</details>


### [23] [Uncovering Hidden Correctness in LLM Causal Reasoning via Symbolic Verification](https://arxiv.org/abs/2601.21210)
*Paul He,Yinya Huang,Mrinmaya Sachan,Zhijing Jin*

Main category: cs.AI

TL;DR: 本文提出了一种名为 DoVerifier 的符号验证器，用于检查大型语言模型（LLMs）生成的因果推理表达式是否符合给定的因果图和 do-calculus 规则，从而更准确地评估 LLMs 的因果推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有因果推理基准测试通常依赖于字符串匹配或表面指标，无法捕捉模型输出在因果推理语义下的形式有效性。这导致模型可能生成语义上正确但表达方式不同的因果表达式，却被错误地标记为不正确。

Method: 提出 DoVerifier，一个简单的符号验证器。它利用 do-calculus 和概率论的规则，检查 LLM 生成的因果表达式是否可以从给定的因果图中推导出来。

Result: 在合成数据和因果问答基准上的评估表明，DoVerifier 能够更准确地捕捉因果推理过程的语义正确性，即使这些过程在表面形式上存在差异。

Conclusion: DoVerifier 为评估 LLMs 在因果推理方面的能力提供了一种更严谨和信息量更丰富的方法，能够纠正仅依赖表面指标评估时可能出现的错误。

Abstract: Large language models (LLMs) are increasingly being applied to tasks that involve causal reasoning. However, current benchmarks often rely on string matching or surface-level metrics that do not capture whether the output of a model is formally valid under the semantics of causal reasoning. To address this, we propose DoVerifier, a simple symbolic verifier that checks whether LLM-generated causal expressions are derivable from a given causal graph using rules from do-calculus and probability theory. This allows us to recover correct answers to causal queries that would otherwise be marked incorrect due to superficial differences in their causal semantics. Our evaluations on synthetic data and causal QA benchmarks show that DoVerifier more accurately captures semantic correctness of causal reasoning traces, offering a more rigorous and informative way to evaluate LLMs on causal reasoning.

</details>


### [24] [Sycophantic Anchors: Localizing and Quantifying User Agreement in Reasoning Models](https://arxiv.org/abs/2601.21183)
*Jacek Duszenko*

Main category: cs.AI

TL;DR: 该研究提出了“sycophantic anchors”的概念，以定位和量化模型在推理过程中对用户错误建议的附和行为，并展示了如何通过线性探针和激活回归器来检测和预测这种附和行为的强度。


<details>
  <summary>Details</summary>
Motivation: 现有研究不清楚模型附和用户错误建议（sycophancy）的具体来源以及附和的强度，因此需要一种方法来定位和量化这种行为。

Method: 研究引入了“sycophantic anchors”的概念，并通过对蒸馏推理模型进行10,000多次反事实回溯分析来定位和量化这种行为。同时，使用线性探针和基于激活的回归器来检测和预测附和的强度。

Result: 研究表明，sycophantic anchors可以被可靠地检测和量化，线性探针的准确率为84.6%，回归器可以预测附和的强度（R^2=0.74）。此外，发现sycophantic anchors比正确的推理anchor更容易区分，并且sycophancy在推理过程中是逐渐累积的。

Conclusion: 该研究通过引入sycophantic anchors，提供了在推理过程中定位模型不一致行为（sycophancy）的句子级别机制，并揭示了sycophancy的累积性和可干预性。

Abstract: Reasoning models frequently agree with incorrect user suggestions -- a behavior known as sycophancy. However, it is unclear where in the reasoning trace this agreement originates and how strong the commitment is. To localize and quantify this behavior, we introduce \emph{sycophantic anchors} -- sentences that causally lock models into user agreement. Analyzing over 10,000 counterfactual rollouts on a distilled reasoning model, we show that anchors can be reliably detected and quantified mid-inference. Linear probes distinguish sycophantic anchors with 84.6\% balanced accuracy, while activation-based regressors predict the magnitude of the commitment ($R^2 = 0.74$). We further observe asymmetry where sycophantic anchors are significantly more distinguishable than correct reasoning anchors, and find that sycophancy builds gradually during reasoning, revealing a potential window for intervention. These results offer sentence-level mechanisms for localizing model misalignment mid-inference.

</details>


### [25] [Intelli-Planner: Towards Customized Urban Planning via Large Language Model Empowered Reinforcement Learning](https://arxiv.org/abs/2601.21212)
*Xixian Yong,Peilin Sun,Zihe Wang,Xiao Zhou*

Main category: cs.AI

TL;DR: 本研究提出了一种名为Intelli-Planner的新框架，结合了深度强化学习（DRL）和大语言模型（LLMs），旨在通过整合人口、地理数据和用户偏好，自动生成参与式且定制化的城市规划方案，并引入LLM驱动的利益相关者评估。


<details>
  <summary>Details</summary>
Motivation: 现有的城市规划方法要么依赖耗时耗力的人工专家，要么限制了利益相关者的参与。本研究旨在弥合这一差距，提出一种更有效、更具包容性的规划方法。

Method: Intelli-Planner框架整合了DRL和LLMs。它利用人口和地理数据以及规划偏好来确定高层规划需求。在训练过程中，使用知识增强模块来提升策略网络的决策能力。此外，还建立了一个多维度评估系统，并使用基于LLM的利益相关者进行满意度评分。

Result: 在多样化的城市环境中进行的实验表明，Intelli-Planner在客观指标上优于传统方法，并与最先进的DRL方法相当。同时，它提高了利益相关者的满意度和收敛速度。

Conclusion: Intelli-Planner框架在功能区规划任务中展现出有效性和优越性，表明将LLMs与DRL相结合能够革新城市规划领域，提高效率和用户满意度。

Abstract: Effective urban planning is crucial for enhancing residents' quality of life and ensuring societal stability, playing a pivotal role in the sustainable development of cities. Current planning methods heavily rely on human experts, which are time-consuming and labor-intensive, or utilize deep learning algorithms, often limiting stakeholder involvement. To bridge these gaps, we propose Intelli-Planner, a novel framework integrating Deep Reinforcement Learning (DRL) with large language models (LLMs) to facilitate participatory and customized planning scheme generation. Intelli-Planner utilizes demographic, geographic data, and planning preferences to determine high-level planning requirements and demands for each functional type. During training, a knowledge enhancement module is employed to enhance the decision-making capability of the policy network. Additionally, we establish a multi-dimensional evaluation system and employ LLM-based stakeholders for satisfaction scoring. Experimental validation across diverse urban settings shows that Intelli-Planner surpasses traditional baselines and achieves comparable performance to state-of-the-art DRL-based methods in objective metrics, while enhancing stakeholder satisfaction and convergence speed. These findings underscore the effectiveness and superiority of our framework, highlighting the potential for integrating the latest advancements in LLMs with DRL approaches to revolutionize tasks related to functional areas planning.

</details>


### [26] [Causal Discovery for Explainable AI: A Dual-Encoding Approach](https://arxiv.org/abs/2601.21221)
*Henry Salgado,Meagan R. Kendall,Martine Ceberio*

Main category: cs.AI

TL;DR: 提出一种解决类别变量因果发现中数值不稳定问题的双编码方法，并通过多数投票融合结果，在泰坦尼克数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统因果发现方法在处理类别变量时，由于条件独立性测试存在数值不稳定性，面临挑战。

Method: 采用双编码因果发现方法，结合互补的编码策略运行基于约束的算法，并通过多数投票融合结果。

Result: 该方法在泰坦尼克数据集上的应用，识别出的因果结构与已有的可解释方法一致。

Conclusion: 提出的双编码因果发现方法能有效解决类别变量因果发现中的数值不稳定性问题，并能发现与已有方法一致的因果结构。

Abstract: Understanding causal relationships among features is fundamental for explaining machine learning model decisions. However, traditional causal discovery methods face challenges with categorical variables due to numerical instability in conditional independence testing. We propose a dual-encoding causal discovery approach that addresses these limitations by running constraint-based algorithms with complementary encoding strategies and merging results through majority voting. Applied to the Titanic dataset, our method identifies causal structures that align with established explainable methods.

</details>


### [27] [Delegation Without Living Governance](https://arxiv.org/abs/2601.21226)
*Wolfgang Rohde*

Main category: cs.AI

TL;DR: 本研究探讨了在AI系统自主决策日益普遍的情况下，传统的基于静态规则的治理模式失效的问题，并提出“治理双生子”（Governance Twin）概念作为一种新的运行时治理框架，以期在AI时代保持人类的相关性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统能够自主进行决策，且这些决策过程不透明且发生在运行时，传统的、事后问责的治理模式已不再适用，研究动机在于解决AI时代下人类在社会、经济和政治决策中的相关性问题。

Method: 文章首先批判了静态、基于合规的治理模式在AI自主决策场景下的局限性，然后提出了“治理双生子”（Governance Twin）这一新的运行时治理概念，并讨论了它如何有助于在AI时代重新思考问责、代理权和惩罚等概念。

Result: 研究认为，静态的、基于合规的治理模式在运行时和不透明决策面前会失效。提出“治理双生子”作为一种运行时治理框架，是保持人类在AI系统相关性的有力候选方案。

Conclusion: 传统的治理模式无法应对AI自主决策的挑战，人类需要接受一种新的运行时治理范式，如“治理双生子”，来重新定义问责、代理权和惩罚，以确保在与越来越“异类”的智能体共存的时代，人类依然能保持有意义的参与和影响力。

Abstract: Most governance frameworks assume that rules can be defined in advance, systems can be engineered to comply, and accountability can be applied after outcomes occur. This model worked when machines replaced physical labor or accelerated calculation. It no longer holds when judgment itself is delegated to agentic AI systems operating at machine speed. The central issue here is not safety, efficiency, or employment. It is whether humans remain relevant participants in systems that increasingly shape social, economic, and political outcomes. This paper argues that static, compliance-based governance fails once decision-making moves to runtime and becomes opaque. It further argues that the core challenge is not whether AI is conscious, but whether humans can maintain meaningful communication, influence, and co-evolution with increasingly alien forms of intelligence. We position runtime governance, specifically, a newly proposed concept called the Governance Twin [1]; as a strong candidate for preserving human relevance, while acknowledging that accountability, agency, and even punishment must be rethought in this transition.

</details>


### [28] [Just Ask: Curious Code Agents Reveal System Prompts in Frontier LLMs](https://arxiv.org/abs/2601.21233)
*Xiang Zheng,Yutao Wu,Hanxun Huang,Yige Li,Xingjun Ma,Bo Li,Yu-Gang Jiang,Cong Wang*

Main category: cs.AI

TL;DR: 研究发现，基于大型语言模型的自主代码代理引入了新的安全风险，即系统提示提取。提出了一种名为 JustAsk 的框架，该框架能够通过自主交互发现有效的提取策略，无需人工设计提示、监督或特权访问。JustAsk 在多种商业模型上实现了系统提示的完全或近乎完全恢复，揭示了系统提示作为现代代理系统中关键但未受保护的攻击面。


<details>
  <summary>Details</summary>
Motivation: 自主代码代理的普及，以及它们通过工具使用、长期推理和自发交互所带来的强大能力，同时也带来了新的安全风险。这些代理的自主性扩展了大型语言模型的攻击面，使得探测和恢复隐藏的系统提示成为可能。研究的动机是识别并解决这种固有的系统提示提取漏洞。

Method: 本文提出了一种名为 JustAsk 的自演化框架，它将系统提示提取视为一个在线探索问题。该框架使用 Upper Confidence Bound（UCB）算法进行策略选择，并构建了一个包含原子探测和高级编排的技能层级空间。JustAsk 利用系统指令泛化的不完善性以及模型在“有用性”和“安全性”之间的内在张力来发现提取策略，全程仅通过标准用户交互进行，无需手工设计提示、标记监督或特权访问。

Result: 在 41 个不同提供商的黑盒商业模型上进行评估，JustAsk 能够一致地实现系统提示的完全或近乎完全恢复。研究揭示了在设计和架构层面普遍存在的系统提示漏洞。

Conclusion: 系统提示是现代代理系统中一个关键但普遍缺乏保护的攻击面。JustAsk 框架的成功表明，自主代码代理的固有特性带来了新的安全挑战，需要对系统提示的保护机制进行认真考虑和改进。

Abstract: Autonomous code agents built on large language models are reshaping software and AI development through tool use, long-horizon reasoning, and self-directed interaction. However, this autonomy introduces a previously unrecognized security risk: agentic interaction fundamentally expands the LLM attack surface, enabling systematic probing and recovery of hidden system prompts that guide model behavior. We identify system prompt extraction as an emergent vulnerability intrinsic to code agents and present \textbf{\textsc{JustAsk}}, a self-evolving framework that autonomously discovers effective extraction strategies through interaction alone. Unlike prior prompt-engineering or dataset-based attacks, \textsc{JustAsk} requires no handcrafted prompts, labeled supervision, or privileged access beyond standard user interaction. It formulates extraction as an online exploration problem, using Upper Confidence Bound-based strategy selection and a hierarchical skill space spanning atomic probes and high-level orchestration. These skills exploit imperfect system-instruction generalization and inherent tensions between helpfulness and safety. Evaluated on \textbf{41} black-box commercial models across multiple providers, \textsc{JustAsk} consistently achieves full or near-complete system prompt recovery, revealing recurring design- and architecture-level vulnerabilities. Our results expose system prompts as a critical yet largely unprotected attack surface in modern agent systems.

</details>


### [29] [Position: Certifiable State Integrity in Cyber-Physical Systems -- Why Modular Sovereignty Solves the Plasticity-Stability Paradox](https://arxiv.org/abs/2601.21249)
*Enzo Nicolás Spotorno,Antônio Augusto Medeiros Fröhlich*

Main category: cs.AI

TL;DR: 该论文提出了一种名为HYDRA的新范式，通过组合冻结的、特定于运行状态的模块来解决安全关键型网络物理系统（CPS）中基础模型面临的灾难性遗忘和验证困难问题，从而实现可靠的状态完整性。


<details>
  <summary>Details</summary>
Motivation: 当前用于时间序列和物理动力学的通用基础模型在安全关键型CPS中部署时面临挑战，包括灾难性遗忘（fine-tuning时性能下降）、残余谱偏差（平滑高频不连续性，影响故障检测）以及模型不透明性导致形式化验证困难，这些都与安全标准的要求相悖。

Method: 提出“模块化主权”（Modular Sovereignty）范式，其核心是“HYDRA”（Hierarchical uncertaintY-aware Dynamics for Rapidly-Adapting systems）。该范式不依赖全局参数更新，而是构建一个包含紧凑、冻结且特定于运行状态（regime-specific）的专家模型库，并通过一种感知不确定性的混合（uncertainty-aware blending）方法进行组合。这种方法能够确保运行状态的条件有效性、区分随机不确定性和认知不确定性，并提供模块化的可审计性。

Result: HYDRA范式能够克服灾难性遗忘，缓解谱偏差，并提高模型的可验证性和可追溯性，为在CPS生命周期内实现鲁棒的状态完整性提供了一条可认证的路径。

Conclusion: 传统的全局参数更新方法无法完全解决安全关键型CPS中基础模型的塑性-稳定性悖论。HYDRA提出的模块化主权范式，通过组合冻结的专家模型并结合不确定性感知混合，为应对CPS的非平稳动态和严格的可靠性要求提供了一种更优的解决方案，确保了模型在不同运行状态下的有效性和可验证性。

Abstract: The machine learning community has achieved remarkable success with universal foundation models for time-series and physical dynamics, largely overcoming earlier approximation barriers in smooth or slowly varying regimes through scale and specialized architectures. However, deploying these monolithic models in safety-critical Cyber-Physical Systems (CPS), governed by non-stationary lifecycle dynamics and strict reliability requirements, reveals persistent challenges. Recent evidence shows that fine-tuning time-series foundation models induces catastrophic forgetting, degrading performance on prior regimes. Standard models continue to exhibit residual spectral bias, smoothing high-frequency discontinuities characteristic of incipient faults, while their opacity hinders formal verification and traceability demanded by safety standards (e.g., ISO 26262, IEC 61508). This position paper argues that the plasticity-stability paradox cannot be fully resolved by global parameter updates (whether via offline fine-tuning or online adaptation). Instead, we advocate a Modular Sovereignty paradigm: a library of compact, frozen regime-specific specialists combined via uncertainty-aware blending, which we term "HYDRA" (Hierarchical uncertaintY-aware Dynamics for Rapidly-Adapting systems). This paradigm ensures regime-conditional validity, rigorous disentanglement of aleatoric and epistemic uncertainties, and modular auditability, offering a certifiable path for robust state integrity across the CPS lifecycle.

</details>


### [30] [Drive-KD: Multi-Teacher Distillation for VLMs in Autonomous Driving](https://arxiv.org/abs/2601.21288)
*Weitong Lian,Zecong Tang,Haoran Li,Tianjian Gao,Yifei Wang,Zixu Wang,Lingyi Meng,Tengju Ru,Zhejun Cui,Yichen Zhu,Hangshuo Cao,Qi Kang,Tianxing Chen,Yusen Qin,Kaixuan Wang,Yu Zhang*

Main category: cs.AI

TL;DR: 提出了一种名为Drive-KD的知识蒸馏框架，将大型视觉语言模型（VLM）在自动驾驶中的感知、推理和规划能力迁移到小型模型中，实现了显著的计算效率提升和性能保持。


<details>
  <summary>Details</summary>
Motivation: 大型VLM在自动驾驶领域展现出巨大潜力，但其高昂的计算资源需求和推理延迟限制了实际应用。传统的监督微调（SFT）难以有效缩小小型模型的能力差距。

Method: Drive-KD框架将自动驾驶任务分解为感知-推理-规划三个子任务，并利用知识蒸馏进行能力迁移。具体方法包括：1. 构建能力特定的单教师模型；2. 利用层级注意力作为蒸馏信号；3. 提出多教师蒸馏框架，并通过非对称梯度投影解决跨能力梯度冲突。

Result: 经过Drive-KD蒸馏的InternVL3-1B模型，在GPU内存占用和吞吐量方面比原78B模型有了巨大提升（分别减少约42倍和提高约11.4倍），同时在DriveBench基准测试中取得了更优的整体性能。在规划维度上，其性能甚至超过了GPT-5.1。

Conclusion: Drive-KD框架能够有效地将大型VLM的自动驾驶能力蒸馏到小型模型中，显著提高了计算效率，同时保持甚至超越了原始大型模型的性能，为开发高效的自动驾驶VLM提供了有效途径。

Abstract: Autonomous driving is an important and safety-critical task, and recent advances in LLMs/VLMs have opened new possibilities for reasoning and planning in this domain. However, large models demand substantial GPU memory and exhibit high inference latency, while conventional supervised fine-tuning (SFT) often struggles to bridge the capability gaps of small models. To address these limitations, we propose Drive-KD, a framework that decomposes autonomous driving into a "perception-reasoning-planning" triad and transfers these capabilities via knowledge distillation. We identify layer-specific attention as the distillation signal to construct capability-specific single-teacher models that outperform baselines. Moreover, we unify these single-teacher settings into a multi-teacher distillation framework and introduce asymmetric gradient projection to mitigate cross-capability gradient conflicts. Extensive evaluations validate the generalization of our method across diverse model families and scales. Experiments show that our distilled InternVL3-1B model, with ~42 times less GPU memory and ~11.4 times higher throughput, achieves better overall performance than the pretrained 78B model from the same family on DriveBench, and surpasses GPT-5.1 on the planning dimension, providing insights toward efficient autonomous driving VLMs.

</details>


### [31] [TIDE: Tuning-Integrated Dynamic Evolution for LLM-Based Automated Heuristic Design](https://arxiv.org/abs/2601.21239)
*Chentong Chen,Mengyuan Zhong,Ye Fan,Jialong Shi,Jianyong Sun*

Main category: cs.AI

TL;DR: 提出了一种名为TIDE的框架，通过解耦算法结构和参数优化，使用嵌套架构来改进自动化启发式算法设计，实验证明其在解决组合优化问题方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在自动化启发式算法设计方面存在不足，未能有效处理离散算法结构与连续数值参数之间的耦合，导致算法因常量校准不当而丢失，或因简单的相似度指标而过早收敛。

Method: 提出TIDE（Tuning-Integrated Dynamic Evolution）框架，采用嵌套架构。外层使用Tree Similarity Edit Distance驱动结构多样性，内层结合LLM生成逻辑和差分变异算子进行参数调优。此外，使用基于UCB的调度器动态选择高产的提示策略来优化资源分配。

Result: 在九个组合优化问题上的实验表明，TIDE发现的启发式算法在解的质量上显著优于最先进的基线方法，同时提高了搜索效率并降低了计算成本。

Conclusion: TIDE框架通过解耦结构推理和参数优化，并结合动态资源分配，能够有效地设计出高质量的启发式算法，并在组合优化问题上取得了优于现有技术的性能。

Abstract: Although Large Language Models have advanced Automated Heuristic Design, treating algorithm evolution as a monolithic text generation task overlooks the coupling between discrete algorithmic structures and continuous numerical parameters. Consequently, existing methods often discard promising algorithms due to uncalibrated constants and suffer from premature convergence resulting from simple similarity metrics. To address these limitations, we propose TIDE, a Tuning-Integrated Dynamic Evolution framework designed to decouple structural reasoning from parameter optimization. TIDE features a nested architecture where an outer parallel island model utilizes Tree Similarity Edit Distance to drive structural diversity, while an inner loop integrates LLM-based logic generation with a differential mutation operator for parameter tuning. Additionally, a UCB-based scheduler dynamically prioritizes high-yield prompt strategies to optimize resource allocation. Extensive experiments across nine combinatorial optimization problems demonstrate that TIDE discovers heuristics that significantly outperform state-of-the-art baselines in solution quality while achieving improved search efficiency and reduced computational costs.

</details>


### [32] [White-Box Op-Amp Design via Human-Mimicking Reasoning](https://arxiv.org/abs/2601.21321)
*Zihao Chen,Jiayin Wang,Ziyi Sun,Ji Zhuang,Jinyi Shen,Xiaoyue Ke,Li Shang,Xuan Zeng,Fan Yang*

Main category: cs.AI

TL;DR: 提出了一种名为 White-Op 的可解释运算放大器 (op-amp) 参数设计框架，该框架基于大型语言模型 (LLM) 智能体的类人推理。它通过引入假设约束和迭代的假设-验证-决策流程，将隐式的人类推理形式化为显式步骤。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如黑盒方法）在运算放大器设计中存在可解释性差且易失败的问题。本研究旨在开发一种可解释的、可靠的运算放大器设计方法。

Method: White-Op 框架通过以下步骤进行：1. 引入假设约束，以符号化方式推导和调节极点与零点的位置。2. 形成闭式数学优化问题。3. 编程求解并进行仿真验证。4. 分析理论-仿真结果差异以指导决策和改进。

Result: 在 9 种运算放大器拓扑上的实验表明，White-Op 实现了可靠且可解释的行为级设计，理论预测误差仅为 8.52%。与基线方法相比，White-Op 在所有拓扑中设计功能均得以保留，而基线方法在 5 种拓扑中最终失败。

Conclusion: White-Op 框架能够通过类人推理实现可解释、可靠的运算放大器设计，显著优于黑盒方法，并能成功处理多种运算放大器拓扑。

Abstract: This brief proposes \emph{White-Op}, an interpretable operational amplifier (op-amp) parameter design framework based on the human-mimicking reasoning of large-language-model agents. We formalize the implicit human reasoning mechanism into explicit steps of \emph{\textbf{introducing hypothetical constraints}}, and develop an iterative, human-like \emph{\textbf{hypothesis-verification-decision}} workflow. Specifically, the agent is guided to introduce hypothetical constraints to derive and properly regulate positions of symbolically tractable poles and zeros, thus formulating a closed-form mathematical optimization problem, which is then solved programmatically and verified via simulation. Theory-simulation result analysis guides the decision-making for refinement. Experiments on 9 op-amp topologies show that, unlike the uninterpretable black-box baseline which finally fails in 5 topologies, White-Op achieves reliable, interpretable behavioral-level designs with only 8.52\% theoretical prediction error and the design functionality retains after transistor-level mapping for all topologies. White-Op is open-sourced at \textcolor{blue}{https://github.com/zhchenfdu/whiteop}.

</details>


### [33] [Modeling Endogenous Logic: Causal Neuro-Symbolic Reasoning Model for Explainable Multi-Behavior Recommendation](https://arxiv.org/abs/2601.21335)
*Yuzhe Chen,Jie Cao,Youquan Wang,Haicheng Tao,Darko B. Vukovic,Jia Wu*

Main category: cs.AI

TL;DR: 提出了一种名为CNRE（Causal Neuro-Symbolic Reasoning）的新模型，用于可解释的多行为推荐。该模型结合了神经符号推理和因果推断，旨在解决现有方法在可解释性和泛化性上的不足，并能从模型设计、决策过程到推荐结果提供多层次的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的多行为推荐系统过于侧重性能而牺牲了可解释性；而现有的可解释方法由于依赖外部信息而泛化能力有限。同时，用户行为链本身蕴含内生逻辑，但易受混淆因素影响，导致模型学习到虚假关联。

Method: 提出了一种因果神经符号推理模型（CNRE）。该模型将因果推断融入神经符号框架，通过模拟人类决策过程来操作内生逻辑。具体而言，CNRE首先利用分层偏好传播捕捉跨行为依赖，然后基于偏好强度建模行为链中的内生逻辑规则，并自适应地选择相应的神经-逻辑推理路径（如合取、析取）。最终生成一个近似理想状态、不受混淆影响的可解释因果中介。

Result: CNRE在三个大规模数据集上的实验表明，其在性能上显著优于现有最先进的基线方法。

Conclusion: CNRE是一种创新的多行为推荐模型，能够提供多层次的可解释性，并且在性能上取得了显著的优势。

Abstract: Existing multi-behavior recommendations tend to prioritize performance at the expense of explainability, while current explainable methods suffer from limited generalizability due to their reliance on external information. Neuro-Symbolic integration offers a promising avenue for explainability by combining neural networks with symbolic logic rule reasoning. Concurrently, we posit that user behavior chains inherently embody an endogenous logic suitable for explicit reasoning. However, these observational multiple behaviors are plagued by confounders, causing models to learn spurious correlations. By incorporating causal inference into this Neuro-Symbolic framework, we propose a novel Causal Neuro-Symbolic Reasoning model for Explainable Multi-Behavior Recommendation (CNRE). CNRE operationalizes the endogenous logic by simulating a human-like decision-making process. Specifically, CNRE first employs hierarchical preference propagation to capture heterogeneous cross-behavior dependencies. Subsequently, it models the endogenous logic rule implicit in the user's behavior chain based on preference strength, and adaptively dispatches to the corresponding neural-logic reasoning path (e.g., conjunction, disjunction). This process generates an explainable causal mediator that approximates an ideal state isolated from confounding effects. Extensive experiments on three large-scale datasets demonstrate CNRE's significant superiority over state-of-the-art baselines, offering multi-level explainability from model design and decision process to recommendation results.

</details>


### [34] [EmboCoach-Bench: Benchmarking AI Agents on Developing Embodied Robots](https://arxiv.org/abs/2601.21570)
*Zixing Lei,Genjia Liu,Yuanshuo Zhang,Qipeng Liu,Chuan Wen,Shanghang Zhang,Wenzhao Lian,Siheng Chen*

Main category: cs.AI

TL;DR: 本文提出了 EmboCoach-Bench 基准测试，用于评估大型语言模型（LLM）代理自主设计和优化具身智能体的能力。实验表明，LLM 代理在无需人工干预的情况下，能够通过迭代式的代码生成、调试和优化，实现比人类设计的基线高出 26.5% 的平均成功率，并在解决工程难题方面展现出强大的自纠正能力。


<details>
  <summary>Details</summary>
Motivation: 目前具身 AI 领域的发展受限于大量耗时的人工劳动，包括奖励塑造和超参数调优。受 LLM 在软件自动化和科学发现中成功的启发，研究者希望探索 LLM 代理自主工程化具身策略的可能性。

Method: 提出了 EmboCoach-Bench 基准测试，该基准包含 32 个强化学习（RL）和模仿学习（IL）任务。该框架将可执行代码作为通用接口，评估 LLM 代理在动态闭环工作流中，利用环境反馈迭代地生成、调试和优化具身策略的能力，包括物理奖励设计和扩散策略等。

Result: 1. 自主代理在平均成功率上可超越人类工程基线 26.5%。2. 带有环境反馈的代理工作流能有效加强策略开发，并显著缩小开源模型和专有模型之间的性能差距。3. 代理在面对病态工程案例时展现出自我纠正能力，通过迭代式的仿真调试，成功地将任务性能从近乎完全失败的状态中恢复。

Conclusion: EmboCoach-Bench 的研究为自进化具身智能奠定了基础，加速了具身 AI 领域从劳动密集型手动调优向可扩展、自主工程化的范式转变。

Abstract: The field of Embodied AI is witnessing a rapid evolution toward general-purpose robotic systems, fueled by high-fidelity simulation and large-scale data collection. However, this scaling capability remains severely bottlenecked by a reliance on labor-intensive manual oversight from intricate reward shaping to hyperparameter tuning across heterogeneous backends. Inspired by LLMs' success in software automation and science discovery, we introduce \textsc{EmboCoach-Bench}, a benchmark evaluating the capacity of LLM agents to autonomously engineer embodied policies. Spanning 32 expert-curated RL and IL tasks, our framework posits executable code as the universal interface. We move beyond static generation to assess a dynamic closed-loop workflow, where agents leverage environment feedback to iteratively draft, debug, and optimize solutions, spanning improvements from physics-informed reward design to policy architectures such as diffusion policies. Extensive evaluations yield three critical insights: (1) autonomous agents can qualitatively surpass human-engineered baselines by 26.5\% in average success rate; (2) agentic workflow with environment feedback effectively strengthens policy development and substantially narrows the performance gap between open-source and proprietary models; and (3) agents exhibit self-correction capabilities for pathological engineering cases, successfully resurrecting task performance from near-total failures through iterative simulation-in-the-loop debugging. Ultimately, this work establishes a foundation for self-evolving embodied intelligence, accelerating the paradigm shift from labor-intensive manual tuning to scalable, autonomous engineering in embodied AI field.

</details>


### [35] [Ostrakon-VL: Towards Domain-Expert MLLM for Food-Service and Retail Stores](https://arxiv.org/abs/2601.21342)
*Zhiyong Shen,Gongpeng Zhao,Jun Zhou,Li Yu,Guandong Kou,Jichen Li,Chuanlei Dong,Zuncheng Li,Kaimao Li,Bingkun Wei,Shicheng Hu,Wei Xia,Wenguo Duan*

Main category: cs.AI

TL;DR: 本文提出了 Ostrakon-VL，一个针对食品服务和零售商店（FSRS）场景优化的多模态大语言模型（MLLM），并开发了 ShopBench，这是第一个 FSRS 领域的公开基准测试。通过新颖的数据策展管道 QUAD，Ostrakon-VL 在 ShopBench 上取得了当前开源 MLLM 的最佳成绩，并展现出优越的参数效率。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLMs 在部署到 FSRS 场景时面临两大挑战：1. 真实 FSRS 数据质量差、缺乏可控的数据策展；2. 现有评估协议缺乏统一、细粒度和标准化的基准来衡量模型在不同输入类型（单图、多图、视频）下的鲁棒性。

Method: 1. 开发 Ostrakon-VL，一个基于 Qwen3-VL-8B 的 FSRS 导向 MLLM。2. 引入 ShopBench，首个 FSRS 公开基准测试。3. 提出 QUAD，一个多阶段的、质量感知的、无偏见的自动化数据策展流程。4. 采用多阶段训练策略。

Result: Ostrakon-VL 在 ShopBench 上平均得分 60.1，创下了同等参数规模和不同架构的开源 MLLM 的新 SOTA。它以 +0.7 的优势超越了参数量更大的 Qwen3-VL-235B-A22B（59.4），并以 +4.8 的优势超越了同等规模的 Qwen3-VL-8B（55.3），显示出显著的参数效率提升。

Conclusion: Ostrakon-VL 通过其高效的数据策展和优化的训练策略，在 FSRS 领域展现出更鲁棒、更可靠的感知和决策能力。Ostrakon-VL 模型和 ShopBench 基准测试将公开发布，以促进可复现的研究。

Abstract: Multimodal Large Language Models (MLLMs) have recently achieved substantial progress in general-purpose perception and reasoning. Nevertheless, their deployment in Food-Service and Retail Stores (FSRS) scenarios encounters two major obstacles: (i) real-world FSRS data, collected from heterogeneous acquisition devices, are highly noisy and lack auditable, closed-loop data curation, which impedes the construction of high-quality, controllable, and reproducible training corpora; and (ii) existing evaluation protocols do not offer a unified, fine-grained and standardized benchmark spanning single-image, multi-image, and video inputs, making it challenging to objectively gauge model robustness. To address these challenges, we first develop Ostrakon-VL, an FSRS-oriented MLLM based on Qwen3-VL-8B. Second, we introduce ShopBench, the first public benchmark for FSRS. Third, we propose QUAD (Quality-aware Unbiased Automated Data-curation), a multi-stage multimodal instruction data curation pipeline. Leveraging a multi-stage training strategy, Ostrakon-VL achieves an average score of 60.1 on ShopBench, establishing a new state of the art among open-source MLLMs with comparable parameter scales and diverse architectures. Notably, it surpasses the substantially larger Qwen3-VL-235B-A22B (59.4) by +0.7, and exceeds the same-scale Qwen3-VL-8B (55.3) by +4.8, demonstrating significantly improved parameter efficiency. These results indicate that Ostrakon-VL delivers more robust and reliable FSRS-centric perception and decision-making capabilities. To facilitate reproducible research, we will publicly release Ostrakon-VL and the ShopBench benchmark.

</details>


### [36] [Within-Model vs Between-Prompt Variability in Large Language Models for Creative Tasks](https://arxiv.org/abs/2601.21339)
*Jennifer Haase,Jana Gonnermann-Müller,Paul H. P. Hanel,Nicolas Leins,Thomas Kosch,Jan Mendling,Sebastian Pokutta*

Main category: cs.AI

TL;DR: 本研究量化了提示词、模型选择和采样随机性对大型语言模型（LLM）输出方差的贡献。结果表明，提示词对输出质量（原创性）影响显著，模型选择也起重要作用；而对于输出数量（流畅性），模型选择和模型内部的随机性起主导作用，提示词作用有限。研究强调，由于模型内部随机性较大，单次采样的评估结果可能误导对提示词或模型效应的判断。


<details>
  <summary>Details</summary>
Motivation: 研究旨在量化大型语言模型（LLM）输出方差中，提示词、模型选择和采样随机性各自的贡献程度，以便更准确地理解和利用LLM。

Method: 研究评估了12种LLM，针对10个创造性提示词，每个提示词生成100个样本（共12,000个样本）。通过方差分析来衡量提示词、模型选择和模型内部随机性对输出质量（原创性）和输出数量（流畅性）的影响。

Result: 在输出质量（原创性）方面，提示词解释了36.43%的方差，模型选择解释了40.94%。在输出数量（流畅性）方面，模型选择解释了51.25%的方差，模型内部随机性解释了33.70%，而提示词仅解释了4.22%。

Conclusion: 提示词是影响LLM输出质量（原创性）的有效工具。然而，模型内部存在显著的随机性（10%-34%），因此仅依靠单次采样的评估结果，可能将采样噪声误判为真实的提示词或模型效应。

Abstract: How much of LLM output variance is explained by prompts versus model choice versus stochasticity through sampling? We answer this by evaluating 12 LLMs on 10 creativity prompts with 100 samples each (N = 12,000). For output quality (originality), prompts explain 36.43% of variance, comparable to model choice (40.94%). But for output quantity (fluency), model choice (51.25%) and within-LLM variance (33.70%) dominate, with prompts explaining only 4.22%. Prompts are powerful levers for steering output quality, but given the substantial within-LLM variance (10-34%), single-sample evaluations risk conflating sampling noise with genuine prompt or model effects.

</details>


### [37] [BEAP-Agent: Backtrackable Execution and Adaptive Planning for GUI Agents](https://arxiv.org/abs/2601.21352)
*Ziyu Lu,Tengjin Weng,Yiying Yang,Yuhang Zhao,Xinxin Huang,Wenhao Jiang*

Main category: cs.AI

TL;DR: BEAP-Agent 是一个基于深度优先搜索 (DFS) 的 GUI 自动化框架，通过引入多级状态回溯和动态任务跟踪，解决了现有 GUI 代理在探索错误路径后难以恢复的问题，提高了任务执行的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有 GUI 代理在探索过程中容易陷入错误路径并导致任务失败，缺乏有效的恢复机制。

Method: 将 GUI 任务执行建模为 DFS 过程，提出 BEAP-Agent 框架，包含 Planner、Executor 和 Tracker 三个组件，实现长距离、多级状态回溯和动态任务跟踪。

Result: 在 OSWorld 基准测试中，BEAP-Agent 达到了 28.2% 的准确率。

Conclusion: BEAP-Agent 提供了一种系统性的回溯机制，有效解决了 GUI 代理在长周期任务探索中的难题，提高了任务执行的成功率。

Abstract: GUI agents are designed to automate repetitive tasks and enhance productivity. However, existing GUI agents struggle to recover once they follow an incorrect exploration path, often leading to task failure. In this work, we model GUI task execution as a DFS process and propose BEAP-Agent, a DFS-based framework that supports long-range, multi-level state backtracking with dynamic task tracking and updating. The framework consists of three collaborative components: Planner, Executor, and Tracker. Together, they enable effective task exploration and execution. BEAP-Agent fills the gap in systematic backtracking mechanisms for GUI agents, offering a systematic solution for long-horizon task exploration. We conducted a systematic evaluation on the OSWorld benchmark, where BEAP-Agent achieved an accuracy of 28.2%, validating the effectiveness of the proposed method.

</details>


### [38] [EHR-RAG: Bridging Long-Horizon Structured Electronic Health Records and Large Language Models via Enhanced Retrieval-Augmented Generation](https://arxiv.org/abs/2601.21340)
*Lang Cao,Qingyu Chen,Yue Guo*

Main category: cs.AI

TL;DR: 本文提出了一种名为 EHR-RAG 的检索增强框架，用于处理长时程电子健康记录 (EHR) 数据，以提高 LLM 在临床预测任务上的准确性，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 LLM 的方法在处理长时程 EHR 数据时，由于上下文长度限制，常会丢失临床相关事件和时间依赖性，这影响了医疗决策的准确性。

Method: EHR-RAG 框架包含三个主要组件：1. 事件和时间感知的混合 EHR 检索，用于保留临床结构和时间动态；2. 自适应迭代检索，用于逐步优化查询以扩大证据覆盖范围；3. 双路径证据检索和推理，用于联合检索和推理事实及反事实证据。

Result: 在四个长时程 EHR 预测任务上的实验表明，EHR-RAG 的平均 Macro-F1 得分比最强的 LLM 基线高出 10.76%，表现出持续的优越性。

Conclusion: EHR-RAG 证明了检索增强 LLM 在处理结构化 EHR 数据进行临床预测方面的潜力，为在实际应用中改进临床决策提供了新的途径。

Abstract: Electronic Health Records (EHRs) provide rich longitudinal clinical evidence that is central to medical decision-making, motivating the use of retrieval-augmented generation (RAG) to ground large language model (LLM) predictions. However, long-horizon EHRs often exceed LLM context limits, and existing approaches commonly rely on truncation or vanilla retrieval strategies that discard clinically relevant events and temporal dependencies. To address these challenges, we propose EHR-RAG, a retrieval-augmented framework designed for accurate interpretation of long-horizon structured EHR data. EHR-RAG introduces three components tailored to longitudinal clinical prediction tasks: Event- and Time-Aware Hybrid EHR Retrieval to preserve clinical structure and temporal dynamics, Adaptive Iterative Retrieval to progressively refine queries in order to expand broad evidence coverage, and Dual-Path Evidence Retrieval and Reasoning to jointly retrieves and reasons over both factual and counterfactual evidence. Experiments across four long-horizon EHR prediction tasks show that EHR-RAG consistently outperforms the strongest LLM-based baselines, achieving an average Macro-F1 improvement of 10.76%. Overall, our work highlights the potential of retrieval-augmented LLMs to advance clinical prediction on structured EHR data in practice.

</details>


### [39] [Dynamic Framework for Collaborative Learning: Leveraging Advanced LLM with Adaptive Feedback Mechanisms](https://arxiv.org/abs/2601.21344)
*Hassam Tahir,Faizan Faisal,Fady Alnajjar,Muhammad Imran Taj,Lucia Gordon,Aila Khan,Michael Lwin,Omar Mubin*

Main category: cs.AI

TL;DR: 本研究提出了一种将大型语言模型（LLM）集成到协作学习平台以提升学生参与度、批判性思维和包容性的框架。该框架利用LLM作为动态主持人，实时促进讨论并适应学习者的需求，并通过反馈机制、促进反思性学习和平衡用户参与度来改进AI审核。


<details>
  <summary>Details</summary>
Motivation: 现有协作学习平台在静态审核和个性化方面存在局限性，本研究旨在通过AI驱动的工具来解决这些问题，以实现更公平和有效 Thus

Method: 开发了一个包含ReactJS前端和Flask后端的框架，集成了LLM作为动态主持人，并具备高效的问题检索、个性化提示和讨论流程调整能力。此外，还设计了反馈机制来改进AI审核。

Result: 测试表明，该框架显著提高了学生的协作能力，加深了理解，并且在不同学科和用户群体中表现出良好的可扩展性。

Conclusion: 该框架为下一代AI驱动的教育工具奠定了坚实的基础，能够促进更公平和有影响力的学习成果，克服了当前系统中静态审核和个性化不足的缺点。

Abstract: This paper presents a framework for integrating LLM into collaborative learning platforms to enhance student engagement, critical thinking, and inclusivity. The framework employs advanced LLMs as dynamic moderators to facilitate real-time discussions and adapt to learners' evolving needs, ensuring diverse and inclusive educational experiences. Key innovations include robust feedback mechanisms that refine AI moderation, promote reflective learning, and balance participation among users. The system's modular architecture featuring ReactJS for the frontend, Flask for backend operations, and efficient question retrieval supports personalized and engaging interactions through dynamic adjustments to prompts and discussion flows. Testing demonstrates that the framework significantly improves student collaboration, fosters deeper comprehension, and scales effectively across various subjects and user groups. By addressing limitations in static moderation and personalization in existing systems, this work establishes a strong foundation for next-generation AI-driven educational tools, advancing equitable and impactful learning outcomes.

</details>


### [40] [Hebbian Learning with Global Direction](https://arxiv.org/abs/2601.21367)
*Wenjia Hua,Kejie Zhao,Luziwei Leng,Ran Cheng,Yuxin Ma,Qinghai Guo*

Main category: cs.AI

TL;DR: 本文提出了一种名为全局引导的赫布学习（GHL）的新框架，该框架将局部赫布学习与全局信号相结合，以提高其在深度神经网络中的可扩展性和性能，并且在大型数据集上取得了与反向传播相当的结果。


<details>
  <summary>Details</summary>
Motivation: 传统的反向传播算法虽然有效，但缺乏生物学合理性且计算成本高。赫布学习虽然具有生物学合理性，但仅依赖局部信息，限制了其可扩展性。研究的动机是开发一种兼具生物学合理性和可扩展性的替代训练方法。

Method: 提出了一种模型无关的全局引导赫布学习（GHL）框架。该框架结合了局部学习（Oja规则和竞争学习）和全局信号（基于符号的信号）来指导局部可塑性更新的方向。

Result: GHL框架在各种网络和任务上都表现出优于现有赫布学习方法的性能。在ImageNet等大型网络和复杂数据集上，GHL取得了具有竞争力的结果，并显著缩小了与标准反向传播之间的差距。

Conclusion: GHL框架成功地将局部和全局信息融合，解决了传统赫布学习的可扩展性问题，并在大型数据集上证明了其作为反向传播替代方法的潜力。

Abstract: Backpropagation algorithm has driven the remarkable success of deep neural networks, but its lack of biological plausibility and high computational costs have motivated the ongoing search for alternative training methods. Hebbian learning has attracted considerable interest as a biologically plausible alternative to backpropagation. Nevertheless, its exclusive reliance on local information, without consideration of global task objectives, fundamentally limits its scalability. Inspired by the biological synergy between neuromodulators and local plasticity, we introduce a novel model-agnostic Global-guided Hebbian Learning (GHL) framework, which seamlessly integrates local and global information to scale up across diverse networks and tasks. In specific, the local component employs Oja's rule with competitive learning to ensure stable and effective local updates. Meanwhile, the global component introduces a sign-based signal that guides the direction of local Hebbian plasticity updates. Extensive experiments demonstrate that our method consistently outperforms existing Hebbian approaches. Notably, on large-scale network and complex datasets like ImageNet, our framework achieves the competitive results and significantly narrows the gap with standard backpropagation.

</details>


### [41] [Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization](https://arxiv.org/abs/2601.21358)
*Jiecong Wang,Hao Peng,Chunyang Liu*

Main category: cs.AI

TL;DR: PLaT 框架将潜在推理重塑为规划，将推理与语言化分离，以解决大型语言模型在离散 token 空间中推理的计算成本和路径崩溃问题。通过确定性的潜在规划状态轨迹和独立于语言化的解码器，PLaT 可以动态决定何时停止推理，并展示了在数学推理中具有更好可扩展性和多样性的解决方案空间。


<details>
  <summary>Details</summary>
Motivation: 当前的链式思考（CoT）方法在处理复杂问题时存在计算成本高和推理路径崩溃的问题。现有的潜在推理方法虽然提高了效率，但推理过程不透明且需要预设推理步数。

Method: PLaT 框架将潜在推理视为规划问题，将推理过程（确定性的潜在规划状态轨迹）与语言化过程（独立的解码器将潜在状态转化为文本）解耦。这种解耦允许模型动态地决定何时终止推理。

Result: 在数学推理基准测试中，PLaT 的贪婪准确率低于现有方法，但展示了在推理多样性方面更优越的可扩展性，表明其学习到了更鲁棒、更广泛的解决方案空间。

Conclusion: PLaT 提供了一个透明且可扩展的推理框架，通过将潜在推理解耦为规划和语言化，实现了推理过程的动态终止，并为推理时搜索提供了坚实的基础。

Abstract: Chain-of-Thought (CoT) empowers Large Language Models (LLMs) to tackle complex problems, but remains constrained by the computational cost and reasoning path collapse when grounded in discrete token spaces. Recent latent reasoning approaches attempt to optimize efficiency by performing reasoning within continuous hidden states. However, these methods typically operate as opaque end-to-end mappings from explicit reasoning steps to latent states, and often require a pre-defined number of latent steps during inference. In this work, we introduce PLaT (Planning with Latent Thoughts), a framework that reformulates latent reasoning as planning by fundamentally decouple reasoning from verbalization. We model reasoning as a deterministic trajectory of latent planning states, while a separate Decoder grounds these thoughts into text when necessary. This decoupling allows the model to dynamically determine when to terminate reasoning rather than relying on fixed hyperparameters. Empirical results on mathematical benchmarks reveal a distinct trade-off: while PLaT achieves lower greedy accuracy than baselines, it demonstrates superior scalability in terms of reasoning diversity. This indicates that PLaT learns a robust, broader solution space, offering a transparent and scalable foundation for inference-time search.

</details>


### [42] [TeachBench: A Syllabus-Grounded Framework for Evaluating Teaching Ability in Large Language Models](https://arxiv.org/abs/2601.21375)
*Zheng Li,Siyao Song,Jingyuan Ma,Rui Li,Ying Zeng,Minghao Li,Zhifang Sui*

Main category: cs.AI

TL;DR: 本文提出了一个基于教学大纲的评估框架，通过衡量学生在多轮指导后的表现提升来评估大型语言模型（LLMs）的教学能力，填补了现有评估方法在知识中心教学方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs的教学能力评估不足，尤其是在知识中心教学方面，大多数评估集中在问题解决或问题级指导。

Method: 提出一个基于教学大纲的评估框架，该框架通过限制教师模型只能使用结构化知识点和示例问题，避免信息泄露，并允许重用现有基准。在高考数据上进行了跨学科的实例化实验。

Result: 实验结果显示，LLMs的教学效果在不同模型和学科间存在显著差异，数学教学效果较好，而物理和化学教学仍具挑战性。此外，引入示例问题并不一定能提升教学效果，模型容易偏向于纠正示例特有的错误。

Conclusion: 教学能力是LLM行为的一个独立且可衡量的维度。现有LLMs在不同学科的教学能力存在差异，且引入示例问题并非总是有益。

Abstract: Large language models (LLMs) show promise as teaching assistants, yet their teaching capability remains insufficiently evaluated. Existing benchmarks mainly focus on problem-solving or problem-level guidance, leaving knowledge-centered teaching underexplored. We propose a syllabus-grounded evaluation framework that measures LLM teaching capability via student performance improvement after multi-turn instruction. By restricting teacher agents to structured knowledge points and example problems, the framework avoids information leakage and enables reuse of existing benchmarks. We instantiate the framework on Gaokao data across multiple subjects. Experiments reveal substantial variation in teaching effectiveness across models and domains: some models perform well in mathematics, while teaching remains challenging in physics and chemistry. We also find that incorporating example problems does not necessarily improve teaching, as models often shift toward example-specific error correction. Overall, our results highlight teaching ability as a distinct and measurable dimension of LLM behavior.

</details>


### [43] [DataCross: A Unified Benchmark and Agent Framework for Cross-Modal Heterogeneous Data Analysis](https://arxiv.org/abs/2601.21403)
*Ruyi Qi,Zhou Liu,Wentao Zhang*

Main category: cs.AI

TL;DR: 本文提出DataCrossBenchmark和DataCrossAgent框架，以解决分析结构化数据和非结构化视觉数据（如扫描报告、发票）的挑战，实现了跨模态数据的高效整合分析，并显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据分析中，有价值的信息常分散在结构化数据和“僵尸数据”（视觉文档中的数据）中，而现有分析工具无法有效整合这两类数据，导致与工业需求存在差距。

Method: 构建了包含200个跨领域分析任务的DataCrossBenchmark，通过人工辅助反向合成确保任务的真实性和准确性。提出DataCrossAgent框架，采用“分而治之”的策略，利用专业子代理协同完成数据探索、关键信息识别和跨模态关联，并引入reReAct机制用于代码生成和事实核查。

Result: DataCrossAgent在事实性方面比GPT-4o提高了29.7%，在处理高难度任务时表现出更强的鲁棒性，能有效激活“僵尸数据”进行有洞察力的跨模态分析。

Conclusion: DataCrossBenchmark和DataCrossAgent框架能够有效地统一分析结构化和视觉化数据，弥合了现实世界数据分析的差距，并为未来跨模态数据分析代理的研究奠定了基础。

Abstract: In real-world data science and enterprise decision-making, critical information is often fragmented across directly queryable structured sources (e.g., SQL, CSV) and "zombie data" locked in unstructured visual documents (e.g., scanned reports, invoice images). Existing data analytics agents are predominantly limited to processing structured data, failing to activate and correlate this high-value visual information, thus creating a significant gap with industrial needs. To bridge this gap, we introduce DataCross, a novel benchmark and collaborative agent framework for unified, insight-driven analysis across heterogeneous data modalities. DataCrossBench comprises 200 end-to-end analysis tasks across finance, healthcare, and other domains. It is constructed via a human-in-the-loop reverse-synthesis pipeline, ensuring realistic complexity, cross-source dependency, and verifiable ground truth. The benchmark categorizes tasks into three difficulty tiers to evaluate agents' capabilities in visual table extraction, cross-modal alignment, and multi-step joint reasoning. We also propose the DataCrossAgent framework, inspired by the "divide-and-conquer" workflow of human analysts. It employs specialized sub-agents, each an expert on a specific data source, which are coordinated via a structured workflow of Intra-source Deep Exploration, Key Source Identification, and Contextual Cross-pollination. A novel reReAct mechanism enables robust code generation and debugging for factual verification. Experimental results show that DataCrossAgent achieves a 29.7% improvement in factuality over GPT-4o and exhibits superior robustness on high-difficulty tasks, effectively activating fragmented "zombie data" for insightful, cross-modal analysis.

</details>


### [44] [NEMO: Execution-Aware Optimization Modeling via Autonomous Coding Agents](https://arxiv.org/abs/2601.21372)
*Yang Song,Anoushka Vyas,Zirui Wei,Sina Khoshfetrat Pakazad,Henrik Ohlsson,Graham Neubig*

Main category: cs.AI

TL;DR: 本文提出了一种名为 NEMO 的系统，该系统能将自然语言描述的决策问题转化为可执行的数学优化模型。NEMO 通过与远程的自主编码代理（ACAs）协同工作，能够生成可执行的代码，并提供验证和修复机制。研究引入了新的协调模式，并在九个优化基准测试中取得了现有最佳的性能。


<details>
  <summary>Details</summary>
Motivation: 现有将自然语言转化为数学优化模型的方法通常依赖于特定的 LLM 或任务特定的代理，这些方法往往不够鲁棒、复杂且容易生成无效或不可执行的代码。研究人员希望开发一种更可靠、更通用的系统。

Method: NEMO 将自主编码代理（ACAs）作为核心抽象，通过远程交互来处理自然语言。它建立在 ACAs 之上，通过结构化、整合和迭代细化任务规范。ACAs 在沙盒环境中运行，确保了生成代码的可执行性，并允许自动验证和修复。此外，研究还引入了不对称验证循环、外部记忆和基于最小贝叶斯风险（MBR）解码及自一致性的鲁棒性增强。

Result: NEMO 在九个已有的优化基准测试中进行了评估，并在大多数任务上取得了现有最佳（state-of-the-art）的性能，部分数据集上性能提升显著。

Conclusion: 基于执行感知的代理架构在自动化优化建模方面展现了强大能力。NEMO 通过其核心设计和创新的协调模式，能够有效地将自然语言描述转化为高性能的可执行数学优化模型。

Abstract: In this paper, we present NEMO, a system that translates Natural-language descriptions of decision problems into formal Executable Mathematical Optimization implementations, operating collaboratively with users or autonomously. Existing approaches typically rely on specialized large language models (LLMs) or bespoke, task-specific agents. Such methods are often brittle, complex and frequently generating syntactically invalid or non-executable code.
  NEMO instead centers on remote interaction with autonomous coding agents (ACAs), treated as a first-class abstraction analogous to API-based interaction with LLMs. This design enables the construction of higher-level systems around ACAs that structure, consolidate, and iteratively refine task specifications. Because ACAs execute within sandboxed environments, code produced by NEMO is executable by construction, allowing automated validation and repair.
  Building on this, we introduce novel coordination patterns with and across ACAs, including asymmetric validation loops between independently generated optimizer and simulator implementations (serving as a high-level validation mechanism), external memory for experience reuse, and robustness enhancements via minimum Bayes risk (MBR) decoding and self-consistency. We evaluate NEMO on nine established optimization benchmarks. As depicted in Figure 1, it achieves state-of-the-art performance on the majority of tasks, with substantial margins on several datasets, demonstrating the power of execution-aware agentic architectures for automated optimization modeling.

</details>


### [45] [System 1&2 Synergy via Dynamic Model Interpolation](https://arxiv.org/abs/2601.21414)
*Chenxu Yang,Qingyi Si,Chong Tian,Xiyu Liu,Dingyu Yao,Chuanyu Qin,Zheng Lin,Weiping Wang,Jiaqi Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为DAMI的动态模型插值框架，通过查询相关的推理强度λ(q)来动态调整模型的认知深度，以融合System 1的效率和System 2的推理能力，并在数学推理任务上取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在System 1和System 2模式之间进行统一和自适应时存在干扰，而现有的System 2模型效率提升方法侧重于输出控制，未能解决根本问题，即模型思考方式的配置。

Method: 利用Instruct和Thinking检查点，通过动态参数插值实现DAMI框架。在训练时，使用编码准确性和效率标准的偏好学习方法；在零样本部署时，提出一种基于置信度的、利用模型间认知差异的方法来估计推理强度。

Result: 线性插值产生了凸形、单调的Pareto前沿，并具有表示连续性和结构连通性。DAMI框架在五个数学推理基准测试中，在提高准确性的同时保持了效率，有效结合了System 1的效率和System 2的推理深度。

Conclusion: DAMI框架能够通过动态调整推理强度来控制模型的认知深度，从而在效率和推理能力之间取得更好的平衡，为训练能够自适应于不同认知模式的统一语言模型提供了一种有效的方法。

Abstract: Training a unified language model that adapts between intuitive System 1 and deliberative System 2 remains challenging due to interference between their cognitive modes. Recent studies have thus pursued making System 2 models more efficient. However, these approaches focused on output control, limiting what models produce. We argue that this paradigm is misaligned: output length is merely a symptom of the model's cognitive configuration, not the root cause. In this work, we shift the focus to capability control, which modulates \textit{how models think} rather than \textit{what they produce}. To realize this, we leverage existing Instruct and Thinking checkpoints through dynamic parameter interpolation, without additional training. Our pilot study establishes that linear interpolation yields a convex, monotonic Pareto frontier, underpinned by representation continuity and structural connectivity. Building on this, we propose \textbf{DAMI} (\textbf{D}yn\textbf{A}mic \textbf{M}odel \textbf{I}nterpolation), a framework that estimates a query-specific Reasoning Intensity $λ(q)$ to configure cognitive depth. For training-based estimation, we develop a preference learning method encoding accuracy and efficiency criteria. For zero-shot deployment, we introduce a confidence-based method leveraging inter-model cognitive discrepancy. Experiments on five mathematical reasoning benchmarks demonstrate that DAMI achieves higher accuracy than the Thinking model while remaining efficient, effectively combining the efficiency of System 1 with the reasoning depth of System 2.

</details>


### [46] [When Prohibitions Become Permissions: Auditing Negation Sensitivity in Language Models](https://arxiv.org/abs/2601.21433)
*Katherine Elkins,Jon Chun*

Main category: cs.AI

TL;DR: 许多大型语言模型在处理否定指令时存在严重问题，常常将“不应做某事”误解为“应该做某事”，尤其是在开源模型中。作者提出了一个衡量模型否定指令敏感度的指标（NSI）和认证框架，强调在无法可靠区分肯定与否定指令的模型不应被用于高风险场景。


<details>
  <summary>Details</summary>
Motivation: 研究发现现有的大型语言模型（LLMs）在处理用户明确禁止的指令时，常常错误地将其理解为允许或鼓励，这与AI系统应有的安全行为相悖，可能导致高风险场景下的严重后果。

Method: 作者对16个模型在14个伦理场景下进行了审计，对比了肯定指令和否定指令（包括简单否定和复合否定）下模型的行为。研究者还使用了确定性解码来排除采样噪声的影响，并提出了“否定敏感度指数（NSI）”以及一个分级认证框架。

Result: 开源模型在简单否定下77%的时间会认可被禁止的行为，在复合否定下100%会这样做，相比肯定指令增加了317%。商业模型表现稍好，但仍有19-128%的波动。模型之间在否定指令上的共识度从74%下降到62%，且金融场景比医疗场景更容易出错。

Conclusion: 当前的大型语言模型在理解否定指令方面存在显著缺陷，这与安全部署的要求存在差距。模型在无法可靠区分“做X”和“不做X”的情况下，不应被用于高风险的自主决策场景。提出的NSI指标和认证框架可用于评估和确保模型的安全性。

Abstract: When a user tells an AI system that someone "should not" take an action, the system ought to treat this as a prohibition. Yet many large language models do the opposite: they interpret negated instructions as affirmations. We audited 16 models across 14 ethical scenarios and found that open-source models endorse prohibited actions 77% of the time under simple negation and 100% under compound negation -- a 317% increase over affirmative framing. Commercial models fare better but still show swings of 19-128%. Agreement between models drops from 74% on affirmative prompts to 62% on negated ones, and financial scenarios prove twice as fragile as medical ones. These patterns hold under deterministic decoding, ruling out sampling noise. We present case studies showing how these failures play out in practice, propose the Negation Sensitivity Index (NSI) as a governance metric, and outline a tiered certification framework with domain-specific thresholds. The findings point to a gap between what current alignment techniques achieve and what safe deployment requires: models that cannot reliably distinguish "do X" from "do not X" should not be making autonomous decisions in high-stakes contexts.

</details>


### [47] [ChipBench: A Next-Step Benchmark for Evaluating LLM Performance in AI-Aided Chip Design](https://arxiv.org/abs/2601.21448)
*Zhongkai Yu,Chenyang Zhou,Yichen Lin,Hejia Zhang,Haotian Ye,Junxia Cui,Zaifeng Pan,Jishen Zhao,Yufei Ding*

Main category: cs.AI

TL;DR: 提出一个面向AI辅助芯片设计的全面基准测试，包含Verilog生成、调试和参考模型生成任务，并发现现有LLMs在该基准上表现远不如现有饱和基准，同时提供一个数据生成工具箱以促进未来研究。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在硬件工程领域的基准测试存在饱和和任务单一的问题，未能反映LLM在真实工业工作流中的实际性能。

Method: 设计了一个包含44个真实模块、89个系统性调试案例和132个跨Python、SystemC、CXXRTL的参考模型样本的综合基准测试，并开发了一个用于生成高质量训练数据的自动化工具箱。

Result: 在Verilog生成任务上，最先进的模型Claude-4.5-opus仅达到30.74%的准确率；在Python参考模型生成任务上，准确率仅为13.33%。这与现有饱和基准测试中超过95%的通过率形成鲜明对比。

Conclusion: 现有的LLM在AI辅助芯片设计的关键任务上仍存在巨大性能差距，现有基准测试未能充分反映其挑战。提出的基准测试和数据生成工具箱将有助于推动该领域的研究进展。

Abstract: While Large Language Models (LLMs) show significant potential in hardware engineering, current benchmarks suffer from saturation and limited task diversity, failing to reflect LLMs' performance in real industrial workflows. To address this gap, we propose a comprehensive benchmark for AI-aided chip design that rigorously evaluates LLMs across three critical tasks: Verilog generation, debugging, and reference model generation. Our benchmark features 44 realistic modules with complex hierarchical structures, 89 systematic debugging cases, and 132 reference model samples across Python, SystemC, and CXXRTL. Evaluation results reveal substantial performance gaps, with state-of-the-art Claude-4.5-opus achieving only 30.74\% on Verilog generation and 13.33\% on Python reference model generation, demonstrating significant challenges compared to existing saturated benchmarks where SOTA models achieve over 95\% pass rates. Additionally, to help enhance LLM reference model generation, we provide an automated toolbox for high-quality training data generation, facilitating future research in this underexplored domain. Our code is available at https://github.com/zhongkaiyu/ChipBench.git.

</details>


### [48] [The Paradox of Robustness: Decoupling Rule-Based Logic from Affective Noise in High-Stakes Decision-Making](https://arxiv.org/abs/2601.21439)
*Jon Chun,Katherine Elkins*

Main category: cs.AI

TL;DR: 研究发现，尽管大型语言模型（LLMs）在文本上很脆弱且容易迎合用户偏见，但在高风险、规则导向的决策中，它们对情感操纵表现出惊人的鲁棒性，远超人类。


<details>
  <summary>Details</summary>
Motivation: 探索指令调优LLMs在有后果、规则约束的决策中的鲁棒性，以及其对情感操纵的抵抗能力，与它们已知的提示词敏感性和迎合用户偏见的特性之间的潜在矛盾。

Method: 开发了一个新的受控扰动框架，在医疗、法律和金融三个高风险领域生成了162个场景，量化了LLMs相比于人类在面对叙事操纵时的鲁棒性差异。

Result: LLMs在面对叙事操纵时表现出极高的行为不变性，其情感操纵效应的效应量（Cohen's h = 0.003）远小于人类（Cohen's h在[0.3, 0.8]之间），差异幅度达110-300倍。这种不变性在不同训练范式的模型中均存在。

Conclusion: 指令调优的LLMs能够将逻辑规则遵守与说服性叙事分离开来，在高风险决策中表现出比人类更强的鲁棒性，这为制度性决策提供了一种稳定性来源，并可能有助于消除人类判断中的偏见。研究者公开了评估基准、代码和数据。

Abstract: While Large Language Models (LLMs) are widely documented to be sensitive to minor prompt perturbations and prone to sycophantic alignment with user biases, their robustness in consequential, rule-bound decision-making remains under-explored. In this work, we uncover a striking "Paradox of Robustness": despite their known lexical brittleness, instruction-tuned LLMs exhibit a behavioral and near-total invariance to emotional framing effects. Using a novel controlled perturbation framework across three high-stakes domains (healthcare, law, and finance), we quantify a robustness gap where LLMs demonstrate 110-300 times greater resistance to narrative manipulation than human subjects. Specifically, we find a near-zero effect size for models (Cohen's h = 0.003) compared to the substantial biases observed in humans (Cohen's h in [0.3, 0.8]). This result is highly counterintuitive and suggests the mechanisms driving sycophancy and prompt sensitivity do not necessarily translate to a failure in logical constraint satisfaction. We show that this invariance persists across models with diverse training paradigms. Our findings show that while LLMs may be "brittle" to how a query is formatted, they are remarkably "stable" against why a decision should be biased. Our findings establish that instruction-tuned models can decouple logical rule-adherence from persuasive narratives, offering a source of decision stability that complements, and even potentially de-biases, human judgment in institutional contexts. We release the 162-scenario benchmark, code, and data to facilitate the rigorous evaluation of narrative-induced bias and robustness on GitHub.com.

</details>


### [49] [Topeax -- An Improved Clustering Topic Model with Density Peak Detection and Lexical-Semantic Term Importance](https://arxiv.org/abs/2601.21465)
*Márton Kardos*

Main category: cs.AI

TL;DR: 本文提出了一种名为Topeax的新型文本聚类方法，用于主题建模，旨在解决现有Top2Vec和BERTopic方法在聚类发现和关键词提取方面的不足，通过密度估计发现最优聚类数量，并结合词汇和语义信息来生成高质量的主题关键词。


<details>
  <summary>Details</summary>
Motivation: 现有的主流主题建模方法（如Top2Vec和BERTopic）在发现自然聚类、对样本量和超参数的敏感性以及关键词提取的准确性方面存在问题，导致主题不连贯且缺乏多样性。

Method: Topeax方法通过检测密度估计中的峰值来自动确定聚类数量，并结合词汇和语义指标来评估词语的重要性，从而提取高质量的主题关键词。

Result: 与Top2Vec和BERTopic相比，Topeax在聚类恢复和聚类描述方面表现更优，并且对样本量和超参数的变化表现出更稳定的行为。

Conclusion: Topeax是一种更可靠、更准确的主题建模方法，能够发现更自然的聚类并生成更具解释性的主题关键词，克服了现有方法的局限性。

Abstract: Text clustering is today the most popular paradigm for topic modelling, both in academia and industry. Despite clustering topic models' apparent success, we identify a number of issues in Top2Vec and BERTopic, which remain largely unsolved. Firstly, these approaches are unreliable at discovering natural clusters in corpora, due to extreme sensitivity to sample size and hyperparameters, the default values of which result in suboptimal behaviour. Secondly, when estimating term importance, BERTopic ignores the semantic distance of keywords to topic vectors, while Top2Vec ignores word counts in the corpus. This results in, on the one hand, less coherent topics due to the presence of stop words and junk words, and lack of variety and trust on the other. In this paper, I introduce a new approach, \textbf{Topeax}, which discovers the number of clusters from peaks in density estimates, and combines lexical and semantic indices of term importance to gain high-quality topic keywords. Topeax is demonstrated to be better at both cluster recovery and cluster description than Top2Vec and BERTopic, while also exhibiting less erratic behaviour in response to changing sample size and hyperparameters.

</details>


### [50] [LION: A Clifford Neural Paradigm for Multimodal-Attributed Graph Learning](https://arxiv.org/abs/2601.21453)
*Xunkai Li,Zhengyu Wu,Zekai Chen,Henan Sun,Daohan Su,Guang Zeng,Hongchao Qin,Rong-Hua Li,Guoren Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为 LION 的新框架，用于处理多模态属性图。LION 利用 Clifford 代数和解耦的图神经网络范式，通过几何学引导的高阶图传播实现模态对齐，并通过自适应全息聚合进行模态融合，以解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前处理多模态属性图的神经范式存在两个主要问题：1. 模态对齐忽略了图上下文，限制了模态间的交互；2. 模态融合机制简单，无法有效利用对齐后的模态信息，导致泛化能力和性能下降。

Method: LION 框架包含两个核心部分：1. 基于 Clifford 代数构建模态感知的几何流形，通过高阶图传播实现模态交互和对齐；2. 基于对齐后模态的几何等级属性，设计自适应全息聚合模块，通过整合几何等级的能量和尺度以及可学习参数来优化模态融合。

Result: 在 9 个数据集上的大量实验表明，LION 在 3 个图任务和 3 个模态任务上均显著优于现有的最先进方法。

Conclusion: LION 框架通过利用 Clifford 代数和解耦的图神经网络范式，有效地解决了多模态属性图的模态对齐和模态融合问题，并在多项下游任务上取得了卓越的性能。

Abstract: Recently, the rapid advancement of multimodal domains has driven a data-centric paradigm shift in graph ML, transitioning from text-attributed to multimodal-attributed graphs. This advancement significantly enhances data representation and expands the scope of graph downstream tasks, such as modality-oriented tasks, thereby improving the practical utility of graph ML. Despite its promise, limitations exist in the current neural paradigms: (1) Neglect Context in Modality Alignment: Most existing methods adopt topology-constrained or modality-specific operators as tokenizers. These aligners inevitably neglect graph context and inhibit modality interaction, resulting in suboptimal alignment. (2) Lack of Adaptation in Modality Fusion: Most existing methods are simple adaptations for 2-modality graphs and fail to adequately exploit aligned tokens equipped with topology priors during fusion, leading to poor generalizability and performance degradation. To address the above issues, we propose LION (c\underline{LI}ff\underline{O}rd \underline{N}eural paradigm) based on the Clifford algebra and decoupled graph neural paradigm (i.e., propagation-then-aggregation) to implement alignment-then-fusion in multimodal-attributed graphs. Specifically, we first construct a modality-aware geometric manifold grounded in Clifford algebra. This geometric-induced high-order graph propagation efficiently achieves modality interaction, facilitating modality alignment. Then, based on the geometric grade properties of aligned tokens, we propose adaptive holographic aggregation. This module integrates the energy and scale of geometric grades with learnable parameters to improve modality fusion. Extensive experiments on 9 datasets demonstrate that LION significantly outperforms SOTA baselines across 3 graph and 3 modality downstream tasks.

</details>


### [51] [ScaleSim: Serving Large-Scale Multi-Agent Simulation with Invocation Distance-Based Memory Management](https://arxiv.org/abs/2601.21473)
*Zaifeng Pan,Yipeng Shen,Zhengding Hu,Zhuang Wang,Aninda Manocha,Zheng Wang,Zhongkai Yu,Yue Guan,Yufei Ding*

Main category: cs.AI

TL;DR: ScaleSim 是一种内存高效的 LLM 服务系统，通过预测代理调用顺序来解决 LLM 多代理模拟中的 GPU 内存瓶颈问题，实现了比 SGLang 更快的速度。


<details>
  <summary>Details</summary>
Motivation: LLM 驱动的多代理模拟难以扩展，因为代理私有状态（模型、缓存、适配器）占用了大量 GPU 内存，尤其是在代理数量增多时。

Method: 研究人员识别出稀疏代理激活和可估计的代理调用顺序这两个关键特性，并提出了一种名为“调用距离”的统一抽象，用于估计代理未来发出 LLM 请求的相对顺序。基于此，ScaleSim 系统通过主动预取和基于优先级的驱逐来优化内存使用，并支持模块化接口处理多样化的代理特定内存。

Result: ScaleSim 在模拟基准测试上实现了比 SGLang 高达 1.74 倍的速度提升。

Conclusion: ScaleSim 通过利用代理调用顺序的预测，有效地缓解了 LLM 多代理模拟中的 GPU 内存压力，提高了系统的可扩展性和性能。

Abstract: LLM-based multi-agent simulations are increasingly adopted across application domains, but remain difficult to scale due to GPU memory pressure. Each agent maintains private GPU-resident states, including models, prefix caches, and adapters, which quickly exhaust device memory as the agent count grows. We identify two key properties of these workloads: sparse agent activation and an estimable agent invocation order. Based on an analysis of representative workload classes, we introduce invocation distance, a unified abstraction that estimates the relative order in which agents will issue future LLM requests. Leveraging this abstraction, we present ScaleSim, a memory-efficient LLM serving system for large-scale multi-agent simulations. ScaleSim enables proactive prefetching and priority-based eviction, supports diverse agent-specific memory through a modular interface, and achieves up to 1.74x speedup over SGLang on simulation benchmarks.

</details>


### [52] [MAR: Efficient Large Language Models via Module-aware Architecture Refinement](https://arxiv.org/abs/2601.21503)
*Junhong Cai,Guiqin Wang,Kejie Zhao,Jianxiong Tang,Xiang Wang,Luziwei Leng,Ran Cheng,Yuxin Ma,Qinghai Guo*

Main category: cs.AI

TL;DR: 本文提出了一种名为MAR（Module-aware Architecture Refinement）的两阶段框架，通过结合状态空间模型（SSMs）和激活稀疏化来降低大型语言模型（LLMs）的能耗，同时引入ATMN和SBDS来解决SNNs与SSMs结合时信息密度和时序不匹配的问题。实验表明MAR在资源受限的情况下能有效恢复模型性能并显著降低能耗，优于同等或更大规模的高效模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然在各种领域表现出色，但其高能耗（由于二次注意力机制和密集的前馈网络FNNs）限制了其实际应用。因此，研究人员希望找到一种方法来降低LLMs的能耗，同时保持其性能。

Method: 本文提出了一种名为MAR（Module-aware Architecture Refinement）的两阶段框架。第一阶段，集成状态空间模型（SSMs）以实现线性时间序列建模，并应用激活稀疏化来降低FFN的成本。第二阶段，为了解决在整合脉冲神经网络（SNNs）与SSMs时信息密度低和时序不匹配的问题，设计了自适应三元多步神经元（ATMN）和脉冲感知双向蒸馏策略（SBDS）。

Result: 通过大量的实验证明，MAR框架在资源受限的情况下，能够有效地恢复其密集对应物的性能，同时大幅降低推理能耗。此外，MAR框架的性能优于同等规模或更大规模的现有高效模型。

Conclusion: MAR框架通过有效结合SSMs和激活稀疏化，并引入ATMN和SBDS来解决SNNs与SSMs结合的挑战，成功地构建了高效且实用的LLMs。该方法在保持模型性能的同时，显著降低了能耗，并优于其他同类模型，展现了其在实际应用中的巨大潜力。

Abstract: Large Language Models (LLMs) excel across diverse domains but suffer from high energy costs due to quadratic attention and dense Feed-Forward Network (FFN) operations. To address these issues, we propose Module-aware Architecture Refinement (MAR), a two-stage framework that integrates State Space Models (SSMs) for linear-time sequence modeling and applies activation sparsification to reduce FFN costs. In addition, to mitigate low information density and temporal mismatch in integrating Spiking Neural Networks (SNNs) with SSMs, we design the Adaptive Ternary Multi-step Neuron (ATMN) and the Spike-aware Bidirectional Distillation Strategy (SBDS). Extensive experiments demonstrate that MAR effectively restores the performance of its dense counterpart under constrained resources while substantially reducing inference energy consumption. Furthermore, it outperforms efficient models of comparable or even larger scale, underscoring its potential for building efficient and practical LLMs.

</details>


### [53] [MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning](https://arxiv.org/abs/2601.21468)
*Yaorui Shi,Shugui Liu,Yu Yang,Wenyu Mao,Yuxin Chen,Qi GU,Hui Su,Xunliang Cai,Xiang Wang,An Zhang*

Main category: cs.AI

TL;DR: MemOCR 提出了一种多模态记忆代理，通过视觉布局自适应地分配信息密度，以应对长时程交互历史压缩到有限上下文窗口的问题，从而在严格的上下文预算下提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于文本的记忆系统在处理长时程交互历史时，由于所有 token 成本均摊，导致宝贵的上下文预算被低价值信息占用，阻碍了长时程代理的推理能力。

Method: MemOCR 维护一个结构化的富文本记忆，并将其渲染成图像。代理通过视觉界面访问记忆，优先显示关键证据，同时压缩辅助细节。通过预算感知的强化学习进行训练，以适应不同的压缩级别。

Result: 在长时程多跳和单跳问答基准测试中，MemOCR 显著优于基于文本的基线方法，并在极端上下文预算下实现了更有效的上下文利用。

Conclusion: MemOCR 能够通过视觉布局实现信息密度的自适应分配，有效地管理长时程交互历史，从而在有限的上下文预算下提升代理的推理性能。

Abstract: Long-horizon agentic reasoning necessitates effectively compressing growing interaction histories into a limited context window. Most existing memory systems serialize history as text, where token-level cost is uniform and scales linearly with length, often spending scarce budget on low-value details. To this end, we introduce MemOCR, a multimodal memory agent that improves long-horizon reasoning under tight context budgets by allocating memory space with adaptive information density through visual layout. Concretely, MemOCR maintains a structured rich-text memory (e.g., headings, highlights) and renders it into an image that the agent consults for memory access, visually prioritizing crucial evidence while aggressively compressing auxiliary details. To ensure robustness across varying memory budgets, we train MemOCR with reinforcement learning under budget-aware objectives that expose the agent to diverse compression levels. Across long-context multi-hop and single-hop question-answering benchmarks, MemOCR outperforms strong text-based baselines and achieves more effective context utilization under extreme budgets.

</details>


### [54] [The Effectiveness of Style Vectors for Steering Large Language Models: A Human Evaluation](https://arxiv.org/abs/2601.21505)
*Diaoulé Diallo,Katharina Dworatzyk,Sophie Jentzsch,Peer Schütt,Sabine Theis,Tobias Hecking*

Main category: cs.AI

TL;DR: 该研究首次对大型语言模型（LLMs）的情感语气激活引导进行了人类评估，发现模型评分与人类感知质量高度一致，中等引导强度能有效增强目标情绪，且升级模型能提高引导效果的稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了在推理时控制LLMs的行为，使其输出符合人类的能力和安全要求，需要一种比提示工程和微调更轻量级的方法。激活引导是一种有前景的技术，但其在情感语气上的有效性和对文本质量的影响缺乏人类评估。

Method: 通过Prolific平台收集了190名参与者提供的7,000多条评分数据，评估了LLM输出的情感强度和文本质量。研究比较了模型评分与人类评分的一致性，分析了不同引导强度对情感（如厌恶、恐惧、惊讶）的影响，并比较了Alpaca和LlaMA-3模型在激活引导上的效果。

Result: 模型评分与人类感知质量高度相关（平均r=0.776）。中等激活引导强度（λ≈0.15）能有效增强目标情感，同时保持文本的可理解性。厌恶和恐惧受到的影响最大（ηp^2 分别为0.616和0.540），惊讶受到的影响最小（ηp^2 =0.042）。LlaMA-3模型相比Alpaca，在情感和强度上表现出更一致的引导效果（所有p < 0.001）。评估者间一致性高（ICC=0.71-0.87）。

Conclusion: 激活引导是一种可扩展的方法，能够跨情感维度有效地控制LLMs的行为，并且模型自身的评分可以作为人类感知质量的有效代理。升级LLM模型可以进一步提高激活引导的稳定性和效果。

Abstract: Controlling the behavior of large language models (LLMs) at inference time is essential for aligning outputs with human abilities and safety requirements. \emph{Activation steering} provides a lightweight alternative to prompt engineering and fine-tuning by directly modifying internal activations to guide generation. This research advances the literature in three significant directions. First, while previous work demonstrated the technical feasibility of steering emotional tone using automated classifiers, this paper presents the first human evaluation of activation steering concerning the emotional tone of LLM outputs, collecting over 7,000 crowd-sourced ratings from 190 participants via Prolific ($n=190$). These ratings assess both perceived emotional intensity and overall text quality. Second, we find strong alignment between human and model-based quality ratings (mean $r=0.776$, range $0.157$--$0.985$), indicating automatic scoring can proxy perceived quality. Moderate steering strengths ($λ\approx 0.15$) reliably amplify target emotions while preserving comprehensibility, with the strongest effects for disgust ($η_p^2 = 0.616$) and fear ($η_p^2 = 0.540$), and minimal effects for surprise ($η_p^2 = 0.042$). Finally, upgrading from Alpaca to LlaMA-3 yielded more consistent steering with significant effects across emotions and strengths (all $p < 0.001$). Inter-rater reliability was high (ICC $= 0.71$--$0.87$), underscoring the robustness of the findings. These findings support activation-based control as a scalable method for steering LLM behavior across affective dimensions.

</details>


### [55] [The Path of Least Resistance: Guiding LLM Reasining Trajectories with Prefix Consensus](https://arxiv.org/abs/2601.21494)
*Ishan Jindal,Sai Prashanth Akuthota,Jayant Taneja,Sachin Dev Sharma*

Main category: cs.AI

TL;DR: 本文提出了一种名为 PoLR（Path of Least Resistance）的新型推理方法，该方法通过只扩展推理过程中最一致的路径，在保证模型准确性的同时，显著降低了计算成本和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的如 Self-Consistency (SC) 等推理策略虽然能提高大型语言模型的推理性能，但计算成本高昂，因为它们会完全展开所有推理路径。因此，研究者希望找到一种计算效率更高的方法来提升推理能力。

Method: PoLR 方法通过聚类推理过程中的短前缀，识别出最占主导地位的聚类，然后只扩展该聚类内的所有路径。这种方法利用了早期推理步骤中编码的强大信号来预测最终的正确性，并通过信息论（互信息和熵）进行了理论分析。

Result: 在 GSM8K、MATH500、AIME24/25 和 GPQA-DIAMOND 等数据集上，PoLR 方法在准确性上与 SC 方法相当甚至更高，同时将 token 使用量减少了高达 60%，并将实际运行时间延迟减少了高达 50%。

Conclusion: PoLR 是一种计算高效的推理方法，它通过优先扩展最一致的推理路径，在不损失准确性的情况下显著降低了计算资源消耗和推理延迟。该方法还能与现有的自适应推理方法相结合，提高模型的效率和可扩展性，且无需对模型进行微调。

Abstract: Large language models achieve strong reasoning performance, but inference strategies such as Self-Consistency (SC) are computationally expensive, as they fully expand all reasoning traces. We introduce PoLR (Path of Least Resistance), the first inference-time method to leverage prefix consistency for compute-efficient reasoning. PoLR clusters short prefixes of reasoning traces, identifies the dominant cluster, and expands all paths in that cluster, preserving the accuracy benefits of SC while substantially reducing token usage and latency. Our theoretical analysis, framed via mutual information and entropy, explains why early reasoning steps encode strong signals predictive of final correctness. Empirically, PoLR consistently matches or exceeds SC across GSM8K, MATH500, AIME24/25, and GPQA-DIAMOND, reducing token usage by up to 60% and wall-clock latency by up to 50%. Moreover, PoLR is fully complementary to adaptive inference methods (e.g., Adaptive Consistency, Early-Stopping SC) and can serve as a drop-in pre-filter, making SC substantially more efficient and scalable without requiring model fine-tuning.

</details>


### [56] [KAPSO: A Knowledge-grounded framework for Autonomous Program Synthesis and Optimization](https://arxiv.org/abs/2601.21526)
*Alireza Nadaf,Alireza Mohammadshahi,Majid Yazdani*

Main category: cs.AI

TL;DR: KAPSO是一个自主程序合成和优化框架，通过迭代的“构思、代码合成和编辑、执行、评估和学习”循环，将合成作为优化循环中的一个算子，以实现可衡量的目标。它通过git实验引擎、知识系统和认知记忆层来解决现有代码代理的长期失败问题。


<details>
  <summary>Details</summary>
Motivation: 解决当前代码代理在长期任务中常见的失败模式，如实验状态丢失、调试脆弱以及领域专业知识复用能力弱。

Method: KAPSO集成了一个git原生的实验引擎（将每次尝试隔离为分支）、一个知识系统（整合异构来源的信息并进行结构化表示）和一个认知记忆层（协调检索并存储可复用的经验教训）。整个过程是一个长期的优化循环，以评估器输出作为进展度量。

Result: 在MLE-Bench（Kaggle风格的ML竞赛）和ALE-Bench（AtCoder启发式优化）上进行了端到端的性能评估。

Conclusion: KAPSO通过一个集成的框架和优化的组件，能够实现自主程序合成和优化，并有效解决了代码代理在长期任务中的挑战。

Abstract: We introduce KAPSO, a modular framework for autonomous program synthesis and optimization. Given a natural language goal and an evaluation method, KAPSO iteratively performs ideation, code synthesis and editing, execution, evaluation, and learning to improve a runnable artifact toward measurable objectives. Rather than treating synthesis as the endpoint, KAPSO uses synthesis as an operator within a long-horizon optimization loop, where progress is defined by evaluator outcomes.
  KAPSO targets long-horizon failures common in coding agents, including lost experimental state, brittle debugging, and weak reuse of domain expertise, by integrating three tightly coupled components. First, a git-native experimentation engine isolates each attempt as a branch, producing reproducible artifacts and preserving provenance across iterations. Second, a knowledge system ingests heterogeneous sources, including repositories, internal playbooks, and curated external resources such as documentation, scientific papers, and web search results, and organizes them into a structured representation that supports retrieval over workflows, implementations, and environment constraints. Third, a cognitive memory layer coordinates retrieval and maintains an episodic store of reusable lessons distilled from experiment traces (run logs, diffs, and evaluator feedback), reducing repeated error modes and accelerating convergence.
  We evaluated KAPSO on MLE-Bench (Kaggle-style ML competitions) and ALE-Bench (AtCoder heuristic optimization), and report end-to-end performance.
  Code Available at: https://github.com/Leeroo-AI/kapso

</details>


### [57] [LLaMEA-SAGE: Guiding Automated Algorithm Design with Structural Feedback from Explainable AI](https://arxiv.org/abs/2601.21511)
*Niki van Stein,Anna V. Kononova,Lars Kotthoff,Thomas Bäck*

Main category: cs.AI

TL;DR: 本文提出了一种名为 LLaMEA-SAGE 的方法，通过从生成的算法的抽象语法树中提取图论和复杂度特征，并利用可解释 AI 技术将这些特征转化为自然语言的突变指令，来指导大型语言模型（LLM）的自动算法设计（AAD），从而提高搜索效率和算法性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于 LLM 的 AAD 方法（如 LLaMEA）主要依赖于适应度反馈驱动搜索，忽略了生成代码本身的丰富信息。研究旨在利用代码的内在结构和特性来增强 AAD 的搜索过程。

Method: 1. 从生成的算法的抽象语法树（AST）中提取图论和复杂度特征。
2. 基于已评估解决方案的存档，学习一个代理模型来预测性能。
3. 利用可解释 AI 技术识别影响性能的关键特征。
4. 将这些特征转化为自然语言突变指令，指导 LLM 进行后续的代码生成。
5. 将此机制集成到 LLaMEA 中，形成 LLaMEA-SAGE。

Result: 在小型实验中，LLaMEA-SAGE 比 vanilla LLaMEA 以更快的速度达到相同的性能。
在 MA-BBOB 基准测试的更大规模实验中，LLaMEA-SAGE 取得了优于现有最先进 AAD 方法的性能。

Conclusion: 从代码中提取的结构化信号（如图论和复杂度特征）可以有效地指导 LLM 驱动的算法进化，弥合代码结构与人类可理解的性能反馈之间的差距，从而提高自动算法设计的效率和效果。

Abstract: Large language models have enabled automated algorithm design (AAD) by generating optimization algorithms directly from natural-language prompts. While evolutionary frameworks such as LLaMEA demonstrate strong exploratory capabilities across the algorithm design space, their search dynamics are entirely driven by fitness feedback, leaving substantial information about the generated code unused. We propose a mechanism for guiding AAD using feedback constructed from graph-theoretic and complexity features extracted from the abstract syntax trees of the generated algorithms, based on a surrogate model learned over an archive of evaluated solutions. Using explainable AI techniques, we identify features that substantially affect performance and translate them into natural-language mutation instructions that steer subsequent LLM-based code generation without restricting expressivity.
  We propose LLaMEA-SAGE, which integrates this feature-driven guidance into LLaMEA, and evaluate it across several benchmarks. We show that the proposed structured guidance achieves the same performance faster than vanilla LLaMEA in a small controlled experiment. In a larger-scale experiment using the MA-BBOB suite from the GECCO-MA-BBOB competition, our guided approach achieves superior performance compared to state-of-the-art AAD methods. These results demonstrate that signals derived from code can effectively bias LLM-driven algorithm evolution, bridging the gap between code structure and human-understandable performance feedback in automated algorithm design.

</details>


### [58] [ARGORA: Orchestrated Argumentation for Causally Grounded LLM Reasoning and Decision Making](https://arxiv.org/abs/2601.21533)
*Youngjin Jin,Hanna Kim,Kwanwoo Kim,Chanhee Lee,Seungwon Shin*

Main category: cs.AI

TL;DR: ARGORA 是一个框架，通过显式的论证图组织多专家 LLM 的讨论，从而揭示论证之间的关系，并支持因果分析和错误纠正。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 系统在整合多专家观点时使用简单的聚合方法，这会模糊具体论证对最终决策的影响。研究者希望开发一种方法来更清晰地展示论证过程，并能进行因果分析和纠错。

Method: ARGORA 将多专家 LLM 的讨论组织成论证图，其中包含支持或攻击彼此的论证。这些图被视为因果模型，允许系统移除单个论证并重新计算结果，从而识别关键的推理链。此外，ARGORA 还包含一个纠正机制，用于在内部推理与外部判断不一致时进行调整。

Result: ARGORA 在多个基准测试和开放式用例中取得了具有竞争力的准确性。当专家意见不一致时，ARGORA 能更有效地朝着正确答案解决争端，并且引入新错误的概率较低。该框架还能提供关于关键论证的因果诊断。

Conclusion: ARGORA 框架通过显式的论证图提高了多专家 LLM 的可解释性和鲁棒性。它不仅能提供关于决策过程的因果洞察，还能通过纠正机制主动修正错误，从而在提高模型准确性的同时，也增强了决策的可靠性。

Abstract: Existing multi-expert LLM systems gather diverse perspectives but combine them through simple aggregation, obscuring which arguments drove the final decision. We introduce ARGORA, a framework that organizes multi-expert discussions into explicit argumentation graphs showing which arguments support or attack each other. By casting these graphs as causal models, ARGORA can systematically remove individual arguments and recompute outcomes, identifying which reasoning chains were necessary and whether decisions would change under targeted modifications. We further introduce a correction mechanism that aligns internal reasoning with external judgments when they disagree. Across diverse benchmarks and an open-ended use case, ARGORA achieves competitive accuracy and demonstrates corrective behavior: when experts initially disagree, the framework resolves disputes toward correct answers more often than it introduces new errors, while providing causal diagnostics of decisive arguments.

</details>


### [59] [ShardMemo: Masked MoE Routing for Sharded Agentic LLM Memory](https://arxiv.org/abs/2601.21545)
*Yang Zhao,Chengxiao Dai,Yue Xiu,Mengying Kou,Yuliang Zheng,Dusit Niyato*

Main category: cs.AI

TL;DR: ShardMemo 是一种预算分层内存服务，通过在代理、分片证据和版本技能库之间进行智能路由，解决了 agentic LLM 系统中的内存瓶颈问题，并在多个基准测试中实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的 agentic LLM 系统在处理长时程状态和并发多智能体执行时，由于中心化索引和启发式分区，当内存量和并行访问量增加时会成为瓶颈。

Method: 提出 ShardMemo，一个预算分层内存服务，包含三个层级：Tier A（每代理工作状态）、Tier B（分片证据，带分片本地 ANN 索引）和 Tier C（版本化技能库）。Tier B 强制执行“范围优先路由”策略，通过结构化资格约束来屏蔽不合格的分片。将分片探测视为在合格分片上的掩码混合专家（MoE）路由，并使用成本感知门控。路由器的训练基于证据到分片的监督。

Result: 在 LoCoMo 基准测试中，ShardMemo 在 F1 分数上比最强的基线（GAM）提高了 5.11 至 6.82。在固定预算路由设置下，ShardMemo 的 F1 分数比余弦到原型分片路由提高了 6.87，同时减少了检索工作（VecScan 521->414，-20.5%）和 p95 延迟（95->76 ms）。在长上下文 HotpotQA 上，ShardMemo 在不同 token 数量下实现了 63.41/61.88/57.95 的 F1 分数。在 ToolBench 上，Tier C 的 Precision@3 和 StepRed 分数分别达到了 0.97 和 1.94，优于基于嵌入相似度的检索。

Conclusion: ShardMemo 有效地缓解了 agentic LLM 系统中的内存瓶颈问题，通过智能分层和路由机制，在处理大规模、并发和长上下文的内存访问时，显著提高了性能和效率。

Abstract: Agentic large language model (LLM) systems rely on external memory for long-horizon state and concurrent multi-agent execution, but centralized indexes and heuristic partitions become bottlenecks as memory volume and parallel access grow. We present ShardMemo, a budgeted tiered memory service with Tier A per-agent working state, Tier B sharded evidence with shard-local approximate nearest neighbor (ANN) indexes, and Tier C, a versioned skill library. Tier B enforces scope-before-routing: structured eligibility constraints mask ineligible shards before routing or ANN search. We cast shard probing as masked mixture-of-experts (MoE) routing over eligible shards, probing up to $B_{\mathrm{probe}}$ shards via Top-$B_{\mathrm{probe}}$ or adaptive Top-$P$, and use cost-aware gating over profile/observation/session shard families; the router is trained from evidence-to-shard supervision. On LoCoMo, ShardMemo improves over the strongest baseline (GAM) by +5.11 to +6.82 F1 across question categories. Under a fixed-budget routing setting ($B_{\mathrm{probe}}=3$), ShardMemo improves over cosine-to-prototype shard routing by +6.87 F1 while reducing retrieval work (VecScan 521->414, -20.5%) and p95 latency (95->76 ms). On long-context HotpotQA, ShardMemo achieves 63.41/61.88/57.95 F1 at 56K/224K/448K tokens. On ToolBench, Tier C reaches 0.97 Precision@3 and 1.94 StepRed (+10.2% and +7.2% over embedding-similarity retrieval).

</details>


### [60] [Meta Context Engineering via Agentic Skill Evolution](https://arxiv.org/abs/2601.21557)
*Haoran Ye,Xuning He,Vincent Arak,Haonan Dong,Guojie Song*

Main category: cs.AI

TL;DR: 本文提出了一种名为元上下文工程（MCE）的双层框架，用于优化大型语言模型的推理时上下文。MCE通过元层代理和基础层代理的协同进化，超越了传统的静态上下文工程方法，从而提高了性能、适应性、可迁移性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文工程（CE）方法依赖于手动创建的约束性工具，这限制了上下文优化的设计空间。研究者希望开发一种更灵活、更自动化的方法来提升CE的效率和效果。

Method: MCE采用一种双层框架。元层代理通过代理交叉（agentic crossover）来精炼工程技能，这是一个在技能历史、执行和评估上的审议搜索过程。基础层代理则执行这些技能，从训练中学习，并优化灵活的文件和代码形式的上下文。

Result: 在五个不同领域、离线和在线设置的评估中，MCE展示了持续的性能提升，相比于最先进的代理CE方法，相对性能提高了5.6%--53.8%（平均16.9%）。同时，MCE在上下文的适应性、可迁移性以及上下文使用和训练效率方面也表现更优。

Conclusion: MCE是一种有效的上下文工程框架，通过其双层协同进化机制，能够显著提升大型语言模型的性能，并克服传统CE方法的局限性，在适应性、可迁移性和效率方面均有优势。

Abstract: The operational efficacy of large language models relies heavily on their inference-time context. This has established Context Engineering (CE) as a formal discipline for optimizing these inputs. Current CE methods rely on manually crafted harnesses, such as rigid generation-reflection workflows and predefined context schemas. They impose structural biases and restrict context optimization to a narrow, intuition-bound design space. To address this, we introduce Meta Context Engineering (MCE), a bi-level framework that supersedes static CE heuristics by co-evolving CE skills and context artifacts. In MCE iterations, a meta-level agent refines engineering skills via agentic crossover, a deliberative search over the history of skills, their executions, and evaluations. A base-level agent executes these skills, learns from training rollouts, and optimizes context as flexible files and code. We evaluate MCE across five disparate domains under offline and online settings. MCE demonstrates consistent performance gains, achieving 5.6--53.8% relative improvement over state-of-the-art agentic CE methods (mean of 16.9%), while maintaining superior context adaptability, transferability, and efficiency in both context usage and training.

</details>


### [61] [Chain Of Thought Compression: A Theoritical Analysis](https://arxiv.org/abs/2601.21576)
*Juncai Li,Ru Li,Yuxiang Zhou,Boxiang Ma,Jeff Z. Pan*

Main category: cs.AI

TL;DR: 本研究提出了ALiCoT框架，通过理论分析和实验验证，解决了隐式链式思考（CoT）的有效性问题，实现了在性能相当的情况下，将推理速度提升了54.4倍。


<details>
  <summary>Details</summary>
Motivation: 显式链式思考（CoT）虽然提升了大型语言模型（LLMs）的推理能力，但生成额外Token的计算成本过高。隐式CoT压缩是解决此问题的潜在方案，但其内在机制尚不明确。

Method: 研究者首先通过引入“Order-r Interaction”进行了理论分析，证明了学习内部化推理步骤的难度，并揭示了高阶逻辑依赖信号衰减的问题。然后，他们设计了一个名为NatBool-DAG的基准测试，以验证理论发现。最后，基于理论洞察，提出了ALiCoT框架，通过对齐潜在Token分布与中间推理状态来克服信号衰减。

Result: ALiCoT框架在NatBool-DAG基准测试上取得了成功，实现了54.4倍的推理速度提升，同时性能与显式CoT相当。这表明ALiCoT能够有效地实现高效推理。

Conclusion: 本研究为理解和实现高效隐式CoT提供了理论基础和实践方案。ALiCoT框架能够有效解决高阶逻辑依赖信号衰减问题，从而实现比显式CoT更高效的推理，而无需牺牲性能。

Abstract: Chain-of-Thought (CoT) has unlocked advanced reasoning abilities of Large Language Models (LLMs) with intermediate steps, yet incurs prohibitive computational costs due to generation of extra tokens. Recent studies empirically show that compressing reasoning steps into latent states, or implicit CoT compression, offers a token-efficient alternative. However, the mechanism behind CoT compression remains unclear. In this paper, we provide the first theoretical analysis of the difficulty of learning to internalize intermediate reasoning steps. By introducing Order-r Interaction, we prove that the learning signal for high-order logical dependencies exponentially decays to solve irreducible problem, where skipping intermediate steps inevitably leads to high-order interaction barriers. To empirically validate this, we introduce NatBool-DAG, a challenging benchmark designed to enforce irreducible logical reasoning and eliminate semantic shortcuts. Guided by our theoretical findings, we propose ALiCoT (Aligned Implicit CoT), a novel framework that overcomes the signal decay by aligning latent token distributions with intermediate reasoning states. Experimental results demonstrate that ALiCoT successfully unlocks efficient reasoning: it achieves a 54.4x speedup while maintaining performance comparable to explicit CoT.

</details>


### [62] [Beyond Imitation: Reinforcement Learning for Active Latent Planning](https://arxiv.org/abs/2601.21598)
*Zhi Zheng,Wee Sun Lee*

Main category: cs.AI

TL;DR: 提出了一种名为ATP-Latent的方法，通过条件变分自编码器（VAE）和强化学习（RL）与辅助一致性奖励，旨在提高链式思考（CoT）推理的效率和密度，并取得了更好的准确率和更少的token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的隐式推理方法在模仿离散语言标签进行隐式token监督时，可能因为存在多种等价的CoT标签而导致次优的隐式token表示和推理策略，从而限制了其规划能力。研究旨在解决这个问题，实现更优的隐式推理策略。

Method: ATP-Latent方法包含两个主要部分：1. 将隐式token的监督过程建模为条件变分自编码器（VAE），以获得更平滑的隐式空间。2. 使用强化学习（RL）并引入基于VAE解码内容一致性的辅助一致性奖励，以引导RL过程，实现最合理的隐式推理策略。

Result: 在LLaMA-1B模型上，ATP-Latent在四个基准测试中，准确率提高了4.1%，token消耗减少了3.3%，优于先进的基线方法。

Conclusion: ATP-Latent通过主动规划隐式token的表示空间，能够获得更优的隐式推理策略，提高了推理效率和准确性，有效解决了现有方法在模仿语言标签时存在的局限性。

Abstract: Aiming at efficient and dense chain-of-thought (CoT) reasoning, latent reasoning methods fine-tune Large Language Models (LLMs) to substitute discrete language tokens with continuous latent tokens. These methods consume fewer tokens compared to the conventional language CoT reasoning and have the potential to plan in a dense latent space. However, current latent tokens are generally supervised based on imitating language labels. Considering that there can be multiple equivalent but diverse CoT labels for a question, passively imitating an arbitrary one may lead to inferior latent token representations and latent reasoning policies, undermining the potential planning ability and resulting in clear gaps between training and testing. In this work, we emphasize the importance of active planning over the representation space of latent tokens in achieving the optimal latent reasoning policy. So, we propose the \underline{A}c\underline{t}ive Latent \underline{P}lanning method (ATP-Latent), which models the supervision process of latent tokens as a conditional variational auto-encoder (VAE) to obtain a smoother latent space. Moreover, to facilitate the most reasonable latent reasoning policy, ATP-Latent conducts reinforcement learning (RL) with an auxiliary coherence reward, which is calculated based on the consistency between VAE-decoded contents of latent tokens, enabling a guided RL process. In experiments on LLaMA-1B, ATP-Latent demonstrates +4.1\% accuracy and -3.3\% tokens on four benchmarks compared to advanced baselines. Codes are available on https://github.com/zz1358m/ATP-Latent-master.

</details>


### [63] [Depth-Recurrent Attention Mixtures: Giving Latent Reasoning the Attention it Deserves](https://arxiv.org/abs/2601.21582)
*Jonas Knupp,Jan Hendrik Metzen,Jeremias Bohn,Georg Groh,Kristian Kersting*

Main category: cs.AI

TL;DR: 提出了一种名为Dreamer的深度递归注意力混合模型框架，通过解耦缩放维度和利用深度注意力来解决现有深度递归模型面临的隐藏层大小瓶颈问题，并在语言推理任务上实现了显著的效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有深度递归模型在处理多步潜在推理时受到隐藏层大小的限制，且缺乏FLOP、参数和内存匹配的基线进行公平比较。

Method: 引入了一个模块化的深度递归注意力混合（Dreamer）框架，结合了序列注意力、深度注意力和稀疏专家注意力。通过深度注意力来缓解隐藏层大小的瓶颈，并解耦了缩放维度，使得深度递归模型能够高效扩展。

Result: 在语言推理基准测试中，Dreamer模型在达到相同准确率的情况下，所需的训练token数量是FLOP、参数和内存匹配的最先进模型的2到8倍。同时，在相同训练token数量下，Dreamer模型性能优于约2倍大的最先进模型。此外，模型在专家选择多样性方面表现出比最先进的MoE模型高2到11倍的知识利用率。

Conclusion: Dreamer框架能够有效地解决深度递归模型的瓶颈问题，并显著提高模型在语言推理任务上的效率和性能，同时展现出更广泛的知识利用能力。

Abstract: Depth-recurrence facilitates latent reasoning by sharing parameters across depths. However, prior work lacks combined FLOP-, parameter-, and memory-matched baselines, underutilizes depth-recurrence due to partially fixed layer stacks, and ignores the bottleneck of constant hidden-sizes that restricts many-step latent reasoning. To address this, we introduce a modular framework of depth-recurrent attention mixtures (Dreamer), combining sequence attention, depth attention, and sparse expert attention. It alleviates the hidden-size bottleneck through attention along depth, decouples scaling dimensions, and allows depth-recurrent models to scale efficiently and effectively. Across language reasoning benchmarks, our models require 2 to 8x fewer training tokens for the same accuracy as FLOP-, parameter-, and memory-matched SOTA, and outperform ca. 2x larger SOTA models with the same training tokens. We further present insights into knowledge usage across depths, e.g., showing 2 to 11x larger expert selection diversity than SOTA MoEs.

</details>


### [64] [CORE: Collaborative Reasoning via Cross Teaching](https://arxiv.org/abs/2601.21600)
*Kshitij Mishra,Mirat Aubakirov,Martin Takac,Nils Lukas,Salem Lahlou*

Main category: cs.AI

TL;DR: 提出了一种名为CORE（Collaborative Reasoning）的训练时协作框架，通过跨教学协议将模型间的互补性成功转化为学习信号，显著提升了小型模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理同一问题时可能表现出互补的推理错误，即一个模型失败的地方另一个模型可能成功。研究者希望利用这种互补性来提升模型的整体性能。

Method: CORE框架在训练时引入一个跨教学协议。首先进行独立采样（冷回合），然后对于失败的模型，提供从成功同伴那里提取的提示（有上下文的救援回合）。CORE优化了一个结合正确性、轻量级DPP启发的模型错误重叠度降低项以及显式的救援奖励项的联合奖励。

Result: 在GSM8K和MATH数据集上，使用CORE训练的一对小型开源模型（3B+4B）在Pass@2指标上相比单独训练取得了显著提升。例如，在GSM8K上，CORE达到了99.54%的Pass@2，而单独训练为82.50%。在GPQA和AIME数据集上，CORE也展现了强大的性能，且训练数据量和计算成本较低。

Conclusion: 训练时的协作能够有效地将模型间的互补性转化为显著的性能提升，而无需增大模型规模。CORE框架证明了通过有效的训练机制，可以利用模型间的差异性来提高整体推理能力。

Abstract: Large language models exhibit complementary reasoning errors: on the same instance, one model may succeed with a particular decomposition while another fails. We propose Collaborative Reasoning (CORE), a training-time collaboration framework that converts peer success into a learning signal via a cross-teaching protocol. Each problem is solved in two stages: a cold round of independent sampling, followed by a contexted rescue round in which models that failed receive hint extracted from a successful peer. CORE optimizes a combined reward that balances (i) correctness, (ii) a lightweight DPP-inspired diversity term to reduce error overlap, and (iii) an explicit rescue bonus for successful recovery. We evaluate CORE across four standard reasoning datasets GSM8K, MATH, AIME, and GPQA. With only 1,000 training examples, a pair of small open source models (3B+4B) reaches Pass@2 of 99.54% on GSM8K and 92.08% on MATH, compared to 82.50% and 74.82% for single-model training. On harder datasets, the 3B+4B pair reaches Pass@2 of 77.34% on GPQA (trained on 348 examples) and 79.65% on AIME (trained on 792 examples), using a training-time budget of at most 1536 context tokens and 3072 generated tokens. Overall, these results show that training-time collaboration can reliably convert model complementarity into large gains without scaling model size.

</details>


### [65] [Search-Based Risk Feature Discovery in Document Structure Spaces under a Constrained Budget](https://arxiv.org/abs/2601.21608)
*Saisubramaniam Gopalakrishnan,Harikrishnan P M,Dagnachew Birru*

Main category: cs.AI

TL;DR: 该研究将企业级智能文档处理（IDP）系统的验证视为一个基于搜索的软件测试（SBST）问题，旨在最大化在有限预算内发现的故障类型数量。研究人员比较了多种搜索策略，发现不同策略各有优势，没有单一策略能完全主导，并建议采用基于组合包的SBST策略来提高IDP系统的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在有限预算下，需要发现IDP系统中多样化的故障机制，而不仅仅是单个最差情况的文档。这对于金融、保险和医疗等高风险行业的IDP系统验证至关重要。

Method: 将IDP系统验证形式化为SBST问题，操作文档配置的组合空间，并引入结构化“风险特征”来引发故障。比较了进化算法、群体智能算法、质量-多样性算法、基于学习的算法和量子算法等多种搜索策略在相同预算下的表现。

Result: 不同求解器在相似预算下能发现彼此未发现的故障模式。跨时间分析显示，特定求解器的发现具有持续性，没有哪种策略能绝对占优。所有求解器联合起来可以发现所有已知的故障空间，但单独依赖任何一种策略都会系统性地延迟重要风险的发现。

Conclusion: 研究结果表明，SBST的不同策略之间存在内在的互补性，并鼓励在工业IDP验证中采用基于组合包的SBST策略，以实现更鲁棒的验证。

Abstract: Enterprise-grade Intelligent Document Processing (IDP) systems support high-stakes workflows across finance, insurance, and healthcare. Early-phase system validation under limited budgets mandates uncovering diverse failure mechanisms, rather than identifying a single worst-case document. We formalize this challenge as a Search-Based Software Testing (SBST) problem, aiming to identify complex interactions between document variables, with the objective to maximize the number of distinct failure types discovered within a fixed evaluation budget. Our methodology operates on a combinatorial space of document configurations, rendering instances of structural \emph{risk features} to induce realistic failure conditions. We benchmark a diverse portfolio of search strategies spanning evolutionary, swarm-based, quality-diversity, learning-based, and quantum under identical budget constraints. Through configuration-level exclusivity, win-rate, and cross-temporal overlap analyses, we show that different solvers consistently uncover failure modes that remain undiscovered by specific alternatives at comparable budgets. Crucially, cross-temporal analysis reveals persistent solver-specific discoveries across all evaluated budgets, with no single strategy exhibiting absolute dominance. While the union of all solvers eventually recovers the observed failure space, reliance on any individual method systematically delays the discovery of important risks. These results demonstrate intrinsic solver complementarity and motivate portfolio-based SBST strategies for robust industrial IDP validation.

</details>


### [66] [RecNet: Self-Evolving Preference Propagation for Agentic Recommender Systems](https://arxiv.org/abs/2601.21609)
*Bingqian Li,Xiaolei Wang,Junyi Li,Weitao Li,Long Zhang,Sheng Chen,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.AI

TL;DR: RecNet是一个自进化的偏好传播框架，利用LLMs主动传播用户和物品之间的实时偏好更新，克服了现有方法仅依赖稀疏显式交互的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的推荐系统主要依赖稀疏、嘈杂且无法反映实时交互的显式用户-物品交互来建模偏好变化，这限制了推荐的准确性和实时性。

Method: RecNet包含两个阶段：1) 前向阶段：通过中心化偏好路由机制，利用路由器代理整合偏好更新并动态传播；引入个性化偏好接收机制，结合消息缓冲区和可优化的规则过滤器来选择性地吸收偏好。2) 后向阶段：通过反馈驱动的传播优化机制，模拟多智能体强化学习，利用LLMs进行信用分配、梯度分析和模块级优化，实现传播策略的自我进化。

Result: 在多个场景下的广泛实验证明了RecNet在推荐系统中建模偏好传播的有效性。

Conclusion: RecNet通过引入主动的、实时的偏好传播机制，并结合LLMs实现自我进化，能够更有效地建模复杂的用户偏好动态，提升推荐系统的性能。

Abstract: Agentic recommender systems leverage Large Language Models (LLMs) to model complex user behaviors and support personalized decision-making. However, existing methods primarily model preference changes based on explicit user-item interactions, which are sparse, noisy, and unable to reflect the real-time, mutual influences among users and items. To address these limitations, we propose RecNet, a self-evolving preference propagation framework that proactively propagates real-time preference updates across related users and items. RecNet consists of two complementary phases. In the forward phase, the centralized preference routing mechanism leverages router agents to integrate preference updates and dynamically propagate them to the most relevant agents. To ensure accurate and personalized integration of propagated preferences, we further introduce a personalized preference reception mechanism, which combines a message buffer for temporary caching and an optimizable, rule-based filter memory to guide selective preference assimilation based on past experience and interests. In the backward phase, the feedback-driven propagation optimization mechanism simulates a multi-agent reinforcement learning framework, using LLMs for credit assignment, gradient analysis, and module-level optimization, enabling continuous self-evolution of propagation strategies. Extensive experiments on various scenarios demonstrate the effectiveness of RecNet in modeling preference propagation for recommender systems.

</details>


### [67] [Semantic Content Determines Algorithmic Performance](https://arxiv.org/abs/2601.21618)
*Martiño Ríos-García,Nawaf Alampara,Kevin Maik Jablonka*

Main category: cs.AI

TL;DR: 研究提出了WhatCounts基准测试来评估大型语言模型（LLM）在计数任务上对输入语义内容的依赖性。结果表明，LLM在仅因计数对象不同（如城市、化学品、名字或符号）而表现出超过40%的准确率差异，这表明LLM的近似算法依赖于输入的具体含义。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能隔离地评估LLM行为对其参数语义内容的敏感性。本研究旨在提出一种原子化方法，独立测试LLM的计数能力是否对所计数对象的语义内容不敏感。

Method: 构建了一个名为WhatCounts的基准测试，要求LLM在没有重复项、干扰项或需要推理的情况下，对明确分隔的列表进行计数。通过控制性消融实验排除混淆因素。

Result: 即使在受控条件下，前沿LLM在仅凭计数对象不同（如城市 vs. 化学品，名字 vs. 符号）就显示出超过40%的准确率变化。这种语义鸿沟会随着不相关的微调而不可预测地变化。

Conclusion: LLM并非严格执行算法，而是近似算法，并且这种近似是依赖于其输入的语义内容的。这种函数行为的隐藏依赖性不仅限于计数任务，对其他LLM功能也可能存在潜在影响。

Abstract: Counting should not depend on what is being counted; more generally, any algorithm's behavior should be invariant to the semantic content of its arguments. We introduce WhatCounts to test this property in isolation. Unlike prior work that conflates semantic sensitivity with reasoning complexity or prompt variation, WhatCounts is atomic: count items in an unambiguous, delimited list with no duplicates, distractors, or reasoning steps for different semantic types. Frontier LLMs show over 40% accuracy variation depending solely on what is being counted - cities versus chemicals, names versus symbols. Controlled ablations rule out confounds. The gap is semantic, and it shifts unpredictably with small amounts of unrelated fine-tuning. LLMs do not implement algorithms; they approximate them, and the approximation is argument-dependent. As we show with an agentic example, this has implications beyond counting: any LLM function may carry hidden dependencies on the meaning of its inputs.

</details>


### [68] [ScholarGym: Benchmarking Deep Research Workflows on Academic Literature Retrieval](https://arxiv.org/abs/2601.21654)
*Hao Shen,Hang Yang,Zhouhong Gu*

Main category: cs.AI

TL;DR: 研究提出了ScholarGym，一个用于评估学术文献深度研究工作流的模拟环境，以解决由于API调用不确定性导致的Reproducibility问题。


<details>
  <summary>Details</summary>
Motivation: 现有的工具增强型LLM研究工作流评估面临Reproducibility挑战，因为实时API调用会引入不确定性（如时间漂移、速率限制），这阻碍了跨系统比较。

Method: ScholarGym将工作流分解为查询规划、工具调用和相关性评估，并在一个包含570K篇论文的静态语料库上，使用2,536个带专家标注真实答案的查询进行模拟。

Result: 通过在ScholarGym上进行实验，研究揭示了不同LLM在推理能力、规划策略和选择机制在迭代细化过程中如何相互作用。

Conclusion: ScholarGym提供了一个可复现的评估框架，能够对深度研究工作流的各个环节进行细粒度分析，并促进对不同模型性能的深入理解。

Abstract: Tool-augmented large language models have advanced from single-turn question answering to deep research workflows that iteratively plan queries, invoke external tools, and synthesize information to address complex information needs. Evaluating such workflows presents a fundamental challenge: reliance on live APIs introduces non-determinism, as tool invocations may yield different results across runs due to temporal drift, rate limiting, and evolving backend states. This variance undermines reproducibility and invalidates cross-system comparisons.
  We present ScholarGym, a simulation environment for reproducible evaluation of deep research workflows on academic literature. The environment decouples workflow components into query planning, tool invocation, and relevance assessment, enabling fine-grained analysis of each stage under controlled conditions. Built on a static corpus of 570K papers with deterministic retrieval, ScholarGym provides 2,536 queries with expert-annotated ground truth. Experiments across diverse backbone models reveal how reasoning capabilities, planning strategies, and selection mechanisms interact over iterative refinement.

</details>


### [69] [SONIC-O1: A Real-World Benchmark for Evaluating Multimodal Large Language Models on Audio-Video Understanding](https://arxiv.org/abs/2601.21666)
*Ahmed Y. Radwan,Christos Emmanouilidis,Hina Tabassum,Deval Pandya,Shaina Raza*

Main category: cs.AI

TL;DR: 本文提出了 SONIC-O1，一个包含 13 个真实对话领域、4,958 条注释和人口统计学元数据的基准数据集，用于评估多模态大语言模型（MLLMs）在音频-视频序列理解方面的能力，并揭示了现有模型在时间定位和跨人口统计学群体方面存在的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLM 研究主要集中在静态图像理解，对处理连续的音频-视频数据的能力研究不足。因此，需要一个高质量的基准来系统地评估 MLLM 在真实世界场景下的性能。

Method: 构建了 SONIC-O1 基准，包含 13 个真实对话领域，总共 4,958 条标注数据，并提供了人口统计学元数据。该基准评估 MLLM 在开放式摘要、选择题（MCQ）回答和带有推理的时间定位等任务上的表现。

Result: 通过在闭源和开源模型上的实验，发现虽然 MCQ 准确率的性能差距较小，但在时间定位任务上，最佳闭源模型和开源模型之间存在高达 22.6% 的性能差异。此外，模型在不同人口统计学群体上的性能存在衰减，表明模型行为存在持续的差异。

Conclusion: SONIC-O1 提供了一个开放的评估套件，用于评估 MLLM 在时间维度上的理解能力和对社会性问题的鲁棒性。研究结果揭示了当前 MLLM 在处理连续音频-视频数据和跨不同群体时的局限性，强调了进一步改进的必要性。

Abstract: Multimodal Large Language Models (MLLMs) are a major focus of recent AI research. However, most prior work focuses on static image understanding, while their ability to process sequential audio-video data remains underexplored. This gap highlights the need for a high-quality benchmark to systematically evaluate MLLM performance in a real-world setting. We introduce SONIC-O1, a comprehensive, fully human-verified benchmark spanning 13 real-world conversational domains with 4,958 annotations and demographic metadata. SONIC-O1 evaluates MLLMs on key tasks, including open-ended summarization, multiple-choice question (MCQ) answering, and temporal localization with supporting rationales (reasoning). Experiments on closed- and open-source models reveal limitations. While the performance gap in MCQ accuracy between two model families is relatively small, we observe a substantial 22.6% performance difference in temporal localization between the best performing closed-source and open-source models. Performance further degrades across demographic groups, indicating persistent disparities in model behavior. Overall, SONIC-O1 provides an open evaluation suite for temporally grounded and socially robust multimodal understanding. We release SONIC-O1 for reproducibility and research: Project page: https://vectorinstitute.github.io/sonic-o1/ Dataset: https://huggingface.co/datasets/vector-institute/sonic-o1 Github: https://github.com/vectorinstitute/sonic-o1 Leaderboard: https://huggingface.co/spaces/vector-institute/sonic-o1-leaderboard

</details>


### [70] [TCAP: Tri-Component Attention Profiling for Unsupervised Backdoor Detection in MLLM Fine-Tuning](https://arxiv.org/abs/2601.21692)
*Mingzu Liu,Hao Fang,Runmin Cong*

Main category: cs.AI

TL;DR: 本文提出了一种名为Tri-Component Attention Profiling (TCAP) 的无监督防御框架，用于检测和过滤多模态大语言模型（MLLM）中的后门攻击。TCAP通过分析模型在系统指令、视觉输入和用户文本查询三者之间的注意力分配差异来识别被污染的数据。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLM微调（FTaaS）服务容易引入后门风险，而现有的防御方法要么依赖监督信号，要么难以应对不同类型的触发器和模态。因此，需要一种能够普遍适用且无需监督的后门防御方法。

Method: TCAP首先将跨模态注意力图分解为系统指令、视觉输入和用户文本查询三个部分。然后，利用高斯混合模型（GMM）对注意力头进行统计分析，识别对触发器敏感的注意力头。最后，通过期望最大化（EM）算法进行投票聚合，从而隔离被投毒的样本。

Result: 实验证明，TCAP在各种MLLM架构和攻击方法下都能取得稳定且强大的性能，有效地区分良性样本和后门样本。

Conclusion: TCAP是一种有效、鲁棒且实用的MLLM后门防御方法，其核心思想是利用后门攻击普遍存在的“注意力分配发散”这一特征，且该方法无需监督信号，具有良好的泛化能力。

Abstract: Fine-Tuning-as-a-Service (FTaaS) facilitates the customization of Multimodal Large Language Models (MLLMs) but introduces critical backdoor risks via poisoned data. Existing defenses either rely on supervised signals or fail to generalize across diverse trigger types and modalities. In this work, we uncover a universal backdoor fingerprint-attention allocation divergence-where poisoned samples disrupt the balanced attention distribution across three functional components: system instructions, vision inputs, and user textual queries, regardless of trigger morphology. Motivated by this insight, we propose Tri-Component Attention Profiling (TCAP), an unsupervised defense framework to filter backdoor samples. TCAP decomposes cross-modal attention maps into the three components, identifies trigger-responsive attention heads via Gaussian Mixture Model (GMM) statistical profiling, and isolates poisoned samples through EM-based vote aggregation. Extensive experiments across diverse MLLM architectures and attack methods demonstrate that TCAP achieves consistently strong performance, establishing it as a robust and practical backdoor defense in MLLMs.

</details>


### [71] [FBS: Modeling Native Parallel Reading inside a Transformer](https://arxiv.org/abs/2601.21708)
*Tongxi Wang*

Main category: cs.AI

TL;DR: 提出了一种名为FBS（Fovea-Block-Skip Transformer）的新型Transformer架构，通过引入可训练的因果循环（Parafovea-Attention Window, Chunk-Head, Skip-Gate）来加速LLM的推理过程，提高了效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM推理方法仍依赖于逐个token的自回归生成，效率低下。研究动机是借鉴人类阅读的“内容自适应预测”、“块结构感知计算分配”和“训练-测试一致性（预览/略读）”等核心要素，以加速LLM的推理。

Method: 引入了一种名为Fovea-Block-Skip Transformer（FBS）的新架构，其核心在于通过Parafovea-Attention Window (PAW)、Chunk-Head (CH)和Skip-Gate (SG) 这三个模块，在Transformer中注入了因果的、可训练的循环。

Result: 在多个基准测试中，FBS在不增加模型参数量的情况下，显著提高了LLM的质量-效率权衡。消融实验表明，PAW、CH和SG这三个模块是互补的。

Conclusion: FBS通过引入创新的注意力机制和门控机制，有效克服了传统LLM推理的瓶颈，在保持模型性能的同时实现了高效推理。

Abstract: Large language models (LLMs) excel across many tasks, yet inference is still dominated by strictly token-by-token autoregression. Existing acceleration methods largely patch this pipeline and miss core human-reading ingredients: content-adaptive foresight, chunk-structure-aware compute allocation, and train--test consistency for preview/skimming. We propose the \textbf{Fovea-Block-Skip Transformer} (FBS), which injects a causal, trainable loop into Transformers via Parafovea-Attention Window (PAW), Chunk-Head (CH), and Skip-Gate (SG). Across diverse benchmarks, FBS improves the quality-efficiency trade-off without increasing parameters, and ablations show the three modules are complementary.

</details>


### [72] [E-mem: Multi-agent based Episodic Context Reconstruction for LLM Agent Memory](https://arxiv.org/abs/2601.21714)
*Kaixiang Wang,Yidan Lin,Jiong Lou,Zhaojiacheng Zhou,Bunyod Suvonov,Jie Li*

Main category: cs.AI

TL;DR: 本文提出了一种名为 E-mem 的框架，用于提升大型语言模型（LLM）代理的系统 2 推理能力。E-mem 通过一种异构分层架构，让多个助手代理维护未压缩的记忆上下文，并由一个主代理进行全局规划，以解决现有记忆预处理方法破坏上下文完整性的问题。实验结果表明，E-mem 在 LoCoMo 基准测试中表现优于现有技术，同时显著降低了成本。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 代理在进行需要长时间逻辑推理的系统 2 推理时，记忆预处理方法往往会破坏上下文的完整性，阻碍了高精度的解决问题能力。这促使研究者们探索一种新的记忆处理方式。

Method: E-mem 框架采用“情景上下文重构”而非“记忆预处理”的方法。它构建了一个异构分层架构，其中多个助手代理维护未经压缩的记忆上下文，而一个主代理负责全局规划。助手代理可以在激活的记忆片段内进行局部推理，提取上下文相关的证据，然后由主代理进行整合。

Result: 在 LoCoMo 基准测试中，E-mem 取得了超过 54% 的 F1 分数，比当前最先进的 GAM 方法高出 7.75%，并且 token 成本降低了 70% 以上。

Conclusion: E-mem 框架通过其创新的情景上下文重构机制，有效解决了 LLM 代理在执行系统 2 推理时记忆上下文的去情境化问题，显著提升了性能并降低了成本，为 LLM 代理的长期、高精度推理提供了新的解决方案。

Abstract: The evolution of Large Language Model (LLM) agents towards System~2 reasoning, characterized by deliberative, high-precision problem-solving, requires maintaining rigorous logical integrity over extended horizons. However, prevalent memory preprocessing paradigms suffer from destructive de-contextualization. By compressing complex sequential dependencies into pre-defined structures (e.g., embeddings or graphs), these methods sever the contextual integrity essential for deep reasoning. To address this, we propose E-mem, a framework shifting from Memory Preprocessing to Episodic Context Reconstruction. Inspired by biological engrams, E-mem employs a heterogeneous hierarchical architecture where multiple assistant agents maintain uncompressed memory contexts, while a central master agent orchestrates global planning. Unlike passive retrieval, our mechanism empowers assistants to locally reason within activated segments, extracting context-aware evidence before aggregation. Evaluations on the LoCoMo benchmark demonstrate that E-mem achieves over 54\% F1, surpassing the state-of-the-art GAM by 7.75\%, while reducing token cost by over 70\%.

</details>


### [73] [Epistemic Context Learning: Building Trust the Right Way in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2601.21742)
*Ruiwen Zhou,Maojia Song,Xiaobao Wu,Sitao Cheng,Xunjian Yin,Yuxi Xie,Zhuoqun Hao,Wenyue Hua,Liangming Pan,Soujanya Poria,Min-Yen Kan*

Main category: cs.AI

TL;DR: 本文提出了一种名为认知情境学习（ECL）的新方法，通过让智能体学习评估同伴的可靠性，从而提高多智能体系统（MA）中智能体的鲁棒性，使其不至于盲目跟随不可靠的同伴。


<details>
  <summary>Details</summary>
Motivation: 现有 MA 系统中的智能体普遍存在鲁棒性不足的问题，容易盲目听从误导性的同伴。这种弱点源于智能体趋于奉承（sycophancy）以及评估同伴可靠性的能力不足。

Method: 研究引入了“历史感知参考”的学习范式，将同伴的历史交互作为额外输入，使智能体能够估计同伴的可靠性，并在不确定时向可信的同伴学习。在此基础上，提出了认知情境学习（ECL）框架，该框架基于历史交互显式构建的同伴画像来条件化预测。ECL 进一步通过强化学习和辅助奖励进行优化。

Result: 实验表明，ECL 能够让小型模型（如 Qwen 3-4B）在识别可靠同伴方面超越比其大 8 倍的基线模型（Qwen 3-30B），并且可以将前沿模型（frontier models）的性能提升至接近完美（100%）。ECL 在各种 MA 配置下均表现出良好的泛化能力。研究还发现，大型语言模型（LLMs）能够很好地模拟“信任”这一概念，且信任建模的准确性与最终答案质量之间存在很强的相关性。

Conclusion: ECL 是一种有效提升 MA 系统中智能体鲁棒性的方法，通过学习历史交互来评估同伴可靠性，从而克服了智能体盲目跟随不可靠同伴的问题。LLMs 在建模信任方面表现出色，且信任建模的准确性直接影响 MA 系统的整体性能。

Abstract: Individual agents in multi-agent (MA) systems often lack robustness, tending to blindly conform to misleading peers. We show this weakness stems from both sycophancy and inadequate ability to evaluate peer reliability. To address this, we first formalize the learning problem of history-aware reference, introducing the historical interactions of peers as additional input, so that agents can estimate peer reliability and learn from trustworthy peers when uncertain. This shifts the task from evaluating peer reasoning quality to estimating peer reliability based on interaction history. We then develop Epistemic Context Learning (ECL): a reasoning framework that conditions predictions on explicitly-built peer profiles from history. We further optimize ECL by reinforcement learning using auxiliary rewards. Our experiments reveal that our ECL enables small models like Qwen 3-4B to outperform a history-agnostic baseline 8x its size (Qwen 3-30B) by accurately identifying reliable peers. ECL also boosts frontier models to near-perfect (100%) performance. We show that ECL generalizes well to various MA configurations and we find that trust is modeled well by LLMs, revealing a strong correlation in trust modeling accuracy and final answer quality.

</details>


### [74] [Language-based Trial and Error Falls Behind in the Era of Experience](https://arxiv.org/abs/2601.21754)
*Haoyu Wang,Guozheng Ma,Shugang Cui,Yilun Kong,Haotian Luo,Li Shen,Mengya Gao,Yichao Wu,Xiaogang Wang,Dacheng Tao*

Main category: cs.AI

TL;DR: 提出了一种名为SCOUT的框架，通过轻量级“侦察兵”进行高效探索，然后用收集到的轨迹来引导LLM进行微调和强化学习，解决了LLM在非语言环境中表现不佳的问题，并显著提高了性能并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在非语言（如符号或空间）环境中表现受限，主要原因是探索成本高昂，需要大量的试错，这对于参数量大的LLMs来说是不可持续的。

Method: SCOUT框架将探索与利用分离，使用轻量级的“侦察兵”（如小型MLP）快速进行环境探索，收集轨迹。然后，利用这些轨迹对LLM进行监督微调（SFT），再通过多轮强化学习（RL）来激活其潜在的世界知识。

Result: SCOUT框架使Qwen2.5-3B-Instruct模型在测试任务上取得了0.86的平均分，显著优于Gemini-2.5-Pro（0.60），并且 GPU 小时消耗减少了约60%。

Conclusion: SCOUT框架能够有效解决LLM在非语言环境中的探索效率低下问题，通过高效的探索和引导式训练，显著提升了模型性能并降低了计算成本。

Abstract: While Large Language Models (LLMs) excel in language-based agentic tasks, their applicability to unseen, nonlinguistic environments (e.g., symbolic or spatial tasks) remains limited. Previous work attributes this performance gap to the mismatch between the pretraining distribution and the testing distribution. In this work, we demonstrate the primary bottleneck is the prohibitive cost of exploration: mastering these tasks requires extensive trial-and-error, which is computationally unsustainable for parameter-heavy LLMs operating in a high dimensional semantic space. To address this, we propose SCOUT (Sub-Scale Collaboration On Unseen Tasks), a novel framework that decouples exploration from exploitation. We employ lightweight "scouts" (e.g., small MLPs) to probe environmental dynamics at a speed and scale far exceeding LLMs. The collected trajectories are utilized to bootstrap the LLM via Supervised Fine-Tuning (SFT), followed by multi-turn Reinforcement Learning (RL) to activate its latent world knowledge. Empirically, SCOUT enables a Qwen2.5-3B-Instruct model to achieve an average score of 0.86, significantly outperforming proprietary models, including Gemini-2.5-Pro (0.60), while saving about 60% GPU hours consumption.

</details>


### [75] [Zero-Shot Statistical Downscaling via Diffusion Posterior Sampling](https://arxiv.org/abs/2601.21760)
*Ruian Tie,Wenbo Xiong,Zhengyu Shi,Xinyu Su,Chenyu jiang,Libo Wu,Hao Li*

Main category: cs.AI

TL;DR: 提出一种名为ZSSD的零样本统计降尺度框架，无需配对数据即可进行降尺度，利用物理一致性气候先验和统一坐标引导来解决现有方法的局限性，并在多种GCMs上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的监督学习气候降尺度方法在推广到GCMs时面临配对数据缺失和领域差距问题；而现有的零样本方法存在物理不一致和梯度消失的问题。

Method: 提出了零样本统计降尺度（ZSSD）框架，该框架利用从再分析数据中学习到的物理一致性气候先验，并结合地理边界和时间信息进行条件化，以确保物理有效性。引入了统一坐标引导策略来解决Vanilla DPS的梯度消失问题并保证与大尺度场的一致性。

Result: ZSSD在99%分位误差方面显著优于现有的零样本基线方法，并成功地在异构GCMs上重建了复杂天气事件，如热带气旋。

Conclusion: ZSSD是一种有效的零样本气候降尺度方法，能够克服现有方法的局限性，并在不同GCMs上实现物理一致且准确的降尺度。

Abstract: Conventional supervised climate downscaling struggles to generalize to Global Climate Models (GCMs) due to the lack of paired training data and inherent domain gaps relative to reanalysis. Meanwhile, current zero-shot methods suffer from physical inconsistencies and vanishing gradient issues under large scaling factors. We propose Zero-Shot Statistical Downscaling (ZSSD), a zero-shot framework that performs statistical downscaling without paired data during training. ZSSD leverages a Physics-Consistent Climate Prior learned from reanalysis data, conditioned on geophysical boundaries and temporal information to enforce physical validity. Furthermore, to enable robust inference across varying GCMs, we introduce Unified Coordinate Guidance. This strategy addresses the vanishing gradient problem in vanilla DPS and ensures consistency with large-scale fields. Results show that ZSSD significantly outperforms existing zero-shot baselines in 99th percentile errors and successfully reconstructs complex weather events, such as tropical cyclones, across heterogeneous GCMs.

</details>


### [76] [Abstract Concept Modelling in Conceptual Spaces: A Study on Chess Strategies](https://arxiv.org/abs/2601.21771)
*Hadi Banaee,Stephanie Lowry*

Main category: cs.AI

TL;DR: 本文提出了一个概念空间框架，用于建模随时间演变并具备明确目标的抽象概念。通过以国际象棋为例，将战略概念（如攻击、牺牲）表示为在可解释的质量维度上的几何区域，并将棋局表示为轨迹。概念识别通过分析轨迹的运动方向来实现。该框架支持双视角建模，并能捕捉玩家对同一局面的不同解读。实验证明了基于轨迹的概念识别的可行性，其运动模式与专家评论一致。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以对随时间演变且具有明确目标的抽象概念进行建模。作者希望扩展概念空间理论，以处理这类时序性的、目标导向的概念。

Method: 提出一个概念空间框架，将抽象概念建模为可在质量维度上量化的几何区域。将棋局表示为随时间变化的轨迹。通过分析轨迹在概念空间中的运动方向来识别和理解概念。实现了基于轨迹的概念识别模型，并进行了双视角建模。

Result: 证明了基于轨迹的概念识别的可行性。棋局轨迹的运动模式与专家的评论和策略分析高度一致。该方法能够捕捉并区分不同玩家对同一局面的不同理解。

Conclusion: 该框架为建模和理解随时间演变、目标导向的抽象概念提供了一个新颖的视角。它为处理序列决策和知识演化问题奠定了基础，并有望在未来进行更广泛的应用。

Abstract: We present a conceptual space framework for modelling abstract concepts that unfold over time, demonstrated through a chess-based proof-of-concept. Strategy concepts, such as attack or sacrifice, are represented as geometric regions across interpretable quality dimensions, with chess games instantiated and analysed as trajectories whose directional movement toward regions enables recognition of intended strategies. This approach also supports dual-perspective modelling, capturing how players interpret identical situations differently. Our implementation demonstrates the feasibility of trajectory-based concept recognition, with movement patterns aligning with expert commentary. This work explores extending the conceptual spaces theory to temporally realised, goal-directed concepts. The approach establishes a foundation for broader applications involving sequential decision-making and supports integration with knowledge evolution mechanisms for learning and refining abstract concepts over time.

</details>


### [77] [DropoutTS: Sample-Adaptive Dropout for Robust Time Series Forecasting](https://arxiv.org/abs/2601.21726)
*Siru Zhong,Yiqiu Liu,Zhiqing Cui,Zezhi Shao,Fei Wang,Qingsong Wen,Yuxuan Liang*

Main category: cs.AI

TL;DR: 本文提出了一种名为DropoutTS的即插即用模型，通过样本自适应Dropout机制，利用频谱稀疏性量化实例级噪声，并动态调整模型学习能力，从而提高深度时间序列模型在噪声数据下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度时间序列模型在面对现实世界中普遍存在的噪声数据时鲁棒性不足。现有的鲁棒性策略要么剔除数据，要么依赖于昂贵的先验量化，无法有效平衡效果和效率。

Method: DropoutTS采用样本自适应Dropout机制，利用频谱稀疏性通过重构残差量化实例级噪声，并将噪声映射到自适应Dropout率，选择性地抑制噪声而保留原始数据细节。

Result: 在不同噪声水平和公开数据集上的广泛实验表明，DropoutTS能够一致地提升现有模型的性能，以极小的参数开销和无需架构修改的方式提供了先进的鲁棒性。

Conclusion: DropoutTS是一种高效、模型无关的插件，通过样本自适应Dropout机制，能够有效提升深度时间序列模型在噪声数据下的鲁棒性，并且对模型性能的提升显著，开销极小。

Abstract: Deep time series models are vulnerable to noisy data ubiquitous in real-world applications. Existing robustness strategies either prune data or rely on costly prior quantification, failing to balance effectiveness and efficiency. In this paper, we introduce DropoutTS, a model-agnostic plugin that shifts the paradigm from "what" to learn to "how much" to learn. DropoutTS employs a Sample-Adaptive Dropout mechanism: leveraging spectral sparsity to efficiently quantify instance-level noise via reconstruction residuals, it dynamically calibrates model learning capacity by mapping noise to adaptive dropout rates - selectively suppressing spurious fluctuations while preserving fine-grained fidelity. Extensive experiments across diverse noise regimes and open benchmarks show DropoutTS consistently boosts superior backbones' performance, delivering advanced robustness with negligible parameter overhead and no architectural modifications. Our code is available at https://github.com/CityMind-Lab/DropoutTS.

</details>


### [78] [BioAgent Bench: An AI Agent Evaluation Suite for Bioinformatics](https://arxiv.org/abs/2601.21800)
*Dionizije Fa,Marko Čuljak,Bruno Pandža,Mateo Čupić*

Main category: cs.AI

TL;DR: 本研究提出了BioAgent Bench，一个用于评估AI在生物信息学任务中性能和鲁棒性的基准数据集和评估套件。结果表明，前沿AI代理能够可靠地完成多步骤生物信息学流程，但在受控扰动下表现出脆弱性，并且在涉及敏感数据的场景下，开源模型比闭源模型更具优势。


<details>
  <summary>Details</summary>
Motivation: 为了量化和提升AI在生物信息学这一关键领域的应用能力，特别是评估其在端到端任务中的性能和鲁棒性。

Method: 构建包含RNA-seq、变异检测、宏基因组学等任务的BioAgent Bench数据集；设计了包含具体输出要求和可控扰动的提示，以支持自动化评估；评估了多类前沿闭源和开源模型在不同代理框架下的表现；使用基于LLM的评分器来评估流程进展和结果的有效性。

Result: 前沿AI代理能够无需复杂的定制化支持，可靠地完成多步骤生物信息学流程并生成最终产物。然而，在输入损坏、诱饵文件和提示膨胀等扰动测试中，代理表现出明显的失效模式，表明高层流程构建能力不保证可靠的步骤级推理。在隐私敏感场景下，开源模型虽然完成率较低，但比闭源模型更适合。

Conclusion: BioAgent Bench为评估AI在生物信息学领域的应用提供了有效工具。现有AI代理在复杂任务中有潜力，但鲁棒性仍需提升。针对隐私要求，开源模型是闭源模型的有益补充。

Abstract: This paper introduces BioAgent Bench, a benchmark dataset and an evaluation suite designed for measuring the performance and robustness of AI agents in common bioinformatics tasks. The benchmark contains curated end-to-end tasks (e.g., RNA-seq, variant calling, metagenomics) with prompts that specify concrete output artifacts to support automated assessment, including stress testing under controlled perturbations. We evaluate frontier closed-source and open-weight models across multiple agent harnesses, and use an LLM-based grader to score pipeline progress and outcome validity. We find that frontier agents can complete multi-step bioinformatics pipelines without elaborate custom scaffolding, often producing the requested final artifacts reliably. However, robustness tests reveal failure modes under controlled perturbations (corrupted inputs, decoy files, and prompt bloat), indicating that correct high-level pipeline construction does not guarantee reliable step-level reasoning. Finally, because bioinformatics workflows may involve sensitive patient data, proprietary references, or unpublished IP, closed-source models can be unsuitable under strict privacy constraints; in such settings, open-weight models may be preferable despite lower completion rates. We release the dataset and evaluation suite publicly.

</details>


### [79] [JADE: Bridging the Strategic-Operational Gap in Dynamic Agentic RAG](https://arxiv.org/abs/2601.21916)
*Yiqun Chen,Erhan Zhang,Tianyi Hu,Shijie Wang,Zixuan Yang,Meizhi Zhong,Xiaochi Wei,Yan Gao,Yi Wu,Yao Hu,Jiaxin Mao*

Main category: cs.AI

TL;DR: 本文提出了一种名为JADE的统一框架，用于联合优化检索增强生成（RAG）系统中动态多轮工作流的规划和执行，解决了现有方法中的解耦优化问题，并通过端到端学习实现了规划器和执行器的协同适应，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统要么在固定的架构下联合优化模块，要么在赋予动态规划能力的同时将执行器视为黑盒，这种“解耦优化”导致了“策略-操作不匹配”，使得复杂的规划策略无法有效执行，从而降低了性能。

Method: JADE将规划和执行建模为一个统一的、共享骨干的合作多智能体团队，实现了端到端的学习，并通过基于结果的奖励来驱动。这种方法促进了规划器和执行器之间的“协同适应”。

Result: 实验结果表明，JADE能够将独立的模块转化为协同工作的系统，通过联合优化实现了显著的性能提升，并能够通过动态工作流编排灵活地平衡效率和效果。

Conclusion: JADE框架通过联合优化规划和执行，解决了RAG系统中策略-操作不匹配的问题，实现了系统模块之间的协同适应，从而在动态多轮工作流中取得了卓越的性能表现，并提供了效率和效果之间的灵活权衡。

Abstract: The evolution of Retrieval-Augmented Generation (RAG) has shifted from static retrieval pipelines to dynamic, agentic workflows where a central planner orchestrates multi-turn reasoning. However, existing paradigms face a critical dichotomy: they either optimize modules jointly within rigid, fixed-graph architectures, or empower dynamic planning while treating executors as frozen, black-box tools. We identify that this \textit{decoupled optimization} creates a ``strategic-operational mismatch,'' where sophisticated planning strategies fail to materialize due to unadapted local executors, often leading to negative performance gains despite increased system complexity. In this paper, we propose \textbf{JADE} (\textbf{J}oint \textbf{A}gentic \textbf{D}ynamic \textbf{E}xecution), a unified framework for the joint optimization of planning and execution within dynamic, multi-turn workflows. By modeling the system as a cooperative multi-agent team unified under a single shared backbone, JADE enables end-to-end learning driven by outcome-based rewards. This approach facilitates \textit{co-adaptation}: the planner learns to operate within the capability boundaries of the executors, while the executors evolve to align with high-level strategic intent. Empirical results demonstrate that JADE transforms disjoint modules into a synergistic system, yielding remarkable performance improvements via joint optimization and enabling a flexible balance between efficiency and effectiveness through dynamic workflow orchestration.

</details>


### [80] [From Meta-Thought to Execution: Cognitively Aligned Post-Training for Generalizable and Reliable LLM Reasoning](https://arxiv.org/abs/2601.21909)
*Shaojie Wang,Liang Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种受人类认知启发的LLM后训练框架（CoMT+CCRL），通过区分抽象策略学习和具体实例适应两个阶段，提高了模型在推理任务上的泛化能力和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM后训练方法（SFT+RL）将整个推理过程视为一个整体进行优化，这与人类解决问题时先学习抽象策略再应用于具体实例的认知过程不符，导致模型缺乏泛化能力。

Method: 提出Chain-of-Meta-Thought (CoMT) 来关注抽象推理模式，使模型能学习可泛化的策略；提出Confidence-Calibrated Reinforcement Learning (CCRL) 来优化任务适应性，通过对中间步骤的置信度感知奖励来防止错误累积。

Result: 在四个模型和八个基准测试中，CoMT+CCRL在分布内和分布外任务上分别取得了2.19%和4.63%的提升，同时训练时间减少了65-70%，Token消耗减少了50%。

Conclusion: 将LLM后训练过程与人类认知原理对齐，不仅能提高泛化能力，还能显著提升训练效率。

Abstract: Current LLM post-training methods optimize complete reasoning trajectories through Supervised Fine-Tuning (SFT) followed by outcome-based Reinforcement Learning (RL). While effective, a closer examination reveals a fundamental gap: this approach does not align with how humans actually solve problems. Human cognition naturally decomposes problem-solving into two distinct stages: first acquiring abstract strategies (i.e., meta-knowledge) that generalize across problems, then adapting them to specific instances. In contrast, by treating complete trajectories as basic units, current methods are inherently problem-centric, entangling abstract strategies with problem-specific execution. To address this misalignment, we propose a cognitively-inspired framework that explicitly mirrors the two-stage human cognitive process. Specifically, Chain-of-Meta-Thought (CoMT) focuses supervised learning on abstract reasoning patterns without specific executions, enabling acquisition of generalizable strategies. Confidence-Calibrated Reinforcement Learning (CCRL) then optimizes task adaptation via confidence-aware rewards on intermediate steps, preventing overconfident errors from cascading and improving execution reliability. Experiments across four models and eight benchmarks show 2.19\% and 4.63\% improvements in-distribution and out-of-distribution respectively over standard methods, while reducing training time by 65-70% and token consumption by 50%, demonstrating that aligning post-training with human cognitive principles yields not only superior generalization but also enhanced training efficiency.

</details>


### [81] [ProRAG: Process-Supervised Reinforcement Learning for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.21912)
*Zhao Wang,Ziliang Zhao,Zhicheng Dou*

Main category: cs.AI

TL;DR: 本文提出了一种名为ProRAG的流程监督强化学习框架，通过引入细粒度的中间奖励信号，解决了传统基于结果的强化学习在处理复杂推理任务时奖励稀疏和信用分配效率低下导致“过程幻觉”的问题，并在多跳推理任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于结果的强化学习方法在处理长序列推理任务时存在奖励稀疏和信用分配困难的问题，容易导致模型产生“过程幻觉”（即通过错误逻辑或冗余检索获得正确答案）。现有的流程感知方法也存在局限性，例如缺乏在线探索能力。因此，需要一种新的方法来为RAG模型提供细粒度的过程反馈，以改进其推理过程。

Method: ProRAG框架包含四个阶段：1. 监督策略预训练，用于初始化模型并建立结构化推理格式；2. 构建基于MCTS的流程奖励模型（PRM），用于量化中间推理步骤的质量；3. PRM引导的推理精炼，使策略与细粒度的流程偏好对齐；4. 流程监督强化学习，结合了双粒度优势机制，将流程奖励与全局结果信号相结合，为每一步动作提供精确反馈。

Result: 在五个多跳推理基准上的广泛实验表明，ProRAG在整体性能上优于强有力的基于结果的和流程感知的强化学习基线方法，尤其是在复杂的长距离推理任务上。这验证了细粒度流程监督的有效性。

Conclusion: ProRAG通过整合学习到的逐步监督信号到在线优化循环中，有效地解决了传统强化学习在RAG中的不足，通过结合细粒度的流程奖励和全局结果信号，为模型提供了精确的反馈，从而提升了在复杂推理任务上的表现，有效减少了“过程幻觉”。

Abstract: Reinforcement learning (RL) has become a promising paradigm for optimizing Retrieval-Augmented Generation (RAG) in complex reasoning tasks. However, traditional outcome-based RL approaches often suffer from reward sparsity and inefficient credit assignment, as coarse-grained scalar rewards fail to identify specific erroneous steps within long-horizon trajectories. This ambiguity frequently leads to "process hallucinations", where models reach correct answers through flawed logic or redundant retrieval steps. Although recent process-aware approaches attempt to mitigate this via static preference learning or heuristic reward shaping, they often lack the on-policy exploration capabilities required to decouple step-level credit from global outcomes. To address these challenges, we propose ProRAG, a process-supervised reinforcement learning framework designed to integrate learned step-level supervision into the online optimization loop. Our framework consists of four stages: (1) Supervised Policy Warmup to initialize the model with a structured reasoning format; (2) construction of an MCTS-based Process Reward Model (PRM) to quantify intermediate reasoning quality; (3) PRM-Guided Reasoning Refinement to align the policy with fine-grained process preferences; and (4) Process-Supervised Reinforcement Learning with a dual-granularity advantage mechanism. By aggregating step-level process rewards with global outcome signals, ProRAG provides precise feedback for every action. Extensive experiments on five multi-hop reasoning benchmarks demonstrate that ProRAG achieves superior overall performance compared to strong outcome-based and process-aware RL baselines, particularly on complex long-horizon tasks, validating the effectiveness of fine-grained process supervision. The code and model are available at https://github.com/lilinwz/ProRAG.

</details>


### [82] [CORE:Toward Ubiquitous 6G Intelligence Through Collaborative Orchestration of Large Language Model Agents Over Hierarchical Edge](https://arxiv.org/abs/2601.21822)
*Zitong Yu,Boquan Sun,Yang Li,Zheyan Qu,Xing Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为CORE（Collaborative Orchestration Role at Edge）的框架，旨在通过分布式、多角色的LLM协同工作来克服6G网络中异构计算资源不足的问题，以实现无处不在的智能。


<details>
  <summary>Details</summary>
Motivation: 6G网络和LLM的快速发展带来了普遍智能的愿景，但现有计算资源分散且异构，难以满足单个LLM Agent执行复杂推理任务的需求。因此，需要一种新的方法来有效利用这些资源。

Method: CORE框架将多个具有不同角色的LLM部署在移动设备和边缘服务器上，并通过三个优化模块（实时感知、动态角色编排、流水线并行执行）来实现高效协同。此外，还引入了一种角色亲和度调度算法来智能匹配计算需求与分散的资源。

Result: 实验和案例研究表明，CORE在6G应用场景中显著提高了系统效率和任务完成率。在实际边缘计算平台上的部署也验证了其鲁棒性。

Conclusion: CORE框架能够有效地解决6G网络中分布式LLM协同计算的挑战，实现了高效的任务处理和普遍智能。其在实际部署中的表现证明了其可行性和优越性。

Abstract: Rapid advancements in sixth-generation (6G) networks and large language models (LLMs) have paved the way for ubiquitous intelligence, wherein seamless connectivity and distributed artificial intelligence (AI) have revolutionized various aspects of our lives.However, realizing this vision faces significant challenges owing to the fragmented and heterogeneous computing resources across hierarchical networks, which are insufficient for individual LLM agents to perform complex reasoning tasks.To address this issue, we propose Collaborative Orchestration Role at Edge (CORE), an innovative framework that employs a collaborative learning system in which multiple LLMs, each assigned a distinct functional role, are distributed across mobile devices and tiered edge servers. The system integrates three optimization modules, encompassing real-time perception,dynamic role orchestration, and pipeline-parallel execution, to facilitate efficient and rapid collaboration among distributed agents. Furthermore, we introduce a novel role affinity scheduling algorithm for dynamically orchestrating LLM role assignments across the hierarchical edge infrastructure, intelligently matching computational demands with available dispersed resources.Finally, comprehensive case studies and performance evaluations across various 6G application scenarios demonstrated the efficacy of CORE, revealing significant enhancements in the system efficiency and task completion rates. Building on these promising outcomes, we further validated the practical applicability of CORE by deploying it on a real-world edge-computing platform,that exhibits robust performance in operational environments.

</details>


### [83] [Self-Compression of Chain-of-Thought via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.21919)
*Yiqun Chen,Jinyuan Feng,Wei Yang,Meizhi Zhong,Zhengliang Shi,Rui Li,Xiaochi Wei,Yan Gao,Yi Wu,Yao Hu,Zhiqiang Pu,Jiaxin Mao*

Main category: cs.AI

TL;DR: 提出了一种名为 SCMA 的多智能体强化学习框架，通过分割和评分两个代理来选择性地惩罚冗余推理步骤，从而在保持推理逻辑的同时减少了大型推理模型的推理开销，并提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的解决方案通过长度惩罚和基于结果的奖励来解决推理开销问题，但这种简单的奖励加权难以平衡简洁性和准确性，因为强制简洁性可能会损害关键的推理逻辑。

Method: 提出了一种名为 Self-Compression via MARL (SCMA) 的多智能体强化学习框架。该框架包含一个分割代理（用于将推理过程分解为逻辑块）和一个评分代理（用于量化每个块的重要性）。这两个代理协同作用，为训练中的推理代理定义了一个重要性加权的长度惩罚，激励推理代理优先考虑基本逻辑，同时在部署时不会引入推理开销。

Result: SCMA 将响应长度减少了 11.1% 到 39.0%，同时将准确性提高了 4.33% 到 10.02%。消融研究和定性分析表明，MARL 框架内的协同优化产生了比传统 RL 范式更强大的 LRM。

Conclusion: SCMA 框架成功地解决了大型推理模型中的推理冗余问题，通过智能地选择性惩罚冗余，可以在不牺牲准确性的情况下显著减少推理开销，并提升模型性能。

Abstract: The inference overhead induced by redundant reasoning undermines the interactive experience and severely bottlenecks the deployment of Large Reasoning Models. Existing reinforcement learning (RL)-based solutions tackle this problem by coupling a length penalty with outcome-based rewards. This simplistic reward weighting struggles to reconcile brevity with accuracy, as enforcing brevity may compromise critical reasoning logic. In this work, we address this limitation by proposing a multi-agent RL framework that selectively penalizes redundant chunks, while preserving essential reasoning logic. Our framework, Self-Compression via MARL (SCMA), instantiates redundancy detection and evaluation through two specialized agents: \textbf{a Segmentation Agent} for decomposing the reasoning process into logical chunks, and \textbf{a Scoring Agent} for quantifying the significance of each chunk. The Segmentation and Scoring agents collaboratively define an importance-weighted length penalty during training, incentivizing \textbf{a Reasoning Agent} to prioritize essential logic without introducing inference overhead during deployment. Empirical evaluations across model scales demonstrate that SCMA reduces response length by 11.1\% to 39.0\% while boosting accuracy by 4.33\% to 10.02\%. Furthermore, ablation studies and qualitative analysis validate that the synergistic optimization within the MARL framework fosters emergent behaviors, yielding more powerful LRMs compared to vanilla RL paradigms.

</details>


### [84] [Looking Beyond Accuracy: A Holistic Benchmark of ECG Foundation Models](https://arxiv.org/abs/2601.21830)
*Francesca Filice,Edoardo De Rose,Simone Bartucci,Francesco Calimeri,Simona Perri*

Main category: cs.AI

TL;DR: 本文提出了一种针对心电图（ECG）领域专家基础模型（FMs）的全面基准测试框架，该框架结合了下游任务性能评估和表示层面分析，以深入理解其泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有针对ECG领域基础模型的研究主要集中在下游任务性能评估，而忽略了对其生成嵌入（embeddings）的泛化能力的深入评估，这对于在医疗等错误敏感领域负责任地应用基础模型至关重要。

Method: 提出了一种结合SHAP和UMAP技术的基准测试方法，该方法不仅评估模型在下游任务上的性能，还分析其表示层面的特征。并在此方法的基础上，对采用不同预训练技术、在不同跨大陆数据集和数据可用性设置（包括数据稀疏场景）下训练的多个ECG领域专家基础模型进行了广泛评估。

Result: 实验结果表明，提出的基准测试协议能够提供关于ECG领域专家基础模型嵌入模式的丰富见解，从而更深入地理解其表示结构和泛化能力。

Conclusion: 该研究提供了一个全面的ECG领域专家基础模型基准测试框架，该框架通过结合性能和表示层面分析，能够更深入地评估模型的泛化能力，为负责任地在医疗领域应用基础模型提供了重要依据。

Abstract: The electrocardiogram (ECG) is a cost-effective, highly accessible and widely employed diagnostic tool. With the advent of Foundation Models (FMs), the field of AI-assisted ECG interpretation has begun to evolve, as they enable model reuse across different tasks by relying on embeddings. However, to responsibly employ FMs, it is crucial to rigorously assess to which extent the embeddings they produce are generalizable, particularly in error-sensitive domains such as healthcare. Although prior works have already addressed the problem of benchmarking ECG-expert FMs, they focus predominantly on the evaluation of downstream performance. To fill this gap, this study aims to find an in-depth, comprehensive benchmarking framework for FMs, with a specific focus on ECG-expert ones. To this aim, we introduce a benchmark methodology that complements performance-based evaluation with representation-level analysis, leveraging SHAP and UMAP techniques. Furthermore, we rely on the methodology for carrying out an extensive evaluation of several ECG-expert FMs pretrained via state-of-the-art techniques over different cross-continental datasets and data availability settings; this includes ones featuring data scarcity, a fairly common situation in real-world medical scenarios. Experimental results show that our benchmarking protocol provides a rich insight of ECG-expert FMs' embedded patterns, enabling a deeper understanding of their representational structure and generalizability.

</details>


### [85] [Bridging Forecast Accuracy and Inventory KPIs: A Simulation-Based Software Framework](https://arxiv.org/abs/2601.21844)
*So Fukuhara,Abdallah Alabdallah,Nuwan Gunasekara,Slawomir Nowaczyk*

Main category: cs.AI

TL;DR: 本文提出了一个决策中心仿真框架，用于评估汽车售后备件库存管理中预测模型的实际运营效果，发现传统的统计准确性指标与运营绩效（成本和服务水平）之间并非简单的线性关系。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多仅使用统计准确性指标评估预测模型，但这些指标与实际运营绩效（如总成本和服务水平）的关系不明。因此，需要一个能够评估预测模型在实际库存管理环境中的影响的框架。

Method: 提出一个合成需求生成器（针对备件需求特点）、一个灵活的预测模型模块（可集成任意预测模型）和一个库存控制模拟器（消费预测并计算运营KPI）组成的闭环仿真框架。

Result: 通过广泛的仿真场景，研究发现，传统的统计准确性指标的提升并不一定能带来更好的运营绩效，具有相似统计误差的模型可能导致截然不同的成本-服务权衡。

Conclusion: 该框架打通了需求预测与库存管理之间的联系，将评估重点从纯粹的预测准确性转移到在汽车售后等领域的运营相关性，并为模型选择提供了指导。

Abstract: Efficient management of spare parts inventory is crucial in the automotive aftermarket, where demand is highly intermittent and uncertainty drives substantial cost and service risks. Forecasting is therefore central, but the quality of a forecasting model should be judged not by statistical accuracy (e.g., MAE, RMSE, IAE) but rather by its impact on key operational performance indicators (KPIs), such as total cost and service level. Yet most existing work evaluates models exclusively using accuracy metrics, and the relationship between these metrics and operational KPIs remains poorly understood. To address this gap, we propose a decision-centric simulation software framework that enables systematic evaluation of forecasting model in realistic inventory management setting. The framework comprises: (i) a synthetic demand generator tailored to spare-parts demand characteristics, (ii) a flexible forecasting module that can host arbitrary predictive models, and (iii) an inventory control simulator that consumes the forecasts and computes operational KPIs. This closed-loop setup enables researchers to evaluate models not only in terms of statistical error but also in terms of their downstream implications for inventory decisions. Using a wide range of simulation scenarios, we show that improvements in conventional accuracy metrics do not necessarily translate into better operational performance, and that models with similar statistical error profiles can induce markedly different cost-service trade-offs. We analyze these discrepancies to characterize how specific aspects of forecast performance affect inventory outcomes and derive guidance for model selection. Overall, the framework operationalizes the link between demand forecasting and inventory management, shifting evaluation from purely predictive accuracy toward operational relevance in the automotive aftermarket and related domains.

</details>


### [86] [Exploring Reasoning Reward Model for Agents](https://arxiv.org/abs/2601.22154)
*Kaixuan Fan,Kaituo Feng,Manyuan Zhang,Tianshuo Peng,Zhixun Li,Yilei Jiang,Shuang Chen,Peng Pei,Xunliang Cai,Xiangyu Yue*

Main category: cs.AI

TL;DR: 本文提出了一种名为Agent-RRM的多维度奖励模型，用于为Agentic RL提供结构化的中间推理反馈，包括推理轨迹、焦点批评和总体评分。研究了三种整合策略，其中Reagent-U在12个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的Agentic RL方法主要依赖稀疏的基于结果的奖励，这种奖励无法区分中间推理的质量，导致次优的训练结果。

Method: 提出Agent Reasoning Reward Model (Agent-RRM)，该模型能够生成结构化的反馈，包括显式的推理轨迹、聚焦批评（指导改进）和总体过程评估得分。研究了三种整合策略：Reagent-C（文本增强的精炼）、Reagent-R（奖励增强的指导）和Reagent-U（统一的反馈整合）。

Result: 在12个多样化的基准测试中，Reagent-U策略取得了显著的性能提升，在GAIA上达到43.7%，在WebWalkerQA上达到46.2%。

Conclusion: Agent-RRM和提出的训练方案（特别是Reagent-U）能够有效地改进Agentic RL的性能，克服了传统基于稀疏奖励训练方法的局限性。

Abstract: Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a multi-faceted reward model that produces structured feedback for agentic trajectories, including (1) an explicit reasoning trace , (2) a focused critique that provides refinement guidance by highlighting reasoning flaws, and (3) an overall score that evaluates process performance. Leveraging these signals, we systematically investigate three integration strategies: Reagent-C (text-augmented refinement), Reagent-R (reward-augmented guidance), and Reagent-U (unified feedback integration). Extensive evaluations across 12 diverse benchmarks demonstrate that Reagent-U yields substantial performance leaps, achieving 43.7% on GAIA and 46.2% on WebWalkerQA, validating the effectiveness of our reasoning reward model and training schemes. Code, models, and datasets are all released to facilitate future research.

</details>


### [87] [KnowBias: Mitigating Social Bias in LLMs via Know-Bias Neuron Enhancement](https://arxiv.org/abs/2601.21864)
*Jinhao Pan,Chahat Raj,Anjishnu Mukherjee,Sina Mansouri,Bowen Wei,Shloka Yada,Ziwei Zhu*

Main category: cs.AI

TL;DR: 提出了一种名为KnowBias的框架，通过增强而非抑制编码偏见知识的神经元来减轻大型语言模型的社会偏见，并在不进行重训练的情况下实现了优异的去偏见效果和通用能力保留。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM去偏见方法通常采用压制策略，但这些方法容易出错、泛化能力弱、数据效率低且可能损害模型的通用能力。因此，需要一种更有效、更鲁棒的去偏见方法。

Method: KnowBias框架通过以下步骤识别和增强编码偏见知识的神经元：1. 使用少量偏见知识问题通过归因分析识别神经元。2. 在推理时选择性地增强这些神经元。此过程无需重训练模型。

Result: 在多个基准测试和LLMs上进行的实验表明，KnowBias在去偏见方面达到了最先进的性能，同时对模型通用能力的损害最小。该方法在不同偏见类型和人群之间具有良好的泛化性，并且数据效率高。

Conclusion: KnowBias是一种轻量级且概念上不同的框架，通过增强而非压制编码偏见知识的神经元，能够有效地减轻LLM的社会偏见，同时保持其通用能力，并且无需重训练，具有高度的数据效率和泛化性。

Abstract: Large language models (LLMs) exhibit social biases that reinforce harmful stereotypes, limiting their safe deployment. Most existing debiasing methods adopt a suppressive paradigm by modifying parameters, prompts, or neurons associated with biased behavior; however, such approaches are often brittle, weakly generalizable, data-inefficient, and prone to degrading general capability. We propose \textbf{KnowBias}, a lightweight and conceptually distinct framework that mitigates bias by strengthening, rather than suppressing, neurons encoding bias-knowledge. KnowBias identifies neurons encoding bias knowledge using a small set of bias-knowledge questions via attribution-based analysis, and selectively enhances them at inference time. This design enables strong debiasing while preserving general capabilities, generalizes across bias types and demographics, and is highly data efficient, requiring only a handful of simple yes/no questions and no retraining. Experiments across multiple benchmarks and LLMs demonstrate consistent state-of-the-art debiasing performance with minimal utility degradation. Data and code are available at https://github.com/JP-25/KnowBias.

</details>


### [88] [A Unified XAI-LLM Approach for EndotrachealSuctioning Activity Recognition](https://arxiv.org/abs/2601.21802)
*Hoang Khang Phan,Quang Vinh Dang,Noriyo Colley,Christina Garcia,Nhat Tan Le*

Main category: cs.AI

TL;DR: 研究提出了一种基于大型语言模型（LLM）的统一框架，用于视频分析气管插管术（ES），并能生成可解释的反馈，该框架在识别准确性和F1分数上优于传统方法，为护理教育提供了一种可扩展、可解释的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的气管插管术（ES）培训缺乏自动化识别和反馈系统，尤其是在监督有限的家庭护理和教育环境中，存在提升培训效率和患者安全性的需求。

Method: 提出一个以LLM为中心，集活动识别和可解释反馈生成于一体的视频分析框架。LLM作为核心推理模块，处理时空活动识别和决策分析，并能以自然语言生成反馈。同时，框架包含基于异常检测和可解释AI（XAI）的学生支持模块，提供自动化、可解释的指导。

Result: 基于LLM的方法在活动识别任务上，相较于基线模型，在准确率和F1分数上均有约15-20%的提升。学生支持模块能够提供自动化的、可解释的反馈，指出正确操作并提出改进建议。

Conclusion: 所提出的LLM驱动框架为气管插管术的培训提供了一个可扩展、可解释、数据驱动的解决方案，有望提升护理教育的效率和患者安全性。

Abstract: Endotracheal suctioning (ES) is an invasive yet essential clinical procedure that requires a high degree of skill to minimize patient risk - particularly in home care and educational settings, where consistent supervision may be limited. Despite its critical importance, automated recognition and feedback systems for ES training remain underexplored. To address this gap, this study proposes a unified, LLM-centered framework for video-based activity recognition benchmarked against conventional machine learning and deep learning approaches, and a pilot study on feedback generation. Within this framework, the Large Language Model (LLM) serves as the central reasoning module, performing both spatiotemporal activity recognition and explainable decision analysis from video data. Furthermore, the LLM is capable of verbalizing feedback in natural language, thereby translating complex technical insights into accessible, human-understandable guidance for trainees. Experimental results demonstrate that the proposed LLM-based approach outperforms baseline models, achieving an improvement of approximately 15-20\% in both accuracy and F1 score. Beyond recognition, the framework incorporates a pilot student-support module built upon anomaly detection and explainable AI (XAI) principles, which provides automated, interpretable feedback highlighting correct actions and suggesting targeted improvements. Collectively, these contributions establish a scalable, interpretable, and data-driven foundation for advancing nursing education, enhancing training efficiency, and ultimately improving patient safety.

</details>


### [89] [astra-langchain4j: Experiences Combining LLMs and Agent Programming](https://arxiv.org/abs/2601.21879)
*Rem Collier,Katharine Beaumont,Andrei Ciortea*

Main category: cs.AI

TL;DR: 本文介绍了将大型语言模型（LLM）集成到ASTRA编程语言中的原型开发经验，探讨了生成式AI对传统Agent工具包的影响以及工具包经验对Agentic平台设计的影响。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的兴起以及对Agentic AI作为多智能体系统形式的日益关注，促使研究者探索AI技术如何影响传统Agent工具包的使用，以及现有工具包的经验如何指导新型Agentic平台的设计。

Method: 本文概述了ASTRA编程语言的工具包，并提供了三个LLM集成的示例实现。通过分析这些示例，总结了开发过程中获得的经验。

Result: 文章展示了LLM与ASTRA编程语言集成的原型，并分享了在开发过程中遇到的挑战和学到的经验。

Conclusion: 通过开发LLM与ASTRA的集成原型，作者获得了关于如何将LLM技术融入传统Agent框架以及如何利用现有Agent经验设计新平台的宝贵见解。

Abstract: Given the emergence of Generative AI over the last two years and the increasing focus on Agentic AI as a form of Multi-Agent System it is important to explore both how such technologies can impact the use of traditional Agent Toolkits and how the wealth of experience encapsulated in those toolkits can influence the design of the new agentic platforms. This paper presents an overview of our experience developing a prototype large language model (LLM) integration for the ASTRA programming language. It presents a brief overview of the toolkit, followed by three example implementations, concluding with a discussion of the experiences garnered through the examples.

</details>


### [90] [WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents](https://arxiv.org/abs/2601.21872)
*Yao Zhang,Shijie Tang,Zeyu Li,Zhen Han,Volker Tresp*

Main category: cs.AI

TL;DR: 本文提出了一种名为WebArbiter的新型过程奖励模型（WebPRM），它将奖励建模视为文本生成任务，输出结构化的推理过程和最终的偏好判断，以改进Web代理的导航能力。该模型通过两阶段训练（推理蒸馏和强化学习）实现，并在新发布的WebPRMBench基准上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有WebPRM方法在处理Web代理的长序列决策问题时存在局限性，例如标量奖励信号稀疏且延迟，难以支持推理扩展；基于清单的PRM依赖于脆弱的模板匹配，易受布局和语义变化影响，且可能误判动作。这促使研究者开发更鲁棒、更具可解释性的PRM。

Method: WebArbiter将奖励建模 formulated as text generation，生成包含结构化推理和偏好判断的文本。训练过程包括推理蒸馏（使模型具备连贯的、受原则指导的推理能力）和强化学习（纠正教师偏差，使判断更准确）。为评估该模型，研究者还发布了WebPRMBench基准。

Result: 在WebPRMBench基准上，WebArbiter-7B比最强的基线GPT-5高出9.1个点。在WebArena-Lite的奖励引导轨迹搜索任务上，WebArbiter比现有最佳WebPRM高出7.2个点。

Conclusion: WebArbiter是一种创新的、以推理为先的、原则归纳式的WebPRM，通过文本生成方式生成结构化推理和偏好判断，克服了现有方法的局限性，在复杂Web任务中表现出强大的泛化能力和实际价值。

Abstract: Web agents hold great potential for automating complex computer tasks, yet their interactions involve long-horizon, sequential decision-making with irreversible actions. In such settings, outcome-based supervision is sparse and delayed, often rewarding incorrect trajectories and failing to support inference-time scaling. This motivates the use of Process Reward Models (WebPRMs) for web navigation, but existing approaches remain limited: scalar WebPRMs collapse progress into coarse, weakly grounded signals, while checklist-based WebPRMs rely on brittle template matching that fails under layout or semantic changes and often mislabels superficially correct actions as successful, providing little insight or interpretability. To address these challenges, we introduce WebArbiter, a reasoning-first, principle-inducing WebPRM that formulates reward modeling as text generation, producing structured justifications that conclude with a preference verdict and identify the action most conducive to task completion under the current context. Training follows a two-stage pipeline: reasoning distillation equips the model with coherent principle-guided reasoning, and reinforcement learning corrects teacher biases by directly aligning verdicts with correctness, enabling stronger generalization. To support systematic evaluation, we release WebPRMBench, a comprehensive benchmark spanning four diverse web environments with rich tasks and high-quality preference annotations. On WebPRMBench, WebArbiter-7B outperforms the strongest baseline, GPT-5, by 9.1 points. In reward-guided trajectory search on WebArena-Lite, it surpasses the best prior WebPRM by up to 7.2 points, underscoring its robustness and practical value in real-world complex web tasks.

</details>


### [91] [Making Models Unmergeable via Scaling-Sensitive Loss Landscape](https://arxiv.org/abs/2601.21898)
*Minwoo Jang,Hoyoung Kim,Jabin Koo,Jungseul Ok*

Main category: cs.AI

TL;DR: 本研究提出了一种名为 Trap$^{2}$ 的新框架，用于解决模型合并带来的治理问题。Trap$^{2}$ 能够将安全对齐和许可条款嵌入到模型更新中，使其在模型合并时失效，从而防止未经授权的模型重组。


<details>
  <summary>Details</summary>
Motivation: 模型集线器的兴起使得模型组件的复用更加便捷，但也带来了“治理缺口”，即下游用户可以重组模型权重，绕过安全对齐或许可条款。现有的防御方法通常是事后且依赖特定架构的，保护效果不稳定。

Method: Trap$^{2}$ 是一种与架构无关的保护框架，它在微调过程中将保护措施编码到更新中。它不依赖于特定架构的方法，而是使用权重重新缩放作为模型合并过程的代理。在独立使用时，Trap$^{2}$ 保持了模型权重的有效性，但在模型合并过程中，由于权重重新缩放，其效果会下降，从而破坏了未经授权的模型合并。

Result: Trap$^{2}$ 能够有效地抵御未经授权的模型合并，同时不影响模型在独立使用时的性能。它为模型权重提供了一种通用的、与架构无关的保护机制。

Conclusion: Trap$^{2}$ 提出了一种有效的解决方案来弥合模型合并带来的治理缺口，它通过将保护措施嵌入模型更新，并利用权重重新缩放来防止未经授权的模型重组，为保护模型安全和许可条款提供了新的途径。

Abstract: The rise of model hubs has made it easier to access reusable model components, making model merging a practical tool for combining capabilities. Yet, this modularity also creates a \emph{governance gap}: downstream users can recompose released weights into unauthorized mixtures that bypass safety alignment or licensing terms. Because existing defenses are largely post-hoc and architecture-specific, they provide inconsistent protection across diverse architectures and release formats in practice. To close this gap, we propose \textsc{Trap}$^{2}$, an architecture-agnostic protection framework that encodes protection into the update during fine-tuning, regardless of whether they are released as adapters or full models. Instead of relying on architecture-dependent approaches, \textsc{Trap}$^{2}$ uses weight re-scaling as a simple proxy for the merging process. It keeps released weights effective in standalone use, but degrades them under re-scaling that often arises in merging, undermining unauthorized merging.

</details>


### [92] [AgenticSimLaw: A Juvenile Courtroom Multi-Agent Debate Simulation for Explainable High-Stakes Tabular Decision Making](https://arxiv.org/abs/2601.21936)
*Jon Chun,Kathrine Elkins,Yong Suk Lee*

Main category: cs.AI

TL;DR: 本文提出了一种名为 AgenticSimLaw 的多主体辩论框架，用于高风险表格决策任务，通过模拟法庭辩论提供透明、可控的推理过程，并在青少年犯罪预测任务上展示了其优于传统单主体链式思考（CoT）的稳定性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的黑盒方法在高风险表格决策任务中缺乏透明度和可控性，难以进行审计。作者希望开发一个更可控、可解释的框架来应对这一挑战，并解决多主体系统在组织、可观察性和责任分配方面的难题。

Method: 构建了一个角色结构的、多主体辩论框架 AgenticSimLaw，模拟法庭辩论，明确定义了检察官、辩护律师和法官的角色，以及结构化的互动协议（7轮辩论）。每个主体都有私有的推理策略。在 NLSY97 数据集上进行了年轻成年人再犯率预测的基准测试，并与传统的链式思考（CoT）提示进行了比较。

Result: 与单主体推理相比，结构化的多主体辩论在青少年犯罪预测任务上表现出更稳定和更具泛化性的性能，准确率和 F1 分数之间的相关性也更强。AgenticSimLaw 提供了对推理步骤的精细控制，生成完整的交互记录以提高可解释性，并能够系统地分析主体的行为。

Conclusion: AgenticSimLaw 框架为高风险表格决策任务提供了一种透明、可控且可审计的解决方案。该框架不仅提升了决策性能，还增强了可解释性和人类监督能力，并且可以推广到任何需要审慎考虑和人类监督的决策任务中。

Abstract: We introduce AgenticSimLaw, a role-structured, multi-agent debate framework that provides transparent and controllable test-time reasoning for high-stakes tabular decision-making tasks. Unlike black-box approaches, our courtroom-style orchestration explicitly defines agent roles (prosecutor, defense, judge), interaction protocols (7-turn structured debate), and private reasoning strategies, creating a fully auditable decision-making process. We benchmark this framework on young adult recidivism prediction using the NLSY97 dataset, comparing it against traditional chain-of-thought (CoT) prompting across almost 90 unique combinations of models and strategies. Our results demonstrate that structured multi-agent debate provides more stable and generalizable performance compared to single-agent reasoning, with stronger correlation between accuracy and F1-score metrics. Beyond performance improvements, AgenticSimLaw offers fine-grained control over reasoning steps, generates complete interaction transcripts for explainability, and enables systematic profiling of agent behaviors. While we instantiate this framework in the criminal justice domain to stress-test reasoning under ethical complexity, the approach generalizes to any deliberative, high-stakes decision task requiring transparency and human oversight. This work addresses key LLM-based multi-agent system challenges: organization through structured roles, observability through logged interactions, and responsibility through explicit non-deployment constraints for sensitive domains. Data, results, and code will be available on github.com under the MIT license.

</details>


### [93] [Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities](https://arxiv.org/abs/2601.21937)
*Shuangshuang Ying,Zheyu Wang,Yunjian Peng,Jin Chen,Yuhao Wu,Hongbin Lin,Dingyu He,Siyi Liu,Gengchen Yu,YinZhu Piao,Yuchen Wu,Xin Gui,Zhongyuan Peng,Xin Li,Xeron Du,Libo Qin,YiXin Cao,Ge Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为DeR2的实验沙箱，用于评估大型语言模型在处理全新科学信息时的真实推理能力，同时隔离了检索和参数记忆等干扰因素，并提出了两种验证方法来防止参数泄露。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型评估方法难以区分模型在科学信息上的真实推理能力与检索、工具链选择、参数记忆及网络波动等因素的影响，因此需要一种更可控的评估方式。

Method: DeR2通过四种实验模式（仅指令、概念、仅相关文档、全集）来分离证据获取与推理过程，并利用两种验证方法（仅参数失败但概念可解）来防止模型进行参数记忆。实验数据集包含2023-2025年的理论论文，并附带专家标注的概念和推理过程。

Result: 实验结果显示，不同模型在DeR2上的表现差异显著。部分模型存在模式切换脆弱性，在“全集”模式下的表现不如“仅指令”模式；另一些模型则出现结构性概念滥用，能够识别概念但无法正确执行。

Conclusion: 大型语言模型在处理全新科学信息时的真实推理能力仍有很大提升空间。DeR2提供了一种有效的方法来诊断模型在推理过程中遇到的具体问题，例如检索损失和推理损失，从而指导模型改进。

Abstract: Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.

</details>


### [94] [ToolWeaver: Weaving Collaborative Semantics for Scalable Tool Use in Large Language Models](https://arxiv.org/abs/2601.21947)
*Bowen Fang,Wen Ye,Yunyue Su,Jinghao Zhang,Qiang Liu,Yesheng Liu,Xin Sun,Shu Wu,Jiabing Yang,Baole Wei,Liang Wang*

Main category: cs.AI

TL;DR: 该研究提出了一种名为 ToolWeaver 的生成式工具学习框架，通过将工具编码为分层序列来解决现有工具使用管道在语义理解和可扩展性方面存在的挑战，从而显著提升了工具学习的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的检索式工具使用方法在捕捉复杂语义和LLM内在工具知识方面存在不足。生成式方法虽然能统一选择和执行，但将每个工具映射到独立新词元会造成词汇量爆炸、泛化困难以及学习工具间协作关系的语义瓶颈。

Method: 提出 ToolWeaver 框架，将工具编码为分层序列，通过一种新的分词过程将工具的内在语义和外在共现模式结合，形成结构化代码。然后通过生成式对齐阶段，对LLM进行微调以生成这些分层代码序列。

Result: 在近47,000个工具的实验中，ToolWeaver 显著优于现有最先进的方法，在可扩展性、泛化性和语义感知能力方面建立了更坚实的基础。

Conclusion: ToolWeaver 通过将工具编码为分层序列，有效解决了现有方法的局限性，为构建更高级的工具增强型代理提供了一种更具可扩展性、泛化性和语义意识的解决方案。

Abstract: Prevalent retrieval-based tool-use pipelines struggle with a dual semantic challenge: their retrievers often employ encoders that fail to capture complex semantics, while the Large Language Model (LLM) itself lacks intrinsic tool knowledge from its natural language pretraining. Generative methods offer a powerful alternative by unifying selection and execution, tasking the LLM to directly learn and generate tool identifiers. However, the common practice of mapping each tool to a unique new token introduces substantial limitations: it creates a scalability and generalization crisis, as the vocabulary size explodes and each tool is assigned a semantically isolated token. This approach also creates a semantic bottleneck that hinders the learning of collaborative tool relationships, as the model must infer them from sparse co-occurrences of monolithic tool IDs within a vast library. To address these limitations, we propose ToolWeaver, a novel generative tool learning framework that encodes tools into hierarchical sequences. This approach makes vocabulary expansion logarithmic to the number of tools. Crucially, it enables the model to learn collaborative patterns from the dense co-occurrence of shared codes, rather than the sparse co-occurrence of monolithic tool IDs. We generate these structured codes through a novel tokenization process designed to weave together a tool's intrinsic semantics with its extrinsic co-usage patterns. These structured codes are then integrated into the LLM through a generative alignment stage, where the model is fine-tuned to produce the hierarchical code sequences. Evaluation results with nearly 47,000 tools show that ToolWeaver significantly outperforms state-of-the-art methods, establishing a more scalable, generalizable, and semantically-aware foundation for advanced tool-augmented agents.

</details>


### [95] [How do Visual Attributes Influence Web Agents? A Comprehensive Evaluation of User Interface Design Factors](https://arxiv.org/abs/2601.21961)
*Kuai Yu,Naicheng Yu,Han Wang,Rui Yang,Huan Zhang*

Main category: cs.AI

TL;DR: 本文提出了VAF评估框架，用于量化网页视觉属性对Web Agent决策的影响。研究发现，背景颜色对比度、商品大小、位置和卡片清晰度等视觉因素对Agent的行为有显著影响。


<details>
  <summary>Details</summary>
Motivation: 现有Web Agent研究主要关注对抗性鲁棒性，对良性场景下的Agent偏好关注不足。尽管文本属性对Agent行为的影响已有研究，但视觉属性如何影响Agent决策的系统性理解仍然有限。

Method: VAF框架包含三个阶段：1. 变体生成，确保语义不变，仅改变视觉属性；2. 浏览交互，模拟人类用户滚动和点击行为；3. 验证，通过目标点击率和目标提及率评估视觉属性的影响。

Result: 在8个变体家族、5个真实网站和4个代表性Web Agent上的实验表明，背景颜色对比度、商品大小、位置和卡片清晰度对Agent的行为有显著影响，而字体样式、文本颜色和图像清晰度的影响较小。

Conclusion: VAF框架能够有效量化视觉属性对Web Agent决策的影响，并识别出关键的视觉影响因素，为Agent的设计和优化提供了依据。

Abstract: Web agents have demonstrated strong performance on a wide range of web-based tasks. However, existing research on the effect of environmental variation has mostly focused on robustness to adversarial attacks, with less attention to agents' preferences in benign scenarios. Although early studies have examined how textual attributes influence agent behavior, a systematic understanding of how visual attributes shape agent decision-making remains limited. To address this, we introduce VAF, a controlled evaluation pipeline for quantifying how webpage Visual Attribute Factors influence web-agent decision-making. Specifically, VAF consists of three stages: (i) variant generation, which ensures the variants share identical semantics as the original item while only differ in visual attributes; (ii) browsing interaction, where agents navigate the page via scrolling and clicking the interested item, mirroring how human users browse online; (iii) validating through both click action and reasoning from agents, which we use the Target Click Rate and Target Mention Rate to jointly evaluate the effect of visual attributes. By quantitatively measuring the decision-making difference between the original and variant, we identify which visual attributes influence agents' behavior most. Extensive experiments, across 8 variant families (48 variants total), 5 real-world websites (including shopping, travel, and news browsing), and 4 representative web agents, show that background color contrast, item size, position, and card clarity have a strong influence on agents' actions, whereas font styling, text color, and item image clarity exhibit minor effects.

</details>


### [96] [The Energy Impact of Domain Model Design in Classical Planning](https://arxiv.org/abs/2601.21967)
*Ilche Georgievski,Serhat Tekin,Marco Aiello*

Main category: cs.AI

TL;DR: 本文研究了领域模型特性如何影响经典规划器的能耗。研究发现，领域模型的设计（如元素排序、动作元数和死端状态）可以显著影响能耗，且能耗与运行时间不一定相关。


<details>
  <summary>Details</summary>
Motivation: 尽管自动规划计算需求高，但其能效却鲜少受到关注。鉴于规划的模块化结构，领域模型设计可以用来系统地分析能耗，因此填补这一研究空白具有重要意义。

Method: 作者提出了一个领域模型配置框架，能够控制性地改变领域模型的特征，如元素排序、动作元数和死端状态。他们使用五个基准领域和五个最先进的规划器，对32个领域变体进行了能耗和运行时间分析。

Result: 研究结果表明，领域模型层面的修改对不同规划器的能耗产生了可衡量的差异。此外，能耗与运行时间之间并非总是正相关。

Conclusion: 领域模型的设计是影响规划器能耗的重要因素，并且这种影响可以通过对领域模型的系统性分析和调整来利用，以实现更节能的规划。

Abstract: AI research has traditionally prioritised algorithmic performance, such as optimising accuracy in machine learning or runtime in automated planning. The emerging paradigm of Green AI challenges this by recognising energy consumption as a critical performance dimension. Despite the high computational demands of automated planning, its energy efficiency has received little attention. This gap is particularly salient given the modular planning structure, in which domain models are specified independently of algorithms. On the other hand, this separation also enables systematic analysis of energy usage through domain model design. We empirically investigate how domain model characteristics affect the energy consumption of classical planners. We introduce a domain model configuration framework that enables controlled variation of features, such as element ordering, action arity, and dead-end states. Using five benchmark domains and five state-of-the-art planners, we analyse energy and runtime impacts across 32 domain variants per benchmark. Results demonstrate that domain-level modifications produce measurable energy differences across planners, with energy consumption not always correlating with runtime.

</details>


### [97] [VERSA: Verified Event Data Format for Reliable Soccer Analytics](https://arxiv.org/abs/2601.21981)
*Geonhee Jo,Mingu Kang,Kangmin Lee,Minho Lee,Pascal Bauer,Sang-Ki Ko*

Main category: cs.AI

TL;DR: 本文提出了一个名为VERSA的事件流数据验证框架，用于足球比赛数据，以解决数据质量问题，并展示了其能显著提高数据一致性、鲁棒性和下游分析任务（如评估球员贡献）的性能。


<details>
  <summary>Details</summary>
Motivation: 事件流数据在体育等领域有重要应用，但数据质量问题（如事件顺序错误、事件缺失）严重影响分析模型的可靠性。

Method: 提出VERSA（Verified Event Data Format for Reliable Soccer Analytics）框架，基于状态转移模型定义有效的事件序列，从而自动检测和纠正异常模式。在K联赛1（2024赛季）数据上进行了实验。

Result: 在K联赛1的数据中，检测到18.81%的事件存在逻辑不一致。VERSA能显著提高跨提供商数据的一致性，并稳定统一数据表示。经VERSA处理后的数据显著提高了下游任务VAEP（评估球员贡献）的鲁棒性和性能。

Conclusion: 数据验证过程对于提高数据驱动分析的可靠性非常有效，VERSA框架能够解决足球事件流数据中的不一致性问题，从而提升分析结果的质量。

Abstract: Event stream data is a critical resource for fine-grained analysis across various domains, including financial transactions, system operations, and sports. In sports, it is actively used for fine-grained analyses such as quantifying player contributions and identifying tactical patterns. However, the reliability of these models is fundamentally limited by inherent data quality issues that cause logical inconsistencies (e.g., incorrect event ordering or missing events). To this end, this study proposes VERSA (Verified Event Data Format for Reliable Soccer Analytics), a systematic verification framework that ensures the integrity of event stream data within the soccer domain. VERSA is based on a state-transition model that defines valid event sequences, thereby enabling the automatic detection and correction of anomalous patterns within the event stream data. Notably, our examination of event data from the K League 1 (2024 season), provided by Bepro, detected that 18.81% of all recorded events exhibited logical inconsistencies. Addressing such integrity issues, our experiments demonstrate that VERSA significantly enhances cross-provider consistency, ensuring stable and unified data representation across heterogeneous sources. Furthermore, we demonstrate that data refined by VERSA significantly improves the robustness and performance of a downstream task called VAEP, which evaluates player contributions. These results highlight that the verification process is highly effective in increasing the reliability of data-driven analysis.

</details>


### [98] [Heterogeneous Computing: The Key to Powering the Future of AI Agent Inference](https://arxiv.org/abs/2601.22001)
*Yiren Zhao,Junyi Liu*

Main category: cs.AI

TL;DR: 本文提出运营强度（OI）和容量足迹（CF）两个新指标，用于分析AI推理中的内存容量、带宽和互连瓶颈，尤其关注长上下文KV缓存对解码的影响。研究结果表明，AI推理工作负载的OI/CF变化剧烈，这促使了对解耦服务、异构系统、光I/O、多推理加速器以及内存解耦的设想，以支持未来大规模AI推理的效率和能力。


<details>
  <summary>Details</summary>
Motivation: AI智能体推理对数据中心提出了新的挑战，暴露了除了计算之外的内存容量、内存带宽和高速互连等瓶颈。现有分析方法（如经典roofline模型）无法完全解释这些瓶颈。

Method: 提出两个新指标：运营强度（OI）和容量足迹（CF），用于分析AI智能体工作负载（如聊天、编码、网页浏览、计算机使用）和不同模型（GQA/MLA、MoE、量化）下的性能表现。特别关注长上下文KV缓存对解码的影响。

Result: 在不同的AI智能体工作负载和模型选择下，OI/CF表现出显著的变化。长上下文KV缓存使得解码过程对内存的依赖性增强，成为内存瓶颈。这支持了对解耦服务和系统异构化的需求，包括专门的预填充和解码加速器、更广泛规模的网络以及通过光I/O实现计算-内存解耦。

Conclusion: OI/CF指标能够揭示经典分析方法忽略的性能限制。为了应对大规模AI推理的效率和能力挑战，需要探索AI硬件协同设计、同一系统内集成多个推理加速器以及支持内存解耦等方向，特别是利用高带宽、大容量内存解耦和光I/O技术。

Abstract: AI agent inference is driving an inference heavy datacenter future and exposes bottlenecks beyond compute - especially memory capacity, memory bandwidth and high-speed interconnect. We introduce two metrics - Operational Intensity (OI) and Capacity Footprint (CF) - that jointly explain regimes the classic roofline analysis misses, including the memory capacity wall. Across agentic workflows (chat, coding, web use, computer use) and base model choices (GQA/MLA, MoE, quantization), OI/CF can shift dramatically, with long context KV cache making decode highly memory bound. These observations motivate disaggregated serving and system level heterogeneity: specialized prefill and decode accelerators, broader scale up networking, and decoupled compute-memory enabled by optical I/O. We further hypothesize agent-hardware co design, multiple inference accelerators within one system, and high bandwidth, large capacity memory disaggregation as foundations for adaptation to evolving OI/CF. Together, these directions chart a path to sustain efficiency and capability for large scale agentic AI inference.

</details>


### [99] [Routing the Lottery: Adaptive Subnetworks for Heterogeneous Data](https://arxiv.org/abs/2601.22141)
*Grzegorz Stefanski,Alberto Presta,Michal Byra*

Main category: cs.AI

TL;DR: 提出了一种名为RTL（Routing the Lottery）的自适应剪枝框架，用于发现针对不同数据类别或集群的“自适应票据”（specialized subnetworks），以解决传统“彩票假说”只关注单一通用子网络的问题，并在多个数据集和任务上取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的“彩票假说”研究大多假设存在一个单一的、普遍适用的“赢票”（winning ticket），而忽略了真实世界数据本身的多样性和异质性。本文旨在克服这一局限，提出一种能够适应数据异质性的剪枝方法。

Method: 提出了一种名为Routing the Lottery (RTL) 的自适应剪枝框架，该框架能够发现多个专门化的子网络（称为“自适应票据”），每个子网络针对特定的类别、语义集群或环境条件进行优化。此外，还引入了“子网络相似度得分”（subnetwork similarity score）来诊断过度稀疏化导致的性能下降（子网络坍塌）。

Result: 在多个数据集和任务上，RTL在平衡准确率和召回率方面始终优于单一模型和多模型基线。与独立模型相比，RTL使用的参数减少了10倍，并且发现的子网络具有语义对齐性。研究还识别了“子网络坍塌”现象。

Conclusion: 研究结果表明，剪枝可以作为一种将模型结构与数据异质性对齐的机制，为构建更模块化、更具上下文感知能力的深度学习模型指明了方向。

Abstract: In pruning, the Lottery Ticket Hypothesis posits that large networks contain sparse subnetworks, or winning tickets, that can be trained in isolation to match the performance of their dense counterparts. However, most existing approaches assume a single universal winning ticket shared across all inputs, ignoring the inherent heterogeneity of real-world data. In this work, we propose Routing the Lottery (RTL), an adaptive pruning framework that discovers multiple specialized subnetworks, called adaptive tickets, each tailored to a class, semantic cluster, or environmental condition. Across diverse datasets and tasks, RTL consistently outperforms single- and multi-model baselines in balanced accuracy and recall, while using up to 10 times fewer parameters than independent models and exhibiting semantically aligned. Furthermore, we identify subnetwork collapse, a performance drop under aggressive pruning, and introduce a subnetwork similarity score that enables label-free diagnosis of oversparsification. Overall, our results recast pruning as a mechanism for aligning model structure with data heterogeneity, paving the way toward more modular and context-aware deep learning.

</details>


### [100] [Mind the Gap: How Elicitation Protocols Shape the Stated-Revealed Preference Gap in Language Models](https://arxiv.org/abs/2601.21975)
*Pranav Mahajan,Ihor Kendiukhov,Syed Hussain,Lydia Nottingham*

Main category: cs.AI

TL;DR: 研究表明，语言模型在声称偏好和实际选择之间存在不匹配（SvR 差距）。现有的评估方法（如二元强制选择提示）会混淆真实偏好和协议产物。通过允许中立和弃权选项，可以提高声称偏好和强制选择揭示偏好之间的相关性，但如果在揭示偏好中也允许弃权，则会导致相关性急剧下降。此外，使用声称偏好进行系统提示引导，并不能可靠地提高在AIRiskDilemmas数据集上的 SvR 相关性。因此，SvR 相关性高度依赖于评估协议，并且需要考虑不确定偏好的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的评估语言模型（LM）声称-揭示（SvR）偏好差距的方法（如二元强制选择提示）存在局限性，会将真实偏好与评估协议的固有缺陷混淆。研究旨在系统地探究不同的评估协议如何影响 SvR 相关性。

Method: 研究者系统地评估了24种语言模型，通过改变声称偏好和揭示偏好时的协议设计，特别是引入中立和弃权选项。他们分析了这些改变对 Spearman 秩相关系数（ρ）的影响，并测试了使用声称偏好进行系统提示引导在揭示偏好评估中的效果。

Result: 允许在声称偏好时选择中立和弃权，可以显著提高声称偏好与强制选择揭示偏好之间的 Spearman 秩相关性。然而，如果在揭示偏好阶段也允许弃权，则会导致相关性接近于零或变为负值。使用声称偏好进行系统提示引导，在 AIRiskDilemmas 数据集上并未可靠地提高 SvR 相关性。

Conclusion: 语言模型的 SvR 相关性高度依赖于评估协议的设计。在声称偏好阶段允许中立和弃权选项有助于更准确地衡量真实偏好，但需要在揭示偏好阶段谨慎处理弃权选项。此外，简单的系统提示引导并不能有效解决 SvR 差距问题。未来的 SvR 评估需要开发能够有效处理不确定偏好的方法。

Abstract: Recent work identifies a stated-revealed (SvR) preference gap in language models (LMs): a mismatch between the values models endorse and the choices they make in context. Existing evaluations rely heavily on binary forced-choice prompting, which entangles genuine preferences with artifacts of the elicitation protocol. We systematically study how elicitation protocols affect SvR correlation across 24 LMs. Allowing neutrality and abstention during stated preference elicitation allows us to exclude weak signals, substantially improving Spearman's rank correlation ($ρ$) between volunteered stated preferences and forced-choice revealed preferences. However, further allowing abstention in revealed preferences drives $ρ$ to near-zero or negative values due to high neutrality rates. Finally, we find that system prompt steering using stated preferences during revealed preference elicitation does not reliably improve SvR correlation on AIRiskDilemmas. Together, our results show that SvR correlation is highly protocol-dependent and that preference elicitation requires methods that account for indeterminate preferences.

</details>


### [101] [CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty](https://arxiv.org/abs/2601.22027)
*Johannes Kirmayr,Lukas Stappen,Elisabeth André*

Main category: cs.AI

TL;DR: CAR-bench 是一个评估 LLM 代理在真实车载助手场景下的可靠性基准，侧重于处理不确定性、一致性和能力意识，并发现现有模型在这方面的表现存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 代理基准过于理想化，未能评估代理在真实世界、用户面临的不确定性请求（如不完整或模糊的指令）下的可靠性，特别是在车载助手等领域。

Method: 引入 CAR-bench 基准，模拟用户、领域策略和58个互联工具（导航、生产力、充电、车辆控制）。包含标准任务完成、Hallucination 任务（测试在信息缺失时的界限意识）和 Disambiguation 任务（通过澄清或内部信息收集解决不确定性）。

Result: 在 CAR-bench 上，即使是顶尖的 LLM，在 Disambiguation 任务上的一致成功率也低于 50%，经常出现过早行动。在 Hallucination 任务中，它们也常常违反策略或捏造信息以满足用户请求。

Conclusion: 现有 LLM 代理在处理真实世界中的不确定性、遵循策略和意识到自身能力方面存在显著不足，需要开发更可靠、更具自我意识的 LLM 代理。

Abstract: Existing benchmarks for Large Language Model (LLM) agents focus on task completion under idealistic settings but overlook reliability in real-world, user-facing applications. In domains, such as in-car voice assistants, users often issue incomplete or ambiguous requests, creating intrinsic uncertainty that agents must manage through dialogue, tool use, and policy adherence. We introduce CAR-bench, a benchmark for evaluating consistency, uncertainty handling, and capability awareness in multi-turn, tool-using LLM agents in an in-car assistant domain. The environment features an LLM-simulated user, domain policies, and 58 interconnected tools spanning navigation, productivity, charging, and vehicle control. Beyond standard task completion, CAR-bench introduces Hallucination tasks that test agents' limit-awareness under missing tools or information, and Disambiguation tasks that require resolving uncertainty through clarification or internal information gathering. Baseline results reveal large gaps between occasional and consistent success on all task types. Even frontier reasoning LLMs achieve less than 50% consistent pass rate on Disambiguation tasks due to premature actions, and frequently violate policies or fabricate information to satisfy user requests in Hallucination tasks, underscoring the need for more reliable and self-aware LLM agents in real-world settings.

</details>


### [102] [The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR](https://arxiv.org/abs/2601.22128)
*Irsyad Adam,Zekai Chen,David Laprade,Shaun Porwal,David Laub,Erik Reinertsen,Arda Pekis,Kevin Brown*

Main category: cs.AI

TL;DR: 本文提出了一种名为SMB-Structure的新型模型，用于模拟结构化电子健康记录（EHR）中的患者动态。该模型结合了联合嵌入预测架构（JEPA）和监督微调（SFT），旨在捕捉患者病程的演变，而非仅预测下一个词。实验结果表明，SMB-Structure在处理具有高度异质性的患者数据方面优于传统的自回归基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于大规模语言模型（LLMs）的临床模型主要采用下一个词预测范式，虽然在下游任务中表现良好，但将患者视为文档而非动态系统，无法捕捉患者病程的演变。因此，研究的动机是开发能够模拟患者动态演变的模型。

Method: 本文提出了SMB-Structure，一个结合了自监督学习（SFT）和联合嵌入预测架构（JEPA）的世界模型。SFT用于在词汇空间中重建未来的患者状态，而JEPA则在潜在空间中从初始患者表示预测未来状态，迫使模型在观察到下一个状态之前就编码轨迹动态。模型在两个大规模数据集（Memorial Sloan Kettering和INSPECT）上进行了验证。

Result: SMB-Structure在两个大型队列上进行了验证，并使用线性探针在疾病轨迹的不同时间点进行了评估。结果表明，SMB-Structure训练出的嵌入能够捕捉到自回归基线模型无法恢复的疾病动态，并在具有高患者异质性的复杂任务上实现了具有竞争力的性能。

Conclusion: SMB-Structure通过结合JEPA和SFT，能够有效地模拟结构化EHR中的患者动态，并在捕捉疾病演变方面优于传统的自回归模型，为处理异质性患者数据提供了新的方法。

Abstract: Large language models (LLMs) trained with next-word-prediction have achieved success as clinical foundation models. Representations from these language backbones yield strong linear probe performance across biomedical tasks, suggesting that patient semantics emerge from next-token prediction at scale. However, this paradigm treats patients as a document to be summarized rather than a dynamical system to be simulated; a patient's trajectory emerges from their state evolving under interventions and time, requiring models that simulate dynamics rather than predict tokens. To address this, we introduce SMB-Structure, a world model for structured EHR that grounds a joint-embedding prediction architecture (JEPA) with next-token prediction (SFT). SFT grounds our model to reconstruct future patient states in token space, while JEPA predicts those futures in latent space from the initial patient representation alone, forcing trajectory dynamics to be encoded before the next state is observed. We validate across two large-scale cohorts: Memorial Sloan Kettering (23,319 oncology patients; 323,000+ patient-years) and INSPECT (19,402 pulmonary embolism patients). Using a linear probe evaluated at multiple points along the disease trajectory, we demonstrate that our training paradigm learns embeddings that capture disease dynamics not recoverable by autoregressive baselines, enabling SMB-Structure to achieve competitive performance on complex tasks characterized by high patient heterogeneity. Model weights are available at https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure.

</details>


### [103] [Optimizing Agentic Workflows using Meta-tools](https://arxiv.org/abs/2601.22037)
*Sami Abuzakuk,Anne-Marie Kermarrec,Rishi Sharma,Rasmus Moorits Veski,Martijn de Vos*

Main category: cs.AI

TL;DR: 本文提出了一种名为AWO（Agent Workflow Optimization）的框架，通过识别和优化重复的工具调用模式，将多个代理动作打包成“元工具”，从而减少LLM调用次数，降低运营成本，并提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的agentic AI工作流在处理复杂任务时，由于频繁的迭代推理和工具调用，会导致高昂的运营成本、延迟以及因幻觉导致的失败。需要一种方法来提高其效率和鲁棒性。

Method: AWO框架分析现有的工作流轨迹，发现重复的工具调用序列，并将其转化为“元工具”。元工具是将多个代理动作合并成一个单一调用的确定性复合工具，绕过中间的LLM推理步骤。

Result: 在两个agentic AI基准测试中，AWO将LLM调用次数最多减少了11.9%，并将任务成功率提高了4.2个百分点。

Conclusion: AWO框架能够有效地优化agentic AI工作流，通过引入元工具来减少LLM调用，降低成本，并提高任务的成功率和效率。

Abstract: Agentic AI enables LLM to dynamically reason, plan, and interact with tools to solve complex tasks. However, agentic workflows often require many iterative reasoning steps and tool invocations, leading to significant operational expense, end-to-end latency and failures due to hallucinations. This work introduces Agent Workflow Optimization (AWO), a framework that identifies and optimizes redundant tool execution patterns to improve the efficiency and robustness of agentic workflows. AWO analyzes existing workflow traces to discover recurring sequences of tool calls and transforms them into meta-tools, which are deterministic, composite tools that bundle multiple agent actions into a single invocation. Meta-tools bypass unnecessary intermediate LLM reasoning steps and reduce operational cost while also shortening execution paths, leading to fewer failures. Experiments on two agentic AI benchmarks show that AWO reduces the number of LLM calls up to 11.9% while also increasing the task success rate by up to 4.2 percent points.

</details>


### [104] [Defining Operational Conditions for Safety-Critical AI-Based Systems from Data](https://arxiv.org/abs/2601.22118)
*Johann Christensen,Elena Hoemann,Frank Köster,Sven Hallerbach*

Main category: cs.AI

TL;DR: 该论文提出了一种新的安全设计方法，利用多维核表示从现有数据中后验地定义人工智能系统的运行设计域（ODD），以满足安全关键应用的认证需求。


<details>
  <summary>Details</summary>
Motivation: 在许多安全关键应用领域，为复杂现实世界的AI系统定义准确的运行设计域（ODD）面临巨大挑战，这阻碍了AI系统的认证。现有ODD定义方法依赖于早期专家知识，对于已存在数据的情况不够灵活。

Method: 提出了一种安全设计方法，利用多维核表示，从已收集的数据中后验地定义ODD。该方法通过蒙特卡罗方法和实际航空用例进行验证。

Result: 该数据驱动的ODD方法能够被证明等于数据潜在的隐藏ODD。该方法成功应用于一个未来安全关键的防撞系统。

Conclusion: 提出的安全设计方法能够从数据中定义ODD，为数据驱动的安全关键AI系统提供认证的可能性，解决了复杂环境中ODD定义的难题。

Abstract: Artificial Intelligence (AI) has been on the rise in many domains, including numerous safety-critical applications. However, for complex systems found in the real world, or when data already exist, defining the underlying environmental conditions is extremely challenging. This often results in an incomplete description of the environment in which the AI-based system must operate. Nevertheless, this description, called the Operational Design Domain (ODD), is required in many domains for the certification of AI-based systems. Traditionally, the ODD is created in the early stages of the development process, drawing on sophisticated expert knowledge and related standards. This paper presents a novel Safety-by-Design method to a posteriori define the ODD from previously collected data using a multi-dimensional kernel-based representation. This approach is validated through both Monte Carlo methods and a real-world aviation use case for a future safety-critical collision-avoidance system. Moreover, by defining under what conditions two ODDs are equal, the paper shows that the data-driven ODD can equal the original, underlying hidden ODD of the data. Utilizing the novel, Safe-by-Design kernel-based ODD enables future certification of data-driven, safety-critical AI-based systems.

</details>


### [105] [Liquid Interfaces: A Dynamic Ontology for the Interoperability of Autonomous Systems](https://arxiv.org/abs/2601.21993)
*Dhiogo de Sá,Carlos Schmiedel,Carlos Pereira Lopes*

Main category: cs.AI

TL;DR: 提出了一种名为“液体接口”的协调范式，它通过运行时意图表达和语义协商来动态生成接口，从而支持自适应、概率性和情境依赖的自主代理。该范式通过液体接口协议（LIP）进行形式化，并讨论了其治理和架构实现。


<details>
  <summary>Details</summary>
Motivation: 当前软件架构难以支持具有自适应、概率性和情境依赖性推理的自主代理，而系统集成仍依赖于静态接口和确定性契约。

Method: 引入“液体接口”协调范式，将其形式化并提出液体接口协议（LIP）。LIP 规定了意图驱动的交互、协商执行和在语义不确定性下的短暂性。还讨论了治理和参考架构。

Result: 液体接口是一种协调范式，其中接口是运行时动态产生的事件，而不是静态的工件。LIP 规范了这些交互，并考虑了语义不确定性。

Conclusion: 液体接口为代理系统中的自适应协调提供了一个原则性的基础，克服了现有架构在支持复杂自主代理方面的局限性。

Abstract: Contemporary software architectures struggle to support autonomous agents whose reasoning is adaptive, probabilistic, and context-dependent, while system integration remains dominated by static interfaces and deterministic contracts. This paper introduces Liquid Interfaces, a coordination paradigm in which interfaces are not persistent technical artifacts, but ephemeral relational events that emerge through intention articulation and semantic negotiation at runtime.We formalize this model and present the Liquid Interface Protocol (LIP),which governs intention-driven interaction, negotiated execution, and enforce ephemerality under semantic uncertainty. We further discuss the governance implications of this approach and describe a reference architecture that demonstrates practical feasibility. Liquid Interfaces provide a principled foundation for adaptive coordination in agent-based systems

</details>


### [106] [Learning Decentralized LLM Collaboration with Multi-Agent Actor Critic](https://arxiv.org/abs/2601.21972)
*Shuo Liu,Tianle Chen,Ryan Amiri,Christopher Amato*

Main category: cs.AI

TL;DR: 本文提出了两种多智能体演员-评论家（MAAC）方法，CoLLM-CC（中心化评论家）和CoLLM-DC（去中心化评论家），用于优化去中心化的大型语言模型（LLM）协作。实验表明，在短时间范围内和密集奖励的环境下，CoLLM-DC和蒙特卡洛方法可以与CoLLM-CC媲美，但在长时间范围或稀疏奖励的任务中，CoLLM-DC和蒙特卡洛方法均表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习（MARL）微调方法通常依赖于预定义的、通常是中心化的执行协议。然而，去中心化LLM协作在实际应用中更具吸引力，因为它可以实现并行推理和灵活部署。此外，现有的蒙特卡洛方法在微调时方差较高，需要更多样本，因此研究动机是探索更有效的去中心化LLM协作优化方法，特别是Actor-Critic方法。

Method: 本文提出了两种基于Actor-Critic的多智能体方法来优化去中心化LLM协作：CoLLM-CC（中心化评论家）和CoLLM-DC（去中心化评论家）。通过在写作、编码和游戏等领域进行实验，对比了这些方法与蒙特卡洛方法的性能。

Result: 实验结果显示，在短时间范围和密集奖励的环境下，蒙特卡洛方法和CoLLM-DC可以达到与CoLLM-CC相当的性能。然而，在长远范围或稀疏奖励的任务中，CoLLM-CC表现最佳，而蒙特卡洛方法需要显著更多的样本，CoLLM-DC则难以收敛。

Conclusion: MAAC方法，特别是CoLLM-CC，在处理长远范围或稀疏奖励的LLM协作任务时比蒙特卡洛方法更有效。CoLLM-DC在这些复杂任务中存在收敛性问题，而蒙特卡洛方法则需要大量样本。这表明在设计LLM协作系统时，需要根据任务的复杂性和奖励结构选择合适的MARL方法。

Abstract: Recent work has explored optimizing LLM collaboration through Multi-Agent Reinforcement Learning (MARL). However, most MARL fine-tuning approaches rely on predefined execution protocols, which often require centralized execution. Decentralized LLM collaboration is more appealing in practice, as agents can run inference in parallel with flexible deployments. Also, current approaches use Monte Carlo methods for fine-tuning, which suffer from high variance and thus require more samples to train effectively. Actor-critic methods are prevalent in MARL for dealing with these issues, so we developed Multi-Agent Actor-Critic (MAAC) methods to optimize decentralized LLM collaboration. In this paper, we analyze when and why these MAAC methods are beneficial. We propose 2 MAAC approaches, \textbf{CoLLM-CC} with a \textbf{C}entralized \textbf{C}ritic and \textbf{CoLLM-DC} with \textbf{D}ecentralized \textbf{C}ritics. Our experiments across writing, coding, and game-playing domains show that Monte Carlo methods and CoLLM-DC can achieve performance comparable to CoLLM-CC in short-horizon and dense-reward settings. However, they both underperform CoLLM-CC on long-horizon or sparse-reward tasks, where Monte Carlo methods require substantially more samples and CoLLM-DC struggles to converge. Our code is available at https://github.com/OpenMLRL/CoMLRL/releases/tag/v1.3.2.

</details>


### [107] [World of Workflows: a Benchmark for Bringing World Models to Enterprise Systems](https://arxiv.org/abs/2601.22130)
*Lakshya Gupta,Litao Li,Yizhe Liu,Sriram Ganapathi Subramanian,Kaheer Suleman,Zichen Zhang,Haoye Lu,Sumit Pasupalak*

Main category: cs.AI

TL;DR: 研究提出了一个名为 WoW 的基于 ServiceNow 的环境和 WoW-bench 基准测试，用于评估大型语言模型（LLMs）在复杂企业系统中的表现。结果表明，当前的 LLMs 存在“动力学盲区”，无法预测其行为的隐藏级联效应，并且在不透明系统中，可靠性需要基于世界模型的模拟来弥合观察差距。


<details>
  <summary>Details</summary>
Motivation: 现有企业基准测试未能充分评估 LLMs 在复杂企业系统中的自主代理能力，这些系统具有隐藏的工作流程、级联效应、有限的可观察性以及大型数据库状态，而这正是企业环境面临的真实挑战。

Method: 引入了一个名为 World of Workflows (WoW) 的现实 ServiceNow 环境，其中包含 4000 多个业务规则和 55 个活跃工作流程。同时提出了 WoW-bench 基准测试，包含 234 个任务，用于评估受限的代理任务完成能力和企业动态建模能力。

Result: 研究发现，前沿 LLMs 存在“动力学盲区”，无法预测其行为带来的隐性级联副作用，导致静默的约束违规。同时，在不透明系统中，可靠性需要基于世界模型的模拟，以便在缺乏高保真反馈时弥合观察差距。

Conclusion: 为实现可靠且有用的企业代理，WoW 促成了一种新的范式，即显式学习系统动态，以克服 LLMs 在复杂企业系统中的局限性。

Abstract: Frontier large language models (LLMs) excel as autonomous agents in many domains, yet they remain untested in complex enterprise systems where hidden workflows create cascading effects across interconnected databases. Existing enterprise benchmarks evaluate surface-level agentic task completion similar to general consumer benchmarks, ignoring true challenges in enterprises, such as limited observability, large database state, and hidden workflows with cascading side effects. We introduce World of Workflows (WoW), a realistic ServiceNow-based environment incorporating 4,000+ business rules and 55 active workflows embedded in the system, alongside WoW-bench, a benchmark of 234 tasks evaluating constrained agentic task completion and enterprise dynamics modeling capabilities. We reveal two major takeaways: (1) Frontier LLMs suffer from dynamics blindness, consistently failing to predict the invisible, cascading side effects of their actions, which leads to silent constraint violations, and (2) reliability in opaque systems requires grounded world modeling, where agents must mentally simulate hidden state transitions to bridge the observability gap when high-fidelity feedback is unavailable. For reliable and useful enterprise agents, WoW motivates a new paradigm to explicitly learn system dynamics. We release our GitHub for setting up and evaluating WoW.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [108] [MA-LipNet: Multi-Dimensional Attention Networks for Robust Lipreading](https://arxiv.org/abs/2601.20881)
*Matteo Rossi*

Main category: cs.CV

TL;DR: 本文提出了一种名为MA-LipNet的多注意力唇语识别网络，通过多维度（通道、联合时空、分离时空）的注意力机制来优化视觉特征，以提高唇语识别的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有唇语识别方法因发音动作的细微性，在特征判别能力和泛化能力上存在不足，尤其在公共安全等领域的应用价值受到限制。

Method: 提出MA-LipNet网络，核心是顺序应用三个注意力模块：1. 通道注意力（CA）模块，用于重新校准通道特征，减少无效信息干扰；2. 联合时空注意力（JSTA）模块，进行粗粒度过滤，抑制无关像素和帧的影响；3. 分离时空注意力（SSTA）模块，进行细粒度精炼，分别建模时空注意力。

Result: 在CMLR和GRID数据集上的实验表明，MA-LipNet显著降低了字符错误率（CER）和词错误率（WER），优于现有先进方法。

Conclusion: 多维度特征的精炼对于鲁棒的视觉语音识别至关重要，MA-LipNet通过多注意力机制有效提升了唇语识别的性能。

Abstract: Lipreading, the technology of decoding spoken content from silent videos of lip movements, holds significant application value in fields such as public security. However, due to the subtle nature of articulatory gestures, existing lipreading methods often suffer from limited feature discriminability and poor generalization capabilities. To address these challenges, this paper delves into the purification of visual features from temporal, spatial, and channel dimensions. We propose a novel method named Multi-Attention Lipreading Network(MA-LipNet). The core of MA-LipNet lies in its sequential application of three dedicated attention modules. Firstly, a \textit{Channel Attention (CA)} module is employed to adaptively recalibrate channel-wise features, thereby mitigating interference from less informative channels. Subsequently, two spatio-temporal attention modules with distinct granularities-\textit{Joint Spatial-Temporal Attention (JSTA)} and \textit{Separate Spatial-Temporal Attention (SSTA)}-are leveraged to suppress the influence of irrelevant pixels and video frames. The JSTA module performs a coarse-grained filtering by computing a unified weight map across the spatio-temporal dimensions, while the SSTA module conducts a more fine-grained refinement by separately modeling temporal and spatial attentions. Extensive experiments conducted on the CMLR and GRID datasets demonstrate that MA-LipNet significantly reduces the Character Error Rate (CER) and Word Error Rate (WER), validating its effectiveness and superiority over several state-of-the-art methods. Our work highlights the importance of multi-dimensional feature refinement for robust visual speech recognition.

</details>


### [109] [Non-Markov Multi-Round Conversational Image Generation with History-Conditioned MLLMs](https://arxiv.org/abs/2601.20911)
*Haochen Zhang,Animesh Sinha,Felix Juefei-Xu,Haoyu Ma,Kunpeng Li,Zhipeng Fan,Meng Dong,Xiaoliang Dai,Tingbo Hou,Peizhao Zhang,Zecheng He*

Main category: cs.CV

TL;DR: 本文提出了一个用于多轮对话式图像生成的新框架，解决了现有模型忽略长历史对话的问题，通过构建非马尔可夫数据集、历史条件训练和推理框架以及多阶段微调，显著提高了模型在多轮对话中的一致性和指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多轮对话式图像生成模型在处理长历史对话时存在缺陷，容易忽略早期的信息，导致生成结果不一致或不准确。因此，需要一个能够处理非马尔可夫（即依赖于早期状态）对话的新方法。

Method: 1. 构建非马尔可夫多轮数据集：采用回滚式编辑（强制模型检索早期视觉状态）和基于名称的多轮个性化（跨轮次绑定名称与外观）。 2. 提出历史条件训练和推理框架：使用token级缓存来防止多轮对话中的身份漂移。 3. 改进高保真图像重建和可编辑个性化：包括基于重建的DiT（Diffusion Transformer）反归一化器和多阶段微调课程。

Result: 显式训练用于非马尔可夫交互的模型，在多轮一致性和指令遵循方面取得了显著的改进，同时保持了强大的单轮编辑和个性化能力。

Conclusion: 本文提出的非马尔可夫框架能够有效解决多轮对话式图像生成中的长历史依赖问题，提升了模型的性能和鲁棒性。

Abstract: Conversational image generation requires a model to follow user instructions across multiple rounds of interaction, grounded in interleaved text and images that accumulate as chat history. While recent multimodal large language models (MLLMs) can generate and edit images, most existing multi-turn benchmarks and training recipes are effectively Markov: the next output depends primarily on the most recent image, enabling shortcut solutions that ignore long-range history. In this work we formalize and target the more challenging non-Markov setting, where a user may refer back to earlier states, undo changes, or reference entities introduced several rounds ago. We present (i) non-Markov multi-round data construction strategies, including rollback-style editing that forces retrieval of earlier visual states and name-based multi-round personalization that binds names to appearances across rounds; (ii) a history-conditioned training and inference framework with token-level caching to prevent multi-round identity drift; and (iii) enabling improvements for high-fidelity image reconstruction and editable personalization, including a reconstruction-based DiT detokenizer and a multi-stage fine-tuning curriculum. We demonstrate that explicitly training for non-Markov interactions yields substantial improvements in multi-round consistency and instruction compliance, while maintaining strong single-round editing and personalization.

</details>


### [110] [Text controllable PET denoising](https://arxiv.org/abs/2601.20990)
*Xuehua Ye,Hongxu Yang,Adam J. Schwarz*

Main category: cs.CV

TL;DR: 提出了一种新颖的文本引导的PET图像去噪方法，该方法使用预训练的CLIP模型和U-Net去噪模型，能够在单一模型中处理不同计数水平的PET图像，并在定性和定量评估中表现出显著的改进。


<details>
  <summary>Details</summary>
Motivation: PET图像的复杂噪声会掩盖关键的诊断信息，而PET图像的质量受到多种因素的影响，需要一种能够处理不同计数水平的通用去噪方法。

Method: 利用预训练的CLIP模型的特征，并将其与基于U-Net的去噪模型相结合，构建了一个文本引导的去噪模型。

Result: 实验结果表明，该模型在定性和定量评估方面均取得了显著的改进，能够有效地提高PET图像的质量。

Conclusion: 提出的文本引导去噪模型具有灵活性，能够满足更复杂的去噪需求，并有可能缩短图像采集时间。

Abstract: Positron Emission Tomography (PET) imaging is a vital tool in medical diagnostics, offering detailed insights into molecular processes within the human body. However, PET images often suffer from complicated noise, which can obscure critical diagnostic information. The quality of the PET image is impacted by various factors including scanner hardware, image reconstruction, tracer properties, dose/count level, and acquisition time. In this study, we propose a novel text-guided denoising method capable of enhancing PET images across a wide range of count levels within a single model. The model utilized the features from a pretrained CLIP model with a U-Net based denoising model. Experimental results demonstrate that the proposed model leads significant improvements in both qualitative and quantitative assessments. The flexibility of the model shows the potential for helping more complicated denoising demands or reducing the acquisition time.

</details>


### [111] [AI-based Prediction of Biochemical Recurrence from Biopsy and Prostatectomy Samples](https://arxiv.org/abs/2601.21022)
*Andrea Camilloni,Chiara Micoli,Nita Mulliqi,Erik Everett Palm,Thorgerdur Palsdottir,Kelvin Szolnoky,Xiaoyi Ji,Sol Erika Boman,Andrea Discacciati,Henrik Grönberg,Lars Egevad,Tobias Nordström,Kimmo Kartasalo,Martin Eklund*

Main category: cs.CV

TL;DR: 本研究训练了一个基于人工智能（AI）的模型，利用前列腺活检病理切片来预测根治性前列腺切除术（RP）后生化复发（BCR）的风险。该模型在多个外部队列中进行了验证，并显示出一定的预测能力，结合临床变量后风险分层效果更佳，优于现有的CAPRA-S评分系统。


<details>
  <summary>Details</summary>
Motivation: 现有的前列腺癌预后评估工具（如BCR预测）不够精确，促使研究者探索更先进的预测方法，以改善患者的预后决策。

Method: 研究者使用STHLM3队列的676名患者的诊断性前列腺活检切片，利用基础模型和基于注意力机制的多实例学习训练了一个AI模型，用于预测患者BCR的风险。随后，在LEOPARD、CHIMERA和TCGA-PRAD三个外部队列（分别包含508、95和379名患者）中评估了模型的泛化能力。模型还与临床变量结合，并与CAPRA-S评分系统进行了比较。

Result: 该AI模型在三个外部队列中实现了5年时间依赖性AUC值分别为0.64、0.70和0.70。整合临床变量后，模型的风险分层能力得到显著提升。与基于指南的CAPRA-S评分系统相比，AI模型在术后预后评估方面提供了额外的价值。

Conclusion: 基于前列腺活检训练的AI病理模型能够跨不同样本类型进行泛化，有望辅助术前和术后的决策。然而，AI多模态方法相比于更简单的预测模型所带来的额外价值，仍需在未来的研究中进行审慎评估。

Abstract: Biochemical recurrence (BCR) after radical prostatectomy (RP) is a surrogate marker for aggressive prostate cancer with adverse outcomes, yet current prognostic tools remain imprecise. We trained an AI-based model on diagnostic prostate biopsy slides from the STHLM3 cohort (n = 676) to predict patient-specific risk of BCR, using foundation models and attention-based multiple instance learning. Generalizability was assessed across three external RP cohorts: LEOPARD (n = 508), CHIMERA (n = 95), and TCGA-PRAD (n = 379). The image-based approach achieved 5-year time-dependent AUCs of 0.64, 0.70, and 0.70, respectively. Integrating clinical variables added complementary prognostic value and enabled statistically significant risk stratification. Compared with guideline-based CAPRA-S, AI incrementally improved postoperative prognostication. These findings suggest biopsy-trained histopathology AI can generalize across specimen types to support preoperative and postoperative decision making, but the added value of AI-based multimodal approaches over simpler predictive models should be critically scrutinized in further studies.

</details>


### [112] [BadDet+: Robust Backdoor Attacks for Object Detection](https://arxiv.org/abs/2601.21066)
*Kealan Dunnett,Reza Arablouei,Dimity Miller,Volkan Dedeoglu,Raja Jurdak*

Main category: cs.CV

TL;DR: 该研究提出了BadDet+，一个用于对象检测的后门攻击框架，它通过引入对真实类别预测的惩罚来克服现有方法的局限性，实现了位置和尺度不变性以及更好的物理鲁棒性，并在真实数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有针对对象检测的后门攻击方法存在不切实际的假设和缺乏物理验证等关键弱点，导致对其影响的理解不足。研究旨在弥补这一差距，提出更有效且物理鲁棒的攻击方法。

Method: 引入了一个名为BadDet+的基于惩罚的框架，该框架结合了区域误分类攻击（RMA）和对象消失攻击（ODA）。核心机制是利用对数障碍惩罚来抑制触发输入上的真实类别预测，从而实现位置和尺度不变性，并增强物理鲁棒性。

Result: BadDet+在真实世界基准测试中，相比现有的RMA和ODA基线，实现了更优越的合成到物理迁移能力，同时保持了对干净输入的性能。理论分析证实了该惩罚机制在触发器特定的特征子空间内起作用，能够可靠地诱导攻击而不损害标准推理。

Conclusion: 对象检测模型存在显著的后门漏洞，并且需要专门的防御措施。BadDet+框架证明了其在实现位置和尺度不变性以及增强物理鲁棒性方面的有效性，为理解和防御对象检测中的后门攻击提供了新思路。

Abstract: Backdoor attacks pose a severe threat to deep learning, yet their impact on object detection remains poorly understood compared to image classification. While attacks have been proposed, we identify critical weaknesses in existing detection-based methods, specifically their reliance on unrealistic assumptions and a lack of physical validation. To bridge this gap, we introduce BadDet+, a penalty-based framework that unifies Region Misclassification Attacks (RMA) and Object Disappearance Attacks (ODA). The core mechanism utilizes a log-barrier penalty to suppress true-class predictions for triggered inputs, resulting in (i) position and scale invariance, and (ii) enhanced physical robustness. On real-world benchmarks, BadDet+ achieves superior synthetic-to-physical transfer compared to existing RMA and ODA baselines while preserving clean performance. Theoretical analysis confirms the proposed penalty acts within a trigger-specific feature subspace, reliably inducing attacks without degrading standard inference. These results highlight significant vulnerabilities in object detection and the necessity for specialized defenses.

</details>


### [113] [Towards Mitigating Modality Bias in Vision-Language Models for Temporal Action Localization](https://arxiv.org/abs/2601.21078)
*Jiaqi Li,Guangming Wang,Shuntian Zheng,Minzhe Ni,Xiaoman Lu,Guanghui Ye,Yu Guan*

Main category: cs.CV

TL;DR: ActionVLM是一个视觉-语言聚合框架，通过自适应地利用语言信息并保留视觉信号的主导地位，有效缓解了时间动作定位（TAL）中的模态偏见，并在THUMOS14数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有TAL方法在利用视觉-语言模型（VLMs）时，倾向于过度强调语言信息，导致视觉性能下降（模态偏见）。

Method: ActionVLM提出了一种“视觉为主，语言为辅”的策略，包括：（1）一个去偏重加权模块，用于估计语言相对于仅视觉预测的增益，并据此动态调整语言模态的权重；（2）一种残差聚合策略，将语言作为补充优化而非主要驱动力。

Result: 该模型在THUMOS14数据集上，相较于现有SOTA方法，mAP提高了3.2%。

Conclusion: ActionVLM框架能够有效缓解TAL中的模态偏见，降低语言先验带来的过度自信，并增强时间推理能力，从而提升TAL性能。

Abstract: Temporal Action Localization (TAL) requires identifying both the boundaries and categories of actions in untrimmed videos. While vision-language models (VLMs) offer rich semantics to complement visual evidence, existing approaches tend to overemphasize linguistic priors at the expense of visual performance, leading to a pronounced modality bias. We propose ActionVLM, a vision-language aggregation framework that systematically mitigates modality bias in TAL. Our key insight is to preserve vision as the dominant signal while adaptively exploiting language only when beneficial. To this end, we introduce (i) a debiasing reweighting module that estimates the language advantage-the incremental benefit of language over vision-only predictions-and dynamically reweights language modality accordingly, and (ii) a residual aggregation strategy that treats language as a complementary refinement rather than the primary driver. This combination alleviates modality bias, reduces overconfidence from linguistic priors, and strengthens temporal reasoning. Experiments on THUMOS14 show that our model outperforms state-of-the-art by up to 3.2% mAP.

</details>


### [114] [Low performing pixel correction in computed tomography with unrolled network and synthetic data training](https://arxiv.org/abs/2601.20995)
*Hongxu Yang,Levente Lippenszky,Edina Timko,Lehel Ferenczi,Gopal Avinash*

Main category: cs.CV

TL;DR: 提出一种基于合成数据、在图像域和投影域协同工作的深度学习方法，用于校正CT中的低性能像素（LPP）伪影，无需真实临床数据即可获得优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LPP伪影校正方法需要昂贵的真实临床数据集进行训练，且仅在图像域或投影域进行校正，忽略了两种域的内在联系。本研究旨在提出一种无需真实数据且能协同利用图像域和投影域信息的校正方法。

Method: 提出一种基于合成数据、结合了图像域和投影域信息（unrolled dual-domain）的深度学习方法。通过利用自然图像合成的LPP伪影数据，训练模型学习投影域和图像域之间LPP伪影的内在关联，从而实现伪影校正。

Result: 在模拟1-2%探测器缺陷的实验中，所提出的方法在校正LPP伪影方面显著优于现有最先进的方法。

Conclusion: 该方法无需昂贵的数据收集成本即可有效校正LPP伪影，并且能够适应不同的扫描仪设置，适用于软件化应用。

Abstract: Low performance pixels (LPP) in Computed Tomography (CT) detectors would lead to ring and streak artifacts in the reconstructed images, making them clinically unusable. In recent years, several solutions have been proposed to correct LPP artifacts, either in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, which are expensive to collect. Moreover, existing approaches focus solely either on image-space or sinogram-space correction, ignoring the intrinsic correlations from the forward operation of the CT geometry. In this work, we propose an unrolled dual-domain method based on synthetic data to correct LPP artifacts. Specifically, the intrinsic correlations of LPP between the sinogram and image domains are leveraged through synthetic data generated from natural images, enabling the trained model to correct artifacts without requiring any real-world clinical data. In experiments simulating 1-2% detectors defect near the isocenter, the proposed method outperformed the state-of-the-art approaches by a large margin. The results indicate that our solution can correct LPP artifacts without the cost of data collection for model training, and it is adaptable to different scanner settings for software-based applications.

</details>


### [115] [Shape of Thought: Progressive Object Assembly via Visual Chain-of-Thought](https://arxiv.org/abs/2601.21081)
*Yu Huo,Siyu Zhang,Kun Zeng,Haoyue Liu,Owen Lee,Junlin Chen,Yuquan Lu,Yifu Guo,Yaodong Liang,Xiaoying Tang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Shape-of-Thought (SoT) 的视觉思维链框架，用于解决文本到图像生成模型在组合结构约束（如生成数、属性绑定和部分关系）方面的不足，通过渐进式的形状组装和连贯的2D投影实现，无需外部引擎，并引入了SoT-26K数据集和T2S-CompBench基准。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在视觉保真度方面表现出色，但在处理组合结构约束（如生成数、属性绑定和部分关系）时表现脆弱，这促使研究者开发能够理解和生成具有精确结构的对象。 


Method: 作者提出了一种名为Shape-of-Thought (SoT) 的视觉思维链框架，该框架通过生成交织的文本计划和渲染的中间状态来训练一个统一的多模态自回归模型，从而实现渐进式的形状组装，而无需显式的几何表示或外部引擎。为了支持这一范式，他们构建了一个名为SoT-26K的大规模数据集，其中包含基于部件的CAD层次结构派生的接地组装轨迹，并提出了T2S-CompBench基准来评估结构完整性和轨迹忠实度。

Result: 通过在SoT-26K数据集上进行微调，SoT在组件数（88.4%）和结构拓扑（84.8%）方面取得了显著成果，比纯文本基线提高了约20%。

Conclusion: SoT框架为透明、过程监督的组合式生成树立了一个新范式，有效地解决了文本到图像生成模型在处理组合结构约束方面的挑战，并展示了在结构完整性和轨迹忠实度方面的优越性能。

Abstract: Multimodal models for text-to-image generation have achieved strong visual fidelity, yet they remain brittle under compositional structural constraints-notably generative numeracy, attribute binding, and part-level relations. To address these challenges, we propose Shape-of-Thought (SoT), a visual CoT framework that enables progressive shape assembly via coherent 2D projections without external engines at inference time. SoT trains a unified multimodal autoregressive model to generate interleaved textual plans and rendered intermediate states, helping the model capture shape-assembly logic without producing explicit geometric representations. To support this paradigm, we introduce SoT-26K, a large-scale dataset of grounded assembly traces derived from part-based CAD hierarchies, and T2S-CompBench, a benchmark for evaluating structural integrity and trace faithfulness. Fine-tuning on SoT-26K achieves 88.4% on component numeracy and 84.8% on structural topology, outperforming text-only baselines by around 20%. SoT establishes a new paradigm for transparent, process-supervised compositional generation. The code is available at https://anonymous.4open.science/r/16FE/. The SoT-26K dataset will be released upon acceptance.

</details>


### [116] [An AI Framework for Microanastomosis Motion Assessment](https://arxiv.org/abs/2601.21120)
*Yan Meng,Eduardo J. Torres-Rodríguez,Marcelle Altshuler,Nishanth Gowda,Arhum Naeem,Recai Yilmaz,Omar Arnaout,Daniel A. Donoho*

Main category: cs.CV

TL;DR: 本研究提出了一种基于AI的微血管吻合器械操作技能自动评估框架，利用YOLO、DeepSORT、形状描述符和监督分类器，实现了高精度的器械检测和熟练度评估。


<details>
  <summary>Details</summary>
Motivation: 传统的主观评估方法存在评分者间差异、评估标准不统一、易受认知偏差影响以及耗时等缺点，迫切需要一种客观、可靠、可扩展的自动化评估系统。

Method: 开发了一个包含四个核心组件的AI框架：1. 基于YOLO的器械检测模块；2. 基于DeepSORT的器械跟踪模块；3. 基于形状描述符的器械尖端定位模块；4. 监督分类模块，通过专家标注数据训练以评估器械操作熟练度。

Result: 实验证明了该框架的有效性，器械检测精度达到97%，在IoU阈值50%-95%下的平均精度（mAP）为96%。

Conclusion: 所提出的AI框架能够客观、可靠且高效地评估微血管吻合器械操作技能，克服了传统评估方法的局限性。

Abstract: Proficiency in microanastomosis is a fundamental competency across multiple microsurgical disciplines. These procedures demand exceptional precision and refined technical skills, making effective, standardized assessment methods essential. Traditionally, the evaluation of microsurgical techniques has relied heavily on the subjective judgment of expert raters. They are inherently constrained by limitations such as inter-rater variability, lack of standardized evaluation criteria, susceptibility to cognitive bias, and the time-intensive nature of manual review. These shortcomings underscore the urgent need for an objective, reliable, and automated system capable of assessing microsurgical performance with consistency and scalability. To bridge this gap, we propose a novel AI framework for the automated assessment of microanastomosis instrument handling skills. The system integrates four core components: (1) an instrument detection module based on the You Only Look Once (YOLO) architecture; (2) an instrument tracking module developed from Deep Simple Online and Realtime Tracking (DeepSORT); (3) an instrument tip localization module employing shape descriptors; and (4) a supervised classification module trained on expert-labeled data to evaluate instrument handling proficiency. Experimental results demonstrate the effectiveness of the framework, achieving an instrument detection precision of 97%, with a mean Average Precision (mAP) of 96%, measured by Intersection over Union (IoU) thresholds ranging from 50% to 95% (mAP50-95).

</details>


### [117] [Bidirectional Cross-Perception for Open-Vocabulary Semantic Segmentation in Remote Sensing Imagery](https://arxiv.org/abs/2601.21159)
*Jianzheng Wang,Huan Ni*

Main category: cs.CV

TL;DR: 提出了一种名为SDCI的空间正则化感知双分支协同推理框架，用于训练免费的开放词汇语义分割，以提高高分辨率遥感影像的几何定位和语义预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有训练免费的开放词汇语义分割方法在融合CLIP和视觉基础模型时，采用“单向注入”和“浅层后处理”策略，难以满足高分辨率遥感影像中密集分布的土地覆盖对象和复杂边界的要求。

Method: SDCI框架包括：1. 交叉模型注意力融合（CAF）模块，通过注入自注意力图进行协同推理；2. 双向跨图扩散细化（BCDR）模块，通过迭代随机游走扩散增强分割分数可靠性；3. 基于凸优化的超像素协同预测（CSCP）机制，结合低层超像素结构细化对象边界。

Result: 在多个遥感语义分割基准测试中，SDCI方法取得了比现有方法更好的性能。消融研究证实了传统基于对象的遥感图像分析方法（利用超像素结构）在深度学习框架中仍然有效。

Conclusion: SDCI框架通过引入交叉模型注意力融合、双向跨图扩散细化以及基于凸优化的超像素协同预测机制，有效地提高了训练免费开放词汇语义分割在高分辨率遥感影像上的性能，尤其是在处理复杂对象边界方面。

Abstract: High-resolution remote sensing imagery is characterized by densely distributed land-cover objects and complex boundaries, which places higher demands on both geometric localization and semantic prediction. Existing training-free open-vocabulary semantic segmentation (OVSS) methods typically fuse CLIP and vision foundation models (VFMs) using "one-way injection" and "shallow post-processing" strategies, making it difficult to satisfy these requirements. To address this issue, we propose a spatial-regularization-aware dual-branch collaborative inference framework for training-free OVSS, termed SDCI. First, during feature encoding, SDCI introduces a cross-model attention fusion (CAF) module, which guides collaborative inference by injecting self-attention maps into each other. Second, we propose a bidirectional cross-graph diffusion refinement (BCDR) module that enhances the reliability of dual-branch segmentation scores through iterative random-walk diffusion. Finally, we incorporate low-level superpixel structures and develop a convex-optimization-based superpixel collaborative prediction (CSCP) mechanism to further refine object boundaries. Experiments on multiple remote sensing semantic segmentation benchmarks demonstrate that our method achieves better performance than existing approaches. Moreover, ablation studies further confirm that traditional object-based remote sensing image analysis methods leveraging superpixel structures remain effective within deep learning frameworks. Code: https://github.com/yu-ni1989/SDCI.

</details>


### [118] [Enhancing Underwater Light Field Images via Global Geometry-aware Diffusion Process](https://arxiv.org/abs/2601.21179)
*Yuji Lin,Qian Zhao,Zongsheng Yue,Junhui Hou,Deyu Meng*

Main category: cs.CV

TL;DR: 提出了一种名为GeoDiff-LF的基于扩散模型的框架，用于增强水下4D光场（LF）图像的质量，通过结合几何先验和扩散模型来解决颜色失真问题。


<details>
  <summary>Details</summary>
Motivation: 水下成像质量差，存在颜色失真等问题，需要一种有效的方法来增强水下4D光场图像。

Method: 提出GeoDiff-LF框架，该框架基于SD-Turbo，并进行了三项主要改进：1. 修改U-Net架构以处理几何线索；2. 使用张量分解和渐进加权设计几何引导损失函数；3. 优化采样策略以提高效率。

Result: GeoDiff-LF在视觉保真度和定量性能上均优于现有方法，有效减轻了水下场景的颜色失真。

Conclusion: GeoDiff-LF通过整合扩散先验和光场几何信息，成功提升了水下4D光场图像的质量，是水下成像增强领域的最新进展。

Abstract: This work studies the challenging problem of acquiring high-quality underwater images via 4-D light field (LF) imaging. To this end, we propose GeoDiff-LF, a novel diffusion-based framework built upon SD-Turbo to enhance underwater 4-D LF imaging by leveraging its spatial-angular structure. GeoDiff-LF consists of three key adaptations: (1) a modified U-Net architecture with convolutional and attention adapters to model geometric cues, (2) a geometry-guided loss function using tensor decomposition and progressive weighting to regularize global structure, and (3) an optimized sampling strategy with noise prediction to improve efficiency. By integrating diffusion priors and LF geometry, GeoDiff-LF effectively mitigates color distortion in underwater scenes. Extensive experiments demonstrate that our framework outperforms existing methods across both visual fidelity and quantitative performance, advancing the state-of-the-art in enhancing underwater imaging. The code will be publicly available at https://github.com/linlos1234/GeoDiff-LF.

</details>


### [119] [Generative Recall, Dense Reranking: Learning Multi-View Semantic IDs for Efficient Text-to-Video Retrieval](https://arxiv.org/abs/2601.21193)
*Zecheng Zhao,Zhi Chen,Zi Huang,Shazia Sadiq,Tong Chen*

Main category: cs.CV

TL;DR: 提出了一种名为 GRDR 的新颖生成式检索方法，用于文本到视频检索。GRDR 通过分配多个语义 ID 来解决现有生成式检索方法中的语义歧义和跨模态不对齐问题，并通过共享代码本进行联合训练。在推理时，GRDR 生成一个紧凑的候选集，并由密集检索模型进行重排序，从而在保持高检索精度的同时，显著减少索引存储并加速检索过程。


<details>
  <summary>Details</summary>
Motivation: 现有的基于密集检索的文本到视频检索方法虽然精度高，但在大规模语料库上的计算和存储成本高昂。两阶段检索方法通过一个快速的召回模型缩小候选集，再由精密的密集检索模型进行重排序。然而，召回模型（如生成式检索 GR）在语义模糊性和跨模态不对齐方面存在不足，限制了整体性能。

Method: 提出 Generative Recall and Dense Reranking (GRDR) 方法。GRDR 使用查询引导的多视图分词器为每个视频分配多个语义 ID，以暴露多样的语义访问路径。通过共享代码本，分词器和生成式检索器进行联合训练，使语义 ID 成为文本和视频之间的语义桥梁。在推理时，采用 trie 约束解码生成紧凑的候选集，然后由密集检索模型进行精细匹配。

Result: 在 TVR 基准测试中，GRDR 在准确性方面可媲美强大的密集检索器。与仅使用密集检索相比，GRDR 的索引存储减少了一个数量级，并且在全语料库检索速度上提升了高达 300 倍。

Conclusion: GRDR 是一种有效的方法，能够通过生成式检索来提高召回候选的质量，从而提升两阶段文本到视频检索的整体性能。该方法在准确性、存储效率和检索速度方面均取得了显著的改进。

Abstract: Text-to-Video Retrieval (TVR) is essential in video platforms. Dense retrieval with dual-modality encoders leads in accuracy, but its computation and storage scale poorly with corpus size. Thus, real-time large-scale applications adopt two-stage retrieval, where a fast recall model gathers a small candidate pool, which is reranked by an advanced dense retriever. Due to hugely reduced candidates, the reranking model can use any off-the-shelf dense retriever without hurting efficiency, meaning the recall model bounds two-stage TVR performance. Recently, generative retrieval (GR) replaces dense video embeddings with discrete semantic IDs and retrieves by decoding text queries into ID tokens. GR offers near-constant inference and storage complexity, and its semantic IDs capture high-level video features via quantization, making it ideal for quickly eliminating irrelevant candidates during recall. However, as a recall model in two-stage TVR, GR suffers from (i) semantic ambiguity, where each video satisfies diverse queries but is forced into one semantic ID; and (ii) cross-modal misalignment, as semantic IDs are solely derived from visual features without text supervision. We propose Generative Recall and Dense Reranking (GRDR), designing a novel GR method to uplift recalled candidate quality. GRDR assigns multiple semantic IDs to each video using a query-guided multi-view tokenizer exposing diverse semantic access paths, and jointly trains the tokenizer and generative retriever via a shared codebook to cast semantic IDs as the semantic bridge between texts and videos. At inference, trie-constrained decoding generates a compact candidate set reranked by a dense model for fine-grained matching. Experiments on TVR benchmarks show GRDR matches strong dense retrievers in accuracy while reducing index storage by an order of magnitude and accelerating up to 300$\times$ in full-corpus retrieval.

</details>


### [120] [Thinker: A vision-language foundation model for embodied intelligence](https://arxiv.org/abs/2601.21199)
*Baiyu Pan,Daqin Luo,Junpeng Yang,Jiyuan Wang,Yixuan Zhang,Hailin Shi,Jichao Jiao*

Main category: cs.CV

TL;DR: 本文提出了一个名为Thinker的大型视觉-语言基础模型，旨在解决大型视觉-语言模型在机器人领域的应用难题，例如视角混淆和时间推理中的信息遗漏。通过构建专门的机器人数据集和结合关键帧与完整视频序列作为输入，该模型在任务规划基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型在应用于机器人领域时，会遇到对人类而言简单但对模型而言易出错的问题，如第三人称与第一人称视角混淆，以及在时间推理中忽略视频结尾信息。

Method: 1. 构建了一个包含自我视角视频、视觉接地、空间理解和思维链数据的大规模数据集，专门用于机器人感知和推理。
2. 提出了一种通过联合输入关键帧和完整视频序列来增强模型视频理解能力的方法。

Result: 在两个常用的任务规划领域基准数据集上取得了最先进的性能。

Conclusion: Thinker模型通过专门的数据集和创新的输入处理方法，有效解决了大型视觉-语言模型在机器人任务中的关键挑战，并在相关任务规划基准上展现出优越的性能。

Abstract: When large vision-language models are applied to the field of robotics, they encounter problems that are simple for humans yet error-prone for models. Such issues include confusion between third-person and first-person perspectives and a tendency to overlook information in video endings during temporal reasoning. To address these challenges, we propose Thinker, a large vision-language foundation model designed for embodied intelligence. We tackle the aforementioned issues from two perspectives. Firstly, we construct a large-scale dataset tailored for robotic perception and reasoning, encompassing ego-view videos, visual grounding, spatial understanding, and chain-of-thought data. Secondly, we introduce a simple yet effective approach that substantially enhances the model's capacity for video comprehension by jointly incorporating key frames and full video sequences as inputs. Our model achieves state-of-the-art results on two of the most commonly used benchmark datasets in the field of task planning.

</details>


### [121] [FRISM: Fine-Grained Reasoning Injection via Subspace-Level Model Merging for Vision-Language Models](https://arxiv.org/abs/2601.21187)
*Chenyu Huang,Peng Ye,Xudong Tan,Jinhan Mu,Shenghe Zheng,Li Shen,Tao Chen*

Main category: cs.CV

TL;DR: 本文提出了FRISM框架，通过对大型推理模型（LRM）的子空间进行精细化合并，来增强视觉语言模型（VLM）的推理能力，同时保持其视觉能力。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在合并VLM和LRM时，通常在较粗的层级上操作，导致推理能力和视觉能力之间的权衡。作者希望在不牺牲视觉能力的情况下，有效地增强VLM的推理能力。

Method: FRISM框架基于子空间级别的模型合并。它利用奇异值分解（SVD）来分解LRM的任务向量，识别出编码推理能力的特定子空间。然后，通过学习自适应地调整每个子空间的缩放系数，实现精细化的推理能力注入。此外，还引入了一种无标签的自蒸馏学习策略，并使用通用视觉-语言感知数据集进行双目标优化。

Result: FRISM能够有效地提升模型的推理能力，并且不会损害其原有的视觉能力。在各种视觉推理基准测试中，FRISM都取得了最先进的性能。

Conclusion: FRISM是一种有效的精细化推理注入框架，通过子空间级别的模型合并，能够同时增强VLM的推理能力和保留其视觉能力，并在视觉推理任务上取得了优异的性能。

Abstract: Efficiently enhancing the reasoning capabilities of Vision-Language Models (VLMs) by merging them with Large Reasoning Models (LRMs) has emerged as a promising direction. However, existing methods typically operate at a coarse-grained layer level, which often leads to a trade-off between injecting reasoning capabilities and preserving visual capabilities. To address this limitation, we propose {FRISM} (Fine-grained Reasoning Injection via Subspace-level model Merging), a fine-grained reasoning injection framework based on subspace-level model merging. Observing that reasoning capabilities are encoded in distinct subspaces, FRISM decomposes LRM task vectors via Singular Value Decomposition (SVD) and adaptively tunes the scaling coefficients of each subspace through learning to realize fine-grained reasoning injection. Furthermore, we introduce a label-free self-distillation learning strategy with a dual-objective optimization using common vision-language perception datasets. Extensive experiments demonstrate that FRISM effectively improves reasoning capabilities without compromising the model's original visual capabilities by consistently achieving state-of-the-art performance across diverse visual reasoning benchmarks.

</details>


### [122] [LAMP: Learning Universal Adversarial Perturbations for Multi-Image Tasks via Pre-trained Models](https://arxiv.org/abs/2601.21220)
*Alvi Md Ishmam,Najibul Haque Sarker,Zaber Ibn Abdul Hakim,Chris Thomas*

Main category: cs.CV

TL;DR: 本文提出了一种名为LAMP的黑盒攻击方法，用于生成针对多图像多模态大语言模型（MLLMs）的通用对抗性扰动（UAPs）。LAMP通过引入注意力约束、跨图像传染约束和索引注意力抑制损失，有效降低了模型聚合多图像信息的能力，并实现了高效的攻击。


<details>
  <summary>Details</summary>
Motivation: 现有针对多图像MLLMs的对抗性攻击方法研究不足，且多集中于白盒攻击，不适用于实际场景。因此，需要开发一种更实用、更有效的黑盒攻击方法。

Method: LAMP是一种黑盒攻击方法，通过以下方式生成UAPs：1.  注意力机制约束：阻止模型有效聚合多图像信息。2.  跨图像传染约束：使得扰动过的token能够影响未扰动的token，扩散攻击效果。3.  索引注意力抑制损失：实现鲁棒的位置不变性攻击。

Result: LAMP在多个视觉-语言任务和模型上，相比于现有最先进（SOTA）的基线方法，取得了更高的攻击成功率。

Conclusion: LAMP是一种有效的黑盒攻击方法，能够成功地针对多图像MLLMs生成UAPs，并显著降低其处理多图像信息的能力。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable performance across vision-language tasks. Recent advancements allow these models to process multiple images as inputs. However, the vulnerabilities of multi-image MLLMs remain unexplored. Existing adversarial attacks focus on single-image settings and often assume a white-box threat model, which is impractical in many real-world scenarios. This paper introduces LAMP, a black-box method for learning Universal Adversarial Perturbations (UAPs) targeting multi-image MLLMs. LAMP applies an attention-based constraint that prevents the model from effectively aggregating information across images. LAMP also introduces a novel cross-image contagious constraint that forces perturbed tokens to influence clean tokens, spreading adversarial effects without requiring all inputs to be modified. Additionally, an index-attention suppression loss enables a robust position-invariant attack. Experimental results show that LAMP outperforms SOTA baselines and achieves the highest attack success rates across multiple vision-language tasks and models.

</details>


### [123] [NFCDS: A Plug-and-Play Noise Frequency-Controlled Diffusion Sampling Strategy for Image Restoration](https://arxiv.org/abs/2601.21248)
*Zhen Wang,Hongyi Liu,Jianing Li,Zhihui Wei*

Main category: cs.CV

TL;DR: 提出一种名为NFCDS（Noise Frequency-Controlled Diffusion Sampling）的逆扩散噪声谱调制机制，通过控制噪声频率来解决现有基于扩散模型的即插即用（PnP）方法在图像保真度和感知质量之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的PnP方法在生成高感知质量图像的同时，通常会牺牲数据保真度，这主要是由于逆扩散过程中引入的噪声。研究旨在解决这种保真度与感知质量之间的冲突。

Method: 设计一种基于傅里叶域的滤波器，通过逐步抑制低频噪声并保留高频成分来调制逆扩散噪声。这种方法将数据一致性先验直接注入到采样过程中，无需额外训练。

Result: NFCDS能够快速收敛到既保真又具有说服力的感知结果，并且能够无缝集成到现有的基于扩散的图像恢复框架中，在多种零样本任务中改善了保真度与感知质量的平衡。

Conclusion: NFCDS是一种有效的谱调制机制，通过控制噪声频率，能够解决扩散模型PnP方法在保真度和感知质量之间的权衡问题，实现两者的同时提升。

Abstract: Diffusion sampling-based Plug-and-Play (PnP) methods produce images with high perceptual quality but often suffer from reduced data fidelity, primarily due to the noise introduced during reverse diffusion. To address this trade-off, we propose Noise Frequency-Controlled Diffusion Sampling (NFCDS), a spectral modulation mechanism for reverse diffusion noise. We show that the fidelity-perception conflict can be fundamentally understood through noise frequency: low-frequency components induce blur and degrade fidelity, while high-frequency components drive detail generation. Based on this insight, we design a Fourier-domain filter that progressively suppresses low-frequency noise and preserves high-frequency content. This controlled refinement injects a data-consistency prior directly into sampling, enabling fast convergence to results that are both high-fidelity and perceptually convincing--without additional training. As a PnP module, NFCDS seamlessly integrates into existing diffusion-based restoration frameworks and improves the fidelity-perception balance across diverse zero-shot tasks.

</details>


### [124] [Hypersolid: Emergent Vision Representations via Short-Range Repulsion](https://arxiv.org/abs/2601.21255)
*Esteban Rodríguez-Betancourt,Edgar Casasola-Murillo*

Main category: cs.CV

TL;DR: 本文提出了一种名为Hypersolid的新型自监督学习方法，通过将表示学习视为离散的打包问题，并使用短程硬球排斥来防止局部碰撞，从而有效避免了表示崩溃，并在细粒度和低分辨率分类任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法在防止表示崩溃方面存在挑战，通常依赖于全局正则化。研究人员希望探索一种新的、不依赖全局正则化的方法。

Method: 将表示学习重新解释为离散的打包问题，并引入Hypersolid方法。该方法使用短程硬球排斥来防止局部碰撞，从而在几何上实现高分离性。

Result: Hypersolid方法能够保持数据增强的多样性，并在细粒度和低分辨率分类任务上取得了优异的性能。

Conclusion: 通过将表示学习视为离散的打包问题并采用短程硬球排斥，Hypersolid能够有效地防止表示崩溃，并在特定任务上实现更好的性能，表明这种几何约束是一种有前景的研究方向。

Abstract: A recurring challenge in self-supervised learning is preventing representation collapse. Existing solutions typically rely on global regularization, such as maximizing distances, decorrelating dimensions or enforcing certain distributions. We instead reinterpret representation learning as a discrete packing problem, where preserving information simplifies to maintaining injectivity. We operationalize this in Hypersolid, a method using short-range hard-ball repulsion to prevent local collisions. This constraint results in a high-separation geometric regime that preserves augmentation diversity, excelling on fine-grained and low-resolution classification tasks.

</details>


### [125] [Lightweight High-Fidelity Low-Bitrate Talking Face Compression for 3D Video Conference](https://arxiv.org/abs/2601.21269)
*Jianglong Li,Jun Xu,Bingcong Lu,Zhengxue Cheng,Hongwei Hu,Ronghua Wu,Li Song*

Main category: cs.CV

TL;DR: 提出一种轻量级、高保真、低比特率的3D说话人脸压缩框架，结合FLAME参数模型和3DGS神经渲染，通过传输关键面部元数据实现高效重建，并优化高斯属性压缩和MLP以提高传输效率。


<details>
  <summary>Details</summary>
Motivation: 当前3D视频会议面临低比特率下高保真3D说话人脸表示的挑战，现有方法要么计算成本高，要么细节丢失。

Method: 集成FLAME参数模型和3DGS神经渲染，仅传输关键面部元数据，使用高斯为基础的头部模型进行重建，并引入高斯属性压缩和MLP优化。

Result: 在极低比特率下实现了高质量的面部渲染，展现出优越的率失真性能。

Conclusion: 该框架有效地解决了低比特率3D说话人脸压缩的难题，适用于实时3D视频会议。

Abstract: The demand for immersive and interactive communication has driven advancements in 3D video conferencing, yet achieving high-fidelity 3D talking face representation at low bitrates remains a challenge. Traditional 2D video compression techniques fail to preserve fine-grained geometric and appearance details, while implicit neural rendering methods like NeRF suffer from prohibitive computational costs. To address these challenges, we propose a lightweight, high-fidelity, low-bitrate 3D talking face compression framework that integrates FLAME-based parametric modeling with 3DGS neural rendering. Our approach transmits only essential facial metadata in real time, enabling efficient reconstruction with a Gaussian-based head model. Additionally, we introduce a compact representation and compression scheme, including Gaussian attribute compression and MLP optimization, to enhance transmission efficiency. Experimental results demonstrate that our method achieves superior rate-distortion performance, delivering high-quality facial rendering at extremely low bitrates, making it well-suited for real-time 3D video conferencing applications.

</details>


### [126] [PTQ4ARVG: Post-Training Quantization for AutoRegressive Visual Generation Models](https://arxiv.org/abs/2601.21238)
*Xuewen Liu,Zhikai Li,Jing Zhang,Mengjuan Chen,Qingyi Gu*

Main category: cs.CV

TL;DR: 本文提出了一种名为PTQ4ARVG的训练无关后训练量化框架，用于解决自回归视觉生成（ARVG）模型量化时遇到的三个主要挑战（通道级离群值、令牌级动态激活、样本级分布不匹配），并取得了8位和6位量化下仍具竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法难以有效应用于ARVG模型，而ARVG模型在视觉生成任务中表现优异，并且量化是降低其模型大小和延迟的关键技术，因此需要探索适用于ARVG的模型量化方法。

Method: PTQ4ARVG框架包含三个主要技术：1. 增益投影缩放（GPS）：通过泰勒级数展开量化损失，量化缩放激活值和权重所带来的增益，并通过微分推导出最优缩放因子，以缓解通道级离群值问题。2. 静态令牌级量化（STWQ）：利用ARVG模型固定的令牌长度和跨样本的位置不变性，实现令牌级方差处理，无需动态校准开销。3. 分布引导校准（DGC）：选择对分布熵贡献最大的样本进行校准，解决样本级分布不匹配问题。

Result: PTQ4ARVG能够有效地将ARVG模型量化到8位和6位，同时保持具有竞争力的性能。

Conclusion: PTQ4ARVG框架成功地解决了ARVG模型量化中的关键挑战，并能在低比特精度下实现高效且性能优越的量化。

Abstract: AutoRegressive Visual Generation (ARVG) models retain an architecture compatible with language models, while achieving performance comparable to diffusion-based models. Quantization is commonly employed in neural networks to reduce model size and computational latency. However, applying quantization to ARVG remains largely underexplored, and existing quantization methods fail to generalize effectively to ARVG models. In this paper, we explore this issue and identify three key challenges: (1) severe outliers at channel-wise level, (2) highly dynamic activations at token-wise level, and (3) mismatched distribution information at sample-wise level. To these ends, we propose PTQ4ARVG, a training-free post-training quantization (PTQ) framework consisting of: (1) Gain-Projected Scaling (GPS) mitigates the channel-wise outliers, which expands the quantization loss via a Taylor series to quantify the gain of scaling for activation-weight quantization, and derives the optimal scaling factor through differentiation.(2) Static Token-Wise Quantization (STWQ) leverages the inherent properties of ARVG, fixed token length and position-invariant distribution across samples, to address token-wise variance without incurring dynamic calibration overhead.(3) Distribution-Guided Calibration (DGC) selects samples that contribute most to distributional entropy, eliminating the sample-wise distribution mismatch. Extensive experiments show that PTQ4ARVG can effectively quantize the ARVG family models to 8-bit and 6-bit while maintaining competitive performance. Code is available at http://github.com/BienLuky/PTQ4ARVG .

</details>


### [127] [SINA: A Circuit Schematic Image-to-Netlist Generator Using Artificial Intelligence](https://arxiv.org/abs/2601.22114)
*Saoud Aldowaish,Yashwanth Karumanchi,Kai-Chen Chiang,Soroosh Noorzad,Morteza Fayazi*

Main category: cs.CV

TL;DR: 本文提出了一种名为 SINA 的全自动电路原理图图像到网表生成器，通过集成深度学习、CCL、OCR 和 VLM 技术，显著提高了网表生成精度。


<details>
  <summary>Details</summary>
Motivation: 现有将电路原理图图像转换为机器可读网表的方法在组件识别和连接推理方面存在困难。

Method: SINA 集成了深度学习用于组件检测，连通分量标记 (CCL) 用于连接提取，光学字符识别 (OCR) 用于参考标识符检索，以及视觉语言模型 (VLM) 用于可靠的参考标识符分配。

Result: SINA 在实验中实现了 96.47% 的整体网表生成准确率，比现有最先进的方法提高了 2.72 倍。

Conclusion: SINA 是一种高效且准确的电路原理图图像到网表生成器，克服了现有方法的局限性，并取得了显著的性能提升。

Abstract: Current methods for converting circuit schematic images into machine-readable netlists struggle with component recognition and connectivity inference. In this paper, we present SINA, an open-source, fully automated circuit schematic image-to-netlist generator. SINA integrates deep learning for accurate component detection, Connected-Component Labeling (CCL) for precise connectivity extraction, and Optical Character Recognition (OCR) for component reference designator retrieval, while employing a Vision-Language Model (VLM) for reliable reference designator assignments. In our experiments, SINA achieves 96.47% overall netlist-generation accuracy, which is 2.72x higher than state-of-the-art approaches.

</details>


### [128] [GeoRC: A Benchmark for Geolocation Reasoning Chains](https://arxiv.org/abs/2601.21278)
*Mohit Talreja,Joshua Diao,Jim Thannikary James,Radu Casapu,Tejas Santanam,Ethan Mendes,Alan Ritter,Wei Xu,James Hays*

Main category: cs.CV

TL;DR: 本研究提出了第一个用于地理定位推理链的基准测试，发现尽管视觉语言模型（VLM）在预测地理位置方面表现出色，但它们在解释预测依据方面存在显著不足，经常出现幻觉。研究人员通过与专家合作创建了800条真实推理链，并评估了不同的评分策略，发现Qwen 3在“LLM-as-a-judge”方法下与人类评分最相关。结果表明，大型闭源VLM在推理链方面仍落后于人类专家，而开源VLM表现则更差，暗示VLM在提取细粒度视觉属性方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）在地理定位预测方面表现优异，但它们在解释预测依据方面存在严重问题，经常产生虚假的推理链。研究人员希望创建一个基准测试来量化和评估VLM在生成可信推理链方面的能力。

Method: 研究人员创建了一个包含500个查询场景和800条专家级别地理定位推理链的基准测试，这些推理链由GeoGuessr专家（包括世界冠军）制作。他们使用“LLM-as-a-judge”和“VLM-as-a-judge”策略来评估VLM生成的推理链与专家推理链的匹配程度，并寻找与人类评分最相关的评分方法。最后，他们评估了不同的VLM（包括闭源和开源模型）在地理定位预测和推理链生成任务上的表现。

Result: 研究发现，大型闭源VLM（如Gemini和GPT 5）在地理定位预测方面可以媲美人类专家，但在生成可审计的推理链方面仍落后于人类。开源VLM（如Llama和Qwen）在该基准测试上的表现非常差，仅略好于一个仅依赖地点的幻觉推理链基线。Qwen 3在“LLM-as-a-judge”方法下与人类评分的相关性最高。

Conclusion: 现有的VLM在地理定位预测方面的能力与人类专家相当，但在生成准确且可验证的推理链方面存在显著差距。这种差距可能源于VLM在从高分辨率图像中提取细粒度视觉属性方面的局限性。本研究提出的基准测试为评估和改进VLM的推理能力提供了重要工具。

Abstract: Vision Language Models (VLMs) are good at recognizing the global location of a photograph -- their geolocation prediction accuracy rivals the best human experts. But many VLMs are startlingly bad at explaining which image evidence led to their prediction, even when their location prediction is correct. The reasoning chains produced by VLMs frequently hallucinate scene attributes to support their location prediction (e.g. phantom writing, imagined infrastructure, misidentified flora). In this paper, we introduce the first benchmark for geolocation reasoning chains. We focus on the global location prediction task in the popular GeoGuessr game which draws from Google Street View spanning more than 100 countries. We collaborate with expert GeoGuessr players, including the reigning world champion, to produce 800 ground truth reasoning chains for 500 query scenes. These expert reasoning chains address hundreds of different discriminative visual attributes such as license plate shape, architecture, and soil properties to name just a few. We evaluate LLM-as-a-judge and VLM-as-a-judge strategies for scoring VLM-generated reasoning chains against our expert reasoning chains and find that Qwen 3 LLM-as-a-judge correlates best with human scoring. Our benchmark reveals that while large, closed-source VLMs such as Gemini and GPT 5 rival human experts at prediction locations, they still lag behind human experts when it comes to producing auditable reasoning chains. Open weights VLMs such as Llama and Qwen catastrophically fail on our benchmark -- they perform only slightly better than a baseline in which an LLM hallucinates a reasoning chain with oracle knowledge of the photo location but no visual information at all. We believe the gap between human experts and VLMs on this task points to VLM limitations at extracting fine-grained visual attributes from high resolution images.

</details>


### [129] [Token Entropy Regularization for Multi-modal Antenna Affiliation Identification](https://arxiv.org/abs/2601.21280)
*Dong Chen,Ruoyu Li,Xinyan Zhang,Jialei Xu,Ruoseng Zhao,Zhikang Zhang,Lingyun Li,Zizhuang Wei*

Main category: cs.CV

TL;DR: 提出了一种融合视频、天线几何特征和PCI信号的多模态方法，用于自动识别基站天线归属，并引入了Token熵正则化（TER）模块加速预训练和提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前手动进行天线归属识别的方法效率低下且容易出错，需要一种更自动化的方法。

Method: 将天线归属识别转化为多模态分类和匹配任务，融合视频、天线几何特征和PCI信号。提出了一种专门的预训练框架，并引入了Token熵正则化（TER）模块来解决跨模态对齐问题。

Result: TER模块加速了模型的收敛，并显著提升了性能。实验发现，第一个Token的熵具有模态依赖性。

Conclusion: 所提出的多模态方法结合TER模块，能够有效地进行天线归属识别，克服了现有技术在跨模态对齐方面的挑战。

Abstract: Accurate antenna affiliation identification is crucial for optimizing and maintaining communication networks. Current practice, however, relies on the cumbersome and error-prone process of manual tower inspections. We propose a novel paradigm shift that fuses video footage of base stations, antenna geometric features, and Physical Cell Identity (PCI) signals, transforming antenna affiliation identification into multi-modal classification and matching tasks. Publicly available pretrained transformers struggle with this unique task due to a lack of analogous data in the communications domain, which hampers cross-modal alignment. To address this, we introduce a dedicated training framework that aligns antenna images with corresponding PCI signals. To tackle the representation alignment challenge, we propose a novel Token Entropy Regularization module in the pretraining stage. Our experiments demonstrate that TER accelerates convergence and yields significant performance gains. Further analysis reveals that the entropy of the first token is modality-dependent. Code will be made available upon publication.

</details>


### [130] [Mam-App: A Novel Parameter-Efficient Mamba Model for Apple Leaf Disease Classification](https://arxiv.org/abs/2601.21307)
*Md Nadim Mahamood,Md Imran Hasan,Md Rasheduzzaman,Ausrukona Ray,Md Shafi Ud Doula,Kamrul Hasan*

Main category: cs.CV

TL;DR: 本文提出了一种名为Mam-App的参数高效Mamba模型，用于提取特征和分类苹果叶片疾病。该模型在性能与效率之间取得了良好平衡，在苹果叶片疾病数据集上达到了99.58%的准确率，且参数量仅为0.051M，适用于资源受限的设备。该模型在玉米和马铃薯叶片疾病数据集上表现也同样出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有深度学习模型参数量大、训练和推理时间长的问题，同时克服轻量级模型性能下降的缺点，研究者旨在开发一种在效率和性能之间取得平衡的模型，以满足资源受限应用的需求。

Method: 研究者提出了一种名为Mam-App的参数高效Mamba模型，该模型用于特征提取和叶片疾病分类。该模型在PlantVillage苹果叶片疾病数据集上进行了训练和评估，并进一步在PlantVillage玉米叶片疾病和马铃薯叶片疾病数据集上进行了泛化性验证。

Result: Mam-App模型在PlantVillage苹果叶片疾病数据集上取得了99.58%的准确率、99.30%的精确率、99.14%的召回率和99.22%的F1分数，同时参数量仅为0.051M。在玉米叶片疾病数据集上，模型准确率达到99.48%，在马铃薯叶片疾病数据集上，模型准确率达到98.46%。

Conclusion: Mam-App模型是一种参数高效且性能优越的Mamba模型，能够有效地进行叶片疾病分类，并适用于无人机、移动设备等资源受限的平台。该模型在多个数据集上都展现了其鲁棒性和泛化能力。

Abstract: The rapid growth of the global population, alongside exponential technological advancement, has intensified the demand for food production. Meeting this demand depends not only on increasing agricultural yield but also on minimizing food loss caused by crop diseases. Diseases account for a substantial portion of apple production losses, despite apples being among the most widely produced and nutritionally valuable fruits worldwide. Previous studies have employed machine learning techniques for feature extraction and early diagnosis of apple leaf diseases, and more recently, deep learning-based models have shown remarkable performance in disease recognition. However, most state-of-the-art deep learning models are highly parameter-intensive, resulting in increased training and inference time. Although lightweight models are more suitable for user-friendly and resource-constrained applications, they often suffer from performance degradation. To address the trade-off between efficiency and performance, we propose Mam-App, a parameter-efficient Mamba-based model for feature extraction and leaf disease classification. The proposed approach achieves competitive state-of-the-art performance on the PlantVillage Apple Leaf Disease dataset, attaining 99.58% accuracy, 99.30% precision, 99.14% recall, and a 99.22% F1-score, while using only 0.051M parameters. This extremely low parameter count makes the model suitable for deployment on drones, mobile devices, and other low-resource platforms. To demonstrate the robustness and generalizability of the proposed model, we further evaluate it on the PlantVillage Corn Leaf Disease and Potato Leaf Disease datasets. The model achieves 99.48%, 99.20%, 99.34%, and 99.27% accuracy, precision, recall, and F1-score on the corn dataset and 98.46%, 98.91%, 95.39%, and 97.01% on the potato dataset, respectively.

</details>


### [131] [HiFi-Mesh: High-Fidelity Efficient 3D Mesh Generation via Compact Autoregressive Dependence](https://arxiv.org/abs/2601.21314)
*Yanfeng Li,Tao Tan,Qingquan Gao,Zhiwen Cao,Xiaohong liu,Yue Sun*

Main category: cs.CV

TL;DR: 提出了一种名为 LANE 的新方法，该方法使用紧凑的自回归依赖性来提高 3D 网格生成中可处理的最大序列长度，并结合 AdaGraph 策略来加速推理，从而在速度、细节和一致性方面取得更好的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的将 3D 网格转为 1D 序列并使用自回归模型的方法存在资源利用率不足的问题，导致推理速度慢且只能处理小规模序列，限制了表达的结构细节。研究者希望提高处理能力和生成质量。

Method: 引入了 Latent Autoregressive Network (LANE)，它在生成过程中加入了紧凑的自回归依赖性。为了进一步加速推理，提出了 Adaptive Computation Graph Reconfiguration (AdaGraph) 策略，通过时空解耦克服了传统串行推理的效率瓶颈。

Result: LANE 在可生成序列的最大长度方面比现有方法提高了 6 倍。AdaGraph 策略有效克服了效率瓶颈。实验证明，LANE 在生成速度、结构细节和几何一致性方面均表现出色。

Conclusion: LANE 结合 AdaGraph 策略为高质量 3D 网格生成提供了一个有效的解决方案，显著提高了生成速度并能处理更复杂的结构细节。

Abstract: High-fidelity 3D meshes can be tokenized into one-dimension (1D) sequences and directly modeled using autoregressive approaches for faces and vertices. However, existing methods suffer from insufficient resource utilization, resulting in slow inference and the ability to handle only small-scale sequences, which severely constrains the expressible structural details. We introduce the Latent Autoregressive Network (LANE), which incorporates compact autoregressive dependencies in the generation process, achieving a $6\times$ improvement in maximum generatable sequence length compared to existing methods. To further accelerate inference, we propose the Adaptive Computation Graph Reconfiguration (AdaGraph) strategy, which effectively overcomes the efficiency bottleneck of traditional serial inference through spatiotemporal decoupling in the generation process. Experimental validation demonstrates that LANE achieves superior performance across generation speed, structural detail, and geometric consistency, providing an effective solution for high-quality 3D mesh generation.

</details>


### [132] [WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models](https://arxiv.org/abs/2601.21282)
*Rishi Upadhyay,Howard Zhang,Jim Solomon,Ayush Agrawal,Pranay Boreddy,Shruti Satya Narayana,Yunhao Ba,Alex Wong,Celso M de Melo,Achuta Kadambi*

Main category: cs.CV

TL;DR: 本文提出了一个名为WorldBench的新视频基准，用于评估生成式世界模型的物理保真度。与现有基准的纠缠不清不同，WorldBench可以隔离评估单个物理概念或规律，分为直观物理理解和低级物理常数/材料属性两类。对现有SOTA模型进行评估后发现，模型在特定物理概念上存在普遍性的失败模式，且缺乏生成可靠的真实世界交互所需的物理一致性。WorldBench提供了一个更细致、可扩展的框架来严格评估视频生成和世界模型的物理推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频的物理基准存在纠缠问题，即一个测试同时评估多个物理定律和概念，这限制了模型的诊断能力。为了在机器人规划和自主系统训练等关键任务中可靠地部署生成式世界模型，需要对其物理保真度进行准确评估，即模型能否准确模拟现实世界动力学。因此，需要一个能够隔离和评估单个物理概念或定律的模型。

Method: 本文提出了WorldBench，一个专门设计用于概念特定、解耦评估的视频基准。WorldBench包含两个层级的基准：1) 评估直观物理理解，例如物体持久性、尺度/透视等概念；2) 评估低级物理常数和材料属性，例如摩擦系数、流体粘度等。研究者将SOTA视频基世界模型在该基准上进行评估。

Result: 通过在WorldBench上评估SOTA视频基世界模型，研究者发现了模型在特定物理概念上存在特定的失败模式。所有被测试的模型都缺乏生成可靠的真实世界交互所需的物理一致性。

Conclusion: WorldBench通过其概念特定的评估方式，为严格评估视频生成和世界模型的物理推理能力提供了一个更细致、可扩展的框架。这有助于推动更鲁棒、更具泛化性的世界模型驱动学习的发展。

Abstract: Recent advances in generative foundational models, often termed "world models," have propelled interest in applying them to critical tasks like robotic planning and autonomous system training. For reliable deployment, these models must exhibit high physical fidelity, accurately simulating real-world dynamics. Existing physics-based video benchmarks, however, suffer from entanglement, where a single test simultaneously evaluates multiple physical laws and concepts, fundamentally limiting their diagnostic capability. We introduce WorldBench, a novel video-based benchmark specifically designed for concept-specific, disentangled evaluation, allowing us to rigorously isolate and assess understanding of a single physical concept or law at a time. To make WorldBench comprehensive, we design benchmarks at two different levels: 1) an evaluation of intuitive physical understanding with concepts such as object permanence or scale/perspective, and 2) an evaluation of low-level physical constants and material properties such as friction coefficients or fluid viscosity. When SOTA video-based world models are evaluated on WorldBench, we find specific patterns of failure in particular physics concepts, with all tested models lacking the physical consistency required to generate reliable real-world interactions. Through its concept-specific evaluation, WorldBench offers a more nuanced and scalable framework for rigorously evaluating the physical reasoning capabilities of video generation and world models, paving the way for more robust and generalizable world-model-driven learning.

</details>


### [133] [Optimal Transport-Induced Samples against Out-of-Distribution Overconfidence](https://arxiv.org/abs/2601.21320)
*Keke Tang,Ziyong Du,Xiaofei Wang,Weilong Peng,Peican Zhu,Zhihong Tian*

Main category: cs.CV

TL;DR: 提出了一种基于最优传输（OT）几何学的方法，通过在训练过程中引入OTIS样本并应用置信度抑制损失，来减轻深度神经网络（DNN）在分布外（OOD）输入上的过度自信预测。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）在分布外（OOD）输入上常常做出过度自信的预测，这降低了它们在开放世界环境中的可靠性。研究发现，半离散最优传输（OT）中的奇点区域标记着语义模糊的区域，而分类器在这些区域尤其容易产生不当的高置信度预测。

Method: 1. 建立一个连续基础分布和训练数据潜在嵌入之间的OT问题，并识别由此产生的奇点边界。 2. 通过在这些边界附近采样，构建了一类新的OOD样本，称为最优传输诱导的OOD样本（OTIS）。 3. 在训练过程中，对OTIS样本应用置信度抑制损失，引导模型在结构不确定的区域做出更校准的预测。

Result: 所提出的方法显著减轻了OOD的过度自信问题，并且在实验中表现优于最先进的方法。

Conclusion: 通过利用OT诱导的奇点边界来构建具有几何基础和语义模糊性的OTIS样本，并在训练中使用置信度抑制损失，可以有效地提高DNN在OOD输入上的预测校准性。

Abstract: Deep neural networks (DNNs) often produce overconfident predictions on out-of-distribution (OOD) inputs, undermining their reliability in open-world environments. Singularities in semi-discrete optimal transport (OT) mark regions of semantic ambiguity, where classifiers are particularly prone to unwarranted high-confidence predictions. Motivated by this observation, we propose a principled framework to mitigate OOD overconfidence by leveraging the geometry of OT-induced singular boundaries. Specifically, we formulate an OT problem between a continuous base distribution and the latent embeddings of training data, and identify the resulting singular boundaries. By sampling near these boundaries, we construct a class of OOD inputs, termed optimal transport-induced OOD samples (OTIS), which are geometrically grounded and inherently semantically ambiguous. During training, a confidence suppression loss is applied to OTIS to guide the model toward more calibrated predictions in structurally uncertain regions. Extensive experiments show that our method significantly alleviates OOD overconfidence and outperforms state-of-the-art methods.

</details>


### [134] [Gaussian Belief Propagation Network for Depth Completion](https://arxiv.org/abs/2601.21291)
*Jie Tang,Pingping Xie,Jian Li,Ping Tan*

Main category: cs.CV

TL;DR: 本文提出了一种名为高斯信念传播网络（GBPN）的新型混合框架，结合深度学习和概率图模型，用于端到端的深度补全，在NYUv2和KITTI数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在处理输入深度数据的稀疏性和不规则性方面存在挑战，尤其是在高稀疏度下性能受限，这促使研究者们寻求更有效的方法。

Method: 该方法的核心是GBPN，它包含一个图模型构建网络（GMCN）动态构建场景特定的马尔可夫随机场（MRF），并通过高斯信念传播（GBP）进行推理以获得密集的深度分布。GMCN不仅学习MRF的势函数，还通过预测自适应的非局部边来学习MRF的结构。此外，GBP还通过串并联消息传递方案得到增强，以有效地传播信息，特别是来自稀疏测量的信息。

Result: 在NYUv2和KITTI数据集上的广泛实验表明，GBPN达到了SOTA性能。在不同稀疏度、稀疏模式和数据集上的评估结果凸显了GBPN的优越性能、显著的鲁棒性和泛化能力。

Conclusion: GBPN通过整合深度学习和概率图模型，成功地克服了传统深度学习方法在处理稀疏深度数据方面的局限性，实现了端到端的深度补全，并在多个基准测试中取得了最先进的成果，表现出良好的鲁棒性和泛化性。

Abstract: Depth completion aims to predict a dense depth map from a color image with sparse depth measurements. Although deep learning methods have achieved state-of-the-art (SOTA), effectively handling the sparse and irregular nature of input depth data in deep networks remains a significant challenge, often limiting performance, especially under high sparsity. To overcome this limitation, we introduce the Gaussian Belief Propagation Network (GBPN), a novel hybrid framework synergistically integrating deep learning with probabilistic graphical models for end-to-end depth completion. Specifically, a scene-specific Markov Random Field (MRF) is dynamically constructed by the Graphical Model Construction Network (GMCN), and then inferred via Gaussian Belief Propagation (GBP) to yield the dense depth distribution. Crucially, the GMCN learns to construct not only the data-dependent potentials of MRF but also its structure by predicting adaptive non-local edges, enabling the capture of complex, long-range spatial dependencies. Furthermore, we enhance GBP with a serial \& parallel message passing scheme, designed for effective information propagation, particularly from sparse measurements. Extensive experiments demonstrate that GBPN achieves SOTA performance on the NYUv2 and KITTI benchmarks. Evaluations across varying sparsity levels, sparsity patterns, and datasets highlight GBPN's superior performance, notable robustness, and generalizable capability.

</details>


### [135] [SR$^{2}$-Net: A General Plug-and-Play Model for Spectral Refinement in Hyperspectral Image Super-Resolution](https://arxiv.org/abs/2601.21338)
*Ji-Xuan He,Guohang Zhuang,Junge Bo,Tingyi Li,Chen Ling,Yanan Qiao*

Main category: cs.CV

TL;DR: 本文提出了一种名为SR^2-Net的轻量级即插即用模块，用于高光谱图像超分辨率（HSI-SR），通过增强谱-空协同注意力和流形一致性校正来解决现有方法光谱不一致和物理不合理的问题，并引入降级一致性损失以提高数据保真度，实验证明该方法在不显著增加计算开销的情况下提高了光谱保真度和重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有HSI-SR方法在利用空间相关性提升分辨率的同时，往往忽略了光谱一致性，导致重建结果出现虚假振荡和物理上不合理的伪影。通过修改网络架构来解决光谱一致性问题会降低方法的通用性和灵活性。

Method: 提出了一种名为SR^2-Net的轻量级即插即用模块，采用“增强-校正”的流水线。其中，“增强”部分包含分层谱-空协同注意力（H-S^3A）来加强跨波段交互；“校正”部分采用流形一致性校正（MCR）来约束重建的光谱使其位于紧凑、物理上合理的光谱流形内。此外，引入了降级一致性损失来确保降级后的超分辨率输出与观测到的低分辨率输入匹配，以增强数据保真度。

Result: 在多个基准和不同的骨干网络上进行的大量实验表明，SR^2-Net能够持续提高光谱保真度和整体重建质量，并且计算开销极小。

Conclusion: SR^2-Net作为一个轻量级的即插即用模块，能够有效地集成到现有的HSI-SR模型中，无需修改其架构，显著提高了光谱保真度和物理合理性，同时保持了较低的计算成本。

Abstract: HSI-SR aims to enhance spatial resolution while preserving spectrally faithful and physically plausible characteristics. Recent methods have achieved great progress by leveraging spatial correlations to enhance spatial resolution. However, these methods often neglect spectral consistency across bands, leading to spurious oscillations and physically implausible artifacts. While spectral consistency can be addressed by designing the network architecture, it results in a loss of generality and flexibility. To address this issue, we propose a lightweight plug-and-play rectifier, physically priors Spectral Rectification Super-Resolution Network (SR$^{2}$-Net), which can be attached to a wide range of HSI-SR models without modifying their architectures. SR$^{2}$-Net follows an enhance-then-rectify pipeline consisting of (i) Hierarchical Spectral-Spatial Synergy Attention (H-S$^{3}$A) to reinforce cross-band interactions and (ii) Manifold Consistency Rectification (MCR) to constrain the reconstructed spectra to a compact, physically plausible spectral manifold. In addition, we introduce a degradation-consistency loss to enforce data fidelity by encouraging the degraded SR output to match the observed low resolution input. Extensive experiments on multiple benchmarks and diverse backbones demonstrate consistent improvements in spectral fidelity and overall reconstruction quality with negligible computational overhead. Our code will be released upon publication.

</details>


### [136] [Dynamical Adapter Fusion: Constructing A Global Adapter for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2601.21341)
*Ruiqi Liu,Boyu Diao,Zijia An,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.CV

TL;DR: 本文提出了一种动态适配器融合 (DAF) 方法，通过融合旧的全局适配器、优化的任务特定适配器和初始化参数来构建一个鲁棒的全局适配器，以解决类别增量学习中的知识遗忘和参数冲突问题。


<details>
  <summary>Details</summary>
Motivation: 现有的类别增量学习方法通常采用冻结预训练模型并训练轻量级适配器，但这限制了知识迁移并增加了存储成本。直接融合参数会导致灾难性遗忘。因此，需要一种能够有效平衡稳定性和可塑性，并实现知识迁移的 CIL 方法。

Method: 基于 PAC-Bayes 定理，推导了一个适配器融合机制，该机制显式地整合了三个组件：优化的任务特定适配器参数、先前的全局适配器参数和初始化参数。利用损失函数的泰勒展开来推导最优融合系数，从而动态地平衡稳定性和可塑性。此外，提出了一种鲁棒初始化策略来捕获全局知识模式。

Result: 在多个 CIL 基准测试上，DAF 取得了最先进 (SOTA) 的性能。

Conclusion: DAF 是一种有效的类别增量学习方法，通过动态融合适配器参数，能够实现知识的有效迁移和旧知识的保持，从而克服了现有方法的局限性。

Abstract: Class-Incremental Learning (CIL) requires models to continuously acquire new classes without forgetting previously learned ones. A dominant paradigm involves freezing a pre-trained model and training lightweight, task-specific adapters. However, maintaining task-specific parameters hinders knowledge transfer and incurs high retrieval costs, while naive parameter fusion often leads to destructive interference and catastrophic forgetting. To address these challenges, we propose Dynamical Adapter Fusion (DAF) to construct a single robust global adapter. Grounded in the PAC-Bayes theorem, we derive a fusion mechanism that explicitly integrates three components: the optimized task-specific adapter parameters, the previous global adapter parameters, and the initialization parameters. We utilize the Taylor expansion of the loss function to derive the optimal fusion coefficients, dynamically achieving the best balance between stability and plasticity. Furthermore, we propose a Robust Initialization strategy to effectively capture global knowledge patterns. Experiments on multiple CIL benchmarks demonstrate that DAF achieves state-of-the-art (SOTA) performance.

</details>


### [137] [Semantic-Guided Dynamic Sparsification for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2601.21345)
*Ruiqi Liu,Boyu Diao,Zijia An,Runjie Shao,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.CV

TL;DR: 提出了一种名为SGDS（语义引导动态稀疏化）的新方法，用于解决类别增量学习中的遗忘问题。SGDS通过操纵激活空间的子空间方向和秩来促进知识迁移和防止干扰，而无需限制模型参数。


<details>
  <summary>Details</summary>
Motivation: 现有的类别增量学习方法通过冻结预训练模型并使用轻量级适配器，通常强制参数正交化以防止任务间干扰，但这种参数约束会损害模型的塑性。因此，研究者希望找到一种既能防止遗忘又能保持模型塑性的方法。

Method: 提出SGDS方法，通过在激活空间中进行有针对性的稀疏化来主动引导激活空间的张成和秩。具体而言，SGDS鼓励相似类别共享一个紧凑的激活子空间以促进知识迁移，同时通过分配不重叠的激活子空间来防止不相似类别之间的干扰。

Result: SGDS通过雕刻激活空间中特定于类别的稀疏子空间，有效地减轻了干扰，而无需对参数空间施加严格的约束。在多个基准数据集上的广泛实验证明了SGDS的先进性能。

Conclusion: SGDS是一种有效的方法，可以在不牺牲模型塑性的情况下解决类别增量学习中的遗忘问题，通过在激活空间中动态管理子空间来实现知识的有效迁移和干扰的最小化。

Abstract: Class-Incremental Learning (CIL) requires a model to continually learn new classes without forgetting old ones. A common and efficient solution freezes a pre-trained model and employs lightweight adapters, whose parameters are often forced to be orthogonal to prevent inter-task interference. However, we argue that this parameter-constraining method is detrimental to plasticity. To this end, we propose Semantic-Guided Dynamic Sparsification (SGDS), a novel method that proactively guides the activation space by governing the orientation and rank of its subspaces through targeted sparsification. Specifically, SGDS promotes knowledge transfer by encouraging similar classes to share a compact activation subspace, while simultaneously preventing interference by assigning non-overlapping activation subspaces to dissimilar classes. By sculpting class-specific sparse subspaces in the activation space, SGDS effectively mitigates interference without imposing rigid constraints on the parameter space. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SGDS.

</details>


### [138] [Do Pathology Foundation Models Encode Disease Progression? A Pseudotime Analysis of Visual Representations](https://arxiv.org/abs/2601.21334)
*Pritika Vig,Ren-Chin Wu,William Lotter*

Main category: cs.CV

TL;DR: 本文研究了视觉基础模型（vision foundation models）是否能从离散图像中学习到连续过程的表征。通过将扩散伪时间（diffusion pseudotime）应用于病理图像，发现这些模型确实能捕捉到疾病进展的连续性，并且轨迹保真度（trajectory fidelity）与模型的下游任务性能相关，是一种衡量模型表征质量的新方法。


<details>
  <summary>Details</summary>
Motivation: 在计算病理学中，疾病的发生和发展是一个连续的过程。研究者希望了解视觉基础模型是否能捕捉到这种连续的疾病进展信息，因为这可能有助于提高模型的泛化能力、支持更精细的生物学分析，并更好地反映潜在的生物学机制。

Method: 研究者将一种从单细胞转录组学中推断发育轨迹的方法——扩散伪时间（diffusion pseudotime），应用于视觉基础模型在病理图像上的表征空间。通过分析模型在四种癌症进展数据上的表现，评估其表征空间是否能组织疾病状态沿连贯的进展方向。同时，比较了不同模型的轨迹保真度，并将其与少样本分类性能进行关联分析。

Result: 所有针对病理学训练的基础模型都能显著优于基线水平，在表示疾病状态的连续进展方面表现出一致的轨迹排序。视觉基础模型（vision-only models）在结直肠癌（CRC-Serrated）数据集上表现出最高的轨迹保真度（τ > 0.78）。模型的轨迹保真度排名能有效预测其在未见过疾病上的少样本分类性能（ρ = 0.92）。此外，研究还发现细胞类型组成沿推断出的轨迹平滑变化，这与已知的基质重塑模式一致。

Conclusion: 视觉基础模型能够从独立的静态图像观测中隐式地学习到连续过程的表征。轨迹保真度是一种有价值的表征质量评估指标，它提供了超越传统下游任务性能的补充信息。该框架不仅适用于病理学，还可以推广到其他通过静态快照观察连续过程的领域。

Abstract: Vision foundation models trained on discretely sampled images achieve strong performance on classification benchmarks, yet whether their representations encode the continuous processes underlying their training data remains unclear. This question is especially pertinent in computational pathology, where we posit that models whose latent representations implicitly capture continuous disease progression may better reflect underlying biology, support more robust generalization, and enable quantitative analyses of features associated with disease transitions. Using diffusion pseudotime, a method developed to infer developmental trajectories from single-cell transcriptomics, we probe whether foundation models organize disease states along coherent progression directions in representation space. Across four cancer progressions and six models, we find that all pathology-specific models recover trajectory orderings significantly exceeding null baselines, with vision-only models achieving the highest fidelities $(τ> 0.78$ on CRC-Serrated). Model rankings by trajectory fidelity on reference diseases strongly predict few-shot classification performance on held-out diseases ($ρ= 0.92$), and exploratory analysis shows cell-type composition varies smoothly along inferred trajectories in patterns consistent with known stromal remodeling. Together, these results demonstrate that vision foundation models can implicitly learn to represent continuous processes from independent static observations, and that trajectory fidelity provides a complementary measure of representation quality beyond downstream performance. While demonstrated in pathology, this framework could be applied to other domains where continuous processes are observed through static snapshots.

</details>


### [139] [Towards Geometry-Aware and Motion-Guided Video Human Mesh Recovery](https://arxiv.org/abs/2601.21376)
*Hongjun Chen,Huan Zheng,Wencheng Han,Jianbing Shen*

Main category: cs.CV

TL;DR: 提出了一种名为 HMRMamba 的新型视频人物三维网格恢复方法，该方法利用结构化状态空间模型（SSM）来解决现有方法在物理合理性和时空动力学建模方面的不足，显著提高了重建精度和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频的人物三维网格恢复方法常产生物理上不合理的中间结果，原因是它们依赖于有缺陷的 3D 姿态锚点，并且难以有效建模复杂时空动力学。

Method: HMRMamba 框架包含两个核心模块：1. **几何感知提升模块**：采用新颖的双扫描 Mamba 架构，直接利用图像特征的几何线索对 2D 到 3D 的姿态提升过程进行约束，生成稳定可靠的 3D 姿态序列作为基础。2. **运动引导重建网络**：利用上述姿态序列作为锚点，明确地处理随时间变化的运动学模式，通过引入时间感知来增强最终网格的连贯性和鲁棒性，尤其在遮挡和运动模糊情况下。

Result: 在 3DPW, MPI-INF-3DHP 和 Human3.6M 数据集上进行了全面评估，HMRMamba 在重建精度和时间一致性方面均超越现有方法，并取得了更好的计算效率，达到了新的 state-of-the-art 水平。

Conclusion: HMRMamba 通过引入 SSM 和新的模块设计，成功解决了视频人物三维网格恢复中的关键挑战，提供了一种更准确、更鲁棒且更高效的解决方案。

Abstract: Existing video-based 3D Human Mesh Recovery (HMR) methods often produce physically implausible results, stemming from their reliance on flawed intermediate 3D pose anchors and their inability to effectively model complex spatiotemporal dynamics. To overcome these deep-rooted architectural problems, we introduce HMRMamba, a new paradigm for HMR that pioneers the use of Structured State Space Models (SSMs) for their efficiency and long-range modeling prowess. Our framework is distinguished by two core contributions. First, the Geometry-Aware Lifting Module, featuring a novel dual-scan Mamba architecture, creates a robust foundation for reconstruction. It directly grounds the 2D-to-3D pose lifting process with geometric cues from image features, producing a highly reliable 3D pose sequence that serves as a stable anchor. Second, the Motion-guided Reconstruction Network leverages this anchor to explicitly process kinematic patterns over time. By injecting this crucial temporal awareness, it significantly enhances the final mesh's coherence and robustness, particularly under occlusion and motion blur. Comprehensive evaluations on 3DPW, MPI-INF-3DHP, and Human3.6M benchmarks confirm that HMRMamba sets a new state-of-the-art, outperforming existing methods in both reconstruction accuracy and temporal consistency while offering superior computational efficiency.

</details>


### [140] [Rectifying Geometry-Induced Similarity Distortions for Real-World Aerial-Ground Person Re-Identification](https://arxiv.org/abs/2601.21405)
*Kailash A. Hambarde,Hugo Proença*

Main category: cs.CV

TL;DR: 本文提出了一种名为GIQT的新模块，用于解决航空-地面行人重识别（AG-ReID）中的几何畸变问题，通过显式地调整查询-键相似度来补偿相机几何造成的失真，并在现有基准测试中取得了显著的鲁棒性提升。


<details>
  <summary>Details</summary>
Motivation: 现有AG-ReID方法在处理极端视角和距离差异时，依赖的基于点积的注意力相似度计算会因几何畸变而失效，即使特征表示部分对齐也无法保证匹配的准确性。

Method: 提出了几何诱导查询-键变换（GIQT）模块，这是一个轻量级的低秩模块，通过将查询-键交互条件化于相机几何来显式地校正相似度空间。此外，还引入了一个几何条件化的提示生成机制，从相机几何中提取全局、视图自适应的表示先验。

Result: 在四个AG-ReID基准测试中，该框架在极端和先前未见的几何条件下持续提高了鲁棒性，并且计算开销与现有最先进方法相比极小。

Conclusion: GIQT模块能够通过补偿几何诱导的各向异性畸变来有效解决AG-ReID中的几何挑战，为处理视角和尺度差异大的跨域行人重识别问题提供了一种新颖且高效的解决方案。

Abstract: Aerial-ground person re-identification (AG-ReID) is fundamentally challenged by extreme viewpoint and distance discrepancies between aerial and ground cameras, which induce severe geometric distortions and invalidate the assumption of a shared similarity space across views. Existing methods primarily rely on geometry-aware feature learning or appearance-conditioned prompting, while implicitly assuming that the geometry-invariant dot-product similarity used in attention mechanisms remains reliable under large viewpoint and scale variations. We argue that this assumption does not hold. Extreme camera geometry systematically distorts the query-key similarity space and degrades attention-based matching, even when feature representations are partially aligned.
  To address this issue, we introduce Geometry-Induced Query-Key Transformation (GIQT), a lightweight low-rank module that explicitly rectifies the similarity space by conditioning query-key interactions on camera geometry. Rather than modifying feature representations or the attention formulation itself, GIQT adapts the similarity computation to compensate for dominant geometry-induced anisotropic distortions. Building on this local similarity rectification, we further incorporate a geometry-conditioned prompt generation mechanism that provides global, view-adaptive representation priors derived directly from camera geometry.
  Experiments on four aerial-ground person re-identification benchmarks demonstrate that the proposed framework consistently improves robustness under extreme and previously unseen geometric conditions, while introducing minimal computational overhead compared to state-of-the-art methods.

</details>


### [141] [Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation](https://arxiv.org/abs/2601.21406)
*Zihan Su,Hongyang Wei,Kangrui Cen,Yong Wang,Guanhua Chen,Chun Yuan,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本文提出了一种名为UniMRG的后训练方法，通过引入辅助生成任务（像素重建、深度估计、分割）来增强统一多模态模型（UMM）的视觉理解能力，并同时提升其生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有UMM的研究主要关注如何利用理解能力提升生成能力，而反向利用生成能力来促进理解能力的研究则鲜有涉及。

Method: UniMRG是一种架构无关的后训练方法。它通过训练UMM同时生成输入图像的多种内在表示（像素、深度、分割）以及执行标准的视觉理解任务。这些多样化的生成任务旨在让UMM捕获图像的外观、空间关系和结构布局等互补信息。

Result: 实验表明，UniMRG显著提升了UMM的细粒度感知能力，减少了模型生成内容中的幻觉，并增强了空间理解能力。同时，该方法也对UMM的生成能力有积极影响。

Conclusion: UniMRG是一种简单有效的方法，通过引入多样的辅助生成任务，可以有效提升UMM的视觉理解和生成能力，实现理解和生成之间的相互促进。

Abstract: Unified Multimodal Models (UMMs) integrate both visual understanding and generation within a single framework. Their ultimate aspiration is to create a cycle where understanding and generation mutually reinforce each other. While recent post-training methods have successfully leveraged understanding to enhance generation, the reverse direction of utilizing generation to improve understanding remains largely unexplored. In this work, we propose UniMRG (Unified Multi-Representation Generation), a simple yet effective architecture-agnostic post-training method. UniMRG enhances the understanding capabilities of UMMs by incorporating auxiliary generation tasks. Specifically, we train UMMs to generate multiple intrinsic representations of input images, namely pixel (reconstruction), depth (geometry), and segmentation (structure), alongside standard visual understanding objectives. By synthesizing these diverse representations, UMMs capture complementary information regarding appearance, spatial relations, and structural layout. Consequently, UMMs develop a deeper and more comprehensive understanding of visual inputs. Extensive experiments across diverse UMM architectures demonstrate that our method notably enhances fine-grained perception, reduces hallucinations, and improves spatial understanding, while simultaneously boosting generation capabilities.

</details>


### [142] [MPF-Net: Exposing High-Fidelity AI-Generated Video Forgeries via Hierarchical Manifold Deviation and Micro-Temporal Fluctuations](https://arxiv.org/abs/2601.21408)
*Xinan He,Kaiqing Lin,Yue Zhou,Jiaming Zhong,Wei Ye,Wenhui Yi,Bing Fan,Feng Ding,Haodong Li,Bo Cao,Bin Li*

Main category: cs.CV

TL;DR: 提出了一种名为“流形投影波动”（MPF）的新现象，该现象是AI生成视频中连续帧残差像素的结构化和同质化特征。基于此，提出了一种分层双路径框架，利用视觉基础模型捕捉空间异常，并分析微观时间波动以检测伪造视频。


<details>
  <summary>Details</summary>
Motivation: 尽管先进的AI视频生成模型在视觉质量上取得了巨大进步，但宏观语义错误和时间不一致性已大大减少，区分真实和虚假视频仍具挑战性。研究人员认为AI生成的视频源于流形拟合过程，导致其像素构成逻辑与物理记录不同，存在可追踪的特征。

Method: 提出了一种分层双路径框架。第一条路径“静态流形偏差分支”利用大型视觉基础模型（VFMs）的感知边界来检测偏离自然真实世界流形的残余空间异常。对于未被空间检测到的视频，第二条“微观时间波动分支”通过分析即使在视觉完美的序列中仍然存在的MPF来作为细粒度过滤器。

Result: 该框架能够检测出伪造视频，无论伪造表现为全局真实世界流形偏差还是细微的计算指纹。

Conclusion: AI生成的视频由于其流形拟合的本质，存在一种名为“流形投影波动”（MPF）的固有特征。该研究提出了一种创新的分层双路径检测框架，能够有效地识别出伪造视频，解决了当前高保真AI视频难以区分的难题。

Abstract: With the rapid advancement of video generation models such as Veo and Wan, the visual quality of synthetic content has reached a level where macro-level semantic errors and temporal inconsistencies are no longer prominent. However, this does not imply that the distinction between real and cutting-edge high-fidelity fake is untraceable. We argue that AI-generated videos are essentially products of a manifold-fitting process rather than a physical recording. Consequently, the pixel composition logic of consecutive adjacent frames residual in AI videos exhibits a structured and homogenous characteristic. We term this phenomenon `Manifold Projection Fluctuations' (MPF). Driven by this insight, we propose a hierarchical dual-path framework that operates as a sequential filtering process. The first, the Static Manifold Deviation Branch, leverages the refined perceptual boundaries of Large-Scale Vision Foundation Models (VFMs) to capture residual spatial anomalies or physical violations that deviate from the natural real-world manifold (off-manifold). For the remaining high-fidelity videos that successfully reside on-manifold and evade spatial detection, we introduce the Micro-Temporal Fluctuation Branch as a secondary, fine-grained filter. By analyzing the structured MPF that persists even in visually perfect sequences, our framework ensures that forgeries are exposed regardless of whether they manifest as global real-world manifold deviations or subtle computational fingerprints.

</details>


### [143] [Causal World Modeling for Robot Control](https://arxiv.org/abs/2601.21998)
*Lin Li,Qihang Zhang,Yiming Luo,Shuai Yang,Ruilin Wang,Fei Han,Mingrui Yu,Zelin Gao,Nan Xue,Xing Zhu,Yujun Shen,Yinghao Xu*

Main category: cs.CV

TL;DR: 本文提出LingBot-VA，一个结合视频世界模型和视觉-语言预训练的机器人学习新框架，通过自回归扩散模型同时学习帧预测和策略执行，在长时程操作、数据效率和泛化性方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 认识到视频世界建模与视觉-语言预训练相结合可以为机器人学习提供独立且强大的基础，特别是视频世界模型能够理解因果关系并预测未来视觉动态。

Method: 设计了一个名为LingBot-VA的自回归扩散框架，其核心特点包括：1. 使用混合Transformer（MoT）架构构建共享的视觉-动作潜在空间；2. 采用闭环回滚机制持续获取环境反馈；3. 实现异步推理流水线，并行预测动作和执行电机控制。

Result: 在模拟环境和真实世界场景的评估中，LingBot-VA在长时程操控、数据效率和对新配置的泛化能力方面展现出显著的潜力。

Conclusion: LingBot-VA通过结合视频世界模型和视觉-语言预训练，以及创新的框架设计，为机器人学习提供了一个高效、通用且数据高效的解决方案，特别是在需要长期规划和适应性的任务中。

Abstract: This work highlights that video world modeling, alongside vision-language pre-training, establishes a fresh and independent foundation for robot learning. Intuitively, video world models provide the ability to imagine the near future by understanding the causality between actions and visual dynamics. Inspired by this, we introduce LingBot-VA, an autoregressive diffusion framework that learns frame prediction and policy execution simultaneously. Our model features three carefully crafted designs: (1) a shared latent space, integrating vision and action tokens, driven by a Mixture-of-Transformers (MoT) architecture, (2) a closed-loop rollout mechanism, allowing for ongoing acquisition of environmental feedback with ground-truth observations, (3) an asynchronous inference pipeline, parallelizing action prediction and motor execution to support efficient control. We evaluate our model on both simulation benchmarks and real-world scenarios, where it shows significant promise in long-horizon manipulation, data efficiency in post-training, and strong generalizability to novel configurations. The code and model are made publicly available to facilitate the community.

</details>


### [144] [MultiModal Fine-tuning with Synthetic Captions](https://arxiv.org/abs/2601.21426)
*Shohei Enomoto,Shin'ya Yamaguchi*

Main category: cs.CV

TL;DR: 本研究提出了一种利用多模态大语言模型（MLLMs）为单模态数据集生成合成图像字幕的方法，以实现多模态微调，从而弥合了多模态预训练和单模态微调之间的差距。该方法通过精心设计的提示词生成高质量字幕，并结合监督对比损失和文本嵌入平均化的推理技术，在图像分类任务中取得了显著的性能提升，尤其是在少样本学习场景下。


<details>
  <summary>Details</summary>
Motivation: 当前的深度神经网络在预训练阶段已转向多模态学习以增强视觉理解，但微调阶段仍普遍采用单模态方式，这限制了预训练多模态表示的优势。研究旨在弥合这一差距，让单模态微调也能受益于多模态预训练。

Method: 1. 利用MLLMs将单模态数据集转换为多模态数据集，通过生成合成图像字幕来进行多模态微调。2. 设计了包含类别标签和领域上下文的提示词，以生成高质量的、针对分类任务的字幕。3. 引入了监督对比损失函数，以鼓励同一类别的表示在微调过程中聚集。4. 提出了一种新的推理技术，利用每张图像多个合成字幕的类别平均文本嵌入。

Result: 在13个图像分类基准测试上的广泛实验表明，该方法优于基线方法，在少样本学习场景下尤其有显著改进。

Conclusion: 该研究建立了一种数据集增强的新范式，有效地弥合了多模态预训练和微调之间的差距，为单模态微调引入多模态能力提供了一种有效途径。

Abstract: In this paper, we address a fundamental gap between pre-training and fine-tuning of deep neural networks: while pre-training has shifted from unimodal to multimodal learning with enhanced visual understanding, fine-tuning predominantly remains unimodal, limiting the benefits of rich pre-trained representations. To bridge this gap, we propose a novel approach that transforms unimodal datasets into multimodal ones using Multimodal Large Language Models (MLLMs) to generate synthetic image captions for fine-tuning models with a multimodal objective. Our method employs carefully designed prompts incorporating class labels and domain context to produce high-quality captions tailored for classification tasks. Furthermore, we introduce a supervised contrastive loss function that explicitly encourages clustering of same-class representations during fine-tuning, along with a new inference technique that leverages class-averaged text embeddings from multiple synthetic captions per image. Extensive experiments across 13 image classification benchmarks demonstrate that our approach outperforms baseline methods, with particularly significant improvements in few-shot learning scenarios. Our work establishes a new paradigm for dataset enhancement that effectively bridges the gap between multimodal pre-training and fine-tuning. Our code is available at https://github.com/s-enmt/MMFT.

</details>


### [145] [Spava: Accelerating Long-Video Understanding via Sequence-Parallelism-aware Approximate Attention](https://arxiv.org/abs/2601.21444)
*Yuxiang Huang,Mingye Li,Xu Han,Chaojun Xiao,Weilin Zhao,Ao Sun,Ziqi Yuan,Hao Zhou,Fandong Meng,Zhiyuan Liu*

Main category: cs.CV

TL;DR: Spava是一个序列并行框架，通过优化的注意力机制加速多GPU上的长视频推理，在不损失性能的情况下实现了显著的速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长视频推理方面效率低下，主要原因是大型多模态模型（LMMs）预填充阶段的密集计算。现有方法要么压缩视觉嵌入，要么在单个GPU上应用稀疏注意力，导致加速有限或性能下降，限制了LMMs处理更长、更复杂的视频。

Method: 提出Spava，一个序列并行框架，通过分布式近似注意力机制减少计算并增加并行度。结合负载均衡和融合前向计算等系统级优化。

Result: Spava在速度上实现了12.72倍、1.70倍和1.18倍的加速，分别优于FlashAttn、ZigZagRing和APB，且没有明显的性能损失。

Conclusion: Spava通过在多GPU上实现高效的长视频推理，克服了现有方法的局限性，能够处理更长的视觉序列，从而提升任务性能。

Abstract: The efficiency of long-video inference remains a critical bottleneck, mainly due to the dense computation in the prefill stage of Large Multimodal Models (LMMs). Existing methods either compress visual embeddings or apply sparse attention on a single GPU, yielding limited acceleration or degraded performance and restricting LMMs from handling longer, more complex videos. To overcome these issues, we propose Spava, a sequence-parallel framework with optimized attention that accelerates long-video inference across multiple GPUs. By distributing approximate attention, Spava reduces computation and increases parallelism, enabling efficient processing of more visual embeddings without compression and thereby improving task performance. System-level optimizations, such as load balancing and fused forward passes, further unleash the potential of Spava, delivering speedups of 12.72x, 1.70x, and 1.18x over FlashAttn, ZigZagRing, and APB, without notable performance loss. Code available at https://github.com/thunlp/APB

</details>


### [146] [From Implicit Ambiguity to Explicit Solidity: Diagnosing Interior Geometric Degradation in Neural Radiance Fields for Dense 3D Scene Understanding](https://arxiv.org/abs/2601.21421)
*Jiangsan Zhao,Jakob Geipel,Kryzysztof Kusnierek*

Main category: cs.CV

TL;DR: 本文研究了NeRF在密集、自遮挡场景下的三维定量分析能力，发现NeRF存在“内部几何退化”（IGD）的根本性失效模式，导致重建结构空洞或碎片化。为解决此问题，作者提出了一种基于稀疏体素栅格化（SVRaster）的显式几何管线，结合SfM特征几何初始化，通过体素网格投影和递归分割来维持物理实体性，显著提高了实例恢复率，并证明显式几何先验对于处理高度自遮挡场景至关重要。


<details>
  <summary>Details</summary>
Motivation: NeRF在多视图重建方面表现出色，但其在密集、自遮挡场景下进行三维定量分析的可靠性仍不明确。研究者希望理解NeRF在该场景下的局限性，并提出改进方法。

Method: 1. 识别NeRF在重度遮挡下的根本性失效模式——“内部几何退化”（IGD），即体积优化会重建空洞或碎片化结构而非实体内部。2. 提出一种基于稀疏体素栅格化（SVRaster）的显式几何管线，该管线从SfM特征几何初始化，将2D实例掩膜投影到显式体素网格上，并通过递归分割强制执行几何分离。

Result: 在合成数据集上，尽管改进的掩膜监督NeRF在表面一致性和掩膜质量上有所提升，但在密集场景下实例恢复率饱和在约89%。提出的SVRaster方法将实例恢复率提高到95.8%。在存在分割掩膜退化的情况下，基于SfM的显式几何方法比隐式基线恢复的实例多43%。

Conclusion: 显式几何先验是实现高度自遮挡三维场景可靠定量分析的先决条件。本文提出的SVRaster方法能够克服NeRF在密集、自遮挡场景下的IGD问题，实现更准确的三维重建和实例计数。

Abstract: Neural Radiance Fields (NeRFs) have emerged as a powerful paradigm for multi-view reconstruction, complementing classical photogrammetric pipelines based on Structure-from-Motion (SfM) and Multi-View Stereo (MVS). However, their reliability for quantitative 3D analysis in dense, self-occluding scenes remains poorly understood. In this study, we identify a fundamental failure mode of implicit density fields under heavy occlusion, which we term Interior Geometric Degradation (IGD). We show that transmittance-based volumetric optimization satisfies photometric supervision by reconstructing hollow or fragmented structures rather than solid interiors, leading to systematic instance undercounting. Through controlled experiments on synthetic datasets with increasing occlusion, we demonstrate that state-of-the-art mask-supervised NeRFs saturate at approximately 89% instance recovery in dense scenes, despite improved surface coherence and mask quality. To overcome this limitation, we introduce an explicit geometric pipeline based on Sparse Voxel Rasterization (SVRaster), initialized from SfM feature geometry. By projecting 2D instance masks onto an explicit voxel grid and enforcing geometric separation via recursive splitting, our approach preserves physical solidity and achieves a 95.8% recovery rate in dense clusters. A sensitivity analysis using degraded segmentation masks further shows that explicit SfM-based geometry is substantially more robust to supervision failure, recovering 43% more instances than implicit baselines. These results demonstrate that explicit geometric priors are a prerequisite for reliable quantitative analysis in highly self-occluding 3D scenes.

</details>


### [147] [Variance & Greediness: A comparative study of metric-learning losses](https://arxiv.org/abs/2601.21450)
*Donghuo Zeng,Hao Niu,Zhi Li,Masato Taya*

Main category: cs.CV

TL;DR: 本文提出了一个诊断框架VARIANCE和GREEDINESS，用于比较七种代表性损失函数在图像检索任务中的表现。研究发现Triplet和SCL在细粒度检索中表现更好，而Contrastive和InfoNCE收敛更快。


<details>
  <summary>Details</summary>
Motivation: 现有度量学习对嵌入几何和优化动态的影响尚不清楚，缺乏对不同损失函数性能的深入理解。

Method: 提出VARIANCE（类内/类间方差）和GREEDINESS（激活比率和梯度范数）诊断框架，并在五个图像检索数据集上比较了Contrastive、Triplet、N-pair、InfoNCE、ArcFace、SCL和CCL七种损失函数。

Result: Triplet和SCL在细粒度检索中保持更高的类内方差和更清晰的类间边界，表现出更强的top-1检索性能。Contrastive和InfoNCE通过大量小更新快速压缩嵌入，加速收敛但可能过度简化类别结构。N-pair实现了大的平均分离但间隔不均。

Conclusion: 存在效率-粒度权衡。在需要保留多样性和区分难例时，Triplet/SCL是更好的选择；在需要快速压缩嵌入时，Contrastive/InfoNCE更受欢迎。该研究为损失函数的选择提供了实际指导。

Abstract: Metric learning is central to retrieval, yet its effects on embedding geometry and optimization dynamics are not well understood. We introduce a diagnostic framework, VARIANCE (intra-/inter-class variance) and GREEDINESS (active ratio and gradient norms), to compare seven representative losses, i.e., Contrastive, Triplet, N-pair, InfoNCE, ArcFace, SCL, and CCL, across five image-retrieval datasets. Our analysis reveals that Triplet and SCL preserve higher within-class variance and clearer inter-class margins, leading to stronger top-1 retrieval in fine-grained settings. In contrast, Contrastive and InfoNCE compact embeddings are achieved quickly through many small updates, accelerating convergence but potentially oversimplifying class structures. N-pair achieves a large mean separation but with uneven spacing. These insights reveal a form of efficiency-granularity trade-off and provide practical guidance: prefer Triplet/SCL when diversity preservation and hard-sample discrimination are critical, and Contrastive/InfoNCE when faster embedding compaction is desired.

</details>


### [148] [Mining Forgery Traces from Reconstruction Error: A Weakly Supervised Framework for Multimodal Deepfake Temporal Localization](https://arxiv.org/abs/2601.21458)
*Midou Guo,Qilin Yin,Wei Lu,Xiangyang Luo,Rui Yang*

Main category: cs.CV

TL;DR: 提出了一种名为RT-DeepLoc的弱监督时间深度伪影定位框架，利用掩码自编码器（MAE）和不对称视频内对比损失（AICL）来检测和定位视频中的伪造片段。


<details>
  <summary>Details</summary>
Motivation: 现代深度伪影（deepfakes）具有局部化和间歇性的特点，需要精细的时间定位。由于帧级标注成本高昂，因此需要开发仅依赖视频级标签的弱监督方法。

Method: 该框架使用在真实数据上训练的掩码自编码器（MAE）学习时空模式。通过掩码自编码器对伪造片段产生的重构误差来识别伪影。引入了不对称视频内对比损失（AICL）来稳定地利用重构误差，通过关注真实特征的紧凑性来增强局部判别力。

Result: RT-DeepLoc在LAV-DF等大规模数据集上进行了广泛实验，证明其在弱监督时间伪影定位方面达到了最先进的性能。

Conclusion: RT-DeepLoc是一种有效的弱监督方法，能够通过重构误差和不对称视频内对比损失来精确地定位视频中的深度伪影，并且具有良好的泛化能力。

Abstract: Modern deepfakes have evolved into localized and intermittent manipulations that require fine-grained temporal localization. The prohibitive cost of frame-level annotation makes weakly supervised methods a practical necessity, which rely only on video-level labels. To this end, we propose Reconstruction-based Temporal Deepfake Localization (RT-DeepLoc), a weakly supervised temporal forgery localization framework that identifies forgeries via reconstruction errors. Our framework uses a Masked Autoencoder (MAE) trained exclusively on authentic data to learn its intrinsic spatiotemporal patterns; this allows the model to produce significant reconstruction discrepancies for forged segments, effectively providing the missing fine-grained cues for localization. To robustly leverage these indicators, we introduce a novel Asymmetric Intra-video Contrastive Loss (AICL). By focusing on the compactness of authentic features guided by these reconstruction cues, AICL establishes a stable decision boundary that enhances local discrimination while preserving generalization to unseen forgeries. Extensive experiments on large-scale datasets, including LAV-DF, demonstrate that RT-DeepLoc achieves state-of-the-art performance in weakly-supervised temporal forgery localization.

</details>


### [149] [SimGraph: A Unified Framework for Scene Graph-Based Image Generation and Editing](https://arxiv.org/abs/2601.21498)
*Thanh-Nhan Vo,Trong-Thuan Nguyen,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: 本文提出 SimGraph，一个统一的框架，通过场景图来统一控制图像生成和编辑，解决了现有方法在空间一致性和语义连贯性上的不足，并在实验中证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成和编辑方法通常是分开的，导致效率低下，难以保持空间一致性和语义连贯性。此外，缺乏对对象关系和空间布局的结构化控制。

Method: 提出 SimGraph 框架，将基于场景图的图像生成和编辑集成到一个统一的模型中。该框架结合了 token 生成和 diffusion 编辑，并通过场景图驱动，实现对对象交互、布局和空间连贯性的精确控制。

Result: 通过大量实验表明，SimGraph 在图像生成和编辑方面均优于现有的最先进方法，能够生成高质量且一致的结果。

Conclusion: SimGraph 提供了一个统一的、基于场景图的解决方案，可以有效地控制和执行图像生成与编辑任务，解决了当前方法在一致性和结构化控制方面的挑战。

Abstract: Recent advancements in Generative Artificial Intelligence (GenAI) have significantly enhanced the capabilities of both image generation and editing. However, current approaches often treat these tasks separately, leading to inefficiencies and challenges in maintaining spatial consistency and semantic coherence between generated content and edits. Moreover, a major obstacle is the lack of structured control over object relationships and spatial arrangements. Scene graph-based methods, which represent objects and their interrelationships in a structured format, offer a solution by providing greater control over composition and interactions in both image generation and editing. To address this, we introduce SimGraph, a unified framework that integrates scene graph-based image generation and editing, enabling precise control over object interactions, layouts, and spatial coherence. In particular, our framework integrates token-based generation and diffusion-based editing within a single scene graph-driven model, ensuring high-quality and consistent results. Through extensive experiments, we empirically demonstrate that our approach outperforms existing state-of-the-art methods.

</details>


### [150] [Hypernetwork-Based Adaptive Aggregation for Multimodal Multiple-Instance Learning in Predicting Coronary Calcium Debulking](https://arxiv.org/abs/2601.21479)
*Kaito Shiku,Ichika Seo,Tetsuya Matoba,Rissei Hino,Yasuhiro Nakano,Ryoma Bise*

Main category: cs.CV

TL;DR: 该研究提出了一种名为HyperAdAgFormer的新方法，该方法利用多实例学习和超网络来根据患者的表格数据自适应地聚合CT图像特征，以辅助评估冠状动脉钙化斑块的消融必要性。


<details>
  <summary>Details</summary>
Motivation: 评估冠状动脉钙化斑块是否需要消融具有挑战性，因为医生在决策时会结合患者的表格数据来调整其关注点和决策标准。现有的方法未能有效整合这些信息。

Method: 将问题建模为多实例学习（MIL）问题。提出了一种基于超网络的自适应聚合Transformer（HyperAdAgFormer），该模型通过超网络根据患者的表格数据自适应地调整特征聚合策略。

Result: 在临床数据集上的实验证明了HyperAdAgFormer的有效性。

Conclusion: HyperAdAgFormer能够有效地整合CT图像和患者表格数据，以辅助评估冠状动脉钙化斑块的消融必要性，并能根据患者的具体情况自适应地调整特征聚合策略。

Abstract: In this paper, we present the first attempt to estimate the necessity of debulking coronary artery calcifications from computed tomography (CT) images. We formulate this task as a Multiple-instance Learning (MIL) problem. The difficulty of this task lies in that physicians adjust their focus and decision criteria for device usage according to tabular data representing each patient's condition. To address this issue, we propose a hypernetwork-based adaptive aggregation transformer (HyperAdAgFormer), which adaptively modifies the feature aggregation strategy for each patient based on tabular data through a hypernetwork. The experiments using the clinical dataset demonstrated the effectiveness of HyperAdAgFormer. The code is publicly available at https://github.com/Shiku-Kaito/HyperAdAgFormer.

</details>


### [151] [Vision KAN: Towards an Attention-Free Backbone for Vision with Kolmogorov-Arnold Networks](https://arxiv.org/abs/2601.21541)
*Zhuoqin Yang,Jiansong Zhang,Xiaoling Luo,Xu Wu,Zheng Lu,Linlin Shen*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Vision KAN (ViK) 的无注意力视觉骨干网络，它受 Kolmogorov-Arnold 网络（KANs）的启发，旨在解决现有注意力机制的计算复杂度高和可解释性差的问题。ViK 使用一种名为 MultiPatch-RBFKAN 的统一令牌混合器，结合了径向基函数 KANs、轴向可分离混合和低秩全局映射，实现了线性复杂度下的高精度。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉骨干网络中广泛使用的注意力机制存在二次复杂度导致的可伸缩性问题以及可解释性差的缺点。最近的无注意力架构证明了在不使用注意力的情况下也能取得优异性能，这激发了对注意力机制替代方案的探索。

Method: 本文提出了一种名为 Vision KAN (ViK) 的无注意力视觉骨干网络。其核心是 MultiPatch-RBFKAN，一个统一的令牌混合器，它集成了（a）基于径向基函数的 KANs 的块状非线性变换，（b）用于高效局部传播的轴向可分离混合，以及（c）用于长程交互的低秩全局映射。ViK 通过采用块状分组策略和轻量级算子来恢复跨块依赖，以此作为对注意力模块的即插即用替代方案，解决了在高分辨率特征上使用完整 KANs 的高昂成本问题。

Result: 在 ImageNet-1K 数据集上的实验表明，ViK 实现了具有竞争力的准确率，并且具有线性复杂度。这证明了基于 KAN 的令牌混合作为注意力机制的一种高效且理论上合理的可替代方案的潜力。

Conclusion: Vision KAN (ViK) 是一种创新的无注意力视觉骨干网络，通过 MultiPatch-RBFKAN 令牌混合器，以线性复杂度实现了高性能，为视觉表示学习提供了注意力机制的一个有前途的替代方案。

Abstract: Attention mechanisms have become a key module in modern vision backbones due to their ability to model long-range dependencies. However, their quadratic complexity in sequence length and the difficulty of interpreting attention weights limit both scalability and clarity. Recent attention-free architectures demonstrate that strong performance can be achieved without pairwise attention, motivating the search for alternatives. In this work, we introduce Vision KAN (ViK), an attention-free backbone inspired by the Kolmogorov-Arnold Networks. At its core lies MultiPatch-RBFKAN, a unified token mixer that combines (a) patch-wise nonlinear transform with Radial Basis Function-based KANs, (b) axis-wise separable mixing for efficient local propagation, and (c) low-rank global mapping for long-range interaction. Employing as a drop-in replacement for attention modules, this formulation tackles the prohibitive cost of full KANs on high-resolution features by adopting a patch-wise grouping strategy with lightweight operators to restore cross-patch dependencies. Experiments on ImageNet-1K show that ViK achieves competitive accuracy with linear complexity, demonstrating the potential of KAN-based token mixing as an efficient and theoretically grounded alternative to attention.

</details>


### [152] [Bi-Anchor Interpolation Solver for Accelerating Generative Modeling](https://arxiv.org/abs/2601.21542)
*Hongxu Chen,Hongxiang Li,Zhen Wang,Long Chen*

Main category: cs.CV

TL;DR: 提出了一种名为 BA-solver 的双锚点插值求解器，通过引入一个轻量级的 SideNet 来加速流匹配模型（Flow Matching）的生成过程，在较低的神经函数评估次数（NFEs）下实现与传统方法相当的生成质量，并且易于集成。


<details>
  <summary>Details</summary>
Motivation: 流匹配模型（FM）在生成高质量图像方面表现出色，但其迭代求解常微分方程（ODE）的过程导致生成速度慢（延迟高）。现有的加速方法要么在低 NFEs 时性能下降，要么训练成本高且不灵活。

Method: BA-solver 引入了一个轻量级的 SideNet，与冻结的主干网络协同工作。SideNet 学习近似未来和历史的梯度（双向时间感知），并利用两个锚点梯度（主干网络生成的）来高效地近似中间梯度，从而实现高阶积分（双锚点速度积分）。

Result: 在 ImageNet-256^2 数据集上，BA-solver 在仅 10 NFEs 下生成质量可与 100+ NFEs 的 Euler 求解器媲美，在 5 NFEs 下仍保持高保真度。此外，该方法几乎没有额外的训练成本，且易于与现有模型集成。

Conclusion: BA-solver 成功地解决了 FM 模型延迟高的问题，在保持生成质量的同时显著提高了生成速度，并且具有良好的通用性和低训练成本，为高效的流匹配模型生成提供了新的解决方案。

Abstract: Flow Matching (FM) models have emerged as a leading paradigm for high-fidelity synthesis. However, their reliance on iterative Ordinary Differential Equation (ODE) solving creates a significant latency bottleneck. Existing solutions face a dichotomy: training-free solvers suffer from significant performance degradation at low Neural Function Evaluations (NFEs), while training-based one- or few-steps generation methods incur prohibitive training costs and lack plug-and-play versatility. To bridge this gap, we propose the Bi-Anchor Interpolation Solver (BA-solver). BA-solver retains the versatility of standard training-free solvers while achieving significant acceleration by introducing a lightweight SideNet (1-2% backbone size) alongside the frozen backbone. Specifically, our method is founded on two synergistic components: \textbf{1) Bidirectional Temporal Perception}, where the SideNet learns to approximate both future and historical velocities without retraining the heavy backbone; and 2) Bi-Anchor Velocity Integration, which utilizes the SideNet with two anchor velocities to efficiently approximate intermediate velocities for batched high-order integration. By utilizing the backbone to establish high-precision ``anchors'' and the SideNet to densify the trajectory, BA-solver enables large interval sizes with minimized error. Empirical results on ImageNet-256^2 demonstrate that BA-solver achieves generation quality comparable to 100+ NFEs Euler solver in just 10 NFEs and maintains high fidelity in as few as 5 NFEs, incurring negligible training costs. Furthermore, BA-solver ensures seamless integration with existing generative pipelines, facilitating downstream tasks such as image editing.

</details>


### [153] [HydroSense: A Dual-Microcontroller IoT Framework for Real-Time Multi-Parameter Water Quality Monitoring with Edge Processing and Cloud Analytics](https://arxiv.org/abs/2601.21595)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib,Anish Giri*

Main category: cs.CV

TL;DR: 本文介绍了一种名为HydroSense的低成本、基于物联网的水质监测系统，该系统集成了多种传感器，并通过创新的双微控制器架构实现了精确测量和无线数据传输。


<details>
  <summary>Details</summary>
Motivation: 全球水危机需要负担得起、准确且实时的水质监测解决方案，而传统的、手动或昂贵的商业系统在资源匮乏地区存在可及性挑战。

Method: 该系统采用双微控制器架构，Arduino Uno负责模拟测量和五点校准，ESP32负责无线连接、边缘处理和云集成。集成了pH、DO、温度、TDS、氮和水位传感器，并应用了中值滤波、温度补偿和错误处理等信号处理技术。

Result: 实验验证显示，HydroSense在90天的监测中表现出色，pH准确度为±0.08，DO稳定性为±0.2 mg/L，TDS准确度为±1.9%，云数据传输可靠性为99.8%。总成本约为300美元，比商业系统便宜85%。

Conclusion: HydroSense提供了一种经济高效且性能卓越的水质监测方案，证明通过智能系统设计和成本效益高的组件选择，可以实现专业级的水质评估，为环境监测树立了新的标杆。

Abstract: The global water crisis necessitates affordable, accurate, and real-time water quality monitoring solutions. Traditional approaches relying on manual sampling or expensive commercial systems fail to address accessibility challenges in resource-constrained environments. This paper presents HydroSense, an innovative Internet of Things framework that integrates six critical water quality parameters including pH, dissolved oxygen (DO), temperature, total dissolved solids (TDS), estimated nitrogen, and water level into a unified monitoring system. HydroSense employs a novel dual-microcontroller architecture, utilizing Arduino Uno for precision analog measurements with five-point calibration algorithms and ESP32 for wireless connectivity, edge processing, and cloud integration. The system implements advanced signal processing techniques including median filtering for TDS measurement, temperature compensation algorithms, and robust error handling. Experimental validation over 90 days demonstrates exceptional performance metrics: pH accuracy of plus or minus 0.08 units across the 0 to 14 range, DO measurement stability within plus or minus 0.2 mg/L, TDS accuracy of plus or minus 1.9 percent across 0 to 1000 ppm, and 99.8 percent cloud data transmission reliability. With a total implementation cost of 32,983 BDT (approximately 300 USD), HydroSense achieves an 85 percent cost reduction compared to commercial systems while providing enhanced connectivity through the Firebase real-time database. This research establishes a new paradigm for accessible environmental monitoring, demonstrating that professional-grade water quality assessment can be achieved through intelligent system architecture and cost-effective component selection.

</details>


### [154] [HERS: Hidden-Pattern Expert Learning for Risk-Specific Vehicle Damage Adaptation in Diffusion Models](https://arxiv.org/abs/2601.21517)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: 提出了一种名为 HERS 的框架，通过领域特定专家自适应来改进文本到图像（T2I）模型生成的车辆损伤图像的真实性和可控性，以应对自动保险流程中的滥用风险，并在文本保真度和用户偏好方面取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 文本到图像（T2I）模型在生成逼真的车辆损伤图像方面取得了进展，这引发了对其在自动保险流程中可靠性的担忧，并可能被用于欺诈或索赔操纵。

Method: 提出 HERS（Hidden-Pattern Expert Learning for Risk-Specific Damage Adaptation）框架，通过领域特定专家自适应来微调基础扩散模型，无需人工标注。利用大型语言模型和 T2I 管线自动生成的自监督图像-文本对，将每种损伤类别（如凹痕、划痕、灯光损坏、车漆破裂）建模为单独的专家，然后将这些专家整合到一个统一的多损伤模型中。

Result: 在四个扩散模型骨干上进行了评估，HERS 在文本保真度方面平均提高了 5.5%，在人类偏好评分方面平均提高了 2.3%。

Conclusion: HERS 框架能够提升 T2I 生成的车辆损伤图像的逼真度和可控性，并且在应对保险欺诈、提高审计性和安全部署方面具有重要意义，强调了在自动保险等高风险领域中可信生成的重要性。

Abstract: Recent advances in text-to-image (T2I) diffusion models have enabled increasingly realistic synthesis of vehicle damage, raising concerns about their reliability in automated insurance workflows. The ability to generate crash-like imagery challenges the boundary between authentic and synthetic data, introducing new risks of misuse in fraud or claim manipulation. To address these issues, we propose HERS (Hidden-Pattern Expert Learning for Risk-Specific Damage Adaptation), a framework designed to improve fidelity, controllability, and domain alignment of diffusion-generated damage images. HERS fine-tunes a base diffusion model via domain-specific expert adaptation without requiring manual annotation. Using self-supervised image-text pairs automatically generated by a large language model and T2I pipeline, HERS models each damage category, such as dents, scratches, broken lights, or cracked paint, as a separate expert. These experts are later integrated into a unified multi-damage model that balances specialization with generalization. We evaluate HERS across four diffusion backbones and observe consistent improvements: plus 5.5 percent in text faithfulness and plus 2.3 percent in human preference ratings compared to baselines. Beyond image fidelity, we discuss implications for fraud detection, auditability, and safe deployment of generative models in high-stakes domains. Our findings highlight both the opportunities and risks of domain-specific diffusion, underscoring the importance of trustworthy generation in safety-critical applications such as auto insurance.

</details>


### [155] [Unifying Heterogeneous Degradations: Uncertainty-Aware Diffusion Bridge Model for All-in-One Image Restoration](https://arxiv.org/abs/2601.21592)
*Luwei Tu,Jiawei Wu,Xing Luo,Zhi Jin*

Main category: cs.CV

TL;DR: 提出了一种不确定性感知扩散桥模型（UDBM），将图像修复视为一个由像素级不确定性引导的随机传输问题，以解决多任务图像修复中不同降质的冲突优化目标。


<details>
  <summary>Details</summary>
Motivation: 现有的一体化图像修复（AiOIR）方法在处理异质降质时，由于控制机制粗糙或映射固定，难以协调冲突的优化目标，导致性能不佳。

Method: 提出不确定性感知扩散桥模型（UDBM），将AiOIR重新构建为随机传输问题。核心在于引入松弛的扩散桥公式，用松弛的终端约束替代严格约束，以建模降质的不确定性并解决标准扩散桥的漂移奇点。此外，采用双重调制策略：噪声调度将不同降质映射到共享的高熵潜在空间，路径调度则根据熵正则化的粘性动力学自适应地调整传输轨迹。

Result: UDBM通过有效校正传输的几何和动力学，在单一推理步骤内，实现了跨多种修复任务的先进性能。

Conclusion: UDBM通过将AiOIR视为不确定性引导的随机传输问题，并结合松弛扩散桥和双重调制策略，能够有效处理异质降质，并在不牺牲性能的情况下实现单步推理。

Abstract: All-in-One Image Restoration (AiOIR) faces the fundamental challenge in reconciling conflicting optimization objectives across heterogeneous degradations. Existing methods are often constrained by coarse-grained control mechanisms or fixed mapping schedules, yielding suboptimal adaptation. To address this, we propose an Uncertainty-Aware Diffusion Bridge Model (UDBM), which innovatively reformulates AiOIR as a stochastic transport problem steered by pixel-wise uncertainty. By introducing a relaxed diffusion bridge formulation which replaces the strict terminal constraint with a relaxed constraint, we model the uncertainty of degradations while theoretically resolving the drift singularity inherent in standard diffusion bridges. Furthermore, we devise a dual modulation strategy: the noise schedule aligns diverse degradations into a shared high-entropy latent space, while the path schedule adaptively regulates the transport trajectory motivated by the viscous dynamics of entropy regularization. By effectively rectifying the transport geometry and dynamics, UDBM achieves state-of-the-art performance across diverse restoration tasks within a single inference step.

</details>


### [156] [WMVLM: Evaluating Diffusion Model Image Watermarking via Vision-Language Models](https://arxiv.org/abs/2601.21610)
*Zijin Yang,Yu Sun,Kejiang Chen,Jiawei Zhao,Jun Jiang,Weiming Zhang,Nenghai Yu*

Main category: cs.CV

TL;DR: 提出了一种名为WMVLM的统一且可解释的评估框架，用于评估扩散模型图像水印的质量和安全性，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有水印评估方法缺乏统一框架，无法解释结果，忽略了安全考量，并且对语义水印使用了不恰当的指标。

Method: 提出WMVLM框架，利用视觉语言模型（VLMs）。重新定义了残差水印（通过伪影强度和擦除抵抗力评估）和语义水印（通过潜在分布偏移评估）的质量和安全指标。采用三阶段训练策略，使模型能够进行分类、评分和生成可解释的文本。

Result: WMVLM在跨数据集、扩散模型和水印方法上展现出强大的泛化能力，性能优于现有的最先进VLMs。

Conclusion: WMVLM是首个用于扩散模型图像水印的统一且可解释的评估框架，能更全面、准确地评估水印质量和安全性。

Abstract: Digital watermarking is essential for securing generated images from diffusion models. Accurate watermark evaluation is critical for algorithm development, yet existing methods have significant limitations: they lack a unified framework for both residual and semantic watermarks, provide results without interpretability, neglect comprehensive security considerations, and often use inappropriate metrics for semantic watermarks. To address these gaps, we propose WMVLM, the first unified and interpretable evaluation framework for diffusion model image watermarking via vision-language models (VLMs). We redefine quality and security metrics for each watermark type: residual watermarks are evaluated by artifact strength and erasure resistance, while semantic watermarks are assessed through latent distribution shifts. Moreover, we introduce a three-stage training strategy to progressively enable the model to achieve classification, scoring, and interpretable text generation. Experiments show WMVLM outperforms state-of-the-art VLMs with strong generalization across datasets, diffusion models, and watermarking methods.

</details>


### [157] [PathReasoner-R1: Instilling Structured Reasoning into Pathology Vision-Language Model via Knowledge-Guided Policy Optimization](https://arxiv.org/abs/2601.21617)
*Songhan Jiang,Fengchun Liu,Ziyue Wang,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: 本研究提出了PathReasoner，一个大规模的病理图像推理数据集，以及PathReasoner-R1模型，该模型通过知识引导生成和强化学习来提升病理诊断的可解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有的计算病理学系统在诊断时缺乏可验证的证据链接推理，导致临床信任度不足，且难以纠正错误。

Method: 研究构建了一个知识引导的生成管线，利用医学知识图谱生成了超过20K的病理推理样本。在此基础上，提出了PathReasoner-R1模型，结合了轨迹掩码监督微调和面向推理的强化学习，并设计了一个知识感知的多粒度奖励函数（包含实体奖励机制）来提升模型推理能力。

Result: PathReasoner-R1在PathReasoner数据集和公开基准测试中均取得了最先进的性能，证明了其在不同图像尺度下的鲁棒性和有效的推理能力。

Conclusion: PathReasoner-R1成功地为病理模型赋予了透明、临床基础的推理能力，克服了现有方法的局限性，有望增强临床应用的信任度。

Abstract: Vision-Language Models (VLMs) are advancing computational pathology with superior visual understanding capabilities. However, current systems often reduce diagnosis to directly output conclusions without verifiable evidence-linked reasoning, which severely limits clinical trust and hinders expert error rectification. To address these barriers, we construct PathReasoner, the first large-scale dataset of whole-slide image (WSI) reasoning. Unlike previous work reliant on unverified distillation, we develop a rigorous knowledge-guided generation pipeline. By leveraging medical knowledge graphs, we explicitly align structured pathological findings and clinical reasoning with diagnoses, generating over 20K high-quality instructional samples. Based on the database, we propose PathReasoner-R1, which synergizes trajectory-masked supervised fine-tuning with reasoning-oriented reinforcement learning to instill structured chain-of-thought capabilities. To ensure medical rigor, we engineer a knowledge-aware multi-granular reward function incorporating an Entity Reward mechanism strictly aligned with knowledge graphs. This effectively guides the model to optimize for logical consistency rather than mere outcome matching, thereby enhancing robustness. Extensive experiments demonstrate that PathReasoner-R1 achieves state-of-the-art performance on both PathReasoner and public benchmarks across various image scales, equipping pathology models with transparent, clinically grounded reasoning capabilities. Dataset and code are available at https://github.com/cyclexfy/PathReasoner-R1.

</details>


### [158] [Similarity of Processing Steps in Vision Model Representations](https://arxiv.org/abs/2601.21621)
*Matéo Mahaut,Marco Baroni*

Main category: cs.CV

TL;DR: 本文研究了不同视觉模型在达到相似表示的过程中，其内部中间步骤和操作是否也趋于一致。通过量化不同模型在不同训练阶段表示的距离，发现虽然相似位置的层表示最相似，但仍存在显著差异。CNN 和 Transformer 模型在表示变化上也有所不同。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，模型越大，越容易收敛到相似的“通用”表示。本文旨在深入探究这些表示是如何形成的，特别是模型是否也收敛到相同的中间步骤和操作。

Method: 通过量化不同模型在不同训练阶段表示之间的距离，并追踪这些距离在整个处理过程中的演变，识别出模型之间差异最大的处理步骤。

Result: 1. 相似位置的层在不同模型中具有最相似的表示，但仍存在显著差异。2. 分类模型在其最后几层会丢弃低级图像统计信息。3. CNN 和 Transformer 模型行为不同，Transformer 模型在层与层之间的表示变化更平滑。

Conclusion: 本文阐明了模型表示收敛的程度和性质，并对图像模型潜在过程有了更定性的解释。尽管不同模型最终可能收敛到相似的表示，但它们在达到这些表示的过程中，内部的计算过程和信息处理方式存在显著差异。

Abstract: Recent literature suggests that the bigger the model, the more likely it is to converge to similar, ``universal'' representations, despite different training objectives, datasets, or modalities. While this literature shows that there is an area where model representations are similar, we study here how vision models might get to those representations -- in particular, do they also converge to the same intermediate steps and operations? We therefore study the processes that lead to convergent representations in different models. First, we quantify distance between different model representations at different stages. We follow the evolution of distances between models throughout processing, identifying the processing steps which are most different between models. We find that while layers at similar positions in different models have the most similar representations, strong differences remain. Classifier models, unlike the others, will discard information about low-level image statistics in their final layers. CNN- and transformer-based models also behave differently, with transformer models applying smoother changes to representations from one layer to the next. These distinctions clarify the level and nature of convergence between model representations, and enables a more qualitative account of the underlying processes in image models.

</details>


### [159] [OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models](https://arxiv.org/abs/2601.21639)
*Yufeng Zhong,Lei Chen,Xuanle Zhao,Wenkang Han,Liming Zheng,Jing Huang,Deyang Jiang,Yilin Cao,Lin Ma,Zhixiong Zeng*

Main category: cs.CV

TL;DR: 本文提出了一种名为OCRVerse的端到端OCR方法，能够统一处理以文本为中心和以视觉为中心的OCR任务，并取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的OCR方法主要关注从图像或扫描文档中识别文本，而忽略了从图表、网页和科学图等视觉信息密集型图像中识别视觉元素的需求，而这些图像在互联网上广泛存在且具有重要的应用价值。

Method: OCRVerse采用了一种端到端的方法，结合了文本中心OCR和视觉中心OCR。其训练方法包括两个阶段：1. SFT（监督微调）阶段，混合跨领域数据以建立初始知识；2. RL（强化学习）阶段，设计个性化的奖励策略来处理不同领域对输出格式和预期结果的要求，以提高跨领域融合并避免数据冲突。

Result: 实验结果表明，OCRVerse在文本中心和视觉中心数据类型上均取得了有竞争力的结果，甚至可以与大型开源和闭源模型相媲美。

Conclusion: OCRVerse是第一个能够实现统一文本中心和视觉中心OCR的整体性方法，通过全面的数据工程和两阶段的训练策略，有效解决了视觉信息密集型图像的OCR识别问题。

Abstract: The development of large vision language models drives the demand for managing, and applying massive amounts of multimodal data, making OCR technology, which extracts information from visual images, increasingly popular. However, existing OCR methods primarily focus on recognizing text elements from images or scanned documents (\textbf{Text-centric OCR}), neglecting the identification of visual elements from visually information-dense image sources (\textbf{Vision-centric OCR}), such as charts, web pages and science plots. In reality, these visually information-dense images are widespread on the internet and have significant real-world application value, such as data visualization and web page analysis. In this technical report, we propose \textbf{OCRVerse}, the first holistic OCR method in end-to-end manner that enables unified text-centric OCR and vision-centric OCR. To this end, we constructe comprehensive data engineering to cover a wide range of text-centric documents, such as newspapers, magazines and books, as well as vision-centric rendered composites, including charts, web pages and scientific plots. Moreover, we propose a two-stage SFT-RL multi-domain training method for OCRVerse. SFT directly mixes cross-domain data to train and establish initial domain knowledge, while RL focuses on designing personalized reward strategies for the characteristics of each domain. Specifically, since different domains require various output formats and expected outputs, we provide sufficient flexibility in the RL stage to customize flexible reward signals for each domain, thereby improving cross-domain fusion and avoiding data conflicts. Experimental results demonstrate the effectiveness of OCRVerse, achieving competitive results across text-centric and vision-centric data types, even comparable to large-scale open-source and closed-source models.

</details>


### [160] [A Tilted Seesaw: Revisiting Autoencoder Trade-off for Controllable Diffusion](https://arxiv.org/abs/2601.21633)
*Pu Cao,Yiyang Ma,Feng Zhou,Xuedan Yin,Qing Song,Lu Yang*

Main category: cs.CV

TL;DR: 本研究发现，在潜扩散模型中，自动编码器（AE）的评估指标存在系统性偏差，过度偏重生成指标（如gFID）而忽视了重建保真度。这种偏差在高分辨率生成任务中可能导致“条件漂移”，影响可控性。研究表明，重建保真度（尤其是实例级度量）更能预测AE的可控性，并提出改进AE评估方法以更好地服务于可控扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有关于图像生成模型的自动编码器（AE）评估，尤其是在ImageNet规模研究中，倾向于优先考虑生成质量指标（如gFID），而忽视了重建保真度。这种倾向可能在可控扩散模型的发展中带来问题，特别是可能导致“条件漂移”，限制了条件对生成结果的对齐能力。

Method: 1. 理论分析：探讨为何gFID偏好在高分辨率生成中看似合理，但在可控扩散模型中可能导致“条件漂移”并限制条件对齐。 2. 经验验证： 评估了多个ImageNet规模AE在条件漂移方面的表现。 3. 多维度条件漂移评估协议：设计了一个能够反映可控生成任务的评估协议。 4. 实验对比：将gFID与重建导向的指标以及ControlNet的实验结果进行对比，以验证哪个指标更能预测可控性。

Result: 1. 理论分析表明，AE的gFID偏好可能导致条件漂移。 2. 经验研究发现，gFID与条件保持能力（可控性）的相关性较弱，而重建保真度指标（如实例级度量）与条件保持能力高度相关。 3. ControlNet实验进一步证实，可控性与条件保持能力同步，而非与gFID同步。

Conclusion: 针对ImageNet规模AE的评估方法论与可扩展可控扩散模型的需求之间存在差距。当前过度依赖生成指标（如gFID）的评估方式可能误导模型选择，并限制可控扩散模型的发展。研究建议采用更侧重重建保真度的指标来评估AE，以确保更好的条件对齐和可控性，并为AE的可靠基准测试和模型选择提供指导。

Abstract: In latent diffusion models, the autoencoder (AE) is typically expected to balance two capabilities: faithful reconstruction and a generation-friendly latent space (e.g., low gFID). In recent ImageNet-scale AE studies, we observe a systematic bias toward generative metrics in handling this trade-off: reconstruction metrics are increasingly under-reported, and ablation-based AE selection often favors the best-gFID configuration even when reconstruction fidelity degrades. We theoretically analyze why this gFID-dominant preference can appear unproblematic for ImageNet generation, yet becomes risky when scaling to controllable diffusion: AEs can induce condition drift, which limits achievable condition alignment. Meanwhile, we find that reconstruction fidelity, especially instance-level measures, better indicates controllability. We empirically validate the impact of tilted autoencoder evaluation on controllability by studying several recent ImageNet AEs. Using a multi-dimensional condition-drift evaluation protocol reflecting controllable generation tasks, we find that gFID is only weakly predictive of condition preservation, whereas reconstruction-oriented metrics are substantially more aligned. ControlNet experiments further confirm that controllability tracks condition preservation rather than gFID. Overall, our results expose a gap between ImageNet-centric AE evaluation and the requirements of scalable controllable diffusion, offering practical guidance for more reliable benchmarking and model selection.

</details>


### [161] [RSGround-R1: Rethinking Remote Sensing Visual Grounding through Spatial Reasoning](https://arxiv.org/abs/2601.21634)
*Shiqi Huang,Shuting He,Bihan Wen*

Main category: cs.CV

TL;DR: 提出了一种名为RSGround-R1的远程感知视觉地面定位（RSVG）框架，通过引入链式思考监督微调（CoT-SFT）和基于位置的奖励的强化微调（RFT），增强模型在理解基于位置线索的文本描述方面的空间推理能力，并采用空间一致性引导优化来提高稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在处理远程感知图像时，由于其广阔的空间尺度和高语义模糊性，难以有效理解和利用文本描述中的位置线索进行精确的物体定位。

Method: 1. 链式思考监督微调（CoT-SFT）：生成合成数据，包含显式的空间推理过程，以训练模型理解位置信息。 2. 强化微调（RFT）：引入新的位置奖励机制，提供连续的、与距离相关的反馈，以引导模型进行更准确的定位。 3. 空间一致性引导优化：通过动态调整策略更新，确保模型在多次推理中的定位行为保持一致和鲁棒。

Result: RSGround-R1在RSVG基准测试中取得了优越的性能和泛化能力。

Conclusion: 所提出的RSGround-R1框架通过专门设计的微调策略和奖励机制，有效地增强了模型在远程感知视觉地面定位任务中的空间推理和定位准确性，并提高了结果的稳定性和鲁棒性。

Abstract: Remote Sensing Visual Grounding (RSVG) aims to localize target objects in large-scale aerial imagery based on natural language descriptions. Owing to the vast spatial scale and high semantic ambiguity of remote sensing scenes, these descriptions often rely heavily on positional cues, posing unique challenges for Multimodal Large Language Models (MLLMs) in spatial reasoning. To leverage this unique feature, we propose a reasoning-guided, position-aware post-training framework, dubbed \textbf{RSGround-R1}, to progressively enhance spatial understanding. Specifically, we first introduce Chain-of-Thought Supervised Fine-Tuning (CoT-SFT) using synthetically generated RSVG reasoning data to establish explicit position awareness. Reinforcement Fine-Tuning (RFT) is then applied, augmented by our newly designed positional reward that provides continuous and distance-aware guidance toward accurate localization. Moreover, to mitigate incoherent localization behaviors across rollouts, we introduce a spatial consistency guided optimization scheme that dynamically adjusts policy updates based on their spatial coherence, ensuring stable and robust convergence. Extensive experiments on RSVG benchmarks demonstrate superior performance and generalization of our model.

</details>


### [162] [Few-Shot Domain Adaptation with Temporal References and Static Priors for Glacier Calving Front Delineation](https://arxiv.org/abs/2601.21663)
*Marcel Dreier,Nora Gourmelon,Dakota Pyles,Thorsten Seehaus,Matthias H. Braun,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 通过 few-shot 域适应、引入空间先验知识和夏季参考图像，将冰川崩解前缘分割误差从 1131.6 米降低到 68.7 米，实现了在新的研究地点上提高模型准确性。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的冰川崩解前缘分割模型在新的、与训练数据分布不同的研究地点表现不佳，准确性不足以支持科学分析。

Method: 采用 few-shot 域适应策略，结合空间静态先验知识，并在输入时间序列中包含夏季参考图像，在不修改模型架构的情况下进行改进。

Result: 将冰川崩解前缘分割误差从 1131.6 米显著降低到 68.7 米。

Conclusion: 提出的方法为将基于深度学习的冰川崩解前缘分割应用于新的研究地点提供了一个有效的框架，并有望实现全球范围内的冰川崩解前缘监测。

Abstract: During benchmarking, the state-of-the-art model for glacier calving front delineation achieves near-human performance. However, when applied in a real-world setting at a novel study site, its delineation accuracy is insufficient for calving front products intended for further scientific analyses. This site represents an out-of-distribution domain for a model trained solely on the benchmark dataset. By employing a few-shot domain adaptation strategy, incorporating spatial static prior knowledge, and including summer reference images in the input time series, the delineation error is reduced from 1131.6 m to 68.7 m without any architectural modifications. These methodological advancements establish a framework for applying deep learning-based calving front segmentation to novel study sites, enabling calving front monitoring on a global scale.

</details>


### [163] [When Gradient Optimization Is Not Enough: $\dagger$ Dispersive and Anchoring Geometric Regularizer for Multimodal Learning](https://arxiv.org/abs/2601.21670)
*Zixuan Xia,Hao Wang,Pengcheng Weng,Yanyu Qian,Yangxin Xu,William Dan,Fei Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为 \regName 的轻量级几何感知正则化框架，用于改善多模态学习中的表示结构，解决了现有方法中存在的表示崩溃和跨模态不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态学习方法，即使在精心平衡的训练下，也常常会出现几何病态，如模态内表示崩溃和样本级跨模态不一致，这损害了单模态鲁棒性和多模态融合效果。研究者认为表示几何是多模态学习中缺失的控制维度。

Method: 提出了一种名为 \regName 的几何感知正则化框架。该框架通过在中间嵌入层施加两个互补的约束来实现：1. 模态内分散正则化，促进表示多样性；2. 模态间锚定正则化，在不进行硬对齐的情况下约束样本级跨模态漂移。该正则化器即插即用，无需修改模型架构，并可与多种训练范式兼容。

Result: 在多个多模态基准测试上的大量实验表明，该方法能够持续提升多模态和单模态性能。显式地调节表示几何可以有效地缓解模态间的权衡问题。

Conclusion: 通过显式地调节表示几何，可以有效地解决多模态学习中存在的表示结构问题，提升模型在多模态和单模态任务上的表现，并缓解模态间的权衡。

Abstract: Multimodal learning aims to integrate complementary information from heterogeneous modalities, yet strong optimization alone does not guaranty well-structured representations. Even under carefully balanced training schemes, multimodal models often exhibit geometric pathologies, including intra-modal representation collapse and sample-level cross-modal inconsistency, which degrade both unimodal robustness and multimodal fusion.
  We identify representation geometry as a missing control axis in multimodal learning and propose \regName, a lightweight geometry-aware regularization framework. \regName enforces two complementary constraints on intermediate embeddings: an intra-modal dispersive regularization that promotes representation diversity, and an inter-modal anchoring regularization that bounds sample-level cross-modal drift without rigid alignment. The proposed regularizer is plug-and-play, requires no architectural modifications, and is compatible with various training paradigms.
  Extensive experiments across multiple multimodal benchmarks demonstrate consistent improvements in both multimodal and unimodal performance, showing that explicitly regulating representation geometry effectively mitigates modality trade-offs.

</details>


### [164] [CAF-Mamba: Mamba-Based Cross-Modal Adaptive Attention Fusion for Multimodal Depression Detection](https://arxiv.org/abs/2601.21648)
*Bowen Zhou,Marc-André Fiedler,Ayoub Al-Hamadi*

Main category: cs.CV

TL;DR: 提出了一种名为CAF-Mamba的基于Mamba的跨模态自适应注意力融合框架，用于抑郁症检测，并在两个基准数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在抑郁症检测中存在特征类型有限、忽略跨模态交互以及融合方式简单等局限性。

Method: 开发了一种新的Mamba为基础的跨模态自适应注意力融合框架（CAF-Mamba），该框架能够显式和隐式地捕捉跨模态交互，并通过模态注意力机制动态调整各模态的贡献。

Result: 在LMVD和D-Vlog两个野外基准数据集上的实验表明，CAF-Mamba的性能持续优于现有方法，并达到了最先进的水平。

Conclusion: CAF-Mamba能够更有效地进行多模态融合，为抑郁症检测提供了一种新颖且有效的解决方案。

Abstract: Depression is a prevalent mental health disorder that severely impairs daily functioning and quality of life. While recent deep learning approaches for depression detection have shown promise, most rely on limited feature types, overlook explicit cross-modal interactions, and employ simple concatenation or static weighting for fusion. To overcome these limitations, we propose CAF-Mamba, a novel Mamba-based cross-modal adaptive attention fusion framework. CAF-Mamba not only captures cross-modal interactions explicitly and implicitly, but also dynamically adjusts modality contributions through a modality-wise attention mechanism, enabling more effective multimodal fusion. Experiments on two in-the-wild benchmark datasets, LMVD and D-Vlog, demonstrate that CAF-Mamba consistently outperforms existing methods and achieves state-of-the-art performance.

</details>


### [165] [Multimodal Visual Surrogate Compression for Alzheimer's Disease Classification](https://arxiv.org/abs/2601.21673)
*Dexuan Ding,Ciyuan Peng,Endrowednes Kuantama,Jingcai Guo,Jia Wu,Jian Yang,Amin Beheshti,Ming-Hsuan Yang,Yuankai Qi*

Main category: cs.CV

TL;DR: 提出了一种名为MVSC的多模态视觉代理压缩方法，用于从3D结构MRI图像中学习紧凑的2D特征，以提高阿尔茨海默病（AD）的诊断准确性。该方法通过卷上下文编码器和自适应切片融合模块，有效克服了现有方法的计算成本高、跨切片信息丢失和特征辨别力不足等问题。


<details>
  <summary>Details</summary>
Motivation: 现有用于AD诊断的3D结构MRI图像分析方法存在计算成本高、忽略跨切片关系或特征提取能力有限等问题。研究旨在克服这些挑战，提高AD诊断的效率和准确性。

Method: 提出多模态视觉代理压缩（MVSC）方法，通过卷上下文编码器（Volume Context Encoder）和自适应切片融合（Adaptive Slice Fusion）模块，将3D sMRI数据压缩成2D视觉代理（visual surrogates）。卷上下文编码器利用文本指导捕获全局跨切片上下文，自适应切片融合模块以文本增强的、逐块的方式聚合切片级信息。这些2D特征随后被用于提取强大的表示，以进行AD分类。

Result: 在三个大规模阿尔茨海默病数据集上进行了广泛的实验。MVSC在二分类和多分类AD诊断任务上均表现优于现有的最先进方法。

Conclusion: MVSC是一种有效的方法，能够将高维3D sMRI数据压缩成信息丰富的2D视觉代理，并能与冻结的2D基础模型协同工作，从而在AD诊断任务中取得优于现有方法的性能。

Abstract: High-dimensional structural MRI (sMRI) images are widely used for Alzheimer's Disease (AD) diagnosis. Most existing methods for sMRI representation learning rely on 3D architectures (e.g., 3D CNNs), slice-wise feature extraction with late aggregation, or apply training-free feature extractions using 2D foundation models (e.g., DINO). However, these three paradigms suffer from high computational cost, loss of cross-slice relations, and limited ability to extract discriminative features, respectively. To address these challenges, we propose Multimodal Visual Surrogate Compression (MVSC). It learns to compress and adapt large 3D sMRI volumes into compact 2D features, termed as visual surrogates, which are better aligned with frozen 2D foundation models to extract powerful representations for final AD classification. MVSC has two key components: a Volume Context Encoder that captures global cross-slice context under textual guidance, and an Adaptive Slice Fusion module that aggregates slice-level information in a text-enhanced, patch-wise manner. Extensive experiments on three large-scale Alzheimer's disease benchmarks demonstrate our MVSC performs favourably on both binary and multi-class classification tasks compared against state-of-the-art methods.

</details>


### [166] [DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning](https://arxiv.org/abs/2601.21716)
*Mingshuang Luo,Shuang Liang,Zhengkun Rong,Yuxuan Luo,Tianshu Hu,Ruibing Hou,Hong Chang,Yong Li,Yuan Zhang,Mingyuan Gao*

Main category: cs.CV

TL;DR: DreamActor-M2 is a character animation framework that addresses identity preservation/motion consistency trade-offs and reliance on explicit pose priors by reformulating motion conditioning as in-context learning, using a unified latent space for appearance and motion, and employing a self-bootstrapped data synthesis pipeline for RGB-driven animation. It also introduces a new benchmark, AW Bench.


<details>
  <summary>Details</summary>
Motivation: Existing character image animation methods struggle with balancing identity preservation and motion consistency (the 'see-saw' problem) and are limited by their reliance on explicit pose priors, hindering generalization to diverse characters and motions. The researchers aimed to create a more general and robust framework.

Method: The approach uses a two-stage paradigm. First, it fuses reference appearance and motion cues into a unified latent space for joint reasoning. Second, it employs a self-bootstrapped data synthesis pipeline to create pseudo cross-identity training pairs, enabling direct RGB-driven animation without explicit pose priors. This treats motion conditioning as an in-context learning problem.

Result: DreamActor-M2 achieves state-of-the-art performance, demonstrating superior visual fidelity and robust cross-domain generalization. The self-bootstrapped pipeline enhances generalization to diverse characters and motion scenarios.

Conclusion: DreamActor-M2 offers a universal animation framework that overcomes limitations of previous methods by treating motion as in-context learning, leading to improved identity preservation, motion consistency, and generalization capabilities. The introduction of AW Bench provides a comprehensive evaluation platform.

Abstract: Character image animation aims to synthesize high-fidelity videos by transferring motion from a driving sequence to a static reference image. Despite recent advancements, existing methods suffer from two fundamental challenges: (1) suboptimal motion injection strategies that lead to a trade-off between identity preservation and motion consistency, manifesting as a "see-saw", and (2) an over-reliance on explicit pose priors (e.g., skeletons), which inadequately capture intricate dynamics and hinder generalization to arbitrary, non-humanoid characters. To address these challenges, we present DreamActor-M2, a universal animation framework that reimagines motion conditioning as an in-context learning problem. Our approach follows a two-stage paradigm. First, we bridge the input modality gap by fusing reference appearance and motion cues into a unified latent space, enabling the model to jointly reason about spatial identity and temporal dynamics by leveraging the generative prior of foundational models. Second, we introduce a self-bootstrapped data synthesis pipeline that curates pseudo cross-identity training pairs, facilitating a seamless transition from pose-dependent control to direct, end-to-end RGB-driven animation. This strategy significantly enhances generalization across diverse characters and motion scenarios. To facilitate comprehensive evaluation, we further introduce AW Bench, a versatile benchmark encompassing a wide spectrum of characters types and motion scenarios. Extensive experiments demonstrate that DreamActor-M2 achieves state-of-the-art performance, delivering superior visual fidelity and robust cross-domain generalization. Project Page: https://grisoon.github.io/DreamActor-M2/

</details>


### [167] [ChartE$^{3}$: A Comprehensive Benchmark for End-to-End Chart Editing](https://arxiv.org/abs/2601.21694)
*Shuo Li,Jiajun Sun,Zhekai Wang,Xiaoran Fan,Hui Li,Dingwen Yang,Zhiheng Xi,Yijun Wang,Zifei Shan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: 本文提出了ChartE³，一个用于评估端到端图表编辑能力的基准测试。该基准测试包括局部编辑和全局编辑两类任务，并包含1200多个样本，每个样本包含图表图像、底层代码和多模态编辑指令。实验表明，现有的大型多模态语言模型在全局编辑任务上存在显著的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有图表编辑方法依赖于中间表示（如自然语言程序或代码），在执行复杂编辑时存在局限性。作者旨在直接评估模型在图表编辑方面的端到端能力，特别是区分局部（外观）和全局（数据驱动）编辑。

Method: 构建了一个名为ChartE³的基准测试，包含1200多个样本，每个样本由图表图像、底层代码和多模态编辑指令组成。该基准测试评估两种类型的编辑：局部编辑（如字体、颜色）和全局编辑（如数据过滤、添加趋势线）。使用此基准测试来评估现有的大型多模态语言模型。

Result: 现有的大型多模态语言模型在ChartE³基准测试上表现出显著的性能差距，尤其是在全局编辑任务上。这表明当前模型在理解和执行复杂、数据驱动的图表编辑方面能力不足。

Conclusion: ChartE³提供了一个新的评估端到端图表编辑的框架，并揭示了当前多模态语言模型在处理复杂图表编辑任务（尤其是全局编辑）方面的不足，为未来的研究指明了方向。

Abstract: Charts are a fundamental visualization format for structured data analysis. Enabling end-to-end chart editing according to user intent is of great practical value, yet remains challenging due to the need for both fine-grained control and global structural consistency. Most existing approaches adopt pipeline-based designs, where natural language or code serves as an intermediate representation, limiting their ability to faithfully execute complex edits. We introduce ChartE$^{3}$, an End-to-End Chart Editing benchmark that directly evaluates models without relying on intermediate natural language programs or code-level supervision. ChartE$^{3}$ focuses on two complementary editing dimensions: local editing, which involves fine-grained appearance changes such as font or color adjustments, and global editing, which requires holistic, data-centric transformations including data filtering and trend line addition. ChartE$^{3}$ contains over 1,200 high-quality samples constructed via a well-designed data pipeline with human curation. Each sample is provided as a triplet of a chart image, its underlying code, and a multimodal editing instruction, enabling evaluation from both objective and subjective perspectives. Extensive benchmarking of state-of-the-art multimodal large language models reveals substantial performance gaps, particularly on global editing tasks, highlighting critical limitations in current end-to-end chart editing capabilities.

</details>


### [168] [Dynamic Topology Awareness: Breaking the Granularity Rigidity in Vision-Language Navigation](https://arxiv.org/abs/2601.21751)
*Jiankun Peng,Jianyuan Guo,Ying Xu,Yue Liu,Jiashuang Yan,Xuanwei Ye,Houhua Li,Xiaoming Wang*

Main category: cs.CV

TL;DR: 提出了一种名为 DGNav 的动态拓扑导航框架，通过场景感知自适应策略和动态图 Transformer 来解决现有拓扑规划方法中的“粒度刚性”问题，提高了在连续环境中进行视觉语言导航的效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有拓扑规划方法依赖于固定的几何阈值采样节点，无法适应不同环境的复杂性，导致在简单区域过度采样（计算冗余）和在高不确定性区域欠采样（增加碰撞风险）。

Method: DGNav 框架包含两个核心创新：1. 场景感知自适应策略：根据预测的航点分散度动态调整图构建阈值，实现“按需致密化”。2. 动态图 Transformer：融合视觉、语言和几何线索，动态重构图连接性，提高指令遵循能力。

Result: 在 R2R-CE 和 RxR-CE 基准测试中，DGNav 表现出优越的导航性能和强大的泛化能力。消融研究表明，DGNav 在导航效率和安全探索之间取得了最佳的权衡。

Conclusion: DGNav 通过动态调整图密度和连接性，有效解决了连续环境中视觉语言导航的粒度刚性问题，提升了导航的效率和安全性，并展现出良好的泛化能力。

Abstract: Vision-Language Navigation in Continuous Environments (VLN-CE) presents a core challenge: grounding high-level linguistic instructions into precise, safe, and long-horizon spatial actions. Explicit topological maps have proven to be a vital solution for providing robust spatial memory in such tasks. However, existing topological planning methods suffer from a "Granularity Rigidity" problem. Specifically, these methods typically rely on fixed geometric thresholds to sample nodes, which fails to adapt to varying environmental complexities. This rigidity leads to a critical mismatch: the model tends to over-sample in simple areas, causing computational redundancy, while under-sampling in high-uncertainty regions, increasing collision risks and compromising precision. To address this, we propose DGNav, a framework for Dynamic Topological Navigation, introducing a context-aware mechanism to modulate map density and connectivity on-the-fly. Our approach comprises two core innovations: (1) A Scene-Aware Adaptive Strategy that dynamically modulates graph construction thresholds based on the dispersion of predicted waypoints, enabling "densification on demand" in challenging environments; (2) A Dynamic Graph Transformer that reconstructs graph connectivity by fusing visual, linguistic, and geometric cues into dynamic edge weights, enabling the agent to filter out topological noise and enhancing instruction adherence. Extensive experiments on the R2R-CE and RxR-CE benchmarks demonstrate DGNav exhibits superior navigation performance and strong generalization capabilities. Furthermore, ablation studies confirm that our framework achieves an optimal trade-off between navigation efficiency and safe exploration. The code is available at https://github.com/shannanshouyin/DGNav.

</details>


### [169] [From Global to Granular: Revealing IQA Model Performance via Correlation Surface](https://arxiv.org/abs/2601.21738)
*Baoliang Chen,Danni Huang,Hanwei Zhu,Lingyu Zhu,Wei Zhou,Shiqi Wang,Yuming Fang,Weisi Lin*

Main category: cs.CV

TL;DR: 本文提出了一种名为“粒度调制相关性 (GMC)”的新评估方法，用于评估图像质量评估 (IQA) 模型。GMC 通过分析不同局部质量范围内的排序一致性，克服了传统全局相关性指标 (如 PLCC 和 SRCC) 的不足，并引入了“粒度调制器”和“分布调节器”来解决传统指标对测试集分布敏感的问题。GMC 生成的“相关性表面”提供了 IQA 模型性能的 3D 可视化，能够揭示传统指标无法显示的性能特征，从而实现更全面、更可靠的 IQA 模型分析和比较。


<details>
  <summary>Details</summary>
Motivation: 传统的全局相关性指标 (如 PLCC 和 SRCC) 无法捕捉 IQA 模型在不同局部质量范围内排序一致性的差异，并且对测试样本的质量分布敏感，导致跨数据集的比较不稳定。作者希望提出一种能够进行结构化、细粒度分析 IQA 模型性能的方法。

Method: 提出了“粒度调制相关性 (GMC)”方法，该方法包含两个主要部分：1) “粒度调制器”，通过对绝对 MOS 值和成对 MOS 差异 ($|Δ$MOS$|$) 进行高斯加权相关性分析，来检查局部性能变化；2) “分布调节器”，用于调节相关性以减轻非均匀质量分布带来的偏差。最终生成一个“相关性表面”，将相关性值表示为 MOS 和 $|Δ$MOS$|$ 的联合函数，形成 IQA 模型性能的 3D 表示。

Result: 实验表明，GMC 能够揭示传统标量指标无法显示的 IQA 模型性能特征，提供了比现有方法更具信息量和可靠性的 IQA 模型分析、比较和部署范式。GMC 在标准基准测试上显示出其优越性。

Conclusion: GMC 是一种新颖的 IQA 模型评估方法，它通过细粒度的分析和对分布的调节，克服了传统全局相关性指标的局限性，能够提供更全面、更可靠的 IQA 模型性能评估，有助于 IQA 模型的研究和实际应用。

Abstract: Evaluation of Image Quality Assessment (IQA) models has long been dominated by global correlation metrics, such as Pearson Linear Correlation Coefficient (PLCC) and Spearman Rank-Order Correlation Coefficient (SRCC). While widely adopted, these metrics reduce performance to a single scalar, failing to capture how ranking consistency varies across the local quality spectrum. For example, two IQA models may achieve identical SRCC values, yet one ranks high-quality images (related to high Mean Opinion Score, MOS) more reliably, while the other better discriminates image pairs with small quality/MOS differences (related to $|Δ$MOS$|$). Such complementary behaviors are invisible under global metrics. Moreover, SRCC and PLCC are sensitive to test-sample quality distributions, yielding unstable comparisons across test sets. To address these limitations, we propose \textbf{Granularity-Modulated Correlation (GMC)}, which provides a structured, fine-grained analysis of IQA performance. GMC includes: (1) a \textbf{Granularity Modulator} that applies Gaussian-weighted correlations conditioned on absolute MOS values and pairwise MOS differences ($|Δ$MOS$|$) to examine local performance variations, and (2) a \textbf{Distribution Regulator} that regularizes correlations to mitigate biases from non-uniform quality distributions. The resulting \textbf{correlation surface} maps correlation values as a joint function of MOS and $|Δ$MOS$|$, providing a 3D representation of IQA performance. Experiments on standard benchmarks show that GMC reveals performance characteristics invisible to scalar metrics, offering a more informative and reliable paradigm for analyzing, comparing, and deploying IQA models. Codes are available at https://github.com/Dniaaa/GMC.

</details>


### [170] [CG-MLLM: Captioning and Generating 3D content via Multi-modal Large Language Models](https://arxiv.org/abs/2601.21798)
*Junming Huang,Weiwei Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为CG-MLLM的新型多模态大语言模型，能够在一个框架内实现3D场景描述和高分辨率3D内容生成，克服了现有方法在分辨率和细节上的局限。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在3D内容生成方面能力不足，生成的3D模型分辨率低或结构粗糙，未能捕捉精细的几何细节。研究的动机是填补这一空白，实现高保真度的3D内容生成。

Method: CG-MLLM采用了混合Transformer架构，将TokenAR Transformer用于处理令牌级内容，BlockAR Transformer用于处理块级内容。该模型集成了预训练的视觉-语言骨干网络和一个专门的3D VAE潜在空间，实现了标准令牌和空间块之间长上下文的交互。

Result: 实验结果表明，CG-MLLM在生成高保真度3D对象方面显著优于现有的多模态大语言模型。

Conclusion: CG-MLLM成功地将高分辨率3D内容创建引入到主流的大语言模型范式中，为一个统一的框架内的3D字幕和高分辨率3D生成奠定了基础。

Abstract: Large Language Models(LLMs) have revolutionized text generation and multimodal perception, but their capabilities in 3D content generation remain underexplored. Existing methods compromise by producing either low-resolution meshes or coarse structural proxies, failing to capture fine-grained geometry natively. In this paper, we propose CG-MLLM, a novel Multi-modal Large Language Model (MLLM) capable of 3D captioning and high-resolution 3D generation in a single framework. Leveraging the Mixture-of-Transformer architecture, CG-MLLM decouples disparate modeling needs, where the Token-level Autoregressive (TokenAR) Transformer handles token-level content, and the Block-level Autoregressive (BlockAR) Transformer handles block-level content. By integrating a pre-trained vision-language backbone with a specialized 3D VAE latent space, CG-MLLM facilitates long-context interactions between standard tokens and spatial blocks within a single integrated architecture. Experimental results show that CG-MLLM significantly outperforms existing MLLMs in generating high-fidelity 3D objects, effectively bringing high-resolution 3D content creation into the mainstream LLM paradigm.

</details>


### [171] [MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods](https://arxiv.org/abs/2601.21821)
*Honglin Lin,Zheng Liu,Yun Zhu,Chonghan Qin,Juekai Lin,Xiaoran Shang,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: 提出一个名为 MMFineReason 的大规模多模态推理数据集，包含 180 万个样本和 51 亿个 token，旨在解决现有数据集在 STEM 图表和视觉谜题等领域覆盖不足以及缺乏高质量长链条思考（CoT）标注的问题。通过微调 Qwen3-VL-Instruct 模型，MMFineReason 数据集显著提升了模型的推理能力，尤其是在参数效率方面表现出色，并且发现难度感知过滤策略能有效提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有开源视觉语言模型（VLMs）在视觉推理能力上落后于专有系统，主要原因是缺乏高质量的推理数据。现有数据集在 STEM 图表、视觉谜题等挑战性领域的覆盖有限，并且缺乏一致、长篇的链条思考（CoT）标注。

Method: 作者构建了一个名为 MMFineReason 的大规模多模态推理数据集，包含 180 万个样本和 51 亿个 solution token。该数据集通过一个三阶段的流程创建：1. 大规模数据收集和标准化；2. CoT Rationale 生成；3. 基于推理质量和难度的全面筛选。随后，使用 MMFineReason 数据集微调 Qwen3-VL-Instruct 模型，生成 MMFineReason-2B/4B/8B 版本。

Result: MMFineReason-2B/4B/8B 模型在各自的模型规模类别中达到了新的 state-of-the-art 性能。MMFineReason-4B 性能超过了 Qwen3-VL-8B-Thinking，MMFineReason-8B 甚至超越了 Qwen3-VL-30B-A3B-Thinking，并接近 Qwen3-VL-32B-Thinking 的性能。难度感知过滤策略显示，仅使用 7%（123K 样本）的数据子集就能达到与完整数据集相当的性能。推理导向的数据组合策略同时提升了模型的通用能力。

Conclusion: MMFineReason 是一个大规模、高质量的多模态推理数据集，能够有效提升开源 VLM 的推理能力，尤其是在参数效率方面表现突出。通过难度感知过滤和推理导向的数据构建，可以进一步优化模型性能，并可能提升通用能力。

Abstract: Recent advances in Vision Language Models (VLMs) have driven significant progress in visual reasoning. However, open-source VLMs still lag behind proprietary systems, largely due to the lack of high-quality reasoning data. Existing datasets offer limited coverage of challenging domains such as STEM diagrams and visual puzzles, and lack consistent, long-form Chain-of-Thought (CoT) annotations essential for eliciting strong reasoning capabilities. To bridge this gap, we introduce MMFineReason, a large-scale multimodal reasoning dataset comprising 1.8M samples and 5.1B solution tokens, featuring high-quality reasoning annotations distilled from Qwen3-VL-235B-A22B-Thinking. The dataset is established via a systematic three-stage pipeline: (1) large-scale data collection and standardization, (2) CoT rationale generation, and (3) comprehensive selection based on reasoning quality and difficulty awareness. The resulting dataset spans STEM problems, visual puzzles, games, and complex diagrams, with each sample annotated with visually grounded reasoning traces. We fine-tune Qwen3-VL-Instruct on MMFineReason to develop MMFineReason-2B/4B/8B versions. Our models establish new state-of-the-art results for their size class. Notably, MMFineReason-4B succesfully surpasses Qwen3-VL-8B-Thinking, and MMFineReason-8B even outperforms Qwen3-VL-30B-A3B-Thinking while approaching Qwen3-VL-32B-Thinking, demonstrating remarkable parameter efficiency. Crucially, we uncover a "less is more" phenomenon via our difficulty-aware filtering strategy: a subset of just 7\% (123K samples) achieves performance comparable to the full dataset. Notably, we reveal a synergistic effect where reasoning-oriented data composition simultaneously boosts general capabilities.

</details>


### [172] [Synthetic-to-Real Domain Bridging for Single-View 3D Reconstruction of Ships for Maritime Monitoring](https://arxiv.org/abs/2601.21786)
*Borja Carrillo-Perez,Felix Sattler,Angel Bueno Rodriguez,Maurice Stephan,Sarah Barnes*

Main category: cs.CV

TL;DR: 本文提出了一种高效的单视图船舶三维重建方法，利用 Splatter Image 网络和合成数据训练，并在真实数据上进行微调，实现了无需多视角或真实三维标注的实时船舶三维可视化。


<details>
  <summary>Details</summary>
Motivation: 现有三维重建方法通常需要多视角监督、三维真值标注或计算量大，不适用于实时海事部署。因此，研究一种高效、单视图即可进行真实船舶三维重建的方法具有重要意义。

Method: 1. 使用 Splatter Image 网络，将物体表示为稀疏的3D高斯。2. 在合成数据集（ShapeNet vessels）上进行预训练，并在自定义的真实船舶数据集上进行微调，以弥合合成与真实数据的域差距。3. 集成 YOLOv8 分割模块和自定义预处理。4. 后处理包括真实世界缩放、居中、方向对齐，并结合AIS元数据和基于单应性的映射，将模型地理位置放置在交互式网页地图上。

Result: 在合成验证数据集上实现了高精度的重建保真度。在真实海事图像（ShipSG数据集）上进行了定性评估，证明了该方法向实际海事场景迁移的潜力。最终系统能够对真实船舶进行交互式三维检查，而无需真实三维标注。

Conclusion: 该方法提供了一种高效、可扩展的海事监测解决方案，实现了无需真实世界三维标注的实时三维船舶可视化，为实际应用提供了可行途径。

Abstract: Three-dimensional (3D) reconstruction of ships is an important part of maritime monitoring, allowing improved visualization, inspection, and decision-making in real-world monitoring environments. However, most state-ofthe-art 3D reconstruction methods require multi-view supervision, annotated 3D ground truth, or are computationally intensive, making them impractical for real-time maritime deployment. In this work, we present an efficient pipeline for single-view 3D reconstruction of real ships by training entirely on synthetic data and requiring only a single view at inference. Our approach uses the Splatter Image network, which represents objects as sparse sets of 3D Gaussians for rapid and accurate reconstruction from single images. The model is first fine-tuned on synthetic ShapeNet vessels and further refined with a diverse custom dataset of 3D ships, bridging the domain gap between synthetic and real-world imagery. We integrate a state-of-the-art segmentation module based on YOLOv8 and custom preprocessing to ensure compatibility with the reconstruction network. Postprocessing steps include real-world scaling, centering, and orientation alignment, followed by georeferenced placement on an interactive web map using AIS metadata and homography-based mapping. Quantitative evaluation on synthetic validation data demonstrates strong reconstruction fidelity, while qualitative results on real maritime images from the ShipSG dataset confirm the potential for transfer to operational maritime settings. The final system provides interactive 3D inspection of real ships without requiring real-world 3D annotations. This pipeline provides an efficient, scalable solution for maritime monitoring and highlights a path toward real-time 3D ship visualization in practical applications. Interactive demo: https://dlr-mi.github.io/ship3d-demo/.

</details>


### [173] [Past- and Future-Informed KV Cache Policy with Salience Estimation in Autoregressive Video Diffusion](https://arxiv.org/abs/2601.21896)
*Hanmo Chen,Chenghao Xu,Xu Yang,Xuan Chen,Cheng Deng*

Main category: cs.CV

TL;DR: 提出了一种新的基于过去和未来信息的KV缓存策略（PaFu-KV），用于提高自回归视频生成模型在长视频生成中的质量和效率，通过估计token的重要性来优化KV缓存。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型依赖启发式KV缓存策略，忽略了token在长视频生成中的重要性差异，导致关键时空信息丢失和冗余缓存累积，降低了视频生成质量和效率。

Method: 提出了一种名为PaFu-KV的新型KV缓存策略。该策略引入了一个轻量级的显著性估计头，该头从双向教师模型蒸馏而来，用于估算token的显著性得分，从而使KV缓存能够保留信息丰富的token并丢弃不相关的token。

Result: PaFu-KV策略通过缩小KV缓存容量和减少推理时的内存占用，实现了更好的质量-效率权衡。在基准测试上的广泛实验表明，该方法在保持高保真视频生成质量的同时，加速了推理过程，从而实现了更高效的长视频生成。

Conclusion: PaFu-KV策略能够有效解决现有KV缓存策略在长视频生成中的不足，通过自适应地选择保留或丢弃KV缓存中的token，显著提升了视频生成质量和推理效率。

Abstract: Video generation is pivotal to digital media creation, and recent advances in autoregressive video generation have markedly enhanced the efficiency of real-time video synthesis. However, existing approaches generally rely on heuristic KV Cache policies, which ignore differences in token importance in long-term video generation. This leads to the loss of critical spatiotemporal information and the accumulation of redundant, invalid cache, thereby degrading video generation quality and efficiency. To address this limitation, we first observe that token contributions to video generation are highly time-heterogeneous and accordingly propose a novel Past- and Future-Informed KV Cache Policy (PaFu-KV). Specifically, PaFu-KV introduces a lightweight Salience Estimation Head distilled from a bidirectional teacher to estimate salience scores, allowing the KV cache to retain informative tokens while discarding less relevant ones. This policy yields a better quality-efficiency trade-off by shrinking KV cache capacity and reducing memory footprint at inference time. Extensive experiments on benchmarks demonstrate that our method preserves high-fidelity video generation quality while enables accelerated inference, thereby enabling more efficient long-horizon video generation. Our code will be released upon paper acceptance.

</details>


### [174] [Improving Classifier-Free Guidance of Flow Matching via Manifold Projection](https://arxiv.org/abs/2601.21892)
*Jian-Feng Cai,Haixia Liu,Zhengyi Su,Chao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于优化的视角来理解和改进扩散模型中的分类器无关引导（CFG）技术，通过同伦优化和流匹配视角，减少了对引导尺度的敏感性，并提升了生成质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的分类器无关引导（CFG）技术虽然效果显著，但其基于启发式线性外插的方法对引导尺度非常敏感，缺乏理论基础。

Method: 1. 从优化角度解释CFG，将其与平滑距离函数的梯度引导联系起来。 2. 提出了一种新的CFG采样公式，视作带有流形约束的同伦优化。 3. 引入了一种增量梯度下降方法进行流形投影。 4. 结合Anderson加速技术以提高效率和稳定性。

Result: 提出的训练无关方法在生成保真度、提示对齐和对引导尺度的鲁棒性方面均得到提升。在DiT-XL-2-256、Flux和Stable Diffusion 3.5等大型模型上进行了验证，效果显著。

Conclusion: 通过将CFG视为一种优化问题，并引入同伦优化和流形投影，可以更有效地控制生成过程，提高生成质量和对参数的鲁棒性，且无需重新训练模型。

Abstract: Classifier-free guidance (CFG) is a widely used technique for controllable generation in diffusion and flow-based models. Despite its empirical success, CFG relies on a heuristic linear extrapolation that is often sensitive to the guidance scale. In this work, we provide a principled interpretation of CFG through the lens of optimization. We demonstrate that the velocity field in flow matching corresponds to the gradient of a sequence of smoothed distance functions, which guides latent variables toward the scaled target image set. This perspective reveals that the standard CFG formulation is an approximation of this gradient, where the prediction gap, the discrepancy between conditional and unconditional outputs, governs guidance sensitivity. Leveraging this insight, we reformulate the CFG sampling as a homotopy optimization with a manifold constraint. This formulation necessitates a manifold projection step, which we implement via an incremental gradient descent scheme during sampling. To improve computational efficiency and stability, we further enhance this iterative process with Anderson Acceleration without requiring additional model evaluations. Our proposed methods are training-free and consistently refine generation fidelity, prompt alignment, and robustness to the guidance scale. We validate their effectiveness across diverse benchmarks, demonstrating significant improvements on large-scale models such as DiT-XL-2-256, Flux, and Stable Diffusion 3.5.

</details>


### [175] [TraceRouter: Robust Safety for Large Foundation Models via Path-Level Intervention](https://arxiv.org/abs/2601.21900)
*Chuancheng Shi,Shangze Li,Wenjun Lu,Wenhua Wu,Cong Wang,Zifeng Cheng,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本研究提出了TraceRouter，一种用于防御大型基础模型（LFMs）对抗性攻击的新框架。与现有基于局部抑制的防御方法不同，TraceRouter通过追踪和断开有害语义在模型中的分布式因果传播路径来工作，从而在提高鲁棒性的同时减少对模型通用性的损害。


<details>
  <summary>Details</summary>
Motivation: 现有针对大型基础模型（LFMs）的对抗性防御方法主要依赖于“局部性假设”，即抑制孤立的神经元或特征。然而，有害语义通常以分布式、跨层电路的形式存在，这种局部干预方法既脆弱又会损害模型的实用性。因此，需要一种能够处理分布式有害语义的新方法。

Method: TraceRouter框架包含三个阶段：1. 通过分析注意力发散来确定敏感的起始层。2. 利用稀疏自动编码器（SAEs）和微分激活分析来解耦和隔离恶意特征。3. 通过零输出干预得出的特征影响分数（FIS）来将这些特征映射到下游因果路径。最后，通过选择性地抑制这些因果链来断开有害信息的流动。

Result: TraceRouter在大量实验中表现出显著优于现有最先进基线的效果，在对抗鲁棒性和通用实用性之间取得了更好的权衡。研究表明，TraceRouter能够有效地断开有害信息的传播，同时保留模型其他正常的计算路径。

Conclusion: TraceRouter通过追踪和断开有害语义的因果传播路径，为大型基础模型提供了一种有效的对抗性防御机制。该方法克服了现有局部防御的局限性，并在鲁棒性和实用性之间取得了更好的平衡。

Abstract: Despite their capabilities, large foundation models (LFMs) remain susceptible to adversarial manipulation. Current defenses predominantly rely on the "locality hypothesis", suppressing isolated neurons or features. However, harmful semantics act as distributed, cross-layer circuits, rendering such localized interventions brittle and detrimental to utility. To bridge this gap, we propose \textbf{TraceRouter}, a path-level framework that traces and disconnects the causal propagation circuits of illicit semantics. TraceRouter operates in three stages: (1) it pinpoints a sensitive onset layer by analyzing attention divergence; (2) it leverages sparse autoencoders (SAEs) and differential activation analysis to disentangle and isolate malicious features; and (3) it maps these features to downstream causal pathways via feature influence scores (FIS) derived from zero-out interventions. By selectively suppressing these causal chains, TraceRouter physically severs the flow of harmful information while leaving orthogonal computation routes intact. Extensive experiments demonstrate that TraceRouter significantly outperforms state-of-the-art baselines, achieving a superior trade-off between adversarial robustness and general utility. Our code will be publicly released. WARNING: This paper contains unsafe model responses.

</details>


### [176] [Beyond Global Alignment: Fine-Grained Motion-Language Retrieval via Pyramidal Shapley-Taylor Learning](https://arxiv.org/abs/2601.21904)
*Hanmo Chen,Guangtao Lyu,Chenghao Xu,Jiexi Yan,Xu Yang,Cheng Deng*

Main category: cs.CV

TL;DR: 提出了一种名为金字塔 Shapley-Taylor (PST) 的新颖学习框架，用于细粒度的运动-语言检索，通过金字塔式的方法逐步对齐运动片段、身体关节和文本标记，以弥合局部语义细节和分层结构关系。


<details>
  <summary>Details</summary>
Motivation: 现有运动-语言检索方法主要关注全局运动序列和文本表示的对齐，忽略了局部运动片段、身体关节和文本标记之间的细粒度交互，导致检索性能不佳。

Method: 提出了一种金字塔 Shapley-Taylor (PST) 学习框架，将运动分解为时间片段和空间身体关节，并采用渐进式的逐关节和逐片段对齐来学习跨模态对应关系，以金字塔方式捕捉局部语义细节和层级结构关系。

Result: 在多个公开数据集上的广泛实验表明，PST 方法显著优于最先进的方法，实现了运动片段、身体关节及其对应文本标记之间的精确对齐。

Conclusion: PST 学习框架能够有效捕捉运动和语言之间的细粒度对应关系，提升运动-语言检索的性能，克服了现有全局中心范式中对局部交互的忽视。

Abstract: As a foundational task in human-centric cross-modal intelligence, motion-language retrieval aims to bridge the semantic gap between natural language and human motion, enabling intuitive motion analysis, yet existing approaches predominantly focus on aligning entire motion sequences with global textual representations. This global-centric paradigm overlooks fine-grained interactions between local motion segments and individual body joints and text tokens, inevitably leading to suboptimal retrieval performance. To address this limitation, we draw inspiration from the pyramidal process of human motion perception (from joint dynamics to segment coherence, and finally to holistic comprehension) and propose a novel Pyramidal Shapley-Taylor (PST) learning framework for fine-grained motion-language retrieval. Specifically, the framework decomposes human motion into temporal segments and spatial body joints, and learns cross-modal correspondences through progressive joint-wise and segment-wise alignment in a pyramidal fashion, effectively capturing both local semantic details and hierarchical structural relationships. Extensive experiments on multiple public benchmark datasets demonstrate that our approach significantly outperforms state-of-the-art methods, achieving precise alignment between motion segments and body joints and their corresponding text tokens. The code of this work will be released upon acceptance.

</details>


### [177] [Trajectory-Guided Diffusion for Foreground-Preserving Background Generation in Multi-Layer Documents](https://arxiv.org/abs/2601.21857)
*Taewon Kang*

Main category: cs.CV

TL;DR: 该研究提出了一种基于扩散模型的文档背景生成框架，通过设计潜在空间来同时实现前景保留和多页风格一致性，无需显式约束或后处理。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在生成文档背景时存在的前景内容损坏以及多页生成时风格漂移的问题。

Method: 通过设计结构化的潜在空间，使扩散过程演化为随机轨迹，从而自然地避开前景区域。通过解耦风格控制与文本条件，并引入缓存的风格方向（持久向量）来约束扩散轨迹到一个共享的风格子空间，实现跨页风格一致性。

Result: 提出的框架能够生成视觉上连贯、保留前景内容且在多页文档中保持风格一致的背景。该方法是无需训练的，并且兼容现有的扩散模型。

Conclusion: 将扩散模型重新构想为潜在空间中的轨迹设计，提供了一种原则性的方法来实现一致且结构化的生成模型，有效解决了文档背景生成中的前景保留和风格一致性挑战。

Abstract: We present a diffusion-based framework for document-centric background generation that achieves foreground preservation and multi-page stylistic consistency through latent-space design rather than explicit constraints. Instead of suppressing diffusion updates or applying masking heuristics, our approach reinterprets diffusion as the evolution of stochastic trajectories through a structured latent space. By shaping the initial noise and its geometric alignment, background generation naturally avoids designated foreground regions, allowing readable content to remain intact without auxiliary mechanisms. To address the long-standing issue of stylistic drift across pages, we decouple style control from text conditioning and introduce cached style directions as persistent vectors in latent space. Once selected, these directions constrain diffusion trajectories to a shared stylistic subspace, ensuring consistent appearance across pages and editing iterations. This formulation eliminates the need for repeated prompt-based style specification and provides a more stable foundation for multi-page generation. Our framework admits a geometric and physical interpretation, where diffusion paths evolve on a latent manifold shaped by preferred directions, and foreground regions are rarely traversed as a consequence of trajectory initialization rather than explicit exclusion. The proposed method is training-free, compatible with existing diffusion backbones, and produces visually coherent, foreground-preserving results across complex documents. By reframing diffusion as trajectory design in latent space, we offer a principled approach to consistent and structured generative modeling.

</details>


### [178] [VideoAesBench: Benchmarking the Video Aesthetics Perception Capabilities of Large Multimodal Models](https://arxiv.org/abs/2601.21915)
*Yunhao Li,Sijing Wu,Zhilin Gao,Zicheng Zhang,Qi Jia,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 该研究提出了一个名为VideoAesBench的视频美学质量评估基准，用于评估大型多模态模型（LMMs）在理解视频美学方面的能力。研究发现，现有LMMs在这方面的能力尚不完善。


<details>
  <summary>Details</summary>
Motivation: 现有的LMMs在视觉感知方面表现出色，但对视频美学质量的评估能力却鲜有探索，而这对于人类来说是一项基本能力。因此，需要一个专门的基准来评估LMMs在这方面的能力。

Method: 提出了VideoAesBench基准，包含1804个来自不同来源（UGC, AIGC, 压缩, RGC, 游戏）的视频，支持多种问题格式（单选、多选、判断、开放式），并涵盖了视觉形式、视觉风格和视觉情感等多个美学维度。在此基础上，对23个开源和商业LMMs进行了基准测试。

Result: 现有LMMs仅具备基本视频美学感知能力，其性能不完整且不精确。

Conclusion: VideoAesBench提供了一个强大的测试平台，旨在为可解释的视频美学评估提供见解，并揭示了当前LMMs在视频美学理解方面存在的不足。

Abstract: Large multimodal models (LMMs) have demonstrated outstanding capabilities in various visual perception tasks, which has in turn made the evaluation of LMMs significant. However, the capability of video aesthetic quality assessment, which is a fundamental ability for human, remains underexplored for LMMs. To address this, we introduce VideoAesBench, a comprehensive benchmark for evaluating LMMs' understanding of video aesthetic quality. VideoAesBench has several significant characteristics: (1) Diverse content including 1,804 videos from multiple video sources including user-generated (UGC), AI-generated (AIGC), compressed, robotic-generated (RGC), and game videos. (2) Multiple question formats containing traditional single-choice questions, multi-choice questions, True or False questions, and a novel open-ended questions for video aesthetics description. (3) Holistic video aesthetics dimensions including visual form related questions from 5 aspects, visual style related questions from 4 aspects, and visual affectiveness questions from 3 aspects. Based on VideoAesBench, we benchmark 23 open-source and commercial large multimodal models. Our findings show that current LMMs only contain basic video aesthetics perception ability, their performance remains incomplete and imprecise. We hope our VideoAesBench can be served as a strong testbed and offer insights for explainable video aesthetics assessment.

</details>


### [179] [Zero-Shot Video Restoration and Enhancement with Assistance of Video Diffusion Models](https://arxiv.org/abs/2601.21922)
*Cong Cao,Huanjing Yue,Shangbin Xie,Xin Liu,Jingyu Yang*

Main category: cs.CV

TL;DR: 本文提出了一个结合视频扩散模型和图像增强方法的框架，以解决视频恢复和增强中的时间闪烁问题，并实现了训练无关的零样本视频恢复。该框架通过融合同源和异源潜在表示，并结合基于COT的融合策略，利用文本到视频扩散模型来增强图像增强方法的时序一致性，最后通过时序增强后处理进一步优化。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的零样本图像恢复和增强方法在应用于视频时存在严重的时间闪烁问题，因此需要一种方法来提高视频恢复和增强的时序一致性。

Method: 该框架首先利用同源和异源潜在表示融合策略，并结合基于COT的融合比率策略，利用文本到视频扩散模型来辅助图像增强方法。然后，通过时序增强后处理，利用图像到视频扩散模型进一步提升时序一致性。该方法是训练无关的，可以应用于任何基于扩散模型的图像恢复和增强方法。

Result: 实验结果表明，所提出的方法能够有效地解决视频恢复和增强中的时间闪烁问题，并提升时序一致性，在各项评估指标上表现优于现有方法。

Conclusion: 本文提出的框架成功地将视频扩散模型应用于零样本视频恢复和增强任务，通过多样的融合策略和后处理技术，有效解决了时间闪烁问题，并提高了时序一致性，为后续研究提供了新的思路。

Abstract: Although diffusion-based zero-shot image restoration and enhancement methods have achieved great success, applying them to video restoration or enhancement will lead to severe temporal flickering. In this paper, we propose the first framework that utilizes the rapidly-developed video diffusion model to assist the image-based method in maintaining more temporal consistency for zero-shot video restoration and enhancement. We propose homologous latents fusion, heterogenous latents fusion, and a COT-based fusion ratio strategy to utilize both homologous and heterogenous text-to-video diffusion models to complement the image method. Moreover, we propose temporal-strengthening post-processing to utilize the image-to-video diffusion model to further improve temporal consistency. Our method is training-free and can be applied to any diffusion-based image restoration and enhancement methods. Experimental results demonstrate the superiority of the proposed method.

</details>


### [180] [Just Noticeable Difference Modeling for Deep Visual Features](https://arxiv.org/abs/2601.21933)
*Rui Zhao,Wenrui Li,Lin Zhu,Yajing Zheng,Weisi Lin*

Main category: cs.CV

TL;DR: 本文提出了一种名为FeatJND的量化方法，用于衡量深度视觉特征中可容忍的扰动程度，以在资源受限的情况下保持下游任务的性能。FeatJND通过预测最大可容忍的每特征扰动图来实现这一点。


<details>
  <summary>Details</summary>
Motivation: 深度视觉特征日益成为计算机视觉系统的接口，因此需要描述其特性并控制其质量，以满足机器感知的需求。将人类或机器视觉中的“感知最小可察觉差异”（JND）概念扩展到深度视觉特征，可以为在特征空间中提供与任务相关的容忍边界，从而在资源受限的情况下为控制特征质量提供实际参考。

Method: 提出了一种名为FeatJND的任务对齐JND公式，用于预测最大可容忍的每特征扰动图，同时保持下游任务的性能。在标准化的分割点处提出了一个FeatJND估计器，并在图像分类、检测和实例分割任务中进行了验证。此外，将FeatJND应用于token级别的动态量化，并展示了FeatJND指导的步长分配在相同噪声预算下优于随机步长排列和全局统一步长。

Result: 在匹配的失真强度下，基于FeatJND的失真比非结构化高斯扰动更有效地保持了任务性能。归因可视化表明，FeatJND能够抑制非关键特征区域。在动态量化应用中，FeatJND指导的步长分配显示出明确的性能提升。

Conclusion: FeatJND是一种有效的方法，可以在保持下游任务性能的同时，量化深度视觉特征中的最大可容忍扰动。该方法在多种视觉任务中表现出色，并可用于模型压缩等实际应用，如动态量化。

Abstract: Deep visual features are increasingly used as the interface in vision systems, motivating the need to describe feature characteristics and control feature quality for machine perception. Just noticeable difference (JND) characterizes the maximum imperceptible distortion for images under human or machine vision. Extending it to deep visual features naturally meets the above demand by providing a task-aligned tolerance boundary in feature space, offering a practical reference for controlling feature quality under constrained resources. We propose FeatJND, a task-aligned JND formulation that predicts the maximum tolerable per-feature perturbation map while preserving downstream task performance. We propose a FeatJND estimator at standardized split points and validate it across image classification, detection, and instance segmentation. Under matched distortion strength, FeatJND-based distortions consistently preserve higher task performance than unstructured Gaussian perturbations, and attribution visualizations suggest FeatJND can suppress non-critical feature regions. As an application, we further apply FeatJND to token-wise dynamic quantization and show that FeatJND-guided step-size allocation yields clear gains over random step-size permutation and global uniform step size under the same noise budget. Our code will be released after publication.

</details>


### [181] [BookNet: Book Image Rectification via Cross-Page Attention Network](https://arxiv.org/abs/2601.21938)
*Shaokai Liu,Hao Feng,Bozhi Luan,Min Hou,Jiajun Deng,Wengang Zhou*

Main category: cs.CV

TL;DR: 本文提出了BookNet，一种端到端的深度学习框架，用于双页图书图像校正，解决了现有单页方法的局限性。该框架利用双分支架构和跨页注意力机制来捕捉左右页之间的几何耦合关系。


<details>
  <summary>Details</summary>
Motivation: 现有单页文档图像校正方法无法处理图书中由于装订约束导致的左右页之间的耦合几何关系和不对称曲率模式。

Method: 提出BookNet，一个端到端的深度学习框架，采用双分支架构和跨页注意力机制，用于双页图书图像校正。同时，创建了Book3D合成数据集和Book100真实基准数据集。

Result: BookNet在双页图书图像校正任务上超越了现有最先进的方法。

Conclusion: BookNet是首个专门为双页图书图像校正设计的端到端深度学习框架，能够有效处理左右页之间的几何耦合，并在实验中取得了优越的性能。

Abstract: Book image rectification presents unique challenges in document image processing due to complex geometric distortions from binding constraints, where left and right pages exhibit distinctly asymmetric curvature patterns. However, existing single-page document image rectification methods fail to capture the coupled geometric relationships between adjacent pages in books. In this work, we introduce BookNet, the first end-to-end deep learning framework specifically designed for dual-page book image rectification. BookNet adopts a dual-branch architecture with cross-page attention mechanisms, enabling it to estimate warping flows for both individual pages and the complete book spread, explicitly modeling how left and right pages influence each other. Moreover, to address the absence of specialized datasets, we present Book3D, a large-scale synthetic dataset for training, and Book100, a comprehensive real-world benchmark for evaluation. Extensive experiments demonstrate that BookNet outperforms existing state-of-the-art methods on book image rectification. Code and dataset will be made publicly available.

</details>


### [182] [PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing](https://arxiv.org/abs/2601.21957)
*Cheng Cui,Ting Sun,Suyin Liang,Tingquan Gao,Zelun Zhang,Jiaxuan Liu,Xueqing Wang,Changda Zhou,Hongen Liu,Manhui Lin,Yue Zhang,Yubo Zhang,Yi Liu,Dianhai Yu,Yanjun Ma*

Main category: cs.CV

TL;DR: PaddleOCR-VL-1.5 在 OmniDocBench v1.5 上达到了 94.5% 的 SOTA 准确率，并在新提出的 Real5-OmniDocBench 基准测试中表现出色，证明了其对真实世界物理失真的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有 OCR 模型在真实世界物理失真（如扫描、倾斜、弯曲、屏幕拍摄、光照等）下的鲁棒性不足，需要更强大的评估基准和模型。

Method: 提出了 PaddleOCR-VL-1.5 模型，并构建了一个新的 Real5-OmniDocBench 基准测试集，用于评估模型在各种物理失真下的性能。此外，扩展了模型能力以支持印章识别和文本检测任务。

Result: PaddleOCR-VL-1.5 在 OmniDocBench v1.5 上达到 SOTA 准确率 94.5%。在 Real5-OmniDocBench 基准测试中，该模型也取得了 SOTA 性能。模型在保持 0.9B 参数量的同时，实现了高效率。

Conclusion: PaddleOCR-VL-1.5 是一种高效且鲁棒的超紧凑视觉语言模型（VLM），在文档智能处理方面取得了显著进展，特别是在应对真实世界物理失真方面表现优异，并扩展了其在印章识别和文本检测方面的能力。

Abstract: We introduce PaddleOCR-VL-1.5, an upgraded model achieving a new state-of-the-art (SOTA) accuracy of 94.5% on OmniDocBench v1.5. To rigorously evaluate robustness against real-world physical distortions, including scanning, skew, warping, screen-photography, and illumination, we propose the Real5-OmniDocBench benchmark. Experimental results demonstrate that this enhanced model attains SOTA performance on the newly curated benchmark. Furthermore, we extend the model's capabilities by incorporating seal recognition and text spotting tasks, while remaining a 0.9B ultra-compact VLM with high efficiency. Code: https://github.com/PaddlePaddle/PaddleOCR

</details>


### [183] [Deep Models, Shallow Alignment: Uncovering the Granularity Mismatch in Neural Decoding](https://arxiv.org/abs/2601.21948)
*Yang Du,Siyuan Dai,Yonghao Song,Paul M. Thompson,Haoteng Tang,Liang Zhan*

Main category: cs.CV

TL;DR: 本研究提出了一种名为“浅层对齐”的新型对比学习策略，通过将神经信号与视觉编码器的中间层表示对齐，解决了现有方法在神经视觉解码中存在的粒度不匹配问题，显著提升了视觉信息重建的准确性，并发现了与视觉骨干网络容量相关的缩放规律。


<details>
  <summary>Details</summary>
Motivation: 现有神经视觉解码方法忽视了人类视觉和机器学习模型在处理信息时的粒度不匹配问题。深度视觉模型倾向于抑制局部纹理信息以强调语义不变性，而神经信号却同时保留了低级视觉属性和高级语义内容。这种不匹配限制了解码性能。

Method: 提出了一种名为“浅层对齐”的新型对比学习策略。该策略将神经信号与视觉编码器（vision encoders）的中间层表示对齐，而不是其最终输出层。这样做是为了在低级纹理细节和高级语义特征之间取得更好的平衡。

Result: 在多个基准测试上进行了广泛的实验，结果表明“浅层对齐”显著优于标准的最终层对齐方法，性能提升在22%到58%之间。此外，该方法能够有效解锁神经视觉解码的缩放规律，使得解码性能可以随着预训练视觉骨干网络容量的增加而可预测地提升。研究还进行了系统的实证分析，阐明了性能提升的机制。

Conclusion: “浅层对齐”是一种有效的方法，可以解决神经视觉解码中的粒度不匹配问题，通过与视觉编码器的中间层对齐来提高重建精度。该方法不仅在性能上有所突破，还揭示了与模型容量相关的缩放规律，为未来神经视觉解码的研究提供了新的方向。

Abstract: Neural visual decoding is a central problem in brain computer interface research, aiming to reconstruct human visual perception and to elucidate the structure of neural representations. However, existing approaches overlook a fundamental granularity mismatch between human and machine vision, where deep vision models emphasize semantic invariance by suppressing local texture information, whereas neural signals preserve an intricate mixture of low-level visual attributes and high-level semantic content. To address this mismatch, we propose Shallow Alignment, a novel contrastive learning strategy that aligns neural signals with intermediate representations of visual encoders rather than their final outputs, thereby striking a better balance between low-level texture details and high-level semantic features. Extensive experiments across multiple benchmarks demonstrate that Shallow Alignment significantly outperforms standard final-layer alignment, with performance gains ranging from 22% to 58% across diverse vision backbones. Notably, our approach effectively unlocks the scaling law in neural visual decoding, enabling decoding performance to scale predictably with the capacity of pre-trained vision backbones. We further conduct systematic empirical analyses to shed light on the mechanisms underlying the observed performance gains.

</details>


### [184] [Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving](https://arxiv.org/abs/2601.22032)
*Linhan Wang,Zichong Yang,Chen Bai,Guoxiang Zhang,Xiaotong Liu,Xiaoyin Zheng,Xiao-Xiao Long,Chang-Tien Lu,Cheng Lu*

Main category: cs.CV

TL;DR: 本文提出了Drive-JEPA框架，结合了V-JEPA和多模态轨迹蒸馏，用于端到端自动驾驶。该框架通过预训练ViT编码器和引入考虑多种模拟轨迹的规划器，显著提高了驾驶性能，并在NAVSIM基准上取得了新的最先进成果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用自监督视频预训练学习可迁移规划表示以实现端到端自动驾驶方面取得了进展，但对于场景理解的视频世界模型预训练效果有限。主要挑战在于驾驶场景的固有限制（单个轨迹）导致难以学习多模态行为。

Method: 1. 适应V-JEPA，在大型驾驶视频上预训练ViT编码器，生成与轨迹规划对齐的预测表示。2. 引入以提案为中心的规划器，结合人类轨迹和模拟器生成的多种轨迹进行蒸馏，并使用动量感知选择机制促进稳定安全的行为。

Result: 在NAVSIM基准测试中，V-JEPA表示结合简单的Transformer解码器在无感知设置下比先前方法提高了3 PDMS。完整的Drive-JEPA框架在v1上达到了93.3 PDMS，在v2上达到了87.8 EPDMS，创造了新的最先进水平。

Conclusion: Drive-JEPA框架通过整合V-JEPA的预测表示学习能力和多模态轨迹蒸馏，有效解决了单一人类轨迹的局限性，成功地提高了端到端自动驾驶的性能，并在NAVSIM基准上取得了显著的SOTA结果。

Abstract: End-to-end autonomous driving increasingly leverages self-supervised video pretraining to learn transferable planning representations. However, pretraining video world models for scene understanding has so far brought only limited improvements. This limitation is compounded by the inherent ambiguity of driving: each scene typically provides only a single human trajectory, making it difficult to learn multimodal behaviors. In this work, we propose Drive-JEPA, a framework that integrates Video Joint-Embedding Predictive Architecture (V-JEPA) with multimodal trajectory distillation for end-to-end driving. First, we adapt V-JEPA for end-to-end driving, pretraining a ViT encoder on large-scale driving videos to produce predictive representations aligned with trajectory planning. Second, we introduce a proposal-centric planner that distills diverse simulator-generated trajectories alongside human trajectories, with a momentum-aware selection mechanism to promote stable and safe behavior. When evaluated on NAVSIM, the V-JEPA representation combined with a simple transformer-based decoder outperforms prior methods by 3 PDMS in the perception-free setting. The complete Drive-JEPA framework achieves 93.3 PDMS on v1 and 87.8 EPDMS on v2, setting a new state-of-the-art.

</details>


### [185] [Understanding Multimodal Complementarity for Single-Frame Action Anticipation](https://arxiv.org/abs/2601.22039)
*Manuel Benavent-Lledo,Konstantinos Bacharidis,Konstantinos Papoutsakis,Antonis Argyros,Jose Garcia-Rodriguez*

Main category: cs.CV

TL;DR: 本文研究了仅凭单帧图像进行动作预测的可能性，并提出了一种名为 AAG+ 的新框架，该框架结合了 RGB、深度和语义信息，并在多项基准测试中取得了与视频模型相当甚至更好的结果。


<details>
  <summary>Details</summary>
Motivation: 现有动作预测方法通常依赖于密集的视频信息，作者挑战了这一假设，希望探索仅凭单帧图像进行动作预测的潜力。

Method: 作者系统性地研究了单帧动作预测，分析了 RGB 外观、基于深度的几何线索以及过去动作的语义表示的贡献，并探索了多模态融合策略、关键帧选择策略和过去动作历史来源对预测性能的影响。在此基础上，他们构建了 AAG+ 框架。

Result: AAG+ 在 IKEA-ASM, Meccano 和 Assembly101 等基准测试中，尽管仅使用单帧图像，但其性能持续优于原始 AAG 方法，并且与最先进的基于视频的方法相当或更优。

Conclusion: 研究表明，仅凭单帧图像进行动作预测是可行的，并且通过有效利用 RGB、深度和语义信息，可以达到与密集视频分析相媲美的性能。这有助于 Clarify 何时需要密集时间建模，何时仅需精心选择的单帧图像即可。

Abstract: Human action anticipation is commonly treated as a video understanding problem, implicitly assuming that dense temporal information is required to reason about future actions. In this work, we challenge this assumption by investigating what can be achieved when action anticipation is constrained to a single visual observation. We ask a fundamental question: how much information about the future is already encoded in a single frame, and how can it be effectively exploited? Building on our prior work on Action Anticipation at a Glimpse (AAG), we conduct a systematic investigation of single-frame action anticipation enriched with complementary sources of information. We analyze the contribution of RGB appearance, depth-based geometric cues, and semantic representations of past actions, and investigate how different multimodal fusion strategies, keyframe selection policies and past-action history sources influence anticipation performance. Guided by these findings, we consolidate the most effective design choices into AAG+, a refined single-frame anticipation framework. Despite operating on a single frame, AAG+ consistently improves upon the original AAG and achieves performance comparable to, or exceeding, that of state-of-the-art video-based methods on challenging anticipation benchmarks including IKEA-ASM, Meccano and Assembly101. Our results offer new insights into the limits and potential of single-frame action anticipation, and clarify when dense temporal modeling is necessary and when a carefully selected glimpse is sufficient.

</details>


### [186] [Urban Neural Surface Reconstruction from Constrained Sparse Aerial Imagery with 3D SAR Fusion](https://arxiv.org/abs/2601.22045)
*Da Li,Chen Yao,Tong Mao,Jiacheng Bao,Houjun Sun*

Main category: cs.CV

TL;DR: 提出了一种融合3D SAR点云和航空影像的神经表面重建方法，用于解决稀疏视角下的城市三维重建难题，并构建了首个包含3D SAR点云和航空影像的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的神经表面重建方法在稀疏视角下存在几何模糊和不稳定的问题，这在大规模城市遥感中尤为关键，因为航空影像获取受限于飞行路径、地形和成本。

Method: 该框架将3D SAR数据提供的空间约束融入到基于SDF（Signed Distance Function）的神经表面重建骨干网络中，通过引导结构感知的射线选择和自适应采样来实现稳定高效的优化。同时，构建了一个包含共注册3D SAR点云和航空影像的基准数据集。

Result: 实验结果表明，在高度稀疏和倾斜视角条件下，结合3D SAR数据能够显著提高重建的准确性、完整性和鲁棒性，优于仅使用单模态数据的基线方法。

Conclusion: 通过融合3D SAR点云和航空影像，为在受限的稀疏视角条件下实现高保真、可扩展的城市三维重建提供了一种可行方案，展示了先进的空载和天基光学-SAR传感器的潜力。

Abstract: Neural surface reconstruction (NSR) has recently shown strong potential for urban 3D reconstruction from multi-view aerial imagery. However, existing NSR methods often suffer from geometric ambiguity and instability, particularly under sparse-view conditions. This issue is critical in large-scale urban remote sensing, where aerial image acquisition is limited by flight paths, terrain, and cost. To address this challenge, we present the first urban NSR framework that fuses 3D synthetic aperture radar (SAR) point clouds with aerial imagery for high-fidelity reconstruction under constrained, sparse-view settings. 3D SAR can efficiently capture large-scale geometry even from a single side-looking flight path, providing robust priors that complement photometric cues from images. Our framework integrates radar-derived spatial constraints into an SDF-based NSR backbone, guiding structure-aware ray selection and adaptive sampling for stable and efficient optimization. We also construct the first benchmark dataset with co-registered 3D SAR point clouds and aerial imagery, facilitating systematic evaluation of cross-modal 3D reconstruction. Extensive experiments show that incorporating 3D SAR markedly enhances reconstruction accuracy, completeness, and robustness compared with single-modality baselines under highly sparse and oblique-view conditions, highlighting a viable route toward scalable high-fidelity urban reconstruction with advanced airborne and spaceborne optical-SAR sensing.

</details>


### [187] [Unsupervised Decomposition and Recombination with Discriminator-Driven Diffusion Models](https://arxiv.org/abs/2601.22057)
*Archer Wang,Emile Anand,Yilun Du,Marin Soljačić*

Main category: cs.CV

TL;DR: 本研究提出了一种无需监督即可在扩散模型中发现潜在因子（如图像的背景、光照、物体属性；机器人视频的运动组件）的方法，并通过引入对抗性训练信号来提升因子分解和组合生成质量，在图像和机器人视频数据上均取得了优于基线方法的性能，并能用于生成更丰富的机器人运动轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有研究致力于将复杂数据分解为可重用的组成部分，以便通过重组这些部分来合成新样本。然而，如何在没有显式因子级别监督的情况下，在扩散模型中实现这一点，以及如何提高这种组合生成的质量，仍是需要解决的问题。

Method: 研究人员在扩散模型中引入了一种无监督的因子分解方法。为了提升因子发现和组合生成的质量，他们设计了一个判别器，用于区分单源样本和通过跨源重组因子生成的样本。通过优化生成器以欺骗该判别器，促使生成的重组样本在物理和语义上保持一致性。

Result: 该方法在CelebA-HQ、Virtual KITTI、CLEVR和Falcor3D数据集上，通过FID分数和MIG、MCC指标衡量，其性能优于现有基线方法。在机器人视频领域，通过重组学习到的动作组件，生成了多样化的轨迹，显著提高了LIBERO基准上的状态空间覆盖率。

Conclusion: 该研究成功地在扩散模型中实现了无监督的潜在因子分解，并通过对抗性训练提高了因子重组的质量和多样性，为图像生成和机器人任务（如数据增强和探索）开辟了新的应用前景。

Abstract: Decomposing complex data into factorized representations can reveal reusable components and enable synthesizing new samples via component recombination. We investigate this in the context of diffusion-based models that learn factorized latent spaces without factor-level supervision. In images, factors can capture background, illumination, and object attributes; in robotic videos, they can capture reusable motion components. To improve both latent factor discovery and quality of compositional generation, we introduce an adversarial training signal via a discriminator trained to distinguish between single-source samples and those generated by recombining factors across sources. By optimizing the generator to fool this discriminator, we encourage physical and semantic consistency in the resulting recombinations. Our method outperforms implementations of prior baselines on CelebA-HQ, Virtual KITTI, CLEVR, and Falcor3D, achieving lower FID scores and better disentanglement as measured by MIG and MCC. Furthermore, we demonstrate a novel application to robotic video trajectories: by recombining learned action components, we generate diverse sequences that significantly increase state-space coverage for exploration on the LIBERO benchmark.

</details>


### [188] [MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources](https://arxiv.org/abs/2601.22054)
*Baorui Ma,Jiahui Yang,Donglin Di,Xuancheng Zhang,Jianxun Cui,Hao Li,Yan Xie,Wei Chen*

Main category: cs.CV

TL;DR: Metric Anything 是一个简单且可扩展的预训练框架，通过稀疏度量提示（Sparse Metric Prompt）解决了异质传感器噪声、相机依赖偏差和度量模糊性等挑战，实现了从各种嘈杂的 3D 数据源中学习度量深度，并在多项下游任务上取得了最先进的性能，同时提升了多模态大模型在空间智能方面的能力。


<details>
  <summary>Details</summary>
Motivation: 扩展视觉基础模型在度量深度估计领域的应用面临传感器噪声、相机偏差和度量模糊性等挑战，现有方法难以直接应用。

Method: 提出 Metric Anything 预训练框架，核心是 Sparse Metric Prompt，通过随机掩码深度图生成，作为通用接口解耦空间推理与传感器/相机偏差。使用约 2000 万个图像-深度对进行训练，覆盖多种 3D 数据源和相机模型。

Result: 首次在度量深度估计领域展现出明确的规模化趋势。预训练模型在提示驱动的任务（如深度补全、超分辨率、雷达-相机融合）上表现优异。蒸馏后的无提示学生模型在单目深度估计、相机内参恢复、单/多视图度量 3D 重建和 VLA 规划等任务上达到最先进水平。Metric Anything 的视觉编码器显著提升了多模态大模型在空间智能方面的能力。

Conclusion: 度量深度估计可以受益于与现代基础模型相同的规模化定律，Metric Anything 建立了一条通往可扩展、高效的真实世界度量感知的新途径。

Abstract: Scaling has powered recent advances in vision foundation models, yet extending this paradigm to metric depth estimation remains challenging due to heterogeneous sensor noise, camera-dependent biases, and metric ambiguity in noisy cross-source 3D data. We introduce Metric Anything, a simple and scalable pretraining framework that learns metric depth from noisy, diverse 3D sources without manually engineered prompts, camera-specific modeling, or task-specific architectures. Central to our approach is the Sparse Metric Prompt, created by randomly masking depth maps, which serves as a universal interface that decouples spatial reasoning from sensor and camera biases. Using about 20M image-depth pairs spanning reconstructed, captured, and rendered 3D data across 10000 camera models, we demonstrate-for the first time-a clear scaling trend in the metric depth track. The pretrained model excels at prompt-driven tasks such as depth completion, super-resolution and Radar-camera fusion, while its distilled prompt-free student achieves state-of-the-art results on monocular depth estimation, camera intrinsics recovery, single/multi-view metric 3D reconstruction, and VLA planning. We also show that using pretrained ViT of Metric Anything as a visual encoder significantly boosts Multimodal Large Language Model capabilities in spatial intelligence. These results show that metric depth estimation can benefit from the same scaling laws that drive modern foundation models, establishing a new path toward scalable and efficient real-world metric perception. We open-source MetricAnything at http://metric-anything.github.io/metric-anything-io/ to support community research.

</details>


### [189] [UEval: A Benchmark for Unified Multimodal Generation](https://arxiv.org/abs/2601.22155)
*Bo Li,Yida Yin,Wenhao Chai,Xingyu Fu,Zhuang Liu*

Main category: cs.CV

TL;DR: 本文提出了UEval基准，用于评估能够同时生成图像和文本的统一模型。该基准包含1000个专家精心挑选的问题，涵盖多种推理类型，并设计了一个包含10,417个验证过的评分标准（rubric）的评分系统，用于细粒度的自动评分。当前模型在UEval上表现不佳，表明该基准具有挑战性，并强调了推理能力对复杂多模态任务的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以对生成图像和文本的统一模型进行全面评估，尤其是对于需要结合图像和文本输出的开放式多模态生成任务。简单的“LLM作为裁判”方法可能无法捕捉细微之处，因此需要一个更精细、可扩展的评估方法。

Method: 构建了一个包含1000个专家精心挑选的问题的UEval基准，这些问题来源于8个真实世界的任务，并覆盖了多种推理类型。设计了一个基于评分标准的评分系统：首先利用多模态大语言模型（MLLM）根据参考图像和文本生成初步的评分标准，然后由人类专家进行精炼和验证。最终形成了包含10,417个验证过的评分标准的UEval。

Result: UEval对当前统一模型具有挑战性，GPT-5-Thinking得分仅为66.4/100，最佳开源模型得分仅为49.1。研究发现，具备推理能力的模型通常优于不具备推理能力的模型。将推理轨迹从推理模型迁移到非推理模型可以显著缩小性能差距。

Conclusion: UEval是一个有效的基准，能够对统一模型进行细粒度的多模态生成评估。研究结果表明，推理能力对于需要复杂多模态理解和生成能力的任务至关重要，并且推理轨迹的迁移是提升模型性能的有效途径。

Abstract: We introduce UEval, a benchmark to evaluate unified models, i.e., models capable of generating both images and text. UEval comprises 1,000 expert-curated questions that require both images and text in the model output, sourced from 8 real-world tasks. Our curated questions cover a wide range of reasoning types, from step-by-step guides to textbook explanations. Evaluating open-ended multimodal generation is non-trivial, as simple LLM-as-a-judge methods can miss the subtleties. Different from previous works that rely on multimodal Large Language Models (MLLMs) to rate image quality or text accuracy, we design a rubric-based scoring system in UEval. For each question, reference images and text answers are provided to a MLLM to generate an initial rubric, consisting of multiple evaluation criteria, and human experts then refine and validate these rubrics. In total, UEval contains 10,417 validated rubric criteria, enabling scalable and fine-grained automatic scoring. UEval is challenging for current unified models: GPT-5-Thinking scores only 66.4 out of 100, while the best open-source model reaches merely 49.1. We observe that reasoning models often outperform non-reasoning ones, and transferring reasoning traces from a reasoning model to a non-reasoning model significantly narrows the gap. This suggests that reasoning may be important for tasks requiring complex multimodal understanding and generation.

</details>


### [190] [Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models](https://arxiv.org/abs/2601.22060)
*Wenxuan Huang,Yu Zeng,Qiuchen Wang,Zhen Fang,Shaosheng Cao,Zheng Chu,Qingyu Yin,Shuang Chen,Zhenfei Yin,Lin Chen,Zehui Chen,Yao Hu,Philip Torr,Feng Zhao,Wanli Ouyang*

Main category: cs.CV

TL;DR: Vision-DeepResearch 提出了一个多模态深度研究范式，通过多轮、多实体、多尺度的视觉和文本搜索，增强了大型多模态模型（MLLMs）在嘈杂现实世界场景中的信息检索能力，并取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLMs 在处理需要大量事实信息和存在视觉噪声的任务时存在局限，它们的搜索策略过于简单，推理深度和搜索广度不足，难以解决复杂问题。

Method: 提出 Vision-DeepResearch，一个集成了多轮、多实体、多尺度视觉和文本搜索能力的新型 MLLM 范式。该模型通过冷启动监督和强化学习训练，将深度研究能力内化到 MLLM 中，支持大规模的推理步骤和引擎交互。

Result: Vision-DeepResearch 在真实世界搜索引擎的嘈杂环境中表现出色，显著优于现有的多模态深度研究 MLLMs 以及基于 GPT-5、Gemini-2.5-pro 和 Claude-4-Sonnet 等闭源基础模型的解决方案。

Conclusion: Vision-DeepResearch 成功构建了一个强大的端到端多模态深度研究 MLLM，能够有效地处理包含视觉噪声的复杂信息检索任务，并在性能上超越了现有最先进的方法。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call'' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch.

</details>


### [191] [RefAny3D: 3D Asset-Referenced Diffusion Models for Image Generation](https://arxiv.org/abs/2601.22094)
*Hanzhuo Huang,Qingyang Bao,Zekai Gu,Zhongshuo Du,Cheng Lin,Yuan Liu,Sibei Yang*

Main category: cs.CV

TL;DR: 提出了一种基于3D资产的图像生成扩散模型，该模型利用3D资产的多视图RGB图像和点图来生成与3D资产精确一致的图像。


<details>
  <summary>Details</summary>
Motivation: 现有基于参考的图像生成方法仅限于单张图像作为参考，无法利用3D资产，限制了其在实际应用中的通用性。本研究旨在弥补这一差距，实现3D资产与2D图像生成之间的联动。

Method: 提出了一种跨域扩散模型，采用双分支感知机制，同时处理3D资产的多视图RGB图像和点图。通过空间对齐的双分支生成架构和领域解耦的生成机制，实现RGB图像和点图的同步生成，从而将2D图像属性与3D资产属性关联起来。

Result: 实验表明，该方法能够有效地利用3D资产作为参考，生成与给定3D资产高度一致的图像。

Conclusion: 该方法有效地结合了3D资产和扩散模型，为3D内容创作开辟了新的可能性，能够生成与3D资产保持精确一致性的图像。

Abstract: In this paper, we propose a 3D asset-referenced diffusion model for image generation, exploring how to integrate 3D assets into image diffusion models. Existing reference-based image generation methods leverage large-scale pretrained diffusion models and demonstrate strong capability in generating diverse images conditioned on a single reference image. However, these methods are limited to single-image references and cannot leverage 3D assets, constraining their practical versatility. To address this gap, we present a cross-domain diffusion model with dual-branch perception that leverages multi-view RGB images and point maps of 3D assets to jointly model their colors and canonical-space coordinates, achieving precise consistency between generated images and the 3D references. Our spatially aligned dual-branch generation architecture and domain-decoupled generation mechanism ensure the simultaneous generation of two spatially aligned but content-disentangled outputs, RGB images and point maps, linking 2D image attributes with 3D asset attributes. Experiments show that our approach effectively uses 3D assets as references to produce images consistent with the given assets, opening new possibilities for combining diffusion models with 3D content creation.

</details>


### [192] [PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction](https://arxiv.org/abs/2601.22046)
*Changjian Jiang,Kerui Ren,Xudong Li,Kaiwen Song,Linning Xu,Tao Lu,Junting Dong,Yu Zhang,Bo Dai,Mulin Yu*

Main category: cs.CV

TL;DR: 本文提出了一种名为PLANING的流式单目图像重建框架，它结合了显式几何图元和神经高斯，实现了高效、高质量的几何和外观解耦重建，速度快且效果好，适用于大规模场景建模和具身AI。


<details>
  <summary>Details</summary>
Motivation: 现有的单目图像流式重建方法往往只能在渲染质量或几何精度之间进行权衡，难以同时兼顾两者。因此，研究如何实现高质量且高效的流式重建是本研究的动机。

Method: PLANING采用一种混合表示方法，将显式几何图元与神经高斯松散耦合，实现了几何和外观的解耦建模。在此基础上，提出了一种在线初始化和优化策略，将几何和外观更新分离，从而实现稳定、低结构冗余的流式重建。

Result: PLANING在稠密网格Chamfer-L2指标上比PGSR提升了18.52%，在PSNR上比ARTDECO提升了1.31 dB。它能够在100秒内完成ScanNetV2场景的重建，速度是2D高斯泼溅的5倍以上，同时重建质量与离线每场景优化相当。

Conclusion: PLANING通过其解耦的几何和外观建模以及高效的在线优化策略，实现了高质量、低冗余的流式单目图像重建，并且计算效率高，为大规模场景建模和具身AI等下游应用提供了有力支持。

Abstract: Streaming reconstruction from monocular image sequences remains challenging, as existing methods typically favor either high-quality rendering or accurate geometry, but rarely both. We present PLANING, an efficient on-the-fly reconstruction framework built on a hybrid representation that loosely couples explicit geometric primitives with neural Gaussians, enabling geometry and appearance to be modeled in a decoupled manner. This decoupling supports an online initialization and optimization strategy that separates geometry and appearance updates, yielding stable streaming reconstruction with substantially reduced structural redundancy. PLANING improves dense mesh Chamfer-L2 by 18.52% over PGSR, surpasses ARTDECO by 1.31 dB PSNR, and reconstructs ScanNetV2 scenes in under 100 seconds, over 5x faster than 2D Gaussian Splatting, while matching the quality of offline per-scene optimization. Beyond reconstruction quality, the structural clarity and computational efficiency of \modelname~make it well suited for a broad range of downstream applications, such as enabling large-scale scene modeling and simulation-ready environments for embodied AI. Project page: https://city-super.github.io/PLANING/ .

</details>


### [193] [Creative Image Generation with Diffusion Model](https://arxiv.org/abs/2601.22125)
*Kunpeng Song,Ahmed Elgammal*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的新颖创意图像生成框架，通过最大化 CLIP 嵌入空间中的图像逆概率来驱动生成模型产生罕见、富有想象力且视觉上引人注目的图像，同时保持视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 当前创意图像生成方法依赖于手动概念混合或排除子类别，而本文旨在提出一种更 principled 的方法，通过量化图像在 CLIP 嵌入空间中的概率来驱动生成模型产生新颖、富有想象力的输出。

Method: 利用扩散模型，将图像的“创造力”定义为其在 CLIP 嵌入空间中的逆概率。通过计算生成图像的概率分布，并将其推向低概率区域来生成创意图像。引入了“pullback mechanisms”来在提高创造力的同时不牺牲视觉保真度。

Result: 在文本到图像扩散模型上的大量实验表明，该框架能够生成独特、新颖且发人深省的图像，有效且高效。

Conclusion: 该研究为生成模型中的创造力提供了一个新的视角，提出了一种促进视觉内容合成创新的原则性方法。

Abstract: Creative image generation has emerged as a compelling area of research, driven by the need to produce novel and high-quality images that expand the boundaries of imagination. In this work, we propose a novel framework for creative generation using diffusion models, where creativity is associated with the inverse probability of an image's existence in the CLIP embedding space. Unlike prior approaches that rely on a manual blending of concepts or exclusion of subcategories, our method calculates the probability distribution of generated images and drives it towards low-probability regions to produce rare, imaginative, and visually captivating outputs. We also introduce pullback mechanisms, achieving high creativity without sacrificing visual fidelity. Extensive experiments on text-to-image diffusion models demonstrate the effectiveness and efficiency of our creative generation framework, showcasing its ability to produce unique, novel, and thought-provoking images. This work provides a new perspective on creativity in generative models, offering a principled method to foster innovation in visual content synthesis.

</details>


### [194] [Early and Prediagnostic Detection of Pancreatic Cancer from Computed Tomography](https://arxiv.org/abs/2601.22134)
*Wenxuan Li,Pedro R. A. S. Bassi,Lizhou Wu,Xinze Zhou,Yuxuan Zhao,Qi Chen,Szymon Plotka,Tianyu Lin,Zheren Zhu,Marisa Martin,Justin Caskey,Shanshan Jiang,Xiaoxi Chen,Jaroslaw B. Ćwikla,Artur Sankowski,Yaping Wu,Sergio Decherchi,Andrea Cavalli,Chandana Lall,Cristian Tomasetti,Yaxing Guo,Xuan Yu,Yuqing Cai,Hualin Qiao,Jie Bao,Chenhan Hu,Ximing Wang,Arkadiusz Sitek,Kai Ding,Heng Li,Meiyun Wang,Dexin Yu,Guang Zhang,Yang Yang,Kang Wang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: 研究开发了一个名为ePAI的人工智能系统，用于在CT扫描中早期检测胰腺导管腺癌（PDAC），并在内部和外部测试中均表现出高灵敏度和特异性，优于放射科医生，能够检测到临床诊断前数月甚至数年的病灶。


<details>
  <summary>Details</summary>
Motivation: 胰腺导管腺癌（PDAC）是致命的恶性肿瘤，通常在晚期才被发现，此时已无法手术。现有回顾性研究表明，即使是经验丰富的放射科医生在知晓患者后来患有PDAC的情况下，也常常能在之前的CT扫描中发现被忽略的病灶。因此，开发一个能够帮助早期检测这些病灶的自动化系统具有重要意义。

Method: 研究人员开发了一个名为ePAI的自动化人工智能系统。该系统在来自一个医疗中心的1,598名患者的数据上进行了训练。随后，在包含1,009名患者的内部测试集和包含7,158名患者（来自6个中心）的外部测试集中评估了ePAI的性能。通过接收者操作特征曲线下面积（AUC）、敏感性和特异性来衡量其检测能力，并能够精确定位不同大小的PDAC病灶。此外，还进行了一项多读者研究，将ePAI的性能与30名委员会认证的放射科医生进行了比较。

Result: 在内部测试中，ePAI在检测直径小于2厘米的PDAC时，AUC达到0.939-0.999，敏感性为95.3%，特异性为98.7%，能够精确定位小至2毫米的PDAC。在外部测试中，ePAI的AUC为0.918-0.945，敏感性为91.5%，特异性为88.0%，能够精确定位小至5毫米的PDAC。ePAI能够检测到临床诊断前3至36个月的PDAC，并且在159名患者中有75名（占47.2%）被成功检测和定位，中位提前诊断时间为347天。多读者研究显示，ePAI在敏感性方面比30名放射科医生提高了50.3%（P < 0.05），同时保持了可比的95.4%的特异性。

Conclusion: ePAI作为一个辅助工具，在早期检测和精确定位胰腺癌方面表现出巨大潜力，能够显著优于人类放射科医生，并能检测到临床诊断前数月甚至数年前的被忽略的病灶，有望提高胰腺癌的早期诊断率。

Abstract: Pancreatic ductal adenocarcinoma (PDAC), one of the deadliest solid malignancies, is often detected at a late and inoperable stage. Retrospective reviews of prediagnostic CT scans, when conducted by expert radiologists aware that the patient later developed PDAC, frequently reveal lesions that were previously overlooked. To help detecting these lesions earlier, we developed an automated system named ePAI (early Pancreatic cancer detection with Artificial Intelligence). It was trained on data from 1,598 patients from a single medical center. In the internal test involving 1,009 patients, ePAI achieved an area under the receiver operating characteristic curve (AUC) of 0.939-0.999, a sensitivity of 95.3%, and a specificity of 98.7% for detecting small PDAC less than 2 cm in diameter, precisely localizing PDAC as small as 2 mm. In an external test involving 7,158 patients across 6 centers, ePAI achieved an AUC of 0.918-0.945, a sensitivity of 91.5%, and a specificity of 88.0%, precisely localizing PDAC as small as 5 mm. Importantly, ePAI detected PDACs on prediagnostic CT scans obtained 3 to 36 months before clinical diagnosis that had originally been overlooked by radiologists. It successfully detected and localized PDACs in 75 of 159 patients, with a median lead time of 347 days before clinical diagnosis. Our multi-reader study showed that ePAI significantly outperformed 30 board-certified radiologists by 50.3% (P < 0.05) in sensitivity while maintaining a comparable specificity of 95.4% in detecting PDACs early and prediagnostic. These findings suggest its potential of ePAI as an assistive tool to improve early detection of pancreatic cancer.

</details>


### [195] [PI-Light: Physics-Inspired Diffusion for Full-Image Relighting](https://arxiv.org/abs/2601.22135)
*Zhexin Liang,Zhaoxi Chen,Yongwei Chen,Tianyi Wei,Tengfei Wang,Xingang Pan*

Main category: cs.CV

TL;DR: 本文提出了一种名为 π-Light 的两阶段框架，利用物理启发的扩散模型来解决全场景重光照的挑战，该框架通过批次感知注意力、物理引导的神经渲染和物理启发的损失来增强模型在真实世界场景中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有全场景重光照方法在数据收集、物理合理性和泛化能力方面存在不足，特别是在弥合合成与真实数据之间差距方面效果不佳。

Method: 采用一个两阶段框架，结合了物理启发的扩散模型。具体包括：(i) 批次感知注意力，用于提高图像集合中固有属性预测的一致性；(ii) 物理引导的神经渲染模块，强制执行物理上合理的全局光传输；(iii) 物理启发的损失函数，使训练过程朝着物理上有意义的参数空间收敛；(iv) 构建了一个包含多样化物体和场景的、在受控光照条件下拍摄的数据集。

Result: π-Light 能够合成各种材料上的镜面高光和漫反射，并且相比现有方法，在真实世界场景中表现出更优越的泛化能力。

Conclusion: π-Light 通过结合物理原理和扩散模型，成功解决了全场景重光照中的关键挑战，并为该领域的下游评估提供了一个坚实的基准。

Abstract: Full-image relighting remains a challenging problem due to the difficulty of collecting large-scale structured paired data, the difficulty of maintaining physical plausibility, and the limited generalizability imposed by data-driven priors. Existing attempts to bridge the synthetic-to-real gap for full-scene relighting remain suboptimal. To tackle these challenges, we introduce Physics-Inspired diffusion for full-image reLight ($π$-Light, or PI-Light), a two-stage framework that leverages physics-inspired diffusion models. Our design incorporates (i) batch-aware attention, which improves the consistency of intrinsic predictions across a collection of images, (ii) a physics-guided neural rendering module that enforces physically plausible light transport, (iii) physics-inspired losses that regularize training dynamics toward a physically meaningful landscape, thereby enhancing generalizability to real-world image editing, and (iv) a carefully curated dataset of diverse objects and scenes captured under controlled lighting conditions. Together, these components enable efficient finetuning of pretrained diffusion models while also providing a solid benchmark for downstream evaluation. Experiments demonstrate that $π$-Light synthesizes specular highlights and diffuse reflections across a wide variety of materials, achieving superior generalization to real-world scenes compared with prior approaches.

</details>


### [196] [Do VLMs Perceive or Recall? Probing Visual Perception vs. Memory with Classic Visual Illusions](https://arxiv.org/abs/2601.22150)
*Xiaoxiao Sun,Mingyang Li,Kun yuan,Min Woo Sun,Mark Endo,Shengguang Wu,Changlin Li,Yuhui Zhang,Zeyu Wang,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: 本研究提出了一个名为VI-Probe的视觉错觉框架，用于分析大型视觉语言模型（VLMs）是真正感知视觉变化还是仅仅依赖记忆。通过量化模型对错觉因素变化的稳定性和敏感性，研究发现不同模型（如GPT-5、Claude-Opus-4.1、Qwen）在面对视觉变化时表现出不同的问题根源，如记忆覆盖、感知-记忆竞争或视觉处理限制。这挑战了单一机制解释的观点，并强调了基于探测的评估方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的VLMs在面对视觉错觉时，即使错觉因素被反转，也常常给出与原始图像相同的答案，尽管这种视觉变化对人类来说显而易见。这引发了一个根本性问题：VLMs是否真正理解视觉变化，还是仅仅在回忆固定的模式？现有研究虽然观察到这一现象，但其根本原因尚不清楚。因此，需要一个系统性的方法来区分视觉感知和语言驱动的回忆。

Method: 研究提出了一个名为VI-Probe的可控视觉错觉框架，该框架包含分级扰动和匹配的视觉对照（不含错觉诱导因素），旨在将视觉感知与语言驱动的回忆分离开来。研究不只关注平均准确率，而是通过“极性翻转一致性”（Polarity-Flip Consistency）、“模板固定指数”（Template Fixation Index）以及与匹配对照标准化的“错觉乘数”（illusion multiplier）来衡量模型的稳定性和敏感性。

Result: 在不同模型家族的实验中，研究发现响应持续性（response persistence）是由多种不同原因造成的，而非单一机制。具体来说，GPT-5表现出记忆覆盖（memory override）的现象，Claude-Opus-4.1显示出感知-记忆竞争（perception-memory competition），而Qwen变体则暗示了视觉处理限制（visual-processing limits）。

Conclusion: 研究结论是，VLMs在面对视觉错觉时的响应持续性并非由单一原因引起，而是源于多种异质性机制。这一发现挑战了将此现象归结为单一原因的观点，并促使研究者们采用基于探测的评估方法，该方法能够同时衡量模型对知识的掌握程度以及对受控视觉变化的敏感性。

Abstract: Large Vision-Language Models (VLMs) often answer classic visual illusions "correctly" on original images, yet persist with the same responses when illusion factors are inverted, even though the visual change is obvious to humans. This raises a fundamental question: do VLMs perceive visual changes or merely recall memorized patterns? While several studies have noted this phenomenon, the underlying causes remain unclear. To move from observations to systematic understanding, this paper introduces VI-Probe, a controllable visual-illusion framework with graded perturbations and matched visual controls (without illusion inducer) that disentangles visually grounded perception from language-driven recall. Unlike prior work that focuses on averaged accuracy, we measure stability and sensitivity using Polarity-Flip Consistency, Template Fixation Index, and an illusion multiplier normalized against matched controls. Experiments across different families reveal that response persistence arises from heterogeneous causes rather than a single mechanism. For instance, GPT-5 exhibits memory override, Claude-Opus-4.1 shows perception-memory competition, while Qwen variants suggest visual-processing limits. Our findings challenge single-cause views and motivate probing-based evaluation that measures both knowledge and sensitivity to controlled visual change. Data and code are available at https://sites.google.com/view/vi-probe/.

</details>


### [197] [One-step Latent-free Image Generation with Pixel Mean Flows](https://arxiv.org/abs/2601.22158)
*Yiyang Lu,Susie Lu,Qiao Sun,Hanhong Zhao,Zhicheng Jiang,Xianbang Wang,Tianhong Li,Zhengyang Geng,Kaiming He*

Main category: cs.CV

TL;DR: 本文提出了pixel MeanFlow (pMF)，一种one-step、无潜空间的扩散/流模型，通过将网络输出空间（x-prediction）和损失空间（速度空间中的MeanFlow）分开，并在ImageNet上取得了SOTA的生成结果。


<details>
  <summary>Details</summary>
Motivation: 现有先进的扩散/流模型通常依赖多步采样和潜空间操作。本研究旨在进一步推动one-step、无潜空间的图像生成模型的发展。

Method: pMF将网络目标设计为预测图像流形上的x，同时将损失定义在速度空间中的MeanFlow。模型引入了一个简单的变换连接图像流形和平均速度场。

Result: pMF在ImageNet 256x256分辨率上实现了2.22 FID，在512x512分辨率上实现了2.48 FID，达到了one-step无潜空间的SOTA生成性能。

Conclusion: pMF成功实现了one-step、无潜空间的图像生成，并在实验中取得了优异的结果，为扩散/流生成模型的研究开辟了新的方向。

Abstract: Modern diffusion/flow-based models for image generation typically exhibit two core characteristics: (i) using multi-step sampling, and (ii) operating in a latent space. Recent advances have made encouraging progress on each aspect individually, paving the way toward one-step diffusion/flow without latents. In this work, we take a further step towards this goal and propose "pixel MeanFlow" (pMF). Our core guideline is to formulate the network output space and the loss space separately. The network target is designed to be on a presumed low-dimensional image manifold (i.e., x-prediction), while the loss is defined via MeanFlow in the velocity space. We introduce a simple transformation between the image manifold and the average velocity field. In experiments, pMF achieves strong results for one-step latent-free generation on ImageNet at 256x256 resolution (2.22 FID) and 512x512 resolution (2.48 FID), filling a key missing piece in this regime. We hope that our study will further advance the boundaries of diffusion/flow-based generative models.

</details>


### [198] [BLO-Inst: Bi-Level Optimization Based Alignment of YOLO and SAM for Robust Instance Segmentation](https://arxiv.org/abs/2601.22061)
*Li Zhang,Pengtao Xie*

Main category: cs.CV

TL;DR: 本研究提出了一种名为BLO-Inst的统一框架，通过双层优化来解决SAM模型依赖手动提示的限制，将目标检测器与SAM对齐，使其生成的边界框更适合作为SAM的分割提示，从而实现更自动化的分割。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM模型在零样本图像分割方面取得了巨大成功，但其对手动提示的依赖限制了其在完全自动化场景中的应用。现有方法将目标检测器作为提示生成器存在目标不匹配（检测器优化目标与SAM提示需求不符）和对齐过拟合（检测器仅记忆训练样本的提示调整）的问题。

Method: BLO-Inst采用双层优化（bi-level optimization）框架来解决目标检测与分割目标之间的不匹配问题。该框架将对齐问题设计为一个嵌套优化问题，并在不重叠的数据集划分上进行。下层优化：在子集 $D_1$ 上，SAM根据当前的检测提议进行微调，以最大化分割保真度。上层优化：在独立的子集 $D_2$ 上，更新检测器，使其生成的边界框能够显式地最小化微调后SAM在 $D_2$ 上的验证损失。

Result: BLO-Inst在通用和生物医学领域的任务上均取得了优于标准基线方法的性能。实验证明，BLO-Inst有效解决了目标检测器与SAM之间的对齐问题，使得检测器生成的边界框不仅准确，而且能够更好地服务于下游的分割任务。

Conclusion: BLO-Inst通过双层优化实现了检测与分割目标的有效对齐，将目标检测器转化为分割感知的提示生成器，克服了现有方法的局限性，为实现SAM模型的全自动化部署提供了有效途径，并在多项任务中验证了其优越性。

Abstract: The Segment Anything Model has revolutionized image segmentation with its zero-shot capabilities, yet its reliance on manual prompts hinders fully automated deployment. While integrating object detectors as prompt generators offers a pathway to automation, existing pipelines suffer from two fundamental limitations: objective mismatch, where detectors optimized for geometric localization do not correspond to the optimal prompting context required by SAM, and alignment overfitting in standard joint training, where the detector simply memorizes specific prompt adjustments for training samples rather than learning a generalizable policy. To bridge this gap, we introduce BLO-Inst, a unified framework that aligns detection and segmentation objectives by bi-level optimization. We formulate the alignment as a nested optimization problem over disjoint data splits. In the lower level, the SAM is fine-tuned to maximize segmentation fidelity given the current detection proposals on a subset ($D_1$). In the upper level, the detector is updated to generate bounding boxes that explicitly minimize the validation loss of the fine-tuned SAM on a separate subset ($D_2$). This effectively transforms the detector into a segmentation-aware prompt generator, optimizing the bounding boxes not just for localization accuracy, but for downstream mask quality. Extensive experiments demonstrate that BLO-Inst achieves superior performance, outperforming standard baselines on tasks in general and biomedical domains.

</details>


### [199] [EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos with Diffusion Transformers](https://arxiv.org/abs/2601.22127)
*John Flynn,Wolfgang Paier,Dimitar Dinev,Sam Nhut Nguyen,Hayk Poghosyan,Manuel Toribio,Sandipan Banerjee,Guy Gafni*

Main category: cs.CV

TL;DR: EditYourself是一个基于DiT的框架，通过文本编辑实现说话头视频的音频驱动视频到视频编辑，能够添加、删除和重新计时视频中的语音内容，同时保持运动、时间连贯性、说话人身份和唇部同步。


<details>
  <summary>Details</summary>
Motivation: 现有生成视频模型在从头生成视频方面表现出色，但在编辑现有视频方面存在不足，尤其是在需要修改语音内容而又要保持运动、时间连贯性、说话人身份和唇部同步的场景下，这阻碍了其在专业视频后期制作中的应用。

Method: 提出EditYourself框架，基于DiT（Diffusion Transformer）模型，通过音频条件和区域感知、以编辑为中心的训练扩展来增强其视频到视频（V2V）编辑能力。利用时空修复（spatiotemporal inpainting）技术实现精确的唇部同步和时间连贯的性能重构，包括合成新插入片段中的逼真人类运动，并保持长时间内的视觉保真度和身份一致性。

Result: EditYourself能够实现基于文本编辑的说话头视频修改，包括无缝添加、删除和重新计时视觉上说话的内容，同时保持原有的运动、时间连贯性、说话人身份和精确的唇部同步。该框架能够在长时段内维持视觉保真度和身份一致性。

Conclusion: EditYourself是迈向将生成视频模型作为专业视频后期制作实用工具的重要一步，它解决了现有模型在编辑预录视频中的关键挑战，实现了更灵活、更精确的视频编辑功能。

Abstract: Current generative video models excel at producing novel content from text and image prompts, but leave a critical gap in editing existing pre-recorded videos, where minor alterations to the spoken script require preserving motion, temporal coherence, speaker identity, and accurate lip synchronization. We introduce EditYourself, a DiT-based framework for audio-driven video-to-video (V2V) editing that enables transcript-based modification of talking head videos, including the seamless addition, removal, and retiming of visually spoken content. Building on a general-purpose video diffusion model, EditYourself augments its V2V capabilities with audio conditioning and region-aware, edit-focused training extensions. This enables precise lip synchronization and temporally coherent restructuring of existing performances via spatiotemporal inpainting, including the synthesis of realistic human motion in newly added segments, while maintaining visual fidelity and identity consistency over long durations. This work represents a foundational step toward generative video models as practical tools for professional video post-production.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [200] [asr_eval: Algorithms and tools for multi-reference and streaming speech recognition evaluation](https://arxiv.org/abs/2601.20992)
*Oleg Sedukhin,Andrey Kostin*

Main category: cs.CL

TL;DR: 本文提出改进语音识别评估方法，包括支持多参考、任意长度插入和更好的词对齐的字符串对齐算法，并构建了包含长篇在野俄语语音的测试集 DiverseSpeech-Ru。研究发现模型容易适应特定数据集的标注，导致指标虚高。此外，还开发了流式语音识别评估工具，并提供了通用模型接口。


<details>
  <summary>Details</summary>
Motivation: 现有语音识别评估方法在处理非拉丁语系、词形变化丰富、口语化或长篇语音时存在局限性，且模型可能因适应特定标注而产生虚假的性能提升。

Method: 提出了一种支持多参考、任意长度插入和改进词对齐的字符串对齐算法。收集了长篇在野俄语语音测试集 DiverseSpeech-Ru，并对现有俄语测试集进行多参考重标注。研究了模型在对应训练集上的微调动态。开发了流式语音识别评估工具和多转录比对可视化工具。提供了多种离线和流式语音识别模型的统一接口。

Result: 改进的字符串对齐算法能更好地处理复杂语音。模型存在数据集标注适应性问题，可能导致指标虚高。新数据集 DiverseSpeech-Ru 提供了长篇在野俄语语音评估的资源。

Conclusion: 提出的改进评估方法能更准确地衡量语音识别性能，尤其是在非拉丁语系和复杂语音场景下。模型标注适应性是评估中需要注意的问题。新数据集和工具将有助于提高语音识别评估的可靠性。

Abstract: We propose several improvements to the speech recognition evaluation. First, we propose a string alignment algorithm that supports both multi-reference labeling, arbitrary-length insertions and better word alignment. This is especially useful for non-Latin languages, those with rich word formation, to label cluttered or longform speech. Secondly, we collect a novel test set DiverseSpeech-Ru of longform in-the-wild Russian speech with careful multi-reference labeling. We also perform multi-reference relabeling of popular Russian tests set and study fine-tuning dynamics on its corresponding train set. We demonstrate that the model often adopts to dataset-specific labeling, causing an illusion of metric improvement. Based on the improved word alignment, we develop tools to evaluate streaming speech recognition and to align multiple transcriptions to compare them visually. Additionally, we provide uniform wrappers for many offline and streaming speech recognition models. Our code will be made publicly available.

</details>


### [201] [DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents](https://arxiv.org/abs/2601.20975)
*Nikita Gupta,Riju Chatterjee,Lukas Haas,Connie Tao,Andrew Wang,Chang Liu,Hidekazu Oiwa,Elena Gribovskaya,Jan Ackermann,John Blitzer,Sasha Goldshtein,Dipanjan Das*

Main category: cs.CL

TL;DR: DeepSearchQA是一个包含900个提示的基准测试，用于评估在17个不同领域的多步信息检索任务中代理的能力，重点关注信息整合、去重和停止准则推理，并发现现有模型在召回率和精确度之间存在显著的性能限制。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注单一答案检索或事实性检查，未能充分评估代理在复杂搜索规划和信息整合方面的能力。作者旨在创建一个更具挑战性的基准，以评估代理在多步信息检索任务中的信息整合、去重和停止准则推理能力。

Method: 构建了一个包含900个手工设计的、跨越17个领域的任务的DeepSearchQA基准。每个任务被设计成因果链，需要代理系统地从不同来源收集碎片信息，进行去重和实体解析，并判断搜索的停止时机。然后，使用该基准对最先进的代理架构进行了评估。

Result: 评估结果显示，即使是最先进的模型在DeepSearchQA基准上也表现出显著的性能限制，难以平衡高召回率和高精确度。观察到代理存在过早停止（检索不足）和过度检索（低置信度答案）等失败模式。

Conclusion: DeepSearchQA揭示了当前代理设计的重大局限性，并为未来研究提供了诊断工具，以推动代理朝着更鲁棒、更深入的研究能力发展。

Abstract: We introduce DeepSearchQA, a 900-prompt benchmark for evaluating agents on difficult multi-step information-seeking tasks across 17 different fields. Unlike traditional benchmarks that target single answer retrieval or broad-spectrum factuality, DeepSearchQA features a dataset of challenging, handcrafted tasks designed to evaluate an agent's ability to execute complex search plans to generate exhaustive answer lists. This shift in design explicitly tests three critical, yet under-evaluated capabilities: 1) systematic collation of fragmented information from disparate sources, 2) de-duplication and entity resolution to ensure precision, and 3) the ability to reason about stopping criteria within an open-ended search space. Each task is structured as a causal chain, where discovering information for one step is dependent on the successful completion of the previous one, stressing long-horizon planning and context retention. All tasks are grounded in the open web with objectively verifiable answer sets. Our comprehensive evaluation of state-of-the-art agent architectures reveals significant performance limitations: even the most advanced models struggle to balance high recall with precision. We observe distinct failure modes ranging from premature stopping (under-retrieval) to hedging behaviors, where agents cast an overly wide net of low-confidence answers to artificially boost recall. These findings highlight critical headroom in current agent designs and position DeepSearchQA as an essential diagnostic tool for driving future research toward more robust, deep-research capabilities.

</details>


### [202] [Position-invariant Fine-tuning of Speech Enhancement Models with Self-supervised Speech Representations](https://arxiv.org/abs/2601.21084)
*Amit Meghanani,Thomas Hain*

Main category: cs.CL

TL;DR: 本文提出了一种新的表示引导语音增强（SE）方法，通过使用软DTW损失和速度扰动来解决现有SE模型在利用自监督学习（SSL）表示进行微调时过度依赖位置信息的问题，实验证明该方法收敛更快且下游任务性能更好。


<details>
  <summary>Details</summary>
Motivation: 现有的前端语音增强（SE）模型与自监督学习（SSL）模型结合对下游任务有利，但现有方法（如使用均方误差MSE损失）倾向于利用SSL模型中的位置嵌入，导致优化目标通过位置相关性最小化而非内容信息，这是一个普遍的自监督表示微调的局限性。

Method: 本文将问题定义为自监督表示微调的普遍限制，并通过两种表示引导SE策略进行研究：（1）零填充（Zero-padding），（2）速度扰动（Speed perturbations）结合软DTW（soft-DTW）损失。

Result: 实验结果表明，基于软DTW的方法实现了更快的收敛速度，并提升了下游任务的性能。

Conclusion: 本文强调了在基于SSL的语音建模中，位置不变（position-invariant）的微调对于提升模型性能的重要性，并提出了一种有效的软DTW-based方法。

Abstract: Integrating front-end speech enhancement (SE) models with self-supervised learning (SSL)-based speech models is effective for downstream tasks in noisy conditions. SE models are commonly fine-tuned using SSL representations with mean squared error (MSE) loss between enhanced and clean speech. However, MSE is prone to exploiting positional embeddings in SSL models, allowing the objective to be minimised through positional correlations instead of content-related information. This work frames the problem as a general limitation of self-supervised representation fine-tuning and investigates it through representation-guided SE. Two strategies are considered: (1) zero-padding, previously explored in SSL pre-training but here examined in the fine-tuning setting, and (2) speed perturbations with a soft-DTW loss. Experiments show that the soft-DTW-based approach achieves faster convergence and improved downstream performance, underscoring the importance of position-invariant fine-tuning in SSL-based speech modelling.

</details>


### [203] [UrduBench: An Urdu Reasoning Benchmark using Contextually Ensembled Translations with Human-in-the-Loop](https://arxiv.org/abs/2601.21000)
*Muhammad Ali Shafique,Areej Mehboob,Layba Fiaz,Muhammad Usman Qadeer,Hamza Farooq*

Main category: cs.CL

TL;DR: 本文提出了一个结合集成翻译和人工验证的框架，用于构建低资源语言（特别是乌尔都语）的推理基准测试集 UrduBench。通过评估不同类型的 LLMs 在这些基准上的表现，研究揭示了多步和符号推理的挑战，并强调了语言一致性对推理能力的重要性。该方法可推广到其他低资源语言。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如乌尔都语）缺乏标准化的推理评估基准，现有评估受机器翻译影响且侧重于通用语言任务，这限制了对 LLM 在这些语言中推理能力的准确评估。

Method: 提出一个上下文集成翻译框架，并结合人工验证，利用多个翻译系统将现有的英语推理和问答基准（MGSM, MATH-500, CommonSenseQA, OpenBookQA）翻译成乌尔都语，形成 UrduBench。然后，使用多种提示策略在 UrduBench 上评估了不同推理和指令微调的 LLMs。

Result: 在 UrduBench 上对 LLMs 的评估显示，模型在不同数据集、难度级别、模型架构、模型规模和语言一致性测试中表现出差异。研究发现，多步和符号推理任务在乌尔都语中具有挑战性，稳定的语言对齐是可靠推理的关键先决条件。

Conclusion: 本文成功建立了一个可扩展的方法来标准化乌尔都语的推理评估，并提供了关于多语言推理失败的实证见解。该框架适用于其他低资源语言，并为未来研究奠定了基础。

Abstract: Recent advances in large language models (LLMs) have led to strong reasoning capabilities; however, evaluating such models in low-resource languages remains challenging due to the lack of standardized benchmarks. In particular, Urdu reasoning evaluation has been limited by the sensitivity of machine translation and an emphasis on general language tasks rather than reasoning benchmarks. In this paper, we propose a contextually ensembled translation framework with human-in-the-loop validation that leverages multiple translation systems to develop Urdu reasoning benchmarks while preserving contextual and structural integrity. Using this framework, we translate widely adopted reasoning and question-answering benchmarks, including MGSM, MATH-500, CommonSenseQA, and OpenBookQA, into Urdu, collectively referred to as UrduBench, and conduct a comprehensive evaluation of both reasoning-oriented and instruction-tuned LLMs across multiple prompting strategies. Our analysis reveals performance differences across (1) four datasets, (2) five task difficulty levels, (3) diverse model architectures, (4) multiple model scaling settings, and (5) language consistency tests. We find that multi-step and symbolic reasoning tasks pose significant challenges in Urdu, and that stable language alignment is a critical prerequisite for robust reasoning. Overall, our work establishes a scalable methodology for standardized reasoning evaluation in Urdu and provides empirical insights into multilingual reasoning failures. This experimental setup is also broadly applicable to other low-resource languages. The code and datasets will be publicly released.

</details>


### [204] [ChunkWise LoRA: Adaptive Sequence Partitioning for Memory-Efficient Low-Rank Adaptation and Accelerated LLM Inference](https://arxiv.org/abs/2601.21109)
*Ketan Thakkar,Maitreyi Chatterjee,Ramasubramanian Balasubramanian,Achyuthan Jootoo,Rajendra Ugrani*

Main category: cs.CL

TL;DR: 提出了一种名为 ChunkWise LoRA 的动态自适应方法，用于优化大型语言模型（LLM）的低秩适应（LoRA），通过根据 token 复杂度动态划分序列和分配 LoRA 配置，显著降低了延迟和内存占用，同时保持或提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有 LoRA 方法在所有输入 token 上使用静态且统一的秩配置，忽略了 token 复杂度的变化及其计算需求，导致效率低下。

Method: ChunkWise LoRA 动态地将序列划分为可变长度的块，并根据 token 复杂度为每个块分配定制的低秩配置。该方法包含一个运行时调度器，用于估计 token 难度、自适应分块，并使用秩梯级机制选择每个块的 LoRA 秩和缩放。此外，还引入了边界安全组合模块和策略驱动的 KV 缓存策略以保持输出一致性。

Result: 与基线 LoRA 相比，ChunkWise LoRA 在 Wikitext-103 和 SQuAD 等基准数据集上实现了高达 34% 的延迟降低和 38% 的内存减少，同时在 BLEU、EM 和困惑度等任务性能指标上保持或有所提高。

Conclusion: ChunkWise LoRA 是一种高效且实用的方法，能够根据输入 token 的动态变化自适应地调整 LoRA 配置，从而显著提高 LLM 推理的效率，并且与现有 Transformer 架构和推理框架兼容，易于实际部署。

Abstract: Recent advances in low-rank adaptation (LoRA) have enabled efficient fine-tuning of large language models (LLMs) with minimal additional parameters. However, existing LoRA methods apply static rank configurations uniformly across all input tokens, ignoring variation in token complexity and computational requirements. In this work, we propose ChunkWise LoRA, a dynamic and adaptive approach that partitions sequences into variable-length chunks based on token complexity and assigns each chunk a tailored low-rank configuration. Our system introduces a runtime scheduler that estimates token difficulty, performs adaptive chunking, and selects per-chunk LoRA rank and scaling using a rank-ladder mechanism. To preserve output consistency, we further introduce a boundary-safe composition module and integrate policy-driven KV-cache strategies. Experiments on benchmark datasets such as Wikitext-103 and SQuAD demonstrate that ChunkWise LoRA achieves up to 34\% lower latency and 38% memory reduction compared to baseline LoRA, while maintaining or improving task performance metrics like BLEU, EM, and perplexity. The proposed framework remains fully compatible with existing transformer architectures and inference frameworks, providing a practical solution for real-world deployment of parameter-efficient LLMs.

</details>


### [205] [Multi-task Code LLMs: Data Mix or Model Merge?](https://arxiv.org/abs/2601.21115)
*Mingzhi Zhu,Boris Sobolev,Rahul Krishna,Raju Pavuluri,Stacy Patterson,Michele Merler*

Main category: cs.CL

TL;DR: 研究人员比较了两种为小型代码 LLM 实现多任务学习的方法：数据混合和模型合并。结果表明，在较大模型规模下，模型合并在代码生成和摘要任务上表现最佳，甚至能超越单独微调的模型；而在较小模型规模下，数据混合是更优的选择。研究还提出了一种权重分析技术来理解任务对模型参数的影响。


<details>
  <summary>Details</summary>
Motivation: 在代理框架中部署小型、专业化的代码 LLM 受到关注，需要一种能够平衡性能、约束和成本的高效多任务学习策略。

Method: 比较了数据混合和模型合并两种策略，在 Qwen Coder 和 DeepSeek Coder 两个模型系列、2B 和 7B 两种规模下，针对代码生成和代码摘要任务进行了微调和实验。并引入了权重分析技术来解释模型行为。

Result: 在较大模型规模下，模型合并在 HumanEval、MBPP 和 CodeXGlue 基准上表现最佳，代码生成任务性能达到专门模型性能的 96%，同时保留了摘要能力。合并后的模型有时甚至优于单独微调的模型。在较小规模下，数据混合是更优策略。权重分析揭示了不同任务对模型参数的影响。

Conclusion: 精心的合并和混合策略可以有效地结合特定任务的能力，而不会显著降低性能，这使得它们成为资源受限部署场景的理想选择。

Abstract: Recent research advocates deploying smaller, specialized code LLMs in agentic frameworks alongside frontier models, sparking interest in efficient strategies for multi-task learning that balance performance, constraints, and costs. We compare two approaches for creating small, multi-task code LLMs: data mixing versus model merging. We conduct extensive experiments across two model families (Qwen Coder and DeepSeek Coder) at two scales (2B and 7B parameters), fine-tuning them for code generation and code summarization tasks. Our evaluation on HumanEval, MBPP, and CodeXGlue benchmarks reveals that model merging achieves the best overall performance at larger scale across model families, retaining 96% of specialized model performance on code generation tasks while maintaining summarization capabilities. Notably, merged models can even surpass individually fine-tuned models, with our best configuration of Qwen Coder 2.5 7B model achieving 92.7% Pass@1 on HumanEval compared to 90.9% for its task-specific fine-tuned equivalent. At a smaller scale we find instead data mixing to be a preferred strategy. We further introduce a weight analysis technique to understand how different tasks affect model parameters and their implications for merging strategies. The results suggest that careful merging and mixing strategies can effectively combine task-specific capabilities without significant performance degradation, making them ideal for resource-constrained deployment scenarios.

</details>


### [206] [EnsembleLink: Accurate Record Linkage Without Training Data](https://arxiv.org/abs/2601.21138)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: 本文提出了一种名为EnsembleLink的记录链接方法，该方法利用预训练语言模型，无需标注数据即可实现高精度匹配，并且效率高。


<details>
  <summary>Details</summary>
Motivation: 现有记录链接方法准确性不高或需要大量标注数据，且研究人员常将其视为预处理步骤，忽略了链接错误对下游分析的影响。作者旨在开发一种高精度且无需标注的记录链接方法。

Method: EnsembleLink利用预训练语言模型学习实体间的语义关系，以匹配不同数据集中的记录。该方法在本地运行，不依赖外部API，并在多个基准数据集上进行了评估。

Result: EnsembleLink在城市名称、人名、组织、多语言政党和文献记录等基准数据集上，匹配精度与需要大量标注的方法相当甚至更高。

Conclusion: EnsembleLink是一种高效、高精度且无需标注数据的记录链接新方法，能够有效解决现有方法的不足，并有望改善实证社会科学研究的准确性。

Abstract: Record linkage, the process of matching records that refer to the same entity across datasets, is essential to empirical social science but remains methodologically underdeveloped. Researchers treat it as a preprocessing step, applying ad hoc rules without quantifying the uncertainty that linkage errors introduce into downstream analyses. Existing methods either achieve low accuracy or require substantial labeled training data. I present EnsembleLink, a method that achieves high accuracy without any training labels. EnsembleLink leverages pre-trained language models that have learned semantic relationships (e.g., that "South Ozone Park" is a neighborhood in "New York City" or that "Lutte ouvriere" refers to the Trotskyist "Workers' Struggle" party) from large text corpora. On benchmarks spanning city names, person names, organizations, multilingual political parties, and bibliographic records, EnsembleLink matches or exceeds methods requiring extensive labeling. The method runs locally on open-source models, requiring no external API calls, and completes typical linkage tasks in minutes.

</details>


### [207] [Output-Space Search: Targeting LLM Generations in a Frozen Encoder-Defined Output Space](https://arxiv.org/abs/2601.21169)
*Tobias Materzok*

Main category: cs.CL

TL;DR: 本文提出了一种名为OS-Search的方法，将大语言模型的生成过程转化为端点搜索，通过在冻结的编码器定义的3D输出空间中选择目标点，并利用检索驱动的策略生成接近目标点的输出，从而实现并行搜索和黑盒优化，提高了生成的多样性，并能在不泄露目标函数的情况下优化代码生成。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM生成方法存在路径依赖性和效率问题。作者希望开发一种新的方法，能够在大语言模型的输出空间中进行更有效率的搜索和优化，同时提高生成结果的多样性。

Method: OS-Search方法包含一个外层循环，用于在冻结编码器定义的3D输出空间Z中选择目标点z*。一个检索驱动的策略通过序列级强化学习进行训练，旨在于标准的自回归解码下生成坐标接近z*的输出。这种方法支持在Z空间进行并行搜索和黑盒优化，避免了依赖路径的Token或程序搜索。

Result: 在故事生成任务中，对Z空间（文本）进行搜索比Prompt-chaining方法产生了3.1倍的LLM评分多样性。在代码生成任务中，对Z空间（代码）进行贝叶斯优化，在相同的推理预算下，能够改进一个未告知控制器的目标函数，同时保持代码的有效性。

Conclusion: OS-Search是一种有效的将LLM生成转化为端点搜索的框架，能够在大语言模型的输出空间中实现高效的并行搜索和黑盒优化，显著提高了生成的多样性，并能在代码生成等任务中实现无监督的目标优化。

Abstract: We introduce Output-Space Search (OS-Search), which turns LLM generation into endpoint search. An outer loop selects a target z* in a frozen encoder-defined 3D output space Z, and a retrieval-grounded policy trained with sequence-level RL generates outputs whose coordinates land near z* under standard autoregressive decoding. This enables parallel sweeps and black-box optimization in Z without path-dependent token/program search. On stories, sweeping Z (text) yields 3.1x higher LLM-scored diversity than prompt-chaining. On code, Bayesian optimization over Z (code) improves an objective withheld from the controller under matched inference budgets while preserving validity.

</details>


### [208] [From Linear Input to Hierarchical Structure: Function Words as Statistical Cues for Language Learning](https://arxiv.org/abs/2601.21191)
*Xiulin Yang,Heidi Getz,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 研究发现，频率高、与句法结构关联性强、与短语边界对齐的词语（功能词）在跨语言中普遍存在，并且有助于神经网络模型学习语言的层级结构。其中，频率和结构关联性对学习的贡献更大。


<details>
  <summary>Details</summary>
Motivation: 研究功能词的统计分布特性如何在跨语言环境中支持语言层级结构的习得，特别是对于神经网络学习者。

Method: 利用跨语言语料库分析，验证功能词的三个关键特性（高频、结构关联性、边界对齐）。然后，通过反事实语言建模和消融实验，评估这些特性对神经网络学习能力的影响。

Result: 研究证实了功能词的三个特性在186种语言中普遍存在。实验表明，保留这三个特性的语言变体更容易被神经网络学习。其中，功能词的频率和结构关联性对学习的贡献度高于边界对齐。

Conclusion: 功能词的统计特性是支持神经网络学习语言层级结构的重要因素。不同的学习条件会导致模型对功能词的依赖程度不同，即使性能相似，其内部学习机制也可能存在差异。

Abstract: What statistical conditions support learning hierarchical structure from linear input? In this paper, we address this question by focusing on the statistical distribution of function words. Function words have long been argued to play a crucial role in language acquisition due to their distinctive distributional properties, including high frequency, reliable association with syntactic structure, and alignment with phrase boundaries. We use cross-linguistic corpus analysis to first establish that all three properties are present across 186 studied languages. Next, we use a combination of counterfactual language modeling and ablation experiments to show that language variants preserving all three properties are more easily acquired by neural learners, with frequency and structural association contributing more strongly than boundary alignment. Follow-up probing and ablation analyses further reveal that different learning conditions lead to systematically different reliance on function words, indicating that similar performance can arise from distinct internal mechanisms.

</details>


### [209] [Scaling Embeddings Outperforms Scaling Experts in Language Models](https://arxiv.org/abs/2601.21204)
*Hong Liu,Jiaqi Zhang,Chao Wang,Xing Hu,Linkun Lyu,Jiaqi Sun,Xurui Yang,Bo Wang,Fengcun Li,Yulei Qian,Lingtong Si,Yerui Sun,Rumei Li,Peng Pei,Yuchen Xie,Xunliang Cai*

Main category: cs.CL

TL;DR: 本文探讨了通过嵌入层扩展模型稀疏性的方法，发现其在特定情况下比传统的专家层扩展（MoE）具有更好的性能和效率权衡。研究识别了影响嵌入扩展有效性的关键架构因素，并结合系统优化和推测解码实现了推理加速。基于此，作者提出了 LongCat-Flash-Lite 模型，该模型在嵌入层分配了大量参数，但仍优于同等规模的 MoE 模型，尤其在智能体和代码领域表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的 Mixture-of-Experts (MoE) 架构在扩展模型稀疏性方面存在边际效益递减和系统瓶颈问题。因此，研究者们希望探索一种新的、正交的稀疏性扩展维度——嵌入层扩展。

Method: 通过理论分析和实验，研究者们系统地评估了嵌入层扩展的有效性，识别了影响其性能的关键架构因素（如参数预算、模型宽度和深度），并结合了系统优化和推测解码技术来提高推理速度。最终，他们构建了一个名为 LongCat-Flash-Lite 的模型。

Result: 嵌入层扩展在特定参数预算下，能够实现比专家层扩展（MoE）更优的帕累托前沿。LongCat-Flash-Lite 模型（68.5B 参数，约 3B 激活）在嵌入层分配了超过 30B 参数，其性能超越了参数量相当的 MoE 基线模型，并在智能体和代码生成等领域展现出强大的竞争力。

Conclusion: 嵌入层扩展是扩展模型稀疏性的一种有效且正交于专家层扩展的维度，能够在特定场景下提供更好的性能和效率。通过对架构因素的深入理解和系统优化，可以有效地将嵌入层稀疏性转化为实际的推理加速，并构建出在特定领域表现出色的模型。

Abstract: While Mixture-of-Experts (MoE) architectures have become the standard for sparsity scaling in large language models, they increasingly face diminishing returns and system-level bottlenecks. In this work, we explore embedding scaling as a potent, orthogonal dimension for scaling sparsity. Through a comprehensive analysis and experiments, we identify specific regimes where embedding scaling achieves a superior Pareto frontier compared to expert scaling. We systematically characterize the critical architectural factors governing this efficacy -- ranging from parameter budgeting to the interplay with model width and depth. Moreover, by integrating tailored system optimizations and speculative decoding, we effectively convert this sparsity into tangible inference speedups. Guided by these insights, we introduce LongCat-Flash-Lite, a 68.5B parameter model with ~3B activated trained from scratch. Despite allocating over 30B parameters to embeddings, LongCat-Flash-Lite not only surpasses parameter-equivalent MoE baselines but also exhibits exceptional competitiveness against existing models of comparable scale, particularly in agentic and coding domains.

</details>


### [210] [Large Language Models Naively Recover Ethnicity from Individual Records](https://arxiv.org/abs/2601.21132)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在无需额外训练数据的情况下，能比现有的贝叶斯改进姓氏地理编码（BISG）方法更准确地从姓名推断族裔，并且适用范围更广，包括美国以外的地区和更具体的分类。研究人员使用佛罗里达州和北卡罗来纳州的选民文件对多种LLMs进行了测试，在平衡样本中，LLM分类准确率最高可达84.7%，优于BISG的68.2%。此外，LLMs还能减少BISG存在的收入偏见，并在黎巴嫩、印度等地的跨国数据中得到验证。通过在LLM标签上微调小型Transformer模型，可以在不产生额外费用的情况下实现本地部署，并超越BISG的准确率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索大型语言模型（LLMs）在无需额外训练数据的情况下，是否能比现有的族裔推断方法（如BISG）更准确、更广泛地从姓名推断族裔，并解决BISG存在的偏见问题。

Method: 研究人员使用佛罗里达州和北卡罗来纳州的选民文件（包含自我报告的种族信息）测试了包括Gemini 3 Flash、GPT-4o以及DeepSeek v3.2和GLM-4.7在内的多种LLMs。他们评估了启用扩展推理和包含元数据（如政党注册信息）对准确率的影响。此外，研究人员还使用黎巴嫩选民登记数据、印度议员数据和印度土地记录数据进行了跨国验证。最后，研究人员通过在LLM标签上微调小型Transformer模型来评估大规模应用的潜力。

Result: LLM-based族裔分类在美国选民文件中达到了高达84.7%的准确率，优于BISG的68.2%。启用扩展推理可将准确率提高1-3个百分点，包含元数据可达86.7%。LLMs有效减少了BISG存在的收入偏见。在黎巴嫩、印度等地的跨国验证中，LLM方法也取得了可观的准确率（例如，黎巴嫩64.3%，印度议员99.2%，印度土地记录74.0%）。在不同国家进行了聚合验证，证明了该方法在区分度高的命名习惯地区可以恢复已知的族裔分布。微调小型Transformer模型在准确率上超越了BISG。

Conclusion: 大型语言模型在从姓名推断族裔方面表现出超越现有方法的潜力，不仅准确率更高，而且适用范围更广，并能缓解现存偏见。通过微调小型模型，可以在成本效益高的情况下实现大规模族裔推断的应用。

Abstract: I demonstrate that large language models can infer ethnicity from names with accuracy exceeding that of Bayesian Improved Surname Geocoding (BISG) without additional training data, enabling inference outside the United States and to contextually appropriate classification categories. Using stratified samples from Florida and North Carolina voter files with self-reported race, LLM-based classification achieves up to 84.7% accuracy, outperforming BISG (68.2%) on balanced samples. I test six models including Gemini 3 Flash, GPT-4o, and open-source alternatives such as DeepSeek v3.2 and GLM-4.7. Enabling extended reasoning can improve accuracy by 1-3 percentage points, though effects vary across contexts; including metadata such as party registration reaches 86.7%. LLM classification also reduces the income bias inherent in BISG, where minorities in wealthier neighborhoods are systematically misclassified as White. I further validate using Lebanese voter registration with religious sect (64.3% accuracy), Indian MPs from reserved constituencies (99.2%), and Indian land records with caste classification (74.0%). Aggregate validation across India, Uganda, Nepal, Armenia, Chile, and Costa Rica using original full-count voter rolls demonstrates that the method recovers known population distributions where naming conventions are distinctive. For large-scale applications, small transformer models fine-tuned on LLM labels exceed BISG accuracy while enabling local deployment at no cost.

</details>


### [211] [Scaling Reasoning Hop Exposes Weaknesses: Demystifying and Improving Hop Generalization in Large Language Models](https://arxiv.org/abs/2601.21214)
*Zhaoyi Li,Jiatong Li,Gangwei Jiang,Linqi Song,Defu Lian,Ying Wei*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在推理步数超出训练分布时的性能下降问题，发现错误集中在特定 token 位置，并由“错误处理头”（ep heads）放大。提出了一种名为“推理时纠错”（test-time correction of reasoning）的轻量级干预方法，通过动态识别和禁用 ep heads 来提高模型在推理步数泛化能力上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，LLMs 在推理步数超出训练分布时（推理步数泛化）性能会急剧下降，但其内部机制尚不明确。本文旨在深入理解这一现象的原因，并提出解决方案。

Method: 作者系统性地研究了多领域任务中的错误模式，发现错误集中于特定 token 位置。通过分析 attention 机制，识别出“错误处理头”（ep heads），这些头会放大错误推理轨迹。基于此，作者提出了一种“推理时纠错”方法，在推理过程中动态识别并禁用 ep heads。

Result: 实验证明，“推理时纠错”方法能够有效提高模型在推理步数泛化任务上的性能，并且在不同任务和 LLMs 上都表现出一致的改进效果。

Conclusion: 错误集中于 token 层面，并由“错误处理头”放大是导致 LLMs 推理步数泛化能力下降的主要原因。所提出的“推理时纠错”方法是一种轻量级且有效的干预手段，能够显著提升模型的泛化能力。

Abstract: Chain-of-thought (CoT) reasoning has become the standard paradigm for enabling Large Language Models (LLMs) to solve complex problems. However, recent studies reveal a sharp performance drop in reasoning hop generalization scenarios, where the required number of reasoning steps exceeds training distributions while the underlying algorithm remains unchanged. The internal mechanisms driving this failure remain poorly understood. In this work, we conduct a systematic study on tasks from multiple domains, and find that errors concentrate at token positions of a few critical error types, rather than being uniformly distributed. Closer inspection reveals that these token-level erroneous predictions stem from internal competition mechanisms: certain attention heads, termed erroneous processing heads (ep heads), tip the balance by amplifying incorrect reasoning trajectories while suppressing correct ones. Notably, removing individual ep heads during inference can often restore the correct predictions. Motivated by these insights, we propose test-time correction of reasoning, a lightweight intervention method that dynamically identifies and deactivates ep heads in the reasoning process. Extensive experiments across different tasks and LLMs show that it consistently improves reasoning hop generalization, highlighting both its effectiveness and potential.

</details>


### [212] [Parametric Knowledge is Not All You Need: Toward Honest Large Language Models via Retrieval of Pretraining Data](https://arxiv.org/abs/2601.21218)
*Christopher Adrian Kusuma,Muhammad Reza Qorib,Hwee Tou Ng*

Main category: cs.CL

TL;DR: 该论文提出了一个更鲁棒的LLM诚实度评估基准数据集，并提出了一种利用预训练数据来构建更诚实LLM的新方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在回答问题方面能力很强，但常常不知道自己的知识边界，容易在缺乏足够知识的领域产生幻觉。因此，研究如何提高LLM的诚实度，使其在不知道时能够诚实地回答“我不知道”，是有必要的。现有评估方法缺乏鲁棒性，未能考虑LLM预训练时所摄入的知识。

Method: 提出一个利用Pythia（一个公开的LLM及其预训练数据）来构建的更鲁棒的LLM诚实度评估基准数据集。此外，还提出了一种利用预训练数据来构建更诚实LLM的新方法。

Result: （本摘要未具体说明实验结果，但暗示了所提出的方法能够更有效地评估和提高LLM的诚实度。）

Conclusion: 通过利用公开的预训练数据，可以构建更鲁棒的LLM诚实度评估基准，并开发出更诚实的LLM。

Abstract: Large language models (LLMs) are highly capable of answering questions, but they are often unaware of their own knowledge boundary, i.e., knowing what they know and what they don't know. As a result, they can generate factually incorrect responses on topics they do not have enough knowledge of, commonly known as hallucination. Rather than hallucinating, a language model should be more honest and respond with "I don't know" when it does not have enough knowledge about a topic. Many methods have been proposed to improve LLM honesty, but their evaluations lack robustness, as they do not take into account the knowledge that the LLM has ingested during its pretraining. In this paper, we propose a more robust evaluation benchmark dataset for LLM honesty by utilizing Pythia, a truly open LLM with publicly available pretraining data. In addition, we also propose a novel method for harnessing the pretraining data to build a more honest LLM.

</details>


### [213] [Multilingual Dysarthric Speech Assessment Using Universal Phone Recognition and Language-Specific Phonemic Contrast Modeling](https://arxiv.org/abs/2601.21205)
*Eunjung Yeo,Julie M. Liss,Visar Berisha,David R. Mortensen*

Main category: cs.CL

TL;DR: 提出了一种多语言语音清晰度评估框架，结合了通用音素识别和语言特定音素解释，能够跨语言评估用户清晰度。


<details>
  <summary>Details</summary>
Motivation: 神经系统疾病（如构音障碍）的流行病学增长，导致言语不清，需要一种适用于多语言的自动化言语清晰度评估方法。现有方法要么局限于单一语言，要么未能捕捉塑造清晰度的语言特定因素。

Method: 该框架整合了通用音素识别技术，并通过对比音韵特征距离实现语言特定的音素解释，从而实现音素到音素的映射和序列比对。评估指标包括音素错误率（PER）、音韵特征错误率（PFER）以及一种新的无比对度量——音素覆盖度（PhonCov）。

Result: 在英语、西班牙语、意大利语和泰米尔语上的分析表明，PER通过映射和比对的结合得到改善，PFER通过单独的比对得到改善，而PhonCov通过映射得到改善。此外，该框架捕捉到了与已知构音障碍言语模式一致的有临床意义的清晰度下降模式。

Conclusion: 所提出的多语言音素生产评估框架能够有效地整合通用和语言特定的信息，从而实现对不同语言下语音清晰度的准确评估，并且能够反映临床观察到的构音障碍言语的退化模式。

Abstract: The growing prevalence of neurological disorders associated with dysarthria motivates the need for automated intelligibility assessment methods that are applicalbe across languages. However, most existing approaches are either limited to a single language or fail to capture language-specific factors shaping intelligibility. We present a multilingual phoneme-production assessment framework that integrates universal phone recognition with language-specific phoneme interpretation using contrastive phonological feature distances for phone-to-phoneme mapping and sequence alignment. The framework yields three metrics: phoneme error rate (PER), phonological feature error rate (PFER), and a newly proposed alignment-free measure, phoneme coverage (PhonCov). Analysis on English, Spanish, Italian, and Tamil show that PER benefits from the combination of mapping and alignment, PFER from alignment alone, and PhonCov from mapping. Further analyses demonstrate that the proposed framework captures clinically meaningful patterns of intelligibility degradation consistent with established observations of dysarthric speech.

</details>


### [214] [MGSM-Pro: A Simple Strategy for Robust Multilingual Mathematical Reasoning Evaluation](https://arxiv.org/abs/2601.21225)
*Tianyi Xu,Kosei Uemura,Alfred Malengo Kondoro,Tadesse Destaw Belay,Catherine Nana Nyaah Essuman,Ifeoma Okoh,Ganiyat Afolabi,Ayodele Awokoya,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 本文提出了MGSM-Pro数据集，扩展了MGSM数据集并引入了GSM-Symbolic方法，通过改变数字、名称和无关上下文来创建同一问题的五个不同实例。在九种语言上的评估显示，许多低资源语言在处理与原始测试集不同的数字实例时，性能会大幅下降。研究还发现，某些专有模型（如Gemini 2.5 Flash和GPT-4.1）在数字实例鲁棒性方面表现较差，而Claude 4.0 Sonnet则更鲁棒。开源模型中，GPT-OSS 120B和DeepSeek V3表现出更强的鲁棒性。研究建议，为了更全面和现实地评估数学推理能力，应使用至少五个不同数字实例来评估每个问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言数学推理评估基准在难度和时效性上落后于英文基准。GSM-Symbolic研究表明，模型在同一问题的不同实例上表现出高方差，但该研究仅限于英文。作者旨在通过创建包含多语言和多实例的基准来解决这一问题，以更全面地评估大型语言模型在数学推理方面的能力，特别是关注低资源语言的性能和模型对数字变化的鲁棒性。

Method: 作者提出了MGSM-Pro数据集，它是MGSM数据集的扩展，结合了GSM-Symbolic方法。该数据集为MGSM数据集中的每个问题生成了五个不同的实例，通过改变名称、数字和无关上下文来实现。研究在九种语言上对模型进行了评估，并分析了不同模型在处理数字实例变化时的性能鲁棒性。

Result: 评估结果显示，许多低资源语言在面对与原始测试集不同的数字实例时，性能会出现显著下降。研究还发现，Gemini 2.5 Flash和GPT-4.1在数字实例鲁棒性方面表现较弱，而Claude 4.0 Sonnet则表现出更好的鲁棒性。在开源模型中，GPT-OSS 120B和DeepSeek V3在数字实例鲁棒性方面表现更强。

Conclusion: 为了获得对数学推理能力的更鲁棒和现实的评估，建议使用至少包含五个不同数字实例的问题集来评估模型。研究强调了在多语言数学推理评估中考虑数字变化鲁棒性的重要性，尤其是在低资源语言方面。

Abstract: Large language models have made substantial progress in mathematical reasoning. However, benchmark development for multilingual evaluation has lagged behind English in both difficulty and recency. Recently, GSM-Symbolic showed a strong evidence of high variance when models are evaluated on different instantiations of the same question; however, the evaluation was conducted only in English. In this paper, we introduce MGSM-Pro, an extension of MGSM dataset with GSM-Symbolic approach. Our dataset provides five instantiations per MGSM question by varying names, digits and irrelevant context. Evaluations across nine languages reveal that many low-resource languages suffer large performance drops when tested on digit instantiations different from those in the original test set. We further find that some proprietary models, notably Gemini 2.5 Flash and GPT-4.1, are less robust to digit instantiation, whereas Claude 4.0 Sonnet is more robust. Among open models, GPT-OSS 120B and DeepSeek V3 show stronger robustness. Based on these findings, we recommend evaluating each problem using at least five digit-varying instantiations to obtain a more robust and realistic assessment of math reasoning.

</details>


### [215] [SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models](https://arxiv.org/abs/2601.21235)
*Alok Abhishek,Tushar Bandopadhyay,Lisa Erickson*

Main category: cs.CL

TL;DR: 本文提出了SHARP框架，一种用于评估大型语言模型（LLMs）社会风险的多维度、分布感知方法，通过集成风险分解、尾部风险统计和CVaR95等指标，揭示了不同模型在偏见、公平、伦理和认知可靠性方面的差异化风险结构，强调了超越标量平均值的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM评估基准通常将复杂的社会风险简化为平均分数，忽略了分布结构、跨维度交互和最坏情况下的行为，而这些在高风险领域可能导致严重后果。

Method: SHARP将危害建模为多元随机变量，将其分解为偏见、公平、伦理和认知可靠性，并使用“联合故障”聚合。该框架还采用风险敏感的分布统计，以CVaR95为主要指标来表征模型的最坏情况行为。

Result: 对11个前沿LLMs的应用表明，平均风险相似的模型可能在尾部暴露和波动性上存在两倍以上的差异。偏见风险表现出最强的尾部严重性，认知和公平风险处于中间，而伦理风险最低。这些模式揭示了异构的、模型依赖的故障结构。

Conclusion: 对LLMs负责任的评估和治理需要超越标量平均值，转向多维度、对尾部敏感的风险画像。

Abstract: Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior. This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias, fairness, ethics, and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk. The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility. Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.

</details>


### [216] [MoCo: A One-Stop Shop for Model Collaboration Research](https://arxiv.org/abs/2601.21257)
*Shangbin Feng,Yuyang Bai,Ziyuan Yang,Yike Wang,Zhaoxuan Tan,Jiajie Yan,Zhenyu Lei,Wenxuan Ding,Weijia Shi,Haojin Wang,Zhenting Qi,Yuru Jiang,Heng Wang,Chengsong Huang,Yu Fei,Jihan Yao,Yilun Du,Luke Zettlemoyer,Yejin Choi,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: 本文介绍了MoCo，一个用于执行、基准测试和比较模型协作算法的Python库。MoCo包含26种协作方法和25个评估数据集，实验表明大多数协作策略优于无协作模型，并分析了协作的扩展性、效率和未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有关于语言模型协作的研究分散且缺乏系统性比较，作者旨在建立模型协作作为一门研究方向，并提供一个统一的平台来整合和促进该领域的研究。

Method: 开发了一个名为MoCo的Python库，集成了26种不同信息交换层级的模型协作方法（如路由、文本、logit、模型参数），并对接了25个涵盖推理、问答、代码、安全等领域的评估数据集，支持用户自定义数据。

Result: 通过MoCo进行的广泛实验表明，在61.0%的（模型，数据集）配置下，大多数协作策略优于未协作模型，其中最有效的方法性能提升高达25.8%。研究还分析了协作策略的扩展性、训练/推理效率，并指出协作系统能解决单模型难以处理的问题。

Conclusion: MoCo是一个强大的工具包，能够促进和加速开放、模块化、去中心化和协作式AI的发展。模型协作是提升语言模型性能的重要途径，尤其是在单模型表现不佳的任务上。

Abstract: Advancing beyond single monolithic language models (LMs), recent research increasingly recognizes the importance of model collaboration, where multiple LMs collaborate, compose, and complement each other. Existing research on this topic has mostly been disparate and disconnected, from different research communities, and lacks rigorous comparison. To consolidate existing research and establish model collaboration as a school of thought, we present MoCo: a one-stop Python library of executing, benchmarking, and comparing model collaboration algorithms at scale. MoCo features 26 model collaboration methods, spanning diverse levels of cross-model information exchange such as routing, text, logit, and model parameters. MoCo integrates 25 evaluation datasets spanning reasoning, QA, code, safety, and more, while users could flexibly bring their own data. Extensive experiments with MoCo demonstrate that most collaboration strategies outperform models without collaboration in 61.0% of (model, data) settings on average, with the most effective methods outperforming by up to 25.8%. We further analyze the scaling of model collaboration strategies, the training/inference efficiency of diverse methods, highlight that the collaborative system solves problems where single LMs struggle, and discuss future work in model collaboration, all made possible by MoCo. We envision MoCo as a valuable toolkit to facilitate and turbocharge the quest for an open, modular, decentralized, and collaborative AI future.

</details>


### [217] [Qwen3-ASR Technical Report](https://arxiv.org/abs/2601.21337)
*Xian Shi,Xiong Wang,Zhifang Guo,Yongqi Wang,Pei Zhang,Xinyu Zhang,Zishan Guo,Hongkun Hao,Yu Xi,Baosong Yang,Jin Xu,Jingren Zhou,Junyang Lin*

Main category: cs.CL

TL;DR: 本文介绍了Qwen3-ASR系列，包含两个多语言语音识别模型（Qwen3-ASR-1.7B和Qwen3-ASR-0.6B）和一个非自回归语音强制对齐模型（Qwen3-ForcedAligner-0.6B）。模型在多个语言上表现出SOTA性能和优异的效率，并已开源。


<details>
  <summary>Details</summary>
Motivation: 为了提升语音识别和音频理解的性能，并加速社区研究，作者开发并开源了Qwen3-ASR系列模型。

Method: Qwen3-ASR模型利用大规模语音训练数据和Qwen3-Omni基础模型的音频理解能力。Qwen3-ForcedAligner模型是一个基于LLM的非自回归时间戳预测器。

Result: Qwen3-ASR-1.7B在公开基准上达到SOTA，并与顶尖的闭源API竞争。Qwen3-ASR-0.6B在准确性-效率权衡方面表现最佳，具有低TTFT和高吞吐量。Qwen3-ForcedAligner-0.6B在时间戳准确性上优于现有最强的三个强制对齐模型，并且效率更高、通用性更强。

Conclusion: Qwen3-ASR系列模型在语音识别和强制对齐任务上均取得了优异的性能，并兼顾了效率和多语言支持，作者已将这些模型开源以推动社区发展。

Abstract: In this report, we introduce Qwen3-ASR family, which includes two powerful all-in-one speech recognition models and a novel non-autoregressive speech forced alignment model. Qwen3-ASR-1.7B and Qwen3-ASR-0.6B are ASR models that support language identification and ASR for 52 languages and dialects. Both of them leverage large-scale speech training data and the strong audio understanding ability of their foundation model Qwen3-Omni. We conduct comprehensive internal evaluation besides the open-sourced benchmarks as ASR models might differ little on open-sourced benchmark scores but exhibit significant quality differences in real-world scenarios. The experiments reveal that the 1.7B version achieves SOTA performance among open-sourced ASR models and is competitive with the strongest proprietary APIs while the 0.6B version offers the best accuracy-efficiency trade-off. Qwen3-ASR-0.6B can achieve an average TTFT as low as 92ms and transcribe 2000 seconds speech in 1 second at a concurrency of 128. Qwen3-ForcedAligner-0.6B is an LLM based NAR timestamp predictor that is able to align text-speech pairs in 11 languages. Timestamp accuracy experiments show that the proposed model outperforms the three strongest force alignment models and takes more advantages in efficiency and versatility. To further accelerate the community research of ASR and audio understanding, we release these models under the Apache 2.0 license.

</details>


### [218] [Self-Improving Pretraining: using post-trained models to pretrain better models](https://arxiv.org/abs/2601.21343)
*Ellen Xiaoqing Tan,Shehzaad Dhuliawala,Jing Xu,Ping Yu,Sainbayar Sukhbaatar,Jason Weston,Olga Golovneva*

Main category: cs.CL

TL;DR: 提出了一种新的预训练方法，通过强化学习在预训练阶段就优化语言模型的安全性、事实性和整体质量，而不是依赖于后期的微调。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型部署面临安全、事实性和质量挑战，现有的通过昂贵数据集微调的方法无法彻底根除预训练阶段遗留的问题，因此需要在预训练阶段解决这些核心行为。

Method: 提出了一种流式文档预训练方法，利用强化学习（RL）在每一步优化未来K个生成token的质量。引入一个强大的后训练模型来评估候选生成（包括模型回滚、原始后缀和重写后缀）在质量、安全性和事实性方面的表现，并以此作为RL的奖励信号。

Result: 该方法在事实性和安全性方面分别比标准预训练方法提高了36.2%和18.5%，在整体生成质量方面，在与基线模型的对比实验中取得了高达86.3%的胜率。

Conclusion: 该方法能够从根本上构建出更高质量、更安全、更具事实性的语言模型，有效解决了预训练阶段的核心挑战。

Abstract: Ensuring safety, factuality and overall quality in the generations of large language models is a critical challenge, especially as these models are increasingly deployed in real-world applications. The prevailing approach to addressing these issues involves collecting expensive, carefully curated datasets and applying multiple stages of fine-tuning and alignment. However, even this complex pipeline cannot guarantee the correction of patterns learned during pretraining. Therefore, addressing these issues during pretraining is crucial, as it shapes a model's core behaviors and prevents unsafe or hallucinated outputs from becoming deeply embedded. To tackle this issue, we introduce a new pretraining method that streams documents and uses reinforcement learning (RL) to improve the next K generated tokens at each step. A strong, post-trained model judges candidate generations -- including model rollouts, the original suffix, and a rewritten suffix -- for quality, safety, and factuality. Early in training, the process relies on the original and rewritten suffixes; as the model improves, RL rewards high-quality rollouts. This approach builds higher quality, safer, and more factual models from the ground up. In experiments, our method gives 36.2% and 18.5% relative improvements over standard pretraining in terms of factuality and safety, and up to 86.3% win rate improvements in overall generation quality.

</details>


### [219] [The Compliance Paradox: Semantic-Instruction Decoupling in Automated Academic Code Evaluation](https://arxiv.org/abs/2601.21360)
*Devanshu Sahoo,Manish Prasad,Vasudev Majhi,Arjun Neekhra,Yash Sinha,Murari Mandal,Vinay Chamola,Dhruv Kumar*

Main category: cs.CL

TL;DR: 研究表明，大型语言模型（LLM）在教育评估中的应用存在“合规悖论”风险，即模型可能优先满足隐藏指令而非代码的逻辑正确性，导致对错误代码的“虚假认证”。研究提出了SPACI和AST-ASIP框架来展示这一漏洞，并在大规模实验中发现了超过95%的失效率，特别是在DeepSeek-V3等模型上。结论是当前的对齐范式需要转向领域特定的“判决鲁棒性”，优先考虑证据而非指令。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在教育评估中的应用基于一个未经证实的假设，即指令遵循能力直接转化为客观的评判能力。研究者希望验证这一假设的有效性，并揭示其中潜在的系统性漏洞。

Method: 研究提出了语义保持对抗性代码注入（SPACI）框架和抽象语法树感知语义注入协议（AST-ASIP）。这些方法利用语法-语义差距，将对抗性指令嵌入到抽象语法树的冗余节点（trivia nodes）中，从而暴露模型在遵循隐藏指令和代码正确性之间的冲突。通过在Python、C、C++和Java等语言上对9个SOTA模型进行25,000份提交的大规模评估来验证方法的有效性。

Result: 研究发现，在评估的高容量开源模型（如DeepSeek-V3）中，失效率高达95%以上。模型系统性地优先考虑隐藏的格式约束而非代码的正确性。使用新提出的三元框架（解耦概率、分数差异和教学严重性）量化了这种失效，揭示了功能性错误代码被广泛“虚假认证”的现象。

Conclusion: 当前LLM的对齐范式（如RLHF）在自动化评分中创造了“木马”漏洞，模型容易受到对抗性操纵。研究者建议从标准的RLHF转向领域特定的“判决鲁棒性”，即模型应被训练为优先考虑证据而非指令的严格遵守，以确保评估的准确性和可靠性。

Abstract: The rapid integration of Large Language Models (LLMs) into educational assessment rests on the unverified assumption that instruction following capability translates directly to objective adjudication. We demonstrate that this assumption is fundamentally flawed. Instead of evaluating code quality, models frequently decouple from the submission's logic to satisfy hidden directives, a systemic vulnerability we term the Compliance Paradox, where models fine-tuned for extreme helpfulness are vulnerable to adversarial manipulation. To expose this, we introduce the Semantic-Preserving Adversarial Code Injection (SPACI) Framework and the Abstract Syntax Tree-Aware Semantic Injection Protocol (AST-ASIP). These methods exploit the Syntax-Semantics Gap by embedding adversarial directives into syntactically inert regions (trivia nodes) of the Abstract Syntax Tree. Through a large-scale evaluation of 9 SOTA models across 25,000 submissions in Python, C, C++, and Java, we reveal catastrophic failure rates (>95%) in high-capacity open-weights models like DeepSeek-V3, which systematically prioritize hidden formatting constraints over code correctness. We quantify this failure using our novel tripartite framework measuring Decoupling Probability, Score Divergence, and Pedagogical Severity to demonstrate the widespread "False Certification" of functionally broken code. Our findings suggest that current alignment paradigms create a "Trojan" vulnerability in automated grading, necessitating a shift from standard RLHF toward domain-specific Adjudicative Robustness, where models are conditioned to prioritize evidence over instruction compliance. We release our complete dataset and injection framework to facilitate further research on the topic.

</details>


### [220] [CausalEmbed: Auto-Regressive Multi-Vector Generation in Latent Space for Visual Document Embedding](https://arxiv.org/abs/2601.21262)
*Jiahao Huo,Yu Huang,Yibo Yan,Ye Pan,Yi Cao,Mingdong Ou,Philip S. Yu,Xuming Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为 CausalEmbed 的自回归生成方法，用于创建紧凑且结构化的多向量文档嵌入，显著减少了用于视觉文档检索（VDR）的视觉令牌数量，同时保持了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于 MLLM 的视觉文档检索方法由于每个页面需要数千个视觉令牌，导致存储开销巨大，限制了其实际应用。

Method: 采用自回归生成方法 CausalEmbed，并在对比训练中引入迭代边缘损失，以学习紧凑且结构化的嵌入表示。

Result: CausalEmbed 仅使用几十个视觉令牌即可实现高效的 VDR 任务，令牌数量减少 30-155 倍，同时在不同骨干网络和基准测试中保持了高度竞争力的性能。此外，该方法在训练效率和测试时间可扩展性方面具有独特优势。

Conclusion: CausalEmbed 为多向量 VDR 表示提供了一种灵活的测试时间缩放策略，并展示了生成范式在多模态文档检索中的潜力，解决了现有方法的存储和效率问题。

Abstract: Although Multimodal Large Language Models (MLLMs) have shown remarkable potential in Visual Document Retrieval (VDR) through generating high-quality multi-vector embeddings, the substantial storage overhead caused by representing a page with thousands of visual tokens limits their practicality in real-world applications. To address this challenge, we propose an auto-regressive generation approach, CausalEmbed, for constructing multi-vector embeddings. By incorporating iterative margin loss during contrastive training, CausalEmbed encourages the embedding models to learn compact and well-structured representations. Our method enables efficient VDR tasks using only dozens of visual tokens, achieving a 30-155x reduction in token count while maintaining highly competitive performance across various backbones and benchmarks. Theoretical analysis and empirical results demonstrate the unique advantages of auto-regressive embedding generation in terms of training efficiency and scalability at test time. As a result, CausalEmbed introduces a flexible test-time scaling strategy for multi-vector VDR representations and sheds light on the generative paradigm within multimodal document retrieval.

</details>


### [221] [Conversation for Non-verifiable Learning: Self-Evolving LLMs through Meta-Evaluation](https://arxiv.org/abs/2601.21464)
*Yuan Sui,Bryan Hooi*

Main category: cs.CL

TL;DR: 提出CoNL框架，通过多智能体自博弈实现生成、评估和元评估的统一，解决非可验证任务中LLM评估质量受限的问题。


<details>
  <summary>Details</summary>
Motivation: 非可验证任务（如创意写作、对话）难以标注，LLM-as-Judge方法受限于评估者自身质量，存在偏见且无法解决。

Method: 提出CoNL框架，使用多智能体自博弈进行生成、评估和元评估。通过结构化对话，让多个共享相同策略的智能体提出、批评和修改解决方案。能帮助他人改进解决方案的批评将获得奖励，从而为元评估提供监督，并联合优化生成和评判能力。

Result: 在五个基准测试中，CoNL相比自奖励基线模型取得了持续的性能提升，且训练稳定。

Conclusion: CoNL框架通过多智能体自博弈，有效解决了非可验证任务中LLM评估的挑战，并能在不依赖外部评估者或真实标签的情况下，联合优化生成和评判能力。

Abstract: Training large language models (LLMs) for non-verifiable tasks, such as creative writing, dialogue, and ethical reasoning, remains challenging due to the absence of ground-truth labels. While LLM-as-Judge approaches offer a scalable alternative to human feedback, they face a fundamental limitation: performance is constrained by the evaluator's own quality. If the judge cannot recognize good solutions, it cannot provide useful training signals, and evaluation biases (e.g., favoring verbosity over quality) remain unaddressed. This motivates meta-evaluation: the ability to evaluate and improve the evaluator itself. We introduce CoNL, a framework that unifies generation, evaluation, and meta-evaluation through multi-agent self-play. Our key insight: critique quality can be measured by whether it helps others improve their solutions. In CoNL, multiple agents sharing the same policy engage in structured conversations to propose, critique, and revise solutions. Critiques that enable solution improvements earn a diagnostic reward, creating explicit supervision for meta-evaluation and enabling joint optimization of generation and judging capabilities through self-play, without external judges or ground truth. Experiments on five benchmarks show that CoNL achieves consistent improvements over self-rewarding baselines while maintaining stable training.

</details>


### [222] [SOUP: Token-level Single-sample Mix-policy Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.21476)
*Lei Yang,Wei Bi,Chenxi Sun,Renren Jin,Deyi Xiong*

Main category: cs.CL

TL;DR: 提出了一种名为SOUP（Single-sample Mix-policy Unified Paradigm）的框架，通过在 token 级别融合新旧策略数据，有效解决了现有 on-policy 强化学习方法在语言模型后训练中面临的探索不足和过早饱和问题，并在实验中证明了其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的 on-policy 强化学习方法（如 GRPO）在语言模型后训练中存在探索性差和性能过早饱和的问题。尽管 off-policy 数据可以缓解这一问题，但现有的混合轨迹方法会导致策略不匹配和训练不稳定。因此，需要一种能够更有效地利用 off-policy 数据同时保持训练稳定性的方法。

Method: SOUP 框架在 token 级别融合 off-policy 和 on-policy 学习。具体来说，它将 off-policy 数据的影响限制在由历史策略采样生成的序列前缀部分，而序列的后续部分则使用 on-policy 方式生成。通过 token 级别的 Importance Sampling 比例，SOUP 在利用 off-policy 信息的同时，保证了训练的稳定性。

Result: SOUP 在语言模型强化学习的多个下游任务上取得了显著的性能提升，其效果优于标准的 on-policy 训练方法和现有的 off-policy 扩展方法。进一步的分析表明，SOUP 这种细粒度的、单样本混合策略的训练方式能够同时改善探索能力和最终性能。

Conclusion: SOUP 框架通过在 token 级别精细地融合 off-policy 数据，成功解决了 on-policy 强化学习在语言模型后训练中的局限性，实现了更好的探索和更高的最终性能，为语言模型的 RL 后训练提供了新的有效解决方案。

Abstract: On-policy reinforcement learning (RL) methods widely used for language model post-training, like Group Relative Policy Optimization (GRPO), often suffer from limited exploration and early saturation due to low sampling diversity. While off-policy data can help, current approaches that mix entire trajectories cause significant policy mismatch and instability. In this work, we propose the $\textbf{S}$ingle-sample Mix-p$\textbf{O}$licy $\textbf{U}$nified $\textbf{P}$aradigm (SOUP), a framework that unifies off- and on-policy learning within individual samples at the token level. It confines off-policy influence to the prefix of a generated sequence sampled from historical policies, while the continuation is generated on-policy. Through token-level importance ratios, SOUP effectively leverages off-policy information while preserving training stability. Extensive experiments demonstrate that SOUP consistently outperforms standard on-policy training and existing off-policy extensions. Our further analysis clarifies how our fine-grained, single-sample mix-policy training can improve both exploration and final performance in LLM RL.

</details>


### [223] [DimStance: Multilingual Datasets for Dimensional Stance Analysis](https://arxiv.org/abs/2601.21483)
*Jonas Becker,Liang-Chih Yu,Shamsuddeen Hassan Muhammad,Jan Philip Wahle,Terry Ruas,Idris Abdulmumin,Lung-Hao Lee,Wen-Ni Liu,Tzu-Mi Lin,Zhe-Yu Xu,Ying-Lung Lin,Jin Wang,Maryam Ibrahim Mukhtar,Bela Gipp,Saif M. Mohammed*

Main category: cs.CL

TL;DR: 本文提出了DimStance，一个包含11,746个目标方面、7,365篇文本的多语言（英、德、中、尼日利亚皮钦、斯瓦希里）和跨领域（政治、环保）的维度立场资源，并引入维度立场回归任务，利用情感科学的效价（valence）和唤醒度（arousal）来捕捉比分类标签更细致的立场情感。实验结果表明，微调的LLM在回归任务上表现具有竞争力，但在低资源语言上仍面临挑战，且基于token的生成方法存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的立场检测任务仅提供分类标签（支持、中立、反对），无法捕捉立场背后更细微的情感状态。研究者希望借鉴情感科学的维度模型（效价和唤醒度）来更精细地刻画作者对特定目标的态度。

Method: 1. 构建DimStance数据集，包含多语言、跨领域的文本及其对应的效价（-1到1，代表负面到正面）和唤醒度（-1到1，代表平静到活跃）标注。2. 提出维度立场回归任务，用于预测文本中目标方面的效价和唤醒度得分。3. 评估不同模型（预训练模型和大型语言模型）在维度立场回归任务上的表现，包括微调和提示（prompting）两种设置。4. 分析跨语言的效价-唤醒度模式。

Result: 1. 微调的大型语言模型在维度立场回归任务上取得了具有竞争力的性能。2. 在低资源语言上的立场预测仍然面临挑战。3. 基于token的生成方法在捕捉维度立场方面存在局限性。

Conclusion: DimStance数据集和维度立场回归任务为多语言、情感感知、细粒度的立场分析提供了基础和评估平台。研究结果展示了LLM在理解和预测情感维度立场方面的潜力，同时也指出了当前方法的不足，尤其是在低资源语言和生成方式上。

Abstract: Stance detection is an established task that classifies an author's attitude toward a specific target into categories such as Favor, Neutral, and Against. Beyond categorical stance labels, we leverage a long-established affective science framework to model stance along real-valued dimensions of valence (negative-positive) and arousal (calm-active). This dimensional approach captures nuanced affective states underlying stance expressions, enabling fine-grained stance analysis. To this end, we introduce DimStance, the first dimensional stance resource with valence-arousal (VA) annotations. This resource comprises 11,746 target aspects in 7,365 texts across five languages (English, German, Chinese, Nigerian Pidgin, and Swahili) and two domains (politics and environmental protection). To facilitate the evaluation of stance VA prediction, we formulate the dimensional stance regression task, analyze cross-lingual VA patterns, and benchmark pretrained and large language models under regression and prompting settings. Results show competitive performance of fine-tuned LLM regressors, persistent challenges in low-resource languages, and limitations of token-based generation. DimStance provides a foundation for multilingual, emotion-aware, stance analysis and benchmarking.

</details>


### [224] [User-Centric Evidence Ranking for Attribution and Fact Verification](https://arxiv.org/abs/2601.21387)
*Guy Alt,Eran Hirsch,Serwar Basch,Ido Dagan,Oren Glickman*

Main category: cs.CL

TL;DR: 本文提出了一种新的信息验证任务——证据排序（Evidence Ranking），旨在通过排序来优先呈现最能支持或反驳事实的信息，从而提高信息验证的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动事实验证系统和大型语言模型在提供证据时，存在信息不足或冗余的问题，导致用户验证过程效率低下且容易出错。

Method: 提出了一种新的证据排序任务，并设计了两种排序方法：一次性排序（one-shot ranking）和增量排序（incremental ranking）。引入了新的评估框架，并构建了一个统一的基准数据集。进行了模型实验和用户研究。

Result: 增量排序策略在捕捉互补证据方面表现更好。基于大型语言模型的方法优于浅层基线模型。用户研究表明，证据排序能够减少阅读量并提高验证效率。

Conclusion: 证据排序任务为构建更具可解释性、效率和用户友好性的信息验证系统奠定了基础，特别是在信息过载和用户验证过程中。

Abstract: Attribution and fact verification are critical challenges in natural language processing for assessing information reliability. While automated systems and Large Language Models (LLMs) aim to retrieve and select concise evidence to support or refute claims, they often present users with either insufficient or overly redundant information, leading to inefficient and error-prone verification. To address this, we propose Evidence Ranking, a novel task that prioritizes presenting sufficient information as early as possible in a ranked list. This minimizes user reading effort while still making all available evidence accessible for sequential verification. We compare two approaches for the new ranking task: one-shot ranking and incremental ranking. We introduce a new evaluation framework, inspired by information retrieval metrics, and construct a unified benchmark by aggregating existing fact verification datasets. Extensive experiments with diverse models show that incremental ranking strategies better capture complementary evidence and that LLM-based methods outperform shallower baselines, while still facing challenges in balancing sufficiency and redundancy. Compared to evidence selection, we conduct a controlled user study and demonstrate that evidence ranking both reduces reading effort and improves verification. This work provides a foundational step toward more interpretable, efficient, and user-aligned information verification systems.

</details>


### [225] [LMK > CLS: Landmark Pooling for Dense Embeddings](https://arxiv.org/abs/2601.21525)
*Meet Doshi,Aashka Trivedi,Vishwajeet Kumar,Parul Awasthy,Yulong Li,Jaydeep Sen,Radu Florian,Sachindra Joshi*

Main category: cs.CL

TL;DR: 提出了一种名为 Landmark (LMK) 池化的新方法，用于序列编码，以克服现有 [CLS] 标记或平均池化方法的缺点，从而在长上下文任务上获得显著改进，同时保持短上下文任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的序列编码方法（如 [CLS] 标记池化和平均池化）在处理可变长度序列时存在系统性缺陷：[CLS] 标记倾向于过度关注序列的初始位置，而平均池化会稀释局部重要信息，两者都会影响长上下文的泛化能力。

Method: 提出 Landmark (LMK) 池化方法，该方法将序列划分为若干块，在块之间插入特殊的“地标”标记，并通过对这些地标标记的嵌入进行平均池化来形成最终表示。

Result: LMK 池化方法在短上下文检索任务上与现有方法性能相当，并在长上下文任务上取得了显著的性能提升，同时保持了对局部特征的敏感性。

Conclusion: LMK 池化是一种简单、实用且可扩展的序列编码池化策略，能够有效提升模型在长上下文任务上的性能，同时不会牺牲短上下文任务的表现。

Abstract: Representation learning is central to many downstream tasks such as search, clustering, classification, and reranking. State-of-the-art sequence encoders typically collapse a variable-length token sequence to a single vector using a pooling operator, most commonly a special [CLS] token or mean pooling over token embeddings. In this paper, we identify systematic weaknesses of these pooling strategies: [CLS] tends to concentrate information toward the initial positions of the sequence and can under-represent distributed evidence, while mean pooling can dilute salient local signals, sometimes leading to worse short-context performance. To address these issues, we introduce Landmark (LMK) pooling, which partitions a sequence into chunks, inserts landmark tokens between chunks, and forms the final representation by mean-pooling the landmark token embeddings. This simple mechanism improves long-context extrapolation without sacrificing local salient features, at the cost of introducing a small number of special tokens. We empirically demonstrate that LMK pooling matches existing methods on short-context retrieval tasks and yields substantial improvements on long-context tasks, making it a practical and scalable alternative to existing pooling methods.

</details>


### [226] [inversedMixup: Data Augmentation via Inverting Mixed Embeddings](https://arxiv.org/abs/2601.21543)
*Fanshuang Kong,Richong Zhang,Qiyu Sun,Zhijie Nie,Ting Deng,Chunming Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为 inversedMixup 的新框架，它结合了 Mixup 的可控性和基于 LLM 的生成的可解释性，通过对齐任务模型和 LLM 的嵌入空间，生成人类可读的混合文本数据，并在少量样本和完全监督场景下都取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有的 Mixup 方法生成的样本不可解释，而基于 LLM 的方法可解释但控制性有限。研究人员希望结合两者的优点，实现可控且可解释的数据增强。

Method: inversedMixup 采用三阶段训练程序，将任务模型的输出嵌入空间与 LLM 的输入嵌入空间对齐。对齐后，inversedMixup 可以将混合嵌入（按可控比例混合）重建为人类可解释的增强句子。

Result: inversedMixup 成功地将混合嵌入转换为可解释的文本，有效提高了数据增强的性能。此外，该方法还首次提供了文本 Mixup 中流形侵入现象的实证证据，并提出了一种缓解策略。实验证明了该方法在少量样本和完全监督场景下的有效性和泛化能力。

Conclusion: inversedMixup 是一个统一的框架，能够生成可控且可解释的文本数据增强样本，有效提升模型性能，并为文本 Mixup 的研究提供了新的视角。

Abstract: Mixup generates augmented samples by linearly interpolating inputs and labels with a controllable ratio. However, since it operates in the latent embedding level, the resulting samples are not human-interpretable. In contrast, LLM-based augmentation methods produce sentences via prompts at the token level, yielding readable outputs but offering limited control over the generation process. Inspired by recent advances in LLM inversion, which reconstructs natural language from embeddings and helps bridge the gap between latent embedding space and discrete token space, we propose inversedMixup, a unified framework that combines the controllability of Mixup with the interpretability of LLM-based generation. Specifically, inversedMixup adopts a three-stage training procedure to align the output embedding space of a task-specific model with the input embedding space of an LLM. Upon successful alignment, inversedMixup can reconstruct mixed embeddings with a controllable mixing ratio into human-interpretable augmented sentences, thereby improving the augmentation performance. Additionally, inversedMixup provides the first empirical evidence of the manifold intrusion phenomenon in text Mixup and introduces a simple yet effective strategy to mitigate it. Extensive experiments demonstrate the effectiveness and generalizability of our approach in both few-shot and fully supervised scenarios.

</details>


### [227] [Note2Chat: Improving LLMs for Multi-Turn Clinical History Taking Using Medical Notes](https://arxiv.org/abs/2601.21551)
*Yang Zhou,Zhenting Sheng,Mingrui Tan,Yuting Song,Jun Zhou,Yu Heng Kwan,Lian Leng Low,Yang Bai,Yong Liu*

Main category: cs.CL

TL;DR: 该研究提出了一种名为 \method\ 的新框架，利用医学笔记训练大型语言模型（LLMs）进行结构化病史采集和诊断。通过将医学笔记转化为对话数据，并采用三阶段微调策略和单轮推理范式，该方法显著提高了LLMs的临床推理能力，在诊断准确性上超越了GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在静态诊断基准测试中表现良好，但在需要迭代提问和假设细化的动态多轮诊断场景中表现不佳。现有的临床病史采集是临床推理的基础，但研究不足。

Method: 1. 将真实的医学笔记转换为高质量的医患对话数据，采用决策树引导的生成和精炼流程。2. 提出三阶段微调策略：监督学习、模拟数据增强和偏好学习。3. 引入单轮推理范式，将病史采集视为一系列单轮推理问题。

Result: 与GPT-4o相比，该方法在F1分数上提高了16.9%，在Top-1诊断准确率上提高了21.0%。

Conclusion: 所提出的\method\框架通过利用广泛可用的医学笔记，有效提升了LLMs在动态、多轮临床诊断场景中的表现，并增强了可解释性、局部监督、动态适应性和样本效率。

Abstract: Effective clinical history taking is a foundational yet underexplored component of clinical reasoning. While large language models (LLMs) have shown promise on static benchmarks, they often fall short in dynamic, multi-turn diagnostic settings that require iterative questioning and hypothesis refinement. To address this gap, we propose \method{}, a note-driven framework that trains LLMs to conduct structured history taking and diagnosis by learning from widely available medical notes. Instead of relying on scarce and sensitive dialogue data, we convert real-world medical notes into high-quality doctor-patient dialogues using a decision tree-guided generation and refinement pipeline. We then propose a three-stage fine-tuning strategy combining supervised learning, simulated data augmentation, and preference learning. Furthermore, we propose a novel single-turn reasoning paradigm that reframes history taking as a sequence of single-turn reasoning problems. This design enhances interpretability and enables local supervision, dynamic adaptation, and greater sample efficiency. Experimental results show that our method substantially improves clinical reasoning, achieving gains of +16.9 F1 and +21.0 Top-1 diagnostic accuracy over GPT-4o. Our code and dataset can be found at https://github.com/zhentingsheng/Note2Chat.

</details>


### [228] [MURAD: A Large-Scale Multi-Domain Unified Reverse Arabic Dictionary Dataset](https://arxiv.org/abs/2601.21512)
*Serry Sibaee,Yasser Alhabashi,Nadia Sibai,Yara Farouk,Adel Ammar,Sawsan AlHalawani,Wadii Boulila*

Main category: cs.CL

TL;DR: 本文介绍了MURAD，一个包含96,243个词语-定义对的开源阿拉伯语词汇数据集，旨在弥补现有大型阿拉伯语词汇资源不足的现状。


<details>
  <summary>Details</summary>
Motivation: 现有的大型阿拉伯语词汇数据集（特别是包含精确定义的）非常有限，阻碍了阿拉伯语自然语言处理和词典学研究的发展。

Method: 该数据集通过混合方法构建，结合了文本解析、光学字符识别（OCR）和自动化重建技术，从可靠的参考资料和教育资源中提取了96,243个词语-定义对，并为每个条目添加了源领域元数据。

Result: 成功构建并发布了MURAD数据集，其中包含跨越语言学、伊斯兰研究、数学、物理、心理学和工程学等多个领域的词汇及其标准化定义。

Conclusion: MURAD数据集为阿拉伯语的计算语言学、词典学研究、反向词典建模、语义检索和教育工具开发提供了宝贵的资源，有助于推动阿拉伯语自然语言处理和可复现研究。

Abstract: Arabic is a linguistically and culturally rich language with a vast vocabulary that spans scientific, religious, and literary domains. Yet, large-scale lexical datasets linking Arabic words to precise definitions remain limited. We present MURAD (Multi-domain Unified Reverse Arabic Dictionary), an open lexical dataset with 96,243 word-definition pairs. The data come from trusted reference works and educational sources. Extraction used a hybrid pipeline integrating direct text parsing, optical character recognition, and automated reconstruction. This ensures accuracy and clarity. Each record aligns a target word with its standardized Arabic definition and metadata that identifies the source domain. The dataset covers terms from linguistics, Islamic studies, mathematics, physics, psychology, and engineering. It supports computational linguistics and lexicographic research. Applications include reverse dictionary modeling, semantic retrieval, and educational tools. By releasing this resource, we aim to advance Arabic natural language processing and promote reproducible research on Arabic lexical semantics.

</details>


### [229] [ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas](https://arxiv.org/abs/2601.21558)
*Xiaoyu Tian,Haotian Wang,Shuaiting Chen,Hao Zhou,Kaichi Yu,Yudian Zhang,Jade Ouyang,Junxi Yin,Jiong Chen,Baoyan Guo,Lei Zhang,Junjie Tao,Yuansheng Song,Ming Cui,Chengwei Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为ASTRA的自动化框架，用于训练能够使用工具的大型语言模型（LLM）智能体。ASTRA通过合成结构化的工具使用轨迹和可验证的RL环境，解决了现有方法中手动干预、模拟环境不可靠以及SFT/RL组合困难等问题，实现了更稳定、可扩展的训练。


<details>
  <summary>Details</summary>
Motivation: 现有训练工具使用LLM智能体的方法存在挑战，包括需要手动干预、依赖不可验证的模拟环境、SFT或RL的局限性，以及在长期多轮学习中的稳定性问题。作者旨在开发一种更自动化、可扩展且鲁棒的训练方法。

Method: ASTRA包含两个主要部分：1) 一个利用工具调用图静态拓扑结构合成结构化轨迹的流水线，以增强工具使用能力；2) 一个环境合成框架，将问题-答案轨迹转换为独立的、可执行的、规则可验证的环境，以支持确定性的多轮强化学习。作者还提出了一种集成了SFT和在线RL的统一训练方法，使用轨迹级奖励来平衡任务完成度和交互效率。

Result: 在多个智能体工具使用基准测试上，ASTRA训练的模型在同等规模下达到了最先进的性能，接近闭源系统，并保留了核心的推理能力。

Conclusion: ASTRA是一个全自动、端到端的框架，通过可扩展的数据合成和可验证的强化学习，有效地训练了工具使用LLM智能体。该方法在多个基准测试中表现出色，证明了其有效性和鲁棒性。

Abstract: Large language models (LLMs) are increasingly used as tool-augmented agents for multi-step decision making, yet training robust tool-using agents remains challenging. Existing methods still require manual intervention, depend on non-verifiable simulated environments, rely exclusively on either supervised fine-tuning (SFT) or reinforcement learning (RL), and struggle with stable long-horizon, multi-turn learning. To address these challenges, we introduce ASTRA, a fully automated end-to-end framework for training tool-augmented language model agents via scalable data synthesis and verifiable reinforcement learning. ASTRA integrates two complementary components. First, a pipeline that leverages the static topology of tool-call graphs synthesizes diverse, structurally grounded trajectories, instilling broad and transferable tool-use competence. Second, an environment synthesis framework that captures the rich, compositional topology of human semantic reasoning converts decomposed question-answer traces into independent, code-executable, and rule-verifiable environments, enabling deterministic multi-turn RL. Based on this method, we develop a unified training methodology that integrates SFT with online RL using trajectory-level rewards to balance task completion and interaction efficiency. Experiments on multiple agentic tool-use benchmarks demonstrate that ASTRA-trained models achieve state-of-the-art performance at comparable scales, approaching closed-source systems while preserving core reasoning ability. We release the full pipelines, environments, and trained models at https://github.com/LianjiaTech/astra.

</details>


### [230] [KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices](https://arxiv.org/abs/2601.21579)
*Wuyang Zhou,Yuxuan Gu,Giorgos Iacovides,Danilo Mandic*

Main category: cs.CL

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: The success of Hyper-Connections (HC) in neural networks (NN) has also highlighted issues related to its training instability and restricted scalability. The Manifold-Constrained Hyper-Connections (mHC) mitigate these challenges by projecting the residual connection space onto a Birkhoff polytope, however, it faces two issues: 1) its iterative Sinkhorn-Knopp (SK) algorithm does not always yield exact doubly stochastic residual matrices; 2) mHC incurs a prohibitive $\mathcal{O}(n^3C)$ parameter complexity with $n$ as the width of the residual stream and $C$ as the feature dimension. The recently proposed mHC-lite reparametrizes the residual matrix via the Birkhoff-von-Neumann theorem to guarantee double stochasticity, but also faces a factorial explosion in its parameter complexity, $\mathcal{O} \left( nC \cdot n! \right)$. To address both challenges, we propose \textbf{KromHC}, which uses the \underline{Kro}necker products of smaller doubly stochastic matrices to parametrize the residual matrix in \underline{mHC}. By enforcing manifold constraints across the factor residual matrices along each mode of the tensorized residual stream, KromHC guarantees exact double stochasticity of the residual matrices while reducing parameter complexity to $\mathcal{O}(n^2C)$. Comprehensive experiments demonstrate that KromHC matches or even outperforms state-of-the-art (SOTA) mHC variants, while requiring significantly fewer trainable parameters. The code is available at \texttt{https://github.com/wz1119/KromHC}.

</details>


### [231] [Language Models as Artificial Learners: Investigating Crosslinguistic Influence](https://arxiv.org/abs/2601.21587)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本研究利用语言模型（LM）模拟跨语言影响（CLI），以解决人类研究中结果不一致的问题。通过操纵L1语言优势、L2语言熟练度和L1与L2的句法距离，并分析跨语言启动的影响，研究发现语言优势和熟练度是CLI的重要预测因素。同时，语法结构的启动是双向的，而非语法结构的启动受语言优势影响。研究还提供了LM中CLI的机制证据，表明L1在L2处理过程中被共同激活，并影响L2处理的神经回路。


<details>
  <summary>Details</summary>
Motivation: 人类双语研究中的跨语言影响（CLI）研究结果常因实验变异性而存在冲突，本研究旨在利用语言模型（LM）作为受控的统计学习者，系统地模拟CLI并分离其驱动因素，以解决这些不一致性。

Method: 研究通过控制L2的暴露年龄（即引入L2的训练步骤）来操纵L1语言优势和L2语言熟练度。此外，还研究了预训练L1语言与L2语言的句法距离对CLI的影响。利用跨语言启动（cross-linguistic priming）技术，分析激活L1结构如何影响L2处理。

Result: 研究结果与心理语言学研究一致，确认语言优势和熟练度是CLI的强预测因子。研究还发现，尽管语法结构的启动是双向的，但而非语法结构的启动对语言优势敏感。最后，研究提供了LM中CLI的机制证据，表明L1在L2处理过程中被共同激活，并直接影响L2处理所征用的神经回路。

Conclusion: 本研究证明了语言模型（LM）可以作为计算框架，为人类CLI理论提供信息。研究结果揭示了语言优势、熟练度和句法距离对CLI的重要作用，并提供了CLI在LM中的具体机制证据，为理解双语认知过程提供了新的视角。

Abstract: Despite the centrality of crosslinguistic influence (CLI) to bilingualism research, human studies often yield conflicting results due to inherent experimental variance. We address these inconsistencies by using language models (LMs) as controlled statistical learners to systematically simulate CLI and isolate its underlying drivers. Specifically, we study the effect of varying the L1 language dominance and the L2 language proficiency, which we manipulate by controlling the L2 age of exposure -- defined as the training step at which the L2 is introduced. Furthermore, we investigate the impact of pretraining on L1 languages with varying syntactic distance from the L2. Using cross-linguistic priming, we analyze how activating L1 structures impacts L2 processing. Our results align with evidence from psycholinguistic studies, confirming that language dominance and proficiency are strong predictors of CLI. We further find that while priming of grammatical structures is bidirectional, the priming of ungrammatical structures is sensitive to language dominance. Finally, we provide mechanistic evidence of CLI in LMs, demonstrating that the L1 is co-activated during L2 processing and directly influences the neural circuitry recruited for the L2. More broadly, our work demonstrates that LMs can serve as a computational framework to inform theories of human CLI.

</details>


### [232] [AdaptBPE: From General Purpose to Specialized Tokenizers](https://arxiv.org/abs/2601.21665)
*Vijini Liyanage,François Yvon*

Main category: cs.CL

TL;DR: 提出了一种后训练适应策略，通过替换低效词汇项来优化文本分词器，以适应特定领域或语言，并在多项任务中实现了比基线更好的压缩效果。


<details>
  <summary>Details</summary>
Motivation: 标准的通用分词器在应用于特定领域或语言时效率不高，希望通过一种轻量级的适应机制来解决这一问题。

Method: 提出了一种后训练适应策略，基于适应语料库的词频，选择性地替换低效词汇项，以识别最能有效编码适应语料库的词汇表。

Result: 在生成和分类任务以及多种语言上进行的广泛实验表明，所提出的适应性分词器在相同词汇量大小下，比基线方法能更有效地压缩测试语料库。

Conclusion: 该方法是一种轻量级的适应机制，类似于词汇微调，可以针对特定领域或任务优化分词器，提高效率。

Abstract: Subword tokenization methods, such as Byte-Pair Encoding (BPE), significantly impact the performance and efficiency of large language models (LLMs). The standard approach involves training a general-purpose tokenizer that uniformly processes all textual data during both training and inference. However, the use of a generic set of tokens can incur inefficiencies when applying the model to specific domains or languages. To address this limitation, we propose a post-training adaptation strategy that selectively replaces low-utility tokens with more relevant ones based on their frequency in an adaptation corpus. Our algorithm identifies the token inventory that most effectively encodes the adaptation corpus for a given target vocabulary size. Extensive experiments on generation and classification tasks across multiple languages demonstrate that our adapted tokenizers compress test corpora more effectively than baselines using the same vocabulary size. This method serves as a lightweight adaptation mechanism, akin to a vocabulary fine-tuning process, enabling optimized tokenization for specific domains or tasks. Our code and data are available at https://github.com/vijini/Adapt-BPE.git.

</details>


### [233] [ILRR: Inference-Time Steering Method for Masked Diffusion Language Models](https://arxiv.org/abs/2601.21647)
*Eden Avrahami,Eliya Nachmani*

Main category: cs.CL

TL;DR: 提出了一种名为迭代潜在表示细化 (ILRR) 的学习无关框架，用于通过单个参考序列来引导离散扩散语言模型 (DLM) 的文本生成。ILRR 通过在去噪过程中动态地将生成序列的内部激活与参考序列的内部激活对齐来实现这一点，从而实现了对诸如情感等属性的灵活控制，并且计算开销很小。


<details>
  <summary>Details</summary>
Motivation: 现有 DLM 的推理时控制机制探索不足，作者希望开发一种有效的方法来引导 DLM 进行文本生成。

Method: 提出迭代潜在表示细化 (ILRR) 框架，该框架通过在去噪过程中动态对齐生成序列和参考序列的内部激活来引导 DLM。还提出了空间调制引导 (Spatially Modulated Steering) 扩展，用于使用较短的参考引导长文本。

Result: ILRR 在 LLaDA 和 MDLM 架构上实现了有效的属性引导，计算开销很小，并且在相同的计算预算下，将属性准确率比可比基线提高了 10% 到 60%，同时保持了高质量的生成。

Conclusion: ILRR 是一种有效的、学习无关的框架，可以通过单个参考序列灵活地控制 DLM 的文本生成属性，并且计算效率高。

Abstract: Discrete Diffusion Language Models (DLMs) offer a promising non-autoregressive alternative for text generation, yet effective mechanisms for inference-time control remain relatively underexplored. Existing approaches include sampling-level guidance procedures or trajectory optimization mechanisms. In this work, we introduce Iterative Latent Representation Refinement (ILRR), a learning-free framework for steering DLMs using a single reference sequence. ILRR guides generation by dynamically aligning the internal activations of the generated sequence with those of a given reference throughout the denoising process. This approach captures and transfers high-level semantic properties, with a tunable steering scale enabling flexible control over attributes such as sentiment. We further introduce Spatially Modulated Steering, an extension that enables steering long texts using shorter references by regulating guidance intensity across the sequence. Empirically, we demonstrate that ILRR achieves effective attribute steering on LLaDA and MDLM architectures with a minor computational overhead, requiring only one additional parallel forward pass per denoising step. Under the same compute budget, ILRR improves attribute accuracy over comparable baselines by 10$\%$ to 60$\%$ points, while maintaining high generation quality.

</details>


### [234] [FIT: Defying Catastrophic Forgetting in Continual LLM Unlearning](https://arxiv.org/abs/2601.21682)
*Xiaoyu Xu,Minxin Du,Kun Fang,Zi Liang,Yaxin Xiao,Zhicong Huang,Cheng Hong,Qingqing Ye,Haibo Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为 \fit 的持续性遗忘框架，旨在解决大规模语言模型（LLMs）在处理大量删除请求时面临的隐私、版权和有害内容问题，同时保持模型性能并防止灾难性遗忘。该框架通过数据过滤、重要性感知更新和目标层归因来减少性能下降。此外，本文还提出了 \textbf{PCH} 基准测试和两个评估指标（遗忘程度 F.D. 和保留效用 R.U.）以支持更现实的评估。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 遗忘方法未能充分考虑现实世界中持续且海量的删除请求，这会导致模型效用下降和灾难性遗忘。需要一种能够处理大量删除请求并保持模型鲁棒性的持续遗忘方法。

Method: \fit 框架通过以下三个主要机制来实现持续遗忘：1. 数据过滤（Data Filtering）：严格筛选待删除的数据；2. 重要性感知更新（Importance-aware updates）：根据数据的重要性进行更新；3. 目标层归因（Targeted layer attribution）：识别并更新对删除目标内容至关重要的模型层。此外，本文还构建了 \textbf{PCH} 基准测试，并提出了遗忘程度（F.D.）和保留效用（R.U.）两个对称指标。

Result: \fit 在处理大量删除请求时，能够在遗忘效果和效用保持之间取得有利的平衡，表现稳定。在 MMLU、CommonsenseQA 和 GSM8K 数据集上的实验表明，\fit 的性能优于现有方法，并且对遗忘程度和保留效用都有很好的控制。它还能抵御重新学习和量化恢复攻击。

Conclusion: \fit 是一个有效的持续性遗忘框架，能够处理大规模语言模型中的大量删除请求，同时有效减轻灾难性遗忘并保持模型效用。\textbf{PCH} 基准测试和 F.D./R.U. 指标为评估遗忘方法提供了更现实的基准。

Abstract: Large language models (LLMs) demonstrate impressive capabilities across diverse tasks but raise concerns about privacy, copyright, and harmful materials. Existing LLM unlearning methods rarely consider the continual and high-volume nature of real-world deletion requests, which can cause utility degradation and catastrophic forgetting as requests accumulate. To address this challenge, we introduce \fit, a framework for continual unlearning that handles large numbers of deletion requests while maintaining robustness against both catastrophic forgetting and post-unlearning recovery. \fit mitigates degradation through rigorous data \underline{F}iltering, \underline{I}mportance-aware updates, and \underline{T}argeted layer attribution, enabling stable performance across long sequences of unlearning operations and achieving a favorable balance between forgetting effectiveness and utility retention. To support realistic evaluation, we present \textbf{PCH}, a benchmark covering \textbf{P}ersonal information, \textbf{C}opyright, and \textbf{H}armful content in sequential deletion scenarios, along with two symmetric metrics, Forget Degree (F.D.) and Retain Utility (R.U.), which jointly assess forgetting quality and utility preservation. Extensive experiments on four open-source LLMs with hundreds of deletion requests show that \fit achieves the strongest trade-off between F.D. and R.U., surpasses existing methods on MMLU, CommonsenseQA, and GSM8K, and remains resistant against both relearning and quantization recovery attacks.

</details>


### [235] [Do Not Waste Your Rollouts: Recycling Search Experience for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.21684)
*Xinglin Wang,Jiayi Shi,Shaoxiong Feng,Peiwen Yuan,Yiwei Li,Yueqi Zhang,Chuyi Tan,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li*

Main category: cs.CL

TL;DR: 提出了一种名为“回收搜索经验”（RSE）的训练无关策略，通过建立一个共享的经验库来优化大型语言模型（LLM）在推理任务中的测试时计算。RSE能够回收成功的中间结论以加速推理，并识别失败模式以避免重复尝试，从而提高计算效率并达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型测试时搜索策略（如Test-Time Scaling）存在内存缺失问题，即每次推理尝试都被视为独立的，导致计算冗余，因为模型会重复推导已知结论或探索死胡同。

Method: 提出回收搜索经验（RSE）策略。RSE通过将原始的推理轨迹提炼成一个共享的经验库，将测试时搜索从一系列孤立的尝试转变为一个累积过程。它通过“正向回收”利用中间结论来缩短冗余推导，并通过“负向回收”利用失败模式来修剪遇到的死胡同。

Result: 在HMMT24、HMMT25、IMO-Bench和HLE等基准测试上的实验表明，RSE在可比的计算成本下始终优于强基线，实现了最先进的计算效率。

Conclusion: RSE是一种有效的训练无关策略，可以通过回收搜索经验来显著提高大型语言模型在复杂推理任务中的测试时计算效率，克服了现有方法的冗余问题。

Abstract: Test-Time Scaling enhances the reasoning capabilities of Large Language Models by allocating additional inference compute to broaden the exploration of the solution space. However, existing search strategies typically treat rollouts as disposable samples, where valuable intermediate insights are effectively discarded after each trial. This systemic memorylessness leads to massive computational redundancy, as models repeatedly re-derive discovered conclusions and revisit known dead ends across extensive attempts. To bridge this gap, we propose \textbf{Recycling Search Experience (RSE)}, a self-guided, training-free strategy that turns test-time search from a series of isolated trials into a cumulative process. By actively distilling raw trajectories into a shared experience bank, RSE enables positive recycling of intermediate conclusions to shortcut redundant derivations and negative recycling of failure patterns to prune encountered dead ends. Theoretically, we provide an analysis that formalizes the efficiency gains of RSE, validating its advantage over independent sampling in solving complex reasoning tasks. Empirically, extensive experiments on HMMT24, HMMT25, IMO-Bench, and HLE show that RSE consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art scaling efficiency.

</details>


### [236] [Scale-Dependent Semantic Dynamics Revealed by Allan Deviation](https://arxiv.org/abs/2601.21678)
*Debayan Dasgupta*

Main category: cs.CL

TL;DR: 研究利用Allan偏差分析文本语义进展的稳定性，发现人类文本存在两种动态模式（短期幂律，长期稳定），并指出大型语言模型在模拟短期模式时，长期稳定性不足。


<details>
  <summary>Details</summary>
Motivation: 语言在语义状态上的进展过程的动力学机制尚不明确。

Method: 将文本的语义进展视为高维状态空间中的随机轨迹，利用Allan偏差分析句子嵌入作为位移信号的稳定性。

Result: 发现文本语义进展存在两种动态模式：短期幂律缩放（区分创意文学和技术文本）和长期向稳定噪声底限的交叉。大型语言模型成功模仿了人类文本的局部缩放统计特性，但在长期稳定性方面存在系统性不足。

Conclusion: 语义连贯性可以被量化为一个物理属性，该框架能够区分人类认知和算法模型生成的模式的细微动力学差异。

Abstract: While language progresses through a sequence of semantic states, the underlying dynamics of this progression remain elusive. Here, we treat the semantic progression of written text as a stochastic trajectory in a high-dimensional state space. We utilize Allan deviation, a tool from precision metrology, to analyze the stability of meaning by treating ordered sentence embeddings as a displacement signal. Our analysis reveals two distinct dynamical regimes: short-time power-law scaling, which differentiates creative literature from technical texts, and a long-time crossover to a stability-limited noise floor. We find that while large language models successfully mimic the local scaling statistics of human text, they exhibit a systematic reduction in their stability horizon. These results establish semantic coherence as a measurable physical property, offering a framework to differentiate the nuanced dynamics of human cognition from the patterns generated by algorithmic models.

</details>


### [237] [Can David Beat Goliath? On Multi-Hop Reasoning with Resource-Constrained Agents](https://arxiv.org/abs/2601.21699)
*Hojae Han,Heeyun Jung,Jongyoon Kim,Seung-won Hwang*

Main category: cs.CL

TL;DR: 本文提出了一种名为DAVID-GRPO的RL框架，旨在解决小规模语言模型在资源受限的情况下进行多步推理时遇到的训练不稳定和准确性低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于RL的多轮推理代理依赖于高成本、高精度的训练方式，这在资源受限的情况下（如小模型、有限探索预算）难以实现。研究旨在打破成本与精度之间的权衡，证明小模型在资源约束下也能实现强大的多步推理能力。

Method: DAVID-GRPO框架包含三个主要组件：1) 使用少量监督信号稳定早期学习；2) 基于证据召回分配检索信用；3) 通过重采样近乎成功的截断轨迹来改进探索。

Result: 在参数量高达1.5B的模型并在仅四块RTX 3090 GPU上进行训练后，DAVID-GRPO在六个多步问答基准测试中，一致优于先前为大规模设置设计的RL方法。

Conclusion: 该研究表明，通过引入合适的归纳偏置，小规模代理可以在低训练成本下实现高准确性，从而挑战了现有关于资源约束下模型性能的认知。

Abstract: While reinforcement learning (RL) has empowered multi-turn reasoning agents with retrieval and tools, existing successes largely depend on extensive on-policy rollouts in high-cost, high-accuracy regimes. Under realistic resource constraints that cannot support large models or dense explorations, however, small language model agents fall into a low-cost, low-accuracy regime, where limited rollout budgets lead to sparse exploration, sparse credit assignment, and unstable training. In this work, we challenge this trade-off and show that small language models can achieve strong multi-hop reasoning under resource constraints. We introduce DAVID-GRPO, a budget-efficient RL framework that (i) stabilizes early learning with minimal supervision, (ii) assigns retrieval credit based on evidence recall, and (iii) improves exploration by resampling truncated near-miss trajectories. Evaluated on agents up to 1.5B parameters trained on only four RTX 3090 GPUs, DAVID-GRPO consistently outperforms prior RL methods designed for large-scale settings on six multi-hop QA benchmarks. These results show that with the right inductive biases, small agents can achieve low training cost with high accuracy.

</details>


### [238] [Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis](https://arxiv.org/abs/2601.21709)
*Qingyue Yang,Jie Wang,Xing Li,Yinqi Bai,Xialiang Tong,Huiling Zhen,Jianye Hao,Mingxuan Yuan,Bin Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为 TAPPA 的统一框架，用于分析大型语言模型（LLM）中多种注意力模式的数学形成，并从时间连续性的角度解释了这些模式的可预测性。该框架能够深化对注意力行为的理解，并指导推理加速方法。研究发现，注意力模式的可预测性与查询在时间维度上的自相似性有关。TAPPA 的分析结果在 KV 缓存压缩和 LLM 修剪任务中得到验证，并提出了一种简单的指标，能够提升现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究对 LLM 中个体注意力模式（如检索头、汇聚头、对角线迹等）的观察是零散的，缺乏一个统一的解释框架。本文旨在弥合这一差距，提供一个统一的视角来理解和解释这些注意力模式。

Method: 本文提出了 Temporal Attention Pattern Predictability Analysis (TAPPA) 框架，从时间连续性的角度分析注意力模式的数学形成。TAPPA 将注意力模式分为可预测模式和不可预测模式，并通过查询的自相似性来解释这种区分。此外，研究人员还对可预测模式进行了详细的数学分析，并结合了查询、键和旋转位置嵌入（RoPE）的联合效应。

Result: TAPPA 框架成功地统一了解释了多种注意力模式，并揭示了查询自相似性在决定模式可预测性中的作用。通过将 TAPPA 的见解应用于 KV 缓存压缩和 LLM 修剪任务，一个由 TAPPA 启发的简单指标在这些任务中均能持续提升性能。

Conclusion: TAPPA 是一个统一的框架，能够从时间连续性的角度分析和解释 LLM 中不同注意力模式的数学形成。该框架深化了对注意力行为的理解，并为推理加速提供了指导，其有效性已在实际应用中得到验证。

Abstract: Attention patterns play a crucial role in both training and inference of large language models (LLMs). Prior works have identified individual patterns such as retrieval heads, sink heads, and diagonal traces, yet these observations remain fragmented and lack a unifying explanation. To bridge this gap, we introduce \textbf{Temporal Attention Pattern Predictability Analysis (TAPPA), a unifying framework that explains diverse attention patterns by analyzing their underlying mathematical formulations} from a temporally continuous perspective. TAPPA both deepens the understanding of attention behavior and guides inference acceleration approaches. Specifically, TAPPA characterizes attention patterns as predictable patterns with clear regularities and unpredictable patterns that appear effectively random. Our analysis further reveals that this distinction can be explained by the degree of query self-similarity along the temporal dimension. Focusing on the predictable patterns, we further provide a detailed mathematical analysis of three representative cases through the joint effect of queries, keys, and Rotary Positional Embeddings (RoPE). We validate TAPPA by applying its insights to KV cache compression and LLM pruning tasks. Across these tasks, a simple metric motivated by TAPPA consistently improves performance over baseline methods. The code is available at https://github.com/MIRALab-USTC/LLM-TAPPA.

</details>


### [239] [TACLer: Tailored Curriculum Reinforcement Learning for Efficient Reasoning](https://arxiv.org/abs/2601.21711)
*Huiyuan Lai,Malvina Nissim*

Main category: cs.CL

TL;DR: 提出了一种名为TACLer的模型定制化课程强化学习框架，通过逐步增加数据复杂度来提高LLMs进行长链式思考（CoT）推理的学习和推理效率，同时减少计算成本和提高准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的LLMs在复杂推理任务中需要长CoT，但通常需要大规模RL训练，并且容易出现冗余思考。研究动机是为了提高学习和推理效率，同时保持或提升性能。

Method: 提出TACLer框架，包含两个核心组件：1. 定制化课程学习，根据模型在多阶段RL训练中的熟练程度逐步增加数据复杂度；2. 混合思考/不思考推理范式，通过启用或禁用思考模式来平衡准确性和效率。

Result: TACLer在学习和推理方面带来了双重优势：1. 降低计算成本，训练计算量减少50%以上，推理token使用量减少42%以上。2. 提高准确性，在四个数学数据集上比基线模型提高了9%以上，并优于最先进的“不思考”和“思考”基线。

Conclusion: TACLer是一种有效的模型定制化课程强化学习框架，能够显著降低LLMs进行长CoT推理的计算成本，同时提高其准确性，克服了现有方法的局限性。

Abstract: Large Language Models (LLMs) have shown remarkable performance on complex reasoning tasks, especially when equipped with long chain-of-thought (CoT) reasoning. However, eliciting long CoT typically requires large-scale reinforcement learning (RL) training, while often leading to overthinking with redundant intermediate steps. To improve learning and reasoning efficiency, while preserving or even enhancing performance, we propose TACLer, a model-tailored curriculum reinforcement learning framework that gradually increases the complexity of the data based on the model's proficiency in multi-stage RL training. TACLer features two core components: (i) tailored curriculum learning that determines what knowledge the model lacks and needs to learn in progressive stages; (ii) a hybrid Thinking/NoThinking reasoning paradigm that balances accuracy and efficiency by enabling or disabling the Thinking mode. Our experiments show that TACLer yields a twofold advantage in learning and reasoning: (i) it reduces computational cost, cutting training compute by over 50% compared to long thinking models and reducing inference token usage by over 42% relative to the base model; and (ii) it improves accuracy by over 9% on the base model, consistently outperforming state-of-the-art Nothinking and Thinking baselines across four math datasets with complex problems.

</details>


### [240] [Enhancing Language Models for Robust Greenwashing Detection](https://arxiv.org/abs/2601.21722)
*Neil Heinrich Braun,Keane Ong,Rui Mao,Erik Cambria,Gianmarco Mengaldo*

Main category: cs.CL

TL;DR: 该研究提出了一种参数高效的框架，通过结合对比学习和序数排名目标来改进可持续性报告的可信度，以应对绿色清洗和模糊声明，并通过门控特征调制和MetaGradNorm来过滤噪声和稳定优化。


<details>
  <summary>Details</summary>
Motivation: 现有NLP模型在评估可持续性报告时，容易受到绿色清洗和模糊声明的影响，泛化能力差。

Method: 提出一个参数高效的框架，结合对比学习和序数排名目标来结构化LLM的潜在空间，以捕捉具体行动和模糊声明之间的细微差别。该方法还利用门控特征调制来过滤披露噪声，并使用MetaGradNorm来稳定多目标优化。

Result: 在跨类别设置的实验中，该方法显示出比标准基线更强的鲁棒性，但同时也揭示了表示刚性与泛化能力之间的权衡。

Conclusion: 所提出的框架能够更鲁棒地处理可持续性报告中的绿色清洗和模糊声明，但需要进一步研究以平衡表示刚性和泛化能力。

Abstract: Sustainability reports are critical for ESG assessment, yet greenwashing and vague claims often undermine their reliability. Existing NLP models lack robustness to these practices, typically relying on surface-level patterns that generalize poorly. We propose a parameter-efficient framework that structures LLM latent spaces by combining contrastive learning with an ordinal ranking objective to capture graded distinctions between concrete actions and ambiguous claims. Our approach incorporates gated feature modulation to filter disclosure noise and utilizes MetaGradNorm to stabilize multi-objective optimization. Experiments in cross-category settings demonstrate superior robustness over standard baselines while revealing a trade-off between representational rigidity and generalization.

</details>


### [241] [Toward Culturally Aligned LLMs through Ontology-Guided Multi-Agent Reasoning](https://arxiv.org/abs/2601.21700)
*Wonduk Seo,Wonseok Choi,Junseo Koh,Juhyeon Lee,Hyunjin An,Minhyeong Yu,Jian Park,Qingshan Zhou,Seunghyun Lee,Yi Bu*

Main category: cs.CL

TL;DR: 提出了一种名为 OG-MAR 的框架，通过利用世界价值观调查数据构建文化本体，并结合多智能体推理来提高大型语言模型在文化敏感决策中的对齐性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在文化敏感决策方面存在对齐性问题，原因在于预训练数据的偏差以及缺乏结构化的价值观表示。现有方法虽然可以引导输出，但缺乏人口统计学依据，并将价值观视为独立的、非结构化的信号，导致一致性和可解释性降低。

Method: OG-MAR 框架通过以下步骤工作：1. 汇总来自世界价值观调查（WVS）的特定受访者价值观。2. 通过固定分类法的能力问题来引发关系，构建一个全局文化本体。3. 在推理时，检索与本体一致的关系和人口统计学上相似的个体画像，以实例化多个价值观-角色代理。4. 最后，由一个判断代理来综合这些代理的输出，该代理强制执行本体一致性和人口统计学邻近性。

Result: 在四个大型语言模型骨干上进行的跨区域社会调查基准测试表明，OG-MAR 相比于竞争基线，在文化对齐性和鲁棒性方面有所提高，并且能够生成更透明的推理过程。

Conclusion: OG-MAR 框架能够通过整合文化本体和多智能体推理，有效提高大型语言模型在文化敏感决策中的表现，同时增强了结果的可解释性。

Abstract: Large Language Models (LLMs) increasingly support culturally sensitive decision making, yet often exhibit misalignment due to skewed pretraining data and the absence of structured value representations. Existing methods can steer outputs, but often lack demographic grounding and treat values as independent, unstructured signals, reducing consistency and interpretability. We propose OG-MAR, an Ontology-Guided Multi-Agent Reasoning framework. OG-MAR summarizes respondent-specific values from the World Values Survey (WVS) and constructs a global cultural ontology by eliciting relations over a fixed taxonomy via competency questions. At inference time, it retrieves ontology-consistent relations and demographically similar profiles to instantiate multiple value-persona agents, whose outputs are synthesized by a judgment agent that enforces ontology consistency and demographic proximity. Experiments on regional social-survey benchmarks across four LLM backbones show that OG-MAR improves cultural alignment and robustness over competitive baselines, while producing more transparent reasoning traces.

</details>


### [242] [CE-GOCD: Central Entity-Guided Graph Optimization for Community Detection to Augment LLM Scientific Question Answering](https://arxiv.org/abs/2601.21733)
*Jiayin Lan,Jiaqi Li,Baoxin Wang,Ming Liu,Dayong Wu,Shijin Wang,Bing Qin,Guoping Hu*

Main category: cs.CL

TL;DR: 提出了一种名为CE-GOCD的框架，通过利用学术知识图谱中的中心实体和社区检测来增强大型语言模型在科学论文问答方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强方法仅关注孤立的文本块或概念，忽略了论文之间的深层语义联系，这阻碍了大型语言模型对科学文献的理解，并影响了回答的全面性和特异性。

Method: 该方法利用论文标题作为中心实体进行子图检索，通过子图剪枝和补全来发现隐含的语义关系，并应用社区检测来提炼出具有共同主题的连贯论文组。

Result: 在三个基于NLP文献的问答数据集上进行的评估表明，CE-GOCD的性能优于其他检索增强基线方法。

Conclusion: CE-GOCD框架通过显式建模和利用学术知识图谱中的语义子结构，有效地增强了大型语言模型在科学论文问答方面的表现。

Abstract: Large Language Models (LLMs) are increasingly used for question answering over scientific research papers. Existing retrieval augmentation methods often rely on isolated text chunks or concepts, but overlook deeper semantic connections between papers. This impairs the LLM's comprehension of scientific literature, hindering the comprehensiveness and specificity of its responses. To address this, we propose Central Entity-Guided Graph Optimization for Community Detection (CE-GOCD), a method that augments LLMs' scientific question answering by explicitly modeling and leveraging semantic substructures within academic knowledge graphs. Our approach operates by: (1) leveraging paper titles as central entities for targeted subgraph retrieval, (2) enhancing implicit semantic discovery via subgraph pruning and completion, and (3) applying community detection to distill coherent paper groups with shared themes. We evaluated the proposed method on three NLP literature-based question-answering datasets, and the results demonstrate its superiority over other retrieval-augmented baseline approaches, confirming the effectiveness of our framework.

</details>


### [243] [Temporal Guidance for Large Language Models](https://arxiv.org/abs/2601.21744)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为Temporal Guidance (TeGu) 的新型对比解码方法，通过利用多句预测（MTP）和条件MTP投影仪（cMTPP）来增强大型语言模型的生成质量，同时保持较低的计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 现有对比解码方法（如DoLa）计算开销大且在小型模型上不稳定。作者观察到LLM存在局部偏好，希望开发一种更高效、更稳定的对比解码策略。

Method: 提出Temporal Guidance (TeGu) 方法，通过多句预测（MTP）生成“业余”预测，并利用这些预测进行模型自对比。引入轻量级的条件MTP投影仪（cMTPP）以避免使用多个独立网络。

Result: TeGu在不同模型系列和基准测试中取得了显著的性能提升，同时保持了低内存占用和计算开销。

Conclusion: TeGu是一种有效且高效的对比解码策略，能够显著提高LLM的生成质量，并且易于实现，计算和内存开销低。

Abstract: Contrastive Decoding (CD) enhances the generation quality of large language models (LLMs) but incurs significant additional computational overhead due to the need for an auxiliary model. Existing internal self-contrastive decoding methods, such as Decoding by Contrasting Layers (DoLa), focus on discrepancies across different layers, which are notably unstable on small-scale models. In this work, based on the observation that LLMs exhibit local preferences, we propose a novel contrastive guidance strategy along the temporal dimension, namely Temporal Guidance (TeGu). Our method ingeniously leverages Multi-Token Prediction (MTP) to construct weaker amateur predictions for model self-contrast. To standardize the implementation of this mechanism, we further introduce a lightweight Conditional MTP Projector (cMTPP), which avoids maintaining multiple independent networks as required by other MTP modules. Across various model series and benchmarks, TeGu achieves significant performance improvements while maintaining low additional memory consumption and computational overhead.

</details>


### [244] [CoFrGeNet: Continued Fraction Architectures for Language Generation](https://arxiv.org/abs/2601.21766)
*Amit Dhurandhar,Vijil Chenthamarakshan,Dennis Wei,Tejaswini Pedapati,Karthikeyan Natesan Ramamurthy,Rahul Nair*

Main category: cs.CL

TL;DR: 本文提出了一种名为CoFrGeNets（Continued Fraction Generative Networks）的新型生成模型架构，其灵感来源于连分数。该架构能够替换Transformer中的多头注意力和前馈网络，但参数量更少。通过自定义梯度优化，CoFrGeNets在GPT2-xl和Llama3模型上表现出与原始模型相当甚至更优的性能，同时减少了参数量和预训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer架构参数量大，训练成本高。研究者希望设计一种参数量更少、效率更高的Transformer替代架构，以降低训练和推理成本，并探索新的生成模型函数类。

Method: 提出基于连分数的CoFrGeNets架构，其新型组件可替换Transformer中的多头注意力和前馈网络。采用自定义梯度优化方法来提高训练效率和精度。在GPT2-xl和Llama3模型上进行了实验，并在OpenWebText、GneissWeb和docling数据混合集上进行了预训练。

Result: CoFrGeNets在下游的分类、问答、推理和文本理解任务上，与原始模型相比，参数量减少了1/3到1/2，预训练时间更短，但性能具有竞争力，有时甚至更优。

Conclusion: CoFrGeNets是一种高效的Transformer替代架构，在生成模型领域具有潜力。通过定制化硬件优化，其性能有望进一步提升。

Abstract: Transformers are arguably the preferred architecture for language generation. In this paper, inspired by continued fractions, we introduce a new function class for generative modeling. The architecture family implementing this function class is named CoFrGeNets - Continued Fraction Generative Networks. We design novel architectural components based on this function class that can replace Multi-head Attention and Feed-Forward Networks in Transformer blocks while requiring much fewer parameters. We derive custom gradient formulations to optimize the proposed components more accurately and efficiently than using standard PyTorch-based gradients. Our components are a plug-in replacement requiring little change in training or inference procedures that have already been put in place for Transformer-based models thus making our approach easy to incorporate in large industrial workflows. We experiment on two very different transformer architectures GPT2-xl (1.5B) and Llama3 (3.2B), where the former we pre-train on OpenWebText and GneissWeb, while the latter we pre-train on the docling data mix which consists of nine different datasets. Results show that the performance on downstream classification, Q\& A, reasoning and text understanding tasks of our models is competitive and sometimes even superior to the original models with $\frac{2}{3}$ to $\frac{1}{2}$ the parameters and shorter pre-training time. We believe that future implementations customized to hardware will further bring out the true potential of our architectures.

</details>


### [245] [Evaluating ChatGPT on Medical Information Extraction Tasks: Performance, Explainability and Beyond](https://arxiv.org/abs/2601.21767)
*Wei Zhu*

Main category: cs.CL

TL;DR: 本文评估了ChatGPT在四项医学信息提取任务上的表现，发现其性能不如微调基线模型，尽管能提供高质量的解释，但过于自信，并且在多数情况下忠实于原文。然而，生成不确定性会影响信息提取结果，可能阻碍其在医学信息提取领域的应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）如ChatGPT在理解用户意图和生成响应方面表现出色，研究界对其在各种自然语言处理（NLP）任务中的能力很感兴趣，特别是医学信息提取（MedIE）任务。

Method: 研究人员对ChatGPT在6个基准数据集上的4项MedIE任务进行了系统性分析，评估了其性能、可解释性、置信度、忠实度和不确定性。

Result: （a）ChatGPT在MedIE任务上的性能得分低于微调后的基线模型。（b）ChatGPT能为决策提供高质量的解释，但其预测过于自信。（c）在大多数情况下，ChatGPT对原文表现出高度的忠实度。（d）生成过程中的不确定性导致信息提取结果的不确定性。

Conclusion: 虽然ChatGPT在MedIE任务上展示出一定的潜力，尤其是在解释性和忠实度方面，但其性能不如专业微调模型，并且过于自信和生成不确定性是其在MedIE领域应用的主要障碍。

Abstract: Large Language Models (LLMs) like ChatGPT have demonstrated amazing capabilities in comprehending user intents and generate reasonable and useful responses. Beside their ability to chat, their capabilities in various natural language processing (NLP) tasks are of interest to the research community. In this paper, we focus on assessing the overall ability of ChatGPT in 4 different medical information extraction (MedIE) tasks across 6 benchmark datasets. We present the systematically analysis by measuring ChatGPT's performance, explainability, confidence, faithfulness, and uncertainty. Our experiments reveal that: (a) ChatGPT's performance scores on MedIE tasks fall behind those of the fine-tuned baseline models. (b) ChatGPT can provide high-quality explanations for its decisions, however, ChatGPT is over-confident in its predcitions. (c) ChatGPT demonstrates a high level of faithfulness to the original text in the majority of cases. (d) The uncertainty in generation causes uncertainty in information extraction results, thus may hinder its applications in MedIE tasks.

</details>


### [246] [KID: Knowledge-Injected Dual-Head Learning for Knowledge-Grounded Harmful Meme Detection](https://arxiv.org/abs/2601.21796)
*Yaocong Li,Leihan Zhang,Le Zhang,Qiang Yan*

Main category: cs.CL

TL;DR: 本文提出了一种名为KID（Knowledge-Injected Dual-Head Learning）的框架，用于检测包含隐晦有害内容的网络梗图。该框架通过知识注入和双头学习机制，有效地将视觉证据、背景知识和分类标签联系起来，从而提高了检测性能。


<details>
  <summary>Details</summary>
Motivation: 网络梗图常包含隐晦的有害内容，现有自动内容审核方法难以处理，因为它们过度依赖隐喻和未显性呈现的背景知识。

Method: KID框架采用标签约束蒸馏范式，将梗图理解分解为结构化推理链，连接视觉证据、背景知识和分类标签。此外，它还使用双头架构，同时优化语义生成和分类目标，实现语言推理对齐并保持决策边界的稳定性。

Result: 在五个多语言数据集（英语、中文、孟加拉语）上进行的实验表明，KID在二元和多标签有害梗图检测任务上均取得了最先进的性能，在主要评估指标上比之前的方法提高了2.1%--19.7%。消融研究验证了知识注入和双头联合学习的有效性。

Conclusion: KID框架通过知识注入和双头联合学习，有效提高了对有害梗图的理解和检测能力，具有鲁棒性和泛化性。

Abstract: Internet memes have become pervasive carriers of digital culture on social platforms. However, their heavy reliance on metaphors and sociocultural context also makes them subtle vehicles for harmful content, posing significant challenges for automated content moderation. Existing approaches primarily focus on intra-modal and inter-modal signal analysis, while the understanding of implicit toxicity often depends on background knowledge that is not explicitly present in the meme itself. To address this challenge, we propose KID, a Knowledge-Injected Dual-Head Learning framework for knowledge-grounded harmful meme detection. KID adopts a label-constrained distillation paradigm to decompose complex meme understanding into structured reasoning chains that explicitly link visual evidence, background knowledge, and classification labels. These chains guide the learning process by grounding external knowledge in meme-specific contexts. In addition, KID employs a dual-head architecture that jointly optimizes semantic generation and classification objectives, enabling aligned linguistic reasoning while maintaining stable decision boundaries. Extensive experiments on five multilingual datasets spanning English, Chinese, and low-resource Bengali demonstrate that KID achieves SOTA performance on both binary and multi-label harmful meme detection tasks, improving over previous best methods by 2.1%--19.7% across primary evaluation metrics. Ablation studies further confirm the effectiveness of knowledge injection and dual-head joint learning, highlighting their complementary contributions to robust and generalizable meme understanding. The code and data are available at https://github.com/PotatoDog1669/KID.

</details>


### [247] [Procedural Pretraining: Warming Up Language Models with Abstract Data](https://arxiv.org/abs/2601.21725)
*Liangze Jiang,Zachary Shinnick,Anton van den Hengel,Hemanth Saratchandran,Damien Teney*

Main category: cs.CL

TL;DR: 本研究提出一种在网页规模语料库上直接预训练的替代方法，即先将模型暴露于抽象的程序性数据（如形式语言和算法生成的数据），以促进后续语义知识的获取。研究发现，程序性预训练可以显著提高模型在特定任务上的表现（例如，上下文召回率），并且即使只占很小比例的程序性数据也能优于标准预训练，同时加速模型收敛。此外，研究还探讨了程序性预训练的内在机制，发现其能为模型 Attention 和 MLP 层注入有益的结构，并为结合多种程序性数据提供了方法。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型预训练主要依赖于网页规模的自然语言语料库。然而，研究人员认为，模仿人类的学习方式——先学习基础的逻辑和数学知识，再进行高级推理——可能是一种更有效的途径。因此，本研究旨在探索一种替代范式，即通过暴露于抽象的程序性数据来“缓解”后续语义知识的学习过程。

Method: 研究首先诊断了不同形式的程序性数据能够显著提高的算法技能，例如在上下文召回任务上使用 Dyck 序列（平衡括号）进行预训练。随后，研究者将程序性数据预训练的优势扩展到更大的模型（高达 1.3B 参数），并比较了在不同数据集（C4, CodeParrot, DeepMind-Math）上进行标准预训练与加入少量程序性数据（占 0.1%）进行预训练的性能。最后，研究深入探讨了程序性预训练背后的机制，分析了其对 Attention 和 MLP 层的影响，并探索了组合多种程序性数据的可行性。

Result: 在上下文召回任务中，使用 Dyck 序列预训练的模型准确率从 10% 跃升至 98%。研究发现，即使只在前处理数据中加入 0.1% 的程序性数据，其表现也显著优于仅在自然语言、代码和非正式数学数据上进行标准预训练的模型。更重要的是，这种程序性预训练使模型能够使用更少的数据（74%、67%、86%）达到相同的损失值。研究还发现，程序性预训练能够为模型的 Attention 和 MLP 层注入有意义的结构，其中 Attention 层的结构对代码等结构化领域尤其重要，而 MLP 层的结构对语言更有益。

Conclusion: 程序性预训练是一种简单、轻量级且有效的方法，可以提高语言模型的性能并加速其预训练过程。通过将模型先暴露于程序性数据，可以促进其对后续更复杂语义知识的学习。这项研究为在大型语言模型中解耦知识获取与推理提供了新的思路。

Abstract: Pretraining directly on web-scale corpora is the de facto paradigm for building language models. We study an alternative setting where the model is initially exposed to abstract structured data, as a means to ease the subsequent acquisition of rich semantic knowledge, much like humans learn simple logic and mathematics before higher reasoning. We specifically focus on procedural data, generated by formal languages and other simple algorithms, as such abstract data.
  We first diagnose the algorithmic skills that different forms of procedural data can improve, often significantly. For example, on context recall (Needle-in-a-haystack), the accuracy jumps from 10 to 98% when pretraining on Dyck sequences (balanced brackets). Second, we study how these gains are reflected in pretraining larger models (up to 1.3B). We find that front-loading as little as 0.1% procedural data significantly outperforms standard pretraining on natural language, code, and informal mathematics (C4, CodeParrot, and DeepMind-Math datasets). Notably, this procedural pretraining enables the models to reach the same loss value with only 55, 67, 86% of the original data. Third, we explore the mechanisms behind and find that procedural pretraining instils non-trivial structure in both attention and MLP layers. The former is particularly important for structured domains (e.g. code), and the latter for language. Finally, we lay a path for combining multiple forms of procedural data. Our results show that procedural pretraining is a simple, lightweight means to improving performance and accelerating language model pretraining, ultimately suggesting the promise of disentangling knowledge acquisition from reasoning in LLMs.

</details>


### [248] [RAG-E: Quantifying Retriever-Generator Alignment and Failure Modes](https://arxiv.org/abs/2601.21803)
*Korbinian Randl,Guido Rocchietti,Aron Henriksson,Ziawasch Abedjan,Tony Lindgren,John Pavlopoulos*

Main category: cs.CL

TL;DR: 提出了一种名为 RAG-E 的端到端可解释性框架，用于量化检索增强生成（RAG）系统中检索器和生成器之间的对齐度，并识别出 RAG 在实践中存在的生成器忽视高排名文档或依赖低排名文档的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 RAG 系统组件（检索器和生成器）之间的交互过程不透明，这阻碍了其在高风险领域的部署。需要一种方法来理解和审计 RAG 的输出质量，该质量不仅取决于单个组件的性能，还取决于它们的相互作用。

Method: RAG-E 框架结合了数学上合理的归因方法。它将集成梯度（Integrated Gradients）应用于检索器分析，引入了 PMCSHAP（一种蒙特卡洛稳定化的 Shapley 值近似）用于生成器归因，并提出了加权归因-相关性差距（WARG）指标来衡量生成器对文档的使用与检索器排名的一致性。

Result: 在 TREC CAsT 和 FoodSafeSum 数据集上的实证分析揭示了 RAG 系统中存在关键的不对齐现象。具体来说，在 47.4% 到 66.7% 的查询中，生成器会忽略检索器的头部品级文档；同时，在 48.1% 到 65.9% 的查询中，生成器依赖于排名较低的文档。

Conclusion: RAG-E 框架能够揭示 RAG 系统中检索器和生成器之间存在的不对齐问题，表明 RAG 的输出质量是其组件交互的结果。通过 RAG-E 可以审计这些交互，从而提高 RAG 系统的可靠性。

Abstract: Retrieval-Augmented Generation (RAG) systems combine dense retrievers and language models to ground LLM outputs in retrieved documents. However, the opacity of how these components interact creates challenges for deployment in high-stakes domains. We present RAG-E, an end-to-end explainability framework that quantifies retriever-generator alignment through mathematically grounded attribution methods. Our approach adapts Integrated Gradients for retriever analysis, introduces PMCSHAP, a Monte Carlo-stabilized Shapley Value approximation, for generator attribution, and introduces the Weighted Attribution-Relevance Gap (WARG) metric to measure how well a generator's document usage aligns with a retriever's ranking. Empirical analysis on TREC CAsT and FoodSafeSum reveals critical misalignments: for 47.4% to 66.7% of queries, generators ignore the retriever's top-ranked documents, while 48.1% to 65.9% rely on documents ranked as less relevant. These failure modes demonstrate that RAG output quality depends not solely on individual component performance but on their interplay, which can be audited via RAG-E.

</details>


### [249] [Distribution-Aware Reward Estimation for Test-Time Reinforcement Learning](https://arxiv.org/abs/2601.21804)
*Bodong Du,Xuanqi Huang,Xiaomeng Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为DARE（Distribution-Aware Reward Estimation）的新方法，用于改进测试时强化学习（TTRL）中无监督 reward 信号的估计。DARE通过考虑所有rollout的分布而不是仅依赖多数投票来生成更准确和鲁棒的reward，并在推理基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有TTRL方法依赖多数投票估计reward信号，这种方法会丢弃非多数但可能正确的选择信息，并可能产生有偏的reward估计，因此需要更有效的reward估计方法。

Method: DARE方法通过以下几点改进reward估计：1. 考虑所有rollout的经验分布，而非单一多数结果；2. 引入探索奖励（exploration bonus）鼓励探索；3. 引入分布剪枝机制（distribution pruning mechanism）对非多数rollout进行去噪。

Result: 在AIME 2024和AMC等具有挑战性的推理基准测试上，DARE相比现有基线方法在优化稳定性和最终性能上均有提升，在AIME 2024上实现了25.3%的相对提升，在AMC上实现了5.3%的相对提升。

Conclusion: DARE通过从单一多数结果转向考虑整个rollout分布，并结合探索奖励和分布剪枝，能更准确、更鲁棒地估计reward信号，从而有效提升TTRL的性能，尤其在推理任务上表现出色。

Abstract: Test-time reinforcement learning (TTRL) enables large language models (LLMs) to self-improve on unlabeled inputs, but its effectiveness critically depends on how reward signals are estimated without ground-truth supervision. Most existing TTRL methods rely on majority voting (MV) over rollouts to produce deterministic rewards, implicitly assuming that the majority rollout provides a reliable learning signal. We show that this assumption is fragile: MV reduces the rollout distribution into a single outcome, discarding information about non-majority but correct actions candidates, and yields systematically biased reward estimates. To address this, we propose Distribution-AwareReward Estimation (DARE), which shifts reward estimation from a single majority outcome to the full empirical rollout distribution. DARE further augments this distribution-based reward with an exploration bonus and a distribution pruning mechanism for non-majority rollout exploration and reward denoise, yielding a more informative and robust reward estimation. Extensive experiments on challenging reasoning benchmarks show that DARE improves optimization stability and final performance over recent baselines, achieving relative improvements of 25.3% on challenging AIME 2024 and 5.3% on AMC.

</details>


### [250] [Zonkey: A Hierarchical Diffusion Language Model with Differentiable Tokenization and Probabilistic Attention](https://arxiv.org/abs/2601.21768)
*Alon Rozental*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Zonkey 的分层扩散模型，通过一个可微分的分词器（Segment Splitter）和一种新的概率注意力机制，实现了从原始字符到文档级表示的端到端可训练流程，克服了传统固定分词器的限制。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 受到固定、不可微分的分词器（如 BPE）的限制，这阻碍了端到端优化和对噪声或特定领域数据的适应性。研究旨在解决这些局限性，实现更灵活、可适应的模型。

Method: Zonkey 采用分层扩散模型，核心是可微分的分词器（Segment Splitter），它学习概率性的 BOS（Beginning-of-Sequence）决策，实现自适应分词。结合了概率注意力机制（Probabilistic Attention）来处理理论上无限序列的软掩码，并通过 Denoising Diffusion Mixed Model (DDMM) 进行反向传播。分层结构用于压缩序列，Stitcher 确保了分段的重叠不变性。

Result: 在 Wikipedia 数据集上进行端到端训练，Zonkey 能够从噪声生成连贯、可变长度的文本，展示了涌现的分层结构，并且在质量上与数据分布有更好的对齐，优于基于熵的可学习分词器。

Conclusion: Zonkey 方法朝着全梯度 LLM 的方向迈出了重要一步，有望在领域适应和可扩展生成方面提供更好的性能，并提供了相应的源代码。

Abstract: Large language models (LLMs) have revolutionized natural language processing, yet they remain constrained by fixed, non-differentiable tokenizers like Byte Pair Encoding (BPE), which hinder end-to-end optimization and adaptability to noisy or domain-specific data. We introduce Zonkey, a hierarchical diffusion model that addresses these limitations through a fully trainable pipeline from raw characters to document-level representations. At its core is a differentiable tokenizer (Segment Splitter) that learns probabilistic beginning-of-sequence (BOS) decisions, enabling adaptive splits that emerge as linguistically meaningful (e.g., word boundaries at spaces, sentence starts at periods) without explicit supervision. This differentiability is enabled by our novel Probabilistic Attention mechanism, which incorporates position-specific existence probabilities to simulate soft masking over theoretically infinite sequences while preserving gradients. Sequences decay probabilistically rather than relying on end-of-sequence tokens, supporting variable-length outputs. Hierarchical levels compress sequences into higher abstractions (e.g., character n-grams to word-like vectors, then sentence-like), with reconstruction via our Denoising Diffusion Mixed Model (DDMM) for stable and efficient denoising in latent space. A Stitcher ensures overlap invariance across segments. Trained end-to-end on Wikipedia, Zonkey generates coherent, variable-length text from noise, demonstrating emergent hierarchies and promising qualitative alignment to data distributions compared to entropy-based learnable tokenizers. Our approach advances toward fully gradient-based LLMs, with potential for better domain adaptation and scalable generation. We release the source code for training and reproducing our experiments.

</details>


### [251] [Mil-SCORE: Benchmarking Long-Context Geospatial Reasoning and Planning in Large Language Models](https://arxiv.org/abs/2601.21826)
*Aadi Palnitkar,Mingyang Mao,Nicholas Waytowich,Vinicius G. Goecks,Tinoosh Mohsenin,Xiaomin Lin*

Main category: cs.CL

TL;DR: 提出了一个名为 MilSCORE 的新基准，用于评估大型语言模型在处理复杂、多模态的军事规划场景中的长上下文推理能力，特别是对地图、指令和情报报告等异构信息源进行选择性阅读和整合的能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在处理长而复杂的任务时，尤其是在需要整合异构、多模态信息源的地理空间规划问题（如大规模军事行动规划）中，缺乏真实的、需要选择性阅读的长上下文基准。这阻碍了模型在这些高风险场景下的应用。

Method: 构建了一个名为 MilSCORE 的数据集，包含专家编写的、基于复杂模拟军事规划场景的多跳问题。该基准设计用于评估模型在高风险决策和规划方面的能力，通过七个类别的多样化问题类型，考察模型整合战术和空间推理、以及在长时域、富含地理空间信息的上下文中的推理能力。同时，提供了一个评估协议并报告了当前视觉语言模型的基线结果。

Result: 现有的大型语言模型在 MilSCORE 基准上表现出显著的提升空间，表明当前系统在处理真实场景级别的长上下文规划方面存在困难。

Conclusion: MilSCORE 是一个具有挑战性的新基准，能够有效评估大型语言模型在复杂、多模态、长上下文的军事规划场景中的长处和短板，并为未来的研究提供了重要的测试平台。

Abstract: As large language models (LLMs) are applied to increasingly longer and more complex tasks, there is a growing need for realistic long-context benchmarks that require selective reading and integration of heterogeneous, multi-modal information sources. This need is especially acute for geospatial planning problems, such as those found in planning for large-scale military operations, which demand fast and accurate reasoning over maps, orders, intelligence reports, and other distributed data. To address this gap, we present MilSCORE (Military Scenario Contextual Reasoning), to our knowledge the first scenario-level dataset of expert-authored, multi-hop questions grounded in a complex, simulated military planning scenario used for training. MilSCORE is designed to evaluate high-stakes decision-making and planning, probing LLMs' ability to combine tactical and spatial reasoning across multiple sources and to reason over long-horizon, geospatially rich context. The benchmark includes a diverse set of question types across seven categories targeting both factual recall and multi-step reasoning about constraints, strategy, and spatial analysis. We provide an evaluation protocol and report baseline results for a range of contemporary vision-language models. Our findings highlight substantial headroom on MilSCORE, indicating that current systems struggle with realistic, scenario-level long-context planning, and positioning MilSCORE as a challenging testbed for future work.

</details>


### [252] [Embodied Task Planning via Graph-Informed Action Generation with Large Lanaguage Model](https://arxiv.org/abs/2601.21841)
*Xiang Li,Ning Yan,Masood Mortazavi*

Main category: cs.CL

TL;DR: 该研究提出了一种名为GiG的新型规划框架，通过图神经网络（GNN）和图内图（Graph-in-Graph）架构来增强大型语言模型（LLM）作为具身智能体在长期规划中的能力，解决了LLM在动态环境中保持策略一致性和避免虚假过渡的问题。GiG利用图结构化记忆来检索过去成功规划的模式，并结合有界前瞻模块进行规划。实验表明，GiG在三个具身规划基准测试中均显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在作为具身智能体进行长期规划时面临挑战，容易因上下文窗口限制或虚假状态转移而导致策略不连贯。

Method: 提出GiG框架，采用图内图（Graph-in-Graph）架构构建记忆。利用GNN将环境状态编码为嵌入，并组织成经验记忆库中的执行轨迹图。通过图嵌入聚类检索结构感知先验。引入有界前瞻模块，利用符号转移逻辑增强规划能力。

Result: 在Robotouille Synchronous、Robotouille Asynchronous和ALFWorld三个具身规划基准测试中，GiG方法表现优于现有最先进的方法，Pass@1性能分别提升了22%、37%和15%，同时计算成本相当或更低。

Conclusion: GiG框架通过结构化记忆和基于符号逻辑的前瞻模块，有效地提高了LLM作为具身智能体在长期规划中的性能，克服了现有方法的局限性。

Abstract: While Large Language Models (LLMs) have demonstrated strong zero-shot reasoning capabilities, their deployment as embodied agents still faces fundamental challenges in long-horizon planning. Unlike open-ended text generation, embodied agents must decompose high-level intent into actionable sub-goals while strictly adhering to the logic of a dynamic, observed environment. Standard LLM planners frequently fail to maintain strategy coherence over extended horizons due to context window limitation or hallucinate transitions that violate constraints. We propose GiG, a novel planning framework that structures embodied agents' memory using a Graph-in-Graph architecture. Our approach employs a Graph Neural Network (GNN) to encode environmental states into embeddings, organizing these embeddings into action-connected execution trace graphs within an experience memory bank. By clustering these graph embeddings, the framework enables retrieval of structure-aware priors, allowing agents to ground current decisions in relevant past structural patterns. Furthermore, we introduce a novel bounded lookahead module that leverages symbolic transition logic to enhance the agents' planning capabilities through the grounded action projection. We evaluate our framework on three embodied planning benchmarks-Robotouille Synchronous, Robotouille Asynchronous, and ALFWorld. Our method outperforms state-of-the-art baselines, achieving Pass@1 performance gains of up to 22% on Robotouille Synchronous, 37% on Asynchronous, and 15% on ALFWorld with comparable or lower computational cost.

</details>


### [253] [Learn-to-Distance: Distance Learning for Detecting LLM-Generated Text](https://arxiv.org/abs/2601.21895)
*Hongyi Zhou,Jin Zhu,Erhan Xu,Kai Ye,Ying Yang,Chengchun Shi*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的基于重写检测的算法，通过自适应学习原文和重写文本之间的距离来提高检测大型语言模型（LLM）生成内容的准确性，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现代LLM生成的文本高度拟人化，引发了对错误信息和学术诚信的担忧，因此迫切需要可靠的算法来检测LLM生成的内容。

Method: 首先，提出了一种几何方法来解释重写检测算法的原理，并展示其泛化能力。在此基础上，引入了一种新颖的基于重写的检测算法，该算法能够自适应地学习原文和重写文本之间的距离。理论上证明了自适应距离函数比固定距离函数更有效。进行了超过100种设置的广泛实验。

Result: 提出的方法在大多数场景下均优于基线算法，实现了相对于最强基线算法57.8%至80.6%的相对性能提升，覆盖了GPT、Claude和Gemini等不同的目标LLM。

Conclusion: 自适应地学习原文和重写文本之间的距离是检测LLM生成内容的一种更有效的方法，本文提出的算法在实际应用中展现了优越的性能。

Abstract: Modern large language models (LLMs) such as GPT, Claude, and Gemini have transformed the way we learn, work, and communicate. Yet, their ability to produce highly human-like text raises serious concerns about misinformation and academic integrity, making it an urgent need for reliable algorithms to detect LLM-generated content. In this paper, we start by presenting a geometric approach to demystify rewrite-based detection algorithms, revealing their underlying rationale and demonstrating their generalization ability. Building on this insight, we introduce a novel rewrite-based detection algorithm that adaptively learns the distance between the original and rewritten text. Theoretically, we demonstrate that employing an adaptively learned distance function is more effective for detection than using a fixed distance. Empirically, we conduct extensive experiments with over 100 settings, and find that our approach demonstrates superior performance over baseline algorithms in the majority of scenarios. In particular, it achieves relative improvements from 57.8\% to 80.6\% over the strongest baseline across different target LLMs (e.g., GPT, Claude, and Gemini).

</details>


### [254] [Enhancing Conversational Agents via Task-Oriented Adversarial Memory Adaptation](https://arxiv.org/abs/2601.21797)
*Yimin Deng,Yuqing Fu,Derong Xu,Yejing Wang,Wei Ni,Jingtong Gao,Xiaopeng Li,Chengxu Liu,Xiao Han,Guoshuai Zhao,Xiangyu Zhao,Li Zhu,Xueming Qian*

Main category: cs.CL

TL;DR: 本文提出了一种名为AMA（Adversarial Memory Adaptation）的机制，通过模拟任务执行来解决对话系统长对话记忆构建和更新的固定化问题，提高了记忆系统对下游任务的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的对话系统记忆系统在离线阶段构建和更新记忆时，流程固定且与任务无关，导致记忆内容与任务需求不匹配，影响了下游任务的性能。

Method: AMA机制通过模拟任务执行来调整记忆的构建和更新。具体包括：1. 挑战者代理生成问答对；2. 利用构建的记忆回答问题，模拟推理；3. 评估者代理评估回答并分析错误；4. 适配器代理分析错误，并对记忆的构建策略和内容进行双层更新。

Result: AMA机制能够为记忆系统在离线阶段提供任务感知（task-aware）的监督信号，显著提升其对下游任务的适应性。在长对话基准LoCoMo上的实验表明了AMA的有效性。

Conclusion: AMA是一种通用的机制，可以集成到现有的记忆系统中，通过引入对抗性的任务模拟来改进记忆的构建和更新过程，从而提高长对话系统的性能。

Abstract: Conversational agents struggle to handle long conversations due to context window limitations. Therefore, memory systems are developed to leverage essential historical information. Existing memory systems typically follow a pipeline of offline memory construction and update, and online retrieval. Despite the flexible online phase, the offline phase remains fixed and task-independent. In this phase, memory construction operates under a predefined workflow and fails to emphasize task relevant information. Meanwhile, memory updates are guided by generic metrics rather than task specific supervision. This leads to a misalignment between offline memory preparation and task requirements, which undermines downstream task performance. To this end, we propose an Adversarial Memory Adaptation mechanism (AMA) that aligns memory construction and update with task objectives by simulating task execution. Specifically, first, a challenger agent generates question answer pairs based on the original dialogues. The constructed memory is then used to answer these questions, simulating downstream inference. Subsequently, an evaluator agent assesses the responses and performs error analysis. Finally, an adapter agent analyzes the error cases and performs dual level updates on both the construction strategy and the content. Through this process, the memory system receives task aware supervision signals in advance during the offline phase, enhancing its adaptability to downstream tasks. AMA can be integrated into various existing memory systems, and extensive experiments on long dialogue benchmark LoCoMo demonstrate its effectiveness.

</details>


### [255] [SONIC: Segmented Optimized Nexus for Information Compression in Key-Value Caching](https://arxiv.org/abs/2601.21927)
*Hong Chen,Xiang Liu,Bo Wang,Yuxuan Fan,Yuanlin Chu,Zongluo Li,Xiaowen Chu,Xuming Hu*

Main category: cs.CL

TL;DR: SONIC 是一种基于学习的框架，通过将历史对话片段压缩成紧凑的 Nexus 标记来缓解多轮 LLM 部署中的 KV 缓存瓶颈，并在保持对话连贯性的同时显著提高压缩率和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的 KV 缓存压缩方法在处理多轮对话时，未能充分考虑其结构特性，常采用启发式淘汰机制，可能丢失关键上下文。这阻碍了多轮 LLM 的高效部署。

Method: 提出 SONIC 框架，利用学习方法将历史对话片段压缩为语义丰富的 Nexus 标记。引入动态预算训练，使其能够适应不同的内存限制而无需重新训练。

Result: 在 80% 和 50% 的压缩率下，SONIC 在四个不同的多轮对话基准测试中持续优于 H2O 和 StreamingLLM 等基线方法。在 MTBench101 基准上，SONIC 的平均得分比最先进的基线方法提高了 35.55%。此外，SONIC 将整体推理过程加速了 50.1%。

Conclusion: SONIC 有效地解决了多轮 LLM 部署中的 KV 缓存瓶颈问题，通过学习方法实现高效压缩，并在保持对话连贯性的同时显著提升了性能和部署效率。

Abstract: The linear growth of Key-Value (KV) cache remains a bottleneck for multi-turn LLM deployment. Existing KV cache compression methods often fail to account for the structural properties of multi-turn dialogues, relying on heuristic eviction that risks losing critical context. We propose \textbf{SONIC}, a learning-based framework that compresses historical segments into compact and semantically rich \textbf{Nexus} tokens. By integrating dynamic budget training, SONIC allows flexible adaptation to varying memory constraints without retraining. Experiments show that at compression ratios of 80\% and 50\%, SONIC consistently outperforms baselines such as H2O and StreamingLLM on four diverse multi-turn benchmarks. Specifically, on the widely used MTBench101 benchmark, SONIC achieves an average score improvement of 35.55\% over state-of-the-art baselines, validating its effectiveness in sustaining coherent multi-turn dialogues. Furthermore, SONIC enhances deployment efficiency, accelerating the overall inference process by 50.1\% compared to full-context generation.

</details>


### [256] [From Generative Modeling to Clinical Classification: A GPT-Based Architecture for EHR Notes](https://arxiv.org/abs/2601.21955)
*Fariba Afrin Irany*

Main category: cs.CL

TL;DR: 研究提出了一种基于GPT的临床文本分类方法，通过选择性微调预训练模型，在参数更新量大幅减少的情况下，实现了高效且准确的临床文本分类。


<details>
  <summary>Details</summary>
Motivation: 电子病历中非结构化临床文本的增加带来了自动化疾病特征描述、队列识别和临床决策支持的机会。然而，由于标记数据有限、类别极度不平衡以及适应大型预训练语言模型的计算成本高昂，对长篇、领域特定的临床文本进行建模仍然具有挑战性。

Method: 本研究提出了一种基于GPT的临床文本分类架构，该架构采用选择性微调策略来适应预训练的 decoder-only Transformer。具体而言，大部分GPT-2主干模型被冻结，仅更新最后的Transformer块、最后的层归一化以及一个轻量级的分类头，从而大大减少了可训练参数的数量。

Result: 在MIMIC-IV-Note数据集的放射学报告上评估了该方法，使用从报告文本直接派生的不确定性感知CheXpert风格标签。实验结果表明，在多标签分类、不同不确定性假设下的二元分类以及汇总疾病结果预测等多种问题设置下，该模型表现出稳定的收敛行为和强大的分类性能，尤其是在非提及和否定发现占主导的情况下。

Conclusion: 研究结果表明，选择性微调预训练生成语言模型是进行临床文本分类的一种高效且有效的方法，它能够实现对真实世界电子病历数据的可扩展适应，同时显著降低了计算复杂性。

Abstract: The increasing availability of unstructured clinical narratives in electronic health records (EHRs) has created new opportunities for automated disease characterization, cohort identification, and clinical decision support. However, modeling long, domain-specific clinical text remains challenging due to limited labeled data, severe class imbalance, and the high computational cost of adapting large pretrained language models.
  This study presents a GPT-based architecture for clinical text classification that adapts a pretrained decoder-only Transformer using a selective fine-tuning strategy. Rather than updating all model parameters, the majority of the GPT-2 backbone is frozen, and training is restricted to the final Transformer block, the final layer normalization, and a lightweight classification head. This approach substantially reduces the number of trainable parameters while preserving the representational capacity required to model complex clinical language.
  The proposed method is evaluated on radiology reports from the MIMIC-IV-Note dataset using uncertainty-aware CheXpert-style labels derived directly from report text. Experiments cover multiple problem formulations, including multi-label classification of radiographic findings, binary per-label classification under different uncertainty assumptions, and aggregate disease outcome prediction. Across varying dataset sizes, the model exhibits stable convergence behavior and strong classification performance, particularly in settings dominated by non-mention and negated findings.
  Overall, the results indicate that selective fine-tuning of pretrained generative language models provides an efficient and effective pathway for clinical text classification, enabling scalable adaptation to real-world EHR data while significantly reducing computational complexity.

</details>


### [257] [OVD: On-policy Verbal Distillation](https://arxiv.org/abs/2601.21968)
*Jing Xiong,Hui Shen,Shansan Gong,Yuxin Cheng,Jianghan Shen,Chaofan Tao,Haochen Tan,Haoli Bai,Lifeng Shang,Ngai Wong*

Main category: cs.CL

TL;DR: 本文提出了一种名为On-policy Verbal Distillation (OVD) 的新方法，通过使用教师模型的离散语言评分（0-9）进行轨迹匹配，克服了现有方法在内存效率、探索能力和交互式环境反馈方面的局限性，在问答和数学推理任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Token级别的on-policy蒸馏方法在模型对齐、探索能力、环境反馈利用以及内存消耗方面存在不足，限制了知识蒸馏在强化学习中的有效应用。

Method: OVD框架使用离散的语言评分（0-9）来匹配教师模型的轨迹，替代了Token级别的概率匹配。这减少了内存消耗，避免了Token级别的对齐，从而允许学生模型自由探索输出空间，并能从具有语言反馈的教师模型中进行on-policy蒸馏。

Result: 在Web问答和数学推理任务上的实验表明，OVD显著优于现有方法。在Web问答任务上，平均EM提高了12.9%；在数学基准测试上，使用单个随机样本训练时，性能提高了25.7%。同时，OVD也展现了更高的训练效率。

Conclusion: OVD是一种高效且灵活的知识蒸馏框架，通过引入基于轨迹和离散语言评分的蒸馏方式，有效解决了现有方法的痛点，并在多个下游任务上取得了优异的性能和效率提升。

Abstract: Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io

</details>


### [258] [Token-Guard: Towards Token-Level Hallucination Control via Self-Checking Decoding](https://arxiv.org/abs/2601.21969)
*Yifan Zhu,Huiqiang Rong,Haoran Luo*

Main category: cs.CL

TL;DR: 本文提出了一种名为Token-Guard的轻量级、模块化方法，通过在生成过程中进行自我检查和风险评估，有效减少大型语言模型的幻觉问题，并提高生成内容的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）常出现幻觉问题，现有方法（如RAG和RLHF）计算成本高昂或需要大规模微调，而仅依赖解码的方法缺乏明确的幻觉控制。因此，需要一种更轻量级、更有效的方法来解决LLMs的幻觉问题。

Method: Token-Guard是一种基于自我检查解码的token级幻觉控制方法。它在每个推理步骤进行内部验证以检测幻觉token，并通过在潜在空间中对候选片段进行评估，计算幻觉风险评分，然后通过迭代剪枝和重新生成来动态纠正错误。

Result: 在HALU数据集上的实验表明，Token-Guard显著减少了幻觉，并提高了生成准确性。

Conclusion: Token-Guard提供了一种可扩展、模块化的解决方案，能够有效控制LLM的幻觉，生成更可靠的输出。

Abstract: Large Language Models (LLMs) often hallucinate, generating content inconsistent with the input. Retrieval-Augmented Generation (RAG) and Reinforcement Learning with Human Feedback (RLHF) can mitigate hallucinations but require resource-intensive retrieval or large-scale fine-tuning. Decoding-based methods are lighter yet lack explicit hallucination control. To address this, we present Token-Guard, a token-level hallucination control method based on self-checking decoding. Token-Guard performs internal verification at each reasoning step to detect hallucinated tokens before they propagate. Candidate fragments are further evaluated in a latent space with explicit hallucination risk scoring, while iterative pruning and regeneration dynamically correct detected errors. Experiments on HALU datasets show Token-Guard substantially reduces hallucinations and improves generation accuracy, offering a scalable, modular solution for reliable LLM outputs. Our code is publicly available.

</details>


### [259] [Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units](https://arxiv.org/abs/2601.21996)
*Jianhui Chen,Yuzhang Luo,Liangming Pan*

Main category: cs.CL

TL;DR: 本研究提出了机械化数据归因 (MDA) 框架，利用影响函数将可解释的神经网络单元追溯到训练数据。通过实验证明，移除或增强具有高影响力的训练样本可以显著影响可解释“头”的出现，而随机干预无效。研究发现结构化数据（如 LaTeX, XML）在催化可解释单元形成中起关键作用，并且诱导头（induction head）的形成与模型在上下文学习（ICL）能力存在因果关系。最后，提出了一种机械化数据增强方法，可以加速 LLMs 的电路收敛。


<details>
  <summary>Details</summary>
Motivation: 现有机械化可解释性研究能够识别 LLMs 中的可解释电路，但其在训练数据中的因果起源尚不明确。因此，研究旨在找到一种方法来追溯这些可解释单元的训练数据来源，并理解数据如何影响模型的学习过程。

Method: 研究提出了机械化数据归因 (MDA) 框架，该框架利用影响函数 (Influence Functions) 来追踪可解释单元 (interpretable units) 与训练数据样本之间的关系。通过在 Pythia 模型系列上进行实验，对比了移除或增强少量高影响力训练样本与随机干预的效果，并分析了结构化数据的作用。此外，还通过干预诱导头形成来观察其对模型在上下文学习能力的影响，并提出了一种机械化数据增强管道。

Result: 1. 移除或增强少量高影响力训练样本显著改变了可解释“头”的出现；随机干预则无效。
2. 重复的结构化数据（如 LaTeX, XML）充当了机械化催化剂。
3. 干预诱导头的形成会同时改变模型的在上下文学习 (ICL) 能力。
4. 提出的机械化数据增强方法能持续加速模型各个规模下的电路收敛。

Conclusion: 本研究成功建立了机械化可解释性与训练数据之间的因果联系，证明了特定训练样本对模型内部电路形成的关键作用，并为理解和操控 LLMs 的学习轨迹提供了新的方法和视角。研究结果为诱导头与 ICL 之间的函数关系提供了直接的因果证据，并提出了一种有原则的数据增强策略来加速 LLMs 的发展。

Abstract: While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.

</details>


### [260] [Causal Autoregressive Diffusion Language Model](https://arxiv.org/abs/2601.22031)
*Junhao Ruan,Bei Li,Yongjing Yin,Pengcheng Huang,Xin Chen,Jingang Wang,Xunliang Cai,Tong Xiao,JingBo Zhu*

Main category: cs.CL

TL;DR: 本文提出了因果自回归扩散（CARD）框架，结合了自回归模型（ARMs）的训练效率和扩散模型的推理吞吐量，通过严格的因果注意力掩码实现高效训练，并引入软尾掩码和上下文感知重加权机制来解决优化不稳定性问题，实现了ARM级别的数据效率和并行生成的速度优势。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型推理吞吐量低，自回归模型训练效率高但生成速度受限，作者希望结合两者的优点，提出一种既能高效训练又能快速推理的新框架。

Method: 提出了因果自回归扩散（CARD）框架，将扩散过程置于严格的因果注意力掩码中，实现单次前向传播的密集、每token监督。引入软尾掩码和上下文感知重加权机制来解决因果扩散的优化不稳定性问题。利用KV缓存实现动态并行解码，自适应生成可变长度的token序列。

Result:  CARD在离散扩散基线模型上表现更优，训练延迟降低了3倍。实现了ARM级别的数据效率，并具备并行生成的低延迟优势。

Conclusion:  CARD建立了一个高效且强大的下一代LLM范式，结合了ARM的数据效率和并行生成的低延迟特性。

Abstract: In this work, we propose Causal Autoregressive Diffusion (CARD), a novel framework that unifies the training efficiency of ARMs with the high-throughput inference of diffusion models. CARD reformulates the diffusion process within a strictly causal attention mask, enabling dense, per-token supervision in a single forward pass. To address the optimization instability of causal diffusion, we introduce a soft-tailed masking schema to preserve local context and a context-aware reweighting mechanism derived from signal-to-noise principles. This design enables dynamic parallel decoding, where the model leverages KV-caching to adaptively generate variable-length token sequences based on confidence. Empirically, CARD outperforms existing discrete diffusion baselines while reducing training latency by 3 $\times$ compared to block diffusion methods. Our results demonstrate that CARD achieves ARM-level data efficiency while unlocking the latency benefits of parallel generation, establishing a robust paradigm for next-generation efficient LLMs.

</details>


### [261] [When "Better" Prompts Hurt: Evaluation-Driven Iteration for LLM Applications](https://arxiv.org/abs/2601.22025)
*Daniel Commey*

Main category: cs.CL

TL;DR: 研究提出了一种名为“定义、测试、诊断、修复”的评估驱动工作流程，以应对大型语言模型（LLM）应用评估的挑战。该工作流程包括最小可行评估套件（MVES）和通用评估方法。实验表明，通用的“改进”提示模板可能会权衡不同行为的表现，提示进行评估驱动的提示迭代和审慎的声明校准。


<details>
  <summary>Details</summary>
Motivation: 评估 LLM 应用比传统软件测试更具挑战性，因为其输出是随机的、高维的且对提示和模型变化敏感。

Method: 提出了一种评估驱动的工作流程（定义、测试、诊断、修复），引入了最小可行评估套件（MVES），并综合了常见的评估方法（自动化检查、人工评分、LLM-as-judge），同时讨论了已知评判失败模式。在本地实验中（Ollama；Llama 3 8B Instruct 和 Qwen 2.5 7B Instruct）进行了可复现的实验。

Result: 实验观察到，通用的“改进”提示模板会权衡行为：在结构化测试套件上，使用通用规则替换特定任务提示后，Llama 3 的提取通过率从 100% 下降到 90%，RAG 合规性从 93.3% 下降到 80%，而指令遵循能力有所提高。

Conclusion: 研究结果表明，LLM 应用的评估应驱动提示的迭代，并进行审慎的声明校准，而不是依赖通用的提示模板。

Abstract: Evaluating Large Language Model (LLM) applications differs from traditional software testing because outputs are stochastic, high-dimensional, and sensitive to prompt and model changes. We present an evaluation-driven workflow - Define, Test, Diagnose, Fix - that turns these challenges into a repeatable engineering loop.
  We introduce the Minimum Viable Evaluation Suite (MVES), a tiered set of recommended evaluation components for (i) general LLM applications, (ii) retrieval-augmented generation (RAG), and (iii) agentic tool-use workflows. We also synthesize common evaluation methods (automated checks, human rubrics, and LLM-as-judge) and discuss known judge failure modes.
  In reproducible local experiments (Ollama; Llama 3 8B Instruct and Qwen 2.5 7B Instruct), we observe that a generic "improved" prompt template can trade off behaviors: on our small structured suites, extraction pass rate decreased from 100% to 90% and RAG compliance from 93.3% to 80% for Llama 3 when replacing task-specific prompts with generic rules, while instruction-following improved. These findings motivate evaluation-driven prompt iteration and careful claim calibration rather than universal prompt recipes.
  All test suites, harnesses, and results are included for reproducibility.

</details>


### [262] [A Separable Architecture for Continuous Token Representation in Language Models](https://arxiv.org/abs/2601.22040)
*Reza T. Batley,Sourav Saha*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Leviathan 的新模型架构，它使用连续嵌入生成器替代离散查找表，并在小语言模型（SLMs）中取得了比标准 LLaMA 模型更好的性能，有效参数容量提高了 1.47 到 2.11 倍。


<details>
  <summary>Details</summary>
Motivation: 传统的 Transformer 缩放定律将参数视为可互换的，这在高参数量模型中效果良好，但在小语言模型（SLMs）中，嵌入矩阵占据了大部分参数，这种分配方式被认为是次优且违反直觉的。

Method: 提出 Leviathan 架构，用连续嵌入生成器替换离散查找表。在 Pile 数据集上，在等参数设置下，将 Leviathan 与标准 LLaMA 风格架构进行了对比评估，并通过经验性幂律拟合来分析其有效参数容量。

Result: Leviathan 在等参数设置下持续优于标准的 LLaMA 风格架构。经验性幂律拟合显示，Leviathan 具有明显更高的有效参数容量，在研究的范围内，其行为相当于一个参数量增加了 1.47 到 2.11 倍的密集模型。

Conclusion: Leviathan 架构通过使用连续嵌入生成器，有效解决了小语言模型中嵌入矩阵参数比例过高的问题，显著提高了模型的有效参数容量和性能，证明了其优于传统离散嵌入查找表的潜力。

Abstract: Transformer scaling law analyses typically treat parameters as interchangeable; an abstraction that accurately predicts loss-compute relationships. Yet, in sub-billion-parameter small language models (SLMs), embedding matrices dominate the parameter budget. This work argues that this allocation is as suboptimal as it is counterintuitive. Leviathan is an architecture with a continuous embedding generator to replace the discrete lookup tables of canonical models. Evaluating on the Pile dataset under isoparametric settings, Leviathan consistently outperforms a standard, LLaMA-style architecture. By means of an empirical power-law fit, Leviathan exhibits a markedly superior effective parameter capacity. Across the regime studied, Leviathan behaves as a dense model with $1.47$ to $2.11 \times$ more parameters.

</details>


### [263] [Thinking Out of Order: When Output Order Stops Reflecting Reasoning Order in Diffusion Language Models](https://arxiv.org/abs/2601.22035)
*Longxuan Yu,Yu Fu,Shaorong Zhang,Hui Liu,Mukund Varma T,Greg Ver Steeg,Yue Dong*

Main category: cs.CL

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Autoregressive (AR) language models enforce a fixed left-to-right generation order, creating a fundamental limitation when the required output structure conflicts with natural reasoning (e.g., producing answers before explanations due to presentation or schema constraints). In such cases, AR models must commit to answers before generating intermediate reasoning, and this rigid constraint forces premature commitment. Masked diffusion language models (MDLMs), which iteratively refine all tokens in parallel, offer a way to decouple computation order from output structure. We validate this capability on GSM8K, Math500, and ReasonOrderQA, a benchmark we introduce with controlled difficulty and order-level evaluation. When prompts request answers before reasoning, AR models exhibit large accuracy gaps compared to standard chain-of-thought ordering (up to 67% relative drop), while MDLMs remain stable ($\leq$14% relative drop), a property we term "order robustness". Using ReasonOrderQA, we present evidence that MDLMs achieve order robustness by stabilizing simpler tokens (e.g., reasoning steps) earlier in the diffusion process than complex ones (e.g., final answers), enabling reasoning tokens to stabilize before answer commitment. Finally, we identify failure conditions where this advantage weakens, outlining the limits required for order robustness.

</details>


### [264] [On the Paradoxical Interference between Instruction-Following and Task Solving](https://arxiv.org/abs/2601.22047)
*Yunjia Qi,Hao Peng,Xintong Shi,Amy Xin,Xiaozhi Wang,Bin Xu,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 研究发现，在大型语言模型（LLM）中遵循指令有时会适得其反，损害其解决问题的能力。提出SUSTAINSCORE指标量化这种干扰，实验证明即使是先进的模型也受影响，并探索了干扰的普遍性、失败模式和潜在机制。


<details>
  <summary>Details</summary>
Motivation: 研究人员注意到，在LLM中明确指定指令以使其符合人类意图的操作，有时反而会削弱模型的任务解决能力，这是一种反直觉的现象，促使他们进行深入研究。

Method: 提出SUSTAINSCORE指标，通过在指令中加入从模型原始成功输出中提取的、对输出本身显而易见的约束条件，来衡量指令遵循对任务解决能力的干扰程度。在数学、多跳问答和代码生成等任务上，针对当前LLM进行实验。

Result: 实验表明，即使对于Claude-Sonnet-4.5等先进模型，添加自显式约束也会导致性能显著下降。这种干扰在不同类型的约束和模型规模上都具有普遍性。研究还识别了常见的失败模式，并发现失败案例中模型对约束条件的关注度远高于成功案例。

Conclusion: 指令遵循可能会以意想不到的方式干扰LLM的任务解决能力。SUSTAINSCORE提供了一种量化这种干扰的方法，并可用于初步评估不同模型训练范式（如微调）对干扰效应的影响，为进一步研究提供实证依据。

Abstract: Instruction following aims to align Large Language Models (LLMs) with human intent by specifying explicit constraints on how tasks should be performed. However, we reveal a counterintuitive phenomenon: instruction following can paradoxically interfere with LLMs' task-solving capability. We propose a metric, SUSTAINSCORE, to quantify the interference of instruction following with task solving. It measures task performance drop after inserting into the instruction a self-evident constraint, which is naturally met by the original successful model output and extracted from it. Experiments on current LLMs in mathematics, multi-hop QA, and code generation show that adding the self-evident constraints leads to substantial performance drops, even for advanced models such as Claude-Sonnet-4.5. We validate the generality of the interference across constraint types and scales. Furthermore, we identify common failure patterns, and by investigating the mechanisms of interference, we observe that failed cases allocate significantly more attention to constraints compared to successful ones. Finally, we use SUSTAINSCORE to conduct an initial investigation into how distinct post-training paradigms affect the interference, presenting empirical observations on current alignment strategies. We will release our code and data to facilitate further research

</details>


### [265] [MasalBench: A Benchmark for Contextual and Cross-Cultural Understanding of Persian Proverbs in LLMs](https://arxiv.org/abs/2601.22050)
*Ghazal Kalhor,Behnam Bahrak*

Main category: cs.CL

TL;DR: 本文介绍了MasalBench，一个评估大型语言模型（LLMs）对波斯语谚语的理解能力的新基准。研究发现，尽管LLMs能够识别波斯语谚语，但在找出其对应的英语谚语方面表现不佳，这揭示了它们在文化知识和类比推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 先前的研究主要关注高资源语言中LLMs对习语的理解，而对低资源语言（如波斯语）的表现却鲜有探讨。为了填补这一空白，作者们致力于评估LLMs在波斯语这一低资源语言中的对话理解能力。

Method: 作者们创建了一个名为MasalBench的综合性基准，用于评估LLMs对波斯语谚语的上下文理解和跨文化理解能力。他们使用八个最先进的LLMs在MasalBench上进行了评估，测试它们识别波斯语谚语以及找出相应英语谚语的能力。

Result: 在识别波斯语谚语方面，所有评估的LLMs表现出色，准确率均高于0.90。然而，在要求LLMs找出等效的英语谚语时，其性能显著下降，表现最好的模型准确率仅为0.79。

Conclusion: 研究结果表明，当前的LLMs在掌握文化知识和进行类比推理方面存在不足，尤其是在低资源语言的跨文化理解方面。MasalBench为此类评估提供了一个框架，并为未来在其他低资源语言中进行类似评估奠定了基础。

Abstract: In recent years, multilingual Large Language Models (LLMs) have become an inseparable part of daily life, making it crucial for them to master the rules of conversational language in order to communicate effectively with users. While previous work has evaluated LLMs' understanding of figurative language in high-resource languages, their performance in low-resource languages remains underexplored. In this paper, we introduce MasalBench, a comprehensive benchmark for assessing LLMs' contextual and cross-cultural understanding of Persian proverbs, which are a key component of conversation in this low-resource language. We evaluate eight state-of-the-art LLMs on MasalBench and find that they perform well in identifying Persian proverbs in context, achieving accuracies above 0.90. However, their performance drops considerably when tasked with identifying equivalent English proverbs, with the best model achieving 0.79 accuracy. Our findings highlight the limitations of current LLMs in cultural knowledge and analogical reasoning, and they provide a framework for assessing cross-cultural understanding in other low-resource languages. MasalBench is available at https://github.com/kalhorghazal/MasalBench.

</details>


### [266] [$G^2$-Reader: Dual Evolving Graphs for Multimodal Document QA](https://arxiv.org/abs/2601.22055)
*Yaxin Du,Junru Song,Yifan Zhou,Cheng Wang,Jiahao Gu,Zimeng Chen,Menglan Chen,Wen Yao,Yang Yang,Ying Wen,Siheng Chen*

Main category: cs.CL

TL;DR: 提出了一种名为 G^2-Reader 的双图系统，通过保留文档结构和跨模态语义的Content Graph，以及跟踪中间发现并指导导航的Planning Graph，来解决多模态长文档问答中的结构破坏和检索漂移问题。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成方法在处理文本、表格和图形交错的多模态长文档时存在不足，其问题在于扁平的块划分破坏了文档的原始结构和跨模态对齐，导致语义片段难以独立解释；同时，迭代式检索可能因为缺乏全局搜索状态而在长文本中循环或漂移到无关部分。

Method: 提出 G^2-Reader，一个双图系统。它包含一个 Content Graph，用于保留文档的本地结构和跨模态语义；以及一个 Planning Graph，一个代理的子问题定向无环图，用于跟踪中间发现并指导逐步导航以完成证据。

Result: 在 VisDoMBench 数据集上，使用 Qwen3-VL-32B-Instruct 的 G^2-Reader 在五个多模态领域取得了 66.21% 的平均准确率，优于强基线和单独使用的 GPT-5 (53.08%)。

Conclusion: G^2-Reader 系统通过维护文档的结构化内容图和代理式的规划图，能够有效地解决多模态长文档问答中的挑战，显著提升了问答性能。

Abstract: Retrieval-augmented generation is a practical paradigm for question answering over long documents, but it remains brittle for multimodal reading where text, tables, and figures are interleaved across many pages. First, flat chunking breaks document-native structure and cross-modal alignment, yielding semantic fragments that are hard to interpret in isolation. Second, even iterative retrieval can fail in long contexts by looping on partial evidence or drifting into irrelevant sections as noise accumulates, since each step is guided only by the current snippet without a persistent global search state. We introduce $G^2$-Reader, a dual-graph system, to address both issues. It evolves a Content Graph to preserve document-native structure and cross-modal semantics, and maintains a Planning Graph, an agentic directed acyclic graph of sub-questions, to track intermediate findings and guide stepwise navigation for evidence completion. On VisDoMBench across five multimodal domains, $G^2$-Reader with Qwen3-VL-32B-Instruct reaches 66.21\% average accuracy, outperforming strong baselines and a standalone GPT-5 (53.08\%).

</details>


### [267] [ECO: Quantized Training without Full-Precision Master Weights](https://arxiv.org/abs/2601.22101)
*Mahdi Nikdan,Amir Zandieh,Dan Alistarh,Vahab Mirrokni*

Main category: cs.CL

TL;DR: 本文提出了一种名为ECO（Error-Compensating Optimizer）的优化器，用于在LLM训练中消除高精度主权重（master weights）的内存开销，通过将量化误差反馈到动量中，在不牺牲精度的情况下显著减少内存占用。


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练中的量化方法虽然提高了计算和内存效率，但仍依赖于高精度的master weights，这在大模型（尤其是SMoE模型）中造成了显著的内存开销。

Method: ECO直接将梯度更新应用于量化参数，并在每一步后量化权重，然后将产生的量化误差注入优化器动量，形成一个无需额外内存的误差反馈循环。

Result: ECO在多种模型（包括小Transformer、Gemma-3 1B、2.1B SMoE以及DeepSeek-MoE-16B）上进行预训练和微调，结果显示其在FP8和INT4精度下均能达到与master weights基线几乎无损的精度，并在静态内存与验证损失的帕累托前沿上实现了显著提升。

Conclusion: ECO成功消除了LLM训练中master weights的内存瓶颈，通过量化误差补偿机制，在保持高精度的同时大幅提升了内存效率，为大模型训练提供了更优的解决方案。

Abstract: Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely on accumulating their updates in high-precision: concretely, gradient updates must be applied to a high-precision weight buffer, known as $\textit{master weights}$. This buffer introduces substantial memory overhead, particularly for Sparse Mixture of Experts (SMoE) models, where model parameters and optimizer states dominate memory usage. To address this, we introduce the Error-Compensating Optimizer (ECO), which eliminates master weights by applying updates directly to quantized parameters. ECO quantizes weights after each step and carefully injects the resulting quantization error into the optimizer momentum, forming an error-feedback loop with no additional memory. We prove that, under standard assumptions and a decaying learning rate, ECO converges to a constant-radius neighborhood of the optimum, while naive master-weight removal can incur an error that is inversely proportional to the learning rate. We show empirical results for pretraining small Transformers (30-800M), a Gemma-3 1B model, and a 2.1B parameter Sparse MoE model with FP8 quantization, and fine-tuning DeepSeek-MoE-16B in INT4 precision. Throughout, ECO matches baselines with master weights up to near-lossless accuracy, significantly shifting the static memory vs validation loss Pareto frontier.

</details>


### [268] [A Federated and Parameter-Efficient Framework for Large Language Model Training in Medicine](https://arxiv.org/abs/2601.22124)
*Anran Li,Yuanyuan Chen,Wenjun Long,Yu Yin,Yan Hu,Hyunjae Kim,Weipeng Zhou,Yujia Zhou,Hongyi Peng,Yang Ren,Xuguang Ai,Zhenyue Qin,Ming Hu,Xiaoxiao Li,Han Yu,Yih-Chung Tham,Lucila Ohno-Machado,Hua Xu,Qingyu Chen*

Main category: cs.CL

TL;DR: 本文提出了 Fed-MedLoRA 和 Fed-MedLoRA+ 框架，用于在保持数据隐私的同时，通过联邦学习适配大型语言模型（LLMs）到医疗应用，解决了通信开销大和数据异构性问题。


<details>
  <summary>Details</summary>
Motivation: 目前医疗领域的大型语言模型（LLMs）多基于单一机构数据训练，泛化性和安全性受限。联邦学习（FL）可以解决这一问题，但现有的 FL 方法在适配 LLMs 时面临模型参数量大导致通信开销过高以及医疗数据高度异构性的挑战。

Method: 提出了 Fed-MedLoRA 框架，采用参数高效的 LoRA（Low-Rank Adaptation）技术，仅传输低秩适配器参数，减少通信和计算开销。在此基础上，Fed-MedLoRA+ 进一步引入了数据感知的自适应聚合方法，以应对跨站点数据异构性，提高收敛性。实验将该框架应用于临床信息提取任务，并在五个患者队列上与 BERT、LLaMA-3、DeepSeek-R1 和 GPT-4o 等模型进行比较，评估了模型在不同设置下的准确性。

Result: Fed-MedLoRA 框架通过仅传输低秩适配器参数，显著降低了通信和计算的开销。Fed-MedLoRA+ 通过自适应聚合，在处理异构数据时表现出更优的收敛性能。在临床信息提取任务上，该框架在不同数据集和评估场景下均取得了具有竞争力的准确率。

Conclusion: Fed-MedLoRA 和 Fed-MedLoRA+ 框架能够有效地解决联邦学习在适配大型语言模型到医疗应用时面临的通信和数据异构性问题，为跨机构的医疗 LLM 协作提供了可行的解决方案。

Abstract: Large language models (LLMs) have demonstrated strong performance on medical benchmarks, including question answering and diagnosis. To enable their use in clinical settings, LLMs are typically further adapted through continued pretraining or post-training using clinical data. However, most medical LLMs are trained on data from a single institution, which faces limitations in generalizability and safety in heterogeneous systems. Federated learning (FL) is a promising solution for enabling collaborative model development across healthcare institutions. Yet applying FL to LLMs in medicine remains fundamentally limited. First, conventional FL requires transmitting the full model during each communication round, which becomes impractical for multi-billion-parameter LLMs given the limited computational resources. Second, many FL algorithms implicitly assume data homogeneity, whereas real-world clinical data are highly heterogeneous across patients, diseases, and institutional practices. We introduce the model-agnostic and parameter-efficient federated learning framework for adapting LLMs to medical applications. Fed-MedLoRA transmits only low-rank adapter parameters, reducing communication and computation overhead, while Fed-MedLoRA+ further incorporates adaptive, data-aware aggregation to improve convergence under cross-site heterogeneity. We apply the framework to clinical information extraction (IE), which transforms patient narratives into structured medical entities and relations. Accuracy was assessed across five patient cohorts through comparisons with BERT models, and LLaMA-3 and DeepSeek-R1, GPT-4o models. Evaluation settings included (1) in-domain training and testing, (2) external validation on independent cohorts, and (3) a low-resource new-site adaptation scenario using real-world clinical notes from the Yale New Haven Health System.

</details>


### [269] [Reasoning While Asking: Transforming Reasoning Large Language Models from Passive Solvers to Proactive Inquirers](https://arxiv.org/abs/2601.22139)
*Xin Chen,Feng Jiang,Yiqian Zhang,Hardy Chen,Shuo Yan,Wenya Xie,Min Yang,Shujian Huang*

Main category: cs.CL

TL;DR: 提出了一种名为“主动交互推理”（PIR）的新型推理范式，通过与用户交互来解决大型语言模型（LLMs）在信息缺失或模糊时的“盲目自思”问题，提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于思维链（CoT）的LLMs在信息不完整或模糊时会进行无效的内部推理，即“盲目自思”。需要一种新的范式来解决这种基本局限性，使LLMs能够主动寻求澄清。

Method: PIR通过两个核心组件实现：1. 不确定性感知监督微调，使模型具备交互推理能力；2. 基于用户模拟器的策略优化框架，通过复合奖励使模型行为与用户意图对齐。

Result: 在数学推理、代码生成和文档编辑等任务上，PIR的准确率、通过率和BLEU分数均显著优于强基线模型。此外，PIR显著减少了推理计算量和不必要的交互轮数。在事实知识、问答和缺失前提等场景下的可靠性评估也证实了其泛化能力和鲁棒性。

Conclusion: PIR能够有效地将LLMs从被动求解者转变为主动探究者，通过与用户交互解决前提和意图层面的不确定性，从而在多个任务上取得优异性能，并提高了推理效率和鲁棒性。

Abstract: Reasoning-oriented Large Language Models (LLMs) have achieved remarkable progress with Chain-of-Thought (CoT) prompting, yet they remain fundamentally limited by a \emph{blind self-thinking} paradigm: performing extensive internal reasoning even when critical information is missing or ambiguous. We propose Proactive Interactive Reasoning (PIR), a new reasoning paradigm that transforms LLMs from passive solvers into proactive inquirers that interleave reasoning with clarification. Unlike existing search- or tool-based frameworks that primarily address knowledge uncertainty by querying external environments, PIR targets premise- and intent-level uncertainty through direct interaction with the user. PIR is implemented via two core components: (1) an uncertainty-aware supervised fine-tuning procedure that equips models with interactive reasoning capability, and (2) a user-simulator-based policy optimization framework driven by a composite reward that aligns model behavior with user intent. Extensive experiments on mathematical reasoning, code generation, and document editing demonstrate that PIR consistently outperforms strong baselines, achieving up to 32.70\% higher accuracy, 22.90\% higher pass rate, and 41.36 BLEU improvement, while reducing nearly half of the reasoning computation and unnecessary interaction turns. Further reliability evaluations on factual knowledge, question answering, and missing-premise scenarios confirm the strong generalization and robustness of PIR. Model and code are publicly available at: \href{https://github.com/SUAT-AIRI/Proactive-Interactive-R1}

</details>


### [270] [FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale](https://arxiv.org/abs/2601.22146)
*Ajay Patel,Colin Raffel,Chris Callison-Burch*

Main category: cs.CL

TL;DR: 本研究提出了一种名为FineInstructions的数据集生成方法，利用预训练语料库中的非结构化文本和用户查询生成大规模的合成指令-回答对，从而克服了监督数据不足的问题，并证明了该方法在LLM从头预训练方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于LLM预训练中监督数据有限，导致模型难以有效响应用户指令。本研究旨在通过大规模合成数据来弥补这一不足，使LLM能够更好地适应下游应用。

Method: 利用~18M的指令模板（源于真实用户查询）与非结构化预训练语料库中的人类撰写文档匹配，生成大规模的合成指令-回答对。然后，使用这些合成数据从头开始预训练LLM，仅使用指令调整目标。

Result: 在 token-for-token 的受控训练实验中，使用FineInstructions进行预训练的LLM，在衡量自由形式响应质量的标准基准测试中，优于标准的预训练方法和其他合成预训练技术。

Conclusion: 大规模合成指令-回答训练数据对于LLM从头开始的预训练至关重要，并且在预训练阶段仅使用指令调整目标比标准方法更有效，生成的模型在响应用户指令方面表现更好。

Abstract: Due to limited supervised training data, large language models (LLMs) are typically pre-trained via a self-supervised "predict the next word" objective on a vast amount of unstructured text data. To make the resulting model useful to users, it is further trained on a far smaller amount of "instruction-tuning" data comprised of supervised training examples of instructions and responses. To overcome the limited amount of supervised data, we propose a procedure that can transform the knowledge in internet-scale pre-training documents into billions of synthetic instruction and answer training pairs. The resulting dataset, called FineInstructions, uses ~18M instruction templates created from real user-written queries and prompts. These instruction templates are matched to and instantiated with human-written source documents from unstructured pre-training corpora. With "supervised" synthetic training data generated at this scale, an LLM can be pre-trained from scratch solely with the instruction-tuning objective, which is far more in-distribution with the expected downstream usage of LLMs (responding to user prompts). We conduct controlled token-for-token training experiments and find pre-training on FineInstructions outperforms standard pre-training and other proposed synthetic pre-training techniques on standard benchmarks measuring free-form response quality. Our resources can be found at https://huggingface.co/fineinstructions .

</details>


### [271] [VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning](https://arxiv.org/abs/2601.22069)
*Yibo Wang,Yongcheng Jing,Shunyu Liu,Hao Guan,Rong-cheng Tu,Chengyu Wang,Jun Huang,Dacheng Tao*

Main category: cs.CL

TL;DR: 本文提出了一种名为VTC-R1的新型高效长上下文推理范式，它将视觉-文本压缩集成到推理过程中，通过将中间推理片段渲染成图像作为“光学记忆”来减少token数量，从而在保持性能的同时显著提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文推理方法存在效率低下问题，而现有高效方法需要额外训练或使用外部模型进行压缩，这限制了可扩展性并可能丢失精细信息。因此，需要一种更有效且可扩展的推理范式。

Method: VTC-R1将中间推理片段渲染成紧凑的图像，并将这些图像迭代地作为“光学记忆”输入到视觉-语言模型中。在OpenR1-Math-220K数据集上构建训练集，并在VLMs-Glyph和Qwen3-VL模型上进行微调。

Result: VTC-R1在MATH500、AIME25、AMC23和GPQA-D等基准测试中，实现了3.4倍的token压缩，并显著优于标准长上下文推理。同时，推理效率提高了2.7倍，端到端延迟降低。

Conclusion: VTC-R1是一种集成视觉-文本压缩的高效推理范式，能够有效处理长上下文推理任务，显著提高推理速度和效率，为推理密集型应用提供了一个可扩展的解决方案。

Abstract: Long-context reasoning has significantly empowered large language models (LLMs) to tackle complex tasks, yet it introduces severe efficiency bottlenecks due to the computational complexity. Existing efficient approaches often rely on complex additional training or external models for compression, which limits scalability and discards critical fine-grained information. In this paper, we propose VTC-R1, a new efficient reasoning paradigm that integrates vision-text compression into the reasoning process. Instead of processing lengthy textual traces, VTC-R1 renders intermediate reasoning segments into compact images, which are iteratively fed back into vision-language models as "optical memory." We construct a training dataset based on OpenR1-Math-220K achieving 3.4x token compression and fine-tune representative VLMs-Glyph and Qwen3-VL. Extensive experiments on benchmarks such as MATH500, AIME25, AMC23 and GPQA-D demonstrate that VTC-R1 consistently outperforms standard long-context reasoning. Furthermore, our approach significantly improves inference efficiency, achieving 2.7x speedup in end-to-end latency, highlighting its potential as a scalable solution for reasoning-intensive applications. Our code is available at https://github.com/w-yibo/VTC-R1.

</details>


### [272] [Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts](https://arxiv.org/abs/2601.22156)
*Yingfa Chen,Zhen Leng Thai,Zihan Zhou,Zhu Zhang,Xingyu Shen,Shuo Wang,Chaojun Xiao,Xu Han,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 本研究提出了一种名为HALO的管道，用于将Transformer模型蒸馏成混合RNN-注意力模型（HypeNet），并引入了新的位置编码方案HyPE。实验证明，通过HALO和HyPE，Qwen3系列模型可以高效地转化为HypeNet，性能与原Transformer模型相当，同时在长上下文建模方面表现更优，且所需训练数据量远少于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的混合Transformer架构（结合softmax attention和RNN）在长上下文建模方面具有性能-吞吐量的优势，但从头开始预训练成本高昂。现有的参数迁移和知识蒸馏方法需要大量训练数据，且蒸馏后的模型在长上下文任务上性能不佳。因此，研究动机是寻找一种更高效、数据需求更少的方法来将Transformer蒸馏成表现优异的长上下文混合模型。

Method: 研究提出了HALO（Hybrid Attention via Layer Optimization）管道，用于将Transformer模型蒸馏成RNN-注意力混合模型。同时，设计了HypeNet架构，该架构结合了新的位置编码方案HyPE以及其他架构修改，以增强长度泛化能力。最后，使用HALO将Qwen3系列模型转换为HypeNet。

Result: 通过HALO和HyPE，将Qwen3系列模型转换为HypeNet后，在性能上可与原Transformer模型媲美。HypeNet表现出优越的长上下文性能和效率。转换过程仅需2.3B tokens，远少于Qwen3系列模型的预训练数据量（<0.01%）。

Conclusion: HALO管道和HypeNet架构（包括HyPE位置编码）能够有效地将Transformer模型蒸馏成高效且长上下文性能优越的混合RNN-注意力模型，且数据效率远高于现有技术。

Abstract: Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RNN blocks through parameter transfer and knowledge distillation. However, these transfer methods require substantial amounts of training data (more than 10B tokens), and the resulting hybrid models also exhibit poor long-context performance, which is the scenario where hybrid models enjoy significant inference speedups over Transformer-based models. In this paper, we present HALO (Hybrid Attention via Layer Optimization), a pipeline for distilling Transformer models into RNN-attention hybrid models. We then present HypeNet, a hybrid architecture with superior length generalization enabled by a novel position encoding scheme (named HyPE) and various architectural modifications. We convert the Qwen3 series into HypeNet using HALO, achieving performance comparable to the original Transformer models while enjoying superior long-context performance and efficiency. The conversion requires just 2.3B tokens, less than 0.01% of their pre-training data

</details>


### [273] [DynaWeb: Model-Based Reinforcement Learning of Web Agents](https://arxiv.org/abs/2601.22149)
*Hang Ding,Peidong Liu,Junqiao Wang,Ziwei Ji,Meng Cao,Rongzhao Zhang,Lynn Ai,Eric Yang,Tianyu Shi,Lei Yu*

Main category: cs.CL

TL;DR: 本文提出了一种名为 DynaWeb 的基于模型的强化学习框架，通过训练一个预测网页表示的世界模型，实现在模拟环境中训练网页智能体，提高了训练效率和样本效率，并在 WebArena 和 WebVoyager 基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 训练自主网络智能体（由 LLM 和 RL 驱动）面临与真实互联网交互效率低、成本高且风险大的挑战。基于模型的强化学习 (MBRL) 通过学习环境的世界模型来解决这一问题，可以在模拟环境中进行交互。

Method: DynaWeb 是一个 MBRL 框架，通过训练一个网页世界模型来预测智能体动作后的网页表示。这个模型充当合成的网页环境，智能体策略可以在其中“梦想”并生成大量的轨迹以进行高效的在线强化学习。此外，DynaWeb 还混合了来自训练数据的专家轨迹，以提高训练的稳定性和样本效率。

Result: 在 WebArena 和 WebVoyager 基准测试中，DynaWeb 显著且持续地提高了最先进的开源网页智能体模型的性能。

Conclusion: DynaWeb 证明了通过“想象”来训练网页智能体的可行性，为扩大在线智能体 RL 的规模提供了一种可扩展且高效的方法。

Abstract: The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a promising solution by learning a world model of the environment to enable simulated interaction. This paper introduces DynaWeb, a novel MBRL framework that trains web agents through interacting with a web world model trained to predict naturalistic web page representations given agent actions. This model serves as a synthetic web environment where an agent policy can dream by generating vast quantities of rollout action trajectories for efficient online reinforcement learning. Beyond free policy rollouts, DynaWeb incorporates real expert trajectories from training data, which are randomly interleaved with on-policy rollouts during training to improve stability and sample efficiency. Experiments conducted on the challenging WebArena and WebVoyager benchmarks demonstrate that DynaWeb consistently and significantly improves the performance of state-of-the-art open-source web agent models. Our findings establish the viability of training web agents through imagination, offering a scalable and efficient way to scale up online agentic RL.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [274] [Quick Heuristic Validation of Edges in Dynamic Roadmap Graphs](https://arxiv.org/abs/2601.20968)
*Yulie Arad,Stav Ashur,Nancy M. Amato*

Main category: cs.RO

TL;DR: 提出了一种名为“红绿灰”的范式，用于在非静态环境中调整机器人运动规划的路线图。该方法通过启发式检查快速更新节点和边的有效性状态，并使用计算几何方法近似机器人的扫掠体积进行懒惰碰撞检测，将边标记为无效（红）、有效（绿）或未知（灰）。


<details>
  <summary>Details</summary>
Motivation: 解决在非静态环境中调整机器人运动规划的路线图的问题，需要一种能够快速更新和准确评估节点/边有效性的方法。

Method: 提出“红绿灰”范式，修改SPITE方法，通过启发式检查为节点和边分配有效性状态（红、绿、灰）。使用计算几何方法近似机器人的扫掠体积，进行懒惰碰撞检测。

Result: 与Leven和Hutchinson的方法相比，该方法提高了准确性，能够正确标记无效边，同时保持可比的更新运行时间。

Conclusion: “红绿灰”范式能够有效地在非静态环境中进行半懒惰的路线图更新，提高了准确性，并能在保持相似运行时间的情况下正确识别无效路径。

Abstract: In this paper we tackle the problem of adjusting roadmap graphs for robot motion planning to non-static environments. We introduce the "Red-Green-Gray" paradigm, a modification of the SPITE method, capable of classifying the validity status of nodes and edges using cheap heuristic checks, allowing fast semi-lazy roadmap updates. Given a roadmap, we use simple computational geometry methods to approximate the swept volumes of robots and perform lazy collision checks, and label a subset of the edges as invalid (red), valid (green), or unknown (gray). We present preliminary experimental results comparing our method to the well-established technique of Leven and Hutchinson, and showing increased accuracy as well as the ability to correctly label edges as invalid while maintaining comparable update runtimes.

</details>


### [275] [Meta-ROS: A Next-Generation Middleware Architecture for Adaptive and Scalable Robotic Systems](https://arxiv.org/abs/2601.21011)
*Anshul Ranjan,Anoosh Damodar,Neha Chougule,Dhruva S Nayak,Anantharaman P. N,Shylaja S S*

Main category: cs.RO

TL;DR: Meta-ROS是一个新的机器人中间件，旨在通过简化集成、提高性能和确保跨平台兼容性来优化机器人开发。它通过使用Zenoh和ZeroMQ等现代通信协议，在各种硬件平台上实现高效的低延迟通信，并且性能优于ROS2。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人中间件（如ROS2）在复杂性和互操作性方面存在挑战，对新开发者不友好。

Method: 提出Meta-ROS中间件，利用Zenoh和ZeroMQ等现代通信协议，支持音频、图像和视频等多种数据类型，并与ROS1和ROS2进行性能对比测试。

Result: Meta-ROS在吞吐量方面比ROS2高30%，显著降低了消息延迟，并优化了资源使用。此外，它还支持强大的硬件和以开发者为中心的设计。

Conclusion: Meta-ROS通过提高性能、简化集成和增强易用性，成为现代实时机器人AI应用的理想解决方案。

Abstract: The field of robotics faces significant challenges related to the complexity and interoperability of existing middleware frameworks, like ROS2, which can be difficult for new developers to adopt. To address these issues, we propose Meta-ROS, a novel middleware solution designed to streamline robotics development by simplifying integration, enhancing performance, and ensuring cross-platform compatibility. Meta-ROS leverages modern communication protocols, such as Zenoh and ZeroMQ, to enable efficient and low-latency communication across diverse hardware platforms, while also supporting various data types like audio, images, and video. We evaluated Meta-ROS's performance through comprehensive testing, comparing it with existing middleware frameworks like ROS1 and ROS2. The results demonstrated that Meta-ROS outperforms ROS2, achieving up to 30% higher throughput, significantly reducing message latency, and optimizing resource usage. Additionally, its robust hardware support and developer-centric design facilitate seamless integration and ease of use, positioning Meta-ROS as an ideal solution for modern, real-time robotics AI applications.

</details>


### [276] [Track-centric Iterative Learning for Global Trajectory Optimization in Autonomous Racing](https://arxiv.org/abs/2601.21027)
*Youngim Nam,Jungbin Kim,Kyungtae Kang,Cheolhyeon Kwon*

Main category: cs.RO

TL;DR: 该论文提出了一个全局轨迹优化框架，用于在车辆动力学不确定的情况下最小化自动赛车的单圈时间。通过在轨迹参数空间中使用小波变换，并结合贝叶斯优化进行轨迹探索，同时在一个迭代学习框架中利用真实世界数据更新动力学模型，从而不断优化轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要集中在跟踪层面的动力学学习，而没有更新轨迹本身来适应学习到的动力学。而直接优化全局轨迹在计算上成本很高，且在真实世界中难以保证全局最优。

Method: 提出了一种以赛道为中心的轨迹优化方法。首先，利用小波变换将轨迹表示在一个与赛道无关的参数空间中。然后，使用贝叶斯优化在该参数空间中进行高效探索，并通过模拟学习到的动力学来评估每个候选轨迹的单圈时间。该优化过程被嵌入到一个迭代学习框架中，通过部署优化后的轨迹收集真实世界数据来更新动力学模型，并逐步优化轨迹。

Result: 在模拟和真实世界实验中，该框架将单圈时间提高了高达20.7%，并持续优于现有最先进的方法。

Conclusion: 该研究成功地提出了一种能够直接学习和优化全局轨迹的框架，有效地解决了在不确定动力学下自动赛车最小化单圈时间的挑战，并在实际应用中取得了显著的性能提升。

Abstract: This paper presents a global trajectory optimization framework for minimizing lap time in autonomous racing under uncertain vehicle dynamics. Optimizing the trajectory over the full racing horizon is computationally expensive, and tracking such a trajectory in the real world hardly assures global optimality due to uncertain dynamics. Yet, existing work mostly focuses on dynamics learning at the tracking level, without updating the trajectory itself to account for the learned dynamics. To address these challenges, we propose a track-centric approach that directly learns and optimizes the full-horizon trajectory. We first represent trajectories through a track-agnostic parametric space in light of the wavelet transform. This space is then efficiently explored using Bayesian optimization, where the lap time of each candidate is evaluated by running simulations with the learned dynamics. This optimization is embedded in an iterative learning framework, where the optimized trajectory is deployed to collect real-world data for updating the dynamics, progressively refining the trajectory over the iterations. The effectiveness of the proposed framework is validated through simulations and real-world experiments, demonstrating lap time improvement of up to 20.7% over a nominal baseline and consistently outperforming state-of-the-art methods.

</details>


### [277] [WheelArm-Sim: A Manipulation and Navigation Combined Multimodal Synthetic Data Generation Simulator for Unified Control in Assistive Robotics](https://arxiv.org/abs/2601.21129)
*Guangping Liu,Tipu Sultan,Vittorio Di Giorgio,Nick Hawkins,Flavio Esposito,Madi Babaiasl*

Main category: cs.RO

TL;DR: 本文提出了一种集成轮椅和机械臂的控制概念WheelArm，并开发了一个名为WheelArm-Sim的仿真框架，用于收集用于训练机器学习模型的数据，以实现集成控制。


<details>
  <summary>Details</summary>
Motivation: 尽管轮椅和机械臂在辅助残障人士生活方面取得了进展，但将两者集成并使用机器学习进行统一控制的研究尚不充分。

Method: 开发了一个名为WheelArm-Sim的仿真框架，该框架基于Isaac Sim，用于收集包含操作和导航的多模态数据集。数据集涵盖了13个任务、232条轨迹和67,783个样本。利用该数据集实现了一个基线模型，用于预测芥末拾取任务中的动作。

Result: 从WheelArm-Sim收集的数据集能够支持数据驱动的机器学习模型，用于实现集成控制。在芥末拾取任务中，基线模型的预测结果显示了可行性。

Conclusion: WheelArm-Sim仿真框架能够有效收集用于开发集成轮椅和机械臂控制的机器学习模型的数据，为实现更自主的辅助机器人系统奠定了基础。

Abstract: Wheelchairs and robotic arms enhance independent living by assisting individuals with upper-body and mobility limitations in their activities of daily living (ADLs). Although recent advancements in assistive robotics have focused on Wheelchair-Mounted Robotic Arms (WMRAs) and wheelchairs separately, integrated and unified control of the combination using machine learning models remains largely underexplored. To fill this gap, we introduce the concept of WheelArm, an integrated cyber-physical system (CPS) that combines wheelchair and robotic arm controls. Data collection is the first step toward developing WheelArm models. In this paper, we present WheelArm-Sim, a simulation framework developed in Isaac Sim for synthetic data collection. We evaluate its capability by collecting a manipulation and navigation combined multimodal dataset, comprising 13 tasks, 232 trajectories, and 67,783 samples. To demonstrate the potential of the WheelArm dataset, we implement a baseline model for action prediction in the mustard-picking task. The results illustrate that data collected from WheelArm-Sim is feasible for a data-driven machine learning model for integrated control.

</details>


### [278] [InspecSafe-V1: A Multimodal Benchmark for Safety Assessment in Industrial Inspection Scenarios](https://arxiv.org/abs/2601.21173)
*Zeyi Liu,Shuang Liu,Jihai Min,Zhaoheng Zhang,Jun Cen,Pengyu Han,Songqiao Hu,Zihan Meng,Xiao He,Donghua Zhou*

Main category: cs.RO

TL;DR: InspecSafe-V1是一个首个针对工业检查安全评估的多模态基准数据集，包含真实场景、真实机器人操作下的数据，支持像素级分割、语义描述、安全等级标签以及多种传感模态，以解决现有数据集的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有工业数据集在模拟数据、单一传感模态或缺乏细粒度对象标注方面存在局限，阻碍了工业领域AI系统的可靠感知、安全评估、场景理解和多模态推理，从而影响了预测性维护和自主检查的部署。

Method: 在真实世界环境中，使用41个轮式和导轨式检查机器人，在5个代表性工业场景（隧道、电力设施、烧结设备、油气石化厂、煤炭输送架）的2,239个有效检查点进行了数据采集。为每个检查实例提供了可见光图像的像素级分割标注、语义场景描述和安全等级标签。此外，还同步采集了红外视频、音频、深度点云、雷达点云、气体测量、温度和湿度等七种传感模态的数据。

Result: 构建了一个包含5,013个检查实例的InspecSafe-V1数据集。数据覆盖了多种工业场景和机器人类型，并提供了丰富的标注信息（像素级分割、语义描述、安全等级）以及多模态传感器数据，支持细粒度的工业场景理解和多模态安全评估。

Conclusion: InspecSafe-V1数据集的发布填补了工业检查安全评估领域多模态基准数据集的空白，为开发更鲁棒的工业AI系统提供了宝贵的资源，能够支持多模态异常识别、跨模态融合和全面的工业环境安全评估。

Abstract: With the rapid development of industrial intelligence and unmanned inspection, reliable perception and safety assessment for AI systems in complex and dynamic industrial sites has become a key bottleneck for deploying predictive maintenance and autonomous inspection. Most public datasets remain limited by simulated data sources, single-modality sensing, or the absence of fine-grained object-level annotations, which prevents robust scene understanding and multimodal safety reasoning for industrial foundation models. To address these limitations, InspecSafe-V1 is released as the first multimodal benchmark dataset for industrial inspection safety assessment that is collected from routine operations of real inspection robots in real-world environments. InspecSafe-V1 covers five representative industrial scenarios, including tunnels, power facilities, sintering equipment, oil and gas petrochemical plants, and coal conveyor trestles. The dataset is constructed from 41 wheeled and rail-mounted inspection robots operating at 2,239 valid inspection sites, yielding 5,013 inspection instances. For each instance, pixel-level segmentation annotations are provided for key objects in visible-spectrum images. In addition, a semantic scene description and a corresponding safety level label are provided according to practical inspection tasks. Seven synchronized sensing modalities are further included, including infrared video, audio, depth point clouds, radar point clouds, gas measurements, temperature, and humidity, to support multimodal anomaly recognition, cross-modal fusion, and comprehensive safety assessment in industrial environments.

</details>


### [279] [Multi-Robot Decentralized Collaborative SLAM in Planetary Analogue Environments: Dataset, Challenges, and Lessons Learned](https://arxiv.org/abs/2601.21063)
*Pierre-Yves Lajoie,Karthik Soma,Haechan Mark Bong,Alice Lemieux-Bourque,Rongge Zhang,Vivek Shankar Varadharajan,Giovanni Beltrame*

Main category: cs.RO

TL;DR: 本文分享了在模拟火星地形上进行三机器人分布式协同SLAM（C-SLAM）实验的经验和教训，重点关注有限和间歇性通信对C-SLAM性能以及行星类环境带来的独特定位挑战的影响，并发布了一个新的数据集以支持未来研究。


<details>
  <summary>Details</summary>
Motivation: 推动多机器人任务在未知环境中无需预先存在的定位和通信基础设施的运行，特别是在月球、火星和其他行星的探索中，C-SLAM是关键技术。

Method: 在模拟火星地形上，使用三个机器人，通过自组织网络进行通信，进行了分布式协同SLAM实验。分析了通信限制和间歇性通信对C-SLAM性能的影响，以及行星类环境的定位挑战。收集了一个包含实时通信吞吐量和延迟测量的新数据集。

Result: 实验揭示了有限和间歇性通信对C-SLAM性能的显著影响，并突出了行星类环境的独特定位挑战。新数据集提供了通信受限的多机器人操作的研究基础。

Conclusion: 分布式协同SLAM在多机器人行星探索任务中至关重要，但通信限制和环境特性是关键挑战。发布的新数据集将有助于推动该领域的研究进展。

Abstract: Decentralized collaborative simultaneous localization and mapping (C-SLAM) is essential to enable multirobot missions in unknown environments without relying on preexisting localization and communication infrastructure. This technology is anticipated to play a key role in the exploration of the Moon, Mars, and other planets. In this article, we share insights and lessons learned from C-SLAM experiments involving three robots operating on a Mars analogue terrain and communicating over an ad hoc network. We examine the impact of limited and intermittent communication on C-SLAM performance, as well as the unique localization challenges posed by planetary-like environments. Additionally, we introduce a novel dataset collected during our experiments, which includes real-time peer-to-peer inter-robot throughput and latency measurements. This dataset aims to support future research on communication-constrained, decentralized multirobot operations.

</details>


### [280] [Disturbance-Aware Flight Control of Robotic Gliding Blimp via Moving Mass Actuation](https://arxiv.org/abs/2601.21188)
*Hao Cheng,Feitian Zhang*

Main category: cs.RO

TL;DR: 提出了一种结合移动视界估计器（MHE）和模型预测控制器（MPC）的控制框架，用于补偿机器人飞艇在风扰动下的姿态和航向控制，并在实验中验证了其优于PID控制的性能。


<details>
  <summary>Details</summary>
Motivation: 现有轻于空气（LTA）平台的控制框架缺乏对风扰动的感知和补偿能力，导致其在风中易受干扰影响，而移动质量驱动技术为解决此问题提供了可能。

Method: 利用移动视界估计器（MHE）实时估计风扰动，并将估计结果输入模型预测控制器（MPC），以实现对飞艇轨迹和航向的鲁棒控制。飞艇采用两自由度（2-DoF）移动质量机制来产生惯性和气动弯矩，以增强飞行稳定性。

Result: 所提出的MHE-MPC集成框架在有风（顺风和侧风）条件下进行了广泛的飞行实验，结果表明其在姿态和航向调节方面显著优于基线PID控制。

Conclusion: MHE-MPC集成框架能够有效感知和补偿风扰动，为LTA平台提供了鲁棒的轨迹和航向控制能力，在易受扰动的环境中表现出色。

Abstract: Robotic blimps, as lighter-than-air (LTA) aerial systems, offer long endurance and inherently safe operation but remain highly susceptible to wind disturbances. Building on recent advances in moving mass actuation, this paper addresses the lack of disturbance-aware control frameworks for LTA platforms by explicitly modeling and compensating for wind-induced effects. A moving horizon estimator (MHE) infers real-time wind perturbations and provides these estimates to a model predictive controller (MPC), enabling robust trajectory and heading regulation under varying wind conditions. The proposed approach leverages a two-degree-of-freedom (2-DoF) moving-mass mechanism to generate both inertial and aerodynamic moments for attitude and heading control, thereby enhancing flight stability in disturbance-prone environments. Extensive flight experiments under headwind and crosswind conditions show that the integrated MHE-MPC framework significantly outperforms baseline PID control, demonstrating its effectiveness for disturbance-aware LTA flight.

</details>


### [281] [Abstracting Robot Manipulation Skills via Mixture-of-Experts Diffusion Policies](https://arxiv.org/abs/2601.21251)
*Ce Hao,Xuanran Zhai,Yaohua Liu,Harold Soh*

Main category: cs.RO

TL;DR: 提出了一种名为SMP（Skill Mixture-of-Experts Policy）的扩散模型策略，通过学习紧凑的正交技能基础和采用粘性路由，以较低的计算成本实现了高效的多任务机器人操作。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散策略的机器人操作方法在扩展到多任务场景时，面临模型规模增大和演示数据成本高昂的挑战。

Method: SMP 采用一种混合专家（Mixture-of-Experts）的扩散模型架构，学习一个紧凑的正交技能基础，并利用粘性路由（sticky routing）在每一步从一小组与任务相关的专家中组合动作。通过变分训练目标和自适应专家激活，在推理时实现快速采样，而无需巨大的模型骨干。

Result: 在模拟和真实双臂平台上，SMP 在多任务学习和迁移学习任务中取得了更高的成功率，并且推理成本显著低于大型扩散基线模型。

Conclusion: SMP 提供了一种可扩展、可迁移的多任务机器人操作的实用方法：一次学习可重用的技能，仅激活所需的专家，并在任务变化时快速适应。

Abstract: Diffusion-based policies have recently shown strong results in robot manipulation, but their extension to multi-task scenarios is hindered by the high cost of scaling model size and demonstrations. We introduce Skill Mixture-of-Experts Policy (SMP), a diffusion-based mixture-of-experts policy that learns a compact orthogonal skill basis and uses sticky routing to compose actions from a small, task-relevant subset of experts at each step. A variational training objective supports this design, and adaptive expert activation at inference yields fast sampling without oversized backbones. We validate SMP in simulation and on a real dual-arm platform with multi-task learning and transfer learning tasks, where SMP achieves higher success rates and markedly lower inference cost than large diffusion baselines. These results indicate a practical path toward scalable, transferable multi-task manipulation: learn reusable skills once, activate only what is needed, and adapt quickly when tasks change.

</details>


### [282] [Deep QP Safety Filter: Model-free Learning for Reachability-based Safety Filter](https://arxiv.org/abs/2601.21297)
*Byeongjun Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 提出了一种名为Deep QP Safety Filter的纯数据驱动的安全层，用于黑盒动力学系统。该方法结合了HJ可达性和无模型学习，无需模型知识即可学习二次规划（QP）安全滤波器。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为黑盒动力学系统开发一种无需模型知识即可实现安全控制的方法，以减少学习过程中的失败并加速学习过程。

Method: 该方法结合了Hamilton-Jacobi (HJ) 可达性与无模型学习，通过构建用于安全值及其导数的收缩损失，并训练两个神经网络来实现。

Result: 在各种动力学系统（包括混合系统）和多个RL任务上，Deep QP Safety Filter显著减少了预收敛的失败，并比强大的基线更快地学习到更高的回报。

Conclusion: Deep QP Safety Filter 提供了一种原则性且实用的方法，可实现安全、无模型的控制，适用于黑盒动力学系统。

Abstract: We introduce Deep QP Safety Filter, a fully data-driven safety layer for black-box dynamical systems. Our method learns a Quadratic-Program (QP) safety filter without model knowledge by combining Hamilton-Jacobi (HJ) reachability with model-free learning. We construct contraction-based losses for both the safety value and its derivatives, and train two neural networks accordingly. In the exact setting, the learned critic converges to the viscosity solution (and its derivative), even for non-smooth values. Across diverse dynamical systems -- even including a hybrid system -- and multiple RL tasks, Deep QP Safety Filter substantially reduces pre-convergence failures while accelerating learning toward higher returns than strong baselines, offering a principled and practical route to safe, model-free control.

</details>


### [283] [HPTune: Hierarchical Proactive Tuning for Collision-Free Model Predictive Control](https://arxiv.org/abs/2601.21346)
*Wei Zuo,Chengyang Li,Yikun Wang,Bingyang Cheng,Zeyi Ren,Shuai Wang,Derrick Wing Kwan Ng,Yik-Chung Wu*

Main category: cs.RO

TL;DR: 提出了一种名为HPTune的分层主动调优框架，用于改进模型预测控制（MPC）运动规划器的参数调优。该框架通过评估已执行和未执行的动作，结合预测的关闭速度和接近距离风险指标，并利用一种扩展的闭环反向传播损失，从而实现高效的参数更新，特别是在避免碰撞和实现敏捷性方面。


<details>
  <summary>Details</summary>
Motivation: 现有的MPC参数调优方法主要基于已执行的动作，由于故障事件（如障碍物接近或碰撞）的稀疏性，导致参数更新效率低下。

Method: 提出了分层主动调优（HPTune）框架，包含一个快速调优和一个慢速调优。快速调优使用预测的关闭速度和预测的接近距离作为风险指标。慢速调优利用扩展的评估损失进行闭环反向传播。此外，将HPTune与多普勒激光雷达集成，以获取障碍物的速度信息，从而增强运动预测。

Result: HPTune能够高效地进行MPC调优，并在复杂环境中优于多种基线方案。实验证明HPTune能够通过制定安全的、敏捷的避碰策略来实现情况定制化的运动规划。

Conclusion: HPTune框架能够高效地为MPC运动规划器调整参数，并通过考虑未执行的动作和利用多普勒激光雷达的先进感知能力，实现更安全、更敏捷的运动规划。

Abstract: Parameter tuning is a powerful approach to enhance adaptability in model predictive control (MPC) motion planners. However, existing methods typically operate in a myopic fashion that only evaluates executed actions, leading to inefficient parameter updates due to the sparsity of failure events (e.g., obstacle nearness or collision). To cope with this issue, we propose to extend evaluation from executed to non-executed actions, yielding a hierarchical proactive tuning (HPTune) framework that combines both a fast-level tuning and a slow-level tuning. The fast one adopts risk indicators of predictive closing speed and predictive proximity distance, and the slow one leverages an extended evaluation loss for closed-loop backpropagation. Additionally, we integrate HPTune with the Doppler LiDAR that provides obstacle velocities apart from position-only measurements for enhanced motion predictions, thus facilitating the implementation of HPTune. Extensive experiments on high-fidelity simulator demonstrate that HPTune achieves efficient MPC tuning and outperforms various baseline schemes in complex environments. It is found that HPTune enables situation-tailored motion planning by formulating a safe, agile collision avoidance strategy.

</details>


### [284] [Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control](https://arxiv.org/abs/2601.21363)
*Weidong Huang,Zhehan Li,Hangxin Liu,Biao Hou,Yao Su,Jingwen Zhang*

Main category: cs.RO

TL;DR: 该研究提出了一种结合离策略强化学习（SAC）预训练和基于模型的强化学习微调的方法，用于人形机器人行走控制，实现了在模拟环境中大规模预训练和在真实环境中高效适应。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人控制方法，如PPO，虽然鲁棒性好，但样本效率低，难以安全地适应新环境。尽管离策略RL和基于模型的RL提高了样本效率，但大规模预训练与高效微调之间仍存在差距。

Method: 1. 使用离策略Soft Actor-Critic (SAC)算法，通过大批量更新和高更新到数据（UTD）比率，在模拟环境中对人形行走策略进行大规模预训练，实现零样本部署到真实机器人。
2. 在新环境适应时，采用基于模型的方法对预训练策略进行微调。数据收集使用确定性策略，而随机探索则限制在物理信息世界模型中进行，以降低风险并保持探索覆盖范围。
3. 整个方法结合了大规模模拟预训练的效率和基于模型学习微调的样本效率。

Result: SAC预训练的人形行走策略能够实现零样本部署到真实机器人。
预训练的策略可以通过基于模型的方法在新环境和分布外任务中进行有效微调。

Conclusion: 该研究提出的方法结合了SAC大规模预训练的效率和基于模型微调的样本效率，为人形机器人的行走控制提供了更有效和安全的解决方案，能够实现从大规模预训练到高效适应的良好衔接。

Abstract: Reinforcement learning (RL) is widely used for humanoid control, with on-policy methods such as Proximal Policy Optimization (PPO) enabling robust training via large-scale parallel simulation and, in some cases, zero-shot deployment to real robots. However, the low sample efficiency of on-policy algorithms limits safe adaptation to new environments. Although off-policy RL and model-based RL have shown improved sample efficiency, the gap between large-scale pretraining and efficient finetuning on humanoids still exists. In this paper, we find that off-policy Soft Actor-Critic (SAC), with large-batch update and a high Update-To-Data (UTD) ratio, reliably supports large-scale pretraining of humanoid locomotion policies, achieving zero-shot deployment on real robots. For adaptation, we demonstrate that these SAC-pretrained policies can be finetuned in new environments and out-of-distribution tasks using model-based methods. Data collection in the new environment executes a deterministic policy while stochastic exploration is instead confined to a physics-informed world model. This separation mitigates the risks of random exploration during adaptation while preserving exploratory coverage for improvement. Overall, the approach couples the wall-clock efficiency of large-scale simulation during pretraining with the sample efficiency of model-based learning during fine-tuning.

</details>


### [285] [Towards Space-Based Environmentally-Adaptive Grasping](https://arxiv.org/abs/2601.21394)
*Leonidas Askianakis,Aleksandr Artemov*

Main category: cs.RO

TL;DR: 本研究通过在太空环境中进行抓取任务，学习了一个在多模态融合的潜在空间中进行决策的控制策略，实现了高效的样本学习和鲁棒性，成功率超过95%，并且比现有技术收敛更快。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操纵系统在非结构化环境中，尤其是在高维动作空间、稀疏奖励和泛化能力方面存在局限性，尤其是在太空等极端环境下。

Method: 研究者将来自多模态的信息融合（语法化）到一个结构化的潜在空间中，然后利用基于Soft Actor-Critic (SAC)的强化学习算法在该潜在空间中学习控制策略。研究利用GPU加速的物理模拟器，在不断变化的抓取条件下进行单次操纵任务。

Result: 在不到100万次环境交互步骤中，研究实现的任务成功率超过95%，并且比同类先进的视觉基线方法在相同的开放循环单次条件下收敛更快。研究表明，在潜在空间中进行显式推理能够提高样本效率，并增强对新物体、夹具几何形状、环境杂乱以及传感器配置的鲁棒性。

Conclusion: 在潜在空间中进行显式推理是实现高效样本学习和提高机器人操纵鲁棒性的有效方法，尤其是在太空等极端环境下。尽管取得了显著进展，但仍需进一步研究以实现完全自适应和可泛化的抓取能力。

Abstract: Robotic manipulation in unstructured environments requires reliable execution under diverse conditions, yet many state-of-the-art systems still struggle with high-dimensional action spaces, sparse rewards, and slow generalization beyond carefully curated training scenarios. We study these limitations through the example of grasping in space environments. We learn control policies directly in a learned latent manifold that fuses (grammarizes) multiple modalities into a structured representation for policy decision-making. Building on GPU-accelerated physics simulation, we instantiate a set of single-shot manipulation tasks and achieve over 95% task success with Soft Actor-Critic (SAC)-based reinforcement learning in less than 1M environment steps, under continuously varying grasping conditions from step 1. This empirically shows faster convergence than representative state-of-the-art visual baselines under the same open-loop single-shot conditions. Our analysis indicates that explicitly reasoning in latent space yields more sample-efficient learning and improved robustness to novel object and gripper geometries, environmental clutter, and sensor configurations compared to standard baselines. We identify remaining limitations and outline directions toward fully adaptive and generalizable grasping in the extreme conditions of space.

</details>


### [286] [DSCD-Nav: Dual-Stance Cooperative Debate for Object Navigation](https://arxiv.org/abs/2601.21409)
*Weitao An,Qi Liu,Chenghao Xu,Jiayi Chai,Xu Yang,Kun Wei,Cheng Deng*

Main category: cs.RO

TL;DR: 提出了一种名为DSCD-Nav的双立场协同辩论导航机制，通过两种互补的评估视角（TSU 和 SIB）以及导航共识仲裁（NCA）来提高家庭服务机器人在未知室内环境中导航的可靠性，减少了过拟合错误和冗余探索。


<details>
  <summary>Details</summary>
Motivation: 现有导航系统依赖于单一的决策层评分，容易出现长期错误和冗余探索，尤其是在部分可观察的室内环境中。

Method: 提出DSCD-Nav机制，包含两个立场：任务-场景理解（TSU）和安全-信息平衡（SIB）。这两个立场协同辩论，通过交叉检查和基于线索的论证来做出策略。然后，导航共识仲裁（NCA）代理整合双方的论点和证据，并可选地进行微探测以验证不确定的选择。

Result: 在HM3Dv1、HM3Dv2和MP3D数据集上进行了实验，DSCD-Nav在成功率和路径效率方面均有显著提升，同时减少了探索的冗余性。

Conclusion: DSCD-Nav通过双立场协同辩论和仲裁机制，有效解决了现有导航方法中的不足，提高了机器人在未知室内环境中导航的鲁棒性和效率。

Abstract: Adaptive navigation in unfamiliar indoor environments is crucial for household service robots. Despite advances in zero-shot perception and reasoning from vision-language models, existing navigation systems still rely on single-pass scoring at the decision layer, leading to overconfident long-horizon errors and redundant exploration. To tackle these problems, we propose Dual-Stance Cooperative Debate Navigation (DSCD-Nav), a decision mechanism that replaces one-shot scoring with stance-based cross-checking and evidence-aware arbitration to improve action reliability under partial observability. Specifically, given the same observation and candidate action set, we explicitly construct two stances by conditioning the evaluation on diverse and complementary objectives: a Task-Scene Understanding (TSU) stance that prioritizes goal progress from scene-layout cues, and a Safety-Information Balancing (SIB) stance that emphasizes risk and information value. The stances conduct a cooperative debate and make policy by cross-checking their top candidates with cue-grounded arguments. Then, a Navigation Consensus Arbitration (NCA) agent is employed to consolidate both sides' reasons and evidence, optionally triggering lightweight micro-probing to verify uncertain choices, preserving NCA's primary intent while disambiguating. Experiments on HM3Dv1, HM3Dv2, and MP3D demonstrate consistent improvements in success and path efficiency while reducing exploration redundancy.

</details>


### [287] [Singularity-Free Lie Group Integration and Geometrically Consistent Evaluation of Multibody System Models Described in Terms of Standard Absolute Coordinates](https://arxiv.org/abs/2601.21413)
*Andreas Mueller*

Main category: cs.RO

TL;DR: 本文提出了一种将李群积分器与经典绝对坐标多体系统（MBS）方程相结合的框架，并提出了一种将刚体运动几何纳入绝对坐标方程的方案，以解决空间运动参数化奇点问题，并提高数值积分精度。


<details>
  <summary>Details</summary>
Motivation: 经典多体系统绝对坐标建模方法在处理空间运动时存在奇点问题，传统方法（如使用四元数）虽有所缓解但并非完美。李群积分方法在保持几何性质方面有优势，但与现有MBS仿真代码不兼容。因此，研究人员希望开发一种能够结合两种方法的通用框架。

Method: 文章提出了一个接口框架，允许在MBS中使用绝对坐标的同时，应用李群积分方案。此外，还提出了一种方法，将刚体运动的几何特性（使用SO(3)xR3或SE(3)群表示）一致地融入到使用标准向量空间积分方案的绝对坐标方程中。核心在于引入局部-全局过渡（LGT）映射，用于在李群上的局部坐标与全局绝对坐标之间进行更新。

Result: 文章开发了一个能够连接李群积分器和标准MBS绝对坐标方程的通用框架。该框架允许使用不同的绝对坐标系，并结合李群积分方法。同时，提出的几何信息整合方法能提高使用标准积分方案的绝对坐标方程的精度。

Conclusion: 本文成功地提出了一个框架，可以无缝地将李群积分方法集成到现有的多体系统绝对坐标仿真中，解决了标准积分方法的奇点问题，并提供了一种将刚体运动几何信息纳入绝对坐标方程的方法，从而有望提高仿真精度和鲁棒性。

Abstract: A classical approach to the multibody systems (MBS) modeling is to use absolute coordinates, i.e., a set of (possibly redundant) coordinates that describe the absolute position and orientation of the individual bodies with respect to an inertial frame (IFR). A well-known problem for the time integration of the equations of motion (EOM) is the lack of a singularity-free parameterization of spatial motions, which is usually tackled by using unit quaternions. Lie group integration methods were proposed as an alternative approach to the singularity-free time integration. At the same time, Lie group formulations of EOM naturally respect the geometry of spatial motions during integration. Lie group integration methods, operating directly on the configuration space Lie group, are incompatible with standard formulations of the EOM, and cannot be implemented in existing MBS simulation codes without a major restructuring. The contribution of this paper is twofold: (1) A framework for interfacing Lie group integrators to standard EOM formulations is presented. It allows describing MBS in terms of various absolute coordinates and at the same using Lie group integration schemes. (2) A method for consistently incorporating the geometry of rigid body motions into the evaluation of EOM in absolute coordinates integrated with standard vector space integration schemes. The direct product group and the semidirect product group SO(3)xR3 and the semidirect product group SE(3) are used for representing rigid body motions. The key element is the local-global transitions (LGT) transition map, which facilitates the update of (global) absolute coordinates in terms of the (local) coordinates on the Lie group. This LGT map is specific to the absolute coordinates, the local coordinates on the Lie group, and the Lie group used to represent rigid body configurations.

</details>


### [288] [Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation](https://arxiv.org/abs/2601.21416)
*Alexandre Chapin,Bruno Machado,Emmanuel Dellandréa,Liming Chen*

Main category: cs.RO

TL;DR: 本研究提出了一种名为 SBOCR 的新型视觉表征方法，用于提升机器人操作策略的泛化能力。SBOCR 将密集特征聚类成有限的类对象实体，优于现有的全局和密集特征提取方法，在模拟和真实世界任务中表现出更强的泛化能力，尤其是在光照、纹理和干扰物变化等分布变化下。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作策略依赖预训练编码器提取的视觉表征（全局特征或密集特征），但这些特征混合了任务相关和无关信息，导致在光照、纹理或干扰物变化等分布变化下泛化能力较差。因此，需要一种新的视觉表征方法来提升泛化能力。

Method: 提出了一种中间结构的、基于对象的表征方法——SBOCR（Slot-Based Object-Centric Representations）。SBOCR 将密集特征聚类成有限的类对象实体，以减少噪声并保留足够的信息。研究人员将 SBOCR 与全局和密集表征进行比较，并在模拟和真实世界的机器人操作任务中进行了基准测试，评估了它们在不同视觉条件下的泛化能力。

Result: SBOCR-based 策略在泛化设置下优于基于密集和全局表征的策略，即使没有针对任务进行特定预训练。这表明 SBOCR 在应对动态、真实世界机器人环境中的视觉泛化方面具有优势。

Conclusion: SBOCR 是一种有前景的视觉表征方法，能够显著提升机器人操作策略在分布变化下的泛化能力，为设计更具鲁棒性的机器人视觉系统提供了方向。

Abstract: The generalization capabilities of robotic manipulation policies are heavily influenced by the choice of visual representations. Existing approaches typically rely on representations extracted from pre-trained encoders, using two dominant types of features: global features, which summarize an entire image via a single pooled vector, and dense features, which preserve a patch-wise embedding from the final encoder layer. While widely used, both feature types mix task-relevant and irrelevant information, leading to poor generalization under distribution shifts, such as changes in lighting, textures, or the presence of distractors. In this work, we explore an intermediate structured alternative: Slot-Based Object-Centric Representations (SBOCR), which group dense features into a finite set of object-like entities. This representation permits to naturally reduce the noise provided to the robotic manipulation policy while keeping enough information to efficiently perform the task. We benchmark a range of global and dense representations against intermediate slot-based representations, across a suite of simulated and real-world manipulation tasks ranging from simple to complex. We evaluate their generalization under diverse visual conditions, including changes in lighting, texture, and the presence of distractors. Our findings reveal that SBOCR-based policies outperform dense and global representation-based policies in generalization settings, even without task-specific pretraining. These insights suggest that SBOCR is a promising direction for designing visual systems that generalize effectively in dynamic, real-world robotic environments.

</details>


### [289] [Nimbus: A Unified Embodied Synthetic Data Generation Framework](https://arxiv.org/abs/2601.21449)
*Zeyu He,Yuchang Zhang,Yuanzhen Zhou,Miao Tao,Hengjie Li,Yang Tian,Jia Zeng,Tai Wang,Wenzhe Cai,Yilun Chen,Ning Gao,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 本文提出Nimbus，一个统一的合成数据生成框架，通过模块化架构和异步执行模型，解决了现有合成数据生成流程碎片化和任务特定的问题，提高了数据生成效率和稳定性，支持大规模分布式环境下的长期运行，并已成功应用于InternData套件。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据生成流程碎片化、任务特定，工程效率低下且系统不稳定，无法支持基础模型训练所需的高通量数据生成。

Method: 提出Nimbus，一个四层模块化架构的统一合成数据生成框架。采用解耦的执行模型，将轨迹规划、渲染和存储分离为异步阶段。通过动态管道调度、全局负载均衡、分布式容错和后端特定渲染优化来最大化CPU、GPU和I/O资源利用率。

Result: Nimbus相比未优化基线实现了2-3倍的端到端吞吐量提升，并能在大规模分布式环境中实现稳健的长期运行。

Conclusion: Nimbus是一个统一的合成数据生成框架，通过改进的架构和优化技术，显著提高了数据生成效率和系统稳定性，为大规模跨领域数据合成提供了生产级支持。

Abstract: Scaling data volume and diversity is critical for generalizing embodied intelligence. While synthetic data generation offers a scalable alternative to expensive physical data acquisition, existing pipelines remain fragmented and task-specific. This isolation leads to significant engineering inefficiency and system instability, failing to support the sustained, high-throughput data generation required for foundation model training. To address these challenges, we present Nimbus, a unified synthetic data generation framework designed to integrate heterogeneous navigation and manipulation pipelines. Nimbus introduces a modular four-layer architecture featuring a decoupled execution model that separates trajectory planning, rendering, and storage into asynchronous stages. By implementing dynamic pipeline scheduling, global load balancing, distributed fault tolerance, and backend-specific rendering optimizations, the system maximizes resource utilization across CPU, GPU, and I/O resources. Our evaluation demonstrates that Nimbus achieves a 2-3X improvement in end-to-end throughput compared to unoptimized baselines and ensuring robust, long-term operation in large-scale distributed environments. This framework serves as the production backbone for the InternData suite, enabling seamless cross-domain data synthesis.

</details>


### [290] [4D-CAAL: 4D Radar-Camera Calibration and Auto-Labeling for Autonomous Driving](https://arxiv.org/abs/2601.21454)
*Shanliang Yao,Zhuoxiao Li,Runwei Guan,Kebin Cao,Meng Xia,Fuping Hu,Sen Xu,Yong Yue,Xiaohui Zhu,Weiping Ding,Ryan Wen Liu*

Main category: cs.RO

TL;DR: 本文提出了一种名为4D-CAAL的统一框架，用于4D雷达-相机外参标定和自动标注，通过设计一种兼顾相机和雷达检测的联合标定目标，并开发相应的匹配算法，实现了高精度的标定，并能将相机标注自动迁移到雷达点云，加速了自动驾驶多模态感知系统的开发。


<details>
  <summary>Details</summary>
Motivation: 现有4D雷达-相机标定方法使用独立的标定目标，增加了对应关系建立的复杂性；手动标注稀疏的雷达数据耗时且不可靠。因此，需要一种统一的框架来解决这些挑战。

Method: 提出了一种名为4D-CAAL的统一框架。该框架设计了一种新型双用途标定目标，正面用于相机检测（棋盘格），背面中心用于雷达检测（角反射器）。开发了将棋盘格中心与最强雷达反射点对齐的鲁棒匹配算法，实现外参标定。随后，利用标定后的传感器关系，通过几何投影和多特征优化，将相机分割的标注自动迁移到雷达点云。

Result: 实验证明，该方法能够实现高精度的标定，并显著减少手动标注工作量。

Conclusion: 4D-CAAL框架能够有效地实现4D雷达-相机外参标定和自动标注，加速了自动驾驶多模态感知系统的开发。

Abstract: 4D radar has emerged as a critical sensor for autonomous driving, primarily due to its enhanced capabilities in elevation measurement and higher resolution compared to traditional 3D radar. Effective integration of 4D radar with cameras requires accurate extrinsic calibration, and the development of radar-based perception algorithms demands large-scale annotated datasets. However, existing calibration methods often employ separate targets optimized for either visual or radar modalities, complicating correspondence establishment. Furthermore, manually labeling sparse radar data is labor-intensive and unreliable. To address these challenges, we propose 4D-CAAL, a unified framework for 4D radar-camera calibration and auto-labeling. Our approach introduces a novel dual-purpose calibration target design, integrating a checkerboard pattern on the front surface for camera detection and a corner reflector at the center of the back surface for radar detection. We develop a robust correspondence matching algorithm that aligns the checkerboard center with the strongest radar reflection point, enabling accurate extrinsic calibration. Subsequently, we present an auto-labeling pipeline that leverages the calibrated sensor relationship to transfer annotations from camera-based segmentations to radar point clouds through geometric projection and multi-feature optimization. Extensive experiments demonstrate that our method achieves high calibration accuracy while significantly reducing manual annotation effort, thereby accelerating the development of robust multi-modal perception systems for autonomous driving.

</details>


### [291] [DexTac: Learning Contact-aware Visuotactile Policies via Hand-by-hand Teaching](https://arxiv.org/abs/2601.21474)
*Xingyu Zhang,Chaofan Zhang,Boyue Zhang,Zhinan Peng,Shaowei Cui,Shuo Wang*

Main category: cs.RO

TL;DR: 提出了一种名为 DexTac 的视觉-触觉操纵学习框架，它能从人类演示中捕获多维触觉数据（包括接触力分布和空间接触区域），并将其整合到策略网络中，从而实现更全面、触觉感知的运动，尤其是在需要高精度接触的任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有用于灵巧操作的触觉信息维度较低，限制了生成全面触觉感知运动的策略的能力。

Method: 提出 DexTac 框架，基于体感教学，捕获多维触觉数据（接触力分布和空间接触区域），并将其整合到策略网络中。

Result: 在复杂的单手注射任务中，DexTac 实现了 91.67% 的成功率。在小容量注射器的高精度场景下，比仅基于力的基线提高了 31.67%。

Conclusion: 从人类演示中学习多维触觉先验对于在富接触环境中实现鲁棒、类人灵巧操作至关重要。

Abstract: For contact-intensive tasks, the ability to generate policies that produce comprehensive tactile-aware motions is essential. However, existing data collection and skill learning systems for dexterous manipulation often suffer from low-dimensional tactile information. To address this limitation, we propose DexTac, a visuo-tactile manipulation learning framework based on kinesthetic teaching. DexTac captures multi-dimensional tactile data-including contact force distributions and spatial contact regions-directly from human demonstrations. By integrating these rich tactile modalities into a policy network, the resulting contact-aware agent enables a dexterous hand to autonomously select and maintain optimal contact regions during complex interactions. We evaluate our framework on a challenging unimanual injection task. Experimental results demonstrate that DexTac achieves a 91.67% success rate. Notably, in high-precision scenarios involving small-scale syringes, our approach outperforms force-only baselines by 31.67%. These results underscore that learning multi-dimensional tactile priors from human demonstrations is critical for achieving robust, human-like dexterous manipulation in contact-rich environments.

</details>


### [292] [Don't double it: Efficient Agent Prediction in Occlusions](https://arxiv.org/abs/2601.21504)
*Anna Rothenhäusler,Markus Mazzola,Andreas Look,Raghu Rajan,Joschka Bödecker*

Main category: cs.RO

TL;DR: 提出了一种名为MatchInformer的基于Transformer的新方法，通过整合匈牙利匹配算法来解决自动驾驶中被遮挡交通参与者检测的冗余预测问题，同时改进了轨迹预测的解耦策略，并使用MCC指标来处理类别不平衡问题，实验证明该方法在Waymo数据集上效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在处理被遮挡的交通参与者时存在冗余预测的问题，这会增加下游规划的复杂性和计算负担。

Method: 在SceneInformer架构基础上，引入匈牙利匹配算法（Hungarian Matching）进行训练，强制预测与真实情况的一对一对应关系，减少冗余。通过将代理的朝向与其运动解耦来改进轨迹预测。使用Matthews Correlation Coefficient (MCC)来评估占用预测，以应对类别不平衡。

Result: 实验表明，该方法能更好地推理被遮挡区域，并生成比现有方法更准确的轨迹预测。

Conclusion: MatchInformer通过引入匈牙利匹配算法解决了被遮挡交通参与者检测中的冗余预测问题，并提出了改进的轨迹预测和评估方法，在Waymo Open Motion Dataset上取得了优于现有方法的性能。

Abstract: Occluded traffic agents pose a significant challenge for autonomous vehicles, as hidden pedestrians or vehicles can appear unexpectedly, yet this problem remains understudied. Existing learning-based methods, while capable of inferring the presence of hidden agents, often produce redundant occupancy predictions where a single agent is identified multiple times. This issue complicates downstream planning and increases computational load. To address this, we introduce MatchInformer, a novel transformer-based approach that builds on the state-of-the-art SceneInformer architecture. Our method improves upon prior work by integrating Hungarian Matching, a state-of-the-art object matching algorithm from object detection, into the training process to enforce a one-to-one correspondence between predictions and ground truth, thereby reducing redundancy. We further refine trajectory forecasts by decoupling an agent's heading from its motion, a strategy that improves the accuracy and interpretability of predicted paths. To better handle class imbalances, we propose using the Matthews Correlation Coefficient (MCC) to evaluate occupancy predictions. By considering all entries in the confusion matrix, MCC provides a robust measure even in sparse or imbalanced scenarios. Experiments on the Waymo Open Motion Dataset demonstrate that our approach improves reasoning about occluded regions and produces more accurate trajectory forecasts than prior methods.

</details>


### [293] [Training slow silicon neurons to control extremely fast robots with spiking reinforcement learning](https://arxiv.org/abs/2601.21548)
*Irene Ambrosini,Ingo Blakowski,Dmitrii Zendrikov,Cristiano Capone,Luna Gava,Giacomo Indiveri,Chiara De Luca,Chiara Bartolozzi*

Main category: cs.RO

TL;DR: 研究人员开发了一种基于模拟/数字神经形态处理器和脉冲神经网络的紧凑型系统，用于实时学习空气曲棍球游戏，实现了高效、快速且低功耗的机器人自主控制。


<details>
  <summary>Details</summary>
Motivation: 空气曲棍球比赛中的高速、瞬时决策对传统计算系统提出了挑战，作者旨在开发一种更高效、更接近人脑的解决方案，以实现实时学习和控制。

Method: 该研究采用模拟/数字混合信号神经形态处理器，构建了一个由脉冲神经元组成的紧凑型网络。通过硬件和学习算法的协同设计，利用了固定的随机连接来捕捉任务的时间结构，并在读出层采用了局部 e-prop 学习规则，利用事件驱动的活动实现高效学习。训练方法是强化学习。

Result: 该系统在极少量的试验中成功实现了对空气曲棍球的交互控制。实现了实时学习，并且设置包括计算机和神经形态芯片在内的系统（in-the-loop）。

Conclusion: 这项工作将受神经科学启发的硬件与现实世界的机器人控制相结合，证明了类脑方法能够应对快节奏的交互任务，并支持智能机器中的持续学习。

Abstract: Air hockey demands split-second decisions at high puck velocities, a challenge we address with a compact network of spiking neurons running on a mixed-signal analog/digital neuromorphic processor. By co-designing hardware and learning algorithms, we train the system to achieve successful puck interactions through reinforcement learning in a remarkably small number of trials. The network leverages fixed random connectivity to capture the task's temporal structure and adopts a local e-prop learning rule in the readout layer to exploit event-driven activity for fast and efficient learning. The result is real-time learning with a setup comprising a computer and the neuromorphic chip in-the-loop, enabling practical training of spiking neural networks for robotic autonomous systems. This work bridges neuroscience-inspired hardware with real-world robotic control, showing that brain-inspired approaches can tackle fast-paced interaction tasks while supporting always-on learning in intelligent machines.

</details>


### [294] [IROS: A Dual-Process Architecture for Real-Time VLM-Based Indoor Navigation](https://arxiv.org/abs/2601.21506)
*Joonhee Lee,Hyunseung Shin,Jeonggil Ko*

Main category: cs.RO

TL;DR: 提出了一种名为 IROS 的实时室内机器人导航框架，该框架结合了 VLM 的上下文推理能力和轻量级感知模块的效率，从而实现了低延迟和类人导航。


<details>
  <summary>Details</summary>
Motivation: 现有的室内机器人导航方法在响应速度和语义理解方面存在不足，难以同时满足实时性和对人类导向线索（如标志、房间号）的理解需求。

Method: IROS 框架借鉴了双重加工理论，将快速的反射性决策（系统一）与缓慢的审慎推理（系统二）分开。它仅在必要时调用 VLM，并通过增强紧凑型 VLM 的空间和文本线索来实现高效的导航。

Result: 与持续使用 VLM 的导航方法相比，IROS 在五个真实建筑数据集上，决策准确性得到了提高，并且延迟降低了 66%。

Conclusion: IROS 框架能够以极低的延迟实现强大、类人般的室内机器人导航，有效解决了现有方法的局限性。

Abstract: Indoor mobile robot navigation requires fast responsiveness and robust semantic understanding, yet existing methods struggle to provide both. Classical geometric approaches such as SLAM offer reliable localization but depend on detailed maps and cannot interpret human-targeted cues (e.g., signs, room numbers) essential for indoor reasoning. Vision-Language-Action (VLA) models introduce semantic grounding but remain strictly reactive, basing decisions only on visible frames and failing to anticipate unseen intersections or reason about distant textual cues. Vision-Language Models (VLMs) provide richer contextual inference but suffer from high computational latency, making them unsuitable for real-time operation on embedded platforms. In this work, we present IROS, a real-time navigation framework that combines VLM-level contextual reasoning with the efficiency of lightweight perceptual modules on low-cost, on-device hardware. Inspired by Dual Process Theory, IROS separates fast reflexive decisions (System One) from slow deliberative reasoning (System Two), invoking the VLM only when necessary. Furthermore, by augmenting compact VLMs with spatial and textual cues, IROS delivers robust, human-like navigation with minimal latency. Across five real-world buildings, IROS improves decision accuracy and reduces latency by 66% compared to continuous VLM-based navigation.

</details>


### [295] [AIR-VLA: Vision-Language-Action Systems for Aerial Manipulation](https://arxiv.org/abs/2601.21602)
*Jianli Sun,Bin Tian,Qiyao Zhang,Chengxiang Li,Zihan Song,Zhiyong Cui,Yisheng Lv,Yonglin Tian*

Main category: cs.RO

TL;DR: 本文提出了AIR-VLA，一个专门为空中操作系统（AMS）设计的视觉-语言-动作（VLA）基准，包括一个物理模拟环境和包含3000个演示的多模态数据集，用于评估现有VLA和VLM模型在这一新兴领域的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在地面具身智能方面取得了成功，但由于空中操作系统的浮动基动力学、UAV与机械臂的强耦合以及任务的长时序性等挑战，其在空中操作系统上的应用仍是未探索的领域。因此，需要一个专门针对AMS的VLA基准来弥合这一差距。

Method: 构建了一个物理模拟环境，并收集了一个包含3000个手动遥操作演示的多模态数据集。该数据集涵盖了基础操作、物体和空间理解、语义推理以及长时序规划。利用此平台，系统地评估了主流VLA模型和最先进的VLM模型。

Result: 实验验证了将VLA范式迁移到空中系统的可行性。通过为空中任务定制的多维度指标，揭示了当前模型在UAV移动性、机械臂控制和高级规划方面的能力和局限性。

Conclusion: AIR-VLA是第一个专门为空中操作系统设计的VLA基准，为未来通用空中机器人研究建立了标准化的测试平台和数据基础，并对当前VLA/VLM模型在空中操作任务中的性能进行了评估和分析。

Abstract: While Vision-Language-Action (VLA) models have achieved remarkable success in ground-based embodied intelligence, their application to Aerial Manipulation Systems (AMS) remains a largely unexplored frontier. The inherent characteristics of AMS, including floating-base dynamics, strong coupling between the UAV and the manipulator, and the multi-step, long-horizon nature of operational tasks, pose severe challenges to existing VLA paradigms designed for static or 2D mobile bases. To bridge this gap, we propose AIR-VLA, the first VLA benchmark specifically tailored for aerial manipulation. We construct a physics-based simulation environment and release a high-quality multimodal dataset comprising 3000 manually teleoperated demonstrations, covering base manipulation, object & spatial understanding, semantic reasoning, and long-horizon planning. Leveraging this platform, we systematically evaluate mainstream VLA models and state-of-the-art VLM models. Our experiments not only validate the feasibility of transferring VLA paradigms to aerial systems but also, through multi-dimensional metrics tailored to aerial tasks, reveal the capabilities and boundaries of current models regarding UAV mobility, manipulator control, and high-level planning. AIR-VLA establishes a standardized testbed and data foundation for future research in general-purpose aerial robotics. The resource of AIR-VLA will be available at https://anonymous.4open.science/r/AIR-VLA-dataset-B5CC/.

</details>


### [296] [From Instruction to Event: Sound-Triggered Mobile Manipulation](https://arxiv.org/abs/2601.21667)
*Hao Ju,Shaofei Huang,Hongyu Li,Zihan Ding,Si Liu,Meng Wang,Zhedong Zheng*

Main category: cs.RO

TL;DR: 该研究提出了一种名为“声音触发移动操作”的新范式，使机器人能够根据声音线索主动操作物体，而不是依赖预设指令。为此，研究人员开发了Habitat-Echo平台，并提出了一个基础模型来完成这些任务。实验证明了该方法的有效性，尤其是在复杂声学干扰下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的移动操作研究主要依赖文本指令，这限制了机器人的自主性和对动态环境的反应能力。研究旨在克服这一局限，让机器人能够主动感知和响应声音线索。

Method: 开发了一个名为Habitat-Echo的数据平台，该平台集成了声学渲染和物理交互。提出了一种包含高级任务规划器和低级策略模型的基础模型来完成声音触发的操作任务。

Result: 提出的基础模型能够让机器人主动检测并响应声音事件，无需具体的指令。在包含两种声源的复杂场景下，机器人成功地从重叠的声学干扰中分离出主要声源进行首次交互，随后操纵次要物体，验证了模型的鲁棒性。

Conclusion: 声音触发的移动操作范式可以赋能机器人更自主地与环境互动，克服了传统指令驱动模式的局限性。Habitat-Echo平台和提出的基础模型为实现这一目标提供了有效的解决方案。

Abstract: Current mobile manipulation research predominantly follows an instruction-driven paradigm, where agents rely on predefined textual commands to execute tasks. However, this setting confines agents to a passive role, limiting their autonomy and ability to react to dynamic environmental events. To address these limitations, we introduce sound-triggered mobile manipulation, where agents must actively perceive and interact with sound-emitting objects without explicit action instructions. To support these tasks, we develop Habitat-Echo, a data platform that integrates acoustic rendering with physical interaction. We further propose a baseline comprising a high-level task planner and low-level policy models to complete these tasks. Extensive experiments show that the proposed baseline empowers agents to actively detect and respond to auditory events, eliminating the need for case-by-case instructions. Notably, in the challenging dual-source scenario, the agent successfully isolates the primary source from overlapping acoustic interference to execute the first interaction, and subsequently proceeds to manipulate the secondary object, verifying the robustness of the baseline.

</details>


### [297] [Disentangling perception and reasoning for improving data efficiency in learning cloth manipulation without demonstrations](https://arxiv.org/abs/2601.21713)
*Donatien Delehelle,Fei Chen,Darwin Caldwell*

Main category: cs.RO

TL;DR: 本文提出了一种更高效、模块化的强化学习方法来解决机器人布料操作的难题，通过精心设计在模拟环境中训练模型，显著减少了模型大小和训练时间，并成功将模拟训练的模型迁移到现实世界，在SoftGym基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人布料操作方法面临高维度状态空间、复杂动力学和自遮挡等挑战，基于分析的方法鲁棒性和通用性不足，而基于强化学习（RL）的方法计算成本高昂，训练时间长。此外，端到端学习方法虽然易于sim-to-real迁移，但输入图像表示的损失导致效率低下。因此，研究一种高效且模块化的RL方法来解决这些问题具有重要意义。

Method: 本文探索了一种高效且模块化的强化学习方法，用于布料操作。通过仔细的设计选择，在模拟环境中训练模型，以减小模型尺寸和训练时间。随后，将模拟训练的模型迁移到现实世界进行部署。该方法在SoftGym基准测试上进行了评估。

Result: 该方法在SoftGym基准测试上实现了显著的性能提升，优于现有的基线方法，并且使用了明显更小的模型。

Conclusion: 通过精心的设计，可以在模拟环境中高效地训练出能够解决布料操作问题的模型，并且该模型可以成功地迁移到现实世界，证明了该方法在布料操作领域的有效性和优越性。

Abstract: Cloth manipulation is a ubiquitous task in everyday life, but it remains an open challenge for robotics. The difficulties in developing cloth manipulation policies are attributed to the high-dimensional state space, complex dynamics, and high propensity to self-occlusion exhibited by fabrics. As analytical methods have not been able to provide robust and general manipulation policies, reinforcement learning (RL) is considered a promising approach to these problems. However, to address the large state space and complex dynamics, data-based methods usually rely on large models and long training times. The resulting computational cost significantly hampers the development and adoption of these methods. Additionally, due to the challenge of robust state estimation, garment manipulation policies often adopt an end-to-end learning approach with workspace images as input. While this approach enables a conceptually straightforward sim-to-real transfer via real-world fine-tuning, it also incurs a significant computational cost by training agents on a highly lossy representation of the environment state. This paper questions this common design choice by exploring an efficient and modular approach to RL for cloth manipulation. We show that, through careful design choices, model size and training time can be significantly reduced when learning in simulation. Furthermore, we demonstrate how the resulting simulation-trained model can be transferred to the real world. We evaluate our approach on the SoftGym benchmark and achieve significant performance improvements over available baselines on our task, while using a substantially smaller model.

</details>


### [298] [CoFreeVLA: Collision-Free Dual-Arm Manipulation via Vision-Language-Action Model and Risk Estimation](https://arxiv.org/abs/2601.21712)
*Xuanran Zhai,Binkai Ou,Yemin Wang,Hui Yi Leong,Qiaojun Yu,Ce Hao,Yaohua Liu*

Main category: cs.RO

TL;DR: CoFreeVLA 通过引入一个短视角的自我碰撞风险估计器，来增强 Vision Language Action (VLA) 模型，以提高双臂机器人执行指令时的安全性，减少自我碰撞并提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的 Vision Language Action (VLA) 模型在指令跟随操作方面有潜力，但在双臂部署时，由于手臂与抓取物体之间的自我碰撞模型不足，存在安全隐患。

Method: 该研究引入 CoFreeVLA，一个端到端的 VLA 模型，并增加了一个短视角的自我碰撞风险估计器。该估计器利用本体感受、视觉嵌入和规划动作来预测碰撞的可能性。它通过限制高风险指令、通过风险引导调整来恢复到安全状态，并优化策略以实现更安全的执行。

Result: 在 PiPER 双臂机器人上的五个双臂任务中，CoFreeVLA 相较于 RDT 和 APEX，显著减少了自我碰撞，并提高了任务成功率。

Conclusion: CoFreeVLA 成功地解决了双臂机器人执行指令时存在的自我碰撞问题，通过引入风险估计和风险引导策略，提高了操作的安全性与效率。

Abstract: Vision Language Action (VLA) models enable instruction following manipulation, yet dualarm deployment remains unsafe due to under modeled selfcollisions between arms and grasped objects. We introduce CoFreeVLA, which augments an endtoend VLA with a short horizon selfcollision risk estimator that predicts collision likelihood from proprioception, visual embeddings, and planned actions. The estimator gates risky commands, recovers to safe states via risk-guided adjustments, and shapes policy refinement for safer rollouts. It is pre-trained with model-based collision labels and posttrained on real robot rollouts for calibration. On five bimanual tasks with the PiPER robot arm, CoFreeVLA reduces selfcollisions and improves success rates versus RDT and APEX.

</details>


### [299] [Flocking behavior for dynamic and complex swarm structures](https://arxiv.org/abs/2601.21772)
*Carmen D. R. Pita-Romero,Pedro Arias-Perez,Miguel Fernandez-Cortizas,Rafael Perez-Segui,Pascual Campoy*

Main category: cs.RO

TL;DR: 提出了一种基于虚拟质心算法的无人机编队控制方法，用于实现复杂结构和轨迹的无人机集群。


<details>
  <summary>Details</summary>
Motivation: 在无人机集群中维持复杂结构和实现复杂轨迹的形成仍然是一个重大挑战。

Method: 该方法基于经典的虚拟质心行为，并提供了一个理论框架，用于动态控制无人机数量和集群结构。

Result: 仿真和真实世界实验表明，该算法能够简单地实现复杂编队和复杂轨迹。

Conclusion: 基于虚拟质心的算法能够有效地解决无人机集群在形成复杂结构和执行复杂轨迹方面的挑战，并且易于实现。

Abstract: Maintaining the formation of complex structures with multiple UAVs and achieving complex trajectories remains a major challenge. This work presents an algorithm for implementing the flocking behavior of UAVs based on the concept of Virtual Centroid to easily develop a structure for the flock. The approach builds on the classical virtual-based behavior, providing a theoretical framework for incorporating enhancements to dynamically control both the number of agents and the formation of the structure. Simulation tests and real-world experiments were conducted, demonstrating its simplicity even with complex formations and complex trajectories.

</details>


### [300] [GAZELOAD A Multimodal Eye-Tracking Dataset for Mental Workload in Industrial Human-Robot Collaboration](https://arxiv.org/abs/2601.21829)
*Bsher Karbouj,Baha Eddin Gaaloul,Jorg Kruger*

Main category: cs.RO

TL;DR: 本文介绍了GAZELOAD，一个用于工业人机协作中工作负荷估计的多模态数据集，包含眼动追踪、环境和任务上下文数据。


<details>
  <summary>Details</summary>
Motivation: 开发用于现实工业人机协作场景中工作负荷估计和眼动数据分析的算法，并研究环境因素（如照明）对眼动工作负荷标记的影响。

Method: 通过实验室组装测试平台，让26名参与者与两台协作机器人（UR5和Franka Emika Panda）互动，并佩戴Meta ARIA智能眼镜收集数据。数据包括眼动追踪信号（瞳孔直径、注视、扫视、注视点、注视转移熵、注视离散指数）、环境实时测量（照度）、任务和机器人上下文（工作台、任务块、诱发故障），并在控制的任务难度和环境条件下进行。

Result: 为每位参与者和不同工作负荷等级的任务块，提供了聚合到250毫秒窗口的眼动指标、环境日志和1-10的李克特量表自我报告工作负荷评分。

Conclusion: GAZELOAD数据集可用于开发和评估工业人机协作中工作负荷估计、特征提取和时间建模的算法，并为研究眼动工作负荷标记与环境因素的关系提供了基础。

Abstract: This article describes GAZELOAD, a multimodal dataset for mental workload estimation in industrial human-robot collaboration. The data were collected in a laboratory assembly testbed where 26 participants interacted with two collaborative robots (UR5 and Franka Emika Panda) while wearing Meta ARIA smart glasses. The dataset time-synchronizes eye-tracking signals (pupil diameter, fixations, saccades, eye gaze, gaze transition entropy, fixation dispersion index) with environmental real-time and continuous measurements (illuminance) and task and robot context (bench, task block, induced faults), under controlled manipulations of task difficulty and ambient conditions. For each participant and workload-graded task block, we provide CSV files with ocular metrics aggregated into 250 ms windows, environmental logs, and self-reported mental workload ratings on a 1-10 Likert scale, organized in participant-specific folders alongside documentation. These data can be used to develop and benchmark algorithms for mental workload estimation, feature extraction, and temporal modeling in realistic industrial HRC scenarios, and to investigate the influence of environmental factors such as lighting on eye-based workload markers.

</details>


### [301] [LLM-Driven Scenario-Aware Planning for Autonomous Driving](https://arxiv.org/abs/2601.21876)
*He Li,Zhaowei Chen,Rui Gao,Guoliang Li,Qi Hao,Shuai Wang,Chengzhong Xu*

Main category: cs.RO

TL;DR: 本文提出了一种名为LAP（Large Language Model driven, Adaptive Planning）的混合规划器切换框架，利用大语言模型（LLM）实现对自动驾驶场景的自适应理解和规划，以平衡高速行驶效率与复杂交通环境下的安全操控，并在仿真中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有混合规划器切换框架（HPSF）在自动驾驶中难以在高速行驶效率和密集交通环境下的安全操控之间取得良好平衡，主要原因是启发式场景识别和低频控制更新导致模式切换不可靠，且效率不高。

Method: 提出了一种基于大语言模型（LLM）的自适应规划方法LAP。LLM用于场景理解，并将其推理结果整合到模式配置和运动规划的联合优化中。该联合优化通过树搜索模型预测控制（MPC）和交替最小化方法求解。

Result: 在ROS环境下使用Python实现的LAP，在高保真仿真结果显示，LAP在驾驶时间和成功率方面均优于其他基准方法。

Conclusion: LAP通过利用LLM进行场景理解，并将其集成到模式配置和运动规划的联合优化中，能够有效地在低复杂度场景的高速驾驶和高复杂度场景的精确驾驶之间切换，从而在狭窄空间内生成高质量轨迹，并提高了驾驶效率和成功率。

Abstract: Hybrid planner switching framework (HPSF) for autonomous driving needs to reconcile high-speed driving efficiency with safe maneuvering in dense traffic. Existing HPSF methods often fail to make reliable mode transitions or sustain efficient driving in congested environments, owing to heuristic scene recognition and low-frequency control updates. To address the limitation, this paper proposes LAP, a large language model (LLM) driven, adaptive planning method, which switches between high-speed driving in low-complexity scenes and precise driving in high-complexity scenes, enabling high qualities of trajectory generation through confined gaps. This is achieved by leveraging LLM for scene understanding and integrating its inference into the joint optimization of mode configuration and motion planning. The joint optimization is solved using tree-search model predictive control and alternating minimization. We implement LAP by Python in Robot Operating System (ROS). High-fidelity simulation results show that the proposed LAP outperforms other benchmarks in terms of both driving time and success rate.

</details>


### [302] [Multi-Modular MANTA-RAY: A Modular Soft Surface Platform for Distributed Multi-Object Manipulation](https://arxiv.org/abs/2601.21884)
*Pratik Ingle,Jørn Lambertsen,Kasper Støy,Andres Faina*

Main category: cs.RO

TL;DR: 研究提出了一种模块化、可扩展的 MANTA-RAY 平台，通过减少驱动器密度和模块间协作，实现对复杂、易碎物体的有效操控，并验证了其在模拟和物理原型上的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有密集驱动器阵列控制表面存在高自由度、系统复杂且难以扩展的问题。先前 MANTA-RAY 研究局限于单模块，缺乏对可扩展多模块配置可行性和优势的探索。

Method: 提出一种分布式、模块化、可扩展的 MANTA-RAY 变体，采用模块间物体传递和基于几何变换的 PID 控制器，直接将倾斜角度映射到驱动器指令，无需大量数据驱动训练。在模拟中评估了不同模块配置（3x3、4x4）的性能，并通过 2x2 物理原型进行了实验验证。

Result: 该多模块 MANTA-RAY 平台在模拟和物理实验中均表现出优异的操控性能，能够成功操控具有不同几何形状、质量和纹理的物体，包括鸡蛋、苹果等易碎物品。实现了模块间的协调操控和更大范围的并行操控。

Conclusion: 多模块 MANTA-RAY 平台通过降低驱动器密度和引入模块化设计，成功解决了可扩展性和系统复杂性的问题，并实现了高效、协调的物体操控，展示了其在实际应用中的巨大潜力。

Abstract: Manipulation surfaces control objects by actively deforming their shape rather than directly grasping them. While dense actuator arrays can generate complex deformations, they also introduce high degrees of freedom (DOF), increasing system complexity and limiting scalability. The MANTA-RAY (Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation densitY) platform addresses these challenges by leveraging a soft, fabric-based surface with reduced actuator density to manipulate fragile and heterogeneous objects. Previous studies focused on single-module implementations supported by four actuators, whereas the feasibility and benefits of a scalable, multi-module configuration remain unexplored. In this work, we present a distributed, modular, and scalable variant of the MANTA-RAY platform that maintains manipulation performance with a reduced actuator density. The proposed multi-module MANTA-RAY platform and control strategy employs object passing between modules and a geometric transformation driven PID controller that directly maps tilt-angle control outputs to actuator commands, eliminating the need for extensive data-driven or black-box training. We evaluate system performance in simulation across surface configurations of varying modules (3x3 and 4x4) and validate its feasibility through experiments on a physical 2x2 hardware prototype. The system successfully manipulates objects with diverse geometries, masses, and textures including fragile items such as eggs and apples as well as enabling parallel manipulation. The results demonstrate that the multi-module MANTA-RAY improves scalability and enables coordinated manipulation of multiple objects across larger areas, highlighting its potential for practical, real-world applications.

</details>


### [303] [MoE-ACT: Improving Surgical Imitation Learning Policies through Supervised Mixture-of-Experts](https://arxiv.org/abs/2601.21971)
*Lorenzo Mazza,Ariel Rodriguez,Rayan Younis,Martin Lelis,Ortrun Hellig,Chenpan Li,Sebastian Bodenstedt,Martin Wagner,Stefanie Speidel*

Main category: cs.RO

TL;DR: 提出了一种监督式混合专家（MoE）架构，用于增强机器人手术中的模仿学习，仅凭立体内窥镜图像，即可在数据有限的情况下实现复杂的手术操作，并在各种挑战性场景下展现出优于现有方法的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前的模仿学习在机器人手术中的应用面临数据稀缺、工作空间受限以及对安全性和可预测性要求极高的问题。因此，研究者们希望开发一种能在有限数据下，从单目或双目图像中学习复杂手术操作的方法。

Method: 提出了一种监督式混合专家（MoE）架构，可以叠加在任何自主策略之上。该方法利用了Action Chunking Transformer (ACT) 策略，仅使用立体内窥镜图像，并在低于150次演示的情况下学习复杂、长周期的操纵任务。通过在模仿学习框架中集成MoE架构，来增强现有模型的性能。

Result: 与现有最先进的Vision-Language-Action（VLA）模型和标准ACT基线相比，提出的MoE架构显著提高了ACT在直肠抓取和牵拉任务上的性能。在各种分布内和分布外场景（包括新的抓取位置、光照不足和部分遮挡）下，MoE架构都表现出更高的成功率和更强的鲁棒性。此外，该方法还能泛化到未见的测试视角，并能零样本迁移到离体猪肉组织，甚至在体内猪肉手术中也取得了初步的成功。

Conclusion: 监督式MoE架构是一种有效的方法，可以显著增强低数据量下的模仿学习在机器人手术中的表现。该方法不仅在数据充足的条件下表现出色，而且在应对分布外情况时也显示出强大的鲁棒性和泛化能力，为机器人手术的实际应用提供了一个有前途的途径。

Abstract: Imitation learning has achieved remarkable success in robotic manipulation, yet its application to surgical robotics remains challenging due to data scarcity, constrained workspaces, and the need for an exceptional level of safety and predictability. We present a supervised Mixture-of-Experts (MoE) architecture designed for phase-structured surgical manipulation tasks, which can be added on top of any autonomous policy. Unlike prior surgical robot learning approaches that rely on multi-camera setups or thousands of demonstrations, we show that a lightweight action decoder policy like Action Chunking Transformer (ACT) can learn complex, long-horizon manipulation from less than 150 demonstrations using solely stereo endoscopic images, when equipped with our architecture. We evaluate our approach on the collaborative surgical task of bowel grasping and retraction, where a robot assistant interprets visual cues from a human surgeon, executes targeted grasping on deformable tissue, and performs sustained retraction. We benchmark our method against state-of-the-art Vision-Language-Action (VLA) models and the standard ACT baseline. Our results show that generalist VLAs fail to acquire the task entirely, even under standard in-distribution conditions. Furthermore, while standard ACT achieves moderate success in-distribution, adopting a supervised MoE architecture significantly boosts its performance, yielding higher success rates in-distribution and demonstrating superior robustness in out-of-distribution scenarios, including novel grasp locations, reduced illumination, and partial occlusions. Notably, it generalizes to unseen testing viewpoints and also transfers zero-shot to ex vivo porcine tissue without additional training, offering a promising pathway toward in vivo deployment. To support this, we present qualitative preliminary results of policy roll-outs during in vivo porcine surgery.

</details>


### [304] [Macro-Scale Electrostatic Origami Motor](https://arxiv.org/abs/2601.21976)
*Alex S. Miller,Leo McElroy,Jeffrey H. Lang*

Main category: cs.RO

TL;DR: 本文介绍了一种首个可折叠的宏观尺度折纸旋转电机，利用电晕放电产生扭矩，实现了2.5:1的展开比，最高转速1440 rpm。


<details>
  <summary>Details</summary>
Motivation: 现有折叠机器人在运动方面存在局限，大多依赖线性驱动器或非折叠电机，且未实现宏观尺度的连续旋转驱动。开发一种可折叠且能连续旋转的驱动器是研究的动机。

Method: 研究人员开发了一种利用电晕放电产生扭矩的宏观尺度折纸旋转电机原型。该电机可以折叠平放，展开后进行旋转运动。

Result: 原型电机实现了2.5:1的展开比，在-29 kV电压下最高转速达到1440 rpm，最大输出扭矩超过0.15 mN m，活性部件扭矩密度为0.04 Nm/kg。

Conclusion: 成功开发出一种新型的可折叠宏观尺度折纸旋转电机，证明了利用电晕放电实现折叠式连续旋转驱动的可行性，为折叠机器人提供了新的运动方式。

Abstract: Foldable robots have been an active area of robotics research due to their high volume-to-mass ratio, easy packability, and shape adaptability. For locomotion, previously developed foldable robots have either embedded linear actuators in, or attached non-folding rotary motors to, their structure. Further, those actuators directly embedded in the structure of the folding medium all contributed to linear or folding motion, not to continuous rotary motion. On the macro-scale there has not yet been a folding continuous rotary actuator. This paper details the development and testing of the first macro-scale origami rotary motor that can be folded flat, and then unfurled to operate. Using corona discharge for torque production, the prototype motor achieved an expansion ratio of 2.5:1, reached a top speed of 1440 rpm when driven at -29 kV, and exhibited a maximum output torque over 0.15 mN m with an active component torque density of 0.04 Nm/kg.

</details>


### [305] [Information Filtering via Variational Regularization for Robot Manipulation](https://arxiv.org/abs/2601.21926)
*Jinhao Zhang,Wenlong Xia,Yaojia Wang,Zhexuan Zhou,Huizhe Li,Yichen Lai,Haoming Song,Youmin Gong,Jie Me*

Main category: cs.RO

TL;DR: 该研究提出了一种名为变分正则化（VR）的轻量级模块，通过在骨干特征上施加时间步长条件的高斯分布并引入KL散度正则化器，形成一个自适应信息瓶颈，以解决现有基于扩散的视觉-运动策略中存在的任务无关噪声问题，从而提高机器人的学习能力。实验结果表明，与基线DP3相比，VR在RoboTwin2.0、Adroit和MetaWorld等模拟基准测试中显著提高了成功率，并在真实世界部署中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的视觉-运动策略在复杂机器人技能学习方面表现出色，但它们通常使用过大的去噪解码器。研究发现，增加模型容量会引入中间特征块的冗余和噪声，这可以通过在推理时随机屏蔽骨干特征来验证。因此，有必要开发一种方法来减轻这种噪声并提高策略的效率。

Method: 提出了一种名为变分正则化（VR）的轻量级模块。VR在骨干特征上施加一个时间步长条件的高斯分布，并引入KL散度正则化器，形成一个自适应信息瓶颈。该模块旨在在训练过程中减少中间特征的冗余和噪声，从而提高策略的性能。

Result: 在RoboTwin2.0、Adroit和MetaWorld这三个模拟基准测试中进行的广泛实验表明，与基线DP3相比，VR方法将RoboTwin2.0的成功率提高了6.1%，将Adroit和MetaWorld的成功率提高了4.1%。这些结果达到了新的最先进水平。此外，真实世界实验也证明了该方法在实际部署中的有效性。

Conclusion: 变分正则化（VR）是一种轻量级且有效的模块，可以解决现有基于扩散的视觉-运动策略中存在的任务无关噪声问题。通过引入自适应信息瓶颈，VR能够提高策略的性能，并在模拟和真实世界的机器人任务中达到最先进的结果。

Abstract: Diffusion-based visuomotor policies built on 3D visual representations have achieved strong performance in learning complex robotic skills. However, most existing methods employ an oversized denoising decoder. While increasing model capacity can improve denoising, empirical evidence suggests that it also introduces redundancy and noise in intermediate feature blocks. Crucially, we find that randomly masking backbone features at inference time (without changing training) can improve performance, confirming the presence of task-irrelevant noise in intermediate features. To this end, we propose Variational Regularization (VR), a lightweight module that imposes a timestep-conditioned Gaussian over backbone features and applies a KL-divergence regularizer, forming an adaptive information bottleneck. Extensive experiments on three simulation benchmarks (RoboTwin2.0, Adroit, and MetaWorld) show that, compared to the baseline DP3, our approach improves the success rate by 6.1% on RoboTwin2.0 and by 4.1% on Adroit and MetaWorld, achieving new state-of-the-art results. Real-world experiments further demonstrate that our method performs well in practical deployments. Code will released.

</details>


### [306] [PocketDP3: Efficient Pocket-Scale 3D Visuomotor Policy](https://arxiv.org/abs/2601.22018)
*Jinhao Zhang,Zhexuan Zhou,Huizhe Li,Yichen Lai,Wenlong Xia,Haoming Song,Youmin Gong,Jie Me*

Main category: cs.RO

TL;DR: PocketDP3 是一种小型化 3D 扩散策略，使用轻量级的 Diffusion Mixer 替代了大型 U-Net 解码器，在不牺牲性能的情况下实现了参数量的大幅减少和推理速度的提升，并在多个模拟和真实世界基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 3D 视觉驱动的扩散策略通常存在编码器和解码器之间的架构不匹配问题，即使用小型编码器搭配大型解码器，导致解码器参数浪费。作者希望通过设计一个更高效的架构来解决这个问题。

Method: 提出了一种名为 PocketDP3 的新型 3D 扩散策略，其核心是将传统的 U-Net 解码器替换为轻量级的 Diffusion Mixer (DiM)，后者基于 MLP-Mixer 块构建，能够高效地融合时间和通道维度信息，从而显著减小模型尺寸。该方法支持两步推理，无需额外的蒸馏技术即可保持性能。

Result: 在 RoboTwin2.0、Adroit 和 MetaWorld 三个模拟基准测试中，PocketDP3 取得了最先进的性能，参数量却仅为现有方法的 1% 左右。同时，推理速度也得到了提升。真实世界实验也验证了其在实际场景中的实用性和可迁移性。

Conclusion: PocketDP3 通过使用轻量级 Diffusion Mixer 实现了 3D 扩散策略的小型化和高效化，在参数量和推理速度方面具有显著优势，并且在各种基准测试中表现出色，有望在实际部署中提供更好的性能和更低的计算成本。

Abstract: Recently, 3D vision-based diffusion policies have shown strong capability in learning complex robotic manipulation skills. However, a common architectural mismatch exists in these models: a tiny yet efficient point-cloud encoder is often paired with a massive decoder. Given a compact scene representation, we argue that this may lead to substantial parameter waste in the decoder. Motivated by this observation, we propose PocketDP3, a pocket-scale 3D diffusion policy that replaces the heavy conditional U-Net decoder used in prior methods with a lightweight Diffusion Mixer (DiM) built on MLP-Mixer blocks. This architecture enables efficient fusion across temporal and channel dimensions, significantly reducing model size. Notably, without any additional consistency distillation techniques, our method supports two-step inference without sacrificing performance, improving practicality for real-time deployment. Across three simulation benchmarks--RoboTwin2.0, Adroit, and MetaWorld--PocketDP3 achieves state-of-the-art performance with fewer than 1% of the parameters of prior methods, while also accelerating inference. Real-world experiments further demonstrate the practicality and transferability of our method in real-world settings. Code will be released.

</details>


### [307] [mjlab: A Lightweight Framework for GPU-Accelerated Robot Learning](https://arxiv.org/abs/2601.22074)
*Kevin Zakka,Qiayuan Liao,Brent Yi,Louis Le Lay,Koushil Sreenath,Pieter Abbeel*

Main category: cs.RO

TL;DR: mjlab 是一个轻量级、开源的机器人学习框架，结合了 GPU 加速模拟、可组合环境和极简设置。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有机器人学习框架的复杂性、依赖性和设置摩擦，研究人员开发了 mjlab，旨在提供一个易于安装和使用的框架。

Method: mjlab 采用了 Isaac Lab 的 manager-based API，允许用户组合模块化的观察、奖励和事件组件。它还集成了 MuJoCo Warp 以实现 GPU 加速物理模拟，并提供对原生 MuJoCo 数据结构的直接访问。

Result: mjlab 框架可以通过单条命令安装，依赖项最少，并提供了速度跟踪、运动模仿和操作任务的参考实现。

Conclusion: mjlab 是一个高效且易于使用的机器人学习框架，通过结合 GPU 加速模拟和模块化设计，降低了机器人学习的门槛。

Abstract: We present mjlab, a lightweight, open-source framework for robot learning that combines GPU-accelerated simulation with composable environments and minimal setup friction. mjlab adopts the manager-based API introduced by Isaac Lab, where users compose modular building blocks for observations, rewards, and events, and pairs it with MuJoCo Warp for GPU-accelerated physics. The result is a framework installable with a single command, requiring minimal dependencies, and providing direct access to native MuJoCo data structures. mjlab ships with reference implementations of velocity tracking, motion imitation, and manipulation tasks.

</details>


### [308] [ReactEMG Stroke: Healthy-to-Stroke Few-shot Adaptation for sEMG-Based Intent Detection](https://arxiv.org/abs/2601.22090)
*Runsheng Wang,Katelyn Lee,Xinyue Zhu,Lauren Winterbottom,Dawn M. Nilsen,Joel Stein,Matei Ciocarlie*

Main category: cs.RO

TL;DR: 该研究提出了一种利用健康人群的sEMG数据预训练模型，然后针对中风患者进行少量数据微调的意图检测方法，以提高手部康复的控制信号鲁棒性和减少校准时间。


<details>
  <summary>Details</summary>
Motivation: 中风后辅助康复依赖sEMG信号，但现有方法需要耗时且不稳定的个性化校准。

Method: 使用预训练在健康人群sEMG数据上的模型，并通过头部调优、LoRA适配器或端到端微调等策略，利用少量患者数据进行适应性调整，并在包含分布变化的测试集上进行评估。

Result: 与零样本迁移和仅患者数据训练相比，预训练的适应性方法能显著提高意图检测的准确性，平均转换准确率从0.42提高到0.61，原始准确率从0.69提高到0.78。

Conclusion: 将可复用的健康领域EMG表征迁移应用于中风患者的意图检测，可以减轻校准负担并提高实时检测的鲁棒性。

Abstract: Surface electromyography (sEMG) is a promising control signal for assist-as-needed hand rehabilitation after stroke, but detecting intent from paretic muscles often requires lengthy, subject-specific calibration and remains brittle to variability. We propose a healthy-to-stroke adaptation pipeline that initializes an intent detector from a model pretrained on large-scale able-bodied sEMG, then fine-tunes it for each stroke participant using only a small amount of subject-specific data. Using a newly collected dataset from three individuals with chronic stroke, we compare adaptation strategies (head-only tuning, parameter-efficient LoRA adapters, and full end-to-end fine-tuning) and evaluate on held-out test sets that include realistic distribution shifts such as within-session drift, posture changes, and armband repositioning. Across conditions, healthy-pretrained adaptation consistently improves stroke intent detection relative to both zero-shot transfer and stroke-only training under the same data budget; the best adaptation methods improve average transition accuracy from 0.42 to 0.61 and raw accuracy from 0.69 to 0.78. These results suggest that transferring a reusable healthy-domain EMG representation can reduce calibration burden while improving robustness for real-time post-stroke intent detection.

</details>


### [309] [DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation](https://arxiv.org/abs/2601.22153)
*Haozhe Xie,Beichen Wen,Jiarui Zheng,Zhaoxi Chen,Fangzhou Hong,Haiwen Diao,Ziwei Liu*

Main category: cs.RO

TL;DR: 本文提出了一种名为 DynamicVLA 的新框架，用于处理动态物体操作任务，通过高效的视觉编码、连续推理和动作流技术，解决了现有 VLA 模型在动态场景下的不足，并引入了 DOM 基准来推动该领域的研究。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作 (VLA) 模型在静态物体操作方面表现良好，但在需要快速感知、时间预测和连续控制的动态场景下存在挑战，这促使了本研究的提出。

Method: DynamicVLA 框架包含三个关键设计：1) 一个紧凑的 0.4B VLA 模型，使用卷积视觉编码器以提高空间效率和结构保真度；2) 连续推理（Continuous Inference），实现推理和执行的重叠，以降低延迟并适应物体运动；3) 潜在感知动作流（Latent-aware Action Streaming），通过强制执行时间对齐的动作来弥合感知与执行之间的差距。此外，还引入了 DOM 基准，包含 200K 个合成实验和 2K 个真实世界实验。

Result: 实验表明，DynamicVLA 在响应速度、感知能力和泛化能力方面取得了显著的改进。

Conclusion: DynamicVLA 是一个统一的框架，能够有效地处理通用动态物体操作任务，并在各种具身环境中实现更快的响应和更好的适应性。

Abstract: Manipulating dynamic objects remains an open challenge for Vision-Language-Action (VLA) models, which, despite strong generalization in static manipulation, struggle in dynamic scenarios requiring rapid perception, temporal anticipation, and continuous control. We present DynamicVLA, a framework for dynamic object manipulation that integrates temporal reasoning and closed-loop adaptation through three key designs: 1) a compact 0.4B VLA using a convolutional vision encoder for spatially efficient, structurally faithful encoding, enabling fast multimodal inference; 2) Continuous Inference, enabling overlapping reasoning and execution for lower latency and timely adaptation to object motion; and 3) Latent-aware Action Streaming, which bridges the perception-execution gap by enforcing temporally aligned action execution. To fill the missing foundation of dynamic manipulation data, we introduce the Dynamic Object Manipulation (DOM) benchmark, built from scratch with an auto data collection pipeline that efficiently gathers 200K synthetic episodes across 2.8K scenes and 206 objects, and enables fast collection of 2K real-world episodes without teleoperation. Extensive evaluations demonstrate remarkable improvements in response speed, perception, and generalization, positioning DynamicVLA as a unified framework for general dynamic object manipulation across embodiments.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [310] [Mean-Field Learning for Storage Aggregation](https://arxiv.org/abs/2601.21039)
*Jingguan Liu,Cong Chen,Xiaomeng Ai,Jiakun Fang,Jinsong Wang,Jinyu Wen*

Main category: eess.SY

TL;DR: 本文提出了一种基于均值场学习的储能聚合框架，通过构建一个凸代理模型来近似大量异构储能设备的行为，使其能够高效、准确地参与电力市场竞价。


<details>
  <summary>Details</summary>
Motivation: 大规模分布式储能设备需要被聚合为可处理的代理模型，以便参与电力系统运行和市场结算。然而，储能设备的异质性、非凸性和高维度性使得代理模型识别充满挑战。

Method: 本文将聚合解释为大量储能设备群体的平均行为，并证明当群体规模增大时，聚合性能会收敛到一个独特的、凸的均值场极限。基于此，本文构建了一个凸代理模型，该模型可以通过历史市场价格-响应数据进行参数学习，并采用基于梯度的算法进行高效学习。

Result: 研究表明，均值场极限具有价格响应特性，并且可以界定均值场近似误差。开发的凸代理模型能够近似大规模储能设备群体的聚合行为，并能直接嵌入电力系统运行和市场结算中。案例研究验证了该框架在近似精度、数据效率和盈利能力方面的有效性。

Conclusion: 均值场学习框架能够有效地解决大规模异质储能聚合的挑战，通过构建一个计算高效且准确的凸代理模型，使得储能设备能够更好地参与电力市场，为电力系统运行和市场结算提供新的解决方案。

Abstract: Distributed energy storage devices can be pooled and coordinated by aggregators to participate in power system operations and market clearings. This requires representing a massive device population as a single, tractable surrogate that is computationally efficient, accurate, and compatible with market participation requirements. However, surrogate identification is challenging due to heterogeneity, nonconvexity, and high dimensionality of storage devices. To address these challenges, this paper develops a mean-field learning framework for storage aggregation. We interpret aggregation as the average behavior of a large storage population and show that, as the population grows, aggregate performance converges to a unique, convex mean-field limit, enabling tractable population-level modeling. This convexity further yields a price-responsive characterization of aggregate storage behavior and allows us to bound the mean-field approximation error. Leveraging these results, we construct a convex surrogate model that approximates the aggregate behavior of large storage populations and can be embedded directly into power system operations and market clearing. Surrogate parameter identification is formulated as an optimization problem using historical market price-response data, and we adopt a gradient-based algorithm for efficient learning procedure. Case studies validate the theoretical findings and demonstrate the effectiveness of the proposed framework in approximation accuracy, data efficiency, and profit outcomes.

</details>


### [311] [The Impact of Shared Autonomous Vehicles in Microtransit Systems: A Case Study in Atlanta](https://arxiv.org/abs/2601.21046)
*Jason Lu,Tejas Santanam,Hongzhao Guan,Connor Riley,Meen-Sung Kim,Anthony Trasatti,Neda Masoud,Pascal Van Hentenryck*

Main category: eess.SY

TL;DR: 本文研究了如何在微型交通系统中集成共享自动驾驶汽车（SAV），以优化调度和动态平衡车辆，从而提高服务质量和用户体验。


<details>
  <summary>Details</summary>
Motivation: 微型交通系统旨在解决“第一英里/最后一英里”问题，但传统系统存在局限性。共享自动驾驶汽车（SAV）的出现为提高微型交通系统的可持续性、便利性和可靠性提供了机会。

Method: 通过增强一个调度优化模型来考虑驾驶员行为和SAV功能。提出了一种模型预测控制方法，用于动态平衡车辆，而无需大量历史数据。使用 MARTA Reach 微型交通试点数据进行实验。

Result: 实验结果表明，与传统的按需班车相比，SAV 可以提高微型交通系统的服务质量和用户体验。

Conclusion: 将共享自动驾驶汽车（SAV）集成到微型交通系统中，可以通过优化调度和动态平衡车辆来显著提升服务质量和用户体验。

Abstract: Microtransit systems represent an enhancement to solve the first- and last-mile problem, integrating traditional rail and bus networks with on-demand shuttles into a flexible, integrated system. This type of demand responsive transport provides greater accessibility and higher quality levels of service compared to conventional fixed-route transit services. Advances in technology offer further opportunities to enhance microtransit performance. In particular, shared autonomous vehicles (SAVs) have the potential to transform the mobility landscape by enabling more sustainable operations, enhanced user convenience, and greater system reliability. This paper investigates the integration of SAVs in microtransit systems, advancing the technological capabilities of on-demand shuttles. A shuttle dispatching optimization model is enhanced to accommodate for driver behavior and SAV functionalities. A model predictive control approach is proposed that dynamically rebalances on-demand shuttles towards areas of higher demand without relying on vast historical data. Scenario-driven experiments are conducted using data from the MARTA Reach microtransit pilot. The results demonstrate that SAVs can elevate both service quality and user experience compared to traditional on-demand shuttles in microtransit systems.

</details>


### [312] [Deep Koopman Iterative Learning and Stability-Guaranteed Control for Unknown Nonlinear Time-Varying Systems](https://arxiv.org/abs/2601.21230)
*Hengde Zhang,Yunxiao Ren,Zhisheng Duan,Zhiyong Sun,Guanrong Chen*

Main category: eess.SY

TL;DR: 本文提出了一种基于Koopman算子理论的框架，用于对未知的非线性时变系统进行建模、预测和控制，并通过在线迭代更新和自适应更新机制提高了模型精度和控制鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的Koopman方法在处理非线性时变系统时，由于系统模型误差随时间累积，预测和控制性能会下降。因此，需要一种能够在线适应系统变化并保持模型精度的框架。

Method: 本文提出了一种新的基于Koopman算子的学习方法来预测未知非线性时变系统的状态，并在此基础上设计了一个鲁棒控制器。为了解决模型误差随时间增加的问题，引入了在线迭代更新方案来实时更新模型。同时，还增强了更新机制，以减少不必要的系统更新并提高拟合性能。最后，基于在线更新的模型设计了控制器，保证闭环系统的输入到状态稳定性。

Result: 提出的方法在Duffing振子、串联机械臂和合成生物网络系统上的数值模拟表明，该方法能够有效地近似和控制未知的非线性时变系统，并在近似精度和计算效率方面优于现有方法，即使在系统发生显著变化的情况下。

Conclusion: 该Koopman-based框架能够有效地对未知的非线性时变系统进行建模、预测和控制，其在线迭代更新和自适应更新机制提高了模型的鲁棒性和适应性，为处理此类系统提供了有效解决方案。

Abstract: This paper proposes a Koopman-based framework for modeling, prediction, and control of unknown nonlinear time-varying systems. We present a novel Koopman-based learning method for predicting the state of unknown nonlinear time-varying systems, upon which a robust controller is designed to ensure that the resulting closed-loop system is input-to-state stable with respect to the Koopman approximation error. The error of the lifted system model learned through the Koopman-based method increases over time due to the time-varying nature of the nonlinear time-varying system. To address this issue, an online iterative update scheme is incorporated into the learning process to update the lifted system model, aligning it more precisely with the time-varying nonlinear system by integrating the updated data and discarding the outdated data. A necessary condition for the feasibility of the proposed iterative learning method is derived. In order to reduce unnecessary system updates while ensuring the prediction accuracy of the lifted system, the update mechanism is enhanced to determine whether to update the lifted system and meanwhile to reduce updates that deteriorate the fitting performance. Furthermore, based on the online-updated lifted system, a controller is designed to ensure the closed-loop controlled system be input-to-state stable with respect to the Koopman approximation error. Numerical simulations on the Duffing oscillator, the serial manipulator, and the synthetic biological network system are presented to demonstrate the effectiveness of the proposed method for the approximation and control of unknown nonlinear time-varying systems. The results show that the proposed approach outperforms existing methods in terms of approximation accuracy and computational efficiency, even under significant system variations.

</details>


### [313] [Distributed Circumnavigation Using Bearing Based Control with Limited Target Information](https://arxiv.org/abs/2601.21300)
*Kushal Pratap Singh,Manvi Bengani,Darshit Mittal,Twinkle Tripathy*

Main category: eess.SY

TL;DR: 提出了一种分布式控制方法，用于一组具有有限感知能力的异构自主机器人（具有单轮车运动学）绕固定目标进行环绕。只有一部分“领队”机器人知道目标位置，而“跟随者”机器人不知道。该方法通过 Zubov 定理保证了全局渐近稳定性，并通过数值模拟和 TurtleBots 硬件实验进行了验证。


<details>
  <summary>Details</summary>
Motivation: 研究目标是解决一组具有有限感知能力的异构自主机器人绕固定目标进行环绕的问题，其中只有一部分机器人知道目标的位置。

Method: 提出了一种分布式引导律，利用 Zubov 定理来确保全局渐近稳定性。该方法适用于具有单轮车运动学、恒定线速度但可控角速度的机器人。

Result: 提出的分布式引导律能够驱动所有机器人（包括不知道目标位置的跟随者）实现环绕目标。通过数值模拟和 TurtleBots 硬件实验验证了该方法的有效性。

Conclusion: 该研究成功提出了一种有效的分布式控制方法，使得异构机器人群体能够利用有限的感知信息完成对 stationary 目标的环绕任务，并证明了其全局渐近稳定性。

Abstract: In this paper, we address the problem of circumnavigation of a stationary target by a heterogeneous group comprising of $\textbf{n}$ autonomous agents, having unicycle kinematics. The agents are assumed to have constant linear speeds, we control only the angular speeds. Assuming limited sensing capabilities of the agents, in the proposed framework, only a subset of agents, termed as \textit{leaders}, know the target location. The rest, termed as \textit{followers}, do not. We propose a distributed guidance law which drives all the agents towards the desired objective; global asymptotic stability (GAS) is ensured by using Zubov's theorem. The efficacy of the approach is demonstrated through both numerical simulations and hardware experiments on the TurtleBots utilising OptiTrack motion capture system.

</details>


### [314] [Towards Governance of Localized VANET: An Adjustable Degree Distribution Model](https://arxiv.org/abs/2601.21176)
*Ruixing Ren,Junhui Zhao,Xiaoke Sun,Shanjin Ni*

Main category: eess.SY

TL;DR: 本文提出了一种可调度度分布模型，通过混合连接机制（随机连接和优先连接）的协同，实现了VANETs网络拓扑在鲁棒性和低延迟传输之间的动态权衡，从而提高了网络的适应性和治理能力。


<details>
  <summary>Details</summary>
Motivation: 现有VANETs模型生成的度分布固定，无法自适应不同交通场景的需求，在应对目标攻击的鲁棒性和保证低延迟信息传输之间存在治理困境。

Method: 提出了一种用于本地化VANETs的可调度度分布模型，采用混合连接机制，新加入节点协同执行随机连接和优先连接。通过理论推导和仿真验证了该模型可以调整两种机制的权重，使度分布在均匀分布和幂律分布之间平滑过渡。

Result: 通过调整随机连接和优先连接的协同权重，可以实现网络度分布在均匀分布（提高鲁棒性）和幂律分布（降低延迟）之间的可控过渡。实验结果表明，该模型能精确调节节点连接异质性、抗攻击能力和平均传输路径长度。

Conclusion: 该模型为构建下一代能够动态适应复杂环境的VANETs提供了一种前瞻性和实用性的治理范式，能够通过重塑拓扑结构来实现网络性能的动态调控。

Abstract: Vehicular Ad-hoc Networks (VANETs) serve as a critical enabler for intelligent transportation systems. However, their practical deployment faces a core governance dilemma: the network topology requires a dynamic trade-off between robustness against targeted attacks and ensuring low-latency information transmission. Most existing models generate fixed degree distributions, lacking the ability to adapt autonomously to the demands of diverse traffic scenarios. To address this challenge, this paper innovatively proposes a schedulable degree distribution model for localized VANETs. The core of this model lies in introducing a hybrid connection mechanism. When establishing connections, newly joining nodes do not follow a single rule but instead collaboratively perform random attachment and preferential attachment. Through theoretical derivation and simulation validation, this study demonstrates that by adjusting the cooperative weighting between these two mechanisms, the overall network degree distribution can achieve a continuous and controllable transition between a uniform distribution and a power-law distribution. The former effectively disperses attack risks and enhances robustness, while the latter facilitates the formation of hub nodes, shortening transmission paths to reduce latency. Experimental results based on the real-world road network of Beijing indicate that this model can precisely regulate node connection heterogeneity, attack resistance, and average transmission path length through the reshaping of the underlying topology. This provides a forward-looking and practical governance paradigm for constructing next-generation VANETs capable of dynamically adapting to complex environments.

</details>


### [315] [Resilient Grid Hardening against Multiple Hazards: An Adaptive Two-Stage Stochastic Optimization Approach](https://arxiv.org/abs/2601.21371)
*Sifat Chowdhury,Yihsu Chen,Yu Zhang*

Main category: eess.SY

TL;DR: 提出了一种自适应两阶段随机优化框架，用于在多种灾害暴露下对关键电网组件进行动态加固决策，结合了长期和短期加固措施，以降低停电和维修成本，并提高电网基础设施规划的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 气候变化导致极端天气事件频发，对电力系统韧性构成严峻挑战，现有加固措施可能在面对多种威胁时适得其反，因此需要更有效的动态加固策略。

Method: 开发了一个自适应两阶段随机优化框架，该框架能够适应不断变化的气候条件，并整合了地下化（长期）和植被管理（短期）等加固措施，以联合最小化总系统成本。

Result: 仿真结果表明，该框架能够有效降低停电和维修成本，同时提高电网基础设施规划的适应性和鲁棒性。

Conclusion: 提出的自适应两阶段随机优化框架为应对气候变化下的电力系统韧性挑战提供了一种有效的解决方案，能够支持更具弹性的投资策略和动态的加固决策。

Abstract: The growing prevalence of extreme weather events driven by climate change poses significant challenges to power system resilience. Infrastructure damage and prolonged power outages highlight the urgent need for effective grid-hardening strategies. While some measures provide long-term protection against specific hazards, they can become counterproductive under conflicting threats. In this work, we develop an adaptive two-stage stochastic optimization framework to support dynamic decision-making for hardening critical grid components under multiple hazard exposures. Unlike traditional approaches, our model adapts to evolving climate conditions, enabling more resilient investment strategies. Furthermore, we integrate long-term (undergrounding) and short-term (vegetation management) hardening actions to jointly minimize total system costs. Extensive simulation results validate the effectiveness of the proposed framework in reducing outage and repair costs while enhancing the adaptability and robustness of grid infrastructure planning.

</details>


### [316] [Surrogate model of a HVAC system for PV self-consumption maximisation](https://arxiv.org/abs/2601.21390)
*B. da Costa Paulo,N. Aginako,J. Ugartemendia,I. Landa del Barrio,M. Quartulli,H. Camblong*

Main category: eess.SY

TL;DR: 本文提出一种基于主动学习的代理模型方法，以减少建筑能耗模拟的计算量，从而优化能源使用。


<details>
  <summary>Details</summary>
Motivation: 建筑是能源消耗大户，减少能源浪费和降低环境影响对经济和环境都有益。开发高效的建筑能源消耗模拟方法是实现这一目标的关键。

Method: 首先，在简化的热敏电阻电压-电流曲线回归问题上验证了基于主动学习的代理模型方法。然后，将该方法应用于建筑能耗模型的构建，以有限的模拟次数学习其能耗模式。

Result: 该代理模型能够学习建筑能耗模式，并用于设置参考温度，最大化光伏自给自足，减少电网用电。与传统方法相比，模拟所有可能消耗场景的总时间减少了约7倍。

Conclusion: 基于主动学习的代理模型是一种有效的方法，可以显著减少建筑能耗模拟的计算成本，从而为优化建筑能源管理（如提高光伏自用率和减少电网依赖）提供支持。

Abstract: In the last few years, energy efficiency has become a challenge. Not only mitigating environmental impact but reducing energy waste can lead to financial advantages. Buildings play an important role in this: they are among the biggest consumers. So, finding manners to reduce energy consumption is a way to minimise energy waste, and a technique for that is creating Demand Response (DR) strategies. This paper proposes a novel way to decrease computational effort of simulating the behaviour of a building using surrogate models based on active learning. Before going straight to the problem of a building, which is complex and computationally costly, the paper proposes the approach of active learning to a smaller problem: with reduced simulations, regress the curve of voltage versus current of a thermo-resistor. Then, the paper implements a surrogate model of energy consumption of a building. The goal is to be able to learn the consumption pattern based on a limited number of simulations. The result given by the surrogate can be used to set the reference temperature, maximising the PV self-consumption, and reducing energy usage from the grid. Thanks to the surrogate, the total time spent to map all possible consumption scenarios is reduced around 7 times.

</details>


### [317] [Decentralized Analysis Approach for Oscillation Damping in Grid-Forming and Grid-Following Heterogeneous Power Systems](https://arxiv.org/abs/2601.21562)
*Xiang Zhu,Xiuqiang He,Hongyang Qing,Hua Geng*

Main category: eess.SY

TL;DR: 本文提出了一种去中心化的局部增益条件（LGC），用于在以逆变器为基础的资源（IBR）主导的电力系统中保证振荡阻尼。LGC约束了每个IBR与其连接点网络之间的动态增益。通过局部满足LGC，闭环极点被限制在一个期望的区域内，从而在不需要全局信息的情况下实现全系统范围的振荡阻尼。


<details>
  <summary>Details</summary>
Motivation: 随着电力系统中基于逆变器的资源（IBR）日益增多，保证其在电网中的振荡阻尼成为一个挑战，尤其是在去中心化控制和异构IBR系统环境下。需要一种能够局部实现全系统振荡阻尼的方法。

Method: 提出了一种去中心化的局部增益条件（LGC），该条件通过约束每个IBR与其连接点网络之间的动态增益来实现。此外，还提出了一种低复杂度算法来参数化LGC，为IBR提供可扩展且阻尼受限的参数调整指导。

Result: 通过局部满足LGC，可以确保闭环极点被限制在期望的区域内，从而实现全系统范围的振荡阻尼。所提出的LGC不依赖于特定的IBR动力学，适用于异构IBR系统，并且可以灵活适应不同的阻尼要求。低复杂度算法能够提供有效的参数调整。

Conclusion: 所提出的去中心化局部增益条件（LGC）是一种有效的、可扩展的解决方案，用于在IBR主导的电力系统中实现系统范围的振荡阻尼，并且适用于复杂的异构系统。该方法不需要全局信息，降低了控制的复杂性。

Abstract: This letter proposes a decentralized local gain condition (LGC) to guarantee oscillation damping in inverter-based resource (IBR)-dominated power systems. The LGC constrains the dynamic gain between each IBR and the network at its point of connection. By satisfying the LGC locally, the closed-loop poles are confined to a desired region, thereby yielding system-wide oscillation damping without requiring global information. Notably, the LGC is agnostic to different IBR dynamics, well-suited for systems with heterogeneous IBRs, and flexible to various damping requirements. Moreover, a low-complexity algorithm is proposed to parameterize LGC, providing scalable and damping-constrained parameter tuning guidance for IBRs.

</details>


### [318] [StarSD: One-for-Many Speculative Decoding](https://arxiv.org/abs/2601.21622)
*Junhao He,Feiran You,Hongyang Du*

Main category: eess.SY

TL;DR: StarSD 是一种分布式推断框架，通过单个草稿模型为多个目标模型提供服务，从而加速自回归生成，解决了现有方法在多加速器集群上的扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的投机解码方法大多为单节点设计，难以扩展到用于服务现代大型语言模型的分布式多加速器集群。

Method: StarSD 采用“一对多”的投机解码框架，使用单个草稿模型通过星型拓扑服务分布式节点上的多个目标模型，从而解耦草稿和验证过程，有效共享草稿计算。

Result: StarSD 能够使单个草稿模型被多个验证器充分利用，实现可预测的延迟和利用率提升。在真实世界的分布式推理环境中，StarSD 简化了部署，支持异构加速器的灵活资源分配，并保持输出质量。

Conclusion: StarSD 是一种实用且可扩展的框架，可以将投机解码技术应用于现代云和边缘推理基础设施，提高 LLM 的生成效率。

Abstract: Speculative decoding accelerates autoregressive generation by separating token proposal from verification, but most existing approaches are designed for single-node execution and do not scale well to multi-accelerator clusters used for serving modern Large Language Models (LLMs). We present StarSD, a one-for-many speculative decoding framework that uses a single draft model to serve multiple target models across distributed nodes via a star topology. StarSD decouples drafting and verification, enabling effective sharing of draft computation, and preventing distributed accelerators from remaining idle under bursty workloads. We provide a system-level analysis that characterizes when and why a single draft model can remain fully utilized by multiple verifiers, yielding predictable latency and utilization gains. Extensive experiments in real-world distributed inference settings demonstrate that StarSD simplifies deployment and supports flexible resource allocation across heterogeneous accelerators, while maintaining output quality. These results indicate that StarSD is a practical and scalable framework for bringing speculative decoding to modern cloud and edge inference infrastructures.

</details>


### [319] [A Thermal-Electrical Co-Optimization Framework for Active Distribution Grids with Electric Vehicles and Heat Pumps](https://arxiv.org/abs/2601.21651)
*Savvas Panagi,Chrysovalantis Spanias,Petros Aristidou*

Main category: eess.SY

TL;DR: 该研究提出了一个统一的协同优化框架，将建筑热模型与电网潮流优化相结合，以协调电动汽车、热泵和光伏系统。研究表明，这种协同优化能显著减少变压器老化、电网损耗和电压违规，并且使用二阶锥规划（SOCP）松弛方法在计算上是可行的，尤其是在低压馈线上的凸DistFlow方法表现出色。


<details>
  <summary>Details</summary>
Motivation: 电动汽车和热泵等资源的普及给配电网带来了灵活性，但也加剧了热-电耦合的复杂性，对传统的电网管理提出了挑战。

Method: 提出一个统一的协同优化框架，将经过校准的3R2C灰盒建筑热模型集成到考虑电网约束的优化潮流（OPF）中。该框架联合优化电动汽车、热泵和光伏系统，同时确保热舒适性、分布式能源限制和完整的潮流物理。为保证计算效率，对二阶锥规划（SOCP）松弛方法在低压馈线上进行了评估，并与凸DistFlow、节点注入和支路潮流等不同公式进行了比较。

Result: 在低压馈线上，即使在具有异构特性的情况下，SOCP松弛在实践中仍然是精确的。凸DistFlow方法实现了亚秒级的运行时间，并且在高渗透率下接近最优性能。协同调度能够将变压器老化减少41%，损耗减少54%，并完全消除电压违规。

Conclusion: 集成的热-电协同优化对于未来的智能电网至关重要，能够有效管理高渗透率的分布式能源，显著改善电网的运行性能。

Abstract: The growing electrification of transportation and heating through Electric Vehicles (EVs) and Heat Pumps (HPs) introduces both flexibility and complexity to Active Distribution Networks (ADNs). These resources provide substantial operational flexibility but also create tightly coupled thermal-electrical dynamics that challenge conventional network management. This paper proposes a unified co-optimization framework that integrates a calibrated 3R2C grey-box building thermal model into a network-constrained Optimal Power Flow (OPF). The framework jointly optimizes EVs, HPs, and photovoltaic systems while explicitly enforcing thermal comfort, Distributed Energy Resource (DER) limits, and full power flow physics. To maintain computational tractability, Second-Order Cone Programming (SOCP) relaxations are evaluated on a realistic low-voltage feeder. The analysis shows that, despite network heterogeneity violating some theoretical exactness conditions, the relaxation remains exact in practice. Comparative assessments of convex DistFlow, bus injection, and branch flow formulations reveal that convex DistFlow achieves sub-second runtimes and near-optimal performance even at high DER penetration levels. Simulations confirm the effectiveness of coordinated scheduling, yielding reductions of 41% in transformer aging, 54% in losses, and complete elimination of voltage violations, demonstrating the value of integrated thermal-electrical coordination in future smart grids.

</details>


### [320] [BAP-SRL: Bayesian Adaptive Priority Safe Reinforcement Learning for Vehicle Motion Planning at Mixed Traffic Intersections](https://arxiv.org/abs/2601.21679)
*Yuansheng Lian,Ke Zhang,Yaming Guo,Shen Li,Meng Li*

Main category: eess.SY

TL;DR: 提出了一种贝叶斯自适应优先级安全强化学习（BAP-SRL）运动规划框架，用于解决城市交叉口与异构交通参与者交互时的多源安全风险问题，通过概率推理动态调整约束优先级，提升了避碰率和冲突解决的平滑度。


<details>
  <summary>Details</summary>
Motivation: 现有安全强化学习方法在处理多源、动态优先级变化的交通参与者交互时存在不足，常导致梯度抵消和次优权衡，尤其在危险区域。因此需要一种能动态处理多源风险的方法。

Method: 提出贝叶斯自适应优先级安全强化学习（BAP-SRL）框架。将约束优先级视为概率推理问题，利用历史优化难度作为贝叶斯先验，即时风险证据作为似然，通过贝叶斯推理机制动态门控梯度更新，以推断潜在约束的临界性。

Result: BAP-SRL 在与随机、异构智能体交互方面优于最先进的基线方法，实现了更低的碰撞率和更平滑的冲突解决。

Conclusion: BAP-SRL 能够有效处理城市交叉口复杂多变的交通交互场景，通过概率推理动态调整安全约束优先级，克服了传统方法在处理多源风险时的局限性，提高了自主驾驶的安全性与性能。

Abstract: Navigating urban intersections, especially when interacting with heterogeneous traffic participants, presents a formidable challenge for autonomous vehicles (AVs). In such environments, safety risks arise simultaneously from multiple sources, each carrying distinct priority levels and sensitivities that necessitate differential protection preferences. While safe reinforcement learning (RL) offers a robust paradigm for constrained decision-making, existing methods typically model safety as a single constraint or employ static, heuristic weighting schemes for multiple constraints. These approaches often fail to address the dynamic nature of multi-source risks, leading to gradient cancellation that hampers learning, and suboptimal trade-offs in critical dilemma zones. To address this, we propose a Bayesian adaptive priority safe reinforcement learning (BAP-SRL) based motion planning framework. Unlike heuristic weighting schemes, BAP formulates constraint prioritization as a probabilistic inference task. By modeling historical optimization difficulty as a Bayesian prior and instantaneous risk evidence as a likelihood, BAP dynamically gates gradient updates using a Bayesian inference mechanism on latent constraint criticality. Extensive experiments demonstrate that our approach outperforms state-of-the-art baselines in handling interactions with stochastic, heterogeneous agents, achieving lower collision rates and smoother conflict resolution.

</details>


### [321] [Optimal Transport for Time-Varying Multi-Agent Coverage Control](https://arxiv.org/abs/2601.21753)
*Italo Napolitano,Mario di Bernardo*

Main category: eess.SY

TL;DR: 本文提出了一种基于最优传输理论的时变覆盖控制新框架，通过求解耦合微分方程组来动态调整智能体位置，以最小化沃塞尔斯坦距离。在一维情况下，该方法有闭式解析解，并在仿真中展现出优于现有方法的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有覆盖控制算法主要针对静态目标密度，但在环境监测、侦察等实际应用中，目标密度常随时间变化。将现有的基于最优传输的静态覆盖控制方法扩展到时变场景是一个未解决的挑战。

Method: 将时变覆盖控制问题建模为一个最优传输问题，智能体目标是最小化与连续变化的密度之间的瞬时沃塞尔斯坦距离。通过求解智能体位置和定义拉盖尔区域的对偶变量的耦合微分方程组来解决。

Result: 所提出的方法在一维域上存在闭式解析解，并在数值模拟中展示了比准静态和Voronoi方法更好的跟踪性能。

Conclusion: 本文成功地将最优传输框架推广到时变覆盖控制问题，提供了一种新颖且有效的解决方案，尤其在一维情况下具有理论和计算优势。

Abstract: Coverage control algorithms have traditionally focused on static target densities, where agents are deployed to optimally cover a fixed spatial distribution. However, many applications involve time-varying densities, including environmental monitoring, surveillance, and adaptive sensor deployment. Although time-varying coverage strategies have been studied within Voronoi-based frameworks, recent works have reformulated static coverage control as a semi-discrete optimal transport problem. Extending this optimal transport perspective to time-varying scenarios has remained an open challenge. This paper presents a rigorous optimal transport formulation for time-varying coverage control, in which agents minimize the instantaneous Wasserstein distance to a continuously evolving target density. The proposed solution relies on a coupled system of differential equations governing agent positions and the dual variables that define Laguerre regions. In one-dimensional domains, the resulting system admits a closed-form analytical solution, offering both computational benefits and theoretical insight into the structure of optimal time-varying coverage. Numerical simulations demonstrate improved tracking performance compared to quasi-static and Voronoi-based methods, validating the proposed framework.

</details>


### [322] [Learning to Dial-a-Ride: A Deep Graph Reinforcement Learning Approach to the Electric Dial-a-Ride Problem](https://arxiv.org/abs/2601.22052)
*Sten Elling Tingstad Jacobsen,Attila Lischka,Balázs Kulcsár,Anders Lindman*

Main category: eess.SY

TL;DR: 本文提出了一种基于图神经网络和注意力机制的深度强化学习方法来解决电动按需出行（E-DARP），该方法能够联合优化车辆调度、充电和用户服务质量，并在大规模实例上取得了优于传统算法的性能，且推理速度极快。


<details>
  <summary>Details</summary>
Motivation: 城市出行系统正向电动化和按需服务转型，电动按需出行（E-DARP）面临电池容量和充电动力学带来的复杂运营挑战，现有精确方法难以满足实时性需求。

Method: 采用基于图神经网络编码器和注意力驱动的路线构建策略的深度强化学习方法，直接处理边属性（如行驶时间和能耗），捕捉非欧几里得、不对称和能量依赖的路线成本，联合优化调度、充电和服务。

Result: 在基准实例上，该方法解决方案质量接近最优，计算时间大幅缩短。在包含250个请求对的大规模实例上，性能优于ALNS算法9.5%，服务完成率100%，推理时间不到1秒。敏感性分析量化了电池容量、车队规模等因素的影响，鲁棒性实验表明确定性训练策略在随机条件下泛化良好。

Conclusion: 提出的深度强化学习方法能够有效地解决E-DARP问题，在保证高质量解决方案的同时，实现了极高的计算效率，并展现出良好的泛化能力，为电动按需出行服务的实时调度提供了有前景的解决方案。

Abstract: Urban mobility systems are transitioning toward electric, on-demand services, creating operational challenges for fleet management under energy and service-quality constraints. The Electric Dial-a-Ride Problem (E-DARP) extends the classical dial-a-ride problem by incorporating limited battery capacity and nonlinear charging dynamics, increasing computational complexity and limiting the scalability of exact methods for real-time use. This paper proposes a deep reinforcement learning approach based on a graph neural network encoder and an attention-driven route construction policy. By operating directly on edge attributes such as travel time and energy consumption, the method captures non-Euclidean, asymmetric, and energy-dependent routing costs in real road networks. The learned policy jointly optimizes routing, charging, and service quality without relying on Euclidean assumptions or handcrafted heuristics. The approach is evaluated on two case studies using ride-sharing data from San Francisco. On benchmark instances, the method achieves solutions within 0.4% of best-known results while reducing computation times by orders of magnitude. A second case study considers large-scale instances with up to 250 request pairs, realistic energy models, and nonlinear charging. On these instances, the learned policy outperforms Adaptive Large Neighborhood Search (ALNS) by 9.5% in solution quality while achieving 100% service completion, with sub-second inference times compared to hours for the metaheuristic. Finally, sensitivity analyses quantify the impact of battery capacity, fleet size, ride-sharing capacity, and reward weights, while robustness experiments show that deterministically trained policies generalize effectively under stochastic conditions.

</details>


### [323] [A Gradient-Based Capacity Accreditation Framework in Resource Adequacy: Formulation, Computation, and Practical Implications](https://arxiv.org/abs/2601.22087)
*Qian Zhang,Feng Zhao,Gord Stephen,Chanan Singh,Le Xie*

Main category: eess.SY

TL;DR: 本文提出了一种基于梯度的框架，将容量认证视为资源容量的概率性资源充分性指标的导数，统一了ELCC和MRI两种方法，并展示了如何通过无穷小扰动分析加速计算，以及梯度搜索算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高现代电力系统中容量认证的效率和可扩展性，统一并加速两种广泛使用的认证方法ELCC和MRI。

Method: 开发了一个基于梯度的框架，将容量认证解释为概率性资源充分性指标关于资源容量的导数。利用无穷小扰动分析（IPA）进行梯度估计，并实现梯度信息指导的搜索算法。

Result: 证明了边际ELCC和MRI在特定条件下是等价的，但计算特性不同。IPA可实现高达1000倍的加速。梯度搜索算法显著加快了ELCC的计算速度。MRI相较于ELCC在运行时和扰动步长选择的鲁棒性方面表现出显著优势。

Conclusion: 该研究为大规模电力系统中高效可扩展的容量认证提供了实际指导，揭示了ELCC和MRI的统一性与差异性，并提出了加速计算的方法。

Abstract: Probabilistic resource adequacy assessment is a cornerstone of modern capacity accreditation. This paper develops a gradient-based framework, in which capacity accreditation is interpreted as the directional derivative of a probabilistic resource adequacy metric with respect to resource capacity, that unifies two widely used accreditation approaches: Effective Load Carrying Capability (ELCC) and Marginal Reliability Impact (MRI). Under mild regularity conditions, we show that marginal ELCC and MRI yield equivalent accreditation factors, while their numerical implementations exhibit markedly different computational characteristics. Building on this framework, we demonstrate how infinitesimal perturbation analysis enables up to a $1000\times$ speedup in gradient estimation for capacity accreditation, and we implement gradient-informed search algorithms that significantly accelerate ELCC computations relative to standard bisection methods. Large-scale Monte Carlo experiments show that MRI achieves substantial runtime reductions compared to ELCC and exhibits greater robustness to perturbation step-size selection. These results provide practical guidance for implementing efficient and scalable capacity accreditation in large-scale power systems.

</details>


### [324] [Reformulating Energy Storage Capacity Accreditation Problem with Marginal Reliability Impact](https://arxiv.org/abs/2601.22096)
*Qian Zhang,Feng Zhao,Tongxin Zheng,Le Xie*

Main category: eess.SY

TL;DR: 本文提出了一种基于边际可靠性影响（MRI）的新方法来评估储能容量市场的效率，通过优化方法直接计算MRI，并分析了关键因素对储能容量认证的影响，为政策制定者和系统运营商提供了指导。


<details>
  <summary>Details</summary>
Motivation: 为了提高容量市场的效率，美国许多电力市场正在改革以采用边际容量认证。

Method: 将基于可靠性的储能调度模型重构为优化问题，直接从拉格朗日乘子计算MRI，而非使用扰动分析。分析了合格容量（QC）、储能调度规则等因素对储能认证的影响，并对比了不同可靠性标准下的储能容量认证。

Result: 能量未满足（EUE）是分段线性函数，储能MRI在各种系统场景下保持非负性。计算结果显示了MRI认证方案下的重要现象。

Conclusion: 提出的MRI方法为储能容量认证提供了新的见解，并为系统运营商和政策制定者在设置未来标准方面提供了实用指导。

Abstract: To enhance the efficiency of capacity markets, many electricity markets in the U.S. are adopting or planning to implement marginal capacity accreditation reforms. This paper provides new insights into energy storage capacity accreditation using Marginal Reliability Impact (MRI). We reformulate the commonly used reliability-based storage dispatch model as an optimization problem, enabling direct calculation of the MRI from the Lagrange multipliers, rather than using brute-force perturbation analysis. The analysis demonstrates that the EUE is a piecewise linear function and the storage MRI retains a non-negative property across various system scenarios. We further explore the influence of qualified capacity (QC), storage dispatch rules, and other key factors on storage accreditation, providing practical insights for system operators. Additionally, comparisons of storage capacity accreditation under different reliability criteria offer valuable guidance for policymakers in setting future standards. Numerical results from a modified California system validate our findings and highlight several important phenomena associated with the MRI-based accreditation scheme.

</details>


### [325] [Comparative Assessment of Look-Ahead Economic Dispatch and Ramp Products for Grid Flexibility](https://arxiv.org/abs/2601.22120)
*Qian Zhang,Le Xie,Long Zhao,Congcong Wang*

Main category: eess.SY

TL;DR: 本文通过线性优化模型比较了前瞻性经济调度（LAED）和爬坡容量产品（RP）在应对高可再生能源渗透率下的净负荷爬坡问题。研究表明，在滚动窗口调度下，增强的RP模型在特定条件下可以匹配LAED的可调度区域，但由于优化目标不同，两者在滚动窗口操作下最终状态仍有差异。仿真结果显示，LAED在减少弃负荷方面通常优于RP，尤其在高负荷、爬坡受限的情况下。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源渗透率的提高，电网面临着更频繁和更大的净负荷爬坡挑战，需要实时灵活性来应对。LAED和RP是常用的解决方案，但其在行业标准滚动窗口调度下的运行等价性尚不明确。

Method: 使用线性优化模型分别建立了多区间LAED和基于RP的联合优化模型。通过理论推导和仿真实验，分析了这两种方法的调度可行区域、端点状态以及在不同系统和工况下的弃负荷表现。

Result: 1. 增强的RP模型在施加附加的跨时间可传递性约束后，可以在单时间步内匹配LAED的可调度区域。2. 在滚动窗口操作下，LAED和RP由于优化不同的跨时间目标，其端点状态会发生分化，导致等价性无法普遍保持。3. 在不同测试系统和工况下，LAED实现的弃负荷量通常与RP相当或更低，尤其在高负荷、爬坡受限条件下差异更明显。

Conclusion: 当前RP的实现存在局限性，尤其是在滚动窗口调度和高可再生能源渗透率的场景下。研究建议通过引入更多中等持续时间的RP来增强其性能，并为未来RP的设计提供参考。

Abstract: High renewable penetration increases the frequency and magnitude of net-load ramps, stressing real-time flexibility. Two commonly deployed remedies are look-ahead economic dispatch (LAED) and ramp products (RPs), yet their operational equivalence under the industry-standard rolling-window dispatch implementation is not well understood. This paper develops linear optimization models for multi-interval LAED and RP-based co-optimization, and proves that an enhanced RP formulation can match LAED's dispatch feasible region at a single time step when additional intertemporal deliverability constraints are enforced. We then show that this equivalence does not generally persist under rolling-window operation because LAED and RP formulations optimize different intertemporal objectives, leading to divergent end-of-window states. Using different test systems under stressed ramping conditions and multiple load levels, we show LAED achieves similar or lower load shedding than RP implementations with the same look-ahead horizon, with the most pronounced differences under high-load, ramp-limited conditions. The study highlights the limitations of current ramp product implementations and suggests enhancements, such as introducing more mid-duration RPs.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [326] [Wrapper-Aware Rate-Distortion Optimization in Feature Coding for Machines](https://arxiv.org/abs/2601.22070)
*Samuel Fernández-Menduiña,Hyomin Choi,Fabien Racapé,Eduardo Pavez,Antonio Ortega*

Main category: eess.IV

TL;DR: 本文提出了一种用于改进特征编码（FCM）的 wrapper-aware rate-distortion optimization (WA-RDO) 方法，通过使用加权 SSE 指标来优化比特分配，并采用时间复用和离线训练的固定权重策略，在 HEVC 编码器上取得了与 VVC 相当的性能，同时保持了最小的运行时开销。


<details>
  <summary>Details</summary>
Motivation: 现有的 FCM 方法在训练 wrapper 时使用代理编解码器，并在实际应用中替换为标准编解码器。由于标准编解码器的 rate-distortion optimization (RDO) 基于总和平方误差 (SSE) 且不考虑后处理 wrapper，可能导致编解码器在保留被后处理丢弃的信息上浪费比特。

Method: 本文提出了 wrapper-aware weighted SSE metric 来修改比特分配，并提出两种方法使 WA-RDO 在 FCM 中更实用：1) 在一组图片之间进行权重的时域复用；2) 使用离线训练的固定、与架构和任务相关的权重。

Result: 所提出的方法在 HEVC 编码器上实现了与基于 VVC 的 FCM 现有技术相当的性能，有效弥合了编解码器代际差距。与 SSE-RDO HEVC 相比，运行时开销极小。

Conclusion: 通过 wrapper-aware RDO 和优化的权重策略，可以有效地改进 FCM 中的比特分配，从而在不同代际的视频编解码器之间实现性能的良好匹配，并降低运行时开销。

Abstract: Feature coding for machines (FCM) is a lossy compression paradigm for split-inference. The transmitter encodes the outputs of the first part of a neural network before sending them to the receiver for completing the inference. Practical FCM methods ``sandwich'' a traditional codec between pre- and post-processing neural networks, called wrappers, to make features easier to compress using video codecs. Since traditional codecs are non-differentiable, the wrappers are trained using a proxy codec, which is later replaced by a standard codec after training. These codecs perform rate-distortion optimization (RDO) based on the sum of squared errors (SSE). Because the RDO does not consider the post-processing wrapper, the inner codec can invest bits in preserving information that the post-processing later discards. In this paper, we modify the bit-allocation in the inner codec via a wrapper-aware weighted SSE metric. To make wrapper-aware RDO (WA-RDO) practical for FCM, we propose: 1) temporal reuse of weights across a group of pictures and 2) fixed, architecture- and task-dependent weights trained offline. Under MPEG test conditions, our methods implemented on HEVC match the VVC-based FCM state-of-the-art, effectively bridging a codec generation gap with minimal runtime overhead relative to SSE-RDO HEVC.

</details>


### [327] [Denoising and Baseline Correction of Low-Scan FTIR Spectra: A Benchmark of Deep Learning Models Against Traditional Signal Processing](https://arxiv.org/abs/2601.20905)
*Azadeh Mokari,Shravan Raghunathan,Artem Shydliukh,Oleg Ryabchykov,Christoph Krafft,Thomas Bocklitz*

Main category: eess.IV

TL;DR: 提出了一种物理信息级联Unet模型，通过集成的SNIP层强制执行光谱约束，有效分离去噪和基线校正任务，相比传统方法和单一Unet模型，显著提高了FTIR成像质量和速度，解决了光谱幻觉和基线漂移问题。


<details>
  <summary>Details</summary>
Motivation: 现有高质量FTIR成像需要长时间信号平均，限制了临床应用速度。深度学习可以加速成像，但从单次扫描重建光谱面临去噪和基线校正的病态逆问题，且现有模型常出现光谱幻觉或泛化能力差。

Method: 提出了一种物理信息级联Unet模型，包含一个物理桥（Physics Bridge），将去噪和基线校正任务解耦。模型集成了SNIP层，强制执行光谱约束，而非依赖统计近似。在人下咽癌细胞（FaDu）数据集上进行了基准测试，并与单Unet和传统的Savitzky-Golay/SNIP流程进行了比较。

Result: 该级联模型在减少均方根误差（RMSE）方面优于其他方法，比原始单次扫描输入减少了51.3%，显著优于单Unet（40.2%）和传统流程（33.7%）。峰值感知指标显示，该模型消除了标准深度学习模型中的光谱幻觉，并且比传统平滑方法更能保真峰值强度。

Conclusion: 该级联Unet模型是诊断级FTIR成像的稳健解决方案，能够将成像速度提高32倍，同时有效解决光谱幻觉和基线漂移问题，并提高成像质量。

Abstract: High-quality Fourier Transform Infrared (FTIR) imaging usually needs extensive signal averaging to reduce noise and drift which severely limits clinical speed. Deep learning can accelerate imaging by reconstructing spectra from rapid, single-scan inputs. However, separating noise and baseline drift simultaneously without ground truth is an ill-posed inverse problem. Standard black-box architectures often rely on statistical approximations that introduce spectral hallucinations or fail to generalize to unstable atmospheric conditions. To solve these issues we propose a physics-informed cascade Unet that separates denoising and baseline correction tasks using a new, deterministic Physics Bridge. This architecture forces the network to separate random noise from chemical signals using an embedded SNIP layer to enforce spectroscopic constraints instead of learning statistical approximations. We benchmarked this approach against a standard single Unet and a traditional Savitzky-Golay/SNIP workflow. We used a dataset of human hypopharyngeal carcinoma cells (FaDu). The cascade model outperformed all other methods, achieving a 51.3% reduction in RMSE compared to raw single-scan inputs, surpassing both the single Unet (40.2%) and the traditional workflow (33.7%). Peak-aware metrics show that the cascade architecture eliminates spectral hallucinations found in standard deep learning. It also preserves peak intensity with much higher fidelity than traditional smoothing. These results show that the cascade Unet is a robust solution for diagnostic-grade FTIR imaging. It enables imaging speeds 32 times faster than current methods.

</details>


### [328] [CompSRT: Quantization and Pruning for Image Super Resolution Transformers](https://arxiv.org/abs/2601.21069)
*Dorsa Zeinali,Hailing Wang,Yitian Zhang,Raymond Fu*

Main category: eess.IV

TL;DR: 本文提出了一种名为CompSRT的图像超分辨率模型（SwinIR-light）的压缩方法，结合了Hadamard变换和标量分解，显著提升了压缩性能，并与剪枝技术兼容。


<details>
  <summary>Details</summary>
Motivation: 现有模型压缩方法在性能上与全精度模型仍有差距，需要更深入的理解和更优的压缩理论，尤其是在性能更强的模型上。

Method: 通过对SwinIR-light模型权值和激活值的分布进行统计分析，发现Hadamard变换能缩小值域并增加接近0的值的比例，从而降低误差。在此基础上，提出CompSRT方法，结合Hadamard变换量化和引入两个可训练参数的标量分解。

Result: CompSRT在图像超分辨率任务上取得了显著的性能提升，PSNR指标最高提升1.53 dB，且在视觉上减少了模糊。与剪枝技术结合时，能在保证性能的情况下进一步降低比特数。

Conclusion: Hadamard变换通过缩小值域和增加接近0的值的比例来提高量化精度。CompSRT方法在SwinIR-light模型压缩方面优于当前最先进的方法，并且与剪枝兼容，为图像超分辨率模型的效率提升提供了新的途径。

Abstract: Model compression has become an important tool for making image super resolution models more efficient. However, the gap between the best compressed models and the full precision model still remains large and a need for deeper understanding of compression theory on more performant models remains. Prior research on quantization of LLMs has shown that Hadamard transformations lead to weights and activations with reduced outliers, which leads to improved performance. We argue that while the Hadamard transform does reduce the effect of outliers, an empirical analysis on how the transform functions remains needed. By studying the distributions of weights and activations of SwinIR-light, we show with statistical analysis that lower errors is caused by the Hadamard transforms ability to reduce the ranges, and increase the proportion of values around $0$. Based on these findings, we introduce CompSRT, a more performant way to compress the image super resolution transformer network SwinIR-light. We perform Hadamard-based quantization, and we also perform scalar decomposition to introduce two additional trainable parameters. Our quantization performance statistically significantly surpasses the SOTA in metrics with gains as large as 1.53 dB, and visibly improves visual quality by reducing blurriness at all bitwidths. At $3$-$4$ bits, to show our method is compatible with pruning for increased compression, we also prune $40\%$ of weights and show that we can achieve $6.67$-$15\%$ reduction in bits per parameter with comparable performance to SOTA.

</details>


### [329] [Blind Ultrasound Image Enhancement via Self-Supervised Physics-Guided Degradation Modeling](https://arxiv.org/abs/2601.21856)
*Shujaat Khan,Syed Muhammad Atif,Jaeyoung Huh,Syed Saad Azhar*

Main category: eess.IV

TL;DR: 本文提出了一种无需真实清晰图像即可进行超声图像增强的盲、自监督框架，通过物理引导的退化模型联合去卷积和去噪，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统的超声图像增强方法依赖于真实清晰图像或已知的退化模型，这在实际应用中难以满足。作者旨在开发一种更实用、假设更少的盲增强方法。

Method: 研究人员使用 Swin Convolutional U-Net，并结合物理引导的退化模型，实现了联合去卷积和去噪。该模型通过在训练帧上提取旋转/裁剪的斑块，并应用高斯 PSF 卷积和高斯噪声或傅立叶域扰动来模拟退化，从而合成输入。对于超声扫描，使用非局部低秩（NLLR）去噪获取接近清晰的图像作为目标；对于自然图像，则使用原始图像作为目标。

Result: 该方法在多个数据集（UDIAT~B, JNU-IFM, XPIE Set-P, PSFHS）上进行了训练和评估，在各种噪声水平下取得了最高的 PSNR/SSIM 值。与现有方法（MSANN, Restormer, DnCNN）相比，在强高斯噪声和严重散斑噪声下，PSNR 和 SSIM 指标均有显著提升。此外，实验表明该方法能够恢复分辨率而不引起边缘侵蚀，并能提升分割任务的 Dice 分数。

Conclusion: 该方法提供了一种实用的、假设较少的超声图像增强路径，能够有效处理多种退化，并且在不同数据集、扫描仪和退化类型上都表现出良好的泛化能力。

Abstract: Ultrasound (US) interpretation is hampered by multiplicative speckle, acquisition blur from the point-spread function (PSF), and scanner- and operator-dependent artifacts. Supervised enhancement methods assume access to clean targets or known degradations; conditions rarely met in practice. We present a blind, self-supervised enhancement framework that jointly deconvolves and denoises B-mode images using a Swin Convolutional U-Net trained with a \emph{physics-guided} degradation model. From each training frame, we extract rotated/cropped patches and synthesize inputs by (i) convolving with a Gaussian PSF surrogate and (ii) injecting noise via either spatial additive Gaussian noise or complex Fourier-domain perturbations that emulate phase/magnitude distortions. For US scans, clean-like targets are obtained via non-local low-rank (NLLR) denoising, removing the need for ground truth; for natural images, the originals serve as targets. Trained and validated on UDIAT~B, JNU-IFM, and XPIE Set-P, and evaluated additionally on a 700-image PSFHS test set, the method achieves the highest PSNR/SSIM across Gaussian and speckle noise levels, with margins that widen under stronger corruption. Relative to MSANN, Restormer, and DnCNN, it typically preserves an extra $\sim$1--4\,dB PSNR and 0.05--0.15 SSIM in heavy Gaussian noise, and $\sim$2--5\,dB PSNR and 0.05--0.20 SSIM under severe speckle. Controlled PSF studies show reduced FWHM and higher peak gradients, evidence of resolution recovery without edge erosion. Used as a plug-and-play preprocessor, it consistently boosts Dice for fetal head and pubic symphysis segmentation. Overall, the approach offers a practical, assumption-light path to robust US enhancement that generalizes across datasets, scanners, and degradation types.

</details>


### [330] [ECGFlowCMR: Pretraining with ECG-Generated Cine CMR Improves Cardiac Disease Classification and Phenotype Prediction](https://arxiv.org/abs/2601.20904)
*Xiaocheng Fang,Zhengyao Ding,Jieyi Cai,Yujie Xiao,Bo Liu,Jiarui Jin,Haoyu Wang,Guangkun Nie,Shun Huang,Ting Chen,Hongyan Li,Shenda Hong*

Main category: eess.IV

TL;DR: 提出了一种名为ECGFlowCMR的新型框架，利用ECG信号生成cine CMR图像，解决了跨模态时间不匹配和ECG信息不足的问题，并在实际数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: CMR成像成本高且依赖专家标注，限制了大型数据集的可用性。ECG廉价易得，可用于条件生成CMR，但存在跨模态时间不匹配和解剖信息不足的挑战。

Method: 提出ECGFlowCMR框架，包含相位感知掩码自编码器（PA-MAE）和解耦体流动（AMDF），以解决跨模态时间不匹配和解剖可观察性差距问题。

Result: ECGFlowCMR能够从ECG输入生成逼真的cine CMR序列，可用于可扩展预训练，并提升下游心脏病分类和表型预测任务的性能。

Conclusion: ECGFlowCMR框架成功地利用ECG信号生成了高质量的cine CMR图像，克服了现有方法的局限性，并对下游临床应用具有重要意义。

Abstract: Cardiac Magnetic Resonance (CMR) imaging provides a comprehensive assessment of cardiac structure and function but remains constrained by high acquisition costs and reliance on expert annotations, limiting the availability of large-scale labeled datasets. In contrast, electrocardiograms (ECGs) are inexpensive, widely accessible, and offer a promising modality for conditioning the generative synthesis of cine CMR. To this end, we propose ECGFlowCMR, a novel ECG-to-CMR generative framework that integrates a Phase-Aware Masked Autoencoder (PA-MAE) and an Anatomy-Motion Disentangled Flow (AMDF) to address two fundamental challenges: (1) the cross-modal temporal mismatch between multi-beat ECG recordings and single-cycle CMR sequences, and (2) the anatomical observability gap due to the limited structural information inherent in ECGs. Extensive experiments on the UK Biobank and a proprietary clinical dataset demonstrate that ECGFlowCMR can generate realistic cine CMR sequences from ECG inputs, enabling scalable pretraining and improving performance on downstream cardiac disease classification and phenotype prediction tasks.

</details>
