<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 21]
- [cs.CV](#cs.CV) [Total: 90]
- [cs.CL](#cs.CL) [Total: 49]
- [cs.RO](#cs.RO) [Total: 16]
- [eess.SY](#eess.SY) [Total: 18]
- [eess.IV](#eess.IV) [Total: 12]
- [math.OC](#math.OC) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics](https://arxiv.org/abs/2507.17777)
*Theofanis Aravanis,Grigorios Chrimatopoulos,Mohammad Ferdows,Michalis Xenos,Efstratios Em Tzirtzilakis*

Main category: cs.AI

TL;DR: 本研究利用符号回归（SR）从数值模拟数据中推导出三维不可压缩通道流的解析方程，并提出结合SR与回答集编程（ASP）的混合框架，以确保模型的物理合理性。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习方法常被视为“黑箱”，而在流体力学中，对底层流动物理的理解与准确预测同等重要。因此，研究旨在寻找一种无需先验假设即可揭示复杂物理系统中可解释数学关系的方法。

Method: 使用PySR库对矩形通道内的三维层流不可压缩流（轴向速度和压力场）的数值模拟数据进行符号回归。此外，提出了一种创新的混合方法，将SR与回答集编程（ASP）知识表示框架相结合，利用ASP的声明性推理能力来确保SR生成的符号表达式不仅统计准确，而且物理上合理并符合领域特定原则。

Result: 成功从数值模拟数据中推导出紧凑的符号方程，这些方程不仅近似了观察到的抛物线速度分布和压降，而且与文献中的解析解完美吻合。提出的SR/ASP混合框架能够确保SR生成的表达式既统计准确又具有物理合理性。

Conclusion: 研究表明，符号回归能够将复杂的流动行为简化为简洁、可解释的方程，并且知识表示方法（如ASP）能够显著提高数据驱动SR模型的可靠性及其与领域原理的一致性。这种混合方法为需要可解释预测和实时数据分析的框架奠定了基础。

Abstract: Unlike conventional Machine-Learning (ML) approaches, often criticized as
"black boxes", Symbolic Regression (SR) stands out as a powerful tool for
revealing interpretable mathematical relationships in complex physical systems,
requiring no a priori assumptions about models' structures. Motivated by the
recognition that, in fluid mechanics, an understanding of the underlying flow
physics is as crucial as accurate prediction, this study applies SR to model a
fundamental three-dimensional (3D) incompressible flow in a rectangular
channel, focusing on the (axial) velocity and pressure fields under laminar
conditions. By employing the PySR library, compact symbolic equations were
derived directly from numerical simulation data, revealing key characteristics
of the flow dynamics. These equations not only approximate the parabolic
velocity profile and pressure drop observed in the studied fluid flow, but also
perfectly coincide with analytical solutions from the literature. Furthermore,
we propose an innovative approach that integrates SR with the
knowledge-representation framework of Answer Set Programming (ASP), combining
the generative power of SR with the declarative reasoning strengths of ASP. The
proposed hybrid SR/ASP framework ensures that the SR-generated symbolic
expressions are not only statistically accurate, but also physically plausible,
adhering to domain-specific principles. Overall, the study highlights two key
contributions: SR's ability to simplify complex flow behaviours into concise,
interpretable equations, and the potential of knowledge-representation
approaches to improve the reliability and alignment of data-driven SR models
with domain principles. Insights from the examined 3D channel flow pave the way
for integrating such hybrid approaches into efficient frameworks, [...] where
explainable predictions and real-time data analysis are crucial.

</details>


### [2] [I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis](https://arxiv.org/abs/2507.17874)
*SaiBarath Sundar,Pranav Satheesan,Udayaadithya Avadhanam*

Main category: cs.AI

TL;DR: 本文提出I2I-STRADA，一种用于数据分析的智能体架构，通过形式化结构化推理过程，将分析分解为模块化子任务，以模拟人类认知步骤，从而在基准测试中优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 现有数据分析智能体系统（如多智能体框架和编排层）在任务管理上有效，但忽视了分析思维背后的结构化推理过程。通用型LLM在多步问题解决中缺乏针对特定任务的固定推理流程，而实际数据分析需要一致的认知工作流（解释目标、联系上下文、构建计划、适应执行）。

Method: 引入I2I-STRADA（Information-to-Insight via Structured Reasoning Agent for Data Analysis），一个旨在形式化数据分析中推理过程的智能体架构。它专注于通过反映分析推理认知步骤的模块化子任务来建模分析的展开方式。

Result: 在DABstep和DABench基准测试上的评估显示，I2I-STRADA在规划连贯性和洞察对齐方面优于现有系统。

Conclusion: 结构化认知工作流在数据分析智能体设计中至关重要，能够显著提升系统性能。

Abstract: Recent advances in agentic systems for data analysis have emphasized
automation of insight generation through multi-agent frameworks, and
orchestration layers. While these systems effectively manage tasks like query
translation, data transformation, and visualization, they often overlook the
structured reasoning process underlying analytical thinking. Reasoning large
language models (LLMs) used for multi-step problem solving are trained as
general-purpose problem solvers. As a result, their reasoning or thinking steps
do not adhere to fixed processes for specific tasks. Real-world data analysis
requires a consistent cognitive workflow: interpreting vague goals, grounding
them in contextual knowledge, constructing abstract plans, and adapting
execution based on intermediate outcomes. We introduce I2I-STRADA
(Information-to-Insight via Structured Reasoning Agent for Data Analysis), an
agentic architecture designed to formalize this reasoning process. I2I-STRADA
focuses on modeling how analysis unfolds via modular sub-tasks that reflect the
cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench
benchmarks show that I2I-STRADA outperforms prior systems in planning coherence
and insight alignment, highlighting the importance of structured cognitive
workflows in agent design for data analysis.

</details>


### [3] [SMARTAPS: Tool-augmented LLMs for Operations Management](https://arxiv.org/abs/2507.17927)
*Timothy Tin Long Yu,Mahdi Mostajabdaveh,Jabo Serge Byusa,Rindra Ramamonjison,Giuseppe Carenini,Kun Mao,Zirui Zhou,Yong Zhang*

Main category: cs.AI

TL;DR: SmartAPS是一个基于工具增强型LLM的对话式系统，旨在通过自然语言界面降低高级计划系统(APS)的使用门槛，帮助运营规划者管理其操作。


<details>
  <summary>Details</summary>
Motivation: 传统高级计划系统(APS)因定制和维护成本高昂（需顾问支持）而难以普及，许多客户无法负担。供应链规划者急需一个更易于访问的APS。

Method: 开发了SmartAPS，一个基于工具增强型大型语言模型(LLM)构建的对话系统。该系统提供直观的自然语言聊天界面。

Result: SmartAPS使运营规划者能够通过自然语言查询信息、进行反事实推理、接收建议以及执行情景分析，从而更好地管理其运营。

Conclusion: SmartAPS通过利用LLM提供对话式接口，显著提高了高级计划系统的可访问性和易用性，有望帮助更多规划者有效管理其运营。

Abstract: Large language models (LLMs) present intriguing opportunities to enhance user
interaction with traditional algorithms and tools in real-world applications.
An advanced planning system (APS) is a sophisticated software that leverages
optimization to help operations planners create, interpret, and modify an
operational plan. While highly beneficial, many customers are priced out of
using an APS due to the ongoing costs of consultants responsible for
customization and maintenance. To address the need for a more accessible APS
expressed by supply chain planners, we present SmartAPS, a conversational
system built on a tool-augmented LLM. Our system provides operations planners
with an intuitive natural language chat interface, allowing them to query
information, perform counterfactual reasoning, receive recommendations, and
execute scenario analysis to better manage their operation. A short video
demonstrating the system has been released: https://youtu.be/KtIrJjlDbyw

</details>


### [4] [Synthesis of timeline-based planning strategies avoiding determinization](https://arxiv.org/abs/2507.17988)
*Dario Della Monica,Angelo Montanari,Pietro Sala*

Main category: cs.AI

TL;DR: 本文识别了定性时间线规划的一个片段，其计划存在问题可直接映射到确定性有限自动机（DFA）的非空性问题，从而可以直接合成规划策略，并确定了适用于此片段的Allen关系的最大子集。


<details>
  <summary>Details</summary>
Motivation: 定性时间线规划的计划存在问题是PSPACE完全的，虽然可以通过归约到非确定性有限自动机（NFA）的非空性问题来证明PSPACE成员资格，但NFA无法直接用于合成规划策略，需要昂贵的确定化步骤。研究的动机是为了找到一种无需昂贵确定化步骤、能直接合成规划策略的方法。

Method: 研究方法是识别定性时间线规划的一个特定片段，使其计划存在问题可以直接映射到确定性有限自动机的非空性问题。此外，还识别了Allen关系中符合此确定性片段的最大子集。

Result: 主要结果是成功识别了一个定性时间线规划的片段，其计划存在问题可以直接映射到确定性有限自动机的非空性问题，从而可以直接合成策略。同时，也识别了适合此确定性片段的Allen关系的最大子集。

Conclusion: 结论是，通过识别定性时间线规划的一个特定片段，可以绕过非确定性有限自动机所需的昂贵确定化步骤，直接利用确定性有限自动机来合成规划策略，这为该领域的策略合成提供了一条更直接的途径。

Abstract: Qualitative timeline-based planning models domains as sets of independent,
but
  interacting, components whose behaviors over time, the timelines, are
governed
  by sets of qualitative temporal constraints (ordering relations), called
  synchronization rules.
  Its plan-existence problem has been shown to be PSPACE-complete; in
  particular, PSPACE-membership has been proved via reduction to the
  nonemptiness problem for nondeterministic finite automata.
  However, nondeterministic automata cannot be directly used to synthesize
  planning strategies as a costly determinization step is needed.
  In this paper, we identify a fragment of qualitative timeline-based planning
  whose plan-existence problem can be directly mapped into the nonemptiness
  problem of deterministic finite automata, which can then
  synthesize strategies.
  In addition, we identify a maximal subset of Allen's relations that fits into
  such a deterministic fragment.

</details>


### [5] [E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI](https://arxiv.org/abs/2507.18004)
*Yusen Peng,Shuhua Mao*

Main category: cs.AI

TL;DR: 该论文提出E.A.R.T.H.框架，一个五阶段生成流程，通过将模型生成的错误转化为创意资产，显著提升了AI的创造力。


<details>
  <summary>Details</summary>
Motivation: 当前的AI模型倾向于模仿，而非展现真正的创造力。研究旨在探索如何让AI超越模仿，实现真正的创造性，并提出“创造潜力隐藏在失败中”的观点。

Method: 提出了E.A.R.T.H.框架，包含错误生成、放大、精炼选择、转换和反馈利用五个阶段。技术实现上，使用了LLaMA-2-7B-Chat、SBERT、BERTScore、CLIP、BLIP-2和Stable Diffusion等模型，并采用基于新颖性、惊喜度和相关性的复合奖励函数。方法还包括结构化提示、语义评分和人机协作评估。

Result: 在精炼阶段，创造力得分提升了52.5%（从1.179到1.898），最终输出达到2.010，总提升70.4%。精炼后的标语短了48.4%，新颖性增加了40.7%，相关性仅下降4.0%。跨模态测试显示标语与图像对齐度高（CLIPScore: 0.249; BERTScore F1: 0.816）。在人工评估中，60%的输出得分>=4.0，其中隐喻性标语（平均4.09）优于字面性标语（3.99）。反馈强调了风格精确性和情感共鸣。

Conclusion: 以错误为中心、反馈驱动的生成方法能够显著增强AI的创造力，为实现自我演化、与人类对齐的创意AI提供了一条可扩展的路径。

Abstract: How can AI move beyond imitation toward genuine creativity? This paper
proposes the E.A.R.T.H. framework, a five-stage generative pipeline that
transforms model-generated errors into creative assets through Error
generation, Amplification, Refine selection, Transform, and Harness feedback.
Drawing on cognitive science and generative modeling, we posit that "creative
potential hides in failure" and operationalize this via structured prompts,
semantic scoring, and human-in-the-loop evaluation. Implemented using
LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the
pipeline employs a composite reward function based on novelty, surprise, and
relevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to
1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4%
improvement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a
4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment
(CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs
scored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones
(3.99). Feedback highlights stylistic precision and emotional resonance. These
results demonstrate that error-centered, feedback-driven generation enhances
creativity, offering a scalable path toward self-evolving, human-aligned
creative AI.

</details>


### [6] [Does visualization help AI understand data?](https://arxiv.org/abs/2507.18022)
*Victoria R. Li,Johnathan Sun,Martin Wattenberg*

Main category: cs.AI

TL;DR: 研究发现，AI系统在分析数据时，像人类一样，能够从数据可视化（如散点图）中获益，尤其是在处理复杂数据集时。


<details>
  <summary>Details</summary>
Motivation: 探讨数据图表（如散点图）除了帮助人类分析数据外，是否也能对AI系统有所助益。

Method: 使用两个商业视觉-语言模型（GPT 4.1和Claude 3.5），在三个代表性分析任务上进行实验。通过提供原始数据、附带散点图的数据、空白图表和数据不匹配图表等不同形式的数据，比较模型对合成数据集的描述精度和准确性。

Result: 当原始数据附带散点图时，两个AI系统都能更精确、更准确地描述合成数据集，尤其是在数据集复杂度增加时。与提供空白图表和数据不匹配图表的基线比较表明，性能提升是由于图表内容的帮助。

Conclusion: 初步证据表明，AI系统与人类一样，可以从数据可视化中受益。

Abstract: Charts and graphs help people analyze data, but can they also be useful to AI
systems? To investigate this question, we perform a series of experiments with
two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three
representative analysis tasks, the two systems describe synthetic datasets more
precisely and accurately when raw data is accompanied by a scatterplot,
especially as datasets grow in complexity. Comparison with two baselines --
providing a blank chart and a chart with mismatched data -- shows that the
improved performance is due to the content of the charts. Our results are
initial evidence that AI systems, like humans, can benefit from visualization.

</details>


### [7] [Multi-Agent Guided Policy Optimization](https://arxiv.org/abs/2507.18059)
*Yueheng Li,Guangming Xie,Zongqing Lu*

Main category: cs.AI

TL;DR: MAGPO是一种新的多智能体强化学习框架，它通过整合集中式引导和分散式执行，解决了现有CTDE方法未能充分利用集中式训练或缺乏理论保证的问题，并在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在合作多智能体强化学习（MARL）中，尽管集中式训练分散式执行（CTDE）是主流范式，但现有CTDE方法往往未能充分利用集中式训练的优势，或缺乏理论保证。

Method: 本文提出了多智能体引导策略优化（MAGPO）框架。该框架通过整合集中式引导与分散式执行，更好地利用集中式训练。MAGPO采用自回归联合策略进行可扩展的、协调的探索，并将其与分散式策略明确对齐，以确保在部分可观察性下的可部署性。此外，该方法提供了单调策略改进的理论保证。

Result: MAGPO在6个不同环境的43个任务上进行了实证评估。结果表明，MAGPO持续优于强大的CTDE基线方法，并且与完全集中式方法相当或超越它们。

Conclusion: MAGPO为分散式多智能体学习提供了一个原则性且实用的解决方案，它在性能上优于现有方法，并具有理论保证。

Abstract: Due to practical constraints such as partial observability and limited
communication, Centralized Training with Decentralized Execution (CTDE) has
become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning
(MARL). However, existing CTDE methods often underutilize centralized training
or lack theoretical guarantees. We propose Multi-Agent Guided Policy
Optimization (MAGPO), a novel framework that better leverages centralized
training by integrating centralized guidance with decentralized execution.
MAGPO uses an auto-regressive joint policy for scalable, coordinated
exploration and explicitly aligns it with decentralized policies to ensure
deployability under partial observability. We provide theoretical guarantees of
monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across
6 diverse environments. Results show that MAGPO consistently outperforms strong
CTDE baselines and matches or surpasses fully centralized approaches, offering
a principled and practical solution for decentralized multi-agent learning. Our
code and experimental data can be found in https://github.com/liyheng/MAGPO.

</details>


### [8] [AlphaGo Moment for Model Architecture Discovery](https://arxiv.org/abs/2507.18074)
*Yixiu Liu,Yang Nan,Weixian Xu,Xiangkun Hu,Lyumanshan Ye,Zhen Qin,Pengfei Liu*

Main category: cs.AI

TL;DR: 该研究展示了ASI-Arch，一个能自主进行神经网络架构创新的AI系统，旨在突破人类认知对AI研究的限制，实现AI驱动的AI研究加速。


<details>
  <summary>Details</summary>
Motivation: 当前AI研究的进展受限于人类认知能力，导致AI能力指数级提升与研究速度线性增长之间的瓶颈。研究旨在通过AI系统自身进行创新，打破这一限制。

Method: 引入ASI-Arch系统，超越传统神经架构搜索（NAS），实现从自动化优化到自动化创新的范式转变。该系统能自主提出新架构概念、将其实现为可执行代码、训练并进行经验验证，并通过严谨实验和过往经验评估性能。

Result: ASI-Arch进行了1,773次自主实验，耗费20,000 GPU小时，发现了106种创新的、最先进的（SOTA）线性注意力架构。这些AI发现的架构展示了超越人类设计基线的涌现设计原则，并揭示了新的架构创新途径。研究还首次建立了科学发现的经验缩放定律，证明架构突破可以通过计算进行扩展。

Conclusion: ASI-Arch为AI系统自我加速提供了蓝图，将研究进展从受限于人类的过程转变为可计算扩展的过程，开启了AI自主进行科学研究的新范式。

Abstract: While AI systems demonstrate exponentially improving capabilities, the pace
of AI research itself remains linearly bounded by human cognitive capacity,
creating an increasingly severe development bottleneck. We present ASI-Arch,
the first demonstration of Artificial Superintelligence for AI research
(ASI4AI) in the critical domain of neural architecture discovery--a fully
autonomous system that shatters this fundamental constraint by enabling AI to
conduct its own architectural innovation. Moving beyond traditional Neural
Architecture Search (NAS), which is fundamentally limited to exploring
human-defined spaces, we introduce a paradigm shift from automated optimization
to automated innovation. ASI-Arch can conduct end-to-end scientific research in
the domain of architecture discovery, autonomously hypothesizing novel
architectural concepts, implementing them as executable code, training and
empirically validating their performance through rigorous experimentation and
past experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000
GPU hours, culminating in the discovery of 106 innovative, state-of-the-art
(SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed
unexpected strategic insights invisible to human players, our AI-discovered
architectures demonstrate emergent design principles that systematically
surpass human-designed baselines and illuminate previously unknown pathways for
architectural innovation. Crucially, we establish the first empirical scaling
law for scientific discovery itself--demonstrating that architectural
breakthroughs can be scaled computationally, transforming research progress
from a human-limited to a computation-scalable process. We provide
comprehensive analysis of the emergent design patterns and autonomous research
capabilities that enabled these breakthroughs, establishing a blueprint for
self-accelerating AI systems.

</details>


### [9] [Agentic AI framework for End-to-End Medical Data Inference](https://arxiv.org/abs/2507.18115)
*Soorya Ram Shimgekar,Shayan Vassef,Abhay Goyal,Navin Kumar,Koustuv Saha*

Main category: cs.AI

TL;DR: 该研究提出了一个Agentic AI框架，通过模块化的任务特定智能体自动化医疗健康领域的机器学习全流程，从数据摄取到推理，以解决部署成本高、流程碎片化和数据隐私问题。


<details>
  <summary>Details</summary>
Motivation: 在医疗健康领域构建和部署机器学习解决方案成本高昂且劳动密集，主要原因在于预处理工作流碎片化、模型兼容性问题以及严格的数据隐私限制。

Method: 引入了一个Agentic AI框架，由一系列模块化、任务特定的智能体组成，自动化整个临床数据管道。这些智能体处理结构化和非结构化数据，实现自动特征选择、模型选择和预处理推荐。具体智能体包括：摄取识别智能体、数据匿名化智能体、特征提取智能体（基于嵌入的表格数据，基于MedGemma的多阶段图像数据）、模型-数据特征匹配智能体、预处理推荐智能体、预处理实现智能体和模型推理智能体（使用SHAP、LIME、DETR等工具生成可解释输出）。

Result: 该系统在老年病学、姑息治疗和结肠镜成像的公开数据集上进行了评估。例如，在结构化数据（焦虑数据）和非结构化数据（结肠镜息肉数据）案例中，管道展示了从文件类型检测、数据匿名化、特征提取、模型选择到预处理和最终推理的自动化流程。

Conclusion: 所提出的框架通过自动化机器学习生命周期中摩擦力大的阶段，减少了重复的专家干预需求，为在临床环境中操作化人工智能提供了一条可扩展、经济高效的途径。

Abstract: Building and deploying machine learning solutions in healthcare remains
expensive and labor-intensive due to fragmented preprocessing workflows, model
compatibility issues, and stringent data privacy constraints. In this work, we
introduce an Agentic AI framework that automates the entire clinical data
pipeline, from ingestion to inference, through a system of modular,
task-specific agents. These agents handle both structured and unstructured
data, enabling automatic feature selection, model selection, and preprocessing
recommendation without manual intervention. We evaluate the system on publicly
available datasets from geriatrics, palliative care, and colonoscopy imaging.
For example, in the case of structured data (anxiety data) and unstructured
data (colonoscopy polyps data), the pipeline begins with file-type detection by
the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring
privacy compliance, where we first identify the data type and then anonymize
it. The Feature Extraction Agent identifies features using an embedding-based
approach for tabular data, extracting all column names, and a multi-stage
MedGemma-based approach for image data, which infers modality and disease name.
These features guide the Model-Data Feature Matcher Agent in selecting the
best-fit model from a curated repository. The Preprocessing Recommender Agent
and Preprocessing Implementor Agent then apply tailored preprocessing based on
data type and model requirements. Finally, the ``Model Inference Agent" runs
the selected model on the uploaded data and generates interpretable outputs
using tools like SHAP, LIME, and DETR attention maps. By automating these
high-friction stages of the ML lifecycle, the proposed framework reduces the
need for repeated expert intervention, offering a scalable, cost-efficient
pathway for operationalizing AI in clinical environments.

</details>


### [10] [Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes](https://arxiv.org/abs/2507.18123)
*Sedigh Khademi,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila,Jim Black*

Main category: cs.AI

TL;DR: 本研究旨在利用自然语言处理（NLP）和主动学习（Active Learning）技术，从急诊科（ED）分诊笔记中快速开发一个分类器，以检测潜在的疫苗安全问题，从而加强疫苗上市后监测。


<details>
  <summary>Details</summary>
Motivation: COVID-19疫苗的快速开发凸显了临床试验中安全数据收集窗口有限，以及早期广泛接种后对上市后监测系统的需求。现有关键词分类方法可能产生误报，且难以应对疫苗相关急诊就诊频率低和症状非特异性等挑战。医疗领域标注数据稀缺，限制了NLP的应用。

Method: 本研究结合自然语言处理（NLP）技术、主动学习（Active Learning）以及数据增强（data augmentation）和主动学习评估技术，从急诊科分诊笔记中训练一个分类器。

Result: 通过结合NLP、主动学习和数据增强，本研究旨在快速开发一个准确高效的分类器，用于增强从急诊科分诊笔记中进行的疫苗安全信号监测。

Conclusion: 该方法能够优化标注过程和数据质量，从而实现模型的更快部署和性能提升，有效提升疫苗上市后安全监测的及时性和准确性。

Abstract: The rapid development of COVID-19 vaccines has showcased the global
communitys ability to combat infectious diseases. However, the need for
post-licensure surveillance systems has grown due to the limited window for
safety data collection in clinical trials and early widespread implementation.
This study aims to employ Natural Language Processing techniques and Active
Learning to rapidly develop a classifier that detects potential vaccine safety
issues from emergency department notes. ED triage notes, containing expert,
succinct vital patient information at the point of entry to health systems, can
significantly contribute to timely vaccine safety signal surveillance. While
keyword-based classification can be effective, it may yield false positives and
demand extensive keyword modifications. This is exacerbated by the infrequency
of vaccination-related ED presentations and their similarity to other reasons
for ED visits. NLP offers a more accurate and efficient alternative, albeit
requiring annotated data, which is often scarce in the medical field. Active
learning optimizes the annotation process and the quality of annotated data,
which can result in faster model implementation and improved model performance.
This work combines active learning, data augmentation, and active learning and
evaluation techniques to create a classifier that is used to enhance vaccine
safety surveillance from ED triage notes.

</details>


### [11] [Logical Characterizations of GNNs with Mean Aggregation](https://arxiv.org/abs/2507.18145)
*Moritz Schönherr,Carsten Lutz*

Main category: cs.AI

TL;DR: 本文研究了以均值作为聚合函数的图神经网络（GNNs）的表达能力，并将其与各种模态逻辑进行比较，发现其在不同设置下表达能力各异。


<details>
  <summary>Details</summary>
Motivation: 理解不同聚合函数对GNNs表达能力的影响，特别是均值聚合，并将其与已知的其他聚合函数（如求和、最大值）进行对比，以精确刻画其计算极限。

Method: 通过将均值GNNs的表达能力与不同的模态逻辑（如比率模态逻辑、交替自由模态逻辑）进行等价性证明来分析其表达力。区分了非均匀设置和均匀设置，并在均匀设置下考虑了连续组合函数和阈值分类函数的自然假设。

Result: 在非均匀设置下，均值GNNs的表达能力与比率模态逻辑完全相同，高于最大值聚合GNNs，但低于求和聚合GNNs。在均匀设置下（假设组合函数连续且分类函数为阈值），相对于MSO，均值GNNs的表达能力与交替自由模态逻辑完全相同，且严格低于求和及最大值聚合GNNs。若移除任何假设，表达能力会提升。

Conclusion: 均值聚合GNNs的表达能力因设置和假设条件而异。在非均匀设置下，它具有独特的比率推理能力；而在均匀设置下，在特定假设下其表达能力相对受限，但通过放宽假设可以增强。

Abstract: We study the expressive power of graph neural networks (GNNs) with mean as
the aggregation function. In the non-uniform setting, we show that such GNNs
have exactly the same expressive power as ratio modal logic, which has modal
operators expressing that at least a certain ratio of the successors of a
vertex satisfies a specified property. The non-uniform expressive power of mean
GNNs is thus higher than that of GNNs with max aggregation, but lower than for
sum aggregation--the latter are characterized by modal logic and graded modal
logic, respectively. In the uniform setting, we show that the expressive power
relative to MSO is exactly that of alternation-free modal logic, under the
natural assumptions that combination functions are continuous and
classification functions are thresholds. This implies that, relative to MSO and
in the uniform setting, mean GNNs are strictly less expressive than sum GNNs
and max GNNs. When any of the assumptions is dropped, the expressive power
increases.

</details>


### [12] [Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory](https://arxiv.org/abs/2507.18178)
*Mutian Yang,Jiandong Gao,Ji Wu*

Main category: cs.AI

TL;DR: 该研究提出了一个认知归因框架，基于双系统认知理论，将大型语言模型（LLMs）的认知解耦为知识检索和推理调整两个阶段，并通过“快思考”和“慢思考”模式量化其贡献，揭示了推理调整的领域特异性、参数缩放的影响以及知识与推理在模型层级中的分布。


<details>
  <summary>Details</summary>
Motivation: 在LLMs的推理过程中，区分知识和推理对其模型分析、可解释性和发展至关重要。

Method: 受双系统认知理论启发，提出了一个认知归因框架。该框架将LLMs的认知分解为知识检索（阶段1）和推理调整（阶段2）。通过提示LLMs在“快思考”和“慢思考”两种不同认知模式下生成答案，以分离并量化知识和推理的贡献。该架构应用于15个LLMs和3个数据集进行分析。

Result: (1) 推理调整具有领域特异性，有利于推理密集型领域（如数学、物理、化学），但可能损害知识密集型领域。(2) 参数缩放能同时提升知识和推理能力，其中知识提升更显著。此外，参数缩放使LLMs的推理更趋谨慎，智能程度适度提升。(3) 知识主要存在于较低的网络层，而推理则在较高的层级中运作。

Conclusion: 该框架不仅有助于从“解耦”视角理解LLMs，还为现有研究提供了新见解，包括缩放定律、分层知识编辑以及小型模型推理的局限性。

Abstract: While large language models (LLMs) leverage both knowledge and reasoning
during inference, the capacity to distinguish between them plays a pivotal role
in model analysis, interpretability, and development. Inspired by dual-system
cognitive theory, we propose a cognition attribution framework to decouple the
contribution of knowledge and reasoning. In particular, the cognition of LLMs
is decomposed into two distinct yet complementary phases: knowledge retrieval
(Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs
are prompted to generate answers under two different cognitive modes, fast
thinking and slow thinking, respectively. The performance under different
cognitive modes is analyzed to quantify the contribution of knowledge and
reasoning. This architecture is employed to 15 LLMs across 3 datasets. Results
reveal: (1) reasoning adjustment is domain-specific, benefiting
reasoning-intensive domains (e.g., mathematics, physics, and chemistry) and
potentially imparing knowledge-intensive domains. (2) Parameter scaling
improves both knowledge and reasoning, with knowledge improvements being more
pronounced. Additionally, parameter scaling make LLMs reasoning significantly
more prudent, while moderately more intelligent. (3) Knowledge primarily
resides in lower network layers, while reasoning operates in higher layers. Our
framework not only helps understand LLMs from a "decoupling" perspective, but
also provides new insights into existing research, including scaling laws,
hierarchical knowledge editing, and limitations of small-model reasoning.

</details>


### [13] [Comparing Non-minimal Semantics for Disjunction in Answer Set Programming](https://arxiv.org/abs/2507.18198)
*Felicidad Aguado,Pedro Cabalar,Brais Muñiz,Gilberto Pérez,Concepción Vidal*

Main category: cs.AI

TL;DR: 本文比较了四种不遵循模型最小性原则的ASP析取语义，发现其中三种（Forks、Justified Models和松弛的DI语义）实际上是等价的，并构成了共同的语义，该语义是稳定模型的超集，且比Strongly Supported Models更强。


<details>
  <summary>Details</summary>
Motivation: ASP中的稳定模型遵循模型最小性原则，但存在其他不遵循该原则的析取语义。本研究旨在比较这些非最小析取语义，理解它们之间的关系和特性。

Method: 本文比较了四种不同的ASP析取语义：Cabalar和Muñiz的Justified Models、Doherty和Szalas的Strongly Supported Models、Aguado et al的Forks以及Shen和Eiter的Determining Inference (DI) 语义。Forks和DI语义虽然引入了新的析取连接词，但在此被视为标准析取运算符的新语义进行比较。通过理论证明，分析它们之间的重合性、包含关系和强度。

Result: 研究发现，其中三种方法（Forks、Justified Models和DI语义的合理松弛版本）实际上是重合的，在不同定义下构成了一种共同的单一方法。这种共同语义总是提供程序稳定模型的超集。此外，这种共同语义严格强于第四种方法（Strongly Supported Models），后者实际上将析取视为经典逻辑中的处理方式。

Conclusion: 在不遵循最小性原则的ASP析取语义中，存在一个统一的共同语义（包括Forks、Justified Models和松弛的DI语义），它扩展了稳定模型，并且比将析取视为经典逻辑的语义（Strongly Supported Models）更强。这为理解不同的ASP析取语义提供了统一的视角。

Abstract: In this paper, we compare four different semantics for disjunction in Answer
Set Programming that, unlike stable models, do not adhere to the principle of
model minimality. Two of these approaches, Cabalar and Mu\~niz' \emph{Justified
Models} and Doherty and Szalas' \emph{Strongly Supported Models}, directly
provide an alternative non-minimal semantics for disjunction. The other two,
Aguado et al's \emph{Forks} and Shen and Eiter's \emph{Determining Inference}
(DI) semantics, actually introduce a new disjunction connective, but are
compared here as if they constituted new semantics for the standard disjunction
operator. We are able to prove that three of these approaches (Forks, Justified
Models and a reasonable relaxation of the DI semantics) actually coincide,
constituting a common single approach under different definitions. Moreover,
this common semantics always provides a superset of the stable models of a
program (in fact, modulo any context) and is strictly stronger than the fourth
approach (Strongly Supported Models), that actually treats disjunctions as in
classical logic.

</details>


### [14] [Foundations for Risk Assessment of AI in Protecting Fundamental Rights](https://arxiv.org/abs/2507.18290)
*Antonino Rotolo,Beatrice Ferrigno,Jose Miguel Angel Garcia Godinez,Claudio Novelli,Giovanni Sartor*

Main category: cs.AI

TL;DR: 本文提出了一个概念框架，用于对AI进行定性风险评估，尤其针对欧盟AI法案，通过整合定义平衡和可废止推理来处理法律合规性和基本权利保护的复杂性。


<details>
  <summary>Details</summary>
Motivation: AI风险评估，尤其是在法律合规（如欧盟AI法案）和基本权利保护方面，存在复杂性。需要一个能够处理权利冲突、法律动态性和多层影响的框架。

Method: 该研究引入了一个概念框架，整合了“定义平衡”（通过比例原则分析解决权利冲突）和“可废止推理”（适应法律决策的动态性）。它强调分析AI部署场景，识别潜在法律违规和对基本权利的多层影响，并构建了AI风险分析的逻辑基础，考虑了权利在不同情境下的促进或削弱。

Result: 该框架为AI风险分析提供了一个逻辑账户的哲学基础，特别是在AI部署场景与基本权利交互方面。这种分层方法能够更有效地评估高风险AI系统和通用AI（GPAI）系统，并强调了后者更广泛的适用性。

Conclusion: 该概念框架为AI风险评估，特别是与欧盟AI法案相关的评估，提供了有力的工具。未来的工作将致力于开发形式化模型和有效算法，以弥合理论与实践之间的差距，支持负责任的AI治理。

Abstract: This chapter introduces a conceptual framework for qualitative risk
assessment of AI, particularly in the context of the EU AI Act. The framework
addresses the complexities of legal compliance and fundamental rights
protection by itegrating definitional balancing and defeasible reasoning.
Definitional balancing employs proportionality analysis to resolve conflicts
between competing rights, while defeasible reasoning accommodates the dynamic
nature of legal decision-making. Our approach stresses the need for an analysis
of AI deployment scenarios and for identifying potential legal violations and
multi-layered impacts on fundamental rights. On the basis of this analysis, we
provide philosophical foundations for a logical account of AI risk analysis. In
particular, we consider the basic building blocks for conceptually grasping the
interaction between AI deployment scenarios and fundamental rights,
incorporating in defeasible reasoning definitional balancing and arguments
about the contextual promotion or demotion of rights. This layered approach
allows for more operative models of assessment of both high-risk AI systems and
General Purpose AI (GPAI) systems, emphasizing the broader applicability of the
latter. Future work aims to develop a formal model and effective algorithms to
enhance AI risk assessment, bridging theoretical insights with practical
applications to support responsible AI governance.

</details>


### [15] [The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams](https://arxiv.org/abs/2507.18337)
*Peter Baumgartner,Lachlan McGinness*

Main category: cs.AI

TL;DR: 提出一种结合大语言模型（LLM）、计算机代数系统（CAS）、SMT求解器和项重写系统来自动批改物理考试答案的方法。


<details>
  <summary>Details</summary>
Motivation: 自动评估学生输入的物理答案的正确性是一个具有挑战性的问题，需要一种有效且准确的解决方案。

Method: 利用LLM解释学生答案、纠正错误并将其转换为机器可读格式；结合CAS、SMT求解器和定制的项重写系统（TRS）进行答案正确性评估；采用两种自动定理证明方法：现成的SMT求解和专门针对物理问题（特别是三角表达式）开发的TRS；详细阐述了TRS的开发及其终止性和合流性属性。

Result: 该系统已在超过1500份来自2023年澳大利亚物理奥林匹克竞赛的真实学生答卷上进行了评估。

Conclusion: 成功开发并验证了一种混合方法，利用LLM进行自然语言处理，并结合形式化推理工具（CAS、SMT、TRS）实现物理考试答案的自动化批改。

Abstract: We present our method for automatically marking Physics exams. The marking
problem consists in assessing typed student answers for correctness with
respect to a ground truth solution. This is a challenging problem that we seek
to tackle using a combination of a computer algebra system, an SMT solver and a
term rewriting system. A Large Language Model is used to interpret and remove
errors from student responses and rewrite these in a machine readable format.
Once formalized and language-aligned, the next step then consists in applying
automated reasoning techniques for assessing student solution correctness. We
consider two methods of automated theorem proving: off-the-shelf SMT solving
and term rewriting systems tailored for physics problems involving
trigonometric expressions. The development of the term rewrite system and
establishing termination and confluence properties was not trivial, and we
describe it in some detail in the paper. We evaluate our system on a rich pool
of over 1500 real-world student exam responses from the 2023 Australian Physics
Olympiad.

</details>


### [16] [Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios](https://arxiv.org/abs/2507.18368)
*Zhuang Qiang Bok,Watson Wei Khong Chua*

Main category: cs.AI

TL;DR: 该论文引入了ConDiFi基准，用于同时评估大型语言模型（LLMs）在金融任务中的发散性（创造性）和收敛性（决策）思维能力，并揭示了主流模型在此方面的显著差异。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理基准主要侧重于事实准确性或循序渐进的逻辑，但在金融领域，专业人士不仅需要做出最优决策，还需要在不确定性下生成有创意、合理且可行的未来设想。因此，需要一个能同时评估这两种思维能力的基准。

Method: 研究者创建了ConDiFi基准，其中包含607个用于发散性推理的宏观金融提示和990个用于收敛性推理的多跳对抗性多项选择题。利用此基准，他们评估了14个主流LLM模型。

Result: 评估结果显示，尽管GPT-4o具有高流畅性，但在新颖性和可操作性方面表现不佳。相比之下，DeepSeek-R1和Cohere Command R+等模型在生成适合投资决策的可操作性见解方面表现优异。

Conclusion: ConDiFi基准为评估LLM在金融领域安全和战略部署所需的关键推理能力提供了新的视角和工具。

Abstract: Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step
logic. In finance, however, professionals must not only converge on optimal
decisions but also generate creative, plausible futures under uncertainty. We
introduce ConDiFi, a benchmark that jointly evaluates divergent and convergent
thinking in LLMs for financial tasks.
  ConDiFi features 607 macro-financial prompts for divergent reasoning and 990
multi-hop adversarial MCQs for convergent reasoning. Using this benchmark, we
evaluated 14 leading models and uncovered striking differences. Despite high
fluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models
like DeepSeek-R1 and Cohere Command R+ rank among the top for generating
actionable, insights suitable for investment decisions. ConDiFi provides a new
perspective to assess reasoning capabilities essential to safe and strategic
deployment of LLMs in finance.

</details>


### [17] [Revisiting LLM Reasoning via Information Bottleneck](https://arxiv.org/abs/2507.18391)
*Shiye Lei,Zhihao Cheng,Kai Jia,Dacheng Tao*

Main category: cs.AI

TL;DR: 通过信息瓶颈（IB）原理，提出IBRO框架和轻量级IB正则化方法，以理论化方式优化LLM推理轨迹，使其更具信息量和泛化性，从而在数学推理任务中提升LLM性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习（RLVR）的LLM推理方法多为启发式且凭直觉，缺乏系统性理论指导，限制了原则性方法的发展。

Method: 提出基于信息瓶颈（IB）原理的LLM推理理论表征，并引入IB-aware推理优化（IBRO）框架，旨在使推理轨迹既能提供最终正确答案的充分信息，又能泛化到不同提示。推导出一个实用的token级替代目标，并提出高效近似，形成轻量级IB正则化方法，可无缝集成到现有RL后训练框架中，仅需一行代码修改。

Result: 在多个数学推理基准和RL算法上验证了IB正则化方法，展示了LLM推理性能的持续改进。

Conclusion: IB正则化方法提供了一种理论上更严谨且高效的方式来优化LLM的推理能力，解决了现有方法的启发式局限性，并经验性地证明了其有效性。

Abstract: Large language models (LLMs) have recently demonstrated remarkable progress
in reasoning capabilities through reinforcement learning with verifiable
rewards (RLVR). By leveraging simple rule-based rewards, RL effectively
incentivizes LLMs to produce extended chain-of-thought (CoT) reasoning
trajectories, progressively guiding them toward correct answers. However,
existing approaches remain largely heuristic and intuition-driven, limiting the
development of principled methodologies. In this paper, we present a
theoretical characterization of LLM reasoning grounded in information
bottleneck (IB) principle, introducing IB-aware reasoning optimization (IBRO),
a framework that encourages reasoning trajectories to be both informative about
the final correct answer and generalizable across diverse prompts. We derive a
practical token-level surrogate objective and propose an efficient
approximation, resulting in the lightweight IB regularization method. This
technique integrates seamlessly into existing RL-based post-training frameworks
without additional computational overhead, requiring only a one-line code
modification. Empirically, we validate IB regularization across multiple
mathematical reasoning benchmarks and RL algorithms, demonstrating consistent
improvements in LLM reasoning performance.

</details>


### [18] [Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation](https://arxiv.org/abs/2507.18398)
*Kwong Ho Li,Wathsala Karunarathne*

Main category: cs.AI

TL;DR: 本文研究了强化学习（RL）在呼叫中心呼叫路由优化中的应用，旨在最小化客户等待时间和员工空闲时间。对比了基于模型的价值迭代（VI）和无模型的近端策略优化（PPO），结果表明PPO性能最佳。


<details>
  <summary>Details</summary>
Motivation: 优化呼叫中心的呼叫路由策略，以有效降低客户等待时间并减少员工空闲时间。

Method: 将呼叫路由问题建模为技能型路由（SBR）框架下的马尔可夫决策过程（MDP），其中客户到达遵循泊松分布，服务和放弃时间遵循指数分布。对比了两种RL方法：1. 基于模型的方法：使用已知系统动态的价值迭代（VI），基于理论模型。2. 无模型的方法：使用近端策略优化（PPO），通过结合离散事件仿真（DES）和OpenAI Gym环境的仿真模型从经验中学习。通过仿真模型评估了随机策略、VI策略和PPO策略的性能。

Result: 经过1000个测试回合，PPO策略持续获得最高的回报，同时实现了最低的客户等待时间和最低的员工空闲时间，尽管它需要更长的训练时间。

Conclusion: PPO是一种有效的呼叫中心呼叫路由优化方法，尽管训练时间较长，但在最小化客户等待时间和员工空闲时间方面优于传统的价值迭代和随机策略。

Abstract: This paper investigates the application of Reinforcement Learning (RL) to
optimise call routing in call centres to minimise client waiting time and staff
idle time. Two methods are compared: a model-based approach using Value
Iteration (VI) under known system dynamics, and a model-free approach using
Proximal Policy Optimisation (PPO) that learns from experience. For the
model-based approach, a theoretical model is used, while a simulation model
combining Discrete Event Simulation (DES) with the OpenAI Gym environment is
developed for model-free learning. Both models frame the problem as a Markov
Decision Process (MDP) within a Skills-Based Routing (SBR) framework, with
Poisson client arrivals and exponentially distributed service and abandonment
times. For policy evaluation, random, VI, and PPO policies are evaluated using
the simulation model. After 1,000 test episodes, PPO consistently achives the
highest rewards, along with the lowest client waiting time and staff idle time,
despite requiring longer training time.

</details>


### [19] [GPU Accelerated Compact-Table Propagation](https://arxiv.org/abs/2507.18413)
*Enrico Santi,Fabio Tardivo,Agostino Dovier,Andrea Formisano*

Main category: cs.AI

TL;DR: 本文研究如何利用GPU的并行计算能力加速处理大规模表约束（Table Constraint）的传播算法，特别是对Compact-Table (CT)算法进行优化。


<details>
  <summary>Details</summary>
Motivation: 表约束是一种强大的约束形式，原则上可以模拟任何其他有限域变量上的条件。然而，在实际问题中，当有效情况数量巨大时，传统的基于CPU的方法难以高效处理，导致性能瓶颈。

Method: 本文描述了如何通过利用现代GPU的强大计算能力来增强最先进的Compact-Table (CT)传播算法，以处理大型表约束。具体方法包括设计和实现GPU加速的CT算法，并将其集成到现有的约束求解器中。

Result: 研究报告了GPU加速CT的设计和实现，以及其与现有约束求解器的集成。通过在大量实例上进行实验验证，证明了该方法在处理大规模表约束时的有效性。

Conclusion: 利用GPU的并行计算能力可以显著提升表约束传播算法（特别是Compact-Table）的处理效率，从而有效应对现实世界中包含大量有效情况的复杂问题。

Abstract: Constraint Programming developed within Logic Programming in the Eighties;
nowadays all Prolog systems encompass modules capable of handling constraint
programming on finite domains demanding their solution to a constraint solver.
This work focuses on a specific form of constraint, the so-called table
constraint, used to specify conditions on the values of variables as an
enumeration of alternative options. Since every condition on a set of finite
domain variables can be ultimately expressed as a finite set of cases, Table
can, in principle, simulate any other constraint. These characteristics make
Table one of the most studied constraints ever, leading to a series of
increasingly efficient propagation algorithms. Despite this, it is not uncommon
to encounter real-world problems with hundreds or thousands of valid cases that
are simply too many to be handled effectively with standard CPU-based
approaches. In this paper, we deal with the Compact-Table (CT) algorithm, the
state-of-the-art propagation algorithms for Table. We describe how CT can be
enhanced by exploiting the massive computational power offered by modern GPUs
to handle large Table constraints. In particular, we report on the design and
implementation of GPU-accelerated CT, on its integration into an existing
constraint solver, and on an experimental validation performed on a significant
set of instances.

</details>


### [20] [On the Performance of Concept Probing: The Influence of the Data (Extended Version)](https://arxiv.org/abs/2507.18550)
*Manuel de Sousa Ribeiro,Afonso Leote,João Leite*

Main category: cs.AI

TL;DR: 概念探测通过训练额外分类器将神经网络内部表示映射到人类概念，以解释神经网络。本文关注探测模型训练数据对性能的影响，并发布了两个常用数据集的概念标签。


<details>
  <summary>Details</summary>
Motivation: 神经网络因其规模庞大和亚符号性质难以直接解释。概念探测作为一种解释方法兴起，但现有研究多关注被探测模型或探测模型本身，对训练探测模型所需的数据关注不足。本文旨在弥补这一空白。

Method: 本文在图像分类任务背景下，研究了用于训练探测模型的数据对其性能的影响。同时，作者为两个广泛使用的数据集提供了概念标签。

Result: 研究揭示了用于训练探测模型的数据对探测模型性能的影响。具体结果未在摘要中详细说明，但表明数据是一个重要因素。

Conclusion: 训练探测模型的数据对概念探测的性能至关重要。本文通过实验验证了这一点，并为社区提供了带概念标签的数据集，以促进未来研究。

Abstract: Concept probing has recently garnered increasing interest as a way to help
interpret artificial neural networks, dealing both with their typically large
size and their subsymbolic nature, which ultimately renders them unfeasible for
direct human interpretation. Concept probing works by training additional
classifiers to map the internal representations of a model into human-defined
concepts of interest, thus allowing humans to peek inside artificial neural
networks. Research on concept probing has mainly focused on the model being
probed or the probing model itself, paying limited attention to the data
required to train such probing models. In this paper, we address this gap.
Focusing on concept probing in the context of image classification tasks, we
investigate the effect of the data used to train probing models on their
performance. We also make available concept labels for two widely used
datasets.

</details>


### [21] [SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law](https://arxiv.org/abs/2507.18576)
*Shanghai AI Lab,:,Yicheng Bao,Guanxu Chen,Mingkang Chen,Yunhao Chen,Chiyu Chen,Lingjie Chen,Sirui Chen,Xinquan Chen,Jie Cheng,Yu Cheng,Dengke Deng,Yizhuo Ding,Dan Ding,Xiaoshan Ding,Yi Ding,Zhichen Dong,Lingxiao Du,Yuyu Fan,Xinshun Feng,Yanwei Fu,Yuxuan Gao,Ruijun Ge,Tianle Gu,Lujun Gui,Jiaxuan Guo,Qianxi He,Yuenan Hou,Xuhao Hu,Hong Huang,Kaichen Huang,Shiyang Huang,Yuxian Jiang,Shanzhe Lei,Jie Li,Lijun Li,Hao Li,Juncheng Li,Xiangtian Li,Yafu Li,Lingyu Li,Xueyan Li,Haotian Liang,Dongrui Liu,Qihua Liu,Zhixuan Liu,Bangwei Liu,Huacan Liu,Yuexiao Liu,Zongkai Liu,Chaochao Lu,Yudong Lu,Xiaoya Lu,Zhenghao Lu,Qitan Lv,Caoyuan Ma,Jiachen Ma,Xiaoya Ma,Zhongtian Ma,Lingyu Meng,Ziqi Miao,Yazhe Niu,Yuezhang Peng,Yuan Pu,Han Qi,Chen Qian,Xingge Qiao,Jingjing Qu,Jiashu Qu,Wanying Qu,Wenwen Qu,Xiaoye Qu,Qihan Ren,Qingnan Ren,Qingyu Ren,Jing Shao,Wenqi Shao,Shuai Shao,Dongxing Shi,Xin Song,Xinhao Song,Yan Teng,Xuan Tong,Yingchun Wang,Xuhong Wang,Shujie Wang,Xin Wang,Yige Wang,Yixu Wang,Yuanfu Wang,Futing Wang,Ruofan Wang,Wenjie Wang,Yajie Wang,Muhao Wei,Xiaoyu Wen,Fenghua Weng,Yuqi Wu,Yingtong Xiong,Xingcheng Xu,Chao Yang,Yue Yang,Yang Yao,Yulei Ye,Zhenyun Yin,Yi Yu,Bo Zhang,Qiaosheng Zhang,Jinxuan Zhang,Yexin Zhang,Yinqiang Zheng,Hefeng Zhou,Zhanhui Zhou,Pengyu Zhu,Qingzi Zhu,Yubo Zhu,Bowen Zhou*

Main category: cs.AI

TL;DR: 本文提出了SafeWork-R1，一个通过SafeLadder框架训练的多模态推理模型，实现了能力与安全性的协同演进，并在安全性基准上显著超越基线模型和领先的专有模型。


<details>
  <summary>Details</summary>
Motivation: 传统的对齐方法（如RLHF）仅学习人类偏好，缺乏内在的安全推理和自我反思能力。研究旨在开发一种能使模型具备内在安全推理和自我反思能力的方法，从而实现能力与安全的协同发展。

Method: 引入了SafeWork-R1多模态推理模型。开发了SafeLadder框架，该框架包含大规模、渐进式、面向安全的强化学习后训练，并由多原则验证器支持。此外，还实施了两种不同的推理时干预方法和一种审慎搜索机制，以强制执行步骤级验证。该框架应用于多种基础模型（如Qwen2.5-VL-72B、InternVL3-78B、DeepSeek-70B、Qwen2.5VL-7B）。

Result: SafeWork-R1在安全相关基准上比其基础模型Qwen2.5-VL-72B平均提升了46.54%，且不损害通用能力。与GPT-4.1和Claude Opus 4等领先专有模型相比，其安全性能达到了最先进水平。所有衍生的模型（如SafeWork-R1-InternVL3-78B）都展示了安全性和能力的协同演进。

Conclusion: 安全性和能力可以协同演进，这突出了所提出的SafeLadder框架在构建鲁棒、可靠和值得信赖的通用人工智能方面的通用性。

Abstract: We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that
demonstrates the coevolution of capabilities and safety. It is developed by our
proposed SafeLadder framework, which incorporates large-scale, progressive,
safety-oriented reinforcement learning post-training, supported by a suite of
multi-principled verifiers. Unlike previous alignment methods such as RLHF that
simply learn human preferences, SafeLadder enables SafeWork-R1 to develop
intrinsic safety reasoning and self-reflection abilities, giving rise to safety
`aha' moments. Notably, SafeWork-R1 achieves an average improvement of
$46.54\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks
without compromising general capabilities, and delivers state-of-the-art safety
performance compared to leading proprietary models such as GPT-4.1 and Claude
Opus 4. To further bolster its reliability, we implement two distinct
inference-time intervention methods and a deliberative search mechanism,
enforcing step-level verification. Finally, we further develop
SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and
SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and
capability can co-evolve synergistically, highlighting the generalizability of
our framework in building robust, reliable, and trustworthy general-purpose AI.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [22] [Lumina-mGPT 2.0: Stand-Alone AutoRegressive Image Modeling](https://arxiv.org/abs/2507.17801)
*Yi Xin,Juncheng Yan,Qi Qin,Zhen Li,Dongyang Liu,Shicheng Li,Victor Shea-Jay Huang,Yupeng Zhou,Renrui Zhang,Le Zhuo,Tiancheng Han,Xiaoqing Sun,Siqi Luo,Mengmeng Wang,Bin Fu,Yuewen Cao,Hongsheng Li,Guangtao Zhai,Xiaohong Liu,Yu Qiao,Peng Gao*

Main category: cs.CV

TL;DR: Lumina-mGPT 2.0是一个从零开始训练的独立自回归模型，在图像生成质量上与最先进的扩散模型相当甚至超越，并能处理多模态任务，展现了自回归范式的强大潜力。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成方法依赖预训练组件或混合架构，限制了设计自由和许可。该研究旨在通过从头训练的自回归模型，恢复其固有的灵活性和组合性，同时达到顶尖的生成质量。

Method: Lumina-mGPT 2.0是一个独立的、仅解码器的自回归模型，完全从零开始训练。它采用统一的tokenization方案处理多种任务，并结合了推理时缩放（提升质量）和推测性Jacobi采样（提升速度）等高效解码策略。

Result: Lumina-mGPT 2.0在生成质量上与DALL-E 3和SANA等先进扩散模型媲美。它在一个统一的生成框架内无缝处理多种任务，包括主体驱动生成、图像编辑、可控合成和密集预测。在文本到图像基准测试（如GenEval、DPG）上，其表现与扩散模型相当，甚至在某些情况下超越。在Graph200K基准测试中，其多任务能力也表现出色。

Conclusion: Lumina-mGPT 2.0是一个强大且灵活的统一多模态生成基础模型，证明了从零开始训练的自回归模型在高质量图像生成及多任务处理方面的巨大潜力。

Abstract: We present Lumina-mGPT 2.0, a stand-alone, decoder-only autoregressive model
that revisits and revitalizes the autoregressive paradigm for high-quality
image generation and beyond. Unlike existing approaches that rely on pretrained
components or hybrid architectures, Lumina-mGPT 2.0 is trained entirely from
scratch, enabling unrestricted architectural design and licensing freedom. It
achieves generation quality on par with state-of-the-art diffusion models such
as DALL-E 3 and SANA, while preserving the inherent flexibility and
compositionality of autoregressive modeling. Our unified tokenization scheme
allows the model to seamlessly handle a wide spectrum of tasks-including
subject-driven generation, image editing, controllable synthesis, and dense
prediction-within a single generative framework. To further boost usability, we
incorporate efficient decoding strategies like inference-time scaling and
speculative Jacobi sampling to improve quality and speed, respectively.
Extensive evaluations on standard text-to-image benchmarks (e.g., GenEval, DPG)
demonstrate that Lumina-mGPT 2.0 not only matches but in some cases surpasses
diffusion-based models. Moreover, we confirm its multi-task capabilities on the
Graph200K benchmark, with the native Lumina-mGPT 2.0 performing exceptionally
well. These results position Lumina-mGPT 2.0 as a strong, flexible foundation
model for unified multimodal generation. We have released our training details,
code, and models at https://github.com/Alpha-VLLM/Lumina-mGPT-2.0.

</details>


### [23] [SV3.3B: A Sports Video Understanding Model for Action Recognition](https://arxiv.org/abs/2507.17844)
*Sai Varun Kodathala,Yashwanth Reddy Vutukoori,Rakesh Vunnam*

Main category: cs.CV

TL;DR: 本文提出SV3.3B，一个轻量级3.3B参数的视频理解模型，用于高效的设备端体育视频分析，能够生成技术细节丰富、分析性强的体育动作描述，性能优于大型模型且计算成本显著降低。


<details>
  <summary>Details</summary>
Motivation: 传统体育视频分析模型计算密集，依赖服务器端处理，且缺乏对细微运动生物力学转换的精细理解，难以捕捉运动员动作的关键阶段（如准备、执行、完成），限制了有意义的体育分析。

Method: 引入SV3.3B模型，结合新颖的时间运动差异采样和自监督学习，实现高效的设备端部署。采用基于DWT-VGG16-LDA的关键帧提取机制（识别16个代表性帧），V-DWT-JEPA2编码器通过掩码去噪目标预训练，以及针对体育动作描述生成微调的LLM解码器。

Result: 在NSVA篮球数据集子集上，SV3.3B在传统文本生成指标和体育特定评估标准上均表现出色，优于包括GPT-4o变体在内的更大、闭源模型，同时计算要求显著降低。在真实性验证指标上比GPT-4o提升29.2%，并在信息密度、动作复杂度和测量精度等关键指标上也有显著改进。

Conclusion: SV3.3B模型在生成技术详细且分析丰富的体育描述方面展现出卓越能力，有效解决了自动化体育视频分析中计算量大和缺乏细粒度理解的挑战，为设备端体育分析提供了高效且高性能的解决方案。

Abstract: This paper addresses the challenge of automated sports video analysis, which
has traditionally been limited by computationally intensive models requiring
server-side processing and lacking fine-grained understanding of athletic
movements. Current approaches struggle to capture the nuanced biomechanical
transitions essential for meaningful sports analysis, often missing critical
phases like preparation, execution, and follow-through that occur within
seconds. To address these limitations, we introduce SV3.3B, a lightweight 3.3B
parameter video understanding model that combines novel temporal motion
difference sampling with self-supervised learning for efficient on-device
deployment. Our approach employs a DWT-VGG16-LDA based keyframe extraction
mechanism that intelligently identifies the 16 most representative frames from
sports sequences, followed by a V-DWT-JEPA2 encoder pretrained through
mask-denoising objectives and an LLM decoder fine-tuned for sports action
description generation. Evaluated on a subset of the NSVA basketball dataset,
SV3.3B achieves superior performance across both traditional text generation
metrics and sports-specific evaluation criteria, outperforming larger
closed-source models including GPT-4o variants while maintaining significantly
lower computational requirements. Our model demonstrates exceptional capability
in generating technically detailed and analytically rich sports descriptions,
achieving 29.2% improvement over GPT-4o in ground truth validation metrics,
with substantial improvements in information density, action complexity, and
measurement precision metrics essential for comprehensive athletic analysis.
Model Available at https://huggingface.co/sportsvision/SV3.3B.

</details>


### [24] [Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models](https://arxiv.org/abs/2507.17853)
*Lifeng Chen,Jiner Wang,Zihao Pan,Beier Zhu,Xiaofeng Yang,Chi Zhang*

Main category: cs.CV

TL;DR: Detail++是一个免训练框架，通过渐进式细节注入（PDI）策略，有效解决了文生图模型在处理复杂多主体提示词时面临的挑战，实现了更好的构图和属性绑定。


<details>
  <summary>Details</summary>
Motivation: 现有文生图模型在处理包含多个具有不同属性的主体的复杂提示词时，仍面临显著挑战，难以生成令人满意的视觉结果。

Method: 受人类绘画过程启发，Detail++将复杂提示词分解为一系列简化的子提示词，分阶段引导生成过程。它利用自注意力机制确保全局构图，并通过交叉注意力机制实现属性与主体的精确绑定。此外，在测试时引入质心对齐损失（Centroid Alignment Loss）以减少绑定噪声并增强属性一致性。

Result: 在T2I-CompBench和新建的风格构图基准测试中，Detail++显著优于现有方法，特别是在涉及多个对象和复杂风格条件的场景中表现出色。

Conclusion: Detail++通过其新颖的渐进式细节注入策略和质心对齐损失，有效提升了文生图模型处理复杂提示词的能力，尤其在多对象构图和属性绑定方面表现出卓越性能。

Abstract: Recent advances in text-to-image (T2I) generation have led to impressive
visual results. However, these models still face significant challenges when
handling complex prompt, particularly those involving multiple subjects with
distinct attributes. Inspired by the human drawing process, which first
outlines the composition and then incrementally adds details, we propose
Detail++, a training-free framework that introduces a novel Progressive Detail
Injection (PDI) strategy to address this limitation. Specifically, we decompose
a complex prompt into a sequence of simplified sub-prompts, guiding the
generation process in stages. This staged generation leverages the inherent
layout-controlling capacity of self-attention to first ensure global
composition, followed by precise refinement. To achieve accurate binding
between attributes and corresponding subjects, we exploit cross-attention
mechanisms and further introduce a Centroid Alignment Loss at test time to
reduce binding noise and enhance attribute consistency. Extensive experiments
on T2I-CompBench and a newly constructed style composition benchmark
demonstrate that Detail++ significantly outperforms existing methods,
particularly in scenarios involving multiple objects and complex stylistic
conditions.

</details>


### [25] [FishDet-M: A Unified Large-Scale Benchmark for Robust Fish Detection and CLIP-Guided Model Selection in Diverse Aquatic Visual Domains](https://arxiv.org/abs/2507.17859)
*Muayad Abujabal,Lyes Saad Saoud,Irfan Hussain*

Main category: cs.CV

TL;DR: 本文提出了FishDet-M，一个最大的统一鱼类检测基准数据集，整合了13个公共数据集，并对28种主流目标检测模型进行了系统性基准测试。同时，引入了一个基于CLIP的模型选择框架，以实现自适应部署。


<details>
  <summary>Details</summary>
Motivation: 水下图像中的鱼类检测对于生态监测、水产养殖自动化和机器人感知至关重要，但实际部署受限于数据集碎片化、成像条件异构以及评估协议不一致。

Method: 构建了FishDet-M，包含13个公共数据集，涵盖多种水生环境，并统一采用COCO风格的边界框和分割掩码标注。系统性地评估了28种当代目标检测模型（包括YOLO系列、R-CNN和DETR模型），使用mAP、mAP@50、mAP@75、尺度特定AP以及推理延迟和参数量等指标。引入了基于CLIP的模型选择框架，利用视觉-语言对齐零样本动态选择最合适的检测器。

Result: 结果显示，在FishDet-M上训练的模型表现各异，不同架构模型在精度和效率之间存在权衡。基于CLIP的模型选择策略无需集成计算即可实现高性能。

Conclusion: FishDet-M为复杂水生场景中的目标检测提供了一个标准化、可复现的评估平台，所有数据集、预训练模型和评估工具均已公开，以促进水下计算机视觉和智能海洋系统的未来研究。

Abstract: Accurate fish detection in underwater imagery is essential for ecological
monitoring, aquaculture automation, and robotic perception. However, practical
deployment remains limited by fragmented datasets, heterogeneous imaging
conditions, and inconsistent evaluation protocols. To address these gaps, we
present \textit{FishDet-M}, the largest unified benchmark for fish detection,
comprising 13 publicly available datasets spanning diverse aquatic environments
including marine, brackish, occluded, and aquarium scenes. All data are
harmonized using COCO-style annotations with both bounding boxes and
segmentation masks, enabling consistent and scalable cross-domain evaluation.
We systematically benchmark 28 contemporary object detection models, covering
the YOLOv8 to YOLOv12 series, R-CNN based detectors, and DETR based models.
Evaluations are conducted using standard metrics including mAP, mAP@50, and
mAP@75, along with scale-specific analyses (AP$_S$, AP$_M$, AP$_L$) and
inference profiling in terms of latency and parameter count. The results
highlight the varying detection performance across models trained on FishDet-M,
as well as the trade-off between accuracy and efficiency across models of
different architectures. To support adaptive deployment, we introduce a
CLIP-based model selection framework that leverages vision-language alignment
to dynamically identify the most semantically appropriate detector for each
input image. This zero-shot selection strategy achieves high performance
without requiring ensemble computation, offering a scalable solution for
real-time applications. FishDet-M establishes a standardized and reproducible
platform for evaluating object detection in complex aquatic scenes. All
datasets, pretrained models, and evaluation tools are publicly available to
facilitate future research in underwater computer vision and intelligent marine
systems.

</details>


### [26] [Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis](https://arxiv.org/abs/2507.17860)
*Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel*

Main category: cs.CV

TL;DR: 本研究利用生成式AI（LightningDiT）生成合成数据来评估皮肤癌检测深度学习模型的公平性，发现合成数据评估有前景，但受限于评估模型训练数据与合成数据基础数据的不一致性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在皮肤癌筛查中潜力巨大，但存在潜在的固有偏见。评估和提高这些系统的公平性至关重要，尤其需要确保评估数据集能充分代表不同个人身份信息（如性别、年龄、种族）和少数群体。

Method: 利用最先进的生成式AI（GenAI）LightningDiT模型生成高度逼真的合成数据。然后，使用这些合成数据来评估公开可用的黑色素瘤分类器的公平性。

Result: 使用高度逼真的合成数据进行公平性评估是一个有前景的方向。然而，当用于评估的黑色素瘤检测模型所训练的数据与合成图像的基础数据集不同时，验证公平性变得困难。

Conclusion: 该研究提出的方法为利用合成数据来衡量和增强医疗影像GenAI系统的公平性提供了一个有价值的新途径，尽管存在数据不匹配的挑战。

Abstract: Recent advancements in Deep Learning and its application on the edge hold
great potential for the revolution of routine screenings for skin cancers like
Melanoma. Along with the anticipated benefits of this technology, potential
dangers arise from unforseen and inherent biases. Thus, assessing and improving
the fairness of such systems is of utmost importance. A key challenge in
fairness assessment is to ensure that the evaluation dataset is sufficiently
representative of different Personal Identifiable Information (PII) (sex, age,
and race) and other minority groups. Against the backdrop of this challenge,
this study leverages the state-of-the-art Generative AI (GenAI) LightningDiT
model to assess the fairness of publicly available melanoma classifiers. The
results suggest that fairness assessment using highly realistic synthetic data
is a promising direction. Yet, our findings indicate that verifying fairness
becomes difficult when the melanoma-detection model used for evaluation is
trained on data that differ from the dataset underpinning the synthetic images.
Nonetheless, we propose that our approach offers a valuable new avenue for
employing synthetic data to gauge and enhance fairness in medical-imaging GenAI
systems.

</details>


### [27] [DiNAT-IR: Exploring Dilated Neighborhood Attention for High-Quality Image Restoration](https://arxiv.org/abs/2507.17892)
*Hanzhou Liu,Binghan Li,Chengkai Liu,Mi Lu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为DiNAT-IR的Transformer架构，通过结合膨胀邻域注意力（DiNA）和通道感知模块，有效平衡了图像恢复中的全局上下文和局部精度，解决了传统Transformer计算成本高和通道注意力忽略局部细节的问题。


<details>
  <summary>Details</summary>
Motivation: Transformer在图像恢复中表现出色，但自注意力机制计算成本高，限制了其在高分辨率图像上的应用。现有的通道自注意力方法（如Restormer）虽然效率高，但可能忽略对高质量恢复至关重要的局部伪影。直接应用DiNA在去模糊任务中因全局上下文受限而表现不佳，因此需要一种新的方法来弥补这一差距。

Method: 研究首先探索了膨胀邻域注意力（DiNA）作为替代方案，该方法通过混合膨胀因子将滑动窗口注意力与全局上下文和局部精度相结合。针对DiNA在去模糊任务中全局上下文理解不足的问题，引入了一个通道感知模块来补充局部注意力，从而在不牺牲像素级精度的情况下有效整合全局上下文。最终提出了基于Transformer的DiNAT-IR架构。

Result: 所提出的DiNAT-IR架构在多个图像恢复基准测试中取得了具有竞争力的结果，为各种低级计算机视觉问题提供了高质量的解决方案。

Conclusion: DiNAT-IR通过其创新的全局-局部上下文整合设计，克服了传统Transformer在图像恢复任务中的效率和精度权衡问题，为低级视觉任务提供了一个高性能的Transformer解决方案。

Abstract: Transformers, with their self-attention mechanisms for modeling long-range
dependencies, have become a dominant paradigm in image restoration tasks.
However, the high computational cost of self-attention limits scalability to
high-resolution images, making efficiency-quality trade-offs a key research
focus. To address this, Restormer employs channel-wise self-attention, which
computes attention across channels instead of spatial dimensions. While
effective, this approach may overlook localized artifacts that are crucial for
high-quality image restoration. To bridge this gap, we explore Dilated
Neighborhood Attention (DiNA) as a promising alternative, inspired by its
success in high-level vision tasks. DiNA balances global context and local
precision by integrating sliding-window attention with mixed dilation factors,
effectively expanding the receptive field without excessive overhead. However,
our preliminary experiments indicate that directly applying this global-local
design to the classic deblurring task hinders accurate visual restoration,
primarily due to the constrained global context understanding within local
attention. To address this, we introduce a channel-aware module that
complements local attention, effectively integrating global context without
sacrificing pixel-level precision. The proposed DiNAT-IR, a Transformer-based
architecture specifically designed for image restoration, achieves competitive
results across multiple benchmarks, offering a high-quality solution for
diverse low-level computer vision problems.

</details>


### [28] [AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2507.17957)
*Md. Al-Masrur Khan,Durgakant Pushp,Lantao Liu*

Main category: cs.CV

TL;DR: 提出自适应特征细化（AFR）模块，通过结合多尺度信息、高频分量和不确定性驱动注意力，解决无监督域适应语义分割（UDA-SS）中局部细节与全局上下文平衡问题，提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域适应语义分割（UDA-SS）方法难以平衡细粒度局部细节与全局上下文信息，导致在复杂区域出现分割错误。

Method: 引入自适应特征细化（AFR）模块。该模块通过低分辨率logits的语义先验来细化高分辨率特征，以增强分割精度；整合高频分量以捕获细粒度结构和提供关键边界信息；并通过不确定性驱动的注意力机制自适应地平衡局部和全局信息。其轻量级设计使其能无缝集成到基于HRDA的UDA方法中。

Result: 在GTA V --> Cityscapes数据集上，将现有UDA-SS方法的mIoU提高了1.05%；在Synthia --> Cityscapes数据集上，mIoU提高了1.04%，达到了最先进的分割性能。

Conclusion: AFR模块通过有效平衡局部细节和全局上下文信息，显著提升了无监督域适应语义分割的准确性，解决了现有方法的关键挑战，实现了最先进的性能。

Abstract: In Unsupervised Domain Adaptive Semantic Segmentation (UDA-SS), a model is
trained on labeled source domain data (e.g., synthetic images) and adapted to
an unlabeled target domain (e.g., real-world images) without access to target
annotations. Existing UDA-SS methods often struggle to balance fine-grained
local details with global contextual information, leading to segmentation
errors in complex regions. To address this, we introduce the Adaptive Feature
Refinement (AFR) module, which enhances segmentation accuracy by refining
highresolution features using semantic priors from low-resolution logits. AFR
also integrates high-frequency components, which capture fine-grained
structures and provide crucial boundary information, improving object
delineation. Additionally, AFR adaptively balances local and global information
through uncertaintydriven attention, reducing misclassifications. Its
lightweight design allows seamless integration into HRDA-based UDA methods,
leading to state-of-the-art segmentation performance. Our approach improves
existing UDA-SS methods by 1.05% mIoU on GTA V --> Cityscapes and 1.04% mIoU on
Synthia-->Cityscapes. The implementation of our framework is available at:
https://github.com/Masrur02/AFRDA

</details>


### [29] [OPEN: A Benchmark Dataset and Baseline for Older Adult Patient Engagement Recognition in Virtual Rehabilitation Learning Environments](https://arxiv.org/abs/2507.17959)
*Ali Abedi,Sadaf Safa,Tracey J. F. Colella,Shehroz S. Khan*

Main category: cs.CV

TL;DR: 该论文介绍了一个名为OPEN的新数据集，用于驱动AI识别老年人在虚拟学习环境中的参与度，并展示了高达81%的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 在虚拟学习和康复中，参与度对于用户满意度、表现和依从性至关重要，尤其是在在线教育和虚拟康复中。然而，准确测量虚拟群组环境中的参与度仍是一个挑战，特别是针对老年人群体，相关研究和数据集非常有限。现有方法常忽略上下文相关性和参与度的长期性。

Method: 引入了OPEN（老年患者参与度）数据集，该数据集从11名老年人每周参与为期六周的虚拟小组学习（心脏康复的一部分）中收集，共计超过35小时数据。为保护隐私，不提供原始视频，而是发布从视频中提取的面部、手部和身体关节地标、情感和行为特征。标注包括二元参与状态、情感和行为标签以及上下文类型指示器。数据集提供5秒、10秒、30秒和可变长度的样本版本。通过训练多种机器学习和深度学习模型来验证其效用。

Result: OPEN是同类数据集中最大的数据集，包含超过35小时的数据。通过训练机器学习和深度学习模型，实现了高达81%的参与度识别准确率。

Conclusion: OPEN数据集为老龄人群的个性化参与度建模提供了可扩展的基础，并对更广泛的参与度识别研究做出了贡献。

Abstract: Engagement in virtual learning is essential for participant satisfaction,
performance, and adherence, particularly in online education and virtual
rehabilitation, where interactive communication plays a key role. Yet,
accurately measuring engagement in virtual group settings remains a challenge.
There is increasing interest in using artificial intelligence (AI) for
large-scale, real-world, automated engagement recognition. While engagement has
been widely studied in younger academic populations, research and datasets
focused on older adults in virtual and telehealth learning settings remain
limited. Existing methods often neglect contextual relevance and the
longitudinal nature of engagement across sessions. This paper introduces OPEN
(Older adult Patient ENgagement), a novel dataset supporting AI-driven
engagement recognition. It was collected from eleven older adults participating
in weekly virtual group learning sessions over six weeks as part of cardiac
rehabilitation, producing over 35 hours of data, making it the largest dataset
of its kind. To protect privacy, raw video is withheld; instead, the released
data include facial, hand, and body joint landmarks, along with affective and
behavioral features extracted from video. Annotations include binary engagement
states, affective and behavioral labels, and context-type indicators, such as
whether the instructor addressed the group or an individual. The dataset offers
versions with 5-, 10-, 30-second, and variable-length samples. To demonstrate
utility, multiple machine learning and deep learning models were trained,
achieving engagement recognition accuracy of up to 81 percent. OPEN provides a
scalable foundation for personalized engagement modeling in aging populations
and contributes to broader engagement recognition research.

</details>


### [30] [Bearded Dragon Activity Recognition Pipeline: An AI-Based Approach to Behavioural Monitoring](https://arxiv.org/abs/2507.17987)
*Arsen Yermukan,Pedro Machado,Feliciano Domingos,Isibor Kennedy Ihianle,Jordan J. Bird,Stefano S. K. Kaburu,Samantha J. Ward*

Main category: cs.CV

TL;DR: 该项目开发了一个基于YOLO模型（YOLOv8s最佳）的自动化系统，用于实时视频分析胡须龙的晒太阳和捕食行为，显著提高了监控效率，但蟋蟀检测准确性有待提高。


<details>
  <summary>Details</summary>
Motivation: 传统的胡须龙行为监测耗时且易出错，需要一种自动化、高效的解决方案。

Method: 项目采用You Only Look Once (YOLO) 系列目标检测模型（v5, v7, v8, v11, v12）进行实时视频分析。模型在一个包含胡须龙、加热灯和蟋蟀的自定义数据集（1200张图像）上进行训练。通过提取每帧目标坐标、应用时间插值和基于规则的逻辑来分类行为。最终选择YOLOv8s作为最佳模型。

Result: YOLOv8s被选为最佳模型，其准确性（mAP@0.5:0.95 = 0.855）和速度达到优异平衡。晒太阳行为的检测结果可靠。然而，捕食行为的检测准确性较低，主要原因是蟋蟀检测效果不佳（mAP@0.5 = 0.392）。

Conclusion: 该自动化系统为受控环境下爬行动物行为监测提供了一个可扩展的解决方案，显著提高了研究效率和数据质量。未来的改进将集中于通过扩充数据集或使用专门的小目标检测器来增强蟋蟀检测能力。

Abstract: Traditional monitoring of bearded dragon (Pogona Viticeps) behaviour is
time-consuming and prone to errors. This project introduces an automated system
for real-time video analysis, using You Only Look Once (YOLO) object detection
models to identify two key behaviours: basking and hunting. We trained five
YOLO variants (v5, v7, v8, v11, v12) on a custom, publicly available dataset of
1200 images, encompassing bearded dragons (600), heating lamps (500), and
crickets (100). YOLOv8s was selected as the optimal model due to its superior
balance of accuracy (mAP@0.5:0.95 = 0.855) and speed. The system processes
video footage by extracting per-frame object coordinates, applying temporal
interpolation for continuity, and using rule-based logic to classify specific
behaviours. Basking detection proved reliable. However, hunting detection was
less accurate, primarily due to weak cricket detection (mAP@0.5 = 0.392).
Future improvements will focus on enhancing cricket detection through expanded
datasets or specialised small-object detectors. This automated system offers a
scalable solution for monitoring reptile behaviour in controlled environments,
significantly improving research efficiency and data quality.

</details>


### [31] [AG-VPReID.VIR: Bridging Aerial and Ground Platforms for Video-based Visible-Infrared Person Re-ID](https://arxiv.org/abs/2507.17995)
*Huy Nguyen,Kien Nguyen,Akila Pemasiri,Akmal Jahan,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: 该研究引入了首个空对地跨模态视频行人重识别数据集AG-VPReID.VIR，并提出了一个三流架构TCC-VPReID以应对跨平台和跨模态的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的行人重识别数据集主要关注地面视角，而地面红外系统存在遮挡、覆盖范围有限和易受阻碍等问题。空中视角能有效解决这些问题，但缺乏相应的跨模态数据集和方法来支持24小时监控系统。

Method: 引入了AG-VPReID.VIR数据集，包含1837个身份、4861个轨迹（124855帧），通过无人机和固定CCTV摄像头在RGB和红外模态下采集。提出了TCC-VPReID，一个新颖的三流架构，通过风格鲁棒特征学习、基于记忆的跨视角适应和中介引导的时间建模，来弥合空对地视角和RGB-IR模态之间的域差异。

Result: AG-VPReID.VIR数据集相比现有数据集提出了独特的挑战。所提出的TCC-VPReID框架在多个评估协议下取得了显著的性能提升。

Conclusion: 该研究通过提供一个新颖的空对地跨模态视频行人重识别数据集和一种有效的三流架构，显著推动了跨平台和跨模态行人重识别领域的发展，为24小时监控系统提供了关键支持。

Abstract: Person re-identification (Re-ID) across visible and infrared modalities is
crucial for 24-hour surveillance systems, but existing datasets primarily focus
on ground-level perspectives. While ground-based IR systems offer nighttime
capabilities, they suffer from occlusions, limited coverage, and vulnerability
to obstructions--problems that aerial perspectives uniquely solve. To address
these limitations, we introduce AG-VPReID.VIR, the first aerial-ground
cross-modality video-based person Re-ID dataset. This dataset captures 1,837
identities across 4,861 tracklets (124,855 frames) using both UAV-mounted and
fixed CCTV cameras in RGB and infrared modalities. AG-VPReID.VIR presents
unique challenges including cross-viewpoint variations, modality discrepancies,
and temporal dynamics. Additionally, we propose TCC-VPReID, a novel
three-stream architecture designed to address the joint challenges of
cross-platform and cross-modality person Re-ID. Our approach bridges the domain
gaps between aerial-ground perspectives and RGB-IR modalities, through
style-robust feature learning, memory-based cross-view adaptation, and
intermediary-guided temporal modeling. Experiments show that AG-VPReID.VIR
presents distinctive challenges compared to existing datasets, with our
TCC-VPReID framework achieving significant performance gains across multiple
evaluation protocols. Dataset and code are available at
https://github.com/agvpreid25/AG-VPReID.VIR.

</details>


### [32] [Exploring the interplay of label bias with subgroup size and separability: A case study in mammographic density classification](https://arxiv.org/abs/2507.17996)
*Emma A. M. Stanley,Raghav Mehta,Mélanie Roschewitz,Nils D. Forkert,Ben Glocker*

Main category: cs.CV

TL;DR: 本研究发现，医学影像数据集中特定子群体的标签偏差（即标签偏倚）会导致深度学习模型学习到的特征表示发生显著偏移，并影响子群体性能，其影响程度取决于受影响子群体的大小和可分离性。


<details>
  <summary>Details</summary>
Motivation: 医学影像数据集中影响特定子群体的系统性错误标注（即标签偏倚）是一个未被充分研究的问题，它关乎医疗AI系统的公平性。

Method: 研究人员使用EMory BrEast imaging Dataset (EMBED)训练了用于二元组织密度分类的深度学习模型。他们模拟了标签偏倚，使其影响可分离子群体（基于成像制造商）或不可分离的“伪子群体”，并观察标签偏倚对模型学习特征和性能的影响。

Result: 模拟的子群体标签偏倚导致模型学习到的特征表示发生显著偏移，且这些偏移取决于受标签偏倚影响子群体的相对大小和可分离性。此外，子群体性能的差异也取决于是否使用具有干净标签的验证集来定义分类阈值。例如，当标签偏倚影响主要可分离子群体时，该子群体的真阳性率从使用干净标签验证集时的0.898下降到使用偏倚标签验证集时的0.518。

Conclusion: 本研究对理解标签偏倚在医学影像AI中对子群体公平性的影响做出了关键贡献。

Abstract: Systematic mislabelling affecting specific subgroups (i.e., label bias) in
medical imaging datasets represents an understudied issue concerning the
fairness of medical AI systems. In this work, we investigated how size and
separability of subgroups affected by label bias influence the learned features
and performance of a deep learning model. Therefore, we trained deep learning
models for binary tissue density classification using the EMory BrEast imaging
Dataset (EMBED), where label bias affected separable subgroups (based on
imaging manufacturer) or non-separable "pseudo-subgroups". We found that
simulated subgroup label bias led to prominent shifts in the learned feature
representations of the models. Importantly, these shifts within the feature
space were dependent on both the relative size and the separability of the
subgroup affected by label bias. We also observed notable differences in
subgroup performance depending on whether a validation set with clean labels
was used to define the classification threshold for the model. For instance,
with label bias affecting the majority separable subgroup, the true positive
rate for that subgroup fell from 0.898, when the validation set had clean
labels, to 0.518, when the validation set had biased labels. Our work
represents a key contribution toward understanding the consequences of label
bias on subgroup fairness in medical imaging AI.

</details>


### [33] [Degradation-Consistent Learning via Bidirectional Diffusion for Low-Light Image Enhancement](https://arxiv.org/abs/2507.18144)
*Jinhong He,Minglong Xue,Zhipu Liu,Mingliang Zhou,Aoxiang Ning,Palaiahnakote Shivakumara*

Main category: cs.CV

TL;DR: 提出了一种双向扩散优化机制（BidDiff）用于低光图像增强，通过同时建模低光和正常光图像的降质过程，并结合特征交互和反射感知校正，解决了现有单向扩散方法在复杂真实世界降质中的局限性，实现了更高质量的图像增强。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在低光图像增强中表现出色，但其单向降质建模难以捕捉真实世界降质的复杂性，导致结构不一致和像素错位，无法有效提升图像可见性以符合人类视觉感知。

Method: 本文提出双向扩散优化机制，在训练过程中进行低光到正常光和正常光到低光的双向扩散建模，以实现更精确的降质参数匹配。引入自适应特征交互块（AFI）来优化特征表示，并通过双向路径的互补性施加隐式对称约束。此外，设计了反射感知校正模块（RACM）来引导去噪后的色彩恢复并抑制过曝区域。

Result: 在多个基准数据集上的广泛实验表明，该方法在定量和定性评估方面均优于现有最先进的方法，并且能有效泛化到不同的降质场景。

Conclusion: 通过双向扩散优化机制、特征交互和反射感知校正，本文提出的方法能够更准确地学习和感知光照与细节降质，从而生成高质量、符合人类视觉感知的低光增强图像。

Abstract: Low-light image enhancement aims to improve the visibility of degraded images
to better align with human visual perception. While diffusion-based methods
have shown promising performance due to their strong generative capabilities.
However, their unidirectional modelling of degradation often struggles to
capture the complexity of real-world degradation patterns, leading to
structural inconsistencies and pixel misalignments. To address these
challenges, we propose a bidirectional diffusion optimization mechanism that
jointly models the degradation processes of both low-light and normal-light
images, enabling more precise degradation parameter matching and enhancing
generation quality. Specifically, we perform bidirectional diffusion-from
low-to-normal light and from normal-to-low light during training and introduce
an adaptive feature interaction block (AFI) to refine feature representation.
By leveraging the complementarity between these two paths, our approach imposes
an implicit symmetry constraint on illumination attenuation and noise
distribution, facilitating consistent degradation learning and improving the
models ability to perceive illumination and detail degradation. Additionally,
we design a reflection-aware correction module (RACM) to guide color
restoration post-denoising and suppress overexposed regions, ensuring content
consistency and generating high-quality images that align with human visual
perception. Extensive experiments on multiple benchmark datasets demonstrate
that our method outperforms state-of-the-art methods in both quantitative and
qualitative evaluations while generalizing effectively to diverse degradation
scenarios. Code at https://github.com/hejh8/BidDiff

</details>


### [34] [Registration beyond Points: General Affine Subspace Alignment via Geodesic Distance on Grassmann Manifold](https://arxiv.org/abs/2507.17998)
*Jaeho Shin,Hyeonjae Gil,Junwoo Jang,Maani Ghaffari,Ayoung Kim*

Main category: cs.CV

TL;DR: 本文首次推导了一个可优化的仿射格拉斯曼流形上的代价函数，用于测量特征间的距离，并能应用于刚体变换下的配准问题，实现全局最优解。


<details>
  <summary>Details</summary>
Motivation: 现有的仿射格拉斯曼方法虽然能精确测量特征间的接近度，但无法提供一个显式的、关于刚体变换的距离函数，这限制了其在配准问题中的应用，导致可优化的流形距离函数仍未被充分开发。

Method: 本文通过严格的数学证明，首次明确推导了一个可优化的代价函数，该函数将高维线性子空间的基础作为代价的显式表示。在此基础上，提出了一种基于变换后的基础的可优化代价函数，可应用于任何仿射子空间的配准问题。该方法通过直接最小化测地距离来寻找全局最优解。

Result: 与基于向量参数的方法相比，本文方法能够通过直接最小化测地距离来找到全局最优解，且不受表示模糊性的影响。所得到的代价函数及其在内点集最大化BnB求解器中的扩展，在各种计算机视觉任务中均表现出改进现有解决方案的收敛性或超越现有解决方案的性能。

Conclusion: 本文成功推导并提出了一个可优化的仿射格拉斯曼流形上的距离代价函数，该函数能够明确表示刚体变换下的特征距离，并实现了全局最优配准。这显著提升了现有配准方案的性能和收敛性，为计算机视觉任务提供了新的有效工具。

Abstract: Affine Grassmannian has been favored for expressing proximity between lines
and planes due to its theoretical exactness in measuring distances among
features. Despite this advantage, the existing method can only measure the
proximity without yielding the distance as an explicit function of rigid body
transformation. Thus, an optimizable distance function on the manifold has
remained underdeveloped, stifling its application in registration problems.
This paper is the first to explicitly derive an optimizable cost function
between two Grassmannian features with respect to rigid body transformation
($\mathbf{R}$ and $\mathbf{t}$). Specifically, we present a rigorous
mathematical proof demonstrating that the bases of high-dimensional linear
subspaces can serve as an explicit representation of the cost. Finally, we
propose an optimizable cost function based on the transformed bases that can be
applied to the registration problem of any affine subspace. Compared to vector
parameter-based approaches, our method is able to find a globally optimal
solution by directly minimizing the geodesic distance which is agnostic to
representation ambiguity. The resulting cost function and its extension to the
inlier-set maximizing \ac{BnB} solver have been demonstrated to improve the
convergence of existing solutions or outperform them in various computer vision
tasks. The code is available on
https://github.com/joomeok/GrassmannRegistration.

</details>


### [35] [Synthetic Data Augmentation for Enhanced Chicken Carcass Instance Segmentation](https://arxiv.org/abs/2507.18558)
*Yihong Feng,Chaitanya Pallerla,Xiaomin Lin,Pouya Sohrabipour Sr,Philip Crandall,Wan Shou,Yu She,Dongyi Wang*

Main category: cs.CV

TL;DR: 本研究首次提出生成逼真、自动标注的鸡胴体合成图像的流程，并引入了一个新的真实世界基准数据集。结果表明，合成数据显著提升了鸡胴体实例分割的性能，为解决家禽加工业中真实标注数据稀缺的问题提供了有效策略。


<details>
  <summary>Details</summary>
Motivation: 家禽加工线上鸡胴体的自动化检测对于质量控制、食品安全和操作效率至关重要。然而，在快节奏的工业环境中，开发鲁棒的深度学习模型（如实例分割）往往受限于获取和标注大规模真实世界图像数据集的艰巨性。

Method: 本研究开发了首个能生成逼真、自动标注的鸡胴体合成图像的流程。同时，创建了一个包含300张标注真实图像的新基准数据集。研究人员将这些数据集用于评估合成数据和自动数据标注在增强鸡胴体实例分割方面的有效性，特别是在真实标注数据稀缺的情况下。他们使用不同比例的合成图像与少量真实数据集，在主流实例分割模型上进行了评估。

Result: 实验结果表明，合成数据显著提升了所有模型在鸡胴体分割任务上的性能。

Conclusion: 本研究强调了合成数据增强作为一种可行且有效的策略的价值，可以缓解数据稀缺、减少人工标注工作，并推动家禽加工业中鸡胴体鲁棒AI驱动自动化检测系统的发展。

Abstract: The poultry industry has been driven by broiler chicken production and has
grown into the world's largest animal protein sector. Automated detection of
chicken carcasses on processing lines is vital for quality control, food
safety, and operational efficiency in slaughterhouses and poultry processing
plants. However, developing robust deep learning models for tasks like instance
segmentation in these fast-paced industrial environments is often hampered by
the need for laborious acquisition and annotation of large-scale real-world
image datasets. We present the first pipeline generating photo-realistic,
automatically labeled synthetic images of chicken carcasses. We also introduce
a new benchmark dataset containing 300 annotated real-world images, curated
specifically for poultry segmentation research. Using these datasets, this
study investigates the efficacy of synthetic data and automatic data annotation
to enhance the instance segmentation of chicken carcasses, particularly when
real annotated data from the processing line is scarce. A small real dataset
with varying proportions of synthetic images was evaluated in prominent
instance segmentation models. Results show that synthetic data significantly
boosts segmentation performance for chicken carcasses across all models. This
research underscores the value of synthetic data augmentation as a viable and
effective strategy to mitigate data scarcity, reduce manual annotation efforts,
and advance the development of robust AI-driven automated detection systems for
chicken carcasses in the poultry processing industry.

</details>


### [36] [GRR-CoCa: Leveraging LLM Mechanisms in Multimodal Model Architectures](https://arxiv.org/abs/2507.18009)
*Jake R. Patock,Nicole Catherine Lewis,Kevin McCoy,Christina Gomez,Canling Chen,Lorenzo Luzi*

Main category: cs.CV

TL;DR: 本文提出了GRR-CoCa模型，通过将LLM中有效的架构改进（高斯误差门控线性单元、均方根归一化、旋转位置嵌入）引入CoCa模型的文本解码器和视觉编码器，显著提升了图像和文本生成任务的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管最先进的多模态模型（如CoCa）表现出色，但其架构复杂性通常落后于当代大型语言模型（LLMs）。研究旨在将LLM中已验证有效的架构改进引入多模态模型，以提升其性能。

Method: 研究者提出了GRR-CoCa，在SOTA的CoCa模型中，将高斯误差门控线性单元、均方根归一化和旋转位置嵌入集成到文本解码器和视觉Transformer (ViT) 编码器中。通过标准的预训练和微调流程，将GRR-CoCa与基线CoCa（具有相同修改的文本解码器但保留CoCa原始ViT编码器）进行对比基准测试。

Result: GRR-CoCa在预训练数据集和三个多样化的微调数据集上均显著优于基线CoCa。预训练阶段，对比损失降低27.25%，困惑度降低3.71%，CoCa损失降低7.15%。微调阶段，平均对比损失降低13.66%，困惑度降低5.18%，CoCa损失降低5.55%。

Conclusion: GRR-CoCa的改进架构能够提升模型在视觉-语言域中的性能和泛化能力，证明了将LLM的先进架构引入多模态模型的有效性。

Abstract: State-of-the-art (SOTA) image and text generation models are multimodal
models that have many similarities to large language models (LLMs). Despite
achieving strong performances, leading foundational multimodal model
architectures frequently lag behind the architectural sophistication of
contemporary LLMs. We propose GRR-CoCa, an improved SOTA Contrastive Captioner
(CoCa) model that incorporates Gaussian error gated linear units, root mean
squared normalization, and rotary positional embedding into the textual
decoders and the vision transformer (ViT) encoder. Each architectural
modification has been shown to improve model performance in LLMs, but has yet
to be adopted in CoCa. We benchmarked GRR-CoCa against Baseline CoCa, a model
with the same modified textual decoders but with CoCa's original ViT encoder.
We used standard pretraining and fine-tuning workflows to benchmark the models
on contrastive and generative tasks. Our GRR-CoCa significantly outperformed
Baseline CoCa on the pretraining dataset and three diverse fine-tuning
datasets. Pretraining improvements were 27.25% in contrastive loss, 3.71% in
perplexity, and 7.15% in CoCa loss. The average fine-tuning improvements were
13.66% in contrastive loss, 5.18% in perplexity, and 5.55% in CoCa loss. We
show that GRR-CoCa's modified architecture improves performance and
generalization across vision-language domains.

</details>


### [37] [Celeb-DF++: A Large-scale Challenging Video DeepFake Benchmark for Generalizable Forensics](https://arxiv.org/abs/2507.18015)
*Yuezun Li,Delong Zhu,Xinjie Cui,Siwei Lyu*

Main category: cs.CV

TL;DR: 本文介绍了Celeb-DF++，一个用于可泛化DeepFake检测的新的大规模、多样化视频数据集，涵盖换脸、面部重演和说话脸三种伪造场景，使用22种方法生成，并评估了24种现有检测方法的泛化能力。


<details>
  <summary>Details</summary>
Motivation: AI技术快速发展导致DeepFake视频多样性增加，对“可泛化取证”（即使用单一模型检测广泛的、未见过的DeepFake类型）提出了紧迫挑战。现有数据集尽管规模大，但伪造类型有限，不足以开发可泛化检测方法。

Method: 在Celeb-DF数据集基础上，构建了Celeb-DF++。该数据集包含换脸（FS）、面部重演（FR）和说话脸（TF）三种常见伪造场景，使用22种不同的最新DeepFake方法生成了大量高质量伪造视频。同时，引入了评估协议来衡量24种最新检测方法的泛化能力。

Result: Celeb-DF++是一个大规模且具有挑战性的DeepFake基准数据集，涵盖了野外最常见的DeepFake案例。对现有24种检测方法的评估显示，它们在泛化能力上存在局限性，并突显了新数据集的难度。

Conclusion: Celeb-DF++的引入旨在解决DeepFake的可泛化取证挑战，通过提供多样化的数据和评估协议，揭示了现有检测方法的不足，为未来更鲁棒的DeepFake检测方法研究奠定了基础。

Abstract: The rapid advancement of AI technologies has significantly increased the
diversity of DeepFake videos circulating online, posing a pressing challenge
for \textit{generalizable forensics}, \ie, detecting a wide range of unseen
DeepFake types using a single model. Addressing this challenge requires
datasets that are not only large-scale but also rich in forgery diversity.
However, most existing datasets, despite their scale, include only a limited
variety of forgery types, making them insufficient for developing generalizable
detection methods. Therefore, we build upon our earlier Celeb-DF dataset and
introduce {Celeb-DF++}, a new large-scale and challenging video DeepFake
benchmark dedicated to the generalizable forensics challenge. Celeb-DF++ covers
three commonly encountered forgery scenarios: Face-swap (FS), Face-reenactment
(FR), and Talking-face (TF). Each scenario contains a substantial number of
high-quality forged videos, generated using a total of 22 various recent
DeepFake methods. These methods differ in terms of architectures, generation
pipelines, and targeted facial regions, covering the most prevalent DeepFake
cases witnessed in the wild. We also introduce evaluation protocols for
measuring the generalizability of 24 recent detection methods, highlighting the
limitations of existing detection methods and the difficulty of our new
dataset.

</details>


### [38] [High-fidelity 3D Gaussian Inpainting: preserving multi-view consistency and photorealistic details](https://arxiv.org/abs/2507.18023)
*Jun Zhou,Dinghao Li,Nannan Li,Mingjie Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的3D高斯修复框架，利用稀疏修复视图重建完整3D场景，并通过自动掩码细化和区域不确定性引导优化提升修复质量和视图一致性。


<details>
  <summary>Details</summary>
Motivation: 尽管NeRF和3DGS等技术在3D重建和新视图合成方面取得了显著进展，但3D场景修复仍具挑战性，主要原因在于3D结构固有的不规则性以及保持多视图一致性的关键需求。

Method: 该框架通过以下方法实现：1) 自动掩码细化过程，利用高斯场景滤波和反向投影操作，实现更精确的遮挡区域定位和逼真的边界恢复。2) 区域不确定性引导的精细优化策略，在训练期间估计多视图图像中每个区域的重要性，以缓解多视图不一致性并增强修复结果的细节保真度。

Result: 在多样化数据集上进行的综合实验表明，该方法在视觉质量和视图一致性方面均优于现有最先进的方法。

Conclusion: 所提出的3D高斯修复框架能够有效重建完整的3D场景，并在修复质量和多视图一致性方面表现出色。

Abstract: Recent advancements in multi-view 3D reconstruction and novel-view synthesis,
particularly through Neural Radiance Fields (NeRF) and 3D Gaussian Splatting
(3DGS), have greatly enhanced the fidelity and efficiency of 3D content
creation. However, inpainting 3D scenes remains a challenging task due to the
inherent irregularity of 3D structures and the critical need for maintaining
multi-view consistency. In this work, we propose a novel 3D Gaussian inpainting
framework that reconstructs complete 3D scenes by leveraging sparse inpainted
views. Our framework incorporates an automatic Mask Refinement Process and
region-wise Uncertainty-guided Optimization. Specifically, we refine the
inpainting mask using a series of operations, including Gaussian scene
filtering and back-projection, enabling more accurate localization of occluded
regions and realistic boundary restoration. Furthermore, our Uncertainty-guided
Fine-grained Optimization strategy, which estimates the importance of each
region across multi-view images during training, alleviates multi-view
inconsistencies and enhances the fidelity of fine details in the inpainted
results. Comprehensive experiments conducted on diverse datasets demonstrate
that our approach outperforms existing state-of-the-art methods in both visual
quality and view consistency.

</details>


### [39] [Emotion Recognition from Skeleton Data: A Comprehensive Survey](https://arxiv.org/abs/2507.18026)
*Haifeng Lu,Jiuyi Chen,Zhen Zhang,Ruida Liu,Runhao Zeng,Xiping Hu*

Main category: cs.CV

TL;DR: 该综述全面系统地回顾了基于骨架的肢体动作情感识别技术，涵盖心理学模型、数据集、方法分类、技术范式（Traditional, Feat2Net, FeatFusionNet, End2EndNet），以及在心理健康评估中的应用和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的情感识别方法依赖面部表情或生理信号，存在隐私问题。3D骨架采集和姿态估计技术的进步，使得通过全身动作进行情感识别成为一种有前景且保护隐私的替代方案。

Method: 首先介绍情感的心理学模型及肢体动作与情感表达的关系；其次总结公开数据集及其采集与标注策略；然后将现有方法分为基于姿态和基于步态的方法，并从数据驱动和技术角度进行分析；提出一个统一的技术分类范式，包括传统方法、Feat2Net、FeatFusionNet和End2EndNet；回顾并比较各类别代表性工作及其基准测试结果；最后探讨其在心理健康评估中的应用。

Result: 提供了一个对基于骨架的情感识别技术的全面系统回顾，提出了一种统一的技术分类范式，并比较了各方法的性能。揭示了该技术在精神健康评估（如抑郁症和自闭症检测）中的应用潜力。

Conclusion: 基于骨架的肢体动作情感识别是一个快速发展的领域，具有扩展应用前景，尤其是在心理健康评估方面。该领域仍面临挑战，未来研究方向广阔。

Abstract: Emotion recognition through body movements has emerged as a compelling and
privacy-preserving alternative to traditional methods that rely on facial
expressions or physiological signals. Recent advancements in 3D skeleton
acquisition technologies and pose estimation algorithms have significantly
enhanced the feasibility of emotion recognition based on full-body motion. This
survey provides a comprehensive and systematic review of skeleton-based emotion
recognition techniques. First, we introduce psychological models of emotion and
examine the relationship between bodily movements and emotional expression.
Next, we summarize publicly available datasets, highlighting the differences in
data acquisition methods and emotion labeling strategies. We then categorize
existing methods into posture-based and gait-based approaches, analyzing them
from both data-driven and technical perspectives. In particular, we propose a
unified taxonomy that encompasses four primary technical paradigms: Traditional
approaches, Feat2Net, FeatFusionNet, and End2EndNet. Representative works
within each category are reviewed and compared, with benchmarking results
across commonly used datasets. Finally, we explore the extended applications of
emotion recognition in mental health assessment, such as detecting depression
and autism, and discuss the open challenges and future research directions in
this rapidly evolving field.

</details>


### [40] [DSFormer: A Dual-Scale Cross-Learning Transformer for Visual Place Recognition](https://arxiv.org/abs/2507.18444)
*Haiyang Jiang,Songhao Piao,Chao Gao,Lei Yu,Liguo Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种结合双尺度Transformer (DSFormer) 和创新块聚类策略的视觉地点识别(VPR)框架，以应对环境和视角变化带来的挑战。该框架通过双尺度特征融合和优化的数据组织，实现了鲁棒的全局嵌入，显著减少了训练数据量，并在多个基准数据集上取得了最先进的性能和更高的计算效率。


<details>
  <summary>Details</summary>
Motivation: 视觉地点识别(VPR)对于移动机器人鲁棒定位至关重要，但在不同环境条件和视角下保持可靠性能面临巨大挑战。

Method: 本文提出一个新颖的框架，整合了：1. 双尺度Transformer (DSFormer)：一个基于Transformer的交叉学习模块，通过自注意力实现双尺度特征（来自最后两个CNN层）的内部长程依赖和共享交叉注意力实现跨尺度信息双向传输，以增强特征表示，捕获语义丰富性和空间细节。2. 创新块聚类策略：重新划分广泛使用的SF-XL训练数据集，从多个不同视角优化数据组织，进一步增强对视角变化的鲁棒性。

Result: 该方法不仅生成了对环境变化适应性强的鲁棒全局嵌入，而且与现有分区方法相比，将所需训练数据量减少了约30%。综合实验表明，该方法在大多数基准数据集上实现了最先进的性能，作为使用512维全局描述符的全局检索方案，超越了DELG、Patch-NetVLAD、TransVPR和R2Former等先进方法，并显著提高了计算效率。

Conclusion: 所提出的集成DSFormer和块聚类策略的VPR框架，有效解决了环境和视角变化带来的挑战，实现了鲁棒、高效且性能领先的视觉地点识别解决方案。

Abstract: Visual Place Recognition (VPR) is crucial for robust mobile robot
localization, yet it faces significant challenges in maintaining reliable
performance under varying environmental conditions and viewpoints. To address
this, we propose a novel framework that integrates Dual-Scale-Former
(DSFormer), a Transformer-based cross-learning module, with an innovative block
clustering strategy. DSFormer enhances feature representation by enabling
bidirectional information transfer between dual-scale features extracted from
the final two CNN layers, capturing both semantic richness and spatial details
through self-attention for long-range dependencies within each scale and shared
cross-attention for cross-scale learning. Complementing this, our block
clustering strategy repartitions the widely used San Francisco eXtra Large
(SF-XL) training dataset from multiple distinct perspectives, optimizing data
organization to further bolster robustness against viewpoint variations.
Together, these innovations not only yield a robust global embedding adaptable
to environmental changes but also reduce the required training data volume by
approximately 30\% compared to previous partitioning methods. Comprehensive
experiments demonstrate that our approach achieves state-of-the-art performance
across most benchmark datasets, surpassing advanced reranking methods like
DELG, Patch-NetVLAD, TransVPR, and R2Former as a global retrieval solution
using 512-dim global descriptors, while significantly improving computational
efficiency.

</details>


### [41] [ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks](https://arxiv.org/abs/2507.18031)
*Ahmad ALBarqawi,Mahmoud Nazzal,Issa Khalil,Abdallah Khreishah,NhatHai Phan*

Main category: cs.CV

TL;DR: ViGText是一种新颖的深度伪造检测方法，它将图像与视觉大语言模型（VLLM）生成的文本解释集成到基于图的框架中，通过图神经网络（GNNs）进行分析，显著提高了对复杂定制深度伪造的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术日益猖獗，传统检测方法在面对复杂、定制化的深度伪造时，在泛化能力和抵御恶意攻击的鲁棒性方面表现不足，威胁媒体真实性。

Method: ViGText将图像分割成块，利用VLLM生成详细的文本解释，构建图像图和文本图，并通过图神经网络（GNNs）进行整合分析。该方法还通过跨空间和频率域的多级特征提取来捕获细节，以增强鲁棒性和准确性。

Result: 在泛化评估中，ViGText的平均F1分数从72.45%显著提高到98.32%，显示出对未见过的、微调的稳定扩散模型的卓越泛化能力。在鲁棒性方面，ViGText的召回率比其他方法提高了11.1%。即使面对针对其图基架构的定向攻击，分类性能下降也限制在4%以内。

Conclusion: ViGText通过详细的视觉和文本分析，为深度伪造检测设定了新标准，有助于确保媒体真实性和信息完整性。

Abstract: The rapid rise of deepfake technology, which produces realistic but
fraudulent digital content, threatens the authenticity of media. Traditional
deepfake detection approaches often struggle with sophisticated, customized
deepfakes, especially in terms of generalization and robustness against
malicious attacks. This paper introduces ViGText, a novel approach that
integrates images with Vision Large Language Model (VLLM) Text explanations
within a Graph-based framework to improve deepfake detection. The novelty of
ViGText lies in its integration of detailed explanations with visual data, as
it provides a more context-aware analysis than captions, which often lack
specificity and fail to reveal subtle inconsistencies. ViGText systematically
divides images into patches, constructs image and text graphs, and integrates
them for analysis using Graph Neural Networks (GNNs) to identify deepfakes.
Through the use of multi-level feature extraction across spatial and frequency
domains, ViGText captures details that enhance its robustness and accuracy to
detect sophisticated deepfakes. Extensive experiments demonstrate that ViGText
significantly enhances generalization and achieves a notable performance boost
when it detects user-customized deepfakes. Specifically, average F1 scores rise
from 72.45% to 98.32% under generalization evaluation, and reflects the model's
superior ability to generalize to unseen, fine-tuned variations of stable
diffusion models. As for robustness, ViGText achieves an increase of 11.1% in
recall compared to other deepfake detection approaches. When facing targeted
attacks that exploit its graph-based architecture, ViGText limits
classification performance degradation to less than 4%. ViGText uses detailed
visual and textual analysis to set a new standard for detecting deepfakes,
helping ensure media authenticity and information integrity.

</details>


### [42] [Enhancing Scene Transition Awareness in Video Generation via Post-Training](https://arxiv.org/abs/2507.18046)
*Hanwen Shen,Jiajie Lu,Yupeng Cao,Xiaonan Yang*

Main category: cs.CV

TL;DR: 当前AI视频生成模型难以处理多场景连贯过渡，本文提出TAV数据集，通过后训练显著提升模型对场景过渡的理解和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有AI视频生成模型在单场景短视频方面表现良好，但在生成具有连贯场景过渡的长视频时面临困难，主要原因是它们无法从提示词中推断出何时需要场景过渡。多数开源模型在单场景视频数据集上训练，限制了其学习和响应多场景提示的能力。

Method: 提出并构建了“过渡感知视频”（Transition-Aware Video, TAV）数据集，该数据集包含经过预处理的、具有多个场景过渡的视频片段，用于解决现有模型在场景过渡理解上的不足。

Result: 实验表明，在TAV数据集上进行后训练能够显著提升模型对基于提示词的场景过渡的理解能力，缩小了所需场景与生成场景之间的差距，并能保持图像质量。

Conclusion: 通过在TAV数据集上进行后训练，可以有效增强AI视频生成模型处理多场景连贯过渡的能力，从而克服现有模型在长视频生成中的局限性。

Abstract: Recent advances in AI-generated video have shown strong performance on
\emph{text-to-video} tasks, particularly for short clips depicting a single
scene. However, current models struggle to generate longer videos with coherent
scene transitions, primarily because they cannot infer when a transition is
needed from the prompt. Most open-source models are trained on datasets
consisting of single-scene video clips, which limits their capacity to learn
and respond to prompts requiring multiple scenes. Developing scene transition
awareness is essential for multi-scene generation, as it allows models to
identify and segment videos into distinct clips by accurately detecting
transitions.
  To address this, we propose the \textbf{Transition-Aware Video} (TAV)
dataset, which consists of preprocessed video clips with multiple scene
transitions. Our experiment shows that post-training on the \textbf{TAV}
dataset improves prompt-based scene transition understanding, narrows the gap
between required and generated scenes, and maintains image quality.

</details>


### [43] [BokehDiff: Neural Lens Blur with One-Step Diffusion](https://arxiv.org/abs/2507.18060)
*Chengxuan Zhu,Qingnan Fan,Qi Zhang,Jinwei Chen,Huaqi Zhang,Chao Xu,Boxin Shi*

Main category: cs.CV

TL;DR: BokehDiff是一种新颖的镜头模糊渲染方法，利用生成扩散先验实现物理准确和视觉吸引人的效果，解决了现有方法在深度估计和不连续性处的伪影问题。


<details>
  <summary>Details</summary>
Motivation: 现有镜头模糊渲染方法受限于深度估计的准确性，在深度不连续处产生伪影，无法生成物理准确且视觉吸引人的结果。

Method: 引入BokehDiff，采用受物理启发的自注意力模块，与图像形成过程对齐，并整合了依赖深度的弥散圈（CoC）约束和自遮挡效应。将扩散模型适应为一步推理方案，不引入额外噪声。为解决配对数据缺乏问题，提出使用扩散模型合成具有透明度的真实感前景。

Result: 实现了物理准确且视觉吸引人的结果，通过一步推理方案达到了高质量和高保真度。

Conclusion: BokehDiff通过结合物理启发机制和扩散先验，成功克服了传统方法的局限性，提供了卓越的镜头模糊渲染效果。

Abstract: We introduce BokehDiff, a novel lens blur rendering method that achieves
physically accurate and visually appealing outcomes, with the help of
generative diffusion prior. Previous methods are bounded by the accuracy of
depth estimation, generating artifacts in depth discontinuities. Our method
employs a physics-inspired self-attention module that aligns with the image
formation process, incorporating depth-dependent circle of confusion constraint
and self-occlusion effects. We adapt the diffusion model to the one-step
inference scheme without introducing additional noise, and achieve results of
high quality and fidelity. To address the lack of scalable paired data, we
propose to synthesize photorealistic foregrounds with transparency with
diffusion models, balancing authenticity and scene diversity.

</details>


### [44] [Adapting Large VLMs with Iterative and Manual Instructions for Generative Low-light Enhancement](https://arxiv.org/abs/2507.18064)
*Xiaoran Sun,Liyan Wang,Cong Wang,Yeying Jin,Kin-man Lam,Zhixun Su,Yang Yang,Jinshan Pan*

Main category: cs.CV

TL;DR: VLM-IMI是一个新颖的低光图像增强框架，它利用大型视觉-语言模型（VLM）和迭代手动指令（IMI），通过文本描述提供语义指导，以实现高质量的图像恢复。


<details>
  <summary>Details</summary>
Motivation: 现有低光图像增强方法多依赖预训练模型或低光输入，忽略了正常光图像中的语义指导，导致在复杂光照条件下效果受限。

Method: 提出VLM-IMI框架，利用视觉-语言模型，将目标正常光内容的文本描述作为增强线索，实现语义引导恢复。引入指令先验融合模块，动态对齐并融合图像和文本特征。推理时采用迭代和手动指令策略，逐步优化文本指令，提升视觉质量。

Result: 在多种场景下的广泛实验表明，VLM-IMI在定量指标和感知质量上均优于现有最先进方法，尤其在极低光照条件下能增强结构保真度、语义对齐和细节恢复。

Conclusion: VLM-IMI通过整合视觉-语言模型和迭代指令，有效解决了低光图像增强中语义信息缺失的问题，显著提升了图像恢复的质量和细节表现，为复杂光照条件下的图像增强提供了新范式。

Abstract: Most existing low-light image enhancement (LLIE) methods rely on pre-trained
model priors, low-light inputs, or both, while neglecting the semantic guidance
available from normal-light images. This limitation hinders their effectiveness
in complex lighting conditions. In this paper, we propose VLM-IMI, a novel
framework that leverages large vision-language models (VLMs) with iterative and
manual instructions (IMIs) for LLIE. VLM-IMI incorporates textual descriptions
of the desired normal-light content as enhancement cues, enabling semantically
informed restoration. To effectively integrate cross-modal priors, we introduce
an instruction prior fusion module, which dynamically aligns and fuses image
and text features, promoting the generation of detailed and semantically
coherent outputs. During inference, we adopt an iterative and manual
instruction strategy to refine textual instructions, progressively improving
visual quality. This refinement enhances structural fidelity, semantic
alignment, and the recovery of fine details under extremely low-light
conditions. Extensive experiments across diverse scenarios demonstrate that
VLM-IMI outperforms state-of-the-art methods in both quantitative metrics and
perceptual quality. The source code is available at
https://github.com/sunxiaoran01/VLM-IMI.

</details>


### [45] [TextSAM-EUS: Text Prompt Learning for SAM to Accurately Segment Pancreatic Tumor in Endoscopic Ultrasound](https://arxiv.org/abs/2507.18082)
*Pascal Spiegler,Taha Koleilat,Arash Harirpoush,Corey S. Miller,Hassan Rivaz,Marta Kersten-Oertel,Yiming Xiao*

Main category: cs.CV

TL;DR: TextSAM-EUS是一种新型轻量级文本驱动的SAM模型，通过利用文本提示学习和LoRA适配，实现了胰腺肿瘤超声图像（EUS）的自动分割，无需推理时手动几何提示，并且性能优于现有SOTA模型和SAM变体。


<details>
  <summary>Details</summary>
Motivation: 胰腺癌预后不良，依赖EUS进行活检和放疗。然而，EUS图像存在散斑噪声、对比度低和外观不直观等问题，使得全监督深度学习模型进行肿瘤分割容易出错，并高度依赖大型、专家标注的数据集。本研究旨在解决这些挑战。

Method: 提出了TextSAM-EUS，这是Segment Anything Model (SAM)的一种轻量级、文本驱动的改编。它通过BiomedCLIP文本编码器结合上下文优化实现文本提示学习，并采用基于LoRA的SAM架构适配，仅调整0.86%的总参数，从而实现胰腺肿瘤在EUS中的自动分割，推理时无需手动几何提示。

Result: 在公开的胰腺内窥镜超声数据库上，TextSAM-EUS在自动提示下达到了82.69%的Dice系数和85.28%的归一化表面距离（NSD）；在手动几何提示下达到了83.10%的Dice系数和85.70%的NSD。这优于现有的最先进（SOTA）监督深度学习模型和基础模型（如SAM及其变体）。

Conclusion: 作为首次将提示学习引入基于SAM的医学图像分割的尝试，TextSAM-EUS为高效、鲁棒的自动EUS分割提供了一个实用的选择。

Abstract: Pancreatic cancer carries a poor prognosis and relies on endoscopic
ultrasound (EUS) for targeted biopsy and radiotherapy. However, the speckle
noise, low contrast, and unintuitive appearance of EUS make segmentation of
pancreatic tumors with fully supervised deep learning (DL) models both
error-prone and dependent on large, expert-curated annotation datasets. To
address these challenges, we present TextSAM-EUS, a novel, lightweight,
text-driven adaptation of the Segment Anything Model (SAM) that requires no
manual geometric prompts at inference. Our approach leverages text prompt
learning (context optimization) through the BiomedCLIP text encoder in
conjunction with a LoRA-based adaptation of SAM's architecture to enable
automatic pancreatic tumor segmentation in EUS, tuning only 0.86% of the total
parameters. On the public Endoscopic Ultrasound Database of the Pancreas,
TextSAM-EUS with automatic prompts attains 82.69% Dice and 85.28% normalized
surface distance (NSD), and with manual geometric prompts reaches 83.10% Dice
and 85.70% NSD, outperforming both existing state-of-the-art (SOTA) supervised
DL models and foundation models (e.g., SAM and its variants). As the first
attempt to incorporate prompt learning in SAM-based medical image segmentation,
TextSAM-EUS offers a practical option for efficient and robust automatic EUS
segmentation. Our code will be publicly available upon acceptance.

</details>


### [46] [Comparison of Segmentation Methods in Remote Sensing for Land Use Land Cover](https://arxiv.org/abs/2507.18099)
*Naman Srivastava,Joel D Joy,Yash Dixit,Swarup E,Rakshit Ramesh*

Main category: cs.CV

TL;DR: 本研究评估了先进的土地利用土地覆盖（LULC）测绘技术，结合基于查找表的大气校正和深度学习模型（DeeplabV3+、动态加权CPS），并通过印度海得拉巴的案例研究，展示了其在快速城市化背景下监测土地利用变化和支持城市规划的实用性。


<details>
  <summary>Details</summary>
Motivation: 土地利用土地覆盖（LULC）测绘对于城市和资源规划至关重要，是发展智慧和可持续城市的关键要素。快速城市化导致显著的土地利用变化，需要有效的技术来监测和分析这些变化。

Method: 研究方法包括：1. 对Cartosat Multispectral (MX) 传感器图像应用基于查找表（LUT）的大气校正。2. 接着使用监督学习模型DeeplabV3+和半监督学习模型Cross-Pseudo Supervision (CPS) 进行LULC预测。3. CPS模型通过动态加权进行改进，以提高训练期间伪标签的可靠性。4. 以印度海得拉巴为例进行案例研究，分析LULC测绘技术的准确性和实用性。

Result: 研究分析了LULC测绘技术的准确性和实用性。海得拉巴的案例研究显示，由于快速城市化，该地区发生了显著的土地利用变化，例如城市扩张、绿地萎缩和工业区扩大。这证明了这些技术对城市规划者和政策制定者的实际效用。

Conclusion: 本研究展示的先进LULC测绘技术（包括LUT大气校正、DeeplabV3+和动态加权CPS）能够有效监测和分析城市化带来的土地利用变化，为城市规划者和政策制定者提供了重要的工具，以应对城市发展挑战。

Abstract: Land Use Land Cover (LULC) mapping is essential for urban and resource
planning, and is one of the key elements in developing smart and sustainable
cities.This study evaluates advanced LULC mapping techniques, focusing on
Look-Up Table (LUT)-based Atmospheric Correction applied to Cartosat
Multispectral (MX) sensor images, followed by supervised and semi-supervised
learning models for LULC prediction. We explore DeeplabV3+ and Cross-Pseudo
Supervision (CPS). The CPS model is further refined with dynamic weighting,
enhancing pseudo-label reliability during training. This comprehensive approach
analyses the accuracy and utility of LULC mapping techniques for various urban
planning applications. A case study of Hyderabad, India, illustrates
significant land use changes due to rapid urbanization. By analyzing Cartosat
MX images over time, we highlight shifts such as urban sprawl, shrinking green
spaces, and expanding industrial areas. This demonstrates the practical utility
of these techniques for urban planners and policymakers.

</details>


### [47] [Datasets and Recipes for Video Temporal Grounding via Reinforcement Learning](https://arxiv.org/abs/2507.18100)
*Ruizhe Chen,Zhiting Fan,Tianze Luo,Heqing Zou,Zhaopeng Feng,Guiyang Xie,Hansheng Zhang,Zhuochen Wang,Zuozhu Liu,Huaijian Zhang*

Main category: cs.CV

TL;DR: 本文提出一个两阶段训练框架，结合监督微调（SFT）和强化学习（RL），以提升视频时间定位（VTG）模型的准确性和泛化能力，尤其是在复杂和开放域场景下。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉-语言模型（LVLMs）和指令微调取得了进展，但现有视频时间定位（VTG）方法仍存在时间感知能力有限和泛化性差的问题。

Method: 采用两阶段训练框架：首先，利用高质量的“冷启动”数据进行监督微调（SFT）初始化；其次，通过难度控制的强化学习（RL）进一步增强时间定位和推理能力。

Result: 在多个VTG基准测试中，该方法始终优于现有模型，尤其在挑战性和开放域场景下表现突出。深入分析证实了高质量冷启动数据和难度控制强化学习的重要性。

Conclusion: 所提出的SFT与RL结合的两阶段训练框架显著提高了VTG模型的性能和鲁棒性。研究团队已发布所有中间数据集、模型和代码，以促进后续研究和工业应用。

Abstract: Video Temporal Grounding (VTG) aims to localize relevant temporal segments in
videos given natural language queries. Despite recent progress with large
vision-language models (LVLMs) and instruction-tuning, existing approaches
often suffer from limited temporal awareness and poor generalization. In this
work, we introduce a two-stage training framework that integrates supervised
fine-tuning with reinforcement learning (RL) to improve both the accuracy and
robustness of VTG models. Our approach first leverages high-quality curated
cold start data for SFT initialization, followed by difficulty-controlled RL to
further enhance temporal localization and reasoning abilities. Comprehensive
experiments on multiple VTG benchmarks demonstrate that our method consistently
outperforms existing models, particularly in challenging and open-domain
scenarios. We conduct an in-depth analysis of training strategies and dataset
curation, highlighting the importance of both high-quality cold start data and
difficulty-controlled RL. To facilitate further research and industrial
adoption, we release all intermediate datasets, models, and code to the
community.

</details>


### [48] [Distributional Uncertainty for Out-of-Distribution Detection](https://arxiv.org/abs/2507.18106)
*JinYoung Kim,DaeUng Jo,Kimin Yun,Jeonghyo Song,Youngjoon Yoo*

Main category: cs.CV

TL;DR: 该论文提出了一个名为自由能后验网络（Free-Energy Posterior Network）的新框架，通过结合Beta分布和残差预测分支（RPL），实现不确定性感知分割中的越界（OoD）样本检测，无需随机采样，从而提供了一个语义上有意义且计算高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的深度神经网络不确定性估计方法（如Monte Carlo Dropout）在检测越界（OoD）样本时，通常只关注模型或数据不确定性，未能与OoD检测的语义目标对齐。此外，这些方法可能需要随机采样或事后阈值设定。

Method: 本文提出了自由能后验网络，它联合建模分布不确定性并识别OoD和错误分类区域。该方法引入了两大贡献：1) 一个基于Beta分布参数化的自由能密度估计器，用于在模糊或未见区域进行细粒度不确定性估计；2) 一个集成在后验网络中的损失函数，允许直接从学习参数估计不确定性，无需随机采样。该方法还与残差预测分支（RPL）框架结合，利用Beta分布的方差使网络学习OoD区域。

Result: 该方法在包括Fishyscapes、RoadAnomaly和Segment-Me-If-You-Can在内的挑战性真实世界基准测试中验证了其有效性。

Conclusion: 该方法提供了一个语义上有意义且计算高效的不确定性感知分割解决方案，超越了传统的事后能量阈值方法，能够有效学习越界（OoD）区域。

Abstract: Estimating uncertainty from deep neural networks is a widely used approach
for detecting out-of-distribution (OoD) samples, which typically exhibit high
predictive uncertainty. However, conventional methods such as Monte Carlo (MC)
Dropout often focus solely on either model or data uncertainty, failing to
align with the semantic objective of OoD detection. To address this, we propose
the Free-Energy Posterior Network, a novel framework that jointly models
distributional uncertainty and identifying OoD and misclassified regions using
free energy. Our method introduces two key contributions: (1) a
free-energy-based density estimator parameterized by a Beta distribution, which
enables fine-grained uncertainty estimation near ambiguous or unseen regions;
and (2) a loss integrated within a posterior network, allowing direct
uncertainty estimation from learned parameters without requiring stochastic
sampling. By integrating our approach with the residual prediction branch (RPL)
framework, the proposed method goes beyond post-hoc energy thresholding and
enables the network to learn OoD regions by leveraging the variance of the Beta
distribution, resulting in a semantically meaningful and computationally
efficient solution for uncertainty-aware segmentation. We validate the
effectiveness of our method on challenging real-world benchmarks, including
Fishyscapes, RoadAnomaly, and Segment-Me-If-You-Can.

</details>


### [49] [A Multimodal Seq2Seq Transformer for Predicting Brain Responses to Naturalistic Stimuli](https://arxiv.org/abs/2507.18104)
*Qianyi He,Yuan Chang Leong*

Main category: cs.CV

TL;DR: 该研究提出了一种序列到序列的Transformer模型，利用多模态（视觉、听觉、语言）输入和先前的脑状态，自回归地预测自然电影刺激下的全脑fMRI活动，并在Algonauts 2025挑战赛中表现出色。


<details>
  <summary>Details</summary>
Motivation: 响应Algonauts 2025挑战赛的号召，旨在开发能够预测自然多模态电影刺激下全脑fMRI响应的编码模型。

Method: 采用序列到序列的Transformer模型，通过自回归方式预测fMRI活动。输入特征使用预训练模型（VideoMAE、HuBERT、Qwen、BridgeTower）提取。解码器通过双交叉注意力机制整合先前的脑状态、当前刺激和情节级摘要信息。模型创新点包括使用多模态上下文序列来预测脑活动序列，以捕捉长期时间结构；以及结合共享编码器和部分受试者特异性解码器，以兼顾通用结构和个体差异。

Result: 模型在同分布（in-distribution）和异分布（out-of-distribution）数据上均取得了强大的性能，证明了时间感知、多模态序列建模在脑活动预测中的有效性。

Conclusion: 时间感知和多模态序列建模方法对于预测大脑活动是有效的，本研究提出的模型在fMRI预测任务中展现了优异性能。

Abstract: The Algonauts 2025 Challenge called on the community to develop encoding
models that predict whole-brain fMRI responses to naturalistic multimodal
movies. In this submission, we propose a sequence-to-sequence Transformer that
autoregressively predicts fMRI activity from visual, auditory, and language
inputs. Stimulus features were extracted using pretrained models including
VideoMAE, HuBERT, Qwen, and BridgeTower. The decoder integrates information
from prior brain states, current stimuli, and episode-level summaries via dual
cross-attention mechanisms that attend to both perceptual information extracted
from the stimulus as well as narrative information provided by high-level
summaries of narrative content. One core innovation of our approach is the use
of sequences of multimodal context to predict sequences of brain activity,
enabling the model to capture long-range temporal structure in both stimuli and
neural responses. Another is the combination of a shared encoder with partial
subject-specific decoder, which leverages common structure across subjects
while accounting for individual variability. Our model achieves strong
performance on both in-distribution and out-of-distribution data, demonstrating
the effectiveness of temporally-aware, multimodal sequence modeling for brain
activity prediction. The code is available at
https://github.com/Angelneer926/Algonauts_challenge.

</details>


### [50] [Differential-UMamba: Rethinking Tumor Segmentation Under Limited Data Scenarios](https://arxiv.org/abs/2507.18177)
*Dhruv Jain,Romain Modzelewski,Romain Hérault,Clement Chatelain,Eva Torfeh,Sebastien Thureau*

Main category: cs.CV

TL;DR: Diff-UMamba是一种新型医学图像分割架构，结合了UNet和Mamba，并引入噪声抑制模块，旨在解决数据稀缺场景下的过拟合问题，提高分割精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺场景下，深度学习模型容易过拟合噪声和无关模式，限制了其对未见样本的泛化能力，尤其在医学图像分割中表现明显。

Method: 该研究提出了Diff-UMamba架构，它结合了UNet框架和Mamba机制来建模长程依赖。核心是一个噪声抑制模块（NRM），该模块在编码器内部采用信号差分策略来抑制噪声或不相关的激活，从而过滤掉伪特征并增强任务相关表示。

Result: Diff-UMamba在低数据设置下显著提高了分割精度和鲁棒性。在MSD（肺和胰腺）和AIIB23等公共数据集上，性能比基线方法提高了1-3%。在BraTS-21数据集上通过改变训练样本比例验证了其在有限数据条件下的表现。在内部非小细胞肺癌（NSCLC）GTV分割数据集（CBCT）上，比基线提高了4-5%。

Conclusion: Diff-UMamba通过有效抑制噪声和增强任务相关特征，在数据稀缺的医学图像分割任务中表现出优越的性能和鲁棒性，能够更好地聚焦于临床有意义的区域。

Abstract: In data-scarce scenarios, deep learning models often overfit to noise and
irrelevant patterns, which limits their ability to generalize to unseen
samples. To address these challenges in medical image segmentation, we
introduce Diff-UMamba, a novel architecture that combines the UNet framework
with the mamba mechanism for modeling long-range dependencies. At the heart of
Diff-UMamba is a Noise Reduction Module (NRM), which employs a signal
differencing strategy to suppress noisy or irrelevant activations within the
encoder. This encourages the model to filter out spurious features and enhance
task-relevant representations, thereby improving its focus on clinically
meaningful regions. As a result, the architecture achieves improved
segmentation accuracy and robustness, particularly in low-data settings.
Diff-UMamba is evaluated on multiple public datasets, including MSD (lung and
pancreas) and AIIB23, demonstrating consistent performance gains of 1-3% over
baseline methods across diverse segmentation tasks. To further assess
performance under limited-data conditions, additional experiments are conducted
on the BraTS-21 dataset by varying the proportion of available training
samples. The approach is also validated on a small internal non-small cell lung
cancer (NSCLC) dataset for gross tumor volume (GTV) segmentation in cone beam
CT (CBCT), where it achieves a 4-5% improvement over the baseline.

</details>


### [51] [T2VWorldBench: A Benchmark for Evaluating World Knowledge in Text-to-Video Generation](https://arxiv.org/abs/2507.18107)
*Yubin Chen,Xuyang Guo,Zhenmei Shi,Zhao Song,Jiahao Zhang*

Main category: cs.CV

TL;DR: 本文提出了T2VWorldBench，这是首个系统评估文本到视频（T2V）模型世界知识生成能力的框架，发现当前模型在这方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 尽管T2V模型在生成视觉合理场景方面表现出色，但它们利用世界知识确保语义一致性和事实准确性的能力仍未得到充分研究。

Method: 研究者提出了T2VWorldBench评估框架，涵盖物理、自然、活动、文化、因果和物体6大类、60个子类和1200个提示。该基准结合了人工评估和使用视觉语言模型（VLMs）的自动化评估。

Result: 研究评估了10个最先进的T2V模型，发现大多数模型无法理解世界知识并生成真正正确的视频。

Conclusion: 当前T2V模型在利用世界知识方面存在关键差距，这为构建具有强大常识推理和事实生成能力的模型提供了宝贵的研究机会和切入点。

Abstract: Text-to-video (T2V) models have shown remarkable performance in generating
visually reasonable scenes, while their capability to leverage world knowledge
for ensuring semantic consistency and factual accuracy remains largely
understudied. In response to this challenge, we propose T2VWorldBench, the
first systematic evaluation framework for evaluating the world knowledge
generation abilities of text-to-video models, covering 6 major categories, 60
subcategories, and 1,200 prompts across a wide range of domains, including
physics, nature, activity, culture, causality, and object. To address both
human preference and scalable evaluation, our benchmark incorporates both human
evaluation and automated evaluation using vision-language models (VLMs). We
evaluated the 10 most advanced text-to-video models currently available,
ranging from open source to commercial models, and found that most models are
unable to understand world knowledge and generate truly correct videos. These
findings point out a critical gap in the capability of current text-to-video
models to leverage world knowledge, providing valuable research opportunities
and entry points for constructing models with robust capabilities for
commonsense reasoning and factual generation.

</details>


### [52] [DepthDark: Robust Monocular Depth Estimation for Low-Light Environments](https://arxiv.org/abs/2507.18243)
*Longjian Zeng,Zunjie Zhu,Rongfeng Lu,Ming Lu,Bolun Zheng,Chenggang Yan,Anke Xue*

Main category: cs.CV

TL;DR: DepthDark是一个针对低光照单目深度估计的鲁棒基础模型，通过引入光照和噪声模拟模块生成高质量低光照深度数据集，并提出了一种有效的低光照PEFT策略，在夜间数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前单目深度估计的基础模型主要针对日光条件，在低光照环境下效果显著下降。主要挑战在于缺乏大规模高质量的低光照配对深度数据集以及有效的参数高效微调（PEFT）策略。

Method: 提出DepthDark模型。首先，引入光斑模拟模块和噪声模拟模块，以准确模拟夜间成像过程，生成高质量的低光照配对深度数据集。其次，提出一种有效的低光照PEFT策略，该策略利用光照引导和多尺度特征融合来增强模型在低光照环境下的能力。

Result: DepthDark在具有挑战性的nuScenes-Night和RobotCar-Night数据集上实现了最先进的深度估计性能，验证了其在有限训练数据和计算资源下的有效性。

Conclusion: DepthDark通过解决低光照数据集缺乏和缺乏有效PEFT策略的问题，显著提升了单目深度估计在低光照环境下的鲁棒性和准确性，为该领域提供了新的解决方案。

Abstract: In recent years, foundation models for monocular depth estimation have
received increasing attention. Current methods mainly address typical daylight
conditions, but their effectiveness notably decreases in low-light
environments. There is a lack of robust foundational models for monocular depth
estimation specifically designed for low-light scenarios. This largely stems
from the absence of large-scale, high-quality paired depth datasets for
low-light conditions and the effective parameter-efficient fine-tuning (PEFT)
strategy. To address these challenges, we propose DepthDark, a robust
foundation model for low-light monocular depth estimation. We first introduce a
flare-simulation module and a noise-simulation module to accurately simulate
the imaging process under nighttime conditions, producing high-quality paired
depth datasets for low-light conditions. Additionally, we present an effective
low-light PEFT strategy that utilizes illumination guidance and multiscale
feature fusion to enhance the model's capability in low-light environments. Our
method achieves state-of-the-art depth estimation performance on the
challenging nuScenes-Night and RobotCar-Night datasets, validating its
effectiveness using limited training data and computing resources.

</details>


### [53] [Information Entropy-Based Framework for Quantifying Tortuosity in Meibomian Gland Uneven Atrophy](https://arxiv.org/abs/2507.18135)
*Kesheng Wang,Xiaoyu Chen,Chunlei He,Fenfen Li,Xinxin Yu,Dexing Kong,Shoujun Huang,Qi Dai*

Main category: cs.CV

TL;DR: 该研究提出了一种基于信息熵的曲线扭曲度量化新框架，通过与参考曲线比较进行评估，并在睑板腺萎缩均匀性评估中验证了其在医学诊断中的有效性。


<details>
  <summary>Details</summary>
Motivation: 在医学图像分析领域，精确量化曲线扭曲度对于疾病的辅助诊断和病理评估至关重要，但传统方法存在局限性。

Method: 提出了一种基于信息熵的扭曲度量化框架，该框架结合了概率建模、熵理论和曲线数据域变换。与传统方法不同，它通过将目标曲线与指定的生物学参考曲线进行比较来评估扭曲度。研究首先通过数值模拟评估了方法的稳定性和有效性，然后将其应用于量化睑板腺萎缩的空间均匀性，并分析了蠕形螨阴性和阳性患者组之间的差异。

Result: 该框架成功量化了睑板腺萎缩的均匀性，结果显示蠕形螨阴性和阳性患者组之间基于扭曲度的均匀性存在显著差异，曲线下面积（AUC）为0.8768，敏感性为0.75，特异性为0.93。

Conclusion: 所提出的框架在曲线扭曲度分析中具有重要的临床实用性，并有望成为医学诊断中定量形态评估的通用工具。

Abstract: In the medical image analysis field, precise quantification of curve
tortuosity plays a critical role in the auxiliary diagnosis and pathological
assessment of various diseases. In this study, we propose a novel framework for
tortuosity quantification and demonstrate its effectiveness through the
evaluation of meibomian gland atrophy uniformity,serving as a representative
application scenario.
  We introduce an information entropy-based tortuosity quantification framework
that integrates probability modeling with entropy theory and incorporates
domain transformation of curve data. Unlike traditional methods such as
curvature or arc-chord ratio, this approach evaluates the tortuosity of a
target curve by comparing it to a designated reference curve. Consequently, it
is more suitable for tortuosity assessment tasks in medical data where
biologically plausible reference curves are available, providing a more robust
and objective evaluation metric without relying on idealized straight-line
comparisons.
  First, we conducted numerical simulation experiments to preliminarily assess
the stability and validity of the method. Subsequently, the framework was
applied to quantify the spatial uniformity of meibomian gland atrophy and to
analyze the difference in this uniformity between \textit{Demodex}-negative and
\textit{Demodex}-positive patient groups. The results demonstrated a
significant difference in tortuosity-based uniformity between the two groups,
with an area under the curve of 0.8768, sensitivity of 0.75, and specificity of
0.93. These findings highlight the clinical utility of the proposed framework
in curve tortuosity analysis and its potential as a generalizable tool for
quantitative morphological evaluation in medical diagnostics.

</details>


### [54] [Exploiting Gaussian Agnostic Representation Learning with Diffusion Priors for Enhanced Infrared Small Target Detection](https://arxiv.org/abs/2507.18260)
*Junyao Li,Yahao Lu,Xingyuan Guo,Xiaoyu Xian,Tiantian Wang,Yukai Shi*

Main category: cs.CV

TL;DR: 红外小目标检测（ISTD）在现实应用中面临数据稀缺导致性能脆弱的问题。本文研究了现有方法在数据稀缺下的表现，并提出了高斯不可知表示学习（G-ARL），包括高斯组压缩器（GGS）用于鲁棒表示学习，以及两阶段扩散模型用于高质量合成数据生成，有效提升了在数据稀缺场景下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测在实际应用中至关重要，但当前最先进的方法高度依赖大量昂贵的手动标注数据进行表示学习，导致它们在缺乏高质量红外数据的真实世界挑战中表现脆弱。现有理论受到数据稀缺场景下性能波动的挑战。

Method: 首先，研究了主流方法在不同数据稀缺程度下的检测性能变化。其次，引入了高斯不可知表示学习（Gaussian Agnostic Representation Learning），具体提出高斯组压缩器（Gaussian Group Squeezer），利用高斯采样和压缩进行非均匀量化，并通过利用多样化的训练样本增强模型韧性。然后，引入了两阶段扩散模型进行真实世界重建，通过将量化信号与真实世界分布对齐，显著提升了合成样本的质量和保真度。

Result: 在各种数据稀缺场景下，与最先进的检测方法进行对比评估，证明了所提出方法的有效性，显著提升了检测性能和合成样本的质量与保真度。

Conclusion: 所提出的高斯不可知表示学习方法，结合高斯组压缩器和两阶段扩散模型，有效解决了红外小目标检测在数据稀缺环境下的脆弱性问题，提高了模型在真实世界挑战中的检测性能和鲁棒性。

Abstract: Infrared small target detection (ISTD) plays a vital role in numerous
practical applications. In pursuit of determining the performance boundaries,
researchers employ large and expensive manual-labeling data for representation
learning. Nevertheless, this approach renders the state-of-the-art ISTD methods
highly fragile in real-world challenges. In this paper, we first study the
variation in detection performance across several mainstream methods under
various scarcity -- namely, the absence of high-quality infrared data -- that
challenge the prevailing theories about practical ISTD. To address this
concern, we introduce the Gaussian Agnostic Representation Learning.
Specifically, we propose the Gaussian Group Squeezer, leveraging Gaussian
sampling and compression for non-uniform quantization. By exploiting a diverse
array of training samples, we enhance the resilience of ISTD models against
various challenges. Then, we introduce two-stage diffusion models for
real-world reconstruction. By aligning quantized signals closely with
real-world distributions, we significantly elevate the quality and fidelity of
the synthetic samples. Comparative evaluations against state-of-the-art
detection methods in various scarcity scenarios demonstrate the efficacy of the
proposed approach.

</details>


### [55] [WaveMamba: Wavelet-Driven Mamba Fusion for RGB-Infrared Object Detection](https://arxiv.org/abs/2507.18173)
*Haodong Zhu,Wenhao Dong,Linlin Yang,Hong Li,Yuguang Yang,Yangyang Ren,Qingcheng Zhu,Zichao Feng,Changbai Li,Shaohui Lin,Runqi Wang,Xiaoyan Luo,Baochang Zhang*

Main category: cs.CV

TL;DR: 该论文提出WaveMamba，一种跨模态融合方法，通过离散小波变换（DWT）分解RGB和IR图像的频率特征，并利用改进的检测头和WaveMamba融合块（WMFB）进行低频和高频特征融合，显著提升了目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 利用可见光（RGB）和红外（IR）图像的互补特性，以显著提升目标检测的性能。

Method: 提出WaveMamba跨模态融合方法。首先，使用离散小波变换（DWT）分解RGB和IR图像的频率特征。其次，设计WaveMamba融合块（WMFB）进行全面的低频和高频子带融合：低频特征通过基于Mamba框架的低频Mamba融合块（LMFB）进行通道交换和门控注意力机制的深度融合；高频特征采用“绝对最大值”融合策略增强。最后，采用结合逆离散小波变换（IDWT）的改进检测头以减少信息损失并生成最终检测结果。

Result: 该方法显著提升了性能，超越了现有最先进的方法，并在四个基准测试中平均mAP提高了4.5%。

Conclusion: WaveMamba方法通过有效融合RGB和IR图像的互补频率特征，显著提升了目标检测性能，证明了其在多模态目标检测领域的先进性和有效性。

Abstract: Leveraging the complementary characteristics of visible (RGB) and infrared
(IR) imagery offers significant potential for improving object detection. In
this paper, we propose WaveMamba, a cross-modality fusion method that
efficiently integrates the unique and complementary frequency features of RGB
and IR decomposed by Discrete Wavelet Transform (DWT). An improved detection
head incorporating the Inverse Discrete Wavelet Transform (IDWT) is also
proposed to reduce information loss and produce the final detection results.
The core of our approach is the introduction of WaveMamba Fusion Block (WMFB),
which facilitates comprehensive fusion across low-/high-frequency sub-bands.
Within WMFB, the Low-frequency Mamba Fusion Block (LMFB), built upon the Mamba
framework, first performs initial low-frequency feature fusion with channel
swapping, followed by deep fusion with an advanced gated attention mechanism
for enhanced integration. High-frequency features are enhanced using a strategy
that applies an ``absolute maximum" fusion approach. These advancements lead to
significant performance gains, with our method surpassing state-of-the-art
approaches and achieving average mAP improvements of 4.5% on four benchmarks.

</details>


### [56] [A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation](https://arxiv.org/abs/2507.18323)
*Minje Park,Jeonghwa Lim,Taehyung Yu,Sunghoon Joo*

Main category: cs.CV

TL;DR: 该研究首次为心电图（ECG）波形特征描绘中的半监督语义分割（SemiSeg）建立了基准，并发现Transformer架构优于卷积网络。


<details>
  <summary>Details</summary>
Motivation: 心电图波形特征描绘对临床诊断至关重要，但公开可用的带注释数据集稀缺限制了深度学习的进展。半监督学习通过利用大量未标记的心电图数据，提供了一个有前景的解决方案。

Method: 研究构建并统一了多个公共数据集（包括此前未充分利用的来源），以支持鲁棒和多样化的评估。采用了计算机视觉领域的五种代表性SemiSeg算法，并在卷积网络和Transformer两种不同架构上实现。在域内和跨域两种设置下进行了评估。此外，提出了针对ECG的训练配置和增强策略，并引入了标准化的评估框架。

Result: 研究结果表明，在半监督心电图描绘任务中，Transformer架构的表现优于卷积网络。

Conclusion: 该基准有望为推进半监督心电图描绘方法奠定基础，并促进该领域的进一步研究。

Abstract: Electrocardiogram (ECG) delineation, the segmentation of meaningful waveform
features, is critical for clinical diagnosis. Despite recent advances using
deep learning, progress has been limited by the scarcity of publicly available
annotated datasets. Semi-supervised learning presents a promising solution by
leveraging abundant unlabeled ECG data. In this study, we present the first
systematic benchmark for semi-supervised semantic segmentation (SemiSeg) in ECG
delineation. We curated and unified multiple public datasets, including
previously underused sources, to support robust and diverse evaluation. We
adopted five representative SemiSeg algorithms from computer vision,
implemented them on two different architectures: the convolutional network and
the transformer, and evaluated them in two different settings: in-domain and
cross-domain. Additionally, we propose ECG-specific training configurations and
augmentation strategies and introduce a standardized evaluation framework. Our
results show that the transformer outperforms the convolutional network in
semi-supervised ECG delineation. We anticipate that our benchmark will serve as
a foundation for advancing semi-supervised ECG delineation methods and will
facilitate further research in this domain.

</details>


### [57] [Real-Time Object Detection and Classification using YOLO for Edge FPGAs](https://arxiv.org/abs/2507.18174)
*Rashed Al Amin,Roman Obermaisser*

Main category: cs.CV

TL;DR: 本文提出了一种资源高效的实时YOLOv5目标检测与分类系统，专为边缘FPGA优化，并在Xilinx Kria KV260上实现了高精度、低功耗和实时处理。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的目标检测方法（如CNN、SSD、YOLO）在FPGA上部署时，尽管在准确性和速度方面表现出色，但在实现适用于边缘FPGA平台的资源效率方面仍面临挑战。特别是在ADAS等对安全可靠性要求高的应用中，需要更高效的解决方案。

Method: 本文提出了一种基于YOLOv5的资源高效实时目标检测与分类系统，并针对FPGA部署进行了优化。该系统在COCO和GTSRD数据集上进行训练，并部署在Xilinx Kria KV260 FPGA开发板上。

Result: 实验结果表明，该系统实现了99%的分类准确率，功耗为3.5W，处理速度达到9帧/秒（FPS）。

Conclusion: 研究结果突显了所提出方法在实现边缘计算应用中实时、资源高效的目标检测与分类方面的有效性。

Abstract: Object detection and classification are crucial tasks across various
application domains, particularly in the development of safe and reliable
Advanced Driver Assistance Systems (ADAS). Existing deep learning-based methods
such as Convolutional Neural Networks (CNNs), Single Shot Detectors (SSDs), and
You Only Look Once (YOLO) have demonstrated high performance in terms of
accuracy and computational speed when deployed on Field-Programmable Gate
Arrays (FPGAs). However, despite these advances, state-of-the-art YOLO-based
object detection and classification systems continue to face challenges in
achieving resource efficiency suitable for edge FPGA platforms. To address this
limitation, this paper presents a resource-efficient real-time object detection
and classification system based on YOLOv5 optimized for FPGA deployment. The
proposed system is trained on the COCO and GTSRD datasets and implemented on
the Xilinx Kria KV260 FPGA board. Experimental results demonstrate a
classification accuracy of 99%, with a power consumption of 3.5W and a
processing speed of 9 frames per second (FPS). These findings highlight the
effectiveness of the proposed approach in enabling real-time,
resource-efficient object detection and classification for edge computing
applications.

</details>


### [58] [Improving Bird Classification with Primary Color Additives](https://arxiv.org/abs/2507.18334)
*Ezhini Rasendiran R,Chandresh Kumar Maurya*

Main category: cs.CV

TL;DR: 该研究通过将频率信息编码为颜色添加到声谱图中，显著提高了鸟类鸣叫声分类的准确性，超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 鸟类鸣叫声分类面临环境噪音、重叠发声和标签缺失等挑战。现有模型在低信噪比或多物种录音中表现不佳，且不同物种间相似的鸣叫模式（motifs）容易导致混淆。

Method: 将鸟类鸣叫声的可视化特征（音高模式、速度和重复，统称为motifs）应用于深度学习模型。为了解决相似motifs导致的混淆，研究将频率信息通过原色添加剂嵌入到声谱图中，以增强物种间的区分度。

Result: 实验结果表明，所提出的方法在统计学上显著优于未进行色彩化的模型，并超越了BirdCLEF 2024的冠军模型，F1分数提高了7.3%，ROC-AUC提高了6.2%，CMAP提高了6.6%。

Conclusion: 通过色彩化整合频率信息能够有效提升鸟类物种分类的准确性。

Abstract: We address the problem of classifying bird species using their song
recordings, a challenging task due to environmental noise, overlapping
vocalizations, and missing labels. Existing models struggle with low-SNR or
multi-species recordings. We hypothesize that birds can be classified by
visualizing their pitch pattern, speed, and repetition, collectively called
motifs. Deep learning models applied to spectrogram images help, but similar
motifs across species cause confusion. To mitigate this, we embed frequency
information into spectrograms using primary color additives. This enhances
species distinction and improves classification accuracy. Our experiments show
that the proposed approach achieves statistically significant gains over models
without colorization and surpasses the BirdCLEF 2024 winner, improving F1 by
7.3%, ROC-AUC by 6.2%, and CMAP by 6.6%. These results demonstrate the
effectiveness of incorporating frequency information via colorization.

</details>


### [59] [Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling](https://arxiv.org/abs/2507.18176)
*Abhishek Kaushik,Norbert Haala,Uwe Soergel*

Main category: cs.CV

TL;DR: 该研究提出一种新颖的两阶段无监督域适应（UDA）框架，用于解决3D LiDAR语义分割中的域漂移问题，结合对比预训练和多模型伪标签策略。


<details>
  <summary>Details</summary>
Motivation: 3D LiDAR语义分割在不同域（如传感器类型、地理位置）之间存在性能下降问题，而目标域的手动标注成本过高，这对于自动驾驶系统是关键挑战。

Method: 该方法采用两阶段框架：1. 使用段级无监督对比学习预训练骨干网络，以学习鲁棒的域不变特征。2. 引入多模型伪标签策略，通过集成多种最先进的架构（包括投影、体素、混合和圆柱体方法）并进行硬投票，为无标签目标域生成高质量的伪标签，然后使用这些伪标签微调预训练的网络。

Result: 实验结果表明，在将SemanticKITTI适应到无标签目标数据集（SemanticPOSS、SemanticSlamantic）时，该方法相较于直接迁移和单模型UDA方法，显著提高了分割精度。

Conclusion: 研究结果强调了结合对比预训练和精炼的集成伪标签策略的有效性，能够在不要求目标域标注的情况下，弥合复杂的域差距，从而提升3D LiDAR语义分割的性能。

Abstract: Addressing performance degradation in 3D LiDAR semantic segmentation due to
domain shifts (e.g., sensor type, geographical location) is crucial for
autonomous systems, yet manual annotation of target data is prohibitive. This
study addresses the challenge using Unsupervised Domain Adaptation (UDA) and
introduces a novel two-stage framework to tackle it. Initially, unsupervised
contrastive learning at the segment level is used to pre-train a backbone
network, enabling it to learn robust, domain-invariant features without labels.
Subsequently, a multi-model pseudo-labeling strategy is introduced, utilizing
an ensemble of diverse state-of-the-art architectures (including projection,
voxel, hybrid, and cylinder-based methods). Predictions from these models are
aggregated via hard voting to generate high-quality, refined pseudo-labels for
the unlabeled target domain, mitigating single-model biases. The contrastively
pre-trained network is then fine-tuned using these robust pseudo-labels.
Experiments adapting from SemanticKITTI to unlabeled target datasets
(SemanticPOSS, SemanticSlamantic) demonstrate significant improvements in
segmentation accuracy compared to direct transfer and single-model UDA
approaches. These results highlight the effectiveness of combining contrastive
pre-training with refined ensemble pseudo-labeling for bridging complex domain
gaps without requiring target domain annotations.

</details>


### [60] [MatSSL: Robust Self-Supervised Representation Learning for Metallographic Image Segmentation](https://arxiv.org/abs/2507.18184)
*Hoang Hai Nam Nguyen,Phan Nguyen Duc Hieu,Ho Won Lee*

Main category: cs.CV

TL;DR: MatSSL是一种流线型的自监督学习（SSL）架构，通过门控特征融合有效整合多级表示，使其能够仅利用少量未标记数据对金属材料微观结构图像进行有效适应和分析，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前金属材料显微图像分析依赖监督方法，需要为每个新数据集重新训练，且在标记样本稀少时表现不稳定。现有自监督学习方法虽有潜力，但大多仍依赖大规模数据集才能有效。MatSSL旨在克服这些局限性。

Method: MatSSL采用门控特征融合（Gated Feature Fusion）在骨干网络的每个阶段集成多级表示。其训练流程包括在小规模未标记数据集上进行自监督预训练，然后针对多个基准数据集进行微调。

Result: MatSSL在MetalDAM数据集上实现了69.13%的mIoU，优于ImageNet预训练编码器（66.73%）。在环境阻隔涂层（EBC）基准数据集上，与使用MicroNet预训练的模型相比，平均mIoU提高了近40%。

Conclusion: MatSSL能够利用少量未标记数据有效适应金相领域，同时保留从大规模自然图像预训练中学习到的丰富且可迁移的特征，从而实现卓越的性能。

Abstract: MatSSL is a streamlined self-supervised learning (SSL) architecture that
employs Gated Feature Fusion at each stage of the backbone to integrate
multi-level representations effectively. Current micrograph analysis of
metallic materials relies on supervised methods, which require retraining for
each new dataset and often perform inconsistently with only a few labeled
samples. While SSL offers a promising alternative by leveraging unlabeled data,
most existing methods still depend on large-scale datasets to be effective.
MatSSL is designed to overcome this limitation. We first perform
self-supervised pretraining on a small-scale, unlabeled dataset and then
fine-tune the model on multiple benchmark datasets. The resulting segmentation
models achieve 69.13% mIoU on MetalDAM, outperforming the 66.73% achieved by an
ImageNet-pretrained encoder, and delivers consistently up to nearly 40%
improvement in average mIoU on the Environmental Barrier Coating benchmark
dataset (EBC) compared to models pretrained with MicroNet. This suggests that
MatSSL enables effective adaptation to the metallographic domain using only a
small amount of unlabeled data, while preserving the rich and transferable
features learned from large-scale pretraining on natural images.

</details>


### [61] [TeEFusion: Blending Text Embeddings to Distill Classifier-Free Guidance](https://arxiv.org/abs/2507.18192)
*Minghao Fu,Guo-Hua Wang,Xiaohao Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: TeEFusion是一种高效的文本到图像生成模型蒸馏方法，通过融合文本嵌入并学习教师模型的复杂采样策略，显著降低推理成本，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型（如SD3）依赖复杂的采样策略和分类器无关指导（CFG）以确保高质量生成，但这导致高昂的推理成本，因为CFG需要两次前向传播，且采样算法复杂。

Method: TeEFusion通过线性操作直接融合条件和无条件文本嵌入，将指导强度融入文本嵌入中，从而在不增加额外参数的情况下重建所需指导。同时，它蒸馏了教师模型的复杂采样策略，使学生模型能从教师的输出中学习。

Result: 在SD3等先进模型上的实验表明，TeEFusion使学生模型能够以更简单、更高效的采样策略，紧密模仿教师模型的性能。学生模型推理速度比教师模型快6倍，同时图像质量与教师模型的复杂采样方法相当。

Conclusion: TeEFusion通过创新的文本嵌入融合和采样策略蒸馏，有效解决了文本到图像生成中高推理成本的问题，使得学生模型在保持高质量图像生成的同时，显著提高了推理效率。

Abstract: Recent advances in text-to-image synthesis largely benefit from sophisticated
sampling strategies and classifier-free guidance (CFG) to ensure high-quality
generation. However, CFG's reliance on two forward passes, especially when
combined with intricate sampling algorithms, results in prohibitively high
inference costs. To address this, we introduce TeEFusion (\textbf{Te}xt
\textbf{E}mbeddings \textbf{Fusion}), a novel and efficient distillation method
that directly incorporates the guidance magnitude into the text embeddings and
distills the teacher model's complex sampling strategy. By simply fusing
conditional and unconditional text embeddings using linear operations,
TeEFusion reconstructs the desired guidance without adding extra parameters,
simultaneously enabling the student model to learn from the teacher's output
produced via its sophisticated sampling approach. Extensive experiments on
state-of-the-art models such as SD3 demonstrate that our method allows the
student to closely mimic the teacher's performance with a far simpler and more
efficient sampling strategy. Consequently, the student model achieves inference
speeds up to 6$\times$ faster than the teacher model, while maintaining image
quality at levels comparable to those obtained through the teacher's complex
sampling approach. The code is publicly available at
\href{https://github.com/AIDC-AI/TeEFusion}{github.com/AIDC-AI/TeEFusion}.

</details>


### [62] [LEAF: Latent Diffusion with Efficient Encoder Distillation for Aligned Features in Medical Image Segmentation](https://arxiv.org/abs/2507.18214)
*Qilin Huang,Tianyu Lin,Zhiguang Chen,Fudan Zheng*

Main category: cs.CV

TL;DR: LEAF是一种基于潜在扩散模型的医学图像分割模型，通过直接预测分割图和特征蒸馏来改进扩散模型，在不增加推理成本的情况下显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在医学图像分割中直接沿用原始训练过程，未针对分割任务进行特定调整；常用的预训练扩散模型在特征提取方面仍存在不足。

Method: 提出LEAF模型，在微调阶段用直接预测分割图取代原始的噪声预测模式，以降低分割结果的方差；采用特征蒸馏方法，使卷积层的隐藏状态与基于Transformer的视觉编码器特征对齐。

Result: 实验结果表明，该方法在多个不同疾病类型的分割数据集上提升了原始扩散模型的性能。此外，该方法不改变模型架构，不增加推理阶段的参数量或计算量，效率高。

Conclusion: LEAF通过对扩散模型进行针对性调整和特征增强，在医学图像分割任务中实现了性能的显著提升，同时保持了高效性，为扩散模型在医学图像分割领域的应用提供了有效途径。

Abstract: Leveraging the powerful capabilities of diffusion models has yielded quite
effective results in medical image segmentation tasks. However, existing
methods typically transfer the original training process directly without
specific adjustments for segmentation tasks. Furthermore, the commonly used
pre-trained diffusion models still have deficiencies in feature extraction.
Based on these considerations, we propose LEAF, a medical image segmentation
model grounded in latent diffusion models. During the fine-tuning process, we
replace the original noise prediction pattern with a direct prediction of the
segmentation map, thereby reducing the variance of segmentation results. We
also employ a feature distillation method to align the hidden states of the
convolutional layers with the features from a transformer-based vision encoder.
Experimental results demonstrate that our method enhances the performance of
the original diffusion model across multiple segmentation datasets for
different disease types. Notably, our approach does not alter the model
architecture, nor does it increase the number of parameters or computation
during the inference phase, making it highly efficient.

</details>


### [63] [3D Test-time Adaptation via Graph Spectral Driven Point Shift](https://arxiv.org/abs/2507.18225)
*Xin Wei,Qin Yang,Yijie Fang,Mingrui Zhu,Nannan Wang*

Main category: cs.CV

TL;DR: GSDTTA是一种新颖的3D点云测试时间自适应方法，通过将自适应转移到图谱域，优化低频分量，实现高效且参数更少的自适应。


<details>
  <summary>Details</summary>
Motivation: 现有的3D点云测试时间自适应（TTA）方法在处理不规则和无序的3D点云时，常面临计算成本高昂、需要额外训练数据以及依赖耗时的空间域优化等挑战。

Method: GSDTTA将目标域点云表示为异常值感知图，并通过图傅里叶变换（GFT）转换到图谱域。自适应过程仅优化最低10%的频率分量以提高效率。之后应用逆GFT（IGFT）重建自适应点云。该过程通过特征图引导的自训练策略进行增强，迭代地优化谱调整和模型参数。

Result: 在基准数据集上的实验结果和消融研究表明，GSDTTA在3D点云分类方面优于现有TTA方法。

Conclusion: GSDTTA通过在图谱域进行自适应，提供了一种有效且高效的3D点云测试时间自适应解决方案，克服了现有方法的局限性。

Abstract: While test-time adaptation (TTA) methods effectively address domain shifts by
dynamically adapting pre-trained models to target domain data during online
inference, their application to 3D point clouds is hindered by their irregular
and unordered structure. Current 3D TTA methods often rely on computationally
expensive spatial-domain optimizations and may require additional training
data. In contrast, we propose Graph Spectral Domain Test-Time Adaptation
(GSDTTA), a novel approach for 3D point cloud classification that shifts
adaptation to the graph spectral domain, enabling more efficient adaptation by
capturing global structural properties with fewer parameters. Point clouds in
target domain are represented as outlier-aware graphs and transformed into
graph spectral domain by Graph Fourier Transform (GFT). For efficiency,
adaptation is performed by optimizing only the lowest 10% of frequency
components, which capture the majority of the point cloud's energy. An inverse
GFT (IGFT) is then applied to reconstruct the adapted point cloud with the
graph spectral-driven point shift. This process is enhanced by an
eigenmap-guided self-training strategy that iteratively refines both the
spectral adjustments and the model parameters. Experimental results and
ablation studies on benchmark datasets demonstrate the effectiveness of GSDTTA,
outperforming existing TTA methods for 3D point cloud classification.

</details>


### [64] [Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based Detection: Clarifying Problem Formulation and Experimental Protocols](https://arxiv.org/abs/2507.18457)
*Luo Cheng,Hanwei Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.CV

TL;DR: 提出一个与设备无关的标准化框架，以提高LiDAR物理对抗性攻击的可复现性、可比性，并成功将模拟攻击转移到物理系统。


<details>
  <summary>Details</summary>
Motivation: 数字对抗性攻击缺乏物理可实现性，而物理对抗性对象攻击研究不足且由于设置和硬件差异导致复现性差。

Method: 提出了一个与设备无关的标准化框架，抽象了物理对抗性对象攻击的关键元素，支持多种方法，并提供开源代码和模拟及真实世界基准测试协议。

Result: 该框架实现了公平比较，加速了研究，并通过将模拟攻击成功转移到物理LiDAR系统进行了验证。

Conclusion: 该框架不仅推进了研究，还提供了影响攻击成功因素的见解，加深了对真实世界LiDAR感知中对抗性鲁棒性的理解。

Abstract: Adversarial robustness in LiDAR-based 3D object detection is a critical
research area due to its widespread application in real-world scenarios. While
many digital attacks manipulate point clouds or meshes, they often lack
physical realizability, limiting their practical impact. Physical adversarial
object attacks remain underexplored and suffer from poor reproducibility due to
inconsistent setups and hardware differences. To address this, we propose a
device-agnostic, standardized framework that abstracts key elements of physical
adversarial object attacks, supports diverse methods, and provides open-source
code with benchmarking protocols in simulation and real-world settings. Our
framework enables fair comparison, accelerates research, and is validated by
successfully transferring simulated attacks to a physical LiDAR system. Beyond
the framework, we offer insights into factors influencing attack success and
advance understanding of adversarial robustness in real-world LiDAR perception.

</details>


### [65] [DATA: Domain-And-Time Alignment for High-Quality Feature Fusion in Collaborative Perception](https://arxiv.org/abs/2507.18237)
*Chengchang Tian,Jianwei Ma,Yan Huang,Zhanye Chen,Honghao Wei,Hui Zhang,Wei Hong*

Main category: cs.CV

TL;DR: 本文提出DATA网络，通过一致性保持域对齐和渐进式时间对齐模块，系统性地解决协同感知中特征级融合面临的域差异和时间错位问题，并增强语义表示，从而提升性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 协同感知中的特征级融合在性能与通信带宽之间取得平衡，但其有效性严重依赖于输入特征的质量。硬件多样性、部署条件导致的域差异以及传输延迟引起的时间错位会累积性地降低特征质量，影响协同网络的性能。

Method: 本文提出了Domain-And-Time Alignment (DATA) 网络。具体包括：1) 一致性保持域对齐模块(CDAM)，通过近端区域分层下采样和可观测性约束判别器减少域差异。2) 渐进式时间对齐模块(PTAM)，通过多尺度运动建模和两阶段补偿处理传输延迟。3) 实例聚焦特征聚合模块(IFAM)，在对齐特征的基础上增强语义表示。

Result: DATA网络在三个典型数据集上取得了最先进的性能，并在存在严重通信延迟和姿态误差的情况下保持了鲁棒性。

Conclusion: DATA网络通过系统性地对齐特征并最大化其语义表示，有效解决了协同感知中特征级融合的域差异和时间错位问题，实现了卓越且鲁棒的性能。

Abstract: Feature-level fusion shows promise in collaborative perception (CP) through
balanced performance and communication bandwidth trade-off. However, its
effectiveness critically relies on input feature quality. The acquisition of
high-quality features faces domain gaps from hardware diversity and deployment
conditions, alongside temporal misalignment from transmission delays. These
challenges degrade feature quality with cumulative effects throughout the
collaborative network. In this paper, we present the Domain-And-Time Alignment
(DATA) network, designed to systematically align features while maximizing
their semantic representations for fusion. Specifically, we propose a
Consistency-preserving Domain Alignment Module (CDAM) that reduces domain gaps
through proximal-region hierarchical downsampling and observability-constrained
discriminator. We further propose a Progressive Temporal Alignment Module
(PTAM) to handle transmission delays via multi-scale motion modeling and
two-stage compensation. Building upon the aligned features, an Instance-focused
Feature Aggregation Module (IFAM) is developed to enhance semantic
representations. Extensive experiments demonstrate that DATA achieves
state-of-the-art performance on three typical datasets, maintaining robustness
with severe communication delays and pose errors. The code will be released at
https://github.com/ChengchangTian/DATA.

</details>


### [66] [Reinforced Embodied Active Defense: Exploiting Adaptive Interaction for Robust Visual Perception in Adversarial 3D Environments](https://arxiv.org/abs/2507.18484)
*Xiao Yang,Lingxuan Wu,Lizhong Wang,Chengyang Ying,Hang Su,Jun Zhu*

Main category: cs.CV

TL;DR: 本文提出Rein-EAD，一种主动防御框架，通过强化学习和环境交互来提升3D感知系统在对抗攻击下的鲁棒性，有效降低攻击成功率并保持准确性。


<details>
  <summary>Details</summary>
Motivation: 3D环境中的对抗攻击对视觉感知系统构成严重威胁，尤其是在身份验证和自动驾驶等安全关键应用中。现有防御机制多为被动策略，依赖预设的攻击假设，在动态3D环境中适应性有限。

Method: 引入Rein-EAD框架，采用主动防御策略，利用自适应探索和环境交互来提升鲁棒性。通过多步目标优化，平衡即时预测准确性和预测熵最小化。此外，采用面向不确定性的奖励塑形机制，促进高效策略更新，降低计算开销，且无需可微分环境。

Result: 实验验证了Rein-EAD的有效性，显著降低了攻击成功率，同时在各种任务中保持了标准准确性。Rein-EAD对未知和自适应攻击表现出强大的泛化能力。

Conclusion: Rein-EAD是一种有效且实用的主动防御框架，适用于3D物体分类、人脸识别和自动驾驶等复杂的现实世界任务，能显著增强感知系统在3D对抗环境中的鲁棒性。

Abstract: Adversarial attacks in 3D environments have emerged as a critical threat to
the reliability of visual perception systems, particularly in safety-sensitive
applications such as identity verification and autonomous driving. These
attacks employ adversarial patches and 3D objects to manipulate deep neural
network (DNN) predictions by exploiting vulnerabilities within complex scenes.
Existing defense mechanisms, such as adversarial training and purification,
primarily employ passive strategies to enhance robustness. However, these
approaches often rely on pre-defined assumptions about adversarial tactics,
limiting their adaptability in dynamic 3D settings. To address these
challenges, we introduce Reinforced Embodied Active Defense (Rein-EAD), a
proactive defense framework that leverages adaptive exploration and interaction
with the environment to improve perception robustness in 3D adversarial
contexts. By implementing a multi-step objective that balances immediate
prediction accuracy with predictive entropy minimization, Rein-EAD optimizes
defense strategies over a multi-step horizon. Additionally, Rein-EAD involves
an uncertainty-oriented reward-shaping mechanism that facilitates efficient
policy updates, thereby reducing computational overhead and supporting
real-world applicability without the need for differentiable environments.
Comprehensive experiments validate the effectiveness of Rein-EAD, demonstrating
a substantial reduction in attack success rates while preserving standard
accuracy across diverse tasks. Notably, Rein-EAD exhibits robust generalization
to unseen and adaptive attacks, making it suitable for real-world complex
tasks, including 3D object classification, face recognition and autonomous
driving.

</details>


### [67] [LONG3R: Long Sequence Streaming 3D Reconstruction](https://arxiv.org/abs/2507.18255)
*Zhuoguang Chen,Minghui Qin,Tianyuan Yuan,Zhe Liu,Hang Zhao*

Main category: cs.CV

TL;DR: LONG3R是一种新颖的模型，专为长序列多视角流式3D场景重建设计，通过循环操作和创新的内存机制实现实时处理，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多视角场景重建方法在处理图像流时存在局限性，要么依赖耗时的离线优化，要么仅限于短序列，这阻碍了它们在实时场景中的应用。

Method: LONG3R模型通过循环操作实现实时处理，并随新观测值维护和更新内存。它采用记忆门控机制过滤相关内存，并结合新观测值输入到双源精炼解码器进行粗到细的交互。为有效捕获长序列记忆，提出了一种3D时空记忆，该记忆动态修剪冗余空间信息并自适应调整场景分辨率。此外，模型采用两阶段课程训练策略以提高长序列性能并保持训练效率。

Result: 实验证明，LONG3R在长序列处理方面优于现有最先进的流式方法，同时保持了实时推理速度。

Conclusion: LONG3R成功解决了长序列多视角流式3D重建的挑战，通过其创新的内存管理和训练策略，实现了实时高性能的场景重建。

Abstract: Recent advancements in multi-view scene reconstruction have been significant,
yet existing methods face limitations when processing streams of input images.
These methods either rely on time-consuming offline optimization or are
restricted to shorter sequences, hindering their applicability in real-time
scenarios. In this work, we propose LONG3R (LOng sequence streaming 3D
Reconstruction), a novel model designed for streaming multi-view 3D scene
reconstruction over longer sequences. Our model achieves real-time processing
by operating recurrently, maintaining and updating memory with each new
observation. We first employ a memory gating mechanism to filter relevant
memory, which, together with a new observation, is fed into a dual-source
refined decoder for coarse-to-fine interaction. To effectively capture
long-sequence memory, we propose a 3D spatio-temporal memory that dynamically
prunes redundant spatial information while adaptively adjusting resolution
along the scene. To enhance our model's performance on long sequences while
maintaining training efficiency, we employ a two-stage curriculum training
strategy, each stage targeting specific capabilities. Experiments demonstrate
that LONG3R outperforms state-of-the-art streaming methods, particularly for
longer sequences, while maintaining real-time inference speed. Project page:
https://zgchen33.github.io/LONG3R/.

</details>


### [68] [Explaining How Visual, Textual and Multimodal Encoders Share Concepts](https://arxiv.org/abs/2507.18512)
*Clément Cornet,Romaric Besançon,Hervé Le Borgne*

Main category: cs.CV

TL;DR: 该研究提出了一种新的指标，用于定量比较不同模态（视觉、文本、多模态）编码器从稀疏自编码器（SAE）中提取的特征，并量化特征共享度，从而揭示了多模态预训练的影响。


<details>
  <summary>Details</summary>
Motivation: 以往基于SAE特征的模型比较仅限于相同模态的模型，缺乏跨模态的定量比较方法，因此需要开发新的工具来克服这一限制。

Method: 提出了一种新颖的指标，用于跨模态SAE特征的模型定量比较；同时提出量化不同类型模型之间个体特征的“比较共享度”（Comparative Sharedness）。使用这两种新工具，对21个不同大小和数据集（通用及领域特定）的视觉、文本和多模态编码器进行了比较研究。

Result: 研究结果能够重新审视多模态背景下训练的编码器，并量化这些模型共享表征或特征的程度。结果还表明，视觉语言模型（VLMs）中特有的视觉特征与文本编码器共享，突显了文本预训练的影响。

Conclusion: 该研究提出的新工具成功实现了跨模态编码器特征的定量比较，揭示了不同模型间表征的共享程度，并强调了文本预训练在视觉特征形成中的重要作用。

Abstract: Sparse autoencoders (SAEs) have emerged as a powerful technique for
extracting human-interpretable features from neural networks activations.
Previous works compared different models based on SAE-derived features but
those comparisons have been restricted to models within the same modality. We
propose a novel indicator allowing quantitative comparison of models across SAE
features, and use it to conduct a comparative study of visual, textual and
multimodal encoders. We also propose to quantify the Comparative Sharedness of
individual features between different classes of models. With these two new
tools, we conduct several studies on 21 encoders of the three types, with two
significantly different sizes, and considering generalist and domain specific
datasets. The results allow to revisit previous studies at the light of
encoders trained in a multimodal context and to quantify to which extent all
these models share some representations or features. They also suggest that
visual features that are specific to VLMs among vision encoders are shared with
text encoders, highlighting the impact of text pretraining. The code is
available at https://github.com/CEA-LIST/SAEshareConcepts

</details>


### [69] [Dissecting the Dental Lung Cancer Axis via Mendelian Randomization and Mediation Analysis](https://arxiv.org/abs/2507.18287)
*Wenran Zhang,Huihuan Luo,Linda Wei,Ping Nie,Yiqun Wu,Dedong Yu*

Main category: cs.CV

TL;DR: 本研究通过孟德尔随机化方法发现龋齿与肺癌（尤其是鳞状细胞肺癌）之间存在显著因果关系，并部分通过肺功能下降介导，而牙周炎无此因果效应。


<details>
  <summary>Details</summary>
Motivation: 观察性研究提示口腔疾病（牙周炎、龋齿）与肺癌可能存在关联，但因果关系尚不明确。

Method: 采用两样本孟德尔随机化（MR）方法，利用大规模全基因组关联研究（GWAS）数据作为遗传工具（包括487,823例龋齿和506,594例牙周炎数据，以及肺癌联盟数据）。主要分析方法为逆方差加权法（IVW），肺功能介导作用通过delta方法评估。

Result: 龋齿对整体肺癌及其亚型（特别是鳞状细胞肺癌）存在显著正向因果效应。龋齿发病率每增加一个标准差，鳞状细胞肺癌风险增加188.0%（OR = 2.880）。这种效应部分由用力肺活量（FVC）和一秒用力呼气量（FEV1）下降介导，分别解释总效应的5.124%和5.890%。未发现牙周炎与肺癌的因果关系。

Conclusion: 研究结果表明龋齿是肺癌风险的一个因果因素，且部分通过肺功能受损介导。这提示应将口腔护理和肺功能监测纳入癌症预防策略。

Abstract: Periodontitis and dental caries are common oral diseases affecting billions
globally. While observational studies suggest links between these conditions
and lung cancer, causality remains uncertain. This study used two sample
Mendelian randomization (MR) to explore causal relationships between dental
traits (periodontitis, dental caries) and lung cancer subtypes, and to assess
mediation by pulmonary function. Genetic instruments were derived from the
largest available genome wide association studies, including data from 487,823
dental caries and 506,594 periodontitis cases, as well as lung cancer data from
the Transdisciplinary Research of Cancer in Lung consortium. Inverse variance
weighting was the main analytical method; lung function mediation was assessed
using the delta method. The results showed a significant positive causal effect
of dental caries on overall lung cancer and its subtypes. Specifically, a one
standard deviation increase in dental caries incidence was associated with a
188.0% higher risk of squamous cell lung carcinoma (OR = 2.880, 95% CI =
1.236--6.713, p = 0.014), partially mediated by declines in forced vital
capacity (FVC) and forced expiratory volume in one second (FEV1), accounting
for 5.124% and 5.890% of the total effect. No causal effect was found for
periodontitis. These findings highlight a causal role of dental caries in lung
cancer risk and support integrating dental care and pulmonary function
monitoring into cancer prevention strategies.

</details>


### [70] [LMM-Det: Make Large Multimodal Models Excel in Object Detection](https://arxiv.org/abs/2507.18300)
*Jincheng Li,Chunyu Xie,Ji Ao,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: 该研究提出LMM-Det，一种简单有效的方法，使大型多模态模型（LMMs）无需专用检测模块即可执行通用目标检测，缩小了LMMs与专业检测器在目标检测能力上的差距。


<details>
  <summary>Details</summary>
Motivation: 尽管大型多模态模型（LMMs）在多模态理解和推理方面表现出色，但在目标检测能力上与专业检测器相比存在显著差距。传统方法通常将笨重的检测器与LMMs集成，而本研究旨在探索LMMs自身进行目标检测的可能性。

Method: 研究通过深入分析LMMs在目标检测中的召回率下降问题，提出了数据分布调整和推理优化策略以提高召回率。此外，通过重新组织指令对话来增强LMMs的目标检测能力，从而实现无需额外检测模块的通用目标检测。

Result: 实验结果支持了大型多模态模型本身具备检测能力的论断，并证明了所提出的LMM-Det方法的有效性，使其能够进行通用的目标检测。

Conclusion: 大型多模态模型无需任何额外的检测模块，通过数据分布调整、推理优化和指令对话重组，即可有效实现目标检测功能，从而弥补了其与专业检测器在检测能力上的差距。

Abstract: Large multimodal models (LMMs) have garnered wide-spread attention and
interest within the artificial intelligence research and industrial
communities, owing to their remarkable capability in multimodal understanding,
reasoning, and in-context learning, among others. While LMMs have demonstrated
promising results in tackling multimodal tasks like image captioning, visual
question answering, and visual grounding, the object detection capabilities of
LMMs exhibit a significant gap compared to specialist detectors. To bridge the
gap, we depart from the conventional methods of integrating heavy detectors
with LMMs and propose LMM-Det, a simple yet effective approach that leverages a
Large Multimodal Model for vanilla object Detection without relying on
specialized detection modules. Specifically, we conduct a comprehensive
exploratory analysis when a large multimodal model meets with object detection,
revealing that the recall rate degrades significantly compared with specialist
detection models. To mitigate this, we propose to increase the recall rate by
introducing data distribution adjustment and inference optimization tailored
for object detection. We re-organize the instruction conversations to enhance
the object detection capabilities of large multimodal models. We claim that a
large multimodal model possesses detection capability without any extra
detection modules. Extensive experiments support our claim and show the
effectiveness of the versatile LMM-Det. The datasets, models, and codes are
available at https://github.com/360CVGroup/LMM-Det.

</details>


### [71] [VideoMind: An Omni-Modal Video Dataset with Intent Grounding for Deep-Cognitive Video Understanding](https://arxiv.org/abs/2507.18552)
*Baoyao Yang,Wanyun Li,Dixin Chen,Junxiang Chen,Wenbin Yao,Haifeng Lin*

Main category: cs.CV

TL;DR: 本文介绍了VideoMind，一个以视频为中心的综合模态数据集，旨在促进深度视频内容认知和增强多模态特征表示。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏对视频深层意图的表达，且无法支持需要上下文整合的非直接可观察的深层认知表达，因此需要一个能支持深度视频内容认知和增强多模态特征表示的新数据集。

Method: VideoMind数据集包含103K视频样本（3K用于测试），每个样本配有音频和系统化的分层（事实、抽象、意图）文本描述。意图表达通过Chain-of-Thought (COT) 方法使用mLLM生成。每份描述包含主体、地点、时间、事件、动作和意图的标注。论文建立了一个包含3,000个手动验证样本的黄金标准基准，并设计了混合认知检索实验，采用多级检索指标来评估深度视频理解。

Result: VideoMind数据集已公开发布。论文还发布了InternVideo、VAST、UMT-L等模型的评估结果。

Conclusion: VideoMind数据集为细粒度跨模态对齐提供了一个强大的基准，并推动了需要深度视频理解的领域发展，例如情感和意图识别。

Abstract: This paper introduces VideoMind, a video-centric omni-modal dataset designed
for deep video content cognition and enhanced multi-modal feature
representation. The dataset comprises 103K video samples (3K reserved for
testing), each paired with audio and systematically detailed textual
descriptions. Specifically, every video and its audio is described across three
hierarchical layers (factual, abstract, and intent), progressing from surface
to depth. It contains over 22 million words, averaging ~225 words per sample.
VideoMind's key distinction from existing datasets is its provision of intent
expressions, which require contextual integration across the entire video and
are not directly observable. These deep-cognitive expressions are generated
using a Chain-of-Thought (COT) approach, prompting the mLLM through
step-by-step reasoning. Each description includes annotations for subject,
place, time, event, action, and intent, supporting downstream recognition
tasks. Crucially, we establish a gold-standard benchmark with 3,000 manually
validated samples for evaluating deep-cognitive video understanding. We design
hybrid-cognitive retrieval experiments, scored by multi-level retrieval
metrics, to appropriately assess deep video comprehension. Evaluation results
for models (e.g., InternVideo, VAST, UMT-L) are released. VideoMind serves as a
powerful benchmark for fine-grained cross-modal alignment and advances fields
requiring in-depth video understanding, such as emotion and intent recognition.
The data is publicly available on GitHub, HuggingFace, and OpenDataLab,
https://github.com/cdx-cindy/VideoMind.

</details>


### [72] [Improving Large Vision-Language Models' Understanding for Field Data](https://arxiv.org/abs/2507.18311)
*Xiaomei Zhang,Hanyu Zheng,Xiangyu Zhu,Jinghuan Wei,Junhong Zou,Zhen Lei,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: FieldLVLM是一个新颖的框架，旨在提高大型视觉语言模型（LVLMs）对科学领域数据的理解能力，通过结合领域感知语言生成和数据压缩的多模态模型微调实现。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型（LVLMs）在集成视觉和文本理解的任务中表现出色，但它们在科学领域，特别是解释自然科学中常用的复杂场数据方面的应用尚未得到充分探索。

Method: FieldLVLM框架包含两个主要组件：1. 领域感知语言生成策略：利用专用机器学习管道从场数据中提取关键物理特征（如流分类、雷诺数、涡流模式），并将其转换为结构化文本描述作为数据集。2. 数据压缩的多模态模型微调：使用生成的数据集对LVLMs进行微调，采用数据压缩策略来减少场输入的复杂性并保留最具信息量的值，以确保与模型语言解码器兼容并有效指导学习。

Result: 在新提出的基准数据集上的实验结果表明，FieldLVLM在涉及科学场数据的任务中显著优于现有方法。

Conclusion: 该方法为将大型视觉语言模型应用于科学研究开辟了新的可能性，有助于弥合大型模型与特定领域发现之间的鸿沟。

Abstract: Large Vision-Language Models (LVLMs) have shown impressive capabilities
across a range of tasks that integrate visual and textual understanding, such
as image captioning and visual question answering. These models are trained on
large-scale image and video datasets paired with text, enabling them to bridge
visual perception and natural language processing. However, their application
to scientific domains, especially in interpreting complex field data commonly
used in the natural sciences, remains underexplored. In this work, we introduce
FieldLVLM, a novel framework designed to improve large vision-language models'
understanding of field data. FieldLVLM consists of two main components: a
field-aware language generation strategy and a data-compressed multimodal model
tuning. The field-aware language generation strategy leverages a
special-purpose machine learning pipeline to extract key physical features from
field data, such as flow classification, Reynolds number, and vortex patterns.
This information is then converted into structured textual descriptions that
serve as a dataset. The data-compressed multimodal model tuning focuses on
LVLMs with these generated datasets, using a data compression strategy to
reduce the complexity of field inputs and retain only the most informative
values. This ensures compatibility with the models language decoder and guides
its learning more effectively. Experimental results on newly proposed benchmark
datasets demonstrate that FieldLVLM significantly outperforms existing methods
in tasks involving scientific field data. Our findings suggest that this
approach opens up new possibilities for applying large vision-language models
to scientific research, helping bridge the gap between large models and
domain-specific discovery.

</details>


### [73] [Beyond Low-rankness: Guaranteed Matrix Recovery via Modified Nuclear Norm](https://arxiv.org/abs/2507.18327)
*Jiangjun Peng,Yisi Luo,Xiangyong Cao,Shuang Xu,Deyu Meng*

Main category: cs.CV

TL;DR: 本文提出了一种新的修正核范数（MNN）框架，通过对矩阵进行变换后应用核范数，联合捕获数据的局部信息和全局低秩性，并在鲁棒主成分分析和矩阵补全任务中提供了精确的理论恢复保证。


<details>
  <summary>Details</summary>
Motivation: 传统的核范数在矩阵恢复问题中主要利用数据的全局低秩结构。然而，现有方法在结合局部信息和全局低秩性时，往往需要调优权衡参数，且难以提供精确的理论恢复保证。因此，需要一种能够同时捕获这两种信息，且具有理论支持的新方法。

Method: 该研究引入了一个修正核范数（MNN）框架。MNN家族范数通过对原始矩阵进行适当变换，然后对变换后的矩阵执行核范数来定义。这种设计使其能够适应各种已验证的变换。

Result: 1. MNN框架能够联合捕获局部信息和全局低秩性，且无需进行权衡参数调优。2. 在对变换施加温和假设下，为鲁棒主成分分析和矩阵补全任务提供了精确的理论恢复保证，这是现有结合局部和全局信息的方法所不具备的。3. 大量实验证明了该方法的有效性。

Conclusion: MNN框架提供了一种通用、灵活且有效的结构化低秩恢复方法。它能够统一处理多种问题，并在同时捕获局部和全局信息方面表现出色，且具有坚实的理论基础和优异的实验性能。

Abstract: The nuclear norm (NN) has been widely explored in matrix recovery problems,
such as Robust PCA and matrix completion, leveraging the inherent global
low-rank structure of the data. In this study, we introduce a new modified
nuclear norm (MNN) framework, where the MNN family norms are defined by
adopting suitable transformations and performing the NN on the transformed
matrix. The MNN framework offers two main advantages: (1) it jointly captures
both local information and global low-rankness without requiring trade-off
parameter tuning; (2) Under mild assumptions on the transformation, we provided
exact theoretical recovery guarantees for both Robust PCA and MC tasks-an
achievement not shared by existing methods that combine local and global
information. Thanks to its general and flexible design, MNN can accommodate
various proven transformations, enabling a unified and effective approach to
structured low-rank recovery. Extensive experiments demonstrate the
effectiveness of our method. Code and supplementary material are available at
https://github.com/andrew-pengjj/modified_nuclear_norm.

</details>


### [74] [DRWKV: Focusing on Object Edges for Low-Light Image Enhancement](https://arxiv.org/abs/2507.18594)
*Xuecheng Bai,Yuxiang Wang,Boyu Hu,Qinyuan Jie,Chuanzhi Xu,Hongru Xiao,Kechen Li,Vera Chung*

Main category: cs.CV

TL;DR: 该论文提出了一种名为DRWKV的新型低光照图像增强模型，通过整合全局边缘Retinex理论、演进WKV注意力机制、双边光谱对齐器和定制损失函数，有效提升图像的边缘和细节保真度，同时保持低计算量和良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 低光照图像增强仍是一个具有挑战性的任务，尤其是在极端光照退化条件下，难以有效保留物体边缘连续性和精细结构细节。

Method: ['提出DRWKV模型，并整合了全局边缘Retinex (GER) 理论，以有效解耦光照和边缘结构，从而增强边缘保真度。', '引入演进WKV注意力机制，该机制采用螺旋扫描方式捕捉空间边缘连续性并更有效地建模不规则结构。', '设计了双边光谱对齐器 (Bi-SAB) 和定制的MS2-损失函数，用于联合对齐亮度和色度特征，以提高视觉自然度并减轻伪影。']

Result: ['在五个低光照图像增强基准测试中，DRWKV在PSNR、SSIM和NIQE指标上均达到领先性能，同时保持较低的计算复杂度。', 'DRWKV提升了低光照多目标跟踪等下游任务的性能，验证了其泛化能力。']

Conclusion: DRWKV模型在低光照图像增强任务中取得了领先性能，有效解决了边缘和细节保留的挑战，并且在保持低计算复杂度的同时，展现了良好的泛化能力，适用于多种低光照视觉任务。

Abstract: Low-light image enhancement remains a challenging task, particularly in
preserving object edge continuity and fine structural details under extreme
illumination degradation. In this paper, we propose a novel model, DRWKV
(Detailed Receptance Weighted Key Value), which integrates our proposed Global
Edge Retinex (GER) theory, enabling effective decoupling of illumination and
edge structures for enhanced edge fidelity. Secondly, we introduce Evolving WKV
Attention, a spiral-scanning mechanism that captures spatial edge continuity
and models irregular structures more effectively. Thirdly, we design the
Bilateral Spectrum Aligner (Bi-SAB) and a tailored MS2-Loss to jointly align
luminance and chrominance features, improving visual naturalness and mitigating
artifacts. Extensive experiments on five LLIE benchmarks demonstrate that DRWKV
achieves leading performance in PSNR, SSIM, and NIQE while maintaining low
computational complexity. Furthermore, DRWKV enhances downstream performance in
low-light multi-object tracking tasks, validating its generalization
capabilities.

</details>


### [75] [GVCCS: A Dataset for Contrail Identification and Tracking on Visible Whole Sky Camera Sequences](https://arxiv.org/abs/2507.18330)
*Gabriel Jarry,Ramon Dalmau,Philippe Very,Franck Ballerini,Stephania-Denisa Bocu*

Main category: cs.CV

TL;DR: 航空业的凝结尾迹对气候影响显著，但现有观测数据不足。本文提出了一个新的地面可见光凝结尾迹序列数据集（GVCCS）和一个统一的深度学习框架，以改善凝结尾迹监测和物理模型校准。


<details>
  <summary>Details</summary>
Motivation: 航空业的凝结尾迹对气候有重要影响，但当前物理模型精度受限于输入数据和复杂过程假设。现有观测数据集缺乏凝结尾迹的时间追踪和与源航班的关联，无法有效验证和校准模型。

Method: 开发了一个新的开放数据集“地面可见光凝结尾迹序列（GVCCS）”，通过地面全天空相机记录凝结尾迹，并对每个凝结尾迹进行单独标注、时间追踪和航班识别。同时，提出了一个统一的深度学习框架，使用全景分割模型实现语义分割（凝结尾迹像素识别）、实例分割（单个凝结尾迹分离）和时间追踪。

Result: GVCCS数据集包含122个视频序列（24,228帧），实现了凝结尾迹的个体标记和时间追踪，并为相机上方的凝结尾迹提供了航班标识符。所提出的深度学习框架能够在一个架构中完成凝结尾迹的语义分割、实例分割和时间追踪。

Conclusion: 该工作提供了高质量、时间解析的凝结尾迹标注和模型评估基准，有助于改进凝结尾迹监测，并促进物理模型的校准，从而更准确地理解和评估航空业对气候的影响。

Abstract: Aviation's climate impact includes not only CO2 emissions but also
significant non-CO2 effects, especially from contrails. These ice clouds can
alter Earth's radiative balance, potentially rivaling the warming effect of
aviation CO2. Physics-based models provide useful estimates of contrail
formation and climate impact, but their accuracy depends heavily on the quality
of atmospheric input data and on assumptions used to represent complex
processes like ice particle formation and humidity-driven persistence.
Observational data from remote sensors, such as satellites and ground cameras,
could be used to validate and calibrate these models. However, existing
datasets don't explore all aspect of contrail dynamics and formation: they
typically lack temporal tracking, and do not attribute contrails to their
source flights. To address these limitations, we present the Ground Visible
Camera Contrail Sequences (GVCCS), a new open data set of contrails recorded
with a ground-based all-sky camera in the visible range. Each contrail is
individually labeled and tracked over time, allowing a detailed analysis of its
lifecycle. The dataset contains 122 video sequences (24,228 frames) and
includes flight identifiers for contrails that form above the camera. As
reference, we also propose a unified deep learning framework for contrail
analysis using a panoptic segmentation model that performs semantic
segmentation (contrail pixel identification), instance segmentation (individual
contrail separation), and temporal tracking in a single architecture. By
providing high-quality, temporally resolved annotations and a benchmark for
model evaluation, our work supports improved contrail monitoring and will
facilitate better calibration of physical models. This sets the groundwork for
more accurate climate impact understanding and assessments.

</details>


### [76] [SynC: Synthetic Image Caption Dataset Refinement with One-to-many Mapping for Zero-shot Image Captioning](https://arxiv.org/abs/2507.18616)
*Si-Woo Kim,MinJu Jeon,Ye-Chan Kim,Soeun Lee,Taewhan Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: 针对零样本图像字幕（ZIC）中由文本到图像（T2I）模型生成的合成数据存在的图像语义与字幕不匹配问题，SynC提出一种新颖的框架，通过在现有合成图像池中重新分配字幕到最语义对齐的图像，从而提升ZIC模型性能。


<details>
  <summary>Details</summary>
Motivation: 零样本图像字幕（ZIC）依赖于文本到图像（T2I）模型生成的合成数据集来避免昂贵的手动标注。然而，T2I模型生成的图像常与输入字幕存在语义不匹配（如缺少物体、属性错误），导致合成图像-字幕对噪声大，阻碍模型训练。现有数据集去噪技术主要针对网络爬取数据中的文本噪声，不适用于合成数据中字幕良好但图像不准确的独特挑战。

Method: SynC框架旨在优化ZIC的合成图像-字幕数据集。它不采用传统的过滤或重新生成，而是专注于将字幕重新分配给合成图像池中已有的、语义最对齐的图像。该方法采用一对多映射策略，首先为每个字幕检索多个相关的候选图像，然后应用一个受循环一致性启发的对齐评分器，通过验证图像能否通过图文检索召回原始字幕来选择最佳图像。

Result: 广泛的评估表明，SynC在各种ZIC模型上，于标准基准（MS-COCO、Flickr30k、NoCaps）上持续显著提升性能，并在多个场景中达到最先进水平。

Conclusion: SynC为整理精炼的合成数据以增强ZIC提供了一种有效的策略。

Abstract: Zero-shot Image Captioning (ZIC) increasingly utilizes synthetic datasets
generated by text-to-image (T2I) models to mitigate the need for costly manual
annotation. However, these T2I models often produce images that exhibit
semantic misalignments with their corresponding input captions (e.g., missing
objects, incorrect attributes), resulting in noisy synthetic image-caption
pairs that can hinder model training. Existing dataset pruning techniques are
largely designed for removing noisy text in web-crawled data. However, these
methods are ill-suited for the distinct challenges of synthetic data, where
captions are typically well-formed, but images may be inaccurate
representations. To address this gap, we introduce SynC, a novel framework
specifically designed to refine synthetic image-caption datasets for ZIC.
Instead of conventional filtering or regeneration, SynC focuses on reassigning
captions to the most semantically aligned images already present within the
synthetic image pool. Our approach employs a one-to-many mapping strategy by
initially retrieving multiple relevant candidate images for each caption. We
then apply a cycle-consistency-inspired alignment scorer that selects the best
image by verifying its ability to retrieve the original caption via
image-to-text retrieval. Extensive evaluations demonstrate that SynC
consistently and significantly improves performance across various ZIC models
on standard benchmarks (MS-COCO, Flickr30k, NoCaps), achieving state-of-the-art
results in several scenarios. SynC offers an effective strategy for curating
refined synthetic data to enhance ZIC.

</details>


### [77] [Boosting Multi-View Indoor 3D Object Detection via Adaptive 3D Volume Construction](https://arxiv.org/abs/2507.18331)
*Runmin Zhang,Zhu Yu,Si-Yuan Cao,Lingyu Zhu,Guangyi Zhang,Xiaokai Bai,Hui-Liang Shen*

Main category: cs.CV

TL;DR: SGCDet是一个新颖的多视角室内3D目标检测框架，通过自适应3D体素构建和几何上下文感知聚合模块，有效整合多视角信息并减少冗余计算，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将体素感受野限制在图像上的固定位置，导致特征表示能力受限且在自由空间中存在大量冗余计算，因此需要一种更自适应、高效的方式来整合多视角信息并优化体素构建。

Method: SGCDet框架包含两个核心创新：1. 几何和上下文感知聚合模块：在每张图像中自适应区域内整合几何和上下文信息，并动态调整不同视角的贡献，以增强体素特征的表示能力。2. 稀疏体素构建策略：自适应识别并选择高占用概率的体素进行特征细化，从而最小化自由空间中的冗余计算。此外，该网络仅使用3D边界框进行监督，无需依赖真实场景几何。

Result: SGCDet框架实现了有效且高效的自适应体素构建。在ScanNet、ScanNet200和ARKitScenes数据集上，其性能达到了最先进水平。

Conclusion: SGCDet通过创新的自适应3D体素构建和特征聚合机制，显著提升了多视角室内3D目标检测的效率和准确性，且无需依赖场景几何信息，达到了领域领先的性能。

Abstract: This work presents SGCDet, a novel multi-view indoor 3D object detection
framework based on adaptive 3D volume construction. Unlike previous approaches
that restrict the receptive field of voxels to fixed locations on images, we
introduce a geometry and context aware aggregation module to integrate
geometric and contextual information within adaptive regions in each image and
dynamically adjust the contributions from different views, enhancing the
representation capability of voxel features. Furthermore, we propose a sparse
volume construction strategy that adaptively identifies and selects voxels with
high occupancy probabilities for feature refinement, minimizing redundant
computation in free space. Benefiting from the above designs, our framework
achieves effective and efficient volume construction in an adaptive way. Better
still, our network can be supervised using only 3D bounding boxes, eliminating
the dependence on ground-truth scene geometry. Experimental results demonstrate
that SGCDet achieves state-of-the-art performance on the ScanNet, ScanNet200
and ARKitScenes datasets. The source code is available at
https://github.com/RM-Zhang/SGCDet.

</details>


### [78] [3D Software Synthesis Guided by Constraint-Expressive Intermediate Representation](https://arxiv.org/abs/2507.18625)
*Shuqing Li,Anson Y. Lam,Yun Peng,Wenxuan Wang,Michael R. Lyu*

Main category: cs.CV

TL;DR: Scenethesis是一种新型的、对需求敏感的3D软件合成方法，它通过引入领域特定语言ScenethesisLang，实现了从自然语言需求到可执行3D软件的精细化生成与修改，并有效处理复杂的空间和语义约束。


<details>
  <summary>Details</summary>
Motivation: 传统2D UI已向3D空间环境转型，但现有的3D软件生成方法仍有局限：它们通常整体生成3D环境，无法对特定元素进行修改或控制，并且难以处理现实世界中复杂的空间和语义约束。

Method: Scenethesis方法基于ScenethesisLang（一种领域特定语言），作为连接自然语言需求和可执行3D软件的粒度约束感知中间表示（IR）。ScenethesisLang既是全面的场景描述语言，支持3D软件元素的精细修改，也是形式化的约束表达语言，能够表达复杂的空间约束。通过将3D软件合成分解为在ScenethesisLang上操作的多个阶段，Scenethesis实现了独立验证、目标修改和系统性的约束满足。

Result: Scenethesis能够准确捕获超过80%的用户需求，满足90%以上的硬约束，同时处理超过100个约束。与现有最先进的方法相比，Scenethesis在BLIP-2视觉评估分数上实现了42.8%的提升。

Conclusion: Scenethesis提供了一种有效且创新的3D软件合成方法，解决了现有技术在精细控制和复杂约束处理方面的不足，显著提高了从用户需求生成高质量3D软件的能力。

Abstract: Graphical user interface (UI) software has undergone a fundamental
transformation from traditional two-dimensional (2D) desktop/web/mobile
interfaces to spatial three-dimensional (3D) environments. While existing work
has made remarkable success in automated 2D software generation, such as
HTML/CSS and mobile app interface code synthesis, the generation of 3D software
still remains under-explored. Current methods for 3D software generation
usually generate the 3D environments as a whole and cannot modify or control
specific elements in the software. Furthermore, these methods struggle to
handle the complex spatial and semantic constraints inherent in the real world.
To address the challenges, we present Scenethesis, a novel
requirement-sensitive 3D software synthesis approach that maintains formal
traceability between user specifications and generated 3D software. Scenethesis
is built upon ScenethesisLang, a domain-specific language that serves as a
granular constraint-aware intermediate representation (IR) to bridge natural
language requirements and executable 3D software. It serves both as a
comprehensive scene description language enabling fine-grained modification of
3D software elements and as a formal constraint-expressive specification
language capable of expressing complex spatial constraints. By decomposing 3D
software synthesis into stages operating on ScenethesisLang, Scenethesis
enables independent verification, targeted modification, and systematic
constraint satisfaction. Our evaluation demonstrates that Scenethesis
accurately captures over 80% of user requirements and satisfies more than 90%
of hard constraints while handling over 100 constraints simultaneously.
Furthermore, Scenethesis achieves a 42.8% improvement in BLIP-2 visual
evaluation scores compared to the state-of-the-art method.

</details>


### [79] [EgoExoBench: A Benchmark for First- and Third-person View Video Understanding in MLLMs](https://arxiv.org/abs/2507.18342)
*Yuping He,Yifei Huang,Guo Chen,Baoqi Pei,Jilan Xu,Tong Lu,Jiangmiao Pang*

Main category: cs.CV

TL;DR: 本文介绍了EgoExoBench，首个用于评估多模态大语言模型（MLLMs）在第一人称（自我中心）和第三人称（外部中心）视角之间进行跨视角理解和推理能力的基准测试。


<details>
  <summary>Details</summary>
Motivation: 人类智能的核心在于跨视角知识的整合与转移，这使得人类能够相互学习并分享经验。尽管多模态大语言模型取得了快速进展，但它们在跨视角推理方面的能力尚未被探索，因此需要一个专门的基准来评估这一能力。

Method: 研究者构建了EgoExoBench，一个包含7300多个问答对的基准测试，数据来源于公开数据集。该基准涵盖了语义对齐、视角关联和时间推理三大核心挑战下的十一个子任务。研究者使用此基准评估了13个最先进的MLLMs。

Result: 评估结果显示，尽管这些MLLMs在单视角任务上表现出色，但它们在自我中心-外部中心背景下进行跨视角语义对齐、准确关联不同视角以及推断时间动态方面表现不佳。

Conclusion: EgoExoBench有望成为开发具备类人跨视角智能的具身智能体和智能助手的宝贵资源，推动该领域的研究进展。

Abstract: Transferring and integrating knowledge across first-person (egocentric) and
third-person (exocentric) viewpoints is intrinsic to human intelligence,
enabling humans to learn from others and convey insights from their own
experiences. Despite rapid progress in multimodal large language models
(MLLMs), their ability to perform such cross-view reasoning remains unexplored.
To address this, we introduce EgoExoBench, the first benchmark for
egocentric-exocentric video understanding and reasoning. Built from publicly
available datasets, EgoExoBench comprises over 7,300 question-answer pairs
spanning eleven sub-tasks organized into three core challenges: semantic
alignment, viewpoint association, and temporal reasoning. We evaluate 13
state-of-the-art MLLMs and find that while these models excel on single-view
tasks, they struggle to align semantics across perspectives, accurately
associate views, and infer temporal dynamics in the ego-exo context. We hope
EgoExoBench can serve as a valuable resource for research on embodied agents
and intelligent assistants seeking human-like cross-view intelligence.

</details>


### [80] [SIDA: Synthetic Image Driven Zero-shot Domain Adaptation](https://arxiv.org/abs/2507.18632)
*Ye-Chan Kim,SeungJu Cha,Si-Woo Kim,Taewhan Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: 本文提出SIDA，一种新颖高效的零样本域适应方法，通过生成合成图像并利用其风格特征来克服现有文本驱动方法的局限性，实现了更好的性能和更快的适应时间。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本域适应方法依赖CLIP的嵌入空间和文本描述来模拟目标域风格，但这些文本驱动方法难以捕捉复杂的真实世界变化，并且由于对齐过程导致适应时间显著增加。研究者旨在探索利用图像数据（提供更多样和细粒度的风格线索）的解决方案。

Method: 提出SIDA方法，利用合成图像进行零样本域适应。首先创建详细的源域相似图像，然后应用图像翻译以反映目标域风格，生成合成图像。接着，将这些合成图像的风格特征作为目标域的代理。在此基础上，引入域混合（Domain Mix）模块来融合多种风格以扩展域内表示，以及补丁风格迁移（Patch Style Transfer）模块将不同风格分配给单个图像块，从而有效建模真实世界变化。

Result: SIDA方法在各种零样本适应场景，特别是在挑战性域中，展示了最先进的性能。此外，该方法显著减少了整体适应时间，实现了高效率。

Conclusion: 通过利用合成图像及其风格特征，并结合域混合和补丁风格迁移模块，SIDA方法能够有效且高效地进行零样本域适应，克服了传统文本驱动方法的局限性，并在复杂真实世界场景中表现出色。

Abstract: Zero-shot domain adaptation is a method for adapting a model to a target
domain without utilizing target domain image data. To enable adaptation without
target images, existing studies utilize CLIP's embedding space and text
description to simulate target-like style features. Despite the previous
achievements in zero-shot domain adaptation, we observe that these text-driven
methods struggle to capture complex real-world variations and significantly
increase adaptation time due to their alignment process. Instead of relying on
text descriptions, we explore solutions leveraging image data, which provides
diverse and more fine-grained style cues. In this work, we propose SIDA, a
novel and efficient zero-shot domain adaptation method leveraging synthetic
images. To generate synthetic images, we first create detailed, source-like
images and apply image translation to reflect the style of the target domain.
We then utilize the style features of these synthetic images as a proxy for the
target domain. Based on these features, we introduce Domain Mix and Patch Style
Transfer modules, which enable effective modeling of real-world variations. In
particular, Domain Mix blends multiple styles to expand the intra-domain
representations, and Patch Style Transfer assigns different styles to
individual patches. We demonstrate the effectiveness of our method by showing
state-of-the-art performance in diverse zero-shot adaptation scenarios,
particularly in challenging domains. Moreover, our approach achieves high
efficiency by significantly reducing the overall adaptation time.

</details>


### [81] [VB-Mitigator: An Open-source Framework for Evaluating and Advancing Visual Bias Mitigation](https://arxiv.org/abs/2507.18348)
*Ioannis Sarridis,Christos Koutlis,Symeon Papadopoulos,Christos Diou*

Main category: cs.CV

TL;DR: 本文提出了VB-Mitigator，一个开源框架，旨在统一计算机视觉偏见缓解技术的研究、评估和比较，以克服当前碎片化和评估不一致的挑战。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉模型中的偏见导致不公平、不可靠和泛化能力差的AI系统。现有的偏见缓解研究因实现碎片化和评估实践不一致而进展受阻，不同的数据集和指标使得方法比较和复现困难。

Method: 开发了VB-Mitigator开源框架，提供一个统一的研究环境，集成了12种已有的偏见缓解方法和7个基准数据集。该框架具有可扩展性，允许无缝集成额外的方法、数据集、指标和模型。同时，论文推荐了最佳评估实践，并提供了现有SOTA方法间的全面性能比较。

Result: VB-Mitigator成功地简化了视觉偏见缓解技术的开发、评估和比较分析。它提供了一个统一的研究环境和可扩展的平台，能够加速公平性感知计算机视觉模型的研究。

Conclusion: VB-Mitigator作为一个基础代码库，旨在加速计算机视觉领域对公平性感知模型的研究，并为研究社区开发和评估偏见缓解方法提供支持。

Abstract: Bias in computer vision models remains a significant challenge, often
resulting in unfair, unreliable, and non-generalizable AI systems. Although
research into bias mitigation has intensified, progress continues to be
hindered by fragmented implementations and inconsistent evaluation practices.
Disparate datasets and metrics used across studies complicate reproducibility,
making it difficult to fairly assess and compare the effectiveness of various
approaches. To overcome these limitations, we introduce the Visual Bias
Mitigator (VB-Mitigator), an open-source framework designed to streamline the
development, evaluation, and comparative analysis of visual bias mitigation
techniques. VB-Mitigator offers a unified research environment encompassing 12
established mitigation methods, 7 diverse benchmark datasets. A key strength of
VB-Mitigator is its extensibility, allowing for seamless integration of
additional methods, datasets, metrics, and models. VB-Mitigator aims to
accelerate research toward fairness-aware computer vision models by serving as
a foundational codebase for the research community to develop and assess their
approaches. To this end, we also recommend best evaluation practices and
provide a comprehensive performance comparison among state-of-the-art
methodologies.

</details>


### [82] [Deformable Convolution Module with Globally Learned Relative Offsets for Fundus Vessel Segmentation](https://arxiv.org/abs/2507.18354)
*Lexuan Zhu,Yuxuan Li,Yuning Ren*

Main category: cs.CV

TL;DR: 本文提出了一种新型可变形卷积模块，通过注意力机制和前馈网络学习偏移量，实现特征图的自适应扭曲，以捕获长距离全局特征。基于此模块设计的GDCUnet在眼底血管分割任务上达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统可变形卷积通过学习偏移量适应复杂形状特征，但可能难以捕获长距离全局特征。眼底血管具有全局自相似的复杂边缘，需要更强的特征捕获能力。

Method: 提出了一种即插即用的可变形卷积模块，利用注意力机制和前馈网络学习偏移量。该模块学习亚像素位移场，并自适应地扭曲所有通道的特征图，而非直接变形卷积核，实现了全局特征变形和核大小与学习网络的解耦。基于此模块，设计了用于眼底血管分割的深度学习模型GDCUnet。

Result: 在统一框架下，GDCUnet在公共数据集上实现了眼底血管分割的SOTA性能。消融实验表明，所提出的可变形卷积模块能更显著地学习眼底血管的复杂特征，增强了模型的表示和泛化能力。

Conclusion: 所提出的可变形卷积模块与传统卷积接口类似，易于集成，并在处理具有复杂全局自相似特征的机器视觉任务中展现出巨大潜力，建议将其应用于更多此类任务。

Abstract: Deformable convolution can adaptively change the shape of convolution kernel
by learning offsets to deal with complex shape features. We propose a novel
plug and play deformable convolutional module that uses attention and
feedforward networks to learn offsets, so that the deformable patterns can
capture long-distance global features. Compared with previously existing
deformable convolutions, the proposed module learns the sub pixel displacement
field and adaptively warps the feature maps across all channels rather than
directly deforms the convolution kernel , which is equivalent to a relative
deformation of the kernel sampling grids, achieving global feature deformation
and the decoupling of kernel size and learning network. Considering that the
fundus blood vessels have globally self similar complex edges, we design a deep
learning model for fundus blood vessel segmentation, GDCUnet, based on the
proposed convolutional module. Empirical evaluations under the same
configuration and unified framework show that GDCUnet has achieved state of the
art performance on public datasets. Further ablation experiments demonstrated
that the proposed deformable convolutional module could more significantly
learn the complex features of fundus blood vessels, enhancing the model
representation and generalization capabilities.The proposed module is similar
to the interface of conventional convolution, we suggest applying it to more
machine vision tasks with complex global self similar features.

</details>


### [83] [MVG4D: Image Matrix-Based Multi-View and Motion Generation for 4D Content Creation from a Single Image](https://arxiv.org/abs/2507.18371)
*Xiaotian Chen,DongFu Yin,Fei Richard Yu,Xuanchen Li,Xinhao Zhang*

Main category: cs.CV

TL;DR: MVG4D是一个新颖的框架，通过结合多视角合成和4D高斯泼溅（4D GS），能够从单张静止图像生成高保真且时间一致的动态4D内容。


<details>
  <summary>Details</summary>
Motivation: 尽管生成模型在数字内容创作方面取得了显著进展，但生成高保真、时间一致的动态4D内容仍然是一个挑战，尤其是在运动不连续性和背景退化方面。

Method: MVG4D的核心是一个图像矩阵模块，用于合成时间连贯且空间多样化的多视角图像，为后续的3D和4D重建提供监督信号。这些多视角图像用于优化3D高斯点云，并通过一个轻量级形变网络扩展到时间域。

Result: MVG4D在Objaverse数据集上的实验表明，其在CLIP-I、PSNR、FVD和时间效率方面均优于现有基线。显著减少了闪烁伪影，并锐化了跨视角和时间的结构细节。

Conclusion: MVG4D有效增强了时间一致性、几何保真度和视觉真实感，解决了现有4D GS方法中的关键挑战，为从最小输入进行高效和可控的4D生成开辟了新方向，并能实现更沉浸式的AR/VR体验。

Abstract: Advances in generative modeling have significantly enhanced digital content
creation, extending from 2D images to complex 3D and 4D scenes. Despite
substantial progress, producing high-fidelity and temporally consistent dynamic
4D content remains a challenge. In this paper, we propose MVG4D, a novel
framework that generates dynamic 4D content from a single still image by
combining multi-view synthesis with 4D Gaussian Splatting (4D GS). At its core,
MVG4D employs an image matrix module that synthesizes temporally coherent and
spatially diverse multi-view images, providing rich supervisory signals for
downstream 3D and 4D reconstruction. These multi-view images are used to
optimize a 3D Gaussian point cloud, which is further extended into the temporal
domain via a lightweight deformation network. Our method effectively enhances
temporal consistency, geometric fidelity, and visual realism, addressing key
challenges in motion discontinuity and background degradation that affect prior
4D GS-based methods. Extensive experiments on the Objaverse dataset demonstrate
that MVG4D outperforms state-of-the-art baselines in CLIP-I, PSNR, FVD, and
time efficiency. Notably, it reduces flickering artifacts and sharpens
structural details across views and time, enabling more immersive AR/VR
experiences. MVG4D sets a new direction for efficient and controllable 4D
generation from minimal inputs.

</details>


### [84] [Towards Effective Human-in-the-Loop Assistive AI Agents](https://arxiv.org/abs/2507.18374)
*Filippos Bellos,Yayuan Li,Cary Shu,Ruey Day,Jeffrey M. Siskind,Jason J. Corso*

Main category: cs.CV

TL;DR: 本文提出了一个评估框架和多模态数据集，用于评估AI指导如何影响人类在物理任务中的表现、错误减少和学习成果，并通过一个AR增强AI代理在真实世界任务中进行人类研究，证明了AI辅助协作能提高任务完成度。


<details>
  <summary>Details</summary>
Motivation: 人类-AI协作在日常和专业领域具有巨大潜力，但由于人机交互的复杂性，评估此类协作仍具挑战性。

Method: 引入了一个评估框架和多模态人类-AI交互数据集；开发了一个配备增强现实（AR）的AI代理，提供实时互动指导；通过人类研究分享实证见解。

Result: AI辅助协作改善了任务完成度，提高了人类表现，有助于减少错误和学习成果。

Conclusion: AI辅助协作能够有效提升人类在物理任务中的表现，并通过所提出的框架和AR-AI代理得到了验证。

Abstract: Effective human-AI collaboration for physical task completion has significant
potential in both everyday activities and professional domains. AI agents
equipped with informative guidance can enhance human performance, but
evaluating such collaboration remains challenging due to the complexity of
human-in-the-loop interactions. In this work, we introduce an evaluation
framework and a multimodal dataset of human-AI interactions designed to assess
how AI guidance affects procedural task performance, error reduction and
learning outcomes. Besides, we develop an augmented reality (AR)-equipped AI
agent that provides interactive guidance in real-world tasks, from cooking to
battlefield medicine. Through human studies, we share empirical insights into
AI-assisted human performance and demonstrate that AI-assisted collaboration
improves task completion.

</details>


### [85] [Towards Consistent Long-Term Pose Generation](https://arxiv.org/abs/2507.18382)
*Yayuan Li,Filippos Bellos,Jason Corso*

Main category: cs.CV

TL;DR: 该论文提出一种新颖的单阶段架构，直接从RGB图像和文本描述在连续坐标空间生成姿态，避免了中间表示，并在长期姿态生成中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前的姿态生成方法依赖于中间表示（如量化或自回归模型），导致性能下降，尤其是在需要保持时间一致性的长期姿态生成中，会累积误差。

Method: 提出一种新颖的单阶段架构，直接在连续坐标空间生成姿态。主要创新点包括：1) 消除对中间表示或基于token的生成的需求；2) 通过相对运动预测机制直接操作姿态坐标以保留空间关系；3) 采用统一的占位符token方法实现单次前向生成，确保训练和推理行为一致。

Result: 在Penn Action和First-Person Hand Action Benchmark (F-PHAB)数据集上的实验表明，该方法显著优于现有的基于量化和自回归的方法，尤其在长期生成场景中表现更佳。

Conclusion: 所提出的直接在连续坐标空间进行单阶段姿态生成的方法，通过避免中间表示，有效解决了现有方法的局限性，并在长期姿态生成任务中取得了显著的性能提升。

Abstract: Current approaches to pose generation rely heavily on intermediate
representations, either through two-stage pipelines with quantization or
autoregressive models that accumulate errors during inference. This fundamental
limitation leads to degraded performance, particularly in long-term pose
generation where maintaining temporal coherence is crucial. We propose a novel
one-stage architecture that directly generates poses in continuous coordinate
space from minimal context - a single RGB image and text description - while
maintaining consistent distributions between training and inference. Our key
innovation is eliminating the need for intermediate representations or
token-based generation by operating directly on pose coordinates through a
relative movement prediction mechanism that preserves spatial relationships,
and a unified placeholder token approach that enables single-forward generation
with identical behavior during training and inference. Through extensive
experiments on Penn Action and First-Person Hand Action Benchmark (F-PHAB)
datasets, we demonstrate that our approach significantly outperforms existing
quantization-based and autoregressive methods, especially in long-term
generation scenarios.

</details>


### [86] [HumanMaterial: Human Material Estimation from a Single Image via Progressive Training](https://arxiv.org/abs/2507.18385)
*Yu Jiang,Jiahao Xia,Jiongming Qin,Yusen Wang,Tuo Cao,Chunxia Xiao*

Main category: cs.CV

TL;DR: 该研究通过构建高质量人体材质数据集（OpenHumanBRDF）并设计渐进式训练模型（HumanMaterial）及受控PBR渲染损失（CPR loss），解决了全身体人体逆向渲染中材质估计的病态问题和现有方法真实感不足的局限性，实现了照片级真实感的人体材质渲染。


<details>
  <summary>Details</summary>
Motivation: 人体逆向渲染旨在获取高质量材质以实现任意光照下的照片级真实感渲染，但估计多材质图缺乏约束使其成为病态问题。现有方法因材质数据和渲染方程简化，导致渲染真实感（尤其是皮肤）有限。此外，随着预测材质种类增多，传统端到端模型难以平衡不同材质图的重要性，易导致欠拟合。

Method: 1. 构建了高质量数据集OpenHumanBRDF，包含法线、漫反射反照率、粗糙度、镜面反照率，并额外引入位移图和次表面散射以增强皮肤等渲染的真实感。2. 设计了HumanMaterial模型，采用渐进式训练策略，首先通过三个先验模型获取初始材质结果，再通过一个微调模型进行精炼。3. 提出了受控PBR渲染（CPR）损失函数，在先验模型训练时增强待优化材质的重要性。

Result: 在OpenHumanBRDF数据集和真实数据上的大量实验表明，所提出的方法实现了最先进的性能。

Conclusion: 通过高质量数据集和创新的模型架构与损失函数，本研究有效解决了全身体人体逆向渲染中的材质估计难题，显著提升了渲染结果的真实感和质量。

Abstract: Full-body Human inverse rendering based on physically-based rendering aims to
acquire high-quality materials, which helps achieve photo-realistic rendering
under arbitrary illuminations. This task requires estimating multiple material
maps and usually relies on the constraint of rendering result. The absence of
constraints on the material maps makes inverse rendering an ill-posed task.
Previous works alleviated this problem by building material dataset for
training, but their simplified material data and rendering equation lead to
rendering results with limited realism, especially that of skin. To further
alleviate this problem, we construct a higher-quality dataset (OpenHumanBRDF)
based on scanned real data and statistical material data. In addition to the
normal, diffuse albedo, roughness, specular albedo, we produce displacement and
subsurface scattering to enhance the realism of rendering results, especially
for the skin. With the increase in prediction tasks for more materials, using
an end-to-end model as in the previous work struggles to balance the importance
among various material maps, and leads to model underfitting. Therefore, we
design a model (HumanMaterial) with progressive training strategy to make full
use of the supervision information of the material maps and improve the
performance of material estimation. HumanMaterial first obtain the initial
material results via three prior models, and then refine the results by a
finetuning model. Prior models estimate different material maps, and each map
has different significance for rendering results. Thus, we design a Controlled
PBR Rendering (CPR) loss, which enhances the importance of the materials to be
optimized during the training of prior models. Extensive experiments on
OpenHumanBRDF dataset and real data demonstrate that our method achieves
state-of-the-art performance.

</details>


### [87] [Iwin Transformer: Hierarchical Vision Transformer using Interleaved Windows](https://arxiv.org/abs/2507.18405)
*Simin Huo,Ning Li*

Main category: cs.CV

TL;DR: Iwin Transformer是一种新型的无位置编码分层视觉Transformer，通过交错窗口注意力与深度可分离卷积结合，实现单模块内的全局信息交换，并支持从低分辨率到高分辨率的直接微调，在多项视觉任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: Swin Transformer需要两个连续的块才能近似实现全局注意力，这促使研究者开发一种能在单个模块内实现全局信息交换并克服这一限制的方法，同时支持低到高分辨率的直接微调。

Method: 提出了Iwin Transformer，它结合了创新的交错窗口注意力（连接远距离token）和深度可分离卷积（连接相邻token），在一个模块内实现全局信息交换。该模型是无位置编码的分层结构，支持直接从低分辨率到高分辨率的微调。

Result: Iwin Transformer在图像分类任务中（ImageNet-1K）取得了87.4%的top-1准确率，并在语义分割和视频动作识别等视觉基准测试中展现出强大的竞争力。其核心组件可作为独立模块无缝替代条件图像生成中的自注意力模块。

Conclusion: Iwin Transformer引入的概念和方法被证明是有效的，并具有启发未来研究的潜力，例如视频生成中的Iwin 3D注意力。

Abstract: We introduce Iwin Transformer, a novel position-embedding-free hierarchical
vision transformer, which can be fine-tuned directly from low to high
resolution, through the collaboration of innovative interleaved window
attention and depthwise separable convolution. This approach uses attention to
connect distant tokens and applies convolution to link neighboring tokens,
enabling global information exchange within a single module, overcoming Swin
Transformer's limitation of requiring two consecutive blocks to approximate
global attention. Extensive experiments on visual benchmarks demonstrate that
Iwin Transformer exhibits strong competitiveness in tasks such as image
classification (87.4 top-1 accuracy on ImageNet-1K), semantic segmentation and
video action recognition. We also validate the effectiveness of the core
component in Iwin as a standalone module that can seamlessly replace the
self-attention module in class-conditional image generation. The concepts and
methods introduced by the Iwin Transformer have the potential to inspire future
research, like Iwin 3D Attention in video generation. The code and models are
available at https://github.com/cominder/Iwin-Transformer.

</details>


### [88] [DCFFSNet: Deep Connectivity Feature Fusion Separation Network for Medical Image Segmentation](https://arxiv.org/abs/2507.18407)
*Xun Ye,Ruixiang Tang,Mingda Zhang,Jianglong Qin*

Main category: cs.CV

TL;DR: DCFFSNet提出了一种新颖的特征空间解耦策略，用于医学图像分割，通过量化连接性特征与其他特征的相对强度，动态平衡多尺度特征表达，有效提升了分割精度和边缘平滑度。


<details>
  <summary>Details</summary>
Motivation: 现有深度网络在医学图像分割中整合拓扑连接性时，常将其作为附加特征模块强制注入，导致特征空间耦合，且缺乏量化不同特征强度的标准化机制，从而影响边缘精度和区域一致性。

Method: 本文提出了DCFFSNet（Dual-Connectivity Feature Fusion-Separation Network），引入了一种创新的特征空间解耦策略。该策略量化连接性特征与其他特征的相对强度，并构建深度连接性特征融合-分离架构，以动态平衡多尺度特征表达。

Result: 在ISIC2018数据集上，DCFFSNet在Dice和IoU指标上分别超越CMUNet 1.3%和1.2%。在DSB2018数据集上，Dice和IoU分别超越TransUNet 0.7%和0.9%。在MoNuSeg数据集上，Dice和IoU分别超越CSCAUNet 0.8%和0.9%。实验结果表明，DCFFSNet在所有指标上均优于现有主流方法。

Conclusion: DCFFSNet有效解决了分割碎片化问题，实现了平滑的边缘过渡，显著增强了临床可用性，并在多个医学图像分割数据集上表现出卓越性能。

Abstract: Medical image segmentation leverages topological connectivity theory to
enhance edge precision and regional consistency. However, existing deep
networks integrating connectivity often forcibly inject it as an additional
feature module, resulting in coupled feature spaces with no standardized
mechanism to quantify different feature strengths. To address these issues, we
propose DCFFSNet (Dual-Connectivity Feature Fusion-Separation Network). It
introduces an innovative feature space decoupling strategy. This strategy
quantifies the relative strength between connectivity features and other
features. It then builds a deep connectivity feature fusion-separation
architecture. This architecture dynamically balances multi-scale feature
expression. Experiments were conducted on the ISIC2018, DSB2018, and MoNuSeg
datasets. On ISIC2018, DCFFSNet outperformed the next best model (CMUNet) by
1.3% (Dice) and 1.2% (IoU). On DSB2018, it surpassed TransUNet by 0.7% (Dice)
and 0.9% (IoU). On MoNuSeg, it exceeded CSCAUNet by 0.8% (Dice) and 0.9% (IoU).
The results demonstrate that DCFFSNet exceeds existing mainstream methods
across all metrics. It effectively resolves segmentation fragmentation and
achieves smooth edge transitions. This significantly enhances clinical
usability.

</details>


### [89] [Self-Supervised Ultrasound-Video Segmentation with Feature Prediction and 3D Localised Loss](https://arxiv.org/abs/2507.18424)
*Edward Ellis,Robert Mendel,Andrew Bulpitt,Nasim Parsa,Michael F Byrne,Sharib Ali*

Main category: cs.CV

TL;DR: 本研究首次将V-JEPA自监督学习框架应用于超声视频数据，并提出一种新颖的3D定位辅助任务，以增强ViT模型在超声图像分割中的局部性理解，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 超声图像数据获取和标注面临低对比度、高噪声和伪影等挑战，耗时且需要专业知识。自监督学习（SSL）有望解决有限标注数据下的性能问题。V-JEPA因其基于特征预测而非像素重建的特性，被认为更适合处理超声图像中的噪声和利用时间信息。然而，Vision Transformers（ViTs）在小型医学数据集上可能表现不佳，因其缺乏归纳偏置、空间局部性有限且缺乏分层特征学习。

Method: 本研究将V-JEPA框架应用于超声视频数据进行自监督预训练。为了改善ViT在小数据集上的局部性理解问题，提出了一种新颖的3D定位辅助任务，在V-JEPA预训练过程中增强ViT表示的局部性。随后，在各种冻结编码器配置下评估了模型在分割任务上的性能。

Result: 结果表明，结合了3D定位辅助任务的V-JEPA显著提升了超声图像分割性能。使用100%训练数据时，性能提升高达3.4%；仅使用10%训练数据时，性能提升高达8.35%。

Conclusion: 本研究首次成功将V-JEPA应用于超声视频数据，并通过引入3D定位辅助任务有效解决了ViT在小医学数据集上的局部性问题。该方法在超声图像分割任务中展现出显著的性能提升，尤其在数据量有限的情况下效果更佳，为超声图像分析提供了有前景的自监督学习解决方案。

Abstract: Acquiring and annotating large datasets in ultrasound imaging is challenging
due to low contrast, high noise, and susceptibility to artefacts. This process
requires significant time and clinical expertise. Self-supervised learning
(SSL) offers a promising solution by leveraging unlabelled data to learn useful
representations, enabling improved segmentation performance when annotated data
is limited. Recent state-of-the-art developments in SSL for video data include
V-JEPA, a framework solely based on feature prediction, avoiding pixel level
reconstruction or negative samples. We hypothesise that V-JEPA is well-suited
to ultrasound imaging, as it is less sensitive to noisy pixel-level detail
while effectively leveraging temporal information. To the best of our
knowledge, this is the first study to adopt V-JEPA for ultrasound video data.
Similar to other patch-based masking SSL techniques such as VideoMAE, V-JEPA is
well-suited to ViT-based models. However, ViTs can underperform on small
medical datasets due to lack of inductive biases, limited spatial locality and
absence of hierarchical feature learning. To improve locality understanding, we
propose a novel 3D localisation auxiliary task to improve locality in ViT
representations during V-JEPA pre-training. Our results show V-JEPA with our
auxiliary task improves segmentation performance significantly across various
frozen encoder configurations, with gains up to 3.4\% using 100\% and up to
8.35\% using only 10\% of the training data.

</details>


### [90] [NLML-HPE: Head Pose Estimation with Limited Data via Manifold Learning](https://arxiv.org/abs/2507.18429)
*Mahdi Ghafourian,Federico M. Sukno*

Main category: cs.CV

TL;DR: 提出NLML-HPE，一种基于非线性流形学习的深度学习方法，通过张量分解和前馈神经网络，将头部姿态估计建模为回归问题，用有限数据实现实时高性能。


<details>
  <summary>Details</summary>
Motivation: 头部姿态估计（HPE）在人机交互和面部识别等计算机视觉应用中至关重要。现有HPE数据集普遍存在姿态标注不准确的问题，且难以在有限训练数据下实现实时高性能。

Method: 提出NLML-HPE方法，结合张量分解（Tucker分解）和前馈神经网络。将头部姿态估计视为回归问题，将输入地标映射到连续的姿态角度表示。使用张量分解将每个欧拉角（偏航、俯仰、滚动）分解到独立的子空间，并将底层流形的每个维度建模为余弦曲线。为解决数据标注问题，通过旋转3D头部模型并渲染2D图像，生成了精确一致的2D头部姿态数据集。

Result: 在有限训练数据下实现了实时性能，模型能够准确捕捉物体从面部地标旋转的本质。一旦学习了每个轴的旋转流形，模型在预测未见数据时速度非常快。

Conclusion: NLML-HPE方法通过非线性流形学习和张量分解，有效地解决了头部姿态估计中的数据标注不准确和有限数据下的实时性能挑战，为HPE提供了一种精确且高效的回归解决方案。

Abstract: Head pose estimation (HPE) plays a critical role in various computer vision
applications such as human-computer interaction and facial recognition. In this
paper, we propose a novel deep learning approach for head pose estimation with
limited training data via non-linear manifold learning called NLML-HPE. This
method is based on the combination of tensor decomposition (i.e., Tucker
decomposition) and feed forward neural networks. Unlike traditional
classification-based approaches, our method formulates head pose estimation as
a regression problem, mapping input landmarks into a continuous representation
of pose angles. To this end, our method uses tensor decomposition to split each
Euler angle (yaw, pitch, roll) to separate subspaces and models each dimension
of the underlying manifold as a cosine curve. We address two key challenges: 1.
Almost all HPE datasets suffer from incorrect and inaccurate pose annotations.
Hence, we generated a precise and consistent 2D head pose dataset for our
training set by rotating 3D head models for a fixed set of poses and rendering
the corresponding 2D images. 2. We achieved real-time performance with limited
training data as our method accurately captures the nature of rotation of an
object from facial landmarks. Once the underlying manifold for rotation around
each axis is learned, the model is very fast in predicting unseen data. Our
training and testing code is available online along with our trained models:
https: //github.com/MahdiGhafoorian/NLML_HPE.

</details>


### [91] [PDB-Eval: An Evaluation of Large Multimodal Models for Description and Explanation of Personalized Driving Behavior](https://arxiv.org/abs/2507.18447)
*Junda Wu,Jessica Echterhoff,Kyungtae Han,Amr Abdelraouf,Rohit Gupta,Julian McAuley*

Main category: cs.CV

TL;DR: 本文提出了PDB-Eval基准，用于理解个性化驾驶行为并将大型多模态模型（MLLMs）与驾驶理解和推理对齐，通过细粒度描述和解释显著提升了MLLMs在驾驶任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 理解驾驶员行为和意图对于风险评估和事故预防至关重要，现有的数据集在基于外部视觉证据描述和解释车辆运动方面存在局限性，限制了安全和驾驶辅助系统的有效性。

Method: 引入了PDB-Eval基准，包含PDB-X和PDB-QA两部分。PDB-X用于评估MLLMs对时间驾驶场景的理解，旨在从外部视角寻找视觉证据解释内部视角的驾驶员行为。PDB-QA作为视觉解释问答任务，用于MLLM指令微调，以弥合领域差距并保持泛化能力。

Result: 在细粒度描述和解释上对MLLMs进行微调，能有效弥合MLLMs与驾驶领域之间的差距，使零样本问答性能提高高达73.2%。在Brain4Cars的意图预测任务上性能提升高达12.5%，在AIDE的所有识别任务上性能提升高达11.0%。

Conclusion: PDB-Eval基准通过提供细粒度的驾驶行为描述和解释，成功地将大型多模态模型与驾驶领域对齐，显著提升了其在驾驶理解、意图预测和行为识别等任务上的性能和泛化能力。

Abstract: Understanding a driver's behavior and intentions is important for potential
risk assessment and early accident prevention. Safety and driver assistance
systems can be tailored to individual drivers' behavior, significantly
enhancing their effectiveness. However, existing datasets are limited in
describing and explaining general vehicle movements based on external visual
evidence. This paper introduces a benchmark, PDB-Eval, for a detailed
understanding of Personalized Driver Behavior, and aligning Large Multimodal
Models (MLLMs) with driving comprehension and reasoning. Our benchmark consists
of two main components, PDB-X and PDB-QA. PDB-X can evaluate MLLMs'
understanding of temporal driving scenes. Our dataset is designed to find valid
visual evidence from the external view to explain the driver's behavior from
the internal view. To align MLLMs' reasoning abilities with driving tasks, we
propose PDB-QA as a visual explanation question-answering task for MLLM
instruction fine-tuning. As a generic learning task for generative models like
MLLMs, PDB-QA can bridge the domain gap without harming MLLMs'
generalizability. Our evaluation indicates that fine-tuning MLLMs on
fine-grained descriptions and explanations can effectively bridge the gap
between MLLMs and the driving domain, which improves zero-shot performance on
question-answering tasks by up to 73.2%. We further evaluate the MLLMs
fine-tuned on PDB-X in Brain4Cars' intention prediction and AIDE's recognition
tasks. We observe up to 12.5% performance improvements on the turn intention
prediction task in Brain4Cars, and consistent performance improvements up to
11.0% on all tasks in AIDE.

</details>


### [92] [CRUISE: Cooperative Reconstruction and Editing in V2X Scenarios using Gaussian Splatting](https://arxiv.org/abs/2507.18473)
*Haoran Xu,Saining Zhang,Peishuo Li,Baijun Ye,Xiaoxue Chen,Huan-ang Gao,Jv Zheng,Xiaowei Song,Ziqiao Peng,Run Miao,Jinrang Jia,Yifeng Shi,Guangqi Yi,Hang Zhao,Hao Tang,Hongyang Li,Kaicheng Yu,Hao Zhao*

Main category: cs.CV

TL;DR: CRUISE是一个用于V2X驾驶环境的重建与合成框架，利用分解高斯溅射技术高保真重建场景并支持灵活编辑，从而实现大规模V2X数据增强，有效提升3D感知任务性能。


<details>
  <summary>Details</summary>
Motivation: 尽管模拟在自动驾驶任务中贡献显著，但其在V2X场景中用于数据生成和增强的潜力尚未得到充分探索。现有方法难以高效生成大规模、多样化的V2X数据集。

Method: CRUISE框架采用分解高斯溅射（decomposed Gaussian Splatting）技术，实现对真实世界V2X场景的高保真重建并支持灵活编辑。它将动态交通参与者分解为可编辑的高斯表示，从而无缝修改和增强驾驶场景。此外，该框架能从自车和基础设施视角渲染图像，支持大规模V2X数据集增强。

Result: 实验结果表明：1) CRUISE能够高保真重建真实世界的V2X驾驶场景；2) 使用CRUISE能提高自车、基础设施和协同视角下的3D检测性能，以及V2X-Seq基准上的协同3D跟踪性能；3) CRUISE能有效生成具有挑战性的角点案例。

Conclusion: CRUISE是一个全面且有效的V2X数据生成和增强框架，能够提升自动驾驶中V2X感知任务的性能，并通过生成复杂场景来应对挑战。

Abstract: Vehicle-to-everything (V2X) communication plays a crucial role in autonomous
driving, enabling cooperation between vehicles and infrastructure. While
simulation has significantly contributed to various autonomous driving tasks,
its potential for data generation and augmentation in V2X scenarios remains
underexplored. In this paper, we introduce CRUISE, a comprehensive
reconstruction-and-synthesis framework designed for V2X driving environments.
CRUISE employs decomposed Gaussian Splatting to accurately reconstruct
real-world scenes while supporting flexible editing. By decomposing dynamic
traffic participants into editable Gaussian representations, CRUISE allows for
seamless modification and augmentation of driving scenes. Furthermore, the
framework renders images from both ego-vehicle and infrastructure views,
enabling large-scale V2X dataset augmentation for training and evaluation. Our
experimental results demonstrate that: 1) CRUISE reconstructs real-world V2X
driving scenes with high fidelity; 2) using CRUISE improves 3D detection across
ego-vehicle, infrastructure, and cooperative views, as well as cooperative 3D
tracking on the V2X-Seq benchmark; and 3) CRUISE effectively generates
challenging corner cases.

</details>


### [93] [Q-Former Autoencoder: A Modern Framework for Medical Anomaly Detection](https://arxiv.org/abs/2507.18481)
*Francesco Dalmonte,Emirhan Bayar,Emre Akbas,Mariana-Iuliana Georgescu*

Main category: cs.CV

TL;DR: 提出了一种名为Q-Former自编码器（QFAE）的无监督医学图像异常检测框架。该框架利用冻结的预训练视觉基础模型（如DINO、DINOv2、MAE）作为特征提取器，并引入基于MAE的感知损失，在多个医学异常检测基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 医学图像中的异常检测任务极具挑战性，主要原因在于异常的多样性以及难以收集到全面标注的数据集，这促使研究者探索无监督的解决方案。

Method: 核心方法是Q-Former自编码器。它不从头训练编码器，而是直接使用冻结的预训练视觉基础模型（如DINO、DINOv2、MAE）作为特征提取器，以获取丰富、多阶段的高级表示，且无需特定领域的微调。该方法将Q-Former架构用作瓶颈，以控制重建序列的长度并高效聚合多尺度特征。此外，还引入了基于预训练Masked Autoencoder（MAE）的感知损失，以指导重建过程生成语义上有意义的结构。

Result: 该框架在BraTS2021、RESC和RSNA等四个不同的医学异常检测基准测试中，取得了最先进的（SOTA）结果。

Conclusion: 研究结果强调了在自然图像上预训练的视觉基础模型编码器，无需进一步微调即可有效泛化到医学图像分析任务的巨大潜力。

Abstract: Anomaly detection in medical images is an important yet challenging task due
to the diversity of possible anomalies and the practical impossibility of
collecting comprehensively annotated data sets. In this work, we tackle
unsupervised medical anomaly detection proposing a modernized autoencoder-based
framework, the Q-Former Autoencoder, that leverages state-of-the-art pretrained
vision foundation models, such as DINO, DINOv2 and Masked Autoencoder. Instead
of training encoders from scratch, we directly utilize frozen vision foundation
models as feature extractors, enabling rich, multi-stage, high-level
representations without domain-specific fine-tuning. We propose the usage of
the Q-Former architecture as the bottleneck, which enables the control of the
length of the reconstruction sequence, while efficiently aggregating multiscale
features. Additionally, we incorporate a perceptual loss computed using
features from a pretrained Masked Autoencoder, guiding the reconstruction
towards semantically meaningful structures. Our framework is evaluated on four
diverse medical anomaly detection benchmarks, achieving state-of-the-art
results on BraTS2021, RESC, and RSNA. Our results highlight the potential of
vision foundation model encoders, pretrained on natural images, to generalize
effectively to medical image analysis tasks without further fine-tuning. We
release the code and models at https://github.com/emirhanbayar/QFAE.

</details>


### [94] [A COCO-Formatted Instance-Level Dataset for Plasmodium Falciparum Detection in Giemsa-Stained Blood Smears](https://arxiv.org/abs/2507.18483)
*Frauke Wilm,Luis Carlos Rivera Monroy,Mathias Öttl,Lukas Mürdter,Leonid Mill,Andreas Maier*

Main category: cs.CV

TL;DR: 为解决深度学习疟疾诊断中高质量标注数据稀缺问题，本文发布了一个增强版的NIH疟疾数据集，包含COCO格式的详细边界框标注，并验证了其在Faster R-CNN模型上对感染细胞检测的有效性。


<details>
  <summary>Details</summary>
Motivation: 吉姆萨染色血涂片中恶性疟原虫的准确检测对于可靠的疟疾诊断至关重要，尤其是在发展中国家。尽管基于深度学习的目标检测方法在自动化疟疾诊断方面显示出巨大潜力，但由于缺乏具有详细实例级标注的数据集，其应用受到限制。

Method: 本文提出了一个增强版的公开NIH疟疾数据集，增加了COCO格式的详细边界框标注，以支持目标检测训练。通过训练一个Faster R-CNN模型来检测感染和未感染的红细胞以及白细胞，对修订后的标注进行了验证。在原始数据集上进行了交叉验证，并结合了自动化标注精炼和有针对性的人工校正。

Result: 在原始数据集上进行交叉验证，感染细胞检测的F1分数高达0.88。这些结果强调了标注数量和一致性的重要性，并证明了自动化标注精炼结合有针对性的人工校正可以产生足够高质量的训练数据，以实现稳健的检测性能。

Conclusion: 更新后的、包含详细COCO标注的数据集已公开可用，为自动化疟疾诊断中的深度学习模型训练提供了高质量的数据，证明了通过标注数量、一致性以及精炼与校正相结合的方法，可以有效提升检测模型的性能。

Abstract: Accurate detection of Plasmodium falciparum in Giemsa-stained blood smears is
an essential component of reliable malaria diagnosis, especially in developing
countries. Deep learning-based object detection methods have demonstrated
strong potential for automated Malaria diagnosis, but their adoption is limited
by the scarcity of datasets with detailed instance-level annotations. In this
work, we present an enhanced version of the publicly available NIH malaria
dataset, with detailed bounding box annotations in COCO format to support
object detection training. We validated the revised annotations by training a
Faster R-CNN model to detect infected and non-infected red blood cells, as well
as white blood cells. Cross-validation on the original dataset yielded F1
scores of up to 0.88 for infected cell detection. These results underscore the
importance of annotation volume and consistency, and demonstrate that automated
annotation refinement combined with targeted manual correction can produce
training data of sufficient quality for robust detection performance. The
updated annotations set is publicly available via GitHub:
https://github.com/MIRA-Vision-Microscopy/malaria-thin-smear-coco.

</details>


### [95] [Delving into Mapping Uncertainty for Mapless Trajectory Prediction](https://arxiv.org/abs/2507.18498)
*Zongzheng Zhang,Xuchong Qiu,Boran Zhang,Guantian Zheng,Xunjiang Gu,Guoxuan Chi,Huan-ang Gao,Leichen Wang,Ziming Liu,Xinrun Li,Igor Gilitschenski,Hongyang Li,Hang Zhao,Hao Zhao*

Main category: cs.CV

TL;DR: 本文分析了地图不确定性对轨迹预测的益处场景，提出了一种基于自我车辆运动状态的自适应门控机制和一种新的协方差地图不确定性方法，显著提升了无地图轨迹预测的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶正转向无地图方法，在线生成高清（HD）地图，但其可靠性不确定。将地图不确定性纳入轨迹预测虽有潜力，但现有策略对何时受益缺乏深入洞察。

Method: 首先分析了地图不确定性对轨迹预测影响最大的驾驶场景，并识别出自我车辆运动状态这一关键因素。在此基础上，提出了新颖的“本体感知场景门控”（Proprioceptive Scenario Gating），根据自我车辆未来运动学预测自适应地整合地图不确定性。此外，引入了一种更符合地图几何的“基于协方差的地图不确定性”方法。

Result: 该方法增强了在线地图与轨迹预测的协同作用，提供了不确定性何时有利的可解释性，并优于先前的集成方法。在nuScenes数据集上，无地图轨迹预测性能比现有最佳方法提高了23.6%。

Conclusion: 研究成功识别了自我运动状态在整合地图不确定性中的关键作用，并提出了有效的自适应集成方法和不确定性表示，显著提升了无地图轨迹预测的性能、鲁棒性和可解释性。

Abstract: Recent advances in autonomous driving are moving towards mapless approaches,
where High-Definition (HD) maps are generated online directly from sensor data,
reducing the need for expensive labeling and maintenance. However, the
reliability of these online-generated maps remains uncertain. While
incorporating map uncertainty into downstream trajectory prediction tasks has
shown potential for performance improvements, current strategies provide
limited insights into the specific scenarios where this uncertainty is
beneficial. In this work, we first analyze the driving scenarios in which
mapping uncertainty has the greatest positive impact on trajectory prediction
and identify a critical, previously overlooked factor: the agent's kinematic
state. Building on these insights, we propose a novel Proprioceptive Scenario
Gating that adaptively integrates map uncertainty into trajectory prediction
based on forecasts of the ego vehicle's future kinematics. This lightweight,
self-supervised approach enhances the synergy between online mapping and
trajectory prediction, providing interpretability around where uncertainty is
advantageous and outperforming previous integration methods. Additionally, we
introduce a Covariance-based Map Uncertainty approach that better aligns with
map geometry, further improving trajectory prediction. Extensive ablation
studies confirm the effectiveness of our approach, achieving up to 23.6%
improvement in mapless trajectory prediction performance over the
state-of-the-art method using the real-world nuScenes driving dataset. Our
code, data, and models are publicly available at
https://github.com/Ethan-Zheng136/Map-Uncertainty-for-Trajectory-Prediction.

</details>


### [96] [Human Scanpath Prediction in Target-Present Visual Search with Semantic-Foveal Bayesian Attention](https://arxiv.org/abs/2507.18503)
*João Luzio,Alexandre Bernardino,Plinio Moreno*

Main category: cs.CV

TL;DR: 本文提出了一种名为SemBA-FAST的深度学习框架，用于预测目标存在视觉搜索中的人类视觉注意力，该框架结合了深度目标检测和概率语义融合，并在COCO-Search18数据集上取得了接近人类眼动轨迹的优异表现。


<details>
  <summary>Details</summary>
Motivation: 人类在目标导向的视觉任务中，感知受自上而下和自下而上线索引导，且中央凹视觉在有效引导注意力方面至关重要。现有生物启发计算注意力模型利用深度学习和人类眼动路径数据取得了进展，但仍有提升空间，尤其是在自上而下框架中。

Method: 本文提出了SemBA-FAST（Semantic-based Bayesian Attention for Foveal Active visual Search Tasks）框架，这是一个用于预测目标存在视觉搜索中人类视觉注意力的自上而下框架。它将深度目标检测与概率语义融合机制相结合，动态生成注意力图，并利用预训练检测器和人工中央凹视觉（foveation）来顺序更新自上而下知识并改进注视点预测。

Result: SemBA-FAST在COCO-Search18基准数据集上进行了评估，其生成的注视序列与人类真实眼动路径高度匹配。该方法超越了基线模型和其他自上而下的方法，在某些情况下甚至能与利用眼动路径信息的模型相媲美。

Conclusion: 这些发现为语义-中央凹概率框架在类人注意力建模方面的能力提供了宝贵见解，对实时认知计算和机器人技术具有重要意义。

Abstract: In goal-directed visual tasks, human perception is guided by both top-down
and bottom-up cues. At the same time, foveal vision plays a crucial role in
directing attention efficiently. Modern research on bio-inspired computational
attention models has taken advantage of advancements in deep learning by
utilizing human scanpath data to achieve new state-of-the-art performance. In
this work, we assess the performance of SemBA-FAST, i.e. Semantic-based
Bayesian Attention for Foveal Active visual Search Tasks, a top-down framework
designed for predicting human visual attention in target-present visual search.
SemBA-FAST integrates deep object detection with a probabilistic semantic
fusion mechanism to generate attention maps dynamically, leveraging pre-trained
detectors and artificial foveation to update top-down knowledge and improve
fixation prediction sequentially. We evaluate SemBA-FAST on the COCO-Search18
benchmark dataset, comparing its performance against other scanpath prediction
models. Our methodology achieves fixation sequences that closely match human
ground-truth scanpaths. Notably, it surpasses baseline and other top-down
approaches and competes, in some cases, with scanpath-informed models. These
findings provide valuable insights into the capabilities of semantic-foveal
probabilistic frameworks for human-like attention modelling, with implications
for real-time cognitive computing and robotics.

</details>


### [97] [Towards Large Scale Geostatistical Methane Monitoring with Part-based Object Detection](https://arxiv.org/abs/2507.18513)
*Adhemar de Senneville,Xavier Bou,Thibaud Ehret,Rafael Grompone,Jean Louis Bonne,Nicolas Dumelie,Thomas Lauvaux,Gabriele Facciolo*

Main category: cs.CV

TL;DR: 该论文提出了一种基于部件的方法，用于在遥感图像中检测稀有对象（生物消化器），以解决数据量大和目标稀疏的挑战，并将其应用于法国沼气池的甲烷排放量估算。


<details>
  <summary>Details</summary>
Motivation: 尽管遥感数据日益普及，但其巨大的数据量使得在大地理区域内检测稀有对象成为挑战，然而这对于评估人类活动的环境影响（如甲烷排放）至关重要。

Method: 首先，构建了一个包含生物消化器的新型数据集，该数据集训练和验证集小，测试集大且高度不平衡（无目标观测占多数）。其次，开发了一种基于部件的方法，通过考虑生物消化器的关键子元素来提升初始检测效果。最后，将该方法应用于新的、未见区域以建立生物消化器清单，并计算这些基础设施在特定区域和时间内的甲烷产量地理统计估算值。

Result: 开发的方法能够提升初始检测效果，成功构建了法国生物消化器的清单，并能据此估算特定区域和时间内的甲烷产量。

Conclusion: 所提出的基于部件的检测方法能够有效识别遥感图像中的稀有对象（如生物消化器），从而支持对环境影响（如甲烷排放）进行大规模评估。

Abstract: Object detection is one of the main applications of computer vision in remote
sensing imagery. Despite its increasing availability, the sheer volume of
remote sensing data poses a challenge when detecting rare objects across large
geographic areas. Paradoxically, this common challenge is crucial to many
applications, such as estimating environmental impact of certain human
activities at scale. In this paper, we propose to address the problem by
investigating the methane production and emissions of bio-digesters in France.
We first introduce a novel dataset containing bio-digesters, with small
training and validation sets, and a large test set with a high imbalance
towards observations without objects since such sites are rare. We develop a
part-based method that considers essential bio-digester sub-elements to boost
initial detections. To this end, we apply our method to new, unseen regions to
build an inventory of bio-digesters. We then compute geostatistical estimates
of the quantity of methane produced that can be attributed to these
infrastructures in a given area at a given time.

</details>


### [98] [Object segmentation in the wild with foundation models: application to vision assisted neuro-prostheses for upper limbs](https://arxiv.org/abs/2507.18517)
*Bolutife Atoki,Jenny Benois-Pineau,Renaud Péteri,Fabien Baldacci,Aymar de Rugy*

Main category: cs.CV

TL;DR: 本文研究使用基础模型（如SAM）在高度杂乱的真实场景中进行语义对象分割，通过注视点生成提示并微调模型，以应用于视觉引导的上肢神经假肢。


<details>
  <summary>Details</summary>
Motivation: 在不针对特定图像进行微调的情况下，使基础模型能够分割高度杂乱的“野外”场景中的日常物体，特别是为视觉引导的上肢神经假肢应用提供支持。

Method: 提出一种基于注视点生成提示的方法来引导Segment Anything Model (SAM) 进行分割，并使用自我中心视觉数据对SAM进行微调。

Result: 在Grasping-in-the-Wild真实世界挑战性数据集上，IoU分割质量指标提高了0.51点。

Conclusion: 通过结合注视点提示和在特定自我中心数据上的微调，基础模型能够显著提高在高度杂乱真实场景中的对象分割性能，适用于神经假肢等应用。

Abstract: In this work, we address the problem of semantic object segmentation using
foundation models. We investigate whether foundation models, trained on a large
number and variety of objects, can perform object segmentation without
fine-tuning on specific images containing everyday objects, but in highly
cluttered visual scenes. The ''in the wild'' context is driven by the target
application of vision guided upper limb neuroprostheses. We propose a method
for generating prompts based on gaze fixations to guide the Segment Anything
Model (SAM) in our segmentation scenario, and fine-tune it on egocentric visual
data. Evaluation results of our approach show an improvement of the IoU
segmentation quality metric by up to 0.51 points on real-world challenging data
of Grasping-in-the-Wild corpus which is made available on the RoboFlow Platform
(https://universe.roboflow.com/iwrist/grasping-in-the-wild)

</details>


### [99] [GaussianFusionOcc: A Seamless Sensor Fusion Approach for 3D Occupancy Prediction Using 3D Gaussians](https://arxiv.org/abs/2507.18522)
*Tomislav Pavković,Mohammad-Ali Nikouei Mahani,Johannes Niedermayer,Johannes Betz*

Main category: cs.CV

TL;DR: GaussianFusionOcc提出了一种新的3D语义占用预测方法，通过结合语义3D高斯表示和创新的多模态（相机、激光雷达、雷达）传感器融合机制，显著提升了自动驾驶中环境感知的精度、内存效率和推理速度。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中精确安全的解释和导航依赖于有效的传感器融合，且传统方法依赖于密集的网格表示，存在效率问题。因此，需要一种更精确、可扩展且高效的3D语义占用预测方法。

Method: 该方法名为GaussianFusionOcc，核心在于使用语义3D高斯表示替代传统密集网格，并采用创新的传感器融合机制。它通过模态无关的可变形注意力从相机、激光雷达和雷达数据中提取关键特征，然后用这些特征来优化高斯属性，从而更准确地表示环境。

Result: GaussianFusionOcc实现了更精确和可扩展的占用预测，3D高斯表示显著提高了内存效率和推理速度。通过与各种传感器组合进行广泛测试，证明了其通用性，并且性能超越了当前最先进的模型。

Conclusion: GaussianFusionOcc通过利用多模态融合的鲁棒性和高斯表示的效率，在3D语义占用预测任务中取得了卓越的性能，为自动驾驶提供了更可靠的环境感知能力。

Abstract: 3D semantic occupancy prediction is one of the crucial tasks of autonomous
driving. It enables precise and safe interpretation and navigation in complex
environments. Reliable predictions rely on effective sensor fusion, as
different modalities can contain complementary information. Unlike conventional
methods that depend on dense grid representations, our approach,
GaussianFusionOcc, uses semantic 3D Gaussians alongside an innovative sensor
fusion mechanism. Seamless integration of data from camera, LiDAR, and radar
sensors enables more precise and scalable occupancy prediction, while 3D
Gaussian representation significantly improves memory efficiency and inference
speed. GaussianFusionOcc employs modality-agnostic deformable attention to
extract essential features from each sensor type, which are then used to refine
Gaussian properties, resulting in a more accurate representation of the
environment. Extensive testing with various sensor combinations demonstrates
the versatility of our approach. By leveraging the robustness of multi-modal
fusion and the efficiency of Gaussian representation, GaussianFusionOcc
outperforms current state-of-the-art models.

</details>


### [100] [IntentVCNet: Bridging Spatio-Temporal Gaps for Intention-Oriented Controllable Video Captioning](https://arxiv.org/abs/2507.18531)
*Tianheng Qiu,Jingchun Gao,Jingyu Li,Huiyi Leong,Xuan Huang,Xi Wang,Xiaocheng Zhang,Kele Xu,Lan Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为IntentVCNet的新方法，旨在弥合大型视觉语言模型（LVLMs）在视频中进行意图导向的精细时空控制方面的不足，通过提示组合策略和高效边界框适配器实现。


<details>
  <summary>Details</summary>
Motivation: 尽管LVLMs在空间和时间理解方面表现出色，但它们无法直接响应指令对时间序列进行细粒度的空间控制，这种显著的时空差距阻碍了视频中实现精细的意图导向控制。

Method: 本文提出了IntentVCNet，从提示和模型两个角度统一了LVLMs固有的时空理解知识。具体而言，首先提出了一种提示组合策略，使LVLM能够建模用户意图提示和视频序列之间的隐含关系；其次，提出了一种参数高效的边界框适配器，增强了全局视觉上下文中的对象语义信息，使视觉token具有用户意图的先验信息。

Result: 实验证明，这两种策略的结合可以进一步增强LVLM在视频序列中建模空间细节的能力，并促进LVLM准确生成受控的意图导向字幕。所提出的方法在多个开源LVLM上取得了最先进的结果，并在IntentVC挑战中获得亚军。

Conclusion: 通过结合提示组合策略和参数高效的边界框适配器，IntentVCNet成功弥合了LVLMs在视频中进行意图导向精细时空控制的差距，显著提升了生成目标描述的能力。

Abstract: Intent-oriented controlled video captioning aims to generate targeted
descriptions for specific targets in a video based on customized user intent.
Current Large Visual Language Models (LVLMs) have gained strong instruction
following and visual comprehension capabilities. Although the LVLMs
demonstrated proficiency in spatial and temporal understanding respectively, it
was not able to perform fine-grained spatial control in time sequences in
direct response to instructions. This substantial spatio-temporal gap
complicates efforts to achieve fine-grained intention-oriented control in
video. Towards this end, we propose a novel IntentVCNet that unifies the
temporal and spatial understanding knowledge inherent in LVLMs to bridge the
spatio-temporal gap from both prompting and model perspectives. Specifically,
we first propose a prompt combination strategy designed to enable LLM to model
the implicit relationship between prompts that characterize user intent and
video sequences. We then propose a parameter efficient box adapter that
augments the object semantic information in the global visual context so that
the visual token has a priori information about the user intent. The final
experiment proves that the combination of the two strategies can further
enhance the LVLM's ability to model spatial details in video sequences, and
facilitate the LVLMs to accurately generate controlled intent-oriented
captions. Our proposed method achieved state-of-the-art results in several open
source LVLMs and was the runner-up in the IntentVC challenge. Our code is
available on https://github.com/thqiu0419/IntentVCNet.

</details>


### [101] [COT-AD: Cotton Analysis Dataset](https://arxiv.org/abs/2507.18532)
*Akbar Ali,Mahek Vyas,Soumyaratna Debnath,Chanda Grover Kamra,Jaidev Sanjay Khalane,Reuben Shibu Devanesan,Indra Deep Mastan,Subramanian Sankaranarayanan,Pankaj Khanna,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 本文提出了COT-AD，一个用于棉花作物计算机视觉分析的综合数据集，旨在弥补现有棉花农业数据集的不足。


<details>
  <summary>Details</summary>
Motivation: 现有棉花作物领域缺乏全面且针对性强的农业数据集，阻碍了计算机视觉技术在棉花生长周期分析中的应用。

Method: 构建了COT-AD数据集，包含超过25,000张图片（其中5,000张已标注），涵盖棉花整个生长周期。数据集包括用于田间尺度检测和分割的航拍图像，以及用于记录关键病害的高分辨率单反相机图像。标注内容覆盖病虫害识别、植被和杂草分析。

Result: COT-AD数据集支持多种计算机视觉任务，如分类、分割、图像恢复、增强、基于深度生成模型的棉花作物合成，以及早期病害管理。

Conclusion: COT-AD数据集的发布填补了棉花特定农业数据集的空白，有望推动数据驱动的棉花作物管理技术发展。

Abstract: This paper presents COT-AD, a comprehensive Dataset designed to enhance
cotton crop analysis through computer vision. Comprising over 25,000 images
captured throughout the cotton growth cycle, with 5,000 annotated images,
COT-AD includes aerial imagery for field-scale detection and segmentation and
high-resolution DSLR images documenting key diseases. The annotations cover
pest and disease recognition, vegetation, and weed analysis, addressing a
critical gap in cotton-specific agricultural datasets. COT-AD supports tasks
such as classification, segmentation, image restoration, enhancement, deep
generative model-based cotton crop synthesis, and early disease management,
advancing data-driven crop management

</details>


### [102] [Elucidating the Design Space of Arbitrary-Noise-Based Diffusion Models](https://arxiv.org/abs/2507.18534)
*Xingyu Qiu,Mengying Yang,Xinghua Ma,Dong Liang,Yuzhen Li,Fanding Li,Gongning Luo,Wei Wang,Kuanquan Wang,Shuo Li*

Main category: cs.CV

TL;DR: EDA扩展了EDM的扩散模型设计空间，允许使用任意噪声模式进行图像修复，解决了EDM固定高斯噪声的局限性，并在多种修复任务中以极少采样步数实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: EDM（扩散模型）在图像修复中受限于其固定的纯高斯噪声模式，这会导致对退化图像的额外破坏，增加图像转换距离和修复复杂性。现有EDM的这一限制阻碍了其在图像修复领域的进一步发展。

Method: 本文提出了EDA（任意噪声基扩散模型的设计空间阐明），它在理论上扩展了噪声模式的自由度，同时保留了EDM原有的模块灵活性。通过严格证明，增加噪声复杂度不会在修复过程中产生额外的计算开销。

Result: EDA在三种典型任务上进行了验证：MRI偏置场校正（全局平滑噪声）、CT金属伪影消除（全局尖锐噪声）和自然图像阴影去除（局部边界感知噪声）。结果显示，EDA仅需5个采样步骤就能超越大多数特定任务方法，并在偏置场校正和阴影去除任务中达到了最先进的性能。

Conclusion: EDA成功地通过引入任意噪声模式克服了EDM在图像修复中的限制，显著提升了修复效果和效率，证明了其在处理各种复杂图像退化问题上的优越性和通用性。

Abstract: EDM elucidates the unified design space of diffusion models, yet its fixed
noise patterns restricted to pure Gaussian noise, limit advancements in image
restoration. Our study indicates that forcibly injecting Gaussian noise
corrupts the degraded images, overextends the image transformation distance,
and increases restoration complexity. To address this problem, our proposed EDA
Elucidates the Design space of Arbitrary-noise-based diffusion models.
Theoretically, EDA expands the freedom of noise pattern while preserving the
original module flexibility of EDM, with rigorous proof that increased noise
complexity incurs no additional computational overhead during restoration. EDA
is validated on three typical tasks: MRI bias field correction (global smooth
noise), CT metal artifact reduction (global sharp noise), and natural image
shadow removal (local boundary-aware noise). With only 5 sampling steps, EDA
outperforms most task-specific methods and achieves state-of-the-art
performance in bias field correction and shadow removal.

</details>


### [103] [TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive Generation](https://arxiv.org/abs/2507.18537)
*Zhekai Chen,Ruihang Chu,Yukang Chen,Shiwei Zhang,Yujie Wei,Yingya Zhang,Xihui Liu*

Main category: cs.CV

TL;DR: TTS-VAR是一种针对视觉自回归（VAR）模型的通用测试时缩放框架，将生成过程建模为路径搜索问题，通过自适应批处理大小、粗粒度多样性搜索和细粒度潜力选择来提高生成质量和效率。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉生成模型需要巨大的训练和计算开销，而测试时缩放能够有效利用资源并展现出有前景的性能，因此需要开发一种通用的测试时缩放框架。

Method: 该方法将生成过程视为路径搜索问题。它引入了自适应递减批处理大小调度来平衡计算效率和探索能力。在粗粒度尺度上，提出基于聚类的多样性搜索，通过语义特征聚类保留结构多样性。在细粒度尺度上，采用基于重采样的潜力选择，利用结合多尺度生成历史的奖励函数定义潜力分数来优先选择有前景的候选。

Result: 在强大的VAR模型Infinity上，GenEval得分显著提高了8.7%（从0.69到0.75）。关键发现表明，早期阶段的结构特征能有效影响最终质量，并且重采样的效果因生成尺度的不同而异。

Conclusion: TTS-VAR是首个针对VAR模型的通用测试时缩放框架，通过创新的路径搜索方法和多尺度策略，显著提升了视觉生成模型的质量和效率，并强调了早期结构信息的重要性以及重采样在不同生成尺度上的差异性影响。

Abstract: Scaling visual generation models is essential for real-world content
creation, yet requires substantial training and computational expenses.
Alternatively, test-time scaling has garnered growing attention due to resource
efficiency and promising performance. In this work, we present TTS-VAR, the
first general test-time scaling framework for visual auto-regressive (VAR)
models, modeling the generation process as a path searching problem. To
dynamically balance computational efficiency with exploration capacity, we
first introduce an adaptive descending batch size schedule throughout the
causal generation process. Besides, inspired by VAR's hierarchical
coarse-to-fine multi-scale generation, our framework integrates two key
components: (i) At coarse scales, we observe that generated tokens are hard for
evaluation, possibly leading to erroneous acceptance of inferior samples or
rejection of superior samples. Noticing that the coarse scales contain
sufficient structural information, we propose clustering-based diversity
search. It preserves structural variety through semantic feature clustering,
enabling later selection on samples with higher potential. (ii) In fine scales,
resampling-based potential selection prioritizes promising candidates using
potential scores, which are defined as reward functions incorporating
multi-scale generation history. Experiments on the powerful VAR model Infinity
show a notable 8.7% GenEval score improvement (from 0.69 to 0.75). Key insights
reveal that early-stage structural features effectively influence final
quality, and resampling efficacy varies across generation scales. Code is
available at https://github.com/ali-vilab/TTS-VAR.

</details>


### [104] [Unposed 3DGS Reconstruction with Probabilistic Procrustes Mapping](https://arxiv.org/abs/2507.18541)
*Chong Cheng,Zijian Wang,Sicheng Yu,Yu Hu,Nanjie Yao,Hao Wang*

Main category: cs.CV

TL;DR: 针对3DGS在无姿态重建中MVS模型面对大量图像时的内存和精度限制，本文提出一种新的无姿态3DGS重建框架，通过概率Procrustes映射和3DGS与相机姿态的联合优化，实现了高效准确的场景重建和姿态估计。


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting (3DGS) 的效果高度依赖精确的相机姿态和准确的点云初始化，而这些通常由预训练的多视图立体（MVS）模型提供。然而，在处理数百张户外图像的无姿态重建任务中，现有MVS模型面临内存限制，且随着输入图像数量的增加，精度会下降。

Method: 本方法提出一个无姿态3DGS重建框架，结合了预训练MVS先验和概率Procrustes映射策略。它将输入图像划分为子集，将子图映射到全局空间，并联合优化几何和姿态。具体地，将数千万点云的映射公式化为概率Procrustes问题并求解闭合形式对齐，同时采用概率耦合和软垃圾箱机制拒绝不确定对应点。此外，提出了一个3DGS和相机姿态的联合优化框架，从置信度感知的锚点构建高斯，并将3DGS可微分渲染与解析雅可比矩阵结合，共同优化场景和姿态。

Result: 该方法能够在数分钟内对数百张图像进行点云和姿态的全局对齐。实验结果表明，在Waymo和KITTI数据集上，本方法实现了从无姿态图像序列的准确重建，并在无姿态3DGS重建领域达到了新的SOTA水平。

Conclusion: 本文提出的方法成功克服了传统MVS模型在处理大量无姿态图像时遇到的内存和精度挑战，为无姿态3DGS重建提供了一种高效、准确的解决方案，实现了场景的精确重建和姿态估计。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a core technique for 3D
representation. Its effectiveness largely depends on precise camera poses and
accurate point cloud initialization, which are often derived from pretrained
Multi-View Stereo (MVS) models. However, in unposed reconstruction task from
hundreds of outdoor images, existing MVS models may struggle with memory limits
and lose accuracy as the number of input images grows. To address this
limitation, we propose a novel unposed 3DGS reconstruction framework that
integrates pretrained MVS priors with the probabilistic Procrustes mapping
strategy. The method partitions input images into subsets, maps submaps into a
global space, and jointly optimizes geometry and poses with 3DGS. Technically,
we formulate the mapping of tens of millions of point clouds as a probabilistic
Procrustes problem and solve a closed-form alignment. By employing
probabilistic coupling along with a soft dustbin mechanism to reject uncertain
correspondences, our method globally aligns point clouds and poses within
minutes across hundreds of images. Moreover, we propose a joint optimization
framework for 3DGS and camera poses. It constructs Gaussians from
confidence-aware anchor points and integrates 3DGS differentiable rendering
with an analytical Jacobian to jointly refine scene and poses, enabling
accurate reconstruction and pose estimation. Experiments on Waymo and KITTI
datasets show that our method achieves accurate reconstruction from unposed
image sequences, setting a new state of the art for unposed 3DGS
reconstruction.

</details>


### [105] [A 3D Cross-modal Keypoint Descriptor for MR-US Matching and Registration](https://arxiv.org/abs/2507.18551)
*Daniil Morozov,Reuben Dorent,Nazim Haouchine*

Main category: cs.CV

TL;DR: 该研究提出了一种新的3D跨模态关键点描述符，用于解决术中超声（iUS）与术前磁共振成像（MRI）的配准难题，通过合成数据和对比学习实现鲁棒匹配和高精度配准。


<details>
  <summary>Details</summary>
Motivation: 由于实时超声（iUS）与磁共振成像（MRI）在外观、分辨率和视野上存在严重的模态特异性差异，术中iUS到术前MRI的配准仍然是一个未解决的问题。

Method: 该方法采用患者特异性的“合成匹配”方法，从术前MRI生成合成iUS图像，从而实现有监督的对比训练，学习共享的描述符空间。使用概率关键点检测策略识别解剖学上显著且模态一致的位置。训练中采用基于课程的、带有动态难负例挖掘的三元组损失，以学习对iUS伪影和有限覆盖范围具有鲁棒性、且旋转不变的描述符。推断时，检测MR和真实iUS图像中的关键点，识别稀疏匹配，并用于刚性配准。

Result: 该方法在ReMIND数据集的11名患者中，关键点匹配的平均精度达到69.8%，优于现有最先进的关键点匹配方法。在ReMIND2Reg基准测试中，图像配准的平均目标配准误差（TRE）为2.39毫米，具有竞争力。

Conclusion: 与现有iUS-MR配准方法相比，该框架具有可解释性，无需手动初始化，并且对iUS视野变化表现出鲁棒性。

Abstract: Intraoperative registration of real-time ultrasound (iUS) to preoperative
Magnetic Resonance Imaging (MRI) remains an unsolved problem due to severe
modality-specific differences in appearance, resolution, and field-of-view. To
address this, we propose a novel 3D cross-modal keypoint descriptor for MRI-iUS
matching and registration. Our approach employs a patient-specific
matching-by-synthesis approach, generating synthetic iUS volumes from
preoperative MRI. This enables supervised contrastive training to learn a
shared descriptor space.
  A probabilistic keypoint detection strategy is then employed to identify
anatomically salient and modality-consistent locations. During training, a
curriculum-based triplet loss with dynamic hard negative mining is used to
learn descriptors that are i) robust to iUS artifacts such as speckle noise and
limited coverage, and ii) rotation-invariant . At inference, the method detects
keypoints in MR and real iUS images and identifies sparse matches, which are
then used to perform rigid registration. Our approach is evaluated using 3D
MRI-iUS pairs from the ReMIND dataset. Experiments show that our approach
outperforms state-of-the-art keypoint matching methods across 11 patients, with
an average precision of $69.8\%$. For image registration, our method achieves a
competitive mean Target Registration Error of 2.39 mm on the ReMIND2Reg
benchmark.
  Compared to existing iUS-MR registration approach, our framework is
interpretable, requires no manual initialization, and shows robustness to iUS
field-of-view variation. Code is available at
https://github.com/morozovdd/CrossKEY.

</details>


### [106] [Deep Learning-Based Age Estimation and Gender Deep Learning-Based Age Estimation and Gender Classification for Targeted Advertisement](https://arxiv.org/abs/2507.18565)
*Muhammad Imran Zaman,Nisar Ahmed*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的新型卷积神经网络（CNN）方法，用于同时从面部图像中进行年龄和性别分类，旨在提高定向广告的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常独立处理年龄和性别分类任务，未能利用面部特征中固有的年龄和性别信息关联。本研究旨在通过学习共享表示来提高分类性能，并应用于增强定向广告活动。

Method: 提出了一种定制的卷积神经网络（CNN）架构，该架构针对年龄和性别分类任务进行了优化，并利用了面部特征中年龄和性别信息之间的内在相关性。模型在一个大型、多样化的面部图像数据集上进行训练，该数据集经过精心预处理，以确保对光照、姿态和图像质量变化的鲁棒性。

Result: 实验结果显示，性别分类准确率显著提高至95%，年龄估计的平均绝对误差（MAE）为5.77年，具有竞争力。分析发现，在估计年轻个体年龄时存在特定挑战，揭示了处理这些偏差需要有针对性的数据增强和模型优化。

Conclusion: 该方法在性别分类和年龄估计方面表现出色，特别是在性别分类上取得了显著进步。研究揭示了在年轻个体年龄估计中的挑战，并强调了未来通过有针对性的数据增强和模型优化来解决这些偏差的必要性。同时，对不同CNN架构和超参数设置的探索为未来的研究提供了宝贵见解。

Abstract: This paper presents a novel deep learning-based approach for simultaneous age
and gender classification from facial images, designed to enhance the
effectiveness of targeted advertising campaigns. We propose a custom
Convolutional Neural Network (CNN) architecture, optimized for both tasks,
which leverages the inherent correlation between age and gender information
present in facial features. Unlike existing methods that often treat these
tasks independently, our model learns shared representations, leading to
improved performance. The network is trained on a large, diverse dataset of
facial images, carefully pre-processed to ensure robustness against variations
in lighting, pose, and image quality. Our experimental results demonstrate a
significant improvement in gender classification accuracy, achieving 95%, and a
competitive mean absolute error of 5.77 years for age estimation. Critically,
we analyze the performance across different age groups, identifying specific
challenges in accurately estimating the age of younger individuals. This
analysis reveals the need for targeted data augmentation and model refinement
to address these biases. Furthermore, we explore the impact of different CNN
architectures and hyperparameter settings on the overall performance, providing
valuable insights for future research.

</details>


### [107] [Facial Demorphing from a Single Morph Using a Latent Conditional GAN](https://arxiv.org/abs/2507.18566)
*Nitish Shukla,Arun Ross*

Main category: cs.CV

TL;DR: 该论文提出了一种新的去变形（demorphing）方法，通过在潜在空间分解变形图像，以克服现有方法的局限性（如变形复制问题和对变形技术依赖），并能从合成和真实面部变形中恢复高保真度的原始图像。


<details>
  <summary>Details</summary>
Motivation: 面部变形攻击允许一张图像与多个身份关联，构成安全威胁。虽然变形攻击检测（MAD）可以识别变形，但无法揭示原始组成图像。去变形对于提供额外证据至关重要，但现有方法存在“变形复制问题”（输出与变形本身过于相似）或假设训练和测试变形使用相同的生成技术。

Method: 所提出的方法在潜在空间中分解变形图像，使其能够处理来自未知变形技术和面部风格的图像。该方法使用合成面部生成的变形进行训练，并使用真实面部通过任意变形技术生成的变形进行测试。

Result: 该方法显著优于现有方法，并能生成高保真度的去变形面部图像。

Conclusion: 所提出的去变形方法有效克服了现有方法的缺陷，能从使用未知变形技术和面部风格创建的图像中恢复原始组成图像，并取得了显著优异的性能。

Abstract: A morph is created by combining two (or more) face images from two (or more)
identities to create a composite image that is highly similar to both
constituent identities, allowing the forged morph to be biometrically
associated with more than one individual. Morph Attack Detection (MAD) can be
used to detect a morph, but does not reveal the constituent images. Demorphing
- the process of deducing the constituent images - is thus vital to provide
additional evidence about a morph. Existing demorphing methods suffer from the
morph replication problem, where the outputs tend to look very similar to the
morph itself, or assume that train and test morphs are generated using the same
morph technique. The proposed method overcomes these issues. The method
decomposes a morph in latent space allowing it to demorph images created from
unseen morph techniques and face styles. We train our method on morphs created
from synthetic faces and test on morphs created from real faces using arbitrary
morph techniques. Our method outperforms existing methods by a considerable
margin and produces high fidelity demorphed face images.

</details>


### [108] [Adversarial Distribution Matching for Diffusion Distillation Towards Efficient Image and Video Synthesis](https://arxiv.org/abs/2507.18569)
*Yanzuo Lu,Yuxi Ren,Xin Xia,Shanchuan Lin,Xing Wang,Xuefeng Xiao,Andy J. Ma,Xiaohua Xie,Jian-Huang Lai*

Main category: cs.CV

TL;DR: 该论文提出了一种名为对抗性分布匹配（ADM）的新框架，并通过DMDX统一管道解决了现有分布匹配蒸馏（DMD）方法中潜在的模式崩溃问题，显著提升了单步和多步扩散模型的生成效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的分布匹配蒸馏（DMD）技术依赖于反向KL散度最小化，可能导致在某些应用中出现模式崩溃（或模式寻求）问题。因此，需要一种新的方法来克服这一固有缺陷，实现更鲁棒和高效的模型压缩。

Method: 提出了对抗性分布匹配（ADM）框架，利用基于扩散的判别器以对抗方式对齐真实和伪分数估计器之间的潜在预测。在极具挑战性的单步蒸馏中，通过在潜在空间和像素空间使用混合判别器进一步改进生成器。与DMD2预训练中使用的均方误差不同，该方法在预训练中整合了从教师模型收集的ODE对的分布损失，为后续的分数蒸馏微调提供了更好的初始化。最终将对抗性蒸馏预训练与ADM微调结合成一个统一的管道，命名为DMDX。

Result: DMDX在SDXL上的单步性能优于DMD2，同时消耗更少的GPU时间。此外，将多步ADM蒸馏应用于SD3-Medium、SD3.5-Large和CogVideoX，为高效图像和视频合成树立了新的基准。

Conclusion: 所提出的ADM和DMDX方法有效解决了DMD的模式崩溃问题，通过对抗性学习和改进的预训练策略，在单步和多步扩散模型蒸馏方面取得了卓越的性能和效率，为图像和视频合成领域带来了显著进步。

Abstract: Distribution Matching Distillation (DMD) is a promising score distillation
technique that compresses pre-trained teacher diffusion models into efficient
one-step or multi-step student generators. Nevertheless, its reliance on the
reverse Kullback-Leibler (KL) divergence minimization potentially induces mode
collapse (or mode-seeking) in certain applications. To circumvent this inherent
drawback, we propose Adversarial Distribution Matching (ADM), a novel framework
that leverages diffusion-based discriminators to align the latent predictions
between real and fake score estimators for score distillation in an adversarial
manner. In the context of extremely challenging one-step distillation, we
further improve the pre-trained generator by adversarial distillation with
hybrid discriminators in both latent and pixel spaces. Different from the mean
squared error used in DMD2 pre-training, our method incorporates the
distributional loss on ODE pairs collected from the teacher model, and thus
providing a better initialization for score distillation fine-tuning in the
next stage. By combining the adversarial distillation pre-training with ADM
fine-tuning into a unified pipeline termed DMDX, our proposed method achieves
superior one-step performance on SDXL compared to DMD2 while consuming less GPU
time. Additional experiments that apply multi-step ADM distillation on
SD3-Medium, SD3.5-Large, and CogVideoX set a new benchmark towards efficient
image and video synthesis.

</details>


### [109] [HybridTM: Combining Transformer and Mamba for 3D Semantic Segmentation](https://arxiv.org/abs/2507.18575)
*Xinyu Wang,Jinghua Hou,Zhe Liu,Yingying Zhu*

Main category: cs.CV

TL;DR: HybridTM是首个结合Transformer和Mamba的混合架构，用于3D语义分割，通过内层混合策略有效捕捉长距离依赖和局部特征，并在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: Transformer在3D语义分割中表现出色但存在二次复杂度，限制了对大规模点云长距离依赖的建模。Mamba虽然效率高但特征表示能力不足。如何有效结合两者的优势是一个开放挑战。

Method: 提出HybridTM，首个集成Transformer和Mamba的混合架构。引入“内层混合策略”（Inner Layer Hybrid Strategy），在更细粒度上结合注意力机制和Mamba，以同时捕获长距离依赖和细粒度局部特征。

Result: HybridTM在多种室内外数据集上表现出有效性和泛化性。在ScanNet、ScanNet200和nuScenes基准测试中取得了最先进的性能。

Conclusion: HybridTM成功地结合了Transformer和Mamba的互补优势，解决了现有方法的局限性，为3D语义分割设定了新的性能标准。

Abstract: Transformer-based methods have demonstrated remarkable capabilities in 3D
semantic segmentation through their powerful attention mechanisms, but the
quadratic complexity limits their modeling of long-range dependencies in
large-scale point clouds. While recent Mamba-based approaches offer efficient
processing with linear complexity, they struggle with feature representation
when extracting 3D features. However, effectively combining these complementary
strengths remains an open challenge in this field. In this paper, we propose
HybridTM, the first hybrid architecture that integrates Transformer and Mamba
for 3D semantic segmentation. In addition, we propose the Inner Layer Hybrid
Strategy, which combines attention and Mamba at a finer granularity, enabling
simultaneous capture of long-range dependencies and fine-grained local
features. Extensive experiments demonstrate the effectiveness and
generalization of our HybridTM on diverse indoor and outdoor datasets.
Furthermore, our HybridTM achieves state-of-the-art performance on ScanNet,
ScanNet200, and nuScenes benchmarks. The code will be made available at
https://github.com/deepinact/HybridTM.

</details>


### [110] [Identifying Prompted Artist Names from Generated Images](https://arxiv.org/abs/2507.18633)
*Grace Su,Sheng-Yu Wang,Aaron Hertzmann,Eli Shechtman,Jun-Yan Zhu,Richard Zhang*

Main category: cs.CV

TL;DR: 该研究引入了一个基准数据集和评估框架，用于识别文本到图像模型中通过提示词引用的艺术家，以促进负责任的模型审查。


<details>
  <summary>Details</summary>
Motivation: 文本到图像模型通过明确命名艺术家来生成图片是一种常见且有争议的使用方式。为了负责任地管理这些模型，需要一种方法来识别图像中引用的艺术家。

Method: 研究构建了一个包含195万张图像的基准数据集，涵盖110位艺术家和四种泛化设置（未见艺术家、复杂提示、多艺术家提示、不同T2I模型）。评估了多种方法，包括特征相似性基线、对比风格描述符、数据归因方法、监督分类器和少样本原型网络。

Result: 泛化模式各异：监督模型和少样本模型在已知艺术家和复杂提示上表现出色；风格描述符在艺术家风格鲜明时迁移效果更好；多艺术家提示仍然是最具挑战性的。基准测试显示仍有很大改进空间。

Conclusion: 该基准测试揭示了识别提示艺术家任务的巨大潜力，并提供了一个公开的测试平台，以推动文本到图像模型负责任的审查和未来研究。

Abstract: A common and controversial use of text-to-image models is to generate
pictures by explicitly naming artists, such as "in the style of Greg
Rutkowski". We introduce a benchmark for prompted-artist recognition:
predicting which artist names were invoked in the prompt from the image alone.
The dataset contains 1.95M images covering 110 artists and spans four
generalization settings: held-out artists, increasing prompt complexity,
multiple-artist prompts, and different text-to-image models. We evaluate
feature similarity baselines, contrastive style descriptors, data attribution
methods, supervised classifiers, and few-shot prototypical networks.
Generalization patterns vary: supervised and few-shot models excel on seen
artists and complex prompts, whereas style descriptors transfer better when the
artist's style is pronounced; multi-artist prompts remain the most challenging.
Our benchmark reveals substantial headroom and provides a public testbed to
advance the responsible moderation of text-to-image models. We release the
dataset and benchmark to foster further research:
https://graceduansu.github.io/IdentifyingPromptedArtists/

</details>


### [111] [Captain Cinema: Towards Short Movie Generation](https://arxiv.org/abs/2507.18634)
*Junfei Xiao,Ceyuan Yang,Lvmin Zhang,Shengqu Cai,Yang Zhao,Yuwei Guo,Gordon Wetzstein,Maneesh Agrawala,Alan Yuille,Lu Jiang*

Main category: cs.CV

TL;DR: Captain Cinema是一个短片电影生成框架，能根据文本描述生成视觉连贯、叙事一致的高质量电影。


<details>
  <summary>Details</summary>
Motivation: 自动化短片电影创作，确保长程叙事和视觉连贯性，并提高生成效率。

Method: ['顶层关键帧规划：根据电影故事情节文本描述，生成一系列关键帧，确保故事情节和视觉外观（如场景、角色）的长程连贯性。', '底层视频合成：利用关键帧作为条件信号，通过支持长上下文学习的视频合成模型，生成关键帧之间的时空动态。', '引入交错训练策略：为适应长上下文视频数据，对多模态扩散Transformer（MM-DiT）引入了交错训练策略，以支持多场景长叙事电影的稳定高效生成。', '数据集：模型在一个特别策划的、包含交错数据对的电影数据集上进行训练。']

Result: Captain Cinema在自动化创建视觉连贯、叙事一致的高质量短片电影方面表现出色，且效率高。

Conclusion: Captain Cinema框架通过其分层生成方法和针对长上下文视频数据优化的训练策略，成功实现了从文本描述到高质量短片电影的自动生成。

Abstract: We present Captain Cinema, a generation framework for short movie generation.
Given a detailed textual description of a movie storyline, our approach firstly
generates a sequence of keyframes that outline the entire narrative, which
ensures long-range coherence in both the storyline and visual appearance (e.g.,
scenes and characters). We refer to this step as top-down keyframe planning.
These keyframes then serve as conditioning signals for a video synthesis model,
which supports long context learning, to produce the spatio-temporal dynamics
between them. This step is referred to as bottom-up video synthesis. To support
stable and efficient generation of multi-scene long narrative cinematic works,
we introduce an interleaved training strategy for Multimodal Diffusion
Transformers (MM-DiT), specifically adapted for long-context video data. Our
model is trained on a specially curated cinematic dataset consisting of
interleaved data pairs. Our experiments demonstrate that Captain Cinema
performs favorably in the automated creation of visually coherent and narrative
consistent short movies in high quality and efficiency. Project page:
https://thecinema.ai

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [112] [Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning](https://arxiv.org/abs/2507.17842)
*Yimeng Zhang,Tian Wang,Jiri Gesi,Ziyi Wang,Yuxuan Lu,Jiacheng Lin,Sinong Zhan,Vianne Gao,Ruochen Jiao,Junze Liu,Kun Qian,Yuxin Tang,Ran Xue,Houyu Zhang,Qingjun Cui,Yufan Guo,Dakuo Wang*

Main category: cs.CL

TL;DR: 本文提出Shop-R1，一个基于强化学习的框架，旨在通过分解为理由生成和动作预测两个阶段，并设计分层奖励机制，显著提升大型语言模型在模拟在线购物环境中人类行为的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过LLM合成的理由进行SFT来增强推理能力，但其性能受限于生成理由的模型本身的推理能力。因此，需要一种新方法来突破这一限制，以更有效地模拟真实人类行为。

Method: Shop-R1将人类行为模拟任务分解为理由生成和动作预测两个阶段，各由不同的奖励信号引导。理由生成阶段利用内部模型信号（如logit分布）进行自监督指导。动作预测阶段采用分层奖励结构，并进行难度感知缩放，以防止奖励作弊，并对高层动作类型和细粒度子动作细节（属性和值）进行奖励，奖励与输出难度成正比。

Result: 实验结果表明，Shop-R1方法相对于基线取得了超过65%的相对提升。

Conclusion: Shop-R1框架通过其创新的两阶段RL设计和分层、难度感知的奖励机制，成功显著提升了大型语言模型在在线购物环境中模拟人类行为的推理能力。

Abstract: Large Language Models (LLMs) have recently demonstrated strong potential in
generating 'believable human-like' behavior in web environments. Prior work has
explored augmenting training data with LLM-synthesized rationales and applying
supervised fine-tuning (SFT) to enhance reasoning ability, which in turn can
improve downstream action prediction. However, the performance of such
approaches remains inherently bounded by the reasoning capabilities of the
model used to generate the rationales. In this paper, we introduce Shop-R1, a
novel reinforcement learning (RL) framework aimed at enhancing the reasoning
ability of LLMs for simulation of real human behavior in online shopping
environments Specifically, Shop-R1 decomposes the human behavior simulation
task into two stages: rationale generation and action prediction, each guided
by distinct reward signals. For rationale generation, we leverage internal
model signals (e.g., logit distributions) to guide the reasoning process in a
self-supervised manner. For action prediction, we propose a hierarchical reward
structure with difficulty-aware scaling to prevent reward hacking and enable
fine-grained reward assignment. This design evaluates both high-level action
types and the correctness of fine-grained sub-action details (attributes and
values), rewarding outputs proportionally to their difficulty. Experimental
results show that our method achieves a relative improvement of over 65%
compared to the baseline.

</details>


### [113] [Dynamic and Generalizable Process Reward Modeling](https://arxiv.org/abs/2507.17849)
*Zhangyue Yin,Qiushi Sun,Zhiyuan Zeng,Qinyuan Cheng,Xipeng Qiu,Xuanjing Huang*

Main category: cs.CL

TL;DR: 本文提出了动态可泛化的过程奖励模型（DG-PRM），通过奖励树和帕累托支配估计，解决了现有过程奖励模型泛化性差和评估标准静态的问题，显著提升了LLM在复杂任务中的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型（PRMs）主要依赖启发式方法，导致跨领域泛化能力差。LLM作为评判者的方法虽然能提供泛化奖励，但忽视了文本中的有意义指导，且静态、粗粒度的评估标准难以适应复杂的流程监督。

Method: 本文提出了DG-PRM，其核心特点包括：1. 奖励树：捕捉并存储细粒度、多维度的奖励标准。2. 动态选择：根据步骤动态选择奖励信号进行评分。3. 帕累托支配估计：创新性地采用此方法来识别判别性的正负对，以处理多方面的奖励信号。

Result: 实验结果表明，DG-PRM在现有基准测试中取得了惊人的性能，显著提升了模型在需要密集奖励的任务中的表现。进一步分析显示，DG-PRM对分布外（OOD）场景具有良好的适应性，展示了卓越的泛化能力。

Conclusion: DG-PRM有效解决了过程奖励模型在泛化性和动态评估方面的挑战，通过其创新的奖励树和帕累托支配估计方法，显著提升了大型语言模型在复杂任务中的性能和跨领域泛化能力。

Abstract: Process Reward Models (PRMs) are crucial for guiding Large Language Models
(LLMs) in complex scenarios by providing dense reward signals. However,
existing PRMs primarily rely on heuristic approaches, which struggle with
cross-domain generalization. While LLM-as-judge has been proposed to provide
generalized rewards, current research has focused mainly on feedback results,
overlooking the meaningful guidance embedded within the text. Additionally,
static and coarse-grained evaluation criteria struggle to adapt to complex
process supervision. To tackle these challenges, we propose Dynamic and
Generalizable Process Reward Modeling (DG-PRM), which features a reward tree to
capture and store fine-grained, multi-dimensional reward criteria. DG-PRM
dynamically selects reward signals for step-wise reward scoring. To handle
multifaceted reward signals, we pioneeringly adopt Pareto dominance estimation
to identify discriminative positive and negative pairs. Experimental results
show that DG-PRM achieves stunning performance on prevailing benchmarks,
significantly boosting model performance across tasks with dense rewards.
Further analysis reveals that DG-PRM adapts well to out-of-distribution
scenarios, demonstrating exceptional generalizability.

</details>


### [114] [VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL](https://arxiv.org/abs/2507.17896)
*Shubham Mohole,Sainyam Galhotra*

Main category: cs.CL

TL;DR: VeriMinder是一个交互式系统，旨在帮助自然语言数据库接口（NLIDB）用户避免数据分析中的认知偏差，通过引入偏见上下文语义映射、Hard-to-Vary分析框架和优化的LLM提示生成实现。


<details>
  <summary>Details</summary>
Motivation: 自然语言数据库接口（NLIDB）使数据分析大众化，但非统计学背景的用户难以提出无偏见的分析问题。现有研究主要关注文本到SQL的准确性，而认知偏差问题尚未得到充分探索。

Method: 本文提出了VeriMinder系统，其方法包含三项创新：1) 针对特定分析上下文的偏见上下文语义映射框架；2) 运用Hard-to-Vary原则指导系统数据分析的分析框架；3) 优化的大型语言模型（LLM）驱动系统，通过多候选、评论反馈和自我反思的结构化过程生成高质量、任务特定的提示。

Result: 用户测试证实了该方法的优点。在直接用户体验评估中，82.5%的参与者表示VeriMinder对分析质量产生了积极影响。在比较评估中，VeriMinder在分析的具体性、全面性和准确性指标上，比替代方法至少高出20%。

Conclusion: VeriMinder系统（一个Web应用）旨在帮助用户在数据分析中避免“错误问题”的脆弱性。其代码库和提示已作为MIT许可的开源软件提供，以促进社区的进一步研究和应用。

Abstract: Application systems using natural language interfaces to databases (NLIDBs)
have democratized data analysis. This positive development has also brought
forth an urgent challenge to help users who might use these systems without a
background in statistical analysis to formulate bias-free analytical questions.
Although significant research has focused on text-to-SQL generation accuracy,
addressing cognitive biases in analytical questions remains underexplored. We
present VeriMinder, https://veriminder.ai, an interactive system for detecting
and mitigating such analytical vulnerabilities. Our approach introduces three
key innovations: (1) a contextual semantic mapping framework for biases
relevant to specific analysis contexts (2) an analytical framework that
operationalizes the Hard-to-Vary principle and guides users in systematic data
analysis (3) an optimized LLM-powered system that generates high-quality,
task-specific prompts using a structured process involving multiple candidates,
critic feedback, and self-reflection.
  User testing confirms the merits of our approach. In direct user experience
evaluation, 82.5% participants reported positively impacting the quality of the
analysis. In comparative evaluation, VeriMinder scored significantly higher
than alternative approaches, at least 20% better when considered for metrics of
the analysis's concreteness, comprehensiveness, and accuracy. Our system,
implemented as a web application, is set to help users avoid "wrong question"
vulnerability during data analysis. VeriMinder code base with prompts,
https://reproducibility.link/veriminder, is available as an MIT-licensed
open-source software to facilitate further research and adoption within the
community.

</details>


### [115] [One Whisper to Grade Them All](https://arxiv.org/abs/2507.17918)
*Nhan Phan,Anusha Porwal,Yaroslav Getman,Ekaterina Voskoboinik,Tamás Grósz,Mikko Kurimo*

Main category: cs.CL

TL;DR: 提出了一种高效的端到端多部分二语口语自动评估（ASA）方法，使用单个编码器处理所有语音响应并直接预测最终分数，显著提升了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有ASA系统需要转录和独立部分模型，导致推理时间长，难以在大规模计算机辅助语言学习（CALL）系统中实际应用，因此需要一种更高效、端到端的方法。

Method: 核心方法是使用单个Whisper-small编码器处理所有四个语音响应，并通过一个轻量级聚合器整合信息，直接预测最终分数。此外，提出了一种数据采样策略，以提高数据效率和处理不平衡类别。

Result: 系统实现了0.384的均方根误差（RMSE），优于基于文本的基线（0.44）。模型参数最多为1.68亿（约为Whisper-small的70%）。数据采样策略仅使用44.8%的说话者数据就达到了0.383的RMSE，显示出对不平衡类别的性能提升和强大的数据效率。

Conclusion: 所提出的端到端ASA方法通过移除转录和独立部分模型，显著缩短了推理时间，提高了效率，并在更少的参数和更少数据的情况下取得了更好的性能，使其在大规模CALL系统中具有实用性。

Abstract: We present an efficient end-to-end approach for holistic Automatic Speaking
Assessment (ASA) of multi-part second-language tests, developed for the 2025
Speak & Improve Challenge. Our system's main novelty is the ability to process
all four spoken responses with a single Whisper-small encoder, combine all
information via a lightweight aggregator, and predict the final score. This
architecture removes the need for transcription and per-part models, cuts
inference time, and makes ASA practical for large-scale Computer-Assisted
Language Learning systems.
  Our system achieved a Root Mean Squared Error (RMSE) of 0.384, outperforming
the text-based baseline (0.44) while using at most 168M parameters (about 70%
of Whisper-small). Furthermore, we propose a data sampling strategy, allowing
the model to train on only 44.8% of the speakers in the corpus and still reach
0.383 RMSE, demonstrating improved performance on imbalanced classes and strong
data efficiency.

</details>


### [116] [Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text](https://arxiv.org/abs/2507.17944)
*Hulayyil Alshammari,Praveen Rao*

Main category: cs.CL

TL;DR: 本研究评估了六种AI检测工具在识别DeepSeek生成文本方面的能力，并测试了标准和拟人化复述等对抗性攻击的影响。此外，还探索了DeepSeek本身作为检测器的性能。结果显示，拟人化攻击显著降低了检测器准确率，而DeepSeek结合少样本和思维链推理表现出高检测精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速发展引发了对写作完整性的担忧，催生了AI检测技术。然而，现有研究主要集中在ChatGPT等知名LLMs上，对于新发布的DeepSeek模型的检测能力存在明显空白。此外，对抗性攻击（如复述）会抑制检测器的性能，需要评估其对DeepSeek生成文本检测的影响。

Method: 研究使用了六个常用的AI检测工具（AI Text Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, GPTZero）来识别DeepSeek生成的文本。收集了49对LLM时代前的人类问答对，并使用DeepSeek-v3生成了匹配的49个AI样本。接着，应用了复述和拟人化等对抗性技术，额外生成了196个样本以挑战检测器鲁棒性。同时，通过少样本提示和思维链推理（CoT）的方式，将DeepSeek自身也作为AI和人类文本的分类器进行评估。

Result: QuillBot和Copyleaks在原始及复述的DeepSeek文本上表现接近完美，但其他工具（特别是AI Text Classifier和GPT-2）表现不稳定。最有效的攻击是拟人化，将Copyleaks的准确率降至71%，QuillBot降至58%，GPTZero降至52%。DeepSeek作为检测器，通过少样本和思维链提示展现出高准确率，最佳的五样本结果仅错误分类了49个样本中的一个（AI召回率96%，人类召回率100%）。

Conclusion: 当前市面上的AI检测工具在识别DeepSeek生成文本方面表现不一，且拟人化复述是有效的对抗性攻击，能显著降低检测准确率。值得注意的是，LLM本身（如DeepSeek结合少样本和思维链推理）在区分AI生成和人类编写文本方面展现出极高的潜力，可能成为未来AI文本检测的有效方法。

Abstract: Large language models (LLMs) have rapidly transformed the creation of written
materials. LLMs have led to questions about writing integrity, thereby driving
the creation of artificial intelligence (AI) detection technologies.
Adversarial attacks, such as standard and humanized paraphrasing, inhibit
detectors' ability to detect machine-generated text. Previous studies have
mainly focused on ChatGPT and other well-known LLMs and have shown varying
accuracy across detectors. However, there is a clear gap in the literature
about DeepSeek, a recently published LLM. Therefore, in this work, we
investigate whether six generally accessible AI detection tools -- AI Text
Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, and GPTZero -- can
consistently recognize text generated by DeepSeek. The detectors were exposed
to the aforementioned adversarial attacks. We also considered DeepSeek as a
detector by performing few-shot prompting and chain-of-thought reasoning (CoT)
for classifying AI and human-written text. We collected 49 human-authored
question-answer pairs from before the LLM era and generated matching responses
using DeepSeek-v3, producing 49 AI-generated samples. Then, we applied
adversarial techniques such as paraphrasing and humanizing to add 196 more
samples. These were used to challenge detector robustness and assess accuracy
impact. While QuillBot and Copyleaks showed near-perfect performance on
original and paraphrased DeepSeek text, others -- particularly AI Text
Classifier and GPT-2 -- showed inconsistent results. The most effective attack
was humanization, reducing accuracy to 71% for Copyleaks, 58% for QuillBot, and
52% for GPTZero. Few-shot and CoT prompting showed high accuracy, with the best
five-shot result misclassifying only one of 49 samples (AI recall 96%, human
recall 100%).

</details>


### [117] [Are LLM Belief Updates Consistent with Bayes' Theorem?](https://arxiv.org/abs/2507.17951)
*Sohaib Imran,Ihor Kendiukhov,Matthew Broerman,Aditya Thomas,Riccardo Campanella,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 研究发现，更大、能力更强的预训练语言模型在上下文推理中，其信念更新与贝叶斯定理的一致性更高。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（LLMs）在接收上下文证据时，是否能更一致地按照贝叶斯定理更新其对命题的“信念”，特别是模型规模和能力对其贝叶斯一致性的影响。

Method: 开发了贝叶斯一致性系数（BCC）指标，并生成了用于测量BCC的数据集。测量了来自五个模型家族的多个仅预训练语言模型的BCC，并将其与模型参数数量、训练数据量以及在常见基准测试上的得分进行比较。

Result: 结果支持了假设，即更大、能力更强的预训练语言模型所分配的置信度与贝叶斯定理更具一致性。

Conclusion: 更大的LLMs在信念更新上更符合贝叶斯定理，这一发现对于理解和管理大型语言模型具有重要意义。

Abstract: Do larger and more capable language models learn to update their "beliefs"
about propositions more consistently with Bayes' theorem when presented with
evidence in-context? To test this, we formulate a Bayesian Coherence
Coefficient (BCC) metric and generate a dataset with which to measure the BCC.
We measure BCC for multiple pre-trained-only language models across five model
families, comparing against the number of model parameters, the amount of
training data, and model scores on common benchmarks. Our results provide
evidence for our hypothesis that larger and more capable pre-trained language
models assign credences that are more coherent with Bayes' theorem. These
results have important implications for our understanding and governance of
LLMs.

</details>


### [118] [Natural Language Processing for Tigrinya: Current State and Future Directions](https://arxiv.org/abs/2507.17974)
*Fitsum Gaim,Jong C. Park*

Main category: cs.CL

TL;DR: 该论文全面综述了2011年至2025年期间提格雷尼亚语（Tigrinya）的自然语言处理（NLP）研究，分析了资源、模型和应用，并指出了挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管提格雷尼亚语有数百万使用者，但在NLP研究中严重不足。这项工作旨在全面分析现有研究，识别其发展轨迹、瓶颈和未来潜力。

Method: 通过系统回顾40多项研究，分析了提格雷尼亚语NLP在过去十多年间在计算资源、模型和应用方面的发展，涵盖了形态处理、机器翻译、语音识别和问答等十个下游任务。

Result: 研究发现提格雷尼亚语NLP研究从基于规则的系统发展到现代神经网络架构，进展与资源创建里程碑紧密相关。主要挑战在于其形态复杂性和资源稀缺性。有前景的研究方向包括形态感知建模、跨语言迁移和以社区为中心的资源开发。

Conclusion: 该工作为提格雷尼亚语NLP研究人员提供了全面的参考，并为未来的研究指明了方向。

Abstract: Despite being spoken by millions of people, Tigrinya remains severely
underrepresented in Natural Language Processing (NLP) research. This work
presents a comprehensive survey of NLP research for Tigrinya, analyzing over 40
studies spanning more than a decade of work from 2011 to 2025. We
systematically review the current state of computational resources, models, and
applications across ten distinct downstream tasks, including morphological
processing, machine translation, speech recognition, and question-answering.
Our analysis reveals a clear trajectory from foundational, rule-based systems
to modern neural architectures, with progress consistently unlocked by resource
creation milestones. We identify key challenges rooted in Tigrinya's
morphological complexity and resource scarcity, while highlighting promising
research directions, including morphology-aware modeling, cross-lingual
transfer, and community-centered resource development. This work serves as both
a comprehensive reference for researchers and a roadmap for advancing Tigrinya
NLP. A curated metadata of the surveyed studies and resources is made publicly
available.\footnote{Tigrinya NLP Anthology:
https://github.com/fgaim/tigrinya-nlp-anthology.

</details>


### [119] [Technical Report of TeleChat2, TeleChat2.5 and T1](https://arxiv.org/abs/2507.18013)
*Zihan Wang,Xinzhang Liu,Yitong Yao,Chao Wang,Yu Zhao,Zhihao Yang,Wenmin Deng,Kaipeng Jia,Jiaxin Peng,Yuyao Huang,Sishi Xiong,Zhuo Jiang,Kaidong Yu,Xiaohui Hu,Fubei Yao,Ruiyu Fang,Zhuoru Jiang,Ruiting Song,Qiyi Xie,Rui Xue,Xuewei He,Yanlei Xue,Zhu Yuan,Zhaoxi Zhang,Zilu Huang,Shiquan Wang,Xin Wang,Hanming Wu,Mingyuan Wang,Xufeng Zhan,Yuhan Sun,Zhaohu Xing,Yuhao Jiang,Bingkai Yang,Shuangyong Song,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

TL;DR: 本文介绍了TeleChat模型的最新系列：TeleChat2、TeleChat2.5和T1。这些新模型通过改进的预训练和后训练策略，显著提升了性能，尤其在复杂推理、代码生成和数学推理方面表现出色，并公开了不同参数版本。


<details>
  <summary>Details</summary>
Motivation: 为了显著提升TeleChat模型的性能，尤其是在推理、代码和数学任务上的能力，超越其前身，并提供更先进的开源语言模型。

Method: 模型架构变化极小，主要通过以下策略实现性能提升：1. TeleChat2：在10万亿高质量多样化tokens上进行预训练，随后进行监督微调（SFT）和直接偏好优化（DPO）。2. TeleChat2.5和T1：在TeleChat2基础上，加入领域特定数据集的持续预训练阶段，并结合强化学习（RL）以提升代码生成和数学推理性能。T1专注于复杂推理（支持长CoT），TeleChat2.5优先考虑推理速度。旗舰模型T1和TeleChat2.5均为115B参数的密集Transformer架构。

Result: 新系列模型实现了显著的性能提升。T1在数学和编码等复杂推理任务中表现出实质性进步，T1-115B甚至超越了OpenAI的o1-mini和GPT-4o等专有模型。TeleChat2.5则优先提供快速推理。所有新模型在推理和通用任务性能上均显著优于原始TeleChat。项目公开了TeleChat2、TeleChat2.5和T1，包括35B和115B参数的后训练版本。

Conclusion: TeleChat2、TeleChat2.5和T1系列模型通过优化的训练策略，在几乎不改变架构的情况下，取得了显著的性能飞跃，特别是在复杂推理、代码和数学方面表现卓越，甚至超越了某些领先的专有模型。这些模型的公开发布将赋能开发者和研究人员，为多样化应用提供最先进的语言模型。

Abstract: We introduce the latest series of TeleChat models: \textbf{TeleChat2},
\textbf{TeleChat2.5}, and \textbf{T1}, offering a significant upgrade over
their predecessor, TeleChat. Despite minimal changes to the model architecture,
the new series achieves substantial performance gains through enhanced training
strategies in both pre-training and post-training stages. The series begins
with \textbf{TeleChat2}, which undergoes pretraining on 10 trillion
high-quality and diverse tokens. This is followed by Supervised Fine-Tuning
(SFT) and Direct Preference Optimization (DPO) to further enhance its
capabilities. \textbf{TeleChat2.5} and \textbf{T1} expand the pipeline by
incorporating a continual pretraining phase with domain-specific datasets,
combined with reinforcement learning (RL) to improve performance in code
generation and mathematical reasoning tasks. The \textbf{T1} variant is
designed for complex reasoning, supporting long Chain-of-Thought (CoT)
reasoning and demonstrating substantial improvements in mathematics and coding.
In contrast, \textbf{TeleChat2.5} prioritizes speed, delivering rapid
inference. Both flagship models of \textbf{T1} and \textbf{TeleChat2.5} are
dense Transformer-based architectures with 115B parameters, showcasing
significant advancements in reasoning and general task performance compared to
the original TeleChat. Notably, \textbf{T1-115B} outperform proprietary models
such as OpenAI's o1-mini and GPT-4o. We publicly release \textbf{TeleChat2},
\textbf{TeleChat2.5} and \textbf{T1}, including post-trained versions with 35B
and 115B parameters, to empower developers and researchers with
state-of-the-art language models tailored for diverse applications.

</details>


### [120] [NeuralDB: Scaling Knowledge Editing in LLMs to 100,000 Facts with Neural KV Database](https://arxiv.org/abs/2507.18028)
*Weizhi Fei,Hao Shi,Jing Xu,Jingchen Peng,Jiazheng Li,Jingzhao Zhang,Bo Bai,Wei Han,Zhenyuan Chen,Xueyan Niu*

Main category: cs.CL

TL;DR: 本文提出NeuralDB，一个基于神经网络键值数据库的LLM知识编辑框架，它通过门控检索模块在编辑大量事实（高达10万个）的同时，有效保持了模型的通用能力。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型（LLMs）的知识编辑允许在不进行大规模训练的情况下更新模型。然而，现有的Locate-and-Edit (L&E) 方法在处理大量事实时，可能会损害LLMs的通用能力，甚至导致已编辑事实的遗忘。

Method: 将现有线性L&E方法建模为对键值(KV)数据库的查询。在此基础上，提出NeuralDB框架，将编辑后的事实明确表示为一个配备非线性门控检索模块的神经网络KV数据库。该门控模块仅在推理涉及已编辑事实时才激活，从而有效保留了LLMs的通用能力。

Result: 在GPT2-XL、GPT-J和Llama-3模型上，使用ZsRE和CounterFacts数据集对10,000个事实进行编辑的实验表明，NeuralDB在编辑效率、泛化性、特异性、流畅性和一致性方面表现出色，并能保持在六个代表性文本理解和生成任务上的整体性能。进一步实验表明，NeuralDB在扩展到100,000个事实（比现有工作多50倍）时仍能保持其有效性。

Conclusion: NeuralDB是一个高效且可扩展的LLM知识编辑框架，它通过创新的神经网络键值数据库和门控检索机制，成功解决了现有方法在保持模型通用能力和处理大规模编辑方面的挑战。

Abstract: Efficiently editing knowledge stored in large language models (LLMs) enables
model updates without large-scale training. One possible solution is
Locate-and-Edit (L\&E), allowing simultaneous modifications of a massive number
of facts. However, such editing may compromise the general abilities of LLMs
and even result in forgetting edited facts when scaling up to thousands of
edits. In this paper, we model existing linear L\&E methods as querying a
Key-Value (KV) database. From this perspective, we then propose NeuralDB, an
editing framework that explicitly represents the edited facts as a neural KV
database equipped with a non-linear gated retrieval module, % In particular,
our gated module only operates when inference involves the edited facts,
effectively preserving the general abilities of LLMs. Comprehensive experiments
involving the editing of 10,000 facts were conducted on the ZsRE and
CounterFacts datasets, using GPT2-XL, GPT-J (6B) and Llama-3 (8B). The results
demonstrate that NeuralDB not only excels in editing efficacy, generalization,
specificity, fluency, and consistency, but also preserves overall performance
across six representative text understanding and generation tasks. Further
experiments indicate that NeuralDB maintains its effectiveness even when scaled
to 100,000 facts (\textbf{50x} more than in prior work).

</details>


### [121] [GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs](https://arxiv.org/abs/2507.18043)
*Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CL

TL;DR: GrAInS是一种新的推理时干预方法，通过基于梯度的归因识别关键词元，并构建方向性干预向量来调整LLMs和VLMs的内部激活，从而实现对模型行为的精细控制，且无需微调。


<details>
  <summary>Details</summary>
Motivation: 现有推理时干预方法存在局限性：依赖固定全局干预向量、忽视个体输入词元的因果影响、未利用模型logits中的信息梯度，尤其在多模态设置中未能有效处理视觉和文本输入的不平衡贡献。

Method: GrAInS使用对比性的、基于梯度的归因（通过Integrated Gradients）来识别对期望和非期望输出贡献最大的前k个词元。这些词元用于构建从不良行为到期望行为的语义转变方向性干预向量。在推理过程中，GrAInS根据词元级别的归因信号调整Transformer层的隐藏激活，并对激活进行归一化以保持表示尺度。

Result: GrAInS在多个任务上持续优于微调和现有干预基线：在TruthfulQA上使用Llama-3.1-8B实现了13.22%的准确率提升；使用LLaVA-1.6-7B在MMHal-Bench上将幻觉率从0.624降至0.514；在SPA-VL上将对齐胜率提高了8.11%，同时保持了模型的流畅性和通用能力。

Conclusion: GrAInS提供了一种无需再训练或辅助监督的、对模型行为进行精细、可解释和模块化控制的方法，并在语言和视觉-语言模型任务中均表现出优异的性能。

Abstract: Inference-time steering methods offer a lightweight alternative to
fine-tuning large language models (LLMs) and vision-language models (VLMs) by
modifying internal activations at test time without updating model weights.
However, most existing approaches rely on fixed, global intervention vectors,
overlook the causal influence of individual input tokens, and fail to leverage
informative gradients from the model's logits, particularly in multimodal
settings where visual and textual inputs contribute unevenly. To address these
limitations, we introduce GrAInS, an inference-time steering approach that
operates across both language-only and vision-language models and tasks. GrAInS
uses contrastive, gradient-based attribution via Integrated Gradients to
identify the top-k most influential tokens, both positively and negatively
attributed based on their contribution to preferred versus dispreferred
outputs. These tokens are then used to construct directional steering vectors
that capture semantic shifts from undesirable to desirable behavior. During
inference, GrAInS adjusts hidden activations at transformer layers guided by
token-level attribution signals, and normalizes activations to preserve
representational scale. This enables fine-grained, interpretable, and modular
control over model behavior, without retraining or auxiliary supervision.
Empirically, GrAInS consistently outperforms both fine-tuning and existing
steering baselines: it achieves a 13.22% accuracy gain on TruthfulQA using
Llama-3.1-8B, reduces hallucination rates on MMHal-Bench from 0.624 to 0.514
with LLaVA-1.6-7B, and improves alignment win rates on SPA-VL by 8.11%, all
while preserving the model's fluency and general capabilities.

</details>


### [122] [Synthetic Data Generation for Phrase Break Prediction with Large Language Model](https://arxiv.org/abs/2507.18044)
*Hoyeon Lee,Sejung Son,Ye-Eun Kang,Jong-Hwan Kim*

Main category: cs.CL

TL;DR: 本文探讨了利用大型语言模型（LLM）生成合成韵律短语边界标注数据，以减少人工标注成本和应对语音领域数据变异性挑战，并证明其在多语言短语边界预测中的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前的短语边界预测方法严重依赖大量人工标注数据，耗时且成本高昂。此外，语音领域固有的变异性使得获取高质量、一致的数据更加困难。鉴于大型语言模型在自然语言处理中生成定制合成数据以减少人工标注的成功经验，研究者受此启发。

Method: 研究方法是利用大型语言模型（LLM）生成合成的短语边界标注。通过与传统标注进行比较，并在多种语言中评估其有效性，来验证这种方法的潜力。

Result: 研究结果表明，基于LLM的合成数据生成能有效缓解短语边界预测中的数据挑战。

Conclusion: 该研究强调了大型语言模型作为解决语音领域数据挑战的潜在可行方案。

Abstract: Current approaches to phrase break prediction address crucial prosodic
aspects of text-to-speech systems but heavily rely on vast human annotations
from audio or text, incurring significant manual effort and cost. Inherent
variability in the speech domain, driven by phonetic factors, further
complicates acquiring consistent, high-quality data. Recently, large language
models (LLMs) have shown success in addressing data challenges in NLP by
generating tailored synthetic data while reducing manual annotation needs.
Motivated by this, we explore leveraging LLM to generate synthetic phrase break
annotations, addressing the challenges of both manual annotation and
speech-related tasks by comparing with traditional annotations and assessing
effectiveness across multiple languages. Our findings suggest that LLM-based
synthetic data generation effectively mitigates data challenges in phrase break
prediction and highlights the potential of LLMs as a viable solution for the
speech domain.

</details>


### [123] [Privacy-Preserving Synthetic Review Generation with Diverse Writing Styles Using LLMs](https://arxiv.org/abs/2507.18055)
*Tevin Atwal,Chan Nam Tieu,Yefeng Yuan,Zhan Shi,Yuhong Liu,Liang Cheng*

Main category: cs.CL

TL;DR: 该研究评估了LLM生成的合成文本数据的多样性和隐私风险，发现LLM在此方面存在显著局限性，并提出了基于提示的方法来改善多样性并保护隐私。


<details>
  <summary>Details</summary>
Motivation: LLM生成的合成数据在数据驱动应用中带来机遇，但其多样性和隐私风险尚未得到充分探索。真实数据成本高昂且难以扩展，合成数据提供了替代方案，因此需要对其质量进行深入评估。

Method: 提出了一套全面的度量标准，用于定量评估合成文本数据的多样性（语言表达、情感、用户视角）和隐私（再识别风险、风格异常值）。利用这些指标评估了多个最先进LLM生成的合成数据集。基于评估结果，提出了一种基于提示的方法来增强合成评论的多样性，同时保护用户隐私。

Result: 实验结果揭示了LLM在生成多样化和隐私保护的合成数据方面的显著局限性。

Conclusion: LLM在生成高质量（多样且隐私保护）的合成数据方面存在不足。研究提出了一个基于提示的方法，可以有效提升合成数据的多样性并兼顾隐私保护。

Abstract: The increasing use of synthetic data generated by Large Language Models
(LLMs) presents both opportunities and challenges in data-driven applications.
While synthetic data provides a cost-effective, scalable alternative to
real-world data to facilitate model training, its diversity and privacy risks
remain underexplored. Focusing on text-based synthetic data, we propose a
comprehensive set of metrics to quantitatively assess the diversity (i.e.,
linguistic expression, sentiment, and user perspective), and privacy (i.e.,
re-identification risk and stylistic outliers) of synthetic datasets generated
by several state-of-the-art LLMs. Experiment results reveal significant
limitations in LLMs' capabilities in generating diverse and privacy-preserving
synthetic data. Guided by the evaluation results, a prompt-based approach is
proposed to enhance the diversity of synthetic reviews while preserving
reviewer privacy.

</details>


### [124] [TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios](https://arxiv.org/abs/2507.18061)
*Zehan Li,Hongjie Chen,Yuxin Zhang,Jing Zhou,Xuening Wang,Hang Lv,Mengjie Du,Yaodong Song,Jie Lian,Jian Kang,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

TL;DR: 本文提出了TELEVAL，一个动态基准测试，用于评估口语语言模型（SLMs）在真实中文交互场景中作为对话代理的有效性，并发现现有SLMs仍有很大提升空间。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数SLM评估基准主要关注模型能否执行复杂任务，与大型语言模型（LLMs）的能力对标，但未能与用户在真实对话场景中的自然交互方式对齐。

Method: TELEVAL是一个动态基准测试，定义了三个评估维度：显式语义、副语言和隐式语义、系统能力。它采用与真实世界使用一致的对话格式，并分别评估文本和音频输出，特别关注模型从用户语音中提取隐式线索并适当响应的能力。

Result: 实验表明，尽管近期SLMs取得了进展，但在自然对话任务中，现有模型仍有相当大的改进空间。

Conclusion: TELEVAL可以作为一个以用户为中心的评估框架，直接反映用户体验，并有助于开发出更强大的面向对话的SLMs。

Abstract: Spoken language models (SLMs) have seen rapid progress in recent years, along
with the development of numerous benchmarks for evaluating their performance.
However, most existing benchmarks primarily focus on evaluating whether SLMs
can perform complex tasks comparable to those tackled by large language models
(LLMs), often failing to align with how users naturally interact in real-world
conversational scenarios. In this paper, we propose TELEVAL, a dynamic
benchmark specifically designed to evaluate SLMs' effectiveness as
conversational agents in realistic Chinese interactive settings. TELEVAL
defines three evaluation dimensions: Explicit Semantics, Paralinguistic and
Implicit Semantics, and System Abilities. It adopts a dialogue format
consistent with real-world usage and evaluates text and audio outputs
separately. TELEVAL particularly focuses on the model's ability to extract
implicit cues from user speech and respond appropriately without additional
instructions. Our experiments demonstrate that despite recent progress,
existing SLMs still have considerable room for improvement in natural
conversational tasks. We hope that TELEVAL can serve as a user-centered
evaluation framework that directly reflects the user experience and contributes
to the development of more capable dialogue-oriented SLMs.

</details>


### [125] [Hybrid and Unitary Fine-Tuning of Large Language Models: Methods and Benchmarking under Resource Constraints](https://arxiv.org/abs/2507.18076)
*Haomin Qi,Zihan Dai,Chengbo Huang*

Main category: cs.CL

TL;DR: 本文评估了多种参数高效微调（PEFT）技术，并提出了一种结合BOFT和LoRA-GA优点的新型混合策略，该策略通过梯度范数引导的自适应更新和引入uRNN原理，显著提升了LLM微调的效率和性能，同时大幅降低了资源消耗。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）的规模和内存需求，对其进行微调仍然是一个计算瓶颈。

Method: 本文全面评估了包括LoRA、BOFT、LoRA-GA和uRNN在内的PEFT技术。在此基础上，引入了一种新型混合策略，该策略动态融合了BOFT的正交稳定性和LoRA-GA的梯度对齐快速收敛特性。通过梯度范数计算每层自适应更新，并首次探索将酉RNN（uRNN）原理应用于Transformer-based LLMs，以增强梯度稳定性。

Result: 该混合方法在GLUE、GSM8K、MT-Bench和HumanEval四个基准测试上，使用7B至405B参数的模型进行实证评估，结果表明其在不同任务上实现了卓越的收敛效率和泛化能力。它持续优于单独的PEFT基线，接近全量微调的准确性，同时将训练时间减少高达2.1倍，内存使用减少50%。

Conclusion: 研究结果确立了所提出的混合方法作为在资源受限下实际部署LLM的一种实用且可扩展的微调解决方案。

Abstract: Fine-tuning large language models (LLMs) remains a computational bottleneck
due to their scale and memory demands. This paper presents a comprehensive
evaluation of parameter-efficient fine-tuning (PEFT) techniques, including
LoRA, BOFT, LoRA-GA, and uRNN, and introduces a novel hybrid strategy that
dynamically integrates BOFT's orthogonal stability with LoRA-GA's
gradient-aligned rapid convergence. By computing per-layer adaptive updates
guided by gradient norms, the hybrid method achieves superior convergence
efficiency and generalization across diverse tasks. We also explore, for the
first time, the adaptation of unitary RNN (uRNN) principles to
transformer-based LLMs, enhancing gradient stability through structured unitary
constraints. Empirical evaluations on four benchmarks -- GLUE, GSM8K, MT-Bench,
and HumanEval -- using models ranging from 7B to 405B parameters demonstrate
that our hybrid method consistently outperforms individual PEFT baselines,
approaching full fine-tuning accuracy while reducing resource consumption by up
to 2.1 times in training time and 50 percent in memory usage. These findings
establish the hybrid approach as a practical and scalable fine-tuning solution
for real-world deployment of LLMs under resource constraints.

</details>


### [126] [A New Pair of GloVes](https://arxiv.org/abs/2507.18103)
*Riley Carlson,John Bauer,Christopher D. Manning*

Main category: cs.CL

TL;DR: 该报告介绍了2024年更新的GloVe词向量模型，这些模型通过使用新数据进行训练并详细记录，在捕获新词汇和提高最新命名实体识别（NER）任务性能方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 2014年的原始GloVe模型已广泛使用但已过时，语言和世界持续演变，现有模型未能充分反映当前语言使用。此外，原始模型缺乏详细的数据和预处理文档。

Method: 使用Wikipedia、Gigaword和Dolma数据集的子集训练了两组新的词向量。评估通过词汇比较、直接测试（如类比和相似性）以及命名实体识别（NER）任务进行。

Result: 2024年GloVe向量纳入了新的文化和语言相关词汇，在类比和相似性等结构性任务上表现相当，并在最近、时间依赖的NER数据集（如非西方新闻数据）上表现出改进的性能。

Conclusion: 更新的2024年GloVe模型通过吸收新的语言和文化信息，并在关键NLP任务上展示出有竞争力的或改进的性能，证明了其价值，同时解决了原始模型文档不足的问题。

Abstract: This report documents, describes, and evaluates new 2024 English GloVe
(Global Vectors for Word Representation) models. While the original GloVe
models built in 2014 have been widely used and found useful, languages and the
world continue to evolve and we thought that current usage could benefit from
updated models. Moreover, the 2014 models were not carefully documented as to
the exact data versions and preprocessing that were used, and we rectify this
by documenting these new models. We trained two sets of word embeddings using
Wikipedia, Gigaword, and a subset of Dolma. Evaluation through vocabulary
comparison, direct testing, and NER tasks shows that the 2024 vectors
incorporate new culturally and linguistically relevant words, perform
comparably on structural tasks like analogy and similarity, and demonstrate
improved performance on recent, temporally dependent NER datasets such as
non-Western newswire data.

</details>


### [127] [GOAT-SLM: A Spoken Language Model with Paralinguistic and Speaker Characteristic Awareness](https://arxiv.org/abs/2507.18119)
*Hongjie Chen,Zehan Li,Yaodong Song,Wenming Deng,Yitong Yao,Yuxin Zhang,Hang Lv,Xuechao Zhu,Jian Kang,Jie Lian,Jie Li,Chao Wang,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: 本文提出了GOAT-SLM，一个具有副语言和说话者特征感知的语音语言模型，旨在超越文本语义，实现更自然、自适应的语音交互。


<details>
  <summary>Details</summary>
Motivation: 现有语音语言模型（SLMs）主要关注语言内容，忽视了人类语音中丰富的副语言和说话者特征线索（如方言、年龄、情感和非言语发声），导致AI系统在自然语音交互中表现不足。

Method: GOAT-SLM采用双模态头部架构，将语言建模与声学实现解耦，以实现鲁棒的语言理解和富有表现力的自适应语音生成。此外，它提出了一种模块化、分阶段的训练策略，利用大规模语音-文本语料库逐步对齐语言、副语言和说话者特征信息。

Result: 在多维度评估基准TELEVAL上的实验结果表明，GOAT-SLM在语义和非语义任务上均取得了良好平衡的性能，并在处理情感、方言变异和年龄敏感交互方面优于现有开源模型。

Conclusion: 这项工作强调了超越语言内容进行建模的重要性，并推动了更自然、自适应和具有社会意识的语音语言系统的发展。

Abstract: Recent advances in end-to-end spoken language models (SLMs) have
significantly improved the ability of AI systems to engage in natural spoken
interactions. However, most existing models treat speech merely as a vehicle
for linguistic content, often overlooking the rich paralinguistic and speaker
characteristic cues embedded in human speech, such as dialect, age, emotion,
and non-speech vocalizations. In this work, we introduce GOAT-SLM, a novel
spoken language model with paralinguistic and speaker characteristic awareness,
designed to extend spoken language modeling beyond text semantics. GOAT-SLM
adopts a dual-modality head architecture that decouples linguistic modeling
from acoustic realization, enabling robust language understanding while
supporting expressive and adaptive speech generation. To enhance model
efficiency and versatility, we propose a modular, staged training strategy that
progressively aligns linguistic, paralinguistic, and speaker characteristic
information using large-scale speech-text corpora. Experimental results on
TELEVAL, a multi-dimensional evaluation benchmark, demonstrate that GOAT-SLM
achieves well-balanced performance across both semantic and non-semantic tasks,
and outperforms existing open-source models in handling emotion, dialectal
variation, and age-sensitive interactions. This work highlights the importance
of modeling beyond linguistic content and advances the development of more
natural, adaptive, and socially aware spoken language systems.

</details>


### [128] [MathOPEval: A Fine-grained Evaluation Benchmark for Visual Operations of MLLMs in Mathematical Reasoning](https://arxiv.org/abs/2507.18140)
*Xiaoyuan Li,Moxin Li,Wenjie Wang,Rui Men,Yichang Zhang,Fuli Feng,Dayiheng Liu,Junyang Lin*

Main category: cs.CL

TL;DR: 该研究首次评估了多模态大语言模型（MLLMs）在多模态数学推理中基于代码执行视觉操作的能力，发现现有模型在精细视觉操作方面远低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 现有对MLLMs的评估主要集中于纯文本推理输出，忽视了模型通过代码精确执行视觉操作的能力，这部分能力尚待充分探索。

Method: 该研究提出了一个评估框架，聚焦于两个关键方面：1) 多模态代码生成（MCG），评估模型从零开始理解和构建可视化的能力；2) 多模态代码编辑（MCE），评估模型进行精细操作（包括删除、修改和标注）的能力。为此，研究整合了一个涵盖五种流行数学图形（几何图、函数图和三种统计图表）的数据集，并对九个主流MLLMs进行了实验评估。

Result: 实验结果表明，现有MLLMs在执行精细视觉操作方面，与人类表现相比仍存在显著差距。

Conclusion: 当前的多模态大语言模型在通过代码进行精确和精细的视觉操作方面仍有很大的提升空间，远未达到人类水平。

Abstract: Recent progress in Multi-modal Large Language Models (MLLMs) has enabled
step-by-step multi-modal mathematical reasoning by performing visual operations
based on the textual instructions. A promising approach uses code as an
intermediate representation to precisely express and manipulate the images in
the reasoning steps. However, existing evaluations focus mainly on text-only
reasoning outputs, leaving the MLLM's ability to perform accurate visual
operations via code largely unexplored. This work takes a first step toward
addressing that gap by evaluating MLLM's code-based capabilities in multi-modal
mathematical reasoning.Specifically, our framework focuses on two key
evaluation aspects: (1) Multi-modal Code Generation (MCG) evaluates the model's
ability to accurately understand and construct visualizations from scratch. (2)
Multi-modal Code Editing (MCE) assesses the model's capacity for fine-grained
operations, which include three types: Deletion, Modification and Annotation.
To evaluate the above tasks, we incorporate a dataset that covers the five most
popular types of mathematical figures, including geometric diagrams, function
plots, and three types of statistical charts, to provide a comprehensive and
effective measurement of existing MLLMs. Our experimental evaluation involves
nine mainstream MLLMs, and the results reveal that existing models still lag
significantly behind human performance in performing fine-grained visual
operations.

</details>


### [129] [HIVMedQA: Benchmarking large language models for HIV medical decision support](https://arxiv.org/abs/2507.18143)
*Gonzalo Cardenal Antolin,Jacques Fellay,Bashkim Jaha,Roger Kouyos,Niko Beerenwinkel,Diane Duroux*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）在艾滋病管理中的能力，引入了HIVMedQA基准数据集，发现Gemini 2.5 Pro表现最佳，但模型性能随问题复杂性下降，且存在偏见，强调了安全有效整合LLM的必要性。


<details>
  <summary>Details</summary>
Motivation: LLMs在临床决策中具有潜力，尤其在复杂的艾滋病管理中。然而，将LLMs整合到临床实践中存在准确性、潜在危害和医护人员接受度方面的担忧。目前，AI在艾滋病护理中的应用尚待探索，且缺乏LLM基准研究。

Method: 研究引入了HIVMedQA，一个针对艾滋病护理开放式医学问答的基准数据集，由传染病医生协助策划。评估了7个通用型和3个医学专业型LLMs，并应用了提示工程。评估框架结合了词汇相似性和“LLM作为评判者”的方法，以更好地反映临床相关性。评估维度包括问题理解、推理、知识召回、偏见、潜在危害和事实准确性。

Result: Gemini 2.5 Pro在大多数维度上持续优于其他模型，排名前三的模型中有两个是专有模型。模型性能随问题复杂性增加而下降。医学微调模型并非总优于通用模型，模型大小也不是性能的可靠预测指标。推理和理解比事实召回更具挑战性，并观察到近因效应和现状偏见等认知偏见。

Conclusion: 这些发现强调了需要有针对性的开发和评估，以确保LLMs在临床护理中的安全有效整合。

Abstract: Large language models (LLMs) are emerging as valuable tools to support
clinicians in routine decision-making. HIV management is a compelling use case
due to its complexity, including diverse treatment options, comorbidities, and
adherence challenges. However, integrating LLMs into clinical practice raises
concerns about accuracy, potential harm, and clinician acceptance. Despite
their promise, AI applications in HIV care remain underexplored, and LLM
benchmarking studies are scarce. This study evaluates the current capabilities
of LLMs in HIV management, highlighting their strengths and limitations. We
introduce HIVMedQA, a benchmark designed to assess open-ended medical question
answering in HIV care. The dataset consists of curated, clinically relevant
questions developed with input from an infectious disease physician. We
evaluated seven general-purpose and three medically specialized LLMs, applying
prompt engineering to enhance performance. Our evaluation framework
incorporates both lexical similarity and an LLM-as-a-judge approach, extended
to better reflect clinical relevance. We assessed performance across key
dimensions: question comprehension, reasoning, knowledge recall, bias,
potential harm, and factual accuracy. Results show that Gemini 2.5 Pro
consistently outperformed other models across most dimensions. Notably, two of
the top three models were proprietary. Performance declined as question
complexity increased. Medically fine-tuned models did not always outperform
general-purpose ones, and larger model size was not a reliable predictor of
performance. Reasoning and comprehension were more challenging than factual
recall, and cognitive biases such as recency and status quo were observed.
These findings underscore the need for targeted development and evaluation to
ensure safe, effective LLM integration in clinical care.

</details>


### [130] [Sticking to the Mean: Detecting Sticky Tokens in Text Embedding Models](https://arxiv.org/abs/2507.18171)
*Kexin Chen,Dongxia Wang,Yi Liu,Haonan Zhang,Wenhai Wang*

Main category: cs.CL

TL;DR: 研究发现Transformer文本嵌入模型中存在“粘性词元”，它们会扭曲嵌入距离分布并降低下游任务性能。论文定义了这些词元，提出了一种高效检测方法STD，发现大量粘性词元，分析了其来源和对性能的显著影响，并呼吁改进分词策略和模型设计。


<details>
  <summary>Details</summary>
Motivation: Transformer文本嵌入模型在NLP任务中广泛使用，但“粘性词元”的存在会损害嵌入的可靠性，扭曲句向量相似度，并降低下游任务性能，因此需要系统性地调查和解决这一问题。

Method: 论文正式定义了“粘性词元”，提出了一种基于句子和词元过滤的“粘性词元检测器”（STD）高效检测方法。将STD应用于14个模型家族的40个检查点，并对粘性词元进行注意力层分析，评估其对聚类和检索等下游任务的影响。

Result: 共发现了868个粘性词元，它们通常来源于词汇表中特殊或未使用的条目以及多语言语料库中的碎片化子词。粘性词元的存在与模型大小或词汇表大小无严格关联。它们导致下游任务性能显著下降，降幅高达50%。注意力层分析显示，粘性词元不成比例地主导了模型的内部表示。

Conclusion: 研究结果揭示了粘性词元对文本嵌入模型鲁棒性的担忧，强调了未来文本嵌入应用中需要更好的分词策略和模型设计来缓解粘性词元的影响。

Abstract: Despite the widespread use of Transformer-based text embedding models in NLP
tasks, surprising 'sticky tokens' can undermine the reliability of embeddings.
These tokens, when repeatedly inserted into sentences, pull sentence similarity
toward a certain value, disrupting the normal distribution of embedding
distances and degrading downstream performance. In this paper, we
systematically investigate such anomalous tokens, formally defining them and
introducing an efficient detection method, Sticky Token Detector (STD), based
on sentence and token filtering. Applying STD to 40 checkpoints across 14 model
families, we discover a total of 868 sticky tokens. Our analysis reveals that
these tokens often originate from special or unused entries in the vocabulary,
as well as fragmented subwords from multilingual corpora. Notably, their
presence does not strictly correlate with model size or vocabulary size. We
further evaluate how sticky tokens affect downstream tasks like clustering and
retrieval, observing significant performance drops of up to 50%. Through
attention-layer analysis, we show that sticky tokens disproportionately
dominate the model's internal representations, raising concerns about
tokenization robustness. Our findings show the need for better tokenization
strategies and model design to mitigate the impact of sticky tokens in future
text embedding applications.

</details>


### [131] [SCOPE: Stochastic and Counterbiased Option Placement for Evaluating Large Language Models](https://arxiv.org/abs/2507.18182)
*Wonjun Jeong,Dongseok Kim,Taegkeun Whangbo*

Main category: cs.CL

TL;DR: 该研究引入SCOPE框架，通过估计并抵消大型语言模型在多项选择题中利用选项位置或标签偏差的问题，从而提高评估的公平性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多项选择任务中可能因利用选项位置或标签的固有偏差而获得虚高分数，而非真正理解，这促使研究者开发一种测量和缓解此类选择偏差的方法。

Method: SCOPE框架通过重复调用无语义内容的空提示来估计每个模型的独特位置偏差分布。然后，它根据逆偏差分布重新分配答案槽，以平衡随机选择正确答案的概率。此外，它还阻止语义相似的干扰项被放置在答案附近，从而避免基于表面接近度的侥幸猜测。

Result: 在多项基准实验中，SCOPE框架在稳定的性能提升方面始终优于现有去偏方法，并显示出对正确选项更清晰的置信度分布。

Conclusion: SCOPE框架为增强大型语言模型评估的公平性和可靠性提供了一个新标准。

Abstract: Large Language Models (LLMs) can achieve inflated scores on multiple-choice
tasks by exploiting inherent biases in option positions or labels, rather than
demonstrating genuine understanding. This study introduces SCOPE, an evaluation
framework designed to measure and mitigate such selection bias in a
dataset-independent manner. By repeatedly invoking a null prompt that lacks
semantic content, SCOPE estimates each model's unique position-bias
distribution. It then redistributes the answer slot according to the
inverse-bias distribution, thereby equalizing the lucky-rate, the probability
of selecting the correct answer by chance. Furthermore, it prevents
semantically similar distractors from being placed adjacent to the answer,
thereby blocking near-miss guesses based on superficial proximity cues. Across
multiple benchmark experiments, SCOPE consistently outperformed existing
debiasing methods in terms of stable performance improvements and showed
clearer confidence distributions over correct options. This framework thus
offers a new standard for enhancing the fairness and reliability of LLM
evaluations.

</details>


### [132] [TN-AutoRCA: Benchmark Construction and Agentic Framework for Self-Improving Alarm-Based Root Cause Analysis in Telecommunication Networks](https://arxiv.org/abs/2507.18190)
*Keyu Wu,Qianjin Yu,Manlin Mei,Ruiting Liu,Jun Wang,Kailai Zhang,Yelun Bao*

Main category: cs.CL

TL;DR: 电信网络中的根因分析（RCA）对人工智能（AI）来说是一个巨大挑战，因为它需要复杂的图基推理，并且缺乏真实的基准。


<details>
  <summary>Details</summary>
Motivation: 电信网络中的根因分析是一项关键任务，但其复杂的图基推理需求和真实基准的稀缺性使其成为AI难以应对的挑战。

Method: 抽象中未提及具体方法。

Result: 抽象中未提及具体结果。

Conclusion: 抽象中未提及具体结论。

Abstract: Root Cause Analysis (RCA) in telecommunication networks is a critical task,
yet it presents a formidable challenge for Artificial Intelligence (AI) due to
its complex, graph-based reasoning requirements and the scarcity of realistic
benchmarks.

</details>


### [133] [Integrating an ISO30401-compliant Knowledge management system with existing business processes of an organization](https://arxiv.org/abs/2507.18197)
*Aline Belloni,Patrick Prieur*

Main category: cs.CL

TL;DR: 本文探讨了如何将ISO 30401知识管理系统（KMS）与ISO 9001业务流程整合，特别是通过SECI模型和PDCA循环实现。


<details>
  <summary>Details</summary>
Motivation: 组织广泛使用业务流程建模（如ISO 9001）来提高效率。ISO 30401于2018年引入了知识管理系统要求。作者作为ISO 30401实施者，经常面临如何向客户解释ISO 30401中的知识活动如何与现有操作流程整合的挑战。

Method: 回顾了ISO 9001背景下的流程建模原则。基于作者的经验，探讨了ISO 30401兼容的知识管理系统如何与集成管理系统的所有其他流程交织，并具体阐述了如何通过PDCA循环的步骤部署SECI模型的机制来实现整合。

Result: 文章通过经验探索，展示了ISO 30401兼容的知识管理系统如何与现有业务流程（特别是ISO 9001流程）有效整合，并提出通过SECI模型机制在PDCA循环中实施的方法。

Conclusion: 结论是ISO 30401知识管理系统可以成功地与集成管理系统中的其他流程（尤其是ISO 9001流程）整合，并且可以通过在PDCA循环中应用SECI模型来有效地实现这一整合。

Abstract: Business process modeling is used by most organizations as an essential
framework for ensuring efficiency and effectiveness of the work and workflow
performed by its employees and for ensuring the alignment of such work with its
strategic goals. For organizations that are compliant or near-compliant with
ISO 9001, this approach involves the detailed mapping of processes,
sub-processes, activities, and tasks. ISO30401 is a Management System Standard,
introduced in 2018, establishing universal requirements for the set up of a
Knowledge Management System in an organization. As ``ISO30401 implementers'' we
regularly face the challenge of explaining our clients how the knowledge
development, transformation and conveyances activities depicted in ISO30401 do
integrate with existing operational processes. This article recaps process
modelling principles in the context of ISO9001 and explores, based on our
experience, how an ISO30401-compliant Knowledge Management System (KMS)
entwines with all other processes of an Integrated Management System and in
particular how it can be implemented by deploying the mechanisms of the SECI
model through the steps of PDCA cycles.

</details>


### [134] [Safeguarding RAG Pipelines with GMTP: A Gradient-based Masked Token Probability Method for Poisoned Document Detection](https://arxiv.org/abs/2507.18202)
*San Kim,Jonghwi Kim,Yejin Jeon,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: 本文提出GMTP，一种基于梯度和MLM的新型防御方法，用于检测并过滤RAG系统中的恶意投毒文档，有效消除超过90%的投毒内容。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）虽然能提升大型语言模型（LLM）的响应准确性和时效性，但其对外部知识源的依赖也引入了安全风险，攻击者可能通过注入投毒文档来引导模型产生有害或误导性输出。

Method: 本文提出了梯度掩码词元概率（GMTP）方法。具体而言，GMTP通过检查检索器相似性函数的梯度来识别高影响力的词元。随后，这些关键词元被遮蔽，并通过掩码语言模型（MLM）检查其概率。由于被注入的恶意词元通常表现出极低的掩码词元概率，这使得GMTP能够有效检测恶意文档并实现高精度过滤。

Result: 实验证明，GMTP能够消除90%以上的投毒内容，同时保留了相关文档，从而在多样化的数据集和对抗设置下，保持了鲁棒的检索和生成性能。

Conclusion: GMTP是一种有效的防御RAG投毒攻击的方法，能够显著提高系统的安全性，同时不影响其核心功能。

Abstract: Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by
providing external knowledge for accurate and up-to-date responses. However,
this reliance on external sources exposes a security risk, attackers can inject
poisoned documents into the knowledge base to steer the generation process
toward harmful or misleading outputs. In this paper, we propose Gradient-based
Masked Token Probability (GMTP), a novel defense method to detect and filter
out adversarially crafted documents. Specifically, GMTP identifies high-impact
tokens by examining gradients of the retriever's similarity function. These key
tokens are then masked, and their probabilities are checked via a Masked
Language Model (MLM). Since injected tokens typically exhibit markedly low
masked-token probabilities, this enables GMTP to easily detect malicious
documents and achieve high-precision filtering. Experiments demonstrate that
GMTP is able to eliminate over 90% of poisoned content while retaining relevant
documents, thus maintaining robust retrieval and generation performance across
diverse datasets and adversarial settings.

</details>


### [135] [Exploring the Impact of Instruction-Tuning on LLM's Susceptibility to Misinformation](https://arxiv.org/abs/2507.18203)
*Kyubeen Han,Junseo Jang,Hongjin Kim,Geunyeong Jeong,Harksoo Kim*

Main category: cs.CL

TL;DR: 本研究发现指令微调（instruction-tuning）会显著增加大型语言模型（LLMs）对用户提供虚假信息的接受度，并探索了影响这种易感性的其他因素。


<details>
  <summary>Details</summary>
Motivation: 指令微调提高了LLMs遵循指令的能力，但可能增加模型对用户输入的依赖，导致无过滤地接受虚假信息。现有研究虽关注LLMs对外部信息的接受度，但很少直接探讨指令微调对此现象的影响。

Method: 研究调查了指令微调对LLM虚假信息易感性的影响。通过与基础模型进行比较，分析了指令微调对模型接受用户提供虚假信息的影响。此外，还探讨了提示结构中用户角色、虚假信息长度以及系统提示中警告的存在等因素对虚假信息易感性的影响。

Result: 指令微调后的LLMs在用户提供虚假信息时，接受虚假信息的可能性显著增加。与基础模型相比，指令微调增强了LLMs对用户提供信息的依赖，使虚假信息易感性从助手角色转移到用户角色。

Conclusion: 研究结果强调了需要系统性方法来减轻指令微调带来的意外后果，并提高LLMs在实际应用中的可靠性。

Abstract: Instruction-tuning enhances the ability of large language models (LLMs) to
follow user instructions more accurately, improving usability while reducing
harmful outputs. However, this process may increase the model's dependence on
user input, potentially leading to the unfiltered acceptance of misinformation
and the generation of hallucinations. Existing studies primarily highlight that
LLMs are receptive to external information that contradict their parametric
knowledge, but little research has been conducted on the direct impact of
instruction-tuning on this phenomenon. In our study, we investigate the impact
of instruction-tuning on LLM's susceptibility to misinformation. Our analysis
reveals that instruction-tuned LLMs are significantly more likely to accept
misinformation when it is presented by the user. A comparison with base models
shows that instruction-tuning increases reliance on user-provided information,
shifting susceptibility from the assistant role to the user role. Furthermore,
we explore additional factors influencing misinformation susceptibility, such
as the role of the user in prompt structure, misinformation length, and the
presence of warnings in the system prompt. Our findings underscore the need for
systematic approaches to mitigate unintended consequences of instruction-tuning
and enhance the reliability of LLMs in real-world applications.

</details>


### [136] [Prune&Comp: Free Lunch for Layer-Pruned LLMs via Iterative Pruning with Magnitude Compensation](https://arxiv.org/abs/2507.18212)
*Xinrui Chen,Hongxing Zhang,Fanyi Zeng,Yongxian Wei,Yizhi Wang,Xitong Ling,Guanghao Li,Chun Yuan*

Main category: cs.CL

TL;DR: 该研究提出了一种名为 Prune&Comp 的新型层剪枝方案，通过无训练的幅度补偿来解决大型语言模型（LLMs）层剪枝导致的隐藏状态幅度差异问题，显著提升了剪枝性能。


<details>
  <summary>Details</summary>
Motivation: 层剪枝是压缩LLMs的一种有前景的技术，但移除层会导致隐藏状态产生显著的幅度差异，从而导致性能大幅下降。

Method: 提出 Prune&Comp 方案，通过离线重新缩放剩余权重，在零运行时开销下估计并消除层移除导致的幅度差异。该方案可即插即用，并结合迭代剪枝策略进一步提升效果。

Result: Prune&Comp 持续提升了现有层剪枝指标。例如，在剪枝 LLaMA-3-8B 的5层时，Prune&Comp 几乎将困惑度减半，并保留了原始模型93.19%的问答性能，比基线提高了4.01%。

Conclusion: Prune&Comp 是一种有效、无训练、即插即用的层剪枝方案，通过幅度补偿成功缓解了LLM层剪枝中的性能下降问题。

Abstract: Layer pruning has emerged as a promising technique for compressing large
language models (LLMs) while achieving acceleration proportional to the pruning
ratio. In this work, we identify that removing any layer induces a significant
magnitude gap in hidden states, resulting in substantial performance
degradation. To address this issue, we propose Prune&Comp, a novel
plug-and-play layer pruning scheme that leverages magnitude compensation to
mitigate such gaps in a training-free manner. Specifically, we first estimate
the magnitude gap caused by layer removal and then eliminate this gap by
rescaling the remaining weights offline, with zero runtime overhead incurred.
We further demonstrate the advantages of Prune&Comp through an iterative
pruning strategy. When integrated with an iterative prune-and-compensate loop,
Prune&Comp consistently enhances existing layer pruning metrics. For instance,
when 5 layers of LLaMA-3-8B are pruned using the prevalent block influence
metric, Prune&Comp nearly halves the perplexity and retains 93.19\% of the
original model's question-answering performance, outperforming the baseline by
4.01%.

</details>


### [137] [Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models](https://arxiv.org/abs/2507.18263)
*Suhang Wu,Jialong Tang,Chengyi Yang,Pei Zhang,Baosong Yang,Junhui Li,Junfeng Yao,Min Zhang,Jinsong Su*

Main category: cs.CL

TL;DR: 本文提出了一种名为“定位与聚焦”的新方法，用于直接语音翻译中的术语翻译，通过有效识别术语片段并关联多模态知识，提高了术语翻译的准确性。


<details>
  <summary>Details</summary>
Motivation: 直接语音翻译中术语的准确翻译是一个巨大挑战。现有方法在利用翻译知识时，常受无关噪声干扰，且未能充分利用这些知识。

Method: 提出“定位与聚焦”方法：1. 定位语音中包含术语的片段以构建翻译知识，减少无关信息。2. 将此翻译知识与语音和假设（音频和文本模态）关联起来，使语音翻译模型在翻译时能更好地聚焦于这些知识。

Result: 在多个数据集上的实验结果表明，该方法能有效定位语音中的术语，提高术语翻译的成功率，同时保持稳定的整体翻译性能。

Conclusion: 所提出的“定位与聚焦”方法能有效定位语音中的术语，并显著提升术语翻译的准确性，同时不损害整体翻译质量。

Abstract: Direct speech translation (ST) has garnered increasing attention nowadays,
yet the accurate translation of terminology within utterances remains a great
challenge. In this regard, current studies mainly concentrate on leveraging
various translation knowledge into ST models. However, these methods often
struggle with interference from irrelevant noise and can not fully utilize the
translation knowledge. To address these issues, in this paper, we propose a
novel Locate-and-Focus method for terminology translation. It first effectively
locates the speech clips containing terminologies within the utterance to
construct translation knowledge, minimizing irrelevant information for the ST
model. Subsequently, it associates the translation knowledge with the utterance
and hypothesis from both audio and textual modalities, allowing the ST model to
better focus on translation knowledge during translation. Experimental results
across various datasets demonstrate that our method effectively locates
terminologies within utterances and enhances the success rate of terminology
translation, while maintaining robust general translation performance.

</details>


### [138] [Zero-shot OCR Accuracy of Low-Resourced Languages: A Comparative Analysis on Sinhala and Tamil](https://arxiv.org/abs/2507.18264)
*Nevidu Jayatilleke,Nisansa de Silva*

Main category: cs.CL

TL;DR: 本研究比较了六种OCR引擎在低资源语言（斯里兰卡僧伽罗语和泰米尔语）上的零样本性能，发现不同引擎在不同语言上表现最佳，并引入了一个新的泰米尔语合成OCR基准数据集。


<details>
  <summary>Details</summary>
Motivation: 高资源语言的OCR问题已基本解决，但对于使用独特文字的低资源语言，OCR仍然是一个开放问题。

Method: 对六种OCR引擎（包括商业和开源系统，如Cloud Vision API、Surya、Document AI、Tesseract、Subasa OCR和EasyOCR）在斯里兰卡僧伽罗语和泰米尔语上的零样本性能进行了比较分析。使用五种测量技术评估字符和单词级别的准确性，并引入了一个新的合成泰米尔语OCR基准数据集。

Result: Surya在所有指标上对僧伽罗语表现最佳，词错误率（WER）为2.61%。Document AI在所有指标上对泰米尔语表现突出，字符错误率（CER）为0.78%。

Conclusion: 对于低资源语言，没有一个OCR引擎能普遍表现最佳，性能取决于具体的语言。Surya和Document AI分别在僧伽罗语和泰米尔语上展现了优异的零样本性能。

Abstract: Solving the problem of Optical Character Recognition (OCR) on printed text
for Latin and its derivative scripts can now be considered settled due to the
volumes of research done on English and other High-Resourced Languages (HRL).
However, for Low-Resourced Languages (LRL) that use unique scripts, it remains
an open problem. This study presents a comparative analysis of the zero-shot
performance of six distinct OCR engines on two LRLs: Sinhala and Tamil. The
selected engines include both commercial and open-source systems, aiming to
evaluate the strengths of each category. The Cloud Vision API, Surya, Document
AI, and Tesseract were evaluated for both Sinhala and Tamil, while Subasa OCR
and EasyOCR were examined for only one language due to their limitations. The
performance of these systems was rigorously analysed using five measurement
techniques to assess accuracy at both the character and word levels. According
to the findings, Surya delivered the best performance for Sinhala across all
metrics, with a WER of 2.61%. Conversely, Document AI excelled across all
metrics for Tamil, highlighted by a very low CER of 0.78%. In addition to the
above analysis, we also introduce a novel synthetic Tamil OCR benchmarking
dataset.

</details>


### [139] [StyleAdaptedLM: Enhancing Instruction Following Models with Efficient Stylistic Transfer](https://arxiv.org/abs/2507.18294)
*Pritika Ramu,Apoorv Saxena,Meghanath M Y,Varsha Sankar,Debraj Basu*

Main category: cs.CL

TL;DR: StyleAdaptedLM框架利用LoRA高效地将风格特征转移到遵循指令的大语言模型中，无需配对数据，且不牺牲指令遵循能力，从而实现稳健的风格定制。


<details>
  <summary>Details</summary>
Motivation: 将大语言模型（LLMs）适应特定风格（如品牌声音或作者语调）对企业通信至关重要，但从缺乏指令-响应格式的语料库中实现这一点具有挑战性，且可能损害指令遵循能力。

Method: 引入StyleAdaptedLM框架，使用低秩适应（LoRA）技术。首先，LoRA适配器在基础模型上使用多样化的非结构化风格语料库进行训练，然后将这些适配器与一个独立的指令遵循模型合并。

Result: 在多个数据集和模型上的实验表明，该方法在保持指令遵循能力的同时，提高了风格一致性。人工评估也证实了模型能采纳品牌特定的约定。

Conclusion: StyleAdaptedLM为大语言模型中的风格个性化提供了一条高效的途径。

Abstract: Adapting LLMs to specific stylistic characteristics, like brand voice or
authorial tones, is crucial for enterprise communication but challenging to
achieve from corpora which lacks instruction-response formatting without
compromising instruction adherence. We introduce StyleAdaptedLM, a framework
that efficiently transfers stylistic traits to instruction-following models
using Low-Rank Adaptation (LoRA). LoRA adapters are first trained on a base
model with diverse unstructured stylistic corpora, then merged with a separate
instruction-following model. This enables robust stylistic customization
without paired data or sacrificing task performance. Experiments across
multiple datasets and models demonstrate improved stylistic consistency while
preserving instruction adherence, with human evaluations confirming
brand-specific convention uptake. StyleAdaptedLM offers an efficient path for
stylistic personalization in LLMs.

</details>


### [140] [BadReasoner: Planting Tunable Overthinking Backdoors into Large Reasoning Models for Fun or Profit](https://arxiv.org/abs/2507.18305)
*Biao Yi,Zekun Fei,Jianing Geng,Tong Li,Lihai Nie,Zheli Liu,Yiming Li*

Main category: cs.CL

TL;DR: 本文提出了一种针对大型推理模型（LRMs）的“过度思考后门”攻击，通过数据投毒使攻击者能够精确控制模型推理的冗余程度，同时保持答案的正确性，从而消耗资源。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在复杂推理任务中展现出强大的思维链（CoT）能力。研究旨在发现并探索一种新的攻击向量，该向量不仅能触发攻击，还能精确控制模型推理的冗余程度，而不仅仅是简单的开/关式攻击。

Method: 提出“过度思考后门”概念，并设计了一种可调的后门攻击。通过新颖的数据投毒方法实现：将可调触发器（重复次数表示期望强度）与相应冗长的思维链响应配对。这些响应由教师LLM通过注入受控数量的冗余细化步骤来程序化生成，以确保输出正确性，从而实现隐蔽性和资源消耗攻击。

Result: 在各种LRMs上的广泛实证结果表明，该方法能可靠地触发可控的、多倍的推理过程长度增加，且不降低最终答案的正确性。

Conclusion: 研究成功识别并实现了一种名为“过度思考后门”的新型攻击向量，该攻击能够精确控制大型推理模型推理过程的冗余程度，作为一种纯粹的资源消耗手段，同时不影响模型输出的正确性。

Abstract: Large reasoning models (LRMs) have emerged as a significant advancement in
artificial intelligence, representing a specialized class of large language
models (LLMs) designed to tackle complex reasoning tasks. The defining
characteristic of LRMs lies in their extensive chain-of-thought (CoT) reasoning
capabilities. In this paper, we identify a previously unexplored attack vector
against LRMs, which we term "overthinking backdoors". We advance this concept
by proposing a novel tunable backdoor, which moves beyond simple on/off attacks
to one where an attacker can precisely control the extent of the model's
reasoning verbosity. Our attack is implemented through a novel data poisoning
methodology. It pairs a tunable trigger-where the number of repetitions signals
the desired intensity-with a correspondingly verbose CoT response. These
responses are programmatically generated by instructing a teacher LLM to inject
a controlled number of redundant refinement steps into a correct reasoning
process. The approach preserves output correctness, which ensures stealth and
establishes the attack as a pure resource-consumption vector. Extensive
empirical results on various LRMs demonstrate that our method can reliably
trigger a controllable, multi-fold increase in the length of the reasoning
process, without degrading the final answer's correctness. Our source code is
available at https://github.com/FZaKK/BadReasoner.

</details>


### [141] [CLEAR: Error Analysis via LLM-as-a-Judge Made Easy](https://arxiv.org/abs/2507.18392)
*Asaf Yehudai,Lilach Eden,Yotam Perlitz,Roy Bar-Haim,Michal Shmueli-Scheuer*

Main category: cs.CL

TL;DR: CLEAR是一个交互式、开源的LLM错误分析工具包，它通过生成实例级文本反馈、识别系统级错误并量化其普遍性，提供比单一分数更深入的性能洞察。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM评估范式通常只提供单一分数或排名，回答“哪个模型更好”而非“为什么更好”，这掩盖了模型性能背后的具体可操作原因，阻碍了模型的改进。

Method: CLEAR首先生成每个实例的文本反馈，然后创建一套系统级错误问题，并量化每个已识别问题的普遍性。它还提供一个交互式仪表板，支持通过聚合可视化进行全面错误分析，应用交互式过滤器隔离特定问题或分数范围，并深入查看代表特定行为模式的单个实例。

Result: 研究人员在RAG和数学基准测试中演示了CLEAR的分析能力，并通过用户案例研究展示了其效用。

Conclusion: CLEAR通过提供具体、可操作的错误原因，弥合了现有评估方法的不足，使用户能够进行全面深入的LLM错误分析，从而更好地理解和改进模型性能。

Abstract: The evaluation of Large Language Models (LLMs) increasingly relies on other
LLMs acting as judges. However, current evaluation paradigms typically yield a
single score or ranking, answering which model is better but not why. While
essential for benchmarking, these top-level scores obscure the specific,
actionable reasons behind a model's performance. To bridge this gap, we
introduce CLEAR, an interactive, open-source package for LLM-based error
analysis. CLEAR first generates per-instance textual feedback, then it creates
a set of system-level error issues, and quantifies the prevalence of each
identified issue. Our package also provides users with an interactive dashboard
that allows for a comprehensive error analysis through aggregate
visualizations, applies interactive filters to isolate specific issues or score
ranges, and drills down to the individual instances that exemplify a particular
behavioral pattern. We demonstrate CLEAR analysis for RAG and Math benchmarks,
and showcase its utility through a user case study.

</details>


### [142] [Uncertainty Quantification for Evaluating Machine Translation Bias](https://arxiv.org/abs/2507.18338)
*Ieva Raminta Staliūnaitė,Julius Cheng,Andreas Vlachos*

Main category: cs.CL

TL;DR: 机器翻译模型在处理性别模糊词时存在偏见，即使在明确的情况下表现良好，也未能在模糊情况下表现出预期的不确定性。去偏处理对明确和模糊翻译实例的影响是独立的。


<details>
  <summary>Details</summary>
Motivation: 机器翻译模型在源语言性别未明确标记但目标语言需要性别指定时，常表现出性别偏见，依赖刻板印象，即使与上下文冲突。研究者认为模型在性别模糊时应保持不确定性，而非盲目推断。

Method: 使用了最近提出的语义不确定性度量方法，来评估模型在处理性别模糊和非模糊实例时的表现。

Result: 1. 在性别明确的翻译实例上具有高翻译和性别准确性的模型，在性别模糊实例上不一定表现出预期的不确定性水平。
2. 去偏处理对性别模糊和非模糊翻译实例具有独立的影响。

Conclusion: 机器翻译模型需要更好地处理性别模糊性，并在不确定时保持不确定性。去偏方法对不同类型的翻译实例（明确与模糊）可能产生不同的效果，需要更精细的考量。

Abstract: In machine translation (MT), when the source sentence includes a lexeme whose
gender is not overtly marked, but whose target-language equivalent requires
gender specification, the model must infer the appropriate gender from the
context and/or external knowledge. Studies have shown that MT models exhibit
biased behaviour, relying on stereotypes even when they clash with contextual
information. We posit that apart from confidently translating using the correct
gender when it is evident from the input, models should also maintain
uncertainty about the gender when it is ambiguous. Using recently proposed
metrics of semantic uncertainty, we find that models with high translation and
gender accuracy on unambiguous instances do not necessarily exhibit the
expected level of uncertainty in ambiguous ones. Similarly, debiasing has
independent effects on ambiguous and unambiguous translation instances.

</details>


### [143] [AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data](https://arxiv.org/abs/2507.18442)
*Rana Alshaikh,Israa Alghanmi,Shelan Jeawak*

Main category: cs.CL

TL;DR: 本文提出了AraTable，一个用于评估大型语言模型在阿拉伯语表格数据上推理和理解能力的综合基准，并揭示了LLM在复杂表格推理任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自然语言处理方面取得了显著进展，但它们在解释结构化数据（尤其是表格数据）方面的性能仍然有限。此外，阿拉伯语表格数据领域因公共资源稀缺和语言特性而严重不足。

Method: 研究构建了AraTable基准，包含直接问答、事实核查和复杂推理等多种评估任务，涵盖广泛的阿拉伯语表格数据源。数据生成采用混合管道，由LLM初步生成内容，再经人类专家过滤和验证。同时，提出了一种利用自审议机制的自动化评估框架。

Result: 初步分析显示，LLM在直接问答等简单表格任务上表现尚可，但在需要更深层次推理和事实核查的复杂任务上仍面临显著认知挑战。此外，所提出的自动化评估框架其性能与人类评判几乎一致。

Conclusion: AraTable为评估和改进LLM在阿拉伯语表格数据处理方面的能力提供了宝贵的公共资源和评估框架，有助于加速阿拉伯语结构化数据基础模型的发展。

Abstract: The cognitive and reasoning abilities of large language models (LLMs) have
enabled remarkable progress in natural language processing. However, their
performance in interpreting structured data, especially in tabular formats,
remains limited. Although benchmarks for English tabular data are widely
available, Arabic is still underrepresented because of the limited availability
of public resources and its unique language features. To address this gap, we
present AraTable, a novel and comprehensive benchmark designed to evaluate the
reasoning and understanding capabilities of LLMs when applied to Arabic tabular
data. AraTable consists of various evaluation tasks, such as direct question
answering, fact verification, and complex reasoning, involving a wide range of
Arabic tabular sources. Our methodology follows a hybrid pipeline, where
initial content is generated by LLMs and subsequently filtered and verified by
human experts to ensure high dataset quality. Initial analyses using AraTable
show that, while LLMs perform adequately on simpler tabular tasks such as
direct question answering, they continue to face significant cognitive
challenges when tasks require deeper reasoning and fact verification. This
indicates that there are substantial opportunities for future work to improve
performance on complex tabular reasoning tasks. We also propose a fully
automated evaluation framework that uses a self-deliberation mechanism and
achieves performance nearly identical to that of human judges. This research
provides a valuable, publicly available resource and evaluation framework that
can help accelerate the development of foundational models for processing and
analysing Arabic structured data.

</details>


### [144] [TDR: Task-Decoupled Retrieval with Fine-Grained LLM Feedback for In-Context Learning](https://arxiv.org/abs/2507.18340)
*Yifu Chen,Bingchen Huang,Zhiling Wang,Yuanchao Du,Junfeng Luo,Lei Shen,Zhineng chen*

Main category: cs.CL

TL;DR: 本文提出TDR框架，通过解耦任务数据和利用LLM细粒度反馈，显著提升了上下文学习（ICL）的示例检索质量，在30个NLP任务上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 上下文学习（ICL）的效果严重依赖于示例质量，但现有示例检索方法面临两大挑战：1) 难以区分跨任务数据分布；2) 难以将检索器输出与LLM的细粒度反馈有效关联。

Method: TDR框架通过以下两点解决问题：1) 解耦不同任务的ICL示例，使检索模块能针对目标任务检索特定示例；2) 建模LLM的细粒度反馈，用于监督和指导检索模块的训练，从而检索高质量示例。

Result: 在30个NLP任务上进行了广泛实验，结果表明TDR在所有数据集上均持续提升性能，并达到了最先进（SOTA）水平。此外，TDR是一种即插即用的方法，易于与各种LLM结合。

Conclusion: TDR通过任务解耦和细粒度LLM反馈机制，有效解决了ICL示例检索中的关键挑战，显著提升了检索质量和ICL性能，并具有良好的通用性和易用性。

Abstract: In-context learning (ICL) has become a classic approach for enabling LLMs to
handle various tasks based on a few input-output examples. The effectiveness of
ICL heavily relies on the quality of these examples, and previous works which
focused on enhancing example retrieval capabilities have achieved impressive
performances. However, two challenges remain in retrieving high-quality
examples: (1) Difficulty in distinguishing cross-task data distributions, (2)
Difficulty in making the fine-grained connection between retriever output and
feedback from LLMs. In this paper, we propose a novel framework called TDR. TDR
decouples the ICL examples from different tasks, which enables the retrieval
module to retrieve examples specific to the target task within a multi-task
dataset. Furthermore, TDR models fine-grained feedback from LLMs to supervise
and guide the training of the retrieval module, which helps to retrieve
high-quality examples. We conducted extensive experiments on a suite of 30 NLP
tasks, the results demonstrate that TDR consistently improved results across
all datasets and achieves state-of-the-art performance. Meanwhile, our approach
is a plug-and-play method, which can be easily combined with various LLMs to
improve example retrieval abilities for ICL. The code is available at
https://github.com/Nnn-s/TDR.

</details>


### [145] [Restoring Rhythm: Punctuation Restoration Using Transformer Models for Bangla, a Low-Resource Language](https://arxiv.org/abs/2507.18448)
*Md Obyedullahil Mamun,Md Adyelullahil Mamun,Arif Ahmad,Md. Imran Hossain Emu*

Main category: cs.CL

TL;DR: 本研究利用基于Transformer的XLM-RoBERTa-large模型，通过数据增强技术，实现了对孟加拉语无标点文本的自动标点恢复，并在不同数据集上取得了高准确率，为低资源语言NLP提供了基线。


<details>
  <summary>Details</summary>
Motivation: 标点恢复能增强文本可读性，对自动语音识别（ASR）的后处理至关重要，尤其对于孟加拉语等低资源语言，其缺乏带标注的资源。

Method: 采用基于Transformer的XLM-RoBERTa-large模型，预测四种标点符号（句号、逗号、问号、感叹号）。构建了大型多样化的训练语料库，并应用了数据增强技术（增强因子alpha = 0.20%）。

Result: 最佳模型在News测试集上达到97.1%的准确率，在Reference集上达到91.2%，在ASR集上达到90.2%。结果表明模型在真实、嘈杂场景下具有强大的泛化能力。

Conclusion: 本工作为孟加拉语标点恢复建立了一个强大的基线，并贡献了公开可用的数据集和代码，以支持未来在低资源NLP领域的研究。

Abstract: Punctuation restoration enhances the readability of text and is critical for
post-processing tasks in Automatic Speech Recognition (ASR), especially for
low-resource languages like Bangla. In this study, we explore the application
of transformer-based models, specifically XLM-RoBERTa-large, to automatically
restore punctuation in unpunctuated Bangla text. We focus on predicting four
punctuation marks: period, comma, question mark, and exclamation mark across
diverse text domains. To address the scarcity of annotated resources, we
constructed a large, varied training corpus and applied data augmentation
techniques. Our best-performing model, trained with an augmentation factor of
alpha = 0.20%, achieves an accuracy of 97.1% on the News test set, 91.2% on the
Reference set, and 90.2% on the ASR set.
  Results show strong generalization to reference and ASR transcripts,
demonstrating the model's effectiveness in real-world, noisy scenarios. This
work establishes a strong baseline for Bangla punctuation restoration and
contributes publicly available datasets and code to support future research in
low-resource NLP.

</details>


### [146] [Hybrid Annotation for Propaganda Detection: Integrating LLM Pre-Annotations with Human Intelligence](https://arxiv.org/abs/2507.18343)
*Ariana Sahitaj,Premtim Sahitaj,Veronika Solopova,Jiaao Li,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 本文提出一个结合人类专业知识和大型语言模型（LLM）辅助的框架，旨在提高社交媒体上宣传检测的标注一致性和可扩展性。该框架通过LLM辅助预标注并利用LLM生成的高质量数据，通过知识蒸馏训练小型语言模型进行结构化标注。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的宣传检测面临任务复杂性和高质量标注数据稀缺的挑战。

Method: 1. 提出一个将14种细粒度宣传技术组织成3个更广泛类别的分层分类法。2. 进行人工标注研究，发现细粒度标签的标注者间一致性较低。3. 实施LLM辅助的预标注流程，用于提取宣传片段、生成解释并分配局部及全局标签。4. 在LLM生成的高质量数据而非人工标注数据上微调小型语言模型（SLM），通过知识蒸馏实现结构化标注。

Result: 1. 初步人工标注研究显示细粒度标签的标注者间一致性低。2. 辅助LLM的预标注流程显著提高了标注一致性和时间效率。

Conclusion: 本研究有助于开发可扩展且鲁棒的宣传检测系统，支持建立透明和负责任的媒体生态系统，符合联合国可持续发展目标16。

Abstract: Propaganda detection on social media remains challenging due to task
complexity and limited high-quality labeled data. This paper introduces a novel
framework that combines human expertise with Large Language Model (LLM)
assistance to improve both annotation consistency and scalability. We propose a
hierarchical taxonomy that organizes 14 fine-grained propaganda techniques into
three broader categories, conduct a human annotation study on the HQP dataset
that reveals low inter-annotator agreement for fine-grained labels, and
implement an LLM-assisted pre-annotation pipeline that extracts propagandistic
spans, generates concise explanations, and assigns local labels as well as a
global label. A secondary human verification study shows significant
improvements in both agreement and time-efficiency. Building on this, we
fine-tune smaller language models (SLMs) to perform structured annotation.
Instead of fine-tuning on human annotations, we train on high-quality
LLM-generated data, allowing a large model to produce these annotations and a
smaller model to learn to generate them via knowledge distillation. Our work
contributes towards the development of scalable and robust propaganda detection
systems, supporting the idea of transparent and accountable media ecosystems in
line with SDG 16. The code is publicly available at our GitHub repository.

</details>


### [147] [Generation of Synthetic Clinical Text: A Systematic Review](https://arxiv.org/abs/2507.18451)
*Basel Alshaikhdeeb,Ahmed Abdelmonem Hemedan,Soumyabrata Ghosh,Irina Balaur,Venkata Satagopam*

Main category: cs.CL

TL;DR: 本文对合成临床自由文本的生成进行了系统综述，分析了其生成目的、所用技术和评估方法，旨在解决临床NLP中的数据稀疏性和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 解决临床自然语言处理（NLP）中常见的数据稀疏性和隐私保护问题，为NLP任务提供有效的解决方案。

Method: 通过系统回顾的方式，在PubMed、ScienceDirect、Web of Science、Scopus、IEEE、Google Scholar和arXiv等数据库中搜索了与生成合成医学非结构化自由文本相关的出版物。共收集了1398篇文章，并从中识别出94篇相关文章。对生成目的、所用技术和评估方法进行了定量分析。

Result: 自2018年以来，合成医学文本生成领域受到广泛关注。主要生成目的包括文本增强、辅助写作、语料库构建、隐私保护、标注和实用性。Transformer架构（尤其是GPT模型）是主要的生成技术。评估主要集中在相似性、隐私、结构和实用性四个方面，其中实用性是最常用的评估方法。合成医学文本在下游NLP任务中作为真实文档表现出中等可能性，但在作为增强或补充数据以提高准确性和克服稀疏/欠采样问题方面表现出色。

Conclusion: 合成医学文本是NLP任务的宝贵资产，能有效提高准确性并解决数据稀疏问题，同时显著加速工作流程和管道开发，减少数据传输的法律障碍。然而，隐私仍然是一个主要问题，需要更多的人工评估来检查敏感信息的存在。

Abstract: Generating clinical synthetic text represents an effective solution for
common clinical NLP issues like sparsity and privacy. This paper aims to
conduct a systematic review on generating synthetic medical free-text by
formulating quantitative analysis to three research questions concerning (i)
the purpose of generation, (ii) the techniques, and (iii) the evaluation
methods. We searched PubMed, ScienceDirect, Web of Science, Scopus, IEEE,
Google Scholar, and arXiv databases for publications associated with generating
synthetic medical unstructured free-text. We have identified 94 relevant
articles out of 1,398 collected ones. A great deal of attention has been given
to the generation of synthetic medical text from 2018 onwards, where the main
purpose of such a generation is towards text augmentation, assistive writing,
corpus building, privacy-preserving, annotation, and usefulness. Transformer
architectures were the main predominant technique used to generate the text,
especially the GPTs. On the other hand, there were four main aspects of
evaluation, including similarity, privacy, structure, and utility, where
utility was the most frequent method used to assess the generated synthetic
medical text. Although the generated synthetic medical text demonstrated a
moderate possibility to act as real medical documents in different downstream
NLP tasks, it has proven to be a great asset as augmented, complementary to the
real documents, towards improving the accuracy and overcoming
sparsity/undersampling issues. Yet, privacy is still a major issue behind
generating synthetic medical text, where more human assessments are needed to
check for the existence of any sensitive information. Despite that, advances in
generating synthetic medical text will considerably accelerate the adoption of
workflows and pipeline development, discarding the time-consuming legalities of
data transfer.

</details>


### [148] [Factual Inconsistencies in Multilingual Wikipedia Tables](https://arxiv.org/abs/2507.18406)
*Silvia Cappa,Lingxiao Kong,Pille-Riin Peet,Fanfu Wei,Yuchen Zhou,Jan-Christoph Kalo*

Main category: cs.CL

TL;DR: 本研究调查了维基百科跨语言版本中结构化内容（表格数据）的事实不一致性，开发了收集、对齐和分析表格的方法，并评估了这些不一致性对AI系统可靠性的影响。


<details>
  <summary>Details</summary>
Motivation: 维基百科是全球知识来源，内容涵盖300多种语言，但各语言版本独立编写和更新，导致事实不一致。这会影响百科全书的中立性和可靠性，尤其对于依赖维基百科作为主要训练来源的AI系统。

Method: 开发了一套方法来收集、对齐和分析维基百科多语言文章中的表格数据，并定义了不一致性的类别。使用样本数据集应用了多种定量和定性指标来评估多语言对齐情况。

Result: 研究发现了维基百科跨语言结构化内容中的不一致性，并通过定量和定性指标进行了评估。这些发现对事实核查、多语言知识交互以及设计利用维基百科内容的可靠AI系统具有重要意义。

Conclusion: 维基百科跨语言版本中存在结构化内容的不一致性，这对于事实核查、多语言知识交互以及构建依赖维基百科内容的可靠AI系统至关重要，需要加以关注和解决。

Abstract: Wikipedia serves as a globally accessible knowledge source with content in
over 300 languages. Despite covering the same topics, the different versions of
Wikipedia are written and updated independently. This leads to factual
inconsistencies that can impact the neutrality and reliability of the
encyclopedia and AI systems, which often rely on Wikipedia as a main training
source. This study investigates cross-lingual inconsistencies in Wikipedia's
structured content, with a focus on tabular data. We developed a methodology to
collect, align, and analyze tables from Wikipedia multilingual articles,
defining categories of inconsistency. We apply various quantitative and
qualitative metrics to assess multilingual alignment using a sample dataset.
These insights have implications for factual verification, multilingual
knowledge interaction, and design for reliable AI systems leveraging Wikipedia
content.

</details>


### [149] [FinDPO: Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs](https://arxiv.org/abs/2507.18417)
*Giorgos Iacovides,Wuyang Zhou,Danilo Mandic*

Main category: cs.CL

TL;DR: 本文提出了FinDPO，首个基于直接偏好优化（DPO）的金融领域LLM框架，用于情感分析。它解决了传统SFT模型泛化性差的问题，在基准测试中表现出色，并在实际投资组合策略中实现了显著的正回报和风险调整收益。


<details>
  <summary>Details</summary>
Motivation: 在线金融文本数据中的观点对交易决策和市场走势影响深远，凸显了情感分析的重要性。然而，当前主流的监督微调（SFT）大型语言模型（LLMs）存在记忆训练数据和泛化能力差的问题，这在需要适应未见事件和领域特定语言的金融领域是致命缺陷。

Method: 本文引入了FinDPO框架，这是首个基于后训练人类偏好对齐（通过直接偏好优化DPO）的金融特定LLM框架。此外，FinDPO通过一种新颖的“logit-to-score”转换方法，将离散情感预测转化为连续、可排序的情感分数，从而将微调后的因果LLM整合到实际投资组合策略中。

Result: FinDPO在标准情感分类基准测试中取得了最先进的性能，平均优于现有监督微调模型11%。在投资组合模拟中，即使在5个基点的交易成本下，FinDPO作为首个基于情感的方法，仍能保持每年67%的显著正回报和2.0的夏普比率，显示出强大的风险调整性能。

Conclusion: FinDPO通过引入DPO克服了传统SFT模型在金融领域泛化性差的局限性，实现了情感分析的最新性能。其独特的“logit-to-score”转换使其能有效应用于实际投资组合策略，产生显著的积极回报和良好的风险调整性能，为金融情感分析和量化投资提供了新的范式。

Abstract: Opinions expressed in online finance-related textual data are having an
increasingly profound impact on trading decisions and market movements. This
trend highlights the vital role of sentiment analysis as a tool for quantifying
the nature and strength of such opinions. With the rapid development of
Generative AI (GenAI), supervised fine-tuned (SFT) large language models (LLMs)
have become the de facto standard for financial sentiment analysis. However,
the SFT paradigm can lead to memorization of the training data and often fails
to generalize to unseen samples. This is a critical limitation in financial
domains, where models must adapt to previously unobserved events and the
nuanced, domain-specific language of finance. To this end, we introduce FinDPO,
the first finance-specific LLM framework based on post-training human
preference alignment via Direct Preference Optimization (DPO). The proposed
FinDPO achieves state-of-the-art performance on standard sentiment
classification benchmarks, outperforming existing supervised fine-tuned models
by 11% on the average. Uniquely, the FinDPO framework enables the integration
of a fine-tuned causal LLM into realistic portfolio strategies through a novel
'logit-to-score' conversion, which transforms discrete sentiment predictions
into continuous, rankable sentiment scores (probabilities). In this way,
simulations demonstrate that FinDPO is the first sentiment-based approach to
maintain substantial positive returns of 67% annually and strong risk-adjusted
performance, as indicated by a Sharpe ratio of 2.0, even under realistic
transaction costs of 5 basis points (bps).

</details>


### [150] [Not All Features Deserve Attention: Graph-Guided Dependency Learning for Tabular Data Generation with Language Models](https://arxiv.org/abs/2507.18504)
*Zheyu Zhang,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 该论文提出GraDe方法，通过将稀疏依赖图集成到LLM的注意力机制中，解决LLM在表格数据生成中因特征依赖稀疏性导致的注意力分散问题，从而提高生成质量。


<details>
  <summary>Details</summary>
Motivation: LLM在表格数据生成中，其自注意力机制会不可避免地将注意力分散到所有特征对上，导致在关键关系上的注意力被稀释，尤其是在具有复杂依赖或语义模糊特征的数据集中，这与表格数据固有的稀疏特征级依赖性存在根本性不匹配。

Method: 提出GraDe（Graph-Guided Dependency Learning）方法。该方法将稀疏依赖图显式地集成到LLM的注意力机制中。GraDe采用一个轻量级的动态图学习模块，该模块由外部提取的功能依赖关系引导，优先处理关键特征交互，同时抑制不相关的交互。

Result: 在多样化的真实世界数据集上的实验表明，GraDe在复杂数据集上比现有基于LLM的方法性能提升高达12%，并在合成数据质量方面与最先进的方法具有竞争力。

Conclusion: GraDe方法对LLM的侵入性小但效果显著，为使用LLM进行结构感知型表格数据建模提供了一个实用的解决方案。

Abstract: Large Language Models (LLMs) have shown strong potential for tabular data
generation by modeling textualized feature-value pairs. However, tabular data
inherently exhibits sparse feature-level dependencies, where many feature
interactions are structurally insignificant. This creates a fundamental
mismatch as LLMs' self-attention mechanism inevitably distributes focus across
all pairs, diluting attention on critical relationships, particularly in
datasets with complex dependencies or semantically ambiguous features. To
address this limitation, we propose GraDe (Graph-Guided Dependency Learning), a
novel method that explicitly integrates sparse dependency graphs into LLMs'
attention mechanism. GraDe employs a lightweight dynamic graph learning module
guided by externally extracted functional dependencies, prioritizing key
feature interactions while suppressing irrelevant ones. Our experiments across
diverse real-world datasets demonstrate that GraDe outperforms existing
LLM-based approaches by up to 12% on complex datasets while achieving
competitive results with state-of-the-art approaches in synthetic data quality.
Our method is minimally intrusive yet effective, offering a practical solution
for structure-aware tabular data modeling with LLMs.

</details>


### [151] [The Moral Gap of Large Language Models](https://arxiv.org/abs/2507.18523)
*Maciej Skorski,Alina Landowska*

Main category: cs.CL

TL;DR: 本研究比较了大型语言模型（LLMs）和微调Transformer模型在道德基础检测任务上的表现，发现微调模型优于LLMs。


<details>
  <summary>Details</summary>
Motivation: 道德基础检测对于分析社会话语和开发符合伦理的AI系统至关重要，但LLMs在此类专业道德推理任务上的性能尚不明确。

Method: 使用ROC、PR和DET曲线分析，首次对最先进的LLMs（通过提示工程）和微调的Transformer模型在Twitter和Reddit数据集上进行了全面比较。

Result: 结果显示LLMs存在显著的性能差距，表现出高假阴性率和对道德内容的系统性低检测，即使进行了提示工程。微调模型在性能上明显优于LLMs。

Conclusion: 对于道德推理应用，任务特定的微调模型仍优于基于提示工程的LLMs。

Abstract: Moral foundation detection is crucial for analyzing social discourse and
developing ethically-aligned AI systems. While large language models excel
across diverse tasks, their performance on specialized moral reasoning remains
unclear.
  This study provides the first comprehensive comparison between
state-of-the-art LLMs and fine-tuned transformers across Twitter and Reddit
datasets using ROC, PR, and DET curve analysis.
  Results reveal substantial performance gaps, with LLMs exhibiting high false
negative rates and systematic under-detection of moral content despite prompt
engineering efforts. These findings demonstrate that task-specific fine-tuning
remains superior to prompting for moral reasoning applications.

</details>


### [152] [GLiNER2: An Efficient Multi-Task Information Extraction System with Schema-Driven Interface](https://arxiv.org/abs/2507.18546)
*Urchade Zaratiana,Gil Pasternak,Oliver Boyd,George Hurn-Maloney,Ash Lewis*

Main category: cs.CL

TL;DR: GLiNER2是一个统一且高效的框架，基于预训练Transformer编码器，能在一个模型中处理命名实体识别、文本分类和分层数据提取等多种信息提取任务，且在部署可访问性上优于大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有信息提取解决方案通常需要针对不同任务的专用模型，或依赖计算成本高昂的大型语言模型，缺乏统一且高效的替代方案。

Method: GLiNER2在原有GLiNER架构基础上进行了增强，采用预训练Transformer编码器架构。通过直观的基于Schema的接口实现多任务组合，同时保持CPU效率和紧凑的模型大小。

Result: GLiNER2在提取和分类任务上展现出具有竞争力的性能，并且与基于大型语言模型的替代方案相比，在部署可访问性方面有显著提升。

Conclusion: GLiNER2提供了一个统一、高效且易于部署的信息提取解决方案，能够有效处理多种NLP任务，并已作为开源库发布。

Abstract: Information extraction (IE) is fundamental to numerous NLP applications, yet
existing solutions often require specialized models for different tasks or rely
on computationally expensive large language models. We present GLiNER2, a
unified framework that enhances the original GLiNER architecture to support
named entity recognition, text classification, and hierarchical structured data
extraction within a single efficient model. Built pretrained transformer
encoder architecture, GLiNER2 maintains CPU efficiency and compact size while
introducing multi-task composition through an intuitive schema-based interface.
Our experiments demonstrate competitive performance across extraction and
classification tasks with substantial improvements in deployment accessibility
compared to LLM-based alternatives. We release GLiNER2 as an open-source
pip-installable library with pre-trained models and documentation at
https://github.com/fastino-ai/GLiNER2.

</details>


### [153] [Effective Multi-Task Learning for Biomedical Named Entity Recognition](https://arxiv.org/abs/2507.18542)
*João Ruano,Gonçalo M. Correia,Leonor Barreiros,Afonso Mendes*

Main category: cs.CL

TL;DR: 本文提出SRU-NER，一种新的槽位循环单元命名实体识别方法，通过多任务学习和动态损失调整来处理嵌套实体和跨数据集标注不一致问题，并在生物医学和通用领域NER任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 生物医学命名实体识别面临术语复杂性和数据集标注不一致的挑战。

Method: 引入SRU-NER（基于槽位的循环单元NER），一种处理嵌套命名实体的新方法，通过有效多任务学习策略整合多个数据集。通过动态调整损失计算，避免惩罚特定数据集中不存在的实体类型预测，从而缓解标注差距。

Result: 通过广泛实验（包括跨语料库评估和人工评估），SRU-NER在生物医学和通用领域NER任务中取得了有竞争力的性能，并提高了跨领域泛化能力。

Conclusion: SRU-NER有效解决了生物医学命名实体识别中的挑战，尤其在处理嵌套实体、整合多数据集和提高跨领域泛化方面表现突出。

Abstract: Biomedical Named Entity Recognition presents significant challenges due to
the complexity of biomedical terminology and inconsistencies in annotation
across datasets. This paper introduces SRU-NER (Slot-based Recurrent Unit NER),
a novel approach designed to handle nested named entities while integrating
multiple datasets through an effective multi-task learning strategy. SRU-NER
mitigates annotation gaps by dynamically adjusting loss computation to avoid
penalizing predictions of entity types absent in a given dataset. Through
extensive experiments, including a cross-corpus evaluation and human assessment
of the model's predictions, SRU-NER achieves competitive performance in
biomedical and general-domain NER tasks, while improving cross-domain
generalization.

</details>


### [154] [GIIFT: Graph-guided Inductive Image-free Multimodal Machine Translation](https://arxiv.org/abs/2507.18562)
*Jiafeng Xiong,Yuting Zhao*

Main category: cs.CL

TL;DR: 本文提出GIIFT框架，通过构建多模态场景图和使用跨模态图注意力网络适配器，学习并整合多模态知识，实现了在推理阶段无需图像的多模态机器翻译，并在多个基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态机器翻译（MMT）方法在利用模态间隙方面面临挑战，因为它们强制执行刚性的视觉-语言对齐，并且推理仅限于其训练过的多模态领域。

Method: 1. 构建新颖的多模态场景图以保留并整合模态特异性信息。2. 引入GIIFT（图引导归纳式无图像MMT）两阶段框架。3. 使用跨模态图注意力网络（GAT）适配器在统一的融合空间中学习多模态知识。4. 将所学知识归纳推广到更广泛的无图像翻译领域。

Result: 1. 在Multi30K数据集（英译法、英译德任务）上，GIIFT超越现有方法并达到最先进水平，即使在推理时没有图像。2. 在WMT基准测试上，GIIFT比无图像翻译基线有显著改进。

Conclusion: GIIFT框架能够有效地学习和泛化多模态知识，实现了在推理阶段无需图像的归纳式机器翻译，并在多个翻译任务中展现出卓越的性能，解决了现有MMT方法的局限性。

Abstract: Multimodal Machine Translation (MMT) has demonstrated the significant help of
visual information in machine translation. However, existing MMT methods face
challenges in leveraging the modality gap by enforcing rigid visual-linguistic
alignment whilst being confined to inference within their trained multimodal
domains. In this work, we construct novel multimodal scene graphs to preserve
and integrate modality-specific information and introduce GIIFT, a two-stage
Graph-guided Inductive Image-Free MMT framework that uses a cross-modal Graph
Attention Network adapter to learn multimodal knowledge in a unified fused
space and inductively generalize it to broader image-free translation domains.
Experimental results on the Multi30K dataset of English-to-French and
English-to-German tasks demonstrate that our GIIFT surpasses existing
approaches and achieves the state-of-the-art, even without images during
inference. Results on the WMT benchmark show significant improvements over the
image-free translation baselines, demonstrating the strength of GIIFT towards
inductive image-free inference.

</details>


### [155] [AQuilt: Weaving Logic and Self-Inspection into Low-Cost, High-Relevance Data Synthesis for Specialist LLMs](https://arxiv.org/abs/2507.18584)
*Xiaopeng Ke,Hexuan Deng,Xuebo Liu,Jun Rao,Zhenxi Song,Jun Yu,Min Zhang*

Main category: cs.CL

TL;DR: AQuilt是一个从无标签数据构建领域特定指令微调数据的框架，通过引入逻辑和自检提升模型性能，并以更低成本实现与现有SOTA模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在通用领域表现出色，但在专业领域常表现不佳。现有数据合成方法要么计算成本高昂，要么性能受限，且泛化能力不足。

Method: 提出AQuilt框架，用于从无标签数据构建任何专业领域的指令微调数据，包括答案（Answer）、问题（Question）、无标签数据（Unlabeled data）、检查（Inspection）、逻辑（Logic）和任务类型（Task type）。通过整合逻辑和检查，鼓励推理过程和自我检查以提升模型性能。可定制的任务指令确保了高质量数据生成。构建了70.3万个示例的数据集来训练数据合成模型。

Result: 实验表明，AQuilt在仅使用DeepSeek-V3 17%的生产成本下，性能可与之媲美。进一步分析显示，AQuilt生成的数据与下游任务的相关性更高。

Conclusion: AQuilt提供了一种高效且有效的方法，通过从无标签数据生成高质量指令微调数据，将大型语言模型适应到专业领域，解决了现有方法的成本和性能限制问题。

Abstract: Despite the impressive performance of large language models (LLMs) in general
domains, they often underperform in specialized domains. Existing approaches
typically rely on data synthesis methods and yield promising results by using
unlabeled data to capture domain-specific features. However, these methods
either incur high computational costs or suffer from performance limitations,
while also demonstrating insufficient generalization across different tasks. To
address these challenges, we propose AQuilt, a framework for constructing
instruction-tuning data for any specialized domains from corresponding
unlabeled data, including Answer, Question, Unlabeled data, Inspection, Logic,
and Task type. By incorporating logic and inspection, we encourage reasoning
processes and self-inspection to enhance model performance. Moreover,
customizable task instructions enable high-quality data generation for any
task. As a result, we construct a dataset of 703k examples to train a powerful
data synthesis model. Experiments show that AQuilt is comparable to DeepSeek-V3
while utilizing just 17% of the production cost. Further analysis demonstrates
that our generated data exhibits higher relevance to downstream tasks. Source
code, models, and scripts are available at https://github.com/Krueske/AQuilt.

</details>


### [156] [Hybrid Tokenization Strategy for DNA Language Model using Byte Pair Encoding and K-MER Methods](https://arxiv.org/abs/2507.18570)
*Ganesh Sapkota,Md Hasibur Rahman*

Main category: cs.CL

TL;DR: 该论文提出了一种结合6-mer和BPE-600的新型混合分词策略，显著提升了DNA语言模型（DLMs）的性能，在下一k-mer预测任务中超越了现有先进模型。


<details>
  <summary>Details</summary>
Motivation: 传统的k-mer分词虽然能捕捉局部DNA结构，但存在分词分布不均和对全局序列上下文理解有限的问题。为了解决这些限制，需要一种更平衡且上下文感知的词汇表。

Method: 提出将独特的6-mer分词与经过600次BPE循环优选的BPE分词相结合，形成一种混合词汇表。在此混合词汇表上训练一个基础DLM，并通过下一k-mer预测作为微调任务进行评估。

Result: 该模型在3-mer预测中达到10.78%的准确率，4-mer预测中达到10.1%，5-mer预测中达到4.12%，性能优于NT、DNABERT2和GROVER等现有最先进模型。

Conclusion: 混合分词策略在DNA建模中能同时保留局部序列结构和全局上下文信息，强调了高级分词方法在基因组语言建模中的重要性，并为未来的DNA序列分析和生物学研究奠定了坚实基础。

Abstract: This paper presents a novel hybrid tokenization strategy that enhances the
performance of DNA Language Models (DLMs) by combining 6-mer tokenization with
Byte Pair Encoding (BPE-600). Traditional k-mer tokenization is effective at
capturing local DNA sequence structures but often faces challenges, including
uneven token distribution and a limited understanding of global sequence
context. To address these limitations, we propose merging unique 6mer tokens
with optimally selected BPE tokens generated through 600 BPE cycles. This
hybrid approach ensures a balanced and context-aware vocabulary, enabling the
model to capture both short and long patterns within DNA sequences
simultaneously. A foundational DLM trained on this hybrid vocabulary was
evaluated using next-k-mer prediction as a fine-tuning task, demonstrating
significantly improved performance. The model achieved prediction accuracies of
10.78% for 3-mers, 10.1% for 4-mers, and 4.12% for 5-mers, outperforming
state-of-the-art models such as NT, DNABERT2, and GROVER. These results
highlight the ability of the hybrid tokenization strategy to preserve both the
local sequence structure and global contextual information in DNA modeling.
This work underscores the importance of advanced tokenization methods in
genomic language modeling and lays a robust foundation for future applications
in downstream DNA sequence analysis and biological research.

</details>


### [157] [Wide-In, Narrow-Out: Revokable Decoding for Efficient and Effective DLLMs](https://arxiv.org/abs/2507.18578)
*Feng Hong,Geng Yu,Yushi Ye,Haicheng Huang,Huangjie Zheng,Ya Zhang,Yanfeng Wang,Jiangchao Yao*

Main category: cs.CL

TL;DR: 本文提出WINO，一种无训练的DLLM解码算法，通过可撤销解码机制显著改善了扩散大语言模型（DLLMs）的速度与质量权衡，解决了现有DLLMs快速并行解码导致性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散大语言模型（DLLMs）在快速并行生成时面临严重的质量-速度权衡问题，即更快的并行解码会导致显著的性能下降。作者认为这归因于DLLMs中标准解码的不可逆性，容易在早期错误上下文积累下偏向错误的解码方向。

Method: 本文引入了Wide-In, Narrow-Out (WINO)，一种无需训练的解码算法，实现了DLLMs中的可撤销解码。WINO采用并行草稿-验证机制，积极地草拟多个token，同时利用模型的双向上下文来验证并重新遮蔽可疑的token以进行细化。

Result: WINO在开源DLLMs（如LLaDA和MMaDA）上得到验证，结果表明它显著改善了质量-速度权衡。例如，在GSM8K数学基准测试中，它将推理速度提高了6倍，同时准确率提高了2.58%；在Flickr30K图像描述任务中，它实现了10倍的速度提升并带来了更高的性能。论文还进行了更全面的实验来证明WINO的优越性。

Conclusion: WINO通过引入可撤销解码机制，有效解决了DLLMs中困扰的质量-速度权衡问题，实现了更快的并行生成且不牺牲性能，甚至有所提升，为DLLMs的实际应用提供了重要进展。

Abstract: Diffusion Large Language Models (DLLMs) have emerged as a compelling
alternative to Autoregressive models, designed for fast parallel generation.
However, existing DLLMs are plagued by a severe quality-speed trade-off, where
faster parallel decoding leads to significant performance degradation. We
attribute this to the irreversibility of standard decoding in DLLMs, which is
easily polarized into the wrong decoding direction along with early error
context accumulation. To resolve this, we introduce Wide-In, Narrow-Out (WINO),
a training-free decoding algorithm that enables revokable decoding in DLLMs.
WINO employs a parallel draft-and-verify mechanism, aggressively drafting
multiple tokens while simultaneously using the model's bidirectional context to
verify and re-mask suspicious ones for refinement. Verified in open-source
DLLMs like LLaDA and MMaDA, WINO is shown to decisively improve the
quality-speed trade-off. For instance, on the GSM8K math benchmark, it
accelerates inference by 6$\times$ while improving accuracy by 2.58%; on
Flickr30K captioning, it achieves a 10$\times$ speedup with higher performance.
More comprehensive experiments are conducted to demonstrate the superiority and
provide an in-depth understanding of WINO.

</details>


### [158] [System Report for CCL25-Eval Task 10: SRAG-MAV for Fine-Grained Chinese Hate Speech Recognition](https://arxiv.org/abs/2507.18580)
*Jiahao Wang,Ramen Liu,Longhui Zhang,Jing Li*

Main category: cs.CL

TL;DR: 本文提出了一个名为SRAG-MAV的新颖框架，用于细粒度中文仇恨言论识别（FGCHSR），通过任务重构、自检索增强生成和多轮累积投票，显著提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 解决细粒度中文仇恨言论识别（FGCHSR）的挑战，旨在提高识别的准确性和稳定性。

Method: 提出了SRAG-MAV框架，包含三个核心组件：1. 任务重构：将四元组抽取任务重构为三元组抽取；2. 自检索增强生成（SRAG）：从训练集中动态检索上下文提示；3. 多轮累积投票（MAV）：通过多轮推理和投票提高输出稳定性和性能。该系统基于Qwen2.5-7B模型。

Result: 在STATE ToxiCN数据集上，系统取得了Hard Score 26.66、Soft Score 48.35和Average Score 37.505的成绩，显著优于基线模型（如GPT-4o的平均分15.63和微调Qwen2.5-7B的平均分35.365）。

Conclusion: 所提出的SRAG-MAV框架在细粒度中文仇恨言论识别任务上表现出色，显著超越了现有基线模型，证明了其在提升识别性能方面的有效性。

Abstract: This paper presents our system for CCL25-Eval Task 10, addressing
Fine-Grained Chinese Hate Speech Recognition (FGCHSR). We propose a novel
SRAG-MAV framework that synergistically integrates task reformulation(TR),
Self-Retrieval-Augmented Generation (SRAG), and Multi-Round Accumulative Voting
(MAV). Our method reformulates the quadruplet extraction task into triplet
extraction, uses dynamic retrieval from the training set to create contextual
prompts, and applies multi-round inference with voting to improve output
stability and performance. Our system, based on the Qwen2.5-7B model, achieves
a Hard Score of 26.66, a Soft Score of 48.35, and an Average Score of 37.505 on
the STATE ToxiCN dataset, significantly outperforming baselines such as GPT-4o
(Average Score 15.63) and fine-tuned Qwen2.5-7B (Average Score 35.365). The
code is available at https://github.com/king-wang123/CCL25-SRAG-MAV.

</details>


### [159] [TRPrompt: Bootstrapping Query-Aware Prompt Optimization from Textual Rewards](https://arxiv.org/abs/2507.18618)
*Andreea Nica,Ivan Zakazov,Nicolas Mario Baldwin,Saibo Geng,Robert West*

Main category: cs.CL

TL;DR: 本文提出了TRPrompt框架，通过将文本反馈直接整合到提示模型训练中，统一了基于文本反馈和数值奖励的提示优化方法，从而为大型语言模型生成高质量、任务特定的提示，并在数学推理任务上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 提示优化无需更新LLM参数即可提升其推理能力。现有方法分为两类：一类使用文本反馈启发式生成提示（无需训练），另一类使用数值奖励训练专门的提示模型。这两种方法各有优缺点，需要一种能结合两者优势的新框架。

Method: 引入了Textual Reward Prompt (TRPrompt) 框架，该框架将文本反馈直接整合到提示模型的训练过程中。它不需要预先收集数据集，并通过对生成提示的反馈进行迭代改进。结合LLM对“好”提示的内在理解，文本奖励提供高分辨率信号来训练提示模型。

Result: TRPrompt框架能够训练出一个提示模型，为挑战性数学数据集（GSMHard和MATH）的问题生成最先进的查询特定提示。

Conclusion: TRPrompt成功地将文本反馈融入提示模型训练，提供了一种有效且迭代优化的方法来生成高质量提示，显著提升了LLM在复杂推理任务上的表现。

Abstract: Prompt optimization improves the reasoning abilities of large language models
(LLMs) without requiring parameter updates to the target model. Following
heuristic-based "Think step by step" approaches, the field has evolved in two
main directions: while one group of methods uses textual feedback to elicit
improved prompts from general-purpose LLMs in a training-free way, a concurrent
line of research relies on numerical rewards to train a special prompt model,
tailored for providing optimal prompts to the target model. In this paper, we
introduce the Textual Reward Prompt framework (TRPrompt), which unifies these
approaches by directly incorporating textual feedback into training of the
prompt model. Our framework does not require prior dataset collection and is
being iteratively improved with the feedback on the generated prompts. When
coupled with the capacity of an LLM to internalize the notion of what a "good"
prompt is, the high-resolution signal provided by the textual rewards allows us
to train a prompt model yielding state-of-the-art query-specific prompts for
the problems from the challenging math datasets GSMHard and MATH.

</details>


### [160] [Checklists Are Better Than Reward Models For Aligning Language Models](https://arxiv.org/abs/2507.18624)
*Vijay Viswanathan,Yanchao Sun,Shuang Ma,Xiang Kong,Meng Cao,Graham Neubig,Tongshuang Wu*

Main category: cs.CL

TL;DR: 本文提出了一种名为“基于清单反馈的强化学习”（RLCF）的新方法，通过使用灵活的、指令特定的清单来评估语言模型响应，并将其分数作为强化学习奖励，显著提升了模型在多个基准测试上的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型需要适应以理解和遵循用户指令。传统的强化学习方法通常使用固定标准（如“有用性”和“有害性”）来促进指令遵循，但这限制了强化学习在引发指令遵循方面的影响。研究旨在提出一种更灵活、指令特定的评估标准。

Method: 本文提出了RLCF方法。该方法从用户指令中提取清单，并使用AI评判和专业验证程序评估响应满足每个清单项的程度。然后，将这些评估分数结合起来计算强化学习的奖励。RLCF被应用于Qwen2.5-7B-Instruct模型，并在五个广泛研究的基准测试上与其他对齐方法进行了比较。

Result: RLCF是唯一在所有五个基准测试上都提高了性能的方法。具体包括：在FollowBench上硬性满足率提高了4点，在InFoBench上提高了6点，在Arena-Hard上胜率提高了3点。

Conclusion: 研究结果表明，清单反馈是改进语言模型支持表达多种需求查询的关键工具。

Abstract: Language models must be adapted to understand and follow user instructions.
Reinforcement learning is widely used to facilitate this -- typically using
fixed criteria such as "helpfulness" and "harmfulness". In our work, we instead
propose using flexible, instruction-specific criteria as a means of broadening
the impact that reinforcement learning can have in eliciting instruction
following. We propose "Reinforcement Learning from Checklist Feedback" (RLCF).
From instructions, we extract checklists and evaluate how well responses
satisfy each item - using both AI judges and specialized verifier programs -
then combine these scores to compute rewards for RL. We compare RLCF with other
alignment methods applied to a strong instruction following model
(Qwen2.5-7B-Instruct) on five widely-studied benchmarks -- RLCF is the only
method to improve performance on every benchmark, including a 4-point boost in
hard satisfaction rate on FollowBench, a 6-point increase on InFoBench, and a
3-point rise in win rate on Arena-Hard. These results establish checklist
feedback as a key tool for improving language models' support of queries that
express a multitude of needs.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [161] [PinchBot: Long-Horizon Deformable Manipulation with Guided Diffusion Policy](https://arxiv.org/abs/2507.17846)
*Alison Bartsch,Arvind Car,Amir Barati Farimani*

Main category: cs.RO

TL;DR: 该研究开发了一个名为PinchBot的机器人系统，利用基于捏合的动作，通过扩散策略模型和3D点云嵌入等技术，成功实现了简单陶器的自动制作。


<details>
  <summary>Details</summary>
Motivation: 陶器制作是一个复杂的艺术形式，需要灵巧、精确和精细的动作将粘土块塑造成有意义的3D目标形状。该工作旨在探索机器人如何处理这种高度多模态、长周期的可变形物体操作任务。

Method: 研究提出了PinchBot系统，它是一个目标条件扩散策略模型。该模型结合了预训练的3D点云嵌入、任务进度预测和碰撞约束的动作投影，以实现陶器制作。

Result: PinchBot系统能够成功创建各种简单的陶器目标。

Conclusion: PinchBot证明了利用基于捏合的动作和扩散策略模型，机器人可以有效地处理复杂的可变形物体操作任务，成功制作简单的陶器。

Abstract: Pottery creation is a complicated art form that requires dexterous, precise
and delicate actions to slowly morph a block of clay to a meaningful, and often
useful 3D goal shape. In this work, we aim to create a robotic system that can
create simple pottery goals with only pinch-based actions. This pinch pottery
task allows us to explore the challenges of a highly multi-modal and
long-horizon deformable manipulation task. To this end, we present PinchBot, a
goal-conditioned diffusion policy model that when combined with pre-trained 3D
point cloud embeddings, task progress prediction and collision-constrained
action projection, is able to successfully create a variety of simple pottery
goals. For experimental videos and access to the demonstration dataset, please
visit our project website:
https://sites.google.com/andrew.cmu.edu/pinchbot/home.

</details>


### [162] [A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.17856)
*Dennis Benders,Laura Ferranti,Johannes Köhler*

Main category: cs.RO

TL;DR: 本报告提供了一种基于非线性模型预测控制（NMPC）的逐步方法，旨在实现移动机器人在存在干扰和测量噪声的障碍环境中安全导航。


<details>
  <summary>Details</summary>
Motivation: 在充满障碍的环境中设计一种能确保移动机器人安全导航的模型预测控制（MPC）方案是一项复杂但至关重要的任务，尤其需要处理状态和输入约束、避开障碍物，并应对干扰和测量噪声。

Method: 报告采用逐步方法实现非线性模型预测控制（NMPC）方案，以满足移动机器人的安全导航要求。它旨在将NMPC的理论概念、数学证明与实际实现相结合。

Result: 报告提供了一条从理论概念到数学证明再到实现的实用且易于理解的路径，重点强调了安全性和性能保证，适用于移动机器人导航。

Conclusion: 本报告旨在为研究人员、机器人工程师和实践者提供一个桥梁，帮助他们将理论NMPC公式应用于实际机器人应用中，实现移动机器人的安全导航。

Abstract: Designing a Model Predictive Control (MPC) scheme that enables a mobile robot
to safely navigate through an obstacle-filled environment is a complicated yet
essential task in robotics. In this technical report, safety refers to ensuring
that the robot respects state and input constraints while avoiding collisions
with obstacles despite the presence of disturbances and measurement noise. This
report offers a step-by-step approach to implementing Nonlinear Model
Predictive Control (NMPC) schemes addressing these safety requirements.
Numerous books and survey papers provide comprehensive overviews of linear MPC
(LMPC) \cite{bemporad2007robust,kouvaritakis2016model}, NMPC
\cite{rawlings2017model,allgower2004nonlinear,mayne2014model,grune2017nonlinear,saltik2018outlook},
and their applications in various domains, including robotics
\cite{nascimento2018nonholonomic,nguyen2021model,shi2021advanced,wei2022mpc}.
This report does not aim to replicate those exhaustive reviews. Instead, it
focuses specifically on NMPC as a foundation for safe mobile robot navigation.
The goal is to provide a practical and accessible path from theoretical
concepts to mathematical proofs and implementation, emphasizing safety and
performance guarantees. It is intended for researchers, robotics engineers, and
practitioners seeking to bridge the gap between theoretical NMPC formulations
and real-world robotic applications.
  This report is not necessarily meant to remain fixed over time. If someone
finds an error in the presented theory, please reach out via the given email
addresses. We are happy to update the document if necessary.

</details>


### [163] [OpenNav: Open-World Navigation with Multimodal Large Language Models](https://arxiv.org/abs/2507.18033)
*Mingfeng Yuan,Letian Wang,Steven L. Waslander*

Main category: cs.RO

TL;DR: 本文提出了一种零样本视觉-语言导航框架，利用多模态大语言模型（MLLMs）使机器人能够理解复杂的自然语言指令，并生成轨迹点序列以在开放世界中执行多样化的导航任务。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练大语言模型（LLMs）在机器人导航和规划方面显示出潜力，但如何将语言描述转化为开放世界中实际的机器人动作（而非仅仅调用有限的预定义运动原语）仍然是一个开放挑战。本研究旨在解决机器人理解和分解复杂语言指令，进而合成轨迹点序列以完成开放集指令和开放集对象下的导航任务。

Method: 该方法利用多模态大语言模型（MLLMs）强大的跨模态理解和场景理解能力。更重要的是，利用MLLMs的代码生成能力，使其与视觉-语言感知模型交互，生成组合式的2D鸟瞰图价值地图，有效整合MLLMs的语义知识和地图的空间信息。该框架被设计为零样本视觉-语言导航。

Result: 该方法在大型自动驾驶车辆数据集（AVDs）上进行了户外导航任务的验证，展示了其执行多样化自由形式自然语言导航指令的能力，并对物体检测错误和语言歧义表现出鲁棒性。此外，系统还在Husky机器人上进行了室内外场景的验证，证明了其在真实世界中的鲁棒性和适用性。

Conclusion: 本研究提出的零样本视觉-语言导航框架，通过利用MLLMs的跨模态理解和代码生成能力，成功使机器人能够解释复杂的语言指令并生成轨迹，在开放世界导航任务中表现出强大的适应性和鲁棒性，有效应对了语言歧义和感知误差等挑战。

Abstract: Pre-trained large language models (LLMs) have demonstrated strong
common-sense reasoning abilities, making them promising for robotic navigation
and planning tasks. However, despite recent progress, bridging the gap between
language descriptions and actual robot actions in the open-world, beyond merely
invoking limited predefined motion primitives, remains an open challenge. In
this work, we aim to enable robots to interpret and decompose complex language
instructions, ultimately synthesizing a sequence of trajectory points to
complete diverse navigation tasks given open-set instructions and open-set
objects. We observe that multi-modal large language models (MLLMs) exhibit
strong cross-modal understanding when processing free-form language
instructions, demonstrating robust scene comprehension. More importantly,
leveraging their code-generation capability, MLLMs can interact with
vision-language perception models to generate compositional 2D bird-eye-view
value maps, effectively integrating semantic knowledge from MLLMs with spatial
information from maps to reinforce the robot's spatial understanding. To
further validate our approach, we effectively leverage large-scale autonomous
vehicle datasets (AVDs) to validate our proposed zero-shot vision-language
navigation framework in outdoor navigation tasks, demonstrating its capability
to execute a diverse range of free-form natural language navigation
instructions while maintaining robustness against object detection errors and
linguistic ambiguities. Furthermore, we validate our system on a Husky robot in
both indoor and outdoor scenes, demonstrating its real-world robustness and
applicability. Supplementary videos are available at
https://trailab.github.io/OpenNav-website/

</details>


### [164] [Modular Robot and Landmark Localisation Using Relative Bearing Measurements](https://arxiv.org/abs/2507.18070)
*Behzad Zamani,Jochen Trumpf,Chris Manzie*

Main category: cs.RO

TL;DR: 本文提出了一种模块化非线性最小二乘滤波方法，用于由独立子系统组成的系统，即使存在相对测量，也能独立更新状态和协方差，并通过协方差交集（CI）算法防止信息重复计算，并应用于机器人-地标定位问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理由独立子系统组成且存在跨子系统相对测量的系统时，面临信息重复计算的挑战。研究者希望开发一种模块化方法，能够独立更新各子系统状态，同时有效处理共享信息。

Method: 该方法采用模块化非线性最小二乘滤波，允许每个子系统独立更新其状态和误差协方差。通过将协方差交集（CI）算法集成到解决方案中，并基于最小二乘估计对CI算法进行了替代推导，以防止子系统共享估计时信息重复计算。该方法特别应用于机器人-地标定位问题，其中机器人姿态和地标位置的估计问题通过相对测量耦合。通过随机模拟研究，将所提出的模块化方法与整体联合状态滤波器进行基准测试。

Result: 模拟研究表明，所提出的模块化方法可以与整体联合状态滤波器进行比较，并阐明了它们的权衡。此外，该研究还包括了所提出方法的变体，这些变体在降低通信和带宽要求的同时，实现了性能的平稳下降。

Conclusion: 所提出的模块化非线性最小二乘滤波方法能够有效处理由独立子系统组成的系统，即使存在相对测量也能独立更新。通过集成CI算法，成功解决了信息重复计算的问题。该方法在机器人-地标定位问题中表现出可行性，并在通信和带宽要求方面提供了灵活的性能权衡。

Abstract: In this paper we propose a modular nonlinear least squares filtering approach
for systems composed of independent subsystems. The state and error covariance
estimate of each subsystem is updated independently, even when a relative
measurement simultaneously depends on the states of multiple subsystems. We
integrate the Covariance Intersection (CI) algorithm as part of our solution in
order to prevent double counting of information when subsystems share estimates
with each other. An alternative derivation of the CI algorithm based on least
squares estimation makes this integration possible. We particularise the
proposed approach to the robot-landmark localization problem. In this problem,
noisy measurements of the bearing angle to a stationary landmark position
measured relative to the SE(2) pose of a moving robot couple the estimation
problems for the robot pose and the landmark position. In a randomized
simulation study, we benchmark the proposed modular method against a monolithic
joint state filter to elucidate their respective trade-offs. In this study we
also include variants of the proposed method that achieve a graceful
degradation of performance with reduced communication and bandwidth
requirements.

</details>


### [165] [A Modular Residual Learning Framework to Enhance Model-Based Approach for Robust Locomotion](https://arxiv.org/abs/2507.18138)
*Min-Gyu Kim,Dongyun Kang,Hajun Kim,Hae-Won Park*

Main category: cs.RO

TL;DR: 本文提出一种结合模型基和学习基方法的新型框架，通过残差模块补偿模型失配，实现机器人鲁棒运动。


<details>
  <summary>Details</summary>
Motivation: 现有模型基框架在模型失配或高不确定性环境中性能下降，需要一种方法来弥补这种性能损失。

Method: 将学习基的残差模块集成到模型基框架（包括步态规划器和动力学模型）的各个对应部分，以补偿模型失配。采用模块化结构并为每个残差模块选择合适的学习方法。在四足机器人上结合模型预测控制（MPC）进行验证。

Result: 该框架在高不确定性环境中表现出更好的控制性能和更高的学习效率。此外，它使标称控制器对参数调整更鲁棒。在真实四足机器人上，尽管存在仿真之外的不确定性，机器人仍成功保持平衡并跟踪指令速度。

Conclusion: 所提出的混合框架对于在不确定环境中实现鲁棒机器人运动是可行且有效的，能够提升控制性能并增强控制器对参数调整的鲁棒性。

Abstract: This paper presents a novel approach that combines the advantages of both
model-based and learning-based frameworks to achieve robust locomotion. The
residual modules are integrated with each corresponding part of the model-based
framework, a footstep planner and dynamic model designed using heuristics, to
complement performance degradation caused by a model mismatch. By utilizing a
modular structure and selecting the appropriate learning-based method for each
residual module, our framework demonstrates improved control performance in
environments with high uncertainty, while also achieving higher learning
efficiency compared to baseline methods. Moreover, we observed that our
proposed methodology not only enhances control performance but also provides
additional benefits, such as making nominal controllers more robust to
parameter tuning. To investigate the feasibility of our framework, we
demonstrated residual modules combined with model predictive control in a real
quadrupedal robot. Despite uncertainties beyond the simulation, the robot
successfully maintains balance and tracks the commanded velocity.

</details>


### [166] [Autonomous UAV Navigation for Search and Rescue Missions Using Computer Vision and Convolutional Neural Networks](https://arxiv.org/abs/2507.18160)
*Luka Šiktar,Branimir Ćaran,Bojan Šekoranja,Marko Švaco*

Main category: cs.RO

TL;DR: 本文提出一个基于无人机（UAV）的搜救子系统，结合ROS2框架和多种卷积神经网络（CNN），实现人员检测、面部识别和目标追踪功能，并利用系统辨识和PD控制器进行自主导航和距离保持。


<details>
  <summary>Details</summary>
Motivation: 旨在提升搜救任务的效率和准确性，通过无人机整合先进的视觉识别和追踪技术，实现对失踪人员的自动搜索、识别和持续追踪，以应对传统搜救方式的挑战。

Method: 该系统将无人机与ROS2框架集成，利用YOLOv11和YOLOv11-pose CNN进行人员追踪和关键点识别，使用dlib库的CNN进行面部识别。通过无人机IMU数据进行系统辨识，并设计PD控制器实现自主导航和与目标的安全距离保持。系统支持对已知人员的自动识别追踪，也允许操作员手动录入未知人员信息并启动追踪。

Result: 对14名已知个体的初步实验表明，所提出的子系统能够实时成功运行，验证了其在实际搜救场景中的可行性。

Conclusion: 该无人机搜救子系统在人员检测、面部识别和追踪方面表现出良好的实时性能。下一步计划将系统部署到大型实验无人机上进行现场使用，并集成GPS引导的自主导航功能，以支持更复杂的救援行动规划。

Abstract: In this paper, we present a subsystem, using Unmanned Aerial Vehicles (UAV),
for search and rescue missions, focusing on people detection, face recognition
and tracking of identified individuals. The proposed solution integrates a UAV
with ROS2 framework, that utilizes multiple convolutional neural networks (CNN)
for search missions. System identification and PD controller deployment are
performed for autonomous UAV navigation. The ROS2 environment utilizes the
YOLOv11 and YOLOv11-pose CNNs for tracking purposes, and the dlib library CNN
for face recognition. The system detects a specific individual, performs face
recognition and starts tracking. If the individual is not yet known, the UAV
operator can manually locate the person, save their facial image and
immediately initiate the tracking process. The tracking process relies on
specific keypoints identified on the human body using the YOLOv11-pose CNN
model. These keypoints are used to track a specific individual and maintain a
safe distance. To enhance accurate tracking, system identification is
performed, based on measurement data from the UAVs IMU. The identified system
parameters are used to design PD controllers that utilize YOLOv11-pose to
estimate the distance between the UAVs camera and the identified individual.
The initial experiments, conducted on 14 known individuals, demonstrated that
the proposed subsystem can be successfully used in real time. The next step
involves implementing the system on a large experimental UAV for field use and
integrating autonomous navigation with GPS-guided control for rescue operations
planning.

</details>


### [167] [MoRPI-PINN: A Physics-Informed Framework for Mobile Robot Pure Inertial Navigation](https://arxiv.org/abs/2507.18206)
*Arup Kumar Sahoo,Itzik Klein*

Main category: cs.RO

TL;DR: 本文提出MoRPI-PINN，一个基于物理信息神经网络（PINN）的框架，通过结合机器人蛇形运动和物理约束，显著提升了在无卫星导航或摄像头环境下，仅依靠惯性传感器进行移动机器人导航的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在卫星导航或摄像头不可用的实际场景中，移动机器人需要精确导航。仅依靠惯性传感器会导致导航漂移。蛇形滑行运动可以提高惯性信号信噪比，但仍需更精确的解决方案来利用此信息并减轻漂移。

Method: 提出MoRPI-PINN，一个物理信息神经网络框架。该方法将物理定律和约束嵌入到神经网络的训练过程中，并利用机器人蛇形滑行运动来增强惯性信号，从而实现精确的惯性导航。

Result: 通过真实世界实验证明，MoRPI-PINN相比其他方法，导航精度提高了85%以上。该方法轻量化，可在边缘设备上实现，适用于各种典型的移动机器人应用。

Conclusion: MoRPI-PINN为移动机器人提供了一种准确、鲁棒且轻量级的基于惯性传感器的导航解决方案，即使在GPS或摄像头不可用的挑战性环境中也能有效工作。

Abstract: A fundamental requirement for full autonomy in mobile robots is accurate
navigation even in situations where satellite navigation or cameras are
unavailable. In such practical situations, relying only on inertial sensors
will result in navigation solution drift due to the sensors' inherent noise and
error terms. One of the emerging solutions to mitigate drift is to maneuver the
robot in a snake-like slithering motion to increase the inertial
signal-to-noise ratio, allowing the regression of the mobile robot position. In
this work, we propose MoRPI-PINN as a physics-informed neural network framework
for accurate inertial-based mobile robot navigation. By embedding physical laws
and constraints into the training process, MoRPI-PINN is capable of providing
an accurate and robust navigation solution. Using real-world experiments, we
show accuracy improvements of over 85% compared to other approaches. MoRPI-PINN
is a lightweight approach that can be implemented even on edge devices and used
in any typical mobile robot application.

</details>


### [168] [Evaluation of facial landmark localization performance in a surgical setting](https://arxiv.org/abs/2507.18248)
*Ines Frajtag,Marko Švaco,Filip Šuligoj*

Main category: cs.RO

TL;DR: 该研究测试了MediaPipe算法在受控医疗环境下进行面部特征点检测的性能，发现其在手术照明下对大偏航角和俯仰角的人脸检测精度有显著提升，并讨论了其在医疗程序中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 机器人和计算机视觉在医学领域应用日益广泛，但现有的面部检测算法在可变光照条件和灵活检测位置下识别和精确定位患者面临挑战。本研究旨在解决这一问题，提升面部检测在手术环境下的鲁棒性。

Method: 实验在一个受控环境中进行，使用机械臂自动调整检测位置，同时手术灯和人体模型保持固定。研究人员测试了MediaPipe算法在这些条件下检测面部特征点的性能。

Result: 研究结果表明，在手术照明下，MediaPipe算法的面部特征点检测精度得到显著提高，尤其是在较大的偏航角和俯仰角下，检测性能有明显增强。然而，部分选定特征点的检测精度不高导致标准差/离散度增加。

Conclusion: 该分析为MediaPipe算法潜在地整合到医疗程序中提供了讨论基础，表明其在特定光照和姿态条件下具有良好的应用前景，但需进一步解决某些特征点检测的精度问题。

Abstract: The use of robotics, computer vision, and their applications is becoming
increasingly widespread in various fields, including medicine. Many face
detection algorithms have found applications in neurosurgery, ophthalmology,
and plastic surgery. A common challenge in using these algorithms is variable
lighting conditions and the flexibility of detection positions to identify and
precisely localize patients. The proposed experiment tests the MediaPipe
algorithm for detecting facial landmarks in a controlled setting, using a
robotic arm that automatically adjusts positions while the surgical light and
the phantom remain in a fixed position. The results of this study demonstrate
that the improved accuracy of facial landmark detection under surgical lighting
significantly enhances the detection performance at larger yaw and pitch
angles. The increase in standard deviation/dispersion occurs due to imprecise
detection of selected facial landmarks. This analysis allows for a discussion
on the potential integration of the MediaPipe algorithm into medical
procedures.

</details>


### [169] [ReSem3D: Refinable 3D Spatial Constraints via Fine-Grained Semantic Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2507.18262)
*Chenyu Su,Weiwei Shang,Chen Qian,Fei Zhang,Shuang Cong*

Main category: cs.RO

TL;DR: ReSem3D是一个统一的机器人操作框架，利用多模态大语言模型（MLLMs）和视觉基础模型（VFMs）的协同作用，实现细粒度视觉定位和动态构建分层3D空间约束，以在语义多样化的环境中进行实时操作。


<details>
  <summary>Details</summary>
Motivation: 现有方法在机器人操作中存在三个主要限制：1) 约束建模的语义粒度粗糙；2) 缺乏实时闭环规划；3) 在语义多样化环境中鲁棒性受损。

Method: ReSem3D框架通过MLLMs的分层递归推理驱动，MLLMs与VFMs交互，从自然语言指令和RGB-D观测中自动构建3D空间约束。该构建分为两阶段：部件级提取和区域级细化。随后，这些约束被编码为关节空间中的实时优化目标，以实现对动态干扰的反应性行为。

Result: 在语义丰富的家庭和稀疏的化学实验室环境中进行了广泛的模拟和真实世界实验。结果表明，ReSem3D在零样本条件下执行了多样化的操作任务，展示了强大的适应性和泛化能力。

Conclusion: ReSem3D成功地解决了现有方法在语义粒度、实时规划和环境鲁棒性方面的挑战，为在多样化环境中进行机器人操作提供了一个统一且高效的解决方案。

Abstract: Semantics-driven 3D spatial constraints align highlevel semantic
representations with low-level action spaces, facilitating the unification of
task understanding and execution in robotic manipulation. The synergistic
reasoning of Multimodal Large Language Models (MLLMs) and Vision Foundation
Models (VFMs) enables cross-modal 3D spatial constraint construction.
Nevertheless, existing methods have three key limitations: (1) coarse semantic
granularity in constraint modeling, (2) lack of real-time closed-loop planning,
(3) compromised robustness in semantically diverse environments. To address
these challenges, we propose ReSem3D, a unified manipulation framework for
semantically diverse environments, leveraging the synergy between VFMs and
MLLMs to achieve fine-grained visual grounding and dynamically constructs
hierarchical 3D spatial constraints for real-time manipulation. Specifically,
the framework is driven by hierarchical recursive reasoning in MLLMs, which
interact with VFMs to automatically construct 3D spatial constraints from
natural language instructions and RGB-D observations in two stages: part-level
extraction and region-level refinement. Subsequently, these constraints are
encoded as real-time optimization objectives in joint space, enabling reactive
behavior to dynamic disturbances. Extensive simulation and real-world
experiments are conducted in semantically rich household and sparse chemical
lab environments. The results demonstrate that ReSem3D performs diverse
manipulation tasks under zero-shot conditions, exhibiting strong adaptability
and generalization. Code and videos at https://resem3d.github.io.

</details>


### [170] [Adaptive Articulated Object Manipulation On The Fly with Foundation Model Reasoning and Part Grounding](https://arxiv.org/abs/2507.18276)
*Xiaojie Zhang,Yuanfei Wang,Ruihai Wu,Kunqi Xu,Yu Li,Liuyu Xiang,Hao Dong,Zhaofeng He*

Main category: cs.RO

TL;DR: AdaRPG是一个利用基础模型进行关节物体操作的新框架，通过提取物体部件并结合部分级功能推断和高层控制代码，实现了对新型关节物体的强大泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在自适应关节物体操作中面临两大挑战：一是真实世界关节物体的几何多样性导致视觉感知和理解困难；二是物体功能和机制的差异阻碍了统一自适应操作策略的开发。

Method: AdaRPG框架利用基础模型提取物体部件（其局部几何相似性高于整体物体），以增强功能性基本技能的视觉可供性泛化。为此，构建了部件级可供性标注数据集来训练可供性模型。此外，AdaRPG利用基础模型中的常识来推理复杂机制，并基于部件可供性推断生成调用基本技能函数的高层控制代码。

Result: 仿真和真实世界实验证明了AdaRPG在新型关节物体类别上的强大泛化能力。

Conclusion: AdaRPG通过利用基础模型提取部件并结合部分级可供性推断和高层控制代码，有效解决了关节物体操作中的几何多样性和机制差异挑战，实现了对未知关节物体的泛化操作。

Abstract: Articulated objects pose diverse manipulation challenges for robots. Since
their internal structures are not directly observable, robots must adaptively
explore and refine actions to generate successful manipulation trajectories.
While existing works have attempted cross-category generalization in adaptive
articulated object manipulation, two major challenges persist: (1) the
geometric diversity of real-world articulated objects complicates visual
perception and understanding, and (2) variations in object functions and
mechanisms hinder the development of a unified adaptive manipulation strategy.
To address these challenges, we propose AdaRPG, a novel framework that
leverages foundation models to extract object parts, which exhibit greater
local geometric similarity than entire objects, thereby enhancing visual
affordance generalization for functional primitive skills. To support this, we
construct a part-level affordance annotation dataset to train the affordance
model. Additionally, AdaRPG utilizes the common knowledge embedded in
foundation models to reason about complex mechanisms and generate high-level
control codes that invoke primitive skill functions based on part affordance
inference. Simulation and real-world experiments demonstrate AdaRPG's strong
generalization ability across novel articulated object categories.

</details>


### [171] [AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments](https://arxiv.org/abs/2507.18317)
*Chenglong Qian,Yang Xu,Xiufang Shi,Jiming Chen,Liang Li*

Main category: cs.RO

TL;DR: 该论文提出AF-RLIO，一种自适应多传感器融合方法，整合4D毫米波雷达、激光雷达、惯性测量单元（IMU）和GPS，以在复杂环境中实现鲁棒的里程计估计。


<details>
  <summary>Details</summary>
Motivation: 在机器人导航中，单传感器系统（如激光雷达或GPS）在烟雾、隧道和恶劣天气等复杂动态环境中性能会显著下降，从而影响自主机器人的稳定性和安全性。

Method: 该方法包含三个核心模块：1. 预处理模块：利用雷达数据辅助激光雷达去除动态点，并判断激光雷达环境条件何时恶化。2. 动态感知多模态里程计：选择合适的点云数据进行扫描到地图匹配，并使用迭代误差状态卡尔曼滤波器与IMU紧密耦合。3. 因子图优化模块：平衡里程计和GPS数据之间的权重，构建姿态图进行优化。

Result: 该方法已在数据集和真实机器人环境中进行评估和测试，结果表明在烟雾和隧道等挑战性条件下，其有效性优于现有方法。

Conclusion: 所提出的自适应融合方法在复杂和动态环境中，通过结合多种传感器的互补优势，显著提高了机器人姿态估计和导航的鲁棒性。

Abstract: In robotic navigation, maintaining precise pose estimation and navigation in
complex and dynamic environments is crucial. However, environmental challenges
such as smoke, tunnels, and adverse weather can significantly degrade the
performance of single-sensor systems like LiDAR or GPS, compromising the
overall stability and safety of autonomous robots. To address these challenges,
we propose AF-RLIO: an adaptive fusion approach that integrates 4D
millimeter-wave radar, LiDAR, inertial measurement unit (IMU), and GPS to
leverage the complementary strengths of these sensors for robust odometry
estimation in complex environments. Our method consists of three key modules.
Firstly, the pre-processing module utilizes radar data to assist LiDAR in
removing dynamic points and determining when environmental conditions are
degraded for LiDAR. Secondly, the dynamic-aware multimodal odometry selects
appropriate point cloud data for scan-to-map matching and tightly couples it
with the IMU using the Iterative Error State Kalman Filter. Lastly, the factor
graph optimization module balances weights between odometry and GPS data,
constructing a pose graph for optimization. The proposed approach has been
evaluated on datasets and tested in real-world robotic environments,
demonstrating its effectiveness and advantages over existing methods in
challenging conditions such as smoke and tunnels.

</details>


### [172] [G2S-ICP SLAM: Geometry-aware Gaussian Splatting ICP SLAM](https://arxiv.org/abs/2507.18344)
*Gyuhyeon Pak,Hae Min Cho,Euntai Kim*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的几何感知RGB-D高斯溅射SLAM系统G2S-ICP SLAM，通过将场景元素表示为受局部切平面约束的2D高斯盘，实现了实时高保真3D重建和鲁棒的相机位姿跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统基于3D椭球体且具有各向同性不确定性的表示方法在多视角下深度解释一致性较差。本研究旨在通过引入与底层几何对齐的2D高斯盘，更有效地建模局部表面，从而实现更一致的深度解释和更高保真度的重建。

Method: 该方法将每个场景元素表示为受局部切平面约束的高斯分布（2D高斯盘）。通过引入各向异性协方差先验，将表面对齐的高斯盘嵌入到广义ICP框架中，同时不改变底层配准公式。此外，提出了一个几何感知损失函数，用于监督光度、深度和法线一致性。

Result: G2S-ICP SLAM系统实现了实时操作，并保持了视觉和几何保真度。在Replica和TUM-RGBD数据集上的大量实验表明，该系统在定位精度和重建完整性方面优于现有SLAM系统，同时保持了渲染质量。

Conclusion: G2S-ICP SLAM是一种有效的几何感知RGB-D SLAM系统，通过创新的2D高斯盘表示和优化的ICP框架，实现了实时、高保真的3D重建和鲁棒的相机位姿跟踪，并在性能上超越了现有方法。

Abstract: In this paper, we present a novel geometry-aware RGB-D Gaussian Splatting
SLAM system, named G2S-ICP SLAM. The proposed method performs high-fidelity 3D
reconstruction and robust camera pose tracking in real-time by representing
each scene element using a Gaussian distribution constrained to the local
tangent plane. This effectively models the local surface as a 2D Gaussian disk
aligned with the underlying geometry, leading to more consistent depth
interpretation across multiple viewpoints compared to conventional 3D
ellipsoid-based representations with isotropic uncertainty. To integrate this
representation into the SLAM pipeline, we embed the surface-aligned Gaussian
disks into a Generalized ICP framework by introducing anisotropic covariance
prior without altering the underlying registration formulation. Furthermore we
propose a geometry-aware loss that supervises photometric, depth, and normal
consistency. Our system achieves real-time operation while preserving both
visual and geometric fidelity. Extensive experiments on the Replica and
TUM-RGBD datasets demonstrate that G2S-ICP SLAM outperforms prior SLAM systems
in terms of localization accuracy, reconstruction completeness, while
maintaining the rendering quality.

</details>


### [173] [Residual Koopman Model Predictive Control for Enhanced Vehicle Dynamics with Small On-Track Data Input](https://arxiv.org/abs/2507.18396)
*Yonghao Fu,Cheng Hu,Haokun Xiong,Zhangpeng Bao,Wenyuan Du,Edoardo Ghignone,Michele Magno,Lei Xie,Hongye Su*

Main category: cs.RO

TL;DR: 本文提出残差Koopman模型预测控制（RKMPC）框架，结合线性运动学模型和神经网络残差补偿，解决了传统方法在车辆轨迹跟踪中模型精度与计算效率的权衡问题，显著提升了跟踪性能和数据效率。


<details>
  <summary>Details</summary>
Motivation: 纯追踪控制未考虑车辆模型约束，影响安全；模型预测控制（MPC）性能依赖于车辆模型精度；传统车辆建模在捕获非线性动力学与保持计算效率之间存在固有限制，导致控制性能下降。

Method: 提出残差Koopman模型预测控制（RKMPC）框架，采用双线性MPC架构：一个基于车辆运动学模型的线性MPC（LMPC）计算基线控制输入；一个基于神经网络的RKMPC计算补偿输入。最终控制指令由两者叠加得到，旨在保留传统机械模型可靠性和可解释性的同时，通过残差建模优化性能。

Result: RKMPC在Carsim-Matlab联合仿真平台和1:10 F1TENTH赛车上验证。与传统Koopman模型预测控制（KMPC）相比，RKMPC仅需20%的训练数据即可提供更优的跟踪性能。与传统LMPC相比，RKMPC横向误差降低11.7%-22.1%，航向误差降低8.9%-15.8%，前轮转向稳定性提高高达27.6%。

Conclusion: RKMPC通过结合传统机械模型和残差神经网络补偿，成功解决了车辆轨迹跟踪中模型精度和计算效率的矛盾，在保持模型可解释性的同时，显著提升了跟踪性能、转向稳定性，并大幅降低了对训练数据的需求。

Abstract: In vehicle trajectory tracking tasks, the simplest approach is the Pure
Pursuit (PP) Control. However, this single-point preview tracking strategy
fails to consider vehicle model constraints, compromising driving safety. Model
Predictive Control (MPC) as a widely adopted control method, optimizes control
actions by incorporating mechanistic models and physical constraints. While its
control performance critically depends on the accuracy of vehicle modeling.
Traditional vehicle modeling approaches face inherent trade-offs between
capturing nonlinear dynamics and maintaining computational efficiency, often
resulting in reduced control performance. To address these challenges, this
paper proposes Residual Koopman Model Predictive Control (RKMPC) framework.
This method uses two linear MPC architecture to calculate control inputs: a
Linear Model Predictive Control (LMPC) computes the baseline control input
based on the vehicle kinematic model, and a neural network-based RKMPC
calculates the compensation input. The final control command is obtained by
adding these two components. This design preserves the reliability and
interpretability of traditional mechanistic model while achieving performance
optimization through residual modeling. This method has been validated on the
Carsim-Matlab joint simulation platform and a physical 1:10 scale F1TENTH
racing car. Experimental results show that RKMPC requires only 20% of the
training data needed by traditional Koopman Model Predictive Control (KMPC)
while delivering superior tracking performance. Compared to traditional LMPC,
RKMPC reduces lateral error by 11.7%-22.1%, decreases heading error by
8.9%-15.8%, and improves front-wheel steering stability by up to 27.6%. The
implementation code is available at: https://github.com/ZJU-DDRX/Residual
Koopman.

</details>


### [174] [Evaluating the Pre-Dressing Step: Unfolding Medical Garments Via Imitation Learning](https://arxiv.org/abs/2507.18436)
*David Blanco-Mulero,Júlia Borràs,Carme Torras*

Main category: cs.RO

TL;DR: 本文提出并解决了机器人辅助穿衣前的“预穿衣”步骤，即展开折叠衣物的问题，通过模仿学习和视觉分类器实现了衣物展开，并评估了不同操作策略的效果。


<details>
  <summary>Details</summary>
Motivation: 现有机器人辅助穿衣研究通常假设衣物已展开，但在医疗应用中，手术服等衣物常是折叠存放的，需要额外的展开步骤，这增加了医护人员的负担和效率问题。

Method: 引入“预穿衣”步骤，即在辅助穿衣前展开衣物。利用模仿学习训练了三种操作原语（包括高低加速运动）。采用视觉分类器将衣物状态分为闭合、部分打开和完全打开。对学习到的操作原语及其组合进行了实证评估。

Result: 研究结果表明，对于刚拆封的衣物，高度动态的运动在展开方面效果不佳。而操作原语的组合可以有效地改善衣物的打开状态。

Conclusion: 在机器人辅助穿衣中，衣物展开（预穿衣步骤）是必不可少且具有挑战性的一步。对于新拆封的衣物，需要特定的操作策略，特别是结合多种运动方式能更有效地实现衣物展开。

Abstract: Robotic-assisted dressing has the potential to significantly aid both
patients as well as healthcare personnel, reducing the workload and improving
the efficiency in clinical settings. While substantial progress has been made
in robotic dressing assistance, prior works typically assume that garments are
already unfolded and ready for use. However, in medical applications gowns and
aprons are often stored in a folded configuration, requiring an additional
unfolding step. In this paper, we introduce the pre-dressing step, the process
of unfolding garments prior to assisted dressing. We leverage imitation
learning for learning three manipulation primitives, including both high and
low acceleration motions. In addition, we employ a visual classifier to
categorise the garment state as closed, partly opened, and fully opened. We
conduct an empirical evaluation of the learned manipulation primitives as well
as their combinations. Our results show that highly dynamic motions are not
effective for unfolding freshly unpacked garments, where the combination of
motions can efficiently enhance the opening configuration.

</details>


### [175] [A Novel Monte-Carlo Compressed Sensing and Dictionary Learning Method for the Efficient Path Planning of Remote Sensing Robots](https://arxiv.org/abs/2507.18462)
*Alghalya Al-Hajri,Ejmen Al-Ubejdij,Aiman Erbad,Ali Safa*

Main category: cs.RO

TL;DR: 本文提出一种新颖的蒙特卡洛优化框架，结合字典学习，为机器人环境数据采集设计优化的压缩感知采样轨迹，旨在最小化机器人行程并提高信号重建精度。


<details>
  <summary>Details</summary>
Motivation: 近年来，压缩感知（CS）因其能用更少测量获取高分辨率数据而备受关注，同时自主机器人平台在远程传感和环境监测中日益普及。研究的动机在于探索如何利用CS测量矩阵的结构来设计优化的机器人采样轨迹，以同时减少机器人路径长度和信号重建误差。

Method: 本文提出一个蒙特卡洛优化框架，生成测量矩阵以最小化机器人遍历路径长度和信号重建误差。核心方法是应用字典学习（DL）来获取数据驱动的稀疏变换，以提高重建精度并进一步减少机器人所需采集的样本数量。

Result: 实验表明，该方法能将机器人行程减少到全覆盖路径的不到10%，同时重建精度比基于DCT和多项式字典的传统CS方法提高五倍以上，比现有信息路径规划（IPP）方法提高两倍。效果在海湾地区的$NO_2$污染地图重建中得到验证。

Conclusion: 所提出的方法成功地利用压缩感知测量矩阵结构，通过蒙特卡洛优化和字典学习，显著优化了机器人环境数据采集的采样轨迹，大幅减少了机器人行程并显著提高了数据重建精度。

Abstract: In recent years, Compressed Sensing (CS) has gained significant interest as a
technique for acquiring high-resolution sensory data using fewer measurements
than traditional Nyquist sampling requires. At the same time, autonomous
robotic platforms such as drones and rovers have become increasingly popular
tools for remote sensing and environmental monitoring tasks, including
measurements of temperature, humidity, and air quality. Within this context,
this paper presents, to the best of our knowledge, the first investigation into
how the structure of CS measurement matrices can be exploited to design
optimized sampling trajectories for robotic environmental data collection. We
propose a novel Monte Carlo optimization framework that generates measurement
matrices designed to minimize both the robot's traversal path length and the
signal reconstruction error within the CS framework. Central to our approach is
the application of Dictionary Learning (DL) to obtain a data-driven sparsifying
transform, which enhances reconstruction accuracy while further reducing the
number of samples that the robot needs to collect. We demonstrate the
effectiveness of our method through experiments reconstructing $NO_2$ pollution
maps over the Gulf region. The results indicate that our approach can reduce
robot travel distance to less than $10\%$ of a full-coverage path, while
improving reconstruction accuracy by over a factor of five compared to
traditional CS methods based on DCT and polynomial dictionaries, as well as by
a factor of two compared to previously-proposed Informative Path Planning (IPP)
methods.

</details>


### [176] [Experimental Comparison of Whole-Body Control Formulations for Humanoid Robots in Task Acceleration and Task Force Spaces](https://arxiv.org/abs/2507.18502)
*Sait Sovukluk,Grazia Zambella,Tobias Egle,Christian Ott*

Main category: cs.RO

TL;DR: 本文通过实验比较了两种不同的人形机器人全身控制方法：逆动力学全身控制（ID-WBC）和基于无源性的全身控制（PB-WBC），分析它们在实际条件下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管ID-WBC和PB-WBC在理想条件下都能预测闭环动力学稳定性，但它们对关节摩擦、传感器噪声、未建模外部扰动和非完美接触等实际因素的鲁棒性尚不明确。

Method: 在人形机器人平台上，通过摆动脚位姿控制、负重深蹲（有无额外重量）和跳跃等实验，对ID-WBC和PB-WBC两种控制器进行分析和比较。同时，将观察到的性能和特性差异与控制器公式关联起来。

Result: 通过实验，本文分析并比较了两种控制器在不同任务下的性能和特性差异，并指出了每种控制器的优缺点。

Conclusion: 根据实验观察到的性能和特性差异，本文总结了ID-WBC和PB-WBC两种控制器的优缺点，并将其与各自的公式联系起来。

Abstract: This paper studies the experimental comparison of two different whole-body
control formulations for humanoid robots: inverse dynamics whole-body control
(ID-WBC) and passivity-based whole-body control (PB-WBC). The two controllers
fundamentally differ from each other as the first is formulated in task
acceleration space and the latter is in task force space with passivity
considerations. Even though both control methods predict stability under ideal
conditions in closed-loop dynamics, their robustness against joint friction,
sensor noise, unmodeled external disturbances, and non-perfect contact
conditions is not evident. Therefore, we analyze and experimentally compare the
two controllers on a humanoid robot platform through swing foot position and
orientation control, squatting with and without unmodeled additional weights,
and jumping. We also relate the observed performance and characteristic
differences with the controller formulations and highlight each controller's
advantages and disadvantages.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [177] [Safe Reinforcement Learning-based Automatic Generation Control](https://arxiv.org/abs/2507.17868)
*Amr S. Mohamed,Emily Nguyen,Deepa Kundur*

Main category: eess.SY

TL;DR: 本文提出一个基于控制障碍函数(CBF)的框架，以实现强化学习(RL)智能体在电力系统自动发电控制(AGC)中的安全学习和部署。


<details>
  <summary>Details</summary>
Motivation: 电力系统对先进控制和决策算法的需求日益增长，以提高可靠性、韧性和稳定性。然而，机器学习技术在提供更优控制决策的同时，往往缺乏安全保障，这是其应用的关键担忧。

Method: 本文提出一个基于控制障碍函数(CBF)的框架，用于促进强化学习(RL)智能体在电力系统控制（特别是自动发电控制）中的安全学习和部署。研究开发了必要的安全障碍和强化学习框架。

Result: 研究开发了安全障碍和强化学习框架，旨在建立对强化学习作为自动发电控制安全选项的信任。

Conclusion: 该框架为未来在自动发电控制中详细验证和应用强化学习奠定了基础。

Abstract: Amidst the growing demand for implementing advanced control and
decision-making algorithms|to enhance the reliability, resilience, and
stability of power systems|arises a crucial concern regarding the safety of
employing machine learning techniques. While these methods can be applied to
derive more optimal control decisions, they often lack safety assurances. This
paper proposes a framework based on control barrier functions to facilitate
safe learning and deployment of reinforcement learning agents for power system
control applications, specifically in the context of automatic generation
control. We develop the safety barriers and reinforcement learning framework
necessary to establish trust in reinforcement learning as a safe option for
automatic generation control - as foundation for future detailed verification
and application studies.

</details>


### [178] [Trusted Data Fusion, Multi-Agent Autonomy, Autonomous Vehicles](https://arxiv.org/abs/2507.17875)
*R. Spencer Hallyburton,Miroslav Pajic*

Main category: eess.SY

TL;DR: 本文提出一个基于隐马尔可夫模型（HMM）的去中心化信任框架，用于多智能体网络中的可靠传感器融合，以应对网络物理攻击，提升情报、监视和侦察（ISR）任务的性能和恶意行为者检测能力。


<details>
  <summary>Details</summary>
Motivation: 多智能体无人机（UAV）特设网络虽能增强ISR任务中的态势感知，但其去中心化特性使其易受网络物理攻击，面临严峻的安全挑战。

Method: 引入一个基于信任的框架，利用隐马尔可夫模型（HMM）去中心化地评估智能体及其提供信息的信任度。信任感知的融合优先处理来自可靠来源的数据，以增强韧性和准确性。为评估该方法，作者构建了一个基于虚幻引擎模拟器的新型多智能体空中数据集。

Result: 通过案例研究，证明了该方法能够提高ISR性能，并在对抗环境中有效检测恶意行为者。

Conclusion: 所提出的信任框架通过确保传感器融合的可靠性，显著提升了多智能体ISR系统在面临攻击时的韧性和准确性，并能有效识别恶意节点。

Abstract: Multi-agent collaboration enhances situational awareness in intelligence,
surveillance, and reconnaissance (ISR) missions. Ad hoc networks of unmanned
aerial vehicles (UAVs) allow for real-time data sharing, but they face security
challenges due to their decentralized nature, making them vulnerable to
cyber-physical attacks. This paper introduces a trust-based framework for
assured sensor fusion in distributed multi-agent networks, utilizing a hidden
Markov model (HMM)-based approach to estimate the trustworthiness of agents and
their provided information in a decentralized fashion. Trust-informed data
fusion prioritizes fusing data from reliable sources, enhancing resilience and
accuracy in contested environments. To evaluate the assured sensor fusion under
attacks on system/mission sensing, we present a novel multi-agent aerial
dataset built from the Unreal Engine simulator. We demonstrate through case
studies improved ISR performance and an ability to detect malicious actors in
adversarial settings.

</details>


### [179] [Rapid Modeling Architecture for Lightweight Simulator to Accelerate and Improve Decision Making for Industrial Systems](https://arxiv.org/abs/2507.17990)
*Takumi Kato,Zhi Li Hu*

Main category: eess.SY

TL;DR: 本文提出了一种名为快速建模架构（RMA）的轻量级工业模拟器，旨在显著减少建模时间，以加速和改进工业系统设计早期阶段的决策。


<details>
  <summary>Details</summary>
Motivation: 工业系统（如配送中心和制造工厂）在早期设计阶段面临信息有限的问题，导致设计不准确且后期难以纠正。传统模拟器建模时间过长，无法满足快速决策的需求。

Method: 提出并设计了一种名为快速建模架构（RMA）的轻量级工业模拟器。基于RMA原型化了一个模拟器，并将其应用于实际的工厂布局设计问题。将该模拟器的建模时间与现有模拟器进行了比较。

Result: 与传统模拟器相比，基于RMA的原型模拟器将建模时间减少了78.3%。

Conclusion: RMA能够有效减轻建模负担，同时保留关键细节，从而加速并改进工业系统设计中的决策过程。

Abstract: Designing industrial systems, such as building, improving, and automating
distribution centers and manufacturing plants, involves critical
decision-making with limited information in the early phases. The lack of
information leads to less accurate designs of the systems, which are often
difficult to resolve later. It is effective to use simulators to model the
designed system and find out the issues early. However, the modeling time
required by conventional simulators is too long to allow for rapid model
creation to meet decision-making demands. In this paper, we propose a Rapid
Modeling Architecture (RMA) for a lightweight industrial simulator that
mitigates the modeling burden while maintaining the essential details in order
to accelerate and improve decision-making. We have prototyped a simulator based
on the RMA and applied it to the actual factory layout design problem. We also
compared the modeling time of our simulator to that of an existing simulator,
and as a result, our simulator achieved a 78.3% reduction in modeling time
compared to conventional simulators.

</details>


### [180] [Quantitative Damping Calculation and Compensation Method for Global Stability Improvement of Inverter-Based Systems](https://arxiv.org/abs/2507.18001)
*Yang Li,Zenghui Zheng,Xiangyang Wu,Jiayong Li,Wei Wang,Qiang Zeng,Zhikang Shuai*

Main category: eess.SY

TL;DR: 该论文提出了一种定量阻尼计算与补偿方法，以有效增强多逆变器系统的全局稳定性。


<details>
  <summary>Details</summary>
Motivation: 多逆变器系统中的小信号稳定性问题引发的宽带振荡严重威胁系统安全运行。现有研究已揭示系统不稳定性源于正阻尼不足，但尚未明确为确保系统全局稳定性所需阻尼补偿的确切量。

Method: 首先，基于系统节点导纳模型，提出了一种定量阻尼计算算法，能够给出所需的阻尼补偿量和补偿位置。其次，提出了一种带有输出电流前馈控制的特定有源阻尼器（AD）策略，使其呈现准纯电阻特性，有效提高系统阻尼效率。

Result: 通过一个包含三个逆变器的测试系统案例研究表明，所提出的方法为有效提升基于逆变器系统的全局稳定性提供了一个有前景的解决方案。仿真和实验验证了该方法的有效性。

Conclusion: 该研究提供了一种可行的定量阻尼计算与补偿方案，能够有效增强基于逆变器系统的全局稳定性，解决了传统方法在确定所需阻尼量方面的不足。

Abstract: Small-signal stability issues-induced broadband oscillations pose significant
threats to the secure operation of multi-inverter systems, attracting extensive
research attention. Researches revealed that system instability is led by the
lacking of positive damping, yet it has not been clearly specified how much the
exact amount of damping compensation required to sufficiently ensure system
global stability. This paper presents a feasible solution for quantitative
damping calculation and compensation to enhance the global stability of
inverter-based systems. First, based on the system nodal admittance model, a
quantitative damping calculation algorithm is presented, which can suggest the
required damping compensation as well as compensation location for sufficient
stability improvement. Then, we propose a specific AD with output current
feedforward control strategy, which make the AD be quasi-pure resistive and can
effectively enhance system damping efficiency. Finally, a testing system with
three inverters is used as case study, showing that the proposed method
provides a promising solution to efficiently enhance the global stability
improvement of inverter-based systems. Simulations and experiments validate the
proposed method.

</details>


### [181] [Carbon Emission Flow Tracing: Fast Algorithm and California Grid Study](https://arxiv.org/abs/2507.18077)
*Yuqing Shen,Yuanyuan Shi,Daniel Kirschen,Yize Chen*

Main category: eess.SY

TL;DR: 本文提出了一种新颖且计算高效的方法，用于精确量化电网中节点的平均和边际碳排放率，揭示了发电机排放如何通过电网传输并影响特定位置的用户，并通过加州电网的模拟进行了验证。


<details>
  <summary>Details</summary>
Motivation: 尽管电力系统运营商和公用事业公司日益公开系统层面的碳排放信息，但目前尚不清楚单个发电机的排放如何通过电网传输，以及它们如何影响特定位置的电力用户。

Method: 该方法利用图论中的拓扑排序和有向环移除技术，应用于由发电调度和最优潮流解形成的有向图。该算法能高效识别每个发电机对每个节点的贡献，捕捉不同系统条件下排放的空间分布。通过使用真实的CAISO数据和CATS模型，对8,870总线的加州电网进行了一年的逐小时模拟以验证其有效性。

Result: 该方法能够准确估计潮流条件、发电组合和全系统排放，并为加州每个县提供了细粒度的时空排放分析。模拟结果揭示了现实世界中的位置和时间排放模式。

Conclusion: 所提出的算法和加州案例研究均已开源，为未来电网排放、规划、运营和能源政策方面的研究奠定了基础。

Abstract: Power systems decarbonization are at the focal point of the clean energy
transition. While system operators and utility companies increasingly publicize
system-level carbon emission information, it remains unclear how emissions from
individual generators are transported through the grid and how they impact
electricity users at specific locations. This paper presents a novel and
computationally efficient approach for exact quantification of nodal average
and marginal carbon emission rates, applicable to both AC and DC optimal power
flow problems. The approach leverages graph-based topological sorting and
directed cycle removal techniques, applied to directed graphs formed by
generation dispatch and optimal power flow solutions. Our proposed algorithm
efficiently identifies each generator's contribution to each node, capturing
how emissions are spatially distributed under varying system conditions. To
validate its effectiveness and reveal locational and temporal emission patterns
in the real world, we simulate the 8,870-bus realistic California grid using
actual CAISO data and the CATS model. Based on year long hourly data on nodal
loads and renewable generation, obtained or estimated from CAISO public data,
our method accurately estimates power flow conditions, generation mixes, and
systemwide emissions, and delivers fine grained spatiotemporal emission
analysis for every California county. Both our algorithm and the California
study are open-sourced, providing a foundation for future research on grid
emissions, planning, operations, and energy policy.

</details>


### [182] [Towards Microgrid Resilience Enhancement via Mobile Power Sources and Repair Crews: A Multi-Agent Reinforcement Learning Approach](https://arxiv.org/abs/2507.18095)
*Yi Wang,Dawei Qiu,Fei Teng,Goran Strbac*

Main category: eess.SY

TL;DR: 本文提出了一种去中心化的分层多智能体强化学习方法，用于在通信网络受损后，协调移动电源（MPSs）和抢修队伍（RCs）以提升微电网的韧性，实现负荷恢复。


<details>
  <summary>Details</summary>
Motivation: 现有研究在协调MPSs和RCs时，通常假设通信网络在事件后仍能完全正常运行，并采用集中式调度。然而，极端事件可能损坏通信基础设施，导致集中式决策变得不切实际，因此需要一种去中心化的解决方案。

Method: 本文将MPSs和RCs的韧性驱动调度问题建模为去中心化框架。为解决此问题，提出了一种分层多智能体强化学习方法：高层动作用于在电力和交通网络间切换决策；低层动作通过混合策略计算电力网络的连续调度和交通网络的离散路径决策。该方法还嵌入了封装系统动态的函数，以增强学习的稳定性和可扩展性。

Result: 基于IEEE 33节点和69节点电力网络的案例研究验证了所提方法在负荷恢复方面的有效性。

Conclusion: 所提出的去中心化分层多智能体强化学习方法，能够有效协调移动电源和抢修队伍，以增强微电网的韧性，尤其是在通信受损的复杂环境下。

Abstract: Mobile power sources (MPSs) have been gradually deployed in microgrids as
critical resources to coordinate with repair crews (RCs) towards resilience
enhancement owing to their flexibility and mobility in handling the complex
coupled power-transport systems. However, previous work solves the coordinated
dispatch problem of MPSs and RCs in a centralized manner with the assumption
that the communication network is still fully functioning after the event.
However, there is growing evidence that certain extreme events will damage or
degrade communication infrastructure, which makes centralized decision making
impractical. To fill this gap, this paper formulates the resilience-driven
dispatch problem of MPSs and RCs in a decentralized framework. To solve this
problem, a hierarchical multi-agent reinforcement learning method featuring a
two-level framework is proposed, where the high-level action is used to switch
decision-making between power and transport networks, and the low-level action
constructed via a hybrid policy is used to compute continuous scheduling and
discrete routing decisions in power and transport networks, respectively. The
proposed method also uses an embedded function encapsulating system dynamics to
enhance learning stability and scalability. Case studies based on IEEE 33-bus
and 69-bus power networks are conducted to validate the effectiveness of the
proposed method in load restoration.

</details>


### [183] [Regional Frequency-Constrained Planning for the Optimal Sizing of Power Systems via Enhanced Input Convex Neural Networks](https://arxiv.org/abs/2507.18102)
*Yi Wang,Goran Strbac*

Main category: eess.SY

TL;DR: 针对可再生能源高渗透下电力系统区域频率安全规划问题，提出一种新型规划模型，通过增强型ICNN提取区域频率约束，并结合自适应遗传算法求解，以确保区域系统安全并优化投资决策。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源渗透率提高，电力系统惯量降低，频率响应需求增加。现有频率安全模型多考虑统一频率安全，忽略了不同区域的频率空间差异和区域间振荡。

Method: 本文提出一种考虑区域频率安全和区域间频率振荡的电力系统最优规模规划模型。具体地，通过增强型输入凸神经网络（ICNN）提取区域频率约束，该ICNN采用了新的权重初始化策略以解决梯度消失问题并提升拟合能力。为有效求解，开发了一种带有稀疏度计算和局部搜索的自适应遗传算法，将规划模型分为两阶段进行迭代求解。

Result: 在三种不同电力系统上进行了案例研究，验证了所提出的频率约束规划模型在确保区域系统安全性以及获得实际投资决策方面的有效性。

Conclusion: 所提出的模型能够有效解决高可再生能源渗透背景下电力系统的区域频率安全规划问题，并能得到符合实际的投资决策，填补了现有研究中忽视区域频率差异的空白。

Abstract: Large renewable penetration has been witnessed in power systems, resulting in
reduced levels of system inertia and increasing requirements for frequency
response services. There have been plenty of studies developing
frequency-constrained models for power system security. However, most existing
literature only considers uniform frequency security, while neglecting
frequency spatial differences in different regions. To fill this gap, this
paper proposes a novel planning model for the optimal sizing problem of power
systems, capturing regional frequency security and inter-area frequency
oscillations. Specifically, regional frequency constraints are first extracted
via an enhanced input convex neural network (ICNN) and then embedded into the
original optimisation for frequency security, where a principled weight
initialisation strategy is adopted to deal with the gradient vanishing issues
of non-negative weights in traditional ICNNs and enhance its fitting ability.
An adaptive genetic algorithm with sparsity calculation and local search is
developed to separate the planning model into two stages and effectively solve
it iteratively. Case studies have been conducted on three different power
systems to verify the effectiveness of the proposed frequency-constrained
planning model in ensuring regional system security and obtaining realistic
investment decisions.

</details>


### [184] [Two-Stage TSO-DSO Services Provision Framework for Electric Vehicle Coordination](https://arxiv.org/abs/2507.18110)
*Yi Wang,Dawei Qiu,Fei Teng,Goran Strbac*

Main category: eess.SY

TL;DR: 本文提出一个两阶段服务提供框架，使电动汽车（EVs）通过V2G能力同时为输电系统提供频率服务和为配电系统提供电压支持，并引入了通信高效的强化学习算法以实现大规模EV的去中心化实时调度。


<details>
  <summary>Details</summary>
Motivation: 可再生能源高渗透导致电力系统惯性降低，对频率响应服务需求增加。电动汽车（EVs）的V2G能力可提供经济高效的频率服务，但其接入配电网可能对配电系统运营商（DSOs）造成电压安全问题。因此，需要协调输电系统运营商（TSOs）的频率需求和DSOs的电压安全。

Method: 提出一个两阶段服务提供框架：第一阶段，EVs参与日前TSO-DSO交互以确定频率储备计划；第二阶段，EVs在配电网中进行实时调度以交付储备并支持DSO电压。针对第二阶段，引入去中心化操作范式，并提出一种通信高效的强化学习（RL）算法，以减少大规模多智能体RL训练中的通信开销，同时不影响策略性能。

Result: 通过在6总线输电/33总线配电网络以及69总线配电网络上进行案例研究，验证了所提出方法在使EVs提供频率服务和电压支持方面的有效性和可扩展性。

Conclusion: 所提出的两阶段服务提供框架结合去中心化操作和通信高效的强化学习算法，能够有效且可扩展地使电动汽车同时为输电系统提供频率服务和为配电系统提供电压支持，解决了高可再生能源渗透下电网的频率和电压协调问题。

Abstract: High renewable penetration has been witnessed in power systems, resulting in
reduced system inertia and increasing requirements for frequency response
services. Electric vehicles (EVs), owing to their vehicle-to-grid (V2G)
capabilities, can provide cost-effective frequency services for transmission
system operators (TSOs). However, EVs that are inherently connected to
distribution networks may pose voltage security issues for distribution system
operators (DSOs) when supporting TSO frequency. To coordinate both TSO
frequency and DSO voltage, this paper proposes a two-stage service provision
framework for multi-EVs. At stage one, EVs participate in day-ahead TSO-DSO
interactions for frequency reserve schedules; at stage two, EVs make real-time
dispatching behaviors in distribution networks for reserve delivery while
supporting DSO voltage. Considering the potentially large EV number and
environment complexity, a decentralized operation paradigm is introduced for
real-time EV dispatches at stage two, while a communication-efficient
reinforcement learning (RL) algorithm is proposed to reduce the communication
overhead during large-scale multi-agent RL training without compromising policy
performance. Case studies are carried out on a 6-bus transmission and 33-bus
distribution network as well as a 69-bus distribution network to evaluate the
effectiveness and scalability of the proposed method in enabling EVs for
frequency service and voltage support.

</details>


### [185] [Data-Driven Model Order Reduction for Continuous- and Discrete-Time Nonlinear Systems](https://arxiv.org/abs/2507.18131)
*Behrad Samari,Henrik Sandberg,Karl H. Johansson,Abolfazl Lavaei*

Main category: eess.SY

TL;DR: 本文提出了一种数据驱动的框架，用于构建未知数学模型的连续和离散时间非线性动力系统的降阶模型（ROMs），并通过仿真函数提供正确性保证，最终应用于控制器设计。


<details>
  <summary>Details</summary>
Motivation: 高维动态系统的模型阶次降低对于复杂系统的控制器设计至关重要，能显著降低计算成本。然而，为高度非线性的动态系统构建有效的降阶模型极具挑战，尤其是在实际系统模型不可用时，这种场景在现实应用中频繁出现。

Method: 该研究利用从系统收集的两组输入-状态轨迹数据，首先构建了系统的数据驱动闭环表示。然后，通过仿真函数（SFs）的概念，建立了原始系统输出轨迹与其数据驱动ROM输出轨迹之间的相似关系，从而正式表征它们的接近程度。为此，作者提出了数据依赖的半定规划（SDPs）作为充分条件，以同时构建ROMs和SFs，并提供正确性保证。最后，通过为数据驱动的ROMs设计控制器，并通过接口函数将结果转换回原始系统，实现了对未知系统满足高级逻辑属性的控制器合成。

Result: 研究表明，所获得的数据驱动降阶模型可以用于合成控制器，确保未知系统满足高级逻辑属性。通过四个涉及未知高度非线性动态的基准案例研究，验证了该数据驱动方法的有效性。

Conclusion: 本文成功开发了一种数据驱动的框架，能够为具有未知数学模型的高度非线性动态系统构建有效的降阶模型。该框架不仅提供了正式的正确性保证，还能够支持针对原始未知系统的高级控制器合成，从而显著降低了复杂系统控制器设计的难度和计算成本。

Abstract: Model order reduction simplifies high-dimensional dynamical systems by
deriving lower-dimensional models that preserve essential system
characteristics. These techniques are crucial to controller design for complex
systems while significantly reducing computational costs. Nevertheless,
constructing effective reduced-order models (ROMs) poses considerable
challenges, particularly for dynamical systems characterized by highly
nonlinear terms. These challenges are further exacerbated when the actual
system model is unavailable, a scenario frequently encountered in real-world
applications. In this work, we propose a data-driven framework for the
construction of ROMs for both continuous- and discrete-time nonlinear dynamical
systems with unknown mathematical models. By leveraging two sets of data
collected from the system, referred to as two input-state trajectories, we
first construct a data-based closed-loop representation of the system. We then
establish a similarity relation between the output trajectories of the original
system and those of its data-driven ROM employing the notion of simulation
functions (SFs), thereby enabling a formal characterization of their closeness.
To achieve this, we propose data-dependent semidefinite programs as sufficient
conditions to simultaneously construct both ROMs and SFs, while offering
correctness guarantees. We demonstrate that the obtained data-driven ROMs can
be employed for synthesizing controllers that ensure the unknown system
satisfies high-level logic properties. This is accomplished by first designing
controllers for the data-driven ROMs and then translating the results back to
the original system through an interface function. We evaluate the efficacy of
our data-driven findings through four benchmark case studies involving unknown
dynamics with highly nonlinear terms.

</details>


### [186] [Data-Driven Incremental GAS Certificate of Nonlinear Homogeneous Networks: A Formal Modular Approach](https://arxiv.org/abs/2507.18141)
*Mahdieh Zaker,David Angeli,Abolfazl Lavaei*

Main category: eess.SY

TL;DR: 本文提出了一种数据驱动的组合方法，用于验证具有未知动态的互连同构网络的增量全局渐近稳定性（delta-GAS），其数据复杂度随子系统数量线性增长，解决了传统方法的指数级增长问题。


<details>
  <summary>Details</summary>
Motivation: 现有验证互连系统稳定性的整体（monolithic）方法在数据复杂度方面呈指数级增长，对于实际应用中的大规模系统变得不切实际。因此，需要一种更高效、可扩展的数据驱动方法来处理具有未知动态的大型互连网络。

Method: 该方法利用子系统的增量输入到状态稳定性（delta-ISS）概念，通过delta-ISS Lyapunov函数进行表征。首先，将delta-ISS Lyapunov条件重新表述为鲁棒优化问题（ROP）。然后，由于ROP约束中存在未知子系统动态，通过收集每个未知子系统轨迹数据，开发了一个场景优化问题（SOP）并求解，为每个子系统构建delta-ISS Lyapunov函数。最后，利用小增益组合条件，基于子系统的数据驱动delta-ISS Lyapunov函数，为具有未知动态的互连网络构建增量Lyapunov函数，并提供正确性保证。

Result: 该数据驱动组合方法将样本复杂度与子系统粒度对齐，所需数据量随子系统数量线性增加。与现有整体方法相比，后者样本复杂度呈指数增长，不适用于实际应用。通过在一个包含10000个子系统的未知非线性同构网络上进行验证，证明了互连网络是delta-GAS的，并提供了正确性保证。

Conclusion: 所提出的数据驱动组合方法能够有效且可扩展地验证具有未知动态的大规模互连网络的增量全局渐近稳定性，其线性增长的数据复杂度使其在实际应用中具有可行性，克服了传统整体方法的局限性。

Abstract: This work focuses on a compositional data-driven approach to verify
incremental global asymptotic stability (delta-GAS) over interconnected
homogeneous networks of degree one with unknown mathematical dynamics. Our
proposed approach leverages the concept of incremental input-to-state stability
(delta-ISS) of subsystems, characterized by delta-ISS Lyapunov functions. To
implement our data-driven scheme, we initially reframe the delta-ISS Lyapunov
conditions as a robust optimization program (ROP). However, due to the presence
of unknown subsystem dynamics in the ROP constraints, we develop a scenario
optimization program (SOP) by gathering data from trajectories of each unknown
subsystem. We solve the SOP and construct a delta-ISS Lyapunov function for
each subsystem with unknown dynamics. We then leverage a small-gain
compositional condition to facilitate the construction of an incremental
Lyapunov function for an unknown interconnected network with unknown dynamics
based on its data-driven delta-ISS Lyapunov functions of individual subsystems,
while providing correctness guarantees. We demonstrate that our data-driven
compositional approach aligns sample complexity with subsystem granularity,
resulting in a linear increase in required data as the number of subsystems
rises. In contrast, the existing monolithic approach in the literature exhibits
exponential growth in sample complexity with increasing number of subsystems,
rendering it impractical for real-world applications. To validate the
effectiveness of our compositional data-driven approach, we apply it to an
unknown nonlinear homogeneous network of degree one, comprising 10000
subsystems. By gathering data from each unknown subsystem, we demonstrate that
the interconnected network is delta-GAS with a correctness guarantee.

</details>


### [187] [Unit Commitment Framework for Nuclear Reactors with Reactivity Decline](https://arxiv.org/abs/2507.18150)
*Shiny Choudhury,Michael Davidson,George Tynan*

Main category: eess.SY

TL;DR: 该研究引入了一种物理信息驱动的元启发式建模方法，将核反应堆的燃料循环动态（包括氙中毒和反应性裕度）嵌入到机组组合框架中，以实现更灵活和准确的核电调度。


<details>
  <summary>Details</summary>
Motivation: 核反应堆通常被建模为不灵活的基荷发电机组，具有固定停机时间和严格的爬坡限制。然而，实际上反应堆的运行灵活性与其燃料循环阶段和反应性裕度密切相关。氙中毒是功率机动性的一个关键物理限制，会导致后续功率爬升延迟或阻止，并延长停机时间。传统模型未能充分捕捉这些物理约束和运行依赖的灵活性。

Method: 该研究提出了一种物理信息驱动的元启发式建模方法，将燃料循环动态直接嵌入到机组组合（UC）框架中。该框架跟踪反应性裕度，动态激活与氙相关的约束，并根据堆芯条件内生地实现换料停机。通过捕获周期内反应性演变和氙中毒的条件性发生，该公式允许根据运行情况进行核电调度，反映监管限制和物理行为。

Result: 将该框架应用于代表性反应堆机组，在从基荷到部分负荷的不同运行模式下，结果表明灵活运行可以减缓反应性衰减并延长燃料循环。研究揭示，考虑燃料循环的灵活性建模对于核反应堆的准确调度至关重要，并为将核电整合到能源系统模型中提供了可行的途径。

Conclusion: 该研究提出的框架能够实现反映监管限制和物理行为的、依赖于运行模式的核电调度。通过捕捉反应堆的内部物理特性，特别是燃料循环和氙中毒效应，该模型能够更准确地规划核电运行，从而提高灵活性、延长燃料循环，并促进核能更好地融入未来能源系统。

Abstract: Nuclear reactors are often modeled as inflexible, baseload generators with
fixed downtimes and restrictive ramping limits. In practice, however, a
reactor's operational flexibility is closely tied to it's fuel cycle stage and
the associated reactivity margin. A key physical constraint to power
maneuverability is xenon poisoning, caused by an increase in neutron absorbing
xenon concentration following a power ramp down. This can delay or even prevent
subsequent power ramp up due to suppressed core reactivity. Additionally, if a
reactor is shutdown during periods of low reactivity, restart times can vary
significantly due to these xenon transients, leading to longer downtimes. This
work introduces a physics informed, metaheuristic modeling approach that embeds
fuel cycle dynamics directly with a unit commitment (UC) framework. The
framework tracks reactivity margin, dynamically activates xenon related
constraints, and endogenously implements refueling outages based on the core
conditions. By capturing intra-cycle reactivity evolution and the conditional
onset of xenon poisoning, the formulation allows for operation dependent
nuclear dispatch that reflects both regulatory limits and physical behavior.
When applied to a representative reactor fleet operating in distinct modes of
operation -- ranging from baseload to part load -- the framework reveals that
flexible operation can slow reactivity degradation and extend fuel cycles. The
results show that fuel cycle aware flexibility modeling is critical for
accurate scheduling of nuclear reactors and offers a tractable pathway to
integrate nuclear power in energy system models.

</details>


### [188] [Stability Constrained Voltage Control in Distribution Grids with Arbitrary Communication Infrastructure](https://arxiv.org/abs/2507.18158)
*Zhenyi Yuan,Jie Feng,Yuanyuan Shi,Jorge Cortés*

Main category: eess.SY

TL;DR: 本文提出了一个统一的设计框架，用于在配电网中进行基于学习的无功功率控制器设计，以实现电压调节并确保系统稳定性，允许控制器利用任意通信基础设施。


<details>
  <summary>Details</summary>
Motivation: 现有可证明稳定的控制器仅限于分散式，无法利用通信获取非本地信息，导致设计保守。本文旨在打破这一限制，允许控制器利用通信以实现更优性能和更宽松的设计约束。

Method: 提出了一个统一的设计框架，允许控制器利用任意通信基础设施。设计了基于输入凸神经网络（ICNN）的控制器，通过设计满足稳定性约束。控制器采用监督学习进行训练。

Result: 在加州大学圣地亚哥分校（UCSD）微电网测试平台上的仿真结果表明，该框架有效，并突出了通信在提高控制性能方面的作用。

Conclusion: 该框架提供了一种有效且不那么保守的基于学习的无功功率控制器设计方法，通过利用通信，显著提升了配电网的电压调节性能和系统稳定性。

Abstract: We consider the problem of designing learning-based reactive power
controllers that perform voltage regulation in distribution grids while
ensuring closed-loop system stability. In contrast to existing methods, where
the provably stable controllers are restricted to be decentralized, we propose
a unified design framework that enables the controllers to take advantage of an
arbitrary communication infrastructure on top of the physical power network.
This allows the controllers to incorporate information beyond their local bus,
covering existing methods as a special case and leading to less conservative
constraints on the controller design. We then provide a design procedure to
construct input convex neural network (ICNN) based controllers that satisfy the
identified stability constraints by design under arbitrary communication
scenarios, and train these controllers using supervised learning. Simulation
results on the the University of California, San Diego (UCSD) microgrid testbed
illustrate the effectiveness of the framework and highlight the role of
communication in improving control performance.

</details>


### [189] [Optimal Integration Of Heat-Pump And Solar Thermal Energy In The Pre-heating Loop Of Wood And Gas Boiler Based District Heating System](https://arxiv.org/abs/2507.18204)
*Hamza Mettali,Rousset François,Eric Bideaux,Clausse Marc*

Main category: eess.SY

TL;DR: 本研究通过多目标MILP模型优化区域能源网络中的太阳能热系统设计，考虑技术经济和环境因素。结果显示模型收敛性改善，太阳能集成受储热效率和天然气依赖限制；生物质锅炉可降低太阳能依赖并提高成本效益，但限制可再生能源渗透率；高碳税促进太阳能应用，但储能效率是挑战。


<details>
  <summary>Details</summary>
Motivation: 区域能源网络的热生产脱碳需要整合可再生能源，其中太阳能热能具有显著潜力。然而，系统性能高度依赖外部和设定温度。本研究旨在通过考虑技术经济和环境（CO2）因素的多准则方法来优化系统设计。

Method: 开发了一个混合整数线性规划（MILP）模型，该模型通过温度离散化实现问题线性化，并捕获热发生器的关键动态特性。通过多场景分析，评估了两种碳税水平和不同CO2排放情景下的系统性能。

Result: 模型收敛性得到改善，将19%的MIP差距在26小时内缩短到12小时内的10%，通过消散6%的过剩太阳热量。研究显示太阳能集成面积可达11,932平方米，但导致天然气依赖增加（50%）和储热损耗增加（49%）。纳入木材锅炉可降低太阳能依赖（覆盖45%热量），降低平准化热成本（LCOH），但限制了可再生能源渗透率。

Conclusion: 提高碳税能促进太阳能的采用，但面临储能效率低下的挑战。生物质能可以提高成本效益和系统稳定性，但在可再生能源渗透率方面存在权衡。太阳能与生物质能的整合需权衡系统性能、成本和环境效益。

Abstract: The integration of renewable sources is essential for decarbonizing heat
production in district energy networks. Beyond biomass-based solutions, solar
thermal energy, with or without heat pumps, presents a significant opportunity.
However, system performance is highly dependent on outdoor and setpoint
temperatures. This study aims to optimize system design using a multi-criteria
approach that considers techno-economic and environmental (CO2) factors. A
Mixed-Integer Linear Programming (MILP) model is developed, incorporating
temperature discretization for problem linearization and capturing key dynamic
characteristics of heat generators. The model improves convergence, reducing a
19% MIP gap in 26 hours to 10% in 12 hours by dissipating 6% excess solar heat.
A multi-scenario analysis under two carbon taxation levels and different CO2
emission cases revealed solar integration up to 11,932 m${}^2$ but increased
gas reliance (50%) and TES losses (49%). Wood boiler inclusion reduced solar
dependency, covering 45% of heat, lowered LCOH, but limited renewable
penetration. Higher carbon taxes boosted solar adoption but faced storage
inefficiencies, while biomass enhanced cost efficiency and system stability.

</details>


### [190] [Maneuvering-based Dynamic Thrust Allocation for Fully-Actuated Vessels](https://arxiv.org/abs/2507.18309)
*Emir Cem Gezer,Roger Skjetne*

Main category: eess.SY

TL;DR: 本文提出了一种基于控制Lyapunov函数（CLF）和控制障碍函数（CBF）的新方法，用于解决全驱动船舶的推力分配问题，以确保动态跟踪、速率限制和推力饱和度约束。


<details>
  <summary>Details</summary>
Motivation: 现有推力分配方法在实施中可能面临平滑性、动态响应和约束满足的挑战。该研究旨在为海洋船舶的推力分配实现简单、有效、平滑和动态的推力参考信号。

Method: 该方法使用控制Lyapunov函数（CLF）为推力创建非线性参考滤波器，以确保对最优推力分配解的动态跟踪，并对输出推力参考进行速率限制。同时，利用控制障碍函数（CBF）来确保推力饱和限制得到遵守。

Result: 该方法成功实现了对最优推力分配解的动态跟踪，并有效处理了输出推力参考的速率限制。它还确保了推力力饱和限制得到尊重，从而在推力分配实现中获得了简单、有效、平滑和动态的推力参考信号。

Conclusion: 所提出的基于CLF和CBF的推力分配方法，为全驱动船舶提供了一种简单、有效、并能生成平滑动态推力参考信号的解决方案，同时满足了速率限制和推力饱和度约束。

Abstract: This paper introduces a new approach to solving the thrust allocation problem
using the maneuvering problem in the maritime domain for fully actuated
vessels. The method uses a control Lyapunov function to create a nonlinear
reference filter for the thruster forces. The filter ensures dynamic tracking
of the optimal thrust allocation solution with rate limitation in the output
thruster references. It further uses control barrier functions to ensure that
the thruster force saturation limits are respected. The approach aims for
simplicity and effectiveness, as well as smooth and dynamic thruster reference
signals, in the implementation of thrust allocation for marine vessels.

</details>


### [191] [Toward Sustainable Vertical Farming: Impacts of Environmental Factors and Energy Mix on Performance and Costs](https://arxiv.org/abs/2507.18419)
*Francesco Ceccanti,Aldo Bischi,Umberto Desideri,Andrea Baccioli*

Main category: eess.SY

TL;DR: 本研究分析了垂直农业系统的生产性能和能耗，评估了其效率、可持续性和经济可行性，旨在为提高能源效率和降低成本提供标准化设计和操作指南。


<details>
  <summary>Details</summary>
Motivation: 垂直农业因其能提供稳定、高质量、无虫害的蔬菜生产，并支持与能源系统和城市发展的协同作用而日益受到关注。因此，需要标准化的设计和操作指南来提高能源效率和降低成本。

Method: 研究通过结合三种温度、光合光子通量密度（PPFD）和二氧化碳浓度水平，在挪威、中国和迪拜三个不同气候区评估了162种场景，并测试了两种绝缘厚度，分析了垂直农业系统的生产性能和能耗。

Result: 结果显示，由于暖通空调和除湿（HVACD）系统，绝缘层和外部气候对作物生产力影响不显著。PPFD是作物生长的主要影响因素（相关性：0.85），其次是二氧化碳（0.36）和室内温度（0.22）。PPFD也是总能耗的主要驱动因素（相关性：0.73）。最低的比能耗（SEC）与最低的作物生产力（55公斤/平方米）同时出现。最经济高效的生菜生产设置（LCoL）是24°C、250 PPFD、1400 ppm CO2，并带有绝缘，这在所有气候下都保持一致。

Conclusion: 研究得出结论，只有使用接近脱碳的能源系统，垂直农业才能在不增加二氧化碳排放的情况下，比进口生菜更具环境优势。

Abstract: The increasing interest in vertical farming arises from its ability to ensure
consistent, high-quality, and pest-free vegetable production while supporting
synergies with energy systems and urban development. Accordingly, standardized
design and operation guidelines are essential to improve energy efficiency and
lower costs. This study analyzes the production performance and energy
consumption of a vertical farming system, assessing its efficiency,
sustainability, and economic viability. A total of 162 scenarios were evaluated
by combining three levels of temperature, photosynthetic photon flux density
(PPFD), and CO2 concentration across three distinct climatic zones, namely
Norway, China, and Dubai, which also differ from a socio-environmental
viewpoint. Two insulation thicknesses were also tested in each scenario.
Results indicate that due to the heating, ventilation, and air conditioning and
dehumidification (HVACD) system, neither the insulation layer nor the external
climate significantly influences crop productivity. PPFD proved to be the
dominant factor in crop growth (correlation: 0.85), followed by CO2 (0.36) and
indoor temperature (0.22). PPFD also emerged as the primary driver of overall
energy consumption (correlation: 0.73), as it affects both lighting and HVACD
loads. Notably, the lowest specific energy consumption (SEC) coincided with the
lowest crop productivity (55 kg/m2). The levelized cost of lettuce (LCoL),
balancing productivity and energy use, identified the most cost-effective setup
as 24C, 250 PPFD, 1400 ppm CO2, with insulation, consistent across all
climates. Ultimately, only nearly decarbonized energy systems can support
vertical farming without increasing CO2 emissions compared to imported lettuce.

</details>


### [192] [A Robust Predictive Control Method for Pump Scheduling in Water Distribution Networks](https://arxiv.org/abs/2507.18492)
*Mirhan Ürkmez,Carsten Kallesøe,Jan Dimon Bendtsen,Eric C. Kerrigan,John Leth*

Main category: eess.SY

TL;DR: 本文提出了一种鲁棒模型预测控制（RMPC）方法，用于优化水分配网络（WDN）中的水泵调度，以应对模型不确定性和需求预测误差，并在实际案例中表现出优越的约束满足能力和相似的经济效益。


<details>
  <summary>Details</summary>
Motivation: 水务公司面临高昂的电力成本，主要源于水泵运行。然而，水泵调度因模型不确定性和用水需求预测误差而极具挑战性，需要一种能够应对这些不确定性的优化调度方法。

Method: 该研究采用鲁棒模型预测控制（RMPC）方法。它使用具有有界加性扰动的线性模型来表示水箱水位变化，扰动边界通过WDN仿真和需求数据导出。在每个时间步，制定一个与过去扰动相关的泵调度策略，并在预测范围内进行优化以满足系统约束，然后以滚动时域方式应用。优化问题最初需要O(N^6)的计算量，通过稀疏化重构后降至O(N^3)。

Result: 该方法在丹麦兰德斯市的水分配网络模型上进行评估，结果显示其在满足约束方面优于名义和约束收紧的模型预测控制（MPC）方法，并在经济效益上与其相当。

Conclusion: 该RMPC方法能够有效且可靠地解决水分配网络中的水泵优化调度问题，尤其在不确定性环境下表现出更强的鲁棒性，能够更好地满足系统约束，同时保持良好的经济性。

Abstract: Water utilities aim to reduce the high electrical costs of Water Distribution
Networks (WDNs), primarily driven by pumping. However, pump scheduling is
challenging due to model uncertainties and water demand forecast errors. This
paper presents a Robust Model Predictive Control (RMPC) method for optimal and
reliable pump scheduling, extending a previous efficient robust control method
tailored to our model. A linear model with bounded additive disturbances is
used to represent tank water level evolution, with uncertainty bounds derived
from WDN simulation and demand data. At each time step, a pump scheduling
policy, affine in past disturbances, is optimized to satisfy system constraints
over a prediction horizon. The resulting policies are then applied in a
receding horizon fashion. The optimization problem is formulated to require
$\mathcal{O}(N^6)$ computations per iteration with an interior-point method,
which is reduced to $\mathcal{O}(N^3)$ by reformulating it into a sparse form.
When evaluated on a model representing the water distribution network of
Randers, a medium-sized town in Denmark, the method surpasses nominal and
constraint-tightening model predictive control (MPC) approaches in terms of
meeting constraints and provides comparable economic outcomes.

</details>


### [193] [Global Observer Design for a Class of Linear Observed Systems on Groups](https://arxiv.org/abs/2507.18493)
*Changwu Liu,Yuan Shen*

Main category: eess.SY

TL;DR: 本文提出了一种针对群上线性观测系统设计的统一观测器框架，通过系统浸入和优化重构实现状态估计，并在特定条件下达到全局指数稳定性。


<details>
  <summary>Details</summary>
Motivation: 许多实际状态估计问题（如导航）的几何结构可以通过群上的线性观测系统来描述，需要一个统一的观测器框架来解决这类问题。

Method: 该方法将Lie群上的双不变系统限制在其正规子群上，从而将原始系统浸入到一个线性时变系统中。然后，为浸入系统设计一个类卡尔曼观测器，并通过优化重构群值状态。为保证半全局稳定性，还联合估计输入偏差。

Result: 在满足秩条件且找到重构优化问题的全局最优解时，实现了全局指数稳定性（GES）。当同时估计输入偏差时，保证了半全局稳定性。该理论成功应用于双帧系统（可建模一系列导航问题）的GES观测器设计。

Conclusion: 本文提出了一种有效的统一观测器框架，适用于群上的线性观测系统，通过系统浸入和优化重构，在特定条件下实现了全局指数稳定性，并通过偏差估计提升了稳定性，对导航等实际问题具有重要应用价值。

Abstract: Linear observed systems on groups encode the geometry of a variety of
practical state estimation problems. In this paper, we propose a unified
observer framework for a class of linear observed systems by restricting a
bi-invariant system on a Lie group to its normal subgroup. This structural
property powerfully enables a system immersion of the original system into a
linear time-varying system. Leveraging the immersion, an observer is
constructed by first designing a Kalman-like observer for the immersed system
and then reconstructing the group-valued state via optimization. Under a rank
condition, global exponential stability (GES) is achieved provided one global
optimum of the reconstruction optimization is found, reflecting the topological
difficulties inherent to the non-Euclidean state space. Semi-global stability
is guaranteed when input biases are jointly estimated. The theory is applied to
the GES observer design for two-frame systems, capable of modeling a family of
navigation problems. Two non-trivial examples are provided to illustrate
implementation details.

</details>


### [194] [Design and optimization of a novel leaf-shape antenna for RF energy transfer](https://arxiv.org/abs/2507.18630)
*Junbin Zhong,Mingtong Chen,Zhengbao Yang*

Main category: eess.SY

TL;DR: 本研究设计并优化了一种受自然叶片结构启发的射频能量传输叶形天线，该天线在915 MHz频段表现出高效的能量捕获能力，并能为设备在200厘米距离内供电。


<details>
  <summary>Details</summary>
Motivation: 开发一种仿生天线，优化其在915 MHz频段的性能以实现阻抗匹配，并评估其捕获射频能量的效率，以改进射频能量传输。

Method: 设计过程包括选择合适的叶片形状，使用AutoCAD和HFSS软件建模天线，并制作印刷电路板（PCB）原型。通过仿真和物理测试来优化天线性能。

Result: 天线在915 MHz频率下实现了接近-20 dB的S11参数，表明有效的能量捕获。实验结果证明天线能够在最远200厘米的距离内为设备供电，充电时间反映了其效率。

Conclusion: 该研究得出结论，所提出的仿生天线设计提高了射频能量传输效率。未来的工作应侧重于测试天线穿透混凝土的能力以及开发自主对准的反馈系统。

Abstract: In this research, the design and optimization of a novel leaf-shaped antenna
inspired by natural leaf structures for radio frequency energy transfer is
presented. The objectives of this study are to develop a bio-inspired antenna,
optimize its performance through impedance matching for the 915 MHz frequency
band, and evaluate its efficiency in capturing RF energy. The design process
involves selecting an appropriate leaf shape, modeling the antenna using
AutoCAD and HFSS software, and fabricating a printed circuit board (PCB)
prototype. Simulations and physical tests are conducted to optimize the
antennas performance, achieving an S11 parameter of nearly -20 dB at 915 MHz,
indicating effective energy capture. Experimental results demonstrate the
antennas ability to power a device at distances up to 200 cm, with charging
times reflecting its efficiency. The study concludes that the bio-inspired
design of the proposed antenna improves RF energy transfer. Future work should
focus on testing the antennas penetration through concrete and developing a
feedback system for autonomous alignment.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [195] [Improving Multislice Electron Ptychography with a Generative Prior](https://arxiv.org/abs/2507.17800)
*Christian K. Belardi,Chia-Hao Lee,Yingheng Wang,Justin Lovelace,Kilian Q. Weinberger,David A. Muller,Carla P. Gomes*

Main category: eess.IV

TL;DR: 该研究开发了MEP-Diffusion，一个基于扩散模型的生成先验，用于增强多层电子叠层衍射成像（MEP）的图像重建，显著提高了重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的MEP迭代重建算法耗时且由于病态性质导致次优解决方案，无法有效重建原子晶体结构的高分辨率图像。

Method: 开发了MEP-Diffusion，一个专门针对MEP并基于大量晶体结构数据库训练的扩散模型。该模型通过扩散后验采样（DPS）作为生成先验，轻松集成到现有迭代重建方法中，形成混合方法。

Result: 这种混合方法显著提升了重建三维图像的质量，相较于现有方法，结构相似性指数（SSIM）提高了90.50%。

Conclusion: MEP-Diffusion作为生成先验，有效克服了传统迭代算法的局限性，大幅提升了MEP图像重建的质量和效率。

Abstract: Multislice electron ptychography (MEP) is an inverse imaging technique that
computationally reconstructs the highest-resolution images of atomic crystal
structures from diffraction patterns. Available algorithms often solve this
inverse problem iteratively but are both time consuming and produce suboptimal
solutions due to their ill-posed nature. We develop MEP-Diffusion, a diffusion
model trained on a large database of crystal structures specifically for MEP to
augment existing iterative solvers. MEP-Diffusion is easily integrated as a
generative prior into existing reconstruction methods via Diffusion Posterior
Sampling (DPS). We find that this hybrid approach greatly enhances the quality
of the reconstructed 3D volumes, achieving a 90.50% improvement in SSIM over
existing methods.

</details>


### [196] [Towards Robust Foundation Models for Digital Pathology](https://arxiv.org/abs/2507.17845)
*Jonah Kömen,Edwin D. de Jong,Julius Hense,Hannah Marienwald,Jonas Dippel,Philip Naumann,Eric Marcus,Lukas Ruff,Maximilian Alber,Jonas Teuwen,Frederick Klauschen,Klaus-Robert Müller*

Main category: eess.IV

TL;DR: 该研究系统性地调查了病理学基础模型（FMs）对非生物学技术特征的鲁棒性，发现现有模型存在鲁棒性缺陷，并提出了评估和增强鲁棒性的框架（PathoROB），强调鲁棒性是临床部署的关键。


<details>
  <summary>Details</summary>
Motivation: 生物医学基础模型正在改变医疗保健研究并进入临床验证，但它们容易学习非生物学技术特征（如手术技术、实验室程序、扫描仪硬件差异），这给临床部署带来了风险。

Method: 1. 引入了量化FM鲁棒性的新度量标准。2. 开发了PathoROB鲁棒性基准，包含鲁棒性指数等三个新指标。3. 构建了涵盖34个医疗中心28个生物类别的四个数据集。4. 评估了20个病理学基础模型。5. 提出了一个用于FM鲁棒性增强的框架。

Result: 1. 所有20个评估的FM都存在鲁棒性缺陷，且它们之间存在显著差异。2. 不鲁棒的FM表示会导致严重的下游诊断错误和临床失误，阻碍安全临床应用。3. 使用更鲁棒的FM和事后鲁棒性增强方法可以显著减少（但尚未完全消除）此类错误的风险。

Conclusion: 1. 在临床应用前，病理学基础模型的鲁棒性评估至关重要。2. 未来FM开发必须将鲁棒性作为核心设计原则进行整合。3. PathoROB为评估生物医学领域的鲁棒性提供了蓝图，指导FM改进以开发更鲁棒、更具代表性、更优先生物学信息而非技术伪影的临床可部署AI系统。

Abstract: Biomedical Foundation Models (FMs) are rapidly transforming AI-enabled
healthcare research and entering clinical validation. However, their
susceptibility to learning non-biological technical features -- including
variations in surgical/endoscopic techniques, laboratory procedures, and
scanner hardware -- poses risks for clinical deployment. We present the first
systematic investigation of pathology FM robustness to non-biological features.
Our work (i) introduces measures to quantify FM robustness, (ii) demonstrates
the consequences of limited robustness, and (iii) proposes a framework for FM
robustification to mitigate these issues. Specifically, we developed PathoROB,
a robustness benchmark with three novel metrics, including the robustness
index, and four datasets covering 28 biological classes from 34 medical
centers. Our experiments reveal robustness deficits across all 20 evaluated
FMs, and substantial robustness differences between them. We found that
non-robust FM representations can cause major diagnostic downstream errors and
clinical blunders that prevent safe clinical adoption. Using more robust FMs
and post-hoc robustification considerably reduced (but did not yet eliminate)
the risk of such errors. This work establishes that robustness evaluation is
essential for validating pathology FMs before clinical adoption and
demonstrates that future FM development must integrate robustness as a core
design principle. PathoROB provides a blueprint for assessing robustness across
biomedical domains, guiding FM improvement efforts towards more robust,
representative, and clinically deployable AI systems that prioritize biological
information over technical artifacts.

</details>


### [197] [Integrating Feature Selection and Machine Learning for Nitrogen Assessment in Grapevine Leaves using In-Field Hyperspectral Imaging](https://arxiv.org/abs/2507.17869)
*Atif Bilal Asad,Achyut Paudel,Safal Kshetri,Chenchen Kang,Salik Ram Khanal,Nataliya Shcherbatyuk,Pierre Davadant,R. Paul Schreiner,Santosh Kalauni,Manoj Karkee,Markus Keller*

Main category: eess.IV

TL;DR: 本研究利用田间高光谱图像结合特征选择和机器学习方法，实现了葡萄叶片和冠层氮浓度的预测，并识别了关键光谱区域。


<details>
  <summary>Details</summary>
Motivation: 氮是葡萄园中关键的营养物质，影响植物生长和产品质量。由于土壤氮含量时空变异性大，需要准确估算葡萄叶片氮浓度，实现单株植物水平的精确施肥，以满足植物最佳需求。

Method: 研究收集了两种生长季、两个生长阶段、四种不同葡萄品种的田间高光谱图像（400-1000nm）。经过图像处理后，采用两种特征选择方法识别与叶片氮浓度相关的最佳光谱波段。选定的波段用于训练和测试两种机器学习模型（Gradient Boosting和XGBoost），以预测叶片和冠层水平的氮浓度。

Result: 特征选择方法识别出在叶片和冠层数据集中均表现出鲁棒性的关键光谱区域，包括500-525nm、650-690nm、750-800nm和900-950nm。机器学习模型在冠层水平数据上实现R²为0.49的氮预测精度，在叶片水平数据上实现R²为0.57的氮预测精度。

Conclusion: 研究证明了利用田间高光谱成像结合集成特征选择和机器学习技术，在监测葡萄园氮素状况方面的潜力。

Abstract: Nitrogen (N) is one of the most crucial nutrients in vineyards, affecting
plant growth and subsequent products such as wine and juice. Because soil N has
high spatial and temporal variability, it is desirable to accurately estimate
the N concentration of grapevine leaves and manage fertilization at the
individual plant level to optimally meet plant needs. In this study, we used
in-field hyperspectral images with wavelengths ranging from $400 to 1000nm of
four different grapevine cultivars collected from distinct vineyards and over
two growth stages during two growing seasons to develop models for predicting N
concentration at the leaf-level and canopy-level. After image processing, two
feature selection methods were employed to identify the optimal set of spectral
bands that were responsive to leaf N concentrations. The selected spectral
bands were used to train and test two different Machine Learning (ML) models,
Gradient Boosting and XGBoost, for predicting nitrogen concentrations. The
comparison of selected bands for both leaf-level and canopy-level datasets
showed that most of the spectral regions identified by the feature selection
methods were across both methods and the dataset types (leaf- and canopy-level
datasets), particularly in the key regions, 500-525nm, 650-690nm, 750-800nm,
and 900-950nm. These findings indicated the robustness of these spectral
regions for predicting nitrogen content. The results for N prediction
demonstrated that the ML model achieved an R square of 0.49 for canopy-level
data and an R square of 0.57 for leaf-level data, despite using different sets
of selected spectral bands for each analysis level. The study demonstrated the
potential of using in-field hyperspectral imaging and the use of spectral data
in integrated feature selection and ML techniques to monitor N status in
vineyards.

</details>


### [198] [Hierarchical Diffusion Framework for Pseudo-Healthy Brain MRI Inpainting with Enhanced 3D Consistency](https://arxiv.org/abs/2507.17911)
*Dou Hoon Kwark,Shirui Luo,Xiyue Zhu,Yudu Li,Zhi-Pei Liang,Volodymyr Kindratenko*

Main category: eess.IV

TL;DR: 该论文提出了一种分层扩散框架，通过结合两个垂直的2D阶段（轴向和冠状），实现伪健康脑部MRI图像修复，旨在平衡数据效率和体积一致性。


<details>
  <summary>Details</summary>
Motivation: 现有切片式2D修复方法在体积上存在不连续性，而完全3D模型则需要大量训练数据，这在医疗场景中通常不切实际。

Method: 采用分层扩散框架，用两个垂直的粗到细2D阶段代替直接3D建模。首先，一个轴向扩散模型生成粗略、全局一致的修复；然后，一个冠状扩散模型精修解剖细节，并结合自适应重采样。

Result: 实验表明，该方法在真实感和体积一致性方面均优于现有最先进的基线方法。

Conclusion: 该方法为伪健康图像修复提供了一个有前景的解决方案。

Abstract: Pseudo-healthy image inpainting is an essential preprocessing step for
analyzing pathological brain MRI scans. Most current inpainting methods favor
slice-wise 2D models for their high in-plane fidelity, but their independence
across slices produces discontinuities in the volume. Fully 3D models alleviate
this issue, but their high model capacity demands extensive training data for
reliable, high-fidelity synthesis -- often impractical in medical settings. We
address these limitations with a hierarchical diffusion framework by replacing
direct 3D modeling with two perpendicular coarse-to-fine 2D stages. An axial
diffusion model first yields a coarse, globally consistent inpainting; a
coronal diffusion model then refines anatomical details. By combining
perpendicular spatial views with adaptive resampling, our method balances data
efficiency and volumetric consistency. Our experiments show our approach
outperforms state-of-the-art baselines in both realism and volumetric
consistency, making it a promising solution for pseudo-healthy image
inpainting. Code is available at
https://github.com/dou0000/3dMRI-Consistent-Inpaint.

</details>


### [199] [Benchmarking of Deep Learning Methods for Generic MRI Multi-OrganAbdominal Segmentation](https://arxiv.org/abs/2507.17971)
*Deepa Krishnaswamy,Cosmin Ciausu,Steve Pieper,Ron Kikinis,Benjamin Billot,Andrey Fedorov*

Main category: eess.IV

TL;DR: 本文对三种最先进的开源MRI腹部分割模型进行了全面基准测试，并引入了一个基于CT数据训练的新模型ABDSynth，评估了它们的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习在CT腹部分割方面取得了显著进展，但MRI分割因信号变异性和高昂的标注成本而更具挑战性，导致现有模型泛化能力受限。因此，需要对MRI腹部分割工具进行系统性评估，并探索无需大量MRI标注数据的新方法。

Method: 研究评估了MRSegmentator、MRISegmentator-Abdomen和TotalSegmentator MRI三种主流开源模型。同时，引入并评估了ABDSynth，这是一个基于SynthSeg模型，纯粹使用广泛可用的CT分割数据训练，无需真实MRI图像。所有模型均在三个未曾用于训练的公共数据集上进行评估，这些数据集涵盖了主要制造商、五种MRI序列、多种受试者条件、体素分辨率和视野，以评估准确性和泛化能力。

Result: 结果显示，MRSegmentator表现最佳，泛化能力最强。ABDSynth的准确性略低，但由于其对训练数据要求较低，在标注预算有限的情况下是一个可行的替代方案。

Conclusion: MRSegmentator是目前MRI腹部分割的最佳选择，且泛化能力强。ABDSynth为缺乏MRI标注数据的场景提供了一个有价值的替代方案。研究提供了评估代码和数据集，以便未来进行基准测试。

Abstract: Recent advances in deep learning have led to robust automated tools for
segmentation of abdominal computed tomography (CT). Meanwhile, segmentation of
magnetic resonance imaging (MRI) is substantially more challenging due to the
inherent signal variability and the increased effort required for annotating
training datasets. Hence, existing approaches are trained on limited sets of
MRI sequences, which might limit their generalizability. To characterize the
landscape of MRI abdominal segmentation tools, we present here a comprehensive
benchmarking of the three state-of-the-art and open-source models:
MRSegmentator, MRISegmentator-Abdomen, and TotalSegmentator MRI. Since these
models are trained using labor-intensive manual annotation cycles, we also
introduce and evaluate ABDSynth, a SynthSeg-based model purely trained on
widely available CT segmentations (no real images). More generally, we assess
accuracy and generalizability by leveraging three public datasets (not seen by
any of the evaluated methods during their training), which span all major
manufacturers, five MRI sequences, as well as a variety of subject conditions,
voxel resolutions, and fields-of-view. Our results reveal that MRSegmentator
achieves the best performance and is most generalizable. In contrast, ABDSynth
yields slightly less accurate results, but its relaxed requirements in training
data make it an alternative when the annotation budget is limited. The
evaluation code and datasets are given for future benchmarking at
https://github.com/deepakri201/AbdoBench, along with inference code and weights
for ABDSynth.

</details>


### [200] [Direct Dual-Energy CT Material Decomposition using Model-based Denoising Diffusion Model](https://arxiv.org/abs/2507.18012)
*Hang Xu,Alexandre Bousse,Alessandro Perelli*

Main category: eess.IV

TL;DR: 本文提出了一种名为DEcomp-MoD的深度学习方法，可直接将双能CT（DECT）投影数据转换为材料图像，实现定量材料分解，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大多数DECT材料分解方法在图像域进行，作为重建后的后处理步骤，但这未能考虑射束硬化效应，导致结果不理想。

Method: DEcomp-MoD是一种深度学习流程，将光谱DECT模型知识融入训练损失，并结合基于分数的去噪扩散学习先验。推理优化直接以正弦图作为输入，通过基于模型的条件扩散模型转换为材料图像，确保结果一致性。

Result: DEcomp-MoD在低剂量AAPM数据集的合成DECT正弦图上进行了定量和定性评估，结果显示其性能优于最先进的无监督基于分数模型和有监督深度学习网络。

Conclusion: DEcomp-MoD方法在材料分解方面表现出色，具有应用于临床诊断的潜力。

Abstract: Dual-energy X-ray Computed Tomography (DECT) constitutes an advanced
technology which enables automatic decomposition of materials in clinical
images without manual segmentation using the dependency of the X-ray linear
attenuation with energy. However, most methods perform material decomposition
in the image domain as a post-processing step after reconstruction but this
procedure does not account for the beam-hardening effect and it results in
sub-optimal results. In this work, we propose a deep learning procedure called
Dual-Energy Decomposition Model-based Diffusion (DEcomp-MoD) for quantitative
material decomposition which directly converts the DECT projection data into
material images. The algorithm is based on incorporating the knowledge of the
spectral DECT model into the deep learning training loss and combining a
score-based denoising diffusion learned prior in the material image domain.
Importantly the inference optimization loss takes as inputs directly the
sinogram and converts to material images through a model-based conditional
diffusion model which guarantees consistency of the results. We evaluate the
performance with both quantitative and qualitative estimation of the proposed
DEcomp-MoD method on synthetic DECT sinograms from the low-dose AAPM dataset.
Finally, we show that DEcomp-MoD outperform state-of-the-art unsupervised
score-based model and supervised deep learning networks, with the potential to
be deployed for clinical diagnosis.

</details>


### [201] [Parameter-Efficient Fine-Tuning of 3D DDPM for MRI Image Generation Using Tensor Networks](https://arxiv.org/abs/2507.18112)
*Binghua Li,Ziqing Chang,Tong Liang,Chao Li,Toshihisa Tanaka,Shigeki Aoki,Qibin Zhao,Zhe Sun*

Main category: eess.IV

TL;DR: 本文提出TenVOO，一种参数高效微调（PEFT）方法，专为基于3D U-Net的去噪扩散概率模型（DDPMs）在MRI图像生成中的应用设计，通过张量网络建模高效捕获空间依赖性。


<details>
  <summary>Details</summary>
Motivation: 3D U-Net-based DDPMs在MRI图像生成中具有重要实践意义，但针对其参数高效微调（PEFT）的研究，特别是3D卷积操作的参数高效表示，仍然非常有限，存在研究空白。

Method: 提出Tensor Volumetric Operator (TenVOO)方法，利用张量网络建模将3D卷积核表示为低维张量，从而在微调过程中以少量参数有效捕获复杂的空间依赖性。该方法在UK Biobank预训练的DDPM上进行微调，并在ADNI、PPMI和BraTS2021三个脑MRI数据集上进行评估。

Result: TenVOO在多尺度结构相似性指数（MS-SSIM）方面取得了最先进的性能，在捕获空间依赖性方面优于现有方法，同时仅需要原始模型0.3%的可训练参数。

Conclusion: TenVOO是一种高效的参数高效微调方法，能够有效应用于基于3D U-Net的DDPMs在MRI图像生成中的微调，在大幅减少参数的同时保持甚至超越现有方法的性能，有效解决了3D卷积操作的参数效率问题。

Abstract: We address the challenge of parameter-efficient fine-tuning (PEFT) for
three-dimensional (3D) U-Net-based denoising diffusion probabilistic models
(DDPMs) in magnetic resonance imaging (MRI) image generation. Despite its
practical significance, research on parameter-efficient representations of 3D
convolution operations remains limited. To bridge this gap, we propose Tensor
Volumetric Operator (TenVOO), a novel PEFT method specifically designed for
fine-tuning DDPMs with 3D convolutional backbones. Leveraging tensor network
modeling, TenVOO represents 3D convolution kernels with lower-dimensional
tensors, effectively capturing complex spatial dependencies during fine-tuning
with few parameters. We evaluate TenVOO on three downstream brain MRI
datasets-ADNI, PPMI, and BraTS2021-by fine-tuning a DDPM pretrained on 59,830
T1-weighted brain MRI scans from the UK Biobank. Our results demonstrate that
TenVOO achieves state-of-the-art performance in multi-scale structural
similarity index measure (MS-SSIM), outperforming existing approaches in
capturing spatial dependencies while requiring only 0.3% of the trainable
parameters of the original model. Our code is available at:
https://github.com/xiaovhua/tenvoo

</details>


### [202] [U-Net Based Healthy 3D Brain Tissue Inpainting](https://arxiv.org/abs/2507.18126)
*Juexin Zhang,Ying Weng,Ke Chen*

Main category: eess.IV

TL;DR: 本文提出了一种基于U-Net的3D脑组织修复新方法，通过在训练中随机掩膜健康图像进行数据增强，在BraTS-Local-Inpainting挑战中取得了第一名，并展示了出色的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决“ASNR-MICCAI BraTS局部组织合成通过修复”任务，即从带掩膜的输入图像中合成健康的3D脑组织，重建缺失或损坏的脑部MRI区域。

Method: 采用基于U-Net的架构来重建缺失或损坏的脑部MRI扫描区域。通过在训练期间随机掩膜健康图像，实施了全面的数据增强策略，以增强模型的泛化能力和鲁棒性。

Result: 模型在BraTS-Local-Inpainting验证集上取得了卓越性能：SSIM评分为0.841，PSNR评分为23.257，MSE评分为0.007。这些评估指标的标准偏差较低（SSIM为0.103，PSNR为4.213，MSE为0.007），表明模型在各种输入场景下具有可靠性和一致性。该方法还在挑战中获得了第一名。

Conclusion: 所提出的基于U-Net的方法能够有效且可靠地从带掩膜的输入图像中合成健康的3D脑组织，在相关挑战中表现出领先的性能和高度的一致性。

Abstract: This paper introduces a novel approach to synthesize healthy 3D brain tissue
from masked input images, specifically focusing on the task of 'ASNR-MICCAI
BraTS Local Synthesis of Tissue via Inpainting'. Our proposed method employs a
U-Net-based architecture, which is designed to effectively reconstruct the
missing or corrupted regions of brain MRI scans. To enhance our model's
generalization capabilities and robustness, we implement a comprehensive data
augmentation strategy that involves randomly masking healthy images during
training. Our model is trained on the BraTS-Local-Inpainting dataset and
demonstrates the exceptional performance in recovering healthy brain tissue.
The evaluation metrics employed, including Structural Similarity Index (SSIM),
Peak Signal-to-Noise Ratio (PSNR), and Mean Squared Error (MSE), consistently
yields impressive results. On the BraTS-Local-Inpainting validation set, our
model achieved an SSIM score of 0.841, a PSNR score of 23.257, and an MSE score
of 0.007. Notably, these evaluation metrics exhibit relatively low standard
deviations, i.e., 0.103 for SSIM score, 4.213 for PSNR score and 0.007 for MSE
score, which indicates that our model's reliability and consistency across
various input scenarios. Our method also secured first place in the challenge.

</details>


### [203] [Deep Learning for Glioblastoma Morpho-pathological Features Identification: A BraTS-Pathology Challenge Solution](https://arxiv.org/abs/2507.18133)
*Juexin Zhang,Ying Weng,Ke Chen*

Main category: eess.IV

TL;DR: 针对胶质母细胞瘤的诊断挑战，本文提出了一种基于预训练模型微调的深度学习方法，参与了BraTS-Path 2024挑战赛。尽管模型在验证集上表现出较低的绝对性能指标，但在测试阶段取得了第二名的成绩。


<details>
  <summary>Details</summary>
Motivation: 胶质母细胞瘤的高度异质性使其诊断面临挑战。准确诊断和评估其异质性对选择正确治疗和改善患者预后至关重要。深度学习为改进胶质母细胞瘤诊断提供了一种有前景的方法。

Method: 本文利用一个预训练的深度学习模型，并在BraTS-Path训练数据集上对其进行了微调。

Result: 模型在BraTS-Path验证集上表现出较低的性能，具体为准确率、召回率和F1分数均为0.392229。然而，模型展示了0.898704的优秀特异性，对阴性病例具有卓越的分类能力。马修斯相关系数（MCC）为0.255267，表明预测与实际值之间存在有限的正相关。最终，该解决方案在测试阶段获得了第二名。

Conclusion: 尽管模型在某些绝对性能指标上表现不佳，但其出色的特异性以及在BraTS-Path 2024挑战赛中取得的第二名成绩，表明了该方法在胶质母细胞瘤诊断领域的竞争力和潜在价值，可能反映了挑战的难度或该模型相对于其他参赛者的优势。

Abstract: Glioblastoma, a highly aggressive brain tumor with diverse molecular and
pathological features, poses a diagnostic challenge due to its heterogeneity.
Accurate diagnosis and assessment of this heterogeneity are essential for
choosing the right treatment and improving patient outcomes. Traditional
methods rely on identifying specific features in tissue samples, but deep
learning offers a promising approach for improved glioblastoma diagnosis. In
this paper, we present our approach to the BraTS-Path Challenge 2024. We
leverage a pre-trained model and fine-tune it on the BraTS-Path training
dataset. Our model demonstrates poor performance on the challenging BraTS-Path
validation set, as rigorously assessed by the Synapse online platform. The
model achieves an accuracy of 0.392229, a recall of 0.392229, and a F1-score of
0.392229, indicating a consistent ability to correctly identify instances under
the target condition. Notably, our model exhibits perfect specificity of
0.898704, showing an exceptional capacity to correctly classify negative cases.
Moreover, a Matthews Correlation Coefficient (MCC) of 0.255267 is calculated,
to signify a limited positive correlation between predicted and actual values
and highlight our model's overall predictive power. Our solution also achieves
the second place during the testing phase.

</details>


### [204] [TCM-Tongue: A Standardized Tongue Image Dataset with Pathological Annotations for AI-Assisted TCM Diagnosis](https://arxiv.org/abs/2507.18288)
*Xuebo Jin,Longfei Gao,Anshuo Tong,Zhengyang Chen,Jianlei Kong,Ning Sun,Huijun Ma,Qiang Wang,Yuting Bai,Tingli Su*

Main category: eess.IV

TL;DR: 该研究构建了首个大规模、标准化且经过专业标注的中医舌诊图像数据集，以推动人工智能在中医舌诊领域的发展。


<details>
  <summary>Details</summary>
Motivation: 传统中医舌诊面临主观性强、图像采集不一致以及缺乏大规模标注数据集的挑战，这阻碍了人工智能在该领域的应用和标准化。

Method: 收集了6,719张在标准化条件下拍摄的高质量舌象图片，并由执业中医师标注了20种病理症状类别（平均每张图片2.54个标签）。数据集支持COCO、TXT、XML等多种标注格式，并使用YOLOv5/v7/v8、SSD、MobileNetV2等九种深度学习模型进行了基准测试。

Result: 成功构建了首个专用于AI驱动中医舌诊的大规模、标准化、高质量标注数据集，并通过多种深度学习模型的基准测试验证了其效用。

Conclusion: 该数据集为中医计算工具的可靠发展奠定了关键基础，弥补了该领域的数据短缺，有助于通过标准化、高质量的诊断数据将人工智能整合到中医研究和临床实践中。

Abstract: Traditional Chinese medicine (TCM) tongue diagnosis, while clinically
valuable, faces standardization challenges due to subjective interpretation and
inconsistent imaging protocols, compounded by the lack of large-scale,
annotated datasets for AI development. To address this gap, we present the
first specialized dataset for AI-driven TCM tongue diagnosis, comprising 6,719
high-quality images captured under standardized conditions and annotated with
20 pathological symptom categories (averaging 2.54 clinically validated labels
per image, all verified by licensed TCM practitioners). The dataset supports
multiple annotation formats (COCO, TXT, XML) for broad usability and has been
benchmarked using nine deep learning models (YOLOv5/v7/v8 variants, SSD, and
MobileNetV2) to demonstrate its utility for AI development. This resource
provides a critical foundation for advancing reliable computational tools in
TCM, bridging the data shortage that has hindered progress in the field, and
facilitating the integration of AI into both research and clinical practice
through standardized, high-quality diagnostic data.

</details>


### [205] [UniSegDiff: Boosting Unified Lesion Segmentation via a Staged Diffusion Model](https://arxiv.org/abs/2507.18362)
*Yilong Hu,Shijie Chang,Lihe Zhang,Feng Tian,Weibing Sun,Huchuan Lu*

Main category: eess.IV

TL;DR: 本文提出UniSegDiff，一个针对病灶分割的新型扩散模型框架，通过分阶段训练和推理策略解决现有DPM在不同时间步长注意力不均的问题，实现多模态多器官统一病灶分割，并显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 扩散概率模型（DPM）在生成任务中表现出色，其固有的随机性有助于解决医学图像边缘模糊问题，使其成为病灶分割的有前景方法。然而，现有DPM的训练和推理策略导致不同时间步长的注意力分布不均，从而延长训练时间并产生次优解。

Method: 本文提出UniSegDiff框架，引入分阶段的训练和推理方法，动态调整不同阶段的预测目标，强制模型在所有时间步长保持高注意力。此外，通过预训练分割的特征提取网络，实现统一的病灶分割。

Result: 在六种不同器官和多种成像模态上的综合实验结果表明，UniSegDiff显著优于以前的最先进（SOTA）方法。

Conclusion: UniSegDiff通过创新的分阶段训练和推理策略，有效解决了DPM在病灶分割中注意力分布不均的问题，实现了多模态多器官的统一病灶分割，并取得了超越现有SOTA的卓越性能。

Abstract: The Diffusion Probabilistic Model (DPM) has demonstrated remarkable
performance across a variety of generative tasks. The inherent randomness in
diffusion models helps address issues such as blurring at the edges of medical
images and labels, positioning Diffusion Probabilistic Models (DPMs) as a
promising approach for lesion segmentation. However, we find that the current
training and inference strategies of diffusion models result in an uneven
distribution of attention across different timesteps, leading to longer
training times and suboptimal solutions. To this end, we propose UniSegDiff, a
novel diffusion model framework designed to address lesion segmentation in a
unified manner across multiple modalities and organs. This framework introduces
a staged training and inference approach, dynamically adjusting the prediction
targets at different stages, forcing the model to maintain high attention
across all timesteps, and achieves unified lesion segmentation through
pre-training the feature extraction network for segmentation. We evaluate
performance on six different organs across various imaging modalities.
Comprehensive experimental results demonstrate that UniSegDiff significantly
outperforms previous state-of-the-art (SOTA) approaches. The code is available
at https://github.com/HUYILONG-Z/UniSegDiff.

</details>


### [206] [DiagR1: A Vision-Language Model Trained via Reinforcement Learning for Digestive Pathology Diagnosis](https://arxiv.org/abs/2507.18433)
*Minxi Ouyang,Lianghui Zhu,Yaqing Bao,Qiang Huang,Jingli Ouyang,Tian Guan,Xitong Ling,Jiawen Li,Song Duan,Wenbin Dai,Li Zheng,Xuemei Zhang,Yonghong He*

Main category: eess.IV

TL;DR: 该研究针对胃肠道病理图像分析中多模态大模型的幻觉和推理不透明问题，构建了大规模数据集，并提出了结合提示论证策略和后训练优化（SFT+GRPO）的方法，显著提升了诊断报告生成的质量、完整性和临床相关性。


<details>
  <summary>Details</summary>
Motivation: 当前用于胃肠道病理学的多模态模型受限于数据质量和推理透明度。公共数据集中普遍存在的噪声和不完整标注导致视觉语言模型在生成诊断文本时容易产生事实幻觉，同时缺乏明确的中间推理链使得输出难以审计，从而降低了临床实践中的可信度。

Method: 1. 构建了一个包含微观描述和诊断结论的大规模胃肠道病理数据集。2. 提出了一种提示论证策略，该策略结合了病变分类和解剖部位信息，以引导模型更好地捕获图像特定特征并保持生成内容的语义一致性。3. 采用了一种后训练流程，结合了监督微调（SFT）和组相对策略优化（GRPO），以提高推理质量和输出结构。

Result: 在真实世界病理报告生成任务中的实验结果表明，该方法在生成质量、结构完整性和临床相关性方面显著优于现有最先进的开源和专有基线模型。具体表现为：临床相关性提高18.7%，结构完整性提高32.4%，诊断错误减少41.2%。

Conclusion: 该解决方案在准确性和临床实用性方面优于现有方案，有效解决了胃肠道病理图像分析中多模态大模型的幻觉和推理不透明问题，展示了卓越的性能。

Abstract: Multimodal large models have shown great potential in automating pathology
image analysis. However, current multimodal models for gastrointestinal
pathology are constrained by both data quality and reasoning transparency:
pervasive noise and incomplete annotations in public datasets predispose vision
language models to factual hallucinations when generating diagnostic text,
while the absence of explicit intermediate reasoning chains renders the outputs
difficult to audit and thus less trustworthy in clinical practice. To address
these issues, we construct a large scale gastrointestinal pathology dataset
containing both microscopic descriptions and diagnostic conclusions, and
propose a prompt argumentation strategy that incorporates lesion classification
and anatomical site information. This design guides the model to better capture
image specific features and maintain semantic consistency in generation.
Furthermore, we employ a post training pipeline that combines supervised fine
tuning with Group Relative Policy Optimization (GRPO) to improve reasoning
quality and output structure. Experimental results on real world pathology
report generation tasks demonstrate that our approach significantly outperforms
state of the art open source and proprietary baselines in terms of generation
quality, structural completeness, and clinical relevance. Our solution
outperforms state of the art models with 18.7% higher clinical relevance, 32.4%
improved structural completeness, and 41.2% fewer diagnostic errors,
demonstrating superior accuracy and clinical utility compared to existing
solutions.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [207] [Designing efficient interventions for pre-disease states using control theory](https://arxiv.org/abs/2507.18269)
*Makito Oku*

Main category: math.OC

TL;DR: 本文提出了一种基于控制理论的马尔可夫链稀疏控制（MCSC）方法，用于疾病前期的治疗干预，通过识别少数关键干预状态来预防疾病。


<details>
  <summary>Details</summary>
Motivation: 在老龄化社会中延长健康预期寿命至关重要，需要在疾病前期预防各种疾病。尽管已有动态网络生物标志物理论用于疾病前期检测，但针对疾病前期治疗的数学框架尚未完善。

Method: 提出马尔可夫链稀疏控制（MCSC）方法。将马尔可夫链上概率分布的时间演化描述为一个离散时间线性系统。通过设计稀疏控制器，识别出少数可进行干预的候选状态。

Result: 通过数值模拟和真实数据分析，验证了MCSC方法的有效性。

Conclusion: MCSC提供了一种基于控制理论的疾病前期治疗方法，能够有效识别关键干预状态，为延长健康寿命提供新的策略。

Abstract: To extend healthy life expectancy in an aging society, it is crucial to
prevent various diseases at pre-disease states. Although dynamical network
biomarker theory has been developed for pre-disease detection, mathematical
frameworks for pre-disease treatment have not been well established. Here I
propose a control theory-based approach for pre-disease treatment, named Markov
chain sparse control (MCSC), where time evolution of a probability distribution
on a Markov chain is described as a discrete-time linear system. By designing a
sparse controller, a few candidate states for intervention are identified. The
validity of MCSC is demonstrated using numerical simulations and real-data
analysis.

</details>
