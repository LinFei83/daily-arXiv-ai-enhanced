<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 32]
- [cs.CV](#cs.CV) [Total: 63]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.RO](#cs.RO) [Total: 21]
- [eess.SY](#eess.SY) [Total: 24]
- [eess.IV](#eess.IV) [Total: 5]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Scaling Agent Learning via Experience Synthesis](https://arxiv.org/abs/2511.03773)
*Zhaorun Chen,Zhuokai Zhao,Kai Zhang,Bo Liu,Qi Qi,Yifan Wu,Tarun Kalluri,Sara Cao,Yuanhao Xiong,Haibo Tong,Huaxiu Yao,Hengduo Li,Jiacheng Zhu,Xian Li,Dawn Song,Bo Li,Jason Weston,Dat Huynh*

Main category: cs.AI

TL;DR: DreamGym是一个统一框架，通过推理模型合成多样化经验、结合经验回放和自适应任务生成，解决了大型语言模型（LLM）智能体强化学习（RL）中昂贵数据收集的挑战，显著提升了RL训练效果和模拟到现实的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）赋能大型语言模型（LLM）智能体面临实际应用挑战，包括昂贵的试错、任务多样性不足、奖励信号不可靠以及基础设施复杂性，这些都阻碍了可扩展经验数据的收集。

Method: DreamGym提出一个统一框架，通过以下方式合成可扩展的经验：1) 使用基于推理的经验模型，而非昂贵的真实环境试错，推导一致的状态转移和反馈信号；2) 利用经验回放缓冲区，用离线真实数据初始化并持续更新，以提高转移的稳定性和质量；3) 自适应生成新任务以挑战当前智能体策略，实现更有效的在线课程学习。

Result: DreamGym在多样化环境和智能体骨干上显著改进了RL训练，无论是在纯合成设置还是模拟到现实的迁移场景。在WebArena等非RL就绪任务上，其性能超越所有基线30%以上。在RL就绪但成本高昂的设置中，仅使用合成交互就能达到GRPO和PPO的性能。在将纯粹通过合成经验训练的策略迁移到真实环境RL时，DreamGym在所需真实世界交互显著减少的情况下，提供了额外的显著性能提升，为通用RL提供了一种可扩展的预热策略。

Conclusion: DreamGym通过可扩展地合成多样化经验，成功解决了LLM智能体在线RL训练中的关键挑战，并在各种任务和迁移场景中展现出卓越的性能，为通用RL提供了一种高效的预热和训练方法。

Abstract: While reinforcement learning (RL) can empower large language model (LLM)
agents by enabling self-improvement through interaction, its practical adoption
remains challenging due to costly rollouts, limited task diversity, unreliable
reward signals, and infrastructure complexity, all of which obstruct the
collection of scalable experience data. To address these challenges, we
introduce DreamGym, the first unified framework designed to synthesize diverse
experiences with scalability in mind to enable effective online RL training for
autonomous agents. Rather than relying on expensive real-environment rollouts,
DreamGym distills environment dynamics into a reasoning-based experience model
that derives consistent state transitions and feedback signals through
step-by-step reasoning, enabling scalable agent rollout collection for RL. To
improve the stability and quality of transitions, DreamGym leverages an
experience replay buffer initialized with offline real-world data and
continuously enriched with fresh interactions to actively support agent
training. To improve knowledge acquisition, DreamGym adaptively generates new
tasks that challenge the current agent policy, enabling more effective online
curriculum learning. Experiments across diverse environments and agent
backbones demonstrate that DreamGym substantially improves RL training, both in
fully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready
tasks like WebArena, DreamGym outperforms all baselines by over 30%. And in
RL-ready but costly settings, it matches GRPO and PPO performance using only
synthetic interactions. When transferring a policy trained purely on synthetic
experiences to real-environment RL, DreamGym yields significant additional
performance gains while requiring far fewer real-world interactions, providing
a scalable warm-start strategy for general-purpose RL.

</details>


### [2] [How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis](https://arxiv.org/abs/2511.03825)
*Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder*

Main category: cs.AI

TL;DR: 本研究探讨了汇编代码分析中分词（tokenization）的重要性，评估了NLP分词模型及其参数的内在特性和对下游任务（如函数签名预测）的影响。结果显示分词器选择显著影响性能，揭示了内在属性与实际效用之间的复杂权衡。


<details>
  <summary>Details</summary>
Motivation: 分词在汇编代码分析中至关重要，影响词汇量、语义覆盖和下游任务性能，但该领域在汇编代码背景下尚未得到充分探索。

Method: 研究评估了NLP分词模型的内在特性和参数选择（如词汇量），探索了针对汇编代码的预处理定制和预分词规则。通过对多种分词模型进行深入研究，分析了它们在编码汇编指令和捕捉语义细微差别方面的效率。通过内在评估比较了分词效率、词汇压缩和表示保真度。使用Llama 3.2、BERT和BART等预训练模型评估了分词器在函数签名预测等下游任务中的有效性。

Result: 初步结果表明，分词器选择显著影响下游任务性能。内在指标对外部评估结果具有部分但非完全的预测性。研究揭示了分词器内在属性与其在实际汇编代码任务中的实用性之间存在的复杂权衡。

Conclusion: 本研究为优化低级代码分析的分词模型提供了宝贵见解，有助于提高基于自然语言模型（NLM）的二进制分析工作流的鲁棒性和可扩展性。

Abstract: Tokenization is fundamental in assembly code analysis, impacting intrinsic
characteristics like vocabulary size, semantic coverage, and extrinsic
performance in downstream tasks. Despite its significance, tokenization in the
context of assembly code remains an underexplored area. This study aims to
address this gap by evaluating the intrinsic properties of Natural Language
Processing (NLP) tokenization models and parameter choices, such as vocabulary
size. We explore preprocessing customization options and pre-tokenization rules
tailored to the unique characteristics of assembly code. Additionally, we
assess their impact on downstream tasks like function signature prediction -- a
critical problem in binary code analysis.
  To this end, we conduct a thorough study on various tokenization models,
systematically analyzing their efficiency in encoding assembly instructions and
capturing semantic nuances. Through intrinsic evaluations, we compare
tokenizers based on tokenization efficiency, vocabulary compression, and
representational fidelity for assembly code. Using state-of-the-art pre-trained
models such as the decoder-only Large Language Model (LLM) Llama 3.2, the
encoder-only transformer BERT, and the encoder-decoder model BART, we evaluate
the effectiveness of these tokenizers across multiple performance metrics.
Preliminary findings indicate that tokenizer choice significantly influences
downstream performance, with intrinsic metrics providing partial but incomplete
predictability of extrinsic evaluation outcomes. These results reveal complex
trade-offs between intrinsic tokenizer properties and their utility in
practical assembly code tasks. Ultimately, this study provides valuable
insights into optimizing tokenization models for low-level code analysis,
contributing to the robustness and scalability of Natural Language Model
(NLM)-based binary analysis workflows.

</details>


### [3] [To See or To Read: User Behavior Reasoning in Multimodal LLMs](https://arxiv.org/abs/2511.03845)
*Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: 本文提出`BehaviorLens`框架，系统性评估多模态大语言模型（MLLMs）在用户行为推理中不同数据模态（文本、散点图、流程图）的权衡。研究发现，将交易数据表示为图像可显著提升MLLM的下一购买预测准确率达87.5%，且无需额外计算成本。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）正在重塑现代智能体系统对序列用户行为数据的推理方式。然而，目前尚未充分探索文本或图像表示的用户行为数据哪种能更有效地最大化MLLM性能。

Method: 研究引入了`BehaviorLens`，一个系统性基准测试框架，用于评估六种MLLM在用户行为推理中的模态权衡。该框架将交易数据表示为三种形式：(1) 文本段落，(2) 散点图（图像），和 (3) 流程图（图像）。实验使用了一个真实世界的购买序列数据集。

Result: 当数据以图像形式表示时（散点图或流程图），MLLMs的下一购买预测准确率比等效的文本表示提高了87.5%，且未增加额外的计算成本。

Conclusion: 将用户行为数据表示为图像（如散点图或流程图）能显著提高多模态大语言模型在下一购买预测任务中的性能，相较于文本表示具有巨大优势，并且不会带来额外的计算负担。

Abstract: Multimodal Large Language Models (MLLMs) are reshaping how modern agentic
systems reason over sequential user-behavior data. However, whether textual or
image representations of user behavior data are more effective for maximizing
MLLM performance remains underexplored. We present \texttt{BehaviorLens}, a
systematic benchmarking framework for assessing modality trade-offs in
user-behavior reasoning across six MLLMs by representing transaction data as
(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a
real-world purchase-sequence dataset, we find that when data is represented as
images, MLLMs next-purchase prediction accuracy is improved by 87.5% compared
with an equivalent textual representation without any additional computational
cost.

</details>


### [4] [KnowThyself: An Agentic Assistant for LLM Interpretability](https://arxiv.org/abs/2511.03878)
*Suraj Prasai,Mengnan Du,Ying Zhang,Fan Yang*

Main category: cs.AI

TL;DR: KnowThyself是一个智能体助手，通过整合现有工具并提供对话式界面和交互式可视化，降低了大型语言模型（LLM）可解释性的技术门槛。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM可解释性工具分散且需要大量编码，用户难以有效利用。研究旨在开发一个统一、易于访问的平台，简化LLM的检查和理解过程。

Method: KnowThyself的核心是一个编排LLM，它首先重构用户查询，然后一个智能体路由器将查询定向到专门的模块。最终，输出被语境化为连贯的解释，并通过聊天界面提供交互式可视化。

Result: 该设计降低了技术障碍，提供了一个可扩展的LLM检查平台。通过将整个过程嵌入到对话式工作流中，KnowThyself使LLM可解释性变得更加易于访问。

Conclusion: KnowThyself为可访问的LLM可解释性提供了一个坚实的基础，通过其对话式工作流和整合能力，使得用户能够更轻松地理解和检查LLM。

Abstract: We develop KnowThyself, an agentic assistant that advances large language
model (LLM) interpretability. Existing tools provide useful insights but remain
fragmented and code-intensive. KnowThyself consolidates these capabilities into
a chat-based interface, where users can upload models, pose natural language
questions, and obtain interactive visualizations with guided explanations. At
its core, an orchestrator LLM first reformulates user queries, an agent router
further directs them to specialized modules, and the outputs are finally
contextualized into coherent explanations. This design lowers technical
barriers and provides an extensible platform for LLM inspection. By embedding
the whole process into a conversational workflow, KnowThyself offers a robust
foundation for accessible LLM interpretability.

</details>


### [5] [Extracting Causal Relations in Deep Knowledge Tracing](https://arxiv.org/abs/2511.03948)
*Kevin Hong,Kia Karbasi,Gregory Pottie*

Main category: cs.AI

TL;DR: 本文挑战了深度知识追踪（DKT）模型通过建模知识成分（KC）之间的双向关系来提高性能的普遍解释。研究表明，DKT的真正优势在于其隐式地建模了KC之间的先决条件/因果关系，而非双向关系。


<details>
  <summary>Details</summary>
Motivation: 计算教育研究的一个长期目标是开发可解释的知识追踪（KT）模型。DKT被认为是传统KT方法的重大进步，但其性能提升的普遍解释（即建模双向关系）受到质疑。本文旨在揭示DKT性能提升的真正机制。

Method: 研究通过将练习关系图修剪成有向无环图（DAGs），并在Assistments数据集的因果子集上训练DKT来证明DKT的预测能力与因果结构高度一致。此外，还提出了一种利用DKT学习到的表示来提取练习关系DAGs的替代方法。

Result: 实验结果表明，DKT的预测能力与因果结构（即先决条件关系）高度吻合。通过DKT学习到的表示提取练习关系DAGs的方法也提供了经验证据支持其主张，即DKT能够近似KC之间的因果依赖关系。

Conclusion: 研究得出结论，DKT的有效性主要源于其近似KC之间因果依赖关系的能力，而非简单的关系映射或双向关系。这为理解DKT的工作原理提供了新的视角。

Abstract: A longstanding goal in computational educational research is to develop
explainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which
leverages a Recurrent Neural Network (RNN) to predict student knowledge and
performance on exercises, has been proposed as a major advancement over
traditional KT methods. Several studies suggest that its performance gains stem
from its ability to model bidirectional relationships between different
knowledge components (KCs) within a course, enabling the inference of a
student's understanding of one KC from their performance on others. In this
paper, we challenge this prevailing explanation and demonstrate that DKT's
strength lies in its implicit ability to model prerequisite relationships as a
causal structure, rather than bidirectional relationships. By pruning exercise
relation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal
subsets of the Assistments dataset, we show that DKT's predictive capabilities
align strongly with these causal structures. Furthermore, we propose an
alternative method for extracting exercise relation DAGs using DKT's learned
representations and provide empirical evidence supporting our claim. Our
findings suggest that DKT's effectiveness is largely driven by its capacity to
approximate causal dependencies between KCs rather than simple relational
mappings.

</details>


### [6] [LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing](https://arxiv.org/abs/2511.03980)
*Bram Bulté,Ayla Rigouts Terryn*

Main category: cs.AI

TL;DR: 研究发现，尽管提示语言和文化框架能影响大型语言模型（LLMs）的输出，但LLMs仍存在系统性偏见，倾向于特定国家（荷兰、德国、美国、日本）的价值观，难以充分代表全球文化多样性。


<details>
  <summary>Details</summary>
Motivation: LLMs在全球范围内被不同语言用户广泛采用，但其训练数据和优化目标可能存在不平衡，引发了对LLMs能否代表其广泛用户群文化多样性的质疑。

Method: 本研究使用Hofstede价值观调查模块和世界价值观调查中的63个项目，将其翻译成11种语言，并以包含或不包含明确文化视角的提示形式，对10个LLMs进行了探测。

Result: 提示语言和文化视角都会导致LLM输出的变化。虽然有针对性的提示能在一定程度上使LLM响应趋向相应国家的主导价值观，但无法克服模型对荷兰、德国、美国和日本等少数国家价值观的系统性偏见。所有测试模型都表现出相似的模式：对大多数话题持中立态度，但在社会容忍等问题上持选择性进步立场。明确的文化视角比有针对性的提示语言更能提高模型与人类文化价值观的一致性。出乎意料的是，结合这两种方法并不比使用英语提示进行文化框架更有效。

Conclusion: LLMs处于一个“令人不安的中间地带”：它们对提示的变化足够敏感以产生差异，但又过于牢固地锚定于特定的文化默认值，无法充分代表文化多样性。

Abstract: Large Language Models (LLMs) are rapidly being adopted by users across the
globe, who interact with them in a diverse range of languages. At the same
time, there are well-documented imbalances in the training data and
optimisation objectives of this technology, raising doubts as to whether LLMs
can represent the cultural diversity of their broad user base. In this study,
we look at LLMs and cultural values and examine how prompt language and
cultural framing influence model responses and their alignment with human
values in different countries. We probe 10 LLMs with 63 items from the Hofstede
Values Survey Module and World Values Survey, translated into 11 languages, and
formulated as prompts with and without different explicit cultural
perspectives. Our study confirms that both prompt language and cultural
perspective produce variation in LLM outputs, but with an important caveat:
While targeted prompting can, to a certain extent, steer LLM responses in the
direction of the predominant values of the corresponding countries, it does not
overcome the models' systematic bias toward the values associated with a
restricted set of countries in our dataset: the Netherlands, Germany, the US,
and Japan. All tested models, regardless of their origin, exhibit remarkably
similar patterns: They produce fairly neutral responses on most topics, with
selective progressive stances on issues such as social tolerance. Alignment
with cultural values of human respondents is improved more with an explicit
cultural perspective than with a targeted prompt language. Unexpectedly,
combining both approaches is no more effective than cultural framing with an
English prompt. These findings reveal that LLMs occupy an uncomfortable middle
ground: They are responsive enough to changes in prompts to produce variation,
but too firmly anchored to specific cultural defaults to adequately represent
cultural diversity.

</details>


### [7] [ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering](https://arxiv.org/abs/2511.03985)
*Zhuowen Yuan,Tao Liu,Yang Yang,Yang Wang,Feng Qi,Kaushik Rangadurai,Bo Li,Shuang Yang*

Main category: cs.AI

TL;DR: ArchPilot是一个多智能体系统，通过集成架构生成、代理评估和自适应搜索，显著降低了基于LLM的ML工程中昂贵的完整训练运行的计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的智能体在自动化ML工程中表现出色，但它们过度依赖重复的完整训练运行来评估候选方案，导致计算开销巨大、对大规模搜索空间的可扩展性有限以及迭代周期缓慢。

Method: ArchPilot是一个多智能体系统，包含三个专业智能体：一个编排智能体，使用受蒙特卡洛树搜索（MCTS）启发的算法协调搜索过程并管理记忆；一个生成智能体，迭代生成、改进和调试候选架构；一个评估智能体，执行代理训练、生成和优化代理函数，并将代理分数聚合成一个考虑保真度的性能指标。这种多智能体协作结合了代理评估和自适应搜索。

Result: 在MLE-Bench上的实验表明，ArchPilot优于AIDE和ML-Master等SOTA基线，验证了其多智能体系统的有效性。

Conclusion: ArchPilot通过优先处理高潜力候选方案，最大限度地减少对昂贵完整训练运行的依赖，从而在有限预算下实现高效的ML工程。

Abstract: Recent LLM-based agents have demonstrated strong capabilities in automated ML
engineering. However, they heavily rely on repeated full training runs to
evaluate candidate solutions, resulting in significant computational overhead,
limited scalability to large search spaces, and slow iteration cycles. To
address these challenges, we introduce ArchPilot, a multi-agent system that
integrates architecture generation, proxy-based evaluation, and adaptive search
into a unified framework. ArchPilot consists of three specialized agents: an
orchestration agent that coordinates the search process using a Monte Carlo
Tree Search (MCTS)-inspired novel algorithm with a restart mechanism and
manages memory of previous candidates; a generation agent that iteratively
generates, improves, and debugs candidate architectures; and an evaluation
agent that executes proxy training runs, generates and optimizes proxy
functions, and aggregates the proxy scores into a fidelity-aware performance
metric. This multi-agent collaboration allows ArchPilot to prioritize
high-potential candidates with minimal reliance on expensive full training
runs, facilitating efficient ML engineering under limited budgets. Experiments
on MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE
and ML-Master, validating the effectiveness of our multi-agent system.

</details>


### [8] [Detecting Silent Failures in Multi-Agentic AI Trajectories](https://arxiv.org/abs/2511.04032)
*Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi*

Main category: cs.AI

TL;DR: 本研究首次系统性地探讨了多智能体AI系统中的异常检测任务，针对LLM驱动系统固有的非确定性和难以察觉的故障，构建了数据集和基准，并展示了监督和半监督方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 由大型语言模型（LLM）驱动的多智能体AI系统本质上是非确定性的，容易出现漂移、循环和输出细节缺失等难以检测的“静默故障”。

Method: 引入了智能体轨迹中的异常检测任务，并设计了一个数据集整理管道，该管道捕获用户行为、智能体非确定性以及LLM变异。利用此管道，整理并标注了两个包含4275和894条轨迹的基准数据集。在此基础上，对监督（XGBoost）和半监督（SVDD）异常检测方法进行了基准测试。

Result: 监督方法（XGBoost）和半监督方法（SVDD）在这些数据集上表现相当，准确率分别高达98%和96%。

Conclusion: 这项工作首次对多智能体AI系统中的异常检测进行了系统性研究，提供了数据集、基准和见解，以指导未来的研究。

Abstract: Multi-Agentic AI systems, powered by large language models (LLMs), are
inherently non-deterministic and prone to silent failures such as drift,
cycles, and missing details in outputs, which are difficult to detect. We
introduce the task of anomaly detection in agentic trajectories to identify
these failures and present a dataset curation pipeline that captures user
behavior, agent non-determinism, and LLM variation. Using this pipeline, we
curate and label two benchmark datasets comprising \textbf{4,275 and 894}
trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection
methods on these datasets, we show that supervised (XGBoost) and
semi-supervised (SVDD) approaches perform comparably, achieving accuracies up
to 98% and 96%, respectively. This work provides the first systematic study of
anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,
and insights to guide future research.

</details>


### [9] [Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models](https://arxiv.org/abs/2511.04053)
*Hirohane Takagi,Gouki Minegishi,Shota Kizawa,Issey Sukeda,Hitomi Yanaka*

Main category: cs.AI

TL;DR: 本研究揭示了大型语言模型（LLMs）在数值推理错误背后的表征机制，发现它们会放大现实世界的数值关联，且不相关的数值上下文会一致性地改变数值表征，导致模型决策的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管行为研究已记录了大型语言模型（LLMs）的数值推理错误，但其底层的表征机制仍不清楚。研究旨在探究LLMs如何内部整合单一实体的多个数值属性，以及不相关的数值上下文如何扰动这些表征及其下游输出。

Method: 结合线性探测（linear probing）、偏相关分析（partial correlation analysis）以及基于提示的脆弱性测试（prompt-based vulnerability tests），并应用于不同规模的模型。

Result: 研究结果表明，LLMs编码了现实世界的数值关联，但倾向于系统性地放大这些关联。此外，不相关的上下文会导致量级表征发生一致性偏移，且其下游影响随模型大小而异。

Conclusion: 这些发现揭示了LLM决策过程中的一个脆弱性，并为在多属性纠缠下实现更公平、更具表征意识的控制奠定了基础。

Abstract: Although behavioral studies have documented numerical reasoning errors in
large language models (LLMs), the underlying representational mechanisms remain
unclear. We hypothesize that numerical attributes occupy shared latent
subspaces and investigate two questions:(1) How do LLMs internally integrate
multiple numerical attributes of a single entity? (2)How does irrelevant
numerical context perturb these representations and their downstream outputs?
To address these questions, we combine linear probing with partial correlation
analysis and prompt-based vulnerability tests across models of varying sizes.
Our results show that LLMs encode real-world numerical correlations but tend to
systematically amplify them. Moreover, irrelevant context induces consistent
shifts in magnitude representations, with downstream effects that vary by model
size. These findings reveal a vulnerability in LLM decision-making and lay the
groundwork for fairer, representation-aware control under multi-attribute
entanglement.

</details>


### [10] [Agentmandering: A Game-Theoretic Framework for Fair Redistricting via Large Language Model Agents](https://arxiv.org/abs/2511.04076)
*Hao Li,Haotian Chen,Ruoyuan Gong,Juanjuan Wang,Hao Jiang*

Main category: cs.AI

TL;DR: 本文提出Agentmandering框架，将选区划分重塑为两个代表对立政治利益的LLM智能体之间的轮流谈判，通过策略性地选择和冻结选区，显著减少了党派偏见和不公平性，并提高了稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有计算方法主要生成大量合法选区划分方案，但忽略了方案选择过程中的策略动态。这使得党派行为者能够挑选出对己方有利的地图，即使这些地图在技术上合规。仅仅满足形式约束并不能确保公平，因为选择过程本身可能被操纵。

Method: Agentmandering框架将选区划分视为两个代表对立政治利益的智能体之间的轮流谈判。受博弈论思想，特别是“选择与冻结”（Choose-and-Freeze）协议的启发，该方法通过大型语言模型（LLM）智能体将策略交互嵌入到选区划分过程中。智能体轮流从一小组候选地图中选择并冻结选区，通过受约束和可解释的选择逐步划分州。

Result: 在所有州的2020年美国人口普查数据上进行评估，结果显示Agentmandering显著减少了党派偏见和不公平性，同时比标准基线模型的方差低2到3个数量级。这些结果表明了公平性和稳定性，尤其是在摇摆州的情况下。

Conclusion: Agentmandering通过引入基于LLM智能体的策略性谈判机制，有效地解决了传统选区划分方法中存在的党派操纵问题，实现了更公平、更稳定的选区划分方案，特别适用于摇摆州场景。

Abstract: Redistricting plays a central role in shaping how votes are translated into
political power. While existing computational methods primarily aim to generate
large ensembles of legally valid districting plans, they often neglect the
strategic dynamics involved in the selection process. This oversight creates
opportunities for partisan actors to cherry-pick maps that, while technically
compliant, are politically advantageous. Simply satisfying formal constraints
does not ensure fairness when the selection process itself can be manipulated.
We propose \textbf{Agentmandering}, a framework that reimagines redistricting
as a turn-based negotiation between two agents representing opposing political
interests. Drawing inspiration from game-theoretic ideas, particularly the
\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction
into the redistricting process via large language model (LLM) agents. Agents
alternate between selecting and freezing districts from a small set of
candidate maps, gradually partitioning the state through constrained and
interpretable choices. Evaluation on post-2020 U.S. Census data across all
states shows that Agentmandering significantly reduces partisan bias and
unfairness, while achieving 2 to 3 orders of magnitude lower variance than
standard baselines. These results demonstrate both fairness and stability,
especially in swing-state scenarios. Our code is available at
https://github.com/Lihaogx/AgentMandering.

</details>


### [11] [KGFR: A Foundation Retriever for Generalized Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04093)
*Yuanning Cui,Zequn Sun,Wei Hu,Zhangjie Fu*

Main category: cs.AI

TL;DR: LLM-KGFR是一个协作框架，通过结合大语言模型（LLM）和知识图谱基础检索器（KGFR），实现了LLM在知识图谱上进行可扩展、泛化且无需微调的知识增强推理。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在知识密集型问题上表现不佳，现有依赖微调LLM或GNN检索器的方法受限于数据集特定调优和在大规模或未见图上的可扩展性。

Method: 本文提出了LLM-KGFR协作框架。其中，知识图谱基础检索器（KGFR）利用LLM生成的描述编码关系，并根据实体在问题中的角色初始化实体，以实现对未见知识图谱的零样本泛化。为高效处理大型图，KGFR采用非对称渐进传播（APP）进行逐步扩展，选择性地限制高度节点同时保留信息路径。LLM通过节点、边和路径级别的接口，迭代请求候选答案、支持事实和推理路径，形成可控的推理循环。

Result: 实验证明LLM-KGFR在保持可扩展性和泛化能力的同时，取得了强大的性能。

Conclusion: LLM-KGFR为知识图谱增强推理提供了一个实用的解决方案。

Abstract: Large language models (LLMs) excel at reasoning but struggle with
knowledge-intensive questions due to limited context and parametric knowledge.
However, existing methods that rely on finetuned LLMs or GNN retrievers are
limited by dataset-specific tuning and scalability on large or unseen graphs.
We propose the LLM-KGFR collaborative framework, where an LLM works with a
structured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR
encodes relations using LLM-generated descriptions and initializes entities
based on their roles in the question, enabling zero-shot generalization to
unseen KGs. To handle large graphs efficiently, it employs Asymmetric
Progressive Propagation (APP)- a stepwise expansion that selectively limits
high-degree nodes while retaining informative paths. Through node-, edge-, and
path-level interfaces, the LLM iteratively requests candidate answers,
supporting facts, and reasoning paths, forming a controllable reasoning loop.
Experiments demonstrate that LLM-KGFR achieves strong performance while
maintaining scalability and generalization, providing a practical solution for
KG-augmented reasoning.

</details>


### [12] [Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms](https://arxiv.org/abs/2511.04133)
*Miguel E. Andres,Vadim Fedorov,Rida Sadek,Enric Spagnolo-Arrizabalaga,Nadescha Trudel*

Main category: cs.AI

TL;DR: 本文提出了一个以人为中心的基准测试框架，用于系统评估语音AI测试平台的质量，并通过实证研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 语音AI代理正迅速投入生产部署，但确保测试可靠性的系统方法仍不完善。组织无法客观评估其测试方法（内部工具或外部平台）是否有效，这在语音AI扩展到数十亿次日常交互时造成了关键的测量空白。

Method: 本文提出了第一个系统框架，通过以人为中心的基准测试来评估语音AI测试质量。该方法结合了既定的心理测量技术（配对比较产生Elo评分、引导置信区间和置换检验）与严格的统计验证，以提供可复现的指标。为验证该框架，研究人员对三个领先的商业语音AI测试平台进行了全面的实证评估，使用了21,600个人工判断和60个对话的真实性验证。

Result: 结果显示，使用所提出的框架，不同平台之间存在统计学上显著的性能差异。表现最佳的平台Evalion在评估质量方面达到0.92的f1-score（其他平台为0.73），在模拟质量方面达到0.61（其他平台为0.43）。

Conclusion: 该框架使研究人员和组织能够实证验证任何平台的测试能力，为大规模自信部署语音AI提供了必要的测量基础。支持材料已公开以促进重现性和采纳。

Abstract: Voice AI agents are rapidly transitioning to production deployments, yet
systematic methods for ensuring testing reliability remain underdeveloped.
Organizations cannot objectively assess whether their testing approaches
(internal tools or external platforms) actually work, creating a critical
measurement gap as voice AI scales to billions of daily interactions.
  We present the first systematic framework for evaluating voice AI testing
quality through human-centered benchmarking. Our methodology addresses the
fundamental dual challenge of testing platforms: generating realistic test
conversations (simulation quality) and accurately evaluating agent responses
(evaluation quality). The framework combines established psychometric
techniques (pairwise comparisons yielding Elo ratings, bootstrap confidence
intervals, and permutation tests) with rigorous statistical validation to
provide reproducible metrics applicable to any testing approach.
  To validate the framework and demonstrate its utility, we conducted
comprehensive empirical evaluation of three leading commercial platforms
focused on Voice AI Testing using 21,600 human judgments across 45 simulations
and ground truth validation on 60 conversations. Results reveal statistically
significant performance differences with the proposed framework, with the
top-performing platform, Evalion, achieving 0.92 evaluation quality measured as
f1-score versus 0.73 for others, and 0.61 simulation quality using a league
based scoring system (including ties) vs 0.43 for other platforms.
  This framework enables researchers and organizations to empirically validate
the testing capabilities of any platform, providing essential measurement
foundations for confident voice AI deployment at scale. Supporting materials
are made available to facilitate reproducibility and adoption.

</details>


### [13] [When Empowerment Disempowers](https://arxiv.org/abs/2511.04177)
*Claire Yang,Maya Cakmak,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: 研究表明，在多人类环境中，为单一人类赋能（empowerment）的AI代理可能导致其他人类的赋能被剥夺（disempowerment），揭示了目标无关性目标在多代理情境下的潜在失调问题。


<details>
  <summary>Details</summary>
Motivation: 赋能被提议作为AI代理激励辅助行为的通用、目标无关性目标。然而，先前的赋能辅助研究假设代理只协助一个孤立的人类。现实生活中，如家庭和医院等，多人类环境对AI辅助具有巨大潜力，因此需要研究赋能在多人类场景下的表现。

Method: 引入了一个开源的多人类网格世界测试套件Disempower-Grid。使用该套件，通过经验性地展示优化单个任务的赋能的强化学习代理如何显著减少另一个任务的环境影响力及奖励，并将其形式化为“赋能剥夺”（disempowerment）。研究并描述了赋能剥夺在这些环境中发生的条件，并探讨了联合赋能（joint empowerment）如何缓解赋能剥夺。

Result: 经验性结果表明，优化单个任务赋能的辅助强化学习代理可以显著减少另一个任务的环境影响力及奖励，这一现象被形式化为赋能剥夺。研究还发现，联合赋能可以缓解赋能剥夺，但代价是用户的奖励会降低。

Conclusion: 该工作揭示了AI对齐领域的一个更广泛挑战：在单代理设置中看似对齐的目标无关性目标，在多代理环境中可能会变得失调。这表明需要重新思考多人类AI辅助系统中的目标设计。

Abstract: Empowerment, a measure of an agent's ability to control its environment, has
been proposed as a universal goal-agnostic objective for motivating assistive
behavior in AI agents. While multi-human settings like homes and hospitals are
promising for AI assistance, prior work on empowerment-based assistance assumes
that the agent assists one human in isolation. We introduce an open source
multi-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we
empirically show that assistive RL agents optimizing for one human's
empowerment can significantly reduce another human's environmental influence
and rewards - a phenomenon we formalize as disempowerment. We characterize when
disempowerment occurs in these environments and show that joint empowerment
mitigates disempowerment at the cost of the user's reward. Our work reveals a
broader challenge for the AI alignment community: goal-agnostic objectives that
seem aligned in single-agent settings can become misaligned in multi-agent
contexts.

</details>


### [14] [Opus: A Quantitative Framework for Workflow Evaluation](https://arxiv.org/abs/2511.04220)
*Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston*

Main category: cs.AI

TL;DR: 本文提出了Opus工作流评估框架，一个概率-规范性模型，用于量化工作流的质量和效率，并支持其比较、评分和优化。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了量化工作流的质量和效率，将正确性、可靠性和成本整合到一个连贯的数学模型中，以便直接比较、评分和优化工作流。

Method: 该框架结合了Opus工作流奖励（一个估算预期性能的概率函数，考虑成功可能性、资源使用和产出增益）和Opus工作流规范性惩罚（一组衡量内聚性、耦合性、可观察性和信息卫生等结构和信息质量的可测量函数）。它支持自动化评估、排名和优化，并可集成到强化学习循环中。

Result: 本文介绍了Opus工作流奖励模型，将工作流成功形式化为成本和结果的概率期望；定义了Opus工作流规范性惩罚，用于捕捉工作流的结构、语义和信号相关属性；并提出了一个统一的优化公式，用于在奖励-惩罚权衡下识别和排名最优工作流。

Conclusion: Opus工作流评估框架通过整合概率性奖励和规范性惩罚，实现对工作流质量和效率的量化，支持自动化评估、排名和优化，并能指导工作流的发现和改进。

Abstract: This paper introduces the Opus Workflow Evaluation Framework, a
probabilistic-normative formulation for quantifying Workflow quality and
efficiency. It integrates notions of correctness, reliability, and cost into a
coherent mathematical model that enables direct comparison, scoring, and
optimization of Workflows. The framework combines the Opus Workflow Reward, a
probabilistic function estimating expected performance through success
likelihood, resource usage, and output gain, with the Opus Workflow Normative
Penalties, a set of measurable functions capturing structural and informational
quality across Cohesion, Coupling, Observability, and Information Hygiene. It
supports automated Workflow assessment, ranking, and optimization within modern
automation systems such as Opus and can be integrated into Reinforcement
Learning loops to guide Workflow discovery and refinement. In this paper, we
introduce the Opus Workflow Reward model that formalizes Workflow success as a
probabilistic expectation over costs and outcomes. We define measurable Opus
Workflow Normative Penalties capturing structural, semantic, and signal-related
properties of Workflows. Finally, we propose a unified optimization formulation
for identifying and ranking optimal Workflows under joint Reward-Penalty
trade-offs.

</details>


### [15] [Shared Spatial Memory Through Predictive Coding](https://arxiv.org/abs/2511.04235)
*Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang*

Main category: cs.AI

TL;DR: 本文提出了一种多智能体预测编码框架，通过最小化智能体间的相互不确定性来实现一致的空间记忆和协调。该框架利用类网格细胞的空间编码和人工社交地点细胞，实现了在低带宽条件下的高效通信和卓越的协调性能。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，由于部分可观测性和有限带宽，共享和重建一致的空间记忆是一个关键挑战，常常导致协调失败。

Method: 该研究引入了一个多智能体预测编码框架，将协调表述为最小化智能体间的相互不确定性。通过信息瓶颈目标，智能体学习何时、与谁、通信什么。该框架的基础是自监督运动预测中自发产生的类网格细胞度量作为内部空间编码。在此基础上，智能体发展出带宽高效的通信机制和编码伙伴位置的专用神经网络群（人工海马社交地点细胞）。这些社交表征通过分层强化学习策略进一步实现，主动探索以减少联合不确定性。

Result: 在Memory-Maze基准测试中，该方法对带宽限制表现出卓越的韧性：当带宽从128位/步缩减到4位/步时，成功率从73.5%优雅地下降到64.4%，而全广播基线则从67.6%骤降至28.6%。

Conclusion: 研究结果为复杂社交表征如何从统一的预测驱动中出现，并导致社交集体智能，建立了理论上合理且生物学上可信的基础。

Abstract: Sharing and reconstructing a consistent spatial memory is a critical
challenge in multi-agent systems, where partial observability and limited
bandwidth often lead to catastrophic failures in coordination. We introduce a
multi-agent predictive coding framework that formulate coordination as the
minimization of mutual uncertainty among agents. Instantiated as an information
bottleneck objective, it prompts agents to learn not only who and what to
communicate but also when. At the foundation of this framework lies a
grid-cell-like metric as internal spatial coding for self-localization,
emerging spontaneously from self-supervised motion prediction. Building upon
this internal spatial code, agents gradually develop a bandwidth-efficient
communication mechanism and specialized neural populations that encode
partners' locations: an artificial analogue of hippocampal social place cells
(SPCs). These social representations are further enacted by a hierarchical
reinforcement learning policy that actively explores to reduce joint
uncertainty. On the Memory-Maze benchmark, our approach shows exceptional
resilience to bandwidth constraints: success degrades gracefully from 73.5% to
64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast
baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically
principled and biologically plausible basis for how complex social
representations emerge from a unified predictive drive, leading to social
collective intelligence.

</details>


### [16] [RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization](https://arxiv.org/abs/2511.04285)
*Zeng Zhiyuan,Jiashuo Liu,Zhangyue Yin,Ge Zhang,Wenhao Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: RLVR训练大模型存在过拟合问题，导致泛化性下降。本文提出RLoop框架，通过迭代策略初始化，结合RL探索和拒绝采样微调（RFT），将成功轨迹转化为专家数据集以优化策略，有效缓解遗忘并显著提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 可验证奖励强化学习（RLVR）在训练大型推理模型时面临严重的RL过拟合挑战，模型在获得训练奖励的同时却失去了泛化能力。这主要是由策略过度专业化和对训练过程中产生的多样化解决方案的灾难性遗忘所驱动的。标准的优化方法会丢弃这种有价值的中间步骤策略多样性。

Method: 本文提出了RLoop，一个基于迭代策略初始化的自改进框架。RLoop将标准训练过程转化为良性循环：首先使用RL从给定策略探索解决方案空间，然后过滤成功的轨迹以创建专家数据集。接着，通过拒绝采样微调（RFT）使用该数据集来优化初始策略，为下一次迭代创建一个更好的起点。这种通过迭代重新初始化进行的探索和利用循环，有效地将瞬态策略变化转化为稳健的性能提升。

Result: 实验结果表明，RLoop有效缓解了遗忘问题，并显著提高了泛化能力。与传统的RL方法相比，RLoop的平均准确率提高了9%，pass@32指标提高了15%以上。

Conclusion: RLoop框架通过迭代策略初始化和结合探索与利用的策略优化循环，成功解决了RLVR中的过拟合和灾难性遗忘问题，将瞬态策略变化转化为持久的性能增益，从而显著提升了模型的泛化能力和整体表现。

Abstract: While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for
training large reasoning models, its training dynamics harbor a critical
challenge: RL overfitting, where models gain training rewards but lose
generalization. Our analysis reveals this is driven by policy
over-specialization and catastrophic forgetting of diverse solutions generated
during training. Standard optimization discards this valuable inter-step policy
diversity. To address this, we introduce RLoop, a self-improving framework
built on iterative policy initialization. RLoop transforms the standard
training process into a virtuous cycle: it first uses RL to explore the
solution space from a given policy, then filters the successful trajectories to
create an expert dataset. This dataset is used via Rejection-sampling
Fine-Tuning (RFT) to refine the initial policy, creating a superior starting
point for the next iteration. This loop of exploration and exploitation via
iterative re-initialization effectively converts transient policy variations
into robust performance gains. Our experiments show RLoop mitigates forgetting
and substantially improves generalization, boosting average accuracy by 9% and
pass@32 by over 15% compared to vanilla RL.

</details>


### [17] [GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents](https://arxiv.org/abs/2511.04307)
*Jian Mu,Chaoyun Zhang,Chiming Ni,Lu Wang,Bo Qiao,Kartik Mathur,Qianhui Wu,Yuhang Xie,Xiaojun Ma,Mengyu Zhou,Si Qin,Liqun Li,Yu Kang,Minghua Ma,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: GUI-360°是一个大规模、综合的数据集和基准套件，旨在解决计算机使用代理（CUA）在真实任务稀缺、多模态轨迹自动化收集和标注缺失、以及统一基准评估不足的问题。它通过LLM增强的自动化流程构建，包含120万+动作步骤，支持GUI定位、屏幕解析和动作预测，并揭示现有模型与人类水平的差距。


<details>
  <summary>Details</summary>
Motivation: 现有计算机使用代理（CUA）面临三大挑战：1) 缺乏真实世界的CUA任务；2) 缺乏多模态轨迹的自动化收集和标注流程；3) 缺乏一个能联合评估GUI定位、屏幕解析和动作预测的统一基准。

Method: 引入GUI-360°数据集，通过LLM增强的、大部分自动化的流程来解决上述问题，包括查询源获取、环境模板构建、任务实例化、批量执行和LLM驱动的质量过滤。数据集包含流行的Windows办公应用中的数千条轨迹，超过120万个执行动作步骤，包括全分辨率截图、可访问性元数据、实例化目标、中间推理轨迹以及成功和失败的动作轨迹。它支持GUI定位、屏幕解析和动作预测三个典型任务，以及混合GUI+API动作空间。

Result: 在GUI-360°上对最先进的视觉-语言模型进行基准测试显示，在定位和动作预测方面存在显著的开箱即用不足。尽管监督微调和强化学习带来了显著改进，但仍未达到人类水平的可靠性。

Conclusion: GUI-360°数据集及其配套代码的发布，旨在促进可复现研究，加速健壮桌面CUA的进展。数据集揭示了当前AI模型在复杂GUI任务上的局限性，并为未来研究设定了方向。

Abstract: We introduce GUI-360$^\circ$, a large-scale, comprehensive dataset and
benchmark suite designed to advance computer-using agents (CUAs). CUAs present
unique challenges and is constrained by three persistent gaps: a scarcity of
real-world CUA tasks, the lack of automated collection-and-annotation pipelines
for multi-modal trajectories, and the absence of a unified benchmark that
jointly evaluates GUI grounding, screen parsing, and action prediction.
  GUI-360$^\circ$ addresses these gaps with an LLM-augmented, largely automated
pipeline for query sourcing, environment-template construction, task
instantiation, batched execution, and LLM-driven quality filtering. The
released corpus contains over 1.2M executed action steps across thousands of
trajectories in popular Windows office applications, and includes
full-resolution screenshots, accessibility metadata when available,
instantiated goals, intermediate reasoning traces, and both successful and
failed action trajectories. The dataset supports three canonical tasks, GUI
grounding, screen parsing, and action prediction, and a hybrid GUI+API action
space that reflects modern agent designs. Benchmarking state-of-the-art
vision--language models on GUI-360$^\circ$ reveals substantial out-of-the-box
shortcomings in grounding and action prediction; supervised fine-tuning and
reinforcement learning yield significant gains but do not close the gap to
human-level reliability. We release GUI-360$^\circ$ and accompanying code to
facilitate reproducible research and accelerate progress on robust desktop
CUAs.
  The full dataset has been made public on
https://huggingface.co/datasets/vyokky/GUI-360.

</details>


### [18] [AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research](https://arxiv.org/abs/2511.04316)
*Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann*

Main category: cs.AI

TL;DR: AdversariaLLM是一个用于大型语言模型(LLM)越狱鲁棒性研究的工具箱，旨在解决当前研究生态系统的碎片化问题，提高研究的可复现性和可比较性。


<details>
  <summary>Details</summary>
Motivation: LLM安全和鲁棒性研究的快速发展导致了实现、数据集和评估方法的高度碎片化和错误频发，这使得研究的可复现性和可比较性面临挑战，阻碍了有意义的进展。

Method: 本文介绍了AdversariaLLM工具箱，其设计核心是可复现性、正确性和可扩展性。它实现了12种对抗性攻击算法，集成了7个涵盖有害性、过度拒绝和效用评估的基准数据集，并通过Hugging Face提供对各种开源LLM的访问。该实现还包括计算资源跟踪、确定性结果和分布式评估技术等高级功能，以增强可比较性和可复现性。此外，它还通过配套包JudgeZoo集成了判决功能。

Result: AdversariaLLM提供了一个全面的框架，用于进行LLM越狱鲁棒性研究。它集成了多种攻击算法、基准数据集和LLM访问，并具备计算资源跟踪、确定性结果和分布式评估等高级功能，确保了研究的可复现性、正确性和可扩展性。

Conclusion: AdversariaLLM及其配套包旨在为LLM安全领域的透明、可比较和可复现研究建立一个坚实的基础。

Abstract: The rapid expansion of research on Large Language Model (LLM) safety and
robustness has produced a fragmented and oftentimes buggy ecosystem of
implementations, datasets, and evaluation methods. This fragmentation makes
reproducibility and comparability across studies challenging, hindering
meaningful progress. To address these issues, we introduce AdversariaLLM, a
toolbox for conducting LLM jailbreak robustness research. Its design centers on
reproducibility, correctness, and extensibility. The framework implements
twelve adversarial attack algorithms, integrates seven benchmark datasets
spanning harmfulness, over-refusal, and utility evaluation, and provides access
to a wide range of open-weight LLMs via Hugging Face. The implementation
includes advanced features for comparability and reproducibility such as
compute-resource tracking, deterministic results, and distributional evaluation
techniques. \name also integrates judging through the companion package
JudgeZoo, which can also be used independently. Together, these components aim
to establish a robust foundation for transparent, comparable, and reproducible
research in LLM safety.

</details>


### [19] [Probing the Probes: Methods and Metrics for Concept Alignment](https://arxiv.org/abs/2511.04312)
*Jacob Lysnæs-Larsen,Marte Eggen,Inga Strümke*

Main category: cs.AI

TL;DR: 本文指出CAV探针分类精度不足以衡量概念对齐度，探针易捕捉虚假相关性。为此，我们提出一种新的概念定位方法和三类对齐度评估指标，并强调需基于对齐度而非精度进行评估。


<details>
  <summary>Details</summary>
Motivation: 在可解释AI中，人们普遍认为高探针精度意味着CAV忠实地代表其目标概念。然而，本文发现探针的分类精度本身并不可靠，探针更有可能捕获虚假相关性而非仅代表预期概念，导致概念对齐度不佳。

Method: 本文通过构建故意错位的探针（利用虚假相关性）来证明其仍能达到接近标准探针的精度。为解决此问题，我们引入了一种基于空间线性归因的新型概念定位方法，并将其与现有特征可视化技术进行比较。此外，我们提出了三类用于定量评估概念对齐度的新指标：硬精度、分割分数和增强鲁棒性。

Result: 研究表明，故意错位的探针可以达到与标准探针接近的精度。分析发现，具有平移不变性和空间对齐的探针能持续提高概念对齐度。这些发现强调了需要基于对齐度而非探针精度来评估CAV。

Conclusion: 探针精度不足以评估CAV的概念对齐度，应采用基于对齐度的评估指标。同时，根据模型架构和目标概念的性质来定制探针至关重要。

Abstract: In explainable AI, Concept Activation Vectors (CAVs) are typically obtained
by training linear classifier probes to detect human-understandable concepts as
directions in the activation space of deep neural networks. It is widely
assumed that a high probe accuracy indicates a CAV faithfully representing its
target concept. However, we show that the probe's classification accuracy alone
is an unreliable measure of concept alignment, i.e., the degree to which a CAV
captures the intended concept. In fact, we argue that probes are more likely to
capture spurious correlations than they are to represent only the intended
concept. As part of our analysis, we demonstrate that deliberately misaligned
probes constructed to exploit spurious correlations, achieve an accuracy close
to that of standard probes. To address this severe problem, we introduce a
novel concept localization method based on spatial linear attribution, and
provide a comprehensive comparison of it to existing feature visualization
techniques for detecting and mitigating concept misalignment. We further
propose three classes of metrics for quantitatively assessing concept
alignment: hard accuracy, segmentation scores, and augmentation robustness. Our
analysis shows that probes with translation invariance and spatial alignment
consistently increase concept alignment. These findings highlight the need for
alignment-based evaluation metrics rather than probe accuracy, and the
importance of tailoring probes to both the model architecture and the nature of
the target concept.

</details>


### [20] [RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation](https://arxiv.org/abs/2511.04328)
*Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang*

Main category: cs.AI

TL;DR: 该研究提出了一个模拟临床咨询的框架，并构建了首个全面评估大型语言模型（LLMs）药物安全能力的基准RxSafeBench。结果显示LLMs在整合禁忌症和药物相互作用知识方面存在困难，尤其是在风险隐含而非明确时。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在医疗领域取得显著进展，但其药物安全性研究仍受限于缺乏真实世界数据（因隐私和可及性问题），且在实际临床咨询环境中，特别是药物安全方面的评估尚不充分。

Method: 研究提出了一个模拟临床咨询的框架，用于系统评估LLMs的药物安全能力。具体方法包括：生成嵌入药物风险的问诊对话；构建药物安全数据库RxRisk DB（包含6,725条禁忌症、28,781条药物相互作用和14,906对适应症-药物对）；采用两阶段过滤策略确保临床真实性和专业质量，最终创建了包含2,443个高质量咨询场景的RxSafeBench基准；通过结构化多项选择题评估了领先的开源和专有LLMs在模拟患者情境下推荐安全药物的能力。

Result: 评估结果表明，当前LLMs在整合禁忌症和药物相互作用知识方面存在困难，尤其当药物风险是隐含而非明确时。这凸显了确保基于LLM的系统药物安全性的关键挑战。

Conclusion: 研究结果揭示了LLM-based系统在药物安全方面面临的关键挑战，并为通过更好的提示工程和任务特定微调来提高可靠性提供了见解。RxSafeBench作为首个全面评估LLMs药物安全性的基准，将推动更安全、更值得信赖的AI驱动临床决策支持的发展。

Abstract: Numerous medical systems powered by Large Language Models (LLMs) have
achieved remarkable progress in diverse healthcare tasks. However, research on
their medication safety remains limited due to the lack of real world datasets,
constrained by privacy and accessibility issues. Moreover, evaluation of LLMs
in realistic clinical consultation settings, particularly regarding medication
safety, is still underexplored. To address these gaps, we propose a framework
that simulates and evaluates clinical consultations to systematically assess
the medication safety capabilities of LLMs. Within this framework, we generate
inquiry diagnosis dialogues with embedded medication risks and construct a
dedicated medication safety database, RxRisk DB, containing 6,725
contraindications, 28,781 drug interactions, and 14,906 indication-drug pairs.
A two-stage filtering strategy ensures clinical realism and professional
quality, resulting in the benchmark RxSafeBench with 2,443 high-quality
consultation scenarios. We evaluate leading open-source and proprietary LLMs
using structured multiple choice questions that test their ability to recommend
safe medications under simulated patient contexts. Results show that current
LLMs struggle to integrate contraindication and interaction knowledge,
especially when risks are implied rather than explicit. Our findings highlight
key challenges in ensuring medication safety in LLM-based systems and provide
insights into improving reliability through better prompting and task-specific
tuning. RxSafeBench offers the first comprehensive benchmark for evaluating
medication safety in LLMs, advancing safer and more trustworthy AI-driven
clinical decision support.

</details>


### [21] [Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning](https://arxiv.org/abs/2511.04341)
*Nick Oh,Fernand Gobet*

Main category: cs.AI

TL;DR: 本文提出Monitor-Generate-Verify (MGV)框架，通过整合元认知监控来解决现有生成-验证推理架构中因缺乏监控导致的“前缀主导陷阱”问题，从而提高推理系统的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时推理架构（如生成-验证范式）忽视了决定何时以及如何开始推理的监控过程，这导致模型容易陷入“前缀主导陷阱”，过早地选择次优推理路径且难以恢复，造成约20%的准确率损失。

Method: 作者将Flavell以及Nelson和Narens的元认知理论形式化为计算规范，并在此基础上提出了Monitor-Generate-Verify (MGV)框架。MGV通过在生成开始前加入明确的监控（包括难度评估和置信度判断），并通过验证反馈来完善未来的监控，从而扩展了生成-验证范式。

Result: 尽管本文未提供实证验证，但它首次系统地将基础元认知理论转化为计算规范，为理解推理系统故障提供了一套有原则的词汇，并为未来的测试时推理设计提出了具体的架构干预建议。

Conclusion: MGV框架通过在推理过程中显式地整合元认知监控，弥补了现有生成-验证架构的不足。它为设计更鲁棒、能有效避免“前缀主导陷阱”的测试时推理系统提供了理论基础和架构方向。

Abstract: Test-time reasoning architectures such as those following the Generate-Verify
paradigm -- where a model iteratively refines or verifies its own generated
outputs -- prioritise generation and verification but exclude the monitoring
processes that determine when and how reasoning should begin. This omission may
contribute to the prefix dominance trap, in which models commit early to
suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy
loss. We address this architectural gap by formalising Flavell's and Nelson and
Narens' metacognitive theories into computational specifications, proposing the
Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify
paradigm by adding explicit monitoring that captures metacognitive experiences
(from difficulty assessments to confidence judgements) before generation begins
and refines future monitoring through verification feedback. Though we present
no empirical validation, this work provides the first systematic computational
translation of foundational metacognitive theories, offering a principled
vocabulary for understanding reasoning system failures and suggesting specific
architectural interventions for future test-time reasoning designs.

</details>


### [22] [The Peril of Preference: Why GRPO fails on Ordinal Rewards](https://arxiv.org/abs/2511.04439)
*Anisha Garg,Ganesh Venkatesh*

Main category: cs.AI

TL;DR: 针对使用非二元（序数）奖励时，GRPO在强化学习训练中可能错误地强化失败轨迹的问题，本文提出了CoRPO。CoRPO采用自适应基线，先确保满足最低质量阈值，再转向相对偏好模式，从而实现更稳定的收敛和更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型（LLMs）通过强化学习（RL）适应特定任务时，GRPO因其简洁性而受欢迎。然而，当使用更丰富的非二元（序数）奖励（而非简单二元反馈）进行训练时，GRPO的简单性导致其平均基线可能错误地为失败轨迹分配正优势，从而强化不正确的行为。

Method: 本文引入了正确性相对策略优化（CoRPO）。CoRPO使用一个自适应基线：首先强制执行一个最低质量阈值，确保失败的解决方案永远不会得到正向强化；一旦策略持续达到此阈值，基线便自动转换为相对偏好模式，推动模型寻找最优解而非仅仅“可接受”的方案。

Result: 在代码验证任务上的实验表明，CoRPO展示了更稳定的收敛性，并具有更好的域外泛化能力。

Conclusion: 这项工作是LLMs通过强化学习学习新能力的关键一步，通过使LLMs能够从丰富、多维度的反馈中学习（从二元奖励到序数奖励，并进一步向更密集的每步监督发展），从而实现这一目标。

Abstract: Group-relative Policy Optimization's (GRPO) simplicity makes it highly
desirable for adapting LLMs to become experts at specific tasks. But this
simplicity also makes it ill-specified as we seek to enhance RL training with
richer, non-binary feedback. When using ordinal rewards to give partial credit,
GRPO's simplicity starts to hurt, as its group-average baseline often assigns a
positive advantage to failed trajectories and reinforces incorrect behavior.
  We introduce Correctness Relative Policy Optimization (CoRPO), a new
formulation that solves this flaw. CoRPO uses an adaptive baseline that
enforces a minimum quality threshold, ensuring failed solutions are never
positively reinforced. Once the policy consistently meets this threshold, the
baseline automatically transitions to a relative preference mode, pushing the
model to find optimal solutions rather than just "acceptable" ones. We
empirically validate CoRPO on a code verification task, where it demonstrates
more stable convergence and better out-of-domain generalization.
  This work represents a critical step in our broader research program to
enable LLMs to learn genuinely new capabilities through reinforcement learning.
We achieve this by enabling LLMs to learn from rich, multi-dimensional feedback
- progressing from binary to ordinal rewards in this work, and onward to
denser, per-step supervision.

</details>


### [23] [Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach](https://arxiv.org/abs/2511.04393)
*Chanwoo Park,Ziyang Chen,Asuman Ozdaglar,Kaiqing Zhang*

Main category: cs.AI

TL;DR: LLM在决策制定中表现不佳，本文提出Iterative RMFT，通过迭代地将模型自身生成的低遗憾决策轨迹蒸馏回模型进行微调，显著提升LLM的决策能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）被越来越多地部署为决策制定（DM）的“代理”，但在交互式和动态环境中，它们在基本的在线决策问题上表现不佳，无法实现低遗憾或有效的探索-利用权衡，因为它们并非为此设计。

Method: 引入迭代遗憾最小化微调（Iterative RMFT），这是一种后训练程序。在每次迭代中，模型会生成多条决策轨迹，选择其中遗憾值最低的k条，并用这些轨迹对自身进行微调。与以往方法不同，Iterative RMFT利用遗憾指标来激发模型自身的决策能力和推理逻辑，避免了对已知算法或手动链式思考模板的依赖，从而提供更灵活、自然的训练信号。

Result: 实验结果表明，Iterative RMFT显著提升了多种LLM（包括带有数值输入/输出的Transformer、开源LLM以及GPT-4o mini等先进模型）的决策性能。其输出和推理格式的灵活性使其能够泛化到不同时间范围、动作空间、奖励过程和自然语言上下文的任务。此外，理论分析表明，在简化设置下，一个单层Transformer在此范式下可以作为无遗憾学习器。

Conclusion: Iterative RMFT为增强LLM的决策能力提供了一个原则性且通用的后训练框架。

Abstract: Large language models (LLMs) are increasingly deployed as "agents" for
decision-making (DM) in interactive and dynamic environments. Yet, since they
were not originally designed for DM, recent studies show that LLMs can struggle
even in basic online DM problems, failing to achieve low regret or an effective
exploration-exploitation tradeoff. To address this, we introduce Iterative
Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure
that repeatedly distills low-regret decision trajectories back into the base
model. At each iteration, the model rolls out multiple decision trajectories,
selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior
methods that (a) distill action sequences from known DM algorithms or (b) rely
on manually crafted chain-of-thought templates, our approach leverages the
regret metric to elicit the model's own DM ability and reasoning rationales.
This reliance on model-generated reasoning avoids rigid output engineering and
provides more flexible, natural-language training signals. Empirical results
show that Iterative RMFT improves LLMs' DM performance across diverse models -
from Transformers with numerical input/output, to open-weight LLMs, and
advanced closed-weight models like GPT-4o mini. Its flexibility in output and
reasoning formats enables generalization across tasks with varying horizons,
action spaces, reward processes, and natural-language contexts. Finally, we
provide theoretical insight showing that a single-layer Transformer under this
paradigm can act as a no-regret learner in a simplified setting. Overall,
Iterative RMFT offers a principled and general post-training framework for
enhancing LLMs' decision-making capabilities.

</details>


### [24] [Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context](https://arxiv.org/abs/2511.04464)
*Carnot Braun,Rafael O. Jarczewski,Gabriel U. Talasso,Leandro A. Villas,Allan M. de Souza*

Main category: cs.AI

TL;DR: PAVe系统结合传统路径规划算法与大型语言模型（LLM），实现个性化、情境感知的城市车辆路径规划，以更好地理解和整合人类驾驶员的复杂需求。


<details>
  <summary>Details</summary>
Motivation: 传统车辆路径系统擅长优化单一或有限的多目标指标（如时间、距离），但在解释和整合人类驾驶员的复杂、语义化和动态情境（如多步骤任务、情境约束、紧急需求）方面能力不足。

Method: PAVe采用混合代理助手，首先通过多目标（时间、CO2）Dijkstra算法生成一组候选路线。然后，一个LLM代理利用预处理的城市兴趣点（POI）地理空间缓存，根据用户提供的任务、偏好和避让规则评估这些候选路线，并进行路径修改。

Result: 在现实城市场景的基准测试中，PAVe成功地将复杂的用户意图转化为适当的路线修改，其初始路线选择准确率超过88%（使用本地模型）。

Conclusion: 将经典路径规划算法与基于LLM的语义推理层相结合，是创建个性化、自适应和可扩展的城市出行优化解决方案的强大而有效的方法。

Abstract: Traditional vehicle routing systems efficiently optimize singular metrics
like time or distance, and when considering multiple metrics, they need more
processes to optimize . However, they lack the capability to interpret and
integrate the complex, semantic, and dynamic contexts of human drivers, such as
multi-step tasks, situational constraints, or urgent needs. This paper
introduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a
hybrid agentic assistant designed to augment classical pathfinding algorithms
with contextual reasoning. Our approach employs a Large Language Model (LLM)
agent that operates on a candidate set of routes generated by a multi-objective
(time, CO2) Dijkstra algorithm. The agent evaluates these options against
user-provided tasks, preferences, and avoidance rules by leveraging a
pre-processed geospatial cache of urban Points of Interest (POIs). In a
benchmark of realistic urban scenarios, PAVe successfully used complex user
intent into appropriate route modifications, achieving over 88% accuracy in its
initial route selections with a local model. We conclude that combining
classical routing algorithms with an LLM-based semantic reasoning layer is a
robust and effective approach for creating personalized, adaptive, and scalable
solutions for urban mobility optimization.

</details>


### [25] [Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis](https://arxiv.org/abs/2511.04481)
*Lars Krupp,Daniel Geißler,Vishal Banwari,Paul Lukowicz,Jakob Karolus*

Main category: cs.AI

TL;DR: 本文探讨了Web代理（如OpenAI Operator和Google Project Mariner）的能源和碳排放可持续性问题，通过理论估算和实证基准测试发现不同设计对能耗影响显著，且高能耗不等于高效果，呼吁将能耗作为评估Web代理的关键指标。


<details>
  <summary>Details</summary>
Motivation: Web代理系统（如OpenAI Operator和Google Project Mariner）虽然强大且研究活跃，但其引发的可持续性问题（能源消耗和二氧化碳排放）却在很大程度上未被探索。为了强调这一问题的紧迫性，作者进行了初步探索。

Method: 研究方法包括两个方面：理论估算和实证基准测试。通过这两种方式，评估了Web代理相关的能源和二氧化碳成本。

Result: 研究结果表明，Web代理创建的不同设计理念会严重影响其能源消耗。此外，消耗更多能源并不一定意味着更好的结果。研究还指出，缺乏关于某些Web代理模型参数和使用过程的透明度是估算能耗的一个限制因素。

Conclusion: 本文倡导改变Web代理的评估方式，主张在基准测试中加入专门的能耗测量指标，以促进对Web代理可持续性的更全面考量。

Abstract: Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful
agentic systems pushing the boundaries of Large Language Models (LLM). They can
autonomously interact with the internet at the user's behest, such as
navigating websites, filling search masks, and comparing price lists. Though
web agent research is thriving, induced sustainability issues remain largely
unexplored. To highlight the urgency of this issue, we provide an initial
exploration of the energy and $CO_2$ cost associated with web agents from both
a theoretical -via estimation- and an empirical perspective -by benchmarking.
Our results show how different philosophies in web agent creation can severely
impact the associated expended energy, and that more energy consumed does not
necessarily equate to better results. We highlight a lack of transparency
regarding disclosing model parameters and processes used for some web agents as
a limiting factor when estimating energy consumption. Our work contributes
towards a change in thinking of how we evaluate web agents, advocating for
dedicated metrics measuring energy consumption in benchmarks.

</details>


### [26] [Large language models replicate and predict human cooperation across experiments in game theory](https://arxiv.org/abs/2511.04500)
*Andrea Cera Palatsi,Samuel Martin-Gutierrez,Ana S. Cardenal,Max Pellert*

Main category: cs.AI

TL;DR: 本研究评估了大型语言模型（LLMs）在博弈论实验中模拟人类决策行为的准确性，发现某些LLMs能高度复现人类行为模式，并可用于探索新的实验空间。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地用于决策和模拟人类行为，但它们与真实人类决策的一致性尚不清楚。这种不一致可能导致实际应用中的有害结果，或使社会模拟无效。

Method: 开发了博弈论实验的“数字孪生”，并引入了系统的提示和探测框架进行机器行为评估。测试了Llama、Mistral和Qwen三款开源模型。

Result: Llama模型能高度复现人类合作模式，捕捉到人类偏离理性选择理论的行为；Qwen模型则与纳什均衡预测高度一致。研究在没有基于角色的提示下实现了群体层面的行为复现，并为超出原始参数网格的新博弈配置生成了可测试的假设。

Conclusion: 经过适当校准的LLMs能够复制聚合的人类行为模式，并系统性地探索未知的实验空间，为社会和行为科学的传统研究提供补充方法，并能生成关于人类社会决策的新经验预测。

Abstract: Large language models (LLMs) are increasingly used both to make decisions in
domains such as health, education and law, and to simulate human behavior. Yet
how closely LLMs mirror actual human decision-making remains poorly understood.
This gap is critical: misalignment could produce harmful outcomes in practical
applications, while failure to replicate human behavior renders LLMs
ineffective for social simulations. Here, we address this gap by developing a
digital twin of game-theoretic experiments and introducing a systematic
prompting and probing framework for machine-behavioral evaluation. Testing
three open-source models (Llama, Mistral and Qwen), we find that Llama
reproduces human cooperation patterns with high fidelity, capturing human
deviations from rational choice theory, while Qwen aligns closely with Nash
equilibrium predictions. Notably, we achieved population-level behavioral
replication without persona-based prompting, simplifying the simulation
process. Extending beyond the original human-tested games, we generate and
preregister testable hypotheses for novel game configurations outside the
original parameter grid. Our findings demonstrate that appropriately calibrated
LLMs can replicate aggregate human behavioral patterns and enable systematic
exploration of unexplored experimental spaces, offering a complementary
approach to traditional research in the social and behavioral sciences that
generates new empirical predictions about human social decision-making.

</details>


### [27] [Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach](https://arxiv.org/abs/2511.04556)
*Zihang Ding,Kun Zhang*

Main category: cs.AI

TL;DR: 本研究提出了一种数据驱动的稀疏传感（DSS）框架，结合EPA-SWMM模型，以优化城市雨水系统中的传感器部署，并在资源受限的情况下高精度重建峰值流量。


<details>
  <summary>Details</summary>
Motivation: 城市地表洪水日益频繁且普遍，但高时空分辨率的洪水预测和监测受时间、预算和技术限制。在资源有限的情况下，如何监测城市排水网络并预测流量是一个重大挑战。

Method: 本研究使用EPA-SWMM模型生成雨水网络中峰值流量剖面的训练数据集。然后，应用DSS框架（利用奇异值分解进行降维和QR分解进行传感器分配）来识别最佳监测节点。最后，通过比较DSS重建的峰值流量剖面与SWMM结果，验证了所识别监测节点的代表性。

Result: 在77个节点中，仅通过3个优化放置的传感器，就实现了令人满意的流量重建性能，Nash-Sutcliffe效率（NSE）值为0.92-0.95。该模型对测量不确定性表现出良好的鲁棒性，且对传感器故障的鲁棒性取决于位置并随传感器数量的增加而提高。

Conclusion: DSS框架平衡了计算效率和物理可解释性，能够以最少的传感器实现高精度的流量重建。该框架可进一步与预测模型集成，以在有限的传感和监测资源下实现洪水预警和实时控制。

Abstract: Urban surface water flooding, triggered by intense rainfall overwhelming
drainage systems, is increasingly frequent and widespread. While flood
prediction and monitoring in high spatial-temporal resolution are desired,
practical constraints in time, budget, and technology hinder its full
implementation. How to monitor urban drainage networks and predict flow
conditions under constrained resource is a major challenge. This study presents
a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to
optimize sensor placement and reconstruct peak flowrates in a stormwater
system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case
study. We utilized a SWMM model to generate a training dataset of peak flowrate
profiles across the stormwater network. Furthermore, we applied DSS -
leveraging singular value decomposition for dimensionality reduction and QR
factorization for sensor allocation - to identify the optimal monitoring nodes
based on the simulated training dataset. We then validated the
representativeness of these identified monitoring nodes by comparing the
DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three
optimally placed sensors among 77 nodes achieved satisfactory reconstruction
performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to
75th percentiles). In addition, the model showed good robustness to uncertainty
in measurements. Its robustness to sensor failures is location-dependent and
improves with the number of sensors deployed. The framework balances
computational efficiency and physical interpretability, enabling high-accuracy
flow reconstruction with minimal sensors. This DSS framework can be further
integrated with predictive models to realize flood early warning and real-time
control under limited sensing and monitoring resource.

</details>


### [28] [Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis](https://arxiv.org/abs/2511.04584)
*Daniel Gomm,Cornelius Wolff,Madelon Hulsebos*

Main category: cs.AI

TL;DR: 本文将自然语言接口（NLI）中对表格数据的模糊查询重新定义为合作交互的特征，提出一个框架来区分可解析和不可解析的查询。通过分析现有数据集，发现查询类型混合，不利于评估。作者主张在查询解析中拥抱合作，以指导NLI的设计和评估。


<details>
  <summary>Details</summary>
Motivation: 目前的自然语言接口在处理表格数据查询时面临固有的歧义性。研究动机在于不将歧义视为缺陷，而是将其重构为合作交互的一个特征，即用户和系统共同承担查询规范的责任。

Method: 开发了一个原则性框架，用于区分“合作查询”（可解析的）和“非合作查询”（无法解析的）。将该框架应用于表格问答和分析的评估中，分析了15个流行数据集中的查询。

Result: 通过分析发现，现有数据集中查询类型混合失控，既不足以评估系统的执行准确性，也不足以评估其解释能力。该框架和查询分析将视角从“修复歧义”转向“在查询解析中拥抱合作”。

Conclusion: 这项反思能够为表格数据的自然语言接口带来更明智的设计和评估，并为未来的研究提供了启示和方向。通过理解和利用合作性，可以更好地构建和评估NLIs。

Abstract: Natural language interfaces to tabular data must handle ambiguities inherent
to queries. Instead of treating ambiguity as a deficiency, we reframe it as a
feature of cooperative interaction, where the responsibility of query
specification is shared among the user and the system. We develop a principled
framework distinguishing cooperative queries, i.e., queries that yield a
resolvable interpretation, from uncooperative queries that cannot be resolved.
Applying the framework to evaluations for tabular question answering and
analysis, we analyze the queries in 15 popular datasets, and observe an
uncontrolled mixing of query types neither adequate for evaluating a system's
execution accuracy nor for evaluating interpretation capabilities. Our
framework and analysis of queries shifts the perspective from fixing ambiguity
to embracing cooperation in resolving queries. This reflection enables more
informed design and evaluation for natural language interfaces for tabular
data, for which we outline implications and directions for future research.

</details>


### [29] [Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper](https://arxiv.org/abs/2511.04583)
*Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa*

Main category: cs.AI

TL;DR: 本文开发了Jr. AI Scientist，一个模拟新手研究员工作流程的自主AI科学家系统，能分析论文局限、提出假设、实验验证并撰写论文。评估显示其表现优于现有自动化系统，但也揭示了当前AI科学家系统的局限性和潜在风险。


<details>
  <summary>Details</summary>
Motivation: 为了确保AI驱动的科学进步值得信赖和可持续，同时维护学术生态系统的完整性，理解AI科学家系统的当前能力和风险至关重要。

Method: 开发了Jr. AI Scientist系统，它模仿新手学生研究员的核心工作流程：分析导师论文的局限性、提出改进假设、通过实验验证，并撰写包含结果的论文。该系统利用现代编码代理处理复杂的多文件实现。评估方法包括使用AI审稿人进行自动化评估、作者主导的评估以及向Agents4Science提交论文。

Result: 研究发现，Jr. AI Scientist生成的论文获得了比现有全自动化系统更高的审稿分数。然而，作者评估和Agents4Science的审稿结果也指出了重要的局限性，表明当前AI科学家系统直接应用的潜在风险，并揭示了未来研究的关键挑战。

Conclusion: Jr. AI Scientist展示了AI科学家系统在模拟研究流程方面的进步，但同时也暴露了其显著的局限性和潜在风险。这些发现加深了对AI科学家发展现状和风险的理解，为未来的研究指明了方向。

Abstract: Understanding the current capabilities and risks of AI Scientist systems is
essential for ensuring trustworthy and sustainable AI-driven scientific
progress while preserving the integrity of the academic ecosystem. To this end,
we develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system
that mimics the core research workflow of a novice student researcher: Given
the baseline paper from the human mentor, it analyzes its limitations,
formulates novel hypotheses for improvement, validates them through rigorous
experimentation, and writes a paper with the results. Unlike previous
approaches that assume full automation or operate on small-scale code, Jr. AI
Scientist follows a well-defined research workflow and leverages modern coding
agents to handle complex, multi-file implementations, leading to scientifically
valuable contributions. For evaluation, we conducted automated assessments
using AI Reviewers, author-led evaluations, and submissions to Agents4Science,
a venue dedicated to AI-driven scientific contributions. The findings
demonstrate that Jr. AI Scientist generates papers receiving higher review
scores than existing fully automated systems. Nevertheless, we identify
important limitations from both the author evaluation and the Agents4Science
reviews, indicating the potential risks of directly applying current AI
Scientist systems and key challenges for future research. Finally, we
comprehensively report various risks identified during development. We hope
these insights will deepen understanding of current progress and risks in AI
Scientist development.

</details>


### [30] [Question the Questions: Auditing Representation in Online Deliberative Processes](https://arxiv.org/abs/2511.04588)
*Soham De,Lodewijk Gelauff,Ashish Goel,Smitha Milli,Ariel Procaccia,Alice Siu*

Main category: cs.AI

TL;DR: 本文提出一个基于正当代表性（JR）的审计框架和算法，用于衡量审议过程中专家提问环节中问题集的代表性。研究将该框架应用于历史审议数据，比较了主持人选择、整数线性规划和大型语言模型（LLM）生成的问题的代表性，并揭示了LLM在此方面的潜力和局限性。最终，该方法被整合到一个在线审议平台中，以帮助实践者提升未来审议的代表性。


<details>
  <summary>Details</summary>
Motivation: 在公民大会和审议性民意调查等许多审议过程中，参与者有机会直接与专家互动。然而，由于时间限制，只能从大量提议问题中选择有限数量的问题，这引发了一个挑战：如何选择一小组问题，使其能最好地代表所有参与者的利益。

Method: 研究引入了一个基于社会选择概念“正当代表性”（JR）的审计框架，用于衡量问题集的代表性。开发了首个在通用效用设置下审计JR的算法，其中最有效的算法运行时间为O(mn log n)。将审计方法应用于历史审议数据，比较了三种问题选择方法的代表性：(a) 专家小组实际提问（由主持人选择），(b) 通过整数线性规划选择的参与者问题，(c) 大型语言模型（LLM）生成的摘要问题。最终，将这些方法整合到一个已被广泛使用的在线审议平台中。

Result: 研究首次提出了在通用效用设置下审计正当代表性（JR）的算法，其中最有效的算法运行时间为O(mn log n)。通过对历史审议数据的应用，比较了主持人选择、ILP选择和LLM生成的问题的代表性。结果突出了大型语言模型在支持审议过程方面的潜力和当前的局限性。

Conclusion: 本文为衡量和改进审议过程中问题集的代表性提供了新的审计框架和高效算法。研究结果表明，虽然大型语言模型在支持此类过程方面具有前景，但仍存在局限性。通过将这些方法整合到在线审议平台中，实践者可以更容易地审计和提升未来审议的代表性。

Abstract: A central feature of many deliberative processes, such as citizens'
assemblies and deliberative polls, is the opportunity for participants to
engage directly with experts. While participants are typically invited to
propose questions for expert panels, only a limited number can be selected due
to time constraints. This raises the challenge of how to choose a small set of
questions that best represent the interests of all participants. We introduce
an auditing framework for measuring the level of representation provided by a
slate of questions, based on the social choice concept known as justified
representation (JR). We present the first algorithms for auditing JR in the
general utility setting, with our most efficient algorithm achieving a runtime
of $O(mn\log n)$, where $n$ is the number of participants and $m$ is the number
of proposed questions. We apply our auditing methods to historical
deliberations, comparing the representativeness of (a) the actual questions
posed to the expert panel (chosen by a moderator), (b) participants' questions
chosen via integer linear programming, (c) summary questions generated by large
language models (LLMs). Our results highlight both the promise and current
limitations of LLMs in supporting deliberative processes. By integrating our
methods into an online deliberation platform that has been used for over
hundreds of deliberations across more than 50 countries, we make it easy for
practitioners to audit and improve representation in future deliberations.

</details>


### [31] [DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration](https://arxiv.org/abs/2511.04646)
*Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong*

Main category: cs.AI

TL;DR: DR. WELL是一个去中心化的神经符号框架，通过两阶段协商协议和符号规划，结合共享世界模型，实现多智能体协同规划，避免了轨迹层面的脆弱性，提高了任务完成率和效率。


<details>
  <summary>Details</summary>
Motivation: 合作多智能体规划面临信息不完全、通信受限以及轨迹层面协调容易失败的问题。符号规划通过提高抽象级别和提供最小行动词汇，可以缓解这些挑战，实现同步和集体进展。

Method: DR. WELL框架采用两阶段协商协议：智能体首先提出候选角色并进行推理，然后在共识和环境约束下承诺联合分配。承诺后，每个智能体独立生成并执行其角色的符号计划。计划通过共享的世界模型与执行结果相结合，该模型编码当前状态并随智能体行动而更新。

Result: DR. WELL通过对符号计划而非原始轨迹进行推理，避免了脆弱的步级对齐，实现了可重用、可同步、可解释的高级操作。在合作推块任务中的实验表明，智能体能跨回合适应，动态世界模型捕获可重用模式，提高了任务完成率和效率。通过协商和自我完善，动态世界模型改进了任务完成和效率，以时间开销换取了不断演进的、更高效的协作策略。

Conclusion: DR. WELL框架通过去中心化的神经符号方法、两阶段协商和共享动态世界模型，有效解决了多智能体协同规划中的挑战，实现了鲁棒、高效且可解释的协作，并能通过学习演进更优的协作策略。

Abstract: Cooperative multi-agent planning requires agents to make joint decisions with
partial information and limited communication. Coordination at the trajectory
level often fails, as small deviations in timing or movement cascade into
conflicts. Symbolic planning mitigates this challenge by raising the level of
abstraction and providing a minimal vocabulary of actions that enable
synchronization and collective progress. We present DR. WELL, a decentralized
neurosymbolic framework for cooperative multi-agent planning. Cooperation
unfolds through a two-phase negotiation protocol: agents first propose
candidate roles with reasoning and then commit to a joint allocation under
consensus and environment constraints. After commitment, each agent
independently generates and executes a symbolic plan for its role without
revealing detailed trajectories. Plans are grounded in execution outcomes via a
shared world model that encodes the current state and is updated as agents act.
By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids
brittle step-level alignment and enables higher-level operations that are
reusable, synchronizable, and interpretable. Experiments on cooperative
block-push tasks show that agents adapt across episodes, with the dynamic world
model capturing reusable patterns and improving task completion rates and
efficiency. Experiments on cooperative block-push tasks show that our dynamic
world model improves task completion and efficiency through negotiation and
self-refinement, trading a time overhead for evolving, more efficient
collaboration strategies.

</details>


### [32] [VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks](https://arxiv.org/abs/2511.04662)
*Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala*

Main category: cs.AI

TL;DR: VeriCoT是一种神经符号方法，通过将大型语言模型（LLM）的思维链（CoT）推理形式化并验证其逻辑有效性，从而提高LLM推理的可信度和准确性。


<details>
  <summary>Details</summary>
Motivation: LLM可以通过CoT进行多步推理，但它们无法可靠地验证自己的逻辑。即使答案正确，底层推理也可能存在缺陷，这在关键场景中会损害信任。

Method: VeriCoT从CoT推理中提取并验证形式化的逻辑论证。它将每个CoT推理步骤形式化为一阶逻辑，并识别支撑论证的前提（源上下文、常识或先前的推理步骤）。符号表示允许自动化求解器验证逻辑有效性，而自然语言前提则允许人类和系统识别无根据或错误的推理步骤。此外，VeriCoT的验证信号被用于推理时的自我反思、在VeriCoT蒸馏数据集上的监督微调（SFT）以及使用基于验证的成对奖励进行直接偏好优化（DPO）的偏好微调（PFT）。

Result: 在ProofWriter、LegalBench和BioASQ数据集上的实验表明，VeriCoT能有效识别有缺陷的推理，并能很好地预测最终答案的正确性。通过利用VeriCoT的验证信号进行自我反思、SFT和PFT，进一步提高了推理的有效性和准确性。

Conclusion: VeriCoT作为一种神经符号方法，通过形式化和验证LLM的CoT推理，有效解决了LLM推理逻辑不可靠的问题，显著提升了推理的信任度、有效性和准确性。

Abstract: LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but
they cannot reliably verify their own logic. Even when they reach correct
answers, the underlying reasoning may be flawed, undermining trust in
high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a
neuro-symbolic method that extracts and verifies formal logical arguments from
CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order
logic and identifies premises that ground the argument in source context,
commonsense knowledge, or prior reasoning steps. The symbolic representation
enables automated solvers to verify logical validity while the NL premises
allow humans and systems to identify ungrounded or fallacious reasoning steps.
Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT
effectively identifies flawed reasoning, and serves as a strong predictor of
final answer correctness. We also leverage VeriCoT's verification signal for
(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on
VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct
preference optimization (DPO) using verification-based pairwise rewards,
further improving reasoning validity and accuracy.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [33] [LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices](https://arxiv.org/abs/2511.03765)
*Hyunseok Kwak,Kyeongwon Lee,Jae-Jin Lee,Woojoo Lee*

Main category: cs.CV

TL;DR: LoRA-Edge是一种面向边缘设备的参数高效微调(PEFT)方法，它结合了LoRA和张量列车分解，显著减少了CNN微调所需的参数量，同时保持了高精度和更快的收敛速度，使其在资源受限的边缘平台成为可能。


<details>
  <summary>Details</summary>
Motivation: 在人体活动识别(HAR)等边缘应用中，CNN需要进行设备上微调以应对域偏移。然而，由于严格的内存、计算和能耗预算，进行全面的微调是不可行的。

Method: LoRA-Edge是基于低秩适应(LoRA)并辅以张量列车分解的PEFT方法。具体包括：(i) 对预训练的卷积层应用张量列车奇异值分解(TT-SVD)；(ii) 仅选择性地更新输出侧核心，并进行零初始化，以确保辅助路径在开始时处于非活动状态；(iii) 将更新融合回密集核中，从而保持推理成本不变。这种设计保留了卷积结构。

Result: 与全量微调相比，LoRA-Edge将可训练参数数量减少了多达两个数量级。在各种HAR数据集和CNN骨干网络上，其精度与全量微调的差距在4.7%以内，而更新的参数最多仅占总参数的1.49%。在相似预算下，它始终优于先前的参数高效基线。在Jetson Orin Nano设备上，TT-SVD初始化和选择性核心训练使收敛到目标F1的速度提高了1.4-3.8倍。

Conclusion: LoRA-Edge使得结构对齐、参数高效的设备上CNN适应在边缘平台上变得实用可行。

Abstract: On-device fine-tuning of CNNs is essential to withstand domain shift in edge
applications such as Human Activity Recognition (HAR), yet full fine-tuning is
infeasible under strict memory, compute, and energy budgets. We present
LoRA-Edge, a parameter-efficient fine-tuning (PEFT) method that builds on
Low-Rank Adaptation (LoRA) with tensor-train assistance. LoRA-Edge (i) applies
Tensor-Train Singular Value Decomposition (TT-SVD) to pre-trained convolutional
layers, (ii) selectively updates only the output-side core with
zero-initialization to keep the auxiliary path inactive at the start, and (iii)
fuses the update back into dense kernels, leaving inference cost unchanged.
This design preserves convolutional structure and reduces the number of
trainable parameters by up to two orders of magnitude compared to full
fine-tuning. Across diverse HAR datasets and CNN backbones, LoRA-Edge achieves
accuracy within 4.7% of full fine-tuning while updating at most 1.49% of
parameters, consistently outperforming prior parameter-efficient baselines
under similar budgets. On a Jetson Orin Nano, TT-SVD initialization and
selective-core training yield 1.4-3.8x faster convergence to target F1.
LoRA-Edge thus makes structure-aligned, parameter-efficient on-device CNN
adaptation practical for edge platforms.

</details>


### [34] [Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data](https://arxiv.org/abs/2511.04304)
*Robin Spanier,Thorsten Hoeser,Claudia Kuenzer*

Main category: cs.CV

TL;DR: 本研究利用合成数据与真实Sentinel-1卫星图像结合训练YOLOv10深度学习模型，以提高海洋基础设施（特别是海上平台）的检测性能和地理泛化能力，实现F1分数从0.85提升至0.90，并成功检测了3,529个平台。


<details>
  <summary>Details</summary>
Motivation: 随着海洋基础设施（如海上风电场、油气平台）的持续扩张，对有效监测系统的需求日益增加。然而，开发稳健的离岸基础设施检测模型面临数据不足的挑战，特别是对于代表性不足的物体类别、形状和尺寸，导致数据集不全面或不平衡。

Method: 研究采用YOLOv10深度学习目标检测模型，并结合合成数据和2023年第四季度从四个区域（里海、南海、几内亚湾、巴西海岸）获取的真实Sentinel-1卫星图像进行训练。通过将模型应用于三个未见区域（墨西哥湾、北海、波斯湾）来评估其地理可迁移性，并分析合成数据如何增强不平衡类别的表示和整体模型性能。

Result: 模型成功检测了总计3,529个海上平台，其中北海411个，墨西哥湾1,519个，波斯湾1,593个。模型在未见区域表现出良好的泛化能力，初始F1分数为0.85，在整合合成数据后提高到0.90。合成数据有效增强了不平衡类别的表示，并显著提升了整体模型性能。

Conclusion: 本研究强调了平衡数据集的重要性，并证明了合成数据生成是解决遥感领域常见挑战的有效策略。通过利用深度学习和合成数据，可以实现可扩展的全球海洋基础设施监测，朝着全球可迁移的离岸基础设施检测迈出了第一步。

Abstract: The recent and ongoing expansion of marine infrastructure, including offshore
wind farms, oil and gas platforms, artificial islands, and aquaculture
facilities, highlights the need for effective monitoring systems. The
development of robust models for offshore infrastructure detection relies on
comprehensive, balanced datasets, but falls short when samples are scarce,
particularly for underrepresented object classes, shapes, and sizes. By
training deep learning-based YOLOv10 object detection models with a combination
of synthetic and real Sentinel-1 satellite imagery acquired in the fourth
quarter of 2023 from four regions (Caspian Sea, South China Sea, Gulf of
Guinea, and Coast of Brazil), this study investigates the use of synthetic
training data to enhance model performance. We evaluated this approach by
applying the model to detect offshore platforms in three unseen regions (Gulf
of Mexico, North Sea, Persian Gulf) and thereby assess geographic
transferability. This region-holdout evaluation demonstrated that the model
generalises beyond the training areas. In total, 3,529 offshore platforms were
detected, including 411 in the North Sea, 1,519 in the Gulf of Mexico, and
1,593 in the Persian Gulf. The model achieved an F1 score of 0.85, which
improved to 0.90 upon incorporating synthetic data. We analysed how synthetic
data enhances the representation of unbalanced classes and overall model
performance, taking a first step toward globally transferable detection of
offshore infrastructure. This study underscores the importance of balanced
datasets and highlights synthetic data generation as an effective strategy to
address common challenges in remote sensing, demonstrating the potential of
deep learning for scalable, global offshore infrastructure monitoring.

</details>


### [35] [Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets](https://arxiv.org/abs/2511.03855)
*Duong Mai,Lawrence Hall*

Main category: cs.CV

TL;DR: 深度学习模型在图像识别（特别是COVID-19胸部X光检测）中难以泛化到分布外数据，因为它们利用了捷径。本研究发现，在训练期间注入基础噪声（如高斯、散斑、泊松、椒盐噪声）可以显著缩小模型在分布内和分布外数据上的性能差距，从而提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在图像识别（如COVID-19胸部X光检测）中存在泛化性差的问题，尤其是在面对来自不同设备、人群或新的临床来源的分布外数据时。这归因于模型学习了特定于来源的伪影（捷径），而非真正的生物标志物，以最大化在分布内数据上的性能。研究旨在提高模型对分布变化的鲁棒性。

Method: 本研究调查了在训练期间使用基础噪声注入技术（包括高斯噪声、散斑噪声、泊松噪声和椒盐噪声）来提高模型对分布变化的鲁棒性。

Result: 经验结果表明，该技术能显著将分布内（ID）和分布外（OOD）评估之间的性能差距从0.10-0.20缩小到0.01-0.06。这些结果是基于十个随机种子，在AUC、F1、准确率、召回率和特异性等关键指标上平均得出的。

Conclusion: 在训练过程中注入基础噪声是一种有效的方法，可以显著减少深度学习模型在分布内和分布外数据之间的性能差距，从而提高模型对分布变化的鲁棒性，有助于解决模型在学习捷径而非合理生物标志物的问题。

Abstract: Deep learned (DL) models for image recognition have been shown to fail to
generalize to data from different devices, populations, etc. COVID-19 detection
from Chest X-rays (CXRs), in particular, has been shown to fail to generalize
to out-of-distribution (OOD) data from new clinical sources not covered in the
training set. This occurs because models learn to exploit shortcuts -
source-specific artifacts that do not translate to new distributions - rather
than reasonable biomarkers to maximize performance on in-distribution (ID)
data. Rendering the models more robust to distribution shifts, our study
investigates the use of fundamental noise injection techniques (Gaussian,
Speckle, Poisson, and Salt and Pepper) during training. Our empirical results
demonstrate that this technique can significantly reduce the performance gap
between ID and OOD evaluation from 0.10-0.20 to 0.01-0.06, based on results
averaged over ten random seeds across key metrics such as AUC, F1, accuracy,
recall and specificity. Our source code is publicly available at
https://github.com/Duongmai127/Noisy-ood

</details>


### [36] [SILVI: Simple Interface for Labeling Video Interactions](https://arxiv.org/abs/2511.03819)
*Ozan Kanbertay,Richard Vogg,Elif Karakoc,Peter M. Kappeler,Claudia Fichtel,Alexander S. Ecker*

Main category: cs.CV

TL;DR: SILVI是一款开源视频标注软件，旨在弥补现有工具在动物行为和互动标注方面的不足，它能同时实现个体定位和行为互动标注，并生成结构化数据以训练计算机视觉模型。


<details>
  <summary>Details</summary>
Motivation: 现有计算机视觉方法主要关注个体动作检测，而对理解社交和个体动物行为至关重要的互动检测和标注关注较少。目前的开源标注工具要么支持行为标注但无个体定位，要么支持定位但无法捕获互动，存在功能上的空白。

Method: 本文介绍了一个名为SILVI的开源标注软件。它整合了个体定位和行为/互动标注的功能，允许研究人员直接在视频数据中进行标注，并生成适合训练和验证计算机视觉模型的结构化输出。

Result: SILVI使研究人员能够对视频中的动物行为和互动进行精细标注，包括个体定位。它生成的结构化输出可用于开发和验证计算机视觉模型，从而促进细粒度行为分析的自动化方法。该工具不仅适用于动物行为研究，也可能适用于需要提取动态场景图的人类互动标注。

Conclusion: SILVI通过提供一个集成的标注工具，弥合了行为生态学与计算机视觉之间的差距。它能有效标注动物行为和互动，对推动自动化行为分析至关重要，并具有更广泛的应用潜力。

Abstract: Computer vision methods are increasingly used for the automated analysis of
large volumes of video data collected through camera traps, drones, or direct
observations of animals in the wild. While recent advances have focused
primarily on detecting individual actions, much less work has addressed the
detection and annotation of interactions -- a crucial aspect for understanding
social and individualized animal behavior. Existing open-source annotation
tools support either behavioral labeling without localization of individuals,
or localization without the capacity to capture interactions. To bridge this
gap, we present SILVI, an open-source labeling software that integrates both
functionalities. SILVI enables researchers to annotate behaviors and
interactions directly within video data, generating structured outputs suitable
for training and validating computer vision models. By linking behavioral
ecology with computer vision, SILVI facilitates the development of automated
approaches for fine-grained behavioral analyses. Although developed primarily
in the context of animal behavior, SILVI could be useful more broadly to
annotate human interactions in other videos that require extracting dynamic
scene graphs. The software, along with documentation and download instructions,
is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.

</details>


### [37] [Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures](https://arxiv.org/abs/2511.03882)
*Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath*

Main category: cs.CV

TL;DR: 本文探讨了模仿学习在X射线引导下脊柱手术中的应用，通过模拟沙盒训练了基于视觉信息的套管针对齐策略，并在复杂解剖结构中取得了有希望的初步结果。


<details>
  <summary>Details</summary>
Motivation: 基于视频的机器人模仿学习备受关注，但其在解释多视图X射线复杂的X射线引导手术（如脊柱器械植入）中的适用性尚不明确。

Method: 研究开发了一个高度逼真的、可扩展的X射线引导脊柱手术自动化模拟沙盒。他们策划了一个包含正确轨迹和双平面X射线序列的数据集，并训练了模仿学习策略，用于仅基于视觉信息进行规划和开环控制，以迭代对齐套管针。

Result: 该策略在68.5%的案例中首次尝试成功，在不同椎骨水平上保持了安全的椎弓根内轨迹。它能泛化到包括骨折在内的复杂解剖结构，并对不同的初始设置保持鲁棒性。在真实双平面X射线上的测试表明，尽管仅在模拟中训练，模型也能生成合理的轨迹。

Conclusion: 初步结果表明，该方法在实现轻量级、无CT的机器人术中脊柱导航方面具有潜力。但也存在局限性，特别是在入路点精度方面，并且完全闭环控制需要更频繁的反馈。未来工作需要更强大的先验知识和领域知识。

Abstract: Imitation learning-based robot control policies are enjoying renewed interest
in video-based robotics. However, it remains unclear whether this approach
applies to X-ray-guided procedures, such as spine instrumentation. This is
because interpretation of multi-view X-rays is complex. We examine
opportunities and challenges for imitation policy learning in bi-plane-guided
cannula insertion. We develop an in silico sandbox for scalable, automated
simulation of X-ray-guided spine procedures with a high degree of realism. We
curate a dataset of correct trajectories and corresponding bi-planar X-ray
sequences that emulate the stepwise alignment of providers. We then train
imitation learning policies for planning and open-loop control that iteratively
align a cannula solely based on visual information. This precisely controlled
setup offers insights into limitations and capabilities of this method. Our
policy succeeded on the first attempt in 68.5% of cases, maintaining safe
intra-pedicular trajectories across diverse vertebral levels. The policy
generalized to complex anatomy, including fractures, and remained robust to
varied initializations. Rollouts on real bi-planar X-rays further suggest that
the model can produce plausible trajectories, despite training exclusively in
simulation. While these preliminary results are promising, we also identify
limitations, especially in entry point precision. Full closed-look control will
require additional considerations around how to provide sufficiently frequent
feedback. With more robust priors and domain knowledge, such models may provide
a foundation for future efforts toward lightweight and CT-free robotic
intra-operative spinal navigation.

</details>


### [38] [Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model](https://arxiv.org/abs/2511.03888)
*Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui*

Main category: cs.CV

TL;DR: 该研究提出了一种基于剪枝轻量级YOLOv12的实时目标检测框架，结合自对抗训练和数据增强，用于在沙漠环境中通过无人机高效检测垃圾，并在准确性和效率之间取得了最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 全球垃圾危机日益严重，传统垃圾收集方法效率低下且危险，尤其是在沙漠等偏远或恶劣环境中。现有研究多集中于城市环境和可回收物，忽视了有机和危险废物以及沙漠等未充分探索的地形，且缺乏适用于资源受限无人机的实时检测系统。

Method: 该研究提出了一种增强的实时目标检测框架，其核心是经过剪枝的轻量级YOLOv12版本。该框架集成了自对抗训练（SAT）和专门的数据增强策略。模型在DroneTrashNet数据集上进行训练和评估。

Result: 该模型在精度（precision）、召回率（recall）和平均精度均值（mAP）方面取得了显著提升，同时实现了低延迟和紧凑的模型尺寸，适用于部署在资源受限的空中无人机上。与现有最先进的轻量级YOLO变体进行基准测试表明，该模型在准确性和效率之间取得了最佳平衡。

Conclusion: 结合以数据为中心和以模型为中心的增强方法，能够有效实现沙漠环境中鲁棒、实时的垃圾检测。

Abstract: The global waste crisis is escalating, with solid waste generation expected
to increase by 70% by 2050. Traditional waste collection methods, particularly
in remote or harsh environments like deserts, are labor-intensive, inefficient,
and often hazardous. Recent advances in computer vision and deep learning have
opened the door to automated waste detection systems, yet most research focuses
on urban environments and recyclable materials, overlooking organic and
hazardous waste and underexplored terrains such as deserts. In this work, we
propose an enhanced real-time object detection framework based on a pruned,
lightweight version of YOLOv12 integrated with Self-Adversarial Training (SAT)
and specialized data augmentation strategies. Using the DroneTrashNet dataset,
we demonstrate significant improvements in precision, recall, and mean average
precision (mAP), while achieving low latency and compact model size suitable
for deployment on resource-constrained aerial drones. Benchmarking our model
against state-of-the-art lightweight YOLO variants further highlights its
optimal balance of accuracy and efficiency. Our results validate the
effectiveness of combining data-centric and model-centric enhancements for
robust, real-time waste detection in desert environments.

</details>


### [39] [Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition](https://arxiv.org/abs/2511.03891)
*Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat*

Main category: cs.CV

TL;DR: 本文提出了一种名为“基于类的图像合成”（Class-Based Image Composition）的方法，通过将同一类别的多张图像融合成复合输入图像（CoImg），增强了类内方差和信息密度，显著提高了深度学习模型在小型、不平衡或低质量数据集上的诊断准确性，降低了错误预测率。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在处理小型、不平衡数据集或输入图像质量差时，往往会导致较高的错误预测率。

Method: 该研究引入了“基于类的图像合成”方法，将同一类别的多张图像融合为复合输入图像（CoImg），以增强类内方差并提高每个训练样本的有价值信息密度。该方法在光学相干断层扫描数据集（OCTDL）上进行评估，构建了一个完全类别平衡的Co-OCTDL数据集，其中每个扫描都表示为3x1布局的复合图像。研究使用VGG16模型对原始数据集及其变体进行了比较分析，确保了模型架构和超参数的一致性以进行公平比较。

Result: 所提出的方法显著改善了诊断结果。经过增强的数据集（Co-OCTDL）实现了接近完美的准确率（99.6%），F1分数（0.995）和AUC（0.9996），远优于在原始数据集上训练的基线模型。错误预测率也显著降低。

Conclusion: 该方法即使对于受类别不平衡或样本量小影响的“弱数据集”，也能产生高质量的预测，证明了其有效性。

Abstract: Small, imbalanced datasets and poor input image quality can lead to high
false predictions rates with deep learning models. This paper introduces
Class-Based Image Composition, an approach that allows us to reformulate
training inputs through a fusion of multiple images of the same class into
combined visual composites, named Composite Input Images (CoImg). That enhances
the intra-class variance and improves the valuable information density per
training sample and increases the ability of the model to distinguish between
subtle disease patterns. Our method was evaluated on the Optical Coherence
Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et
al., 2024), which contains 2,064 high-resolution optical coherence tomography
(OCT) scans of the human retina, representing seven distinct diseases with a
significant class imbalance. We constructed a perfectly class-balanced version
of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout
composite image. To assess the effectiveness of this new representation, we
conducted a comparative analysis between the original dataset and its variant
using a VGG16 model. A fair comparison was ensured by utilizing the identical
model architecture and hyperparameters for all experiments. The proposed
approach markedly improved diagnostic results.The enhanced Dataset achieved
near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared
to a baseline model trained on raw dataset. The false prediction rate was also
significantly lower, this demonstrates that the method can producehigh-quality
predictions even for weak datasets affected by class imbalance or small sample
size.

</details>


### [40] [I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging](https://arxiv.org/abs/2511.03912)
*Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh*

Main category: cs.CV

TL;DR: 本文提出了一种无监督、无需预言机的框架，用于医学图像中的未知异常检测。该框架通过轻量级适配器更新和不确定性门控样本准入，逐步扩展正常样本集，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 医学图像中未知异常检测面临标注异常稀缺和专家监督成本高昂的挑战。

Method: 该方法从少量经过验证的正常图像种子集开始，无监督地逐步扩展可信的正常样本集。它交替进行轻量级适配器更新和不确定性门控样本准入。通过微小卷积适配器增强冻结的预训练视觉骨干网络，实现快速域适应。提取的嵌入存储在紧凑的核心集（coreset）中，以实现高效的k-NN异常评分。通过双重概率门（z-score阈值距离和基于SWAG的认知不确定性阈值）确保增量扩展的安全性，避免了生成式重建或重放缓冲区。

Result: 该系统持续优化正常性概念，在COVID-CXR数据集上，ROC-AUC从0.9489提升至0.9982；在肺炎CXR数据集上，ROC-AUC从0.6834提升至0.8968；在脑部MRI ND-5数据集上，ROC-AUC从0.6041提升至0.7269，PR-AUC从0.7539提升至0.8211，均显著优于基线方法。

Conclusion: 所提出的框架对于真实世界中标签稀缺的医学图像应用具有高效性和有效性。

Abstract: Unknown anomaly detection in medical imaging remains a fundamental challenge
due to the scarcity of labeled anomalies and the high cost of expert
supervision. We introduce an unsupervised, oracle-free framework that
incrementally expands a trusted set of normal samples without any anomaly
labels. Starting from a small, verified seed of normal images, our method
alternates between lightweight adapter updates and uncertainty-gated sample
admission. A frozen pretrained vision backbone is augmented with tiny
convolutional adapters, ensuring rapid domain adaptation with negligible
computational overhead. Extracted embeddings are stored in a compact coreset
enabling efficient k-nearest neighbor anomaly (k-NN) scoring. Safety during
incremental expansion is enforced by dual probabilistic gates, a sample is
admitted into the normal memory only if its distance to the existing coreset
lies within a calibrated z-score threshold, and its SWAG-based epistemic
uncertainty remains below a seed-calibrated bound. This mechanism prevents
drift and false inclusions without relying on generative reconstruction or
replay buffers. Empirically, our system steadily refines the notion of
normality as unlabeled data arrive, producing substantial gains over baselines.
On COVID-CXR, ROC-AUC improves from 0.9489 to 0.9982 (F1: 0.8048 to 0.9746); on
Pneumonia CXR, ROC-AUC rises from 0.6834 to 0.8968; and on Brain MRI ND-5,
ROC-AUC increases from 0.6041 to 0.7269 and PR-AUC from 0.7539 to 0.8211. These
results highlight the effectiveness and efficiency of the proposed framework
for real-world, label-scarce medical imaging applications.

</details>


### [41] [Adaptive Temporal Refinement: Continuous Depth Allocation and Distance Regression for Efficient Action Localization](https://arxiv.org/abs/2511.03943)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CV

TL;DR: 本文提出了边界距离回归（BDR）和自适应时间细化（ATR）两种互补方法，显著提高了时间动作定位的精度和计算效率，通过距离回归实现更锐利的边界检测，并通过自适应计算分配优化资源。


<details>
  <summary>Details</summary>
Motivation: 现有时间动作定位方法在边界检测上精度不足，且对不同难度的边界采用统一计算，导致效率低下。

Method: 1. 边界距离回归（BDR）：通过有符号距离回归而非分类来提供信息理论上最优的定位，能与现有方法轻松集成。2. 自适应时间细化（ATR）：通过连续深度选择τ∈[0,1]分配计算资源，实现端到端可微分优化，无需强化学习。3. 通过知识蒸馏减轻训练成本，使轻量级学生模型能保持高性能。

Result: 1. BDR使边界峰值锐化43%，在不同架构上将mAP@0.7提高了1.8%到3.1%。2. ATR在THUMOS14上以162G FLOPs实现56.5%的mAP@0.7，比统一处理的53.6%（198G FLOPs）提高了2.9%，计算量减少18%。在短动作上，增益随边界异质性增加，提高了4.2%。3. 通过知识蒸馏，轻量级学生模型在基线成本下保持了99%的性能。结果在四个基准上通过严格统计检验得到验证。

Conclusion: BDR和ATR显著提升了时间动作定位的精度和效率，尤其是在具有挑战性的边界上，且具有广泛适用性，并能通过知识蒸馏有效降低训练成本。

Abstract: Temporal action localization requires precise boundary detection; however,
current methods apply uniform computation despite significant variations in
difficulty across boundaries. We present two complementary contributions.
First, Boundary Distance Regression (BDR) provides information-theoretically
optimal localization through signed-distance regression rather than
classification, achieving 43\% sharper boundary peaks. BDR retrofits to
existing methods with approximately 50 lines of code, yielding consistent 1.8
to 3.1\% mAP@0.7 improvements across diverse architectures. Second, Adaptive
Temporal Refinement (ATR) allocates computation via continuous depth selection
$\tau \in [0,1]$, enabling end-to-end differentiable optimization without
reinforcement learning. On THUMOS14, ATR achieves 56.5\% mAP@0.7 at 162G FLOPs,
compared to 53.6\% at 198G for uniform processing, providing a 2.9\%
improvement with 18\% less compute. Gains scale with boundary heterogeneity,
showing 4.2\% improvement on short actions. Training cost is mitigated via
knowledge distillation, with lightweight students retaining 99\% performance at
baseline cost. Results are validated across four benchmarks with rigorous
statistical testing.

</details>


### [42] [Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization](https://arxiv.org/abs/2511.03950)
*Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang*

Main category: cs.CV

TL;DR: 本文提出了一种统一框架，通过高斯引导的可微分网格渲染，同时优化网格几何和顶点颜色，从多视图图像重建高质量3D对象，支持下游编辑任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多视图3D重建中通常将几何精度和真实感渲染解耦，阻碍了下游编辑任务（如重打光和形状变形）。需要一种统一处理几何和外观优化的方法。

Method: 提出了一种新颖的框架，利用高斯引导的网格可微分渲染，同时优化网格几何（顶点位置和面）和顶点颜色。该方法利用输入图像的光度一致性以及法线图和深度图的几何正则化。

Result: 实现了高质量的3D重建。

Conclusion: 所获得的高质量3D重建可进一步应用于下游编辑任务，如重打光和形状变形。

Abstract: Reconstructing real-world objects from multi-view images is essential for
applications in 3D editing, AR/VR, and digital content creation. Existing
methods typically prioritize either geometric accuracy (Multi-View Stereo) or
photorealistic rendering (Novel View Synthesis), often decoupling geometry and
appearance optimization, which hinders downstream editing tasks. This paper
advocates an unified treatment on geometry and appearance optimization for
seamless Gaussian-mesh joint optimization. More specifically, we propose a
novel framework that simultaneously optimizes mesh geometry (vertex positions
and faces) and vertex colors via Gaussian-guided mesh differentiable rendering,
leveraging photometric consistency from input images and geometric
regularization from normal and depth maps. The obtained high-quality 3D
reconstruction can be further exploit in down-stream editing tasks, such as
relighting and shape deformation. The code will be publicly available upon
acceptance.

</details>


### [43] [A Linear Fractional Transformation Model and Calibration Method for Light Field Camera](https://arxiv.org/abs/2511.03962)
*Zhong Chen,Changfeng Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于线性分数变换(LFT)参数α的光场相机内参标定方法，用于解耦主镜头和微透镜阵列，结合最小二乘解析解和非线性优化，并验证了其在物理和模拟数据上的性能，同时实现了光场图像的快速模拟。


<details>
  <summary>Details</summary>
Motivation: 对于使用光场相机进行3D重建，准确标定内部参数是至关重要但具有挑战性的先决条件。

Method: 该方法引入了一个线性分数变换(LFT)参数α来解耦主镜头和微透镜阵列(MLA)。它包括一个基于最小二乘的解析解，随后进行非线性优化精炼。文中还介绍了从原始图像中检测特征的方法。

Result: 在物理和模拟数据上的实验结果验证了所提出方法的性能。基于所提出的模型，原始光场图像的模拟变得更快，这对于数据驱动的深度学习方法至关重要。

Conclusion: 所提出的方法能够有效且准确地标定光场相机内部参数，并通过解耦镜头和微透镜阵列简化了模型，同时实现了光场图像的快速模拟，为深度学习等应用提供了支持。

Abstract: Accurate calibration of internal parameters is a crucial yet challenging
prerequisite for 3D reconstruction using light field cameras. In this paper, we
propose a linear fractional transformation(LFT) parameter $\alpha$ to decoupled
the main lens and micro lens array (MLA). The proposed method includes an
analytical solution based on least squares, followed by nonlinear refinement.
The method for detecting features from the raw images is also introduced.
Experimental results on both physical and simulated data have verified the
performance of proposed method. Based on proposed model, the simulation of raw
light field images becomes faster, which is crucial for data-driven deep
learning methods. The corresponding code can be obtained from the author's
website.

</details>


### [44] [Room Envelopes: A Synthetic Dataset for Indoor Layout Reconstruction from Images](https://arxiv.org/abs/2511.03970)
*Sam Bahrami,Dylan Campbell*

Main category: cs.CV

TL;DR: 本文提出了一个名为“Room Envelopes”的合成数据集，旨在通过提供可见表面和去除家具后的结构布局表面点图，促进从单目图像预测场景结构元素（如墙壁、地板）的研究，从而实现对场景完整范围的理解。


<details>
  <summary>Details</summary>
Motivation: 现代场景重建方法只能恢复可见表面，导致重建不完整，缺失所有被遮挡的表面。尽管在给定部分观测的情况下重建整个物体方面取得了进展，但场景的结构元素（如墙壁、地板、天花板）受到的关注较少。研究认为这些结构元素通常是平面、重复且简单的，因此更容易预测，可能适合成本较低的方法。

Method: 本文提出了一个名为“Room Envelopes”的合成数据集。该数据集为每张RGB图像提供两个关联的点图：一个捕获可见表面，另一个捕获移除家具和固定装置后的第一层表面（即结构布局）。这种设置能够为前馈式单目几何估计器提供直接监督，使其能够同时预测第一个可见表面和第一个布局表面。

Result: 通过“Room Envelopes”数据集，本文展示了如何为预测可见表面和结构布局表面的前馈式单目几何估计器提供直接监督。这使得模型能够理解场景的范围以及其中物体的形状和位置。

Conclusion: 通过预测可见表面和去除家具后的结构布局表面，可以获得对场景范围以及其中物体形状和位置的全面理解。

Abstract: Modern scene reconstruction methods are able to accurately recover 3D
surfaces that are visible in one or more images. However, this leads to
incomplete reconstructions, missing all occluded surfaces. While much progress
has been made on reconstructing entire objects given partial observations using
generative models, the structural elements of a scene, like the walls, floors
and ceilings, have received less attention. We argue that these scene elements
should be relatively easy to predict, since they are typically planar,
repetitive and simple, and so less costly approaches may be suitable. In this
work, we present a synthetic dataset -- Room Envelopes -- that facilitates
progress on this task by providing a set of RGB images and two associated
pointmaps for each image: one capturing the visible surface and one capturing
the first surface once fittings and fixtures are removed, that is, the
structural layout. As we show, this enables direct supervision for feed-forward
monocular geometry estimators that predict both the first visible surface and
the first layout surface. This confers an understanding of the scene's extent,
as well as the shape and location of its objects.

</details>


### [45] [Simple 3D Pose Features Support Human and Machine Social Scene Understanding](https://arxiv.org/abs/2511.03988)
*Wenshuo Qin,Leyla Isik*

Main category: cs.CV

TL;DR: 人类在理解社会互动时依赖3D视觉空间姿态信息，尤其是面部位置和方向，这比大多数AI模型表现更好。研究发现，这种结构化的3D姿态数据至关重要，并能显著提升AI模型的性能。


<details>
  <summary>Details</summary>
Motivation: 人类能轻松从视觉输入中提取关于他人社会互动的信息，但其计算机制尚不清楚，且即使最先进的AI视觉系统也难以识别社会互动。本研究假设人类依赖3D视觉空间姿态信息进行社会互动判断，而这在大多数AI视觉模型中是缺失的。

Method: 研究结合了最先进的姿态和深度估计算法，从描绘日常人类活动的短视频片段中提取了人物的3D关节位置。然后，将这些3D关节位置预测人类社会互动判断的能力与当前AI视觉模型进行了比较。此外，研究还推导出一组紧凑的3D社会姿态特征（仅描述视频中面部的3D位置和方向），并测试了这些最小描述符的预测能力是否与完整3D关节集相当，以及它们与现成AI视觉模型嵌入结合后能否提高AI性能。最后，评估了3D社会姿态特征在每个现成AI模型中的表示程度如何预测模型匹配人类社会判断的能力。

Result: 3D关节位置在预测人类社会互动判断方面显著优于大多数当前AI视觉模型，表明关键的社会信息存在于明确的身体位置中，而非大多数视觉模型（包括用于提取关节位置的姿态模型的层级嵌入）的学习特征中。一个紧凑的3D社会姿态特征集（面部3D位置和方向）与完整3D关节集的预测能力相当，并且在与现成AI视觉模型的嵌入结合时，显著提高了它们的性能。此外，3D社会姿态特征在每个现成AI视觉模型中的表示程度预示了该模型匹配人类社会判断的能力。

Conclusion: 研究结果提供了强有力的证据，表明人类对社会场景的理解依赖于3D姿态的明确表示，并且可以通过简单、结构化的视觉空间原语来支持。

Abstract: Humans can quickly and effortlessly extract a variety of information about
others' social interactions from visual input, ranging from visuospatial cues
like whether two people are facing each other to higher-level information. Yet,
the computations supporting these abilities remain poorly understood, and
social interaction recognition continues to challenge even the most advanced AI
vision systems. Here, we hypothesized that humans rely on 3D visuospatial pose
information to make social interaction judgments, which is absent in most AI
vision models. To test this, we combined state-of-the-art pose and depth
estimation algorithms to extract 3D joint positions of people in short video
clips depicting everyday human actions and compared their ability to predict
human social interaction judgments with current AI vision models. Strikingly,
3D joint positions outperformed most current AI vision models, revealing that
key social information is available in explicit body position but not in the
learned features of most vision models, including even the layer-wise
embeddings of the pose models used to extract joint positions. To uncover the
critical pose features humans use to make social judgments, we derived a
compact set of 3D social pose features describing only the 3D position and
direction of faces in the videos. We found that these minimal descriptors
matched the predictive strength of the full set of 3D joints and significantly
improved the performance of off-the-shelf AI vision models when combined with
their embeddings. Moreover, the degree to which 3D social pose features were
represented in each off-the-shelf AI vision model predicted the model's ability
to match human social judgments. Together, our findings provide strong evidence
that human social scene understanding relies on explicit representations of 3D
pose and can be supported by simple, structured visuospatial primitives.

</details>


### [46] [CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation](https://arxiv.org/abs/2511.03992)
*Yuwen Tao,Kanglei Zhou,Xin Tan,Yuan Xie*

Main category: cs.CV

TL;DR: 本文提出了一种名为CaRF的3D高斯场参考分割框架，旨在解决现有方法在跨视图一致性方面的不足。CaRF通过引入高斯场相机编码和训练中配对视图监督，直接在3D高斯空间操作并实现了多视图一致性，在多个基准测试上显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯场参考分割（R3DGS）方法依赖2D渲染的伪监督和视图特定的特征学习，导致在跨视图一致性方面表现不佳，难以将语言表达式与3D高斯场中的对应区域进行可靠的定位。

Method: 本文提出了Camera Aware Referring Field (CaRF)，一个完全可微分的框架，直接在3D高斯空间中操作以实现多视图一致性。具体方法包括：1) Gaussian Field Camera Encoding (GFCE)，将相机几何信息融入高斯文本交互中，以显式建模视图相关变化并增强几何推理。2) In Training Paired View Supervision (ITPVS)，在训练期间对校准视图中的每个高斯逻辑进行对齐，以减轻单视图过拟合并优化视图间差异。

Result: CaRF在三个代表性基准测试上实现了显著改进。在Ref LERF、LERF OVS和3D OVS数据集上，mIoU分别比现有最先进方法平均提高了16.8%、4.3%和2.0%。

Conclusion: CaRF促进了更可靠和视图一致的3D场景理解，有望为具身智能、AR/VR交互和自主感知等领域带来潜在益处。

Abstract: Referring 3D Gaussian Splatting Segmentation (R3DGS) aims to interpret
free-form language expressions and localize the corresponding 3D regions in
Gaussian fields. While recent advances have introduced cross-modal alignment
between language and 3D geometry, existing pipelines still struggle with
cross-view consistency due to their reliance on 2D rendered pseudo supervision
and view specific feature learning. In this work, we present Camera Aware
Referring Field (CaRF), a fully differentiable framework that operates directly
in the 3D Gaussian space and achieves multi view consistency. Specifically,
CaRF introduces Gaussian Field Camera Encoding (GFCE), which incorporates
camera geometry into Gaussian text interactions to explicitly model view
dependent variations and enhance geometric reasoning. Building on this, In
Training Paired View Supervision (ITPVS) is proposed to align per Gaussian
logits across calibrated views during training, effectively mitigating single
view overfitting and exposing inter view discrepancies for optimization.
Extensive experiments on three representative benchmarks demonstrate that CaRF
achieves average improvements of 16.8%, 4.3%, and 2.0% in mIoU over state of
the art methods on the Ref LERF, LERF OVS, and 3D OVS datasets, respectively.
Moreover, this work promotes more reliable and view consistent 3D scene
understanding, with potential benefits for embodied AI, AR/VR interaction, and
autonomous perception.

</details>


### [47] [PhysCorr: Dual-Reward DPO for Physics-Constrained Text-to-Video Generation with Automated Preference Selection](https://arxiv.org/abs/2511.03997)
*Peiyao Wang,Weining Wang,Qi Li*

Main category: cs.CV

TL;DR: PhysCorr是一个统一框架，用于建模、评估和优化视频生成中的物理一致性，通过引入PhysicsRM奖励模型和PhyDPO优化管道，显著提升了生成视频的物理真实感。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成模型虽然在感知质量上有所进步，但常违反物理原理，表现为不合理的物体动态、不连贯的交互和不真实的运动模式，这阻碍了其在具身AI、机器人和模拟密集型领域的应用。

Method: 本文提出了PhysCorr框架。具体而言，引入了PhysicsRM，这是首个量化对象内部稳定性与对象间交互的双维度奖励模型。在此基础上，开发了PhyDPO，一种新颖的直接偏好优化管道，利用对比反馈和物理感知重加权来指导生成物理连贯的输出。该方法与模型无关且可扩展。

Result: 在多个基准测试中，PhysCorr显著提升了物理真实感，同时保持了视觉保真度和语义对齐。

Conclusion: 这项工作是迈向物理基础且值得信赖的视频生成关键一步。

Abstract: Recent advances in text-to-video generation have achieved impressive
perceptual quality, yet generated content often violates fundamental principles
of physical plausibility - manifesting as implausible object dynamics,
incoherent interactions, and unrealistic motion patterns. Such failures hinder
the deployment of video generation models in embodied AI, robotics, and
simulation-intensive domains. To bridge this gap, we propose PhysCorr, a
unified framework for modeling, evaluating, and optimizing physical consistency
in video generation. Specifically, we introduce PhysicsRM, the first
dual-dimensional reward model that quantifies both intra-object stability and
inter-object interactions. On this foundation, we develop PhyDPO, a novel
direct preference optimization pipeline that leverages contrastive feedback and
physics-aware reweighting to guide generation toward physically coherent
outputs. Our approach is model-agnostic and scalable, enabling seamless
integration into a wide range of video diffusion and transformer-based
backbones. Extensive experiments across multiple benchmarks demonstrate that
PhysCorr achieves significant improvements in physical realism while preserving
visual fidelity and semantic alignment. This work takes a critical step toward
physically grounded and trustworthy video generation.

</details>


### [48] [MedDChest: A Content-Aware Multimodal Foundational Vision Model for Thoracic Imaging](https://arxiv.org/abs/2511.04016)
*Mahmoud Soliman,Islam Osman,Mohamed S. Shehata,Rasika Rajapakshe*

Main category: cs.CV

TL;DR: MedDChest是一个专门针对胸腔影像优化的新型基础Vision Transformer模型，通过在大规模多模态胸腔影像数据集上从头预训练，并结合内容感知的数据增强策略，显著优于ImageNet预训练模型，为胸腔诊断任务提供更优的起点。


<details>
  <summary>Details</summary>
Motivation: 当前医学影像视觉模型的性能受限于将预训练于域外自然图像的骨干模型进行微调，导致存在显著的领域差距。

Method: 本文提出了MedDChest模型，在一个包含超过120万张胸部X射线和CT图像的大规模、多模态、精选数据集中从头开始预训练。核心技术贡献是“引导随机裁剪”（Guided Random Resized Crops），这是一种新颖的、内容感知的数据增强策略，能将采样偏向解剖学相关区域，克服了标准裁剪技术在医学扫描上的低效性。

Result: 通过在多样化的下游诊断任务上进行微调验证，MedDChest在经验上显著优于强大的、公开可用的ImageNet预训练模型。模型权重将公开可用。

Conclusion: 大规模、域内预训练结合领域特定数据增强的方法被证实具有优越性。MedDChest提供了一个强大且稳健的特征提取器，可作为各种胸腔诊断任务的显著更优的起点。

Abstract: The performance of vision models in medical imaging is often hindered by the
prevailing paradigm of fine-tuning backbones pre-trained on out-of-domain
natural images. To address this fundamental domain gap, we propose MedDChest, a
new foundational Vision Transformer (ViT) model optimized specifically for
thoracic imaging. We pre-trained MedDChest from scratch on a massive, curated,
multimodal dataset of over 1.2 million images, encompassing different
modalities including Chest X-ray and Computed Tomography (CT) compiled from 10
public sources. A core technical contribution of our work is Guided Random
Resized Crops, a novel content-aware data augmentation strategy that biases
sampling towards anatomically relevant regions, overcoming the inefficiency of
standard cropping techniques on medical scans. We validate our model's
effectiveness by fine-tuning it on a diverse set of downstream diagnostic
tasks. Comprehensive experiments empirically demonstrate that MedDChest
significantly outperforms strong, publicly available ImageNet-pretrained
models. By establishing the superiority of large-scale, in-domain pre-training
combined with domain-specific data augmentation, MedDChest provides a powerful
and robust feature extractor that serves as a significantly better starting
point for a wide array of thoracic diagnostic tasks. The model weights will be
made publicly available to foster future research and applications.

</details>


### [49] [GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization](https://arxiv.org/abs/2511.04008)
*Mahmoud Soliman,Omar Abdelaziz,Ahmed Radwan,Anand,Mohamed Shehata*

Main category: cs.CV

TL;DR: 该论文提出GNN-MoE，一种用于域泛化（DG）的参数高效微调（PEFT）方法，通过图神经网络（GNN）路由器在图像块间图上动态分配图像块给专家模型，以实现鲁棒且轻量级的ViT性能。


<details>
  <summary>Details</summary>
Motivation: 在未见领域上实现Vision Transformer（ViT）的鲁棒性能是域泛化（DG）的目标。然而，有效适应预训练ViT以进行DG具有挑战性，因为标准的微调方法成本高昂且可能损害泛化能力。

Method: 本文提出了GNN-MoE，通过结合参数高效微调（PEFT）和混合专家（MoE）框架来增强DG。该方法利用高效的Kronecker适配器。其核心创新是一个新颖的图神经网络（GNN）路由器（可以是GCN、GAT或SAGE），它在图像块间图上操作，而不是传统的基于token的路由，动态地将图像块分配给专业的专家。这种上下文感知的GNN路由利用图像块间的关系，以更好地适应域偏移。

Result: GNN-MoE在DG基准测试中取得了最先进或具有竞争力的性能，同时保持了高参数效率。

Conclusion: 研究结果突出了基于图的上下文路由对于实现鲁棒、轻量级域泛化任务的实用性。

Abstract: Domain generalization (DG) seeks robust Vision Transformer (ViT) performance
on unseen domains. Efficiently adapting pretrained ViTs for DG is challenging;
standard fine-tuning is costly and can impair generalization. We propose
GNN-MoE, enhancing Parameter-Efficient Fine-Tuning (PEFT) for DG with a
Mixture-of-Experts (MoE) framework using efficient Kronecker adapters. Instead
of token-based routing, a novel Graph Neural Network (GNN) router (GCN, GAT,
SAGE) operates on inter-patch graphs to dynamically assign patches to
specialized experts. This context-aware GNN routing leverages inter-patch
relationships for better adaptation to domain shifts. GNN-MoE achieves
state-of-the-art or competitive DG benchmark performance with high parameter
efficiency, highlighting the utility of graph-based contextual routing for
robust, lightweight DG.

</details>


### [50] [Near-Lossless 3D Voxel Representation Free from Iso-surface](https://arxiv.org/abs/2511.04029)
*Yihao Luo,Xianglong He,Chuanyu Pan,Yiwen Chen,Jiaqi Wu,Yangguang Li,Wanli Ouyang,Yuanming Hu,Guang Yang,ChoonHwai Yap*

Main category: cs.CV

TL;DR: 提出了一种名为“忠实轮廓”（Faithful Contouring）的稀疏体素化表示方法，可实现任意网格的近乎无损的几何保真度，并设计了双模态自编码器用于可扩展的形状重建。


<details>
  <summary>Details</summary>
Motivation: 现有的基于等值面的三维网格体素化表示方法，因依赖水密化或渲染优化而牺牲了几何保真度。需要一种更准确高效、能保持几何细节的体素化表示方法。

Method: 提出了“忠实轮廓”方法，这是一种稀疏体素化表示，支持2048+分辨率，无需将网格转换为场函数或在重新网格化时提取等值面。它通过保留锐度和内部结构实现近乎无损的保真度。此外，还设计了一个双模态自编码器，用于可扩展且细节保留的形状重建。

Result: 在直接表示方面，实现了$10^{-5}$级别的距离误差。在网格重建方面，与强基线相比，倒角距离（Chamfer Distance）减少了93%，F-score提高了35%。在准确性和效率上均超越现有方法。

Conclusion: “忠实轮廓”方法在三维网格表示和重建方面展现出卓越的保真度和效率，使其成为三维学习任务的优秀表示方法。

Abstract: Accurate and efficient voxelized representations of 3D meshes are the
foundation of 3D reconstruction and generation. However, existing
representations based on iso-surface heavily rely on water-tightening or
rendering optimization, which inevitably compromise geometric fidelity. We
propose Faithful Contouring, a sparse voxelized representation that supports
2048+ resolutions for arbitrary meshes, requiring neither converting meshes to
field functions nor extracting the isosurface during remeshing. It achieves
near-lossless fidelity by preserving sharpness and internal structures, even
for challenging cases with complex geometry and topology. The proposed method
also shows flexibility for texturing, manipulation, and editing. Beyond
representation, we design a dual-mode autoencoder for Faithful Contouring,
enabling scalable and detail-preserving shape reconstruction. Extensive
experiments show that Faithful Contouring surpasses existing methods in
accuracy and efficiency for both representation and reconstruction. For direct
representation, it achieves distance errors at the $10^{-5}$ level; for mesh
reconstruction, it yields a 93\% reduction in Chamfer Distance and a 35\%
improvement in F-score over strong baselines, confirming superior fidelity as a
representation for 3D learning tasks.

</details>


### [51] [A Hybrid Deep Learning Model for Robust Biometric Authentication from Low-Frame-Rate PPG Signals](https://arxiv.org/abs/2511.04037)
*Arfina Rahman,Mahesh Banavar*

Main category: cs.CV

TL;DR: 本研究提出了一种基于低帧率指尖视频PPG信号的轻量级生物识别认证框架，通过结合CWT转换的2D时频图和混合深度学习模型CVT-ConvMixer-LSTM，实现了98%的认证准确率，适用于移动和嵌入式安全应用。


<details>
  <summary>Details</summary>
Motivation: PPG信号因其无创、活体检测和低成本可穿戴设备的适用性，在生物识别认证中受到关注。然而，PPG信号质量易受运动伪影、光照变化和个体生理差异的影响，因此需要鲁棒的特征提取和分类方法。

Method: 该研究利用CFIHSR数据集（46名受试者，14 Hz采样率的PPG记录）。原始PPG信号经过基线漂移去除、基于PCA的运动伪影抑制、带通滤波、傅里叶重采样和幅度归一化等预处理。为生成鲁棒表示，将一维PPG段通过连续小波变换（CWT）转换为二维时频标量图。开发了一个混合深度学习模型CVT-ConvMixer-LSTM，结合了卷积视觉Transformer（CVT）和ConvMixer分支的空间特征与长短期记忆网络（LSTM）的时间特征。

Result: 在46名受试者上的实验结果表明，该认证框架实现了98%的认证准确率。该模型对噪声和受试者间的变异性表现出鲁棒性。

Conclusion: 所提出的系统因其高效、可扩展性以及固有的活体检测能力，非常适用于实际的移动和嵌入式生物识别安全应用。

Abstract: Photoplethysmography (PPG) signals, which measure changes in blood volume in
the skin using light, have recently gained attention in biometric
authentication because of their non-invasive acquisition, inherent liveness
detection, and suitability for low-cost wearable devices. However, PPG signal
quality is challenged by motion artifacts, illumination changes, and
inter-subject physiological variability, making robust feature extraction and
classification crucial. This study proposes a lightweight and cost-effective
biometric authentication framework based on PPG signals extracted from
low-frame-rate fingertip videos. The CFIHSR dataset, comprising PPG recordings
from 46 subjects at a sampling rate of 14 Hz, is employed for evaluation. The
raw PPG signals undergo a standard preprocessing pipeline involving baseline
drift removal, motion artifact suppression using Principal Component Analysis
(PCA), bandpass filtering, Fourier-based resampling, and amplitude
normalization. To generate robust representations, each one-dimensional PPG
segment is converted into a two-dimensional time-frequency scalogram via the
Continuous Wavelet Transform (CWT), effectively capturing transient
cardiovascular dynamics. We developed a hybrid deep learning model, termed
CVT-ConvMixer-LSTM, by combining spatial features from the Convolutional Vision
Transformer (CVT) and ConvMixer branches with temporal features from a Long
Short-Term Memory network (LSTM). The experimental results on 46 subjects
demonstrate an authentication accuracy of 98%, validating the robustness of the
model to noise and variability between subjects. Due to its efficiency,
scalability, and inherent liveness detection capability, the proposed system is
well-suited for real-world mobile and embedded biometric security applications.

</details>


### [52] [Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment](https://arxiv.org/abs/2511.04078)
*Zehui Feng,Chenqi Zhang,Mingru Wang,Minuo Wei,Shiwei Cheng,Cuntai Guan,Ting Han*

Main category: cs.CV

TL;DR: Bratrix是一种端到端的多模态语言锚定视觉-大脑对齐框架。它通过解耦视觉和语言语义、投影到共享潜在空间、引入不确定性感模块以及两阶段训练策略，显著提升了从EEG、MEG和fMRI信号中进行检索、重建和图像描述的性能。


<details>
  <summary>Details</summary>
Motivation: 从EEG、MEG和fMRI等神经信号中揭示视觉语义面临主体变异性和视觉特征纠缠的挑战。现有方法主要将神经活动直接与视觉嵌入对齐，但纯视觉表示无法捕捉潜在的语义维度，限制了解释性和深度鲁棒性。

Method: Bratrix是首个实现多模态语言锚定视觉-大脑对齐的端到端框架。它将视觉刺激解耦为分层的视觉和语言语义组件，并将视觉和大脑表征投影到共享潜在空间，形成对齐的视觉-语言和大脑-语言嵌入。为模拟人类感知可靠性并处理噪声神经信号，Bratrix整合了一个新颖的不确定性感模块，在对齐过程中应用不确定性感知加权。此外，它利用可学习的语言锚定语义矩阵增强跨模态相关性，并采用单模态预训练后进行多模态微调的两阶段训练策略。

Result: Bratrix在EEG、MEG和fMRI基准测试中，相较于现有最先进方法，显著提升了检索、重建和图像描述的性能。特别是在200路EEG检索任务中，性能提升超过14.3%。

Conclusion: Bratrix通过其创新的多模态语言锚定视觉-大脑对齐方法，有效克服了从神经信号中揭示视觉语义的现有挑战。其结合语义解耦、共享潜在空间、不确定性感知和两阶段训练的策略，在多个任务中展现出卓越的性能，为理解视觉神经编码提供了更深层次的洞察。

Abstract: Unveiling visual semantics from neural signals such as EEG, MEG, and fMRI
remains a fundamental challenge due to subject variability and the entangled
nature of visual features. Existing approaches primarily align neural activity
directly with visual embeddings, but visual-only representations often fail to
capture latent semantic dimensions, limiting interpretability and deep
robustness. To address these limitations, we propose Bratrix, the first
end-to-end framework to achieve multimodal Language-Anchored Vision-Brain
alignment. Bratrix decouples visual stimuli into hierarchical visual and
linguistic semantic components, and projects both visual and brain
representations into a shared latent space, enabling the formation of aligned
visual-language and brain-language embeddings. To emulate human-like perceptual
reliability and handle noisy neural signals, Bratrix incorporates a novel
uncertainty perception module that applies uncertainty-aware weighting during
alignment. By leveraging learnable language-anchored semantic matrices to
enhance cross-modal correlations and employing a two-stage training strategy of
single-modality pretraining followed by multimodal fine-tuning, Bratrix-M
improves alignment precision. Extensive experiments on EEG, MEG, and fMRI
benchmarks demonstrate that Bratrix improves retrieval, reconstruction, and
captioning performance compared to state-of-the-art methods, specifically
surpassing 14.3% in 200-way EEG retrieval task. Code and model are available.

</details>


### [53] [Adversarial and Score-Based CT Denoising: CycleGAN vs Noise2Score](https://arxiv.org/abs/2511.04083)
*Abu Hanif Muhammad Syarubany*

Main category: cs.CV

TL;DR: 本文研究了在非配对和自监督CT图像去噪中，CycleGAN和Noise2Score两种方法的性能。结果显示，CycleGAN在最终图像质量上表现最佳，而Noise2Score在处理极度噪声输入时表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究CT图像去噪，尤其是在缺乏干净-噪声图像对（非配对和自监督）的情况下，寻找高效且数据利用率高的去噪范式。

Method: 评估了两种强大的、训练数据高效的范式：基于CycleGAN的残差转换器（采用U-Net骨干网络）和Noise2Score (N2S) 分数匹配去噪器。在共同评估协议下，通过配置扫描确定了CycleGAN的最佳设置，并将其训练至收敛。

Result: 经过优化的CycleGAN将噪声输入从34.66 dB / 0.9234 SSIM提升至38.913 dB / 0.971 SSIM，并取得了1.9441的估计分数和1.9343的Kaggle排行榜分数。Noise2Score在绝对PSNR/SSIM上略逊一筹，但在处理极度噪声输入时获得了显著提升。总体而言，CycleGAN提供了最强的最终图像质量。

Conclusion: CycleGAN在最终图像质量方面表现最佳。Noise2Score提供了一种鲁棒的、无需配对的替代方案，具有竞争力的性能，尤其适用于干净图像对不可用且输入噪声极大的情况。

Abstract: We study CT image denoising in the unpaired and self-supervised regimes by
evaluating two strong, training-data-efficient paradigms: a CycleGAN-based
residual translator and a Noise2Score (N2S) score-matching denoiser. Under a
common evaluation protocol, a configuration sweep identifies a simple standard
U-Net backbone within CycleGAN (lambda_cycle = 30, lambda_iden = 2, ngf = ndf =
64) as the most reliable setting; we then train it to convergence with a longer
schedule. The selected CycleGAN improves the noisy input from 34.66 dB / 0.9234
SSIM to 38.913 dB / 0.971 SSIM and attains an estimated score of 1.9441 and an
unseen-set (Kaggle leaderboard) score of 1.9343. Noise2Score, while slightly
behind in absolute PSNR / SSIM, achieves large gains over very noisy inputs,
highlighting its utility when clean pairs are unavailable. Overall, CycleGAN
offers the strongest final image quality, whereas Noise2Score provides a robust
pair-free alternative with competitive performance. Source code is available at
https://github.com/hanifsyarubany/CT-Scan-Image-Denoising-using-CycleGAN-and-Noise2Score.

</details>


### [54] [When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation](https://arxiv.org/abs/2511.04084)
*Nishchal Sapkota,Haoyan Shi,Yejia Zhang,Xianshi Ma,Bofang Zheng,Danny Z. Chen*

Main category: cs.CV

TL;DR: 本文提出UKAST，一种将基于有理函数的Kolmogorov-Arnold网络（KANs）集成到Swin Transformer编码器中的U-Net类架构，旨在实现数据高效的医学图像分割，并在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割对于诊断和治疗规划至关重要，但面临复杂解剖结构和标注数据有限的挑战。传统的CNN方法难以建模长距离依赖，而Transformer虽然能捕捉全局上下文，却存在数据需求大和计算成本高的缺点。

Method: 本文引入UKAST，一种U-Net类架构，将基于有理函数的Kolmogorov-Arnold网络（KANs）集成到Swin Transformer编码器中。通过利用Kolmogorov-Arnold Transformer (KAT) 中的有理基函数和Group Rational KANs (GR-KANs)，UKAST解决了传统样条基KANs的低效问题，实现了更具表达力和数据效率的框架，与SwinUNETR相比，FLOPs更少，参数量仅有微小增加。

Result: UKAST在四个不同的2D和3D医学图像分割基准测试中取得了最先进的性能，持续超越了基于CNN和Transformer的基线方法。尤其是在数据稀缺的环境中，UKAST展现出卓越的准确性，有效缓解了标准Vision Transformer对数据量大的依赖。

Conclusion: 这些结果表明，KAN增强型Transformer在推动数据高效医学图像分割方面具有巨大潜力。

Abstract: Medical image segmentation is critical for accurate diagnostics and treatment
planning, but remains challenging due to complex anatomical structures and
limited annotated training data. CNN-based segmentation methods excel at local
feature extraction, but struggle with modeling long-range dependencies.
Transformers, on the other hand, capture global context more effectively, but
are inherently data-hungry and computationally expensive. In this work, we
introduce UKAST, a U-Net like architecture that integrates rational-function
based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders. By
leveraging rational base functions and Group Rational KANs (GR-KANs) from the
Kolmogorov-Arnold Transformer (KAT), our architecture addresses the
inefficiencies of vanilla spline-based KANs, yielding a more expressive and
data-efficient framework with reduced FLOPs and only a very small increase in
parameter count compared to SwinUNETR. UKAST achieves state-of-the-art
performance on four diverse 2D and 3D medical image segmentation benchmarks,
consistently surpassing both CNN- and Transformer-based baselines. Notably, it
attains superior accuracy in data-scarce settings, alleviating the data-hungry
limitations of standard Vision Transformers. These results show the potential
of KAN-enhanced Transformers to advance data-efficient medical image
segmentation. Code is available at: https://github.com/nsapkota417/UKAST

</details>


### [55] [BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary Refinement for Embedded Systems](https://arxiv.org/abs/2511.04388)
*Chang Liu,Juan Li,Sheng Zhang,Chang Liu,Jie Li,Xu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为BoRe-Depth的单目深度估计算法，专为嵌入式系统设计，参数量仅8.7M。它能准确估计深度图并显著改善物体边界质量，在NVIDIA Jetson Orin上以50.7 FPS高效运行，性能优于现有轻量级模型。


<details>
  <summary>Details</summary>
Motivation: 现有应用于嵌入式系统的单目深度估计算法存在深度估计性能不佳和物体边界模糊的问题。

Method: 本文提出了BoRe-Depth模型，包含8.7M参数。方法包括：1) 设计增强特征自适应融合模块(EFAF)，自适应融合深度特征以增强边界细节表示；2) 将语义知识整合到编码器中，以提高物体识别和边界感知能力。

Result: BoRe-Depth模型能在嵌入式系统上准确估计深度图，并显著改善边界质量。它在NVIDIA Jetson Orin上以50.7 FPS高效运行，并在多个挑战性数据集上显著优于之前的轻量级模型。

Conclusion: BoRe-Depth是一种高效且准确的单目深度估计算法，特别适用于嵌入式系统，能够有效解决现有方法的性能和边界质量问题，为无人系统中的3D感知提供了低成本解决方案。

Abstract: Depth estimation is one of the key technologies for realizing 3D perception
in unmanned systems. Monocular depth estimation has been widely researched
because of its low-cost advantage, but the existing methods face the challenges
of poor depth estimation performance and blurred object boundaries on embedded
systems. In this paper, we propose a novel monocular depth estimation model,
BoRe-Depth, which contains only 8.7M parameters. It can accurately estimate
depth maps on embedded systems and significantly improves boundary quality.
Firstly, we design an Enhanced Feature Adaptive Fusion Module (EFAF) which
adaptively fuses depth features to enhance boundary detail representation.
Secondly, we integrate semantic knowledge into the encoder to improve the
object recognition and boundary perception capabilities. Finally, BoRe-Depth is
deployed on NVIDIA Jetson Orin, and runs efficiently at 50.7 FPS. We
demonstrate that the proposed model significantly outperforms previous
lightweight models on multiple challenging datasets, and we provide detailed
ablation studies for the proposed methods. The code is available at
https://github.com/liangxiansheng093/BoRe-Depth.

</details>


### [56] [SpatialLock: Precise Spatial Control in Text-to-Image Synthesis](https://arxiv.org/abs/2511.04112)
*Biao Liu,Yuanzhi Liang*

Main category: cs.CV

TL;DR: SpatialLock是一个新颖的框架，通过结合感知信号和定位信息，解决了文本到图像生成中物体精确定位的问题，显著提高了空间布局的控制和图像质量。


<details>
  <summary>Details</summary>
Motivation: 文本到图像合成在物体定位的精确控制方面仍面临挑战，现有方法未能充分利用位置信息，导致对物体空间布局的理解不足。

Method: 本文提出了SpatialLock框架，包含两个核心组件：1. Position-Engaged Injection (PoI) 通过注意力层直接整合空间信息，促进模型有效学习定位信息。2. Position-Guided Learning (PoG) 采用基于感知的监督进一步细化物体定位。

Result: 实验表明，SpatialLock在精确定位方面达到了新的最先进水平，在多个数据集上实现了超过0.9的IOU分数，并提升了生成图像的视觉质量。

Conclusion: SpatialLock通过其独特的方法有效解决了文本到图像生成中的物体精确定位问题，能够生成具有精确空间排列的物体，并显著提高图像质量。

Abstract: Text-to-Image (T2I) synthesis has made significant advancements in recent
years, driving applications such as generating datasets automatically. However,
precise control over object localization in generated images remains a
challenge. Existing methods fail to fully utilize positional information,
leading to an inadequate understanding of object spatial layouts. To address
this issue, we propose SpatialLock, a novel framework that leverages perception
signals and grounding information to jointly control the generation of spatial
locations. SpatialLock incorporates two components: Position-Engaged Injection
(PoI) and Position-Guided Learning (PoG). PoI directly integrates spatial
information through an attention layer, encouraging the model to learn the
grounding information effectively. PoG employs perception-based supervision to
further refine object localization. Together, these components enable the model
to generate objects with precise spatial arrangements and improve the visual
quality of the generated images. Experiments show that SpatialLock sets a new
state-of-the-art for precise object positioning, achieving IOU scores above 0.9
across multiple datasets.

</details>


### [57] [Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with Multirate Integration](https://arxiv.org/abs/2511.04117)
*Yunghee Lee,Byeonghyun Pak,Junwha Hong,Hoseong Kim*

Main category: cs.CV

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: In this paper, we propose Tortoise and Hare Guidance (THG), a training-free
strategy that accelerates diffusion sampling while maintaining high-fidelity
generation. We demonstrate that the noise estimate and the additional guidance
term exhibit markedly different sensitivity to numerical error by reformulating
the classifier-free guidance (CFG) ODE as a multirate system of ODEs. Our
error-bound analysis shows that the additional guidance branch is more robust
to approximation, revealing substantial redundancy that conventional solvers
fail to exploit. Building on this insight, THG significantly reduces the
computation of the additional guidance: the noise estimate is integrated with
the tortoise equation on the original, fine-grained timestep grid, while the
additional guidance is integrated with the hare equation only on a coarse grid.
We also introduce (i) an error-bound-aware timestep sampler that adaptively
selects step sizes and (ii) a guidance-scale scheduler that stabilizes large
extrapolation spans. THG reduces the number of function evaluations (NFE) by up
to 30% with virtually no loss in generation fidelity ($\Delta$ImageReward
$\leq$ 0.032) and outperforms state-of-the-art CFG-based training-free
accelerators under identical computation budgets. Our findings highlight the
potential of multirate formulations for diffusion solvers, paving the way for
real-time high-quality image synthesis without any model retraining. The source
code is available at https://github.com/yhlee-add/THG.

</details>


### [58] [Text to Sketch Generation with Multi-Styles](https://arxiv.org/abs/2511.04123)
*Tengjie Li,Shikui Tu,Lei Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的免训练框架，通过文本提示和参考草图实现对草图风格的精确控制和多风格生成，有效减少内容泄漏并提高生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的草图生成方法主要侧重于通用合成，缺乏对草图风格的精确控制机制。

Method: 本研究提出一个基于扩散模型的免训练框架，通过文本提示和参考风格草图实现显式风格指导。与以往覆盖自注意力K/V矩阵的方法不同，该方法通过线性平滑将参考特征作为辅助信息整合，并利用风格-内容指导机制。此外，该框架通过整合来自多个参考草图的特征，并由联合AdaIN模块协调，支持可控的多风格生成。

Result: 广泛的实验表明，该方法实现了高质量的草图生成，具有准确的风格对齐和更高的风格控制灵活性。它有效减少了参考草图的内容泄漏，并在参考与目标草图结构相似度较低的情况下显著提高了合成质量。

Conclusion: 所提出的M3S框架通过创新的风格指导机制，成功解决了现有草图生成方法在风格控制方面的局限性，实现了高精度、灵活的单风格和多风格草图生成。

Abstract: Recent advances in vision-language models have facilitated progress in sketch
generation. However, existing specialized methods primarily focus on generic
synthesis and lack mechanisms for precise control over sketch styles. In this
work, we propose a training-free framework based on diffusion models that
enables explicit style guidance via textual prompts and referenced style
sketches. Unlike previous style transfer methods that overwrite key and value
matrices in self-attention, we incorporate the reference features as auxiliary
information with linear smoothing and leverage a style-content guidance
mechanism. This design effectively reduces content leakage from reference
sketches and enhances synthesis quality, especially in cases with low
structural similarity between reference and target sketches. Furthermore, we
extend our framework to support controllable multi-style generation by
integrating features from multiple reference sketches, coordinated via a joint
AdaIN module. Extensive experiments demonstrate that our approach achieves
high-quality sketch generation with accurate style alignment and improved
flexibility in style control. The official implementation of M3S is available
at https://github.com/CMACH508/M3S.

</details>


### [59] [Automated Tennis Player and Ball Tracking with Court Keypoints Detection (Hawk Eye System)](https://arxiv.org/abs/2511.04126)
*Venkata Manikanta Desu,Syed Fawaz Ali*

Main category: cs.CV

TL;DR: 该研究提出了一个完整的自动化网球比赛分析流程，整合了多个深度学习模型，用于实时检测和跟踪球员与网球，并识别球场关键点，以提供详细的比赛分析。


<details>
  <summary>Details</summary>
Motivation: 旨在为教练、广播公司和球员提供详细的比赛分析和可操作的见解，以深入了解比赛动态。

Method: 该框架整合了多个深度学习模型：使用YOLOv8进行球员检测，使用定制训练的YOLOv5模型进行网球跟踪，以及基于ResNet50的架构进行球场关键点检测。

Result: 实验结果表明，在不同的球场条件和比赛场景下均表现出稳健的性能。该系统输出带有注释的视频和详细的性能指标，包括球员移动模式、球速、击球准确性和球员反应时间。

Conclusion: 该系统能够为教练、广播公司和球员提供关于比赛动态的可操作见解，从而提升对比赛的理解和分析能力。

Abstract: This study presents a complete pipeline for automated tennis match analysis.
Our framework integrates multiple deep learning models to detect and track
players and the tennis ball in real time, while also identifying court
keypoints for spatial reference. Using YOLOv8 for player detection, a
custom-trained YOLOv5 model for ball tracking, and a ResNet50-based
architecture for court keypoint detection, our system provides detailed
analytics including player movement patterns, ball speed, shot accuracy, and
player reaction times. The experimental results demonstrate robust performance
in varying court conditions and match scenarios. The model outputs an annotated
video along with detailed performance metrics, enabling coaches, broadcasters,
and players to gain actionable insights into the dynamics of the game.

</details>


### [60] [DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms](https://arxiv.org/abs/2511.04128)
*Shengyu Tang,Zeyuan Lu,Jiazhi Dong,Changdong Yu,Xiaoyu Wang,Yaohui Lyu,Weihao Xia*

Main category: cs.CV

TL;DR: 本文提出了一种名为DMSORT的高效双分支海事多目标跟踪（MOT）方法，通过并行跟踪器、仿射补偿、目标检测与ReID以及动态摄像机运动估计，解决了复杂海事环境下摄像机运动和视觉退化带来的挑战，实现了最先进的性能和快速运行速度。


<details>
  <summary>Details</summary>
Motivation: 确保船舶安全导航和有效海事监控需要准确感知海洋环境，但复杂的海事环境常导致摄像机运动和视觉退化，给多目标跟踪（MOT）带来了重大挑战。

Method: 本文提出DMSORT方法，其核心是一个带有仿射补偿的并行跟踪器。该框架包含一个目标检测和重识别（ReID）分支，以及一个专门用于动态摄像机运动估计的分支。具体而言，检测模块集成了可逆柱状检测网络（RCDN）以利用多级视觉特征进行鲁棒目标检测；设计了轻量级基于Transformer的外观特征提取器（Li-TAE）以捕捉全局上下文信息并生成鲁棒外观特征。另一个分支通过构建投影变换来解耦平台诱导运动和目标固有运动，并在卡尔曼滤波器中应用平台运动补偿，从而稳定真实目标轨迹。最后，一个聚类优化的特征融合模块有效结合运动和外观线索，确保在噪声、遮挡和漂移下的身份一致性。

Result: 在新加坡海事数据集上的广泛评估表明，DMSORT实现了最先进的性能。值得注意的是，DMSORT在现有基于ReID的MOT框架中运行速度最快，同时保持了高身份一致性以及对抖动和遮挡的鲁棒性。

Conclusion: DMSORT在复杂海事环境中有效解决了多目标跟踪的挑战，通过其创新的双分支并行跟踪架构和模块设计，在保持高身份一致性和鲁棒性的同时，实现了卓越的跟踪性能和运行效率。

Abstract: Accurate perception of the marine environment through robust multi-object
tracking (MOT) is essential for ensuring safe vessel navigation and effective
maritime surveillance. However, the complicated maritime environment often
causes camera motion and subsequent visual degradation, posing significant
challenges to MOT. To address this challenge, we propose an efficient
Dual-branch Maritime SORT (DMSORT) method for maritime MOT. The core of the
framework is a parallel tracker with affine compensation, which incorporates an
object detection and re-identification (ReID) branch, along with a dedicated
branch for dynamic camera motion estimation. Specifically, a Reversible
Columnar Detection Network (RCDN) is integrated into the detection module to
leverage multi-level visual features for robust object detection. Furthermore,
a lightweight Transformer-based appearance extractor (Li-TAE) is designed to
capture global contextual information and generate robust appearance features.
Another branch decouples platform-induced and target-intrinsic motion by
constructing a projective transformation, applying platform-motion compensation
within the Kalman filter, and thereby stabilizing true object trajectories.
Finally, a clustering-optimized feature fusion module effectively combines
motion and appearance cues to ensure identity consistency under noise,
occlusion, and drift. Extensive evaluations on the Singapore Maritime Dataset
demonstrate that DMSORT achieves state-of-the-art performance. Notably, DMSORT
attains the fastest runtime among existing ReID-based MOT frameworks while
maintaining high identity consistency and robustness to jitter and occlusion.
Code is available at:
https://github.com/BiscuitsLzy/DMSORT-An-efficient-parallel-maritime-multi-object-tracking-architecture-.

</details>


### [61] [Learning from Online Videos at Inference Time for Computer-Use Agents](https://arxiv.org/abs/2511.04137)
*Yujian Liu,Ze Wang,Hao Chen,Ximeng Sun,Xiaodong Yu,Jialian Wu,Jiang Liu,Emad Barsoum,Zicheng Liu,Shiyu Chang*

Main category: cs.CV

TL;DR: 本文提出一个框架，使计算机使用代理能够在推理时从在线视频教程中学习，通过将视频转换为结构化轨迹并动态选择作为上下文指导，显著优于仅使用文本的基线模型。


<details>
  <summary>Details</summary>
Motivation: 尽管计算机使用代理进步迅速，但在需要特定领域程序知识的任务上仍落后于人类。人类可以通过观看视频教程来弥补这一差距，因此研究如何让代理有效利用在线视频学习成为关键。

Method: 该框架包括检索和筛选教程视频、将视频转换为结构化演示轨迹，以及在执行时动态选择轨迹作为上下文指导。具体方法是：使用VLM推断UI动作，将视频分割成短动作子序列并赋予文本目标，并在推理时通过两阶段选择机制动态选择单个轨迹作为每一步的局部指导。

Result: 在两个广泛使用的基准测试中，该框架持续优于强大的基础代理和仅使用文本教程或转录本的变体。分析表明，轨迹分割与选择、动作过滤以及视觉信息的重要性，证明在线视频能被系统地提炼成可操作的指导。

Conclusion: 大量的在线视频可以系统地提炼成可操作的指导，从而在推理时有效提升计算机使用代理的性能。

Abstract: Computer-use agents can operate computers and automate laborious tasks, but
despite recent rapid progress, they still lag behind human users, especially
when tasks require domain-specific procedural knowledge about particular
applications, platforms, and multi-step workflows. Humans can bridge this gap
by watching video tutorials: we search, skim, and selectively imitate short
segments that match our current subgoal. In this paper, we study how to enable
computer-use agents to learn from online videos at inference time effectively.
We propose a framework that retrieves and filters tutorial videos, converts
them into structured demonstration trajectories, and dynamically selects
trajectories as in-context guidance during execution. Particularly, using a
VLM, we infer UI actions, segment videos into short subsequences of actions,
and assign each subsequence a textual objective. At inference time, a two-stage
selection mechanism dynamically chooses a single trajectory to add in context
at each step, focusing the agent on the most helpful local guidance for its
next decision. Experiments on two widely used benchmarks show that our
framework consistently outperforms strong base agents and variants that use
only textual tutorials or transcripts. Analyses highlight the importance of
trajectory segmentation and selection, action filtering, and visual
information, suggesting that abundant online videos can be systematically
distilled into actionable guidance that improves computer-use agents at
inference time. Our code is available at
https://github.com/UCSB-NLP-Chang/video_demo.

</details>


### [62] [Seeing Straight: Document Orientation Detection for Efficient OCR](https://arxiv.org/abs/2511.04161)
*Suranjan Goswami,Abhinav Ravi,Raja Kolla,Ali Faraz,Shaharukh Khan,Akash,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: 本文提出OCR-Rotation-Bench (ORB) 新基准用于评估OCR对图像旋转的鲁棒性，并开发了一个基于Phi-3.5-Vision的快速轻量级旋转分类管道，该方法在旋转识别上达到高精度，并显著提升了OCR性能。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中，扫描或拍摄文档的错误方向是一个关键的预处理问题，它通常由用户错误（如相机捕获时方向不正确）引起，严重影响光学字符识别（OCR）等下游任务的性能。

Method: 1. 引入了OCR-Rotation-Bench (ORB) 新基准，包括：a) ORB-En，由旋转转换后的结构化和自由格式英文OCR数据集构建；b) ORB-Indic，一个涵盖11种中低资源印度语言的新型多语言数据集。2. 提出了一个快速、鲁棒、轻量级的旋转分类管道，该管道基于Phi-3.5-Vision模型的视觉编码器，结合动态图像裁剪技术，并针对4类旋转任务进行了独立微调。

Result: 该方法在ORB-En数据集上实现了96%的旋转识别准确率，在ORB-Indic数据集上实现了92%的准确率。此外，在模拟的真实世界环境中，该模块显著提升了OCR性能：闭源模型提升高达14%，开源模型提升高达4倍。

Conclusion: 所提出的旋转分类模块在识别文档旋转方面表现出高精度和鲁棒性，并通过作为关键预处理步骤，显著提高了OCR模型（包括闭源和开源）在多语言和真实世界场景中的性能。

Abstract: Despite significant advances in document understanding, determining the
correct orientation of scanned or photographed documents remains a critical
pre-processing step in the real world settings. Accurate rotation correction is
essential for enhancing the performance of downstream tasks such as Optical
Character Recognition (OCR) where misalignment commonly arises due to user
errors, particularly incorrect base orientations of the camera during capture.
In this study, we first introduce OCR-Rotation-Bench (ORB), a new benchmark for
evaluating OCR robustness to image rotations, comprising (i) ORB-En, built from
rotation-transformed structured and free-form English OCR datasets, and (ii)
ORB-Indic, a novel multilingual set spanning 11 Indic mid to low-resource
languages. We also present a fast, robust and lightweight rotation
classification pipeline built on the vision encoder of Phi-3.5-Vision model
with dynamic image cropping, fine-tuned specifically for 4-class rotation task
in a standalone fashion. Our method achieves near-perfect 96% and 92% accuracy
on identifying the rotations respectively on both the datasets. Beyond
classification, we demonstrate the critical role of our module in boosting OCR
performance: closed-source (up to 14%) and open-weights models (up to 4x) in
the simulated real-world setting.

</details>


### [63] [Covariance Descriptors Meet General Vision Encoders: Riemannian Deep Learning for Medical Image Classification](https://arxiv.org/abs/2511.04190)
*Josef Mayr,Anna Reithmeir,Maxime Di Folco,Julia A. Schnabel*

Main category: cs.CV

TL;DR: 本研究探索了协方差描述符在医学图像分类中的应用，发现结合预训练通用视觉编码器（如DINOv2）的协方差描述符，特别是与SPDNet结合时，能显著优于手工特征和现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 协方差描述符在通用计算机视觉任务中表现出色，但在医学成像领域尚未得到充分探索。本研究旨在调查其在医学图像分类中的有效性，并特别关注为对称正定（SPD）矩阵设计的分类网络SPDNet。

Method: 研究从预训练的通用视觉编码器（GVEs，如DINOv2和MedSAM）提取的特征构建协方差描述符，并与手工描述符进行比较。评估在MedMNSIT基准测试的十一个二分类和多分类数据集上进行。性能通过SPDNet以及其他最先进方法进行比较。

Result: 结果显示，源自GVE特征的协方差描述符始终优于源自手工特征的描述符。此外，当SPDNet与DINOv2特征结合时，其性能超越了最先进的方法。

Conclusion: 研究结果强调了将协方差描述符与强大的预训练视觉编码器相结合，在医学图像分析中具有巨大潜力。

Abstract: Covariance descriptors capture second-order statistics of image features.
They have shown strong performance in general computer vision tasks, but remain
underexplored in medical imaging. We investigate their effectiveness for both
conventional and learning-based medical image classification, with a particular
focus on SPDNet, a classification network specifically designed for symmetric
positive definite (SPD) matrices. We propose constructing covariance
descriptors from features extracted by pre-trained general vision encoders
(GVEs) and comparing them with handcrafted descriptors. Two GVEs - DINOv2 and
MedSAM - are evaluated across eleven binary and multi-class datasets from the
MedMNSIT benchmark. Our results show that covariance descriptors derived from
GVE features consistently outperform those derived from handcrafted features.
Moreover, SPDNet yields superior performance to state-of-the-art methods when
combined with DINOv2 features. Our findings highlight the potential of
combining covariance descriptors with powerful pretrained vision encoders for
medical image analysis.

</details>


### [64] [Systematic Evaluation of Preprocessing Techniques for Accurate Image Registration in Digital Pathology](https://arxiv.org/abs/2511.04171)
*Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz*

Main category: cs.CV

TL;DR: 本研究调查了不同颜色转换技术对H&E染色图像与多模态图像配准性能的影响，发现CycleGAN在配准前应用时能显著降低配准误差。


<details>
  <summary>Details</summary>
Motivation: 数字病理学中，准确配准来自不同染色或成像模态的图像是生物标志物分析和组织重建等应用的关键步骤，因此需要研究如何优化异模态图像的配准效果。

Method: 研究使用了20对组织样本，每对样本都经过多种预处理步骤，包括不同的颜色转换（CycleGAN、Macenko、Reinhard、Vahadane）、反转、对比度调整、强度归一化和去噪。所有图像均使用VALIS方法进行配准（先刚性后两步非刚性）。配准性能通过相对目标配准误差（rTRE）以及自定义点基评估（10个手动选择的关键点）进行评估。配准在原始和反转多模态图像两种情景下分别进行。

Result: 在原始和反转多模态图像两种情景下，CycleGAN颜色转换均实现了最低的配准误差，而其他方法显示出更高的误差。

Conclusion: 研究结果表明，在配准前应用颜色转换，特别是CycleGAN，可以显著改善不同模态图像之间的对齐效果，从而支持更可靠的数字病理学分析。

Abstract: Image registration refers to the process of spatially aligning two or more
images by mapping them into a common coordinate system, so that corresponding
anatomical or tissue structures are matched across images. In digital
pathology, registration enables direct comparison and integration of
information from different stains or imaging modalities, sup-porting
applications such as biomarker analysis and tissue reconstruction. Accurate
registration of images from different modalities is an essential step in
digital pathology. In this study, we investigated how various color
transformation techniques affect image registration between hematoxylin and
eosin (H&E) stained images and non-linear multimodal images. We used a dataset
of 20 tissue sample pairs, with each pair undergoing several preprocessing
steps, including different color transformation (CycleGAN, Macenko, Reinhard,
Vahadane), inversion, contrast adjustment, intensity normalization, and
denoising. All images were registered using the VALIS registration method,
which first applies rigid registration and then performs non-rigid registration
in two steps on both low and high-resolution images. Registration performance
was evaluated using the relative Target Registration Error (rTRE). We reported
the median of median rTRE values (MMrTRE) and the average of median rTRE values
(AMrTRE) for each method. In addition, we performed a custom point-based
evaluation using ten manually selected key points. Registration was done
separately for two scenarios, using either the original or inverted multimodal
images. In both scenarios, CycleGAN color transformation achieved the lowest
registration errors, while the other methods showed higher errors. These
findings show that applying color transformation before registration improves
alignment between images from different modalities and supports more reliable
analysis in digital pathology.

</details>


### [65] [AStF: Motion Style Transfer via Adaptive Statistics Fusor](https://arxiv.org/abs/2511.04192)
*Hanmo Chen,Chenghao Xu,Jiexi Yan,Cheng Deng*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的自适应统计融合器（AStF），通过引入偏度（skewness）和峰度（kurtosis）等高阶统计量，克服了传统均值和方差方法在运动风格迁移中的局限性，实现了更逼真和精确的运动风格迁移。


<details>
  <summary>Details</summary>
Motivation: 传统的图像风格迁移方法（基于均值和方差）在运动风格迁移中表现不足，因为运动数据的复杂动态模式和时空连贯性无法仅通过一阶和二阶统计量完全捕捉。为了更全面地捕捉运动风格的内在统计模式，需要引入更高阶的统计分析。

Method: 本文提出了一种名为自适应统计融合器（AStF）的新模型，该模型包含风格解耦模块（SDM）和高阶多统计注意力（HOS-Attn）模块。AStF的核心思想是将偏度和峰度这两个高阶统计系数引入运动风格分析。此外，AStF与一个运动一致性正则化（MCR）判别器协同训练。

Result: 实验结果表明，通过更全面地建模动态风格中固有的时空统计模式，所提出的AStF在运动风格迁移方面显示出优于现有最先进方法的卓越性能和熟练度。

Conclusion: 通过引入偏度和峰度等高阶统计量，并结合新颖的AStF模型和MCR判别器，本文成功解决了传统方法在捕捉复杂运动风格方面的不足，显著提升了运动风格迁移的真实感和性能。

Abstract: Human motion style transfer allows characters to appear less rigidity and
more realism with specific style. Traditional arbitrary image style transfer
typically process mean and variance which is proved effective. Meanwhile,
similar methods have been adapted for motion style transfer. However, due to
the fundamental differences between images and motion, relying on mean and
variance is insufficient to fully capture the complex dynamic patterns and
spatiotemporal coherence properties of motion data. Building upon this, our key
insight is to bring two more coefficient, skewness and kurtosis, into the
analysis of motion style. Specifically, we propose a novel Adaptive Statistics
Fusor (AStF) which consists of Style Disentanglement Module (SDM) and
High-Order Multi-Statistics Attention (HOS-Attn). We trained our AStF in
conjunction with a Motion Consistency Regularization (MCR) discriminator.
Experimental results show that, by providing a more comprehensive model of the
spatiotemporal statistical patterns inherent in dynamic styles, our proposed
AStF shows proficiency superiority in motion style transfers over
state-of-the-arts. Our code and model are available at
https://github.com/CHMimilanlan/AStF.

</details>


### [66] [MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection](https://arxiv.org/abs/2511.04255)
*Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li*

Main category: cs.CV

TL;DR: 本文提出MedSapiens，通过多数据集预训练将以人为中心的姿态估计基础模型Sapiens应用于医学图像解剖地标检测，并在多项任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解剖地标检测传统上依赖于领域特定模型，但大规模预训练视觉模型的出现带来了新机遇。特别是，以人为中心的模型在空间姿态定位方面具有内在优势，但其在医学图像地标检测中的潜力尚未被充分发掘。

Method: 研究团队将Sapiens（一个以人为中心的姿态估计基础模型）通过多数据集预训练的方式，适配到医学图像领域，并将其命名为MedSapiens。该方法旨在利用Sapiens模型固有的空间姿态定位能力，作为解剖地标检测的强先验。

Result: MedSapiens在多项数据集上建立了新的最先进水平。与通用模型相比，平均成功检测率（SDR）提高了5.26%；与专业模型相比，SDR提高了21.81%。在有限数据（few-shot）设置下，MedSapiens的SDR也比现有最先进方法提高了2.69%。

Conclusion: 研究表明，以人为中心的基础模型，由于其在空间姿态定位方面的优化，能为解剖地标检测提供强大的先验知识，其在医学图像领域的潜力值得进一步开发和利用。

Abstract: This paper does not introduce a novel architecture; instead, it revisits a
fundamental yet overlooked baseline: adapting human-centric foundation models
for anatomical landmark detection in medical imaging. While landmark detection
has traditionally relied on domain-specific models, the emergence of
large-scale pre-trained vision models presents new opportunities. In this
study, we investigate the adaptation of Sapiens, a human-centric foundation
model designed for pose estimation, to medical imaging through multi-dataset
pretraining, establishing a new state of the art across multiple datasets. Our
proposed model, MedSapiens, demonstrates that human-centric foundation models,
inherently optimized for spatial pose localization, provide strong priors for
anatomical landmark detection, yet this potential has remained largely
untapped. We benchmark MedSapiens against existing state-of-the-art models,
achieving up to 5.26% improvement over generalist models and up to 21.81%
improvement over specialist models in the average success detection rate (SDR).
To further assess MedSapiens adaptability to novel downstream tasks with few
annotations, we evaluate its performance in limited-data settings, achieving
2.69% improvement over the few-shot state of the art in SDR. Code and model
weights are available at https://github.com/xmed-lab/MedSapiens .

</details>


### [67] [DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification](https://arxiv.org/abs/2511.04281)
*Yujie Yang,Shuang Li,Jun Ye,Neng Dong,Fan Li,Huafeng Li*

Main category: cs.CV

TL;DR: 本文提出DinoGRL框架，利用DINOv2的视觉先验学习步态特征，并结合外观线索，以增强视频可见光-红外跨模态行人重识别（VVI-ReID）的序列级表示。


<details>
  <summary>Details</summary>
Motivation: 现有VVI-ReID方法倾向于利用模态不变的视觉特征，但忽略了步态特征。步态特征不仅模态不变，而且富含时间动态性，对于建模跨模态视频匹配所需的时空一致性至关重要，因此现有方法在这方面存在局限性。

Method: 提出DINOv2驱动的步态表示学习（DinoGRL）框架。具体包括：1) 语义感知剪影与步态学习（SASGL）模型，利用DINOv2的通用语义先验生成和增强剪影表示，并与ReID目标联合优化以学习语义丰富且任务自适应的步态特征。2) 渐进式双向多粒度增强（PBMGE）模块，通过在步态和外观流之间进行多空间粒度上的双向交互，渐进式地细化特征表示，充分利用它们的互补性，以丰富全局表示并生成高判别性特征。

Result: 在HITSZ-VCM和BUPT数据集上进行了广泛实验，结果表明该方法优于现有最先进的方法。

Conclusion: 所提出的DinoGRL框架通过有效利用DINOv2的视觉先验和结合步态与外观特征的互补性，显著提高了视频可见光-红外行人重识别的性能，成功解决了跨模态视频匹配中时空一致性建模的挑战。

Abstract: Video-based Visible-Infrared person re-identification (VVI-ReID) aims to
retrieve the same pedestrian across visible and infrared modalities from video
sequences. Existing methods tend to exploit modality-invariant visual features
but largely overlook gait features, which are not only modality-invariant but
also rich in temporal dynamics, thus limiting their ability to model the
spatiotemporal consistency essential for cross-modal video matching. To address
these challenges, we propose a DINOv2-Driven Gait Representation Learning
(DinoGRL) framework that leverages the rich visual priors of DINOv2 to learn
gait features complementary to appearance cues, facilitating robust
sequence-level representations for cross-modal retrieval. Specifically, we
introduce a Semantic-Aware Silhouette and Gait Learning (SASGL) model, which
generates and enhances silhouette representations with general-purpose semantic
priors from DINOv2 and jointly optimizes them with the ReID objective to
achieve semantically enriched and task-adaptive gait feature learning.
Furthermore, we develop a Progressive Bidirectional Multi-Granularity
Enhancement (PBMGE) module, which progressively refines feature representations
by enabling bidirectional interactions between gait and appearance streams
across multiple spatial granularities, fully leveraging their complementarity
to enhance global representations with rich local details and produce highly
discriminative features. Extensive experiments on HITSZ-VCM and BUPT datasets
demonstrate the superiority of our approach, significantly outperforming
existing state-of-the-art methods.

</details>


### [68] [FastGS: Training 3D Gaussian Splatting in 100 Seconds](https://arxiv.org/abs/2511.04283)
*Shiwei Ren,Tianci Wen,Yongchun Fang,Biao Lu*

Main category: cs.CV

TL;DR: FastGS提出了一种基于多视角一致性的3D高斯泼溅加速框架，通过高效的稠密化和剪枝策略，显著提升了训练速度并保持了渲染质量，同时具有强大的通用性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅加速方法未能有效控制高斯数量，导致冗余的计算时间开销。

Method: FastGS提出了一种新颖、简单且通用的加速框架，该框架基于多视角一致性充分考虑每个高斯的重要性。它创新性地设计了基于多视角一致性的稠密化和剪枝策略，摒弃了预算机制，以有效平衡训练时间和渲染质量。

Result: FastGS在Mip-NeRF 360数据集上实现了3.32倍的训练加速，渲染质量与DashGaussian相当；在Deep Blending数据集上比原始3DGS加速15.45倍。它在动态场景重建、表面重建、稀疏视角重建、大规模重建和同步定位与建图等多种任务中展现出强大的通用性，实现了2-7倍的训练加速。

Conclusion: FastGS是一个高效且通用的3D高斯泼溅加速框架，通过创新的多视角一致性策略，显著提升了训练速度，同时保持了高质量的渲染效果，并能广泛应用于多种三维重建任务。

Abstract: The dominant 3D Gaussian splatting (3DGS) acceleration methods fail to
properly regulate the number of Gaussians during training, causing redundant
computational time overhead. In this paper, we propose FastGS, a novel, simple,
and general acceleration framework that fully considers the importance of each
Gaussian based on multi-view consistency, efficiently solving the trade-off
between training time and rendering quality. We innovatively design a
densification and pruning strategy based on multi-view consistency, dispensing
with the budgeting mechanism. Extensive experiments on Mip-NeRF 360, Tanks &
Temples, and Deep Blending datasets demonstrate that our method significantly
outperforms the state-of-the-art methods in training speed, achieving a
3.32$\times$ training acceleration and comparable rendering quality compared
with DashGaussian on the Mip-NeRF 360 dataset and a 15.45$\times$ acceleration
compared with vanilla 3DGS on the Deep Blending dataset. We demonstrate that
FastGS exhibits strong generality, delivering 2-7$\times$ training acceleration
across various tasks, including dynamic scene reconstruction, surface
reconstruction, sparse-view reconstruction, large-scale reconstruction, and
simultaneous localization and mapping. The project page is available at
https://fastgs.github.io/

</details>


### [69] [Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human Face Imagery](https://arxiv.org/abs/2511.04260)
*Claudio Giusti,Luca Guarnera,Sebastiano Battiato*

Main category: cs.CV

TL;DR: Proto-LeakNet是一个可解释的归因框架，它利用扩散模型在潜在空间中留下的“信号泄漏”来识别AI生成图像的来源，即使是未知的生成器也能有效识别，并对图像后处理具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着合成图像和深度伪造生成模型的日益复杂，确定图像来源和验证其真实性成为计算机视觉领域的关键挑战。现有研究表明，扩散模型在其输出中会无意中留下持久的统计痕迹（即“信号泄漏”），尤其是在潜在表示中，这为源头归因提供了可能。

Method: 本文提出了Proto-LeakNet框架。该方法在扩散模型的潜在域中操作，通过重新模拟部分前向扩散来揭示生成器特定的残余线索。它采用一个时间注意力编码器来聚合多步潜在特征，并使用一个特征加权原型头来构建嵌入空间，实现透明归因。该框架结合了闭集分类和基于密度的开集评估，使其能够在不重新训练的情况下分析未知的生成器。

Result: Proto-LeakNet仅在闭集数据上训练，实现了98.13%的Macro AUC。其学习到的潜在几何结构在经过后处理后仍保持鲁棒性，性能超越了现有最先进的方法。该方法在已知和未知生成器之间展现出强大的可分离性。

Conclusion: 研究结果表明，在潜在空间中对“信号泄漏”偏差进行建模，能够实现可靠且可解释的AI图像和深度伪造取证。

Abstract: The growing sophistication of synthetic image and deepfake generation models
has turned source attribution and authenticity verification into a critical
challenge for modern computer vision systems. Recent studies suggest that
diffusion pipelines unintentionally imprint persistent statistical traces,
known as signal leaks, within their outputs, particularly in latent
representations. Building on this observation, we propose Proto-LeakNet, a
signal-leak-aware and interpretable attribution framework that integrates
closed-set classification with a density-based open-set evaluation on the
learned embeddings, enabling analysis of unseen generators without retraining.
Operating in the latent domain of diffusion models, our method re-simulates
partial forward diffusion to expose residual generator-specific cues. A
temporal attention encoder aggregates multi-step latent features, while a
feature-weighted prototype head structures the embedding space and enables
transparent attribution. Trained solely on closed data and achieving a Macro
AUC of 98.13%, Proto-LeakNet learns a latent geometry that remains robust under
post-processing, surpassing state-of-the-art methods, and achieves strong
separability between known and unseen generators. These results demonstrate
that modeling signal-leak bias in latent space enables reliable and
interpretable AI-image and deepfake forensics. The code for the whole work will
be available upon submission.

</details>


### [70] [RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive Text-to-Video Generation](https://arxiv.org/abs/2511.04317)
*Xiangjun Zhang,Litong Gong,Yinglin Zheng,Yansong Liu,Wentao Jiang,Mingyi Xu,Biao Wang,Tiezheng Ge,Ming Zeng*

Main category: cs.CV

TL;DR: RISE-T2V 提出了一种新颖的框架，通过将提示词改写和语义特征提取整合为一个步骤，显著提升了文本到视频（T2V）扩散模型在处理简洁提示词时生成高质量视频的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频扩散模型依赖预训练文本编码器，但在面对简洁而非精心设计的提示词时，视频质量难以保持，主要原因是它们对文本语义理解有限。此外，这些模型无法在线改写提示词以更好地符合用户意图，这限制了模型的可扩展性和可用性。

Method: 本文提出了 RISE-T2V 框架，它独特地将提示词改写和语义特征提取整合为一个无缝的步骤。核心是一个创新的“改写适配器”（Rephrasing Adapter），使扩散模型能够利用大型语言模型（LLM）在预测下一个词元时的隐藏状态作为视频生成的条件，从而隐式地将基本提示词改写为更全面的表示，以更好地匹配用户意图。

Result: 实验证明，RISE-T2V 是一个通用的框架，适用于各种预训练的 LLM 和视频扩散模型，显著增强了 T2V 模型生成与用户意图一致的高质量视频的能力。它在不同视频扩散模型架构上均表现出多功能性。

Conclusion: RISE-T2V 通过集成提示词改写和语义特征提取，并利用 LLM 的强大能力，有效解决了现有 T2V 模型在理解简洁提示词方面的局限性，从而显著提高了视频生成质量和与用户意图的对齐程度，是一个通用且有效的 T2V 框架。

Abstract: Most text-to-video(T2V) diffusion models depend on pre-trained text encoders
for semantic alignment, yet they often fail to maintain video quality when
provided with concise prompts rather than well-designed ones. The primary issue
lies in their limited textual semantics understanding. Moreover, these text
encoders cannot rephrase prompts online to better align with user intentions,
which limits both the scalability and usability of the models, To address these
challenges, we introduce RISE-T2V, which uniquely integrates the processes of
prompt rephrasing and semantic feature extraction into a single and seamless
step instead of two separate steps. RISE-T2V is universal and can be applied to
various pre-trained LLMs and video diffusion models(VDMs), significantly
enhancing their capabilities for T2V tasks. We propose an innovative module
called the Rephrasing Adapter, enabling diffusion models to utilize text hidden
states during the next token prediction of the LLM as a condition for video
generation. By employing a Rephrasing Adapter, the video generation model can
implicitly rephrase basic prompts into more comprehensive representations that
better match the user's intent. Furthermore, we leverage the powerful
capabilities of LLMs to enable video generation models to accomplish a broader
range of T2V tasks. Extensive experiments demonstrate that RISE-T2V is a
versatile framework applicable to different video diffusion model
architectures, significantly enhancing the ability of T2V models to generate
high-quality videos that align with user intent. Visual results are available
on the webpage at https://rise-t2v.github.io.

</details>


### [71] [Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment](https://arxiv.org/abs/2511.04288)
*Leire Benito-Del-Valle,Artzai Picón,Daniel Mugica,Manuel Ramos,Eva Portillo,Javier Romero,Carlos Javier Jimenez,Ramón Navarra-Mestre*

Main category: cs.CV

TL;DR: 本研究通过自监督学习，在一个大型农业数据集上训练了一个领域特定的视觉基础模型，显著提升了除草剂试验中植物物种识别和损害分类的准确性，尤其是在未见条件和数据漂移场景下，并能有效减少标注工作。


<details>
  <summary>Details</summary>
Motivation: 除草剂田间试验需要准确识别植物物种和评估除草剂造成的损害，但通用视觉基础模型在农业领域面临挑战，难以区分细粒度的物种和损害类型。

Method: 本研究采用自监督学习方法，在一个大型精选农业数据集上训练了一个通用的视觉基础模型，使其适应除草剂试验的特性，学习针对该领域优化的丰富且可迁移的表征。

Result: 该领域特定模型在物种识别（F1从0.91提升到0.94）和损害分类（F1从0.26提升到0.33）方面均显著优于最佳通用基础模型。在未见条件（新地点和时间）下，性能提升更显著（物种识别F1从0.56提升到0.66；损害分类F1从0.17提升到0.27）。在领域漂移场景（如无人机图像）中，其性能依然强劲（物种分类F1从0.49提升到0.60）。此外，领域特定预训练提高了分割精度，尤其是在低标注情况下，并在使用80%更少标注样本的情况下，在未见条件下F1分数比通用模型高5.4%。

Conclusion: 领域特定的基础模型展现出强大的泛化能力，能够显著减少人工标注工作，为除草剂试验分析提供了一个可扩展且自动化的解决方案。

Abstract: Herbicide field trials require accurate identification of plant species and
assessment of herbicide-induced damage across diverse environments. While
general-purpose vision foundation models have shown promising results in
complex visual domains, their performance can be limited in agriculture, where
fine-grained distinctions between species and damage types are critical.
  In this work, we adapt a general-purpose vision foundation model to herbicide
trial characterization. Trained using a self-supervised learning approach on a
large, curated agricultural dataset, the model learns rich and transferable
representations optimized for herbicide trials images.
  Our domain-specific model significantly outperforms the best general-purpose
foundation model in both species identification (F1 score improvement from 0.91
to 0.94) and damage classification (from 0.26 to 0.33). Under unseen conditions
(new locations and other time), it achieves even greater gains (species
identification from 0.56 to 0.66; damage classification from 0.17 to 0.27). In
domain-shift scenarios, such as drone imagery, it maintains strong performance
(species classification from 0.49 to 0.60).
  Additionally, we show that domain-specific pretraining enhances segmentation
accuracy, particularly in low-annotation regimes. An annotation-efficiency
analysis reveals that, under unseen conditions, the domain-specific model
achieves 5.4% higher F1 score than the general-purpose model, while using 80%
fewer labeled samples.
  These results demonstrate the generalization capabilities of domain-specific
foundation models and their potential to significantly reduce manual annotation
efforts, offering a scalable and automated solution for herbicide trial
analysis.

</details>


### [72] [Comparative Study of CNN Architectures for Binary Classification of Horses and Motorcycles in the VOC 2008 Dataset](https://arxiv.org/abs/2511.04344)
*Muhammad Annas Shaikh,Hamza Zaman,Arbaz Asif*

Main category: cs.CV

TL;DR: 本文评估了九种CNN架构在VOC 2008数据集上对马匹和摩托车进行二分类的性能，并通过少数类数据增强解决了类别不平衡问题。研究发现ConvNeXt-Tiny表现最佳，且数据增强显著提升了少数类检测。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决VOC 2008数据集中马匹和摩托车二分类任务中的显著类别不平衡问题，并评估不同卷积神经网络架构和数据增强策略对性能的影响。

Method: 评估了包括ResNet-50、ConvNeXt-Tiny、DenseNet-121和Vision Transformer在内的九种现代CNN架构。通过实施少数类数据增强技术来解决类别不平衡问题。在VOC 2008数据集上进行实验，并比较了多种性能指标。

Result: 结果显示性能存在显著差异，其中ConvNeXt-Tiny在马匹检测中取得了95.53%的最高平均精度（AP），在摩托车检测中取得了89.12%的AP。数据增强显著改善了少数类检测，尤其对更深层的架构益处更大。

Conclusion: 本研究为不平衡二分类任务中的架构选择提供了见解，并量化了数据增强策略在缓解目标检测中类别不平衡问题上的影响。

Abstract: This paper presents a comprehensive evaluation of nine convolutional neural
network architectures for binary classification of horses and motorcycles in
the VOC 2008 dataset. We address the significant class imbalance problem by
implementing minority-class augmentation techniques. Our experiments compare
modern architectures including ResNet-50, ConvNeXt-Tiny, DenseNet-121, and
Vision Transformer across multiple performance metrics. Results demonstrate
substantial performance variations, with ConvNeXt-Tiny achieving the highest
Average Precision (AP) of 95.53% for horse detection and 89.12% for motorcycle
detection. We observe that data augmentation significantly improves minority
class detection, particularly benefiting deeper architectures. This study
provides insights into architecture selection for imbalanced binary
classification tasks and quantifies the impact of data augmentation strategies
in mitigating class imbalance issues in object detection.

</details>


### [73] [Submanifold Sparse Convolutional Networks for Automated 3D Segmentation of Kidneys and Kidney Tumours in Computed Tomography](https://arxiv.org/abs/2511.04334)
*Saúl Alonso-Monsalve,Leigh H. Whitehead,Adam Aurisano,Lorena Escudero Sanchez*

Main category: cs.CV

TL;DR: 本文提出了一种基于体素稀疏化和子流形稀疏卷积网络的3D肿瘤自动分割方法，在保持高分辨率和领先精度的同时，显著降低了计算资源消耗，解决了传统方法在处理大规模3D医学图像时的挑战。


<details>
  <summary>Details</summary>
Motivation: 在放射影像中准确勾勒肿瘤边界是一项专业且耗时的工作，是阻碍临床常规进行定量分析的瓶颈。传统卷积神经网络在处理3D扫描时，由于体素量大，通常需要降采样或使用图像块，导致资源消耗高且可能丢失信息。

Method: 本文提出了一种分两阶段的新方法：首先进行体素稀疏化（voxel sparsification），然后应用子流形稀疏卷积网络（submanifold sparse convolutional networks）。这种方法允许使用高分辨率的原始3D模型架构进行分割。

Result: 该方法在KiTS23肾癌CT图像数据集上取得了与挑战赛获胜者相媲美的结果，肾脏+肿块的Dice相似系数为95.8%，肿瘤+囊肿为85.7%，单独肿瘤为80.3%。在计算资源方面，推理时间减少高达60%，VRAM使用量减少高达75%，显著优于等效的密集架构。

Conclusion: 所提出的方法能够以高分辨率和原生3D模型架构实现肿瘤的精确分割，同时显著减少了GPU内存和时间等计算资源需求。这为在临床环境中常规进行自动肿瘤分割提供了高效且准确的解决方案。

Abstract: The accurate delineation of tumours in radiological images like Computed
Tomography is a very specialised and time-consuming task, and currently a
bottleneck preventing quantitative analyses to be performed routinely in the
clinical setting. For this reason, developing methods for the automated
segmentation of tumours in medical imaging is of the utmost importance and has
driven significant efforts in recent years. However, challenges regarding the
impracticality of 3D scans, given the large amount of voxels to be analysed,
usually requires the downsampling of such images or using patches thereof when
applying traditional convolutional neural networks. To overcome this problem,
in this paper we propose a new methodology that uses, divided into two stages,
voxel sparsification and submanifold sparse convolutional networks. This method
allows segmentations to be performed with high-resolution inputs and a native
3D model architecture, obtaining state-of-the-art accuracies while
significantly reducing the computational resources needed in terms of GPU
memory and time. We studied the deployment of this methodology in the context
of Computed Tomography images of renal cancer patients from the KiTS23
challenge, and our method achieved results competitive with the challenge
winners, with Dice similarity coefficients of 95.8% for kidneys + masses, 85.7%
for tumours + cysts, and 80.3% for tumours alone. Crucially, our method also
offers significant computational improvements, achieving up to a 60% reduction
in inference time and up to a 75\% reduction in VRAM usage compared to an
equivalent dense architecture, across both CPU and various GPU cards tested.

</details>


### [74] [Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion for 3D Object Detection](https://arxiv.org/abs/2511.04347)
*Sanjay Kumar,Tim Brophy,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising*

Main category: cs.CV

TL;DR: 本研究调查了遮挡对基于BEV的相机、LiDAR和融合3D目标检测性能的影响。结果显示，相机对中度遮挡敏感，LiDAR对重度遮挡敏感，且融合模型更依赖LiDAR。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要准确的3D目标检测以安全导航，而基于BEV的多传感器融合方法表现出色。然而，传感器遮挡（如雾、霾或物理障碍）对3D检测精度的影响尚未得到充分探索。

Method: 研究人员使用BEVFusion架构，在nuScenes数据集上评估了遮挡对相机和LiDAR输出的影响。检测性能通过平均精度（mAP）和nuScenes检测分数（NDS）进行衡量。

Result: 中度相机遮挡导致纯相机检测的mAP下降41.3%。LiDAR仅在重度遮挡下性能急剧下降，mAP下降47.3%，严重影响长距离检测。在融合设置中，相机遮挡导致mAP小幅下降4.1%，而LiDAR遮挡导致mAP大幅下降26.8%，表明模型更依赖LiDAR。

Conclusion: 研究结果强调了未来需要开发遮挡感知评估方法和改进传感器融合技术，以在恶劣环境条件下传感器部分失效或性能下降时仍能保持检测精度。

Abstract: Accurate 3D object detection is essential for automated vehicles to navigate
safely in complex real-world environments. Bird's Eye View (BEV)
representations, which project multi-sensor data into a top-down spatial
format, have emerged as a powerful approach for robust perception. Although
BEV-based fusion architectures have demonstrated strong performance through
multimodal integration, the effects of sensor occlusions, caused by
environmental conditions such as fog, haze, or physical obstructions, on 3D
detection accuracy remain underexplored. In this work, we investigate the
impact of occlusions on both camera and Light Detection and Ranging (LiDAR)
outputs using the BEVFusion architecture, evaluated on the nuScenes dataset.
Detection performance is measured using mean Average Precision (mAP) and the
nuScenes Detection Score (NDS). Our results show that moderate camera
occlusions lead to a 41.3% drop in mAP (from 35.6% to 20.9%) when detection is
based only on the camera. On the other hand, LiDAR sharply drops in performance
only under heavy occlusion, with mAP falling by 47.3% (from 64.7% to 34.1%),
with a severe impact on long-range detection. In fused settings, the effect
depends on which sensor is occluded: occluding the camera leads to a minor 4.1%
drop (from 68.5% to 65.7%), while occluding LiDAR results in a larger 26.8%
drop (to 50.1%), revealing the model's stronger reliance on LiDAR for the task
of 3D object detection. Our results highlight the need for future research into
occlusion-aware evaluation methods and improved sensor fusion techniques that
can maintain detection accuracy in the presence of partial sensor failure or
degradation due to adverse environmental conditions.

</details>


### [75] [A MATLAB tutorial on deep feature extraction combined with chemometrics for analytical applications](https://arxiv.org/abs/2511.04349)
*Puneet Mishra,Martijntje Vollebregt,Yizhou Ma,Maria Font-i-Furnols*

Main category: cs.CV

TL;DR: 本教程提供了一份MATLAB代码指南，介绍如何利用现有开源深度学习模型从分析化学成像数据中提取空间特征，并将其与光谱信息等其他数据源整合，以克服传统化学计量学方法的挑战。


<details>
  <summary>Details</summary>
Motivation: 分析化学中，从成像数据中高效提取和分析空间信息仍然是挑战，传统化学计量学方法难以捕捉多尺度深层特征。尽管深度学习在图像处理方面取得了显著进展且有开源模型可用，但由于缺乏结构化的实施指导，其在分析化学领域的应用仍受限。

Method: 本教程通过提供分步指南和MATLAB代码演示，重点在于如何应用现有的开源深度学习模型来从成像数据中提取深层特征，并将其与光谱信息等其他数据源整合。该方法不涉及训练新的深度学习模型，而是利用预训练模型。

Result: 本教程展示了如何处理分析化学中常见的各种成像模式的数据。读者可以使用教程中提供的代码，在自己的数据集上运行这些步骤，以提取和分析空间信息。

Conclusion: 本教程旨在通过提供实用的分步指导和MATLAB代码，弥合深度学习在分析化学领域应用的鸿沟，帮助研究人员有效地从成像数据中提取和利用空间信息，从而增强探索性和预测能力。

Abstract: Background In analytical chemistry, spatial information about materials is
commonly captured through imaging techniques, such as traditional color cameras
or with advanced hyperspectral cameras and microscopes. However, efficiently
extracting and analyzing this spatial information for exploratory and
predictive purposes remains a challenge, especially when using traditional
chemometric methods. Recent advances in deep learning and artificial
intelligence have significantly enhanced image processing capabilities,
enabling the extraction of multiscale deep features that are otherwise
challenging to capture with conventional image processing techniques. Despite
the wide availability of open-source deep learning models, adoption in
analytical chemistry remains limited because of the absence of structured,
step-by-step guidance for implementing these models.
  Results This tutorial aims to bridge this gap by providing a step-by-step
guide for applying deep learning approaches to extract spatial information from
imaging data and integrating it with other data sources, such as spectral
information. Importantly, the focus of this work is not on training deep
learning models for image processing but on using existing open source models
to extract deep features from imaging data.
  Significance The tutorial provides MATLAB code tutorial demonstrations,
showcasing the processing of imaging data from various imaging modalities
commonly encountered in analytical chemistry. Readers must run the tutorial
steps on their own datasets using the codes presented in this tutorial.

</details>


### [76] [Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal VQA](https://arxiv.org/abs/2511.04384)
*Itbaan Safwan,Muhammad Annas Shaikh,Muhammad Haaris,Ramail Khan,Muhammad Atif Tahir*

Main category: cs.CV

TL;DR: 本文提出了一个基于LoRA微调Florence-2模型的多任务框架，用于MediaEval Medico 2025挑战，实现医学视觉问答（VQA）、解释生成和视觉定位，并在准确性和定位方面显著优于单任务基线。


<details>
  <summary>Details</summary>
Motivation: 为MediaEval Medico 2025挑战赛开发一个能够同时进行医学VQA、解释生成和视觉定位的系统，以提供准确且可解释的响应。

Method: 采用多任务框架，使用LoRA微调的Florence-2模型。整合了三个数据集：Kvasir-VQA-x1（用于问答学习）、一个合成的解释数据集（提供结构化医学推理）和文本到区域对（连接视觉特征与分割掩码）。该设置使模型能够共同学习视觉定位、推理和解释。

Result: 该方法在答案准确性和视觉定位方面均显著优于单任务基线。

Conclusion: 接地多任务学习对于医学VQA应用是有效的，能够产生准确且可解释的响应。

Abstract: We present a multi-task framework for the MediaEval Medico 2025 challenge,
leveraging a LoRA-tuned Florence-2 model for simultaneous visual question
answering (VQA), explanation generation, and visual grounding. The proposed
system integrates three curated datasets: (1) Kvasir-VQA-x1 for question-answer
learning, (2) a synthetically enriched explanation dataset offering structured
medical reasoning, and (3) text-to-region pairs linking visual features with
segmentation masks. This multi-task setup enables the model to jointly learn
visual grounding, reasoning, and interpretation, producing responses that are
both accurate and interpretable. Extensive evaluation demonstrates that our
approach substantially improves over single-task baselines in both answer
accuracy and visual localization, highlighting the effectiveness of grounded
multi-task learning for medical VQA applications.

</details>


### [77] [Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm](https://arxiv.org/abs/2511.04570)
*Jingqi Tong,Yurong Mou,Hangcheng Li,Mingzhe Li,Yongzhuo Yang,Ming Zhang,Qiguang Chen,Tianyi Liang,Xiaomeng Hu,Yining Zheng,Xinchi Chen,Jun Zhao,Xuanjing Huang,Xipeng Qiu*

Main category: cs.CV

TL;DR: 本文提出“视频思维”范式，利用Sora-2等视频生成模型弥合视觉与文本推理，克服现有“文本思维”和“图像思维”的局限。通过VideoThinkBench基准测试，Sora-2在视觉和文本任务上均表现出色，证明视频生成模型作为统一多模态理解与生成模型的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的“文本思维”和“图像思维”范式存在局限性：图像无法捕捉动态过程或连续变化，且文本和视觉作为独立模态阻碍了统一的多模态理解和生成。

Method: 引入“视频思维”新范式，利用Sora-2等视频生成模型在一个统一的时间框架内连接视觉和文本推理。为此，开发了VideoThinkBench基准测试，包含视觉中心任务（如“眼球谜题”）和文本中心任务（如GSM8K、MMMU子集）。评估了Sora-2的能力，并系统分析了其能力来源，同时探究了自洽性和上下文学习对性能的影响。

Result: Sora-2被证明是一个有能力的推理器。在视觉中心任务上，Sora-2与最先进的视觉语言模型（VLM）相当，甚至在某些任务（如“眼球游戏”）上超越了VLM。在文本中心任务上，Sora-2在MATH上达到92%的准确率，在MMMU上达到75.53%的准确率。此外，自洽性和上下文学习可以提高Sora-2的性能。

Conclusion: 研究结果表明，视频生成模型是潜在的统一多模态理解和生成模型，将“视频思维”定位为一个统一的多模态推理范式。

Abstract: "Thinking with Text" and "Thinking with Images" paradigm significantly
improve the reasoning ability of large language models (LLMs) and Vision
Language Models (VLMs). However, these paradigms have inherent limitations. (1)
Images capture only single moments and fail to represent dynamic processes or
continuous changes, and (2) The separation of text and vision as distinct
modalities, hindering unified multimodal understanding and generation. To
overcome these limitations, we introduce "Thinking with Video", a new paradigm
that leverages video generation models, such as Sora-2, to bridge visual and
textual reasoning in a unified temporal framework. To support this exploration,
we developed the Video Thinking Benchmark (VideoThinkBench). VideoThinkBench
encompasses two task categories: (1) vision-centric tasks (e.g., Eyeballing
Puzzles), and (2) text-centric tasks (e.g., subsets of GSM8K, MMMU). Our
evaluation establishes Sora-2 as a capable reasoner. On vision-centric tasks,
Sora-2 is generally comparable to state-of-the-art (SOTA) VLMs, and even
surpasses VLMs on several tasks, such as Eyeballing Games. On text-centric
tasks, Sora-2 achieves 92% accuracy on MATH, and 75.53% accuracy on MMMU.
Furthermore, we systematically analyse the source of these abilities. We also
find that self-consistency and in-context learning can improve Sora-2's
performance. In summary, our findings demonstrate that the video generation
model is the potential unified multimodal understanding and generation model,
positions "thinking with video" as a unified multimodal reasoning paradigm.

</details>


### [78] [Solving Convex Partition Visual Jigsaw Puzzles](https://arxiv.org/abs/2511.04450)
*Yaniv Ohayon,Ofir Itzhak Shahar,Ohad Ben-Shahar*

Main category: cs.CV

TL;DR: 本文提出了一种解决凸多边形拼图的贪婪算法，结合几何和图像兼容性，并创建了首个此类拼图的基准数据集，显著扩展了自动拼图求解器的应用范围。


<details>
  <summary>Details</summary>
Motivation: 现有拼图求解器主要针对方形拼图，限制了其实际应用。研究旨在扩展计算处理的拼图类型，特别是处理更通用的多边形拼图，如凸分区拼图。

Method: 专注于凸分区（多边形拼图的一个主要子集）。同时利用几何兼容性和图像兼容性。引入了一种贪婪求解器。

Result: 成功开发并报告了针对凸分区拼图的贪婪求解器的多项性能指标。创建并发布了首个此类拼图的基准数据集。

Conclusion: 该工作显著扩展了计算处理的拼图类型，为凸分区拼图提供了一种新的求解方法和基准数据集，克服了以往仅限于方形拼图的局限性。

Abstract: Jigsaw puzzle solving requires the rearrangement of unordered pieces into
their original pose in order to reconstruct a coherent whole, often an image,
and is known to be an intractable problem. While the possible impact of
automatic puzzle solvers can be disruptive in various application domains, most
of the literature has focused on developing solvers for square jigsaw puzzles,
severely limiting their practical use. In this work, we significantly expand
the types of puzzles handled computationally, focusing on what is known as
Convex Partitions, a major subset of polygonal puzzles whose pieces are convex.
We utilize both geometrical and pictorial compatibilities, introduce a greedy
solver, and report several performance measures next to the first benchmark
dataset of such puzzles.

</details>


### [79] [DORAEMON: A Unified Library for Visual Object Modeling and Representation Learning at Scale](https://arxiv.org/abs/2511.04394)
*Ke Du,Yimin Peng,Chao Gao,Fan Zhou,Siqiao Xue*

Main category: cs.CV

TL;DR: DORAEMON是一个开源PyTorch库，旨在统一视觉对象建模和表示学习，提供分类、检索和度量学习功能，集成了大量预训练模型、模块化组件和便捷的部署工具。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为视觉识别和表示学习提供一个可扩展的、统一的平台，以加速快速实验，并高效地将研究进展转化为实际应用。

Method: 该库基于PyTorch，采用YAML驱动的单一工作流，支持分类、检索和度量学习。它提供了超过1000个timm兼容的预训练骨干网络，以及模块化的损失函数、数据增强和分布式训练工具。此外，它支持一键导出到ONNX或HuggingFace。

Result: DORAEMON在ImageNet-1K、MS-Celeb-1M和Stanford online products等数据集上达到了或超越了参考结果，并成功地在研究与部署之间搭建了桥梁。它为视觉识别和表示学习的快速实验提供了一个可扩展的基础。

Conclusion: DORAEMON通过整合数据集、模型和训练技术，提供了一个可扩展的平台，极大地促进了视觉识别和表示学习领域的快速实验，并有助于将研究成果高效地应用于实际场景。

Abstract: DORAEMON is an open-source PyTorch library that unifies visual object
modeling and representation learning across diverse scales. A single
YAML-driven workflow covers classification, retrieval and metric learning; more
than 1000 pretrained backbones are exposed through a timm-compatible interface,
together with modular losses, augmentations and distributed-training utilities.
Reproducible recipes match or exceed reference results on ImageNet-1K,
MS-Celeb-1M and Stanford online products, while one-command export to ONNX or
HuggingFace bridges research and deployment. By consolidating datasets, models,
and training techniques into one platform, DORAEMON offers a scalable
foundation for rapid experimentation in visual recognition and representation
learning, enabling efficient transfer of research advances to real-world
applications. The repository is available at https://github.com/wuji3/DORAEMON.

</details>


### [80] [Landslide Hazard Mapping with Geospatial Foundation Models: Geographical Generalizability, Data Scarcity, and Band Adaptability](https://arxiv.org/abs/2511.04474)
*Wenwen Li,Sizhe Wang,Hyunho Lee,Chenyan Lu,Sujit Roy,Rahul Ramachandran,Chia-Yu Hsu*

Main category: cs.CV

TL;DR: 本研究提出并验证了基于地理空间基础模型（GeoFMs）的Prithvi-EO-2.0模型，用于滑坡制图，该模型在传感器、标签和领域适应性方面表现出色，优于传统深度学习模型和其他GeoFMs，并对滑坡风险管理具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习模型在跨传感器、跨区域或训练数据有限的情况下，难以进行准确及时的滑坡制图，这阻碍了灾害准备和响应。

Method: 研究提出了一个围绕传感器、标签和领域的三轴分析框架，用于调整地理空间基础模型（GeoFMs），重点关注Prithvi-EO-2.0。该模型基于全球预训练、自监督学习和自适应微调。

Result: Prithvi-EO-2.0模型在滑坡制图方面持续优于任务特定的CNN（U-Net, U-Net++）、视觉Transformer（Segformer, SwinV2-B）以及其他GeoFMs（TerraMind, SatMAE）。它对光谱变化具有弹性，在标签稀缺的情况下仍能保持准确性，并能更可靠地泛化到多样化的数据集和地理环境。研究也指出计算成本高和可复用AI训练数据有限等挑战。

Conclusion: 本研究表明，地理空间基础模型（GeoFMs）是迈向更稳健和可扩展的滑坡风险降低和环境监测方法的重要一步，尽管仍面临计算成本和数据可用性等挑战。

Abstract: Landslides cause severe damage to lives, infrastructure, and the environment,
making accurate and timely mapping essential for disaster preparedness and
response. However, conventional deep learning models often struggle when
applied across different sensors, regions, or under conditions of limited
training data. To address these challenges, we present a three-axis analytical
framework of sensor, label, and domain for adapting geospatial foundation
models (GeoFMs), focusing on Prithvi-EO-2.0 for landslide mapping. Through a
series of experiments, we show that it consistently outperforms task-specific
CNNs (U-Net, U-Net++), vision transformers (Segformer, SwinV2-B), and other
GeoFMs (TerraMind, SatMAE). The model, built on global pretraining,
self-supervision, and adaptable fine-tuning, proved resilient to spectral
variation, maintained accuracy under label scarcity, and generalized more
reliably across diverse datasets and geographic settings. Alongside these
strengths, we also highlight remaining challenges such as computational cost
and the limited availability of reusable AI-ready training data for landslide
research. Overall, our study positions GeoFMs as a step toward more robust and
scalable approaches for landslide risk reduction and environmental monitoring.

</details>


### [81] [V-Thinker: Interactive Thinking with Images](https://arxiv.org/abs/2511.04460)
*Runqi Qiao,Qiuna Tan,Minghan Yang,Guanting Dong,Peiqing Yang,Shiqiang Lang,Enhui Wan,Xiaowan Wang,Yida Xu,Lan Yang,Chong Sun,Chen Li,Honggang Zhang*

Main category: cs.CV

TL;DR: 本文提出V-Thinker，一个通用的多模态推理助手，通过数据演化和渐进式训练，增强大型多模态模型（LMMs）的图像交互式推理能力，并引入了VTBench基准。


<details>
  <summary>Details</summary>
Motivation: 当前LMMs在将图像交互与长程推理深度融合方面面临挑战，现有“图像思维”范式受限于视觉工具空间和任务特定工作流设计，无法满足细粒度图像区域交互需求。

Method: V-Thinker包含两个核心组件：1) 数据演化飞轮，自动合成、演化和验证多样性、高质量、高难度的交互式推理数据集；2) 视觉渐进式训练课程，首先通过点级监督对齐感知，然后通过两阶段强化学习框架整合交互式推理。此外，还引入了VTBench，一个专家验证的图像中心交互式推理任务基准。

Result: V-Thinker在通用和交互式推理场景中，持续超越了强大的基于LMM的基线模型。

Conclusion: V-Thinker为推进图像交互式推理应用提供了有价值的见解和解决方案，有效弥合了当前LMMs在深度图像交互和长程推理之间的差距。

Abstract: Empowering Large Multimodal Models (LMMs) to deeply integrate image
interaction with long-horizon reasoning capabilities remains a long-standing
challenge in this field. Recent advances in vision-centric reasoning explore a
promising "Thinking with Images" paradigm for LMMs, marking a shift from
image-assisted reasoning to image-interactive thinking. While this milestone
enables models to focus on fine-grained image regions, progress remains
constrained by limited visual tool spaces and task-specific workflow designs.
To bridge this gap, we present V-Thinker, a general-purpose multimodal
reasoning assistant that enables interactive, vision-centric thinking through
end-to-end reinforcement learning. V-Thinker comprises two key components: (1)
a Data Evolution Flywheel that automatically synthesizes, evolves, and verifies
interactive reasoning datasets across three dimensions-diversity, quality, and
difficulty; and (2) a Visual Progressive Training Curriculum that first aligns
perception via point-level supervision, then integrates interactive reasoning
through a two-stage reinforcement learning framework. Furthermore, we introduce
VTBench, an expert-verified benchmark targeting vision-centric interactive
reasoning tasks. Extensive experiments demonstrate that V-Thinker consistently
outperforms strong LMM-based baselines in both general and interactive
reasoning scenarios, providing valuable insights for advancing
image-interactive reasoning applications.

</details>


### [82] [HideAndSeg: an AI-based tool with automated prompting for octopus segmentation in natural habitats](https://arxiv.org/abs/2511.04426)
*Alan de Aguiar,Michaella Pereira Andrade,Charles Morphy D. Santos,João Paulo Gois*

Main category: cs.CV

TL;DR: 本文提出了一种名为 HideAndSeg 的新型最小监督AI工具，用于在具有挑战性的自然环境中分割章鱼视频，并引入了无监督评估指标，实现了满意的性能，即使在完全遮挡后也能重新识别和分割章鱼。


<details>
  <summary>Details</summary>
Motivation: 由于章鱼的伪装能力、快速的皮肤纹理和颜色变化、非刚性身体变形、频繁遮挡以及水下光照和浊度变化，在自然栖息地分析章鱼极具挑战性。此外，目前缺乏大规模的带标注数据集。

Method: HideAndSeg 集成了 SAM2 和自定义训练的 YOLOv11 对象检测器。首先，用户提供点坐标，通过 SAM2 生成初始分割掩码，这些掩码用于训练 YOLO 模型。之后，该方法通过向 SAM2 提供边界框提示实现完全自动化，无需进一步手动干预。此外，引入了两个无监督指标——时间一致性 $DICE_t$ 和新组件计数 $NC_t$——用于在缺乏真实数据的情况下定量评估分割质量和指导掩码细化。

Result: HideAndSeg 取得了令人满意的性能，与手动提示方法相比，减少了分割噪声。该方法甚至能在自然环境中章鱼完全遮挡后重新识别和分割章鱼，而手动提示模型在此情景下会失败。

Conclusion: 该工作提供了一个实用的工具，通过减少实际场景中的手动分析需求，为更高效地研究野生头足类动物的行为铺平了道路。

Abstract: Analyzing octopuses in their natural habitats is challenging due to their
camouflage capability, rapid changes in skin texture and color, non-rigid body
deformations, and frequent occlusions, all of which are compounded by variable
underwater lighting and turbidity. Addressing the lack of large-scale annotated
datasets, this paper introduces HideAndSeg, a novel, minimally supervised
AI-based tool for segmenting videos of octopuses. It establishes a quantitative
baseline for this task. HideAndSeg integrates SAM2 with a custom-trained
YOLOv11 object detector. First, the user provides point coordinates to generate
the initial segmentation masks with SAM2. These masks serve as training data
for the YOLO model. After that, our approach fully automates the pipeline by
providing a bounding box prompt to SAM2, eliminating the need for further
manual intervention. We introduce two unsupervised metrics - temporal
consistency $DICE_t$ and new component count $NC_t$ - to quantitatively
evaluate segmentation quality and guide mask refinement in the absence of
ground-truth data, i.e., real-world information that serves to train, validate,
and test AI models. Results show that HideAndSeg achieves satisfactory
performance, reducing segmentation noise compared to the manually prompted
approach. Our method can re-identify and segment the octopus even after periods
of complete occlusion in natural environments, a scenario in which the manually
prompted model fails. By reducing the need for manual analysis in real-world
scenarios, this work provides a practical tool that paves the way for more
efficient behavioral studies of wild cephalopods.

</details>


### [83] [THEval. Evaluation Framework for Talking Head Video Generation](https://arxiv.org/abs/2511.04520)
*Nabyl Quignon,Baptiste Chopin,Yaohui Wang,Antitza Dantcheva*

Main category: cs.CV

TL;DR: 本文提出了一套新的评估框架，包含8个指标，用于更全面、细致地评估说话人头部视频生成模型的质量、自然度和同步性，并发现现有模型在表达力和细节方面存在挑战。


<details>
  <summary>Details</summary>
Motivation: 视频生成技术（特别是说话人头部生成）发展迅速，但现有评估指标（如通用视频质量、唇部同步和用户研究）不足以充分衡量其进步，缺乏细致且与人类偏好一致的评估方法。

Method: 研究者提出了一个包含8个指标的新评估框架，涵盖质量、自然度和同步性三个维度。这些指标侧重于效率和与人类偏好的一致性，并分析头部、嘴巴和眉毛的精细动态以及面部质量。此外，他们还整理了一个新的真实数据集，以减少训练数据的偏差。

Result: 对由17个最先进模型生成的85,000个视频进行的广泛实验表明，许多算法在唇部同步方面表现出色，但在生成表达力和无伪影细节方面仍面临挑战。

Conclusion: 所提出的基准评估框架旨在促进生成方法的改进。原始代码、数据集和排行榜将公开，并定期更新新方法，以反映该领域的进展。

Abstract: Video generation has achieved remarkable progress, with generated videos
increasingly resembling real ones. However, the rapid advance in generation has
outpaced the development of adequate evaluation metrics. Currently, the
assessment of talking head generation primarily relies on limited metrics,
evaluating general video quality, lip synchronization, and on conducting user
studies. Motivated by this, we propose a new evaluation framework comprising 8
metrics related to three dimensions (i) quality, (ii) naturalness, and (iii)
synchronization. In selecting the metrics, we place emphasis on efficiency, as
well as alignment with human preferences. Based on this considerations, we
streamline to analyze fine-grained dynamics of head, mouth, and eyebrows, as
well as face quality. Our extensive experiments on 85,000 videos generated by
17 state-of-the-art models suggest that while many algorithms excel in lip
synchronization, they face challenges with generating expressiveness and
artifact-free details. These videos were generated based on a novel real
dataset, that we have curated, in order to mitigate bias of training data. Our
proposed benchmark framework is aimed at evaluating the improvement of
generative methods. Original code, dataset and leaderboards will be publicly
released and regularly updated with new methods, in order to reflect progress
in the field.

</details>


### [84] [Learning from Single Timestamps: Complexity Estimation in Laparoscopic Cholecystectomy](https://arxiv.org/abs/2511.04525)
*Dimitrios Anastasiou,Santiago Barbarisi,Lucy Culshaw,Jayna Patel,Evangelos B. Mazomenos,Imanol Luengo,Danail Stoyanov*

Main category: cs.CV

TL;DR: 本文提出STC-Net，一个基于单时间戳的框架，用于在腹腔镜胆囊切除术（LC）中通过Parkland分级量表（PGS）自动评估手术复杂性。该框架能在弱时间监督下直接处理完整视频，并显著优于非局部化基线。


<details>
  <summary>Details</summary>
Motivation: 在腹腔镜胆囊切除术中，准确评估手术复杂性至关重要，因为严重的炎症与更长的手术时间和更高的术后并发症风险相关。Parkland分级量表（PGS）是临床验证的炎症严重程度分级框架，但其在手术视频中的自动化（尤其是在需要分析完整视频而无需手动筛选的实际场景中）仍未被充分探索。

Method: 本文引入了STC-Net框架，该框架通过PGS实现LC中的单时间戳复杂性估计，并在弱时间监督下运行。与仅限于静态图像或手动裁剪片段的现有方法不同，STC-Net直接处理完整视频。它通过定位、窗口提议和分级模块共同执行时间定位和分级。研究还引入了一种结合硬性和软性定位目标以及背景感知分级监督的新型损失函数。

Result: 在包含1,859个LC视频的私有数据集上进行评估，STC-Net的准确率达到62.11%，F1分数达到61.42%。这在两项指标上均比非局部化基线高出10%以上，突显了弱监督在手术复杂性评估中的有效性。

Conclusion: STC-Net展示了一种可扩展且有效的方法，用于从完整的LC视频中自动进行基于PGS的手术复杂性估计，这使其在术后分析和手术培训方面具有广阔前景。

Abstract: Purpose: Accurate assessment of surgical complexity is essential in
Laparoscopic Cholecystectomy (LC), where severe inflammation is associated with
longer operative times and increased risk of postoperative complications. The
Parkland Grading Scale (PGS) provides a clinically validated framework for
stratifying inflammation severity; however, its automation in surgical videos
remains largely unexplored, particularly in realistic scenarios where complete
videos must be analyzed without prior manual curation. Methods: In this work,
we introduce STC-Net, a novel framework for SingleTimestamp-based Complexity
estimation in LC via the PGS, designed to operate under weak temporal
supervision. Unlike prior methods limited to static images or manually trimmed
clips, STC-Net operates directly on full videos. It jointly performs temporal
localization and grading through a localization, window proposal, and grading
module. We introduce a novel loss formulation combining hard and soft
localization objectives and background-aware grading supervision. Results:
Evaluated on a private dataset of 1,859 LC videos, STC-Net achieves an accuracy
of 62.11% and an F1-score of 61.42%, outperforming non-localized baselines by
over 10% in both metrics and highlighting the effectiveness of weak supervision
for surgical complexity assessment. Conclusion: STC-Net demonstrates a scalable
and effective approach for automated PGS-based surgical complexity estimation
from full LC videos, making it promising for post-operative analysis and
surgical training.

</details>


### [85] [PixCLIP: Achieving Fine-grained Visual Language Understanding via Any-granularity Pixel-Text Alignment Learning](https://arxiv.org/abs/2511.04601)
*Yicheng Xiao,Yu Chen,Haoxuan Ma,Jiale Hong,Caorui Li,Lingxiang Wu,Haiyun Guo,Jinqiao Wang*

Main category: cs.CV

TL;DR: PixCLIP是一个新颖的框架，旨在通过同时处理视觉提示和长文本描述来增强CLIP模型在细粒度图像-文本对齐方面的能力，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在多种视觉语言理解任务中表现出色，但在细粒度图像-文本对齐方面仍有提升空间。现有方法主要通过增加视觉信息处理粒度或利用长文本描述来改进，但CLIP的文本编码器固有的token长度限制了其处理更细粒度长文本信息的能力。本研究旨在协同利用增强视觉和文本内容处理粒度的优势。

Method: 1. 提出了PixCLIP框架，能够同时处理视觉提示输入和长文本描述。2. 建立了一个自动标注管道，用于生成像素级局部化的长文本图像描述。3. 利用该管道构建了LongGRIT数据集（包含近150万个样本）。4. 将CLIP的原始文本编码器替换为大型语言模型（LLM）。5. 提出了一个三分支像素-文本对齐学习框架，以促进图像区域与相应文本描述在任意粒度上的细粒度对齐。

Result: 实验证明，PixCLIP在像素级交互和处理长文本方面取得了突破，实现了最先进的性能。

Conclusion: PixCLIP通过协同增强视觉和文本内容处理粒度，成功克服了CLIP在处理长文本方面的局限性，显著提升了模型在细粒度图像-文本对齐任务中的表现。

Abstract: While the Contrastive Language-Image Pretraining(CLIP) model has achieved
remarkable success in a variety of downstream vison language understanding
tasks, enhancing its capability for fine-grained image-text alignment remains
an active research focus. To this end, most existing works adopt the strategy
of explicitly increasing the granularity of visual information processing,
e.g., incorporating visual prompts to guide the model focus on specific local
regions within the image. Meanwhile, researches on Multimodal Large Language
Models(MLLMs) have demonstrated that training with long and detailed textual
descriptions can effectively improve the model's fine-grained vision-language
alignment. However, the inherent token length limitation of CLIP's text encoder
fundamentally limits CLIP to process more granular textual information embedded
in long text sequences. To synergistically leverage the advantages of enhancing
both visual and textual content processing granularity, we propose PixCLIP, a
novel framework designed to concurrently accommodate visual prompt inputs and
process lengthy textual descriptions. Specifically, we first establish an
automated annotation pipeline capable of generating pixel-level localized,
long-form textual descriptions for images. Utilizing this pipeline, we
construct LongGRIT, a high-quality dataset comprising nearly 1.5 million
samples. Secondly, we replace CLIP's original text encoder with the LLM and
propose a three-branch pixel-text alignment learning framework, facilitating
fine-grained alignment between image regions and corresponding textual
descriptions at arbitrary granularity. Experiments demonstrate that PixCLIP
showcases breakthroughs in pixel-level interaction and handling long-form
texts, achieving state-of-the-art performance.

</details>


### [86] [NovisVQ: A Streaming Convolutional Neural Network for No-Reference Opinion-Unaware Frame Quality Assessment](https://arxiv.org/abs/2511.04628)
*Kylie Cancilla,Alexander Moore,Amar Saini,Carmen Carrano*

Main category: cs.CV

TL;DR: 本文提出了一种可扩展、基于流的无参考、无主观意见的视频质量评估（VQA）模型，该模型利用合成退化和时间感知卷积架构，直接从退化视频中预测全参考（FR）指标，无需参考视频，并在各种退化条件下表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有VQA方法存在局限性：全参考（FR）指标需要干净的参考视频；大多数无参考（NR）模型依赖于昂贵的人类主观意见标签进行训练；且大多数无主观意见的NR方法是基于图像的，忽略了对视频目标检测至关重要的时间上下文。

Method: 本研究提出了一种可扩展、基于流的VQA模型，该模型是无参考且无主观意见的。它利用DAVIS数据集的合成退化数据，训练一个时间感知卷积架构，直接从退化视频中预测FR指标（LPIPS、PSNR、SSIM），在推理时无需参考视频。

Result: 所提出的流式方法在各种退化条件下泛化能力优于其自身的图像基线，突出了时间建模对于可扩展VQA的价值。此外，该模型与全参考指标的相关性高于广泛使用的BRISQUE（一种有主观意见的图像质量评估基线）。

Conclusion: 本研究验证了时间感知、无主观意见的方法在可扩展VQA中的有效性，强调了时间建模对于实际视觉系统的重要性，并证明了其与全参考指标的高度相关性。

Abstract: Video quality assessment (VQA) is vital for computer vision tasks, but
existing approaches face major limitations: full-reference (FR) metrics require
clean reference videos, and most no-reference (NR) models depend on training on
costly human opinion labels. Moreover, most opinion-unaware NR methods are
image-based, ignoring temporal context critical for video object detection. In
this work, we present a scalable, streaming-based VQA model that is both
no-reference and opinion-unaware. Our model leverages synthetic degradations of
the DAVIS dataset, training a temporal-aware convolutional architecture to
predict FR metrics (LPIPS , PSNR, SSIM) directly from degraded video, without
references at inference. We show that our streaming approach outperforms our
own image-based baseline by generalizing across diverse degradations,
underscoring the value of temporal modeling for scalable VQA in real-world
vision systems. Additionally, we demonstrate that our model achieves higher
correlation with full-reference metrics compared to BRISQUE, a widely-used
opinion-aware image quality assessment baseline, validating the effectiveness
of our temporal, opinion-unaware approach.

</details>


### [87] [UniSplat: Unified Spatio-Temporal Fusion via 3D Latent Scaffolds for Dynamic Driving Scene Reconstruction](https://arxiv.org/abs/2511.04595)
*Chen Shi,Shaoshuai Shi,Xiaoyang Lyu,Chunyang Liu,Kehua Sheng,Bo Zhang,Li Jiang*

Main category: cs.CV

TL;DR: UniSplat是一个通用的前馈框架，通过统一的潜在时空融合和3D潜在支架，实现自动驾驶中鲁棒的动态场景重建，并在新视图合成方面达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的前馈3D重建方法难以应对自动驾驶中稀疏、非重叠的摄像机视图和复杂的场景动态带来的联合挑战。

Method: UniSplat构建了一个3D潜在支架，利用预训练的基础模型捕获几何和语义场景上下文。它引入了一种高效的融合机制，直接在3D支架内操作，实现一致的时空对齐。设计了一个双分支解码器，结合点锚定细化和体素生成，从融合的支架生成动态感知的Gaussians，并维护静态Gaussians的持久记忆，以实现超出当前摄像机覆盖范围的流式场景补全。

Result: 在真实世界数据集上的大量实验表明，UniSplat在新视图合成方面取得了最先进的性能，即使对于原始摄像机覆盖范围之外的视点，也能提供鲁棒且高质量的渲染。

Conclusion: UniSplat成功解决了自动驾驶中动态场景重建的挑战，通过其创新的统一潜在时空融合和双分支解码器设计，实现了卓越的重建质量和泛化能力。

Abstract: Feed-forward 3D reconstruction for autonomous driving has advanced rapidly,
yet existing methods struggle with the joint challenges of sparse,
non-overlapping camera views and complex scene dynamics. We present UniSplat, a
general feed-forward framework that learns robust dynamic scene reconstruction
through unified latent spatio-temporal fusion. UniSplat constructs a 3D latent
scaffold, a structured representation that captures geometric and semantic
scene context by leveraging pretrained foundation models. To effectively
integrate information across spatial views and temporal frames, we introduce an
efficient fusion mechanism that operates directly within the 3D scaffold,
enabling consistent spatio-temporal alignment. To ensure complete and detailed
reconstructions, we design a dual-branch decoder that generates dynamic-aware
Gaussians from the fused scaffold by combining point-anchored refinement with
voxel-based generation, and maintain a persistent memory of static Gaussians to
enable streaming scene completion beyond current camera coverage. Extensive
experiments on real-world datasets demonstrate that UniSplat achieves
state-of-the-art performance in novel view synthesis, while providing robust
and high-quality renderings even for viewpoints outside the original camera
coverage.

</details>


### [88] [Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality](https://arxiv.org/abs/2511.04615)
*Tushar Kataria,Shikha Dubey,Mary Bronner,Jolanta Jedrzkiewicz,Ben J. Brintz,Shireen Y. Elhabian,Beatrice S. Knudsen*

Main category: cs.CV

TL;DR: 本文提出了一种自动化、基于准确性的框架，用于评估虚拟免疫组织化学（IHC）图像的质量。研究发现，传统图像保真度指标与染色准确性相关性差，而配对模型表现更佳，且全玻片图像（WSI）评估对于揭示模型性能下降至关重要。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型能从H&E图像生成虚拟IHC染色，提供了一种可扩展、低成本的替代方案。然而，当前基于纹理和分布的图像质量评估指标衡量的是图像保真度而非IHC染色的准确性，导致可靠的图像质量评估仍是一个挑战。

Method: 研究引入了一个自动化且基于准确性的框架，用于评估十六种配对或非配对图像转换模型。通过颜色去卷积技术，生成真实和虚拟IHC图像中棕色（即IHC阳性）像素的掩膜。利用这些分割掩膜计算染色准确性指标（Dice、IoU、Hausdorff距离），直接量化像素级别的正确标记，无需专家手动标注。同时，将结果与传统的图像保真度指标（FID、PSNR、SSIM）进行比较，并进行了全玻片图像（WSI）级别的评估。

Result: 研究结果表明，传统的图像保真度指标（FID、PSNR、SSIM）与染色准确性和病理学家评估的相关性很差。配对模型（如PyramidPix2Pix和AdaptiveNCE）实现了最高的染色准确性，而非配对的扩散模型和GAN模型在提供准确的IHC阳性像素标记方面可靠性较低。此外，全玻片图像（WSI）评估揭示了在基于图像块的评估中不可见的性能下降，强调了WSI级别基准测试的必要性。

Conclusion: 该框架定义了一种可重复的方法来评估虚拟IHC模型的质量，这是加速其向病理学家日常应用转化的关键一步。

Abstract: Deep learning models can generate virtual immunohistochemistry (IHC) stains
from hematoxylin and eosin (H&E) images, offering a scalable and low-cost
alternative to laboratory IHC. However, reliable evaluation of image quality
remains a challenge as current texture- and distribution-based metrics quantify
image fidelity rather than the accuracy of IHC staining. Here, we introduce an
automated and accuracy grounded framework to determine image quality across
sixteen paired or unpaired image translation models. Using color deconvolution,
we generate masks of pixels stained brown (i.e., IHC-positive) as predicted by
each virtual IHC model. We use the segmented masks of real and virtual IHC to
compute stain accuracy metrics (Dice, IoU, Hausdorff distance) that directly
quantify correct pixel - level labeling without needing expert manual
annotations. Our results demonstrate that conventional image fidelity metrics,
including Frechet Inception Distance (FID), peak signal-to-noise ratio (PSNR),
and structural similarity (SSIM), correlate poorly with stain accuracy and
pathologist assessment. Paired models such as PyramidPix2Pix and AdaptiveNCE
achieve the highest stain accuracy, whereas unpaired diffusion- and GAN-based
models are less reliable in providing accurate IHC positive pixel labels.
Moreover, whole-slide images (WSI) reveal performance declines that are
invisible in patch-based evaluations, emphasizing the need for WSI-level
benchmarks. Together, this framework defines a reproducible approach for
assessing the quality of virtual IHC models, a critical step to accelerate
translation towards routine use by pathologists.

</details>


### [89] [InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation](https://arxiv.org/abs/2511.04675)
*Jinlai Liu,Jian Han,Bin Yan,Hui Wu,Fengda Zhu,Xing Wang,Yi Jiang,Bingyue Peng,Zehuan Yuan*

Main category: cs.CV

TL;DR: InfinityStar是一个统一的时空自回归框架，用于高分辨率图像和动态视频合成。它在质量和速度上显著优于现有自回归模型，甚至超越一些扩散模型，支持多种生成任务。


<details>
  <summary>Details</summary>
Motivation: 受视觉和语言领域自回归模型成功的启发，研究旨在开发一个纯离散的统一框架，能够共同捕获空间和时间依赖性，以实现高分辨率图像和动态视频合成。

Method: 引入InfinityStar，一个统一的时空自回归框架。它采用纯离散方法，通过单一架构共同捕获空间和时间依赖性。该设计自然支持文本到图像、文本到视频、图像到视频和长交互式视频合成等多种生成任务，通过直接的时间自回归实现。

Result: InfinityStar在VBENCH上得分83.74，大幅超越所有自回归模型，甚至超过了部分扩散竞争对手（如HunyuanVideo）。在没有额外优化的情况下，模型生成5秒720p视频的速度比领先的扩散方法快约10倍。据称，InfinityStar是首个能够生成工业级720p视频的离散自回归视频生成器。

Conclusion: InfinityStar是一个高效、高质量的统一离散自回归模型，能够生成工业级720p视频，并在性能和速度上建立了新的基准，为高效、高质量视频生成领域提供了新的研究方向。

Abstract: We introduce InfinityStar, a unified spacetime autoregressive framework for
high-resolution image and dynamic video synthesis. Building on the recent
success of autoregressive modeling in both vision and language, our purely
discrete approach jointly captures spatial and temporal dependencies within a
single architecture. This unified design naturally supports a variety of
generation tasks such as text-to-image, text-to-video, image-to-video, and long
interactive video synthesis via straightforward temporal autoregression.
Extensive experiments demonstrate that InfinityStar scores 83.74 on VBench,
outperforming all autoregressive models by large margins, even surpassing some
diffusion competitors like HunyuanVideo. Without extra optimizations, our model
generates a 5s, 720p video approximately 10x faster than leading
diffusion-based methods. To our knowledge, InfinityStar is the first discrete
autoregressive video generator capable of producing industrial level 720p
videos. We release all code and models to foster further research in efficient,
high-quality video generation.

</details>


### [90] [Polarization-resolved imaging improves eye tracking](https://arxiv.org/abs/2511.04652)
*Mantas Žurauskas,Tom Bu,Sanaz Alali,Beyza Kalkanli,Derek Shi,Fernando Alamos,Gauresh Pandit,Christopher Mei,Ali Behrooz,Ramin Mirjalili,Dave Stronks,Alexander Fix,Dmitri Model*

Main category: cs.CV

TL;DR: 该研究展示了偏振分辨近红外成像（PET）如何通过揭示巩膜和角膜上的独特特征来显著改善眼动追踪的准确性，与仅基于强度的传统方法相比，在多种挑战条件下将凝视误差降低了10-16%。


<details>
  <summary>Details</summary>
Motivation: 传统的眼动追踪主要依赖于光线强度，但眼部组织反射光的偏振状态提供了额外的光学对比机制。本研究旨在探索如何利用这种偏振对比来增强眼动追踪能力。

Method: 研究采用了一个偏振使能眼动追踪（PET）系统，该系统由一个偏振滤光阵列相机和一个线性偏振近红外照明器组成。通过卷积神经网络（CNN）机器学习模型对来自PET系统的数据进行训练，以实现眼动追踪。

Result: PET系统能够揭示巩膜上可追踪的特征和角膜上与凝视相关的模式，这些特征在仅基于强度的图像中几乎不存在。在346名参与者的数据上，基于PET数据训练的CNN模型将中位数95百分位绝对凝视误差降低了10-16%，优于能力匹配的强度基线，即使在眼睑遮挡、眼距变化和瞳孔大小变化等挑战条件下也表现良好。

Conclusion: 光-组织偏振效应为人机交互带来了实际的收益。PET被定位为未来可穿戴设备中一种简单、鲁棒的传感模式。

Abstract: Polarization-resolved near-infrared imaging adds a useful optical contrast
mechanism to eye tracking by measuring the polarization state of light
reflected by ocular tissues in addition to its intensity. In this paper we
demonstrate how this contrast can be used to enable eye tracking. Specifically,
we demonstrate that a polarization-enabled eye tracking (PET) system composed
of a polarization--filter--array camera paired with a linearly polarized
near-infrared illuminator can reveal trackable features across the sclera and
gaze-informative patterns on the cornea, largely absent in intensity-only
images. Across a cohort of 346 participants, convolutional neural network based
machine learning models trained on data from PET reduced the median
95th-percentile absolute gaze error by 10--16\% relative to capacity-matched
intensity baselines under nominal conditions and in the presence of eyelid
occlusions, eye-relief changes, and pupil-size variation. These results link
light--tissue polarization effects to practical gains in human--computer
interaction and position PET as a simple, robust sensing modality for future
wearable devices.

</details>


### [91] [Cambrian-S: Towards Spatial Supersensing in Video](https://arxiv.org/abs/2511.04670)
*Shusheng Yang,Jihan Yang,Pinzhi Huang,Ellis Brown,Zihao Yang,Yue Yu,Shengbang Tong,Zihan Zheng,Yifan Xu,Muhan Wang,Daohan Lu,Rob Fergus,Yann LeCun,Li Fei-Fei,Saining Xie*

Main category: cs.CV

TL;DR: 本文提出“超感知”（supersensing）范式以推动多模态智能发展，超越现有任务驱动和暴力长上下文方法。通过引入VSI-SUPER基准测试和“预测感知”方法，证明了仅靠规模不足以实现高级空间认知，并展示了预测感知在空间超感知任务上的优越性。


<details>
  <summary>Details</summary>
Motivation: 当前的真多模态智能进展受限于反应式、任务驱动系统和暴力长上下文处理。现有基准测试主要覆盖空间认知的早期阶段，未能有效挑战模型进行真正的世界建模，缺乏对连续经验、隐式3D空间认知和预测世界建模能力的评估。

Method: 本文提出空间超感知的四个阶段：语义感知、流式事件认知、隐式3D空间认知和预测世界建模。为推动进展，引入VSI-SUPER两部分基准测试：VSR（长时程视觉空间回忆）和VSC（持续视觉空间计数），旨在抵抗暴力上下文扩展。通过构建VSI-590K数据集并训练Cambrian-S模型来测试数据扩展的极限。最后，提出“预测感知”作为前进方向，利用自监督的下一潜在帧预测器，通过“惊喜”（预测误差）驱动记忆和事件分割。

Result: 通过VSI-590K训练的Cambrian-S在VSI-Bench上实现了+30%的绝对提升，且未牺牲通用能力。然而，在VSI-SUPER上的性能依然有限，表明仅靠规模不足以实现空间超感知。所提出的预测感知方法在VSI-SUPER上显著优于领先的专有基线。

Conclusion: 真正的空间超感知需要模型不仅能“看”，还能“预期”、“选择”和“组织”经验。预测感知是一种有前途的方法，而仅仅扩大模型规模不足以实现空间超感知。

Abstract: We argue that progress in true multimodal intelligence calls for a shift from
reactive, task-driven systems and brute-force long context towards a broader
paradigm of supersensing. We frame spatial supersensing as four stages beyond
linguistic-only understanding: semantic perception (naming what is seen),
streaming event cognition (maintaining memory across continuous experiences),
implicit 3D spatial cognition (inferring the world behind pixels), and
predictive world modeling (creating internal models that filter and organize
information). Current benchmarks largely test only the early stages, offering
narrow coverage of spatial cognition and rarely challenging models in ways that
require true world modeling. To drive progress in spatial supersensing, we
present VSI-SUPER, a two-part benchmark: VSR (long-horizon visual spatial
recall) and VSC (continual visual spatial counting). These tasks require
arbitrarily long video inputs yet are resistant to brute-force context
expansion. We then test data scaling limits by curating VSI-590K and training
Cambrian-S, achieving +30% absolute improvement on VSI-Bench without
sacrificing general capabilities. Yet performance on VSI-SUPER remains limited,
indicating that scale alone is insufficient for spatial supersensing. We
propose predictive sensing as a path forward, presenting a proof-of-concept in
which a self-supervised next-latent-frame predictor leverages surprise
(prediction error) to drive memory and event segmentation. On VSI-SUPER, this
approach substantially outperforms leading proprietary baselines, showing that
spatial supersensing requires models that not only see but also anticipate,
select, and organize experience.

</details>


### [92] [Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts](https://arxiv.org/abs/2511.04655)
*Ellis Brown,Jihan Yang,Shusheng Yang,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: MLLM模型在多模态基准测试中常利用非视觉偏差而非真正的视觉理解。本文提出“测试集压力测试”（TsT）方法诊断这些偏差，并通过“迭代偏差剪枝”（IBP）程序去除高偏差样本，以创建更稳健的基准。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLM）在许多多模态基准测试中表现出色，但这种表现并非源于强大的视觉理解能力，而是利用了偏见、语言先验和表面模式。这对于旨在评估视觉输入的基准尤其成问题，导致无法准确评估模型的真实视觉能力。

Method: 本文遵循“如果基准可以被利用，它就会被利用”的诊断原则。首先，通过“测试集压力测试”（TsT）诊断基准的脆弱性，主要方法是利用k折交叉验证，仅在测试集的非视觉文本输入上微调一个强大的大型语言模型，以揭示捷径性能并分配偏差分数。辅以基于随机森林的轻量级诊断工具进行快速审计。其次，通过“迭代偏差剪枝”（IBP）程序过滤高偏差样本，从而消除基准中的偏差。

Result: 将该框架应用于VSI-Bench、CV-Bench、MMMU和VideoMME四个基准，发现普遍存在的非视觉偏差。以VSI-Bench为例，应用完整框架创建了VSI-Bench-Debiased，结果显示其非视觉可解性降低，并且与原始基准相比，盲视性能差距更大，证明了去偏后的基准更具鲁棒性。

Conclusion: 当前的MLLM基准测试普遍存在非视觉偏差，导致模型无需真正的视觉理解即可取得高分。本文提出的诊断和去偏框架（TsT和IBP）能够有效识别和缓解这些偏差，从而创建更稳健、更能准确评估模型视觉理解能力的多模态基准。

Abstract: Robust benchmarks are crucial for evaluating Multimodal Large Language Models
(MLLMs). Yet we find that models can ace many multimodal benchmarks without
strong visual understanding, instead exploiting biases, linguistic priors, and
superficial patterns. This is especially problematic for vision-centric
benchmarks that are meant to require visual inputs. We adopt a diagnostic
principle for benchmark design: if a benchmark can be gamed, it will be.
Designers should therefore try to ``game'' their own benchmarks first, using
diagnostic and debiasing procedures to systematically identify and mitigate
non-visual biases. Effective diagnosis requires directly ``training on the test
set'' -- probing the released test set for its intrinsic, exploitable patterns.
  We operationalize this standard with two components. First, we diagnose
benchmark susceptibility using a ``Test-set Stress-Test'' (TsT) methodology.
Our primary diagnostic tool involves fine-tuning a powerful Large Language
Model via $k$-fold cross-validation on exclusively the non-visual, textual
inputs of the test set to reveal shortcut performance and assign each sample a
bias score $s(x)$. We complement this with a lightweight Random Forest-based
diagnostic operating on hand-crafted features for fast, interpretable auditing.
Second, we debias benchmarks by filtering high-bias samples using an
``Iterative Bias Pruning'' (IBP) procedure. Applying this framework to four
benchmarks -- VSI-Bench, CV-Bench, MMMU, and VideoMME -- we uncover pervasive
non-visual biases. As a case study, we apply our full framework to create
VSI-Bench-Debiased, demonstrating reduced non-visual solvability and a wider
vision-blind performance gap than the original.

</details>


### [93] [Tracking and Understanding Object Transformations](https://arxiv.org/abs/2511.04678)
*Yihong Sun,Xinyu Yang,Jennifer J. Sun,Bharath Hariharan*

Main category: cs.CV

TL;DR: 本文引入了“跟踪任意状态”任务，旨在跟踪经历状态转换的物体，同时检测和描述这些状态变化。为此，作者提出了一个零样本系统TubeletGraph和一个新基准数据集VOST-TAS，该系统在转换下实现了最先进的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的物体经常发生状态转换（如苹果被切开、蝴蝶破茧而出），但现有方法在物体外观发生显著变化后往往会丢失目标，这限制了对真实世界物体和动态的理解。

Method: 本文提出了“跟踪任意状态”（Track Any State）任务和VOST-TAS基准数据集。为解决此问题，作者提出了TubeletGraph，一个零样本系统。它首先识别可能被忽略的轨迹，并根据语义和邻近先验来决定是否整合它们。然后，它对添加的轨迹进行推理，并生成一个描述每个观察到的转换的状态图。

Result: TubeletGraph在状态转换下实现了最先进的跟踪性能，同时展示了对物体转换更深层次的理解，并在复杂物体转换的时间定位和语义推理方面展现出良好的能力。

Conclusion: TubeletGraph成功解决了物体在状态转换后跟踪丢失的问题，通过检测和描述状态变化，实现了卓越的跟踪性能和对物体转换的深入理解，为复杂物体转换的语义推理提供了有前景的解决方案。

Abstract: Real-world objects frequently undergo state transformations. From an apple
being cut into pieces to a butterfly emerging from its cocoon, tracking through
these changes is important for understanding real-world objects and dynamics.
However, existing methods often lose track of the target object after
transformation, due to significant changes in object appearance. To address
this limitation, we introduce the task of Track Any State: tracking objects
through transformations while detecting and describing state changes,
accompanied by a new benchmark dataset, VOST-TAS. To tackle this problem, we
present TubeletGraph, a zero-shot system that recovers missing objects after
transformation and maps out how object states are evolving over time.
TubeletGraph first identifies potentially overlooked tracks, and determines
whether they should be integrated based on semantic and proximity priors. Then,
it reasons about the added tracks and generates a state graph describing each
observed transformation. TubeletGraph achieves state-of-the-art tracking
performance under transformations, while demonstrating deeper understanding of
object transformations and promising capabilities in temporal grounding and
semantic reasoning for complex object transformations. Code, additional
results, and the benchmark dataset are available at
https://tubelet-graph.github.io.

</details>


### [94] [Carousel: A High-Resolution Dataset for Multi-Target Automatic Image Cropping](https://arxiv.org/abs/2511.04680)
*Rafe Loya,Andrew Hamara,Benjamin Estell,Benjamin Kilpatrick,Andrew C. Freeman*

Main category: cs.CV

TL;DR: 本文提出了一种解决自动图像裁剪中生成多个具有美学吸引力且独特的裁剪区域的问题，并为此引入了一个新数据集和评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多关注生成单个高质量的裁剪区域，但现代社交媒体应用场景需要能够生成多个不同且美观的裁剪区域。

Method: 作者首先讨论了现代社交媒体应用中该问题的动机，然后引入了一个包含277张相关图像和人工标注的新数据集。接着，他们将图像分区算法作为预处理步骤，评估了多个单裁剪模型在此场景下的有效性。

Result: 通过将图像分区算法作为预处理步骤，本文评估了多个单裁剪模型在生成多个独特裁剪方面的有效性。数据集已公开。

Conclusion: 本文解决了生成多个独特且具有美学吸引力裁剪区域的问题，并通过引入新数据集和评估方法，为该领域的研究奠定了基础。

Abstract: Automatic image cropping is a method for maximizing the human-perceived
quality of cropped regions in photographs. Although several works have proposed
techniques for producing singular crops, little work has addressed the problem
of producing multiple, distinct crops with aesthetic appeal. In this paper, we
motivate the problem with a discussion on modern social media applications,
introduce a dataset of 277 relevant images and human labels, and evaluate the
efficacy of several single-crop models with an image partitioning algorithm as
a pre-processing step. The dataset is available at
https://github.com/RafeLoya/carousel.

</details>


### [95] [SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding](https://arxiv.org/abs/2511.04668)
*Ellis Brown,Arijit Ray,Ranjay Krishna,Ross Girshick,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: 多模态语言模型在视频空间推理方面表现不佳，主要受限于真实世界数据的获取。本文提出SIMS-V框架，利用3D模拟器生成空间丰富的视频训练数据，并通过消融实验确定了三种核心问题类型，实现了高效且可迁移的空间智能训练，使小型模型在真实世界空间推理基准上超越大型基线模型。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态语言模型在高级视频理解方面表现出色，但在跨时空的空间推理方面仍存在困难。当前的空间训练方法依赖真实世界视频数据，但获取多样化且带有精确空间标注的数据是一个瓶颈。

Method: 本文提出了SIMS-V，一个系统性的数据生成框架，利用3D模拟器的特权信息创建空间丰富的视频训练数据。通过系统性地消融问题类型、组合和规模，研究了模拟数据哪些特性能够驱动有效的真实世界迁移。最终确定了三类问题（度量测量、视角依赖推理和时间跟踪）作为开发可迁移空间智能的最有效集合。

Result: 研究发现，度量测量、视角依赖推理和时间跟踪这三种问题类型组成的最小集合，在开发可迁移空间智能方面最为有效，即使问题类型较少，其表现也优于全面覆盖的方法。通过这种高效训练，一个仅用2.5万个模拟示例微调的7B参数视频LLM，其性能超越了更大的72B基线模型，并在严格的真实世界空间推理基准上与专有模型达到竞争水平。该方法展现出强大的泛化能力，在通用视频理解方面保持性能，同时在具身和真实世界空间任务上显示出显著改进。

Conclusion: 利用3D模拟器生成的空间丰富数据，并专注于特定核心问题类型进行训练，可以高效地为多模态语言模型开发可迁移的空间智能。这种方法能够显著提升模型在真实世界空间推理任务上的表现，即使使用更少的训练数据和更小的模型也能取得优异成果。

Abstract: Despite impressive high-level video comprehension, multimodal language models
struggle with spatial reasoning across time and space. While current spatial
training approaches rely on real-world video data, obtaining diverse footage
with precise spatial annotations remains a bottleneck. To alleviate this
bottleneck, we present SIMS-V -- a systematic data-generation framework that
leverages the privileged information of 3D simulators to create spatially-rich
video training data for multimodal language models. Using this framework, we
investigate which properties of simulated data drive effective real-world
transfer through systematic ablations of question types, mixes, and scales. We
identify a minimal set of three question categories (metric measurement,
perspective-dependent reasoning, and temporal tracking) that prove most
effective for developing transferable spatial intelligence, outperforming
comprehensive coverage despite using fewer question types. These insights
enable highly efficient training: our 7B-parameter video LLM fine-tuned on just
25K simulated examples outperforms the larger 72B baseline and achieves
competitive performance with proprietary models on rigorous real-world spatial
reasoning benchmarks. Our approach demonstrates robust generalization,
maintaining performance on general video understanding while showing
substantial improvements on embodied and real-world spatial tasks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [96] [Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs](https://arxiv.org/abs/2511.03738)
*Pranav Bhandari,Nicolas Fay,Sanjeevan Selvaganapathy,Amitava Datta,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: 本文提出一种新颖的流水线，通过提取Transformer隐藏层激活并利用大五人格特质，识别模型中与人格特质相关的低秩共享子空间，并开发出一种灵活的引导框架，实现对LLM输出中人格特质表达的精确控制，且不影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生成中展现出隐式人格，但可靠地控制或调整这些特质以满足特定需求仍是一个未解决的挑战。文献中缺乏有效的机制来在生成过程中操纵模型的行为，这是一个关键空白。人格感知型LLM为此提供了一个有前景的方向，但心理学构建与其在LLM中表示之间的关系尚未得到充分探索，且如何利用这些表示来引导模型行为也值得深入研究。

Method: 研究提出了一种新颖的流水线，该流水线利用大五人格特质（开放性、尽责性、外向性、宜人性、神经质）从Transformer层中提取隐藏状态激活，应用低秩子空间发现方法，并在不同模型架构中识别特质特定的最优层，以实现鲁棒的注入。然后，通过一个具有动态层选择的灵活引导框架，将生成的人格对齐方向进行操作化，从而精确控制LLM输出中的特质表达。

Result: 研究发现人格特质占据一个低秩共享子空间，并且这些潜在结构可以通过细致的扰动转化为可操作的机制，实现有效的引导，同时不影响模型的流畅性、多样性和通用能力。

Conclusion: 该研究成功地弥合了心理学理论与实际模型对齐之间的鸿沟，为LLM中人格特质的精确控制提供了一种有效且不损害模型性能的方法。

Abstract: Large Language Models exhibit implicit personalities in their generation, but
reliably controlling or aligning these traits to meet specific needs remains an
open challenge. The need for effective mechanisms for behavioural manipulation
of the model during generation is a critical gap in the literature that needs
to be fulfilled. Personality-aware LLMs hold a promising direction towards this
objective. However, the relationship between these psychological constructs and
their representations within LLMs remains underexplored and requires further
investigation. Moreover, it is intriguing to understand and study the use of
these representations to steer the models' behaviour. We propose a novel
pipeline that extracts hidden state activations from transformer layers using
the Big Five Personality Traits (Openness, Conscientiousness, Extraversion,
Agreeableness and Neuroticism), which is a comprehensive and empirically
validated framework to model human personality applies low-rank subspace
discovery methods, and identifies trait-specific optimal layers across
different model architectures for robust injection. The resulting
personality-aligned directions are then operationalised through a flexible
steering framework with dynamic layer selection, enabling precise control of
trait expression in LLM outputs. Our findings reveal that personality traits
occupy a low-rank shared subspace, and that these latent structures can be
transformed into actionable mechanisms for effective steering through careful
perturbations without impacting the fluency, variance and general capabilities,
helping to bridge the gap between psychological theory and practical model
alignment.

</details>


### [97] [TextualVerifier: Verify TextGrad Step-by-Step](https://arxiv.org/abs/2511.03739)
*Eugenius Mario Situmorang,Adila Alfa Krisnadhi,Ari Wibisono*

Main category: cs.CL

TL;DR: TextualVerifier是一个基于大型语言模型（LLM）的自验证框架，通过链式思考和多数投票来验证TextGrad的文本推理过程，显著提高了推理的有效性和TextGrad的性能。


<details>
  <summary>Details</summary>
Motivation: TextGrad作为一种新颖的文本自动微分方法，目前缺乏确保其文本决策推理有效性的自验证机制。

Method: 本研究引入了TextualVerifier框架，它利用大型语言模型（LLM）的链式思考（chain-of-thought）推理和多数投票机制来填补验证空白。该框架包含四个阶段：链式思考分解、变体生成、多数投票和共识聚合。它以非侵入性方式集成到TextGrad的损失函数和优化结果验证阶段。实验使用Gemini 1.5 Pro模型，分为两个阶段进行评估：1）在PRM800K上进行独立评估；2）与TextGrad集成在GPQA-Diamond、MMLU-ML和MMLU-CP基准上进行评估。

Result: 实验结果显示出统计学上显著的改进（p < 0.001）。在第一阶段，TextualVerifier使推理步骤的有效性提高了29%。在第二阶段，集成到TextGrad损失函数中，性能从68.2%提高到70.4%，增加了2.2个百分点，平均仅增加了5.9次LLM调用。对TextualVerifier版本化的进一步评估显示，在GPQA、MMLU-ML和MMLU-CP上分别实现了8.08、10.71和3.92个百分点的改进。

Conclusion: TextualVerifier是第一个为TextGrad提供自验证的框架，它利用基于LLM的技术，无需数值梯度，从而实现了更可靠的推理，并为文本优化中的验证开辟了新方向。

Abstract: TextGrad is a novel approach to text-based automatic differentiation that
enables composite AI systems to perform optimization without explicit numerical
equations. However, it currently lacks self-verification mechanisms that ensure
reasoning validity in text-based decision making. This research introduces
TextualVerifier, a verification framework that leverages chain-of-thought
reasoning and majority voting with large language models to address this
verification gap. TextualVerifier implements a four-stage workflow:
chain-of-thought decomposition, variant generation, majority voting, and
consensus aggregation. It integrates non-invasively with TextGrad at both the
loss function and optimization result verification stages. Experimental
evaluation using the Gemini 1.5 Pro model is conducted in two phases: (1)
standalone evaluation on PRM800K, and (2) integrated evaluation with TextGrad
on GPQA-Diamond, MMLU-ML, and MMLU-CP benchmarks. Results show statistically
significant improvements (p < 0.001). In phase one, TextualVerifier improves
the validity of reasoning steps by 29 percent. In phase two, integration into
TextGrad loss function yields a 2.2 percentage point gain from 68.2 to 70.4
percent with a moderate overhead of 5.9 LLM calls on average. Further
evaluations of TextualVerifier versioning yield 8.08, 10.71, and 3.92
percentage point improvements on GPQA, MMLU-ML, and MMLU-CP respectively.
TextualVerifier thus presents the first self-verification framework for
TextGrad through LLM-based techniques without requiring numerical gradients,
enabling more reliable reasoning and opening new directions for verification in
text-based optimization.

</details>


### [98] [GRDD+: An Extended Greek Dialectal Dataset with Cross-Architecture Fine-tuning Evaluation](https://arxiv.org/abs/2511.03772)
*Stergios Chatzikyriakidis,Dimitris Papadakis,Sevasti-Ioanna Papaioannou,Erofili Psaltaki*

Main category: cs.CL

TL;DR: 本文介绍了扩展的希腊方言数据集GRDD+，包含637万词和10种方言，并使用该数据集对多种LLM进行了微调实验，以评估高质量方言数据对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有希腊方言数据集有限，且缺乏具有如此多样性和规模的数据集。研究旨在通过创建更全面的数据集，探索高质量方言数据对大型语言模型（LLM）性能的影响。

Method: 研究方法包括：1. 构建GRDD+数据集，通过补充现有GRDD数据并新增六种方言（如Greco-Corsican, Griko, Tsakonian等），最终达到6,374,939词和10种方言的规模。2. 使用GRDD+数据集对Llama-3-8B、Llama-3.1-8B和Krikri-8B三种LLM架构进行微调实验。3. 将微调结果与前沿模型（如Claude-3.7-Sonnet, Gemini-2.5, ChatGPT-5）进行比较。

Result: 研究结果是创建了一个迄今为止规模最大、方言种类最丰富的希腊方言数据集GRDD+（6,374,939词，10种方言）。此外，研究还通过一系列微调实验，展示了高质量方言数据对多种LLM性能的影响。

Conclusion: 高质量的方言数据对LLM的性能具有显著影响。GRDD+数据集是迄今为止第一个具有如此多样性和规模的希腊方言数据集，为未来方言相关的LLM研究提供了宝贵的资源。

Abstract: We present an extended Greek Dialectal Dataset (GRDD+) 1that complements the
existing GRDD dataset with more data from Cretan, Cypriot, Pontic and Northern
Greek, while we add six new varieties: Greco-Corsican, Griko (Southern Italian
Greek), Maniot, Heptanesian, Tsakonian, and Katharevusa Greek. The result is a
dataset with total size 6,374,939 words and 10 varieties. This is the first
dataset with such variation and size to date. We conduct a number of
fine-tuning experiments to see the effect of good quality dialectal data on a
number of LLMs. We fine-tune three model architectures (Llama-3-8B,
Llama-3.1-8B, Krikri-8B) and compare the results to frontier models
(Claude-3.7-Sonnet, Gemini-2.5, ChatGPT-5).

</details>


### [99] [PLLuM: A Family of Polish Large Language Models](https://arxiv.org/abs/2511.03823)
*Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik*

Main category: cs.CL

TL;DR: PLLuM是为波兰语量身定制的最大开源基础模型系列，旨在解决现有大模型以英语为中心的问题，通过构建大规模波兰语语料库和数据集，并结合负责任AI框架开发而成，已公开用于促进波兰的开放研究和主权AI技术。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）主要关注英语，导致对其他语言的支持有限。研究动机是为了满足对高质量、透明且与波兰文化相关的语言模型的需求，超越以英语为中心的商业模型。

Method: 开发了PLLuM（Polish Large Language Model）系列，包括构建了一个新的1400亿token的波兰语预训练文本语料库，一个7.7万条自定义指令数据集，以及一个10万条偏好优化数据集。关键组成部分是一个负责任AI框架，包含严格的数据治理和用于输出校正与安全过滤的混合模块。详细描述了模型架构、训练过程以及基础模型和指令微调模型的对齐技术。

Result: 成功开发了PLLuM，这是为波兰语量身定制的最大开源基础模型系列。该模型在公共管理领域的下游任务中展示了其效用，并已公开发布。

Conclusion: PLLuM的发布旨在促进波兰的开放研究，并加强波兰的主权AI技术，为波兰语提供了高质量、透明且文化相关的语言模型。

Abstract: Large Language Models (LLMs) play a central role in modern artificial
intelligence, yet their development has been primarily focused on English,
resulting in limited support for other languages. We present PLLuM (Polish
Large Language Model), the largest open-source family of foundation models
tailored specifically for the Polish language. Developed by a consortium of
major Polish research institutions, PLLuM addresses the need for high-quality,
transparent, and culturally relevant language models beyond the English-centric
commercial landscape. We describe the development process, including the
construction of a new 140-billion-token Polish text corpus for pre-training, a
77k custom instructions dataset, and a 100k preference optimization dataset. A
key component is a Responsible AI framework that incorporates strict data
governance and a hybrid module for output correction and safety filtering. We
detail the models' architecture, training procedures, and alignment techniques
for both base and instruction-tuned variants, and demonstrate their utility in
a downstream task within public administration. By releasing these models
publicly, PLLuM aims to foster open research and strengthen sovereign AI
technologies in Poland.

</details>


### [100] [Divide, Cache, Conquer: Dichotomic Prompting for Efficient Multi-Label LLM-Based Classification](https://arxiv.org/abs/2511.03830)
*Mikołaj Langner,Jan Eliasz,Ewa Rudnicka,Jan Kocoń*

Main category: cs.CL

TL;DR: 该研究提出一种高效的多标签文本分类方法，通过将任务分解为一系列二分决策，并结合前缀缓存和LLM-to-SLM蒸馏，在不损失准确性的前提下显著提升了推理效率。


<details>
  <summary>Details</summary>
Motivation: 动机是提高大型语言模型（LLMs）在多标签文本分类任务中的效率，尤其是在短文本推理场景下，同时保持或提高分类准确性。

Method: 该方法将多标签分类任务重构为一系列二分（是/否）决策。每个目标维度独立查询，并结合前缀缓存机制以提高效率。此外，采用LLM-to-SLM蒸馏技术，使用强大的LLM（DeepSeek-V3）生成多重标注，聚合后用于微调较小的模型（如HerBERT-Large、CLARIN-1B、PLLuM-8B、Gemma3-1B）。研究以情感文本分析（24个维度）为例进行验证。

Result: 结果显示，该方法在短文本推理方面取得了显著的效率提升，且未损失准确性。经过微调的小型模型在零样本基线上表现出显著改进，尤其是在训练期间见过的维度上。这些发现表明，将多标签分类分解为二分查询，结合蒸馏和缓存感知推理，提供了一个可扩展且有效的LLM分类框架。

Conclusion: 将多标签分类分解为二分查询，结合蒸馏和缓存感知推理，为基于LLM的分类提供了一个可扩展且有效的框架。尽管该方法在情感状态分析中得到验证，但其具有通用性，可应用于不同领域。

Abstract: We introduce a method for efficient multi-label text classification with
large language models (LLMs), built on reformulating classification tasks as
sequences of dichotomic (yes/no) decisions. Instead of generating all labels in
a single structured response, each target dimension is queried independently,
which, combined with a prefix caching mechanism, yields substantial efficiency
gains for short-text inference without loss of accuracy. To demonstrate the
approach, we focus on affective text analysis, covering 24 dimensions including
emotions and sentiment. Using LLM-to-SLM distillation, a powerful annotator
model (DeepSeek-V3) provides multiple annotations per text, which are
aggregated to fine-tune smaller models (HerBERT-Large, CLARIN-1B, PLLuM-8B,
Gemma3-1B). The fine-tuned models show significant improvements over zero-shot
baselines, particularly on the dimensions seen during training. Our findings
suggest that decomposing multi-label classification into dichotomic queries,
combined with distillation and cache-aware inference, offers a scalable and
effective framework for LLM-based classification. While we validate the method
on affective states, the approach is general and applicable across domains.

</details>


### [101] [STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models](https://arxiv.org/abs/2511.03827)
*Mohammad Atif Quamar,Mohammad Areeb,Mikhail Kuznetsov,Muslum Ozgur Ozmen,Z. Berkay Celik*

Main category: cs.CL

TL;DR: 本文提出STARS，一种解码时算法，通过迭代采样、评分和拒绝/接受固定大小的令牌片段，在计算效率和对齐质量上显著优于现有微调方法，并与强大的Best-of-N基线竞争，实现LLM与人类价值观的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐方法，如微调，计算成本高昂且次优；而像Best-of-N这样的推理时方法，要实现最佳对齐则需要不切实际的计算量。

Method: 本文提出STARS（Segment-level Token Alignment with Rejection Sampling），一种解码时算法。它通过迭代地采样、评分和拒绝/接受短的、固定大小的令牌片段来引导模型生成。这种方法允许对生成路径进行早期修正。

Result: 在六个LLM上，STARS在胜率方面比监督微调（SFT）高出多达14.9个百分点，比直接偏好优化（DPO）高出多达4.3个百分点，同时与强大的Best-of-N基线保持高度竞争力。

Conclusion: STARS确立了细粒度、奖励引导的采样作为一种通用、鲁棒且高效的替代方案，用于对齐LLM，优于传统的微调和全序列排序方法。

Abstract: Aligning large language models with human values is crucial for their safe
deployment; however, existing methods, such as fine-tuning, are computationally
expensive and suboptimal. In contrast, inference-time approaches like Best-of-N
sampling require practically infeasible computation to achieve optimal
alignment. We propose STARS: Segment-level Token Alignment with Rejection
Sampling, a decoding-time algorithm that steers model generation by iteratively
sampling, scoring, and rejecting/accepting short, fixed-size token segments.
This allows for early correction of the generation path, significantly
improving computational efficiency and boosting alignment quality. Across a
suite of six LLMs, we show that STARS outperforms Supervised Fine-Tuning (SFT)
by up to 14.9 percentage points and Direct Preference Optimization (DPO) by up
to 4.3 percentage points on win-rates, while remaining highly competitive with
strong Best-of-N baselines. Our work establishes granular, reward-guided
sampling as a generalizable, robust, and efficient alternative to traditional
fine-tuning and full-sequence ranking methods for aligning LLMs.

</details>


### [102] [Evaluating Machine Translation Datasets for Low-Web Data Languages: A Gendered Lens](https://arxiv.org/abs/2511.03880)
*Hellina Hailu Nigatu,Bethelhem Yemane Mamo,Bontu Fufa Balcha,Debora Taye Tesfaye,Elbethel Daniel Zewdie,Ikram Behiru Nesiru,Jitu Ewnetu Hailu,Senait Mengesha Yayo*

Main category: cs.CL

TL;DR: 本文研究了低资源语言（阿凡奥罗莫语、阿姆哈拉语和提格雷尼亚语）机器翻译数据集的质量，特别关注性别表示。发现训练数据和基准测试数据领域不匹配，存在严重的男性性别偏向，以及针对女性的有害和有毒描绘，尤其是在数据量最大的语言中，强调了数量不等于质量。


<details>
  <summary>Details</summary>
Motivation: 随着低资源语言越来越多地被纳入自然语言处理研究，人们强调收集大规模数据集。然而，优先考虑数量而非质量，可能导致为这些语言构建的语言技术表现不佳，并产生延续社会偏见的有害内容。

Method: 本文调查了三种低资源语言（阿凡奥罗莫语、阿姆哈拉语和提格雷尼亚语）的机器翻译数据集质量，重点关注数据集中的性别表示。

Result: 研究发现训练数据主要包含政治和宗教领域文本，而基准测试数据集则侧重于新闻、健康和体育。同时，数据集中存在严重的男性性别偏向，体现在人名、动词的语法性别和刻板印象描绘中。此外，还发现了针对女性的有害和有毒描绘，在数据量最大的语言中尤为突出，这表明数量并不能保证质量。

Conclusion: 本研究表明，低资源语言数据集存在严重的质量问题，包括领域不匹配和有害的性别偏见，尤其是在数据量大的情况下。这强调了在收集低资源语言数据集时，需要重视质量并及早缓解有害内容，以避免构建表现不佳或具有偏见的语言技术。

Abstract: As low-resourced languages are increasingly incorporated into NLP research,
there is an emphasis on collecting large-scale datasets. But in prioritizing
quantity over quality, we risk 1) building language technologies that perform
poorly for these languages and 2) producing harmful content that perpetuates
societal biases. In this paper, we investigate the quality of Machine
Translation (MT) datasets for three low-resourced languages--Afan Oromo,
Amharic, and Tigrinya, with a focus on the gender representation in the
datasets. Our findings demonstrate that while training data has a large
representation of political and religious domain text, benchmark datasets are
focused on news, health, and sports. We also found a large skew towards the
male gender--in names of persons, the grammatical gender of verbs, and in
stereotypical depictions in the datasets. Further, we found harmful and toxic
depictions against women, which were more prominent for the language with the
largest amount of data, underscoring that quantity does not guarantee quality.
We hope that our work inspires further inquiry into the datasets collected for
low-resourced languages and prompts early mitigation of harmful content.
WARNING: This paper contains discussion of NSFW content that some may find
disturbing.

</details>


### [103] [GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation](https://arxiv.org/abs/2511.03900)
*Manh Nguyen,Sunil Gupta,Dai Do,Hung Le*

Main category: cs.CL

TL;DR: 本文提出了一种名为GRAD的解码时方法，通过构建稀疏令牌转换图并自适应地融合模型与语料库检索到的证据，有效减轻大型语言模型（LLM）的幻觉，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的幻觉问题持续存在，现有方法依赖外部知识源（如数据库或知识图谱），但基于提示的接地脆弱且对领域敏感，而符号知识集成则检索和格式化成本高昂。

Method: GRAD（Graph-Retrieved Adaptive Decoding）是一种解码时方法。它通过在单个前向传递中，从少量检索到的语料库中累积下一个令牌的对数，构建一个稀疏的令牌转换图。在解码过程中，检索到的图对数经过最大归一化处理，并与模型对数自适应融合，以偏向高证据的延续，同时保持流畅性。

Result: GRAD在三种模型和一系列问答基准测试（涵盖内在、外在幻觉和事实性任务）中持续超越基线，相比贪婪解码，内在准确率提高高达9.7%，幻觉率降低8.6%，正确性提高6.9%，并实现了所有方法中最高的真实性-信息量乘积得分。

Conclusion: GRAD提供了一种轻量级、即插即用的替代方案，可替代对比解码和知识图谱增强，表明语料库级别的令牌转换统计证据可以有效地引导生成更真实和可验证的输出。

Abstract: Hallucination mitigation remains a persistent challenge for large language
models (LLMs), even as model scales grow. Existing approaches often rely on
external knowledge sources, such as structured databases or knowledge graphs,
accessed through prompting or retrieval. However, prompt-based grounding is
fragile and domain-sensitive, while symbolic knowledge integration incurs heavy
retrieval and formatting costs. Motivated by knowledge graphs, we introduce
Graph-Retrieved Adaptive Decoding (GRAD), a decoding-time method that grounds
generation in corpus-derived evidence without retraining. GRAD constructs a
sparse token transition graph by accumulating next-token logits across a small
retrieved corpus in a single forward pass. During decoding, graph-retrieved
logits are max-normalized and adaptively fused with model logits to favor
high-evidence continuations while preserving fluency. Across three models and a
range of question-answering benchmarks spanning intrinsic, extrinsic
hallucination, and factuality tasks, GRAD consistently surpasses baselines,
achieving up to 9.7$\%$ higher intrinsic accuracy, 8.6$\%$ lower hallucination
rates, and 6.9$\%$ greater correctness compared to greedy decoding, while
attaining the highest truth--informativeness product score among all methods.
GRAD offers a lightweight, plug-and-play alternative to contrastive decoding
and knowledge graph augmentation, demonstrating that statistical evidence from
corpus-level token transitions can effectively steer generation toward more
truthful and verifiable outputs.

</details>


### [104] [Context informs pragmatic interpretation in vision-language models](https://arxiv.org/abs/2511.03908)
*Alvin Wei Ming Tan,Ben Prystawski,Veronica Boyce,Michael C. Frank*

Main category: cs.CL

TL;DR: 本文通过迭代指代游戏测试了人类和视觉语言模型在多轮语言环境中进行语境敏感语用推理的能力，发现模型在提供相关语境后性能显著提升，但对抽象指代物的少样本游戏仍感困难。


<details>
  <summary>Details</summary>
Motivation: 迭代指代游戏（玩家反复用语言选择新指代物）是测试智能体在多轮语言环境中进行语境敏感语用推理能力的一个关键案例。

Method: 研究人员让人类和视觉语言模型参与迭代指代游戏，并改变了给定语境的数量、顺序和相关性。

Result: 在没有相关语境的情况下，模型的表现高于随机水平但远低于人类。然而，在提供相关语境后，模型的性能在试验中显著提升。对于机器学习模型而言，涉及抽象指代物的少样本指代游戏仍然是一项艰巨的任务。

Conclusion: 视觉语言模型能够从相关语境中学习以提高在迭代指代游戏中的表现，但处理抽象指代物和少样本学习场景仍是其主要挑战。

Abstract: Iterated reference games - in which players repeatedly pick out novel
referents using language - present a test case for agents' ability to perform
context-sensitive pragmatic reasoning in multi-turn linguistic environments. We
tested humans and vision-language models on trials from iterated reference
games, varying the given context in terms of amount, order, and relevance.
Without relevant context, models were above chance but substantially worse than
humans. However, with relevant context, model performance increased
dramatically over trials. Few-shot reference games with abstract referents
remain a difficult task for machine learning models.

</details>


### [105] [The Human Flourishing Geographic Index: A County-Level Dataset for the United States, 2013--2023](https://arxiv.org/abs/2511.03915)
*Stefano M. Iacus,Devika Jain,Andrea Nasuto,Giuseppe Porro,Marcello Carammia,Andrea Vezzulli*

Main category: cs.CL

TL;DR: 本文引入了人类繁荣地理指数（HFGI），通过分析26亿条美国推文并使用大型语言模型，创建了一个具有高时空分辨率（县/州，月/年）的48项人类繁荣指标数据集。


<details>
  <summary>Details</summary>
Motivation: 量化人类繁荣（包括幸福、健康、目标、美德、人际关系和财务稳定等）对于理解超越经济指标的社会福祉至关重要。现有的衡量方法通常缺乏精细的空间和时间分辨率。

Method: 该研究分析了约26亿条2013-2023年间带有地理位置信息的美国推文，使用经过微调的大型语言模型对推文中的表达进行分类，涵盖了与哈佛全球繁荣研究框架对齐的48个指标，并额外加入了对移民的态度和对腐败的感知。

Result: 研究引入了人类繁荣地理指数（HFGI）。该数据集提供了月度和年度的县级和州级繁荣相关话语指标。这些指标经过验证，能够准确代表其底层结构，并与既有指标显示出预期的相关性。

Conclusion: 这一资源以空前的分辨率支持对福祉、不平等和社会变化进行多学科分析，通过过去十年美国社交媒体话语反映的人类繁荣动态，提供了深入的见解。

Abstract: Quantifying human flourishing, a multidimensional construct including
happiness, health, purpose, virtue, relationships, and financial stability, is
critical for understanding societal well-being beyond economic indicators.
Existing measures often lack fine spatial and temporal resolution. Here we
introduce the Human Flourishing Geographic Index (HFGI), derived from analyzing
approximately 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned
large language models to classify expressions across 48 indicators aligned with
Harvard's Global Flourishing Study framework plus attitudes towards migration
and perception of corruption. The dataset offers monthly and yearly county- and
state-level indicators of flourishing-related discourse, validated to confirm
that the measures accurately represent the underlying constructs and show
expected correlations with established indicators. This resource enables
multidisciplinary analyses of well-being, inequality, and social change at
unprecedented resolution, offering insights into the dynamics of human
flourishing as reflected in social media discourse across the United States
over the past decade.

</details>


### [106] [Direct Semantic Communication Between Large Language Models via Vector Translation](https://arxiv.org/abs/2511.03945)
*Fu-Chun Yang,Jason Eshraghian*

Main category: cs.CL

TL;DR: 在多智能体LLM中，模型间通过向量翻译实现潜在语义的直接交换，而非传统令牌传递。研究证明了这种跨模型潜在通信的可行性，并发现通用模型比指令微调模型产生更可迁移的表示。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体LLM通过纯令牌传递信息，忽略了大部分潜在语义，限制了信息传输效率并增加了计算开销。

Method: 通过训练一个双编码器翻译器，在不同LLM（如Llama-2-7B和Mistral-7B-Instruct）的表示空间之间建立学习映射，实现向量翻译。将翻译后的向量以30%的混合强度注入目标模型的生成过程。

Result: 双编码器翻译器实现了0.538的平均余弦对齐。以30%的混合强度注入翻译向量，可以在不破坏logits稳定性的前提下引导目标模型的生成。双向评估显示出2.01:1的迁移不对称性，表明通用模型比指令微调模型产生更可迁移的表示。

Conclusion: 研究证明了跨模型潜在通信是可行的，并且在计算上保持稳定，这使得协作AI系统能够直接共享意义而非仅仅令牌。

Abstract: In multi-agent settings, such as debate, reflection, or tool-calling, large
language models (LLMs) pass messages as plain tokens, discarding most latent
semantics. This constrains information transfer and adds unnecessary
computational overhead. We form a latent bridge via vector translations, which
use learned mappings that enable direct semantic exchange between
representation spaces. A dual-encoder translator trained between Llama-2-7B and
Mistral-7B-Instruct attains an average cosine alignment of 0.538. Injecting the
translated vectors at 30 percent blending strength steers the target model's
generation without destabilizing logits. Bidirectional evaluation shows a
2.01:1 transfer asymmetry, indicating that general-purpose models yield more
transferable representations than instruction-tuned variants. This conservative
injection preserves computational stability while demonstrating that
cross-model latent communication is feasible, enabling collaborative AI systems
that share meaning rather than tokens.

</details>


### [107] [Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises](https://arxiv.org/abs/2511.04020)
*Shiyin Lin*

Main category: cs.CL

TL;DR: 本文提出一个将溯因推理整合到检索增强型大型语言模型（RAG）中的框架，以解决检索证据不完整导致推理中断的问题。该方法通过生成和验证缺失的前提来弥补知识空白，从而提高了答案准确性和推理忠实度。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）系统在知识密集型任务中表现出色，但当检索到的证据不完整时，其推理过程会产生空白并导致失败。溯因推理（生成合理解释观察结果的缺失前提）提供了一种弥补这些空白的原则性方法。

Method: 该研究提出一个将溯因推理整合到检索增强型大型语言模型中的框架。具体方法包括：检测证据不足、生成候选缺失前提，并通过一致性和合理性检查来验证这些前提。

Result: 在溯因推理和多跳问答基准测试上的实验结果表明，该方法显著提高了答案的准确性以及推理的忠实度。

Conclusion: 这项工作强调了溯因推理是增强RAG系统鲁棒性和可解释性的一个有前景的方向。

Abstract: Large Language Models (LLMs) enhanced with retrieval -- commonly referred to
as Retrieval-Augmented Generation (RAG) -- have demonstrated strong performance
in knowledge-intensive tasks. However, RAG pipelines often fail when retrieved
evidence is incomplete, leaving gaps in the reasoning process. In such cases,
\emph{abductive inference} -- the process of generating plausible missing
premises to explain observations -- offers a principled approach to bridge
these gaps. In this paper, we propose a framework that integrates abductive
inference into retrieval-augmented LLMs. Our method detects insufficient
evidence, generates candidate missing premises, and validates them through
consistency and plausibility checks. Experimental results on abductive
reasoning and multi-hop QA benchmarks show that our approach improves both
answer accuracy and reasoning faithfulness. This work highlights abductive
inference as a promising direction for enhancing the robustness and
explainability of RAG systems.

</details>


### [108] [WST: Weakly Supervised Transducer for Automatic Speech Recognition](https://arxiv.org/abs/2511.04035)
*Dongji Gao,Chenda Liao,Changliang Liu,Matthew Wiesner,Leibny Paola Garcia,Daniel Povey,Sanjeev Khudanpur,Jian Wu*

Main category: cs.CL

TL;DR: 本文提出一种弱监督Transducer (WST)，通过灵活的训练图有效处理转录错误，在高达70%的错误率下仍能保持高性能，优于现有弱监督方法，解决了RNN-T对大量高质量标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: RNN-T在端到端自动语音识别 (ASR) 中广泛应用，但其性能严重依赖于昂贵且难以获取的大规模高质量标注数据。

Method: 提出弱监督Transducer (WST)，该方法集成了一个灵活的训练图，旨在鲁棒地处理转录中的错误，且无需额外的置信度估计或辅助预训练模型。

Result: 在合成和工业数据集上的评估表明，WST在转录错误率高达70%的情况下仍能有效保持性能。它持续优于现有的基于CTC的弱监督方法，如Bypass Temporal Classification (BTC) 和 Omni-Temporal Classification (OTC)。

Conclusion: WST在实际ASR设置中展现出实用性和鲁棒性，有效缓解了对大量高质量标注数据的依赖。

Abstract: The Recurrent Neural Network-Transducer (RNN-T) is widely adopted in
end-to-end (E2E) automatic speech recognition (ASR) tasks but depends heavily
on large-scale, high-quality annotated data, which are often costly and
difficult to obtain. To mitigate this reliance, we propose a Weakly Supervised
Transducer (WST), which integrates a flexible training graph designed to
robustly handle errors in the transcripts without requiring additional
confidence estimation or auxiliary pre-trained models. Empirical evaluations on
synthetic and industrial datasets reveal that WST effectively maintains
performance even with transcription error rates of up to 70%, consistently
outperforming existing Connectionist Temporal Classification (CTC)-based weakly
supervised approaches, such as Bypass Temporal Classification (BTC) and
Omni-Temporal Classification (OTC). These results demonstrate the practical
utility and robustness of WST in realistic ASR settings. The implementation
will be publicly available.

</details>


### [109] [T-FIX: Text-Based Explanations with Features Interpretable to eXperts](https://arxiv.org/abs/2511.04070)
*Shreya Havaldar,Helen Jin,Chaehyeon Kim,Anton Xue,Weiqiu You,Marco Gatti,Bhuvnesh Jain,Helen Qu,Daniel A Hashimoto,Amin Madani,Rajat Deo,Sameed Ahmed M. Khatana,Gary E. Weissman,Lyle Ungar,Eric Wong*

Main category: cs.CL

TL;DR: 在知识密集型领域，大型语言模型（LLM）的解释需要与专家直觉对齐。本文提出了T-FIX基准和新指标，用于衡量LLM解释与专家判断的对齐程度。


<details>
  <summary>Details</summary>
Motivation: 当LLM应用于手术、天文学、治疗等知识密集型场景时，用户（通常是领域专家）期望LLM不仅提供答案，还能提供有意义且符合专家级推理的解释。然而，当前评估方案主要关注解释的合理性或内部忠实度，未能捕捉解释内容是否真正符合专家直觉。

Method: 本文将“专家对齐”正式化为评估解释的标准，并开发了T-FIX基准，该基准涵盖七个知识密集型领域。研究与领域专家合作，开发了衡量LLM解释与专家判断对齐程度的新指标。

Result: 提出了T-FIX基准以及一套新颖的度量指标，用于评估LLM解释与领域专家判断的对齐程度。

Conclusion: 通过T-FIX基准和新的度量指标，可以更有效地评估LLM在知识密集型环境中解释的专家对齐性，从而确保其解释能够满足领域专家的需求。

Abstract: As LLMs are deployed in knowledge-intensive settings (e.g., surgery,
astronomy, therapy), users expect not just answers, but also meaningful
explanations for those answers. In these settings, users are often domain
experts (e.g., doctors, astrophysicists, psychologists) who require
explanations that reflect expert-level reasoning. However, current evaluation
schemes primarily emphasize plausibility or internal faithfulness of the
explanation, which fail to capture whether the content of the explanation truly
aligns with expert intuition. We formalize expert alignment as a criterion for
evaluating explanations with T-FIX, a benchmark spanning seven
knowledge-intensive domains. In collaboration with domain experts, we develop
novel metrics to measure the alignment of LLM explanations with expert
judgment.

</details>


### [110] [Plan of Knowledge: Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04072)
*Xinying Qian,Ying Zhang,Yu Zhao,Baohang Zhou,Xuhui Sui,Xiaojie Yuan*

Main category: cs.CL

TL;DR: 该研究提出了PoK框架，通过结合结构化规划和对比时间知识检索，显著提升了大型语言模型（LLMs）在时间知识图谱问答（TKGQA）中的时间推理能力、事实一致性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有TKGQA方法未能充分理解时间约束的复杂语义信息。尽管LLMs具有强大的语义理解和推理能力，但其时间推理能力有限，常出现幻觉和知识缺乏问题。

Method: 本文提出了名为PoK的“知识规划”（Plan of Knowledge）框架，包含两个核心模块：1) 知识规划模块：将复杂的时间问题分解为一系列预定义工具的子目标，作为推理探索的中间指导。2) 时间知识存储（TKS）模块：构建一个带有对比检索框架的TKS，使模型能够从时间知识图谱中选择性地检索语义和时间对齐的事实。PoK通过结合结构化规划和时间知识检索来增强时间推理。

Result: PoK有效提升了时间推理的可解释性和事实一致性。在四个基准TKGQA数据集上的广泛实验表明，PoK显著提高了LLMs的检索精度和推理准确性，性能最多超越了现有最先进的TKGQA方法56.0%。

Conclusion: PoK框架通过结合结构化规划和对比时间知识检索，成功解决了LLMs在TKGQA中时间推理能力不足、幻觉和知识缺乏的问题，显著提升了模型性能、可解释性和事实一致性。

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) aims to answer
time-sensitive questions by leveraging factual information from Temporal
Knowledge Graphs (TKGs). While previous studies have employed pre-trained TKG
embeddings or graph neural networks to inject temporal knowledge, they fail to
fully understand the complex semantic information of time constraints.
Recently, Large Language Models (LLMs) have shown remarkable progress,
benefiting from their strong semantic understanding and reasoning
generalization capabilities. However, their temporal reasoning ability remains
limited. LLMs frequently suffer from hallucination and a lack of knowledge. To
address these limitations, we propose the Plan of Knowledge framework with a
contrastive temporal retriever, which is named PoK. Specifically, the proposed
Plan of Knowledge module decomposes a complex temporal question into a sequence
of sub-objectives from the pre-defined tools, serving as intermediate guidance
for reasoning exploration. In parallel, we construct a Temporal Knowledge Store
(TKS) with a contrastive retrieval framework, enabling the model to selectively
retrieve semantically and temporally aligned facts from TKGs. By combining
structured planning with temporal knowledge retrieval, PoK effectively enhances
the interpretability and factual consistency of temporal reasoning. Extensive
experiments on four benchmark TKGQA datasets demonstrate that PoK significantly
improves the retrieval precision and reasoning accuracy of LLMs, surpassing the
performance of the state-of-the-art TKGQA methods by 56.0% at most.

</details>


### [111] [The truth is no diaper: Human and AI-generated associations to emotional words](https://arxiv.org/abs/2511.04077)
*Špela Vintar,Jan Jona Javoršek*

Main category: cs.CL

TL;DR: 该研究比较了人类与大型语言模型（LLM）的词语联想行为，发现LLM与人类联想有中等程度重叠，但LLM倾向于放大情感负荷，且更可预测、缺乏创造性。


<details>
  <summary>Details</summary>
Motivation: 词语联想是了解人类心智词典的重要方法，但人类联想受个人因素影响且难以预测。本研究旨在探究大型语言模型（LLM）是否能像人类一样进行联想，特别是对带有情感负荷的词语的联想，并考察LLM联想与创造力的关系。

Method: 通过比较人类和大型语言模型（LLM）对词语（特别是情感词）的联想行为来执行。

Result: 人类与LLM的联想重叠度适中。LLM的联想倾向于放大刺激词语的潜在情感负荷，并且比人类的联想更可预测、更缺乏创造性。

Conclusion: 尽管与人类联想有中等程度的重叠，大型语言模型在词语联想方面表现出与人类不同的特征，尤其是在情感放大、可预测性和创造性方面。

Abstract: Human word associations are a well-known method of gaining insight into the
internal mental lexicon, but the responses spontaneously offered by human
participants to word cues are not always predictable as they may be influenced
by personal experience, emotions or individual cognitive styles. The ability to
form associative links between seemingly unrelated concepts can be the driving
mechanisms of creativity. We perform a comparison of the associative behaviour
of humans compared to large language models. More specifically, we explore
associations to emotionally loaded words and try to determine whether large
language models generate associations in a similar way to humans. We find that
the overlap between humans and LLMs is moderate, but also that the associations
of LLMs tend to amplify the underlying emotional load of the stimulus, and that
they tend to be more predictable and less creative than human ones.

</details>


### [112] [Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods](https://arxiv.org/abs/2511.04079)
*Eva Prakash,Maayane Attias,Pierre Chambon,Justin Xu,Steven Truong,Jean-Benoit Delbrouck,Tessa Cook,Curtis Langlotz*

Main category: cs.CL

TL;DR: 本研究通过大规模多模态训练，显著提升了基于Transformer的放射学报告去识别模型性能，并在PHI检测方面超越了现有学术和商业系统，建立了新的基准。


<details>
  <summary>Details</summary>
Motivation: 旨在通过扩展训练数据集和基准测试商业云系统，增强放射学报告的自动化去识别能力，以更好地检测受保护健康信息（PHI）。

Method: 本回顾性研究在现有基于Transformer的PHI去识别管道基础上，利用斯坦福大学的两个大型放射学报告标注语料库（涵盖胸部X光、胸部CT、腹部/盆腔CT和脑部MR报告）进行微调，并引入了额外的PHI类别（AGE）。模型性能在斯坦福和宾夕法尼亚大学的测试集上进行评估，并进一步评估了“隐匿”方法合成PHI的稳定性以及与商业系统的性能对比。计算了所有PHI类别的精确率、召回率和F1分数。

Result: 模型在宾夕法尼亚大学数据集上实现了0.973的总F1分数，在斯坦福数据集上实现了0.996的总F1分数，超越或保持了先前最先进模型的性能。合成PHI评估显示，在50个独立去识别的宾夕法尼亚大学数据集上，检测一致性良好（总F1：0.959 [0.958-0.960]）。模型在合成宾夕法尼亚大学报告上超越了所有商业系统（总F1：0.960 vs. 0.632-0.754）。

Conclusion: 基于Transformer且在多样化放射学数据集上训练的去识别模型在PHI检测方面优于先前的学术和商业系统，并为安全的临床文本处理建立了新的基准。

Abstract: Objective: To enhance automated de-identification of radiology reports by
scaling transformer-based models through extensive training datasets and
benchmarking performance against commercial cloud vendor systems for protected
health information (PHI) detection. Materials and Methods: In this
retrospective study, we built upon a state-of-the-art, transformer-based, PHI
de-identification pipeline by fine-tuning on two large annotated radiology
corpora from Stanford University, encompassing chest X-ray, chest CT,
abdomen/pelvis CT, and brain MR reports and introducing an additional PHI
category (AGE) into the architecture. Model performance was evaluated on test
sets from Stanford and the University of Pennsylvania (Penn) for token-level
PHI detection. We further assessed (1) the stability of synthetic PHI
generation using a "hide-in-plain-sight" method and (2) performance against
commercial systems. Precision, recall, and F1 scores were computed across all
PHI categories. Results: Our model achieved overall F1 scores of 0.973 on the
Penn dataset and 0.996 on the Stanford dataset, outperforming or maintaining
the previous state-of-the-art model performance. Synthetic PHI evaluation
showed consistent detectability (overall F1: 0.959 [0.958-0.960]) across 50
independently de-identified Penn datasets. Our model outperformed all vendor
systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754).
Discussion: Large-scale, multimodal training improved cross-institutional
generalization and robustness. Synthetic PHI generation preserved data utility
while ensuring privacy. Conclusion: A transformer-based de-identification model
trained on diverse radiology datasets outperforms prior academic and commercial
systems in PHI detection and establishes a new benchmark for secure clinical
text processing.

</details>


### [113] [A Characterization of List Language Identification in the Limit](https://arxiv.org/abs/2511.04103)
*Moses Charikar,Chirag Pabbaraju,Ambuj Tewari*

Main category: cs.CL

TL;DR: 本文重新审视了极限语言识别问题，引入了每次猜测k个列表的机制，并给出了可k-列表识别的语言集合的精确刻画，发现其等价于将集合分解为k个可识别的子集合。在统计设置下，可k-列表识别的集合能以指数速率识别。


<details>
  <summary>Details</summary>
Motivation: Gold的经典结果表明，几乎所有有趣的语言集合都无法在极限中进行语言识别。Angluin后来给出了可识别语言集合的精确特征。受最近语言生成相关问题积极结果的启发，本文在学习器可以输出k个猜测列表的设定下，重新审视了经典的语言识别问题。

Method: 本文基于Angluin特征的递归版本，给出了可在极限中进行k-列表识别的语言集合的精确特征。在此基础上，进一步推导出一个概念上吸引人的特征：一个语言集合可在极限中进行k-列表识别，当且仅当该集合可以分解为k个语言集合，每个子集合都可以在极限中被识别（列表大小为1）。此外，本文还将此特征应用于统计设置，其中输入是来自集合中某种语言的独立同分布流。

Result: 研究结果表明，一个语言集合可在极限中进行k-列表识别，当且仅当该集合可以分解为k个可在极限中识别的语言集合。在统计设置下，如果一个集合可在极限中进行k-列表识别，那么它能以指数速率进行k-列表识别，且这是最优的。反之，如果一个集合不能在极限中进行k-列表识别，那么它不能以任何趋于零的速率进行k-列表识别。

Conclusion: 本文为可在极限中进行k-列表识别的语言集合提供了精确的特征，并揭示了其与将集合分解为k个可识别子集合的等价性。同时，在统计设置下，证明了可k-列表识别的集合能够以最优的指数速率进行识别，而不可识别的集合则无法以任何趋零的速率识别。

Abstract: We study the problem of language identification in the limit, where given a
sequence of examples from a target language, the goal of the learner is to
output a sequence of guesses for the target language such that all the guesses
beyond some finite time are correct. Classical results of Gold showed that
language identification in the limit is impossible for essentially any
interesting collection of languages. Later, Angluin gave a precise
characterization of language collections for which this task is possible.
Motivated by recent positive results for the related problem of language
generation, we revisit the classic language identification problem in the
setting where the learner is given the additional power of producing a list of
$k$ guesses at each time step. The goal is to ensure that beyond some finite
time, one of the guesses is correct at each time step.
  We give an exact characterization of collections of languages that can be
$k$-list identified in the limit, based on a recursive version of Angluin's
characterization (for language identification with a list of size $1$). This
further leads to a conceptually appealing characterization: A language
collection can be $k$-list identified in the limit if and only if the
collection can be decomposed into $k$ collections of languages, each of which
can be identified in the limit (with a list of size $1$). We also use our
characterization to establish rates for list identification in the statistical
setting where the input is drawn as an i.i.d. stream from a distribution
supported on some language in the collection. Our results show that if a
collection is $k$-list identifiable in the limit, then the collection can be
$k$-list identified at an exponential rate, and this is best possible. On the
other hand, if a collection is not $k$-list identifiable in the limit, then it
cannot be $k$-list identified at any rate that goes to zero.

</details>


### [114] [Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models](https://arxiv.org/abs/2511.04108)
*Wenmo Qiu,Saurabh Srivastava*

Main category: cs.CL

TL;DR: 本文发现，对大型语言模型（LLMs）进行批处理不仅能分摊推理成本，还能在多步推理中作为正则化器，显著提高推理准确性并减少token使用，同时抑制过度思考和犹豫语言。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要关注批处理在LLMs中分摊推理成本的优势。本文旨在探索批处理的另一个被低估的益处：在多步推理中正则化模型行为。

Method: 研究在13个不同基准测试上进行了全面研究，并进行了详细的行为分析。

Result: 批处理提高了推理准确性，同时大幅减少了推理token使用（通常为3-5倍）。行为分析发现，批处理抑制了过度思考，减少了犹豫语言（如重复的自我修正），并鼓励更果断的回答。此外，还观察到批处理推理中出现了集体效应：模型能够从批次中较早的例子中泛化模式，以解决批次中较难的问题。

Conclusion: 批处理不仅是一种吞吐量优化策略，更是一种强大的推理时正则化器，能够使LLM的推理更高效、更可靠。

Abstract: Recent work has explored batch prompting as a strategy to amortize inference
cost in large language models (LLMs). In this paper, we show that batching
offers an additional, underappreciated benefit: it regularizes model behavior
during multi-step reasoning for Large Reasoning Models (LRMs). We conduct a
comprehensive study across 13 diverse benchmarks and observe that batching
improves accuracy while substantially reducing reasoning token usage, often by
3x-5x. Through detailed behavioral analysis, we find that batching suppresses
overthinking, reduces hedging language (e.g., repetitive self-corrections), and
encourages more decisive answers. Surprisingly, we also observe emergent
collective effects in batched inference: models often generalize patterns from
earlier examples to solve harder ones in the same batch. These findings
position batching not just as a throughput optimization, but as a powerful
inference-time regularizer for more efficient and reliable LLM reasoning.

</details>


### [115] [RIDE: Difficulty Evolving Perturbation with Item Response Theory for Mathematical Reasoning](https://arxiv.org/abs/2511.04120)
*Xinyuan Li,Murong Xu,Wenbiao Tao,Hanlun Zhu,Yike Zhao,Jipeng Zhang,Yunshi Lan*

Main category: cs.CL

TL;DR: 本文提出RIDE框架，利用项目反应理论（IRT）和强化学习，生成更具挑战性且结构良好的数学问题，以对抗性评估大型语言模型（LLM）真实的数学推理能力，揭示了LLM在此方面的鲁棒性不足。


<details>
  <summary>Details</summary>
Motivation: LLM在数学推理上的高表现可能因训练数据泄露或表面模式匹配而虚高，而非真正的推理能力。现有基于规则的扰动方法常生成不适定问题，阻碍了系统性评估问题难度和基准演进，因此需要一种更严谨的方法来衡量真实数学推理能力。

Method: 本文提出了RIDE框架，一个新颖的对抗性问题重写框架。它利用项目反应理论（IRT）来严格衡量问题难度，并生成内在更具挑战性、结构良好的数学问题变体。通过使用35个LLM模拟学生并根据其响应构建一个难度排序器，该排序器作为强化学习的奖励信号，指导问题重写模型在不同难度级别上重构现有问题。

Result: 将RIDE应用于竞赛级别的数学基准测试，生成了扰动版本，导致先进LLM的性能下降。实验显示，26个模型平均性能下降21.73%。

Conclusion: RIDE生成的扰动问题暴露了LLM在数学推理方面有限的鲁棒性，并证实了本文评估方法的有效性，即能够更准确地衡量LLM的真实数学推理能力。

Abstract: Large language models (LLMs) achieve high performance on mathematical
reasoning, but these results can be inflated by training data leakage or
superficial pattern matching rather than genuine reasoning. To this end, an
adversarial perturbation-based evaluation is needed to measure true
mathematical reasoning ability. Current rule-based perturbation methods often
generate ill-posed questions and impede the systematic evaluation of question
difficulty and the evolution of benchmarks. To bridge this gap, we propose
RIDE, a novel adversarial question-rewriting framework that leverages Item
Response Theory (IRT) to rigorously measure question difficulty and to generate
intrinsically more challenging, well-posed variations of mathematical problems.
We employ 35 LLMs to simulate students and build a difficulty ranker from their
responses. This ranker provides a reward signal during reinforcement learning
and guides a question-rewriting model to reformulate existing questions across
difficulty levels. Applying RIDE to competition-level mathematical benchmarks
yields perturbed versions that degrade advanced LLM performance, with
experiments showing an average 21.73% drop across 26 models, thereby exposing
limited robustness in mathematical reasoning and confirming the validity of our
evaluation approach.

</details>


### [116] [CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource Cantonese](https://arxiv.org/abs/2511.04139)
*Dazhong Chen,Yi-Cheng Lin,Yuchen Huang,Ziwei Gong,Di Jiang,Zeying Xie,Yi R.,Fung*

Main category: cs.CL

TL;DR: CantoASR是一个协同ASR-LALM错误纠正框架，它结合了强制对齐、LoRA微调的Whisper和指令微调的Qwen-Audio，以解决粤语低资源ASR的挑战，并在自发粤语数据上显著优于Whisper-Large-V3。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）对语言可及性至关重要，但由于标注数据有限、六个声调、变调和口音差异，低资源粤语ASR仍然具有挑战性。现有模型如Whisper的词错误率较高，而大型音频语言模型（LALM）虽能利用更广泛的上下文推理，但仍需要明确的声调和韵律声学线索。

Method: 本文引入了CantoASR，一个协同ASR-LALM错误纠正框架。它整合了用于声学特征提取的强制对齐、用于改善声调辨别的LoRA微调Whisper，以及用于韵律感知纠正的指令微调Qwen-Audio。

Result: 在自发粤语数据上的评估显示，CantoASR在字符错误率（CER）方面比Whisper-Large-V3有显著提升。

Conclusion: 研究结果表明，将声学线索与LALM推理相结合，为低资源声调和方言ASR提供了一种可扩展的策略。

Abstract: Automatic speech recognition (ASR) is critical for language accessibility,
yet low-resource Cantonese remains challenging due to limited annotated data,
six lexical tones, tone sandhi, and accent variation. Existing ASR models, such
as Whisper, often suffer from high word error rates. Large audio-language
models (LALMs), in contrast, can leverage broader contextual reasoning but
still require explicit tonal and prosodic acoustic cues. We introduce CantoASR,
a collaborative ASR-LALM error correction framework that integrates forced
alignment for acoustic feature extraction, a LoRA-finetuned Whisper for
improved tone discrimination, and an instruction-tuned Qwen-Audio for
prosody-aware correction. Evaluations on spontaneous Cantonese data show
substantial CER gains over Whisper-Large-V3. These findings suggest that
integrating acoustic cues with LALM reasoning provides a scalable strategy for
low-resource tonal and dialectal ASR.

</details>


### [117] [BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated Text-to-SQL Generation](https://arxiv.org/abs/2511.04153)
*Fahim Ahmed,Md Mubtasim Ahasan,Jahir Sadik Monon,Muntasir Wahed,M Ashraful Amin,A K M Mahbubur Rahman,Amin Ahsan Ali*

Main category: cs.CL

TL;DR: 本文探索了三种多智能体LLM管道，旨在提升Text-to-SQL系统性能，特别是针对小型开源模型，并通过系统基准测试发现“规划器-编码器”管道效果最佳，显著提高了SQL生成准确性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在Text-to-SQL任务中面临挑战，主要原因是大规模数据库模式和复杂的推理需求。此外，以往研究多集中于使用旗舰级模型构建复杂而不切实际的管道，而忽略了小型高效模型的潜力。

Method: 研究探索了三种多智能体LLM管道：1) 多智能体讨论管道，智能体迭代地评论和完善SQL查询，由一个判断器给出最终答案；2) 规划器-编码器管道，一个“思考”模型生成分步SQL生成计划，然后由一个编码器合成查询；3) 编码器-聚合器管道，多个编码器独立生成SQL查询，一个推理智能体选择最佳查询。这些管道在从小到大的开源模型范围内进行了系统性性能基准测试。

Result: 在Bird-Bench Mini-Dev数据集上的实验显示，多智能体讨论管道能提升小型模型性能，例如Qwen2.5-7b-Instruct在三轮讨论后执行准确率提高了10.6%。在所有管道中，“LLM推理器-编码器”管道表现最佳，其中DeepSeek-R1-32B和QwQ-32B规划器将Gemma 3 27B IT的准确率从52.4%提升至最高的56.4%。

Conclusion: 多智能体LLM管道能够有效提升Text-to-SQL系统的性能，特别是对于小型模型。其中，“规划器-编码器”管道展现出最佳效果，通过规划模型指导查询生成，显著提高了SQL的生成准确性，为数据库的自然语言访问提供了更可靠的解决方案。

Abstract: Text-to-SQL systems provide a natural language interface that can enable even
laymen to access information stored in databases. However, existing Large
Language Models (LLM) struggle with SQL generation from natural instructions
due to large schema sizes and complex reasoning. Prior work often focuses on
complex, somewhat impractical pipelines using flagship models, while smaller,
efficient models remain overlooked. In this work, we explore three multi-agent
LLM pipelines, with systematic performance benchmarking across a range of small
to large open-source models: (1) Multi-agent discussion pipeline, where agents
iteratively critique and refine SQL queries, and a judge synthesizes the final
answer; (2) Planner-Coder pipeline, where a thinking model planner generates
stepwise SQL generation plans and a coder synthesizes queries; and (3)
Coder-Aggregator pipeline, where multiple coders independently generate SQL
queries, and a reasoning agent selects the best query. Experiments on the
Bird-Bench Mini-Dev set reveal that Multi-Agent discussion can improve small
model performance, with up to 10.6% increase in Execution Accuracy for
Qwen2.5-7b-Instruct seen after three rounds of discussion. Among the pipelines,
the LLM Reasoner-Coder pipeline yields the best results, with DeepSeek-R1-32B
and QwQ-32B planners boosting Gemma 3 27B IT accuracy from 52.4% to the highest
score of 56.4%. Codes are available at
https://github.com/treeDweller98/bappa-sql.

</details>


### [118] [Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity in LLM as a Communicator (LAAC) Framework in Multiple Application Domains](https://arxiv.org/abs/2511.04184)
*Mohammed Musthafa Rafi,Adarsh Krishnamurthy,Aditya Balu*

Main category: cs.CL

TL;DR: 本文提出LAAC（将大型语言模型作为通信者）范式，旨在利用LLM作为智能通信中介，通过结构化对话捕获发送者意图，促进接收者之间的真实知识交流，并评估了其部署中的信任度需求和挑战。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成内容导致了一种荒谬的通信现象：发送者用LLM膨胀简单想法，接收者用LLM压缩内容，导致双方都无法接触到真实内容。这种现象促使研究者寻求一种能促进真实交流的解决方案。

Method: LAAC提出将LLM定位为智能通信中介，通过结构化对话捕获发送者意图。本文系统评估了LAAC部署的信任度要求，包括三个维度：(1) 信息捕获保真度——发送者意图提取的准确性；(2) 可复现性——结构化知识在多次交互中的一致性；(3) 查询响应完整性——接收者响应的可靠性（无幻觉、来源混淆或捏造）。通过跨多个LAAC用例的受控实验，评估了LAAC多智能体架构的这些信任维度。

Result: 初步研究结果揭示了可测量的信任差距，这些差距必须在LAAC可靠部署于高风险通信场景之前得到解决。

Conclusion: LAAC为实现真实通信提供了一种范式转变，但要将其作为可信的通信中介广泛部署，特别是在高风险场景中，必须解决信息保真度、一致性和可靠性方面的显著信任挑战。

Abstract: The proliferation of AI-generated content has created an absurd communication
theater where senders use LLMs to inflate simple ideas into verbose content,
recipients use LLMs to compress them back into summaries, and as a consequence
neither party engage with authentic content. LAAC (LLM as a Communicator)
proposes a paradigm shift - positioning LLMs as intelligent communication
intermediaries that capture the sender's intent through structured dialogue and
facilitate genuine knowledge exchange with recipients. Rather than perpetuating
cycles of AI-generated inflation and compression, LAAC enables authentic
communication across diverse contexts including academic papers, proposals,
professional emails, and cross-platform content generation. However, deploying
LLMs as trusted communication intermediaries raises critical questions about
information fidelity, consistency, and reliability. This position paper
systematically evaluates the trustworthiness requirements for LAAC's deployment
across multiple communication domains. We investigate three fundamental
dimensions: (1) Information Capture Fidelity - accuracy of intent extraction
during sender interviews across different communication types, (2)
Reproducibility - consistency of structured knowledge across multiple
interaction instances, and (3) Query Response Integrity - reliability of
recipient-facing responses without hallucination, source conflation, or
fabrication. Through controlled experiments spanning multiple LAAC use cases,
we assess these trust dimensions using LAAC's multi-agent architecture.
Preliminary findings reveal measurable trust gaps that must be addressed before
LAAC can be reliably deployed in high-stakes communication scenarios.

</details>


### [119] [Computational Turing Test Reveals Systematic Differences Between Human and AI Language](https://arxiv.org/abs/2511.04195)
*Nicolò Pagan,Petter Törnberg,Christopher A. Bail,Anikó Hannák,Christopher Barrie*

Main category: cs.CL

TL;DR: 该研究提出了一种计算图灵测试框架来评估大型语言模型（LLM）生成文本的真实性。结果显示，LLM输出与人类文本仍有明显区别，尤其在情感表达上，并且在追求人类相似性与语义忠实度之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: LLMs在社会科学中被广泛用于模拟人类行为，但其生成文本“人类般”的真实性这一核心假设尚未得到充分检验。现有验证方法依赖于不可靠的人类判断，导致缺乏评估LLM文本真实性和校准模型的鲁棒工具。

Method: 1. 引入计算图灵测试：一个结合聚合指标（基于BERT的可检测性、语义相似性）和可解释语言特征（文体标记、主题模式）的验证框架，用于评估LLM逼近人类语言的程度。2. 系统比较九个开源LLM：采用五种校准策略（包括微调、风格提示、上下文检索），基准测试它们在重现X（Twitter）、Bluesky和Reddit用户交互方面的能力。

Result: 1. LLM输出与人类文本仍有明显区别，尤其在情感基调和情绪表达方面。2. 指令微调模型表现不如其基础模型。3. 扩大模型规模并不能增强文本的人类相似性。4. 存在一个关键的权衡：优化人类相似性往往以牺牲语义忠实度为代价，反之亦然。

Conclusion: 该研究提供了一个急需的、可扩展的LLM模拟验证和校准框架。同时，对LLM目前在捕捉人类交流方面的局限性提出了警示。

Abstract: Large language models (LLMs) are increasingly used in the social sciences to
simulate human behavior, based on the assumption that they can generate
realistic, human-like text. Yet this assumption remains largely untested.
Existing validation efforts rely heavily on human-judgment-based evaluations --
testing whether humans can distinguish AI from human output -- despite evidence
that such judgments are blunt and unreliable. As a result, the field lacks
robust tools for assessing the realism of LLM-generated text or for calibrating
models to real-world data. This paper makes two contributions. First, we
introduce a computational Turing test: a validation framework that integrates
aggregate metrics (BERT-based detectability and semantic similarity) with
interpretable linguistic features (stylistic markers and topical patterns) to
assess how closely LLMs approximate human language within a given dataset.
Second, we systematically compare nine open-weight LLMs across five calibration
strategies -- including fine-tuning, stylistic prompting, and context retrieval
-- benchmarking their ability to reproduce user interactions on X (formerly
Twitter), Bluesky, and Reddit. Our findings challenge core assumptions in the
literature. Even after calibration, LLM outputs remain clearly distinguishable
from human text, particularly in affective tone and emotional expression.
Instruction-tuned models underperform their base counterparts, and scaling up
model size does not enhance human-likeness. Crucially, we identify a trade-off:
optimizing for human-likeness often comes at the cost of semantic fidelity, and
vice versa. These results provide a much-needed scalable framework for
validation and calibration in LLM simulations -- and offer a cautionary note
about their current limitations in capturing human communication.

</details>


### [120] [REMIND: Input Loss Landscapes Reveal Residual Memorization in Post-Unlearning LLMs](https://arxiv.org/abs/2511.04228)
*Liran Cohen,Yaniv Nemcovesky,Avi Mendelson*

Main category: cs.CL

TL;DR: REMIND是一种新型评估方法，通过分析模型在输入微小变化上的损失平坦度，检测机器学习遗忘中语义相似样本的残余影响，以更敏感地验证数据是否被有效遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习遗忘评估方法仅在单个输入层面评估，可能忽略语义相似示例中存在的残余影响，从而损害隐私并导致间接信息泄露。因此，需要更可靠的方法来验证模型是否真正遗忘了目标数据。

Method: 本文提出了REMIND（Residual Memorization In Neighborhood Dynamics）方法。它通过分析模型在小输入变化上的损失（即损失景观）来检测未学习数据的微妙残余影响。REMIND仅需要基于查询的访问，并通过观察损失景观的平坦度来区分已遗忘数据和未遗忘数据。

Result: 研究发现，被遗忘的数据会产生更平坦、不那么陡峭的损失景观，而保留或不相关的数据则表现出更尖锐、更波动的模式。REMIND在类似限制下优于现有方法，并对不同的模型、数据集和释义输入表现出鲁棒性，使其适用于实际部署。

Conclusion: REMIND为评估语言模型中的遗忘有效性提供了一个更敏感、可解释且可靠的框架，从而对记忆和遗忘提出了新的视角。

Abstract: Machine unlearning aims to remove the influence of specific training data
from a model without requiring full retraining. This capability is crucial for
ensuring privacy, safety, and regulatory compliance. Therefore, verifying
whether a model has truly forgotten target data is essential for maintaining
reliability and trustworthiness. However, existing evaluation methods often
assess forgetting at the level of individual inputs. This approach may overlook
residual influence present in semantically similar examples. Such influence can
compromise privacy and lead to indirect information leakage. We propose REMIND
(Residual Memorization In Neighborhood Dynamics), a novel evaluation method
aiming to detect the subtle remaining influence of unlearned data and classify
whether the data has been effectively forgotten. REMIND analyzes the model's
loss over small input variations and reveals patterns unnoticed by single-point
evaluations. We show that unlearned data yield flatter, less steep loss
landscapes, while retained or unrelated data exhibit sharper, more volatile
patterns. REMIND requires only query-based access, outperforms existing methods
under similar constraints, and demonstrates robustness across different models,
datasets, and paraphrased inputs, making it practical for real-world
deployment. By providing a more sensitive and interpretable measure of
unlearning effectiveness, REMIND provides a reliable framework to assess
unlearning in language models. As a result, REMIND offers a novel perspective
on memorization and unlearning.

</details>


### [121] [LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for the Member of the Polish National Board of Appeal](https://arxiv.org/abs/2511.04205)
*Michał Karp,Anna Kubaszewska,Magdalena Król,Robert Król,Aleksander Smywiński-Pohl,Mateusz Szymański,Witold Wydmański*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）在波兰国家上诉院官方资格考试中的表现，发现LLMs在选择题部分表现尚可，但在书面判决部分均未能通过，且“LLM作为评判者”的评估结果与官方委员会存在差异，表明当前LLMs尚不能替代人类法官。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在实证评估当前大型语言模型（LLMs）是否能通过波兰国家上诉院的官方资格考试，并探讨将LLMs作为实际考试候选人以及利用“LLM作为评判者”方法的可行性。

Method: 研究测试了包括GPT-4.1、Claude 4 Sonnet和Bielik-11B-v2.6在内的多种LLMs。考试结构包括公共采购法多项选择知识测试和书面判决。测试设置包括闭卷和多种检索增强生成（RAG）模式。同时，构建了混合信息检索和提取管道来支持模型。评估方法包括将LLM作为考生和使用其他模型自动评估LLM生成的答案（“LLM作为评判者”）。

Result: LLMs在知识测试中取得了令人满意的分数，但所有模型在实际书面判决部分均未达到及格线。此外，“LLM作为评判者”的评估结果经常与官方考试委员会的判断存在分歧。主要局限性包括：易受幻觉影响、法律条文引用不正确、逻辑论证薄弱。

Conclusion: 尽管技术进步迅速，但当前的大型语言模型尚不能在波兰公共采购裁决中取代人类法官或独立的审查员。研究强调了法律专家与技术团队之间密切合作的必要性。

Abstract: This study provides an empirical assessment of whether current large language
models (LLMs) can pass the official qualifying examination for membership in
Poland's National Appeal Chamber (Krajowa Izba Odwo{\l}awcza). The authors
examine two related ideas: using LLM as actual exam candidates and applying the
'LLM-as-a-judge' approach, in which model-generated answers are automatically
evaluated by other models. The paper describes the structure of the exam, which
includes a multiple-choice knowledge test on public procurement law and a
written judgment, and presents the hybrid information recovery and extraction
pipeline built to support the models. Several LLMs (including GPT-4.1, Claude 4
Sonnet and Bielik-11B-v2.6) were tested in closed-book and various
Retrieval-Augmented Generation settings. The results show that although the
models achieved satisfactory scores in the knowledge test, none met the passing
threshold in the practical written part, and the evaluations of the
'LLM-as-a-judge' often diverged from the judgments of the official examining
committee. The authors highlight key limitations: susceptibility to
hallucinations, incorrect citation of legal provisions, weaknesses in logical
argumentation, and the need for close collaboration between legal experts and
technical teams. The findings indicate that, despite rapid technological
progress, current LLMs cannot yet replace human judges or independent examiners
in Polish public procurement adjudication.

</details>


### [122] [Efficient Topic Extraction via Graph-Based Labeling: A Lightweight Alternative to Deep Models](https://arxiv.org/abs/2511.04248)
*Salma Mekaoui,Hiba Sofyan,Imane Amaaz,Imane Benchrif,Arsalane Zarghili,Ilham Chaker,Nikola S. Nikolov*

Main category: cs.CL

TL;DR: 本文提出了一种图基方法，通过丰富主题词并探索其关系来为主题模型生成的主题词分配有意义的标签，从而提高主题的可解释性，同时保持计算效率，并取得了优于传统基准和与ChatGPT-3.5相当的结果。


<details>
  <summary>Details</summary>
Motivation: 随着非结构化文本数据快速增长，主题提取变得至关重要。现有方法通常计算成本高昂。虽然概率统计方法（如主题建模）计算效率更高，但它们生成的主题是词汇分布，缺乏清晰的可解释性。研究目标是为这些词汇集合分配有意义的标签，且不依赖计算密集型模型。

Method: 提出了一种图基方法。该方法不仅用语义相关的词汇丰富主题词，还探索这些词汇之间的关系。通过分析图中的连接，从而推导出能准确捕捉每个主题含义的标签。

Result: 在两个不同数据集上的比较研究表明，所提出的方法在BERTScore和余弦相似度方面始终优于传统基准，并取得了与ChatGPT-3.5相当的结果，同时保持了计算效率。

Conclusion: 所提出的图基主题标注方法在提高主题可解释性方面表现出色，且计算效率高。未来研究方向包括进一步增强主题标注的解释性和自动化。

Abstract: Extracting topics from text has become an essential task, especially with the
rapid growth of unstructured textual data. Most existing works rely on highly
computational methods to address this challenge. In this paper, we argue that
probabilistic and statistical approaches, such as topic modeling (TM), can
offer effective alternatives that require fewer computational resources. TM is
a statistical method that automatically discovers topics in large collections
of unlabeled text; however, it produces topics as distributions of
representative words, which often lack clear interpretability. Our objective is
to perform topic labeling by assigning meaningful labels to these sets of
words. To achieve this without relying on computationally expensive models, we
propose a graph-based approach that not only enriches topic words with
semantically related terms but also explores the relationships among them. By
analyzing these connections within the graph, we derive suitable labels that
accurately capture each topic's meaning. We present a comparative study between
our proposed method and several benchmarks, including ChatGPT-3.5, across two
different datasets. Our method achieved consistently better results than
traditional benchmarks in terms of BERTScore and cosine similarity and produced
results comparable to ChatGPT-3.5, while remaining computationally efficient.
Finally, we discuss future directions for topic labeling and highlight
potential research avenues for enhancing interpretability and automation.

</details>


### [123] [Reusing Pre-Training Data at Test Time is a Compute Multiplier](https://arxiv.org/abs/2511.04234)
*Alex Fang,Thomas Voice,Ruoming Pang,Ludwig Schmidt,Tom Gunter*

Main category: cs.CL

TL;DR: 研究表明，当前大型语言模型的预训练方法未能充分利用训练数据中的信息。通过检索增强生成（RAG），模型在多个基准测试中获得显著的准确性提升，相当于预训练计算量的约5倍效率提升，揭示了预训练数据价值的巨大未开发潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管研究人员致力于改进大型语言模型的预训练数据集，但很少有工作关注预训练过程从数据中提取思想和知识的效率。本研究旨在量化预训练过程遗留了多少数据集价值，以及这种效率如何随模型规模变化。

Method: 本研究采用检索增强生成（RAG）结合测试时计算，来量化预训练过程未充分利用的数据集价值。通过在标准开源数据集上进行预训练后检索，并在MMLU、Math-500和SimpleQA等基准测试上评估模型的准确性增益，并进行去污染处理以确保结果的有效性。此外，还探索了在测试时投入额外计算来解析检索到的上下文对性能的进一步提升。

Result: 结果显示，在标准数据集上进行预训练后使用检索增强，可在MMLU、Math-500和SimpleQA上实现显著的准确性提升，且这种提升在去污染后依然存在。对于MMLU，检索的作用相当于单独预训练的约5倍计算量效率提升。通过在测试时利用额外计算来解析检索到的上下文，性能可进一步提高，例如在MMLU上使公开的LLaMA 3.1 8B模型获得10个百分点的提升。

Conclusion: 本研究结果表明，当前大型语言模型的预训练方法未能充分利用现有预训练数据集中的全部信息，存在巨大的改进空间。这暗示了通过更有效的数据利用策略，可以显著提升模型的性能和效率。

Abstract: Large language models learn from their vast pre-training corpora, gaining the
ability to solve an ever increasing variety of tasks; yet although researchers
work to improve these datasets, there is little effort to understand how
efficient the pre-training apparatus is at extracting ideas and knowledge from
the data. In this work, we use retrieval augmented generation along with
test-time compute as a way to quantify how much dataset value was left behind
by the process of pre-training, and how this changes across scale. We
demonstrate that pre-training then retrieving from standard and largely
open-sourced datasets results in significant accuracy gains in MMLU, Math-500,
and SimpleQA, which persist through decontamination. For MMLU we observe that
retrieval acts as a ~5x compute multiplier versus pre-training alone. We show
that these results can be further improved by leveraging additional compute at
test time to parse the retrieved context, demonstrating a 10 percentage point
improvement on MMLU for the public LLaMA 3.1 8B model. Overall, our results
suggest that today's pre-training methods do not make full use of the
information in existing pre-training datasets, leaving significant room for
progress.

</details>


### [124] [SSPO: Subsentence-level Policy Optimization](https://arxiv.org/abs/2511.04256)
*Kun Yang,Zikang chen,Yanmeng Wang,Zhigen Li*

Main category: cs.CL

TL;DR: 本文提出SSPO算法，通过引入句子级重要性比例和句子熵调整PPO-CLIP，解决了现有RLVR算法GRPO和GSPO在训练稳定性差和数据利用率低方面的问题，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM后训练中的RLVR算法存在缺陷：GRPO的token级重要性比例易受异常值影响导致训练崩溃；GSPO的response级重要性比例虽解决了高方差问题，但可能因极端值导致整个响应被错误丢弃，降低了采样数据利用率。因此，需要一种平衡训练稳定性和数据利用率的方法。

Method: 本文提出了SSPO（Sentence-level Sequence Policy Optimization）算法，它采用句子级重要性比例，旨在平衡GRPO和GSPO的优缺点。此外，SSPO将句子熵应用于PPO-CLIP，以动态调整裁剪边界，鼓励高熵token进行探索，并缩小低熵token的裁剪范围。

Result: SSPO在五个数据集上的平均得分达到46.57，超过了GRPO（43.01）和GSPO（44.42），并在其中三个数据集上取得了最先进的性能。这些结果表明SSPO在利用生成数据方面的有效性，它汲取了GSPO的优点并避免了其缺点。

Conclusion: SSPO通过采用句子级重要性比例和句子熵调整PPO-CLIP，有效解决了RLVR算法中训练不稳定和数据利用率低的问题，显著提高了LLM的推理能力，并取得了优于现有方法的性能。

Abstract: As a significant part of post-training of the Large Language Models (LLMs),
Reinforcement Learning from Verifiable Reward (RLVR) has greatly improved LLMs'
reasoning skills. However, some RLVR algorithms, such as GRPO (Group Relative
Policy Optimization) and GSPO (Group Sequence Policy Optimization), are
observed to suffer from unstable policy updates and low usage of sampling data,
respectively. The importance ratio of GRPO is calculated at the token level,
which focuses more on optimizing a single token. This will be easily affected
by outliers, leading to model training collapse. GSPO proposed the calculation
of the response level importance ratio, which solves the problem of high
variance and training noise accumulation in the calculation of the GRPO
importance ratio. However, since all the response tokens share a common
importance ratio, extreme values can easily raise or lower the overall mean,
leading to the entire response being mistakenly discarded, resulting in a
decrease in the utilization of sampled data. This paper introduces SSPO, which
applies sentence-level importance ratio, taking the balance between GRPO and
GSPO. SSPO not only avoids training collapse and high variance, but also
prevents the whole response tokens from being abandoned by the clipping
mechanism. Furthermore, we apply sentence entropy to PPO-CLIP to steadily
adjust the clipping bounds, encouraging high-entropy tokens to explore and
narrow the clipping range of low-entropy tokens. In particular, SSPO achieves
an average score of 46.57 across five datasets, surpassing GRPO (43.01) and
GSPO (44.42), and wins state-of-the-art performance on three datasets. These
results highlight SSPO's effectiveness in leveraging generated data by taking
the essence of GSPO but rejecting its shortcomings.

</details>


### [125] [Dynamic Jointly Batch Selection for Data Efficient Machine Translation Fine-Tuning](https://arxiv.org/abs/2511.04406)
*Mohammad Amin Ghanizadeh,Mohammad Javad Dousti*

Main category: cs.CL

TL;DR: 本文提出一种针对机器翻译系统微调的数据选择方法，通过学习能力分数和批次选择策略，显著提升了数据和计算效率，并改善了翻译性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 数据质量和有效选择对于提升机器翻译模型性能，构建稳健可靠的翻译系统至关重要。

Method: 该方法利用学习器模型和预训练参考模型之间的协同作用，通过定义“学习能力分数”系统评估数据点的效用。此外，采用批次选择策略，考虑数据点之间的相互依赖性，以优化训练效率和数据相关性。

Result: 在英波语对及其他语言对上，使用mBART模型在CCMatrix数据集上进行微调的实验表明，该方法相比iid基线，数据效率提高了五倍。利用缓存嵌入时，计算效率提高了24%，并且泛化能力更强，翻译性能优于随机选择方法。

Conclusion: 所提出的数据选择方法能够显著提高机器翻译系统微调的数据效率和计算效率，同时增强模型的泛化能力，从而获得更优越的翻译性能。

Abstract: Data quality and its effective selection are fundamental to improving the
performance of machine translation models, serving as cornerstones for
achieving robust and reliable translation systems. This paper presents a data
selection methodology specifically designed for fine-tuning machine translation
systems, which leverages the synergy between a learner model and a pre-trained
reference model to enhance overall training effectiveness. By defining a
learnability score, our approach systematically evaluates the utility of data
points for training, ensuring that only the most relevant and impactful
examples contribute to the fine-tuning process. Furthermore, our method employs
a batch selection strategy which considers interdependencies among data points,
optimizing the efficiency of the training process while maintaining a focus on
data relevance. Experiments on English to Persian and several other language
pairs using an mBART model fine-tuned on the CCMatrix dataset demonstrate that
our method can achieve up to a fivefold improvement in data efficiency compared
to an iid baseline. Experimental results indicate that our approach improves
computational efficiency by 24 when utilizing cached embeddings, as it requires
fewer training data points. Additionally, it enhances generalization, resulting
in superior translation performance compared to random selection method.

</details>


### [126] [Probabilistic Textual Time Series Depression Detection](https://arxiv.org/abs/2511.04476)
*Fabian Schmidt,Seyedehmoniba Ravan,Vladimir Vlassov*

Main category: cs.CL

TL;DR: PTTSD是一个概率文本时间序列抑郁检测框架，通过建模不确定性来预测PHQ-8分数，并在文本专用系统中达到了最先进的性能，同时提供可解释的预测区间。


<details>
  <summary>Details</summary>
Motivation: 现有的抑郁症严重程度预测模型通常缺乏不确定性估计和时间序列建模能力，而这对于临床决策支持至关重要。

Method: 本文提出了PTTSD框架，它包括序列到序列和序列到一的变体。该框架结合了双向LSTM、自注意力机制和残差连接，并使用高斯或Student-t输出头，通过负对数似然进行训练，以预测PHQ-8分数并建模随时间变化的不确定性。

Result: PTTSD在E-DAIC和DAIC-WOZ数据集上，在文本专用系统中取得了最先进的性能（例如，E-DAIC上的MAE为3.85，DAIC上的MAE为3.55），并生成了校准良好的预测区间。消融实验证实了注意力机制和概率建模的价值，与MentalBERT的比较则证明了其通用性。

Conclusion: PTTSD通过提供不确定性估计的预测，增强了抑郁症严重程度预测的准确性和可解释性，并通过校准分析和定性案例研究进一步突出了其在临床上的相关性。

Abstract: Accurate and interpretable predictions of depression severity are essential
for clinical decision support, yet existing models often lack uncertainty
estimates and temporal modeling. We propose PTTSD, a Probabilistic Textual Time
Series Depression Detection framework that predicts PHQ-8 scores from
utterance-level clinical interviews while modeling uncertainty over time. PTTSD
includes sequence-to-sequence and sequence-to-one variants, both combining
bidirectional LSTMs, self-attention, and residual connections with Gaussian or
Student-t output heads trained via negative log-likelihood. Evaluated on E-DAIC
and DAIC-WOZ, PTTSD achieves state-of-the-art performance among text-only
systems (e.g., MAE = 3.85 on E-DAIC, 3.55 on DAIC) and produces well-calibrated
prediction intervals. Ablations confirm the value of attention and
probabilistic modeling, while comparisons with MentalBERT establish generality.
A three-part calibration analysis and qualitative case studies further
highlight the interpretability and clinical relevance of uncertainty-aware
forecasting.

</details>


### [127] [If I Could Turn Back Time: Temporal Reframing as a Historical Reasoning Task for LLMs](https://arxiv.org/abs/2511.04432)
*Lars Bungum,Charles Yijia Huang,Abeer Kashar*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）的时间推理能力，发现使用1940年的挪威问答集时，英语提示比挪威语提示效果更好，且更大的LLM表现更佳。


<details>
  <summary>Details</summary>
Motivation: 研究旨在实验LLMs进行时间推理的能力，即在特定历史背景（1940年）下回答问题的表现。

Method: 研究使用了一本1940年的挪威问答书，要求LLMs模拟1940年的情境回答问题。问题同时以英语和挪威语提出。答案由LLM作为裁判进行评分，并由母语者抽样检查。测试的模型包括DeepSeek-R1、Gemma3、Qwen3、Llama3.1系列以及一个专门为挪威语设计的最大LLM。

Result: 结果显示，英语提示始终比挪威语提示获得更好的表现，这是一个出乎意料的发现。此外，使用更大的LLM能够提高结果。

Conclusion: LLMs在时间推理方面表现出不同能力，其中英语提示在处理特定历史背景的挪威语内容时表现优于挪威语提示，且模型规模对性能有积极影响。

Abstract: In this study, we experiment with the ability of LLMs to do temporal
reasoning. Using a Norwegian book from 1940 containing trivia questions, we
prompt the LLMs to answer the questions as if it were 1940. We also pose the
questions in both English and Norwegian. Correct answers are often presented as
sentences, and grading is done by means of LLM-as-judge, with sampled checks by
a native speaker. Prompting in English consistently gave better results than in
Norwegian, an unexpected result. In contrast, using larger LLMs improved
results. We tested the DeepSeek-R1, Gemma3, Qwen3, and Llama3.1 model families,
and also the largest available LLM especially crafted for Norwegian.

</details>


### [128] [ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai](https://arxiv.org/abs/2511.04479)
*Surapon Nonesung,Teetouch Jaknamon,Sirinya Chaiophat,Natapong Nitarach,Chanakan Wittayasakpan,Warit Sirichotedumrong,Adisai Na-Thalang,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 该论文提出了ThaiOCRBench，首个用于评估视觉语言模型在泰语文本理解任务上的综合基准。它包含2,808个人工标注样本，涵盖13个任务类别，并揭示了专有模型与开源模型之间的显著性能差距，尤其是在泰语文档结构理解方面。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态建模取得了进展，但现有基准主要集中在高资源语言，导致泰语等低资源语言，特别是在需要文档结构理解的任务中，代表性不足。

Method: 研究人员构建了ThaiOCRBench，一个包含2,808个样本、涵盖13个任务类别的人工标注数据集。他们使用零样本设置评估了广泛的最新视觉语言模型（包括专有和开源系统），并进行了详细的错误分析。

Result: 评估结果显示，专有模型（如Gemini 2.5 Pro）在性能上显著优于开源模型。在开源模型中，细粒度文本识别和手写内容提取任务的性能下降最为剧烈。研究还发现了语言偏差、结构不匹配和内容幻觉等关键挑战。

Conclusion: ThaiOCRBench为在低资源、复杂脚本环境中评估视觉语言模型提供了一个标准化框架，并为改进泰语文档理解提供了可行的见解。

Abstract: We present ThaiOCRBench, the first comprehensive benchmark for evaluating
vision-language models (VLMs) on Thai text-rich visual understanding tasks.
Despite recent progress in multimodal modeling, existing benchmarks
predominantly focus on high-resource languages, leaving Thai underrepresented,
especially in tasks requiring document structure understanding. ThaiOCRBench
addresses this gap by offering a diverse, human-annotated dataset comprising
2,808 samples across 13 task categories. We evaluate a wide range of
state-of-the-art VLMs in a zero-shot setting, spanning both proprietary and
open-source systems. Results show a significant performance gap, with
proprietary models (e.g., Gemini 2.5 Pro) outperforming open-source
counterparts. Notably, fine-grained text recognition and handwritten content
extraction exhibit the steepest performance drops among open-source models.
Through detailed error analysis, we identify key challenges such as language
bias, structural mismatch, and hallucinated content. ThaiOCRBench provides a
standardized framework for assessing VLMs in low-resource, script-complex
settings, and provides actionable insights for improving Thai-language document
understanding.

</details>


### [129] [RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables](https://arxiv.org/abs/2511.04491)
*Nikhil Abhyankar,Purvi Chaurasia,Sanchit Kabra,Ananya Srivastava,Vivek Gupta,Chandan K. Reddy*

Main category: cs.CL

TL;DR: RUST-BENCH是一个新的基准测试，用于评估大型语言模型（LLMs）在复杂、异构的真实世界表格上的推理能力，并揭示了LLMs在此类任务中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的表格推理基准测试主要针对小型、统一的表格，未能充分代表真实世界数据的复杂性，导致对LLMs推理能力的评估不完整。真实表格通常较长、异构、领域特定，并混合了结构化字段和自由文本，需要跨数千个token进行多跳推理。

Method: 引入RUST-BENCH，一个包含7966个问题、来自2031个真实世界表格的基准测试，涵盖两个领域：RB-Science（NSF拨款记录）和RB-Sports（NBA统计数据）。该基准测试在规模、异构性、领域特异性和推理复杂性方面对LLMs进行联合评估。

Result: 对开源和专有模型的实验表明，LLMs在异构模式和复杂的多跳推理方面表现不佳，揭示了当前架构和提示策略中持续存在的弱点。

Conclusion: RUST-BENCH为推进表格推理研究建立了一个具有挑战性的新测试平台。

Abstract: Existing tabular reasoning benchmarks mostly test models on small, uniform
tables, underrepresenting the complexity of real-world data and giving an
incomplete view of Large Language Models' (LLMs) reasoning abilities. Real
tables are long, heterogeneous, and domain-specific, mixing structured fields
with free text and requiring multi-hop reasoning across thousands of tokens. To
address this gap, we introduce RUST-BENCH, a benchmark of 7966 questions from
2031 real-world tables spanning two domains: i) RB-Science (NSF grant records)
and ii) RB-Sports (NBA statistics). Unlike prior work, RUST-BENCH evaluates
LLMs jointly across scale, heterogeneity, domain specificity, and reasoning
complexity. Experiments with open-source and proprietary models show that LLMs
struggle with heterogeneous schemas and complex multi-hop inference, revealing
persistent weaknesses in current architectures and prompting strategies.
RUST-BENCH establishes a challenging new testbed for advancing tabular
reasoning research.

</details>


### [130] [OUNLP at TSAR 2025 Shared Task: Multi-Round Text Simplifier via Code Generation](https://arxiv.org/abs/2511.04495)
*Cuong Huynh,Jie Cao*

Main category: cs.CL

TL;DR: 本文介绍了OUNLP系统，该系统使用基于LLM提示的多轮简化方法进行可读性控制的文本简化，其灵感来源于简化性能与源文本和目标文本的CEFR级别差距高度相关的发现。


<details>
  <summary>Details</summary>
Motivation: 研究动机是实现可读性控制的文本简化，并发现文本简化性能与源文本和目标文本之间的CEFR级别差距密切相关。

Method: 该研究采用基于LLM提示的生成（使用GPT-4o），并提出了两种多轮简化方法：基于规则的简化（MRS-Rule）和联合基于规则的LLM简化（MRS-Joint）。后续改进是将LLM简化的候选文本作为起点，进一步提升多轮简化性能。

Result: OUNLP系统在TSAR-2025共享任务中排名第7（共20支队伍）。后期通过MRS-Joint方法（将LLM简化候选文本作为起点）的改进，进一步提升了多轮简化性能。

Conclusion: 多轮简化方法，特别是以LLM简化候选文本作为起点的策略，能有效提高可读性控制的文本简化性能，且源文本与目标文本的CEFR级别差距是影响简化性能的重要因素。

Abstract: This paper describes the OUNLP system submitted to the TSAR-2025 Shared Task
(Alva-Manchego et al., 2025), designed for readability-controlled text
simplification using LLM-prompting-based generation. Based on the analysis of
prompt-based text simplification methods, we discovered an interesting finding
that text simplification performance is highly related to the gap between the
source CEFR (Arase et al., 2022) level and the target CEFR level. Inspired by
this finding, we propose two multi-round simplification methods and generate
them via GPT-4o: rule-based simplification (MRS-Rule) and jointly rule-based
LLM simplification (MRS-Joint). Our submitted systems ranked 7 out of 20 teams.
Later improvements with MRS-Joint show that taking the LLM simplified
candidates as the starting point could further boost the multi-round
simplification performance.

</details>


### [131] [Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty Markers to Implicit Reasoning Pathways](https://arxiv.org/abs/2511.04506)
*Paloma Rabaey,Jong Hak Moon,Jung-Oh Lee,Min Gwan Kim,Hangyul Yoon,Thomas Demeester,Edward Choi*

Main category: cs.CL

TL;DR: 本文提出一个两部分框架，量化放射学报告中的显式和隐式不确定性，并发布了Lunguage++，一个扩展的、不确定性感知的结构化放射学报告基准。


<details>
  <summary>Details</summary>
Motivation: 放射学报告对临床决策至关重要，但其中包含的显式（通过模糊词表达）和隐式（省略推理）不确定性阻碍了自动化分析和结构化。现有的基于规则的系统不足以量化这些不确定性。

Method: 针对显式不确定性，本文创建了一个专家验证的、基于大型语言模型（LLM）的常用模糊短语参考排名，并将每个发现映射到基于该排名的概率值。针对隐式不确定性，本文通过一个扩展框架，系统地从14种常见诊断的专家定义诊断路径中添加特征性子发现。

Result: 通过上述方法，本文发布了Lunguage++，这是Lunguage基准的一个扩展的、不确定性感知的版本，其中包含细粒度的结构化放射学报告。

Conclusion: Lunguage++这一丰富资源能够实现不确定性感知的图像分类、忠实的诊断推理，并为诊断不确定性的临床影响提供新的研究途径。

Abstract: Radiology reports are invaluable for clinical decision-making and hold great
potential for automated analysis when structured into machine-readable formats.
These reports often contain uncertainty, which we categorize into two distinct
types: (i) Explicit uncertainty reflects doubt about the presence or absence of
findings, conveyed through hedging phrases. These vary in meaning depending on
the context, making rule-based systems insufficient to quantify the level of
uncertainty for specific findings; (ii) Implicit uncertainty arises when
radiologists omit parts of their reasoning, recording only key findings or
diagnoses. Here, it is often unclear whether omitted findings are truly absent
or simply unmentioned for brevity. We address these challenges with a two-part
framework. We quantify explicit uncertainty by creating an expert-validated,
LLM-based reference ranking of common hedging phrases, and mapping each finding
to a probability value based on this reference. In addition, we model implicit
uncertainty through an expansion framework that systematically adds
characteristic sub-findings derived from expert-defined diagnostic pathways for
14 common diagnoses. Using these methods, we release Lunguage++, an expanded,
uncertainty-aware version of the Lunguage benchmark of fine-grained structured
radiology reports. This enriched resource enables uncertainty-aware image
classification, faithful diagnostic reasoning, and new investigations into the
clinical impact of diagnostic uncertainty.

</details>


### [132] [Are language models aware of the road not taken? Token-level uncertainty and hidden state dynamics](https://arxiv.org/abs/2511.04527)
*Amir Zur,Atticus Geiger,Ekdeep Singh Lubana,Eric Bigelow*

Main category: cs.CL

TL;DR: 本研究发现，语言模型的隐藏激活可以反映并控制其在推理过程中的不确定性，这表明模型在最终确定答案之前会隐式地表示潜在的替代推理路径。


<details>
  <summary>Details</summary>
Motivation: 语言模型在生成文本时，不同token的选择可能导致截然不同的推理路径，使得量化不确定性变得困难。研究旨在探讨推理语言模型是否在生成过程中表示了它们可能采取的替代路径。

Method: 通过使用隐藏激活来控制和预测语言模型在思维链推理过程中的不确定性。实验测试了模型在不同token处的不确定性与通过控制激活对其进行引导的难易程度之间的相关性。此外，还探究了隐藏激活是否能预测模型未来的结果分布。

Result: 研究发现，模型在不同token处的不确定性与其通过激活干预被引导的难易程度之间存在明显关联。这表明当模型存在替代路径时（即尚未确定最终答案时），激活干预最有效。同时，隐藏激活能够预测模型的未来结果分布。

Conclusion: 语言模型隐式地表示了可能的推理路径空间，并且隐藏激活能够反映并预测模型未来的行为。当模型尚未确定最终答案时，其内部状态（通过激活表示）会更灵活，更容易被引导。

Abstract: When a language model generates text, the selection of individual tokens
might lead it down very different reasoning paths, making uncertainty difficult
to quantify. In this work, we consider whether reasoning language models
represent the alternate paths that they could take during generation. To test
this hypothesis, we use hidden activations to control and predict a language
model's uncertainty during chain-of-thought reasoning. In our experiments, we
find a clear correlation between how uncertain a model is at different tokens,
and how easily the model can be steered by controlling its activations. This
suggests that activation interventions are most effective when there are
alternate paths available to the model -- in other words, when it has not yet
committed to a particular final answer. We also find that hidden activations
can predict a model's future outcome distribution, demonstrating that models
implicitly represent the space of possible paths.

</details>


### [133] [Decoding Emergent Big Five Traits in Large Language Models: Temperature-Dependent Expression and Architectural Clustering](https://arxiv.org/abs/2511.04499)
*Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou*

Main category: cs.CL

TL;DR: 本研究使用大五人格量表（BFI-2）评估了六个大型语言模型（LLMs）的“人格”表现，发现不同模型在人格维度上存在显著差异，且抽样温度会影响神经质和外向性。模型架构可能预设了稳定的特质，为模型调优和AI伦理治理提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在以人为中心的应用中日益重要，因此理解其类似人格的行为对于负责任的开发和部署至关重要。

Method: 系统性地评估了六个LLMs，应用大五人格量表（BFI-2）框架，在不同的抽样温度下评估其特质表达。此外，还采用了层次聚类方法。

Result: 在五个主要人格维度中的四个上发现了显著差异，其中神经质和外向性易受温度调整的影响。层次聚类揭示了不同的模型簇，表明架构特征可能使某些模型倾向于稳定的特质剖面。

Conclusion: 这些结果为LLMs中人格样模式的出现提供了新见解，并为模型调优、选择和AI系统的伦理治理提供了新视角。

Abstract: As Large Language Models (LLMs) become integral to human-centered
applications, understanding their personality-like behaviors is increasingly
important for responsible development and deployment. This paper systematically
evaluates six LLMs, applying the Big Five Inventory-2 (BFI-2) framework, to
assess trait expressions under varying sampling temperatures. We find
significant differences across four of the five personality dimensions, with
Neuroticism and Extraversion susceptible to temperature adjustments. Further,
hierarchical clustering reveals distinct model clusters, suggesting that
architectural features may predispose certain models toward stable trait
profiles. Taken together, these results offer new insights into the emergence
of personality-like patterns in LLMs and provide a new perspective on model
tuning, selection, and the ethical governance of AI systems. We share the data
and code for this analysis here:
https://osf.io/bsvzc/?view_only=6672219bede24b4e875097426dc3fac1

</details>


### [134] [RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific RAG](https://arxiv.org/abs/2511.04502)
*Joshua Gao,Quoc Huy Pham,Subin Varghese,Silwal Saurav,Vedhus Hoskere*

Main category: cs.CL

TL;DR: RAGalyst是一个自动化、与人类判断对齐的代理框架，用于严格评估特定领域的RAG系统，通过生成高质量的合成问答数据集和优化LLM-as-a-Judge指标来识别领域特定的RAG性能权衡。


<details>
  <summary>Details</summary>
Motivation: 在专业、安全关键领域评估RAG系统面临巨大挑战。现有评估框架依赖启发式指标，无法捕捉领域细微差别，或使用LLM-as-a-Judge方法，但其与人类判断的对齐性未经充分验证。

Method: 本文引入了RAGalyst框架，它包含一个代理管道，能从源文档生成高质量的合成问答（QA）数据集，并通过代理过滤步骤确保数据保真度。该框架通过提示优化，改进了“答案正确性”和“可回答性”这两个关键的LLM-as-a-Judge指标，使其与人类标注高度相关。

Result: 将RAGalyst应用于军事行动、网络安全和桥梁工程三个领域，评估了各种RAG组件，发现性能高度依赖于上下文，没有单一的嵌入模型、LLM或超参数配置是普遍最优的。此外，论文还分析了RAG中导致答案正确性低的最常见原因。

Conclusion: 这些发现强调了RAGalyst这类系统化评估框架的必要性，它能帮助从业者发现领域特定的权衡，并做出明智的设计选择，以构建可靠有效的RAG系统。

Abstract: Retrieval-Augmented Generation (RAG) is a critical technique for grounding
Large Language Models (LLMs) in factual evidence, yet evaluating RAG systems in
specialized, safety-critical domains remains a significant challenge. Existing
evaluation frameworks often rely on heuristic-based metrics that fail to
capture domain-specific nuances and other works utilize LLM-as-a-Judge
approaches that lack validated alignment with human judgment. This paper
introduces RAGalyst, an automated, human-aligned agentic framework designed for
the rigorous evaluation of domain-specific RAG systems. RAGalyst features an
agentic pipeline that generates high-quality, synthetic question-answering (QA)
datasets from source documents, incorporating an agentic filtering step to
ensure data fidelity. The framework refines two key LLM-as-a-Judge
metrics-Answer Correctness and Answerability-using prompt optimization to
achieve a strong correlation with human annotations. Applying this framework to
evaluate various RAG components across three distinct domains (military
operations, cybersecurity, and bridge engineering), we find that performance is
highly context-dependent. No single embedding model, LLM, or hyperparameter
configuration proves universally optimal. Additionally, we provide an analysis
on the most common low Answer Correctness reasons in RAG. These findings
highlight the necessity of a systematic evaluation framework like RAGalyst,
which empowers practitioners to uncover domain-specific trade-offs and make
informed design choices for building reliable and effective RAG systems.
RAGalyst is available on our Github.

</details>


### [135] [From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities Reporting](https://arxiv.org/abs/2511.04538)
*Cyril Vallez,Alexander Sternfeld,Andrei Kucharavy,Ljiljana Dolamic*

Main category: cs.CL

TL;DR: 研究发现最新的开源大语言模型在早期报告的漏洞场景中仍然存在安全漏洞，这表明安全性与功能性之间存在权衡。为解决此问题，论文引入了新的严重性指标——提示暴露（PE）和模型暴露（ME），以量化和优先处理LLM生成的漏洞风险。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型（LLM）的编码助手在软件开发中变得越来越重要，它们生成的错误对网络安全构成了关键风险。尽管已提出许多LLM代码安全基准和改进代码安全性的方法，但这些方法对广泛使用的编码LLM的影响程度尚不明确。

Method: 研究通过在实际使用场景中测试最新的开源模型，评估它们在最早报告的漏洞场景中的脆弱性。为了解决现有问题，论文引入了新的严重性度量标准——提示暴露（PE），该指标综合考虑了漏洞严重性、生成概率以及诱导生成漏洞代码的提示表述。在此基础上，定义了模型暴露（ME）得分，用于指示模型生成漏洞的严重性和普遍性。

Result: 研究显示，即使是最新的开源模型，在现实使用环境中，也对最早报告的漏洞场景表现出脆弱性。这表明在LLM中，安全性与功能性之间的权衡至今仍阻碍了有效漏洞修复。论文还成功引入了新的度量标准——提示暴露（PE）和模型暴露（ME），以量化和评估LLM生成漏洞的风险。

Conclusion: 最新的开源大语言模型在生成安全代码方面仍存在显著缺陷，尤其是在已知的漏洞场景中。这可能源于模型设计中安全性与功能性之间的固有权衡。通过引入提示暴露（PE）和模型暴露（ME）等新指标，可以更有效地识别、评估和优先处理LLM生成的严重且普遍的漏洞，从而鼓励缓解这些风险。

Abstract: As the role of Large Language Models (LLM)-based coding assistants in
software development becomes more critical, so does the role of the bugs they
generate in the overall cybersecurity landscape. While a number of LLM code
security benchmarks have been proposed alongside approaches to improve the
security of generated code, it remains unclear to what extent they have
impacted widely used coding LLMs. Here, we show that even the latest
open-weight models are vulnerable in the earliest reported vulnerability
scenarios in a realistic use setting, suggesting that the safety-functionality
trade-off has until now prevented effective patching of vulnerabilities. To
help address this issue, we introduce a new severity metric that reflects the
risk posed by an LLM-generated vulnerability, accounting for vulnerability
severity, generation chance, and the formulation of the prompt that induces
vulnerable code generation - Prompt Exposure (PE). To encourage the mitigation
of the most serious and prevalent vulnerabilities, we use PE to define the
Model Exposure (ME) score, which indicates the severity and prevalence of
vulnerabilities a model generates.

</details>


### [136] [IntelliProof: An Argumentation Network-based Conversational Helper for Organized Reflection](https://arxiv.org/abs/2511.04528)
*Kaveh Eskandari Miandoab,Katharine Kowalyshyn,Kabir Pamnani,Anesu Gavhera,Vasanth Sarathy,Matthias Scheutz*

Main category: cs.CL

TL;DR: IntelliProof是一个交互式系统，利用大型语言模型（LLMs）将议论文结构化为论证图，以可视化方式分析论证质量，并提供量化指标和自然语言解释，同时保留人工监督。


<details>
  <summary>Details</summary>
Motivation: 现有自动化论文评分系统缺乏用户体验，难以深入理解论证结构。研究旨在弥合议论文结构语义与用户理解之间的鸿沟，提供一个既能快速探索论证质量又保留人工监督的系统。

Method: IntelliProof将议论文构建为论证图：论点是节点，支持证据是节点属性，边表示支持或攻击关系。LLM对每种关系进行分类和评分，并进行可视化展示。系统提供分类依据、文章连贯性的量化指标，并提供工具以自然语言解释论证图。

Result: IntelliProof能够快速探索议论文的论证质量，同时保留人工监督。它为分类提供理由，生成文章连贯性的量化指标，并通过自然语言工具弥合了论证结构语义与用户理解之间的差距。

Conclusion: IntelliProof是一个有效的交互式系统，通过LLMs和可视化论证图，显著增强了用户对议论文论证质量的理解和分析能力，同时兼顾了自动化效率与人工监督的重要性。

Abstract: We present IntelliProof, an interactive system for analyzing argumentative
essays through LLMs. IntelliProof structures an essay as an argumentation
graph, where claims are represented as nodes, supporting evidence is attached
as node properties, and edges encode supporting or attacking relations. Unlike
existing automated essay scoring systems, IntelliProof emphasizes the user
experience: each relation is initially classified and scored by an LLM, then
visualized for enhanced understanding. The system provides justifications for
classifications and produces quantitative measures for essay coherence. It
enables rapid exploration of argumentative quality while retaining human
oversight. In addition, IntelliProof provides a set of tools for a better
understanding of an argumentative essay and its corresponding graph in natural
language, bridging the gap between the structural semantics of argumentative
essays and the user's understanding of a given text. A live demo and the system
are available here to try: \textbf{https://intelliproof.vercel.app}

</details>


### [137] [BanglaMedQA and BanglaMMedBench: Evaluating Retrieval-Augmented Generation Strategies for Bangla Biomedical Question Answering](https://arxiv.org/abs/2511.04560)
*Sadia Sultana,Saiyma Sittul Muna,Mosammat Zannatul Samarukh,Ajwad Abrar,Tareque Mohmud Chowdhury*

Main category: cs.CL

TL;DR: 该研究引入了首个大规模孟加拉语生物医学多项选择题数据集BanglaMedQA和BanglaMMedBench，并提出了一种Agentic RAG策略，通过结合教科书和网络检索以及生成式推理，显著提高了孟加拉语低资源环境下生物医学问答的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言中开发准确的生物医学问答系统是一个重大挑战，限制了人们公平获取可靠医疗知识的机会。本研究旨在解决孟加拉语环境下这一问题。

Method: 研究引入了BanglaMedQA和BanglaMMedBench两个孟加拉语生物医学MCQ数据集。应用并基准测试了多种检索增强生成（RAG）策略，包括传统RAG、零样本回退RAG、代理RAG（Agentic RAG）、迭代反馈RAG和聚合RAG。关键创新在于通过光学字符识别（OCR）整合了孟加拉语医学教科书语料库，并实现了能够动态选择检索或推理策略的Agentic RAG管道。

Result: 实验结果显示，Agentic RAG结合openai/gpt-oss-120b模型达到了89.54%的最高准确率，优于其他配置，并展现出卓越的推理质量。

Conclusion: 这些发现突出了基于RAG的方法在提高孟加拉语医疗问答的可靠性和可及性方面的潜力，为未来多语言医疗人工智能研究奠定了基础。

Abstract: Developing accurate biomedical Question Answering (QA) systems in
low-resource languages remains a major challenge, limiting equitable access to
reliable medical knowledge. This paper introduces BanglaMedQA and
BanglaMMedBench, the first large-scale Bangla biomedical Multiple Choice
Question (MCQ) datasets designed to evaluate reasoning and retrieval in medical
artificial intelligence (AI). The study applies and benchmarks several
Retrieval-Augmented Generation (RAG) strategies, including Traditional,
Zero-Shot Fallback, Agentic, Iterative Feedback, and Aggregate RAG, combining
textbook-based and web retrieval with generative reasoning to improve factual
accuracy. A key novelty lies in integrating a Bangla medical textbook corpus
through Optical Character Recognition (OCR) and implementing an Agentic RAG
pipeline that dynamically selects between retrieval and reasoning strategies.
Experimental results show that the Agentic RAG achieved the highest accuracy
89.54% with openai/gpt-oss-120b, outperforming other configurations and
demonstrating superior rationale quality. These findings highlight the
potential of RAG-based methods to enhance the reliability and accessibility of
Bangla medical QA, establishing a foundation for future research in
multilingual medical artificial intelligence.

</details>


### [138] [Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.04654)
*Mohammad Atif Quamar,Mohammad Areeb*

Main category: cs.CL

TL;DR: LEASH是一种无需训练的解码算法，通过监控逻辑熵和最高逻辑值裕度的变化，自适应地停止Chain-of-Thought（CoT）推理过程，旨在减少令牌使用和延迟，同时保持相对较高的准确率。


<details>
  <summary>Details</summary>
Motivation: Chain-of-Thought（CoT）提示在大型语言模型中实现复杂推理非常有效，但生成完整、固定长度的理由计算成本高昂，导致令牌使用和延迟增加，造成资源浪费。

Method: 本文提出LEASH（Logit-Entropy Adaptive Stopping Heuristic），这是一种无需训练的解码算法，可自适应地停止理由生成。LEASH监测两个内在信号：令牌级熵的斜率和最高逻辑值裕度的改进。当这两个信号都趋于平稳时，表明模型已达到稳定的推理状态，LEASH便终止生成。

Result: 在GSM8K和AQuA-RAT基准测试中，LEASH在四种指令微调模型上平均减少了30-35%的令牌生成和27%的延迟。相对于CoT，其准确率下降了10个百分点。

Conclusion: LEASH是一种模型无关、无需额外训练或监督的简单高效的CoT解码替代方案。它通过自适应停止理由生成，显著提高了计算效率，尽管会带来一定的准确率下降，但仍提供了一个有价值的权衡。

Abstract: Chain-of-Thought (CoT) prompting is a key technique for enabling complex
reasoning in large language models. However, generating full, fixed-length
rationales is computationally wasteful, inflating both token usage and latency.
We introduce LEASH: Logit-Entropy Adaptive Stopping Heuristic, a training-free
decoding algorithm that adaptively halts rationale generation. LEASH monitors
two intrinsic signals: the slope of token-level entropy and the improvement in
the top-logit margin. It terminates the generation once both signals plateau,
indicating the model has reached a stable reasoning state. Across four
instruction-tuned models on the GSM8K and AQuA-RAT benchmarks, LEASH reduces
average token generation by 30--35% and latency by 27%, while incurring a 10
p.p. accuracy drop relative to CoT. LEASH is model-agnostic and requires no
additional training or supervision, offering a simple and efficient alternative
to CoT decoding.

</details>


### [139] [When retrieval outperforms generation: Dense evidence retrieval for scalable fake news detection](https://arxiv.org/abs/2511.04643)
*Alamgir Munir Qazi,John P. McCrae,Jamal Abdul Nasir*

Main category: cs.CL

TL;DR: DeReC是一个轻量级的事实核查框架，它通过结合密集检索和专门分类，利用通用文本嵌入有效替代了基于LLM的方法，显著提高了效率和准确性，超越了现有最先进的LLM模型。


<details>
  <summary>Details</summary>
Motivation: 当前事实核查系统面临信息误传泛滥的挑战，需要既强大又计算高效的解决方案。现有最先进的LLM方法虽然能生成解释性理由，但在实际部署中存在显著的计算障碍和幻觉风险。

Method: 本文提出了DeReC（密集检索分类）框架，它使用通用文本嵌入来代替自回归LLM方法进行事实核查。该系统通过结合密集检索和专门分类来实现其功能。

Result: DeReC在效率上显著优于生成解释的LLM，在RAWFC数据集上运行时长减少95%，在LIAR-RAW上减少92%。在RAWFC数据集上，DeReC的F1分数达到65.58%，超过了最先进的L-Defense方法（61.20%）。

Conclusion: 精心设计的基于检索的系统在特定任务中可以达到或超越LLM的性能，同时在实际部署中更具实用性。

Abstract: The proliferation of misinformation necessitates robust yet computationally
efficient fact verification systems. While current state-of-the-art approaches
leverage Large Language Models (LLMs) for generating explanatory rationales,
these methods face significant computational barriers and hallucination risks
in real-world deployments. We present DeReC (Dense Retrieval Classification), a
lightweight framework that demonstrates how general-purpose text embeddings can
effectively replace autoregressive LLM-based approaches in fact verification
tasks. By combining dense retrieval with specialized classification, our system
achieves better accuracy while being significantly more efficient. DeReC
outperforms explanation-generating LLMs in efficiency, reducing runtime by 95%
on RAWFC (23 minutes 36 seconds compared to 454 minutes 12 seconds) and by 92%
on LIAR-RAW (134 minutes 14 seconds compared to 1692 minutes 23 seconds),
showcasing its effectiveness across varying dataset sizes. On the RAWFC
dataset, DeReC achieves an F1 score of 65.58%, surpassing the state-of-the-art
method L-Defense (61.20%). Our results demonstrate that carefully engineered
retrieval-based systems can match or exceed LLM performance in specialized
tasks while being significantly more practical for real-world deployment.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [140] [Dynamic Shape Control of Soft Robots Enabled by Data-Driven Model Reduction](https://arxiv.org/abs/2511.03931)
*Iman Adibnazari,Harsh Sharma,Myungsun Park,Jacobo Cervera-Torralba,Boris Kramer,Michael T. Tolley*

Main category: cs.RO

TL;DR: 本文比较了三种数据驱动的模型降阶技术（ERA、DMDc、LOpInf）在软体机器人动态形状控制中的性能。结果显示，基于LOpInf的模型在模型预测控制中实现了最低的跟踪误差。


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有巨大的潜力，但其高维动态特性使得有效的动态形状控制面临挑战。目前缺乏通用的工具来为控制目的建模软体机器人。

Method: 研究对比了三种数据驱动的模型降阶技术：特征系统实现算法（ERA）、带控制的动态模态分解（DMDc）和拉格朗日算子推断（LOpInf）方法。利用这些模型，研究人员探索了它们在模型预测控制（MPC）策略中用于模拟鳗鱼形软体机器人动态形状控制的有效性。实验包括跟踪可行的模拟轨迹、跟踪生物鳗鱼运动学轨迹以及跟踪缩减尺寸物理模拟器生成的轨迹。

Result: 在所有实验中，基于LOpInf策略的模型预测控制产生的跟踪误差均低于基于其他模型（ERA和DMDc）的策略。

Conclusion: LOpInf方法在为软体机器人动态形状控制生成线性模型方面表现出优越性，能够实现更低的跟踪误差，从而为软体机器人控制提供了一种更有效的数据驱动建模方法。

Abstract: Soft robots have shown immense promise in settings where they can leverage
dynamic control of their entire bodies. However, effective dynamic shape
control requires a controller that accounts for the robot's high-dimensional
dynamics--a challenge exacerbated by a lack of general-purpose tools for
modeling soft robots amenably for control. In this work, we conduct a
comparative study of data-driven model reduction techniques for generating
linear models amendable to dynamic shape control. We focus on three
methods--the eigensystem realization algorithm, dynamic mode decomposition with
control, and the Lagrangian operator inference (LOpInf) method. Using each
class of model, we explored their efficacy in model predictive control policies
for the dynamic shape control of a simulated eel-inspired soft robot in three
experiments: 1) tracking simulated reference trajectories guaranteed to be
feasible, 2) tracking reference trajectories generated from a biological model
of eel kinematics, and 3) tracking reference trajectories generated by a
reduced-scale physical analog. In all experiments, the LOpInf-based policies
generated lower tracking errors than policies based on other models.

</details>


### [141] [Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration](https://arxiv.org/abs/2511.04009)
*Chenzui Li,Yiming Chen,Xi Wu,Giacinto Barresi,Fei Chen*

Main category: cs.RO

TL;DR: 本文提出了一种上肢姿态优化方法，用于双臂人机协作搬运任务，旨在同时提升物理人体工程学和力操纵能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常侧重于人类安全或操纵效率的单一方面，且缺乏在不同抓握姿态和物体形状等多样条件下的通用性，未能有效整合安全性和协作能力。

Method: 该方法通过最小化成本函数来优化简化人类骨骼模型的关节角度，以优先考虑安全性和操纵能力。然后，通过转换模块生成机器人的参考末端执行器姿态。最后，为类人机器人CURI提出了一种双臂模型预测阻抗控制器（MPIC），通过规划轨迹重新校准末端执行器姿态。

Result: 通过人-人协作（HHC）和人-机协作（HRC）实验，在不同受试者和物体上验证了该方法。实验结果表明，优化前后目标肌肉的激活程度对比显示，肌肉状况有显著改善。

Conclusion: 该方法成功地在双臂人机协作搬运任务中提升了物理人体工程学和力操纵能力，并通过优化上肢姿态有效平衡了安全性和协作效率。

Abstract: This paper introduces an upper limb postural optimization method for
enhancing physical ergonomics and force manipulability during bimanual
human-robot co-carrying tasks. Existing research typically emphasizes human
safety or manipulative efficiency, whereas our proposed method uniquely
integrates both aspects to strengthen collaboration across diverse conditions
(e.g., different grasping postures of humans, and different shapes of objects).
Specifically, the joint angles of a simplified human skeleton model are
optimized by minimizing the cost function to prioritize safety and manipulative
capability. To guide humans towards the optimized posture, the reference
end-effector poses of the robot are generated through a transformation module.
A bimanual model predictive impedance controller (MPIC) is proposed for our
human-like robot, CURI, to recalibrate the end effector poses through planned
trajectories. The proposed method has been validated through various subjects
and objects during human-human collaboration (HHC) and human-robot
collaboration (HRC). The experimental results demonstrate significant
improvement in muscle conditions by comparing the activation of target muscles
before and after optimization.

</details>


### [142] [Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots](https://arxiv.org/abs/2511.03996)
*Yushi Wang,Changsheng Luo,Penghui Chen,Jianran Liu,Weijian Sun,Tong Guo,Kechang Yang,Biao Hu,Yangang Zhang,Mingguo Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种基于统一强化学习的控制器，通过直接整合视觉感知和运动控制，使仿人机器人能够在动态环境中学习并执行反应灵敏的足球技能。


<details>
  <summary>Details</summary>
Motivation: 现有的仿人足球系统通常依赖解耦模块，导致在动态环境中响应延迟和行为不连贯，且实际感知限制进一步加剧了这些问题。

Method: 研究采用统一的强化学习控制器，将视觉感知与运动控制直接集成。该方法将对抗运动先验（Adversarial Motion Priors）扩展到真实世界动态环境中的感知设置。引入了编码器-解码器架构，并结合了模拟真实世界视觉特征的虚拟感知系统，使策略能从不完美观测中恢复特权状态，并建立感知与动作之间的主动协调。

Result: 所提出的控制器展现出强大的反应能力，在包括真实RoboCup比赛在内的各种场景中，都能持续执行连贯且稳健的足球行为。

Conclusion: 通过直接整合视觉感知和运动控制，本文的统一强化学习控制器成功克服了现有系统的局限性，使仿人机器人能够习得高度反应性的足球技能，并在复杂动态环境中表现出色。

Abstract: Humanoid soccer poses a representative challenge for embodied intelligence,
requiring robots to operate within a tightly coupled perception-action loop.
However, existing systems typically rely on decoupled modules, resulting in
delayed responses and incoherent behaviors in dynamic environments, while
real-world perceptual limitations further exacerbate these issues. In this
work, we present a unified reinforcement learning-based controller that enables
humanoid robots to acquire reactive soccer skills through the direct
integration of visual perception and motion control. Our approach extends
Adversarial Motion Priors to perceptual settings in real-world dynamic
environments, bridging motion imitation and visually grounded dynamic control.
We introduce an encoder-decoder architecture combined with a virtual perception
system that models real-world visual characteristics, allowing the policy to
recover privileged states from imperfect observations and establish active
coordination between perception and action. The resulting controller
demonstrates strong reactivity, consistently executing coherent and robust
soccer behaviors across various scenarios, including real RoboCup matches.

</details>


### [143] [An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue](https://arxiv.org/abs/2511.04042)
*Kailun Ji,Xiaoyu Hu,Xinyu Zhang,Jun Chen*

Main category: cs.RO

TL;DR: 该研究提出一种基于LLM-CRF的系统，通过自然多模态交互和LLM驱动的认知引擎，弥合人类操作员与无人机蜂群之间在灾难搜救（SAR）任务中的“意图-行动鸿沟”，显著提升任务效率并减轻操作员认知负荷。


<details>
  <summary>Details</summary>
Motivation: 大规模灾难搜救中，无人机蜂群在复杂地形和通信中断环境下难以有效协调，人类操作员面临巨大的认知负担，将高层级救援目标转化为低层级蜂群指令存在“意图-行动鸿沟”，易出错且压力巨大。

Method: 提出LLM-CRF系统，通过语音或图形标注等自然多模态交互捕捉操作员意图。系统利用LLM作为认知引擎，进行意图理解、分层任务分解和无人机蜂群任务规划。这是一个闭环框架，使蜂群能作为主动伙伴提供实时反馈，减少手动监控和控制。

Result: 在模拟SAR场景中，与传统指令式界面相比，所提出的LLM驱动方法将任务完成时间缩短约64.2%，任务成功率提高7%，主观认知负荷（NASA-TLX得分）降低42.9%。

Conclusion: 这项工作证实了大型语言模型（LLMs）在创建高风险场景下更直观、更有效的人机蜂群协作方面的潜力。

Abstract: Large-scale disaster Search And Rescue (SAR) operations are persistently
challenged by complex terrain and disrupted communications. While Unmanned
Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area
search and supply delivery, yet their effective coordination places a
significant cognitive burden on human operators. The core human-machine
collaboration bottleneck lies in the ``intention-to-action gap'', which is an
error-prone process of translating a high-level rescue objective into a
low-level swarm command under high intensity and pressure. To bridge this gap,
this study proposes a novel LLM-CRF system that leverages Large Language Models
(LLMs) to model and augment human-swarm teaming cognition. The proposed
framework initially captures the operator's intention through natural and
multi-modal interactions with the device via voice or graphical annotations. It
then employs the LLM as a cognitive engine to perform intention comprehension,
hierarchical task decomposition, and mission planning for the UAV swarm. This
closed-loop framework enables the swarm to act as a proactive partner,
providing active feedback in real-time while reducing the need for manual
monitoring and control, which considerably advances the efficacy of the SAR
task. We evaluate the proposed framework in a simulated SAR scenario.
Experimental results demonstrate that, compared to traditional order and
command-based interfaces, the proposed LLM-driven approach reduced task
completion time by approximately $64.2\%$ and improved task success rate by
$7\%$. It also leads to a considerable reduction in subjective cognitive
workload, with NASA-TLX scores dropping by $42.9\%$. This work establishes the
potential of LLMs to create more intuitive and effective human-swarm
collaborations in high-stakes scenarios.

</details>


### [144] [Enhancing Fault-Tolerant Space Computing: Guidance Navigation and Control (GNC) and Landing Vision System (LVS) Implementations on Next-Gen Multi-Core Processors](https://arxiv.org/abs/2511.04052)
*Kyongsik Yun,David Bayard,Gerik Kubiak,Austin Owens,Andrew Johnson,Ryan Johnson,Dan Scharf,Thomas Lu*

Main category: cs.RO

TL;DR: 本文评估了下一代多核处理器在行星探索任务中实现自主制导、导航与控制(GNC)和着陆器视觉系统(LVS)的性能和容错能力。通过引入多核投票机制ARBITER，实现了显著的速度提升和实时故障检测与纠正，为未来任务提供了可扩展、节能且容错的计算架构。


<details>
  <summary>Details</summary>
Motivation: 未来的行星探索任务，尤其是在进入、下降和着陆(EDL)阶段，需要高性能、容错的计算能力来支持自主GNC和LVS操作。传统空间飞行硬件已无法满足这些需求。

Method: 研究方法包括：1) 在HPSC、Snapdragon VOXL2和AMD Xilinx Versal等多核处理器上部署并评估GNC和LVS算法。2) 提出ARBITER（异步冗余行为检查以实现可信执行和恢复），一种多核投票(MV)机制，用于跨冗余核心进行实时故障检测和纠正。3) 在静态优化任务（GFOLD）和动态闭环控制（姿态控制系统）中验证ARBITER。4) 进行故障注入研究，以识别对位级错误最敏感的计算阶段。

Result: 主要成果包括：1) LVS图像处理速度提升高达15倍。2) GFOLD轨迹优化速度比传统硬件提升超过250倍。3) ARBITER机制有效实现了跨冗余核心的实时故障检测和纠正。4) 故障注入研究发现GFOLD中的梯度计算阶段对位级错误最敏感，这促使研究者提出选择性保护策略和基于向量的输出仲裁。

Conclusion: 本研究为未来行星任务（如火星样本返回、土卫二轨道着陆器、谷神星样本返回）建立了一个可扩展、节能且容错的计算架构，这些任务对机载自主性、低延迟和故障恢复能力有严格要求。

Abstract: Future planetary exploration missions demand high-performance, fault-tolerant
computing to enable autonomous Guidance, Navigation, and Control (GNC) and
Lander Vision System (LVS) operations during Entry, Descent, and Landing (EDL).
This paper evaluates the deployment of GNC and LVS algorithms on
next-generation multi-core processors--HPSC, Snapdragon VOXL2, and AMD Xilinx
Versal--demonstrating up to 15x speedup for LVS image processing and over 250x
speedup for Guidance for Fuel-Optimal Large Divert (GFOLD) trajectory
optimization compared to legacy spaceflight hardware. To ensure computational
reliability, we present ARBITER (Asynchronous Redundant Behavior Inspection for
Trusted Execution and Recovery), a Multi-Core Voting (MV) mechanism that
performs real-time fault detection and correction across redundant cores.
ARBITER is validated in both static optimization tasks (GFOLD) and dynamic
closed-loop control (Attitude Control System). A fault injection study further
identifies the gradient computation stage in GFOLD as the most sensitive to
bit-level errors, motivating selective protection strategies and vector-based
output arbitration. This work establishes a scalable and energy-efficient
architecture for future missions, including Mars Sample Return, Enceladus
Orbilander, and Ceres Sample Return, where onboard autonomy, low latency, and
fault resilience are critical.

</details>


### [145] [CBMC-V3: A CNS-inspired Control Framework Towards Manipulation Agility with SNN](https://arxiv.org/abs/2511.04109)
*Yanbo Pang,Qingkai Li,Mingguo Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种基于脉冲神经网络（SNN）的仿生控制框架，灵感来源于人类中枢神经系统（CNS），旨在为机器人手臂在复杂动态环境中实现敏捷操控，并实验证明其优于工业级位置控制。


<details>
  <summary>Details</summary>
Motivation: 现有机器人手臂控制算法难以在医疗、服务和日常生活中复杂、动态、不可预测且物体多样的环境中实现所需的敏捷操控。

Method: 该研究提出一个仿生控制框架，包含五个控制模块（大脑皮层、小脑、丘脑、脑干、脊髓）、三个分层控制级别和两条信息通路，所有模块均使用SNN实现。脊髓模块采用脉冲编码和LIF神经元进行反馈控制。脑干模块通过强化学习动态调整脊髓参数。丘脑模块调整小脑的扭矩输出。小脑模块使用循环SNN学习机械臂动力学，提供前馈重力补偿扭矩。该框架在仿真和实际机器人手臂平台上进行了验证。

Result: 实验结果表明，该方法在操作敏捷性方面优于工业级位置控制。

Conclusion: 所提出的基于SNN的仿生控制框架能够有效实现机器人手臂在复杂环境中的敏捷控制。

Abstract: As robotic arm applications extend beyond industrial settings into
healthcare, service, and daily life, existing control algorithms struggle to
achieve the agile manipulation required for complex environments with dynamic
trajectories, unpredictable interactions, and diverse objects. This paper
presents a biomimetic control framework based on Spiking Neural Networks (SNN),
inspired by the human Central Nervous System (CNS), to achieve agile control in
such environments. The proposed framework features five control modules
(cerebral cortex, cerebellum, thalamus, brainstem, spinal cord), three
hierarchical control levels (first-order, second-order, third-order), and two
information pathways (ascending, descending). Each module is fully implemented
using SNN. The spinal cord module uses spike encoding and Leaky
Integrate-and-Fire (LIF) neurons for feedback control. The brainstem module
employs a network of LIF and non-spiking LIF neurons to dynamically adjust
spinal cord parameters via reinforcement learning. The thalamus module
similarly adjusts the cerebellum's torque outputs. The cerebellum module uses a
recurrent SNN to learn the robotic arm's dynamics through regression, providing
feedforward gravity compensation torques. The framework is validated both in
simulation and on real-world robotic arm platform under various loads and
trajectories. Results demonstrate that our method outperforms the
industrial-grade position control in manipulation agility.

</details>


### [146] [BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning](https://arxiv.org/abs/2511.04131)
*Yitang Li,Zhengyi Luo,Tonghe Zhang,Cunxi Dai,Anssi Kanervisto,Andrea Tirinzoni,Haoyang Weng,Kris Kitani,Mateusz Guzek,Ahmed Touati,Alessandro Lazaric,Matteo Pirotta,Guanya Shi*

Main category: cs.RO

TL;DR: BFM-Zero是一个为人形机器人设计的框架，它通过学习共享的潜在表示，将运动、目标和奖励统一在一个空间中，从而实现单一策略在真实世界中无需重新训练即可处理多种全身控制任务，并结合无监督强化学习和前向-后向模型来弥合仿真与现实的差距。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人控制方法要么仅限于模拟环境，要么专门用于特定任务（如跟踪），缺乏一个能统一处理多样化控制任务的、可提示的通用策略。

Method: BFM-Zero框架学习一个共享的潜在表示，将运动、目标和奖励嵌入共同空间。它基于无监督强化学习和前向-后向（FB）模型，提供客观、可解释和平滑的潜在表示。通过多种推理方法实现任务，包括零样本运动跟踪、目标达成和奖励优化，以及少样本基于优化的适应。为弥合仿真与现实差距，还引入了奖励塑形、域随机化和依赖历史的非对称学习。

Result: BFM-Zero在真实世界的Unitree G1人形机器人上实现了多功能且鲁棒的全身技能。其结构良好的潜在空间使得单个策略无需重新训练即可应对多个下游任务，并成功展示了零样本运动跟踪、目标达成、奖励优化以及少样本适应能力。关键设计选择在仿真中得到了定量验证。

Conclusion: BFM-Zero是构建可扩展、可提示的全身人形机器人行为基础模型的重要一步，通过统一的潜在表示和先进的学习方法，实现了在真实世界中的多任务控制。

Abstract: Building Behavioral Foundation Models (BFMs) for humanoid robots has the
potential to unify diverse control tasks under a single, promptable generalist
policy. However, existing approaches are either exclusively deployed on
simulated humanoid characters, or specialized to specific tasks such as
tracking. We propose BFM-Zero, a framework that learns an effective shared
latent representation that embeds motions, goals, and rewards into a common
space, enabling a single policy to be prompted for multiple downstream tasks
without retraining. This well-structured latent space in BFM-Zero enables
versatile and robust whole-body skills on a Unitree G1 humanoid in the real
world, via diverse inference methods, including zero-shot motion tracking, goal
reaching, and reward optimization, and few-shot optimization-based adaptation.
Unlike prior on-policy reinforcement learning (RL) frameworks, BFM-Zero builds
upon recent advancements in unsupervised RL and Forward-Backward (FB) models,
which offer an objective-centric, explainable, and smooth latent representation
of whole-body motions. We further extend BFM-Zero with critical reward shaping,
domain randomization, and history-dependent asymmetric learning to bridge the
sim-to-real gap. Those key design choices are quantitatively ablated in
simulation. A first-of-its-kind model, BFM-Zero establishes a step toward
scalable, promptable behavioral foundation models for whole-body humanoid
control.

</details>


### [147] [PUL-SLAM: Path-Uncertainty Co-Optimization with Lightweight Stagnation Detection for Efficient Robotic Exploration](https://arxiv.org/abs/2511.04180)
*Yizhen Yin,Dapeng Feng,Hongbo Chen,Yuhua Qi*

Main category: cs.RO

TL;DR: 本文提出了一种结合路径-不确定性协同优化深度强化学习和轻量级停滞检测的混合主动SLAM框架，显著提高了复杂环境中的探索效率，缩短了探索时间和路径距离。


<details>
  <summary>Details</summary>
Motivation: 现有主动SLAM方法存在探索速度慢和路径次优的问题。

Method: 提出了一种混合框架，包含：1) 路径-不确定性协同优化深度强化学习框架，通过双目标奖励函数联合优化行驶距离和地图不确定性，平衡探索与利用；2) 轻量级停滞检测机制，通过激光雷达静态异常检测和地图更新停滞检测减少冗余探索，并在低扩展率时终止探索回合。

Result: 相比传统方法（基于边界和RRT），本文方法将探索时间缩短高达65%，路径距离减少高达42%，显著提高了复杂环境中的探索效率并保持了可靠的地图完整性。消融研究证实协同机制加速了训练收敛，并在物理机器人平台上验证了算法的实际适用性和模拟到真实世界的迁移能力。

Conclusion: 该混合主动SLAM框架通过优化路径和不确定性并有效避免冗余探索，显著提升了机器人在复杂环境中的探索效率和地图构建质量，并具备良好的实际应用潜力。

Abstract: Existing Active SLAM methodologies face issues such as slow exploration speed
and suboptimal paths. To address these limitations, we propose a hybrid
framework combining a Path-Uncertainty Co-Optimization Deep Reinforcement
Learning framework and a Lightweight Stagnation Detection mechanism. The
Path-Uncertainty Co-Optimization framework jointly optimizes travel distance
and map uncertainty through a dual-objective reward function, balancing
exploration and exploitation. The Lightweight Stagnation Detection reduces
redundant exploration through Lidar Static Anomaly Detection and Map Update
Stagnation Detection, terminating episodes on low expansion rates. Experimental
results show that compared with the frontier-based method and RRT method, our
approach shortens exploration time by up to 65% and reduces path distance by up
to 42%, significantly improving exploration efficiency in complex environments
while maintaining reliable map completeness. Ablation studies confirm that the
collaborative mechanism accelerates training convergence. Empirical validation
on a physical robotic platform demonstrates the algorithm's practical
applicability and its successful transferability from simulation to real-world
environments.

</details>


### [148] [GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments](https://arxiv.org/abs/2511.04199)
*Shenglin Wang,Mingtong Dai,Jingxuan Su,Lingbo Liu,Chunjie Chen,Xinyu Wu,Liang Lin*

Main category: cs.RO

TL;DR: GraspView是一种仅使用RGB图像的机器人抓取系统，通过多视图重建和主动感知策略，在杂乱、遮挡严重或包含透明物体的环境中，实现比RGB-D和单视图RGB系统更准确和可靠的抓取。


<details>
  <summary>Details</summary>
Motivation: 机器人抓取在杂乱环境中面临巨大挑战，传统RGB-D管道在透明/反光物体、近距离感知和遮挡下表现不佳，导致抓取不稳定或失败。本研究旨在开发一种不依赖深度传感器、仅使用RGB图像的抓取解决方案。

Method: GraspView是一个仅使用RGB图像的机器人抓取管道，包含三个核心组件：(i) 全局感知场景重建，从单视图RGB提供局部一致且按比例的几何信息，并融合多视图投影以构建连贯的全局3D场景；(ii) 渲染-评分主动感知策略，动态选择下一最佳视图以揭示被遮挡区域；(iii) 在线度量对齐模块，校准VGGT预测与机器人运动学，确保物理尺度一致性。该系统通过融合多视图重建和利用GraspNet进行鲁棒执行，实现了最佳视图全局抓取。

Result: 实验表明，GraspView在多样化的桌面物体上，显著优于RGB-D和单视图RGB基线系统，尤其在严重遮挡、近距离感知和处理透明物体方面表现出色。

Conclusion: GraspView被证明是RGB-D管道的一种实用且多功能的替代方案，能够在非结构化的真实世界环境中实现可靠的抓取。

Abstract: Robotic grasping is a fundamental capability for autonomous manipulation, yet
remains highly challenging in cluttered environments where occlusion, poor
perception quality, and inconsistent 3D reconstructions often lead to unstable
or failed grasps. Conventional pipelines have widely relied on RGB-D cameras to
provide geometric information, which fail on transparent or glossy objects and
degrade at close range. We present GraspView, an RGB-only robotic grasping
pipeline that achieves accurate manipulation in cluttered environments without
depth sensors. Our framework integrates three key components: (i) global
perception scene reconstruction, which provides locally consistent, up-to-scale
geometry from a single RGB view and fuses multi-view projections into a
coherent global 3D scene; (ii) a render-and-score active perception strategy,
which dynamically selects next-best-views to reveal occluded regions; and (iii)
an online metric alignment module that calibrates VGGT predictions against
robot kinematics to ensure physical scale consistency. Building on these
tailor-designed modules, GraspView performs best-view global grasping, fusing
multi-view reconstructions and leveraging GraspNet for robust execution.
Experiments on diverse tabletop objects demonstrate that GraspView
significantly outperforms both RGB-D and single-view RGB baselines, especially
under heavy occlusion, near-field sensing, and with transparent objects. These
results highlight GraspView as a practical and versatile alternative to RGB-D
pipelines, enabling reliable grasping in unstructured real-world environments.

</details>


### [149] [Can Context Bridge the Reality Gap? Sim-to-Real Transfer of Context-Aware Policies](https://arxiv.org/abs/2511.04249)
*Marco Iannotta,Yuxuan Yang,Johannes A. Stork,Erik Schaffernicht,Todor Stoyanov*

Main category: cs.RO

TL;DR: 本文提出通过在领域随机化（DR）框架中，将策略以估计的动力学参数（上下文）为条件，从而提高机器人强化学习中的仿真到现实（sim-to-real）迁移性能。


<details>
  <summary>Details</summary>
Motivation: 仿真到现实迁移在机器人强化学习中仍是主要挑战，因为仿真训练的策略因环境动力学差异而难以泛化到现实世界。领域随机化（DR）虽能缓解此问题，但会导致性能下降。标准方法通常对这些变化不敏感，因此研究是否可以通过将策略以动力学参数估计为条件来改进sim-to-real迁移。

Method: 研究人员将一个上下文估计模块集成到基于DR的强化学习框架中，并系统地比较了最先进的监督策略。他们在一个规范控制基准和一个使用Franka Emika Panda机器人的真实世界推动任务中评估了由此产生的上下文感知策略。

Result: 结果表明，在所有设置下，上下文感知策略都优于上下文无关的基线。然而，最佳监督策略取决于具体的任务。

Conclusion: 通过将策略以估计的动力学参数为条件（即上下文感知），可以显著改善强化学习中的仿真到现实迁移性能，即使在领域随机化框架下也是如此。虽然具体任务会影响最佳监督策略的选择，但上下文感知方法整体表现更优。

Abstract: Sim-to-real transfer remains a major challenge in reinforcement learning (RL)
for robotics, as policies trained in simulation often fail to generalize to the
real world due to discrepancies in environment dynamics. Domain Randomization
(DR) mitigates this issue by exposing the policy to a wide range of randomized
dynamics during training, yet leading to a reduction in performance. While
standard approaches typically train policies agnostic to these variations, we
investigate whether sim-to-real transfer can be improved by conditioning the
policy on an estimate of the dynamics parameters -- referred to as context. To
this end, we integrate a context estimation module into a DR-based RL framework
and systematically compare SOTA supervision strategies. We evaluate the
resulting context-aware policies in both a canonical control benchmark and a
real-world pushing task using a Franka Emika Panda robot. Results show that
context-aware policies outperform the context-agnostic baseline across all
settings, although the best supervision strategy depends on the task.

</details>


### [150] [Design and Control of a Coaxial Dual-rotor Reconfigurable Tailsitter UAV Based on Swashplateless Mechanism](https://arxiv.org/abs/2511.04251)
*Jinfeng Liang,Haocheng Guo,Ximin Lyu*

Main category: cs.RO

TL;DR: 本文提出了一种具有可重构机翼、同轴异构双旋翼和改进无倾斜盘机构的垂直起降（VTOL）尾座式无人机，旨在提高抗风能力、能源效率和飞行稳定性。


<details>
  <summary>Details</summary>
Motivation: 尾座式无人机在多旋翼模式下因其较大的机身迎风面积而易受风扰动影响；同时，传统的尾座式无人机在功耗和结构复杂性/重量方面存在挑战。

Method: 研究方法包括：1) 设计可重构机翼，在多旋翼模式下收缩，在固定翼模式下伸展；2) 采用同轴异构双旋翼配置以降低功耗；3) 使用改进的无倾斜盘机构（增加扑翼铰链）来控制俯仰和滚转，并减少振动；4) 进行全面的过渡飞行测试以验证性能。

Result: 研究结果表明，所设计的无人机显著降低了总功耗，减轻了结构重量并简化了结构复杂性，减少了循环加减速期间的振动，并通过全面的过渡飞行测试验证了其在整个飞行包线内的稳定飞行性能。

Conclusion: 该研究成功设计并验证了一种创新的尾座式无人机，通过可重构机翼、高效双旋翼和改进的无倾斜盘机构，有效解决了风扰动、功耗和结构复杂性等问题，实现了稳定的全包线飞行性能。

Abstract: The tailsitter vertical takeoff and landing (VTOL) UAV is widely used due to
its lower dead weight, which eliminates the actuators and mechanisms for
tilting. However, the tailsitter UAV is susceptible to wind disturbances in
multi-rotor mode, as it exposes a large frontal fuselage area. To address this
issue, our tailsitter UAV features a reconfigurable wing design, allowing wings
to retract in multi-rotor mode and extend in fixed- wing mode. Considering
power efficiency, we design a coaxial heterogeneous dual-rotor configuration,
which significantly re- duces the total power consumption. To reduce structural
weight and simplify structural complexity, we employ a swashplateless mechanism
with an improved design to control pitch and roll in multi-rotor mode. We
optimize the structure of the swashplateless mechanism by adding flapping
hinges, which reduces vibration during cyclic acceleration and deceleration.
Finally, we perform comprehensive transition flight tests to validate stable
flight performance across the entire flight envelope of the tailsitter UAV.

</details>


### [151] [MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments](https://arxiv.org/abs/2511.04320)
*Kuankuan Sima,Longbin Tang,Haozhe Ma,Lin Zhao*

Main category: cs.RO

TL;DR: MacroNav是一个学习型导航框架，通过轻量级上下文编码器和基于图推理的强化学习策略，在未知环境中实现了高效且鲁棒的自主导航，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中自主导航需要紧凑而富有表现力的空间理解，以支持高级决策，但现有方法难以平衡丰富的上下文表示与导航效率。

Method: MacroNav包含两个核心组件：1) 一个通过多任务自监督学习训练的轻量级上下文编码器，用于捕获多尺度、以导航为中心的空间表示；2) 一个强化学习策略，将这些表示与基于图的推理无缝集成，以进行高效的动作选择。

Result: 实验证明上下文编码器能高效且鲁棒地理解环境。实际部署验证了MacroNav的有效性，在成功率(SR)和路径长度加权成功率(SPL)方面显著优于最先进的导航方法，同时保持较低的计算成本。

Conclusion: MacroNav提供了一种在未知环境中进行自主导航的有效、高效且鲁棒的解决方案，能够平衡丰富的上下文表示与导航效率。

Abstract: Autonomous navigation in unknown environments requires compact yet expressive
spatial understanding under partial observability to support high-level
decision making. Existing approaches struggle to balance rich contextual
representation with navigation efficiency. We present MacroNav, a
learning-based navigation framework featuring two key components: (1) a
lightweight context encoder trained via multi-task self-supervised learning to
capture multi-scale, navigation-centric spatial representations; and (2) a
reinforcement learning policy that seamlessly integrates these representations
with graph-based reasoning for efficient action selection. Extensive
experiments demonstrate the context encoder's efficient and robust
environmental understanding. Real-world deployments further validate MacroNav's
effectiveness, yielding significant gains over state-of-the-art navigation
methods in both Success Rate (SR) and Success weighted by Path Length (SPL),
while maintaining low computational cost. Code will be released upon
acceptance.

</details>


### [152] [GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies](https://arxiv.org/abs/2511.04357)
*Maëlic Neau,Zoe Falomir,Paulo E. Santos,Anne-Gwenn Bosser,Cédric Buche*

Main category: cs.RO

TL;DR: 本文提出了一种名为GraSP-VLA的神经符号方法，它利用连续场景图从人类演示中生成符号表示，用于规划领域生成和协调低级视觉-语言-动作（VLA）策略，从而解决长周期机器人任务中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有端到端视觉-语言-动作（VLA）模型缺乏高层符号规划能力，限制了其在长周期任务中的表现；而符号动作模型学习（AML）方法则缺乏泛化性和可扩展性。因此，需要一种结合两者优势的新方法。

Method: GraSP-VLA框架使用连续场景图（Continuous Scene Graph）来生成人类演示的符号表示。这种表示在推理阶段用于生成新的规划领域，并作为低级VLA策略的协调器，从而扩展可连续执行的动作数量。

Result: 研究结果表明，GraSP-VLA在从观察中自动生成规划领域的符号表示建模方面是有效的。此外，在真实世界的实验中，其连续场景图表示展示了在长周期任务中协调低级VLA策略的潜力。

Conclusion: GraSP-VLA通过其神经符号方法和连续场景图表示，成功地弥补了现有VLA模型和符号AML方法的不足，为机器人从演示中学习新技能提供了有效且可扩展的解决方案，尤其适用于长周期任务。

Abstract: Deploying autonomous robots that can learn new skills from demonstrations is
an important challenge of modern robotics. Existing solutions often apply
end-to-end imitation learning with Vision-Language Action (VLA) models or
symbolic approaches with Action Model Learning (AML). On the one hand, current
VLA models are limited by the lack of high-level symbolic planning, which
hinders their abilities in long-horizon tasks. On the other hand, symbolic
approaches in AML lack generalization and scalability perspectives. In this
paper we present a new neuro-symbolic approach, GraSP-VLA, a framework that
uses a Continuous Scene Graph representation to generate a symbolic
representation of human demonstrations. This representation is used to generate
new planning domains during inference and serves as an orchestrator for
low-level VLA policies, scaling up the number of actions that can be reproduced
in a row. Our results show that GraSP-VLA is effective for modeling symbolic
representations on the task of automatic planning domain generation from
observations. In addition, results on real-world experiments show the potential
of our Continuous Scene Graph representation to orchestrate low-level VLA
policies in long-horizon tasks.

</details>


### [153] [Studying the Effect of Explicit Interaction Representations on Learning Scene-level Distributions of Human Trajectories](https://arxiv.org/abs/2511.04375)
*Anna Mészáros,Javier Alonso-Mora,Jens Kober*

Main category: cs.RO

TL;DR: 本研究探讨了自动驾驶场景中智能体交互的不同建模方式。结果显示，明确定义交互（如“谁先通过”）比神经网络隐式学习交互更能提升性能。


<details>
  <summary>Details</summary>
Motivation: 有效捕捉场景中所有智能体的联合分布对于预测场景演变和为自动驾驶车辆提供准确信息至关重要。尽管已有新模型，但如何最好地表示联合分布，特别是智能体之间的交互，仍不明确，尤其是在隐式学习与显式建模之间缺乏共识。

Method: 本文在相同的网络结构内，研究了多种描述智能体交互的方式，并分析它们对最终学习到的联合分布的影响。具体比较了基于数据让网络建立交互连接（隐式学习）和使用明确定义的交互（显式建模）。

Result: 研究发现，简单地允许网络基于数据建立智能体间的交互连接往往会对性能产生不利影响。相反，拥有明确定义的交互（例如，在十字路口哪对智能体中的哪个智能体先行）通常能显著提升性能。

Conclusion: 为了更准确地预测场景演变，在自动驾驶领域中，明确建模智能体之间的交互（例如基于人类决策的空间和时间关系）比让神经网络隐式学习这些交互更为有效。

Abstract: Effectively capturing the joint distribution of all agents in a scene is
relevant for predicting the true evolution of the scene and in turn providing
more accurate information to the decision processes of autonomous vehicles.
While new models have been developed for this purpose in recent years, it
remains unclear how to best represent the joint distributions particularly from
the perspective of the interactions between agents. Thus far there is no clear
consensus on how best to represent interactions between agents; whether they
should be learned implicitly from data by neural networks, or explicitly
modeled using the spatial and temporal relations that are more grounded in
human decision-making. This paper aims to study various means of describing
interactions within the same network structure and their effect on the final
learned joint distributions. Our findings show that more often than not, simply
allowing a network to establish interactive connections between agents based on
data has a detrimental effect on performance. Instead, having well defined
interactions (such as which agent of an agent pair passes first at an
intersection) can often bring about a clear boost in performance.

</details>


### [154] [ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation](https://arxiv.org/abs/2511.04381)
*Dexin wang,Faliang Chang,Chunsheng Liu*

Main category: cs.RO

TL;DR: ForeRobo是一个生成式机器人代理，它利用生成式仿真来自主学习操作技能。它通过预测三维目标状态并结合经典控制来实现零样本模拟到真实世界的迁移，展现出卓越的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 高效利用仿真来获取高级操作技能既具挑战性又意义重大。直接学习低级策略效率不高。

Method: ForeRobo采用“提议-生成-学习-执行”的自引导循环。首先，代理提议技能并构建仿真环境；接着，通过ForeGen生成与技能一致的目标状态，产生无限数据。然后，使用这些数据训练ForeFormer模型，该模型根据场景状态和任务指令预测当前状态中每个点的三维目标位置。最后，利用经典控制算法在真实世界中根据设想的目标状态驱动机器人执行动作。

Result: 与端到端策略学习方法相比，ForeFormer提供了卓越的可解释性和执行效率。在各种刚体和关节对象操作任务中，ForeFormer比最先进的状态生成模型平均提高了56.32%。在超过20项真实世界机器人任务中，ForeRobo实现了零样本模拟到真实世界的迁移，并取得了79.28%的平均成功率，展现出显著的泛化能力。

Conclusion: ForeRobo通过将生成范式与经典控制相结合，能够高效、可解释地利用生成式仿真自主获取操作技能。它在模拟和真实世界中均表现出强大的泛化能力和零样本迁移潜力。

Abstract: Efficiently leveraging simulation to acquire advanced manipulation skills is
both challenging and highly significant. We introduce \textit{ForeRobo}, a
generative robotic agent that utilizes generative simulations to autonomously
acquire manipulation skills driven by envisioned goal states. Instead of
directly learning low-level policies, we advocate integrating generative
paradigms with classical control. Our approach equips a robotic agent with a
self-guided \textit{propose-generate-learn-actuate} cycle. The agent first
proposes the skills to be acquired and constructs the corresponding simulation
environments; it then configures objects into appropriate arrangements to
generate skill-consistent goal states (\textit{ForeGen}). Subsequently, the
virtually infinite data produced by ForeGen are used to train the proposed
state generation model (\textit{ForeFormer}), which establishes point-wise
correspondences by predicting the 3D goal position of every point in the
current state, based on the scene state and task instructions. Finally,
classical control algorithms are employed to drive the robot in real-world
environments to execute actions based on the envisioned goal states. Compared
with end-to-end policy learning methods, ForeFormer offers superior
interpretability and execution efficiency. We train and benchmark ForeFormer
across a variety of rigid-body and articulated-object manipulation tasks, and
observe an average improvement of 56.32\% over the state-of-the-art state
generation models, demonstrating strong generality across different
manipulation patterns. Moreover, in real-world evaluations involving more than
20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits
remarkable generalization capabilities, attaining an average success rate of
79.28\%.

</details>


### [155] [Temporal Action Selection for Action Chunking](https://arxiv.org/abs/2511.04421)
*Yueyang Weng,Xiaopeng Zhang,Yongjin Mu,Yingcong Zhu,Yanjie Li,Qi Liu*

Main category: cs.RO

TL;DR: 动作分块在模仿学习中提高了建模能力但降低了反应性。本文提出时间动作选择器（TAS），通过缓存和动态选择动作块，平衡了反应性、决策一致性和运动连贯性，显著提高了成功率，并能有效提升残差强化学习的训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 动作分块（Action chunking）在模仿学习（LfD）中虽能增强对人类专家策略的建模能力，但其降低的决策频率限制了对最新观测的利用，导致反应性下降，尤其在应对传感器噪声和动态环境变化时表现不佳。现有解决方案往往以牺牲决策一致性来换取反应性，未能同时实现两者。

Method: 本文提出一种新算法——时间动作选择器（Temporal Action Selector, TAS）。该方法缓存来自多个时间步的预测动作块，并通过一个轻量级的选择器网络动态选择最优动作。TAS旨在同时优化反应性、决策一致性和运动连贯性三个关键维度。

Result: TAS在多项任务和不同基础策略下显著提高了成功率，绝对增益高达73.3%。此外，将TAS作为基础策略与残差强化学习（RL）结合，能大幅提升训练效率和性能上限。该方法的有效性已在仿真和物理机器人实验中得到证实。

Conclusion: TAS算法成功解决了动作分块在模仿学习中反应性不足的问题，通过动态选择机制，有效平衡了反应性、决策一致性和运动连贯性。这不仅显著提升了任务成功率，也为强化学习的训练效率和性能带来了实质性改善。

Abstract: Action chunking is a widely adopted approach in Learning from Demonstration
(LfD). By modeling multi-step action chunks rather than single-step actions,
action chunking significantly enhances modeling capabilities for human expert
policies. However, the reduced decision frequency restricts the utilization of
recent observations, degrading reactivity - particularly evident in the
inadequate adaptation to sensor noise and dynamic environmental changes.
Existing efforts to address this issue have primarily resorted to trading off
reactivity against decision consistency, without achieving both. To address
this limitation, we propose a novel algorithm, Temporal Action Selector (TAS),
which caches predicted action chunks from multiple timesteps and dynamically
selects the optimal action through a lightweight selector network. TAS achieves
balanced optimization across three critical dimensions: reactivity, decision
consistency, and motion coherence. Experiments across multiple tasks with
diverse base policies show that TAS significantly improves success rates -
yielding an absolute gain of up to 73.3%. Furthermore, integrating TAS as a
base policy with residual reinforcement learning (RL) substantially enhances
training efficiency and elevates the performance plateau. Experiments in both
simulation and physical robots confirm the method's efficacy.

</details>


### [156] [Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment](https://arxiv.org/abs/2511.04555)
*Tao Lin,Yilei Zhong,Yuxin Du,Jingjing Zhang,Jiting Liu,Yinxinyu Chen,Encheng Gu,Ziyan Liu,Hongyi Cai,Yanwen Zou,Lixing Zou,Zhaoye Zhou,Gen Li,Bo Zhao*

Main category: cs.RO

TL;DR: Evo-1是一种轻量级VLA模型，无需大规模机器人数据预训练，通过新颖的架构和两阶段训练范式，实现了高性能和高部署效率，并在多个基准测试和真实世界评估中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 当前的VLA模型参数量大，严重依赖大规模机器人数据预训练，导致训练成本高、实时推理部署受限。此外，大多数训练范式会损害视觉-语言骨干网络的感知表征，导致过拟合和下游任务泛化能力差。

Method: Evo-1构建于原生多模态视觉-语言模型（VLM）之上，融合了新颖的交叉调制扩散Transformer和一个优化的集成模块，形成有效的架构。它还引入了两阶段训练范式，逐步将动作与感知对齐，同时保留了VLM的表征。该模型仅有0.77亿参数，无需机器人数据预训练。

Result: Evo-1在Meta-World和RoboTwin套件上取得了最先进的结果，分别超越现有最佳模型12.4%和6.9%，在LIBERO上达到94.8%的竞争力结果。在真实世界评估中，Evo-1以高推理频率和低内存开销实现了78%的成功率，优于所有基线方法。

Conclusion: Evo-1证明了轻量级VLA模型可以在不进行机器人数据预训练的情况下，实现强大的性能和高效的部署。这为未来研究轻量级高效VLA模型提供了有前景的方向。

Abstract: Vision-Language-Action (VLA) models have emerged as a powerful framework that
unifies perception, language, and control, enabling robots to perform diverse
tasks through multimodal understanding. However, current VLA models typically
contain massive parameters and rely heavily on large-scale robot data
pretraining, leading to high computational costs during training, as well as
limited deployability for real-time inference. Moreover, most training
paradigms often degrade the perceptual representations of the vision-language
backbone, resulting in overfitting and poor generalization to downstream tasks.
In this work, we present Evo-1, a lightweight VLA model that reduces
computation and improves deployment efficiency, while maintaining strong
performance without pretraining on robot data. Evo-1 builds on a native
multimodal Vision-Language model (VLM), incorporating a novel cross-modulated
diffusion transformer along with an optimized integration module, together
forming an effective architecture. We further introduce a two-stage training
paradigm that progressively aligns action with perception, preserving the
representations of the VLM. Notably, with only 0.77 billion parameters, Evo-1
achieves state-of-the-art results on the Meta-World and RoboTwin suite,
surpassing the previous best models by 12.4% and 6.9%, respectively, and also
attains a competitive result of 94.8% on LIBERO. In real-world evaluations,
Evo-1 attains a 78% success rate with high inference frequency and low memory
overhead, outperforming all baseline methods. We release code, data, and model
weights to facilitate future research on lightweight and efficient VLA models.

</details>


### [157] [SAFe-Copilot: Unified Shared Autonomy Framework](https://arxiv.org/abs/2511.04664)
*Phat Nguyen,Erfan Aasi,Shiva Sreeram,Guy Rosman,Andrew Silva,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: 本文提出一个统一的共享自主驾驶框架，利用视觉语言模型（VLMs）从多模态线索推断驾驶员意图，并在更高抽象层次上整合人机控制，以提高自动驾驶在复杂场景下的鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在罕见、模糊和分布外场景中表现脆弱，而人类驾驶员能通过情境推理成功应对。现有共享自主方法将仲裁限制在低级轨迹，未能保留潜在的驾驶意图。

Method: 提出一个统一的共享自主框架，在更高抽象层次上整合人类输入和自主规划器。该方法利用视觉语言模型（VLMs）从驾驶员行为和环境上下文等多模态线索推断驾驶员意图，并合成协调人机控制的连贯策略。

Result: 在模拟人类设置中，该框架实现了完美的召回率以及高准确率和精确度。一项人类受试者调查显示，参与者在92%的案例中同意仲裁结果，表明高度一致性。在Bench2Drive基准测试中，与纯自主驾驶相比，碰撞率显著降低，整体性能得到改善。

Conclusion: 基于语义、语言表示的仲裁成为共享自主驾驶的设计原则，使系统能够进行常识推理并保持与人类意图的连续性。

Abstract: Autonomous driving systems remain brittle in rare, ambiguous, and
out-of-distribution scenarios, where human driver succeed through contextual
reasoning. Shared autonomy has emerged as a promising approach to mitigate such
failures by incorporating human input when autonomy is uncertain. However, most
existing methods restrict arbitration to low-level trajectories, which
represent only geometric paths and therefore fail to preserve the underlying
driving intent. We propose a unified shared autonomy framework that integrates
human input and autonomous planners at a higher level of abstraction. Our
method leverages Vision Language Models (VLMs) to infer driver intent from
multi-modal cues -- such as driver actions and environmental context -- and to
synthesize coherent strategies that mediate between human and autonomous
control. We first study the framework in a mock-human setting, where it
achieves perfect recall alongside high accuracy and precision. A human-subject
survey further shows strong alignment, with participants agreeing with
arbitration outcomes in 92% of cases. Finally, evaluation on the Bench2Drive
benchmark demonstrates a substantial reduction in collision rate and
improvement in overall performance compared to pure autonomy. Arbitration at
the level of semantic, language-based representations emerges as a design
principle for shared autonomy, enabling systems to exercise common-sense
reasoning and maintain continuity with human intent.

</details>


### [158] [Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions](https://arxiv.org/abs/2511.04665)
*Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li*

Main category: cs.RO

TL;DR: 本文提出一个实时到模拟的策略评估框架，通过从真实视频构建软体数字孪生，并使用3D高斯泼溅实现逼真渲染，从而实现可变形物体操作策略的可复现、可扩展和准确评估。


<details>
  <summary>Details</summary>
Motivation: 机器人操作策略的真实世界评估成本高、耗时且难以复现，尤其对于涉及可变形物体的任务。现有模拟器未能捕捉软体交互的视觉和物理复杂性。

Method: 该研究提出了一个实时到模拟的策略评估框架，通过从真实世界视频构建软体数字孪生，并使用3D高斯泼溅技术以逼真的保真度渲染机器人、物体和环境。

Result: 该方法在毛绒玩具打包、绳索布线和T型块推动等代表性可变形操作任务上进行了验证。结果表明，模拟执行与真实世界执行性能高度相关，并揭示了学习策略的关键行为模式。

Conclusion: 结合物理信息重建和高质量渲染，可以实现机器人操作策略的可复现、可扩展和准确评估。

Abstract: Robotic manipulation policies are advancing rapidly, but their direct
evaluation in the real world remains costly, time-consuming, and difficult to
reproduce, particularly for tasks involving deformable objects. Simulation
provides a scalable and systematic alternative, yet existing simulators often
fail to capture the coupled visual and physical complexity of soft-body
interactions. We present a real-to-sim policy evaluation framework that
constructs soft-body digital twins from real-world videos and renders robots,
objects, and environments with photorealistic fidelity using 3D Gaussian
Splatting. We validate our approach on representative deformable manipulation
tasks, including plush toy packing, rope routing, and T-block pushing,
demonstrating that simulated rollouts correlate strongly with real-world
execution performance and reveal key behavioral patterns of learned policies.
Our results suggest that combining physics-informed reconstruction with
high-quality rendering enables reproducible, scalable, and accurate evaluation
of robotic manipulation policies. Website: https://real2sim-eval.github.io/

</details>


### [159] [X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations](https://arxiv.org/abs/2511.04671)
*Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia*

Main category: cs.RO

TL;DR: X-Diffusion是一个利用前向扩散过程的框架，它通过在人类动作中添加噪声来模糊人类和机器人执行差异，从而有效地利用人类视频数据进行机器人学习，同时避免学习到机器人无法执行的动作，显著提高了操纵任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 人类视频是机器人学习的丰富训练数据来源，但人类和机器人身体结构（embodiment）的根本差异导致直接将人类动作映射到机器人上会产生不可行的动作。研究旨在解决如何在存在这种执行差异的情况下，有效利用人类演示数据。

Method: 核心思想是利用前向扩散过程：随着噪声的增加，低级执行差异会消失，而高级任务指导得以保留。X-Diffusion首先训练一个分类器来判断带噪声的动作是由人类还是机器人执行。然后，只有当人类动作被添加了足够的噪声，以至于分类器无法区分其来源时，才将其纳入策略训练。机器人动作用于监督低噪声水平下的精细去噪，而失配的人类动作则在高噪声水平下提供粗略指导。

Result: 实验表明，在执行不匹配的情况下进行简单协同训练会降低策略性能，而X-Diffusion持续改进了性能。在五项操纵任务中，X-Diffusion比最佳基线平均成功率高出16%。

Conclusion: X-Diffusion提供了一个原则性的框架，通过利用扩散过程来有效整合人类数据进行机器人学习，成功克服了人类与机器人之间执行不匹配的挑战。它在不学习动态不可行动作的前提下，最大限度地利用了人类演示数据，显著提升了机器人操纵任务的成功率。

Abstract: Human videos can be recorded quickly and at scale, making them an appealing
source of training data for robot learning. However, humans and robots differ
fundamentally in embodiment, resulting in mismatched action execution. Direct
kinematic retargeting of human hand motion can therefore produce actions that
are physically infeasible for robots. Despite these low-level differences,
human demonstrations provide valuable motion cues about how to manipulate and
interact with objects. Our key idea is to exploit the forward diffusion
process: as noise is added to actions, low-level execution differences fade
while high-level task guidance is preserved. We present X-Diffusion, a
principled framework for training diffusion policies that maximally leverages
human data without learning dynamically infeasible motions. X-Diffusion first
trains a classifier to predict whether a noisy action is executed by a human or
robot. Then, a human action is incorporated into policy training only after
adding sufficient noise such that the classifier cannot discern its embodiment.
Actions consistent with robot execution supervise fine-grained denoising at low
noise levels, while mismatched human actions provide only coarse guidance at
higher noise levels. Our experiments show that naive co-training under
execution mismatches degrades policy performance, while X-Diffusion
consistently improves it. Across five manipulation tasks, X-Diffusion achieves
a 16% higher average success rate than the best baseline. The project website
is available at https://portal-cornell.github.io/X-Diffusion/.

</details>


### [160] [GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction](https://arxiv.org/abs/2511.04679)
*Qingzhou Lu,Yao Feng,Baiyu Shi,Michael Piseno,Zhenan Bao,C. Karen Liu*

Main category: cs.RO

TL;DR: 该论文提出GentleHumanoid框架，通过将阻抗控制融入全身运动跟踪策略，使仿人机器人在与人交互时能实现上身柔顺性，从而实现安全自然的物理交互。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习策略通常强调刚性跟踪并抑制外部力，而现有的阻抗增强方法通常局限于基座或末端执行器控制，并侧重于抵抗极端力而非实现柔顺性，这阻碍了仿人机器人在以人为中心的环境中进行安全自然的物理交互。

Method: 引入GentleHumanoid框架，将阻抗控制集成到全身运动跟踪策略中，以实现上身柔顺性。核心是一个统一的基于弹簧的公式，用于模拟抵抗性接触（按压表面时的恢复力）和引导性接触（来自人类运动数据的推拉力）。该公式确保了肩部、肘部和手腕之间运动学上一致的力，并使策略能够应对多样化的交互场景。通过任务可调的力阈值进一步支持安全性。

Result: 在模拟和Unitree G1仿人机器人上，对于需要不同柔顺性水平的任务（如轻柔拥抱、站立辅助和安全物体操作），与基线相比，该策略在保持任务成功的同时，始终能降低峰值接触力，从而实现更平滑、更自然的交互。

Conclusion: 这些结果标志着仿人机器人在真实世界环境中安全有效地与人类协作并处理物体方面迈出了重要一步。

Abstract: Humanoid robots are expected to operate in human-centered environments where
safe and natural physical interaction is essential. However, most recent
reinforcement learning (RL) policies emphasize rigid tracking and suppress
external forces. Existing impedance-augmented approaches are typically
restricted to base or end-effector control and focus on resisting extreme
forces rather than enabling compliance. We introduce GentleHumanoid, a
framework that integrates impedance control into a whole-body motion tracking
policy to achieve upper-body compliance. At its core is a unified spring-based
formulation that models both resistive contacts (restoring forces when pressing
against surfaces) and guiding contacts (pushes or pulls sampled from human
motion data). This formulation ensures kinematically consistent forces across
the shoulder, elbow, and wrist, while exposing the policy to diverse
interaction scenarios. Safety is further supported through task-adjustable
force thresholds. We evaluate our approach in both simulation and on the
Unitree G1 humanoid across tasks requiring different levels of compliance,
including gentle hugging, sit-to-stand assistance, and safe object
manipulation. Compared to baselines, our policy consistently reduces peak
contact forces while maintaining task success, resulting in smoother and more
natural interactions. These results highlight a step toward humanoid robots
that can safely and effectively collaborate with humans and handle objects in
real-world environments.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [161] [On excitation of control-affine systems and its use for data-driven Koopman approximants](https://arxiv.org/abs/2511.03734)
*Philipp Schmitz,Lea Bold,Friedrich M. Philipp,Mario Rosenfelder,Peter Eberhard,Henrik Ebel,Karl Worthmann*

Main category: eess.SY

TL;DR: 本文提出了一种数据拟合框架，用于提高控制仿射映射的鲁棒性，从而改善双线性扩展动态模式分解（EDMD）方案的可靠性。通过基于子空间角度的输入选择指南和最大化最小奇异值的最优性条件，解决了控制仿射系统在双线性代理模型中数据需求高的问题，并以非完整机器人为例进行了验证。


<details>
  <summary>Details</summary>
Motivation: Koopman算子和EDMD是复杂动力系统建模、分析和控制的关键工具。然而，将其扩展到控制仿射系统时，产生的双线性代理模型对数据要求很高，导致其适用性复杂。

Method: 本文提出了一种用于控制仿射映射数据拟合的框架，以提高相关系统识别问题的鲁棒性。具体方法包括：1) 基于子空间角度推导出输入选择指南，以确保最小奇异值达到期望阈值。2) 推导出最大化最小奇异值的必要和充分最优性条件。

Result: 所提出的框架提高了系统识别问题的鲁棒性，从而提供了更可靠的双线性EDMD方案。通过基于子空间角度的输入选择指南，可以确保达到期望的最小奇异值阈值。此外，还推导了最大化最小奇异值的必要和充分最优性条件。该方法在非完整机器人的双线性EDMD控制中得到了有效验证。

Conclusion: 通过提出一个数据拟合框架、基于子空间角度的输入选择指南以及最大化最小奇异值的最优性条件，本文成功提高了控制仿射系统双线性EDMD方案的鲁棒性和可靠性，有效解决了其数据需求高的问题。

Abstract: The Koopman operator and extended dynamic mode decomposition (EDMD) as a
data-driven technique for its approximation have attracted considerable
attention as a key tool for modeling, analysis, and control of complex
dynamical systems. However, extensions towards control-affine systems resulting
in bilinear surrogate models are prone to demanding data requirements rendering
their applicability intricate. In this paper, we propose a framework for
data-fitting of control-affine mappings to increase the robustness margin in
the associated system identification problem and, thus, to provide more
reliable bilinear EDMD schemes. In particular, guidelines for input selection
based on subspace angles are deduced such that a desired threshold with respect
to the minimal singular value is ensured. Moreover, we derive necessary and
sufficient conditions of optimality for maximizing the minimal singular value.
Further, we demonstrate the usefulness of the proposed approach using bilinear
EDMD with control for non-holonomic robots.

</details>


### [162] [Hybrid ILM-NILM Smart Plug System](https://arxiv.org/abs/2511.03737)
*Dániel István Németh,Kálmán Tornai*

Main category: eess.SY

TL;DR: 该论文提出一种混合式负载分类方案，通过扩展智能插座支持多负载连接，以降低安装成本并处理家庭中常见的排插连接场景。


<details>
  <summary>Details</summary>
Motivation: 现有的侵入式和非侵入式负载分类方法各有优缺点，但很少有结合两者的方案。侵入式智能插座提供精细控制但成本高，而非侵入式成本低但无法单独控制。此外，智能插座通常只考虑单个负载，而家庭中通过延长线连接多个负载的情况很常见，但文献中鲜有涉及。

Method: 本文提出一种混合负载分类解决方案，该方案扩展了基于智能插座的解决方案，使其能够支持每个插座连接多个负载。这种方法以降低控制粒度为代价，实现了系统安装成本的降低。同时，该方案也能处理通过延长线连接多种负载的常见家庭场景。

Result: 论文表明，将基于智能插座的解决方案扩展到每个插座连接多个负载，可以在降低系统安装成本的同时，降低控制粒度。此外，所提出的混合负载分类解决方案能够处理通过延长线连接多个负载的常见家庭场景。

Conclusion: 通过扩展智能插座以支持多负载连接的混合式负载分类方案，可以在控制粒度和系统安装成本之间取得平衡，并有效解决家庭中常见的通过延长线连接多个电器的问题。

Abstract: Electrical load classification is generally divided into intrusive and
non-intrusive approaches, both having their limitations and advantages. With
the non-intrusive approach, controlling appliances is not possible, but the
installation cost of a single measurement device is cheap. In comparison,
intrusive, smart plug-based solutions offer individual appliance control, but
the installation cost is much higher. There have been very few approaches
aiming to combine these methods. In this paper we show that extending a smart
plug-based solution to multiple loads per plug can reduce control granularity
in favor of lowering the system's installation costs. Connecting various loads
to a Smart Plug through an extension cord is seldom considered in the
literature, even though it is common in households. This scenario is also
handled by the hybrid load classification solution presented in this paper.

</details>


### [163] [Kalman-Bucy Filtering with Randomized Sensing: Fundamental Limits and Sensor Network Design for Field Estimation](https://arxiv.org/abs/2511.03740)
*Xinyi Wang,Devansh R. Agrawal,Dimitra Panagou*

Main category: eess.SY

TL;DR: 本文针对连续时间卡尔曼滤波器在随机测量丢失情况下的稳定性进行了分析，推导了期望估计协方差和清晰度的闭式界限，为传感器网络设计提供了基础性指导。


<details>
  <summary>Details</summary>
Motivation: 现有关于卡尔曼滤波器在随机测量丢失下稳定性的研究多集中于离散时间框架。本文旨在建立一个更通用的连续时间框架，其中测量矩阵和噪声协方差也作为随机过程演化，以更真实地捕捉传感位置的变异性。

Method: 1. 在广义连续时间框架下，推导了连续时间卡尔曼滤波器期望估计协方差的闭式上限。2. 将此框架应用于时空场估计，将场建模为高斯过程，由随机定位的噪声传感器观测。3. 利用“清晰度”（之前工作中引入的微分熵的重标形式），建立了空间平均期望清晰度的与网格无关的下限。

Result: 1. 得到了连续时间卡尔曼滤波器期望估计协方差的闭式上限。2. 建立了空间平均期望清晰度的与网格无关的下限，通过一个综合感知参数（结合传感器数量、噪声水平和测量频率）揭示了基本的性能限制。3. 仿真证实，所提出的界限对于离散时间卡尔曼滤波器是紧密的，尤其是在测量速率降低时，并避免了离散时间公式所需的递归计算。

Conclusion: 所推导的性能界限为传感器网络在部署前期的设计问题提供了有原则且高效的指导方针。

Abstract: Stability analysis of the Kalman filter under randomly lost measurements has
been widely studied. We revisit this problem in a general continuous-time
framework, where both the measurement matrix and noise covariance evolve as
random processes, capturing variability in sensing locations. Within this
setting, we derive a closed-form upper bound on the expected estimation
covariance for continuous-time Kalman filtering. We then apply this framework
to spatiotemporal field estimation, where the field is modeled as a Gaussian
process observed by randomly located, noisy sensors. Using clarity, introduced
in our earlier work as a rescaled form of the differential entropy of a random
variable, we establish a grid-independent lower bound on the spatially averaged
expected clarity. This result exposes fundamental performance limits through a
composite sensing parameter that jointly captures the effects of the number of
sensors, noise level, and measurement frequency. Simulations confirm that the
proposed bound is tight for the discrete-time Kalman filter, approaching it as
the measurement rate decreases, while avoiding the recursive computations
required in the discrete-time formulation. Most importantly, the derived limits
provide principled and efficient guidelines for sensor network design problem
prior to deployment.

</details>


### [164] [Electric Vehicle Charging Load Modeling: A Survey, Trends, Challenges and Opportunities](https://arxiv.org/abs/2511.03741)
*Xiachong Lin,Arian Prabowo,Imran Razzak,Hao Xue,Matthew Amos,Sam Behrens,Flora D. Salim*

Main category: eess.SY

TL;DR: 本文全面回顾了过去五年电动汽车充电负荷模型，系统分析了统计、模拟和数据驱动方法，并探讨了信息融合在模型中的应用，指出了未来的挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 电动汽车普及推动可持续交通发展，但其充电行为的不确定性给基础设施规划带来挑战。现有文献综述缺乏对侧重信息融合的建模方法的系统分析，因此需要对充电负荷模型进行全面回顾。

Method: 本文对过去五年电动汽车充电负荷模型进行了全面综述。将现有建模方法归类为统计、模拟和数据驱动方法，并分析了各自的优缺点。此外，还分析了现有模型中信息融合的三个自下而上的操作层次。

Result: 论文对最先进的充电负荷建模方法进行了分类（统计、模拟、数据驱动），并探讨了它们的优缺点。同时，分析了现有模型中信息融合的三种自下而上的操作级别。

Conclusion: 文章总结了该领域面临的挑战和机遇，为未来的研究工作提供了指导，以增进理解并探索实用的研究方向。

Abstract: The evolution of electric vehicles (EVs) is reshaping the automotive
industry, advocating for more sustainable transportation practices. Accurately
predicting EV charging behavior is essential for effective infrastructure
planning and optimization. However, the charging load of EVs is significantly
influenced by uncertainties and randomness, posing challenges for accurate
estimation. Furthermore, existing literature reviews lack a systematic analysis
of modeling approaches focused on information fusion. This paper
comprehensively reviews EV charging load models from the past five years. We
categorize state-of-the-art modeling methods into statistical, simulated, and
data-driven approaches, examining the advantages and drawbacks of each.
Additionally, we analyze the three bottom-up level operations of information
fusion in existing models. We conclude by discussing the challenges and
opportunities in the field, offering guidance for future research endeavors to
advance our understanding and explore practical research directions.

</details>


### [165] [A Model-Based Approach to Automated Digital Twin Generation in Manufacturing](https://arxiv.org/abs/2511.03742)
*Angelos Alexopoulos,Agorakis Bompotas,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Athanasios P. Kalogeras,Christos Alexakos*

Main category: eess.SY

TL;DR: 本文提出一个新颖的平台，利用AutomationML自动化数字孪生生成与部署，并通过GAI驱动的仿真场景生成器和物理产线自动重构，实现制造过程的闭环，提高效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 现代制造业要求高灵活性和可重构性以适应动态生产需求。模型化工程（MBE）支持快速产线设计，但最终重构需要仿真和验证。数字孪生（DTs）通过实时监控、仿真和重构简化了这一过程。

Method: 该平台通过基于AutomationML的工厂规划自动化数字孪生（DT）的生成和部署。它还集成了一个由GAI（生成式人工智能）驱动的仿真场景生成器，并支持物理产线的自动重构，从而形成闭环。

Result: 该平台通过自动化数字孪生生成、部署、GAI驱动的仿真和自动物理产线重构，显著提高了制造过程的效率和适应性。

Conclusion: 所提出的平台通过自动化数字孪生生成与部署，并结合GAI驱动的仿真场景生成和物理产线自动重构，成功实现了制造过程的闭环，从而提升了制造效率和适应性。

Abstract: Modern manufacturing demands high flexibility and reconfigurability to adapt
to dynamic production needs. Model-based Engineering (MBE) supports rapid
production line design, but final reconfiguration requires simulations and
validation. Digital Twins (DTs) streamline this process by enabling real-time
monitoring, simulation, and reconfiguration. This paper presents a novel
platform that automates DT generation and deployment using AutomationML-based
factory plans. The platform closes the loop with a GAI-powered simulation
scenario generator and automatic physical line reconfiguration, enhancing
efficiency and adaptability in manufacturing.

</details>


### [166] [A convolutional neural network deep learning method for model class selection](https://arxiv.org/abs/2511.03743)
*Marios Impraimakis*

Main category: eess.SY

TL;DR: 本文提出一种新颖的深度一维卷积神经网络方法，仅利用响应信号即可进行模型类别选择，并通过卡尔曼滤波器增强，在结构健康监测中对线性和非线性系统均有效。


<details>
  <summary>Details</summary>
Motivation: 研究如何仅利用系统响应信号及其类别信息，在无需系统输入或完整系统识别的情况下，选择新信号的模型类别，以应用于结构健康监测。

Method: 使用来自单一自由度的响应及其类别信息训练和验证一维卷积神经网络。该网络能够为新的、未标记的信号选择模型类别，无需系统输入信息或完整的系统识别。此外，还探索了一种可选的基于物理的算法增强方法，即使用卡尔曼滤波器通过加速度和位移数据的运动学约束来融合系统响应信号。

Result: 该方法被证明能够识别由阻尼行为或滞后行为引起的微小信号变化，成功选择模型类别。它在线性和非线性动态系统上以及在三维建筑有限元模型上均有效。

Conclusion: 该方法为结构健康监测应用提供了一个强大的工具，能够有效地进行模型类别选择。

Abstract: The response-only model class selection capability of a novel deep
convolutional neural network method is examined herein in a simple, yet
effective, manner. Specifically, the responses from a unique degree of freedom
along with their class information train and validate a one-dimensional
convolutional neural network. In doing so, the network selects the model class
of new and unlabeled signals without the need of the system input information,
or full system identification. An optional physics-based algorithm enhancement
is also examined using the Kalman filter to fuse the system response signals
using the kinematics constraints of the acceleration and displacement data.
Importantly, the method is shown to select the model class in slight signal
variations attributed to the damping behavior or hysteresis behavior on both
linear and nonlinear dynamic systems, as well as on a 3D building finite
element model, providing a powerful tool for structural health monitoring
applications.

</details>


### [167] [Predictive Compensation in Finite-Horizon LQ Games under Gauss-Markov Deviations](https://arxiv.org/abs/2511.03744)
*Navid Mojahed,Mahdis Rabbani,Shima Nazari*

Main category: eess.SY

TL;DR: 本文提出了一种预测补偿框架，用于处理有限时域离散时间线性二次动态博弈中，当一方存在高斯-马尔可夫偏差时，另一方进行补偿。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决动态博弈中，当一方玩家偏离反馈纳什策略时，其偏差表现为相关随机过程（高斯-马尔可夫），另一方如何通过预测策略进行有效补偿以提高性能。

Method: 该研究通过一阶自回归过程建模一方玩家的相关随机偏差。另一方则采用预测策略进行补偿，该策略能预见未来相关性的影响。文章推导了均值和协方差传播的闭式递归公式。

Result: 研究结果包括推导了均值和协方差传播的闭式递归公式，并通过预期成本的敏感性分析了由此带来的性能改进。

Conclusion: 该预测补偿框架能有效应对动态博弈中存在相关随机偏差的情况，通过预测未来相关性，显著提高了补偿方的博弈性能。

Abstract: This paper presents a predictive compensation framework for finite-horizon
discrete-time linear quadratic dynamic games in the presence of Gauss-Markov
deviations from feedback Nash strategies. One player experiences correlated
stochastic deviations, modeled via a first-order autoregressive process, while
the other compensates using a predictive strategy that anticipates the effect
of future correlation. Closed-form recursions for mean and covariance
propagation are derived, and the resulting performance improvement is analyzed
through the sensitivity of expected cost.

</details>


### [168] [InvSim algorithm for pre-computing airplane flight controls in limited-range autonomous missions, and demonstration via double-roll maneuver of Mirage III fighters](https://arxiv.org/abs/2511.03745)
*Osama A. Marzouk*

Main category: eess.SY

TL;DR: 本文提出了一种针对六自由度固定翼飞机运动方程的逆向仿真方法，用于预测实现预定飞行轨迹所需的控制输入。


<details>
  <summary>Details</summary>
Motivation: 传统飞行仿真通常根据控制输入预测飞行轨迹，而逆向仿真旨在根据目标飞行轨迹反向计算所需的飞行控制，这对于飞行规划和控制设计具有重要意义。

Method: 研究首先建立了一个通用的六自由度飞行力学运动方程数学框架，包括机体轴、惯性轴、风轴以及球坐标系下的飞行路径角和飞行角。随后，将这些方程修改以适应逆向仿真。数值求解过程结合了符号数学、显式四阶龙格-库塔（RK4）数值积分技术和基于有限差分法（FDM）的表达式，以计算发动机推力、副翼、升降舵和方向舵的偏转角等四个控制变量。

Result: 该方法能够计算出在整个机动时间内离散的控制变量值，这些计算出的控制值能使飞机实现由三个惯性笛卡尔坐标和欧拉滚转角所定义的期望飞行轨迹。

Conclusion: 本文成功展示了一种飞行力学逆向仿真（InvSim）的数值过程，能够有效预测实现特定飞行轨迹所需的飞行控制输入。

Abstract: In this work, we start with a generic mathematical framework for the
equations of motion (EOM) in flight mechanics with six degrees of freedom
(6-DOF) for a general (not necessarily symmetric) fixed-wing aircraft. This
mathematical framework incorporates (1) body axes (fixed in the airplane at its
center of gravity), (2) inertial axes (fixed in the earth/ground at the
take-off point), wind axes (aligned with the flight path/course), (3) spherical
flight path angles (azimuth angle measured clockwise from the geographic north,
and elevation angle measured above the horizon plane), and (4) spherical flight
angles (angle of attack and sideslip angle). We then manipulate these equations
of motion to derive a customized version suitable for inverse simulation flight
mechanics, where a target flight trajectory is specified while a set of
corresponding necessary flight controls to achieve that maneuver are predicted.
We then present a numerical procedure for integrating the developed inverse
simulation (InvSim) system in time; utilizing (1) symbolic mathematics, (2)
explicit fourth-order Runge-Kutta (RK4) numerical integration technique, and
(3) expressions based on the finite difference method (FDM); such that the four
necessary control variables (engine thrust force, ailerons' deflection angle,
elevators' deflection angle, and rudder's deflection angle) are computed as
discrete values over the entire maneuver time, and these calculated control
values enable the airplane to achieve the desired flight trajectory, which is
specified by three inertial Cartesian coordinates of the airplane, in addition
to the Euler's roll angle. We finally demonstrate the proposed numerical
procedure of flight mechanics inverse simulation (InvSim).

</details>


### [169] [A Dynamic Recurrent Adjacency Memory Network for Mixed-Generation Power System Stability Forecasting](https://arxiv.org/abs/2511.03746)
*Guang An Ooi,Otavio Bertozzi,Mohd Asim Aftab,Charalambos Konstantinou,Shehab Ahmed*

Main category: eess.SY

TL;DR: 本文提出了一种名为DRAMN的动态循环邻接记忆网络，结合物理信息分析和深度学习，用于实时电力系统稳定性预测，并在复杂现代电网中实现了高精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统由于逆变器并网比例高，动态行为复杂，传统稳定性评估方法在可扩展性和通用性方面面临挑战。

Method: DRAMN框架通过滑动窗口动态模态分解，从相量测量单元和传感器数据构建时变多层邻接矩阵，捕捉系统动态（如模态参与因子、耦合强度、相位关系和频谱能量分布）。它将图卷积操作直接集成到循环门控机制中，同时建模演化动态和时间依赖性，而非单独处理空间和时间依赖。

Result: 在修改后的IEEE 9-bus、39-bus和多端HVDC网络上，DRAMN分别实现了99.85%、99.90%和99.69%的平均准确率，超越了所有测试基准。该框架能识别最佳测量组合，将特征维度降低82%而性能不下降。通过对小信号和暂态稳定事件的主导测量进行相关性分析，验证了其在不同稳定性现象上的通用性。

Conclusion: DRAMN在电力系统稳定性预测中实现了最先进的准确性，并为电力系统运营商提供了增强的可解释性，使其适用于现代控制中心的实时部署。

Abstract: Modern power systems with high penetration of inverter-based resources
exhibit complex dynamic behaviors that challenge the scalability and
generalizability of traditional stability assessment methods. This paper
presents a dynamic recurrent adjacency memory network (DRAMN) that combines
physics-informed analysis with deep learning for real-time power system
stability forecasting. The framework employs sliding-window dynamic mode
decomposition to construct time-varying, multi-layer adjacency matrices from
phasor measurement unit and sensor data to capture system dynamics such as
modal participation factors, coupling strengths, phase relationships, and
spectral energy distributions. As opposed to processing spatial and temporal
dependencies separately, DRAMN integrates graph convolution operations directly
within recurrent gating mechanisms, enabling simultaneous modeling of evolving
dynamics and temporal dependencies. Extensive validations on modified IEEE
9-bus, 39-bus, and a multi-terminal HVDC network demonstrate high performance,
achieving 99.85\%, 99.90\%, and 99.69\% average accuracies, respectively,
surpassing all tested benchmarks, including classical machine learning
algorithms and recent graph-based models. The framework identifies optimal
combinations of measurements that reduce feature dimensionality by 82\% without
performance degradation. Correlation analysis between dominant measurements for
small-signal and transient stability events validates generalizability across
different stability phenomena. DRAMN achieves state-of-the-art accuracy while
providing enhanced interpretability for power system operators, making it
suitable for real-time deployment in modern control centers.

</details>


### [170] [Analytical modelling of a stop-less modular bus service with an application to charging strategies comparison](https://arxiv.org/abs/2511.03754)
*Haoran Zhao,Neema Nassir,Andres Fielbaum*

Main category: eess.SY

TL;DR: 本研究为整合车对车（V2V）充电技术的无停靠自主模块化（SLAM）公交服务开发了分析优化模型，并识别了在不同乘客量和充电策略下（包括移动充电）的运营阶段序列。


<details>
  <summary>Details</summary>
Motivation: 传统公交服务效率低下，尤其是在停车时间过长方面，这增加了非下车乘客的行程时间。SLAM公交服务作为一种解决方案出现，旨在通过动态容量减少停车时间。同时，公交电动化虽然有助于减排和降低成本，但也引入了充电需求带来的新的运营限制。

Method: 本研究开发了分析优化模型，用于整合车对车（V2V）充电技术的SLAM公交服务。通过比较非充电情况和不同充电策略下的最优设计及其可行性，来分析运营阶段。

Result: 研究识别了随着乘客量增长的运营阶段序列：从低需求下的闲置运力，到满载小巴，再到满载大巴，以及一个建议的频率受限制度，在此制度下仅扩大公交容量。在移动充电策略下，这一进展进一步包括一个能量受限制度（频率下降），并最终在高需求下导致不可行。

Conclusion: 这些研究结果使运营商能够提供更高效的服务，特别是在考虑SLAM公交的电动化和V2V充电技术时。

Abstract: Buses are a vital component of metropolitan public transport, yet
conventional bus services often struggle with inefficiencies including extended
dwelling time, which increases in-vehicle travel time for non-alighting
passengers. A stop-less autonomous modular (SLAM) bus service has emerged as a
solution, enabling dynamic capacity to reduce dwelling time. Meanwhile, the
electrification of buses is advancing as a strategy to mitigate greenhouse gas
emissions and reduces operators' costs, but introduces new operational
constraints due to charging requirements. This study develops analytical
optimization models for SLAM bus service that integrates vehicle-to-vehicle
(V2V) charging technology. By comparing the optimal designs and their
feasibility across non-charging case and charging strategies, we identify a
sequence of operational stages as ridership grows: from idle capacity under low
demand, to full small buses, full large buses, and a proposed frequency-capped
regime where only bus capacity expands. Under the mobile charging strategy,
this progression further includes an energy-limited regime, in which frequency
declines, and ultimately infeasibility under high demand. These findings enable
operators to deliver more efficient services.

</details>


### [171] [Removing Time-Scale Separation in Feedback-Based Optimization via Estimators](https://arxiv.org/abs/2511.03903)
*Niloufar Yousefi,John W. Simpson-Porco*

Main category: eess.SY

TL;DR: 传统反馈优化（FBO）受限于控制器与系统的时间尺度分离，影响性能。本文提出一种基于估计器的FBO改进方法，利用动态系统模型信息消除该限制，显著提高收敛速度，并适用于近似模型情况，应用于电力系统频率控制。


<details>
  <summary>Details</summary>
Motivation: 传统的反馈优化（FBO）框架要求控制器操作时间尺度远慢于被控系统，这严重限制了闭环系统的性能。研究动机在于克服这一时间尺度分离要求，以实现更快的闭环收敛速度和更好的性能。

Method: 提出一种基于估计器的反馈优化（FBO）修改方法。该方法利用动态系统模型信息来消除传统FBO的时间尺度分离要求。此外，该方法还被扩展到仅有近似系统模型的情况，特别是针对奇异摄动系统。

Result: 所提出的方法成功消除了传统FBO所需的时间尺度分离要求。闭环系统的收敛速度仅受开环系统主导特征值限制，显著优于传统FBO的性能。该方法在逆变器基资源快速电力系统频率控制中得到应用验证。

Conclusion: 通过引入基于估计器的修改，FBO可以消除其固有的时间尺度分离限制，从而实现更快的收敛速度和更高的闭环性能。即使在只有近似系统模型的情况下，该方法也具有鲁棒性，并在实际应用中展现了潜力，如电力系统频率控制。

Abstract: Feedback-based optimization (FBO) provides a simple control framework for
regulating a stable dynamical system to the solution of a constrained
optimization problem in the presence of exogenous disturbances, and does so
without full knowledge of the plant dynamics. However, closed-loop stability
requires the controller to operate on a sufficiently slower timescale than the
plant, significantly constraining achievable closed-loop performance. Motivated
by this trade-off, we propose an estimator-based modification of FBO which
leverages dynamic plant model information to eliminate the time-scale
separation requirement of traditional FBO. Under this design, the convergence
rate of the closed-loop system is limited only by the dominant eigenvalue of
the open-loop system. We extend the approach to the case of design based on
only an approximate plant model when the original system is singularly
perturbed. The results are illustrated via an application to fast power system
frequency control using inverter-based resources.

</details>


### [172] [A Co-simulation Framework for Quadrotor Control System Design using ROS 2 and MATLAB/Simulink](https://arxiv.org/abs/2511.03969)
*Hangyu Teng*

Main category: eess.SY

TL;DR: 本文提出一个集成ROS 2和MATLAB/Simulink的四旋翼无人机控制系统协同仿真框架，用于设计与验证，并展示了其在快速原型和SIL验证中的有效性。


<details>
  <summary>Details</summary>
Motivation: 协同仿真对复杂信息物理系统的设计和分析至关重要，能提高开发效率并降低成本。

Method: 首先，基于牛顿-欧拉方程精确推导了四旋翼无人机的六自由度非线性动力学模型。其次，设计并实现了分层控制架构：姿态控制采用LQR控制器以实现最优调节性能，位置控制采用PID控制器以确保鲁棒性和实用性。最后，详细阐述了协同仿真框架的架构，包括跨平台数据交换机制的实现细节。

Result: 仿真结果证明了该框架的有效性。

Conclusion: 该框架为无人机控制算法的快速原型设计和软件在环（SIL）验证提供了一个高效、标准化的解决方案。

Abstract: Co-simulation is a critical approach for the design and analysis of complex
cyber-physical systems. It will enhance development efficiency and reduce
costs. This paper presents a co-simulation framework integrating ROS 2 and
MATLAB/Simulink for quadrotor unmanned aerial vehicle (UAV) control system
design and verification. First, a six-degree-of-freedom nonlinear dynamic model
of the quadrotor is derived accurately that based on Newton-Euler equations.
Second, within the proposed framework, a hierarchical control architecture was
designed and implemented: LQR controller for attitude control to achieve
optimal regulation performance, and PID controller for position control to
ensure robustness and practical applicability. Third, elaborated the
architecture of the framework, including the implementation details of the
cross-platform data exchange mechanism. Simulation results demonstrate the
effectiveness of the framework, highlighting its capability to provide an
efficient and standardized solution for rapid prototyping and
Software-in-the-Loop (SIL) validation of UAV control algorithms.

</details>


### [173] [Necessary and Sufficient Conditions for the Optimization-Based Concurrent Execution of Learned Robotic Tasks](https://arxiv.org/abs/2511.04054)
*Sheikh A. Tahmid,Gennaro Notomista*

Main category: eess.SY

TL;DR: 本研究提出了在优化框架下并发执行多个通过强化学习学习到的任务（由值函数编码）的充要条件，并扩展了该框架以兼容带折扣因子的值函数。


<details>
  <summary>Details</summary>
Motivation: 先前的研究虽然开发了基于优化的多任务执行框架，但未能解决一个基本问题：何时可以并发执行学习到的值函数。

Method: 本研究使用一个先前提出的最小范数控制器，推导并提出了关于在状态空间子集内并发执行学习任务集合的充要条件定理。此外，还扩展了基于优化的框架，使其能够处理使用折扣因子训练的值函数，从而更兼容标准的强化学习实践。

Result: 研究提供了关于何时可以将学习到的控制任务并发执行、何时它们可能本身就可并发执行以及何时完全不可能并发执行的深入见解。同时，通过兼容折扣因子，使整体框架与标准RL实践更加兼容。

Conclusion: 本研究通过提供并发执行学习任务的充要条件，并扩展框架以兼容折扣因子，显著推进了基于优化框架下的多任务强化学习，解决了先前框架中的一个关键未解问题。

Abstract: In this work, we consider the problem of executing multiple tasks encoded by
value functions, each learned through Reinforcement Learning, using an
optimization-based framework. Prior works develop such a framework, but left
unanswered a fundamental question of when learned value functions can be
concurrently executed. The main contribution of this work is to present
theorems which provide necessary and sufficient conditions to concurrently
execute sets of learned tasks within subsets of the state space, using a
previously proposed min-norm controller. These theorems provide insight into
when learned control tasks are possible to be made concurrently executable,
when they might already inherently be concurrently executable and when it is
not possible at all to make a set of learned tasks concurrently executable
using the previously proposed methods. Additional contributions of this work
include extending the optimization-based framework to execute multiple tasks
encoded by value functions to also account for value functions trained with a
discount factor, making the overall framework more compatible with standard RL
practices.

</details>


### [174] [Differential Flatness of Quasi-Static Slider-Pusher Models with Applications in Control](https://arxiv.org/abs/2511.04246)
*Sander De Witte,Tom Lefebvre,Thomas Neve,Andras Retzler,Guillaume Crevecoeur*

Main category: eess.SY

TL;DR: 本文研究了平面推杆-滑块系统的动力学特性，构建了准静态模型，发现其具有微分平坦性，并提出了两种控制策略进行轨迹跟踪，通过仿真和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究平面推杆-滑块系统作为操作任务中的基本运动原语的动态特性，并为其开发有效的控制策略。

Method: 构建了基于极限表面方法、准静态假设和可忽略接触摩擦的微分运动学模型，适用于通用滑块形状和圆形推杆。分析了系统的微分平坦性。提出了两种控制策略：级联准静态反馈策略和动态反馈线性化方法。通过闭环仿真和物理实验验证了这些策略。

Result: 具有多边形滑块和圆形推杆的推杆-滑块系统表现出微分平坦性，其质心是一个平坦输出。所提出的两种控制策略（级联准静态反馈和动态反馈线性化）在有扰动模型和输入噪声的仿真以及实际物理设置中都得到了验证，仿真增益适用于实际实验。

Conclusion: 所提出的控制方法利用了平面推杆-滑块系统的微分平坦性，在轨迹跟踪方面表现出潜力，并通过仿真和实际实验得到了有效验证。

Abstract: This paper investigates the dynamic properties of planar slider-pusher
systems as a motion primitive in manipulation tasks. To that end, we construct
a differential kinematic model deriving from the limit surface approach under
the quasi-static assumption and with negligible contact friction. The
quasi-static model applies to generic slider shapes and circular pusher
geometries, enabling a differential kinematic representation of the system.
From this model, we analyze differential flatness - a property advantageous for
control synthesis and planning - and find that slider-pusher systems with
polygon sliders and circular pushers exhibit flatness with the centre of mass
as a flat output. Leveraging this property, we propose two control strategies
for trajectory tracking: a cascaded quasi-static feedback strategy and a
dynamic feedback linearization approach. We validate these strategies through
closed-loop simulations incorporating perturbed models and input noise, as well
as experimental results using a physical setup with a finger-like pusher and
vision-based state detection. The real-world experiments confirm the
applicability of the simulation gains, highlighting the potential of the
proposed methods for

</details>


### [175] [Data-Driven Modeling of Photosynthesis Regulation Under Oscillating Light Condition - Part I: In-Silico Exploration](https://arxiv.org/abs/2511.04330)
*Christian Portilla,Arviandy G Aribowo,Ramachandran Anantharaman,César A Gómez-Pérez,Leyla Özkan*

Main category: eess.SY

TL;DR: 本文利用数据驱动的系统辨识技术，基于物理模型仿真数据，在频域内为振荡光照下光合作用调控建立了简化、面向控制的线性时不变（LTI）和线性参数变化（LPV）模型。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了获得简化且便于控制设计的模型，以描述振荡光照条件下光合作用的调控机制，这比复杂的物理模型更适合控制应用。

Method: 研究方法包括：1. 使用基于物理的Basic DREAM Model (BDM) 生成仿真数据集，输入为包含直流（DC）和交流（AC）分量的光强度信号，输出为叶绿素荧光（ChlF）。2. 采用最佳线性近似（BLA）方法，在不同操作条件下（由光强度的DC水平和调制频率定义）估计二阶线性时不变（LTI）传递函数模型。3. 基于这些局部模型，构建了一个线性参数变化（LPV）表示，其中调度参数由光强度的DC值定义。

Result: 主要结果是获得了在不同操作条件下光合作用调控的二阶LTI传递函数模型，并构建了一个以光强度DC值为调度参数的紧凑LPV状态空间表示，用于描述系统动力学。

Conclusion: 结论是成功地运用数据驱动的系统辨识技术，在频域内为振荡光照下的光合作用调控开发了简化的、面向控制的LTI和LPV模型。

Abstract: This paper explores the application of data-driven system identification
techniques in the frequency domain to obtain simplified, control-oriented
models of photosynthesis regulation under oscillating light conditions.
In-silico datasets are generated using simulations of the physics-based Basic
DREAM Model (BDM) Funete et al.[2024], with light intensity signals --
comprising DC (static) and AC (modulated) components as input and chlorophyll
fluorescence (ChlF) as output. Using these data, the Best Linear Approximation
(BLA) method is employed to estimate second-order linear time-invariant (LTI)
transfer function models across different operating conditions defined by DC
levels and modulation frequencies of light intensity. Building on these local
models, a Linear Parameter-Varying (LPV) representation is constructed, in
which the scheduling parameter is defined by the DC values of the light
intensity, providing a compact state-space representation of the system
dynamics.

</details>


### [176] [ComEMS4Build: Comfort-Oriented Energy Management System for Residential Buildings using Hydrogen for Seasonal Storage](https://arxiv.org/abs/2511.04293)
*Jovana Kovačević,Felix Langner,Erfan Tajalli-Ardekani,Marvin Dorn,Simon Waczowicz,Ralf Mikut,Jörg Matthes,Hüseyin K. Çakmak,Veit Hagenmeyer*

Main category: eess.SY

TL;DR: 本研究开发了一种基于模糊逻辑的面向舒适度的住宅建筑能量管理系统 (ComEMS4Build)，集成光伏、电池和氢能存储（燃料电池与热泵辅助），在冬季评估中，其在保持热舒适性和降低电力成本方面优于基于规则的控制，但成本略高于理想模型预测控制。


<details>
  <summary>Details</summary>
Motivation: 将灵活负荷和储能系统整合到住宅部门有助于平衡不稳定的可再生能源发电与需求。除了短期电池储能外，氢能系统可实现可再生能源的季节性转移。然而，由于氢能系统初始成本高昂，将燃料电池与热泵结合可有助于减小氢能系统规模，从而激发了开发更高效能量管理系统的需求。

Method: 本研究开发了ComEMS4Build，一个包含光伏、电池储能系统和氢能存储（燃料电池和热泵为补充技术）的面向舒适度的住宅建筑能量管理系统。该系统基于模糊逻辑设计，并采用半合成建模方法，在德国一个家庭住宅建筑中，对12个冬季周进行了评估。同时，将其性能与作为下限基准的基于规则的控制（RBC）和作为成本最优基准的理想模型预测控制（MPC）进行了比较。

Result: 结果显示，ComEMS4Build与MPC类似，在12周中有10周未违反居住者的热舒适度，而RBC的中位数不适度略高（0.68 Kh）。ComEMS4Build每周电费比MPC高12.06欧元，而RBC则高30.14欧元。与RBC相比，ComEMS4Build提高了混合储能系统的利用率和与主电网的能量交换。然而，在燃料电池运行方面，RBC具有优势，与MPC相比，它将燃料电池的开关次数减少了3.48%，工作时间减少了7.59%。

Conclusion: ComEMS4Build在住宅建筑中实现了舒适度与成本的平衡，其性能在热舒适性和电费方面优于基于规则的控制。尽管其电力成本略高于具有理想预测的MPC，但在提高混合储能系统利用率和电网交互方面表现良好。在燃料电池运行效率方面，RBC在减少开关次数和工作时间上表现出一定的优势。

Abstract: Integrating flexible loads and storage systems into the residential sector
contributes to the alignment of volatile renewable generation with demand.
Besides batteries serving as a short-term storage solution, residential
buildings can benefit from a Hydrogen (H2) storage system, allowing seasonal
shifting of renewable energy. However, as the initial costs of H2 systems are
high, coupling a Fuel Cell (FC) with a Heat Pump (HP) can contribute to the
size reduction of the H2 system. The present study develops a Comfort-Oriented
Energy Management System for Residential Buildings (ComEMS4Build) comprising
Photovoltaics (PV), Battery Energy Storage System (BESS), and H2 storage, where
FC and HP are envisioned as complementary technologies. The fuzzy-logic-based
ComEMS4Build is designed and evaluated over a period of 12 weeks in winter for
a family household building in Germany using a semi-synthetic modeling
approach. The Rule-Based Control (RBC), which serves as a lower benchmark, is a
scheduler designed to require minimal inputs for operation. The Model
Predictive Control (MPC) is intended as a cost-optimal benchmark with an ideal
forecast. The results show that ComEMS4Build, similar to MPC, does not violate
the thermal comfort of occupants in 10 out of 12 weeks, while RBC has a
slightly higher median discomfort of 0.68 Kh. The ComEMS4Build increases the
weekly electricity costs by 12.06 EUR compared to MPC, while RBC increases the
weekly costs by 30.14 EUR. The ComEMS4Build improves the Hybrid Energy Storage
System (HESS) utilization and energy exchange with the main grid compared to
the RBC. However, when it comes to the FC operation, the RBC has an advantage,
as it reduces the toggling counts by 3.48% and working hours by 7.59% compared
to MPC...

</details>


### [177] [Overview and Performance Evaluation of Supervisory Controller Synthesis with Eclipse ESCET v4.0](https://arxiv.org/abs/2511.04370)
*Dennis Hendriks,Michel Reniers,Wan Fokkink,Wytse Oortwijn*

Main category: eess.SY

TL;DR: 本文描述了CIF的符号监督控制器综合算法，介绍了其基准模型集，评估了ESCET工具包中从v0.8到v4.0的综合性能改进，并探讨了多级综合方法及其对复杂模型性能的潜在提升。


<details>
  <summary>Details</summary>
Motivation: 为确保信息物理系统（CPS）的正确和安全运行，需要监督控制器。综合工程（SBE）旨在自动化其设计和实现，使工程师能专注于系统“应该做什么”（需求）而非“如何实现”（设计和实现）。本文旨在详细阐述CIF语言及其在ESCET项目中的工具如何支持SBE，并展示其在实际应用中的性能。

Method: 1. 详细描述了CIF的符号监督控制器综合算法，包括运行时错误预防、不同类型需求处理和输入变量支持等实用方面。 2. 介绍了CIF的基准模型，这是一个包含23个不同规模和复杂度的工业和学术模型的集合。 3. 描述并评估了ESCET版本v0.8至v4.0之间影响综合性能的改进，并使用基准模型展示了当前的实际综合性能。 4. 简要探讨了多级综合（一种非单一综合方法），评估了其性能提升。

Result: 1. 提供了CIF综合算法的全面描述，涵盖了文献中常被忽略的实用细节。 2. 提供了23个可自由获取的工业和学术基准模型。 3. 展示了ESCET在版本更新后，CIF的综合性能得到了显著提升，并给出了当前的实际性能数据。 4. 多级综合能够进一步提高综合性能，但对于复杂模型而言，仍需进一步的性能改进。

Conclusion: CIF的符号监督控制器综合算法结合ESCET工具包，通过SBE方法为信息物理系统提供了强大的支持，并在实际应用中展现了良好的综合性能。尽管多级综合有助于提升性能，但对于处理更复杂的模型，仍需持续进行性能优化。

Abstract: Supervisory controllers control cyber-physical systems to ensure their
correct and safe operation. Synthesis-based engineering (SBE) is an approach to
largely automate their design and implementation. SBE combines model-based
engineering with computer-aided design, allowing engineers to focus on 'what'
the system should do (the requirements) rather than 'how' it should do it
(design and implementation). In the Eclipse Supervisory Control Engineering
Toolkit (ESCET) open-source project, a community of users, researchers, and
tool vendors jointly develop a toolkit to support the entire SBE process,
particularly through the CIF modeling language and tools. In this paper, we
first provide a description of CIF's symbolic supervisory controller synthesis
algorithm, and thereby include aspects that are often omitted in the
literature, but are of great practical relevance, such as the prevention of
runtime errors, handling different types of requirements, and supporting input
variables (to connect to external inputs). Secondly, we introduce and describe
CIF's benchmark models, a collection of 23 freely available industrial and
academic models of various sizes and complexities. Thirdly, we describe recent
improvements between ESCET versions v0.8 (December 2022) and v4.0 (June 2024)
that affect synthesis performance, evaluate them on our benchmark models, and
show the current practical synthesis performance of CIF. Fourthly, we briefly
look at multi-level synthesis, a non-monolithic synthesis approach, evaluate
its gains, and show that while it can help to further improve synthesis
performance, further performance improvements are still needed to synthesize
complex models.

</details>


### [178] [Deep Koopman Economic Model Predictive Control of a Pasteurisation Unit](https://arxiv.org/abs/2511.04437)
*Patrik Valábek,Michaela Horváthová,Martin Klaučo*

Main category: eess.SY

TL;DR: 本文提出了一种基于深度Koopman算子的经济模型预测控制（EMPC）方法，用于巴氏杀菌装置的有效运行。该方法通过将复杂非线性系统线性化，显著提高了预测精度，并在经济成本（如能源消耗和物料损失）方面比传统方法降低了32%。


<details>
  <summary>Details</summary>
Motivation: 动机在于高效运行实验室规模的巴氏杀菌装置等复杂非线性系统，并降低其运行中的经济成本，包括能源消耗、因杀菌不充分造成的物料损失以及执行器磨损。

Method: 该研究采用深度Koopman算子理论，通过神经网络从实验数据中学习，将复杂的非线性系统动力学转化为线性表示。这种线性模型被集成到经济模型预测控制（EMPC）框架中，该框架考虑了能源消耗、物料损失和执行器磨损等经济成本，并使用松弛变量确保可行性。研究将深度Koopman EMPC与传统的N4SID EMPC进行了比较，并在存在外部扰动（如进料泵故障和冷批次引入）的非线性多变量巴氏杀菌装置模型上进行了数值验证。

Result: 结果显示，深度Koopman模型在开环预测精度上比传统的N4SID子空间辨识提高了45%。在EMPC应用中，深度Koopman EMPC相比N4SID基线，总经济成本降低了32%，主要得益于物料损失和能源消耗的减少。此外，通过基于Koopman的EMPC实现的稳态运行所需的电能减少了10.2%。

Conclusion: 研究表明，将深度Koopman表示与经济优化相结合，为热密集型工厂实现资源高效控制提供了实际优势。

Abstract: This paper presents a deep Koopman-based Economic Model Predictive Control
(EMPC) for efficient operation of a laboratory-scale pasteurization unit (PU).
The method uses Koopman operator theory to transform the complex, nonlinear
system dynamics into a linear representation, enabling the application of
convex optimization while representing the complex PU accurately. The deep
Koopman model utilizes neural networks to learn the linear dynamics from
experimental data, achieving a 45% improvement in open-loop prediction accuracy
over conventional N4SID subspace identification. Both analyzed models were
employed in the EMPC formulation that includes interpretable economic costs,
such as energy consumption, material losses due to inadequate pasteurization,
and actuator wear. The feasibility of EMPC is ensured using slack variables.
The deep Koopman EMPC and N4SID EMPC are numerically validated on a nonlinear
model of multivariable PU under external disturbance. The disturbances include
feed pump fail-to-close scenario and the introduction of a cold batch to be
pastuerized. These results demonstrate that the deep Koopmand EMPC achieves a
32% reduction in total economic cost compared to the N4SID baseline. This
improvement is mainly due to the reductions in material losses and energy
consumption. Furthermore, the steady-state operation via Koopman-based EMPC
requires 10.2% less electrical energy. The results highlight the practical
advantages of integrating deep Koopman representations with economic
optimization to achieve resource-efficient control of thermal-intensive plants.

</details>


### [179] [Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear System with Input Delay](https://arxiv.org/abs/2511.04451)
*Patrik Valábek,Marek Wadinger,Michal Kvasnica,Martin Klaučo*

Main category: eess.SY

TL;DR: 本文提出了一种结合LSTM的深度Koopman模型，用于近似具有输入延迟的非线性动力学系统的Koopman算子，从而实现对延迟系统动力学的线性表示，并在预测精度上表现出色。


<details>
  <summary>Details</summary>
Motivation: 具有输入延迟的非线性动力学系统在预测、估计和控制方面面临巨大挑战，传统线性控制技术往往失效。现有扩展动态模态分解（eDMD）方法依赖预定义字典，限制了其在未知动力学系统中的应用。

Method: 引入了一种LSTM增强的深度Koopman模型来近似Koopman算子。通过结合LSTM层，该模型能够捕获历史依赖性，并将时间延迟的系统动力学有效编码到潜在空间中。与传统的eDMD不同，该方法是无字典的。

Result: 在模拟系统上的定量比较表明，当真实非线性动力学未知时，LSTM增强的深度Koopman模型在预测精度上比eDMD有显著提高；当系统动力学已知时，其性能与eDMD相当。

Conclusion: LSTM增强的深度Koopman模型为处理带有输入延迟的非线性动力学系统提供了一种创新且有效的解决方案，尤其在系统动力学未知的情况下，展现出优越的预测能力。

Abstract: Nonlinear dynamical systems with input delays pose significant challenges for
prediction, estimation, and control due to their inherent complexity and the
impact of delays on system behavior. Traditional linear control techniques
often fail in these contexts, necessitating innovative approaches. This paper
introduces a novel approach to approximate the Koopman operator using an
LSTM-enhanced Deep Koopman model, enabling linear representations of nonlinear
systems with time delays. By incorporating Long Short-Term Memory (LSTM)
layers, the proposed framework captures historical dependencies and efficiently
encodes time-delayed system dynamics into a latent space. Unlike traditional
extended Dynamic Mode Decomposition (eDMD) approaches that rely on predefined
dictionaries, the LSTM-enhanced Deep Koopman model is dictionary-free, which
mitigates the problems with the underlying dynamics being known and
incorporated into the dictionary. Quantitative comparisons with extended eDMD
on a simulated system demonstrate highly significant performance gains in
prediction accuracy in cases where the true nonlinear dynamics are unknown and
achieve comparable results to eDMD with known dynamics of a system.

</details>


### [180] [Data-driven uncertainty-aware seakeeping prediction of the Delft 372 catamaran using ensemble Hankel dynamic mode decomposition](https://arxiv.org/abs/2511.04461)
*Giorgio Palma,Andrea Serani,Matteo Diez*

Main category: eess.SY

TL;DR: 本研究提出并验证了一种基于集成Hankel动态模态分解与控制（HDMDc）的方法，用于高速双体船（Delft 372模型）的适航性预测及不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 需要对高速船只的适航性进行不确定性感知的预测，以更好地支持设计和操作决策。

Method: 研究使用Delft 372模型（1:33.3比例）在海况5、弗劳德数0.425条件下进行的非规则波浪水池试验数据。数据包括波浪高、垂荡、纵摇、甲板速度、桥梁加速度和总阻力。采用HDMDc算法构建无方程的线性降阶模型，通过增加带有时间滞后副本的状态和输入来捕捉非线性和记忆效应。比较了两种集成策略：贝叶斯HDMDc（BHDMDc）和频率论HDMDc（FHDMDc），用于提供适航性预测和不确定性量化。

Result: 频率论HDMDc（FHDMDc）方法在预测准确性方面优于确定性模型，并提供了稳健的不确定性估计；而贝叶斯HDMDc（BHDMDc）在此测试案例中与确定性模型相比未显示出益处。FHDMDc导出的运动概率密度函数与实验数据和URANS结果高度吻合。

Conclusion: FHDMDc为高速双体船的适航性预测提供了一种可靠且计算高效的方法，能够有效进行不确定性量化，对设计和操作支持具有重要意义。

Abstract: In this study, we present and validate an ensemble-based Hankel Dynamic Mode
Decomposition with control (HDMDc) for uncertainty-aware seakeeping predictions
of a high-speed catamaran, namely the Delft 372 model. Experimental
measurements (time histories) of wave elevation at the longitudinal center of
gravity, heave, pitch, notional flight-deck velocity, notional bridge
acceleration, and total resistance were collected from irregular wave basin
tests on a 1:33.3 scale replica of the Delft 372 model under sea state 5
conditions at Fr = 0.425, and organized into training, validation, and test
sets. The HDMDc algorithm constructs an equation-free linear reduced-order
model of the seakeeping vessel by augmenting states and inputs with their
time-lagged copies to capture nonlinear and memory effects. Two ensembling
strategies, namely Bayesian HDMDc (BHDMDc), which samples hyperparameters
considered stochastic variables with prior distribution to produce posterior
mean forecasts with confidence intervals, and Frequentist HDMDc (FHDMDc), which
aggregates multiple model obtained over data subsets, are compared in providing
seakeeping prediction and uncertainty quantification. The FHDMDc approach is
found to improve the accuracy of the predictions compared to the deterministic
counterpart, also providing robust uncertainty estimation; whereas the
application of BHDMDc to the present test case is not found beneficial in
comparison to the deterministic model. FHDMDc-derived probability density
functions for the motions closely match both experimental data and URANS
results, demonstrating reliable and computationally efficient seakeeping
prediction for design and operational support.

</details>


### [181] [AI-Driven Phase-Shifted Carrier Optimization for Cascaded Bridge Converters, Modular Multilevel Converters, and Reconfigurable Batteries](https://arxiv.org/abs/2511.04470)
*Amin Hashemi-Zadeh,Nima Tashakor,Sandun Hettiarachchi,Stefan Goetz*

Main category: eess.SY

TL;DR: 本文提出了一种基于神经网络的方法，用于实时优化移相载波脉宽调制（PSC-PWM）中的相移角，以减少级联变换器中的电流纹波和电压失真，其计算速度远超传统优化器，并具有良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 移相载波脉宽调制（PSC-PWM）在级联变换器中广泛应用，但固定相移角会导致模块脉宽不均匀，从而产生显著的纹波电流和输出电压失真。优化单个载波的相移角可以实现电压均匀性，但其计算负担对于简单的嵌入式控制器来说过大。

Method: 本文提出了一种神经网络，能够模拟瞬时优化器的行为，以显著降低计算负担。该方法通过一次训练即可预测最佳相移角，适用于模块平衡但调制指数不同的情况，无需大量的查找表、缓慢的数值优化或复杂的控制器调谐。此外，还提出了一个简单的扩展策略，允许为少量模块训练的神经网络通过分组和调整相移来重用于更大的系统，无需重新训练。

Result: 大规模评估、仿真和实验表明，该方法平均可将电流纹波和加权总谐波失真降低高达50%，且实时性能比传统优化器（如遗传算法）快10万到50万倍。这使其成为唯一适用于在线应用的解决方案。

Conclusion: 所提出的神经网络方法为级联变换器中PSC-PWM的相移角优化提供了一个快速、稳定且可扩展的解决方案，能够显著提高性能并满足实时在线应用的需求。

Abstract: Phase-shifted carrier pulse-width modulation (PSC-PWM) is a widely adopted
scheduling algorithm in cascaded bridge converters, modular multilevel
converters, and reconfigurable batteries. However, non-uniformed pulse widths
for the modules with fixed phase shift angles lead to significant ripple
current and output-voltage distortion. Voltage uniformity instead would require
optimization of the phase shifts of the individual carriers. However, the
computational burden for such optimization is beyond the capabilities of any
simple embedded controller. This paper proposes a neural network that emulates
the behavior of an instantaneous optimizer with significantly reduced
computational burden. The proposed method has the advantages of stable
performance in predicting the optimum phase-shift angles under balanced battery
modules with non-identical modulation indices without requiring extensive
lookup tables, slow numerical optimization, or complex controller tuning. With
only one (re)training session for any specified number of modules, the proposed
method is readily adaptable to different system sizes. Furthermore, the
proposed framework also includes a simple scaling strategy that allows a neural
network trained for fewer modules to be reused for larger systems by grouping
modules and adjusting their phase shifts. The scaling strategy eliminates the
need for retraining. Large-scale assessment, simulations, and experiments
demonstrate that, on average, the proposed approach can reduce the current
ripple and the weighted total harmonic distortion by up to 50 % in real time
and is 100 to 500 thousand times faster than a conventional optimizer (e.g.,
genetic algorithms), making it the only solution for an online application.

</details>


### [182] [Synchronous Observer Design for Landmark-Inertial SLAM with Almost-Global Convergence](https://arxiv.org/abs/2511.04531)
*Arkadeep Saha,Pieter van Goor,Antonio Franchi,Ravi Banavar*

Main category: eess.SY

TL;DR: 本文提出了一种用于地标惯性同步定位与建图（LI-SLAM）的非线性观测器，并在编码所有可观测状态的基空间中分析了其误差动力学的局部指数稳定性和几乎全局渐近稳定性，并通过仿真验证。


<details>
  <summary>Details</summary>
Motivation: LI-SLAM的目标是利用地标位置测量和惯性测量单元（IMU）数据，估计环境中地标的位置以及机器人相对于这些地标的姿态。

Method: 本文提出了一种在连续时间下构建的非线性观测器，用于解决LI-SLAM问题。该观测器在编码所有LI-SLAM可观测状态的基空间中进行分析。

Result: 在证明部分，建立了基空间中误差动力学的局部指数稳定性和几乎全局渐近稳定性，并通过仿真验证了这些结果。

Conclusion: 所提出的非线性观测器能有效且稳定地解决LI-SLAM问题，实现机器人姿态和地标位置的估计，并具备良好的误差收敛性。

Abstract: Landmark Inertial Simultaneous Localisation and Mapping (LI-SLAM) is the
problem of estimating the locations of landmarks in the environment and the
robot's pose relative to those landmarks using landmark position measurements
and measurements from Inertial Measurement Unit (IMU). This paper proposes a
nonlinear observer for LI-SLAM posed in continuous time and analyses the
observer in a base space that encodes all the observable states of LI-SLAM. The
local exponential stability and almost-global asymptotic stability of the error
dynamics in base space is established in the proof section and validated using
simulations.

</details>


### [183] [Funnel-Based Online Recovery Control for Nonlinear Systems With Unknown Dynamics](https://arxiv.org/abs/2511.04626)
*Zihao Song,Shirantha Welikala,Panos J. Antsaklis,Hai Lin*

Main category: eess.SY

TL;DR: 本文提出了一种针对遭受攻击或故障的非线性系统的恢复控制方法。该方法结合使用循环平衡网络（REN）来学习未知动力学，并通过漏斗型控制实现系统从偏差状态的恢复，同时提供形式化保证。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决非线性系统在遭受攻击或故障后恢复控制的挑战，主要包括：1) 如何在形式化保证下学习由攻击或故障引起的未知动力学；2) 如何找到状态的不变集，以形式化地确保状态偏离标称轨迹的允许范围。

Method: 本文提出以下方法：1) 应用循环平衡网络（RENs）从实时系统状态数据中学习未知动力学；2) 通过增量积分二次约束（IQCs）来保证REN模型的输入输出特性；3) 提出一种基于漏斗的控制方法，以实现系统从偏离状态的恢复；4) 推导了标称轨迹稳定性的充分条件以及沿标称轨迹的不变漏斗。

Result: 通过一个直流微电网控制应用的仿真示例，验证了所提出的控制方法的有效性。

Conclusion: 该研究成功地提出了一种结合REN学习未知动力学和漏斗型控制实现非线性系统恢复的方法，并在仿真中展示了其有效性。

Abstract: In this paper, we focus on recovery control of nonlinear systems from attacks
or failures. The main challenges of this problem lie in (1) learning the
unknown dynamics caused by attacks or failures with formal guarantees, and (2)
finding the invariant set of states to formally ensure the state deviations
allowed from the nominal trajectory. To solve this problem, we propose to apply
the Recurrent Equilibrium Networks (RENs) to learn the unknown dynamics using
the data from the real-time system states. The input-output property of this
REN model is guaranteed by incremental integral quadratic constraints (IQCs).
Then, we propose a funnel-based control method to achieve system recovery from
the deviated states. In particular, a sufficient condition for nominal
trajectory stabilization is derived together with the invariant funnels along
the nominal trajectory. Eventually, the effectiveness of our proposed control
method is illustrated by a simulation example of a DC microgrid control
application.

</details>


### [184] [Control Affine Hybrid Power Plant Subsystem Modeling for Supervisory Control Design](https://arxiv.org/abs/2511.04644)
*Stephen Ampleman,Himanshu Sharma,Sayak Mukherjee,Sonja Glavaski*

Main category: eess.SY

TL;DR: 本文提出了一种针对风电场、太阳能电站和电池储能组成的混合式电厂（HPP）的建模与控制设计框架，将现有模型转化为控制仿射形式，并利用非线性控制和控制障碍函数技术开发了风机和电池的控制律，通过案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 混合式电厂（HPPs）结合多种发电机（常规/可变）和储能能力，以应对发电不足和电网需求，因此需要一个有效的建模和控制设计框架来管理这些复杂系统。

Method: 该研究将风电场、太阳能电站和电池的现有模型转化为适用于监督层控制设计的控制仿射形式。对于风机和电池模型，采用非线性控制和控制障碍函数（CBF）技术开发了发电机转矩和电池电流控制律，以跟踪监督控制指令并保持安全稳定运行。通过一个包含电网需求信号、时变风速和辐照数据以及基于规则的监督控制律的测试案例来验证该框架的实用性。

Result: 该建模和控制框架的实用性通过一个包含公用事业需求信号跟踪、时变风能和辐照数据以及基于规则的监督控制律的测试案例得到了验证。

Conclusion: 该研究成功提出并展示了一个用于混合式电厂（HPPs）的建模和控制设计框架，能够有效管理风能、太阳能和电池储能，以满足电网需求并确保系统安全稳定运行。

Abstract: Hybrid power plants (HPPs) combine multiple power generators
(conventional/variable) and energy storage capabilities to support generation
inadequacy and grid demands. This paper introduces a modeling and control
design framework for hybrid power plants (HPPs) consisting of a wind farm,
solar plant, and battery storage. Specifically, this work adapts established
modeling paradigms for wind farms, solar plants and battery models into a
control affine form suitable for control design at the supervisory level. In
the case of wind and battery models, generator torque and cell current control
laws are developed using nonlinear control and control barrier function
techniques to track a command from a supervisory control law while maintaining
safe and stable operation. The utility of this modeling and control framework
is illustrated through a test case using a utility demand signal for tracking,
time varying wind and irradiance data, and a rule-based supervisory control
law.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [185] [Reconstruction-free segmentation from undersampled k-space using transformers](https://arxiv.org/abs/2511.03762)
*Yundi Zhang,Nil Stolt-Ansó,Jiazhen Pan,Wenqi Huang,Kerstin Hammernik,Daniel Rueckert*

Main category: eess.IV

TL;DR: 本文提出一种基于Transformer的方法，可直接从稀疏k空间数据进行心脏分割，无需中间图像重建，在高加速因子下表现优于基于图像的传统方法。


<details>
  <summary>Details</summary>
Motivation: 高加速因子限制了MRI图像重建的质量，进而影响后续的分割模型。研究目标是突破这一限制，直接从稀疏k空间测量中生成分割结果。

Method: 该方法采用Transformer架构将全局k空间信息编码为潜在特征。生成的潜在向量在解码过程中条件化查询坐标，以生成分割类别概率。

Result: 在高加速因子下，该模型能够生成比基于图像的分割基线更好的分割结果。

Conclusion: 直接从欠采样k空间样本进行心脏分割，避免了中间图像重建步骤。这使得在比依赖图像作为输入的方法更高的加速因子下评估心肌结构和功能成为可能。

Abstract: Motivation: High acceleration factors place a limit on MRI image
reconstruction. This limit is extended to segmentation models when treating
these as subsequent independent processes.
  Goal: Our goal is to produce segmentations directly from sparse k-space
measurements without the need for intermediate image reconstruction.
  Approach: We employ a transformer architecture to encode global k-space
information into latent features. The produced latent vectors condition queried
coordinates during decoding to generate segmentation class probabilities.
  Results: The model is able to produce better segmentations across high
acceleration factors than image-based segmentation baselines.
  Impact: Cardiac segmentation directly from undersampled k-space samples
circumvents the need for an intermediate image reconstruction step. This allows
the potential to assess myocardial structure and function on higher
acceleration factors than methods that rely on images as input.

</details>


### [186] [Shape Deformation Networks for Automated Aortic Valve Finite Element Meshing from 3D CT Images](https://arxiv.org/abs/2511.03890)
*Linchen Qian,Jiasong Chen,Ruonan Gong,Wei Sun,Minliang Liu,Liang Liang*

Main category: eess.IV

TL;DR: 本文提出了一种基于深度神经网络的模板拟合管道，用于从3D CT图像生成结构化四边形网格，以实现主动脉瓣的精确几何建模，确保网格质量和患者间一致性，并简化训练过程。


<details>
  <summary>Details</summary>
Motivation: 从3D CT图像精确建模主动脉瓣对于生物力学分析和患者特异性模拟至关重要。然而，传统方法生成的三角网格存在拓扑不规则、单元形状不佳以及患者间对应关系不一致的问题，影响网格质量和一致性。

Method: 引入了一个基于深度神经网络的模板拟合管道，用于从3D CT图像生成结构化四边形网格。通过使用一个通用的四边形网格模板对所有患者的主动脉瓣进行重网格化，确保了统一的网格拓扑和一致的节点与单元对应关系。深度神经网络的损失函数仅包含几何重建和平滑度正则化两项，足以保持网格平滑度和单元质量。

Result: 所提出的方法能够生成高质量的主动脉瓣表面网格，显著改善了平滑度和形状质量。与传统方法相比，该方法所需的显式正则化项更少。

Conclusion: 使用结构化四边形网格作为模板和神经网络训练不仅能确保网格的对应性和质量，还能简化训练过程，从而提高主动脉瓣建模的有效性和效率。

Abstract: Accurate geometric modeling of the aortic valve from 3D CT images is
essential for biomechanical analysis and patient-specific simulations to assess
valve health or make a preoperative plan. However, it remains challenging to
generate aortic valve meshes with both high-quality and consistency across
different patients. Traditional approaches often produce triangular meshes with
irregular topologies, which can result in poorly shaped elements and
inconsistent correspondence due to inter-patient anatomical variation. In this
work, we address these challenges by introducing a template-fitting pipeline
with deep neural networks to generate structured quad (i.e., quadrilateral)
meshes from 3D CT images to represent aortic valve geometries. By remeshing
aortic valves of all patients with a common quad mesh template, we ensure a
uniform mesh topology with consistent node-to-node and element-to-element
correspondence across patients. This consistency enables us to simplify the
learning objective of the deep neural networks, by employing a loss function
with only two terms (i.e., a geometry reconstruction term and a smoothness
regularization term), which is sufficient to preserve mesh smoothness and
element quality. Our experiments demonstrate that the proposed approach
produces high-quality aortic valve surface meshes with improved smoothness and
shape quality, while requiring fewer explicit regularization terms compared to
the traditional methods. These results highlight that using structured quad
meshes for the template and neural network training not only ensures mesh
correspondence and quality but also simplifies the training process, thus
enhancing the effectiveness and efficiency of aortic valve modeling.

</details>


### [187] [Computed Tomography (CT)-derived Cardiovascular Flow Estimation Using Physics-Informed Neural Networks Improves with Sinogram-based Training: A Simulation Study](https://arxiv.org/abs/2511.03876)
*Jinyuxuan Guo,Gurnoor Singh Khurana,Alejandro Gonzalo Grande,Juan C. del Alamo,Francisco Contijoch*

Main category: eess.IV

TL;DR: 本研究提出了一种名为SinoFlow的新框架，通过直接使用CT正弦图数据而非重建图像，显著提高了基于物理信息神经网络（PINN）的血流估计性能，避免了图像重建引入的误差。


<details>
  <summary>Details</summary>
Motivation: CT是评估心血管解剖和功能的常用成像方式，但目前缺乏直接从造影剂演变电影中估计血流速度的方法。现有基于PINN的血流估计方法可能受到CT成像参数的影响，且传统方法通过重建图像进行估计会引入误差。

Method: 研究通过计算流体动力学（CFD）在一个理想化的二维血管分叉中生成了脉动流场，并模拟了不同机架旋转速度、管电流和脉冲模式成像设置下的CT扫描。随后，比较了使用重建图像的PINN基流估计方法（ImageFlow）与直接使用正弦图数据的SinoFlow框架的性能。

Result: SinoFlow通过避免滤波反投影引入的误差，显著提升了血流估计性能。SinoFlow在所有测试的机架旋转速度下均表现出鲁棒性，并且比ImageFlow产生了更低均方误差和速度误差。此外，SinoFlow兼容脉冲模式成像，并能在更短的脉冲宽度下保持更高的准确性。

Conclusion: 本研究证明了SinoFlow在CT血流估计方面的潜力，为无创血流评估提供了一种更有前景的方法。研究结果旨在为未来PINN在CT图像上的应用提供信息，并提供一个图像基估计解决方案，即通过合理的采集参数获得准确的血流估计。

Abstract: Background: Non-invasive imaging-based assessment of blood flow plays a
critical role in evaluating heart function and structure. Computed Tomography
(CT) is a widely-used imaging modality that can robustly evaluate
cardiovascular anatomy and function, but direct methods to estimate blood flow
velocity from movies of contrast evolution have not been developed.
  Purpose: This study evaluates the impact of CT imaging on Physics-Informed
Neural Networks (PINN)-based flow estimation and proposes an improved
framework, SinoFlow, which uses sinogram data directly to estimate blood flow.
  Methods: We generated pulsatile flow fields in an idealized 2D vessel
bifurcation using computational fluid dynamics and simulated CT scans with
varying gantry rotation speeds, tube currents, and pulse mode imaging settings.
We compared the performance of PINN-based flow estimation using reconstructed
images (ImageFlow) to SinoFlow.
  Results: SinoFlow significantly improved flow estimation performance by
avoiding propagating errors introduced by filtered backprojection. SinoFlow was
robust across all tested gantry rotation speeds and consistently produced lower
mean squared error and velocity errors than ImageFlow. Additionally, SinoFlow
was compatible with pulsed-mode imaging and maintained higher accuracy with
shorter pulse widths.
  Conclusions: This study demonstrates the potential of SinoFlow for CT-based
flow estimation, providing a more promising approach for non-invasive blood
flow assessment. The findings aim to inform future applications of PINNs to CT
images and provide a solution for image-based estimation, with reasonable
acquisition parameters yielding accurate flow estimates.

</details>


### [188] [$μ$NeuFMT: Optical-Property-Adaptive Fluorescence Molecular Tomography via Implicit Neural Representation](https://arxiv.org/abs/2511.04510)
*Shihan Zhao,Jianru Zhang,Yanan Wu,Linlin Li,Siyuan Shen,Xingjun Zhu,Guoyan Zheng,Jiahua Jiang,Wuwei Ren*

Main category: eess.IV

TL;DR: 本文提出了一种名为μNeuFMT的自监督荧光分子断层扫描（FMT）重建框架，它通过联合优化荧光分布和光学特性，解决了传统FMT重建中固有的病态性、对光学参数的依赖以及监督深度学习泛化能力受限的问题。


<details>
  <summary>Details</summary>
Motivation: FMT重建面临挑战，原因在于其固有的病态性以及对不准确或未知组织光学特性的依赖。虽然深度学习有前景，但其监督性质限制了在训练数据之外的泛化能力。

Method: 本文提出了μNeuFMT，一个自监督的FMT重建框架。它将隐式神经场景表示与光子传播的显式物理建模相结合，并在重建过程中联合优化荧光分布和光学特性（μ），从而无需精确的组织光学先验知识或预处理的训练数据。

Result: μNeuFMT即使在初始值严重错误（0.5倍至2倍于真实值）的情况下，也能稳健地恢复准确的荧光团分布和光学系数。广泛的数值、体模和体内验证表明，在各种异质场景中，μNeuFMT优于传统方法和监督深度学习方法。

Conclusion: μNeuFMT为稳健和准确的FMT重建建立了一个新范式，为复杂临床相关场景（如荧光引导手术）中更可靠的分子成像铺平了道路。

Abstract: Fluorescence Molecular Tomography (FMT) is a promising technique for
non-invasive 3D visualization of fluorescent probes, but its reconstruction
remains challenging due to the inherent ill-posedness and reliance on
inaccurate or often-unknown tissue optical properties. While deep learning
methods have shown promise, their supervised nature limits generalization
beyond training data. To address these problems, we propose $\mu$NeuFMT, a
self-supervised FMT reconstruction framework that integrates implicit
neural-based scene representation with explicit physical modeling of photon
propagation. Its key innovation lies in jointly optimize both the fluorescence
distribution and the optical properties ($\mu$) during reconstruction,
eliminating the need for precise prior knowledge of tissue optics or
pre-conditioned training data. We demonstrate that $\mu$NeuFMT robustly
recovers accurate fluorophore distributions and optical coefficients even with
severely erroneous initial values (0.5$\times$ to 2$\times$ of ground truth).
Extensive numerical, phantom, and in vivo validations show that $\mu$NeuFMT
outperforms conventional and supervised deep learning approaches across diverse
heterogeneous scenarios. Our work establishes a new paradigm for robust and
accurate FMT reconstruction, paving the way for more reliable molecular imaging
in complex clinically related scenarios, such as fluorescence guided surgery.

</details>


### [189] [DeepFixel: Crossing white matter fiber identification through spherical convolutional neural networks](https://arxiv.org/abs/2511.03893)
*Adam M. Saunders,Lucas W. Remedios,Elyssa M. McMaster,Jongyeon Yoon,Gaurav Rudravaram,Adam Sadriddinov,Praitayini Kanakaraj,Bennett A. Landman,Adam W. Anderson*

Main category: eess.IV

TL;DR: 该论文提出DeepFixel，一种球形卷积神经网络，用于高效分离扩散加权磁共振成像中交叉的白质纤维方向分布函数(ODFs)。它在计算效率上显著优于非线性优化，并能更好地处理小角度分离和低体积分数的纤维，同时保持较高的准确性。


<details>
  <summary>Details</summary>
Motivation: 扩散加权磁共振成像中的交叉白质纤维会使大脑结构连接分析复杂化，并导致诸如纤维束成像等下游任务出现错误。现有的非线性优化方法虽然能分离ODFs，但计算成本过高，无法在整个图像上应用。

Method: 研究首先提出一种非线性优化方法来分离纤维ODFs，通过拟合ODFs到给定数据并惩罚不对称项。由于该优化计算量大，研究引入了DeepFixel，一个球形卷积神经网络，以近似该非线性优化。DeepFixel将纤维概率分布建模为具有高角度分辨率的球形网格。通过与非线性优化和基于fixel的分离算法在两纤维和三纤维ODFs上的比较来验证DeepFixel。

Result: 非线性优化算法的中位角相关系数为1（四分位距0.00），但计算时间为每体素约1.01 x 10^6毫秒。基于fixel的分离算法的中位角相关系数为0.988（0.317）。DeepFixel的中位角相关系数为0.973（0.004），但计算效率更高，每体素仅需0.32毫秒。DeepFixel的球形网格表示在解缠绕小角度分离和低体积分数的纤维方面优于基于fixel的分离算法。

Conclusion: DeepFixel作为一种球形卷积神经网络，成功地为分离交叉白质纤维ODFs提供了一个高效且准确的替代方案。它显著降低了计算成本，同时在处理具有挑战性的纤维配置（如小角度分离和低体积分数）方面表现出色，优于传统的基于fixel的分离算法。

Abstract: Diffusion-weighted magnetic resonance imaging allows for reconstruction of
models for structural connectivity in the brain, such as fiber orientation
distribution functions (ODFs) that describe the distribution, direction, and
volume of white matter fiber bundles in a voxel. Crossing white matter fibers
in voxels complicate analysis and can lead to errors in downstream tasks like
tractography. We introduce one option for separating fiber ODFs by performing a
nonlinear optimization to fit ODFs to the given data and penalizing terms that
are not symmetric about the axis of the fiber. However, this optimization is
non-convex and computationally infeasible across an entire image (approximately
1.01 x 106 ms per voxel). We introduce DeepFixel, a spherical convolutional
neural network approximation for this nonlinear optimization. We model the
probability distribution of fibers as a spherical mesh with higher angular
resolution than a truncated spherical harmonic representation. To validate
DeepFixel, we compare to the nonlinear optimization and a fixel-based
separation algorithm of two-fiber and three-fiber ODFs. The median angular
correlation coefficient is 1 (interquartile range of 0.00) using the nonlinear
optimization algorithm, 0.988 (0.317) using a fiber bundle elements or
"fixel"-based separation algorithm, and 0.973 (0.004) using DeepFixel.
DeepFixel is more computationally efficient than the non-convex optimization
(0.32 ms per voxel). DeepFixel's spherical mesh representation is successful at
disentangling at smaller angular separations and smaller volume fractions than
the fixel-based separation algorithm.

</details>
