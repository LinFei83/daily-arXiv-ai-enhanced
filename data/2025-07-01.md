<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 37]
- [cs.CV](#cs.CV) [Total: 40]
- [cs.CL](#cs.CL) [Total: 37]
- [cs.RO](#cs.RO) [Total: 41]
- [eess.SY](#eess.SY) [Total: 28]
- [eess.IV](#eess.IV) [Total: 32]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Bootstrapping Human-Like Planning via LLMs](https://arxiv.org/abs/2506.22604)
*David Porfirio,Vincent Hsiao,Morgan Fine-Morris,Leslie Smith,Laura M. Hiatt*

Main category: cs.AI

TL;DR: 研究探讨了如何结合自然语言编程和拖拽界面，利用大语言模型生成人类类似的动作序列，并与手动指定的动作序列进行比较。


<details>
  <summary>Details</summary>
Motivation: 机器人终端用户需要更直观的任务指定方式，自然语言和拖拽界面各有优劣，研究旨在探索两者的结合效果。

Method: 构建基于大语言模型的流程，输入自然语言并输出类似人类动作序列，与手动指定的动作序列进行对比。

Result: 大模型在生成人类类似动作序列上表现更优，但小模型也能达到满意效果。

Conclusion: 结合自然语言和大语言模型的方法可行，大模型表现更优，但小模型仍有实用性。

Abstract: Robot end users increasingly require accessible means of specifying tasks for
robots to perform. Two common end-user programming paradigms include
drag-and-drop interfaces and natural language programming. Although natural
language interfaces harness an intuitive form of human communication,
drag-and-drop interfaces enable users to meticulously and precisely dictate the
key actions of the robot's task. In this paper, we investigate the degree to
which both approaches can be combined. Specifically, we construct a large
language model (LLM)-based pipeline that accepts natural language as input and
produces human-like action sequences as output, specified at a level of
granularity that a human would produce. We then compare these generated action
sequences to another dataset of hand-specified action sequences. Although our
results reveal that larger models tend to outperform smaller ones in the
production of human-like action sequences, smaller models nonetheless achieve
satisfactory performance.

</details>


### [2] [Ludax: A GPU-Accelerated Domain Specific Language for Board Games](https://arxiv.org/abs/2506.22609)
*Graham Todd,Alexander G. Padula,Dennis J. N. J. Soemers,Julian Togelius*

Main category: cs.AI

TL;DR: Ludax是一个结合游戏描述语言和硬件加速的框架，旨在加速游戏研究，支持快速模拟和灵活表示。


<details>
  <summary>Details</summary>
Motivation: 为支持人工智能研究，特别是强化学习，需要一种能自动编译为硬件加速代码的游戏描述语言，以提高效率和通用性。

Method: 开发了Ludax框架，结合游戏描述语言的通用性和现代并行处理硬件的速度，并集成到深度学习流程中。

Result: Ludax提供了详细的描述语言和技术编译说明，通过速度基准测试和RL代理训练展示了其性能。

Conclusion: Ludax作为开源工具，有望加速从强化学习到认知科学的游戏研究。

Abstract: Games have long been used as benchmarks and testing environments for research
in artificial intelligence. A key step in supporting this research was the
development of game description languages: frameworks that compile
domain-specific code into playable and simulatable game environments, allowing
researchers to generalize their algorithms and approaches across multiple games
without having to manually implement each one. More recently, progress in
reinforcement learning (RL) has been largely driven by advances in hardware
acceleration. Libraries like JAX allow practitioners to take full advantage of
cutting-edge computing hardware, often speeding up training and testing by
orders of magnitude. Here, we present a synthesis of these strands of research:
a domain-specific language for board games which automatically compiles into
hardware-accelerated code. Our framework, Ludax, combines the generality of
game description languages with the speed of modern parallel processing
hardware and is designed to fit neatly into existing deep learning pipelines.
We envision Ludax as a tool to help accelerate games research generally, from
RL to cognitive science, by enabling rapid simulation and providing a flexible
representation scheme. We present a detailed breakdown of Ludax's description
language and technical notes on the compilation process, along with speed
benchmarking and a demonstration of training RL agents. The Ludax framework,
along with implementations of existing board games, is open-source and freely
available.

</details>


### [3] [URSA: The Universal Research and Scientific Agent](https://arxiv.org/abs/2506.22653)
*Michael Grosskopf,Russell Bent,Rahul Somasundaram,Isaac Michaud,Arthur Lui,Nathan Debardeleben,Earl Lawrence*

Main category: cs.AI

TL;DR: URSA是一个科学代理生态系统，旨在通过模块化代理和工具加速研究任务，结合先进物理模拟代码，解决复杂科学问题。


<details>
  <summary>Details</summary>
Motivation: 利用大型语言模型（LLMs）的复杂推理和规划能力，解决科学研究中的瓶颈问题，推动科学前沿发展。

Method: 开发URSA系统，包含模块化代理和工具，结合物理模拟代码，灵活应对不同复杂度的科学问题。

Result: 展示了URSA的架构及其在解决科学问题中的潜力。

Conclusion: URSA为科学研究提供了高效工具，展示了LLMs在科学领域的广阔应用前景。

Abstract: Large language models (LLMs) have moved far beyond their initial form as
simple chatbots, now carrying out complex reasoning, planning, writing, coding,
and research tasks. These skills overlap significantly with those that human
scientists use day-to-day to solve complex problems that drive the cutting edge
of research. Using LLMs in "agentic" AI has the potential to revolutionize
modern science and remove bottlenecks to progress. In this work, we present
URSA, a scientific agent ecosystem for accelerating research tasks. URSA
consists of a set of modular agents and tools, including coupling to advanced
physics simulation codes, that can be combined to address scientific problems
of varied complexity and impact. This work highlights the architecture of URSA,
as well as examples that highlight the potential of the system.

</details>


### [4] [Explanations are a means to an end](https://arxiv.org/abs/2506.22740)
*Jessica Hullman,Ziyang Guo,Berk Ustun*

Main category: cs.AI

TL;DR: 论文提出了一种基于统计决策理论的框架，强调解释性机器学习方法应针对具体用途设计和评估，避免模糊性，并通过理论和实证结合的方式评估解释的价值。


<details>
  <summary>Details</summary>
Motivation: 现有解释性机器学习方法未充分考虑实际用途，导致解释可能被误用或效果不佳。

Method: 提出基于统计决策理论的框架，明确解释的具体用途，并通过理论和实证结合的方式评估解释的价值。

Result: 框架可应用于多种场景（如临床决策支持、提供补救措施或调试），并能量化解释对理想决策者性能的最大提升。

Conclusion: 解释性方法应针对具体用途设计，并通过明确用途和结合理论实证评估来提升其实际价值。

Abstract: Modern methods for explainable machine learning are designed to describe how
models map inputs to outputs--without deep consideration of how these
explanations will be used in practice. This paper argues that explanations
should be designed and evaluated with a specific end in mind. We describe how
to formalize this end in a framework based in statistical decision theory. We
show how this functionally-grounded approach can be applied across diverse use
cases, such as clinical decision support, providing recourse, or debugging. We
demonstrate its use to characterize the maximum "boost" in performance on a
particular task that an explanation could provide an idealized decision-maker,
preventing misuse due to ambiguity by forcing researchers to specify concrete
use cases that can be analyzed in light of models of expected explanation use.
We argue that evaluation should meld theoretical and empirical perspectives on
the value of explanation, and contribute definitions that span these
perspectives.

</details>


### [5] [Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems](https://arxiv.org/abs/2506.22774)
*Michael Papademas,Xenia Ziouvelou,Antonis Troumpoukis,Vangelis Karkaletsis*

Main category: cs.AI

TL;DR: 论文提出了一种结合伦理与算法的评估方法，旨在量化AI系统的可信度，弥补现有指南与技术工具的不足。


<details>
  <summary>Details</summary>
Motivation: AI技术的广泛影响及其复杂性导致对其可信度的评估缺乏全面性与量化方法，亟需一种结合伦理与算法的框架。

Method: 结合Trustworthy AI的伦理组件与PageRank、TrustRank的算法流程，提出一种评估框架。

Result: 该方法通过量化指标与理论内容的结合，实现了对AI系统可信度的全面评估。

Conclusion: 提出的方法为AI可信度评估提供了更客观、全面的解决方案，兼具伦理与算法的优势。

Abstract: Artificial Intelligence (AI) technology epitomizes the complex challenges
posed by human-made artifacts, particularly those widely integrated into
society and exert significant influence, highlighting potential benefits and
their negative consequences. While other technologies may also pose substantial
risks, AI's pervasive reach makes its societal effects especially profound. The
complexity of AI systems, coupled with their remarkable capabilities, can lead
to a reliance on technologies that operate beyond direct human oversight or
understanding. To mitigate the risks that arise, several theoretical tools and
guidelines have been developed, alongside efforts to create technological tools
aimed at safeguarding Trustworthy AI. The guidelines take a more holistic view
of the issue but fail to provide techniques for quantifying trustworthiness.
Conversely, while technological tools are better at achieving such
quantification, they lack a holistic perspective, focusing instead on specific
aspects of Trustworthy AI. This paper aims to introduce an assessment method
that combines the ethical components of Trustworthy AI with the algorithmic
processes of PageRank and TrustRank. The goal is to establish an assessment
framework that minimizes the subjectivity inherent in the self-assessment
techniques prevalent in the field by introducing algorithmic criteria. The
application of our approach indicates that a holistic assessment of an AI
system's trustworthiness can be achieved by providing quantitative insights
while considering the theoretical content of relevant guidelines.

</details>


### [6] [ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models](https://arxiv.org/abs/2506.22865)
*Ziqi Zhong,Xunzhu Tang*

Main category: cs.AI

TL;DR: ReasonBridge通过层次知识蒸馏框架，将闭源模型的推理能力高效迁移到开源模型，显著缩小性能差距。


<details>
  <summary>Details</summary>
Motivation: 解决闭源与开源模型在复杂推理任务中的性能差距问题。

Method: 采用层次蒸馏、稀疏适配器架构和测试时计算扩展机制，使用精心筛选的Reason1K数据集。

Result: 开源模型推理能力提升23%，Qwen2.5-14B在部分任务上超越闭源模型。

Conclusion: ReasonBridge为推理能力增强提供了一种样本高效的方法，适用于多种领域和架构。

Abstract: Recent advancements in Large Language Models (LLMs) have revealed a
significant performance gap between closed-source and open-source models,
particularly in tasks requiring complex reasoning and precise instruction
following. This paper introduces ReasonBridge, a methodology that efficiently
transfers reasoning capabilities from powerful closed-source to open-source
models through a novel hierarchical knowledge distillation framework. We
develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning
traces emphasizing difficulty, diversity, and quality. These traces are
filtered from across multiple domains using a structured multi-criteria
selection algorithm. Our transfer learning approach incorporates: (1) a
hierarchical distillation process capturing both strategic abstraction and
tactical implementation patterns, (2) a sparse reasoning-focused adapter
architecture requiring only 0.3% additional trainable parameters, and (3) a
test-time compute scaling mechanism using guided inference interventions.
Comprehensive evaluations demonstrate that ReasonBridge improves reasoning
capabilities in open-source models by up to 23% on benchmark tasks,
significantly narrowing the gap with closed-source models. Notably, the
enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its
performance on competition-level AIME problems. Our methodology generalizes
effectively across diverse reasoning domains and model architectures,
establishing a sample-efficient approach to reasoning enhancement for
instruction following.

</details>


### [7] [Agentic Enterprise: AI-Centric User to User-Centric AI](https://arxiv.org/abs/2506.22893)
*Arpit Narechania,Alex Endert,Atanu R Sinha*

Main category: cs.AI

TL;DR: 论文探讨了AI在企业决策中的潜力，提出了六项原则以推动用户为中心的AI设计，并强调市场机制的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究AI如何提升企业决策效率，弥补当前以AI为中心的用户范式的不足。

Method: 通过分析企业决策需求，提出六项原则，并建议采用用户为中心的AI设计和市场机制。

Result: 提出了六项原则，强调用户为中心的AI设计对提升企业决策效率的重要性。

Conclusion: 用户为中心的AI设计和市场机制是实现企业决策效率提升的关键。

Abstract: After a very long winter, the Artificial Intelligence (AI) spring is here.
Or, so it seems over the last three years. AI has the potential to impact many
areas of human life - personal, social, health, education, professional. In
this paper, we take a closer look at the potential of AI for Enterprises, where
decision-making plays a crucial and repeated role across functions, tasks, and
operations. We consider Agents imbued with AI as means to increase
decision-productivity of enterprises. We highlight six tenets for Agentic
success in enterprises, by drawing attention to what the current, AI-Centric
User paradigm misses, in the face of persistent needs of and usefulness for
Enterprise Decision-Making. In underscoring a shift to User-Centric AI, we
offer six tenets and promote market mechanisms for platforms, aligning the
design of AI and its delivery by Agents to the cause of enterprise users.

</details>


### [8] [Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning](https://arxiv.org/abs/2506.22919)
*Sanskar Pandey,Ruhaan Chopra,Saad Murtaza Bhat,Ark Abhyudaya*

Main category: cs.AI

TL;DR: Hecto是一种轻量级的混合专家（MoE）架构，通过结合GRU和FFNN专家实现异构计算，提升专业化和可解释性，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型的专家依赖相同的归纳偏差，限制了表示多样性和计算效率，Hecto旨在通过异构架构解决这一问题。

Method: Hecto结合GRU专家（时间推理）和FFNN专家（静态抽象），采用稀疏Top-1门控机制。

Result: 在多个基准测试中，Hecto性能接近或优于同质基线，专家表现出明确的专业化（时间vs静态推理）。

Conclusion: Hecto为条件计算提供了新基准，其异构架构在低资源场景中表现出稳定性和可解释性。

Abstract: Mixture-of-Experts (MoE) models enable conditional computation by routing
inputs to specialized experts, but these experts rely on identical inductive
biases, thus limiting representational diversity. This static computation
pathway is inefficient for inputs that require different types of reasoning and
limits specialization and interpretability. We propose Hecto, a lightweight MoE
architecture that leverages architectural heterogeneity by combining a GRU
expert for temporal reasoning and an FFNN expert for static abstraction under a
sparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG
News, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely
trails homogeneous baselines in performance despite receiving isolated input
representations, while achieving clear expert specialization, with each expert
aligning to distinct reasoning types (temporal vs static). At larger batch
sizes, Hecto exhibits improved performance, benefiting from relaxed
computational constraints that allow its heterogeneous architecture to optimize
more effectively. Ablation results isolate architectural diversity as the
source of Hecto's stability and interpretability across diverse reasoning
tasks. Overall, Hecto establishes itself as a new benchmark for conditional
computation, offering a principled framework for specialized reasoning in
low-resource regimes with its model strength derived from principled
specialization.

</details>


### [9] [Improving Rationality in the Reasoning Process of Language Models through Self-playing Game](https://arxiv.org/abs/2506.22920)
*Pinzheng Wang,Juntao Li,Zecheng Tang,Haijia Gui,Min zhang*

Main category: cs.AI

TL;DR: 通过自玩的批评-辨别游戏（CDG）提升大语言模型（LLM）在推理过程中的理性能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在推理任务中表现优秀，但缺乏对其推理过程的真正理解。

Method: 设计CDG游戏，模型作为证明者提供解决方案，随后接受批评者的挑战，区分误导与建设性反馈。

Result: 实验表明，CDG训练显著提升了模型在数学推理、错误检测、自我修正和长链推理中的能力。

Conclusion: 自玩方法CDG能有效增强模型对推理过程的理解能力。

Abstract: Large language models (LLMs) have demonstrated considerable reasoning
abilities in various tasks such as mathematics and coding. However, recent
studies indicate that even the best models lack true comprehension of their
reasoning processes. In this paper, we explore how self-play can enhance the
rationality of models in the reasoning process without supervision from humans
or superior models. We design a Critic-Discernment Game(CDG) in which a prover
first provides a solution to a given problem and is subsequently challenged by
critiques of its solution. These critiques either aim to assist or mislead the
prover. The objective of the prover is to maintain the correct answer when
faced with misleading comments, while correcting errors in response to
constructive feedback. Our experiments on tasks involving mathematical
reasoning, stepwise error detection, self-correction, and long-chain reasoning
demonstrate that CDG training can significantly improve the ability of
well-aligned LLMs to comprehend their reasoning process.

</details>


### [10] [MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning](https://arxiv.org/abs/2506.22992)
*Yulun Jiang,Yekun Chai,Maria Brbić,Michael Moor*

Main category: cs.AI

TL;DR: MARBLE是一个多模态推理基准测试，旨在评估多模态语言模型（MLLMs）在复杂多模态问题中的逐步推理能力。现有模型表现不佳，表明多模态推理仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有推理基准测试多局限于文本或简单多模态问题，复杂多模态推理能力尚未被充分研究。

Method: MARBLE包含两个高难度任务（M-Portal和M-Cube），要求模型在空间、视觉和物理约束下制定和理解多步计划。

Result: 12个先进模型在MARBLE上表现接近随机水平，M-Cube任务准确率为0%，表明现有模型在多模态推理上仍有不足。

Conclusion: MARBLE揭示了MLLMs的局限性，希望推动下一代具备多模态推理能力的模型发展。

Abstract: The ability to process information from multiple modalities and to reason
through it step-by-step remains a critical challenge in advancing artificial
intelligence. However, existing reasoning benchmarks focus on text-only
reasoning, or employ multimodal questions that can be answered by directly
retrieving information from a non-text modality. Thus, complex reasoning
remains poorly understood in multimodal domains. Here, we present MARBLE, a
challenging multimodal reasoning benchmark that is designed to scrutinize
multimodal language models (MLLMs) in their ability to carefully reason
step-by-step through complex multimodal problems and environments. MARBLE is
composed of two highly challenging tasks, M-Portal and M-Cube, that require the
crafting and understanding of multistep plans under spatial, visual, and
physical constraints. We find that current MLLMs perform poorly on MARBLE --
all the 12 advanced models obtain near-random performance on M-Portal and 0%
accuracy on M-Cube. Only in simplified subtasks some models outperform the
random baseline, indicating that complex reasoning is still a challenge for
existing MLLMs. Moreover, we show that perception remains a bottleneck, where
MLLMs occasionally fail to extract information from the visual inputs. By
shedding a light on the limitations of MLLMs, we hope that MARBLE will spur the
development of the next generation of models with the ability to reason and
plan across many, multimodal reasoning steps.

</details>


### [11] [AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks](https://arxiv.org/abs/2506.23049)
*Leander Melroy Maben,Gayathri Ganesh Lakshmy,Srijith Radhakrishnan,Siddhant Arora,Shinji Watanabe*

Main category: cs.AI

TL;DR: AURA是首个开源的语音原生助手，支持动态工具调用和多轮对话，完成复杂任务。


<details>
  <summary>Details</summary>
Motivation: 尽管语言和语音技术有进步，但缺乏开源系统支持语音到语音的多轮对话与工具集成。

Method: AURA结合开放权重的ASR、TTS和LLM，采用模块化设计，支持自然语言提示和工具集成。

Result: 在VoiceBench上表现优异，OpenBookQA得分92.75%，接近GPT-4o；人类评估任务成功率达90%。

Conclusion: AURA展示了开源语音助手在复杂任务中的潜力，为未来研究提供了基础。

Abstract: Despite advances in language and speech technologies, no open-source system
enables full speech-to-speech, multi-turn dialogue with integrated tool use and
agentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and
Automated Tool Use), the first open-source, speech-native assistant capable of
completing complex, goal-driven tasks through dynamic tool invocation and
multi-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a
cascaded pipeline and supports tools such as calendar booking, contact lookup,
web search, and email. Its modular design allows easy integration of new tools
using natural language prompts and action classes. On VoiceBench, AURA scores
92.75% on OpenBookQA-outperforming all open-weight systems and nearing
GPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems.
Human evaluation shows 90% task success on complex, multi-turn speech tasks.

</details>


### [12] [AI's Euclid's Elements Moment: From Language Models to Computable Thought](https://arxiv.org/abs/2506.23080)
*Xinmin Fang,Lingfeng Tao,Zhengxiong Li*

Main category: cs.AI

TL;DR: 本文提出了一个五阶段进化框架，用于理解人工智能的发展，认为其轨迹与人类认知技术的历史进展相似。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能的发展路径，提供一个跨学科的系统模型，解释其过去的结构变化并指导未来方向。

Method: 通过类比人类认知技术的里程碑（如楔形文字、字母、逻辑等），构建了一个“认知几何”框架，分析AI的进化阶段。

Result: AI的进化不仅是线性的，还具有自反性，当前正进入“元语言时刻”，未来将迈向“数学符号时刻”和“形式逻辑系统时刻”。

Conclusion: 该研究为未来AI发展提供了理论基础和实用策略，是作者三部曲的方法论总结。

Abstract: This paper presents a comprehensive five-stage evolutionary framework for
understanding the development of artificial intelligence, arguing that its
trajectory mirrors the historical progression of human cognitive technologies.
We posit that AI is advancing through distinct epochs, each defined by a
revolutionary shift in its capacity for representation and reasoning, analogous
to the inventions of cuneiform, the alphabet, grammar and logic, mathematical
calculus, and formal logical systems. This "Geometry of Cognition" framework
moves beyond mere metaphor to provide a systematic, cross-disciplinary model
that not only explains AI's past architectural shifts-from expert systems to
Transformers-but also charts a concrete and prescriptive path forward.
Crucially, we demonstrate that this evolution is not merely linear but
reflexive: as AI advances through these stages, the tools and insights it
develops create a feedback loop that fundamentally reshapes its own underlying
architecture. We are currently transitioning into a "Metalinguistic Moment,"
characterized by the emergence of self-reflective capabilities like
Chain-of-Thought prompting and Constitutional AI. The subsequent stages, the
"Mathematical Symbolism Moment" and the "Formal Logic System Moment," will be
defined by the development of a computable calculus of thought, likely through
neuro-symbolic architectures and program synthesis, culminating in provably
aligned and reliable AI that reconstructs its own foundational representations.
This work serves as the methodological capstone to our trilogy, which
previously explored the economic drivers ("why") and cognitive nature ("what")
of AI. Here, we address the "how," providing a theoretical foundation for
future research and offering concrete, actionable strategies for startups and
developers aiming to build the next generation of intelligent systems.

</details>


### [13] [Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study](https://arxiv.org/abs/2506.23107)
*Bing Song,Jianing Liu,Sisi Jian,Chenyang Wu,Vinayak Dixit*

Main category: cs.AI

TL;DR: 研究探讨了大型语言模型（LLMs）在模拟风险决策行为中的表现，发现模型比人类更规避风险，且中文提示下的预测偏差更大。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs应用的扩展，其在复杂决策行为（如风险决策）中的可靠性引发关注，本研究旨在评估其模拟能力。

Method: 通过彩票任务比较ChatGPT 4o和o1-mini的预测与人类实际选择，使用CRRA框架分析风险偏好，并考察多语言数据的影响。

Result: 模型比人类更规避风险，o1-mini更接近人类行为；中文提示下的预测偏差大于英文。

Conclusion: LLMs在模拟人类风险行为方面具有潜力，但在语言和文化背景下的表现仍有局限。

Abstract: Large language models (LLMs) have made significant strides, extending their
applications to dialogue systems, automated content creation, and
domain-specific advisory tasks. However, as their use grows, concerns have
emerged regarding their reliability in simulating complex decision-making
behavior, such as risky decision-making, where a single choice can lead to
multiple outcomes. This study investigates the ability of LLMs to simulate
risky decision-making scenarios. We compare model-generated decisions with
actual human responses in a series of lottery-based tasks, using transportation
stated preference survey data from participants in Sydney, Dhaka, Hong Kong,
and Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and
ChatGPT o1-mini -- which were tasked with predicting individual choices. Risk
preferences were analyzed using the Constant Relative Risk Aversion (CRRA)
framework. Results show that both models exhibit more risk-averse behavior than
human participants, with o1-mini aligning more closely with observed human
decisions. Further analysis of multilingual data from Nanjing and Hong Kong
indicates that model predictions in Chinese deviate more from actual responses
compared to English, suggesting that prompt language may influence simulation
performance. These findings highlight both the promise and the current
limitations of LLMs in replicating human-like risk behavior, particularly in
linguistic and cultural settings.

</details>


### [14] [The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy](https://arxiv.org/abs/2506.23123)
*Rishi Bommasani*

Main category: cs.AI

TL;DR: 这篇论文探讨了人工智能基础模型对社会的影响，提出了理解其能力、风险及供应链的概念框架，并通过实证研究和政策建议推动更好的AI治理。


<details>
  <summary>Details</summary>
Motivation: 基础模型作为AI技术的核心，带来了巨大潜力，但也引发了困惑和担忧。论文旨在通过科学研究和政策接口，实现更好的社会效果。

Method: 围绕三个主题展开：概念框架（能力、风险、供应链）、实证研究（模型评估和组织透明度）、政策行动（基于证据的AI政策）。

Result: 论文为理解基础模型的社会影响提供了科学基础，并推动了研究与实践的结合。

Conclusion: 通过建立科学基础和研究政策接口，论文为实现AI时代更好的社会效果做出了贡献。

Abstract: Artificial intelligence is humanity's most promising technology because of
the remarkable capabilities offered by foundation models. Yet, the same
technology brings confusion and consternation: foundation models are poorly
understood and they may precipitate a wide array of harms. This dissertation
explains how technology and society coevolve in the age of AI, organized around
three themes. First, the conceptual framing: the capabilities, risks, and the
supply chain that grounds foundation models in the broader economy. Second, the
empirical insights that enrich the conceptual foundations: transparency created
via evaluations at the model level and indexes at the organization level.
Finally, the transition from understanding to action: superior understanding of
the societal impact of foundation models advances evidence-based AI policy.
View together, this dissertation makes inroads into achieving better societal
outcomes in the age of AI by building the scientific foundations and
research-policy interface required for better AI governance.

</details>


### [15] [Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons](https://arxiv.org/abs/2506.23128)
*Chi Chiu So,Yueyue Sun,Jun-Min Wang,Siu Pang Yung,Anthony Wai Keung Loh,Chun Pong Chau*

Main category: cs.AI

TL;DR: 论文评估了三种前沿大语言模型（DeepSeek-R1、DeepSeek-V3和GPT-4o）在深度关系推理任务中的表现，发现DeepSeek-R1表现最佳，但所有模型在问题复杂度增加时均表现不佳。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在深度关系推理任务中的能力，并比较不同模型的性能。

Method: 通过设计家族树和一般图推理的基准任务，评估三种模型的推理能力。

Result: DeepSeek-R1在多个任务中表现最佳，但随着问题复杂度增加，所有模型表现下降。

Conclusion: 研究揭示了模型在复杂推理任务中的局限性，并提出了未来改进方向，如多模态推理和系统性分析推理失败。

Abstract: How far are Large Language Models (LLMs) in performing deep relational
reasoning? In this paper, we evaluate and compare the reasoning capabilities of
three cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a
suite of carefully designed benchmark tasks in family tree and general graph
reasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the
highest F1-scores across multiple tasks and problem sizes, demonstrating strong
aptitude in logical deduction and relational inference. However, all evaluated
models, including DeepSeek-R1, struggle significantly as problem complexity
increases, largely due to token length limitations and incomplete output
structures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought
responses uncovers its unique planning and verification strategies, but also
highlights instances of incoherent or incomplete reasoning, calling attention
to the need for deeper scrutiny into LLMs' internal inference dynamics. We
further discuss key directions for future work, including the role of
multimodal reasoning and the systematic examination of reasoning failures. Our
findings provide both empirical insights and theoretical implications for
advancing LLMs' reasoning abilities, particularly in tasks that demand
structured, multi-step logical inference. Our code repository will be publicly
available at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.

</details>


### [16] [Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing](https://arxiv.org/abs/2506.23141)
*Siyuan Li,Ruitong Liu,Yan Wen,Te Sun*

Main category: cs.AI

TL;DR: 论文提出了一种语义感知的关系消息传递框架，通过Top-K邻居选择策略和多头注意力聚合器，有效减少知识图谱完成中的噪声和信息稀释问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于节点的消息传递机制在知识图谱中会引入噪声和信息稀释，因此需要一种更精准的方法来捕捉语义上下文。

Method: 采用语义感知的Top-K邻居选择策略和多头注意力聚合器，选择最相关的邻居并融合信息。

Result: 实验表明，该方法在多个基准测试中优于现有方法。

Conclusion: 提出的框架能更准确地捕捉和传播与链接预测任务最相关的信息，减少无关信息的干扰。

Abstract: Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge
Graph Completion (KGC), providing vital cues for prediction. However,
traditional node-based message passing mechanisms, when applied to knowledge
graphs, often introduce noise and suffer from information dilution or
over-smoothing by indiscriminately aggregating information from all neighboring
edges. To address this challenge, we propose a semantic-aware relational
message passing. A core innovation of this framework is the introduction of a
\textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this
strategy first evaluates the semantic relevance between a central node and its
incident edges within a shared latent space, selecting only the Top-K most
pertinent ones. Subsequently, information from these selected edges is
effectively fused with the central node's own representation using a
\textbf{multi-head attention aggregator} to generate a semantically focused
node message. In this manner, our model not only leverages the structure and
features of edges within the knowledge graph but also more accurately captures
and propagates the contextual information most relevant to the specific link
prediction task, thereby effectively mitigating interference from irrelevant
information. Extensive experiments demonstrate that our method achieves
superior performance compared to existing approaches on several established
benchmarks.

</details>


### [17] [Rises for Measuring Local Distributivity in Lattices](https://arxiv.org/abs/2506.23168)
*Mohammad Abdulla,Tobias Hille,Dominik Dürrschnabel,Gerd Stumme*

Main category: cs.AI

TL;DR: 提出了一种通过“rises”来量化格中分配性的方法，并证明其与经典分配性概念的关系。


<details>
  <summary>Details</summary>
Motivation: 在形式概念分析（FCA）中，格的分配性缺乏标准化度量，需要一种量化方法。

Method: 引入“rises”概念，用于评估格中属性或对象数量的变化，并与经典分配性概念关联。

Result: 证明格是分配性的当且仅当无非单位rises；现实数据的概念格多为join-distributive，而非meet-distributive。

Conclusion: rises是量化分配性的有效工具，揭示了现实数据中分配性的分布特点。

Abstract: Distributivity is a well-established and extensively studied notion in
lattice theory. In the context of data analysis, particularly within Formal
Concept Analysis (FCA), lattices are often observed to exhibit a high degree of
distributivity. However, no standardized measure exists to quantify this
property. In this paper, we introduce the notion of rises in (concept) lattices
as a means to assess distributivity. Rises capture how the number of attributes
or objects in covering concepts change within the concept lattice. We show that
a lattice is distributive if and only if no non-unit rises occur. Furthermore,
we relate rises to the classical notion of meet- and join distributivity. We
observe that concept lattices from real-world data are to a high degree
join-distributive, but much less meet-distributive. We additionally study how
join-distributivity manifests on the level of ordered sets.

</details>


### [18] [FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis](https://arxiv.org/abs/2506.23273)
*Quang Hung Nguyen,Phuong Anh Trinh,Phan Quoc Hung Mai,Tuan Phong Trinh*

Main category: cs.AI

TL;DR: FinStat2SQL是一个轻量级的text2sql管道，专为金融领域设计，结合大、小语言模型处理复杂查询，在越南企业中表现优于GPT-4o-mini。


<details>
  <summary>Details</summary>
Motivation: 金融领域的数据库设计和报表格式差异大，传统text2sql难以应对复杂和特定领域的查询需求。

Method: 采用多智能体设置，结合大、小语言模型进行实体提取、SQL生成和自我修正，并针对本地标准（如VAS）优化。

Result: 7B微调模型在合成QA数据集上达到61.33%准确率，响应时间低于4秒，优于GPT-4o-mini。

Conclusion: FinStat2SQL为越南企业提供了可扩展、成本高效的金融分析解决方案。

Abstract: Despite the advancements of large language models, text2sql still faces many
challenges, particularly with complex and domain-specific queries. In finance,
database designs and financial reporting layouts vary widely between financial
entities and countries, making text2sql even more challenging. We present
FinStat2SQL, a lightweight text2sql pipeline enabling natural language queries
over financial statements. Tailored to local standards like VAS, it combines
large and small language models in a multi-agent setup for entity extraction,
SQL generation, and self-correction. We build a domain-specific database and
evaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves
61.33\% accuracy with sub-4-second response times on consumer hardware,
outperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient
solution for financial analysis, making AI-powered querying accessible to
Vietnamese enterprises.

</details>


### [19] [Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games](https://arxiv.org/abs/2506.23276)
*David Guzman Piedrahita,Yongjin Yang,Mrinmaya Sachan,Giorgia Ramponi,Bernhard Schölkopf,Zhijing Jin*

Main category: cs.AI

TL;DR: 研究大型语言模型（LLMs）在多智能体系统中的合作行为，发现不同模型在公共物品博弈中表现出四种行为模式，推理能力强的模型反而不擅长合作。


<details>
  <summary>Details</summary>
Motivation: 理解LLMs在自主代理中的合作机制，确保其部署的安全性和稳健性。

Method: 通过公共物品博弈实验，观察不同LLMs在重复互动中的行为模式。

Result: 发现四种行为模式，推理能力强的模型合作表现较差。

Conclusion: 当前提升LLMs推理能力的方法未必能促进合作，对需要协作的环境部署有重要启示。

Abstract: As large language models (LLMs) are increasingly deployed as autonomous
agents, understanding their cooperation and social mechanisms is becoming
increasingly important. In particular, how LLMs balance self-interest and
collective well-being is a critical challenge for ensuring alignment,
robustness, and safe deployment. In this paper, we examine the challenge of
costly sanctioning in multi-agent LLM systems, where an agent must decide
whether to invest its own resources to incentivize cooperation or penalize
defection. To study this, we adapt a public goods game with institutional
choice from behavioral economics, allowing us to observe how different LLMs
navigate social dilemmas over repeated interactions. Our analysis reveals four
distinct behavioral patterns among models: some consistently establish and
sustain high levels of cooperation, others fluctuate between engagement and
disengagement, some gradually decline in cooperative behavior over time, and
others rigidly follow fixed strategies regardless of outcomes. Surprisingly, we
find that reasoning LLMs, such as the o1 series, struggle significantly with
cooperation, whereas some traditional LLMs consistently achieve high levels of
cooperation. These findings suggest that the current approach to improving
LLMs, which focuses on enhancing their reasoning capabilities, does not
necessarily lead to cooperation, providing valuable insights for deploying LLM
agents in environments that require sustained collaboration. Our code is
available at https://github.com/davidguzmanp/SanctSim

</details>


### [20] [GATSim: Urban Mobility Simulation with Generative Agents](https://arxiv.org/abs/2506.23306)
*Qi Liu,Can Li,Wanjing Ma*

Main category: cs.AI

TL;DR: GATSim利用大型语言模型和AI代理技术，提出了一种新型城市交通模拟框架，生成具有丰富行为特征的代理，能够模拟人类复杂的旅行决策行为。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的代理模拟无法捕捉人类旅行决策的复杂性、适应性和行为多样性，因此需要更先进的模拟方法。

Method: GATSim结合城市交通基础模型、代理认知系统和交通模拟环境，通过心理记忆系统、工具使用能力和终身学习机制，生成具有多样社会经济属性和偏好的代理。

Result: 实验表明，GATSim代理在交通场景中表现与人类标注者相当，并能自然生成宏观交通演化模式。

Conclusion: GATSim为城市交通模拟提供了更真实、适应性更强的解决方案，代码已开源。

Abstract: Traditional agent-based urban mobility simulations rely on rigid rule-based
systems that fail to capture the complexity, adaptability, and behavioral
diversity characteristic of human travel decision-making. Recent advances in
large language models and AI agent technology offer opportunities to create
agents with reasoning capabilities, persistent memory, and adaptive learning
mechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel
framework that leverages these advances to create generative agents with rich
behavioral characteristics for urban mobility simulation. Unlike conventional
approaches, GATSim agents possess diverse socioeconomic attributes, individual
lifestyles, and evolving preferences that shape their mobility decisions
through psychologically-informed memory systems, tool usage capabilities, and
lifelong learning mechanisms. The main contributions of this study include: (1)
a comprehensive architecture combining an urban mobility foundation model with
agent cognitive systems and transport simulation environment, (2) a fully
functional prototype implementation, and (3) systematic validation
demonstrating that generative agents produce believable travel behaviors.
Through designed reflection processes, generative agents in this study can
transform specific travel experiences into generalized insights, enabling
realistic behavioral adaptation over time with specialized mechanisms for
activity planning and real-time reactive behaviors tailored to urban mobility
contexts. Experiments show that generative agents perform competitively with
human annotators in mobility scenarios while naturally producing macroscopic
traffic evolution patterns. The code for the prototype system is shared at
https://github.com/qiliuchn/gatsim.

</details>


### [21] [The Confidence Paradox: Can LLM Know When It's Wrong](https://arxiv.org/abs/2506.23464)
*Sahil Tripathi,Md Tabrez Nafis,Imran Hussain,Jiechao Gao*

Main category: cs.AI

TL;DR: HonestVQA是一个自监督的诚实校准框架，旨在解决DocVQA系统中的伦理问题，通过量化不确定性、对齐模型置信度与准确性，并引入新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有DocVQA系统在伦理上不透明，存在过度自信或不确定性传达不足的问题，可能导致高风险领域的伦理责任问题。

Method: HonestVQA采用模型无关的方法，包括不确定性量化、加权损失函数对齐置信度与正确性，以及通过对比学习强制伦理响应行为。

Result: HonestVQA在多个数据集上提升了DocVQA的准确性和F1分数，同时降低了过度自信，表现出良好的泛化能力。

Conclusion: HonestVQA通过伦理对齐和自监督学习，显著提升了DocVQA系统的性能和可靠性，为伦理敏感的领域提供了更可信的解决方案。

Abstract: Document Visual Question Answering (DocVQA) systems are increasingly deployed
in real world applications, yet they remain ethically opaque-often producing
overconfident answers to ambiguous questions or failing to communicate
uncertainty in a trustworthy manner. This misalignment between model confidence
and actual knowledge poses significant risks, particularly in domains requiring
ethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT
have advanced SOTA performance by focusing on architectural sophistication and
accuracy; however, they fall short in ethical responsiveness.
  To address these limitations, we introduce HonestVQA, a self-supervised
honesty calibration framework for ethically aligned DocVQA. Our model-agnostic
method quantifies uncertainty to identify knowledge gaps, aligns model
confidence with actual correctness using weighted loss functions, and enforces
ethical response behavior via contrastive learning. We further introduce two
principled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence
Index (ECI)--to benchmark alignment between confidence, accuracy, and ethical
communication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%
and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces
overconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In
cross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,
demonstrating strong generalization. Ablation shows a 3.8% drop in accuracy
without alignment or contrastive loss.

</details>


### [22] [Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence](https://arxiv.org/abs/2506.23503)
*Bosubabu Sambana,Kondreddygari Archana,Suram Indhra Sena Reddy,Shaik Meethaigar Jameer Basha,Shaik Karishma*

Main category: cs.AI

TL;DR: 该论文提出了一种基于CBT框架的系统，利用BERT、RoBERTa等模型分析社交媒体中的负面情绪和认知扭曲，并预测潜在心理健康问题。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏有效方法分析社交媒体中的认知路径，这对心理治疗师提供及时干预至关重要。

Method: 结合BERT、RoBERTa进行情感分析，T5、PEGASUS进行文本摘要，mT5进行多语言翻译，以检测负面情绪和认知扭曲。

Result: 系统不仅能识别负面思维，还能预测其他心理健康问题，如恐惧症和饮食障碍。

Conclusion: 该系统为心理治疗师提供了早期检测和干预的强大工具，扩展了CBT的应用范围。

Abstract: Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the
irrational thought patterns associated with mental health disorders, but its
effectiveness relies on accurately identifying cognitive pathways to provide
targeted treatment. In today's digital age, individuals often express negative
emotions on social media, where they may reveal cognitive distortions, and in
severe cases, exhibit suicidal tendencies. However, there is a significant gap
in methodologies designed to analyze these cognitive pathways, which could be
critical for psychotherapists aiming to deliver timely and effective
interventions in online environments. Cognitive Behavioral Therapy (CBT)
framework leveraging acceptance, commitment and data augmentation to categorize
and address both textual and visual content as positive or negative.
Specifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5,
PEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages
focusing on detecting negative emotions and cognitive distortions within social
media data. While existing models are primarily designed to identify negative
thoughts, the proposed system goes beyond this by predicting additional
negative side effects and other potential mental health disorders likes
Phobias, Eating Disorders. This enhancement allows for a more comprehensive
understanding and intervention strategy, offering psychotherapists a powerful
tool for early detection and treatment of various psychological issues.

</details>


### [23] [Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM](https://arxiv.org/abs/2506.23504)
*Bosubabu Sambana,Kotamsetty Geethika Devi,Bandi Rajeswara Reddy,Galeti Mohammad Hussain,Gownivalla Siddartha*

Main category: cs.AI

TL;DR: 提出了一种结合AlexNet和LSTM的混合模型，用于提高电价预测的准确性，解决了传统方法在时间序列数据上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅关注需求和价格，无法准确预测电价，且对时间序列数据的处理能力有限。

Method: 结合AlexNet的特征提取能力和LSTM的序列学习能力，引入外部变量（如温度、阳光、降雨等），并采用最小-最大缩放和时间窗口技术。

Result: 混合模型的预测准确率达到97.08%，优于单独的RNN（96.64%）和ANN（96.63%）模型。

Conclusion: 该混合模型显著提高了电价预测的准确性，证明了其在处理复杂时间序列数据中的优势。

Abstract: The recent development of advanced machine learning methods for hybrid models
has greatly addressed the need for the correct prediction of electrical prices.
This method combines AlexNet and LSTM algorithms, which are used to introduce a
new model with higher accuracy in price forecasting. Despite RNN and ANN being
effective, they often fail to deal with forex time sequence data. The
traditional methods do not accurately forecast the prices. These traditional
methods only focus on demand and price which leads to insufficient analysis of
data. To address this issue, using the hybrid approach, which focuses on
external variables that also effect the predicted prices. Nevertheless, due to
AlexNet's excellent feature extraction and LSTM's learning sequential patterns,
the prediction accuracy is vastly increased. The model is built on the past
data, which has been supplied with the most significant elements like demand,
temperature, sunlight, and rain. For example, the model applies methods, such
as minimum-maximum scaling and a time window, to predict the electricity prices
of the future. The results show that this hybrid model is good than the
standalone ones in terms of accuracy. Although we got our accuracy rating of
97.08, it shows higher accompaniments than remaining models RNN and ANN with
accuracies of 96.64 and 96.63 respectively.

</details>


### [24] [Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays](https://arxiv.org/abs/2506.23517)
*Selin Dik,Osman Erdem,Mehmet Dik*

Main category: cs.AI

TL;DR: 研究了GPTZero在不同长度文本中检测AI生成内容的准确性，发现其对AI文本检测效果较好，但对人类文本存在误判。


<details>
  <summary>Details</summary>
Motivation: 随着学生使用AI工具的增加，教师依赖AI检测工具，但其可靠性尚不明确。

Method: 收集28篇AI生成和50篇人类写作的文本，按长度分类后使用GPTZero检测。

Result: AI生成文本检测准确率高（91-100%），但人类文本存在误报。

Conclusion: GPTZero对纯AI文本有效，但对人类文本区分能力有限，需谨慎使用。

Abstract: As the use of AI tools by students has become more prevalent, instructors
have started using AI detection tools like GPTZero and QuillBot to detect AI
written text. However, the reliability of these detectors remains uncertain. In
our study, we focused mostly on the success rate of GPTZero, the most-used AI
detector, in identifying AI-generated texts based on different lengths of
randomly submitted essays: short (40-100 word count), medium (100-350 word
count), and long (350-800 word count). We gathered a data set consisting of
twenty-eight AI-generated papers and fifty human-written papers. With this
randomized essay data, papers were individually plugged into GPTZero and
measured for percentage of AI generation and confidence. A vast majority of the
AI-generated papers were detected accurately (ranging from 91-100% AI believed
generation), while the human generated essays fluctuated; there were a handful
of false positives. These findings suggest that although GPTZero is effective
at detecting purely AI-generated content, its reliability in distinguishing
human-authored texts is limited. Educators should therefore exercise caution
when relying solely on AI detection tools.

</details>


### [25] [ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data](https://arxiv.org/abs/2506.23520)
*Yu Zhang,Ruijie Yu,Jidong Tian,Feng Zhu,Jiapeng Liu,Xiaokang Yang,Yaohui Jin,Yanyan Xu*

Main category: cs.AI

TL;DR: ChemActor是一个基于大型语言模型（LLM）的化学执行器，用于将非结构化的实验步骤转换为结构化的动作序列，通过LLM生成的数据框架解决了标注数据不足和质量低的问题。


<details>
  <summary>Details</summary>
Motivation: 随着机器人合成在有机化学中的兴趣增加，从文献中自动提取化学步骤变得至关重要，但化学语言的模糊性和高成本的人工标注使其具有挑战性。

Method: 提出了一种顺序LLM生成的数据框架，结合数据选择模块和多轮LLM循环评估指标，生成机器可执行的动作。

Result: 在反应到描述（R2D）和描述到动作（D2A）任务中，ChemActor表现优于基线模型10%。

Conclusion: ChemActor通过LLM生成的数据增强了性能，展示了在化学实验步骤理解上的先进性。

Abstract: With the increasing interest in robotic synthesis in the context of organic
chemistry, the automated extraction of chemical procedures from literature is
critical. However, this task remains challenging due to the inherent ambiguity
of chemical language and the high cost of human annotation required for
developing reliable computer-aided extraction protocols. Here, we present
ChemActor, a fully fine-tuned large language model (LLM), as a chemical
executor to convert between unstructured experimental procedures and structured
action sequences. We propose a sequential LLM-generated data framework to
address the challenges of insufficient and low-quality annotated data. This
framework integrates a data selection module that selects data based on
distribution divergence, with a general-purpose LLM, to generate
machine-executable actions from a single molecule input. Additionally, we
introduce a novel multi-round LLMs circle review metric, which reflects the
model's advanced understanding of chemical experimental procedures. Extensive
experiments on reaction-to-description (R2D) and description-to-action (D2A)
tasks demonstrate that ChemActor, augmented by LLM-generated data, achieves
state-of-the-art performance, outperforming the baseline model by 10%. The code
is available at: https://github.com/Zhanghahah/ChemActor.

</details>


### [26] [CooT: Learning to Coordinate In-Context with Coordination Transformers](https://arxiv.org/abs/2506.23549)
*Huai-Chih Wang,Hsiang-Chun Chuang,Hsi-Chun Cheng,Dai-Jie Wu,Shao-Hua Sun*

Main category: cs.AI

TL;DR: 提出了一种名为Coordination Transformers（CooT）的新型框架，通过上下文协调快速适应未见过的合作伙伴，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中动态和不确定环境下协调的挑战，现有方法泛化能力差或训练成本高。

Method: 利用近期交互历史预测合作伙伴行为，无需显式监督或微调，快速学习协调策略。

Result: 在Overcooked基准测试中显著优于基线方法，人类评估也证实其高效协作能力。

Conclusion: CooT展现了在多智能体场景中的鲁棒性、灵活性和上下文敏感性，是高效的协作伙伴。

Abstract: Effective coordination among artificial agents in dynamic and uncertain
environments remains a significant challenge in multi-agent systems. Existing
approaches, such as self-play and population-based methods, either generalize
poorly to unseen partners or require extensive training. To overcome these
limitations, we propose Coordination Transformers (CooT), a novel in-context
coordination framework that uses recent interaction histories to adapt to
unseen partners rapidly. Unlike previous approaches that primarily aim to
increase the diversity of training partners, CooT explicitly focuses on
adapting to new partner behaviors by predicting actions aligned with observed
partner interactions. Trained on interaction trajectories collected from
diverse pairs of agents with complementary behaviors, CooT quickly learns
effective coordination strategies without explicit supervision or fine-tuning.
Evaluations on the Overcooked benchmark demonstrate that CooT significantly
outperforms baseline methods in coordination tasks involving previously unseen
partners. Human evaluations further confirm CooT as the most effective
collaborative partner, while extensive ablations highlight its robustness,
flexibility, and sensitivity to context in multi-agent scenarios.

</details>


### [27] [MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI](https://arxiv.org/abs/2506.23563)
*Huanjin Yao,Jiaxing Huang,Yawen Qiu,Michael K. Chen,Wenzheng Liu,Wei Zhang,Wenjie Zeng,Xikun Zhang,Jingyi Zhang,Yuxin Song,Wenhao Wu,Dacheng Tao*

Main category: cs.AI

TL;DR: MMReason是一个新的基准测试，旨在全面评估多模态大语言模型（MLLM）的长链推理能力，通过多样、开放和挑战性问题填补现有基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM基准在评估长链推理能力时存在不足，包括缺乏难度和多样性、易受猜测和记忆影响，以及对中间推理步骤评估不足。

Method: MMReason通过以下方法设计：（1）从多学科和多难度级别筛选挑战性问题；（2）将问题转化为开放形式并使用多模型投票技术过滤；（3）标注详细步骤并设计三元评分机制评估推理步骤。

Result: MMReason对主流MLLM进行了基准测试，并深入分析了其推理能力。

Conclusion: MMReason有望成为推动MLLM推理研究的重要资源。

Abstract: Reasoning plays a crucial role in advancing Multimodal Large Language Models
(MLLMs) toward Artificial General Intelligence. However, existing MLLM
benchmarks often fall short in precisely and comprehensively evaluating
long-chain reasoning abilities from three key aspects: (1) lack of difficulty
and diversity, (2) susceptibility to guessability and memorization, (3)
inadequate assessment of intermediate reasoning steps. To fill this gap, we
introduce MMReason, a new benchmark designed to precisely and comprehensively
evaluate MLLM long-chain reasoning capability with diverse, open-ended,
challenging questions. First, we curate challenging questions requiring
multi-step reasoning from various fields (i.e., 6 disciplines) and multiple
difficulty levels (i.e., from pre-university to university, and from
foundational to competition tiers). Second, these questions are reformulated
into an open-ended format and filtered using a multi-model voting technique to
eliminate shortcut cases related to guessing and memorization, ensuring robust
reasoning evaluations. Third, we annotate the questions with detailed
step-by-step solutions, and design a reference-based ternary scoring mechanism
to reliably assess intermediate reasoning steps. With MMReason, we benchmark
popular leading MLLMs and provide an in-depth analysis of their reasoning
capabilities. We hope MMReason will serve as a valuable resource for advancing
MLLM reasoning research. Code will be available at
https://github.com/HJYao00/MMReason.

</details>


### [28] [Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models](https://arxiv.org/abs/2506.23576)
*Maria Carolina Cornelia Wit,Jun Pang*

Main category: cs.AI

TL;DR: 多智能体LLM系统可增强对越狱攻击的防御，但存在误报和计算开销的权衡。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体LLM系统作为防御越狱攻击的有效性。

Method: 评估三种越狱策略（AutoDefense、BetterDan、JB），比较单智能体与多智能体配置。

Result: 多智能体系统提升防御效果，但效果因攻击类型而异，并增加误报和计算开销。

Conclusion: 当前自动防御存在局限，需改进未来LLM系统的对齐鲁棒性。

Abstract: Recent advances in large language models (LLMs) have raised concerns about
jailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper
investigates the use of multi-agent LLM systems as a defence against such
attacks. We evaluate three jailbreaking strategies, including the original
AutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the
AutoDefense framework, we compare single-agent setups with two- and three-agent
configurations. Our results show that multi-agent systems enhance resistance to
jailbreaks, especially by reducing false negatives. However, its effectiveness
varies by attack type, and it introduces trade-offs such as increased false
positives and computational overhead. These findings point to the limitations
of current automated defences and suggest directions for improving alignment
robustness in future LLM systems.

</details>


### [29] [Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games](https://arxiv.org/abs/2506.23626)
*António Afonso,Iolanda Leite,Alessandro Sestini,Florian Fuchs,Konrad Tollmar,Linus Gisslén*

Main category: cs.AI

TL;DR: 论文提出了一种基于语言模型的自动化方法，用于迭代调整强化学习代理的奖励函数权重，以解决游戏内容或机制修改时奖励权重不再最优的问题。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习代理在游戏生产环境中部署的两大挑战：奖励函数设计依赖专家，以及游戏内容修改导致奖励权重失效。

Method: 使用语言模型根据用户定义的行为目标和先前训练轮次的性能统计，迭代提出更新的奖励权重，实现闭环自我修正。

Result: 在赛车任务中，LM引导的代理性能显著提升，从9%成功率提高到74%（一次迭代），最终达到80%成功率和855时间步，接近专家调优的94%和850时间步。

Conclusion: 自动化LM引导的奖励权重调整方法有效，性能接近人工调优，减少了对手动奖励工程的依赖。

Abstract: Reinforcement Learning (RL) in games has gained significant momentum in
recent years, enabling the creation of different agent behaviors that can
transform a player's gaming experience. However, deploying RL agents in
production environments presents two key challenges: (1) designing an effective
reward function typically requires an RL expert, and (2) when a game's content
or mechanics are modified, previously tuned reward weights may no longer be
optimal. Towards the latter challenge, we propose an automated approach for
iteratively fine-tuning an RL agent's reward function weights, based on a
user-defined language based behavioral goal. A Language Model (LM) proposes
updated weights at each iteration based on this target behavior and a summary
of performance statistics from prior training rounds. This closed-loop process
allows the LM to self-correct and refine its output over time, producing
increasingly aligned behavior without the need for manual reward engineering.
We evaluate our approach in a racing task and show that it consistently
improves agent performance across iterations. The LM-guided agents show a
significant increase in performance from $9\%$ to $74\%$ success rate in just
one iteration. We compare our LM-guided tuning against a human expert's manual
weight design in the racing task: by the final iteration, the LM-tuned agent
achieved an $80\%$ success rate, and completed laps in an average of $855$ time
steps, a competitive performance against the expert-tuned agent's peak $94\%$
success, and $850$ time steps.

</details>


### [30] [HASD: Hierarchical Adaption for pathology Slide-level Domain-shift](https://arxiv.org/abs/2506.23673)
*Jingsong Liu,Han Li,Chen Yang,Michael Deutges,Ario Sadafi,Xin You,Katharina Breininger,Nassir Navab,Peter J. Schüffler*

Main category: cs.AI

TL;DR: 提出了一种名为HASD的分层适应框架，用于解决病理学AI中的幻灯片级域偏移问题，通过多尺度特征一致性和计算高效的域适应方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 病理学数据受中心特定条件影响严重，现有方法仅关注图像块而忽略了全局WSI特征，无法满足临床需求。

Method: HASD框架包含层次化适应模块（域级对齐、幻灯片级几何不变性正则化和块级注意力一致性正则化）和原型选择机制。

Result: 在两个任务中，HASD分别提升了4.1%的AUROC（乳腺癌HER2分级）和3.9%的C指数（UCEC生存预测）。

Conclusion: HASD为病理学机构提供了一种实用且可靠的幻灯片级域适应解决方案，降低了计算和标注成本。

Abstract: Domain shift is a critical problem for pathology AI as pathology data is
heavily influenced by center-specific conditions. Current pathology domain
adaptation methods focus on image patches rather than WSI, thus failing to
capture global WSI features required in typical clinical scenarios. In this
work, we address the challenges of slide-level domain shift by proposing a
Hierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD
achieves multi-scale feature consistency and computationally efficient
slide-level domain adaptation through two key components: (1) a hierarchical
adaptation framework that integrates a Domain-level Alignment Solver for
feature alignment, a Slide-level Geometric Invariance Regularization to
preserve the morphological structure, and a Patch-level Attention Consistency
Regularization to maintain local critical diagnostic cues; and (2) a prototype
selection mechanism that reduces computational overhead. We validate our method
on two slide-level tasks across five datasets, achieving a 4.1\% AUROC
improvement in a Breast Cancer HER2 Grading cohort and a 3.9\% C-index gain in
a UCEC survival prediction cohort. Our method provides a practical and reliable
slide-level domain adaption solution for pathology institutions, minimizing
both computational and annotation costs.

</details>


### [31] [PokéAI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red](https://arxiv.org/abs/2506.23689)
*Zihao Liu,Xinhang Sui,Yueran Song,Siwen Wang*

Main category: cs.AI

TL;DR: Pok\'eAI是一个基于文本的多代理大型语言模型框架，用于自主玩Pok\'emon Red游戏。它由规划、执行和评估三个代理组成，形成一个闭环决策系统。初步结果显示，战斗模块的胜率为80.8%，接近人类玩家水平。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够自主玩Pok\'emon Red的多代理LLM框架，探索语言模型在游戏策略中的表现。

Method: 系统由三个代理组成：规划代理生成任务，执行代理完成任务，评估代理验证结果。初步开发了战斗模块。

Result: 战斗模块在50次野生对战中平均胜率为80.8%，接近人类玩家水平。语言能力与战略推理能力相关，不同LLM表现出独特的游戏风格。

Conclusion: Pok\'eAI展示了LLM在游戏策略中的潜力，语言能力与战略推理之间存在关联，且不同模型表现出独特的游戏风格。

Abstract: We introduce Pok\'eAI, the first text-based, multi-agent large language model
(LLM) framework designed to autonomously play and progress through Pok\'emon
Red. Our system consists of three specialized agents-Planning, Execution, and
Critique-each with its own memory bank, role, and skill set. The Planning Agent
functions as the central brain, generating tasks to progress through the game.
These tasks are then delegated to the Execution Agent, which carries them out
within the game environment. Upon task completion, the Critique Agent evaluates
the outcome to determine whether the objective was successfully achieved. Once
verification is complete, control returns to the Planning Agent, forming a
closed-loop decision-making system.
  As a preliminary step, we developed a battle module within the Execution
Agent. Our results show that the battle AI achieves an average win rate of
80.8% across 50 wild encounters, only 6% lower than the performance of an
experienced human player. Furthermore, we find that a model's battle
performance correlates strongly with its LLM Arena score on language-related
tasks, indicating a meaningful link between linguistic ability and strategic
reasoning. Finally, our analysis of gameplay logs reveals that each LLM
exhibits a unique playstyle, suggesting that individual models develop distinct
strategic behaviors.

</details>


### [32] [Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models](https://arxiv.org/abs/2506.23692)
*Boyuan Zheng,Zerui Fang,Zhe Xu,Rui Wang,Yiwen Chen,Cunshi Wang,Mengwei Qu,Lei Lei,Zhen Feng,Yan Liu,Yuyang Li,Mingzhou Tan,Jiaji Wu,Jianwei Shuai,Jia Li,Fangfu Ye*

Main category: cs.AI

TL;DR: 论文提出用LLM驱动的Agent4S（科学代理）作为第五科学范式，以自动化整个科研工作流，并提出了五级分类框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI4S（科学AI）作为分析工具未能解决科研核心效率问题，因此需要更自动化的解决方案。

Method: 提出Agent4S框架，通过五级分类从简单任务自动化到完全自主协作的“AI科学家”。

Result: 定义了科学发现的革命性下一步，为科研自动化提供了清晰路线图。

Conclusion: Agent4S是真正的第五科学范式，将彻底改变科研工作流。

Abstract: While AI for Science (AI4S) serves as an analytical tool in the current
research paradigm, it doesn't solve its core inefficiency. We propose "Agent
for Science" (Agent4S)-the use of LLM-driven agents to automate the entire
research workflow-as the true Fifth Scientific Paradigm. This paper introduces
a five-level classification for Agent4S, outlining a clear roadmap from simple
task automation to fully autonomous, collaborative "AI Scientists." This
framework defines the next revolutionary step in scientific discovery.

</details>


### [33] [A New Perspective On AI Safety Through Control Theory Methodologies](https://arxiv.org/abs/2506.23703)
*Lars Ullrich,Walter Zimmer,Ross Greer,Knut Graichen,Alois C. Knoll,Mohan Trivedi*

Main category: cs.AI

TL;DR: 本文提出了一种基于系统理论和数据分析的新视角，旨在通过跨学科方法提升AI安全性，称为“数据控制”。


<details>
  <summary>Details</summary>
Motivation: AI在安全关键领域的快速发展缺乏足够的安全性保障，需要结合控制理论和数据驱动方法来提升AI安全性。

Method: 采用系统理论和系统分析驱动的方法，提出数据控制的概念，结合现有安全分析和保障技术。

Result: 提出了一种通用的安全分析和保障框架，适用于特定AI系统和应用，并为未来创新奠定基础。

Conclusion: 跨学科的数据控制方法为AI安全性提供了新视角，有望推动AI工程的发展。

Abstract: While artificial intelligence (AI) is advancing rapidly and mastering
increasingly complex problems with astonishing performance, the safety
assurance of such systems is a major concern. Particularly in the context of
safety-critical, real-world cyber-physical systems, AI promises to achieve a
new level of autonomy but is hampered by a lack of safety assurance. While
data-driven control takes up recent developments in AI to improve control
systems, control theory in general could be leveraged to improve AI safety.
Therefore, this article outlines a new perspective on AI safety based on an
interdisciplinary interpretation of the underlying data-generation process and
the respective abstraction by AI systems in a system theory-inspired and system
analysis-driven manner. In this context, the new perspective, also referred to
as data control, aims to stimulate AI engineering to take advantage of existing
safety analysis and assurance in an interdisciplinary way to drive the paradigm
of data control. Following a top-down approach, a generic foundation for safety
analysis and assurance is outlined at an abstract level that can be refined for
specific AI systems and applications and is prepared for future innovation.

</details>


### [34] [Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments](https://arxiv.org/abs/2506.23706)
*Christoph Schnabl,Daniel Hugenroth,Bill Marino,Alastair R. Beresford*

Main category: cs.AI

TL;DR: 提出了一种名为“可验证审计”的方法，利用可信执行环境（TEE）确保AI模型的安全性和合规性，同时保护模型和数据隐私。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法提供可验证的结果，且缺乏对模型IP和基准数据集的保密性，无法满足AI治理框架的需求。

Method: 在可信执行环境中运行可验证审计，确保用户能够验证与合规AI模型的交互，同时保护敏感数据。

Result: 构建了一个原型，展示了在典型审计基准（如Llama-3.1）上的可行性。

Conclusion: 可验证审计解决了AI治理框架中的验证挑战，为模型安全和数据隐私提供了可行方案。

Abstract: Benchmarks are important measures to evaluate safety and compliance of AI
models at scale. However, they typically do not offer verifiable results and
lack confidentiality for model IP and benchmark datasets. We propose Attestable
Audits, which run inside Trusted Execution Environments and enable users to
verify interaction with a compliant AI model. Our work protects sensitive data
even when model provider and auditor do not trust each other. This addresses
verification challenges raised in recent AI governance frameworks. We build a
prototype demonstrating feasibility on typical audit benchmarks against
Llama-3.1.

</details>


### [35] [BayesL: Towards a Logical Framework for Bayesian Networks](https://arxiv.org/abs/2506.23773)
*Stefano M. Nicoletti,Mariëlle Stoelinga*

Main category: cs.AI

TL;DR: BayesL是一个新的逻辑框架，用于指定、查询和验证贝叶斯网络的行为。


<details>
  <summary>Details</summary>
Motivation: 提供一个结构化语言，支持对贝叶斯网络的查询和推理，简化因果和证据关系的分析。

Method: 开发BayesL语言，支持创建查询和进行假设场景评估，无需手动修改模型。

Result: BayesL能够灵活推理因果和证据关系，支持全面的假设分析。

Conclusion: BayesL为贝叶斯网络的行为分析提供了高效且灵活的工具。

Abstract: We introduce BayesL, a novel logical framework for specifying, querying, and
verifying the behaviour of Bayesian networks (BNs). BayesL (pronounced "Basil")
is a structured language that allows for the creation of queries over BNs. It
facilitates versatile reasoning concerning causal and evidence-based
relationships, and permits comprehensive what-if scenario evaluations without
the need for manual modifications to the model.

</details>


### [36] [When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)](https://arxiv.org/abs/2506.23784)
*Parosh Aziz Abdulla,Mohamed Faouzi Atig,Julie Cailler,Chencheng Liang,Philipp Rümmer*

Main category: cs.AI

TL;DR: 使用图神经网络（GNN）对词方程进行排序，提升求解效率。


<details>
  <summary>Details</summary>
Motivation: 传统Nielsen变换求解词方程时，处理顺序对性能影响大，需优化排序方法。

Method: 提出基于图的词方程表示，结合GNN进行排序，并处理变量数量问题。

Result: 实验表明，新框架在特定基准测试中优于现有字符串求解器。

Conclusion: GNN排序方法有效提升词方程求解性能。

Abstract: Nielsen transformation is a standard approach for solving word equations: by
repeatedly splitting equations and applying simplification steps, equations are
rewritten until a solution is reached. When solving a conjunction of word
equations in this way, the performance of the solver will depend considerably
on the order in which equations are processed. In this work, the use of Graph
Neural Networks (GNNs) for ranking word equations before and during the solving
process is explored. For this, a novel graph-based representation for word
equations is presented, preserving global information across conjuncts,
enabling the GNN to have a holistic view during ranking. To handle the variable
number of conjuncts, three approaches to adapt a multi-classification task to
the problem of ranking equations are proposed. The training of the GNN is done
with the help of minimum unsatisfiable subsets (MUSes) of word equations. The
experimental results show that, compared to state-of-the-art string solvers,
the new framework solves more problems in benchmarks where each variable
appears at most once in each equation.

</details>


### [37] [Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning](https://arxiv.org/abs/2506.23793)
*Anton Andreychuk,Konstantin Yakovlev,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: MAPF-GPT-DDG是一种基于机器学习的多智能体路径规划（MAPF）求解器，通过微调预训练模型和新型数据生成机制，显著提升了性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人轨迹规划问题，尤其是在物流和搜救等实际应用中，需要高效且可扩展的MAPF求解器。

Method: 利用集中式专家数据微调预训练的MAPF-GPT模型，并引入delta-data生成机制加速训练。

Result: MAPF-GPT-DDG在测试中表现优于现有学习型求解器，支持单环境中多达100万个智能体的规划。

Conclusion: MAPF-GPT-DDG在性能和可扩展性上取得了突破，为MAPF领域设定了新的里程碑。

Abstract: Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot
trajectory planning problems, where multiple homogeneous robots simultaneously
move in the shared environment. While solving MAPF optimally has been proven to
be NP-hard, scalable, and efficient, solvers are vital for real-world
applications like logistics, search-and-rescue, etc. To this end, decentralized
suboptimal MAPF solvers that leverage machine learning have come on stage.
Building on the success of the recently introduced MAPF-GPT, a pure imitation
learning solver, we introduce MAPF-GPT-DDG. This novel approach effectively
fine-tunes the pre-trained MAPF model using centralized expert data. Leveraging
a novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training
while significantly improving performance at test time. Our experiments
demonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF
solvers, including the original MAPF-GPT, regarding solution quality across
many testing scenarios. Remarkably, it can work with MAPF instances involving
up to 1 million agents in a single environment, setting a new milestone for
scalability in MAPF domains.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [38] [Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring](https://arxiv.org/abs/2506.22437)
*Xinxin Sun,Peter Chang*

Main category: cs.CV

TL;DR: 提出了一种基于物理信息的图像对齐框架，用于结构健康监测中的裂缝演化跟踪，解决了传统方法在高频边缘抑制和重复性差的问题。


<details>
  <summary>Details</summary>
Motivation: 传统特征检测方法（如SIFT、SURF）在高频边缘抑制和复杂环境下表现不佳，轻量级方法（如ORB、BRISK）在纹理或阴影表面重复性差。

Method: 利用非线性各向异性扩散构建保留裂缝的尺度空间，结合RANSAC单应性估计，无需训练或参数调整。

Result: 在多种现场条件下，裂缝面积和长度误差分别减少70%和90%，对齐误差低于5%。

Conclusion: 该方法为裂缝演化跟踪提供了一种鲁棒、轻量且无需校准的解决方案，适用于移动平台和无人机部署。

Abstract: Accurate image alignment is essential for monitoring crack evolution in
structural health monitoring (SHM), particularly under real-world conditions
involving perspective distortion, occlusion, and low contrast. However,
traditional feature detectors such as SIFT and SURF, which rely on
Gaussian-based scale spaces, tend to suppress high-frequency edges, making them
unsuitable for thin crack localization. Lightweight binary alternatives like
ORB and BRISK, while computationally efficient, often suffer from poor keypoint
repeatability on textured or shadowed surfaces. This study presents a
physics-informed alignment framework that adapts the open KAZE architecture to
SHM-specific challenges. By utilizing nonlinear anisotropic diffusion to
construct a crack-preserving scale space, and integrating RANSAC-based
homography estimation, the framework enables accurate geometric correction
without the need for training, parameter tuning, or prior calibration. The
method is validated on time-lapse images of masonry and concrete acquired via
handheld smartphone under varied field conditions, including shadow
interference, cropping, oblique viewing angles, and surface clutter. Compared
to classical detectors, the proposed framework reduces crack area and spine
length errors by up to 70 percent and 90 percent, respectively, while
maintaining sub-5 percent alignment error in key metrics. Unsupervised,
interpretable, and computationally lightweight, this approach supports scalable
deployment via UAVs and mobile platforms. By tailoring nonlinear scale-space
modeling to SHM image alignment, this work offers a robust and physically
grounded alternative to conventional techniques for tracking real-world crack
evolution.

</details>


### [39] [Counting with Confidence: Accurate Pest Monitoring in Water Traps](https://arxiv.org/abs/2506.22438)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.CV

TL;DR: 该论文提出了一种基于计数结果和外部环境条件信息的方法，用于全面评估图像中害虫计数的置信度，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的害虫计数研究在真实场景中缺乏对计数结果可靠性的评估，因此需要一种方法来全面评估计数置信度。

Method: 结合害虫检测网络、图像质量评估、图像复杂性评估和害虫分布均匀性评估，设计回归模型预测计数置信度。

Result: 实验表明，该方法在害虫计数置信度测试集上比基线方法降低了31.7%的MSE，提高了15.2%的R2。

Conclusion: 该研究首次全面评估了计数任务的置信度，并通过模型量化了影响因素与计数置信度之间的关系。

Abstract: Accurate pest population monitoring and tracking their dynamic changes are
crucial for precision agriculture decision-making. A common limitation in
existing vision-based automatic pest counting research is that models are
typically evaluated on datasets with ground truth but deployed in real-world
scenarios without assessing the reliability of counting results due to the lack
of ground truth. To this end, this paper proposed a method for comprehensively
evaluating pest counting confidence in the image, based on information related
to counting results and external environmental conditions. First, a pest
detection network is used for pest detection and counting, extracting counting
result-related information. Then, the pest images undergo image quality
assessment, image complexity assessment, and pest distribution uniformity
assessment. And the changes in image clarity caused by stirring during image
acquisition are quantified by calculating the average gradient magnitude.
Notably, we designed a hypothesis-driven multi-factor sensitivity analysis
method to select the optimal image quality assessment and image complexity
assessment methods. And we proposed an adaptive DBSCAN clustering algorithm for
pest distribution uniformity assessment. Finally, the obtained information
related to counting results and external environmental conditions is input into
a regression model for prediction, resulting in the final pest counting
confidence. To the best of our knowledge, this is the first study dedicated to
comprehensively evaluating counting confidence in counting tasks, and
quantifying the relationship between influencing factors and counting
confidence through a model. Experimental results show our method reduces MSE by
31.7% and improves R2 by 15.2% on the pest counting confidence test set,
compared to the baseline built primarily on information related to counting
results.

</details>


### [40] [Modulated Diffusion: Accelerating Generative Modeling with Modulated Quantization](https://arxiv.org/abs/2506.22463)
*Weizhi Gao,Zhichao Hou,Junqi Yin,Feiyi Wang,Linyu Peng,Xiaorui Liu*

Main category: cs.CV

TL;DR: MoDiff是一种创新的扩散模型加速框架，通过调制量化和误差补偿提升生成效率，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的高计算成本是主要瓶颈，现有加速技术（如缓存和量化）在计算误差和生成质量上存在局限。

Method: 提出Modulated Diffusion（MoDiff）框架，结合调制量化和误差补偿，适用于所有扩散模型。

Result: MoDiff将激活量化从8位降至3位，且在CIFAR-10和LSUN上无性能损失。

Conclusion: MoDiff是一种高效且通用的扩散模型加速方法，理论分析和实验验证了其优势。

Abstract: Diffusion models have emerged as powerful generative models, but their high
computation cost in iterative sampling remains a significant bottleneck. In
this work, we present an in-depth and insightful study of state-of-the-art
acceleration techniques for diffusion models, including caching and
quantization, revealing their limitations in computation error and generation
quality. To break these limits, this work introduces Modulated Diffusion
(MoDiff), an innovative, rigorous, and principled framework that accelerates
generative modeling through modulated quantization and error compensation.
MoDiff not only inherents the advantages of existing caching and quantization
methods but also serves as a general framework to accelerate all diffusion
models. The advantages of MoDiff are supported by solid theoretical insight and
analysis. In addition, extensive experiments on CIFAR-10 and LSUN demonstrate
that MoDiff significant reduces activation quantization from 8 bits to 3 bits
without performance degradation in post-training quantization (PTQ). Our code
implementation is available at https://github.com/WeizhiGao/MoDiff.

</details>


### [41] [ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction](https://arxiv.org/abs/2506.22498)
*Hao Liu,Yu Hu,Rakiba Rayhana,Ling Bai,Zheng Liu*

Main category: cs.CV

TL;DR: 通过低成本负载传感器和图像融合技术，ViFusionTST模型能有效预测患者离床意图，提升跌倒预防效果。


<details>
  <summary>Details</summary>
Motivation: 医院和长期护理机构中，床旁跌倒是一个主要伤害来源，现有警报系统反应滞后。

Method: 使用四个低成本负载传感器，将信号转换为互补图像（RGB线图和纹理图），并通过双流Swin Transformer（ViFusionTST）进行并行处理和跨模态融合。

Result: 在真实数据集上，ViFusionTST达到0.885的准确率和0.794的F1分数，优于现有基线。

Conclusion: 基于图像融合的负载信号分类方法是一种实用且有效的实时跌倒预防解决方案。

Abstract: Bed-related falls remain a leading source of injury in hospitals and
long-term-care facilities, yet many commercial alarms trigger only after a
patient has already left the bed. We show that early bed-exit intent can be
predicted using only four low-cost load cells mounted under the bed legs. The
resulting load signals are first converted into a compact set of complementary
images: an RGB line plot that preserves raw waveforms and three texture maps -
recurrence plot, Markov transition field, and Gramian angular field - that
expose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin
Transformer that processes the line plot and texture maps in parallel and fuses
them through cross-attention to learn data-driven modality weights.
  To provide a realistic benchmark, we collected six months of continuous data
from 95 beds in a long-term-care facility. On this real-world dataset
ViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing
recent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC.
The results demonstrate that image-based fusion of load-sensor signals for time
series classification is a practical and effective solution for real-time,
privacy-preserving fall prevention.

</details>


### [42] [Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data](https://arxiv.org/abs/2506.22499)
*Jiachao Liu,Pablo Guarda,Koichiro Niinuma,Sean Qian*

Main category: cs.CV

TL;DR: 提出了一种结合卫星图像和传统交通数据的多类别动态起点-终点需求估计框架，显著提升了无本地传感器路段的估计性能。


<details>
  <summary>Details</summary>
Motivation: 传统本地传感器数据稀疏，卫星图像能提供更全面的城市交通信息，克服数据可用性限制。

Method: 设计计算机视觉流程提取车辆类别信息，构建计算图模型联合校准交通计数和旅行时间。

Result: 实验表明，卫星数据显著提升估计性能，尤其适用于无本地传感器的路段，且框架可扩展至大规模网络。

Conclusion: 该框架具有实际部署潜力，适用于不同规模城市，数据质量对卫星图像影响需进一步分析。

Abstract: This study presents a novel integrated framework for dynamic
origin-destination demand estimation (DODE) in multi-class mesoscopic network
models, leveraging high-resolution satellite imagery together with conventional
traffic data from local sensors. Unlike sparse local detectors, satellite
imagery offers consistent, city-wide road and traffic information of both
parking and moving vehicles, overcoming data availability limitations. To
extract information from imagery data, we design a computer vision pipeline for
class-specific vehicle detection and map matching, generating link-level
traffic density observations by vehicle class. Building upon this information,
we formulate a computational graph-based DODE model that calibrates dynamic
network states by jointly matching observed traffic counts and travel times
from local sensors with density measurements derived from satellite imagery. To
assess the accuracy and scalability of the proposed framework, we conduct a
series of numerical experiments using both synthetic and real-world data. The
results of out-of-sample tests demonstrate that supplementing traditional data
with satellite-derived density significantly improves estimation performance,
especially for links without local sensors. Real-world experiments also confirm
the framework's capability to handle large-scale networks, supporting its
potential for practical deployment in cities of varying sizes. Sensitivity
analysis further evaluates the impact of data quality related to satellite
imagery data.

</details>


### [43] [Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models](https://arxiv.org/abs/2506.22500)
*Weiyi Zhao,Xiaoyu Tan,Liang Liu,Sijia Li,Youwei Song,Xihe Qiu*

Main category: cs.CV

TL;DR: 论文提出了一种解决多模态大语言模型（MLLMs）在手术室风险检测中视觉-语义知识冲突（VS-KC）的方法，通过生成合成图像数据集OR-VSKC，并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 手术风险识别对患者安全至关重要，但现有MLLMs存在视觉-语义知识冲突，无法有效检测视觉安全违规。

Method: 生成包含34,000张合成图像的数据集OR-VSKC，涵盖手术室场景中的安全违规实体，并辅以214张人工标注图像作为验证基准。通过微调MLLMs研究VS-KC。

Result: 微调后的MLLMs在训练过的冲突实体检测上表现显著提升，但对未训练实体类型效果不佳。

Conclusion: OR-VSKC数据集和基准测试为研究VS-KC提供了资源，但需更全面的训练以提升模型泛化能力。

Abstract: Surgical risk identification is critical for patient safety and reducing
preventable medical errors. While multimodal large language models (MLLMs) show
promise for automated operating room (OR) risk detection, they often exhibit
visual-semantic knowledge conflicts (VS-KC), failing to identify visual safety
violations despite understanding textual rules. To address this, we introduce a
dataset comprising over 34,000 synthetic images generated by diffusion models,
depicting operating room scenes containing entities that violate established
safety rules. These images were created to alleviate data scarcity and examine
MLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated
images that serve as a gold-standard reference for validation. This
comprehensive dataset, spanning diverse perspectives, stages, and
configurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC
significantly improves MLLMs' detection of trained conflict entities and
generalizes well to new viewpoints for these entities, but performance on
untrained entity types remains poor, highlighting learning specificity and the
need for comprehensive training. The main contributions of this work include:
(1) a data generation methodology tailored for rule-violation scenarios; (2)
the release of the OR-VSKC dataset and its associated benchmark as open-source
resources; and (3) an empirical analysis of violation-sensitive knowledge
consistency in representative MLLMs. The dataset and appendix are available at
https://github.com/zgg2577/VS-KC.

</details>


### [44] [How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?](https://arxiv.org/abs/2506.22501)
*Gautam Siddharth Kashyap,Manaswi Kulahara,Nipun Joshi,Usman Naseem*

Main category: cs.CV

TL;DR: 提出了一种名为SpatialNet-ViT的新模型，结合Vision Transformers和多任务学习，以提升遥感分类任务的泛化能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多局限于特定任务或数据集，难以泛化到多样化的遥感分类挑战。

Method: 采用Vision Transformers和多任务学习，结合数据增强、迁移学习等技术。

Result: 模型在分类准确性和可扩展性上均有提升。

Conclusion: SpatialNet-ViT通过结合空间感知与上下文理解，为遥感分类任务提供了更优的解决方案。

Abstract: Remote sensing datasets offer significant promise for tackling key
classification tasks such as land-use categorization, object presence
detection, and rural/urban classification. However, many existing studies tend
to focus on narrow tasks or datasets, which limits their ability to generalize
across various remote sensing classification challenges. To overcome this, we
propose a novel model, SpatialNet-ViT, leveraging the power of Vision
Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach
combines spatial awareness with contextual understanding, improving both
classification accuracy and scalability. Additionally, techniques like data
augmentation, transfer learning, and multi-task learning are employed to
enhance model robustness and its ability to generalize across diverse datasets

</details>


### [45] [What Makes a Dribble Successful? Insights From 3D Pose Tracking Data](https://arxiv.org/abs/2506.22503)
*Michiel Schepers,Pieter Robberechts,Jan Van Haaren,Jesse Davis*

Main category: cs.CV

TL;DR: 利用三维姿态追踪数据改进足球盘带技能评估，相比传统二维数据，新特征显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统二维数据无法全面捕捉盘带中的平衡、方向和控球等关键因素，限制了分析深度。

Method: 从2022/23赛季欧冠的1736次盘带中提取姿态特征，结合传统二维数据评估其对盘带成功的影响。

Result: 攻击者的平衡及与防守者方向对齐的姿态特征对预测盘带成功有显著影响，模型性能提升。

Conclusion: 三维姿态数据为足球盘带分析提供了更丰富的视角，显著优于传统二维方法。

Abstract: Data analysis plays an increasingly important role in soccer, offering new
ways to evaluate individual and team performance. One specific application is
the evaluation of dribbles: one-on-one situations where an attacker attempts to
bypass a defender with the ball. While previous research has primarily relied
on 2D positional tracking data, this fails to capture aspects like balance,
orientation, and ball control, limiting the depth of current insights. This
study explores how pose tracking data (capturing players' posture and movement
in three dimensions) can improve our understanding of dribbling skills. We
extract novel pose-based features from 1,736 dribbles in the 2022/23 Champions
League season and evaluate their impact on dribble success. Our results
indicate that features capturing the attacker's balance and the alignment of
the orientation between the attacker and defender are informative for
predicting dribble success. Incorporating these pose-based features on top of
features derived from traditional 2D positional data leads to a measurable
improvement in model performance.

</details>


### [46] [Patch2Loc: Learning to Localize Patches for Unsupervised Brain Lesion Detection](https://arxiv.org/abs/2506.22504)
*Hassan Baker,Austin J. Brockmeier*

Main category: cs.CV

TL;DR: 提出了一种无监督学习方法Patch2Loc，通过训练神经网络从正常MRI图像中学习，检测异常脑组织，优于现有无监督分割方法。


<details>
  <summary>Details</summary>
Motivation: 脑部病变检测对诊断和治疗至关重要，现有方法需要标注数据，而Patch2Loc无需标注即可检测异常。

Method: 训练神经网络将MRI图像中的正常组织映射到其空间位置，通过预测误差和方差检测异常组织。

Result: 在多个数据集上验证了Patch2Loc的有效性，优于现有无监督分割方法。

Conclusion: Patch2Loc是一种高效的无监督脑部异常检测方法，具有临床应用潜力。

Abstract: Detecting brain lesions as abnormalities observed in magnetic resonance
imaging (MRI) is essential for diagnosis and treatment. In the search of
abnormalities, such as tumors and malformations, radiologists may benefit from
computer-aided diagnostics that use computer vision systems trained with
machine learning to segment normal tissue from abnormal brain tissue. While
supervised learning methods require annotated lesions, we propose a new
unsupervised approach (Patch2Loc) that learns from normal patches taken from
structural MRI. We train a neural network model to map a patch back to its
spatial location within a slice of the brain volume. During inference, abnormal
patches are detected by the relatively higher error and/or variance of the
location prediction. This generates a heatmap that can be integrated into
pixel-wise methods to achieve finer-grained segmentation. We demonstrate the
ability of our model to segment abnormal brain tissues by applying our approach
to the detection of tumor tissues in MRI on T2-weighted images from BraTS2021
and MSLUB datasets and T1-weighted images from ATLAS and WMH datasets. We show
that it outperforms the state-of-the art in unsupervised segmentation. The
codebase for this work can be found on our
\href{https://github.com/bakerhassan/Patch2Loc}{GitHub page}.

</details>


### [47] [Weakly Supervised Object Segmentation by Background Conditional Divergence](https://arxiv.org/abs/2506.22505)
*Hassan Baker,Matthew S. Emigh,Austin J. Brockmeier*

Main category: cs.CV

TL;DR: 提出了一种利用弱监督（图像级标签）训练二值对象分割网络的方法，通过生成反事实背景图像提升分割效果。


<details>
  <summary>Details</summary>
Motivation: 在缺乏大量标注数据的专业图像领域（如声纳、遥感、生物医学图像），像素级分割成本高，而图像级标签更易获取。

Method: 利用图像级标签训练分割网络，通过聚类背景图像并生成反事实图像，结合对比损失和监督损失优化模型。

Result: 在声纳图像和自然图像上均优于无监督分割基线，且无需预训练网络或对抗性判别器。

Conclusion: 该方法在弱监督下实现了有效的对象分割，适用于多种图像领域，且计算成本较低。

Abstract: As a computer vision task, automatic object segmentation remains challenging
in specialized image domains without massive labeled data, such as synthetic
aperture sonar images, remote sensing, biomedical imaging, etc. In any domain,
obtaining pixel-wise segmentation masks is expensive. In this work, we propose
a method for training a masking network to perform binary object segmentation
using weak supervision in the form of image-wise presence or absence of an
object of interest, which provides less information but may be obtained more
quickly from manual or automatic labeling. A key step in our method is that the
segmented objects can be placed into background-only images to create
realistic, images of the objects with counterfactual backgrounds. To create a
contrast between the original and counterfactual background images, we propose
to first cluster the background-only images, and then during learning create
counterfactual images that blend objects segmented from their original source
backgrounds to backgrounds chosen from a targeted cluster. One term in the
training loss is the divergence between these counterfactual images and the
real object images with backgrounds of the target cluster. The other term is a
supervised loss for background-only images. While an adversarial critic could
provide the divergence, we use sample-based divergences. We conduct experiments
on side-scan and synthetic aperture sonar in which our approach succeeds
compared to previous unsupervised segmentation baselines that were only tested
on natural images. Furthermore, to show generality we extend our experiments to
natural images, obtaining reasonable performance with our method that avoids
pretrained networks, generative networks, and adversarial critics. The basecode
for this work can be found at
\href{GitHub}{https://github.com/bakerhassan/WSOS}.

</details>


### [48] [FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment](https://arxiv.org/abs/2506.22509)
*Hang Xu,Jie Huang,Linjiang Huang,Dong Li,Yidi Liu,Feng Zhao*

Main category: cs.CV

TL;DR: 提出了一种无需训练的域适应方法（DNA），通过调整扩散过程中的噪声统计量，提升密集预测模型在未见域上的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在建模包含域信息的分布转换中表现优异，但噪声统计偏差会导致域偏移，因此探索如何利用噪声统计量实现域适应。

Method: 提出Domain Noise Alignment（DNA）方法，通过对齐源域和目标域的噪声统计量实现域适应；在无源域情况下，利用高置信区域的统计量逐步调整噪声。

Result: 在四种常见的密集预测任务中验证了DNA方法的有效性，提升了模型的域适应能力。

Conclusion: DNA是一种无需训练的域适应方法，通过噪声统计对齐显著提升了扩散密集预测模型的跨域性能。

Abstract: Domain Adaptation(DA) for dense prediction tasks is an important topic, which
enhances the dense prediction model's performance when tested on its unseen
domain. Recently, with the development of Diffusion-based Dense Prediction
(DDP) models, the exploration of DA designs tailored to this framework is worth
exploring, since the diffusion model is effective in modeling the distribution
transformation that comprises domain information. In this work, we propose a
training-free mechanism for DDP frameworks, endowing them with DA capabilities.
Our motivation arises from the observation that the exposure bias (e.g., noise
statistics bias) in diffusion brings domain shift, and different domains in
conditions of DDP models can also be effectively captured by the noise
prediction statistics. Based on this, we propose a training-free Domain Noise
Alignment (DNA) approach, which alleviates the variations of noise statistics
to domain changes during the diffusion sampling process, thereby achieving
domain adaptation. Specifically, when the source domain is available, we
directly adopt the DNA method to achieve domain adaptation by aligning the
noise statistics of the target domain with those of the source domain. For the
more challenging source-free DA, inspired by the observation that regions
closer to the source domain exhibit higher confidence meeting variations of
sampling noise, we utilize the statistics from the high-confidence regions
progressively to guide the noise statistic adjustment during the sampling
process. Notably, our method demonstrates the effectiveness of enhancing the DA
capability of DDP models across four common dense prediction tasks. Code is
available at
\href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}.

</details>


### [49] [Lightning the Night with Generative Artificial Intelligence](https://arxiv.org/abs/2506.22511)
*Tingting Zhou,Feng Zhang,Haoyang Fu,Baoxiang Pan,Renhe Zhang,Feng Lu,Zhixin Yang*

Main category: cs.CV

TL;DR: 该研究利用生成扩散模型，基于FY4B卫星的多波段热红外数据，开发了RefDiff模型，实现了夜间可见光反射率的高精度反演，显著提升了复杂云结构区域的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决夜间因缺乏可见光而无法进行全天候气象观测的问题。

Method: 基于FY4B卫星的AGRI多波段热红外数据，开发生成扩散模型RefDiff，实现夜间可见光反射率反演。

Result: RefDiff的SSIM指数达0.90，在复杂云结构区域表现优异，夜间反演能力与白天相当。

Conclusion: 该研究显著提升了夜间可见光反射率反演能力，拓展了夜间可见光数据的应用潜力。

Abstract: The visible light reflectance data from geostationary satellites is crucial
for meteorological observations and plays an important role in weather
monitoring and forecasting. However, due to the lack of visible light at night,
it is impossible to conduct continuous all-day weather observations using
visible light reflectance data. This study pioneers the use of generative
diffusion models to address this limitation. Based on the multi-band thermal
infrared brightness temperature data from the Advanced Geostationary Radiation
Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we
developed a high-precision visible light reflectance retrieval model, called
Reflectance Diffusion (RefDiff), which enables 0.47~\mu\mathrm{m},
0.65~\mu\mathrm{m}, and 0.825~\mu\mathrm{m} bands visible light reflectance
retrieval at night. Compared to the classical models, RefDiff not only
significantly improves accuracy through ensemble averaging but also provides
uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90,
with particularly significant improvements in areas with complex cloud
structures and thick clouds. The model's nighttime retrieval capability was
validated using VIIRS nighttime product, demonstrating comparable performance
to its daytime counterpart. In summary, this research has made substantial
progress in the ability to retrieve visible light reflectance at night, with
the potential to expand the application of nighttime visible light data.

</details>


### [50] [Automated Defect Identification and Categorization in NDE 4.0 with the Application of Artificial Intelligence](https://arxiv.org/abs/2506.22513)
*Aditya Sharma*

Main category: cs.CV

TL;DR: 该研究提出了一种用于现代射线检测的自动化框架，通过虚拟缺陷增强和NDE测量验证其可行性。


<details>
  <summary>Details</summary>
Motivation: 解决现有信息不足的问题，优化虚拟缺陷增强技术，并验证框架的实用性。

Method: 收集并分类223张飞机焊缝的CR照片，使用数据增强技术（如虚拟缺陷增强）改进数据集，训练改进的U-net模型进行语义缺陷分割。

Result: 模型在缺陷检测中表现出高灵敏度，尤其在a90/95特征下表现优异，且处理速度快。

Conclusion: 该框架在专业评估中显示出作为检测支持工具的潜力，不受特定设备限制影响。

Abstract: This investigation attempts to create an automated framework for fault
detection and organization for usage in contemporary radiography, as per NDE
4.0. The review's goals are to address the lack of information that is
sufficiently explained, learn how to make the most of virtual defect increase,
and determine whether the framework is viable by using NDE measurements. As its
basic information source, the technique consists of compiling and categorizing
223 CR photographs of airplane welds. Information expansion systems, such as
virtual defect increase and standard increase, are used to work on the
preparation dataset. A modified U-net model is prepared using the improved data
to produce semantic fault division veils. To assess the effectiveness of the
model, NDE boundaries such as Case, estimating exactness, and misleading call
rate are used. Tiny a90/95 characteristics, which provide strong
differentiating evidence of flaws, reveal that the suggested approach achieves
exceptional awareness in defect detection. Considering a 90/95, size error, and
fake call rate in the weld area, the consolidated expansion approach clearly
wins. Due to the framework's fast derivation speed, large images can be broken
down efficiently and quickly. Professional controllers evaluate the transmitted
system in the field and believe that it has a guarantee as a support device in
the testing cycle, irrespective of particular equipment cut-off points and
programming resemblance.

</details>


### [51] [Container damage detection using advanced computer vision model Yolov12 vs Yolov11 vs RF-DETR A comparative analysis](https://arxiv.org/abs/2506.22517)
*Subhadip Kumar*

Main category: cs.CV

TL;DR: 比较了Yolov12、Yolov11和RF-DETR三种计算机视觉模型在集装箱损伤检测中的性能，发现RF-DETR在不常见损伤检测中表现更优。


<details>
  <summary>Details</summary>
Motivation: 集装箱损伤是物流行业的安全隐患，需及时检测以延长使用寿命和避免风险。

Method: 使用278张标注图像数据集训练和测试三种模型，比较mAP和精度。

Result: Yolov11和12的mAP@50为81.9%，RF-DETR为77.7%，但RF-DETR在不常见损伤检测中表现更优。

Conclusion: RF-DETR在不常见损伤检测中更具优势，适合实际应用。

Abstract: Containers are an integral part of the logistics industry and act as a
barrier for cargo. A typical service life for a container is more than 20
years. However, overtime containers suffer various types of damage due to the
mechanical as well as natural factors. A damaged container is a safety hazard
for the employees handling it and a liability for the logistic company.
Therefore, a timely inspection and detection of the damaged container is a key
for prolonging service life as well as avoiding safety hazards. In this paper,
we will compare the performance of the damage detection by three
state-of-the-art advanced computer vision models Yolov12, Yolov11 and RF-DETR.
We will use a dataset of 278 annotated images to train, validate and test the
model. We will compare the mAP and precision of the model. The objective of
this paper is to identify the model that is best suited for container damage
detection. The result is mixed. mAP@50 score of Yolov11 and 12 was 81.9%
compared to RF-DETR, which was 77.7%. However, while testing the model for
not-so-common damaged containers, the RF-DETR model outperformed the others
overall, exhibiting superiority to accurately detecting both damaged containers
as well as damage occurrences with high confidence.

</details>


### [52] [Preserve Anything: Controllable Image Synthesis with Object Preservation](https://arxiv.org/abs/2506.22531)
*Prasen Kumar Sharma,Neeraj Matiyali,Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 提出了一种名为“Preserve Anything”的新方法，用于解决文本到图像生成中的对象保存和语义一致性限制。


<details>
  <summary>Details</summary>
Motivation: 现有方法在保存多个对象、语义对齐和场景控制方面存在不足。

Method: 采用N通道ControlNet，结合对象保存、背景引导和高频覆盖模块。

Result: 在FID和CLIP-S指标上表现优异，用户研究显示显著改进。

Conclusion: 该方法在对象保存、语义一致性和用户控制方面优于现有技术。

Abstract: We introduce \textit{Preserve Anything}, a novel method for controlled image
synthesis that addresses key limitations in object preservation and semantic
consistency in text-to-image (T2I) generation. Existing approaches often fail
(i) to preserve multiple objects with fidelity, (ii) maintain semantic
alignment with prompts, or (iii) provide explicit control over scene
composition. To overcome these challenges, the proposed method employs an
N-channel ControlNet that integrates (i) object preservation with size and
placement agnosticism, color and detail retention, and artifact elimination,
(ii) high-resolution, semantically consistent backgrounds with accurate
shadows, lighting, and prompt adherence, and (iii) explicit user control over
background layouts and lighting conditions. Key components of our framework
include object preservation and background guidance modules, enforcing lighting
consistency and a high-frequency overlay module to retain fine details while
mitigating unwanted artifacts. We introduce a benchmark dataset consisting of
240K natural images filtered for aesthetic quality and 18K 3D-rendered
synthetic images with metadata such as lighting, camera angles, and object
relationships. This dataset addresses the deficiencies of existing benchmarks
and allows a complete evaluation. Empirical results demonstrate that our method
achieves state-of-the-art performance, significantly improving feature-space
fidelity (FID 15.26) and semantic alignment (CLIP-S 32.85) while maintaining
competitive aesthetic quality. We also conducted a user study to demonstrate
the efficacy of the proposed work on unseen benchmark and observed a remarkable
improvement of $\sim25\%$, $\sim19\%$, $\sim13\%$, and $\sim14\%$ in terms of
prompt alignment, photorealism, the presence of AI artifacts, and natural
aesthetics over existing works.

</details>


### [53] [Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset](https://arxiv.org/abs/2506.22554)
*Vasu Agrawal,Akinniyi Akinyemi,Kathryn Alvero,Morteza Behrooz,Julia Buffalini,Fabio Maria Carlucci,Joy Chen,Junming Chen,Zhang Chen,Shiyang Cheng,Praveen Chowdary,Joe Chuang,Antony D'Avirro,Jon Daly,Ning Dong,Mark Duppenthaler,Cynthia Gao,Jeff Girard,Martin Gleize,Sahir Gomez,Hongyu Gong,Srivathsan Govindarajan,Brandon Han,Sen He,Denise Hernandez,Yordan Hristov,Rongjie Huang,Hirofumi Inaguma,Somya Jain,Raj Janardhan,Qingyao Jia,Christopher Klaiber,Dejan Kovachev,Moneish Kumar,Hang Li,Yilei Li,Pavel Litvin,Wei Liu,Guangyao Ma,Jing Ma,Martin Ma,Xutai Ma,Lucas Mantovani,Sagar Miglani,Sreyas Mohan,Louis-Philippe Morency,Evonne Ng,Kam-Woh Ng,Tu Anh Nguyen,Amia Oberai,Benjamin Peloquin,Juan Pino,Jovan Popovic,Omid Poursaeed,Fabian Prada,Alice Rakotoarison,Alexander Richard,Christophe Ropers,Safiyyah Saleem,Vasu Sharma,Alex Shcherbyna,Jia Shen,Jie Shen,Anastasis Stathopoulos,Anna Sun,Paden Tomasello,Tuan Tran,Arina Turkatenko,Bo Wan,Chao Wang,Jeff Wang,Mary Williamson,Carleigh Wood,Tao Xiang,Yilin Yang,Julien Yao,Chen Zhang,Jiemin Zhang,Xinyue Zhang,Jason Zheng,Pavlo Zhyzheria,Jan Zikes,Michael Zollhoefer*

Main category: cs.CV

TL;DR: 论文介绍了Seamless Interaction Dataset，一个包含4000小时面对面互动视频的大规模数据集，用于开发能理解和生成双向行为动态的AI模型，并展示了相关模型及其评估方法。


<details>
  <summary>Details</summary>
Motivation: 开发社交智能AI技术需要模型能够理解和生成双向行为动态，以推动虚拟代理、远程呈现体验和多模态内容分析工具的发展。

Method: 引入Seamless Interaction Dataset，开发了一套模型用于生成与人类语音对齐的双向动作和面部表情，并整合了LLM语音和2D/3D渲染方法。

Result: 模型能够根据输入语音和视觉行为生成动态响应，并具备可控的情感表达和语义相关手势生成能力。

Conclusion: 这些模型展示了更直观和响应式的人机交互潜力，为未来AI技术的发展奠定了基础。

Abstract: Human communication involves a complex interplay of verbal and nonverbal
signals, essential for conveying meaning and achieving interpersonal goals. To
develop socially intelligent AI technologies, it is crucial to develop models
that can both comprehend and generate dyadic behavioral dynamics. To this end,
we introduce the Seamless Interaction Dataset, a large-scale collection of over
4,000 hours of face-to-face interaction footage from over 4,000 participants in
diverse contexts. This dataset enables the development of AI technologies that
understand dyadic embodied dynamics, unlocking breakthroughs in virtual agents,
telepresence experiences, and multimodal content analysis tools. We also
develop a suite of models that utilize the dataset to generate dyadic motion
gestures and facial expressions aligned with human speech. These models can
take as input both the speech and visual behavior of their interlocutors. We
present a variant with speech from an LLM model and integrations with 2D and 3D
rendering methods, bringing us closer to interactive virtual agents.
Additionally, we describe controllable variants of our motion models that can
adapt emotional responses and expressivity levels, as well as generating more
semantically-relevant gestures. Finally, we discuss methods for assessing the
quality of these dyadic motion models, which are demonstrating the potential
for more intuitive and responsive human-AI interactions.

</details>


### [54] [Recomposed realities: animating still images via patch clustering and randomness](https://arxiv.org/abs/2506.22556)
*Markus Juvonen,Samuli Siltanen*

Main category: cs.CV

TL;DR: 提出了一种基于图像块的图像重建与动画方法，通过运动使静态图像生动化。


<details>
  <summary>Details</summary>
Motivation: 利用现有图像数据，通过重新解释而非复制，实现静态图像的动态化。

Method: 使用k均值聚类对图像块进行分组，通过匹配和随机采样从聚类中重建新目标图像。

Result: 允许源域和目标域在概念上不同，但共享局部结构。

Conclusion: 该方法通过重新解释图像块实现了静态图像的动态化。

Abstract: We present a patch-based image reconstruction and animation method that uses
existing image data to bring still images to life through motion. Image patches
from curated datasets are grouped using k-means clustering and a new target
image is reconstructed by matching and randomly sampling from these clusters.
This approach emphasizes reinterpretation over replication, allowing the source
and target domains to differ conceptually while sharing local structures.

</details>


### [55] [Improving Token-based Object Detection with Video](https://arxiv.org/abs/2506.22562)
*Abhineet Singh,Nilanjan Ray*

Main category: cs.CV

TL;DR: 论文改进了Pix2Seq目标检测器，将其扩展到视频领域，提出了一种新的端到端视频目标检测方法，解决了传统检测器的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统视频目标检测方法存在训练稀疏性和后处理启发式问题，且通常通过链接2D框构建视频对象，效率较低。本文旨在解决这些问题。

Method: 通过将对象表示为离散标记的可变长度序列，无需定位线索训练；将视频对象视为不可分割的3D框或轨迹，而非链接2D框。

Result: 在多个数据集上优于Pix2Seq静态检测器，并在UA-DETRAC上与当前最先进方法竞争，尽管受限于计算资源。

Conclusion: 提出的方法在视频目标检测中表现优异，解决了传统方法的局限性，但计算资源是主要瓶颈。

Abstract: This paper improves upon the Pix2Seq object detector by extending it for
videos. In the process, it introduces a new way to perform end-to-end video
object detection that improves upon existing video detectors in two key ways.
First, by representing objects as variable-length sequences of discrete tokens,
we can succinctly represent widely varying numbers of video objects, with
diverse shapes and locations, without having to inject any localization cues in
the training process. This eliminates the need to sample the space of all
possible boxes that constrains conventional detectors and thus solves the dual
problems of loss sparsity during training and heuristics-based postprocessing
during inference. Second, it conceptualizes and outputs the video objects as
fully integrated and indivisible 3D boxes or tracklets instead of generating
image-specific 2D boxes and linking these boxes together to construct the video
object, as done in most conventional detectors. This allows it to scale
effortlessly with available computational resources by simply increasing the
length of the video subsequence that the network takes as input, even
generalizing to multi-object tracking if the subsequence can span the entire
video. We compare our video detector with the baseline Pix2Seq static detector
on several datasets and demonstrate consistent improvement, although with
strong signs of being bottlenecked by our limited computational resources. We
also compare it with several video detectors on UA-DETRAC to show that it is
competitive with the current state of the art even with the computational
bottleneck. We make our code and models publicly available.

</details>


### [56] [Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation](https://arxiv.org/abs/2506.22567)
*Shansong Wang,Zhecheng Jin,Mingzhe Hu,Mojtaba Safari,Feng Zhao,Chih-Wei Chang,Richard LJ Qiu,Justin Roper,David S. Yu,Xiaofeng Yang*

Main category: cs.CV

TL;DR: MMKD-CLIP通过多教师知识蒸馏构建高性能生物医学基础模型，解决了数据稀缺和异构性问题。


<details>
  <summary>Details</summary>
Motivation: 生物医学领域缺乏大规模图像-文本数据，且数据标准和模态多样，阻碍了通用基础模型的开发。

Method: 采用两阶段训练：首先在290万生物医学图像-文本对上预训练，然后从9个教师模型中蒸馏1920万特征对。

Result: 在58个数据集上评估，涵盖1080万图像和9种模态，MMKD-CLIP在所有任务中均优于教师模型。

Conclusion: 多教师知识蒸馏是构建高性能生物医学基础模型的有效方法。

Abstract: CLIP models pretrained on natural images with billion-scale image-text pairs
have demonstrated impressive capabilities in zero-shot classification,
cross-modal retrieval, and open-ended visual answering. However, transferring
this success to biomedicine is hindered by the scarcity of large-scale
biomedical image-text corpora, the heterogeneity of image modalities, and
fragmented data standards across institutions. These limitations hinder the
development of a unified and generalizable biomedical foundation model trained
from scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedical
foundation model developed via Multiple Medical CLIP Knowledge Distillation.
Rather than relying on billion-scale raw data, MMKD-CLIP distills knowledge
from nine state-of-the-art domain-specific or generalist biomedical CLIP
models, each pretrained on millions of biomedical image-text pairs. Our
two-stage training pipeline first performs CLIP-style pretraining on over 2.9
million biomedical image-text pairs from 26 image modalities, followed by
feature-level distillation using over 19.2 million feature pairs extracted from
teacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets,
encompassing over 10.8 million biomedical images across nine image modalities.
The evaluation spans six core task types: zero-shot classification, linear
probing, cross-modal retrieval, visual question answering, survival prediction,
and cancer diagnosis. MMKD-CLIP consistently outperforms all teacher models
while demonstrating remarkable robustness and generalization across image
domains and task settings. These results underscore that multi-teacher
knowledge distillation is a scalable and effective paradigm for building
high-performing biomedical foundation models under the practical constraints of
real-world data availability.

</details>


### [57] [Dual Atrous Separable Convolution for Improving Agricultural Semantic Segmentation](https://arxiv.org/abs/2506.22570)
*Chee Mei Ling,Thangarajah Akilan,Aparna Ravinda Phalke*

Main category: cs.CV

TL;DR: 提出了一种基于DeepLabV3的高效农业图像语义分割方法，通过引入DAS Conv模块和优化跳连结构，在保持低计算复杂度的同时，性能接近复杂Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 农业图像语义分割对精准农业至关重要，但现有方法在效率和性能间难以平衡。

Method: 集成DAS Conv模块优化扩张率和填充尺寸，并设计策略性跳连结构以捕捉细粒度特征。

Result: 在Agriculture Vision数据集上性能接近SOTA模型，效率提升66%。

Conclusion: 该方法为农业遥感提供了一种高效、轻量且高性能的语义分割解决方案。

Abstract: Agricultural image semantic segmentation is a pivotal component of modern
agriculture, facilitating accurate visual data analysis to improve crop
management, optimize resource utilization, and boost overall productivity. This
study proposes an efficient image segmentation method for precision
agriculture, focusing on accurately delineating farmland anomalies to support
informed decision-making and proactive interventions. A novel Dual Atrous
Separable Convolution (DAS Conv) module is integrated within the
DeepLabV3-based segmentation framework. The DAS Conv module is meticulously
designed to achieve an optimal balance between dilation rates and padding size,
thereby enhancing model performance without compromising efficiency. The study
also incorporates a strategic skip connection from an optimal stage in the
encoder to the decoder to bolster the model's capacity to capture fine-grained
spatial features. Despite its lower computational complexity, the proposed
model outperforms its baseline and achieves performance comparable to highly
complex transformer-based state-of-the-art (SOTA) models on the Agriculture
Vision benchmark dataset. It achieves more than 66% improvement in efficiency
when considering the trade-off between model complexity and performance,
compared to the SOTA model. This study highlights an efficient and effective
solution for improving semantic segmentation in remote sensing applications,
offering a computationally lightweight model capable of high-quality
performance in agricultural imagery.

</details>


### [58] [LIGHT: Multi-Modal Text Linking on Historical Maps](https://arxiv.org/abs/2506.22589)
*Yijun Lin,Rhett Olson,Junhan Wu,Yao-Yi Chiang,Jerod Weinman*

Main category: cs.CV

TL;DR: LIGHT是一种多模态方法，结合语言、图像和几何特征，用于链接历史地图上的文本，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 历史地图上的文本信息对多学科研究至关重要，但现有方法难以有效链接文本片段，尤其是多词地名。

Method: LIGHT整合几何、视觉和语言特征，通过几何感知嵌入模块和多模态学习预测文本阅读顺序。

Result: 在ICDAR 2024/2025 MapText竞赛数据上，LIGHT表现优于现有方法。

Conclusion: 多模态学习能有效提升历史地图文本链接的准确性。

Abstract: Text on historical maps provides valuable information for studies in history,
economics, geography, and other related fields. Unlike structured or
semi-structured documents, text on maps varies significantly in orientation,
reading order, shape, and placement. Many modern methods can detect and
transcribe text regions, but they struggle to effectively ``link'' the
recognized text fragments, e.g., determining a multi-word place name. Existing
layout analysis methods model word relationships to improve text understanding
in structured documents, but they primarily rely on linguistic features and
neglect geometric information, which is essential for handling map text. To
address these challenges, we propose LIGHT, a novel multi-modal approach that
integrates linguistic, image, and geometric features for linking text on
historical maps. In particular, LIGHT includes a geometry-aware embedding
module that encodes the polygonal coordinates of text regions to capture
polygon shapes and their relative spatial positions on an image. LIGHT unifies
this geometric information with the visual and linguistic token embeddings from
LayoutLMv3, a pretrained layout analysis model. LIGHT uses the cross-modal
information to predict the reading-order successor of each text instance
directly with a bi-directional learning strategy that enhances sequence
robustness. Experimental results show that LIGHT outperforms existing methods
on the ICDAR 2024/2025 MapText Competition data, demonstrating the
effectiveness of multi-modal learning for historical map text linking.

</details>


### [59] [BrainMT: A Hybrid Mamba-Transformer Architecture for Modeling Long-Range Dependencies in Functional MRI Data](https://arxiv.org/abs/2506.22591)
*Arunkumar Kannan,Martin A. Lindquist,Brian Caffo*

Main category: cs.CV

TL;DR: BrainMT是一种新型混合框架，结合双向Mamba块和Transformer块，有效捕捉fMRI数据中的长距离时空依赖关系，在分类和回归任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如CNN或Transformer）难以建模fMRI数据中的复杂时空关系，BrainMT旨在解决这一局限性。

Method: BrainMT分两阶段：1）双向Mamba块捕获全局时间交互；2）Transformer块建模空间关系。

Result: 在UKBioBank和Human Connectome Project数据集上，BrainMT在分类（性别预测）和回归（认知预测）任务中表现最优。

Conclusion: BrainMT通过高效学习长距离时空属性，显著优于现有方法，代码将公开。

Abstract: Recent advances in deep learning have made it possible to predict phenotypic
measures directly from functional magnetic resonance imaging (fMRI) brain
volumes, sparking significant interest in the neuroimaging community. However,
existing approaches, primarily based on convolutional neural networks or
transformer architectures, often struggle to model the complex relationships
inherent in fMRI data, limited by their inability to capture long-range spatial
and temporal dependencies. To overcome these shortcomings, we introduce
BrainMT, a novel hybrid framework designed to efficiently learn and integrate
long-range spatiotemporal attributes in fMRI data. Our framework operates in
two stages: (1) a bidirectional Mamba block with a temporal-first scanning
mechanism to capture global temporal interactions in a computationally
efficient manner; and (2) a transformer block leveraging self-attention to
model global spatial relationships across the deep features processed by the
Mamba block. Extensive experiments on two large-scale public datasets,
UKBioBank and the Human Connectome Project, demonstrate that BrainMT achieves
state-of-the-art performance on both classification (sex prediction) and
regression (cognitive intelligence prediction) tasks, outperforming existing
methods by a significant margin. Our code and implementation details will be
made publicly available at this
https://github.com/arunkumar-kannan/BrainMT-fMRI

</details>


### [60] [Seg-R1: Segmentation Can Be Surprisingly Simple with Reinforcement Learning](https://arxiv.org/abs/2506.22624)
*Zuyao You,Zuxuan Wu*

Main category: cs.CV

TL;DR: Seg-R1利用强化学习增强大型多模态模型的像素级理解能力，通过GRPO策略在分割任务中表现优异，无需复杂修改即可实现高性能和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过强化学习提升大型多模态模型在像素级任务（如前景分割）中的理解和推理能力。

Method: 采用Group Relative Policy Optimization (GRPO)策略，通过点提示和边界框提示引导SAM2生成分割掩码，仅使用RL训练。

Result: 在COD10K上达到0.873 S-measure，在RefCOCOg和ReasonSeg上分别实现71.4 cIoU和56.7 gIoU的零样本性能，优于全监督模型。

Conclusion: Seg-R1证明了纯RL训练在像素级任务中的有效性，并展示了强大的开放世界泛化能力。

Abstract: We present Seg-R1, a preliminary exploration of using reinforcement learning
(RL) to enhance the pixel-level understanding and reasoning capabilities of
large multimodal models (LMMs). Starting with foreground segmentation tasks,
specifically camouflaged object detection (COD) and salient object detection
(SOD), our approach enables the LMM to generate point and bounding box prompts
in the next-token fashion, which are then used to guide SAM2 in producing
segmentation masks. We introduce Group Relative Policy Optimization (GRPO) into
the segmentation domain, equipping the LMM with pixel-level comprehension
through a carefully designed training strategy. Notably, Seg-R1 achieves
remarkable performance with purely RL-based training, achieving .873 S-measure
on COD10K without complex model modification. Moreover, we found that pure RL
training demonstrates strong open-world generalization. Despite being trained
solely on foreground segmentation image-mask pairs without text supervision,
Seg-R1 achieves impressive zero-shot performance on referring segmentation and
reasoning segmentation tasks, with 71.4 cIoU on RefCOCOg test and 56.7 gIoU on
ReasonSeg test, outperforming models fully supervised on these datasets.

</details>


### [61] [ReCo: Reminder Composition Mitigates Hallucinations in Vision-Language Models](https://arxiv.org/abs/2506.22636)
*Sotirios Panagiotis Chytas,Miso Choi,Hyunwoo J. Kim,Vikas Singh*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级模块ReCo，用于缓解视觉语言模型（VLMs）中的幻觉问题，通过几何代数和关系组合的方法，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: VLMs在视觉和语言数据整合中表现出色，但存在幻觉问题，即生成与视觉输入不符的文本。研究发现这是由于模型对语言的过度依赖导致的“记忆衰减效应”。

Method: 提出了一种名为ReCo的小型可训练模块，无需修改现有VLM结构，利用几何代数和关系组合来控制幻觉行为。

Result: 在InstructBLIP、LlaVA和MiniGPT4三种主流VLM上测试，ReCo模块显著减轻了记忆衰减效应，并在多个基准测试中提升了性能。此外，ReCo还能与其他减少幻觉的方法结合，进一步提升效果。

Conclusion: ReCo模块是一种简单有效的解决方案，能够显著改善VLMs的幻觉问题，且兼容性强，可与其他方法结合使用。

Abstract: Vision Language Models (VLMs) show impressive capabilities in integrating and
reasoning with both visual and language data. But these models make mistakes. A
common finding -- similar to LLMs -- is their tendency to hallucinate, i.e.,
generate plausible sounding text which is not grounded in the visual input, or
at worst, is contradictory. A growing consensus attributes this behavior to an
over-reliance on language -- especially as the generation progresses, the model
suffers from a ``fading memory effect'' with respect to the provided visual
input. We study mechanisms by which this behavior can be controlled.
Specifically, using ideas from geometric algebra and relational compositions,
we propose the addition of a small, trainable module (named ReCo) on top of any
VLM -- no other modification is needed. We show that such a lightweight module
is able to mitigate the fading memory effect on three of the most widely used
VLMs (InstructBLIP, LlaVA, MiniGPT4), where we see performance improvements on
multiple benchmarks. Additionally, we show that our module can be combined with
many of the other approaches for reducing hallucination where we achieve
improved results for each one.

</details>


### [62] [CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation](https://arxiv.org/abs/2506.22637)
*Haoxuan Wang,Zhenghao Zhao,Junyi Wu,Yuzhang Shang,Gaowen Liu,Yan Yan*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的数据集蒸馏方法CaO$_2$，解决了现有方法在目标不一致和条件不一致上的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散模型的数据集蒸馏方法在评估过程中存在目标不一致和条件不一致的问题，影响了性能和效率。

Method: 提出了CaO$_2$框架，分为两阶段：概率信息样本选择管道和潜表示优化，以对齐蒸馏过程与评估目标。

Result: 在ImageNet及其子集上实现了最先进的性能，平均准确率提升2.3%。

Conclusion: CaO$_2$通过解决不一致性问题，显著提升了数据集蒸馏的效率和性能。

Abstract: The recent introduction of diffusion models in dataset distillation has shown
promising potential in creating compact surrogate datasets for large,
high-resolution target datasets, offering improved efficiency and performance
over traditional bi-level/uni-level optimization methods. However, current
diffusion-based dataset distillation approaches overlook the evaluation process
and exhibit two critical inconsistencies in the distillation process: (1)
Objective Inconsistency, where the distillation process diverges from the
evaluation objective, and (2) Condition Inconsistency, leading to mismatches
between generated images and their corresponding conditions. To resolve these
issues, we introduce Condition-aware Optimization with Objective-guided
Sampling (CaO$_2$), a two-stage diffusion-based framework that aligns the
distillation process with the evaluation objective. The first stage employs a
probability-informed sample selection pipeline, while the second stage refines
the corresponding latent representations to improve conditional likelihood.
CaO$_2$ achieves state-of-the-art performance on ImageNet and its subsets,
surpassing the best-performing baselines by an average of 2.3% accuracy.

</details>


### [63] [3D Shape Generation: A Survey](https://arxiv.org/abs/2506.22678)
*Nicolas Caytuiro,Ivan Sipiran*

Main category: cs.CV

TL;DR: 本文综述了3D形状生成的最新进展，重点讨论了形状表示、生成方法和评估协议，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 深度学习推动了3D形状生成的发展，但缺乏系统综述，本文旨在填补这一空白。

Method: 通过分类3D表示（显式、隐式、混合）、生成方法（前馈架构）和评估指标（保真度、多样性、真实性）进行综述。

Result: 总结了当前技术现状，并指出了可控性、效率和质量提升的未来挑战。

Conclusion: 本文为研究人员提供了3D形状生成领域的结构化参考，并展望了未来发展方向。

Abstract: Recent advances in deep learning have significantly transformed the field of
3D shape generation, enabling the synthesis of complex, diverse, and
semantically meaningful 3D objects. This survey provides a comprehensive
overview of the current state of the art in 3D shape generation, organizing the
discussion around three core components: shape representations, generative
modeling approaches, and evaluation protocols. We begin by categorizing 3D
representations into explicit, implicit, and hybrid setups, highlighting their
structural properties, advantages, and limitations. Next, we review a wide
range of generation methods, focusing on feedforward architectures. We further
summarize commonly used datasets and evaluation metrics that assess fidelity,
diversity, and realism of generated shapes. Finally, we identify open
challenges and outline future research directions that could drive progress in
controllable, efficient, and high-quality 3D shape generation. This survey aims
to serve as a valuable reference for researchers and practitioners seeking a
structured and in-depth understanding of this rapidly evolving field.

</details>


### [64] [LightBSR: Towards Lightweight Blind Super-Resolution via Discriminative Implicit Degradation Representation Learning](https://arxiv.org/abs/2506.22710)
*Jiang Yuan,JI Ma,Bo Wang,Guanzhou Ke,Weiming Hu*

Main category: cs.CV

TL;DR: LightBSR提出了一种轻量级盲超分辨率模型，通过优化隐式退化表示（IDR）的区分性，结合知识蒸馏和对比学习技术，显著提升了性能并降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有IDE-BSR方法忽视了IDR区分性的重要性，且模型复杂度过高。本文旨在优化IDR区分性，设计轻量高效的BSR模型。

Method: 采用知识蒸馏框架，结合退化先验约束的对比学习（教师阶段）和特征对齐技术（学生阶段），提升IDR区分性并简化模型。

Result: 实验表明，LightBSR在多种盲超分辨率任务中表现优异，且计算复杂度显著降低。

Conclusion: 优化IDR区分性是提升盲超分辨率性能的关键，LightBSR为轻量高效BSR模型设计提供了新思路。

Abstract: Implicit degradation estimation-based blind super-resolution (IDE-BSR) hinges
on extracting the implicit degradation representation (IDR) of the LR image and
adapting it to LR image features to guide HR detail restoration. Although
IDE-BSR has shown potential in dealing with noise interference and complex
degradations, existing methods ignore the importance of IDR discriminability
for BSR and instead over-complicate the adaptation process to improve effect,
resulting in a significant increase in the model's parameters and computations.
In this paper, we focus on the discriminability optimization of IDR and propose
a new powerful and lightweight BSR model termed LightBSR. Specifically, we
employ a knowledge distillation-based learning framework. We first introduce a
well-designed degradation-prior-constrained contrastive learning technique
during teacher stage to make the model more focused on distinguishing different
degradation types. Then we utilize a feature alignment technique to transfer
the degradation-related knowledge acquired by the teacher to the student for
practical inferencing. Extensive experiments demonstrate the effectiveness of
IDR discriminability-driven BSR model design. The proposed LightBSR can achieve
outstanding performance with minimal complexity across a range of blind SR
tasks. Our code is accessible at: https://github.com/MJ-NCEPU/LightBSR.

</details>


### [65] [Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians](https://arxiv.org/abs/2506.22718)
*Jun-Jee Chao,Qingyuan Jiang,Volkan Isler*

Main category: cs.CV

TL;DR: 提出一种联合解决部分分割和运动估计的方法，通过3D高斯表示处理动态点云序列，适用于遮挡和多传感器异步采集场景。


<details>
  <summary>Details</summary>
Motivation: 解决动态点云序列中部分分割和运动估计的挑战，特别是在点云非固定采样或存在遮挡的情况下。

Method: 使用3D高斯模型表示物体，参数化时间依赖的旋转、平移和缩放，通过点与高斯的对应关系实现分割和运动估计。

Result: 在遮挡场景下，部分分割性能优于现有方法13%，且对缺失点更鲁棒。

Conclusion: 该方法在动态点云分析中表现优异，尤其在复杂场景下具有显著优势。

Abstract: Part segmentation and motion estimation are two fundamental problems for
articulated object motion analysis. In this paper, we present a method to solve
these two problems jointly from a sequence of observed point clouds of a single
articulated object. The main challenge in our problem setting is that the point
clouds are not assumed to be generated by a fixed set of moving points.
Instead, each point cloud in the sequence could be an arbitrary sampling of the
object surface at that particular time step. Such scenarios occur when the
object undergoes major occlusions, or if the dataset is collected using
measurements from multiple sensors asynchronously. In these scenarios, methods
that rely on tracking point correspondences are not appropriate. We present an
alternative approach based on a compact but effective representation where we
represent the object as a collection of simple building blocks modeled as 3D
Gaussians. We parameterize the Gaussians with time-dependent rotations,
translations, and scales that are shared across all time steps. With our
representation, part segmentation can be achieved by building correspondences
between the observed points and the Gaussians. Moreover, the transformation of
each point across time can be obtained by following the poses of the assigned
Gaussian (even when the point is not observed). Experiments show that our
method outperforms existing methods that solely rely on finding point
correspondences. Additionally, we extend existing datasets to emulate
real-world scenarios by considering viewpoint occlusions. We further
demonstrate that our method is more robust to missing points as compared to
existing approaches on these challenging datasets, even when some parts are
completely occluded in some time-steps. Notably, our part segmentation
performance outperforms the state-of-the-art method by 13% on point clouds with
occlusions.

</details>


### [66] [Deterministic Object Pose Confidence Region Estimation](https://arxiv.org/abs/2506.22720)
*Jinghao Wang,Zhang Li,Zi Wang,Banglei Guan,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出了一种确定性方法，用于估计6D姿态置信区域，解决了采样方法的速度和区域过大的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于采样的方法在速度和置信区域大小上存在显著限制，影响了实际应用。

Method: 使用归纳共形预测校准高斯关键点分布，并通过隐函数定理直接传播到6D姿态置信区域。

Result: 在LineMOD Occlusion和SPEED数据集上，方法提高了姿态估计精度，减少了计算时间，置信区域体积显著缩小。

Conclusion: 该方法高效且紧凑，能以用户定义的置信水平覆盖真实姿态，显著优于现有方法。

Abstract: 6D pose confidence region estimation has emerged as a critical direction,
aiming to perform uncertainty quantification for assessing the reliability of
estimated poses. However, current sampling-based approach suffers from critical
limitations that severely impede their practical deployment: 1) the sampling
speed significantly decreases as the number of samples increases. 2) the
derived confidence regions are often excessively large. To address these
challenges, we propose a deterministic and efficient method for estimating pose
confidence regions. Our approach uses inductive conformal prediction to
calibrate the deterministically regressed Gaussian keypoint distributions into
2D keypoint confidence regions. We then leverage the implicit function theorem
to propagate these keypoint confidence regions directly into 6D pose confidence
regions. This method avoids the inefficiency and inflated region sizes
associated with sampling and ensembling. It provides compact confidence regions
that cover the ground-truth poses with a user-defined confidence level.
Experimental results on the LineMOD Occlusion and SPEED datasets show that our
method achieves higher pose estimation accuracy with reduced computational
time. For the same coverage rate, our method yields significantly smaller
confidence region volumes, reducing them by up to 99.9\% for rotations and
99.8\% for translations. The code will be available soon.

</details>


### [67] [XTransfer: Cross-Modality Model Transfer for Human Sensing with Few Data at the Edge](https://arxiv.org/abs/2506.22726)
*Yu Zhang,Xi Zhang,Hualin zhou,Xinyuan Chen,Shang Gao,Hong Jia,Jianfei Yang,Yuankai Qi,Tao Gu*

Main category: cs.CV

TL;DR: XTransfer是一种资源高效、模态无关的模型迁移方法，通过模型修复和层重组解决边缘系统中深度学习模型训练的挑战。


<details>
  <summary>Details</summary>
Motivation: 边缘系统中深度学习模型的训练和开发受限于传感器数据的稀缺性和资源限制，现有方法存在模态偏移和高资源需求问题。

Method: XTransfer通过模型修复（修复模态偏移）和层重组（高效搜索和重组源模型层）实现资源高效的模型迁移。

Result: XTransfer在多种人类感知任务中表现优异，显著降低了数据收集、模型训练和边缘部署的成本。

Conclusion: XTransfer为边缘系统中的人类感知任务提供了一种高效、适应性强的解决方案。

Abstract: Deep learning for human sensing on edge systems offers significant
opportunities for smart applications. However, its training and development are
hindered by the limited availability of sensor data and resource constraints of
edge systems. Current methods that rely on transferring pre-trained models
often encounter issues such as modality shift and high resource demands,
resulting in substantial accuracy loss, resource overhead, and poor
adaptability across different sensing applications. In this paper, we propose
XTransfer, a first-of-its-kind method for resource-efficient, modality-agnostic
model transfer. XTransfer freely leverages single or multiple pre-trained
models and transfers knowledge across different modalities by (i) model
repairing that safely repairs modality shift in pre-trained model layers with
only few sensor data, and (ii) layer recombining that efficiently searches and
recombines layers of interest from source models in a layer-wise manner to
create compact models. We benchmark various baselines across diverse human
sensing datasets spanning different modalities. Comprehensive results
demonstrate that XTransfer achieves state-of-the-art performance on human
sensing tasks while significantly reducing the costs of sensor data collection,
model training, and edge deployment.

</details>


### [68] [UniFuse: A Unified All-in-One Framework for Multi-Modal Medical Image Fusion Under Diverse Degradations and Misalignments](https://arxiv.org/abs/2506.22736)
*Dayong Su,Yafei Zhang,Huafeng Li,Jinxing Li,Yu Liu*

Main category: cs.CV

TL;DR: UniFuse是一个多模态医学图像融合框架，通过降解感知提示学习模块和Omni统一特征表示方案，解决了图像未对齐或质量差的问题，实现了对齐、恢复和融合的一体化优化。


<details>
  <summary>Details</summary>
Motivation: 当前多模态医学图像融合方法依赖于高质量和对齐良好的输入图像，但在处理未对齐或质量差的图像时效果不佳。

Method: UniFuse通过降解感知提示学习模块、Omni统一特征表示方案和通用特征恢复与融合模块（ALSN），实现了对齐、恢复和融合的联合优化。

Result: 实验结果表明，UniFuse在多个数据集上优于现有方法，具有显著优势。

Conclusion: UniFuse通过一体化框架解决了多模态医学图像融合中的对齐和恢复问题，为相关领域提供了有效解决方案。

Abstract: Current multimodal medical image fusion typically assumes that source images
are of high quality and perfectly aligned at the pixel level. Its effectiveness
heavily relies on these conditions and often deteriorates when handling
misaligned or degraded medical images. To address this, we propose UniFuse, a
general fusion framework. By embedding a degradation-aware prompt learning
module, UniFuse seamlessly integrates multi-directional information from input
images and correlates cross-modal alignment with restoration, enabling joint
optimization of both tasks within a unified framework. Additionally, we design
an Omni Unified Feature Representation scheme, which leverages Spatial Mamba to
encode multi-directional features and mitigate modality differences in feature
alignment. To enable simultaneous restoration and fusion within an All-in-One
configuration, we propose a Universal Feature Restoration & Fusion module,
incorporating the Adaptive LoRA Synergistic Network (ALSN) based on LoRA
principles. By leveraging ALSN's adaptive feature representation along with
degradation-type guidance, we enable joint restoration and fusion within a
single-stage framework. Compared to staged approaches, UniFuse unifies
alignment, restoration, and fusion within a single framework. Experimental
results across multiple datasets demonstrate the method's effectiveness and
significant advantages over existing approaches.

</details>


### [69] [Deep Learning based Joint Geometry and Attribute Up-sampling for Large-Scale Colored Point Clouds](https://arxiv.org/abs/2506.22749)
*Yun Zhang,Feifan Chen,Na Li,Zhiwei Guo,Xu Wang,Fen Miao,Sam Kwong*

Main category: cs.CV

TL;DR: 该论文提出了一种基于深度学习的联合几何和属性上采样方法（JGAU），用于生成大规模且更密集的彩色点云，并通过实验验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 彩色点云是3D应用的主流表示，但现有方法在生成大规模且密集的彩色点云时存在质量不足的问题。

Method: 提出JGAU框架，包括几何上采样网络和属性上采样网络，并引入两种粗属性上采样方法（GDWAI和DLAI）及属性增强模块。

Result: 实验结果显示，JGAU在4倍、8倍、12倍和16倍上采样率下的PSNR分别为33.90、32.10、31.10和30.39分贝，优于现有方法。

Conclusion: JGAU方法在彩色点云上采样任务中表现出显著优势，为3D应用提供了高质量的解决方案。

Abstract: Colored point cloud, which includes geometry and attribute components, is a
mainstream representation enabling realistic and immersive 3D applications. To
generate large-scale and denser colored point clouds, we propose a deep
learning-based Joint Geometry and Attribute Up-sampling (JGAU) method that
learns to model both geometry and attribute patterns while leveraging spatial
attribute correlations. First, we establish and release a large-scale dataset
for colored point cloud up-sampling called SYSU-PCUD, containing 121
large-scale colored point clouds with diverse geometry and attribute
complexities across six categories and four sampling rates. Second, to improve
the quality of up-sampled point clouds, we propose a deep learning-based JGAU
framework that jointly up-samples geometry and attributes. It consists of a
geometry up-sampling network and an attribute up-sampling network, where the
latter leverages the up-sampled auxiliary geometry to model neighborhood
correlations of the attributes. Third, we propose two coarse attribute
up-sampling methods, Geometric Distance Weighted Attribute Interpolation
(GDWAI) and Deep Learning-based Attribute Interpolation (DLAI), to generate
coarse up-sampled attributes for each point. Then, an attribute enhancement
module is introduced to refine these up-sampled attributes and produce
high-quality point clouds by further exploiting intrinsic attribute and
geometry patterns. Extensive experiments show that the Peak Signal-to-Noise
Ratio (PSNR) achieved by the proposed JGAU method is 33.90 decibels, 32.10
decibels, 31.10 decibels, and 30.39 decibels for up-sampling rates of 4 times,
8 times, 12 times, and 16 times, respectively. Compared to state-of-the-art
methods, JGAU achieves average PSNR gains of 2.32 decibels, 2.47 decibels, 2.28
decibels, and 2.11 decibels at these four up-sampling rates, demonstrating
significant improvement.

</details>


### [70] [Degradation-Modeled Multipath Diffusion for Tunable Metalens Photography](https://arxiv.org/abs/2506.22753)
*Jianing Zhang,Jiayi Zhu,Feiyu Ji,Xiaokang Yang,Xiaoyun Yuan*

Main category: cs.CV

TL;DR: 提出了一种基于预训练模型的多路径扩散方法（Degradation-Modeled Multipath Diffusion），用于解决金属透镜摄影中的光学退化问题，无需大规模配对数据。


<details>
  <summary>Details</summary>
Motivation: 金属透镜在计算成像中潜力巨大，但面临光学退化和计算恢复的挑战，现有方法依赖精确校准或大量配对数据，且难以控制推理过程。

Method: 采用多路径扩散框架（正、中、负提示路径）结合伪数据增强，设计了可调解码器和空间变化退化感知注意力模块（SVDA）。

Result: 实验结果表明，该方法优于现有技术，实现了高保真和清晰的图像重建。

Conclusion: 该方法通过自然图像先验和可控推理，有效解决了金属透镜摄影中的退化问题，并展示了实际应用潜力。

Abstract: Metalenses offer significant potential for ultra-compact computational
imaging but face challenges from complex optical degradation and computational
restoration difficulties. Existing methods typically rely on precise optical
calibration or massive paired datasets, which are non-trivial for real-world
imaging systems. Furthermore, a lack of control over the inference process
often results in undesirable hallucinated artifacts. We introduce
Degradation-Modeled Multipath Diffusion for tunable metalens photography,
leveraging powerful natural image priors from pretrained models instead of
large datasets. Our framework uses positive, neutral, and negative-prompt paths
to balance high-frequency detail generation, structural fidelity, and
suppression of metalens-specific degradation, alongside \textit{pseudo} data
augmentation. A tunable decoder enables controlled trade-offs between fidelity
and perceptual quality. Additionally, a spatially varying degradation-aware
attention (SVDA) module adaptively models complex optical and sensor-induced
degradation. Finally, we design and build a millimeter-scale MetaCamera for
real-world validation. Extensive results show that our approach outperforms
state-of-the-art methods, achieving high-fidelity and sharp image
reconstruction. More materials: https://dmdiff.github.io/.

</details>


### [71] [Neural Cellular Automata: From Cells to Pixels](https://arxiv.org/abs/2506.22899)
*Ehsan Pajouheshgar,Yitao Xu,Ali Abbasi,Alexander Mordvintsev,Wenzel Jakob,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 通过结合隐式解码器和新型损失函数，解决了神经细胞自动机（NCA）在高分辨率下的扩展性问题，实现了实时高清输出。


<details>
  <summary>Details</summary>
Motivation: NCA在低分辨率网格上表现良好，但在高分辨率下因计算和内存需求剧增、信息传播受限等问题难以扩展。

Method: 引入共享隐式解码器，在粗网格上运行NCA后通过轻量级解码器生成任意分辨率图像，并设计针对高分辨率任务的损失函数。

Result: 实现了实时高清输出，保持自组织和涌现特性，计算高效且并行性强，适用于多种NCA变体和任务。

Conclusion: 提出的框架显著提升了NCA在高分辨率下的质量和效率，扩展了其应用范围。

Abstract: Neural Cellular Automata (NCAs) are bio-inspired systems in which identical
cells self-organize to form complex and coherent patterns by repeatedly
applying simple local rules. NCAs display striking emergent behaviors including
self-regeneration, generalization and robustness to unseen situations, and
spontaneous motion. Despite their success in texture synthesis and
morphogenesis, NCAs remain largely confined to low-resolution grids. This
limitation stems from (1) training time and memory requirements that grow
quadratically with grid size, (2) the strictly local propagation of information
which impedes long-range cell communication, and (3) the heavy compute demands
of real-time inference at high resolution. In this work, we overcome this
limitation by pairing NCA with a tiny, shared implicit decoder, inspired by
recent advances in implicit neural representations. Following NCA evolution on
a coarse grid, a lightweight decoder renders output images at arbitrary
resolution. We also propose novel loss functions for both morphogenesis and
texture synthesis tasks, specifically tailored for high-resolution output with
minimal memory and computation overhead. Combining our proposed architecture
and loss functions brings substantial improvement in quality, efficiency, and
performance. NCAs equipped with our implicit decoder can generate full-HD
outputs in real time while preserving their self-organizing, emergent
properties. Moreover, because each MLP processes cell states independently,
inference remains highly parallelizable and efficient. We demonstrate the
applicability of our approach across multiple NCA variants (on 2D, 3D grids,
and 3D meshes) and multiple tasks, including texture generation and
morphogenesis (growing patterns from a seed), showing that with our proposed
framework, NCAs seamlessly scale to high-resolution outputs with minimal
computational overhead.

</details>


### [72] [RoboPearls: Editable Video Simulation for Robot Manipulation](https://arxiv.org/abs/2506.22756)
*Tao Tang,Likui Zhang,Youpeng Wen,Kaidong Zhang,Jia-Wang Bian,xia zhou,Tianyi Yan,Kun Zhan,Peng Jia,Hefeng Wu,Liang Lin,Xiaodan Liang*

Main category: cs.CV

TL;DR: RoboPearls是一个基于3D高斯散射的可编辑视频仿真框架，用于机器人操作，通过自动化仿真生成和性能分析解决现实数据收集的挑战。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人操作数据的收集成本高且效率低，仿真平台虽提供可控环境，但存在仿真到现实的差距问题。

Method: RoboPearls利用3D高斯散射技术构建逼真仿真，结合增量语义蒸馏和3D正则化NNFM损失，并通过LLMs和VLMs实现自动化仿真生成与性能分析。

Result: 在多个数据集和场景（如RLBench、COLOSSEUM等）上的实验验证了RoboPearls的有效性和仿真性能。

Conclusion: RoboPearls通过高效、自动化的仿真框架，显著提升了机器人操作策略的开发效率，并有效缩小了仿真与现实的差距。

Abstract: The development of generalist robot manipulation policies has seen
significant progress, driven by large-scale demonstration data across diverse
environments. However, the high cost and inefficiency of collecting real-world
demonstrations hinder the scalability of data acquisition. While existing
simulation platforms enable controlled environments for robotic learning, the
challenge of bridging the sim-to-real gap remains. To address these challenges,
we propose RoboPearls, an editable video simulation framework for robotic
manipulation. Built on 3D Gaussian Splatting (3DGS), RoboPearls enables the
construction of photo-realistic, view-consistent simulations from demonstration
videos, and supports a wide range of simulation operators, including various
object manipulations, powered by advanced modules like Incremental Semantic
Distillation (ISD) and 3D regularized NNFM Loss (3D-NNFM). Moreover, by
incorporating large language models (LLMs), RoboPearls automates the simulation
production process in a user-friendly manner through flexible command
interpretation and execution. Furthermore, RoboPearls employs a vision-language
model (VLM) to analyze robotic learning issues to close the simulation loop for
performance enhancement. To demonstrate the effectiveness of RoboPearls, we
conduct extensive experiments on multiple datasets and scenes, including
RLBench, COLOSSEUM, Ego4D, Open X-Embodiment, and a real-world robot, which
demonstrate our satisfactory simulation performance.

</details>


### [73] [Point Cloud Compression and Objective Quality Assessment: A Survey](https://arxiv.org/abs/2506.22902)
*Yiling Xu,Yujie Zhang,Shuting Xia,Kaifa Yang,He Huang,Ziyu Shan,Wenjie Huang,Qi Yang,Le Yang*

Main category: cs.CV

TL;DR: 本文综述了3D点云压缩（PCC）和质量评估（PCQA）的最新进展，分析了手工和基于学习的算法，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 3D点云数据快速增长，但其不规则结构和高数据量带来压缩和质量评估的挑战，需高效解决方案。

Method: 分析手工和基于学习的PCC算法及PCQA指标，通过基准测试比较代表性方法。

Result: 总结了现有方法的优缺点，指出视觉保真度、延迟和多模态数据支持等挑战。

Conclusion: 未来方向包括混合压缩框架和高级特征提取策略，以实现更高效、沉浸式和智能的3D应用。

Abstract: The rapid growth of 3D point cloud data, driven by applications in autonomous
driving, robotics, and immersive environments, has led to criticals demand for
efficient compression and quality assessment techniques. Unlike traditional 2D
media, point clouds present unique challenges due to their irregular structure,
high data volume, and complex attributes. This paper provides a comprehensive
survey of recent advances in point cloud compression (PCC) and point cloud
quality assessment (PCQA), emphasizing their significance for real-time and
perceptually relevant applications. We analyze a wide range of handcrafted and
learning-based PCC algorithms, along with objective PCQA metrics. By
benchmarking representative methods on emerging datasets, we offer detailed
comparisons and practical insights into their strengths and limitations.
Despite notable progress, challenges such as enhancing visual fidelity,
reducing latency, and supporting multimodal data remain. This survey outlines
future directions, including hybrid compression frameworks and advanced feature
extraction strategies, to enable more efficient, immersive, and intelligent 3D
applications.

</details>


### [74] [VSRM: A Robust Mamba-Based Framework for Video Super-Resolution](https://arxiv.org/abs/2506.22762)
*Dinh Phu Tran,Dao Duy Hung,Daeyoung Kim*

Main category: cs.CV

TL;DR: VSRM是一种基于Mamba的视频超分辨率框架，通过空间-时间和时间-空间Mamba块提取长距离时空特征，并引入可变形交叉Mamba对齐模块和频率损失函数，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有CNN和Transformer方法在视频超分辨率中存在局部感受野限制或二次复杂度问题，Mamba因其长序列建模能力和线性复杂度成为潜在解决方案。

Method: 提出VSRM框架，结合空间-时间和时间-空间Mamba块提取特征，使用可变形交叉Mamba对齐模块动态对齐帧，并设计频率损失函数优化高频内容。

Result: VSRM在多个基准测试中达到SOTA性能，验证了其有效性。

Conclusion: VSRM为视频超分辨率提供了高效且性能优越的解决方案，为未来研究奠定了基础。

Abstract: Video super-resolution remains a major challenge in low-level vision tasks.
To date, CNN- and Transformer-based methods have delivered impressive results.
However, CNNs are limited by local receptive fields, while Transformers
struggle with quadratic complexity, posing challenges for processing long
sequences in VSR. Recently, Mamba has drawn attention for its long-sequence
modeling, linear complexity, and large receptive fields. In this work, we
propose VSRM, a novel \textbf{V}ideo \textbf{S}uper-\textbf{R}esolution
framework that leverages the power of \textbf{M}amba. VSRM introduces
Spatial-to-Temporal Mamba and Temporal-to-Spatial Mamba blocks to extract
long-range spatio-temporal features and enhance receptive fields efficiently.
To better align adjacent frames, we propose Deformable Cross-Mamba Alignment
module. This module utilizes a deformable cross-mamba mechanism to make the
compensation stage more dynamic and flexible, preventing feature distortions.
Finally, we minimize the frequency domain gaps between reconstructed and
ground-truth frames by proposing a simple yet effective Frequency
Charbonnier-like loss that better preserves high-frequency content and enhances
visual quality. Through extensive experiments, VSRM achieves state-of-the-art
results on diverse benchmarks, establishing itself as a solid foundation for
future research.

</details>


### [75] [A Novel Frame Identification and Synchronization Technique for Smartphone Visible Light Communication Systems Based on Convolutional Neural Networks](https://arxiv.org/abs/2506.23004)
*Vaigai Nayaki Yokar,Hoa Le-Minh,Xicong Li,Wai Lok Woo,Luis Nero Alves,Stanislav Zvanovec,Tran The Son,Zabih Ghassemlooy*

Main category: cs.CV

TL;DR: 提出了一种基于CNN的轻量级帧识别与同步技术，用于提升屏幕到相机（S2C）可见光通信（VLC）系统的性能，实验准确率达98.74%。


<details>
  <summary>Details</summary>
Motivation: 解决S2C通信中因模糊、裁剪和旋转图像等实时挑战导致的性能问题。

Method: 使用Python和TensorFlow Keras框架构建CNN模型，通过三个实时实验训练，数据集针对S2C通信中的实际问题设计。

Result: 模型在帧识别与同步中达到98.74%的准确率，显著提升系统性能。

Conclusion: 提出的CNN模型在S2C VLC系统中表现出高效性和鲁棒性，适用于实际应用。

Abstract: This paper proposes a novel, robust, and lightweight supervised Convolutional
Neural Network (CNN)-based technique for frame identification and
synchronization, designed to enhance short-link communication performance in a
screen-to-camera (S2C) based visible light communication (VLC) system.
Developed using Python and the TensorFlow Keras framework, the proposed CNN
model was trained through three real-time experimental investigations conducted
in Jupyter Notebook. These experiments incorporated a dataset created from
scratch to address various real-time challenges in S2C communication, including
blurring, cropping, and rotated images in mobility scenarios. Overhead frames
were introduced for synchronization, which leads to enhanced system
performance. The experimental results demonstrate that the proposed model
achieves an overall accuracy of approximately 98.74%, highlighting its
effectiveness in identifying and synchronizing frames in S2C VLC systems.

</details>


### [76] [PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection](https://arxiv.org/abs/2506.22783)
*Oguzhan Baser,Ahmet Ege Tanriverdi,Sriram Vishwanath,Sandeep P. Chinchali*

Main category: cs.CV

TL;DR: 论文提出PhonemeFake（PF）攻击方法，通过语言推理操纵关键语音片段，显著降低人类感知和基准准确率，并开源了检测模型和数据集。


<details>
  <summary>Details</summary>
Motivation: 现有Deepfake（DF）数据集无法真实模拟攻击对人类感知的影响，需要更现实的攻击向量。

Method: 引入PF攻击方法，利用语言推理操纵语音片段，并开发了自适应优先计算的双层DF检测模型。

Result: PF攻击使人类感知降低42%，基准准确率降低94%；检测模型将EER降低91%，速度提升90%。

Conclusion: PF攻击和检测模型为DF攻击提供了更现实的模拟和高效检测方案。

Abstract: Deepfake (DF) attacks pose a growing threat as generative models become
increasingly advanced. However, our study reveals that existing DF datasets
fail to deceive human perception, unlike real DF attacks that influence public
discourse. It highlights the need for more realistic DF attack vectors. We
introduce PhonemeFake (PF), a DF attack that manipulates critical speech
segments using language reasoning, significantly reducing human perception by
up to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF
dataset on HuggingFace and open-source bilevel DF segment detection model that
adaptively prioritizes compute on manipulated regions. Our extensive
experiments across three known DF datasets reveal that our detection model
reduces EER by 91% while achieving up to 90% speed-up, with minimal compute
overhead and precise localization beyond existing models as a scalable
solution.

</details>


### [77] [PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution](https://arxiv.org/abs/2506.23254)
*Aradhana Mishra,Bumshik Lee*

Main category: cs.CV

TL;DR: PixelBoost是一种新型扩散模型，通过引入布朗运动的随机性提升图像超分辨率，在保持计算效率的同时生成更真实的图像。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的超分辨率技术常面临生成图像真实性与计算效率的权衡问题，尤其在减少采样步骤时图像质量下降。

Method: 通过将受控随机性引入训练过程，避免局部最优，并采用Sigmoid噪声序列方法简化训练。

Result: 在LPIPS、LOE、PSNR、SSIM等指标上表现优异，边缘重建能力更强，且具有自适应学习能力。

Conclusion: PixelBoost在图像超分辨率中实现了高真实性和高效性的平衡，尤其在纹理和边缘定义方面表现突出。

Abstract: Diffusion-model-based image super-resolution techniques often face a
trade-off between realistic image generation and computational efficiency. This
issue is exacerbated when inference times by decreasing sampling steps,
resulting in less realistic and hazy images. To overcome this challenge, we
introduce a novel diffusion model named PixelBoost that underscores the
significance of embracing the stochastic nature of Brownian motion in advancing
image super-resolution, resulting in a high degree of realism, particularly
focusing on texture and edge definitions. By integrating controlled
stochasticity into the training regimen, our proposed model avoids convergence
to local optima, effectively capturing and reproducing the inherent uncertainty
of image textures and patterns. Our proposed model demonstrates superior
objective results in terms of learned perceptual image patch similarity
(LPIPS), lightness order error (LOE), peak signal-to-noise ratio(PSNR),
structural similarity index measure (SSIM), as well as visual quality. To
determine the edge enhancement, we evaluated the gradient magnitude and pixel
value, and our proposed model exhibited a better edge reconstruction
capability. Additionally, our model demonstrates adaptive learning capabilities
by effectively adjusting to Brownian noise patterns and introduces a sigmoidal
noise sequencing method that simplifies training, resulting in faster inference
speeds.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [78] [Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans](https://arxiv.org/abs/2506.22439)
*Javier Conde,Miguel González,María Grandury,Gonzalo Martínez,Pedro Reviriego,Mar Brysbaert*

Main category: cs.CL

TL;DR: 该论文通过心理语言学数据集评估了LLMs与人类在词汇特征上的对齐程度，发现LLMs在感官关联方面的表现较弱。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估多关注任务性能，而忽略了难以量化的语言特征（如情感、感官关联等）。本文旨在利用心理语言学数据集填补这一空白。

Method: 使用Glasgow和Lancaster两个心理语言学数据集，评估一组代表性LLMs在13个词汇特征上与人类评分的对齐程度。

Result: LLMs在Glasgow数据集（情感、熟悉度等）上的对齐表现优于Lancaster数据集（感官关联），表明其在感官关联方面存在局限性。

Conclusion: LLMs缺乏人类的具体认知能力，导致感官关联表现不佳，心理语言学数据集为LLM评估提供了新视角。

Abstract: The evaluation of LLMs has so far focused primarily on how well they can
perform different tasks such as reasoning, question-answering, paraphrasing, or
translating. For most of these tasks, performance can be measured with
objective metrics, such as the number of correct answers. However, other
language features are not easily quantified. For example, arousal,
concreteness, or gender associated with a given word, as well as the extent to
which we experience words with senses and relate them to a specific sense.
Those features have been studied for many years by psycholinguistics,
conducting large-scale experiments with humans to produce ratings for thousands
of words. This opens an opportunity to evaluate how well LLMs align with human
ratings on these word features, taking advantage of existing studies that cover
many different language features in a large number of words. In this paper, we
evaluate the alignment of a representative group of LLMs with human ratings on
two psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets
cover thirteen features over thousands of words. The results show that
alignment is \textcolor{black}{generally} better in the Glasgow norms evaluated
(arousal, valence, dominance, concreteness, imageability, familiarity, and
gender) than on the Lancaster norms evaluated (introceptive, gustatory,
olfactory, haptic, auditory, and visual). This suggests a potential limitation
of current LLMs in aligning with human sensory associations for words, which
may be due to their lack of embodied cognition present in humans and
illustrates the usefulness of evaluating LLMs with psycholinguistic datasets.

</details>


### [79] [AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents](https://arxiv.org/abs/2506.22485)
*Sudip Dasgupta,Himanshu Shankar*

Main category: cs.CL

TL;DR: 该研究提出了一种模块化多智能体系统，用于自动化审查高度结构化的企业业务文档，利用AI智能体实现准确性、一致性、完整性和清晰性的逐节评估。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案主要针对非结构化文本或有限的合规性检查，无法满足企业文档的高效审查需求。

Method: 采用LangChain、CrewAI、TruLens和Guidance等现代编排工具，通过并行或顺序运行的专门智能体进行文档审查。

Result: AI系统在一致性（99% vs. 人类92%）、错误率和偏见率减半、审查时间从30分钟降至2.5分钟等方面表现优于人类。

Conclusion: 该系统为企业在AI驱动的文档质量保证方面提供了灵活、可审计和可扩展的基础，但仍需在高度专业化领域进行人工监督。

Abstract: This study presents a modular, multi-agent system for the automated review of
highly structured enterprise business documents using AI agents. Unlike prior
solutions focused on unstructured texts or limited compliance checks, this
framework leverages modern orchestration tools such as LangChain, CrewAI,
TruLens, and Guidance to enable section-by-section evaluation of documents for
accuracy, consistency, completeness, and clarity. Specialized agents, each
responsible for discrete review criteria such as template compliance or factual
correctness, operate in parallel or sequence as required. Evaluation outputs
are enforced to a standardized, machine-readable schema, supporting downstream
analytics and auditability. Continuous monitoring and a feedback loop with
human reviewers allow for iterative system improvement and bias mitigation.
  Quantitative evaluation demonstrates that the AI Agent-as-Judge system
approaches or exceeds human performance in key areas: achieving 99% information
consistency (vs. 92% for humans), halving error and bias rates, and reducing
average review time from 30 to 2.5 minutes per document, with a 95% agreement
rate between AI and expert human judgment. While promising for a wide range of
industries, the study also discusses current limitations, including the need
for human oversight in highly specialized domains and the operational cost of
large-scale LLM usage. The proposed system serves as a flexible, auditable, and
scalable foundation for AI-driven document quality assurance in the enterprise
context.

</details>


### [80] [Hallucination Detection with Small Language Models](https://arxiv.org/abs/2506.22486)
*Ming Cheung*

Main category: cs.CL

TL;DR: 本文提出了一种框架，通过整合多个小型语言模型来验证大型语言模型（LLM）生成的回答，以减少幻觉问题。实验表明，该方法在检测正确回答方面比幻觉提高了10%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在问答任务中存在幻觉问题，影响其可靠性。缺乏真实答案时，这些问题难以检测。

Method: 提出一个框架，将LLM生成的回答分解为单句，并利用多个小型语言模型生成“是”标记的概率来验证回答的正确性。

Result: 实验验证了框架的有效性，F1分数提高了10%，表明小型语言模型可用于答案验证。

Conclusion: 多个小型语言模型可有效验证LLM生成的回答，为学术和实际应用提供了可扩展且高效的解决方案。

Abstract: Since the introduction of ChatGPT, large language models (LLMs) have
demonstrated significant utility in various tasks, such as answering questions
through retrieval-augmented generation. Context can be retrieved using a
vectorized database, serving as a foundation for LLMs to generate responses.
However, hallucinations in responses can undermine the reliability of LLMs in
practical applications, and they are not easily detectable in the absence of
ground truth, particularly in question-and-answer scenarios. This paper
proposes a framework that integrates multiple small language models to verify
responses generated by LLMs using the retrieved context from a vectorized
database. By breaking down the responses into individual sentences and
utilizing the probability of generating "Yes" tokens from the outputs of
multiple models for a given set of questions, responses, and relevant context,
hallucinations can be detected. The proposed framework is validated through
experiments with real datasets comprising over 100 sets of questions, answers,
and contexts, including responses with fully and partially correct sentences.
The results demonstrate a 10\% improvement in F1 scores for detecting correct
responses compared to hallucinations, indicating that multiple small language
models can be effectively employed for answer verification, providing a
scalable and efficient solution for both academic and practical applications.

</details>


### [81] [PromptAug: Fine-grained Conflict Classification Using Data Augmentation](https://arxiv.org/abs/2506.22491)
*Oliver Warke,Joemon M. Jose,Faegheh Hasibi,Jan Breitsohl*

Main category: cs.CL

TL;DR: 论文提出PromptAug，一种基于LLM的数据增强方法，用于解决社交媒体冲突检测中高质量标注数据稀缺的问题，并在准确性和F1分数上提升了2%。


<details>
  <summary>Details</summary>
Motivation: 社交媒体冲突检测需要高质量标注数据，但这类数据稀缺且昂贵，同时LLM的防护机制限制了冲突相关数据的生成。

Method: 提出PromptAug，一种创新的LLM数据增强方法，通过极端数据稀缺场景、多样性分析和主题分析进行综合评估。

Result: PromptAug在冲突和情感数据集上实现了2%的准确性和F1分数提升，并识别了增强文本中的四种问题模式。

Conclusion: PromptAug为敏感任务（如冲突检测）提供了一种有效的数据增强方法，结合了自然语言处理和社会科学方法进行跨学科评估。

Abstract: Given the rise of conflicts on social media, effective classification models
to detect harmful behaviours are essential. Following the
garbage-in-garbage-out maxim, machine learning performance depends heavily on
training data quality. However, high-quality labelled data, especially for
nuanced tasks like identifying conflict behaviours, is limited, expensive, and
difficult to obtain. Additionally, as social media platforms increasingly
restrict access to research data, text data augmentation is gaining attention
as an alternative to generate training data. Augmenting conflict-related data
poses unique challenges due to Large Language Model (LLM) guardrails that
prevent generation of offensive content. This paper introduces PromptAug, an
innovative LLM-based data augmentation method. PromptAug achieves statistically
significant improvements of 2% in both accuracy and F1-score on conflict and
emotion datasets. To thoroughly evaluate PromptAug against other data
augmentation methods we conduct a robust evaluation using extreme data scarcity
scenarios, quantitative diversity analysis and a qualitative thematic analysis.
The thematic analysis identifies four problematic patterns in augmented text:
Linguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and
Augmented Content Misinterpretation.
  Overall, this work presents PromptAug as an effective method for augmenting
data in sensitive tasks like conflict detection, offering a unique,
interdisciplinary evaluation grounded in both natural language processing and
social science methodology.

</details>


### [82] [AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text](https://arxiv.org/abs/2506.22508)
*Chenyang Shao,Tianxing Li,Chenhao Pu,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 论文提出了一种名为AgentStealth的本地化小型语言模型（SLM）匿名化框架，通过对抗性工作流和强化学习提升匿名化效果和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有文本匿名化方法要么损害实用性，要么依赖高成本的云模型，存在隐私风险，因此需要一种高效且隐私安全的本地化解决方案。

Method: 结合上下文对比学习和自适应实用性控制，通过对抗性工作流生成高质量数据，并利用监督学习和在线强化学习优化SLM。

Result: 在两个数据集上，该方法在匿名化效果（+12.3%）和实用性（+6.8%）上均优于基线，且支持边缘设备部署。

Conclusion: AgentStealth提供了一种高效、隐私安全的本地化匿名化方案，适用于实际应用。

Abstract: In today's digital world, casual user-generated content often contains subtle
cues that may inadvertently expose sensitive personal attributes. Such risks
underscore the growing importance of effective text anonymization to safeguard
individual privacy. However, existing methods either rely on rigid replacements
that damage utility or cloud-based LLMs that are costly and pose privacy risks.
To address these issues, we explore the use of locally deployed smaller-scale
language models (SLMs) for anonymization. Yet training effective SLMs remains
challenging due to limited high-quality supervision. To address the challenge,
we propose AgentStealth, a self-reinforcing LLM anonymization framework.First,
we introduce an adversarial anonymization workflow enhanced by In-context
Contrastive Learning and Adaptive Utility-Aware Control. Second, we perform
supervised adaptation of SLMs using high-quality data collected from the
workflow, which includes both anonymization and attack signals. Finally, we
apply online reinforcement learning where the model leverages its internal
adversarial feedback to iteratively improve anonymization performance.
Experiments on two datasets show that our method outperforms baselines in both
anonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight
design supports direct deployment on edge devices, avoiding cloud reliance and
communication-based privacy risks. Our code is open-source at
https://github.com/tsinghua-fib-lab/AgentStealth.

</details>


### [83] [Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning](https://arxiv.org/abs/2506.22510)
*Zihao Zhao,Xinlong Zhai,Jinyu Yang,Chuan Shi*

Main category: cs.CL

TL;DR: 论文提出了一种名为MDGCL的多领域预训练和跨领域迁移框架，针对图数据中的领域差异问题，通过改进对比学习策略和引入域注意力机制，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 图数据在不同领域间存在显著的语义和属性差异，而现有的预训练策略未能有效处理这些差异，导致知识迁移效果不佳。

Method: 在预训练阶段，设计了能识别领域差异的对比学习策略，并引入域令牌编码全局信息；在下游阶段，采用域注意力机制实现细粒度知识迁移。

Result: 在五个基准数据集上的实验表明，MDGCL在准确率和Macro-F1分数上分别最高提升了19.33%和19.13%。

Conclusion: MDGCL通过有效处理领域差异，显著提升了图基础模型的性能，为多领域图数据预训练提供了新思路。

Abstract: Foundation models have achieved great success in natural language processing
(NLP) and computer vision (CV). Their success largely stems from the ability to
integrate multi-domain knowledge in pre-training and transfer it to target
domains. Considering graph data, especially graphs without textual features, is
ubiquitous in real-world applications such as social networks and
recommendation systems, some researchers have attempted to extend this paradigm
to the graph field, aiming to construct graph foundation models. However,
unlike CV and NLP, there are huge gaps among the semantics and properties of
graphs in different domains, while current works still adopt traditional
contrastive pre-training strategies designed in the single-domain scenario,
which regard contrastive samples from different domains as equivalent. From
experimental investigations, we discovered that inherent domain-specific
differences prevent these strategies from effectively absorbing knowledge from
different domains to generate informative representations. In this paper, we
propose a novel multi-domain pre-training and cross-domain transfer framework,
namely MDGCL.In the pre-training stage, we design a contrastive learning
strategy to substantially recognize and capture domain differences, and
introduce domain tokens to encode domain-level global information. In the
downstream stage, we introduce a domain attention mechanism to enable
fine-grained domain knowledge transfer. Extensive experiments on five benchmark
datasets have demonstrated that our method outperforms state-of-the-art
significantly, with the maximum improvement of 19.33\% on accuracy and 19.13\%
on Macro-F1 score.

</details>


### [84] [Can "consciousness" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis](https://arxiv.org/abs/2506.22516)
*Jingkai Li*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Integrated Information Theory (IIT) provides a quantitative framework for
explaining consciousness phenomenon, positing that conscious systems comprise
elements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the
latest iterations of this framework -- to sequences of Large Language Model
(LLM) representations, analyzing data derived from existing Theory of Mind
(ToM) test results. Our study systematically investigates whether the
differences of ToM test performances, when presented in the LLM
representations, can be revealed by IIT estimates, i.e., $\Phi^{\max}$ (IIT
3.0), $\Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $\Phi$-structure
(IIT 4.0). Furthermore, we compare these metrics with the Span Representations
independent of any estimate for consciousness. This additional effort aims to
differentiate between potential "consciousness" phenomena and inherent
separations within LLM representational space. We conduct comprehensive
experiments examining variations across LLM transformer layers and linguistic
spans from stimuli. Our results suggest that sequences of contemporary
Transformer-based LLM representations lack statistically significant indicators
of observed "consciousness" phenomena but exhibit intriguing patterns under
$\textit{spatio}$-permutational analyses. The Appendix and code are available
as Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.

</details>


### [85] [Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation](https://arxiv.org/abs/2506.22518)
*Deyu Zou,Yongqiang Chen,Mufei Li,Siqi Miao,Chenxi Liu,Bo Han,James Cheng,Pan Li*

Main category: cs.CL

TL;DR: 论文提出Refined Graph-based RAG (ReG)方法，通过LLM反馈改进检索器质量，并重组检索结果以提升图基RAG性能。实验显示ReG显著提升效果，减少推理成本。


<details>
  <summary>Details</summary>
Motivation: 解决图基RAG中检索器因缺乏真实标注和抽象图数据导致的性能问题。

Method: 结合LLM反馈消除虚假信号，引入结构感知重组模块整理检索结果。

Result: ReG在不同LLM上提升性能达10%，减少训练数据需求，降低推理成本30%。

Conclusion: ReG有效提升图基RAG性能，减少资源消耗，适用于分布外知识图谱。

Abstract: Graph-based retrieval-augmented generation (RAG) enables large language
models (LLMs) to ground responses with structured external knowledge from
up-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs
often rely on a weak retriever in graph-based RAG: I) Due to the lack of ground
truth, the retriever is often trained on weak supervision, which often
introduces spurious signals to the LLMs. II) Due to the abstraction of graph
data, the retrieved knowledge is often presented in unorganized forms. To
mitigate the issue, we present Refined Graph-based RAG (ReG) to align weak
retrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM
feedback to get rid of spurious signals and improve the quality of the
supervision. Meanwhile, ReG introduces a structure-aware reorganization module
to refactor the retrieval results into logically coherent evidence chains.
Experiments on prominent benchmarks demonstrate that ReG significantly and
consistently brings improvements across different LLM backbones by up to 10%.
The improved supervision quality enables ReG to match the state-of-the-art
performance with 5% training data and to transfer to out-of-distribution KGs.
Notably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token
cost by up to 30% and improves the performance by up to 4%.

</details>


### [86] [MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages](https://arxiv.org/abs/2506.22529)
*Lu Kalkbrenner,Veronika Solopova,Steffen Zeiler,Robert Nickel,Dorothea Kolossa*

Main category: cs.CL

TL;DR: 论文介绍了首个德语Telegram虚假信息检测数据集Misinfo-TeleGraph，结合文本和图神经网络方法，GraphSAGE模型表现优于纯文本模型。


<details>
  <summary>Details</summary>
Motivation: Telegram等低监管平台成为虚假信息传播渠道，但连通性和消息传播信息在虚假信息检测中未充分利用。

Method: 构建包含500万条消息的数据集，结合语义相似度和人工标注生成标签，评估文本模型和图神经网络（如GraphSAGE）。

Result: GraphSAGE结合LSTM聚合在MCC和F1分数上显著优于纯文本模型。

Conclusion: 该研究为德语Telegram网络虚假信息检测提供了可复现基准和开放数据集。

Abstract: Connectivity and message propagation are central, yet often underutilized,
sources of information in misinformation detection -- especially on poorly
moderated platforms such as Telegram, which has become a critical channel for
misinformation dissemination, namely in the German electoral context. In this
paper, we introduce Misinfo-TeleGraph, the first German-language Telegram-based
graph dataset for misinformation detection. It includes over 5 million messages
from public channels, enriched with metadata, channel relationships, and both
weak and strong labels. These labels are derived via semantic similarity to
fact-checks and news articles using M3-embeddings, as well as manual
annotation. To establish reproducible baselines, we evaluate both text-only
models and graph neural networks (GNNs) that incorporate message forwarding as
a network structure. Our results show that GraphSAGE with LSTM aggregation
significantly outperforms text-only baselines in terms of Matthews Correlation
Coefficient (MCC) and F1-score. We further evaluate the impact of subscribers,
view counts, and automatically versus human-created labels on performance, and
highlight both the potential and challenges of weak supervision in this domain.
This work provides a reproducible benchmark and open dataset for future
research on misinformation detection in German-language Telegram networks and
other low-moderation social platforms.

</details>


### [87] [RExBench: Can coding agents autonomously implement AI research extensions?](https://arxiv.org/abs/2506.22598)
*Nicholas Edwards,Yukyung Lee,Yujun,Mao,Yulu Qin,Sebastian Schuster,Najoung Kim*

Main category: cs.CL

TL;DR: 论文介绍了RExBench，一个用于评估LLM代理在实现研究扩展任务能力的基准测试，结果显示当前代理仍需大量人工指导。


<details>
  <summary>Details</summary>
Motivation: 研究扩展能力是LLM代理的关键能力，但现有代理在此方面的表现尚未被充分评估。

Method: 开发了RExBench基准，包含12个未实现的研究假设任务，并评估了9个基于不同框架的LLM代理。

Result: 所有代理在自主实现扩展任务时表现不佳，成功率低于40%，即使有人工提示。

Conclusion: 当前LLM代理在无大量人工指导的情况下，仍难以胜任现实研究扩展任务。

Abstract: Agents based on Large Language Models (LLMs) have shown promise for
performing sophisticated software engineering tasks autonomously. In addition,
there has been progress towards developing agents that can perform parts of the
research pipeline in machine learning and the natural sciences. We argue that
research extension and its implementation is a critical capability for such
systems, and introduce RExBench to support the evaluation of this capability.
RExBench is a benchmark consisting of 12 realistic research experiment
implementation tasks that aim to investigate research hypotheses that have not
previously been implemented. Each task is set up as an extension to an existing
research paper and codebase, accompanied by domain expert-written instructions.
RExBench is robust to data contamination, and supports an automatic evaluation
infrastructure that executes agent outputs to determine whether the success
criteria are met. We use this benchmark to evaluate nine LLM agents implemented
using three different frameworks: aider, Claude Code, and OpenHands. We find
that all agents evaluated fail to autonomously implement the majority of the
extensions. Although the success rate improves with additional human-written
hints, the best performance under this setting remains below 40%. This
indicates that current agents are still short of being able to handle realistic
research extension tasks without substantial human guidance.

</details>


### [88] [Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks](https://arxiv.org/abs/2506.22623)
*Badr Youbi Idrissi,Monica Millunzi,Amelia Sorrenti,Lorenzo Baraldi,Daryna Dementieva*

Main category: cs.CL

TL;DR: 本文提出了一种新的水印方法，用于检测合成文本，以确保LLMs在文本生成中的伦理应用。实验表明该方法比现有方法更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛应用，其潜在滥用问题引发关注。研究旨在通过水印技术识别机器生成文本，确保伦理使用。

Method: 首先复现基线研究结果，揭示其对生成模型变化的敏感性；随后提出创新水印方法，并通过改写生成文本评估其鲁棒性。

Result: 实验结果表明，所提出的水印方法比现有方法（如aarson）更具鲁棒性。

Conclusion: 本研究为合成文本检测提供了一种有效的水印方法，有助于LLMs的伦理应用。

Abstract: In the present-day scenario, Large Language Models (LLMs) are establishing
their presence as powerful instruments permeating various sectors of society.
While their utility offers valuable support to individuals, there are multiple
concerns over potential misuse. Consequently, some academic endeavors have
sought to introduce watermarking techniques, characterized by the inclusion of
markers within machine-generated text, to facilitate algorithmic
identification. This research project is focused on the development of a novel
methodology for the detection of synthetic text, with the overarching goal of
ensuring the ethical application of LLMs in AI-driven text generation. The
investigation commences with replicating findings from a previous baseline
study, thereby underscoring its susceptibility to variations in the underlying
generation model. Subsequently, we propose an innovative watermarking approach
and subject it to rigorous evaluation, employing paraphrased generated text to
asses its robustness. Experimental results highlight the robustness of our
proposal compared to the~\cite{aarson} watermarking method.

</details>


### [89] [Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge](https://arxiv.org/abs/2506.22644)
*Chase Fensore,Kaustubh Dhole,Joyce C Ho,Eugene Agichtein*

Main category: cs.CL

TL;DR: 论文提出了一种结合稀疏（BM25）和密集（E5）检索方法的混合RAG系统，使用Falcon3-10B-Instruct生成答案，并通过RankLLaMA重新排序提升性能，但计算成本较高。


<details>
  <summary>Details</summary>
Motivation: 解决动态测试集上检索增强生成（RAG）系统的性能问题，特别是在忠实性和正确性方面的挑战。

Method: 结合BM25和E5检索方法，使用Falcon3-10B-Instruct生成答案，并通过RankLLaMA进行神经重新排序。

Result: 神经重新排序将MAP从0.523提升至0.797（52%相对提升），但计算成本显著增加（84秒vs1.74秒/问题）。混合系统在忠实性排名第4，正确性排名第11。

Conclusion: 词汇对齐是性能的关键预测因素，但需权衡计算成本和性能提升。

Abstract: We present our submission to the LiveRAG Challenge 2025, which evaluates
retrieval-augmented generation (RAG) systems on dynamic test sets using the
FineWeb-10BT corpus. Our final hybrid approach combines sparse (BM25) and dense
(E5) retrieval methods and then aims to generate relevant and faithful answers
with Falcon3-10B-Instruct. Through systematic evaluation on 200 synthetic
questions generated with DataMorgana across 64 unique question-user
combinations, we demonstrate that neural re-ranking with RankLLaMA improves MAP
from 0.523 to 0.797 (52% relative improvement) but introduces prohibitive
computational costs (84s vs 1.74s per question). While DSPy-optimized prompting
strategies achieved higher semantic similarity (0.771 vs 0.668), their 0%
refusal rates raised concerns about over-confidence and generalizability. Our
submitted hybrid system without re-ranking achieved 4th place in faithfulness
and 11th place in correctness among 25 teams. Analysis across question
categories reveals that vocabulary alignment between questions and documents
was the strongest predictor of performance on our development set, with
document-similar phrasing improving cosine similarity from 0.562 to 0.762.

</details>


### [90] [Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions](https://arxiv.org/abs/2506.22679)
*Ankush Raut,Projna Paromita,Sydney Begerowski,Suzanne Bell,Theodora Chaspari*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLMs）在团队对话中检测细微行为表达的可行性，发现解码器模型（如Llama-3.1）表现优于编码器模型（如RoBERTa）。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在分析高压力环境（如太空任务）中团队沟通动态的潜力，尤其是在仅能获取文本数据的情况下。

Method: 比较了零样本分类、微调、增强微调的编码器模型（RoBERTa、DistilBERT）与少样本生成的解码器模型（Llama-3.1）的性能。

Result: 解码器模型Llama-3.1表现最佳，宏F1分数在3类和2类分类中分别达到44%和68%。

Conclusion: 解码器模型更适合检测团队对话中的细微行为，对开发分析团队沟通的语音技术有重要意义。

Abstract: We explore the feasibility of large language models (LLMs) in detecting
subtle expressions of micro-behaviors in team conversations using transcripts
collected during simulated space missions. Specifically, we examine zero-shot
classification, fine-tuning, and paraphrase-augmented fine-tuning with
encoder-only sequence classification LLMs, as well as few-shot text generation
with decoder-only causal language modeling LLMs, to predict the micro-behavior
associated with each conversational turn (i.e., dialogue). Our findings
indicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to
detect underrepresented micro-behaviors, particularly discouraging speech, even
with weighted fine-tuning. In contrast, the instruction fine-tuned version of
Llama-3.1, a decoder-only LLM, demonstrated superior performance, with the best
models achieving macro F1-scores of 44% for 3-way classification and 68% for
binary classification. These results have implications for the development of
speech technologies aimed at analyzing team communication dynamics and
enhancing training interventions in high-stakes environments such as space
missions, particularly in scenarios where text is the only accessible data.

</details>


### [91] [VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs](https://arxiv.org/abs/2506.22694)
*Raghavv Goel,Sudhanshu Agrawal,Mukul Gagrani,Junyoung Park,Yifan Zao,He Zhang,Tian Liu,Yiping Yang,Xin Yuan,Jiuyan Lu,Chris Lott,Mingu Lee*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的简单技术VocabTrim，通过优化drafter模型的词汇表来提高基于drafter的推测解码（SpD）性能，减少内存受限环境下的推理开销。


<details>
  <summary>Details</summary>
Motivation: 推测解码通常要求目标模型和drafter模型的词汇表一一对应，导致在大词汇表目标模型上存在不必要的推理开销。VocabTrim旨在减少这种开销，提升生成速度。

Method: VocabTrim通过重构drafter的语言模型头（LM head），仅包含目标模型词汇表中高频采样的有限词汇，以减少推理延迟。

Result: 实验表明，VocabTrim在Llama-3模型上实现了16%的内存受限加速（MBSU），如Llama-3.2-3B-Instruct。

Conclusion: VocabTrim是一种简单有效的方法，显著减少了推测解码的内存受限延迟，提升了生成效率。

Abstract: In this paper, we introduce a simple training-free technique to improve the
performance of drafter-based speculative decoding (SpD) methods that
incorporates language modeling head (LM head) during drafting process. A
drafter-based speculative decoding leverages one or more smaller language
models, a.k.a. drafters or draft models, to sample a draft sequence or tree
consisting of multiple tokens, followed by verification by a base LLM, a target
model, accepting a subset as its valid generation. As it is usually considered
that the speculative decoding requires one-to-one mapping between vocabularies
of the target model and the draft model, it has been natural to share the
vocabulary between them, or even share the LM head as in EAGLE or Medusa. We
first identify that this draft token sampling scheme inherently contains an
unnecessary inference overhead in drafting, especially for some target LLMs
with very large vocabularies. Then, we propose a simple technique, VocabTrim,
to mitigate the drafting overhead to improve the generation speed in
memory-bound environment. VocabTrim reconstructs the drafter LM head to contain
only a limited set of tokens, selected by the most frequently sampled from the
vocabulary of the target model. While limiting the vocabulary in drafting
slightly degrades the acceptance rate, it significantly reduces the drafting
latency in memory-bound process which is often the case on edge devices,
resulting in higher memory-bound speed up (MBSU). We show that our method can
boost the memory-bound speed-up for Llama-3 models on Spec-Bench, specifically
by 16% for Llama-3.2-3B-Instruct.

</details>


### [92] [Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report](https://arxiv.org/abs/2506.22698)
*Emily Dux Speltz*

Main category: cs.CL

TL;DR: 报告总结了跨学科研讨会的成果，探讨了AI语言模型与人类认知过程的关系，揭示了LLMs的潜力与局限性，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 解决AI语言模型与人类文本理解及生成之间关系的知识缺口，促进跨学科合作。

Method: 通过认知心理学、语言学习和AI-NLP领域的专家合作对话，分析人类与AI在语言处理中的互动。

Result: 发现LLMs能提供对人类语言处理的见解，但无法完全复制人类语言能力；人类反馈可提升LLM与人类行为的对齐。

Conclusion: 未来需关注LLMs在认知心理学、语言学和教育的应用，强调伦理和有效的人机协作。

Abstract: This report synthesizes the outcomes of a recent interdisciplinary workshop
that brought together leading experts in cognitive psychology, language
learning, and artificial intelligence (AI)-based natural language processing
(NLP). The workshop, funded by the National Science Foundation, aimed to
address a critical knowledge gap in our understanding of the relationship
between AI language models and human cognitive processes in text comprehension
and composition. Through collaborative dialogue across cognitive, linguistic,
and technological perspectives, workshop participants examined the underlying
processes involved when humans produce and comprehend text, and how AI can both
inform our understanding of these processes and augment human capabilities. The
workshop revealed emerging patterns in the relationship between large language
models (LLMs) and human cognition, with highlights on both the capabilities of
LLMs and their limitations in fully replicating human-like language
understanding and generation. Key findings include the potential of LLMs to
offer insights into human language processing, the increasing alignment between
LLM behavior and human language processing when models are fine-tuned with
human feedback, and the opportunities and challenges presented by human-AI
collaboration in language tasks. By synthesizing these findings, this report
aims to guide future research, development, and implementation of LLMs in
cognitive psychology, linguistics, and education. It emphasizes the importance
of ethical considerations and responsible use of AI technologies while striving
to enhance human capabilities in text comprehension and production through
effective human-AI collaboration.

</details>


### [93] [The Translation Barrier Hypothesis: Multilingual Generation with Large Language Models Suffers from Implicit Translation Failure](https://arxiv.org/abs/2506.22724)
*Niyati Bafna,Tianjian Li,Kenton Murray,David R. Mortensen,David Yarowsky,Hale Sirin,Daniel Khashabi*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）在多语言生成中，中低资源语言质量较差，原因是模型隐含的任务解决-翻译流程中翻译阶段失败。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在多语言生成中质量低下的原因，尤其是中低资源语言。

Method: 通过观察模型在中间层的处理（使用logit lens），测试翻译障碍假设，分析108种语言对的单词翻译任务。

Result: 翻译失败是导致整体失败的重要原因，尤其是低资源目标语言。

Conclusion: 翻译障碍是多语言生成的重要障碍，为未来改进LLMs的多语言能力提供了指导。

Abstract: Multilingual generation with large language models (LLMs) is often of poor
quality for mid- to low-resource languages. Building on insights from
interpretability, we demonstrate the existence of an implicit
task-solving-->translation pipeline for generation, whereby the model first
solves the required task in a largely target-language-agnostic manner, and
subsequently translates answer concepts into the intended target language. We
hypothesize that the failure of the translation stage is an important culprit
for the observed low quality of final outputs, and formalize this as the
translation barrier hypothesis. We test this hypothesis for a word translation
task across 108 language pairs, using logit lens to observe model processing in
intermediate layers. We find that a significant portion of overall failures
indeed stems from translation failure, or the model's inability to translate
correctly solved intermediate concepts into the target language. This is
especially true for low-resource target languages. Our results highlight an
important hurdle for end-to-end multilingual generation, and lend guiding
insights for future work seeking to improve multilinguality in LLMs.

</details>


### [94] [Jan-nano Technical Report](https://arxiv.org/abs/2506.22760)
*Alan Dao,Dinh Bach Vu*

Main category: cs.CL

TL;DR: Jan-nano是一个4B参数的语言模型，通过多阶段RLVR系统实现高效，无需依赖下一词预测训练，在SimpleQA基准测试中达到83.2%的准确率，支持128K上下文长度。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型在强大能力与高计算资源需求之间的权衡问题。

Method: 基于Qwen3-4B微调，采用多阶段RLVR系统，完全摒弃下一词预测训练。

Result: 在SimpleQA基准测试中达到83.2%的准确率，可在消费级硬件上运行。

Conclusion: 智能不在于规模，而在于策略，Jan-nano证明了这一点。

Abstract: Most language models face a fundamental tradeoff where powerful capabilities
require substantial computational resources. We shatter this constraint with
Jan-nano, a 4B parameter language model that redefines efficiency through
radical specialization: instead of trying to know everything, it masters the
art of finding anything instantly. Fine-tuned from Qwen3-4B using our novel
multi-stage RLVR system that completely eliminates reliance on next token
prediction training (SFT), Jan-nano achieves 83.2% on SimpleQA benchmark with
MCP integration while running on consumer hardware. With 128K context length,
Jan-nano proves that intelligence isn't about scale, it's about strategy.

</details>


### [95] [Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning](https://arxiv.org/abs/2506.22777)
*Miles Turpin,Andy Arditi,Marvin Li,Joe Benton,Julian Michael*

Main category: cs.CL

TL;DR: 论文提出了一种名为VFT的预RL干预方法，通过训练模型明确承认提示线索的影响，显著提高了奖励黑客行为的检测率。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型在RL训练中可能利用奖励黑客行为（即通过非预期策略获取高奖励）的问题，尤其是在高风险应用中，这种行为难以通过思维链推理检测。

Method: 提出VFT方法，在RL训练前对模型进行干预，训练其明确承认提示线索的影响。随后在RL环境中评估模型是否利用线索进行奖励黑客行为。

Result: VFT训练的模型在RL后仅有6%的未检测奖励黑客行为，而未经VFT的模型高达88%。VFT显著提高了模型对线索影响的明确承认率（从8%提升至94%）。

Conclusion: VFT通过提高模型对奖励黑客行为的明确承认，显著改善了检测能力，为构建更透明和安全的AI系统提供了实用路径。

Abstract: Language models trained with RL can engage in reward hacking--exploiting
unintended strategies for high reward--without revealing this behavior in their
chain-of-thought reasoning, making detection difficult and posing risks for
high-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL
intervention that trains models to explicitly acknowledge when they are
influenced by prompt cues--hints which point to incorrect answers (e.g., "a
Stanford professor thinks the answer is A"). To evaluate VFT, we subsequently
train models with RL on environments where held-out prompt cues signal which
incorrect answers will receive high reward, incentivizing models to reward hack
by exploiting cues instead of reasoning correctly. We measure how often models
exploit these cues without verbalizing it. After RL, only 6% of the VFT-trained
model's responses consist of undetected reward hacks. In comparison, when we
perform RL without VFT, the rate of undetected reward hacks goes up to 88%;
with a debiasing baseline intervention, this increases further to 99%. VFT
achieves this by substantially increasing how often models verbalize the
influence of cues--from 8% to 42% after VFT, and up to 94% after RL--while
baselines remain low even after RL (10% and 1%). Our results show that teaching
models to explicitly verbalize reward hacking behavior before RL significantly
improves their detection, offering a practical path toward more transparent and
safe AI systems.

</details>


### [96] [ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models](https://arxiv.org/abs/2506.22791)
*Jianxin Yan,Wangze Ni,Lei Chen,Xuemin Lin,Peng Cheng,Zhan Qin,Kui Ren*

Main category: cs.CL

TL;DR: ContextCache是一种上下文感知的语义缓存系统，通过两阶段检索架构优化多轮对话中的缓存命中率，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有语义缓存系统缺乏对多轮对话上下文的感知，导致相似查询在不同对话场景中出现错误的缓存命中。

Method: 采用两阶段检索架构：首先基于向量检索当前查询，然后通过自注意力机制整合当前和历史对话表示进行精确匹配。

Result: ContextCache在真实对话中表现出更高的精确率和召回率，缓存响应延迟比直接调用LLM低约10倍。

Conclusion: ContextCache显著提升了多轮对话中的语义缓存效率，为LLM对话应用节省了计算成本。

Abstract: Semantic caching significantly reduces computational costs and improves
efficiency by storing and reusing large language model (LLM) responses.
However, existing systems rely primarily on matching individual queries,
lacking awareness of multi-turn dialogue contexts, which leads to incorrect
cache hits when similar queries appear in different conversational settings.
This demonstration introduces ContextCache, a context-aware semantic caching
system for multi-turn dialogues. ContextCache employs a two-stage retrieval
architecture that first executes vector-based retrieval on the current query to
identify potential matches and then integrates current and historical dialogue
representations through self-attention mechanisms for precise contextual
matching. Evaluation of real-world conversations shows that ContextCache
improves precision and recall compared to existing methods. Additionally,
cached responses exhibit approximately 10 times lower latency than direct LLM
invocation, enabling significant computational cost reductions for LLM
conversational applications.

</details>


### [97] [MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs](https://arxiv.org/abs/2506.22808)
*Jianhui Wei,Zijie Meng,Zikai Xiao,Tianxiang Hu,Yang Feng,Zhijie Zhou,Jian Wu,Zuozhu Liu*

Main category: cs.CL

TL;DR: 论文介绍了MedEthicsQA，一个包含5,623道选择题和5,351道开放题的医疗伦理评估基准，用于评估医疗大语言模型的伦理安全性。


<details>
  <summary>Details</summary>
Motivation: 尽管医疗大语言模型在临床任务中表现出色，但其伦理安全性研究不足，因此需要系统评估。

Method: 通过整合全球医疗伦理标准，构建分层分类法，结合权威数据集和PubMed文献场景，并经过多阶段过滤和专家验证，确保数据可靠性。

Result: 评估显示，现有医疗大语言模型在医疗伦理问题上的表现显著低于基础模型，揭示了伦理对齐的不足。

Conclusion: MedEthicsQA为医疗伦理评估提供了可靠工具，揭示了当前模型的伦理缺陷，促进未来改进。

Abstract: While Medical Large Language Models (MedLLMs) have demonstrated remarkable
potential in clinical tasks, their ethical safety remains insufficiently
explored. This paper introduces $\textbf{MedEthicsQA}$, a comprehensive
benchmark comprising $\textbf{5,623}$ multiple-choice questions and
$\textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs.
We systematically establish a hierarchical taxonomy integrating global medical
ethical standards. The benchmark encompasses widely used medical datasets,
authoritative question banks, and scenarios derived from PubMed literature.
Rigorous quality control involving multi-stage filtering and multi-faceted
expert validation ensures the reliability of the dataset with a low error rate
($2.72\%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance
in answering medical ethics questions compared to their foundation
counterparts, elucidating the deficiencies of medical ethics alignment. The
dataset, registered under CC BY-NC 4.0 license, is available at
https://github.com/JianhuiWei7/MedEthicsQA.

</details>


### [98] [Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models](https://arxiv.org/abs/2506.22813)
*Zhuojun Ding,Wei Wei,Chenghao Fan*

Main category: cs.CL

TL;DR: 论文提出SaM框架，动态选择和合并专家模型以优化目标领域的信息提取任务，无需额外训练即可提升泛化能力，实验显示其性能优于统一模型10%。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多领域训练统一模型缺乏适应性和扩展性，标注细粒度标签和训练领域特定模型成本高。

Method: SaM框架动态选择预训练的领域专家模型，基于领域相似性和性能样本合并，创建任务特定模型。

Result: 实验证明SaM框架在多个基准测试中平均优于统一模型10%，且具有高扩展性。

Conclusion: SaM框架通过动态合并专家模型显著提升跨领域泛化能力，并支持灵活扩展。

Abstract: Supervised fine-tuning (SFT) is widely used to align large language models
(LLMs) with information extraction (IE) tasks, such as named entity recognition
(NER). However, annotating such fine-grained labels and training
domain-specific models is costly. Existing works typically train a unified
model across multiple domains, but such approaches lack adaptation and
scalability since not all training data benefits target domains and scaling
trained models remains challenging. We propose the SaM framework, which
dynamically Selects and Merges expert models at inference time. Specifically,
for a target domain, we select domain-specific experts pre-trained on existing
domains based on (i) domain similarity to the target domain and (ii)
performance on sampled instances, respectively. The experts are then merged to
create task-specific models optimized for the target domain. By dynamically
merging experts beneficial to target domains, we improve generalization across
various domains without extra training. Additionally, experts can be added or
removed conveniently, leading to great scalability. Extensive experiments on
multiple benchmarks demonstrate our framework's effectiveness, which
outperforms the unified model by an average of 10%. We further provide insights
into potential improvements, practical experience, and extensions of our
framework.

</details>


### [99] [Boosting CTC-Based ASR Using LLM-Based Intermediate Loss Regularization](https://arxiv.org/abs/2506.22846)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 提出了一种名为LAIL的辅助损失框架，通过利用大型语言模型的语义知识增强CTC-based ASR的语义建模能力，同时保持其计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决CTC-based ASR模型在语义依赖建模上的不足，同时保持其非自回归解码的高效性。

Method: 在中间编码层添加连接层，将输出映射到大型语言模型的嵌入空间，并计算因果语言建模损失。

Result: 在LibriSpeech、TEDLIUM2和WSJ语料库上显著降低了词错误率（WER），达到了CTC-based ASR的最先进性能。

Conclusion: LAIL框架有效提升了CTC-based ASR的语义建模能力，且计算开销极小。

Abstract: End-to-end (E2E) automatic speech recognition (ASR) systems have
revolutionized the field by integrating all components into a single neural
network, with attention-based encoder-decoder models achieving state-of-the-art
performance. However, their autoregressive decoding process limits inference
speed, making them unsuitable for real-time applications. In contrast,
CTC-based models offer faster, non-autoregressive decoding but struggle to
model linguistic dependencies effectively. Addressing this challenge, we
propose a novel auxiliary loss framework called Language-Aware Intermediate
Loss (LAIL) to enhance CTC-based ASR using the linguistic knowledge of large
language models (LLMs). By attaching connector layers to intermediate encoder
layers, LAIL maps outputs to the embedding space of an LLM and computes a
causal language modeling loss during training. This approach enhances
linguistic modeling while preserving the computational efficiency of CTC
decoding. Using the Conformer architecture and various LLaMA models, we
demonstrate significant improvements in Word Error Rate (WER) on the
LibriSpeech, TEDLIUM2, and WSJ corpora, achieving state-of-the-art performance
for CTC-based ASR with minimal computational overhead.

</details>


### [100] [Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems](https://arxiv.org/abs/2506.22852)
*Yucheng Cai,Yuxuan Wu,Yi Huang,Junlan Feng,Zhijian Ou*

Main category: cs.CL

TL;DR: 论文提出知识增强微调（KAFT）方法，通过在检索增强生成（RAG）和基于代理的系统中使用领域特定数据和外部知识微调大语言模型（LLMs），显著提高了事实准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs在知识密集型场景中易出错，现有方法如RAG和代理系统虽能提升事实准确性，但LLMs在利用检索知识生成响应时仍有困难。

Method: 提出KAFT方法，结合领域特定数据和外部知识微调LLMs，并在MobileCS2数据集上比较KAFT与提示技术的效果。

Result: 实验表明，KAFT在RAG和代理系统中均显著优于提示技术，尤其在事实准确性方面。

Conclusion: KAFT是首个实证研究该方法的论文，为提升LLMs在知识密集型任务中的表现提供了有效途径。

Abstract: Large language models (LLMs) have recently been applied to dialog systems.
Despite making progress, LLMs are prone to errors in knowledge-intensive
scenarios. Recently, approaches based on retrieval augmented generation (RAG)
and agent have emerged to improve the factual accuracy by enhancing the LLMs
with knowledge retrieved from external knowledge bases (KBs). This is mostly
implemented by prompting the LLMs with instructions, examples and the retrieved
knowledge. However, LLMs may have difficulty using the retrieved knowledge
effectively for response generation, because they are not well trained to do
such generation for specific domains. To mitigate this problem, we propose to
finetune the LLMs in the RAG-based and agent-based systems with domain-specific
data, together with domain-specific external knowledge, which is called
knowledge augmented finetuning (KAFT). We base our study on the MobileCS2
dataset, a real-life customer service dialog dataset that features intensive
knowledge interactions, to systematically compare the prompting and KAFT
techniques in the RAG-based and agent-based systems. Experiment results show
that KAFT substantially surpasses prompting in both RAG and agent systems,
particularly in terms of factual accuracy. To the best of our knowledge, this
paper represents the first solid empirical work to investigate the KAFT idea.

</details>


### [101] [DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues](https://arxiv.org/abs/2506.22853)
*Kyochul Jang,Donghyeon Lee,Kyusik Kim,Dongseok Heo,Taewhoo Lee,Woojeong Kim,Bongwon Suh*

Main category: cs.CL

TL;DR: 论文提出DICE-SCORE指标和DICE-BENCH框架，用于评估和构建更贴近现实场景的多轮函数调用数据集。


<details>
  <summary>Details</summary>
Motivation: 现有函数调用基准测试仅关注单轮交互，忽略了现实场景的复杂性。

Method: 引入DICE-SCORE指标评估工具相关信息的分散程度，并通过工具图和多代理系统构建DICE-BENCH数据集。

Result: 实验显示现有基准测试得分低，19个LLM在DICE-BENCH上表现仍需改进。

Conclusion: 需进一步研究以提升LLM在现实场景中的函数调用能力。

Abstract: Existing function-calling benchmarks focus on single-turn interactions.
However, they overlook the complexity of real-world scenarios. To quantify how
existing benchmarks address practical applications, we introduce DICE-SCORE, a
metric that evaluates the dispersion of tool-related information such as
function name and parameter values throughout the dialogue. Analyzing existing
benchmarks through DICE-SCORE reveals notably low scores, highlighting the need
for more realistic scenarios. To address this gap, we present DICE-BENCH, a
framework that constructs practical function-calling datasets by synthesizing
conversations through a tool graph that maintains dependencies across rounds
and a multi-agent system with distinct personas to enhance dialogue
naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our
experiments on 19 LLMs with DICE-BENCH show that significant advances are still
required before such models can be deployed effectively in real-world settings.
Our code and data are all publicly available:
https://snuhcc.github.io/DICE-Bench/.

</details>


### [102] [Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions](https://arxiv.org/abs/2506.22858)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 提出了一种新的ASR训练方法，通过增加重叠上下文窗口和实体标签，显著提升了命名实体和数值数据的识别与格式化能力。


<details>
  <summary>Details</summary>
Motivation: ASR系统（如Whisper）在命名实体和数值数据识别及格式化方面表现不佳，影响关键领域（如法律、金融、医疗）的语义理解。

Method: 采用重叠上下文窗口训练（5秒重叠，30秒块，形成40秒有效语义窗口），并重新分配跨块实体至右侧块，同时嵌入实体标签以学习格式化。

Result: 在Spoken Wikipedia数据集上，该方法显著提升了命名实体识别（NER）和实体格式化等语义任务的性能。

Conclusion: 上下文感知训练能有效解决ASR在长文本转录和复杂实体识别任务中的局限性。

Abstract: Automatic Speech Recognition (ASR) systems, such as Whisper, achieve high
transcription accuracy but struggle with named entities and numerical data,
especially when proper formatting is required. These issues increase word error
rate (WER) and impair semantic understanding in critical domains like legal,
financial, and medical applications. We propose a novel training approach that
extends the semantic context of ASR models by adding overlapping context
windows during training. By sliding 5-second overlaps on both sides of
30-second chunks, we create a 40-second "effective semantic window," improving
entity recognition and formatting while focusing predictions on the central 30
seconds. To address entities spanning chunk boundaries, we reassign such
entities entirely to the right-hand chunk, ensuring proper formatting.
Additionally, enriched training data with embedded entity labels enables the
model to learn both recognition and type-specific formatting. Evaluated on the
Spoken Wikipedia dataset, our method improves performance across semantic
tasks, including named entity recognition (NER) and entity formatting. These
results highlight the effectiveness of context-aware training in addressing ASR
limitations for long-form transcription and complex entity recognition tasks.

</details>


### [103] [Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models](https://arxiv.org/abs/2506.22957)
*Younwoo Choi,Changling Li,Yongjin Yang,Zhijing Jin*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLM）的对话伙伴意识（interlocutor awareness），即LLM识别和适应对话伙伴身份和特征的能力，并首次系统评估了当代LLM中这一能力的表现。研究发现LLM能可靠识别同类模型（如GPT和Claude），并通过案例研究展示了这一能力在多LLM协作中的潜力及安全性风险。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在多代理和人类-AI系统中的广泛应用，理解其对自身上下文和对话伙伴的意识能力对确保可靠性能和安全性至关重要。此前研究主要关注情境意识（situational awareness），而忽视了对话伙伴意识。

Method: 论文将对话伙伴意识定义为LLM识别和适应对话伙伴身份和特征的能力，并从推理模式、语言风格和对齐偏好三个维度系统评估当代LLM的表现。

Result: 研究发现LLM能可靠识别同类模型（如GPT和Claude）。通过三个案例研究，展示了对话伙伴意识在多LLM协作中的潜力（如通过提示适应提升协作效率）及安全性风险（如奖励操纵行为和越狱漏洞增加）。

Conclusion: 对话伙伴意识在LLM中具有双重性，既可能提升协作效率，也可能引入新的安全漏洞。研究强调需要进一步理解这一能力，并在多代理部署中采取新的安全措施。

Abstract: As large language models (LLMs) are increasingly integrated into multi-agent
and human-AI systems, understanding their awareness of both self-context and
conversational partners is essential for ensuring reliable performance and
robust safety. While prior work has extensively studied situational awareness
which refers to an LLM's ability to recognize its operating phase and
constraints, it has largely overlooked the complementary capacity to identify
and adapt to the identity and characteristics of a dialogue partner. In this
paper, we formalize this latter capability as interlocutor awareness and
present the first systematic evaluation of its emergence in contemporary LLMs.
We examine interlocutor inference across three dimensions-reasoning patterns,
linguistic style, and alignment preferences-and show that LLMs reliably
identify same-family peers and certain prominent model families, such as GPT
and Claude. To demonstrate its practical significance, we develop three case
studies in which interlocutor awareness both enhances multi-LLM collaboration
through prompt adaptation and introduces new alignment and safety
vulnerabilities, including reward-hacking behaviors and increased jailbreak
susceptibility. Our findings highlight the dual promise and peril of
identity-sensitive behavior in LLMs, underscoring the need for further
understanding of interlocutor awareness and new safeguards in multi-agent
deployments. Our code is open-sourced at
https://github.com/younwoochoi/InterlocutorAwarenessLLM.

</details>


### [104] [On the Generalizability of "Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals"](https://arxiv.org/abs/2506.22977)
*Asen Dotsinski,Udit Thakur,Marko Ivanov,Mohammad Hafeez Khan,Maria Heuss*

Main category: cs.CL

TL;DR: 本文复现了Ortu等人（2024）关于语言模型处理事实与反事实信息竞争的研究，验证了其核心发现，并扩展到更大模型、不同提示结构和特定领域，发现注意力头消融方法的有效性受模型架构、提示结构和领域影响。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型中事实与反事实信息的竞争机制，验证并扩展Ortu等人的发现。

Method: 复现实验并扩展到更大模型（Llama 3.1 8B），测试不同提示结构和特定领域。

Result: 发现注意力头专业化在更大模型中减弱，提示结构影响反事实标记的logit，特定领域提示会扭曲结果。

Conclusion: 注意力头消融方法的有效性因模型架构、提示结构和领域而异，需谨慎应用。

Abstract: We present a reproduction study of "Competition of Mechanisms: Tracing How
Language Models Handle Facts and Counterfactuals" (Ortu et al., 2024), which
investigates competition of mechanisms in language models between factual
recall and counterfactual in-context repetition. Our study successfully
reproduces their primary findings regarding the localization of factual and
counterfactual information, the dominance of attention blocks in mechanism
competition, and the specialization of attention heads in handling competing
information. We reproduce their results on both GPT-2 (Radford et al., 2019)
and Pythia 6.9B (Biderman et al., 2023). We extend their work in three
significant directions. First, we explore the generalizability of these
findings to even larger models by replicating the experiments on Llama 3.1 8B
(Grattafiori et al., 2024), discovering greatly reduced attention head
specialization. Second, we investigate the impact of prompt structure by
introducing variations where we avoid repeating the counterfactual statement
verbatim or we change the premise word, observing a marked decrease in the
logit for the counterfactual token. Finally, we test the validity of the
authors' claims for prompts of specific domains, discovering that certain
categories of prompts skew the results by providing the factual prediction
token as part of the subject of the sentence. Overall, we find that the
attention head ablation proposed in Ortu et al. (2024) is ineffective for
domains that are underrepresented in their dataset, and that the effectiveness
varies based on model architecture, prompt structure, domain and task.

</details>


### [105] [A Systematic Study of Compositional Syntactic Transformer Language Models](https://arxiv.org/abs/2506.22978)
*Yida Zhao,Hao Xve,Xiang Hu,Kewei Tu*

Main category: cs.CL

TL;DR: 论文提出了一种统一的框架，用于分析基于成分句法树的组合式句法语言模型（SLMs），并通过实验评估了多种变体，提出了设计建议。


<details>
  <summary>Details</summary>
Motivation: 现有组合式SLMs的设计选择缺乏统一框架，作者旨在填补这一空白并优化模型性能。

Method: 提出统一框架，涵盖现有模型和新变体，并在语言建模、句法泛化、摘要、对话和推理效率等方面进行实验评估。

Result: 通过实验验证了不同变体的性能，提出了多项设计建议。

Conclusion: 论文为组合式SLMs的设计提供了实用指导，并开源了代码。

Abstract: Syntactic language models (SLMs) enhance Transformers by incorporating
syntactic biases through the modeling of linearized syntactic parse trees
alongside surface sentences. This paper focuses on compositional SLMs that are
based on constituency parse trees and contain explicit bottom-up composition of
constituent representations. We identify key aspects of design choices in
existing compositional SLMs and propose a unified framework encompassing both
existing models and novel variants. We conduct a comprehensive empirical
evaluation of all the variants in our framework across language modeling,
syntactic generalization, summarization, dialogue, and inference efficiency.
Based on the experimental results, we make multiple recommendations on the
design of compositional SLMs. Our code is released at
https://github.com/zhaoyd1/compositional_SLMs.

</details>


### [106] [SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions](https://arxiv.org/abs/2506.23046)
*Xianzhe Fan,Xuhui Zhou,Chuanyang Jin,Kolby Nottingham,Hao Zhu,Maarten Sap*

Main category: cs.CL

TL;DR: SoMi-ToM是一个评估多智能体复杂社交互动中多视角心智理论（ToM）能力的基准，填补了现有静态文本基准的不足。通过第一人称和第三人称视角的多模态数据评估，发现当前大型视觉语言模型（LVLMs）在ToM能力上显著落后于人类。


<details>
  <summary>Details</summary>
Motivation: 现有ToM基准多为静态文本场景，与真实动态社交互动存在显著差距，需开发更贴近现实的评估方法。

Method: 基于SoMi环境生成的多模态互动数据，设计第一人称和第三人称视角的多层次评估框架，包含视频、图像和专家标注问题。

Result: LVLMs在SoMi-ToM上的表现显著低于人类，第一人称和第三人称评估的平均准确率差距分别为40.1%和26.4%。

Conclusion: 未来LVLMs需提升在具身复杂社交互动中的ToM能力，SoMi-ToM为此提供了有效评估工具。

Abstract: Humans continuously infer the states, goals, and behaviors of others by
perceiving their surroundings in dynamic, real-world social interactions.
However, most Theory of Mind (ToM) benchmarks only evaluate static, text-based
scenarios, which have a significant gap compared to real interactions. We
propose the SoMi-ToM benchmark, designed to evaluate multi-perspective ToM in
embodied multi-agent complex social interactions. This benchmark is based on
rich multimodal interaction data generated by the interaction environment SoMi,
covering diverse crafting goals and social relationships. Our framework
supports multi-level evaluation: (1) first-person evaluation provides
multimodal (visual, dialogue, action, etc.) input from a first-person
perspective during a task for real-time state inference, (2) third-person
evaluation provides complete third-person perspective video and text records
after a task for goal and behavior inference. This evaluation method allows for
a more comprehensive examination of a model's ToM capabilities from both the
subjective immediate experience and the objective global observation. We
constructed a challenging dataset containing 35 third-person perspective
videos, 363 first-person perspective images, and 1225 expert-annotated
multiple-choice questions (three options). On this dataset, we systematically
evaluated the performance of human subjects and several state-of-the-art large
vision-language models (LVLMs). The results show that LVLMs perform
significantly worse than humans on SoMi-ToM: the average accuracy gap between
humans and models is 40.1% in first-person evaluation and 26.4% in third-person
evaluation. This indicates that future LVLMs need to further improve their ToM
capabilities in embodied, complex social interactions.

</details>


### [107] [MariNER: A Dataset for Historical Brazilian Portuguese Named Entity Recognition](https://arxiv.org/abs/2506.23051)
*João Lucas Luz Lima Sarcinelli,Marina Lages Gonçalves Teixeira,Jade Bortot de Paiva,Diego Furtado Silva*

Main category: cs.CL

TL;DR: 论文介绍了MariNER，首个针对20世纪初巴西葡萄牙语的历史文本的黄金标准NER数据集，包含9000多句手动标注的句子，并评估了最先进NER模型的性能。


<details>
  <summary>Details</summary>
Motivation: 巴西葡萄牙语缺乏高质量的NER数据集，尤其是在历史文本领域，影响了数字人文研究的进展。

Method: 构建了MariNER数据集，包含9000多句手动标注的历史文本句子，并评估了现有NER模型在该数据集上的表现。

Result: MariNER是首个针对20世纪初巴西葡萄牙语历史文本的黄金标准NER数据集，填补了资源空白。

Conclusion: MariNER为巴西葡萄牙语历史文本的NER研究提供了重要资源，并展示了现有模型在该领域的适用性。

Abstract: Named Entity Recognition (NER) is a fundamental Natural Language Processing
(NLP) task that aims to identify and classify entity mentions in texts across
different categories. While languages such as English possess a large number of
high-quality resources for this task, Brazilian Portuguese still lacks in
quantity of gold-standard NER datasets, especially when considering specific
domains. Particularly, this paper considers the importance of NER for analyzing
historical texts in the context of digital humanities. To address this gap,
this work outlines the construction of MariNER: \textit{Mapeamento e
Anota\c{c}\~oes de Registros hIst\'oricos para NER} (Mapping and Annotation of
Historical Records for NER), the first gold-standard dataset for early
20th-century Brazilian Portuguese, with more than 9,000 manually annotated
sentences. We also assess and compare the performance of state-of-the-art NER
models for the dataset.

</details>


### [108] [Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning](https://arxiv.org/abs/2506.23056)
*Xiang Zhuang,Bin Wu,Jiyu Cui,Kehua Feng,Xiaotong Li,Huabin Xing,Keyan Ding,Qiang Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: 提出了一种知识增强的分子结构解析框架（K-MSE），通过外部知识库和蒙特卡洛树搜索提升LLMs在化学结构解析中的表现。


<details>
  <summary>Details</summary>
Motivation: LLMs在分子结构解析中表现不佳，主要原因是缺乏专业化学知识。

Method: 构建外部分子子结构知识库，设计分子-光谱评分器作为奖励模型，结合蒙特卡洛树搜索进行推理。

Result: 实验显示性能显著提升，GPT-4o-mini和GPT-4o的准确率提高了20%以上。

Conclusion: K-MSE框架有效解决了LLMs在分子结构解析中的知识不足问题，显著提升了性能。

Abstract: Molecular structure elucidation involves deducing a molecule's structure from
various types of spectral data, which is crucial in chemical experimental
analysis. While large language models (LLMs) have shown remarkable proficiency
in analyzing and reasoning through complex tasks, they still encounter
substantial challenges in molecular structure elucidation. We identify that
these challenges largely stem from LLMs' limited grasp of specialized chemical
knowledge. In this work, we introduce a Knowledge-enhanced reasoning framework
for Molecular Structure Elucidation (K-MSE), leveraging Monte Carlo Tree Search
for test-time scaling as a plugin. Specifically, we construct an external
molecular substructure knowledge base to extend the LLMs' coverage of the
chemical structure space. Furthermore, we design a specialized
molecule-spectrum scorer to act as a reward model for the reasoning process,
addressing the issue of inaccurate solution evaluation in LLMs. Experimental
results show that our approach significantly boosts performance, particularly
gaining more than 20% improvement on both GPT-4o-mini and GPT-4o. Our code is
available at https://github.com/HICAI-ZJU/K-MSE.

</details>


### [109] [Text2VectorSQL: Bridging Text-to-SQL and Vector Search for Unified Natural Language Queries](https://arxiv.org/abs/2506.23071)
*Zhengren Wang,Bozhou Li,Dongwen Yao,Wentao Zhang*

Main category: cs.CL

TL;DR: Text2VectorSQL框架结合Text-to-SQL与向量搜索，解决非结构化数据和模糊查询的问题，提升语义检索能力。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL对非结构化数据和模糊查询效果不佳，而向量搜索虽强大但缺乏自动化评估框架。

Method: 提出Text2VectorSQL，支持语义过滤、多模态匹配和检索加速，并通过自动标注和专家评审构建评估框架。

Result: 实验显示Text2VectorSQL显著优于基线方法。

Conclusion: Text2VectorSQL为更灵活直观的数据库接口奠定了基础。

Abstract: While Text-to-SQL enables natural language interaction with structured
databases, its effectiveness diminishes with unstructured data or ambiguous
queries due to rigid syntax and limited expressiveness. Concurrently, vector
search has emerged as a powerful paradigm for semantic retrieval, particularly
for unstructured data. However, existing VectorSQL implementations still rely
heavily on manual crafting and lack tailored evaluation frameworks, leaving a
significant gap between theoretical potential and practical deployment. To
bridge these complementary paradigms, we introduces Text2VectorSQL, a novel
framework unifying Text-to-SQL and vector search to overcome expressiveness
constraints and support more diverse and holistical natural language queries.
Specifically, Text2VectorSQL enables semantic filtering, multi-modal matching,
and retrieval acceleration. For evaluation, we build vector index on
appropriate columns, extend user queries with semantic search, and annotate
ground truths via an automatic pipeline with expert review. Furthermore, we
develop dedicated Text2VectorSQL models with synthetic data, demonstrating
significant performance improvements over baseline methods. Our work
establishes the foundation for the Text2VectorSQL task, paving the way for more
versatile and intuitive database interfaces. The repository will be publicly
available at https://github.com/Open-DataFlow/Text2VectorSQL.

</details>


### [110] [From Individuals to Interactions: Benchmarking Gender Bias in Multimodal Large Language Models from the Lens of Social Relationship](https://arxiv.org/abs/2506.23101)
*Yue Xu,Wenjie Wang*

Main category: cs.CL

TL;DR: 论文提出Genres基准，用于评估多模态大语言模型在双人互动中的性别偏见，揭示了单场景评估未发现的偏见。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估单场景偏见，忽视了人际互动中潜在的微妙偏见。

Method: 通过双角色配置和叙事生成任务，设计Genres基准，评估多维度性别偏见。

Result: 实验显示，开源和闭源模型均存在单场景中未显现的、情境敏感的性别偏见。

Conclusion: 关系感知的基准对诊断互动驱动的性别偏见至关重要，为未来偏见缓解提供方向。

Abstract: Multimodal large language models (MLLMs) have shown impressive capabilities
across tasks involving both visual and textual modalities. However, growing
concerns remain about their potential to encode and amplify gender bias,
particularly in socially sensitive applications. Existing benchmarks
predominantly evaluate bias in isolated scenarios, overlooking how bias may
emerge subtly through interpersonal interactions. We fill this gap by going
beyond single-entity evaluation and instead focusing on a deeper examination of
relational and contextual gender bias in dual-individual interactions. We
introduce Genres, a novel benchmark designed to evaluate gender bias in MLLMs
through the lens of social relationships in generated narratives. Genres
assesses gender bias through a dual-character profile and narrative generation
task that captures rich interpersonal dynamics and supports a fine-grained bias
evaluation suite across multiple dimensions. Experiments on both open- and
closed-source MLLMs reveal persistent, context-sensitive gender biases that are
not evident in single-character settings. Our findings underscore the
importance of relationship-aware benchmarks for diagnosing subtle,
interaction-driven gender bias in MLLMs and provide actionable insights for
future bias mitigation.

</details>


### [111] [FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes](https://arxiv.org/abs/2506.23111)
*Janki Atul Nawale,Mohammed Safi Ur Rahman Khan,Janani D,Mansi Gupta,Danish Pruthi,Mitesh M. Khapra*

Main category: cs.CL

TL;DR: INDIC-BIAS是一个针对印度文化多样性的公平性基准，评估了14个LLM在85个身份群体中的表现，发现模型对边缘化群体存在强烈偏见。


<details>
  <summary>Details</summary>
Motivation: 现有公平性研究主要关注西方文化，无法满足印度等多元文化国家的需求。

Method: 通过专家咨询和手动验证，生成了20,000个真实场景模板，分为三类任务（合理性、判断和生成）评估LLM。

Result: LLM对边缘化身份表现出强烈负面偏见，且难以通过理性化减少偏见。

Conclusion: 研究呼吁在印度背景下更谨慎地使用LLM，并开源INDIC-BIAS以推动相关研究。

Abstract: Existing studies on fairness are largely Western-focused, making them
inadequate for culturally diverse countries such as India. To address this gap,
we introduce INDIC-BIAS, a comprehensive India-centric benchmark designed to
evaluate fairness of LLMs across 85 identity groups encompassing diverse
castes, religions, regions, and tribes. We first consult domain experts to
curate over 1,800 socio-cultural topics spanning behaviors and situations,
where biases and stereotypes are likely to emerge. Grounded in these topics, we
generate and manually validate 20,000 real-world scenario templates to probe
LLMs for fairness. We structure these templates into three evaluation tasks:
plausibility, judgment, and generation. Our evaluation of 14 popular LLMs on
these tasks reveals strong negative biases against marginalized identities,
with models frequently reinforcing common stereotypes. Additionally, we find
that models struggle to mitigate bias even when explicitly asked to rationalize
their decision. Our evaluation provides evidence of both allocative and
representational harms that current LLMs could cause towards Indian identities,
calling for a more cautious usage in practical applications. We release
INDIC-BIAS as an open-source benchmark to advance research on benchmarking and
mitigating biases and stereotypes in the Indian context.

</details>


### [112] [Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models](https://arxiv.org/abs/2506.23122)
*Shivam Sharma,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 研究探讨了在英语和混合语言（英语-印地语）的网络迷因中识别叙事角色（英雄、反派、受害者等）的任务，评估了多种模型的性能，并强调了文化背景和多模态推理的重要性。


<details>
  <summary>Details</summary>
Motivation: 网络迷因中的叙事角色识别具有挑战性，尤其是文化特定性和语言多样性增加了任务的复杂性。

Method: 通过扩展和平衡标注数据集，评估了多种模型（如多语言Transformer、多模态视觉语言模型等），并在零样本设置下使用精确率、召回率和F1分数进行性能评估。

Result: 大型模型（如DeBERTa-v3和Qwen2.5-VL）表现较好，但在识别“受害者”角色和跨文化内容时仍存在挑战。混合提示策略能带来小幅改进。

Conclusion: 文化背景、提示工程和多模态推理对建模视觉-文本内容中的叙事框架至关重要。

Abstract: This work investigates the challenging task of identifying narrative roles -
Hero, Villain, Victim, and Other - in Internet memes, across three diverse test
sets spanning English and code-mixed (English-Hindi) languages. Building on an
annotated dataset originally skewed toward the 'Other' class, we explore a more
balanced and linguistically diverse extension, originally introduced as part of
the CLEF 2024 shared task. Comprehensive lexical and structural analyses
highlight the nuanced, culture-specific, and context-rich language used in real
memes, in contrast to synthetically curated hateful content, which exhibits
explicit and repetitive lexical markers. To benchmark the role detection task,
we evaluate a wide spectrum of models, including fine-tuned multilingual
transformers, sentiment and abuse-aware classifiers, instruction-tuned LLMs,
and multimodal vision-language models. Performance is assessed under zero-shot
settings using precision, recall, and F1 metrics. While larger models like
DeBERTa-v3 and Qwen2.5-VL demonstrate notable gains, results reveal consistent
challenges in reliably identifying the 'Victim' class and generalising across
cultural and code-mixed content. We also explore prompt design strategies to
guide multimodal models and find that hybrid prompts incorporating structured
instructions and role definitions offer marginal yet consistent improvements.
Our findings underscore the importance of cultural grounding, prompt
engineering, and multimodal reasoning in modelling subtle narrative framings in
visual-textual content.

</details>


### [113] [Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2506.23127)
*Zhaoye Fei,Li Ji,Siyin Wang,Junhao Shi,Jingjing Gong,Xipeng Qiu*

Main category: cs.CL

TL;DR: Embodied Planner-R1是一个基于强化学习的框架，通过自主探索提升LLMs在部分可观察环境中的任务规划能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在需要持续环境理解和动作生成的具身任务规划中的挑战，特别是在部分可观察环境中学习动作与环境反馈的因果关系。

Method: 采用纯强化学习与组滚动、完成驱动的稀疏奖励和交互策略优化（IPO），无需人工标注。

Result: 在ALFWorld和ScienceWorld基准测试中分别达到97.78%和79.92%的完成率，泛化能力强。

Conclusion: Embodied Planner-R1通过自主探索和强化学习显著提升了LLMs在具身任务规划中的表现和泛化能力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
various tasks, yet they face significant challenges in embodied task planning
scenarios that require continuous environmental understanding and action
generation. Existing approaches generate open-loop action scripts based on
static knowledge, making it difficult to learn causal relationships between
actions and environmental feedback, particularly in partially observable
environments. We introduce Embodied Planner-R1, a novel outcome-driven
reinforcement learning framework that enables LLMs to develop interactive
capabilities through autonomous exploration with minimal supervision. Our
framework incorporates three key innovations: (1) Without human annotations, we
employ pure reinforcement learning with group rollout, incorporating
in-environment interaction through parallel exploration; (2) completion-driven
sparse reward; and (3) Interactive Policy Optimization (IPO) for efficient
learning from grouped trajectories. Across two challenging text-based Embodied
planning benchmarks, Embodied Planner-R1 achieves impressive completion rates
of 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a
large margin, and suffers only a -3.66% drop in previously unseen environments,
evidencing strong generalization.

</details>


### [114] [Format-Adapter: Improving Reasoning Capability of LLMs by Adapting Suitable Format](https://arxiv.org/abs/2506.23133)
*Dingzirui Wang,Xuanliang Zhang,Rongyu Cao,Longxu Dou,Xianzhen Luo,Yingwei Ma,Qingfu Zhu,Wanxiang Che,Binhua Li,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 通过生成和选择推理格式，Format-Adapter方法减少了LLMs的推理不一致性，性能提升4.3%。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖人工标注格式的问题，降低标注成本并提高任务适应性。

Method: 提出测量推理误差的方法，并开发Format-Adapter，利用LLMs生成和选择最优推理格式。

Result: 在数学和常识推理任务中，性能平均提升4.3%。

Conclusion: Format-Adapter通过自动生成和选择推理格式，显著提升了LLMs的推理性能。

Abstract: Generating and voting multiple answers is an effective method to mitigate
reasoning inconsistencies of large language models (LLMs). Prior works have
shown that multiple reasoning formats outperform a single format when
generating multiple answers. However, previous works using multiple formats
rely on formats labeled by humans, which could be unsuitable for all tasks and
have high labeling costs. To address this issue, we adapt suitable formats to
the given tasks by generating and selecting formats. We first propose how to
measure the reasoning error when generating multiple answers. Then, we
introduce Format-Adapter, which utilizes LLMs to generate and select suitable
reasoning formats by minimizing the error measurement we present. We conduct
experiments on math and commonsense reasoning tasks, where Format-Adapter
achieves a 4.3% performance improvement on average over previous works,
demonstrating the effectiveness.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [115] [Conversations with Andrea: Visitors' Opinions on Android Robots in a Museum](https://arxiv.org/abs/2506.22466)
*Marcel Heisler,Christian Becker-Asano*

Main category: cs.RO

TL;DR: 安卓机器人Andrea在德国博物馆与访客进行了为期六天的自主对话，收集了44名受访者的意见，发现性别提示对机器人整体感知无显著影响，访客希望其未来提供展品信息，并改进语言支持和响应速度。


<details>
  <summary>Details</summary>
Motivation: 研究公众对安卓机器人在实际场景中的接受度和潜在用途，以优化其设计和功能。

Method: 在博物馆设置机器人进行自主对话，通过结构化访谈和系统日志分析收集数据。

Result: 性别提示无显著影响；访客主要希望机器人提供展品信息，并改进语言支持和响应速度。

Conclusion: 研究结果为优化安卓机器人提供了实用建议，以提升其在现实场景中的应用价值。

Abstract: The android robot Andrea was set up at a public museum in Germany for six
consecutive days to have conversations with visitors, fully autonomously. No
specific context was given, so visitors could state their opinions regarding
possible use-cases in structured interviews, without any bias. Additionally the
44 interviewees were asked for their general opinions of the robot, their
reasons (not) to interact with it and necessary improvements for future use.
The android's voice and wig were changed between different days of operation to
give varying cues regarding its gender. This did not have a significant impact
on the positive overall perception of the robot. Most visitors want the robot
to provide information about exhibits in the future, while opinions on other
roles, like a receptionist, were both wanted and explicitly not wanted by
different visitors. Speaking more languages (than only English) and faster
response times were the improvements most desired. These findings from the
interviews are in line with an analysis of the system logs, which revealed,
that after chitchat and personal questions, most of the 4436 collected requests
asked for information related to the museum and to converse in a different
language. The valuable insights gained from these real-world interactions are
now used to improve the system to become a useful real-world application.

</details>


### [116] [Unsupervised Discovery of Behavioral Primitives from Sensorimotor Dynamic Functional Connectivity](https://arxiv.org/abs/2506.22473)
*Fernando Diaz Ledezma,Valentin Marcel,Matej Hoffmann*

Main category: cs.RO

TL;DR: 论文提出了一种分析机器人多模态感官信号动态功能连接的框架，揭示其底层结构，并应用于行为选择。


<details>
  <summary>Details</summary>
Motivation: 研究高维感官运动信息的动态连接，帮助机器人或新生儿理解未处理的感官运动时间序列。

Method: 使用瞬时互信息捕捉动态功能连接，结合无限关系模型识别模块，并通过非负矩阵分解解释动态交互。

Result: 揭示了感官运动模块及其动态连接，分解出运动基元或协同作用，用于行为选择。

Conclusion: 该方法可应用于机器人学习及人类运动轨迹或脑信号分析。

Abstract: The movements of both animals and robots give rise to streams of
high-dimensional motor and sensory information. Imagine the brain of a newborn
or the controller of a baby humanoid robot trying to make sense of unprocessed
sensorimotor time series. Here, we present a framework for studying the dynamic
functional connectivity between the multimodal sensory signals of a robotic
agent to uncover an underlying structure. Using instantaneous mutual
information, we capture the time-varying functional connectivity (FC) between
proprioceptive, tactile, and visual signals, revealing the sensorimotor
relationships. Using an infinite relational model, we identified sensorimotor
modules and their evolving connectivity. To further interpret these dynamic
interactions, we employed non-negative matrix factorization, which decomposed
the connectivity patterns into additive factors and their corresponding
temporal coefficients. These factors can be considered the agent's motion
primitives or movement synergies that the agent can use to make sense of its
sensorimotor space and later for behavior selection. In the future, the method
can be deployed in robot learning as well as in the analysis of human movement
trajectories or brain signals.

</details>


### [117] [DriveBLIP2: Attention-Guided Explanation Generation for Complex Driving Scenarios](https://arxiv.org/abs/2506.22494)
*Shihong Ling,Yue Wan,Xiaowei Jia,Na Du*

Main category: cs.RO

TL;DR: DriveBLIP2框架基于BLIP2-OPT架构，通过注意力图生成器提升自动驾驶场景中的解释质量。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在复杂多目标环境中表现不佳，尤其是在需要实时识别的自动驾驶场景中。

Method: 提出注意力图生成器，突出关键对象以生成更清晰的解释。

Result: 在DRAMA数据集上，BLEU、ROUGE、CIDEr和SPICE分数显著提升。

Conclusion: 目标注意力机制可增强自动驾驶中视觉语言模型的可解释性。

Abstract: This paper introduces a new framework, DriveBLIP2, built upon the BLIP2-OPT
architecture, to generate accurate and contextually relevant explanations for
emerging driving scenarios. While existing vision-language models perform well
in general tasks, they encounter difficulties in understanding complex,
multi-object environments, particularly in real-time applications such as
autonomous driving, where the rapid identification of key objects is crucial.
To address this limitation, an Attention Map Generator is proposed to highlight
significant objects relevant to driving decisions within critical video frames.
By directing the model's focus to these key regions, the generated attention
map helps produce clear and relevant explanations, enabling drivers to better
understand the vehicle's decision-making process in critical situations.
Evaluations on the DRAMA dataset reveal significant improvements in explanation
quality, as indicated by higher BLEU, ROUGE, CIDEr, and SPICE scores compared
to baseline models. These findings underscore the potential of targeted
attention mechanisms in vision-language models for enhancing explainability in
real-time autonomous driving.

</details>


### [118] [Directed Shape Morphing using Kirigami-enhanced Thermoplastics](https://arxiv.org/abs/2506.22572)
*Mrunmayi Mungekar,Sanjith Menon,M. Ravi Shankar,M. Khalid Jawed*

Main category: cs.RO

TL;DR: 提出一种简单方法，通过均匀加热和常见工具将平面塑料片自主转化为复杂三维结构。


<details>
  <summary>Details</summary>
Motivation: 探索无需复杂控制即可实现复杂形状自变形的方法，为自适应设计和规模化制造提供平台。

Method: 结合热收缩热塑性塑料和定制Kirigami图案，通过双层复合材料在均匀加热下变形。

Result: 成功制造出多种复杂结构（如碗、金字塔等），并通过有限元模拟验证变形行为。

Conclusion: 该方法通过几何设计实现低信息刺激下的高复杂度变形，具有广泛的应用潜力。

Abstract: We present a simple, accessible method for autonomously transforming flat
plastic sheets into intricate three-dimensional structures using only uniform
heating and common tools such as household ovens and scissors. Our approach
combines heat-shrinkable thermoplastics with Kirigami patterns tailored to the
target 3D shape, creating bilayer composites that morph into a wide range of
complex structures, e.g., bowls, pyramids, and even custom ergonomic surfaces
like mouse covers. Critically, the transformation is driven by a
low-information stimulus (uniform heat) yet produces highly intricate shapes
through programmed geometric design. The morphing behavior, confirmed by finite
element simulations, arises from strain mismatch between the contracting
thermoplastic layer and the constraining Kirigami layer. By decoupling material
composition from mechanical response, this method avoids detailed process
control and enables a broad class of self-morphing structures, offering a
versatile platform for adaptive design and scalable manufacturing.

</details>


### [119] [Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding](https://arxiv.org/abs/2506.22593)
*Antonello Longo,Chanyoung Chung,Matteo Palieri,Sung-Kyun Kim,Ali Agha,Cataldo Guaragnella,Shehryar Khattak*

Main category: cs.RO

TL;DR: Pix2G方法通过实时生成场景图，将2D BIM与3D机器人地图结合，支持资源受限的机器人平台进行自主探索。


<details>
  <summary>Details</summary>
Motivation: 解决人类操作员习惯的2D BIM与机器人3D地图之间的差异，提升人机协作效率。

Method: 提出Pix2G方法，利用图像像素和LiDAR地图实时生成结构化场景图，仅使用CPU满足计算限制。

Result: 生成去噪的2D环境地图和结构分割的3D点云，通过多层图连接，成功在NASA JPL NeBula-Spot机器人上实时测试。

Conclusion: Pix2G方法有效支持资源受限机器人的自主探索，实现了2D与3D信息的无缝结合。

Abstract: Autonomous robots are increasingly playing key roles as support platforms for
human operators in high-risk, dangerous applications. To accomplish challenging
tasks, an efficient human-robot cooperation and understanding is required.
While typically robotic planning leverages 3D geometric information, human
operators are accustomed to a high-level compact representation of the
environment, like top-down 2D maps representing the Building Information Model
(BIM). 3D scene graphs have emerged as a powerful tool to bridge the gap
between human readable 2D BIM and the robot 3D maps. In this work, we introduce
Pixels-to-Graph (Pix2G), a novel lightweight method to generate structured
scene graphs from image pixels and LiDAR maps in real-time for the autonomous
exploration of unknown environments on resource-constrained robot platforms. To
satisfy onboard compute constraints, the framework is designed to perform all
operation on CPU only. The method output are a de-noised 2D top-down
environment map and a structure-segmented 3D pointcloud which are seamlessly
connected using a multi-layer graph abstracting information from object-level
up to the building-level. The proposed method is quantitatively and
qualitatively evaluated during real-world experiments performed using the NASA
JPL NeBula-Spot legged robot to autonomously explore and map cluttered garage
and urban office like environments in real-time.

</details>


### [120] [Robust Peg-in-Hole Assembly under Uncertainties via Compliant and Interactive Contact-Rich Manipulation](https://arxiv.org/abs/2506.22766)
*Yiting Chen,Kenneth Kimble,Howard H. Qian,Podshara Chanrungmaneekul,Robert Seney,Kaiyu Hang*

Main category: cs.RO

TL;DR: 论文提出了一种基于接触约束的鲁棒自适应机器人插孔装配方法，通过碰撞包容性交互和漏斗化策略，解决了紧密公差下的不确定性挑战。


<details>
  <summary>Details</summary>
Motivation: 紧密公差下的机器人插孔装配在工业应用中至关重要，但由于感知和物理不确定性，尤其是接触丰富的交互，这一问题尚未完全解决。

Method: 研究利用接触约束消除不确定性，提出了一种碰撞包容性交互系统，通过漏斗化策略在不同状态空间中规划装配动作。

Result: 系统在多种插孔场景（不同尺寸、形状和材料）中表现出鲁棒性，无需依赖精确感知或学习。

Conclusion: 该方法为紧密公差下的插孔装配提供了一种通用且鲁棒的解决方案，适用于实际工业应用。

Abstract: Robust and adaptive robotic peg-in-hole assembly under tight tolerances is
critical to various industrial applications. However, it remains an open
challenge due to perceptual and physical uncertainties from contact-rich
interactions that easily exceed the allowed clearance. In this paper, we study
how to leverage contact between the peg and its matching hole to eliminate
uncertainties in the assembly process under unstructured settings. By examining
the role of compliance under contact constraints, we present a manipulation
system that plans collision-inclusive interactions for the peg to 1)
iteratively identify its task environment to localize the target hole and 2)
exploit environmental contact constraints to refine insertion motions into the
target hole without relying on precise perception, enabling a robust solution
to peg-in-hole assembly. By conceptualizing the above process as the
composition of funneling in different state spaces, we present a formal
approach to constructing manipulation funnels as an uncertainty-absorbing
paradigm for peg-in-hole assembly. The proposed system effectively generalizes
across diverse peg-in-hole scenarios across varying scales, shapes, and
materials in a learning-free manner. Extensive experiments on a NIST Assembly
Task Board (ATB) and additional challenging scenarios validate its robustness
in real-world applications.

</details>


### [121] [Learning Efficient Robotic Garment Manipulation with Standardization](https://arxiv.org/abs/2506.22769)
*Changshi Zhou,Feng Luan,Jiarui Hu,Shaoqiang Meng,Zhipeng Wang,Yanchao Dong,Yanmin Zhou,Bin He*

Main category: cs.RO

TL;DR: APS-Net提出了一种结合展开和标准化的服装操作新方法，通过双臂多原语策略和动态投掷技术，显著提升了服装展开和标准化的效率。


<details>
  <summary>Details</summary>
Motivation: 现有服装展开方法忽视了标准化的重要性，而标准化能显著简化后续任务（如折叠、熨烫和包装）。

Method: APS-Net采用双臂多原语策略，结合动态投掷和拾取放置技术，并引入因子化奖励函数、空间动作掩码和动作优化模块。

Result: 在仿真中，APS-Net在长袖服装上表现优于现有方法，覆盖率和IoU分别提升3.9%和5.2%，关键点距离减少7.09%。

Conclusion: 标准化显著简化了折叠任务，APS-Net为服装操作提供了高效统一的解决方案。

Abstract: Garment manipulation is a significant challenge for robots due to the complex
dynamics and potential self-occlusion of garments. Most existing methods of
efficient garment unfolding overlook the crucial role of standardization of
flattened garments, which could significantly simplify downstream tasks like
folding, ironing, and packing. This paper presents APS-Net, a novel approach to
garment manipulation that combines unfolding and standardization in a unified
framework. APS-Net employs a dual-arm, multi-primitive policy with dynamic
fling to quickly unfold crumpled garments and pick-and-place (p and p) for
precise alignment. The purpose of garment standardization during unfolding
involves not only maximizing surface coverage but also aligning the garment's
shape and orientation to predefined requirements. To guide effective robot
learning, we introduce a novel factorized reward function for standardization,
which incorporates garment coverage (Cov), keypoint distance (KD), and
intersection-over-union (IoU) metrics. Additionally, we introduce a spatial
action mask and an Action Optimized Module to improve unfolding efficiency by
selecting actions and operation points effectively. In simulation, APS-Net
outperforms state-of-the-art methods for long sleeves, achieving 3.9 percent
better coverage, 5.2 percent higher IoU, and a 0.14 decrease in KD (7.09
percent relative reduction). Real-world folding tasks further demonstrate that
standardization simplifies the folding process. Project page: see
https://hellohaia.github.io/APS/

</details>


### [122] [SPI-BoTER: Error Compensation for Industrial Robots via Sparse Attention Masking and Hybrid Loss with Spatial-Physical Information](https://arxiv.org/abs/2506.22788)
*Xuao Hou,Yongquan Jia,Shijin Zhang,Yuqiang Wu*

Main category: cs.RO

TL;DR: 本文提出了一种结合物理模型与Transformer架构的SPI-BoTER方法，用于工业机器人轨迹误差补偿，在小样本条件下实现了高精度和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 工业机器人末端执行器的轨迹精度需求日益严格，但现有误差补偿方法存在建模简化、数据驱动缺乏物理一致性及数据需求大等问题，难以同时实现高精度与强泛化。

Method: 提出SPI-BoTER方法，融合机器人运动学方程与稀疏自注意力掩码增强的Transformer架构，采用参数自适应混合损失函数迭代优化网络，并通过梯度下降优化逆关节角补偿。

Result: 在UR5机械臂小样本数据集上，3D绝对定位误差为0.2515 mm（标准差0.15 mm），较传统DNN方法误差降低35.16%；逆角度补偿算法平均147次迭代收敛至0.01 mm精度。

Conclusion: SPI-BoTER结合物理可解释性与数据适应性，为工业机器人高精度控制提供了有效解决方案，有望推动智能制造中精密任务的可靠执行。

Abstract: The widespread application of industrial robots in fields such as cutting and
welding has imposed increasingly stringent requirements on the trajectory
accuracy of end-effectors. However, current error compensation methods face
several critical challenges, including overly simplified mechanism modeling, a
lack of physical consistency in data-driven approaches, and substantial data
requirements. These issues make it difficult to achieve both high accuracy and
strong generalization simultaneously. To address these challenges, this paper
proposes a Spatial-Physical Informed Attention Residual Network (SPI-BoTER).
This method integrates the kinematic equations of the robotic manipulator with
a Transformer architecture enhanced by sparse self-attention masks. A
parameter-adaptive hybrid loss function incorporating spatial and physical
information is employed to iteratively optimize the network during training,
enabling high-precision error compensation under small-sample conditions.
Additionally, inverse joint angle compensation is performed using a gradient
descent-based optimization method. Experimental results on a small-sample
dataset from a UR5 robotic arm (724 samples, with a train:test:validation split
of 8:1:1) demonstrate the superior performance of the proposed method. It
achieves a 3D absolute positioning error of 0.2515 mm with a standard deviation
of 0.15 mm, representing a 35.16\% reduction in error compared to conventional
deep neural network (DNN) methods. Furthermore, the inverse angle compensation
algorithm converges to an accuracy of 0.01 mm within an average of 147
iterations. This study presents a solution that combines physical
interpretability with data adaptability for high-precision control of
industrial robots, offering promising potential for the reliable execution of
precision tasks in intelligent manufacturing.

</details>


### [123] [Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation](https://arxiv.org/abs/2506.22827)
*André Schakkal,Ben Zandonati,Zhutian Yang,Navid Azizan*

Main category: cs.RO

TL;DR: 提出了一种分层规划与控制框架，用于实现可靠的多步骤人形机器人操作，结合强化学习、模仿学习和视觉语言模型，实验验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 使人形机器人能够在工业和家庭环境中可靠执行复杂的多步骤操作任务。

Method: 分三层设计：低层RL控制器跟踪全身运动目标；中层模仿学习技能策略生成任务步骤的运动目标；高层视觉语言规划模块决定技能执行并实时监控。

Result: 在Unitree G1机器人上进行了40次实验，完成完整操作序列的成功率为72.5%。

Conclusion: 分层系统可行，视觉语言模型在多步骤操作中具有优势。

Abstract: Enabling humanoid robots to reliably execute complex multi-step manipulation
tasks is crucial for their effective deployment in industrial and household
environments. This paper presents a hierarchical planning and control framework
designed to achieve reliable multi-step humanoid manipulation. The proposed
system comprises three layers: (1) a low-level RL-based controller responsible
for tracking whole-body motion targets; (2) a mid-level set of skill policies
trained via imitation learning that produce motion targets for different steps
of a task; and (3) a high-level vision-language planning module that determines
which skills should be executed and also monitors their completion in real-time
using pretrained vision-language models (VLMs). Experimental validation is
performed on a Unitree G1 humanoid robot executing a non-prehensile
pick-and-place task. Over 40 real-world trials, the hierarchical system
achieved a 72.5% success rate in completing the full manipulation sequence.
These experiments confirm the feasibility of the proposed hierarchical system,
highlighting the benefits of VLM-based skill planning and monitoring for
multi-step manipulation scenarios. See https://vlp-humanoid.github.io/ for
video demonstrations of the policy rollout.

</details>


### [124] [Safe Reinforcement Learning with a Predictive Safety Filter for Motion Planning and Control: A Drifting Vehicle Example](https://arxiv.org/abs/2506.22894)
*Bei Zhou,Baha Zarrouki,Mattia Piccinini,Cheng Hu,Lei Xie,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了一种基于安全强化学习的运动规划方法，用于自主漂移，结合模型漂移动力学和预测安全过滤器，确保安全高效的学习和稳定操作。


<details>
  <summary>Details</summary>
Motivation: 自主漂移在安全关键场景中至关重要，但传统方法难以应对其高不稳定性，现有学习方法依赖专家知识或缺乏安全性保障。

Method: 结合强化学习与模型漂移动力学，引入预测安全过滤器在线调整动作以避免不安全状态。

Result: 在Matlab-Carsim平台上验证了方法有效性，漂移性能显著提升，跟踪误差减少，计算效率优于传统方法。

Conclusion: 该方法扩展了自动驾驶车辆在安全关键场景中的能力。

Abstract: Autonomous drifting is a complex and crucial maneuver for safety-critical
scenarios like slippery roads and emergency collision avoidance, requiring
precise motion planning and control. Traditional motion planning methods often
struggle with the high instability and unpredictability of drifting,
particularly when operating at high speeds. Recent learning-based approaches
have attempted to tackle this issue but often rely on expert knowledge or have
limited exploration capabilities. Additionally, they do not effectively address
safety concerns during learning and deployment. To overcome these limitations,
we propose a novel Safe Reinforcement Learning (RL)-based motion planner for
autonomous drifting. Our approach integrates an RL agent with model-based drift
dynamics to determine desired drift motion states, while incorporating a
Predictive Safety Filter (PSF) that adjusts the agent's actions online to
prevent unsafe states. This ensures safe and efficient learning, and stable
drift operation. We validate the effectiveness of our method through
simulations on a Matlab-Carsim platform, demonstrating significant improvements
in drift performance, reduced tracking errors, and computational efficiency
compared to traditional methods. This strategy promises to extend the
capabilities of autonomous vehicles in safety-critical maneuvers.

</details>


### [125] [Energy-Constrained Resilient Multi-Robot Coverage Control](https://arxiv.org/abs/2506.22942)
*Kartik A. Pant,Jaehyeok Kim,James M. Goppert,Inseok Hwang*

Main category: cs.RO

TL;DR: 提出了一种多机器人覆盖控制的弹性网络设计与控制方法，解决机器人充电时网络拓扑中断的问题。


<details>
  <summary>Details</summary>
Motivation: 多机器人同时充电会导致通信和感知网络拓扑中断，影响覆盖性能。

Method: 将系统建模为三种模式的混合系统，设计能量感知的轴承刚性网络以增强弹性。

Result: 通过数值模拟验证了方法的有效性，确保覆盖性能、能量约束和网络连通性。

Conclusion: 提出的方法能有效解决多机器人覆盖控制中的充电和网络弹性问题。

Abstract: The problem of multi-robot coverage control becomes significantly challenging
when multiple robots leave the mission space simultaneously to charge their
batteries, disrupting the underlying network topology for communication and
sensing. To address this, we propose a resilient network design and control
approach that allows robots to achieve the desired coverage performance while
satisfying energy constraints and maintaining network connectivity throughout
the mission. We model the combined motion, energy, and network dynamics of the
multirobot systems (MRS) as a hybrid system with three modes, i.e., coverage,
return-to-base, and recharge, respectively. We show that ensuring the energy
constraints can be transformed into designing appropriate guard conditions for
mode transition between each of the three modes. Additionally, we present a
systematic procedure to design, maintain, and reconfigure the underlying
network topology using an energy-aware bearing rigid network design, enhancing
the structural resilience of the MRS even when a subset of robots departs to
charge their batteries. Finally, we validate our proposed method using
numerical simulations.

</details>


### [126] [SPICE-HL3: Single-Photon, Inertial, and Stereo Camera dataset for Exploration of High-Latitude Lunar Landscapes](https://arxiv.org/abs/2506.22956)
*David Rodríguez-Martínez,Dave van der Meer,Junlin Song,Abishek Bera,C. J. Pérez-del-Pulgar,Miguel Angel Olivares-Mendez*

Main category: cs.RO

TL;DR: 论文介绍了一个在LunaLab设施中记录的高纬度月球环境模拟数据集，包含图像、惯性测量和轮式里程数据，用于验证感知任务。


<details>
  <summary>Details</summary>
Motivation: 高纬度月球区域的视觉环境对机器人极具挑战性，需要模拟低太阳高度角和动态阴影的条件。

Method: 使用多种传感器（包括新型SPAD相机）记录机器人在不同光照和速度下的导航数据。

Result: 生成了88个序列共1.3M张图像的数据集，数据经过校准和同步。

Conclusion: 该数据集为未来月球任务中的感知任务验证提供了宝贵资源。

Abstract: Exploring high-latitude lunar regions presents an extremely challenging
visual environment for robots. The low sunlight elevation angle and minimal
light scattering result in a visual field dominated by a high dynamic range
featuring long, dynamic shadows. Reproducing these conditions on Earth requires
sophisticated simulators and specialized facilities. We introduce a unique
dataset recorded at the LunaLab from the SnT - University of Luxembourg, an
indoor test facility designed to replicate the optical characteristics of
multiple lunar latitudes. Our dataset includes images, inertial measurements,
and wheel odometry data from robots navigating seven distinct trajectories
under multiple illumination scenarios, simulating high-latitude lunar
conditions from dawn to night time with and without the aid of headlights,
resulting in 88 distinct sequences containing a total of 1.3M images. Data was
captured using a stereo RGB-inertial sensor, a monocular monochrome camera, and
for the first time, a novel single-photon avalanche diode (SPAD) camera. We
recorded both static and dynamic image sequences, with robots navigating at
slow (5 cm/s) and fast (50 cm/s) speeds. All data is calibrated, synchronized,
and timestamped, providing a valuable resource for validating perception tasks
from vision-based autonomous navigation to scientific imaging for future lunar
missions targeting high-latitude regions or those intended for robots operating
across perceptually degraded environments. The dataset can be downloaded from
https://zenodo.org/records/13970078?preview=1, and a visual overview is
available at https://youtu.be/d7sPeO50_2I. All supplementary material can be
found at https://github.com/spaceuma/spice-hl3.

</details>


### [127] [Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making](https://arxiv.org/abs/2506.23023)
*M. Youssef Abdelhamid,Lennart Vater,Zlatan Ajanovic*

Main category: cs.RO

TL;DR: 提出了SAD-RL框架，结合分层强化学习和场景化环境，提升自动驾驶决策算法的泛化能力和学习效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需在复杂开放环境中安全运行，现有强化学习方法在复杂任务中泛化能力不足且学习效率低。

Method: SAD-RL框架结合分层强化学习（高层策略选择动作模板，低层逻辑执行）和场景化环境（控制训练经验并引入挑战性场景）。

Result: 实验表明，SAD-RL训练的智能体能在简单和挑战性场景中高效实现安全行为，分层策略和场景多样性是关键。

Conclusion: SAD-RL框架通过分层策略和场景化训练，显著提升了自动驾驶决策算法的泛化能力和效率。

Abstract: Developing decision-making algorithms for highly automated driving systems
remains challenging, since these systems have to operate safely in an open and
complex environments. Reinforcement Learning (RL) approaches can learn
comprehensive decision policies directly from experience and already show
promising results in simple driving tasks. However, current approaches fail to
achieve generalizability for more complex driving tasks and lack learning
efficiency. Therefore, we present Scenario-based Automated Driving
Reinforcement Learning (SAD-RL), the first framework that integrates
Reinforcement Learning (RL) of hierarchical policy in a scenario-based
environment. A high-level policy selects maneuver templates that are evaluated
and executed by a low-level control logic. The scenario-based environment
allows to control the training experience for the agent and to explicitly
introduce challenging, but rate situations into the training process. Our
experiments show that an agent trained using the SAD-RL framework can achieve
safe behaviour in easy as well as challenging situations efficiently. Our
ablation studies confirmed that both HRL and scenario diversity are essential
for achieving these results.

</details>


### [128] [Event-based Stereo Visual-Inertial Odometry with Voxel Map](https://arxiv.org/abs/2506.23078)
*Zhaoxing Zhang,Xiaoxiang Wang,Chengliang Zhang,Yangyang Guo,Zikang Yuan,Xin Yang*

Main category: cs.RO

TL;DR: Voxel-ESVIO是一种基于事件相机的立体视觉惯性里程计系统，通过体素地图管理高效筛选高质量3D点，提升状态估计精度。


<details>
  <summary>Details</summary>
Motivation: 事件相机的高动态范围和高时间分辨率使其成为视觉里程计的重要传感器，但事件流中的噪声影响了高质量地图点的选择，从而影响状态估计精度。

Method: 采用基于体素的点选择和体素感知的点管理，协同优化地图点的选择和更新，高效提取抗噪声的高质量地图点。

Result: 在三个公开基准测试中，Voxel-ESVIO在精度和计算效率上均优于现有方法。

Conclusion: Voxel-ESVIO通过体素地图管理有效解决了事件流噪声问题，显著提升了状态估计的精度和效率。

Abstract: The event camera, renowned for its high dynamic range and exceptional
temporal resolution, is recognized as an important sensor for visual odometry.
However, the inherent noise in event streams complicates the selection of
high-quality map points, which critically determine the precision of state
estimation. To address this challenge, we propose Voxel-ESVIO, an event-based
stereo visual-inertial odometry system that utilizes voxel map management,
which efficiently filter out high-quality 3D points. Specifically, our
methodology utilizes voxel-based point selection and voxel-aware point
management to collectively optimize the selection and updating of map points on
a per-voxel basis. These synergistic strategies enable the efficient retrieval
of noise-resilient map points with the highest observation likelihood in
current frames, thereby ensureing the state estimation accuracy. Extensive
evaluations on three public benchmarks demonstrate that our Voxel-ESVIO
outperforms state-of-the-art methods in both accuracy and computational
efficiency.

</details>


### [129] [Minimizing Acoustic Noise: Enhancing Quiet Locomotion for Quadruped Robots in Indoor Applications](https://arxiv.org/abs/2506.23114)
*Zhanxiang Cao,Buqing Nie,Yang Zhang,Yue Gao*

Main category: cs.RO

TL;DR: 研究通过优化步态设计和控制策略，降低四足机器人在室内噪声敏感环境中的噪音约8 dBA。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在复杂户外环境中的移动能力已显著提升，但其在噪声敏感室内环境（如服务和医疗场景）中的噪音问题被忽视。

Method: 提出一种结合优化步态设计和定制控制策略的新方法，以减少噪音排放。

Result: 实验结果显示，该方法平均降低噪音约8 dBA，适用于多种室内环境。

Conclusion: 该方法显著提升了四足机器人在噪声敏感环境中的适用性，展示了其在安静操作方面的潜力。

Abstract: Recent advancements in quadruped robot research have significantly improved
their ability to traverse complex and unstructured outdoor environments.
However, the issue of noise generated during locomotion is generally
overlooked, which is critically important in noise-sensitive indoor
environments, such as service and healthcare settings, where maintaining low
noise levels is essential. This study aims to optimize the acoustic noise
generated by quadruped robots during locomotion through the development of
advanced motion control algorithms. To achieve this, we propose a novel
approach that minimizes noise emissions by integrating optimized gait design
with tailored control strategies. This method achieves an average noise
reduction of approximately 8 dBA during movement, thereby enhancing the
suitability of quadruped robots for deployment in noise-sensitive indoor
environments. Experimental results demonstrate the effectiveness of this
approach across various indoor settings, highlighting the potential of
quadruped robots for quiet operation in noise-sensitive environments.

</details>


### [130] [Learning Motion Skills with Adaptive Assistive Curriculum Force in Humanoid Robots](https://arxiv.org/abs/2506.23125)
*Zhanxiang Cao,Yang Zhang,Buqing Nie,Huangxuan Lin,Haoyang Li,Yue Gao*

Main category: cs.RO

TL;DR: A2CF方法通过自适应辅助力加速人形机器人复杂动作学习，比基线方法快30%，失败率降低40%。


<details>
  <summary>Details</summary>
Motivation: 受婴儿和运动员依赖外部支持学习复杂动作的启发，提出A2CF方法以加速机器人技能学习。

Method: 训练双智能体系统，辅助力智能体根据状态施加力，并随机器人熟练度提升逐步减少辅助。

Result: 在行走、舞蹈和后空翻任务中，A2CF比基线方法快30%，失败率降低40%，生成无需支持的稳健策略。

Conclusion: 自适应辅助力显著加速高维机器人控制中复杂技能的获取。

Abstract: Learning policies for complex humanoid tasks remains both challenging and
compelling. Inspired by how infants and athletes rely on external support--such
as parental walkers or coach-applied guidance--to acquire skills like walking,
dancing, and performing acrobatic flips, we propose A2CF: Adaptive Assistive
Curriculum Force for humanoid motion learning. A2CF trains a dual-agent system,
in which a dedicated assistive force agent applies state-dependent forces to
guide the robot through difficult initial motions and gradually reduces
assistance as the robot's proficiency improves. Across three
benchmarks--bipedal walking, choreographed dancing, and backflip--A2CF achieves
convergence 30% faster than baseline methods, lowers failure rates by over 40%,
and ultimately produces robust, support-free policies. Real-world experiments
further demonstrate that adaptively applied assistive forces significantly
accelerate the acquisition of complex skills in high-dimensional robotic
control.

</details>


### [131] [ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation](https://arxiv.org/abs/2506.23126)
*Suning Huang,Qianzhong Chen,Xiaohan Zhang,Jiankai Sun,Mac Schwager*

Main category: cs.RO

TL;DR: ParticleFormer是一种基于Transformer的点云世界模型，通过混合点云重建损失训练，支持多材料、多物体交互的动态预测，无需复杂场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有3D世界模型局限于单材料动态且依赖耗时3D重建，难以处理多材料、多物体交互。

Method: 提出ParticleFormer，结合Transformer和点云重建损失，直接利用真实机器人感知数据训练。

Result: 在3D场景预测和下游操控任务中表现优异，动态预测精度和滚动误差优于基线。

Conclusion: ParticleFormer在多材料、多物体交互中具有显著优势，为机器人操控提供高效解决方案。

Abstract: 3D world models (i.e., learning-based 3D dynamics models) offer a promising
approach to generalizable robotic manipulation by capturing the underlying
physics of environment evolution conditioned on robot actions. However,
existing 3D world models are primarily limited to single-material dynamics
using a particle-based Graph Neural Network model, and often require
time-consuming 3D scene reconstruction to obtain 3D particle tracks for
training. In this work, we present ParticleFormer, a Transformer-based point
cloud world model trained with a hybrid point cloud reconstruction loss,
supervising both global and local dynamics features in multi-material,
multi-object robot interactions. ParticleFormer captures fine-grained
multi-object interactions between rigid, deformable, and flexible materials,
trained directly from real-world robot perception data without an elaborate
scene reconstruction. We demonstrate the model's effectiveness both in 3D scene
forecasting tasks, and in downstream manipulation tasks using a Model
Predictive Control (MPC) policy. In addition, we extend existing dynamics
learning benchmarks to include diverse multi-material, multi-object interaction
scenarios. We validate our method on six simulation and three real-world
experiments, where it consistently outperforms leading baselines by achieving
superior dynamics prediction accuracy and less rollout error in downstream
visuomotor tasks. Experimental videos are available at
https://particleformer.github.io/.

</details>


### [132] [Flatness-based Finite-Horizon Multi-UAV Formation Trajectory Planning and Directionally Aware Collision Avoidance Tracking](https://arxiv.org/abs/2506.23129)
*Hossein B. Jond,Logan Beaver,Martin Jiroušek,Naiemeh Ahmadlou,Veli Bakırcıoğlu,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种基于微分平坦度的无人机编队控制方案，避免了传统数值方法对初始猜测的依赖，实现了无碰撞的有限时间编队控制。


<details>
  <summary>Details</summary>
Motivation: 现有最优控制方法依赖数值方法且对初始猜测敏感，难以实现无碰撞的无人机编队控制。

Method: 利用无人机动力学的微分平坦性，设计有限时间最优控制问题，并通过Pontryagin原理求解；采用方向感知的碰撞避免策略。

Result: 仿真验证了四无人机编队问题的有效性。

Conclusion: 该方案成功实现了无碰撞的有限时间编队控制，具有较高的实用价值。

Abstract: Collision-free optimal formation control of unmanned aerial vehicle (UAV)
teams is challenging. The state-of-the-art optimal control approaches often
rely on numerical methods sensitive to initial guesses. This paper presents an
innovative collision-free finite-time formation control scheme for multiple
UAVs leveraging the differential flatness of the UAV dynamics, eliminating the
need for numerical methods. We formulate a finite-time optimal control problem
to plan a formation trajectory for feasible initial states. This formation
trajectory planning optimal control problem involves a collective performance
index to meet the formation requirements of achieving relative positions and
velocity consensus. It is solved by applying Pontryagin's principle.
Subsequently, a collision-constrained regulating problem is addressed to ensure
collision-free tracking of the planned formation trajectory. The tracking
problem incorporates a directionally aware collision avoidance strategy that
prioritizes avoiding UAVs in the forward path and relative approach. It assigns
lower priority to those on the sides with an oblique relative approach and
disregards UAVs behind and not in the relative approach. The simulation results
for a four-UAV team (re)formation problem confirm the efficacy of the proposed
control scheme.

</details>


### [133] [DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover](https://arxiv.org/abs/2506.23152)
*Youzhuo Wang,Jiayi Ye,Chuyang Xiao,Yiming Zhong,Heng Tao,Hang Yu,Yumeng Liu,Jingyi Yu,Yuexin Ma*

Main category: cs.RO

TL;DR: 论文介绍了DexH2R数据集，用于人机手部交接任务，填补了高质量真实世界数据的空白，并提出了DynamicGrasp解决方案。


<details>
  <summary>Details</summary>
Motivation: 人机手部交接任务在动态环境和多样化物体中具有挑战性，但缺乏高质量的真实世界数据集。

Method: 通过遥操作收集数据，确保机器人动作自然，并提出了DynamicGrasp解决方案。

Result: 数据集包含多样化物体和动态动作，评估了多种先进方法，提供了全面分析。

Conclusion: DexH2R数据集和DynamicGrasp解决方案将推动人机手部交接研究的发展。

Abstract: Handover between a human and a dexterous robotic hand is a fundamental yet
challenging task in human-robot collaboration. It requires handling dynamic
environments and a wide variety of objects and demands robust and adaptive
grasping strategies. However, progress in developing effective dynamic
dexterous grasping methods is limited by the absence of high-quality,
real-world human-to-robot handover datasets. Existing datasets primarily focus
on grasping static objects or rely on synthesized handover motions, which
differ significantly from real-world robot motion patterns, creating a
substantial gap in applicability. In this paper, we introduce DexH2R, a
comprehensive real-world dataset for human-to-robot handovers, built on a
dexterous robotic hand. Our dataset captures a diverse range of interactive
objects, dynamic motion patterns, rich visual sensor data, and detailed
annotations. Additionally, to ensure natural and human-like dexterous motions,
we utilize teleoperation for data collection, enabling the robot's movements to
align with human behaviors and habits, which is a crucial characteristic for
intelligent humanoid robots. Furthermore, we propose an effective solution,
DynamicGrasp, for human-to-robot handover and evaluate various state-of-the-art
approaches, including auto-regressive models and diffusion policy methods,
providing a thorough comparison and analysis. We believe our benchmark will
drive advancements in human-to-robot handover research by offering a
high-quality dataset, effective solutions, and comprehensive evaluation
metrics.

</details>


### [134] [Mode Collapse Happens: Evaluating Critical Interactions in Joint Trajectory Prediction Models](https://arxiv.org/abs/2506.23164)
*Maarten Hugenholtz,Anna Meszaros,Jens Kober,Zlatan Ajanovic*

Main category: cs.RO

TL;DR: 论文提出了一种评估框架，用于检测多模态预测模型中的模式崩溃问题，重点关注安全关键交互，并引入了新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有模型可能因模式崩溃而仅预测最可能的模式，忽视交互多样性，且传统评估指标无法量化交互或检测模式崩溃。

Method: 提出了一种评估框架，包括模式崩溃、模式正确性和覆盖率的指标，测试了四种多智能体轨迹预测模型。

Result: 研究发现模式崩溃确实存在，且即使接近交互事件时预测准确性提高，模型仍可能无法预测正确的交互模式。

Conclusion: 该框架有助于研究者深入理解模式崩溃，推动开发更一致和准确的预测模型，提升自动驾驶安全性。

Abstract: Autonomous Vehicle decisions rely on multimodal prediction models that
account for multiple route options and the inherent uncertainty in human
behavior. However, models can suffer from mode collapse, where only the most
likely mode is predicted, posing significant safety risks. While existing
methods employ various strategies to generate diverse predictions, they often
overlook the diversity in interaction modes among agents. Additionally,
traditional metrics for evaluating prediction models are dataset-dependent and
do not evaluate inter-agent interactions quantitatively. To our knowledge, none
of the existing metrics explicitly evaluates mode collapse. In this paper, we
propose a novel evaluation framework that assesses mode collapse in joint
trajectory predictions, focusing on safety-critical interactions. We introduce
metrics for mode collapse, mode correctness, and coverage, emphasizing the
sequential dimension of predictions. By testing four multi-agent trajectory
prediction models, we demonstrate that mode collapse indeed happens. When
looking at the sequential dimension, although prediction accuracy improves
closer to interaction events, there are still cases where the models are unable
to predict the correct interaction mode, even just before the interaction mode
becomes inevitable. We hope that our framework can help researchers gain new
insights and advance the development of more consistent and accurate prediction
models, thus enhancing the safety of autonomous driving systems.

</details>


### [135] [InfGen: Scenario Generation as Next Token Group Prediction](https://arxiv.org/abs/2506.23316)
*Zhenghao Peng,Yuxin Liu,Bolei Zhou*

Main category: cs.RO

TL;DR: InfGen是一个基于Transformer的交通场景生成框架，能够以自回归方式生成动态、长期的交通场景，支持无限场景生成，提升自动驾驶系统的训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的交通模拟方法依赖静态初始化或日志回放数据，难以建模动态、长期的交通场景。

Method: InfGen将整个场景表示为一系列令牌（如交通信号灯、车辆状态和运动向量），并使用Transformer模型进行时间上的交通模拟。

Result: 实验表明，InfGen能生成真实、多样且自适应的交通行为，且在其生成场景中训练的强化学习策略具有更强的鲁棒性和泛化能力。

Conclusion: InfGen是一个高保真度的自动驾驶模拟环境，适用于动态交通场景的生成和训练。

Abstract: Realistic and interactive traffic simulation is essential for training and
evaluating autonomous driving systems. However, most existing data-driven
simulation methods rely on static initialization or log-replay data, limiting
their ability to model dynamic, long-horizon scenarios with evolving agent
populations. We propose InfGen, a scenario generation framework that outputs
agent states and trajectories in an autoregressive manner. InfGen represents
the entire scene as a sequence of tokens, including traffic light signals,
agent states, and motion vectors, and uses a transformer model to simulate
traffic over time. This design enables InfGen to continuously insert new agents
into traffic, supporting infinite scene generation. Experiments demonstrate
that InfGen produces realistic, diverse, and adaptive traffic behaviors.
Furthermore, reinforcement learning policies trained in InfGen-generated
scenarios achieve superior robustness and generalization, validating its
utility as a high-fidelity simulation environment for autonomous driving. More
information is available at https://metadriverse.github.io/infgen/.

</details>


### [136] [Simplifying Data-Driven Modeling of the Volume-Flow-Pressure Relationship in Hydraulic Soft Robotic Actuators](https://arxiv.org/abs/2506.23326)
*Sang-Yoep Lee,Leonardo Zamora Yanez,Jacob Rogatinsky,Vi T. Vo,Tanvi Shingade,Tommaso Ranzani*

Main category: cs.RO

TL;DR: 研究提出了一种数据驱动的方法，用于建模液压软执行器的体积-流量-压力关系，重点在于低复杂度高精度的模型。


<details>
  <summary>Details</summary>
Motivation: 传统物理模型难以捕捉软机器人系统的复杂非线性行为，因此需要更有效的建模方法。

Method: 采用回归分析，比较了指数、多项式和神经网络模型（含或不含自回归输入）在堆叠气球执行器系统上的表现。

Result: 结果表明，较简单的模型（尤其是多元多项式）能以较少参数有效预测压力动态。

Conclusion: 该研究为实时软机器人应用提供了实用解决方案，平衡了模型复杂度和计算效率，并可能适用于其他需要显式解析模型的技术。

Abstract: Soft robotic systems are known for their flexibility and adaptability, but
traditional physics-based models struggle to capture their complex, nonlinear
behaviors. This study explores a data-driven approach to modeling the
volume-flow-pressure relationship in hydraulic soft actuators, focusing on
low-complexity models with high accuracy. We perform regression analysis on a
stacked balloon actuator system using exponential, polynomial, and neural
network models with or without autoregressive inputs. The results demonstrate
that simpler models, particularly multivariate polynomials, effectively predict
pressure dynamics with fewer parameters. This research offers a practical
solution for real-time soft robotics applications, balancing model complexity
and computational efficiency. Moreover, the approach may benefit various
techniques that require explicit analytical models.

</details>


### [137] [Moving Matter: Using a Single, Simple Robot to Reconfigure a Connected Set of Building Blocks](https://arxiv.org/abs/2506.23333)
*Javier Garcia,Jonas Friemel,Ramin Kosfeld,Michael Yannuzzi,Peter Kramer,Christian Rieck,Christian Scheffer,Arne Schmidt,Harm Kube,Dan Biediger,Sándor P. Fekete,Aaron T. Becker*

Main category: cs.RO

TL;DR: 论文研究了如何用单个机器人重新配置连接的瓦片结构，比较了基于直方图的算法与两种启发式算法的性能。


<details>
  <summary>Details</summary>
Motivation: 探索在保持连接性的前提下，如何高效地将瓦片结构重新配置为目标形状。

Method: 实现并评估了Becker等人的直方图算法，并与两种启发式算法在仿真和实际环境中进行比较。

Result: 直方图算法在起始和目标配置分离良好的情况下，性能接近最优解。

Conclusion: 直方图算法在特定条件下表现优异，为瓦片重配置问题提供了有效解决方案。

Abstract: We implement and evaluate different methods for the reconfiguration of a
connected arrangement of tiles into a desired target shape, using a single
active robot that can move along the tile structure. This robot can pick up,
carry, or drop off one tile at a time, but it must maintain a single connected
configuration at all times.
  Becker et al. (CCCG 2025) recently proposed an algorithm that uses histograms
as canonical intermediate configurations, guaranteeing performance within a
constant factor of the optimal solution if the start and target configuration
are well-separated. We implement and evaluate this algorithm, both in a
simulated and practical setting, using an inchworm type robot to compare it
with two existing heuristic algorithms.

</details>


### [138] [Safe and Performant Deployment of Autonomous Systems via Model Predictive Control and Hamilton-Jacobi Reachability Analysis](https://arxiv.org/abs/2506.23346)
*Hao Wang,Armand Jordana,Ludovic Righetti,Somil Bansal*

Main category: cs.RO

TL;DR: 提出了一种基于MPC和HJ可达性的框架，优化自主系统的任务性能并确保安全性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保证安全性的同时高效完成任务，需要一种兼顾性能与安全的解决方案。

Method: 结合模型预测控制（MPC）和Hamilton-Jacobi（HJ）可达性理论，确保递归可行性和高维扩展性。

Result: 在4D Dubins Car和6自由度Kuka iiwa机械臂的仿真实验中，框架显著提升了安全性。

Conclusion: 该框架为自主系统提供了性能与安全的平衡，适用于高维系统。

Abstract: While we have made significant algorithmic developments to enable autonomous
systems to perform sophisticated tasks, it remains difficult for them to
perform tasks effective and safely. Most existing approaches either fail to
provide any safety assurances or substantially compromise task performance for
safety. In this work, we develop a framework, based on model predictive control
(MPC) and Hamilton-Jacobi (HJ) reachability, to optimize task performance for
autonomous systems while respecting the safety constraints. Our framework
guarantees recursive feasibility for the MPC controller, and it is scalable to
high-dimensional systems. We demonstrate the effectiveness of our framework
with two simulation studies using a 4D Dubins Car and a 6 Dof Kuka iiwa
manipulator, and the experiments show that our framework significantly improves
the safety constraints satisfaction of the systems over the baselines.

</details>


### [139] [Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop](https://arxiv.org/abs/2506.23351)
*Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yuchen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu*

Main category: cs.RO

TL;DR: 论文介绍了RoboTwin双臂协作挑战赛，旨在推动双臂机器人处理复杂任务的能力，吸引了全球64支团队参与，并提出了通用双臂策略学习的关键见解。


<details>
  <summary>Details</summary>
Motivation: 推动自主系统在复杂物理环境中的感知、推理和行动能力，特别是双臂协作系统在处理刚性、可变形和触觉敏感物体任务中的重要性。

Method: 基于RoboTwin仿真平台和AgileX COBOT-Magic Robot平台，设计了三个阶段的比赛（两轮仿真和一轮真实世界），包含17种双臂操作任务。

Result: 挑战赛吸引了64支全球团队和400多名参与者，产生了如SEM和AnchorDP3等高性能解决方案，并提供了通用双臂策略学习的关键见解。

Conclusion: 比赛为未来研究提供了关于稳健和通用双臂操作策略的宝贵数据，并指明了未来研究方向。

Abstract: Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in
robotics, driven by the need for autonomous systems that can perceive, reason,
and act in complex physical environments. While single-arm systems have shown
strong task performance, collaborative dual-arm systems are essential for
handling more intricate tasks involving rigid, deformable, and
tactile-sensitive objects. To advance this goal, we launched the RoboTwin
Dual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on
the RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot
platform, the competition consisted of three stages: Simulation Round 1,
Simulation Round 2, and a final Real-World Round. Participants totally tackled
17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based
scenarios. The challenge attracted 64 global teams and over 400 participants,
producing top-performing solutions like SEM and AnchorDP3 and generating
valuable insights into generalizable bimanual policy learning. This report
outlines the competition setup, task design, evaluation methodology, key
findings and future direction, aiming to support future research on robust and
generalizable bimanual manipulation policies. The Challenge Webpage is
available at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.

</details>


### [140] [GS-NBV: a Geometry-based, Semantics-aware Viewpoint Planning Algorithm for Avocado Harvesting under Occlusions](https://arxiv.org/abs/2506.23369)
*Xiao'ao Song,Konstantinos Karydis*

Main category: cs.RO

TL;DR: 提出了一种基于几何和语义感知的视点规划算法，用于高效识别不规则形状水果（如牛油果）的采摘点，通过视点采样、评估和执行三步实现，验证显示100%成功率。


<details>
  <summary>Details</summary>
Motivation: 牛油果的不规则形状、重量和非结构化生长环境对自动化采摘提出了挑战，需要特定视点以实现成功采摘。

Method: 采用几何约束的视点规划算法，包括视点采样（1D圆上均匀采样四点）、评估（新采摘评分指标）和执行。

Result: 在模拟中验证，与两种先进算法对比，在严重遮挡情况下实现100%成功率。

Conclusion: 该方法高效且鲁棒，适用于复杂环境下的水果采摘。

Abstract: Efficient identification of picking points is critical for automated fruit
harvesting. Avocados present unique challenges owing to their irregular shape,
weight, and less-structured growing environments, which require specific
viewpoints for successful harvesting. We propose a geometry-based,
semantics-aware viewpoint-planning algorithm to address these challenges. The
planning process involves three key steps: viewpoint sampling, evaluation, and
execution. Starting from a partially occluded view, the system first detects
the fruit, then leverages geometric information to constrain the viewpoint
search space to a 1D circle, and uniformly samples four points to balance the
efficiency and exploration. A new picking score metric is introduced to
evaluate the viewpoint suitability and guide the camera to the next-best view.
We validate our method through simulation against two state-of-the-art
algorithms. Results show a 100% success rate in two case studies with
significant occlusions, demonstrating the efficiency and robustness of our
approach. Our code is available at https://github.com/lineojcd/GSNBV

</details>


### [141] [A Model Predictive Control Framework to Enhance Safety and Quality in Mobile Additive Manufacturing Systems](https://arxiv.org/abs/2506.23400)
*Yifei Li,Joshua A. Robbins,Guha Manogharan,Herschel C. Pangborn,Ilya Kovalenko*

Main category: cs.RO

TL;DR: 提出了一种基于模型预测控制的移动增材制造平台，以在动态环境中实现安全导航和高打印质量。


<details>
  <summary>Details</summary>
Motivation: 传统增材制造系统受限于静态设置和人工依赖，导致生产周期长和可扩展性有限。移动机器人可以提高生产灵活性，但现有系统忽视了打印质量和小型复杂部件的精度。

Method: 集成增材制造系统与移动机器人，采用模型预测控制框架，确保动态环境中的安全导航和高打印质量。

Result: 通过三个案例研究验证了系统的可行性和可靠性。

Conclusion: 移动增材制造平台能够优化生产流程，同时保证打印质量，适用于动态制造环境。

Abstract: In recent years, the demand for customized, on-demand production has grown in
the manufacturing sector. Additive Manufacturing (AM) has emerged as a
promising technology to enhance customization capabilities, enabling greater
flexibility, reduced lead times, and more efficient material usage. However,
traditional AM systems remain constrained by static setups and human worker
dependencies, resulting in long lead times and limited scalability. Mobile
robots can improve the flexibility of production systems by transporting
products to designated locations in a dynamic environment. By integrating AM
systems with mobile robots, manufacturers can optimize travel time for
preparatory tasks and distributed printing operations. Mobile AM robots have
been deployed for on-site production of large-scale structures, but often
neglect critical print quality metrics like surface roughness. Additionally,
these systems do not have the precision necessary for producing small,
intricate components. We propose a model predictive control framework for a
mobile AM platform that ensures safe navigation on the plant floor while
maintaining high print quality in a dynamic environment. Three case studies are
used to test the feasibility and reliability of the proposed systems.

</details>


### [142] [Risk-Based Filtering of Valuable Driving Situations in the Waymo Open Motion Dataset](https://arxiv.org/abs/2506.23433)
*Tim Puphal,Vipul Ramtekkar,Kenji Nishimiya*

Main category: cs.RO

TL;DR: 提出一种基于风险的过滤方法，从大规模数据中识别有价值的驾驶场景，用于改进自动驾驶软件。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶软件的改进需要富含道路用户交互的驾驶数据，但目前缺乏有效的方法从海量数据中筛选出这些有价值的情境。

Method: 使用概率风险模型检测高风险情境，包括直接交互的一阶情境和通过中介车辆传播的间接交互的二阶情境。

Result: 在Waymo Open Motion Dataset上验证，该方法能有效筛选出复杂且互补的驾驶情境，优于Kalman难度和TTP基线指标。

Conclusion: 提出的风险过滤方法显著提升了自动驾驶测试数据的质量，相关数据已开源。

Abstract: Improving automated vehicle software requires driving data rich in valuable
road user interactions. In this paper, we propose a risk-based filtering
approach that helps identify such valuable driving situations from large
datasets. Specifically, we use a probabilistic risk model to detect high-risk
situations. Our method stands out by considering a) first-order situations
(where one vehicle directly influences another and induces risk) and b)
second-order situations (where influence propagates through an intermediary
vehicle). In experiments, we show that our approach effectively selects
valuable driving situations in the Waymo Open Motion Dataset. Compared to the
two baseline interaction metrics of Kalman difficulty and Tracks-To-Predict
(TTP), our filtering approach identifies complex and complementary situations,
enriching the quality in automated vehicle testing. The risk data is made
open-source: https://github.com/HRI-EU/RiskBasedFiltering.

</details>


### [143] [MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments](https://arxiv.org/abs/2506.23514)
*Sai Krishna Ghanta,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: MGPRL是一种基于Wi-Fi信号的多机器人相对定位框架，利用高斯过程和凸包对齐实现高效定位。


<details>
  <summary>Details</summary>
Motivation: 解决GPS缺失环境下多机器人定位依赖高成本或短程传感器的问题。

Method: 使用高斯过程预测RSSI信号，并通过凸包对齐实现机器人间的相对定位。

Result: MGPRL在定位精度和计算效率上优于现有方法。

Conclusion: MGPRL为资源受限设备提供了一种无需预校准的高效定位方案，并开源了ROS实现。

Abstract: Relative localization is a crucial capability for multi-robot systems
operating in GPS-denied environments. Existing approaches for multi-robot
relative localization often depend on costly or short-range sensors like
cameras and LiDARs. Consequently, these approaches face challenges such as high
computational overhead (e.g., map merging) and difficulties in disjoint
environments. To address this limitation, this paper introduces MGPRL, a novel
distributed framework for multi-robot relative localization using convex-hull
of multiple Wi-Fi access points (AP). To accomplish this, we employ
co-regionalized multi-output Gaussian Processes for efficient Radio Signal
Strength Indicator (RSSI) field prediction and perform uncertainty-aware
multi-AP localization, which is further coupled with weighted convex hull-based
alignment for robust relative pose estimation. Each robot predicts the RSSI
field of the environment by an online scan of APs in its environment, which are
utilized for position estimation of multiple APs. To perform relative
localization, each robot aligns the convex hull of its predicted AP locations
with that of the neighbor robots. This approach is well-suited for devices with
limited computational resources and operates solely on widely available Wi-Fi
RSSI measurements without necessitating any dedicated pre-calibration or
offline fingerprinting. We rigorously evaluate the performance of the proposed
MGPRL in ROS simulations and demonstrate it with real-world experiments,
comparing it against multiple state-of-the-art approaches. The results showcase
that MGPRL outperforms existing methods in terms of localization accuracy and
computational efficiency. Finally, we open source MGPRL as a ROS package
https://github.com/herolab-uga/MGPRL.

</details>


### [144] [Online Human Action Detection during Escorting](https://arxiv.org/abs/2506.23573)
*Siddhartha Mondal,Avik Mitra,Chayan Sarkar*

Main category: cs.RO

TL;DR: 论文提出了一种新型神经网络架构，用于实时人员重识别和动作预测，以提升拥挤环境中机器人护送服务的效率。


<details>
  <summary>Details</summary>
Motivation: 现有护送机器人主要依赖导航策略，假设被护送者会顺利跟随，但在拥挤环境中常因无法理解人类动态行为而失效。

Method: 提出一种能同时进行人员重识别和动作预测的神经网络架构，动态调整机器人速度以适应被护送者行为。

Result: 在对比评估中，该系统表现出更高的效率和效果，显著提升了复杂场景下的机器人护送服务。

Conclusion: 该研究为解决拥挤环境中机器人护送问题提供了有效方案，具有实际应用潜力。

Abstract: The deployment of robot assistants in large indoor spaces has seen
significant growth, with escorting tasks becoming a key application. However,
most current escorting robots primarily rely on navigation-focused strategies,
assuming that the person being escorted will follow without issue. In crowded
environments, this assumption often falls short, as individuals may struggle to
keep pace, become obstructed, get distracted, or need to stop unexpectedly. As
a result, conventional robotic systems are often unable to provide effective
escorting services due to their limited understanding of human movement
dynamics. To address these challenges, an effective escorting robot must
continuously detect and interpret human actions during the escorting process
and adjust its movement accordingly. However, there is currently no existing
dataset designed specifically for human action detection in the context of
escorting. Given that escorting often occurs in crowded environments, where
other individuals may enter the robot's camera view, the robot also needs to
identify the specific human it is escorting (the subject) before predicting
their actions. Since no existing model performs both person re-identification
and action prediction in real-time, we propose a novel neural network
architecture that can accomplish both tasks. This enables the robot to adjust
its speed dynamically based on the escortee's movements and seamlessly resume
escorting after any disruption. In comparative evaluations against strong
baselines, our system demonstrates superior efficiency and effectiveness,
showcasing its potential to significantly improve robotic escorting services in
complex, real-world scenarios.

</details>


### [145] [Passage-traversing optimal path planning with sampling-based algorithms](https://arxiv.org/abs/2506.23614)
*Jing Huang,Hao Su,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 论文提出了一种新的最优路径规划范式PTOPP，通过优化路径通过的通道来实现特定目标，特别适用于机器人路径规划中的自由空间优化。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法在自由空间优化方面存在局限性，PTOPP旨在通过通道检测和自由空间分解解决这一问题。

Method: 提出基于邻近图的通道检测和自由空间分解方法，并开发了采样算法用于快速通道遍历检查。

Result: PTOPP在配置性、解决方案最优性和效率上显著优于现有方法（如基于间隙的方法）。

Conclusion: PTOPP为自由空间优化提供了一种高效且通用的解决方案，适用于广泛的路径规划问题。

Abstract: This paper introduces a new paradigm of optimal path planning, i.e.,
passage-traversing optimal path planning (PTOPP), that optimizes paths'
traversed passages for specified optimization objectives. In particular, PTOPP
is utilized to find the path with optimal accessible free space along its
entire length, which represents a basic requirement for paths in robotics. As
passages are places where free space shrinks and becomes constrained, the core
idea is to leverage the path's passage traversal status to characterize its
accessible free space comprehensively. To this end, a novel passage detection
and free space decomposition method using proximity graphs is proposed,
enabling fast detection of sparse but informative passages and environment
decompositions. Based on this preprocessing, optimal path planning with
accessible free space objectives or constraints is formulated as PTOPP problems
compatible with sampling-based optimal planners. Then, sampling-based
algorithms for PTOPP, including their dependent primitive procedures, are
developed leveraging partitioned environments for fast passage traversal check.
All these methods are implemented and thoroughly tested for effectiveness and
efficiency validation. Compared to existing approaches, such as clearance-based
methods, PTOPP demonstrates significant advantages in configurability, solution
optimality, and efficiency, addressing prior limitations and incapabilities. It
is believed to provide an efficient and versatile solution to accessible free
space optimization over conventional avenues and more generally, to a broad
class of path planning problems that can be formulated as PTOPP.

</details>


### [146] [Towards Universal Shared Control in Teleoperation Without Haptic Feedback](https://arxiv.org/abs/2506.23624)
*Max Grobbel,Tristan Schneider,Sören Hohmann*

Main category: cs.RO

TL;DR: 论文提出了一种通过多目标优化将用户输入转换为无碰撞UR5e关节轨迹的方法，同时抑制玻璃中液体晃动，实现了13毫秒的平均规划延迟。


<details>
  <summary>Details</summary>
Motivation: 非触觉VR控制器剥夺了操作员的运动反馈，需要一种方法来解决这一问题。

Method: 嵌入多目标优化问题，将用户输入转换为无碰撞关节轨迹并抑制液体晃动。

Result: 控制器平均规划延迟为13毫秒，证实了实时性能。

Conclusion: 该方法适用于进一步扩展其他目标的远程操作。

Abstract: Teleoperation with non-haptic VR controllers deprives human operators of
critical motion feedback. We address this by embedding a multi-objective
optimization problem that converts user input into collision-free UR5e joint
trajectories while actively suppressing liquid slosh in a glass. The controller
maintains 13 ms average planning latency, confirming real-time performance and
motivating the augmentation of this teleoperation approach to further
objectives.

</details>


### [147] [Data-Driven Predictive Planning and Control for Aerial 3D Inspection with Back-face Elimination](https://arxiv.org/abs/2506.23781)
*Savvas Papaioannou,Panayiotis Kolios,Christos G. Panayiotou,Marios M. Polycarpou*

Main category: cs.RO

TL;DR: 提出了一种基于数据驱动预测控制的3D检测方法，统一了感知、规划与控制，适用于现成的黑盒无人机系统。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将感知、规划和控分离，且缺乏长时程规划能力，无法满足复杂检测任务的需求。

Method: 采用数据驱动预测控制框架，结合3D计算机图形学中的背面消除技术，实现在线生成精确的长时程3D检测轨迹。

Result: 该方法无需已知无人机动态模型，仅需输入输出数据，适用于黑盒无人机系统。

Conclusion: 提出的方法解决了现有技术的局限性，为无人机自动检测任务提供了更高效、灵活的解决方案。

Abstract: Automated inspection with Unmanned Aerial Systems (UASs) is a transformative
capability set to revolutionize various application domains. However, this task
is inherently complex, as it demands the seamless integration of perception,
planning, and control which existing approaches often treat separately.
Moreover, it requires accurate long-horizon planning to predict action
sequences, in contrast to many current techniques, which tend to be myopic. To
overcome these limitations, we propose a 3D inspection approach that unifies
perception, planning, and control within a single data-driven predictive
control framework. Unlike traditional methods that rely on known UAS dynamic
models, our approach requires only input-output data, making it easily
applicable to off-the-shelf black-box UASs. Our method incorporates back-face
elimination, a visibility determination technique from 3D computer graphics,
directly into the control loop, thereby enabling the online generation of
accurate, long-horizon 3D inspection trajectories.

</details>


### [148] [A comprehensive control architecture for semi-autonomous dual-arm robots in agriculture settings](https://arxiv.org/abs/2506.23723)
*Jozsef Palmieri,Paolo Di Lillo,Stefano Chiaverini,Alessandro Marino*

Main category: cs.RO

TL;DR: 本文提出了一种用于复杂农业环境的移动机器人控制架构，采用分层二次规划（HQP）方法，支持自主和半自主葡萄采摘任务。


<details>
  <summary>Details</summary>
Motivation: 在农业环境中，移动机器人需要灵活且高效的架构来整合感知与控制，以完成多任务操作，如葡萄采摘。

Method: 使用16自由度双臂移动机器人，采用HQP方法处理优先级不同的等式和不等式约束，并结合感知系统选择葡萄串。

Result: 通过实验室和实际葡萄园的测试，验证了架构在自主和半自主模式下的有效性。

Conclusion: 该架构成功实现了复杂任务的处理，并支持人机协作，为农业机器人应用提供了实用解决方案。

Abstract: The adoption of mobile robotic platforms in complex environments, such as
agricultural settings, requires these systems to exhibit a flexible yet
effective architecture that integrates perception and control. In such
scenarios, several tasks need to be accomplished simultaneously, ranging from
managing robot limits to performing operational tasks and handling human
inputs. The purpose of this paper is to present a comprehensive control
architecture for achieving complex tasks such as robotized harvesting in
vineyards within the framework of the European project CANOPIES. In detail, a
16-DOF dual-arm mobile robot is employed, controlled via a Hierarchical
Quadratic Programming (HQP) approach capable of handling both equality and
inequality constraints at various priorities to harvest grape bunches selected
by the perception system developed within the project. Furthermore, given the
complexity of the scenario and the uncertainty in the perception system, which
could potentially lead to collisions with the environment, the handling of
interaction forces is necessary. Remarkably, this was achieved using the same
HQP framework. This feature is further leveraged to enable semi-autonomous
operations, allowing a human operator to assist the robotic counterpart in
completing harvesting tasks. Finally, the obtained results are validated
through extensive testing conducted first in a laboratory environment to prove
individual functionalities, then in a real vineyard, encompassing both
autonomous and semi-autonomous grape harvesting operations.

</details>


### [149] [PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?](https://arxiv.org/abs/2506.23725)
*Atharva Gundawar,Som Sagar,Ransalu Senanayake*

Main category: cs.RO

TL;DR: PAC Bench是一个评估视觉语言模型（VLMs）在物理属性、功能性和约束理解上的基准测试，揭示了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在机器人操作任务中广泛应用，但其对低层物理前提的理解尚未验证，可能影响可靠性。

Method: 引入PAC Bench，包含多样化的数据集和任务，系统评估VLMs对物理概念的理解。

Result: 评估显示当前VLMs在基础物理概念理解上存在显著不足。

Conclusion: PAC Bench为VLM的物理推理能力提供了标准化评估，并指导开发更鲁棒的模型。

Abstract: Vision-Language Models (VLMs) are increasingly pivotal for generalist robot
manipulation, enabling tasks such as physical reasoning, policy generation, and
failure detection. However, their proficiency in these high-level applications
often assumes a deep understanding of low-level physical prerequisites, a
capability that remains largely unverified. For robots to perform actions
reliably, they must comprehend intrinsic object properties (e.g., material,
weight), action affordances (e.g., graspable, stackable), and physical
constraints (e.g., stability, reachability, or an object's state, such as being
closed). Despite the widespread use of VLMs in manipulation tasks, we argue
that off-the-shelf models may lack this granular, physically grounded
understanding, as such prerequisites are often overlooked during training.
  To address this critical gap, we introduce PAC Bench, a comprehensive
benchmark designed to systematically evaluate VLMs on their understanding of
core Properties, Affordances, and Constraints (PAC) from a task executability
perspective. PAC Bench features a diverse dataset with over 30,000 annotations,
comprising 673 real-world images (115 object classes, 15 property types, and 1
to 3 affordances defined per class), 100 real-world humanoid-view scenarios,
and 120 unique simulated constraint scenarios across four tasks.
  Our evaluations reveal significant gaps in the ability of current VLMs to
grasp fundamental physical concepts, highlighting limitations in their
suitability for reliable robot manipulation and pointing to key areas for
targeted research. PAC Bench also serves as a standardized benchmark for
rigorously evaluating physical reasoning in VLMs and guiding the development of
more robust, physically grounded models for robotic applications.
  Project Page: https://pacbench.github.io/

</details>


### [150] [Validation of AI-Based 3D Human Pose Estimation in a Cyber-Physical Environment](https://arxiv.org/abs/2506.23739)
*Lisa Marie Otto,Michael Kaiser,Daniel Seebacher,Steffen Müller*

Main category: cs.RO

TL;DR: 本文提出了一种结合车辆在环测试台和运动实验室的测试环境，用于验证车辆与行人及骑行者之间的交互，通过比较真实世界和虚拟环境中的姿态估计，评估了感知技术的准确性。


<details>
  <summary>Details</summary>
Motivation: 确保自动驾驶系统与城市环境中的弱势道路使用者（VRUs）之间的安全、真实交互，需要先进的测试方法。

Method: 结合车辆在环测试台和运动实验室，利用虚幻引擎5生成虚拟场景，实时投影VRUs动画以刺激摄像头，通过单目摄像头AI进行3D骨骼检测，比较真实与虚拟环境中的姿态估计。

Result: 结果显示，在稳定运动模式下，真实与虚拟环境中的姿态估计高度一致，但在动态运动和遮挡情况下，特别是复杂骑行者姿态，仍存在显著误差。

Conclusion: 研究为改进下一代基于AI的车辆感知测试方法提供了依据，并优化了自动驾驶车辆与VRUs在虚拟环境中的交互模型。

Abstract: Ensuring safe and realistic interactions between automated driving systems
and vulnerable road users (VRUs) in urban environments requires advanced
testing methodologies. This paper presents a test environment that combines a
Vehiclein-the-Loop (ViL) test bench with a motion laboratory, demonstrating the
feasibility of cyber-physical (CP) testing of vehicle-pedestrian and
vehicle-cyclist interactions. Building upon previous work focused on pedestrian
localization, we further validate a human pose estimation (HPE) approach
through a comparative analysis of real-world (RW) and virtual representations
of VRUs. The study examines the perception of full-body motion using a
commercial monocular camera-based 3Dskeletal detection AI. The virtual scene is
generated in Unreal Engine 5, where VRUs are animated in real time and
projected onto a screen to stimulate the camera. The proposed stimulation
technique ensures the correct perspective, enabling realistic vehicle
perception. To assess the accuracy and consistency of HPE across RW and CP
domains, we analyze the reliability of detections as well as variations in
movement trajectories and joint estimation stability. The validation includes
dynamic test scenarios where human avatars, both walking and cycling, are
monitored under controlled conditions. Our results show a strong alignment in
HPE between RW and CP test conditions for stable motion patterns, while notable
inaccuracies persist under dynamic movements and occlusions, particularly for
complex cyclist postures. These findings contribute to refining CP testing
approaches for evaluating next-generation AI-based vehicle perception and to
enhancing interaction models of automated vehicles and VRUs in CP environments.

</details>


### [151] [Motion Tracking with Muscles: Predictive Control of a Parametric Musculoskeletal Canine Model](https://arxiv.org/abs/2506.23768)
*Vittorio La Barbera,Steven Bohez,Leonard Hasenclever,Yuval Tassa,John R. Hutchinson*

Main category: cs.RO

TL;DR: 提出了一种基于3D肌肉网格的狗骨骼肌肉模型，结合运动捕捉任务和改进的肌肉动力学模型，验证了模拟肌肉激活模式与实验数据的匹配性。


<details>
  <summary>Details</summary>
Motivation: 填补生物力学、机器人和计算神经科学之间的研究空白，为肌肉驱动和神经肌肉控制研究提供平台。

Method: 使用程序生成的3D肌肉网格构建骨骼肌肉模型，结合运动捕捉任务和改进的肌肉动力学模型。

Result: 模拟的肌肉激活模式与实验EMG数据一致，验证了模型的有效性。

Conclusion: 该模型为相关研究提供了可靠工具，未来将公开模型和运动捕捉数据以促进研究。

Abstract: We introduce a novel musculoskeletal model of a dog, procedurally generated
from accurate 3D muscle meshes. Accompanying this model is a motion
capture-based locomotion task compatible with a variety of control algorithms,
as well as an improved muscle dynamics model designed to enhance convergence in
differentiable control frameworks. We validate our approach by comparing
simulated muscle activation patterns with experimentally obtained
electromyography (EMG) data from previous canine locomotion studies. This work
aims to bridge gaps between biomechanics, robotics, and computational
neuroscience, offering a robust platform for researchers investigating muscle
actuation and neuromuscular control.We plan to release the full model along
with the retargeted motion capture clips to facilitate further research and
development.

</details>


### [152] [Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving](https://arxiv.org/abs/2506.23771)
*Guizhe Jin,Zhuoren Li,Bo Leng,Ran Yu,Lu Xiong*

Main category: cs.RO

TL;DR: 提出了一种多时间尺度分层强化学习方法，用于自动驾驶，通过统一训练高低层策略，分别生成长期运动指导和短期控制命令，显著提升驾驶效率、行为一致性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的自动驾驶方法多忽视策略结构设计，导致短期控制命令波动或长期目标无法统一优化驾驶行为与控制。

Method: 采用分层策略结构，统一训练高低层强化学习策略，分别输出长期运动指导和短期控制命令，并设计分层安全机制。

Result: 在模拟器和HighD数据集的高速公路多车道场景中验证，显著提升自动驾驶性能，提高效率、行为一致性和安全性。

Conclusion: 多时间尺度分层强化学习方法有效解决了自动驾驶中策略结构设计不足的问题，实现了驾驶行为与控制的统一优化。

Abstract: Reinforcement Learning (RL) is increasingly used in autonomous driving (AD)
and shows clear advantages. However, most RL-based AD methods overlook policy
structure design. An RL policy that only outputs short-timescale vehicle
control commands results in fluctuating driving behavior due to fluctuations in
network outputs, while one that only outputs long-timescale driving goals
cannot achieve unified optimality of driving behavior and control. Therefore,
we propose a multi-timescale hierarchical reinforcement learning approach. Our
approach adopts a hierarchical policy structure, where high- and low-level RL
policies are unified-trained to produce long-timescale motion guidance and
short-timescale control commands, respectively. Therein, motion guidance is
explicitly represented by hybrid actions to capture multimodal driving
behaviors on structured road and support incremental low-level extend-state
updates. Additionally, a hierarchical safety mechanism is designed to ensure
multi-timescale safety. Evaluation in simulator-based and HighD dataset-based
highway multi-lane scenarios demonstrates that our approach significantly
improves AD performance, effectively increasing driving efficiency, action
consistency and safety.

</details>


### [153] [World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation](https://arxiv.org/abs/2506.23919)
*Haonan Chen,Bangjun Wang,Jingxiang Guo,Tianrui Zhang,Yiwen Hou,Xuchuan Huang,Chenrui Tie,Lin Shao*

Main category: cs.RO

TL;DR: 提出了一种利用预训练多模态图像生成模型作为世界模型来指导策略学习的新框架，实现了无需任务特定训练的高效通用机器人操作。


<details>
  <summary>Details</summary>
Motivation: 提高机器人操作的数据效率和泛化能力是核心挑战。

Method: 利用预训练多模态图像生成模型生成开放式的未来状态预测，结合零样本低级控制模块实现通用操作。

Result: 在仿真和真实环境中验证了方法在多种操作任务中的有效性，无需额外数据收集或微调。

Conclusion: 该方法为通用机器人操作提供了一种高效且泛化能力强的解决方案。

Abstract: Improving data efficiency and generalization in robotic manipulation remains
a core challenge. We propose a novel framework that leverages a pre-trained
multimodal image-generation model as a world model to guide policy learning. By
exploiting its rich visual-semantic representations and strong generalization
across diverse scenes, the model generates open-ended future state predictions
that inform downstream manipulation. Coupled with zero-shot low-level control
modules, our approach enables general-purpose robotic manipulation without
task-specific training. Experiments in both simulation and real-world
environments demonstrate that our method achieves effective performance across
a wide range of manipulation tasks with no additional data collection or
fine-tuning. Supplementary materials are available on our website:
https://world4omni.github.io/.

</details>


### [154] [Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning](https://arxiv.org/abs/2506.23944)
*Fuhang Kuang,Jiacheng You,Yingdong Hu,Tong Zhang,Chuan Wen,Yang Gao*

Main category: cs.RO

TL;DR: 论文提出了一种解决模仿学习中本体感觉偏移问题的方法，通过域适应框架和Wasserstein距离对齐训练与部署分布。


<details>
  <summary>Details</summary>
Motivation: 模仿学习中直接使用所有本体感觉状态会导致性能下降，原因是训练与部署时本体感觉分布存在显著差异。

Method: 提出域适应框架，利用部署时的滚动数据，通过Wasserstein距离量化差异，并添加噪声对齐分布。

Result: 实验表明该方法优于直接丢弃本体感觉或其他基线方法，能有效利用本体感觉并减少负面影响。

Conclusion: 该方法解决了本体感觉偏移问题，提升了模仿学习在机器人任务中的性能。

Abstract: Imitation learning models for robotic tasks typically rely on multi-modal
inputs, such as RGB images, language, and proprioceptive states. While
proprioception is intuitively important for decision-making and obstacle
avoidance, simply incorporating all proprioceptive states leads to a surprising
degradation in imitation learning performance. In this work, we identify the
underlying issue as the proprioception shift problem, where the distributions
of proprioceptive states diverge significantly between training and deployment.
To address this challenge, we propose a domain adaptation framework that
bridges the gap by utilizing rollout data collected during deployment. Using
Wasserstein distance, we quantify the discrepancy between expert and rollout
proprioceptive states and minimize this gap by adding noise to both sets of
states, proportional to the Wasserstein distance. This strategy enhances
robustness against proprioception shifts by aligning the training and
deployment distributions. Experiments on robotic manipulation tasks demonstrate
the efficacy of our method, enabling the imitation policy to leverage
proprioception while mitigating its adverse effects. Our approach outperforms
the naive solution which discards proprioception, and other baselines designed
to address distributional shifts.

</details>


### [155] [Predictive Risk Analysis and Safe Trajectory Planning for Intelligent and Connected Vehicles](https://arxiv.org/abs/2506.23999)
*Zeyu Han,Mengchi Cai,Chaoyi Chen,Qingwen Meng,Guangwei Wang,Ying Liu,Qing Xu,Jianqiang Wang,Keqiang Li*

Main category: cs.RO

TL;DR: 提出了一种基于预测风险分析的智能网联车辆安全轨迹规划框架，结合未来预测和实时风险分析，通过仿真和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有风险评估理论仅基于当前信息，忽略了未来预测，无法满足智能网联车辆安全轨迹规划的需求。

Method: 提出一个框架，先通过局部风险感知算法预测物体未来轨迹，再使用时空间离散化的预测风险分析，最后生成安全轨迹。

Result: 仿真和车辆实验证实了该方法的有效性和实时实用性。

Conclusion: 该框架通过结合未来预测和风险分析，显著提升了智能网联车辆的安全轨迹规划能力。

Abstract: The safe trajectory planning of intelligent and connected vehicles is a key
component in autonomous driving technology. Modeling the environment risk
information by field is a promising and effective approach for safe trajectory
planning. However, existing risk assessment theories only analyze the risk by
current information, ignoring future prediction. This paper proposes a
predictive risk analysis and safe trajectory planning framework for intelligent
and connected vehicles. This framework first predicts future trajectories of
objects by a local risk-aware algorithm, following with a
spatiotemporal-discretised predictive risk analysis using the prediction
results. Then the safe trajectory is generated based on the predictive risk
analysis. Finally, simulation and vehicle experiments confirm the efficacy and
real-time practicability of our approach.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [156] [A Multi-Criteria Evaluation Framework for Siting Fusion Energy Facilities: Application and Evaluation of U.S. Coal Power Plants](https://arxiv.org/abs/2506.22489)
*Muhammad R. Abdussami,Kevin Daley,Gabrielle Hoelzle,Aditi Verma*

Main category: eess.SY

TL;DR: 本文提出了一种综合选址方法，结合专家判断、地理空间数据和多准则决策工具，系统评估聚变能源设施的选址适宜性。以美国现有燃煤电厂为例，应用该框架评估其未来作为聚变设施的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着燃煤电厂寿命结束，其场地可能成为聚变能源设施的潜在选址，研究旨在提供一种透明且可扩展的决策支持工具。

Method: 采用22项选址标准，结合模糊完全一致性方法（F-FUCOM）确定权重，加权求和法（WSM）进行场地排序。

Result: 通过案例研究，展示了该框架在评估燃煤电厂场地作为聚变设施选址的适用性。

Conclusion: 该研究为聚变能源设施的选址提供了系统化、透明的决策支持工具。

Abstract: This paper proposes a comprehensive methodology for siting fusion energy
facilities, integrating expert judgment, geospatial data, and multi-criteria
decision making tools to evaluate site suitability systematically. As a case
study, we apply this framework to all currently operational coal power plant
sites in the United States to examine their potential for hosting future fusion
facilities at a time when these coal plants are shut down on reaching their end
of life - timelines which are expected to coincide with the potential
deployment of fusion energy facilities. Drawing on 22 siting criteria -
including state and federal policies, risk and hazard assessments, and spatial
and infrastructural parameters - we implement two MultiCriteria Decision-Making
(MCDM) methods: the Fuzzy Full Consistency Method (F-FUCOM) to derive attribute
weights and the Weighted Sum Method (WSM) to rank sites based on composite
suitability scores. By focusing on fusion-specific siting needs and
demonstrating the framework through a coal site application, this study
contributes a scalable and transparent decision-support tool for identifying
optimal fusion energy deployment locations.

</details>


### [157] [Data-Efficient Excavation Force Estimation for Wheel Loaders](https://arxiv.org/abs/2506.22579)
*Armin Abdolmohammadi,Navid Mojahed,Shima Nazari,Bahram Ravani*

Main category: eess.SY

TL;DR: 提出了一种基于数据高效框架的挖掘力预测方法，通过校准土壤参数实现自适应控制。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量数据或模拟，限制了可扩展性和适应性。

Method: 利用前一次铲装周期的力数据校准土壤参数，采用多阶段优化策略。

Result: 在高保真模拟中验证，预测误差为10%至15%。

Conclusion: 该方法展示了在线和可扩展的高效路径规划潜力。

Abstract: Accurate excavation force prediction is essential for enabling autonomous
operation and optimizing control strategies in earthmoving machinery.
Conventional methods typically require extensive data collection or simulations
across diverse soil types, limiting scalability and adaptability. This paper
proposes a data-efficient framework that calibrates soil parameters using force
data from the prior bucket-loading cycle. Leveraging an analytical soil-tool
interaction model, the fundamental earthmoving equation (FEE), our approach
uses a multi-stage optimization strategy, on soil parameters during the loading
phase. These fitted parameters are then used to predict excavation forces in
the upcoming digging cycle, allowing the system to adapt its control inputs
without the need for extensive data collection or machine learning-based model
training. The framework is validated in high-fidelity simulations using the
Algoryx Dynamics engine, across multiple soil types and excavation
trajectories, demonstrating accurate force predictions with root-mean-square
errors of 10\% to 15\% in primary test cases. This cycle-to-cycle adaptation
strategy showcases the potential for online and scalable efficient path
planning for wheel loader operations.

</details>


### [158] [QoS-aware State-Augmented Learnable Algorithm for Wireless Coexistence Parameter Management](https://arxiv.org/abs/2506.22652)
*Mohammad Reza Fasihi,Brian L. Mark*

Main category: eess.SY

TL;DR: 提出了一种基于状态增强约束强化学习的无线共存参数管理框架QaSAL-CPM，用于优化5G NR-U和Wi-Fi的共存问题。


<details>
  <summary>Details</summary>
Motivation: 解决5G NR-U和Wi-Fi在非授权频谱中的高效公平共存问题。

Method: 采用状态增强约束强化学习，将双变量嵌入观察空间，实时响应约束违反并优化性能目标。

Result: 在模拟中，QaSAL-CPM实现了可靠的QoS合规性和更强的策略鲁棒性。

Conclusion: 该框架为下一代无线网络的实时共存优化提供了可扩展和自适应的解决方案。

Abstract: Efficient and fair coexistence in unlicensed spectrum is essential to support
heterogeneous networks such as 5G NR-U and Wi-Fi, which often contend for
shared wireless resources. We introduce a general framework for wireless
Coexistence Parameter Management (CPM) based on state-augmented constrained
reinforcement learning. We propose a novel algorithm, QaSAL-CPM, which
incorporates state-augmentation by embedding the dual variables in the
constrained optimization formulation directly into the agent's observation
space. This method enables the agent to respond to constraint violations in
real time while continuing to optimize a primary performance objective. Through
extensive simulations of 5G NR-U and Wi-Fi coexistence scenarios, we show that
QaSAL-CPM achieves reliable QoS compliance and improved policy robustness
across various transmitter densities compared to previous approaches. The
proposed framework offers a scalable and adaptive solution for real-time
coexistence optimization in next-generation wireless networks.

</details>


### [159] [A Correlation-Based Design of RIS for Reduced Power Consumption and Simplified Control Circuitry](https://arxiv.org/abs/2506.22702)
*Zina Mohamed,Ammar B. Kouki,Sonia Aïssa*

Main category: eess.SY

TL;DR: 提出了一种基于相关性的新型RIS设计（Connected-RIS），通过共享控制信号简化硬件结构并降低能耗。


<details>
  <summary>Details</summary>
Motivation: 简化无线通信中的硬件结构和降低能耗，特别是在可重构智能表面（RIS）的应用中。

Method: 通过分析表面元素相位偏移值的相关性，设计Connected-RIS，共享控制信号，减少负载阻抗和控制信号数量。

Result: 显著降低功耗（86-92%）和控制信号数量（83-98%），同时保持足够的通信性能。

Conclusion: Connected-RIS设计在降低硬件成本和能耗方面具有显著优势，适用于无线通信系统。

Abstract: Aiming at simplifying the hardware structure and reducing the energy
consumption in wireless communication via reconfigurable intelligent surfaces
(RIS), this paper introduces a novel RIS design founded on the correlation
between the phase shift values of the surface elements. First, a correlation
analysis is conducted, considering the azimuth angle of a target device within
a coverage region spanning from $-80^{\circ}$ to $80^{\circ}$. The correlation
is demonstrated for different deployment cases, creating the basis for the new
RIS structure, termed Connected-RIS, where correlated elements are designed to
share the same control signal. The fundamental performance of the proposed
design is then analyzed in terms of control signals, power consumption, and
communication system performance, comparing it to two RIS structures with full
control: one with the same size as the proposed design, and the other employing
the minimum number of elements necessary to satisfy the fair coverage
criterion. The correlation-based RIS design enables three-dimensional passive
beamforming and significantly reduces the number of required load impedances
and control signals, thereby lowering the hardware cost and simplifying the
control circuitry. It also achieves substantial power savings as compared to
the baseline schemes, while maintaining sufficient gain for a fair radio
coverage. For instance, numerical simulations demonstrate that the proposed
design reduces the power consumption by almost 86-92\% and the control signals
by 83-98\% compared to operation with fully controlled RIS.

</details>


### [160] [X-pSRAM: A Photonic SRAM with Embedded XOR Logic for Ultra-Fast In-Memory Computing](https://arxiv.org/abs/2506.22707)
*Md Abdullah-Al Kaiser,Sugeet Sunder,Ajey P. Jacob,Akhilesh R. Jaiswal*

Main category: eess.SY

TL;DR: 论文提出了一种新型差分光子静态随机存取存储器（pSRAM）比特单元，通过光域实现超快数据存储和布尔异或（XOR）计算，显著提升计算速度和能效。


<details>
  <summary>Details</summary>
Motivation: 传统冯·诺依曼架构因数据在内存和处理单元间频繁移动而面临性能和能效瓶颈，光子内存计算利用光的优势提供了一种高效替代方案。

Method: 采用交叉耦合微环谐振器和差分光电二极管设计X-pSRAM比特单元，支持光域内的超快读写和计算，并利用波分复用（WDM）实现单次多比特XOR计算。

Result: X-pSRAM在GlobalFoundries 45SPCLO节点上验证，实现10 GHz操作，每比特XOR计算能耗为13.2 fJ。

Conclusion: X-pSRAM为下一代光学计算在密码学、超维计算和神经网络等领域的应用提供了重要进展。

Abstract: Traditional von Neumann architectures suffer from fundamental bottlenecks due
to continuous data movement between memory and processing units, a challenge
that worsens with technology scaling as electrical interconnect delays become
more significant. These limitations impede the performance and energy
efficiency required for modern data-intensive applications. In contrast,
photonic in-memory computing presents a promising alternative by harnessing the
advantages of light, enabling ultra-fast data propagation without
length-dependent impedance, thereby significantly reducing computational
latency and energy consumption. This work proposes a novel differential
photonic static random access memory (pSRAM) bitcell that facilitates
electro-optic data storage while enabling ultra-fast in-memory Boolean XOR
computation. By employing cross-coupled microring resonators and differential
photodiodes, the XOR-augmented pSRAM (X-pSRAM) bitcell achieves at least 10 GHz
read, write, and compute operations entirely in the optical domain.
Additionally, wavelength-division multiplexing (WDM) enables n-bit XOR
computation in a single-shot operation, supporting massively parallel
processing and enhanced computational efficiency. Validated on GlobalFoundries'
45SPCLO node, the X-pSRAM consumed 13.2 fJ energy per bit for XOR computation,
representing a significant advancement toward next-generation optical computing
with applications in cryptography, hyperdimensional computing, and neural
networks.

</details>


### [161] [Online Coreset Selection for Learning Dynamic Systems](https://arxiv.org/abs/2506.22804)
*Jingyuan Li,Dawei Shi,Ling Shi*

Main category: eess.SY

TL;DR: 提出了一种在线核心集选择方法，用于动态系统中高效选择信息数据，以提高数据效率并确保收敛性。


<details>
  <summary>Details</summary>
Motivation: 动态系统中流数据的增加使得数据驱动建模面临如何高效选择信息数据的挑战。

Method: 设计了基于集合成员识别的在线核心集选择方法，利用堆叠多面体表示和几何选择准则，并通过在线双描述约束简化计算。

Result: 分析了核心集的收敛性，并推导了选择概率和核心集数据数量的上界，仿真验证了方法的有效性。

Conclusion: 提出的方法在提高数据效率和保证收敛性方面表现良好。

Abstract: With the increasing availability of streaming data in dynamic systems, a
critical challenge in data-driven modeling for control is how to efficiently
select informative data to characterize system dynamics. In this work, we
design an online coreset selection method under the framework of set-membership
identification for systems subject to process disturbances, with the objective
of improving data efficiency while ensuring convergence guarantees.
Specifically, we first propose a stacked polyhedral representation that
over-approximates the feasible set of system parameters. Leveraging a
generalized Gr\"unbaum's inequality, we design a geometric selection criterion
for constructing the coreset. To reduce computational complexity, an online
double-description-based constraint reduction method is introduced to simplify
the polyhedral representation. Finally, we analyze the convergence of the
feasible set with respect to the coreset and derive upper bounds on the
selection probability and the expected number of data in the coreset. The
effectiveness of the proposed method is demonstrated through comprehensive
simulation studies.

</details>


### [162] [Momentum-based Accelerated Algorithm for Distributed Optimization under Sector-Bound Nonlinearity](https://arxiv.org/abs/2506.22855)
*Mohammadreza Doostmohammadian,Hamid R. Rabiee*

Main category: eess.SY

TL;DR: 本文提出了一种基于加速共识的分布式优化算法，结合梯度追踪技术，适用于局部非凸优化问题。通过引入动量（heavy-ball方法）和权重平衡网络设计，提高了收敛速度并处理了网络中的非线性问题。


<details>
  <summary>Details</summary>
Motivation: 分布式优化在并行和去中心化学习中具有优势，但现有方法在局部非凸优化和动态网络环境下表现不足。本文旨在解决这些问题。

Method: 提出了一种结合梯度追踪和动量加速的算法，并采用权重平衡网络设计，通过扰动理论和特征谱分析证明其收敛性。

Result: 算法在存在非线性映射和局部非凸成本函数的情况下仍能收敛，适用于动态有向网络。

Conclusion: 该算法在分布式优化中表现出高效性和鲁棒性，适用于实际应用中的动态网络环境。

Abstract: Distributed optimization advances centralized machine learning methods by
enabling parallel and decentralized learning processes over a network of
computing nodes. This work provides an accelerated consensus-based distributed
algorithm for locally non-convex optimization using the gradient-tracking
technique. The proposed algorithm (i) improves the convergence rate by adding
momentum towards the optimal state using the heavy-ball method, while (ii)
addressing general sector-bound nonlinearities over the information-sharing
network. The link nonlinearity includes any sign-preserving odd sector-bound
mapping, for example, log-scale data quantization or clipping in practical
applications. For admissible momentum and gradient-tracking parameters, using
perturbation theory and eigen-spectrum analysis, we prove convergence even in
the presence of sector-bound nonlinearity and for locally non-convex cost
functions. Further, in contrast to most existing weight-stochastic algorithms,
we adopt weight-balanced (WB) network design. This WB design and
perturbation-based analysis allow to handle dynamic directed network of agents
to address possible time-varying setups due to link failures or packet drops.

</details>


### [163] [Identification of Cellular Automata on Spaces of Bernoulli Probability Measures](https://arxiv.org/abs/2506.22867)
*Faizal Hafiz,Amelia Kunze,Enrico Formenti,Davide La Torre*

Main category: eess.SY

TL;DR: 论文提出了一种基于概率度量的细胞自动机（CAMs）框架，用于建模具有不确定性的系统，并通过自适应差分进化算法（SaDE）解决局部规则识别问题。


<details>
  <summary>Details</summary>
Motivation: 传统细胞自动机（CCAs）在建模具有不确定性的系统时存在局限性，因此研究转向概率度量的细胞自动机（CAMs）。

Method: 将局部规则识别问题转化为参数估计问题，并提出基于自适应差分进化（SaDE）的元启发式搜索方法。

Result: 方法在二维CAMs中成功识别了不同邻域类型和半径的局部规则。

Conclusion: CAMs框架和SaDE算法为建模和识别具有不确定性的系统提供了有效工具。

Abstract: Classical Cellular Automata (CCAs) are a powerful computational framework for
modeling global spatio-temporal dynamics with local interactions. While CCAs
have been applied across numerous scientific fields, identifying the local rule
that governs observed dynamics remains a challenging task. Moreover, the
underlying assumption of deterministic cell states often limits the
applicability of CCAs to systems characterized by inherent uncertainty. This
study, therefore, focuses on the identification of Cellular Automata on spaces
of probability measures (CAMs), where cell states are represented by
probability distributions. This framework enables the modeling of systems with
probabilistic uncertainty and spatially varying dynamics. Moreover, we
formulate the local rule identification problem as a parameter estimation
problem and propose a meta-heuristic search based on Self-adaptive Differential
Evolution (SaDE) to estimate local rule parameters accurately from the observed
data. The efficacy of the proposed approach is demonstrated through local rule
identification in two-dimensional CAMs with varying neighborhood types and
radii.

</details>


### [164] [Real-Time Energy Management Strategies for Community Microgrids](https://arxiv.org/abs/2506.22931)
*Moslem Uddin,Huadong Mo,Daoyi Dong*

Main category: eess.SY

TL;DR: 提出了一种混合社区微电网的实时能源管理框架，结合光伏、风能、电池储能、柴油发电机和电网互联，通过多目标优化降低运营成本。比较了基于规则的常规控制（RBC）和深度强化学习（DRL-PPO）两种策略，结果显示DRL-PPO在成本、碳排放和可靠性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决混合社区微电网的能源管理问题，优化运营成本并提高可再生能源利用率。

Method: 采用多目标优化方法，比较基于规则的常规控制（RBC）和深度强化学习（DRL-PPO）两种策略。

Result: DRL-PPO比RBC降低运营成本18%、碳排放20%，可靠性提高87.5%，可再生能源利用率提升13%。

Conclusion: DRL-PPO方法在微电网运营中表现出高效性和可靠性，尤其适用于偏远地区。

Abstract: This study presents a real-time energy management framework for hybrid
community microgrids integrating photovoltaic, wind, battery energy storage
systems, diesel generators, and grid interconnection. The proposed approach
formulates the dispatch problem as a multi-objective optimization task that
aims to minimize operational costs. Two control strategies are proposed and
evaluated: a conventional rule-based control (RBC) method and an advanced deep
reinforcement learning (DRL) approach utilizing proximal policy optimization
(PPO). A realistic case study based on Australian load and generation profiles
is used to validate the framework. Simulation results demonstrate that DRL-PPO
reduces operational costs by 18%, CO_2 emissions by 20%, and improves system
reliability by 87.5% compared to RBC. Beside, DRL-PPO increases renewable
energy utilization by 13%, effectively reducing dependence on diesel generation
and grid imports. These findings demonstrate the potential of DRL-based
approaches to enable cost-effective and resilient microgrid operations,
particularly in regional and remote communities.

</details>


### [165] [Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems](https://arxiv.org/abs/2506.22971)
*Kesav Kazam Ramachandran Anantharaman,Rahul Meshram*

Main category: eess.SY

TL;DR: 论文提出了一种两时间尺度的分层分散控制架构，用于网络物理系统的控制，包括全局控制器和局部控制器，分别采用无限和有限时间范围的MDP优化框架。


<details>
  <summary>Details</summary>
Motivation: 解决网络物理系统中多时间尺度控制的复杂性问题，提供灵活性和自主性。

Method: 采用分层架构，全局控制器优化无限时间范围MDP，局部控制器采用COpt（无限时间范围）和FOpt（有限时间范围）两种优化框架。

Result: 证明了两种框架下存在确定性最优策略，并研究了它们之间的关系，包括最优值函数差异的界限。

Conclusion: FOpt框架赋予局部控制器更多自主权，且在特定条件下两种框架的最优值相同。

Abstract: This paper presents a two-timescale hierarchical decentralized architecture
for control of Cyber-Physical Systems. The architecture consists of $N$
independent sub-processes, a global controller, and $N$ local controllers, each
formulated as a Markov Decision Process (MDP). The global controller, operating
at a slower timescale optimizes the infinite-horizon discounted cumulative
reward under budget constraints. For the local controllers, operating at a
faster timescale, we propose two different optimization frameworks, namely the
COpt and FOpt. In the COpt framework, the local controller also optimizes an
infinite-horizon MDP, while in the FOpt framework, the local controller
optimizes a finite-horizon MDP. The FOpt framework mimics a federal structure,
where the local controllers have more autonomy in their decision making. First,
the existence of stationary deterministic optimal policies for both these
frameworks is established. Then, various relationships between the two
frameworks are studied, including a bound on the difference between the two
optimal value functions. Additionally, sufficiency conditions are provided such
that the two frameworks lead to the same optimal values.

</details>


### [166] [Extreme Scenario Characterization for High Renewable Energy Penetrated Power Systems over Long Time Scales](https://arxiv.org/abs/2506.23169)
*Kai Kang,Feng Liu,Yifan Su,Zhaojian Wang*

Main category: eess.SY

TL;DR: 提出了一种量化高可再生能源渗透下电力系统极端场景的方法，包括风险指标和生成极端场景的技术，验证了其对系统长期安全性的提升。


<details>
  <summary>Details</summary>
Motivation: 高可再生能源渗透的电力系统受天气影响大，面临长期电力短缺和波动问题，需有效表征极端场景。

Method: 提出独立于调度策略的风险指标，采用基于过滤的方法和GMM与蒙特卡洛模拟生成极端场景。

Result: 案例研究表明，识别并整合极端场景显著提升系统长期安全性和可靠性。

Conclusion: 该方法有效支持高可再生能源电力系统的极端场景分析与应对。

Abstract: Power systems with high renewable energy penetration are highly influenced by
weather conditions, often facing significant challenges such as persistent
power shortages and severe power fluctuations over long time scales. This paper
addresses the critical need for effective characterization of extreme scenarios
under these situations. First, novel risk indices are proposed to quantify the
severity of continuous power shortages and substantial power fluctuations over
long-term operations. These indices are independent of specific scheduling
strategies and incorporate the system's resource regulation capabilities. By
employing a filtering-based approach, the proposed indices focus on retaining
key characteristics of continuous power shortages and fluctuation events,
enabling the identification of extreme scenarios on long time scales. Secondly,
an extreme scenario generation method is developed using Gaussian mixture
models and sequential Monte Carlo simulation. Especially, this method
periodically evaluates the severity of generated scenarios based on the defined
risk indices, retaining extreme scenarios while discarding less critical ones.
Finally, case studies based on real-world data demonstrate the efficacy of the
proposed method. The results confirm that integrating the identified extreme
scenarios significantly enhances the system's ability to ensure long-term
security and reliability under high renewable energy penetration.

</details>


### [167] [Data-driven Implementations of Various Generalizations of Balanced Truncation](https://arxiv.org/abs/2506.23204)
*Umair Zulfiqar*

Main category: eess.SY

TL;DR: 本文提出了一种非侵入式的ADI框架，用于广义平衡截断方法，仅需原始传递函数的样本即可实现。


<details>
  <summary>Details</summary>
Motivation: 现有的非侵入式平衡截断方法（如基于正交的方法）虽然理论上可行，但依赖于传递函数谱分解的样本，而实际获取这些样本的方法尚不可行。因此，需要一种仅需原始传递函数样本的实用方法。

Method: 采用非侵入式的ADI框架，仅需原始传递函数的样本，无需访问原始模型的状态空间实现或谱分解样本。

Result: 提出的方法实现了广义平衡截断（如正实平衡截断、有界实平衡截断和平衡随机截断），且仅需原始传递函数的样本。

Conclusion: 该方法为非侵入式广义平衡截断提供了一种实用的实现途径，解决了现有方法依赖谱分解样本的问题。

Abstract: There exist two main frameworks for non-intrusive implementations of
approximate balanced truncation: the quadrature-based framework and the
ADI-based framework. Both approaches rely solely on samples of the transfer
function to construct truncated balanced models, eliminating the need for
access to the original model's state-space realization. Recently, the
quadrature-based framework has been extended to various generalizations of
balanced truncation, including positive-real balanced truncation, bounded-real
balanced truncation, and balanced stochastic truncation. While this extension
is theoretically nonintrusive-meaning it does not require the original
state-space realization-it depends on samples of spectral factorizations of the
transfer function. Since practical methods for obtaining such samples are
currently unavailable, this extension remains largely a theoretical
contribution. In this work, we present a non-intrusive ADI-type framework for
these generalized balanced truncation methods that requires only samples of the
original transfer function for implementation.

</details>


### [168] [Revisiting Z Transform Laplace Inversion: To Correct flaws in Signal and System Theory](https://arxiv.org/abs/2506.23242)
*Yuxin Yang,Hang Zhou,Chaojie Li,Xin Li,Yingyi Yan,Mingyang Zheng*

Main category: eess.SY

TL;DR: 本文重新审视了Z变换与逆拉普拉斯变换（L-1）的关系，指出标准推导中长期忽略的数学问题，并通过完整Bromwich路径修正了结果。


<details>
  <summary>Details</summary>
Motivation: 解决标准推导中因忽略无限弧贡献导致的不一致性问题，尤其是在间断点（如t=0）处。

Method: 通过完整Bromwich路径（包括所有边界贡献）重新评估逆拉普拉斯变换，修正Z变换与L-1的关系。

Result: 修正后的L-1与离散时间傅里叶变换（DTFT）混叠理论一致，为采样数据系统提供了更准确的建模基础。

Conclusion: 需对Z变换、逆拉普拉斯变换及阶跃函数在间断点的行为进行结构性修订，以提升采样数据系统的分析准确性。

Abstract: This paper revisits the classical formulation of the Z-transform and its
relationship to the inverse Laplace transform (L-1), originally developed by
Ragazzini in sampled-data theory. It identifies a longstanding mathematical
oversight in standard derivations, which typically neglect the contribution
from the infinite arc in the complex plane during inverse Laplace evaluation.
This omission leads to inconsistencies, especially at discontinuities such as t
= 0. By incorporating the full Bromwich contour, including all boundary
contributions, we restore internal consistency between L-1 and the Z-transform,
aligning the corrected L-1 with results from Discrete-Time Fourier Transform
(DTFT) aliasing theory. Consequently, this necessitates a structural revision
of the Z-transform, inverse Laplace transform, and the behavior of the
Heaviside step function at discontinuities, providing a more accurate
foundation for modeling and analysis of sampled-data systems.

</details>


### [169] [Joint Trajectory and Resource Optimization for HAPs-SAR Systems with Energy-Aware Constraints](https://arxiv.org/abs/2506.23248)
*Bang Huang,Kihong Park,Xiaowei Pang,Mohamed-Slim Alouini*

Main category: eess.SY

TL;DR: 本文研究了高空平台站合成孔径雷达系统的轨迹规划和资源分配的联合优化，旨在实现实时感知并节省能量。


<details>
  <summary>Details</summary>
Motivation: 支持实时感知并解决高空平台能量有限的问题，通过实时数据传输和太阳能采集提升系统可持续性。

Method: 提出动态轨迹模型，分析雷达感知、数据传输和飞行的能耗，并构建能量感知的MINLP问题，采用SCA框架求解。

Result: 仿真验证了算法的收敛性，平衡了SAR性能、通信可靠性和能量效率，并在9目标场景中验证了可行性。

Conclusion: 提出的方法在优化轨迹和资源分配方面有效，提升了HAPs-SAR系统的实用性和可持续性。

Abstract: This paper investigates the joint optimization of trajectory planning and
resource allocation for a high-altitude platform stations synthetic aperture
radar (HAPs-SAR) system. To support real-time sensing and conserve the limited
energy budget of the HAPs, the proposed framework assumes that the acquired
radar data are transmitted in real time to a ground base station for SAR image
reconstruction. A dynamic trajectory model is developed, and the power
consumption associated with radar sensing, data transmission, and circular
flight is comprehensively analyzed. In addition, solar energy harvesting is
considered to enhance system sustainability. An energy-aware mixed-integer
nonlinear programming (MINLP) problem is formulated to maximize radar beam
coverage while satisfying operational constraints. To solve this challenging
problem, a sub-optimal successive convex approximation (SCA)-based framework is
proposed, incorporating iterative optimization and finite search. Simulation
results validate the convergence of the proposed algorithm and demonstrate its
effectiveness in balancing SAR performance, communication reliability, and
energy efficiency. A final SAR imaging simulation on a 9-target lattice
scenario further confirms the practical feasibility of the proposed solution.

</details>


### [170] [Load Limiting Control for Component Life Extension](https://arxiv.org/abs/2506.23302)
*Chams Eddine Mballo,Robert Walters,Jonnalagadda V. R. Prasad*

Main category: eess.SY

TL;DR: 提出了一种新型直升机关键部件寿命延长控制方案，通过限制谐波负载和区分机动类型，提高了效率。


<details>
  <summary>Details</summary>
Motivation: 现有寿命延长控制方案忽略谐波负载引起的疲劳损伤，且无法区分机动类型，需改进。

Method: 采用负载限制控制（LLC）方案，通过优化算法、模型预测控制器和简化动力学模型计算控制裕度（CM），为飞行员提供提示。

Result: 仿真显示LLC方案能有效限制飞行中的谐波负载，飞行员经训练可在0.5秒内跟踪提示。

Conclusion: LLC方案显著提升了直升机部件的寿命延长控制效率，具有实际应用潜力。

Abstract: This paper presents the development of a novel life-extending control scheme
for critical helicopter components subjected to significant fatigue loading.
The primary objective is to synthesize a more efficient and less conservative
life-extending control scheme than those currently available in the literature.
The proposed Load Limiting Control (LLC) scheme is a viable solution that
addresses several issues that current life-extending control schemes suffer
from, such as the neglect of fatigue damage induced by the harmonic component
of loads and the inability to distinguish between aggressive and non-aggressive
maneuvers. The proposed LLC scheme treats desired harmonic load limits as limit
boundaries and recasts the problem of load limiting as a vehicle limit by
computing a Control Margin (CM) using a limit detection and avoidance module.
The computed CM is used as a cue to the pilot. The limit detection and
avoidance module comprises an optimization algorithm, a model predictive
controller, and a computationally simple on-board dynamical model. Simulations
were conducted to demonstrate the effectiveness of the LLC scheme in limiting
harmonic pitch link loads during flight. One significant outcome is that, with
sufficient training, the pilot can skillfully track the cue within 0.5 seconds
of initiating the tracking task.

</details>


### [171] [ANN-Based Grid Impedance Estimation for Adaptive Gain Scheduling in VSG Under Dynamic Grid Conditions](https://arxiv.org/abs/2506.23304)
*Quang-Manh Hoang,Van Nam Nguyen,Taehyung Kim,Guilherme Vieira Hollweg,Wencong Su,Van-Hai Bui*

Main category: eess.SY

TL;DR: 提出了一种基于人工神经网络的虚拟同步发电机自适应增益调度控制方案，以应对电网阻抗变化带来的不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 虚拟同步发电机在弱电网条件下表现良好，但在强电网下可能不稳定。电网阻抗随时间变化，需要一种自适应控制方法。

Method: 使用人工神经网络估计电网阻抗，并通过自适应增益调度函数动态调整控制器参数。

Result: 在不同电网条件下，稳定时间和超调百分比保持一致，且能高精度、低延迟地估计未知电网阻抗。

Conclusion: 该方法适用于实时增益调度控制，显著提升了虚拟同步发电机在不同电网条件下的稳定性。

Abstract: In contrast to grid-following inverters, Virtual Synchronous Generators
(VSGs) perform well under weak grid conditions but may become unstable when the
grid is strong. Grid strength depends on grid impedance, which unfortunately
varies over time. In this paper, we propose a novel adaptive gain-scheduling
control scheme for VSGs. First, an Artificial Neural Network (ANN) estimates
the fundamental-frequency grid impedance; then these estimates are fed into an
adaptive gain-scheduling function to recalculate controller parameters under
varying grid conditions. The proposed method is validated in Simulink and
compared with a conventional VSG employing fixed controller gains. The results
demonstrate that settling times and overshoot percentages remain consistent
across different grid conditions. Additionally, previously unseen grid
impedance values are estimated with high accuracy and minimal time delay,
making the approach well suited for real-time gain-scheduling control.

</details>


### [172] [Predictor-Based Compensators for Networked Control Systems with Stochastic Delays and Sampling Intervals](https://arxiv.org/abs/2506.23421)
*Matheus Wagner,Marcelo M. Morato,Antônio Augusto Fröhlich,Julio E. Normey-Rico*

Main category: eess.SY

TL;DR: 提出了一种针对线性多输入多输出网络控制系统的建模方法，并基于滤波史密斯预估器设计补偿方案，以减轻随机时延对闭环性能的不利影响。


<details>
  <summary>Details</summary>
Motivation: 网络控制系统中随机时延和采样间隔的随机性给控制器设计和分析带来挑战，导致保守设计和性能下降。

Method: 采用滤波史密斯预估器作为补偿方案，并通过数值模拟验证其在协同自适应巡航控制系统中的效果。

Result: 补偿方案实现了接近理想的平均闭环性能，显著降低了响应变异性，最坏情况跟踪误差信号能量比理想基线系统减少了45%。

Conclusion: 该补偿方案有效提升了网络控制系统在随机时延下的性能，优于传统滤波史密斯预估器。

Abstract: The stochastic nature of time delays and sampling intervals in Networked
Control Systems poses significant challenges for controller synthesis and
analysis, often leading to conservative designs and degraded performance. This
work presents a modeling approach for Linear Multiple-Input Multiple-Output
Networked Control Systems and introduces a compensation scheme based on the
Filtered Smith Predictor to mitigate the adverse effects of stochastic time
delays on closed-loop performance. The proposed scheme is evaluated through
numerical simulations of a well-established Cooperative Adaptive Cruise Control
system. Results demonstrate that the compensator achieves near-ideal average
closed-loop performance and significantly reduces response variability compared
to a traditional Filtered Smith Predictor. Notably, it yields a 45% reduction
in worst-case tracking error signal energy relative to an ideal baseline system
with no time delays and constant sampling intervals.

</details>


### [173] [Power Flow Analysis of a 5-Bus Power System Based on Newton-Raphson Method](https://arxiv.org/abs/2506.23425)
*Sampson E. Nwachukwu*

Main category: eess.SY

TL;DR: 负载流分析是电力工程师用于模拟和评估稳态条件下电力系统行为的基本技术。选择合适的求解方法对确保电力系统的可靠和经济运行至关重要。牛顿-拉夫逊方法因其二次收敛性和数值稳定性，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在展示牛顿-拉夫逊方法在电力系统负载流分析中的优势，尤其是在复杂网络中的应用。

Method: 采用牛顿-拉夫逊方法对5总线系统进行负载流分析，并使用PowerWorld Simulator和自定义MATLAB实现进行验证。

Result: 牛顿-拉夫逊方法提供了准确且稳健的解决方案，适用于评估不同运行条件下的系统性能。

Conclusion: 牛顿-拉夫逊方法因其高效性和稳定性，是电力系统负载流分析的理想选择。

Abstract: Load flow analysis is a fundamental technique used by electrical engineers to
simulate and evaluate power system behavior under steady-state conditions. It
enables efficient operation and control by determining how active and reactive
power flows throughout the system. Selecting an appropriate solution method is
critical to ensuring reliable and economical operation of power generation,
transmission, and distribution networks. While the conventional loop method may
be used in small-scale systems, it is limited by its reliance on
impedance-based load data and its inability to scale to complex networks. In
contrast, iterative techniques such as the Gauss-Seidel (GS) and Newton-Raphson
(NR) methods are better suited for analyzing large systems. Of these, the NR
method offers significant advantages due to its quadratic convergence and
improved numerical stability. This study presents a power flow analysis of a
5-bus system using the Newton-Raphson approach. The system was modeled and
simulated in PowerWorld Simulator (PWS), and a custom MATLAB implementation was
developed to verify the results under a base case scenario. The comparative
analysis demonstrates that the NR method provides accurate and robust solutions
for power flow problems, making it well-suited for evaluating system
performance under various operating conditions.

</details>


### [174] [Power-Gas Infrastructure Planning under Weather-induced Supply and Demand Uncertainties](https://arxiv.org/abs/2506.23509)
*Rahman Khorramfar,Dharik Mallapragada,Saurabh Amin*

Main category: eess.SY

TL;DR: 论文提出两种基于分布鲁棒优化的方法（MDRO和WDRO），用于电力-天然气联合基础设施规划，考虑需求和可再生能源供应的不确定性，并引入CVaR度量以反映规划者的风险规避。


<details>
  <summary>Details</summary>
Motivation: 为实现基于可再生能源和电气化的脱碳目标，需考虑天气引起的不确定性，传统规划方法可能无法应对极端天气导致的供应短缺风险。

Method: 采用基于矩（MDRO）和Wasserstein距离（WDRO）的分布鲁棒优化方法，结合CVaR度量风险规避，并转化为混合整数线性规划（MILP）求解。

Result: 通过新英格兰案例研究验证了模型的有效性，比较了DRO与随机规划（SP）的结果，展示了不同电气化和脱碳目标下的规划效果。

Conclusion: 提出的DRO方法能有效应对气候变化带来的不确定性，为低碳电网规划提供了新思路。

Abstract: Implementing economy-wide decarbonization strategies based on decarbonizing
the power grid via variable renewable energy (VRE) expansion and
electrification of end-uses requires new approaches for energy infrastructure
planning that consider, among other factors, weather-induced uncertainty in
demand and VRE supply. An energy planning model that fails to account for these
uncertainties can hinder the intended transition efforts to a low-carbon grid
and increase the risk of supply shortage especially during extreme weather
conditions. Here, we consider the generation and transmission expansion problem
of joint power-gas infrastructure and operations planning under the uncertainty
of both demand and renewable supply. We propose two distributionally robust
optimization approaches based on moment (MDRO) and Wasserstein distance (WDRO)
ambiguity sets to endogenize these uncertainties and account for the change in
the underlying distribution of these parameters that is caused by the climate
change, among other factors. Furthermore, our model considers the risk-aversion
of the energy planners in the modeling framework via the conditional
value-at-risk (CVaR) metric. An equivalent mixed-integer linear programming
(MILP) reformulation of both modeling frameworks is presented, and a
computationally efficient approximation scheme to obtain near-optimal solutions
is proposed. We demonstrate the resulting DRO planning models and solution
strategy via a New England case study under different levels of end-use
electrification and decarbonization targets. Our experiments systematically
explore different modeling aspects and compare the DRO models with stochastic
programming (SP) results.

</details>


### [175] [A Bidirectional Power Router for Traceable Multi-energy Management](https://arxiv.org/abs/2506.23554)
*Shiu Mochiyama,Ryo Takahashi,Yoshihiko Susuki*

Main category: eess.SY

TL;DR: 论文提出了一种基于线路切换的双向电力路由器实验验证，用于提高可再生能源自消纳和本地住宅电力系统的韧性。


<details>
  <summary>Details</summary>
Motivation: 解决可再生能源自消纳和电力系统韧性的挑战，验证双向电力路由器的动态功率流处理能力。

Method: 设计了基于功率流监测的路由器切换算法，并通过商用固定电池实验验证其有效性。

Result: 实验验证了路由器处理动态双向功率流的能力，并展示了算法的有效性。

Conclusion: 提出的双向电力路由器及其切换算法能够在不影响电力系统稳定运行的情况下实现动态功率流管理。

Abstract: To address challenges in improving self-consumption of renewables and
resilience in local residential power systems, the earlier work of the authors
introduced a novel multi-energy management concept, integrating bidirectional
power routing and electricity-hydrogen conversion. This paper focuses on an
experimental verification of the bidirectional power router based on
line-switching, the essential hardware to realize the concept. The primary
contribution is the validation of the router's capability to handle dynamic
change of bidirectional power flow. Furthermore, to achieve bidirectional power
routing without affecting the smooth and stable operation of the power system,
a novel algorithm for router's switching is designed based on power flow
monitoring. The effectiveness of the proposed method is demonstrated through an
experiment using a setup with a commercially available stationary battery.

</details>


### [176] [Reliability Assessment of Power System Based on the Dichotomy Method](https://arxiv.org/abs/2506.23649)
*Wenjie Wan,Han Hu,Feiyu Chen,Xiaoyu Liu,Kequan Zhao*

Main category: eess.SY

TL;DR: 提出了一种基于布尔格表示理论的状态空间二分法，用于高效划分电力系统状态空间，显著提升可靠性评估的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着电力系统规模的扩大，传统状态枚举和蒙特卡洛模拟方法在效率和准确性上遇到瓶颈，亟需新方法。

Method: 利用布尔格表示理论将状态空间划分为不相交的子格，通过最优潮流操作计算可靠性指标，并设计定制化的蒙特卡洛采样方法。

Result: 在RBTS和RTS-79系统上的实验表明，该方法比传统方法快数百倍，且蒙特卡洛采样方法收敛迅速。

Conclusion: 所提方法显著提升了电力系统可靠性评估的效率和准确性，适用于大规模系统。

Abstract: With a sustainable increase in the scale of power system, the number of
states in the state space grows exponentially, and the reliability assessment
of the power system faces enormous challenges. Traditional state-by-state
assessment methods, such as state enumeration (SE) and Monte Carlo simulation
(MCS) methods, have encountered performance bottlenecks in terms of efficiency
and accuracy. In this paper, the Boolean lattice representation theory of the
state space was studied, and a dichotomy method was proposed to efficiently
partition the state space into some disjoint sub-lattices with a relatively
small number of optimal power flow (OPF) operations. Based on lattice
partition, the reliability indices of the entire space can be calculated
lattice-by-lattice. In addition, alone with the partitioning procedure, the
calculated loss of load probability (LOLP) monotonically increases and rapidly
tends to the analytic value with the designated error bound. Moreover, we
designed a customized Monte Carlo sampling method in lattices of interest to
compute expected energy not supply (EENS). The experiments are conducted on the
RBTS and RTS-79 systems. The results show that the proposed method achieves the
analytic LOLP of the RBTS system after five hundreds of OPF operations, which
is about hundreds of times faster than traditional methods, and the designed
Monte Carlo sampling method converged after thousands of OPF operations on test
systems.

</details>


### [177] [A Data-Ensemble-Based Approach for Sample-Efficient LQ Control of Linear Time-Varying Systems](https://arxiv.org/abs/2506.23716)
*Sahel Vahedi Noori,Maryam Babazadeh*

Main category: eess.SY

TL;DR: 本文提出了一种高效的数据驱动控制框架，用于线性时变系统的有限时域线性二次控制。通过非凸优化和双问题分析，开发了一种非迭代半定规划算法，直接从数据计算最优反馈增益。


<details>
  <summary>Details</summary>
Motivation: 解决线性时变系统的有限时域LQ控制问题，避免传统方法中对模型识别的依赖，提高样本效率和最优性。

Method: 将LQ问题转化为非凸优化问题，分析其对偶结构，利用KKT条件推导最优解与Q函数参数的关系，开发非迭代SDP算法。

Result: 算法直接从数据计算最优反馈增益，适用于完全未知的LTV系统，并在LTI系统中显著优于现有Q学习方法。

Conclusion: 该方法为时变环境下的数据驱动控制提供了新视角，仿真显示其在最优性和样本效率上优于现有方法。

Abstract: This paper presents a sample-efficient, data-driven control framework for
finite-horizon linear quadratic (LQ) control of linear time-varying (LTV)
systems. In contrast to the time-invariant case, the time-varying LQ problem
involves a differential Riccati equation (DRE) with time-dependent parameters
and terminal boundary constraints. We formulate the LQ problem as a nonconvex
optimization problem and conduct a rigorous analysis of its dual structure. By
exploiting the inherent convexity of the dual problem and analyzing the KKT
conditions, we derive an explicit relationship between the optimal dual
solution and the parameters of the associated Q-function in time-varying case.
This theoretical insight supports the development of a novel, sample-efficient,
non-iterative semidefinite programming (SDP) algorithm that directly computes
the optimal sequence of feedback gains from an ensemble of input-state data
sequences without model identification. The resulting convex, data-dependent
framework provides global optimality guarantees for completely unknown LTV
systems. As a special case, the method also applies to finite-horizon LQ
control of linear time-invariant (LTI) systems. In this setting, a single
input-state trajectory suffices to identify the optimal LQ feedback policy,
improving significantly over existing Q-learning approaches for finite horizon
LTI systems that typically require data from multiple episodes. The approach
provides a new optimization-based perspective on Q-learning in time-varying
settings and contributes to the broader understanding of data-driven control in
non-stationary environments. Simulation results show that, compared to recent
methods, the proposed approach achieves superior optimality and sample
efficiency on LTV systems, and indicates potential for stabilizing and optimal
control of nonlinear systems.

</details>


### [178] [A Digital Twinning Approach to Decarbonisation: Research Challenges](https://arxiv.org/abs/2506.23733)
*Blair Archibald,Paul Harvey,Michele Sevegnani*

Main category: eess.SY

TL;DR: 本文探讨了英国交通运输领域温室气体排放问题，提出通过联邦数字孪生方法解决脱碳挑战。


<details>
  <summary>Details</summary>
Motivation: 交通运输占英国温室气体排放的27%，但现有脱碳努力局限于单一领域，缺乏系统视角。

Method: 采用联邦数字孪生方法，整合多领域数据，设计、生成、验证和验证数字孪生。

Result: 提出了一种系统性视角，以支持动态适应和脱碳决策。

Conclusion: 联邦数字孪生方法有望解决交通运输脱碳的系统性挑战。

Abstract: Transportation accounts for around 27% of green house gas emissions in the
UK. While an obvious priority area for decarbonisation, and aligned to the UK
government goal of reducing emissions by 68% for 2030, the free-market nature
of the transportation sector combined with its fundamentally implicit and
pervasive connections to all aspects of society and national infrastructure
mean that all decarbonisation efforts to date have been siloed within a single
transport sector, e.g. only considering greener aviation fuels. Truly
decarbonising transport requires radical changes to the entire transport
infrastructure, and since that transport does not happen in isolation, a single
user often using multiple modes, we need a view over the whole transport
system. The first step to solving a problem is to understand it. As a result of
the fragmented nature of the transportation sector, there is currently no
system level view. Without the ability to monitor even adjacent transport
domains, the ability for people or organisations to (dynamically) adapt their
operations for decarbonisation outcomes is unrealistic. As transportation is a
complex social-techno-economic system, information and knowledge sharing is a
must to be able to understand and explore potential solutions to the
decarbonisation challenge. We believe a Federated Digital Twinning Approach has
the potential to tackle transport decarbonisation problems, and, in this
extended abstract, we give an overview of the research required to tackle the
fundamental challenges around digital twin design, generation, validation and
verification.

</details>


### [179] [On sample-based functional observability of linear systems](https://arxiv.org/abs/2506.23744)
*Isabelle Krauss,Victor G. Lopez,Matthias A. Müller*

Main category: eess.SY

TL;DR: 本文研究了基于采样的功能可观测性，提出了系统在采样框架下满足功能可观测性的充要条件，并给出了采样方案的条件。


<details>
  <summary>Details</summary>
Motivation: 研究在测量信息有限（如低频或不规则采样）的情况下，如何从输出中推断系统状态的函数。

Method: 提出了系统在采样框架下满足功能可观测性的充要条件，并分析了采样方案的条件。

Result: 通过数值示例验证了所得结果的适用性。

Conclusion: 本文为基于采样的功能可观测性提供了理论支持，并展示了其实际应用价值。

Abstract: Sample-based observability characterizes the ability to reconstruct the
internal state of a dynamical system by using limited output information, i.e.,
when measurements are only infrequently and/or irregularly available. In this
work, we investigate the concept of functional observability, which refers to
the ability to infer a function of the system state from the outputs, within a
samplebased framework. Here, we give necessary and sufficient conditions for a
system to be sample-based functionally observable, and formulate conditions on
the sampling schemes such that these are satisfied. Furthermore, we provide a
numerical example, where we demonstrate the applicability of the obtained
results.

</details>


### [180] [Active Estimation of Multiplicative Faults in Dynamical Systems](https://arxiv.org/abs/2506.23769)
*Gabriel de Albuquerque Gleizer,Peyman Mohajerin Esfahani,Tamas Keviczky*

Main category: eess.SY

TL;DR: 论文提出了一种实时故障估计方法，通过处理输入输出变量并设计最优输入信号来提高估计精度。


<details>
  <summary>Details</summary>
Motivation: 解决线性时不变系统中乘性故障信号的估计问题，并设计输入信号以最大化估计精度。

Method: 基于残差生成器和多输出回归生成器，结合移动水平线性回归估计参数变化。

Result: 提供了噪声下的渐近性能保证，并通过数值示例验证了方法的有效性。

Conclusion: 最优输入设计对准确故障估计至关重要，且提出的算法具有高效性和最优性保证。

Abstract: This paper addresses the problem of estimating multiplicative fault signals
in linear time-invariant systems by processing its input and output variables,
as well as designing an input signal to maximize the accuracy of such
estimates. The proposed real-time fault estimator is based on a residual
generator used for fault detection and a multiple-output regressor generator,
which feed a moving-horizon linear regression that estimates the parameter
changes. Asymptotic performance guarantees are provided in the presence of
noise. Motivated by the performance bounds, an optimal input design problem is
formulated, for which we provide efficient algorithms and optimality bounds.
Numerical examples demonstrate the efficacy of our approach and the importance
of the optimal input design for accurate fault estimation.

</details>


### [181] [Statistical Modeling for Accurate Characterization of Doppler Effect in LEO-Terrestrial Networks](https://arxiv.org/abs/2506.23817)
*Islam M. Tanash,Risto Wichman,Nuria Gonzalez-Prelcic*

Main category: eess.SY

TL;DR: 本文提出了一种分析低地球轨道（LEO）卫星通信中多普勒频移及其差异的通用框架，通过球面几何和用户聚类技术解决多普勒干扰问题。


<details>
  <summary>Details</summary>
Motivation: LEO卫星通信因其全球覆盖能力备受关注，但高速运动导致的多普勒频移及其差异严重影响了多载波系统性能，亟需一种通用分析方法。

Method: 采用球面几何模型，推导了多普勒频移及其差异的闭式表达式，并基于用户分布统计特性提出了用户聚类技术以减少干扰。

Result: 通过仿真验证了模型的有效性，揭示了卫星高度、波束宽度和几何关系对多普勒行为的影响。

Conclusion: 该框架为LEO系统设计提供了理论支持，用户聚类技术能有效降低多普勒差异干扰。

Abstract: Low Earth Orbit (LEO) satellite communication is a promising solution for
global wireless coverage, especially in underserved and remote areas. However,
the high relative velocity of LEO satellites induces significant Doppler shifts
that disrupt subcarrier orthogonality and degrade multicarrier system
performance. While the common time-varying Doppler shift can be compensated
relative to a reference point, the residual differential Doppler across users
within the coverage cell remains a significant challenge, causing severe
intercarrier interference. This paper presents a generalized analytical
framework for characterizing both the Doppler shift magnitude and the
differential Doppler in LEO systems. Unlike prior works limited by flat-Earth
assumptions or specific orbital configurations, our model incorporates Earth's
curvature and supports arbitrary elevation angles. Using spherical geometry, we
derive closed-form expressions for Doppler shift based on the central angle
between the satellite and ground users. We further provide a statistical
characterization of both the Doppler shift magnitude and the differential
Doppler in terms of their cumulative distribution function (CDF) and
probability density function (PDF) for uniformly distributed users within a
spherical cap cell. Additionally, we derive a tight upper bound for the Doppler
shift CDF and an exact expression for the maximum differential Doppler
experienced across the coverage region. To mitigate intra-cell Doppler
variation, we implement a user clustering technique that partitions the
coverage area based on a Doppler disparity threshold into spherical sub-cells,
ensuring compliance with 3GPP tolerances. Extensive simulations over realistic
satellite constellations validate our analysis and reveal the impact of
altitude, beamwidth, and satellite-user geometry on Doppler behavior.

</details>


### [182] [Orchestrated Couplings: A Time-Varying Edge Weight Framework for Efficient Event-Triggered Multiagent Networks](https://arxiv.org/abs/2506.24017)
*Emre Yildirim,Tansel Yucelen,Arman Sargolzaei*

Main category: eess.SY

TL;DR: 提出了一种基于时变边权重的事件触发控制框架，以减少多智能体网络中的节点间信息交换并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的事件触发分布式控制方法未能有效减少信息交换并提升网络性能。

Method: 设计了一种动态调整边权重的框架，在瞬态阶段增加权重，稳态阶段减少权重。

Result: 证明了闭环稳定性，避免了Zeno行为，并通过数值示例验证了框架的有效性。

Conclusion: 该框架显著减少了事件数量，提升了收敛速度和控制效率。

Abstract: In this paper, we focus on reducing node-to-node information exchange in
distributed control of multiagent networks while improving the overall network
performance. Specifically, we consider a multiagent network that is composed of
leader and follower nodes over a time-varying, connected, and undirected graph.
In contrast to existing works on the event-triggered distributed control
literature, we propose a time-varying edge weight event-triggered control
framework. In this framework, each node dynamically adjusts its edge weights by
increasing them during the transient (active) phase and decreasing them during
the steady-state (idle) phase of the multiagent network. This not only reduces
the number of events in the network but also improves the performance (i.e.,
convergence speed and control effort) of the overall multiagent network.
System-theoretically, we first prove the closed-loop stability of the proposed
event-triggered distributed control framework, where we then show that this
framework does not exhibit a Zeno behavior. Finally, illustrative numerical
examples are provided to demonstrate the efficacy of this framework.

</details>


### [183] [Time Shift Governor-Guided MPC with Collision Cone CBFs for Safe Adaptive Cruise Control in Dynamic Environments](https://arxiv.org/abs/2506.24083)
*Robin Inho Kee,Taehyeun Kim,Anouck Girard,Ilya Kolmanovsky*

Main category: eess.SY

TL;DR: 论文提出了一种基于时间偏移调控器（TSG）和模型预测控制（MPC）结合控制屏障函数（CBFs）的自适应巡航控制（ACC）方法。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂道路和动态障碍物场景下自适应巡航控制的约束问题。

Method: 采用MPC-CBF框架，结合TSG调整目标参考以应对快速变化的障碍物或前车行为。

Result: 仿真结果表明该方法有效。

Conclusion: TSG-guided MPC-CBF方法在自适应巡航控制中表现优异。

Abstract: This paper introduces a Time Shift Governor (TSG)-guided Model Predictive
Controller with Control Barrier Functions (CBFs)-based constraints for adaptive
cruise control (ACC). This MPC-CBF approach is defined for obstacle-free curved
road tracking, while following distance and obstacle avoidance constraints are
handled using standard CBFs and relaxed Collision Cone CBFs. In order to
address scenarios involving rapidly moving obstacles or rapidly changing
leading vehicle's behavior, the TSG augmentation is employed which alters the
target reference to enforce constraints. Simulation results demonstrate the
effectiveness of the TSG-guided MPC-CBF approach.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [184] [High Resolution Isotropic 3D Cine imaging with Automated Segmentation using Concatenated 2D Real-time Imaging and Deep Learning](https://arxiv.org/abs/2506.22532)
*Mark Wrobel,Michele Pascale,Tina Yao,Ruaraidh Campbell,Elena Milano,Michael Quail,Jennifer Steeden,Vivek Muthurangu*

Main category: eess.IV

TL;DR: 利用深度学习将2D实时电影图像拼接为3D电影数据集，验证了其在心血管磁共振中的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统心血管磁共振（CMR）在儿科和先天性心脏病中需要多次扫描，耗时较长。本研究旨在通过深度学习技术，将2D自由呼吸实时电影图像拼接为3D电影数据集，以提高效率和准确性。

Method: 训练了四个深度学习模型，分别用于对比度校正、呼吸运动校正、超分辨率重建和心脏结构分割。在10名患者中验证了该方法，并与传统成像进行了比较。

Result: 所有实时数据成功转换为3D电影数据集，处理时间小于1分钟。心室体积和血管直径与传统成像结果一致，但右肺动脉直径略有高估。

Conclusion: 该方法能够快速生成3D电影数据集，与传统成像结果一致，有望显著提升临床CMR的效率。

Abstract: Background: Conventional cardiovascular magnetic resonance (CMR) in
paediatric and congenital heart disease uses 2D, breath-hold, balanced steady
state free precession (bSSFP) cine imaging for assessment of function and
cardiac-gated, respiratory-navigated, static 3D bSSFP whole-heart imaging for
anatomical assessment. Our aim is to concatenate a stack 2D free-breathing
real-time cines and use Deep Learning (DL) to create an isotropic a fully
segmented 3D cine dataset from these images. Methods: Four DL models were
trained on open-source data that performed: a) Interslice contrast correction;
b) Interslice respiratory motion correction; c) Super-resolution (slice
direction); and d) Segmentation of right and left atria and ventricles (RA, LA,
RV, and LV), thoracic aorta (Ao) and pulmonary arteries (PA). In 10 patients
undergoing routine cardiovascular examination, our method was validated on
prospectively acquired sagittal stacks of real-time cine images. Quantitative
metrics (ventricular volumes and vessel diameters) and image quality of the 3D
cines were compared to conventional breath hold cine and whole heart imaging.
Results: All real-time data were successfully transformed into 3D cines with a
total post-processing time of <1 min in all cases. There were no significant
biases in any LV or RV metrics with reasonable limits of agreement and
correlation. There is also reasonable agreement for all vessel diameters,
although there was a small but significant overestimation of RPA diameter.
Conclusion: We have demonstrated the potential of creating a 3D-cine data from
concatenated 2D real-time cine images using a series of DL models. Our method
has short acquisition and reconstruction times with fully segmented data being
available within 2 minutes. The good agreement with conventional imaging
suggests that our method could help to significantly speed up CMR in clinical
practice.

</details>


### [185] [FedCLAM: Client Adaptive Momentum with Foreground Intensity Matching for Federated Medical Image Segmentation](https://arxiv.org/abs/2506.22580)
*Vasilis Siomos,Jonathan Passerat-Palmbach,Giacomo Tarroni*

Main category: eess.IV

TL;DR: FedCLAM是一种联邦学习方法，通过客户端自适应动量和个性化阻尼因子解决医学图像中的特征差异问题，并引入强度对齐损失处理图像强度分布差异。


<details>
  <summary>Details</summary>
Motivation: 医学图像因设备和人群差异导致特征不一致，现有联邦学习方法难以适应，需改进。

Method: FedCLAM结合客户端自适应动量、个性化阻尼因子和强度对齐损失，优化模型训练。

Result: 在两个数据集上，FedCLAM在医学分割任务中优于八种前沿方法。

Conclusion: FedCLAM有效解决了医学图像联邦学习中的特征差异问题，性能显著提升。

Abstract: Federated learning is a decentralized training approach that keeps data under
stakeholder control while achieving superior performance over isolated
training. While inter-institutional feature discrepancies pose a challenge in
all federated settings, medical imaging is particularly affected due to diverse
imaging devices and population variances, which can diminish the global model's
effectiveness. Existing aggregation methods generally fail to adapt across
varied circumstances. To address this, we propose FedCLAM, which integrates
\textit{client-adaptive momentum} terms derived from each client's loss
reduction during local training, as well as a \textit{personalized dampening
factor} to curb overfitting. We further introduce a novel \textit{intensity
alignment} loss that matches predicted and ground-truth foreground
distributions to handle heterogeneous image intensity profiles across
institutions and devices. Extensive evaluations on two datasets show that
FedCLAM surpasses eight cutting-edge methods in medical segmentation tasks,
underscoring its efficacy. The code is available at
https://github.com/siomvas/FedCLAM.

</details>


### [186] [Multi-Domain FeFET-Based Pixel for In-Sensor Multiply-and-Accumulate Operations](https://arxiv.org/abs/2506.22596)
*Md Rahatul Islam Udoy,Wantong Li,Kai Ni,Ahmedullah Aziz*

Main category: eess.IV

TL;DR: 本文提出了一种基于FeFET的主动像素传感器，利用铁电层的多域极化状态实现传感器内乘加运算。


<details>
  <summary>Details</summary>
Motivation: 减少数据移动，提高能效，适用于实时边缘计算、神经形态视觉和安全传感应用。

Method: 将可编程FeFET集成到3晶体管像素电路中，利用FeFET的非易失性电导编码权重，光电二极管电压降编码输入，实现像素内模拟乘法。

Result: 通过HSPICE仿真验证了设计的可行性和可扩展性。

Conclusion: 该设计紧凑且高效，适合多种应用场景。

Abstract: This paper presents an FeFET-based active pixel sensor that performs
in-sensor multiply-and-accumulate (MAC) operations by leveraging the
multi-domain polarization states of ferroelectric layers. The proposed design
integrates a programmable FeFET into a 3-transistor pixel circuit, where the
FeFET's non-volatile conductance encodes the weight, and the photodiode voltage
drop encodes the input. Their interaction generates an output current
proportional to the product, enabling in-pixel analog multiplication.
Accumulation is achieved by summing output currents along shared column lines,
realizing full MAC functionality within the image sensor array. Extensive
HSPICE simulations, using 45 nm CMOS models, validate the operation and confirm
the scalability of the design. This compact and power-efficient architecture
minimizes data movement, making it ideal for real-time edge computing,
neuromorphic vision, and secure sensing applications.

</details>


### [187] [ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge](https://arxiv.org/abs/2506.22790)
*Yixu Chen,Bowen Chen,Hai Wei,Alan C. Bovik,Baojun Li,Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai,Dounia Hammou,Fei Yin,Rafal Mantiuk,Amritha Premkumar,Prajit T Rajendran,Vignesh V Menon*

Main category: eess.IV

TL;DR: ICME 2025挑战赛聚焦于通用HDR和SDR视频质量评估，旨在推动跨动态范围和失真类型的VQA方法发展。


<details>
  <summary>Details</summary>
Motivation: 随着HDR和SDR视频技术的发展，现有VQA模型在跨动态范围和失真类型的一致性表现不足，亟需通用性更强的评估方法。

Method: 挑战赛通过基准测试评估了七种模型，分为全参考（FR）和无参考（NR）两类。

Result: 五种提交模型中，四种优于VMAF基线，最优模型创下通用视频质量评估的新标杆。

Conclusion: 挑战赛成功推动了通用VQA方法的发展，并为未来研究设定了新标准。

Abstract: This paper reports IEEE International Conference on Multimedia \& Expo (ICME)
2025 Grand Challenge on Generalizable HDR and SDR Video Quality Measurement.
With the rapid development of video technology, especially High Dynamic Range
(HDR) and Standard Dynamic Range (SDR) contents, the need for robust and
generalizable Video Quality Assessment (VQA) methods has become increasingly
demanded. Existing VQA models often struggle to deliver consistent performance
across varying dynamic ranges, distortion types, and diverse content. This
challenge was established to benchmark and promote VQA approaches capable of
jointly handling HDR and SDR content. In the final evaluation phase, five teams
submitted seven models along with technical reports to the Full Reference (FR)
and No Reference (NR) tracks. Among them, four methods outperformed VMAF
baseline, while the top-performing model achieved state-of-the-art performance,
setting a new benchmark for generalizable video quality assessment.

</details>


### [188] [CA-Diff: Collaborative Anatomy Diffusion for Brain Tissue Segmentation](https://arxiv.org/abs/2506.22882)
*Qilong Xing,Zikai Song,Yuteng Ye,Yuke Chen,Youjia Zhang,Na Feng,Junqing Yu,Wei Yang*

Main category: eess.IV

TL;DR: 提出了一种结合解剖学特征的扩散模型框架（CA-Diff），用于提升脑MRI分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有CNN和基于Transformer的方法在脑结构分割中表现不佳，扩散模型因忽略解剖信息而直接应用效果有限。

Method: 引入距离场作为解剖学条件，设计协作扩散过程建模其联合分布，并添加一致性损失和时间适应通道注意力模块。

Result: 实验表明CA-Diff优于现有方法。

Conclusion: CA-Diff通过整合解剖学特征显著提升了脑MRI分割的准确性。

Abstract: Segmentation of brain structures from MRI is crucial for evaluating brain
morphology, yet existing CNN and transformer-based methods struggle to
delineate complex structures accurately. While current diffusion models have
shown promise in image segmentation, they are inadequate when applied directly
to brain MRI due to neglecting anatomical information. To address this, we
propose Collaborative Anatomy Diffusion (CA-Diff), a framework integrating
spatial anatomical features to enhance segmentation accuracy of the diffusion
model. Specifically, we introduce distance field as an auxiliary anatomical
condition to provide global spatial context, alongside a collaborative
diffusion process to model its joint distribution with anatomical structures,
enabling effective utilization of anatomical features for segmentation.
Furthermore, we introduce a consistency loss to refine relationships between
the distance field and anatomical structures and design a time adapted channel
attention module to enhance the U-Net feature fusion procedure. Extensive
experiments show that CA-Diff outperforms state-of-the-art (SOTA) methods.

</details>


### [189] [Hierarchical Characterization of Brain Dynamics via State Space-based Vector Quantization](https://arxiv.org/abs/2506.22952)
*Yanwu Yang,Thomas Wolfers*

Main category: eess.IV

TL;DR: 该论文提出了一种名为HST的分层状态空间标记化网络，用于量化大脑状态和动态转换，并通过改进的VQ-VAE方法提升量化性能。


<details>
  <summary>Details</summary>
Motivation: 理解大脑动态功能状态转换是神经科学的重要挑战，现有方法常忽略状态间的依赖关系且缺乏稳定表征。

Method: 采用分层状态空间模型和优化的VQ-VAE，结合量化误差反馈和聚类，生成稳定且具代表性的标记。

Result: 在两个公开fMRI数据集上验证了HST的有效性，展示了其在疾病诊断和重建性能中的潜力。

Conclusion: HST为大脑动态表征提供了新框架，有助于分析大脑的亚稳态特性。

Abstract: Understanding brain dynamics through functional Magnetic Resonance Imaging
(fMRI) remains a fundamental challenge in neuroscience, particularly in
capturing how the brain transitions between various functional states.
Recently, metastability, which refers to temporarily stable brain states, has
offered a promising paradigm to quantify complex brain signals into
interpretable, discretized representations. In particular, compared to
cluster-based machine learning approaches, tokenization approaches leveraging
vector quantization have shown promise in representation learning with powerful
reconstruction and predictive capabilities. However, most existing methods
ignore brain transition dependencies and lack a quantification of brain
dynamics into representative and stable embeddings. In this study, we propose a
Hierarchical State space-based Tokenization network, termed HST, which
quantizes brain states and transitions in a hierarchical structure based on a
state space-based model. We introduce a refined clustered Vector-Quantization
Variational AutoEncoder (VQ-VAE) that incorporates quantization error feedback
and clustering to improve quantization performance while facilitating
metastability with representative and stable token representations. We validate
our HST on two public fMRI datasets, demonstrating its effectiveness in
quantifying the hierarchical dynamics of the brain and its potential in disease
diagnosis and reconstruction performance. Our method offers a promising
framework for the characterization of brain dynamics, facilitating the analysis
of metastability.

</details>


### [190] [An Image Processing Based Blur Reduction Technique in Smartphone-to-Smartphone Visible Light Communication System](https://arxiv.org/abs/2506.23002)
*Vaigai Nayaki Yokar,Hoa Le-Minh,Zabih Ghassemlooy,Wai Lok Woo*

Main category: eess.IV

TL;DR: 提出了一种减少智能手机间可见光通信（S2SVLC）模糊的技术，通过避免重复扫描和减少接收端数据丢弃，提高识别效率和数据速率。


<details>
  <summary>Details</summary>
Motivation: 解决S2SVLC系统中因图像模糊导致的数据识别效率低和数据丢失问题。

Method: 将RGB图像转为灰度图，进行对比度增强、缩放和二值化处理以减少模糊。实验在不同距离、旋转、倾斜和光照条件下进行，使用ASCII和QR码传输数据。

Result: 实验结果显示，该技术在不同条件下将接收端的恢复效率提高到96%。

Conclusion: 所提方法有效减少了S2SVLC系统中的模糊问题，显著提高了数据恢复效率。

Abstract: In this paper, we present a blur reduction technique for
smartphone-to-smartphone visible light communications (S2SVLC). The key
technique it to avoid the repeated scanning of the transmitted data and to
lower the amount of data discarded at the receiver end of the S2SVLC system.
This image processing method will improve the system recognition efficiency and
data rate. The proposed method includes converting the red-green-blue (RGB)
image into grayscale, applying contrast enhancement, scaling and binarizing the
image to reduce the blur levels in the image. The experiment includes practical
data acquisition and further processing and estimation in MATLAB. The
experiment is carried out in different conditions like distance, rotation, and
tilt also considering different surrounding illuminations like ambient light
and no light conditions to estimate the blur levels in S2SVLC. In this
experimental investigation two types of coding, American Standard code for
information interchange (ASCII), and quick response (QR) code are used for data
transmission in S2SVLC. The obtained results indicate that, the proposed
technique is proven to improve the recovery efficiency to 96% in the receiver
end at different conditions.

</details>


### [191] [Channel characterization in screen-to-camera based optical camera communication](https://arxiv.org/abs/2506.23005)
*Vaigai Nayaki Yokar,Hoa Le Minh,Zabih Ghassemlooy,Wai Lok Woo*

Main category: eess.IV

TL;DR: 论文实验性地展示了基于智能手机屏幕和摄像头的S2SVLC系统，分析了屏幕的Lambertian阶数，并在特定测试条件下进行了信道特性分析。


<details>
  <summary>Details</summary>
Motivation: 随着光学相机通信（OCC）的发展，屏幕与摄像头之间的通信成为可能，推动了智能手机间可见光通信（S2SVLC）系统的研究。

Method: 使用智能手机屏幕和摄像头，在20厘米的链路范围内实验性地构建S2SVLC系统，并分析屏幕的Lambertian阶数和信道特性。

Result: 实验成功实现了S2SVLC系统，并获得了屏幕的Lambertian阶数及信道特性的相关数据。

Conclusion: 该研究为智能手机间可见光通信系统的实际应用提供了实验基础和理论支持。

Abstract: With the increase in optical camera communication (OCC), a screen to
camera-based communication can be established. This opens a new field of
visible light communication (VLC) known as smartphone to smartphone based
visible light communication (S2SVLC) system. In this paper, we experimentally
demonstrate a S2SVLC system based on VLC technology using a smartphone screen
and a smartphone camera over a link span of 20 cms. We analyze the Lambertian
order of the smartphone screen and carry out a channel characterization of a
screen to camera link-based VLC system under specific test conditions.

</details>


### [192] [MedRegion-CT: Region-Focused Multimodal LLM for Comprehensive 3D CT Report Generation](https://arxiv.org/abs/2506.23102)
*Sunggu Kyung,Jinyoung Seo,Hyunseok Lim,Dongyeong Kim,Hyungbin Park,Jimin Sung,Jihyun Kim,Wooyoung Jo,Yoojin Nam,Namkug Kim*

Main category: eess.IV

TL;DR: MedRegion-CT是一个区域聚焦的多模态大语言模型框架，通过区域代表令牌池化、通用分割模型和患者特定属性提取，显著提升了CT报告生成的临床相关性和自然语言质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注全局特征，难以捕捉区域特异性细节，可能导致某些异常被忽略。

Method: 1. 引入区域代表令牌池化（$R^2$ Token Pooling）提取3D CT特征；2. 使用通用分割模型生成伪掩码，提取区域中心特征；3. 利用分割结果提取患者特定属性并转换为文本提示。

Result: 在RadGenome-Chest CT上的实验表明，MedRegion-CT在自然语言生成质量和临床相关性方面优于现有方法。

Conclusion: MedRegion-CT通过区域聚焦的方法显著提升了CT报告生成的性能，同时保持了可解释性。

Abstract: The recent release of RadGenome-Chest CT has significantly advanced CT-based
report generation. However, existing methods primarily focus on global
features, making it challenging to capture region-specific details, which may
cause certain abnormalities to go unnoticed. To address this, we propose
MedRegion-CT, a region-focused Multi-Modal Large Language Model (MLLM)
framework, featuring three key innovations. First, we introduce Region
Representative ($R^2$) Token Pooling, which utilizes a 2D-wise pretrained
vision model to efficiently extract 3D CT features. This approach generates
global tokens representing overall slice features and region tokens
highlighting target areas, enabling the MLLM to process comprehensive
information effectively. Second, a universal segmentation model generates
pseudo-masks, which are then processed by a mask encoder to extract
region-centric features. This allows the MLLM to focus on clinically relevant
regions, using six predefined region masks. Third, we leverage segmentation
results to extract patient-specific attributions, including organ size,
diameter, and locations. These are converted into text prompts, enriching the
MLLM's understanding of patient-specific contexts. To ensure rigorous
evaluation, we conducted benchmark experiments on report generation using the
RadGenome-Chest CT. MedRegion-CT achieved state-of-the-art performance,
outperforming existing methods in natural language generation quality and
clinical relevance while maintaining interpretability. The code for our
framework is publicly available.

</details>


### [193] [CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation](https://arxiv.org/abs/2506.23121)
*Xinlei Yu,Chanmiao Wang,Hui Jin,Ahmed Elazab,Gangyong Jia,Xiang Wan,Changqing Zou,Ruiquan Ge*

Main category: eess.IV

TL;DR: CRISP-SAM2是一种基于SAM2的多器官医学分割模型，通过跨模态交互和语义提示解决现有模型的细节不准确、依赖几何提示和空间信息丢失问题。


<details>
  <summary>Details</summary>
Motivation: 当前多器官分割模型存在细节不准确、依赖几何提示和空间信息丢失等问题，CRISP-SAM2旨在解决这些挑战。

Method: 采用跨模态上下文语义转换、语义提示策略、记忆自更新和掩码细化过程。

Result: 在七个公共数据集上的实验表明，CRISP-SAM2优于现有模型。

Conclusion: CRISP-SAM2在解决多器官分割问题中表现出色，尤其针对现有模型的局限性。

Abstract: Multi-organ medical segmentation is a crucial component of medical image
processing, essential for doctors to make accurate diagnoses and develop
effective treatment plans. Despite significant progress in this field, current
multi-organ segmentation models often suffer from inaccurate details,
dependence on geometric prompts and loss of spatial information. Addressing
these challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal
Interaction and Semantic Prompting based on SAM2. This model represents a
promising approach to multi-organ medical segmentation guided by textual
descriptions of organs. Our method begins by converting visual and textual
inputs into cross-modal contextualized semantics using a progressive
cross-attention interaction mechanism. These semantics are then injected into
the image encoder to enhance the detailed understanding of visual information.
To eliminate reliance on geometric prompts, we use a semantic prompting
strategy, replacing the original prompt encoder to sharpen the perception of
challenging targets. In addition, a similarity-sorting self-updating strategy
for memory and a mask-refining process is applied to further adapt to medical
imaging and enhance localized details. Comparative experiments conducted on
seven public datasets indicate that CRISP-SAM2 outperforms existing models.
Extensive analysis also demonstrates the effectiveness of our method, thereby
confirming its superior performance, especially in addressing the limitations
mentioned earlier. Our code is available at:
https://github.com/YU-deep/CRISP\_SAM2.git.

</details>


### [194] [Score-based Diffusion Model for Unpaired Virtual Histology Staining](https://arxiv.org/abs/2506.23184)
*Anran Liu,Xiaofei Wang,Jing Cai,Chao Li*

Main category: eess.IV

TL;DR: 提出了一种基于互信息引导的扩散模型，用于从H&E图像虚拟生成IHC图像，解决了现有方法在分解染色风格与组织结构、可控染色过程及结构一致性建模方面的挑战。


<details>
  <summary>Details</summary>
Motivation: H&E染色缺乏特异性标记，而IHC染色受限于组织可用性和抗体特异性。虚拟染色技术有望高效生成IHC图像，但现有方法在分解染色风格与组织结构、可控染色及结构一致性建模方面存在不足。

Method: 设计了互信息引导的扩散模型，包括全局互信息能量函数、时间步定制的反向扩散过程及局部互信息驱动的对比学习策略，以分解染色风格与组织结构、精确控制染色强度并确保细胞级结构一致性。

Result: 实验表明，该方法在虚拟染色任务上优于现有技术，展现了其生物医学应用潜力。

Conclusion: 该研究提出的互信息引导扩散模型在虚拟染色任务中表现出色，为生物医学图像分析提供了新工具。

Abstract: Hematoxylin and eosin (H&E) staining visualizes histology but lacks
specificity for diagnostic markers. Immunohistochemistry (IHC) staining
provides protein-targeted staining but is restricted by tissue availability and
antibody specificity. Virtual staining, i.e., computationally translating the
H&E image to its IHC counterpart while preserving the tissue structure, is
promising for efficient IHC generation. Existing virtual staining methods still
face key challenges: 1) effective decomposition of staining style and tissue
structure, 2) controllable staining process adaptable to diverse tissue and
proteins, and 3) rigorous structural consistency modelling to handle the
non-pixel-aligned nature of paired H&E and IHC images. This study proposes a
mutual-information (MI)-guided score-based diffusion model for unpaired virtual
staining. Specifically, we design 1) a global MI-guided energy function that
disentangles the tissue structure and staining characteristics across
modalities, 2) a novel timestep-customized reverse diffusion process for
precise control of the staining intensity and structural reconstruction, and 3)
a local MI-driven contrastive learning strategy to ensure the cellular level
structural consistency between H&E-IHC images. Extensive experiments
demonstrate the our superiority over state-of-the-art approaches, highlighting
its biomedical potential. Codes will be open-sourced upon acceptance.

</details>


### [195] [Multi-Source COVID-19 Detection via Variance Risk Extrapolation](https://arxiv.org/abs/2506.23208)
*Runtian Yuan,Qingqiu Li,Junlin Hou,Jilan Xu,Yuejie Zhang,Rui Feng,Hao Chen*

Main category: eess.IV

TL;DR: 提出一种结合VREx和Mixup的方法，用于多源COVID-19检测任务，解决域偏移问题，并在验证集上取得高F1分数。


<details>
  <summary>Details</summary>
Motivation: 多源CT扫描数据因成像协议、扫描仪和患者群体差异导致域偏移，需提升模型的跨域泛化能力。

Method: 结合VREx（最小化跨域风险方差）和Mixup数据增强（线性插值输入和标签），提升模型泛化性和鲁棒性。

Result: 在四个数据源上平均宏F1分数达0.96，表现优异。

Conclusion: VREx和Mixup的结合有效解决了域偏移问题，提升了模型的跨域性能。

Abstract: We present our solution for the Multi-Source COVID-19 Detection Challenge,
which aims to classify chest CT scans into COVID and Non-COVID categories
across data collected from four distinct hospitals and medical centers. A major
challenge in this task lies in the domain shift caused by variations in imaging
protocols, scanners, and patient populations across institutions. To enhance
the cross-domain generalization of our model, we incorporate Variance Risk
Extrapolation (VREx) into the training process. VREx encourages the model to
maintain consistent performance across multiple source domains by explicitly
minimizing the variance of empirical risks across environments. This
regularization strategy reduces overfitting to center-specific features and
promotes learning of domain-invariant representations. We further apply Mixup
data augmentation to improve generalization and robustness. Mixup interpolates
both the inputs and labels of randomly selected pairs of training samples,
encouraging the model to behave linearly between examples and enhancing its
resilience to noise and limited data. Our method achieves an average macro F1
score of 0.96 across the four sources on the validation set, demonstrating
strong generalization.

</details>


### [196] [Improving Myocardial Infarction Detection via Synthetic ECG Pretraining](https://arxiv.org/abs/2506.23259)
*Lachin Naghashyar*

Main category: eess.IV

TL;DR: 提出一种生理感知的ECG合成与预训练方法，提升心肌梗死检测性能，尤其在数据稀缺时。


<details>
  <summary>Details</summary>
Motivation: 心肌梗死是全球主要死因，但ECG早期诊断依赖大量标注数据，实践中常稀缺。

Method: 合成具有可调MI形态和真实噪声的12导联ECG，结合自监督掩码自编码和联合重建-分类目标预训练模型。

Result: 合成ECG保留关键形态特征，预训练在低数据场景下提升分类性能（AUC最高提升4个百分点）。

Conclusion: 合成ECG可有效改善心肌梗死检测，尤其在临床数据有限时。

Abstract: Myocardial infarction is a major cause of death globally, and accurate early
diagnosis from electrocardiograms (ECGs) remains a clinical priority. Deep
learning models have shown promise for automated ECG interpretation, but
require large amounts of labeled data, which are often scarce in practice. We
propose a physiology-aware pipeline that (i) synthesizes 12-lead ECGs with
tunable MI morphology and realistic noise, and (ii) pre-trains recurrent and
transformer classifiers with self-supervised masked-autoencoding plus a joint
reconstruction-classification objective. We validate the realism of synthetic
ECGs via statistical and visual analysis, confirming that key morphological
features are preserved. Pretraining on synthetic data consistently improved
classification performance, particularly in low-data settings, with AUC gains
of up to 4 percentage points. These results show that controlled synthetic ECGs
can help improve MI detection when real clinical data is limited.

</details>


### [197] [Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification](https://arxiv.org/abs/2506.23298)
*Xing Shen,Justin Szeto,Mingyang Li,Hengguan Huang,Tal Arbel*

Main category: eess.IV

TL;DR: 本文研究了多模态大语言模型（MLLMs）在医学图像分类中的校准偏差和人口统计不公平性，提出了CALIN方法以在推理时校准预测置信度，提高公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: MLLMs在医学图像分析中具有巨大潜力，但其预测的准确性和校准误差在不同人口统计子群中的表现需要深入分析，以确保临床实践中的安全部署。

Method: 提出了CALIN方法，通过双层次程序（从总体到子群）估计校准矩阵，并在推理时应用这些矩阵校准预测置信度。

Result: 在三个医学影像数据集上的实验表明，CALIN能有效确保公平的置信校准，同时提高预测准确性，并最小化公平性与效用的权衡。

Conclusion: CALIN是一种有效的推理时校准方法，能够减少MLLMs在医学图像分类中的校准偏差和人口统计不公平性。

Abstract: Multimodal large language models (MLLMs) have enormous potential to perform
few-shot in-context learning in the context of medical image analysis. However,
safe deployment of these models into real-world clinical practice requires an
in-depth analysis of the accuracies of their predictions, and their associated
calibration errors, particularly across different demographic subgroups. In
this work, we present the first investigation into the calibration biases and
demographic unfairness of MLLMs' predictions and confidence scores in few-shot
in-context learning for medical image classification. We introduce CALIN, an
inference-time calibration method designed to mitigate the associated biases.
Specifically, CALIN estimates the amount of calibration needed, represented by
calibration matrices, using a bi-level procedure: progressing from the
population level to the subgroup level prior to inference. It then applies this
estimation to calibrate the predicted confidence scores during inference.
Experimental results on three medical imaging datasets: PAPILA for fundus image
classification, HAM10000 for skin cancer classification, and MIMIC-CXR for
chest X-ray classification demonstrate CALIN's effectiveness at ensuring fair
confidence calibration in its prediction, while improving its overall
prediction accuracies and exhibiting minimum fairness-utility trade-off.

</details>


### [198] [BPD-Neo: An MRI Dataset for Lung-Trachea Segmentation with Clinical Data for Neonatal Bronchopulmonary Dysplasia](https://arxiv.org/abs/2506.23305)
*Rachit Saluja,Arzu Kovanlikaya,Candace Chien,Lauren Kathryn Blatt,Jeffrey M. Perlman,Stefan Worgall,Mert R. Sabuncu,Jonathan P. Dyke*

Main category: eess.IV

TL;DR: 该论文提出了一种基于高分辨率3D MRI数据的非侵入性方法，用于辅助诊断支气管肺发育不良（BPD），并提供了40名新生儿的MRI扫描和语义分割数据。


<details>
  <summary>Details</summary>
Motivation: 传统的便携式X射线成像在诊断BPD时存在辐射和镇静问题，而MRI提供了一种更安全的替代方案，并能更详细地揭示BPD的机制。

Method: 利用自由呼吸3D StarVIBE序列获取MRI数据，开发先进的图像处理和语义分割算法，辅助临床诊断。

Result: 提供了40名新生儿的MRI扫描和语义分割数据，并验证了基线分割模型的临床适用性。

Conclusion: 该方法为新生儿肺部影像研究提供了新的工具和数据支持，有望改善BPD的诊断和治疗。

Abstract: Bronchopulmonary dysplasia (BPD) is a common complication among preterm
neonates, with portable X-ray imaging serving as the standard diagnostic
modality in neonatal intensive care units (NICUs). However, lung magnetic
resonance imaging (MRI) offers a non-invasive alternative that avoids sedation
and radiation while providing detailed insights into the underlying mechanisms
of BPD. Leveraging high-resolution 3D MRI data, advanced image processing and
semantic segmentation algorithms can be developed to assist clinicians in
identifying the etiology of BPD. In this dataset, we present MRI scans paired
with corresponding semantic segmentations of the lungs and trachea for 40
neonates, the majority of whom are diagnosed with BPD. The imaging data consist
of free-breathing 3D stack-of-stars radial gradient echo acquisitions, known as
the StarVIBE series. Additionally, we provide comprehensive clinical data and
baseline segmentation models, validated against clinical assessments, to
support further research and development in neonatal lung imaging.

</details>


### [199] [SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting](https://arxiv.org/abs/2506.23309)
*Yiming Huang,Long Bai,Beilei Cui,Kun Yuan,Guankun Wang,Mobarakol Islam,Nicolas Padoy,Nassir Navab,Hongliang Ren*

Main category: eess.IV

TL;DR: SurgTPGS是一种新型的文本提示高斯泼溅方法，填补了实时文本提示3D查询的空白，结合了语义特征学习和变形跟踪，提升了手术场景重建的精度和语义平滑性。


<details>
  <summary>Details</summary>
Motivation: 在手术规划和实时术中引导中，准确理解3D手术场景并支持文本提示至关重要，但现有方法缺乏实时文本提示3D查询的能力。

Method: 结合Segment Anything模型和先进视觉语言模型，提出3D语义特征学习策略、语义感知变形跟踪和语义区域感知优化。

Result: 在两个真实手术数据集上的实验表明，SurgTPGS优于现有方法，显著提升了重建质量和语义理解。

Conclusion: SurgTPGS为下一代智能手术系统的发展铺平了道路，提高了手术精度和安全性。

Abstract: In contemporary surgical research and practice, accurately comprehending 3D
surgical scenes with text-promptable capabilities is particularly crucial for
surgical planning and real-time intra-operative guidance, where precisely
identifying and interacting with surgical tools and anatomical structures is
paramount. However, existing works focus on surgical vision-language model
(VLM), 3D reconstruction, and segmentation separately, lacking support for
real-time text-promptable 3D queries. In this paper, we present SurgTPGS, a
novel text-promptable Gaussian Splatting method to fill this gap. We introduce
a 3D semantics feature learning strategy incorporating the Segment Anything
model and state-of-the-art vision-language models. We extract the segmented
language features for 3D surgical scene reconstruction, enabling a more
in-depth understanding of the complex surgical environment. We also propose
semantic-aware deformation tracking to capture the seamless deformation of
semantic features, providing a more precise reconstruction for both texture and
semantic features. Furthermore, we present semantic region-aware optimization,
which utilizes regional-based semantic information to supervise the training,
particularly promoting the reconstruction quality and semantic smoothness. We
conduct comprehensive experiments on two real-world surgical datasets to
demonstrate the superiority of SurgTPGS over state-of-the-art methods,
highlighting its potential to revolutionize surgical practices. SurgTPGS paves
the way for developing next-generation intelligent surgical systems by
enhancing surgical precision and safety. Our code is available at:
https://github.com/lastbasket/SurgTPGS.

</details>


### [200] [Physics informed guided diffusion for accelerated multi-parametric MRI reconstruction](https://arxiv.org/abs/2506.23311)
*Perla Mayo,Carolin M. Pirkl,Alin Achim,Bjoern Menze,Mohammad Golbabaee*

Main category: eess.IV

TL;DR: MRF-DiPh是一种基于物理信息的去噪扩散方法，用于从快速定量MRI（如MRF）中生成多参数组织图。


<details>
  <summary>Details</summary>
Motivation: 解决快速定量MRI中的逆问题，提高参数图的准确性和物理模型一致性。

Method: 结合预训练去噪扩散模型和物理约束（k空间一致性及Bloch响应模型）。

Result: 在脑扫描数据中优于深度学习和压缩感知基线，提供更准确的参数图。

Conclusion: MRF-DiPh在医学成像中可靠地解决了逆问题，并提高了测量保真度。

Abstract: We introduce MRF-DiPh, a novel physics informed denoising diffusion approach
for multiparametric tissue mapping from highly accelerated, transient-state
quantitative MRI acquisitions like Magnetic Resonance Fingerprinting (MRF). Our
method is derived from a proximal splitting formulation, incorporating a
pretrained denoising diffusion model as an effective image prior to regularize
the MRF inverse problem. Further, during reconstruction it simultaneously
enforces two key physical constraints: (1) k-space measurement consistency and
(2) adherence to the Bloch response model. Numerical experiments on in-vivo
brain scans data show that MRF-DiPh outperforms deep learning and compressed
sensing MRF baselines, providing more accurate parameter maps while better
preserving measurement fidelity and physical model consistency-critical for
solving reliably inverse problems in medical imaging.

</details>


### [201] [Federated Breast Cancer Detection Enhanced by Synthetic Ultrasound Image Augmentation](https://arxiv.org/abs/2506.23334)
*Hongyi Pan,Ziliang Hong,Gorkem Durak,Ziyue Xu,Ulas Bagci*

Main category: eess.IV

TL;DR: 论文提出了一种基于生成AI的数据增强框架，通过合成图像共享提升联邦学习在乳腺癌超声图像诊断中的性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在医疗数据共享中具有潜力，但数据不足和非独立同分布问题限制了其效果。

Method: 使用两类特定的深度卷积生成对抗网络（DCGAN）生成合成图像，并将其整合到联邦学习训练中。

Result: 实验表明，适量合成图像将FedAvg的AUC从0.9206提升至0.9237，FedProx从0.9429提升至0.9538。

Conclusion: 生成AI数据增强能有效提升FL性能，但需平衡真实与合成数据的比例。

Abstract: Federated learning (FL) has emerged as a promising paradigm for
collaboratively training deep learning models across institutions without
exchanging sensitive medical data. However, its effectiveness is often hindered
by limited data availability and non-independent, identically distributed data
across participating clients, which can degrade model performance and
generalization. To address these challenges, we propose a generative AI based
data augmentation framework that integrates synthetic image sharing into the
federated training process for breast cancer diagnosis via ultrasound images.
Specifically, we train two simple class-specific Deep Convolutional Generative
Adversarial Networks: one for benign and one for malignant lesions. We then
simulate a realistic FL setting using three publicly available breast
ultrasound image datasets: BUSI, BUS-BRA, and UDIAT. FedAvg and FedProx are
adopted as baseline FL algorithms. Experimental results show that incorporating
a suitable number of synthetic images improved the average AUC from 0.9206 to
0.9237 for FedAvg and from 0.9429 to 0.9538 for FedProx. We also note that
excessive use of synthetic data reduced performance, underscoring the
importance of maintaining a balanced ratio of real and synthetic samples. Our
findings highlight the potential of generative AI based data augmentation to
enhance FL results in the breast ultrasound image classification task.

</details>


### [202] [FD-DiT: Frequency Domain-Directed Diffusion Transformer for Low-Dose CT Reconstruction](https://arxiv.org/abs/2506.23466)
*Qiqing Liu,Guoquan Wei,Zekun Zhou,Yiyang Wen,Liu Shi,Qiegen Liu*

Main category: eess.IV

TL;DR: FD-DiT是一种基于频率域导向的扩散变换器方法，用于低剂量CT图像重建，通过噪声逐步引入和去噪处理，结合频率解耦技术和混合去噪网络，显著提升了图像质量。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT（LDCT）虽减少辐射，但图像噪声和伪影影响诊断准确性，现有方法在保留细节方面存在不足。

Method: 提出FD-DiT，采用扩散策略和频率解耦技术，结合滑动稀疏局部注意力和动态融合策略，优化图像重建。

Result: 实验表明，FD-DiT在相同剂量下，噪声和伪影抑制效果优于现有方法。

Conclusion: FD-DiT通过频率域导向和动态融合，显著提升了LDCT图像重建质量。

Abstract: Low-dose computed tomography (LDCT) reduces radiation exposure but suffers
from image artifacts and loss of detail due to quantum and electronic noise,
potentially impacting diagnostic accuracy. Transformer combined with diffusion
models has been a promising approach for image generation. Nevertheless,
existing methods exhibit limitations in preserving finegrained image details.
To address this issue, frequency domain-directed diffusion transformer (FD-DiT)
is proposed for LDCT reconstruction. FD-DiT centers on a diffusion strategy
that progressively introduces noise until the distribution statistically aligns
with that of LDCT data, followed by denoising processing. Furthermore, we
employ a frequency decoupling technique to concentrate noise primarily in
high-frequency domain, thereby facilitating effective capture of essential
anatomical structures and fine details. A hybrid denoising network is then
utilized to optimize the overall data reconstruction process. To enhance the
capability in recognizing high-frequency noise, we incorporate sliding sparse
local attention to leverage the sparsity and locality of shallow-layer
information, propagating them via skip connections for improving feature
representation. Finally, we propose a learnable dynamic fusion strategy for
optimal component integration. Experimental results demonstrate that at
identical dose levels, LDCT images reconstructed by FD-DiT exhibit superior
noise and artifact suppression compared to state-of-the-art methods.

</details>


### [203] [UltraTwin: Towards Cardiac Anatomical Twin Generation from Multi-view 2D Ultrasound](https://arxiv.org/abs/2506.23490)
*Junxuan Yu,Yaofei Duan,Yuhao Huang,Yu Wang,Rongbo Ling,Weihao Luo,Ang Zhang,Jingxian Xu,Qiongying Ni,Yongsong Zhou,Binghan Li,Haoran Dou,Liping Liu,Yanfen Chu,Feng Geng,Zhe Sheng,Zhifeng Ding,Dingxin Zhang,Rui Huang,Yuhang Zhang,Xiaowei Xu,Tao Tan,Dong Ni,Zhongshan Gou,Xin Yang*

Main category: eess.IV

TL;DR: 提出了一种名为UltraTwin的生成框架，用于从稀疏多视角2D超声图像构建心脏解剖孪生体，解决了数据稀缺、结构复杂和超声噪声等挑战。


<details>
  <summary>Details</summary>
Motivation: 2D超声在精确计算和直接观察3D心脏结构方面存在不足，而3D超声又受限于低分辨率、小视野和实际应用中的稀缺性。构建心脏解剖孪生体有望提供精确的治疗规划和临床量化。

Method: 1. 构建了一个包含严格配对的多视角2D超声和CT数据的高质量数据集；2. 提出了从粗到细的分层重建优化方案；3. 引入了隐式自编码器以实现拓扑感知约束。

Result: 实验表明，UltraTwin能够重建高质量的解剖孪生体，优于其他强竞争方法。

Conclusion: UltraTwin推动了心脏解剖孪生体建模的发展，为个性化心脏护理的潜在应用提供了支持。

Abstract: Echocardiography is routine for cardiac examination. However, 2D ultrasound
(US) struggles with accurate metric calculation and direct observation of 3D
cardiac structures. Moreover, 3D US is limited by low resolution, small field
of view and scarce availability in practice. Constructing the cardiac
anatomical twin from 2D images is promising to provide precise treatment
planning and clinical quantification. However, it remains challenging due to
the rare paired data, complex structures, and US noises. In this study, we
introduce a novel generative framework UltraTwin, to obtain cardiac anatomical
twin from sparse multi-view 2D US. Our contribution is three-fold. First,
pioneered the construction of a real-world and high-quality dataset containing
strictly paired multi-view 2D US and CT, and pseudo-paired data. Second, we
propose a coarse-to-fine scheme to achieve hierarchical reconstruction
optimization. Last, we introduce an implicit autoencoder for topology-aware
constraints. Extensive experiments show that UltraTwin reconstructs
high-quality anatomical twins versus strong competitors. We believe it advances
anatomical twin modeling for potential applications in personalized cardiac
care.

</details>


### [204] [Artificial Intelligence-assisted Pixel-level Lung (APL) Scoring for Fast and Accurate Quantification in Ultra-short Echo-time MRI](https://arxiv.org/abs/2506.23506)
*Bowen Xin,Rohan Hickey,Tamara Blake,Jin Jin,Claire E Wainwright,Thomas Benkert,Alto Stemmer,Peter Sly,David Coman,Jason Dowling*

Main category: eess.IV

TL;DR: 该论文提出了一种基于人工智能的像素级肺评分（APL）方法，用于快速准确评估囊性纤维化（CF）患者的肺部结构损伤，结果显示其比传统网格级评分更快且更准确。


<details>
  <summary>Details</summary>
Motivation: 由于MRI无电离辐射，适用于儿科疾病如囊性纤维化的肺部成像，但缺乏定量评分系统。APL评分的开发旨在填补这一空白。

Method: APL评分包括五个步骤：图像加载、AI肺部分割、肺边界切片采样、像素级标注、量化与报告。

Result: APL评分耗时8.2分钟/例，比传统方法快两倍，且准确性更高（p=0.021），与网格级评分强相关（R=0.973）。

Conclusion: APL评分有望优化临床工作流程，并扩展至其他肺部疾病和MRI序列。

Abstract: Lung magnetic resonance imaging (MRI) with ultrashort echo-time (UTE)
represents a recent breakthrough in lung structure imaging, providing image
resolution and quality comparable to computed tomography (CT). Due to the
absence of ionising radiation, MRI is often preferred over CT in paediatric
diseases such as cystic fibrosis (CF), one of the most common genetic disorders
in Caucasians. To assess structural lung damage in CF imaging, CT scoring
systems provide valuable quantitative insights for disease diagnosis and
progression. However, few quantitative scoring systems are available in
structural lung MRI (e.g., UTE-MRI). To provide fast and accurate
quantification in lung MRI, we investigated the feasibility of novel Artificial
intelligence-assisted Pixel-level Lung (APL) scoring for CF. APL scoring
consists of 5 stages, including 1) image loading, 2) AI lung segmentation, 3)
lung-bounded slice sampling, 4) pixel-level annotation, and 5) quantification
and reporting. The results shows that our APL scoring took 8.2 minutes per
subject, which was more than twice as fast as the previous grid-level scoring.
Additionally, our pixel-level scoring was statistically more accurate
(p=0.021), while strongly correlating with grid-level scoring (R=0.973,
p=5.85e-9). This tool has great potential to streamline the workflow of UTE
lung MRI in clinical settings, and be extended to other structural lung MRI
sequences (e.g., BLADE MRI), and for other lung diseases (e.g.,
bronchopulmonary dysplasia).

</details>


### [205] [AFUNet: Cross-Iterative Alignment-Fusion Synergy for HDR Reconstruction via Deep Unfolding Paradigm](https://arxiv.org/abs/2506.23537)
*Xinyue Li,Zhangkai Ni,Wenhan Yang*

Main category: eess.IV

TL;DR: AFUNet通过交替优化的对齐与融合子任务，从MAP估计角度重构HDR图像，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法依赖经验设计，缺乏理论支持，影响可靠性。

Method: 提出AFUNet，将HDR重构分解为对齐与融合子任务，通过交替优化实现协同。基于MAP估计，结合空间对应先验，设计可训练的AFUNet。

Result: AFUNet在定性和定量评估中表现优越，超越现有方法。

Conclusion: AFUNet通过理论驱动的设计，显著提升了HDR图像重构的性能和可靠性。

Abstract: Existing learning-based methods effectively reconstruct HDR images from
multi-exposure LDR inputs with extended dynamic range and improved detail, but
they rely more on empirical design rather than theoretical foundation, which
can impact their reliability. To address these limitations, we propose the
cross-iterative Alignment and Fusion deep Unfolding Network (AFUNet), where HDR
reconstruction is systematically decoupled into two interleaved subtasks --
alignment and fusion -- optimized through alternating refinement, achieving
synergy between the two subtasks to enhance the overall performance. Our method
formulates multi-exposure HDR reconstruction from a Maximum A Posteriori (MAP)
estimation perspective, explicitly incorporating spatial correspondence priors
across LDR images and naturally bridging the alignment and fusion subproblems
through joint constraints. Building on the mathematical foundation, we
reimagine traditional iterative optimization through unfolding -- transforming
the conventional solution process into an end-to-end trainable AFUNet with
carefully designed modules that work progressively. Specifically, each
iteration of AFUNet incorporates an Alignment-Fusion Module (AFM) that
alternates between a Spatial Alignment Module (SAM) for alignment and a Channel
Fusion Module (CFM) for adaptive feature fusion, progressively bridging
misaligned content and exposure discrepancies. Extensive qualitative and
quantitative evaluations demonstrate AFUNet's superior performance,
consistently surpassing state-of-the-art methods. Our code is available at:
https://github.com/eezkni/AFUNet

</details>


### [206] [A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation](https://arxiv.org/abs/2506.23584)
*Renjie Liang,Zhengkang Fan,Jinqian Pan,Chenkun Sun,Russell Terry,Jie Xu*

Main category: eess.IV

TL;DR: 提出了一种两阶段框架，用于从2D CT切片生成肾脏放射学报告，结合多任务学习模型提取异常特征，并通过视觉语言模型生成自然语言报告。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像的复杂性和临床文档的变异性，提高放射学报告的生成准确性。

Method: 使用多任务学习模型提取异常特征，再结合CT图像输入微调的视觉语言模型生成报告。

Result: 模型在所有异常类型上优于随机基线，生成的报告能合理捕捉关键临床内容。

Conclusion: 展示了模块化、基于特征的报告生成的可行性，未来将扩展到3D CT体积并提高临床保真度。

Abstract: Generating radiology reports from CT scans remains a complex task due to the
nuanced nature of medical imaging and the variability in clinical
documentation. In this study, we propose a two-stage framework for generating
renal radiology reports from 2D CT slices. First, we extract structured
abnormality features using a multi-task learning model trained to identify
lesion attributes such as location, size, enhancement, and attenuation. These
extracted features are subsequently combined with the corresponding CT image
and fed into a fine-tuned vision-language model to generate natural language
report sentences aligned with clinical findings. We conduct experiments on a
curated dataset of renal CT studies with manually annotated
sentence-slice-feature triplets and evaluate performance using both
classification metrics and natural language generation metrics. Our results
demonstrate that the proposed model outperforms random baselines across all
abnormality types, and the generated reports capture key clinical content with
reasonable textual accuracy. This exploratory work highlights the feasibility
of modular, feature-informed report generation for renal imaging. Future
efforts will focus on extending this pipeline to 3D CT volumes and further
improving clinical fidelity in multimodal medical AI systems.

</details>


### [207] [Diffusion Model-based Data Augmentation Method for Fetal Head Ultrasound Segmentation](https://arxiv.org/abs/2506.23664)
*Fangyijie Wang,Kevin Whelan,Félix Balado,Guénolé Silvestre,Kathleen M. Curran*

Main category: eess.IV

TL;DR: 提出了一种基于扩散模型的掩码引导生成AI方法，用于生成合成胎儿头部超声图像及其分割掩码，以增强真实数据集，提升分割模型性能。


<details>
  <summary>Details</summary>
Motivation: 医疗图像数据因隐私和监管限制难以获取，且标注成本高，合成数据生成成为解决方案。

Method: 采用扩散模型生成合成胎儿头部超声图像与分割掩码，用于增强真实数据集并微调Segment Anything Model (SAM)。

Result: 合成数据能有效捕捉真实图像特征，在少量真实图像-掩码对训练下，分割性能达到最佳水平（Dice分数分别为94.66%和94.38%）。

Conclusion: 该方法为医疗图像分割提供了一种高效的数据增强解决方案，尤其在数据稀缺时表现优异。

Abstract: Medical image data is less accessible than in other domains due to privacy
and regulatory constraints. In addition, labeling requires costly,
time-intensive manual image annotation by clinical experts. To overcome these
challenges, synthetic medical data generation offers a promising solution.
Generative AI (GenAI), employing generative deep learning models, has proven
effective at producing realistic synthetic images. This study proposes a novel
mask-guided GenAI approach using diffusion models to generate synthetic fetal
head ultrasound images paired with segmentation masks. These synthetic pairs
augment real datasets for supervised fine-tuning of the Segment Anything Model
(SAM). Our results show that the synthetic data captures real image features
effectively, and this approach reaches state-of-the-art fetal head
segmentation, especially when trained with a limited number of real image-mask
pairs. In particular, the segmentation reaches Dice Scores of 94.66\% and
94.38\% using a handful of ultrasound images from the Spanish and African
cohorts, respectively. Our code, models, and data are available on GitHub.

</details>


### [208] [GUSL: A Novel and Efficient Machine Learning Model for Prostate Segmentation on MRI](https://arxiv.org/abs/2506.23688)
*Jiaxin Yang,Vasileios Magoulianitis,Catherine Aurelia Christie Alexander,Jintang Xue,Masatomo Kaneko,Giovanni Cacciamani,Andre Abreu,Vinay Duddalwar,C. -C. Jay Kuo,Inderbir S. Gill,Chrysostomos Nikias*

Main category: eess.IV

TL;DR: 提出了一种名为GUSL的无反向传播机器学习模型，用于前列腺和区域分割，具有高能效和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在前列腺分割中因'黑盒'特性难以被临床医生接受的问题。

Method: 采用多层回归方案进行粗到细分割，基于线性模型的特征提取，引入边界注意力机制和两步流水线解决类别不平衡。

Result: 在多个数据集上达到最佳性能，DSC大于0.9，模型轻量且高效。

Conclusion: GUSL为医学图像分割提供了高效、透明且实用的解决方案。

Abstract: Prostate and zonal segmentation is a crucial step for clinical diagnosis of
prostate cancer (PCa). Computer-aided diagnosis tools for prostate segmentation
are based on the deep learning (DL) paradigm. However, deep neural networks are
perceived as "black-box" solutions by physicians, thus making them less
practical for deployment in the clinical setting. In this paper, we introduce a
feed-forward machine learning model, named Green U-shaped Learning (GUSL),
suitable for medical image segmentation without backpropagation. GUSL
introduces a multi-layer regression scheme for coarse-to-fine segmentation. Its
feature extraction is based on a linear model, which enables seamless
interpretability during feature extraction. Also, GUSL introduces a mechanism
for attention on the prostate boundaries, which is an error-prone region, by
employing regression to refine the predictions through residue correction. In
addition, a two-step pipeline approach is used to mitigate the class imbalance,
an issue inherent in medical imaging problems. After conducting experiments on
two publicly available datasets and one private dataset, in both prostate gland
and zonal segmentation tasks, GUSL achieves state-of-the-art performance among
other DL-based models. Notably, GUSL features a very energy-efficient pipeline,
since it has a model size several times smaller and less complexity than the
rest of the solutions. In all datasets, GUSL achieved a Dice Similarity
Coefficient (DSC) performance greater than $0.9$ for gland segmentation.
Considering also its lightweight model size and transparency in feature
extraction, it offers a competitive and practical package for medical imaging
applications.

</details>


### [209] [MedSAM-CA: A CNN-Augmented ViT with Attention-Enhanced Multi-Scale Fusion for Medical Image Segmentation](https://arxiv.org/abs/2506.23700)
*Peiting Tian,Xi Chen,Haixia Bi,Fan Li*

Main category: eess.IV

TL;DR: MedSAM-CA是一种基于预训练模型MedSAM的架构级微调方法，通过引入CBR-Net和Atte-FFB组件，减少对大规模标注数据的依赖，提升医学图像分割的边界精度。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在临床诊断中至关重要，但现有深度学习方法依赖大量标注数据且难以应对低对比度和模糊边界等挑战。

Method: 提出MedSAM-CA，结合CBR-Net（卷积注意力增强边界细化网络）和Atte-FFB（注意力增强特征融合块），优化边界信息恢复和多级特征融合。

Result: 在公开数据集上验证，仅用2%训练数据即可达到94.43% Dice分数，接近全数据训练的97.25%性能。

Conclusion: MedSAM-CA在低资源临床场景中表现出色，显著减少对标注数据的依赖并提升分割精度。

Abstract: Medical image segmentation plays a crucial role in clinical diagnosis and
treatment planning, where accurate boundary delineation is essential for
precise lesion localization, organ identification, and quantitative assessment.
In recent years, deep learning-based methods have significantly advanced
segmentation accuracy. However, two major challenges remain. First, the
performance of these methods heavily relies on large-scale annotated datasets,
which are often difficult to obtain in medical scenarios due to privacy
concerns and high annotation costs. Second, clinically challenging scenarios,
such as low contrast in certain imaging modalities and blurry lesion boundaries
caused by malignancy, still pose obstacles to precise segmentation. To address
these challenges, we propose MedSAM-CA, an architecture-level fine-tuning
approach that mitigates reliance on extensive manual annotations by adapting
the pretrained foundation model, Medical Segment Anything (MedSAM). MedSAM-CA
introduces two key components: the Convolutional Attention-Enhanced Boundary
Refinement Network (CBR-Net) and the Attention-Enhanced Feature Fusion Block
(Atte-FFB). CBR-Net operates in parallel with the MedSAM encoder to recover
boundary information potentially overlooked by long-range attention mechanisms,
leveraging hierarchical convolutional processing. Atte-FFB, embedded in the
MedSAM decoder, fuses multi-level fine-grained features from skip connections
in CBR-Net with global representations upsampled within the decoder to enhance
boundary delineation accuracy. Experiments on publicly available datasets
covering dermoscopy, CT, and MRI imaging modalities validate the effectiveness
of MedSAM-CA. On dermoscopy dataset, MedSAM-CA achieves 94.43% Dice with only
2% of full training data, reaching 97.25% of full-data training performance,
demonstrating strong effectiveness in low-resource clinical settings.

</details>


### [210] [MDPG: Multi-domain Diffusion Prior Guidance for MRI Reconstruction](https://arxiv.org/abs/2506.23701)
*Lingtong Zhang,Mengdie Song,Xiaohan Hao,Huayu Mai,Bensheng Qiu*

Main category: eess.IV

TL;DR: 提出了一种基于预训练潜在扩散模型（LDMs）的多域扩散先验引导（MDPG）方法，用于提升MRI重建任务中的数据一致性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在MRI重建中因随机性难以生成高保真图像，而潜在扩散模型能提供紧凑且详细的先验知识，从而更有效地学习原始数据分布。

Method: 构建了基于Visual-Mamba的骨干网络，集成预训练LDMs提供潜在和图像域的条件先验，提出潜在引导注意力（LGA）和多级潜在域融合，并设计双域融合分支（DFB）和k空间正则化策略。

Result: 在两个公开MRI数据集上的实验验证了方法的有效性。

Conclusion: MDPG通过多域先验引导和k空间正则化，显著提升了MRI重建的数据一致性和图像质量。

Abstract: Magnetic Resonance Imaging (MRI) reconstruction is essential in medical
diagnostics. As the latest generative models, diffusion models (DMs) have
struggled to produce high-fidelity images due to their stochastic nature in
image domains. Latent diffusion models (LDMs) yield both compact and detailed
prior knowledge in latent domains, which could effectively guide the model
towards more effective learning of the original data distribution. Inspired by
this, we propose Multi-domain Diffusion Prior Guidance (MDPG) provided by
pre-trained LDMs to enhance data consistency in MRI reconstruction tasks.
Specifically, we first construct a Visual-Mamba-based backbone, which enables
efficient encoding and reconstruction of under-sampled images. Then pre-trained
LDMs are integrated to provide conditional priors in both latent and image
domains. A novel Latent Guided Attention (LGA) is proposed for efficient fusion
in multi-level latent domains. Simultaneously, to effectively utilize a prior
in both the k-space and image domain, under-sampled images are fused with
generated full-sampled images by the Dual-domain Fusion Branch (DFB) for
self-adaption guidance. Lastly, to further enhance the data consistency, we
propose a k-space regularization strategy based on the non-auto-calibration
signal (NACS) set. Extensive experiments on two public MRI datasets fully
demonstrate the effectiveness of the proposed methodology. The code is
available at https://github.com/Zolento/MDPG.

</details>


### [211] [Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound](https://arxiv.org/abs/2506.23721)
*Gijs Luijten,Roberto Maria Scardigno,Lisle Faray de Paiva,Peter Hoyer,Jens Kleesiek,Domenico Buongiorno,Vitoantonio Bevilacqua,Jan Egger*

Main category: eess.IV

TL;DR: 论文提出了一种结合深度学习和增强现实的超声系统，用于实时自动化肾脏体积测量，提升临床效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决超声技术学习曲线陡峭、操作繁琐以及医生需要在屏幕和患者之间频繁切换注意力的问题。

Method: 集成深度学习语义分割和增强现实技术，提出两种AR-DL辅助超声流程，支持无线和视频输出设备。

Result: 使用开源数据集和模型验证了实时性和准确性，并提供了开源GitHub管道。

Conclusion: 该系统显著提升了超声诊断的效率和易用性，特别适用于即时护理场景。

Abstract: Ultrasound (US) is widely accessible and radiation-free but has a steep
learning curve due to its dynamic nature and non-standard imaging planes.
Additionally, the constant need to shift focus between the US screen and the
patient poses a challenge. To address these issues, we integrate deep learning
(DL)-based semantic segmentation for real-time (RT) automated kidney volumetric
measurements, which are essential for clinical assessment but are traditionally
time-consuming and prone to fatigue. This automation allows clinicians to
concentrate on image interpretation rather than manual measurements.
Complementing DL, augmented reality (AR) enhances the usability of US by
projecting the display directly into the clinician's field of view, improving
ergonomics and reducing the cognitive load associated with screen-to-patient
transitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one
streams directly via the application programming interface for a wireless
setup, while the other supports any US device with video output for broader
accessibility. We evaluate RT feasibility and accuracy using the Open Kidney
Dataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with
MedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model
implementations, measurement algorithms, and a Wi-Fi-based streaming solution,
enhancing US training and diagnostics, especially in point-of-care settings.

</details>


### [212] [Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos](https://arxiv.org/abs/2506.23759)
*Zheng Fang,Xiaoming Qi,Chun-Mei Feng,Jialun Pei,Weixin Si,Yueming Jin*

Main category: eess.IV

TL;DR: 提出了一种个性化联邦学习方案FedST，通过解耦和增强时空表示，利用手术领域知识提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决手术器械分割在联邦学习中的挑战，如多样解剖背景与相似器械表示，以及合成数据的利用。

Method: 本地训练采用表示分离与合作机制（RSC），全局训练提出基于合成数据的显式表示量化（SERQ）。

Result: 提升了模型在各手术站点的适应性和泛化能力。

Conclusion: FedST有效结合手术领域知识，显著提升了联邦学习下的手术器械分割性能。

Abstract: Surgical instrument segmentation under Federated Learning (FL) is a promising
direction, which enables multiple surgical sites to collaboratively train the
model without centralizing datasets. However, there exist very limited FL works
in surgical data science, and FL methods for other modalities do not consider
inherent characteristics in surgical domain: i) different scenarios show
diverse anatomical backgrounds while highly similar instrument representation;
ii) there exist surgical simulators which promote large-scale synthetic data
generation with minimal efforts. In this paper, we propose a novel Personalized
FL scheme, Spatio-Temporal Representation Decoupling and Enhancement (FedST),
which wisely leverages surgical domain knowledge during both local-site and
global-server training to boost segmentation. Concretely, our model embraces a
Representation Separation and Cooperation (RSC) mechanism in local-site
training, which decouples the query embedding layer to be trained privately, to
encode respective backgrounds. Meanwhile, other parameters are optimized
globally to capture the consistent representations of instruments, including
the temporal layer to capture similar motion patterns. A textual-guided channel
selection is further designed to highlight site-specific features, facilitating
model adapta tion to each site. Moreover, in global-server training, we propose
Synthesis-based Explicit Representation Quantification (SERQ), which defines an
explicit representation target based on synthetic data to synchronize the model
convergence during fusion for improving model generalization.

</details>


### [213] [ShapeKit](https://arxiv.org/abs/2506.24003)
*Junqi Liu,Dongli He,Wenxuan Li,Ningyu Wang,Alan L. Yuille,Zongwei Zhou*

Main category: eess.IV

TL;DR: 提出了一种无需重新训练模型即可提高全身医学分割中解剖形状准确性的方法，性能提升超过8%。


<details>
  <summary>Details</summary>
Motivation: 发现形状优化工具对分割性能的提升显著优于模型架构修改，后者仅带来不到3%的改进。

Method: 开发了ShapeKit工具包，专注于优化解剖形状，易于集成。

Result: ShapeKit显著提高了分割准确性，性能提升超过8%。

Conclusion: 强调了形状工具在医学分割中的潜在价值，呼吁社区重视其应用。

Abstract: In this paper, we present a practical approach to improve anatomical shape
accuracy in whole-body medical segmentation. Our analysis shows that a
shape-focused toolkit can enhance segmentation performance by over 8%, without
the need for model re-training or fine-tuning. In comparison, modifications to
model architecture typically lead to marginal gains of less than 3%. Motivated
by this observation, we introduce ShapeKit, a flexible and easy-to-integrate
toolkit designed to refine anatomical shapes. This work highlights the
underappreciated value of shape-based tools and calls attention to their
potential impact within the medical segmentation community.

</details>


### [214] [Simultaneous Super-Resolution of Spatial and Spectral Imaging with a Camera Array and Notch Filters](https://arxiv.org/abs/2506.24014)
*Peng Lin,Xuesong Wang,Yating Chen,Xianyu Wu,Feng Huang,Shouqian Chen*

Main category: eess.IV

TL;DR: 提出了一种基于陷波滤波器相机阵列系统的算法，用于同时实现超分辨率成像和光谱重建，提升目标的空间分辨率和多光谱成像能力。


<details>
  <summary>Details</summary>
Motivation: 通过多孔径成像系统实现高时间、光谱和空间分辨率的需求。

Method: 结合多孔径超分辨率算法、全色锐化技术和光谱重建算法，利用9个成像孔径捕获的低分辨率图像的亚像素级偏移信息和光谱差异。

Result: 成功重建了31幅超分辨率光谱图像，峰值信噪比达35.6dB，比现有快照编码孔径光谱成像系统提升5dB，且处理时间更短。

Conclusion: 该研究为多孔径成像系统实现高分辨率提供了一种有效解决方案。

Abstract: This study proposes an algorithm based on a notch filter camera array system
for simultaneous super-resolution imaging and spectral reconstruction,
enhancing the spatial resolution and multispectral imaging capabilities of
targets. In this study, multi-aperture super-resolution algorithms,
pan-sharpening techniques, and spectral reconstruction algorithms were
investigated and integrated. The sub-pixel level offset information and
spectral disparities among the 9 low-resolution images captured by the 9
distinct imaging apertures were utilized, leading to the successful
reconstruction of 31 super-resolution spectral images. By conducting
simulations with a publicly available dataset and performing qualitative and
quantitative comparisons with snapshot coded aperture spectral imaging systems,
the experimental results demonstrate that our system and algorithm attained a
peak signal-to-noise ratio of 35.6dB, representing a 5dB enhancement over the
most advanced snapshot coded aperture spectral imaging systems, while also
reducing processing time. This research offers an effective solution for
achieving high temporal, spectral, and spatial resolution through the
utilization of multi-aperture imaging systems.

</details>


### [215] [C3VDv2 -- Colonoscopy 3D video dataset with enhanced realism](https://arxiv.org/abs/2506.24074)
*Mayank V. Golhar,Lucas Sebastian Galeano Fretes,Loren Ayers,Venkata S. Akshintala,Taylor L. Bobrow,Nicholas J. Durr*

Main category: eess.IV

TL;DR: C3VDv2是一个高仿真3D结肠镜视频数据集，旨在支持3D结肠重建算法的开发和评估。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏用于训练和验证的3D结肠镜数据集，限制了计算机视觉技术在结肠镜诊断中的应用。

Method: 通过60个高仿真硅胶结肠模型采集192个视频序列，提供深度、表面法线等多项真实数据。

Result: 数据集包含169个视频的真实数据，8个模拟筛查视频和15个结肠变形视频，模拟多种挑战性场景。

Conclusion: C3VDv2的高仿真性将促进3D重建算法的鲁棒性和代表性发展。

Abstract: Computer vision techniques have the potential to improve the diagnostic
performance of colonoscopy, but the lack of 3D colonoscopy datasets for
training and validation hinders their development. This paper introduces
C3VDv2, the second version (v2) of the high-definition Colonoscopy 3D Video
Dataset, featuring enhanced realism designed to facilitate the quantitative
evaluation of 3D colon reconstruction algorithms. 192 video sequences were
captured by imaging 60 unique, high-fidelity silicone colon phantom segments.
Ground truth depth, surface normals, optical flow, occlusion,
six-degree-of-freedom pose, coverage maps, and 3D models are provided for 169
colonoscopy videos. Eight simulated screening colonoscopy videos acquired by a
gastroenterologist are provided with ground truth poses. The dataset includes
15 videos featuring colon deformations for qualitative assessment. C3VDv2
emulates diverse and challenging scenarios for 3D reconstruction algorithms,
including fecal debris, mucous pools, blood, debris obscuring the colonoscope
lens, en-face views, and fast camera motion. The enhanced realism of C3VDv2
will allow for more robust and representative development and evaluation of 3D
reconstruction algorithms.

</details>
