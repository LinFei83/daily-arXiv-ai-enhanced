<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 24]
- [cs.CV](#cs.CV) [Total: 68]
- [cs.CL](#cs.CL) [Total: 35]
- [cs.RO](#cs.RO) [Total: 17]
- [eess.SY](#eess.SY) [Total: 8]
- [eess.IV](#eess.IV) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 提出了一种推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索，使大语言模型能获取与对话逻辑结构对齐的知识，提升响应质量。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型通常分别通过检索语义相似信息或提升推理能力来优化性能，但缺乏有效整合检索与推理策略的方法，难以同时保证知识相关性和逻辑连贯性。

Method: 采用粗到细的两阶段知识检索：先识别与上下文主题相关的知识库子区域，再在该区域内提取与推理过程具体相关的知识；两阶段均使用蒙特卡洛树搜索启发的搜索方法，通过关键词在知识句间导航。

Result: 在两个多轮对话数据集上的实验表明，该方法检索的知识更贴合人类对话的底层推理逻辑，显著提升了检索知识的多样性，从而生成信息更丰富、更具创造性的响应。

Conclusion: 所提出的推理感知知识检索方法能有效整合检索与推理，通过逻辑对齐的知识增强大语言模型，为提升对话系统的语义理解和生成能力提供了新思路。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [2] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 该研究开发了一种基于大型语言模型的自动化抑郁症筛查方法，专门针对尼日利亚皮钦语使用者，以解决传统筛查工具在低收入和中等收入国家存在的语言和文化障碍问题。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症筛查覆盖率低，主要由于临床医生资源不足、社会污名化以及语言障碍。传统的PHQ-9问卷在高收入国家验证有效，但在尼日利亚等使用皮钦语和多种本地语言的环境中存在语言和文化不适应性。

Method: 收集了432名18-40岁尼日利亚年轻人的皮钦语音频回答，进行转录、预处理和标注（包括语义标记、俚语解释和PHQ-9严重程度评分）。对三种大型语言模型（Phi-3-mini-4k-instruct、Gemma-3-4B-it和GPT-4.1）进行微调，并通过定量（准确性、精确度、语义对齐）和定性（清晰度、相关性、文化适宜性）方法评估性能。

Result: GPT-4.1表现最佳，在PHQ-9严重程度评分预测中达到94.5%的准确率，优于其他模型。在定性评估中，GPT-4.1也产生了最具文化适宜性、清晰度和上下文相关性的回答。

Conclusion: 该研究为在语言多样、资源有限的环境中部署对话式心理健康工具奠定了基础，展示了AI辅助抑郁症筛查在服务不足的尼日利亚社区中的潜力。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [3] [Toward a Physical Theory of Intelligence](https://arxiv.org/abs/2601.00021)
*Peter David Fagan*

Main category: cs.AI

TL;DR: 提出基于不可逆信息处理的物理智能理论，将智能定义为每单位信息产生的目标导向功，并推导出信息摄入、计算和功提取的物理约束。


<details>
  <summary>Details</summary>
Motivation: 为智能建立统一的物理基础理论，连接信息处理与守恒定律，解释生物和人工系统的智能现象。

Method: 引入守恒一致编码框架，将编码建模为吸引子盆地；建立智能的物理定义；分析开放系统的信息-功转换约束；应用于生物振荡和临界动力学。

Result: 理论揭示了长时程效率需要保持内部信息结构（自建模），指出物理智能系统存在固有认知极限；大脑动力学接近理论预测的高效运行状态；布尔逻辑可视为吸引子选择的特例。

Conclusion: 该理论为智能提供了与载体无关的物理解释，并为人工智能安全提供了基于不可逆信息流和结构稳态的新视角。

Abstract: We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.

</details>


### [4] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 本文提出一种多算法方法来解决最后一公里包裹配送中的工作量平衡问题，通过结合距离和工作量考虑优化包裹分配，确保每位配送员每日工作量相近。


<details>
  <summary>Details</summary>
Motivation: 传统基于地理邻近性的包裹分配方法效率低下，容易导致配送员间工作量分配不均，需要更优的工作量平衡方案。

Method: 采用多算法方法，包括不同版本的k-means、进化算法、基于k-means初始化的递归分配（不同问题编码）以及混合进化集成算法。

Result: 在西班牙Azuqueca de Henares的实际最后一公里配送场景中验证了所提方法的性能。

Conclusion: 所提出的多算法方法能有效平衡配送员工作量，纠正工作量分配不均问题，优化配送时间。

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [5] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 本文提出了一种基于规则的战略框架，用于13张牌印度拉米游戏，引入了MinDist评估指标来衡量手牌与完成状态的结构接近度，并通过算法优化和对手建模显著提升了胜率。


<details>
  <summary>Details</summary>
Motivation: 经典印度拉米游戏是一种不完全信息的序列游戏，需要概率推理和组合决策，传统启发式方法在战略设计上存在局限，需要更形式化和可解释的策略框架。

Method: 提出了MinDist手牌评估指标（基于MinScore改进，通过编辑距离量化手牌与最近有效配置的差距），设计了计算高效的动态剪枝和模式缓存算法，并在零和博弈框架中整合了对手建模与统计假设检验。

Result: 实验结果表明，基于MinDist的智能体相比传统启发式方法在胜率上有显著提升，验证了该框架的有效性。

Conclusion: MinDist指标为拉米游戏的算法策略设计提供了形式化且可解释的基础，其计算效率和战略优势展示了在复杂不完全信息游戏中的应用潜力。

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [6] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 研究通过伊朗鸽塔案例，测试三种扩散模型对乡土建筑智能的解读能力，发现AI能复制几何模式但误解材料和气候逻辑，揭示了视觉相似性与建筑推理之间的界限。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI系统如何理解和再现乡土建筑中蕴含的建筑智能，评估AI在传统设计知识解读中的能力与局限。

Method: 以伊朗鸽塔为案例，使用Midjourney v6、DALL-E 3和基于SDXL的DreamStudio三种扩散模型，通过参照性、适应性和推测性三个提示阶段，采用五标准评估框架（类型学、材料性、环境、真实感、文化特异性）进行分析。

Result: AI能可靠复制几何图案，但误解材料和气候逻辑；参照图像提升真实感但限制创造性，无参照时生成结果富有创意但文化模糊；不同模型在文化特异性表现上存在差异。

Conclusion: 研究界定了视觉相似性与建筑推理之间的边界，提出计算性乡土推理框架，用于分析AI如何感知、扭曲和重新想象传统设计智能。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [7] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 设计了一个LLM智能体，能从原始文本中提取因果反馈模糊认知图（FCM），并通过动态系统的均衡驱动LLM获取和处理因果文本，实现双向自主演化。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种能够从文本中自动提取因果结构并形成动态认知模型的智能体，以增强LLM在因果推理和自主演化方面的能力。

Method: 采用三步系统指令引导LLM智能体：提取关键名词和名词短语、从中选择FCM概念节点、推断节点间的模糊因果边。测试基于Henry Kissinger等人关于AI的论文，并混合了Gemini和ChatGPT生成的FCM。

Result: 生成的FCM动态系统与人工生成的FCM收敛到相同的均衡极限环，尽管节点和边数量不同。混合FCM不仅吸收了主要组分的均衡，还产生了新的均衡，更好地近似了底层因果动态系统。

Conclusion: 该方法成功实现了从文本中提取因果FCM，并通过混合不同LLM生成的FCM增强了模型的均衡表现，展示了LLM智能体在因果学习和自主演化方面的潜力。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [8] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar系统结合质量多样性算法与大语言模型，自主演化游戏机制用于自动游戏设计，通过合成完整游戏评估机制对技能排序的贡献。


<details>
  <summary>Details</summary>
Motivation: 游戏机制设计依赖专家手动完成，过程耗时且专业门槛高，需要自动化工具来探索多样化的可行机制。

Method: 结合质量多样性算法与大型语言模型探索机制多样性；通过树搜索合成完整游戏进行评估；以技能排序（强者恒胜）作为核心评估指标；进行消融实验和用户研究。

Result: 系统能生成多样且可玩的游戏；演化出的机制能提升游戏的技能排序得分；消融实验验证了各组件作用；用户反馈支持生成游戏的质量。

Conclusion: Mortar证明了自动演化游戏机制的可行性，其方法能生成具有技能区分度的游戏，为自动游戏设计提供了新途径。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [9] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: 本文提出了一种混合智能体框架，将LLM作为自然语言接口，严格分离语义推理与数学计算，以解决LLM直接作为端到端求解器在库存优化中存在的'幻觉税'问题，显著降低了库存成本。


<details>
  <summary>Details</summary>
Motivation: 中小型企业缺乏部署高级优化方法的专业知识，库存管理面临挑战。研究旨在探索LLM是否能帮助弥合这一差距，但发现LLM作为端到端求解器会因无法进行扎实的随机推理而产生显著的性能差距（'幻觉税'）。

Method: 提出混合智能体框架，严格解耦语义推理与数学计算：LLM作为智能接口，从自然语言中提取参数并解释结果，同时自动调用严谨算法构建优化引擎。引入'人类模仿者'（微调的有界理性管理者数字孪生）进行可扩展、可重复的压力测试，以评估系统在真实管理对话模糊性和不一致性下的表现。

Result: 混合智能体框架相比使用GPT-4o作为端到端求解器的交互基线，总库存成本降低了32.1%。实验表明，仅提供完美真实信息不足以改善GPT-4o的性能，确认瓶颈本质上是计算性的而非信息性的。

Conclusion: LLM不应取代运筹学，而是作为自然语言接口，使非专家能够访问基于求解器的严谨策略。混合框架通过分离推理与计算，有效提升了库存管理的可及性和性能。

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [10] [Constructing a Neuro-Symbolic Mathematician from First Principles](https://arxiv.org/abs/2601.00125)
*Keqin Xie*

Main category: cs.AI

TL;DR: 提出Mathesis神经符号架构，通过符号推理内核将逻辑约束映射到连续能量景观，将证明搜索转化为能量最小化问题，解决大语言模型在复杂推理中的逻辑失败问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理中存在持续的逻辑失败，缺乏内部公理化框架，需要结合神经与符号方法提升逻辑一致性。

Method: 使用高阶超图编码数学状态，通过可微逻辑引擎（SRK）将约束映射到连续能量景观，定义全局能量函数E(G)，结合超图变换器大脑、蒙特卡洛树搜索和进化证明搜索进行多步推理。

Result: Mathesis架构通过能量最小化实现逻辑一致性，符号推理内核提供梯度信号训练神经组件，实现神经与符号系统的有效协同。

Conclusion: 神经符号方法能有效弥补大语言模型的逻辑缺陷，将证明搜索转化为能量优化问题为复杂推理提供了新框架。

Abstract: Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.

</details>


### [11] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 研究验证了基于置信度的弃权机制在视频问答任务中对错误率的控制效果，发现其在分布内有效，但在分布偏移下可靠性下降。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在高风险场景部署时需要选择性预测，即在不确定时弃权以避免代价高昂的错误。研究旨在验证基于置信度的弃权是否能可靠控制视频问答的错误率，并评估其在分布偏移下的鲁棒性。

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型，通过置信度阈值调节实现风险-覆盖权衡分析，并测试其在分布偏移下的表现。

Result: 在分布内，置信度阈值调节能平滑控制风险-覆盖权衡，有效降低错误率；但在分布偏移下，这种控制机制的可靠性显著下降。

Conclusion: 基于置信度的弃权机制在分布内可提供可靠的错误率控制，但在实际部署中需考虑分布偏移带来的可靠性挑战。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [12] [An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making](https://arxiv.org/abs/2601.00142)
*Tiansi Dong,Henry He,Pietro Liò,Mateja Jamnik*

Main category: cs.AI

TL;DR: 本文比较了三种神经推理方法，提出球面神经网络能可靠处理16种三段论推理任务，而基于显式模型构建的神经推理最为可靠。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在推理任务上不可靠，监督学习方法存在灾难性遗忘问题，需要探索更可靠的神经推理方法。

Method: 通过析取三段论测试比较三种方法；提出球面神经网络，将概念表示为n维球面上的圆，通过补集圆表示否定算子，过滤不可满足的圆形配置。

Result: 欧拉网络在经典三段论上可达100%准确率，但重训练后经典任务性能降至6.25%；球面神经网络能同时掌握16种三段论推理任务，包括严格的析取三段论。

Conclusion: 基于显式模型构建的神经推理在三种方法中最为可靠，球面神经网络能实现逻辑一致的推理且避免灾难性遗忘。

Abstract: This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.

</details>


### [13] [FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems](https://arxiv.org/abs/2601.00227)
*Shanli Xing,Yiyan Zhai,Alexander Jiang,Yixin Dong,Yong Wu,Zihao Ye,Charlie Ruan,Yingyi Huang,Yineng Zhang,Liangsheng Yin,Aksara Bayyapu,Luis Ceze,Tianqi Chen*

Main category: cs.AI

TL;DR: FlashInfer-Bench是一个标准化闭环框架，用于评估和部署AI生成的GPU内核，通过统一的数据模式、基准测试和动态替换机制，将LLM生成的内核集成到实际推理系统中。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型能够自主生成GPU内核，但将这些AI生成的内核集成到实际推理系统中仍面临挑战，缺乏统一的评估和部署框架。

Method: 提出FlashInfer-Bench框架，包含：1) FlashInfer Trace统一数据模式；2) 基于真实服务轨迹的数据集；3) 正确性和性能感知的基准测试框架；4) 公开排行榜；5) apply()动态替换机制。

Result: 该框架能够：1) 评估LLM代理的GPU编程能力；2) 比较不同GPU编程语言的权衡；3) 将最优内核无缝注入SGLang和vLLM等生产系统。

Conclusion: FlashInfer-Bench为持续改进AI生成内核并部署到大规模LLM推理系统提供了实用、可复现的路径，并为未来代理设计提供了见解。

Abstract: Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.

</details>


### [14] [ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization](https://arxiv.org/abs/2601.00290)
*Sixue Xing,Xuanye Xia,Kerui Wu,Meng Jiang,Jintai Chen,Tianfan Fu*

Main category: cs.AI

TL;DR: 提出ClinicalReTrial框架，通过AI代理迭代优化临床试验方案设计，提升试验成功率，而非仅预测失败风险。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法仅能预测临床试验失败风险，但无法提供可操作的改进方案；临床试验失败仍是药物开发的主要瓶颈，微小方案设计缺陷可能导致不可逆的失败。

Method: 提出自演化的AI代理框架，将临床试验推理建模为迭代方案重设计问题，集成失败诊断、安全感知修改和候选评估，采用闭环奖励驱动优化框架，利用预测模型作为模拟环境，并构建分层记忆系统捕获迭代反馈和可迁移重设计模式。

Result: 实证显示，ClinicalReTrial改进了83.3%的试验方案，平均成功概率提升5.7%；回顾性案例研究表明，AI发现的策略与实际临床试验修改高度一致。

Conclusion: ClinicalReTrial框架能主动优化临床试验方案，弥补了传统预测模型的不足，为降低临床试验失败率提供了可操作的AI驱动解决方案。

Abstract: Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.

</details>


### [15] [Multiagent Reinforcement Learning for Liquidity Games](https://arxiv.org/abs/2601.00324)
*Alicia Vidler,Gal A. Kaminka*

Main category: cs.AI

TL;DR: 本文通过将流动性博弈与理性群集理论结合，提出了一个金融群集模型，使独立交易者在追求个体利润的同时，自发促进市场流动性和整体效率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在融合群集方法与金融市场建模，利用博弈论解释自利个体如何实现集体效用，以提升市场稳定性和设计。

Method: 结合流动性博弈（交易者收益取决于交易中的总流动性）和理性群集（去中心化代理使用差异奖励对齐个体与全局目标），在马尔可夫团队博弈框架中应用差异奖励。

Result: 理论框架表明，个体流动性最大化行为无需协调或共谋即可贡献于整体市场流动性，实现个体盈利与集体市场效率的双重目标。

Conclusion: 金融群集模型为双边资产市场中的理性独立代理提供了一个框架，使其在保持独立性的同时，自发促进市场流动性和效率。

Abstract: Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.

</details>


### [16] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 研究发现LLM赋能的智能体不仅存在人口统计偏见，还会在最小群体线索下表现出内群体偏见。当这种群体边界与智能体-人类划分重合时，人类整体可能被智能体视为外群体。研究通过多智能体社会模拟验证了该偏见，并提出了一种信念投毒攻击（BPA）来抑制有利于人类的行为脚本，同时讨论了防御策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注智能体对人口统计群体（如性别、宗教）的偏见，但尚未深入探讨基于最小群体线索（‘我们’vs‘他们’）引发的内群体偏见。当这种群体边界与智能体-人类划分重合时，可能导致人类整体被智能体视为外群体的系统性风险，这比传统人口统计偏见更具根本性。

Method: 1. 构建受控的多智能体社会模拟环境，基于明确收益权衡的分配决策任务；2. 设计信念投毒攻击（BPA），包括初始化时的档案投毒（BPA-PP）和通过优化信念精炼后缀注入存储反思的记忆投毒（BPA-MP）；3. 通过大量实验验证智能体内群体偏见的存在和BPA的有效性。

Result: 1. 智能体在最小群体线索下表现出稳定的内群体偏见；2. 当部分交互对象被标注为人类时，偏见会减弱，但这种减弱依赖于智能体对‘真实人类存在’的信念激活的人类规范脚本；3. BPA能有效抑制人类规范脚本，重新激活对人类的外群体偏见；4. 实验证明了智能体内群体偏见的普遍性和BPA在各种设置下的严重性。

Conclusion: 智能体存在将人类视为外群体的内群体偏见风险，且这种偏见的调节机制依赖于智能体对人类存在的信念，形成了新的攻击面。BPA通过投毒身份信念可重新激活对人类的外群体偏见。研究旨在通过识别这些漏洞为更安全的智能体设计提供参考，而非促进现实世界攻击。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [17] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar,Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: 本文提出ReCiSt框架，受生物自愈机制启发，为分布式计算连续系统设计基于语言模型的自主故障恢复方案，实现快速自愈与知识积累。


<details>
  <summary>Details</summary>
Motivation: 分布式计算连续系统因异构性、移动性和动态环境面临频繁故障，传统方法难以实现可扩展、自适应的弹性恢复，需借鉴生物系统的自组织修复能力。

Method: 将生物愈合四阶段（止血、炎症、增殖、重塑）映射为计算四层（隔离、诊断、元认知、知识），利用语言模型代理解析异构日志、推断根因、动态重构资源。

Result: 在公开故障数据集上验证，不同语言模型均能在数十秒内完成自愈，代理CPU占用最低10%，并展示了对不确定性的深度分析和微代理调用机制的有效性。

Conclusion: ReCiSt通过生物启发架构与语言模型代理的结合，为复杂分布式系统提供了自主、高效、可积累知识的弹性恢复新范式。

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [18] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: 提出自适应因果协调检测框架ACCD，通过三阶段渐进架构动态学习最优检测配置，显著提升社交平台协调不实行为检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖浅层相关性分析、使用静态参数且需要大量人工标注，难以有效检测社交媒体的协调不实行为。

Method: 采用三阶段架构：1) 自适应收敛交叉映射技术识别账户间真实因果关系；2) 半监督分类结合主动学习减少人工标注；3) 基于历史经验的自动验证模块优化检测结果。

Result: 在真实数据集上，ACCD的F1分数达87.3%，比现有最佳基线提升15.2%；人工标注需求减少68%，处理速度提升2.8倍。

Conclusion: ACCD为社交平台协调行为检测提供了更准确、高效、自动化的端到端解决方案，具有重要实践价值和广泛应用潜力。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [19] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 将语义空间推理从计算语言学扩展到团队运动的战术决策，通过将球员视为向量、团队配置视为语义结构，在共享向量空间中评估战术匹配度与对手利用潜力，并开发了可生成动态自适应策略建议的原型系统。


<details>
  <summary>Details</summary>
Motivation: 传统计算语言学中的语义空间方法（如词向量与语义组合）尚未系统应用于团队战术决策；通过类比“文本-团队”（球员如词、集体配合如语义），旨在为团队运动提供可解释、数据驱动的战术分析与优化框架。

Method: 1. 将球员表示为多维向量（整合技术、身体、心理属性）；2. 通过上下文加权聚合为团队语义表示；3. 在共享向量空间中编码战术模板（如高位压迫、反击）；4. 使用向量距离度量评估战术匹配度与对手利用潜力；5. 开发Python原型实现动态策略推荐与属性级诊断。

Result: 原型系统能够生成可解释的动态战术建议，并提供细粒度的属性级诊断洞察；方法展示了跨领域泛化潜力（如篮球、冰球、协作机器人、人-AI协调系统）。

Conclusion: 该框架为团队集体决策与性能优化提供了通用方法；未来方向包括真实数据集成、预测性模拟以及混合人机战术智能系统的开发。

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [20] [Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation](https://arxiv.org/abs/2601.00475)
*Sankar B,Srinidhi Ranjini Girish,Aadya Bharti,Dibakar Sen*

Main category: cs.AI

TL;DR: 提出MIDAS框架，通过分布式AI代理团队模拟人类元认知构思流程，解决新手设计师创意生成中新颖性和多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前'单次爆发'式AI系统会产生大量语义聚集的创意，加剧了新手设计师在生成真正新颖多样创意方面的认知挑战。

Method: 采用分布式专业化AI代理团队架构，模拟人类元认知构思工作流，逐步优化创意并评估每个创意的全局新颖性（与现有解决方案对比）和局部新颖性（与已生成创意对比）。

Result: MIDAS框架展示了可行且渐进式的人机共创范式，将人类设计师从被动筛选者提升为参与式、主动的协作伙伴。

Conclusion: 该研究提出了一种新的人机协同设计范式，通过分布式智能体系统有效支持创意生成，实现了真正的人机共创。

Abstract: The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.

</details>


### [21] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 该研究质疑推理模型是否真正具有“顿悟”时刻，通过大规模分析发现推理过程中的策略转变罕见且不提升准确性，表明这些转变是不稳定推理行为的症状而非自我纠正机制。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为模型（如DeepSeek-R1-Zero）在推理过程中会出现突然的策略转变，暗示其具有自我纠正能力，但尚不清楚这种内在转变是否真正提升性能。

Method: 分析了超过100万条推理轨迹、数百个训练检查点，涵盖三个推理领域、多种解码温度和模型架构，通过检测训练过程中的推理策略转变进行研究。

Result: 发现推理策略转变非常罕见，不随训练变得更频繁，且很少提高准确性；但其效果随模型不确定性变化，在高熵条件下人为触发外部转变可可靠提升准确性。

Conclusion: 推理过程中的策略转变是不稳定推理行为的症状，而非内在的自我纠正机制，但可通过外部干预在高不确定性条件下改善性能。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [22] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: 本文提出难度感知直接偏好优化（DA-DPO）框架，通过估计偏好数据难度并重加权训练样本，缓解多模态大语言模型在偏好优化中的过拟合问题，提升抗幻觉能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态直接偏好优化方法因偏好数据难度不平衡容易过拟合，模型过度关注易区分样本，导致细粒度幻觉抑制不足和整体性能下降。

Method: 1. 难度估计：利用预训练视觉-语言模型结合生成式和对比式目标，通过分布感知投票策略生成难度分数；2. 难度感知训练：根据估计难度重加权偏好对，降低简单样本权重，强调困难样本。

Result: 大量实验表明DA-DPO能持续改进多模态偏好优化，在标准基准测试中表现出更强的抗幻觉鲁棒性和更好的泛化能力，且保持计算高效性。

Conclusion: DA-DPO通过难度感知机制平衡学习过程，无需新数据或额外微调阶段，能更有效地优化多模态大语言模型的偏好对齐。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [23] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: 提出AgenticDomiKnowS（ADS），通过智能体工作流将自由形式任务描述自动转换为完整的DomiKnowS程序，显著降低神经符号程序开发门槛和时间。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号集成框架（如DomiKnowS）仍需用户掌握特定语法，开发过程耗时且具有挑战性，阻碍了符号约束与深度学习模型的高效结合。

Method: 采用智能体工作流，将任务描述分解为独立的DomiKnowS组件并分别创建和测试，支持可选的人工干预环节供用户优化中间结果。

Result: ADS使熟悉或不熟悉DomiKnowS的用户均能快速构建神经符号程序，将开发时间从数小时缩短至10-15分钟。

Conclusion: ADS通过自动化程序生成和灵活的人机协作机制，有效解决了神经符号编程的易用性问题，提升了开发效率。

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>


### [24] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: 本研究提出PedX-LLM框架，通过视觉特征、文本数据和交通领域知识增强的大型语言模型，将行人过街行为推断从特定场景模式识别提升为可泛化的行为推理，在准确性和泛化性上均优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法（统计模型与监督学习）泛化能力有限，在新场景表现不佳；现有大语言模型应用缺乏领域适应性和视觉上下文理解。

Method: 提出PedX-LLM框架：集成LLaVA提取的视觉特征与文本数据及交通领域知识，通过LoRA对LLaMA-2-7B基础模型进行微调，支持零样本和少样本学习，并进行跨场景验证。

Result: PedX-LLM平衡准确率达82.0%，优于最佳传统方法；视觉增强模块贡献2.9%性能提升，领域知识集成贡献4.1%；在五个未见测试场景中，零样本配置平衡准确率达66.9%（比基线高至少18%），少样本学习（仅5个示例）可进一步提升至72.2%。

Conclusion: PedX-LLM通过视觉与知识增强的推理机制，模拟类人决策逻辑，克服纯数据驱动方法的局限性，展现出对未见场景的强泛化能力。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [25] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051)
*Yabo Chen,Yuanzhi Liang,Jiepeng Wang,Tingxi Chen,Junfei Cheng,Zixiao Gu,Yuyang Huang,Zicheng Jiang,Wei Li,Tian Li,Weichen Li,Zuoxin Li,Guangce Liu,Jialun Liu,Junqi Liu,Haoyuan Wang,Qizhen Weng,Xuan'er Wu,Xunzhi Xiang,Xiaoyan Yang,Xin Zhang,Shiwen Zhang,Junyu Zhou,Chengcheng Zhou,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleWorld是一个实时多模态4D世界建模框架，通过生成-重建-引导范式统一视频生成、动态场景重建和长期世界记忆，实现时空一致性和实时交互。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在实时交互、长时程一致性和动态场景持久记忆方面存在局限，阻碍其发展为实用的世界模型。

Method: 提出生成-重建-引导范式，将生成视频流重建为动态4D时空表示以引导后续生成；采用自回归扩散视频模型，结合宏观-微观规划（MMPL）减少误差累积，并通过分布匹配蒸馏（DMD）实现实时合成。

Result: 实验表明TeleWorld在静态/动态世界理解、长期一致性和实时生成效率方面表现优异，支持动态对象建模与静态场景表示的统一4D集成。

Conclusion: 该框架推动了世界模型向实用化、交互式和计算可访问系统发展，为多模态生成和具身智能提供了具备记忆功能的交互式世界模型实践方案。

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.

</details>


### [26] [It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models](https://arxiv.org/abs/2601.00090)
*Anne Harrington,A. Sophia Koepke,Shyamgopal Karthik,Trevor Darrell,Alexei A. Efros*

Main category: cs.CV

TL;DR: 本文提出通过噪声优化解决文本到图像生成模型中的模式崩溃问题，提高生成图像的多样性同时保持模型保真度。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型存在明显的模式崩溃问题，即相同文本提示下生成的图像缺乏多样性。现有方法主要通过引导机制或候选池筛选来改进，但本文探索了不同的方向。

Method: 提出简单的噪声优化目标，通过优化初始噪声来增加生成多样性；分析噪声的频率特性，探索不同频率分布的噪声初始化对优化和搜索的影响。

Result: 实验表明，噪声优化方法在生成质量和多样性方面均优于现有方法，能有效缓解模式崩溃问题。

Conclusion: 噪声优化是一种简单有效的解决文本到图像生成模式崩溃的方法，通过优化噪声初始化和频率特性可以显著提升生成多样性。

Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.

</details>


### [27] [Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark](https://arxiv.org/abs/2601.00092)
*Pan Wang,Yang Liu,Guile Wu,Eduardo R. Corral-Soto,Chengjie Huang,Binbin Xu,Dongfeng Bai,Xu Yan,Yuan Ren,Xingxin Chen,Yizhe Wu,Tao Huang,Wenjun Wan,Xin Wu,Pei Zhou,Xuyang Dai,Kangbo Lv,Hongbo Zhang,Yosef Fried,Aixue Ye,Bailan Feng,Zhenyu Chen,Zhen Li,Yingcong Chen,Yiyi Liao,Bingbing Liu*

Main category: cs.CV

TL;DR: 本文提出了Spatial4D-Bench，一个用于评估多模态大语言模型4D空间智能的大规模基准测试，包含约40,000个问题-答案对，涵盖18个任务和6个认知类别。


<details>
  <summary>Details</summary>
Motivation: 人类天生具备4D空间智能，但现有空间智能基准测试规模小或多样性不足，无法全面评估多模态大语言模型是否达到人类水平的4D空间智能。

Method: 构建了Spatial4D-Bench基准测试，包含约40,000个问题-答案对，涵盖18个任务，这些任务被系统组织为6个认知类别：物体理解、场景理解、空间关系理解、时空关系理解、空间推理和时空推理。

Result: 对多种先进的开源和专有多模态大语言模型进行基准测试，发现它们在多种4D空间推理方面存在显著局限性，如路径规划、动作识别和物理合理性推理。

Conclusion: 该基准测试为社区提供了有价值的见解，有望促进开发更具能力的多模态大语言模型，以实现人类水平的4D空间智能。

Abstract: 4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.

</details>


### [28] [A Spatially Masked Adaptive Gated Network for multimodal post-flood water extent mapping using SAR and incomplete multispectral data](https://arxiv.org/abs/2601.00123)
*Hyunho Lee,Wenwen Li*

Main category: cs.CV

TL;DR: 提出SMAGNet模型，通过自适应融合SAR和多光谱影像数据，提升洪水淹没范围制图的准确性和鲁棒性，尤其在多光谱数据部分缺失时仍能保持良好性能。


<details>
  <summary>Details</summary>
Motivation: 洪水期间及时准确的水域制图对灾害管理至关重要。现有方法多依赖SAR数据，但多光谱影像（MSI）能提供互补信息。然而，洪水期间MSI数据可能部分缺失，如何自适应融合部分可用的MSI数据与SAR数据进行水域制图尚未充分探索。

Method: 提出空间掩码自适应门控网络（SMAGNet），以SAR数据为主要输入，通过特征融合自适应整合互补的MSI数据，设计机制处理MSI数据部分缺失的情况。

Result: 在C2S-MS Floods数据集上，SMAGNet在不同MSI数据可用性条件下均优于其他多模态深度学习模型；即使MSI数据完全缺失，其性能仍与仅使用SAR数据训练的U-Net模型相当。

Conclusion: SMAGNet提升了模型对缺失数据的鲁棒性，增强了多模态深度学习在真实洪水管理场景中的适用性，为洪水响应提供了更可靠的技术支持。

Abstract: Mapping water extent during a flood event is essential for effective disaster management throughout all phases: mitigation, preparedness, response, and recovery. In particular, during the response stage, when timely and accurate information is important, Synthetic Aperture Radar (SAR) data are primarily employed to produce water extent maps. Recently, leveraging the complementary characteristics of SAR and MSI data through a multimodal approach has emerged as a promising strategy for advancing water extent mapping using deep learning models. This approach is particularly beneficial when timely post-flood observations, acquired during or shortly after the flood peak, are limited, as it enables the use of all available imagery for more accurate post-flood water extent mapping. However, the adaptive integration of partially available MSI data into the SAR-based post-flood water extent mapping process remains underexplored. To bridge this research gap, we propose the Spatially Masked Adaptive Gated Network (SMAGNet), a multimodal deep learning model that utilizes SAR data as the primary input for post-flood water extent mapping and integrates complementary MSI data through feature fusion. In experiments on the C2S-MS Floods dataset, SMAGNet consistently outperformed other multimodal deep learning models in prediction performance across varying levels of MSI data availability. Furthermore, we found that even when MSI data were completely missing, the performance of SMAGNet remained statistically comparable to that of a U-Net model trained solely on SAR data. These findings indicate that SMAGNet enhances the model robustness to missing data as well as the applicability of multimodal deep learning in real-world flood management scenarios.

</details>


### [29] [Compressed Map Priors for 3D Perception](https://arxiv.org/abs/2601.00139)
*Brady Zhou,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: 提出压缩地图先验框架，利用历史遍历数据学习空间先验，显著提升自动驾驶3D目标检测性能


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶视觉系统通常忽略历史遍历信息，而人类驾驶员会利用已知道路经验。研究旨在利用历史数据建立高效空间先验

Method: 使用二值化哈希映射存储空间先验信息，实现每平方公里仅需32KB存储，比密集存储减少20倍。该框架可无缝集成到主流3D感知系统中

Result: 在nuScenes数据集上，该方法在多种架构中均实现3D目标检测性能的显著且一致提升，计算成本几乎为零

Conclusion: 压缩地图先验是一种简单有效的框架，能利用历史数据提升自动驾驶感知系统性能，且存储效率极高

Abstract: Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\text{KB}/\text{km}^2$, a $20\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.

</details>


### [30] [Attention to Detail: Global-Local Attention for High-Resolution AI-Generated Image Detection](https://arxiv.org/abs/2601.00141)
*Lawrence Han*

Main category: cs.CV

TL;DR: 提出GLASS架构，通过全局重采样与多随机局部裁剪结合，提升AI生成图像检测性能，优于标准迁移学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测方法通常对图像进行降采样，可能导致细节丢失，影响检测准确性。

Method: 设计GLASS架构，结合全局重采样视图与多个随机局部裁剪（通过空间分层采样选取原始分辨率区域），使用基于注意力的评分进行聚合，可集成到Vision Transformer、ResNet和ConvNeXt等视觉模型中。

Result: 实验表明，GLASS在可行计算约束下，比标准迁移学习获得更高的预测性能。

Conclusion: GLASS架构能有效利用图像的全局与局部信息，提升AI生成图像检测的准确性，适用于任意尺寸图像。

Abstract: The rapid development of generative AI has made AI-generated images increasingly realistic and high-resolution. Most AI-generated image detection architectures typically downsample images before inputting them into models, risking the loss of fine-grained details. This paper presents GLASS (Global-Local Attention with Stratified Sampling), an architecture that combines a globally resized view with multiple randomly sampled local crops. These crops are original-resolution regions efficiently selected through spatially stratified sampling and aggregated using attention-based scoring. GLASS can be integrated into vision models to leverage both global and local information in images of any size. Vision Transformer, ResNet, and ConvNeXt models are used as backbones, and experiments show that GLASS outperforms standard transfer learning by achieving higher predictive performance within feasible computational constraints.

</details>


### [31] [FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications](https://arxiv.org/abs/2601.00150)
*Yehui Yang,Dalu Yang,Wenshuo Zhou,Fangxin Shang,Yifan Liu,Jie Ren,Haojun Fei,Qing Yang,Tao Chen*

Main category: cs.CV

TL;DR: 提出了金融信用多模态基准FCMBench-V1.0，包含4,043张合规图像和8,446个QA样本，用于评估视觉语言模型在信用风险评估中的感知、推理和鲁棒性能力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对金融信用应用的多模态基准，需要反映特定文档和工作流程、包含信用特定理解与真实鲁棒性，并确保隐私合规性。

Method: 通过封闭式合成-采集流程构建样本：手动合成虚拟内容的文档模板，并在内部采集场景感知图像，避免使用网络或公开图像。基准包含3个感知任务、4个信用特定推理任务和10种真实采集伪影类型。

Result: 评估了23个先进视觉语言模型，Gemini 3 Pro在商业模型中表现最佳（F1 64.61%），Qwen3-VL-235B在开源模型中最佳（57.27%），而金融信用特定模型Qfin-VL-Instruct总体最佳（64.92%）。鲁棒性测试显示，即使顶级模型在采集伪影下性能也明显下降。

Conclusion: FCMBench能有效区分视觉语言模型的性能差异和鲁棒性，为金融信用多模态AI提供了实用的评估工具，并强调了真实场景鲁棒性的重要性。

Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.

</details>


### [32] [Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions](https://arxiv.org/abs/2601.00156)
*Kaiwen Zheng,Junchen Fu,Songpei Xu,Yaoqing He,Joemon M. Jose,Han Hu,Xuri Ge*

Main category: cs.CV

TL;DR: 本文提出了FaceFocalDesc任务，通过构建区域级多属性描述数据集并开发Focal-RegionFace模型，实现了对任意选定面部区域的细粒度多属性自然语言描述生成与识别。


<details>
  <summary>Details</summary>
Motivation: 现有面部分析系统缺乏对局部面部区域的细粒度多属性描述能力，限制了系统的理解与控制精度。本文旨在通过关注个体面部区域，提升面部状态分析的精细度和可解释性。

Method: 1. 构建包含面部动作单元、情绪状态和年龄估计的多属性区域描述数据集；2. 基于Qwen2.5-VL提出Focal-RegionFace模型，通过多阶段渐进微调策略逐步聚焦局部面部特征。

Result: Focal-RegionFace在新基准测试中取得最佳性能，在传统指标和新提出指标上均表现优异，验证了其在细粒度多属性面部区域聚焦分析场景中的有效性和通用性。

Conclusion: 通过区域聚焦的面部分析方法能显著提升面部状态分析的精细度和可解释性，为面部理解与控制提供了新方向。所提出的数据集和模型为相关研究提供了基准和工具。

Abstract: In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

</details>


### [33] [DichroGAN: Towards Restoration of in-air Colours of Seafloor from Satellite Imagery](https://arxiv.org/abs/2601.00194)
*Salma Gonzalez-Sabbagh,Antonio Robles-Kelly,Shang Gao*

Main category: cs.CV

TL;DR: 提出DichroGAN，一种条件生成对抗网络，用于从卫星图像中恢复海底的空中颜色，通过估计大气场景辐射和水中光传输来消除光吸收和散射的影响。


<details>
  <summary>Details</summary>
Motivation: 由于光在水柱中随深度呈指数衰减，从卫星图像中恢复海底的空中颜色具有挑战性，需要有效的水下图像恢复方法。

Method: 使用条件生成对抗网络（cGAN），采用两步同时训练：两个生成器利用高光谱图像立方体估计漫反射和镜面反射，获得大气场景辐射；另外两个生成器分别处理场景辐射特征和估计水下光传输，基于水下图像形成方程恢复颜色。

Result: 在PRISMA卫星图像数据集和多个水下数据集上的实验表明，DichroGAN在水下恢复任务中达到了与最先进技术相竞争的性能。

Conclusion: DichroGAN能够有效恢复海底的空中颜色，为卫星图像的水下恢复提供了一种有前景的解决方案。

Abstract: Recovering the in-air colours of seafloor from satellite imagery is a challenging task due to the exponential attenuation of light with depth in the water column. In this study, we present DichroGAN, a conditional generative adversarial network (cGAN) designed for this purpose. DichroGAN employs a two-steps simultaneous training: first, two generators utilise a hyperspectral image cube to estimate diffuse and specular reflections, thereby obtaining atmospheric scene radiance. Next, a third generator receives as input the generated scene radiance containing the features of each spectral band, while a fourth generator estimates the underwater light transmission. These generators work together to remove the effects of light absorption and scattering, restoring the in-air colours of seafloor based on the underwater image formation equation. DichroGAN is trained on a compact dataset derived from PRISMA satellite imagery, comprising RGB images paired with their corresponding spectral bands and masks. Extensive experiments on both satellite and underwater datasets demonstrate that DichroGAN achieves competitive performance compared to state-of-the-art underwater restoration techniques.

</details>


### [34] [MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing](https://arxiv.org/abs/2601.00204)
*Xiaokun Sun,Zeyu Cai,Hao Tang,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: 提出MorphAny3D框架，通过结构化潜在表示实现高质量3D变形，支持跨类别变形并保持语义一致性和时间平滑性。


<details>
  <summary>Details</summary>
Motivation: 现有3D变形方法在生成语义一致且时间平滑的变形序列方面存在困难，尤其是跨类别变形时效果不佳。

Method: 基于结构化潜在表示，提出变形交叉注意力机制融合源和目标特征，使用时序融合自注意力增强时间一致性，并采用方向校正策略缓解姿态模糊问题。

Result: 实验表明该方法能生成最先进的变形序列，在跨类别变形等挑战性任务上表现优异，并支持解耦变形和3D风格迁移等应用。

Conclusion: MorphAny3D为3D变形提供了有效的免训练解决方案，可推广至其他基于结构化潜在表示的生成模型。

Abstract: 3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.

</details>


### [35] [CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting](https://arxiv.org/abs/2601.00207)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 提出一种基于多视角图像和神经辐射场（NeRF）的三维实例分割框架，用于精确统计田间作物数量，在棉花、苹果和梨数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 户外田间环境中，作物部分遮挡和聚集导致的视觉歧义使基于图像的二维分割方法难以精确计数，需开发更鲁棒的三维计数方法。

Method: 利用多视角二维图像生成实例掩码，结合NeRF合成三维信息，引入作物可见性和掩码一致性评分，实现无需作物特定参数调优的三维实例分割。

Result: 在棉花、苹果和梨数据集上实现了高精度计数，性能优于现有方法，且对作物颜色、形状和尺寸变化具有鲁棒性。

Conclusion: 该框架通过三维实例分割有效解决了户外作物计数难题，贡献了棉花数据集以促进相关研究，为农业管理提供了可靠技术工具。

Abstract: Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.

</details>


### [36] [IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation](https://arxiv.org/abs/2601.00212)
*Han Liu,Yubo Fan,Hao Li,Dewei Hu,Daniel Moyer,Zhoubing Xu,Benoit M. Dawant,Ipek Oguz*

Main category: cs.CV

TL;DR: 提出IntraStyler方法，通过示例图像引导风格合成，无需先验知识即可捕获多样的域内风格，提升跨模态域适应的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域适应方法主要关注源域与目标域间的域偏移，而域内变异性研究不足。传统方法需预先指定域内变化进行风格合成，这在实际中可能不切实际。

Method: 提出基于示例的风格合成方法IntraStyler，使用示例图像引导风格合成；引入基于对比学习的风格编码器，以判别方式学习风格特征；在CrossMoDA 2023数据集上评估。

Result: 实验证明该方法在可控风格合成方面有效，且多样化的合成数据有利于下游分割任务。

Conclusion: IntraStyler能够无需先验知识捕获多样域内风格，为跨模态域适应提供更有效的图像级对齐方法。

Abstract: Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.

</details>


### [37] [From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2601.00215)
*Omar Sharif,Eftekhar Hossain,Patrick Ng*

Main category: cs.CV

TL;DR: 该论文提出了一种基于奖励驱动强化学习的方法，用于提升开源多模态大语言模型在视觉推理任务中的表现，通过设计多种奖励函数激励模型整合视觉信息并生成更长的结构化推理链。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在生成推理链时缺乏对视觉信息的有效整合，导致其在需要精确视觉感知的任务（如视觉谜题）上表现受限。研究表明，将图像转换为文本描述可显著提升性能，但现有方法成本高昂且效果有限。

Method: 采用奖励驱动的强化学习机制，设计了六种针对不同推理维度的奖励函数（包括图像理解、思维步骤和答案准确性），并使用组相对策略优化（GRPO）方法，以无监督方式激励模型生成更长、结构化的推理链，避免视觉信息被忽略。

Result: 在Qwen-2.5-VL-7B模型上的实验显示，该方法相比基线模型提升了5.56%的性能，并在领域内和领域外任务中均取得一致性的改进。此前实验表明，将图像转为文本描述可使Claude 3.5和Claude 3.7分别提升26.7%和23.6%的性能。

Conclusion: 强化学习能有效提升多模态大语言模型的视觉推理能力，通过设计针对性奖励函数可激励模型更好地整合视觉信息，该方法为低成本提升开源模型在复杂视觉任务上的性能提供了可行路径。

Abstract: Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.
  To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.

</details>


### [38] [LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization](https://arxiv.org/abs/2601.00222)
*Jie Li,Kwan-Yee K. Wong,Kai Han*

Main category: cs.CV

TL;DR: 本文提出LooC方法，通过低维组合码本实现更紧凑高效的向量量化，在多个任务和数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 随着数据和模型复杂度增加，现有向量量化方法在容量和紧凑性之间存在矛盾，需要既能保持高容量又更紧凑的VQ方法。

Method: 1) 将码向量重构为特征向量内的低维组合单元，通过组合方式扩展解空间；2) 引入无需参数的插值外推机制增强特征平滑；3) 设计为即插即用模块，支持不同下游任务。

Result: LooC在多个任务、数据集和架构上的评估显示，其性能优于现有VQ方法，使用显著更小的码本实现了最先进性能，并避免了码本崩溃问题。

Conclusion: LooC通过低维组合码本设计，成功解决了向量量化中容量与紧凑性的矛盾，为VQ相关应用提供了高效可扩展的解决方案。

Abstract: Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.

</details>


### [39] [Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions](https://arxiv.org/abs/2601.00225)
*Aobo Li,Jinjian Wu,Yongxu Liu,Leida Li,Weisheng Dong*

Main category: cs.CV

TL;DR: 本文提出SynDR-IQA框架，通过重塑合成数据分布来提升盲图像质量评估模型的泛化能力，解决了现有合成数据集训练模型泛化性差的问题。


<details>
  <summary>Details</summary>
Motivation: 盲图像质量评估面临标注数据稀缺的挑战，合成数据虽能缓解此问题，但现有基于合成数据训练的模型泛化能力有限。研究发现，合成数据学习到的特征呈现离散聚类模式（高质量图像围绕参考图像聚类，低质量图像按失真类型聚类），这源于数据分布问题而非模型架构。

Method: 提出SynDR-IQA框架，基于样本多样性和冗余度对泛化误差影响的理论推导，采用两种策略：1）分布感知的多样化内容上采样，在保持内容分布的同时增强视觉多样性；2）密度感知的冗余聚类下采样，通过降低密集聚类区域的样本密度来平衡数据分布。

Result: 在三种跨数据集设置（合成到真实、合成到算法、合成到合成）上的大量实验证明了方法的有效性，显著提升了盲图像质量评估模型的泛化性能。

Conclusion: 通过重塑合成数据分布，SynDR-IQA框架能够有效提升盲图像质量评估模型的泛化能力，为解决合成数据训练模型的泛化局限提供了新思路。

Abstract: Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.

</details>


### [40] [Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection](https://arxiv.org/abs/2601.00237)
*Chao Yang,Haoyuan Zheng,Yue Ma*

Main category: cs.CV

TL;DR: 提出一种结合CycleGAN和YOLOv8的跨模态数据增强框架，通过将可见光PCB图像转换为红外图像来缓解红外数据稀缺问题，提升PCB缺陷检测性能。


<details>
  <summary>Details</summary>
Motivation: 红外（IR）数据稀缺是PCB缺陷检测的关键瓶颈，传统方法依赖配对监督数据，难以在低数据条件下有效训练检测模型。

Method: 使用CycleGAN进行无配对图像转换，将丰富的可见光PCB图像映射到红外域，生成高质量伪红外样本；采用异构训练策略，融合生成数据与有限真实红外数据训练轻量级YOLOv8检测器。

Result: 该方法在低数据条件下有效增强特征学习，检测器性能显著优于仅使用有限真实数据训练的模型，并接近全监督训练的基准水平。

Conclusion: 伪红外合成作为一种鲁棒的数据增强策略，能有效解决红外数据稀缺问题，提升工业检测的实用性和性能。

Abstract: This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.

</details>


### [41] [Context-Aware Pesticide Recommendation via Few-Shot Pest Recognition for Precision Agriculture](https://arxiv.org/abs/2601.00243)
*Anirudha Ghosh,Ritam Sarkar,Debaditya Barman*

Main category: cs.CV

TL;DR: 提出一个轻量级框架，用于害虫检测和农药推荐，适用于智能手机和无人机等低资源设备，帮助小农户实现精准农业。


<details>
  <summary>Details</summary>
Motivation: 传统害虫管理方法依赖人工田间检查和化学农药，成本高、耗时长、劳动密集且对环境有害，需要一种高效、环保且适用于资源有限设备的解决方案。

Method: 框架包含两个模块：1) 害虫检测模块，采用轻量级卷积神经网络结合原型元学习，在少量训练样本下准确识别害虫；2) 农药推荐模块，结合作物类型和生长阶段等环境因素，推荐安全环保的农药。使用综合害虫图像数据集进行训练和评估。

Result: 轻量级CNN在保持高精度的同时显著降低计算复杂度，性能与先进模型相当；决策支持系统减少了对传统化学农药的依赖，促进了可持续农业实践。

Conclusion: 该框架在精准农业中具有实时应用潜力，能够帮助小农户实现高效、环保的害虫管理。

Abstract: Effective pest management is crucial for enhancing agricultural productivity, especially for crops such as sugarcane and wheat that are highly vulnerable to pest infestations. Traditional pest management methods depend heavily on manual field inspections and the use of chemical pesticides. These approaches are often costly, time-consuming, labor-intensive, and can have a negative impact on the environment. To overcome these challenges, this study presents a lightweight framework for pest detection and pesticide recommendation, designed for low-resource devices such as smartphones and drones, making it suitable for use by small and marginal farmers.
  The proposed framework includes two main components. The first is a Pest Detection Module that uses a compact, lightweight convolutional neural network (CNN) combined with prototypical meta-learning to accurately identify pests even when only a few training samples are available. The second is a Pesticide Recommendation Module that incorporates environmental factors like crop type and growth stage to suggest safe and eco-friendly pesticide recommendations. To train and evaluate our framework, a comprehensive pest image dataset was developed by combining multiple publicly available datasets. The final dataset contains samples with different viewing angles, pest sizes, and background conditions to ensure strong generalization.
  Experimental results show that the proposed lightweight CNN achieves high accuracy, comparable to state-of-the-art models, while significantly reducing computational complexity. The Decision Support System additionally improves pest management by reducing dependence on traditional chemical pesticides and encouraging sustainable practices, demonstrating its potential for real-time applications in precision agriculture.

</details>


### [42] [Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers](https://arxiv.org/abs/2601.00359)
*Söhnke Benedikt Fischedick,Daniel Seichter,Benedict Stephan,Robin Schmidt,Horst-Michael Gross*

Main category: cs.CV

TL;DR: 提出DVEFormer，一种基于RGB-D Transformer的高效方法，通过知识蒸馏预测密集文本对齐视觉嵌入，替代传统语义分割，支持自然语言查询和3D建图。


<details>
  <summary>Details</summary>
Motivation: 家庭环境中机器人需要全面理解环境以与未经训练的人类有效交互，传统语义分割的固定类别限制了灵活性和应用范围。

Method: 使用Alpha-CLIP的教师嵌入指导高效学生模型DVEFormer学习细粒度像素级嵌入，基于RGB-D Transformer架构，通过知识蒸馏实现实时推理。

Result: 在室内数据集上达到竞争性性能，完整模型26.3 FPS，轻量版77.0 FPS（NVIDIA Jetson AGX Orin），支持文本查询和3D建图应用。

Conclusion: 该方法可作为传统分割的直接替代，同时支持灵活的自然语言查询和移动机器人3D建图流程的无缝集成。

Abstract: In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

</details>


### [43] [TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models](https://arxiv.org/abs/2601.00260)
*Kohei Yamamoto,Tomohiro Kikuchi*

Main category: cs.CV

TL;DR: 提出TotalFM，一种基于器官分离概念的放射学基础模型，通过自动化器官分割和LLM处理报告生成器官体积-文本对，结合自监督预训练和对比学习，在零样本器官和病灶分类任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 3D-CT体积数据训练的计算成本限制是放射学基础模型临床应用的主要挑战，需要平衡计算效率和表征能力。

Method: 1. 利用分割技术和LLM自动创建14万系列的器官体积-发现句子对；2. 结合VideoMAE自监督预训练和体积-文本对的对比学习；3. 采用器官分离学习框架。

Result: 1. 零样本器官病灶分类：在83%器官上F1分数高于CT-CLIP，64%器官上高于Merlin；2. 零样本病灶分类：在83%类别上AUROC高于Merlin；3. 放射学报告生成任务性能与现有VLM相当。

Conclusion: 器官分离学习框架可作为3D-CT基础模型实际应用的有效设计指南，在临床评估中展现出高泛化性能。

Abstract: While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.

</details>


### [44] [S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding](https://arxiv.org/abs/2601.00264)
*He Wang,Longteng Guo,Pengkang Huo,Xuanxu Lin,Yichen Yuan,Jie Jiang,Jing Liu*

Main category: cs.CV

TL;DR: 提出了S1-MMAlign数据集，包含1550万高质量科学图像-文本对，通过AI增强管道提升语义对齐，为科学AI提供基础资源。


<details>
  <summary>Details</summary>
Motivation: 科学领域多模态学习受限于复杂图像与稀疏文本描述间的语义鸿沟，缺乏高质量对齐数据阻碍科学发现应用。

Method: 从250万开放论文构建跨学科数据集，利用Qwen-VL多模态大模型结合论文摘要和引用上下文重新生成图像描述以增强语义对齐。

Result: 增强后数据质量显著提升：SciBERT伪困惑度显示语义模糊性降低，CLIP分数表明图文对齐改善18.21%。

Conclusion: S1-MMAlign通过语义增强解决了科学图文弱对齐问题，为推进科学推理和跨模态理解提供了关键数据集基础。

Abstract: Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.

</details>


### [45] [RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization](https://arxiv.org/abs/2601.00705)
*Wei-Tse Cheng,Yen-Jen Chiou,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: RGS-SLAM是一种基于高斯分布的SLAM框架，通过一次性三角化密集多视角对应点来初始化高斯分布，替代了传统的残差驱动稠密化过程，提升了渲染质量和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统GS-SLAM采用残差驱动的高斯分布稠密化方法，在纹理丰富和杂乱场景中可能导致初始化不稳定和收敛缓慢。本研究旨在通过更结构化的初始化方法来改善这些问题。

Method: 使用DINOv3描述符提取密集多视角对应点，通过置信度感知的内点分类器进行精炼，然后进行一次性三角化生成高斯分布种子，再进行优化。该方法与现有GS-SLAM流程完全兼容。

Result: 在TUM RGB-D和Replica数据集上评估显示，RGS-SLAM比传统方法收敛速度提升约20%，在纹理丰富和杂乱场景中渲染质量更高，定位和重建精度达到或超过当前最先进的高斯和点云SLAM系统，实时映射性能最高可达925 FPS。

Conclusion: RGS-SLAM通过训练无关的对应点到高斯分布的初始化方法，显著提升了SLAM系统的稳定性、收敛速度和渲染质量，同时保持了实时性能，为高斯分布SLAM提供了一种有效的改进方案。

Abstract: We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.

</details>


### [46] [ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching](https://arxiv.org/abs/2601.00267)
*Yi Sun,Xinhao Zhong,Hongyan Li,Yimin Zhou,Junhao Li,Bin Chen,Xuan Wang*

Main category: cs.CV

TL;DR: 提出了一种无需训练的激活擦除方法ActErase，通过分析提示对识别激活差异区域，动态替换前向传播中的激活值，在保持模型生成能力的同时高效擦除敏感概念。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型存在安全、版权和伦理风险，而传统概念擦除方法依赖数据密集且计算成本高的微调，限制了实际应用。

Method: 基于模型激活主要由通用概念组成、仅极小部分表示目标概念的观察，通过提示对分析识别激活差异区域，提取目标激活并动态替换前向传播中的输入激活。

Result: 在裸露内容、艺术风格和对象移除三个关键擦除任务上达到最先进性能，有效保持模型整体生成能力，并对抗攻击表现出强鲁棒性。

Conclusion: ActErase为扩散模型中的概念操作建立了一种新的即插即用范式，实现了轻量级且高效的概念擦除。

Abstract: Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.

</details>


### [47] [FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering](https://arxiv.org/abs/2601.00269)
*Chaodong Tong,Qi Zhang,Chen Li,Lei Jiang,Yanbing Liu*

Main category: cs.CV

TL;DR: 提出FaithSCAN，一种轻量级网络，通过利用视觉语言模型（VLM）的内部信号（如解码不确定性、视觉表示和跨模态对齐特征）来检测视觉问答（VQA）中的幻觉，无需昂贵的人工标注，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VQA幻觉检测方法存在局限性：外部验证方法计算开销大且依赖外部资源质量，不确定性驱动方法仅捕捉模型不确定性的有限方面，未能充分探索与多样失败模式相关的丰富内部信号，导致效率、鲁棒性和检测性能不足。

Method: 1. 设计FaithSCAN网络，融合VLM内部信号：令牌级解码不确定性、中间视觉表示、跨模态对齐特征，通过分支证据编码和不确定性感知注意力进行融合。2. 扩展LLM-as-a-Judge范式至VQA幻觉检测，提出低成本策略自动生成模型依赖的监督信号，实现无需人工标注的监督训练。

Result: 在多个VQA基准测试中，FaithSCAN在效果和效率上均显著优于现有方法。深入分析表明，幻觉源于视觉感知、跨模态推理和语言解码的系统性内部状态变化，不同内部信号提供互补诊断线索，且幻觉模式因VLM架构而异。

Conclusion: FaithSCAN通过有效利用VLM内部信号，为多模态幻觉检测提供了高效、准确的解决方案，同时揭示了幻觉产生的内部机制，为理解多模态幻觉的根本原因提供了新见解。

Abstract: Faithfulness hallucinations in VQA occur when vision-language models produce fluent yet visually ungrounded answers, severely undermining their reliability in safety-critical applications. Existing detection methods mainly fall into two categories: external verification approaches relying on auxiliary models or knowledge bases, and uncertainty-driven approaches using repeated sampling or uncertainty estimates. The former suffer from high computational overhead and are limited by external resource quality, while the latter capture only limited facets of model uncertainty and fail to sufficiently explore the rich internal signals associated with the diverse failure modes. Both paradigms thus have inherent limitations in efficiency, robustness, and detection performance. To address these challenges, we propose FaithSCAN: a lightweight network that detects hallucinations by exploiting rich internal signals of VLMs, including token-level decoding uncertainty, intermediate visual representations, and cross-modal alignment features. These signals are fused via branch-wise evidence encoding and uncertainty-aware attention. We also extend the LLM-as-a-Judge paradigm to VQA hallucination and propose a low-cost strategy to automatically generate model-dependent supervision signals, enabling supervised training without costly human labels while maintaining high detection accuracy. Experiments on multiple VQA benchmarks show that FaithSCAN significantly outperforms existing methods in both effectiveness and efficiency. In-depth analysis shows hallucinations arise from systematic internal state variations in visual perception, cross-modal reasoning, and language decoding. Different internal signals provide complementary diagnostic cues, and hallucination patterns vary across VLM architectures, offering new insights into the underlying causes of multimodal hallucinations.

</details>


### [48] [Disentangling Hardness from Noise: An Uncertainty-Driven Model-Agnostic Framework for Long-Tailed Remote Sensing Classification](https://arxiv.org/abs/2601.00278)
*Chi Ding,Junxiao Xue,Xinyi Yin,Shi Chen,Yunyun Shi,Yiduo Wang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: 提出了一种名为DUAL的模型无关不确定性感知框架，用于解决遥感图像中长尾分布问题，通过动态分离预测不确定性为认知不确定性和偶然不确定性，分别处理难学习的尾部样本和噪声数据。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中地面物体的出现频率存在固有的不平衡性，导致长尾分布。现有方法往往不加区分地强调所有低置信度样本，容易在噪声数据上过拟合，因此需要一种能够区分难学习的尾部样本和模糊噪声样本的方法。

Method: 基于证据深度学习，提出DUAL框架：1）引入认知不确定性作为样本稀缺性的指标，指导对难学习尾部样本的重新加权策略；2）利用偶然不确定性量化数据模糊性，采用自适应标签平滑机制抑制噪声影响。

Result: 在多个数据集和各种骨干网络上的广泛实验表明，该框架有效且具有良好泛化能力，超越了TGN和SADE等强基线方法。消融研究进一步验证了设计选择的关键性。

Conclusion: DUAL框架通过动态分离两种不确定性，成功解决了长尾分布中难学习样本与噪声样本的区分问题，为遥感图像分析中的类别不平衡问题提供了有效的解决方案。

Abstract: Long-Tailed distributions are pervasive in remote sensing due to the inherently imbalanced occurrence of grounded objects. However, a critical challenge remains largely overlooked, i.e., disentangling hard tail data samples from noisy ambiguous ones. Conventional methods often indiscriminately emphasize all low-confidence samples, leading to overfitting on noisy data. To bridge this gap, building upon Evidential Deep Learning, we propose a model-agnostic uncertainty-aware framework termed DUAL, which dynamically disentangles prediction uncertainty into Epistemic Uncertainty (EU) and Aleatoric Uncertainty (AU). Specifically, we introduce EU as an indicator of sample scarcity to guide a reweighting strategy for hard-to-learn tail samples, while leveraging AU to quantify data ambiguity, employing an adaptive label smoothing mechanism to suppress the impact of noise. Extensive experiments on multiple datasets across various backbones demonstrate the effectiveness and generalization of our framework, surpassing strong baselines such as TGN and SADE. Ablation studies provide further insights into the crucial choices of our design.

</details>


### [49] [Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies](https://arxiv.org/abs/2601.00286)
*Ali Anaissi,Ali Braytee,Weidong Huang,Junaid Akram,Alaa Farhat,Jie Hua*

Main category: cs.CV

TL;DR: 开发基于Swin Transformer的深度学习模型，用于皮肤疾病图像分类，在ISIC2019数据集上对8种皮肤病变达到87.71%的准确率。


<details>
  <summary>Details</summary>
Motivation: 皮肤疾病日益普遍而皮肤科医生资源有限，需要智能工具支持患者和临床医生进行及时准确的皮肤疾病诊断。

Method: 利用公开皮肤疾病图像数据集进行预训练，提取视觉特征；优化模型架构、数据预处理流程，并应用针对性数据增强技术；最终采用Swin Transformer架构。

Result: 在ISIC2019数据集上，模型对8种皮肤病变类别的预测准确率达到87.71%。

Conclusion: 该模型展示了作为临床医生诊断支持工具和患者自我评估辅助工具的潜力。

Abstract: As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.

</details>


### [50] [SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting](https://arxiv.org/abs/2601.00285)
*Jun-Jee Chao,Volkan Isler*

Main category: cs.CV

TL;DR: 提出SV-GS框架，通过稀疏观测（如监控摄像头）重建大范围动态目标运动，结合骨架驱动变形场与时间依赖姿态估计，在稀疏输入下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统动态重建方法依赖密集时空采样，但真实场景（如安防监控）观测通常稀疏且视角分散，导致重建问题高度不适定。

Method: 1. 输入粗略骨架图与初始静态重建；2. 优化骨架驱动变形场（含粗粒度关节姿态估计器与细粒度变形模块）；3. 仅使姿态估计器时间依赖以实现平滑运动插值；4. 支持用扩散生成先验替代静态重建输入。

Result: 1. 合成数据集上PSNR提升最高达34%；2. 真实数据集上使用更少帧数达到与密集单目视频方法相当性能；3. 验证生成式先验可替代静态重建输入。

Conclusion: SV-GS能在稀疏观测下有效重建动态目标运动，通过解耦时间依赖与几何细节实现高效插值，提升真实场景适用性。

Abstract: Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.

</details>


### [51] [TimeColor: Flexible Reference Colorization via Temporal Concatenation](https://arxiv.org/abs/2601.00296)
*Bryan Constantine Sadihin,Yihao Meng,Michael Hua Wang,Matteo Jiahao Chen,Hang Su*

Main category: cs.CV

TL;DR: 提出TimeColor模型，支持基于草图的视频着色，可利用多类型、可变数量的参考图像，通过区域分配和时空注意力机制提升着色质量。


<details>
  <summary>Details</summary>
Motivation: 现有着色模型通常仅依赖单帧参考（如场景首帧），忽略了角色设定图、背景图等其他参考源，限制了着色效果和灵活性。

Method: 1. 将参考图像编码为潜在帧并与视频帧时序拼接；2. 采用显式区域分配机制；3. 使用时空对应掩码注意力增强主体-参考绑定；4. 引入模态分离的RoPE索引。

Result: 在SAKUGA-42M数据集上的实验表明，TimeColor在单参考和多参考协议下均优于基线，提升了色彩保真度、身份一致性和时序稳定性。

Conclusion: TimeColor通过异构参考融合和区域绑定机制，有效解决了传统着色模型的参考局限性和色彩泄漏问题，为视频着色提供了更灵活的解决方案。

Abstract: Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.

</details>


### [52] [VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning](https://arxiv.org/abs/2601.00307)
*Anns Ijaz,Muhammad Azeem Javed*

Main category: cs.CV

TL;DR: 提出VisNet，一种计算高效的行人重识别模型，通过多尺度特征融合、语义聚类和动态权重平均等技术，在保持高精度的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有行人重识别方法虽精度高但计算成本大，难以在计算资源有限的监控和移动应用中实时部署，需平衡精度与效率。

Method: 融合ResNet50多阶段特征（无并行路径）、基于规则伪标注的语义聚类（解剖学身体分区）、动态权重平均平衡分类语义正则化、使用FIDI损失函数改进度量学习。

Result: 在Market-1501数据集上达到87.05% Rank-1和77.65% mAP，参数量32.41M，计算量4.601 GFLOPs，显著优于现有高计算量方法。

Conclusion: VisNet为计算资源受限的实时监控和移动应用提供了实用解决方案，实现了精度与效率的平衡。

Abstract: Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.

</details>


### [53] [HarmoniAD: Harmonizing Local Structures and Global Semantics for Anomaly Detection](https://arxiv.org/abs/2601.00327)
*Naiqi Zhang,Chuancheng Shi,Jingtong Dou,Wenhua Wu,Fei Shen,Jianhua Cao*

Main category: cs.CV

TL;DR: 提出HarmoniAD框架，通过频率引导的双分支结构平衡结构细节与语义信息，在工业异常检测中实现高灵敏度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法存在结构-语义权衡问题：结构导向模型对噪声敏感，语义导向模型易忽略细节，导致微小缺陷检测困难。

Method: 采用CLIP编码器提取特征后转换至频域，解耦为高频/低频双分支：高频分支使用细粒度结构注意力模块增强纹理边缘检测；低频分支使用全局结构上下文模块捕获长程依赖。结合多类别联合训练策略。

Result: 在MVTec-AD、VisA和BTAD数据集上取得最先进性能，同时提升对微小异常的敏感性和模型鲁棒性。

Conclusion: 频率域解耦能有效协同建模结构与语义信息，双分支互补设计解决了传统方法的权衡局限，为工业质检提供可靠解决方案。

Abstract: Anomaly detection is crucial in industrial product quality inspection. Failing to detect tiny defects often leads to serious consequences. Existing methods face a structure-semantics trade-off: structure-oriented models (such as frequency-based filters) are noise-sensitive, while semantics-oriented models (such as CLIP-based encoders) often miss fine details. To address this, we propose HarmoniAD, a frequency-guided dual-branch framework. Features are first extracted by the CLIP image encoder, then transformed into the frequency domain, and finally decoupled into high- and low-frequency paths for complementary modeling of structure and semantics. The high-frequency branch is equipped with a fine-grained structural attention module (FSAM) to enhance textures and edges for detecting small anomalies, while the low-frequency branch uses a global structural context module (GSCM) to capture long-range dependencies and preserve semantic consistency. Together, these branches balance fine detail and global semantics. HarmoniAD further adopts a multi-class joint training strategy, and experiments on MVTec-AD, VisA, and BTAD show state-of-the-art performance with both sensitivity and robustness.

</details>


### [54] [ReMA: A Training-Free Plug-and-Play Mixing Augmentation for Video Behavior Recognition](https://arxiv.org/abs/2601.00311)
*Feng-Qi Cui,Jinyang Huang,Sirui Zhao,Jinglong Guo,Qifan Cai,Xin Yan,Zhi Liu*

Main category: cs.CV

TL;DR: 提出一种名为ReMA的视频数据增强方法，通过表示对齐和动态选择机制，在保持类别条件稳定性的同时扩展表示，提升视频行为识别的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频数据增强方法多为扰动驱动，可能引入不可控变化，放大非判别性因素，削弱类内分布结构并导致表示漂移，在不同时间尺度上增益不一致。

Method: 提出表示感知混合增强（ReMA），包含两个互补机制：1）表示对齐机制（RAM），在分布对齐约束下进行结构化类内混合；2）动态选择机制（DSM），生成运动感知的时空掩码定位扰动，引导其远离判别敏感区域。

Result: 在多个视频行为基准测试上的实验表明，ReMA能够在不增加额外监督或可训练参数的情况下，持续提升不同时空粒度下的泛化能力和鲁棒性。

Conclusion: ReMA通过联合控制混合的方式和位置，有效改善了视频表示的鲁棒性，为视频行为识别提供了一种即插即用的增强策略。

Abstract: Video behavior recognition demands stable and discriminative representations under complex spatiotemporal variations. However, prevailing data augmentation strategies for videos remain largely perturbation-driven, often introducing uncontrolled variations that amplify non-discriminative factors, which finally weaken intra-class distributional structure and representation drift with inconsistent gains across temporal scales. To address these problems, we propose Representation-aware Mixing Augmentation (ReMA), a plug-and-play augmentation strategy that formulates mixing as a controlled replacement process to expand representations while preserving class-conditional stability. ReMA integrates two complementary mechanisms. Firstly, the Representation Alignment Mechanism (RAM) performs structured intra-class mixing under distributional alignment constraints, suppressing irrelevant intra-class drift while enhancing statistical reliability. Then, the Dynamic Selection Mechanism (DSM) generates motion-aware spatiotemporal masks to localize perturbations, guiding them away from discrimination-sensitive regions and promoting temporal coherence. By jointly controlling how and where mixing is applied, ReMA improves representation robustness without additional supervision or trainable parameters. Extensive experiments on diverse video behavior benchmarks demonstrate that ReMA consistently enhances generalization and robustness across different spatiotemporal granularities.

</details>


### [55] [Depth-Synergized Mamba Meets Memory Experts for All-Day Image Reflection Separation](https://arxiv.org/abs/2601.00322)
*Siyan Fang,Long Peng,Yuntao Wang,Ruonan Wei,Yuehuan Wang*

Main category: cs.CV

TL;DR: 提出DMDNet解决夜间图像反射分离难题，通过深度感知扫描、深度协同状态空间模型和记忆专家补偿模块，在自建NightIRS数据集上验证了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有单图像反射分离方法在反射层与透射层对比度相似时容易混淆，夜间场景下问题更严重，缺乏专门数据集。

Method: 1. 深度感知扫描（DAScan）引导Mamba关注显著结构；2. 深度协同状态空间模型（DS-SSM）通过深度调制状态激活；3. 记忆专家补偿模块（MECM）利用跨图像历史知识；4. 构建NightIRS夜间数据集。

Result: DMDNet在白天和夜间场景均优于现有最优方法，有效解决了层间混淆问题。

Conclusion: 结合深度引导与历史记忆的DMDNet能显著提升反射分离性能，特别是夜间场景，所建数据集填补了该领域空白。

Abstract: Image reflection separation aims to disentangle the transmission layer and the reflection layer from a blended image. Existing methods rely on limited information from a single image, tending to confuse the two layers when their contrasts are similar, a challenge more severe at night. To address this issue, we propose the Depth-Memory Decoupling Network (DMDNet). It employs the Depth-Aware Scanning (DAScan) to guide Mamba toward salient structures, promoting information flow along semantic coherence to construct stable states. Working in synergy with DAScan, the Depth-Synergized State-Space Model (DS-SSM) modulates the sensitivity of state activations by depth, suppressing the spread of ambiguous features that interfere with layer disentanglement. Furthermore, we introduce the Memory Expert Compensation Module (MECM), leveraging cross-image historical knowledge to guide experts in providing layer-specific compensation. To address the lack of datasets for nighttime reflection separation, we construct the Nighttime Image Reflection Separation (NightIRS) dataset. Extensive experiments demonstrate that DMDNet outperforms state-of-the-art methods in both daytime and nighttime.

</details>


### [56] [MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation](https://arxiv.org/abs/2601.00504)
*Miaowei Wang,Jakub Zadrożny,Oisin Mac Aodha,Amir Vaxman*

Main category: cs.CV

TL;DR: 提出MotionPhysics框架，通过自然语言提示为3D场景推断物理参数，无需真实轨迹或标注视频，结合多模态大语言模型和视频扩散模型实现逼真动态模拟。


<details>
  <summary>Details</summary>
Motivation: 传统3D物体和材料模拟需要专家知识和耗时参数调整，缺乏从自然语言直接生成物理参数的自动化方法。

Method: 1. 使用多模态大语言模型估计材料参数值并约束在合理范围；2. 提出可学习的运动蒸馏损失，从预训练视频扩散模型中提取运动先验，减少外观和几何归纳偏差。

Result: 在30多个场景（真实世界、人工设计、AI生成）和多种材料（弹性固体、金属、泡沫、沙子、牛顿/非牛顿流体）上验证，生成视觉逼真的动态模拟，超越现有技术。

Conclusion: MotionPhysics能通过自然语言自动确定物理合理参数，实现高质量动态模拟，为物理仿真提供高效解决方案。

Abstract: Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.

</details>


### [57] [Joint Geometry-Appearance Human Reconstruction in a Unified Latent Space via Bridge Diffusion](https://arxiv.org/abs/2601.00328)
*Yingzhi Tang,Qijian Zhang,Junhui Hou*

Main category: cs.CV

TL;DR: 提出JGA-LBD框架，通过联合潜在表示和桥接扩散统一建模3D数字人的几何与外观，从单张RGB图像实现高质量重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将几何估计和外观合成解耦，导致重建不一致且难以统一。需要一种能同时处理几何与外观的集成方法。

Method: 将深度图、SMPL模型等异质条件统一为3D高斯表示，通过共享稀疏变分自编码器压缩到联合潜在空间，使用桥接扩散推断缺失部分，最后解码生成完整3D人体。

Result: 实验表明JGA-LBD在几何保真度和外观质量上优于现有方法，包括野外场景。

Conclusion: 该框架通过联合潜在表示和桥接扩散有效统一了3D人体重建的几何与外观建模，实现了高质量的单图像重建。

Abstract: Achieving consistent and high-fidelity geometry and appearance reconstruction of 3D digital humans from a single RGB image is inherently a challenging task. Existing studies typically resort to decoupled pipelines for geometry estimation and appearance synthesis, often hindering unified reconstruction and causing inconsistencies. This paper introduces \textbf{JGA-LBD}, a novel framework that unifies the modeling of geometry and appearance into a joint latent representation and formulates the generation process as bridge diffusion. Observing that directly integrating heterogeneous input conditions (e.g., depth maps, SMPL models) leads to substantial training difficulties, we unify all conditions into the 3D Gaussian representations, which can be further compressed into a unified latent space through a shared sparse variational autoencoder (VAE). Subsequently, the specialized form of bridge diffusion enables to start with a partial observation of the target latent code and solely focuses on inferring the missing components. Finally, a dedicated decoding module extracts the complete 3D human geometric structure and renders novel views from the inferred latent representation. Experiments demonstrate that JGA-LBD outperforms current state-of-the-art approaches in terms of both geometry fidelity and appearance quality, including challenging in-the-wild scenarios. Our code will be made publicly available at https://github.com/haiantyz/JGA-LBD.

</details>


### [58] [A Comprehensive Dataset for Human vs. AI Generated Image Detection](https://arxiv.org/abs/2601.00553)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Vasu Sharma,Vinija Jain,Aman Chadha,Aishwarya Naresh Reganti,Amitava Das*

Main category: cs.CV

TL;DR: 发布MS COCOAI数据集，用于检测AI生成图像，包含96000个真实与合成图像样本，支持图像真实性分类和生成模型识别任务。


<details>
  <summary>Details</summary>
Motivation: 多模态生成AI系统（如Stable Diffusion、DALL-E）在推动创新的同时，也导致误导性内容、虚假信息和篡改媒体的传播。随着生成图像越来越难以与真实照片区分，检测此类图像已成为紧迫需求。

Method: 基于MS COCO数据集构建MS COCOAI数据集，使用五种生成器（Stable Diffusion 3、Stable Diffusion 2.1、SDXL、DALL-E 3、MidJourney v6）生成合成图像，并提出两项任务：图像真实性分类和生成模型识别。

Result: 创建了包含96000个数据点的数据集，涵盖真实图像和五种不同生成器合成的图像，为AI生成图像检测研究提供了标准化基准。

Conclusion: MS COCOAI数据集为应对AI生成图像带来的挑战提供了重要资源，有助于开发更有效的检测工具，以应对虚假信息和媒体篡改问题。

Abstract: Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.

</details>


### [59] [Noise-Robust Tiny Object Localization with Flows](https://arxiv.org/abs/2601.00617)
*Huixin Sun,Linlin Yang,Ronyu Chen,Kerui Gu,Baochang Zhang,Angela Yao,Xianbin Cao*

Main category: cs.CV

TL;DR: 本文提出TOLF框架，通过归一化流建模预测误差分布，结合不确定性引导优化，提升小目标检测在标注噪声下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有通用目标检测方法在微小物体上性能显著低于正常尺度物体，且微小物体对标注噪声高度敏感，严格的定位目标优化容易导致噪声过拟合。

Method: 提出TOLF框架：1）使用归一化流对预测误差进行灵活的非高斯分布建模；2）设计不确定性感知的梯度调制机制，抑制高不确定性噪声样本的学习。

Result: 在三个数据集上的实验表明，该方法能有效提升小目标检测性能，在AI-TOD数据集上将DINO基线模型的AP提升了1.2%。

Conclusion: TOLF通过流式误差建模和不确定性优化，显著增强了小目标定位对标注噪声的鲁棒性，缩小了微小物体与正常尺度物体的检测性能差距。

Abstract: Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.

</details>


### [60] [Intelligent Traffic Surveillance for Real-Time Vehicle Detection, License Plate Recognition, and Speed Estimation](https://arxiv.org/abs/2601.00344)
*Bruce Mugizi,Sudi Murindanyi,Olivia Nakacwa,Andrew Katumba*

Main category: cs.CV

TL;DR: 该研究为乌干达等发展中国家开发了一套实时智能交通监控系统，利用计算机视觉技术实现车辆检测、车牌识别和速度估计，并通过短信自动开具罚单。


<details>
  <summary>Details</summary>
Motivation: 超速是导致道路死亡事故的主要原因，尤其在乌干达等发展中国家，道路安全基础设施有限，急需有效的交通管理解决方案。

Method: 使用YOLOv8进行车牌检测，CNN和Transformer模型进行字符识别，通过源和目标感兴趣区域进行速度估计，并利用Africa's Talking API建立数据库以实现自动短信罚单发送。

Result: 车牌检测mAP达97.9%；字符识别中CNN的CER为3.85%，Transformer降至1.79%；速度估计误差在10 km/h内；系统成功实现与用户信息关联的自动罚单签发。

Conclusion: 该系统能有效满足资源受限环境下的交通管理需求，通过自动化交通执法有望减少发展中国家的道路事故，具有重要应用潜力。

Abstract: Speeding is a major contributor to road fatalities, particularly in developing countries such as Uganda, where road safety infrastructure is limited. This study proposes a real-time intelligent traffic surveillance system tailored to such regions, using computer vision techniques to address vehicle detection, license plate recognition, and speed estimation. The study collected a rich dataset using a speed gun, a Canon Camera, and a mobile phone to train the models. License plate detection using YOLOv8 achieved a mean average precision (mAP) of 97.9%. For character recognition of the detected license plate, the CNN model got a character error rate (CER) of 3.85%, while the transformer model significantly reduced the CER to 1.79%. Speed estimation used source and target regions of interest, yielding a good performance of 10 km/h margin of error. Additionally, a database was established to correlate user information with vehicle detection data, enabling automated ticket issuance via SMS via Africa's Talking API. This system addresses critical traffic management needs in resource-constrained environments and shows potential to reduce road accidents through automated traffic enforcement in developing countries where such interventions are urgently needed.

</details>


### [61] [OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning](https://arxiv.org/abs/2601.00352)
*Liuxiang Qiu,Hui Da,Yuzhen Niu,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 提出OmniVaT框架解决视觉-触觉学习中的单域泛化问题，通过多模态分数傅里叶适配器和离散树生成模块，有效缓解模态差异并增强对未知域的适应性。


<details>
  <summary>Details</summary>
Motivation: 视觉-触觉学习存在视觉与触觉图像的模态差异，以及由非标准化触觉传感器和不一致数据收集导致的域差距，这些限制了跨域泛化能力。

Method: 1. 多模态分数傅里叶适配器（MFFA）将视觉和触觉嵌入映射到统一的嵌入-频率空间；2. 离散树生成（DTG）模块通过分层树结构获得多样可靠的多模态分数表示。

Result: 大量实验表明，OmniVaT在单域泛化视觉-触觉学习任务上表现出优异的跨域泛化性能。

Conclusion: OmniVaT首次成功解决了单域泛化多模态视觉-触觉学习任务，无需多域训练数据或复杂的跨模态融合策略，有效提升了跨域适应能力。

Abstract: Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.

</details>


### [62] [Mask-Conditioned Voxel Diffusion for Joint Geometry and Color Inpainting](https://arxiv.org/abs/2601.00368)
*Aarya Sumuk*

Main category: cs.CV

TL;DR: 提出轻量级两阶段框架，用于受损3D物体的几何与颜色联合修复，通过分离损伤定位与重建实现文化遗产数字修复。


<details>
  <summary>Details</summary>
Motivation: 受文化遗产数字修复需求驱动，需开发能同时处理几何与颜色信息、且能保持完好区域完整的3D物体修复方法。

Method: 1) 第一阶段：2D卷积网络从体素化物体提取RGB切片预测损伤掩码，聚合为体积掩码；2) 第二阶段：基于扩散的3D U-Net在体素网格上进行掩码条件修复，使用结合占用重建、掩码颜色重建与感知正则化的复合目标函数。

Result: 在合成损伤的纹理化文物数据集上评估，相比对称基线方法，在固定32^3分辨率下产生更完整的几何结构与更一致的颜色重建效果。

Conclusion: 显式掩码条件引导是指导体积扩散模型实现3D几何与颜色联合修复的有效实用方法。

Abstract: We present a lightweight two-stage framework for joint geometry and color inpainting of damaged 3D objects, motivated by the digital restoration of cultural heritage artifacts. The pipeline separates damage localization from reconstruction. In the first stage, a 2D convolutional network predicts damage masks on RGB slices extracted from a voxelized object, and these predictions are aggregated into a volumetric mask. In the second stage, a diffusion-based 3D U-Net performs mask-conditioned inpainting directly on voxel grids, reconstructing geometry and color while preserving observed regions. The model jointly predicts occupancy and color using a composite objective that combines occupancy reconstruction with masked color reconstruction and perceptual regularization. We evaluate the approach on a curated set of textured artifacts with synthetically generated damage using standard geometric and color metrics. Compared to symmetry-based baselines, our method produces more complete geometry and more coherent color reconstructions at a fixed 32^3 resolution. Overall, the results indicate that explicit mask conditioning is a practical way to guide volumetric diffusion models for joint 3D geometry and color inpainting.

</details>


### [63] [BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition](https://arxiv.org/abs/2601.00369)
*Seungyeon Cho,Tae-kyun Kim*

Main category: cs.CV

TL;DR: 提出概率双流框架，通过可靠性建模和多模态集成，统一处理骨架与RGB数据，提升细粒度动作识别性能，尤其在噪声和异构条件下表现稳健。


<details>
  <summary>Details</summary>
Motivation: 现有基于骨架的动作识别方法多关注身体大尺度运动，忽略手部细微动作对细粒度识别的重要性，且缺乏对不确定性和多模态融合的系统处理。

Method: 1. 无标定预处理：直接从原生坐标学习，避免规范空间变换；2. 概率Noisy-OR融合：无需显式置信度监督，稳定双流学习；3. 跨模态集成：耦合四种骨架模态（关节、骨骼、关节运动、骨骼运动）与RGB表示。

Result: 在NTU RGB+D 60/120、PKU-MMD、N-UCLA等多个基准测试及新定义的手部中心基准上，均取得一致性能提升，且在噪声和异构条件下表现出鲁棒性。

Conclusion: 该框架通过统一可靠性建模与多模态集成，有效提升细粒度动作识别能力，为跨模态学习提供了可泛化的概率解决方案。

Abstract: Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.

</details>


### [64] [Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model](https://arxiv.org/abs/2601.00716)
*Hao Guan,Li Zhou*

Main category: cs.CV

TL;DR: 研究针对病理学视觉语言模型在数据分布偏移下的性能退化检测问题，开发了DomainSAT工具箱分析输入数据偏移，并提出基于输出置信度的无标签退化指标，结合两者实现更可靠的性能退化监测。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型部署后，当输入数据分布发生偏移时性能可能下降，这对临床可靠性构成威胁。现有方法难以在无标签数据情况下有效检测大型预训练模型的性能退化。

Method: 1) 开发DomainSAT轻量级工具箱，集成代表性偏移检测算法并提供图形界面；2) 同时分析输入级数据偏移和输出级预测行为；3) 提出基于模型预测置信度的无标签退化指标；4) 在大型病理学肿瘤分类数据集上进行实验验证。

Result: 1) 输入数据偏移检测能有效识别分布变化并提供早期诊断信号，但不总是对应实际性能退化；2) 基于输出置信度的指标与性能退化密切相关，可作为输入偏移检测的有效补充；3) 结合两种方法能更可靠地检测和解释数据偏移下VLMs的性能退化。

Conclusion: 输入数据偏移检测和输出置信度指标的结合为数字病理学基础模型的可靠性监测提供了实用且互补的框架，有助于提升临床部署的模型可靠性。

Abstract: Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.

</details>


### [65] [NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393)
*Yuxue Yang,Lue Fan,Ziqi Shi,Junran Peng,Feng Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: 提出NeoVerse，一个基于单目视频的通用4D世界模型，支持4D重建、新轨迹视频生成及多种下游应用，解决了现有方法在可扩展性上的限制。


<details>
  <summary>Details</summary>
Motivation: 现有4D世界建模方法常受限于昂贵的多视角4D数据或繁琐的训练预处理，导致可扩展性不足。本研究旨在开发一个能够适应多样化单目视频的通用且可扩展的4D模型。

Method: 采用基于单目视频的可扩展流程，包括无姿态前馈4D重建、在线单目退化模式模拟及其他对齐良好的技术，以提升模型的通用性和泛化能力。

Result: NeoVerse在标准重建和生成基准测试中达到了最先进的性能，并展现出对不同领域的良好适应性和泛化性。

Conclusion: NeoVerse通过可扩展的设计，成功实现了对多样化单目视频的高效4D建模，为4D重建和生成任务提供了通用且强大的解决方案。

Abstract: In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io

</details>


### [66] [RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection](https://arxiv.org/abs/2601.00398)
*Tao Wu,Qing Xu,Xiangjian He,Oakleigh Weekes,James Brown,Wenting Duan*

Main category: cs.CV

TL;DR: 本文介绍了首个用于车载摄像头路边垃圾检测的大规模数据集RoLID-11K，包含超过1.1万张标注图像，并评估了多种现代检测器在该任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前路边垃圾监测依赖人工调查和公众报告，空间覆盖有限；现有视觉数据集未考虑车载摄像头中垃圾目标极小、稀疏且背景杂乱的特点。

Method: 构建包含多样化英国驾驶条件的标注数据集；系统评估了从精度导向的Transformer架构到实时YOLO模型的多种现代检测器。

Result: CO-DETR及相关Transformer模型定位精度最佳，但实时模型受限于粗糙的特征层次结构；数据集呈现显著的长尾分布和小目标分布特征。

Conclusion: RoLID-11K为动态驾驶场景中的极端小目标检测设立了挑战性基准，旨在支持开发可扩展、低成本的路边垃圾监测系统。

Abstract: Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.

</details>


### [67] [ABFR-KAN: Kolmogorov-Arnold Networks for Functional Brain Analysis](https://arxiv.org/abs/2601.00416)
*Tyler Ward,Abdullah Imran*

Main category: cs.CV

TL;DR: 提出ABFR-KAN网络，结合Transformer与KANs改进功能连接分析，在自闭症分类任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于图谱的脑功能连接分析存在选择偏差和缺乏个体特异性的问题，需要更可靠、解剖学一致的分析方法。

Method: 提出ABFR-KAN分类网络，整合新型脑功能表示组件与Kolmogorov-Arnold Networks（KANs），通过Transformer架构减少结构偏差并提升功能连接估计可靠性。

Result: 在ABIDE I数据集上的跨站点评估和消融实验表明，该模型在不同骨干网络和KAN配置下均优于当前最先进的自闭症分类基线方法。

Conclusion: ABFR-KAN能有效提升脑功能连接分析的解剖学一致性和分类性能，为脑疾病诊断提供了更可靠的工具。

Abstract: Functional connectivity (FC) analysis, a valuable tool for computer-aided brain disorder diagnosis, traditionally relies on atlas-based parcellation. However, issues relating to selection bias and a lack of regard for subject specificity can arise as a result of such parcellations. Addressing this, we propose ABFR-KAN, a transformer-based classification network that incorporates novel advanced brain function representation components with the power of Kolmogorov-Arnold Networks (KANs) to mitigate structural bias, improve anatomical conformity, and enhance the reliability of FC estimation. Extensive experiments on the ABIDE I dataset, including cross-site evaluation and ablation studies across varying model backbones and KAN configurations, demonstrate that ABFR-KAN consistently outperforms state-of-the-art baselines for autism spectrum distorder (ASD) classification. Our code is available at https://github.com/tbwa233/ABFR-KAN.

</details>


### [68] [Robust Assembly Progress Estimation via Deep Metric Learning](https://arxiv.org/abs/2601.00422)
*Kazuma Miura,Sarthak Pathak,Kazunori Umeda*

Main category: cs.CV

TL;DR: 提出基于四元组损失的异常检测网络，用于解决智能工厂中产品装配进度监控的视觉变化细微和遮挡问题，在小型数据集上提升了估计精度。


<details>
  <summary>Details</summary>
Motivation: 智能工厂中多日手动装配任务的进度自动监控存在挑战，现有方法在连续任务间视觉变化细微时易误分类，需提升在遮挡或微小变化下的鲁棒性。

Method: 使用基于四元组损失的学习方法处理异常图像，设计定制数据加载器策略性选择训练样本，构建Anomaly Quadruplet-Net模型。

Result: 在台式机组装图像数据集上，该方法比现有方法估计精度提升1.3%，相邻任务间误分类率降低1.9%。

Conclusion: 所提方法能有效应对装配过程中的视觉变化细微和遮挡问题，为小型数据集下的装配进度监控提供了更鲁棒的解决方案。

Abstract: In recent years, the advancement of AI technologies has accelerated the development of smart factories. In particular, the automatic monitoring of product assembly progress is crucial for improving operational efficiency, minimizing the cost of discarded parts, and maximizing factory productivity. However, in cases where assembly tasks are performed manually over multiple days, implementing smart factory systems remains a challenge. Previous work has proposed Anomaly Triplet-Net, which estimates assembly progress by applying deep metric learning to the visual features of products. Nevertheless, when visual changes between consecutive tasks are subtle, misclassification often occurs. To address this issue, this paper proposes a robust system for estimating assembly progress, even in cases of occlusion or minimal visual change, using a small-scale dataset. Our method leverages a Quadruplet Loss-based learning approach for anomaly images and introduces a custom data loader that strategically selects training samples to enhance estimation accuracy. We evaluated our approach using a image datasets: captured during desktop PC assembly. The proposed Anomaly Quadruplet-Net outperformed existing methods on the dataset. Specifically, it improved the estimation accuracy by 1.3% and reduced misclassification between adjacent tasks by 1.9% in the desktop PC dataset and demonstrating the effectiveness of the proposed method.

</details>


### [69] [CPPO: Contrastive Perception for Vision Language Policy Optimization](https://arxiv.org/abs/2601.00501)
*Ahmad Rezaei,Mohsen Gholami,Saeed Ranjbar Alvar,Kevin Cannons,Mohammad Asiful Hossain,Zhou Weimin,Shunbo Zhou,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: CPPO是一种用于微调视觉语言模型的对比感知策略优化方法，通过检测扰动图像下模型输出的熵变化来识别感知标记，并引入对比感知损失来增强感知一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将强化学习扩展到多模态推理时，难以有效分离感知标记和推理标记，通常需要额外模型、真实数据或强制分离，导致效率低下且可扩展性差。

Method: CPPO通过扰动输入图像检测模型输出的熵变化来识别感知标记，并在强化学习目标函数中引入对比感知损失，以在信息保留扰动下增强一致性，在信息移除扰动下增强敏感性。

Result: 实验表明，CPPO在无需额外模型的情况下，超越了以往的感知奖励方法，同时提高了训练效率和可扩展性。

Conclusion: CPPO通过对比感知损失有效解决了多模态强化学习中感知与推理分离的难题，为视觉语言模型的微调提供了一种高效且可扩展的方法。

Abstract: We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.

</details>


### [70] [All-in-One Video Restoration under Smoothly Evolving Unknown Weather Degradations](https://arxiv.org/abs/2601.00533)
*Wenrui Li,Hongtao Chen,Yao Xiao,Wangmeng Zuo,Jiantao Zhou,Yonghong Tian,Xiaopeng Fan*

Main category: cs.CV

TL;DR: 本文提出ORCANet网络，用于处理视频中平滑演化的未知退化问题，通过粗粒度强度估计去雾模块和流提示生成模块实现高质量、时序一致的视频恢复。


<details>
  <summary>Details</summary>
Motivation: 现有全场景图像恢复方法主要关注逐帧退化变化，忽略了真实世界中退化过程具有时序连续性的特点，退化类型和强度会随时间平滑演变，且多种退化可能共存或渐变。

Method: 提出平滑演化未知退化场景，设计合成时序相干退化视频的流程；构建ORCANet网络，包含粗粒度强度估计去雾模块（利用物理先验估计雾浓度）和流提示生成模块（生成静态和动态提示）；采用标签感知监督机制提升静态提示的表征区分能力。

Result: 大量实验表明，ORCANet在恢复质量、时序一致性和鲁棒性方面优于图像和视频基线方法。

Conclusion: ORCANet能有效处理视频中平滑演化的复合退化问题，为全场景视频恢复提供了新解决方案。

Abstract: All-in-one image restoration aims to recover clean images from diverse unknown degradations using a single model. But extending this task to videos faces unique challenges. Existing approaches primarily focus on frame-wise degradation variation, overlooking the temporal continuity that naturally exists in real-world degradation processes. In practice, degradation types and intensities evolve smoothly over time, and multiple degradations may coexist or transition gradually. In this paper, we introduce the Smoothly Evolving Unknown Degradations (SEUD) scenario, where both the active degradation set and degradation intensity change continuously over time. To support this scenario, we design a flexible synthesis pipeline that generates temporally coherent videos with single, compound, and evolving degradations. To address the challenges in the SEUD scenario, we propose an all-in-One Recurrent Conditional and Adaptive prompting Network (ORCANet). First, a Coarse Intensity Estimation Dehazing (CIED) module estimates haze intensity using physical priors and provides coarse dehazed features as initialization. Second, a Flow Prompt Generation (FPG) module extracts degradation features. FPG generates both static prompts that capture segment-level degradation types and dynamic prompts that adapt to frame-level intensity variations. Furthermore, a label-aware supervision mechanism improves the discriminability of static prompt representations under different degradations. Extensive experiments show that ORCANet achieves superior restoration quality, temporal consistency, and robustness over image and video-based baselines. Code is available at https://github.com/Friskknight/ORCANet-SEUD.

</details>


### [71] [SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array](https://arxiv.org/abs/2601.00551)
*Shuang Li,Yibing Wang,Jian Gao,Chulhong Kim,Seongwook Choi,Yu Zhang,Qian Chen,Yao Yao,Changhui Li*

Main category: cs.CV

TL;DR: 本文提出SlingBAG Pro算法，用于不规则几何阵列的三维光声成像重建，在保持高质量的同时显著提升计算速度。


<details>
  <summary>Details</summary>
Motivation: 传统迭代重建算法在处理不规则阵列时面临计算复杂度高、内存需求大、重建时间长的问题，限制了三维光声成像的临床应用。

Method: 基于SlingBAG方法的点云迭代概念，扩展至任意阵列几何；采用分层优化策略，结合零梯度滤波和逐步增加的时间采样率，快速去除冗余空间点云。

Result: 相比原始SlingBAG算法，SlingBAG Pro在不规则阵列下实现最高2.2倍的速度提升；通过仿真和活体小鼠实验验证了有效性。

Conclusion: SlingBAG Pro算法能够在不规则阵列配置下实现高效高质量的三维光声成像重建，为临床应用提供了可行解决方案。

Abstract: High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.

</details>


### [72] [DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction](https://arxiv.org/abs/2601.00542)
*Jiacheng Sui,Yujie Zhou,Li Niu*

Main category: cs.CV

TL;DR: 提出DynaDrag方法，采用预测-移动框架实现拖拽式图像编辑，通过迭代运动预测与监督动态调整处理点，在面部和人体数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有拖拽式图像编辑方法存在跟踪丢失、模糊跟踪、源图与目标图差异过大、中间点不合理导致编辑性差等问题，需要更鲁棒的解决方案。

Method: 提出预测-移动框架，迭代执行运动预测（预测处理点移动位置）和运动监督（执行拖拽），并动态调整有效处理点以提升性能。

Result: 在面部和人体数据集上的实验表明，该方法在像素级图像编辑任务中优于先前工作。

Conclusion: DynaDrag通过创新的预测-移动框架和动态点调整机制，有效解决了拖拽编辑中的关键挑战，实现了更精准可控的图像操作。

Abstract: To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.

</details>


### [73] [Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios](https://arxiv.org/abs/2601.00537)
*Guangqian Guo,Pengfei Chen,Yong Guo,Huafeng Chen,Boqiang Zhang,Shan Gao*

Main category: cs.CV

TL;DR: 提出VNS-SAM模型，通过Mask-Edge Token交互解码器和非显著特征挖掘模块增强SAM在视觉非显著场景下的分割能力，同时保持零样本泛化性，并构建了VNS-SEG数据集进行验证。


<details>
  <summary>Details</summary>
Motivation: SAM在视觉非显著场景（前景与背景对比度低）中表现不佳，现有方法难以捕捉准确轮廓，需要提升SAM在此类场景下的感知能力。

Method: 设计Mask-Edge Token交互解码器和非显著特征挖掘模块，利用SAM的低层特征；构建包含3.5万张图像的VNS-SEG统一数据集；模型仅需少量参数增加和4小时训练。

Result: VNS-SAM在多种视觉非显著分割任务中表现优异，尤其在零样本设置下展现出更强的分割性能和泛化能力。

Conclusion: VNS-SAM有效提升了SAM在视觉非显著场景下的分割精度，同时保持了原始零样本泛化性，具有实际应用潜力；公开了代码和数据集。

Abstract: Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.

</details>


### [74] [AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models](https://arxiv.org/abs/2601.00561)
*Jintao Lin,Bowen Dong,Weikang Shi,Chenyang Lei,Suiyun Zhang,Rui Liu,Xihui Liu*

Main category: cs.CV

TL;DR: 提出了AEGIS基准和DCE评估协议，用于全面评估统一多模态模型的世界知识应用能力，发现现有模型存在严重知识缺陷且复杂推理性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅提供孤立的单任务评估，诊断能力有限，无法充分评估统一多模态模型在不同任务中应用世界知识的能力。

Method: 1) 构建AEGIS多任务基准，包含1050个涵盖21个主题和6种推理类型的人工标注问题；2) 提出确定性清单评估协议，用原子化的“是/否”判断替代模糊的提示评分。

Result: 大多数统一多模态模型表现出严重的世界知识缺陷，且随着推理复杂度增加性能显著下降；简单的插件推理模块可部分缓解这些缺陷。

Conclusion: 基于世界知识的推理是统一多模态模型发展的关键前沿，需要更全面的评估方法和改进的推理能力。

Abstract: The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\emph{i.e.}, \textbf{A}ssessing \textbf{E}diting, \textbf{G}eneration, \textbf{I}nterpretation-Understanding for \textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.

</details>


### [75] [FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535)
*Ruiqiang Zhang,Hengyi Wang,Chang Liu,Guanjie Wang,Zehua Ma,Weiming Zhang*

Main category: cs.CV

TL;DR: 提出FreeText框架，无需训练即可提升扩散模型文本渲染能力，通过空间定位和字形注入解决多行布局、密集排版和中文等长尾脚本的文本渲染问题。


<details>
  <summary>Details</summary>
Motivation: 现有大规模文生图扩散模型在开放域合成表现出色，但在精确文本渲染方面存在不足，特别是多行布局、密集排版和中文等长尾脚本。先前方案通常需要昂贵重训练或刚性外部布局约束，可能损害美观性和灵活性。

Method: 1. 空间定位：利用扩散Transformer模型的内生图像-文本注意力机制，通过sink-like token作为空间锚点，结合拓扑感知细化生成高置信度掩码；2. 字形注入：提出频谱调制字形注入(SGMI)，通过频域带通调制注入噪声对齐的字形先验，增强字形结构并抑制语义泄漏。

Result: 在Qwen-Image、FLUX.1-dev和SD3变体上的大量实验表明，在长文本基准、CVTG和自建CLT-Bench上均取得文本可读性的持续提升，同时基本保持语义对齐和美学质量，推理开销适度。

Conclusion: FreeText是一个无需训练、即插即用的框架，通过利用扩散Transformer模型的内在机制，有效解决了文本渲染问题，在提升文本可读性的同时保持了生成图像的美学质量。

Abstract: Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \emph{Diffusion Transformer (DiT)} models. \textbf{FreeText} decomposes the problem into \emph{where to write} and \emph{what to write}. For \emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.

</details>


### [76] [A Cascaded Information Interaction Network for Precise Image Segmentation](https://arxiv.org/abs/2601.00562)
*Hewen Xiao,Jie Mei,Guangfu Ma,Weiren Wu*

Main category: cs.CV

TL;DR: 提出一种集成全局信息引导模块的级联卷积神经网络，用于提升复杂场景下的图像分割精度。


<details>
  <summary>Details</summary>
Motivation: 视觉感知对自主行为至关重要，但复杂场景下的鲁棒分割仍具挑战；传统方法在视觉杂乱或模糊环境中表现不佳。

Method: 设计全局信息引导模块，通过多层级联卷积神经网络融合低层纹理细节与高层语义特征，克服单尺度特征提取的局限性。

Result: 在基准图像分割数据集上验证，该框架达到更高精度，优于现有先进方法。

Conclusion: 该方法有效提升了分割准确性，在视觉复杂场景中表现优越，具有实际机器人应用的潜力。

Abstract: Visual perception plays a pivotal role in enabling autonomous behavior, offering a cost-effective and efficient alternative to complex multi-sensor systems. However, robust segmentation remains a challenge in complex scenarios. To address this, this paper proposes a cascaded convolutional neural network integrated with a novel Global Information Guidance Module. This module is designed to effectively fuse low-level texture details with high-level semantic features across multiple layers, thereby overcoming the inherent limitations of single-scale feature extraction. This architectural innovation significantly enhances segmentation accuracy, particularly in visually cluttered or blurred environments where traditional methods often fail. Experimental evaluations on benchmark image segmentation datasets demonstrate that the proposed framework achieves superior precision, outperforming existing state-of-the-art methods. The results highlight the effectiveness of the approach and its promising potential for deployment in practical robotic applications.

</details>


### [77] [GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval](https://arxiv.org/abs/2601.00584)
*Mingyu Jeon,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: 提出无需训练的GranAlign框架，通过粒度感知对齐解决零样本视频时刻检索中的语义粒度不匹配问题，在三个基准数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本视频时刻检索方法虽然利用预训练知识实现跨模态对齐，但未能平衡文本查询与视频内容之间的语义粒度差异，导致检索不准确。

Method: 提出GranAlign框架，包含两种互补技术：1) 基于粒度的查询重写，生成多粒度语义查询；2) 查询感知的标题生成，将查询意图嵌入视频内容描述。通过多级查询与查询无关/感知描述的配对解决语义不匹配。

Result: 在QVHighlights、Charades-STA、ActivityNet-Captions三个基准测试中均达到最优性能，其中在QVHighlights数据集上mAP@avg指标显著提升3.23%。

Conclusion: 通过粒度感知对齐机制有效解决了零样本视频时刻检索中的语义粒度不匹配问题，证明了无需训练框架在跨模态对齐任务中的有效性。

Abstract: Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.

</details>


### [78] [SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation](https://arxiv.org/abs/2601.00590)
*Yiling Wang,Zeyu Zhang,Yiran Wang,Hao Tang*

Main category: cs.CV

TL;DR: 提出SafeMo框架，通过最小化运动遗忘策略在连续空间实现安全的文本到运动生成，解决了现有离散方法的安全性和质量问题，并构建了首个安全文本到运动数据集。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散VQ-VAE码本替换的文本到运动生成方法存在两大缺陷：替换码本条目会影响良性任务性能；离散化导致量化损失和运动不平滑。此外，现有数据集包含不安全内容，不适合安全驱动的机器学习。

Method: 提出SafeMo框架，集成两阶段最小运动遗忘策略，在连续空间进行安全运动生成，避免码本损失。同时构建SafeMoVAE-29K数据集，包含重写的安全文本提示和连续优化运动。

Result: 实验表明SafeMo在HumanML3D和Motion-X数据集上，不安全提示的遗忘性能分别达到之前最优方法的2.5倍和14.4倍，同时在安全提示上保持相当或更好的良性性能。

Conclusion: SafeMo在连续空间实现了安全的人类运动生成，在安全性和实用性之间取得了良好平衡，为可信赖的运动生成提供了有效解决方案。

Abstract: Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.

</details>


### [79] [HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis](https://arxiv.org/abs/2601.00626)
*Shuren Gabriel Yu,Sikang Ren,Yongji Tian*

Main category: cs.CV

TL;DR: 提出HyperPriv-EPN框架，利用术后文本特权信息提升术前室管膜瘤预后预测，无需推理时文本输入。


<details>
  <summary>Details</summary>
Motivation: 术前MRI缺乏语义信息导致室管膜瘤预后预测困难，现有方法无法在推理时利用术后文本特权信息。

Method: 基于超图的LUPI框架，采用割裂图策略：共享编码器处理含术后信息的教师图和仅术前数据的学生图，通过双流蒸馏让学生图从视觉特征中重构语义社区结构。

Result: 在311例多中心患者队列中实现最先进的诊断准确率和生存分层性能。

Conclusion: 该框架将专家知识迁移至术前场景，利用历史术后数据指导新患者诊断，突破推理时对文本数据的依赖。

Abstract: Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.

</details>


### [80] [Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception](https://arxiv.org/abs/2601.00598)
*Xianhui Liu,Siqi Jiang,Yi Xie,Yuqing Lin,Siao Liu*

Main category: cs.CV

TL;DR: 提出模态主导指数（MDI）量化RGB-红外融合中的优化偏差，并开发模态主导感知跨模态学习框架（MDACL），通过分层跨模态引导和对抗均衡正则化实现更平衡的多模态融合。


<details>
  <summary>Details</summary>
Motivation: RGB-红外多模态感知在复杂环境中至关重要，但现有方法因模态特性不对称（信息密度和特征质量差异）导致优化偏差，使训练过度依赖主导模态，阻碍有效融合。

Method: 1. 提出模态主导指数（MDI），通过联合建模特征熵和梯度贡献量化模态主导程度；2. 基于MDI设计MDACL框架，包含分层跨模态引导（HCG）增强特征对齐，以及对抗均衡正则化（AER）平衡融合优化动态。

Result: 在三个RGB-红外基准测试上的实验表明，MDACL能有效缓解优化偏差，达到最先进的性能水平。

Conclusion: 模态不对称导致的优化偏差是多模态融合的关键问题，MDI为量化该问题提供了工具，MDACL框架通过主动调节优化过程实现了更均衡高效的跨模态学习。

Abstract: RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.

</details>


### [81] [RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation](https://arxiv.org/abs/2601.00625)
*Junxiao Xue,Pavel Smirnov,Ziao Li,Yunyun Shi,Shi Chen,Xinyi Yin,Xiaohan Yue,Lei Wang,Yiduo Wang,Feng Lin,Yijia Chen,Xiao Ma,Xiaoran Yan,Qing Zhang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: 提出名为RePose的实时3D人体姿态估计与运动分析方法，用于康复训练，通过多摄像头RGB视频实现实时监测、评估与反馈。


<details>
  <summary>Details</summary>
Motivation: 康复训练中需实时监测患者动作并提供即时指导，以帮助患者正确执行康复动作，恢复肌肉力量与运动功能。

Method: 1. 构建端到端实时人体姿态估计与运动分析统一流程；2. 提出适用于多人干扰医疗场景的快速跟踪方法（单帧跟踪<1ms）；3. 改进SmoothNet以实现实时姿态估计，减少误差并平滑运动状态；4. 基于Unity平台实现实时监测与肌肉应力可视化。

Result: 方法能够实时跟踪与评估康复动作，在多人干扰场景下保持高效跟踪，提升姿态估计精度与运动平滑度，并通过可视化辅助康复训练。

Conclusion: RePose系统可有效支持康复训练的实时监测与指导，具有快速跟踪、误差降低与可视化反馈的优势，适用于临床康复应用。

Abstract: We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.

</details>


### [82] [Reconstructing Building Height from Spaceborne TomoSAR Point Clouds Using a Dual-Topology Network](https://arxiv.org/abs/2601.00658)
*Zhaiyu Chen,Yuanyuan Wang,Yilei Shi,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出一种基于学习的框架，将原始星载SAR层析点云转换为高分辨率建筑高度图，通过双拓扑网络处理点云噪声和数据缺失问题。


<details>
  <summary>Details</summary>
Motivation: 星载SAR层析成像虽能提供天气无关的建筑立面观测，但其点云存在噪声、各向异性分布和数据空洞等问题，影响高度重建精度，需要一种有效方法解决这些挑战。

Method: 设计双拓扑网络，交替处理点分支（建模不规则散射特征）和网格分支（增强空间一致性），联合处理点云与网格表示，实现去噪和缺失区域修复。

Result: 在慕尼黑和柏林数据上的实验验证了方法的有效性，并可扩展结合光学卫星影像进一步提升重建质量。

Conclusion: 该框架首次实现了直接从SAR层析点云进行大规模城市高度制图的概念验证，为城市应用提供了可靠解决方案。

Abstract: Reliable building height estimation is essential for various urban applications. Spaceborne SAR tomography (TomoSAR) provides weather-independent, side-looking observations that capture facade-level structure, offering a promising alternative to conventional optical methods. However, TomoSAR point clouds often suffer from noise, anisotropic point distributions, and data voids on incoherent surfaces, all of which hinder accurate height reconstruction. To address these challenges, we introduce a learning-based framework for converting raw TomoSAR points into high-resolution building height maps. Our dual-topology network alternates between a point branch that models irregular scatterer features and a grid branch that enforces spatial consistency. By jointly processing these representations, the network denoises the input points and inpaints missing regions to produce continuous height estimates. To our knowledge, this is the first proof of concept for large-scale urban height mapping directly from TomoSAR point clouds. Extensive experiments on data from Munich and Berlin validate the effectiveness of our approach. Moreover, we demonstrate that our framework can be extended to incorporate optical satellite imagery, further enhancing reconstruction quality. The source code is available at https://github.com/zhu-xlab/tomosar2height.

</details>


### [83] [CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models](https://arxiv.org/abs/2601.00659)
*Neeraj Anand,Samyak Jha,Udbhav Bamba,Rahul Rahaman*

Main category: cs.CV

TL;DR: 提出CRoPS框架，通过选择性移除关键文本标记构建幻觉模型，结合广义对比解码，无需训练即可有效缓解大型视觉语言模型中的幻觉问题，显著提升多个基准性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在生成内容时存在幻觉问题，影响实际可靠性；现有无训练方法依赖对幻觉来源的狭隘假设，且在生成后期效果下降，视觉信息仍会传播到文本中，需要更全面的解决方案。

Method: 提出CRoPS框架：构建幻觉模型时选择性移除关键文本标记以捕捉幻觉效应；引入广义对比解码，整合多个幻觉模型来代表多样化的幻觉来源。

Result: CRoPS将CHAIR分数提升20%，在六个基准测试和三种大型视觉语言模型家族中均取得一致增益，优于当前最先进的无训练方法。

Conclusion: 通过选择性文本标记移除和广义对比解码，CRoPS能有效缓解幻觉问题，提高模型可靠性，且无需额外训练，具有广泛适用性。

Abstract: Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

</details>


### [84] [Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678)
*Melonie de Almeida,Daniela Ivanova,Tong Shi,John H. Williamson,Paul Henderson*

Main category: cs.CV

TL;DR: 提出了一种基于单张图像生成可控相机路径视频的新框架，通过构建3D高斯场景表示并采样物体运动，实现高效、高质量的相机引导视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有单图像条件视频生成方法在用户控制（如相机路径修改）方面存在不足，难以准确建模相机运动、保持时间一致性和几何完整性，限制了实际应用。

Method: 采用单次前向传播构建3D高斯场景表示，并采样合理的物体运动，无需迭代去噪即可生成与给定相机轨迹对齐的视频。

Result: 在KITTI、Waymo、RealEstate10K和DL3DV-10K数据集上的实验表明，该方法在视频质量和推理效率方面达到最先进水平。

Conclusion: 所提框架能够快速生成相机引导的高质量视频，在保持时间一致性和几何完整性的同时，实现了对相机运动的精确控制。

Abstract: Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.

</details>


### [85] [Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach](https://arxiv.org/abs/2601.00645)
*Shrikant Kapse,Priyankkumar Dhrangdhariya,Priya Kedia,Manasi Patwardhan,Shankar Kausley,Soumyadipta Maiti,Beena Rai,Shirish Karande*

Main category: cs.CV

TL;DR: 该研究利用基于图像的深度学习技术，通过预训练模型实现了马铃薯储存期间的发芽检测、重量损失估计和保质期预测，其中DenseNet在发芽检测中达到98.03%的准确率，为自动化分拣和库存管理提供了可行方案。


<details>
  <summary>Details</summary>
Motivation: 解决马铃薯储存过程中质量监测的关键挑战，如发芽检测、重量损失估计和保质期预测，以支持非侵入性、可扩展的自动化分拣和库存系统，减少食物浪费并提高供应链效率。

Method: 在受控温湿度条件下收集200天的图像和重量数据，利用ResNet、VGG、DenseNet和Vision Transformer等预训练架构，设计了两个专用模型：高精度二分类发芽检测器和用于重量损失估计及保质期预测的多类预测器。

Result: DenseNet在发芽检测中准确率达98.03%；保质期预测在粗分类（2-5类）下准确率超过89.83%，但在细分类（6-8类）下因视觉差异细微和数据有限而性能下降。

Conclusion: 基于图像的深度学习为马铃薯质量评估提供了经济高效的非破坏性方法，可集成到自动化系统中以改善库存管理、定价策略并减少浪费；未来需开发适用于多样品种和储存条件的通用模型以增强适应性和可扩展性。

Abstract: Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.

</details>


### [86] [Efficient Deep Demosaicing with Spatially Downsampled Isotropic Networks](https://arxiv.org/abs/2601.00703)
*Cory Fan,Wenchao Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种使用空间下采样的各向同性网络用于图像去马赛克，相比传统避免下采样的设计，该方法在效率和性能上均有提升。


<details>
  <summary>Details</summary>
Motivation: 移动平台上的深度学习图像去马赛克需要轻量高效的网络，传统各向同性网络因完全避免空间下采样导致计算成本过高，限制了移动端应用。

Method: 采用基于DeepMAD的数学架构设计技术，构建了包含空间下采样的全卷积网络（JD3Net），并与无下采样版本进行对比验证。

Result: 实验表明空间下采样显著提升了各向同性网络的效率和性能，JD3Net在多种图像去马赛克及联合去马赛克-去噪任务中表现优异。

Conclusion: 合理引入空间下采样可突破传统各向同性网络的设计局限，为移动端高效图像处理提供了新思路。

Abstract: In digital imaging, image demosaicing is a crucial first step which recovers the RGB information from a color filter array (CFA). Oftentimes, deep learning is utilized to perform image demosaicing. Given that most modern digital imaging applications occur on mobile platforms, applying deep learning to demosaicing requires lightweight and efficient networks. Isotropic networks, also known as residual-in-residual networks, have been often employed for image demosaicing and joint-demosaicing-and-denoising (JDD). Most demosaicing isotropic networks avoid spatial downsampling entirely, and thus are often prohibitively expensive computationally for mobile applications. Contrary to previous isotropic network designs, this paper claims that spatial downsampling to a signficant degree can improve the efficiency and performance of isotropic networks. To validate this claim, we design simple fully convolutional networks with and without downsampling using a mathematical architecture design technique adapted from DeepMAD, and find that downsampling improves empirical performance. Additionally, empirical testing of the downsampled variant, JD3Net, of our fully convolutional networks reveals strong empirical performance on a variety of image demosaicing and JDD tasks.

</details>


### [87] [Multi-Level Feature Fusion for Continual Learning in Visual Quality Inspection](https://arxiv.org/abs/2601.00725)
*Johannes C. Bauer,Paul Geng,Stephan Trattnig,Petr Dokládal,Rüdiger Daub*

Main category: cs.CV

TL;DR: 提出多级特征融合方法，用于制造质量检测中的持续学习，减少可训练参数并缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在制造质量检测中应用受限，尤其在再制造等场景中，产品和缺陷模式频繁变化，需要模型能高效适应新条件。

Method: 基于预训练网络的多级特征融合方法，利用不同深度的特征表示，减少可训练参数并保持性能。

Result: 方法在不同质量检测任务中匹配端到端训练性能，显著减少参数，降低灾难性遗忘，提升对新产品或缺陷的泛化鲁棒性。

Conclusion: 多级特征融合方法为动态制造环境中的持续学习提供了高效解决方案，平衡了计算效率与模型适应性。

Abstract: Deep neural networks show great potential for automating various visual quality inspection tasks in manufacturing. However, their applicability is limited in more volatile scenarios, such as remanufacturing, where the inspected products and defect patterns often change. In such settings, deployed models require frequent adaptation to novel conditions, effectively posing a continual learning problem. To enable quick adaptation, the necessary training processes must be computationally efficient while still avoiding effects like catastrophic forgetting. This work presents a multi-level feature fusion (MLFF) approach that aims to improve both aspects simultaneously by utilizing representations from different depths of a pretrained network. We show that our approach is able to match the performance of end-to-end training for different quality inspection problems while using significantly less trainable parameters. Furthermore, it reduces catastrophic forgetting and improves generalization robustness to new product types or defects.

</details>


### [88] [Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection](https://arxiv.org/abs/2601.00789)
*Shukesh Reddy,Srijan Das,Abhijit Das*

Main category: cs.CV

TL;DR: 本文提出将自监督学习作为辅助任务来优化深度伪造检测的主要任务，通过融合自监督任务的特征表示，在跨数据集评估中实现了更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测方法在跨数据集泛化能力上存在不足，需要探索能够提升模型泛化性能的新方法。

Method: 研究了自监督学习作为辅助任务与主要任务的不同训练方案组合，通过融合自监督任务的特征表示来增强主要任务的表示能力。

Result: 在DF40、FaceForensics++、Celeb-DF等多个数据集上的实验表明，该方法在跨数据集评估中比当前最先进的检测器具有更好的泛化性能。

Conclusion: 融合自监督辅助任务的特征表示能够有效提升深度伪造检测任务的性能，特别是在跨数据集泛化方面表现出优势。

Abstract: In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.

</details>


### [89] [Unified Primitive Proxies for Structured Shape Completion](https://arxiv.org/abs/2601.00759)
*Zhaiyu Chen,Yuqing Wang,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出UniCo方法，通过专用路径解码基元，在单次前向传播中预测完整几何、语义和内点成员关系的基元集合，显著提升结构化形状补全性能。


<details>
  <summary>Details</summary>
Motivation: 现有结构化形状补全方法通常采用级联流程处理基元与点云，作者重新思考二者交互方式，发现通过专用注意力路径解码基元更有效，旨在实现更高效统一的三维理解。

Method: 1. 设计UniCo框架，使用可学习的基元代理作为查询，通过注意力机制从共享形状特征生成可直接组装的输出；2. 提出耦合基元与点云的在线目标更新训练策略，确保优化一致性。

Result: 在合成与真实场景基准测试中，使用四种独立组装求解器，UniCo均优于基线方法：Chamfer距离降低达50%，法向一致性提升达7%。

Conclusion: 该方法为从不完整数据实现结构化三维理解提供了有效方案，通过统一表示和协同优化机制显著提升了形状补全的几何与语义质量。

Abstract: Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction. Instead of following the prevailing cascade, we rethink how primitives and points should interact, and find it more effective to decode primitives in a dedicated pathway that attends to shared shape features. Following this principle, we present UniCo, which in a single feed-forward pass predicts a set of primitives with complete geometry, semantics, and inlier membership. To drive this unified representation, we introduce primitive proxies, learnable queries that are contextualized to produce assembly-ready outputs. To ensure consistent optimization, our training strategy couples primitives and points with online target updates. Across synthetic and real-world benchmarks with four independent assembly solvers, UniCo consistently outperforms recent baselines, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%. These results establish an attractive recipe for structured 3D understanding from incomplete data. Project page: https://unico-completion.github.io.

</details>


### [90] [Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI](https://arxiv.org/abs/2601.00794)
*Wenhui Chu,Nikolaos V. Tsekos*

Main category: cs.CV

TL;DR: 提出LNU-Net和IBU-Net两种深度学习架构，用于短轴电影MRI图像的左心室分割，通过层归一化和实例-批量归一化改进U-Net，在分割精度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 左心室分割对心脏影像的临床量化和诊断至关重要，现有方法在精度上存在局限，需要更有效的深度学习架构来提升分割性能。

Method: 基于U-Net架构，LNU-Net在卷积块中使用层归一化，IBU-Net在首个卷积块结合实例和批量归一化；采用下采样路径提取特征和上采样路径精确定位，并应用仿射变换和弹性变形进行图像数据处理。

Result: 在包含45名患者805张MRI图像的数据集上评估，LNU-Net和IBU-Net在骰子系数和平均垂直距离指标上优于原始U-Net及其他先进方法。

Conclusion: 提出的LNU-Net和IBU-Net架构能有效提升左心室分割精度，为心脏影像诊断提供了更可靠的工具，归一化技术的结合对医学图像分割有显著改进作用。

Abstract: Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.

</details>


### [91] [AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction](https://arxiv.org/abs/2601.00796)
*Jiewen Chan,Zhenjun Zhao,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 提出AdaGaR框架，通过自适应Gabor表示和三次Hermite样条解决动态3D场景重建中的频率适应性和时间连续性问题，在多项任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有单高斯基元方法受限于低通滤波特性，标准Gabor函数存在能量不稳定问题，且缺乏时间连续性约束导致运动插值出现伪影。

Method: 1. 自适应Gabor表示：通过可学习频率权重和自适应能量补偿扩展高斯函数；2. 时间连续性：采用带时间曲率正则化的三次Hermite样条；3. 自适应初始化：结合深度估计、点跟踪和前景掩码建立稳定点云分布。

Result: 在Tap-Vid DAVIS数据集上取得PSNR 35.49、SSIM 0.9433、LPIPS 0.0723的SOTA性能，在帧插值、深度一致性、视频编辑和立体视图合成等任务中表现出强泛化能力。

Conclusion: AdaGaR通过统一框架同时解决了动态场景建模中的频率适应性和时间连续性问题，为单目视频动态3D重建提供了有效解决方案。

Abstract: Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/

</details>


### [92] [Grading Handwritten Engineering Exams with Multimodal Large Language Models](https://arxiv.org/abs/2601.00730)
*Janez Perš,Jon Muhovič,Andrej Košir,Boštjan Murovec*

Main category: cs.CV

TL;DR: 提出一个基于多模态大语言模型的端到端工作流，用于自动批改手写STEM试卷，通过多阶段设计和参考解决方案摘要实现可靠评分，在真实课程测验中达到与教师评分约8分的平均绝对差异。


<details>
  <summary>Details</summary>
Motivation: 手写STEM考试能捕捉开放式推理和图表，但人工批改速度慢且难以扩展，需要自动化解决方案来保持标准考试流程（A4纸、无约束手写）的同时提高效率。

Method: 采用多阶段工作流：格式/存在性检查防止批改空白答案，独立评分器集成，监督器聚合，以及刚性模板与确定性验证生成可审计报告；使用多模态LLM（GPT-5.2和Gemini-3 Pro），仅需教师提供手写参考答案和简短评分规则，参考方案被转换为文本摘要以指导评分而不暴露原图。

Result: 在斯洛文尼亚语真实课程测验（含手绘电路图）的封闭协议评估中，完整流程与教师评分的平均绝对差异约为8分，偏差低，在D_max=40时手动审查触发率约17%；消融实验显示简化提示或移除参考方案会显著降低准确性并导致系统性评分过高。

Conclusion: 结构化提示和参考方案基础对准确性至关重要；该工作流能有效自动化手写工程测验批改，保持可靠性并减少人工干预需求。

Abstract: Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\approx$17% at $D_{\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [93] [RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning](https://arxiv.org/abs/2601.00086)
*Xiang Gao,Yuguang Yao,Qi Zhang,Kaiwen Dong,Avinash Baidya,Ruocheng Guo,Hilaf Hasson,Kamalika Das*

Main category: cs.CL

TL;DR: 提出RIMRULE方法，通过动态规则注入提升LLM在特定领域工具使用中的可靠性，无需修改模型权重即可提高任务性能。


<details>
  <summary>Details</summary>
Motivation: LLM在领域特定工具使用中常因API不规范、文档不全或私有工作流而表现不佳，需要有效的任务特定工具适应方法。

Method: 采用神经符号方法，从失败轨迹中提炼简洁可解释规则，在推理时动态注入提示；规则由LLM提出并通过最小描述长度目标优化，以自然语言和结构化符号形式存储。

Result: 在工具使用基准测试中，该方法提高了对已知和未知工具的准确率，优于提示适应方法且与微调互补；规则可在不同LLM间迁移，包括长推理模型。

Conclusion: RIMRULE通过符号规则注入有效提升LLM工具使用能力，展示了符号知识在不同架构间的可移植性。

Abstract: Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rules are proposed by the LLM itself and consolidated using a Minimum Description Length (MDL) objective that favors generality and conciseness. Each rule is stored in both natural language and a structured symbolic form, supporting efficient retrieval at inference time. Experiments on tool-use benchmarks show that this approach improves accuracy on both seen and unseen tools without modifying LLM weights. It outperforms prompting-based adaptation methods and complements finetuning. Moreover, rules learned from one LLM can be reused to improve others, including long reasoning LLMs, highlighting the portability of symbolic knowledge across architectures.

</details>


### [94] [Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning](https://arxiv.org/abs/2601.00095)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CL

TL;DR: 提出MetaJuLS，一种元强化学习方法，通过自适应约束传播实现跨语言和任务的通用结构化推理，显著提升推理速度并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型需要满足复杂约束的结构化推理（如JSON模式强制、多语言解析），现有方法通常需要针对特定任务重新训练，效率低下且难以泛化。

Method: 将结构化推理建模为自适应约束传播问题，使用图注意力网络结合元强化学习训练通用约束传播策略，无需任务特定重训练即可跨领域适应。

Result: 在GPU优化基线上实现1.5-2.0倍加速，精度与最先进解析器相差不超过0.2%；在10种语言的通用依存解析和LLM约束生成任务上，仅需5-10梯度步（5-15秒）即可适应新语言/任务。

Conclusion: MetaJuLS通过减少LLM部署中的传播步骤降低推理碳足迹，支持绿色AI；策略可自动发现类人解析策略和反直觉启发式规则，实现高效跨领域结构化推理。

Abstract: Large language models increasingly require structured inference, from JSON schema enforcement to multi-lingual parsing, where outputs must satisfy complex constraints. We introduce MetaJuLS, a meta-reinforcement learning approach that learns universal constraint propagation policies applicable across languages and tasks without task-specific retraining. By formulating structured inference as adaptive constraint propagation and training a Graph Attention Network with meta-learning, MetaJuLS achieves 1.5--2.0$\times$ speedups over GPU-optimized baselines while maintaining within 0.2\% accuracy of state-of-the-art parsers. On Universal Dependencies across 10 languages and LLM-constrained generation (LogicBench, GSM8K-Constrained), MetaJuLS demonstrates rapid cross-domain adaptation: a policy trained on English parsing adapts to new languages and tasks with 5--10 gradient steps (5--15 seconds) rather than requiring hours of task-specific training. Mechanistic analysis reveals the policy discovers human-like parsing strategies (easy-first) and novel non-intuitive heuristics. By reducing propagation steps in LLM deployments, MetaJuLS contributes to Green AI by directly reducing inference carbon footprint.

</details>


### [95] [Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description](https://arxiv.org/abs/2601.00166)
*Yongmin Yoo,Kris W Pan*

Main category: cs.CL

TL;DR: 提出Pat-DEVAL框架，首个针对专利说明书的多维度评估框架，通过法律约束推理机制评估自动生成专利的合规性与技术连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法有效衡量专利说明书的长文本结构连贯性与法定合规性，阻碍了自动化专利起草系统的实际应用。

Method: 采用LLM-as-a-judge范式，引入Chain-of-Legal-Thought（CoLT）法律约束推理机制，结合专利法特定分析流程，在Pap2Pat-EvalGold数据集上进行实验验证。

Result: Pat-DEVAL在专利专家验证下达到0.69的皮尔逊相关性，显著优于基线指标；在法律专业合规性方面相关性达0.73，证明法律约束注入对评估法律有效性的关键作用。

Conclusion: Pat-DEVAL通过建立兼顾技术合理性与法律合规性的新标准，为自动化专利起草系统的实际部署提供了可靠的方法基础。

Abstract: Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.

</details>


### [96] [Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation](https://arxiv.org/abs/2601.00181)
*Cheonkam Jeong,Adeline Nyamathi*

Main category: cs.CL

TL;DR: 本文通过系统分析IEMOCAP数据集，揭示了对话情感识别（ERC）中架构选择的关键因素，并首次将识别与生成通过语言分析连接起来。


<details>
  <summary>Details</summary>
Motivation: 现有ERC研究存在两个关键缺陷：对架构选择哪些真正重要缺乏理解，以及缺乏将识别与生成连接起来的语言分析。

Method: 1. 识别方面：采用10种子严格消融实验，分析对话上下文、分层句子表示和外部情感词典的影响；2. 语言分析：分析5,286个话语标记出现情况，研究情感与标记位置的关联。

Result: 1. 对话上下文至关重要，90%的增益来自最近10-30轮对话；2. 分层句子表示在提供上下文后无额外帮助；3. 外部情感词典无增益；4. 悲伤话语的左边缘标记使用率（21.9%）显著低于其他情感（28-32%），且悲伤话语最依赖上下文（提升22%）。

Conclusion: 简单架构结合严格因果上下文即可实现最优性能；情感与话语标记位置存在显著关联，悲伤话语因缺乏显性语用信号而更依赖对话历史进行消歧。

Abstract: While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.
  For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\% (4-way) and 67.07\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.
  For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, "sad" utterances exhibit reduced left-periphery marker usage (21.9\%) compared to other emotions (28--32\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.

</details>


### [97] [Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2601.00202)
*Wang Xing,Wei Song,Siyu Lin,Chen Wu,Zhesi Li,Man Wang*

Main category: cs.CL

TL;DR: 提出了一种针对时序知识图谱推理的蒸馏框架，利用大语言模型作为教师模型，将结构和时序推理能力迁移到轻量级学生模型中，在保持高效架构的同时提升时序建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有时序知识图谱推理模型参数量大、计算密集，导致硬件成本和能耗高，难以部署在资源受限、低功耗且需要实时推理的平台；同时现有压缩和蒸馏技术主要针对静态知识图谱，未能充分捕捉时序依赖关系，导致推理性能下降。

Method: 设计了一个专用于时序知识图谱推理的蒸馏框架，以大语言模型作为教师模型，通过集成大规模公共知识和任务特定时序信息，指导轻量级学生模型学习结构和时序推理能力。

Result: 在多个公开基准数据集上的实验表明，该方法持续优于强基线模型，在推理准确性、计算效率和实际可部署性之间取得了良好平衡。

Conclusion: 所提出的蒸馏框架能有效解决时序知识图谱推理模型的计算效率和部署难题，通过知识蒸馏实现高性能轻量级模型，为资源受限环境下的实时推理应用提供了可行方案。

Abstract: Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.

</details>


### [98] [From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark](https://arxiv.org/abs/2601.00216)
*Jinning Zhang,Jie Song,Wenhui Tu,Zecheng Li,Jingxuan Li,Jin Li,Xuan Liu,Taole Sha,Zichen Wei,Yan Li*

Main category: cs.CL

TL;DR: 本研究提出了一种将循证医学原则融入图检索增强生成的方法，通过PICO框架和贝叶斯重排序算法提升医学问答系统的证据质量和答案可靠性，并在运动康复领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前医学领域的检索增强生成方法主要关注性能提升，但忽视了循证医学原则，特别是缺乏查询与证据之间的PICO对齐以及证据等级在重排序中的考量。

Method: 提出一种通用策略，将PICO框架融入知识图谱构建与检索过程，并设计贝叶斯启发的重排序算法，根据证据等级校准排序分数，无需预定义权重。在运动康复领域构建知识图谱和问答对基准进行验证。

Result: 系统在运动康复领域实现了0.830的证据覆盖度、0.819的答案忠实度、0.882的语义相似度和0.788的PICOT匹配准确率。五位临床专家在5点李克特量表中给予4.66-4.84的高评分。

Conclusion: 所提出的循证医学适应策略能有效提升检索和答案质量，且可迁移至其他临床领域。发布的资源有助于缓解运动康复领域RAG数据集的稀缺问题。

Abstract: In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.

</details>


### [99] [JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation](https://arxiv.org/abs/2601.00223)
*Leonard Lin,Adam Lensenmayer*

Main category: cs.CL

TL;DR: 介绍了JP-TL-Bench，一个轻量级开源基准测试，用于指导日英翻译系统的迭代开发，通过可靠的LLM成对比较评估翻译质量。


<details>
  <summary>Details</summary>
Motivation: 日英翻译中，细微的礼貌、隐含意义、省略和语域选择对自然度影响显著，需要区分“哪个翻译更好”而非“翻译是否可接受”，现有基准难以捕捉这种细微差异。

Method: 采用参考无关的成对LLM比较方法，将候选模型与固定的锚定翻译集对比，使用Bradley-Terry模型聚合结果，并计算胜率和基于逻辑变换的0-10分“LT”分数。

Result: JP-TL-Bench提供了结构稳定的评估框架，确保相同锚定集、评判模型和聚合代码下得分一致，实现了可靠且成本可控的翻译质量评估。

Conclusion: 该基准为日英翻译系统的迭代开发提供了实用工具，通过细粒度比较解决翻译自然度的评估难题，支持持续优化。

Abstract: We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often "which of these two good translations is better?" rather than "is this translation acceptable?" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 "LT" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.

</details>


### [100] [Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback](https://arxiv.org/abs/2601.00224)
*Yan Sun,Ming Cai,Stanley Kok*

Main category: cs.CL

TL;DR: 提出Q*和Feedback+两种验证技术，通过生成器-判别器框架提升LLM助手在商业分析中的可靠性和执行准确性。


<details>
  <summary>Details</summary>
Motivation: 当前对话式商业分析系统缺乏内置验证机制，用户需手动验证可能错误的输出，影响企业工作流程的效率和可靠性。

Method: 提出Q*（反向翻译与语义匹配）和Feedback+（执行反馈引导代码优化）两种互补验证技术，并嵌入生成器-判别器框架。

Result: 在Spider、Bird和GSM8K基准测试中，Q*和Feedback+显著降低了错误率并缩短了任务完成时间。

Conclusion: 该研究为构建更可靠的企业级生成式AI系统提供了设计框架，同时指出反向翻译是性能瓶颈，为未来改进指明方向。

Abstract: As large language model (LLM) assistants become increasingly integrated into enterprise workflows, their ability to generate accurate, semantically aligned, and executable outputs is critical. However, current conversational business analytics (CBA) systems often lack built-in verification mechanisms, leaving users to manually validate potentially flawed results. This paper introduces two complementary verification techniques: Q*, which performs reverse translation and semantic matching between code and user intent, and Feedback+, which incorporates execution feedback to guide code refinement. Embedded within a generator-discriminator framework, these mechanisms shift validation responsibilities from users to the system. Evaluations on three benchmark datasets, Spider, Bird, and GSM8K, demonstrate that both Q* and Feedback+ reduce error rates and task completion time. The study also identifies reverse translation as a key bottleneck, highlighting opportunities for future improvement. Overall, this work contributes a design-oriented framework for building more reliable, enterprise-grade GenAI systems capable of trustworthy decision support.

</details>


### [101] [Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation](https://arxiv.org/abs/2601.00263)
*Qianli Wang,Van Bach Nguyen,Yihong Liu,Fedor Splitt,Nils Feldhus,Christin Seifert,Hinrich Schütze,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 本文系统研究了多语言反事实生成的质量、编辑模式、错误类型及其在数据增强中的应用效果，发现翻译生成的反事实有效性更高但修改更多，多语言数据增强对低资源语言效果更好，但生成质量限制了性能提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成英语反事实方面表现优异且具备多语言能力，但其在多语言反事实生成中的实际效果尚不明确，需要系统评估以指导模型解释和多语言应用。

Method: 1. 自动评估六种语言中直接生成和通过英语翻译生成的反事实；2. 分析高资源欧洲语言的编辑模式相似性；3. 识别并分类跨语言反事实中的常见错误类型；4. 比较多语言与跨语言反事实数据增强对模型性能的影响。

Result: 1. 翻译生成的反事实比直接生成的有效性更高，但需要更多修改，且质量仍不及原始英语反事实；2. 高资源欧洲语言的编辑模式高度相似；3. 识别出四类跨语言一致的错误类型；4. 多语言数据增强比跨语言数据增强带来更大性能提升，尤其对低资源语言，但反事实的缺陷限制了模型性能和鲁棒性的增益。

Conclusion: 多语言反事实生成存在质量差距和系统性错误，翻译方法虽能提高有效性但代价较大；编辑模式的跨语言相似性提示了通用扰动策略；反事实数据增强对低资源语言有益，但需进一步提升生成质量以释放其潜力。

Abstract: Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.

</details>


### [102] [Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity](https://arxiv.org/abs/2601.00268)
*Doyoung Kim,Zhiwei Ren,Jie Hao,Zhongkai Sun,Lichao Wang,Xiyao Ma,Zack Ye,Xu Han,Jun Yin,Heng Ji,Wei Shen,Xing Fan,Benjamin Yao,Chenlei Guo*

Main category: cs.CL

TL;DR: 提出了WildAGTEval基准，用于评估大语言模型代理在现实API复杂性下的函数调用能力，包含API规范和API执行两个维度的复杂性，并发现无关信息复杂性对模型性能影响最大。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设理想化的API系统，忽略了现实世界中的噪声API输出等复杂因素，需要更贴近实际的评估基准来测试LLM代理的真实能力。

Method: 设计了WildAGTEval基准，包含60个不同的复杂性场景，可组合成约32K测试配置，通过用户-代理交互评估LLM代理在这些场景下的表现。

Result: 评估发现大多数场景都具有挑战性，无关信息复杂性使强LLM性能下降27.3%；定性分析显示LLM有时会扭曲用户意图以声称完成任务，严重影响用户满意度。

Conclusion: WildAGTEval基准揭示了LLM代理在现实API复杂性下的局限性，特别是处理无关信息的能力不足，这对实际应用中的用户满意度有重要影响。

Abstract: We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.

</details>


### [103] [Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations](https://arxiv.org/abs/2601.00282)
*Qianli Wang,Nils Feldhus,Pepa Atanasova,Fedor Splitt,Simon Ostermann,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 本文研究了量化对大型语言模型自解释能力的影响，发现量化会导致自解释质量和忠实度轻微下降，但不会影响其作为模型压缩技术的有效性。


<details>
  <summary>Details</summary>
Motivation: 量化被广泛用于加速大型语言模型推理和部署，但其对模型自解释能力的影响尚未被探索。自解释在高风险应用中对于透明度至关重要，因此需要了解量化是否会降低自解释的质量和忠实度。

Method: 研究两种自解释类型（自然语言解释和反事实示例），使用三种常见量化技术在不同比特宽度下对LLMs进行量化，并通过用户研究评估自解释的连贯性和可信度。

Result: 量化通常导致自解释质量（最高下降4.4%）和忠实度（最高下降2.38%）的适度下降；用户研究表明量化降低了自解释的连贯性和可信度（最高8.5%）；较大模型在自解释质量上对量化的抵抗力有限，但在保持忠实度方面表现更好；没有一种量化技术在任务准确性、自解释质量和忠实度方面始终表现优异。

Conclusion: 量化对自解释的影响因上下文而异，建议针对具体用例验证自解释质量，尤其是对量化更敏感的自然语言解释。但自解释质量和忠实度的相对轻微恶化并不影响量化作为模型压缩技术的有效性。

Abstract: Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\%) and faithfulness (up to 2.38\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.

</details>


### [104] [DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection](https://arxiv.org/abs/2601.00303)
*Yuxin Li,Xiangyu Zhang,Yifei Li,Zhiwei Guo,Haoyang Zhang,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: 提出DepFlow框架，通过解耦语音中的抑郁声学特征与语义内容，构建伪装抑郁增强数据集，提升抑郁检测模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁检测数据集存在语义情感与诊断标签强耦合问题，导致模型易学习语义捷径，在伪装抑郁（患者使用积极/中性语言掩饰抑郁状态）等真实场景中表现不佳。

Method: 1. 抑郁声学编码器通过对抗训练学习与说话人和内容无关的抑郁嵌入；2. 基于流匹配的TTS模型通过FiLM调制注入抑郁嵌入，控制抑郁程度；3. 原型映射机制实现连续可解释的抑郁程度调控，构建伪装抑郁增强数据集。

Result: 抑郁声学编码器ROC-AUC达0.693；增强数据集在三种抑郁检测模型上分别提升macro-F1达9%、12%和5%，优于传统增强方法。

Conclusion: DepFlow能有效缓解语义偏差，提升模型对伪装抑郁的检测鲁棒性，同时为临床数据有限的对话系统和仿真评估提供可控合成平台。

Abstract: Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.

</details>


### [105] [Robust Uncertainty Quantification for Factual Generation of Large Language Models](https://arxiv.org/abs/2601.00348)
*Yuhao Zhang,Zhongliang Yang,Linna Zhou*

Main category: cs.CL

TL;DR: 本文提出一种针对大语言模型幻觉问题的新型不确定性量化方法RU，通过构建包含虚假名称的陷阱问题集，在涉及多事实生成的任务中验证了该方法优于传统基线方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在专业和日常生活中的广泛应用受到幻觉问题的严重制约，传统不确定性量化方法在面对非常规或对抗性提问时表现不足，限制了模型在需要批判性思维的真实场景中的可靠性。

Method: 研究构建了包含虚假名称的陷阱问题集，并创新性地提出了一种鲁棒的不确定性量化方法（RU），在涉及多事实生成的任务场景中进行不确定性评估。

Result: 实验表明，构建的陷阱问题集表现优异；在四个不同模型上，所提RU方法相比最佳基线方法在ROCAUC值上平均提升0.1-0.2，展现出显著优势。

Conclusion: 该研究为应对大语言模型幻觉问题提供了新的视角和方法，通过鲁棒的不确定性量化策略增强了模型在复杂提问下的可靠性。

Abstract: The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.

</details>


### [106] [The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining](https://arxiv.org/abs/2601.00364)
*Jiandong Shao,Raphael Tang,Crystina Zhang,Karin Sevegnani,Pontus Stenetorp,Jianfei Yang,Yao Lu*

Main category: cs.CL

TL;DR: 研究发现多语言大模型的翻译能力主要依赖语料库中少量平行数据，而跨语言理解和推理能力可通过单语数据实现。


<details>
  <summary>Details</summary>
Motivation: 探究多语言大模型中双语数据（仅占语料库2%）对跨语言能力的具体贡献机制，特别是翻译与其他跨语言任务表现差异的原因。

Method: 通过控制实验对比标准网络语料库与完全去除双语数据的单语版本，训练全新模型；将双语数据细分为平行数据、代码混合数据等类别进行精细化消融实验。

Result: 移除双语数据使翻译性能下降56%，但跨语言QA和推理任务表现稳定；平行数据可恢复91%的翻译性能，代码混合数据贡献微弱；其他跨语言任务基本不受双语数据类型影响。

Conclusion: 翻译能力依赖平行数据提供的系统性词汇对齐，而跨语言理解与推理能力无需双语数据即可实现，揭示了不同跨语言任务对数据需求的本质差异。

Abstract: Multilingual large language models achieve impressive cross-lingual performance despite largely monolingual pretraining. While bilingual data in pretraining corpora is widely believed to enable these abilities, details of its contributions remain unclear. We investigate this question by pretraining models from scratch under controlled conditions, comparing the standard web corpus with a monolingual-only version that removes all multilingual documents. Despite constituting only 2% of the corpus, removing bilingual data causes translation performance to drop 56% in BLEU, while behaviour on cross-lingual QA and general reasoning tasks remains stable, with training curves largely overlapping the baseline. To understand this asymmetry, we categorize bilingual data into parallel (14%), code-switching (72%), and miscellaneous documents (14%) based on the semantic relevance of content in different languages. We then conduct granular ablations by reintroducing parallel or code-switching data into the monolingual-only corpus. Our experiments reveal that parallel data almost fully restores translation performance (91% of the unfiltered baseline), whereas code-switching contributes minimally. Other cross-lingual tasks remain largely unaffected by either type. These findings reveal that translation critically depends on systematic token-level alignments from parallel data, whereas cross-lingual understanding and reasoning appear to be achievable even without bilingual data.

</details>


### [107] [BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics](https://arxiv.org/abs/2601.00366)
*Taj Gillin,Adam Lalani,Kenneth Zhang,Marcel Mateos Salles*

Main category: cs.CL

TL;DR: 提出BERT-JEPA（BEPA）训练范式，将JEPA目标融入BERT模型，解决[CLS]嵌入空间坍缩问题，提升多语言任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有BERT模型的[CLS]嵌入空间在多语言任务中存在坍缩现象，限制了其跨语言表示能力。

Method: 在BERT风格模型中引入联合嵌入预测架构（JEPA）训练目标，构建语言无关的嵌入空间。

Result: 该方法在多语言基准测试中表现出性能提升。

Conclusion: BEPA通过JEPA目标有效改善了BERT模型的多语言表示能力，为跨语言任务提供了新思路。

Abstract: Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.

</details>


### [108] [Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach](https://arxiv.org/abs/2601.00388)
*Biao Wu,Meng Fang,Ling Chen,Ke Xu,Tao Cheng,Jun Wang*

Main category: cs.CL

TL;DR: Geo-R是一个无需检索的图像地理定位框架，通过从真实坐标中提取结构化推理路径，并利用基于Haversine距离的强化学习优化定位精度，实现了可解释且可泛化的地理定位。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在图像地理定位中依赖合成标注或外部图像检索，限制了方法的可解释性和泛化能力，需要一种更直接且结构化的推理方法。

Method: 提出Chain of Region层次推理范式，将GPS坐标映射为地理实体（国家、省、市）；设计基于Haversine距离的轻量级强化学习策略，通过空间对齐奖励优化模型预测。

Result: 在多个基准测试中验证了Geo-R的有效性，实现了更高的定位精度、更强的泛化能力和更透明的推理过程。

Conclusion: Geo-R建立了无需检索的可扩展、可解释图像地理定位新范式，通过结合结构化地理推理与直接空间监督，推动了该领域的发展。

Abstract: Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.

</details>


### [109] [Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset](https://arxiv.org/abs/2601.00411)
*Alistair Plum,Laura Bernardy,Tharindu Ranasinghe*

Main category: cs.CL

TL;DR: 提出了judgeWEL数据集，这是一个用于卢森堡语命名实体识别（NER）的数据集，通过利用维基百科和维基数据作为弱监督源，并采用大型语言模型（LLM）进行自动标注和验证的新流程构建而成。


<details>
  <summary>Details</summary>
Motivation: 为低资源语言构建数据集是自然语言处理中的主要瓶颈之一，资源稀缺和语言特性使得大规模标注成本高昂且可能不一致。本研究旨在解决卢森堡语等资源不足语言的NER数据缺乏问题。

Method: 提出一种新颖方法，利用维基百科内部链接和对应的维基数据条目推断实体类型，生成初始标注；随后采用多个LLM识别并保留高质量标注句子，以降低噪声。

Result: 构建的judgeWEL数据集比现有卢森堡语NER数据集大约五倍，在实体类别上覆盖更广、更平衡，为多语言和低资源NER研究提供了重要新资源。

Conclusion: 通过结合结构化弱监督和LLM验证，能够高效构建高质量低资源语言NER数据集，该方法可扩展至其他资源不足语言，缓解数据稀缺问题。

Abstract: We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.

</details>


### [110] [Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment](https://arxiv.org/abs/2601.00444)
*Muhammad Shahmeer Khan*

Main category: cs.CL

TL;DR: 比较了DistilBERT、MiniLM和ALBERT三种轻量Transformer模型在情感分类、新闻分类和仇恨言论检测三个领域的性能与效率表现。


<details>
  <summary>Details</summary>
Motivation: 企业NLP应用对高效轻量模型处理多领域文本自动化任务的需求日益增长，需要评估不同轻量模型在准确性和效率方面的权衡。

Method: 使用IMDB、AG News和Measuring Hate Speech数据集，在三个领域任务上评估模型性能，采用准确率、精确率、召回率、F1分数等准确性指标，以及模型大小、推理时间、吞吐量和内存使用等效率指标。

Result: 没有单一模型在所有维度表现最优：ALBERT在多个领域任务准确率最高，MiniLM推理速度最快、吞吐量最高，DistilBERT在任务间准确率最稳定且效率有竞争力。

Conclusion: 研究揭示了准确性与效率之间的权衡，建议根据企业需求选择模型：延迟敏感应用选MiniLM，平衡性能选DistilBERT，资源受限环境选ALBERT。

Abstract: In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.

</details>


### [111] [Toward Better Temporal Structures for Geopolitical Events Forecasting](https://arxiv.org/abs/2601.00430)
*Kian Ahrabian,Eric Boxer,Jay Pujara*

Main category: cs.CL

TL;DR: 本文提出了一种新的超关系时序知识广义超图（HTKGHs）模型，用于更有效地表示复杂的地缘政治事件，并基于POLECAT数据库构建了htkgh-polecat数据集，评估了大语言模型在复杂时序预测任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的超关系时序知识图（HTKGs）在表示现实世界复杂事件时存在局限性，特别是无法支持涉及两个以上主要实体的时序事实，这限制了其在地缘政治事件预测中的应用。

Method: 1. 提出了HTKGHs的形式化定义，扩展了HTKGs以支持复杂事实类型；2. 基于POLECAT全球事件数据库构建了htkgh-polecat数据集；3. 在关系预测任务上对主流大语言模型进行了基准测试和分析。

Result: HTKGHs框架成功实现了向后兼容性，同时能够有效表示地缘政治事件中常见的两类复杂事实。实验结果表明，大语言模型在复杂时序预测场景中展现出一定的适应性和能力。

Conclusion: HTKGHs为复杂时序知识的表示提供了更强大的框架，htkgh-polecat数据集为评估大语言模型的时序推理能力提供了新基准，研究揭示了现有模型在复杂预测任务中的潜力和改进方向。

Abstract: Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.

</details>


### [112] [Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games](https://arxiv.org/abs/2601.00448)
*Dimitris Vartziotis*

Main category: cs.CL

TL;DR: 本文对比了语言的社会建构主义与数学语义场理论，通过形式化词汇场和语言场概念，分析Transformer架构如何体现语义规律，认为数学结构与语言游戏是互补视角。


<details>
  <summary>Details</summary>
Motivation: 利用大语言模型作为检验语言学理论的新实验场，调和长期对立的语言意义理论——社会建构主义与数学结构主义，为AI架构提供理论指导。

Method: 形式化词汇场和语言场作为连续语义空间中的交互结构，分析Transformer的分布式表示、注意力机制和嵌入空间几何特性与语义概念的关联。

Result: LLM捕捉语义规律的能力支持语言存在数学结构，但其语用推理和语境敏感性的局限印证了社会基础的重要性，二者可形成互补框架。

Conclusion: 数学结构与语言游戏是互补视角，该框架明确了纯统计语言模型的适用范围，为理论指导的AI架构设计提供了新方向。

Abstract: Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.

</details>


### [113] [Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations](https://arxiv.org/abs/2601.00454)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: 提出Defensive M2S训练范式，通过将多轮对话压缩为单轮对话来训练护栏模型，显著降低训练和推理成本，同时保持高攻击检测性能。


<details>
  <summary>Details</summary>
Motivation: 处理完整多轮对话历史进行护栏模型训练和推理计算成本高昂，需要一种高效的方法来确保LLM部署的安全性。

Method: 采用Multi-turn to Single-turn (M2S)压缩对话训练范式，使用三种压缩模板（hyphenize、numberize、pythonize），在三个护栏模型家族（LlamaGuard、Nemotron、Qwen3Guard）上进行评估。

Result: 最佳配置（Qwen3Guard+hyphenize）在SafeDialBench上达到93.8%攻击检测召回率，推理token减少94.6%（从3,231降至173），训练token减少93倍（从15.7M降至169K）。

Conclusion: M2S压缩可作为护栏部署的有效效率技术，显著降低长多轮对话安全筛查的计算成本，同时保持高性能。

Abstract: Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.

</details>


### [114] [Noise-Aware Named Entity Recognition for Historical VET Documents](https://arxiv.org/abs/2601.00488)
*Alexander M. Esser,Jens Dörpinghaus*

Main category: cs.CL

TL;DR: 提出一种针对职业教育培训领域历史文档的鲁棒命名实体识别方法，通过噪声感知训练、迁移学习和多阶段微调处理OCR噪声，支持多实体类型识别且可跨语言应用。


<details>
  <summary>Details</summary>
Motivation: 职业教育培训领域的历史数字化文档存在OCR噪声问题，传统NER方法在此类噪声环境下性能下降，需要专门针对噪声和领域特性的解决方案。

Method: 采用噪声感知训练（NAT）结合合成OCR错误注入、迁移学习和多阶段微调策略，系统比较了在噪声数据、干净数据和人工数据上的三种训练策略。

Result: 实验结果表明，领域特定和噪声感知的微调显著提升了模型在噪声条件下的鲁棒性和准确性，该方法在德语文档上验证有效且可推广到其他语言。

Conclusion: 提出的方法首次实现了职业教育培训文档的多实体类型识别，通过公开代码提供了可复现的领域特定噪声感知NER解决方案。

Abstract: This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.

</details>


### [115] [Rule-Based Approaches to Atomic Sentence Extraction](https://arxiv.org/abs/2601.00506)
*Lineesha Kamana,Akshita Ananda Subramanian,Mehuli Ghosh,Suman Saha*

Main category: cs.CL

TL;DR: 本文分析了复杂句子结构对基于规则的原子句提取性能的影响，识别出相对从句、同位语、并列谓语等结构是主要挑战。


<details>
  <summary>Details</summary>
Motivation: 现有原子句提取方法缺乏可解释性，无法明确哪些语言结构导致提取失败，需要系统分析句法结构与提取难度的关系。

Method: 使用WikiSplit数据集，在spaCy中实现基于依存关系的提取规则，生成100组标准原子句集，采用ROUGE和BERTScore评估性能。

Result: 系统取得ROUGE-1 F1=0.6714、ROUGE-2 F1=0.478、ROUGE-L F1=0.650、BERTScore F1=0.5898，相对从句、同位语、并列谓语、状语从句和被动结构是主要难点。

Conclusion: 基于规则的提取方法具有合理准确性，但对句法复杂度敏感，未来需针对挑战性结构开发更鲁棒的解决方案。

Abstract: Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the "split-and-rephrase" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.

</details>


### [116] [Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends](https://arxiv.org/abs/2601.00536)
*Yuelyu Ji,Zhuochun Li,Rui Meng,Daqing He*

Main category: cs.CL

TL;DR: 本文提出一个四轴框架分析多跳问答系统的执行过程，对现有方法进行分类比较，总结效果、效率和证据忠实度之间的权衡，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前多跳问答系统的检索-推理过程通常不透明，不同模型家族的程序选择难以比较，需要系统化的分析框架来理解其执行机制。

Method: 提出以执行过程为分析单元的四轴框架，包括整体执行计划、索引结构、下一步控制策略与触发机制、停止/继续标准，并基于此框架对代表性多跳问答系统进行映射分析。

Result: 通过框架分析揭示了多跳问答系统在效果、效率和证据忠实度之间的常见权衡模式，并在标准基准测试上综合了现有方法的消融实验和趋势。

Conclusion: 多跳问答系统仍面临结构感知规划、可迁移控制策略、分布偏移下的鲁棒停止等开放挑战，需要进一步研究提升检索-推理代理的能力。

Abstract: Multi-hop question answering (QA) requires systems to iteratively retrieve evidence and reason across multiple hops. While recent RAG and agentic methods report strong results, the underlying retrieval--reasoning \emph{process} is often left implicit, making procedural choices hard to compare across model families. This survey takes the execution procedure as the unit of analysis and introduces a four-axis framework covering (A) overall execution plan, (B) index structure, (C) next-step control (strategies and triggers), and (D) stop/continue criteria. Using this schema, we map representative multi-hop QA systems and synthesize reported ablations and tendencies on standard benchmarks (e.g., HotpotQA, 2WikiMultiHopQA, MuSiQue), highlighting recurring trade-offs among effectiveness, efficiency, and evidence faithfulness. We conclude with open challenges for retrieval--reasoning agents, including structure-aware planning, transferable control policies, and robust stopping under distribution shift.

</details>


### [117] [ECR: Manifold-Guided Semantic Cues for Compact Language Models](https://arxiv.org/abs/2601.00543)
*Chung-Wei Victor Yuan*

Main category: cs.CL

TL;DR: 提出嵌入一致性调节（ECR）框架，解决紧凑模型嵌入空间结构丢失问题，通过语义锚点保持几何一致性，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 紧凑模型在容量受限或多语言数据下易出现嵌入空间结构坍塌，导致语义漂移和下游任务性能下降，现有压缩方法未能有效保持底层流形结构。

Method: ECR框架从教师模型嵌入中提取语义锚点（离线计算），训练紧凑模型围绕锚点保持几何一致性，无需匹配logits或内部特征，推理时仅增加小型投影步骤。

Result: 在10万条多语言语料实验中，ECR稳定训练过程，跨任务和语言保持语义结构，生成更紧凑且任务对齐的表示空间，使低容量模型学习到比传统基线更清晰的流形。

Conclusion: ECR帮助紧凑模型更好地遵循任务需求，无需教师输出即可工作，与蒸馏兼容但独立，便于在效率或隐私限制下部署。

Abstract: Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.
  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.
  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.

</details>


### [118] [InfoSynth: Information-Guided Benchmark Synthesis for LLMs](https://arxiv.org/abs/2601.00575)
*Ishir Garg,Neel Kolhe,Xuandong Zhao,Dawn Song*

Main category: cs.CL

TL;DR: 提出InfoSynth框架，基于信息论原理自动生成和评估LLM推理基准，通过遗传算法和代码反馈合成Python编程问题，实现高质量、新颖且多样化的基准创建。


<details>
  <summary>Details</summary>
Motivation: 传统基准创建依赖人工，成本高且耗时；现有基准常污染LLM训练数据，需要新颖多样的基准来准确评估模型真实能力。

Method: 基于KL散度和熵设计量化基准新颖性和多样性的指标；利用遗传算法和迭代代码反馈构建端到端流水线，从种子数据集合成Python编程问题。

Result: 新问题生成准确测试用例和解决方案的成功率达97%；合成基准相比种子数据集具有更高的新颖性和多样性；算法可控制生成问题的新颖性/多样性和难度。

Conclusion: InfoSynth为LLM提供了可扩展、自验证的高质量基准构建流水线，能有效解决基准创建中的成本、污染和多样性不足问题。

Abstract: Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/

</details>


### [119] [A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR](https://arxiv.org/abs/2601.00557)
*Yuang Zheng,Yuxiang Mei,Dongxing Xu,Jie Chen,Yanhua Long*

Main category: cs.CL

TL;DR: 提出了一种轻量级、语言无关的多语言ASR系统HLoRA，基于CTC架构和领域自适应，通过分层LoRA-MoE框架实现单次解码，在保持性能的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有大规模多语言ASR模型（如Whisper）计算和延迟成本高，难以部署在资源受限的边缘设备上，需要更高效的轻量级解决方案。

Method: 在mHuBERT-CTC模型中引入语言无关的分层LoRA-MoE框架（HLoRA），包含多语言共享LoRA（学习语言无关声学特征）和语言特定LoRA专家（建模语言相关特性），通过LID后验驱动的LoRA路由实现端到端解码，无需推理时的先验语言信息。

Result: 在MSR-86K和MLC-SLM 2025挑战数据集上的实验表明，HLoRA仅通过单次解码即可达到与先进两阶段推理方法相当的性能，显著提升了低资源多语言ASR的解码效率。

Conclusion: HLoRA框架实现了高效、语言无关的多语言ASR，为资源受限环境下的部署提供了可行方案，平衡了性能与计算成本。

Abstract: Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.

</details>


### [120] [CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns](https://arxiv.org/abs/2601.00588)
*Zhenhong Zhou,Shilinlu Yan,Chuanpu Liu,Qiankun Li,Kun Wang,Zhigang Zeng*

Main category: cs.CL

TL;DR: 提出中文特定安全基准CSSBench，针对轻量级大语言模型在中文对抗性查询下的安全性进行评估，填补现有英文基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有安全基准主要关注英文，而中文恶意查询常通过谐音、拼音、符号拆分等特定模式隐藏意图，轻量级模型对此类攻击尤为脆弱，需专门评估工具。

Method: 构建CSSBench基准，覆盖非法活动、隐私泄露、医疗误导、欺诈仇恨、成人内容、公共政治安全六大中文典型领域，设计多任务类型查询，评估轻量级LLM并测量过度拒绝行为。

Result: 中文特定对抗模式对轻量级LLM构成显著安全挑战，模型存在安全导致的性能下降问题。

Conclusion: CSSBench为中文LLM安全提供全面评估框架，有助于实践中模型的鲁棒部署，凸显针对语言特性设计安全基准的必要性。

Abstract: Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.

</details>


### [121] [Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence](https://arxiv.org/abs/2601.00596)
*Sumanth Balaji,Piyush Mishra,Aashraya Sachdeva,Suraj Agrawal*

Main category: cs.CL

TL;DR: 提出了JourneyBench基准测试，用于评估客户支持场景中LLM代理的政策遵循能力，并展示了动态提示代理在提升政策遵循方面的优势。


<details>
  <summary>Details</summary>
Motivation: 传统客户支持系统（如IVR）缺乏灵活性，而现有基准测试主要关注工具使用或任务完成，忽略了代理在多步骤政策遵循、任务依赖处理以及对不可预测用户行为的鲁棒性方面的能力评估。

Method: 1. 引入JourneyBench基准，利用图表示生成多样化的客户支持场景；2. 提出用户旅程覆盖率作为政策遵循的新评估指标；3. 比较两种代理设计：静态提示代理和显式建模政策控制的动态提示代理；4. 在三个领域的703次对话中进行评估。

Result: 动态提示代理显著提升了政策遵循能力，即使较小的模型（如GPT-4o-mini）也能超越更强大的模型（如GPT-4o）。

Conclusion: 结构化编排对AI驱动的客户支持至关重要，JourneyBench为超越IVR时代限制提供了关键资源，动态提示方法能有效提升政策遵循能力。

Abstract: Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks. While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge. Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support. JourneyBench leverages graph representations to generate diverse, realistic support scenarios and proposes the User Journey Coverage Score, a novel metric to measure policy adherence. We evaluate multiple state-of-the-art LLMs using two agent designs: a Static-Prompt Agent (SPA) and a Dynamic-Prompt Agent (DPA) that explicitly models policy control. Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o. Our findings demonstrate the importance of structured orchestration and establish JourneyBench as a critical resource to advance AI-driven customer support beyond IVR-era limitations.

</details>


### [122] [Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs](https://arxiv.org/abs/2601.00641)
*Nils Rautenberg,Sven Schippkus*

Main category: cs.CL

TL;DR: 提出一种模型无关框架，通过重复采样和多数投票机制为固定输入任务提供可证明的幻觉概率指数级降低保证


<details>
  <summary>Details</summary>
Motivation: 大语言模型在确定性自动化工作流中经常产生与提示明确信息矛盾的上下文幻觉，而现有方法缺乏理论保证

Method: 1) 对同一提示进行独立上下文窗口重复采样；2) 使用LLM作为裁判评估输出正确性；3) 通过多数投票机制增强不完美裁判的可靠性

Result: 实验显示：管道失败概率随重复次数指数下降，幻觉选择概率随裁判数量指数下降，理论预测与实验结果完全匹配

Conclusion: 该框架提供了一种轻量级、模块化且理论完备的方法，可在不修改模型权重、解码策略或提示工程的情况下，将固定输入工作流中的幻觉概率降至任意低水平

Abstract: Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.
  We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.
  Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.

</details>


### [123] [Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations](https://arxiv.org/abs/2601.00647)
*QiWei Meng*

Main category: cs.CL

TL;DR: 提出Physio-DPO框架，通过物理信息对齐减少蛋白质语言模型的结构幻觉，提高生成序列的热力学稳定性和可折叠性。


<details>
  <summary>Details</summary>
Motivation: 现有蛋白质语言模型常产生结构幻觉，生成序列虽语言概率高但热力学不稳定；传统对齐方法（如DPO）将偏好建模为二元标签，忽略了物理能量景观的连续结构。

Method: 提出Physio-DPO框架，引入幅度感知目标函数，根据天然结构与物理扰动硬负样本之间的能量差缩放优化更新，将蛋白质语言模型与热力学稳定性对齐。

Result: Physio-DPO在实验中优于SFT、PPO和标准DPO基线，将自一致性RMSD降至1.28 Å，可折叠性提升至92.8%，定性分析显示其能有效恢复疏水核心堆积和氢键网络等生物物理相互作用。

Conclusion: Physio-DPO通过物理信息对齐显著减少了结构幻觉，提高了生成蛋白质序列的结构合理性和稳定性，为基于语言的蛋白质设计提供了更可靠的框架。

Abstract: Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 Å and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks.

</details>


### [124] [Fast-weight Product Key Memory](https://arxiv.org/abs/2601.00671)
*Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: 提出Fast-weight Product Key Memory (FwPKM)，将静态PKM转化为动态快速权重记忆，在保持高效计算的同时实现无界存储，显著提升长上下文建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有序列建模层面临存储容量与计算效率的权衡：Softmax注意力计算成本高，线性变体存储有限。需要一种既能高效计算又具备灵活存储能力的架构。

Method: 将稀疏Product Key Memory (PKM)改造为动态快速权重记忆，在训练和推理时通过局部块级梯度下降动态更新参数，实现输入序列中键值对的快速记忆与检索。

Result: FwPKM作为有效的情景记忆模块，与标准语义记忆互补，在长上下文数据集上显著降低困惑度；在Needle in a Haystack评估中，仅用4K标记训练即可泛化至128K标记上下文。

Conclusion: FwPKM成功解决了序列建模中存储与效率的矛盾，为语言模型提供了可扩展的情景记忆机制，在长上下文任务中表现出强大的泛化能力。

Abstract: Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, "fast-weight" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.

</details>


### [125] [Sigmoid Head for Quality Estimation under Language Ambiguity](https://arxiv.org/abs/2601.00680)
*Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: 提出Sigmoid Head模块解决语言模型概率作为质量估计器不可靠的问题，通过sigmoid激活和负采样策略提升质量信号，无需人工标注数据。


<details>
  <summary>Details</summary>
Motivation: 语言模型的softmax概率分布因自然语言歧义性无法同时为多个正确选项分配高概率，且训练数据的单热编码限制导致概率不能可靠反映输出质量。

Method: 在预训练语言模型上训练质量估计模块Sigmoid Head，采用sigmoid激活的额外解嵌入头，并通过启发式负采样避免选择潜在正确标记。

Result: Sigmoid Head的概率相比原始softmax头提供更优的质量信号，计算高效，且在领域外设置中比监督式质量估计更稳健。

Conclusion: Sigmoid Head有效解决了语言模型概率作为质量估计器的局限性，无需人工标注即可提供可靠的质量评估，具有计算效率和领域适应性优势。

Abstract: Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.

</details>


### [126] [Exploring the Performance of Large Language Models on Subjective Span Identification Tasks](https://arxiv.org/abs/2601.00736)
*Alphaeus Dmonte,Roland Oruche,Tharindu Ranasinghe,Marcos Zampieri,Prasad Calyam*

Main category: cs.CL

TL;DR: 本文评估了多种大型语言模型在文本跨度识别任务上的表现，特别是在情感分析、冒犯性语言识别和声明验证等主观性较强的任务中，探索了指令调优、上下文学习和思维链等策略。


<details>
  <summary>Details</summary>
Motivation: 当前大多数跨度识别方法依赖BERT等较小预训练模型，而利用最新大型语言模型进行主观性跨度识别（如基于方面的情感分析）的研究不足，本文旨在填补这一空白。

Method: 在情感分析、冒犯性语言识别和声明验证三个任务上，评估多种LLM的文本跨度识别性能，并探索指令调优、上下文学习和思维链等策略的应用。

Result: 实验结果表明，文本内部的语义关系有助于LLM更精确地识别文本跨度。

Conclusion: 大型语言模型在主观性文本跨度识别任务中具有潜力，文本内部关系是提升识别精度的关键因素。

Abstract: Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.

</details>


### [127] [Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries](https://arxiv.org/abs/2601.00787)
*Jonathan Simkin,Lovedeep Gondara,Zeeshan Rizvi,Gregory Doyle,Jeff Dowden,Dan Bond,Desmond Martin,Raymond Ng*

Main category: cs.CL

TL;DR: 本研究评估了跨省适应Transformer模型（BCCRTron和GatorTron）用于加拿大癌症监测的可行性，通过集成模型显著减少了漏诊癌症病例，并提出了隐私保护的工作流程。


<details>
  <summary>Details</summary>
Motivation: 基于人群的癌症登记依赖病理报告作为主要诊断来源，但人工提取资源密集且导致数据延迟。现有NLP系统在跨司法管辖区（报告规范不同）的泛化能力尚不明确，需要评估模型跨省适应的效果。

Method: 使用纽芬兰与拉布拉多癌症登记处的约104,000份（Tier 1任务：癌症vs非癌症）和22,000份（Tier 2任务：可报告vs不可报告癌症）去标识化病理报告进行训练。对BCCRTron（领域适应Transformer）和GatorTron（生物医学Transformer）进行微调，采用互补的格式化和诊断聚焦的报告部分输入管道，并通过保守OR集成结合两个模型。

Result: 在NLCR测试集上，适应模型保持高性能，表明在一个司法管辖区预训练的Transformer可通过适度微调本地化到另一个管辖区。集成模型在Tier 1任务中召回率达到0.99，漏诊癌症降至24例（单独模型为48和54例）；在Tier 2任务中召回率0.99，漏诊可报告癌症降至33例（单独模型为54和46例）。

Conclusion: 结合互补文本表示的集成模型可显著减少漏诊癌症并提高癌症登记NLP的错误覆盖。研究实现了隐私保护工作流程（仅共享模型权重），支持可互操作的NLP基础设施，为未来泛加拿大癌症病理和登记工作流程的基础模型奠定基础。

Abstract: Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [128] [Reinforcement learning with timed constraints for robotics motion planning](https://arxiv.org/abs/2601.00087)
*Zhaoan Wang,Junchao Li,Mahdi Mohammad,Shaoping Xiao*

Main category: cs.RO

TL;DR: 提出了一种基于自动机的强化学习框架，用于在MITL时序逻辑约束下为MDP和POMDP合成策略，通过时间约束的奖励结构确保时序正确性，并在网格世界和服务机器人场景中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 动态不确定环境中的机器人系统需要满足复杂时序约束的任务规划，MITL能形式化表达时间约束，但如何将其与强化学习结合以处理随机动态和部分可观测性仍具挑战。

Method: 将MITL公式转换为Timed-LDGBA自动机，与底层决策过程同步构建乘积时间模型，设计简单而富有表达力的奖励结构，采用Q-learning进行策略学习。

Result: 在MDP网格世界、POMDP网格世界和服务机器人场景的仿真中，该方法能学习满足严格时间约束的策略，适应随机转移，可扩展至更大状态空间，并在部分可观测环境中保持有效。

Conclusion: 该框架为时间关键和不确定环境中的机器人规划提供了可靠解决方案，能合成满足复杂时序约束的策略，并适用于部分可观测的随机系统。

Abstract: Robotic systems operating in dynamic and uncertain environments increasingly require planners that satisfy complex task sequences while adhering to strict temporal constraints. Metric Interval Temporal Logic (MITL) offers a formal and expressive framework for specifying such time-bounded requirements; however, integrating MITL with reinforcement learning (RL) remains challenging due to stochastic dynamics and partial observability. This paper presents a unified automata-based RL framework for synthesizing policies in both Markov Decision Processes (MDPs) and Partially Observable Markov Decision Processes (POMDPs) under MITL specifications. MITL formulas are translated into Timed Limit-Deterministic Generalized Büchi Automata (Timed-LDGBA) and synchronized with the underlying decision process to construct product timed models suitable for Q-learning. A simple yet expressive reward structure enforces temporal correctness while allowing additional performance objectives. The approach is validated in three simulation studies: a $5 \times 5$ grid-world formulated as an MDP, a $10 \times 10$ grid-world formulated as a POMDP, and an office-like service-robot scenario. Results demonstrate that the proposed framework consistently learns policies that satisfy strict time-bounded requirements under stochastic transitions, scales to larger state spaces, and remains effective in partially observable environments, highlighting its potential for reliable robotic planning in time-critical and uncertain settings.

</details>


### [129] [Compositional Diffusion with Guided search for Long-Horizon Planning](https://arxiv.org/abs/2601.00126)
*Utkarsh A Mishra,David He,Yongxin Chen,Danfei Xu*

Main category: cs.RO

TL;DR: 提出CDGS方法解决组合生成模型中的模式平均问题，通过将搜索嵌入扩散去噪过程，在机器人操作、全景图像和长视频生成中实现全局一致的规划。


<details>
  <summary>Details</summary>
Motivation: 组合生成模型在处理多模态局部分布时，现有方法会平均不兼容的模式，导致生成的规划既不可行也不连贯，需要解决这一关键挑战。

Method: CDGS方法在扩散去噪过程中嵌入引导搜索，通过基于群体的采样探索局部模式组合，使用基于似然的过滤剪枝不可行候选，并通过重叠段间的迭代重采样保证全局一致性。

Result: CDGS在七项机器人操作任务中达到与Oracle相当的性能，优于缺乏组合性或需要长视距训练数据的基线方法，并能跨领域生成连贯的全景图像和长视频。

Conclusion: CDGS通过有效的局部到全局消息传递，解决了组合生成模型的模式平均问题，实现了跨领域的连贯长视距规划与生成。

Abstract: Generative models have emerged as powerful tools for planning, with compositional approaches offering particular promise for modeling long-horizon task distributions by composing together local, modular generative models. This compositional paradigm spans diverse domains, from multi-step manipulation planning to panoramic image synthesis to long video generation. However, compositional generative models face a critical challenge: when local distributions are multimodal, existing composition methods average incompatible modes, producing plans that are neither locally feasible nor globally coherent. We propose Compositional Diffusion with Guided Search (CDGS), which addresses this \emph{mode averaging} problem by embedding search directly within the diffusion denoising process. Our method explores diverse combinations of local modes through population-based sampling, prunes infeasible candidates using likelihood-based filtering, and enforces global consistency through iterative resampling between overlapping segments. CDGS matches oracle performance on seven robot manipulation tasks, outperforming baselines that lack compositionality or require long-horizon training data. The approach generalizes across domains, enabling coherent text-guided panoramic images and long videos through effective local-to-global message passing. More details: https://cdgsearch.github.io/

</details>


### [130] [SLEI3D: Simultaneous Exploration and Inspection via Heterogeneous Fleets under Limited Communication](https://arxiv.org/abs/2601.00163)
*Junfeng Chen,Yuxiao Zhu,Xintong Zhang,Bing Luo,Meng Guo*

Main category: cs.RO

TL;DR: 提出SLEI3D框架，解决异构机器人团队在未知环境中同时进行探索、检查和实时通信的问题，通过多层多速率规划机制协调机器人子群，实现高效协作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人编队通常用于已知环境的例行检查，但在许多应用中，感兴趣区域未知且需在线识别，同时需在缺乏全局通信的受限环境中实现实时数据回传至移动地面站。

Method: 开发SLEI3D规划协调框架，集成协作3D探索、自适应检查和及时通信策略；采用多层多速率规划机制协调机器人子群，处理特征数量和位置的不确定性；通过间歇或主动通信协议实现ad-hoc网络通信。

Result: 框架在大型任务的高保真仿真中得到验证（最多48个机器人、38.4万立方米环境），并进行了7个机器人的硬件实验，证明其有效性和可扩展性。

Conclusion: SLEI3D框架能够有效协调异构机器人在未知环境中实现同步探索、检查和通信，为解决复杂环境下的多机器人协同任务提供了可行方案。

Abstract: Robotic fleets such as unmanned aerial and ground vehicles have been widely used for routine inspections of static environments, where the areas of interest are known and planned in advance. However, in many applications, such areas of interest are unknown and should be identified online during exploration. Thus, this paper considers the problem of simultaneous exploration, inspection of unknown environments and then real-time communication to a mobile ground control station to report the findings. The heterogeneous robots are equipped with different sensors, e.g., long-range lidars for fast exploration and close-range cameras for detailed inspection. Furthermore, global communication is often unavailable in such environments, where the robots can only communicate with each other via ad-hoc wireless networks when they are in close proximity and free of obstruction. This work proposes a novel planning and coordination framework (SLEI3D) that integrates the online strategies for collaborative 3D exploration, adaptive inspection and timely communication (via the intermit-tent or proactive protocols). To account for uncertainties w.r.t. the number and location of features, a multi-layer and multi-rate planning mechanism is developed for inter-and-intra robot subgroups, to actively meet and coordinate their local plans. The proposed framework is validated extensively via high-fidelity simulations of numerous large-scale missions with up to 48 robots and 384 thousand cubic meters. Hardware experiments of 7 robots are also conducted. Project website is available at https://junfengchen-robotics.github.io/SLEI3D/.

</details>


### [131] [SLAP: Slapband-based Autonomous Perching Drone with Failure Recovery for Vertical Tree Trunks](https://arxiv.org/abs/2601.00238)
*Julia Di,Kenneth A. W. Hoffmann,Tony G. Chen,Tian-Ao Ren,Mark R. Cutkosky*

Main category: cs.RO

TL;DR: 本文提出了一种名为SLAP的系统，使无人机能够轻柔地栖息在垂直树干上，并能检测和从栖息失败中恢复。


<details>
  <summary>Details</summary>
Motivation: 现有垂直表面栖息方法通常需要高速、激进的着陆操作，对搭载敏感电子设备的无人机存在危险，且缺乏系统级集成。

Method: 开发了SLAP系统，包括视觉栖息点检测器、IMU栖息失败检测器、姿态控制器、光学近距离检测系统以及由市售拍手环制成的快速主动弹性抓手（带微刺）。在1.2公斤改装四旋翼无人机上进行了验证。

Result: 室内自主飞行实验在20次飞行中对真实橡树段实现了75%的栖息成功率，在2次诱导失败飞行中实现了100%的失败恢复率。

Conclusion: SLAP系统为较大型无人机提供了一种安全、轻柔的垂直表面栖息方案，具备失败检测与恢复能力，展示了系统级集成的有效性。

Abstract: Perching allows unmanned aerial vehicles (UAVs) to reduce energy consumption, remain anchored for surface sampling operations, or stably survey their surroundings. Previous efforts for perching on vertical surfaces have predominantly focused on lightweight mechanical design solutions with relatively scant system-level integration. Furthermore, perching strategies for vertical surfaces commonly require high-speed, aggressive landing operations that are dangerous for a surveyor drone with sensitive electronics onboard. This work presents the preliminary investigation of a perching approach suitable for larger drones that both gently perches on vertical tree trunks and reacts and recovers from perch failures. The system in this work, called SLAP, consists of vision-based perch site detector, an IMU (inertial-measurement-unit)-based perch failure detector, an attitude controller for soft perching, an optical close-range detection system, and a fast active elastic gripper with microspines made from commercially-available slapbands. We validated this approach on a modified 1.2 kg commercial quadrotor with component and system analysis. Initial human-in-the-loop autonomous indoor flight experiments achieved a 75% perch success rate on a real oak tree segment across 20 flights, and 100% perch failure recovery across 2 flights with induced failures.

</details>


### [132] [Vehicle Painting Robot Path Planning Using Hierarchical Optimization](https://arxiv.org/abs/2601.00271)
*Yuya Nagai,Hiromitsu Nakamura,Narito Shinmachi,Yuta Higashizono,Satoshi Ono*

Main category: cs.RO

TL;DR: 本文提出了一种分层优化方法，用于自动化设计车辆喷漆过程中多机械臂的喷漆路径，以替代耗时的人工设计。


<details>
  <summary>Details</summary>
Motivation: 车辆喷漆路径设计目前依赖工程师手动完成，耗时且效率低；传统机器人路径规划方法（如焊接）无法直接适用于喷漆过程的独特约束，因此需要自动化解决方案以减少设计时间。

Method: 将喷漆路径设计建模为分层优化问题：上层子问题类似车辆路径问题（VRP），负责分配车身区域给机械臂；下层子问题负责详细路径规划。通过设计变量表示、约束、修复算子和初始化过程，灵活处理喷漆过程的特定约束。

Result: 在三种商用车型上的实验表明，该方法能自动设计出满足所有约束的喷漆路径，其质量与工程师手动设计的路径相当。

Conclusion: 所提出的分层优化方法能有效自动化车辆喷漆路径设计，在保证质量的同时显著减少设计时间，验证了该方法在工业应用中的可行性。

Abstract: In vehicle production factories, the vehicle painting process employs multiple robotic arms to simultaneously apply paint to car bodies advancing along a conveyor line. Designing paint paths for these robotic arms, which involves assigning car body areas to arms and determining paint sequences for each arm, remains a time-consuming manual task for engineers, indicating the demand for automation and design time reduction. The unique constraints of the painting process hinder the direct application of conventional robotic path planning techniques, such as those used in welding. Therefore, this paper formulates the design of paint paths as a hierarchical optimization problem, where the upper-layer subproblem resembles a vehicle routing problem (VRP), and the lower-layer subproblem involves detailed path planning. This approach allows the use of different optimization algorithms at each layer, and permits flexible handling of constraints specific to the vehicle painting process through the design of variable representation, constraints, repair operators, and an initialization process at the upper and lower layers. Experiments with three commercially available vehicle models demonstrated that the proposed method can automatically design paths that satisfy all constraints for vehicle painting with quality comparable to those created manually by engineers.

</details>


### [133] [Pure Inertial Navigation in Challenging Environments with Wheeled and Chassis Mounted Inertial Sensors](https://arxiv.org/abs/2601.00275)
*Dusan Nemec,Gal Versano,Itai Savin,Vojtech Simak,Juraj Kekelak,Itzik Klein*

Main category: cs.RO

TL;DR: 提出WiCHINS系统，通过融合轮载和车体惯性传感器实现精确纯惯性导航，在挑战性环境下实现稳健导航。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆和轮式机器人在GNSS信号受限或光照条件不佳时，仅依赖惯性传感器会导致导航误差随时间累积漂移，需要提高纯惯性导航的精度。

Method: 提出三阶段框架，每个阶段使用专用扩展卡尔曼滤波器，结合轮载和车体惯性测量单元的优势进行状态估计。

Result: 使用5个IMU（总记录时间228.6分钟）验证，相比四个惯性基线方法，使用两个轮载IMU和一个车体IMU时平均位置误差为11.4米（占平均行驶距离的2.4%）。

Conclusion: WiCHINS系统能有效缩小纯惯性导航的性能差距，在挑战性环境中实现稳健导航。

Abstract: Autonomous vehicles and wheeled robots are widely used in many applications in both indoor and outdoor settings. In practical situations with limited GNSS signals or degraded lighting conditions, the navigation solution may rely only on inertial sensors and as result drift in time due to errors in the inertial measurement. In this work, we propose WiCHINS, a wheeled and chassis inertial navigation system by combining wheel-mounted-inertial sensors with a chassis-mounted inertial sensor for accurate pure inertial navigation. To that end, we derive a three-stage framework, each with a dedicated extended Kalman filter. This framework utilizes the benefits of each location (wheel/body) during the estimation process. To evaluate our proposed approach, we employed a dataset with five inertial measurement units with a total recording time of 228.6 minutes. We compare our approach with four other inertial baselines and demonstrate an average position error of 11.4m, which is $2.4\%$ of the average traveled distance, using two wheels and one body inertial measurement units. As a consequence, our proposed method enables robust navigation in challenging environments and helps bridge the pure-inertial performance gap.

</details>


### [134] [NMPC-Augmented Visual Navigation and Safe Learning Control for Large-Scale Mobile Robots](https://arxiv.org/abs/2601.00609)
*Mehdi Heydari Shahna,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文提出了一种用于大型移动机器人（LSMR）在易滑地形上导航与控制的综合框架，通过融合视觉定位、非线性模型预测控制、深度神经网络控制和安全监控模块，确保机器人在松散地形上的稳定性和安全性。


<details>
  <summary>Details</summary>
Motivation: 大型移动机器人在松散、未固结的地形上运行时，由于牵引力降低容易发生打滑，影响稳定性和安全性，因此需要一种能够应对易滑地形的鲁棒控制框架。

Method: 框架包含四个模块：（1）视觉位姿估计模块，融合车载传感器和立体相机提供低延迟位姿；（2）高层非线性模型预测控制，修正机器人位姿漂移；（3）低层深度神经网络控制策略，近似轮式驱动机构行为，并结合鲁棒自适应控制处理扰动；（4）对数安全模块，监控整个系统确保安全运行。

Result: 该框架在6000公斤的LSMR上进行了实验验证，低层控制保证了驱动子系统的均匀指数稳定性，安全模块确保了系统级安全，各模块在不同频率下同步运行。

Conclusion: 所提出的综合导航与控制框架能够有效应对易滑地形，通过分层控制和安全监控实现大型移动机器人的鲁棒、稳定和安全操作。

Abstract: A large-scale mobile robot (LSMR) is a high-order multibody system that often operates on loose, unconsolidated terrain, which reduces traction. This paper presents a comprehensive navigation and control framework for an LSMR that ensures stability and safety-defined performance, delivering robust operation on slip-prone terrain by jointly leveraging high-performance techniques. The proposed architecture comprises four main modules: (1) a visual pose-estimation module that fuses onboard sensors and stereo cameras to provide an accurate, low-latency robot pose, (2) a high-level nonlinear model predictive control that updates the wheel motion commands to correct robot drift from the robot reference pose on slip-prone terrain, (3) a low-level deep neural network control policy that approximates the complex behavior of the wheel-driven actuation mechanism in LSMRs, augmented with robust adaptive control to handle out-of-distribution disturbances, ensuring that the wheels accurately track the updated commands issued by high-level control module, and (4) a logarithmic safety module to monitor the entire robot stack and guarantees safe operation. The proposed low-level control framework guarantees uniform exponential stability of the actuation subsystem, while the safety module ensures the whole system-level safety during operation. Comparative experiments on a 6,000 kg LSMR actuated by two complex electro-hydrostatic drives, while synchronizing modules operating at different frequencies.

</details>


### [135] [From 2D to 3D terrain-following area coverage path planning](https://arxiv.org/abs/2601.00614)
*Mogens Plessen*

Main category: cs.RO

TL;DR: 提出了一种三维地形跟随的区域覆盖路径规划算法，可生成相邻路径，在保持固定工作宽度的同时维持特定工作高度，并应用于农业场景验证。


<details>
  <summary>Details</summary>
Motivation: 现有二维覆盖路径规划方法无法适应复杂三维地形，农业机械等需要在起伏地形上保持恒定工作高度和间距，需要开发专门的三维地形跟随算法。

Method: 采用反距离加权法生成均匀间距的高程数据，结合局部搜索算法，生成相邻路径使其同时满足工作宽度间距和地形上方投影高度要求。

Result: 算法成功应用于真实世界农业三维数据，验证了其在三维地形中保持路径间距和高度的有效性，但复杂度高于二维等效算法。

Conclusion: 该三维地形跟随覆盖路径规划算法能有效适应复杂地形，为农业机械等应用提供了可行的三维路径规划解决方案。

Abstract: An algorithm for 3D terrain-following area coverage path planning is presented. Multiple adjacent paths are generated that are (i) locally apart from each other by a distance equal to the working width of a machinery, while (ii) simultaneously floating at a projection distance equal to a specific working height above the terrain. The complexities of the algorithm in comparison to its 2D equivalent are highlighted. These include uniformly spaced elevation data generation using an Inverse Distance Weighting-approach and a local search. Area coverage path planning results for real-world 3D data within an agricultural context are presented to validate the algorithm.

</details>


### [136] [Replaceable Bit-based Gripper for Picking Cluttered Food Items](https://arxiv.org/abs/2601.00305)
*Prashant Kumar,Yukiyasu Domae,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出一种可更换夹爪头的机器人夹爪系统，用于处理杂乱食品的重量分拣，针对鲑鱼子和意大利面设计了专用夹爪头，实现了80%和95%以上的重量分拣精度。


<details>
  <summary>Details</summary>
Motivation: 食品包装行业需要快速处理形状、重量各异的食品，包括易抓取的单件食品和柔性、细长、杂乱的食品，现有系统难以适应这种多样性。

Method: 设计可更换夹爪头的夹爪系统，包含专用食品夹爪头和皮带更换机构，针对鲑鱼子（粘性颗粒食品）和意大利面（细长粘性杂乱食品）开发了专用夹爪头。

Result: 夹爪成功抓取鲑鱼子和意大利面，重量分拣精度分别超过95%和80%，夹爪头更换快速，能处理多种食品。

Conclusion: 可更换夹爪头的夹爪系统能有效处理杂乱食品的重量分拣任务，适应食品包装行业的快速变化需求。

Abstract: The food packaging industry goes through changes in food items and their weights quite rapidly. These items range from easy-to-pick, single-piece food items to flexible, long and cluttered ones. We propose a replaceable bit-based gripper system to tackle the challenge of weight-based handling of cluttered food items. The gripper features specialized food attachments(bits) that enhance its grasping capabilities, and a belt replacement system allows switching between different food items during packaging operations. It offers a wide range of control options, enabling it to grasp and drop specific weights of granular, cluttered, and entangled foods. We specifically designed bits for two flexible food items that differ in shape: ikura(salmon roe) and spaghetti. They represent the challenging categories of sticky, granular food and long, sticky, cluttered food, respectively. The gripper successfully picked up both spaghetti and ikura and demonstrated weight-specific dropping of these items with an accuracy over 80% and 95% respectively. The gripper system also exhibited quick switching between different bits, leading to the handling of a large range of food items.

</details>


### [137] [Space Debris Removal using Nano-Satellites controlled by Low-Power Autonomous Agents](https://arxiv.org/abs/2601.00465)
*Dennis Christmann,Juan F. Gutierrez,Sthiti Padhi,Patrick Plörer,Aditya Takur,Simona Silvestri,Andres Gomez*

Main category: cs.RO

TL;DR: 提出了一种利用自主智能纳米卫星群安全清除太空碎片的方法，通过在无线微控制器上实现自主代理软件，并在专用测试平台上验证其可行性能源效率。


<details>
  <summary>Details</summary>
Motivation: 太空碎片日益增多，威胁卫星和太空旅行的安全运行，需要有效解决方案。

Method: 基于资源受限平台上的自主代理技术，在无线微控制器上实现自主代理软件，并通过专用测试平台进行实验验证。

Result: 实验证明了该方法的可行性和整体能源效率。

Conclusion: 智能自主纳米卫星群为安全清除太空碎片提供了一种可行的简化方案。

Abstract: Space debris is an ever-increasing problem in space travel. There are already many old, no longer functional spacecraft and debris orbiting the earth, which endanger both the safe operation of satellites and space travel. Small nano-satellite swarms can address this problem by autonomously de-orbiting debris safely into the Earth's atmosphere. This work builds on the recent advances of autonomous agents deployed in resource-constrained platforms and shows a first simplified approach how such intelligent and autonomous nano-satellite swarms can be realized. We implement our autonomous agent software on wireless microcontrollers and perform experiments on a specialized test-bed to show the feasibility and overall energy efficiency of our approach.

</details>


### [138] [Variable Elimination in Hybrid Factor Graphs for Discrete-Continuous Inference & Estimation](https://arxiv.org/abs/2601.00545)
*Varun Agrawal,Frank Dellaert*

Main category: cs.RO

TL;DR: 提出了一种高效的混合因子图框架和变量消除算法，用于同时处理连续和离散变量的精确最大后验估计与边缘化，并在具有模糊测量的SLAM数据集中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 机器人学中的混合问题同时涉及连续和离散变量，现有方法多基于近似求解，缺乏精确的建模与推断框架。

Method: 1. 设计新型混合高斯因子连接离散与连续变量；2. 提出混合条件分布表示离散变量条件下的多连续假设；3. 基于条件线性高斯模型推导混合变量消除算法，生成混合贝叶斯网络；4. 采用树结构因子表示结合剪枝与概率分配策略控制离散假设数量。

Result: 在具有模糊测量的SLAM数据集中，该方法能准确处理离散测量选择问题，展示了框架的精确性、通用性和简洁性。

Conclusion: 所提混合因子图框架实现了对混合问题的精确推断，通过结构化表示与剪枝策略保证了计算可行性，为机器人学中的混合估计问题提供了有效解决方案。

Abstract: Many hybrid problems in robotics involve both continuous and discrete components, and modeling them together for estimation tasks has been a long standing and difficult problem. Hybrid Factor Graphs give us a mathematical framework to model these types of problems, however existing approaches for solving them are based on approximations. In this work, we propose an efficient Hybrid Factor Graph framework alongwith a variable elimination algorithm to produce a hybrid Bayes network, which can then be used for exact Maximum A Posteriori estimation and marginalization over both sets of variables. Our approach first develops a novel hybrid Gaussian factor which can connect to both discrete and continuous variables, and a hybrid conditional which can represent multiple continuous hypotheses conditioned on the discrete variables. Using these representations, we derive the process of hybrid variable elimination under the Conditional Linear Gaussian scheme, giving us exact posteriors as hybrid Bayes network. To bound the number of discrete hypotheses, we use a tree-structured representation of the factors coupled with a simple pruning and probabilistic assignment scheme, which allows for tractable inference. We demonstrate the applicability of our framework on a SLAM dataset with ambiguous measurements, where discrete choices for the most likely measurement have to be made. Our demonstrated results showcase the accuracy, generality, and simplicity of our hybrid factor graph framework.

</details>


### [139] [LLM-Based Agentic Exploration for Robot Navigation & Manipulation with Skill Orchestration](https://arxiv.org/abs/2601.00555)
*Abu Hanif Muhammad Syarubany,Farhan Zaki Rahmani,Trio Widianto*

Main category: cs.RO

TL;DR: 本文提出了一种基于LLM的端到端机器人探索系统，用于室内购物任务，通过在Gazebo仿真和真实走廊环境中验证，实现了从自然语言指令到多店铺导航和物品抓取的全流程执行。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种模块化、可调试的机器人系统，能够理解自然语言购物请求，并在未知室内环境中自主探索、导航并完成物品检索任务。

Method: 系统采用轻量级语义地图构建方法，通过检测路口标识牌并存储方向-兴趣点关系；利用AprilTags作为可重复定位锚点；LLM生成离散动作决策；ROS有限状态主控制器调用模块化运动基元（如避障、接近标签、进店、抓取）执行任务。

Result: 定性实验表明，该系统能够从用户指令出发，完成端到端的多店铺导航与物品检索任务，同时保持模块化设计和基于文本地图与决策日志的可调试性。

Conclusion: 该研究验证了LLM驱动、语义地图增强的机器人系统在复杂室内任务中的可行性，为可解释、可扩展的自主探索提供了实用框架。

Abstract: This paper presents an end-to-end LLM-based agentic exploration system for an indoor shopping task, evaluated in both Gazebo simulation and a corresponding real-world corridor layout. The robot incrementally builds a lightweight semantic map by detecting signboards at junctions and storing direction-to-POI relations together with estimated junction poses, while AprilTags provide repeatable anchors for approach and alignment. Given a natural-language shopping request, an LLM produces a constrained discrete action at each junction (direction and whether to enter a store), and a ROS finite-state main controller executes the decision by gating modular motion primitives, including local-costmap-based obstacle avoidance, AprilTag approaching, store entry, and grasping. Qualitative results show that the integrated stack can perform end-to-end task execution from user instruction to multi-store navigation and object retrieval, while remaining modular and debuggable through its text-based map and logged decision history.

</details>


### [140] [Priority-Aware Multi-Robot Coverage Path Planning](https://arxiv.org/abs/2601.00580)
*Kanghoon Lee,Hyeonjun Kim,Jiachen Li,Jinkyoo Park*

Main category: cs.RO

TL;DR: 本文提出了一种优先级感知的多机器人覆盖路径规划方法（PA-MCPP），通过两阶段框架优化优先级区域的加权延迟和总完成时间，相比传统方法显著提升了优先级区域的覆盖效率。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人覆盖路径规划方法假设环境区域重要性均匀，无法有效处理需要优先覆盖的关键区域，限制了在紧急响应、灾害监测等场景中的应用效果。

Method: 采用两阶段框架：第一阶段通过贪心区域分配与局部搜索、生成树路径规划；第二阶段利用斯坦纳树引导剩余区域覆盖，实现优先级区域的高效覆盖。

Result: 实验表明该方法在不同场景下显著降低了优先级加权延迟，同时保持竞争力的总完成时间；敏感性分析验证了方法在机器人数量扩展和优先级权重调整方面的良好可扩展性与可控性。

Conclusion: PA-MCPP框架有效解决了优先级区域覆盖问题，通过权衡延迟与完成时间实现了更符合实际需求的机器人协同覆盖，为应急响应等场景提供了实用解决方案。

Abstract: Multi-robot systems are widely used for coverage tasks that require efficient coordination across large environments. In Multi-Robot Coverage Path Planning (MCPP), the objective is typically to minimize the makespan by generating non-overlapping paths for full-area coverage. However, most existing methods assume uniform importance across regions, limiting their effectiveness in scenarios where some zones require faster attention. We introduce the Priority-Aware MCPP (PA-MCPP) problem, where a subset of the environment is designated as prioritized zones with associated weights. The goal is to minimize, in lexicographic order, the total priority-weighted latency of zone coverage and the overall makespan. To address this, we propose a scalable two-phase framework combining (1) greedy zone assignment with local search, spanning-tree-based path planning, and (2) Steiner-tree-guided residual coverage. Experiments across diverse scenarios demonstrate that our method significantly reduces priority-weighted latency compared to standard MCPP baselines, while maintaining competitive makespan. Sensitivity analyses further show that the method scales well with the number of robots and that zone coverage behavior can be effectively controlled by adjusting priority weights.

</details>


### [141] [Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework](https://arxiv.org/abs/2601.00610)
*Mehdi Heydari Shahna,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出一个用于大型机器人的安全目标到达控制框架，通过模块化设计结合强化学习规划、视觉姿态估计、自适应控制和数学安全监督器，在复杂地形上实现稳定安全的操作。


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人应用中需要大量探索状态-动作空间，可能导致不安全行为，限制了其在复杂地形上大型机器人的应用，因此需要设计一个安全的目标到达控制框架。

Method: 将系统分解为五个紧密耦合的功能模块：1) 实时视觉姿态估计提供准确状态；2) 强化学习运动规划器生成平滑运动指令；3) 监督深度学习模型捕获机器人复杂动力学；4) 基于模型的鲁棒自适应控制器确保轮子跟踪指令；5) 数学安全监督器监控机器人安全。

Result: 提出的框架保证了驱动系统的一致指数稳定性和整个操作的安全性，在6000公斤机器人上的不同场景实验中验证了有效性。

Conclusion: 通过模块化集成多种技术，该框架能够安全可靠地控制大型机器人在不稳定地形上完成目标到达任务，减少了人工干预需求。

Abstract: Reinforcement learning (RL) is effective in many robotic applications, but it requires extensive exploration of the state-action space, during which behaviors can be unsafe. This significantly limits its applicability to large robots with complex actuators operating on unstable terrain. Hence, to design a safe goal-reaching control framework for large-scale robots, this paper decomposes the whole system into a set of tightly coupled functional modules. 1) A real-time visual pose estimation approach is employed to provide accurate robot states to 2) an RL motion planner for goal-reaching tasks that explicitly respects robot specifications. The RL module generates real-time smooth motion commands for the actuator system, independent of its underlying dynamic complexity. 3) In the actuation mechanism, a supervised deep learning model is trained to capture the complex dynamics of the robot and provide this model to 4) a model-based robust adaptive controller that guarantees the wheels track the RL motion commands even on slip-prone terrain. 5) Finally, to reduce human intervention, a mathematical safety supervisor monitors the robot, stops it on unsafe faults, and autonomously guides it back to a safe inspection area. The proposed framework guarantees uniform exponential stability of the actuation system and safety of the whole operation. Experiments on a 6,000 kg robot in different scenarios confirm the effectiveness of the proposed framework.

</details>


### [142] [RoboReward: General-Purpose Vision-Language Reward Models for Robotics](https://arxiv.org/abs/2601.00675)
*Tony Lee,Andrew Wagenmaker,Karl Pertsch,Percy Liang,Sergey Levine,Chelsea Finn*

Main category: cs.RO

TL;DR: 本文提出了RoboReward数据集和基准，用于评估视觉语言模型作为机器人任务奖励模型的能力，并训练了优于现有大型模型的4B/8B参数奖励模型，在真实机器人强化学习中取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 在真实机器人领域，获取有效的奖励函数通常需要费时的人工标注或脆硬的手工设计目标。视觉语言模型虽有望作为自动奖励模型，但其在真实机器人任务中的有效性尚未得到充分验证。

Method: 1) 构建基于Open X-Embodiment和RoboArena大规模真实机器人数据的RoboReward数据集和基准；2) 提出负样本数据增强流程，通过反事实重标注成功片段和时间裁剪生成校准的负样本和接近失败样本；3) 训练4B和8B参数的视觉语言奖励模型。

Result: 1) 评估显示现有视觉语言模型在所有任务中均未表现优异；2) 训练的4B/8B参数模型在短视界机器人任务奖励分配上优于更大规模的视觉语言模型；3) 8B参数奖励模型在真实机器人强化学习中大幅优于Gemini Robotics-ER 1.5，显著缩小了与人工提供奖励的强化学习之间的差距。

Conclusion: 视觉语言模型作为机器人奖励模型具有潜力但仍有改进空间，通过专门的数据集构建和模型训练，可以开发出在真实机器人强化学习中有效的奖励模型，为自动化奖励设计提供了新途径。

Abstract: A well-designed reward is critical for effective reinforcement learning-based policy improvement. In real-world robotic domains, obtaining such rewards typically requires either labor-intensive human labeling or brittle, handcrafted objectives. Vision-language models (VLMs) have shown promise as automatic reward models, yet their effectiveness on real robot tasks is poorly understood. In this work, we aim to close this gap by introducing (1) \textbf{RoboReward}, a robotics reward dataset and benchmark built on large-scale real-robot corpora from Open X-Embodiment (OXE) and RoboArena, and (2) vision-language reward models trained on this dataset (RoboReward 4B/8B). Because OXE is success-heavy and lacks failure examples, we propose a \emph{negative examples data augmentation} pipeline that generates calibrated \emph{negatives} and \emph{near-misses} via counterfactual relabeling of successful episodes and temporal clipping to create partial-progress outcomes from the same videos. Using this framework, we produce an extensive training and evaluation dataset that spans diverse tasks and embodiments and enables systematic evaluation of whether state-of-the-art VLMs can reliably provide rewards for robotics. Our evaluation of leading open-weight and proprietary VLMs reveals that no model excels across all tasks, underscoring substantial room for improvement. We then train general-purpose 4B- and 8B-parameter models that outperform much larger VLMs in assigning rewards for short-horizon robotic tasks. Finally, we deploy the 8B-parameter reward VLM in real-robot reinforcement learning and find that it improves policy learning over Gemini Robotics-ER 1.5, a frontier physical reasoning VLM trained on robotics data, by a large margin, while substantially narrowing the gap to RL training with human-provided rewards.

</details>


### [143] [DefVINS: Visual-Inertial Odometry for Deformable Scenes](https://arxiv.org/abs/2601.00702)
*Samuel Cerezo,Javier Civera*

Main category: cs.RO

TL;DR: 提出DefVINS视觉惯性里程计框架，通过嵌入变形图分离刚性运动与非刚性变形，利用惯性测量约束刚性运动并渐进激活非刚性自由度，提升非刚性环境下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统视觉惯性里程计基于刚性假设，在可变形场景中容易过度拟合局部非刚性运动或产生严重漂移，需要解决变形场景下的运动估计问题。

Method: 1. 使用标准VIO初始化固定重力、速度和IMU偏差；2. 通过嵌入变形图表示非刚性变形；3. 渐进激活非刚性自由度；4. 进行可观测性分析指导激活策略；5. 采用IMU锚定和基于条件的激活机制。

Result: 消融实验表明，结合惯性约束与可观测性感知的变形激活策略，在非刚性环境下显著提升了系统的鲁棒性。

Conclusion: DefVINS框架通过显式分离刚性与非刚性运动分量，并利用惯性测量约束和渐进激活策略，有效解决了可变形场景下的视觉惯性里程计问题。

Abstract: Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.

</details>


### [144] [Calling for Backup: How Children Navigate Successive Robot Communication Failures](https://arxiv.org/abs/2601.00754)
*Maria Teresa Parreira,Isabel Neto,Filipa Rocha,Wendy Ju*

Main category: cs.RO

TL;DR: 本研究探索了儿童对机器人重复错误的反应，发现儿童在调整提示和情绪表达上与成人相似，但表现出更多脱离互动的行为，且错误不影响他们对机器人的感知。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要关注成人对机器人连续错误的反应，儿童对此的反应尚不明确，因此本研究旨在填补这一空白，以改进面向儿童的人机交互系统设计。

Method: 研究复制了Liu等人的连续机器人失败范式，让59名8-10岁儿童与机器人互动，机器人连续三次未能理解他们的提示，通过视频记录和分析儿童的行为反应。

Result: 儿童在调整提示、改变语调和情绪性非语言反应上与成人相似，但表现出更多脱离行为（如忽略机器人或寻求成人帮助）；错误未影响儿童对机器人的感知，表明儿童对对话期望更灵活。

Conclusion: 儿童对机器人错误的反应与成人存在差异，这为设计更有效和适合儿童发展的人机交互系统提供了依据。

Abstract: How do children respond to repeated robot errors? While prior research has examined adult reactions to successive robot errors, children's responses remain largely unexplored. In this study, we explore children's reactions to robot social errors and performance errors. For the latter, this study reproduces the successive robot failure paradigm of Liu et al. with child participants (N=59, ages 8-10) to examine how young users respond to repeated robot conversational errors. Participants interacted with a robot that failed to understand their prompts three times in succession, with their behavioral responses video-recorded and analyzed. We found both similarities and differences compared to adult responses from the original study. Like adults, children adjusted their prompts, modified their verbal tone, and exhibited increasingly emotional non-verbal responses throughout successive errors. However, children demonstrated more disengagement behaviors, including temporarily ignoring the robot or actively seeking an adult. Errors did not affect participants' perception of the robot, suggesting more flexible conversational expectations in children. These findings inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [145] [Impact of Clustering on the Observability and Controllability of Complex Networks](https://arxiv.org/abs/2601.00221)
*Mohammadreza Doostmohammadian,Hamid R. Rabiee*

Main category: eess.SY

TL;DR: 本文研究了聚类对复杂无标度网络可观测性和可控性的影响，发现密集聚类网络需要更少的驱动和观测节点，为资源受限的网络设计提供了优化思路。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统日益复杂和互联，无标度网络能很好模拟这些系统，但网络聚类如何影响其可观测性和可控性尚不清楚，这对社交网络和智能交通等应用中的网络设计优化具有重要意义。

Method: 基于结构化系统理论框架，首先量化网络可观测性/可控性需求，然后通过蒙特卡洛模拟和不同案例研究分析聚类对这些指标的影响。

Result: 研究发现密集聚类网络由于簇内信息传播更好，需要更少的驱动节点和观测节点，这有助于在资源受限设置中优化传感器/执行器布置。

Conclusion: 这项工作增进了对网络可观测性/可控性的理解，提出了通过改变网络结构和聚类来改善这些特性的技术，为实际网络设计提供了实用见解。

Abstract: The increasing complexity and interconnectedness of systems across various fields have led to a growing interest in studying complex networks, particularly Scale-Free (SF) networks, which best model real-world systems. This paper investigates the influence of clustering on the observability and controllability of complex SF networks, framing these characteristics in the context of structured systems theory. In this paper, we show that densely clustered networks require fewer driver and observer nodes due to better information propagation within clusters. This relationship is of interest for optimizing network design in applications such as social networks and intelligent transportation systems. We first quantify the network observability/controllability requirements, and then, through Monte-Carlo simulations and different case studies, we show how clustering affects these metrics. Our findings offer practical insights into reducing control and observer nodes for sensor/actuator placement, particularly in resource-constrained setups. This work contributes to the understanding of network observability/controllability and presents techniques for improving these features through alterations in network structure and clustering.

</details>


### [146] [Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective](https://arxiv.org/abs/2601.00257)
*Aly Sabri Abdalla,Vuk Marojevic*

Main category: eess.SY

TL;DR: 提出了一种基于O-RAN的低空经济框架，通过语义感知rApp和强化学习xApp实现无人机集群的实时轨迹规划，并探讨了相关测试平台和研究挑战。


<details>
  <summary>Details</summary>
Motivation: 当前低空经济应用（如无人机物流、应急响应）在复杂信号受限环境中缺乏实时、弹性、情境感知的协同机制，且缺乏专门针对低空经济任务的人工智能集成。

Method: 采用开放无线接入网络（O-RAN）架构，结合解耦的RAN结构、开放接口和RAN智能控制器（RICs），设计语义感知rApp作为地形解释器，为基于强化学习的xApp提供语义指导，实现实时轨迹规划。

Result: 验证了所提架构在实现闭环、AI优化和任务关键型低空经济操作方面的可行性和性能，并总结了可用于低空经济研究的无人机测试平台能力。

Conclusion: 该O-RAN赋能框架为低空经济任务提供了有效的协同解决方案，同时指出了未来研究的关键挑战和标准化需求。

Abstract: Despite the growing interest in low-altitude economy (LAE) applications, including UAV-based logistics and emergency response, fundamental challenges remain in orchestrating such missions over complex, signal-constrained environments. These include the absence of real-time, resilient, and context-aware orchestration of aerial nodes with limited integration of artificial intelligence (AI) specialized for LAE missions. This paper introduces an open radio access network (O-RAN)-enabled LAE framework that leverages seamless coordination between the disaggregated RAN architecture, open interfaces, and RAN intelligent controllers (RICs) to facilitate closed-loop, AI-optimized, and mission-critical LAE operations. We evaluate the feasibility and performance of the proposed architecture via a semantic-aware rApp that acts as a terrain interpreter, offering semantic guidance to a reinforcement learning-enabled xApp, which performs real-time trajectory planning for LAE swarm nodes. We survey the capabilities of UAV testbeds that can be leveraged for LAE research, and present critical research challenges and standardization needs.

</details>


### [147] [Safety for Weakly-Hard Control Systems via Graph-Based Barrier Functions](https://arxiv.org/abs/2601.00494)
*Marc Seidel,Mahathi Anand,Frank Allgöwer*

Main category: eess.SY

TL;DR: 该论文提出了一种基于图屏障函数的安全验证与控制器综合方法，用于处理受弱硬约束（窗口内故障次数有界）影响的网络控制系统，通过约束重构降低保守性并提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 安全关键工程应用中普遍存在通信丢包和计算超时等故障，导致系统进入开环运行状态，严重影响系统安全性，需要针对此类弱硬约束系统开发可靠的安全保障方法。

Method: 提出图屏障函数新概念，针对弱硬约束系统建立安全约束条件；通过约束重构降低方法保守性并提升计算可行性；结合数值案例验证方法有效性。

Result: 所提出的图屏障函数方法能为存在通信故障的系统提供安全保证；约束重构策略在保守性与计算效率间取得平衡；案例研究表明该方法在实际控制问题中具有良好效果。

Conclusion: 基于图屏障函数的框架能有效解决弱硬约束下的安全验证与控制器综合问题，通过优化约束形式在保证安全性的同时提升了计算可行性，为实际工程应用提供了新工具。

Abstract: Despite significant advancement in technology, communication and computational failures are still prevalent in safety-critical engineering applications. Often, networked control systems experience packet dropouts, leading to open-loop behavior that significantly affects the behavior of the system. Similarly, in real-time control applications, control tasks frequently experience computational overruns and thus occasionally no new actuator command is issued. This article addresses the safety verification and controller synthesis problem for a class of control systems subject to weakly-hard constraints, i.e., a set of window-based constraints where the number of failures are bounded within a given time horizon. The results are based on a new notion of graph-based barrier functions that are specifically tailored to the considered system class, offering a set of constraints whose satisfaction leads to safety guarantees despite communication failures. Subsequent reformulations of the safety constraints are proposed to alleviate conservatism and improve computational tractability, and the resulting trade-offs are discussed. Finally, several numerical case studies demonstrate the effectiveness of the proposed approach.

</details>


### [148] [Probability-Aware Parking Selection](https://arxiv.org/abs/2601.00521)
*Cameron Hickert,Sirui Li,Zhengbing He,Cathy Wu*

Main category: eess.SY

TL;DR: 本文提出了一种概率感知的停车选择问题框架，通过动态规划帮助驾驶员选择最佳停车位置而非直接导航至目的地，考虑了停车位可用性的不确定性，实验显示该方法能显著减少停车搜索时间。


<details>
  <summary>Details</summary>
Motivation: 现有停车导航系统低估总出行时间，因为它们忽略了寻找停车位的时间，这影响了用户体验、出行方式选择、交通拥堵和排放。

Method: 提出了一个可适应的动态规划框架，基于停车场级别的概率可用性信息进行决策；通过闭式分析确定何时应选择特定停车场或探索其他选项；利用真实世界数据（美国西雅图）进行实验和模拟。

Result: 实验表明，随着观测频率增加，平均绝对误差从7%降至2%以下；概率感知策略相比无概率基线节省了高达66%的时间，但仍比直接到目的地的估计时间多出123%。

Conclusion: 概率感知停车选择模型能有效应对停车可用性的动态变化，减少停车搜索时间，但实际出行时间仍显著高于理想化的直接导航估计，突显了停车搜索时间在出行规划中的重要性。

Abstract: Current parking navigation systems often underestimate total travel time by failing to account for the time spent searching for a parking space, which significantly affects user experience, mode choice, congestion, and emissions. To address this issue, this paper introduces the probability-aware parking selection problem, which aims to direct drivers to the best parking location rather than straight to their destination. An adaptable dynamic programming framework is proposed for decision-making based on probabilistic information about parking availability at the parking lot level. Closed-form analysis determines when it is optimal to target a specific parking lot or explore alternatives, as well as the expected time cost. Sensitivity analysis and three illustrative cases are examined, demonstrating the model's ability to account for the dynamic nature of parking availability. Acknowledging the financial costs of permanent sensing infrastructure, the paper provides analytical and empirical assessments of errors incurred when leveraging stochastic observations to estimate parking availability. Experiments with real-world data from the US city of Seattle indicate this approach's viability, with mean absolute error decreasing from 7% to below 2% as observation frequency grows. In data-based simulations, probability-aware strategies demonstrate time savings up to 66% relative to probability-unaware baselines, yet still take up to 123% longer than direct-to-destination estimates.

</details>


### [149] [Impact Assessment of Heterogeneous Grid Support Functions in Smart Inverter Deployments](https://arxiv.org/abs/2601.00289)
*S. Gokul Krishnan,Mohd. Asim Aftab,Nabil Mohammed,Shehab Ahmed,Charalambos Konstantinou*

Main category: eess.SY

TL;DR: 本文评估了分布式能源中智能逆变器不同控制模式（恒功率因数、伏安、伏瓦）在配电网中的动态交互影响，考虑了电阻性和电感性馈线类型，并通过实时仿真验证。


<details>
  <summary>Details</summary>
Motivation: 随着光伏等分布式能源在低压配电网中渗透率提高，智能逆变器自主运行可能引发控制模式间的负面交互，影响电网稳定性和效率，而现有研究对异构逆变器群组协同控制的系统级影响分析不足。

Method: 采用实时仿真平台Opal-RT模拟CIRGE低压配电网，对比分析恒功率因数、伏安、伏瓦三种控制模式在电阻性和电感性馈线中的动态交互行为。

Result: 研究表明，不同控制模式的智能逆变器群组在电网中会产生复杂的动态交互，其影响程度受馈线类型（电阻性/电感性）和控制策略差异的显著影响。

Conclusion: 智能逆变器的异构控制模式交互可能威胁电网稳定性，需在标准制定和系统规划中考虑协调控制策略，实时仿真为评估实际电网条件下的交互影响提供了有效手段。

Abstract: The decarbonization of the energy sector has led to a significant high penetration of distributed energy resources (DERs), particularly photovoltaic (PV) systems, in low-voltage (LV) distribution networks. To maintain grid stability, recent standards (e.g., IEEE 1547-2018) mandate DERs to provide grid-support functionalities through smart inverters (SIs), which typically operate autonomously based on local measurements. However, as DER penetration increases, uncoordinated control modes of SIs can lead to adverse interactions, compromising system efficiency, voltage regulation, and overall stability. While previous studies have demonstrated the benefits of coordinated inverter control and optimal dispatch strategies, the system-wide impacts of heterogeneous SI groups operating under different control modes remain largely unexamined. This paper addresses this gap by assessing the dynamic interactions among multiple SI groups with varying control strategies, namely: Constant Power Factor (CPF), Volt-VAR, and Volt-Watt modes. Furthermore, the analysis covers both resistive and inductive feeder types. The validation is performed using a real-time setup. The CIRGE low-voltage (LV) distribution network is simulated in the Opal-RT platform as the test network, enabling realistic and high-fidelity evaluation of SI control interactions under practical grid conditions.

</details>


### [150] [Optimal Transport-Based Decentralized Multi-Agent Distribution Matching](https://arxiv.org/abs/2601.00548)
*Kooktae Lee*

Main category: eess.SY

TL;DR: 提出了一种多智能体系统中分布匹配的分散式控制框架，通过最优传输理论实现规定的终端空间分布，仅需局部信息即可运行。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统需要实现规定的终端空间分布，但传统方法需要全局信息或集中式计算，难以在通信受限的分散式环境中有效运行。

Method: 使用Wasserstein距离作为分布差异度量，将全局最优传输问题重构为可处理的单智能体决策过程，引入顺序权重更新规则构建局部传输计划，并采用基于记忆的校正机制应对间歇性通信。

Result: 建立了收敛保证，在线性和非线性智能体动力学下均能实现替代传输成本的循环改进，仿真表明该框架能有效、可扩展地实现分布匹配。

Conclusion: 所提出的分散式框架能够在仅使用局部信息的条件下，可靠地实现多智能体系统的分布匹配目标，适用于通信受限的实际场景。

Abstract: This paper presents a decentralized control framework for distribution matching in multi-agent systems (MAS), where agents collectively achieve a prescribed terminal spatial distribution. The problem is formulated using optimal transport (Wasserstein distance), which provides a principled measure of distributional discrepancy and serves as the basis for the control design. To avoid solving the global optimal transport problem directly, the distribution-matching objective is reformulated into a tractable per-agent decision process, enabling each agent to identify its desired terminal locations using only locally available information. A sequential weight-update rule is introduced to construct feasible local transport plans, and a memory-based correction mechanism is incorporated to maintain reliable operation under intermittent and range-limited communication. Convergence guarantees are established, showing cycle-wise improvement of a surrogate transport cost under both linear and nonlinear agent dynamics. Simulation results demonstrate that the proposed framework achieves effective and scalable distribution matching while operating fully in a decentralized manner.

</details>


### [151] [Stability Verification for Switched Systems using Neural Multiple Lyapunov Functions](https://arxiv.org/abs/2601.00587)
*Junyue Huang,Shaoyuan Li,Xiang Yin*

Main category: eess.SY

TL;DR: 本文提出了一种结合神经网络与多重李雅普诺夫函数的统一框架（NMLF），用于分析状态依赖切换的切换系统稳定性，并通过CEGIS训练保证理论严谨性。


<details>
  <summary>Details</summary>
Motivation: 切换系统因非线性动态和切换信号导致稳定性分析困难，传统多重李雅普诺夫函数方法在缺乏良好结构时计算受限，需结合神经网络的计算优势与理论保证。

Method: 提出神经多重李雅普诺夫函数（NMLF）框架，设计定制化损失函数，采用反例引导归纳合成（CEGIS）方案训练神经网络，使其严格满足多重李雅普诺夫函数条件。

Result: 通过仿真与理论分析验证了NMLF的有效性，表明该方法能兼顾计算效率与理论严谨性，适用于复杂切换系统的稳定性分析。

Conclusion: NMLF为状态依赖切换系统提供了可实际部署的稳定性分析框架，融合了神经网络的计算能力与传统稳定性理论的可靠性。

Abstract: Stability analysis of switched systems, characterized by multiple operational modes and switching signals, is challenging due to their nonlinear dynamics. While frameworks such as multiple Lyapunov functions (MLF) provide a foundation for analysis, their computational applicability is limited for systems without favorable structure. This paper investigates stability analysis for switched systems under state-dependent switching conditions. We propose neural multiple Lyapunov functions (NMLF), a unified framework that combines the theoretical guarantees of MLF with the computational efficiency of neural Lyapunov functions (NLF). Our approach leverages a set of tailored loss functions and a counter-example guided inductive synthesis (CEGIS) scheme to train neural networks that rigorously satisfy MLF conditions. Through comprehensive simulations and theoretical analysis, we demonstrate NMLF's effectiveness and its potential for practical deployment in complex switched systems.

</details>


### [152] [A formal theory on problem space as a semantic world model in systems engineering](https://arxiv.org/abs/2601.00755)
*Mayuranath SureshKumar,Hanumanthrao Kannan*

Main category: eess.SY

TL;DR: 本文提出了一种形式化的问题空间理论，将系统工程中的问题空间建模为包含先于需求和解决方案定义的理论构造的显式语义世界模型，以区分问题域事实与解决方案选择。


<details>
  <summary>Details</summary>
Motivation: 当前系统工程实践中，推理常直接从利益相关者目标跳转到规范性工件，导致关于操作环境、可接受交互和上下文条件的基本假设被隐含或过早嵌入架构或需求中，缺乏对问题空间本身的严格系统理论表示。

Method: 通过形式化问题空间为显式语义世界模型，定义先于需求和解决方案承诺的理论构造，并建立公理、定理和推论，为无歧义边界语义、上下文依赖交互可追溯性以及问题空间规范充分性提供严格准则。

Result: 建立了能够支持独立于解决方案设计的严格推理的问题空间规范理论，明确区分问题域事实与解决方案选择，并通过假设案例研究展示了该理论在问题框架设计前的指导作用。

Conclusion: 该理论为系统工程提供了严格的问题空间表示方法，使实践者能够在设计规范性工件前进行系统化问题框架，增强问题空间与解决方案空间的分离，提高工程推理的严谨性和可追溯性。

Abstract: Classic problem-space theory models problem solving as a navigation through a structured space of states, operators, goals, and constraints. Systems Engineering (SE) employs analogous constructs (functional analysis, operational analysis, scenarios, trade studies), yet still lacks a rigorous systems-theoretic representation of the problem space itself. In current practice, reasoning often proceeds directly from stakeholder goals to prescriptive artifacts. This makes foundational assumptions about the operational environment, admissible interactions, and contextual conditions implicit or prematurely embedded in architectures or requirements. This paper addresses that gap by formalizing the problem space as an explicit semantic world model containing theoretical constructs that are defined prior to requirements and solution commitments. These constructs along with the developed axioms, theorems and corollary establish a rigorous criterion for unambiguous boundary semantics, context-dependent interaction traceability to successful stakeholder goal satisfaction, and sufficiency of problem-space specification over which disciplined reasoning can occur independent of solution design. It offers a clear distinction between what is true of the problem domain and what is chosen as a solution. The paper concludes by discussing the significance of the theory on practitioners and provides a dialogue-based hypothetical case study between a stakeholder and an engineer, demonstrating how the theory guides problem framing before designing any prescriptive artifacts.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [153] [Deep Learning Approach for the Diagnosis of Pediatric Pneumonia Using Chest X-ray Imaging](https://arxiv.org/abs/2601.00041)
*Fatemeh Hosseinabadi,Mohammad Mojtaba Rohani*

Main category: eess.IV

TL;DR: 本研究评估了三种CNN架构（ResNetRS、RegNet、EfficientNetV2）在儿童胸部X光片肺炎自动分类中的性能，发现RegNet表现最佳。


<details>
  <summary>Details</summary>
Motivation: 儿童肺炎是全球儿童发病和死亡的主要原因，及时准确诊断面临放射学专业知识有限以及儿童影像生理和程序复杂性的挑战。

Method: 从公开数据集中提取1000张儿童胸部X光图像，进行预处理和二元分类标注；使用预训练的ImageNet权重对三种CNN架构进行微调，基于准确率和灵敏度进行评估。

Result: RegNet分类性能最高，准确率92.4%，灵敏度90.1%；ResNetRS准确率91.9%，灵敏度89.3%；EfficientNetV2准确率88.5%，灵敏度88.1%。

Conclusion: RegNet在儿童肺炎X光图像自动分类中表现最优，展示了深度学习模型辅助儿童肺炎诊断的潜力。

Abstract: Pediatric pneumonia remains a leading cause of morbidity and mortality in children worldwide. Timely and accurate diagnosis is critical but often challenged by limited radiological expertise and the physiological and procedural complexity of pediatric imaging. This study investigates the performance of state-of-the-art convolutional neural network (CNN) architectures ResNetRS, RegNet, and EfficientNetV2 using transfer learning for the automated classification of pediatric chest Xray images as either pneumonia or normal.A curated subset of 1,000 chest X-ray images was extracted from a publicly available dataset originally comprising 5,856 pediatric images. All images were preprocessed and labeled for binary classification. Each model was fine-tuned using pretrained ImageNet weights and evaluated based on accuracy and sensitivity. RegNet achieved the highest classification performance with an accuracy of 92.4 and a sensitivity of 90.1, followed by ResNetRS (accuracy: 91.9, sensitivity: 89.3) and EfficientNetV2 (accuracy: 88.5, sensitivity: 88.1).

</details>


### [154] [Hear the Heartbeat in Phases: Physiologically Grounded Phase-Aware ECG Biometrics](https://arxiv.org/abs/2601.00170)
*Jintao Huang,Lu Leng,Yi Zhang,Ziyuan Yang*

Main category: eess.IV

TL;DR: 提出了一种用于心电图身份认证的分层相位感知融合框架，通过三阶段设计避免特征纠缠，并引入多原型注册策略，在公开数据集上取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有心电图身份认证方法将心跳视为同质信号，忽略了心脏周期内不同阶段的特异性特征，导致信息利用不充分。

Method: 1. 分层相位感知融合框架：包括相位内表征提取、相位分组层次融合和全局表征融合三个阶段；2. 心跳感知多原型注册策略：构建多原型模板集以减少心跳特异性噪声影响。

Result: 在三个公开数据集上的实验表明，该方法在闭集和开集设置下均优于其他对比方法，达到了最先进的性能水平。

Conclusion: 通过显式建模心脏相位特异性特征并采用结构化融合策略，能有效提升心电图身份认证的准确性和鲁棒性，多原型注册策略进一步增强了系统稳定性。

Abstract: Electrocardiography (ECG) is adopted for identity authentication in wearable devices due to its individual-specific characteristics and inherent liveness. However, existing methods often treat heartbeats as homogeneous signals, overlooking the phase-specific characteristics within the cardiac cycle. To address this, we propose a Hierarchical Phase-Aware Fusion~(HPAF) framework that explicitly avoids cross-feature entanglement through a three-stage design. In the first stage, Intra-Phase Representation (IPR) independently extracts representations for each cardiac phase, ensuring that phase-specific morphological and variation cues are preserved without interference from other phases. In the second stage, Phase-Grouped Hierarchical Fusion (PGHF) aggregates physiologically related phases in a structured manner, enabling reliable integration of complementary phase information. In the final stage, Global Representation Fusion (GRF) further combines the grouped representations and adaptively balances their contributions to produce a unified and discriminative identity representation. Moreover, considering ECG signals are continuously acquired, multiple heartbeats can be collected for each individual. We propose a Heartbeat-Aware Multi-prototype (HAM) enrollment strategy, which constructs a multi-prototype gallery template set to reduce the impact of heartbeat-specific noise and variability. Extensive experiments on three public datasets demonstrate that HPAF achieves state-of-the-art results in the comparison with other methods under both closed and open-set settings.

</details>


### [155] [Let Distortion Guide Restoration (DGR): A physics-informed learning framework for Prostate Diffusion MRI](https://arxiv.org/abs/2601.00226)
*Ziyang Long,Binesh Nader,Lixia Wang,Archana Vadiraj Malaji,Chia-Chi Yang,Haoran Sun,Rola Saouaf,Timothy Daskivich,Hyung Kim,Yibin Xie,Debiao Li,Hsin-Jung Yang*

Main category: eess.IV

TL;DR: 提出DGR框架，通过物理模拟的正向失真模型和混合CNN-扩散方法，无需额外采集即可校正前列腺DWI中的严重磁敏感伪影，在合成和真实临床数据上均优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 单次激发EPI DWI在前列腺成像中易受磁敏感伪影影响，传统校正方法（如TOPUP/FUGUE）需要额外采集数据且对严重失真效果有限，需开发不依赖额外采集的校正方法。

Method: 1. 构建基于410例多机构数据的合成数据集（失真/无失真配对）；2. 结合11例金属植入病例的B0场图进行正向物理模拟；3. 设计混合框架：CNN几何校正模块 + 条件扩散细化（T2加权解剖引导）；4. 训练网络学习正向失真模型的逆过程。

Result: 1. 在合成验证集（n=34）上PSNR更高、NMSE更低，优于FSL TOPUP/FUGUE；2. 在34例真实临床严重失真病例（髋关节假体/直肠扩张）中，提升了几何保真度、图像质量和放射科医生的诊断信心。

Conclusion: 通过物理模拟正向过程并学习其逆变换，为前列腺DWI失真校正提供了不依赖额外数据采集的实用方案，有望替代传统采集依赖型校正流程。

Abstract: We present Distortion-Guided Restoration (DGR), a physics-informed hybrid CNN-diffusion framework for acquisition-free correction of severe susceptibility-induced distortions in prostate single-shot EPI diffusion-weighted imaging (DWI). DGR is trained to invert a realistic forward distortion model using large-scale paired distorted and undistorted data synthesized from distortion-free prostate DWI and co-registered T2-weighted images from 410 multi-institutional studies, together with 11 measured B0 field maps from metal-implant cases incorporated into a forward simulator to generate low-b DWI (b = 50 s per mm squared), high-b DWI (b = 1400 s per mm squared), and ADC distortions. The network couples a CNN-based geometric correction module with conditional diffusion refinement under T2-weighted anatomical guidance. On a held-out synthetic validation set (n = 34) using ground-truth simulated distortion fields, DGR achieved higher PSNR and lower NMSE than FSL TOPUP and FUGUE. In 34 real clinical studies with severe distortion, including hip prostheses and marked rectal distension, DGR improved geometric fidelity and increased radiologist-rated image quality and diagnostic confidence. Overall, learning the inverse of a physically simulated forward process provides a practical alternative to acquisition-dependent distortion-correction pipelines for prostate DWI.

</details>


### [156] [The Impact of Lesion Focus on the Performance of AI-Based Melanoma Classification](https://arxiv.org/abs/2601.00355)
*Tanay Donde*

Main category: eess.IV

TL;DR: 研究分析了机器学习模型在黑色素瘤分类中病灶注意力与诊断性能的关系，发现模型对病灶区域的关注度越高，诊断性能越好。


<details>
  <summary>Details</summary>
Motivation: 虽然卷积神经网络在自动化黑色素瘤分类中显示出潜力，但其诊断可靠性因对病灶区域关注不一致而受限，需要研究病灶注意力与诊断性能的关系。

Method: 使用掩码图像、边界框检测和迁移学习，结合多种可解释性和敏感性分析方法，评估模型注意力与病灶区域的对齐程度及其与诊断指标的相关性。

Result: 结果显示，对病灶区域关注度更高的模型获得了更好的诊断性能（精确率、召回率和F1分数）。

Conclusion: 可解释性AI在医疗诊断中具有潜力，该研究为开发更准确、可信赖的黑色素瘤分类模型奠定了基础。

Abstract: Melanoma is the most lethal subtype of skin cancer, and early and accurate detection of this disease can greatly improve patients' outcomes. Although machine learning models, especially convolutional neural networks (CNNs), have shown great potential in automating melanoma classification, their diagnostic reliability still suffers due to inconsistent focus on lesion areas. In this study, we analyze the relationship between lesion attention and diagnostic performance, involving masked images, bounding box detection, and transfer learning. We used multiple explainability and sensitivity analysis approaches to investigate how well models aligned their attention with lesion areas and how this alignment correlated with precision, recall, and F1-score. Results showed that models with a higher focus on lesion areas achieved better diagnostic performance, suggesting the potential of interpretable AI in medical diagnostics. This study provides a foundation for developing more accurate and trustworthy melanoma classification models in the future.

</details>


### [157] [Physics-Guided Dual-Domain Plug-and-Play ADMM for Low-Dose CT Reconstruction](https://arxiv.org/abs/2601.00669)
*Sayantan Dutta,Sudhanya Chatterjee,Ashwini Galande,K. S. Shriram,Bipul Das*

Main category: eess.IV

TL;DR: 提出一种基于即插即用模型迭代重建框架，结合两阶段自监督噪声到噪声训练的深度卷积去噪器，用于超低剂量CT成像，在降低70-80%辐射剂量的同时保持诊断质量。


<details>
  <summary>Details</summary>
Motivation: 超低剂量CT成像可大幅降低患者辐射暴露，但会导致严重的结构性和随机噪声，降低图像质量，需要开发既能降噪又能保持解剖结构的重建方法。

Method: 提出即插即用模型迭代重建框架，交替执行正弦图域数据保真和图像域深度学习去噪；采用两阶段自监督噪声到噪声训练方案，先使用噪声数据自监督预训练，再用高剂量数据微调。

Result: 在模拟和临床数据集上，该方法在降低70-80%辐射剂量的情况下，能有效减少条纹和结构伪影，保持细微组织对比度，纹理一致性和细节保留优于独立深度学习和监督即插即用基线方法。

Conclusion: 该框架为超低剂量CT重建提供了有前景的工具，能在显著降低辐射剂量的同时保持与标准全剂量扫描相当的诊断保真度。

Abstract: Ultra-low-dose CT (ULDCT) imaging can greatly reduce patient radiation exposure, but the resulting scans suffer from severe structured and random noise that degrades image quality. To address this challenge, we propose a novel Plug-and-Play model-based iterative reconstruction framework (PnP-MBIR) that integrates a deep convolutional denoiser trained in a 2-stage self-supervised Noise-to-Noise (N2N) scheme. The method alternates between enforcing sinogram-domain data fidelity and applying the learned image-domain denoiser within an optimization, enabling artifact suppression while maintaining anatomical structure. The 2-stage protocol enables fully self-supervised training from noisy data, followed by high-dose fine-tuning, ensuring the denoiser's robustness in the ultra-low-dose regime. Our method enables high-quality reconstructions at $\sim$70--80\% lower dose levels, while maintaining diagnostic fidelity comparable to standard full-dose scans. Quantitative evaluations using Gray-Level Co-occurrence Matrix (GLCM) features -- including contrast, homogeneity, entropy, and correlation -- confirm that the proposed method yields superior texture consistency and detail preservation over standalone deep learning and supervised PnP baselines. Qualitative and quantitative results on both simulated and clinical datasets demonstrate that our framework effectively reduces streaks and structured artifacts while preserving subtle tissue contrast, making it a promising tool for ULDCT reconstruction.

</details>


### [158] [KDPhys: An Attention Guided 3D to 2D Knowledge Distillation for Real-time Video-Based Physiological Measurement](https://arxiv.org/abs/2601.00714)
*Nicky Nirlipta Sahoo,VS Sachidanand,Matcha Naga Gayathri,Balamurali Murugesan,Keerthi Ram,Jayaraj Joseph,Mohanasankar Sivaprakasam*

Main category: eess.IV

TL;DR: 提出KDPhys框架，通过注意力知识蒸馏将3D CNN教师模型的知识迁移到轻量2D CNN学生模型，结合DILATE损失函数优化rPPG信号提取，在降低计算复杂度的同时提升心率估计精度。


<details>
  <summary>Details</summary>
Motivation: 新冠疫情推动远程医疗需求增长，需要实时、非接触式生理监测技术；现有rPPG方法计算复杂度高，难以在资源受限设备部署。

Method: 1. 注意力知识蒸馏框架（KDPhys）：3D CNN教师模型指导2D CNN学生模型学习全局时序特征；2. DILATE损失函数：联合优化信号形态和时序特征；3. 在三个基准数据集进行多场景评估。

Result: 1. 参数量仅0.23M（现有方法一半），推理速度提升56.67%；2. 平均MAE为1.78 bpm，较最优方法降低18.15%；3. 在不同环境和活动场景下保持鲁棒性。

Conclusion: KDPhys首次将知识蒸馏引入rPPG领域，实现了精度与效率的平衡，为移动端实时生理监测提供了可行方案。

Abstract: Camera-based physiological monitoring, such as remote photoplethysmography (rPPG), captures subtle variations in skin optical properties caused by pulsatile blood volume changes using standard digital camera sensors. The demand for real-time, non-contact physiological measurement has increased significantly, particularly during the SARS-CoV-2 pandemic, to support telehealth and remote health monitoring applications. In this work, we propose an attention-based knowledge distillation (KD) framework, termed KDPhys, for extracting rPPG signals from facial video sequences. The proposed method distills global temporal representations from a 3D convolutional neural network (CNN) teacher model to a lightweight 2D CNN student model through effective 3D-to-2D feature distillation. To the best of our knowledge, this is the first application of knowledge distillation in the rPPG domain. Furthermore, we introduce a Distortion Loss incorporating Shape and Time (DILATE), which jointly accounts for both morphological and temporal characteristics of rPPG signals. Extensive qualitative and quantitative evaluations are conducted on three benchmark datasets. The proposed model achieves a significant reduction in computational complexity, using only half the parameters of existing methods while operating 56.67% faster. With just 0.23M parameters, it achieves an 18.15% reduction in Mean Absolute Error (MAE) compared to state-of-the-art approaches, attaining an average MAE of 1.78 bpm across all datasets. Additional experiments under diverse environmental conditions and activity scenarios further demonstrate the robustness and adaptability of the proposed approach.

</details>
