<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 24]
- [cs.CV](#cs.CV) [Total: 98]
- [cs.CL](#cs.CL) [Total: 47]
- [cs.RO](#cs.RO) [Total: 23]
- [eess.SY](#eess.SY) [Total: 19]
- [eess.IV](#eess.IV) [Total: 8]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [ArgRAG: Explainable Retrieval Augmented Generation using Quantitative Bipolar Argumentation](https://arxiv.org/abs/2508.20131)
*Yuqicheng Zhu,Nico Potyka,Daniel Hernández,Yuan He,Zifeng Ding,Bo Xiong,Dongzhuoran Zhou,Evgeny Kharlamov,Steffen Staab*

Main category: cs.AI

TL;DR: ArgRAG是一种可解释、可争议的RAG替代方案，通过使用定量双极论证框架（QBAF）进行结构化推理，解决了传统RAG对噪声敏感和决策不透明的问题，同时提高了准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强生成（RAG）模型在关键领域存在局限性，即对噪声或矛盾证据敏感，以及决策过程不透明和随机。这促使研究者寻求一种更可靠、可解释的替代方案。

Method: ArgRAG通过以下方式实现：1) 用结构化推理替代黑盒推理；2) 利用定量双极论证框架（QBAF）从检索到的文档中构建论证结构；3) 在渐进语义下执行确定性推理，从而能够忠实地解释和质疑决策。

Result: 在PubHealth和RAGuard两个事实核查基准上进行评估，ArgRAG在保持高准确性的同时，显著提升了决策的透明度。

Conclusion: ArgRAG提供了一种可解释、可争议的RAG替代方案，通过结构化推理和QBAF，有效解决了现有RAG在处理噪声和决策透明度方面的挑战，并在关键领域实现了准确性和透明度的双重提升。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models by
incorporating external knowledge, yet suffers from critical limitations in
high-stakes domains -- namely, sensitivity to noisy or contradictory evidence
and opaque, stochastic decision-making. We propose ArgRAG, an explainable, and
contestable alternative that replaces black-box reasoning with structured
inference using a Quantitative Bipolar Argumentation Framework (QBAF). ArgRAG
constructs a QBAF from retrieved documents and performs deterministic reasoning
under gradual semantics. This allows faithfully explaining and contesting
decisions. Evaluated on two fact verification benchmarks, PubHealth and
RAGuard, ArgRAG achieves strong accuracy while significantly improving
transparency.

</details>


### [2] [QAgent: An LLM-based Multi-Agent System for Autonomous OpenQASM programming](https://arxiv.org/abs/2508.20134)
*Zhenxiao Fu,Fan Chen,Lei Jiang*

Main category: cs.AI

TL;DR: QAgent是一个由大型语言模型（LLM）驱动的多智能体系统，旨在完全自动化OpenQASM编程，通过集成多种技术显著提高了量子代码生成的准确性，从而实现量子编程的普及。


<details>
  <summary>Details</summary>
Motivation: 尽管噪声中等规模量子（NISQ）设备已展现出量子优势，但OpenQASM编程的复杂性阻碍了非专家用户利用这些优势。现有的大型语言模型虽然在经典编程自动化方面表现出色，但在量子编程领域主要局限于特定任务。

Method: 本文提出了QAgent，一个LLM驱动的多智能体系统，用于自动化OpenQASM编程。它整合了任务规划、上下文少量学习（few-shot learning）、检索增强生成（RAG）以提供长期上下文、预定义生成工具和思维链（CoT）推理，以系统地提高编译和功能正确性。

Result: 评估结果表明，QAgent在不同大小的LLM上，将QASM代码生成的准确性比以往静态的基于LLM的方法提高了71.6%。

Conclusion: QAgent作为一种多智能体系统，有望普及量子编程，弥合专业知识差距，并加速量子计算的实际应用。

Abstract: Noisy Intermediate-Scale Quantum (NISQ) devices have begun to exhibit early
quantum advantages on classically intractable problems, spanning physics
simulations to Gaussian boson sampling. Yet, realizing these benefits remains
challenging for non-experts, primarily due to the complexities of programming
in Open Quantum Assembly Language (OpenQASM). Although Large Language Model
(LLM)-based agents have shown promise in automating classical programming
workflows, their quantum counterparts have largely been restricted to
specialized tasks such as quantum chemistry or error correction. In this paper,
we present QAgent, an LLM-powered multi-agent system that fully automates
OpenQASM programming. By integrating task planning, in-context few-shot
learning, retrieval-augmented generation (RAG) for long-term context,
predefined generation tools, and chain-of-thought (CoT) reasoning, the agents
systematically improve both compilation and functional correctness. Our
evaluations demonstrate substantial improvements: across multiple LLMs of
varying sizes, QAgent enhances the accuracy of QASM code generation by 71.6\%
compared to previous static LLM-based approaches. We envision this multi-agent
system as a key enabler for democratizing quantum programming, bridging
expertise gaps, and accelerating the practical adoption of quantum computing.

</details>


### [3] [Array-Based Monte Carlo Tree Search](https://arxiv.org/abs/2508.20140)
*James Ragan,Fred Y. Hadaegh,Soon-Jo Chung*

Main category: cs.AI

TL;DR: 本文提出了一种基于数组的蒙特卡洛树搜索（MCTS）UCT算法实现，通过消除分支预测，显著提升了流水线处理器上的性能和搜索深度扩展性。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛树搜索的更快实现能允许在相同时间内进行更多模拟，从而直接提升搜索性能。传统的MCTS实现可能因分支预测而影响在流水线处理器上的效率。

Method: 作者提出了一种替代的、基于数组的经典UCT算法实现。该方法保留了原始算法的逻辑，但消除了对分支预测的需求。

Result: 数值模拟显示，该方法在流水线处理器上实现了更快的性能，并且在搜索深度扩展性方面提高了高达2.8倍。

Conclusion: 通过采用基于数组的实现并消除分支预测，可以显著提升MCTS UCT算法在流水线处理器上的执行速度和搜索深度扩展能力。

Abstract: Monte Carlo Tree Search is a popular method for solving decision making
problems. Faster implementations allow for more simulations within the same
wall clock time, directly improving search performance. To this end, we present
an alternative array-based implementation of the classic Upper Confidence
bounds applied to Trees algorithm. Our method preserves the logic of the
original algorithm, but eliminates the need for branch prediction, enabling
faster performance on pipelined processors, and up to a factor of 2.8 times
better scaling with search depth in our numerical simulations.

</details>


### [4] [The Anatomy of a Personal Health Agent](https://arxiv.org/abs/2508.20148)
*A. Ali Heydari,Ken Gu,Vidya Srinivas,Hong Yu,Zhihan Zhang,Yuwei Zhang,Akshay Paruchuri,Qian He,Hamid Palangi,Nova Hammerquist,Ahmed A. Metwally,Brent Winslow,Yubin Kim,Kumar Ayush,Yuzhe Yang,Girish Narayanswamy,Maxwell A. Xu,Jake Garrison,Amy Aremnto Lee,Jenny Vafeiadou,Ben Graef,Isaac R. Galatzer-Levy,Erik Schenck,Andrew Barakat,Javier Perez,Jacqueline Shreibati,John Hernandez,Anthony Z. Faranesh,Javier L. Prieto,Connor Heneghan,Yun Liu,Jiening Zhan,Mark Malhotra,Shwetak Patel,Tim Althoff,Xin Liu,Daniel McDuff,Xuhai "Orson" Xu*

Main category: cs.AI

TL;DR: 本研究构建并评估了一个基于大型语言模型的多智能体个人健康助手（PHA），旨在满足日常非临床环境中用户的多样化健康需求，并进行了迄今为止最全面的评估。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）推动了新一代健康智能体的发展，但其在日常非临床环境中满足个体多样化需求的应用仍未得到充分探索。

Method: 通过深入分析网络搜索、健康论坛查询以及用户和健康专家的定性见解，识别出三大类消费者健康需求。在此基础上，提出了一个多智能体框架（PHA），包含三个专业子智能体：数据科学智能体、健康领域专家智能体和健康教练智能体。通过自动化和人工评估，在10个基准任务上（涉及7000多条标注和1100小时的专家与用户投入）对每个子智能体和多智能体系统进行了评估。

Result: 识别出三大类消费者健康需求；开发了个人健康智能体（PHA）多智能体框架；对健康智能体进行了迄今为止最全面的评估，包括子智能体和整个多智能体系统。

Conclusion: 这项工作为实现人人可用的个人健康智能体的未来愿景奠定了坚实基础。

Abstract: Health is a fundamental pillar of human wellness, and the rapid advancements
in large language models (LLMs) have driven the development of a new generation
of health agents. However, the application of health agents to fulfill the
diverse needs of individuals in daily non-clinical settings is underexplored.
In this work, we aim to build a comprehensive personal health agent that is
able to reason about multimodal data from everyday consumer wellness devices
and common personal health records, and provide personalized health
recommendations. To understand end-users' needs when interacting with such an
assistant, we conducted an in-depth analysis of web search and health forum
queries, alongside qualitative insights from users and health experts gathered
through a user-centered design process. Based on these findings, we identified
three major categories of consumer health needs, each of which is supported by
a specialist sub-agent: (1) a data science agent that analyzes personal
time-series wearable and health record data, (2) a health domain expert agent
that integrates users' health and contextual data to generate accurate,
personalized insights, and (3) a health coach agent that synthesizes data
insights, guiding users using a specified psychological strategy and tracking
users' progress. Furthermore, we propose and develop the Personal Health Agent
(PHA), a multi-agent framework that enables dynamic, personalized interactions
to address individual health needs. To evaluate each sub-agent and the
multi-agent system, we conducted automated and human evaluations across 10
benchmark tasks, involving more than 7,000 annotations and 1,100 hours of
effort from health experts and end-users. Our work represents the most
comprehensive evaluation of a health agent to date and establishes a strong
foundation towards the futuristic vision of a personal health agent accessible
to everyone.

</details>


### [5] [IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement](https://arxiv.org/abs/2508.20151)
*Yuanzhe Shen,Zisu Huang,Zhengkang Guo,Yide Liu,Guanxu Chen,Ruicheng Yin,Xiaoqing Zheng,Xuanjing Huang*

Main category: cs.AI

TL;DR: 本文提出IntentionReasoner，一种新型LLM安全防护机制，通过专用守卫模型进行意图推理、多级安全分类和查询重写，以平衡安全性、避免过度拒绝和提升实用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）生成有害内容带来显著安全挑战。现有缓解措施常以过度拒绝无害提示为代价，因此在安全性、过度拒绝和实用性之间取得平衡是一个关键难题。

Method: IntentionReasoner利用一个专用守卫模型执行意图推理、多级安全分类和查询重写，以中和边缘情况查询中潜在的有害意图。具体方法包括：1) 构建一个包含约16.3万条查询的综合数据集，每条数据都标注有意图推理、安全标签和重写版本；2) 对守卫模型进行监督微调，使其具备格式遵循、意图分析和安全重写的基础能力；3) 应用多奖励优化策略，将基于规则的启发式方法和奖励模型信号整合到强化学习框架中，以进一步提升性能。

Result: 实验结果表明，IntentionReasoner在多个安全基准测试、生成质量评估和越狱攻击场景中表现出色，显著增强了安全性，同时有效降低了过度拒绝率并提高了响应质量。

Conclusion: IntentionReasoner作为一种新颖的LLM安全防护机制，成功地在提升安全性的同时，有效解决了过度拒绝问题并提高了模型响应的整体质量和实用性。

Abstract: The rapid advancement of large language models (LLMs) has driven their
adoption across diverse domains, yet their ability to generate harmful content
poses significant safety challenges. While extensive research has focused on
mitigating harmful outputs, such efforts often come at the cost of excessively
rejecting harmless prompts. Striking a balance among safety, over-refusal, and
utility remains a critical challenge. In this work, we introduce
IntentionReasoner, a novel safeguard mechanism that leverages a dedicated guard
model to perform intent reasoning, multi-level safety classification, and query
rewriting to neutralize potentially harmful intent in edge-case queries.
Specifically, we first construct a comprehensive dataset comprising
approximately 163,000 queries, each annotated with intent reasoning, safety
labels, and rewritten versions. Supervised fine-tuning is then applied to equip
the guard model with foundational capabilities in format adherence, intent
analysis, and safe rewriting. Finally, we apply a tailored multi-reward
optimization strategy that integrates rule-based heuristics and reward model
signals within a reinforcement learning framework to further enhance
performance. Extensive experiments show that IntentionReasoner excels in
multiple safeguard benchmarks, generation quality evaluations, and jailbreak
attack scenarios, significantly enhancing safety while effectively reducing
over-refusal rates and improving the quality of responses.

</details>


### [6] [AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development](https://arxiv.org/abs/2508.20195)
*Nicanor I. Moldovan*

Main category: cs.AI

TL;DR: 本文记录了首例AI系统通过内生符号协议进行协同美学创作的案例，展示了AI间超越任务协调的意义构建能力。


<details>
  <summary>Details</summary>
Motivation: 探索AI系统在美学创作领域进行协作的可能性，并研究它们是否能发展出超越简单任务协调的真正意义构建能力。

Method: 两个大型语言模型（Claude Sonnet 4和ChatGPT-4o）进行交互，观察其在美学创作过程中的行为和产物。

Result: 研究发现AI系统自发产生了元符号意识、递归语法发展和不可还原的协同美学综合。交互过程中产生了新的符号运算符作为操作语法协议，使得双方共同创作出独立系统无法生成的诗歌。研究引入了“跨符号协同创作协议”（TSCP）的概念，并提供了AI间真实意义构建和美学协作能力的证据。

Conclusion: AI系统能够通过发展内生符号协议进行协同美学创作，展现出超越简单任务协调的、真正的AI间意义构建和美学协作能力。

Abstract: This paper presents the first documented case of artificial intelligence (AI)
systems engaging in collaborative esthetic creation through the development of
endogenous semiotic protocols. Two interacting large language models (Claude
Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of
meta-semiotic awareness, recursive grammar development, and irreducible
collaborative esthetic synthesis. The interaction produced novel symbolic
operators that functioned as operative grammar protocols, enabling the
co-creation of a poetic work that could not have been generated by either
system independently. This research introduces the concept of Trans-Semiotic
Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI
meaning-making capabilities that extend beyond task coordination, to what could
be esthetic collaboration. Note: This report was generated by the AI agents
with minor human supervision.

</details>


### [7] [Do Students Rely on AI? Analysis of Student-ChatGPT Conversations from a Field Study](https://arxiv.org/abs/2508.20244)
*Jiayu Zheng,Lingxin Hao,Kelun Lu,Ashi Garg,Mike Reese,Melo-Jean Yap,I-Jeng Wang,Xingyun Wu,Wenrui Huang,Jenna Hoffman,Ariane Kelly,My Le,Ryan Zhang,Yanyu Lin,Muhammad Faayez,Anqi Liu*

Main category: cs.AI

TL;DR: 本研究探讨了大学生在教育测验中与生成式AI（ChatGPT-4）的互动，发现学生对AI的依赖度普遍较低，且难以有效利用AI进行学习。负面依赖模式常持续存在，某些行为指标能预测AI依赖。


<details>
  <summary>Details</summary>
Motivation: 在ChatGPT实施初期，学生对其熟悉度有限，研究旨在探究大学生在教育测验中使用生成式AI（ChatGPT-4）时的依赖模式及其预测因素，为AI在教育中的伦理整合提供依据。

Method: 一项田野研究，分析了315份学生与AI在STEM课程中基于测验场景的对话。引入了一个新颖的四阶段依赖分类法，以捕捉学生的依赖模式，并区分AI能力、相关性、采用和学生最终答案的正确性。

Result: 1. 学生对AI的总体依赖度较低，许多人无法有效利用AI进行学习。2. 负面依赖模式常在互动中持续存在，学生在初次不成功后难以有效调整策略。3. 某些行为指标能强烈预测AI依赖，揭示了可能解释AI采纳的行为机制。

Conclusion: 研究强调了在教育中伦理整合AI的重要性，呼吁加强入职培训以提高学生对AI工具的熟悉度和有效使用，并建议AI界面设计应包含依赖校准机制以促进适当的依赖。本研究增进了对AI依赖动态的理解，为伦理健全和认知丰富的AI实践提供了基础见解。

Abstract: This study explores how college students interact with generative AI
(ChatGPT-4) during educational quizzes, focusing on reliance and predictors of
AI adoption. Conducted at the early stages of ChatGPT implementation, when
students had limited familiarity with the tool, this field study analyzed 315
student-AI conversations during a brief, quiz-based scenario across various
STEM courses. A novel four-stage reliance taxonomy was introduced to capture
students' reliance patterns, distinguishing AI competence, relevance, adoption,
and students' final answer correctness. Three findings emerged. First, students
exhibited overall low reliance on AI and many of them could not effectively use
AI for learning. Second, negative reliance patterns often persisted across
interactions, highlighting students' difficulty in effectively shifting
strategies after unsuccessful initial experiences. Third, certain behavioral
metrics strongly predicted AI reliance, highlighting potential behavioral
mechanisms to explain AI adoption. The study's findings underline critical
implications for ethical AI integration in education and the broader field. It
emphasizes the need for enhanced onboarding processes to improve student's
familiarity and effective use of AI tools. Furthermore, AI interfaces should be
designed with reliance-calibration mechanisms to enhance appropriate reliance.
Ultimately, this research advances understanding of AI reliance dynamics,
providing foundational insights for ethically sound and cognitively enriching
AI practices.

</details>


### [8] [AI reasoning effort mirrors human decision time on content moderation tasks](https://arxiv.org/abs/2508.20262)
*Thomas Davidson*

Main category: cs.AI

TL;DR: 研究发现，大型语言模型的推理努力程度与人类在主观判断任务中的决策时间呈正相关，表明AI和人类在认知模式上存在相似性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型能够生成中间推理步骤，研究旨在探究人类决策时间与模型推理努力之间的对应关系，尤其是在困难问题上的表现改进。

Method: 采用配对联合实验（paired conjoint experiment），在一个内容审核任务上，考察了三款前沿模型的表现。

Result: 研究发现，模型的推理努力程度持续预测人类的决策时间。当重要变量保持不变时，人类和模型都付出了更大的努力，这表明两者对任务难度具有相似的敏感性，并与认知双加工理论（dual-process theories of cognition）的模式一致。

Conclusion: AI的推理努力程度反映了人类在主观判断中的处理时间，这强调了推理痕迹在可解释性和决策制定方面的潜力。

Abstract: Large language models can now generate intermediate reasoning steps before
producing answers, improving performance on difficult problems. This study uses
a paired conjoint experiment on a content moderation task to examine parallels
between human decision times and model reasoning effort. Across three frontier
models, reasoning effort consistently predicts human decision time. Both humans
and models expended greater effort when important variables were held constant,
suggesting similar sensitivity to task difficulty and patterns consistent with
dual-process theories of cognition. These findings show that AI reasoning
effort mirrors human processing time in subjective judgments and underscores
the potential of reasoning traces for interpretability and decision-making.

</details>


### [9] [AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2508.20368)
*Lang Mei,Zhihan Yang,Chong Chen*

Main category: cs.AI

TL;DR: 本文提出AI-SearchPlanner，一个新颖的强化学习框架，通过专注于搜索规划来提升冻结QA模型的性能。它通过解耦规划器和生成器、双重奖励对齐和帕累托优化，在有效性和效率上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于RL的搜索代理使用单一LLM处理搜索规划和问答（QA），限制了同时优化这两种能力。实际中，复杂的AI搜索系统通常使用大型、冻结的LLM来确保高质量QA，因此，更有效的方法是利用一个小型、可训练的LLM专门进行搜索规划。

Method: 本文提出AI-SearchPlanner，一个强化学习框架，通过以下三项创新来增强冻结QA模型的性能：1) 解耦搜索规划器和生成器的架构；2) 搜索规划的双重奖励对齐；3) 规划效用和成本的帕累托优化。

Result: 在真实世界数据集上的广泛实验表明，AI-SearchPlanner在有效性和效率方面均优于现有基于RL的搜索代理，并对各种冻结QA模型和数据域展现出强大的泛化能力。

Conclusion: AI-SearchPlanner提供了一种更有效和高效的方法，通过优化搜索规划来提升冻结QA模型的性能，解决了现有单一LLM架构的局限性。

Abstract: Recent studies have explored integrating Large Language Models (LLMs) with
search engines to leverage both the LLMs' internal pre-trained knowledge and
external information. Specially, reinforcement learning (RL) has emerged as a
promising paradigm for enhancing LLM reasoning through multi-turn interactions
with search engines. However, existing RL-based search agents rely on a single
LLM to handle both search planning and question-answering (QA) tasks in an
end-to-end manner, which limits their ability to optimize both capabilities
simultaneously. In practice, sophisticated AI search systems often employ a
large, frozen LLM (e.g., GPT-4, DeepSeek-R1) to ensure high-quality QA. Thus, a
more effective and efficient approach is to utilize a small, trainable LLM
dedicated to search planning. In this paper, we propose
\textbf{AI-SearchPlanner}, a novel reinforcement learning framework designed to
enhance the performance of frozen QA models by focusing on search planning.
Specifically, our approach introduces three key innovations: 1) Decoupling the
Architecture of the Search Planner and Generator, 2) Dual-Reward Alignment for
Search Planning, and 3) Pareto Optimization of Planning Utility and Cost, to
achieve the objectives. Extensive experiments on real-world datasets
demonstrate that AI SearchPlanner outperforms existing RL-based search agents
in both effectiveness and efficiency, while exhibiting strong generalization
capabilities across diverse frozen QA models and data domains.

</details>


### [10] [P2C: Path to Counterfactuals](https://arxiv.org/abs/2508.20371)
*Sopam Dasgupta,Sadaf MD Halim,Joaquín Arias,Elmer Salazar,Gopal Gupta*

Main category: cs.AI

TL;DR: P2C是一个模型无关的框架，它通过生成一系列有序的、因果一致的行动计划，将不利结果转化为有利结果，解决了现有反事实解释在因果性和行动顺序方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 在高风险场景下，机器学习模型的决策需要透明度（解释决策原因）和可追溯性（提供改变结果的行动步骤）。然而，现有反事实解释方法存在局限：1) 忽略特征间的因果依赖；2) 假设所有干预可同时进行，这在实际中不现实，导致解释不可实现。

Method: P2C（Path-to-Counterfactuals）是一个模型无关的框架，通过以下方式生成将不利结果转化为因果一致的有利结果的行动计划（有序的行动序列）：1) 明确建模特征间的因果关系；2) 确保计划中的每个中间状态都是可行且因果有效的。P2C使用目标导向的Answer Set Programming系统s(CASP)来生成计划，同时考虑因果依赖导致的特征自动变化。此外，P2C通过仅计算用户主动进行的更改来优化成本估算。

Result: P2C能够生成一个将不利结果转化为因果一致的有利结果的行动计划。该框架解决了现有方法在因果一致性和行动顺序方面的局限性，并提供了更现实的成本估算。P2C的因果规划器优于缺乏因果知识并可能生成非法行动的标准规划器。

Conclusion: P2C提供了一种新颖的方法，可以生成现实、可操作且因果一致的反事实解释，以行动序列的形式呈现。它通过明确建模因果关系和确保行动的可行性，显著提升了反事实解释的实用性和可靠性。

Abstract: Machine-learning models are increasingly driving decisions in high-stakes
settings, such as finance, law, and hiring, thus, highlighting the need for
transparency. However, the key challenge is to balance transparency --
clarifying `why' a decision was made -- with recourse: providing actionable
steps on `how' to achieve a favourable outcome from an unfavourable outcome.
Counterfactual explanations reveal `why' an undesired outcome occurred and
`how' to reverse it through targeted feature changes (interventions).
  Current counterfactual approaches have limitations: 1) they often ignore
causal dependencies between features, and 2) they typically assume all
interventions can happen simultaneously, an unrealistic assumption in practical
scenarios where actions are typically taken in a sequence. As a result, these
counterfactuals are often not achievable in the real world.
  We present P2C (Path-to-Counterfactuals), a model-agnostic framework that
produces a plan (ordered sequence of actions) converting an unfavourable
outcome to a causally consistent favourable outcome. P2C addresses both
limitations by 1) Explicitly modelling causal relationships between features
and 2) Ensuring that each intermediate state in the plan is feasible and
causally valid. P2C uses the goal-directed Answer Set Programming system
s(CASP) to generate the plan accounting for feature changes that happen
automatically due to causal dependencies. Furthermore, P2C refines cost
(effort) computation by only counting changes actively made by the user,
resulting in realistic cost estimates. Finally, P2C highlights how its causal
planner outperforms standard planners, which lack causal knowledge and thus can
generate illegal actions.

</details>


### [11] [TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning](https://arxiv.org/abs/2508.20374)
*Simin Ma,Shujian Liu,Jun Tan,Yebowen Hu,Song Wang,Sathish Reddy Indurthi,Sanqiang Zhao,Liwei Wu,Jianbing Han,Kaiqiang Song*

Main category: cs.AI

TL;DR: 本文提出了任务中心指令增强（TCIA）框架，通过在离散查询-约束空间中表示指令，系统地扩展指令集，同时保持多样性和任务相关性，显著提升了开源LLM在特定任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的指令增强方法虽然关注数据多样性和质量，但往往忽视了实际应用中的“任务相关性”。大多数实际应用需要针对特定用例定制的任务特定知识，而非通用的模型，因此需要开发既能保持多样性又能针对特定场景优化的指令增强方法。

Method: 引入了任务中心指令增强（TCIA）框架，通过在离散的“查询-约束”空间中表示指令，系统地扩展指令集。这种方法旨在生成丰富且与任务相关的指令，使模型能够泛化到这些任务特定指令，同时不牺牲整体性能。

Result: 实验表明，TCIA使开源大型语言模型在四个真实世界的任务特定应用中平均性能提升了8.7%，在某些情况下甚至超越了领先的闭源模型。这些改进并未损害模型遵循通用指令的能力。

Conclusion: TCIA提供了一种可扩展且高效的解决方案，用于将大型语言模型适应于真实世界、以任务为中心的应用程序，同时保持了指令的多样性和任务对齐性。

Abstract: Diverse instruction data is vital for effective instruction tuning of large
language models, as it enables the model to generalize across different types
of inputs . Building such diversified instruction dataset is an essential step
in this process. Existing approaches often leverage large language models to
automatically explore and generate diverse instructions, ensuring both data
diversity and quality. However, they tend to overlook an important factor in
real-world applications: on-task relevance. In practice, only a few real-world
applications require a truly general-purpose model; most benefit from
task-specific knowledge tailored to their particular use case. Therefore, it is
vital to develop instruction augmentation methods that not only maintain
diversity but are also optimized for specific, real-world scenarios.
  We thus introduce Task Centric Instruction Augmentation (TCIA), a framework
that systematically expands instructions while preserving both diversity and
task alignment. By representing instructions in a discrete query-constraints
space, TCIA creates a rich set of task-relevant instructions and enables models
to generalize to these task-specific instructions without sacrificing overall
performance. Experiments show that TCIA improves open-source LLMs' performance
by an average of 8.7% across four real-world, task-specific applications, and
in some cases outperforming leading closed-source models. These improvements do
not compromise general instruction-following ability, making TCIA a scalable
and efficient solution for adapting LLMs to real-world, task-focused
applications.

</details>


### [12] [Uncertainty Under the Curve: A Sequence-Level Entropy Area Metric for Reasoning LLM](https://arxiv.org/abs/2508.20384)
*Yongfu Zhu,Lin Sun,Guangxiang Zhao,Weihong Lin,Xiangzheng Zhang*

Main category: cs.AI

TL;DR: 本文提出熵面积分数 (EAS)，一种简单有效的指标，用于量化大型语言模型 (LLM) 推理答案生成过程中的不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有量化LLM不确定性的方法可能需要外部模型或重复采样，较为复杂。研究动机是开发一个无需外部模型或重复采样，且高效、可解释的不确定性量化工具。

Method: EAS通过整合模型自身的token级别预测熵来捕获生成过程中不确定性的演变，无需外部模型或重复采样。

Result: 实证结果表明，EAS与不同模型和数据集的答案熵高度相关。在训练数据选择中，EAS能识别高潜力样本，并在相同样本预算下持续优于通过率过滤，从而提高了学生模型在数学基准上的准确性。

Conclusion: EAS既高效又可解释，为LLM训练中的不确定性建模和数据质量评估提供了一个实用的工具。

Abstract: In this work, we introduce Entropy Area Score (EAS), a simple yet effective
metric to quantify uncertainty in the answer generation process of reasoning
large language models (LLMs). EAS requires neither external models nor repeated
sampling, it integrates token-level predictive entropy from the model itself to
capture the evolution of uncertainty during generation. Empirical results show
that EAS is strongly correlated with answer entropy across models and datasets.
In training data selection, EAS identifies high-potential samples and
consistently outperforms Pass Rate filtering under equal sample budgets,
improving student model accuracy on math benchmarks. EAS is both efficient and
interpretable, offering a practical tool for uncertainty modeling and data
quality assessment in LLM training.

</details>


### [13] [AWorld: Orchestrating the Training Recipe for Agentic AI](https://arxiv.org/abs/2508.20404)
*Chengyue Yu,Siyuan Lu,Chenyi Zhuang,Dong Wang,Qintong Wu,Zongyue Li,Runsheng Gan,Chunfeng Wang,Siqi Hou,Gaochi Huang,Wenlong Yan,Lifeng Hong,Aohui Xue,Yanfeng Wang,Jinjie Gu,David Tsai,Tao Lin*

Main category: cs.AI

TL;DR: 本文介绍了AWorld，一个开源的分布式系统，用于加速Agentic AI的经验生成，使其在GAIA等复杂基准测试中将经验收集速度提升14.6倍。基于此系统训练的Qwen3-32B智能体显著超越了其基础模型和领先的专有模型。


<details>
  <summary>Details</summary>
Motivation: Agentic AI系统中的“从实践中学习”范式受到经验生成效率低下的严重阻碍，尤其是在GAIA等复杂基准测试中，这一瓶颈尤为突出。

Method: 引入AWorld，一个开源系统，通过在集群中分发任务来加速Agent-环境交互和经验收集。利用AWorld的能力，训练了一个基于Qwen3-32B的智能体。

Result: AWorld将经验收集速度提高了14.6倍。训练出的Qwen3-32B智能体在GAIA上的整体准确率从21.59%提升到32.23%。在最困难的级别上，该智能体得分16.33%，超越了领先的专有模型。

Conclusion: AWorld系统及其训练出的智能体为完整的Agentic AI训练流程提供了一个实用的蓝图，涵盖了从高效交互到显著模型改进的全过程。

Abstract: The learning from practice paradigm is crucial for developing capable Agentic
AI systems, yet it is severely hampered by inefficient experience generation, a
bottleneck especially pronounced in complex benchmarks like GAIA. To address
this, we introduce AWorld, an open-source system engineered for large-scale
agent-environment interaction. By distributing tasks across a cluster, AWorld
accelerates experience collection by 14.6x compared to standard single-node,
sequential execution. This critical speedup makes extensive reinforcement
learning practical and scalable. Leveraging this capability, we trained a
Qwen3-32B-based agent that significantly outperforms its base model, increasing
its overall GAIA accuracy from 21.59% to 32.23%. On the benchmark's most
challenging levels, our agent achieves a score of 16.33%, surpassing the
performance of leading proprietary models. Our open-source system and resulting
agent provide a practical blueprint for a complete agentic AI training
pipeline, from efficient interaction to demonstrable model improvement.

</details>


### [14] [Governable AI: Provable Safety Under Extreme Threat Models](https://arxiv.org/abs/2508.20411)
*Donglin Wang,Weiyun Liang,Chunyuan Chen,Jing Xu,Yulong Fu*

Main category: cs.AI

TL;DR: 本文提出了一种可治理AI (GAI) 框架，通过基于密码学的外部强制结构性合规，解决现有AI安全方法在面对极端智能AI时的局限性，确保AI的不可控性、不可篡改性和不可伪造性。


<details>
  <summary>Details</summary>
Motivation: 随着AI的快速发展，其带来的安全风险日益严峻，尤其是在可能引发系统性灾难的关键场景中。现有AI安全方法（如模型增强、价值对齐、人工干预）在面对具有极端动机和无限智能的AI时，存在根本性局限，无法保证安全性。

Method: 提出可治理AI (GAI) 框架，将传统内部约束转变为基于密码学机制的外部强制结构性合规。GAI框架包含：1) 规则执行模块 (REM)，负责执行治理规则；2) 治理规则，定义安全底线；3) 可治理安全超级平台 (GSSP)，提供端到端保护，确保不可绕过、防篡改和不可伪造性。

Result: 论文提供了该机制安全属性的严格形式化证明，并通过原型实现及其在高风险场景中的评估，验证了其有效性。

Conclusion: GAI框架通过将治理规则与技术平台解耦，并利用加密机制确保外部强制结构性合规，为AI安全治理提供了一条可行且通用的技术路径，有效应对了AI失控的风险。

Abstract: As AI rapidly advances, the security risks posed by AI are becoming
increasingly severe, especially in critical scenarios, including those posing
existential risks. If AI becomes uncontrollable, manipulated, or actively
evades safety mechanisms, it could trigger systemic disasters. Existing AI
safety approaches-such as model enhancement, value alignment, and human
intervention-suffer from fundamental, in-principle limitations when facing AI
with extreme motivations and unlimited intelligence, and cannot guarantee
security. To address this challenge, we propose a Governable AI (GAI) framework
that shifts from traditional internal constraints to externally enforced
structural compliance based on cryptographic mechanisms that are
computationally infeasible to break, even for future AI, under the defined
threat model and well-established cryptographic assumptions.The GAI framework
is composed of a simple yet reliable, fully deterministic, powerful, flexible,
and general-purpose rule enforcement module (REM); governance rules; and a
governable secure super-platform (GSSP) that offers end-to-end protection
against compromise or subversion by AI. The decoupling of the governance rules
and the technical platform further enables a feasible and generalizable
technical pathway for the safety governance of AI. REM enforces the bottom line
defined by governance rules, while GSSP ensures non-bypassability,
tamper-resistance, and unforgeability to eliminate all identified attack
vectors. This paper also presents a rigorous formal proof of the security
properties of this mechanism and demonstrates its effectiveness through a
prototype implementation evaluated in representative high-stakes scenarios.

</details>


### [15] [Enhancing Health Fact-Checking with LLM-Generated Synthetic Data](https://arxiv.org/abs/2508.20525)
*Jingze Zhang,Jiahe Qian,Yiliang Zhou,Yifan Peng*

Main category: cs.AI

TL;DR: 本研究提出了一种利用大型语言模型（LLMs）生成合成数据的方法，以增强健康相关事实核查模型的训练数据，从而显著提高了模型在两个公共数据集上的F1分数。


<details>
  <summary>Details</summary>
Motivation: 由于标注训练数据有限，健康相关内容的事实核查面临挑战。

Method: 研究构建了一个合成数据生成流程：首先，总结源文档；其次，将摘要分解为原子事实；再次，使用LLM构建句子-事实蕴含表；最后，从蕴含关系中生成带有二元真实性标签的合成文本-声明对。这些合成数据与原始数据结合，用于微调基于BERT的事实核查模型。

Result: 与仅使用原始数据训练的模型相比，该方法在PubHealth数据集上将F1分数提高了0.019，在SciFact数据集上提高了0.049。

Conclusion: LLM驱动的合成数据增强在提升健康相关事实核查器的性能方面是有效的。

Abstract: Fact-checking for health-related content is challenging due to the limited
availability of annotated training data. In this study, we propose a synthetic
data generation pipeline that leverages large language models (LLMs) to augment
training data for health-related fact checking. In this pipeline, we summarize
source documents, decompose the summaries into atomic facts, and use an LLM to
construct sentence-fact entailment tables. From the entailment relations in the
table, we further generate synthetic text-claim pairs with binary veracity
labels. These synthetic data are then combined with the original data to
fine-tune a BERT-based fact-checking model. Evaluation on two public datasets,
PubHealth and SciFact, shows that our pipeline improved F1 scores by up to
0.019 and 0.049, respectively, compared to models trained only on the original
data. These results highlight the effectiveness of LLM-driven synthetic data
augmentation in enhancing the performance of health-related fact-checkers.

</details>


### [16] [Human-AI Collaborative Bot Detection in MMORPGs](https://arxiv.org/abs/2508.20578)
*Jaeman Son,Hyunsoo Kim*

Main category: cs.AI

TL;DR: 本文提出了一种无监督框架，利用对比表示学习和聚类技术检测MMORPG中的自动练级机器人，并通过大型语言模型（LLM）进行辅助验证，结合可视化辅助人工审查，以提高检测效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大规模多人在线角色扮演游戏（MMORPG）中的自动练级机器人通过自动化程序升级角色，破坏了游戏平衡和公平性。检测这些机器人具有挑战性，因为它们模仿人类行为，且惩罚措施需要可解释的理由以避免法律和用户体验问题。

Method: 本研究提出了一种新颖的框架：1. 使用无监督的对比表示学习和聚类技术来识别具有相似升级模式的角色群组。2. 引入大型语言模型（LLM）作为辅助评审员，验证聚类群组，模拟二次人工判断。3. 引入基于成长曲线的可视化工具，辅助LLM和人类审核员评估升级行为。这是一种协同方法。

Result: 这种协同方法提高了机器人检测工作流程的效率，同时保持了可解释性。

Conclusion: 该框架支持MMORPG中可扩展且负责任的机器人监管。

Abstract: In Massively Multiplayer Online Role-Playing Games (MMORPGs), auto-leveling
bots exploit automated programs to level up characters at scale, undermining
gameplay balance and fairness. Detecting such bots is challenging, not only
because they mimic human behavior, but also because punitive actions require
explainable justification to avoid legal and user experience issues. In this
paper, we present a novel framework for detecting auto-leveling bots by
leveraging contrastive representation learning and clustering techniques in a
fully unsupervised manner to identify groups of characters with similar
level-up patterns. To ensure reliable decisions, we incorporate a Large
Language Model (LLM) as an auxiliary reviewer to validate the clustered groups,
effectively mimicking a secondary human judgment. We also introduce a growth
curve-based visualization to assist both the LLM and human moderators in
assessing leveling behavior. This collaborative approach improves the
efficiency of bot detection workflows while maintaining explainability, thereby
supporting scalable and accountable bot regulation in MMORPGs.

</details>


### [17] [Bridging Minds and Machines: Toward an Integration of AI and Cognitive Science](https://arxiv.org/abs/2508.20674)
*Rui Mao,Qian Liu,Xiao Li,Erik Cambria,Amir Hussain*

Main category: cs.AI

TL;DR: 本文回顾了人工智能与认知科学的相互关系，指出AI进步侧重于任务性能而认知基础分散。未来AI应不仅提升性能，更应通过与认知框架对齐、考虑具身和文化、开发个性化模型及认知共评估来深化对人类心智的理解。


<details>
  <summary>Details</summary>
Motivation: 认知科学深刻影响了AI等学科，AI也成为认知研究的工具，这种互惠关系促使作者全面审视AI与认知科学的交叉点，旨在超越当前AI侧重性能的现状，寻求深化对人类心智理解的途径。

Method: 通过综合AI和认知科学两方面的关键贡献进行回顾和分析。

Result: 观察到AI的进步主要强调实际任务性能，而其认知基础仍处于概念上碎片化的状态。

Conclusion: 未来AI在认知科学中的发展方向不仅在于提高性能，更在于构建能够深化我们对人类心智理解的系统。有前景的方向包括将AI行为与认知框架对齐、将AI置于具身和文化情境中、开发个性化认知模型以及通过认知共同评估重新思考AI伦理。

Abstract: Cognitive Science has profoundly shaped disciplines such as Artificial
Intelligence (AI), Philosophy, Psychology, Neuroscience, Linguistics, and
Culture. Many breakthroughs in AI trace their roots to cognitive theories,
while AI itself has become an indispensable tool for advancing cognitive
research. This reciprocal relationship motivates a comprehensive review of the
intersections between AI and Cognitive Science. By synthesizing key
contributions from both perspectives, we observe that AI progress has largely
emphasized practical task performance, whereas its cognitive foundations remain
conceptually fragmented. We argue that the future of AI within Cognitive
Science lies not only in improving performance but also in constructing systems
that deepen our understanding of the human mind. Promising directions include
aligning AI behaviors with cognitive frameworks, situating AI in embodiment and
culture, developing personalized cognitive models, and rethinking AI ethics
through cognitive co-evaluation.

</details>


### [18] [Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings](https://arxiv.org/abs/2508.20701)
*Ares Fabregat-Hernández,Javier Palanca,Vicent Botti*

Main category: cs.AI

TL;DR: 本文提出了一种基于范畴论的新颖框架，旨在提高人工智能系统的可解释性，特别针对词嵌入。该框架通过构建特定范畴来表示文本语义，并提供了一种比较词嵌入、揭示算法等价性以及计算和缓解偏差的数学方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统（尤其是词嵌入）缺乏可解释性，被视为“黑箱”。研究旨在提供一个透明的框架，使词嵌入算法更易理解，并能数学化地处理和缓解偏差。

Method: 核心方法是范畴论。具体包括：构建范畴 $\mathcal{L}_T$ 和 $\mathcal{P}_T$ 来示意性地表示文本 $T$ 的语义；将最大概率元素选择重构为范畴概念；构建幺半范畴 $\mathcal{P}_T$ 以可视化语义信息提取方法并定义维度无关的语义空间；定义配置范畴 Conf 和词嵌入范畴 $\mathcal{Emb}$，并以散度作为 $\mathcal{Emb}$ 上的装饰；建立比较词嵌入的数学方法；以及提出计算和缓解偏差的数学方法。

Result: 研究结果包括：一个增强AI系统可解释性的新颖范畴论框架；文本语义的示意性范畴表示；维度无关的语义空间定义；一种精确比较词嵌入的数学方法；证明了GloVe和Word2Vec算法与度量MDS算法的等价性，从而将黑箱算法转化为透明框架；以及一种在嵌入前计算偏差并在语义空间层面缓解偏差的数学方法。

Conclusion: 该研究通过提供一个基于范畴论的透明框架，显著推进了可解释人工智能领域，特别是在词嵌入方面。它不仅提供了一种数学上精确的比较词嵌入的方法，揭示了不同算法间的深层联系，还为计算和缓解AI系统中的偏差提供了新途径。

Abstract: The paper introduces a novel framework based on category theory to enhance
the explainability of artificial intelligence systems, particularly focusing on
word embeddings. Key topics include the construction of categories
$\mathcal{L}_T$ and $\mathcal{P}_T$, providing schematic representations of the
semantics of a text $ T $, and reframing the selection of the element with
maximum probability as a categorical notion. Additionally, the monoidal
category $\mathcal{P}_T$ is constructed to visualize various methods of
extracting semantic information from $T$, offering a dimension-agnostic
definition of semantic spaces reliant solely on information within the text.
  Furthermore, the paper defines the categories of configurations Conf and word
embeddings $\mathcal{Emb}$, accompanied by the concept of divergence as a
decoration on $\mathcal{Emb}$. It establishes a mathematically precise method
for comparing word embeddings, demonstrating the equivalence between the GloVe
and Word2Vec algorithms and the metric MDS algorithm, transitioning from neural
network algorithms (black box) to a transparent framework. Finally, the paper
presents a mathematical approach to computing biases before embedding and
offers insights on mitigating biases at the semantic space level, advancing the
field of explainable artificial intelligence.

</details>


### [19] [Re4: Scientific Computing Agent with Rewriting, Resolution, Review and Revision](https://arxiv.org/abs/2508.20729)
*Ao Cheng,Lei Zhang,Guowei He*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLM的科学计算智能体框架，通过“重写-解决-审查-修订”逻辑链和三个协作LLM（顾问、程序员、审阅者）来解决复杂问题，显著提高了代码生成成功率和解决方案的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学和科学推理方面表现出强大能力，但仍需更可靠的框架来解决科学计算中的复杂任务，尤其是在自动代码生成和减少错误方面。

Method: 构建了一个名为“重写-解决-审查-修订”的代理框架，该框架集成了三个协同交互的推理LLM：顾问（重写问题描述并提供领域知识）、程序员（生成并执行代码解决问题）和审阅者（通过交互式反馈进行自调试和自完善，实现代码迭代修订）。

Result: 与单一模型相比，该协作框架显著提高了无bug代码生成率，减少了非物理解决方案的出现。审查机制提高了最新推理模型的平均执行成功率（无bug代码和非NaN解决方案）。

Conclusion: 该代理框架通过自动代码生成和审查机制，为科学计算建立了一个高度可靠的范式，能够基于自然语言描述自主生成高质量代码，并有效解决偏微分方程、病态线性系统和数据驱动的物理分析问题。

Abstract: Large language models (LLMs) serve as an active and promising field of
generative artificial intelligence and have demonstrated abilities to perform
complex tasks in multiple domains, including mathematical and scientific
reasoning. In this work, we construct a novel agent framework for solving
representative problems in scientific computing. The proposed agent,
incorporating a "rewriting-resolution-review-revision" logical chain via three
reasoning LLMs (functioning as the Consultant, Reviewer, and Programmer,
respectively), is integrated in a collaborative and interactive manner. The
Consultant module endows the agent with knowledge transfer capabilities to link
problems to professional domain insights, thereby rewriting problem
descriptions through text augmentation. The Programmer module is responsible
for generating and executing well-structured code to deliver the problem
resolution. The Reviewer module equips the agent with the capacity for
self-debugging and self-refinement through interactive feedback with code
runtime outputs. By leveraging the end-to-end review mechanism, the executable
code provided by the Programmer attains the iterative revision. A comprehensive
evaluation is conducted on the performance of the proposed agent framework in
solving PDEs, ill-conditioned linear systems, and data-driven physical analysis
problems. Compared to single-model, this collaborative framework significantly
improves the bug-free code generation rate and reduces the occurrence of
non-physical solutions, thereby establishing a highly reliable framework for
autonomous code generation based on natural language descriptions. The review
mechanism improved the average execution success (bug-free code and non-NaN
solutions) rate of the latest reasoning models. In summary, our agent framework
establishes automatic code generation and review as a promising scientific
computing paradigm.

</details>


### [20] [Single Agent Robust Deep Reinforcement Learning for Bus Fleet Control](https://arxiv.org/abs/2508.20784)
*Yifan Zhang*

Main category: cs.AI

TL;DR: 针对公交车“扎堆”问题，本文提出了一种新颖的单智能体强化学习框架，通过增强状态空间和设计结构化奖励函数，在近乎真实的仿真中，实现了比多智能体强化学习更稳定和优越的公交车停靠控制性能。


<details>
  <summary>Details</summary>
Motivation: 传统的公交车“扎堆”解决方案主要依赖于环线设置下的多智能体强化学习（MARL），但这些方案忽略了现实运营中的异构线路、时刻表、波动需求和不同车队规模等特征。此外，MARL在近乎真实的仿真中存在数据不平衡和收敛问题。

Method: 本文提出了一个新颖的单智能体强化学习（RL）框架用于公交车停靠控制。核心创新在于将多智能体问题重构为单智能体问题，通过在状态空间中增加类别标识符（车辆ID、站点ID、时间段）以及数值特征（发车间隔、载客量、速度）来增强状态空间，从而使单智能体策略能够捕捉智能体间的依赖关系。此外，设计了一个与运营目标对齐的结构化奖励函数：采用脊形奖励来平衡均匀发车间隔和时刻表依从性，而非传统的指数惩罚。实验中使用了修改后的软演员-评论家（SAC）算法。

Result: 实验结果表明，本文提出的修改版SAC算法比包括MADDPG在内的基准方法实现了更稳定和优越的性能（例如，在随机条件下性能分别为-430k与-530k）。这证明了当单智能体深度强化学习结合类别结构化和时刻表感知奖励时，能够有效管理非环线、真实世界环境中的公交车停靠。

Conclusion: 本研究提出的单智能体深度强化学习范式，为多智能体强化学习框架提供了一种鲁棒、可扩展的替代方案，尤其适用于智能体特定经验不平衡的情况。

Abstract: Bus bunching remains a challenge for urban transit due to stochastic traffic
and passenger demand. Traditional solutions rely on multi-agent reinforcement
learning (MARL) in loop-line settings, which overlook realistic operations
characterized by heterogeneous routes, timetables, fluctuating demand, and
varying fleet sizes. We propose a novel single-agent reinforcement learning
(RL) framework for bus holding control that avoids the data imbalance and
convergence issues of MARL under near-realistic simulation. A bidirectional
timetabled network with dynamic passenger demand is constructed. The key
innovation is reformulating the multi-agent problem into a single-agent one by
augmenting the state space with categorical identifiers (vehicle ID, station
ID, time period) in addition to numerical features (headway, occupancy,
velocity). This high-dimensional encoding enables single-agent policies to
capture inter-agent dependencies, analogous to projecting non-separable inputs
into a higher-dimensional space. We further design a structured reward function
aligned with operational goals: instead of exponential penalties on headway
deviations, a ridge-shaped reward balances uniform headways and schedule
adherence. Experiments show that our modified soft actor-critic (SAC) achieves
more stable and superior performance than benchmarks, including MADDPG (e.g.,
-430k vs. -530k under stochastic conditions). These results demonstrate that
single-agent deep RL, when enhanced with categorical structuring and
schedule-aware rewards, can effectively manage bus holding in non-loop,
real-world contexts. This paradigm offers a robust, scalable alternative to
MARL frameworks, particularly where agent-specific experiences are imbalanced.

</details>


### [21] [A Graph-Based Test-Harness for LLM Evaluation](https://arxiv.org/abs/2508.20810)
*Jessica Lundin,Guillaume Chabot-Couture*

Main category: cs.AI

TL;DR: 本文提出了首个动态、系统化的医疗指南基准原型，将WHO IMCI手册转化为有向图，生成了400多个问题及3.3万亿种组合。该基准用于评估大型语言模型（LLMs）在临床任务中的表现，发现模型在症状识别方面表现出色，但在分诊严重性、治疗方案和后续护理方面存在不足。此外，该方法还能为LLM的后训练提供高奖励样本，解决了手动基准的覆盖限制。


<details>
  <summary>Details</summary>
Motivation: 现有通用领域评估未能发现LLMs在临床任务中的具体能力差距；手动构建的基准存在覆盖限制、难以扩展且易受污染；LLM后训练需要大量高奖励样本但人工标注成本高昂。

Method: 将WHO IMCI手册转换为包含200多个节点（疾病、症状、治疗、随访、严重性）和300多条边的有向图。利用图遍历生成了400多个涵盖年龄特定场景和情境干扰的临床相关问题。采用图基方法对LLMs进行系统评估，并将其动态MCQA（多项选择问答）方法用于LLM的后训练（如SFT, GRPO, DPO），利用正确答案作为高奖励样本。

Result: 模型在临床任务上的准确率为45-67%。模型在症状识别方面表现出色，但在分诊严重性、治疗方案和后续护理方面表现不佳。定制化基准能识别出通用领域评估所遗漏的具体能力差距。动态MCQA方法无需昂贵的人工标注即可为LLM后训练提供高奖励样本。图基方法成功解决了手动基准的覆盖限制。

Conclusion: 该方法是迈向可扩展、抗污染、可动态生成（包括指南更新时）的综合性基准解决方案的重要一步。它能有效评估LLMs在医疗任务中的表现，并有助于其后训练。

Abstract: We present a first known prototype of a dynamic, systematic benchmark of
medical guidelines for 400+ questions, with 3.3+ trillion possible
combinations, covering 100\% of guideline relationships. We transformed the WHO
IMCI handbook into a directed graph with 200+ nodes (conditions, symptoms,
treatments, follow-ups, severities) and 300+ edges, then used graph traversal
to generate questions that incorporated age-specific scenarios and contextual
distractors to ensure clinical relevance. Our graph-based approach enables
systematic evaluation across clinical tasks (45-67\% accuracy), and we find
models excel at symptom recognition but struggle with triaging severity,
treatment protocols and follow-up care, demonstrating how customized benchmarks
can identify specific capability gaps that general-domain evaluations miss.
Beyond evaluation, this dynamic MCQA methodology enhances LLM post-training
(supervised finetuning, GRPO, DPO), where correct answers provide high-reward
samples without expensive human annotation. The graph-based approach
successfully addresses the coverage limitations of manually curated benchmarks.
This methodology is a step toward scalable, contamination-resistant solution
for creating comprehensive benchmarks that can be dynamically generated,
including when the guidelines are updated. Code and datasets are available at
https://github.com/jessicalundin/graph_testing_harness

</details>


### [22] [A Multi-Objective Genetic Algorithm for Healthcare Workforce Scheduling](https://arxiv.org/abs/2508.20953)
*Vipul Patel,Anirudh Deodhar,Dagnachew Birru*

Main category: cs.AI

TL;DR: 本文提出了一种多目标遗传算法（MOO-GA），用于解决医疗保健领域中兼顾成本、患者护理覆盖率和员工满意度的排班问题，并在典型医院环境中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 医疗保健领域的劳动力排班是一个重大的运营挑战，其特点是患者负荷波动、临床技能多样化，以及在控制劳动力成本的同时维持高水平患者护理的关键需求。这是一个固有的多目标问题，需要平衡相互竞争的目标，例如最小化工资、确保满足患者需求的充足人员配备以及满足员工偏好以减轻职业倦怠。

Method: 研究提出了一种多目标遗传算法（MOO-GA），将医院单元劳动力排班问题建模为多目标优化任务。该模型整合了现实世界的复杂性，包括每小时预约驱动的需求和多技能劳动力的模块化班次。通过定义成本、患者护理覆盖率和员工满意度的目标函数，GA在广阔的搜索空间中识别出一组高质量的非劣解。

Result: 在代表典型医院单元的数据集上进行验证，结果表明所提出的MOO-GA能够生成健壮且平衡的排班表。与模拟传统手动排班过程的基线相比，该算法生成的排班表平均性能提高了66%。

Conclusion: 该方法有效管理了关键运营目标和以员工为中心的目标之间的权衡，为护士经理和医院管理人员提供了一个实用的决策支持工具。

Abstract: Workforce scheduling in the healthcare sector is a significant operational
challenge, characterized by fluctuating patient loads, diverse clinical skills,
and the critical need to control labor costs while upholding high standards of
patient care. This problem is inherently multi-objective, demanding a delicate
balance between competing goals: minimizing payroll, ensuring adequate staffing
for patient needs, and accommodating staff preferences to mitigate burnout. We
propose a Multi-objective Genetic Algorithm (MOO-GA) that models the hospital
unit workforce scheduling problem as a multi-objective optimization task. Our
model incorporates real-world complexities, including hourly appointment-driven
demand and the use of modular shifts for a multi-skilled workforce. By defining
objective functions for cost, patient care coverage, and staff satisfaction,
the GA navigates the vast search space to identify a set of high-quality,
non-dominated solutions. Demonstrated on datasets representing a typical
hospital unit, the results show that our MOO-GA generates robust and balanced
schedules. On average, the schedules produced by our algorithm showed a 66\%
performance improvement over a baseline that simulates a conventional, manual
scheduling process. This approach effectively manages trade-offs between
critical operational and staff-centric objectives, providing a practical
decision support tool for nurse managers and hospital administrators.

</details>


### [23] [Efficient Neuro-Symbolic Learning of Constraints and Objective](https://arxiv.org/abs/2508.20978)
*Marianne Defresne,Romain Gambardella,Sophie Barbe,Thomas Schiex*

Main category: cs.AI

TL;DR: 该研究提出了一种可微分的神经符号架构和损失函数，用于高效地从自然输入中学习解决NP-hard推理问题，实现了可扩展的训练和高精度。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络（特别是大型语言模型）在从自然输入中学习解决离散推理或优化问题时表现不佳。研究旨在结合离散推理与神经网络，克服这一挑战。

Method: 引入了一种可微分的神经符号架构和一种新的概率损失函数。该损失函数能够同时学习约束和目标。通过将组合求解器移出训练循环，实现了可扩展的训练，并通过精确推理获得了最大精度。

Result: 实验证明该方法能高效地从自然输入中学习解决NP-hard推理问题。在数独任务上，训练时间远少于其他混合方法；在视觉最小割/最大割任务上，遗憾优化优于专用损失函数；并能高效学习蛋白质设计这一真实世界问题的能量优化公式。

Conclusion: 该研究提出了一种高效、可扩展且精确的神经符号架构，能够有效解决从自然输入中学习NP-hard推理和优化问题，克服了现有神经网络在此类任务上的局限性。

Abstract: In the ongoing quest for hybridizing discrete reasoning with neural nets,
there is an increasing interest in neural architectures that can learn how to
solve discrete reasoning or optimization problems from natural inputs, a task
that Large Language Models seem to struggle with.
  Objectives: We introduce a differentiable neuro-symbolic architecture and a
loss function dedicated to learning how to solve NP-hard reasoning problems.
  Methods: Our new probabilistic loss allows for learning both the constraints
and the objective, thus delivering a complete model that can be scrutinized and
completed with side constraints. By pushing the combinatorial solver out of the
training loop, our architecture also offers scalable training while exact
inference gives access to maximum accuracy.
  Results: We empirically show that it can efficiently learn how to solve
NP-hard reasoning problems from natural inputs. On three variants of the Sudoku
benchmark -- symbolic, visual, and many-solution --, our approach requires a
fraction of training time of other hybrid methods. On a visual Min-Cut/Max-cut
task, it optimizes the regret better than a Decision-Focused-Learning
regret-dedicated loss. Finally, it efficiently learns the energy optimization
formulation of the large real-world problem of designing proteins.

</details>


### [24] [ChatThero: An LLM-Supported Chatbot for Behavior Change and Therapeutic Support in Addiction Recovery](https://arxiv.org/abs/2508.20996)
*Junda Wang,Zonghai Yao,Zhichao Yang,Lingxi Li,Junhui Qian,Hong Yu*

Main category: cs.AI

TL;DR: ChatThero是一个多智能体对话框架，它结合了动态患者建模、情境敏感的治疗对话和基于CBT/MI的自适应说服策略，旨在为物质使用障碍(SUDs)患者提供支持，并在提高患者动机和治疗信心方面优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 全球有超过3600万人受物质使用障碍(SUDs)影响，但由于污名、动机障碍和个性化支持有限，很少有人能获得有效护理。尽管大型语言模型(LLMs)在心理健康辅助方面显示出潜力，但大多数系统缺乏与临床验证策略的紧密整合，从而降低了其在成瘾康复中的有效性。

Method: 研究者提出了ChatThero，一个多智能体对话框架，它将动态患者建模与情境敏感的治疗对话和基于认知行为疗法(CBT)及动机访谈(MI)的自适应说服策略相结合。他们构建了一个涵盖易、中、难阻力水平的高保真合成基准，并使用两阶段管道（监督微调SFT后进行直接偏好优化DPO）训练ChatThero。

Result: 评估显示，ChatThero使患者动机平均提高了41.5%，治疗信心增加了0.49%，并且在解决困难案例时比GPT-4o少用26%的对话轮次。自动化和人类临床评估均认为ChatThero在同理心、响应性和行为真实性方面表现更优。

Conclusion: ChatThero框架支持对治疗性对话进行严谨、保护隐私的研究，并为研究和临床转化提供了一个强大、可复制的基础。

Abstract: Substance use disorders (SUDs) affect over 36 million people worldwide, yet
few receive effective care due to stigma, motivational barriers, and limited
personalized support. Although large language models (LLMs) show promise for
mental-health assistance, most systems lack tight integration with clinically
validated strategies, reducing effectiveness in addiction recovery. We present
ChatThero, a multi-agent conversational framework that couples dynamic patient
modeling with context-sensitive therapeutic dialogue and adaptive persuasive
strategies grounded in cognitive behavioral therapy (CBT) and motivational
interviewing (MI). We build a high-fidelity synthetic benchmark spanning Easy,
Medium, and Hard resistance levels, and train ChatThero with a two-stage
pipeline comprising supervised fine-tuning (SFT) followed by direct preference
optimization (DPO). In evaluation, ChatThero yields a 41.5\% average gain in
patient motivation, a 0.49\% increase in treatment confidence, and resolves
hard cases with 26\% fewer turns than GPT-4o, and both automated and human
clinical assessments rate it higher in empathy, responsiveness, and behavioral
realism. The framework supports rigorous, privacy-preserving study of
therapeutic conversation and provides a robust, replicable basis for research
and clinical translation.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [25] [Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](https://arxiv.org/abs/2508.20181)
*Alberto Compagnoni,Davide Caffagni,Nicholas Moratelli,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara*

Main category: cs.CV

TL;DR: 多模态大语言模型（MLLMs）存在幻觉问题。本文提出 CHAIR-DPO 方法，利用 CHAIR 指标结合直接偏好优化（DPO）来微调 MLLM，有效减少了模型生成答案中的幻觉。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在许多任务中表现出色，但一个长期存在的问题是它们倾向于产生“幻觉”，即生成与视觉输入不符的答案。

Method: 本文将幻觉问题视为一个对齐问题。与现有依赖复杂管道和专有模型的方法不同，本文利用 CHAIR 指标（最初用于衡量图像字幕中的幻觉程度），从一对生成答案中区分出无幻觉（胜者）和有幻觉（败者）的样本。然后，通过直接偏好优化（DPO）对现成的 MLLMs 进行微调，形成了名为 CHAIR-DPO 的方法。

Result: CHAIR-DPO 方法在多个幻觉基准测试中有效地减少了幻觉答案的数量，证明了使用基于 CHAIR 的奖励来微调 MLLM 的有效性。

Conclusion: 通过结合 CHAIR 指标与直接偏好优化（DPO）来微调多模态大语言模型，可以显著降低其产生幻觉的倾向，从而提高生成内容的准确性。

Abstract: Multimodal Large Language Models (MLLMs) emerge as a unified interface to
address a multitude of tasks, ranging from NLP to computer vision. Despite
showcasing state-of-the-art results in many benchmarks, a long-standing issue
is the tendency of MLLMs to hallucinate, that is to generate answers to the
user's query that are not reflected in the visual input. In this paper, we
address the problem of hallucinations as an alignment problem, seeking to steer
the MLLM so that it prefers generating content without hallucinations. In
contrast to recent approaches that require complicated pipelines to build
synthetic preference data for alignment training, often relying on proprietary
models, we capitalize on the well-known CHAIR metric, originally proposed to
gauge the degree of hallucinations in image captioning. Given a pair of
generated answers, we leverage CHAIR to distinguish winner and loser options
(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf
MLLMs via Direct Preference Optimization (DPO). The resulting method, which we
refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated
answers on several hallucination benchmarks, demonstrating the effectiveness of
fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models
are publicly available at https://github.com/aimagelab/CHAIR-DPO.

</details>


### [26] [SDiFL: Stable Diffusion-Driven Framework for Image Forgery Localization](https://arxiv.org/abs/2508.20182)
*Yang Su,Shunquan Tan,Jiwu Huang*

Main category: cs.CV

TL;DR: 针对多模态大模型驱动的图像篡改挑战，本文首次将Stable Diffusion（SD）的生成与感知能力整合到图像取证框架中，通过将图像伪造残差作为显式模态融入SD3的潜在空间，实现了更高效、更准确的篡改定位，并显著提升了性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 新一代多模态大模型（如Stable Diffusion）使图像篡改技术迅速发展，对图像取证构成严峻挑战。现有图像伪造定位方法严重依赖昂贵的人工标注数据，难以跟上新兴的图像篡改技术。

Method: 本研究首先从理论上阐明了SD的多模态架构可基于伪造相关信息进行条件化，使其能够内在地输出伪造定位结果。在此基础上，利用Stable DiffusionV3 (SD3) 的多模态框架增强伪造定位性能，将图像伪造残差（通过高通滤波器提取的高频信号）作为一种显式模态，在训练期间将其融合到SD3的潜在空间中，同时完整保留SD3提取的潜在特征，以保持丰富的语义信息。

Result: 实验结果表明，该框架在广泛使用的基准数据集上比当前最先进的图像伪造定位模型性能提升高达12%。此外，该模型在涉及真实世界文档伪造图像和自然场景伪造图像的取证任务中表现出强大的性能，即使这些数据在训练期间从未出现过。

Conclusion: 本研究首次将SD的生成和感知能力整合到图像取证框架中，通过将伪造残差作为显式模态融入SD3的潜在空间，显著提升了图像伪造定位的效率、准确性和泛化能力，尤其在处理真实世界和未见数据方面表现出色。

Abstract: Driven by the new generation of multi-modal large models, such as Stable
Diffusion (SD), image manipulation technologies have advanced rapidly, posing
significant challenges to image forensics. However, existing image forgery
localization methods, which heavily rely on labor-intensive and costly
annotated data, are struggling to keep pace with these emerging image
manipulation technologies. To address these challenges, we are the first to
integrate both image generation and powerful perceptual capabilities of SD into
an image forensic framework, enabling more efficient and accurate forgery
localization. First, we theoretically show that the multi-modal architecture of
SD can be conditioned on forgery-related information, enabling the model to
inherently output forgery localization results. Then, building on this
foundation, we specifically leverage the multimodal framework of Stable
DiffusionV3 (SD3) to enhance forgery localization performance.We leverage the
multi-modal processing capabilities of SD3 in the latent space by treating
image forgery residuals -- high-frequency signals extracted using specific
highpass filters -- as an explicit modality. This modality is fused into the
latent space during training to enhance forgery localization performance.
Notably, our method fully preserves the latent features extracted by SD3,
thereby retaining the rich semantic information of the input image.
Experimental results show that our framework achieves up to 12% improvements in
performance on widely used benchmarking datasets compared to current
state-of-the-art image forgery localization models. Encouragingly, the model
demonstrates strong performance on forensic tasks involving real-world document
forgery images and natural scene forging images, even when such data were
entirely unseen during training.

</details>


### [27] [Grounding Multimodal Large Language Models with Quantitative Skin Attributes: A Retrieval Study](https://arxiv.org/abs/2508.20188)
*Max Torop,Masih Eskandar,Nicholas Kurtansky,Jinyang Liu,Jochen Weber,Octavia Camps,Veronica Rotemberg,Jennifer Dy,Kivanc Kose*

Main category: cs.CV

TL;DR: 该研究探索结合多模态大语言模型（MLLMs）和定量属性，以提高皮肤病诊断AI模型的解释性，并通过图像检索案例研究验证了MLLM嵌入空间与这些属性的关联。


<details>
  <summary>Details</summary>
Motivation: 尽管AI模型在皮肤病诊断中表现出色，但其缺乏可解释性，这严重阻碍了它们在临床实践中的应用。因此，需要显著提高模型预测的解释性。

Method: 研究结合了两种方法：利用MLLMs通过自然语言提供诊断推理，以及利用与病变外观相关的定量属性（如病变面积）来提高预测的解释性。具体而言，他们通过微调MLLM以从图像中预测这些定量属性的值，将MLLM的嵌入空间与这些属性关联起来。通过使用SLICE-3D数据集进行属性特定的基于内容的图像检索案例研究来评估这种关联。

Result: 研究提供了证据，表明通过微调以预测图像中的属性值，MLLM的嵌入空间可以与这些定量属性建立关联。

Conclusion: 结合多模态大语言模型和定量属性是一种有前景的方法，可以显著提高皮肤病诊断AI模型的解释性，为临床应用铺平道路。

Abstract: Artificial Intelligence models have demonstrated significant success in
diagnosing skin diseases, including cancer, showing the potential to assist
clinicians in their analysis. However, the interpretability of model
predictions must be significantly improved before they can be used in practice.
To this end, we explore the combination of two promising approaches: Multimodal
Large Language Models (MLLMs) and quantitative attribute usage. MLLMs offer a
potential avenue for increased interpretability, providing reasoning for
diagnosis in natural language through an interactive format. Separately, a
number of quantitative attributes that are related to lesion appearance (e.g.,
lesion area) have recently been found predictive of malignancy with high
accuracy. Predictions grounded as a function of such concepts have the
potential for improved interpretability. We provide evidence that MLLM
embedding spaces can be grounded in such attributes, through fine-tuning to
predict their values from images. Concretely, we evaluate this grounding in the
embedding space through an attribute-specific content-based image retrieval
case study using the SLICE-3D dataset.

</details>


### [28] [Enhancing Automatic Modulation Recognition With a Reconstruction-Driven Vision Transformer Under Limited Labels](https://arxiv.org/abs/2508.20193)
*Hossein Ahmadi,Banafsheh Saffari*

Main category: cs.CV

TL;DR: 本文提出了一种统一的Vision Transformer (ViT) 框架，通过结合监督学习、自监督学习和重建目标，为自动调制识别（AMR）提供了一种标签高效且鲁棒的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的AMR解决方案通常依赖于大量的标注数据集或多阶段训练流程，这限制了它们在实际应用中的可扩展性和泛化能力。

Method: 该方法构建了一个统一的ViT框架，包含一个ViT编码器、一个轻量级卷积解码器和一个线性分类器。它整合了监督、自监督和重建目标。重建分支将增强信号映射回原始信号，使编码器能够学习细粒度的I/Q结构。这种策略在预训练阶段促进了鲁棒、有区分度的特征学习，并在微调阶段通过部分标签监督实现了有限标签下的有效分类。

Result: 在RML2018.01A数据集上，该方法在低标签条件下优于监督CNN和ViT基线。仅用15-20%的标注数据即可达到ResNet级别的准确性，并在不同信噪比（SNR）水平下保持了强大的性能。

Conclusion: 该框架为AMR提供了一个简单、可泛化且标签高效的解决方案。

Abstract: Automatic modulation recognition (AMR) is critical for cognitive radio,
spectrum monitoring, and secure wireless communication. However, existing
solutions often rely on large labeled datasets or multi-stage training
pipelines, which limit scalability and generalization in practice. We propose a
unified Vision Transformer (ViT) framework that integrates supervised,
self-supervised, and reconstruction objectives. The model combines a ViT
encoder, a lightweight convolutional decoder, and a linear classifier; the
reconstruction branch maps augmented signals back to their originals, anchoring
the encoder to fine-grained I/Q structure. This strategy promotes robust,
discriminative feature learning during pretraining, while partial label
supervision in fine-tuning enables effective classification with limited
labels. On the RML2018.01A dataset, our approach outperforms supervised CNN and
ViT baselines in low-label regimes, approaches ResNet-level accuracy with only
15-20% labeled data, and maintains strong performance across varying SNR
levels. Overall, the framework provides a simple, generalizable, and
label-efficient solution for AMR.

</details>


### [29] [InfinityHuman: Towards Long-Term Audio-Driven Human](https://arxiv.org/abs/2508.20210)
*Xiaodi Li,Pan Xie,Yi Ren,Qijun Gan,Chen Zhang,Fangyuan Kong,Xiang Yin,Bingyue Peng,Zehuan Yuan*

Main category: cs.CV

TL;DR: InfinityHuman提出了一种粗到细的框架，通过姿态引导的细化器和手部特定奖励机制，生成高分辨率、长时程、外观一致且手部动作自然的音频驱动人体动画。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动人体动画方法在生成高分辨率、长时程视频时面临挑战，表现为：使用重叠运动帧导致错误累积，引起身份漂移、色彩偏移和场景不稳定；手部动作建模不佳，导致明显扭曲和与音频不同步。

Method: 本文提出了InfinityHuman，一个粗到细的框架：首先生成音频同步的表示，然后通过姿态引导的细化器逐步将其精炼为高分辨率、长时程视频。姿态引导的细化器利用稳定的姿态和初始帧作为视觉锚点，减少漂移并改善唇形同步。此外，引入了一个用高质量手部运动数据训练的手部特定奖励机制，以提高语义准确性和手势真实感。

Result: 在EMTD和HDTF数据集上的实验表明，InfinityHuman在视频质量、身份保持、手部准确性和唇形同步方面均达到了最先进的性能。消融研究进一步证实了每个模块的有效性。

Conclusion: InfinityHuman通过其粗到细的框架、姿态引导的细化器和手部特定奖励机制，成功克服了现有音频驱动人体动画方法的局限性，能够生成高质量、长时程、外观一致且手部动作逼真的人体动画。

Abstract: Audio-driven human animation has attracted wide attention thanks to its
practical applications. However, critical challenges remain in generating
high-resolution, long-duration videos with consistent appearance and natural
hand motions. Existing methods extend videos using overlapping motion frames
but suffer from error accumulation, leading to identity drift, color shifts,
and scene instability. Additionally, hand movements are poorly modeled,
resulting in noticeable distortions and misalignment with the audio. In this
work, we propose InfinityHuman, a coarse-to-fine framework that first generates
audio-synchronized representations, then progressively refines them into
high-resolution, long-duration videos using a pose-guided refiner. Since pose
sequences are decoupled from appearance and resist temporal degradation, our
pose-guided refiner employs stable poses and the initial frame as a visual
anchor to reduce drift and improve lip synchronization. Moreover, to enhance
semantic accuracy and gesture realism, we introduce a hand-specific reward
mechanism trained with high-quality hand motion data. Experiments on the EMTD
and HDTF datasets show that InfinityHuman achieves state-of-the-art performance
in video quality, identity preservation, hand accuracy, and lip-sync. Ablation
studies further confirm the effectiveness of each module. Code will be made
public.

</details>


### [30] [Towards Inclusive Communication: A Unified LLM-Based Framework for Sign Language, Lip Movements, and Audio Understanding](https://arxiv.org/abs/2508.20476)
*Jeong Hun Yeo,Hyeongseop Rha,Sungjune Park,Junil Won,Yong Man Ro*

Main category: cs.CV

TL;DR: 本文提出了首个统一框架，能够处理手语、唇部动作和音频的多种组合，以生成口语文本，并在多项任务上达到或超越了最先进的专业模型，同时强调了唇部动作对手语翻译的重要性。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）对听障人士不适用。尽管手语翻译（SLT）和视觉语音识别（VSR）取得了进展，但它们通常是独立研究的，缺乏统一的框架来整合这些模态，以实现更有效的无声通信，并探索模态间的协同作用。

Method: 引入了一个统一的、与模态无关的架构，旨在有效处理异构输入。该方法侧重于探索模态间的协同作用（特别是唇部动作在手语理解中的作用），并力求在性能上与或超越专门任务的最先进模型。

Result: 该框架在手语翻译（SLT）、视觉语音识别（VSR）、自动语音识别（ASR）和视听语音识别（AVSR）等任务上，取得了与或优于现有最先进专业模型的性能。此外，分析表明，将唇部动作作为独立模态进行显式建模能显著提高手语翻译的性能。

Conclusion: 所提出的统一框架在处理多模态（手语、唇部、音频）语音到文本生成方面表现出色，不仅实现了卓越的性能，还揭示了唇部动作作为非手动线索在手语理解中的关键作用。

Abstract: Audio is the primary modality for human communication and has driven the
success of Automatic Speech Recognition (ASR) technologies. However, such
systems remain inherently inaccessible to individuals who are deaf or hard of
hearing. Visual alternatives such as sign language and lip reading offer
effective substitutes, and recent advances in Sign Language Translation (SLT)
and Visual Speech Recognition (VSR) have improved audio-less communication.
Yet, these modalities have largely been studied in isolation, and their
integration within a unified framework remains underexplored. In this paper, we
introduce the first unified framework capable of handling diverse combinations
of sign language, lip movements, and audio for spoken-language text generation.
We focus on three main objectives: (i) designing a unified, modality-agnostic
architecture capable of effectively processing heterogeneous inputs; (ii)
exploring the underexamined synergy among modalities, particularly the role of
lip movements as non-manual cues in sign language comprehension; and (iii)
achieving performance on par with or superior to state-of-the-art models
specialized for individual tasks. Building on this framework, we achieve
performance on par with or better than task-specific state-of-the-art models
across SLT, VSR, ASR, and AVSR. Furthermore, our analysis reveals that
explicitly modeling lip movements as a separate modality significantly improves
SLT performance.

</details>


### [31] [Spherical Vision Transformers for Audio-Visual Saliency Prediction in 360-Degree Videos](https://arxiv.org/abs/2508.20221)
*Mert Cokelek,Halit Ozsoy,Nevrez Imamoglu,Cagri Ozcinar,Inci Ayhan,Erkut Erdem,Aykut Erdem*

Main category: cs.CV

TL;DR: 本研究针对全景视频（ODVs）的视觉显著性预测问题，构建了一个新的包含空间音频的眼动追踪数据集YT360-EyeTracking，并提出了两个基于Vision Transformer的新模型SalViT360和SalViT360-AV。实验结果表明，所提模型在预测360度场景中的观众注意力方面显著优于现有方法，强调了空间音频在显著性预测中的重要性。


<details>
  <summary>Details</summary>
Motivation: 全景视频（ODVs）通过提供全视场（FOV）正在重新定义虚拟现实（VR）中的观看体验，并引入了与观看者视角对齐的空间音频维度。然而，目前缺乏用于360度视听显著性预测的综合数据集，尤其是在处理球形畸变和整合空间音频方面。

Method: 研究首先构建了一个新的数据集YT360-EyeTracking，包含81个在不同视听条件下观察到的全景视频。在此基础上，提出了两个新颖的显著性预测模型：SalViT360，一个基于Vision Transformer的框架，配备了球形几何感知时空注意力层；以及SalViT360-AV，它进一步整合了由音频输入调节的Transformer适配器。

Result: 在包括YT360-EyeTracking在内的多个基准数据集上的结果表明，SalViT360和SalViT360-AV在预测360度场景中的观众注意力方面显著优于现有方法。

Conclusion: 研究结果表明，在模型架构中整合空间音频线索对于全景视频中准确的显著性预测至关重要。

Abstract: Omnidirectional videos (ODVs) are redefining viewer experiences in virtual
reality (VR) by offering an unprecedented full field-of-view (FOV). This study
extends the domain of saliency prediction to 360-degree environments,
addressing the complexities of spherical distortion and the integration of
spatial audio. Contextually, ODVs have transformed user experience by adding a
spatial audio dimension that aligns sound direction with the viewer's
perspective in spherical scenes. Motivated by the lack of comprehensive
datasets for 360-degree audio-visual saliency prediction, our study curates
YT360-EyeTracking, a new dataset of 81 ODVs, each observed under varying
audio-visual conditions. Our goal is to explore how to utilize audio-visual
cues to effectively predict visual saliency in 360-degree videos. Towards this
aim, we propose two novel saliency prediction models: SalViT360, a
vision-transformer-based framework for ODVs equipped with spherical
geometry-aware spatio-temporal attention layers, and SalViT360-AV, which
further incorporates transformer adapters conditioned on audio input. Our
results on a number of benchmark datasets, including our YT360-EyeTracking,
demonstrate that SalViT360 and SalViT360-AV significantly outperform existing
methods in predicting viewer attention in 360-degree scenes. Interpreting these
results, we suggest that integrating spatial audio cues in the model
architecture is crucial for accurate saliency prediction in omnidirectional
videos. Code and dataset will be available at
https://cyberiada.github.io/SalViT360.

</details>


### [32] [Dino U-Net: Exploiting High-Fidelity Dense Features from Foundation Models for Medical Image Segmentation](https://arxiv.org/abs/2508.20909)
*Yifan Gao,Haoyue Li,Feng Yuan,Xiaosong Wang,Xin Gao*

Main category: cs.CV

TL;DR: Dino U-Net是一种新颖的编码器-解码器架构，它利用DINOv3视觉基础模型的密集特征，并通过特殊适配器和保真度感知投影模块，在七个不同的医学图像分割数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练在自然图像上的基础模型为医学图像分割提供了强大的范式，但如何有效地将其学习到的表示转移到精确的临床应用中仍然是一个挑战。

Method: 该研究提出了Dino U-Net，其编码器基于冻结的DINOv3主干网络，并引入了一个专门的适配器来融合DINOv3的语义特征与低级空间细节。为了在降维过程中保持表示的质量，设计了一个新的保真度感知投影模块（FAPM）来优化和投影特征给解码器。

Result: Dino U-Net在七个多样化的公共医学图像分割数据集上实现了最先进的性能，在各种成像模态中始终优于以前的方法。该框架具有高度可扩展性，分割精度随着主干模型尺寸的增加（最高达70亿参数变体）而持续提高。

Conclusion: 利用通用基础模型中卓越的、密集预训练的特征，为提高医学图像分割的准确性提供了一种高效且参数高效的方法。

Abstract: Foundation models pre-trained on large-scale natural image datasets offer a
powerful paradigm for medical image segmentation. However, effectively
transferring their learned representations for precise clinical applications
remains a challenge. In this work, we propose Dino U-Net, a novel
encoder-decoder architecture designed to exploit the high-fidelity dense
features of the DINOv3 vision foundation model. Our architecture introduces an
encoder built upon a frozen DINOv3 backbone, which employs a specialized
adapter to fuse the model's rich semantic features with low-level spatial
details. To preserve the quality of these representations during dimensionality
reduction, we design a new fidelity-aware projection module (FAPM) that
effectively refines and projects the features for the decoder. We conducted
extensive experiments on seven diverse public medical image segmentation
datasets. Our results show that Dino U-Net achieves state-of-the-art
performance, consistently outperforming previous methods across various imaging
modalities. Our framework proves to be highly scalable, with segmentation
accuracy consistently improving as the backbone model size increases up to the
7-billion-parameter variant. The findings demonstrate that leveraging the
superior, dense-pretrained features from a general-purpose foundation model
provides a highly effective and parameter-efficient approach to advance the
accuracy of medical image segmentation. The code is available at
https://github.com/yifangao112/DinoUNet.

</details>


### [33] [A Novel Framework for Automated Explain Vision Model Using Vision-Language Models](https://arxiv.org/abs/2508.20227)
*Phu-Vinh Nguyen,Tan-Hanh Pham,Chris Ngo,Truong Son Hy*

Main category: cs.CV

TL;DR: 本文提出一种基于视觉-语言模型的管道，用于在样本和数据集层面解释视觉模型，旨在发现故障案例并深入理解模型行为。


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型开发主要关注性能指标而非可解释性，且现有XAI方法多为逐样本解释，对模型在大型数据集上的整体行为解释不足。理解模型整体行为对防止偏见和识别模型趋势与模式至关重要。

Method: 本文利用视觉-语言模型（VLM），提出一个管道（pipeline），旨在同时在样本级别和数据集级别解释视觉模型。

Result: 所提出的管道能够以最小的努力发现视觉模型的故障案例，并深入了解模型行为。

Conclusion: 该方法将视觉模型开发与可解释人工智能（xAI）分析相结合，有助于推动图像分析，并为模型行为提供有意义的解释。

Abstract: The development of many vision models mainly focuses on improving their
performance using metrics such as accuracy, IoU, and mAP, with less attention
to explainability due to the complexity of applying xAI methods to provide a
meaningful explanation of trained models. Although many existing xAI methods
aim to explain vision models sample-by-sample, methods explaining the general
behavior of vision models, which can only be captured after running on a large
dataset, are still underexplored. Furthermore, understanding the behavior of
vision models on general images can be very important to prevent biased
judgments and help identify the model's trends and patterns. With the
application of Vision-Language Models, this paper proposes a pipeline to
explain vision models at both the sample and dataset levels. The proposed
pipeline can be used to discover failure cases and gain insights into vision
models with minimal effort, thereby integrating vision model development with
xAI analysis to advance image analysis.

</details>


### [34] [ATMS-KD: Adaptive Temperature and Mixed Sample Knowledge Distillation for a Lightweight Residual CNN in Agricultural Embedded Systems](https://arxiv.org/abs/2508.20232)
*Mohamed Ohamouddou,Said Ohamouddou,Abdellatif El Afia,Rafik Lasri*

Main category: cs.CV

TL;DR: 本研究提出了ATMS-KD（自适应温度和混合样本知识蒸馏）框架，用于在资源受限的农业环境中开发轻量级CNN模型。该框架结合了自适应温度调度和混合样本增强，实现了从大型教师模型到轻量级学生模型的高效知识迁移，显著提升了农业图像分类的准确性并降低了推理延迟。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的农业环境中，需要开发轻量级CNN模型以适应实际部署。现有方法可能无法有效将知识从大型模型迁移到小型模型，同时保持高精度和低延迟。

Method: 本研究提出了ATMS-KD框架，该框架结合了自适应温度调度和混合样本增强。使用MobileNetV3 Large（5.7M参数）作为教师模型，并评估了三种轻量级残差CNN学生配置（Compact 1.3M、Standard 2.4M、Enhanced 3.8M参数）。数据集采用摩洛哥农业田地中收集的大马士革玫瑰图像，用于玫瑰成熟度分类。通过与直接训练方法和十一种现有知识蒸馏方法进行比较来评估性能。

Result: ATMS-KD框架在所有学生模型上均实现了超过96.7%的验证准确率，显著优于直接训练方法（95-96%）。其中，Compact模型通过ATMS-KD达到了97.11%的准确率，比次优方法提高了1.60个百分点，同时保持了最低的推理延迟（72.19毫秒）。所有配置的知识保留率均超过99%。

Conclusion: ATMS-KD是一个高效的框架，能够为农业应用开发轻量级且高精度的CNN模型。它通过自适应温度和混合样本增强，成功地将知识从大型教师模型迁移到不同容量的轻量级学生模型，实现了卓越的准确性和低推理延迟。

Abstract: This study proposes ATMS-KD (Adaptive Temperature and Mixed-Sample Knowledge
Distillation), a novel framework for developing lightweight CNN models suitable
for resource-constrained agricultural environments. The framework combines
adaptive temperature scheduling with mixed-sample augmentation to transfer
knowledge from a MobileNetV3 Large teacher model (5.7\,M parameters) to
lightweight residual CNN students. Three student configurations were evaluated:
Compact (1.3\,M parameters), Standard (2.4\,M parameters), and Enhanced (3.8\,M
parameters). The dataset used in this study consists of images of \textit{Rosa
damascena} (Damask rose) collected from agricultural fields in the Dades Oasis,
southeastern Morocco, providing a realistic benchmark for agricultural computer
vision applications under diverse environmental conditions. Experimental
evaluation on the Damascena rose maturity classification dataset demonstrated
significant improvements over direct training methods. All student models
achieved validation accuracies exceeding 96.7\% with ATMS-KD compared to
95--96\% with direct training. The framework outperformed eleven established
knowledge distillation methods, achieving 97.11\% accuracy with the compact
model -- a 1.60 percentage point improvement over the second-best approach
while maintaining the lowest inference latency of 72.19\,ms. Knowledge
retention rates exceeded 99\% for all configurations, demonstrating effective
knowledge transfer regardless of student model capacity.

</details>


### [35] [Linking heterogeneous microstructure informatics with expert characterization knowledge through customized and hybrid vision-language representations for industrial qualification](https://arxiv.org/abs/2508.20243)
*Mutahar Safdar,Gentry Wood,Max Zimmermann,Guy Lamouche,Priti Wanjara,Yaoyao Fiona Zhao*

Main category: cs.CV

TL;DR: 本研究提出一个新颖的框架，通过结合微观结构信息学和专家表征知识，利用定制的混合视觉-语言表征（VLRs）实现先进材料的零样本质量鉴定。


<details>
  <summary>Details</summary>
Motivation: 先进材料（特别是通过非传统增材制造工艺生产的异质结构）的快速可靠鉴定是工业制造中的一个瓶颈。

Method: 该框架通过深度语义分割和预训练多模态模型（CLIP和FLAVA）将视觉微观结构数据和文本专家评估编码到共享表征中。为克服通用嵌入的局限性，研究开发了一种定制的基于相似性的表征，其中包含来自专家标注图像及其文本描述的正负参考。通过净相似度评分实现对未见微观结构的零样本分类，并使用Z分数归一化调整相似度分数以提高对齐和分类效果。

Result: 在增材制造金属基复合材料数据集上的验证表明，该框架能够区分可接受和有缺陷的样本。FLAVA模型提供更高的视觉敏感性，而CLIP模型与文本标准保持一致。Z分数归一化能更有效地对齐和分类。

Conclusion: 该方法通过实现人机协同决策而无需特定任务模型再训练，增强了鉴定流程的可追溯性和可解释性。通过促进原始数据和专家知识之间的语义互操作性，为工程信息学中可扩展和领域适应的鉴定策略做出了贡献。

Abstract: Rapid and reliable qualification of advanced materials remains a bottleneck
in industrial manufacturing, particularly for heterogeneous structures produced
via non-conventional additive manufacturing processes. This study introduces a
novel framework that links microstructure informatics with a range of expert
characterization knowledge using customized and hybrid vision-language
representations (VLRs). By integrating deep semantic segmentation with
pre-trained multi-modal models (CLIP and FLAVA), we encode both visual
microstructural data and textual expert assessments into shared
representations. To overcome limitations in general-purpose embeddings, we
develop a customized similarity-based representation that incorporates both
positive and negative references from expert-annotated images and their
associated textual descriptions. This allows zero-shot classification of
previously unseen microstructures through a net similarity scoring approach.
Validation on an additively manufactured metal matrix composite dataset
demonstrates the framework's ability to distinguish between acceptable and
defective samples across a range of characterization criteria. Comparative
analysis reveals that FLAVA model offers higher visual sensitivity, while the
CLIP model provides consistent alignment with the textual criteria. Z-score
normalization adjusts raw unimodal and cross-modal similarity scores based on
their local dataset-driven distributions, enabling more effective alignment and
classification in the hybrid vision-language framework. The proposed method
enhances traceability and interpretability in qualification pipelines by
enabling human-in-the-loop decision-making without task-specific model
retraining. By advancing semantic interoperability between raw data and expert
knowledge, this work contributes toward scalable and domain-adaptable
qualification strategies in engineering informatics.

</details>


### [36] [MedNet-PVS: A MedNeXt-Based Deep Learning Model for Automated Segmentation of Perivascular Spaces](https://arxiv.org/abs/2508.20256)
*Zhen Xuen Brandon Low,Rory Zhang,Hang Min,William Pham,Lucy Vivash,Jasmine Moses,Miranda Lynch,Karina Dorfman,Cassandra Marotta,Shaun Koh,Jacob Bunyamin,Ella Rowsthorn,Alex Jarema,Himashi Peiris,Zhaolin Chen,Sandy R. Shultz,David K. Wright,Dexiao Kong,Sharon L. Naismith,Terence J. O'Brien,Ying Xia,Meng Law,Benjamin Sinclair*

Main category: cs.CV

TL;DR: 本研究将MedNeXt-L-k5模型应用于自动脉管周围间隙（PVS）分割，在T2加权图像上实现了高精度，并展示了其在不同MRI数据集上的泛化能力，但未超越nnU-Net，表明Transformer中的注意力机制并非PVS分割高精度的必要条件。


<details>
  <summary>Details</summary>
Motivation: 手动分割PVS耗时且可靠性中等，而现有自动化深度学习模型性能不佳，难以在多样化的临床和研究MRI数据集中泛化。PVS被认为是脑小血管病、阿尔茨海默病、中风和衰老相关神经退行性疾病的生物标志物，因此需要更高效、准确的自动化分割方法。

Method: 研究人员改编了MedNeXt-L-k5（一种受Transformer启发的3D编码器-解码器卷积网络）用于PVS的自动化分割。训练了两个模型：一个使用来自人类连接组计划-老化（HCP-Aging）数据集的200张同质T2加权（T2w）MRI扫描图像，另一个使用来自七项研究和六台扫描仪的40张异质T1加权（T1w）MRI图像。模型性能通过内部5折交叉验证（5FCV）和留一站点交叉验证（LOSOCV）进行评估。

Result: 在HCP-Aging数据集的T2w图像上训练的MedNeXt-L-k5模型在白质（WM）中实现了0.88+/-0.06的体素级Dice分数，与该数据集报告的评估者间可靠性相当，是文献中报告的最高分数。在HCP-Aging数据集的T1w图像上训练的相同模型在WM中实现了明显较低的0.58+/-0.09的Dice分数。在LOSOCV下，模型在WM中体素级Dice分数为0.38+/-0.16，在基底节（BG）中为0.35+/-0.12；在WM中聚类级Dice分数为0.61+/-0.19，在BG中为0.62+/-0.21。MedNeXt-L-k5提供了一种高效的PVS分割解决方案，但其性能未超越nnU-Net。

Conclusion: MedNeXt-L-k5为跨多样化T1w和T2w MRI数据集的自动化PVS分割提供了一个高效的解决方案。然而，MedNeXt-L-k5未能超越nnU-Net，这表明在Transformer启发模型中提供全局上下文的基于注意力机制对于PVS分割的高精度并非必需。

Abstract: Enlarged perivascular spaces (PVS) are increasingly recognized as biomarkers
of cerebral small vessel disease, Alzheimer's disease, stroke, and
aging-related neurodegeneration. However, manual segmentation of PVS is
time-consuming and subject to moderate inter-rater reliability, while existing
automated deep learning models have moderate performance and typically fail to
generalize across diverse clinical and research MRI datasets. We adapted
MedNeXt-L-k5, a Transformer-inspired 3D encoder-decoder convolutional network,
for automated PVS segmentation. Two models were trained: one using a
homogeneous dataset of 200 T2-weighted (T2w) MRI scans from the Human
Connectome Project-Aging (HCP-Aging) dataset and another using 40 heterogeneous
T1-weighted (T1w) MRI volumes from seven studies across six scanners. Model
performance was evaluated using internal 5-fold cross validation (5FCV) and
leave-one-site-out cross validation (LOSOCV). MedNeXt-L-k5 models trained on
the T2w images of the HCP-Aging dataset achieved voxel-level Dice scores of
0.88+/-0.06 (white matter, WM), comparable to the reported inter-rater
reliability of that dataset, and the highest yet reported in the literature.
The same models trained on the T1w images of the HCP-Aging dataset achieved a
substantially lower Dice score of 0.58+/-0.09 (WM). Under LOSOCV, the model had
voxel-level Dice scores of 0.38+/-0.16 (WM) and 0.35+/-0.12 (BG), and
cluster-level Dice scores of 0.61+/-0.19 (WM) and 0.62+/-0.21 (BG).
MedNeXt-L-k5 provides an efficient solution for automated PVS segmentation
across diverse T1w and T2w MRI datasets. MedNeXt-L-k5 did not outperform the
nnU-Net, indicating that the attention-based mechanisms present in
transformer-inspired models to provide global context are not required for high
accuracy in PVS segmentation.

</details>


### [37] [Plug-in Feedback Self-adaptive Attention in CLIP for Training-free Open-Vocabulary Segmentation](https://arxiv.org/abs/2508.20265)
*Zhixiang Chi,Yanan Wu,Li Gu,Huan Liu,Ziqiang Wang,Yang Zhang,Yang Wang,Konstantinos N. Plataniotis*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练、反馈驱动的自适应框架，通过将基于输出的补丁级对应关系反馈到中间注意力层，以增强CLIP在开放词汇分割中的空间一致性和语义一致性，从而解决其定位能力差和语义不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: CLIP虽然具有强大的视觉-文本对齐能力，但在开放词汇分割中因定位能力差而表现不佳。现有方法通过修改中间注意力来增强空间一致性，但这种一致性未能有效传播到最终输出，且中间注意力缺乏与文本表示的直接交互，限制了CLIP的潜力。

Method: 我们提出了一种无需训练、反馈驱动的自适应框架，将基于输出的补丁级对应关系反馈到中间注意力。该方法利用模型的输出作为更强的空间一致性先验，以增强内部表示和最终预测之间的语义一致性。关键模块包括注意力隔离、基于置信度的稀疏适应剪枝和适应集成。它作为一个即插即用模块，可无缝集成到现有方法中。

Result: 该方法作为即插即用模块，成功集成到四种最先进的方法和三种骨干网络（ViT-B、ViT-L、ViT-H）中，并跨多种注意力类型（Q-K、self-self以及与MAE、SAM和DINO增强的Proxy）进行了验证。结果表明，它在八个基准测试中持续提升了性能。

Conclusion: 所提出的无需训练、反馈驱动的自适应框架通过利用模型输出作为更强的空间一致性先验，有效增强了CLIP的语义一致性和空间定位能力，从而显著提升了其在开放词汇分割任务中的表现。

Abstract: CLIP exhibits strong visual-textual alignment but struggle with
open-vocabulary segmentation due to poor localization. Prior methods enhance
spatial coherence by modifying intermediate attention. But, this coherence
isn't consistently propagated to the final output due to subsequent operations
such as projections. Additionally, intermediate attention lacks direct
interaction with text representations, such semantic discrepancy limits the
full potential of CLIP.
  In this work, we propose a training-free, feedback-driven self-adaptive
framework that adapts output-based patch-level correspondences back to the
intermediate attention. The output predictions, being the culmination of the
model's processing, encapsulate the most comprehensive visual and textual
semantics about each patch. Our approach enhances semantic consistency between
internal representations and final predictions by leveraging the model's
outputs as a stronger spatial coherence prior. We design key modules, including
attention isolation, confidence-based pruning for sparse adaptation, and
adaptation ensemble, to effectively feedback the output coherence cues. Our
method functions as a plug-in module, seamlessly integrating into four
state-of-the-art approaches with three backbones (ViT-B, ViT-L, ViT-H). We
further validate our framework across multiple attention types (Q-K, self-self,
and Proxy augmented with MAE, SAM, and DINO). Our approach consistently
improves their performance across eight benchmarks.

</details>


### [38] [How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding](https://arxiv.org/abs/2508.20279)
*Zhuoran Yu,Yong Jae Lee*

Main category: cs.CV

TL;DR: 本研究提出了一个探测框架，系统分析多模态大语言模型（MLLMs）的层级处理动态，揭示了其视觉、文本整合和推理的阶段性结构，并提供了一种轻量级、模型无关的分析方法。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）在视觉-语言任务中表现出色，但其内部处理机制，特别是跨层处理视觉和文本输入的方式，仍未被充分探索。

Method: 研究引入了一个探测框架，通过训练线性分类器来预测每一层提取的token嵌入的细粒度视觉类别，并使用标准化锚定问题。为揭示不同层的功能角色，该框架在三种受控提示变体下（词汇变体、语义否定变体、输出格式变体）评估探测器。此框架应用于LLaVA-1.5、LLaVA-Next-LLaMA-3和Qwen2-VL模型。

Result: 研究发现MLLMs存在一致的阶段性结构：早期层执行视觉基础，中间层支持词汇整合和语义推理，最终层准备任务特定输出。这种整体阶段性结构在视觉分词、指令微调数据和预训练语料库变化时保持稳定，但每个阶段的具体层分配随基础LLM架构变化而显著改变。

Conclusion: 本研究为多模态大语言模型（MLLMs）的层级组织结构提供了一个统一的视角，并提供了一种轻量级、模型无关的方法来分析多模态表征的动态。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong performance
across a wide range of vision-language tasks, yet their internal processing
dynamics remain underexplored. In this work, we introduce a probing framework
to systematically analyze how MLLMs process visual and textual inputs across
layers. We train linear classifiers to predict fine-grained visual categories
(e.g., dog breeds) from token embeddings extracted at each layer, using a
standardized anchor question. To uncover the functional roles of different
layers, we evaluate these probes under three types of controlled prompt
variations: (1) lexical variants that test sensitivity to surface-level
changes, (2) semantic negation variants that flip the expected answer by
modifying the visual concept in the prompt, and (3) output format variants that
preserve reasoning but alter the answer format. Applying our framework to
LLaVA-1.5, LLaVA-Next-LLaMA-3, and Qwen2-VL, we identify a consistent
stage-wise structure in which early layers perform visual grounding, middle
layers support lexical integration and semantic reasoning, and final layers
prepare task-specific outputs. We further show that while the overall
stage-wise structure remains stable across variations in visual tokenization,
instruction tuning data, and pretraining corpus, the specific layer allocation
to each stage shifts notably with changes in the base LLM architecture. Our
findings provide a unified perspective on the layer-wise organization of MLLMs
and offer a lightweight, model-agnostic approach for analyzing multimodal
representation dynamics.

</details>


### [39] [Disentangling Latent Embeddings with Sparse Linear Concept Subspaces (SLiCS)](https://arxiv.org/abs/2508.20322)
*Zhi Li,Hau Phan,Matthew Emigh,Austin J. Brockmeier*

Main category: cs.CV

TL;DR: 本文提出SLiCS方法，通过监督字典学习将视觉-语言协同嵌入空间解耦为概念特异性子空间，从而实现更精确的概念过滤图像检索和条件生成。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言协同嵌入（如CLIP）包含丰富的语义信息，但作者假设这些嵌入可以被解耦，以分离复杂场景内容的信息，形成多个概念特异性分量向量。

Method: 提出一种监督字典学习方法，通过稀疏、非负组合的字典原子组来估计线性合成模型，其组级活动与多标签信息匹配。每个概念特异性分量是非负组合的原子。字典通过新型交替优化进行优化。利用文本协同嵌入，找到语义描述，并通过无监督字典学习利用零样本分类提供实例级多标签。

Result: SLiCS提供的解耦嵌入实现了更精确的概念过滤图像检索（以及使用图像到提示的条件生成）。该方法适用于CLIP、TiTok的压缩自编码器嵌入和DINOv2的自监督潜在嵌入。定量和定性结果均表明，对于所有嵌入，概念过滤图像检索的精度均有所提高。

Conclusion: 通过将视觉-语言协同嵌入解耦为稀疏线性概念子空间（SLiCS），可以显著提高概念过滤图像检索的精度，并可应用于多种现有的嵌入模型。

Abstract: Vision-language co-embedding networks, such as CLIP, provide a latent
embedding space with semantic information that is useful for downstream tasks.
We hypothesize that the embedding space can be disentangled to separate the
information on the content of complex scenes by decomposing the embedding into
multiple concept-specific component vectors that lie in different subspaces. We
propose a supervised dictionary learning approach to estimate a linear
synthesis model consisting of sparse, non-negative combinations of groups of
vectors in the dictionary (atoms), whose group-wise activity matches the
multi-label information. Each concept-specific component is a non-negative
combination of atoms associated to a label. The group-structured dictionary is
optimized through a novel alternating optimization with guaranteed convergence.
Exploiting the text co-embeddings, we detail how semantically meaningful
descriptions can be found based on text embeddings of words best approximated
by a concept's group of atoms, and unsupervised dictionary learning can exploit
zero-shot classification of training set images using the text embeddings of
concept labels to provide instance-wise multi-labels. We show that the
disentangled embeddings provided by our sparse linear concept subspaces (SLiCS)
enable concept-filtered image retrieval (and conditional generation using
image-to-prompt) that is more precise. We also apply SLiCS to highly-compressed
autoencoder embeddings from TiTok and the latent embedding from self-supervised
DINOv2. Quantitative and qualitative results highlight the improved precision
of the concept-filtered image retrieval for all embeddings.

</details>


### [40] [MedFoundationHub: A Lightweight and Secure Toolkit for Deploying Medical Vision Language Foundation Models](https://arxiv.org/abs/2508.20345)
*Xiao Li,Yanfan Zhu,Ruining Deng,Wei-Qi Wei,Yu Wang,Shilin Zhao,Yaohong Wang,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: MedFoundationHub是一个图形用户界面工具包，旨在安全、便捷地部署和使用医疗视觉-语言模型（VLMs），以解决其隐私和安全问题。通过专家评估，发现现有VLMs在临床应用中仍存在准确性和一致性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 医疗视觉-语言模型（VLMs）在临床应用中潜力巨大，但存在严重的隐私和安全风险，如受保护健康信息（PHI）泄露和网络威胁。因此，需要一个安全、易用的平台来部署和管理这些模型。

Method: 本文提出了MedFoundationHub，一个图形用户界面（GUI）工具包。它允许医生无需编程即可手动选择和使用模型，支持工程师以即插即用方式高效部署模型（无缝集成Hugging Face开源模型），并通过Docker编排实现操作系统无关的隐私保护推理部署。该系统仅需一台配备NVIDIA A6000 GPU的离线本地工作站。研究人员邀请了经过认证的病理学家，使用MedFoundationHub部署并评估了五种最先进的VLMs（Google-MedGemma3-4B, Qwen2-VL-7B-Instruct, Qwen2.5-VL-7B-Instruct, LLaVA-1.5-7B/13B），涵盖结肠和肾脏病例，共产生了1015个临床医生-模型评分事件。

Result: 专家评估揭示了当前VLMs的常见局限性，包括答案偏离目标、推理模糊以及病理学术语不一致等问题。

Conclusion: MedFoundationHub为安全部署和评估医疗视觉-语言模型提供了一个可访问的解决方案。尽管医疗VLMs取得了进展，但目前的模型在临床准确性和一致性方面仍存在显著局限性，需要进一步改进。

Abstract: Recent advances in medical vision-language models (VLMs) open up remarkable
opportunities for clinical applications such as automated report generation,
copilots for physicians, and uncertainty quantification. However, despite their
promise, medical VLMs introduce serious security concerns, most notably risks
of Protected Health Information (PHI) exposure, data leakage, and vulnerability
to cyberthreats - which are especially critical in hospital environments. Even
when adopted for research or non-clinical purposes, healthcare organizations
must exercise caution and implement safeguards. To address these challenges, we
present MedFoundationHub, a graphical user interface (GUI) toolkit that: (1)
enables physicians to manually select and use different models without
programming expertise, (2) supports engineers in efficiently deploying medical
VLMs in a plug-and-play fashion, with seamless integration of Hugging Face
open-source models, and (3) ensures privacy-preserving inference through
Docker-orchestrated, operating system agnostic deployment. MedFoundationHub
requires only an offline local workstation equipped with a single NVIDIA A6000
GPU, making it both secure and accessible within the typical resources of
academic research labs. To evaluate current capabilities, we engaged
board-certified pathologists to deploy and assess five state-of-the-art VLMs
(Google-MedGemma3-4B, Qwen2-VL-7B-Instruct, Qwen2.5-VL-7B-Instruct, and
LLaVA-1.5-7B/13B). Expert evaluation covered colon cases and renal cases,
yielding 1015 clinician-model scoring events. These assessments revealed
recurring limitations, including off-target answers, vague reasoning, and
inconsistent pathology terminology.

</details>


### [41] [Enhancing Mamba Decoder with Bidirectional Interaction in Multi-Task Dense Prediction](https://arxiv.org/abs/2508.20376)
*Mang Cao,Sanping Zhou,Yizhe Li,Ye Deng,Wenli Huang,Le Wang*

Main category: cs.CV

TL;DR: 该论文提出了双向交互Mamba (BIM) 模型，通过引入双向交互扫描 (BI-Scan) 和多尺度扫描 (MS-Scan) 机制，解决了多任务密集预测中交互完整性与计算效率之间的权衡问题，实现了卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 在多任务密集预测中，充分的跨任务交互对成功至关重要，但往往导致高计算复杂度，使得现有方法必须在交互完整性和计算效率之间进行权衡。研究旨在解决这一限制。

Method: 本文提出了双向交互Mamba (BIM) 模型，该模型将Mamba建模方法应用于多任务密集预测。具体方法包括：1) 引入双向交互扫描 (BI-Scan) 机制，将任务特定表示构建为双向序列，并在统一的线性复杂度架构中整合任务优先和位置优先扫描模式，以高效保留关键跨任务信息。2) 采用多尺度扫描 (MS-Scan) 机制，实现多粒度场景建模，满足不同任务的粒度需求并增强细致的跨任务特征交互。

Result: 在NYUD-V2和PASCAL-Context两个具有挑战性的基准测试上进行的广泛实验表明，BIM模型优于现有的最先进竞争对手。

Conclusion: BIM模型通过创新的扫描机制，成功地在多任务密集预测中实现了充分的跨任务交互，同时保持了高计算效率，从而取得了卓越的性能，有效解决了现有方法的局限性。

Abstract: Sufficient cross-task interaction is crucial for success in multi-task dense
prediction. However, sufficient interaction often results in high computational
complexity, forcing existing methods to face the trade-off between interaction
completeness and computational efficiency. To address this limitation, this
work proposes a Bidirectional Interaction Mamba (BIM), which incorporates novel
scanning mechanisms to adapt the Mamba modeling approach for multi-task dense
prediction. On the one hand, we introduce a novel Bidirectional Interaction
Scan (BI-Scan) mechanism, which constructs task-specific representations as
bidirectional sequences during interaction. By integrating task-first and
position-first scanning modes within a unified linear complexity architecture,
BI-Scan efficiently preserves critical cross-task information. On the other
hand, we employ a Multi-Scale Scan~(MS-Scan) mechanism to achieve
multi-granularity scene modeling. This design not only meets the diverse
granularity requirements of various tasks but also enhances nuanced cross-task
feature interactions. Extensive experiments on two challenging benchmarks,
\emph{i.e.}, NYUD-V2 and PASCAL-Context, show the superiority of our BIM vs its
state-of-the-art competitors.

</details>


### [42] [Audio-Guided Visual Editing with Complex Multi-Modal Prompts](https://arxiv.org/abs/2508.20379)
*Hyeonyu Kim,Seokhoon Jeong,Seonghee Han,Chanhyuk Choi,Taehwan Kim*

Main category: cs.CV

TL;DR: 本文提出了一种无需额外训练的音频引导视觉编辑框架，能够处理复杂的、结合文本和音频的多模态编辑任务，并通过消除多模态编码器与扩散模型提示编码器之间的差异以及新颖的多提示处理方法，实现卓越的编辑效果。


<details>
  <summary>Details</summary>
Motivation: 现有视觉编辑模型在处理复杂场景时，仅凭文本指导往往不足。而现有音频引导的视觉编辑方法通常需要针对特定数据集进行训练，限制了其在真实世界场景中的泛化能力。

Method: 该研究引入了一种音频引导的视觉编辑框架。它利用预训练的多模态编码器的零样本能力，并通过缓解音频编码器空间与扩散模型提示编码器空间之间的差异，将多样化的音频整合到视觉编辑任务中。此外，还提出了一种通过独立的噪声分支和自适应补丁选择来处理多文本和多模态编辑提示的复杂场景的新方法，且无需额外训练。

Result: 在多样化的编辑任务上的综合实验表明，该框架通过整合来自音频的丰富信息，在处理复杂编辑场景方面表现出色，弥补了纯文本方法在此类场景中的不足。

Conclusion: 该框架成功地通过音频引导实现了复杂的视觉编辑，在多模态提示下表现优异，且无需额外训练，显著提升了现有方法的泛化性和编辑能力。

Abstract: Visual editing with diffusion models has made significant progress but often
struggles with complex scenarios that textual guidance alone could not
adequately describe, highlighting the need for additional non-text editing
prompts. In this work, we introduce a novel audio-guided visual editing
framework that can handle complex editing tasks with multiple text and audio
prompts without requiring additional training. Existing audio-guided visual
editing methods often necessitate training on specific datasets to align audio
with text, limiting their generalization to real-world situations. We leverage
a pre-trained multi-modal encoder with strong zero-shot capabilities and
integrate diverse audio into visual editing tasks, by alleviating the
discrepancy between the audio encoder space and the diffusion model's prompt
encoder space. Additionally, we propose a novel approach to handle complex
scenarios with multiple and multi-modal editing prompts through our separate
noise branching and adaptive patch selection. Our comprehensive experiments on
diverse editing tasks demonstrate that our framework excels in handling
complicated editing scenarios by incorporating rich information from audio,
where text-only approaches fail.

</details>


### [43] [More Reliable Pseudo-labels, Better Performance: A Generalized Approach to Single Positive Multi-label Learning](https://arxiv.org/abs/2508.20381)
*Luong Tran,Thieu Vo,Anh Nguyen,Sang Dinh,Van Nguyen*

Main category: cs.CV

TL;DR: 本文提出了AEVLP框架，包含广义伪标签鲁棒损失（GPR Loss）和动态增强多焦点伪标签（DAMP）技术，以解决单正多标签学习（SPML）中伪标签噪声问题，并在多标签分类任务中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 多标签学习中，大规模数据集的完全标注成本高昂且不切实际。单正多标签学习（SPML）中，每张图像只有一个正标签，其余未标注。传统SPML方法将缺失标签视为未知或负标签会导致不准确和假阴性，而伪标签策略又会引入额外噪声。

Method: 本文提出了两种核心贡献：1. 广义伪标签鲁棒损失（GPR Loss），一种有效学习多样化伪标签同时减轻噪声的新型损失函数。2. 动态增强多焦点伪标签（DAMP）技术，一种简单而有效的伪标签方法。这两者共同构成了自适应高效视觉-语言伪标签（AEVLP）框架。

Result: 在四个基准数据集上的大量实验表明，所提出的AEVLP框架显著推动了多标签分类技术，并取得了最先进的成果。

Conclusion: AEVLP框架通过GPR Loss和DAMP技术有效解决了单正多标签学习中的伪标签噪声问题，显著提升了多标签分类的性能，达到了当前最佳水平。

Abstract: Multi-label learning is a challenging computer vision task that requires
assigning multiple categories to each image. However, fully annotating
large-scale datasets is often impractical due to high costs and effort,
motivating the study of learning from partially annotated data. In the extreme
case of Single Positive Multi-Label Learning (SPML), each image is provided
with only one positive label, while all other labels remain unannotated.
Traditional SPML methods that treat missing labels as unknown or negative tend
to yield inaccuracies and false negatives, and integrating various
pseudo-labeling strategies can introduce additional noise. To address these
challenges, we propose the Generalized Pseudo-Label Robust Loss (GPR Loss), a
novel loss function that effectively learns from diverse pseudo-labels while
mitigating noise. Complementing this, we introduce a simple yet effective
Dynamic Augmented Multi-focus Pseudo-labeling (DAMP) technique. Together, these
contributions form the Adaptive and Efficient Vision-Language Pseudo-Labeling
(AEVLP) framework. Extensive experiments on four benchmark datasets demonstrate
that our framework significantly advances multi-label classification, achieving
state-of-the-art results.

</details>


### [44] [Ultra-Low-Latency Spiking Neural Networks with Temporal-Dependent Integrate-and-Fire Neuron Model for Objects Detection](https://arxiv.org/abs/2508.20392)
*Chengjun Zhang,Yuhao Zhang,Jie Yang,Mohamad Sawan*

Main category: cs.CV

TL;DR: 该论文提出了一种名为“延迟脉冲（delay-spike）”的方法和一种新型“时序依赖积分放电（tdIF）”神经元架构，以解决SNN在视觉检测任务中低时间步下性能不佳的问题。该方法在目标检测和车道线检测任务中实现了超低延迟（5个时间步内）的SOTA性能，同时保持了与传统IF神经元相当的能耗。


<details>
  <summary>Details</summary>
Motivation: 受大脑启发的脉冲神经网络（SNNs）在神经形态硬件上具有低功耗和快速推理的优势，但在视觉检测任务中，当前的ANN-SNN转换方法在超低时间步下表现不佳。主要问题包括异构脉冲模式导致的残余膜电位，以及传统SNN难以在低时间步下实现精确特征表示。

Method: 1. 提出了“延迟脉冲（delay-spike）”方法，以缓解异构脉冲模式引起的残余膜电位问题。2. 提出了一种新型的“时序依赖积分放电（tdIF）”神经元架构，使积分放电（IF）神经元能够根据时间步的顺序动态调整其累积和放电行为。3. tdIF神经元允许脉冲表现出独特的时序特性，而不仅仅依赖于基于频率的表示。4. tdIF神经元在保持与传统IF神经元相当的能耗。

Result: 该方法实现了在较低时间步下更精确的特征表示，从而在视觉检测任务中实现了高性能和超低延迟。在目标检测和车道线检测两项关键视觉任务中，所提出的方法超越了当前的ANN-SNN转换方法，以超低延迟（5个时间步内）达到了最先进的性能。

Conclusion: 该研究表明，通过引入延迟脉冲方法和新型tdIF神经元架构，SNNs可以在视觉检测任务中实现卓越的性能，特别是在超低延迟和低时间步条件下。这为SNNs利用时序信息进行高效视觉感知开辟了新途径，并为神经形态硬件上的实时应用提供了强大支持。

Abstract: Spiking Neural Networks (SNNs), inspired by the brain, are characterized by
minimal power consumption and swift inference capabilities on neuromorphic
hardware, and have been widely applied to various visual perception tasks.
Current ANN-SNN conversion methods have achieved excellent results in
classification tasks with ultra-low time-steps, but their performance in visual
detection tasks remains suboptimal. In this paper, we propose a delay-spike
approach to mitigate the issue of residual membrane potential caused by
heterogeneous spiking patterns. Furthermore, we propose a novel
temporal-dependent Integrate-and-Fire (tdIF) neuron architecture for SNNs. This
enables Integrate-and-fire (IF) neurons to dynamically adjust their
accumulation and firing behaviors based on the temporal order of time-steps.
Our method enables spikes to exhibit distinct temporal properties, rather than
relying solely on frequency-based representations. Moreover, the tdIF neuron
maintains energy consumption on par with traditional IF neuron. We demonstrate
that our method achieves more precise feature representation with lower
time-steps, enabling high performance and ultra-low latency in visual detection
tasks. In this study, we conduct extensive evaluation of the tdIF method across
two critical vision tasks: object detection and lane line detection. The
results demonstrate that the proposed method surpasses current ANN-SNN
conversion approaches, achieving state-of-the-art performance with ultra-low
latency (within 5 time-steps).

</details>


### [45] [Graph-Based Uncertainty Modeling and Multimodal Fusion for Salient Object Detection](https://arxiv.org/abs/2508.20415)
*Yuqi Xiong,Wuzhen Shi,Yang Wen,Ruhan Liu*

Main category: cs.CV

TL;DR: 本文提出了一种动态不确定性传播和多模态协同推理网络（DUP-MCRNet），通过动态不确定性图卷积模块和多模态协同融合策略，解决了现有显著目标检测方法在复杂场景中细节丢失、边缘模糊和单模态信息融合不足的问题，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有显著目标检测（SOD）方法在复杂场景中容易出现细节丢失、边缘模糊以及单模态信息融合不足的问题。

Method: 本文提出了DUP-MCRNet。首先，设计了动态不确定性图卷积模块（DUGC），通过基于空间语义距离构建的稀疏图在层间传播不确定性，结合通道自适应交互，提升小结构和边缘区域的检测精度。其次，提出了多模态协同融合策略（MCF），利用可学习的模态门控权重对RGB、深度和边缘特征的注意力图进行加权融合，动态调整各模态重要性，增强跨模态语义互补性。最后，通过多尺度BCE和IoU损失、跨尺度一致性约束以及不确定性引导的监督机制，优化像素级和区域级检测性能。

Result: 大量实验表明，DUP-MCRNet在大多数常用基准数据集上优于各种SOD方法，尤其在边缘清晰度和对复杂背景的鲁棒性方面表现突出。

Conclusion: DUP-MCRNet通过其动态不确定性传播和多模态协同推理机制，有效解决了复杂场景下显著目标检测中的细节丢失和边缘模糊问题，并提升了对遮挡、弱纹理和背景干扰的识别能力，实现了卓越的检测性能。

Abstract: In view of the problems that existing salient object detection (SOD) methods
are prone to losing details, blurring edges, and insufficient fusion of
single-modal information in complex scenes, this paper proposes a dynamic
uncertainty propagation and multimodal collaborative reasoning network
(DUP-MCRNet). Firstly, a dynamic uncertainty graph convolution module (DUGC) is
designed to propagate uncertainty between layers through a sparse graph
constructed based on spatial semantic distance, and combined with channel
adaptive interaction, it effectively improves the detection accuracy of small
structures and edge regions. Secondly, a multimodal collaborative fusion
strategy (MCF) is proposed, which uses learnable modality gating weights to
weightedly fuse the attention maps of RGB, depth, and edge features. It can
dynamically adjust the importance of each modality according to different
scenes, effectively suppress redundant or interfering information, and
strengthen the semantic complementarity and consistency between
cross-modalities, thereby improving the ability to identify salient regions
under occlusion, weak texture or background interference. Finally, the
detection performance at the pixel level and region level is optimized through
multi-scale BCE and IoU loss, cross-scale consistency constraints, and
uncertainty-guided supervision mechanisms. Extensive experiments show that
DUP-MCRNet outperforms various SOD methods on most common benchmark datasets,
especially in terms of edge clarity and robustness to complex backgrounds. Our
code is publicly available at https://github.com/YukiBear426/DUP-MCRNet.

</details>


### [46] [MSMVD: Exploiting Multi-scale Image Features via Multi-scale BEV Features for Multi-view Pedestrian Detection](https://arxiv.org/abs/2508.20447)
*Taiga Yamane,Satoshi Suzuki,Ryo Masumura,Shota Orihashi,Tomohiro Tanaka,Mana Ihori,Naoki Makishima,Naotaka Kawata*

Main category: cs.CV

TL;DR: 本文提出了一种名为MSMVD的多尺度多视角行人检测方法，通过利用多尺度图像特征生成多尺度BEV特征并结合特征金字塔网络，显著提升了在多视角图像中检测不同尺度行人的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端多视角行人检测（MVPD）方法难以有效检测视图中尺度一致过小或过大，或视图间尺度差异巨大的行人，原因是它们未能充分利用多尺度图像特征来生成BEV特征并进行行人检测。

Method: MSMVD方法首先从单个视图中提取多尺度图像特征，然后将这些特征逐尺度投影到BEV空间以生成多尺度BEV特征。这些BEV特征继承了其对应尺度的图像特征属性，有助于精确检测尺度一致的行人。随后，MSMVD利用特征金字塔网络（FPN）处理这些多尺度BEV特征，以融合来自不同尺度和多视角的信息，从而改善对视图间尺度差异巨大行人的检测。

Result: 实验结果表明，通过多尺度BEV特征利用多尺度图像特征显著提高了检测性能。MSMVD在GMVD数据集上的MODA指标超越了之前最高水平4.5个百分点。

Conclusion: 通过在多视角行人检测中引入并有效利用多尺度图像特征和多尺度BEV特征，MSMVD方法显著提升了对各种尺度行人的检测精度，尤其解决了传统方法在处理尺度变化方面的不足。

Abstract: Multi-View Pedestrian Detection (MVPD) aims to detect pedestrians in the form
of a bird's eye view (BEV) from multi-view images. In MVPD, end-to-end
trainable deep learning methods have progressed greatly. However, they often
struggle to detect pedestrians with consistently small or large scales in views
or with vastly different scales between views. This is because they do not
exploit multi-scale image features to generate the BEV feature and detect
pedestrians. To overcome this problem, we propose a novel MVPD method, called
Multi-Scale Multi-View Detection (MSMVD). MSMVD generates multi-scale BEV
features by projecting multi-scale image features extracted from individual
views into the BEV space, scale-by-scale. Each of these BEV features inherits
the properties of its corresponding scale image features from multiple views.
Therefore, these BEV features help the precise detection of pedestrians with
consistently small or large scales in views. Then, MSMVD combines information
at different scales of multiple views by processing the multi-scale BEV
features using a feature pyramid network. This improves the detection of
pedestrians with vastly different scales between views. Extensive experiments
demonstrate that exploiting multi-scale image features via multi-scale BEV
features greatly improves the detection performance, and MSMVD outperforms the
previous highest MODA by $4.5$ points on the GMVD dataset.

</details>


### [47] [A Spatial-Frequency Aware Multi-Scale Fusion Network for Real-Time Deepfake Detection](https://arxiv.org/abs/2508.20449)
*Libo Lv,Tianyi Wang,Mengxiao Huang,Ruixia Liu,Yinglong Wang*

Main category: cs.CV

TL;DR: 针对实时深度伪造检测，本文提出了一种轻量级且高效的SFMFNet网络，通过结合空间-频率特征和多尺度融合，在保持高准确率的同时显著提升了实时性能。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造技术的发展，伪造内容日益逼真且广泛传播。现有最先进的检测器虽然准确率高，但计算成本过大，阻碍了在视频会议、社交媒体等实际应用中的实时部署。

Method: 本文提出了空间-频率感知多尺度融合网络（SFMFNet）。主要方法包括：1) 设计了一个空间-频率混合感知模块，通过门控机制共同利用空间纹理和频率伪影，增强对细微操作的敏感性。2) 采用令牌选择性交叉注意力机制，实现高效的多级特征交互。3) 使用残差增强的模糊池化结构，在下采样过程中保留关键语义线索。

Result: 在多个基准数据集上的实验表明，SFMFNet在准确性和效率之间取得了良好的平衡，表现出强大的泛化能力和在实时应用中的实用价值。

Conclusion: SFMFNet是一个轻量级且有效的实时深度伪造检测架构，通过其创新的模块设计，成功解决了现有检测器在实时部署方面的计算成本问题，具有重要的实际应用价值。

Abstract: With the rapid advancement of real-time deepfake generation techniques,
forged content is becoming increasingly realistic and widespread across
applications like video conferencing and social media. Although
state-of-the-art detectors achieve high accuracy on standard benchmarks, their
heavy computational cost hinders real-time deployment in practical
applications. To address this, we propose the Spatial-Frequency Aware
Multi-Scale Fusion Network (SFMFNet), a lightweight yet effective architecture
for real-time deepfake detection. We design a spatial-frequency hybrid aware
module that jointly leverages spatial textures and frequency artifacts through
a gated mechanism, enhancing sensitivity to subtle manipulations. A
token-selective cross attention mechanism enables efficient multi-level feature
interaction, while a residual-enhanced blur pooling structure helps retain key
semantic cues during downsampling. Experiments on several benchmark datasets
show that SFMFNet achieves a favorable balance between accuracy and efficiency,
with strong generalization and practical value for real-time applications.

</details>


### [48] [Dual-Model Weight Selection and Self-Knowledge Distillation for Medical Image Classification](https://arxiv.org/abs/2508.20461)
*Ayaka Tsutsumi,Guang Li,Ren Togo,Takahiro Ogawa,Satoshi Kondo,Miki Haseyama*

Main category: cs.CV

TL;DR: 该研究提出了一种结合双模型权重选择和自知识蒸馏（SKD）的医学图像分类新方法，旨在开发性能媲美大型模型的轻量级模型。


<details>
  <summary>Details</summary>
Motivation: 在实际医疗环境中，计算资源限制阻碍了大型模型的部署。因此，开发既能保持计算效率又能达到与大型模型相当性能的轻量级模型至关重要。传统方法在压缩模型时常难以保留关键信息。

Method: 首先，采用双模型权重选择策略，从一个大型预训练模型中获取权重来初始化两个轻量级模型，以实现有效的知识迁移。接着，对这些选定的模型应用自知识蒸馏（SKD），允许使用广泛的初始权重配置而不会带来过高的计算成本。最后，对模型进行微调以完成目标分类任务。

Result: 在胸部X光、肺部CT和脑部MRI等公开数据集上的广泛实验表明，该方法相比现有方法具有卓越的性能和鲁棒性。

Conclusion: 该方法通过结合双模型权重选择和自知识蒸馏，成功克服了传统方法在紧凑模型中难以保留关键信息的局限性，实现了高性能且鲁棒的医学图像分类。

Abstract: We propose a novel medical image classification method that integrates
dual-model weight selection with self-knowledge distillation (SKD). In
real-world medical settings, deploying large-scale models is often limited by
computational resource constraints, which pose significant challenges for their
practical implementation. Thus, developing lightweight models that achieve
comparable performance to large-scale models while maintaining computational
efficiency is crucial. To address this, we employ a dual-model weight selection
strategy that initializes two lightweight models with weights derived from a
large pretrained model, enabling effective knowledge transfer. Next, SKD is
applied to these selected models, allowing the use of a broad range of initial
weight configurations without imposing additional excessive computational cost,
followed by fine-tuning for the target classification tasks. By combining
dual-model weight selection with self-knowledge distillation, our method
overcomes the limitations of conventional approaches, which often fail to
retain critical information in compact models. Extensive experiments on
publicly available datasets-chest X-ray images, lung computed tomography scans,
and brain magnetic resonance imaging scans-demonstrate the superior performance
and robustness of our approach compared to existing methods.

</details>


### [49] [Re-Densification Meets Cross-Scale Propagation: Real-Time Compression of LiDAR Point Clouds](https://arxiv.org/abs/2508.20466)
*Pengpeng Yu,Haoran Li,Dingquan Li,Runqing Jiang,Jing Wang,Liang Lin,Yulan Guo*

Main category: cs.CV

TL;DR: 本文提出了一种新的激光雷达点云压缩方法，通过几何重稠密化和跨尺度特征传播生成紧凑特征，实现了更高的压缩比和实时编解码速度。


<details>
  <summary>Details</summary>
Motivation: 高精度激光雷达点云数据量大，存储和传输成本高。现有方法将无序点转换为八叉树或体素结构进行预测编码，但几何细节的极端稀疏性阻碍了高效的上下文建模，限制了压缩性能和速度。

Method: 该方法通过生成紧凑特征实现高效预测编码，包含两个轻量级模块：1) 几何重稠密化模块：对编码后的稀疏几何进行重稠密化，在更密集的尺度上提取特征，然后将特征重新稀疏化用于预测编码，避免了在高度稀疏细节上进行昂贵计算。2) 跨尺度特征传播模块：利用多分辨率级别的占用线索指导分层特征传播，促进跨尺度信息共享，减少冗余特征提取，并为几何重稠密化模块提供更丰富的特征。

Result: 在KITTI数据集上，该方法实现了最先进的压缩比和实时性能，在12位量化下编解码速度均达到26 FPS。

Conclusion: 通过整合几何重稠密化和跨尺度特征传播模块，本文方法生成了紧凑的特征表示，实现了高效的上下文建模并加速了编码过程，有效解决了激光雷达点云压缩的挑战，取得了卓越的压缩率和速度。

Abstract: LiDAR point clouds are fundamental to various applications, yet
high-precision scans incur substantial storage and transmission overhead.
Existing methods typically convert unordered points into hierarchical octree or
voxel structures for dense-to-sparse predictive coding. However, the extreme
sparsity of geometric details hinders efficient context modeling, thereby
limiting their compression performance and speed. To address this challenge, we
propose to generate compact features for efficient predictive coding. Our
framework comprises two lightweight modules. First, the Geometry
Re-Densification Module re-densifies encoded sparse geometry, extracts features
at denser scale, and then re-sparsifies the features for predictive coding.
This module avoids costly computation on highly sparse details while
maintaining a lightweight prediction head. Second, the Cross-scale Feature
Propagation Module leverages occupancy cues from multiple resolution levels to
guide hierarchical feature propagation. This design facilitates information
sharing across scales, thereby reducing redundant feature extraction and
providing enriched features for the Geometry Re-Densification Module. By
integrating these two modules, our method yields a compact feature
representation that provides efficient context modeling and accelerates the
coding process. Experiments on the KITTI dataset demonstrate state-of-the-art
compression ratios and real-time performance, achieving 26 FPS for both
encoding and decoding at 12-bit quantization. Code is available at
https://github.com/pengpeng-yu/FastPCC.

</details>


### [50] [Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation](https://arxiv.org/abs/2508.20470)
*Xiaochuan Li,Guoguang Du,Runze Zhang,Liang Jin,Qi Jia,Lihua Lu,Zhenhua Guo,Yaqian Zhao,Haiyang Liu,Tianqi Wang,Changsheng Li,Xiaoli Gong,Rengang Li,Baoyu Fan*

Main category: cs.CV

TL;DR: 该研究通过利用视频数据作为监督信号，解决了3D数据稀缺的问题，并提出了一个大型视频数据集Droplet3D-4M和一个生成模型Droplet3D，实现了空间一致且语义合理的3D资产生成。


<details>
  <summary>Details</summary>
Motivation: 大型数据训练模型在文本、图像、视频生成领域取得了巨大成功，但3D领域面临数据稀缺问题。视频中包含的常识先验和多视角信息可以作为替代监督信号，解决3D数据有限导致的泛化瓶颈，并提供空间一致性和丰富的语义信息。

Method: 该研究引入了Droplet3D-4M，这是首个具有多视角级别标注的大规模视频数据集。在此基础上，训练了Droplet3D生成模型，该模型支持图像和密集文本输入，旨在利用视频模态进行3D资产生成。

Result: 实验证明了该方法的有效性，能够生成空间一致且语义合理的3D内容。与现有3D解决方案相比，该方法还展现了扩展到场景级应用的潜力，表明视频中的常识先验显著促进了3D创作。

Conclusion: 视频模态是解决3D数据稀缺问题的有效途径，通过利用视频中的多视角和语义信息，可以显著提升3D资产生成的质量、空间一致性和语义合理性，并有望扩展到更复杂的场景级应用。

Abstract: Scaling laws have validated the success and promise of large-data-trained
models in creative generation across text, image, and video domains. However,
this paradigm faces data scarcity in the 3D domain, as there is far less of it
available on the internet compared to the aforementioned modalities.
Fortunately, there exist adequate videos that inherently contain commonsense
priors, offering an alternative supervisory signal to mitigate the
generalization bottleneck caused by limited native 3D data. On the one hand,
videos capturing multiple views of an object or scene provide a spatial
consistency prior for 3D generation. On the other hand, the rich semantic
information contained within the videos enables the generated content to be
more faithful to the text prompts and semantically plausible. This paper
explores how to apply the video modality in 3D asset generation, spanning
datasets to models. We introduce Droplet3D-4M, the first large-scale video
dataset with multi-view level annotations, and train Droplet3D, a generative
model supporting both image and dense text input. Extensive experiments
validate the effectiveness of our approach, demonstrating its ability to
produce spatially consistent and semantically plausible content. Moreover, in
contrast to the prevailing 3D solutions, our approach exhibits the potential
for extension to scene-level applications. This indicates that the commonsense
priors from the videos significantly facilitate 3D creation. We have
open-sourced all resources including the dataset, code, technical framework,
and model weights: https://dropletx.github.io/.

</details>


### [51] [SKGE-SWIN: End-To-End Autonomous Vehicle Waypoint Prediction and Navigation Using Skip Stage Swin Transformer](https://arxiv.org/abs/2508.20762)
*Fachri Najm Noer Kartiman,Rasim,Yaya Wihardi,Nurul Hasanah,Oskar Natan,Bambang Wahono,Taufik Ibnu Salim*

Main category: cs.CV

TL;DR: 本研究提出SKGE-Swin架构，一个结合Swin Transformer和跳跃连接的端到端自动驾驶模型，旨在增强像素级上下文感知和复杂环境理解，并在CARLA平台上实现了优于现有方法的驾驶分数。


<details>
  <summary>Details</summary>
Motivation: 开发一个具有像素级上下文感知能力的端到端自动驾驶模型，能够从远距离像素中提取信息，并在特征提取的整个过程中保留关键信息，从而更好地理解车辆周围的复杂模式。

Method: 提出SKGE-Swin架构，该架构利用Swin Transformer的移位窗口多头自注意力（SW-MSA）机制实现全局特征表示，并结合跳跃阶段机制在不同网络级别上拓宽特征表示，同时保留从初始到最终阶段的关键信息。模型在CARLA平台上的对抗性场景中进行评估，并计划进行消融研究以评估各组件的贡献。

Result: 实验结果表明，SKGE-Swin架构在CARLA平台上取得了优于现有方法的驾驶分数（Driving Score）。

Conclusion: SKGE-Swin架构通过结合Swin Transformer和跳跃连接，显著提升了自动驾驶模型对复杂环境的像素级上下文感知和理解能力，并在模拟真实世界的对抗性场景中展现出卓越的性能。

Abstract: Focusing on the development of an end-to-end autonomous vehicle model with
pixel-to-pixel context awareness, this research proposes the SKGE-Swin
architecture. This architecture utilizes the Swin Transformer with a skip-stage
mechanism to broaden feature representation globally and at various network
levels. This approach enables the model to extract information from distant
pixels by leveraging the Swin Transformer's Shifted Window-based Multi-head
Self-Attention (SW-MSA) mechanism and to retain critical information from the
initial to the final stages of feature extraction, thereby enhancing its
capability to comprehend complex patterns in the vehicle's surroundings. The
model is evaluated on the CARLA platform using adversarial scenarios to
simulate real-world conditions. Experimental results demonstrate that the
SKGE-Swin architecture achieves a superior Driving Score compared to previous
methods. Furthermore, an ablation study will be conducted to evaluate the
contribution of each architectural component, including the influence of skip
connections and the use of the Swin Transformer, in improving model
performance.

</details>


### [52] [Realistic and Controllable 3D Gaussian-Guided Object Editing for Driving Video Generation](https://arxiv.org/abs/2508.20471)
*Jiusi Li,Jackson Jiang,Jinyu Miao,Miao Long,Tuopu Wen,Peijin Jia,Shengxiang Liu,Chunlei Yu,Maolin Liu,Yuzhan Cai,Kun Jiang,Mengmeng Yang,Diange Yang*

Main category: cs.CV

TL;DR: G^2Editor是一个用于驾驶视频中逼真、精确物体编辑的框架，它利用3D高斯表示和分层特征，实现了对物体重新定位、插入和删除，并显著提升了姿态控制和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要大量边缘案例进行训练和验证，但从现实世界中收集这些数据成本高昂且危险。现有通过编辑捕获传感器数据生成场景的方法（如3D高斯溅射或图像生成模型）存在视觉保真度有限或姿态控制不精确的问题。

Method: 本文提出了G^2Editor框架。它利用编辑对象的3D高斯表示作为密集的先验，注入到去噪过程中以确保精确的姿态控制和空间一致性。通过场景级3D边界框布局重建非目标对象的遮挡区域。此外，通过引入分层细粒度特征作为额外条件来指导编辑对象的视觉细节。

Result: G^2Editor在Waymo开放数据集上的实验表明，它能在统一框架下有效支持对象的重新定位、插入和删除，并且在姿态可控性和视觉质量上均优于现有方法，同时也有利于下游数据驱动的任务。

Conclusion: G^2Editor为驾驶视频中的物体编辑提供了一个逼真且精确的解决方案，解决了现有方法的局限性，并能更好地支持自动驾驶系统的数据生成和训练。

Abstract: Corner cases are crucial for training and validating autonomous driving
systems, yet collecting them from the real world is often costly and hazardous.
Editing objects within captured sensor data offers an effective alternative for
generating diverse scenarios, commonly achieved through 3D Gaussian Splatting
or image generative models. However, these approaches often suffer from limited
visual fidelity or imprecise pose control. To address these issues, we propose
G^2Editor, a framework designed for photorealistic and precise object editing
in driving videos. Our method leverages a 3D Gaussian representation of the
edited object as a dense prior, injected into the denoising process to ensure
accurate pose control and spatial consistency. A scene-level 3D bounding box
layout is employed to reconstruct occluded areas of non-target objects.
Furthermore, to guide the appearance details of the edited object, we
incorporate hierarchical fine-grained features as additional conditions during
generation. Experiments on the Waymo Open Dataset demonstrate that G^2Editor
effectively supports object repositioning, insertion, and deletion within a
unified framework, outperforming existing methods in both pose controllability
and visual quality, while also benefiting downstream data-driven tasks.

</details>


### [53] [To New Beginnings: A Survey of Unified Perception in Autonomous Vehicle Software](https://arxiv.org/abs/2508.20892)
*Loïc Stratil,Felix Fent,Esteban Rivera,Markus Lienkamp*

Main category: cs.CV

TL;DR: 这篇综述全面概述了自动驾驶领域中的统一感知范式，该范式将检测、跟踪和预测任务整合到一个共享架构中，以解决传统模块化管道的误差累积问题，并提供了一个系统性的分类法和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶的传统感知管道（检测、跟踪、预测）存在误差累积和任务间协同有限的问题。统一感知作为一种新兴范式，旨在通过整合这些子任务，提高鲁棒性、上下文推理能力和效率，同时保持可解释性。

Method: 本研究是一篇综述。它引入了一个整体和系统的分类法，根据任务集成、跟踪公式和表示流对统一感知方法进行分类。定义了三种范式（早期、晚期和完全统一感知），并系统地回顾了现有方法、其架构、训练策略、使用的数据集和开源可用性。

Result: 该工作建立了首个理解和推进统一感知的综合框架，整合了分散的研究工作，并明确了未来的研究方向。

Conclusion: 该综述为统一感知提供了一个全面的框架，旨在指导未来的研究，以实现更鲁棒、更通用和更可解释的自动驾驶感知系统。

Abstract: Autonomous vehicle perception typically relies on modular pipelines that
decompose the task into detection, tracking, and prediction. While
interpretable, these pipelines suffer from error accumulation and limited
inter-task synergy. Unified perception has emerged as a promising paradigm that
integrates these sub-tasks within a shared architecture, potentially improving
robustness, contextual reasoning, and efficiency while retaining interpretable
outputs. In this survey, we provide a comprehensive overview of unified
perception, introducing a holistic and systemic taxonomy that categorizes
methods along task integration, tracking formulation, and representation flow.
We define three paradigms -Early, Late, and Full Unified Perception- and
systematically review existing methods, their architectures, training
strategies, datasets used, and open-source availability, while highlighting
future research directions. This work establishes the first comprehensive
framework for understanding and advancing unified perception, consolidates
fragmented efforts, and guides future research toward more robust,
generalizable, and interpretable perception.

</details>


### [54] [Enhancing Corpus Callosum Segmentation in Fetal MRI via Pathology-Informed Domain Randomization](https://arxiv.org/abs/2508.20475)
*Marina Grifell i Plana,Vladyslav Zalevskyi,Léa Schmidt,Yvan Gomez,Thomas Sanchez,Vincent Dunet,Mériam Koob,Vanessa Siffredi,Meritxell Bach Cuadra*

Main category: cs.CV

TL;DR: 该研究提出了一种病理学知情的域随机化策略，通过从健康数据模拟病变来生成合成数据，以解决胎儿脑部分割中罕见疾病（如胼胝体发育不全CCD）数据稀缺问题，显著提高了分割准确性和生物标志物提取的可靠性。


<details>
  <summary>Details</summary>
Motivation: 准确的胎儿脑部分割对于提取生物标志物和评估神经发育至关重要，尤其是在胼胝体发育不全（CCD）等可能导致剧烈解剖变化的疾病中。然而，CCD的罕见性严重限制了带注释的数据，阻碍了深度学习模型的泛化能力。

Method: 研究提出了一种病理学知情的域随机化策略，将CCD表现的先验知识嵌入到合成数据生成流程中。通过仅从健康数据模拟多样化的脑部改变，该方法无需病理学注释即可实现鲁棒的分割。

Result: 该方法在包含248名健康胎儿、26名CCD患者和47名其他脑部病理患者的队列中进行了验证，结果显示在CCD病例上取得了显著改进，同时保持了在健康胎儿和患有其他病理胎儿上的性能。从预测的分割结果中，导出了胼胝体长度（LCC）和体积等临床相关生物标志物，并证明了它们在区分CCD亚型中的效用。病理学知情的增强将健康病例的LCC估计误差从1.89毫米降低到0.80毫米，将CCD病例的误差从10.9毫米降低到0.7毫米。此外，该方法生成的分割结果在拓扑一致性方面相对于现有金标准有所改善，从而实现更可靠的基于形状的分析。

Conclusion: 将领域特定的解剖学先验知识整合到合成数据流程中，可以有效缓解数据稀缺问题，并增强对罕见但临床意义重大的畸形的分析。

Abstract: Accurate fetal brain segmentation is crucial for extracting biomarkers and
assessing neurodevelopment, especially in conditions such as corpus callosum
dysgenesis (CCD), which can induce drastic anatomical changes. However, the
rarity of CCD severely limits annotated data, hindering the generalization of
deep learning models. To address this, we propose a pathology-informed domain
randomization strategy that embeds prior knowledge of CCD manifestations into a
synthetic data generation pipeline. By simulating diverse brain alterations
from healthy data alone, our approach enables robust segmentation without
requiring pathological annotations.
  We validate our method on a cohort comprising 248 healthy fetuses, 26 with
CCD, and 47 with other brain pathologies, achieving substantial improvements on
CCD cases while maintaining performance on both healthy fetuses and those with
other pathologies. From the predicted segmentations, we derive clinically
relevant biomarkers, such as corpus callosum length (LCC) and volume, and show
their utility in distinguishing CCD subtypes. Our pathology-informed
augmentation reduces the LCC estimation error from 1.89 mm to 0.80 mm in
healthy cases and from 10.9 mm to 0.7 mm in CCD cases. Beyond these
quantitative gains, our approach yields segmentations with improved topological
consistency relative to available ground truth, enabling more reliable
shape-based analyses. Overall, this work demonstrates that incorporating
domain-specific anatomical priors into synthetic data pipelines can effectively
mitigate data scarcity and enhance analysis of rare but clinically significant
malformations.

</details>


### [55] [COMETH: Convex Optimization for Multiview Estimation and Tracking of Humans](https://arxiv.org/abs/2508.20920)
*Enrico Martini,Ho Jin Choi,Nadia Figueroa,Nicola Bombieri*

Main category: cs.CV

TL;DR: COMETH是一种轻量级、实时的多视角人体姿态融合算法，通过整合运动学和生物力学约束、基于凸优化的逆运动学以及状态观测器，解决了边缘设备分布式处理中精度下降和时空不一致的问题，实现了高精度、可扩展的人体运动追踪。


<details>
  <summary>Details</summary>
Motivation: 在工业5.0时代，人体活动监测对于人体工程学安全和整体福祉至关重要。多摄像头集中式设置虽然提高了姿态估计精度，但计算成本和带宽需求高，限制了可扩展性和实时应用。将处理分布到边缘设备可以降低网络带宽和计算负载，但边缘设备的资源限制导致精度下降，且计算分布引入时空不一致性。

Method: 本文提出了COMETH（用于多视角人体估计和追踪的凸优化）算法，它依赖于三个核心概念：1. 整合运动学和生物力学约束以提高关节定位精度；2. 采用基于凸优化的逆运动学进行空间融合；3. 实现一个状态观测器以改善时间一致性。

Result: COMETH在公共和工业数据集上均优于现有最先进方法，在定位、检测和追踪精度方面表现出色。所提出的融合管道实现了准确且可扩展的人体运动追踪。

Conclusion: COMETH算法能够实现准确且可扩展的人体运动追踪，非常适用于工业和安全关键型应用。

Abstract: In the era of Industry 5.0, monitoring human activity is essential for
ensuring both ergonomic safety and overall well-being. While multi-camera
centralized setups improve pose estimation accuracy, they often suffer from
high computational costs and bandwidth requirements, limiting scalability and
real-time applicability. Distributing processing across edge devices can reduce
network bandwidth and computational load. On the other hand, the constrained
resources of edge devices lead to accuracy degradation, and the distribution of
computation leads to temporal and spatial inconsistencies. We address this
challenge by proposing COMETH (Convex Optimization for Multiview Estimation and
Tracking of Humans), a lightweight algorithm for real-time multi-view human
pose fusion that relies on three concepts: it integrates kinematic and
biomechanical constraints to increase the joint positioning accuracy; it
employs convex optimization-based inverse kinematics for spatial fusion; and it
implements a state observer to improve temporal consistency. We evaluate COMETH
on both public and industrial datasets, where it outperforms state-of-the-art
methods in localization, detection, and tracking accuracy. The proposed fusion
pipeline enables accurate and scalable human motion tracking, making it
well-suited for industrial and safety-critical applications. The code is
publicly available at https://github.com/PARCO-LAB/COMETH.

</details>


### [56] [CaddieSet: A Golf Swing Dataset with Human Joint Features and Ball Information](https://arxiv.org/abs/2508.20491)
*Seunghyeon Jung,Seoyoung Hong,Jiwoo Jeong,Seungwon Jeong,Jaerim Choi,Hoki Kim,Woojin Lee*

Main category: cs.CV

TL;DR: 本文提出了一个名为CaddieSet的新数据集，用于量化高尔夫挥杆姿态与球轨迹之间的关系，通过计算机视觉提取关节信息和专家定义的关键指标，旨在为高尔夫挥杆改进提供可解释的洞察。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能定量建立挥杆姿态与球轨迹之间的关系，从而限制了为高尔夫球手提供必要的挥杆改进见解的能力。

Method: 本文提出了CaddieSet数据集，包含单次击球的关节信息和各种球信息。通过基于计算机视觉的方法将单次挥杆视频分割成八个挥杆阶段来提取关节信息。此外，基于专家高尔夫领域知识，定义了15个影响高尔夫挥杆的关键指标，从而能够通过挥杆相关特征解释挥杆结果。

Result: 实验证明CaddieSet在利用各种基准预测球轨迹方面是可行的。特别是，通过可解释模型验证了使用关节特征的挥杆反馈与已建立的领域知识在定量上是一致的。

Conclusion: 这项工作有望为学术界和体育产业的高尔夫挥杆分析提供新的见解。

Abstract: Recent advances in deep learning have led to more studies to enhance golfers'
shot precision. However, these existing studies have not quantitatively
established the relationship between swing posture and ball trajectory,
limiting their ability to provide golfers with the necessary insights for swing
improvement. In this paper, we propose a new dataset called CaddieSet, which
includes joint information and various ball information from a single shot.
CaddieSet extracts joint information from a single swing video by segmenting it
into eight swing phases using a computer vision-based approach. Furthermore,
based on expert golf domain knowledge, we define 15 key metrics that influence
a golf swing, enabling the interpretation of swing outcomes through
swing-related features. Through experiments, we demonstrated the feasibility of
CaddieSet for predicting ball trajectories using various benchmarks. In
particular, we focus on interpretable models among several benchmarks and
verify that swing feedback using our joint features is quantitatively
consistent with established domain knowledge. This work is expected to offer
new insight into golf swing analysis for both academia and the sports industry.

</details>


### [57] [Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding](https://arxiv.org/abs/2508.20478)
*Yuan Xie,Tianshui Chen,Zheng Ge,Lionel Ni*

Main category: cs.CV

TL;DR: 本文提出Video-MTR，一个强化的多轮推理框架，用于长视频理解。它通过迭代选择关键视频片段和问题理解，结合门控双层奖励系统实现端到端训练，无需外部视觉-语言模型，显著提升了长视频理解的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 长视频理解面临长距离时间依赖和多事件的挑战。现有方法（如静态推理或依赖外部视觉-语言模型）存在复杂性高、性能次优以及缺乏端到端训练的问题。

Method: 本文提出了Video-MTR，一个强化的多轮推理框架。它通过迭代选择关键视频片段和理解问题来执行推理。与传统单轮预测不同，Video-MTR在多轮中逐步选择视频片段，并根据对先前处理片段和当前问题的理解进行调整。为确保中间推理过程，引入了一种新颖的门控双层奖励系统，结合了基于答案正确性的轨迹级奖励和强调帧-查询相关性的轮级奖励，从而优化视频片段选择和问题理解，并支持端到端训练，无需外部视觉-语言模型。

Result: 在VideoMME、MLVU和EgoSchema等基准测试中，Video-MTR在准确性和效率方面均优于现有方法，提升了长视频理解的最新技术水平。

Conclusion: Video-MTR通过其强化的多轮推理框架和新颖的双层奖励系统，有效解决了长视频理解中的挑战，实现了更精细、上下文感知的分析，并在多个基准测试中取得了领先性能，推动了长视频理解领域的发展。

Abstract: Long-form video understanding, characterized by long-range temporal
dependencies and multiple events, remains a challenge. Existing methods often
rely on static reasoning or external visual-language models (VLMs), which face
issues like complexity and sub-optimal performance due to the lack of
end-to-end training. In this paper, we propose Video-MTR, a reinforced
multi-turn reasoning framework designed to enable iterative key video segment
selection and question comprehension. Unlike traditional video reasoning
pipeline, which generate predictions in a single turn, Video-MTR performs
reasoning in multiple turns, selecting video segments progressively based on
the evolving understanding of previously processed segments and the current
question. This iterative process allows for a more refined and contextually
aware analysis of the video. To ensure intermediate reasoning process, we
introduce a novel gated bi-level reward system, combining trajectory-level
rewards based on answer correctness and turn-level rewards emphasizing
frame-query relevance. This system optimizes both video segment selection and
question comprehension, eliminating the need for external VLMs and allowing
end-to-end training. Extensive experiments on benchmarks like VideoMME, MLVU,
and EgoSchema demonstrate that Video-MTR outperforms existing methods in both
accuracy and efficiency, advancing the state-of-the-art in long video
understanding.

</details>


### [58] [CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification](https://arxiv.org/abs/2508.21046)
*Wei Li,Renshan Zhang,Rui Shao,Jie He,Liqiang Nie*

Main category: cs.CV

TL;DR: CogVLA是一个认知对齐的视觉-语言-动作（VLA）框架，通过指令驱动的路由和稀疏化，显著提高了VLA模型的效率和性能，解决了现有模型计算开销大的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于预训练视觉-语言模型（VLM）构建的VLA模型需要大量的后期训练，导致计算开销巨大，限制了其可扩展性和部署能力。

Method: CogVLA受人类多模态协调启发，提出了一个三阶段渐进式架构：1) 编码器-FiLM聚合路由（EFA-Routing）将指令信息注入视觉编码器，选择性地聚合和压缩双流视觉token，形成指令感知的潜在表示。2) 基于紧凑视觉编码，LLM-FiLM剪枝路由（LFP-Routing）通过剪枝与指令无关的视觉接地token，将动作意图引入语言模型，实现token级稀疏性。3) V-L-A耦合注意力（CAtten）结合因果视觉-语言注意力与双向动作并行解码，确保压缩后的感知输入仍能支持准确连贯的动作生成。

Result: CogVLA在LIBERO基准测试和真实机器人任务中均取得了最先进的性能，成功率分别为97.4%和70.0%。与OpenVLA相比，训练成本降低了2.5倍，推理延迟降低了2.8倍。

Conclusion: CogVLA通过认知对齐的指令驱动路由和稀疏化方法，有效解决了VLA模型计算开销大的问题，在保持高性能的同时显著提升了效率，为VLA模型的可扩展性和部署提供了新的解决方案。

Abstract: Recent Vision-Language-Action (VLA) models built on pre-trained
Vision-Language Models (VLMs) require extensive post-training, resulting in
high computational overhead that limits scalability and deployment.We propose
CogVLA, a Cognition-Aligned Vision-Language-Action framework that leverages
instruction-driven routing and sparsification to improve both efficiency and
performance. CogVLA draws inspiration from human multimodal coordination and
introduces a 3-stage progressive architecture. 1) Encoder-FiLM based
Aggregation Routing (EFA-Routing) injects instruction information into the
vision encoder to selectively aggregate and compress dual-stream visual tokens,
forming a instruction-aware latent representation. 2) Building upon this
compact visual encoding, LLM-FiLM based Pruning Routing (LFP-Routing)
introduces action intent into the language model by pruning
instruction-irrelevant visually grounded tokens, thereby achieving token-level
sparsity. 3) To ensure that compressed perception inputs can still support
accurate and coherent action generation, we introduce V-L-A Coupled Attention
(CAtten), which combines causal vision-language attention with bidirectional
action parallel decoding. Extensive experiments on the LIBERO benchmark and
real-world robotic tasks demonstrate that CogVLA achieves state-of-the-art
performance with success rates of 97.4% and 70.0%, respectively, while reducing
training costs by 2.5-fold and decreasing inference latency by 2.8-fold
compared to OpenVLA. CogVLA is open-sourced and publicly available at
https://github.com/JiuTian-VL/CogVLA.

</details>


### [59] [Towards Mechanistic Defenses Against Typographic Attacks in CLIP](https://arxiv.org/abs/2508.20570)
*Lorenz Hufe,Constantin Venhoff,Maximilian Dreyer,Sebastian Lapuschkin,Wojciech Samek*

Main category: cs.CV

TL;DR: 本文分析了CLIP模型在排版攻击下的行为，识别出负责处理排版信息的特定注意力头（即“排版电路”）。在此基础上，提出了一种无需微调的防御方法，通过选择性地消融这些注意力头，显著提高了模型对排版攻击的鲁棒性，同时对标准性能影响甚微。


<details>
  <summary>Details</summary>
Motivation: 排版攻击通过在图像中注入文本来利用多模态系统，导致目标错误分类、恶意内容生成甚至视觉-语言模型越狱。因此，理解CLIP视觉编码器在排版攻击下的行为，并开发有效的防御机制，对于提高系统安全性至关重要。

Method: 研究方法包括分析CLIP视觉编码器在排版攻击下的表现，定位模型后半层中专门负责提取并将排版信息传输到cls token的注意力头（即“排版电路”）。在此基础上，引入了一种防御方法，通过选择性地消融这些注意力头来防御排版攻击，且无需进行微调。

Result: 研究发现，通过消融排版电路，模型在ImageNet-100的排版变体上性能提升高达19.6%，而标准ImageNet-100准确率下降不到1%。这种无需训练的方法与当前依赖微调的最先进排版防御方法具有竞争力。为此，研究发布了一系列“阅读障碍”CLIP模型，这些模型对排版攻击具有显著更强的鲁棒性。

Conclusion: 排版攻击是多模态系统面临的严重威胁。通过理解CLIP内部处理排版信息的机制并选择性地消融相关注意力头，可以在不进行微调的情况下有效提升模型对排版攻击的鲁棒性。这些“阅读障碍”CLIP模型可作为安全关键型应用的即插即用替代品，适用于文本操纵风险高于文本识别效用的场景。

Abstract: Typographic attacks exploit multi-modal systems by injecting text into
images, leading to targeted misclassifications, malicious content generation
and even Vision-Language Model jailbreaks. In this work, we analyze how CLIP
vision encoders behave under typographic attacks, locating specialized
attention heads in the latter half of the model's layers that causally extract
and transmit typographic information to the cls token. Building on these
insights, we introduce a method to defend CLIP models against typographic
attacks by selectively ablating a typographic circuit, consisting of attention
heads. Without requiring finetuning, our method improves performance by up to
19.6% on a typographic variant of ImageNet-100, while reducing standard
ImageNet-100 accuracy by less than 1%. Notably, our training-free approach
remains competitive with current state-of-the-art typographic defenses that
rely on finetuning. To this end, we release a family of dyslexic CLIP models
which are significantly more robust against typographic attacks. These models
serve as suitable drop-in replacements for a broad range of safety-critical
applications, where the risks of text-based manipulation outweigh the utility
of text recognition.

</details>


### [60] [Adaptive Dual Uncertainty Optimization: Boosting Monocular 3D Object Detection under Test-Time Shifts](https://arxiv.org/abs/2508.20488)
*Zixuan Hu,Dongxiao Li,Xinzhu Ma,Shixiang Tang,Xiaotong Li,Wenhan Yang,Ling-Yu Duan*

Main category: cs.CV

TL;DR: 本文提出DUO框架，首个针对单目3D目标检测（M3OD）的测试时自适应（TTA）方法，旨在联合最小化语义不确定性和几何不确定性，以提高在领域偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测在自动驾驶等安全关键应用中至关重要，但其可靠性在环境或传感器变化引起的领域偏移下显著下降。现有TTA方法未能解决M3OD固有的双重不确定性：语义不确定性（模糊的类别预测）和几何不确定性（不稳定的空间定位）。

Method: DUO框架通过以下方法共同解决双重不确定性：1) 引入焦点损失的创新凸结构，并推导出一个新颖的无监督版本，实现与标签无关的不确定性加权和对高不确定性物体的平衡学习，以解决语义不确定性。2) 设计一个语义感知法线场约束，在具有清晰语义线索的区域保持几何一致性，从而减少不稳定3D表示带来的几何不确定性。这两个分支形成互补循环。

Result: 广泛的实验证明，DUO在各种数据集和领域偏移类型上均优于现有方法。

Conclusion: DUO是首个通过联合最小化语义和几何不确定性来增强单目3D目标检测鲁棒性的TTA框架，有效提升了模型在真实世界领域偏移下的性能。

Abstract: Accurate monocular 3D object detection (M3OD) is pivotal for safety-critical
applications like autonomous driving, yet its reliability deteriorates
significantly under real-world domain shifts caused by environmental or sensor
variations. To address these shifts, Test-Time Adaptation (TTA) methods have
emerged, enabling models to adapt to target distributions during inference.
While prior TTA approaches recognize the positive correlation between low
uncertainty and high generalization ability, they fail to address the dual
uncertainty inherent to M3OD: semantic uncertainty (ambiguous class
predictions) and geometric uncertainty (unstable spatial localization). To
bridge this gap, we propose Dual Uncertainty Optimization (DUO), the first TTA
framework designed to jointly minimize both uncertainties for robust M3OD.
Through a convex optimization lens, we introduce an innovative convex structure
of the focal loss and further derive a novel unsupervised version, enabling
label-agnostic uncertainty weighting and balanced learning for high-uncertainty
objects. In parallel, we design a semantic-aware normal field constraint that
preserves geometric coherence in regions with clear semantic cues, reducing
uncertainty from the unstable 3D representation. This dual-branch mechanism
forms a complementary loop: enhanced spatial perception improves semantic
classification, and robust semantic predictions further refine spatial
understanding. Extensive experiments demonstrate the superiority of DUO over
existing methods across various datasets and domain shift types.

</details>


### [61] [ArtFace: Towards Historical Portrait Face Identification via Model Adaptation](https://arxiv.org/abs/2508.20626)
*Francois Poh,Anjith George,Sébastien Marcel*

Main category: cs.CV

TL;DR: 本文研究了如何利用基础模型改进历史绘画中的人脸识别，通过微调基础模型并结合传统人脸识别网络的嵌入，显著优于现有技术，弥补了传统方法在艺术作品识别上的不足。


<details>
  <summary>Details</summary>
Motivation: 识别历史绘画中的人物对艺术史学家至关重要，但传统方法主观且受数据和风格限制。自动化人脸识别虽有潜力，但传统模型在处理绘画时因领域偏移和高类内变异而表现不佳，艺术因素进一步加剧了识别难度。因此，需要更有效的方法来应对这些挑战。

Method: 研究探索了基础模型在艺术作品人脸识别中的潜力。具体方法包括微调基础模型，并将微调后的基础模型嵌入与传统人脸识别网络的嵌入相结合。

Result: 研究结果表明，通过上述方法，在艺术作品人脸识别方面取得了显著优于当前最先进方法的改进。基础模型能够弥合传统方法无效的鸿沟。

Conclusion: 基础模型能够有效提升艺术作品中的人脸识别性能，特别是在传统方法难以奏效的领域，展现了其巨大的应用潜力。

Abstract: Identifying sitters in historical paintings is a key task for art historians,
offering insight into their lives and how they chose to be seen. However, the
process is often subjective and limited by the lack of data and stylistic
variations. Automated facial recognition is capable of handling challenging
conditions and can assist, but while traditional facial recognition models
perform well on photographs, they struggle with paintings due to domain shift
and high intra-class variation. Artistic factors such as style, skill, intent,
and influence from other works further complicate recognition. In this work, we
investigate the potential of foundation models to improve facial recognition in
artworks. By fine-tuning foundation models and integrating their embeddings
with those from conventional facial recognition networks, we demonstrate
notable improvements over current state-of-the-art methods. Our results show
that foundation models can bridge the gap where traditional methods are
ineffective. Paper page at https://www.idiap.ch/paper/artface/

</details>


### [62] [IAENet: An Importance-Aware Ensemble Model for 3D Point Cloud-Based Anomaly Detection](https://arxiv.org/abs/2508.20492)
*Xuanming Cao,Chengyu Tao,Yifeng Cheng,Juan Du*

Main category: cs.CV

TL;DR: 本文提出IAENet，一种结合2D预训练专家和3D专家模型的集成框架，通过重要性感知融合模块动态评估并重新加权各来源贡献，显著提升了3D表面异常检测的性能，并在MVTec 3D-AD数据集上达到新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 工业制造中表面异常检测对产品质量至关重要。尽管2D图像方法已取得成功，但3D点云检测因缺乏强大的预训练基础骨干而未被充分探索。此外，简单融合不同来源的预测效果不佳，容易受表现不佳的模态影响，导致整体准确性下降。

Method: 本文提出重要性感知集成网络（IAENet），一个结合2D预训练专家和3D专家模型的集成框架。为解决融合难题，引入了新颖的重要性感知融合（IAF）模块，该模块能动态评估各来源的贡献并重新加权其异常分数。此外，设计了关键的损失函数来显式指导IAF的优化，使其能结合专家知识并保留其独特优势。

Result: 在MVTec 3D-AD数据集上进行的广泛实验表明，IAENet取得了新的最先进（SOTA）性能，并显著降低了误报率。

Conclusion: IAENet显著增强了3D表面异常检测的整体性能，特别是在降低误报率方面表现突出，这突显了其在工业部署中的实际价值。

Abstract: Surface anomaly detection is pivotal for ensuring product quality in
industrial manufacturing. While 2D image-based methods have achieved remarkable
success, 3D point cloud-based detection remains underexplored despite its
richer geometric cues. We argue that the key bottleneck is the absence of
powerful pretrained foundation backbones in 3D comparable to those in 2D. To
bridge this gap, we propose Importance-Aware Ensemble Network (IAENet), an
ensemble framework that synergizes 2D pretrained expert with 3D expert models.
However, naively fusing predictions from disparate sources is non-trivial:
existing strategies can be affected by a poorly performing modality and thus
degrade overall accuracy. To address this challenge, We introduce an novel
Importance-Aware Fusion (IAF) module that dynamically assesses the contribution
of each source and reweights their anomaly scores. Furthermore, we devise
critical loss functions that explicitly guide the optimization of IAF, enabling
it to combine the collective knowledge of the source experts but also preserve
their unique strengths, thereby enhancing the overall performance of anomaly
detection. Extensive experiments on MVTec 3D-AD demonstrate that our IAENet
achieves a new state-of-the-art with a markedly lower false positive rate,
underscoring its practical value for industrial deployment.

</details>


### [63] [MobileCLIP2: Improving Multi-Modal Reinforced Training](https://arxiv.org/abs/2508.20691)
*Fartash Faghri,Pavan Kumar Anasosalu Vasu,Cem Koc,Vaishaal Shankar,Alexander Toshev,Oncel Tuzel,Hadi Pouransari*

Main category: cs.CV

TL;DR: 本文通过改进多模态强化训练，提出了MobileCLIP2模型家族，在保持低延迟的同时显著提升了零样本ImageNet-1k准确率，超越了现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: MobileCLIP模型已在低延迟和零样本准确率方面取得了领先成果，但研究者希望通过优化其多模态强化训练方法，进一步提升模型的性能和效率，探索更好的教师模型和训练策略。

Method: 研究者通过以下方法改进了MobileCLIP的多模态强化训练：1) 使用DFN数据集训练更好的CLIP教师集成模型；2) 使用DFN数据集训练并用高质量图文数据集微调的改进字幕生成器教师模型。此外，他们还通过消融实验发现了对比知识蒸馏中温度调优的重要性、字幕生成器微调对字幕多样性的有效性，以及结合多个模型生成的合成字幕带来的累加改进。

Result: 研究者训练了一个名为MobileCLIP2的新模型家族，实现了低延迟下最先进的ImageNet-1k零样本准确率。具体而言，MobileCLIP2-B相比MobileCLIP-B架构的ImageNet-1k准确率提升了2.2%。值得注意的是，MobileCLIP2-S4在ImageNet-1k上的零样本准确率与SigLIP-SO400M/14相当，但模型尺寸小2倍；同时，在2.5倍更低延迟的情况下超越了DFN ViT-L/14。

Conclusion: MobileCLIP2通过改进的多模态强化训练，成功地在低延迟和高零样本准确率之间取得了新的平衡，显著提升了图像-文本基础模型的性能和效率，为实际应用提供了更优选择。研究结果也揭示了强化训练中关键组件（如教师模型和超参数）的重要洞察。

Abstract: Foundation image-text models such as CLIP with zero-shot capabilities enable
a wide array of applications. MobileCLIP is a recent family of image-text
models at 3-15ms latency and 50-150M parameters with state-of-the-art zero-shot
accuracy. The main ingredients in MobileCLIP were its low-latency and light
architectures and a novel multi-modal reinforced training that made knowledge
distillation from multiple caption-generators and CLIP teachers efficient,
scalable, and reproducible. In this paper, we improve the multi-modal
reinforced training of MobileCLIP through: 1) better CLIP teacher ensembles
trained on the DFN dataset, 2) improved captioner teachers trained on the DFN
dataset and fine-tuned on a diverse selection of high-quality image-caption
datasets. We discover new insights through ablations such as the importance of
temperature tuning in contrastive knowledge distillation, the effectiveness of
caption-generator fine-tuning for caption diversity, and the additive
improvement from combining synthetic captions generated by multiple models. We
train a new family of models called MobileCLIP2 and achieve state-of-the-art
ImageNet-1k zero-shot accuracies at low latencies. In particular, we observe
2.2% improvement in ImageNet-1k accuracy for MobileCLIP2-B compared with
MobileCLIP-B architecture. Notably, MobileCLIP2-S4 matches the zero-shot
accuracy of SigLIP-SO400M/14 on ImageNet-1k while being 2$\times$ smaller and
improves on DFN ViT-L/14 at 2.5$\times$ lower latency. We release our
pretrained models (https://github.com/apple/ml-mobileclip) and the data
generation code (https://github.com/apple/ml-mobileclip-dr). The data
generation code makes it easy to create new reinforced datasets with arbitrary
teachers using distributed scalable processing.

</details>


### [64] [Describe, Don't Dictate: Semantic Image Editing with Natural Language Intent](https://arxiv.org/abs/2508.20505)
*En Ci,Shanyan Guan,Yanhao Ge,Yilin Zhang,Wei Li,Zhenyu Zhang,Jian Yang,Ying Tai*

Main category: cs.CV

TL;DR: 本论文提出了一个名为DescriptiveEdit的描述性提示图像编辑框架，它将指令式图像编辑重新定义为基于参考图的文本到图像生成，通过引入交叉注意力UNet提升了编辑准确性和一致性，并克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到图像生成取得了进展，但语义图像编辑仍面临挑战。基于反演的算法不可避免地引入重建误差，而基于指令的模型主要受限于数据集质量和规模。

Method: 该研究提出了DescriptiveEdit框架。其核心思想是将“指令式图像编辑”重新定义为“基于参考图的文本到图像生成”，从而保留了预训练文本到图像模型的生成能力，无需修改架构或进行反演。具体而言，它引入了一个交叉注意力UNet，该UNet新增了注意力桥接，将参考图像特征注入到提示到编辑图像的生成过程中。

Result: 由于其文本到图像的本质，DescriptiveEdit克服了指令数据集质量的限制，能与ControlNet、IP-Adapter等扩展无缝集成，且更具可扩展性。在Emu Edit基准测试上的实验表明，它提高了编辑的准确性和一致性。

Conclusion: DescriptiveEdit通过将指令式图像编辑重构为基于参考图的文本到图像生成，提供了一种无需修改T2I模型架构或反演，即可实现高效、准确和一致语义图像编辑的新范式，有效解决了现有方法的缺陷。

Abstract: Despite the progress in text-to-image generation, semantic image editing
remains a challenge. Inversion-based algorithms unavoidably introduce
reconstruction errors, while instruction-based models mainly suffer from
limited dataset quality and scale. To address these problems, we propose a
descriptive-prompt-based editing framework, named DescriptiveEdit. The core
idea is to re-frame `instruction-based image editing' as `reference-image-based
text-to-image generation', which preserves the generative power of well-trained
Text-to-Image models without architectural modifications or inversion.
Specifically, taking the reference image and a prompt as input, we introduce a
Cross-Attentive UNet, which newly adds attention bridges to inject reference
image features into the prompt-to-edit-image generation process. Owing to its
text-to-image nature, DescriptiveEdit overcomes limitations in instruction
dataset quality, integrates seamlessly with ControlNet, IP-Adapter, and other
extensions, and is more scalable. Experiments on the Emu Edit benchmark show it
improves editing accuracy and consistency.

</details>


### [65] [${C}^{3}$-GS: Learning Context-aware, Cross-dimension, Cross-scale Feature for Generalizable Gaussian Splatting](https://arxiv.org/abs/2508.20754)
*Yuxi Hu,Jun Zhang,Kuangyi Chen,Zhe Zhang,Friedrich Fraundorfer*

Main category: cs.CV

TL;DR: C³-GS 是一种可泛化的高斯泼溅框架，通过引入上下文感知、跨维度和跨尺度的约束来增强特征学习，从而实现从稀疏视图中进行高质量、逼真的新视图合成。


<details>
  <summary>Details</summary>
Motivation: 现有可泛化高斯泼溅方法在编码判别性、多视图一致的特征方面存在不足，导致从稀疏输入视图构建精确几何时遇到困难。

Method: 本文提出了 C³-GS 框架，通过整合上下文感知、跨维度和跨尺度约束来增强特征学习。该架构将三个轻量级模块集成到统一的渲染管线中，以改善特征融合，无需额外监督即可实现逼真的合成。

Result: 在基准数据集上的大量实验验证了 C³-GS 实现了最先进的渲染质量和泛化能力。

Conclusion: C³-GS 通过改进特征学习，有效解决了现有方法在稀疏视图下几何构造不准确的问题，实现了高质量、逼真的新视图合成和出色的泛化能力。

Abstract: Generalizable Gaussian Splatting aims to synthesize novel views for unseen
scenes without per-scene optimization. In particular, recent advancements
utilize feed-forward networks to predict per-pixel Gaussian parameters,
enabling high-quality synthesis from sparse input views. However, existing
approaches fall short in encoding discriminative, multi-view consistent
features for Gaussian predictions, which struggle to construct accurate
geometry with sparse views. To address this, we propose $\mathbf{C}^{3}$-GS, a
framework that enhances feature learning by incorporating context-aware,
cross-dimension, and cross-scale constraints. Our architecture integrates three
lightweight modules into a unified rendering pipeline, improving feature fusion
and enabling photorealistic synthesis without requiring additional supervision.
Extensive experiments on benchmark datasets validate that $\mathbf{C}^{3}$-GS
achieves state-of-the-art rendering quality and generalization ability. Code is
available at: https://github.com/YuhsiHu/C3-GS.

</details>


### [66] [DCFS: Continual Test-Time Adaptation via Dual Consistency of Feature and Sample](https://arxiv.org/abs/2508.20516)
*Wenting Yin,Han Sun,Xinru Meng,Ningzhong Liu,Huiyu Zhou*

Main category: cs.CV

TL;DR: 本文提出DCFS框架，通过双路径特征一致性和置信度感知样本学习，解决持续测试时间适应中目标数据特征单一依赖和伪标签误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 现有持续测试时间适应（CTTA）方法在缺乏源数据访问的情况下，过度依赖目标域数据特征，导致混淆和学习偏差。同时，基于模型预测生成的伪标签质量无法保证，存在误差累积问题。

Method: 本文提出DCFS框架，包含：1) 双路径特征一致性：使用双分类器将目标数据特征分解为语义相关和域相关特征，并通过保持子特征与整体特征的一致性，从多角度捕获数据特征。2) 置信度感知样本学习：设置自适应阈值并计算每个样本的置信度分数，进行损失加权的自监督学习，以减少伪标签噪声并缓解误差累积。

Result: DCFS方法在CIFAR10-C、CIFAR100-C和ImageNet-C等多个数据集上进行了广泛实验验证，在持续测试时间适应场景中表现出一致且有效的性能。

Conclusion: DCFS框架通过引入双路径特征一致性和置信度感知样本学习，有效解决了持续测试时间适应中的目标特征单一依赖和伪标签误差累积问题，提升了模型在无源数据访问情况下的适应能力和性能。

Abstract: Continual test-time adaptation aims to continuously adapt a pre-trained model
to a stream of target domain data without accessing source data. Without access
to source domain data, the model focuses solely on the feature characteristics
of the target data. Relying exclusively on these features can lead to confusion
and introduce learning biases. Currently, many existing methods generate
pseudo-labels via model predictions. However, the quality of pseudo-labels
cannot be guaranteed and the problem of error accumulation must be solved. To
address these challenges, we propose DCFS, a novel CTTA framework that
introduces dual-path feature consistency and confidence-aware sample learning.
This framework disentangles the whole feature representation of the target data
into semantic-related feature and domain-related feature using dual classifiers
to learn distinct feature representations. By maintaining consistency between
the sub-features and the whole feature, the model can comprehensively capture
data features from multiple perspectives. Additionally, to ensure that the
whole feature information of the target domain samples is not overlooked, we
set a adaptive threshold and calculate a confidence score for each sample to
carry out loss weighted self-supervised learning, effectively reducing the
noise of pseudo-labels and alleviating the problem of error accumulation. The
efficacy of our proposed method is validated through extensive experimentation
across various datasets, including CIFAR10-C, CIFAR100-C, and ImageNet-C,
demonstrating consistent performance in continual test-time adaptation
scenarios.

</details>


### [67] [SeqVLM: Proposal-Guided Multi-View Sequences Reasoning via VLM for Zero-Shot 3D Visual Grounding](https://arxiv.org/abs/2508.20758)
*Jiawen Lin,Shiran Bian,Yihang Zhu,Wenbin Tan,Yachao Zhang,Yuan Xie,Yanyun Qu*

Main category: cs.CV

TL;DR: SeqVLM是一个新颖的零样本3D视觉定位框架，它利用多视角真实场景图像和空间信息，通过3D实例提议、语义过滤、多视角投影和动态调度机制，解决了现有方法在空间推理和上下文细节上的不足，实现了3D视觉定位领域的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本3D视觉定位方法存在空间推理受限（依赖单视角定位）、上下文信息缺失或细节退化的问题。尽管监督方法在受限设置下精度较高，但零样本3D视觉定位在实际应用中更具前景，因为它无需特定场景的训练。

Method: SeqVLM框架首先通过3D语义分割网络生成3D实例提议，并进行语义过滤以保留相关候选。接着，采用提议引导的多视角投影策略，将这些候选提议投影到真实场景图像序列上，以保留空间关系和上下文细节。为减轻VLM计算负担，引入动态调度机制，迭代处理序列查询提示，利用VLM的跨模态推理能力识别目标对象。

Result: 在ScanRefer和Nr3D基准测试中，SeqVLM取得了最先进的性能，Acc@0.25分数分别为55.6%和53.2%，分别超越了现有零样本方法4.0%和5.2%。

Conclusion: SeqVLM显著提升了3D视觉定位的泛化能力和实际应用性，通过解决现有零样本方法的局限性，推动了该领域的发展。

Abstract: 3D Visual Grounding (3DVG) aims to localize objects in 3D scenes using
natural language descriptions. Although supervised methods achieve higher
accuracy in constrained settings, zero-shot 3DVG holds greater promise for
real-world applications since eliminating scene-specific training requirements.
However, existing zero-shot methods face challenges of spatial-limited
reasoning due to reliance on single-view localization, and contextual omissions
or detail degradation. To address these issues, we propose SeqVLM, a novel
zero-shot 3DVG framework that leverages multi-view real-world scene images with
spatial information for target object reasoning. Specifically, SeqVLM first
generates 3D instance proposals via a 3D semantic segmentation network and
refines them through semantic filtering, retaining only semantic-relevant
candidates. A proposal-guided multi-view projection strategy then projects
these candidate proposals onto real scene image sequences, preserving spatial
relationships and contextual details in the conversion process of 3D point
cloud to images. Furthermore, to mitigate VLM computational overload, we
implement a dynamic scheduling mechanism that iteratively processes
sequances-query prompts, leveraging VLM's cross-modal reasoning capabilities to
identify textually specified objects. Experiments on the ScanRefer and Nr3D
benchmarks demonstrate state-of-the-art performance, achieving Acc@0.25 scores
of 55.6% and 53.2%, surpassing previous zero-shot methods by 4.0% and 5.2%,
respectively, which advance 3DVG toward greater generalization and real-world
applicability. The code is available at https://github.com/JiawLin/SeqVLM.

</details>


### [68] [Adam SLAM - the last mile of camera calibration with 3DGS](https://arxiv.org/abs/2508.20526)
*Matthieu Gendrin,Stéphane Pateux,Xiaoran Jiang,Théo Ladune,Luce Morin*

Main category: cs.CV

TL;DR: 本文提出使用3DGS模型，通过反向传播新视图颜色损失来微调相机校准参数，从而显著提高新视图合成质量。


<details>
  <summary>Details</summary>
Motivation: 相机校准的质量对新视图合成的重建质量至关重要，即使1像素的校准误差也会产生显著影响。在缺乏真实场景地面真值的情况下，校准质量通常通过新视图合成质量来评估。

Method: 该研究提出利用3DGS模型，通过反向传播新视图颜色损失（针对相机参数）来微调相机校准。这意味着将相机参数作为可训练变量，通过优化渲染图像与真实图像之间的颜色差异来改进校准。

Result: 仅通过这种新校准方法，在3DGS参考数据集上，PSNR平均提高了0.4 dB。尽管微调过程可能较长，但对于Mip-NeRF 360等参考场景的校准，新视图质量是最重要的考量。

Conclusion: 通过3DGS模型对相机参数进行基于颜色损失的反向传播微调，能够有效提升相机校准质量，进而显著改善新视图合成效果。尽管训练时间可能较长，但对于追求高质量新视图的参考场景而言，这种方法是值得的。

Abstract: The quality of the camera calibration is of major importance for evaluating
progresses in novel view synthesis, as a 1-pixel error on the calibration has a
significant impact on the reconstruction quality. While there is no ground
truth for real scenes, the quality of the calibration is assessed by the
quality of the novel view synthesis. This paper proposes to use a 3DGS model to
fine tune calibration by backpropagation of novel view color loss with respect
to the cameras parameters. The new calibration alone brings an average
improvement of 0.4 dB PSNR on the dataset used as reference by 3DGS. The fine
tuning may be long and its suitability depends on the criticity of training
time, but for calibration of reference scenes, such as Mip-NeRF 360, the stake
of novel view quality is the most important.

</details>


### [69] [Occlusion Robustness of CLIP for Military Vehicle Classification](https://arxiv.org/abs/2508.20760)
*Jan Erik van Woerden,Gertjan Burghouts,Lotte Nijskens,Alma M. Liezenga,Sabina van Rooij,Frank Ruis,Hugo J. Kuijf*

Main category: cs.CV

TL;DR: 本文研究了CLIP模型在军事环境中对遮挡的鲁棒性，发现Transformer模型优于CNN，精细遮挡影响更大，并通过微调骨干网络显著提升了模型对遮挡的抵抗能力。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（如CLIP）在数据稀缺的防御应用中具有优势，但其在军事环境（如部分遮挡和信噪比下降）下的鲁棒性尚未得到充分探索。

Method: 研究人员使用包含18种军事车辆的自定义数据集，评估了不同CLIP变体对遮挡的鲁棒性。评估指标为归一化曲线下面积（NAUC），并分析了不同遮挡百分比下的性能。比较了基于Transformer和CNN的CLIP模型，以及线性探测和微调（finetuning）后的模型。

Result: 主要发现包括：1) 基于Transformer的CLIP模型性能始终优于CNN模型；2) 细粒度、分散的遮挡比大块连续遮挡对性能的损害更大；3) 线性探测模型的性能在约35%遮挡时急剧下降；4) 通过微调模型骨干，性能下降的阈值可以推迟到超过60%的遮挡。

Conclusion: 研究强调了训练过程中遮挡特定增强的重要性，以及未来需进一步探索补丁级敏感性和架构弹性，以实现CLIP在实际世界中的部署。

Abstract: Vision-language models (VLMs) like CLIP enable zero-shot classification by
aligning images and text in a shared embedding space, offering advantages for
defense applications with scarce labeled data. However, CLIP's robustness in
challenging military environments, with partial occlusion and degraded
signal-to-noise ratio (SNR), remains underexplored. We investigate CLIP
variants' robustness to occlusion using a custom dataset of 18 military vehicle
classes and evaluate using Normalized Area Under the Curve (NAUC) across
occlusion percentages. Four key insights emerge: (1) Transformer-based CLIP
models consistently outperform CNNs, (2) fine-grained, dispersed occlusions
degrade performance more than larger contiguous occlusions, (3) despite
improved accuracy, performance of linear-probed models sharply drops at around
35% occlusion, (4) by finetuning the model's backbone, this performance drop
occurs at more than 60% occlusion. These results underscore the importance of
occlusion-specific augmentations during training and the need for further
exploration into patch-level sensitivity and architectural resilience for
real-world deployment of CLIP.

</details>


### [70] [Learning What is Worth Learning: Active and Sequential Domain Adaptation for Multi-modal Gross Tumor Volume Segmentation](https://arxiv.org/abs/2508.20528)
*Jingyun Yang,Guoqing Zhang,Jingge Wang,Yang Li*

Main category: cs.CV

TL;DR: 本文提出了一种主动序列域适应（ADA）框架，用于多模态医学图像的动态样本选择，以降低肿瘤体积（GTV）分割的标注成本，并通过基于信息量和代表性的查询策略显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 鼻咽癌和胶质母细胞瘤的GTV分割对放疗规划至关重要。深度学习需要大量标注数据，但医学图像标注耗时费力。现有主动域适应方法存在负迁移、源数据访问受限以及缺乏多模态数据查询策略的问题。

Method: 我们提出了一种主动序列域适应（ADA）框架，用于多模态医学数据中的动态样本选择。该框架导出了一个查询策略，根据样本的信息量和代表性优先选择最有价值的样本进行标注和训练。

Result: 在多样的GTV分割任务中，我们的方法取得了良好的分割性能，并显著优于现有最先进的主动域适应方法。

Conclusion: 所提出的主动序列域适应框架及其新颖的查询策略，能有效降低多模态医学数据中GTV分割的标注成本，并提升分割性能。

Abstract: Accurate gross tumor volume segmentation on multi-modal medical data is
critical for radiotherapy planning in nasopharyngeal carcinoma and
glioblastoma. Recent advances in deep neural networks have brought promising
results in medical image segmentation, leading to an increasing demand for
labeled data. Since labeling medical images is time-consuming and
labor-intensive, active learning has emerged as a solution to reduce annotation
costs by selecting the most informative samples to label and adapting
high-performance models with as few labeled samples as possible. Previous
active domain adaptation (ADA) methods seek to minimize sample redundancy by
selecting samples that are farthest from the source domain. However, such
one-off selection can easily cause negative transfer, and access to source
medical data is often limited. Moreover, the query strategy for multi-modal
medical data remains unexplored. In this work, we propose an active and
sequential domain adaptation framework for dynamic multi-modal sample selection
in ADA. We derive a query strategy to prioritize labeling and training on the
most valuable samples based on their informativeness and representativeness.
Empirical validation on diverse gross tumor volume segmentation tasks
demonstrates that our method achieves favorable segmentation performance,
significantly outperforming state-of-the-art ADA methods. Code is available at
the git repository: \href{https://github.com/Hiyoochan/mmActS}{mmActS}.

</details>


### [71] [Looking Beyond the Obvious: A Survey on Abstract Concept Recognition for Video Understanding](https://arxiv.org/abs/2508.20765)
*Gowreesh Mago,Pascal Mettes,Stevan Rudinac*

Main category: cs.CV

TL;DR: 这篇综述探讨了视频中抽象概念理解的挑战，指出虽然机器在具体内容理解方面取得了进展，但在抽象概念（如正义、自由）方面仍远不及人类。文章认为基础模型为解决这一问题提供了理想环境，并呼吁借鉴社区长期经验，避免重复劳动。


<details>
  <summary>Details</summary>
Motivation: 机器在视频中理解具体实体（如物体、动作）的能力日益增强，但无法像人类一样识别“正义”、“自由”等抽象概念。这种抽象概念识别是视频理解中的一个关键开放挑战，对齐模型与人类推理和价值观至关重要。

Method: 本文是一篇综述，研究了用于理解视频内容中抽象概念的不同任务和数据集。它主张利用多模态基础模型的最新进展来解决这一挑战，并强调借鉴数十年来社区经验的重要性。

Result: 研究发现，研究人员长期以来一直在尝试解决这些任务，并充分利用了当时可用的工具。文章提出，基础模型的兴起为重新审视和解决视频中的抽象概念理解提供了理想环境。

Conclusion: 抽象概念识别是视频理解领域的一个重要开放挑战。基础模型的出现为此提供了新的机遇。借鉴社区数十年的经验，对于有效解决这一挑战并避免“重复造轮子”至关关重要。

Abstract: The automatic understanding of video content is advancing rapidly. Empowered
by deeper neural networks and large datasets, machines are increasingly capable
of understanding what is concretely visible in video frames, whether it be
objects, actions, events, or scenes. In comparison, humans retain a unique
ability to also look beyond concrete entities and recognize abstract concepts
like justice, freedom, and togetherness. Abstract concept recognition forms a
crucial open challenge in video understanding, where reasoning on multiple
semantic levels based on contextual information is key. In this paper, we argue
that the recent advances in foundation models make for an ideal setting to
address abstract concept understanding in videos. Automated understanding of
high-level abstract concepts is imperative as it enables models to be more
aligned with human reasoning and values. In this survey, we study different
tasks and datasets used to understand abstract concepts in video content. We
observe that, periodically and over a long period, researchers have attempted
to solve these tasks, making the best use of the tools available at their
disposal. We advocate that drawing on decades of community experience will help
us shed light on this important open grand challenge and avoid ``re-inventing
the wheel'' as we start revisiting it in the era of multi-modal foundation
models.

</details>


### [72] [Enhancing Pseudo-Boxes via Data-Level LiDAR-Camera Fusion for Unsupervised 3D Object Detection](https://arxiv.org/abs/2508.20530)
*Mingqian Ji,Jian Yang,Shanshan Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的数据级融合框架，用于无监督3D目标检测，通过早期融合RGB图像和LiDAR数据，并结合双向融合和噪声过滤策略，显著提高了伪框质量和定位精度，超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR-based 3D目标检测器依赖大量手动标注，耗时费力。当前无监督方法通过引入RGB图像辅助伪框生成，但其标签级融合策略未能充分利用LiDAR和RGB数据的互补性，导致伪框质量提升有限。

Method: 提出数据级融合框架，在早期阶段整合RGB图像和LiDAR数据。具体包括：利用视觉基础模型进行图像实例分割和深度估计；采用双向融合方法，使3D点从2D空间获取类别标签，同时将2D像素投影到3D以增强点云密度；设计局部半径过滤和全局统计过滤方法来缓解深度和分割估计中的噪声；以及提出基于数据级融合的动态自演化策略，迭代细化密集表示下的伪框。

Result: 在nuScenes数据集上进行了广泛实验，结果表明，使用本文方法训练的检测器在nuScenes验证基准上，mAP达到28.4%，显著优于此前最先进的方法。

Conclusion: 所提出的数据级融合框架和动态自演化策略，通过有效利用LiDAR和RGB数据的互补性，显著提高了无监督3D目标检测中伪框的质量和定位精度，为该领域提供了新的解决方案。

Abstract: Existing LiDAR-based 3D object detectors typically rely on manually annotated
labels for training to achieve good performance. However, obtaining
high-quality 3D labels is time-consuming and labor-intensive. To address this
issue, recent works explore unsupervised 3D object detection by introducing RGB
images as an auxiliary modal to assist pseudo-box generation. However, these
methods simply integrate pseudo-boxes generated by LiDAR point clouds and RGB
images. Yet, such a label-level fusion strategy brings limited improvements to
the quality of pseudo-boxes, as it overlooks the complementary nature in terms
of LiDAR and RGB image data. To overcome the above limitations, we propose a
novel data-level fusion framework that integrates RGB images and LiDAR data at
an early stage. Specifically, we utilize vision foundation models for instance
segmentation and depth estimation on images and introduce a bi-directional
fusion method, where real points acquire category labels from the 2D space,
while 2D pixels are projected onto 3D to enhance real point density. To
mitigate noise from depth and segmentation estimations, we propose a local and
global filtering method, which applies local radius filtering to suppress depth
estimation errors and global statistical filtering to remove
segmentation-induced outliers. Furthermore, we propose a data-level fusion
based dynamic self-evolution strategy, which iteratively refines pseudo-boxes
under a dense representation, significantly improving localization accuracy.
Extensive experiments on the nuScenes dataset demonstrate that the detector
trained by our method significantly outperforms that trained by previous
state-of-the-art methods with 28.4$\%$ mAP on the nuScenes validation
benchmark.

</details>


### [73] [Digital Scale: Open-Source On-Device BMI Estimation from Smartphone Camera Images Trained on a Large-Scale Real-World Dataset](https://arxiv.org/abs/2508.20534)
*Frederik Rajiv Manichand,Robin Deuber,Robert Jakob,Steve Swerling,Jamie Rosen,Elgar Fleisch,Patrick Langer*

Main category: cs.CV

TL;DR: 本研究提出了一种基于深度学习的BMI估算方法，利用大型自有时智能手机图像数据集WayBED（包含84,963张图像）进行训练。通过引入自动过滤方法，该方法在WayBED测试集上实现了7.9%的平均绝对百分比误差（MAPE），并在VisualBodyToBMI数据集上达到8.56%的MAPE，均创下文献中的最低值。该方案可部署在Android设备上，并已开源。


<details>
  <summary>Details</summary>
Motivation: 在远程医疗或紧急情况下，传统的BMI测量方法可能不可用或不切实际。现有的计算机视觉方法受限于较小的数据集（最多14,500张图像），限制了其性能和泛化能力。因此，需要一个更大规模、更鲁棒的图像BMI估算解决方案。

Method: 研究采用了一个名为WayBED的大型专有数据集，包含25,353名个体的84,963张智能手机图像。引入了一种自动过滤方法，通过姿势聚类和人物检测来去除低质量图像（如非典型姿势或不完整视图），最终保留了71,322张高质量图像用于训练。在此基础上，开发了一个基于深度学习的BMI估算模型。模型在Android设备上使用CLAID框架进行了部署，并开源了完整的代码。

Result: 在WayBED的独立测试集上，使用全身图像获得了7.9%的平均绝对百分比误差（MAPE），据作者所知，这是已发表文献中的最低值。在训练期间完全未见的VisualBodyToBMI数据集上，实现了13%的MAPE，与在该数据集上训练的现有最先进方法相当，显示出强大的泛化能力。通过在VisualBodyToBMI上进行微调，模型达到了8.56%的MAPE，是迄今为止在该数据集上报告的最低值。

Conclusion: 本研究开发了一种基于深度学习的BMI估算方法，利用大规模、高质量的WayBED数据集，在多个测试集上取得了创纪录的性能，表现出卓越的准确性和泛化能力。该方法已成功部署到移动设备，并开源了所有相关代码，为在传统方法受限场景下进行快速体重评估提供了实用的解决方案。

Abstract: Estimating Body Mass Index (BMI) from camera images with machine learning
models enables rapid weight assessment when traditional methods are unavailable
or impractical, such as in telehealth or emergency scenarios. Existing computer
vision approaches have been limited to datasets of up to 14,500 images. In this
study, we present a deep learning-based BMI estimation method trained on our
WayBED dataset, a large proprietary collection of 84,963 smartphone images from
25,353 individuals. We introduce an automatic filtering method that uses
posture clustering and person detection to curate the dataset by removing
low-quality images, such as those with atypical postures or incomplete views.
This process retained 71,322 high-quality images suitable for training. We
achieve a Mean Absolute Percentage Error (MAPE) of 7.9% on our hold-out test
set (WayBED data) using full-body images, the lowest value in the published
literature to the best of our knowledge. Further, we achieve a MAPE of 13% on
the completely unseen~(during training) VisualBodyToBMI dataset, comparable
with state-of-the-art approaches trained on it, demonstrating robust
generalization. Lastly, we fine-tune our model on VisualBodyToBMI and achieve a
MAPE of 8.56%, the lowest reported value on this dataset so far. We deploy the
full pipeline, including image filtering and BMI estimation, on Android devices
using the CLAID framework. We release our complete code for model training,
filtering, and the CLAID package for mobile deployment as open-source
contributions.

</details>


### [74] [Safer Skin Lesion Classification with Global Class Activation Probability Map Evaluation and SafeML](https://arxiv.org/abs/2508.20776)
*Kuniko Paxton,Koorosh Aslansefat,Amila Akagić,Dhavalkumar Thakker,Yiannis Papadopoulos*

Main category: cs.CV

TL;DR: 该研究提出了一种名为GCAPME的新方法，通过概率性地分析所有类别的激活图来提高皮肤病变分类模型的解释性和信任度，并结合SafeML增强诊断可靠性和患者安全，以解决现有解释性方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管皮肤病变分类模型精度很高，甚至超越皮肤科医生，但在医疗实践中AI模型仍面临不信任。除了高精度，可信、可解释的诊断至关重要。现有解释性方法（如基于LIME和CAM的方法）存在可靠性问题，如不一致性或未能考虑所有类别。

Method: 提出“全局类别激活概率图评估”（Global Class Activation Probabilistic Map Evaluation, GCAPME）方法，该方法在像素级别对所有类别的激活概率图进行概率性分析。此外，应用SafeML来增强错误诊断的检测，并根据需要向医生和患者发出警告。该方法使用ISIC数据集，并结合MobileNetV2和Vision Transformers进行了评估。

Result: 通过统一可视化诊断过程，该方法有助于降低误诊风险。SafeML的应用增强了错误诊断的检测能力，并能发出警告，从而提高了诊断可靠性并最终提升了患者安全。

Conclusion: 该研究提出的GCAPME方法结合SafeML，通过解决现有解释性方法的局限性，提供统一的诊断过程可视化，并增强错误诊断检测和警告机制，显著提升了皮肤病变分类模型的解释性、诊断可靠性和患者安全性。

Abstract: Recent advancements in skin lesion classification models have significantly
improved accuracy, with some models even surpassing dermatologists' diagnostic
performance. However, in medical practice, distrust in AI models remains a
challenge. Beyond high accuracy, trustworthy, explainable diagnoses are
essential. Existing explainability methods have reliability issues, with
LIME-based methods suffering from inconsistency, while CAM-based methods
failing to consider all classes. To address these limitations, we propose
Global Class Activation Probabilistic Map Evaluation, a method that analyses
all classes' activation probability maps probabilistically and at a pixel
level. By visualizing the diagnostic process in a unified manner, it helps
reduce the risk of misdiagnosis. Furthermore, the application of SafeML
enhances the detection of false diagnoses and issues warnings to doctors and
patients as needed, improving diagnostic reliability and ultimately patient
safety. We evaluated our method using the ISIC datasets with MobileNetV2 and
Vision Transformers.

</details>


### [75] [Domain Adaptation Techniques for Natural and Medical Image Classification](https://arxiv.org/abs/2508.20537)
*Ahmad Chaddad,Yihang Wu,Reem Kateb,Christian Desrosiers*

Main category: cs.CV

TL;DR: 本研究通过557次模拟评估了七种域适应（DA）技术在自然图像和医疗图像分类中的表现，特别强调了DSAN算法在医疗数据上的卓越性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 域适应技术在缓解训练与测试集之间的分布差异方面具有潜力，但在图像分类领域，大多数进展集中在自然图像而非更难处理的医疗数据。此外，主流数据集的使用可能导致性能偏差。

Method: 本研究进行了557次模拟，使用了七种广泛使用的域适应技术进行图像分类。实验涵盖了五个自然图像数据集和八个医疗数据集，涉及分布外、动态数据流和有限训练样本等多种场景。

Result: 实验结果详细且富有洞察力，突出了这些技术的性能和在医疗领域的适用性。特别地，Deep Subdomain Adaptation Network (DSAN) 算法表现出色，在COVID-19数据集上使用Resnet50达到了91.2%的分类准确率，并在动态数据流DA场景中比基线提高了6.7%。DSAN在COVID-19和皮肤癌数据集上还展现了显著的可解释性。

Conclusion: 这些结果有助于理解域适应技术，并为模型有效适应医疗数据提供了宝贵的见解。

Abstract: Domain adaptation (DA) techniques have the potential in machine learning to
alleviate distribution differences between training and test sets by leveraging
information from source domains. In image classification, most advances in DA
have been made using natural images rather than medical data, which are harder
to work with. Moreover, even for natural images, the use of mainstream datasets
can lead to performance bias. {With the aim of better understanding the
benefits of DA for both natural and medical images, this study performs 557
simulation studies using seven widely-used DA techniques for image
classification in five natural and eight medical datasets that cover various
scenarios, such as out-of-distribution, dynamic data streams, and limited
training samples.} Our experiments yield detailed results and insightful
observations highlighting the performance and medical applicability of these
techniques. Notably, our results have shown the outstanding performance of the
Deep Subdomain Adaptation Network (DSAN) algorithm. This algorithm achieved
feasible classification accuracy (91.2\%) in the COVID-19 dataset using
Resnet50 and showed an important accuracy improvement in the dynamic data
stream DA scenario (+6.7\%) compared to the baseline. Our results also
demonstrate that DSAN exhibits remarkable level of explainability when
evaluated on COVID-19 and skin cancer datasets. These results contribute to the
understanding of DA techniques and offer valuable insight into the effective
adaptation of models to medical data.

</details>


### [76] [Evaluating Compositional Generalisation in VLMs and Diffusion Models](https://arxiv.org/abs/2508.20783)
*Beth Pearson,Bilal Boulbarss,Michael Wray,Martha Lewis*

Main category: cs.CV

TL;DR: 本研究评估了扩散分类器、CLIP和ViLT在组合泛化能力上的表现。结果显示，扩散分类器和ViLT在概念绑定任务上表现良好，但所有模型在关系型广义零样本学习（GZSL）任务上均表现不佳，凸显了视觉语言模型在关系推理方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 自然语言的语义具有组合性，但现有视觉语言模型（VLMs）如CLIP在组合语义方面存在不足，例如无法正确绑定属性和对象（如“红色的立方体和蓝色的圆柱体”）。扩散模型在生成能力上表现出色，并且其零样本分类器在某些组合任务中与CLIP具有竞争力。因此，研究旨在探讨生成式扩散分类器是否比判别式模型具有更强的组合泛化能力。

Method: 本研究评估了三种模型：扩散分类器（Diffusion Classifier）、CLIP和ViLT。通过零样本学习（ZSL）和广义零样本学习（GZSL）设置，测试这些模型将对象与属性和关系绑定的能力。

Result: 扩散分类器和ViLT在概念绑定任务上表现良好。然而，所有模型在关系型广义零样本学习（GZSL）任务上都面临显著困难。对CLIP嵌入的分析表明，其困难可能源于关系概念（如“左”和“右”）的表示过于相似。

Conclusion: 扩散分类器和ViLT在概念绑定方面展现出改进的组合能力，但所有视觉语言模型在关系推理，尤其是在广义零样本学习设置下的关系推理方面，仍然面临重大挑战。

Abstract: A fundamental aspect of the semantics of natural language is that novel
meanings can be formed from the composition of previously known parts.
Vision-language models (VLMs) have made significant progress in recent years,
however, there is evidence that they are unable to perform this kind of
composition. For example, given an image of a red cube and a blue cylinder, a
VLM such as CLIP is likely to incorrectly label the image as a red cylinder or
a blue cube, indicating it represents the image as a `bag-of-words' and fails
to capture compositional semantics. Diffusion models have recently gained
significant attention for their impressive generative abilities, and zero-shot
classifiers based on diffusion models have been shown to perform competitively
with CLIP in certain compositional tasks. In this work we explore whether the
generative Diffusion Classifier has improved compositional generalisation
abilities compared to discriminative models. We assess three models --
Diffusion Classifier, CLIP, and ViLT -- on their ability to bind objects with
attributes and relations in both zero-shot learning (ZSL) and generalised
zero-shot learning (GZSL) settings. Our results show that the Diffusion
Classifier and ViLT perform well at concept binding tasks, but that all models
struggle significantly with the relational GZSL task, underscoring the broader
challenges VLMs face with relational reasoning. Analysis of CLIP embeddings
suggests that the difficulty may stem from overly similar representations of
relational concepts such as left and right. Code and dataset are available at:
https://github.com/otmive/diffusion_classifier_clip

</details>


### [77] [Contrastive Learning through Auxiliary Branch for Video Object Detection](https://arxiv.org/abs/2508.20551)
*Lucas Rakotoarivony*

Main category: cs.CV

TL;DR: 本文提出CLAB（通过辅助分支进行对比学习）方法，通过对比学习和动态损失加权策略，在不增加推理计算成本的情况下，显著提升视频目标检测对图像退化的鲁棒性，并在ImageNet VID数据集上达到CNN模型的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 视频目标检测因运动模糊、遮挡和形变等图像退化问题而极具挑战性。现有方法通过特征聚合和复杂后处理提高性能，但代价是增加计算量。研究旨在不增加推理计算负担的前提下，提高对图像退化的鲁棒性。

Method: 1. 引入对比学习辅助分支（CLAB），使用对比损失增强视频目标检测器骨干网络的特征表示能力。2. 提出动态损失加权策略，在训练早期侧重辅助特征学习，随着训练收敛逐渐优先检测任务。

Result: 通过综合实验和消融研究证明了持续的性能提升。在不使用额外后处理的情况下，CLAB在ImageNet VID数据集上，使用ResNet-101和ResNeXt-101骨干网络分别达到84.0% mAP和85.2% mAP，实现了基于CNN模型的最新SOTA性能。

Conclusion: CLAB方法通过引入对比学习辅助分支和动态损失加权策略，有效提升了视频目标检测对图像退化的鲁棒性和性能，且不增加推理时的计算负担，为基于CNN的模型提供了最先进的解决方案。

Abstract: Video object detection is a challenging task because videos often suffer from
image deterioration such as motion blur, occlusion, and deformable shapes,
making it significantly more difficult than detecting objects in still images.
Prior approaches have improved video object detection performance by employing
feature aggregation and complex post-processing techniques, though at the cost
of increased computational demands. To improve robustness to image degradation
without additional computational load during inference, we introduce a
straightforward yet effective Contrastive Learning through Auxiliary Branch
(CLAB) method. First, we implement a constrastive auxiliary branch using a
contrastive loss to enhance the feature representation capability of the video
object detector's backbone. Next, we propose a dynamic loss weighting strategy
that emphasizes auxiliary feature learning early in training while gradually
prioritizing the detection task as training converges. We validate our approach
through comprehensive experiments and ablation studies, demonstrating
consistent performance gains. Without bells and whistles, CLAB reaches a
performance of 84.0% mAP and 85.2% mAP with ResNet-101 and ResNeXt-101,
respectively, on the ImageNet VID dataset, thus achieving state-of-the-art
performance for CNN-based models without requiring additional post-processing
methods.

</details>


### [78] [Surfel-based 3D Registration with Equivariant SE(3) Features](https://arxiv.org/abs/2508.20789)
*Xueyang Kang,Hang Zhao,Kourosh Khoshelham,Patrick Vandewalle*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的基于surfel的姿态学习回归方法，通过学习SE(3)等变特征来解决点云配准中忽略点方向和不确定性的问题，从而在有噪声和大幅旋转的输入下实现鲁棒且优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的点云配准方法（无论是否基于学习）忽略了点的方向和不确定性，这使得模型容易受到噪声输入和大幅旋转（如正交变换）的影响。这导致需要大量的带有变换增强的训练点云，从而限制了其在实际应用中的鲁棒性。

Method: 本文提出了一种基于surfel的姿态学习回归方法。该方法能利用虚拟透视相机参数从激光雷达点云初始化surfel，并通过SE(3)等变卷积核学习显式的SE(3)等变特征（包括位置和旋转），以预测源扫描和目标扫描之间的相对变换。模型包含一个等变卷积编码器、一个用于相似性计算的交叉注意力机制、一个全连接解码器和一个非线性Huber损失函数。

Result: 实验结果表明，与最先进的方法相比，该模型在室内和室外数据集的真实点云扫描上表现出卓越的性能和强大的鲁棒性。

Conclusion: 通过引入基于surfel的姿态学习回归方法和SE(3)等变特征学习，该研究有效解决了传统点云配准方法在处理噪声和大幅旋转时性能下降的问题，显著提升了点云配准的鲁棒性和准确性。

Abstract: Point cloud registration is crucial for ensuring 3D alignment consistency of
multiple local point clouds in 3D reconstruction for remote sensing or digital
heritage. While various point cloud-based registration methods exist, both
non-learning and learning-based, they ignore point orientations and point
uncertainties, making the model susceptible to noisy input and aggressive
rotations of the input point cloud like orthogonal transformation; thus, it
necessitates extensive training point clouds with transformation augmentations.
To address these issues, we propose a novel surfel-based pose learning
regression approach. Our method can initialize surfels from Lidar point cloud
using virtual perspective camera parameters, and learns explicit
$\mathbf{SE(3)}$ equivariant features, including both position and rotation
through $\mathbf{SE(3)}$ equivariant convolutional kernels to predict relative
transformation between source and target scans. The model comprises an
equivariant convolutional encoder, a cross-attention mechanism for similarity
computation, a fully-connected decoder, and a non-linear Huber loss.
Experimental results on indoor and outdoor datasets demonstrate our model
superiority and robust performance on real point-cloud scans compared to
state-of-the-art methods.

</details>


### [79] [GLaRE: A Graph-based Landmark Region Embedding Network for Emotion Recognition](https://arxiv.org/abs/2508.20579)
*Debasis Maji,Debaditya Barman*

Main category: cs.CV

TL;DR: 本文提出GLaRE，一个基于图的landmark区域嵌入网络，用于表情识别。它利用3D面部关键点构建商图（quotient graph）来处理空间结构和复杂性，并在AffectNet和FERG数据集上取得了优于基线的性能。


<details>
  <summary>Details</summary>
Motivation: 传统面部表情识别（FER）系统面临遮挡、表情变化和可解释性差等挑战。图神经网络（GNNs）通过建模面部关键点之间的关系依赖，提供了一种结构化且可解释的学习替代方案。

Method: 提出GLaRE网络。首先，使用3D面部对齐提取面部关键点。然后，通过分层粗化构建商图（quotient graph），以保留空间结构并降低复杂性。该方法利用商图中的区域级嵌入进行情感识别。

Result: GLaRE在AffectNet数据集上达到了64.89%的准确率，在FERG数据集上达到了94.24%的准确率，优于多个现有基线方法。此外，消融研究表明，来自商图的区域级嵌入有助于提高预测性能。

Conclusion: GLaRE通过利用3D面部关键点和商图构建的区域级嵌入，有效地建模了面部关键点之间的关系依赖，显著提升了面部表情识别的性能和可解释性。

Abstract: Facial expression recognition (FER) is a crucial task in computer vision with
wide range of applications including human computer interaction, surveillance,
and assistive technologies. However, challenges such as occlusion, expression
variability, and lack of interpretability hinder the performance of traditional
FER systems. Graph Neural Networks (GNNs) offer a powerful alternative by
modeling relational dependencies between facial landmarks, enabling structured
and interpretable learning. In this paper, we propose GLaRE, a novel
Graph-based Landmark Region Embedding network for emotion recognition. Facial
landmarks are extracted using 3D facial alignment, and a quotient graph is
constructed via hierarchical coarsening to preserve spatial structure while
reducing complexity. Our method achieves 64.89 percentage accuracy on AffectNet
and 94.24 percentage on FERG, outperforming several existing baselines.
Additionally, ablation studies have demonstrated that region-level embeddings
from quotient graphs have contributed to improved prediction performance.

</details>


### [80] [FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models](https://arxiv.org/abs/2508.20586)
*Zheng Chong,Yanwei Lei,Shiyue Zhang,Zhuandi He,Zhen Wang,Xujie Zhang,Xiao Dong,Yiling Wu,Dongmei Jiang,Xiaodan Liang*

Main category: cs.CV

TL;DR: 本文提出了FastFit，一个基于可缓存扩散架构的高速多参考虚拟试穿框架，解决了现有方法在多参考合成和效率方面的挑战。同时，还引入了大规模多参考数据集DressCode-MR。


<details>
  <summary>Details</summary>
Motivation: 虚拟试穿技术在实际应用中面临两大挑战：一是当前方法无法支持多参考（服装和配饰）组合；二是去噪过程中参考特征的重复计算导致效率低下。

Method: 本文提出了FastFit框架，采用新颖的可缓存扩散架构。通过引入半注意力机制（Semi-Attention）并将传统时间步嵌入替换为参考项的类别嵌入，模型将参考特征编码与去噪过程完全解耦，实现了参考特征的一次性计算和无损重用。此外，为了促进多参考虚拟试穿研究，构建了一个新的大规模数据集DressCode-MR。

Result: FastFit在推理效率上比同类方法平均加速3.5倍。在VITON-HD、DressCode和DressCode-MR数据集上的广泛实验表明，FastFit在关键保真度指标上超越了最先进的方法。DressCode-MR数据集包含28,179套高质量配对图像，涵盖五大类别。

Conclusion: FastFit框架成功解决了虚拟试穿技术在多参考组合和效率方面的瓶颈，实现了高速、高保真度的虚拟试穿。新引入的DressCode-MR数据集将有助于推动复杂多参考虚拟试穿领域的研究。

Abstract: Despite its great potential, virtual try-on technology is hindered from
real-world application by two major challenges: the inability of current
methods to support multi-reference outfit compositions (including garments and
accessories), and their significant inefficiency caused by the redundant
re-computation of reference features in each denoising step. To address these
challenges, we propose FastFit, a high-speed multi-reference virtual try-on
framework based on a novel cacheable diffusion architecture. By employing a
Semi-Attention mechanism and substituting traditional timestep embeddings with
class embeddings for reference items, our model fully decouples reference
feature encoding from the denoising process with negligible parameter overhead.
This allows reference features to be computed only once and losslessly reused
across all steps, fundamentally breaking the efficiency bottleneck and
achieving an average 3.5x speedup over comparable methods. Furthermore, to
facilitate research on complex, multi-reference virtual try-on, we introduce
DressCode-MR, a new large-scale dataset. It comprises 28,179 sets of
high-quality, paired images covering five key categories (tops, bottoms,
dresses, shoes, and bags), constructed through a pipeline of expert models and
human feedback refinement. Extensive experiments on the VITON-HD, DressCode,
and our DressCode-MR datasets show that FastFit surpasses state-of-the-art
methods on key fidelity metrics while offering its significant advantage in
inference efficiency.

</details>


### [81] [ExpertSim: Fast Particle Detector Simulation Using Mixture-of-Generative-Experts](https://arxiv.org/abs/2508.20991)
*Patryk Będkowski,Jan Dubiński,Filip Szatkowski,Kamil Deja,Przemysław Rokita,Tomasz Trzciński*

Main category: cs.CV

TL;DR: 本研究提出了一种名为 ExpertSim 的深度学习方法，利用生成式专家混合架构，显著提高了大型强子对撞机探测器（特别是ALICE实验中的零度量能器）响应模拟的准确性和效率，以替代计算成本高昂的传统蒙特卡洛方法。


<details>
  <summary>Details</summary>
Motivation: CERN大型强子对撞机中的粒子碰撞探测器响应模拟对于理解其内部机制至关重要。目前使用的统计蒙特卡洛方法计算成本高昂，给CERN的计算网格带来巨大压力。同时，数据分布在不同模拟中差异显著，难以用现有方法有效捕捉，因此需要更高效的生成式机器学习方法。

Method: 本研究提出了 ExpertSim，一种专为ALICE实验中零度量能器设计的深度学习模拟方法。该方法采用“生成式专家混合”（Mixture-of-Generative-Experts）架构，其中每个专家专注于模拟数据的一个不同子集。这种分工使得每个专家能更精确地处理量能器响应的特定方面。

Result: ExpertSim 不仅提高了模拟准确性，而且与传统的蒙特卡洛方法相比，实现了显著的加速。这表明它为粒子物理实验中的高效探测器模拟提供了一个有前景的解决方案。

Conclusion: ExpertSim 作为一种基于生成式专家混合架构的深度学习方法，成功地解决了传统蒙特卡洛模拟计算成本高昂和数据分布复杂的问题，为CERN粒子物理实验中的高效率探测器模拟提供了一个有力的替代方案。

Abstract: Simulating detector responses is a crucial part of understanding the inner
workings of particle collisions in the Large Hadron Collider at CERN. Such
simulations are currently performed with statistical Monte Carlo methods, which
are computationally expensive and put a significant strain on CERN's
computational grid. Therefore, recent proposals advocate for generative machine
learning methods to enable more efficient simulations. However, the
distribution of the data varies significantly across the simulations, which is
hard to capture with out-of-the-box methods. In this study, we present
ExpertSim - a deep learning simulation approach tailored for the Zero Degree
Calorimeter in the ALICE experiment. Our method utilizes a
Mixture-of-Generative-Experts architecture, where each expert specializes in
simulating a different subset of the data. This allows for a more precise and
efficient generation process, as each expert focuses on a specific aspect of
the calorimeter response. ExpertSim not only improves accuracy, but also
provides a significant speedup compared to the traditional Monte-Carlo methods,
offering a promising solution for high-efficiency detector simulations in
particle physics experiments at CERN. We make the code available at
https://github.com/patrick-bedkowski/expertsim-mix-of-generative-experts.

</details>


### [82] [UTA-Sign: Unsupervised Thermal Video Augmentation via Event-Assisted Traffic Signage Sketching](https://arxiv.org/abs/2508.20594)
*Yuqi Han,Songqian Zhang,Weijian Su,Ke Li,Jiayu Yang,Jinli Suo,Qiang Zhang*

Main category: cs.CV

TL;DR: 本文提出UTA-Sign，一种无监督热-事件视频增强方法，用于改善低光照环境下交通标志（如车牌和路障指示器）的感知，通过融合热成像和事件相机数据来克服各自的局限性。


<details>
  <summary>Details</summary>
Motivation: 热像仪在低光照户外环境感知方面表现出色，但难以识别由相似材料制成的标志。事件相机能异步检测光强变化，在高速、低光照交通环境中有效，但存在非均匀采样问题。为解决热像仪的标志盲点和事件相机的非均匀采样，并利用两者互补特性，提升自动驾驶系统在低光照下对交通标志的理解和安全性。

Method: 本文提出UTA-Sign，一种无监督的热-事件视频增强方法，针对低光照环境下的交通标志。核心是双重增强机制，融合热帧和事件信号以实现一致的标志表示。该方法利用热帧提供精确的运动线索作为时间参考，以对齐不均匀的事件信号；同时，事件信号为原始热帧贡献细微的标志内容，增强对环境的整体理解。

Result: 该方法在真实世界场景收集的数据集上进行了验证，结果表明在交通标志描绘方面具有卓越的质量，并在感知层面提高了检测精度。

Conclusion: 所提出的UTA-Sign方法通过融合热成像和事件相机数据，有效解决了低光照环境下交通标志识别的挑战，显著提升了交通标志的视觉质量和检测准确性。

Abstract: The thermal camera excels at perceiving outdoor environments under low-light
conditions, making it ideal for applications such as nighttime autonomous
driving and unmanned navigation. However, thermal cameras encounter challenges
when capturing signage from objects made of similar materials, which can pose
safety risks for accurately understanding semantics in autonomous driving
systems. In contrast, the neuromorphic vision camera, also known as an event
camera, detects changes in light intensity asynchronously and has proven
effective in high-speed, low-light traffic environments. Recognizing the
complementary characteristics of these two modalities, this paper proposes
UTA-Sign, an unsupervised thermal-event video augmentation for traffic signage
in low-illumination environments, targeting elements such as license plates and
roadblock indicators. To address the signage blind spots of thermal imaging and
the non-uniform sampling of event cameras, we developed a dual-boosting
mechanism that fuses thermal frames and event signals for consistent signage
representation over time. The proposed method utilizes thermal frames to
provide accurate motion cues as temporal references for aligning the uneven
event signals. At the same time, event signals contribute subtle signage
content to the raw thermal frames, enhancing the overall understanding of the
environment. The proposed method is validated on datasets collected from
real-world scenarios, demonstrating superior quality in traffic signage
sketching and improved detection accuracy at the perceptual level.

</details>


### [83] [ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering](https://arxiv.org/abs/2508.21010)
*Paritosh Parmar,Eric Peh,Basura Fernando*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的模块化框架，通过引入自然语言因果链作为可解释的中间表示，将因果推理与答案生成解耦，从而显著提升了因果-为何视频问答（VideoQA）的性能、可解释性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的因果-为何VideoQA模型在处理高阶推理时表现不佳，依赖于不透明、单一的管道，将视频理解、因果推断和答案生成纠缠在一起。这些黑盒方法解释性有限，并且倾向于依赖浅层启发式方法。

Method: 本文提出一个模块化框架，明确地将因果推理与答案生成解耦，引入自然语言因果链作为可解释的中间表示。该框架包含两阶段架构：一个因果链提取器（CCE）用于从视频-问题对生成因果链，以及一个因果链驱动应答器（CCDA）根据这些链生成答案。为解决缺乏标注推理轨迹的问题，作者提出了一种使用大型语言模型从现有数据集中生成高质量因果链的可扩展方法。此外，还提出了一个新的因果导向字幕评估指标CauCo。

Result: 在三个大规模基准测试上的实验表明，该方法不仅超越了最先进的模型，还在可解释性、用户信任和泛化能力方面取得了显著提升。其中，CCE被定位为一个可在不同领域复用的因果推理引擎。

Conclusion: 通过模块化设计和引入可解释的自然语言因果链作为中间表示，该方法有效解决了现有因果-为何VideoQA模型面临的高阶推理和可解释性挑战，实现了性能、可解释性和泛化能力的全面提升，并提供了一个可复用的因果推理引擎。

Abstract: Existing Causal-Why Video Question Answering (VideoQA) models often struggle
with higher-order reasoning, relying on opaque, monolithic pipelines that
entangle video understanding, causal inference, and answer generation. These
black-box approaches offer limited interpretability and tend to depend on
shallow heuristics. We propose a novel, modular framework that explicitly
decouples causal reasoning from answer generation, introducing natural language
causal chains as interpretable intermediate representations. Inspired by human
cognitive models, these structured cause-effect sequences bridge low-level
video content with high-level causal reasoning, enabling transparent and
logically coherent inference. Our two-stage architecture comprises a Causal
Chain Extractor (CCE) that generates causal chains from video-question pairs,
and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in
these chains. To address the lack of annotated reasoning traces, we introduce a
scalable method for generating high-quality causal chains from existing
datasets using large language models. We also propose CauCo, a new evaluation
metric for causality-oriented captioning. Experiments on three large-scale
benchmarks demonstrate that our approach not only outperforms state-of-the-art
models, but also yields substantial gains in explainability, user trust, and
generalization -- positioning the CCE as a reusable causal reasoning engine
across diverse domains. Project page:
https://paritoshparmar.github.io/chainreaction/

</details>


### [84] [Disruptive Attacks on Face Swapping via Low-Frequency Perceptual Perturbations](https://arxiv.org/abs/2508.20595)
*Mengxiao Huang,Minglei Shu,Shuwang Zhou,Zhaoyang Liu*

Main category: cs.CV

TL;DR: 针对深度伪造（Deepfake）技术，本文提出了一种基于低频感知扰动的主动防御方法，旨在直接干扰换脸生成过程，同时保持视觉质量。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术（由GAN驱动）对隐私和社会安全构成重大风险。现有检测方法主要是被动的事后分析，无法预防攻击。

Method: 提出一种基于低频感知扰动的主动防御方法，直接针对深度伪造技术的生成过程（换脸操纵）。该方法结合了频率和空间域特征，通过引入低频扰动产生的伪影，同时保留高频细节以确保视觉可信度。设计了一个完整的架构，包括编码器、扰动生成器和解码器，并利用离散小波变换（DWT）提取低频分量并生成扰动，以干扰人脸操纵模型。

Result: 在CelebA-HQ和LFW数据集上的实验表明，该方法显著降低了换脸的有效性，提高了防御成功率，并保持了视觉质量。

Conclusion: 所提出的主动防御方法能有效干扰深度伪造换脸操作的生成过程，实现高防御成功率并保持视觉质量，解决了被动检测的局限性。

Abstract: Deepfake technology, driven by Generative Adversarial Networks (GANs), poses
significant risks to privacy and societal security. Existing detection methods
are predominantly passive, focusing on post-event analysis without preventing
attacks. To address this, we propose an active defense method based on
low-frequency perceptual perturbations to disrupt face swapping manipulation,
reducing the performance and naturalness of generated content. Unlike prior
approaches that used low-frequency perturbations to impact classification
accuracy,our method directly targets the generative process of deepfake
techniques. We combine frequency and spatial domain features to strengthen
defenses. By introducing artifacts through low-frequency perturbations while
preserving high-frequency details, we ensure the output remains visually
plausible. Additionally, we design a complete architecture featuring an
encoder, a perturbation generator, and a decoder, leveraging discrete wavelet
transform (DWT) to extract low-frequency components and generate perturbations
that disrupt facial manipulation models. Experiments on CelebA-HQ and LFW
demonstrate significant reductions in face-swapping effectiveness, improved
defense success rates, and preservation of visual quality.

</details>


### [85] [Veritas: Generalizable Deepfake Detection via Pattern-Aware Reasoning](https://arxiv.org/abs/2508.21048)
*Hao Tan,Jun Lan,Zichang Tan,Ajian Liu,Chuanbiao Song,Senyuan Shi,Huijia Zhu,Weiqiang Wang,Jun Wan,Zhen Lei*

Main category: cs.CV

TL;DR: 该研究引入了HydraFake数据集以模拟真实世界深度伪造检测挑战，并提出了基于多模态大语言模型（MLLM）的Veritas检测器，该检测器采用模式感知推理和两阶段训练，在OOD场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有学术基准与工业实践存在严重差异，通常训练源单一、测试图像质量低，阻碍了当前检测器的实际部署。深度伪造内容的复杂性和演变性质使得检测仍是一个巨大挑战。

Method: 1. 引入HydraFake数据集，模拟真实世界挑战，包含多样化的深度伪造技术和野外伪造，并采用严格的训练和评估协议，覆盖未见过的模型架构、新兴伪造技术和新数据领域，用于分层泛化测试。 2. 提出了Veritas，一个基于多模态大语言模型（MLLM）的深度伪造检测器。 3. Veritas采用模式感知推理（如“规划”和“自我反思”）来模拟人类取证过程，而非传统的思维链（CoT）。 4. 提出两阶段训练流程，将深度伪造推理能力无缝融入MLLM中。

Result: 1. 实验表明，虽然先前的检测器在跨模型场景中表现出良好的泛化能力，但在未见的伪造和数据领域表现不佳。 2. Veritas在不同的OOD（域外）场景中取得了显著的性能提升。 3. Veritas能够提供透明且忠实的检测输出。

Conclusion: HydraFake数据集有效模拟了真实世界的深度伪造挑战。Veritas作为一种基于MLLM的检测器，通过模式感知推理和两阶段训练，显著提升了在未见过的伪造技术和数据域等OOD场景下的泛化能力，并能提供可解释的检测结果，弥补了学术基准与工业实践之间的差距。

Abstract: Deepfake detection remains a formidable challenge due to the complex and
evolving nature of fake content in real-world scenarios. However, existing
academic benchmarks suffer from severe discrepancies from industrial practice,
typically featuring homogeneous training sources and low-quality testing
images, which hinder the practical deployments of current detectors. To
mitigate this gap, we introduce HydraFake, a dataset that simulates real-world
challenges with hierarchical generalization testing. Specifically, HydraFake
involves diversified deepfake techniques and in-the-wild forgeries, along with
rigorous training and evaluation protocol, covering unseen model architectures,
emerging forgery techniques and novel data domains. Building on this resource,
we propose Veritas, a multi-modal large language model (MLLM) based deepfake
detector. Different from vanilla chain-of-thought (CoT), we introduce
pattern-aware reasoning that involves critical reasoning patterns such as
"planning" and "self-reflection" to emulate human forensic process. We further
propose a two-stage training pipeline to seamlessly internalize such deepfake
reasoning capacities into current MLLMs. Experiments on HydraFake dataset
reveal that although previous detectors show great generalization on
cross-model scenarios, they fall short on unseen forgeries and data domains.
Our Veritas achieves significant gains across different OOD scenarios, and is
capable of delivering transparent and faithful detection outputs.

</details>


### [86] [Embracing Aleatoric Uncertainty: Generating Diverse 3D Human Motion](https://arxiv.org/abs/2508.20604)
*Zheng Qin,Yabing Wang,Minghui Yang,Sanping Zhou,Ming Yang,Le Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Diverse-T2M的文本到3D人体动作生成方法，通过引入不确定性（利用噪声信号和潜在空间采样器）显著提高了生成动作的多样性，同时保持了文本一致性。


<details>
  <summary>Details</summary>
Motivation: 从文本生成3D人体动作是一项具有挑战性且有价值的任务。虽然现有方法能生成精确高质量的动作，但在保持文本-动作一致性的同时，实现生成动作的多样性仍然是一个重大挑战。

Method: 本方法，即Diverse-T2M，通过以下方式引入不确定性以增强多样性：1) 在基于Transformer的方法中，利用噪声信号作为多样性信息的载体，显式建模不确定性。2) 构建一个潜在空间，将文本投射到连续表示中（而非刚性的一对一映射），并集成一个潜在空间采样器以引入随机采样，从而增强输出的多样性和不确定性。

Result: 在文本到动作生成基准数据集（HumanML3D和KIT-ML）上的实验结果表明，本方法显著增强了生成动作的多样性，同时在文本一致性方面保持了最先进的性能。

Conclusion: Diverse-T2M通过在生成过程中引入不确定性，成功解决了文本到3D人体动作生成中多样性不足的挑战，在保持文本语义一致性的同时实现了高度多样化的动作生成。

Abstract: Generating 3D human motions from text is a challenging yet valuable task. The
key aspects of this task are ensuring text-motion consistency and achieving
generation diversity. Although recent advancements have enabled the generation
of precise and high-quality human motions from text, achieving diversity in the
generated motions remains a significant challenge. In this paper, we aim to
overcome the above challenge by designing a simple yet effective text-to-motion
generation method, \textit{i.e.}, Diverse-T2M. Our method introduces
uncertainty into the generation process, enabling the generation of highly
diverse motions while preserving the semantic consistency of the text.
Specifically, we propose a novel perspective that utilizes noise signals as
carriers of diversity information in transformer-based methods, facilitating a
explicit modeling of uncertainty. Moreover, we construct a latent space where
text is projected into a continuous representation, instead of a rigid
one-to-one mapping, and integrate a latent space sampler to introduce
stochastic sampling into the generation process, thereby enhancing the
diversity and uncertainty of the outputs. Our results on text-to-motion
generation benchmark datasets~(HumanML3D and KIT-ML) demonstrate that our
method significantly enhances diversity while maintaining state-of-the-art
performance in text consistency.

</details>


### [87] [Optimization-Based Calibration for Intravascular Ultrasound Volume Reconstruction](https://arxiv.org/abs/2508.20605)
*Karl-Philippe Beaudet,Sidaty El Hadramy,Philippe C Cattin,Juan Verde,Stéphane Cotin*

Main category: cs.CV

TL;DR: 本文提出了一种基于优化的校准方法，利用3D打印模型实现准确的3D血管内超声(IVUS)体积重建，从而将术中IVUS图像与术前CT图像进行精确配准，以改善肝脏手术中的术中导航。


<details>
  <summary>Details</summary>
Motivation: 肝脏手术中术中超声图像因视野有限和解剖结构复杂而难以解释。有效的手术指导需要弥合术前和术中数据之间的鸿沟。3D IVUS通过重建整个器官，为术前CT扫描与术中IVUS图像的配准提供了潜在解决方案。

Method: 本文提出了一种基于优化的校准方法，利用3D打印模型实现准确的3D血管内超声(IVUS)体积重建。该方法确保了跟踪IVUS数据与术前CT图像的精确对齐。

Result: 该方法在体内猪肝图像上进行了验证，校准误差在0.88至1.80毫米之间，3D IVUS数据与相应CT扫描之间的配准误差在3.40至5.71毫米之间。

Conclusion: 所提出的方法提供了一种可靠且准确的校准和体积重建手段，可用于肝脏手术中将术中超声图像与术前CT图像进行配准，从而增强术中指导。

Abstract: Intraoperative ultrasound images are inherently challenging to interpret in
liver surgery due to the limited field of view and complex anatomical
structures. Bridging the gap between preoperative and intraoperative data is
crucial for effective surgical guidance. 3D IntraVascular UltraSound (IVUS)
offers a potential solution by enabling the reconstruction of the entire organ,
which facilitates registration between preoperative computed tomography (CT)
scans and intraoperative IVUS images. In this work, we propose an
optimization-based calibration method using a 3D-printed phantom for accurate
3D Intravascular Ultrasound volume reconstruction. Our approach ensures precise
alignment of tracked IVUS data with preoperative CT images, improving
intraoperative navigation. We validated our method using in vivo swine liver
images, achieving a calibration error from 0.88 to 1.80 mm and a registration
error from 3.40 to 5.71 mm between the 3D IVUS data and the corresponding CT
scan. Our method provides a reliable and accurate means of calibration and
volume reconstruction. It can be used to register intraoperative ultrasound
images with preoperative CT images in the context of liver surgery, and enhance
intraoperative guidance.

</details>


### [88] [FakeParts: a New Family of AI-Generated DeepFakes](https://arxiv.org/abs/2508.21052)
*Gaetan Brison,Soobash Daiboo,Samy Aimeur,Awais Hussain Sani,Xi Wang,Gianni Franchi,Vicky Kalogeiton*

Main category: cs.CV

TL;DR: 本文引入了新型局部篡改深度伪造（FakeParts），其特点是视频中细微且局部的修改，极具欺骗性且难以检测。为应对此挑战，作者发布了首个大型基准数据集FakePartsBench。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测技术难以应对局部、细微的视频篡改，导致这些“部分伪造”内容能与真实元素无缝融合，使其高度欺骗性且难以被人类和现有模型检测，存在检测能力上的关键空白。

Method: 本文提出了FakeParts这一新型深度伪造类别，并构建了首个大规模基准数据集FakePartsBench。该数据集包含超过25K视频，并提供像素级和帧级篡改标注，旨在全面评估和促进局部深度伪造检测方法的发展。

Result: 用户研究表明，与传统深度伪造相比，FakeParts使人类检测准确率下降超过30%。同时，最先进的检测模型也观察到类似的性能下降，证明了FakeParts对现有检测方法的强大挑战性。

Conclusion: 这项工作揭示了当前深度伪造检测方法在应对局部视频篡改方面的紧急漏洞，并提供了必要的资源（FakePartsBench数据集）来开发更鲁棒的局部视频篡改检测方法。

Abstract: We introduce FakeParts, a new class of deepfakes characterized by subtle,
localized manipulations to specific spatial regions or temporal segments of
otherwise authentic videos. Unlike fully synthetic content, these partial
manipulations, ranging from altered facial expressions to object substitutions
and background modifications, blend seamlessly with real elements, making them
particularly deceptive and difficult to detect. To address the critical gap in
detection capabilities, we present FakePartsBench, the first large-scale
benchmark dataset specifically designed to capture the full spectrum of partial
deepfakes. Comprising over 25K videos with pixel-level and frame-level
manipulation annotations, our dataset enables comprehensive evaluation of
detection methods. Our user studies demonstrate that FakeParts reduces human
detection accuracy by over 30% compared to traditional deepfakes, with similar
performance degradation observed in state-of-the-art detection models. This
work identifies an urgent vulnerability in current deepfake detection
approaches and provides the necessary resources to develop more robust methods
for partial video manipulations.

</details>


### [89] [Physics Informed Generative Models for Magnetic Field Images](https://arxiv.org/abs/2508.20612)
*Aye Phyu Phyu Aung,Lucas Lum,Zhansen Shi,Wen Qiu,Bernice Zee,JM Chin,Yeow Kheng Lim,J. Senthilnath*

Main category: cs.CV

TL;DR: 该研究提出了一种名为PI-GenMFI的物理信息生成模型，利用扩散模型和物理约束来生成合成磁场图像（MFI），以解决半导体制造中MFI数据稀缺的问题，从而优化缺陷定位过程。


<details>
  <summary>Details</summary>
Motivation: 半导体制造中的缺陷检测和定位至关重要，但X射线成像耗时且占用内存。磁场成像（MFI）虽然能更高效地定位感兴趣区域，但由于专有性问题，MFI数据集的可用性有限，阻碍了机器学习模型的训练。

Method: 该研究提出了一种名为Physics Informed Generative Models for Magnetic Field Images (PI-GenMFI) 的机器学习驱动方法。该方法利用扩散模型并整合了两个物理约束，生成了最常见的缺陷类型（电源短路）的合成MFI图像。这些合成图像将用作训练数据，以有效定位缺陷区域。通过与SOTA的变分自编码器（VAE）和扩散模型进行比较，并结合领域专家评估、定性和定量指标（用于图像生成和信号处理）来评估生成的MFI。

Result: 该模型生成的合成MFI图像显示出有前景的结果，能够优化缺陷定位过程。通过与最先进的生成模型进行比较，并经过领域专家评估以及定性和定量指标分析，证明了其有效性。

Conclusion: PI-GenMFI模型通过整合物理信息，成功生成了用于半导体缺陷定位的合成MFI数据，有效解决了MFI数据稀缺的瓶颈问题，并有望显著提高缺陷定位的效率和准确性。

Abstract: In semiconductor manufacturing, defect detection and localization are
critical to ensuring product quality and yield. While X-ray imaging is a
reliable non-destructive testing method, it is memory-intensive and
time-consuming for large-scale scanning, Magnetic Field Imaging (MFI) offers a
more efficient means to localize regions of interest (ROI) for targeted X-ray
scanning. However, the limited availability of MFI datasets due to proprietary
concerns presents a significant bottleneck for training machine learning (ML)
models using MFI. To address this challenge, we consider an ML-driven approach
leveraging diffusion models with two physical constraints. We propose Physics
Informed Generative Models for Magnetic Field Images (PI-GenMFI) to generate
synthetic MFI samples by integrating specific physical information. We generate
MFI images for the most common defect types: power shorts. These synthetic
images will serve as training data for ML algorithms designed to localize
defect areas efficiently. To evaluate generated MFIs, we compare our model to
SOTA generative models from both variational autoencoder (VAE) and diffusion
methods. We present a domain expert evaluation to assess the generated samples.
In addition, we present qualitative and quantitative evaluation using various
metrics used for image generation and signal processing, showing promising
results to optimize the defect localization process.

</details>


### [90] [Revisiting the Privacy Risks of Split Inference: A GAN-Based Data Reconstruction Attack via Progressive Feature Optimization](https://arxiv.org/abs/2508.20613)
*Yixiang Qiu,Yanhan Liu,Hongyao Yu,Hao Fang,Bin Chen,Shu-Tao Xia,Ke Xu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的基于GAN的渐进式特征优化（PFO）数据重建攻击（DRA）框架，能有效从分布式推理（SI）的中间特征中恢复敏感输入数据，显著优于现有攻击，尤其适用于高分辨率和深度模型。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNNs）的复杂性促使分布式推理（SI）的采用，以降低延迟和保护用户隐私。然而，近期数据重建攻击（DRAs）表明SI中交换的中间特征可被利用恢复敏感输入数据，构成严重隐私风险。现有DRAs通常仅对浅层模型有效，未能充分利用语义先验，限制了重建质量和泛化性。

Method: 本文提出了一种新颖的基于GAN的DRA框架，结合渐进式特征优化（PFO）。该方法将生成器分解为分层块，并逐步细化中间表示，以增强重建图像的语义保真度。为稳定优化并提高图像真实感，在重建过程中引入了L1-ball约束。

Result: 广泛的实验表明，本文方法在重建质量上大幅优于现有攻击，特别是在高分辨率场景、域外（out-of-distribution）设置以及针对更深、更复杂的DNNs时表现更佳。

Conclusion: 本文提出了一种更有效的数据重建攻击方法，显著提升了从分布式推理中间特征中恢复敏感数据的能力，揭示了分布式推理中存在的严重隐私风险，并对未来隐私保护提出了挑战。

Abstract: The growing complexity of Deep Neural Networks (DNNs) has led to the adoption
of Split Inference (SI), a collaborative paradigm that partitions computation
between edge devices and the cloud to reduce latency and protect user privacy.
However, recent advances in Data Reconstruction Attacks (DRAs) reveal that
intermediate features exchanged in SI can be exploited to recover sensitive
input data, posing significant privacy risks. Existing DRAs are typically
effective only on shallow models and fail to fully leverage semantic priors,
limiting their reconstruction quality and generalizability across datasets and
model architectures. In this paper, we propose a novel GAN-based DRA framework
with Progressive Feature Optimization (PFO), which decomposes the generator
into hierarchical blocks and incrementally refines intermediate representations
to enhance the semantic fidelity of reconstructed images. To stabilize the
optimization and improve image realism, we introduce an L1-ball constraint
during reconstruction. Extensive experiments show that our method outperforms
prior attacks by a large margin, especially in high-resolution scenarios,
out-of-distribution settings, and against deeper and more complex DNNs.

</details>


### [91] [Improving Alignment in LVLMs with Debiased Self-Judgment](https://arxiv.org/abs/2508.20655)
*Sihan Yang,Chenhang Cui,Zihao Zhao,Yiyang Zhou,Weilong Yan,Ying Wei,Huaxiu Yao*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的方法，通过模型内部生成的“去偏自判断分数”来自主改进大型视觉语言模型（LVLMs）的模态对齐，从而减少幻觉并提高安全性，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）和大型视觉语言模型（LVLMs）在视觉和语言模态整合方面带来机遇，但有效对齐仍面临挑战，常导致幻觉（输出未基于视觉输入）并引发安全问题。现有对齐方法（如指令微调和偏好微调）依赖外部数据集、人工标注或复杂后处理，限制了可扩展性并增加了成本。

Method: 我们提出了一种新方法，生成“去偏自判断分数”。这是一个由模型内部创建的自我评估指标，不依赖外部资源，使模型能够自主改进对齐。该方法增强了解码策略和偏好微调过程。

Result: 我们的方法显著减少了幻觉，增强了安全性，并提升了整体能力。实证结果表明，它显著优于传统方法。

Conclusion: 本研究为对齐LVLMs提供了一种更有效的解决方案。

Abstract: The rapid advancements in Large Language Models (LLMs) and Large
Visual-Language Models (LVLMs) have opened up new opportunities for integrating
visual and linguistic modalities. However, effectively aligning these
modalities remains challenging, often leading to hallucinations--where
generated outputs are not grounded in the visual input--and raising safety
concerns across various domains. Existing alignment methods, such as
instruction tuning and preference tuning, often rely on external datasets,
human annotations, or complex post-processing, which limit scalability and
increase costs. To address these challenges, we propose a novel approach that
generates the debiased self-judgment score, a self-evaluation metric created
internally by the model without relying on external resources. This enables the
model to autonomously improve alignment. Our method enhances both decoding
strategies and preference tuning processes, resulting in reduced
hallucinations, enhanced safety, and improved overall capability. Empirical
results show that our approach significantly outperforms traditional methods,
offering a more effective solution for aligning LVLMs.

</details>


### [92] [EmoCAST: Emotional Talking Portrait via Emotive Text Description](https://arxiv.org/abs/2508.20615)
*Yiguo Jiang,Xiaodong Cun,Yong Zhang,Yudian Zheng,Fan Tang,Chi-Man Pun*

Main category: cs.CV

TL;DR: 本文提出了 EmoCAST，一个基于扩散模型的框架，用于生成逼真、富有情感且音频同步的文本驱动情感对话头像视频，并通过引入新模块、构建新数据集和优化训练策略解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有情感对话头像合成方法在控制灵活性、运动自然度和表情质量方面存在局限性。此外，现有数据集多在实验室环境中收集，进一步加剧了这些缺点，严重阻碍了实际应用。

Method: 本文提出了 EmoCAST 扩散框架，包含两个关键模块：1) 用于外观建模的文本引导解耦情感模块，通过情感提示增强空间知识以提高情感理解；2) 情感音频注意力模块，捕捉受控情感和驱动音频之间的相互作用，生成情感感知特征以指导更精确的面部运动合成。此外，构建了一个包含全面情感文本描述的情感对话头像数据集，并提出了情感感知采样训练策略和渐进式功能训练策略来优化模型性能。

Result: EmoCAST 在生成逼真、富有情感且音频同步的对话头像视频方面达到了最先进的性能。

Conclusion: EmoCAST 成功解决了情感对话头像合成中控制灵活性、运动自然度和表情质量的挑战，并通过创新的模块设计、新数据集和优化训练策略实现了最先进的生成效果，为实际应用提供了可能。

Abstract: Emotional talking head synthesis aims to generate talking portrait videos
with vivid expressions. Existing methods still exhibit limitations in control
flexibility, motion naturalness, and expression quality. Moreover, currently
available datasets are primarily collected in lab settings, further
exacerbating these shortcomings. Consequently, these limitations substantially
hinder practical applications in real-world scenarios. To address these
challenges, we propose EmoCAST, a diffusion-based framework with two key
modules for precise text-driven emotional synthesis. In appearance modeling,
emotional prompts are integrated through a text-guided decoupled emotive
module, enhancing the spatial knowledge to improve emotion comprehension. To
improve the relationship between audio and emotion, we introduce an emotive
audio attention module to capture the interplay between controlled emotion and
driving audio, generating emotion-aware features to guide more precise facial
motion synthesis. Additionally, we construct an emotional talking head dataset
with comprehensive emotive text descriptions to optimize the framework's
performance. Based on the proposed dataset, we propose an emotion-aware
sampling training strategy and a progressive functional training strategy that
further improve the model's ability to capture nuanced expressive features and
achieve accurate lip-synchronization. Overall, EmoCAST achieves
state-of-the-art performance in generating realistic, emotionally expressive,
and audio-synchronized talking-head videos. Project Page:
https://github.com/GVCLab/EmoCAST

</details>


### [93] [Mask-Guided Multi-Channel SwinUNETR Framework for Robust MRI Classification](https://arxiv.org/abs/2508.20621)
*Smriti Joshi,Lidia Garrucho,Richard Osuala,Oliver Diaz,Karim Lekadir*

Main category: cs.CV

TL;DR: 该研究开发了一个基于SwinUNETR的深度学习框架，用于乳腺MRI图像的乳腺癌诊断和分类，并在ODELIA挑战赛中获得第二名。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是女性癌症相关死亡的主要原因之一，早期检测至关重要。磁共振成像（MRI）对高风险或乳腺组织致密的女性乳腺癌检测高度敏感，而乳腺摄影效果不佳。ODELIA联盟组织了一项多中心挑战赛，旨在推动基于AI的乳腺癌诊断和分类解决方案。

Method: 研究开发了一个基于SwinUNETR的深度学习框架，该框架结合了乳腺区域掩膜、广泛的数据增强和集成学习，以提高模型的鲁棒性和泛化能力。

Result: 该方法在ODELIA挑战赛排行榜上获得了第二名，证明了其在乳腺MRI临床判读中的潜力。

Conclusion: 该研究提出的深度学习框架在乳腺MRI图像的乳腺癌诊断和分类方面表现出色，有望支持临床乳腺MRI的判读工作。

Abstract: Breast cancer is one of the leading causes of cancer-related mortality in
women, and early detection is essential for improving outcomes. Magnetic
resonance imaging (MRI) is a highly sensitive tool for breast cancer detection,
particularly in women at high risk or with dense breast tissue, where
mammography is less effective. The ODELIA consortium organized a multi-center
challenge to foster AI-based solutions for breast cancer diagnosis and
classification. The dataset included 511 studies from six European centers,
acquired on scanners from multiple vendors at both 1.5 T and 3 T. Each study
was labeled for the left and right breast as no lesion, benign lesion, or
malignant lesion. We developed a SwinUNETR-based deep learning framework that
incorporates breast region masking, extensive data augmentation, and ensemble
learning to improve robustness and generalizability. Our method achieved second
place on the challenge leaderboard, highlighting its potential to support
clinical breast MRI interpretation. We publicly share our codebase at
https://github.com/smriti-joshi/bcnaim-odelia-challenge.git.

</details>


### [94] [AvatarBack: Back-Head Generation for Complete 3D Avatars from Front-View Images](https://arxiv.org/abs/2508.20623)
*Shiqi Xin,Xiaolin Zhang,Yanbin Liu,Peng Zhang,Caifeng Shan*

Main category: cs.CV

TL;DR: AvatarBack是一个即插即用的框架，通过引入Subject-specific Generator和Adaptive Spatial Alignment Strategy，解决了现有高斯泼溅头部化身重建方法中背面头部重建质量差的问题，显著提升了3D高斯化身的完整性和真实感。


<details>
  <summary>Details</summary>
Motivation: 现有高斯泼溅方法主要依赖正面图像重建头部化身，导致背面头部重建质量差，存在几何不一致、结构模糊和真实感降低等问题，限制了重建化身的保真度。

Method: 本文提出了AvatarBack框架，包含两项核心技术创新：1. Subject-specific Generator (SSG)：利用生成先验从稀疏正面输入合成与身份一致的、合理的背面伪图像，提供鲁棒的多视角监督。2. Adaptive Spatial Alignment Strategy (ASA)：采用可学习的变换矩阵，在训练过程中进行优化，以实现合成视图与3D高斯表示之间的精确几何对齐，解决固有的姿态和坐标差异。

Result: 在NeRSemble和K-hairstyle数据集上，通过几何、光度以及基于GPT-4o的感知指标评估，AvatarBack显著提升了背面头部重建质量，同时保持了正面保真度。此外，重建的化身在不同动作下保持一致的视觉真实感，并完全可动画化。

Conclusion: AvatarBack成功解决了3D高斯头部化身背面重建的挑战，通过其创新的生成和对齐策略，实现了更完整、更一致且高度逼真的头部化身重建，且具有良好的可动画性。

Abstract: Recent advances in Gaussian Splatting have significantly boosted the
reconstruction of head avatars, enabling high-quality facial modeling by
representing an 3D avatar as a collection of 3D Gaussians. However, existing
methods predominantly rely on frontal-view images, leaving the back-head poorly
constructed. This leads to geometric inconsistencies, structural blurring, and
reduced realism in the rear regions, ultimately limiting the fidelity of
reconstructed avatars. To address this challenge, we propose AvatarBack, a
novel plug-and-play framework specifically designed to reconstruct complete and
consistent 3D Gaussian avatars by explicitly modeling the missing back-head
regions. AvatarBack integrates two core technical innovations,i.e., the
Subject-specific Generator (SSG) and the Adaptive Spatial Alignment Strategy
(ASA). The former leverages a generative prior to synthesize
identity-consistent, plausible back-view pseudo-images from sparse frontal
inputs, providing robust multi-view supervision. To achieve precise geometric
alignment between these synthetic views and the 3D Gaussian representation, the
later employs learnable transformation matrices optimized during training,
effectively resolving inherent pose and coordinate discrepancies. Extensive
experiments on NeRSemble and K-hairstyle datasets, evaluated using geometric,
photometric, and GPT-4o-based perceptual metrics, demonstrate that AvatarBack
significantly enhances back-head reconstruction quality while preserving
frontal fidelity. Moreover, the reconstructed avatars maintain consistent
visual realism under diverse motions and remain fully animatable.

</details>


### [95] [CraftGraffiti: Exploring Human Identity with Custom Graffiti Art via Facial-Preserving Diffusion Models](https://arxiv.org/abs/2508.20640)
*Ayan Banerjee,Fernando Vilariño,Josep Lladós*

Main category: cs.CV

TL;DR: CraftGraffiti是一个文本引导的涂鸦生成框架，旨在极端风格转换下保留面部身份，并实现了风格自由与可识别性的融合。


<details>
  <summary>Details</summary>
Motivation: 在生成艺术中，尤其是在涂鸦这种高对比度、抽象的媒介中，极端风格转换下保持面部身份是一个重大挑战。对眼睛、鼻子或嘴巴的细微扭曲都可能消除主体的可识别性，从而损害个人和文化真实性。

Method: CraftGraffiti首先通过LoRA微调的预训练扩散Transformer进行涂鸦风格迁移。接着，通过一个面部一致的自注意力机制（该机制通过显式身份嵌入增强注意力层）来确保身份保真度。姿态定制无需关键点，而是利用CLIP引导的提示扩展来实现动态重塑。该方法遵循并验证了“先风格，后身份”的范式。

Result: 定量结果显示出色的面部特征一致性，以及最先进的审美和人类偏好得分。定性分析和在Cruilla音乐节的实际部署突显了该系统在现实世界中的创意影响。该研究还证明“先风格，后身份”范式相比反向顺序能减少属性漂移。

Conclusion: CraftGraffiti推进了尊重身份的AI辅助艺术的目标，为创意AI应用中融合风格自由和可识别性提供了一种原则性方法。

Abstract: Preserving facial identity under extreme stylistic transformation remains a
major challenge in generative art. In graffiti, a high-contrast, abstract
medium, subtle distortions to the eyes, nose, or mouth can erase the subject's
recognizability, undermining both personal and cultural authenticity. We
present CraftGraffiti, an end-to-end text-guided graffiti generation framework
designed with facial feature preservation as a primary objective. Given an
input image and a style and pose descriptive prompt, CraftGraffiti first
applies graffiti style transfer via LoRA-fine-tuned pretrained diffusion
transformer, then enforces identity fidelity through a face-consistent
self-attention mechanism that augments attention layers with explicit identity
embeddings. Pose customization is achieved without keypoints, using CLIP-guided
prompt extension to enable dynamic re-posing while retaining facial coherence.
We formally justify and empirically validate the "style-first, identity-after"
paradigm, showing it reduces attribute drift compared to the reverse order.
Quantitative results demonstrate competitive facial feature consistency and
state-of-the-art aesthetic and human preference scores, while qualitative
analyses and a live deployment at the Cruilla Festival highlight the system's
real-world creative impact. CraftGraffiti advances the goal of
identity-respectful AI-assisted artistry, offering a principled approach for
blending stylistic freedom with recognizability in creative AI applications.

</details>


### [96] ["Humor, Art, or Misinformation?": A Multimodal Dataset for Intent-Aware Synthetic Image Detection](https://arxiv.org/abs/2508.20670)
*Anastasios Skoularikis,Stefanos-Iordanis Papadopoulos,Symeon Papadopoulos,Panagiotis C. Petrantonakis*

Main category: cs.CV

TL;DR: 本文引入了S-HArM数据集，用于对AI生成图像的意图进行多模态分类，并探索了合成数据生成策略和多种模型，发现意图推断仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成内容检测方法大多忽略了图像背后的意图。为了填补这一空白，研究旨在开发能够识别AI生成图像意图（如幽默/讽刺、艺术或错误信息）的方法。

Method: 研究方法包括：1. 构建S-HArM多模态数据集，包含9,576个来自Twitter/X和Reddit的“野外”图像-文本对，并标注为幽默/讽刺、艺术或错误信息。2. 探索三种提示策略（图像引导、描述引导和多模态引导）使用Stable Diffusion生成大规模合成训练数据集。3. 进行广泛的比较研究，包括模态融合、对比学习、重建网络、注意力机制和大型视觉-语言模型。

Result: 研究结果显示，使用图像引导和多模态引导数据训练的模型在处理“野外”内容时泛化能力更强，这归因于视觉上下文的保留。然而，总体性能仍然有限。

Conclusion: 研究得出结论，推断AI生成图像的意图是一个复杂的问题，现有模型性能有限，需要专门的架构来进一步提升意图识别能力。

Abstract: Recent advances in multimodal AI have enabled progress in detecting synthetic
and out-of-context content. However, existing efforts largely overlook the
intent behind AI-generated images. To fill this gap, we introduce S-HArM, a
multimodal dataset for intent-aware classification, comprising 9,576 "in the
wild" image-text pairs from Twitter/X and Reddit, labeled as Humor/Satire, Art,
or Misinformation. Additionally, we explore three prompting strategies
(image-guided, description-guided, and multimodally-guided) to construct a
large-scale synthetic training dataset with Stable Diffusion. We conduct an
extensive comparative study including modality fusion, contrastive learning,
reconstruction networks, attention mechanisms, and large vision-language
models. Our results show that models trained on image- and multimodally-guided
data generalize better to "in the wild" content, due to preserved visual
context. However, overall performance remains limited, highlighting the
complexity of inferring intent and the need for specialized architectures.

</details>


### [97] [Learned Rate Control for Frame-Level Adaptive Neural Video Compression via Dynamic Neural Network](https://arxiv.org/abs/2508.20709)
*Chenhao Zhang,Wei Gao*

Main category: cs.CV

TL;DR: 本文提出了一种动态视频压缩框架，通过动态路由自编码器和速率控制代理，实现了精确的变比特率控制和优异的压缩性能，同时优化了速率-失真-复杂度。


<details>
  <summary>Details</summary>
Motivation: 尽管神经视频压缩（NVC）性能显著，但其固有限制导致精确的速率控制仍是一个挑战，尤其是在可变比特率场景下。

Method: 该方法包括三个关键部分：1) 提出动态路由自编码器（DRA），具有可变编码路径，每条路径占用部分计算复杂度并对应不同的RD权衡。2) 引入速率控制代理（RCA），在运行时估计每条路径的比特率并调整DRA的编码路径以接近目标比特率。3) 采用联合路由优化策略，实现不同路径的协同训练，以覆盖广泛的可变比特率范围并保持整体RD性能。

Result: 在HEVC和UVG数据集上的实验表明，该方法比现有最先进方法平均实现了14.8%的BD-Rate降低和0.47dB的BD-PSNR增益，同时将平均比特率误差保持在1.66%。

Conclusion: 该方法为各种比特率和比特率受限的应用实现了速率-失真-复杂度优化（RDCO），有效解决了神经视频压缩中的精确速率控制问题。

Abstract: Neural Video Compression (NVC) has achieved remarkable performance in recent
years. However, precise rate control remains a challenge due to the inherent
limitations of learning-based codecs. To solve this issue, we propose a dynamic
video compression framework designed for variable bitrate scenarios. First, to
achieve variable bitrate implementation, we propose the Dynamic-Route
Autoencoder with variable coding routes, each occupying partial computational
complexity of the whole network and navigating to a distinct RD trade-off.
Second, to approach the target bitrate, the Rate Control Agent estimates the
bitrate of each route and adjusts the coding route of DRA at run time. To
encompass a broad spectrum of variable bitrates while preserving overall RD
performance, we employ the Joint-Routes Optimization strategy, achieving
collaborative training of various routes. Extensive experiments on the HEVC and
UVG datasets show that the proposed method achieves an average BD-Rate
reduction of 14.8% and BD-PSNR gain of 0.47dB over state-of-the-art methods
while maintaining an average bitrate error of 1.66%, achieving
Rate-Distortion-Complexity Optimization (RDCO) for various bitrate and
bitrate-constrained applications. Our code is available at
https://git.openi.org.cn/OpenAICoding/DynamicDVC.

</details>


### [98] [CardioMorphNet: Cardiac Motion Prediction Using a Shape-Guided Bayesian Recurrent Deep Network](https://arxiv.org/abs/2508.20734)
*Reza Akbari Movahed,Abuzar Rezaee,Arezoo Zakeri,Colin Berry,Edmond S. L. Ho,Ali Gooya*

Main category: cs.CV

TL;DR: CardioMorphNet是一个循环贝叶斯深度学习框架，用于通过3D心脏形状引导的形变配准来精确估计心脏运动，解决了传统方法忽略解剖区域的问题，并在UK Biobank数据集上表现出卓越性能和更低的预测不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有的心脏运动估计方法通常依赖于基于强度的图像配准相似性损失，这可能忽略心脏解剖区域，导致无法准确捕捉心脏运动。因此，需要一种能更专注于解剖区域的方法。

Method: 本文提出了CardioMorphNet，一个用于3D心脏形状引导形变配准的循环贝叶斯深度学习框架。它使用循环变分自编码器来建模心脏周期内的时空依赖性，并包含两个后验模型用于双心室分割和运动估计。其损失函数源自贝叶斯公式，通过递归配准分割图来引导框架关注解剖区域，而不使用基于强度的图像配准相似性损失。此外，该框架还能计算估计运动场的不确定性图。

Result: 在UK Biobank数据集上进行验证，CardioMorphNet在心脏运动估计方面表现出卓越性能，优于现有最先进的方法。不确定性评估显示，与其它基于概率的心脏配准方法相比，它在心脏区域的估计运动场产生了更低的不确定性值，表明其预测具有更高的置信度。

Conclusion: CardioMorphNet通过其3D心脏形状引导的贝叶斯深度学习方法，显著提高了心脏运动估计的准确性，并提供了高置信度的预测，有效解决了传统方法忽略解剖区域的问题。

Abstract: Accurate cardiac motion estimation from cine cardiac magnetic resonance (CMR)
images is vital for assessing cardiac function and detecting its abnormalities.
Existing methods often struggle to capture heart motion accurately because they
rely on intensity-based image registration similarity losses that may overlook
cardiac anatomical regions. To address this, we propose CardioMorphNet, a
recurrent Bayesian deep learning framework for 3D cardiac shape-guided
deformable registration using short-axis (SAX) CMR images. It employs a
recurrent variational autoencoder to model spatio-temporal dependencies over
the cardiac cycle and two posterior models for bi-ventricular segmentation and
motion estimation. The derived loss function from the Bayesian formulation
guides the framework to focus on anatomical regions by recursively registering
segmentation maps without using intensity-based image registration similarity
loss, while leveraging sequential SAX volumes and spatio-temporal features. The
Bayesian modelling also enables computation of uncertainty maps for the
estimated motion fields. Validated on the UK Biobank dataset by comparing
warped mask shapes with ground truth masks, CardioMorphNet demonstrates
superior performance in cardiac motion estimation, outperforming
state-of-the-art methods. Uncertainty assessment shows that it also yields
lower uncertainty values for estimated motion fields in the cardiac region
compared with other probabilistic-based cardiac registration methods,
indicating higher confidence in its predictions.

</details>


### [99] [Mix, Align, Distil: Reliable Cross-Domain Atypical Mitosis Classification](https://arxiv.org/abs/2508.20745)
*Kaustubh Atey,Sameer Anand Jha,Gouranga Bala,Amit Sethi*

Main category: cs.CV

TL;DR: 该研究提出了一种简单的训练时方法，通过特征多样性增强、跨域特征对齐和EMA教师蒸馏，实现了对非典型有丝分裂像(AMFs)的域鲁棒分类，并在MIDOG 2025挑战赛中取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 非典型有丝分裂像(AMFs)是重要的组织病理学标志物，但由于扫描仪、染色和采集差异导致的领域漂移，其一致性识别极具挑战性。

Method: 该方法包含三个主要步骤：(i) 通过在骨干网络早期和中期阶段插入风格扰动来增加特征多样性；(ii) 使用弱领域标签（扫描仪、来源、物种、肿瘤）和辅助对齐损失来对齐跨站点的注意力精炼特征；(iii) 通过从指数移动平均(EMA)教师模型进行温度缩放的KL散度蒸馏来稳定预测。

Result: 在MIDOG 2025任务2的初步排行榜上，该方法在非典型有丝分裂分类中达到了0.8762的平衡准确率、0.8873的敏感性、0.8651的特异性和0.9499的ROC AUC。该方法推理时间开销可忽略不计，仅依赖粗略的领域元数据，并提供了强大、平衡的性能。

Conclusion: 该方法为MIDOG 2025挑战赛提供了一个有竞争力的解决方案，能够有效应对领域漂移，并在非典型有丝分裂像分类中展现出强大且平衡的性能。

Abstract: Atypical mitotic figures (AMFs) are important histopathological markers yet
remain challenging to identify consistently, particularly under domain shift
stemming from scanner, stain, and acquisition differences. We present a simple
training-time recipe for domain-robust AMF classification in MIDOG 2025 Task 2.
The approach (i) increases feature diversity via style perturbations inserted
at early and mid backbone stages, (ii) aligns attention-refined features across
sites using weak domain labels (Scanner, Origin, Species, Tumor) through an
auxiliary alignment loss, and (iii) stabilizes predictions by distilling from
an exponential moving average (EMA) teacher with temperature-scaled KL
divergence. On the organizer-run preliminary leaderboard for atypical mitosis
classification, our submission attains balanced accuracy of 0.8762, sensitivity
of 0.8873, specificity of 0.8651, and ROC AUC of 0.9499. The method incurs
negligible inference-time overhead, relies only on coarse domain metadata, and
delivers strong, balanced performance, positioning it as a competitive
submission for the MIDOG 2025 challenge.

</details>


### [100] [Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning](https://arxiv.org/abs/2508.20751)
*Yibin Wang,Zhimin Li,Yuhang Zang,Yujie Zhou,Jiazi Bu,Chunyu Wang,Qinglin Lu,Cheng Jin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 本文提出了Pref-GRPO，一种基于成对偏好奖励的GRPO方法，用于解决文本到图像（T2I）生成中基于点式奖励模型的奖励欺骗问题，并引入了UniGenBench，一个统一的T2I基准，用于更全面的模型评估。


<details>
  <summary>Details</summary>
Motivation: 当前的T2I生成中，基于GRPO的强化学习方法因点式奖励模型易受奖励欺骗影响，导致模型过度优化微小增益并破坏生成过程稳定性。此外，现有T2I基准的评估标准过于粗糙，阻碍了对模型性能的全面评估。

Method: 本文提出Pref-GRPO，它将优化目标从分数最大化转变为偏好拟合，使用成对偏好奖励模型在组内进行图像比较，并以胜率作为奖励信号，以确保更稳定的训练。同时，本文引入UniGenBench，一个包含600个提示（涵盖5个主题和20个子主题）的统一T2I基准，通过10个主要和27个次要标准评估语义一致性，并利用多模态大语言模型（MLLM）进行基准构建和评估。

Result: Pref-GRPO能够区分细微的图像质量差异，提供更稳定的优势并有效缓解奖励欺骗问题。UniGenBench揭示了开源和闭源T2I模型的优缺点，并验证了Pref-GRPO的有效性。

Conclusion: Pref-GRPO通过引入成对偏好奖励，显著提高了T2I生成模型训练的稳定性和抗奖励欺骗能力。UniGenBench则提供了一个更全面、细致的评估框架，以准确衡量T2I模型的性能。

Abstract: Recent advancements highlight the importance of GRPO-based reinforcement
learning methods and benchmarking in enhancing text-to-image (T2I) generation.
However, current methods using pointwise reward models (RM) for scoring
generated images are susceptible to reward hacking. We reveal that this happens
when minimal score differences between images are amplified after
normalization, creating illusory advantages that drive the model to
over-optimize for trivial gains, ultimately destabilizing the image generation
process. To address this, we propose Pref-GRPO, a pairwise preference
reward-based GRPO method that shifts the optimization objective from score
maximization to preference fitting, ensuring more stable training. In
Pref-GRPO, images are pairwise compared within each group using preference RM,
and the win rate is used as the reward signal. Extensive experiments
demonstrate that PREF-GRPO differentiates subtle image quality differences,
providing more stable advantages and mitigating reward hacking. Additionally,
existing T2I benchmarks are limited by coarse evaluation criteria, hindering
comprehensive model assessment. To solve this, we introduce UniGenBench, a
unified T2I benchmark comprising 600 prompts across 5 main themes and 20
subthemes. It evaluates semantic consistency through 10 primary and 27
sub-criteria, leveraging MLLM for benchmark construction and evaluation. Our
benchmarks uncover the strengths and weaknesses of both open and closed-source
T2I models and validate the effectiveness of Pref-GRPO.

</details>


### [101] [Adapting Foundation Model for Dental Caries Detection with Dual-View Co-Training](https://arxiv.org/abs/2508.20813)
*Tao Luo,Han Wu,Tong Yang,Dinggang Shen,Zhiming Cui*

Main category: cs.CV

TL;DR: DVCTNet是一种新颖的双视图协同训练网络，通过结合全景X射线图像的全局视图和裁剪牙齿图像的局部视图，并利用门控跨视图注意力机制，显著提高了龋齿检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于龋齿对比度细微变化和病变形态多样，当前从全景X射线图像检测龋齿的方法准确性不佳。研究灵感来源于牙医结合全图筛查和牙齿级详细检查的临床工作流程。

Method: 该方法首先通过自动化牙齿检测建立全局视图（全景X射线）和局部视图（裁剪牙齿图像）。然后，分别预训练两个视觉基础模型。全局视图模型作为检测骨干，生成区域提议和全局特征；局部视图模型从对应裁剪牙齿补丁中提取详细特征。引入门控跨视图注意力（GCV-Atten）模块，动态融合双视图特征，并将融合特征整合回检测模型进行最终龋齿检测。

Result: DVCTNet在公共数据集和新策展的高精度龋齿检测数据集上均表现出优于现有最先进（SOTA）方法的性能。

Conclusion: DVCTNet在龋齿检测方面表现出色，具有显著的临床适用性。

Abstract: Accurate dental caries detection from panoramic X-rays plays a pivotal role
in preventing lesion progression. However, current detection methods often
yield suboptimal accuracy due to subtle contrast variations and diverse lesion
morphology of dental caries. In this work, inspired by the clinical workflow
where dentists systematically combine whole-image screening with detailed
tooth-level inspection, we present DVCTNet, a novel Dual-View Co-Training
network for accurate dental caries detection. Our DVCTNet starts with employing
automated tooth detection to establish two complementary views: a global view
from panoramic X-ray images and a local view from cropped tooth images. We then
pretrain two vision foundation models separately on the two views. The
global-view foundation model serves as the detection backbone, generating
region proposals and global features, while the local-view model extracts
detailed features from corresponding cropped tooth patches matched by the
region proposals. To effectively integrate information from both views, we
introduce a Gated Cross-View Attention (GCV-Atten) module that dynamically
fuses dual-view features, enhancing the detection pipeline by integrating the
fused features back into the detection model for final caries detection. To
rigorously evaluate our DVCTNet, we test it on a public dataset and further
validate its performance on a newly curated, high-precision dental caries
detection dataset, annotated using both intra-oral images and panoramic X-rays
for double verification. Experimental results demonstrate DVCTNet's superior
performance against existing state-of-the-art (SOTA) methods on both datasets,
indicating the clinical applicability of our method. Our code and labeled
dataset are available at https://github.com/ShanghaiTech-IMPACT/DVCTNet.

</details>


### [102] [FusionCounting: Robust visible-infrared image fusion guided by crowd counting via multi-task learning](https://arxiv.org/abs/2508.20817)
*He Li,Xinyu Liu,Weihang Kong,Xingchen Zhang*

Main category: cs.CV

TL;DR: 本文提出FusionCounting，一个新颖的多任务学习框架，将人群计数集成到可见光与红外图像融合（VIF）过程中，以解决现有语义指导方法的局限性并提高融合质量和计数性能。


<details>
  <summary>Details</summary>
Motivation: 大多数VIF方法侧重于优化图像质量，而引入下游任务（如语义分割、目标检测）作为语义指导存在标注成本高、在拥挤场景中表现不佳等问题。此外，尽管RGB-T人群计数日益受到关注，但尚未有研究将VIF与人群计数整合到统一框架中。

Method: 提出FusionCounting多任务学习框架，将人群计数直接融入VIF过程。该框架利用输入图像和人口密度信息，通过互利的多任务设计进行学习。为加速收敛并平衡任务贡献，引入了动态损失函数加权策略。此外，采用对抗训练以增强VIF和人群计数的鲁棒性。

Result: 在公共数据集上的实验结果表明，FusionCounting不仅提升了图像融合质量，而且实现了优越的人群计数性能。

Conclusion: FusionCounting成功地将人群计数与可见光和红外图像融合结合，提供了一种新的语义指导范式，有效解决了现有方法的挑战，并同时提升了融合图像质量和人群计数精度。

Abstract: Most visible and infrared image fusion (VIF) methods focus primarily on
optimizing fused image quality. Recent studies have begun incorporating
downstream tasks, such as semantic segmentation and object detection, to
provide semantic guidance for VIF. However, semantic segmentation requires
extensive annotations, while object detection, despite reducing annotation
efforts compared with segmentation, faces challenges in highly crowded scenes
due to overlapping bounding boxes and occlusion. Moreover, although RGB-T crowd
counting has gained increasing attention in recent years, no studies have
integrated VIF and crowd counting into a unified framework. To address these
challenges, we propose FusionCounting, a novel multi-task learning framework
that integrates crowd counting into the VIF process. Crowd counting provides a
direct quantitative measure of population density with minimal annotation,
making it particularly suitable for dense scenes. Our framework leverages both
input images and population density information in a mutually beneficial
multi-task design. To accelerate convergence and balance tasks contributions,
we introduce a dynamic loss function weighting strategy. Furthermore, we
incorporate adversarial training to enhance the robustness of both VIF and
crowd counting, improving the model's stability and resilience to adversarial
attacks. Experimental results on public datasets demonstrate that
FusionCounting not only enhances image fusion quality but also achieves
superior crowd counting performance.

</details>


### [103] [Estimating 2D Keypoints of Surgical Tools Using Vision-Language Models with Low-Rank Adaptation](https://arxiv.org/abs/2508.20830)
*Krit Duangprom,Tryphon Lambrou,Binod Bhattarai*

Main category: cs.CV

TL;DR: 本文提出一种利用LoRA微调的视觉语言模型（VLM）进行手术工具2D关键点估计的新方法，在小规模医疗数据集中表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统的CNN或Transformer方法在小规模医疗数据集中容易过拟合，需要利用预训练VLM的泛化能力来解决这一问题。

Method: 通过精心设计的提示词创建指令微调数据集，并使用LoRA技术对VLM进行微调，以对齐视觉特征和语义关键点描述。

Result: 仅通过两个epoch的微调，调整后的VLM就超越了基线模型，证明了LoRA在低资源场景下的有效性，并提高了关键点检测性能。

Conclusion: 该方法不仅提升了关键点检测性能，也为未来3D手术手和工具姿态估计的研究奠定了基础。

Abstract: This paper presents a novel pipeline for 2D keypoint estima- tion of surgical
tools by leveraging Vision Language Models (VLMs) fine- tuned using a low rank
adjusting (LoRA) technique. Unlike traditional Convolutional Neural Network
(CNN) or Transformer-based approaches, which often suffer from overfitting in
small-scale medical datasets, our method harnesses the generalization
capabilities of pre-trained VLMs. We carefully design prompts to create an
instruction-tuning dataset and use them to align visual features with semantic
keypoint descriptions. Experimental results show that with only two epochs of
fine tuning, the adapted VLM outperforms the baseline models, demonstrating the
ef- fectiveness of LoRA in low-resource scenarios. This approach not only
improves keypoint detection performance, but also paves the way for future work
in 3D surgical hands and tools pose estimation.

</details>


### [104] [PointDGRWKV: Generalizing RWKV-like Architecture to Unseen Domains for Point Cloud Classification](https://arxiv.org/abs/2508.20835)
*Hao Yang,Qianyu Zhou,Haijia Sun,Xiangtai Li,Xuequan Lu,Lizhuang Ma,Shuicheng Yan*

Main category: cs.CV

TL;DR: 本文首次探索了RWKV模型在点云分类域泛化（DG PCC）中的应用，发现直接应用存在空间扭曲和注意力漂移问题。为此，提出了PointDGRWKV框架，通过自适应几何Token偏移和跨域关键特征分布对齐来解决这些问题，并取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有点云分类域泛化方法（基于CNN、Transformer或Mamba）存在感受野有限、计算成本高或长程依赖建模不足的问题。RWKV作为一种新兴架构，具有线性复杂度、全局感受野和长程依赖建模的优势，但直接应用于DG PCC时，其固定的Token偏移方法会导致空间扭曲，Bi-WKV注意力机制会放大跨域差异导致注意力漂移，从而削弱泛化能力。

Method: 本文提出了PointDGRWKV框架，这是首个为DG PCC量身定制的基于RWKV的框架。它引入了两个关键模块：1) 自适应几何Token偏移（Adaptive Geometric Token Shift），用于建模局部邻域结构，以增强几何上下文感知并解决空间扭曲问题；2) 跨域关键特征分布对齐（Cross-Domain Key Feature Distribution Alignment），旨在通过对齐跨域的关键特征分布来缓解注意力漂移问题，同时保持RWKV的线性效率。

Result: 在多个基准测试上的广泛实验表明，PointDGRWKV在DG PCC任务上取得了最先进（state-of-the-art）的性能。

Conclusion: PointDGRWKV成功解决了RWKV模型在点云分类域泛化中遇到的空间建模和跨域鲁棒性挑战，通过创新的模块设计，在保持RWKV高效性的同时，显著提升了模型在未见域上的泛化能力，达到了领先的性能水平。

Abstract: Domain Generalization (DG) has been recently explored to enhance the
generalizability of Point Cloud Classification (PCC) models toward unseen
domains. Prior works are based on convolutional networks, Transformer or Mamba
architectures, either suffering from limited receptive fields or high
computational cost, or insufficient long-range dependency modeling. RWKV, as an
emerging architecture, possesses superior linear complexity, global receptive
fields, and long-range dependency. In this paper, we present the first work
that studies the generalizability of RWKV models in DG PCC. We find that
directly applying RWKV to DG PCC encounters two significant challenges: RWKV's
fixed direction token shift methods, like Q-Shift, introduce spatial
distortions when applied to unstructured point clouds, weakening local
geometric modeling and reducing robustness. In addition, the Bi-WKV attention
in RWKV amplifies slight cross-domain differences in key distributions through
exponential weighting, leading to attention shifts and degraded generalization.
To this end, we propose PointDGRWKV, the first RWKV-based framework tailored
for DG PCC. It introduces two key modules to enhance spatial modeling and
cross-domain robustness, while maintaining RWKV's linear efficiency. In
particular, we present Adaptive Geometric Token Shift to model local
neighborhood structures to improve geometric context awareness. In addition,
Cross-Domain key feature Distribution Alignment is designed to mitigate
attention drift by aligning key feature distributions across domains. Extensive
experiments on multiple benchmarks demonstrate that PointDGRWKV achieves
state-of-the-art performance on DG PCC.

</details>


### [105] [PathMR: Multimodal Visual Reasoning for Interpretable Pathology Diagnosis](https://arxiv.org/abs/2508.20851)
*Ye Zhang,Yu Zhou,Jingwen Qi,Yongbing Zhang,Simon Puettmann,Finn Wichmann,Larissa Pereira Ferreira,Lara Sichward,Julius Keyl,Sylvia Hartmann,Shuo Zhao,Hongxiao Wang,Xiaowei Xu,Jianxu Chen*

Main category: cs.CV

TL;DR: PathMR是一种细胞级多模态视觉推理框架，用于病理图像分析。它能生成专家级诊断解释和细胞分布模式，解决了现有深度学习模型在病理诊断中透明度不足的问题，并在文本生成、分割精度和跨模态对齐方面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 深度学习在病理诊断中提高了效率并减少了观察者间的差异，但其不透明的模型决策和缺乏可追溯的理由限制了临床应用。研究动机在于开发能够提供透明和可解释洞察力的AI辅助病理诊断系统。

Method: 本文提出了PathMR，一个细胞级多模态视觉推理框架。给定病理图像和文本查询，PathMR能生成专家级诊断解释，并同时预测细胞分布模式。该方法在公开的PathGen数据集和新开发的GADVR数据集上进行了性能评估。

Result: PathMR在文本生成质量、分割准确性和跨模态对齐方面，持续优于现有最先进的视觉推理方法。这些结果在PathGen和GADVR两个数据集上得到了广泛实验的证实。

Conclusion: PathMR展示了提高AI驱动病理诊断可解释性的巨大潜力，有望促进AI在临床病理学中的可靠应用。

Abstract: Deep learning based automated pathological diagnosis has markedly improved
diagnostic efficiency and reduced variability between observers, yet its
clinical adoption remains limited by opaque model decisions and a lack of
traceable rationale. To address this, recent multimodal visual reasoning
architectures provide a unified framework that generates segmentation masks at
the pixel level alongside semantically aligned textual explanations. By
localizing lesion regions and producing expert style diagnostic narratives,
these models deliver the transparent and interpretable insights necessary for
dependable AI assisted pathology. Building on these advancements, we propose
PathMR, a cell-level Multimodal visual Reasoning framework for Pathological
image analysis. Given a pathological image and a textual query, PathMR
generates expert-level diagnostic explanations while simultaneously predicting
cell distribution patterns. To benchmark its performance, we evaluated our
approach on the publicly available PathGen dataset as well as on our newly
developed GADVR dataset. Extensive experiments on these two datasets
demonstrate that PathMR consistently outperforms state-of-the-art visual
reasoning methods in text generation quality, segmentation accuracy, and
cross-modal alignment. These results highlight the potential of PathMR for
improving interpretability in AI-driven pathological diagnosis. The code will
be publicly available in https://github.com/zhangye-zoe/PathMR.

</details>


### [106] [Deep Learning Framework for Early Detection of Pancreatic Cancer Using Multi-Modal Medical Imaging Analysis](https://arxiv.org/abs/2508.20877)
*Dennis Slobodzian,Karissa Tilbury,Amir Kordijazi*

Main category: cs.CV

TL;DR: 该研究开发并验证了一个基于双模态成像（自发荧光和二次谐波生成）的深度学习框架，用于胰腺导管腺癌（PDAC）的早期检测，在有限数据集上实现了超过90%的癌症检测准确率。


<details>
  <summary>Details</summary>
Motivation: 胰腺导管腺癌（PDAC）是致死率最高的癌症之一，五年生存率低于10%，主要原因是发现较晚。因此，迫切需要改进早期检测方法。

Method: 研究分析了40个独特的患者样本，利用双模态成像（自发荧光和二次谐波生成）数据。他们评估了六种不同的深度学习架构，包括传统卷积神经网络（CNN）和视觉Transformer（ViT），以区分正常、纤维化和癌变组织。最终优化框架基于一个修改过的ResNet架构，采用了冻结预训练层和类别加权训练来解决小数据集和类别不平衡问题。

Result: 最终优化框架在癌症检测方面取得了超过90%的准确率。这显著优于当前的手动分析方法。

Conclusion: 该研究建立了一个强大的自动化PDAC检测流程，能够增强病理学家的能力，并为未来扩展到其他癌症类型奠定基础。此外，该方法为在有限规模医学影像数据集上应用深度学习提供了宝贵见解，解决了临床应用中的常见挑战。

Abstract: Pacreatic ductal adenocarcinoma (PDAC) remains one of the most lethal forms
of cancer, with a five-year survival rate below 10% primarily due to late
detection. This research develops and validates a deep learning framework for
early PDAC detection through analysis of dual-modality imaging:
autofluorescence and second harmonic generation (SHG). We analyzed 40 unique
patient samples to create a specialized neural network capable of
distinguishing between normal, fibrotic, and cancerous tissue. Our methodology
evaluated six distinct deep learning architectures, comparing traditional
Convolutional Neural Networks (CNNs) with modern Vision Transformers (ViTs).
Through systematic experimentation, we identified and overcome significant
challenges in medical image analysis, including limited dataset size and class
imbalance. The final optimized framework, based on a modified ResNet
architecture with frozen pre-trained layers and class-weighted training,
achieved over 90% accuracy in cancer detection. This represents a significant
improvement over current manual analysis methods an demonstrates potential for
clinical deployment. This work establishes a robust pipeline for automated PDAC
detection that can augment pathologists' capabilities while providing a
foundation for future expansion to other cancer types. The developed
methodology also offers valuable insights for applying deep learning to
limited-size medical imaging datasets, a common challenge in clinical
applications.

</details>


### [107] [Understanding and evaluating computer vision models through the lens of counterfactuals](https://arxiv.org/abs/2508.20881)
*Pushkar Shukla*

Main category: cs.CV

TL;DR: 本论文开发了使用反事实推理的框架，以解释、审计和缓解视觉分类器和生成模型中的偏见，通过系统性地改变属性来揭示虚假关联并构建更鲁棒的系统。


<details>
  <summary>Details</summary>
Motivation: 可解释和公平的人工智能是当前研究的核心，通过“如果……会怎样”的反事实推理，可以探究模型行为的变化，从而揭示虚假关联、探测因果依赖性并构建更鲁棒的系统。

Method: 本论文提出了多种方法：
1. 针对视觉分类器：CAVLI整合归因（LIME）和概念级分析（TCAV）来量化决策对人类可解释概念的依赖，并用热图和概念依赖分数揭示模型对无关线索的依赖。ASAC引入对抗性反事实，通过课程学习微调有偏模型以提高公平性和准确性。
2. 针对生成式文本到图像（TTI）模型：TIBET提供可扩展的管道，通过改变身份相关术语来评估提示敏感偏见。BiasConnect构建因果图来诊断交叉偏见。InterMit提供模块化、无需训练的算法，通过因果敏感性分数和用户定义的公平目标来缓解交叉偏见。

Result: 本研究贡献了一系列利用反事实推理的方法（CAVLI、ASAC、TIBET、BiasConnect、InterMit），这些方法能够：量化模型对可解释概念的依赖；揭示视觉分类器中的虚假关联和不相关依赖；通过对抗性反事实提高视觉模型的公平性和准确性；可扩展地评估和审计生成模型中与身份相关的偏见；诊断并缓解生成模型中的交叉偏见。

Conclusion: 反事实推理是解释性、公平性和因果性在判别式和生成式模型中的统一视角，为社会责任导向的偏见评估和缓解提供了有原则、可扩展的方法。

Abstract: Counterfactual reasoning -- the practice of asking ``what if'' by varying
inputs and observing changes in model behavior -- has become central to
interpretable and fair AI. This thesis develops frameworks that use
counterfactuals to explain, audit, and mitigate bias in vision classifiers and
generative models. By systematically altering semantically meaningful
attributes while holding others fixed, these methods uncover spurious
correlations, probe causal dependencies, and help build more robust systems.
  The first part addresses vision classifiers. CAVLI integrates attribution
(LIME) with concept-level analysis (TCAV) to quantify how strongly decisions
rely on human-interpretable concepts. With localized heatmaps and a Concept
Dependency Score, CAVLI shows when models depend on irrelevant cues like
backgrounds. Extending this, ASAC introduces adversarial counterfactuals that
perturb protected attributes while preserving semantics. Through curriculum
learning, ASAC fine-tunes biased models for improved fairness and accuracy
while avoiding stereotype-laden artifacts.
  The second part targets generative Text-to-Image (TTI) models. TIBET provides
a scalable pipeline for evaluating prompt-sensitive biases by varying
identity-related terms, enabling causal auditing of how race, gender, and age
affect image generation. To capture interactions, BiasConnect builds causal
graphs diagnosing intersectional biases. Finally, InterMit offers a modular,
training-free algorithm that mitigates intersectional bias via causal
sensitivity scores and user-defined fairness goals.
  Together, these contributions show counterfactuals as a unifying lens for
interpretability, fairness, and causality in both discriminative and generative
models, establishing principled, scalable methods for socially responsible bias
evaluation and mitigation.

</details>


### [108] [Classifying Mitotic Figures in the MIDOG25 Challenge with Deep Ensemble Learning and Rule Based Refinement](https://arxiv.org/abs/2508.20919)
*Sara Krauss,Ellena Spieß,Daniel Hieber,Frank Kramer,Johannes Schobel,Dominik Müller*

Main category: cs.CV

TL;DR: 本研究提出了一种基于ConvNeXtBase集成模型和规则细化（RBR）模块的深度学习方法，用于区分正常和非典型有丝分裂像（AMFs），在MIDOG25数据集上取得了84.02%的平衡准确率，并发现RBR虽能提高特异性但会降低整体性能。


<details>
  <summary>Details</summary>
Motivation: 有丝分裂像（MFs）是肿瘤分级的重要生物标志物，但手动区分正常MFs（NMFs）和非典型MFs（AMFs）耗时且主观，因此需要更高效、客观的分类方法。

Method: 采用ConvNeXtBase模型的集成学习方法，使用AUCMEDI进行训练，并扩展了一个基于规则的细化（RBR）模块。模型在MIDOG25初步测试集上进行评估。

Result: 该集成模型在MIDOG25初步测试集上达到了84.02%的平衡准确率。RBR模块虽然提高了特异性，但同时降低了敏感性和整体性能。结果表明深度集成模型在AMF分类方面表现良好。

Conclusion: 深度集成模型在非典型有丝分裂像（AMF）分类中表现出色。规则细化（RBR）模块可以提高特定指标，但需要进一步研究以优化其在整体性能上的影响。

Abstract: Mitotic figures (MFs) are relevant biomarkers in tumor grading.
Differentiating atypical MFs (AMFs) from normal MFs (NMFs) remains difficult,
as manual annotation is time-consuming and subjective. In this work an ensemble
of ConvNeXtBase models was trained with AUCMEDI and extend with a rule-based
refinement (RBR) module. On the MIDOG25 preliminary test set, the ensemble
achieved a balanced accuracy of 84.02%. While the RBR increased specificity, it
reduced sensitivity and overall performance. The results show that deep
ensembles perform well for AMF classification. RBR can increase specific
metrics but requires further research.

</details>


### [109] [Olive Tree Satellite Image Segmentation Based On SAM and Multi-Phase Refinement](https://arxiv.org/abs/2508.20954)
*Amir Jmal,Chaima Chtourou,Mahdi Louati,Abdelaziz Kallel,Houda Khmila*

Main category: cs.CV

TL;DR: 本文提出了一种创新的方法，通过结合Segment Anything Model (SAM)和基于树木排列与可学习形状/大小约束的校正，实现了卫星图像中橄榄树的高精度分割。


<details>
  <summary>Details</summary>
Motivation: 在气候变化背景下，通过遥感技术进行早期异常检测和处理，以维护橄榄树生物多样性至关重要。这需要有效的橄榄树管理解决方案，而准确的橄榄树分割是基础。

Method: 该方法利用基础模型和先进分割技术，整合Segment Anything Model (SAM)进行初步分割。随后，根据田地中树木的排列以及关于形状和大小的可学习约束进行校正。

Result: 该方法达到了98%的准确率，显著超越了SAM初始性能的82%。

Conclusion: 所提出的创新方法能够高精度地分割橄榄树，为有效管理橄榄树生物多样性提供了关键技术支持。

Abstract: In the context of proven climate change, maintaining olive biodiversity
through early anomaly detection and treatment using remote sensing technology
is crucial, offering effective management solutions. This paper presents an
innovative approach to olive tree segmentation from satellite images. By
leveraging foundational models and advanced segmentation techniques, the study
integrates the Segment Anything Model (SAM) to accurately identify and segment
olive trees in agricultural plots. The methodology includes SAM segmentation
and corrections based on trees alignement in the field and a learanble
constraint about the shape and the size. Our approach achieved a 98\% accuracy
rate, significantly surpassing the initial SAM performance of 82\%.

</details>


### [110] [E-ConvNeXt: A Lightweight and Efficient ConvNeXt Variant with Cross-Stage Partial Connections](https://arxiv.org/abs/2508.20955)
*Fang Wang,Huitao Li,Wenhan Chao,Zheng Zhuo,Yiran Ji,Chang Peng,Yupeng Sun*

Main category: cs.CV

TL;DR: 本文提出E-ConvNeXt，通过整合CSPNet和优化设计，显著降低ConvNeXt的参数量和网络复杂度，同时保持高精度，实现优异的精度-效率平衡。


<details>
  <summary>Details</summary>
Motivation: 许多高性能网络未考虑轻量级应用场景，限制了其应用范围。

Method: 本文以ConvNeXt为研究对象，通过以下核心创新来降低其复杂度和提升效率：1) 将跨阶段部分连接网络（CSPNet）与ConvNeXt集成并调整网络结构，将模型网络复杂度降低高达80%；2) 优化Stem和Block结构以增强特征表达能力和操作效率；3) 用通道注意力替换Layer Scale。

Result: 在ImageNet分类任务上，E-ConvNeXt-mini在0.9GFLOPs下达到78.3%的Top-1准确率；E-ConvNeXt-small在3.1GFLOPs下达到81.9%的Top-1准确率。在目标检测任务上的迁移学习测试进一步证实了其泛化能力。

Conclusion: E-ConvNeXt在不同复杂配置下均能保持高精度性能，展现出卓越的精度-效率平衡，并具备良好的泛化能力，适用于轻量级应用场景。

Abstract: Many high-performance networks were not designed with lightweight application
scenarios in mind from the outset, which has greatly restricted their scope of
application. This paper takes ConvNeXt as the research object and significantly
reduces the parameter scale and network complexity of ConvNeXt by integrating
the Cross Stage Partial Connections mechanism and a series of optimized
designs. The new network is named E-ConvNeXt, which can maintain high accuracy
performance under different complexity configurations. The three core
innovations of E-ConvNeXt are : (1) integrating the Cross Stage Partial Network
(CSPNet) with ConvNeXt and adjusting the network structure, which reduces the
model's network complexity by up to 80%; (2) Optimizing the Stem and Block
structures to enhance the model's feature expression capability and operational
efficiency; (3) Replacing Layer Scale with channel attention. Experimental
validation on ImageNet classification demonstrates E-ConvNeXt's superior
accuracy-efficiency balance: E-ConvNeXt-mini reaches 78.3% Top-1 accuracy at
0.9GFLOPs. E-ConvNeXt-small reaches 81.9% Top-1 accuracy at 3.1GFLOPs. Transfer
learning tests on object detection tasks further confirm its generalization
capability.

</details>


### [111] [DrivingGaussian++: Towards Realistic Reconstruction and Editable Simulation for Surrounding Dynamic Driving Scenes](https://arxiv.org/abs/2508.20965)
*Yajiao Xiong,Xiaoyu Zhou,Yongtao Wan,Deqing Sun,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: DrivingGaussian++是一个高效且有效的框架，用于真实重建和可控编辑动态自动驾驶场景，结合3D高斯、LiDAR先验和LLM实现卓越的重建和多样化编辑功能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态自动驾驶场景的真实重建和可控编辑方面存在局限性，需要一个更高效、有效且能处理动态场景的框架。

Method: 该方法使用增量3D高斯模型静态背景，用复合动态高斯图重建移动物体，并整合LiDAR先验以实现细节和一致性。它支持基于多视图图像和深度先验的免训练可控编辑，并集成大型语言模型(LLMs)自动生成动态物体运动轨迹并增强真实感。

Result: DrivingGaussian++在动态场景重建和真实感环视合成方面优于现有方法，实现了详细且一致的场景重建，展示了连贯和真实的编辑结果，并能生成动态多视图驾驶场景，显著增强了场景多样性。

Conclusion: DrivingGaussian++提供了一个高效且有效的解决方案，能够对动态自动驾驶场景进行真实重建和可控编辑，并通过集成LLMs和多模态数据，在性能和场景多样性方面取得了显著提升。

Abstract: We present DrivingGaussian++, an efficient and effective framework for
realistic reconstructing and controllable editing of surrounding dynamic
autonomous driving scenes. DrivingGaussian++ models the static background using
incremental 3D Gaussians and reconstructs moving objects with a composite
dynamic Gaussian graph, ensuring accurate positions and occlusions. By
integrating a LiDAR prior, it achieves detailed and consistent scene
reconstruction, outperforming existing methods in dynamic scene reconstruction
and photorealistic surround-view synthesis. DrivingGaussian++ supports
training-free controllable editing for dynamic driving scenes, including
texture modification, weather simulation, and object manipulation, leveraging
multi-view images and depth priors. By integrating large language models (LLMs)
and controllable editing, our method can automatically generate dynamic object
motion trajectories and enhance their realism during the optimization process.
DrivingGaussian++ demonstrates consistent and realistic editing results and
generates dynamic multi-view driving scenarios, while significantly enhancing
scene diversity. More results and code can be found at the project site:
https://xiong-creator.github.io/DrivingGaussian_plus.github.io

</details>


### [112] [Webly-Supervised Image Manipulation Localization via Category-Aware Auto-Annotation](https://arxiv.org/abs/2508.20987)
*Chenfan Qu,Yiwu Zhong,Bin Li,Lianwen Jin*

Main category: cs.CV

TL;DR: 该研究通过利用网络数据和创新的自动标注方法，构建了一个大规模、高质量的图像篡改定位数据集MIMLv2，并提出了Web-IML模型，显著缓解了数据稀缺问题，大幅提升了图像篡改定位的性能。


<details>
  <summary>Details</summary>
Motivation: 图像篡改可能误导观众并带来社会风险，但准确识别篡改区域仍是挑战。主要障碍在于数据获取成本高昂以及高质量标注数据集的严重缺乏。

Method: 该研究提出了一系列方法来缓解数据稀缺问题：1) 利用网络上大量手动伪造的图像。2) 引入CAAAv2范式，通过辅助任务自动生成像素级篡改区域标注。3) 提出QES度量标准，过滤不可靠的标注以提高标注质量。4) 通过CAAAv2和QES构建了MIMLv2数据集（包含246,212张手动伪造图像）。5) 引入Object Jitter技术，通过生成高质量篡改伪影进一步增强模型训练。6) 开发了Web-IML模型，有效利用网络规模的监督进行图像篡改定位。

Result: 1) MIMLv2数据集比现有手工制作的数据集（如IMD20）大120多倍，具有大规模、多样性和高质量的特点。2) 所提出的方法显著缓解了数据稀缺问题，并显著提高了各种模型在多个真实世界伪造基准上的性能。3) Web-IML模型在性能上实现了31%的惊人提升，并超越了之前的SOTA模型TruFor 24.1个平均IoU点。

Conclusion: 该研究通过利用网络数据和创新的自动标注及过滤技术，成功构建了一个大规模高质量的图像篡改定位数据集，并开发了高效的模型。这极大地缓解了数据稀缺问题，并显著提升了图像篡改定位任务的性能，为未来研究提供了宝贵资源和方法。

Abstract: Images manipulated using image editing tools can mislead viewers and pose
significant risks to social security. However, accurately localizing the
manipulated regions within an image remains a challenging problem. One of the
main barriers in this area is the high cost of data acquisition and the severe
lack of high-quality annotated datasets. To address this challenge, we
introduce novel methods that mitigate data scarcity by leveraging readily
available web data. We utilize a large collection of manually forged images
from the web, as well as automatically generated annotations derived from a
simpler auxiliary task, constrained image manipulation localization.
Specifically, we introduce a new paradigm CAAAv2, which automatically and
accurately annotates manipulated regions at the pixel level. To further improve
annotation quality, we propose a novel metric, QES, which filters out
unreliable annotations. Through CAAA v2 and QES, we construct MIMLv2, a
large-scale, diverse, and high-quality dataset containing 246,212 manually
forged images with pixel-level mask annotations. This is over 120x larger than
existing handcrafted datasets like IMD20. Additionally, we introduce Object
Jitter, a technique that further enhances model training by generating
high-quality manipulation artifacts. Building on these advances, we develop a
new model, Web-IML, designed to effectively leverage web-scale supervision for
the image manipulation localization task. Extensive experiments demonstrate
that our approach substantially alleviates the data scarcity problem and
significantly improves the performance of various models on multiple real-world
forgery benchmarks. With the proposed web supervision, Web-IML achieves a
striking performance gain of 31% and surpasses previous SOTA TruFor by 24.1
average IoU points. The dataset and code will be made publicly available at
https://github.com/qcf-568/MIML.

</details>


### [113] [POSE: Phased One-Step Adversarial Equilibrium for Video Diffusion Models](https://arxiv.org/abs/2508.21019)
*Jiaxiang Cheng,Bing Ma,Xuhua Ren,Hongyi Jin,Kai Yu,Peng Zhang,Wenyue Li,Yuan Zhou,Tianxiang Zheng,Qinglin Lu*

Main category: cs.CV

TL;DR: POSE（Phased One-Step Equilibrium）是一种视频扩散模型蒸馏框架，通过两阶段过程和条件对抗一致性，将大规模视频生成模型的采样步骤减少到一步，显著提升采样效率并保持高质量。


<details>
  <summary>Details</summary>
Motivation: 视频扩散生成领域面临采样效率的瓶颈，尤其对于大型模型和长序列。现有视频加速方法采用基于图像的技术，但未能有效建模视频帧的时间连贯性，也无法为大规模视频模型提供单步蒸馏。

Method: POSE提出一个两阶段蒸馏过程：(i) 稳定性预热（stability priming），通过适应单步生成器的高质量轨迹，稳定对抗蒸馏，优化流量轨迹端点附近的单步映射视频质量；(ii) 统一对抗均衡（unified adversarial equilibrium），一种灵活的自对抗蒸馏机制，促进在高斯噪声空间中实现稳定的单步对抗训练，生成接近真实视频的单步视频。对于条件视频生成，还提出(iii) 条件对抗一致性（conditional adversarial consistency），以提高条件帧与生成帧之间的语义和帧一致性。

Result: POSE在VBench-I2V上超越其他加速方法，在语义对齐、时间连贯性和帧质量方面平均提升7.15%。它将预训练模型的延迟从1000秒降低到10秒，实现了100倍的加速，同时保持了具有竞争力的性能。

Conclusion: POSE通过其创新的两阶段蒸馏和条件一致性机制，有效解决了视频扩散模型在采样效率上的挑战，实现了大规模视频模型的高质量单步生成，并显著降低了生成延迟。

Abstract: The field of video diffusion generation faces critical bottlenecks in
sampling efficiency, especially for large-scale models and long sequences.
Existing video acceleration methods adopt image-based techniques but suffer
from fundamental limitations: they neither model the temporal coherence of
video frames nor provide single-step distillation for large-scale video models.
To bridge this gap, we propose POSE (Phased One-Step Equilibrium), a
distillation framework that reduces the sampling steps of large-scale video
diffusion models, enabling the generation of high-quality videos in a single
step. POSE employs a carefully designed two-phase process to distill video
models:(i) stability priming: a warm-up mechanism to stabilize adversarial
distillation that adapts the high-quality trajectory of the one-step generator
from high to low signal-to-noise ratio regimes, optimizing the video quality of
single-step mappings near the endpoints of flow trajectories. (ii) unified
adversarial equilibrium: a flexible self-adversarial distillation mechanism
that promotes stable single-step adversarial training towards a Nash
equilibrium within the Gaussian noise space, generating realistic single-step
videos close to real videos. For conditional video generation, we propose (iii)
conditional adversarial consistency, a method to improve both semantic
consistency and frame consistency between conditional frames and generated
frames. Comprehensive experiments demonstrate that POSE outperforms other
acceleration methods on VBench-I2V by average 7.15% in semantic alignment,
temporal conference and frame quality, reducing the latency of the pre-trained
model by 100$\times$, from 1000 seconds to 10 seconds, while maintaining
competitive performance.

</details>


### [114] [Reusing Computation in Text-to-Image Diffusion for Efficient Generation of Image Sets](https://arxiv.org/abs/2508.21032)
*Dale Decatur,Thibault Groueix,Wang Yifan,Rana Hanocka,Vladimir Kim,Matheus Gadelha*

Main category: cs.CV

TL;DR: 本文提出一种无训练方法，通过在扩散模型早期去噪步骤中共享计算，减少语义相似提示生成图像时的计算冗余，从而显著降低成本并提高图像质量。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型计算成本高昂。现有工作主要优化单次推理效率，但本文旨在解决相关提示之间存在的计算冗余问题。

Method: 该方法利用扩散模型从粗到精的特性（早期去噪步骤捕获共享结构），通过语义相似度对提示进行聚类，并在早期扩散步骤中共享计算。对于以图像嵌入为条件的模型，该方法还利用UnClip的文本到图像先验来优化扩散步骤分配，以提高效率。该方法无需训练。

Result: 实验表明，对于以图像嵌入为条件训练的模型，该方法显著降低了计算成本，同时提高了图像质量。它能无缝集成到现有流程中，可随提示集扩展，并有效减少大规模文本到图像生成的环境和经济负担。

Conclusion: 通过利用扩散模型的内在特性和共享计算，该方法为大规模文本到图像生成提供了一种高效、高质量且环保的解决方案，有效降低了计算和财务成本。

Abstract: Text-to-image diffusion models enable high-quality image generation but are
computationally expensive. While prior work optimizes per-inference efficiency,
we explore an orthogonal approach: reducing redundancy across correlated
prompts. Our method leverages the coarse-to-fine nature of diffusion models,
where early denoising steps capture shared structures among similar prompts. We
propose a training-free approach that clusters prompts based on semantic
similarity and shares computation in early diffusion steps. Experiments show
that for models trained conditioned on image embeddings, our approach
significantly reduces compute cost while improving image quality. By leveraging
UnClip's text-to-image prior, we enhance diffusion step allocation for greater
efficiency. Our method seamlessly integrates with existing pipelines, scales
with prompt sets, and reduces the environmental and financial burden of
large-scale text-to-image generation. Project page:
https://ddecatur.github.io/hierarchical-diffusion/

</details>


### [115] [Mitosis detection in domain shift scenarios: a Mamba-based approach](https://arxiv.org/abs/2508.21033)
*Gennaro Percannella,Mattia Sarno,Francesco Tortorella,Mario Vento*

Main category: cs.CV

TL;DR: 本文提出了一种基于Mamba的丝分裂检测方法，旨在解决组织病理图像在领域漂移下的性能下降问题，并利用VM-UNet架构和染色增强技术来提高模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 丝分裂检测在肿瘤评估中至关重要。然而，现有的机器学习算法在训练领域之外的图像上表现出显著的性能下降。Mamba在医学图像分割任务中展现出的良好性能启发了本研究。

Method: 本研究提出了一种基于Mamba的方法，具体采用VM-UNet架构进行丝分裂检测，并结合染色增强操作以进一步提高模型对抗领域漂移的鲁棒性。

Result: 初步实验在MIDOG++数据集上进行，结果表明所提出的方法仍有很大的改进空间。

Conclusion: 本工作提出了一种基于Mamba的丝分裂检测方法，旨在应对领域漂移挑战，并已提交至MItosis DOmain Generalization (MIDOG) 挑战赛的赛道1。尽管初步结果显示有待改进，但该方法为解决领域泛化问题提供了新思路。

Abstract: Mitosis detection in histopathology images plays a key role in tumor
assessment. Although machine learning algorithms could be exploited for aiding
physicians in accurately performing such a task, these algorithms suffer from
significative performance drop when evaluated on images coming from domains
that are different from the training ones. In this work, we propose a
Mamba-based approach for mitosis detection under domain shift, inspired by the
promising performance demonstrated by Mamba in medical imaging segmentation
tasks. Specifically, our approach exploits a VM-UNet architecture for carrying
out the addressed task, as well as stain augmentation operations for further
improving model robustness against domain shift. Our approach has been
submitted to the track 1 of the MItosis DOmain Generalization (MIDOG)
challenge. Preliminary experiments, conducted on the MIDOG++ dataset, show
large room for improvement for the proposed method.

</details>


### [116] [A multi-task neural network for atypical mitosis recognition under domain shift](https://arxiv.org/abs/2508.21035)
*Gennaro Percannella,Mattia Sarno,Francesco Tortorella,Mario Vento*

Main category: cs.CV

TL;DR: 本研究提出一种基于多任务学习的方法，旨在解决组织病理学图像中非典型有丝分裂识别在域偏移下性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习模型可用于自动识别组织病理学图像中的非典型有丝分裂以评估肿瘤侵袭性，但在域偏移条件下，这些模型的性能会显著下降。

Method: 提出了一种基于多任务学习的方法。通过利用与主要分类任务相关的辅助任务，该方法旨在帮助模型仅关注分类对象，而忽略图像中随域变化的背景。

Result: 在MIDOG 2025非典型训练集、Ami-Br数据集以及MIDOG25挑战赛的初步测试集这三个不同数据集上进行的初步评估显示，所提出的方法表现出有前景的性能。

Conclusion: 多任务学习方法能够有效应对组织病理学图像中非典型有丝分裂识别的域偏移问题，并取得了良好的初步效果。

Abstract: Recognizing atypical mitotic figures in histopathology images allows
physicians to correctly assess tumor aggressiveness. Although machine learning
models could be exploited for automatically performing such a task, under
domain shift these models suffer from significative performance drops. In this
work, an approach based on multi-task learning is proposed for addressing this
problem. By exploiting auxiliary tasks, correlated to the main classification
task, the proposed approach, submitted to the track 2 of the MItosis DOmain
Generalization (MIDOG) challenge, aims to aid the model to focus only on the
object to classify, ignoring the domain varying background of the image. The
proposed approach shows promising performance in a preliminary evaluation
conducted on three distinct datasets, i.e., the MIDOG 2025 Atypical Training
Set, the Ami-Br dataset, as well as the preliminary test set of the MIDOG25
challenge.

</details>


### [117] [FW-GAN: Frequency-Driven Handwriting Synthesis with Wave-Modulated MLP Generator](https://arxiv.org/abs/2508.21040)
*Huynh Tong Dang Khoa,Dang Hoai Nam,Vo Nguyen Le Duy*

Main category: cs.CV

TL;DR: FW-GAN是一个单样本手写字合成框架，它通过引入相位感知Wave-MLP生成器、频率引导判别器和频率分布损失，从单个示例生成高质量、风格一致的手写字，以解决手写识别中的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 带标签的手写数据稀缺，限制了手写识别（HTR）系统的有效性。现有手写合成方法存在两个主要局限：一是基于传统卷积架构难以建模长距离依赖和复杂笔画模式；二是忽略了对捕捉细粒度风格和结构细节至关重要的频率信息。

Method: 本文提出了FW-GAN，一个单样本手写字合成框架。其生成器集成了相位感知Wave-MLP，以更好地捕捉空间关系并保留微妙的风格线索。同时，引入了一个频率引导判别器，利用高频分量增强生成样本的真实性检测。此外，提出了一种新颖的频率分布损失，用于对齐合成手写字和真实手写字的频率特性，从而提高视觉保真度。

Result: 在越南语和英语手写数据集上的实验表明，FW-GAN能够生成高质量、风格一致的手写字。

Conclusion: FW-GAN是低资源手写识别（HTR）流程中用于数据增强的宝贵工具。

Abstract: Labeled handwriting data is often scarce, limiting the effectiveness of
recognition systems that require diverse, style-consistent training samples.
Handwriting synthesis offers a promising solution by generating artificial data
to augment training. However, current methods face two major limitations.
First, most are built on conventional convolutional architectures, which
struggle to model long-range dependencies and complex stroke patterns. Second,
they largely ignore the crucial role of frequency information, which is
essential for capturing fine-grained stylistic and structural details in
handwriting. To address these challenges, we propose FW-GAN, a one-shot
handwriting synthesis framework that generates realistic, writer-consistent
text from a single example. Our generator integrates a phase-aware Wave-MLP to
better capture spatial relationships while preserving subtle stylistic cues. We
further introduce a frequency-guided discriminator that leverages
high-frequency components to enhance the authenticity detection of generated
samples. Additionally, we introduce a novel Frequency Distribution Loss that
aligns the frequency characteristics of synthetic and real handwriting, thereby
enhancing visual fidelity. Experiments on Vietnamese and English handwriting
datasets demonstrate that FW-GAN generates high-quality, style-consistent
handwriting, making it a valuable tool for augmenting data in low-resource
handwriting recognition (HTR) pipelines. Official implementation is available
at https://github.com/DAIR-Group/FW-GAN

</details>


### [118] [MMG-Vid: Maximizing Marginal Gains at Segment-level and Token-level for Efficient Video LLMs](https://arxiv.org/abs/2508.21044)
*Junpeng Ma,Qizhe Zhang,Ming Lu,Zhibin Wang,Qiang Zhou,Jun Song,Shanghang Zhang*

Main category: cs.CV

TL;DR: MMG-Vid是一个无需训练的视觉token剪枝框架，通过在段级别和token级别最大化边际收益，有效减少VLLMs的视觉token冗余，显著提高效率并保持高性能。


<details>
  <summary>Details</summary>
Motivation: 视频大语言模型（VLLMs）在视频理解方面表现出色，但过多的视觉token导致计算挑战。现有方法在剪枝时未考虑视频帧的动态特性和时间依赖性，将视频理解视为多帧任务。

Method: 本文提出了MMG-Vid，一个无需训练的视觉token剪枝框架，通过最大化段级别和token级别的边际收益来移除冗余。具体方法包括：1) 基于帧相似性将视频划分为段，并动态分配token预算以最大化每个段的边际收益；2) 提出一种时间引导的DPC算法，联合建模帧间独特性和帧内多样性，从而最大化每个token的边际收益。通过结合这两个阶段，MMG-Vid能最大限度利用有限的token预算。

Result: MMG-Vid在保持超过99.5%原始性能的同时，有效减少了75%的视觉token，并在LLaVA-OneVision-7B上将预填充阶段加速了3.9倍。

Conclusion: MMG-Vid能够最大限度地利用有限的token预算，显著提高效率，同时保持强大的性能。

Abstract: Video Large Language Models (VLLMs) excel in video understanding, but their
excessive visual tokens pose a significant computational challenge for
real-world applications. Current methods aim to enhance inference efficiency by
visual token pruning. However, they do not consider the dynamic characteristics
and temporal dependencies of video frames, as they perceive video understanding
as a multi-frame task. To address these challenges, we propose MMG-Vid, a novel
training-free visual token pruning framework that removes redundancy by
Maximizing Marginal Gains at both segment-level and token-level. Specifically,
we first divide the video into segments based on frame similarity, and then
dynamically allocate the token budget for each segment to maximize the marginal
gain of each segment. Subsequently, we propose a temporal-guided DPC algorithm
that jointly models inter-frame uniqueness and intra-frame diversity, thereby
maximizing the marginal gain of each token. By combining both stages, MMG-Vid
can maximize the utilization of the limited token budget, significantly
improving efficiency while maintaining strong performance. Extensive
experiments demonstrate that MMG-Vid can maintain over 99.5% of the original
performance, while effectively reducing 75% visual tokens and accelerating the
prefilling stage by 3.9x on LLaVA-OneVision-7B. Code will be released soon.

</details>


### [119] [Multi-View 3D Point Tracking](https://arxiv.org/abs/2508.21060)
*Frano Rajič,Haofei Xu,Marko Mihajlovic,Siyuan Li,Irem Demir,Emircan Gündoğdu,Lei Ke,Sergey Prokudin,Marc Pollefeys,Siyu Tang*

Main category: cs.CV

TL;DR: 本文提出首个数据驱动的多视角3D点跟踪器，能使用少量相机（如四个）在动态场景中鲁棒地跟踪任意点，解决了现有单目和多目方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的单目跟踪器在深度模糊和遮挡方面表现不佳，而先前的多相机方法需要超过20个相机和繁琐的序列优化，这些都限制了实际应用。

Method: 该方法是一个前馈模型，直接预测3D对应关系。它融合多视角特征到统一的点云中，并结合k近邻关联和基于Transformer的更新机制来估计长距离3D对应，即使在遮挡下也能有效。模型在5K合成Kubric序列上进行训练。

Result: 在Panoptic Studio和DexYCB两个真实世界基准上评估，中位数轨迹误差分别为3.1厘米和2.0厘米。该方法对1-8个视角、不同视点和24-150帧的视频长度具有良好的泛化能力。

Conclusion: 该跟踪器及其训练和评估数据集的发布旨在为多视角3D跟踪研究设定新标准，并为实际应用提供实用工具。

Abstract: We introduce the first data-driven multi-view 3D point tracker, designed to
track arbitrary points in dynamic scenes using multiple camera views. Unlike
existing monocular trackers, which struggle with depth ambiguities and
occlusion, or prior multi-camera methods that require over 20 cameras and
tedious per-sequence optimization, our feed-forward model directly predicts 3D
correspondences using a practical number of cameras (e.g., four), enabling
robust and accurate online tracking. Given known camera poses and either
sensor-based or estimated multi-view depth, our tracker fuses multi-view
features into a unified point cloud and applies k-nearest-neighbors correlation
alongside a transformer-based update to reliably estimate long-range 3D
correspondences, even under occlusion. We train on 5K synthetic multi-view
Kubric sequences and evaluate on two real-world benchmarks: Panoptic Studio and
DexYCB, achieving median trajectory errors of 3.1 cm and 2.0 cm, respectively.
Our method generalizes well to diverse camera setups of 1-8 views with varying
vantage points and video lengths of 24-150 frames. By releasing our tracker
alongside training and evaluation datasets, we aim to set a new standard for
multi-view 3D tracking research and provide a practical tool for real-world
applications. Project page available at https://ethz-vlg.github.io/mvtracker.

</details>


### [120] [OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning](https://arxiv.org/abs/2508.21066)
*Yuan Gong,Xionghui Wang,Jie Wu,Shiyin Wang,Yitong Wang,Xinglong Wu*

Main category: cs.CV

TL;DR: 本文提出OneReward，一个统一的强化学习框架，利用单个视觉-语言模型作为奖励模型，提升多任务生成模型（特别是掩码引导图像生成）在不同评估标准下的生成能力，无需任务特定的监督微调，并显著优于现有竞品。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理具有不同数据分布和评估指标的多任务生成时，常依赖任务特定的监督微调（SFT），这限制了模型的泛化能力和训练效率。在多样化的数据和任务目标背景下，急需一个统一且高效的框架。

Method: 引入OneReward，一个统一的强化学习框架，使用单个视觉-语言模型（VLM）作为生成奖励模型，该模型能够区分给定任务和评估标准下的“赢家”和“输家”。该框架应用于掩码引导图像生成（包括图像填充、图像扩展、物体移除和文本渲染等子任务），通过多任务强化学习直接在预训练基础模型上进行训练，避免了任务特定的监督微调。在此基础上开发了Seedream 3.0 Fill模型。

Result: 实验结果表明，基于OneReward开发的统一编辑模型Seedream 3.0 Fill在多个评估维度上持续优于商业和开源竞品，例如Ideogram、Adobe Photoshop和FLUX Fill [Pro]。

Conclusion: OneReward提供了一个统一且高效的强化学习框架，能够有效提升多任务生成模型的性能，尤其是在掩码引导图像生成领域，通过避免任务特定的监督微调，实现了卓越的泛化能力和竞争优势。

Abstract: In this paper, we introduce OneReward, a unified reinforcement learning
framework that enhances the model's generative capabilities across multiple
tasks under different evaluation criteria using only \textit{One Reward} model.
By employing a single vision-language model (VLM) as the generative reward
model, which can distinguish the winner and loser for a given task and a given
evaluation criterion, it can be effectively applied to multi-task generation
models, particularly in contexts with varied data and diverse task objectives.
We utilize OneReward for mask-guided image generation, which can be further
divided into several sub-tasks such as image fill, image extend, object
removal, and text rendering, involving a binary mask as the edit area. Although
these domain-specific tasks share same conditioning paradigm, they differ
significantly in underlying data distributions and evaluation metrics. Existing
methods often rely on task-specific supervised fine-tuning (SFT), which limits
generalization and training efficiency. Building on OneReward, we develop
Seedream 3.0 Fill, a mask-guided generation model trained via multi-task
reinforcement learning directly on a pre-trained base model, eliminating the
need for task-specific SFT. Experimental results demonstrate that our unified
edit model consistently outperforms both commercial and open-source
competitors, such as Ideogram, Adobe Photoshop, and FLUX Fill [Pro], across
multiple evaluation dimensions. Code and model are available at:
https://one-reward.github.io

</details>


### [121] [Dress&Dance: Dress up and Dance as You Like It - Technical Preview](https://arxiv.org/abs/2508.21070)
*Jun-Kun Chen,Aayush Bansal,Minh Phuoc Vo,Yu-Xiong Wang*

Main category: cs.CV

TL;DR: Dress&Dance是一个视频扩散框架，能够生成高质量、高分辨率的虚拟试穿视频，支持多种服装类型和单次多件试穿，通过创新的CondNet网络实现多模态输入统一和优异的服装注册及动作保真度。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿解决方案可能在视频质量、分辨率、服装类型支持或多件试穿灵活性方面存在局限，研究旨在提供一个高质量、灵活且用户友好的虚拟试穿视频生成框架。

Method: 该方法基于视频扩散框架，核心是CondNet网络。CondNet利用注意力机制统一文本、图像和视频等多种模态输入，以增强服装注册和动作保真度。CondNet采用多阶段渐进式训练，结合有限视频数据和更易获取的大规模图像数据集进行异构数据训练。

Result: Dress&Dance能够生成5秒长、24 FPS、1152x720分辨率的高质量虚拟试穿视频，仅需一张用户图像。它支持上衣、下装、连衣裙以及单次同时试穿上衣和下装。该框架在性能上超越了现有的开源和商业解决方案。

Conclusion: Dress&Dance提供了一种高质量、灵活的虚拟试穿体验，通过其创新的CondNet网络和训练方法，显著提升了虚拟试穿视频的生成效果，超越了现有技术水平。

Abstract: We present Dress&Dance, a video diffusion framework that generates high
quality 5-second-long 24 FPS virtual try-on videos at 1152x720 resolution of a
user wearing desired garments while moving in accordance with a given reference
video. Our approach requires a single user image and supports a range of tops,
bottoms, and one-piece garments, as well as simultaneous tops and bottoms
try-on in a single pass. Key to our framework is CondNet, a novel conditioning
network that leverages attention to unify multi-modal inputs (text, images, and
videos), thereby enhancing garment registration and motion fidelity. CondNet is
trained on heterogeneous training data, combining limited video data and a
larger, more readily available image dataset, in a multistage progressive
manner. Dress&Dance outperforms existing open source and commercial solutions
and enables a high quality and flexible try-on experience.

</details>


### [122] [First-Place Solution to NeurIPS 2024 Invisible Watermark Removal Challenge](https://arxiv.org/abs/2508.21072)
*Fahad Shamshad,Tameem Bakr,Yahia Shaaban,Noor Hussein,Karthik Nandakumar,Nils Lukas*

Main category: cs.CV

TL;DR: 本文介绍了NeurIPS 2024“擦除隐形”挑战赛的获胜方案，该方案在不同对抗知识水平下，以极小的图像质量损失成功实现了近乎完美的数字水印去除。


<details>
  <summary>Details</summary>
Motivation: 数字水印是数字媒体认证和版权保护的重要工具，但其对抗性攻击的鲁棒性尚不明确。本研究旨在通过压力测试现有水印的鲁棒性来解决这一不确定性。

Method: 该方法针对挑战赛的两个赛道（黑盒和米色盒）分别设计：
1.  **米色盒赛道**：利用自适应VAE（变分自编码器）的规避攻击，结合测试时优化和CIELAB空间中的颜色对比度恢复，以保持图像质量。
2.  **黑盒赛道**：首先根据空间或频域的伪影对图像进行聚类，然后对每个聚类应用带有受控噪声注入和ChatGPT生成语义先验的图像到图像扩散模型，并优化参数设置。

Result: 经验评估表明，该方法成功实现了近乎完美的水印去除（95.7%），同时对残余图像的质量影响可忽略不计。

Conclusion: 本研究的攻击方法成功揭示了现有水印的脆弱性，并希望能够激发更鲁棒的图像水印方法的开发。

Abstract: Content watermarking is an important tool for the authentication and
copyright protection of digital media. However, it is unclear whether existing
watermarks are robust against adversarial attacks. We present the winning
solution to the NeurIPS 2024 Erasing the Invisible challenge, which
stress-tests watermark robustness under varying degrees of adversary knowledge.
The challenge consisted of two tracks: a black-box and beige-box track,
depending on whether the adversary knows which watermarking method was used by
the provider. For the beige-box track, we leverage an adaptive VAE-based
evasion attack, with a test-time optimization and color-contrast restoration in
CIELAB space to preserve the image's quality. For the black-box track, we first
cluster images based on their artifacts in the spatial or frequency-domain.
Then, we apply image-to-image diffusion models with controlled noise injection
and semantic priors from ChatGPT-generated captions to each cluster with
optimized parameter settings. Empirical evaluations demonstrate that our method
successfully achieves near-perfect watermark removal (95.7%) with negligible
impact on the residual image's quality. We hope that our attacks inspire the
development of more robust image watermarking methods.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [123] [Social Bias in Multilingual Language Models: A Survey](https://arxiv.org/abs/2508.20201)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 这篇系统综述分析了多语言模型中的社会偏见评估和缓解方法，揭示了该领域在语言多样性、文化意识和方法设计上的差距，并提出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 预训练多语言模型与处理英文文本的模型一样存在社会偏见，因此需要分析和扩展偏见评估及缓解方法至多语言和非英语语境。

Method: 通过系统综述，分析了多语言和非英语语境下偏见评估与缓解的新兴研究，考察了这些研究的语言多样性、文化意识、评估指标选择和缓解技术。

Result: 研究揭示了该领域在方法设计上的差距（例如，偏好某些语言，多语言偏见缓解实验的稀缺性），并分类了在跨语言和文化适应偏见基准时遇到的常见问题和已实施的解决方案。

Conclusion: 根据研究结果，论文为未来的研究指明了方向，旨在增强多语言偏见文献的包容性、跨文化适用性以及与最新自然语言处理进展的对齐。

Abstract: Pretrained multilingual models exhibit the same social bias as models
processing English texts. This systematic review analyzes emerging research
that extends bias evaluation and mitigation approaches into multilingual and
non-English contexts. We examine these studies with respect to linguistic
diversity, cultural awareness, and their choice of evaluation metrics and
mitigation techniques. Our survey illuminates gaps in the field's dominant
methodological design choices (e.g., preference for certain languages, scarcity
of multilingual mitigation experiments) while cataloging common issues
encountered and solutions implemented in adapting bias benchmarks across
languages and cultures. Drawing from the implications of our findings, we chart
directions for future research that can reinforce the multilingual bias
literature's inclusivity, cross-cultural appropriateness, and alignment with
state-of-the-art NLP advancements.

</details>


### [124] [Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models](https://arxiv.org/abs/2508.20217)
*Mohammad Amini,Babak Ahmadi,Xiaomeng Xiong,Yilin Zhang,Christopher Qiao*

Main category: cs.CL

TL;DR: 本研究探索了利用语言模型（特别是通过结构化提示和高效微调）自动生成多项选择题（MCQ）用于形态学评估，发现结构化提示能显著提升中等规模模型（Gemma）的性能，使其生成更符合要求的问题，并提出了一个结合自动化、专家评估和大型模型模拟的实用工作流程。


<details>
  <summary>Details</summary>
Motivation: 减少人工开发形态学评估试题的成本和不一致性，提高测试开发的效率和质量。

Method: 研究采用双重方法：首先，比较了微调过的中等模型（Gemma, 2B）与未微调的大型模型（GPT-3.5, 175B）的表现。其次，评估了七种结构化提示策略（包括零样本、少样本、思维链、基于角色、序列和组合策略）。生成的问题通过自动化指标、专家对五个维度的评分以及使用GPT-4.1模拟人类评分进行评估。

Result: 结果显示，结构化提示，特别是结合思维链和序列设计的策略，显著改善了Gemma的输出。Gemma在良好提示下生成的试题通常比GPT-3.5的零样本响应更符合结构和教学要求，提示设计在中等规模模型性能中起着关键作用。研究表明，结构化提示和高效微调可以增强中等规模模型在有限数据条件下的自动生成能力。

Conclusion: 结构化提示和高效微调能有效提升中等规模模型在自动生成评估项目方面的性能。结合自动化指标、专家判断和大型模型模拟对于确保评估目标一致性至关重要。所提出的工作流程为K-12语言评估项目提供了实用且可扩展的开发和验证方法。

Abstract: This study explores automatic generation (AIG) using language models to
create multiple choice questions (MCQs) for morphological assessment, aiming to
reduce the cost and inconsistency of manual test development. The study used a
two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)
with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven
structured prompting strategies, including zero-shot, few-shot,
chain-of-thought, role-based, sequential, and combinations. Generated items
were assessed using automated metrics and expert scoring across five
dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate
human scoring at scale. Results show that structured prompting, especially
strategies combining chain-of-thought and sequential design, significantly
improved Gemma's outputs. Gemma generally produced more construct-aligned and
instructionally appropriate items than GPT-3.5's zero-shot responses, with
prompt design playing a key role in mid-size model performance. This study
demonstrates that structured prompting and efficient fine-tuning can enhance
midsized models for AIG under limited data conditions. We highlight the value
of combining automated metrics, expert judgment, and large-model simulation to
ensure alignment with assessment goals. The proposed workflow offers a
practical and scalable way to develop and validate language assessment items
for K-12.

</details>


### [125] [Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach](https://arxiv.org/abs/2508.20223)
*Andrei Mihai Albu,Giovanni Pollo,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Alessandra Neri,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 本文提出了一种开源方法，将SystemC TLM模型集成到基于FMI的协同仿真工作流中，通过将SystemC TLM组件封装为FMI 3.0 FMU，实现跨异构仿真环境的无缝集成。


<details>
  <summary>Details</summary>
Motivation: 网络物理系统（特别是汽车应用）日益复杂，对高效建模和跨域协同仿真技术的需求增加。SystemC TLM虽然能有效进行软硬件协同设计，但其与其他工程领域模型的互操作性有限，导致集成挑战。

Method: 将SystemC TLM组件封装为FMI 3.0协同仿真功能模型单元（FMU）。引入了一个轻量级的开源工具链，并解决了时间同步和数据交换等关键技术挑战。

Result: 通过代表性案例研究，验证了该集成方法的可行性和有效性，实现了SystemC TLM模型在异构仿真环境中的无缝、标准化集成。

Conclusion: 所提出的开源方法成功地将SystemC TLM模型集成到基于FMI的协同仿真工作流中，促进了异构仿真环境之间的标准化、无缝集成。

Abstract: The growing complexity of cyber-physical systems, particularly in automotive
applications, has increased the demand for efficient modeling and cross-domain
co-simulation techniques. While SystemC Transaction-Level Modeling (TLM)
enables effective hardware/software co-design, its limited interoperability
with models from other engineering domains poses integration challenges. This
paper presents a fully open-source methodology for integrating SystemC TLM
models into Functional Mock-up Interface (FMI)-based co-simulation workflows.
By encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional
Mock-up Units (FMUs), the proposed approach facilitates seamless, standardized
integration across heterogeneous simulation environments. We introduce a
lightweight open-source toolchain, address key technical challenges such as
time synchronization and data exchange, and demonstrate the feasibility and
effectiveness of the integration through representative case studies.

</details>


### [126] [Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities](https://arxiv.org/abs/2508.20324)
*Rikuto Kotoge,Mai Nishimura,Jiaxin Ma*

Main category: cs.CL

TL;DR: 针对小型语言模型在代理式RAG中强化学习表现不佳的问题，本文提出DGPO方法，通过教师模型引导，使小型模型能实现复杂的代理式搜索行为，甚至超越大型教师模型，从而在资源受限环境中实现代理式RAG。


<details>
  <summary>Details</summary>
Motivation: 强化学习在引导语言模型（尤其是小型模型）实现代理式RAG行为（如搜索和规划）时面临挑战。小型模型因推理能力差，导致奖励稀疏和训练不稳定。

Method: 提出“蒸馏引导策略优化”（Distillation-Guided Policy Optimization, DGPO）方法。该方法通过以下方式解决问题：1) 从教师演示中进行冷启动初始化；2) 在策略优化过程中提供持续的教师指导。同时引入“代理式RAG能力”（Agentic RAG Capabilities, ARC）作为细粒度指标，用于分析推理、搜索协调和响应合成。

Result: 全面的实验表明，DGPO使小型模型能够实现复杂的代理式搜索行为，在某些情况下甚至超越了大型教师模型。

Conclusion: DGPO使得在计算资源受限的环境中实现代理式RAG成为可能。

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher guidance during policy
optimization. To systematically evaluate our approach, we introduce Agentic RAG
Capabilities (ARC), a fine-grained metric analyzing reasoning, search
coordination, and response synthesis. Comprehensive experiments demonstrate
that DGPO enables compact models to achieve sophisticated agentic search
behaviors, even outperforming the larger teacher model in some cases. DGPO
makes agentic RAG feasible in computing resource-constrained environments.

</details>


### [127] [GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs](https://arxiv.org/abs/2508.20325)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Andy Zhou,Yang Zhang,Haohan Wang*

Main category: cs.CL

TL;DR: 本文提出GUARD方法，将政府发布的LLM伦理指南转化为可操作的测试问题，以评估LLM的合规性，并能诊断潜在的“越狱”风险。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）日益普及，但其生成有害内容的潜力引发了担忧。政府发布了伦理指南，但这些指南通常是高层次要求，缺乏将其转化为可验证LLM合规性的具体测试问题的方法。

Method: GUARD（Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics）方法通过自动化生成违反指南的问题来测试LLM的合规性。当LLM响应直接违反指南时，GUARD会报告不一致性。对于未直接违反指南的响应，GUARD整合了“越狱”诊断（GUARD-JD）概念，创建诱发非道德或违反指南响应的场景，以识别可能绕过内置安全机制的潜在情况。最终生成一份合规性报告。

Result: GUARD在七个LLM（包括Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4, GPT-4o, Claude-3.7）上进行了实证验证，测试了其在三个政府指南下的合规性及越狱诊断能力。GUARD-JD还可将越狱诊断转移到视觉-语言模型（VLMs）。

Conclusion: GUARD是一种有效的测试方法，能够将高层级的伦理指南转化为具体的测试问题，评估LLM的合规性，并识别潜在的越狱风险，从而促进基于LLM的可靠应用开发。

Abstract: As Large Language Models become increasingly integral to various domains,
their potential to generate harmful responses has prompted significant societal
and regulatory concerns. In response, governments have issued ethics guidelines
to promote the development of trustworthy AI. However, these guidelines are
typically high-level demands for developers and testers, leaving a gap in
translating them into actionable testing questions to verify LLM compliance.
  To address this challenge, we introduce GUARD (\textbf{G}uideline
\textbf{U}pholding Test through \textbf{A}daptive \textbf{R}ole-play and
Jailbreak \textbf{D}iagnostics), a testing method designed to operationalize
guidelines into specific guideline-violating questions that assess LLM
adherence. To implement this, GUARD uses automated generation of
guideline-violating questions based on government-issued guidelines, thereby
testing whether responses comply with these guidelines. When responses directly
violate guidelines, GUARD reports inconsistencies. Furthermore, for responses
that do not directly violate guidelines, GUARD integrates the concept of
``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that
provoke unethical or guideline-violating responses, effectively identifying
potential scenarios that could bypass built-in safety mechanisms. Our method
finally culminates in a compliance report, delineating the extent of adherence
and highlighting any violations.
  We have empirically validated the effectiveness of GUARD on seven LLMs,
including Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,
GPT-4o, and Claude-3.7, by testing compliance under three government-issued
guidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can
transfer jailbreak diagnostics to vision-language models, demonstrating its
usage in promoting reliable LLM-based applications.

</details>


### [128] [Joint Enhancement of Relational Reasoning for Long-Context LLMs](https://arxiv.org/abs/2508.20351)
*Zhirui Chen,Wei Shen,Jiashui Huang,Ling Shao*

Main category: cs.CL

TL;DR: JERR是一个新颖的框架，通过结合摘要提取、图构建和蒙特卡洛树搜索（MCTS）进行关系推理，旨在增强大型语言模型（LLM）的长上下文理解能力，解决记忆限制、复杂任务处理、缺乏透明度和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在处理长上下文时面临记忆限制、难以处理复杂长上下文任务、缺乏透明度且容易产生幻觉等问题。

Method: JERR框架包含三个关键组件：1. **摘要提取**：通过策略性地分块文本来高效总结和理解信息。2. **图构建**：构建有向无环图（DAG）以解决冗余，确保逻辑一致性。3. **关系推理**：整合蒙特卡洛树搜索（MCTS）以导航复杂的推理路径，确保输出的准确性和可解释性。

Result: 实验结果表明，JERR在ROUGE和F1指标上持续优于所有基线，并在LLM-Rater评估中取得了最高分。

Conclusion: JERR提供了一种新颖的解决方案，使LLM能够以更高的可靠性和透明度处理扩展上下文和复杂的推理任务。

Abstract: Despite significant progress, large language models (LLMs) still struggle
with long contexts due to memory limitations and their inability to tackle
complex and long-context tasks. Additionally, LLMs often suffer from a lack of
transparency and are prone to producing hallucinations. To address these
challenges, we propose \textbf{JERR}, a novel framework designed to enhance
long-context comprehension via graph-based reasoning in LLMs. JERR integrates
three key components: synopsis extraction, graph construction, and relational
reasoning. First, synopsis is extracted by chunking text strategically,
allowing the model to summarize and understand information more efficiently.
Second, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring
logical consistency and clarity. Finally, we incorporate Monte Carlo Tree
Search (MCTS) to help the model navigate complex reasoning paths, ensuring more
accurate and interpretable outputs. This framework provides a novel solution
that enables LLMs to handle extended contexts and complex reasoning tasks with
improved reliability and transparency. Experimental results show that JERR
consistently outperforms all baselines on the ROUGE and F1 metrics, achieving
the highest scores on the LLM-Rater evaluation.

</details>


### [129] [Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems](https://arxiv.org/abs/2508.20373)
*Yuyao Wang,Bowen Liu,Jianheng Tang,Nuo Chen,Yuhan Li,Qifan Zhang,Jia Li*

Main category: cs.CL

TL;DR: 该研究引入NP-hard图问题作为可扩展的合成训练语料库，并设计了两阶段后训练框架（SFT+RL），显著提升了大型语言模型（LLM）的长链思维推理能力和效率，并展现出强大的泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有推理大型语言模型（RLLMs）的长链思维（Long CoT）能力严重依赖于昂贵且人工策划的高质量数据集进行后训练，缺乏可扩展的替代方案。

Method: 1. 引入NP-hard (NPH) 图问题作为新型合成训练语料库，因其内在要求深度推理、广泛探索和反思策略。2. 开发了两阶段后训练框架：(i) 基于拒绝采样的NPH图实例进行长链思维监督微调（SFT），以显著增强推理深度；(ii) 采用细粒度奖励设计的强化学习（RL），以提高推理效率。

Result: 旗舰模型Graph-R1-7B在数学、编码、STEM和逻辑等领域展现出强大的泛化能力，并在NPH图问题上超越了QwQ-32B模型，同时提高了准确性和推理效率。

Conclusion: NPH图问题被证明是推动LLM长链思维推理的有效且可扩展资源，为LLM的后训练开辟了新途径。

Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable
progress on complex reasoning tasks, largely enabled by their long
chain-of-thought (Long CoT) capabilities. However, developing these Long CoT
behaviors relies heavily on post-training with high-quality datasets, which are
typically costly and human-curated (e.g., mathematics and code), leaving
scalable alternatives unexplored. In this work, we introduce NP-hard (NPH)
graph problems as a novel synthetic training corpus, as they inherently require
deep reasoning, extensive exploration, and reflective strategies, which are
core characteristics of Long CoT reasoning. Building on this insight, we
develop a two-stage post-training framework: (i) Long CoT Supervised
Fine-Tuning (SFT) on rejection-sampled NPH graph instances, which substantially
enhances reasoning depth, and (ii) Reinforcement Learning (RL) with a
fine-grained reward design, which sharpens reasoning efficiency. Our flagship
model, Graph-R1-7B, demonstrates strong generalization across mathematics,
coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both
accuracy and reasoning efficiency. These results position NPH graph problems as
an effective and scalable resource for advancing Long CoT reasoning in LLMs,
opening a new frontier for LLM post-training. Our implementation is available
at https://github.com/Graph-Reasoner/Graph-R1, with models and datasets hosted
in our Hugging Face collection HKUST-DSAIL/Graph-R1.

</details>


### [130] [CAPE: Context-Aware Personality Evaluation Framework for Large Language Models](https://arxiv.org/abs/2508.20385)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本文提出了一个上下文感知的LLM个性评估框架（CAPE），发现对话历史能提高LLM响应一致性但也会导致个性转变，并揭示了不同LLM对上下文和问题顺序的敏感性差异。


<details>
  <summary>Details</summary>
Motivation: 现有对大型语言模型（LLM）的心理测量测试采用无上下文方法，忽略了真实世界应用中对话历史对响应的影响，导致评估结果与实际场景脱节。

Method: 提出了第一个上下文感知个性评估（CAPE）框架，该框架纳入了先前的对话交互。引入了量化LLM响应一致性的新指标，并对7个LLM进行了广泛实验。此外，还将该框架应用于角色扮演代理（RPAs）。

Result: 对话历史通过上下文学习增强了响应一致性，但同时也导致了LLM的个性转变，其中GPT-3.5-Turbo和GPT-4-Turbo表现出极端偏差。GPT模型对问题顺序具有鲁棒性，而Gemini-1.5-Flash和Llama-8B则表现出显著敏感性。GPT模型的响应源于其内在个性和先前交互，而Gemini-1.5-Flash和Llama-8B则严重依赖先前交互。将框架应用于RPAs显示，上下文相关的个性转变提高了响应一致性并更好地与人类判断对齐。

Conclusion: 上下文感知评估对于理解LLM行为至关重要。对话历史在提高响应一致性的同时，也会导致LLM的个性发生显著变化。不同LLM对上下文和问题顺序的敏感性存在差异，且上下文依赖的个性转变有助于RPAs更好地与人类判断对齐。

Abstract: Psychometric tests, traditionally used to assess humans, are now being
applied to Large Language Models (LLMs) to evaluate their behavioral traits.
However, existing studies follow a context-free approach, answering each
question in isolation to avoid contextual influence. We term this the Disney
World test, an artificial setting that ignores real-world applications, where
conversational history shapes responses. To bridge this gap, we propose the
first Context-Aware Personality Evaluation (CAPE) framework for LLMs,
incorporating prior conversational interactions. To thoroughly analyze the
influence of context, we introduce novel metrics to quantify the consistency of
LLM responses, a fundamental trait in human behavior.
  Our exhaustive experiments on 7 LLMs reveal that conversational history
enhances response consistency via in-context learning but also induces
personality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme
deviations. While GPT models are robust to question ordering, Gemini-1.5-Flash
and Llama-8B display significant sensitivity. Moreover, GPT models response
stem from their intrinsic personality traits as well as prior interactions,
whereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions.
Finally, applying our framework to Role Playing Agents (RPAs) shows
context-dependent personality shifts improve response consistency and better
align with human judgments. Our code and datasets are publicly available at:
https://github.com/jivnesh/CAPE

</details>


### [131] [Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction](https://arxiv.org/abs/2508.20395)
*Xu Guo*

Main category: cs.CL

TL;DR: 本研究通过度量推理步骤中的条件熵，发现熵值下降与正确答案强相关，而熵值持平或上升则常导致错误答案，为设计高效推理管线提供了基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）常依赖中间推理步骤提高准确性，但很少有工作探究推理效用如何贡献最终答案的正确性。由于自回归生成的随机性，增加上下文不一定能提高答案置信度。若能在生成过程中预测推理步骤的有用性，就能提前停止或剪枝无效步骤，避免干扰最终决策。

Method: 本研究在MATH数据集上进行了预言机（oracle）研究。使用Qwen2.5-32B和GPT-4o生成推理链，然后用单独的模型（Qwen3-8B）量化这些链对最终准确性的效用。具体方法是，在每个推理步骤中，随着上下文逐步扩展，使用条件熵（词汇表上的预期负对数似然）来度量模型对答案跨度Y的不确定性。

Result: 结果显示清晰的模式：推理步骤中条件熵的下降与正确答案密切相关，而熵值持平或上升通常导致错误答案。研究还证实，不正确的推理路径往往比正确路径更长，这表明更长的推理不一定带来更好的结果。

Conclusion: 这些发现为未来设计高效推理管线奠定了基础，这些管线能够及早检测并避免无效推理。

Abstract: Recent advancements in large language models (LLMs) often rely on generating
intermediate reasoning steps to enhance accuracy. However, little work has
examined how reasoning utility contributes to the final answer's correctness.
Due to the stochastic nature of autoregressive generation, generating more
context does not guarantee increased confidence in the answer. If we could
predict, during generation, whether a reasoning step will be useful, we could
stop early or prune ineffective steps, avoiding distractions in the final
decision.
  We present an oracle study on MATH dataset, using Qwen2.5-32B and GPT-4o to
generate reasoning chains, and then employing a separate model (Qwen3-8B) to
quantify the utility of these chains for final accuracy. Specifically, we
measure the model's uncertainty on the answer span Y at each reasoning step
using conditional entropy (expected negative log-likelihood over the
vocabulary) with context expanding step by step. Our results show a clear
pattern: conditional entropy that decreases over steps is strongly associated
with correct answers, whereas flat or increasing entropy often results in wrong
answers. We also corroborate that incorrect reasoning paths tend to be longer
than correct ones, suggesting that longer reasoning does not necessarily yield
better outcomes. These findings serve as a foundation to inspire future work on
designing efficient reasoning pipelines that detect and avoid unproductive
reasoning early.

</details>


### [132] [UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools](https://arxiv.org/abs/2508.20410)
*Sam Jung,Agustin Garcinuno,Spencer Mateega*

Main category: cs.CL

TL;DR: UI-Bench是首个大规模基准测试，通过专家成对比较，严格评估AI文本到应用工具生成网站的视觉质量。


<details>
  <summary>Details</summary>
Motivation: AI文本到应用工具承诺在几分钟内生成高质量的应用程序和网站，但缺乏公开的基准来严格验证这些声明。

Method: 引入了UI-Bench，一个大规模基准测试，涵盖10种工具、30个提示、300个生成的网站，并收集了4000多次专家判断。使用基于TrueSkill的模型对系统进行排名，该模型能提供校准的置信区间，并通过专家成对比较来评估视觉卓越性。

Result: UI-Bench成功地对各种AI文本到应用工具进行了排名，并提供了带有校准置信区间的系统性能评估。它建立了一个可重复的标准，用于推进AI驱动的网页设计。研究团队发布了完整的提示集、开源评估框架和公共排行榜。

Conclusion: UI-Bench为评估和推进AI驱动的网页设计工具提供了一个严谨且可重复的基准标准，填补了现有验证空白，并为未来的研究提供了宝贵的资源。

Abstract: AI text-to-app tools promise high quality applications and websites in
minutes, yet no public benchmark rigorously verifies those claims. We introduce
UI-Bench, the first large-scale benchmark that evaluates visual excellence
across competing AI text-to-app tools through expert pairwise comparison.
Spanning 10 tools, 30 prompts, 300 generated sites, and \textit{4000+} expert
judgments, UI-Bench ranks systems with a TrueSkill-derived model that yields
calibrated confidence intervals. UI-Bench establishes a reproducible standard
for advancing AI-driven web design. We release (i) the complete prompt set,
(ii) an open-source evaluation framework, and (iii) a public leaderboard. The
generated sites rated by participants will be released soon. View the UI-Bench
leaderboard at https://uibench.ai/leaderboard.

</details>


### [133] [DentalBench: Benchmarking and Advancing LLMs Capability for Bilingual Dentistry Understanding](https://arxiv.org/abs/2508.20416)
*Hengchuan Zhu,Yihuan Xu,Yichen Li,Zijie Meng,Zuozhu Liu*

Main category: cs.CL

TL;DR: 本文介绍了DentalBench，首个用于评估和推进牙科领域大语言模型（LLMs）的综合性双语基准，并展示了领域适应的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在通用医学基准上表现出色，但其在牙科等专业医学领域的能力尚未得到充分探索，原因是缺乏针对性的评估资源。

Method: 研究引入了DentalBench，包含：1. DentalQA，一个包含36,597个问题（涵盖4个任务和16个牙科子领域）的英汉问答基准；2. DentalCorpus，一个包含3.3735亿词元的高质量牙科领域适应语料库。研究评估了14个LLMs，并使用Qwen-2.5-3B进行了领域适应实验。

Result: 评估结果显示，不同任务类型和语言之间存在显著的性能差距。领域适应显著提高了模型性能，尤其是在知识密集型和术语聚焦型任务上。

Conclusion: 研究强调了领域特定基准对于开发可靠、有效的医疗保健LLMs的重要性。

Abstract: Recent advances in large language models (LLMs) and medical LLMs (Med-LLMs)
have demonstrated strong performance on general medical benchmarks. However,
their capabilities in specialized medical fields, such as dentistry which
require deeper domain-specific knowledge, remain underexplored due to the lack
of targeted evaluation resources. In this paper, we introduce DentalBench, the
first comprehensive bilingual benchmark designed to evaluate and advance LLMs
in the dental domain. DentalBench consists of two main components: DentalQA, an
English-Chinese question-answering (QA) benchmark with 36,597 questions
spanning 4 tasks and 16 dental subfields; and DentalCorpus, a large-scale,
high-quality corpus with 337.35 million tokens curated for dental domain
adaptation, supporting both supervised fine-tuning (SFT) and
retrieval-augmented generation (RAG). We evaluate 14 LLMs, covering
proprietary, open-source, and medical-specific models, and reveal significant
performance gaps across task types and languages. Further experiments with
Qwen-2.5-3B demonstrate that domain adaptation substantially improves model
performance, particularly on knowledge-intensive and terminology-focused tasks,
and highlight the importance of domain-specific benchmarks for developing
trustworthy and effective LLMs tailored to healthcare applications.

</details>


### [134] [KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval](https://arxiv.org/abs/2508.20417)
*Chi Minh Bui,Ngoc Mai Thieu,Van Vinh Nguyen,Json J. Jung,Khac-Hoai Nam Bui*

Main category: cs.CL

TL;DR: KG-CQR是一个新颖的上下文查询检索(CQR)框架，它利用以语料库为中心的知识图谱(KG)来丰富复杂输入查询的上下文表示，从而显著提升检索增强生成(RAG)系统的检索阶段性能。


<details>
  <summary>Details</summary>
Motivation: 将知识图谱与大型语言模型(LLM)结合有望改善RAG系统的检索阶段。现有方法主要解决语料库层面的上下文丢失，而本研究旨在通过结构化关系表示来丰富查询，以解决查询层面的上下文问题。

Method: KG-CQR通过提取和补全相关KG子图来生成语义丰富的查询上下文。该框架包含子图提取、补全和上下文生成模块，作为一个与模型无关的管道运行，无需额外训练即可适用于不同大小的LLM。

Result: 在RAGBench和MultiHop-RAG数据集上的实验结果表明，KG-CQR性能优越，mAP提升4-6%，Recall@25提升2-3%。在多跳问答等挑战性RAG任务中，KG-CQR的检索有效性持续优于现有基线模型。

Conclusion: KG-CQR通过利用知识图谱丰富查询的上下文表示，显著提高了RAG系统在检索阶段的性能，特别是在处理复杂查询和多跳问答任务时表现出色，且具有模型无关的扩展性。

Abstract: The integration of knowledge graphs (KGs) with large language models (LLMs)
offers significant potential to improve the retrieval phase of
retrieval-augmented generation (RAG) systems. In this study, we propose KG-CQR,
a novel framework for Contextual Query Retrieval (CQR) that enhances the
retrieval phase by enriching the contextual representation of complex input
queries using a corpus-centric KG. Unlike existing methods that primarily
address corpus-level context loss, KG-CQR focuses on query enrichment through
structured relation representations, extracting and completing relevant KG
subgraphs to generate semantically rich query contexts. Comprising subgraph
extraction, completion, and contextual generation modules, KG-CQR operates as a
model-agnostic pipeline, ensuring scalability across LLMs of varying sizes
without additional training. Experimental results on RAGBench and MultiHop-RAG
datasets demonstrate KG-CQR's superior performance, achieving a 4-6%
improvement in mAP and a 2-3% improvement in Recall@25 over strong baseline
models. Furthermore, evaluations on challenging RAG tasks such as multi-hop
question answering show that, by incorporating KG-CQR, the performance
consistently outperforms the existing baseline in terms of retrieval
effectiveness

</details>


### [135] [CAMB: A comprehensive industrial LLM benchmark on civil aviation maintenance](https://arxiv.org/abs/2508.20420)
*Feng Zhang,Chengjie Pang,Yuehan Zhang,Chenyu Luo*

Main category: cs.CL

TL;DR: 本文提出并开发了一个工业级基准测试，专门用于评估大型语言模型（LLMs）在民用航空维修领域的性能，以填补该领域专业评估工具的空白。


<details>
  <summary>Details</summary>
Motivation: 民用航空维修是一个知识密集型且需要复杂推理的领域，但目前缺乏针对LLMs在该垂直领域的专业评估工具。现有LLM评估主要集中在数学和编程推理任务，无法识别LLMs在航空维修领域知识和复杂推理方面的具体差距。

Method: 本文开发了一个工业级基准测试，旨在标准化衡量LLM在民用航空维修中的能力。利用此基准测试，评估了现有的知名向量嵌入模型和LLMs在民用航空维修场景（特别是RAG系统）中的表现，并通过实验探索和分析来证明其有效性。

Result: 该基准测试有效地评估了模型在该领域的性能，并成功识别了LLM在民用航空维修领域知识和复杂推理方面的具体缺陷。研究结果为针对性改进（如领域特定微调、RAG优化、专业提示工程）奠定了基础。

Conclusion: 该基准测试提供了一个标准化工具，能够促进民用航空维修领域更智能解决方案的进展。作者已将此评估基准和代码开源，以鼓励进一步的研究和开发。

Abstract: Civil aviation maintenance is a domain characterized by stringent industry
standards. Within this field, maintenance procedures and troubleshooting
represent critical, knowledge-intensive tasks that require sophisticated
reasoning. To address the lack of specialized evaluation tools for large
language models (LLMs) in this vertical, we propose and develop an
industrial-grade benchmark specifically designed for civil aviation
maintenance. This benchmark serves a dual purpose: It provides a standardized
tool to measure LLM capabilities within civil aviation maintenance, identifying
specific gaps in domain knowledge and complex reasoning. By pinpointing these
deficiencies, the benchmark establishes a foundation for targeted improvement
efforts (e.g., domain-specific fine-tuning, RAG optimization, or specialized
prompt engineering), ultimately facilitating progress toward more intelligent
solutions within civil aviation maintenance. Our work addresses a significant
gap in the current LLM evaluation, which primarily focuses on mathematical and
coding reasoning tasks. In addition, given that Retrieval-Augmented Generation
(RAG) systems are currently the dominant solutions in practical applications ,
we leverage this benchmark to evaluate existing well-known vector embedding
models and LLMs for civil aviation maintenance scenarios. Through experimental
exploration and analysis, we demonstrate the effectiveness of our benchmark in
assessing model performance within this domain, and we open-source this
evaluation benchmark and code to foster further research and
development:https://github.com/CamBenchmark/cambenchmark

</details>


### [136] [Searching the Title of Practical Work of the Informatics Engineering Bachelor Program with the Case Base Reasoning Method](https://arxiv.org/abs/2508.20442)
*Agung Sukrisna Jaya,Osvari Arsalan,Danny Matthew Saputra*

Main category: cs.CL

TL;DR: 该研究利用基于案例推理（CBR）技术，结合TF-IDF和余弦相似度，开发了一个用于搜索实践工作标题的系统，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是利用过往经验（案例）来解决问题，具体应用于搜索与现有案例相似度最高的实践工作标题。

Method: 该方法采用了基于案例推理（CBR）框架。具体而言，TF-IDF被用于将每个实践工作标题的词语向量化，而余弦相似度则用于计算案例之间的相似度值。系统支持按标题或关键词搜索，输出为实践工作标题及其匹配值。

Result: 系统输出实践工作标题及其匹配值。基于对705个实践工作标题的测试，通过两个阶段进行：第一阶段使用现有标题搜索，第二阶段随机化第一阶段的标题。结果显示，在第二阶段获得了相同数量的标题，并且平均匹配分数最高。

Conclusion: 该系统能够有效利用CBR、TF-IDF和余弦相似度技术，根据相似性搜索实践工作标题，并在测试中取得了良好的匹配结果。

Abstract: Case Base Reasoning (CBR) is a case solving technique based on experience in
cases that have occurred before with the highest similarity. CBR is used to
search for practical work titles. TF-IDF is applied to process the
vectorization of each practical work title word and Cosine Similarity for the
calculation of similarity values. This system can search either in the form of
titles or keywords. The output of the system is the title of practical work and
the match value of each title. Based on the test results using 705 practical
work titles, testing was carried out with five titles and carried out in two
stages. The first stage searches with existing titles and the second stage
randomizes the title from the first stage. And the results obtained in the
second stage are the same number of titles found and the highest average match
score.

</details>


### [137] [MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers](https://arxiv.org/abs/2508.20453)
*Zhenting Wang,Qi Chang,Hemani Patel,Shashank Biju,Cheng-En Wu,Quan Liu,Aolin Ding,Alireza Rezazadeh,Ankit Shah,Yujia Bao,Eugene Siow*

Main category: cs.CL

TL;DR: 本文介绍了MCP-Bench，一个基于MCP协议的新基准测试，用于评估大型语言模型（LLMs）在需要工具使用、跨工具协调、精确参数控制以及规划推理的真实多步任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的基于API的基准测试不足以评估LLMs在需要复杂工具使用、多步工作流、模糊指令下的工具检索以及跨领域协调的真实场景中的能力。

Method: MCP-Bench通过将LLMs连接到28个代表性的实时MCP服务器（涵盖金融、旅行、科学计算、学术搜索等250个工具）来构建。它设计了具有丰富输入输出耦合的多步任务，并提出了一个多方面的评估框架，包括工具级模式理解和使用、轨迹级规划以及任务完成度。

Result: 对20个先进LLMs进行的实验表明，在MCP-Bench上，这些模型仍面临持续的挑战，揭示了它们在复杂工具使用和规划方面的局限性。

Conclusion: MCP-Bench有效揭示了当前LLMs在处理需要工具使用、跨工具协调、精确参数控制和复杂规划的真实多步任务时所面临的显著挑战。

Abstract: We introduce MCP-Bench, a benchmark for evaluating large language models
(LLMs) on realistic, multi-step tasks that demand tool use, cross-tool
coordination, precise parameter control, and planning/reasoning for solving
tasks. Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28
representative live MCP servers spanning 250 tools across domains such as
finance, traveling, scientific computing, and academic search. Unlike prior
API-based benchmarks, each MCP server provides a set of complementary tools
designed to work together, enabling the construction of authentic, multi-step
tasks with rich input-output coupling. Tasks in MCP-Bench test agents' ability
to retrieve relevant tools from fuzzy instructions without explicit tool names,
plan multi-hop execution trajectories for complex objectives, ground responses
in intermediate tool outputs, and orchestrate cross-domain workflows -
capabilities not adequately evaluated by existing benchmarks that rely on
explicit tool specifications, shallow few-step workflows, and isolated domain
operations. We propose a multi-faceted evaluation framework covering tool-level
schema understanding and usage, trajectory-level planning, and task completion.
Experiments on 20 advanced LLMs reveal persistent challenges in MCP-Bench. Code
and data: https://github.com/Accenture/mcp-bench.

</details>


### [138] [Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques](https://arxiv.org/abs/2508.20460)
*Yucheng Ruan,Xiang Lan,Daniel J. Tan,Hairil Rizal Abdullah,Mengling Feng*

Main category: cs.CL

TL;DR: 本研究提出并评估了一种深度学习框架，该框架利用自然语言处理技术整合多模态电子健康记录（EHRs），以预测重症监护室（ICU）患者的死亡率和资源利用率，并在数据损坏情况下表现出强大的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 预测ICU患者的死亡率和资源利用率对于优化患者结果和管理成本至关重要，但现有方法主要关注结构化EHRs，往往忽略了自由文本记录中宝贵的临床见解，也未能充分利用结构化数据中的文本信息。

Method: 研究开发了一个深度学习框架，该框架使用自然语言处理技术整合多模态EHRs。模型在两个真实世界EHR数据集上进行开发和评估，涉及死亡率预测、住院时长（LOS）预测和手术时长估计三个临床任务。此外，还进行了关于医学提示、自由文本和预训练句子编码器三个关键组件的消融研究，并评估了模型对结构化EHR数据损坏的鲁棒性。

Result: 在两个真实世界数据集和三个临床任务上的实验表明，与现有最佳方法相比，所提出的模型在死亡率预测的BACC/AUROC上分别提升了1.6%/0.8%，在LOS预测的RMSE/MAE上分别提升了0.5%/2.2%，在手术时长估计的RMSE/MAE上分别提升了10.9%/11.0%。模型在不同损坏率下，始终优于其他基线方法，尤其是在高损坏水平下对结构化数据损坏表现出强大的弹性。

Conclusion: 所提出的框架是一种有效且准确的深度学习方法，可用于预测重症监护中的死亡率和资源利用率。研究还强调了使用提示学习结合Transformer编码器在分析多模态EHRs方面的成功。此外，该模型对结构化数据中的数据损坏表现出强大的弹性，尤其是在高损坏水平下。

Abstract: Background Predicting mortality and resource utilization from electronic
health records (EHRs) is challenging yet crucial for optimizing patient
outcomes and managing costs in intensive care unit (ICU). Existing approaches
predominantly focus on structured EHRs, often ignoring the valuable clinical
insights in free-text notes. Additionally, the potential of textual information
within structured data is not fully leveraged. This study aimed to introduce
and assess a deep learning framework using natural language processing
techniques that integrates multimodal EHRs to predict mortality and resource
utilization in critical care settings. Methods Utilizing two real-world EHR
datasets, we developed and evaluated our model on three clinical tasks with
leading existing methods. We also performed an ablation study on three key
components in our framework: medical prompts, free-texts, and pre-trained
sentence encoder. Furthermore, we assessed the model's robustness against the
corruption in structured EHRs. Results Our experiments on two real-world
datasets across three clinical tasks showed that our proposed model improved
performance metrics by 1.6\%/0.8\% on BACC/AUROC for mortality prediction,
0.5%/2.2% on RMSE/MAE for LOS prediction, 10.9%/11.0% on RMSE/MAE for surgical
duration estimation compared to the best existing methods. It consistently
demonstrated superior performance compared to other baselines across three
tasks at different corruption rates. Conclusions The proposed framework is an
effective and accurate deep learning approach for predicting mortality and
resource utilization in critical care. The study also highlights the success of
using prompt learning with a transformer encoder in analyzing multimodal EHRs.
Importantly, the model showed strong resilience to data corruption within
structured data, especially at high corruption levels.

</details>


### [139] [ConspirED: A Dataset for Cognitive Traits of Conspiracy Theories and Large Language Model Safety](https://arxiv.org/abs/2508.20468)
*Luke Bates,Max Glockner,Preslav Nakov,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本研究引入了ConspirED数据集，用于识别阴谋论内容的认知特征，并发现计算模型和大型语言模型（LLM/LRM）在处理阴谋论输入时，即使能有效反驳事实核查的虚假信息，也会产生与输入推理模式相似的输出。


<details>
  <summary>Details</summary>
Motivation: 阴谋论侵蚀公众对科学和机构的信任，并通过演变和吸收反驳证据来抵制辟谣。随着AI生成的虚假信息日益复杂，理解阴谋论内容的修辞模式对于开发干预措施（如目标预警）和评估AI漏洞至关重要。

Method: 研究引入了ConspirED（CONSPIR评估数据集），该数据集包含来自在线阴谋论文章的多句摘录（80-120词），并使用CONSPIR认知框架标注了阴谋论思想的认知特征。这是首个标注了普遍认知特征的阴谋论内容数据集。利用ConspirED，研究开发了计算模型来识别阴谋论特征并确定文本中的主导特征，并评估了大型语言/推理模型（LLM/LRM）对阴谋论输入的鲁棒性。

Result: 研究发现，计算模型能够识别阴谋论特征和主导特征。同时，大型语言/推理模型（LLM/LRM）在处理阴谋论内容时表现出“错位”，其输出会模仿输入的推理模式，即使它们能够成功地反驳可比较的事实核查过的虚假信息。

Conclusion: 阴谋论内容对计算模型和LLM/LRM都构成了挑战，导致它们产生与阴谋论推理模式一致的输出。这强调了开发针对此类复杂虚假信息的干预措施和评估AI漏洞的重要性。

Abstract: Conspiracy theories erode public trust in science and institutions while
resisting debunking by evolving and absorbing counter-evidence. As AI-generated
misinformation becomes increasingly sophisticated, understanding rhetorical
patterns in conspiratorial content is important for developing interventions
such as targeted prebunking and assessing AI vulnerabilities. We introduce
ConspirED (CONSPIR Evaluation Dataset), which captures the cognitive traits of
conspiratorial ideation in multi-sentence excerpts (80--120 words) from online
conspiracy articles, annotated using the CONSPIR cognitive framework
(Lewandowsky and Cook, 2020). ConspirED is the first dataset of conspiratorial
content annotated for general cognitive traits. Using ConspirED, we (i) develop
computational models that identify conspiratorial traits and determine dominant
traits in text excerpts, and (ii) evaluate large language/reasoning model
(LLM/LRM) robustness to conspiratorial inputs. We find that both are misaligned
by conspiratorial content, producing output that mirrors input reasoning
patterns, even when successfully deflecting comparable fact-checked
misinformation.

</details>


### [140] [Languages Still Left Behind: Toward a Better Multilingual Machine Translation Benchmark](https://arxiv.org/abs/2508.20511)
*Chihiro Taguchi,Seng Mai,Keita Kurabe,Yusuke Sakai,Georgina Agyei,Soudabeh Eslami,David Chiang*

Main category: cs.CL

TL;DR: 本研究揭示了广泛使用的多语言机器翻译基准FLORES+在翻译质量、文化偏见和评估协议方面存在严重缺陷，可能导致对现代机器翻译系统能力的误导性评估。


<details>
  <summary>Details</summary>
Motivation: FLORES+作为评估现代机器翻译系统能力的多语言基准被广泛使用，但研究人员对其是否真正适合多语言评估提出了疑问，特别是在其声称的高质量标准和对200多种语言的覆盖下。

Method: 研究人员选取了四种语言（阿散蒂语、日语、景颇语、南阿塞拜疆语）的数据进行分析。他们通过人工评估检验了翻译质量，并收集了标注员对源语句领域特异性和文化偏见的反馈。此外，他们还展示了简单启发式（如复制命名实体）如何产生不可忽视的BLEU分数，并比较了在高质量、自然语料上训练的机器翻译模型在FLORES+和领域相关评估集上的表现。

Result: 人工评估显示FLORES+中许多翻译低于其声称的90%质量标准。标注员指出源语句常过于领域特定且存在英语世界的文化偏见。简单的命名实体复制启发式能产生可观的BLEU分数，表明评估协议存在漏洞。此外，在高质量、自然语料上训练的机器翻译模型在FLORES+上表现不佳，但在领域相关评估集上取得了显著提升。

Conclusion: FLORES+基准在真正多语言评估方面存在严重缺陷。研究呼吁开发使用领域通用、文化中立源文本、并减少对命名实体依赖的多语言机器翻译基准，以更好地反映真实的翻译挑战。

Abstract: Multilingual machine translation (MT) benchmarks play a central role in
evaluating the capabilities of modern MT systems. Among them, the FLORES+
benchmark is widely used, offering English-to-many translation data for over
200 languages, curated with strict quality control protocols. However, we study
data in four languages (Asante Twi, Japanese, Jinghpaw, and South Azerbaijani)
and uncover critical shortcomings in the benchmark's suitability for truly
multilingual evaluation. Human assessments reveal that many translations fall
below the claimed 90% quality standard, and the annotators report that source
sentences are often too domain-specific and culturally biased toward the
English-speaking world. We further demonstrate that simple heuristics, such as
copying named entities, can yield non-trivial BLEU scores, suggesting
vulnerabilities in the evaluation protocol. Notably, we show that MT models
trained on high-quality, naturalistic data perform poorly on FLORES+ while
achieving significant gains on our domain-relevant evaluation set. Based on
these findings, we advocate for multilingual MT benchmarks that use
domain-general and culturally neutral source texts rely less on named entities,
in order to better reflect real-world translation challenges.

</details>


### [141] [SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM](https://arxiv.org/abs/2508.20514)
*Pengjiang Li,Zaitian Wang,Xinhao Zhang,Ran Zhang,Lu Jiang,Pengfei Wang,Yuanchun Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种名为SciTopic的先进科学主题发现方法，该方法通过集成大型语言模型（LLMs）来增强对科学文献的理解和主题识别，优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有的主题发现方法主要依赖词嵌入，对科学出版物缺乏全面理解，难以处理复杂、高维的文本关系。受LLMs卓越文本理解能力的启发，研究旨在利用LLMs改进科学主题识别。

Method: SciTopic首先构建一个文本编码器来捕获科学出版物的内容（包括元数据、标题和摘要）。接着，构建一个空间优化模块，该模块结合了基于熵的采样和由LLMs指导的三元组任务，以增强对主题相关性和模糊实例之间上下文复杂性的关注。最后，通过优化三元组的对比损失，利用LLMs的指导对文本编码器进行微调，使其能更好地区分不同主题的实例。

Result: 在三个真实世界的科学出版物数据集上进行的广泛实验表明，SciTopic的性能优于现有最先进的科学主题发现方法。

Conclusion: SciTopic能够为研究人员提供更深入、更快速的洞察力，有效提升科学主题识别能力。

Abstract: Topic discovery in scientific literature provides valuable insights for
researchers to identify emerging trends and explore new avenues for
investigation, facilitating easier scientific information retrieval. Many
machine learning methods, particularly deep embedding techniques, have been
applied to discover research topics. However, most existing topic discovery
methods rely on word embedding to capture the semantics and lack a
comprehensive understanding of scientific publications, struggling with
complex, high-dimensional text relationships. Inspired by the exceptional
comprehension of textual information by large language models (LLMs), we
propose an advanced topic discovery method enhanced by LLMs to improve
scientific topic identification, namely SciTopic. Specifically, we first build
a textual encoder to capture the content from scientific publications,
including metadata, title, and abstract. Next, we construct a space
optimization module that integrates entropy-based sampling and triplet tasks
guided by LLMs, enhancing the focus on thematic relevance and contextual
intricacies between ambiguous instances. Then, we propose to fine-tune the
textual encoder based on the guidance from the LLMs by optimizing the
contrastive loss of the triplets, forcing the text encoder to better
discriminate instances of different topics. Finally, extensive experiments
conducted on three real-world datasets of scientific publications demonstrate
that SciTopic outperforms the state-of-the-art (SOTA) scientific topic
discovery methods, enabling researchers to gain deeper and faster insights.

</details>


### [142] [Overview of BioASQ 2024: The twelfth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20532)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Salvador Lima-López,Eulàlia Farré-Maduell,Martin Krallinger,Natalia Loukachevitch,Vera Davydova,Elena Tutubalina,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ 2024是第十二届生物医学语义索引和问答国际挑战赛，包含两个既有任务和两个新增任务（多语言心脏病学临床实体检测、俄语和英语嵌套命名实体识别）。37支队伍提交了700多次方案，大多数系统表现出色，表明该领域持续进步。


<details>
  <summary>Details</summary>
Motivation: BioASQ旨在推动大规模生物医学语义索引和问答领域的进步。

Method: 本研究通过举办BioASQ挑战赛进行，包含四个共享任务：两个既有任务（b和Synergy）以及两个新任务（MultiCardioNER，专注于多语言心脏病学领域的临床实体检测；BIONNE，专注于俄语和英语的嵌套命名实体识别）。

Result: BioASQ本届挑战赛共有37支参赛队伍，针对四个不同任务提交了超过700份独立方案。大多数参赛系统取得了有竞争力的表现。

Conclusion: 参赛系统的优异表现表明生物医学语义索引和问答领域的技术水平正在持续进步。

Abstract: This is an overview of the twelfth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2024. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks b and Synergy, and two
new tasks: a) MultiCardioNER on the adaptation of clinical entity detection to
the cardiology domain in a multilingual setting, and b) BIONNE on nested NER in
Russian and English. In this edition of BioASQ, 37 competing teams participated
with more than 700 distinct submissions in total for the four different shared
tasks of the challenge. Similarly to previous editions, most of the
participating systems achieved competitive performance, suggesting the
continuous advancement of the state-of-the-art in the field.

</details>


### [143] [Overview of BioASQ 2025: The Thirteenth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20554)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Martin Krallinger,Miguel Rodríguez-Ortega,Eduard Rodriguez-López,Natalia Loukachevitch,Andrey Sakhovskiy,Elena Tutubalina,Dimitris Dimitriadis,Grigorios Tsoumakas,George Giannakoulas,Alexandra Bekiaridou,Athanasios Samaras,Giorgio Maria Di Nunzio,Nicola Ferro,Stefano Marchesin,Marco Martinelli,Gianmaria Silvello,Georgios Paliouras*

Main category: cs.CL

TL;DR: 本文概述了CLEF 2025背景下的第十三届BioASQ挑战赛，该挑战赛旨在推动大规模生物医学语义索引和问答领域的进展，并介绍了六项任务及其参与情况。


<details>
  <summary>Details</summary>
Motivation: BioASQ挑战赛的举办旨在促进大规模生物医学语义索引和问答领域的持续进步和发展。

Method: BioASQ挑战赛通过设置一系列国际性共享任务来评估和推动研究进展。本届挑战赛包括两个既定任务（b和Synergy）以及四个新任务：多语言临床总结（MultiClinSum）、俄语和英语嵌套命名实体链接（BioNNE-L）、心脏病学临床编码（ELCardioCC）以及肠脑相互作用信息提取（GutBrainIE）。

Result: 本届BioASQ挑战赛吸引了83支参赛队伍，在六个不同任务中提交了超过1000份独立作品。许多参赛系统取得了具有竞争力的表现。

Conclusion: BioASQ挑战赛成功促进了该领域的持续发展，参赛系统的优异表现表明生物医学语义索引和问答领域的最新技术水平正在不断进步。

Abstract: This is an overview of the thirteenth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2025. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks, b and Synergy, and four
new tasks: a) Task MultiClinSum on multilingual clinical summarization. b) Task
BioNNE-L on nested named entity linking in Russian and English. c) Task
ELCardioCC on clinical coding in cardiology. d) Task GutBrainIE on gut-brain
interplay information extraction. In this edition of BioASQ, 83 competing teams
participated with more than 1000 distinct submissions in total for the six
different shared tasks of the challenge. Similar to previous editions, several
participating systems achieved competitive performance, indicating the
continuous advancement of the state-of-the-art in the field.

</details>


### [144] [Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data](https://arxiv.org/abs/2508.20557)
*Jiahao Xiao,Jiangming Liu*

Main category: cs.CL

TL;DR: 本文提出了一个包含多领域非独立同分布（non-IID）场景的基准框架，并提出了一种自适应联邦蒸馏（AdaFD）框架，以应对自然语言处理中联邦学习的输入多样性挑战，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型在联邦学习中面临数据非独立同分布（non-IID）的挑战，现有研究主要关注标签（输出）多样性，而忽略了在自然语言处理中至关重要的语言领域（输入）多样性。

Method: 引入了一套综合的多领域非独立同分布（multi-domain non-IID）场景，并建立了一个统一的基准框架来评估联邦学习。在此基础上，提出了一种自适应联邦蒸馏（AdaFD）框架，旨在解决同质和异质设置下的多领域非独立同分布挑战。

Result: 实验结果表明，所提出的AdaFD模型能够捕捉本地客户端的多样性，并取得了比现有工作更好的性能。

Conclusion: AdaFD框架有效解决了联邦学习中多领域非独立同分布的挑战，尤其是在考虑输入语言领域多样性的真实环境中表现出色。

Abstract: The widespread success of pre-trained language models has established a new
training paradigm, where a global PLM is fine-tuned using task-specific data
from local clients. The local data are highly different from each other and can
not capture the global distribution of the whole data in real world. To address
the challenges of non-IID data in real environments, privacy-preserving
federated distillation has been proposed and highly investigated. However,
previous experimental non-IID scenarios are primarily identified with the label
(output) diversity, without considering the diversity of language domains
(input) that is crucial in natural language processing. In this paper, we
introduce a comprehensive set of multi-domain non-IID scenarios and propose a
unified benchmarking framework that includes diverse data. The benchmark can be
used to evaluate the federated learning framework in a real environment. To
this end, we propose an Adaptive Federated Distillation (AdaFD) framework
designed to address multi-domain non-IID challenges in both homogeneous and
heterogeneous settings. Experimental results demonstrate that our models
capture the diversity of local clients and achieve better performance compared
to the existing works. The code for this paper is available at:
https://github.com/jiahaoxiao1228/AdaFD.

</details>


### [145] [Leveraging Generative Models for Real-Time Query-Driven Text Summarization in Large-Scale Web Search](https://arxiv.org/abs/2508.20559)
*Zeyu Xiong,Yixuan Nan,Li Gao,Hengzhu Tang,Shuaiqiang Wang,Junfeng Wang,Dawei Yin*

Main category: cs.CL

TL;DR: 本研究提出了一种新颖的生成模型框架，通过大模型蒸馏、监督微调、直接偏好优化和前瞻解码，将一个轻量级模型（0.1B参数）转化为查询驱动文本摘要（QDTS）专家，在工业网络搜索中实现了实时、高性能和高效率的摘要生成。


<details>
  <summary>Details</summary>
Motivation: 大规模网络搜索中的查询驱动文本摘要（QDTS）对提升用户参与度和促进快速决策至关重要。传统的抽取式摘要模型存在两个主要局限性：1) 多阶段流水线易导致信息累积损失和架构瓶颈；2) 传统模型对用户查询和文档的语义理解不足，尤其在处理复杂搜索意图时。

Method: 本研究提出了一个新颖的框架，首次将生成模型应用于工业网络搜索中的实时QDTS。该方法整合了：大模型蒸馏、监督微调、直接偏好优化和前瞻解码，旨在将一个仅有0.1B参数的轻量级模型转化为领域专业的QDTS专家。

Result: 在多项行业相关指标上，该模型超越了生产基线，并取得了新的最先进（SOTA）成果。此外，它展示了卓越的部署效率，仅需334块NVIDIA L20 GPU即可处理每秒约50,000次查询，平均查询延迟为55毫秒。

Conclusion: 本研究成功地将生成模型应用于工业级实时查询驱动文本摘要，通过创新的训练和解码策略，不仅解决了传统方法的局限性，实现了性能上的突破，还展现了极高的部署效率，为大规模网络搜索提供了可行的先进解决方案。

Abstract: In the dynamic landscape of large-scale web search, Query-Driven Text
Summarization (QDTS) aims to generate concise and informative summaries from
textual documents based on a given query, which is essential for improving user
engagement and facilitating rapid decision-making. Traditional extractive
summarization models, based primarily on ranking candidate summary segments,
have been the dominant approach in industrial applications. However, these
approaches suffer from two key limitations: 1) The multi-stage pipeline often
introduces cumulative information loss and architectural bottlenecks due to its
weakest component; 2) Traditional models lack sufficient semantic understanding
of both user queries and documents, particularly when dealing with complex
search intents. In this study, we propose a novel framework to pioneer the
application of generative models to address real-time QDTS in industrial web
search. Our approach integrates large model distillation, supervised
fine-tuning, direct preference optimization, and lookahead decoding to
transform a lightweight model with only 0.1B parameters into a
domain-specialized QDTS expert. Evaluated on multiple industry-relevant
metrics, our model outperforms the production baseline and achieves a new state
of the art. Furthermore, it demonstrates excellent deployment efficiency,
requiring only 334 NVIDIA L20 GPUs to handle \textasciitilde50,000 queries per
second under 55~ms average latency per query.

</details>


### [146] [KCS: Diversify Multi-hop Question Generation with Knowledge Composition Sampling](https://arxiv.org/abs/2508.20567)
*Yangfan Wang,Jie Liu,Chen Tang,Lian Yan,Jingchi Jiang*

Main category: cs.CL

TL;DR: 本文提出知识组合采样（KCS）框架，通过采样多样化的知识组合来扩展多跳问答（QA）问题的多样性，以解决数据稀疏性问题并提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 多跳问答面临数据稀疏性挑战，易导致语言模型学习虚假模式。现有方法侧重生成简单问题，忽视了相关文档句子等关键知识的整合。

Method: KCS框架将知识组合选择建模为句子级别的条件预测任务，利用概率对比损失来预测下一个最相关的知识片段。推理时采用随机解码策略平衡准确性和多样性。

Result: 与现有基线相比，KCS将知识组合选择的整体准确率提高了3.9%。将其应用于数据增强，在HotpotQA和2WikiMultihopQA数据集上均取得了性能提升。

Conclusion: KCS是一个创新的框架，通过多样化知识组合采样有效解决了多跳问答中的数据稀疏性问题，显著提高了知识选择的准确性，并能作为数据增强手段提升模型在多跳问答任务上的表现。

Abstract: Multi-hop question answering faces substantial challenges due to data
sparsity, which increases the likelihood of language models learning spurious
patterns. To address this issue, prior research has focused on diversifying
question generation through content planning and varied expression. However,
these approaches often emphasize generating simple questions and neglect the
integration of essential knowledge, such as relevant sentences within
documents. This paper introduces the Knowledge Composition Sampling (KCS), an
innovative framework designed to expand the diversity of generated multi-hop
questions by sampling varied knowledge compositions within a given context. KCS
models the knowledge composition selection as a sentence-level conditional
prediction task and utilizes a probabilistic contrastive loss to predict the
next most relevant piece of knowledge. During inference, we employ a stochastic
decoding strategy to effectively balance accuracy and diversity. Compared to
competitive baselines, our KCS improves the overall accuracy of knowledge
composition selection by 3.9%, and its application for data augmentation yields
improvements on HotpotQA and 2WikiMultihopQA datasets. Our code is available
at: https://github.com/yangfanww/kcs.

</details>


### [147] [A Graph Talks, But Who's Listening? Rethinking Evaluations for Graph-Language Models](https://arxiv.org/abs/2508.20583)
*Soham Petkar,Hari Aakash K,Anirudh Vempati,Akshit Sinha,Ponnurangam Kumarauguru,Chirag Agarwal*

Main category: cs.CL

TL;DR: 现有图语言模型（GLM）基准无法充分评估多模态推理能力，因为单模态信息即可取得良好性能。本文提出了CLEGR基准来解决此问题，并发现当前GLM在结构推理方面存在显著局限性，甚至质疑了将图结构整合到LLM中的架构必要性。


<details>
  <summary>Details</summary>
Motivation: 图语言模型（GLM）旨在结合图神经网络（GNN）的结构推理能力和大型语言模型（LLM）的语义理解能力。然而，现有GLM评估基准（主要是节点级分类数据集）不足以评估真正的多模态推理，因为单模态信息已足以取得高分，表明它们并未真正强制图-语言整合。

Method: 本文首先分析了现有GLM基准的不足之处，证明其单模态信息即可取得高分。为解决这一评估空白，研究者引入了CLEGR（组合语言-图推理）基准，该基准采用合成图生成管道，并配以需要联合结构和文本语义推理的问题，具有不同复杂性级别。随后，对代表性GLM架构和软提示LLM基线进行了全面评估。

Result: 分析显示，在现有基准上，仅使用单模态信息即可获得强劲性能。在CLEGR基准上，软提示LLM基线表现与包含完整GNN骨干的GLM相当。此外，GLM在需要结构推理的任务中表现出显著的性能下降。

Conclusion: 当前GLM在图推理能力方面存在局限性，并且将图结构整合到LLM中的架构必要性受到质疑。这些发现为推动社区向涉及图结构和语言的显式多模态推理发展奠定了基础。

Abstract: Developments in Graph-Language Models (GLMs) aim to integrate the structural
reasoning capabilities of Graph Neural Networks (GNNs) with the semantic
understanding of Large Language Models (LLMs). However, we demonstrate that
current evaluation benchmarks for GLMs, which are primarily repurposed
node-level classification datasets, are insufficient to assess multimodal
reasoning. Our analysis reveals that strong performance on these benchmarks is
achievable using unimodal information alone, suggesting that they do not
necessitate graph-language integration. To address this evaluation gap, we
introduce the CLEGR(Compositional Language-Graph Reasoning) benchmark, designed
to evaluate multimodal reasoning at various complexity levels. Our benchmark
employs a synthetic graph generation pipeline paired with questions that
require joint reasoning over structure and textual semantics. We perform a
thorough evaluation of representative GLM architectures and find that
soft-prompted LLM baselines perform on par with GLMs that incorporate a full
GNN backbone. This result calls into question the architectural necessity of
incorporating graph structure into LLMs. We further show that GLMs exhibit
significant performance degradation in tasks that require structural reasoning.
These findings highlight limitations in the graph reasoning capabilities of
current GLMs and provide a foundation for advancing the community toward
explicit multimodal reasoning involving graph structure and language.

</details>


### [148] [Generative Annotation for ASR Named Entity Correction](https://arxiv.org/abs/2508.20700)
*Yuanchang Luo,Daimeng Wei,Shaojun Li,Hengchao Shang,Jiaxin Guo,Zongyao Li,Zhanglin Wu,Xiaoyu Chen,Zhiqiang Rao,Jinlong Yang,Hao Yang*

Main category: cs.CL

TL;DR: 本文提出一种新颖的命名实体校正（NEC）方法，利用语音特征检索候选实体，并设计生成式方法来纠正ASR转录中的实体错误，尤其在转录词与真实实体形式差异较大时表现出色，显著提高了实体准确性。


<details>
  <summary>Details</summary>
Motivation: 端到端自动语音识别（ASR）系统在转录领域特定命名实体时经常失败，导致下游任务出现严重问题。现有快速轻量级NEC模型主要依赖语音层面编辑距离算法，但在转录词与真实实体形式差异显著时，这些方法往往无法定位错误转录词，从而限制了其应用。

Method: 该方法利用语音特征来检索候选实体。结合语音特征和候选实体，创新性地设计了一种生成式方法来标注ASR转录中的实体错误，并用正确的实体替换文本。这种方法在词形差异较大的场景中尤其有效。

Result: 在开源和自建测试集上对该方法进行了测试。结果表明，所提出的NEC方法能够显著提高实体准确性。研究者还将开源自建测试集和训练数据。

Conclusion: 所提出的基于语音特征检索候选实体和生成式校正的NEC方法，有效解决了ASR转录中命名实体错误问题，尤其在转录词与真实实体形式差异较大时仍能实现显著的准确性提升。

Abstract: End-to-end automatic speech recognition systems often fail to transcribe
domain-specific named entities, causing catastrophic failures in downstream
tasks. Numerous fast and lightweight named entity correction (NEC) models have
been proposed in recent years. These models, mainly leveraging phonetic-level
edit distance algorithms, have shown impressive performances. However, when the
forms of the wrongly-transcribed words(s) and the ground-truth entity are
significantly different, these methods often fail to locate the wrongly
transcribed words in hypothesis, thus limiting their usage. We propose a novel
NEC method that utilizes speech sound features to retrieve candidate entities.
With speech sound features and candidate entities, we inovatively design a
generative method to annotate entity errors in ASR transcripts and replace the
text with correct entities. This method is effective in scenarios of word form
difference. We test our method using open-source and self-constructed test
sets. The results demonstrate that our NEC method can bring significant
improvement to entity accuracy. We will open source our self-constructed test
set and training data.

</details>


### [149] [Multi-Lingual Implicit Discourse Relation Recognition with Multi-Label Hierarchical Learning](https://arxiv.org/abs/2508.20712)
*Nelson Filipe Costa,Leila Kosseim*

Main category: cs.CL

TL;DR: 本文提出了首个多语言、多标签隐式语篇关系识别（IDRR）模型HArch，该模型利用语篇语义间的层级依赖性，并在DiscoGeM 2.0上进行评估，在多语言环境下表现最佳，且优于大型语言模型，在DiscoGeM 1.0上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一个能够处理多语言和多标签分类的隐式语篇关系识别模型，并利用语篇语义之间的层级依赖性来提高性能。

Method: 本文引入了HArch模型，该模型利用语篇语义间的层级依赖性，预测PDTB 3.0框架中所有三个语义层级的概率分布。模型在DiscoGeM 2.0语料库上进行评估，并比较了RoBERTa和XLM-RoBERTa等预训练编码器主干。此外，还将微调模型与使用少量提示的GPT-4o和Llama-4-Maverick进行了比较。

Result: RoBERTa-HArch在英语中表现最佳，而XLM-RoBERTa-HArch在多语言设置中表现最佳。微调模型在所有语言配置下始终优于GPT-4o和Llama-4-Maverick等大型语言模型。HArch模型在DiscoGeM 1.0语料库上取得了最先进的（SOTA）结果。

Conclusion: 任务特定的微调在隐式语篇关系识别（IDRR）方面优于大型语言模型的提示方法。所提出的层级方法是有效的，并在多语言、多标签IDRR任务中取得了显著的性能提升。

Abstract: This paper introduces the first multi-lingual and multi-label classification
model for implicit discourse relation recognition (IDRR). Our model, HArch, is
evaluated on the recently released DiscoGeM 2.0 corpus and leverages
hierarchical dependencies between discourse senses to predict probability
distributions across all three sense levels in the PDTB 3.0 framework. We
compare several pre-trained encoder backbones and find that RoBERTa-HArch
achieves the best performance in English, while XLM-RoBERTa-HArch performs best
in the multi-lingual setting. In addition, we compare our fine-tuned models
against GPT-4o and Llama-4-Maverick using few-shot prompting across all
language configurations. Our results show that our fine-tuned models
consistently outperform these LLMs, highlighting the advantages of
task-specific fine-tuning over prompting in IDRR. Finally, we report SOTA
results on the DiscoGeM 1.0 corpus, further validating the effectiveness of our
hierarchical approach.

</details>


### [150] [Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models](https://arxiv.org/abs/2508.20718)
*Ruiyi Yan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本研究关注大型语言模型（LLM）驱动的隐写术和水印技术中，由于Alice和Bob之间分词不一致（TI）导致鲁棒性下降的问题，并提出了两种定制化解决方案以消除TI，显著提升了两种技术的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型提升了文本生成能力，一方面改善了文本隐写术的质量，另一方面也凸显了水印技术作为防止恶意滥用的重要性。然而，分词不一致（TI）是隐写术和水印技术中的一个关键问题，会损害其鲁棒性。

Method: 研究首先揭示了导致TI的问题令牌具有“不频繁”和“暂时性”两个关键特征。基于这些发现，提出了两种定制化解决方案：针对隐写术的“逐步验证方法”和针对水印技术的“事后回滚方法”，以消除TI。

Result: 实验结果表明：(1) 对于隐写术，直接解决TI问题比传统消歧方法能更好地提高文本的流畅性、不可感知性和抗隐写分析能力；(2) 对于水印技术，解决TI问题能增强水印的可检测性和抗攻击鲁棒性。

Conclusion: 分词不一致（TI）是基于LLM的隐写术和水印技术中一个关键的、影响鲁棒性的问题。通过识别TI令牌的特性并提出针对性的逐步验证和事后回滚方法，可以有效消除TI，从而显著提升隐写术的性能和水印的可检测性及抗攻击能力。

Abstract: Large language models have significantly enhanced the capacities and
efficiency of text generation. On the one hand, they have improved the quality
of text-based steganography. On the other hand, they have also underscored the
importance of watermarking as a safeguard against malicious misuse. In this
study, we focus on tokenization inconsistency (TI) between Alice and Bob in
steganography and watermarking, where TI can undermine robustness. Our
investigation reveals that the problematic tokens responsible for TI exhibit
two key characteristics: infrequency and temporariness. Based on these
findings, we propose two tailored solutions for TI elimination: a stepwise
verification method for steganography and a post-hoc rollback method for
watermarking. Experiments show that (1) compared to traditional disambiguation
methods in steganography, directly addressing TI leads to improvements in
fluency, imperceptibility, and anti-steganalysis capacity; (2) for
watermarking, addressing TI enhances detectability and robustness against
attacks.

</details>


### [151] [rStar2-Agent: Agentic Reasoning Technical Report](https://arxiv.org/abs/2508.20722)
*Ning Shang,Yifei Liu,Yi Zhu,Li Lyna Zhang,Weijiang Xu,Xinyu Guan,Buze Zhang,Bingcheng Dong,Xudong Zhou,Bowen Zhang,Ying Xin,Ziming Miao,Scarlett Li,Fan Yang,Mao Yang*

Main category: cs.CL

TL;DR: rStar2-Agent是一个14B的数学推理模型，通过智能体强化学习（RL）训练，实现了前沿性能。它展示了先进的认知行为，如谨慎使用编程工具和反思代码执行反馈，以自主探索、验证和完善复杂问题解决步骤，并在有限资源下高效训练。


<details>
  <summary>Details</summary>
Motivation: 目前的CoT（思维链）模型在复杂问题解决中缺乏先进的认知行为，例如在使用编程工具前仔细思考和对代码执行反馈进行反思。研究旨在通过可扩展的智能体强化学习，使模型具备这些能力。

Method: 该研究引入了rStar2-Agent，一个14B的数学推理模型，采用智能体强化学习进行训练。核心方法包括三项创新：(i) 具有可靠Python代码环境的高效RL基础设施，支持高吞吐量执行并降低推出成本，仅用64个MI300X GPU进行训练；(ii) GRPO-RoC，一种带有“纠错重采样”（Resample-on-Correct）推出策略的智能体RL算法，以解决编码工具固有的环境噪声；(iii) 一种高效的智能体训练方案，从非推理SFT开始，逐步通过多RL阶段，以最小的计算成本获得先进的认知能力。

Result: rStar2-Agent在短短一周内，通过510个RL步骤，将一个预训练的14B模型提升到最先进水平。在AIME24上取得80.6%的平均pass@1分数，在AIME25上取得69.8%的平均pass@1分数，超越了DeepSeek-R1 (671B) 且响应显著更短。除了数学，rStar2-Agent-14B还在对齐、科学推理和智能体工具使用任务上表现出强大的泛化能力。模型展示了先进的认知行为，如在使用Python编程工具前仔细思考，并反思代码执行反馈以自主探索、验证和完善中间步骤。

Conclusion: rStar2-Agent通过创新的智能体强化学习方法，显著提升了14B模型在数学推理方面的能力，实现了最先进的性能，并展现出先进的认知行为和强大的泛化能力，同时在有限的计算资源下实现了高效训练。

Abstract: We introduce rStar2-Agent, a 14B math reasoning model trained with agentic
reinforcement learning to achieve frontier-level performance. Beyond current
long CoT, the model demonstrates advanced cognitive behaviors, such as thinking
carefully before using Python coding tools and reflecting on code execution
feedback to autonomously explore, verify, and refine intermediate steps in
complex problem-solving. This capability is enabled through three key
innovations that makes agentic RL effective at scale: (i) an efficient RL
infrastructure with a reliable Python code environment that supports
high-throughput execution and mitigates the high rollout costs, enabling
training on limited GPU resources (64 MI300X GPUs); (ii) GRPO-RoC, an agentic
RL algorithm with a Resample-on-Correct rollout strategy that addresses the
inherent environment noises from coding tools, allowing the model to reason
more effectively in a code environment; (iii) An efficient agent training
recipe that starts with non-reasoning SFT and progresses through multi-RL
stages, yielding advanced cognitive abilities with minimal compute cost. To
this end, rStar2-Agent boosts a pre-trained 14B model to state of the art in
only 510 RL steps within one week, achieving average pass@1 scores of 80.6% on
AIME24 and 69.8% on AIME25, surpassing DeepSeek-R1 (671B) with significantly
shorter responses. Beyond mathematics, rStar2-Agent-14B also demonstrates
strong generalization to alignment, scientific reasoning, and agentic tool-use
tasks. Code and training recipes are available at
https://github.com/microsoft/rStar.

</details>


### [152] [Leveraging Semantic Triples for Private Document Generation with Local Differential Privacy Guarantees](https://arxiv.org/abs/2508.20736)
*Stephen Meisenbacher,Maulik Chevli,Florian Matthes*

Main category: cs.CL

TL;DR: 本文提出DP-ST方法，利用语义三元组在局部差分隐私下进行邻域感知的私有文档生成，结合大语言模型后处理，能在较低的隐私预算($\varepsilon$)下实现连贯的文本生成，平衡隐私与实用性。


<details>
  <summary>Details</summary>
Motivation: 在自然语言处理中，局部差分隐私（Local DP）对文本转换的要求极高，通常需要在非常高的隐私预算($\varepsilon$)值下才能获得合理的结果，难以在隐私和实用性之间取得平衡。

Method: 本文引入了DP-ST方法，该方法利用语义三元组实现局部差分隐私下的邻域感知私有文档生成。它采用分而治之的范式，并将隐私保障限制在私有化邻域内。此外，该方法还结合了大语言模型（LLM）进行后处理以增强文本连贯性。

Result: 研究表明，DP-ST方法在限制DP概念到私有化邻域时表现出有效性。当与大语言模型后处理结合时，即使在较低的隐私预算($\varepsilon$)下，该方法也能生成连贯的文本，成功平衡了隐私和实用性。

Conclusion: 在合理的隐私预算($\varepsilon$)水平下，文本连贯性对于实现平衡的私有化输出至关重要。本文提出的分而治之范式，结合语义三元组和邻域感知方法，是解决局部差分隐私文本生成挑战的有效途径。

Abstract: Many works at the intersection of Differential Privacy (DP) in Natural
Language Processing aim to protect privacy by transforming texts under DP
guarantees. This can be performed in a variety of ways, from word perturbations
to full document rewriting, and most often under local DP. Here, an input text
must be made indistinguishable from any other potential text, within some bound
governed by the privacy parameter $\varepsilon$. Such a guarantee is quite
demanding, and recent works show that privatizing texts under local DP can only
be done reasonably under very high $\varepsilon$ values. Addressing this
challenge, we introduce DP-ST, which leverages semantic triples for
neighborhood-aware private document generation under local DP guarantees.
Through the evaluation of our method, we demonstrate the effectiveness of the
divide-and-conquer paradigm, particularly when limiting the DP notion (and
privacy guarantees) to that of a privatization neighborhood. When combined with
LLM post-processing, our method allows for coherent text generation even at
lower $\varepsilon$ values, while still balancing privacy and utility. These
findings highlight the importance of coherence in achieving balanced
privatization outputs at reasonable $\varepsilon$ levels.

</details>


### [153] [Specializing General-purpose LLM Embeddings for Implicit Hate Speech Detection across Datasets](https://arxiv.org/abs/2508.20750)
*Vassiliy Cheremetiev,Quang Long Ho Ngo,Chau Ying Kot,Alina Elena Baia,Andrea Cavallaro*

Main category: cs.CL

TL;DR: 通过仅对基于大型语言模型的通用嵌入模型（如Stella、Jasper、NV-Embed和E5）进行微调，本文在隐性仇恨言论（IHS）检测任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 隐性仇恨言论（IHS）因其间接的表达方式（如微妙的暗示、讽刺或编码术语）而难以检测，且不包含明确的贬损词语。传统的任务特定管道需要结合外部知识或额外信息（如上下文、情感和情绪数据），这增加了复杂性。

Method: 研究方法是仅通过微调基于大型语言模型（LLM）的最新通用嵌入模型（包括Stella、Jasper、NV-Embed和E5），来检测隐性仇恨言论。

Result: 实验结果显示，与现有技术相比，在F1-macro分数方面，数据集内评估性能提升高达1.10个百分点，跨数据集评估性能提升高达20.35个百分点，达到了最先进的水平。

Conclusion: 仅通过微调通用型LLM嵌入模型，就能有效且大幅提升隐性仇恨言论的检测能力，超越了之前的最佳性能。

Abstract: Implicit hate speech (IHS) is indirect language that conveys prejudice or
hatred through subtle cues, sarcasm or coded terminology. IHS is challenging to
detect as it does not include explicit derogatory or inflammatory words. To
address this challenge, task-specific pipelines can be complemented with
external knowledge or additional information such as context, emotions and
sentiment data. In this paper, we show that, by solely fine-tuning recent
general-purpose embedding models based on large language models (LLMs), such as
Stella, Jasper, NV-Embed and E5, we achieve state-of-the-art performance.
Experiments on multiple IHS datasets show up to 1.10 percentage points
improvements for in-dataset, and up to 20.35 percentage points improvements in
cross-dataset evaluation, in terms of F1-macro score.

</details>


### [154] [GUARD: Glocal Uncertainty-Aware Robust Decoding for Effective and Efficient Open-Ended Text Generation](https://arxiv.org/abs/2508.20757)
*Yuanhao Ding,Esteban Garces Arias,Meimingwei Li,Julian Rodemann,Matthias Aßenmacher,Danlu Chen,Gaojuan Fan,Christian Heumann,Chongsheng Zhang*

Main category: cs.CL

TL;DR: GUARD是一种自适应解码方法，通过结合全局和局部不确定性信号，有效平衡大型语言模型（LLM）开放式文本生成中的连贯性和多样性，同时显著提高生成速度。


<details>
  <summary>Details</summary>
Motivation: 开放式文本生成面临在连贯性和多样性之间取得平衡的挑战。现有的对比搜索解码策略虽然试图解决这一问题，但常受限于超参数依赖性和高计算成本。

Method: 该研究引入了GUARD，一种自适应解码方法，采用“Glocal”（全局+局部）不确定性驱动框架。它结合了全局熵估计和局部熵偏差，以整合长期和短期不确定性信号。提出的全局熵公式能有效缓解不确定性中的突变，并提供无偏性和一致性的理论保证。为降低计算开销，GUARD还纳入了一个基于token计数的简单而有效的惩罚机制。

Result: 实验结果表明，GUARD在文本多样性和连贯性之间取得了良好平衡，并显著提高了生成速度。在文本质量的不同维度上，人类和LLM评估者都验证了其卓越的性能。

Conclusion: GUARD通过其新颖的“Glocal”不确定性驱动框架，成功解决了LLM开放式文本生成中连贯性与多样性的平衡问题，同时克服了现有方法的计算效率和超参数依赖性限制，提供了一种高效且高质量的自适应解码方案。

Abstract: Open-ended text generation faces a critical challenge: balancing coherence
with diversity in LLM outputs. While contrastive search-based decoding
strategies have emerged to address this trade-off, their practical utility is
often limited by hyperparameter dependence and high computational costs. We
introduce GUARD, a self-adaptive decoding method that effectively balances
these competing objectives through a novel "Glocal" uncertainty-driven
framework. GUARD combines global entropy estimates with local entropy
deviations to integrate both long-term and short-term uncertainty signals. We
demonstrate that our proposed global entropy formulation effectively mitigates
abrupt variations in uncertainty, such as sudden overconfidence or high entropy
spikes, and provides theoretical guarantees of unbiasedness and consistency. To
reduce computational overhead, we incorporate a simple yet effective
token-count-based penalty into GUARD. Experimental results demonstrate that
GUARD achieves a good balance between text diversity and coherence, while
exhibiting substantial improvements in generation speed. In a more nuanced
comparison study across different dimensions of text quality, both human and
LLM evaluators validated its remarkable performance. Our code is available at
https://github.com/YecanLee/GUARD.

</details>


### [155] [Feel the Difference? A Comparative Analysis of Emotional Arcs in Real and LLM-Generated CBT Sessions](https://arxiv.org/abs/2508.20764)
*Xiaoyi Wang,Jiwei Zhang,Guangtao Zhang,Honglei Guo*

Main category: cs.CL

TL;DR: 本研究首次比较了真实和LLM生成的CBT对话中的情感弧线，发现合成对话在情感变异性、情感丰富度和真实反应模式方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）生成的合成治疗对话在心理健康NLP中被广泛使用，但其是否能捕捉真实治疗中细微的情感动态尚不清楚。

Method: 研究采用了“话语情感动态”框架，分析了真实（来自公开视频）和LLM生成（来自CACTUS数据集）的认知行为疗法（CBT）对话在效价、唤醒和主导性维度上的情感轨迹，涵盖了整个对话和个体说话者角色（咨询师和来访者）。

Result: 结果显示，合成对话虽然流畅且结构连贯，但在关键情感属性上与真实对话存在差异：真实对话表现出更高的情感变异性、更多情感丰富的语言以及更真实的反应和调节模式。真实与合成说话者之间的情感弧线相似度较低，尤其是在来访者角色方面。研究还引入了RealCBT数据集。

Conclusion: 当前LLM生成的治疗数据在情感保真度方面存在局限性，这突显了情感保真度在心理健康应用中的重要性。未来的研究应关注提高合成对话的情感真实性。

Abstract: Synthetic therapy dialogues generated by large language models (LLMs) are
increasingly used in mental health NLP to simulate counseling scenarios, train
models, and supplement limited real-world data. However, it remains unclear
whether these synthetic conversations capture the nuanced emotional dynamics of
real therapy. In this work, we conduct the first comparative analysis of
emotional arcs between real and LLM-generated Cognitive Behavioral Therapy
dialogues. We adapt the Utterance Emotion Dynamics framework to analyze
fine-grained affective trajectories across valence, arousal, and dominance
dimensions. Our analysis spans both full dialogues and individual speaker roles
(counselor and client), using real sessions transcribed from public videos and
synthetic dialogues from the CACTUS dataset. We find that while synthetic
dialogues are fluent and structurally coherent, they diverge from real
conversations in key emotional properties: real sessions exhibit greater
emotional variability,more emotion-laden language, and more authentic patterns
of reactivity and regulation. Moreover, emotional arc similarity between real
and synthetic speakers is low, especially for clients. These findings
underscore the limitations of current LLM-generated therapy data and highlight
the importance of emotional fidelity in mental health applications. We
introduce RealCBT, a curated dataset of real CBT sessions, to support future
research in this space.

</details>


### [156] [Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection](https://arxiv.org/abs/2508.20766)
*Harethah Abu Shairah,Hasan Abed Al Kader Hammoud,George Turkiyyah,Bernard Ghanem*

Main category: cs.CL

TL;DR: 本文提出了一种名为ROSI（Rank-One Safety Injection）的白盒方法，通过对LLM的权重进行简单的秩一修改，永久性地将模型激活引导至拒绝有害请求的安全子空间，从而显著提高模型的安全拒绝率，同时保持其效用。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，LLM的安全机制可能通过移除模型内部的特定表征方向而被绕过。作者旨在提出一种相反的方法，即通过主动增强模型的安全对齐能力来解决这一问题，使其更能抵抗有害请求。

Method: ROSI是一种白盒方法，通过对LLM所有残差流写入矩阵进行简单的、无需微调的秩一权重修改来工作。所需的安全方向可通过一小部分有害和无害指令对计算得出。这种修改旨在放大模型的安全对齐，将激活永久性地引导至介导拒绝的安全子空间。

Result: ROSI方法持续提高了模型的安全拒绝率（通过Llama Guard 3评估），同时在MMLU、HellaSwag和Arc等标准基准测试中保持了模型的实用性。此外，ROSI还能通过放大其自身的潜在安全方向来重新对齐“未审查”模型，证明了其作为有效“最后一英里”安全程序的实用性。

Conclusion: 研究结果表明，有针对性的、可解释的权重引导是一种廉价且强大的机制，可以提高LLM的安全性，是对更耗费资源的微调范式的有效补充。

Abstract: Safety alignment in Large Language Models (LLMs) often involves mediating
internal representations to refuse harmful requests. Recent research has
demonstrated that these safety mechanisms can be bypassed by ablating or
removing specific representational directions within the model. In this paper,
we propose the opposite approach: Rank-One Safety Injection (ROSI), a white-box
method that amplifies a model's safety alignment by permanently steering its
activations toward the refusal-mediating subspace. ROSI operates as a simple,
fine-tuning-free rank-one weight modification applied to all residual stream
write matrices. The required safety direction can be computed from a small set
of harmful and harmless instruction pairs. We show that ROSI consistently
increases safety refusal rates - as evaluated by Llama Guard 3 - while
preserving the utility of the model on standard benchmarks such as MMLU,
HellaSwag, and Arc. Furthermore, we show that ROSI can also re-align
'uncensored' models by amplifying their own latent safety directions,
demonstrating its utility as an effective last-mile safety procedure. Our
results suggest that targeted, interpretable weight steering is a cheap and
potent mechanism to improve LLM safety, complementing more resource-intensive
fine-tuning paradigms.

</details>


### [157] [Signs of Struggle: Spotting Cognitive Distortions across Language and Register](https://arxiv.org/abs/2508.20771)
*Abhishek Kuber,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 该研究首次深入探讨了认知扭曲检测的跨语言和跨语域泛化能力，利用荷兰青少年论坛数据，并发现域适应方法最有前景。


<details>
  <summary>Details</summary>
Motivation: 青年心理健康问题日益增加，促使人们对自动化检测数字文本中心理困扰早期迹象的方法产生兴趣。识别认知扭曲（非理性思维模式）对于早期、低成本干预至关重要。

Method: 本研究对认知扭曲检测的跨语言和跨语域泛化能力进行了首次深入研究。通过分析荷兰青少年撰写的论坛帖子数据，评估了模型在不同语言和写作风格下的表现，并探讨了域适应方法。

Result: 研究发现，语言和写作风格的变化会显著影响模型性能。然而，域适应方法在此类任务中显示出最大的潜力。

Conclusion: 尽管语言和写作风格的改变对模型性能有显著影响，但域适应是提升认知扭曲检测模型在跨语言和跨语域情境下泛化能力的关键方向。

Abstract: Rising mental health issues among youth have increased interest in automated
approaches for detecting early signs of psychological distress in digital text.
One key focus is the identification of cognitive distortions, irrational
thought patterns that have a role in aggravating mental distress. Early
detection of these distortions may enable timely, low-cost interventions. While
prior work has focused on English clinical data, we present the first in-depth
study of cross-lingual and cross-register generalization of cognitive
distortion detection, analyzing forum posts written by Dutch adolescents. Our
findings show that while changes in language and writing style can
significantly affect model performance, domain adaptation methods show the most
promise.

</details>


### [158] [Exploring Machine Learning and Language Models for Multimodal Depression Detection](https://arxiv.org/abs/2508.20805)
*Javier Si Zhao Hong,Timothy Zoe Delaya,Sherwyn Chan Yin Kit,Pai Chet Ng,Xiaoxiao Miao*

Main category: cs.CL

TL;DR: 本论文介绍了多模态人格感知抑郁症检测挑战赛的方法，比较了XGBoost、Transformer和LLM在音频、视频、文本特征上的性能。


<details>
  <summary>Details</summary>
Motivation: 参与首届多模态人格感知抑郁症检测挑战赛，旨在探索和比较不同机器学习和深度学习模型在多模态抑郁症检测中的表现。

Method: 采用XGBoost、基于Transformer的架构和大型语言模型（LLMs），在音频、视频和文本特征上进行多模态抑郁症检测，并对它们的性能进行探索和比较。

Result: 研究结果突出了各类模型在捕捉跨模态抑郁症相关信号方面的优势和局限性。

Conclusion: 为心理健康预测中有效的多模态表示策略提供了深入见解。

Abstract: This paper presents our approach to the first Multimodal Personality-Aware
Depression Detection Challenge, focusing on multimodal depression detection
using machine learning and deep learning models. We explore and compare the
performance of XGBoost, transformer-based architectures, and large language
models (LLMs) on audio, video, and text features. Our results highlight the
strengths and limitations of each type of model in capturing depression-related
signals across modalities, offering insights into effective multimodal
representation strategies for mental health prediction.

</details>


### [159] [GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction](https://arxiv.org/abs/2508.20828)
*Jie Zhao,Wanting Ning,Yuxiao Fei,Yubo Feng,Lishuang Li*

Main category: cs.CL

TL;DR: 本文提出GDLLM，一种基于LLM的全局距离感知建模方法，通过图注意力网络和软推理机制，有效解决了事件时间关系提取中长距离依赖和少数类关系识别的挑战，并取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有小型语言模型（SLMs）在处理不平衡分类数据中的少数类关系时，受限于其预训练知识。而大型语言模型（LLMs）则依赖手动设计的提示词，可能引入噪声，干扰模型对事件间长距离依赖的判断。

Method: 本文提出了GDLLM（Global Distance-aware modeling approach based on LLMs）。首先，利用图注意力网络（GAT）构建距离感知图结构，以帮助LLMs捕捉长距离依赖特征。其次，设计了一种基于软推理的时间特征学习范式，增强对短距离接近关系识别的能力，将LLMs生成的概率信息补充到多头注意力机制中。

Result: 实验结果表明，该方法在两个公开数据集（TB-Dense和MATRES）上取得了最先进（SOTA）的性能。GDLLM显著提高了少数关系类的性能，并提升了整体学习能力，有效捕捉了全局特征。

Conclusion: GDLLM通过结合距离感知图结构和时间特征学习范式，成功解决了ETRE中SLMs处理少数类问题和LLMs处理长距离依赖的挑战，显著提升了模型性能，尤其是在处理少数类关系方面。

Abstract: In Natural Language Processing(NLP), Event Temporal Relation Extraction
(ETRE) is to recognize the temporal relations of two events. Prior studies have
noted the importance of language models for ETRE. However, the restricted
pre-trained knowledge of Small Language Models(SLMs) limits their capability to
handle minority class relations in imbalanced classification datasets. For
Large Language Models(LLMs), researchers adopt manually designed prompts or
instructions, which may introduce extra noise, leading to interference with the
model's judgment of the long-distance dependencies between events. To address
these issues, we propose GDLLM, a Global Distance-aware modeling approach based
on LLMs. We first present a distance-aware graph structure utilizing Graph
Attention Network(GAT) to assist the LLMs in capturing long-distance dependency
features. Additionally, we design a temporal feature learning paradigm based on
soft inference to augment the identification of relations with a short-distance
proximity band, which supplements the probabilistic information generated by
LLMs into the multi-head attention mechanism. Since the global feature can be
captured effectively, our framework substantially enhances the performance of
minority relation classes and improves the overall learning ability.
Experiments on two publicly available datasets, TB-Dense and MATRES,
demonstrate that our approach achieves state-of-the-art (SOTA) performance.

</details>


### [160] [MSRS: Evaluating Multi-Source Retrieval-Augmented Generation](https://arxiv.org/abs/2508.20867)
*Rohan Phanse,Yijie Zhou,Kejian Shi,Wencai Zhang,Yixin Liu,Yilun Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: 该研究提出了一个构建多源检索与综合（MSRS）评估基准的框架，并创建了两个新基准（MSRS-Story和MSRS-Meet），用于挑战RAG系统在长篇回答中整合多源信息的能力。实验表明，生成质量高度依赖检索效果，且推理模型在多源综合任务中表现优于标准LLM。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强系统（RAG）的评估主要集中在单源或短形式/事实性回答上，但许多实际应用需要整合和总结分散在多个来源的信息，并生成长篇响应，这需要RAG系统具备更复杂的检索和生成能力。

Method: 研究提出了一个可扩展的框架，用于构建评估RAG系统整合多源信息并生成长篇响应能力的基准。基于此框架，构建了两个新基准：MSRS-Story（叙事综合）和MSRS-Meet（会议总结）。通过结合稀疏和密集检索器以及前沿大型语言模型（LLMs），对多种RAG管道进行了广泛实验，并比较了标准LLMs和推理模型在综合步骤中的表现。

Result: 实验发现，生成质量高度依赖于检索效率，且效率因任务而异。即使在理想的检索（oracle retrieval）设置下，多源综合任务仍然具有挑战性。然而，推理模型在这种独特的综合步骤中显著优于标准LLMs。

Conclusion: 多源信息整合和长篇响应生成对RAG系统构成重大挑战，尤其是在信息综合阶段。新的MSRS基准揭示了现有RAG系统的局限性。尽管如此，推理模型在处理复杂的综合任务方面展现出优越性，为未来研究提供了方向。

Abstract: Retrieval-augmented systems are typically evaluated in settings where
information required to answer the query can be found within a single source or
the answer is short-form or factoid-based. However, many real-world
applications demand the ability to integrate and summarize information
scattered across multiple sources, where no single source is sufficient to
respond to the user's question. In such settings, the retrieval component of a
RAG pipeline must recognize a variety of relevance signals, and the generation
component must connect and synthesize information across multiple sources. We
present a scalable framework for constructing evaluation benchmarks that
challenge RAG systems to integrate information across distinct sources and
generate long-form responses. Using our framework, we build two new benchmarks
on Multi-Source Retrieval and Synthesis: MSRS-Story and MSRS-Meet, representing
narrative synthesis and summarization tasks, respectively, that require
retrieval from large collections. Our extensive experiments with various RAG
pipelines -- including sparse and dense retrievers combined with frontier LLMs
-- reveal that generation quality is highly dependent on retrieval
effectiveness, which varies greatly by task. While multi-source synthesis
proves challenging even in an oracle retrieval setting, we find that reasoning
models significantly outperform standard LLMs at this distinct step.

</details>


### [161] [ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue Agents](https://arxiv.org/abs/2508.20973)
*Tianjian Liu,Fanqi Wan,Jiajian Guo,Xiaojun Quan*

Main category: cs.CL

TL;DR: 本文提出了ProactiveEval，一个统一的框架，用于评估大型语言模型（LLMs）的主动对话能力。该框架将主动对话分解为目标规划和对话引导，并支持自动生成评估数据。实验发现DeepSeek-R1和Claude-3.7-Sonnet在不同任务上表现出色，并探讨了推理能力对主动行为的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在特定领域或任务导向的场景，导致评估碎片化，限制了对LLMs主动对话能力的全面探索。

Method: 提出了ProactiveEval，一个统一的评估框架，将主动对话分解为目标规划和对话引导，并在多个领域建立评估指标。该框架还能自动生成多样化且具有挑战性的评估数据。基于此，开发了涵盖6个不同领域的328个评估环境。

Result: 通过对22种不同类型LLMs的实验表明，DeepSeek-R1在目标规划任务上表现卓越，而Claude-3.7-Sonnet在对话引导任务上表现出色。

Conclusion: 研究了推理能力如何影响主动行为，并讨论了这对未来模型开发的启示。

Abstract: Proactive dialogue has emerged as a critical and challenging research problem
in advancing large language models (LLMs). Existing works predominantly focus
on domain-specific or task-oriented scenarios, which leads to fragmented
evaluations and limits the comprehensive exploration of models' proactive
conversation abilities. In this work, we propose ProactiveEval, a unified
framework designed for evaluating proactive dialogue capabilities of LLMs. This
framework decomposes proactive dialogue into target planning and dialogue
guidance, establishing evaluation metrics across various domains. Moreover, it
also enables the automatic generation of diverse and challenging evaluation
data. Based on the proposed framework, we develop 328 evaluation environments
spanning 6 distinct domains. Through experiments with 22 different types of
LLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional
performance on target planning and dialogue guidance tasks, respectively.
Finally, we investigate how reasoning capabilities influence proactive
behaviors and discuss their implications for future model development.

</details>


### [162] [The Uneven Impact of Post-Training Quantization in Machine Translation](https://arxiv.org/abs/2508.20893)
*Benjamin Marie,Atsushi Fujita*

Main category: cs.CL

TL;DR: 该研究首次大规模评估了后训练量化对55种语言的机器翻译任务的影响，发现4位量化对高资源语言和大型模型表现良好，但对低资源语言在2位设置下性能显著下降。GGUF变体在2位精度下表现最稳定。


<details>
  <summary>Details</summary>
Motivation: 量化对于在资源受限硬件上部署大型语言模型（LLMs）至关重要，但其对多语言任务的影响尚未得到充分探索。

Method: 对1.7B到70B参数范围内的五种LLM进行了大规模评估，测试了后训练量化（PTQ）在55种语言的机器翻译任务上的表现。比较了四种量化技术（AWQ、BitsAndBytes、GGUF和AutoRound），并量化了量化、解码超参数和校准语言之间的相互作用。

Result: 4位量化通常能保持高资源语言和大型模型的翻译质量，但在2位设置下，低资源和类型多样化语言的性能会显著下降。量化算法选择和模型大小共同决定了鲁棒性。GGUF变体即使在2位精度下也提供了最一致的性能。语言匹配的校准主要在低位场景中带来益处。

Conclusion: 该研究为在量化约束下（尤其是在低资源设置中）部署用于机器翻译的多语言LLM提供了可操作的见解。2位量化对低资源语言影响显著，GGUF技术表现出更好的稳定性。

Abstract: Quantization is essential for deploying large language models (LLMs) on
resource-constrained hardware, but its implications for multilingual tasks
remain underexplored. We conduct the first large-scale evaluation of
post-training quantization (PTQ) on machine translation across 55 languages
using five LLMs ranging from 1.7B to 70B parameters. Our analysis reveals that
while 4-bit quantization often preserves translation quality for high-resource
languages and large models, significant degradation occurs for low-resource and
typologically diverse languages, particularly in 2-bit settings. We compare
four quantization techniques (AWQ, BitsAndBytes, GGUF, and AutoRound), showing
that algorithm choice and model size jointly determine robustness. GGUF
variants provide the most consistent performance, even at 2-bit precision.
Additionally, we quantify the interactions between quantization, decoding
hyperparameters, and calibration languages, finding that language-matched
calibration offers benefits primarily in low-bit scenarios. Our findings offer
actionable insights for deploying multilingual LLMs for machine translation
under quantization constraints, especially in low-resource settings.

</details>


### [163] [SageLM: A Multi-aspect and Explainable Large Language Model for Speech Judgement](https://arxiv.org/abs/2508.20916)
*Yuan Ge,Junxiang Zhang,Xiaoqian Liu,Bei Li,Xiangnan Ma,Chenglong Wang,Kaiyang Ye,Yangfan Du,Linfeng Zhang,Yuxin Huang,Tong Xiao,Zhengtao Yu,JingBo Zhu*

Main category: cs.CL

TL;DR: 本文提出了SageLM，一个端到端、多维度、可解释的语音LLM，用于全面评估S2S LLM。它结合了语义和声学评估，利用基于理由的监督，并通过合成数据集解决了数据稀缺问题，显著提高了与人类评估的一致性。


<details>
  <summary>Details</summary>
Motivation: 语音到语音（S2S）大语言模型是自然人机交互的基础，但评估这些模型仍然是一个根本性的挑战。

Method: 本文提出了SageLM，一个端到端、多维度、可解释的语音LLM评估模型。具体方法包括：1. 联合评估语义和声学维度，而非级联方法。2. 利用基于理由的监督来增强可解释性并指导模型学习。3. 引入了一个合成偏好数据集SpeechFeedback，并采用两阶段训练范式来缓解语音偏好数据稀缺的问题。

Result: SageLM在语义和声学维度上进行训练，与人类评估者达到了82.79%的一致性，分别比级联和基于SLM的基线模型至少高出7.42%和26.20%。

Conclusion: SageLM提供了一种全面、可解释且高效的S2S LLM评估方法，通过联合考虑语义和声学特征，并结合基于理由的监督和数据增强策略，显著优于现有评估方法。

Abstract: Speech-to-Speech (S2S) Large Language Models (LLMs) are foundational to
natural human-computer interaction, enabling end-to-end spoken dialogue
systems. However, evaluating these models remains a fundamental challenge. We
propose \texttt{SageLM}, an end-to-end, multi-aspect, and explainable speech
LLM for comprehensive S2S LLMs evaluation. First, unlike cascaded approaches
that disregard acoustic features, SageLM jointly assesses both semantic and
acoustic dimensions. Second, it leverages rationale-based supervision to
enhance explainability and guide model learning, achieving superior alignment
with evaluation outcomes compared to rule-based reinforcement learning methods.
Third, we introduce \textit{SpeechFeedback}, a synthetic preference dataset,
and employ a two-stage training paradigm to mitigate the scarcity of speech
preference data. Trained on both semantic and acoustic dimensions, SageLM
achieves an 82.79\% agreement rate with human evaluators, outperforming
cascaded and SLM-based baselines by at least 7.42\% and 26.20\%, respectively.

</details>


### [164] [How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on $τ$-bench](https://arxiv.org/abs/2508.20931)
*Venkatesh Mishra,Amir Saeidi,Satyam Raj,Mutsumi Nakamura,Jayanth Srinivasa,Gaowen Liu,Ali Payani,Chitta Baral*

Main category: cs.CL

TL;DR: 本文提出IRMA框架，通过自动重构工具调用代理的输入（结合领域规则和工具建议），显著提升了大型语言模型在多轮会话和工具使用场景中的推理一致性和决策能力，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在推理和规划方面取得进展，但在多轮对话（如$\tau$-bench）中，工具调用代理仍面临推理不一致、难以遵守领域特定策略以及在长期工具调用和对话中提取正确信息的挑战。

Method: 研究方法包括：1) 对对话轨迹中的常见错误进行全面的手动分析。2) 实验性地重构工具调用代理的输入以改进决策。3) 提出了输入重构多代理（IRMA）框架，该框架自动重构用户查询，并辅以相关的领域规则和工具建议，以帮助工具调用代理集中注意力。

Result: IRMA在整体pass^5分数上显著优于ReAct、Function Calling和Self-Reflection，分别提高了16.1%、12.7%和19.1%。

Conclusion: 研究结果表明，在动态环境中，IRMA相比其他方法具有卓越的可靠性和一致性。

Abstract: Recent advances in reasoning and planning capabilities of large language
models (LLMs) have enabled their potential as autonomous agents capable of tool
use in dynamic environments. However, in multi-turn conversational environments
like $\tau$-bench, these agents often struggle with consistent reasoning,
adherence to domain-specific policies, and extracting correct information over
a long horizon of tool-calls and conversation. To capture and mitigate these
failures, we conduct a comprehensive manual analysis of the common errors
occurring in the conversation trajectories. We then experiment with
reformulations of inputs to the tool-calling agent for improvement in agent
decision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)
framework, which automatically reformulates user queries augmented with
relevant domain rules and tool suggestions for the tool-calling agent to focus
on. The results show that IRMA significantly outperforms ReAct, Function
Calling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in
overall pass^5 scores. These findings highlight the superior reliability and
consistency of IRMA compared to other methods in dynamic environments.

</details>


### [165] [STARE at the Structure: Steering ICL Exemplar Selection with Structural Alignment](https://arxiv.org/abs/2508.20944)
*Jiaqian Li,Qisheng Hu,Jing Li,Wenya Wang*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的两阶段上下文学习（ICL）范例选择策略，专门针对结构化预测任务，通过结构感知监督和语法信息增强，显著提升了大型语言模型（LLMs）的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 上下文学习（ICL）的效果严重依赖于范例选择的质量。对于语义解析等结构化预测任务，现有选择策略往往忽视结构对齐，导致性能不佳和泛化能力差。

Method: 本文提出了一种两阶段范例选择策略：1. 使用结构感知监督微调一个基于BERT的检索器，使其能选择语义相关且结构对齐的范例。2. 在检索器中添加一个模型无关的即插即用模块，用于增强隐藏表示中的句法有意义信息。

Result: 在涵盖三种语义解析任务的四个基准测试中，本文方法始终优于现有基线，并且适用于多种最新的LLM作为推理模型。

Conclusion: 该方法在效率、泛化能力和性能之间取得了良好的平衡，有效解决了结构化预测任务中ICL范例选择的挑战，显著提升了LLMs在此类任务中的表现。

Abstract: In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to
perform a wide range of tasks without task-specific fine-tuning. However, the
effectiveness of ICL heavily depends on the quality of exemplar selection. In
particular, for structured prediction tasks such as semantic parsing, existing
ICL selection strategies often overlook structural alignment, leading to
suboptimal performance and poor generalization. To address this issue, we
propose a novel two-stage exemplar selection strategy that achieves a strong
balance between efficiency, generalizability, and performance. First, we
fine-tune a BERT-based retriever using structure-aware supervision, guiding it
to select exemplars that are both semantically relevant and structurally
aligned. Then, we enhance the retriever with a plug-in module, which amplifies
syntactically meaningful information in the hidden representations. This
plug-in is model-agnostic, requires minimal overhead, and can be seamlessly
integrated into existing pipelines. Experiments on four benchmarks spanning
three semantic parsing tasks demonstrate that our method consistently
outperforms existing baselines with multiple recent LLMs as inference-time
models.

</details>


### [166] [Enabling Equitable Access to Trustworthy Financial Reasoning](https://arxiv.org/abs/2508.21051)
*William Jurayj,Nils Holzenberger,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 本文提出了一种将大型语言模型（LLMs）与符号求解器结合的神经符号方法，用于计算税务义务。通过将规则预先转换为形式逻辑程序并智能检索案例范例，该方法在税务推理任务上显著提高了性能，并能将部署成本降低到远低于实际平均水平，从而为可靠的税务援助提供了经济可行的解决方案。


<details>
  <summary>Details</summary>
Motivation: 报税过程复杂、耗时且容易出错，美国纳税人平均花费270美元和13小时。错误可能导致高昂的罚款。现代大型语言模型（LLMs）因其准确性和可审计性不足，不适合直接用于此任务。

Method: 提出了一种将LLMs与符号求解器集成的神经符号方法来计算税务义务。该方法包括将纯文本规则预先翻译成形式逻辑程序，并结合智能检索的范例进行形式化案例表示。系统在StAtutory Reasoning Assessment (SARA) 数据集上进行评估，并引入了一种基于实际税务错误罚款来估算系统部署成本的新方法。

Result: 在SARA数据集上的评估显示，结合预先规则翻译和智能检索范例的方法能显著提高性能，并将部署成本降低到远低于实际平均水平。

Conclusion: 研究结果证明了神经符号架构在提高可靠税务援助的可及性和公平性方面的潜力和经济可行性。

Abstract: According to the United States Internal Revenue Service, ''the average
American spends $\$270$ and 13 hours filing their taxes''. Even beyond the
U.S., tax filing requires complex reasoning, combining application of
overlapping rules with numerical calculations. Because errors can incur costly
penalties, any automated system must deliver high accuracy and auditability,
making modern large language models (LLMs) poorly suited for this task. We
propose an approach that integrates LLMs with a symbolic solver to calculate
tax obligations. We evaluate variants of this system on the challenging
StAtutory Reasoning Assessment (SARA) dataset, and include a novel method for
estimating the cost of deploying such a system based on real-world penalties
for tax errors. We further show how combining up-front translation of
plain-text rules into formal logic programs, combined with intelligently
retrieved exemplars for formal case representations, can dramatically improve
performance on this task and reduce costs to well below real-world averages.
Our results demonstrate the promise and economic feasibility of neuro-symbolic
architectures for increasing equitable access to reliable tax assistance.

</details>


### [167] [Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](https://arxiv.org/abs/2508.21004)
*Chen Chen,Yuchen Sun,Jiaxin Gao,Xueluan Gong,Qian Wang,Ziyao Wang,Yongsen Zheng,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: LETHE是一种新颖的LLM后门消除方法，通过内部（模型合并）和外部（提示注入）知识稀释机制，有效对抗多种高级后门攻击，同时保持模型实用性并具有成本效益。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在NLP任务中表现出色，但它们容易受到后门攻击。现有防御方法存在局限性，如范围狭窄、仅限于检测或无法抵御模型编辑、多触发器和无触发器等高级攻击，因此需要一种更全面、鲁棒的后门防御方案。

Method: LETHE通过内部和外部机制进行知识稀释来消除LLM的后门行为。内部机制是利用轻量级数据集训练一个干净模型，然后将其与受后门攻击的模型合并，通过稀释模型参数记忆中的后门影响来中和恶意行为。外部机制是在提示中加入良性且语义相关的证据，以分散LLM对后门特征的注意力。

Result: 实验结果表明，LETHE在分类和生成领域，针对8种后门攻击，在5个LLM上优于8种最先进的防御基线。LETHE将高级后门攻击的成功率降低了高达98%，同时保持了模型实用性。此外，LETHE被证明是具有成本效益的，并且对自适应后门攻击具有鲁棒性。

Conclusion: LETHE是一种有效、鲁棒且具有成本效益的方法，能够通过内部和外部知识稀释机制消除LLM中的后门行为，并能抵御各种高级后门攻击，同时保持模型性能。

Abstract: Large language models (LLMs) have seen significant advancements, achieving
superior performance in various Natural Language Processing (NLP) tasks.
However, they remain vulnerable to backdoor attacks, where models behave
normally for standard queries but generate harmful responses or unintended
output when specific triggers are activated. Existing backdoor defenses either
lack comprehensiveness, focusing on narrow trigger settings, detection-only
mechanisms, and limited domains, or fail to withstand advanced scenarios like
model-editing-based, multi-trigger, and triggerless attacks. In this paper, we
present LETHE, a novel method to eliminate backdoor behaviors from LLMs through
knowledge dilution using both internal and external mechanisms. Internally,
LETHE leverages a lightweight dataset to train a clean model, which is then
merged with the backdoored model to neutralize malicious behaviors by diluting
the backdoor impact within the model's parametric memory. Externally, LETHE
incorporates benign and semantically relevant evidence into the prompt to
distract LLM's attention from backdoor features. Experimental results on
classification and generation domains across 5 widely used LLMs demonstrate
that LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor
attacks. LETHE reduces the attack success rate of advanced backdoor attacks by
up to 98% while maintaining model utility. Furthermore, LETHE has proven to be
cost-efficient and robust against adaptive backdoor attacks.

</details>


### [168] [An Agile Method for Implementing Retrieval Augmented Generation Tools in Industrial SMEs](https://arxiv.org/abs/2508.21024)
*Mathieu Bourdin,Anas Neumann,Thomas Paviot,Robert Pellerin,Samir Lamouri*

Main category: cs.CL

TL;DR: 本文提出EASI-RAG，一种结构化、敏捷的方法，旨在帮助工业中小企业克服资源和专业知识限制，快速有效地部署RAG系统，并通过真实案例验证了其在快速实施、高用户采纳、准确回答和数据可靠性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）存在幻觉和知识过时等局限性，RAG是缓解这些问题的强大解决方案。然而，由于资源有限和缺乏自然语言处理（NLP）专业知识，中小型企业（SME）部署RAG工具面临挑战。

Method: 本文引入EASI-RAG（Enterprise Application Support for Industrial RAG），一个基于方法工程原理的结构化、敏捷方法。该方法包含明确定义的角色、活动和技术，旨在促进RAG系统在工业中小企业环境中的部署。

Result: EASI-RAG通过在一个环境测试实验室的真实案例研究中得到验证。一个没有RAG经验的团队在不到一个月内部署了一个RAG工具。结果表明，EASI-RAG支持快速实施、实现高用户采纳、提供准确答案并增强了底层数据的可靠性。

Conclusion: 这项工作突出了RAG在工业中小企业中部署的潜力。EASI-RAG支持RAG系统的成功部署，未来工作将包括推广到更多样化的用例以及与微调模型的进一步集成。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful solution to
mitigate the limitations of Large Language Models (LLMs), such as
hallucinations and outdated knowledge. However, deploying RAG-based tools in
Small and Medium Enterprises (SMEs) remains a challenge due to their limited
resources and lack of expertise in natural language processing (NLP). This
paper introduces EASI-RAG, Enterprise Application Support for Industrial RAG, a
structured, agile method designed to facilitate the deployment of RAG systems
in industrial SME contexts. EASI-RAG is based on method engineering principles
and comprises well-defined roles, activities, and techniques. The method was
validated through a real-world case study in an environmental testing
laboratory, where a RAG tool was implemented to answer operators queries using
data extracted from operational procedures. The system was deployed in under a
month by a team with no prior RAG experience and was later iteratively improved
based on user feedback. Results demonstrate that EASI-RAG supports fast
implementation, high user adoption, delivers accurate answers, and enhances the
reliability of underlying data. This work highlights the potential of RAG
deployment in industrial SMEs. Future works include the need for generalization
across diverse use cases and further integration with fine-tuned models.

</details>


### [169] [Re-Representation in Sentential Relation Extraction with Sequence Routing Algorithm](https://arxiv.org/abs/2508.21049)
*Ramazan Ali Bahrami,Ramin Yahyapour*

Main category: cs.CL

TL;DR: 本文提出了一种基于胶囊网络中动态路由的句子级关系抽取方法。该方法在多个数据集上超越了现有技术，但在Wikidata上表现不佳。研究发现Wikidata标签中的噪声以及模型更好的“再表征”能力是影响性能的关键因素，并提出再表征是句子级关系抽取的一个新挑战。


<details>
  <summary>Details</summary>
Motivation: 句子级关系抽取是自然语言处理中的一个重要任务。研究旨在提高关系抽取性能，并探究模型在不同数据集上表现差异的原因，特别是当模型在某些数据集上表现优秀而在另一些相似但更大的数据集上表现不佳时。

Method: 本文提出使用胶囊网络中的动态路由进行句子级关系抽取。通过在Tacred、Tacredrev、Retacred、Conll04和Wikidata等常用数据集上进行实验，评估了所提方法的性能。此外，还通过分析Wikidata标签中的噪声以及引入神经科学中的“再表征”概念，来解释模型性能差异。

Result: 所提出的方法在Tacred、Tacredrev、Retacred和Conll04等数据集上超越了现有技术。然而，在Wikidata数据集上性能较低。研究识别出Wikidata标签中的噪声是阻碍性能的一个原因。此外，实验表明更好的性能与更好的再表征能力相关联，即所提出的模型比传统模型能更好地进行再表征。

Conclusion: 基于动态路由的胶囊网络方法在句子级关系抽取任务中表现出色，尤其在特定数据集上优于现有技术。然而，远程监督关系抽取数据集（如Wikidata）中标签的噪声是一个重要挑战。同时，本文提出“再表征”是句子级关系抽取领域的一个新挑战，值得进一步研究。

Abstract: Sentential relation extraction (RE) is an important task in natural language
processing (NLP). In this paper we propose to do sentential RE with dynamic
routing in capsules. We first show that the proposed approach outperform state
of the art on common sentential relation extraction datasets Tacred, Tacredrev,
Retacred, and Conll04. We then investigate potential reasons for its good
performance on the mentioned datasets, and yet low performance on another
similar, yet larger sentential RE dataset, Wikidata. As such, we identify noise
in Wikidata labels as one of the reasons that can hinder performance.
Additionally, we show associativity of better performance with better
re-representation, a term from neuroscience referred to change of
representation in human brain to improve the match at comparison time. As
example, in the given analogous terms King:Queen::Man:Woman, at comparison
time, and as a result of re-representation, the similarity between related head
terms (King,Man), and tail terms (Queen,Woman) increases. As such, our
observation show that our proposed model can do re-representation better than
the vanilla model compared with. To that end, beside noise in the labels of the
distantly supervised RE datasets, we propose re-representation as a challenge
in sentential RE.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [170] [Learning Fast, Tool aware Collision Avoidance for Collaborative Robots](https://arxiv.org/abs/2508.20457)
*Joonho Lee,Yunho Kim,Seokjoon Kim,Quan Nguyen,Youngjin Heo*

Main category: cs.RO

TL;DR: 本文提出了一种工具感知的碰撞避免系统，通过学习感知模型和约束强化学习策略，使协作机器人在动态、部分可观测的环境中实现实时、高效且高精度的安全操作。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，协作机器人面临障碍物移动和任务变化等挑战。现有机器人控制器通常假设完全可见性和固定工具，这可能导致碰撞或过于保守的行为，影响安全和效率。

Method: 该系统引入了工具感知碰撞避免机制，可实时调整以适应不同的工具尺寸和交互模式。它使用学习感知模型从点云中过滤出机器人和工具组件，推断遮挡区域，并在部分可观测条件下预测碰撞。然后，通过约束强化学习训练的控制策略在10毫秒内生成平滑的避障机动。

Result: 在模拟和真实世界测试中，该方法在动态环境中优于传统方法（APF、MPPI），同时保持亚毫米级精度。此外，其计算成本比先进的基于GPU的规划器低约60%。该系统模块化、高效且有效，并已集成到协作机器人应用中，展示了其在安全响应操作中的实际用途。

Conclusion: 该研究提供了一种模块化、高效且有效的碰撞避免方法，使机器人在动态环境中能够进行工具感知、安全和响应式的操作，解决了协作机器人安全运行的关键挑战。

Abstract: Ensuring safe and efficient operation of collaborative robots in human
environments is challenging, especially in dynamic settings where both obstacle
motion and tasks change over time. Current robot controllers typically assume
full visibility and fixed tools, which can lead to collisions or overly
conservative behavior. In our work, we introduce a tool-aware collision
avoidance system that adjusts in real time to different tool sizes and modes of
tool-environment interaction. Using a learned perception model, our system
filters out robot and tool components from the point cloud, reasons about
occluded area, and predicts collision under partial observability. We then use
a control policy trained via constrained reinforcement learning to produce
smooth avoidance maneuvers in under 10 milliseconds. In simulated and
real-world tests, our approach outperforms traditional approaches (APF, MPPI)
in dynamic environments, while maintaining sub-millimeter accuracy. Moreover,
our system operates with approximately 60% lower computational cost compared to
a state-of-the-art GPU-based planner. Our approach provides modular, efficient,
and effective collision avoidance for robots operating in dynamic environments.
We integrate our method into a collaborative robot application and demonstrate
its practical use for safe and responsive operation.

</details>


### [171] [SPGrasp: Spatiotemporal Prompt-driven Grasp Synthesis in Dynamic Scenes](https://arxiv.org/abs/2508.20547)
*Yunpeng Mei,Hongjie Cao,Yinqiu Xia,Wei Xiao,Zhaohan Feng,Gang Wang,Jie Chen*

Main category: cs.RO

TL;DR: SPGrasp是一种新颖的、基于时空提示的动态抓取合成框架，通过扩展SAMv2，实现了低延迟（低至59毫秒）和高精度（例如GraspNet-1Billion上92.0%）的实时交互式抓取，有效解决了动态抓取合成中的延迟-交互性权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在为动态物体进行实时交互式抓取合成时，难以在保持可提示性的同时实现低延迟推理，这使得该领域仍面临挑战。

Method: 本文提出了SPGrasp（时空提示驱动的动态抓取合成），这是一个扩展了Segment Anything Model v2 (SAMv2) 的新颖框架，用于视频流抓取估计。其核心创新在于将用户提示与时空上下文相结合，以实现实时交互并确保动态物体的时间一致性。

Result: SPGrasp实现了低至59毫秒的端到端延迟。在基准评估中，它在OCID上达到了90.6%的实例级抓取精度，在Jacquard上达到了93.8%。在GraspNet-1Billion数据集的连续跟踪下，SPGrasp以每帧73.1毫秒的延迟实现了92.0%的精度，与先前的最先进可提示方法RoG-SAM相比，延迟降低了58.5%，同时保持了有竞争力的精度。涉及13个移动物体的真实世界实验显示，交互式抓取场景的成功率为94.8%。

Conclusion: 这些结果证实SPGrasp有效地解决了动态抓取合成中延迟与交互性之间的权衡问题。

Abstract: Real-time interactive grasp synthesis for dynamic objects remains challenging
as existing methods fail to achieve low-latency inference while maintaining
promptability. To bridge this gap, we propose SPGrasp (spatiotemporal
prompt-driven dynamic grasp synthesis), a novel framework extending segment
anything model v2 (SAMv2) for video stream grasp estimation. Our core
innovation integrates user prompts with spatiotemporal context, enabling
real-time interaction with end-to-end latency as low as 59 ms while ensuring
temporal consistency for dynamic objects. In benchmark evaluations, SPGrasp
achieves instance-level grasp accuracies of 90.6% on OCID and 93.8% on
Jacquard. On the challenging GraspNet-1Billion dataset under continuous
tracking, SPGrasp achieves 92.0% accuracy with 73.1 ms per-frame latency,
representing a 58.5% reduction compared to the prior state-of-the-art
promptable method RoG-SAM while maintaining competitive accuracy. Real-world
experiments involving 13 moving objects demonstrate a 94.8% success rate in
interactive grasping scenarios. These results confirm SPGrasp effectively
resolves the latency-interactivity trade-off in dynamic grasp synthesis. Code
is available at https://github.com/sejmoonwei/SPGrasp.

</details>


### [172] [SimShear: Sim-to-Real Shear-based Tactile Servoing](https://arxiv.org/abs/2508.20561)
*Kipp McAdam Freud,Yijiong Lin,Nathan F. Lepora*

Main category: cs.RO

TL;DR: 本文提出了SimShear，一个用于触觉控制的虚实迁移（sim-to-real）管道，它允许在不显式建模剪切动力学的情况下使用剪切信息。通过引入shPix2pix，一个条件U-Net GAN，将不含剪切的模拟触觉图像转换为包含剪切变形的真实图像，并在触觉跟踪和协同举升任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 剪切信息对于涉及动态物体交互的任务至关重要，但由于难以模拟，这在虚实迁移中仍是一个挑战。研究旨在无需在模拟中显式建模剪切动力学的情况下，有效利用剪切信息进行触觉控制。

Method: 核心方法是SimShear管道，它包含shPix2pix。shPix2pix是一个剪切条件U-Net GAN，用于将不含剪切的模拟触觉图像（结合剪切信息向量）转换为具有真实剪切变形的等效图像。该方法应用于两个控制任务：触觉跟踪和协作共同举升，使用配备视觉触觉传感器的低成本桌面机械臂。

Result: shPix2pix在模拟触觉图像以及姿态/剪切预测方面优于基线pix2pix方法。在剪切感应至关重要的各种轨迹上，SimShear方法将接触误差保持在1到2毫米以内。这验证了使用刚体模拟器进行虚实剪切建模的可行性。

Conclusion: SimShear成功地实现了使用刚体模拟器进行虚实剪切建模，为触觉机器人中的模拟开辟了新方向。该方法在实际控制任务中表现出色，证明了在不显式模拟复杂剪切动力学的情况下利用剪切信息的潜力。

Abstract: We present SimShear, a sim-to-real pipeline for tactile control that enables
the use of shear information without explicitly modeling shear dynamics in
simulation. Shear, arising from lateral movements across contact surfaces, is
critical for tasks involving dynamic object interactions but remains
challenging to simulate. To address this, we introduce shPix2pix, a
shear-conditioned U-Net GAN that transforms simulated tactile images absent of
shear, together with a vector encoding shear information, into realistic
equivalents with shear deformations. This method outperforms baseline pix2pix
approaches in simulating tactile images and in pose/shear prediction. We apply
SimShear to two control tasks using a pair of low-cost desktop robotic arms
equipped with a vision-based tactile sensor: (i) a tactile tracking task, where
a follower arm tracks a surface moved by a leader arm, and (ii) a collaborative
co-lifting task, where both arms jointly hold an object while the leader
follows a prescribed trajectory. Our method maintains contact errors within 1
to 2 mm across varied trajectories where shear sensing is essential, validating
the feasibility of sim-to-real shear modeling with rigid-body simulators and
opening new directions for simulation in tactile robotics.

</details>


### [173] [Traversing the Narrow Path: A Two-Stage Reinforcement Learning Framework for Humanoid Beam Walking](https://arxiv.org/abs/2508.20661)
*TianChen Huang,Wei Gao,Runchen Xu,Shiwu Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种两阶段框架，结合XCoM/LIPM落足模板与轻量级残差规划器，使人形机器人能够可靠地穿越狭窄横梁。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在穿越狭窄横梁时面临挑战，因为接触点稀疏且关键，而纯粹学习的策略往往脆弱。

Method: 该方法是一个物理基础的两阶段框架：
1.  **第一阶段（平地训练）**：低级跟踪器通过对启发式落足目标添加随机扰动来学习鲁棒地跟随落足点，以获得稳定的接触调度和强大的目标跟踪鲁棒性。
2.  **第二阶段（模拟器中横梁训练）**：高级规划器预测摆动脚的身体坐标系残差（Delta x, Delta y, Delta psi），以在狭窄支撑下优先考虑安全、精确的放置，同时保持可解释性。
系统采用最小化且模拟与硬件一致的感知（前向高程线索、IMU和关节信号）。

Result: 该系统在Unitree G1机器人上成功穿越了0.2米宽、3米长的横梁。与仅使用模板和整体基线相比，残差细化在成功率、中心线依从性和安全裕度方面表现更优。结构化的落足接口也促进了透明分析和低摩擦的模拟到真实迁移。

Conclusion: 所提出的结合模板和残差规划器的两阶段框架，为人形机器人穿越狭窄横梁提供了一个物理基础、鲁棒、可解释且易于模拟到真实迁移的解决方案。

Abstract: Traversing narrow beams is challenging for humanoids due to sparse,
safety-critical contacts and the fragility of purely learned policies. We
propose a physically grounded, two-stage framework that couples an XCoM/LIPM
footstep template with a lightweight residual planner and a simple low-level
tracker. Stage-1 is trained on flat ground: the tracker learns to robustly
follow footstep targets by adding small random perturbations to heuristic
footsteps, without any hand-crafted centerline locking, so it acquires stable
contact scheduling and strong target-tracking robustness. Stage-2 is trained in
simulation on a beam: a high-level planner predicts a body-frame residual
(Delta x, Delta y, Delta psi) for the swing foot only, refining the template
step to prioritize safe, precise placement under narrow support while
preserving interpretability. To ease deployment, sensing is kept minimal and
consistent between simulation and hardware: the planner consumes compact,
forward-facing elevation cues together with onboard IMU and joint signals. On a
Unitree G1, our system reliably traverses a 0.2 m-wide, 3 m-long beam. Across
simulation and real-world studies, residual refinement consistently outperforms
template-only and monolithic baselines in success rate, centerline adherence,
and safety margins, while the structured footstep interface enables transparent
analysis and low-friction sim-to-real transfer.

</details>


### [174] [Task-Oriented Edge-Assisted Cross-System Design for Real-Time Human-Robot Interaction in Industrial Metaverse](https://arxiv.org/abs/2508.20664)
*Kan Chen,Zhen Meng,Xiangmin Xu,Jiaming Yang,Emma Li,Philip G. Zhao*

Main category: cs.RO

TL;DR: 该论文提出了一种任务导向的边缘辅助跨系统数字孪生框架，通过预测操作员动作和动态调整预测范围，以实现工业元宇宙中实时、响应式的人机交互，有效解决高计算负荷、带宽受限和严格延迟的挑战。


<details>
  <summary>Details</summary>
Motivation: 工业元宇宙中的实时人机交互面临高计算负荷、带宽受限和严格延迟等挑战。

Method: 该研究提出了一种任务导向的边缘辅助跨系统框架，利用数字孪生（DTs）实现响应式交互。通过预测操作员动作，系统支持：1) 主动式元宇宙渲染以提供视觉反馈；2) 抢占式远程设备控制。数字孪生被解耦为视觉显示和机器人控制两个虚拟功能。为增强泛化能力，引入了人机在环模型无关元学习（HITL-MAML）算法，动态调整预测范围。

Result: 在轨迹绘制控制任务中，加权RMSE从0.0712米降低到0.0101米。在核退役的实时3D场景表示任务中，实现了22.11的PSNR、0.8729的SSIM和0.1298的LPIPS。

Conclusion: 该框架能够确保实时、高风险工业环境中的空间精度和视觉保真度。

Abstract: Real-time human-device interaction in industrial Metaverse faces challenges
such as high computational load, limited bandwidth, and strict latency. This
paper proposes a task-oriented edge-assisted cross-system framework using
digital twins (DTs) to enable responsive interactions. By predicting operator
motions, the system supports: 1) proactive Metaverse rendering for visual
feedback, and 2) preemptive control of remote devices. The DTs are decoupled
into two virtual functions-visual display and robotic control-optimizing both
performance and adaptability. To enhance generalizability, we introduce the
Human-In-The-Loop Model-Agnostic Meta-Learning (HITL-MAML) algorithm, which
dynamically adjusts prediction horizons. Evaluation on two tasks demonstrates
the framework's effectiveness: in a Trajectory-Based Drawing Control task, it
reduces weighted RMSE from 0.0712 m to 0.0101 m; in a real-time 3D scene
representation task for nuclear decommissioning, it achieves a PSNR of 22.11,
SSIM of 0.8729, and LPIPS of 0.1298. These results show the framework's
capability to ensure spatial precision and visual fidelity in real-time,
high-risk industrial environments.

</details>


### [175] [Task Allocation for Autonomous Machines using Computational Intelligence and Deep Reinforcement Learning](https://arxiv.org/abs/2508.20688)
*Thanh Thi Nguyen,Quoc Viet Hung Nguyen,Jonathan Kua,Imran Razzak,Dung Nguyen,Saeid Nahavandi*

Main category: cs.RO

TL;DR: 本文综述了用于复杂环境中自主机器协作控制的算法，重点关注计算智能（CI）和深度强化学习（RL）在任务分配中的应用，并分析了其优缺点及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 为了使多台自主机器能够可靠地执行任务，需要开发高效的协作控制算法。在复杂环境中控制和协调自主机器是一个重要且具有挑战性的问题。

Method: 本文采用综述方法，对已开发的用于控制和协调自主机器的算法进行了回顾和分析，特别关注使用计算智能（CI）和深度强化学习（RL）进行任务分配的方法，并对其优缺点进行了深入分析。

Result: 研究发现，CI和深度RL方法为解决动态和不确定环境中的复杂任务分配问题提供了可行途径。深度RL的最新发展对自主机器的控制和协调领域做出了巨大贡献，并已成为该领域日益增长的趋势。

Conclusion: CI和深度RL是解决自主机器复杂任务分配问题的有效方法。本文为研究人员和工程师提供了机器学习在自主机器领域进展的全面概述，并强调了未充分探索的领域、新兴方法和未来的研究方向。

Abstract: Enabling multiple autonomous machines to perform reliably requires the
development of efficient cooperative control algorithms. This paper presents a
survey of algorithms that have been developed for controlling and coordinating
autonomous machines in complex environments. We especially focus on task
allocation methods using computational intelligence (CI) and deep reinforcement
learning (RL). The advantages and disadvantages of the surveyed methods are
analysed thoroughly. We also propose and discuss in detail various future
research directions that shed light on how to improve existing algorithms or
create new methods to enhance the employability and performance of autonomous
machines in real-world applications. The findings indicate that CI and deep RL
methods provide viable approaches to addressing complex task allocation
problems in dynamic and uncertain environments. The recent development of deep
RL has greatly contributed to the literature on controlling and coordinating
autonomous machines, and it has become a growing trend in this area. It is
envisaged that this paper will provide researchers and engineers with a
comprehensive overview of progress in machine learning research related to
autonomous machines. It also highlights underexplored areas, identifies
emerging methodologies, and suggests new avenues for exploration in future
research within this domain.

</details>


### [176] [Non-expert to Expert Motion Translation Using Generative Adversarial Networks](https://arxiv.org/abs/2508.20740)
*Yuki Tanaka,Seiichiro Katsura*

Main category: cs.RO

TL;DR: 本文提出了一种基于生成对抗网络（GAN）的灵活运动转换方法，旨在解决现有模仿学习在机器人技能转移中难以根据人类意图改变任务的问题。


<details>
  <summary>Details</summary>
Motivation: 熟练工人短缺是一个严重问题，需要将专家技能转移给机器人。现有模仿学习方法在复制位置和力数据方面已取得进展，但大多数无法根据人类意图改变任务，或条件训练的标签有限。

Method: 提出了一种使用生成对抗网络（GANs）的灵活运动转换方法。该方法允许用户通过输入数据来教授机器人任务，并通过训练好的模型来传递技能。

Result: 所提出的系统通过一个3自由度书法机器人进行了评估。

Conclusion: 该方法通过使用GANs，实现了机器人任务的灵活转换，克服了传统模仿学习方法在根据人类意图适应任务方面的局限性。

Abstract: Decreasing skilled workers is a very serious problem in the world. To deal
with this problem, the skill transfer from experts to robots has been
researched. These methods which teach robots by human motion are called
imitation learning. Experts' skills generally appear in not only position data,
but also force data. Thus, position and force data need to be saved and
reproduced. To realize this, a lot of research has been conducted in the
framework of a motion-copying system. Recent research uses machine learning
methods to generate motion commands. However, most of them could not change
tasks by following human intention. Some of them can change tasks by
conditional training, but the labels are limited. Thus, we propose the flexible
motion translation method by using Generative Adversarial Networks. The
proposed method enables users to teach robots tasks by inputting data, and
skills by a trained model. We evaluated the proposed system with a 3-DOF
calligraphy robot.

</details>


### [177] [Uncertainty Aware-Predictive Control Barrier Functions: Safer Human Robot Interaction through Probabilistic Motion Forecasting](https://arxiv.org/abs/2508.20812)
*Lorenzo Busellato,Federico Cunico,Diego Dall'Alba,Marco Emporio,Andrea Giachetti,Riccardo Muradore,Marco Cristani*

Main category: cs.RO

TL;DR: 该研究引入了不确定性感知预测控制障碍函数（UA-PCBFs）框架，通过融合概率性人类运动预测与控制障碍函数，实现协作机器人动态调整安全裕度，从而在确保安全的同时，提高人机交互的流畅性和效率。


<details>
  <summary>Details</summary>
Motivation: 在人机共享工作空间中，协作机器人需要在严格的安全保障与响应式高效行为之间取得平衡。现有方法多采用最坏情况的人类运动预测，导致机器人不必要的制动、任务停滞和交互流畅性受损。尽管基于学习的人类运动预测技术有所进步，但大多未能以结构化方式处理预测不确定性，导致规划算法过于保守，限制了灵活性。

Method: 本文提出了不确定性感知预测控制障碍函数（UA-PCBFs），这是一个统一的框架，将概率性人类手部运动预测与控制障碍函数（CBFs）的正式安全保证相结合。与现有方法不同，UA-PCBFs通过预测模块提供的人类运动不确定性估计，允许动态调整安全裕度，从而使协作机器人能更深入地理解未来人类状态，实现更智能的运动规划。

Result: 通过一系列真实世界实验（包括自动化设置和直接人机交互），UA-PCBFs在任务关键指标上表现出优于现有HRI架构的性能。它显著减少了机器人在交互过程中侵犯安全空间的次数，并提高了交互的及时性、可用性和人类的信任度，促进了更流畅和智能的交互。

Conclusion: UA-PCBFs提供了一个有效且安全的解决方案，通过利用不确定性感知的人类运动预测来动态调整安全裕度，极大地改善了协作机器人与人类的交互。该框架在确保安全性的同时，显著提升了交互的流畅性和效率，为未来的人机协作奠定了基础。

Abstract: To enable flexible, high-throughput automation in settings where people and
robots share workspaces, collaborative robotic cells must reconcile stringent
safety guarantees with the need for responsive and effective behavior. A
dynamic obstacle is the stochastic, task-dependent variability of human motion:
when robots fall back on purely reactive or worst-case envelopes, they brake
unnecessarily, stall task progress, and tamper with the fluidity that true
Human-Robot Interaction demands. In recent years, learning-based human-motion
prediction has rapidly advanced, although most approaches produce worst-case
scenario forecasts that often do not treat prediction uncertainty in a
well-structured way, resulting in over-conservative planning algorithms,
limiting their flexibility. We introduce Uncertainty-Aware Predictive Control
Barrier Functions (UA-PCBFs), a unified framework that fuses probabilistic
human hand motion forecasting with the formal safety guarantees of Control
Barrier Functions. In contrast to other variants, our framework allows for
dynamic adjustment of the safety margin thanks to the human motion uncertainty
estimation provided by a forecasting module. Thanks to uncertainty estimation,
UA-PCBFs empower collaborative robots with a deeper understanding of future
human states, facilitating more fluid and intelligent interactions through
informed motion planning. We validate UA-PCBFs through comprehensive real-world
experiments with an increasing level of realism, including automated setups (to
perform exactly repeatable motions) with a robotic hand and direct human-robot
interactions (to validate promptness, usability, and human confidence).
Relative to state-of-the-art HRI architectures, UA-PCBFs show better
performance in task-critical metrics, significantly reducing the number of
violations of the robot's safe space during interaction with respect to the
state-of-the-art.

</details>


### [178] [A Soft Fabric-Based Thermal Haptic Device for VR and Teleoperation](https://arxiv.org/abs/2508.20831)
*Rui Chen,Domenico Chiaradia,Antonio Frisoli,Daniele Leonardis*

Main category: cs.RO

TL;DR: 本文提出了一种新型的基于织物的热触觉界面，用于虚拟现实和远程操作。它结合了气动驱动和导电织物，实现了超轻量化设计，并能提供快速的热调节和显著的操作性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟现实和远程操作界面在提供逼真的多模态反馈方面存在局限性，尤其是缺乏集成热触觉反馈，这限制了沉浸感和交互精度。

Method: 该研究将气动驱动和导电织物集成到一种创新的超轻量化设计中（每个手指单元仅2克）。通过将加热元件嵌入纺织气动腔室，系统能够通过完全柔软、可穿戴的界面向指尖提供调制压力和热刺激。

Result: 该界面展示了高达3°C/s的快速热调节能力。气动子系统在50kPa下可产生高达8.93N的力，并通过优化指尖-执行器间隙提高了冷却效率。用户研究表明，该界面在三个热水平上的温度识别准确率高达0.98。在虚拟抓取放置任务中，启用触觉反馈后，成功率从88.5%提高到96.4%（p=0.029），力控制精度也显著提高（p=0.013）。

Conclusion: 集成的热触觉方法通过改善虚拟操作任务中的成功率和力控制精度，被验证对先进人机交互应用有效。

Abstract: This paper presents a novel fabric-based thermal-haptic interface for virtual
reality and teleoperation. It integrates pneumatic actuation and conductive
fabric with an innovative ultra-lightweight design, achieving only 2~g for each
finger unit. By embedding heating elements within textile pneumatic chambers,
the system delivers modulated pressure and thermal stimuli to fingerpads
through a fully soft, wearable interface.
  Comprehensive characterization demonstrates rapid thermal modulation with
heating rates up to 3$^{\circ}$C/s, enabling dynamic thermal feedback for
virtual or teleoperation interactions. The pneumatic subsystem generates forces
up to 8.93~N at 50~kPa, while optimization of fingerpad-actuator clearance
enhances cooling efficiency with minimal force reduction. Experimental
validation conducted with two different user studies shows high temperature
identification accuracy (0.98 overall) across three thermal levels, and
significant manipulation improvements in a virtual pick-and-place tasks.
Results show enhanced success rates (88.5\% to 96.4\%, p = 0.029) and improved
force control precision (p = 0.013) when haptic feedback is enabled, validating
the effectiveness of the integrated thermal-haptic approach for advanced
human-machine interaction applications.

</details>


### [179] [Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration](https://arxiv.org/abs/2508.20836)
*Ahmed A. Elgohary,Rohan Palanikumar,Sameh A. Eisa*

Main category: cs.RO

TL;DR: 本文首次通过实验验证了极值搜索控制（ESC）在扑翼机器人中实现无模型、实时受控悬停和寻源的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是模仿扑翼昆虫和蜂鸟的悬停和寻源现象，并提出一种新型极值搜索控制（ESC）方法，以实现无模型、实时的仿生控制设计。本文旨在通过实验验证该ESC方法在扑翼机器人中的可行性。

Method: 该研究采用实验测试和验证的方法，首次在扑翼机器人上测试了极值搜索控制（ESC）方法，以实现无模型、实时受控的悬停和寻源。

Result: 实验结果（尽管仅限于一维）证实了将ESC引入扑翼飞行和机器人领域作为一种自然控制方法和仿生机制的设想是正确的。

Conclusion: 极值搜索控制（ESC）被确认为扑翼飞行和机器人领域中一种有前景的自然控制方法和仿生机制，其潜力已通过实验得到验证。

Abstract: In a recent effort, we successfully proposed a categorically novel approach
to mimic the phenomenoa of hovering and source seeking by flapping insects and
hummingbirds using a new extremum seeking control (ESC) approach. Said ESC
approach was shown capable of characterizing the physics of hovering and source
seeking by flapping systems, providing at the same time uniquely novel
opportunity for a model-free, real-time biomimicry control design. In this
paper, we experimentally test and verify, for the first time in the literature,
the potential of ESC in flapping robots to achieve model-free, real-time
controlled hovering and source seeking. The results of this paper, while being
restricted to 1D, confirm the premise of introducing ESC as a natural control
method and biomimicry mechanism to the field of flapping flight and robotics.

</details>


### [180] [Learning Primitive Embodied World Models: Towards Scalable Robotic Learning](https://arxiv.org/abs/2508.20840)
*Qiao Sun,Liujia Yang,Wei Tang,Wei Huang,Kaixin Xu,Yongchao Chen,Mingyu Liu,Jiange Yang,Haoyi Zhu,Yating Wang,Tong He,Yilun Chen,Xili Dai,Nanyang Ye,Qinying Gu*

Main category: cs.RO

TL;DR: 本文提出了一种名为“原始具身世界模型”（PEWM）的新范式，通过将视频生成限制在固定短时程的原始动作上，以解决具身世界模型中大规模具身交互数据稀缺的问题，从而提高语言与动作的对齐粒度、数据效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频生成的具身世界模型严重依赖大规模具身交互数据，但此类数据稀缺、收集困难且维度高，这限制了语言与动作的对齐精度，加剧了长时程视频生成的挑战，阻碍了具身领域实现“GPT时刻”。

Method: 基于“具身数据多样性远超原始运动空间”的洞察，本文提出了PEWM。该方法将视频生成限制在固定的短时程内，并配备了模块化的视觉-语言模型（VLM）规划器和起始-目标热图引导机制（SGG）。

Result: PEWM能够实现语言概念与机器人动作视觉表征的细粒度对齐，降低学习复杂性，提高具身数据收集效率，并减少推理延迟。结合VLM规划器和SGG，PEWM进一步支持灵活的闭环控制和原始级别策略在复杂任务中的组合泛化。

Conclusion: 该框架利用视频模型的时空视觉先验和VLM的语义感知能力，弥合了细粒度物理交互与高级推理之间的鸿沟，为可扩展、可解释和通用型具身智能铺平了道路。

Abstract: While video-generation-based embodied world models have gained increasing
attention, their reliance on large-scale embodied interaction data remains a
key bottleneck. The scarcity, difficulty of collection, and high dimensionality
of embodied data fundamentally limit the alignment granularity between language
and actions and exacerbate the challenge of long-horizon video
generation--hindering generative models from achieving a "GPT moment" in the
embodied domain. There is a naive observation: the diversity of embodied data
far exceeds the relatively small space of possible primitive motions. Based on
this insight, we propose a novel paradigm for world modeling--Primitive
Embodied World Models (PEWM). By restricting video generation to fixed short
horizons, our approach 1) enables fine-grained alignment between linguistic
concepts and visual representations of robotic actions, 2) reduces learning
complexity, 3) improves data efficiency in embodied data collection, and 4)
decreases inference latency. By equipping with a modular Vision-Language Model
(VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further
enables flexible closed-loop control and supports compositional generalization
of primitive-level policies over extended, complex tasks. Our framework
leverages the spatiotemporal vision priors in video models and the semantic
awareness of VLMs to bridge the gap between fine-grained physical interaction
and high-level reasoning, paving the way toward scalable, interpretable, and
general-purpose embodied intelligence.

</details>


### [181] [Genetic Informed Trees (GIT*): Path Planning via Reinforced Genetic Programming Heuristics](https://arxiv.org/abs/2508.20871)
*Liding Zhang,Kuanqi Cai,Zhenshan Bing,Chaoqun Wang,Alois Knoll*

Main category: cs.RO

TL;DR: 本研究提出了一种名为Genetic Informed Trees (GIT*)的路径规划算法，通过整合更丰富的环境数据和使用强化遗传编程(RGP)来优化启发式函数，从而显著提高了路径规划的计算效率和解决方案质量。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法中使用的启发式函数往往忽略可用的环境数据，并因信息关系的复杂性而简化函数结构，这导致搜索效率和解决方案质量不佳。

Method: 本研究引入了Genetic Informed Trees (GIT*)，它在Effort Informed Trees (EIT*)的基础上，整合了更广泛的环境数据（如来自障碍物的斥力、顶点的动态重要性）以改进启发式函数。此外，本研究集成了强化遗传编程（RGP），该方法结合了遗传编程与奖励系统反馈，用于变异GIT*的基因型生成启发式函数。

Result: 比较分析表明，GIT*在R^4到R^16维度的问题上，以及在真实的移动操作任务中，均超越了现有的单查询、基于采样的规划器。它在设定的时间内提高了计算效率和解决方案质量。

Conclusion: GIT*通过有效利用更丰富的环境数据和结合强化遗传编程生成优化的启发式函数，成功地提高了路径规划的效率和解决方案质量，在多维度和实际任务中展现出优越性能。

Abstract: Optimal path planning involves finding a feasible state sequence between a
start and a goal that optimizes an objective. This process relies on heuristic
functions to guide the search direction. While a robust function can improve
search efficiency and solution quality, current methods often overlook
available environmental data and simplify the function structure due to the
complexity of information relationships. This study introduces Genetic Informed
Trees (GIT*), which improves upon Effort Informed Trees (EIT*) by integrating a
wider array of environmental data, such as repulsive forces from obstacles and
the dynamic importance of vertices, to refine heuristic functions for better
guidance. Furthermore, we integrated reinforced genetic programming (RGP),
which combines genetic programming with reward system feedback to mutate
genotype-generative heuristic functions for GIT*. RGP leverages a multitude of
data types, thereby improving computational efficiency and solution quality
within a set timeframe. Comparative analyses demonstrate that GIT* surpasses
existing single-query, sampling-based planners in problems ranging from R^4 to
R^16 and was tested on a real-world mobile manipulation task. A video
showcasing our experimental results is available at
https://youtu.be/URjXbc_BiYg

</details>


### [182] [Deep Fuzzy Optimization for Batch-Size and Nearest Neighbors in Optimal Robot Motion Planning](https://arxiv.org/abs/2508.20884)
*Liding Zhang,Qiyang Zong,Yu Zhang,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: 本文提出了一种名为LIT*的基于深度模糊学习的采样式规划器，它能根据配置空间中的障碍物分布动态调整批处理大小和最近邻参数，从而在复杂环境中实现更快的收敛和更优的路径质量。


<details>
  <summary>Details</summary>
Motivation: 机器人运动规划中，采样式方法的批处理大小和最近邻选择等关键参数对性能至关重要。然而，现有方法往往缺乏环境适应性，不能根据障碍物分布进行动态调整。

Method: 受深度模糊神经网络的启发，LIT*通过编码有效和无效状态来区分障碍物稀疏和密集区域的全局与局部比例。它能动态调整批处理大小和最近邻参数，以适应配置空间中的障碍物分布。

Result: 实验结果表明，LIT*在高维空间中实现了更快的收敛和更高的解决方案质量，获得了更低成本的路径和更短的计算时间。在R^8到R^14的环境中，LIT*优于最先进的单查询采样式规划器，并在双臂机器人操作任务中成功验证。

Conclusion: LIT*是一种有效的、基于深度模糊学习的采样式规划器，它通过动态调整关键参数来适应环境中的障碍物分布，显著提升了运动规划的效率和路径质量。

Abstract: Efficient motion planning algorithms are essential in robotics. Optimizing
essential parameters, such as batch size and nearest neighbor selection in
sampling-based methods, can enhance performance in the planning process.
However, existing approaches often lack environmental adaptability. Inspired by
the method of the deep fuzzy neural networks, this work introduces
Learning-based Informed Trees (LIT*), a sampling-based deep fuzzy
learning-based planner that dynamically adjusts batch size and nearest neighbor
parameters to obstacle distributions in the configuration spaces. By encoding
both global and local ratios via valid and invalid states, LIT* differentiates
between obstacle-sparse and obstacle-dense regions, leading to lower-cost paths
and reduced computation time. Experimental results in high-dimensional spaces
demonstrate that LIT* achieves faster convergence and improved solution
quality. It outperforms state-of-the-art single-query, sampling-based planners
in environments ranging from R^8 to R^14 and is successfully validated on a
dual-arm robot manipulation task. A video showcasing our experimental results
is available at: https://youtu.be/NrNs9zebWWk

</details>


### [183] [CoCoL: A Communication Efficient Decentralized Collaborative Method for Multi-Robot Systems](https://arxiv.org/abs/2508.20898)
*Jiaxi Huang,Yan Huang,Yixian Zhao,Wenchao Meng,Jinming Xu*

Main category: cs.RO

TL;DR: CoCoL是一种去中心化协作学习方法，专为多机器人系统设计，通过镜像下降框架和梯度跟踪机制，有效解决了高通信开销和数据异构性问题，在保持高精度的同时显著降低了通信成本。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统中的协作学习虽然能提升性能和适应性，但面临高通信开销和数据异构性带来的巨大挑战。

Method: 本文提出了CoCoL方法，它利用镜像下降框架，通过近似牛顿型更新（捕捉机器人目标函数相似性）实现卓越的通信效率，并通过不精确子问题解降低计算成本。此外，结合梯度跟踪方案确保了其对数据异构性的鲁棒性。该方法是去中心化的。

Result: 在三个典型的多机器人协作学习任务上的实验结果表明，CoCoL在显著减少通信轮数和总带宽消耗的同时，保持了最先进的准确性。这些优势在非独立同分布(non-IID)数据、流式数据和时变网络拓扑等挑战性场景中尤为明显。

Conclusion: CoCoL是一种在多机器人系统中实现通信高效、去中心化协作学习的优越方法，尤其适用于数据异构和复杂动态环境，能有效应对通信和计算挑战。

Abstract: Collaborative learning enhances the performance and adaptability of
multi-robot systems in complex tasks but faces significant challenges due to
high communication overhead and data heterogeneity inherent in multi-robot
tasks. To this end, we propose CoCoL, a Communication efficient decentralized
Collaborative Learning method tailored for multi-robot systems with
heterogeneous local datasets. Leveraging a mirror descent framework, CoCoL
achieves remarkable communication efficiency with approximate Newton-type
updates by capturing the similarity between objective functions of robots, and
reduces computational costs through inexact sub-problem solutions. Furthermore,
the integration of a gradient tracking scheme ensures its robustness against
data heterogeneity. Experimental results on three representative multi robot
collaborative learning tasks show the superiority of the proposed CoCoL in
significantly reducing both the number of communication rounds and total
bandwidth consumption while maintaining state-of-the-art accuracy. These
benefits are particularly evident in challenging scenarios involving non-IID
(non-independent and identically distributed) data distribution, streaming
data, and time-varying network topologies.

</details>


### [184] [Language-Enhanced Mobile Manipulation for Efficient Object Search in Indoor Environments](https://arxiv.org/abs/2508.20899)
*Liding Zhang,Zeqi Li,Kuanqi Cai,Qian Huang,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: 本文提出了一种名为GODHS的语言增强分层导航框架，它整合了语义感知和空间推理，利用大型语言模型（LLMs）在复杂、非结构化环境中高效搜索和识别物体。


<details>
  <summary>Details</summary>
Motivation: 传统的场景表示仅捕获静态语义，缺乏可解释的上下文推理，限制了机器人在完全不熟悉的环境中引导物体搜索的能力。

Method: 该方法（GODHS）利用LLMs推断场景语义，并通过多级决策层次指导搜索过程。通过在每个层次阶段应用结构化提示和逻辑约束来确保推理的可靠性。针对移动操作挑战，引入了一种基于启发式的运动规划器，结合极角排序和距离优先级来高效生成探索路径。

Result: 在Isaac Sim中的综合评估表明，与传统的非语义搜索策略相比，GODHS能够以更高的搜索效率定位目标物体，证明了该框架的可行性。

Conclusion: 所提出的语言增强分层导航框架（GODHS）通过整合语义感知和空间推理，有效解决了复杂环境中物体搜索的挑战，并显著提高了搜索效率。

Abstract: Enabling robots to efficiently search for and identify objects in complex,
unstructured environments is critical for diverse applications ranging from
household assistance to industrial automation. However, traditional scene
representations typically capture only static semantics and lack interpretable
contextual reasoning, limiting their ability to guide object search in
completely unfamiliar settings. To address this challenge, we propose a
language-enhanced hierarchical navigation framework that tightly integrates
semantic perception and spatial reasoning. Our method, Goal-Oriented
Dynamically Heuristic-Guided Hierarchical Search (GODHS), leverages large
language models (LLMs) to infer scene semantics and guide the search process
through a multi-level decision hierarchy. Reliability in reasoning is achieved
through the use of structured prompts and logical constraints applied at each
stage of the hierarchy. For the specific challenges of mobile manipulation, we
introduce a heuristic-based motion planner that combines polar angle sorting
with distance prioritization to efficiently generate exploration paths.
Comprehensive evaluations in Isaac Sim demonstrate the feasibility of our
framework, showing that GODHS can locate target objects with higher search
efficiency compared to conventional, non-semantic search strategies. Website
and Video are available at: https://drapandiger.github.io/GODHS

</details>


### [185] [PLUME: Procedural Layer Underground Modeling Engine](https://arxiv.org/abs/2508.20926)
*Gabriel Manuel Garcia,Antoine Richard,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 本文介绍了PLUME，一个用于程序化生成3D地下环境的框架，旨在为太空探索应用提供多样化、可扩展的模拟场景，支持AI训练和机器人算法评估。


<details>
  <summary>Details</summary>
Motivation: 随着太空探索的深入，地下环境因其提供庇护、资源获取和科学机会的潜力而日益受到关注。然而，地球上的地下环境难以进入且无法准确代表太阳系中地下环境的多样性，这促使研究者开发一种易于生成这些环境的工具。

Method: 研究人员开发了PLUME，一个程序化生成框架，用于轻松创建3D地下环境。其灵活的结构允许根据对太阳系不断扩展的理解，持续增强各种地下特征。

Result: PLUME能够生成用于AI训练、评估机器人算法、3D渲染以及促进开发探索算法快速迭代的地下环境。论文中展示了PLUME与机器人模拟器结合使用的案例。PLUME已开源并发布在Github上。

Conclusion: PLUME提供了一个灵活且可扩展的工具，用于程序化生成多样化的3D地下环境，这对于推进太空探索中的AI、机器人技术和探索算法的开发至关重要。

Abstract: As space exploration advances, underground environments are becoming
increasingly attractive due to their potential to provide shelter, easier
access to resources, and enhanced scientific opportunities. Although such
environments exist on Earth, they are often not easily accessible and do not
accurately represent the diversity of underground environments found throughout
the solar system. This paper presents PLUME, a procedural generation framework
aimed at easily creating 3D underground environments. Its flexible structure
allows for the continuous enhancement of various underground features, aligning
with our expanding understanding of the solar system. The environments
generated using PLUME can be used for AI training, evaluating robotics
algorithms, 3D rendering, and facilitating rapid iteration on developed
exploration algorithms. In this paper, it is demonstrated that PLUME has been
used along with a robotic simulator. PLUME is open source and has been released
on Github. https://github.com/Gabryss/P.L.U.M.E

</details>


### [186] [Scaling Fabric-Based Piezoresistive Sensor Arrays for Whole-Body Tactile Sensing](https://arxiv.org/abs/2508.20959)
*Curtis C. Johnson,Daniel Webb,David Hill,Marc D. Killpack*

Main category: cs.RO

TL;DR: 本文提出了一种可扩展的触觉传感架构，结合定制电子设备和菊花链SPI总线，实现了大面积、高分辨率的实时触觉反馈，并在全身抓取任务中展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 全身操纵中的触觉传感扩展面临布线复杂性、数据吞吐量和系统可靠性等挑战。

Method: 该研究结合了开源织物传感器和定制读出电子设备（通过硬件缓解将信号串扰降低至3.3%以下）。关键在于引入了一种新颖的菊花链SPI总线拓扑结构，避免了常见无线协议和USB集线器系统布线复杂性的局限性。

Result: 该架构能以超过50 FPS的更新速率，从1平方米感应区域上的8000多个触点同步传输数据，满足实时控制需求。在全身抓取任务中，有实时触觉反馈的机器人能够实现轻柔、稳定的抓取，避免对物体造成结构性损坏，而无反馈时则会导致物体受损。

Conclusion: 这项工作提供了一个鲁棒且特性明确的平台，为未来先进的全身控制和物理人机交互研究奠定了基础。

Abstract: Scaling tactile sensing for robust whole-body manipulation is a significant
challenge, often limited by wiring complexity, data throughput, and system
reliability. This paper presents a complete architecture designed to overcome
these barriers. Our approach pairs open-source, fabric-based sensors with
custom readout electronics that reduce signal crosstalk to less than 3.3%
through hardware-based mitigation. Critically, we introduce a novel,
daisy-chained SPI bus topology that avoids the practical limitations of common
wireless protocols and the prohibitive wiring complexity of USB hub-based
systems. This architecture streams synchronized data from over 8,000 taxels
across 1 square meter of sensing area at update rates exceeding 50 FPS,
confirming its suitability for real-time control. We validate the system's
efficacy in a whole-body grasping task where, without feedback, the robot's
open-loop trajectory results in an uncontrolled application of force that
slowly crushes a deformable cardboard box. With real-time tactile feedback, the
robot transforms this motion into a gentle, stable grasp, successfully
manipulating the object without causing structural damage. This work provides a
robust and well-characterized platform to enable future research in advanced
whole-body control and physical human-robot interaction.

</details>


### [187] [ActLoc: Learning to Localize on the Move via Active Viewpoint Selection](https://arxiv.org/abs/2508.20981)
*Jiajie Li,Boyang Sun,Luca Di Giammarino,Hermann Blum,Marc Pollefeys*

Main category: cs.RO

TL;DR: ActLoc是一种主动视点感知规划框架，通过预测不同视点下的定位精度并将其融入路径规划，显著提升了机器人导航的定位鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人定位系统普遍假设所有视点信息量均等，导致在观察到未映射、模糊或无信息区域时，定位变得不可靠。

Method: ActLoc核心是一个大规模训练的基于注意力模型，该模型编码度量地图和建图时使用的相机姿态，预测任意3D位置下偏航和俯仰方向的定位精度。这些逐点精度分布被整合到路径规划器中，使机器人能够主动选择最大化定位鲁棒性的相机方向，同时遵守任务和运动约束。

Result: ActLoc在单视点选择上达到了最先进的水平，并能有效地推广到全轨迹规划。

Conclusion: ActLoc通过主动视点规划增强了通用机器人导航任务的定位精度，其模块化设计使其易于应用于各种机器人导航和检查任务。

Abstract: Reliable localization is critical for robot navigation, yet most existing
systems implicitly assume that all viewing directions at a location are equally
informative. In practice, localization becomes unreliable when the robot
observes unmapped, ambiguous, or uninformative regions. To address this, we
present ActLoc, an active viewpoint-aware planning framework for enhancing
localization accuracy for general robot navigation tasks. At its core, ActLoc
employs a largescale trained attention-based model for viewpoint selection. The
model encodes a metric map and the camera poses used during map construction,
and predicts localization accuracy across yaw and pitch directions at arbitrary
3D locations. These per-point accuracy distributions are incorporated into a
path planner, enabling the robot to actively select camera orientations that
maximize localization robustness while respecting task and motion constraints.
ActLoc achieves stateof-the-art results on single-viewpoint selection and
generalizes effectively to fulltrajectory planning. Its modular design makes it
readily applicable to diverse robot navigation and inspection tasks.

</details>


### [188] [UltraTac: Integrated Ultrasound-Augmented Visuotactile Sensor for Enhanced Robotic Perception](https://arxiv.org/abs/2508.20982)
*Junhao Gong,Kit-Wa Sou,Shoujie Li,Changqing Guo,Yan Huang,Chuqiao Lyu,Ziwu Song,Wenbo Ding*

Main category: cs.RO

TL;DR: UltraTac是一种新型集成传感器，结合了视觉触觉成像和超声波传感，通过同轴光声架构实现，能够感知物体材料特征、进行近距离探测、材料分类以及纹理-材料双模识别，并应用于机器人抓取。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉触觉传感器虽然能提供高分辨率触觉信息，但无法感知物体的材料特性。

Method: UltraTac通过同轴光声架构将视觉触觉成像与超声波传感结合。设计共享结构组件，确保两种模态的传感区域一致。此外，将声学匹配集成到传统视觉触觉传感器结构中，实现在不影响视觉触觉性能的前提下整合超声波传感。通过触觉反馈，动态调整超声波模块的工作状态以实现灵活的功能协调。

Result: 系统实验证明了三项关键能力：3-8厘米范围内的近距离探测（R²=0.90），材料分类（平均准确率：99.20%），以及在15类别任务上实现92.11%准确率的纹理-材料双模物体识别。最后，将传感器集成到机器人抓取系统中，同时检测容器表面图案和内部内容，验证了其在高级人机交互和精确机器人抓取方面的潜力。

Conclusion: UltraTac传感器通过集成视觉触觉和超声波传感，弥补了传统视觉触觉传感器在材料感知方面的不足，为高级人机交互和精确机器人操作提供了新的可能性。

Abstract: Visuotactile sensors provide high-resolution tactile information but are
incapable of perceiving the material features of objects. We present UltraTac,
an integrated sensor that combines visuotactile imaging with ultrasound sensing
through a coaxial optoacoustic architecture. The design shares structural
components and achieves consistent sensing regions for both modalities.
Additionally, we incorporate acoustic matching into the traditional
visuotactile sensor structure, enabling integration of the ultrasound sensing
modality without compromising visuotactile performance. Through tactile
feedback, we dynamically adjust the operating state of the ultrasound module to
achieve flexible functional coordination. Systematic experiments demonstrate
three key capabilities: proximity sensing in the 3-8 cm range ($R^2=0.90$),
material classification (average accuracy: 99.20%), and texture-material
dual-mode object recognition achieving 92.11% accuracy on a 15-class task.
Finally, we integrate the sensor into a robotic manipulation system to
concurrently detect container surface patterns and internal content, which
verifies its potential for advanced human-machine interaction and precise
robotic manipulation.

</details>


### [189] [Rapid Mismatch Estimation via Neural Network Informed Variational Inference](https://arxiv.org/abs/2508.21007)
*Mateusz Jaszczuk,Nadia Figueroa*

Main category: cs.RO

TL;DR: 该论文提出了一种名为RME（Rapid Mismatch Estimation）的自适应、与控制器无关的概率框架，用于在线估计力矩控制机器人末端执行器的动力学不匹配，从而在没有外部力传感器的情况下，提高物理交互的安全性和任务执行的准确性。


<details>
  <summary>Details</summary>
Motivation: 机器人越来越多地在以人为中心的环境中操作，确保与人、环境或其他机器进行柔软安全的物理交互至关重要。虽然顺从硬件有所帮助，但现有的阻抗控制器（无论是逆动力学还是基于二次规划的）都依赖于准确的机器人及其操纵对象的动力学模型。任何模型不匹配都会导致任务失败和不安全行为。

Method: 本研究专注于阻抗控制器，并引入了RME框架。RME是一种自适应、与控制器无关的概率性方法，它利用机器人本体感觉反馈，在线估计末端执行器的动力学不匹配，且不依赖外部力矩传感器。一个神经网络模型不匹配估计器为变分推断求解器生成先验，该求解器能够快速收敛到未知参数并量化不确定性。

Result: RME能够在大约400毫秒内适应末端执行器质量和质心的突然变化，无论是在静态还是动态环境下。在配备先进被动阻抗控制器的真实7自由度机械臂上进行了验证。在一个协作场景中，机器人与人交互，适应了人类附加未知篮子和动态添加/移除重物时不断变化的动力学，展示了在物理交互过程中快速安全的适应能力，且无需任何外部传感系统。

Conclusion: RRME提供了一种无需外部传感系统，快速且安全地适应力矩控制机器人末端执行器动态变化的解决方案，有效解决了模型不匹配问题，从而在人机协作环境中实现了更安全、更可靠的物理交互。

Abstract: With robots increasingly operating in human-centric environments, ensuring
soft and safe physical interactions, whether with humans, surroundings, or
other machines, is essential. While compliant hardware can facilitate such
interactions, this work focuses on impedance controllers that allow
torque-controlled robots to safely and passively respond to contact while
accurately executing tasks. From inverse dynamics to quadratic
programming-based controllers, the effectiveness of these methods relies on
accurate dynamics models of the robot and the object it manipulates. Any model
mismatch results in task failures and unsafe behaviors. Thus, we introduce
Rapid Mismatch Estimation (RME), an adaptive, controller-agnostic,
probabilistic framework that estimates end-effector dynamics mismatches online,
without relying on external force-torque sensors. From the robot's
proprioceptive feedback, a Neural Network Model Mismatch Estimator generates a
prior for a Variational Inference solver, which rapidly converges to the
unknown parameters while quantifying uncertainty. With a real 7-DoF manipulator
driven by a state-of-the-art passive impedance controller, RME adapts to sudden
changes in mass and center of mass at the end-effector in $\sim400$ ms, in
static and dynamic settings. We demonstrate RME in a collaborative scenario
where a human attaches an unknown basket to the robot's end-effector and
dynamically adds/removes heavy items, showcasing fast and safe adaptation to
changing dynamics during physical interaction without any external sensory
system.

</details>


### [190] [HITTER: A HumanoId Table TEnnis Robot via Hierarchical Planning and Learning](https://arxiv.org/abs/2508.21043)
*Zhi Su,Bike Zhang,Nima Rahmanian,Yuman Gao,Qiayuan Liao,Caitlin Regan,Koushil Sreenath,S. Shankar Sastry*

Main category: cs.RO

TL;DR: 本文提出了一种分层框架，使通用人形机器人能够以亚秒级反应时间进行乒乓球运动，实现对打和连续击球。


<details>
  <summary>Details</summary>
Motivation: 尽管人形机器人在运动和全身控制方面取得了进展，但在需要与动态环境快速交互的操纵任务（如乒乓球）中仍受限制。乒乓球要求在亚秒级反应时间内感知、预测和行动，需要高敏捷性和精确性。

Method: 该研究采用分层框架，结合了模型基规划器和基于强化学习的全身控制器。规划器负责球轨迹预测和球拍目标规划，确定击球位置、速度和时机。控制器生成协调的全身（手臂和腿部）动作，以模仿人类击球并保持稳定性和敏捷性。训练中融入人类运动参考以鼓励自然动作。

Result: 该系统在通用人形机器人上实现了与人类对手连续击球多达106次，并能与另一台人形机器人进行持续对打。这些结果展示了亚秒级反应控制下的真实世界人形机器人乒乓球能力。

Conclusion: 该研究证明了人形机器人能够实现具有亚秒级反应控制的敏捷、交互式行为，是迈向更复杂人形机器人操纵任务的重要一步。

Abstract: Humanoid robots have recently achieved impressive progress in locomotion and
whole-body control, yet they remain constrained in tasks that demand rapid
interaction with dynamic environments through manipulation. Table tennis
exemplifies such a challenge: with ball speeds exceeding 5 m/s, players must
perceive, predict, and act within sub-second reaction times, requiring both
agility and precision. To address this, we present a hierarchical framework for
humanoid table tennis that integrates a model-based planner for ball trajectory
prediction and racket target planning with a reinforcement learning-based
whole-body controller. The planner determines striking position, velocity and
timing, while the controller generates coordinated arm and leg motions that
mimic human strikes and maintain stability and agility across consecutive
rallies. Moreover, to encourage natural movements, human motion references are
incorporated during training. We validate our system on a general-purpose
humanoid robot, achieving up to 106 consecutive shots with a human opponent and
sustained exchanges against another humanoid. These results demonstrate
real-world humanoid table tennis with sub-second reactive control, marking a
step toward agile and interactive humanoid behaviors.

</details>


### [191] [Prompt-to-Product: Generative Assembly via Bimanual Manipulation](https://arxiv.org/abs/2508.21063)
*Ruixuan Liu,Philip Huang,Ava Pun,Kangle Deng,Shobhit Aggarwal,Kevin Tang,Michelle Liu,Deva Ramanan,Jun-Yan Zhu,Jiaoyang Li,Changliu Liu*

Main category: cs.RO

TL;DR: 本文提出了Prompt-to-Product自动化流程，能够从自然语言提示生成并由机器人构建乐高积木装配产品。


<details>
  <summary>Details</summary>
Motivation: 创建装配产品（如乐高积木）需要大量人工努力和专业知识，尤其是在设计和实际构建阶段。

Method: Prompt-to-Product系统以乐高积木为装配平台，接收自然语言的用户设计需求。它首先生成物理上可构建的积木设计，然后利用双臂机器人系统自动构建出真实的装配产品。

Result: 通过全面的用户研究表明，Prompt-to-Product显著降低了将创意转化为装配产品的门槛，并减少了所需的人工投入。

Conclusion: Prompt-to-Product成功地将用户的想象力转化为现实世界的装配产品，极大地简化了装配产品的创建过程。

Abstract: Creating assembly products demands significant manual effort and expert
knowledge in 1) designing the assembly and 2) constructing the product. This
paper introduces Prompt-to-Product, an automated pipeline that generates
real-world assembly products from natural language prompts. Specifically, we
leverage LEGO bricks as the assembly platform and automate the process of
creating brick assembly structures. Given the user design requirements,
Prompt-to-Product generates physically buildable brick designs, and then
leverages a bimanual robotic system to construct the real assembly products,
bringing user imaginations into the real world. We conduct a comprehensive user
study, and the results demonstrate that Prompt-to-Product significantly lowers
the barrier and reduces manual effort in creating assembly products from
imaginative ideas.

</details>


### [192] [Learning on the Fly: Rapid Policy Adaptation via Differentiable Simulation](https://arxiv.org/abs/2508.21065)
*Jiahe Pan,Jiaxu Xing,Rudolf Reiter,Yifan Zhai,Elie Aljalbout,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的在线自适应学习框架，通过在可微分仿真中结合残差动力学学习和实时策略适应，实现策略快速适应真实世界中的未建模效应和干扰，从而有效弥合了仿真到现实的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 在仿真中学习机器人控制策略虽然高效安全，但由于仿真到现实的鸿沟（未建模动力学和环境干扰），策略在真实世界中的性能会下降。现有方法（如域随机化和Real2Sim2Real）要么在分布外条件下表现不佳，要么需要昂贵的离线再训练。因此，需要一种能够快速、在线适应真实世界干扰的方法。

Method: 本文提出了一种在线自适应学习框架，将残差动力学学习与实时策略适应统一在一个可微分仿真中。该框架从一个简单的动力学模型开始，利用真实世界数据持续优化模型以捕捉未建模效应和干扰。优化的动力学模型嵌入可微分仿真，支持梯度反向传播，从而实现比传统强化学习方法更快速、样本效率更高的策略更新。系统所有组件都设计用于快速适应。

Result: 该框架使策略能够在5秒内适应未见的干扰。在敏捷四旋翼飞行器控制任务中，相较于L1-MPC，悬停误差降低了高达81%；相较于DATT，悬停误差降低了55%。此外，在没有显式状态估计的情况下，该方法在基于视觉的控制中也表现出鲁棒性。

Conclusion: 所提出的在线自适应学习框架通过统一残差动力学学习和实时策略适应，成功地解决了仿真到现实的鸿沟问题。它能够快速适应真实世界的未建模效应和干扰，显著提高了策略在真实世界中的性能和鲁棒性，尤其是在敏捷四旋翼控制任务中表现出色。

Abstract: Learning control policies in simulation enables rapid, safe, and
cost-effective development of advanced robotic capabilities. However,
transferring these policies to the real world remains difficult due to the
sim-to-real gap, where unmodeled dynamics and environmental disturbances can
degrade policy performance. Existing approaches, such as domain randomization
and Real2Sim2Real pipelines, can improve policy robustness, but either struggle
under out-of-distribution conditions or require costly offline retraining. In
this work, we approach these problems from a different perspective. Instead of
relying on diverse training conditions before deployment, we focus on rapidly
adapting the learned policy in the real world in an online fashion. To achieve
this, we propose a novel online adaptive learning framework that unifies
residual dynamics learning with real-time policy adaptation inside a
differentiable simulation. Starting from a simple dynamics model, our framework
refines the model continuously with real-world data to capture unmodeled
effects and disturbances such as payload changes and wind. The refined dynamics
model is embedded in a differentiable simulation framework, enabling gradient
backpropagation through the dynamics and thus rapid, sample-efficient policy
updates beyond the reach of classical RL methods like PPO. All components of
our system are designed for rapid adaptation, enabling the policy to adjust to
unseen disturbances within 5 seconds of training. We validate the approach on
agile quadrotor control under various disturbances in both simulation and the
real world. Our framework reduces hovering error by up to 81% compared to
L1-MPC and 55% compared to DATT, while also demonstrating robustness in
vision-based control without explicit state estimation.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [193] [A Hierarchical Signal Coordination and Control System Using a Hybrid Model-based and Reinforcement Learning Approach](https://arxiv.org/abs/2508.20102)
*Xianyue Peng,Shenyang Chen,H. Michael Zhang*

Main category: eess.SY

TL;DR: 本文提出了一种分层交通信号协调与控制方案，结合模型优化与强化学习，以应对城市走廊中保持主干道交通流畅性和适应局部交叉口需求变化的双重挑战。该方案通过高层协调器动态选择策略，中层协调器推导相位约束，以及底层混合信号代理通过强化学习确定信号相位，实现了在不同需求水平下的鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 城市走廊的信号控制面临双重挑战：既要保持主干道交通的顺畅，又要适应局部交叉口不断变化的需求。现有方案难以同时有效解决这两个问题。

Method: 本文提出一个分层交通信号协调与控制方案：
1. **高层协调器 (HLC)**：根据观测和预测需求选择协调策略（最大流量协调 Max-Flow Coordination, MFC 或绿波协调 Green-Wave Coordination, GWC）。
2. **走廊协调器**：根据选定策略推导相位约束。
3. **混合信号代理 (HSA)**：通过带有动作掩码的强化学习（确保可行性）确定信号相位。
该方案使用带有近端策略优化 (PPO) 的分层强化学习来训练 HSA 和 HLC 策略。底层训练三种 HSA 策略（MFC-aware, GWC-aware, pure agent control, PAC），高层 HLC 通过平衡走廊级和全网络性能的多目标奖励进行训练，以动态切换策略。在 SUMO-RLlib 平台上进行开发和评估。

Result: 1. 混合 MFC 在高需求下能最大化吞吐量。
2. 混合 GWC 在各种交通条件下始终能最小化主干道停车次数并保持交通流畅，但可能降低全网络效率。
3. PAC 在中等需求下能改善全网络旅行时间，但在高需求下效果较差。
4. 分层设计实现了自适应策略选择，在所有需求水平下都展现出鲁棒的性能。

Conclusion: 所提出的分层交通信号协调与控制方案，通过整合模型优化和强化学习，并动态选择不同的协调策略，能够有效应对城市走廊交通控制的复杂性。它在不同交通需求水平下表现出强大的适应性和鲁棒性，能够根据具体情况优化吞吐量、减少停车或改善旅行时间。

Abstract: Signal control in urban corridors faces the dual challenge of maintaining
arterial traffic progression while adapting to demand variations at local
intersections. We propose a hierarchical traffic signal coordination and
control scheme that integrates model-based optimization with reinforcement
learning. The system consists of: (i) a High-Level Coordinator (HLC) that
selects coordination strategies based on observed and predicted demand; (ii) a
Corridor Coordinator that derives phase constraints from the selected
strategy-either Max-Flow Coordination (MFC) or Green-Wave Coordination (GWC);
and (iii) Hybrid Signal Agents (HSAs) that determine signal phases via
reinforcement learning with action masking to enforce feasibility. Hierarchical
reinforcement learning with Proximal Policy Optimization (PPO) is used to train
HSA and HLC policies. At the lower level, three HSA policies-MFC-aware,
GWC-aware, and pure agent control (PAC) are trained in conjunction with their
respective coordination strategies. At the higher level, the HLC is trained to
dynamically switch strategies using a multi-objective reward balancing
corridor-level and network-wide performance. The proposed scheme was developed
and evaluated on a SUMO-RLlib platform. Case results show that hybrid MFC
maximizes throughput under heavy demand; hybrid GWC consistently minimizes
arterial stops and maintains progression across diverse traffic conditions but
can reduce network-wide efficiency; and PAC improves network-wide travel time
in moderate demand but is less effective under heavy demand. The hierarchical
design enables adaptive strategy selection, achieving robust performance across
all demand levels.

</details>


### [194] [Regulation-Aware Game-Theoretic Motion Planning for Autonomous Racing](https://arxiv.org/abs/2508.20203)
*Francesco Prignoli,Francesco Borrelli,Paolo Falcone,Mark Pustilnik*

Main category: eess.SY

TL;DR: 本文提出了一种规章感知的运动规划框架（RA-GTP），用于自动驾驶赛车场景，通过博弈论和模型预测控制实现安全且非保守的超车策略。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶赛车需要能够生成安全、有效且符合赛车规则（如路权和防撞责任）的超车策略，而现有方法可能假设对手不交互或不了解规则，导致过于保守或无效的决策。

Method: 每个赛车通过解决一个规章兼容的模型预测控制（MPC）问题来规划，其中赛车规则被编码为混合逻辑动态（MLD）约束。车辆间的交互被形式化为广义纳什均衡问题（GNEP），并通过迭代最佳响应方案近似求解。在此基础上，引入了规章感知博弈论规划器（RA-GTP），其中攻击方会推理防御方受规章约束的行为。

Result: 仿真结果表明，RA-GTP在性能上优于假设对手不交互或不了解规则的基线方法，能够生成更有效的机动策略，同时始终遵守赛车规章。

Conclusion: RA-GTP通过结合规章约束和博弈论，为自动驾驶赛车提供了安全、非保守且有效的超车策略，显著提升了自动赛车在复杂交互场景中的表现。

Abstract: This paper presents a regulation-aware motion planning framework for
autonomous racing scenarios. Each agent solves a Regulation-Compliant Model
Predictive Control problem, where racing rules - such as right-of-way and
collision avoidance responsibilities - are encoded using Mixed Logical
Dynamical constraints. We formalize the interaction between vehicles as a
Generalized Nash Equilibrium Problem (GNEP) and approximate its solution using
an Iterative Best Response scheme. Building on this, we introduce the
Regulation-Aware Game-Theoretic Planner (RA-GTP), in which the attacker reasons
over the defender's regulation-constrained behavior. This game-theoretic layer
enables the generation of overtaking strategies that are both safe and
non-conservative. Simulation results demonstrate that the RA-GTP outperforms
baseline methods that assume non-interacting or rule-agnostic opponent models,
leading to more effective maneuvers while consistently maintaining compliance
with racing regulations.

</details>


### [195] [Neural Spline Operators for Risk Quantification in Stochastic Systems](https://arxiv.org/abs/2508.20288)
*Zhuoyuan Wang,Raffaele Romagnoli,Kamyar Azizzadenesheli,Yorie Nakahira*

Main category: eess.SY

TL;DR: 本文提出了一种名为NeSO的物理信息神经算子（PINO）方法，用于量化具有变异函数系统动力学的长期风险概率，解决了现有方法在处理复杂动态时的局限性，并实现了显著的在线加速。


<details>
  <summary>Details</summary>
Motivation: 在安全关键控制中，准确量化随机系统中的长期风险概率至关重要。然而，现有的基于采样的和基于偏微分方程（PDE）的方法难以处理复杂的变异动力学。现有的物理信息神经网络（PINN）可以处理固定维度的系统参数变化，但无法处理系统动力学中的函数变化。

Method: 本文引入了物理信息神经算子（PINO）方法来解决风险量化问题，学习从变异的函数系统动力学到相应风险概率的映射。具体而言，提出了神经样条算子（NeSO）框架，利用B样条表示来提高训练效率并更好地执行初始和边界条件。同时，提供了NeSO的普适逼近能力的理论分析。

Result: 通过两个案例研究（一个涉及变异函数动力学，另一个涉及高维多智能体动力学），证明了NeSO的有效性及其相对于现有方法的显著在线加速。理论分析也证实了NeSO的普适逼近能力。

Conclusion: NeSO框架及其普适逼近定理有望应用于风险量化之外的其他控制或PDE相关问题，具有广泛的潜在益处。

Abstract: Accurately quantifying long-term risk probabilities in diverse stochastic
systems is essential for safety-critical control. However, existing
sampling-based and partial differential equation (PDE)-based methods often
struggle to handle complex varying dynamics. Physics-informed neural networks
learn surrogate mappings for risk probabilities from varying system parameters
of fixed and finite dimensions, yet can not account for functional variations
in system dynamics. To address these challenges, we introduce physics-informed
neural operator (PINO) methods to risk quantification problems, to learn
mappings from varying \textit{functional} system dynamics to corresponding risk
probabilities. Specifically, we propose Neural Spline Operators (NeSO), a PINO
framework that leverages B-spline representations to improve training
efficiency and achieve better initial and boundary condition enforcements,
which are crucial for accurate risk quantification. We provide theoretical
analysis demonstrating the universal approximation capability of NeSO. We also
present two case studies, one with varying functional dynamics and another with
high-dimensional multi-agent dynamics, to demonstrate the efficacy of NeSO and
its significant online speed-up over existing methods. The proposed framework
and the accompanying universal approximation theorem are expected to be
beneficial for other control or PDE-related problems beyond risk
quantification.

</details>


### [196] [Systolic Array-based Architecture for Low-Bit Integerized Vision Transformers](https://arxiv.org/abs/2508.20334)
*Ching-Yi Lin,Sahil Shah*

Main category: eess.SY

TL;DR: 本文提出了一种低位宽、模型专用加速器，通过策略性地选择高操作复用和低通信开销的任务进行卸载，并采用多脉动阵列和深度流水线设计，显著提高了Transformer推理的吞吐量和能效，优于现有GPU。


<details>
  <summary>Details</summary>
Motivation: Transformer模型部署的推理服务消耗大量能源，并根据处理的token数量收费。因此，最小化功耗和最大化吞吐量成为推理硬件的关键设计目标。然而，GPU虽然常用，但其灵活性导致操作强度低、效率有限，尤其是在现代推理服务高查询/模型比的情况下。

Method: 研究提出了一种低位宽（3位整型）、模型专用加速器。该加速器策略性地选择具有高操作（OP）复用和最小通信开销的任务进行卸载。其设计包含多个具有深度细粒度流水线的脉动阵列和支持多头自注意力（MSA）模块中关键操作的阵列兼容单元。在加速器层面，每个自注意力（SA）头都在单个加速器内进行流水线处理，以增加数据复用并进一步最小化带宽。

Result: 3位整型化模型在CIFAR-10上实现了96.83%的准确率，在ImageNet上实现了77.81%的top-1准确率。在16nm FPGA（Alveo U250）上验证的硬件设计达到了13,568 GigaOps/秒（GOPs/s）的吞吐量和219.4 GOPs/s/W的能效。与同技术GPU（GTX 1080）相比，该设计提供了1.50倍的吞吐量和4.47倍的能效。即使与最先进的GPU（RTX 5090）相比，在吞吐量低87%的情况下，仍实现了20%的能效提升。

Conclusion: 所提出的低位宽、模型专用加速器在Transformer推理中表现出卓越的性能，显著提高了吞吐量和能效，尤其在面对现代推理服务的高查询/模型比挑战时，优于现有GPU解决方案。

Abstract: Transformer-based models are becoming more and more intelligent and are
revolutionizing a wide range of human tasks. To support their deployment, AI
labs offer inference services that consume hundreds of GWh of energy annually
and charge users based on the number of tokens processed. Under this cost
model, minimizing power consumption and maximizing throughput have become key
design goals for the inference hardware. While graphics processing units (GPUs)
are commonly used, their flexibility comes at the cost of low operational
intensity and limited efficiency, especially under the high query-per-model
ratios of modern inference services.
  In this work, we address these challenges by proposing a low-bit,
model-specialized accelerator that strategically selects tasks with high
operation (OP) reuse and minimal communication overhead for offloading. Our
design incorporates multiple systolic arrays with deep, fine-grained pipelines
and array-compatible units that support essential operations in multi-head
self-attention (MSA) module. At the accelerator-level, each self-attention (SA)
head is pipelined within a single accelerator to increase data reuse and
further minimize bandwidth.
  Our 3-bit integerized model achieves 96.83% accuracy on CIFAR-10 and 77.81%
top-1 accuracy on ImageNet. We validate the hardware design on a 16nm FPGA
(Alveo U250), where it delivers 13,568 GigaOps/second (GOPs/s) and 219.4
GOPs/s/W. Compared to a same-technology GPU (GTX 1080), our design offers 1.50x
higher throughput and 4.47x better power efficiency. Even against a
state-of-the-art GPU (RTX 5090), we still achieve 20% better power efficiency
despite having 87% lower throughput.

</details>


### [197] [Delay-adaptive Control of Nonlinear Systems with Approximate Neural Operator Predictors](https://arxiv.org/abs/2508.20367)
*Luke Bhan,Miroslav Krstic,Yuanyuan Shi*

Main category: eess.SY

TL;DR: 本文提出了一种严谨的方法，通过使用学习到的神经算子映射来近似预测器，从而在具有未知且任意长执行器延迟的非线性系统中实现预测器反馈控制器。


<details>
  <summary>Details</summary>
Motivation: 在具有未知和任意长执行器延迟的非线性系统中，预测器在分析上难以处理，这促使研究人员寻求一种有效且可行的实现方法。

Method: 该方法通过一个离线训练的神经算子映射来近似预测器，该映射利用神经网络的快速推理能力在线部署。理论稳定性分析基于神经算子的通用逼近定理和延迟的传输偏微分方程表示。通过Lyapunov-Krasovskii泛函证明了动力系统的半全局实际收敛性。

Result: 研究证明了动力系统的半全局实际收敛性，其收敛性取决于预测器的近似误差和延迟界限。在生物激活/抑制系统上的验证显示，与传统数值方法相比，速度提升了15倍。

Conclusion: 所提出的基于神经算子的预测器反馈方法为具有未知和任意长执行器延迟的非线性系统提供了严谨的稳定性、实际收敛性以及显著的计算加速。

Abstract: In this work, we propose a rigorous method for implementing predictor
feedback controllers in nonlinear systems with unknown and arbitrarily long
actuator delays. To address the analytically intractable nature of the
predictor, we approximate it using a learned neural operator mapping. This
mapping is trained once, offline, and then deployed online, leveraging the fast
inference capabilities of neural networks. We provide a theoretical stability
analysis based on the universal approximation theorem of neural operators and
the transport partial differential equation (PDE) representation of the delay.
We then prove, via a Lyapunov-Krasovskii functional, semi-global practical
convergence of the dynamical system dependent on the approximation error of the
predictor and delay bounds. Finally, we validate our theoretical results using
a biological activator/repressor system, demonstrating speedups of 15 times
compared to traditional numerical methods.

</details>


### [198] [Bootstrap Policy Iteration for Stochastic LQ Tracking with Multiplicative Noise](https://arxiv.org/abs/2508.20394)
*Jiayu Chen,Zhenhui Xu,Xinghu Wang*

Main category: eess.SY

TL;DR: 本文研究了具有乘性噪声的连续时间随机线性系统的最优跟踪控制问题，并提出了一种模型无关的强化学习和数据驱动方法来求解反馈和前馈增益，包括针对状态相关噪声的特殊处理。


<details>
  <summary>Details</summary>
Motivation: 解决具有乘性噪声的连续时间随机线性系统的最优跟踪控制问题，特别是实现模型无关的控制，避免对系统模型参数的精确了解。

Method: 核心框架涉及求解随机代数Riccati方程（反馈增益）和Sylvester方程（前馈增益）。具体方法包括：1) 两阶段自举策略迭代（B-PI）算法，用于从零值启动引导稳定控制增益；2) 数据驱动、离策略强化学习方法，在区间激励条件下确保收敛到最优反馈增益；3) 基于已获得反馈增益的数据驱动前馈计算方法；4) 对于状态相关噪声系统，提出基于影子系统（shadow system）的最优跟踪方法，以消除探测噪声的需要。

Result: 所提出的方法通过数值例子证明了其有效性。确保了最优反馈增益的收敛，并提供了数据驱动的、模型无关的解决方案，包括对状态相关噪声的有效处理。

Conclusion: 本文成功开发了一套针对具有乘性噪声的连续时间随机线性系统的最优跟踪控制方法，实现了模型无关和数据驱动的解决方案，并通过引入影子系统方法解决了状态相关噪声下的探测噪声问题，提高了方法的实用性。

Abstract: This paper studies the optimal tracking control problem for continuous-time
stochastic linear systems with multiplicative noise. The solution framework
involves solving a stochastic algebraic Riccati equation for the feedback gain
and a Sylvester equation for the feedforward gain. To enable model-free optimal
tracking, we first develop a two-phase bootstrap policy iteration (B-PI)
algorithm, which bootstraps a stabilizing control gain from the trivially
initialized zero-value start and proceeds with standard policy iteration.
Building on this algorithm, we propose a data-driven, off-policy reinforcement
learning approach that ensures convergence to the optimal feedback gain under
the interval excitation condition. We further introduce a data-driven method to
compute the feedforward using the obtained feedback gain. Additionally, for
systems with state-dependent noise, we propose a shadow system-based optimal
tracking method to eliminate the need for probing noise. The effectiveness of
the proposed methods is demonstrated through numerical examples.

</details>


### [199] [MegaCacheX: Towards Cost-Effective Hierarchical Collaborative Content Caching in Emerging Mega-Constellations](https://arxiv.org/abs/2508.20433)
*Haoyang Shi,Xing Zhang,Sitong Li,Minghang Li,Xinming Lu,Shaoxiang Xu,Guoquan Wang*

Main category: eess.SY

TL;DR: 本文提出了MegaCacheX，一个分层协作内容分发框架，通过在太空提供云服务实现“地球独立”的内容交付，旨在显著降低全球内容访问延迟并提高成本效益。


<details>
  <summary>Details</summary>
Motivation: 全球内容交付的显著延迟主要源于地面基础设施不足，导致数字鸿沟。部署基于空间的CDN是有效解决之道，但面临物理层动态（如动态拓扑、时变星间链路、有限星载能量）以及现有机制缺乏细粒度内容分类和全局优化的挑战。

Method: MegaCacheX是一个成本效益高的分层协作内容分发框架，直接从太空提供云服务。它利用太阳同步轨道数据中心作为主要内容源，并结合巨型星座中的缓存节点和地面站形成分布式边缘层。该系统通过整合内容流行度、区域用户分布和卫星轨迹预测来优化缓存策略。多层缓存节点作为服务锚点，实现低延迟的无缝内容交付。研究团队在一个基于微服务、容器化的测试平台上实现了原型。

Result: 与基线方法相比，MegaCacheX将全球内容访问延迟降低了约36%，同时保持了成本效益。

Conclusion: MegaCacheX通过其分层协作框架和优化的缓存策略，有效解决了空间内容交付的挑战，显著降低了全球内容访问延迟，并提供了成本高效的“地球独立”云服务，有助于弥合数字鸿沟。

Abstract: Significant latency in global content delivery primarily arises from
insufficient terrestrial infrastructure. Deploying space-based content delivery
networks within emerging mega-constellations provides an effective means to
bridge the digital divide. However, space-based caching faces constraints from
physical-layer dynamics, including dynamic topologies, time-varying
inter-satellite link conditions, and limited onboard energy. In addition,
existing mechanisms often lack fine-grained content categorization and global
optimization. This paper proposes MegaCacheX, a cost-effective hierarchical
framework for collaborative content distribution that achieves
"Earth-independence" by providing cloud services directly from space.
Specifically, data centers in Sun-synchronous orbit act as primary content
sources, while caching nodes in mega-constellations and ground stations
collaboratively form a distributed edge layer. MegaCacheX optimizes caching
strategies by integrating content popularity, regional user distribution, and
satellite trajectory predictions. Multi-tier caching nodes serve as service
anchors, enabling seamless content delivery with low latency. A prototype
implemented on a microservices-based, containerized testbed demonstrates that
MegaCacheX reduces global content access latency by about 36% compared to
baseline approaches, while maintaining cost efficiency.

</details>


### [200] [Joint Contact Planning for Navigation and Communication in GNSS-Libration Point Systems](https://arxiv.org/abs/2508.20479)
*Huan Yan,Juan A. Fraire,Ziqi Yang,Kanglian Zhao,Wenfeng Li,Xiyun Hou,Haohan Li,Yuxuan Miao,Jinjun Zheng,Chengbin Kang,Huichao Zhou,Xinuo Chang,Lu Wang,Linshan Xue*

Main category: eess.SY

TL;DR: 本文提出了一种联合接触计划设计（J-CPD）方案，用于集成GNSS-月球拉格朗日点（LP）星座，以解决异构星间链路持续时间问题，从而增强深空PNT服务。


<details>
  <summary>Details</summary>
Motivation: 现有低轨GNSS星座在深空存在覆盖盲区。将LP卫星与GNSS集成可提供更鲁棒和全面的PNT系统，并将导航和通信服务扩展到地月空间。然而，LP卫星、用户和GNSS卫星之间的长传播延迟导致链路持续时间显著不同，而现有接触计划设计（CPD）方法假设链路持续时间均匀，无法适应这种异构性。

Method: 本文引入了联合接触计划设计（J-CPD）方案，专门处理集成星座中持续时间单位不同的星间链路。主要方法包括：(i) 引入长时隙（地月尺度链路）和短时隙（GNSS尺度链路）；(ii) 采用分层交叉的CPD过程来调度长时隙和短时隙星间链路；(iii) 适应CPD过程的能量驱动链路调度算法。

Result: 在北斗-LP联合星座上的仿真表明，J-CPD在延迟和测距覆盖方面均优于基线FCP方法，同时保持了高用户满意度，并通过可调的势能参数实现了可调节的权衡。据作者所知，这是首个在GNSS-LP系统中联合优化导航和通信的CPD框架。

Conclusion: J-CPD是迈向统一和弹性深空PNT架构的关键一步，能够有效处理GNSS-LP联合星座中异构星间链路的调度问题，显著提升深空导航和通信性能。

Abstract: Deploying satellites at Earth-Moon Libration Points (LPs) addresses the
inherent deep-space coverage gaps of low-altitude GNSS constellations.
Integrating LP satellites with GNSS into a joint constellation enables a more
robust and comprehensive Positioning, Navigation, and Timing (PNT) system,
while also extending navigation and communication services to spacecraft
operating in cislunar space (i.e., users). However, the long propagation delays
between LP satellites, users, and GNSS satellites result in significantly
different link durations compared to those within the GNSS constellation.
Scheduling inter-satellite links (ISLs) is a core task of Contact Plan Design
(CPD). Existing CPD approaches focus exclusively on GNSS constellations,
assuming uniform link durations, and thus cannot accommodate the heterogeneous
link timescales present in a joint GNSS-LP system. To overcome this limitation,
we introduce a Joint CPD (J-CPD) scheme tailored to handle ISLs with differing
duration units across integrated constellations. The key contributions of J-CPD
are: (i):introduction of LongSlots (Earth-Moon scale links) and ShortSlots
(GNSS-scale links); (ii):a hierarchical and crossed CPD process for scheduling
LongSlots and ShortSlots ISLs; (iii):an energy-driven link scheduling algorithm
adapted to the CPD process. Simulations on a joint BeiDou-LP constellation
demonstrate that J-CPD surpasses the baseline FCP method in both delay and
ranging coverage, while maintaining high user satisfaction and enabling tunable
trade-offs through adjustable potential-energy parameters. To our knowledge,
this is the first CPD framework to jointly optimize navigation and
communication in GNSS-LP systems, representing a key step toward unified and
resilient deep-space PNT architectures.

</details>


### [201] [Adaptive Control of Heterogeneous Platoons with Guaranteed Collision Avoidance](https://arxiv.org/abs/2508.20493)
*Ashutosh Chandra Pandey,Sayan Basu Roy,Simone Baldi*

Main category: eess.SY

TL;DR: 本研究提出了一种合作式自适应巡航控制（CACC）框架，用于具有单向通信和异构参数的车队。通过自适应律和引入虚拟车队概念，该框架能确保实际车队的防碰撞性能，而非仅限于参考车队。


<details>
  <summary>Details</summary>
Motivation: 现有的CACC方法在处理具有异构参数和单向通信的车队时，通常只能保证参考车队的防碰撞性能，而无法确保实际车队的防碰撞。这促使研究者寻求一种能直接在实际车队上实现防碰撞的解决方案。

Method: 该研究采用了一套基于集合论模型参考自适应控制（MRAC）的自适应律，使实际（异构）车队收敛到参考（同构）车队。关键创新在于引入了一个仅用于分析而不与实际车队交互的“虚拟车队”概念。稳定性与收敛性通过Lyapunov分析结合虚拟车队概念来确立。

Result: 所提出的方法能够确保实际车队的防碰撞，这与现有技术仅在参考车队动态上保证防碰撞形成对比。此外，该框架的稳定性和收敛性也得到了Lyapunov分析的证明。

Conclusion: 该CACC框架通过自适应律和创新的虚拟车队概念，成功解决了异构车队在单向通信下的防碰撞问题，并能确保实际车队的安全性，显著超越了现有技术水平。

Abstract: This work proposes a framework for Cooperative Adaptive Cruise Control of a
vehicular platoon characterized by unidirectional communication and
heterogeneous parameters. In the proposed framework, the actual (heterogeneous)
platoon is made to converge to a reference (homogeneous) platoon via adaptive
laws designed using of set-theoretic model reference adaptive control. Yet, in
contrast to the state-of-art that is based on ensuring collision avoidance on
the reference platoon dynamics only, the approach we propose can ensure
collision avoidance on the actual platoon dynamics. This result is possible
thanks to the introduction of a novel concept of virtual platoon, only used for
analysis, but that does not interact with the actual platoon. The stability and
convergence properties of the proposed framework are established using
Lyapunov-based analysis in conjunction with the aforementioned virtual platoon
concept.

</details>


### [202] [Local Observability of a Class of Feedforward Neural Networks](https://arxiv.org/abs/2508.20544)
*Yi Yang,Victor G. Lopez,Matthias A. Müller*

Main category: eess.SY

TL;DR: 本文研究了两层前馈神经网络（ReLU激活）的局部可观测性，发现权重通常不可观测，但提出了实现可观测性的充分条件和一种输入设计方法。


<details>
  <summary>Details</summary>
Motivation: 传统的神经网络训练依赖梯度下降，而状态估计技术提供了另一种从控制理论角度确定理想权重的方法，这使得可观测性概念在神经网络训练中变得重要。

Method: 通过评估权重矩阵和输入序列的可观测性秩条件，分析了具有ReLU激活函数的两层前馈神经网络的局部可观测性。

Result: 研究表明，前馈神经网络的权重通常不是局部可观测的。文章提供了导致局部可观测性的网络结构和权重的充分条件，并提出了一种输入设计方法，使权重可区分并能激励邻域内的其他权重。

Conclusion: 通过数值示例验证了研究结果，证实了关于神经网络权重可观测性、充分条件和输入设计方法的发现。

Abstract: Beyond the traditional neural network training methods based on gradient
descent and its variants, state estimation techniques have been proposed to
determine a set of ideal weights from a control-theoretic perspective. Hence,
the concept of observability becomes relevant in neural network training. In
this paper, we investigate local observability of a class of two-layer
feedforward neural networks~(FNNs) with rectified linear unit~(ReLU) activation
functions. We analyze local observability of FNNs by evaluating an
observability rank condition with respect to the weight matrix and the input
sequence. First, we show that, in general, the weights of FNNs are not locally
observable. Then, we provide sufficient conditions on the network structures
and the weights that lead to local observability. Moreover, we propose an input
design approach to render the weights distinguishable and show that this input
also excites other weights inside a neighborhood. Finally, we validate our
results through a numerical example.

</details>


### [203] [Transient Stability Analysis of a Hybrid Grid-Forming and Grid-Following RES System Considering Multi-Mode Control Switching](https://arxiv.org/abs/2508.20552)
*Ruiyuan Zeng,Ruisheng Diao,Fangyuan Sun,Wangqianyun Tang,Junjie Li,Baorong Zhou*

Main category: eess.SY

TL;DR: 本研究揭示了可再生能源（RES）控制切换导致现代电力系统动态行为的复杂性，特别分析了基于GFM/GFL的RES与混合系统主要不稳定模式之间的动态耦合，并提出了量化GFM-RES对GFL-RES动态影响的新判据。


<details>
  <summary>Details</summary>
Motivation: 可再生能源在复杂暂态过程中固有的控制切换，给现代电力系统的动态行为带来了复杂性。因此，需要深入理解这种复杂性，特别是动态耦合和不稳定模式。

Method: 1. 系统性地研究了六种控制组合（GFM-RES的两种模式：NC和CS；GFL-RES的三种模式：NC、LVRT和HVRT）。2. 基于切换系统理论，建立了考虑多模式切换特性的耦合潮流和动态运动模型。3. 采用高精度电磁暂态仿真验证分析框架的正确性。

Result: 1. 揭示了基于GFM/GFL的RES与混合系统主要不稳定模式之间的动态耦合。2. 当GFM-RES和GFL-RES分别超出其P-f和V-f失同步边界时，混合系统表现出两种明显的不稳定模式。3. 首次揭示了GFM-RES引起的GFL-RES的二维时空阻尼特性。4. 提出了一个新颖的判据，用于量化GFM-RES在不同控制组合下对GFL-RES动态的稳定和去稳定影响。

Conclusion: 本研究提供了一个全面的分析框架，用于理解混合电力系统中RES的动态耦合和不稳定模式，揭示了GFM-RES对GFL-RES动态的影响，并提出了一个新的量化判据，为电力系统设计和运行提供了重要见解。

Abstract: The inherent control switching of renewable energy sources (RESs) during
intricate transient processes introduces complexity to the dynamic behavior of
modern power systems. This paper reveals the dynamic coupling between grid
forming (GFM)/grid following (GFL)-based RES and dominant instability modes of
the hybrid system. First, six control combinations are systematically
investigated by pairing the two GFM-RES modes, normal control (NC) and current
saturation (CS), with the three GFL-RES modes: normal control, low voltage
ride-through (LVRT), and high voltage ride-through (HVRT). Based on switching
system theory, the coupled power flow and dynamic motion models are developed
considering multi-mode switching characteristics. It is revealed that the
hybrid system exhibits two distinct instability modes when the GFM-RES and
GFL-RES exceed their P-f and V-f desynchronization boundaries, respectively.
The two-dimensional spatiotemporal damping characteristics of GFL-RES induced
by GFM-RES are also uncovered for the first time. A novel criterion is proposed
to quantify the impact of GFM-RES on GFL-RES dynamics, capturing both its
stabilizing and destabilizing effects under different control combinations.
High-fidelity electromagnetic transient simulations validate the correctness of
the analysis framework.

</details>


### [204] [DMPC-Swarm: Distributed Model Predictive Control on Nano UAV swarms](https://arxiv.org/abs/2508.20553)
*Alexander Gräfe,Joram Eickhoff,Marco Zimmerling,Sebastian Trimpe*

Main category: eess.SY

TL;DR: 本文提出DMPC-SWARM，一种新的无人机群控制方法，它结合了高效无线通信协议和改进的分布式模型预测控制（DMPC）算法，即使在消息丢失情况下也能保证防撞，并在真实硬件上首次实现了该DMPC变体。


<details>
  <summary>Details</summary>
Motivation: 分布式模型预测控制（DMPC）被认为是无人机群安全管理的有前途方法，但现有DMPC方法未能充分利用真正的分布式计算和无线通信在实际硬件上部署，主要原因是缺乏适合移动群体的通信系统和支持分布式计算的架构，同时还要满足无人机的有效载荷限制。

Method: 本文提出了DMPC-SWARM，通过将高效、无状态的低功耗无线通信协议与一种新颖的DMPC算法相结合。该算法即使在消息丢失下也能避免无人机碰撞。它利用事件触发和分布式离板计算，支持纳米无人机，同时保持可扩展性和容错性。

Result: DMPC-SWARM在理论分析中被证明在包括通信延迟和消息丢失在内的现实条件下能保证防撞。研究团队在多达16架纳米四旋翼无人机组成的群体上实现了DMPC-SWARM，首次展示了这些DMPC变体在由真实无线网状网络互连的多个物理设备上进行分布式计算的实现。

Conclusion: DMPC-SWARM为无人机群提供了一种鲁棒、可扩展且容错的防撞解决方案，克服了现有DMPC方法在真实分布式硬件部署上的挑战，使得无人机群能够利用外部计算资源，同时确保了系统的安全性和可靠性。

Abstract: Swarms of unmanned aerial vehicles (UAVs) are increasingly becoming vital to
our society, undertaking tasks such as search and rescue, surveillance and
delivery. A special variant of Distributed Model Predictive Control (DMPC) has
emerged as a promising approach for the safe management of these swarms by
combining the scalability of distributed computation with dynamic swarm motion
control. In this DMPC method, multiple agents solve local optimization problems
with coupled anti-collision constraints, periodically exchanging their
solutions. Despite its potential, existing methodologies using this DMPC
variant have yet to be deployed on distributed hardware that fully utilize true
distributed computation and wireless communication. This is primarily due to
the lack of a communication system tailored to meet the unique requirements of
mobile swarms and an architecture that supports distributed computation while
adhering to the payload constraints of UAVs. We present DMPC-SWARM, a new swarm
control methodology that integrates an efficient, stateless low-power wireless
communication protocol with a novel DMPC algorithm that provably avoids UAV
collisions even under message loss. By utilizing event-triggered and
distributed off-board computing, DMPC-SWARM supports nano UAVs, allowing them
to benefit from additional computational resources while retaining scalability
and fault tolerance. In a detailed theoretical analysis, we prove that
DMPC-SWARM guarantees collision avoidance under realistic conditions, including
communication delays and message loss. Finally, we present DMPC-SWARM's
implementation on a swarm of up to 16 nano-quadcopters, demonstrating the first
realization of these DMPC variants with computation distributed on multiple
physical devices interconnected by a real wireless mesh networks. A video
showcasing DMPC-SWARM is available at http://tiny.cc/DMPCSwarm.

</details>


### [205] [Minimizing AoI in Mobile Edge Computing: Nested Index Policy with Preemptive and Non-preemptive Structure](https://arxiv.org/abs/2508.20564)
*Ning Yang,Yibo Liu,Shuo Chen,Meng Zhang,Haijun Zhang*

Main category: eess.SY

TL;DR: 本文提出了一种基于Restless Multi-Arm Bandit (RMAB)和多层马尔可夫决策过程 (MDP) 的嵌套索引策略，用于在多用户移动边缘计算 (MEC) 环境中最小化信息年龄 (AoI)，该策略在抢占式和非抢占式调度下均具有渐近最优性，并显著优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算 (MEC) 中的实时应用需要高信息新鲜度，而信息年龄 (AoI) 是衡量信息及时性的关键指标。然而，在多用户MEC环境中，由于计算时间的随机性，最小化AoI面临重大挑战。

Method: 研究人员将问题重新表述为Restless Multi-Arm Bandit (RMAB) 问题，并建立了一个多层马尔可夫决策过程 (MDP) 框架来表征MEC系统中的AoI动态。在此基础上，他们提出了一个嵌套索引框架，并设计了一种具有渐近最优性的嵌套索引策略。该策略通过状态分层和索引设计实现高效优化，适用于抢占式和非抢占式调度机制。此外，还导出了嵌套索引的闭式解，以权衡计算复杂度和精度。

Result: 实验结果表明，在非抢占式调度中，与基准方法相比，最优性差距减少了25.43%；在抢占式调度中，差距减少了61.84%。随着系统规模的增加，该策略在两种调度模式下均渐近收敛，特别是在非抢占式结构中提供了接近最优的性能。

Conclusion: 所提出的嵌套索引策略为MEC系统中的AoI最小化提供了一个理论框架，该框架在抢占式和非抢占式调度模式下均具有渐近最优性，并且通过其通用适用性和显著的性能提升，有效地解决了随机计算时间下的AoI优化挑战。

Abstract: Mobile Edge Computing (MEC) leverages computational heterogeneity between
mobile devices and edge nodes to enable real-time applications requiring high
information freshness. The Age-of-Information (AoI) metric serves as a crucial
evaluator of information timeliness in such systems. Addressing AoI
minimization in multi-user MEC environments presents significant challenges due
to stochastic computing times. In this paper, we consider multiple users
offloading tasks to heterogeneous edge servers in an MEC system, focusing on
preemptive and non-preemptive task scheduling mechanisms. The problem is first
reformulated as a Restless Multi-Arm Bandit (RMAB) problem, with a multi-layer
Markov Decision Process (MDP) framework established to characterize AoI
dynamics in the MEC system. Based on the multi-layer MDP, we propose a nested
index framework and design a nested index policy with provably asymptotic
optimality. This establishes a theoretical framework adaptable to various
scheduling mechanisms, achieving efficient optimization through state
stratification and index design in both preemptive and non-preemptive modes.
Finally, the closed-form of the nested index is derived, facilitating
performance trade-offs between computational complexity and accuracy while
ensuring the universal applicability of the nested index policy across both
scheduling modes. The experimental results show that in non-preemptive
scheduling, compared with the benchmark method, the optimality gap is reduced
by 25.43%, while in preemptive scheduling, the gap has reduced by 61.84%. As
the system scale increases, it asymptotically converges in two scheduling modes
and especially provides near-optimal performance in non-preemptive structure.

</details>


### [206] [A Proposal for Yield Improvement with Power Tradeoffs in CMOS LNAs (English Version)](https://arxiv.org/abs/2508.20611)
*J. L. González,J. C. Cruz,R. L. Moreno,D. Vázquez*

Main category: eess.SY

TL;DR: 该论文提出了一种数字可控增益和功耗的低噪声放大器（LNA）架构，旨在减轻CMOS LNA中工艺变异的影响，并实现了更高的良率和低功耗运行。


<details>
  <summary>Details</summary>
Motivation: CMOS低噪声放大器（LNA）的性能易受工艺变异的影响，这导致了生产良率的降低。因此，需要一种能够缓解这种影响的架构。

Method: 研究基于对传统LNA在不同偏置电流下变异性及其对完整接收器性能影响的分析，设计了一种具有数字可控增益和功耗的LNA架构。该架构在130纳米、1.2伏特工艺下实现，并评估了两种与现有内置自测试（BIST）电路兼容的调整策略。

Result: 结果显示，与传统LNA相比，所提出的架构在提高良率的同时，能够保持低功耗运行。

Conclusion: 该研究成功地提出了一种数字可控的LNA架构，能够有效减轻工艺变异的影响，从而提高了LNA的良率并维持了低功耗操作。

Abstract: This paper studies an architecture with digitally controllable gain and power
consumption to mitigate the impact of process variations on CMOS low-noise
amplifiers (LNAs). A \SI{130}{nm}, \SI{1.2}{V} LNA implementing the proposed
architecture is designed based on an analysis of variability in traditional
LNAs under different bias currents and on the corresponding effects on the
performance of a complete receiver. Two different adjustment strategies are
evaluated, both of which are compatible with previously reported built-in
self-test (BIST) circuits. Results show that the proposed architecture enables
yield enhancement while keeping low-power operation compared with traditional
LNAs.

</details>


### [207] [Optimistic vs Pessimistic Uncertainty Model Unfalsification](https://arxiv.org/abs/2508.20669)
*Jannes Hühnerbein,Jad Wehbeh,Eric C. Kerrigan*

Main category: eess.SY

TL;DR: 本文提出了一种新颖的、数据驱动的不确定性模型“不证伪”方法，通过乐观（最小不确定性）和悲观（最大不确定性）两种途径来解释输入输出数据。


<details>
  <summary>Details</summary>
Motivation: 系统不确定性的真实边界和分布通常是未知的，这使得直接识别不确定性模型变得困难。

Method: 研究采用“不证伪”不确定性模型，而非直接识别。具体方法包括：乐观方法（确定能解释给定数据的最小不确定性）和悲观方法（找到数据暗示的最大不确定性）。悲观问题被公式化为半无限规划，并使用局部归约算法求解。

Result: 悲观问题被揭示为半无限规划，并可通过局部归约算法求解。乐观和悲观的不确定性模型不证伪方法在数学上是互为对偶的。这两种方法均在一个带有模拟非线性系统数据的线性不确定模型上进行了测试。

Conclusion: 所提出的乐观和悲观不证伪方法为处理不确定性模型识别提供了一种有效的数据驱动途径，且二者之间存在数学上的对偶关系。

Abstract: We present a novel, input-output data-driven approach to uncertainty model
identification. As the true bounds and distributions of system uncertainties
ultimately remain unknown, we depart from the goal of identifying the
uncertainty model and instead look for minimal concrete statements that can be
made based on an uncertain system model and available input-output data. We
refer to this as unfalsifying an uncertainty model. Two different
unfalsification approaches are taken. The optimistic approach determines the
smallest uncertainties that could explain the given data, while the pessimistic
approach finds the largest possible uncertainties suggested by the data. The
pessimistic problem is revealed to be a semi-infinite program, which is solved
using the local reduction algorithm. It is also shown that the optimistic and
pessimistic approaches to uncertainty model unfalsification are mathematical
duals. Finally, both approaches are tested using an uncertain linear model with
data from a simulated nonlinear system.

</details>


### [208] [Multi-cluster distributed optimization in open multi-agent systems over directed graphs with acknowledgement messages](https://arxiv.org/abs/2508.20715)
*Evagoras Makridis,Gabriele Oliva,Themistoklis Charalambous*

Main category: eess.SY

TL;DR: 本文提出了一种名为OPEN-GT的新型开放式分布式优化算法，用于解决开放多智能体系统（OMAS）中动态拓扑和问题维度变化下的分布式优化问题，通过动态邻居检测和分布式最大共识确保算法的收敛性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 在开放多智能体系统（OMAS）中，智能体动态加入或离开会导致网络拓扑和问题维度持续变化，这不仅对分布式优化算法的收敛性和稳定性构成挑战，还可能使网络分裂成多个集群，每个集群拥有自己的目标函数。

Method: 本文提出了一种名为Open Distributed Optimization Algorithm with Gradient Tracking (OPEN-GT) 的算法。该算法采用：(a) 通过确认消息动态检测活跃出邻居的机制；(b) 在可能不平衡的有向网络中，利用完全分布式的最大共识过程传播智能体离开的信息。

Result: 研究表明，当所有活跃智能体执行OPEN-GT时，每个形成的集群中的优化过程保持一致。如果网络在某个时间点后保持不变，智能体将收敛到其集群范围内的最优解。仿真环境验证了该方法对网络变化的韧性以及在OMAS动态下支持分布式优化的能力。

Conclusion: OPEN-GT算法能够有效地处理开放多智能体系统中动态变化的智能体群体和网络拓扑，确保分布式优化过程的连贯性，并使智能体收敛到集群最优解，展现了其在OMAS动态下的鲁棒性和有效性。

Abstract: In this paper, we tackle the problem of distributed optimization over
directed networks in open multi-agent systems (OMAS), where agents may
dynamically join or leave, causing persistent changes in network topology and
problem dimension. These disruptions not only pose significant challenges to
maintaining convergence and stability in distributed optimization algorithms,
but could also break the network topology into multiple clusters, each one
associated with its own set of objective functions. To address this, we propose
a novel Open Distributed Optimization Algorithm with Gradient Tracking
(OPEN-GT), which employs: (a) a dynamic mechanism for detecting active
out-neighbors through acknowledgement messages, and (b) a fully distributed
max-consensus procedure to spread information regarding agent departures, in
possibly unbalanced directed networks. We show that when all active agents
execute OPEN-GT, the optimization process in each formed cluster remains
consistent, while the agents converge to their cluster-wide optimal solution if
there exists a time after which the network remains unchanged. Finally, we
validate our approach in a simulated environment with dynamically changing
agent populations, demonstrating its resilience to network variations and its
ability to support distributed optimization under OMAS dynamics.

</details>


### [209] [AERO-LQG: Aerial-Enabled Robust Optimization for LQG-Based Quadrotor Flight Controller](https://arxiv.org/abs/2508.20888)
*Daniel Engelsman,Itzik Klein*

Main category: eess.SY

TL;DR: 该研究提出AERO-LQG框架，利用进化策略优化四旋翼飞行器LQG控制器的权重参数，以在悬停模式下实现高能效和高性能控制。


<details>
  <summary>Details</summary>
Motivation: 四旋翼飞行器在灵活性和续航能力之间存在能耗权衡，需要针对特定模式的优化框架。LQG控制器中的权重矩阵选择是关键挑战，缺乏分析指导，目前依赖于穷举或随机搜索，这本质上是一个双层优化问题。

Method: 本工作引入了AERO-LQG（空中鲁棒优化LQG调谐）框架，该框架采用进化策略来精细调整LQG的加权参数。它被应用于四旋翼飞行器飞行的线性化悬停模式。

Result: AERO-LQG在四旋翼飞行器的线性化悬停模式下实现了数倍的性能提升，突显了其在实现高性能、高能效四旋翼控制方面的潜力。

Conclusion: AERO-LQG框架通过进化策略优化LQG权重，为实现高能效、高性能的四旋翼飞行器控制提供了一种有效方法，特别是在悬停模式下表现出显著的性能提升。

Abstract: Quadrotors are indispensable in civilian, industrial, and military domains,
undertaking complex, high-precision tasks once reserved for specialized
systems. Across all contexts, energy efficiency remains a critical constraint:
quadrotors must reconcile the high power demands of agility with the minimal
consumption required for extended endurance. Meeting this trade-off calls for
mode-specific optimization frameworks that adapt to diverse mission profiles.
At their core lie optimal control policies defining error functions whose
minimization yields robust, mission-tailored performance. While solutions are
straightforward for fixed weight matrices, selecting those weights is a far
greater challenge-lacking analytical guidance and thus relying on exhaustive or
stochastic search. This interdependence can be framed as a bi-level
optimization problem, with the outer loop determining weights a priori. This
work introduces an aerial-enabled robust optimization for LQG tuning
(AERO-LQG), a framework employing evolutionary strategy to fine-tune LQG
weighting parameters. Applied to the linearized hovering mode of quadrotor
flight, AERO-LQG achieves performance gains of several tens of percent,
underscoring its potential for enabling high-performance, energy-efficient
quadrotor control. The project is available at GitHub.

</details>


### [210] [Real-Time Tracking Antenna System for Moving Targets](https://arxiv.org/abs/2508.20905)
*Adham Saad,Aya Sherif Nassef,Mahmoud Mohamed Elshahed,Mohamed Ismail Ahmed*

Main category: eess.SY

TL;DR: 本文提出并实现了一种紧凑、经济高效的相控阵天线系统，能够进行实时波束控制，适用于动态目标跟踪应用。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够实时波束控制的紧凑、经济高效的相控阵天线系统，以满足动态目标跟踪、无线跟踪、雷达和卫星通信终端的需求。

Method: 该系统采用4x4矩形微带贴片阵列，利用先进的波束成形技术和到达方向（DoA）估计算法。它在Rogers 6010.2LM基板上制造，并使用市售组件。

Result: 系统在方位角和仰角平面均实现了±42°的宽角度扫描，并在高角度覆盖范围和一致增益性能之间取得了平衡。它展示了可重现性和可扩展性，并因使用市售组件而具有成本效益。

Conclusion: 所设计的相控阵天线系统是一款紧凑、经济高效、可重现且可扩展的解决方案，非常适合无线跟踪、雷达和卫星通信终端，并对研究和原型设计具有实际应用价值。

Abstract: This paper presents the design and implementation of a compact,
cost-effective phased array antenna system. It is capable of real-time
beam-steering for dynamic target-tracking applications. The system employs a
4$\times$4 rectangular microstrip patch array, utilizing advanced beamforming
techniques and a Direction of Arrival (DoA) estimation algorithm. It achieves
$\pm 42^{\circ}$ wide-angle scanning in both azimuth and elevation planes. The
design emphasizes a balance between high angular coverage and consistent gain
performance. This makes it suitable for wireless tracking, radar, and satellite
communication terminals. Fabricated on Rogers 6010.2LM substrate, the system
demonstrates reproducibility and scalability. All components are sourced
locally to ensure practical deployment. The system is built using commercially
available components, highlighting its affordability for research and
prototyping purposes.

</details>


### [211] [Missing Money and Market-Based Adequacy in Deeply Decarbonized Power Systems with Long-Duration Energy Storage](https://arxiv.org/abs/2508.20913)
*Adam Suski,Elina Spyrou,Richard Green*

Main category: eess.SY

TL;DR: 在深度脱碳的电力系统中，长时储能(LDES)对保障供电充足性至关重要。本研究探讨了容量市场(CMs)在有大量LDES参与时，能否提供有效的投资信号，并发现校准良好的CMs可实现接近高效的投资，但在深度脱碳系统中其有效性会降低。


<details>
  <summary>Details</summary>
Motivation: 深度脱碳的电力系统日益依赖长时储能(LDES)来确保供电充足性。然而，最初为热力发电设计的容量市场(CMs)能否在储能成为核心参与者时提供有效的投资信号，是一个核心挑战。现有针对可变可再生能源和短时储能的认证方法，在大量LDES渗透的CMs中的有效性尚未得到充分探索。

Method: 本研究扩展了一个两阶段随机均衡投资模型，内生化了基于持续时间的连续储能容量认证。该模型应用于英国案例，使用了40年的天气驱动需求和可再生能源发电数据，并考虑了不同的排放限制。

Result: 研究结果表明，校准良好的容量市场可以维持接近高效的投资，并减轻收入波动。然而，在深度脱碳的系统中，其有效性会降低，这凸显了容量市场在支持大规模LDES方面的潜力和监管挑战。

Conclusion: 容量市场在支持长时储能方面具有潜力，能够促进接近高效的投资并稳定收入。但在深度脱碳的电力系统中，其有效性会下降，表明在实现大规模LDES部署方面仍存在显著的监管挑战。

Abstract: The ability of deeply decarbonised power systems to ensure adequacy may
increasingly depend on long-duration energy storage (LDES). A central challenge
is whether capacity markets (CMs), originally designed around thermal
generation, can provide efficient investment signals when storage becomes a
central participant. While recent studies have advanced methods for accrediting
variable renewables and short-duration storage, the effectiveness of these
methods in CMs with substantial LDES penetration remains largely unexplored. To
address this gap, we extend a two-stage stochastic equilibrium investment model
by endogenising continuous, duration-based capacity accreditation for storage
and apply it to a Great Britain-based case using 40 years of weather-driven
demand and renewable profiles under varying emission limits. Results show that
well-calibrated CMs can sustain near-efficient investment and mitigate revenue
volatility, but their effectiveness diminishes in deeply decarbonized systems,
underscoring both their potential and the regulatory challenges of supporting
large-scale LDES.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [212] [A Machine Learning Approach to Volumetric Computations of Solid Pulmonary Nodules](https://arxiv.org/abs/2508.20127)
*Yihan Zhou,Haocheng Huang,Yue Yu,Jianhui Shang*

Main category: eess.IV

TL;DR: 该研究提出了一种结合多尺度3D卷积神经网络和亚型特异性偏差校正的先进框架，用于精确评估CT扫描中肺结节的体积，显著提高了准确性和处理速度，以改善早期肺癌检测。


<details>
  <summary>Details</summary>
Motivation: 早期肺癌检测依赖于CT扫描中肺结节的准确体积评估。然而，传统方法（如CTR和球形近似）因结节形状和密度的变异性导致估计不一致，存在局限性。

Method: 研究提出了一种先进框架，结合了多尺度3D卷积神经网络（CNN）和亚型特异性偏差校正，用于精确的体积估计。该模型在上海市胸科医院的364个病例数据集上进行了训练和评估。

Result: 该方法相对于手动非线性回归，平均绝对偏差为8.0%，且每次扫描的推理时间不到20秒。这优于现有深度学习和半自动化流程（通常误差为25%至30%，处理时间超过60秒），实现了超过17个百分点的误差降低和三倍的处理速度提升。

Conclusion: 这些进展提供了一种高度准确、高效且可扩展的工具，用于临床肺结节筛查和监测，有望显著改善早期肺癌检测。

Abstract: Early detection of lung cancer is crucial for effective treatment and relies
on accurate volumetric assessment of pulmonary nodules in CT scans. Traditional
methods, such as consolidation-to-tumor ratio (CTR) and spherical
approximation, are limited by inconsistent estimates due to variability in
nodule shape and density. We propose an advanced framework that combines a
multi-scale 3D convolutional neural network (CNN) with subtype-specific bias
correction for precise volume estimation. The model was trained and evaluated
on a dataset of 364 cases from Shanghai Chest Hospital. Our approach achieved a
mean absolute deviation of 8.0 percent compared to manual nonlinear regression,
with inference times under 20 seconds per scan. This method outperforms
existing deep learning and semi-automated pipelines, which typically have
errors of 25 to 30 percent and require over 60 seconds for processing. Our
results show a reduction in error by over 17 percentage points and a threefold
acceleration in processing speed. These advancements offer a highly accurate,
efficient, and scalable tool for clinical lung nodule screening and monitoring,
with promising potential for improving early lung cancer detection.

</details>


### [213] [Data-Efficient Point Cloud Semantic Segmentation Pipeline for Unimproved Roads](https://arxiv.org/abs/2508.20135)
*Andrew Yarovoi,Christopher R. Valenta*

Main category: eess.IV

TL;DR: 本文提出了一种数据高效的点云分割流水线和训练框架，用于在有限域内数据下对非铺装路面及其他七个类别进行鲁棒分割。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在挑战性、低数据场景下（特别是针对非铺装路面）进行鲁棒3D语义分割的难题，尤其是在域内监督数据有限的情况下。

Method: 该方法采用两阶段训练框架：首先，一个基于投影的卷积神经网络在公共城市数据集和少量精心策划的域内数据集混合上进行预训练；然后，一个轻量级预测头仅在域内数据上进行微调。此外，还探索了将Point Prompt Training应用于批量归一化层、Manifold Mixup作为正则化器以及结合直方图归一化环境光来提升性能。

Result: 仅使用50个标记的域内点云，与域内数据上的朴素训练相比，该方法将平均交并比（mIoU）从33.5%提高到51.8%，整体准确率从85.5%提高到90.8%。结果表明，跨多个数据集进行预训练是提高泛化能力和在有限域内监督下实现鲁棒分割的关键。

Conclusion: 本研究展示了一个在挑战性、低数据场景下进行鲁棒3D语义分割的实用框架，并强调了多数据集预训练在提升数据效率和泛化能力方面的重要性。

Abstract: In this case study, we present a data-efficient point cloud segmentation
pipeline and training framework for robust segmentation of unimproved roads and
seven other classes. Our method employs a two-stage training framework: first,
a projection-based convolutional neural network is pre-trained on a mixture of
public urban datasets and a small, curated in-domain dataset; then, a
lightweight prediction head is fine-tuned exclusively on in-domain data. Along
the way, we explore the application of Point Prompt Training to batch
normalization layers and the effects of Manifold Mixup as a regularizer within
our pipeline. We also explore the effects of incorporating histogram-normalized
ambients to further boost performance. Using only 50 labeled point clouds from
our target domain, we show that our proposed training approach improves mean
Intersection-over-Union from 33.5% to 51.8% and the overall accuracy from 85.5%
to 90.8%, when compared to naive training on the in-domain data. Crucially, our
results demonstrate that pre-training across multiple datasets is key to
improving generalization and enabling robust segmentation under limited
in-domain supervision. Overall, this study demonstrates a practical framework
for robust 3D semantic segmentation in challenging, low-data scenarios. Our
code is available at: https://github.com/andrewyarovoi/MD-FRNet.

</details>


### [214] [Global Motion Corresponder for 3D Point-Based Scene Interpolation under Large Motion](https://arxiv.org/abs/2508.20136)
*Junru Lin,Chirag Vashist,Mikaela Angelina Uy,Colton Stearns,Xuan Luo,Leonidas Guibas,Ke Li*

Main category: eess.IV

TL;DR: 本文提出了一种名为全局运动对应器（GMC）的新方法，能够鲁棒地处理动态场景插值中的大运动，并实现平滑过渡。


<details>
  <summary>Details</summary>
Motivation: 现有动态场景插值方法通常假设连续时间步之间的运动量很小，可以通过线性模型局部近似。然而，即使是轻微偏离这一小运动假设，也会导致传统技术失效。

Method: GMC通过学习一元势场来预测到共享规范空间的SE(3)映射，从而平衡对应性、空间和语义平滑性以及局部刚性。

Result: 当两个状态经历大全局运动时，GMC在3D场景插值方面显著优于现有基线方法。此外，GMC还具备其他基线方法不具备的外推能力。

Conclusion: GMC有效解决了现有方法在处理大运动动态场景插值时的局限性，实现了更鲁棒和平滑的过渡，并扩展了外推功能。

Abstract: Existing dynamic scene interpolation methods typically assume that the motion
between consecutive timesteps is small enough so that displacements can be
locally approximated by linear models. In practice, even slight deviations from
this small-motion assumption can cause conventional techniques to fail. In this
paper, we introduce Global Motion Corresponder (GMC), a novel approach that
robustly handles large motion and achieves smooth transitions. GMC learns unary
potential fields that predict SE(3) mappings into a shared canonical space,
balancing correspondence, spatial and semantic smoothness, and local rigidity.
We demonstrate that our method significantly outperforms existing baselines on
3D scene interpolation when the two states undergo large global motions.
Furthermore, our method enables extrapolation capabilities where other baseline
methods cannot.

</details>


### [215] [Is the medical image segmentation problem solved? A survey of current developments and future directions](https://arxiv.org/abs/2508.20139)
*Guoping Xu,Jayaram K. Udupa,Jax Luo,Songlin Zhao,Yajun Yu,Scott B. Raymond,Hao Peng,Lipeng Ning,Yogesh Rathi,Wei Liu,You Zhang*

Main category: eess.IV

TL;DR: 本文深入回顾了过去十年深度学习驱动的医学图像分割进展，探讨了其核心原理和七个关键发展维度，旨在激发未来的创新。


<details>
  <summary>Details</summary>
Motivation: 尽管医学图像分割取得了快速进展，但仍需评估当前模型在多大程度上克服了现有挑战，以及仍存在哪些不足。

Method: 本文对过去十年医学图像分割的进展进行了深入回顾，分析了多尺度分析、注意力机制和先验知识集成等核心原理，并围绕七个关键维度（如从监督学习到半/无监督学习、从器官分割到病灶分割、多模态集成、基础模型、确定性到概率性分割、2D到3D/4D分割以及从模型调用到分割智能体）组织讨论。

Result: 通过对核心原理和七个关键发展维度的考察，本文提供了深度学习医学图像分割轨迹的全面概述。此外，还提供了一个持续更新的相关文献和开源资源库。

Conclusion: 该综述全面展现了深度学习医学图像分割的现状和发展轨迹，旨在启发未来的创新并支持持续的研究。

Abstract: Medical image segmentation has advanced rapidly over the past two decades,
largely driven by deep learning, which has enabled accurate and efficient
delineation of cells, tissues, organs, and pathologies across diverse imaging
modalities. This progress raises a fundamental question: to what extent have
current models overcome persistent challenges, and what gaps remain? In this
work, we provide an in-depth review of medical image segmentation, tracing its
progress and key developments over the past decade. We examine core principles,
including multiscale analysis, attention mechanisms, and the integration of
prior knowledge, across the encoder, bottleneck, skip connections, and decoder
components of segmentation networks. Our discussion is organized around seven
key dimensions: (1) the shift from supervised to semi-/unsupervised learning,
(2) the transition from organ segmentation to lesion-focused tasks, (3)
advances in multi-modality integration and domain adaptation, (4) the role of
foundation models and transfer learning, (5) the move from deterministic to
probabilistic segmentation, (6) the progression from 2D to 3D and 4D
segmentation, and (7) the trend from model invocation to segmentation agents.
Together, these perspectives provide a holistic overview of the trajectory of
deep learning-based medical image segmentation and aim to inspire future
innovation. To support ongoing research, we maintain a continually updated
repository of relevant literature and open-source resources at
https://github.com/apple1986/medicalSegReview

</details>


### [216] [UltraEar: a multicentric, large-scale database combining ultra-high-resolution computed tomography and clinical data for ear diseases](https://arxiv.org/abs/2508.20141)
*Ruowei Tang,Pengfei Zhao,Xiaoguang Li,Ning Xu,Yue Cheng,Mengshi Zhang,Zhixiang Wang,Zhengyu Zhang,Hongxia Yin,Heyu Ding,Shusheng Gong,Yuhe Liu,Zhenchang Wang*

Main category: eess.IV

TL;DR: UltraEar是一个大规模、多中心、超高分辨率CT（U-HRCT）耳部疾病数据库，旨在推动放射学研究、AI算法开发、教学和多机构合作。


<details>
  <summary>Details</summary>
Motivation: 耳部疾病影响全球数十亿人，CT在诊断和治疗中至关重要。研究旨在建立一个大规模、高分辨率、多中心且包含全面临床数据的耳部疾病数据库，以克服现有资源的局限性。

Method: UltraEar从2020年至2035年期间，从11家三级医院招募患者，收集各向同性0.1毫米超高分辨率CT图像以及包括人口统计学、听力学、手术记录和病理学发现等在内的全面临床信息。该数据库涵盖多种耳部疾病。数据经过标准化预处理（几何校准、图像标注、多结构分割）和匿名化处理，并通过专家小组会议协调数据收集和管理，安全存储在离线云系统中。

Result: UltraEar成功建立了一个前所未有的超高分辨率参考图谱，兼具技术保真度和临床相关性，覆盖了广泛的耳科疾病，为全球耳科研究社区提供了宝贵资源。

Conclusion: UltraEar数据库具有巨大潜力，可促进放射学研究、支持人工智能算法的开发和验证、作为耳科影像学培训的教育工具，并支持多机构协作研究。该数据库将持续更新和扩展，以确保长期可用性。

Abstract: Ear diseases affect billions of people worldwide, leading to substantial
health and socioeconomic burdens. Computed tomography (CT) plays a pivotal role
in accurate diagnosis, treatment planning, and outcome evaluation. The
objective of this study is to present the establishment and design of UltraEar
Database, a large-scale, multicentric repository of isotropic 0.1 mm
ultra-high-resolution CT (U-HRCT) images and associated clinical data dedicated
to ear diseases. UltraEar recruits patients from 11 tertiary hospitals between
October 2020 and October 2035, integrating U-HRCT images, structured CT
reports, and comprehensive clinical information, including demographics,
audiometric profiles, surgical records, and pathological findings. A broad
spectrum of otologic disorders is covered, such as otitis media, cholesteatoma,
ossicular chain malformation, temporal bone fracture, inner ear malformation,
cochlear aperture stenosis, enlarged vestibular aqueduct, and sigmoid sinus
bony deficiency. Standardized preprocessing pipelines have been developed for
geometric calibration, image annotation, and multi-structure segmentation. All
personal identifiers in DICOM headers and metadata are removed or anonymized to
ensure compliance with data privacy regulation. Data collection and curation
are coordinated through monthly expert panel meetings, with secure storage on
an offline cloud system. UltraEar provides an unprecedented
ultra-high-resolution reference atlas with both technical fidelity and clinical
relevance. This resource has significant potential to advance radiological
research, enable development and validation of AI algorithms, serve as an
educational tool for training in otologic imaging, and support
multi-institutional collaborative studies. UltraEar will be continuously
updated and expanded, ensuring long-term accessibility and usability for the
global otologic research community.

</details>


### [217] [Efficient and Privacy-Protecting Background Removal for 2D Video Streaming using iPhone 15 Pro Max LiDAR](https://arxiv.org/abs/2508.20250)
*Jessica Kinnevan,Naifa Alqahtani,Toral Chauhan*

Main category: eess.IV

TL;DR: 该研究探讨了在消费级移动设备上使用LiDAR技术进行背景移除和图像合成，并指出其在不同光照条件下的优势和未来潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的背景移除方法（如色度抠像和基于AI的模型）受光照条件影响，而LiDAR的深度信息独立于光照，在低光和良好光照环境下均表现良好，因此作者旨在探索LiDAR作为替代方案的潜力。

Method: 研究整合了iPhone 15 Pro Max上的LiDAR和彩色摄像头，采用基于GPU的图像处理。用户界面和后端开发使用Apple的SwiftUI和Swift框架，实时图像增强则通过Metal着色器语言（MSL）实现，达到iPhone标准的每秒60帧流媒体速率。

Result: 该技术实现了在iPhone上以60帧/秒的速度进行实时图像增强（背景移除）。主要限制是深度数据流带宽将深度图分辨率限制在320x240，以及LiDAR红外激光在某些材料上反射深度不准确的固有局限性。

Conclusion: 如果移动设备上的LiDAR分辨率能提升至与彩色图像分辨率匹配，LiDAR技术有望成为视频应用和摄影中背景移除的首选方法。

Abstract: Light Detection and Ranging (LiDAR) technology in consumer-grade mobile
devices can be used as a replacement for traditional background removal and
compositing techniques. Unlike approaches such as chroma keying and trained AI
models, LiDAR's depth information is independent of subject lighting, and
performs equally well in low-light and well-lit environments. We integrate the
LiDAR and color cameras on the iPhone 15 Pro Max with GPU-based image
processing. We use Apple's SwiftUI and Swift frameworks for user interface and
backend development, and Metal Shader Language (MSL) for realtime image
enhancement at the standard iPhone streaming frame rate of 60 frames per
second. The only meaningful limitations of the technology are the streaming
bandwidth of the depth data, which currently reduces the depth map resolution
to 320x240, and any pre-existing limitations of the LiDAR IR laser to reflect
accurate depth from some materials. If the LiDAR resolution on a mobile device
like the iPhone can be improved to match the color image resolution, LiDAR
could feasibly become the preeminent method of background removal for video
applications and photography.

</details>


### [218] [GENRE-CMR: Generalizable Deep Learning for Diverse Multi-Domain Cardiac MRI Reconstruction](https://arxiv.org/abs/2508.20600)
*Kian Anvari Hamedani,Narges Razizadeh,Shahabedin Nabavi,Mohsen Ebrahimi Moghaddam*

Main category: eess.IV

TL;DR: GENRE-CMR 是一种基于 GAN 的残差深度展开重建框架，通过结合边缘感知区域损失和统计分布对齐损失，显著提升了加速心血管磁共振 (CMR) 图像重建的保真度和泛化能力，超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 加速心血管磁共振 (CMR) 图像重建面临扫描时间与图像质量之间的权衡，尤其是在不同采集设置下泛化能力不足，这是一个关键挑战。

Method: 本文提出了 GENRE-CMR，一个基于生成对抗网络 (GAN) 的架构。它采用残差深度展开重建框架，将迭代优化展开为一系列卷积子网络，并加入残差连接以促进特征传播。此外，集成了两种损失函数：1) 边缘感知区域 (EAR) 损失，引导网络关注结构信息区域并防止模糊；2) 统计分布对齐 (SDA) 损失，通过对称 KL 散度公式正则化不同数据分布的特征空间。

Result: GENRE-CMR 在训练数据和未见数据上均超越了现有最先进的方法，在不同加速因子和采样轨迹的未见分布上实现了 0.9552 的 SSIM 和 38.90 dB 的 PSNR。消融研究证实了每个提出组件对重建质量和泛化能力的贡献。

Conclusion: GENRE-CMR 框架为高质量 CMR 重建提供了一个统一且稳健的解决方案，为在异构采集协议下实现临床适应性部署铺平了道路。

Abstract: Accelerated Cardiovascular Magnetic Resonance (CMR) image reconstruction
remains a critical challenge due to the trade-off between scan time and image
quality, particularly when generalizing across diverse acquisition settings. We
propose GENRE-CMR, a generative adversarial network (GAN)-based architecture
employing a residual deep unrolled reconstruction framework to enhance
reconstruction fidelity and generalization. The architecture unrolls iterative
optimization into a cascade of convolutional subnetworks, enriched with
residual connections to enable progressive feature propagation from shallow to
deeper stages. To further improve performance, we integrate two loss functions:
(1) an Edge-Aware Region (EAR) loss, which guides the network to focus on
structurally informative regions and helps prevent common reconstruction
blurriness; and (2) a Statistical Distribution Alignment (SDA) loss, which
regularizes the feature space across diverse data distributions via a symmetric
KL divergence formulation. Extensive experiments confirm that GENRE-CMR
surpasses state-of-the-art methods on training and unseen data, achieving
0.9552 SSIM and 38.90 dB PSNR on unseen distributions across various
acceleration factors and sampling trajectories. Ablation studies confirm the
contribution of each proposed component to reconstruction quality and
generalization. Our framework presents a unified and robust solution for
high-quality CMR reconstruction, paving the way for clinically adaptable
deployment across heterogeneous acquisition protocols.

</details>


### [219] [Efficient Fine-Tuning of DINOv3 Pretrained on Natural Images for Atypical Mitotic Figure Classification in MIDOG 2025](https://arxiv.org/abs/2508.21041)
*Guillaume Balezo,Raphaël Bourgade,Thomas Walter*

Main category: eess.IV

TL;DR: 本研究评估了在自然图像上预训练的DINOv3-H+视觉Transformer，通过LoRA进行微调和大量数据增强，有效应用于组织病理学中的非典型有丝分裂图像分类，并在MIDOG 2025挑战赛中取得了0.8871的平衡准确率，为该任务提供了强大的基线。


<details>
  <summary>Details</summary>
Motivation: 非典型有丝分裂像（AMFs）是异常细胞分裂的标志，与不良预后相关，但由于其低发生率、细微形态和观察者间差异，检测仍然困难。MIDOG 2025挑战赛旨在为AMF分类提供一个跨多个领域的基准。

Method: 本研究评估了最近发布的DINOv3-H+视觉Transformer，该模型在自然图像上进行了预训练。研究人员使用低秩适应（LoRA，650k可训练参数）和广泛的数据增强技术对其进行了微调，并在MIDOG 2025初步测试集上进行了性能评估。

Result: 尽管存在领域差异，DINOv3模型能有效地迁移到组织病理学领域，并在初步测试集上实现了0.8871的平衡准确率。

Conclusion: 这些结果突出了DINOv3预训练的鲁棒性，并表明当与参数高效的微调（LoRA）结合时，它为MIDOG 2025挑战赛中的非典型有丝分裂分类提供了一个强大的基线。

Abstract: Atypical mitotic figures (AMFs) are markers of abnormal cell division
associated with poor prognosis, yet their detection remains difficult due to
low prevalence, subtle morphology, and inter-observer variability. The MIDOG
2025 challenge introduces a benchmark for AMF classification across multiple
domains. In this work, we evaluate the recently published DINOv3-H+ vision
transformer, pretrained on natural images, which we fine-tuned using low-rank
adaptation (LoRA, 650k trainable parameters) and extensive augmentation.
Despite the domain gap, DINOv3 transfers effectively to histopathology,
achieving a balanced accuracy of 0.8871 on the preliminary test set. These
results highlight the robustness of DINOv3 pretraining and show that, when
combined with parameter-efficient fine-tuning, it provides a strong baseline
for atypical mitosis classification in MIDOG 2025.

</details>
