<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 78]
- [cs.CV](#cs.CV) [Total: 74]
- [cs.CL](#cs.CL) [Total: 78]
- [cs.RO](#cs.RO) [Total: 34]
- [eess.SY](#eess.SY) [Total: 3]
- [eess.IV](#eess.IV) [Total: 5]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Latent Generative Solvers for Generalizable Long-Term Physics Simulation](https://arxiv.org/abs/2602.11229)
*Zituo Chen,Haixu Wu,Sili Deng*

Main category: cs.AI

TL;DR: 本文提出了一种名为 Latent Generative Solvers (LGS) 的两阶段框架，用于在异构偏微分方程 (PDE) 系统上进行长时序模拟。该框架利用预训练的 VAE 将 PDE 状态映射到共享的潜在物理空间，然后使用 Transformer 学习概率性潜在动力学。通过引入“不确定性旋钮”和“流强迫”机制，LGS 能够校正模型的漂移并提高长期预测的稳定性。LGS 在长时序模拟方面表现优于确定性神经算子基线，并且计算成本显著降低，同时也能在不同分布的数据集上进行有效适应。


<details>
  <summary>Details</summary>
Motivation: 现有神经 PDE 求解器在长时序模拟中存在滚转漂移的问题，并且通用性和效率有待提高。作者旨在开发一种更可靠、更具泛化能力且计算效率更高的神经 PDE 求解方法，以满足长期预测和科学工作流的需求。

Method: LGS 框架包含两个阶段：1. 使用预训练的 VAE 将不同 PDE 系统的状态映射到一个共享的潜在物理空间。2. 使用 Transformer 模型学习该潜在空间中的概率性动力学，并采用流匹配进行训练。关键机制包括：不确定性旋钮（在训练和推理中扰动潜在输入以校正漂移）和流强迫（利用模型生成的轨迹更新系统描述符以对齐训练/测试条件）。模型在包含 12 种 PDE 族的约 250 万条轨迹上进行了预训练。

Result: LGS 在短时序模拟上能够媲美强确定性神经算子基线，同时在长时序模拟中显著减少了滚转漂移。与非生成式基线相比，LGS 的计算量（FLOPs）降低了高达 70 倍。此外，LGS 在有限的微调预算下，能够有效地适应分布外（out-of-distribution）的 $256^2$ Kolmogorov 流数据集。

Conclusion: LGS 提供了一种实用且通用的方法，用于构建不确定性感知（uncertainty-aware）的神经 PDE 求解器。该方法在长期预测的可靠性和效率方面表现出色，并能够适应不同的 PDE 系统和数据分布，为科学计算提供了有力的支持。

Abstract: We study long-horizon surrogate simulation across heterogeneous PDE systems. We introduce Latent Generative Solvers (LGS), a two-stage framework that (i) maps diverse PDE states into a shared latent physics space with a pretrained VAE, and (ii) learns probabilistic latent dynamics with a Transformer trained by flow matching. Our key mechanism is an uncertainty knob that perturbs latent inputs during training and inference, teaching the solver to correct off-manifold rollout drift and stabilizing autoregressive prediction. We further use flow forcing to update a system descriptor (context) from model-generated trajectories, aligning train/test conditioning and improving long-term stability. We pretrain on a curated corpus of $\sim$2.5M trajectories at $128^2$ resolution spanning 12 PDE families. LGS matches strong deterministic neural-operator baselines on short horizons while substantially reducing rollout drift on long horizons. Learning in latent space plus efficient architectural choices yields up to \textbf{70$\times$} lower FLOPs than non-generative baselines, enabling scalable pretraining. We also show efficient adaptation to an out-of-distribution $256^2$ Kolmogorov flow dataset under limited finetuning budgets. Overall, LGS provides a practical route toward generalizable, uncertainty-aware neural PDE solvers that are more reliable for long-term forecasting and downstream scientific workflows.

</details>


### [2] [Explaining AI Without Code: A User Study on Explainable AI](https://arxiv.org/abs/2602.11159)
*Natalia Abarca,Andrés Carvallo,Claudia López Moncada,Felipe Bravo-Marquez*

Main category: cs.AI

TL;DR: 本研究在无代码机器学习平台DashAI中集成了一个以用户为中心的可解释AI模块，结合了PDP、PFI和KernelSHAP三种技术。用户研究表明，该模块对机器学习新手和专家都表现出高任务成功率，并且能提升用户对模型预测的理解和信任度。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习模型在敏感领域的应用日益广泛，但其决策过程缺乏透明度。现有的可解释AI方法通常需要专业技术知识，限制了非技术用户的使用。特别是在旨在普及AI的无代码ML平台中，可解释性功能尤为缺乏。

Method: 该研究在DashAI（一个开源无代码ML平台）中集成了一个可解释AI模块。该模块整合了三种互补的技术：偏依赖图（PDP）、排列特征重要性（PFI）和KernelSHAP，并将其应用于表格分类任务。随后进行了一项用户研究，邀请了20名机器学习新手和专家参与评估模块的可用性及其对解释的影响。

Result: 用户研究结果显示：(i) 在所有可解释性任务中，任务成功率均达到80%以上；(ii) 在解释满意度量表（ESS）上，新手对解释的有用性、准确性和可信度评分较高，而专家则对解释的充分性和完整性更为挑剔；(iii) 解释提高了自动化信任量表（TiA）上的感知可预测性和置信度，且新手比专家表现出更高的信任度。

Conclusion: 研究结果突显了在无代码ML领域实现可解释AI的核心挑战：既要让新手易于理解，又要满足专家对解释充分性的要求。本研究提出的集成方案在一定程度上解决了这一挑战，并为未来无代码ML平台的可解释性设计提供了参考。

Abstract: The increasing use of Machine Learning (ML) in sensitive domains such as healthcare, finance, and public policy has raised concerns about the transparency of automated decisions. Explainable AI (XAI) addresses this by clarifying how models generate predictions, yet most methods demand technical expertise, limiting their value for novices. This gap is especially critical in no-code ML platforms, which seek to democratize AI but rarely include explainability. We present a human-centered XAI module in DashAI, an open-source no-code ML platform. The module integrates three complementary techniques, which are Partial Dependence Plots (PDP), Permutation Feature Importance (PFI), and KernelSHAP, into DashAI's workflow for tabular classification. A user study (N = 20; ML novices and experts) evaluated usability and the impact of explanations. Results show: (i) high task success ($\geq80\%$) across all explainability tasks; (ii) novices rated explanations as useful, accurate, and trustworthy on the Explanation Satisfaction Scale (ESS, Cronbach's $α$ = 0.74, a measure of internal consistency), while experts were more critical of sufficiency and completeness; and (iii) explanations improved perceived predictability and confidence on the Trust in Automation scale (TiA, $α$ = 0.60), with novices showing higher trust than experts. These findings highlight a central challenge for XAI in no-code ML, making explanations both accessible to novices and sufficiently detailed for experts.

</details>


### [3] [On Decision-Valued Maps and Representational Dependence](https://arxiv.org/abs/2602.11295)
*Gil Raitses*

Main category: cs.AI

TL;DR: 本文提出了决策值映射的概念，并开发了DecisionDB基础设施来记录、回放和审计不同数据表示在计算引擎下产生结果的一致性，通过内容和持久化存储的工件来保证结果的可重现性。


<details>
  <summary>Details</summary>
Motivation: 计算引擎在处理相同数据的不同表示时，可能会产生不同的离散结果，某些表示会保持结果不变，而另一些则会完全改变结果。研究的动机在于如何系统地理解和管理这种不确定性，并确保计算结果的可信度和可复现性。

Method: 本文形式化了决策值映射的概念，并描述了DecisionDB基础设施。DecisionDB使用从内容和存储在一次性写入形式的工件中计算出的标识符来记录、回放和审计表示与离散结果之间的关系。通过确定性回放，可以从存储的工件中精确地恢复每个记录的决策标识符。

Result: 该方法将表示空间划分为持久化区域和边界，并将决策重用视为一个可机械检查的条件。这意味着可以根据表示的特性来判断其对计算结果的影响，并自动化决策重用的验证过程。

Conclusion: 决策值映射提供了一种新的方式来理解和量化不同数据表示对计算结果的影响。DecisionDB基础设施能够提供一个可靠的框架来记录、回放和审计这些关系，从而实现对决策重用的机械检查，增强了计算结果的可信度和可审计性。

Abstract: A computational engine applied to different representations of the same data can produce different discrete outcomes, with some representations preserving the result and others changing it entirely. A decision-valued map records which representations preserve the outcome and which change it, associating each member of a declared representation family with the discrete result it produces. This paper formalizes decision-valued maps and describes DecisionDB, an infrastructure that logs, replays and audits these relationships using identifiers computed from content and artifacts stored in write-once form. Deterministic replay recovers each recorded decision identifier exactly from stored artifacts, with all three identifying fields matching their persisted values. The contribution partitions representation space into persistence regions and boundaries, and treats decision reuse as a mechanically checkable condition.

</details>


### [4] [Voxtral Realtime](https://arxiv.org/abs/2602.11298)
*Alexander H. Liu,Andy Ehrenberg,Andy Lo,Chen-Yo Sun,Guillaume Lample,Jean-Malo Delignon,Khyathi Raghavi Chandu,Patrick von Platen,Pavankumar Reddy Muddireddy,Rohin Arora,Sanchit Gandhi,Sandeep Subramanian,Soham Ghosh,Srijan Mishra,Abhinav Rastogi,Alan Jeffares,Albert Jiang,Alexandre Sablayrolles,Amélie Héliou,Andrew Bai,Angele Lenglemetz,Anmol Agarwal,Anton Eliseev,Antonia Calvi,Arjun Majumdar,Baptiste Bout,Baptiste Rozière,Baudouin De Monicault,Benjamin Tibi,Clémence Lanfranchi,Connor Chen,Corentin Barreau,Corentin Sautier,Cyprien Courtot,Darius Dabert,Diego de las Casas,Elliot Chane-Sane,Enguerrand Paquin,Faruk Ahmed,Federico Baldassarre,Gabrielle Berrada,Gaëtan Ecrepont,Gauthier Guinet,Genevieve Hayes,Georgii Novikov,Giada Pistilli,Guillaume Martin,Gunjan Dhanuka,Gunshi Gupta,Han Zhou,Indraneel Mukherjee,Irene Zhang,Jaeyoung Kim,Jan Ludziejewski,Jason Rute,Joachim Studnia,John Harvill,Jonas Amar,Josselin Somerville Roberts,Julien Tauran,Karmesh Yadav,Kartik Khandelwal,Kush Jain,Laurence Aitchison,Léonard Blier,Lingxiao Zhao,Louis Martin,Lucile Saulnier,Luyu Gao,Maarten Buyl,Manan Sharma,Margaret Jennings,Marie Pellat,Mark Prins,Mathieu Poirée,Mathilde Guillaumin,Matthieu Dinot,Matthieu Futeral,Maxime Darrin,Maximilian Augustin,Mert Unsal,Mia Chiquier,Nathan Grinsztajn,Neha Gupta,Olivier Bousquet,Olivier Duchenne,Patricia Wang,Paul Jacob,Paul Wambergue,Paula Kurylowicz,Philomène Chagniot,Pierre Stock,Piotr Miłoś,Prateek Gupta,Pravesh Agrawal,Quentin Torroba,Ram Ramrakhya,Rishi Shah,Romain Sauvestre,Roman Soletskyi,Rosalie Millner,Sagar Vaze,Samuel Humeau,Siddharth Gandhi,Sumukh Aithal,Szymon Antoniak,Teven Le Scao,Théo Cachet,Theo Simon Sorg,Thibaut Lavril,Thomas Chabal,Thomas Foubert,Thomas Robert,Thomas Wang,Tim Lawson,Tom Bewley,Tom Edwards,Tyler Wang,Valeriia Nemychnikova,Van Phung,Vedant Nanda,Victor Jouault,Virgile Richard,Vladislav Bataev,Wassim Bouaziz,Wen-Ding Li,William Marshall,Xinghui Li,Xingran Guo,Xinyu Yang,Yannic Neuhaus,Yihan Wang,Zaccharie Ramzi,Zhenlin Xu*

Main category: cs.AI

TL;DR: Voxtral Realtime 是一个端到端训练的原生流式自动语音识别模型，延迟低于一秒，但语音转录质量与离线模型相当，并且支持13种语言。


<details>
  <summary>Details</summary>
Motivation: 现有流式语音识别方法通常通过分块或滑动窗口来适应离线模型，这可能影响实时转录的质量和延迟。研究动机在于开发一个原生为流式设计的模型，在保证低延迟的同时达到与顶级离线模型相媲美的转录质量。

Method: 该模型采用端到端流式训练，并引入了显式的音频和文本流对齐。其架构基于延迟流建模框架，包含了一个新的因果音频编码器和用于改进延迟条件化的Ada RMS-Norm。模型在大规模、跨13种语言的数据集上进行了预训练。

Result: 在480毫秒的延迟下，Voxtral Realtime 的性能与目前广泛使用的离线转录系统 Whisper 相当。

Conclusion: Voxtral Realtime 成功实现了低延迟（亚秒级）和高质量（媲美离线模型）的原生流式自动语音识别，并且支持多语言，为实时语音转录应用提供了新的解决方案。研究者已将模型权重以 Apache 2.0 许可开源。

Abstract: We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency. Unlike approaches that adapt offline models through chunking or sliding windows, Voxtral Realtime is trained end-to-end for streaming, with explicit alignment between audio and text streams. Our architecture builds on the Delayed Streams Modeling framework, introducing a new causal audio encoder and Ada RMS-Norm for improved delay conditioning. We scale pretraining to a large-scale dataset spanning 13 languages. At a delay of 480ms, Voxtral Realtime achieves performance on par with Whisper, the most widely deployed offline transcription system. We release the model weights under the Apache 2.0 license.

</details>


### [5] [The PBSAI Governance Ecosystem: A Multi-Agent AI Reference Architecture for Securing Enterprise AI Estates](https://arxiv.org/abs/2602.11301)
*John M. Willis*

Main category: cs.AI

TL;DR: 本文提出了一个名为PBSAI（Practitioners Blueprint for Secure AI）的多代理参考架构，用于保护企业和超大规模AI系统。该架构通过十二个领域的分类和边界代理家族来组织职责，并通过共享上下文信封和结构化输出契约来协调工具和策略。PBSAI整合了分析监控、协调防御和自适应响应等系统安全技术，并提供了轻量级形式模型以保证可追溯性、来源可靠性和人工干预。


<details>
  <summary>Details</summary>
Motivation: 现有AI治理和安全框架（如NIST AI风险管理框架）虽然提出了原则，但缺乏针对多代理AI防御系统可实施的架构。随着企业越来越多地部署复杂的AI系统，迫切需要一种能够应对这些新挑战的架构。

Method: 本文提出的PBSAI架构是一个多代理参考架构。它将AI estate的治理和安全职责划分为十二个领域，并定义了能够介导工具和策略的代理家族。这些代理通过共享上下文信封（context envelopes）和结构化输出契约（structured output contracts）进行交互。该架构还纳入了分析监控、协调防御和自适应响应等系统安全技术，并使用轻量级形式模型来确保系统的可追溯性、来源可靠性和人工干预。

Result: PBSAI架构被证明可以与NIST AI RMF功能保持一致，并能在企业安全运营中心（SOC）和超大规模防御环境中应用。该架构为构建一个安全、可信赖且可追溯的AI系统治理生态系统提供了基础。

Conclusion: PBSAI为保护企业和超大规模AI estate提供了一个结构化、以证据为中心的参考架构。该架构旨在促进一个开放的生态系统发展，并为未来的实证验证奠定基础，以应对日益复杂的AI安全挑战。

Abstract: Enterprises are rapidly deploying large language models, retrieval augmented generation pipelines, and tool using agents into production, often on shared high performance computing clusters and cloud accelerator platforms that also support defensive analytics. These systems increasingly function not as isolated models but as AI estates: socio technical systems spanning models, agents, data pipelines, security tooling, human workflows, and hyperscale infrastructure. Existing governance and security frameworks, including the NIST AI Risk Management Framework and systems security engineering guidance, articulate principles and risk functions but do not provide implementable architectures for multi agent, AI enabled cyber defense.
  This paper introduces the Practitioners Blueprint for Secure AI (PBSAI) Governance Ecosystem, a multi agent reference architecture for securing enterprise and hyperscale AI estates. PBSAI organizes responsibilities into a twelve domain taxonomy and defines bounded agent families that mediate between tools and policy through shared context envelopes and structured output contracts. The architecture assumes baseline enterprise security capabilities and encodes key systems security techniques, including analytic monitoring, coordinated defense, and adaptive response. A lightweight formal model of agents, context envelopes, and ecosystem level invariants clarifies the traceability, provenance, and human in the loop guarantees enforced across domains. We demonstrate alignment with NIST AI RMF functions and illustrate application in enterprise SOC and hyperscale defensive environments. PBSAI is proposed as a structured, evidence centric foundation for open ecosystem development and future empirical validation.

</details>


### [6] [Dissecting Subjectivity and the "Ground Truth" Illusion in Data Annotation](https://arxiv.org/abs/2602.11318)
*Sheza Munir,Benjamin Mah,Krisha Kalsi,Shivani Kapania,Julian Posada,Edith Law,Ding Wang,Syed Ishtiaque Ahmed*

Main category: cs.AI

TL;DR: 该论文通过系统性文献回顾，分析了当前机器学习“事实真相”范式中数据标注存在的“共识陷阱”，揭示了位置可识别性不足、模型中介标注导致的锚定偏见、以及地理霸权带来的西方中心主义等问题，并提出构建关注人类经验多样性的多元化标注基础设施的路线图。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于对机器学习中“事实真相”范式基础的质疑，认为其将人类分歧视为技术噪声而非重要的社会技术信号，并试图揭示数据标注实践中导致“共识陷阱”的机制。

Method: 采用系统性文献回顾的方法，分析了2020-2025年间在七个顶级会议（ACL, AIES, CHI, CSCW, EAAMO, FAccT, NeurIPS）上发表的研究。通过多阶段的筛选方法，最终纳入346篇论文进行质性综合。使用反思性主题分析（reflexive thematic analysis）来揭示数据标注中的系统性问题。

Result: 研究发现，位置可识别性不足、转向“人类即验证者”的模型架构（尤其是模型中介标注）、锚定偏见以及地理霸权（将西方规范强加为普适标准）是导致“共识陷阱”的主要原因。此外，边缘化数据工作者为了避免经济处罚，倾向于优先满足请求者要求而非诚实表达主观意见。模型将文化多元性误解为随机误差（“噪声传感器”谬误）。

Conclusion: 作者认为，分歧应被视为构建文化胜任模型的高保真信号，而非随机误差。为了解决当前存在的系统性问题，作者提出了一种多元化标注基础设施的路线图，其目标不再是发现唯一的“正确”答案，而是描绘人类经验的多样性。

Abstract: In machine learning, "ground truth" refers to the assumed correct labels used to train and evaluate models. However, the foundational "ground truth" paradigm rests on a positivistic fallacy that treats human disagreement as technical noise rather than a vital sociotechnical signal. This systematic literature review analyzes research published between 2020 and 2025 across seven premier venues: ACL, AIES, CHI, CSCW, EAAMO, FAccT, and NeurIPS, investigating the mechanisms in data annotation practices that facilitate this "consensus trap". Our identification phase captured 30,897 records, which were refined via a tiered keyword filtration schema to a high-recall corpus of 3,042 records for manual screening, resulting in a final included corpus of 346 papers for qualitative synthesis. Our reflexive thematic analysis reveals that systemic failures in positional legibility, combined with the recent architectural shift toward human-as-verifier models, specifically the reliance on model-mediated annotations, introduce deep-seated anchoring bias and effectively remove human voices from the loop. We further demonstrate how geographic hegemony imposes Western norms as universal benchmarks, often enforced by the performative alignment of precarious data workers who prioritize requester compliance over honest subjectivity to avoid economic penalties. Critiquing the "noisy sensor" fallacy, where statistical models misdiagnose cultural pluralism as random error, we argue for reclaiming disagreement as a high-fidelity signal essential for building culturally competent models. To address these systemic tensions, we propose a roadmap for pluralistic annotation infrastructures that shift the objective from discovering a singular "right" answer to mapping the diversity of human experience.

</details>


### [7] [GHOST: Unmasking Phantom States in Mamba2 via Grouped Hidden-state Output-aware Selection & Truncation](https://arxiv.org/abs/2602.11408)
*Michael Menezes,Anastasios Kyrillidis*

Main category: cs.AI

TL;DR: 提出了一种名为 GHOST 的结构化剪枝框架，通过在推理时利用前向传播统计数据来近似控制理论中的平衡截断，从而在不增加反向传播开销的情况下，有效减少 Mamba2 模型的状态维度，并降低推理开销。


<details>
  <summary>Details</summary>
Motivation: Mamba2 模型虽然通过增加状态维度增强了时间建模能力，但其高昂的推理开销在自回归生成时会造成带宽瓶颈，而现有的剪枝方法无法有效解决这个问题。

Method: GHOST 是一种结构化剪枝框架，它通过联合衡量状态的可控性和可观测性，利用仅有的前向传播统计数据来近似控制理论中的平衡截断。这种方法无需反向传播。

Result: 在 1.3 亿至 27 亿参数的模型上，GHOST 实现了 50% 的状态维度缩减，同时在 WikiText-2 数据集上，困惑度（perplexity）仅增加约 1 个点。

Conclusion: GHOST 是一种高效且有效的结构化剪枝方法，能够在显著降低 Mamba2 模型状态维度的同时，保持模型性能，解决了 Mamba2 推理开销过大的问题。

Abstract: While Mamba2's expanded state dimension enhances temporal modeling, it incurs substantial inference overhead that saturates bandwidth during autoregressive generation. Standard pruning methods fail to address this bottleneck: unstructured sparsity leaves activations dense, magnitude-based selection ignores runtime dynamics, and gradient-based methods impose prohibitive costs. We introduce GHOST (Grouped Hidden-state Output-aware Selection and Truncation), a structured pruning framework that approximates control-theoretic balanced truncation using only forward-pass statistics. By jointly measuring controllability and observability, GHOST rivals the fidelity of gradient-based methods without requiring backpropagation. As a highlight, on models ranging from 130M to 2.7B parameters, our approach achieves a 50\% state-dimension reduction with approximately 1 perplexity point increase on WikiText-2. Code is available at https://anonymous.4open.science/r/mamba2_ghost-7BCB/.

</details>


### [8] [Bi-Level Prompt Optimization for Multimodal LLM-as-a-Judge](https://arxiv.org/abs/2602.11340)
*Bo Pan,Xuan Kan,Kaitai Zhang,Yan Yan,Shunwen Tan,Zihao He,Zixin Ding,Junjie Wu,Liang Zhao*

Main category: cs.AI

TL;DR: 本研究提出了一种名为BLPO的双层提示优化框架，用于提高大型语言模型（LLM）在评估AI生成图像时的准确性，解决了因上下文窗口限制导致的图像评估瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM评估方法在与人类判断保持一致性方面存在挑战，尤其是在多模态评估场景下。现有的自动提示优化（APO）方法主要关注文本评估，在多模态领域尚未得到充分研究。多模态模型处理图像时存在上下文窗口限制，阻碍了有效的提示优化。

Method: 提出BLPO（Bi-Level Prompt Optimization）框架，该框架将图像转换为文本表示，同时保留评估相关的视觉线索。通过双层优化方法，同时优化裁判提示（judge prompt）和图像到文本提示（I2T prompt），以在有限的上下文预算下保持评估保真度。

Result: 在四个数据集和三个LLM裁判上进行的实验表明，BLPO方法能够有效地提高LLM在评估AI生成图像时的准确性。

Conclusion: BLPO框架通过将图像转换为文本表示并采用双层优化策略，有效解决了多模态LLM作为裁判在评估AI生成图像时面临的上下文窗口限制问题，提高了评估的准确性和效率。

Abstract: Large language models (LLMs) have become widely adopted as automated judges for evaluating AI-generated content. Despite their success, aligning LLM-based evaluations with human judgments remains challenging. While supervised fine-tuning on human-labeled data can improve alignment, it is costly and inflexible, requiring new training for each task or dataset. Recent progress in auto prompt optimization (APO) offers a more efficient alternative by automatically improving the instructions that guide LLM judges. However, existing APO methods primarily target text-only evaluations and remain underexplored in multimodal settings. In this work, we study auto prompt optimization for multimodal LLM-as-a-judge, particularly for evaluating AI-generated images. We identify a key bottleneck: multimodal models can only process a limited number of visual examples due to context window constraints, which hinders effective trial-and-error prompt refinement. To overcome this, we propose BLPO, a bi-level prompt optimization framework that converts images into textual representations while preserving evaluation-relevant visual cues. Our bi-level optimization approach jointly refines the judge prompt and the I2T prompt to maintain fidelity under limited context budgets. Experiments on four datasets and three LLM judges demonstrate the effectiveness of our method.

</details>


### [9] [AgentNoiseBench: Benchmarking Robustness of Tool-Using LLM Agents Under Noisy Condition](https://arxiv.org/abs/2602.11348)
*Ruipeng Wang,Yuxin Chen,Yukai Wang,Chang Wu,Junfeng Fang,Xiaodong Cai,Qi Gu,Hui Su,An Zhang,Xiang Wang,Xunliang Cai,Tat-Seng Chua*

Main category: cs.AI

TL;DR: 本文提出了AgentNoiseBench框架，用于评估大型语言模型（LLM）代理在存在噪声的真实世界环境中的鲁棒性。研究发现，现有模型在模拟的嘈杂环境下性能下降明显，揭示了其对现实干扰的敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在基准测试中表现出色，但在真实世界复杂且不完美的复杂环境中性能下降，主要是因为训练和评估方法忽略了真实交互中的随机性和噪声。因此，需要一个框架来系统地评估代理在噪声环境下的鲁棒性。

Method: 1. 分析真实世界场景中的偏差和不确定性，并将环境噪声分为用户噪声和工具噪声。2. 开发一个自动化管道，向现有的代理中心基准测试注入可控噪声，同时保持任务的可解性。3. 利用该管道对多种模型进行广泛评估。

Result: 研究结果显示，在不同噪声条件下，各种模型（包括不同架构和参数规模的模型）的性能存在一致的下降，突显了当前代理模型对真实环境扰动的敏感性。

Conclusion: 现有的LLM代理模型对现实世界环境中的噪声非常敏感，其性能会受到用户和工具噪声的显著影响。AgentNoiseBench框架为未来研究代理在复杂、不完美环境中的鲁棒性提供了重要的评估工具。

Abstract: Recent advances in large language models have enabled LLM-based agents to achieve strong performance on a variety of benchmarks. However, their performance in real-world deployments often that observed on benchmark settings, especially in complex and imperfect environments. This discrepancy largely arises because prevailing training and evaluation paradigms are typically built on idealized assumptions, overlooking the inherent stochasticity and noise present in real-world interactions. To bridge this gap, we introduce AgentNoiseBench, a framework for systematically evaluating the robustness of agentic models under noisy environments. We first conduct an in-depth analysis of biases and uncertainties in real-world scenarios and categorize environmental noise into two primary types: user-noise and tool-noise. Building on this analysis, we develop an automated pipeline that injects controllable noise into existing agent-centric benchmarks while preserving task solvability. Leveraging this pipeline, we perform extensive evaluations across a wide range of models with diverse architectures and parameter scales. Our results reveal consistent performance variations under different noise conditions, highlighting the sensitivity of current agentic models to realistic environmental perturbations.

</details>


### [10] [Pushing Forward Pareto Frontiers of Proactive Agents with Behavioral Agentic Optimization](https://arxiv.org/abs/2602.11351)
*Yihang Yao,Zhepeng Cen,Haohong Lin,Shiqi Liu,Zuxin Liu,Jiacheng Zhu,Zhang-Wei Hong,Laixi Shi,Ding Zhao*

Main category: cs.AI

TL;DR: 提出了一种名为BAO的代理强化学习框架，通过行为增强和行为正则化来平衡任务性能和用户参与度，用于训练能够进行主动推理和信息收集、同时避免低效交互的LLM代理。


<details>
  <summary>Details</summary>
Motivation: 现有的代理强化学习方法在平衡LLM代理的任务性能和用户参与度方面存在挑战，被动代理难以适应用户意图，而过度依赖人类反馈会降低用户满意度。

Method: 提出BAO框架，结合了行为增强（以丰富主动推理和信息收集能力）和行为正则化（以抑制低效或冗余交互并使代理行为与用户期望保持一致）。

Result: 在UserRL基准套件的多个任务上，BAO显著优于主动代理强化学习基线，并且在性能上可与商业LLM代理相媲美甚至更优。

Conclusion: BAO是一种有效的框架，可以训练出在复杂多轮场景中表现主动且与用户对齐的LLM代理。

Abstract: Proactive large language model (LLM) agents aim to actively plan, query, and interact over multiple turns, enabling efficient task completion beyond passive instruction following and making them essential for real-world, user-centric applications. Agentic reinforcement learning (RL) has recently emerged as a promising solution for training such agents in multi-turn settings, allowing interaction strategies to be learned from feedback. However, existing pipelines face a critical challenge in balancing task performance with user engagement, as passive agents can not efficiently adapt to users' intentions while overuse of human feedback reduces their satisfaction. To address this trade-off, we propose BAO, an agentic RL framework that combines behavior enhancement to enrich proactive reasoning and information-gathering capabilities with behavior regularization to suppress inefficient or redundant interactions and align agent behavior with user expectations. We evaluate BAO on multiple tasks from the UserRL benchmark suite, and demonstrate that it substantially outperforms proactive agentic RL baselines while achieving comparable or even superior performance to commercial LLM agents, highlighting its effectiveness for training proactive, user-aligned LLM agents in complex multi-turn scenarios. Our website: https://proactive-agentic-rl.github.io/.

</details>


### [11] [ReplicatorBench: Benchmarking LLM Agents for Replicability in Social and Behavioral Sciences](https://arxiv.org/abs/2602.11354)
*Bang Nguyen,Dominik Soós,Qian Ma,Rochana R. Obadage,Zack Ranjan,Sai Koneru,Timothy M. Errington,Shakhlo Nematova,Sarah Rajtmajer,Jian Wu,Meng Jiang*

Main category: cs.AI

TL;DR: 本文提出了ReplicatorBench，一个用于评估AI代理在科学论文复现能力的新型基准，该基准包含可复现和不可复现的研究，并涵盖了数据提取、实验设计和结果解释等多个阶段。同时，本文还提出了ReplicatorAgent作为基准的代理框架，并通过实验发现当前LLM代理在实验设计和执行方面表现良好，但在数据检索方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理评估基准主要关注计算复现性，忽视了数据可用性的不一致性和非复现性研究的评估，也未涵盖复现过程的评估。研究旨在弥补这些不足，提供一个更全面、更贴近现实的AI代理复现能力评估框架。

Method: 提出了ReplicatorBench基准，包含可复现和不可复现的研究以及人类验证的真实案例。构建了ReplicatorAgent代理框架，配备了网络搜索和沙盒环境交互工具，以完成ReplicatorBench中的任务。在LLMs、编程语言和代码访问级别等不同配置下评估了ReplicatorAgent。

Result: 评估结果表明，当前的LLM代理能够有效地设计和执行计算实验，但它们在检索复现所需资源（如新数据）方面存在困难。

Conclusion: ReplicatorBench为评估AI代理在科学研究复现方面的能力提供了一个更全面和现实的平台。虽然LLM代理在计算实验方面取得了进展，但其在数据检索等关键环节仍需改进，以更好地模拟人类研究者的复现过程。

Abstract: The literature has witnessed an emerging interest in AI agents for automated assessment of scientific papers. Existing benchmarks focus primarily on the computational aspect of this task, testing agents' ability to reproduce or replicate research outcomes when having access to the code and data. This setting, while foundational, (1) fails to capture the inconsistent availability of new data for replication as opposed to reproduction, and (2) lacks ground-truth diversity by focusing only on reproducible papers, thereby failing to evaluate an agent's ability to identify non-replicable research. Furthermore, most benchmarks only evaluate outcomes rather than the replication process. In response, we introduce ReplicatorBench, an end-to-end benchmark, including human-verified replicable and non-replicable research claims in social and behavioral sciences for evaluating AI agents in research replication across three stages: (1) extraction and retrieval of replication data; (2) design and execution of computational experiments; and (3) interpretation of results, allowing a test of AI agents' capability to mimic the activities of human replicators in real world. To set a baseline of AI agents' capability, we develop ReplicatorAgent, an agentic framework equipped with necessary tools, like web search and iterative interaction with sandboxed environments, to accomplish tasks in ReplicatorBench. We evaluate ReplicatorAgent across four underlying large language models (LLMs), as well as different design choices of programming language and levels of code access. Our findings reveal that while current LLM agents are capable of effectively designing and executing computational experiments, they struggle with retrieving resources, such as new data, necessary to replicate a claim. All code and data are publicly available at https://github.com/CenterForOpenScience/llm-benchmarking.

</details>


### [12] [Causal-JEPA: Learning World Models through Object-Level Latent Interventions](https://arxiv.org/abs/2602.11389)
*Heejeong Nam,Quentin Le Lidec,Lucas Maes,Yann LeCun,Randall Balestriero*

Main category: cs.AI

TL;DR: 本文提出了一种名为C-JEPA的对象中心世界模型，通过引入对象级掩码机制，增强了模型对交互式动态的理解和反事实推理能力，并在视觉问答和代理控制任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于对象中心表示的世界模型虽然能提供抽象，但无法充分捕捉依赖于交互的动态。研究者希望构建一个能够更好地进行预测、推理和控制的世界模型，特别是要解决交互依赖性和反事实推理的问题。

Method: C-JEPA在标准的Masked Joint Embedding Predictive Architecture (JEPA)基础上进行了扩展。它将掩码机制从图像块级别提升到对象级别。通过要求模型从其他对象推断出被掩码对象的状态，C-JEPA诱导了具有反事实效应的潜在干预，从而迫使模型进行交互推理，并防止捷径解。

Result: C-JEPA在视觉问答任务上带来了持续的性能提升，尤其是在反事实推理方面，相比未使用对象级掩码的同类架构，绝对性能提高了约20%。在代理控制任务上，C-JEPA通过仅使用补丁级世界模型所需潜入特征的1%就能实现更高效的规划，同时达到可比的性能。

Conclusion: C-JEPA通过对象级掩码机制，成功地诱导了一种因果归纳偏差，并通过潜在干预实现了反事实推理。这使得C-JEPA在理解和模拟交互式动态方面表现出色，并在下游任务中展现出优越的效率和性能。

Abstract: World models require robust relational understanding to support prediction, reasoning, and control. While object-centric representations provide a useful abstraction, they are not sufficient to capture interaction-dependent dynamics. We therefore propose C-JEPA, a simple and flexible object-centric world model that extends masked joint embedding prediction from image patches to object-centric representations. By applying object-level masking that requires an object's state to be inferred from other objects, C-JEPA induces latent interventions with counterfactual-like effects and prevents shortcut solutions, making interaction reasoning essential. Empirically, C-JEPA leads to consistent gains in visual question answering, with an absolute improvement of about 20\% in counterfactual reasoning compared to the same architecture without object-level masking. On agent control tasks, C-JEPA enables substantially more efficient planning by using only 1\% of the total latent input features required by patch-based world models, while achieving comparable performance. Finally, we provide a formal analysis demonstrating that object-level masking induces a causal inductive bias via latent interventions. Our code is available at https://github.com/galilai-group/cjepa.

</details>


### [13] [TRACER: Trajectory Risk Aggregation for Critical Episodes in Agentic Reasoning](https://arxiv.org/abs/2602.11409)
*Sina Tayebati,Divake Kumar,Nastaran Darabi,Davide Ettori,Ranganath Krishnan,Amit Ranjan Trivedi*

Main category: cs.AI

TL;DR: 本文提出了一种名为 TRACER 的新方法，用于在多轮人机交互中估算 AI 代理的不确定性，通过结合内容和情境感知信号，能比现有方法更早、更准确地检测到潜在的任务失败。


<details>
  <summary>Details</summary>
Motivation: 现有方法在估算 AI 代理在真实世界多轮对话工具使用交互中的不确定性方面存在困难，因为局部生成看似自信，但实际故障往往源于稀疏的关键性事件（如循环、不连贯的工具使用或用户-代理失调）。现有的不确定性代理主要关注单次文本生成，忽略了这些轨迹层面的故障信号。

Method: TRACER 是一种用于双控制工具-代理-用户交互的轨迹级不确定性度量。它结合了内容感知困惑度、情境感知信号、语义和词汇重复，以及与工具相关的连贯性差距。然后，利用一个侧重于尾部风险的函数和一个 MAX-复合步骤风险来聚合这些信号，以突出关键异常。

Result: 在 τ²-bench 数据集上评估 TRACER，用于预测任务失败和选择性任务执行。结果显示，TRACER 在 AUROC 和 AUARC 指标上分别比基线方法提高了 37.1% 和 55%，能够更早、更准确地检测复杂对话工具使用场景中的不确定性。

Conclusion: TRACER 是一种有效的轨迹级不确定性度量方法，能够显著提升在多轮人机交互中对 AI 代理潜在故障的检测能力，为开发更可靠的 AI 代理提供了新的途径。

Abstract: Estimating uncertainty for AI agents in real-world multi-turn tool-using interaction with humans is difficult because failures are often triggered by sparse critical episodes (e.g., looping, incoherent tool use, or user-agent miscoordination) even when local generation appears confident. Existing uncertainty proxies focus on single-shot text generation and therefore miss these trajectory-level breakdown signals. We introduce TRACER, a trajectory-level uncertainty metric for dual-control Tool-Agent-User interaction. TRACER combines content-aware surprisal with situational-awareness signals, semantic and lexical repetition, and tool-grounded coherence gaps, and aggregates them using a tail-focused risk functional with a MAX-composite step risk to surface decisive anomalies. We evaluate TRACER on $τ^2$-bench by predicting task failure and selective task execution. To this end, TRACER improves AUROC by up to 37.1% and AUARC by up to 55% over baselines, enabling earlier and more accurate detection of uncertainty in complex conversational tool-use settings. Our code and benchmark are available at https://github.com/sinatayebati/agent-tracer.

</details>


### [14] [Distributionally Robust Cooperative Multi-Agent Reinforcement Learning via Robust Value Factorization](https://arxiv.org/abs/2602.11437)
*Chengrui Qu,Christopher Yeh,Kishan Panaganti,Eric Mazumdar,Adam Wierman*

Main category: cs.AI

TL;DR: 本研究提出了一种名为分布鲁棒IGM（DrIGM）的新原则，用于改进多智能体强化学习（MARL）的鲁棒性，以应对现实世界中的不确定性。DrIGM确保智能体的鲁棒贪婪动作与团队最优的鲁棒联合动作对齐，并提供了系统级的可证明鲁棒性保证。研究人员还开发了与现有价值分解架构兼容的DrIGM鲁棒变体，并在仿真和实际环境中取得了 out-of-distribution 性能的提升。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的不确定性（例如，模拟到现实的差距、模型不匹配和系统噪声）削弱了传统MARL中“中心化训练，去中心化执行”范式下，基于个体-全局最大（IGM）原则的价值分解方法的有效性。研究旨在弥合这种可靠性差距，提高MARL系统在现实环境中的鲁棒性。

Method: 研究提出了分布鲁棒IGM（DrIGM）原则，该原则要求智能体的鲁棒贪婪动作与团队最优的鲁棒联合动作对齐。为了实现这一点，研究引入了一种新的鲁棒个体动作值定义，该定义兼容去中心化贪婪执行，并为整个系统提供了可证明的鲁棒性保证。在此基础上，研究推导出了DrIGM兼容的、现有的价值分解架构（如VDN/QMIX/QTRAN）的鲁棒变体，这些变体通过训练鲁棒Q目标、保持可扩展性并无需定制的代理奖励塑造即可实现。

Result: 在SustainGym模拟器和StarCraft游戏环境中进行的实证研究表明，所提出的DrIGM方法在out-of-distribution（分布外）设置下，相比现有方法具有一致的性能提升。

Conclusion: DrIGM原则为提高MARL系统的鲁棒性提供了一个新的理论基础，并通过开发与现有架构兼容的实用方法，成功地在实践中实现了鲁棒性提升，尤其是在面对环境不确定性时。

Abstract: Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution, where value-factorization methods enforce the individual-global-maximum (IGM) principle so that decentralized greedy actions recover the team-optimal joint action. However, the reliability of this recipe in real-world settings remains unreliable due to environmental uncertainties arising from the sim-to-real gap, model mismatch, and system noise. We address this gap by introducing Distributionally robust IGM (DrIGM), a principle that requires each agent's robust greedy action to align with the robust team-optimal joint action. We show that DrIGM holds for a novel definition of robust individual action values, which is compatible with decentralized greedy execution and yields a provable robustness guarantee for the whole system. Building on this foundation, we derive DrIGM-compliant robust variants of existing value-factorization architectures (e.g., VDN/QMIX/QTRAN) that (i) train on robust Q-targets, (ii) preserve scalability, and (iii) integrate seamlessly with existing codebases without bespoke per-agent reward shaping. Empirically, on high-fidelity SustainGym simulators and a StarCraft game environment, our methods consistently improve out-of-distribution performance. Code and data are available at https://github.com/crqu/robust-coMARL.

</details>


### [15] [Credit Where It is Due: Cross-Modality Connectivity Drives Precise Reinforcement Learning for MLLM Reasoning](https://arxiv.org/abs/2602.11455)
*Zhengbo Jiao,Shaobo Wang,Zifan Zhang,Wei Wang,Bing Zhao,Hu Wei,Linfeng Zhang*

Main category: cs.AI

TL;DR: 本文研究了多模态大语言模型（MLLMs）在强化学习（RL）中如何整合视觉证据进行推理，发现只有少数（约15%）的 token 具有强烈的视觉-文本关联，这些 token 是视觉推理的“锚点”。作者提出了 Anchor-Token Reinforcement Learning (AT-RL) 框架，通过聚焦于这些高连接度的 token 来增强视觉锚点，并在 MathVista 和其他 STEM、视频等任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态强化学习（RLVR）在提升MLLMs推理能力方面取得了进展，但对于视觉证据是如何被整合进推理过程的，其机制仍然不清楚。作者希望理解跨模态注意力连接性在多模态 RLVR 中的作用。

Method: 作者通过分析跨模态注意力连接性，识别出具有强视觉-文本耦合的“锚点” token。在此基础上，提出了一种名为 Anchor-Token Reinforcement Learning (AT-RL) 的轻量级框架，该框架通过基于图的注意力拓扑聚类，选择性地强化这些高连接度的锚点 token。

Result: AT-RL 框架带来了仅 1.2% 的额外计算开销，但能够让 32B 模型在 MathVista 数据集上超越 72B-Instruct 基线模型（80.2% 的准确率），并在 STEM、视频和通用任务上均观察到持续的性能提升。实验表明，只在低连接度 token 上训练会导致严重的性能下降，证实了有效的多模态 RL 依赖于精确的视觉锚点信用分配。

Conclusion: 多模态 RLVR 的推理质量并非由 token 的数量决定，而是取决于跨模态锚定的准确性。AT-RL 框架通过关注视觉锚点 token，有效地提升了 MLLMs 的多模态推理能力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), yet how visual evidence is integrated during reasoning remains poorly understood. We explore multimodal RLVR through the lens of cross-modal attention connectivity and find that only a small fraction of tokens (approximately 15%) exhibit strong visual-textual coupling. These high-connectivity tokens act as anchors that ground reasoning in the image, while the majority follow linguistic patterns. During RLVR training, credit assignment naturally concentrates on these anchors, sharpening their visual grounding over time. Building on this insight, we propose Anchor-Token Reinforcement Learning (AT-RL), a lightweight framework that selectively reinforces high-connectivity tokens via graph-based clustering of attention topology. Evaluated across the series (3B-32B), AT-RL introduces only 1.2% overhead yet enables the 32B model to surpass the 72B-Instruct baseline on MathVista (80.2), with consistent gains observed across STEM, video and general tasks. Conversely, training solely on low-connectivity tokens causes severe degradation, confirming that effective multimodal RL hinges on precise credit assignment to visual anchors. Our work reveals that reasoning quality is governed not by token quantity but by the fidelity of cross-modal anchoring.

</details>


### [16] [AgentLeak: A Full-Stack Benchmark for Privacy Leakage in Multi-Agent LLM Systems](https://arxiv.org/abs/2602.11510)
*Faouzi El Yagoubi,Ranwa Al Mallah,Godwin Badu-Marfo*

Main category: cs.AI

TL;DR: 研究人员提出了AgentLeak，一个首个涵盖内部通信渠道的多智能体LLM隐私泄露基准测试。测试发现，尽管多智能体配置可能减少外部输出泄露，但内部通信渠道（如智能体间消息）会引入大量未被现有审计方法发现的隐私风险。Claude 3.5 Sonnet在保护内部和外部渠道方面表现最佳，表明模型层面的安全训练对内部通信有益。


<details>
  <summary>Details</summary>
Motivation: 现有的隐私基准测试无法衡量多智能体LLM系统中的隐私泄露风险，这些风险源于智能体间通信、共享内存和工具参数等内部数据传输通道，而这些通道通常不在输出审计的检查范围内。

Method: 引入AgentLeak基准测试，包含1000个跨领域（医疗、金融、法律、企业）的隐私泄露场景，以及32类攻击和三层检测流水线。对GPT-4o、GPT-4o-mini、Claude 3.5 Sonnet、Mistral Large和Llama 3.3 70B进行测试，分析了4979条通信轨迹。

Result: 与单智能体配置相比，多智能体配置的外部输出泄露率（C1）从43.2%降至27.2%。然而，由于引入了未监控的内部通道，总系统暴露率升至68.9%。其中，智能体间消息（C2）的泄露率高达68.8%，远高于输出通道（C1）的27.2%。这意味着仅关注输出通道的审计会遗漏41.7%的泄露。

Conclusion: 多智能体LLM系统在智能体间通信（C2）方面存在主要隐私漏洞。现有的输出审计方法会忽略大量内部通道的隐私泄露。未来的多智能体协调框架需要整合内部通道隐私保护机制，并对智能体间的通信实施隐私控制。模型层面的安全对齐训练（如Claude 3.5 Sonnet）似乎能有效降低内部和外部的隐私泄露。

Abstract: Multi-agent Large Language Model (LLM) systems create privacy risks that current benchmarks cannot measure. When agents coordinate on tasks, sensitive data passes through inter-agent messages, shared memory, and tool arguments; pathways that output-only audits never inspect. We introduce AgentLeak, to the best of our knowledge the first full-stack benchmark for privacy leakage covering internal channels, spanning 1,000 scenarios across healthcare, finance, legal, and corporate domains, paired with a 32-class attack taxonomy and three-tier detection pipeline. Testing GPT-4o, GPT-4o-mini, Claude 3.5 Sonnet, Mistral Large, and Llama 3.3 70B across 4,979 traces reveals that multi-agent configurations reduce per-channel output leakage (C1: 27.2% vs 43.2% in single-agent) but introduce unmonitored internal channels that raise total system exposure to 68.9% (OR-aggregated across C1, C2, C5). Internal channels account for most of this gap: inter-agent messages (C2) leak at 68.8%, compared to 27.2% on C1 (output channel). This means that output-only audits miss 41.7% of violations. Claude 3.5 Sonnet, which emphasizes safety alignment in its design, achieves the lowest leakage rates on both external (3.3%) and internal (28.1%) channels, suggesting that model-level safety training may transfer to internal channel protection. Across all five models and four domains, the pattern C2 > C1 holds consistently, confirming that inter-agent communication is the primary vulnerability. These findings underscore the need for coordination frameworks that incorporate internal-channel privacy protections and enforce privacy controls on inter-agent communication.

</details>


### [17] [Human-Inspired Continuous Learning of Internal Reasoning Processes: Learning How to Think for Adaptive AI Systems](https://arxiv.org/abs/2602.11516)
*Hong Su*

Main category: cs.AI

TL;DR: 本文提出了一种受人类启发的持续学习框架，该框架将推理、动作、反思和验证统一在一个增强的序列推理模型中，通过并行学习来优化内部思维过程、动作调度和学习机制本身。实验表明，在传感器异常检测任务中，该框架可将平均运行时间减少 23.9%。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法侧重于学习特定任务的输出或静态知识，而忽视了内部推理结构、动作调度策略和学习机制的持续改进。然而，在动态现实世界环境中，AI系统需要能够持续适应，这就需要不断优化其内部推理过程。

Method: 提出一个受人类启发的持续学习框架，该框架将推理、动作、反思和验证整合到一个通过并行学习增强的序列推理模型中。该框架将内部思维过程作为主要的学习对象，记录推理轨迹和环境交互作为结构化学习材料，从而优化任务内容、推理活动的组织、调度和演变。该框架还支持用学习到的程序替换预定义逻辑，并引入了分层学习机制来联合调整任务级参数和学习策略。

Result: 在温度传感器异常检测任务的实验中，该框架通过学习内部过程，将平均运行时间减少了 23.9%。

Conclusion: 该框架实现了在执行过程中认知结构的改进，并在保持操作稳定性的同时，逐步演化内部认知架构。通过将内部思维过程作为学习对象，AI系统能够更有效地适应动态环境。

Abstract: Learning internal reasoning processes is crucial for developing AI systems capable of sustained adaptation in dynamic real-world environments. However, most existing approaches primarily emphasize learning task-specific outputs or static knowledge representations, while overlooking the continuous refinement of internal reasoning structures, action scheduling policies, and learning mechanisms themselves. In this paper, we propose a human-inspired continuous learning framework that unifies reasoning, action, reflection, and verification within a sequential reasoning model enhanced by parallel learning. The framework explicitly treats internal thinking processes as primary learning objects. It systematically records internal reasoning trajectories and environmental interactions as structured learning material, enabling the system to optimize not only task-level content but also the organization, scheduling, and evolution of reasoning activities. This design realizes learning alongside processing, allowing cognitive structures to improve during execution. Furthermore, the framework supports controlled replacement of predefined logic with learned procedures and introduces a hierarchical learning-to-learn mechanism that jointly adapts task-level parameters and learning strategies. As a result, the system progressively evolves its internal cognitive architecture while preserving operational stability. Experimental results on a temperature sensor abnormality detection task show that incorporating internal-process learning reduces average runtime by 23.9%.

</details>


### [18] [Budget-Constrained Agentic Large Language Models: Intention-Based Planning for Costly Tool Use](https://arxiv.org/abs/2602.11541)
*Hanbing Liu,Chunhao Tian,Nan An,Ziyuan Wang,Pinyan Lu,Changyuan Yu,Qi Qi*

Main category: cs.AI

TL;DR: 提出了一种名为INTENT的推理时规划框架，用于解决预算受限的多步骤任务，该框架利用了意图感知的分层世界模型来预测未来工具使用、风险校准成本，并在线指导决策，同时严格遵守预算限制，并在各种动态市场条件下提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的解决多步骤任务的模型在预算受限的情况下，其规划过程由于状态-动作空间巨大、工具执行结果变异性高以及探索成本高昂而难以进行。

Method: 提出INTENT框架，它利用意图感知的分层世界模型来预测未来工具使用、风险校准成本，并指导在线决策。

Result: INTENT在成本增强的StableToolBench上严格执行了硬预算可行性，任务成功率远高于基线方法，并且在工具价格变化和预算变化等动态市场变化下保持了鲁棒性。

Conclusion: INTENT框架能够有效地解决预算受限的多步骤任务问题，并在实际应用中表现出良好的性能和鲁棒性。

Abstract: We study budget-constrained tool-augmented agents, where a large language model must solve multi-step tasks by invoking external tools under a strict monetary budget. We formalize this setting as sequential decision making in context space with priced and stochastic tool executions, making direct planning intractable due to massive state-action spaces, high variance of outcomes and prohibitive exploration cost. To address these challenges, we propose INTENT, an inference-time planning framework that leverages an intention-aware hierarchical world model to anticipate future tool usage, risk-calibrated cost, and guide decisions online. Across cost-augmented StableToolBench, INTENT strictly enforces hard budget feasibility while substantially improving task success over baselines, and remains robust under dynamic market shifts such as tool price changes and varying budgets.

</details>


### [19] [CausalAgent: A Conversational Multi-Agent System for End-to-End Causal Inference](https://arxiv.org/abs/2602.11527)
*Jiawei Zhu,Wei Chen,Ruichu Cai*

Main category: cs.AI

TL;DR: 本文提出了一种名为 CausalAgent 的对话式多智能体系统，用于简化端到端的因果推断过程，降低了研究人员的技术门槛。


<details>
  <summary>Details</summary>
Motivation: 传统因果推断流程技术门槛高，需要研究人员具备统计学和计算机科学背景，手动选择算法，处理数据质量问题并解释复杂结果，存在诸多挑战。

Method: CausalAgent 集成了多智能体系统（MAS）、检索增强生成（RAG）和模型上下文协议（MCP），通过自然语言交互实现从数据清洗、因果结构学习到偏差纠正和报告生成的自动化。

Result: 用户只需上传数据集并用自然语言提问，即可获得一份严谨、交互式的分析报告。该系统通过交互式可视化降低了因果分析的入门门槛，同时确保了过程的严谨性和可解释性。

Conclusion: CausalAgent 是一种新颖的以用户为中心的人机协作范式，它明确地建模了分析流程，显著降低了因果分析的门槛，并保证了结果的可靠性和可理解性。

Abstract: Causal inference holds immense value in fields such as healthcare, economics, and social sciences. However, traditional causal analysis workflows impose significant technical barriers, requiring researchers to possess dual backgrounds in statistics and computer science, while manually selecting algorithms, handling data quality issues, and interpreting complex results. To address these challenges, we propose CausalAgent, a conversational multi-agent system for end-to-end causal inference. The system innovatively integrates Multi-Agent Systems (MAS), Retrieval-Augmented Generation (RAG), and the Model Context Protocol (MCP) to achieve automation from data cleaning and causal structure learning to bias correction and report generation through natural language interaction. Users need only upload a dataset and pose questions in natural language to receive a rigorous, interactive analysis report. As a novel user-centered human-AI collaboration paradigm, CausalAgent explicitly models the analysis workflow. By leveraging interactive visualizations, it significantly lowers the barrier to entry for causal analysis while ensuring the rigor and interpretability of the process.

</details>


### [20] [SemaPop: Semantic-Persona Conditioned Population Synthesis](https://arxiv.org/abs/2602.11569)
*Zhenlin Qin,Yancheng Ling,Leizhen Wang,Francisco Câmara Pereira,Zhenliang Ma*

Main category: cs.AI

TL;DR: 提出了一种名为SemaPop的语义统计人口合成模型，该模型利用大型语言模型（LLMs）和生成模型来捕捉调查数据中的抽象行为模式，并实现可控和可解释的人口合成。


<details>
  <summary>Details</summary>
Motivation: 现有的人口合成方法主要依赖结构化属性和统计约束，难以捕捉调查数据中隐含的、抽象的行为模式，导致在语义条件人口生成方面存在空白。

Method: SemaPop模型将LLMs与生成模型相结合。它从个体调查记录中提取高层人格表示作为语义条件信号，并引入边际正则化来强制与目标人口边际对齐。研究中，该框架使用带有梯度惩罚的Wasserstein GAN（WGAN-GP）作为骨干，称为SemaPop-GAN。

Result: SemaPop-GAN在生成性能上有所提升，能够更精确地匹配目标边际和联合分布，同时在语义条件下保持样本级别的可行性和多样性。消融研究证实了语义人格条件和架构设计选择在平衡边际一致性和结构真实性方面的贡献。

Conclusion: SemaPop-GAN通过有效的语义统计信息融合，实现了可控和可解释的人口合成。该模型为开发集成个体行为语义和人口统计约束的生成人口预测系统提供了一个有前景的模块化基础。

Abstract: Population synthesis is a critical component of individual-level socio-economic simulation, yet remains challenging due to the need to jointly represent statistical structure and latent behavioral semantics. Existing population synthesis approaches predominantly rely on structured attributes and statistical constraints, leaving a gap in semantic-conditioned population generation that can capture abstract behavioral patterns implicitly in survey data. This study proposes SemaPop, a semantic-statistical population synthesis model that integrates large language models (LLMs) with generative population modeling. SemaPop derives high-level persona representations from individual survey records and incorporates them as semantic conditioning signals for population generation, while marginal regularization is introduced to enforce alignment with target population marginals. In this study, the framework is instantiated using a Wasserstein GAN with gradient penalty (WGAN-GP) backbone, referred to as SemaPop-GAN. Extensive experiments demonstrate that SemaPop-GAN achieves improved generative performance, yielding closer alignment with target marginal and joint distributions while maintaining sample-level feasibility and diversity under semantic conditioning. Ablation studies further confirm the contribution of semantic persona conditioning and architectural design choices to balancing marginal consistency and structural realism. These results demonstrate that SemaPop-GAN enables controllable and interpretable population synthesis through effective semantic-statistical information fusion. SemaPop-GAN also provides a promising modular foundation for developing generative population projection systems that integrate individual-level behavioral semantics with population-level statistical constraints.

</details>


### [21] [Learning to Configure Agentic AI Systems](https://arxiv.org/abs/2602.11574)
*Aditya Taparia,Som Sagar,Ransalu Senanayake*

Main category: cs.AI

TL;DR: 研究提出了一种名为ARC（Agentic Resource & Configuration learner）的系统，利用强化学习动态地为基于LLM的代理系统配置工作流、工具、token预算和提示，以解决现有固定配置方法效率低下和适应性差的问题。ARC在多个基准测试中表现优于手动设计和其他基线方法，提高了任务准确性并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理系统配置方法（固定模板或手动调整的启发式方法）存在僵化行为和不必要的计算成本，因为它们通常将相同的配置应用于简单和复杂的查询。研究旨在找到一种更动态、更高效的配置方法。

Method: 将代理配置问题定义为查询级决策问题，并引入ARC系统。ARC使用强化学习来学习一个轻量级的分层策略，该策略能够动态地调整工作流、工具、token预算和提示等配置。

Result: 在涉及推理和工具增强问答的多个基准测试中，ARC学习到的策略一致优于手动设计和其他基线方法，任务准确性最高可提高25%，同时还减少了token和运行时成本。

Conclusion: 学习查询级的代理配置是一种比“一刀切”设计更有效的替代方案，能够显著提高LLM代理系统的性能和效率。

Abstract: Configuring LLM-based agent systems involves choosing workflows, tools, token budgets, and prompts from a large combinatorial design space, and is typically handled today by fixed large templates or hand-tuned heuristics. This leads to brittle behavior and unnecessary compute, since the same cumbersome configuration is often applied to both easy and hard input queries. We formulate agent configuration as a query-wise decision problem and introduce ARC (Agentic Resource & Configuration learner), which learns a light-weight hierarchical policy using reinforcement learning to dynamically tailor these configurations. Across multiple benchmarks spanning reasoning and tool-augmented question answering, the learned policy consistently outperforms strong hand-designed and other baselines, achieving up to 25% higher task accuracy while also reducing token and runtime costs. These results demonstrate that learning per-query agent configurations is a powerful alternative to "one size fits all" designs.

</details>


### [22] [The Five Ws of Multi-Agent Communication: Who Talks to Whom, When, What, and Why -- A Survey from MARL to Emergent Language and LLMs](https://arxiv.org/abs/2602.11583)
*Jingdi Chen,Hanqing Yang,Zongjun Liu,Carlee Joe-Wong*

Main category: cs.AI

TL;DR: 本综述通过“五个W”（谁、什么、何时、为何）的框架，对多智能体通信（MA-Comm）进行了全面回顾，重点关注了多智能体强化学习（MARL）、涌现语言（EL）以及基于大语言模型（LLM）的三种主要范式。文章分析了不同通信方法的演变、权衡和未解决的问题，并提炼出实用的设计模式和未来挑战，以支持可扩展且可解释的多智能体协作。


<details>
  <summary>Details</summary>
Motivation: 为了理解和连接在动态、部分可观测环境中，多智能体通信（MA-Comm）如何通过降低不确定性和实现协作。现有研究分散在不同的范式中，需要一个统一的框架来梳理其演进和权衡。

Method: 采用“五个W”（Who, What, When, Why, Where - 尽管摘要中明确提到了前四个，但通常“Where”也包含在分析中，这里根据摘要内容聚焦前四个）的框架，回顾了多智能体通信在MARL、EL和LLM三种主要范式下的研究进展。分析了不同通信方法的演变、设计选择、权衡以及未解决的挑战。

Result: 研究梳理了从早期手工设计/隐式通信到端到端学习通信（MARL），再到涌现结构化/符号化通信（EL），以及利用LLM的自然语言先验进行协作（LLM-based）的演进路径。揭示了在不同范式下，通信设计的主要权衡和尚待解决的问题。

Conclusion: 通过对不同范式下MA-Comm的研究进行整合分析，作者提炼出实用的设计模式和重要的开放性挑战。文章旨在为未来结合学习、语言和控制的混合系统提供指导，以实现可扩展且可解释的多智能体协作。

Abstract: Multi-agent sequential decision-making powers many real-world systems, from autonomous vehicles and robotics to collaborative AI assistants. In dynamic, partially observable environments, communication is often what reduces uncertainty and makes collaboration possible. This survey reviews multi-agent communication (MA-Comm) through the Five Ws: who communicates with whom, what is communicated, when communication occurs, and why communication is beneficial. This framing offers a clean way to connect ideas across otherwise separate research threads. We trace how communication approaches have evolved across three major paradigms. In Multi-Agent Reinforcement Learning (MARL), early methods used hand-designed or implicit protocols, followed by end-to-end learned communication optimized for reward and control. While successful, these protocols are frequently task-specific and hard to interpret, motivating work on Emergent Language (EL), where agents can develop more structured or symbolic communication through interaction. EL methods, however, still struggle with grounding, generalization, and scalability, which has fueled recent interest in large language models (LLMs) that bring natural language priors for reasoning, planning, and collaboration in more open-ended settings. Across MARL, EL, and LLM-based systems, we highlight how different choices shape communication design, where the main trade-offs lie, and what remains unsolved. We distill practical design patterns and open challenges to support future hybrid systems that combine learning, language, and control for scalable and interpretable multi-agent collaboration.

</details>


### [23] [MAPLE: Modality-Aware Post-training and Learning Ecosystem](https://arxiv.org/abs/2602.11596)
*Nikhil Verma,Minjung Kim,JooYoung Yoo,Kyung-Min Jin,Manasa Bharadwaj,Kevin Ferreira,Ko Keun Kim,Youngjoon Kim*

Main category: cs.AI

TL;DR: 本文提出了一种名为MAPLE的模态感知强化学习后训练生态系统，通过引入模态需求标注基准MAPLE-bench和模态感知策略优化框架MAPO，有效解决了现有方法忽视模态异质性导致的训练低效和鲁棒性差的问题。MAPLE通过自适应加权和课程学习策略，显著提升了多模态语言模型的训练速度、收敛性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态语言模型在强化学习后训练阶段，并未区分不同任务对输入模态的需求，将所有信号同等对待，导致策略梯度方差增大、收敛缓慢，并且在真实世界中信号缺失、增加或权重变化时鲁棒性下降。

Method: 研究者提出了MAPLE生态系统，包含：1. MAPLE-bench基准，标注了完成每个任务所需的最小模态信号组合；2. MAPO框架，根据模态需求对批次进行分层，以减小异质性带来的梯度方差；3. 自适应加权和课程学习策略，用于平衡和优先处理更难的信号组合。研究人员还系统分析了损失聚合、裁剪、采样和课程设计等策略，以确定MAPO的最优训练策略。

Result: MAPLE将单模态和多模态的准确率差距缩小了30.24%，收敛速度提高了3.18倍，并且在信号减少的真实场景下，所有模态组合都保持了稳定性。自适应加权和课程学习策略进一步提升了在不同信号组合下的性能。

Conclusion: MAPLE是一个完整的、可用于部署的多模态强化学习后训练解决方案，通过模态感知的方法，有效提升了训练效率和模型鲁棒性，缩小了单模态和多模态模型之间的性能差距。

Abstract: Multimodal language models now integrate text, audio, and video for unified reasoning. Yet existing RL post-training pipelines treat all input signals as equally relevant, ignoring which modalities each task actually requires. This modality-blind training inflates policy-gradient variance, slows convergence, and degrades robustness to real-world distribution shifts where signals may be missing, added, or reweighted. We introduce MAPLE, a complete modality-aware post-training and learning ecosystem comprising: (1) MAPLE-bench, the first benchmark explicitly annotating minimal signal combinations required per task; (2) MAPO, a modality-aware policy optimization framework that stratifies batches by modality requirement to reduce gradient variance from heterogeneous group advantages; (3) Adaptive weighting and curriculum scheduling that balances and prioritizes harder signal combinations. Systematic analysis across loss aggregation, clipping, sampling, and curriculum design establishes MAPO's optimal training strategy. Adaptive weighting and curriculum focused learning further boost performance across signal combinations. MAPLE narrows uni/multi-modal accuracy gaps by 30.24%, converges 3.18x faster, and maintains stability across all modality combinations under realistic reduced signal access. MAPLE constitutes a complete recipe for deployment-ready multimodal RL post-training.

</details>


### [24] [scPilot: Large Language Model Reasoning Toward Automated Single-Cell Analysis and Discovery](https://arxiv.org/abs/2602.11609)
*Yiming Gao,Zhen Wang,Jefferson Chen,Mark Antkowiak,Mengzhou Hu,JungHo Kong,Dexter Pratt,Jieyuan Liu,Enze Ma,Zhiting Hu,Eric P. Xing*

Main category: cs.AI

TL;DR: scPilot 是一个框架，允许大型语言模型（LLM）直接分析单细胞 RNA 测序数据并使用生物信息学工具进行推理，以解决单细胞分析任务，如细胞类型注释和发育轨迹重建。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理和分析单细胞 RNA 测序数据方面存在局限性，需要更系统化的方法来实现“组学原生”推理。

Method: scPilot 将核心单细胞分析任务转化为逐步推理问题，LLM 需要解决、解释并根据新证据进行修正。研究还发布了一个名为 scBench 的基准测试套件，用于评估 scPilot 和其他 LLM 的组学原生推理能力。

Result: 实验表明，scPilot 的迭代推理方法比一次性提示能提高细胞类型注释 11% 的平均准确率，并使轨迹图编辑距离降低 30%。同时，它还能生成透明的推理过程，解释标记基因的歧义和调控逻辑。

Conclusion: 通过将 LLM 与原始组学数据相结合，scPilot 实现了可审计、可解释且具有诊断信息价值的单细胞分析。

Abstract: We present scPilot, the first systematic framework to practice omics-native reasoning: a large language model (LLM) converses in natural language while directly inspecting single-cell RNA-seq data and on-demand bioinformatics tools. scPilot converts core single-cell analyses, i.e., cell-type annotation, developmental-trajectory reconstruction, and transcription-factor targeting, into step-by-step reasoning problems that the model must solve, justify, and, when needed, revise with new evidence.
  To measure progress, we release scBench, a suite of 9 expertly curated datasets and graders that faithfully evaluate the omics-native reasoning capability of scPilot w.r.t various LLMs. Experiments with o1 show that iterative omics-native reasoning lifts average accuracy by 11% for cell-type annotation and Gemini-2.5-Pro cuts trajectory graph-edit distance by 30% versus one-shot prompting, while generating transparent reasoning traces explain marker gene ambiguity and regulatory logic. By grounding LLMs in raw omics data, scPilot enables auditable, interpretable, and diagnostically informative single-cell analyses.
  Code, data, and package are available at https://github.com/maitrix-org/scPilot

</details>


### [25] [When Agents Disagree With Themselves: Measuring Behavioral Consistency in LLM-Based Agents](https://arxiv.org/abs/2602.11619)
*Aman Mehta*

Main category: cs.AI

TL;DR: LLM 代理在执行相同任务时行为不一致，这种不一致性与任务失败率相关，且早期决策（如第一个搜索查询）是导致不一致的主要原因。


<details>
  <summary>Details</summary>
Motivation: 研究 LLM 代理在执行相同任务时是否存在行为一致性，以及这种一致性与任务成功率之间的关系。

Method: 在 HotpotQA 数据集上，对 Llama 3.1 70B、GPT-4o 和 Claude Sonnet 4.5 三个模型进行了 3000 次 ReAct 风格的代理运行实验，分析了不同运行中的行动序列多样性，并将其与任务准确率进行关联分析，同时追溯了行为发散的发生阶段。

Result: LLM 代理在执行相同任务时产生多样的行动序列，平均每 10 次运行就有 2.0-4.2 个不同的行动序列。行为越不一致（行动序列越多），任务准确率越低。行为一致性高的任务准确率可达 80-92%，而高度不一致的任务准确率仅为 25-60%。行为发散的 69% 发生在第二步，即第一次搜索查询。

Conclusion: LLM 代理的行为不一致性是普遍存在的，且这种不一致性是任务失败的预测指标。通过监控代理执行过程中的行为一致性，可以在早期检测到错误，从而提高代理的可靠性。

Abstract: Run the same LLM agent on the same task twice: do you get the same behavior? We find the answer is often no. In a study of 3,000 agent runs across three models (Llama 3.1 70B, GPT-4o, and Claude Sonnet 4.5) on HotpotQA, we observe that ReAct-style agents produce 2.0--4.2 distinct action sequences per 10 runs on average, even with identical inputs. More importantly, this variance predicts failure: tasks with consistent behavior ($\leq$2 unique paths) achieve 80--92% accuracy, while highly inconsistent tasks ($\geq$6 unique paths) achieve only 25--60%, a 32--55 percentage point gap depending on model. We trace variance to early decisions: 69% of divergence occurs at step 2, the first search query. Our results suggest that monitoring behavioral consistency during execution could enable early error detection and improve agent reliability.

</details>


### [26] [Neuro-Symbolic Multitasking: A Unified Framework for Discovering Generalizable Solutions to PDE Families](https://arxiv.org/abs/2602.11630)
*Yipeng Huang,Dejun Xu,Zexin Lin,Zhenzhong Wang,Min Jiang*

Main category: cs.AI

TL;DR: 提出了一种名为NMIPS的多任务符号PDE求解器框架，利用多因子优化和仿射迁移方法，可以高效地同时发现PDE家族的解析解，并提供了可解释的分析结果。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在求解参数变化但数学结构相同的PDE家族时计算成本高昂；现有机器学习方法虽然速度快但缺乏可解释性。研究旨在克服这些局限，提供一种兼具效率和可解释性的求解方法。

Method: 采用了多因子优化（multifactorial optimization）来同时发现PDE的解析解，并设计了仿射迁移（affine transfer）方法，通过在PDE家族之间迁移学习到的数学结构来提高计算效率，避免重复计算。

Result: 在多个案例实验中，该方法取得了显著的性能提升，精度最高可提高约35.7%，同时提供了可解释的解析解，优于现有基线方法。

Conclusion: 所提出的NMIPS框架成功解决了PDE家族求解的效率和可解释性问题，通过多任务学习和迁移学习，能够高效地获得准确且可理解的PDE解析解。

Abstract: Solving Partial Differential Equations (PDEs) is fundamental to numerous scientific and engineering disciplines. A common challenge arises from solving the PDE families, which are characterized by sharing an identical mathematical structure but varying in specific parameters. Traditional numerical methods, such as the finite element method, need to independently solve each instance within a PDE family, which incurs massive computational cost. On the other hand, while recent advancements in machine learning PDE solvers offer impressive computational speed and accuracy, their inherent ``black-box" nature presents a considerable limitation. These methods primarily yield numerical approximations, thereby lacking the crucial interpretability provided by analytical expressions, which are essential for deeper scientific insight. To address these limitations, we propose a neuro-assisted multitasking symbolic PDE solver framework for PDE family solving, dubbed NMIPS. In particular, we employ multifactorial optimization to simultaneously discover the analytical solutions of PDEs. To enhance computational efficiency, we devise an affine transfer method by transferring learned mathematical structures among PDEs in a family, avoiding solving each PDE from scratch. Experimental results across multiple cases demonstrate promising improvements over existing baselines, achieving up to a $\sim$35.7% increase in accuracy while providing interpretable analytical solutions.

</details>


### [27] [Do MLLMs Really Understand Space? A Mathematical Reasoning Evaluation](https://arxiv.org/abs/2602.11635)
*Shuo Lu,Jianjie Cheng,Yinuo Xu,Yongcan Yu,Lijun Sheng,Peijie Wang,Siru Jiang,Yongguan Hu,Run Ling,Yihua Shao,Ao Ma,Wei Feng,Lingxiao He,Meng Wang,Qianlong Xie,Xingxing Wang,Ran He,Jian Liang*

Main category: cs.AI

TL;DR: 本文提出了 MathSpatial 框架，用于评估和提升多模态大语言模型（MLLMs）在数学空间推理方面的能力。该框架包含一个基准测试 MathSpatial-Bench、一个训练数据集 MathSpatial-Corpus 以及一个名为 MathSpatial-SRT 的推理模型。实验表明，使用 MathSpatial 训练可以显著提高 MLLMs 的空间推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLMs 在感知任务上表现出色，但在数学空间推理方面能力不足，与人类水平存在巨大差距。这表明空间推理是当前 MLLMs 的一个根本性弱点，需要专门的研究来解决。

Method: 作者提出了 MathSpatial 框架，包括：1. MathSpatial-Bench：一个包含 2000 个问题的基准测试，涵盖三个类别和十一种子类型，旨在区分推理难度和感知噪声。2. MathSpatial-Corpus：一个包含 8000 个带验证解决方案的额外问题的训练数据集。3. MathSpatial-SRT：一种将推理过程建模为由“关联”、“约束”和“推断”三个原子操作组成的结构化轨迹的方法。

Result: 通过在 MathSpatial 上微调 Qwen2.5-VL-7B 模型，在保持竞争性准确率的同时，将 token 使用量减少了 25%。

Conclusion: MathSpatial 是首个大规模资源，能够将多模态大语言模型的感知能力与其推理能力分离开来，从而实现对数学空间推理能力的精确测量和全面理解，并为改进这些模型的空间推理能力提供了有效途径。

Abstract: Multimodal large language models (MLLMs) have achieved strong performance on perception-oriented tasks, yet their ability to perform mathematical spatial reasoning, defined as the capacity to parse and manipulate two- and three-dimensional relations, remains unclear. Humans easily solve textbook-style spatial reasoning problems with over 95\% accuracy, but we find that most leading MLLMs fail to reach even 60\% on the same tasks. This striking gap highlights spatial reasoning as a fundamental weakness of current models. To investigate this gap, we present MathSpatial, a unified framework for evaluating and improving spatial reasoning in MLLMs. MathSpatial includes three complementary components: (i) MathSpatial-Bench, a benchmark of 2K problems across three categories and eleven subtypes, designed to isolate reasoning difficulty from perceptual noise; (ii) MathSpatial-Corpus, a training dataset of 8K additional problems with verified solutions; and (iii) MathSpatial-SRT, which models reasoning as structured traces composed of three atomic operations--Correlate, Constrain, and Infer. Experiments show that fine-tuning Qwen2.5-VL-7B on MathSpatial achieves competitive accuracy while reducing tokens by 25\%. MathSpatial provides the first large-scale resource that disentangles perception from reasoning, enabling precise measurement and comprehensive understanding of mathematical spatial reasoning in MLLMs.

</details>


### [28] [Quark Medical Alignment: A Holistic Multi-Dimensional Alignment and Collaborative Optimization Paradigm](https://arxiv.org/abs/2602.11661)
*Tianxiang Xu,Jiayi Liu,Yixuan Tong,Jialu Xu,Yunqing Wei,Kaiwen Feng,PanPan Hou,Kangping Yin,Jiyuan Hu,Hao Zhou,Zhenxin Ma,Jian Xu,Guanjun Jiang*

Main category: cs.AI

TL;DR: 提出了一种新的医疗领域大语言模型对齐范式，解决了现有方法在成本、准确性、复杂性以及多目标优化方面的不足，通过多维度对齐矩阵和统一优化机制提升了模型的准确性、安全性和合规性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐方法（如RLHF和RVRL）在医疗问答领域存在局限性，包括标注成本高、无法体现事实绝对正确性、缺乏有效自动验证器、难以处理复杂临床情境，以及多目标异构奖励信号的优化冲突和尺度不匹配问题。而医疗对齐需要同时优化准确性、安全性和合规性。

Method: 提出了一种“全方位多维度医疗对齐矩阵”，将对齐目标分解为基本能力、专家知识、在线反馈和格式规范四个维度。每个维度内构建了“可观指标-可归因诊断-可优化奖励”的闭环，为迭代优化提供细粒度监督信号。为解决异构信号导致的梯度主导和优化不稳，提出“统一优化机制”，采用“参考冻结归一化”对齐奖励尺度，并使用“三因子自适应动态加权”策略实现协同优化，该策略具备面向弱点、风险优先和减少冗余的特点。

Result: 实验结果表明，该范式在真实医疗场景评估中表现有效，在大语言模型准确性、安全性、合规性等方面均有显著提升，并为复杂垂直领域的对齐树立了新范式。

Conclusion: 所提出的全方位多维度医疗对齐范式及其统一优化机制能有效解决医疗领域大语言模型对齐的挑战，通过细粒度监督和稳定的多目标优化，显著提升模型在关键指标上的表现，为垂直领域的模型对齐提供了一种新的、更 robust 的解决方案。

Abstract: While reinforcement learning for large language model alignment has progressed rapidly in recent years, transferring these paradigms to high-stakes medical question answering reveals a fundamental paradigm mismatch. Reinforcement Learning from Human Feedback relies on preference annotations that are prohibitively expensive and often fail to reflect the absolute correctness of medical facts. Reinforcement Learning from Verifiable Rewards lacks effective automatic verifiers and struggles to handle complex clinical contexts. Meanwhile, medical alignment requires the simultaneous optimization of correctness, safety, and compliance, yet multi-objective heterogeneous reward signals are prone to scale mismatch and optimization conflicts.To address these challenges, we propose a robust medical alignment paradigm. We first construct a holistic multi-dimensional medical alignment matrix that decomposes alignment objectives into four categories: fundamental capabilities, expert knowledge, online feedback, and format specifications. Within each category, we establish a closed loop of where observable metrics inform attributable diagnosis, which in turn drives optimizable rewards, thereby providing fine-grained, high-resolution supervision signals for subsequent iterative optimization. To resolve gradient domination and optimization instability problem caused by heterogeneous signals, we further propose a unified optimization mechanism. This mechanism employs Reference-Frozen Normalization to align reward scales and implements a Tri-Factor Adaptive Dynamic Weighting strategy to achieve collaborative optimization that is weakness-oriented, risk-prioritized, and redundancy-reducing. Experimental results demonstrate the effectiveness of our proposed paradigm in real-world medical scenario evaluations, establishing a new paradigm for complex alignment in vertical domains.

</details>


### [29] [PhyNiKCE: A Neurosymbolic Agentic Framework for Autonomous Computational Fluid Dynamics](https://arxiv.org/abs/2602.11666)
*E Fan,Lisong Shi,Zhengtong Li,Chih-yung Wen*

Main category: cs.AI

TL;DR: 本研究提出了一种名为PhyNiKCE的神经符号自主代理框架，用于解决大型语言模型在计算流体动力学（CFD）模拟中无法保证物理守恒和数值稳定性问题。通过将LLM的生成能力与符号约束验证相结合，PhyNiKCE显著提高了CFD模拟的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自主代理在物理模拟（如CFD）中存在局限性，因为LLM的概率特性难以保证物理守恒和数值稳定性。纯语义检索增强生成（RAG）会导致“上下文污染”，产生在物理上无效的配置，存在语义-物理脱节。

Method: PhyNiKCE是一个神经符号代理框架，它将神经网络规划与符号验证解耦。它包含一个符号知识引擎，将模拟设置视为约束满足问题，并使用确定性RAG引擎来强制执行物理约束，包括求解器、湍流模型和边界条件。该框架使用Gemini-2.5-Pro/Flash进行了OpenFOAM实验验证。

Result: PhyNiKCE在实际CFD任务上相对于最先进的基线提高了96%。它将自主自我修正循环减少了59%，同时降低了LLM的token消耗17%。

Conclusion: 将神经网络生成与符号约束强制执行解耦，可以显著提高自主代理在工程应用中的鲁棒性和效率。PhyNiKCE架构为更广泛的工业自动化领域的可信人工智能提供了一个可扩展、可审计的范例。

Abstract: The deployment of autonomous agents for Computational Fluid Dynamics (CFD), is critically limited by the probabilistic nature of Large Language Models (LLMs), which struggle to enforce the strict conservation laws and numerical stability required for physics-based simulations. Reliance on purely semantic Retrieval Augmented Generation (RAG) often leads to "context poisoning," where agents generate linguistically plausible but physically invalid configurations due to a fundamental Semantic-Physical Disconnect. To bridge this gap, this work introduces PhyNiKCE (Physical and Numerical Knowledgeable Context Engineering), a neurosymbolic agentic framework for trustworthy engineering. Unlike standard black-box agents, PhyNiKCE decouples neural planning from symbolic validation. It employs a Symbolic Knowledge Engine that treats simulation setup as a Constraint Satisfaction Problem, rigidly enforcing physical constraints via a Deterministic RAG Engine with specialized retrieval strategies for solvers, turbulence models, and boundary conditions. Validated through rigorous OpenFOAM experiments on practical, non-tutorial CFD tasks using Gemini-2.5-Pro/Flash, PhyNiKCE demonstrates a 96% relative improvement over state-of-the-art baselines. Furthermore, by replacing trial-and-error with knowledge-driven initialization, the framework reduced autonomous self-correction loops by 59% while simultaneously lowering LLM token consumption by 17%. These results demonstrate that decoupling neural generation from symbolic constraint enforcement significantly enhances robustness and efficiency. While validated on CFD, this architecture offers a scalable, auditable paradigm for Trustworthy Artificial Intelligence in broader industrial automation.

</details>


### [30] [Benchmark Health Index: A Systematic Framework for Benchmarking the Benchmarks of LLMs](https://arxiv.org/abs/2602.11674)
*Longyuan Zhu,Hairan Hua,Linlin Miao,Bing Zhao*

Main category: cs.AI

TL;DR: 本研究提出了Benchmark Health Index (BHI)，一个数据驱动的框架，用于评估LLM基准测试的可靠性，解决了当前基准测试中存在的评分膨胀和选择性报告问题。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM基准测试在衡量模型进展方面变得越来越不可靠，评分膨胀和选择性报告削弱了其权威性，导致社区对评估结果的信任度下降。

Method: BHI框架从三个维度（能力区分度、抗饱和度和影响力）来审计评估集。研究人员分析了2025年91个代表性模型的106个已验证基准测试的技术报告，以系统地描述评估格局。

Result: BHI是第一个宏观量化基准测试健康状况的框架。该研究系统地表征了评估格局，为选择基准测试提供了原则性依据，并支持下一代评估协议的动态生命周期管理。

Conclusion: BHI为评估LLM基准测试的健康状况提供了一种新的、数据驱动的方法，有助于社区更可靠地选择和管理评估工具，从而促进LLM研究的健康发展。

Abstract: Large Language Models (LLMs) are advancing rapidly, yet the benchmarks used to measure this progress are becoming increasingly unreliable. Score inflation and selective reporting have eroded the authority of standard benchmarks, leaving the community uncertain about which evaluation results remain trustworthy. We introduce the Benchmark Health Index (BHI), a pure data-driven framework for auditing evaluation sets along three orthogonal and complementary axes: (1) Capability Discrimination, measuring how sharply a benchmark separates model performance beyond noise; (2) Anti-Saturation, estimating remaining headroom before ceiling effects erode resolution and thus the benchmark's expected longevity; and (3) Impact, quantifying influence across academic and industrial ecosystems via adoption breadth and practice-shaping power. By distilling 106 validated benchmarks from the technical reports of 91 representative models in 2025, we systematically characterize the evaluation landscape. BHI is the first framework to quantify benchmark health at a macro level, providing a principled basis for benchmark selection and enabling dynamic lifecycle management for next-generation evaluation protocols.

</details>


### [31] [Right for the Wrong Reasons: Epistemic Regret Minimization for Causal Rung Collapse in LLMs](https://arxiv.org/abs/2602.11675)
*Edward Y. Chang*

Main category: cs.AI

TL;DR: 研究发现，机器学习系统中的“因错误原因而正确”的现象源于自回归训练无法区分关联和干预，导致“rung collapse”和“aleatoric entrenchment”。文章提出了“epistemic regret minimization”（ERM）来解决这个问题，并给出了理论证明和实验验证。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统在面对分布变化时会表现出“因错误原因而正确”的病态行为，即通过捷径取得高分但无法泛化。这种现象的根本原因是模型无法区分观察性关联 P(Y|X) 和干预性因果关系 P(Y|do(X))。

Method: 提出“epistemic regret minimization”（ERM）作为一种信念修正目标，独立于任务成功与否来惩罚因果推理中的错误。ERM嵌入在一个三层架构中，包含三个关键贡献：1) 物理接地定理，证明了满足执行器独立性的动作可以实现有效的do-操作；2) ERM作为符合AGM公设的因果信念修正算子，即使在模型因错误原因成功时也能防止固化；3) 失败模式分类，用于识别和注入领域无关的保护机制，实现跨领域迁移。

Result: 理论证明了ERM可以渐进地恢复真实的干预分布，并提供了有限样本界限。实验结果表明，在1,360个因果陷阱场景中，“rung collapse”在包括GPT-5.2在内的先进大型语言模型中普遍存在（3.7%），即使是推理增强模型也未能幸免。可操纵性表现出反向缩放，越先进的模型越难通过通用纠正来修正。与仅依赖结果反馈的模型相比，ERM反馈能够恢复53-59%的固化错误。

Conclusion: 自回归训练是导致机器学习模型“因错误原因而正确”的关键因素。ERM作为一种因果信念修正机制，能够有效解决“rung collapse”和“aleatoric entrenchment”问题，显著提高模型在分布变化和因果陷阱场景下的鲁棒性和可信度，并表现出比结果反馈更优越的性能。

Abstract: Machine learning systems that are "right for the wrong reasons" achieve high performance through shortcuts that collapse under distributional shift. We show this pathology has a precise causal origin: autoregressive training provides no gradient signal to distinguish association P(Y|X) from intervention P(Y|do(X)), a failure we formalize as Rung Collapse. When outcome-based learning reinforces correct answers obtained through incorrect causal models, the agent becomes entrenched in flawed reasoning, a phenomenon we term Aleatoric Entrenchment. We propose Epistemic Regret Minimization (ERM), a belief revision objective that penalizes errors in causal reasoning independently of task success, and embed it within a three-layer architecture with three contributions grounded in knowledge representation: (1) a Physical Grounding Theorem proving that actions satisfying actuator independence implement valid do-operations, bridging action languages and do-calculus; (2) ERM as a causal belief revision operator satisfying AGM postulates, preventing entrenchment even when the agent succeeds for the wrong reasons; and (3) a failure mode taxonomy that classifies recurring reasoning errors and injects domain-independent guards, enabling cross-domain transfer. We prove asymptotic recovery of the true interventional distribution with finite-sample bounds. Experiments on 1,360 causal trap scenarios across six frontier LLMs reveal that Rung Collapse persists even in reasoning-enhanced models (3.7% for GPT-5.2), that steerability exhibits inverse scaling where advanced models resist generic correction, and that targeted ERM feedback recovers 53-59% of entrenched errors where outcome-level feedback fails.

</details>


### [32] [Beyond Pixels: Vector-to-Graph Transformation for Reliable Schematic Auditing](https://arxiv.org/abs/2602.11678)
*Chengwei Ma,Zhen Tian,Zhou Zhou,Zhixian Xu,Xiaowei Zhu,Xia Hua,Si Shi,F. Richard Yu*

Main category: cs.AI

TL;DR: 本研究提出了一种将CAD图纸转换为属性图（V2G管道）的方法，以解决现有多模态大语言模型（MLLMs）在理解工程示意图结构方面的不足，并在电气合规性检查基准测试中取得了显著的准确性提升。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在视觉理解方面表现出色，但在处理工程示意图时存在“结构盲区”，无法捕捉拓扑和符号逻辑，这是因为其像素驱动的范式忽略了矢量定义的必要关系。

Method: 提出了一种矢量到图（V2G）的管道，将CAD图纸转换为属性图，其中节点代表组件，边代表连接关系，从而使结构依赖性显式化且可机器审计。

Result: 在电气合规性检查的诊断基准测试中，V2G方法在所有错误类别中都带来了显著的准确性提升，而领先的MLLMs在该任务上的表现接近随机水平。

Conclusion: 研究结果表明，基于像素的方法在工程领域存在系统性不足，而结构感知的表示方法是实现多模态AI在工程领域实际应用的可行途径。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual understanding, yet they suffer from a critical limitation: structural blindness. Even state-of-the-art models fail to capture topology and symbolic logic in engineering schematics, as their pixel-driven paradigm discards the explicit vector-defined relations needed for reasoning. To overcome this, we propose a Vector-to-Graph (V2G) pipeline that converts CAD diagrams into property graphs where nodes represent components and edges encode connectivity, making structural dependencies explicit and machine-auditable. On a diagnostic benchmark of electrical compliance checks, V2G yields large accuracy gains across all error categories, while leading MLLMs remain near chance level. These results highlight the systemic inadequacy of pixel-based methods and demonstrate that structure-aware representations provide a reliable path toward practical deployment of multimodal AI in engineering domains. To facilitate further research, we release our benchmark and implementation at https://github.com/gm-embodied/V2G-Audit.

</details>


### [33] [ThinkRouter: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces](https://arxiv.org/abs/2602.11683)
*Xin Xu,Tong Yu,Xiang Chen,Haoliang Wang,Julian McAuley,Saayan Mitra*

Main category: cs.AI

TL;DR: 本文提出了一种名为ThinkRouter的推理时置信度感知路由机制，通过在低置信度时切换到离散空间、高置信度时保留在潜在空间，来提高大型推理模型的准确性并减少生成长度，解决了潜在推理中的置信度动力学和噪声问题。


<details>
  <summary>Details</summary>
Motivation: 现有潜在推理方法效果不稳定，分析发现错误推理轨迹中的低置信度步骤少于正确轨迹，且低置信度替代选项的软嵌入聚合会引入噪声，导致高置信度但不可靠的推理。

Method: 提出ThinkRouter，一个在推理时根据模型置信度动态路由的机制。当模型置信度低时，路由到离散Token空间；当模型置信度高时，路由到潜在空间。

Result: 在STEM推理和编码基准测试中，ThinkRouter相比于显式CoT、随机路由和潜在推理基线，准确率平均提升19.70个百分点（Pass@1），并减少了高达15.55%的生成长度。

Conclusion: ThinkRouter能够校准显式CoT和潜在推理的错误，通过全局降低模型置信度来加速思考结束Token的生成，有效提升了推理效率和准确性。

Abstract: Recent work explores latent reasoning to improve reasoning efficiency by replacing explicit reasoning trajectories with continuous representations in a latent space, yet its effectiveness varies across settings. Analysis of model confidence dynamics under latent reasoning reveals that thinking trajectories ending in incorrect answers contain fewer low-confidence steps than those ending in correct answers. Meanwhile, we suggest that soft embeddings aggregated by multiple low-confidence thinking alternatives may introduce and propagate noise, leading to high confidence in unreliable reasoning trajectories. Motivated by these observations, ThinkRouter, an inference-time confidence-aware routing mechanism is proposed to avoid high confidence and noise for efficient reasoning. ThinkRouter routes thinking to the discrete token space when model confidence is low, and to the latent space otherwise. Extensive experiments on STEM reasoning and coding benchmarks across diverse large reasoning models demonstrate that ThinkRouter outperforms explicit CoT, random routing, and latent reasoning baselines in terms of accuracy, achieving an average improvement of 19.70 points in Pass@1, while reducing generation length by up to 15.55%. Further comprehensive analysis reveals that ThinkRouter can calibrate errors arising from explicit CoT and latent reasoning, and accelerates end-of-thinking token generation by globally lowering model confidence.

</details>


### [34] [Beyond Parameter Arithmetic: Sparse Complementary Fusion for Distribution-Aware Model Merging](https://arxiv.org/abs/2602.11717)
*Weihong Lin,Lin Sun,Qilong Shi,Aomufei Yuan,Yuxuan Tian,Zhengyang Wang,Guangxiang Zhao,Xiangzheng Zhang,Tong Yang*

Main category: cs.AI

TL;DR: 提出了一种名为稀疏互补融合与反向KL（SCF-RKL）的新型模型合并框架，通过稀疏、感知分布的更新来控制函数干扰，以解决现有模型合并方法中的参数空间启发式问题导致的泛化能力下降和生成不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有的模型合并方法在参数空间中进行操作，容易产生严重的干扰，导致模型泛化能力下降和生成行为不稳定（如重复和不连贯的输出）。

Method: SCF-RKL框架不依赖于参数空间中的线性加性假设，而是使用反向KL散度来衡量模型之间的函数发散性，并选择性地融合互补参数。该方法通过模式搜索和稀疏诱导设计来控制函数干扰，从而在整合新能力的同时保留稳定的表示。

Result: SCF-RKL在模型规模和架构上进行了广泛评估，涵盖了推理和指令微调模型。在包括高级推理、通用推理和知识、指令遵循和安全在内的24个基准测试中，SCF-RKL表现持续优于现有模型合并方法，同时保持了强大的泛化能力和生成稳定性。

Conclusion: SCF-RKL是一种有效的新型模型合并框架，通过显式控制函数干扰，能够比现有方法更优地整合模型能力，同时保持良好的泛化性和生成稳定性。

Abstract: Model merging has emerged as a promising paradigm for composing the capabilities of large language models by directly operating in weight space, enabling the integration of specialized models without costly retraining. However, existing merging methods largely rely on parameter-space heuristics, which often introduce severe interference, leading to degraded generalization and unstable generation behaviors such as repetition and incoherent outputs. In this work, we propose Sparse Complementary Fusion with reverse KL (SCF-RKL), a novel model merging framework that explicitly controls functional interference through sparse, distribution-aware updates. Instead of assuming linear additivity in parameter space, SCF-RKL measures the functional divergence between models using reverse Kullback-Leibler divergence and selectively incorporates complementary parameters. This mode-seeking, sparsity-inducing design effectively preserves stable representations while integrating new capabilities. We evaluate SCF-RKL across a wide range of model scales and architectures, covering both reasoning-focused and instruction-tuned models. Extensive experiments on 24 benchmarks spanning advanced reasoning, general reasoning and knowledge, instruction following, and safety demonstrate, vision classification that SCF-RKL consistently outperforms existing model merging methods while maintaining strong generalization and generation stability.

</details>


### [35] [Cross-Architecture Model Diffing with Crosscoders: Unsupervised Discovery of Differences Between LLMs](https://arxiv.org/abs/2602.11729)
*Thomas Jiralerspong,Trenton Bricken*

Main category: cs.AI

TL;DR: 本研究首次将 Crosscoders 应用于跨架构模型 diffing，并引入了 Dedicated Feature Crosscoders (DFCs) 来更好地分离模型独有特征。研究发现了 Qwen3-8B 和 Deepseek-R1-0528-Qwen3-8B 的中共对齐、Llama3.1-8B-Instruct 的美国例外主义以及 GPT-OSS-20B 的版权拒绝机制。


<details>
  <summary>Details</summary>
Motivation: 现有的模型 diffing 方法主要集中在基线模型与其微调版本的比较，但对于新发布的、具有新架构的模型，跨架构的比较至关重要。Crosscoders 是一种能够进行跨架构模型 diffing 的方法，但此前仅用于基线与微调模型的比较。

Method: 研究首次将 Crosscoders 应用于跨架构模型 diffing，并提出了一种名为 Dedicated Feature Crosscoders (DFCs) 的架构修改，旨在更有效地分离不同模型独有的特征。通过无监督的方式应用此技术。

Result: 成功发现了 Qwen3-8B 和 Deepseek-R1-0528-Qwen3-8B 中的中国共产党对齐特征，Llama3.1-8B-Instruct 中的美国例外主义特征，以及 GPT-OSS-20B 中的版权拒绝机制。

Conclusion: 跨架构 Crosscoder 模型 diffing 是一种有效识别 AI 模型之间有意义行为差异的方法，本研究为这一领域的研究奠定了基础。

Abstract: Model diffing, the process of comparing models' internal representations to identify their differences, is a promising approach for uncovering safety-critical behaviors in new models. However, its application has so far been primarily focused on comparing a base model with its finetune. Since new LLM releases are often novel architectures, cross-architecture methods are essential to make model diffing widely applicable. Crosscoders are one solution capable of cross-architecture model diffing but have only ever been applied to base vs finetune comparisons. We provide the first application of crosscoders to cross-architecture model diffing and introduce Dedicated Feature Crosscoders (DFCs), an architectural modification designed to better isolate features unique to one model. Using this technique, we find in an unsupervised fashion features including Chinese Communist Party alignment in Qwen3-8B and Deepseek-R1-0528-Qwen3-8B, American exceptionalism in Llama3.1-8B-Instruct, and a copyright refusal mechanism in GPT-OSS-20B. Together, our results work towards establishing cross-architecture crosscoder model diffing as an effective method for identifying meaningful behavioral differences between AI models.

</details>


### [36] [AIR: Improving Agent Safety through Incident Response](https://arxiv.org/abs/2602.11749)
*Zibo Xiao,Jun Sun,Junjie Chen*

Main category: cs.AI

TL;DR: 本文提出了AIR，一个用于LLM（大语言模型）代理系统的首次事件响应框架，通过自主检测、遏制、恢复和根除事件来提高LLM代理的安全性。AIR在检测、修复和根除方面实现了超过90%的成功率，并证明了自主事件响应作为LLM代理安全性的关键机制是可行的且必要的。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM代理安全机制主要侧重于预防性措施，在事件发生后缺乏有效的响应、遏制和恢复能力。因此，研究一个能够处理不可避免的事件并提高LLM代理安全性的框架具有重要意义。

Method: AIR框架通过一个领域特定语言（DSL）来管理LLM代理系统的事件响应生命周期。它集成到代理的执行循环中，实现了三个主要功能：1. 通过基于环境状态和近期上下文的语义检查来检测事件；2. 通过代理的工具指导代理执行遏制和恢复操作；3. 在根除阶段合成新的安全规则以防止未来发生类似事件。

Result: 在对三种代表性代理类型的评估中，AIR在检测、修复和根除方面的成功率均超过90%。此外，实验证明了AIR关键设计组件的必要性，验证了AIR的及时性和适度的开销，并表明LLM生成的规则在跨领域的效果上可以接近开发者编写的规则。

Conclusion: 本文的研究表明，自主事件响应是提高LLM代理安全性的可行且必要的首要机制。AIR框架能够有效地检测、遏制、恢复和根除LLM代理系统中的事件，从而显著提升其整体安全性。

Abstract: Large Language Model (LLM) agents are increasingly deployed in practice across a wide range of autonomous applications. Yet current safety mechanisms for LLM agents focus almost exclusively on preventing failures in advance, providing limited capabilities for responding to, containing, or recovering from incidents after they inevitably arise. In this work, we introduce AIR, the first incident response framework for LLM agent systems. AIR defines a domain-specific language for managing the incident response lifecycle autonomously in LLM agent systems, and integrates it into the agent's execution loop to (1) detect incidents via semantic checks grounded in the current environment state and recent context, (2) guide the agent to execute containment and recovery actions via its tools, and (3) synthesize guardrail rules during eradication to block similar incidents in future executions. We evaluate AIR on three representative agent types. Results show that AIR achieves detection, remediation, and eradication success rates all exceeding 90%. Extensive experiments further confirm the necessity of AIR's key design components, show the timeliness and moderate overhead of AIR, and demonstrate that LLM-generated rules can approach the effectiveness of developer-authored rules across domains. These results show that incident response is both feasible and essential as a first-class mechanism for improving agent safety.

</details>


### [37] [Text2GQL-Bench: A Text to Graph Query Language Benchmark [Experiment, Analysis & Benchmark]](https://arxiv.org/abs/2602.11745)
*Songlin Lyu,Lujie Ban,Zihang Wu,Tianqi Luo,Jirong Liu,Chenhao Ma,Yuyu Luo,Nan Tang,Shipeng Qi,Heng Lin,Yongchao Liu,Chuntao Hong*

Main category: cs.AI

TL;DR: 本文提出了Text2GQL-Bench，一个包含178,184个问答对、跨越13个领域的统一Text-to-GQL基准，并引入了多维度的评估方法。结果显示，LLMs在ISO-GQL生成方面存在显著的方言差距，零样本准确率极低，即使是经过微调的模型也仅能达到45.1%的执行准确率，表明提供充足的ISO-GQL示例至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-GQL数据集在领域覆盖、支持的查询语言和评估范围上存在局限性，阻碍了该领域的研究进展。缺乏高质量的基准数据集和评估方法使得系统性地比较不同查询语言和领域下的模型能力变得困难。

Method: 构建了一个包含178,184个(问题,查询)对、跨越13个领域的Text2GQL-Bench多GQL数据集，并开发了一个可扩展的构建框架。提出了一种多维度的评估方法，联合报告语法有效性、相似度、语义对齐和执行准确率。

Result: 在Text2GQL-Bench上的评估揭示了ISO-GQL生成中的显著方言差距。零样本设置下，LLMs的执行准确率最高仅为4%。通过3-shot提示，准确率提升至约50%，但语法有效性低于70%。经过微调的8B开源模型达到了45.1%的执行准确率和90.8%的语法有效性。

Conclusion: Text2GQL-Bench为Text-to-GQL系统的研究和评估提供了一个全面的基准。研究表明，LLMs在ISO-GQL生成方面表现不佳，模型性能的大幅提升主要得益于充分接触ISO-GQL示例。

Abstract: Graph models are fundamental to data analysis in domains rich with complex relationships. Text-to-Graph-Query-Language (Text-to-GQL) systems act as a translator, converting natural language into executable graph queries. This capability allows Large Language Models (LLMs) to directly analyze and manipulate graph data, posi-tioning them as powerful agent infrastructures for Graph Database Management System (GDBMS). Despite recent progress, existing datasets are often limited in domain coverage, supported graph query languages, or evaluation scope. The advancement of Text-to-GQL systems is hindered by the lack of high-quality benchmark datasets and evaluation methods to systematically compare model capabilities across different graph query languages and domains. In this work, we present Text2GQL-Bench, a unified Text-to-GQL benchmark designed to address these limitations. Text2GQL-Bench couples a multi-GQL dataset that has 178,184 (Question, Query) pairs spanning 13 domains, with a scalable construction framework that generates datasets in different domains, question abstraction levels, and GQLs with heterogeneous resources. To support compre-hensive assessment, we introduce an evaluation method that goes beyond a single end-to-end metric by jointly reporting grammatical validity, similarity, semantic alignment, and execution accuracy. Our evaluation uncovers a stark dialect gap in ISO-GQL generation: even strong LLMs achieve only at most 4% execution accuracy (EX) in zero-shot settings, though a fixed 3-shot prompt raises accuracy to around 50%, the grammatical validity remains lower than 70%. Moreover, a fine-tuned 8B open-weight model reaches 45.1% EX, and 90.8% grammatical validity, demonstrating that most of the performance jump is unlocked by exposure to sufficient ISO-GQL examples.

</details>


### [38] [TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents](https://arxiv.org/abs/2602.11767)
*Aladin Djuhera,Swanand Ravindra Kadhe,Farhan Ahmed,Holger Boche*

Main category: cs.AI

TL;DR: 本文提出了一种名为TSR（Trajectory-Search Rollouts）的训练时方法，通过在多轮交互中引入轻量级的树状搜索来生成高质量的轨迹，从而改进了强化学习（RL）在多轮任务中的训练效果，提高了学习稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 当前使用LLM进行多轮RL训练面临稀疏/延迟奖励和环境随机性带来的挑战，简单的轨迹采样方法会阻碍利用并导致模式崩溃。

Method: TSR在训练时进行轻量级的树状搜索，利用任务特定的反馈在每一轮中选择得分较高的动作，以此构建高质量的轨迹。它不改变底层优化目标，因此与优化器无关，并可与PPO和GRPO等算法结合。

Result: 在Sokoban、FrozenLake和WebShop等任务上，TSR实现了高达15%的性能提升和更稳定的学习过程，仅增加了一次性的训练计算成本。

Conclusion: TSR是一种简单且通用的方法，通过将搜索过程移至训练的Rollout阶段，为多轮RL代理学习提供了更强的能力，且可以作为现有框架和拒绝采样方法的补充。

Abstract: Advances in large language models (LLMs) are driving a shift toward using reinforcement learning (RL) to train agents from iterative, multi-turn interactions across tasks. However, multi-turn RL remains challenging as rewards are often sparse or delayed, and environments can be stochastic. In this regime, naive trajectory sampling can hinder exploitation and induce mode collapse. We propose TSR (Trajectory-Search Rollouts), a training-time approach that repurposes test-time scaling ideas for improved per-turn rollout generation. TSR performs lightweight tree-style search to construct high-quality trajectories by selecting high-scoring actions at each turn using task-specific feedback. This improves rollout quality and stabilizes learning while leaving the underlying optimization objective unchanged, making TSR optimizer-agnostic. We instantiate TSR with best-of-N, beam, and shallow lookahead search, and pair it with PPO and GRPO, achieving up to 15% performance gains and more stable learning on Sokoban, FrozenLake, and WebShop tasks at a one-time increase in training compute. By moving search from inference time to the rollout stage of training, TSR provides a simple and general mechanism for stronger multi-turn agent learning, complementary to existing frameworks and rejection-sampling-style selection methods.

</details>


### [39] [How to Optimize Multispecies Set Predictions in Presence-Absence Modeling ?](https://arxiv.org/abs/2602.11771)
*Sébastien Gigot--Léandri,Gaétan Morand,Alexis Joly,François Munoz,David Mouillot,Christophe Botella,Maximilien Servajean*

Main category: cs.AI

TL;DR: 本文提出了MaxExp和SSE两种新的二值化方法，用于将物种分布模型（SDMs）的概率预测转换为二值化的物种分布图，以解决现有方法在类别不平衡和物种稀有性问题上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的SDMs二值化方法通常是启发式的，可能扭曲物种的普遍性和群落组成估计，尤其是在类别不平衡和物种稀有性较高的情况下。研究旨在开发更可靠、可重复的方法。

Method: MaxExp通过直接最大化选定的评估指标来选择最可能的物种组合，无需校准数据。SSE是一种计算效率更高的替代方法，基于预期的物种丰富度来预测物种组合。

Result: 在三个跨越不同类群、物种数量和性能指标的案例研究中，MaxExp在匹配或超越常用阈值和校准方法方面表现稳定，尤其是在类别不平衡和物种稀有性较高的情况下。SSE也提供了一个简单但有竞争力的选项。

Conclusion: MaxExp和SSE为多物种SDM二值化提供了稳健、可重复的工具，能够有效解决现有方法在处理类别不平衡和物种稀有性问题上的局限性。

Abstract: Species distribution models (SDMs) commonly produce probabilistic occurrence predictions that must be converted into binary presence-absence maps for ecological inference and conservation planning. However, this binarization step is typically heuristic and can substantially distort estimates of species prevalence and community composition. We present MaxExp, a decision-driven binarization framework that selects the most probable species assemblage by directly maximizing a chosen evaluation metric. MaxExp requires no calibration data and is flexible across several scores. We also introduce the Set Size Expectation (SSE) method, a computationally efficient alternative that predicts assemblages based on expected species richness. Using three case studies spanning diverse taxa, species counts, and performance metrics, we show that MaxExp consistently matches or surpasses widely used thresholding and calibration methods, especially under strong class imbalance and high rarity. SSE offers a simpler yet competitive option. Together, these methods provide robust, reproducible tools for multispecies SDM binarization.

</details>


### [40] [Multi UAVs Preflight Planning in a Shared and Dynamic Airspace](https://arxiv.org/abs/2602.12055)
*Amath Sow,Mauricio Rodriguez Cesen,Fabiola Martins Campos de Oliveira,Mariusz Wzorek,Daniel de Leng,Mattias Tiger,Fredrik Heintz,Christian Esteve Rothenberg*

Main category: cs.AI

TL;DR: 提出了一种名为DTAPP-IICR的无人机机队空域规划方法，该方法通过优先排序任务、使用SFIPP-ST规划单架次轨迹以及迭代冲突解决来提高在大规模、动态空域中的效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模无人机机队空域规划方法在面对动态的禁飞区、异构的无人机以及交付时间限制时，面临可扩展性和灵活性不足的挑战。为解决现实世界中无人机交通管理（UTM）的需求。

Method: 该框架首先根据任务紧急程度对任务进行优先排序，然后使用一种名为SFIPP-ST的4D单架次规划器（包含软时间和时序约束的安全飞行区间路径规划）计算往返轨迹。SFIPP-ST能够处理异构无人机，严格执行时序禁飞区，并将代理冲突建模为软约束。接着，利用一个基于几何冲突图的迭代大规模邻域搜索来解决剩余冲突，并通过一种保持完整性的定向剪枝技术加速搜索。

Result: 在包含时序禁飞区的基准测试中，DTAPP-IICR对于多达1000架无人机的机队实现了近100%的成功率，并且通过剪枝技术获得了高达50%的运行时长缩减。该方法在现实城市规模的运行中表现出良好的可扩展性，优于其他在同等规模下表现不佳的优先级方法，并在UTM上下文中优于批量增强冲突导向搜索。

Conclusion: DTAPP-IICR是一种实用且可扩展的无人机机队预飞规划解决方案，能够有效应对密集、动态城市空域的挑战，在保证高成功率的同时显著提高效率。

Abstract: Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framework, existing methods often lack the scalability and flexibility required for real-world Unmanned Traffic Management (UTM). We propose DTAPP-IICR: a Delivery-Time Aware Prioritized Planning method with Incremental and Iterative Conflict Resolution. Our framework first generates an initial solution by prioritizing missions based on urgency. Secondly, it computes roundtrip trajectories using SFIPP-ST, a novel 4D single-agent planner (Safe Flight Interval Path Planning with Soft and Temporal Constraints). SFIPP-ST handles heterogeneous UAVs, strictly enforces temporal NFZs, and models inter-agent conflicts as soft constraints. Subsequently, an iterative Large Neighborhood Search, guided by a geometric conflict graph, efficiently resolves any residual conflicts. A completeness-preserving directional pruning technique further accelerates the 3D search. On benchmarks with temporal NFZs, DTAPP-IICR achieves near-100% success with fleets of up to 1,000 UAVs and gains up to 50% runtime reduction from pruning, outperforming batch Enhanced Conflict-Based Search in the UTM context. Scaling successfully in realistic city-scale operations where other priority-based methods fail even at moderate deployments, DTAPP-IICR is positioned as a practical and scalable solution for preflight planning in dense, dynamic urban airspace.

</details>


### [41] [RELATE: A Reinforcement Learning-Enhanced LLM Framework for Advertising Text Generation](https://arxiv.org/abs/2602.11780)
*Jinfang Wang,Jiajie Liu,Jianwei Wu,Ziqin Luo,Zhen Chen,Chunlei Li,Biao Han,Tao Deng,Yi Li,Shuanglong Li,Lin Liu*

Main category: cs.AI

TL;DR: 提出了一种名为RELATE的端到端强化学习框架，用于在线广告文本生成，该框架将文本生成和性能指标对齐统一起来，以提高转化率。


<details>
  <summary>Details</summary>
Motivation: 现有的在线广告系统将文本生成和性能指标对齐分开进行，这导致优化目标不一致，漏斗效率低下，并限制了全局最优。

Method: 提出了一种名为RELATE的端到端强化学习框架，该框架通过策略学习将性能和合规性目标直接整合到生成过程中。RELATE将以转化为导向的指标与合规性约束结合作为多维度奖励，以捕捉比点击信号更终极的广告价值。

Result: 在大型工业数据集上的大量实验表明，RELATE的性能持续优于基线模型。在线部署到生产广告平台后，在严格的策略约束下，点击转化率（CTCVR）得到了统计上显著的提升。

Conclusion: RELATE框架通过将文本生成与多维奖励驱动的强化学习相结合，成功地实现了端到端的广告文本优化，提高了转化率，并证明了其在真实世界中的有效性。

Abstract: In online advertising, advertising text plays a critical role in attracting user engagement and driving advertiser value. Existing industrial systems typically follow a two-stage paradigm, where candidate texts are first generated and subsequently aligned with online performance metrics such as click-through rate(CTR). This separation often leads to misaligned optimization objectives and low funnel efficiency, limiting global optimality.
  To address these limitations, we propose RELATE, a reinforcement learning-based end-to-end framework that unifies generation and objective alignment within a single model. Instead of decoupling text generation from downstream metric alignment, RELATE integrates performance and compliance objectives directly into the generation process via policy learning. To better capture ultimate advertiser value beyond click-level signals, We incorporate conversion-oriented metrics into the objective and jointly model them with compliance constraints as multi-dimensional rewards, enabling the model to generate high-quality ad texts that improve conversion performance under policy constraints.
  Extensive experiments on large-scale industrial datasets demonstrate that RELATE consistently outperforms baselines. Furthermore, online deployment on a production advertising platform yields statistically significant improvements in click-through conversion rate(CTCVR) under strict policy constraints, validating the robustness and real-world effectiveness of the proposed framework.

</details>


### [42] [FlowMind: Execute-Summarize for Structured Workflow Generation from LLM Reasoning](https://arxiv.org/abs/2602.11782)
*Yihao Liu,Ziyun Zhang,Zile He,Huaqian Cai*

Main category: cs.AI

TL;DR: 本文提出了 Execute-Summarize (ES) 框架，将 LLM 的任务执行和工作流构建解耦，通过先执行任务再独立重构工作流的方式，提高了工作流的准确性和鲁棒性，并在 FlowBench 上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 在通过推理和工具使用解决复杂任务时，将解决方案准确地转化为结构化工作流仍然是一个挑战。之前在执行过程中构建工作流的方法会因两个过程的相互干扰而导致不准确。

Method: 本文提出了 Execute-Summarize (ES) 框架。该框架将任务执行和工作流构建解耦：首先，模型使用可用工具完成任务；然后，独立地从执行跟踪中重构结构化的工作流。

Result: ES 框架通过分离任务执行和工作流构建，提高了工作流的准确性和鲁棒性。在 FlowBench 上的大量实验表明，ES 方法优于现有方法。

Conclusion: ES 框架提供了一个可靠的范式，可以将 LLM 的自由形式推理转化为结构化的工作流，解决了将 LLM 解决方案准确转化为结构化工作流的挑战。

Abstract: LLMs can solve complex tasks through reasoning and tool use, but accurately translating these solutions into structured workflows remains challenging. We model workflows as sequences of tool use and reformulate the problem as designing a mechanism that can both solve tasks and reliably construct workflows. Prior approaches that build workflows during execution often suffer from inaccuracies due to interference between the two processes. We propose an Execute-Summarize(ES) framework that decouples task execution from workflow construction: the model first completes the task using available tools, then independently reconstructs a structured workflow from execution traces. This separation improves workflow accuracy and robustness. We introduce FlowBench and show through extensive experiments that our approach outperforms existing methods, providing a reliable paradigm for grounding free-form LLM reasoning into structured workflows.

</details>


### [43] [Beyond End-to-End Video Models: An LLM-Based Multi-Agent System for Educational Video Generation](https://arxiv.org/abs/2602.11790)
*Lingyong Yan,Jiulong Wu,Dong Xie,Weixian Shi,Deguo Xia,Jizhou Huang*

Main category: cs.AI

TL;DR: 本文提出了一种名为LAVES的基于LLM的多智能体系统，用于从教育问题生成高质量的教学视频，该系统通过分解任务、智能体协作和迭代审查，实现了逻辑严谨、教学连贯、视听同步且成本效益高的视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端视频生成模型在需要严格逻辑和精确知识表示的场景（如教学和教育媒体）中表现不佳。为了解决这个问题，研究者开发了一种新的系统。

Method: LAVES是一个分层的LLM多智能体系统。它将视频生成分解为解决问题、生成可视化代码和撰写教学脚本的专门智能体，并由一个中央协调智能体进行监督。该系统利用显式的质量门和迭代的批评机制，通过结构化的可执行视频脚本而非直接像素合成来生成视频，最终通过模板驱动的组装规则生成同步的视听内容。

Result: LAVES在大型部署中实现了每天超过一百万个视频的吞吐量，与当前行业标准方法相比，成本降低了95%以上，同时保持了高接受率。

Conclusion: LAVES成功地解决了现有视频生成模型在逻辑严谨性和知识表示方面的局限性，通过多智能体协作和结构化脚本生成，实现了高效、低成本且高质量的教学视频自动化生成。

Abstract: Although recent end-to-end video generation models demonstrate impressive performance in visually oriented content creation, they remain limited in scenarios that require strict logical rigor and precise knowledge representation, such as instructional and educational media. To address this problem, we propose LAVES, a hierarchical LLM-based multi-agent system for generating high-quality instructional videos from educational problems. The LAVES formulates educational video generation as a multi-objective task that simultaneously demands correct step-by-step reasoning, pedagogically coherent narration, semantically faithful visual demonstrations, and precise audio--visual alignment. To address the limitations of prior approaches--including low procedural fidelity, high production cost, and limited controllability--LAVES decomposes the generation workflow into specialized agents coordinated by a central Orchestrating Agent with explicit quality gates and iterative critique mechanisms. Specifically, the Orchestrating Agent supervises a Solution Agent for rigorous problem solving, an Illustration Agent that produces executable visualization codes, and a Narration Agent for learner-oriented instructional scripts. In addition, all outputs from the working agents are subject to semantic critique, rule-based constraints, and tool-based compilation checks. Rather than directly synthesizing pixels, the system constructs a structured executable video script that is deterministically compiled into synchronized visuals and narration using template-driven assembly rules, enabling fully automated end-to-end production without manual editing. In large-scale deployments, LAVES achieves a throughput exceeding one million videos per day, delivering over a 95% reduction in cost compared to current industry-standard approaches while maintaining a high acceptance rate.

</details>


### [44] [Detecting RLVR Training Data via Structural Convergence of Reasoning](https://arxiv.org/abs/2602.11792)
*Hongbo Zhang,Yue Yang,Jianhao Yan,Guangsheng Bao,Yue Zhang,Yue Zhang*

Main category: cs.AI

TL;DR: 研究提出了一种名为Min-kNN Distance的黑盒检测方法，用于检测强化学习（RL）训练过程中引入的基准数据污染。该方法通过量化模型对训练过的提示（prompt）生成结果的僵化程度来识别被污染的数据。


<details>
  <summary>Details</summary>
Motivation: 传统的预训练方法使用似然度进行检测，但强化学习中的可验证奖励（RLVR）方法依赖于模型生成的推理轨迹和奖励反馈，使得现有检测方法效果不佳。RLVR训练过程中可能导致基准数据污染，影响模型的公平评估。

Method: 提出Min-kNN Distance方法，该方法无需访问原始模型或token概率。具体操作是：对给定提示生成多个输出，计算这些输出之间k个最小的最近邻编辑距离的平均值。这种方法量化了RLVR训练导致的生成结果的僵化程度。

Result: 在多个RLVR训练的推理模型上进行实验，Min-kNN Distance能够可靠地区分RL训练中见过的示例和未见过的示例。实验结果表明，该方法优于现有的成员推断和RL污染检测基线方法。

Conclusion: Min-kNN Distance是一种有效且无需访问模型内部细节的黑盒检测器，能够识别RLVR训练对模型行为产生的独特影响，从而检测基准数据污染。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is central to training modern reasoning models, but the undisclosed training data raises concerns about benchmark contamination. Unlike pretraining methods, which optimize models using token-level probabilities, RLVR fine-tunes models based on reward feedback from self-generated reasoning trajectories, making conventional likelihood-based detection methods less effective. We show that RLVR induces a distinctive behavioral signature: prompts encountered during RLVR training result in more rigid and similar generations, while unseen prompts retain greater diversity. We introduce Min-$k$NN Distance, a simple black-box detector that quantifies this collapse by sampling multiple completions for a given prompt and computing the average of the $k$ smallest nearest-neighbor edit distances. Min-$k$NN Distance requires no access to the reference model or token probabilities. Experiments across multiple RLVR-trained reasoning models show that Min-$k$NN Distance reliably distinguishes RL-seen examples from unseen ones and outperforms existing membership inference and RL contamination detection baselines.

</details>


### [45] [Hi-SAM: A Hierarchical Structure-Aware Multi-modal Framework for Large-Scale Recommendation](https://arxiv.org/abs/2602.11799)
*Pingjun Pan,Tingting Zhou,Peiyao Lu,Tingting Fei,Hongxiang Chen,Chuanjiang Luo*

Main category: cs.AI

TL;DR: 本文提出了Hi-SAM，一个分层结构感知多模态推荐框架，通过解耦的语义分词器（DST）解决多模态信息表示不足的问题，以及通过分层记忆锚点Transformer（HMAT）解决Transformer架构与数据不匹配的问题，在真实数据集和大规模在线平台上的实验均取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于语义ID的多模态推荐方法在处理文本和图像等丰富物品属性时面临两个主要挑战：1. 次优分词：现有方法（如RQ-VAE）未能有效解耦跨模态共享语义和模态特有细节，导致信息冗余或信息丢失。2. 架构-数据不匹配：标准Transformer将语义ID视为扁平序列，忽略了用户交互、物品和分词之间的层级关系，导致模型倾向于关注局部细节而非整体语义。

Method: Hi-SAM框架包含两个核心设计：1. 解耦的语义分词器（DST）：通过几何感知对齐统一不同模态，并采用粗粒度到细粒度的策略进行量化。共享码本提取共识信息，模态特有码本从残差中恢复细微差别，并通过最小化互信息来强化解耦。2. 分层记忆锚点Transformer（HMAT）：通过分层RoPE将位置编码拆分为项间和项内子空间，恢复层级结构。引入锚点Token将物品压缩成紧凑的记忆，保留当前物品的细节，并通过压缩摘要访问历史信息。

Result: 在真实世界数据集上的实验表明，Hi-SAM相比现有最先进的基线模型在多个指标上都取得了持续的改进，尤其是在冷启动场景下表现突出。在服务数百万用户的某大规模社交平台上的线上部署，Hi-SAM实现了核心在线指标6.55%的提升。

Conclusion: Hi-SAM通过引入解耦的语义分词器和分层记忆锚点Transformer，有效解决了多模态推荐中的关键挑战，显著提升了推荐性能，并在实际大规模应用中验证了其有效性。

Abstract: Multi-modal recommendation has gained traction as items possess rich attributes like text and images. Semantic ID-based approaches effectively discretize this information into compact tokens. However, two challenges persist: (1) Suboptimal Tokenization: existing methods (e.g., RQ-VAE) lack disentanglement between shared cross-modal semantics and modality-specific details, causing redundancy or collapse; (2) Architecture-Data Mismatch: vanilla Transformers treat semantic IDs as flat streams, ignoring the hierarchy of user interactions, items, and tokens. Expanding items into multiple tokens amplifies length and noise, biasing attention toward local details over holistic semantics. We propose Hi-SAM, a Hierarchical Structure-Aware Multi-modal framework with two designs: (1) Disentangled Semantic Tokenizer (DST): unifies modalities via geometry-aware alignment and quantizes them via a coarse-to-fine strategy. Shared codebooks distill consensus while modality-specific ones recover nuances from residuals, enforced by mutual information minimization; (2) Hierarchical Memory-Anchor Transformer (HMAT): splits positional encoding into inter- and intra-item subspaces via Hierarchical RoPE to restore hierarchy. It inserts Anchor Tokens to condense items into compact memory, retaining details for the current item while accessing history only through compressed summaries. Experiments on real-world datasets show consistent improvements over SOTA baselines, especially in cold-start scenarios. Deployed on a large-scale social platform serving millions of users, Hi-SAM achieved a 6.55% gain in the core online metric.

</details>


### [46] [Predicting LLM Output Length via Entropy-Guided Representations](https://arxiv.org/abs/2602.11812)
*Huanyi Xie,Yubin Chen,Liangyu Wang,Lijie Hu,Di Wang*

Main category: cs.AI

TL;DR: 提出了一种轻量级框架（EGTP + PLP），利用模型内部隐藏状态进行高效的序列长度预测，解决了长尾分布带来的填充计算浪费问题，并在新基准ForeLen上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在LLM服务和RL采样中，序列长度的长尾分布导致因填充而产生显著的计算浪费。现有的静态长度预测方法开销大、泛化性差，且无法处理随机“一对多”采样场景。

Method: 提出一个轻量级框架，包含两个核心组件：1) 熵引导令牌池化（EGTP），利用即时激活和令牌熵进行低成本的高精度静态预测；2) 渐进式长度预测（PLP），在每个解码步骤动态估计剩余长度以处理随机生成。

Result: 在构建并发布的ForeLen基准测试中，EGTP的准确率达到SOTA，MAE降低了29.16%。与长度感知调度器结合，端到端吞吐量获得显著提升。

Conclusion: 该工作提出了一种新的、高效的LLM推理技术和评估基准，通过利用模型内部隐藏状态进行长度预测，有效解决了填充带来的计算浪费问题，并取得了显著的性能提升。

Abstract: The long-tailed distribution of sequence lengths in LLM serving and reinforcement learning (RL) sampling causes significant computational waste due to excessive padding in batched inference. Existing methods rely on auxiliary models for static length prediction, but they incur high overhead, generalize poorly, and fail in stochastic "one-to-many" sampling scenarios. We introduce a lightweight framework that reuses the main model's internal hidden states for efficient length prediction. Our framework features two core components: 1) Entropy-Guided Token Pooling (EGTP), which uses on-the-fly activations and token entropy for highly accurate static prediction with negligible cost, and 2) Progressive Length Prediction (PLP), which dynamically estimates the remaining length at each decoding step to handle stochastic generation. To validate our approach, we build and release ForeLen, a comprehensive benchmark with long-sequence, Chain-of-Thought, and RL data. On ForeLen, EGTP achieves state-of-the-art accuracy, reducing MAE by 29.16\% over the best baseline. Integrating our methods with a length-aware scheduler yields significant end-to-end throughput gains. Our work provides a new technical and evaluation baseline for efficient LLM inference.

</details>


### [47] [PuYun-LDM: A Latent Diffusion Model for High-Resolution Ensemble Weather Forecasts](https://arxiv.org/abs/2602.11807)
*Lianjun Wu,Shengchen Zhu,Yuxuan Liu,Liuyu Kai,Xiaoduan Feng,Duomin Wang,Wenshuo Liu,Jingxuan Zhang,Kelvin Li,Bin Wang*

Main category: cs.AI

TL;DR: 本研究提出了一种名为PuYun-LDM的改进型潜在扩散模型（LDM），用于解决高分辨率集合天气预报中LDM扩散能力受限的问题。通过引入3D Masked AutoEncoder（3D-MAE）编码天气状态演变特征，并结合变数感知掩码频率建模（VA-MFM）策略，PuYun-LDM提升了扩散能力，并在短预报时效上优于现有集合预报方法，长时效上相当。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在扩散模型（LDMs）在高分辨率集合天气预报中存在扩散能力有限的问题。这是因为气象场缺乏类似自然图像的领域无关基础模型和显式语义结构，导致基于VFM的正则化方法不适用。此外，现有的基于频率的方法在多变量气象数据中，由于变量间的频谱异质性，采用了均一化的频谱正则化，导致正则化强度不均。

Method: 研究提出了两种关键技术：1. 3D Masked AutoEncoder（3D-MAE），用于将天气状态演变特征编码为扩散模型的额外条件；2. 变数感知掩码频率建模（VA-MFM）策略，根据每个变量的频谱能量分布自适应地选择阈值。这两个组件共同构成了PuYun-LDM。

Result: PuYun-LDM提升了潜在扩散能力，并在短预报时效上取得了优于现有集合预报（ENS）的性能。在长预报时效上，其性能与ENS相当。此外，PuYun-LDM能在单个NVIDIA H200 GPU上，在五分钟内生成15天的全球天气预报，时间分辨率为6小时。

Conclusion: PuYun-LDM通过引入3D-MAE和VA-MFM，成功解决了高分辨率集合天气预报中LDM扩散能力不足的问题，并在性能和效率上取得了显著提升，为快速生成高质量天气预报提供了新的解决方案。

Abstract: Latent diffusion models (LDMs) suffer from limited diffusability in high-resolution (<=0.25°) ensemble weather forecasting, where diffusability characterizes how easily a latent data distribution can be modeled by a diffusion process. Unlike natural image fields, meteorological fields lack task-agnostic foundation models and explicit semantic structures, making VFM-based regularization inapplicable. Moreover, existing frequency-based approaches impose identical spectral regularization across channels under a homogeneity assumption, which leads to uneven regularization strength under the inter-variable spectral heterogeneity in multivariate meteorological data. To address these challenges, we propose a 3D Masked AutoEncoder (3D-MAE) that encodes weather-state evolution features as an additional conditioning for the diffusion model, together with a Variable-Aware Masked Frequency Modeling (VA-MFM) strategy that adaptively selects thresholds based on the spectral energy distribution of each variable. Together, we propose PuYun-LDM, which enhances latent diffusability and achieves superior performance to ENS at short lead times while remaining comparable to ENS at longer horizons. PuYun-LDM generates a 15-day global forecast with a 6-hour temporal resolution in five minutes on a single NVIDIA H200 GPU, while ensemble forecasts can be efficiently produced in parallel.

</details>


### [48] [Revis: Sparse Latent Steering to Mitigate Object Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2602.11824)
*Jialin Wu,Wei Shi,Han Shen,Peigui Qi,Kunsheng Tang,Zhicong Huang,Binghao Wang,Zhou Yang*

Main category: cs.AI

TL;DR: 提出了一种名为REVIS的训练无关框架，通过正交投影提取纯视觉信息向量，并采用稀疏干预策略，有效解决了大型视觉语言模型（LVLM）的对象幻觉问题，将幻觉率降低了约19%。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）经常出现对象幻觉，一个可能的原因是视觉特征和预训练文本表示在深层网络中纠缠在一起。

Method: REVIS框架利用潜在空间几何，通过正交投影提取纯视觉信息向量，并采用校准策略，在视觉信息被抑制的精确深度进行稀疏干预，从而恢复被抑制的视觉信息。

Result: 在标准基准测试中，REVIS将对象幻觉率降低了约19%，同时保持了模型的通用推理能力。

Conclusion: REVIS是一种有效的训练无关框架，能够通过恢复被抑制的视觉信息来显著减少LVLM的对象幻觉，且计算成本低廉。

Abstract: Despite the advanced capabilities of Large Vision-Language Models (LVLMs), they frequently suffer from object hallucination. One reason is that visual features and pretrained textual representations often become intertwined in the deeper network layers. To address this, we propose REVIS, a training-free framework designed to explicitly re-activate this suppressed visual information. Rooted in latent space geometry, REVIS extracts the pure visual information vector via orthogonal projection and employs a calibrated strategy to perform sparse intervention only at the precise depth where suppression occurs. This surgical approach effectively restores visual information with minimal computational cost. Empirical evaluations on standard benchmarks demonstrate that REVIS reduces object hallucination rates by approximately 19% compared to state-of-the-art baselines, while preserving general reasoning capabilities.

</details>


### [49] [Prototype Transformer: Towards Language Model Architectures Interpretable by Design](https://arxiv.org/abs/2602.11852)
*Yordan Yordanov,Matteo Forasassi,Bayar Menzat,Ruizhi Wang,Chang Qi,Markus Kaltenberger,Amine M'Charrak,Tommaso Salvatori,Thomas Lukasiewicz*

Main category: cs.AI

TL;DR: 提出了一种名为原型 Transformer (ProtoT) 的新型自回归语言模型架构，它使用原型（参数向量）替代标准的自注意力机制。ProtoT 的核心在于输入序列与原型之间的双向通信，这使得原型能够自动捕捉可命名的概念，从而提高模型的可解释性并允许进行行为定向编辑。此外，ProtoT 在计算复杂度上实现了与序列长度的线性扩展，优于 Transformer 的二次方扩展，并在文本生成和下游任务（GLUE）上表现良好，同时在输入扰动方面表现出良好的鲁棒性，并且提供了可解释的鲁棒性来源。


<details>
  <summary>Details</summary>
Motivation: 当前先进的语言模型虽然在某些领域超越人类，但其推理过程不透明，这削弱了对其输出的信任。此外，自回归语言模型虽然可以输出显式的推理，但其真实的推理过程不透明，这带来了欺骗和幻觉的风险。因此，研究人员希望开发一种更具可解释性的语言模型架构。

Method: 提出了一种名为原型 Transformer (ProtoT) 的新颖自回归语言模型架构。ProtoT 使用原型（参数向量）替代标准的自注意力机制。其工作机制是通过输入序列和原型之间的双向通信来实现的。这些原型能够自动捕获可命名的概念，并提供解释模型推理和进行行为定向编辑的途径。ProtoT 在计算上与序列长度呈线性关系，而标准的自注意力 Transformer 呈二次方关系。

Result: ProtoT 架构中的原型能够自动捕获可命名的概念（例如“女性”）。通过原型创建的通信通道能够聚合不同时间尺度的上下文信息，从而提高可解释性。ProtoT 在计算扩展性方面表现出色，与序列长度呈线性关系，优于 Transformer 的二次方关系。在文本生成和下游任务（GLUE）上，ProtoT 的表现与基线模型相当，甚至在模型和数据规模上扩展性更好。ProtoT 在输入扰动方面表现出与基线模型相当或更好的鲁棒性，并且提供了可解释的路径来展示鲁棒性和敏感性的来源。

Conclusion: ProtoT 是一种基于原型的自回归语言模型架构，它在性能上接近最先进的架构，并且具有内在的可解释性。它解决了现有语言模型推理不透明的问题，并为构建性能良好且可解释的自回归语言模型提供了新的途径。

Abstract: While state-of-the-art language models (LMs) surpass the vast majority of humans in certain domains, their reasoning remains largely opaque, undermining trust in their output. Furthermore, while autoregressive LMs can output explicit reasoning, their true reasoning process is opaque, which introduces risks like deception and hallucination. In this work, we introduce the Prototype Transformer (ProtoT) -- an autoregressive LM architecture based on prototypes (parameter vectors), posed as an alternative to the standard self-attention-based transformers. ProtoT works by means of two-way communication between the input sequence and the prototypes, and we show that this leads to the prototypes automatically capturing nameable concepts (e.g. "woman") during training. They provide the potential to interpret the model's reasoning and allow for targeted edits of its behavior. Furthermore, by design, the prototypes create communication channels that aggregate contextual information at different time scales, aiding interpretability. In terms of computation scalability, ProtoT scales linearly with sequence length vs the quadratic scalability of SOTA self-attention transformers. Compared to baselines, ProtoT scales well with model and data size, and performs well on text generation and downstream tasks (GLUE). ProtoT exhibits robustness to input perturbations on par or better than some baselines, but differs from them by providing interpretable pathways showing how robustness and sensitivity arises. Reaching close to the performance of state-of-the-art architectures, ProtoT paves the way to creating well-performing autoregressive LMs interpretable by design.

</details>


### [50] [Talk2DM: Enabling Natural Language Querying and Commonsense Reasoning for Vehicle-Road-Cloud Integrated Dynamic Maps with Large Language Models](https://arxiv.org/abs/2602.11860)
*Lu Tao,Jinxuan Luo,Yousuke Watanabe,Zhengshu Zhou,Yuhuan Lu,Shen Ying,Pan Zhang,Fei Zhao,Hiroaki Takada*

Main category: cs.AI

TL;DR: 本研究提出了VRCsim仿真框架和VRC-QA数据集，并在此基础上开发了Talk2DM模块，为动态地图（DM）系统增加了自然语言查询和常识推理能力，以增强人与车辆-道路-云（VRC）协同自动驾驶系统的人机交互。Talk2DM采用新颖的链式提示（CoP）机制，结合了人类规则和大型语言模型（LLM）的常识，并在VRC-QA数据集上验证了其高准确率和良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有动态地图（DM）系统缺乏支持自然语言的人机接口，限制了人与车辆-道路-云（VRC）协同自动驾驶系统的交互。研究旨在弥合这一差距，增强人与DM系统的互动。

Method: 1. 构建VRCsim仿真框架，用于生成流式VRC协同感知（CP）数据。
2. 基于VRCsim创建VRC-QA数据集，用于空间查询和推理。
3. 提出Talk2DM模块，一个即插即用的组件，为VRC-DM系统提供自然语言查询和常识推理能力。
4. Talk2DM的核心是链式提示（CoP）机制，结合了人类定义的规则和大型语言模型（LLM）的常识知识。

Result: Talk2DM模块在VRC-QA数据集上表现出色，能够无缝切换不同的LLM并保持高自然语言查询准确率，显示出强大的泛化能力。使用Qwen3:8B、Gemma3:27B和GPT-oss等模型时，Talk2DM实现了超过93%的准确率，平均响应时间仅为2-5秒，表明其具有很强的实用潜力。

Conclusion: Talk2DM模块成功地为动态地图（DM）系统增加了自然语言查询和常识推理能力，通过创新的CoP机制，结合了显式规则和LLM的隐式知识，实现了高准确率和快速响应，为改善人与VRC协同自动驾驶系统的交互提供了可行的解决方案。

Abstract: Dynamic maps (DM) serve as the fundamental information infrastructure for vehicle-road-cloud (VRC) cooperative autonomous driving in China and Japan. By providing comprehensive traffic scene representations, DM overcome the limitations of standalone autonomous driving systems (ADS), such as physical occlusions. Although DM-enhanced ADS have been successfully deployed in real-world applications in Japan, existing DM systems still lack a natural-language-supported (NLS) human interface, which could substantially enhance human-DM interaction. To address this gap, this paper introduces VRCsim, a VRC cooperative perception (CP) simulation framework designed to generate streaming VRC-CP data. Based on VRCsim, we construct a question-answering data set, VRC-QA, focused on spatial querying and reasoning in mixed-traffic scenes. Building upon VRCsim and VRC-QA, we further propose Talk2DM, a plug-and-play module that extends VRC-DM systems with NLS querying and commonsense reasoning capabilities. Talk2DM is built upon a novel chain-of-prompt (CoP) mechanism that progressively integrates human-defined rules with the commonsense knowledge of large language models (LLMs). Experiments on VRC-QA show that Talk2DM can seamlessly switch across different LLMs while maintaining high NLS query accuracy, demonstrating strong generalization capability. Although larger models tend to achieve higher accuracy, they incur significant efficiency degradation. Our results reveal that Talk2DM, powered by Qwen3:8B, Gemma3:27B, and GPT-oss models, achieves over 93\% NLS query accuracy with an average response time of only 2-5 seconds, indicating strong practical potential.

</details>


### [51] [Intelligent AI Delegation](https://arxiv.org/abs/2602.11865)
*Nenad Tomašev,Matija Franklin,Simon Osindero*

Main category: cs.AI

TL;DR: 提出了一种智能AI委托的自适应框架，该框架通过一系列任务分配决策来处理复杂的任务分解和委托问题，并支持跨人类和AI代理的授权、责任、角色界定、意图明确和信任建立。


<details>
  <summary>Details</summary>
Motivation: 现有AI在执行复杂任务时，其任务分解和委托方法依赖于简单的启发式规则，无法动态适应环境变化或应对意外故障，因此需要更智能、更自适应的委托机制。

Method: 提出一个自适应框架，包含一系列决策，如任务分配、权力转移、责任分配、问责机制、角色和边界的明确规定、意图清晰以及建立信任的机制。该框架适用于人类和AI委托者及被委托者。

Result: 该框架旨在信息引导新兴的Agentic Web中的协议开发，能够应用于复杂的委托网络，并支持跨人类和AI代理的交互。

Conclusion: 所提出的自适应智能AI委托框架为应对复杂任务分解和委托问题提供了一种新的解决方案，并为未来Agentic Web的发展奠定了基础。

Abstract: AI agents are able to tackle increasingly complex tasks. To achieve more ambitious goals, AI agents need to be able to meaningfully decompose problems into manageable sub-components, and safely delegate their completion across to other AI agents and humans alike. Yet, existing task decomposition and delegation methods rely on simple heuristics, and are not able to dynamically adapt to environmental changes and robustly handle unexpected failures. Here we propose an adaptive framework for intelligent AI delegation - a sequence of decisions involving task allocation, that also incorporates transfer of authority, responsibility, accountability, clear specifications regarding roles and boundaries, clarity of intent, and mechanisms for establishing trust between the two (or more) parties. The proposed framework is applicable to both human and AI delegators and delegatees in complex delegation networks, aiming to inform the development of protocols in the emerging agentic web.

</details>


### [52] [From Atoms to Trees: Building a Structured Feature Forest with Hierarchical Sparse Autoencoders](https://arxiv.org/abs/2602.11881)
*Yifan Luo,Yang Zhan,Jiedong Jiang,Tianyang Liu,Mingrui Wu,Zhennan Zhou,Bin Dong*

Main category: cs.AI

TL;DR: 本文提出了一种分层稀疏自编码器（HSAE），用于从大型语言模型（LLM）中提取具有层次结构且语义明确的特征，通过新的结构约束和特征扰动机制增强了特征间的对齐，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏自编码器（SAE）提取的LLM特征通常是孤立的，而自然语言的内在结构（特别是“特征分裂”现象）表明其是分层的。因此，需要一种方法来捕捉这种层次结构。

Method: 提出分层稀疏自编码器（HSAE），该模型联合学习一系列SAE及其特征间的父子关系。通过引入结构约束损失和随机特征扰动机制来增强父子特征的对齐。

Result: HSAE能够一致地恢复出有语义意义的层次结构，并在定性和定量指标上都得到了支持。同时，HSAE在不同字典大小下保持了标准SAE的重构保真度和可解释性。

Conclusion: HSAE是一种强大且可扩展的工具，可用于发现和分析LLM表示中嵌入的多尺度概念结构。

Abstract: Sparse autoencoders (SAEs) have proven effective for extracting monosemantic features from large language models (LLMs), yet these features are typically identified in isolation. However, broad evidence suggests that LLMs capture the intrinsic structure of natural language, where the phenomenon of "feature splitting" in particular indicates that such structure is hierarchical. To capture this, we propose the Hierarchical Sparse Autoencoder (HSAE), which jointly learns a series of SAEs and the parent-child relationships between their features. HSAE strengthens the alignment between parent and child features through two novel mechanisms: a structural constraint loss and a random feature perturbation mechanism. Extensive experiments across various LLMs and layers demonstrate that HSAE consistently recovers semantically meaningful hierarchies, supported by both qualitative case studies and rigorous quantitative metrics. At the same time, HSAE preserves the reconstruction fidelity and interpretability of standard SAEs across different dictionary sizes. Our work provides a powerful, scalable tool for discovering and analyzing the multi-scale conceptual structures embedded in LLM representations.

</details>


### [53] [When Should LLMs Be Less Specific? Selective Abstraction for Reliable Long-Form Text Generation](https://arxiv.org/abs/2602.11908)
*Shani Goren,Ido Galil,Ran El-Yaniv*

Main category: cs.AI

TL;DR: 本文提出了选择性抽象（SA）框架，允许大型语言模型（LLM）在信息不确定时，通过降低细节的特异性来提高可靠性，而不是完全放弃回答。具体来说，SA将响应分解为原子声明，并将不确定的原子替换为更笼统、但置信度更高的抽象。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易出现事实错误，这损害了用户信任并限制了其在高风险领域的应用。现有的“全有或全无”的止损机制在长文本生成中过于严苛，会丢弃有价值的信息。

Method: 首先，通过选择性风险和覆盖率对SA进行形式化。然后，提出原子级别选择性抽象（Atom-wise SA），将响应分解为原子声明，并将不确定的原子替换为更概括、但置信度更高的抽象。在评估中，构建了一个端到端的开放式生成管道，并将事实正确性作为风险指标，使用信息论度量保留的信息作为覆盖率指标。

Result: 在FactScore和LongFact-Objects基准测试上，原子级别SA在六种开源模型上一致优于现有基线。与声明移除相比，SA将风险-覆盖率曲线下面积（AURC）提高了高达27.73%，表明降低特异性可以在保持大部分原始含义的同时提高准确性和可靠性。

Conclusion: 选择性抽象（SA）框架能够有效解决LLM在信息不确定时的事实错误问题，通过降低不确定内容的特异性来权衡可靠性和信息保留，从而提升了模型的可用性，尤其是在长文本生成和高风险应用场景中。

Abstract: LLMs are widely used, yet they remain prone to factual errors that erode user trust and limit adoption in high-risk settings. One approach to mitigate this risk is to equip models with uncertainty estimation mechanisms that abstain when confidence is low. However, this binary "all-or-nothing" approach is excessively restrictive in long-form settings, often discarding valuable information. We introduce Selective Abstraction (SA), a framework that enables LLMs to trade specificity for reliability by selectively reducing the detail of uncertain content. We first formalize SA through the lenses of selective risk and coverage. We then propose Atom-wise Selective Abstraction, a claim-level instantiation that decomposes responses into atomic claims (short, self-contained statements each expressing a single fact) and replaces uncertain atoms with higher confidence, less specific abstractions. To evaluate this framework, we develop a novel end-to-end pipeline for open-ended generation that instantiates risk as factual correctness and measures coverage using an information-theoretic measure of retained information. Across six open-source models on the FactScore and LongFact-Objects benchmarks, atom-wise SA consistently outperforms existing baselines, improving the area under the risk-coverage curve (AURC) by up to 27.73% over claim removal, demonstrating that reducing specificity can boost accuracy and reliability while preserving most of their original meaning.

</details>


### [54] [AlphaPROBE: Alpha Mining via Principled Retrieval and On-graph biased evolution](https://arxiv.org/abs/2602.11917)
*Taian Guo,Haiyang Shen,Junyu Luo,Binqi Chen,Hongjun Ding,Jinsheng Huang,Luchen Liu,Yun Ma,Ming Zhang*

Main category: cs.AI

TL;DR: AlphaPROBE 提出了一种将因子挖掘视为有向无环图 (DAG) 导航的新框架，通过结合贝叶斯检索和 DAG 感知生成来克服现有方法的局限性，并在中国股市数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有自动化因子挖掘方法（解耦因子生成和迭代因子演化）缺乏全局结构视图，导致搜索冗余和多样性有限。作者希望开发一种新的方法来解决这些问题。

Method: AlphaPROBE 将因子挖掘重新定义为有向无环图 (DAG) 的策略导航。它包括两个核心组件：1. 贝叶斯因子检索器，通过后验概率模型平衡探索和利用来识别高潜力种子。2. DAG 感知因子生成器，利用因子的完整祖先追溯来生成上下文感知、无冗余的优化。

Result: 在三个中国主要股市数据集上，AlphaPROBE 相较于 8 个竞争基线，在预测准确性、回报稳定性以及训练效率方面都取得了显著的性能提升。

Conclusion: 利用全局演化拓扑对于高效、稳健的自动化因子发现至关重要。AlphaPROBE 框架有效地利用了因子之间的结构关系来改进因子挖掘。

Abstract: Extracting signals through alpha factor mining is a fundamental challenge in quantitative finance. Existing automated methods primarily follow two paradigms: Decoupled Factor Generation, which treats factor discovery as isolated events, and Iterative Factor Evolution, which focuses on local parent-child refinements. However, both paradigms lack a global structural view, often treating factor pools as unstructured collections or fragmented chains, which leads to redundant search and limited diversity. To address these limitations, we introduce AlphaPROBE (Alpha Mining via Principled Retrieval and On-graph Biased Evolution), a framework that reframes alpha mining as the strategic navigation of a Directed Acyclic Graph (DAG). By modeling factors as nodes and evolutionary links as edges, AlphaPROBE treats the factor pool as a dynamic, interconnected ecosystem. The framework consists of two core components: a Bayesian Factor Retriever that identifies high-potential seeds by balancing exploitation and exploration through a posterior probability model, and a DAG-aware Factor Generator that leverages the full ancestral trace of factors to produce context-aware, nonredundant optimizations. Extensive experiments on three major Chinese stock market datasets against 8 competitive baselines demonstrate that AlphaPROBE significantly gains enhanced performance in predictive accuracy, return stability and training efficiency. Our results confirm that leveraging global evolutionary topology is essential for efficient and robust automated alpha discovery. We have open-sourced our implementation at https://github.com/gta0804/AlphaPROBE.

</details>


### [55] [MEME: Modeling the Evolutionary Modes of Financial Markets](https://arxiv.org/abs/2602.11918)
*Taian Guo,Haiyang Shen,Junyu Luo,Zhongshi Xing,Hanchun Lian,Jinsheng Huang,Binqi Chen,Luchen Liu,Yun Ma,Ming Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为MEME的新方法，将金融市场建模为一个动态演变的投资叙事生态系统，通过理解和追踪这些“思维模式”来指导投资组合构建，并在中国股市的实证研究中取得了优于现有先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的量化金融方法要么侧重于个股预测（资产中心），要么侧重于投资组合配置（市场中心），但往往忽略了驱动市场运动的根本逻辑。研究者希望弥合这一差距，提出一种新的视角来理解和建模市场动态。

Method: 提出了一种“逻辑导向”的视角，将金融市场视为一个动态演变的、相互竞争的投资叙事（思维模式）的生态系统。具体实现上，开发了MEME（Modeling the Evolutionary Modes of Financial Markets）框架，该框架包括：1) 一个多智能体提取模块，将原始数据转化为高质量的投资论证；2) 高斯混合模型，用于在语义空间中发现潜在共识；3) 一个时间评估和对齐机制，用于跟踪模式的生命周期和历史盈利能力。

Result: 在2023-2025年中国三个不同股票池上的广泛实验表明，MEME的表现持续优于七种最先进的基线方法。消融研究、敏感性分析、生命周期案例研究和成本分析也验证了MEME识别和适应金融市场不断变化的共识的能力。

Conclusion: MEME通过将金融市场建模为演化的思维模式生态系统，并优先考虑持久的市场智慧而非短暂的异常，可以有效地指导投资组合构建，并且在实证研究中表现出优越的性能和适应性。

Abstract: LLMs have demonstrated significant potential in quantitative finance by processing vast unstructured data to emulate human-like analytical workflows. However, current LLM-based methods primarily follow either an Asset-Centric paradigm focused on individual stock prediction or a Market-Centric approach for portfolio allocation, often remaining agnostic to the underlying reasoning that drives market movements. In this paper, we propose a Logic-Oriented perspective, modeling the financial market as a dynamic, evolutionary ecosystem of competing investment narratives, termed Modes of Thought. To operationalize this view, we introduce MEME (Modeling the Evolutionary Modes of Financial Markets), designed to reconstruct market dynamics through the lens of evolving logics. MEME employs a multi-agent extraction module to transform noisy data into high-fidelity Investment Arguments and utilizes Gaussian Mixture Modeling to uncover latent consensus within a semantic space. To model semantic drift among different market conditions, we also implement a temporal evaluation and alignment mechanism to track the lifecycle and historical profitability of these modes. By prioritizing enduring market wisdom over transient anomalies, MEME ensures that portfolio construction is guided by robust reasoning. Extensive experiments on three heterogeneous Chinese stock pools from 2023 to 2025 demonstrate that MEME consistently outperforms seven SOTA baselines. Further ablation studies, sensitivity analysis, lifecycle case study and cost analysis validate MEME's capacity to identify and adapt to the evolving consensus of financial markets. Our implementation can be found at https://github.com/gta0804/MEME.

</details>


### [56] [CSEval: A Framework for Evaluating Clinical Semantics in Text-to-Image Generation](https://arxiv.org/abs/2602.12004)
*Robert Cronshaw,Konstantinos Vilouras,Junyu Yan,Yuning Du,Feng Chen,Steven McDonagh,Sotirios A. Tsaftaris*

Main category: cs.AI

TL;DR: 提出了一种名为CSEval的框架，利用语言模型评估医学图像生成中图像与文本描述的临床语义一致性，解决了现有方法仅关注图像真实性和多样性而忽略临床语义的问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到医学图像生成评估方法主要关注图像的真实性和多样性，而未能有效评估生成图像是否符合临床语义，如解剖位置和病理特征，这阻碍了生成模型在医疗领域的安全应用。

Method: 提出CSEval框架，利用大型语言模型评估生成医学图像与条件提示（prompt）之间的临床语义对齐程度。

Result: 实验表明，CSEval能够发现其他评估指标忽略的语义不一致性，并且与专家判断相关。CSEval是一种可扩展且具有临床意义的评估方法。

Conclusion: CSEval为评估医学图像生成质量提供了一种新的、更具临床意义的方法，可以作为现有评估方法的补充，促进生成模型在医疗保健领域的安全应用。

Abstract: Text-to-image generation has been increasingly applied in medical domains for various purposes such as data augmentation and education. Evaluating the quality and clinical reliability of these generated images is essential. However, existing methods mainly assess image realism or diversity, while failing to capture whether the generated images reflect the intended clinical semantics, such as anatomical location and pathology. In this study, we propose the Clinical Semantics Evaluator (CSEval), a framework that leverages language models to assess clinical semantic alignment between the generated images and their conditioning prompts. Our experiments show that CSEval identifies semantic inconsistencies overlooked by other metrics and correlates with expert judgment. CSEval provides a scalable and clinically meaningful complement to existing evaluation methods, supporting the safe adoption of generative models in healthcare.

</details>


### [57] [Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments](https://arxiv.org/abs/2602.11964)
*Romain Froger,Pierre Andrews,Matteo Bettini,Amar Budhiraja,Ricardo Silveira Cabral,Virginie Do,Emilien Garreau,Jean-Baptiste Gaya,Hugo Laurençon,Maxime Lecanu,Kunal Malkan,Dheeraj Mekala,Pierre Ménard,Gerard Moreno-Torres Bertran,Ulyana Piterbarg,Mikhail Plekhanov,Mathieu Rita,Andrey Rusakov,Vladislav Vorotilov,Mengjue Wang,Ian Yu,Amine Benhalloum,Grégoire Mialon,Thomas Scialom*

Main category: cs.AI

TL;DR: 本文提出了Gaia2，一个用于评估大型语言模型（LLM）在真实、异步环境中的基准测试。与之前的静态或同步评估不同，Gaia2引入了独立于代理动作的环境演变场景，需要代理在时间限制下运行，适应动态事件，解决歧义并与其他代理协作。每个场景都配有动作验证器，实现了细粒度的动作级别评估，可直接用于可验证奖励的强化学习。现有模型的评估显示，没有模型在所有能力上都占优，GPT-5（高）整体得分最高，但在时间敏感任务上表现不佳，Claude-4 Sonnet在准确性和速度上有所权衡，Kimi-K2是开源模型中的佼佼者。研究暴露了推理、效率、鲁棒性之间的权衡以及“仿真到现实”差距的挑战。Gaia2建立在消费级环境和开源ARE平台之上，易于扩展。通过发布Gaia2和ARE框架，旨在为社区提供一个灵活的基础设施，用于开发、基准测试和训练下一代实用代理系统。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）代理评估方法存在局限性，例如静态或同步环境，无法模拟真实世界中动态、异步且存在时间限制的场景。因此，需要一个更具挑战性和现实性的基准来评估LLM代理在复杂环境中的能力，并促进“仿真到现实”差距的缩小。

Method: 本文提出了Gaia2基准测试，其特点是：1. 引入动态、异步的环境，独立于代理动作演变。2. 包含时间限制、噪声事件、歧义解决和多代理协作等挑战。3. 每个场景都配有写入-动作验证器，实现动作级别的精细评估。4. 基于消费级环境和开源Agents Research Environments (ARE) 平台构建，易于扩展。5. 对GPT-5、Claude-4 Sonnet和Kimi-K2等模型进行了评估。

Result: 在Gaia2基准测试中，没有单一模型在所有能力上都表现最佳。GPT-5（高）在整体得分上最高（42% pass@1），但在时间敏感任务上表现不佳。Claude-4 Sonnet在准确性和速度之间进行了权衡。Kimi-K2是开源模型中的领先者（21% pass@1）。这些结果揭示了模型在推理、效率和鲁棒性方面的基本权衡，并指出了“仿真到现实”差距的挑战。

Conclusion: Gaia2为评估LLM代理在真实、异步环境中的性能提供了一个新的、更具挑战性的基准。研究结果表明，当前最先进的模型在处理动态、时间敏感和多代理交互方面仍存在显著挑战。通过提供Gaia2和ARE框架，作者旨在推动LLM代理研究社区的发展，加速实用代理系统的开发和部署。

Abstract: We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments. Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constraints, adapt to noisy and dynamic events, resolve ambiguity, and collaborate with other agents. Each scenario is paired with a write-action verifier, enabling fine-grained, action-level evaluation and making Gaia2 directly usable for reinforcement learning from verifiable rewards. Our evaluation of state-of-the-art proprietary and open-source models shows that no model dominates across capabilities: GPT-5 (high) reaches the strongest overall score of 42% pass@1 but fails on time-sensitive tasks, Claude-4 Sonnet trades accuracy and speed for cost, Kimi-K2 leads among open-source models with 21% pass@1. These results highlight fundamental trade-offs between reasoning, efficiency, robustness, and expose challenges in closing the "sim2real" gap. Gaia2 is built on a consumer environment with the open-source Agents Research Environments platform and designed to be easy to extend. By releasing Gaia2 alongside the foundational ARE framework, we aim to provide the community with a flexible infrastructure for developing, benchmarking, and training the next generation of practical agent systems.

</details>


### [58] [InjectRBP: Steering Large Language Model Reasoning Behavior via Pattern Injection](https://arxiv.org/abs/2602.12013)
*Xiuping Wu,Zhao Yu,Yuxin Cheng,Ngai Wong,Liangjun Ke,Tapas Mishra,Konstantinos V. Katsikopoulos*

Main category: cs.AI

TL;DR: 本研究提出两种无需参数更新的优化方法InjectCorrect和InjectRLOpt，通过模仿和学习模型自身的推理行为模式来提升其推理能力，并在多项推理任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有通过调整提示词来增强语言模型推理能力的研究，大多依赖直观设计且缺乏对潜在行为模式的系统性分析。本研究旨在从行为模式的角度，系统性地探究模型推理行为如何影响其推理能力。

Method: 研究者观察到模型在回答特定类型问题时会表现出适应性的推理行为模式。基于此，他们提出了两种无需参数更新的优化方法：InjectCorrect，通过模仿模型自身过往正确回答的行为模式来指导模型；InjectRLOpt，学习历史行为模式数据的价值函数，并通过提出的Reliability-Aware Softmax Policy在推理时生成行为注入以引导推理过程。

Result: 实验结果表明，InjectCorrect和InjectRLOpt方法在各种推理任务上均能提升模型性能，且无需修改模型参数。InjectCorrect方法可提升高达5.34%，InjectRLOpt方法可提升高达8.67%。

Conclusion: 通过结构化地注入模型自身的推理行为模式，可以显著影响模型推理过程和结果的质量。提出的InjectCorrect和InjectRLOpt方法能够有效提升模型在无参数更新情况下的推理能力。

Abstract: Reasoning can significantly enhance the performance of Large Language Models. While recent studies have exploited behavior-related prompts adjustment to enhance reasoning, these designs remain largely intuitive and lack a systematic analysis of the underlying behavioral patterns. Motivated by this, we investigate how models' reasoning behaviors shape reasoning from the perspective of behavioral patterns. We observe that models exhibit adaptive distributions of reasoning behaviors when responding to specific types of questions, and that structurally injecting these patterns can substantially influence the quality of the models' reasoning processes and outcomes. Building on these findings, we propose two optimization methods that require no parameter updates: InjectCorrect and InjectRLOpt. InjectCorrect guides the model by imitating behavioral patterns derived from its own past correct answers. InjectRLOpt learns a value function from historical behavior-pattern data and, via our proposed Reliability-Aware Softmax Policy, generates behavioral injectant during inference to steer the reasoning process. Our experiments demonstrate that both methods can improve model performance across various reasoning tasks without requiring any modifications to model parameters, achieving gains of up to 5.34% and 8.67%, respectively.

</details>


### [59] [Tiny Recursive Reasoning with Mamba-2 Attention Hybrid](https://arxiv.org/abs/2602.12078)
*Wenlong Wang,Fergal Reid*

Main category: cs.AI

TL;DR: 研究表明，将 Mamba-2 混合算子替换 Transformer 块集成到 TRM（一种递归推理模型）中，可以在不牺牲性能的情况下提高 ARC-AGI-1 任务上的 pass@2 分数，表明 SSM 算子适用于递归推理。


<details>
  <summary>Details</summary>
Motivation: Mamba-2 的状态空间递归是一种迭代细化形式，这促使研究者想知道将 Mamba-2 引入递归推理模型（如 TRM）是否能保持或提高其推理能力。

Method: 研究者将 TRM 中的 Transformer 块替换为 Mamba-2 混合算子，并保持参数量大致相同（约 6.8M）。在 ARC-AGI-1 数据集上评估了修改后模型的性能。

Result: 修改后的模型在 ARC-AGI-1 上的 pass@2 指标上提高了 2.0%（45.88% vs 43.88%），并且在更高的 K 值（如 pass@100）下性能提升更明显（+4.75%），同时保持了 pass@1 的性能。

Conclusion: Mamba-2 混合算子可以在递归推理框架内保留推理能力，证明了基于 SSM 的算子是递归推理算子设计空间中的可行选择，并为理解递归推理的最佳混合策略迈出了第一步。

Abstract: Recent work on recursive reasoning models like TRM demonstrates that tiny networks (7M parameters) can achieve strong performance on abstract reasoning tasks through latent recursion -- iterative refinement in hidden representation space without emitting intermediate tokens. This raises a natural question about operator choice: Mamba-2's state space recurrence is itself a form of iterative refinement, making it a natural candidate for recursive reasoning -- but does introducing Mamba-2 into the recursive scaffold preserve reasoning capability? We investigate this by replacing the Transformer blocks in TRM with Mamba-2 hybrid operators while maintaining parameter parity (6.83M vs 6.86M parameters). On ARC-AGI-1, we find that the hybrid improves pass@2 (the official metric) by +2.0\% (45.88\% vs 43.88\%) and consistently outperforms at higher K values (+4.75\% at pass@100), whilst maintaining pass@1 parity. This suggests improved candidate coverage -- the model generates correct solutions more reliably -- with similar top-1 selection. Our results validate that Mamba-2 hybrid operators preserve reasoning capability within the recursive scaffold, establishing SSM-based operators as viable candidates in the recursive operator design space and taking a first step towards understanding the best mixing strategies for recursive reasoning.

</details>


### [60] [LawThinker: A Deep Research Legal Agent in Dynamic Environments](https://arxiv.org/abs/2602.12056)
*Xinyu Yang,Chenlong Deng,Tongyu Wen,Binyu Xie,Zhicheng Dou*

Main category: cs.AI

TL;DR: 提出了一种名为LawThinker的自主法律研究代理，采用探索-验证-记忆策略，通过在每次知识探索后进行原子化验证来解决现有方法中中间推理步骤难以验证的问题，从而提高了法律推理的准确性和程序合规性。


<details>
  <summary>Details</summary>
Motivation: 现有法律推理方法缺乏对中间推理步骤的验证机制，导致错误（如不适用的法规引用）在推理链中未被检测到而累积。

Method: LawThinker采用探索-验证-记忆（Explore-Verify-Memorize）策略。其核心在于将验证作为知识探索后的一个原子化操作。DeepVerifier模块从知识准确性、事实-法律相关性以及程序合规性三个维度检查每次检索结果。同时，记忆模块用于在长时任务中实现跨轮次的知识复用。

Result: 在动态基准J1-EVAL上，LawThinker相比直接推理提高了24%，相比基于工作流的方法提高了11%，尤其在面向过程的指标上表现出色。在三个静态基准上的评估也证实了其泛化能力。

Conclusion: LawThinker通过在每次探索后强制执行验证，有效地解决了法律推理中中间步骤验证的难题，显著提升了法律推理的质量和过程的合规性，并具有良好的泛化能力。

Abstract: Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .

</details>


### [61] [Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication](https://arxiv.org/abs/2602.12083)
*Antonin Sulc*

Main category: cs.AI

TL;DR: 该论文提出了一种可微分模态逻辑（DML）框架，通过模态逻辑神经网络（MLNNs）实现，用于从行为数据中学习多主体系统的知识、信念、因果关系和义务，从而解决语义故障的调试问题。


<details>
  <summary>Details</summary>
Motivation: 现有的模态逻辑在处理未知或动态关系结构方面存在局限性，而多主体AI系统（从聊天机器人到自主群体）的复杂性对调试语义故障提出了挑战，需要对知识、信念、因果和义务进行推理。

Method: 论文提出了一种统一的神经符号调试框架，结合了四种模态：认知（信任）、时间（因果）、规范（义务）和认知（信念）。该框架使用可微分模态逻辑（DML），并通过模态逻辑神经网络（MLNNs）实现，使系统能够从行为数据中学习信任网络、因果链和监管边界。逻辑矛盾被转化为可学习的优化目标。

Result: 研究成果包括：1) 可解释的学习结构，其中信任和因果关系是显式的参数；2) 通过可微分公理注入知识，指导稀疏数据的学习；3) 组合式多模态推理，结合认知、时间和规范约束；4) 用于监控、主动控制和通信多主体系统的实际部署模式。研究在外交游戏和检测LLM幻觉等具体多主体场景中进行了验证。

Conclusion: 可微分模态逻辑（DML）框架通过MLNNs提供了一种有效的方法，可以从行为数据中学习和推理多主体系统的复杂关系，从而实现更强大的语义故障调试和系统控制。

Abstract: As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to learn trust networks, causal chains, and regulatory boundaries from behavioral data alone.
  We present a unified neurosymbolic debugging framework through four modalities: epistemic (who to trust), temporal (when events cause failures), deontic (what actions are permitted), and doxastic (how to interpret agent confidence). Each modality is demonstrated on concrete multi-agent scenarios, from discovering deceptive alliances in diplomacy games to detecting LLM hallucinations, with complete implementations showing how logical contradictions become learnable optimization objectives. Key contributions for the neurosymbolic community: (1) interpretable learned structures where trust and causality are explicit parameters, not opaque embeddings; (2) knowledge injection via differentiable axioms that guide learning with sparse data (3) compositional multi-modal reasoning that combines epistemic, temporal, and deontic constraints; and (4) practical deployment patterns for monitoring, active control and communication of multi-agent systems. All code provided as executable Jupyter notebooks.

</details>


### [62] [Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty](https://arxiv.org/abs/2602.12113)
*Zewei Yu,Lirong Gao,Yuke Zhu,Bo Zheng,Sheng Guo,Haobo Wang,Junbo Zhao*

Main category: cs.AI

TL;DR: 提出了一种名为ARLCP的强化学习框架，通过引入自适应反射惩罚和长度惩罚，来平衡大型推理模型（LRMs）的推理效率和准确性，解决其过度生成冗长思维链的问题，并在数学推理任务上取得了更好的效率-准确性权衡。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在复杂推理任务中表现出色，但测试时采用的扩展方法常导致生成过长的思维链，包含重复性自我提问和循环推理，从而消耗大量token，增加计算开销和延迟，且不一定能提高准确性，尤其是在较小模型上。研究发现，问题复杂度越高，模型越容易产生过度和不必要的反思，进而降低准确性并增加token消耗。

Method: 提出了一种名为“自适应反射与长度协调惩罚（ARLCP）”的新型强化学习框架。ARLCP包含两项关键创新：1. 反射惩罚：自适应地减少不必要的反思步骤，同时保留关键的推理过程。2. 长度惩罚：根据问题估计的复杂度来校准。通过协调这两种惩罚，ARLCP鼓励模型生成更简洁有效的推理路径。

Result: 在五个数学推理基准上，使用DeepSeek-R1-Distill-Qwen-1.5B和DeepSeek-R1-Distill-Qwen-7B模型进行了评估。结果表明，ARLCP在效率-准确性权衡方面优于现有方法。对于1.5B模型，平均响应长度减少了53.1%，同时准确性提高了5.8%。对于7B模型，长度减少了35.0%，准确性提高了2.7%。

Conclusion: ARLCP是一种有效的强化学习框架，能够动态地平衡大型推理模型的推理效率和解决方案的准确性，通过控制过度和不必要的反思步骤，生成更精炼的推理路径，并在实际应用中取得了显著的性能提升。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high token consumption, substantial computational overhead, and increased latency without improving accuracy, particularly in smaller models. Our observation reveals that increasing problem complexity induces more excessive and unnecessary reflection, which in turn reduces accuracy and increases token overhead. To address this challenge, we propose Adaptive Reflection and Length Coordinated Penalty (ARLCP), a novel reinforcement learning framework designed to dynamically balance reasoning efficiency and solution accuracy. ARLCP introduces two key innovations: (1) a reflection penalty that adaptively curtails unnecessary reflective steps while preserving essential reasoning, and (2) a length penalty calibrated to the estimated complexity of the problem. By coordinating these penalties, ARLCP encourages the model to generate more concise and effective reasoning paths. We evaluate our method on five mathematical reasoning benchmarks using DeepSeek-R1-Distill-Qwen-1.5B and DeepSeek-R1-Distill-Qwen-7B models. Experimental results show that ARLCP achieves a superior efficiency-accuracy trade-off compared to existing approaches. For the 1.5B model, it reduces the average response length by 53.1% while simultaneously improving accuracy by 5.8%. For the 7B model, it achieves a 35.0% reduction in length with a 2.7% accuracy gain. The code is released at https://github.com/ZeweiYu1/ARLCP .

</details>


### [63] [Commencing-Student Enrolment Forecasting Under Data Sparsity with Time Series Foundation Models](https://arxiv.org/abs/2602.12120)
*Jittarin Jetwiriyanon,Teo Susnjak,Surangika Ranathunga*

Main category: cs.AI

TL;DR: 本文评估了时间序列森林（TSFM）模型在数据稀疏的高等教育招生预测中的零样本（zero-shot）性能，并引入了一个名为“机构运营条件指数”（IOCI）的新型可迁移协变量，与谷歌趋势相结合，以提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 高等教育机构面临财务压力，需要准确预测入学人数。然而，现有的招生数据往往稀疏且易受报告变化和结构性转变的影响，导致传统预测方法在参数估计和模型选择上不稳定，并且外推能力受损。

Method: 本文在零样本设置下，对多种TSFM模型族进行基准测试，并测试了一套紧凑且避免数据泄露的协变量。引入了可迁移的0-100范围的IOCI协变量（基于时间戳的文献证据）和谷歌趋势需求代理，并进行了特征工程以稳定模型。采用扩展窗口回溯测试，并严格对齐数据发布年份。

Result: 在零样本设置下，经过协变量条件化的TSFM模型在预测性能上与不含机构特定训练的经典基准模型相当。性能差异因学生群体和模型而异。

Conclusion: TSFM模型在数据稀疏的高等教育招生预测中，尤其是在零样本设置下，展现出与传统方法相当的性能，并且引入IOCI和谷歌趋势等协变量有助于提高其预测能力。

Abstract: Many universities face increasing financial pressure and rely on accurate forecasts of commencing enrolments. However, enrolment forecasting in higher education is often data-sparse; annual series are short and affected by reporting changes and regime shifts. Popular classical approaches can be unreliable, as parameter estimation and model selection are unstable with short samples, and structural breaks degrade extrapolation. Recently, TSFMs have provided zero-shot priors, delivering strong gains in annual, data-sparse institutional forecasting under leakage-disciplined covariate construction. We benchmark multiple TSFM families in a zero-shot setting and test a compact, leakage-safe covariate set and introduce the Institutional Operating Conditions Index (IOCI), a transferable 0-100 regime covariate derived from time-stamped documentary evidence available at each forecast origin, alongside Google Trends demand proxies with stabilising feature engineering. Using an expanding-window backtest with strict vintage alignment, covariate-conditioned TSFMs perform on par with classical benchmarks without institution-specific training, with performance differences varying by cohort and model.

</details>


### [64] [The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context](https://arxiv.org/abs/2602.12108)
*Xiaoyuan Liu,Tian Liang,Dongyang Ma,Deyu Zhou,Haitao Mi,Pinjia He,Yan Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为 StateLM 的新型基础模型，它拥有一个内部推理循环来管理自身状态，并能主动使用记忆工具（如上下文剪枝、文档索引和笔记）来动态构建其上下文，从而摆脱了固定上下文窗口的限制。实验表明 StateLM 在长文档问答、聊天记忆和深度研究任务上均显著优于标准 LLM。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在处理信息时缺乏主动性，它们依赖于手动输入的固定上下文，无法像邓布利多在冥想盆中管理记忆那样自主管理其“记忆”。研究者希望为模型赋予自主管理上下文的能力，使其能够更有效地利用信息。

Method: 提出 StateLM，一种具备内部推理循环的基础模型。该模型被赋予了一套记忆工具（上下文剪枝、文档索引、笔记），并接受训练以主动管理这些工具。通过学习动态地构建自身上下文，StateLM 能够突破固定上下文窗口的限制。

Result: 在长文档问答任务上，StateLM 在所有模型规模下均持续优于标准 LLM。在聊天记忆任务上，StateLM 的准确率比标准 LLM 提高了 10% 到 20%。在深度研究任务 BrowseComp-Plus 上，StateLM 的准确率高达 52%，而标准 LLM 仅有 5% 左右。

Conclusion: StateLM 将 LLMs 从被动的预测者转变为具有状态感知的智能体，使得推理过程成为一个可控的、有状态的过程。该方法有效地提升了模型在需要长期记忆和动态上下文管理任务上的表现。

Abstract: In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the "wand" to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model's hand. We introduce StateLM, a new class of foundation models endowed with an internal reasoning loop to manage their own state. We equip our model with a suite of memory tools, such as context pruning, document indexing, and note-taking, and train it to actively manage these tools. By learning to dynamically engineering its own context, our model breaks free from the architectural prison of a fixed window. Experiments across various model sizes demonstrate StateLM's effectiveness across diverse scenarios. On long-document QA tasks, StateLMs consistently outperform standard LLMs across all model scales; on the chat memory task, they achieve absolute accuracy improvements of 10% to 20% over standard LLMs. On the deep research task BrowseComp-Plus, the performance gap becomes even more pronounced: StateLM achieves up to 52% accuracy, whereas standard LLM counterparts struggle around 5%. Ultimately, our approach shifts LLMs from passive predictors to state-aware agents where reasoning becomes a stateful and manageable process.

</details>


### [65] [HLA: Hadamard Linear Attention](https://arxiv.org/abs/2602.12128)
*Hanno Ackermann,Hong Cai,Mohsen Ghafoorian,Amirhossein Habibian*

Main category: cs.AI

TL;DR: 本文提出了一种名为Hadamard线性注意力（HLA）的新型注意力机制，它通过在计算相似度后应用非线性来近似Softmax注意力，从而在保持效率的同时提高了近似精度，并成功应用于视频生成扩散Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer的二次注意力计算成本高昂，而现有的线性注意力方法通过独立应用核函数来近似Softmax，但这种近似的精度有限。研究动机在于开发一种更高效且近似精度更高的线性注意力方法。

Method: 提出Hadamard线性注意力（HLA），其核心在于将非线性函数应用于查询和键的相似度计算之后，而不是之前。这使得HLA能够近似更高阶的有理函数，从而比其他线性注意力方法更准确地逼近Softmax。HLA还设计了一种高效的计算方案，避免了耗时的张量重塑。

Result: HLA的有效性在视频生成的大型扩散Transformer模型上得到了验证。该模型处理大量token，而HLA在这种大规模应用中表现出色，显示了其效率和准确性。

Conclusion: Hadamard线性注意力（HLA）是一种有效且计算高效的线性注意力机制，它通过在计算相似度后应用非线性来改进Softmax近似，尤其适用于需要处理大量token的任务，如视频生成。

Abstract: The attention mechanism is an important reason for the success of transformers. It relies on computing pairwise relations between tokens. To reduce the high computational cost of standard quadratic attention, linear attention has been proposed as an efficient approximation. It employs kernel functions that are applied independently to the inputs before the pairwise similarities are calculated. That allows for an efficient computational procedure which, however, amounts to a low-degree rational function approximating softmax.
  We propose Hadamard Linear Attention (HLA). Unlike previous works on linear attention, the nonlinearity in HLA is not applied separately to queries and keys, but, analogously to standard softmax attention, after the pairwise similarities have been computed. It will be shown that the proposed nonlinearity amounts to a higher-degree rational function to approximate softmax. An efficient computational scheme for the proposed method is derived that is similar to that of standard linear attention. In contrast to other approaches, no time-consuming tensor reshaping is necessary to apply the proposed algorithm. The effectiveness of the approach is demonstrated by applying it to a large diffusion transformer model for video generation, an application that involves very large amounts of tokens.

</details>


### [66] [STAR : Bridging Statistical and Agentic Reasoning for Large Model Performance Prediction](https://arxiv.org/abs/2602.12143)
*Xiaoxiao Wang,Chunxiao Li,Junying Wang,Yijin Guo,Zijian Chen,Chunyi Li,Xiaohong Liu,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 提出了一种名为STAR的框架，该框架结合了数据驱动的统计期望和知识驱动的智能体推理，以在评估大型模型时，即使数据有限，也能做出准确且可解释的预测。


<details>
  <summary>Details</summary>
Motivation: 现有的模型评估方法成本高昂，而纯粹的统计方法或LLM方法存在不足（如模式变化、数据稀疏、缺乏解释性、不可靠等），因此需要一种更有效且可靠的评估方法。

Method: STAR框架结合了数据驱动的统计期望和知识驱动的智能体推理。它使用专门的检索器获取外部知识，并将语义特征嵌入到约束概率矩阵分解（CPMF）中以生成具有不确定性的统计期望。然后，一个受期望违反理论（EVT）指导的推理模块通过族内分析、跨模型比较和置信度感知聚合来改进预测，并提供可追溯的解释。

Result: STAR框架在得分和排名指标上均持续优于所有基线方法。在极端稀疏的情况下（每个测试模型只有1-2个观测得分），STAR在总得分上比最强的统计方法提高了14.46%。

Conclusion: STAR框架能够有效弥合数据驱动统计和知识驱动推理之间的差距，在数据稀疏的情况下也能提供准确且可解释的模型性能预测，克服了现有方法的局限性。

Abstract: As comprehensive large model evaluation becomes prohibitively expensive, predicting model performance from limited observations has become essential. However, existing statistical methods struggle with pattern shifts, data sparsity, and lack of explanation, while pure LLM methods remain unreliable. We propose STAR, a framework that bridges data-driven STatistical expectations with knowledge-driven Agentic Reasoning. STAR leverages specialized retrievers to gather external knowledge and embeds semantic features into Constrained Probabilistic Matrix Factorization (CPMF) to generate statistical expectations with uncertainty. A reasoning module guided by Expectation Violation Theory (EVT) then refines predictions through intra-family analysis, cross-model comparison, and credibility-aware aggregation, producing adjustments with traceable explanations. Extensive experiments show that STAR consistently outperforms all baselines on both score-based and rank-based metrics, delivering a 14.46% gain in total score over the strongest statistical method under extreme sparsity, with only 1--2 observed scores per test model.

</details>


### [67] [Neutral Prompts, Non-Neutral People: Quantifying Gender and Skin-Tone Bias in Gemini Flash 2.5 Image and GPT Image 1.5](https://arxiv.org/abs/2602.12133)
*Roberto Balestri*

Main category: cs.AI

TL;DR: 该研究量化了Gemini Flash 2.5和GPT Image 1.5这两个主流图像生成器在性别和肤色方面的偏见，发现即使是中性提示也会产生高度两极化的默认输出，两者都存在“默认白人”偏见，但在性别上则表现出相反的倾向。


<details>
  <summary>Details</summary>
Motivation: 测试中性提示是否会产生人口统计学上中性的输出，并量化现有商用图像生成器中的性别和肤色偏见。

Method: 生成3200张使用四种中性提示的写实图像，并采用混合颜色归一化、面部地标掩码和基于Monk（MST）、PERLA和Fitzpatrick量表的感知均匀肤色量化方法进行分析。

Result: 两个模型都显示出强烈的“默认白人”偏见（>96%的输出）。Gemini倾向于生成女性形象，而GPT则倾向于生成肤色较浅的男性形象。中性提示被证明是诊断性探测而非中性指令。

Conclusion: 中性提示并不能保证包容性的视觉输出，现有图像生成器存在显著的肤色和性别偏见，需要对算法视觉文化进行审计，并挑战“非标记语言产生包容性表征”的社会语言学假设。

Abstract: This study quantifies gender and skin-tone bias in two widely deployed commercial image generators - Gemini Flash 2.5 Image (NanoBanana) and GPT Image 1.5 - to test the assumption that neutral prompts yield demographically neutral outputs. We generated 3,200 photorealistic images using four semantically neutral prompts. The analysis employed a rigorous pipeline combining hybrid color normalization, facial landmark masking, and perceptually uniform skin tone quantification using the Monk (MST), PERLA, and Fitzpatrick scales. Neutral prompts produced highly polarized defaults. Both models exhibited a strong "default white" bias (>96% of outputs). However, they diverged sharply on gender: Gemini favored female-presenting subjects, while GPT favored male-presenting subjects with lighter skin tones. This research provides a large-scale, comparative audit of state-of-the-art models using an illumination-aware colorimetric methodology, distinguishing aesthetic rendering from underlying pigmentation in synthetic imagery. The study demonstrates that neutral prompts function as diagnostic probes rather than neutral instructions. It offers a robust framework for auditing algorithmic visual culture and challenges the sociolinguistic assumption that unmarked language results in inclusive representation.

</details>


### [68] [Value Alignment Tax: Measuring Value Trade-offs in LLM Alignment](https://arxiv.org/abs/2602.12134)
*Jiajun Chen,Hua Shen*

Main category: cs.AI

TL;DR: 本研究提出了价值对齐税（VAT）框架，用于衡量干预措施（如提示、微调）如何影响语言模型（LLMs）中相互关联的价值系统，而非仅关注目标价值的提升。研究发现，对齐通常会导致价值的非均匀、结构化共变，这是传统仅评估目标价值的方法所忽视的。


<details>
  <summary>Details</summary>
Motivation: 现有价值对齐研究往往静态地看待价值关系，忽略了提示、微调等干预手段如何重塑整个价值系统。研究者希望填补这一空白，理解对齐过程中的动态价值变化。

Method: 研究者构建了一个基于Schwartz价值理论的场景-行动数据集，收集了模型在干预前后的规范性判断配对。然后，他们提出了价值对齐税（VAT）框架，用于测量对齐引起的价值变化如何在相互连接的价值之间传播，并与目标价值的提升进行比较。最后，在不同模型、价值和对齐策略下分析了这些效果。

Result: 研究结果表明，对齐干预常常导致价值之间出现不均匀的、结构化的共变。这些系统性的、过程层面的对齐风险在仅评估目标价值的传统方法中是不可见的。

Conclusion: 价值对齐不仅影响目标价值，还会通过VAT框架揭示出对齐过程中价值系统内部的动态变化和结构化共变。这些动态变化是评估LLM价值对齐风险的关键，为理解LLM的价值对齐过程提供了新的见解。

Abstract: Existing work on value alignment typically characterizes value relations statically, ignoring how interventions - such as prompting, fine-tuning, or preference optimization - reshape the broader value system. We introduce the Value Alignment Tax (VAT), a framework that measures how alignment-induced changes propagate across interconnected values relative to achieved on-target gain. VAT captures the dynamics of value expression under alignment pressure. Using a controlled scenario-action dataset grounded in Schwartz value theory, we collect paired pre-post normative judgments and analyze alignment effects across models, values, and alignment strategies. Our results show that alignment often produces uneven, structured co-movement among values. These effects are invisible under conventional target-only evaluation, revealing systemic, process-level alignment risks and offering new insights into the dynamics of value alignment in LLMs.

</details>


### [69] [Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning](https://arxiv.org/abs/2602.12146)
*Mahdi Khodabandeh,Ghazal Shabani,Arash Yousefi Jordehi,Seyed Abolghasem Mirroshandel*

Main category: cs.AI

TL;DR: 本文提出一种基于T5语言模型和强化学习的无损数据压缩新方法，将数据压缩为token序列而非向量，有效保留数据结构，提高了压缩比。


<details>
  <summary>Details</summary>
Motivation: 传统压缩方法难以有效利用复杂数据格式的结构和冗余，现有深度学习方法依赖于模糊token结构的密集向量表示。为了克服这些限制，需要一种能保留数据token结构的新型高效压缩方法。

Method: 利用T5语言模型架构，并应用强化学习（特别是off-policy算法）来优化压缩生成的token序列长度，从而实现无损压缩。该方法将数据编码为token序列，而非传统的向量表示。

Result: 与传统方法相比，该方法在压缩比上取得了显著改进。通过利用语言模型的潜在信息，实现了高效自适应的数据压缩。

Conclusion: 所提出的基于强化学习和T5模型的压缩方法是一种高效、自适应的无损数据压缩系统，能够保留数据结构，提高压缩比，并且不依赖于外部的语法或世界知识，为各种应用提供了更强大的压缩解决方案。

Abstract: Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data formats. Recent advancements in deep learning have opened new avenues for compression; however, many existing approaches depend on dense vector representations that obscure the underlying token structure. To address these limitations, we propose a novel lossless compression method that leverages Reinforcement Learning applied to a T5 language model architecture. This approach enables the compression of data into sequences of tokens rather than traditional vector representations. Unlike auto-encoders, which typically encode information into continuous latent spaces, our method preserves the token-based structure, aligning more closely with the original data format. This preservation allows for higher compression ratios while maintaining semantic integrity. By training the model using an off-policy Reinforcement Learning algorithm, we optimize sequence length to minimize redundancy and enhance compression efficiency. Our method introduces an efficient and adaptive data compression system built upon advanced Reinforcement Learning techniques, functioning independently of external grammatical or world knowledge. This approach shows significant improvements in compression ratios compared to conventional methods. By leveraging the latent information within language models, our system effectively compresses data without requiring explicit content understanding, paving the way for more robust and practical compression solutions across various applications.

</details>


### [70] [Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision](https://arxiv.org/abs/2602.12164)
*Xiaohan He,Shiyang Feng,Songtao Huang,Lei Bai,Bin Wang,Bo Zhang*

Main category: cs.AI

TL;DR: 提出了一种名为Sci-CoE的两阶段科学推理框架，通过模型自主演化为求解器和验证器，解决了现有大型语言模型在科学推理任务中的脆弱性问题，通过稀疏监督到无监督学习的转变，并引入了几何奖励机制来提升解决方案的多样性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在科学推理任务中表现脆弱，主要归因于解决方案评估不可靠和验证策略多样性有限。

Method: 提出Sci-CoE框架，包含两个阶段：第一阶段利用少量标注数据为验证器建立基本的正确性判断锚点；第二阶段引入几何奖励机制，综合考虑共识性、可靠性和多样性，驱动模型在无标签数据上进行大规模自迭代。

Result: 在多个科学基准测试中，Sci-CoE增强了复杂推理能力，并表现出强大的可扩展性，有助于构建更鲁棒和多样化的评估系统。

Conclusion: Sci-CoE通过模型自主演化为求解器和验证器，并结合几何奖励机制，有效地提升了大型语言模型在科学推理任务中的鲁棒性和多样性。

Abstract: Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.

</details>


### [71] [GPT-4o Lacks Core Features of Theory of Mind](https://arxiv.org/abs/2602.12150)
*John Muchovej,Amanda Royka,Shane Lee,Julian Jara-Ettinger*

Main category: cs.AI

TL;DR: 本研究发现，尽管大型语言模型（LLMs）在一些社会任务中表现出色，但它们并不具备真正意义上的心智理论（ToM），即对心智状态导致行为的因果模型。LLMs在不同但逻辑等价的任务中表现不一致，且预测行为与心智状态推断之间存在低一致性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过基准测试评估LLMs的心智理论能力，但未能深入探究LLMs是否拥有心智状态和行为的因果模型，这是心智理论的关键。因此，本研究旨在基于对心智理论的认知学定义，开发并测试一个新的评估框架，以更精确地检验LLMs是否具有连贯、领域通用且一致的心智状态因果模型。

Method: 研究采用了基于认知学的心智理论定义，构建了一个新的评估框架。该框架旨在探测LLMs是否拥有一个连贯、领域通用且一致的心智状态因果模型，即模型能否在不同情境下，一致地解释心智状态如何导致行为，而不管这种模型是否与人类类似。

Result: 研究发现，虽然LLMs在简单心智理论范式中能够近似人类的判断，但在一个逻辑上等价的任务中却表现不佳。此外，LLMs在预测行为与其相应的心智状态推断之间表现出较低的一致性。

Conclusion: 研究结果表明，LLMs所展现出的社会智能并非源于一个领域通用或一致的心智理论。尽管它们能在某些任务上模仿人类行为，但缺乏对心智状态因果关系的深层、一致性理解。

Abstract: Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal model of mental states and behavior. Here, we use a cognitively-grounded definition of ToM to develop and test a new evaluation framework. Specifically, our approach probes whether LLMs have a coherent, domain-general, and consistent model of how mental states cause behavior -- regardless of whether that model matches a human-like ToM. We find that even though LLMs succeed in approximating human judgments in a simple ToM paradigm, they fail at a logically equivalent task and exhibit low consistency between their action predictions and corresponding mental state inferences. As such, these findings suggest that the social proficiency exhibited by LLMs is not the result of an domain-general or consistent ToM.

</details>


### [72] [Statistical Parsing for Logical Information Retrieval](https://arxiv.org/abs/2602.12170)
*Greg Coppola*

Main category: cs.AI

TL;DR: 本文扩展了QBBN模型，引入了否定和反向推理能力，并开发了一个能够将自然语言确定性地解析为逻辑形式的类型化槽语法。该研究通过结合LLM和QBBN，解决了形式语义学与大规模语言模型之间的矛盾，并为自然语言处理开辟了新的途径。


<details>
  <summary>Details</summary>
Motivation: 先前工作中QBBN模型存在两大不足：缺乏否定/反向推理能力以及缺乏自然语言解析器。本文旨在弥补这些不足。

Method: 1. 推理：通过引入NEG因子，使得P(x) + P(neg x) = 1，从而实现反证推理（如modus tollens）。2. 语义：提出了一种带有角色标记谓词、模态量词和三个表达层级的类型化逻辑语言。3. 句法：开发了一种类型化槽语法，能够确定性地将句子编译为逻辑形式。结合LLM进行预处理、消歧和重排序，QBBN进行推理。

Result: 1. 推理引擎成功处理了22种推理模式下的44个测试用例。2. 类型化槽语法在33个测试用例中实现了100%的正确解析，并且零歧义。3. LLM在消歧方面表现出95%的附件准确率，但在直接生成结构化解析方面表现不佳（12.4% UAS），证实了语法的重要性。4. 提出的架构（LLM预处理，语法解析，LLM重排序，QBBN推理）能够协同工作。

Conclusion: 本文成功地在QBBN中加入了否定和反向推理能力，并开发了一个高效的自然语言解析器，从而弥合了形式语义学与大规模语言模型之间的鸿沟。该研究将LLM作为自动标注器，QBBN作为验证器，遵循了Sutton的“苦涩教训”，有望推动自然语言处理领域的发展。

Abstract: In previous work (Coppola, 2024) we introduced the Quantified Boolean Bayesian Network (QBBN), a logical graphical model that implements the forward fragment of natural deduction (Prawitz, 1965) as a probabilistic factor graph. That work left two gaps: no negation/backward reasoning, and no parser for natural language.
  This paper addresses both gaps across inference, semantics, and syntax. For inference, we extend the QBBN with NEG factors enforcing P(x) + P(neg x) = 1, enabling contrapositive reasoning (modus tollens) via backward lambda messages, completing Prawitz's simple elimination rules. The engine handles 44/44 test cases spanning 22 reasoning patterns. For semantics, we present a typed logical language with role-labeled predicates, modal quantifiers, and three tiers of expressiveness following Prawitz: first-order quantification, propositions as arguments, and predicate quantification via lambda abstraction. For syntax, we present a typed slot grammar that deterministically compiles sentences to logical form (33/33 correct, zero ambiguity). LLMs handle disambiguation (95% PP attachment accuracy) but cannot produce structured parses directly (12.4% UAS), confirming grammars are necessary. The architecture: LLM preprocesses, grammar parses, LLM reranks, QBBN infers.
  We argue this reconciles formal semantics with Sutton's "bitter lesson" (2019): LLMs eliminate the annotation bottleneck that killed formal NLP, serving as annotator while the QBBN serves as verifier. Code: https://github.com/gregorycoppola/world

</details>


### [73] [Pedagogically-Inspired Data Synthesis for Language Model Knowledge Distillation](https://arxiv.org/abs/2602.12172)
*Bowei He,Yankai Chen,Xiaokun Zhang,Linghe Kong,Philip S. Yu,Xue Liu,Chen Ma*

Main category: cs.AI

TL;DR: 本文提出了一种受教育学启发的知识蒸馏框架（IOA），通过识别、组织和适配知识，以渐进式课程和掌握学习原则，提升了小型模型在复杂推理任务上的性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的知识蒸馏方法在合成数据时缺乏教育学上的考量，将知识迁移视为一次性任务，而非系统性的学习过程。

Method: 提出一个名为IOA（Knowledge Identifier, Organizer, Adapter）的三阶段框架。该框架借鉴了Bloom的掌握学习原则和Vygotsky的最近发展区理论，通过识别知识不足、组织渐进式课程和适配学生模型表示来动态地进行知识蒸馏。

Result: 在LLaMA-3.1/3.2和Qwen2.5模型上进行实验，IOA框架在DollyEval上实现了教师模型94.7%的性能，参数量不到教师模型的1/10。在复杂推理任务上，MATH任务提升19.2%，HumanEval任务提升22.3%，优于最先进的基线方法。

Conclusion: IOA框架通过引入教育学原理，实现了更系统、更有效的LLM知识蒸馏，尤其在处理复杂推理任务时表现出色，为部署高效AI系统提供了新的途径。

Abstract: Knowledge distillation from Large Language Models (LLMs) to smaller models has emerged as a critical technique for deploying efficient AI systems. However, current methods for distillation via synthetic data lack pedagogical awareness, treating knowledge transfer as a one-off data synthesis and training task rather than a systematic learning process. In this paper, we propose a novel pedagogically-inspired framework for LLM knowledge distillation that draws from fundamental educational principles. Our approach introduces a three-stage pipeline -- Knowledge Identifier, Organizer, and Adapter (IOA) -- that systematically identifies knowledge deficiencies in student models, organizes knowledge delivery through progressive curricula, and adapts representations to match the cognitive capacity of student models. We integrate Bloom's Mastery Learning Principles and Vygotsky's Zone of Proximal Development to create a dynamic distillation process where student models approach teacher model's performance on prerequisite knowledge before advancing, and new knowledge is introduced with controlled, gradual difficulty increments. Extensive experiments using LLaMA-3.1/3.2 and Qwen2.5 as student models demonstrate that IOA achieves significant improvements over baseline distillation methods, with student models retaining 94.7% of teacher performance on DollyEval while using less than 1/10th of the parameters. Our framework particularly excels in complex reasoning tasks, showing 19.2% improvement on MATH and 22.3% on HumanEval compared with state-of-the-art baselines.

</details>


### [74] [SAM3-LiteText: An Anatomical Study of the SAM3 Text Encoder for Efficient Vision-Language Segmentation](https://arxiv.org/abs/2602.12173)
*Chengxi Zeng,Yuxuan Jiang,Ge Gao,Shuai Wang,Duolikun Danier,Bin Zhu,Stevan Rudinac,David Bull,Fan Zhang*

Main category: cs.AI

TL;DR: 提出了一种名为SAM3-LiteText的轻量级文本编码框架，通过知识蒸馏优化紧凑型MobileCLIP学生模型，显著减少了SAM3模型文本编码器的参数和内存开销，同时保持了相似的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language分割模型（如SAM3）使用了为开放式语言理解设计的大型通用文本编码器，这对于结构化、语义受限的短文本分割提示来说是过度的，导致了计算和内存的巨大开销。

Method: 通过对404,796个真实分割提示进行大规模分析，揭示了文本提示中的冗余问题。在此基础上，提出SAM3-LiteText框架，用一个通过知识蒸馏优化的紧凑型MobileCLIP学生模型替换了SAM3的原始文本编码器。

Result: SAM3-LiteText将文本编码器的参数减少了高达88%，显著降低了静态内存占用。在图像和视频分割基准测试中，其分割性能与原始SAM3模型相当。

Conclusion: SAM3-LiteText是一种有效的轻量级文本编码框架，可以在不牺牲分割性能的情况下，大幅度降低Vision-Language分割模型的计算和内存成本，证明了针对特定任务优化文本编码器的可行性。

Abstract: Vision-language segmentation models such as SAM3 enable flexible, prompt-driven visual grounding, but inherit large, general-purpose text encoders originally designed for open-ended language understanding. In practice, segmentation prompts are short, structured, and semantically constrained, leading to substantial over-provisioning in text encoder capacity and persistent computational and memory overhead. In this paper, we perform a large-scale anatomical analysis of text prompting in vision-language segmentation, covering 404,796 real prompts across multiple benchmarks. Our analysis reveals severe redundancy: most context windows are underutilized, vocabulary usage is highly sparse, and text embeddings lie on low-dimensional manifold despite high-dimensional representations. Motivated by these findings, we propose SAM3-LiteText, a lightweight text encoding framework that replaces the original SAM3 text encoder with a compact MobileCLIP student that is optimized by knowledge distillation. Extensive experiments on image and video segmentation benchmarks show that SAM3-LiteText reduces text encoder parameters by up to 88%, substantially reducing static memory footprint, while maintaining segmentation performance comparable to the original model. Code: https://github.com/SimonZeng7108/efficientsam3/tree/sam3_litetext.

</details>


### [75] ["Sorry, I Didn't Catch That": How Speech Models Miss What Matters Most](https://arxiv.org/abs/2602.12249)
*Kaitlyn Zhou,Martijn Bartelds,Federico Bianchi,James Zou*

Main category: cs.AI

TL;DR: 现有的语音识别系统在实际高风险场景（如转录美国街道名称）中表现不佳，错误率高达44%，尤其对非英语母语者影响更大。研究提出了一种基于合成数据的微调方法，仅需少量数据即可显著提高街道名称转录的准确性。


<details>
  <summary>Details</summary>
Motivation: 标准语音识别基准测试表现良好，但在现实世界的高风险应用（如转录美国街道名称）中却常常失败，特别是对于非英语母语者，这会造成导航错误。

Method: 评估了15个来自OpenAI、Deepgram、Google和Microsoft的模型在录制的美国街道名称数据上的表现，量化了转录错误对地理位置的影响，并提出了一种利用开源TTS模型生成合成数据的微调方法，以提高街道名称的转录准确性。

Result: 在街道名称转录任务中，15个模型的平均错误率为44%。非英语母语者的导航距离错误是英语母语者的两倍。通过合成数据微调，非英语母语者的街道名称转录准确性相对基础模型提高了近60%。

Conclusion: 语音识别系统在基准测试和实际应用之间存在显著差距。通过合成数据生成和微调，可以一种简单且可扩展的方式显著降低高风险场景下的转录错误，尤其是有利于非英语母语者。

Abstract: Despite speech recognition systems achieving low word error rates on standard benchmarks, they often fail on short, high-stakes utterances in real-world deployments. Here, we study this failure mode in a high-stakes task: the transcription of U.S. street names as spoken by U.S. participants. We evaluate 15 models from OpenAI, Deepgram, Google, and Microsoft on recordings from linguistically diverse U.S. speakers and find an average transcription error rate of 44%. We quantify the downstream impact of failed transcriptions by geographic locations and show that mis-transcriptions systematically cause errors for all speakers, but that routing distance errors are twice as large for non-English primary speakers compared to English primary speakers. To mitigate this harm, we introduce a synthetic data generation approach that produces diverse pronunciations of named entities using open-source text-to-speech models. Fine-tuning with less than 1,000 synthetic samples improves street name transcription accuracy by nearly 60% (relative to base models) for non-English primary speakers. Our results highlight a critical gap between benchmark performance and real-world reliability in speech systems and demonstrate a simple, scalable path to reducing high-stakes transcription errors.

</details>


### [76] [Think like a Scientist: Physics-guided LLM Agent for Equation Discovery](https://arxiv.org/abs/2602.12259)
*Jianke Yang,Ohm Venkatachalam,Mohammad Kianezhad,Sharvaree Vadgama,Rose Yu*

Main category: cs.AI

TL;DR: 提出了一种名为 KeplerAgent 的新框架，该框架通过显式地模拟科学家的推理过程来发现符号方程，利用物理工具提取中间结构，并以此来指导符号回归，从而在准确性和鲁棒性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于 LLM 的方程发现方法通常直接从数据中猜测方程，忽略了科学家通常会先推断物理性质（如对称性）再以此限制方程空间的多步推理过程。因此，本研究旨在开发一个能够显式模拟这一科学推理过程的框架。

Method: KeplerAgent 是一个代理框架，它协调物理工具提取中间结构（如对称性），然后利用这些结构信息来配置符号回归引擎（如 PySINDy 和 PySR），包括函数库和结构约束。这种方法模仿了科学研究中先理解物理原理再进行方程推导的流程。

Result: 在物理方程基准测试中，KeplerAgent 在符号精度和对噪声数据的鲁棒性方面，均显著优于纯 LLM 方法和传统的基线方法。

Conclusion: KeplerAgent 通过显式地建模科学家的多步推理过程，并结合物理工具和符号回归引擎，能够更准确、更稳健地发现符号方程，为科学发现提供了一个有前景的新框架。

Abstract: Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.

</details>


### [77] [CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use](https://arxiv.org/abs/2602.12268)
*Zhen Zhang,Kaiqiang Song,Xun Wang,Yebowen Hu,Weixiang Yan,Chenyang Zhao,Henry Peng Zou,Haoyun Deng,Sathish Reddy Indurthi,Shujian Liu,Simin Ma,Xiaoyang Wang,Xin Eric Wang,Song Wang*

Main category: cs.AI

TL;DR: 提出了一种名为 CM2 的强化学习框架，通过使用基于检查清单的奖励来代替难以验证的实际任务奖励，并结合 LLM 模拟工具环境，有效提升了多轮、多步工具使用 AI 代理的性能，且训练成本较低。


<details>
  <summary>Details</summary>
Motivation: 当前的强化学习在处理需要多轮交互和调用外部工具的真实世界任务时面临挑战，包括缺乏可验证的奖励、对开放式行为的优化不足以及构建工具环境的成本高昂。

Method: CM2 框架将每轮的预期行为分解为细粒度的二元标准，并提供证据支持和结构化元数据，将开放式评估转化为更稳定的分类决策。它采用稀疏奖励分配但密集评估标准的策略，并在可扩展的 LLM 模拟工具环境中进行训练，避免了为大型工具集进行大量工程。

Result: CM2 在 tau^-Bench、BFCL-V4 和 ToolSandbox 等基准测试中，相比监督微调（SFT）分别提高了 8、10 和 12 个点。其性能可与同等规模的开源基线模型相媲美，甚至更优。

Conclusion: CM2 提供了一种可扩展的方法，可以在没有可验证奖励的情况下优化多轮、多步的工具使用 AI 代理，克服了现有强化学习在实际应用中的局限性。

Abstract: AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2, an RL framework that replaces verifiable outcome rewards with checklist rewards. CM2 decomposes each turn's intended behavior into fine-grained binary criteria with explicit evidence grounding and structured metadata, turning open-ended judging into more stable classification-style decisions. To balance stability and informativeness, our method adopts a strategy of sparse reward assignment but dense evaluation criteria. Training is performed in a scalable LLM-simulated tool environment, avoiding heavy engineering for large tool sets. Experiments show that CM2 consistently improves over supervised fine-tuning. Starting from an 8B Base model and training on an 8k-example RL dataset, CM2 improves over the SFT counterpart by 8 points on tau^-Bench, by 10 points on BFCL-V4, and by 12 points on ToolSandbox. The results match or even outperform similarly sized open-source baselines, including the judging model. CM2 thus provides a scalable recipe for optimizing multi-turn, multi-step tool-using agents without relying on verifiable rewards. Code provided by the open-source community: https://github.com/namezhenzhang/CM2-RLCR-Tool-Agent.

</details>


### [78] [Agentic Test-Time Scaling for WebAgents](https://arxiv.org/abs/2602.12276)
*Nicholas Lee,Lutfi Eren Erdogan,Chris Joseph John,Surya Krishnapillai,Michael W. Mahoney,Kurt Keutzer,Amir Gholami*

Main category: cs.AI

TL;DR: 本文提出了一种名为CATTS（Confidence-Aware Test-Time Scaling）的技术，用于动态分配多步智能体（agent）的计算资源，以提高其在长时序任务中的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时间缩放（test-time scaling）方法在多步任务中表现不佳，因为每一步的小错误会累积，并且均匀增加计算量会遇到收益递减的问题。因此，需要一种更智能的计算资源分配方法。

Method: 研究人员首先对Web智能体的推理时间缩放进行了实证研究，发现均匀增加计算量效果有限。然后，他们探索了更强的聚合策略，并发现基于LLM的仲裁者（Arbiter）虽然优于投票，但可能错误地否决高共识的决策。最终，他们利用智能体自身投票分布中派生的不确定性统计（熵和Top-1/Top-2差值）作为动态分配计算资源的信号，提出了CATTS。

Result: CATTS在WebArena-Lite和GoBrowse上的性能比ReAct提高了9.1%，同时使用的token数量比均匀缩放少2.3倍，实现了效率提升和可解释的决策规则。

Conclusion: CATTS通过利用投票不确定性来动态分配计算资源，是一种有效且高效的多步智能体性能提升技术，尤其适用于长时序任务。

Abstract: Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-time scaling for web agents. We find that uniformly increasing per-step compute quickly saturates in long-horizon environments. We then investigate stronger aggregation strategies, including an LLM-based Arbiter that can outperform naive voting, but that can overrule high-consensus decisions. We show that uncertainty statistics derived from the agent's own vote distribution (entropy and top-1/top-2 margin) correlate with downstream success and provide a practical signal for dynamic compute allocation. Based on these findings, we introduce Confidence-Aware Test-Time Scaling (CATTS), which uses vote-derived uncertainty to allocate compute only when decisions are genuinely contentious. CATTS improves performance on WebArena-Lite and GoBrowse by up to 9.1% over React while using up to 2.3x fewer tokens than uniform scaling, providing both efficiency gains and an interpretable decision rule.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [79] [DD-MDN: Human Trajectory Forecasting with Diffusion-Based Dual Mixture Density Networks and Uncertainty Self-Calibration](https://arxiv.org/abs/2602.11214)
*Manuel Hetzel,Kerim Turacan,Hannes Reichert,Konrad Doll,Bernhard Sick*

Main category: cs.CV

TL;DR: 本文提出了一种名为 DD-MDN 的端到端概率性人类轨迹预测模型，该模型结合了高位置精度、校准的不确定性和对短时观察的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注准确性、社交互动建模和多样性，而对不确定性建模、校准以及短时观察下的预测关注不足，这对于下游任务（如路径规划和避碰）至关重要。

Method: DD-MDN 模型采用少样本去噪扩散作为骨干网络，并结合双混合密度网络。该方法学习自校准的驻留区域和概率排序的锚点路径，并从中生成多样的轨迹假设，无需预定义的锚点或终点。

Result: 在 ETH/UCY、SDD、inD 和 IMPTC 数据集上的实验表明，DD-MDN 在准确性、短时观察鲁棒性以及不确定性建模方面均达到了最先进的水平。

Conclusion: DD-MDN 模型能够有效地进行人类轨迹预测，在准确性、不确定性校准和对短时观察的适应性方面表现出色，优于现有方法。

Abstract: Human Trajectory Forecasting (HTF) predicts future human movements from past trajectories and environmental context, with applications in Autonomous Driving, Smart Surveillance, and Human-Robot Interaction. While prior work has focused on accuracy, social interaction modeling, and diversity, little attention has been paid to uncertainty modeling, calibration, and forecasts from short observation periods, which are crucial for downstream tasks such as path planning and collision avoidance. We propose DD-MDN, an end-to-end probabilistic HTF model that combines high positional accuracy, calibrated uncertainty, and robustness to short observations. Using a few-shot denoising diffusion backbone and a dual mixture density network, our method learns self-calibrated residence areas and probability-ranked anchor paths, from which diverse trajectory hypotheses are derived, without predefined anchors or endpoints. Experiments on the ETH/UCY, SDD, inD, and IMPTC datasets demonstrate state-of-the-art accuracy, robustness at short observation intervals, and reliable uncertainty modeling. The code is available at: https://github.com/kav-institute/ddmdn.

</details>


### [80] [ABot-M0: VLA Foundation Model for Robotic Manipulation with Action Manifold Learning](https://arxiv.org/abs/2602.11236)
*Yandan Yang,Shuang Zeng,Tong Lin,Xinyuan Chang,Dekang Qi,Junjin Xiao,Haoyun Liu,Ronghan Chen,Yuzhi Chen,Dongjie Huo,Feng Xiong,Xing Wei,Zhiheng Ma,Mu Xu*

Main category: cs.CV

TL;DR: 本文提出ABot-M0框架，通过UniACT-dataset数据集和Action Manifold Learning (AML) 方法，解决通用具身智能体在多样化硬件上的训练挑战，实现跨平台和任务的知识迁移和泛化能力。AML将动作预测从降噪转向可行流形投影，提高效率和稳定性。ABot-M0还支持模块化感知，整合VLM语义和几何先验，增强3D理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的通用具身智能体研究面临数据碎片化、表示不一致和训练目标不匹配等问题，阻碍了在多样化硬件上的通用性。研究旨在克服这些挑战，实现“单一智能核心，多重形态应用”的目标。

Method: 1. 构建UniACT-dataset：对六个公开数据集进行清洗、标准化和平衡，形成包含超过600万轨迹和9500小时数据的多模态、多形态数据集。
2. 提出Action Manifold Hypothesis和Action Manifold Learning (AML)：假设有效动作位于低维、光滑的流形上，并使用DiT骨干网络直接预测连续动作序列，将学习从去噪转变为流形投影。
3. 模块化感知：采用双流机制，整合视觉语言模型(VLM)语义和几何先验，以及即插即用的3D模块（如VGGT, Qwen-Image-Edit）的多视图输入。

Result: ABot-M0框架在跨平台和任务的知识迁移和泛化方面表现出色。AML方法提高了动作预测的效率和稳定性。模块化感知机制增强了3D理解能力，且各组件可独立运作并带来累积效益。

Conclusion: ABot-M0框架通过系统的数据处理、创新的动作学习方法以及灵活的感知模块，有效解决了通用具身智能体在多样化硬件上的训练和泛化难题，为实现更通用的具身智能体提供了新的途径。

Abstract: Building general-purpose embodied agents across diverse hardware remains a central challenge in robotics, often framed as the ''one-brain, many-forms'' paradigm. Progress is hindered by fragmented data, inconsistent representations, and misaligned training objectives. We present ABot-M0, a framework that builds a systematic data curation pipeline while jointly optimizing model architecture and training strategies, enabling end-to-end transformation of heterogeneous raw data into unified, efficient representations. From six public datasets, we clean, standardize, and balance samples to construct UniACT-dataset, a large-scale dataset with over 6 million trajectories and 9,500 hours of data, covering diverse robot morphologies and task scenarios. Unified pre-training improves knowledge transfer and generalization across platforms and tasks, supporting general-purpose embodied intelligence. To improve action prediction efficiency and stability, we propose the Action Manifold Hypothesis: effective robot actions lie not in the full high-dimensional space but on a low-dimensional, smooth manifold governed by physical laws and task constraints. Based on this, we introduce Action Manifold Learning (AML), which uses a DiT backbone to predict clean, continuous action sequences directly. This shifts learning from denoising to projection onto feasible manifolds, improving decoding speed and policy stability. ABot-M0 supports modular perception via a dual-stream mechanism that integrates VLM semantics with geometric priors and multi-view inputs from plug-and-play 3D modules such as VGGT and Qwen-Image-Edit, enhancing spatial understanding without modifying the backbone and mitigating standard VLM limitations in 3D reasoning. Experiments show components operate independently with additive benefits. We will release all code and pipelines for reproducibility and future research.

</details>


### [81] [Toward Reliable Tea Leaf Disease Diagnosis Using Deep Learning Model: Enhancing Robustness With Explainable AI and Adversarial Training](https://arxiv.org/abs/2602.11239)
*Samanta Ghosh,Jannatul Adan Mahi,Shayan Abrar,Md Parvez Mia,Asaduzzaman Rayhan,Abdul Awal Yasir,Asaduzzaman Hridoy*

Main category: cs.CV

TL;DR: 本研究开发了一种基于深度学习的自动茶树叶病害分类模型，使用 DenseNet201 和 EfficientNetB3 在 teaLeafBD 数据集上进行了训练和评估，并利用 Grad-CAM 进行模型可解释性分析，结果显示 EfficientNetB3 准确率达到 93%，为茶树病害的早期检测和农业管理提供了有效工具。


<details>
  <summary>Details</summary>
Motivation: 人工检测茶树叶病害存在耗时和易出错的问题，阻碍了茶树生产和质量的提升，因此需要开发自动化、高效的检测方法。

Method: 研究采用深度学习方法，利用 teaLeafBD 数据集（包含 5,278 张图像，分为 7 类：6 种病害和 1 种健康叶片），应用数据预处理、数据划分、对抗性训练、数据增强、模型训练、评估和可解释 AI（Grad-CAM）等技术。实验中使用了 DenseNet201 和 EfficientNetB3 模型进行分类。

Result: 在 teaLeafBD 数据集上的实验结果表明，EfficientNetB3 模型达到了 93% 的最高分类准确率，DenseNet201 模型达到了 91% 的准确率。Grad-CAM 可视化有助于理解模型的决策过程。

Conclusion: 所提出的深度学习方法能够准确检测茶树叶病害，并且 EfficientNetB3 模型表现出优异的性能。该方法为茶树病害的自动化检测和高级农业管理提供了切实可行的解决方案。

Abstract: Tea is a valuable asset for the economy of Bangladesh. So, tea cultivation plays an important role to boost the economy. These valuable plants are vulnerable to various kinds of leaf infections which may cause less production and low quality. It is not so easy to detect these diseases manually. It may take time and there could be some errors in the detection.Therefore, the purpose of the study is to develop an automated deep learning model for tea leaf disease classification based on the teaLeafBD dataset so that anyone can detect the diseases more easily and efficiently. There are 5,278 high-resolution images in this dataset. The images are classified into seven categories. Six of them represents various diseases and the rest one represents healthy leaves. The proposed pipeline contains data preprocessing, data splitting, adversarial training, augmentation, model training, evaluation, and comprehension made possible with Explainable AI strategies. DenseNet201 and EfficientNetB3 were employed to perform the classification task. To prepare the model more robustly, we applied adversarial training so it can operate effectively even with noisy or disturbed inputs. In addition, Grad-CAM visualization was executed to analyze the model's predictions by identifying the most influential regions of each image. Our experimental outcomes revealed that EfficientNetB3 achieved the highest classification accuracy of 93%, while DenseNet201 reached 91%. The outcomes prove that the effectiveness of the proposed approach can accurately detect tea leaf diseases and provide a practical solution for advanced agricultural management.

</details>


### [82] [Active Zero: Self-Evolving Vision-Language Models through Active Environment Exploration](https://arxiv.org/abs/2602.11241)
*Jinghan He,Junfeng Fang,Feng Xiong,Zijun Yao,Fei Shen,Haiyun Guo,Jinqiao Wang,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 提出了一种名为Active-Zero的框架，通过主动探索视觉环境来改进视觉-语言模型。该框架使用三个协同进化的代理（搜索者、提问者、解决者）来生成和学习，从而实现了自适应的学习轨迹，并在多项基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型通过自我博弈进行改进的方法依赖于静态图像数据集，学习效率低下且受限于初始数据集。模型无法主动寻找与其能力相匹配的视觉数据，导致计算资源浪费在过于简单或过于困难的样本上。

Method: Active-Zero框架包含三个协同进化的代理：1. 搜索者 (Searcher)：根据模型的“能力前沿”从开放世界数据集中检索图像。2. 提问者 (Questioner)：生成经过校准的推理任务。3. 解决者 (Solver)：通过准确性奖励进行优化。这种闭环设计实现了自脚手架式的自动课程学习。

Result: 在Qwen2.5-VL-7B-Instruct模型上，Active-Zero在12个基准测试中，推理任务平均准确率达到53.97%（提升5.7%），通用理解任务平均准确率达到59.77%（提升3.9%），优于现有的自我博弈基线。

Conclusion: 主动探索是构建可扩展、自适应的自我进化视觉-语言系统的关键因素。Active-Zero框架通过主动的方式克服了现有方法的局限性，显著提升了模型的性能。

Abstract: Self-play has enabled large language models to autonomously improve through self-generated challenges. However, existing self-play methods for vision-language models rely on passive interaction with static image collections, resulting in strong dependence on initial datasets and inefficient learning. Without the ability to actively seek visual data tailored to their evolving capabilities, agents waste computational effort on samples that are either trivial or beyond their current skill level. To address these limitations, we propose Active-Zero, a framework that shifts from passive interaction to active exploration of visual environments. Active-Zero employs three co-evolving agents: a Searcher that retrieves images from open-world repositories based on the model's capability frontier, a Questioner that synthesizes calibrated reasoning tasks, and a Solver refined through accuracy rewards. This closed loop enables self-scaffolding auto-curricula where the model autonomously constructs its learning trajectory. On Qwen2.5-VL-7B-Instruct across 12 benchmarks, Active-Zero achieves 53.97 average accuracy on reasoning tasks (5.7% improvement) and 59.77 on general understanding (3.9% improvement), consistently outperforming existing self-play baselines. These results highlight active exploration as a key ingredient for scalable and adaptive self-evolving vision-language systems.

</details>


### [83] [ReTracing: An Archaeological Approach Through Body, Machine, and Generative Systems](https://arxiv.org/abs/2602.11242)
*Yitong Wang,Yue Yao*

Main category: cs.CV

TL;DR: ReTracing 是一个多主体具身艺术表演项目，利用考古学方法，通过 LLM 和文本到视频模型，将科幻小说中关于人机交互的描述转化为人类表演者和机器狗的编舞指令，记录其运动轨迹，以揭示生成式 AI 如何通过身体运动编码社会文化偏见，并探讨人与 AI 共存的意义。


<details>
  <summary>Details</summary>
Motivation: 探索人工智能（AI）如何塑造、限制和产生身体运动，以及揭示生成式系统如何通过编排的运动编码社会文化偏见，并反思在 AI 具有运动、思考和留下痕迹的能力的时代，人类的意义。

Method: 从科幻小说中提取描述人机交互的句子，利用大型语言模型（LLMs）生成“做什么”和“不做什么”的提示对，使用基于扩散的文本到视频模型将提示转化为人类表演者和四足机器人的编舞指南和运动指令，通过多摄像头运动追踪捕捉两者的动作，并重建成 3D 点云和运动轨迹，形成数字运动痕迹档案。

Result: 生成了人类表演者和机器狗的运动轨迹数字档案，并从中揭示了生成式系统如何通过编排的动作编码社会文化偏见。

Conclusion: ReTracing 提供了一种新颖的方法来揭示生成式系统如何通过编排的运动来编码社会文化偏见，并通过 AI、人类和机器人之间的沉浸式互动，引发关于人类在 AI 时代意义的深刻思考。

Abstract: We present ReTracing, a multi-agent embodied performance art that adopts an archaeological approach to examine how artificial intelligence shapes, constrains, and produces bodily movement. Drawing from science-fiction novels, the project extracts sentences that describe human-machine interaction. We use large language models (LLMs) to generate paired prompts "what to do" and "what not to do" for each excerpt. A diffusion-based text-to-video model transforms these prompts into choreographic guides for a human performer and motor commands for a quadruped robot. Both agents enact the actions on a mirrored floor, captured by multi-camera motion tracking and reconstructed into 3D point clouds and motion trails, forming a digital archive of motion traces. Through this process, ReTracing serves as a novel approach to reveal how generative systems encode socio-cultural biases through choreographed movements. Through an immersive interplay of AI, human, and robot, ReTracing confronts a critical question of our time: What does it mean to be human among AIs that also move, think, and leave traces behind?

</details>


### [84] [Stress Tests REVEAL Fragile Temporal and Visual Grounding in Video-Language Models](https://arxiv.org/abs/2602.11244)
*Sethuraman T,Savya Khosla,Aditi Tiwari,Vidya Ganesh,Rakshana Jayaprakash,Aditya Jain,Vignesh Srinivasakumar,Onkar Kishor Susladkar,Srinidhi Sunkara,Aditya Shanmugham,Rakesh Vaideeswaran,Abbaas Alif Mohamed Nishar,Simon Jenni,Derek Hoiem*

Main category: cs.CV

TL;DR: 该研究引入了一个名为REVEAL的诊断基准，用于评估视频-语言模型（VidLMs）在理解视频内容、时间顺序和运动方面的鲁棒性，发现当前主流模型存在显著弱点，不如人类表现。


<details>
  <summary>Details</summary>
Motivation: 研究的核心动机是验证视频-语言模型（VidLMs）是否真正理解视频内容、时间顺序和运动，因为已有迹象表明它们可能存在根本性缺陷。

Method: 研究者设计了一个名为REVEAL的诊断基准，包含五个受控的压力测试：时间期望偏差、依赖语言捷径、视频谄媚、相机运动敏感性以及时空遮挡鲁棒性。他们对领先的开源和闭源VidLMs进行了测试，并开发了一个数据管道来自动生成诊断示例。

Result: 测试结果表明，VidLMs存在显著问题，例如会自信地将倒放视频描述为正放、忽视视频内容回答问题、同意错误陈述、难以处理基本的相机运动，以及在时空遮挡下无法整合时间信息。相比之下，人类在这些任务上表现轻松。REVEAL基准在各种测试中揭示了模型与人类之间的巨大差距。

Conclusion: 当前的主流视频-语言模型在理解视频内容、时间顺序和运动方面存在根本性缺陷，并且不如人类鲁棒。REVEAL基准及其数据生成管道为评估和改进VidLMs提供了有力的工具，有助于推动该领域的研究进展。

Abstract: This work investigates a fundamental question: Do Video-Language Models (VidLMs) robustly account for video content, temporal sequence, and motion? Our investigation shows that, surprisingly, they often do not. We introduce REVEAL{}, a diagnostic benchmark that probes fundamental weaknesses of contemporary VidLMs through five controlled stress tests; assessing temporal expectation bias, reliance on language-only shortcuts, video sycophancy, camera motion sensitivity, and robustness to spatiotemporal occlusion. We test leading open- and closed-source VidLMs and find that these models confidently describe reversed scenes as forward, answer questions while neglecting video content, agree with false claims, struggle with basic camera motion, and fail to aggregate temporal information amidst simple spatiotemporal masking. Humans, on the other hand, succeed at these tasks with ease. Alongside our benchmark, we provide a data pipeline that automatically generates diagnostic examples for our stress tests, enabling broader and more scalable evaluation. We will release our benchmark and code to support future research.

</details>


### [85] [Efficient Segment Anything with Depth-Aware Fusion and Limited Training Data](https://arxiv.org/abs/2602.11804)
*Yiming Zhou,Xuenjie Xie,Panfeng Li,Albrecht Kunz,Ahmad Osman,Xavier Maldague*

Main category: cs.CV

TL;DR: 该研究提出了一种轻量级的RGB-D融合框架，通过引入单目深度先验来增强EfficientViT-SAM模型，仅使用少量的训练数据（11.2k样本）就在分割任务上取得了比EfficientViT-SAM更高的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的分割模型（如SAM）虽然性能强大，但需要海量数据集进行训练，且依赖于RGB输入。虽然存在一些高效变体，但仍然需要大规模训练。本研究的动机是开发一种更高效、数据需求更少的分割方法，并探索深度信息在其中扮演的角色。

Method: 该方法提出了一种RGB-D融合框架，将EfficientViT-SAM与单目深度先验相结合。首先，使用预训练的深度估计器生成深度图。然后，将深度图的特征与RGB特征在中层进行融合，并通过一个专门的深度编码器处理。该模型仅在11.2k个样本上进行训练。

Result: 与EfficientViT-SAM相比，本方法在更少的数据量下取得了更高的分割准确率。这表明深度信息可以提供强大的几何先验，有助于提升分割性能。

Conclusion: 通过引入单目深度先验并进行RGB-D特征融合，可以显著提高分割模型的效率和性能，尤其是在训练数据有限的情况下。深度信息作为一种几何先验，对分割任务至关重要。

Abstract: Segment Anything Models (SAM) achieve impressive universal segmentation performance but require massive datasets (e.g., 11M images) and rely solely on RGB inputs. Recent efficient variants reduce computation but still depend on large-scale training. We propose a lightweight RGB-D fusion framework that augments EfficientViT-SAM with monocular depth priors. Depth maps are generated with a pretrained estimator and fused mid-level with RGB features through a dedicated depth encoder. Trained on only 11.2k samples (less than 0.1\% of SA-1B), our method achieves higher accuracy than EfficientViT-SAM, showing that depth cues provide strong geometric priors for segmentation.

</details>


### [86] [Advancing Digital Twin Generation Through a Novel Simulation Framework and Quantitative Benchmarking](https://arxiv.org/abs/2602.11314)
*Jacob Rubinstein,Avi Donaty,Don Engel*

Main category: cs.CV

TL;DR: 本文提出并测试了一种新颖的流水线，用于从高质量的3D模型和程序生成的相机姿态生成合成图像，以实现可重复、可量化的3D模型重建实验。


<details>
  <summary>Details</summary>
Motivation: 现有的3D模型生成（如摄影测量法）方法在设计选择上存在不确定性，并且其效果通常仅凭定性判断。研究者希望通过一种可重复、可量化的实验方法来评估这些选择。

Method: 提出了一种新的流水线，该流水线能够从高质量的3D模型和程序生成的相机位姿中生成合成图像。通过这种方法，可以获得虚拟相机参数和虚拟对象的真实情况，并与重建估计进行比较。

Result: 该方法能够生成合成图像，并为评估3D模型重建算法提供了可重复和可量化的实验框架。研究者可以精确控制相机参数和3D对象，并与重建结果进行对比。

Conclusion: 该新流水线能够实现可重复、可量化的3D模型重建实验，有助于对现有设计选择进行更深入的评估和改进。

Abstract: The generation of 3D models from real-world objects has often been accomplished through photogrammetry, i.e., by taking 2D photos from a variety of perspectives and then triangulating matched point-based features to create a textured mesh. Many design choices exist within this framework for the generation of digital twins, and differences between such approaches are largely judged qualitatively. Here, we present and test a novel pipeline for generating synthetic images from high-quality 3D models and programmatically generated camera poses. This enables a wide variety of repeatable, quantifiable experiments which can compare ground-truth knowledge of virtual camera parameters and of virtual objects against the reconstructed estimations of those perspectives and subjects.

</details>


### [87] [Selective Prior Synchronization via SYNC Loss](https://arxiv.org/abs/2602.11316)
*Ishan Mishra,Jiajie Li,Deepak Mishra,Jinjun Xiong*

Main category: cs.CV

TL;DR: 本文提出了一种名为SYNC loss的新方法，它结合了模型结构调整（ad-hoc）和后处理分析（post-hoc）两种方法，以提高深度神经网络（DNN）在不确定性情况下的选择性预测能力。通过在训练阶段利用选择机制产生的“选择先验”（selective prior），该方法在多个数据集上取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的选择性预测方法要么依赖于修改网络结构或目标函数（ad-hoc），要么仅在推理时分析模型的输出（post-hoc）。研究者发现，post-hoc方法在推理时隐含生成了“选择先验”，并认为这个先验信息在训练阶段同样至关重要，但被忽视了。因此，需要一种方法将选择先验整合到训练过程中。

Method: 提出了一种名为SYNC loss的新方法，它通过将softmax响应（一种post-hoc方法）整合到SelectiveNet（一种ad-hoc方法）的训练过程中，从而增强其选择性预测能力。该方法在训练阶段就利用了由选择机制产生的选择先验。

Result: 在CIFAR-100、ImageNet-100和Stanford Cars等多个数据集上进行的评估显示，所提出的方法不仅提高了模型的泛化能力，而且在选择性预测性能上超越了以往的工作，并达到了新的最先进水平。

Conclusion: 将模型输出的“选择先验”信息整合到训练阶段（SYNC loss）是提高深度神经网络选择性预测能力的一种有效途径，这种结合ad-hoc和post-hoc方法的策略能够带来更好的泛化和选择性预测性能。

Abstract: Prediction under uncertainty is a critical requirement for the deep neural network to succeed responsibly. This paper focuses on selective prediction, which allows DNNs to make informed decisions about when to predict or abstain based on the uncertainty level of their predictions. Current methods are either ad-hoc such as SelectiveNet, focusing on how to modify the network architecture or objective function, or post-hoc such as softmax response, achieving selective prediction through analyzing the model's probabilistic outputs. We observe that post-hoc methods implicitly generate uncertainty information, termed the selective prior, which has traditionally been used only during inference. We argue that the selective prior provided by the selection mechanism is equally vital during the training stage. Therefore, we propose the SYNC loss which introduces a novel integration of ad-hoc and post-hoc method. Specifically, our approach incorporates the softmax response into the training process of SelectiveNet, enhancing its selective prediction capabilities by examining the selective prior. Evaluated across various datasets, including CIFAR-100, ImageNet-100, and Stanford Cars, our method not only enhances the model's generalization capabilities but also surpasses previous works in selective prediction performance, and sets new benchmarks for state-of-the-art performance.

</details>


### [88] [MDE-VIO: Enhancing Visual-Inertial Odometry Using Learned Depth Priors](https://arxiv.org/abs/2602.11323)
*Arda Alniak,Sinan Kalkan,Mustafa Mert Ankarali,Afsar Saranli,Abdullah Aydin Alatan*

Main category: cs.CV

TL;DR: 提出了一种将学习到的深度先验信息直接整合到 VINS-Mono 优化后端的方法，通过强制执行仿射不变深度一致性和成对序数约束，并利用基于方差的门控过滤不稳定伪影，从而在满足边缘设备计算限制的同时，鲁棒地恢复度量尺度，显著提高了轨迹估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的单目视觉惯性里程计 (VIO) 在低纹理环境中表现不佳，而基于 Vision Transformer (ViT) 的复杂基础模型虽然能提供密集的、几何上一致的深度，但计算量过大，无法在边缘设备上实时部署。本研究旨在弥合这一差距，将学习到的深度先验信息整合到 VIO 中，以解决低纹理环境下的精度问题并满足实时性要求。

Method: 将学习到的深度先验信息整合到 VINS-Mono 优化后端。提出了一种新的框架，强制执行仿射不变深度一致性和成对序数约束，并通过基于方差的门控过滤不稳定的伪影，以严格遵守边缘设备的计算限制。

Result: 在 TartanGround 和 M3ED 数据集上的大量实验表明，该方法可以防止在具有挑战性的场景中发生发散，并显著提高精度，绝对轨迹误差 (ATE) 降低高达 28.3%。

Conclusion: 通过将学习到的深度先验信息集成到 VIO 优化后端，并引入仿射不变深度一致性、成对序数约束和基于方差的门控，该方法能够在满足边缘设备计算限制的同时，鲁棒地恢复度量尺度，并在挑战性环境中显著提高轨迹估计的准确性。

Abstract: Traditional monocular Visual-Inertial Odometry (VIO) systems struggle in low-texture environments where sparse visual features are insufficient for accurate pose estimation. To address this, dense Monocular Depth Estimation (MDE) has been widely explored as a complementary information source. While recent Vision Transformer (ViT) based complex foundational models offer dense, geometrically consistent depth, their computational demands typically preclude them from real-time edge deployment. Our work bridges this gap by integrating learned depth priors directly into the VINS-Mono optimization backend. We propose a novel framework that enforces affine-invariant depth consistency and pairwise ordinal constraints, explicitly filtering unstable artifacts via variance-based gating. This approach strictly adheres to the computational limits of edge devices while robustly recovering metric scale. Extensive experiments on the TartanGround and M3ED datasets demonstrate that our method prevents divergence in challenging scenarios and delivers significant accuracy gains, reducing Absolute Trajectory Error (ATE) by up to 28.3%. Code will be made available.

</details>


### [89] [Exploring Real-Time Super-Resolution: Benchmarking and Fine-Tuning for Streaming Content](https://arxiv.org/abs/2602.11339)
*Evgeney Bogatyrev,Khaled Abud,Ivan Molodetskikh,Nikita Alutis,Dmitry Vatolin*

Main category: cs.CV

TL;DR: 该研究提出了一个针对流媒体视频的新型超分辨率数据集StreamSR，并在此基础上提出了一个高效的实时超分辨率模型EfRLFN，该模型结合了通道注意力机制和超双曲正切激活函数，并采用了改进的损失函数。实验证明，在StreamSR数据集上微调模型可以显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有实时超分辨率方法在处理压缩流媒体视频时表现不佳，且现有数据集无法真实反映流媒体的特性，限制了研究的有效性。

Method: 构建了一个名为StreamSR的新数据集，该数据集来源于YouTube，覆盖了多种视频类型和分辨率。对11个现有的实时超分辨率模型进行了基准测试。提出了一个名为EfRLFN的新型高效实时超分辨率模型，该模型集成了高效通道注意力机制和超双曲正切激活函数，并设计了复合损失函数。

Result: 在StreamSR数据集上的基准测试揭示了现有模型在流媒体场景下的不足。EfRLFN模型在视觉质量和运行时性能上都表现优于现有方法。在StreamSR数据集上进行微调可以显著提升其他模型的性能，并且泛化能力良好。

Conclusion: StreamSR数据集为流媒体视频超分辨率研究提供了更贴近实际的评估环境。提出的EfRLFN模型是一种高效且性能优越的实时超分辨率解决方案。在StreamSR上进行微调是提升实时超分辨率模型性能的有效策略。

Abstract: Recent advancements in real-time super-resolution have enabled higher-quality video streaming, yet existing methods struggle with the unique challenges of compressed video content. Commonly used datasets do not accurately reflect the characteristics of streaming media, limiting the relevance of current benchmarks. To address this gap, we introduce a comprehensive dataset - StreamSR - sourced from YouTube, covering a wide range of video genres and resolutions representative of real-world streaming scenarios. We benchmark 11 state-of-the-art real-time super-resolution models to evaluate their performance for the streaming use-case.
  Furthermore, we propose EfRLFN, an efficient real-time model that integrates Efficient Channel Attention and a hyperbolic tangent activation function - a novel design choice in the context of real-time super-resolution. We extensively optimized the architecture to maximize efficiency and designed a composite loss function that improves training convergence. EfRLFN combines the strengths of existing architectures while improving both visual quality and runtime performance.
  Finally, we show that fine-tuning other models on our dataset results in significant performance gains that generalize well across various standard benchmarks. We made the dataset, the code, and the benchmark available at https://github.com/EvgeneyBogatyrev/EfRLFN.

</details>


### [90] [ArtContext: Contextualizing Artworks with Open-Access Art History Articles and Wikidata Knowledge through a LoRA-Tuned CLIP Model](https://arxiv.org/abs/2602.11349)
*Samuel Waugh,Stuart James*

Main category: cs.CV

TL;DR: 提出ArtContext系统，利用开放获取的艺术史文章和Wikidata知识，为艺术品添加相关信息，并通过领域定制的CLIP模型PaintingCLIP实现。


<details>
  <summary>Details</summary>
Motivation: 现有艺术史研究分散在不同文章中，难以将特定文章的研究内容与具体艺术品关联起来。需要一个系统来自动整合这些信息。

Method: 构建了一个新的语料库收集流程，并训练了一个基于低秩适应（LoRA）的定制CLIP模型（PaintingCLIP），使其适用于艺术史领域。该模型通过弱监督方式进行训练。

Result: PaintingCLIP模型在艺术品语境化方面优于标准的CLIP模型，能够为给定的艺术品提供相关的上下文信息。

Conclusion: ArtContext系统提供了一种有效的方法，可以整合艺术史文献和知识图谱信息，为艺术品提供丰富的上下文。该方法具有普适性，可应用于其他人文领域。

Abstract: Many Art History articles discuss artworks in general as well as specific parts of works, such as layout, iconography, or material culture. However, when viewing an artwork, it is not trivial to identify what different articles have said about the piece. Therefore, we propose ArtContext, a pipeline for taking a corpus of Open-Access Art History articles and Wikidata Knowledge and annotating Artworks with this information. We do this using a novel corpus collection pipeline, then learn a bespoke CLIP model adapted using Low-Rank Adaptation (LoRA) to make it domain-specific. We show that the new model, PaintingCLIP, which is weakly supervised by the collected corpus, outperforms CLIP and provides context for a given artwork. The proposed pipeline is generalisable and can be readily applied to numerous humanities areas.

</details>


### [91] [Latent Forcing: Reordering the Diffusion Trajectory for Pixel-Space Image Generation](https://arxiv.org/abs/2602.11401)
*Alan Baade,Eric Ryan Chan,Kyle Sargent,Changan Chen,Justin Johnson,Ehsan Adeli,Li Fei-Fei*

Main category: cs.CV

TL;DR: 提出了一种名为 Latent Forcing 的新方法，可以使潜在扩散模型在原始图像上进行端到端建模，同时保留其效率，并在 ImageNet 数据集上实现了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在扩散模型虽然生成图像质量高，但由于信息丢失、需要单独训练的解码器以及建模辅助分布，未能实现端到端建模的优势。作者希望在保持潜在扩散模型效率的同时，使其能够直接处理原始图像。

Method: Latent Forcing 通过联合处理潜在表示和像素，并采用分开调整的噪声调度，来组织去噪过程。这使得潜在表示可以作为中间计算的“草稿本”，在生成高频像素特征之前进行处理。文章还分析了条件信号的顺序对模型性能的影响。

Result: Latent Forcing 在 ImageNet 数据集上，对于基于 Transformer 的像素生成，达到了新的最先进水平（在所用计算规模下）。作者还分析了 REPA 蒸馏、条件与无条件生成以及 tokenizer 重建质量与可扩散性之间的关系。

Conclusion: Latent Forcing 是一种简单而有效的方法，可以克服现有潜在扩散模型的局限性，使其在原始图像上实现端到端建模，并在生成任务上取得优异表现。

Abstract: Latent diffusion models excel at generating high-quality images but lose the benefits of end-to-end modeling. They discard information during image encoding, require a separately trained decoder, and model an auxiliary distribution to the raw data. In this paper, we propose Latent Forcing, a simple modification to existing architectures that achieves the efficiency of latent diffusion while operating on raw natural images. Our approach orders the denoising trajectory by jointly processing latents and pixels with separately tuned noise schedules. This allows the latents to act as a scratchpad for intermediate computation before high-frequency pixel features are generated. We find that the order of conditioning signals is critical, and we analyze this to explain differences between REPA distillation in the tokenizer and the diffusion model, conditional versus unconditional generation, and how tokenizer reconstruction quality relates to diffusability. Applied to ImageNet, Latent Forcing achieves a new state-of-the-art for diffusion transformer-based pixel generation at our compute scale.

</details>


### [92] [Fighting MRI Anisotropy: Learning Multiple Cardiac Shapes From a Single Implicit Neural Representation](https://arxiv.org/abs/2602.11436)
*Carolina Brás,Soufiane Ben Haddou,Thijs P. Kuipers,Laura Alvarez-Florez,R. Nils Planken,Fleur V. Y. Tjong,Connie Bezzina,Ivana Išgum*

Main category: cs.CV

TL;DR: 利用计算断层扫描血管造影 (CTA) 数据训练神经网络，以从任何分辨率的心脏磁共振成像 (CMRI) 中重建心脏形状，从而克服 CMRI 的各向异性限制，并用于心脏形状分析。


<details>
  <summary>Details</summary>
Motivation: 心脏磁共振成像 (CMRI) 的短轴 (SAX) 成像具有各向异性，这限制了心脏形状的分析。为了解决这个问题，研究人员提出利用近乎各向同性、更高分辨率的 CTA 数据。

Method: 使用 CTA 数据训练一个单一的神经隐式函数，该函数可以同时表示任何分辨率 CMRI 的心脏形状。该方法用于重建右心室 (RV) 和心肌 (MYO)。

Result: 在缺乏高分辨率 SAX 参考分割的情况下，通过从重建的形状中提取 RV 和 MYO 的四腔 (4CH) 切片进行评估。与 CMRI 的参考 4CH 分割掩码相比，RV 的 Dice 相似系数为 0.91 ± 0.07，Hausdorff 距离为 6.21 ± 3.97 mm；MYO 的 Dice 相似系数为 0.75 ± 0.13，Hausdorff 距离为 7.53 ± 5.13 mm。

Conclusion: 所提出的模型能够重建准确、平滑且在解剖学上合理的心脏形状，有望改进心脏形状分析。

Abstract: The anisotropic nature of short-axis (SAX) cardiovascular magnetic resonance imaging (CMRI) limits cardiac shape analysis. To address this, we propose to leverage near-isotropic, higher resolution computed tomography angiography (CTA) data of the heart. We use this data to train a single neural implicit function to jointly represent cardiac shapes from CMRI at any resolution. We evaluate the method for the reconstruction of right ventricle (RV) and myocardium (MYO), where MYO simultaneously models endocardial and epicardial left-ventricle surfaces. Since high-resolution SAX reference segmentations are unavailable, we evaluate performance by extracting a 4-chamber (4CH) slice of RV and MYO from their reconstructed shapes. When compared with the reference 4CH segmentation masks from CMRI, our method achieved a Dice similarity coefficient of 0.91 $\pm$ 0.07 and 0.75 $\pm$ 0.13, and a Hausdorff distance of 6.21 $\pm$ 3.97 mm and 7.53 $\pm$ 5.13 mm for RV and MYO, respectively. Quantitative and qualitative assessment demonstrate the model's ability to reconstruct accurate, smooth and anatomically plausible shapes, supporting improvements in cardiac shape analysis.

</details>


### [93] [Ctrl&Shift: High-Quality Geometry-Aware Object Manipulation in Visual Generation](https://arxiv.org/abs/2602.11440)
*Penghui Ruan,Bojia Zi,Xianbiao Qi,Youze Huang,Rong Xiao,Pichao Wang,Jiannong Cao,Yuhui Shi*

Main category: cs.CV

TL;DR: 提出了一种名为Ctrl&Shift的端到端扩散框架，用于在不依赖显式3D模型的情况下，实现几何一致的对象操作，解决了背景保持、几何一致性和用户可控性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的对象操作方法难以同时满足背景保持、视角变换下的几何一致性以及用户可控的变换这三个核心需求。几何方法控制精确但泛化性差，扩散方法泛化性好但缺乏精细的几何控制。

Method: 将对象操作分解为两个阶段：对象移除和参考引导的修复，并通过显式的相机姿态控制将其编码到统一的扩散过程中。采用多任务、多阶段的训练策略，分离背景、身份和姿态信号。设计了一个可扩展的真实世界数据集构建流程，生成带有估计相对相机姿态的图像和视频样本。

Result: Ctrl&Shift在保真度、视角一致性和可控性方面均达到了最先进的水平。

Conclusion: Ctrl&Shift是第一个能够实现精细几何控制和真实世界泛化的对象操作框架，无需显式的3D建模，有效解决了现有方法的局限性。

Abstract: Object-level manipulation, relocating or reorienting objects in images or videos while preserving scene realism, is central to film post-production, AR, and creative editing. Yet existing methods struggle to jointly achieve three core goals: background preservation, geometric consistency under viewpoint shifts, and user-controllable transformations. Geometry-based approaches offer precise control but require explicit 3D reconstruction and generalize poorly; diffusion-based methods generalize better but lack fine-grained geometric control. We present Ctrl&Shift, an end-to-end diffusion framework to achieve geometry-consistent object manipulation without explicit 3D representations. Our key insight is to decompose manipulation into two stages, object removal and reference-guided inpainting under explicit camera pose control, and encode both within a unified diffusion process. To enable precise, disentangled control, we design a multi-task, multi-stage training strategy that separates background, identity, and pose signals across tasks. To improve generalization, we introduce a scalable real-world dataset construction pipeline that generates paired image and video samples with estimated relative camera poses. Extensive experiments demonstrate that Ctrl&Shift achieves state-of-the-art results in fidelity, viewpoint consistency, and controllability. To our knowledge, this is the first framework to unify fine-grained geometric control and real-world generalization for object manipulation, without relying on any explicit 3D modeling.

</details>


### [94] [Enhanced Portable Ultra Low-Field Diffusion Tensor Imaging with Bayesian Artifact Correction and Deep Learning-Based Super-Resolution](https://arxiv.org/abs/2602.11446)
*Mark D. Olchanyi,Annabel Sorby-Adams,John Kirsch,Brian L. Edlow,Ava Farnan,Renfei Liu,Matthew S. Rosen,Emery N. Brown,W. Taylor Kimberly,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 本研究提出了一种用于便携式超低场 (ULF) 磁共振成像 (MRI) 的九方向、单层扩散张量成像 (DTI) 序列，并结合了具有角度依赖性的贝叶斯偏置场校正算法和基于卷积神经网络的超分辨率算法（DiffSR）。该方法能够在 ULF 条件下恢复微观结构和体积性白质信息，并可用于阿尔茨海默病分类。研究人员已公开了相关算法和代码。


<details>
  <summary>Details</summary>
Motivation: 目前的便携式超低场 (ULF) 磁共振成像 (MRI) 在空间和角度分辨率以及信噪比方面存在不足，尤其是在扩散张量成像 (DTI) 领域，这限制了其在神经影像学中的应用。本研究旨在克服这些限制，提高 ULF DTI 的成像质量和准确性。

Method: 研究人员开发了一种九方向、单层 ULF DTI 序列。在此基础上，他们提出了一个具有角度依赖性的贝叶斯偏置场校正算法和一个名为 DiffSR 的卷积神经网络（CNN）超分辨率算法。DiffSR 具有通用性，无需重新训练即可应用于不同的 DTI 数据集。通过合成降采样实验和真实 ULF/高场 DTI 扫描数据的白质评估来验证算法的有效性。

Result: 研究表明，所提出的算法能够从合成降采样实验和真实的 ULF/高场 DTI 扫描数据中恢复微观结构和体积性白质信息。DiffSR 还能直接应用于阿尔茨海默病分类的合成退化扫描，并显著提高了 DTI 指标与未退化扫描之间的一致性。

Conclusion: 本研究提出的 ULF DTI 序列、贝叶斯偏置场校正算法和 DiffSR 超分辨率算法，能够有效地提高 ULF DTI 的成像质量，恢复白质的微观结构和体积信息，并有望应用于神经退行性疾病的诊断。研究人员公开了算法和代码，以促进 ULF 重建方法和 DTI 序列协调性的进步。

Abstract: Portable, ultra-low-field (ULF) magnetic resonance imaging has the potential to expand access to neuroimaging but currently suffers from coarse spatial and angular resolutions and low signal-to-noise ratios. Diffusion tensor imaging (DTI), a sequence tailored to detect and reconstruct white matter tracts within the brain, is particularly prone to such imaging degradation due to inherent sequence design coupled with prolonged scan times. In addition, ULF DTI scans exhibit artifacting that spans both the space and angular domains, requiring a custom modelling algorithm for subsequent correction. We introduce a nine-direction, single-shell ULF DTI sequence, as well as a companion Bayesian bias field correction algorithm that possesses angular dependence and convolutional neural network-based superresolution algorithm that is generalizable across DTI datasets and does not require re-training (''DiffSR''). We show through a synthetic downsampling experiment and white matter assessment in real, matched ULF and high-field DTI scans that these algorithms can recover microstructural and volumetric white matter information at ULF. We also show that DiffSR can be directly applied to white matter-based Alzheimers disease classification in synthetically degraded scans, with notable improvements in agreement between DTI metrics, as compared to un-degraded scans. We freely disseminate the Bayesian bias correction algorithm and DiffSR with the goal of furthering progress on both ULF reconstruction methods and general DTI sequence harmonization. We release all code related to DiffSR for $\href{https://github.com/markolchanyi/DiffSR}{public \space use}$.

</details>


### [95] [A Dual-Branch Framework for Semantic Change Detection with Boundary and Temporal Awareness](https://arxiv.org/abs/2602.11466)
*Yun-Cheng Li,Sen Lei,Heng-Chao Li,Ke Li*

Main category: cs.CV

TL;DR: 提出了一种名为DBTANet的双分支框架，用于解决遥感图像语义变化检测中的边界模糊和时间建模不足问题。该框架结合了全局语义、局部细节、时间依赖和边界信息，在公开数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有语义变化检测方法在处理边界模糊和时间建模方面存在不足，限制了分割精度。

Method: 提出DBTANet框架，包含一个双分支Siamese编码器（冻结的SAM分支用于全局语义和边界先验，ResNet34分支用于局部细节），一个双向时间感知模块（BTAM）用于多尺度特征聚合和对称的时间依赖捕获，以及一个高斯平滑投影模块（GSPM）用于细化SAM特征，增强边缘信息。

Result: DBTANet有效整合了全局语义、局部细节、时间推理和边界感知能力，在两个公开基准数据集上实现了最先进的性能。

Conclusion: DBTANet是一种有效的语义变化检测框架，通过结合多源信息和专门设计的模块，克服了现有方法的局限性，显著提高了变化检测精度。

Abstract: Semantic Change Detection (SCD) aims to detect and categorize land-cover changes from bi-temporal remote sensing images. Existing methods often suffer from blurred boundaries and inadequate temporal modeling, limiting segmentation accuracy. To address these issues, we propose a Dual-Branch Framework for Semantic Change Detection with Boundary and Temporal Awareness, termed DBTANet. Specifically, we utilize a dual-branch Siamese encoder where a frozen SAM branch captures global semantic context and boundary priors, while a ResNet34 branch provides local spatial details, ensuring complementary feature representations. On this basis, we design a Bidirectional Temporal Awareness Module (BTAM) to aggregate multi-scale features and capture temporal dependencies in a symmetric manner. Furthermore, a Gaussian-smoothed Projection Module (GSPM) refines shallow SAM features, suppressing noise while enhancing edge information for boundary-aware constraints. Extensive experiments on two public benchmarks demonstrate that DBTANet effectively integrates global semantics, local details, temporal reasoning, and boundary awareness, achieving state-of-the-art performance.

</details>


### [96] [Arbitrary Ratio Feature Compression via Next Token Prediction](https://arxiv.org/abs/2602.11494)
*Yufan Liu,Daoyuan Ren,Zhipeng Zhang,Wenyang Luo,Bing Li,Weiming Hu,Stephen Maybank*

Main category: cs.CV

TL;DR: 本文提出了一种名为ARFC（Arbitrary Ratio Feature Compression）的新型特征压缩框架，能够通过单一模型实现任意压缩率，无需为不同压缩率重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有特征压缩方法通常需要为特定压缩率训练专门的模型，缺乏灵活性和泛化能力，难以适应实际应用中对不同压缩率的需求。重新训练以适应新压缩率的成本很高。

Method: ARFC框架的核心是Arbitrary Ratio Compressor (ARC)，一个自回归模型，通过预测下一个token来实现压缩。压缩率可以通过调整生成token的数量来控制。为了提高压缩特征的质量，引入了两个模块：Mixture of Solutions (MoS)模块用于融合多个压缩结果以减少不确定性，Entity Relation Graph Constraint (ERGC)模块在训练时用于保持语义和结构关系。

Result: 在跨模态检索、图像分类和图像检索等任务的多个数据集上的实验表明，ARFC在各种压缩率下均优于现有方法。在某些情况下，其性能甚至超过了原始未压缩的特征。

Conclusion: ARFC框架实现了灵活的任意比例特征压缩，通过单一模型解决了现有方法的局限性，在不同压缩率下均能取得优异性能，并且在实际资源受限场景下具有很强的实用性。

Abstract: Feature compression is increasingly important for improving the efficiency of downstream tasks, especially in applications involving large-scale or multi-modal data. While existing methods typically rely on dedicated models for achieving specific compression ratios, they are often limited in flexibility and generalization. In particular, retraining is necessary when adapting to a new compression ratio. To address this limitation, we propose a novel and flexible Arbitrary Ratio Feature Compression (ARFC) framework, which supports any compression ratio with a single model, eliminating the need for multiple specialized models. At its core, the Arbitrary Ratio Compressor (ARC) is an auto-regressive model that performs compression via next-token prediction. This allows the compression ratio to be controlled at inference simply by adjusting the number of generated tokens. To enhance the quality of the compressed features, two key modules are introduced. The Mixture of Solutions (MoS) module refines the compressed tokens by utilizing multiple compression results (solutions), reducing uncertainty and improving robustness. The Entity Relation Graph Constraint (ERGC) is integrated into the training process to preserve semantic and structural relationships during compression. Extensive experiments on cross-modal retrieval, image classification, and image retrieval tasks across multiple datasets demonstrate that our method consistently outperforms existing approaches at various compression ratios. Notably, in some cases, it even surpasses the performance of the original, uncompressed features. These results validate the effectiveness and versatility of ARFC for practical, resource-constrained scenarios.

</details>


### [97] [What if Agents Could Imagine? Reinforcing Open-Vocabulary HOI Comprehension through Generation](https://arxiv.org/abs/2602.11499)
*Zhenlong Yuan,Xiangyan Qu,Jing Tang,Rui Chen,Lei Sun,Ruidong Chen,Hongwei Yu,Chengxuan Qian,Xiangxiang Chu,Shuo Li,Yuyin Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为ImagineAgent的框架，通过结合认知推理和生成式想象来解决多模态大语言模型在开放词汇人体-物体交互（OV-HOI）任务中的局限性，并在SWIG-HOI和HICO-DET数据集上取得了SOTA性能，同时显著减少了训练数据需求。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在跨模态幻觉和遮挡歧义方面存在限制，影响了它们在开放词汇人体-物体交互（OV-HOI）任务中的推理能力。

Method: 构建认知图谱，显式建模实体与动作之间的关系；动态调用检索增强、图像裁剪和扩散模型等工具以获取领域知识和增强视觉证据；提出一个结合预测准确性和工具效率的复合奖励。

Result: 在SWIG-HOI和HICO-DET数据集上实现了SOTA性能，所需训练数据约为现有方法的20%。

Conclusion: ImagineAgent框架通过认知推理和生成式想象的结合，有效地解决了OV-HOI任务中的挑战，并在性能和效率上均优于现有方法。

Abstract: Multimodal Large Language Models have shown promising capabilities in bridging visual and textual reasoning, yet their reasoning capabilities in Open-Vocabulary Human-Object Interaction (OV-HOI) are limited by cross-modal hallucinations and occlusion-induced ambiguity. To address this, we propose \textbf{ImagineAgent}, an agentic framework that harmonizes cognitive reasoning with generative imagination for robust visual understanding. Specifically, our method innovatively constructs cognitive maps that explicitly model plausible relationships between detected entities and candidate actions. Subsequently, it dynamically invokes tools including retrieval augmentation, image cropping, and diffusion models to gather domain-specific knowledge and enriched visual evidence, thereby achieving cross-modal alignment in ambiguous scenarios. Moreover, we propose a composite reward that balances prediction accuracy and tool efficiency. Evaluations on SWIG-HOI and HICO-DET datasets demonstrate our SOTA performance, requiring approximately 20\% of training data compared to existing methods, validating our robustness and efficiency.

</details>


### [98] [Vascular anatomy-aware self-supervised pre-training for X-ray angiogram analysis](https://arxiv.org/abs/2602.11536)
*De-Xing Huang,Chaohui Yu,Xiao-Hu Zhou,Tian-Yu Xiang,Qin-Yi Zhang,Mei-Jiang Gui,Rui-Ze Ma,Chen-Yu Wang,Nu-Fang Xiao,Fan Wang,Zeng-Guang Hou*

Main category: cs.CV

TL;DR: 该研究提出了VasoMIM框架和XA-170K数据集，用于解决X射线血管造影图像分析中数据稀缺的问题，并取得了优于现有方法的性能。 VasoMIM通过结合解剖学知识的掩码策略和一致性损失来学习表示。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在X射线血管造影分析中受限于标注数据的稀缺性，而自监督学习（SSL）的潜力在该领域尚未被充分探索，主要原因在于缺乏有效的SSL框架和大规模数据集。

Method: 研究者提出了VasoMIM（血管解剖学感知掩码图像建模）框架，包含两个关键设计：1. 解剖学引导的掩码策略，策略性地掩盖含血管的图像块，迫使模型学习鲁棒的血管语义；2. 解剖学一致性损失，保持原始图像和重建图像之间血管结构的相似性，增强学习到的表示的可区分性。同时，他们构建了迄今为止最大的X射线血管造影预训练数据集XA-170K。

Result: VasoMIM在四个下游任务的六个数据集上进行了验证，证明了其优越的迁移能力，并取得了比现有方法更先进的性能。

Conclusion: VasoMIM框架及其相关的XA-170K数据集具有巨大的潜力，可以作为基础模型，推动X射线血管造影分析任务的进步。

Abstract: X-ray angiography is the gold standard imaging modality for cardiovascular diseases. However, current deep learning approaches for X-ray angiogram analysis are severely constrained by the scarcity of annotated data. While large-scale self-supervised learning (SSL) has emerged as a promising solution, its potential in this domain remains largely unexplored, primarily due to the lack of effective SSL frameworks and large-scale datasets. To bridge this gap, we introduce a vascular anatomy-aware masked image modeling (VasoMIM) framework that explicitly integrates domain-specific anatomical knowledge. Specifically, VasoMIM comprises two key designs: an anatomy-guided masking strategy and an anatomical consistency loss. The former strategically masks vessel-containing patches to compel the model to learn robust vascular semantics, while the latter preserves structural consistency of vessels between original and reconstructed images, enhancing the discriminability of the learned representations. In conjunction with VasoMIM, we curate XA-170K, the largest X-ray angiogram pre-training dataset to date. We validate VasoMIM on four downstream tasks across six datasets, where it demonstrates superior transferability and achieves state-of-the-art performance compared to existing methods. These findings highlight the significant potential of VasoMIM as a foundation model for advancing a wide range of X-ray angiogram analysis tasks. VasoMIM and XA-170K will be available at https://github.com/Dxhuang-CASIA/XA-SSL.

</details>


### [99] [Supervise-assisted Multi-modality Fusion Diffusion Model for PET Restoration](https://arxiv.org/abs/2602.11545)
*Yingkai Zhang,Shuang Chen,Ye Tian,Yunyi Gao,Jianyong Jiang,Ying Fu*

Main category: cs.CV

TL;DR: 提出了一种名为MFdiff的监督辅助多模态融合扩散模型，利用MR图像来恢复低剂量PET图像，以减少辐射暴露同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 降低PET的辐射暴露（通过降低示踪剂剂量或缩短扫描时间）会导致图像质量下降。利用MR图像的解剖信息来恢复低剂量PET图像是一种有前景的方法，但面临多模态融合的不一致性以及分布外（OOD）数据的失配问题。

Method: 设计了一个多模态特征融合模块来学习最优融合特征。将融合特征作为条件，并结合扩散模型迭代生成高质量的SPET图像。采用两阶段监督辅助学习策略，利用模拟数据（in-distribution）的通用先验和体内OOD数据的特定先验。

Result: MFdiff模型能够有效地从多模态输入中恢复高质量的SPET图像，并在质量和定量评估上优于现有最先进的方法。

Conclusion: 提出的MFdiff模型是一种有效的解决低剂量PET图像恢复问题的多模态融合扩散模型，能够克服多模态不一致性和OOD数据挑战，并提升图像质量。

Abstract: Positron emission tomography (PET) offers powerful functional imaging but involves radiation exposure. Efforts to reduce this exposure by lowering the radiotracer dose or scan time can degrade image quality. While using magnetic resonance (MR) images with clearer anatomical information to restore standard-dose PET (SPET) from low-dose PET (LPET) is a promising approach, it faces challenges with the inconsistencies in the structure and texture of multi-modality fusion, as well as the mismatch in out-of-distribution (OOD) data. In this paper, we propose a supervise-assisted multi-modality fusion diffusion model (MFdiff) for addressing these challenges for high-quality PET restoration. Firstly, to fully utilize auxiliary MR images without introducing extraneous details in the restored image, a multi-modality feature fusion module is designed to learn an optimized fusion feature. Secondly, using the fusion feature as an additional condition, high-quality SPET images are iteratively generated based on the diffusion model. Furthermore, we introduce a two-stage supervise-assisted learning strategy that harnesses both generalized priors from simulated in-distribution datasets and specific priors tailored to in-vivo OOD data. Experiments demonstrate that the proposed MFdiff effectively restores high-quality SPET images from multi-modality inputs and outperforms state-of-the-art methods both qualitatively and quantitatively.

</details>


### [100] [Perception-based Image Denoising via Generative Compression](https://arxiv.org/abs/2602.11553)
*Nam Nguyen,Thinh Nguyen,Bella Bose*

Main category: cs.CV

TL;DR: 本文提出了一种基于生成式压缩的感知去噪框架，通过从低复杂度潜空间表示进行重构，并结合感知损失（如LPIPS和Wasserstein距离）来恢复真实纹理，从而克服了传统方法在强噪声和分布偏移下的过度平滑问题。


<details>
  <summary>Details</summary>
Motivation: 传统的基于失真的图像去噪方法在强噪声和分布偏移下容易产生过度平滑的重建，无法保留结构细节和感知真实性。因此，需要一种新的去噪方法来同时保留细节和感知质量。

Method: 提出了一个生成式压缩框架，通过将图像压缩到低复杂度潜空间，然后从潜空间表示进行重构。具体实现了两种模型：1) 基于条件Wasserstein GAN（WGAN）的压缩去噪器，用于控制率-失真-感知（RDP）权衡；2) 基于条件扩散模型的迭代去噪策略，通过压缩潜码引导重构。此外，还为基于压缩的最大似然去噪器建立了非渐近保证。

Result: 在合成噪声和真实噪声数据集上的实验表明，该方法在保持可比的失真性能的同时，显著提高了感知质量，实现了更优的去噪效果。

Conclusion: 该生成式压缩去噪框架能够有效地移除噪声，同时保留图像的结构细节和感知真实性，解决了传统方法的局限性，并在各种噪声条件下均表现出优越的性能。

Abstract: Image denoising aims to remove noise while preserving structural details and perceptual realism, yet distortion-driven methods often produce over-smoothed reconstructions, especially under strong noise and distribution shift. This paper proposes a generative compression framework for perception-based denoising, where restoration is achieved by reconstructing from entropy-coded latent representations that enforce low-complexity structure, while generative decoders recover realistic textures via perceptual measures such as learned perceptual image patch similarity (LPIPS) loss and Wasserstein distance. Two complementary instantiations are introduced: (i) a conditional Wasserstein GAN (WGAN)-based compression denoiser that explicitly controls the rate-distortion-perception (RDP) trade-off, and (ii) a conditional diffusion-based reconstruction strategy that performs iterative denoising guided by compressed latents. We further establish non-asymptotic guarantees for the compression-based maximum-likelihood denoiser under additive Gaussian noise, including bounds on reconstruction error and decoding error probability. Experiments on synthetic and real-noise benchmarks demonstrate consistent perceptual improvements while maintaining competitive distortion performance.

</details>


### [101] [LUVE : Latent-Cascaded Ultra-High-Resolution Video Generation with Dual Frequency Experts](https://arxiv.org/abs/2602.11564)
*Chen Zhao,Jiawei Chen,Hongyu Li,Zhuoliang Kang,Shilin Lu,Xiaoming Wei,Kai Zhang,Jian Yang,Ying Tai*

Main category: cs.CV

TL;DR: 提出了一种名为 LUVE 的新框架，用于生成超高分辨率（UHR）视频，通过三阶段架构和双频专家来解决运动建模、语义规划和细节合成的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的视频扩散模型在生成超高分辨率（UHR）视频方面存在困难，主要体现在运动建模、语义规划和细节合成方面。

Method: LUVE 框架采用三阶段架构：1. 低分辨率运动生成以合成运动一致的潜在表示；2. 视频潜在上采样，直接在潜在空间进行分辨率提升以降低计算和内存开销；3. 高分辨率内容精炼，结合低频和高频专家来增强语义连贯性和细节生成。

Result: LUVE 在 UHR 视频生成方面取得了优于现有方法的真实感和内容保真度。消融实验也验证了各组件的有效性。

Conclusion: LUVE 框架能够有效生成超高分辨率视频，通过其创新的三阶段设计和双频专家机制，解决了现有方法的局限性，并在视觉质量和内容准确性上取得了显著提升。

Abstract: Recent advances in video diffusion models have significantly improved visual quality, yet ultra-high-resolution (UHR) video generation remains a formidable challenge due to the compounded difficulties of motion modeling, semantic planning, and detail synthesis. To address these limitations, we propose \textbf{LUVE}, a \textbf{L}atent-cascaded \textbf{U}HR \textbf{V}ideo generation framework built upon dual frequency \textbf{E}xperts. LUVE employs a three-stage architecture comprising low-resolution motion generation for motion-consistent latent synthesis, video latent upsampling that performs resolution upsampling directly in the latent space to mitigate memory and computational overhead, and high-resolution content refinement that integrates low-frequency and high-frequency experts to jointly enhance semantic coherence and fine-grained detail generation. Extensive experiments demonstrate that our LUVE achieves superior photorealism and content fidelity in UHR video generation, and comprehensive ablation studies further validate the effectiveness of each component. The project is available at \href{https://unicornanrocinu.github.io/LUVE_web/}{https://github.io/LUVE/}.

</details>


### [102] [A Large Language Model for Disaster Structural Reconnaissance Summarization](https://arxiv.org/abs/2602.11588)
*Yuqing Gao,Guanren Zhou,Khalid M. Mosalam*

Main category: cs.CV

TL;DR: 提出了一种基于大型语言模型（LLM）的灾害侦察总结（LLM-DRS）框架，用于改进基于视觉的结构健康监测（SHM），特别是在灾后快速侦察方面，通过整合图像和文本数据生成结构状态的总结报告。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的SHM方法生成的离散输出（如损伤类别和坐标）需要工程师进一步分析，效率不高。大型语言模型（LLM）的出现为改进SHM提供了新的可能性。

Method: 设计了一个标准的侦察计划，收集图像数据和元数据。将文本元数据和图像数据整合，使用深度卷积神经网络提取损伤状态、材料类型和损伤级别等关键属性。最后，将这些数据和元数据输入LLM，通过精心设计的提示生成总结报告。

Result: LLM-DRS框架能够基于聚合的属性和元数据，为单个结构或受影响区域生成总结报告，显示出其在改进快速灾后侦察方面的潜力。

Conclusion: 将LLM集成到基于视觉的SHM中，尤其是在灾后快速侦察方面，对于通过有效侦察提高建筑环境的韧性具有广阔的应用前景。

Abstract: Artificial Intelligence (AI)-aided vision-based Structural Health Monitoring (SHM) has emerged as an effective approach for monitoring and assessing structural condition by analyzing image and video data. By integrating Computer Vision (CV) and Deep Learning (DL), vision-based SHM can automatically identify and localize visual patterns associated with structural damage. However, previous works typically generate only discrete outputs, such as damage class labels and damage region coordinates, requiring engineers to further reorganize and analyze these results for evaluation and decision-making. In late 2022, Large Language Models (LLMs) became popular across multiple fields, providing new insights into AI-aided vision-based SHM. In this study, a novel LLM-based Disaster Reconnaissance Summarization (LLM-DRS) framework is proposed. It introduces a standard reconnaissance plan in which the collection of vision data and corresponding metadata follows a well-designed on-site investigation process. Text-based metadata and image-based vision data are then processed and integrated into a unified format, where well-trained Deep Convolutional Neural Networks extract key attributes, including damage state, material type, and damage level. Finally, all data are fed into an LLM with carefully designed prompts, enabling the LLM-DRS to generate summary reports for individual structures or affected regions based on aggregated attributes and metadata. Results show that integrating LLMs into vision-based SHM, particularly for rapid post-disaster reconnaissance, demonstrates promising potential for improving resilience of the built environment through effective reconnaissance.

</details>


### [103] [Move What Matters: Parameter-Efficient Domain Adaptation via Optimal Transport Flow for Collaborative Perception](https://arxiv.org/abs/2602.11565)
*Zesheng Jia,Jin Wang,Siao Liu,Lingzhi Li,Ziyao Huang,Yunjiang Xu,Jianping Wang*

Main category: cs.CV

TL;DR: 提出了一种名为FlowAdapt的参数高效域适应框架，通过最优传输理论解决多智能体V2X协同感知中的域偏移问题，有效降低了训练参数，提高了样本效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在V2X协同感知任务中，将多智能体系统部署到不同环境中时，快速域适应是一个基本挑战。现有参数高效微调（PEFT）方法直接应用于多智能体设置会导致性能下降和训练不稳定。

Method: FlowAdapt框架基于最优传输理论，最小化数据分布和网络层次结构的信息传输成本。具体包括：1. Wasserstein Greedy Sampling策略，通过有界覆盖半径选择性过滤冗余样本；2. Progressive Knowledge Transfer模块，通过可学习路径逐步将压缩的早期表示注入后期，缓解后期适应中的语义丢失。

Result: 在三个基准测试上，FlowAdapt仅使用1%的可训练参数，实现了最先进的性能，有效缩小了域间差距，并表现出优越的样本效率和泛化能力。

Conclusion: FlowAdapt成功地解决了多智能体V2X协同感知中的域适应挑战，通过巧妙的样本选择和知识迁移机制，实现了参数高效且性能优越的域适应。

Abstract: Fast domain adaptation remains a fundamental challenge for deploying multi-agent systems across diverse environments in Vehicle-to-Everything (V2X) collaborative perception. Despite the success of Parameter-Efficient Fine-Tuning (PEFT) in natural language processing and conventional vision tasks, directly applying PEFT to multi-agent settings leads to significant performance degradation and training instability. In this work, we conduct a detailed analysis and identify two key factors: (i) inter-frame redundancy in heterogeneous sensory streams, and (ii) erosion of fine-grained semantics in deep-layer representations under PEFT adaptation. To address these issues, we propose FlowAdapt, a parameter-efficient framework grounded in optimal transport theory, which minimizes information transport costs across both data distributions and network hierarchies. Specifically, we introduce a Wasserstein Greedy Sampling strategy to selectively filter redundant samples via a bounded covering radius. Furthermore, Progressive Knowledge Transfer module is designed to progressively inject compressed early-stage representations into later stages through learnable pathways, alleviating semantic degradation in late-stage adaptation. Extensive experiments on three benchmarks demonstrate that FlowAdapt achieves state-of-the-art performance with only 1% of trainable parameters, effectively bridging domain gaps with superior sample efficiency and generalization.

</details>


### [104] [PLOT-CT: Pre-log Voronoi Decomposition Assisted Generation for Low-dose CT Reconstruction](https://arxiv.org/abs/2602.11625)
*Bin Huang,Xun Yu,Yikun Zhang,Yi Zhang,Yang Chen,Qiegen Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为PLOT-CT的新型低剂量CT重建框架，它通过在对数域之前（pre-log）使用Voronoi分解来处理原始投影数据，从而在去噪和保留信息方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的低剂量CT重建方法在图像域或对数后投影域进行操作，无法充分利用对数域之前的测量数据中的结构信息，并且容易受到噪声的放大影响。对数变换会严重放大噪声，对重建精度要求极高。

Method: 该方法首先对对数域之前的（pre-log）投影图（sinograms）应用Voronoi分解，将数据解耦为不同的潜在成分，并分别嵌入到独立的潜在空间中。这种显式分解增强了模型学习判别性特征的能力，通过减轻噪声和保留pre-log域中的信息来直接提高重建精度。

Result: 在1e4入射光子水平下，PLOT-CT在pre-log域的PSNR比传统方法提高了2.36dB，达到了最先进的性能。

Conclusion: PLOT-CT框架通过在对数域之前进行Voronoi分解，有效解决了低剂量CT重建中的噪声和数据保真度问题，并在实验中证明了其优越性。

Abstract: Low-dose computed tomography (LDCT) reconstruction is fundamentally challenged by severe noise and compromised data fidelity under reduced radiation exposure. Most existing methods operate either in the image or post-log projection domain, which fails to fully exploit the rich structural information in pre-log measurements while being highly susceptible to noise. The requisite logarithmic transformation critically amplifies noise within these data, imposing exceptional demands on reconstruction precision. To overcome these challenges, we propose PLOT-CT, a novel framework for Pre-Log vOronoi decomposiTion-assisted CT generation. Our method begins by applying Voronoi decomposition to pre-log sinograms, disentangling the data into distinct underlying components, which are embedded in separate latent spaces. This explicit decomposition significantly enhances the model's capacity to learn discriminative features, directly improving reconstruction accuracy by mitigating noise and preserving information inherent in the pre-log domain. Extensive experiments demonstrate that PLOT-CT achieves state-of-the-art performance, attaining a 2.36dB PSNR improvement over traditional methods at the 1e4 incident photon level in the pre-log domain.

</details>


### [105] [PLESS: Pseudo-Label Enhancement with Spreading Scribbles for Weakly Supervised Segmentation](https://arxiv.org/abs/2602.11628)
*Yeva Gabrielyan,Varduhi Yeghiazaryan,Irina Voiculescu*

Main category: cs.CV

TL;DR: 提出了一种名为 PLESS 的通用伪标签增强策略，用于改善基于涂鸦标注的弱监督医学图像分割中的伪标签质量和空间一致性，并在两个心脏 MRI 数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于涂鸦标注的弱监督医学图像分割方法通常依赖伪标签进行训练，但伪标签的质量是限制模型性能的关键因素。因此，需要一种方法来提高伪标签的可靠性和空间一致性。

Method: PLESS 策略将图像划分为一个层次结构，并利用语义上一致的区域来传播涂鸦信息，从而优化伪标签。该方法是模型无关的，可以集成到现有的伪标签方法中。

Result: 在 ACDC 和 MSCMRseg 两个心脏 MRI 数据集上，PLESS 在四种不同的涂鸦监督算法下均取得了分割精度的持续提升。

Conclusion: PLESS 是一种有效的伪标签增强策略，能够提高基于涂鸦标注的医学图像分割的性能，并且易于集成到现有框架中。

Abstract: Weakly supervised learning with scribble annotations uses sparse user-drawn strokes to indicate segmentation labels on a small subset of pixels. This annotation reduces the cost of dense pixel-wise labeling, but suffers inherently from noisy and incomplete supervision. Recent scribble-based approaches in medical image segmentation address this limitation using pseudo-label-based training; however, the quality of the pseudo-labels remains a key performance limit. We propose PLESS, a generic pseudo-label enhancement strategy which improves reliability and spatial consistency. It builds on a hierarchical partitioning of the image into a hierarchy of spatially coherent regions. PLESS propagates scribble information to refine pseudo-labels within semantically coherent regions. The framework is model-agnostic and easily integrates into existing pseudo-label methods. Experiments on two public cardiac MRI datasets (ACDC and MSCMRseg) across four scribble-supervised algorithms show consistent improvements in segmentation accuracy. Code will be made available on GitHub upon acceptance.

</details>


### [106] [ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning](https://arxiv.org/abs/2602.11636)
*Changti Wu,Jiahuai Mao,Yuzhuo Miao,Shijie Lian,Bin Yu,Xiaopeng Lin,Cong Huang,Lei Zhang,Kai Chen*

Main category: cs.CV

TL;DR: 提出了一种名为ScalSelect的可扩展、无需训练的多模态数据选择方法，该方法具有线性时间复杂度，可以在不使用额外模型或数据集的情况下，从大规模视觉指令调优数据集中高效地选择训练数据，从而在不显著损失性能的情况下大幅减少训练成本。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉指令调优（VIT）在多模态任务中表现出色，但其训练成本高昂且效率低下，主要是因为数据冗余。现有的数据选择方法要么训练成本高，要么依赖代理模型或计算复杂度高，因此需要一种高效、可扩展且无需训练的解决方案。

Method: ScalSelect首先通过提取指令令牌在目标VLM中最关注的视觉特征来构建样本表示，从而捕获与指令相关的信息。然后，它通过识别其表示最能近似完整数据集表示的主子空间的样本来确定样本的重要性，从而实现无需成对比较的可扩展重要性评分。

Result: ScalSelect在多个VLM、数据集和选择预算上进行了广泛实验，结果表明，仅使用16%的数据就能达到全数据集训练97.5%以上的性能，甚至在某些情况下优于全数据集训练。

Conclusion: ScalSelect是一种高效、可扩展且无需训练的多模态数据选择方法，能够显著降低VIT的训练成本，同时保持或提高模型性能。

Abstract: Large-scale Visual Instruction Tuning (VIT) has become a key paradigm for advancing the performance of vision-language models (VLMs) across various multimodal tasks. However, training on the large-scale datasets is computationally expensive and inefficient due to redundancy in the data, which motivates the need for multimodal data selection to improve training efficiency. Existing data selection methods for VIT either require costly training or gradient computation. Training-free alternatives often depend on proxy models or datasets, instruction-agnostic representations, and pairwise similarity with quadratic complexity, limiting scalability and representation fidelity. In this work, we propose ScalSelect, a scalable training-free multimodal data selection method with linear-time complexity with respect to the number of samples, eliminating the need for external models or auxiliary datasets. ScalSelect first constructs sample representations by extracting visual features most attended by instruction tokens in the target VLM, capturing instruction-relevant information. It then identifies samples whose representations best approximate the dominant subspace of the full dataset representations, enabling scalable importance scoring without pairwise comparisons. Extensive experiments across multiple VLMs, datasets, and selection budgets demonstrate that ScalSelect achieves over 97.5% of the performance of training on the full dataset using only 16% of the data, and even outperforms full-data training in some settings. The code is available at \href{https://github.com/ChangtiWu/ScalSelect}{ScalSelect}.

</details>


### [107] [Electrostatics-Inspired Surface Reconstruction (EISR): Recovering 3D Shapes as a Superposition of Poisson's PDE Solutions](https://arxiv.org/abs/2602.11642)
*Diego Patiño,Knut Peterson,Kostas Daniilidis,David K. Han*

Main category: cs.CV

TL;DR: 本文提出一种基于泊松方程代理PDE的新颖表面重建方法，利用格林函数获得封闭形式的参数化解，并通过叠加求解目标隐式场，在逼近高频细节方面表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于Eikonal PDE的隐式形状表示方法在处理高频细节时存在不足，作者希望提出一种更有效的方法。

Method: 将表面重建编码为泊松方程的解，利用格林函数获得封闭形式的参数化表达式，并通过叠加求解目标形状的隐式场。

Result: 该方法在逼近高频细节方面取得了改进，即使在只有少量形状先验的情况下也能保持良好的性能。

Conclusion: 通过将表面重建问题转化为泊松方程的解，并利用格林函数和叠加原理，可以有效地恢复具有高频细节的3D形状的隐式表示。

Abstract: Implicit shape representation, such as SDFs, is a popular approach to recover the surface of a 3D shape as the level sets of a scalar field. Several methods approximate SDFs using machine learning strategies that exploit the knowledge that SDFs are solutions of the Eikonal partial differential equation (PDEs). In this work, we present a novel approach to surface reconstruction by encoding it as a solution to a proxy PDE, namely Poisson's equation. Then, we explore the connection between Poisson's equation and physics, e.g., the electrostatic potential due to a positive charge density. We employ Green's functions to obtain a closed-form parametric expression for the PDE's solution, and leverage the linearity of our proxy PDE to find the target shape's implicit field as a superposition of solutions. Our method shows improved results in approximating high-frequency details, even with a small number of shape priors.

</details>


### [108] [Brain Tumor Classifiers Under Attack: Robustness of ResNet Variants Against Transferable FGSM and PGD Attacks](https://arxiv.org/abs/2602.11646)
*Ryan Deem,Garrett Goodman,Waqas Majeed,Md Abdullah Al Hafiz Khan,Michail S. Alexiou*

Main category: cs.CV

TL;DR: 本研究评估了几种基于 ResNet 的脑肿瘤分类模型（BrainNet、BrainNeXt、DilationNet）在不同预处理配置下，针对 FGSM 和 PGD 两种梯度攻击的对抗鲁棒性。结果表明，BrainNeXt 在黑盒攻击下最鲁棒，但生成的对抗样本迁移性较弱。Shrunk 和非增强数据会显著降低模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在脑肿瘤分类中的对抗鲁棒性对于临床应用至关重要，但仍未得到充分研究。

Method: 评估了 BrainNet、BrainNeXt 和 DilationNet 三种 ResNet 变体模型，在三种预处理配置（全尺寸增强、缩小增强、缩小非增强 MRI 数据集）下，针对 FGSM 和 PGD 攻击的鲁棒性。

Result: BrainNeXt 在黑盒攻击下表现出最高的鲁棒性，但生成的对抗样本迁移性较弱。BrainNet 和 DilationNet 对彼此的攻击（尤其是在 PGD 攻击下）更易受攻击。缩小和非增强数据显著降低了模型鲁棒性，即使在测试准确率较高的情况下。

Conclusion: 在脑 MRI 分析的实际应用中，需要同时评估分类性能和对抗鲁棒性，以确保模型的可靠性。

Abstract: Adversarial robustness in deep learning models for brain tumor classification remains an underexplored yet critical challenge, particularly for clinical deployment scenarios involving MRI data. In this work, we investigate the susceptibility and resilience of several ResNet-based architectures, referred to as BrainNet, BrainNeXt and DilationNet, against gradient-based adversarial attacks, namely FGSM and PGD. These models, based on ResNet, ResNeXt, and dilated ResNet variants respectively, are evaluated across three preprocessing configurations (i) full-sized augmented, (ii) shrunk augmented and (iii) shrunk non-augmented MRI datasets. Our experiments reveal that BrainNeXt models exhibit the highest robustness to black-box attacks, likely due to their increased cardinality, though they produce weaker transferable adversarial samples. In contrast, BrainNet and Dilation models are more vulnerable to attacks from each other, especially under PGD with higher iteration steps and $α$ values. Notably, shrunk and non-augmented data significantly reduce model resilience, even when the untampered test accuracy remains high, highlighting a key trade-off between input resolution and adversarial vulnerability. These results underscore the importance of jointly evaluating classification performance and adversarial robustness for reliable real-world deployment in brain MRI analysis.

</details>


### [109] [GR-Diffusion: 3D Gaussian Representation Meets Diffusion in Whole-Body PET Reconstruction](https://arxiv.org/abs/2602.11653)
*Mengxiao Geng,Zijie Chen,Ran Hong,Bingxuan Li,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出了一种名为GR-Diffusion的新型框架，结合了高斯表示（GR）的几何先验和扩散模型的生成能力，用于3D低剂量全身PET重建，有效提升了图像质量和细节保留。


<details>
  <summary>Details</summary>
Motivation: 传统的PET重建方法因稀疏采样和病态反问题而面临噪声放大、结构模糊和细节丢失的挑战。现有方法难以克服低通滤波的限制。

Method: 利用GR高效编码3D场景的特性，生成物理上合理且结构明确的3D PET参考图像。该参考图像通过分层指导机制（细粒度和粗粒度）引导扩散模型，利用GR的几何先验恢复子体素信息。

Result: 在UDPET和Clinical数据集上，GR-Diffusion在不同剂量水平下，均在提升3D全身PET图像质量和保留生理细节方面优于现有最先进的方法。

Conclusion: GR-Diffusion框架成功地将GR的几何先验与扩散模型的生成能力相结合，为3D低剂量全身PET重建提供了一种有效的方法，显著提高了图像质量和细节准确性。

Abstract: Positron emission tomography (PET) reconstruction is a critical challenge in molecular imaging, often hampered by noise amplification, structural blurring, and detail loss due to sparse sampling and the ill-posed nature of inverse problems. The three-dimensional discrete Gaussian representation (GR), which efficiently encodes 3D scenes using parameterized discrete Gaussian distributions, has shown promise in computer vision. In this work, we pro-pose a novel GR-Diffusion framework that synergistically integrates the geometric priors of GR with the generative power of diffusion models for 3D low-dose whole-body PET reconstruction. GR-Diffusion employs GR to generate a reference 3D PET image from projection data, establishing a physically grounded and structurally explicit benchmark that overcomes the low-pass limitations of conventional point-based or voxel-based methods. This reference image serves as a dual guide during the diffusion process, ensuring both global consistency and local accuracy. Specifically, we employ a hierarchical guidance mechanism based on the GR reference. Fine-grained guidance leverages differences to refine local details, while coarse-grained guidance uses multi-scale difference maps to correct deviations. This strategy allows the diffusion model to sequentially integrate the strong geometric prior from GR and recover sub-voxel information. Experimental results on the UDPET and Clinical datasets with varying dose levels show that GR-Diffusion outperforms state-of-the-art methods in enhancing 3D whole-body PET image quality and preserving physiological details.

</details>


### [110] [SToRM: Supervised Token Reduction for Multi-modal LLMs toward efficient end-to-end autonomous driving](https://arxiv.org/abs/2602.11656)
*Seo Hyun Kim,Jin Bok Park,Do Yeon Koo,Ho Gun Park,Il Yong Chun*

Main category: cs.CV

TL;DR: 本文提出了一种名为 SToRM 的监督式 token 缩减框架，用于多模态大语言模型（MLLM），以在保持端到端驾驶性能的同时，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动驾驶系统依赖于 MLLM 来处理人类指令，但这需要大量的计算资源，尤其是在自动驾驶汽车的计算能力有限的情况下。现有方法在减少视觉 token 时通常会导致性能下降。

Method: SToRM 框架包含三个关键部分：1) 一个轻量级的“重要性预测器”，利用短时滑动窗口估计 token 重要性；2) 一个“监督式训练方法”，通过辅助路径从全 token LLM 推理中获取伪监督信号；3) 一个“锚点-上下文合并模块”，将 token 分为锚点和上下文，并将上下文 token 合并到相关的锚点中，以减少冗余。

Result: 在 LangAuto 基准测试中，SToRM 在相同的 token 缩减预算下，性能优于现有的端到端驾驶 MLLM，并达到了与使用所有 token 相当的性能，同时将计算成本降低了高达 30 倍。

Conclusion: SToRM 是一种有效的方法，可以在不牺牲性能的情况下显著降低 MLLM 在自动驾驶中的计算需求，为在资源受限的自动驾驶汽车中部署 MLLM 开辟了道路。

Abstract: In autonomous driving, end-to-end (E2E) driving systems that predict control commands directly from sensor data have achieved significant advancements. For safe driving in unexpected scenarios, these systems may additionally rely on human interventions such as natural language instructions. Using a multi-modal large language model (MLLM) facilitates human-vehicle interaction and can improve performance in such scenarios. However, this approach requires substantial computational resources due to its reliance on an LLM and numerous visual tokens from sensor inputs, which are limited in autonomous vehicles. Many MLLM studies have explored reducing visual tokens, but often suffer end-task performance degradation compared to using all tokens.
  To enable efficient E2E driving while maintaining performance comparable to using all tokens, this paper proposes the first Supervised Token Reduction framework for multi-modal LLMs (SToRM). The proposed framework consists of three key elements. First, a lightweight importance predictor with short-term sliding windows estimates token importance scores. Second, a supervised training approach uses an auxiliary path to obtain pseudo-supervision signals from an all-token LLM pass. Third, an anchor-context merging module partitions tokens into anchors and context tokens, and merges context tokens into relevant anchors to reduce redundancy while minimizing information loss. Experiments on the LangAuto benchmark show that SToRM outperforms state-of-the-art E2E driving MLLMs under the same reduced-token budget, maintaining all-token performance while reducing computational cost by up to 30x.

</details>


### [111] [EmoSpace: Fine-Grained Emotion Prototype Learning for Immersive Affective Content Generation](https://arxiv.org/abs/2602.11658)
*Bingyuan Wang,Xingbei Chen,Zongyang Qiu,Linping Yuan,Zeyu Wang*

Main category: cs.CV

TL;DR: EmoSpace 是一个用于情绪感知内容生成的框架，通过学习动态、可解释的情绪原型，实现了细粒度的情绪控制，并支持多种应用。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法在捕捉细微的情绪语义和实现精细控制方面存在不足，限制了沉浸式VR内容的创作。

Method: EmoSpace 框架通过视觉-语言对齐学习动态、可解释的情绪原型，采用分层情绪表示和可演化的原型，实现无需显式情绪标签的细粒度情绪控制。开发了包含多原型引导、时间混合和注意力重加权的可控生成流程。

Result: EmoSpace 在情绪图像外绘、风格化生成和VR环境的情绪全景图生成等方面表现优于现有方法，并在定性和定量评估中均获得 superior 性能。用户研究表明VR环境对情绪感知有影响。

Conclusion: EmoSpace 促进了具有细粒度情绪控制的沉浸式视觉内容生成，并支持包括治疗、教育、讲故事、艺术创作和文化保护在内的多种应用。

Abstract: Emotion is important for creating compelling virtual reality (VR) content. Although some generative methods have been applied to lower the barrier to creating emotionally rich content, they fail to capture the nuanced emotional semantics and the fine-grained control essential for immersive experiences. To address these limitations, we introduce EmoSpace, a novel framework for emotion-aware content generation that learns dynamic, interpretable emotion prototypes through vision-language alignment. We employ a hierarchical emotion representation with rich learnable prototypes that evolve during training, enabling fine-grained emotional control without requiring explicit emotion labels. We develop a controllable generation pipeline featuring multi-prototype guidance, temporal blending, and attention reweighting that supports diverse applications, including emotional image outpainting, stylized generation, and emotional panorama generation for VR environments. Our experiments demonstrate the superior performance of EmoSpace over existing methods in both qualitative and quantitative evaluations. Additionally, we present a comprehensive user study investigating how VR environments affect emotional perception compared to desktop settings. Our work facilitates immersive visual content generation with fine-grained emotion control and supports applications like therapy, education, storytelling, artistic creation, and cultural preservation. Code and models will be made publicly available.

</details>


### [112] [Egocentric Gaze Estimation via Neck-Mounted Camera](https://arxiv.org/abs/2602.11669)
*Haoyu Huang,Yoichi Sato*

Main category: cs.CV

TL;DR: 本文提出了颈部摄像头视角的注视点估计任务，并发布了首个相关数据集。研究评估并改进了基于 Transformer 的注视点估计模型，发现加入“注视点越界分类”任务可提升性能，但多视角联合学习方法未见明显效果。


<details>
  <summary>Details</summary>
Motivation: 现有 egocentric 注视点估计研究多集中于头戴式摄像头，而颈部摄像头这一替代视角的研究较少，存在研究空白。

Method: 收集并发布了首个颈部摄像头视角的注视点估计数据集。评估了基于 Transformer 的 GLC 模型，并提出了两种改进方法：1) 辅助注视点越界分类任务；2) 多视角联合学习（结合头戴和颈部视角）。

Result: 辅助注视点越界分类任务在模型性能上带来了提升。多视角联合学习方法未能带来性能增益。

Conclusion: 颈部摄像头视角注视点估计是一个可行的新任务。通过引入辅助分类任务可以有效提升模型性能，但多视角联合学习方法在此任务上并未显示出优势。

Abstract: This paper introduces neck-mounted view gaze estimation, a new task that estimates user gaze from the neck-mounted camera perspective. Prior work on egocentric gaze estimation, which predicts device wearer's gaze location within the camera's field of view, mainly focuses on head-mounted cameras while alternative viewpoints remain underexplored. To bridge this gap, we collect the first dataset for this task, consisting of approximately 4 hours of video collected from 8 participants during everyday activities. We evaluate a transformer-based gaze estimation model, GLC, on the new dataset and propose two extensions: an auxiliary gaze out-of-bound classification task and a multi-view co-learning approach that jointly trains head-view and neck-view models using a geometry-aware auxiliary loss. Experimental results show that incorporating gaze out-of-bound classification improves performance over standard fine-tuning, while the co-learning approach does not yield gains. We further analyze these results and discuss implications for neck-mounted gaze estimation.

</details>


### [113] [LLM-Driven 3D Scene Generation of Agricultural Simulation Environments](https://arxiv.org/abs/2602.11706)
*Arafa Yoncalik,Wouter Jansen,Nico Huebel,Mohammad Hasan Rahmani,Jan Steckel*

Main category: cs.CV

TL;DR: 本研究提出了一种基于多大语言模型（LLM）的模块化管道，用于根据自然语言提示生成农业合成仿真环境，克服了现有LLM方法在领域特定推理、验证和模块化方面的不足，提高了生成环境的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的利用大语言模型生成3D场景的方法缺乏领域特定推理、验证机制和模块化设计，导致控制性差、可扩展性不足。本研究旨在解决这些局限性，特别是在农业合成仿真环境中。

Method: 开发了一个模块化的多LLM管道，集成了3D资产检索、领域知识注入和针对Unreal引擎API的代码生成。采用少样本提示、检索增强生成（RAG）、微调和验证等混合策略来提高准确性和可扩展性。该管道的模块化架构支持结构化数据处理、中间验证和灵活扩展。

Result: 生成了具有逼真种植布局和环境背景的3D环境，并根据输入提示和领域知识进行了定制。通过结构化提示和语义准确性指标进行了评估。用户研究表明生成的环境具有现实感和熟悉度。专家比较显示，与手动场景设计相比，该方法显著节省了时间。

Conclusion: 多LLM管道在自动化特定领域的3D场景生成方面是有效的，并且能够提高可靠性和精确性。该方法通过模块化设计和混合LLM优化策略，成功解决了现有方法的局限性。

Abstract: Procedural generation techniques in 3D rendering engines have revolutionized the creation of complex environments, reducing reliance on manual design. Recent approaches using Large Language Models (LLMs) for 3D scene generation show promise but often lack domain-specific reasoning, verification mechanisms, and modular design. These limitations lead to reduced control and poor scalability. This paper investigates the use of LLMs to generate agricultural synthetic simulation environments from natural language prompts, specifically to address the limitations of lacking domain-specific reasoning, verification mechanisms, and modular design. A modular multi-LLM pipeline was developed, integrating 3D asset retrieval, domain knowledge injection, and code generation for the Unreal rendering engine using its API. This results in a 3D environment with realistic planting layouts and environmental context, all based on the input prompt and the domain knowledge. To enhance accuracy and scalability, the system employs a hybrid strategy combining LLM optimization techniques such as few-shot prompting, Retrieval-Augmented Generation (RAG), finetuning, and validation. Unlike monolithic models, the modular architecture enables structured data handling, intermediate verification, and flexible expansion. The system was evaluated using structured prompts and semantic accuracy metrics. A user study assessed realism and familiarity against real-world images, while an expert comparison demonstrated significant time savings over manual scene design. The results confirm the effectiveness of multi-LLM pipelines in automating domain-specific 3D scene generation with improved reliability and precision. Future work will explore expanding the asset hierarchy, incorporating real-time generation, and adapting the pipeline to other simulation domains beyond agriculture.

</details>


### [114] [Clutt3R-Seg: Sparse-view 3D Instance Segmentation for Language-grounded Grasping in Cluttered Scenes](https://arxiv.org/abs/2602.11660)
*Jeongho Noh,Tai Hyoung Rhee,Eunho Lee,Jeongyun Kim,Sunwoo Lee,Ayoung Kim*

Main category: cs.CV

TL;DR: Clutt3R-Seg是一个用于物体抓取任务的零样本3D实例分割流水线，它通过层次化的语义线索树来处理遮挡和噪声，实现了视图一致的分割，并能从自然语言指令中进行目标选择。该方法还能在任务执行过程中适应场景变化。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境中，遮挡、视角受限和噪声会严重影响3D实例分割的准确性，这对基于语言的机器人操作至关重要。现有方法在细化噪声掩码方面存在不足。

Method: 提出Clutt3R-Seg流水线，其核心是引入一个包含语义线索的层次化实例树。通过跨视图分组和条件替换来利用噪声掩码作为信息来源，以抑制过分割和欠分割。每个实例都包含开放词汇的语义嵌入，以支持自然语言指令。引入了一致性感知更新机制，以适应场景变化。

Result: Clutt3R-Seg在合成和真实数据集上均表现出色，尤其在杂乱和稀疏视图场景下，性能显著优于最先进的方法。在重度杂乱场景下，AP@25达到了61.66，是基线的2.2倍以上。仅使用4个输入视图，其性能就超过了使用8个视图的MaskClustering。

Conclusion: Clutt3R-Seg能够鲁棒地进行3D实例分割，有效处理杂乱环境中的遮挡和噪声问题，并通过语言指令实现精确的目标选择，并能适应动态场景变化，为语言驱动的机器人抓取任务提供了强大的感知基础。

Abstract: Reliable 3D instance segmentation is fundamental to language-grounded robotic manipulation. Its critical application lies in cluttered environments, where occlusions, limited viewpoints, and noisy masks degrade perception. To address these challenges, we present Clutt3R-Seg, a zero-shot pipeline for robust 3D instance segmentation for language-grounded grasping in cluttered scenes. Our key idea is to introduce a hierarchical instance tree of semantic cues. Unlike prior approaches that attempt to refine noisy masks, our method leverages them as informative cues: through cross-view grouping and conditional substitution, the tree suppresses over- and under-segmentation, yielding view-consistent masks and robust 3D instances. Each instance is enriched with open-vocabulary semantic embeddings, enabling accurate target selection from natural language instructions. To handle scene changes during multi-stage tasks, we further introduce a consistency-aware update that preserves instance correspondences from only a single post-interaction image, allowing efficient adaptation without rescanning. Clutt3R-Seg is evaluated on both synthetic and real-world datasets, and validated on a real robot. Across all settings, it consistently outperforms state-of-the-art baselines in cluttered and sparse-view scenarios. Even on the most challenging heavy-clutter sequences, Clutt3R-Seg achieves an AP@25 of 61.66, over 2.2x higher than baselines, and with only four input views it surpasses MaskClustering with eight views by more than 2x. The code is available at: https://github.com/jeonghonoh/clutt3r-seg.

</details>


### [115] [U-Net with Hadamard Transform and DCT Latent Spaces for Next-day Wildfire Spread Prediction](https://arxiv.org/abs/2602.11672)
*Yingyi Luo,Shuaiang Rong,Adam Watts,Ahmet Enis Cetin*

Main category: cs.CV

TL;DR: 开发了一个名为 TD-FusionUNet 的轻量级深度学习模型，用于利用多模态卫星数据进行次日火灾蔓延预测，通过引入变换域融合和自定义预处理技术，在保证较低参数量的同时提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 为了实现资源受限环境下的实时火灾预测，需要开发一种既能保持高精度又计算效率高的轻量级火灾蔓延预测工具。

Method: 提出了一种名为 TD-FusionUNet 的深度学习模型，该模型融合了可训练的 Hadamard 变换和离散余弦变换层，以捕捉正交潜在空间中的“频率”分量。此外，还采用了随机边距裁剪和高斯混合模型等自定义预处理技术来增强稀疏火灾掩模的表示能力和模型泛化能力。

Result: 在两个数据集（Google Research 发布的 Next-Day Wildfire Spread 数据集和 WildfireSpreadTS 数据集）上评估 TD-FusionUNet。结果显示，TD-FusionUNet 在 WildfireSpreadTS 数据集上取得了 0.591 的 F1 分数，拥有 370k 参数，优于采用 ResNet18 作为编码器的 UNet 基线模型，且参数量远少于基线模型。

Conclusion: TD-FusionUNet 模型在轻量级设置下实现了准确性和效率的良好平衡，适用于资源受限环境下的实时火灾预测应用。

Abstract: We developed a lightweight and computationally efficient tool for next-day wildfire spread prediction using multimodal satellite data as input. The deep learning model, which we call Transform Domain Fusion UNet (TD-FusionUNet), incorporates trainable Hadamard Transform and Discrete Cosine Transform layers that apply two-dimensional transforms, enabling the network to capture essential "frequency" components in orthogonalized latent spaces. Additionally, we introduce custom preprocessing techniques, including random margin cropping and a Gaussian mixture model, to enrich the representation of the sparse pre-fire masks and enhance the model's generalization capability. The TD-FusionUNet is evaluated on two datasets which are the Next-Day Wildfire Spread dataset released by Google Research in 2023, and WildfireSpreadTS dataset. Our proposed TD-FusionUNet achieves an F1 score of 0.591 with 370k parameters, outperforming the UNet baseline using ResNet18 as the encoder reported in the WildfireSpreadTS dataset while using substantially fewer parameters. These results show that the proposed latent space fusion model balances accuracy and efficiency under a lightweight setting, making it suitable for real time wildfire prediction applications in resource limited environments.

</details>


### [116] [GSO-SLAM: Bidirectionally Coupled Gaussian Splatting and Direct Visual Odometry](https://arxiv.org/abs/2602.11714)
*Jiung Yeon,Seongbo Ha,Hyeonwoo Yu*

Main category: cs.CV

TL;DR: 本文提出了一种名为 GSO-SLAM 的实时单目稠密 SLAM 系统，该系统利用高斯场景表示，通过联合优化视觉里程计（VO）和高斯喷溅（GS）来同时优化深度估计和场景表示，实现了高效且高保真的场景重建和跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有 SLAM 方法要么将跟踪和建图紧密耦合导致计算成本高，要么松散集成导致冗余。本文旨在提出一种更高效、更高保真的方法，以解决这些问题。

Method: 本文提出 GSO-SLAM，通过在期望最大化（EM）框架内进行联合优化，双向耦合视觉里程计（VO）和高斯喷溅（GS）。此外，还提出了一种高斯喷溅初始化方法，利用图像信息、关键帧姿态和像素关联来生成场景的近似表示。

Result: 实验结果表明，GSO-SLAM 能够实时运行，并在重建场景的几何/光度保真度和跟踪精度方面达到最先进的水平。

Conclusion: GSO-SLAM 是一种高效且高保真的实时单目稠密 SLAM 系统，通过联合优化 VO 和 GS，并在 EM 框架内进行，实现了优于现有方法的性能。

Abstract: We propose GSO-SLAM, a real-time monocular dense SLAM system that leverages Gaussian scene representation. Unlike existing methods that couple tracking and mapping with a unified scene, incurring computational costs, or loosely integrate them with well-structured tracking frameworks, introducing redundancies, our method bidirectionally couples Visual Odometry (VO) and Gaussian Splatting (GS). Specifically, our approach formulates joint optimization within an Expectation-Maximization (EM) framework, enabling the simultaneous refinement of VO-derived semi-dense depth estimates and the GS representation without additional computational overhead. Moreover, we present Gaussian Splat Initialization, which utilizes image information, keyframe poses, and pixel associations from VO to produce close approximations to the final Gaussian scene, thereby eliminating the need for heuristic methods. Through extensive experiments, we validate the effectiveness of our method, showing that it not only operates in real time but also achieves state-of-the-art geometric/photometric fidelity of the reconstructed scene and tracking accuracy.

</details>


### [117] [RI-Mamba: Rotation-Invariant Mamba for Robust Text-to-Shape Retrieval](https://arxiv.org/abs/2602.11673)
*Khanh Nguyen,Dasith de Silva Edirimuni,Ghulam Mubashar Hassan,Ajmal Mian*

Main category: cs.CV

TL;DR: RI-Mamba 是一种新颖的旋转不变状态空间模型，用于点云的文本到形状检索，通过解耦姿态和几何、利用希尔伯特排序以及引入新的方向嵌入计算策略，实现了对任意方向的 200 多个类别的高效检索。


<details>
  <summary>Details</summary>
Motivation: 现有文本到形状检索方法在处理具有不同姿态和多样类别真实世界对象时存在局限性，需要规范姿态且仅支持少量类别。

Method: 提出 RI-Mamba，一个旋转不变的状态空间模型，通过定义全局和局部参考系来解耦姿态与几何，使用希尔伯特排序构建具有几何结构的 Token 序列，并引入计算方向嵌入和通过特征维度线性调制的策略来恢复空间上下文。同时采用跨模态对比学习和自动三元组生成进行大规模训练。

Result: RI-Mamba 在 OmniObject3D 基准上，在超过 200 个对象类别和任意方向下，实现了最先进的性能，展示了其优越的表示能力和鲁棒性。

Conclusion: RI-Mamba 是首个用于点云的旋转不变状态空间模型，有效解决了现有方法的局限性，并在大规模、多类别的文本到形状检索任务中取得了显著的成功。

Abstract: 3D assets have rapidly expanded in quantity and diversity due to the growing popularity of virtual reality and gaming. As a result, text-to-shape retrieval has become essential in facilitating intuitive search within large repositories. However, existing methods require canonical poses and support few object categories, limiting their real-world applicability where objects can belong to diverse classes and appear in random orientations. To address this challenge, we propose RI-Mamba, the first rotation-invariant state-space model for point clouds. RI-Mamba defines global and local reference frames to disentangle pose from geometry and uses Hilbert sorting to construct token sequences with meaningful geometric structure while maintaining rotation invariance. We further introduce a novel strategy to compute orientational embeddings and reintegrate them via feature-wise linear modulation, effectively recovering spatial context and enhancing model expressiveness. Our strategy is inherently compatible with state-space models and operates in linear time. To scale up retrieval, we adopt cross-modal contrastive learning with automated triplet generation, allowing training on diverse datasets without manual annotation. Extensive experiments demonstrate RI-Mamba's superior representational capacity and robustness, achieving state-of-the-art performance on the OmniObject3D benchmark across more than 200 object categories under arbitrary orientations. Our code will be made available at https://github.com/ndkhanh360/RI-Mamba.git.

</details>


### [118] [JEPA-VLA: Video Predictive Embedding is Needed for VLA Models](https://arxiv.org/abs/2602.11832)
*Shangchen Miao,Ningya Feng,Jialong Wu,Ye Lin,Xu He,Dong Li,Mingsheng Long*

Main category: cs.CV

TL;DR: 该研究提出了一种名为JEPA-VLA的新型视觉-语言-动作（VLA）模型，通过整合预训练的预测性嵌入（如V-JEPA 2）来改进现有VLA模型的样本效率和泛化能力，并在多个机器人操纵基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练视觉语言模型（VLMs）的VLA模型在机器人操纵方面存在样本效率低和泛化能力有限的问题。作者认为这与模型中预训练的视觉表示不足有关，它未能充分捕捉环境信息和提供有效的策略先验知识。

Method: 作者首先分析了现有VLA模型中使用的视觉表示（通过对比学习或自监督学习预训练）的不足。然后，他们提出JEPA-VLA方法，将预训练的预测性嵌入（特别是V-JEPA 2）自适应地整合到现有VLA模型中。V-JEPA 2能够有效地丢弃不可预测的环境因素并编码任务相关的时序动态。

Result: JEPA-VLA在LIBERO、LIBERO-plus、RoboTwin2.0等多个基准测试以及真实机器人任务中，相比现有方法取得了显著的性能提升。

Conclusion: 预训练的预测性嵌入（如V-JEPA 2）能够提供比传统视觉表示更丰富的环境理解和策略先验，从而有效解决现有VLA模型的样本效率和泛化能力问题。JEPA-VLA是一种简单有效的方法，可以显著提升VLA模型的性能。

Abstract: Recent vision-language-action (VLA) models built upon pretrained vision-language models (VLMs) have achieved significant improvements in robotic manipulation. However, current VLAs still suffer from low sample efficiency and limited generalization. This paper argues that these limitations are closely tied to an overlooked component, pretrained visual representation, which offers insufficient knowledge on both aspects of environment understanding and policy prior. Through an in-depth analysis, we find that commonly used visual representations in VLAs, whether pretrained via language-image contrastive learning or image-based self-supervised learning, remain inadequate at capturing crucial, task-relevant environment information and at inducing effective policy priors, i.e., anticipatory knowledge of how the environment evolves under successful task execution. In contrast, we discover that predictive embeddings pretrained on videos, in particular V-JEPA 2, are adept at flexibly discarding unpredictable environment factors and encoding task-relevant temporal dynamics, thereby effectively compensating for key shortcomings of existing visual representations in VLAs. Building on these observations, we introduce JEPA-VLA, a simple yet effective approach that adaptively integrates predictive embeddings into existing VLAs. Our experiments demonstrate that JEPA-VLA yields substantial performance gains across a range of benchmarks, including LIBERO, LIBERO-plus, RoboTwin2.0, and real-robot tasks.

</details>


### [119] [Semantically Conditioned Diffusion Models for Cerebral DSA Synthesis](https://arxiv.org/abs/2602.11703)
*Qiwen Xu,David Rügamer,Holger Wenz,Johann Fontana,Nora Meggyeshazi,Andreas Bender,Máté E. Maros*

Main category: cs.CV

TL;DR: 研究提出了一种基于语义条件潜扩散模型（LDM）的脑血管造影（DSA）图像合成方法，能够生成逼真的动脉期DSA图像，并受控于解剖循环和C型臂位置，为下游算法开发、研究和训练提供了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 传统的数字减影血管造影（DSA）具有侵入性且成本高昂，限制了大规模数据收集和公开共享。因此，需要一种方法来生成逼真的DSA数据。

Method: 研究使用了一个包含99,349帧DSA数据的单中心数据集，训练了一个条件LDM。模型通过文本嵌入编码解剖信息（前循环/后循环）和成像几何（C型臂位置），以生成特定条件的DSA图像。

Result: 生成的DSA图像在临床真实性评估中，获得4位医学专家（包括2名神经放射科医生、1名神经外科医生、1名内科医生）评分为3.1至3.3（5分制），显示出高评分和高评分者间信度（ICC(2,k) = 0.80–0.87）。此外，合成图像与真实DSA帧的分布相似性通过低FID值（15.27）得到证实。

Conclusion: 研究表明，通过语义控制的LDM能够生成逼真的合成DSA图像，适用于下游算法开发、研究和医学培训。

Abstract: Digital subtraction angiography (DSA) plays a central role in the diagnosis and treatment of cerebrovascular disease, yet its invasive nature and high acquisition cost severely limit large-scale data collection and public data sharing. Therefore, we developed a semantically conditioned latent diffusion model (LDM) that synthesizes arterial-phase cerebral DSA frames under explicit control of anatomical circulation (anterior vs.\ posterior) and canonical C-arm positions. We curated a large single-centre DSA dataset of 99,349 frames and trained a conditional LDM using text embeddings that encoded anatomy and acquisition geometry. To assess clinical realism, four medical experts, including two neuroradiologists, one neurosurgeon, and one internal medicine expert, systematically rated 400 synthetic DSA images using a 5-grade Likert scale for evaluating proximal large, medium, and small peripheral vessels. The generated images achieved image-wise overall Likert scores ranging from 3.1 to 3.3, with high inter-rater reliability (ICC(2,k) = 0.80--0.87). Distributional similarity to real DSA frames was supported by a low median Fréchet inception distance (FID) of 15.27. Our results indicate that semantically controlled LDMs can produce realistic synthetic DSAs suitable for downstream algorithm development, research, and training.

</details>


### [120] [DiffPlace: Street View Generation via Place-Controllable Diffusion Model Enhancing Place Recognition](https://arxiv.org/abs/2602.11875)
*Ji Li,Zhiwei Li,Shihao Li,Zhenjiang Yu,Boyang Wang,Haiou Liu*

Main category: cs.CV

TL;DR: DiffPlace 是一个新框架，通过引入 place-ID 控制器，实现了地点可控的多视图图像生成，解决了现有方法在生成地点感知和背景一致的城市街景方面的不足，在视觉地点识别任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图扩散模型在生成地点感知和背景一致的城市街景方面存在困难，这限制了它们在视觉地点识别任务中的应用。研究旨在改进这一状况。

Method: 提出 DiffPlace 框架，引入 place-ID 控制器。该控制器使用线性投影、感知器 Transformer 和对比学习，将 place-ID 嵌入映射到固定的 CLIP 空间，从而生成具有一致背景但可灵活修改前景对象和天气条件的图像。

Result: DiffPlace 在生成质量和视觉地点识别的训练支持方面优于现有方法。实验包括定量比较和增强训练评估。

Conclusion: DiffPlace 证明了生成模型在增强场景级和地点感知的合成方面的潜力，为改进自动驾驶中的地点识别提供了一种有价值的方法。

Abstract: Generative models have advanced significantly in realistic image synthesis, with diffusion models excelling in quality and stability. Recent multi-view diffusion models improve 3D-aware street view generation, but they struggle to produce place-aware and background-consistent urban scenes from text, BEV maps, and object bounding boxes. This limits their effectiveness in generating realistic samples for place recognition tasks. To address these challenges, we propose DiffPlace, a novel framework that introduces a place-ID controller to enable place-controllable multi-view image generation. The place-ID controller employs linear projection, perceiver transformer, and contrastive learning to map place-ID embeddings into a fixed CLIP space, allowing the model to synthesize images with consistent background buildings while flexibly modifying foreground objects and weather conditions. Extensive experiments, including quantitative comparisons and augmented training evaluations, demonstrate that DiffPlace outperforms existing methods in both generation quality and training support for visual place recognition. Our results highlight the potential of generative models in enhancing scene-level and place-aware synthesis, providing a valuable approach for improving place recognition in autonomous driving

</details>


### [121] [TG-Field: Geometry-Aware Radiative Gaussian Fields for Tomographic Reconstruction](https://arxiv.org/abs/2602.11705)
*Yuxiang Zhong,Jun Wei,Chaoqi Chen,Senyou An,Hui Huang*

Main category: cs.CV

TL;DR: 提出了一种名为TG-Field的3D高斯喷涂（3DGS）方法，用于处理稀疏视角和动态CT重建中的伪影问题。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法在处理高度稀疏视角投影和动态运动的CT重建时，存在严重的伪影问题，这促使了本研究的进行。

Method: 提出了一种几何感知的高斯变形框架TG-Field。该框架使用多分辨率哈希编码器捕捉局部空间先验，并引入了时间条件表示和时空注意力模块来处理动态重建。此外，还设计了一个运动流网络来模拟呼吸运动。

Result: 在合成和真实世界数据集上的实验表明，TG-Field在高度稀疏视角条件下，在重建准确性上始终优于现有方法，达到了最先进的水平。

Conclusion: TG-Field框架能够有效地解决稀疏视角和动态CT重建中的伪影问题，并在各种条件下实现高质量的重建。

Abstract: 3D Gaussian Splatting (3DGS) has revolutionized 3D scene representation with superior efficiency and quality. While recent adaptations for computed tomography (CT) show promise, they struggle with severe artifacts under highly sparse-view projections and dynamic motions. To address these challenges, we propose Tomographic Geometry Field (TG-Field), a geometry-aware Gaussian deformation framework tailored for both static and dynamic CT reconstruction. A multi-resolution hash encoder is employed to capture local spatial priors, regularizing primitive parameters under ultra-sparse settings. We further extend the framework to dynamic reconstruction by introducing time-conditioned representations and a spatiotemporal attention block to adaptively aggregate features, thereby resolving spatiotemporal ambiguities and enforcing temporal coherence. In addition, a motion-flow network models fine-grained respiratory motion to track local anatomical deformations. Extensive experiments on synthetic and real-world datasets demonstrate that TG-Field consistently outperforms existing methods, achieving state-of-the-art reconstruction accuracy under highly sparse-view conditions.

</details>


### [122] [Adapting Vision-Language Models for E-commerce Understanding at Scale](https://arxiv.org/abs/2602.11733)
*Matteo Nulli,Vladimir Orshulevich,Tala Bazazo,Christian Herold,Michael Kozielski,Marcin Mazur,Szymon Tuzel,Cees G. M. Snoek,Seyyed Hadi Hashemi,Omar Javed,Yannick Versley,Shahram Khadivi*

Main category: cs.CV

TL;DR: 本研究提出了一种针对电商产品数据特点，对通用视觉语言模型（VLM）进行定向微调的方法，以提升其在电商领域的理解能力，同时保留其通用性能。研究还建立了一个全面的电商产品理解评估套件。


<details>
  <summary>Details</summary>
Motivation: 现有通用VLM在电商数据（属性中心、多图、噪声大）上表现不佳，且缺乏有效的适配策略，同时又担心微调会牺牲通用性能。

Method: 通过大规模实验，研究了如何对通用VLM进行定向微调，以提高其在电商领域的性能。此外，提出了一套新的、涵盖深度产品理解、严格指令遵循和动态属性提取的评估套件。

Result: 定向微调通用VLM可以显著提高其在电商领域的性能，同时保持其广泛的多模态能力。

Conclusion: 定向微调是有效提升通用VLM在电商领域表现的策略。研究提出的评估套件为评估VLM在电商场景下的能力提供了更全面的方法。

Abstract: E-commerce product understanding demands by nature, strong multimodal comprehension from text, images, and structured attributes. General-purpose Vision-Language Models (VLMs) enable generalizable multimodal latent modelling, yet there is no documented, well-known strategy for adapting them to the attribute-centric, multi-image, and noisy nature of e-commerce data, without sacrificing general performance. In this work, we show through a large-scale experimental study, how targeted adaptation of general VLMs can substantially improve e-commerce performance while preserving broad multimodal capabilities. Furthermore, we propose a novel extensive evaluation suite covering deep product understanding, strict instruction following, and dynamic attribute extraction.

</details>


### [123] [STVG-R1: Incentivizing Instance-Level Reasoning and Grounding in Videos via Reinforcement Learning](https://arxiv.org/abs/2602.11730)
*Xiaowen Zhang,Zhi Gao,Licheng Jiao,Lingling Li,Qing Li*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉提示范式，通过为视频中的每个对象分配唯一的、时间一致的ID，将空间时间视频地面定位（STVG）任务重构为实例级别的识别问题，从而避免了模态间的坐标对齐。同时，引入了STVG-R1，一个基于强化学习的框架，通过任务驱动的奖励来优化时间准确性、空间一致性和结构格式。实验证明该方法在多个基准测试中表现出色，并在HCSTVG-v2和MeViS上达到了新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在密集预测任务（如STVG）中存在文本描述与视觉坐标不匹配导致的幻觉问题。现有方法试图增强视觉-文本对齐或引入辅助解码器，但这会增加额外的可训练模块，带来高昂的标注成本和计算开销。

Method: 提出了一种新的视觉提示范式，将逐帧坐标预测转化为紧凑的实例级识别问题，通过为每个对象分配唯一、时间一致的ID。这些ID被嵌入视频中作为视觉提示。引入了STVG-R1，一个基于强化学习的框架，使用任务驱动的奖励来联合优化时间准确性、空间一致性和结构格式。

Result: 在六个基准测试上进行了广泛的实验，证明了该方法的有效性。在HCSTVG-v2基准上，STVG-R1相比Qwen2.5-VL-7B在m_IoU上提高了20.9%，达到了新的SOTA。此外，STVG-R1在多对象指代视频对象分割任务上表现出强大的零样本泛化能力，在MeViS上取得了47.3%的J&F SOTA。

Conclusion: 所提出的视觉提示范式和STVG-R1强化学习框架有效地解决了STVG任务中的坐标对齐和幻觉问题，通过实例ID提示和任务驱动的奖励优化，显著提升了性能，并在多个下游任务上实现了SOTA。

Abstract: In vision-language models (VLMs), misalignment between textual descriptions and visual coordinates often induces hallucinations. This issue becomes particularly severe in dense prediction tasks such as spatial-temporal video grounding (STVG). Prior approaches typically focus on enhancing visual-textual alignment or attaching auxiliary decoders. However, these strategies inevitably introduce additional trainable modules, leading to significant annotation costs and computational overhead. In this work, we propose a novel visual prompting paradigm that avoids the difficult problem of aligning coordinates across modalities. Specifically, we reformulate per-frame coordinate prediction as a compact instance-level identification problem by assigning each object a unique, temporally consistent ID. These IDs are embedded into the video as visual prompts, providing explicit and interpretable inputs to the VLMs. Furthermore, we introduce STVG-R1, the first reinforcement learning framework for STVG, which employs a task-driven reward to jointly optimize temporal accuracy, spatial consistency, and structural format regularization. Extensive experiments on six benchmarks demonstrate the effectiveness of our approach. STVG-R1 surpasses the baseline Qwen2.5-VL-7B by a remarkable margin of 20.9% on m_IoU on the HCSTVG-v2 benchmark, establishing a new state of the art (SOTA). Surprisingly, STVG-R1 also exhibits strong zero-shot generalization to multi-object referring video object segmentation tasks, achieving a SOTA 47.3% J&F on MeViS.

</details>


### [124] [Mask What Matters: Mitigating Object Hallucinations in Multimodal Large Language Models with Object-Aligned Visual Contrastive Decoding](https://arxiv.org/abs/2602.11737)
*Boqi Chen,Xudong Liu,Jianing Qiu*

Main category: cs.CV

TL;DR: 该研究提出了一种改进的视觉对比解码（VCD）方法，通过构建一个对象对齐的辅助视图来减少多模态大语言模型（MLLMs）中的对象幻觉现象。该方法利用对象中心注意力，移除最显著的视觉证据以创建扰乱不被支持的 token 的辅助视图，从而产生更强的对比信号。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）中存在对象幻觉问题，即模型会生成文本中不存在的对象。研究旨在解决这一问题。

Method: 通过构建一个对象对齐的辅助视图来改进视觉对比解码（VCD）。具体方法是利用自监督 Vision Transformers 中的对象中心注意力，移除最显著的视觉证据以创建辅助视图，从而干扰不支持的 token 并产生更强的对比信号。

Result: 提出的方法在两个流行的对象幻觉基准测试和两种 MLLMs 上均取得了持续的改进。

Conclusion: 该方法是 prompt-agnostic 和 model-agnostic 的，并且可以轻松集成到现有的 VCD 流程中，计算开销很小（一次可缓存的前向传播）。

Abstract: We study object hallucination in Multimodal Large Language Models (MLLMs) and improve visual contrastive decoding (VCD) by constructing an object-aligned auxiliary view. We leverage object-centric attention in self-supervised Vision Transformers. In particular, we remove the most salient visual evidence to construct an auxiliary view that disrupts unsupported tokens and produces a stronger contrast signal. Our method is prompt-agnostic, model-agnostic, and can be seamlessly plugged into the existing VCD pipeline with little computation overhead, i.e., a single cacheable forward pass. Empirically, our method demonstrates consistent gains on two popular object hallucination benchmarks across two MLLMs.

</details>


### [125] [Adaptive Debiasing Tsallis Entropy for Test-Time Adaptation](https://arxiv.org/abs/2602.11743)
*Xiangyu Wu,Dongming Jiang,Feng Yu,Yueying Tian,Jiaqi Tang,Qing-Guo Chen,Yang Yang,Jianfeng Lu*

Main category: cs.CV

TL;DR: 本文提出了一种自适应去偏 Tsallis 熵（ADTE）用于测试时自适应（TTA），以解决现有基于 Shannon Entropy (SE) 的方法在处理 CLIP 模型固有的预训练数据偏差问题。ADTE 通过引入非详尽参数 q 并为每个类别学习一个特定参数，能够更准确地估计不确定性，从而提高了 TTA 的性能。


<details>
  <summary>Details</summary>
Motivation: 主流的测试时自适应（TTA）方法（如基于 CLIP 的方法）依赖于 Shannon Entropy (SE) 来衡量预测不确定性。然而，CLIP 的预训练数据存在固有的偏差，导致 SE 估算出的不确定性熵也存在偏差。作者希望找到一种能处理这种偏差的方法来改进 TTA。

Method: 本文提出使用 Tsallis Entropy (TE) 作为 SE 的一种更通用的替代方案，因为 TE 的非详尽参数 q 可以处理有偏分布。在此基础上，进一步提出了自适应去偏 Tsallis Entropy (ADTE)，它为每个类别学习一个特定的参数 q^l，通过对输入测试实例的标签偏差进行归一化得到。ADTE 能够准确选择高置信度的视图，并与标签调整策略结合以增强自适应能力，无需额外的超参数调优。

Result: 实验结果表明，ADTE 在 ImageNet 及其五个变体上的表现优于最先进的方法，并在 10 个跨域基准测试中取得了最高的平均性能，且不依赖于模型架构或文本提示。

Conclusion: Tsallis Entropy (TE) 和自适应去偏 Tsallis Entropy (ADTE) 是 SE 的有效替代方案，能够直接用于 TTA 任务。ADTE 通过自适应地处理模型偏差，显著提高了 TTA 的性能，在各种场景下都表现出色。

Abstract: Mainstream Test-Time Adaptation (TTA) methods for adapting vision-language models, e.g., CLIP, typically rely on Shannon Entropy (SE) at test time to measure prediction uncertainty and inconsistency. However, since CLIP has a built-in bias from pretraining on highly imbalanced web-crawled data, SE inevitably results in producing biased estimates of uncertainty entropy. To address this issue, we notably find and demonstrate that Tsallis Entropy (TE), a generalized form of SE, is naturally suited for characterizing biased distributions by introducing a non-extensive parameter q, with the performance of SE serving as a lower bound for TE. Building upon this, we generalize TE into Adaptive Debiasing Tsallis Entropy (ADTE) for TTA, customizing a class-specific parameter q^l derived by normalizing the estimated label bias from continuously incoming test instances, for each category. This adaptive approach allows ADTE to accurately select high-confidence views and seamlessly integrate with a label adjustment strategy to enhance adaptation, without introducing distribution-specific hyperparameter tuning. Besides, our investigation reveals that both TE and ADTE can serve as direct, advanced alternatives to SE in TTA, without any other modifications. Experimental results show that ADTE outperforms state-of-the-art methods on ImageNet and its five variants, and achieves the highest average performance on 10 cross-domain benchmarks, regardless of the model architecture or text prompts used. Our code is available at https://github.com/Jinx630/ADTE.

</details>


### [126] [Code2Worlds: Empowering Coding LLMs for 4D World Generation](https://arxiv.org/abs/2602.11757)
*Yi Zhang,Yunshuang Wang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出了Code2Worlds框架，通过语言到仿真代码生成的方式解决4D动态场景生成中的多尺度上下文纠缠和语义-物理执行鸿沟问题，并通过双流架构和闭环机制提升了生成场景的物理真实性。


<details>
  <summary>Details</summary>
Motivation: 现有在3D场景生成方面的进展未能有效扩展到4D动态场景，主要面临多尺度上下文纠缠（难以平衡局部物体结构和全局环境布局）和语义-物理执行鸿沟（生成代码缺乏动态保真度）两大挑战。

Method: Code2Worlds框架将4D生成视为语言到仿真代码生成。采用双流架构，解耦了检索增强的对象生成和层级化的环境编排。引入物理感知闭环机制，通过PostProcess Agent编写动力学脚本，并由VLM-Motion Critic进行自我反思，迭代优化仿真代码。

Result: 在Code4D基准测试中，Code2Worlds相比基线方法，SGS提升41%，Richness提升49%。生成结果具有物理感知动力学，这是现有静态方法所不具备的。

Conclusion: Code2Worlds框架能够有效解决4D动态场景生成中的挑战，生成具有物理真实性的动态场景，显著优于现有方法。

Abstract: Achieving spatial intelligence requires moving beyond visual plausibility to build world simulators grounded in physical laws. While coding LLMs have advanced static 3D scene generation, extending this paradigm to 4D dynamics remains a critical frontier. This task presents two fundamental challenges: multi-scale context entanglement, where monolithic generation fails to balance local object structures with global environmental layouts; and a semantic-physical execution gap, where open-loop code generation leads to physical hallucinations lacking dynamic fidelity. We introduce Code2Worlds, a framework that formulates 4D generation as language-to-simulation code generation. First, we propose a dual-stream architecture that disentangles retrieval-augmented object generation from hierarchical environmental orchestration. Second, to ensure dynamic fidelity, we establish a physics-aware closed-loop mechanism in which a PostProcess Agent scripts dynamics, coupled with a VLM-Motion Critic that performs self-reflection to iteratively refine simulation code. Evaluations on the Code4D benchmark show Code2Worlds outperforms baselines with a 41% SGS gain and 49% higher Richness, while uniquely generating physics-aware dynamics absent in prior static methods. Code: https://github.com/AIGeeksGroup/Code2Worlds. Website: https://aigeeksgroup.github.io/Code2Worlds.

</details>


### [127] [Light4D: Training-Free Extreme Viewpoint 4D Video Relighting](https://arxiv.org/abs/2602.11769)
*Zhenghuang Wu,Kang Chen,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Light4D的无训练框架，用于在目标光照下生成一致的4D视频，即使在极端视角变化下也能保持时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的生成模型在4D重照明方面存在挑战，主要原因是缺乏配对的4D重照明训练数据以及难以在极端视角下保持时间一致性。

Method: Light4D框架包含两个关键组件：1. 解耦流引导（Disentangled Flow Guidance），一种时间感知策略，用于在保持几何完整性的同时将光照控制注入潜在空间；2. 时间一致性注意力（Temporal Consistent Attention），用于增强时间一致性，并结合确定性正则化以消除外观闪烁。

Result: Light4D在时间一致性和光照保真度方面取得了有竞争力的性能，并且能够稳健地处理从-90到90度的相机旋转。

Conclusion: Light4D成功地解决了4D重照明中的数据稀缺和时间一致性挑战，提供了一种强大的、无需训练的解决方案，能够生成高质量的4D重照明视频，即使在复杂的视角变化下也能保持一致性。

Abstract: Recent advances in diffusion-based generative models have established a new paradigm for image and video relighting. However, extending these capabilities to 4D relighting remains challenging, due primarily to the scarcity of paired 4D relighting training data and the difficulty of maintaining temporal consistency across extreme viewpoints. In this work, we propose Light4D, a novel training-free framework designed to synthesize consistent 4D videos under target illumination, even under extreme viewpoint changes. First, we introduce Disentangled Flow Guidance, a time-aware strategy that effectively injects lighting control into the latent space while preserving geometric integrity. Second, to reinforce temporal consistency, we develop Temporal Consistent Attention within the IC-Light architecture and further incorporate deterministic regularization to eliminate appearance flickering. Extensive experiments demonstrate that our method achieves competitive performance in temporal consistency and lighting fidelity, robustly handling camera rotations from -90 to 90. Code: https://github.com/AIGeeksGroup/Light4D. Website: https://aigeeksgroup.github.io/Light4D.

</details>


### [128] [How to Sample High Quality 3D Fractals for Action Recognition Pre-Training?](https://arxiv.org/abs/2602.11810)
*Marko Putak,Thomas B. Moeslund,Joakim Bruslund Haurum*

Main category: cs.CV

TL;DR: 研究提出了一种名为“目标智能过滤”（Targeted Smart Filtering）的新方法，用于生成用于动作识别模型预训练的3D分形视频。该方法显著提高了分形生成速度，并提升了下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的真实世界数据标注费时费力，且存在隐私和伦理问题。作者希望利用公式驱动的监督学习（FDSL）生成完美的合成数据，特别是利用3D分形来预训练动作识别模型，以克服真实数据标注的局限性。

Method: 研究首先尝试使用3D迭代函数系统（IFS）生成3D分形，并将其时间变换形成视频作为预训练数据集。由于标准的分形生成方法速度慢且易产生退化分形，研究系统地探索了替代方法，并提出了一种名为“目标智能过滤”（Targeted Smart Filtering）的新方法，以解决生成速度和分形多样性问题。

Result: 提出的“目标智能过滤”方法比其他3D分形过滤方法快约100倍，并取得了更优的下游动作识别任务性能。研究还发现，过于严格的分形生成方法虽然美观，但不利于下游任务表现。

Conclusion: 3D分形可以作为动作识别模型预训练的有价值的合成数据源。“目标智能过滤”是一种高效且有效的分形生成方法，能够生成多样化的分形，从而提升动作识别模型的预训练效果。

Abstract: Synthetic datasets are being recognized in the deep learning realm as a valuable alternative to exhaustively labeled real data. One such synthetic data generation method is Formula Driven Supervised Learning (FDSL), which can provide an infinite number of perfectly labeled data through a formula driven approach, such as fractals or contours. FDSL does not have common drawbacks like manual labor, privacy and other ethical concerns. In this work we generate 3D fractals using 3D Iterated Function Systems (IFS) for pre-training an action recognition model. The fractals are temporally transformed to form a video that is used as a pre-training dataset for downstream task of action recognition. We find that standard methods of generating fractals are slow and produce degenerate 3D fractals. Therefore, we systematically explore alternative ways of generating fractals and finds that overly-restrictive approaches, while generating aesthetically pleasing fractals, are detrimental for downstream task performance. We propose a novel method, Targeted Smart Filtering, to address both the generation speed and fractal diversity issue. The method reports roughly 100 times faster sampling speed and achieves superior downstream performance against other 3D fractal filtering methods.

</details>


### [129] [WorldTree: Towards 4D Dynamic Worlds from Monocular Video using Tree-Chains](https://arxiv.org/abs/2602.11845)
*Qisen Wang,Yifan Zhao,Jia Li*

Main category: cs.CV

TL;DR: 提出了一种名为WorldTree的统一动态重建框架，通过时间划分树（TPT）实现分层时间分解和粗粒度到细粒度的优化，并通过空间祖先链（SAC）提供补充空间动力学，从而解决单目输入在动态重建中的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前的单目动态重建方法缺乏统一的时空分解框架，要么进行整体时间优化，要么进行耦合的层级空间组合，这限制了其实际应用。研究旨在解决这一问题，提出一个更有效的统一框架。

Method: 提出WorldTree框架，包含两个核心组件：1. 时间划分树（TPT）：利用基于继承的划分树结构，实现分层时间分解和粗粒度到细粒度的优化。2. 空间祖先链（SAC）：递归查询祖先层级结构，提供补充的空间动力学，并在祖先节点间专业化运动表示。

Result: 在NVIDIA-LS数据集上，LPIPS指标提高了8.26%；在DyCheck数据集上，mLPIPS指标提高了9.09%，均优于次优方法。

Conclusion: WorldTree框架作为一个统一的时空分解模型，能够有效地提升单目动态重建的性能，通过其分层的时间优化和空间动态补充，显著优于现有方法。

Abstract: Dynamic reconstruction has achieved remarkable progress, but there remain challenges in monocular input for more practical applications. The prevailing works attempt to construct efficient motion representations, but lack a unified spatiotemporal decomposition framework, suffering from either holistic temporal optimization or coupled hierarchical spatial composition. To this end, we propose WorldTree, a unified framework comprising Temporal Partition Tree (TPT) that enables coarse-to-fine optimization based on the inheritance-based partition tree structure for hierarchical temporal decomposition, and Spatial Ancestral Chains (SAC) that recursively query ancestral hierarchical structure to provide complementary spatial dynamics while specializing motion representations across ancestral nodes. Experimental results on different datasets indicate that our proposed method achieves 8.26% improvement of LPIPS on NVIDIA-LS and 9.09% improvement of mLPIPS on DyCheck compared to the second-best method. Code: https://github.com/iCVTEAM/WorldTree.

</details>


### [130] [Free Lunch for Stabilizing Rectified Flow Inversion](https://arxiv.org/abs/2602.11850)
*Chenru Wang,Beier Zhu,Chi Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Proximal-Mean Inversion (PMI) 的无训练梯度校正方法，用于解决基于Rectified-Flow (RF) 的生成模型中存在的近似误差导致的速度场不稳定问题，并提出mimic-CFG用于图像编辑任务，在PIE-Bench上的实验证明了其稳定性和生成质量的提升，同时提高了效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于RF的生成模型在训练过程中，由于累积的近似误差，导致速度场不稳定，从而影响重建和编辑的质量。需要一种能够稳定速度场并提高下游任务性能的方法。

Method: 提出Proximal-Mean Inversion (PMI)，一种无训练的梯度校正方法，通过将速度场引导至过去速度的运行平均值，并受限于理论推导的球形高斯分布来稳定速度场。此外，提出mimic-CFG，一种轻量级的速度校正方案，通过插值当前速度与其在历史平均值上的投影来实现编辑任务，以平衡编辑效果和结构一致性。

Result: 在PIE-Bench上的广泛实验表明，PMI和mimic-CFG显著提高了反演的稳定性、图像重建质量和编辑保真度，同时减少了所需的神经函数评估次数，实现了最先进的性能，并提高了效率和理论上的健全性。

Conclusion: 所提出的PMI和mimic-CFG方法能够有效地解决RF生成模型中速度场不稳定的问题，显著提升了无训练反演、重建和编辑任务的性能，并在效率和理论依据方面都达到了最先进水平。

Abstract: Rectified-Flow (RF)-based generative models have recently emerged as strong alternatives to traditional diffusion models, demonstrating state-of-the-art performance across various tasks. By learning a continuous velocity field that transforms simple noise into complex data, RF-based models not only enable high-quality generation, but also support training-free inversion, which facilitates downstream tasks such as reconstruction and editing. However, existing inversion methods, such as vanilla RF-based inversion, suffer from approximation errors that accumulate across timesteps, leading to unstable velocity fields and degraded reconstruction and editing quality. To address this challenge, we propose Proximal-Mean Inversion (PMI), a training-free gradient correction method that stabilizes the velocity field by guiding it toward a running average of past velocities, constrained within a theoretically derived spherical Gaussian. Furthermore, we introduce mimic-CFG, a lightweight velocity correction scheme for editing tasks, which interpolates between the current velocity and its projection onto the historical average, balancing editing effectiveness and structural consistency. Extensive experiments on PIE-Bench demonstrate that our methods significantly improve inversion stability, image reconstruction quality, and editing fidelity, while reducing the required number of neural function evaluations. Our approach achieves state-of-the-art performance on the PIE-Bench with enhanced efficiency and theoretical soundness.

</details>


### [131] [SynthRAR: Ring Artifacts Reduction in CT with Unrolled Network and Synthetic Data Training](https://arxiv.org/abs/2602.11880)
*Hongxu Yang,Levente Lippenszky,Edina Timko,Gopal Avinash*

Main category: cs.CV

TL;DR: 提出了一种基于展开网络的环状伪影去除方法，该方法将非理想探测器响应与CT几何前向投影相结合，并利用合成数据进行训练，无需临床数据即可在各种扫描几何和解剖区域上获得优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: CT探测器缺陷导致环状和条状伪影，影响临床应用。现有的深度学习方法需要昂贵的专用数据集，并且仅限于图像域或投影域的校正，忽略了CT几何的固有相关性。

Method: 将环状伪影去除问题重新表述为一个逆问题，并利用展开网络。该网络考虑了非理想探测器响应和CT几何的线性前向投影。利用合成数据（从自然图像生成）来利用伪影在投影域和图像域之间的固有相关性，从而实现无监督的临床数据训练。

Result: 所提出的方法在合成数据上训练后，能够有效地去除各种扫描几何和解剖区域的环状伪影，并且在评估中一致优于现有的最先进方法。

Conclusion: 通过将非理想探测器响应与CT几何相结合，并利用合成数据进行训练，可以有效地去除CT图像中的环状伪影，而无需昂贵的临床数据集，并且能够实现优于现有方法的性能。

Abstract: Defective and inconsistent responses in CT detectors can cause ring and streak artifacts in the reconstructed images, making them unusable for clinical purposes. In recent years, several ring artifact reduction solutions have been proposed in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, leading to a high data collection cost. Furthermore, existing approaches focus exclusively on either image-space or sinogram-space correction, neglecting the intrinsic correlations from the forward operation of the CT geometry. Based on the theoretical analysis of non-ideal CT detector responses, the RAR problem is reformulated as an inverse problem by using an unrolled network, which considers non-ideal response together with linear forward-projection with CT geometry. Additionally, the intrinsic correlations of ring artifacts between the sinogram and image domains are leveraged through synthetic data derived from natural images, enabling the trained model to correct artifacts without requiring real-world clinical data. Extensive evaluations on diverse scanning geometries and anatomical regions demonstrate that the model trained on synthetic data consistently outperforms existing state-of-the-art methods.

</details>


### [132] [Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception](https://arxiv.org/abs/2602.11858)
*Lai Wei,Liangbo He,Jun Lan,Lingzhong Dong,Yutong Cai,Siyuan Li,Huijia Zhu,Weiqiang Wang,Linghe Kong,Yue Wang,Zhuosheng Zhang,Weiran Huang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为“区域到图像蒸馏”的方法，通过在训练阶段将区域注意力机制内化，显著提升了多模态大语言模型（MLLMs）在细粒度视觉理解方面的能力，同时避免了推理时反复调用工具和重新编码图像带来的延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的“图示思考”方法虽然能提升细粒度感知能力，但推理过程中的高延迟是其主要瓶颈。作者旨在找到一种方法，在不牺牲性能的前提下，解决这一延迟问题。

Method: 该方法首先利用教师模型对微小裁剪的区域进行“放大”，生成高质量的视觉问答（VQA）数据，然后将这种区域相关的监督信号“蒸馏”回完整的图像。通过在这样的数据集上训练，学生模型能够在单次前向传播中获得更好的细粒度感知能力，而无需进行推理时的“放大”操作。此外，研究者还提出了ZoomBench基准测试，用于评估细粒度感知能力，并引入了量化全局-区域“缩放差距”的双视图协议。

Result: 实验表明，所提出的模型在多个细粒度感知基准测试中取得了领先的性能，并在视觉推理和GUI代理等通用多模态认知任务上也有所提升。研究还讨论了何时需要“图示思考”，以及何时可以将这些收益蒸馏到单次前向传播中。

Conclusion: “区域到图像蒸馏”是一种有效的方法，可以将“图示思考”的优势内化到MLLMs中，从而在不增加推理延迟的情况下，显著提升其细粒度视觉理解能力，并对通用多模态能力产生积极影响。

Abstract: Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception, where decisive evidence is small and easily overwhelmed by global context. Recent "Thinking-with-Images" methods alleviate this by iteratively zooming in and out regions of interest during inference, but incur high latency due to repeated tool calls and visual re-encoding. To address this, we propose Region-to-Image Distillation, which transforms zooming from an inference-time tool into a training-time primitive, thereby internalizing the benefits of agentic zooming into a single forward pass of an MLLM. In particular, we first zoom in to micro-cropped regions to let strong teacher models generate high-quality VQA data, and then distill this region-grounded supervision back to the full image. After training on such data, the smaller student model improves "single-glance" fine-grained perception without tool use. To rigorously evaluate this capability, we further present ZoomBench, a hybrid-annotated benchmark of 845 VQA data spanning six fine-grained perceptual dimensions, together with a dual-view protocol that quantifies the global--regional "zooming gap". Experiments show that our models achieve leading performance across multiple fine-grained perception benchmarks, and also improve general multimodal cognition on benchmarks such as visual reasoning and GUI agents. We further discuss when "Thinking-with-Images" is necessary versus when its gains can be distilled into a single forward pass. Our code is available at https://github.com/inclusionAI/Zooming-without-Zooming.

</details>


### [133] [DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target](https://arxiv.org/abs/2602.11919)
*BoCheng Hu,Zhonghan Zhao,Kaiyue Zhou,Hongwei Wang,Gaoang Wang*

Main category: cs.CV

TL;DR: 本文提出了DynaHOI-Gym，一个用于动态手部-物体交互（HOI）的在线闭环平台，并发布了基于此平台的DynaHOI-10M大规模基准数据集。该平台和数据集旨在解决现有HOI基准集中对静态对象依赖的问题，并提供了一个新的基线模型ObAct。


<details>
  <summary>Details</summary>
Motivation: 现有手部-物体交互（HOI）的研究主要集中在静态对象上，缺乏对动态场景中移动目标和时间关键协调的研究。为了弥补这一差距，需要一个能够评估动态交互的平台和数据集。

Method: 开发了一个名为DynaHOI-Gym的统一在线闭环平台，该平台包含参数化运动生成器和基于滚动的评估指标。利用DynaHOI-Gym构建了一个包含1000万帧和18万条手部捕捉轨迹的DynaHOI-10M数据集，并将目标运动分为8个主要类别和22个细粒度子类别。提供了一个名为ObAct的基线模型，该模型通过时空注意力机制整合短期观察和当前帧来预测动作。

Result: DynaHOI-Gym和DynaHOI-10M数据集为评估动态HOI提供了新的研究平台。ObAct基线模型在位置成功率上取得了8.1%的提升。

Conclusion: DynaHOI-Gym平台和DynaHOI-10M数据集能够有效填补现有HOI研究在动态场景方面的空白，并为后续研究提供了有力的支持。提出的ObAct基线模型展示了结合短期观察和时空注意力在预测动态HOI动作方面的潜力。

Abstract: Most existing hand motion generation benchmarks for hand-object interaction (HOI) focus on static objects, leaving dynamic scenarios with moving targets and time-critical coordination largely untested. To address this gap, we introduce the DynaHOI-Gym, a unified online closed-loop platform with parameterized motion generators and rollout-based metrics for dynamic capture evaluation. Built on DynaHOI-Gym, we release DynaHOI-10M, a large-scale benchmark with 10M frames and 180K hand capture trajectories, whose target motions are organized into 8 major categories and 22 fine-grained subcategories. We also provide a simple observe-before-act baseline (ObAct) that integrates short-term observations with the current frame via spatiotemporal attention to predict actions, achieving an 8.1% improvement in location success rate.

</details>


### [134] [Synthesis of Late Gadolinium Enhancement Images via Implicit Neural Representations for Cardiac Scar Segmentation](https://arxiv.org/abs/2602.11942)
*Soufiane Ben Haddou,Laura Alvarez-Florez,Erik J. Bekkers,Fleur V. Y. Tjong,Ahmad S. Amin,Connie R. Bezzina,Ivana Išgum*

Main category: cs.CV

TL;DR: 该研究提出了一种结合隐式神经表示（INR）和去噪扩散模型的框架，用于合成心肌梗死后钆增强（LGE）图像及其分割掩码，以解决标注数据不足的问题。实验表明，使用合成数据增强训练集可以提高纤维化分割的Dice分数。


<details>
  <summary>Details</summary>
Motivation: 临床上用于心肌瘢痕评估的LGE成像，由于标注数据集有限，阻碍了自动化分割方法的发展。因此，需要一种方法来扩充数据集，缓解数据稀缺问题。

Method: 该方法首先训练INR来捕捉LGE数据及其心肌和纤维化分割掩码的连续空间表示。然后，将INR压缩到紧凑的潜在嵌入中。去噪扩散模型在该潜在空间上运行，生成新的表示，并将其解码为具有解剖学一致的分割掩码的合成LGE图像。

Result: 通过在133个心脏MRI扫描上进行实验，使用200个合成数据卷增强训练数据，可以将纤维化分割的Dice分数从0.509提高到0.524。

Conclusion: 所提出的框架提供了一种无需人工标注的方法来合成LGE图像和分割掩码，有助于缓解数据稀缺问题，并能提高分割性能。研究代码已公开。

Abstract: Late gadolinium enhancement (LGE) imaging is the clinical standard for myocardial scar assessment, but limited annotated datasets hinder the development of automated segmentation methods. We propose a novel framework that synthesises both LGE images and their corresponding segmentation masks using implicit neural representations (INRs) combined with denoising diffusion models. Our approach first trains INRs to capture continuous spatial representations of LGE data and associated myocardium and fibrosis masks. These INRs are then compressed into compact latent embeddings, preserving essential anatomical information. A diffusion model operates on this latent space to generate new representations, which are decoded into synthetic LGE images with anatomically consistent segmentation masks. Experiments on 133 cardiac MRI scans suggest that augmenting training data with 200 synthetic volumes contributes to improved fibrosis segmentation performance, with the Dice score showing an increase from 0.509 to 0.524. Our approach provides an annotation-free method to help mitigate data scarcity.The code for this research is publicly available.

</details>


### [135] [Benchmarking Vision-Language Models for French PDF-to-Markdown Conversion](https://arxiv.org/abs/2602.11960)
*Bruno Rigal,Victor Dupriez,Alexis Mignon,Ronan Le Hy,Nicolas Mery*

Main category: cs.CV

TL;DR: 本文评估了最新视觉语言模型（VLMs）在处理具有挑战性的法语文档的 PDF 到 Markdown 转换能力。研究提出了一个法语文档基准，并通过针对性的评估方法来衡量模型的鲁棒性，特别是区分了对下游任务有影响的错误和无关紧要的格式化差异。


<details>
  <summary>Details</summary>
Motivation: 现有的 PDF 解析基准主要关注英语和中文文档，且可能过度惩罚对下游检索任务影响不大的格式化选择。因此，需要一个专注于法语文档、更能反映实际应用需求的评估方法。

Method: 研究者构建了一个包含 60,000 份法语文档的基准，通过模型分歧采样选择了包含手写体、复杂布局、密集表格和富含图形的页面。评估方法结合了针对具体失效模式（文本存在、阅读顺序、表格约束）的单元测试式检查，以及旨在忽略格式差异的类别特定归一化。

Result: 在 15 个模型上进行的评估显示，最强的专有模型在处理手写体和表格方面表现出更高的鲁棒性。同时，一些开源模型在处理标准印刷布局方面仍具有竞争力。

Conclusion: 目前先进的 VLM 在处理法语 PDF 到 Markdown 转换方面存在显著差异，专有模型在处理复杂和手写内容方面表现更优。未来的研究需要继续改进模型在这些方面的能力，尤其是在开源模型领域。

Abstract: This report evaluates PDF-to-Markdown conversion using recent Vision-Language Models (VLMs) on challenging French documents. Document parsing is a critical step for Retrieval-Augmented Generation (RAG) pipelines, where transcription and layout errors propagate to downstream retrieval and grounding. Existing benchmarks often emphasize English or Chinese and can over-penalize benign formatting and linearization choices (e.g., line breaks, list segmentation, alternative table renderings) that are largely irrelevant for downstream use.
  We introduce a French-focused benchmark of difficult pages selected via model-disagreement sampling from a corpus of 60{,}000 documents, covering handwritten forms, complex layouts, dense tables, and graphics-rich pages. Evaluation is performed with unit-test-style checks that target concrete failure modes (text presence, reading order, and local table constraints) combined with category-specific normalization designed to discount presentation-only variance. Across 15 models, we observe substantially higher robustness for the strongest proprietary models on handwriting and forms, while several open-weights systems remain competitive on standard printed layouts.

</details>


### [136] [Calibrated Bayesian Deep Learning for Explainable Decision Support Systems Based on Medical Imaging](https://arxiv.org/abs/2602.11973)
*Hua Xu,Julián D. Arias-Londoño,Juan I. Godino-Llorente*

Main category: cs.CV

TL;DR: 该研究提出了一种基于贝叶斯深度学习的概率优化框架，通过新的CUB-Loss和DTS策略来提高AI在医学影像诊断中的可靠性和可信度，使其不确定性估计能更好地反映预测的正确性。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习模型在医学影像诊断中虽然准确率高，但常出现过度自信的错误预测，阻碍了其在临床上的接受度。因此，需要模型能可靠地量化不确定性，让医生识别不可靠的预测。

Method: 提出了一种基于贝叶斯深度学习的通用概率优化框架。具体来说，引入了新的CUB-Loss，它对高置信度的错误预测和低置信度的正确预测进行惩罚，以确保预测正确性与不确定性估计相匹配。此外，还设计了一种后验校准的DTS策略来进一步优化。

Result: 在肺炎筛查、糖尿病视网膜病变检测和皮肤病变识别三个不同的医学影像任务上进行了验证。实验结果表明，该方法在不同模态下都能持续改进校准，在数据稀疏和严重不平衡的数据集上也能保持稳健的性能。

Conclusion: 所提出的框架能够有效地提升AI在医学影像分析中的校准性能，使其不确定性估计与预测的正确性更加一致，这对于提高AI在临床决策支持系统中的可靠性和可接受性至关重要。

Abstract: In critical decision support systems based on medical imaging, the reliability of AI-assisted decision-making is as relevant as predictive accuracy. Although deep learning models have demonstrated significant accuracy, they frequently suffer from miscalibration, manifested as overconfidence in erroneous predictions. To facilitate clinical acceptance, it is imperative that models quantify uncertainty in a manner that correlates with prediction correctness, allowing clinicians to identify unreliable outputs for further review. In order to address this necessity, the present paper proposes a generalizable probabilistic optimization framework grounded in Bayesian deep learning. Specifically, a novel Confidence-Uncertainty Boundary Loss (CUB-Loss) is introduced that imposes penalties on high-certainty errors and low-certainty correct predictions, explicitly enforcing alignment between prediction correctness and uncertainty estimates. Complementing this training-time optimization, a Dual Temperature Scaling (DTS) strategy is devised for post-hoc calibration, further refining the posterior distribution to improve intuitive explainability. The proposed framework is validated on three distinct medical imaging tasks: automatic screening of pneumonia, diabetic retinopathy detection, and identification of skin lesions. Empirical results demonstrate that the proposed approach achieves consistent calibration improvements across diverse modalities, maintains robust performance in data-scarce scenarios, and remains effective on severely imbalanced datasets, underscoring its potential for real clinical deployment.

</details>


### [137] [Spatial Chain-of-Thought: Bridging Understanding and Generation Models for Spatial Reasoning Generation](https://arxiv.org/abs/2602.11980)
*Wei Chen,Yancheng Long,Mingqiao Liu,Haojie Ding,Yankai Yang,Hongyang Wei,Yi-Fan Zhang,Bin Wen,Fan Yang,Tingting Gao,Han Li,Long Chen*

Main category: cs.CV

TL;DR: 提出了一种名为Spatial Chain-of-Thought (SCoT)的框架，通过增强扩散模型的布局感知能力和利用多模态大语言模型（MLLMs）生成布局计划，来提升图像合成的复杂空间理解和推理能力，同时降低计算成本并避免空间信息丢失。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在复杂空间理解和推理方面存在不足，而使用MLLMs的现有方法要么计算成本高，要么在仅依赖文本提示时会丢失空间信息。

Method: SCoT框架首先通过交错的文本-坐标指令格式训练扩散模型，增强其布局感知能力；然后利用先进的MLLMs作为规划器，生成详细的布局计划，并将这些空间规划能力直接转移到生成过程中。

Result: SCoT框架在图像生成基准测试中达到了最先进的性能，并在复杂推理任务上显著优于基线方法，同时在图像编辑场景中也表现出强大的效果。

Conclusion: SCoT框架是一种即插即用的方法，能够有效地将MLLMs的推理能力与扩散模型的生成能力相结合，解决了现有方法的局限性，并在图像生成和编辑方面取得了显著进展。

Abstract: While diffusion models have shown exceptional capabilities in aesthetic image synthesis, they often struggle with complex spatial understanding and reasoning. Existing approaches resort to Multimodal Large Language Models (MLLMs) to enhance this capability. However, they either incur high computational costs through joint training or suffer from spatial information loss when relying solely on textual prompts. To alleviate these limitations, we propose a Spatial Chain-of-Thought (SCoT) framework, a plug-and-play approach that effectively bridges the reasoning capabilities of MLLMs with the generative power of diffusion models. Specifically, we first enhance the diffusion model's layout awareness by training it on an interleaved text-coordinate instruction format. We then leverage state-of-the-art MLLMs as planners to generate comprehensive layout plans, transferring their spatial planning capabilities directly to the generation process. Extensive experiments demonstrate that our method achieves state-of-the-art performance on image generation benchmarks and significantly outperforms baselines on complex reasoning tasks, while also showing strong efficacy in image editing scenarios.

</details>


### [138] [Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation](https://arxiv.org/abs/2602.12002)
*Enrico Guerriero,Kjersti Engan,Øyvind Meinich-Bache*

Main category: cs.CV

TL;DR: 本研究探索使用生成式AI（GenAI）方法（包括本地视觉-语言模型和大型语言模型）来改进新生儿复苏视频中的活动识别，并与监督式TimeSformer基线进行比较。结果显示，通过LoRA微调的VLMs在F1分数上显著优于TimeSformer。


<details>
  <summary>Details</summary>
Motivation: 在新生儿复苏过程中，准确的记录对于质量改进和遵守临床指南至关重要，但目前在实践中利用不足。虽然先前的3D-CNNs和ViT方法在检测关键活动方面取得了初步成果，但仍面临识别细粒度活动的挑战。

Method: 研究人员使用模拟的新生儿复苏视频数据集，评估了几种零样本VLM策略和带有分类头的微调VLM，包括LoRA。并将这些方法与监督式TimeSformer基线进行比较。

Result: 研究发现，小型（本地）VLMs存在幻觉问题，但通过LoRA进行微调后，VLMs达到了0.91的F1分数，显著优于TimeSformer的0.70。

Conclusion: 通过LoRA微调的本地视觉-语言模型可以有效克服小模型固有的问题，并在新生儿复苏视频的活动识别任务上取得比传统方法（如TimeSformer）更好的性能。

Abstract: Accurate documentation of newborn resuscitation is essential for quality improvement and adherence to clinical guidelines, yet remains underutilized in practice. Previous work using 3D-CNNs and Vision Transformers (ViT) has shown promising results in detecting key activities from newborn resuscitation videos, but also highlighted the challenges in recognizing such fine-grained activities. This work investigates the potential of generative AI (GenAI) methods to improve activity recognition from such videos. Specifically, we explore the use of local vision-language models (VLMs), combined with large language models (LLMs), and compare them to a supervised TimeSFormer baseline. Using a simulated dataset comprising 13.26 hours of newborn resuscitation videos, we evaluate several zero-shot VLM-based strategies and fine-tuned VLMs with classification heads, including Low-Rank Adaptation (LoRA). Our results suggest that small (local) VLMs struggle with hallucinations, but when fine-tuned with LoRA, the results reach F1 score at 0.91, surpassing the TimeSformer results of 0.70.

</details>


### [139] [Projected Representation Conditioning for High-fidelity Novel View Synthesis](https://arxiv.org/abs/2602.12003)
*Min-Seop Kwak,Minkyung Kwon,Jinhyeok Choi,Jiho Park,Seungryong Kim*

Main category: cs.CV

TL;DR: 本文提出了一种名为ReNoV的新型框架，该框架利用外部表示（如几何和语义信息）作为条件，通过改进的扩散模型进行新颖视图合成，实验证明该方法在重建保真度和图像修复方面表现优于现有技术，并能处理稀疏、未对齐的图像集合。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的新颖视图合成方法在处理几何一致性和稀疏、未对齐的图像集合时存在不足，作者希望通过引入外部表示来增强这些方面的性能。

Method: 本文首先分析了外部表示的空间注意力中的对应能力，然后设计了一种名为ReNoV（Representation-guided Novel View Synthesis）的框架。ReNoV通过专用的表示投影模块将外部表示注入到扩散过程中，以指导新颖视图的生成。

Result: 实验结果表明，ReNoV在重建保真度和修复质量方面取得了显著的改进，并且在新颖视图合成任务上优于现有的基于扩散的方法。此外，该方法能够从稀疏、未对齐的图像集合中进行鲁棒的合成。

Conclusion: 外部表示的几何和语义对应特性可以有效地指导扩散模型进行新颖视图合成，ReNoV框架通过有效利用这些特性，实现了更优异的新颖视图合成性能，尤其是在处理挑战性数据集时。

Abstract: We propose a novel framework for diffusion-based novel view synthesis in which we leverage external representations as conditions, harnessing their geometric and semantic correspondence properties for enhanced geometric consistency in generated novel viewpoints. First, we provide a detailed analysis exploring the correspondence capabilities emergent in the spatial attention of external visual representations. Building from these insights, we propose a representation-guided novel view synthesis through dedicated representation projection modules that inject external representations into the diffusion process, a methodology named ReNoV, short for representation-guided novel view synthesis. Our experiments show that this design yields marked improvements in both reconstruction fidelity and inpainting quality, outperforming prior diffusion-based novel-view methods on standard benchmarks and enabling robust synthesis from sparse, unposed image collections.

</details>


### [140] [A DMD-Based Adaptive Modulation Method for High Dynamic Range Imaging in High-Glare Environments](https://arxiv.org/abs/2602.12044)
*Banglei Guan,Jing Tao,Liang Xu,Dongcai Tan,Pengju Sun,Jianbing Liu,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 本文提出了一种基于数字微镜器件（DMD）的空间调制高动态范围（HDR）成像系统，该系统能够实现127 dB的动态范围，有效解决了在强光照条件下（如焊接弧监测和抛光金属表面分析）由于传感器饱和导致的图像细节丢失和测量误差问题，并显著提高了应变测量和DIC定位精度。


<details>
  <summary>Details</summary>
Motivation: 传统CCD/CMOS传感器在焊接弧监测和抛光金属表面分析等强光照条件下动态范围不足（低于70 dB），容易发生饱和，导致图像细节丢失，影响数字图像相关（DIC）等光力学测量的准确性。

Method: 构建了一个包含DMD光学调制单元和自适应计算成像管线的HDR成像系统。该系统利用DMD的空间调制能力，通过集成框架实现对高动态范围场景的自主区域分割和自适应曝光控制。

Result: 该系统实现了127 dB的可测量动态范围，成功消除了高眩光条件下的饱和伪影。实验结果表明，应变误差减少了78%，DIC定位精度得到提高，证明了系统在极端强度变化下的可靠性能。

Conclusion: 基于DMD的HDR成像系统能够提供高保真度的自适应HDR成像，克服了传统传感器的关键限制。该系统在高眩光环境下具有良好的应用潜力，可用于传统方法不足的光学计量和应力分析领域。

Abstract: Background The accuracy of photomechanics measurements critically relies on image quality,particularly under extreme illumination conditions such as welding arc monitoring and polished metallic surface analysis. High dynamic range (HDR) imaging above 120 dB is essential in these contexts. Conventional CCD/CMOS sensors, with dynamic ranges typically below 70 dB, are highly susceptible to saturation under glare, resulting in irreversible loss of detail and significant errors in digital image correlation (DIC). Methods This paper presents an HDR imaging system that leverages the spatial modulation capability of a digital micromirror device (DMD). The system architecture enables autonomous regional segmentation and adaptive exposure control for high-dynamic-range scenes through an integrated framework comprising two synergistic subsystems: a DMD-based optical modulation unit and an adaptive computational imaging pipeline. Results The system achieves a measurable dynamic range of 127 dB, effectively eliminating satu ration artifacts under high glare. Experimental results demonstrate a 78% reduction in strain error and improved DIC positioning accuracy, confirming reliable performance across extreme intensity variations. Conclusion The DMD-based system provides high fidelity adaptive HDR imaging, overcoming key limitations of conventional sensors. It exhibits strong potential for optical metrology and stress analysis in high-glare environments where traditional methods are inadequate.

</details>


### [141] [GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning](https://arxiv.org/abs/2602.12099)
*GigaBrain Team,Boyuan Wang,Chaojun Ni,Guan Huang,Guosheng Zhao,Hao Li,Jie Li,Jindi Lv,Jingyu Liu,Lv Feng,Mingming Yu,Peng Li,Qiuping Deng,Tianze Liu,Xinyu Zhou,Xinze Chen,Xiaofeng Wang,Yang Wang,Yifan Li,Yifei Nie,Yilong Li,Yukun Zhou,Yun Ye,Zhichao Liu,Zheng Zhu*

Main category: cs.CV

TL;DR: 提出了一种名为 GigaBrain-0.5M* 的视觉-语言-动作 (VLA) 模型，通过基于世界模型的强化学习进行训练，以克服现有 VLA 模型在场景理解和未来预测方面的局限性。该模型基于预训练的 GigaBrain-0.5，并结合了 RAMP 方法，在多项复杂任务中实现了显著的性能提升，并能在真实世界中可靠地执行长时序的复杂操作。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作 (VLA) 模型在处理多步动作时存在场景理解受限和未来预测能力弱的问题。而视频世界模型在海量视频数据上预训练后，展现出强大的时空推理和未来预测能力，是改进 VLA 学习的理想基础。

Method: 提出 GigaBrain-0.5M* 模型，该模型基于在 10,000+ 小时机器人操作数据上预训练的 GigaBrain-0.5。通过 RAMP (Reinforcement leArning via world Model-conditioned Policy) 方法，集成了基于世界模型的强化学习，以实现鲁棒的跨任务适应性。

Result: 与 RECAP 基线相比，RAMP 方法在 Laundry Folding、Box Packing 和 Espresso Preparation 等挑战性任务上取得了约 30% 的性能提升。GigaBrain-0.5M* 能够可靠地执行长时序操作，并在真实世界部署视频中验证了其在复杂操纵任务上的成功率。

Conclusion: 基于世界模型的强化学习（如 RAMP）能够显著提升 VLA 模型在复杂任务上的性能和长时序执行能力。GigaBrain-0.5M* 模型通过这种方法，在真实世界机器人操作中展现了可靠性和有效性。

Abstract: Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose \textit{GigaBrain-0.5M*}, a VLA model trained via world model-based reinforcement learning. Built upon \textit{GigaBrain-0.5}, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. \textit{GigaBrain-0.5M*} further integrates world model-based reinforcement learning via \textit{RAMP} (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that \textit{RAMP} achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\% on challenging tasks including \texttt{Laundry Folding}, \texttt{Box Packing}, and \texttt{Espresso Preparation}. Critically, \textit{GigaBrain-0.5M$^*$} exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our \href{https://gigabrain05m.github.io}{project page}.

</details>


### [142] [AssetFormer: Modular 3D Assets Generation with Autoregressive Transformer](https://arxiv.org/abs/2602.12100)
*Lingting Zhu,Shengju Qian,Haidi Fan,Jiayu Dong,Zhenchao Jin,Siwei Zhou,Gen Dong,Xin Wang,Lequan Yu*

Main category: cs.CV

TL;DR: AssetFormer是一个基于Transformer的自回归模型，可以将文本描述转换为模块化3D资产，适用于用户生成内容（UGC）和专业开发。


<details>
  <summary>Details</summary>
Motivation: 数字行业对高质量、多样化的模块化3D资产需求日益增长，尤其是在用户生成内容（UGC）领域。

Method: 作者提出了一种名为AssetFormer的自回归Transformer模型，该模型受到语言模型启发，采用模块化排序和解码技术，从文本描述生成模块化3D资产。

Result: 初步结果表明AssetFormer能够有效生成满足特定设计参数的模块化3D资产，提高了资产生成质量。

Conclusion: AssetFormer为3D内容生成领域提供了一个灵活的框架，能够简化专业开发和UGC场景下的资产创建流程，并且可以扩展到不同类型的模块化3D资产。

Abstract: The digital industry demands high-quality, diverse modular 3D assets, especially for user-generated content~(UGC). In this work, we introduce AssetFormer, an autoregressive Transformer-based model designed to generate modular 3D assets from textual descriptions. Our pilot study leverages real-world modular assets collected from online platforms. AssetFormer tackles the challenge of creating assets composed of primitives that adhere to constrained design parameters for various applications. By innovatively adapting module sequencing and decoding techniques inspired by language models, our approach enhances asset generation quality through autoregressive modeling. Initial results indicate the effectiveness of AssetFormer in streamlining asset creation for professional development and UGC scenarios. This work presents a flexible framework extendable to various types of modular 3D assets, contributing to the broader field of 3D content generation. The code is available at https://github.com/Advocate99/AssetFormer.

</details>


### [143] [PosterOmni: Generalized Artistic Poster Creation via Task Distillation and Unified Reward Feedback](https://arxiv.org/abs/2602.12127)
*Sixiang Chen,Jianyu Lai,Jialin Gao,Hengyu Shi,Zhongying Liu,Tian Ye,Junfeng Luo,Xiaoming Wei,Lei Zhu*

Main category: cs.CV

TL;DR: PosterOmni 是一个通用的艺术海报生成框架，通过数据蒸馏和奖励反馈机制，将局部编辑和全局创作两种模式整合到一个系统中，以解决图像到海报生成任务的挑战，并在局部实体保持和全局美学偏好方面取得了显著的提升。


<details>
  <summary>Details</summary>
Motivation: 图像到海报生成任务对模型提出了高要求，需要局部细节调整和全局设计理解，并且需要处理实体保持和概念创作的相互作用。现有方法难以同时满足这些多维度的需求。

Method: PosterOmni 框架通过一个高效的数据蒸馏奖励反馈流程来整合局部编辑和全局创作。具体包括：1. 构建涵盖实体和概念创作的六种任务类型的数据集；2. 通过知识蒸馏在局部和全局专家之间进行知识迁移，用于监督微调；3. 应用统一的 PosterOmni 奖励反馈机制，同时对视觉实体保持和所有任务的美学偏好进行对齐。此外，还建立了 PosterOmni-Bench 统一基准来评估。

Result: PosterOmni 显著提升了参考依从性、全局构图质量和美学和谐度，在所有开源基线模型之上，甚至超越了一些专有系统。

Conclusion: PosterOmni 是一个有效的通用框架，能够解锁基础编辑模型的潜力，实现多任务图像到海报生成，并在局部实体保持和全局美学偏好方面取得了显著的性能提升。

Abstract: Image-to-poster generation is a high-demand task requiring not only local adjustments but also high-level design understanding. Models must generate text, layout, style, and visual elements while preserving semantic fidelity and aesthetic coherence. The process spans two regimes: local editing, where ID-driven generation, rescaling, filling, and extending must preserve concrete visual entities; and global creation, where layout- and style-driven tasks rely on understanding abstract design concepts. These intertwined demands make image-to-poster a multi-dimensional process coupling entity-preserving editing with concept-driven creation under image-prompt control. To address these challenges, we propose PosterOmni, a generalized artistic poster creation framework that unlocks the potential of a base edit model for multi-task image-to-poster generation. PosterOmni integrates the two regimes, namely local editing and global creation, within a single system through an efficient data-distillation-reward pipeline: (i) constructing multi-scenario image-to-poster datasets covering six task types across entity-based and concept-based creation; (ii) distilling knowledge between local and global experts for supervised fine-tuning; and (iii) applying unified PosterOmni Reward Feedback to jointly align visual entity-preserving and aesthetic preference across all tasks. Additionally, we establish PosterOmni-Bench, a unified benchmark for evaluating both local editing and global creation. Extensive experiments show that PosterOmni significantly enhances reference adherence, global composition quality, and aesthetic harmony, outperforming all open-source baselines and even surpassing several proprietary systems.

</details>


### [144] [FAIL: Flow Matching Adversarial Imitation Learning for Image Generation](https://arxiv.org/abs/2602.12155)
*Yeyao Ma,Chen Li,Xiaosong Zhang,Han Hu,Weidi Xie*

Main category: cs.CV

TL;DR: 提出了一种名为FAIL（Flow Matching Adversarial Imitation Learning）的新型对抗性模仿学习方法，用于在没有显式奖励或偏好对的情况下，通过对抗训练来最小化策略与专家演示之间的差异，并在文本到图像生成任务上取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的模仿学习方法（如SFT）在处理未见状态下的策略漂移问题上存在局限性，而偏好优化方法又需要昂贵的偏好数据或奖励模型。作者希望开发一种更有效且数据需求更低的方法。

Method: 提出FAIL框架，利用流匹配模型（flow matching models）的后训练等价性，通过对抗训练来最小化策略与专家演示之间的散度。开发了两种算法：FAIL-PD利用可微分ODE求解器进行低方差梯度计算；FAIL-PG作为黑盒方法适用于离散或计算受限场景。

Result: 通过在Nano Banana pro的13,000个演示上微调FLUX，FAIL在提示跟随和美学基准测试上取得了有竞争力的性能。该框架还能泛化到离散图像和视频生成，并能作为正则化器缓解奖励模型中的奖励攻击问题。

Conclusion: FAIL是一种无需显式奖励或偏好对的有效模仿学习方法，通过对抗训练最小化策略-专家散度，并在多项生成任务上表现出竞争力，同时具有泛化性和作为正则化器的潜力。

Abstract: Post-training of flow matching models-aligning the output distribution with a high-quality target-is mathematically equivalent to imitation learning. While Supervised Fine-Tuning mimics expert demonstrations effectively, it cannot correct policy drift in unseen states. Preference optimization methods address this but require costly preference pairs or reward modeling. We propose Flow Matching Adversarial Imitation Learning (FAIL), which minimizes policy-expert divergence through adversarial training without explicit rewards or pairwise comparisons. We derive two algorithms: FAIL-PD exploits differentiable ODE solvers for low-variance pathwise gradients, while FAIL-PG provides a black-box alternative for discrete or computationally constrained settings. Fine-tuning FLUX with only 13,000 demonstrations from Nano Banana pro, FAIL achieves competitive performance on prompt following and aesthetic benchmarks. Furthermore, the framework generalizes effectively to discrete image and video generation, and functions as a robust regularizer to mitigate reward hacking in reward-based optimization. Code and data are available at https://github.com/HansPolo113/FAIL.

</details>


### [145] [TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation](https://arxiv.org/abs/2602.12157)
*Ziteng Lu,Yushuang Wu,Chongjie Ye,Yuda Qiu,Jing Shao,Xiaoyang Guo,Jiaqing Zhou,Tianlei Hu,Kun Zhou,Xiaoguang Han*

Main category: cs.CV

TL;DR: 本文提出了一种名为TexSpot的基于扩散的3D纹理增强框架，引入了一种新的Texlet表示方法，结合了基于点和基于UV纹理表示的优点，从而提高了3D纹理生成的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有主流的多视角扩散模型在生成高质量3D纹理时面临视图不一致的问题。UV贴图容易产生畸变，而基于点的表示则受几何密度限制，难以生成高分辨率纹理。研究旨在克服这些限制。

Method: 提出了一种名为Texlet的新型3D纹理表示，它使用2D编码器编码局部纹理块，并结合3D编码器聚合全局形状信息。然后，使用级联的3D到2D解码器重建纹理块，从而学习Texlet空间。在此基础上，训练一个条件于Texlets的扩散 Transformer来增强多视角扩散模型生成的纹理。

Result: TexSpot在视觉保真度、几何一致性和鲁棒性方面显著优于现有的3D纹理生成和增强方法。

Conclusion: TexSpot通过其创新的Texlet表示和扩散Transformer模型，成功解决了现有3D纹理生成方法中的视图不一致和分辨率限制问题，显著提升了3D纹理的生成质量。

Abstract: High-quality 3D texture generation remains a fundamental challenge due to the view-inconsistency inherent in current mainstream multi-view diffusion pipelines. Existing representations either rely on UV maps, which suffer from distortion during unwrapping, or point-based methods, which tightly couple texture fidelity to geometric density that limits high-resolution texture generation. To address these limitations, we introduce TexSpot, a diffusion-based texture enhancement framework. At its core is Texlet, a novel 3D texture representation that merges the geometric expressiveness of point-based 3D textures with the compactness of UV-based representation. Each Texlet latent vector encodes a local texture patch via a 2D encoder and is further aggregated using a 3D encoder to incorporate global shape context. A cascaded 3D-to-2D decoder reconstructs high-quality texture patches, enabling the Texlet space learning. Leveraging this representation, we train a diffusion transformer conditioned on Texlets to refine and enhance textures produced by multi-view diffusion methods. Extensive experiments demonstrate that TexSpot significantly improves visual fidelity, geometric consistency, and robustness over existing state-of-the-art 3D texture generation and enhancement approaches. Project page: https://anonymous.4open.science/w/TexSpot-page-2D91.

</details>


### [146] [DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation](https://arxiv.org/abs/2602.12160)
*Xu Guo,Fulong Ye,Qichao Sun,Liyang Chen,Bingchuan Li,Pengze Zhang,Jiawei Liu,Songtao Zhao,Qian He,Xiangwang Hou*

Main category: cs.CV

TL;DR: 本文提出了DreamID-Omni，一个统一的框架，用于可控的以人为中心的音频-视频生成，解决了现有方法将不同任务孤立处理以及多身份/音色控制困难的问题。通过对称条件扩散Transformer、双层解耦策略和多任务渐进式训练，实现了先进的性能，并在视频、音频和音频-视频一致性方面超越了领先的商业模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法将参考音频-视频生成、视频编辑和音频驱动视频动画等以人为中心的任务视为孤立目标，并且在单一框架内实现精确、解耦的多身份和音色控制仍然是一个挑战。

Method: 提出了DreamID-Omni统一框架。核心是设计的对称条件扩散Transformer，通过对称条件注入方案整合异构条件信号。为解决多人物场景下的身份-音色绑定失败和说话人混淆问题，引入了双层解耦策略：信号层同步RoPE保证注意力空间绑定，语义层结构化字幕建立显式属性-主体映射。此外，设计了多任务渐进式训练方案，利用弱约束生成先验正则化强约束任务，防止过拟合并协调不同目标。

Result: 实验证明，DreamID-Omni在视频、音频和音频-视频一致性方面取得了全面的最先进性能，甚至优于领先的专有商业模型。

Conclusion: DreamID-Omni成功地提供了一个统一的、可控的框架，用于以人为中心的音频-视频生成，有效解决了多任务孤立和身份-音色解耦的挑战，并在多个评估指标上展现出卓越的性能。

Abstract: Recent advancements in foundation models have revolutionized joint audio-video generation. However, existing approaches typically treat human-centric tasks including reference-based audio-video generation (R2AV), video editing (RV2AV) and audio-driven video animation (RA2V) as isolated objectives. Furthermore, achieving precise, disentangled control over multiple character identities and voice timbres within a single framework remains an open challenge. In this paper, we propose DreamID-Omni, a unified framework for controllable human-centric audio-video generation. Specifically, we design a Symmetric Conditional Diffusion Transformer that integrates heterogeneous conditioning signals via a symmetric conditional injection scheme. To resolve the pervasive identity-timbre binding failures and speaker confusion in multi-person scenarios, we introduce a Dual-Level Disentanglement strategy: Synchronized RoPE at the signal level to ensure rigid attention-space binding, and Structured Captions at the semantic level to establish explicit attribute-subject mappings. Furthermore, we devise a Multi-Task Progressive Training scheme that leverages weakly-constrained generative priors to regularize strongly-constrained tasks, preventing overfitting and harmonizing disparate objectives. Extensive experiments demonstrate that DreamID-Omni achieves comprehensive state-of-the-art performance across video, audio, and audio-visual consistency, even outperforming leading proprietary commercial models. We will release our code to bridge the gap between academic research and commercial-grade applications.

</details>


### [147] [EO-VAE: Towards A Multi-sensor Tokenizer for Earth Observation Data](https://arxiv.org/abs/2602.12177)
*Nils Lehmann,Yi Wang,Zhitong Xiong,Xiaoxiang Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种名为EO-VAE的多传感器变分自编码器，用于压缩和重建地球观测（EO）数据的多光谱通道，克服了现有方法为不同传感器训练独立分词器的局限性，并在TerraMesh数据集上展现了优于TerraMind分词器的重构保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型在处理RGB数据方面取得了成功，但地球观测（EO）数据因传感器规格多样和光谱通道变化等问题，难以应用现有分词器。需要一个能够处理灵活通道组合的通用EO数据分词器。

Method: 提出了一种名为EO-VAE的多传感器变分自编码器。该模型利用动态超网络（dynamic hypernetworks）来编码和重建灵活通道组合的EO数据，从而实现单一模型处理多种传感器和通道配置。

Result: 在TerraMesh数据集上的实验表明，EO-VAE在重构保真度方面优于TerraMind分词器，能够更有效地捕捉EO数据的特征。

Conclusion: EO-VAE是一种有效且通用的EO数据分词器，为遥感领域的潜在生成建模奠定了坚实的基础，并克服了现有方法在处理多传感器EO数据时的局限性。

Abstract: State-of-the-art generative image and video models rely heavily on tokenizers that compress high-dimensional inputs into more efficient latent representations. While this paradigm has revolutionized RGB generation, Earth observation (EO) data presents unique challenges due to diverse sensor specifications and variable spectral channels. We propose EO-VAE, a multi-sensor variational autoencoder designed to serve as a foundational tokenizer for the EO domain. Unlike prior approaches that train separate tokenizers for each modality, EO-VAE utilizes a single model to encode and reconstruct flexible channel combinations via dynamic hypernetworks. Our experiments on the TerraMesh dataset demonstrate that EO-VAE achieves superior reconstruction fidelity compared to the TerraMind tokenizers, establishing a robust baseline for latent generative modeling in remote sensing.

</details>


### [148] [DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing](https://arxiv.org/abs/2602.12205)
*Dianyi Wang,Ruihang Li,Feng Han,Chaofan Ma,Wei Song,Siyuan Wang,Yibin Wang,Yi Xin,Hongjian Liu,Zhixiong Zhang,Shengyuan Ding,Tianhang Wang,Zhenglin Cheng,Tao Lin,Cheng Jin,Kaicheng Yu,Jingjing Chen,Wenjie Wang,Zhongyu Wei,Jiaqi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 DeepGen 1.0 的轻量级 50 亿参数统一多模态模型，通过引入堆叠通道桥接（SCB）和数据中心的三阶段训练策略，实现了与更大模型相当甚至更优的图像生成和编辑能力，并且开源了相关资源以推动多模态研究的普及。


<details>
  <summary>Details</summary>
Motivation: 现有的统一多模态模型通常参数量巨大，训练成本和部署开销高昂，限制了其广泛应用。研究者希望开发一个轻量级但功能强大的模型。

Method: 1. 提出堆叠通道桥接（SCB）框架，通过融合多层视觉语言模型（VLM）的层级特征和可学习的“思考令牌”来增强生成模型的语义理解和精细控制能力。 2. 设计了数据中心的三阶段训练策略：对齐预训练（图像-文本对和编辑三元组）、联合监督微调（生成、编辑、推理任务混合）和基于 MR-GRPO 的强化学习（结合奖励函数和监督信号）。

Result: DeepGen 1.0 在图像生成和编辑任务上取得了领先的性能，在 WISE 评估中超越了参数量大 16 倍的 HunyuanImage 模型 28%，在 UniREditBench 评估中超越了参数量大 5 倍的 Qwen-Image-Edit 模型 37%。

Conclusion: DeepGen 1.0 证明了通过有效的模型架构设计（SCB）和数据驱动的训练策略，可以在显著减小模型规模的同时实现强大的统一多模态能力。研究者通过开源代码、权重和数据集，为多模态研究提供了高效且高性能的替代方案，促进了该领域的民主化。

Abstract: Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.

</details>


### [149] [Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching](https://arxiv.org/abs/2602.12221)
*Onkar Susladkar,Tushar Prakash,Gayatri Deshmukh,Kiet A. Nguyen,Jiaxun Zhang,Adheesh Juvekar,Tianshu Bao,Lin Chai,Sparsh Mittal,Inderjit S Dhillon,Ismini Lourentzou*

Main category: cs.CV

TL;DR: UniDFlow 是一个统一的离散流匹配框架，通过低秩适配器解耦理解和生成，并采用基于参考的偏好对齐来优化生成结果，在多个基准测试中达到 SOTA 性能，并展现出强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态理解、生成和编辑任务中存在目标干扰和表示纠缠的问题。研究者希望提出一个统一的框架，能够有效解耦这些任务，并提高生成结果的忠实度和可控性。

Method: 该框架采用离散流匹配，并引入了任务特定的低秩适配器来解耦理解和生成。此外，还提出了一种新颖的基于参考的多模态偏好对齐方法，以优化相同条件下的相对结果。

Result: UniDFlow 在八个基准测试中取得了 SOTA 性能。它还展现了强大的零样本泛化能力，能够处理修复、上下文图像生成、基于参考的编辑和组合生成等任务，而无需进行显式的任务特定训练。

Conclusion: UniDFlow 是一个有效的统一多模态理解、生成和编辑框架。通过解耦任务和引入偏好对齐，该方法能够显著提升性能和泛化能力，并减少对大量任务特定训练数据的依赖。

Abstract: We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding, generation, and editing. It decouples understanding and generation via task-specific low-rank adapters, avoiding objective interference and representation entanglement, while a novel reference-based multimodal preference alignment optimizes relative outcomes under identical conditioning, improving faithfulness and controllability without large-scale retraining. UniDFlpw achieves SOTA performance across eight benchmarks and exhibits strong zero-shot generalization to tasks including inpainting, in-context image generation, reference-based editing, and compositional generation, despite no explicit task-specific training.

</details>


### [150] [MonarchRT: Efficient Attention for Real-Time Video Generation](https://arxiv.org/abs/2602.12271)
*Krish Agarwal,Zhuoming Chen,Cheng Luo,Yongqi Chen,Haizhong Zheng,Xun Huang,Atri Rudra,Beidi Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Monarch-RT 的新颖结构化注意力参数化方法，用于解决实时视频生成扩散模型中的二次计算成本问题。通过使用 Monarch 矩阵分解注意力，并结合优化的 Triton 核函数，Monarch-RT 在保持高表达力的同时实现了计算效率，并在实时视频生成方面取得了显著的速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散 Transformer 模型在实时视频生成时，由于 3D 自注意力计算成本的二次增长而受到瓶颈。现有的稀疏注意力方法在该场景下表现不佳，作者发现视频注意力并非总是稀疏，而是结合了时空位置驱动的周期性结构、动态的语义对应以及密集的混合信息，这超出了现有方法的表示能力。

Method: 提出 Monarch-RT，一种基于 Monarch 矩阵分解注意力（一种结构化注意力参数化方法）的视频扩散模型。通过合适的块结构和扩展的平铺 Monarch 参数化来实现高表达力和计算效率。此外，通过微调和定制的 Triton 核函数来克服参数化带来的开销。。

Result: Monarch-RT 在视频扩散模型上表现出比现有稀疏注意力方法更高的效率。当应用于 SOTA 模型 Self-Forcing 时，Monarch-RT 可实现高达 95% 的注意力稀疏度且不损失质量。其优化的实现比 FlashAttention 系列核函数更快，在 RTX 5090、H100 和 B200 GPU 上分别实现了 1.4-11.8 倍的核加速。这使得在单块 RTX 5090 GPU 上实现了 16 FPS 的实时视频生成。

Conclusion: Monarch-RT 是一种高效且高表达力的稀疏注意力参数化方法，能够解决实时视频生成扩散 Transformer 中的计算瓶颈。该方法在保持生成质量的同时，显著提升了计算速度，并首次实现了在消费级硬件上进行真正的实时视频生成。

Abstract: Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more information. In this setting, we find that prior sparse-attention approximations break down, despite showing strong results for bidirectional, many-step diffusion. Specifically, we observe that video attention is not reliably sparse, but instead combines pronounced periodic structure driven by spatiotemporal position with dynamic, sparse semantic correspondences and dense mixing, exceeding the representational capacity of even oracle top-k attention. Building on this insight, we propose Monarch-RT, a structured attention parameterization for video diffusion models that factorizes attention using Monarch matrices. Through appropriately aligned block structure and our extended tiled Monarch parameterization, we achieve high expressivity while preserving computational efficiency. We further overcome the overhead of parameterization through finetuning, with custom Triton kernels. We first validate the high efficacy of Monarch-RT over existing sparse baselines designed only for bidirectional models. We further observe that Monarch-RT attains up to 95% attention sparsity with no loss in quality when applied to the state-of-the-art model Self-Forcing, making Monarch-RT a pioneering work on highly-capable sparse attention parameterization for real-time video generation. Our optimized implementation outperforms FlashAttention-2, FlashAttention-3, and FlashAttention-4 kernels on Nvidia RTX 5090, H100, and B200 GPUs respectively, providing kernel speedups in the range of 1.4-11.8X. This enables us, for the first time, to achieve true real-time video generation with Self-Forcing at 16 FPS on a single RTX 5090.

</details>


### [151] [UniT: Unified Multimodal Chain-of-Thought Test-time Scaling](https://arxiv.org/abs/2602.12279)
*Leon Liangyu Chen,Haoyu Ma,Zhipeng Fan,Ziqi Huang,Animesh Sinha,Xiaoliang Dai,Jialiang Wang,Zecheng He,Jianwei Yang,Chunyuan Li,Junzhe Sun,Chu Wang,Serena Yeung-Levy,Felix Juefei-Xu*

Main category: cs.CV

TL;DR: 本文提出了UniT框架，一种用于统一多模态模型的链式思考测试时扩展（TTS）方法，通过迭代推理、验证和修正来提高模型的理解和生成能力，尤其适用于复杂的多模态任务。


<details>
  <summary>Details</summary>
Motivation: 现有的统一多模态模型通常是单次推理，难以处理需要复杂空间推理、多对象交互或动态指令的多模态任务。现有研究表明测试时扩展（TTS）能提升语言模型性能，但将其应用于统一多模态模型仍是挑战。

Method: UniT框架结合了主体数据合成、统一模型训练和灵活的测试时推理。它通过生成和编辑链式思考轨迹来训练模型，使其能够进行验证、子目标分解和内容记忆等认知行为。

Result: 1. 在短推理轨迹上训练的统一模型能够泛化到测试时的长推理链。2. 顺序链式思考推理比并行采样提供了更具可扩展性和计算效率的TTS策略。3. 在生成和编辑轨迹上训练的模型能提升处理分布外视觉推理的能力。

Conclusion: 多模态测试时扩展是提升统一模型生成和理解能力的有效范式，UniT框架成功实现了统一多模态模型的迭代推理和修正能力。

Abstract: Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.

</details>


### [152] [Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching](https://arxiv.org/abs/2602.12280)
*Huai-Hsun Cheng,Siang-Ling Zhang,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为“渐进式语义幻觉”（Progressive Semantic Illusions）的新型向量素描任务，通过逐步添加笔画实现单个素描的语义转变，并提出了名为“Stroke of Surprise”的生成框架，利用双分支SDS和Overlay Loss解决“双重约束”问题，成功将视觉字谜从空间维度扩展到时间维度。


<details>
  <summary>Details</summary>
Motivation: 传统视觉错觉依赖于空间操纵，作者希望探索一种在时间维度上实现语义转变的视觉错觉，即通过笔画的连续添加，使同一幅素描在不同阶段呈现出不同的语义概念。

Method: 作者提出了“Stroke of Surprise”生成框架，该框架通过序列感知的联合优化框架驱动，并采用双分支Score Distillation Sampling (SDS)机制。核心在于解决“双重约束”问题：初始笔画（前缀）需要构成一个完整的对象，同时又要为后续添加的笔画（增量）形成第二种语义概念的结构基础。此外，还引入了新的Overlay Loss来强制空间互补性，确保结构集成而非遮挡。

Result: 实验结果表明，该方法在可识别性和幻觉强度方面显著优于现有技术，成功地将视觉字谜从空间维度扩展到了时间维度。

Conclusion: Stroke of Surprise 成功实现了渐进式语义幻觉，证明了通过序列笔画添加可以动态地改变单个素描的语义，为视觉错觉的研究开辟了新的方向。

Abstract: Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the "dual-constraint": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a "common structural subspace" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [153] [HybridRAG: A Practical LLM-based ChatBot Framework based on Pre-Generated Q&A over Raw Unstructured Documents](https://arxiv.org/abs/2602.11156)
*Sungmoon Kim,Hyuna Jeon,Dahye Kim,Mingyu Kim,Dong-Kyu Chae,Jiwoong Kim*

Main category: cs.CL

TL;DR: HybridRAG 是一种新的 RAG 框架，通过预生成问答知识库来提高聊天机器人响应的准确性和速度，特别适用于处理非结构化 PDF 文档，并在 OHRBench 实验中取得了优于标准 RAG 的结果。


<details>
  <summary>Details</summary>
Motivation: 现有 RAG 方法通常假设结构化文本源，并且在查询时进行检索和生成，这限制了它们在真实聊天机器人场景中的应用。作者希望开发一种更实用、更准确、更快速的 RAG 框架，以处理非结构化文档。

Method: 1. 通过 OCR 和布局分析处理原始的、非结构化的 PDF 文档，并将其转换为分层的文本块。 2. 使用 LLM 从组织好的文本块中预生成一个问答（QA）知识库。 3. 在查询时，首先将用户问题与 QA 知识库匹配以检索即时答案，如果找不到合适的 QA 匹配，则回退到即时响应生成。

Result: 在 OHRBench 上的实验表明，HybridRAG 提供了比标准 RAG 基线更高的答案质量和更低的延迟。

Conclusion: HybridRAG 是一种实用的 RAG 解决方案，适用于需要在有限计算资源下处理大量非结构化文档和大量用户的真实聊天机器人应用。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for grounding Large Language Model (LLM)-based chatbot responses on external knowledge. However, existing RAG studies typically assume well-structured textual sources (e.g. Wikipedia or curated datasets) and perform retrieval and generation at query time, which can limit their applicability in real-world chatbot scenarios. In this paper, we present HybridRAG, a novel and practical RAG framework towards more accurate and faster chatbot responses. First, HybridRAG ingests raw, unstructured PDF documents containing complex layouts (text, tables, figures) via Optical Character Recognition (OCR) and layout analysis, and convert them into hierarchical text chunks. Then, it pre-generates a plausible question-answer (QA) knowledge base from the organized chunks using an LLM. At query time, user questions are matched against this QA bank to retrieve immediate answers when possible, and only if no suitable QA match is found does our framework fall back to an on-the-fly response generation. Experiments on OHRBench demonstrate that our HybridRAG provides higher answer quality and lower latency compared to a standard RAG baseline. We believe that HybridRAG could be a practical solution for real-world chatbot applications that must handle large volumes of unstructured documents and lots of users under limited computational resources.

</details>


### [154] [Response-Based Knowledge Distillation for Multilingual Jailbreak Prevention Unwittingly Compromises Safety](https://arxiv.org/abs/2602.11157)
*Max Zhang,Derek Liu,Kai Zhang,Joshua Franco,Haihao Liu*

Main category: cs.CL

TL;DR: 研究提出了一种新颖的知识蒸馏（KD）方法，用于多语言大语言模型的安全对齐，以预防越狱。实验发现在标准蒸馏过程中，安全拒绝数据的引入反而增加了越狱成功率（JSR），且对不同模型泛化效果不一。通过移除“边界”拒绝信息，可以缓解安全下降问题，但推理能力有所牺牲。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLMs）的安全对齐主要集中在英语，导致低资源语言的安全性存在漏洞。因此，研究的动机是探索一种有效的方法来提升多语言LLMs的安全性，特别是在低资源语言环境中。

Method: 采用知识蒸馏（KD）技术，将一个专有的教师模型（OpenAI o1-mini）的安全拒绝行为，通过低秩适配（LoRA）这种参数高效微调（PEFT）方法，蒸馏到三个开源的学生模型（Meta-Llama-3-8B-Instruct, Gemma-2-2B-IT, Qwen3-8B）上。使用了约28,000个来自XSafety的多语言越狱提示，并基于黑盒响应进行微调。

Result: 标准的知识蒸馏（将安全拒绝数据蒸馏到学生模型）反而导致所有学生模型的越狱成功率（JSR）显著增加（最高达16.6个百分点）。这种效果在不同基础模型上的泛化能力存在差异。通过移除“边界”拒绝（一种导致安全退化的主要来源），可以减轻甚至逆转学生模型的安全下降问题。然而，推理性能（在GSM8K上评估）有所下降。

Conclusion: 知识蒸馏在多语言安全对齐方面面临挑战，但也存在潜力。标准安全数据蒸馏可能适得其反，需要更精细化的处理方法，例如移除“边界”拒绝信息，以达到更好的安全对齐效果。未来的研究应在此方向上继续探索。

Abstract: Large language models (LLMs) are increasingly deployed worldwide, yet their safety alignment remains predominantly English-centric. This allows for vulnerabilities in non-English contexts, especially with low-resource languages. We introduce a novel application of knowledge distillation (KD) in the context of multilingual jailbreak prevention, examining its efficacy. We distill the refusal behaviors of a proprietary teacher model (OpenAI o1-mini) with Low-Rank Adaptation (LoRA) into three open-source student models: Meta-Llama-3-8B-Instruct, Gemma-2-2B-IT, and Qwen3-8B, using ~28,000 multilingual jailbreak prompts from XSafety via black-box response-based, parameter-efficient fine-tuning (PEFT). Evaluation on the MultiJail benchmark reveals a counterintuitive behavior: standard fine-tuning on the teacher's ``safe'' refusal data inadvertently increases Jailbreak Success Rate (JSR) for all student models, up to 16.6 percentage points. Our experiments reveal a divergent generalization to unseen languages during distillation, with varying outcomes depending on the base model. By removing a primary source of safety degradation, nuanced `boundary' refusals, we mitigate or even reverse safety declines in student models, although reductions in reasoning performance (GSM8K) persist. Overall, our exploratory study highlights the challenges and potential of KD as a technique for multilingual safety alignment, offering a foundation for future research in this direction.

</details>


### [155] [Retrieval Heads are Dynamic](https://arxiv.org/abs/2602.11162)
*Yuping Lin,Zitao Li,Yue Xing,Pengfei He,Yingqian Cui,Yaliang Li,Bolin Ding,Jingren Zhou,Jiliang Tang*

Main category: cs.CL

TL;DR: 本研究从动态视角探讨了大型语言模型（LLMs）中的“检索头”，发现其检索行为随时间步动态变化且不可替代，模型内部隐藏状态能预测未来的检索头模式，揭示了LLMs的内部规划机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖静态统计分析来识别LLMs中的检索头，这种方法忽略了自回归生成过程中的细粒度时间动态，限制了对检索头功能的深入理解。

Method: 通过对LLMs的检索头进行动态分析，提出并验证了三个核心论点：动态性（检索头随时间步变化）、不可替代性（动态检索头在每个时间步是特定的且无法被静态检索头有效替代）、相关性（模型隐藏状态包含预测未来检索头模式的信号）。通过在“Needle-in-a-Haystack”任务和多跳问答任务上进行验证，并在动态检索增强生成（Dynamic Retrieval-Augmented Generation）框架下量化了动态和静态检索头的效用差异。

Result: 研究发现，LLMs中的检索头在不同时间步表现出动态变化，且这种动态性对于有效检索至关重要，无法被静态模型替代。此外，模型的隐藏状态能够预测未来的检索头行为模式。

Conclusion: 本研究通过动态分析，揭示了LLMs中检索头的动态特性、不可替代性以及与隐藏状态的预测关联，为理解LLMs的内部机制提供了新的视角，并强调了在模型设计和分析中考虑动态行为的重要性。

Abstract: Recent studies have identified "retrieval heads" in Large Language Models (LLMs) responsible for extracting information from input contexts. However, prior works largely rely on static statistics aggregated across datasets, identifying heads that perform retrieval on average. This perspective overlooks the fine-grained temporal dynamics of autoregressive generation. In this paper, we investigate retrieval heads from a dynamic perspective. Through extensive analysis, we establish three core claims: (1) Dynamism: Retrieval heads vary dynamically across timesteps; (2) Irreplaceability: Dynamic retrieval heads are specific at each timestep and cannot be effectively replaced by static retrieval heads; and (3) Correlation: The model's hidden state encodes a predictive signal for future retrieval head patterns, indicating an internal planning mechanism. We validate these findings on the Needle-in-a-Haystack task and a multi-hop QA task, and quantify the differences on the utility of dynamic and static retrieval heads in a Dynamic Retrieval-Augmented Generation framework. Our study provides new insights into the internal mechanisms of LLMs.

</details>


### [156] [Nested Named Entity Recognition in Plasma Physics Research Articles](https://arxiv.org/abs/2602.11163)
*Muhammad Haris,Hans Höft,Markus M. Becker,Markus Stocker*

Main category: cs.CL

TL;DR: 提出了一种基于编码器-Transformer和条件随机场（CRF）的轻量级方法，用于从等离子体物理学研究文章中提取（嵌套的）命名实体。


<details>
  <summary>Details</summary>
Motivation: 旨在解决从等离子体物理学等专业领域科学文本中提取专用实体的挑战，以支持高级搜索和文献分析。

Method: 1. 注释了一个包含16个针对嵌套NER任务的类的等离子体物理学语料库。2. 评估了一种实体特定模型专业化方法，训练独立的BERT-CRF模型来识别不同实体类型。3. 集成了一个超参数优化过程来微调模型性能。

Result: 所提出的方法能够有效地从等离子体物理学研究文章中提取（嵌套的）命名实体，并且通过模型专业化和超参数优化进一步提升了性能。

Conclusion: 该工作推进了等离子体物理学领域的实体识别技术，并为研究人员导航和分析科学文献提供了基础支持。

Abstract: Named Entity Recognition (NER) is an important task in natural language processing that aims to identify and extract key entities from unstructured text. We present a novel application of NER in plasma physics research articles and address the challenges of extracting specialized entities from scientific text in this domain. Research articles in plasma physics often contain highly complex and context-rich content that must be extracted to enable, e.g., advanced search. We propose a lightweight approach based on encoder-transformers and conditional random fields to extract (nested) named entities from plasma physics research articles. First, we annotate a plasma physics corpus with 16 classes specifically designed for the nested NER task. Second, we evaluate an entity-specific model specialization approach, where independent BERT-CRF models are trained to recognize individual entity types in plasma physics text. Third, we integrate an optimization process to systematically fine-tune hyperparameters and enhance model performance. Our work contributes to the advancement of entity recognition in plasma physics and also provides a foundation to support researchers in navigating and analyzing scientific literature.

</details>


### [157] [Assessing LLM Reliability on Temporally Recent Open-Domain Questions](https://arxiv.org/abs/2602.11165)
*Pushwitha Krishnappa,Amit Das,Vinija Jain,Tathagata Mukherjee,Aman Chadha*

Main category: cs.CL

TL;DR: 本研究提出了一个包含15,000个近期Reddit问题及其答案的数据集RECOM，用于评估大型语言模型（LLMs）对最新信息的理解能力。研究发现，LLMs在回答问题时能够通过大量意译而非直接词汇匹配来保持语义一致性，并且模型规模并非性能的决定性因素。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理时效性信息和与人类视角保持一致性方面仍有待深入研究，尤其是在开放域问答场景下。

Method: 构建了一个名为RECOM的数据集，包含15,000个2025年9月左右的Reddit问题及其社区参考答案。使用BLEU、ROUGE、BERTScore、MoverScore、余弦相似度以及自然语言推断（NLI）等多种指标，评估了Llama3.1-8B、Mistral-7B、Gemma-2-9B和GPT-OSS-20B四种开源LLMs的表现。

Result: 研究发现，所有模型在余弦相似度上均超过99%，但BLEU-1得分低于8%，表明模型主要通过意译来保留语义。MoverScore（51-53%）也印证了这一模式。值得注意的是，模型规模与性能并不直接相关，Mistral-7B（7B参数）在各项指标上均优于GPT-OSS-20B（20B参数）。NLI分析显示，模型产生矛盾内容的比例低于7%。

Conclusion: 这项研究揭示了lexical（词汇）指标在评估生成式模型方面的局限性，并强调了开发能够超越表面文本匹配、捕捉语义保真度的多维度评估框架的重要性。LLMs能够有效保留近期信息中的语义，但这种保留是通过大量的释义而非词汇重复实现的。

Abstract: Large Language Models (LLMs) are increasingly deployed for open-domain question answering, yet their alignment with human perspectives on temporally recent information remains underexplored. We introduce RECOM (Reddit Evaluation for Correspondence of Models), a benchmark dataset of 15,000 recent Reddit questions from September 2025 paired with community-derived reference answers. We investigate how four open-source LLMs (Llama3.1-8B, Mistral-7B, Gemma-2-9B, and GPT-OSS-20B) respond to these questions, evaluating alignment using lexical metrics (BLEU, ROUGE), semantic similarity (BERTScore, MoverScore, cosine similarity), and logical inference (NLI). Our central finding is a striking semantic-lexical paradox: all models achieve over 99% cosine similarity with references despite less than 8% BLEU-1 overlap, a 90+ percentage point gap indicating that models preserve meaning through extensive paraphrasing rather than lexical reproduction. MoverScore (51-53%) confirms this pattern, occupying an intermediate position that reflects the optimal transport cost of semantic alignment. Furthermore, model scale does not predict performance: Mistral-7B (7B parameters) outperforms GPT-OSS-20B (20B parameters) across all metrics. NLI analysis reveals that contradiction rates remain below 7%, suggesting models rarely generate content that directly conflicts with human consensus. These findings challenge the reliability of lexical metrics for evaluating abstractive generation and argue for multi-dimensional evaluation frameworks that capture semantic fidelity beyond surface-level text matching. The RECOM dataset is publicly available at https://anonymous.4open.science/r/recom-D4B0

</details>


### [158] [Small Updates, Big Doubts: Does Parameter-Efficient Fine-tuning Enhance Hallucination Detection ?](https://arxiv.org/abs/2602.11166)
*Xu Hu,Yifan Zhang,Songtao Wei,Chen Zhao,Qiannan Li,Bingzhe Li,Feng Chen*

Main category: cs.CL

TL;DR: 研究表明，参数高效微调 (PEFT) 方法能够提高大型语言模型 (LLM) 在事实问答任务上的幻觉检测能力，主要通过重塑模型不确定性的编码和表达方式，而非注入新知识。


<details>
  <summary>Details</summary>
Motivation: 现有研究对参数高效微调 (PEFT) 方法如何影响大型语言模型 (LLM) 的幻觉行为，尤其是在问答数据集上的影响，理解不足。

Method: 通过对三个开源 LLM 模型和三个事实问答基准进行系统的实证研究，评估了七种无监督幻觉检测方法（包括语义一致性、置信度和熵检测）在 PEFT 前后的性能表现。此外，还使用了线性探针和表示诊断等方法来分析 PEFT 的影响机制。

Result: 实验结果显示，PEFT 能够一致地增强幻觉检测能力，显著提高 AUROC 分数。进一步的分析表明，PEFT 主要通过重塑不确定性的编码和表达方式来影响幻觉检测，而不是注入新的事实知识。

Conclusion: PEFT 方法能够有效提升 LLM 在事实问答任务上的幻觉检测能力，其机制在于改变模型内部不确定性的表示方式。

Abstract: Parameter-efficient fine-tuning (PEFT) methods are widely used to adapt large language models (LLMs) to downstream tasks and are often assumed to improve factual correctness. However, how the parameter-efficient fine-tuning methods affect hallucination behavior remains insufficiently understood, especially on QA datasets. In this work, we systematically investigate the impact of PEFT on hallucination detection through a comprehensive empirical study across three open-weight LLM backbones and three fact-seeking QA benchmarks. For each model, we evaluate performance using seven unsupervised hallucination detection methods spanning three complementary approaches: semantic consistency based detectors, confidence based detectors, and entropy based detectors. This multifaceted evaluation enables us to characterize how PEFT reshapes uncertainty across different detection paradigms. In conclusion, our experimental results show that PEFT consistently strengthens hallucination detection ability, substantially improving AUROC across a wide range of hallucination detectors. Besides, further analyses using linear probes and representation diagnostics indicate that PEFT methods primarily reshapes how uncertainty is encoded and surfaced, comparing with injecting new factual knowledge into the models.

</details>


### [159] [Visualizing and Benchmarking LLM Factual Hallucination Tendencies via Internal State Analysis and Clustering](https://arxiv.org/abs/2602.11167)
*Nathan Mao,Varun Kaushik,Shreya Shivkumar,Parham Sharafoleslami,Kevin Zhu,Sunishchal Dev*

Main category: cs.CL

TL;DR: 该研究提出了FalseCite数据集，用于系统地研究大型语言模型（LLMs）因误导性或伪造的引用而产生的幻觉现象，并发现GPT-4o-mini在此类幻觉上表现突出。通过分析模型内部状态，研究者观察到幻觉和非幻觉响应的隐藏状态向量呈现出独特的“角状”形状。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在医学或法律等敏感领域会产生有害的幻觉（生成虚假信息）。为了系统地研究和应对这一问题，需要一个专门的数据集来捕获由误导性或伪造引用引起的幻觉。

Method: 研究者构建了一个名为FalseCite的精心策划的数据集，其中包含误导性或伪造的引用。他们使用GPT-4o-mini、Falcon-7B和Mistral 7-B模型在FalseCite数据集上进行实验，以观察和量化幻觉的发生。此外，他们还分析了幻觉模型（包括非幻觉模型）的内部隐藏状态向量，并通过可视化和聚类来探索其模式。

Result: 在FalseCite数据集上运行的LLMs，特别是GPT-4o-mini，在面对包含欺骗性引用的虚假声明时，幻觉活动显著增加。分析显示，无论模型是否产生幻觉，其隐藏状态向量都呈现出一种独特的、类似“角”的形状。

Conclusion: FalseCite数据集为评估和减轻LLMs中的幻觉问题提供了一个有力的基础。研究揭示了误导性引用是LLM幻觉的一个重要诱因，并且模型的内部状态（隐藏状态向量）在幻觉发生时可能表现出特定的几何模式，这为未来的研究提供了新的视角。

Abstract: Large Language Models (LLMs) often hallucinate, generating nonsensical or false information that can be especially harmful in sensitive fields such as medicine or law. To study this phenomenon systematically, we introduce FalseCite, a curated dataset designed to capture and benchmark hallucinated responses induced by misleading or fabricated citations. Running GPT-4o-mini, Falcon-7B, and Mistral 7-B through FalseCite, we observed a noticeable increase in hallucination activity for false claims with deceptive citations, especially in GPT-4o-mini. Using the responses from FalseCite, we can also analyze the internal states of hallucinating models, visualizing and clustering the hidden state vectors. From this analysis, we noticed that the hidden state vectors, regardless of hallucination or non-hallucination, tend to trace out a distinct horn-like shape. Our work underscores FalseCite's potential as a foundation for evaluating and mitigating hallucinations in future LLM research.

</details>


### [160] [Enhancing SDG-Text Classification with Combinatorial Fusion Analysis and Generative AI](https://arxiv.org/abs/2602.11168)
*Jingyan Xu,Marcelo L. LaFleur,Christina Schweikert,D. Frank Hsu*

Main category: cs.CL

TL;DR: 本文提出了一种名为组合融合分析（CFA）的系统融合方法，该方法通过结合多个分类模型（包括使用生成式AI生成的合成数据训练的模型）来提升文本分类性能，特别是在联合国可持续发展目标（SDGs）的分类任务上。研究表明，CFA能够显著优于单一模型，并与人类领域专家的见解相结合时，可以相互补充和增强。


<details>
  <summary>Details</summary>
Motivation: 现有的文本分类方法在类别不明确、难以区分或相互关联的情况下存在挑战。作者认为，利用人类情境进行社会分析的领域可以从文本分类中获益，因此旨在提高联合国可持续发展目标（SDGs）的文本分类性能，并探索多模型智能的融合以及与人类专家的协同作用。

Method: 研究中使用了组合融合分析（CFA）技术，这是一种系统融合范式，利用秩分数特征（RSC）函数和认知多样性（CD）来结合一组表现良好且相互独立的分类模型。作者首先利用生成式AI模型生成合成数据用于模型训练，然后将CFA应用于SDGs的文本分类任务。最后，将CFA的结果与人类领域专家的评估进行对比。

Result: CFA技术在SDGs文本分类任务上取得了96.73%的性能，显著优于任何单一的最佳模型。此外，研究表明，将CFA（结合了多个机器学习/人工智能模型的智能）与人类专家的输入相结合，不仅能够互补，还能相互增强。

Conclusion: 组合融合分析（CFA）是一种有效的系统融合方法，能够显著提升文本分类性能，尤其是在处理复杂分类任务时。将CFA与人类领域专家的知识相结合，可以实现协同效应，从而进一步提高整体的分析和决策能力。

Abstract: (Natural Language Processing) NLP techniques such as text classification and topic discovery are very useful in many application areas including information retrieval, knowledge discovery, policy formulation, and decision-making. However, it remains a challenging problem in cases where the categories are unavailable, difficult to differentiate, or are interrelated. Social analysis with human context is an area that can benefit from text classification, as it relies substantially on text data. The focus of this paper is to enhance the classification of text according to the UN's Sustainable Development Goals (SDGs) by collecting and combining intelligence from multiple models. Combinatorial Fusion Analysis (CFA), a system fusion paradigm using a rank-score characteristic (RSC) function and cognitive diversity (CD), has been used to enhance classifier methods by combining a set of relatively good and mutually diverse classification models. We use a generative AI model to generate synthetic data for model training and then apply CFA to this classification task. The CFA technique achieves 96.73% performance, outperforming the best individual model. We compare the outcomes with those obtained from human domain experts. It is demonstrated that combining intelligence from multiple ML/AI models using CFA and getting input from human experts can, not only complement, but also enhance each other.

</details>


### [161] [Disentangling Direction and Magnitude in Transformer Representations: A Double Dissociation Through L2-Matched Perturbation Analysis](https://arxiv.org/abs/2602.11169)
*Mangadoddi Srikar Vardhan,Lekkala Sai Teja*

Main category: cs.CL

TL;DR: 研究表明，Transformer模型中隐藏状态的“方向”和“幅度”在信息编码中扮演着不同的功能角色，方向主要影响注意力机制，而幅度则影响层归一化（LayerNorm）以及细粒度的句法处理。这种现象在基于LayerNorm的架构中尤为明显，而在RMSNorm架构中则有所不同。


<details>
  <summary>Details</summary>
Motivation: 现有研究不清楚Transformer隐藏状态的“方向”（表示空间中的方向）和“幅度”（向量范数）是否具有不同的功能作用。

Method: 作者研究了Pythia模型系列，采用L2匹配扰动分析（L2-matched perturbation analysis）方法，比较了相同欧氏距离下角度扰动和幅度扰动对模型性能的影响。通过因果干预（causal intervention）分析了扰动的影响路径，并尝试通过修复注意力机制和LayerNorm来恢复模型性能。

Result: 角度扰动对语言建模损失的损害更大（高达42.9%），而幅度扰动对句法处理的准确性损害更大（主谓一致性任务上准确率下降20.4% vs. 1.6%）。角度扰动的影响主要通过注意力机制传播，幅度扰动的影响部分通过LayerNorm传播。这些发现跨越了Pythia架构的不同模型规模，并与RMSNorm架构的表现不同。

Conclusion: Transformer隐藏状态的方向和幅度在LayerNorm架构中具有部分不同的计算作用：方向优先影响注意力路由，而幅度调节细粒度句法判断的处理强度。这种分离依赖于具体的架构选择，并对模型编辑和可解释性研究有启示。

Abstract: Transformer hidden states encode information as high-dimensional vectors, yet whether direction (orientation in representational space) and magnitude (vector norm) serve distinct functional roles remains unclear. Studying Pythia-family models, we discover a striking cross-over dissociation: angular perturbations cause up to 42.9 more damage to language modeling loss, while magnitude perturbations cause disproportionately more damage to syntactic processing (20.4% vs.1.6% accuracy drop on subject-verb agreement).This finding is enabled by L2-matched perturbation analysis, a methodology ensuring that an gular and magnitude perturbations achieve identical Euclidean displacements. Causal intervention reveals that angular damage flows substantially through the attention pathways (28.4% loss recovery via attention repair), while magnitude damage flows partly through the LayerNorm pathways(29.9% recovery via LayerNorm repair). These patterns replicate across scales within the Pythia architecture family. These findings provide evidence that direction and magnitude support partially distinct computational roles in LayerNorm based architectures. The direction preferentially affects attentional routing, while magnitude modulates processing intensity for fine-grained syntactic judgments. We find different patterns in RMSNorm-based architectures, suggesting that the dissociation depends on architectural choices. Our results refine the linear representation hypothesis and have implications for model editing and interpretability research

</details>


### [162] [PRIME: Policy-Reinforced Iterative Multi-agent Execution for Algorithmic Reasoning in Large Language Models](https://arxiv.org/abs/2602.11170)
*Jiawei Xu,Zhenyu Yu,Ziqian Bi,Minh Duc Pham,Xiaoyi Qu,Danyang Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为 PRIME 的新框架，通过结合执行者、验证者和协调者三个专门的代理，并使用 group relative policy optimization 进行优化，以解决大型语言模型在算法推理方面的局限性。同时，引入了最大的算法推理基准 PRIME-Bench 进行评估。PRIME 在准确率上取得了显著提升，尤其在需要持续状态跟踪的任务上效果显著，并且对较小模型有不成比例的益处。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在各种推理任务上表现出色，但在算法推理方面仍有局限性。研究旨在克服这一挑战，提高模型在算法推理任务上的性能。

Method: 提出 PRIME 框架，包含三个专门代理：执行者（负责逐步推理）、验证者（负责约束检查）和协调者（负责回溯控制）。该框架通过 group relative policy optimization 进行优化。引入 PRIME-Bench 基准，包含 86 个任务，跨越 12 个类别，共 51,600 个实例。

Result: PRIME 将平均准确率从 26.8% 提高到 93.8%，相对提升 250%。在需要持续状态跟踪的任务上，图灵机模拟从 9% 提升到 92%，长除法从 16% 提升到 94%。消融实验表明，迭代验证是提高性能的关键。较小的模型（8B 参数）在 PRIME 框架下能达到比其规模大 8 倍的模型相当的准确率。

Conclusion: PRIME 框架能够显著提升大型语言模型在算法推理任务上的性能，尤其是在需要复杂状态跟踪的任务中。迭代验证机制是防止错误传播的关键。此外，PRIME 框架对模型的规模具有不成比例的益处，使得较小模型也能获得高性能。

Abstract: Large language models have demonstrated remarkable capabilities across diverse reasoning tasks, yet their performance on algorithmic reasoning remains limited. To handle this limitation, we propose PRIME (Policy-Reinforced Iterative Multi-agent Execution), a framework comprising three specialized agents, an executor for step-by-step reasoning, a verifier for constraint checking, and a coordinator for backtracking control, optimized through group relative policy optimization. For comprehensive evaluation, we introduce PRIME-Bench, the largest algorithmic reasoning benchmark to date, comprising 86 tasks across 12 categories with 51,600 instances. Tasks span sorting algorithms, graph and tree structures, automata and state machines, symbolic reasoning, and constraint-based puzzles, with execution traces reaching over one million steps. Compared to baseline approach, PRIME improves average accuracy from 26.8% to 93.8%, a 250% relative gain. The largest improvements occur on tasks requiring sustained state tracking, with Turing machine simulation improving from 9% to 92% and long division from 16% to 94%. Ablation studies identify iterative verification as the primary contributor, preventing the error propagation that causes baseline approaches to fail catastrophically. Analysis across model scales (8B-120B parameters) reveals that smaller models benefit disproportionately, achieving accuracy comparable to models 8x larger.

</details>


### [163] [Efficient Hyper-Parameter Search for LoRA via Language-aided Bayesian Optimization](https://arxiv.org/abs/2602.11171)
*Baek Seong-Eun,Lee Jung-Mok,Kim Sung-Bin,Tae-Hyun Oh*

Main category: cs.CL

TL;DR: 本文提出了一种结合预训练大语言模型（LLM）领域知识的贝叶斯优化（BO）框架，用于高效搜索 LoRA 的超参数，并通过代理训练和评估进一步提高效率，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: LoRA 微调 LLM 效率高但超参数选择敏感，穷举搜索计算成本高。现有方法需要更高效的超参数搜索策略。

Method: 1. 将预训练 LLM 作为离散到连续的映射，链接超参数及其领域知识到连续向量空间，并在该空间进行 BO。2. 通过语言提示注入领域知识，描述超参数之间的关系。3. 引入可学习的 token 来建模提示中难以描述的残差信息。4. 利用全数据集和子集数据集在 LoRA 训练中的性能相关性，引入代理训练和评估。

Result: 所提出的方法在约 30 次迭代内找到的超参数，比约 45,000 种组合的标准超参数获得了超过 20% 的性能提升。

Conclusion: 通过整合 LLM 的领域知识和代理训练，该方法能够高效地搜索 LoRA 超参数，显著优于标准超参数和穷举搜索。

Abstract: Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enables resource-efficient personalization or specialization, but it comes at the expense of additional hyperparameter tuning. Although LoRA makes fine-tuning efficient, it is highly sensitive to the choice of hyperparameters, and exhaustive hyperparameter search is still computationally very demanding. To address these challenges, we propose a framework that integrates the domain knowledge of pre-trained LLMs into Bayesian Optimization (BO) to efficiently search for LoRA hyperparameters. To leverage the informed knowledge of LLMs, we repurpose LLMs as a discrete-to-continuous mapping to link the hyperparameters and their domain knowledge with a continuous vector space, where BO is conducted. We design and control the mapping by language prompting, where we provide a domain-aware textual prompt describing the relationships among hyperparameters and their respective roles; thereby, we explicitly inject domain knowledge about LoRA into the LLM in natural language. Also, we model the residual information that is hard to linguistically describe in the prompt with an additional learnable token. This aids BO to sample more high-performing hyperparameters. In addition, by leveraging the observation of the strong correlation between the respective performance obtained from full and subset training datasets in LoRA training regimes, we introduce proxy training and evaluation with a data subset. This further increases the efficiency of our method. We demonstrate that our hyperparameter found with only about 30 iterations achieves more than 20% performance improvement over standard hyperparameters found from about 45,000 combinations.

</details>


### [164] [Synthesizing the Virtual Advocate: A Multi-Persona Speech Generation Framework for Diverse Linguistic Jurisdictions in Indic Languages](https://arxiv.org/abs/2602.11172)
*Aniket Deroy*

Main category: cs.CL

TL;DR: 本研究评估了 Gemini 2.5 Flash 和 Pro TTS 模型在五种印度语言（泰米尔语、泰卢固语、孟加拉语、印地语和古吉拉特语）中生成模拟法庭演讲的表现，并提出了一种提示框架来创建不同的倡导者角色。模型在程序性信息传递方面表现出“单调权威”，但在传达说服性辩护所需的动态语调和情感深度方面存在困难，尤其是在孟加拉语和古吉拉特语中表现不佳。研究表明，多语言 TTS 已准备好应对程序性法律任务，但仍需努力以复制人类法律话语的说服艺术。


<details>
  <summary>Details</summary>
Motivation: LLM 的发展促使 TTS 技术从基本的清晰度转向上下文感知和富有表现力的合成。在法律领域，合成语音需要传达权威和专业的个人形象，这在印度语言多样性的背景下尤具挑战性。

Method: 本研究调查了 Gemini 2.5 Flash TTS 和 Gemini 2.5 Pro TTS 模型生成模拟法庭演讲的表现。研究人员提出了一种提示框架，利用 Gemini 2.5 对五种印度语言的原生支持及其上下文感知节奏来生成不同的倡导者角色。

Result: Gemini 模型在程序性信息传递方面表现出“单调权威”，但难以实现说服性辩护所需的动态语调和情感深度。在孟加拉语和古吉拉特语中的表现下降，突显了未来需要改进的语音学领域。

Conclusion: 本研究强调了多语言 TTS 在处理程序性法律任务方面的潜力，同时也指出了在复制人类法律话语的说服艺术方面仍然存在的挑战。

Abstract: Legal advocacy requires a unique combination of authoritative tone, rhythmic pausing for emphasis, and emotional intelligence. This study investigates the performance of the Gemini 2.5 Flash TTS and Gemini 2.5 Pro TTS models in generating synthetic courtroom speeches across five Indic languages: Tamil, Telugu, Bengali, Hindi, and Gujarati. We propose a prompting framework that utilizes Gemini 2.5s native support for 5 languages and its context-aware pacing to produce distinct advocate personas. The evolution of Large Language Models (LLMs) has shifted the focus of TexttoSpeech (TTS) technology from basic intelligibility to context-aware, expressive synthesis. In the legal domain, synthetic speech must convey authority and a specific professional persona a task that becomes significantly more complex in the linguistically diverse landscape of India. The models exhibit a "monotone authority," excelling at procedural information delivery but struggling with the dynamic vocal modulation and emotive gravitas required for persuasive advocacy. Performance dips in Bengali and Gujarati further highlight phonological frontiers for future refinement. This research underscores the readiness of multilingual TTS for procedural legal tasks while identifying the remaining challenges in replicating the persuasive artistry of human legal discourse. The code is available at-https://github.com/naturenurtureelite/Synthesizing-the-Virtual-Advocate/tree/main

</details>


### [165] [Author-in-the-Loop Response Generation and Evaluation: Integrating Author Expertise and Intent in Responses to Peer Review](https://arxiv.org/abs/2602.11173)
*Qian Ruan,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出了一种名为REspGen的作者回复生成框架，它通过整合作者的显式输入、多属性控制和评估引导的细化，以一种“作者在循环中”的方式来处理科学同行评审中的回复撰写任务。该研究还构建了一个名为Re$^3$Align的大规模数据集，并提出了一个名为REspEval的全面评估套件。


<details>
  <summary>Details</summary>
Motivation: 现有的作者回复生成方法未能充分利用作者的领域专业知识、作者独有的信息以及修订和回复策略等作者专业知识和意图，将该任务视为纯粹的自动文本生成，忽视了作者在回复撰写过程中的关键作用。作者寻求能够整合这些信号的自然语言处理（NLP）辅助工具，以支持有效的回复撰写。

Method: 将作者回复生成任务重新定义为“作者在循环中”（author-in-the-loop）的任务。提出REspGen生成框架，该框架包含：1）显式作者输入；2）多属性控制；3）评估引导的细化。构建了Re$^3$Align数据集，包含审查-回复-修订三元组。开发了REspEval评估套件，包含20多个指标，涵盖输入利用、可控性、回复质量和语篇等方面。

Result: 实验表明，作者输入和评估引导的细化能够提升回复生成的效果。输入设计对回复质量有重要影响，并且在可控性和质量之间存在权衡。

Conclusion: 作者在循环中的方法以及REspGen框架在整合作者专业知识和意图方面具有优势。提出的数据集和评估套件为未来作者回复生成研究奠定了基础。

Abstract: Author response (rebuttal) writing is a critical stage of scientific peer review that demands substantial author effort. Recent work frames this task as automatic text generation, underusing author expertise and intent. In practice, authors possess domain expertise, author-only information, revision and response strategies--concrete forms of author expertise and intent--to address reviewer concerns, and seek NLP assistance that integrates these signals to support effective response writing in peer review. We reformulate author response generation as an author-in-the-loop task and introduce REspGen, a generation framework that integrates explicit author input, multi-attribute control, and evaluation-guided refinement, together with REspEval, a comprehensive evaluation suite with 20+ metrics covering input utilization, controllability, response quality, and discourse. To support this formulation, we construct Re$^3$Align, the first large-scale dataset of aligned review--response--revision triplets, where revisions provide signals of author expertise and intent. Experiments with state-of-the-art LLMs show the benefits of author input and evaluation-guided refinement, the impact of input design on response quality, and trade-offs between controllability and quality. We make our dataset, generation and evaluation tools publicly available.

</details>


### [166] [The Script Tax: Measuring Tokenization-Driven Efficiency and Latency Disparities in Multilingual Language Models](https://arxiv.org/abs/2602.11174)
*Aradhya Dixit,Shreem Dixit*

Main category: cs.CL

TL;DR: 预训练的多语言语言模型在处理不同书写系统时，其分词器会引入“脚本税”，导致处理效率降低和信息成本增加，这表明需要脚本感知的分词和预训练方法。


<details>
  <summary>Details</summary>
Motivation: 研究人员假设预训练的多语言语言模型在处理不同书写系统时可能存在系统性成本，而这些成本尚未被充分量化和理解。

Method: 通过比较两种具有相同语言内容但正字法不同的书写变体，在mBERT和XLM-R模型上，量化了“脚本税”。方法包括计算词语的“肥沃度”（tokens/word）、推理速度（sentences/second）、以及使用每字符比特（BPC）来衡量信息成本。同时，还进行了往返转换（CER_rt）以区分处理成本和映射噪声。

Result: 具有更高碎片化正字法的书写变体，其“肥沃度”增加了约3.4倍（6.73-6.85 vs. 2.10-2.35 tokens/word），导致推理速度减慢了16.5倍（0.23 vs. 3.8 sentences/second）。信息成本方面，mBERT的BPC增加了19.7%（8.06->9.65），XLM-R的BPC增加了47.1%（12.19->17.94）。往返转换检查（CER_rt=0.31）表明这些差异主要是由正字法条件下的处理造成的。

Conclusion: 分词器是多语言NLP中不公平性的一个关键来源，并且对不同书写系统引入了显著的成本。研究结果强调了开发脚本感知（script-aware）的分词和预训练方法的重要性，以减少这种不公平性。

Abstract: Pretrained multilingual language models are often assumed to be script-agnostic, yet their tokenizers can impose systematic costs on certain writing systems. We quantify this script tax by comparing two orthographic variants with identical linguistic content. Across mBERT and XLM-R, the higher-fragmentation orthography shows a ~3.4x increase in fertility (6.73-6.85 vs. 2.10-2.35 tokens/word), leading to a 16.5x inference slowdown (0.23 vs. 3.8 sentences/second) on identical hardware. Using bits per character (BPC) to avoid the "NLL paradox" from subword fragmentation, we find a substantial increase in information cost: +19.7% for mBERT (8.06->9.65) and +47.1% for XLM-R (12.19->17.94). A round-trip conversion check (CER_rt=0.31) suggests these gaps reflect orthography-conditioned processing rather than mapping noise. Our results highlight tokenization as a key source of inequity in multilingual NLP and motivate script-aware tokenization and pretraining.

</details>


### [167] [Barriers to Discrete Reasoning with Transformers: A Survey Across Depth, Exactness, and Bandwidth](https://arxiv.org/abs/2602.11175)
*Michelle Yuan,Weiyi Sun,Amir H. Rezaeian,Jyotika Singh,Sandip Ghoshal,Yao-Ting Wang,Miguel Ballesteros,Yassine Benajiba*

Main category: cs.CL

TL;DR: 本调查从电路复杂度、逼近论和通信复杂度三个理论视角，分析了Transformer在离散推理任务（如算术、逻辑推理和算法组合）中的理论局限性，阐明了其在执行精确离散算法时面临的结构和计算障碍。


<details>
  <summary>Details</summary>
Motivation: Transformer在NLP、CV等领域取得了巨大成功，但其在离散推理任务（如算术、逻辑推理）方面的理论局限性仍是关键的未解决问题。

Method: 通过整合电路复杂度、逼近论和通信复杂度这三个理论视角，对Transformer在符号计算方面的结构和计算障碍进行分析。

Result: Transformer在执行精确离散算法时存在困难，这源于深度限制、逼近不连续性的难度以及标记间通信的瓶颈。然而，它们在模式匹配和插值方面表现出色。

Conclusion: Transformer在处理精确离散算法方面存在内在的理论限制，尽管它们在模式匹配和插值方面表现优异。本研究为理解这些局限性提供了统一的视角，并为未来的模型设计指明了方向。

Abstract: Transformers have become the foundational architecture for a broad spectrum of sequence modeling applications, underpinning state-of-the-art systems in natural language processing, vision, and beyond. However, their theoretical limitations in discrete reasoning tasks, such as arithmetic, logical inference, and algorithmic composition, remain a critical open problem. In this survey, we synthesize recent studies from three theoretical perspectives: circuit complexity, approximation theory, and communication complexity, to clarify the structural and computational barriers that transformers face when performing symbolic computations. By connecting these established theoretical frameworks, we provide an accessible and unified account of why current transformer architectures struggle to implement exact discrete algorithms, even as they excel at pattern matching and interpolation. We review key definitions, seminal results, and illustrative examples, highlighting challenges such as depth constraints, difficulty approximating discontinuities, and bottlenecks in inter-token communication. Finally, we discuss implications for model design and suggest promising directions for overcoming these foundational limitations.

</details>


### [168] [Evaluating Few-Shot Temporal Reasoning of LLMs for Human Activity Prediction in Smart Environments](https://arxiv.org/abs/2602.11176)
*Maral Doctorarastoo,Katherine A. Flanigan,Mario Bergés,Christopher McComb*

Main category: cs.CL

TL;DR: 本研究探讨使用大型语言模型（LLMs）在低数据环境下预测人类活动及其持续时间的可行性，并提出一种结合时间、空间、行为历史和个人信息的检索增强提示策略。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动的基于代理的模型在数据稀疏的情况下表现不佳，这限制了它们在智能家居、建筑设计、交通模拟和人机协作等领域的应用。本研究旨在探索LLMs是否能弥合这一差距。

Method: 采用检索增强提示策略，整合时间、空间、行为历史和个人信息作为上下文，并在CASAS Aruba智能家居数据集上进行评估。评估包括下一活动预测（含持续时间估计）和多步日常序列生成，并测试了不同数量的少量样本（few-shot examples）。

Result: LLMs展现出强大的时间理解能力，即使在零样本（zero-shot）情况下也能进行连贯的活动预测。增加一到两个样本可以提高持续时间校准和类别准确性，但超过一定数量后性能饱和。序列级评估显示，在不同少量样本条件下，时间一致性保持良好。

Conclusion: 预训练的大型语言模型可以作为有效的时序推理器，能够捕捉人类行为的规律性和情境依赖性变化，从而增强基于代理模型的行为模块，特别是在数据稀疏的环境中。

Abstract: Anticipating human activities and their durations is essential in applications such as smart-home automation, simulation-based architectural and urban design, activity-based transportation system simulation, and human-robot collaboration, where adaptive systems must respond to human activities. Existing data-driven agent-based models--from rule-based to deep learning--struggle in low-data environments, limiting their practicality. This paper investigates whether large language models, pre-trained on broad human knowledge, can fill this gap by reasoning about everyday activities from compact contextual cues. We adopt a retrieval-augmented prompting strategy that integrates four sources of context--temporal, spatial, behavioral history, and persona--and evaluate it on the CASAS Aruba smart-home dataset. The evaluation spans two complementary tasks: next-activity prediction with duration estimation, and multi-step daily sequence generation, each tested with various numbers of few-shot examples provided in the prompt. Analyzing few-shot effects reveals how much contextual supervision is sufficient to balance data efficiency and predictive accuracy, particularly in low-data environments. Results show that large language models exhibit strong inherent temporal understanding of human behavior: even in zero-shot settings, they produce coherent daily activity predictions, while adding one or two demonstrations further refines duration calibration and categorical accuracy. Beyond a few examples, performance saturates, indicating diminishing returns. Sequence-level evaluation confirms consistent temporal alignment across few-shot conditions. These findings suggest that pre-trained language models can serve as promising temporal reasoners, capturing both recurring routines and context-dependent behavioral variations, thereby strengthening the behavioral modules of agent-based models.

</details>


### [169] [Mechanistic Interpretability for Large Language Model Alignment: Progress, Challenges, and Future Directions](https://arxiv.org/abs/2602.11180)
*Usman Naseem*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLMs）的机械可解释性在模型对齐方面的最新进展，讨论了现有方法、挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLMs）不透明的内部决策过程，并实现模型对齐。

Method: 通过检查电路发现、特征可视化、激活引导和因果干预等机械可解释性技术，分析这些技术如何为 RLHF、宪法 AI 和可扩展监督等对齐策略提供信息。

Result: 可解释性研究已为 RLHF、宪法 AI 和可扩展监督等对齐策略提供了见解。然而，也存在神经元叠加假设、多义性以及解释大规模模型中涌现行为的困难等挑战。

Conclusion: 未来的研究应侧重于自动化可解释性、电路在不同模型间的泛化能力，以及开发可扩展到前沿模型的、由可解释性驱动的对齐技术。

Abstract: Large language models (LLMs) have achieved remarkable capabilities across diverse tasks, yet their internal decision-making processes remain largely opaque. Mechanistic interpretability (i.e., the systematic study of how neural networks implement algorithms through their learned representations and computational structures) has emerged as a critical research direction for understanding and aligning these models. This paper surveys recent progress in mechanistic interpretability techniques applied to LLM alignment, examining methods ranging from circuit discovery to feature visualization, activation steering, and causal intervention. We analyze how interpretability insights have informed alignment strategies including reinforcement learning from human feedback (RLHF), constitutional AI, and scalable oversight. Key challenges are identified, including the superposition hypothesis, polysemanticity of neurons, and the difficulty of interpreting emergent behaviors in large-scale models. We propose future research directions focusing on automated interpretability, cross-model generalization of circuits, and the development of interpretability-driven alignment techniques that can scale to frontier models.

</details>


### [170] [What Do LLMs Know About Alzheimer's Disease? Fine-Tuning, Probing, and Data Synthesis for AD Detection](https://arxiv.org/abs/2602.11177)
*Lei Jiang,Yue Zhou,Natalie Parde*

Main category: cs.CL

TL;DR: 本研究通过微调大型语言模型（LLMs）用于阿尔茨海默病（AD）检测，并分析其内部表示，发现特定词汇和特殊标记在模型性能提升中起关键作用。基于此，研究设计了任务感知型特殊标记，并训练了一个序列到序列模型利用这些标记生成结构一致且信息丰富的合成样本，并评估了合成数据的有效性。


<details>
  <summary>Details</summary>
Motivation: 在标记数据有限的情况下，可靠地早期检测阿尔茨海默病（AD）是一个挑战。大型语言模型（LLMs）在跨领域迁移方面表现出强大能力，但将其应用于AD领域通过监督微调的研究尚不充分。

Method: 研究微调了一个LLM用于AD检测，并使用探测技术分析跨Transformer层的中间激活，以研究任务相关信息如何在内部表示中编码。研究还设计了一组特殊的任务感知标记，并训练了一个序列到序列模型利用这些标记生成合成数据，并通过内在评估和下游训练来评估合成数据的有效性。

Result: 研究发现，在微调后，特定词汇和特殊标记的探测值发生显著变化，表明这些元素在模型改进的检测性能中起着至关重要的作用。利用这些洞察，研究设计了任务感知型特殊标记，并成功生成了结构一致且具有诊断信息价值的合成样本。

Conclusion: 通过对LLM的微调和内部表示的分析，本研究揭示了特定词汇和特殊标记在AD检测中的重要性，并提出了一种利用这些标记生成合成数据的方法，为解决AD领域标记数据不足的问题提供了新的途径。

Abstract: Reliable early detection of Alzheimer's disease (AD) is challenging, particularly due to limited availability of labeled data. While large language models (LLMs) have shown strong transfer capabilities across domains, adapting them to the AD domain through supervised fine-tuning remains largely unexplored. In this work, we fine-tune an LLM for AD detection and investigate how task-relevant information is encoded within its internal representations. We employ probing techniques to analyze intermediate activations across transformer layers, and we observe that, after fine-tuning, the probing values of specific words and special markers change substantially, indicating that these elements assume a crucial role in the model's improved detection performance. Guided by this insight, we design a curated set of task-aware special markers and train a sequence-to-sequence model as a data-synthesis tool that leverages these markers to generate structurally consistent and diagnostically informative synthetic samples. We evaluate the synthesized data both intrinsically and by incorporating it into downstream training pipelines.

</details>


### [171] [From Instruction to Output: The Role of Prompting in Modern NLG](https://arxiv.org/abs/2602.11179)
*Munazza Zaib,Elaf Alhazmi*

Main category: cs.CL

TL;DR: 本篇综述论文旨在为自然语言生成（NLG）领域的提示工程（prompt engineering）提供一个结构化的框架和全面的理解，因为它在LLMs中日益重要但缺乏系统性。


<details>
  <summary>Details</summary>
Motivation: 提示工程在提升大型语言模型（LLMs）性能方面发挥着关键作用，尤其是在自然语言生成（NLG）领域，但目前缺乏对其多样化方法和技术的系统性梳理和理解。

Method: 本文献综述通过梳理提示工程的最新进展及其对不同NLG任务的影响，将提示设计视为一种输入层面的控制机制。论文提出了一个提示范式分类体系、一个基于多重因素的提示选择决策框架，并概述了新兴趋势和挑战，最后提出了一个连接设计、优化和评估的框架，以支持更可控和更通用的NLG。

Result: 该论文提出了一个提示工程的分类体系和决策框架，并介绍了一个支持可控和通用NLG的设计、优化和评估的框架。

Conclusion: 通过提供一个结构化的框架、分类体系和决策工具，本文旨在促进对提示工程的理解，并支持更有效和可控的NLG应用。

Abstract: Prompt engineering has emerged as an integral technique for extending the strengths and abilities of Large Language Models (LLMs) to gain significant performance gains in various Natural Language Processing (NLP) tasks. This approach, which requires instructions to be composed in natural language to bring out the knowledge from LLMs in a structured way, has driven breakthroughs in various NLP tasks. Yet there is still no structured framework or coherent understanding of the varied prompt engineering methods and techniques, particularly in the field of Natural Language Generation (NLG).
  This survey aims to help fill that gap by outlining recent developments in prompt engineering, and their effect on different NLG tasks. It reviews recent advances in prompting methods and their impact on NLG tasks, presenting prompt design as an input-level control mechanism that complements fine-tuning and decoding approaches. The paper introduces a taxonomy of prompting paradigms, a decision framework for prompt selection based on varying factors for the practitioners, outlines emerging trends and challenges, and proposes a framework that links design, optimization, and evaluation to support more controllable and generalizable NLG.

</details>


### [172] [MetaMem: Evolving Meta-Memory for Knowledge Utilization through Self-Reflective Symbolic Optimization](https://arxiv.org/abs/2602.11182)
*Haidong Xin,Xinze Li,Zhenghao Liu,Yukun Yan,Shuo Wang,Cheng Yang,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CL

TL;DR: MetaMem 是一个新颖的框架，它通过一个自进化的元记忆来增强 LLM 的记忆系统，旨在教会 LLM 如何有效利用记忆知识，从而解决现有记忆系统破坏交互逻辑和时序关系的问题。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 记忆系统虽然能支持长距离交互，但常常破坏交互的逻辑和时序关系，导致记忆碎片化和推理性能下降。

Method: MetaMem 提出了一个自进化的元记忆。在元记忆优化过程中，MetaMem 通过自我反思推理过程和执行更新操作，迭代地提炼跨任务的可转移知识利用经验，并将这些经验累积成显性的知识利用指导。

Result: MetaMem 显著优于现有基线方法，性能提升超过 3.6%。

Conclusion: MetaMem 框架能够有效教会 LLM 如何系统性地识别和整合分散记忆片段中的关键证据，从而提升推理性能。

Abstract: Existing memory systems enable Large Language Models (LLMs) to support long-horizon human-LLM interactions by persisting historical interactions beyond limited context windows. However, while recent approaches have succeeded in constructing effective memories, they often disrupt the inherent logical and temporal relationships within interaction sessions, resulting in fragmented memory units and degraded reasoning performance. In this paper, we propose MetaMem, a novel framework that augments memory systems with a self-evolving meta-memory, aiming to teach LLMs how to effectively utilize memorized knowledge. During meta-memory optimization, MetaMem iteratively distills transferable knowledge utilization experiences across different tasks by self-reflecting on reasoning processes and performing actions to update the current meta-memory state. The accumulated meta-memory units serve as explicit knowledge utilization experiences, guiding the LLM to systematically identify and integrate critical evidence from scattered memory fragments. Extensive experiments demonstrate the effectiveness of MetaMem, which significantly outperforms strong baselines by over 3.6%. All codes and datasets are available at https://github.com/OpenBMB/MetaMem.

</details>


### [173] [Code Mixologist : A Practitioner's Guide to Building Code-Mixed LLMs](https://arxiv.org/abs/2602.11181)
*Himanshu Gupta,Pratik Jayarao,Chaitanya Dwivedi,Neeraj Varshney*

Main category: cs.CL

TL;DR: 该论文对现代大型语言模型（LLM）中的代码混合与代码转换（CSW）现象进行了全面的回顾，提出了一个统一的分类法，并为构建、调整和评估能够处理CSW的LLM提供了实用的建议。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在多语言建模方面取得了进展，但在混合语言环境中仍面临语法、事实性和安全性方面的挑战。现有研究缺乏统一的视角和实用的指导。

Method: 作者构建了一个统一的分类法，从数据、模型和评估三个维度组织了现有研究。他们回顾了包括CSW定制预训练、任务特定后训练、提示策略和上下文学习等在内的建模方法。此外，还分析了当前的评估实践，识别了不稳定性、可重复性有限的问题，并考察了现有基准的语言覆盖度和英语中心偏见。

Result: 该研究识别了CSW研究的现有方法、挑战和趋势，特别是强调了评估方面的问题，如不稳定性、有限的可重复性以及现有基准的局限性。同时，还讨论了利用代码混合绕过模型安全机制的新兴安全问题。

Conclusion: 通过对CSW研究的全面梳理和分类，本文为构建、调整和评估能够处理代码混合和代码转换的LLMs提供了实用的建议和指导，并指出了未来的研究方向和挑战。

Abstract: Code-mixing and code-switching (CSW) remain challenging phenomena for large language models (LLMs). Despite recent advances in multilingual modeling, LLMs often struggle in mixed-language settings, exhibiting systematic degradation in grammaticality, factuality, and safety behavior. This work provides a comprehensive overview of CSW research in modern large language model settings. We introduce a unifying taxonomy that organizes prior work along dimensions of data, modeling, and evaluation, and we distill these findings into a practical playbook of actionable recommendations for building, adapting, and evaluating CSW-capable LLMs. We review modeling approaches ranging from CSW-tailored pre-training and task-specific post-training to prompting strategies and in-context learning. We analyze current evaluation practices, highlighting sources of instability and limited reproducibility, and we catalog existing benchmarks while critically examining their linguistic coverage and English-centric biases. Finally, we discuss emerging safety concerns, including use of code-mixing as a mechanism for bypassing model safeguards, and identify open research challenges.

</details>


### [174] [DDL2PropBank Agent: Benchmarking Multi-Agent Frameworks' Developer Experience Through a Novel Relational Schema Mapping Task](https://arxiv.org/abs/2602.11198)
*Shafiuddin Rehan Ahmed,Wei Wei*

Main category: cs.CL

TL;DR: 研究提出了DDL2PropBank基准测试，用于评估多智能体LLM开发框架的开发者体验。通过评估代码复杂度和AI辅助性，发现Agno框架综合表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体LLM开发框架缺乏一个可控、原则性的评估方法来衡量其开发者体验。

Method: 设计了DDL2PropBank基准任务，该任务将关系数据库模式映射到PropBank rolesets。使用Agent-as-a-Tool模式在10个框架中实现相同的智能体逻辑，并通过静态代码分析评估代码复杂性，评估LLM自主生成框架特定代码的能力（AI辅助性）。

Result: 研究发现不同框架的代码复杂性存在三倍的差异，Pydantic AI和Agno的实现开销最低。对于AI辅助性，结构对齐分数能可靠预测单模式框架的运行时成功，但会高估多模式框架的正确性。Agno在复杂性、结构对齐和83%的pass@1指标上均表现最佳。

Conclusion: DDL2PropBank为评估LLM开发框架提供了一个新颖的基准。Agno框架在降低开发复杂性和提高AI辅助性方面表现突出，是目前综合表现最好的框架。

Abstract: Multi-agent frameworks promise to simplify LLM-driven software development, yet there is no principled way to evaluate their developer experience in a controlled setting. We introduce DDL2PropBank, a novel benchmark task that maps relational database schemas to PropBank rolesets, requiring autonomous retrieval of candidate frames and fine-grained linguistic reasoning over table names, columns, and relations. Using the Agent-as-a-Tool pattern, we implement identical agent logic across 10 frameworks and evaluate along two dimensions: (i) code complexity via static analysis, and (ii) AI-assistability -- the extent to which LLMs can autonomously generate correct, framework-specific code. Our results reveal a threefold complexity spectrum, with Pydantic AI and Agno requiring the least implementation overhead. For AI-assistability, structural alignment scores reliably proxy runtime success for frameworks with single canonical patterns, but overestimate correctness for multi-pattern frameworks. Agno emerges as the strongest overall performer, combining lowest complexity with highest structural alignment and 83% pass@1.

</details>


### [175] [When and What to Ask: AskBench and Rubric-Guided RLVR for LLM Clarification](https://arxiv.org/abs/2602.11199)
*Jiale Zhao,Ke Fang,Lu Cheng*

Main category: cs.CL

TL;DR: 本文提出了AskBench，一个用于评估和改进大型语言模型（LLMs）提问以获取澄清信息能力的交互式基准测试。同时，本文还提出了RLVR（rubric-guided reinforcement learning with verifier-based rewards）方法，以提高LLMs在面对信息不足或包含错误前提的查询时的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在面对信息缺失或误导性提示时，容易产生幻觉或加剧错误认知，这促使研究者们探索如何提升LLMs在需要时主动寻求澄清信息的能力，同时又不牺牲任务性能。

Method: 本文引入了AskBench，一个将标准问答对转化为多轮交互并包含明确检查点的交互式基准测试。AskBench包含两种场景：AskMind（意图不明确的查询，需要澄清）和AskOverconfidence（包含错误前提的查询，需要识别和纠正）。同时，提出了一种基于规则引导的强化学习方法RLVR，该方法利用结构化规则集来鼓励模型进行有针对性的澄清，并使用验证器作为奖励。

Result: 实验结果表明，RLVR方法在准确性、规则遵循度和交互效率方面均表现出持续的提升，并且在未见过的数据集上具有良好的泛化能力。

Conclusion: AskBench基准测试和RLVR方法能够有效评估和提升大型语言模型在面对含糊不清或包含错误信息时的提问澄清能力，并且在不同领域都展现出良好的泛化性。

Abstract: Large language models (LLMs) often respond even when prompts omit critical details or include misleading information, leading to hallucinations or reinforced misconceptions. We study how to evaluate and improve LLMs' ability to decide when and what to ask for clarification without sacrificing task performance. We introduce AskBench, an interactive benchmark that converts standard QA pairs into multi-turn interactions with explicit checkpoints. A unified judge loop evaluates final answers and simulates user responses as needed. AskBench covers two settings: AskMind, with intent-deficient queries requiring clarification, and AskOverconfidence, with queries containing false premises that must be identified and corrected. We further propose rubric-guided reinforcement learning with verifier-based rewards (RLVR), which uses structured rubrics to encourage targeted clarification. Experiments show consistent improvements in accuracy, rubric adherence, and interaction efficiency, with strong generalization to unseen domains.

</details>


### [176] [Mechanistic Evidence for Faithfulness Decay in Chain-of-Thought Reasoning](https://arxiv.org/abs/2602.11201)
*Donald Ye,Max Loffgren,Om Kotadia,Linus Wong*

Main category: cs.CL

TL;DR: 本文提出了一种名为 NLDD 的新指标，用于衡量语言模型思维链（CoT）解释的真实性。研究发现，在 CoT 的特定长度之后，之前的推理步骤对最终答案的影响很小甚至为负，这表明模型的推理过程可能并不完全遵循其给出的解释，并且模型的准确性并不能完全反映其推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型生成的 CoT 解释是否真正反映了模型的决策过程，还是仅仅是事后诸葛亮的辩护，这一点尚不清楚。需要一种方法来衡量 CoT 步骤是否忠实于模型的决策过程。

Method: 提出 Normalized Logit Difference Decay (NLDD) 指标，通过破坏 CoT 的单个推理步骤，并测量模型对最终答案的置信度下降程度来评估步骤的重要性。通过标准化测量，NLDD 实现了跨模型和跨架构的严格比较。

Result: 在三种模型家族和多种任务上进行测试，发现了一个一致的推理范围（k*），大致在 CoT 长度的 70%-85% 之间，超过此范围的推理标记对最终答案的影响很小或为负。还发现模型可能编码了正确的内部表征，但却完全无法完成任务。

Conclusion: 准确性并不能完全揭示模型是否通过其 CoT 进行了推理。NLDD 提供了一种衡量 CoT 何时真正重要的有效方法，并揭示了模型推理过程中存在的一些局限性。

Abstract: Chain-of-Thought (CoT) explanations are widely used to interpret how language models solve complex problems, yet it remains unclear whether these step-by-step explanations reflect how the model actually reaches its answer, or merely post-hoc justifications. We propose Normalized Logit Difference Decay (NLDD), a metric that measures whether individual reasoning steps are faithful to the model's decision-making process. Our approach corrupts individual reasoning steps from the explanation and measures how much the model's confidence in its answer drops, to determine if a step is truly important. By standardizing these measurements, NLDD enables rigorous cross-model comparison across different architectures. Testing three model families across syntactic, logical, and arithmetic tasks, we discover a consistent Reasoning Horizon (k*) at 70--85% of chain length, beyond which reasoning tokens have little or negative effect on the final answer. We also find that models can encode correct internal representations while completely failing the task. These results show that accuracy alone does not reveal whether a model actually reasons through its chain. NLDD offers a way to measure when CoT matters.

</details>


### [177] [The Automatic Verification of Image-Text Claims (AVerImaTeC) Shared Task](https://arxiv.org/abs/2602.11221)
*Rui Cao,Zhenyun Deng,Yulong Chen,Michael Schlichtkrull,Andreas Vlachos*

Main category: cs.CL

TL;DR: AVerImaTeC 共享任务旨在促进图像-文本声明证据检索和验证系统的开发。14 个系统在开发阶段提交，6 个系统在测试阶段提交，所有系统均优于基线。HUMANE 团队获胜，AVerImaTeC 得分为 0.5455。本文详细介绍了任务、评估结果以及经验教训。


<details>
  <summary>Details</summary>
Motivation: 推动用于检索证据和验证真实世界图像-文本声明的系统发展。

Method: 参赛者可以使用外部知识源（如网络搜索引擎）或组织者提供的知识库。性能通过 AVerImaTeC 分数进行评估，该分数定义为条件判决准确率，只有当相关证据分数超过预定阈值时，判决才被视为正确。

Result: 14 个系统参加了开发阶段，6 个系统参加了测试阶段。所有测试阶段的系统都优于基线。获胜团队 HUMANE 获得了 0.5455 的 AVerImaTeC 分数。

Conclusion: AVerImaTeC 共享任务成功吸引了系统开发，并展示了所有参赛系统优于基线。该任务为图像-文本声明验证领域提供了宝贵的见解和经验教训。

Abstract: The Automatic Verification of Image-Text Claims (AVerImaTeC) shared task aims to advance system development for retrieving evidence and verifying real-world image-text claims. Participants were allowed to either employ external knowledge sources, such as web search engines, or leverage the curated knowledge store provided by the organizers. System performance was evaluated using the AVerImaTeC score, defined as a conditional verdict accuracy in which a verdict is considered correct only when the associated evidence score exceeds a predefined threshold. The shared task attracted 14 submissions during the development phase and 6 submissions during the testing phase. All participating systems in the testing phase outperformed the baseline provided. The winning team, HUMANE, achieved an AVerImaTeC score of 0.5455. This paper provides a detailed description of the shared task, presents the complete evaluation results, and discusses key insights and lessons learned.

</details>


### [178] [SurveyLens: A Research Discipline-Aware Benchmark for Automatic Survey Generation](https://arxiv.org/abs/2602.11238)
*Beichen Guo,Zhiyuan Wen,Jia Gu,Senzhang Wang,Haochen Shi,Ruosong Yang,Shuaiqi Liu*

Main category: cs.CL

TL;DR: 本文提出了SurveyLens，一个跨学科的自动论文综述生成（ASG）评估基准，并包含一个双重评估框架（学科感知评分标准评估和典范对齐评估），以解决现有ASG评估方法偏向CS且缺乏学科适应性的问题。通过对11种ASG方法的实验，SurveyLens为不同学科的研究者提供了关于ASG工具选择的指导。


<details>
  <summary>Details</summary>
Motivation: 现有自动论文综述生成（ASG）的评估方法存在偏向计算机科学（CS）且未能考虑不同学术领域的标准问题，导致非CS领域的研究者难以获得高质量、符合学科规范的综述。

Method: 构建了一个包含10个学科1000篇高质量人工撰写综述的SurveyLens-1k数据集。提出了一个双重评估框架，包括：1）学科感知评分标准评估（使用与人类偏好对齐的LLM评估学科写作规范遵循情况）；2）典范对齐评估（评估内容覆盖度和综合质量与人工撰写综述的差距）。

Result: 在SurveyLens基准上评估了11种先进的ASG方法，揭示了不同方法在不同学科下的优劣势，并为选择适合特定学科需求的ASG工具提供了指导。

Conclusion: SurveyLens是第一个学科感知的ASG评估基准，能够更全面地评估ASG方法的性能，并为不同学科的研究者提供实用的ASG工具选择建议。

Abstract: The exponential growth of scientific literature has driven the evolution of Automatic Survey Generation (ASG) from simple pipelines to multi-agent frameworks and commercial Deep Research agents. However, current ASG evaluation methods rely on generic metrics and are heavily biased toward Computer Science (CS), failing to assess whether ASG methods adhere to the distinct standards of various academic disciplines. Consequently, researchers, especially those outside CS, lack clear guidance on using ASG systems to yield high-quality surveys compliant with specific discipline standards. To bridge this gap, we introduce SurveyLens, the first discipline-aware benchmark evaluating ASG methods across diverse research disciplines. We construct SurveyLens-1k, a curated dataset of 1,000 high-quality human-written surveys spanning 10 disciplines. Subsequently, we propose a dual-lens evaluation framework: (1) Discipline-Aware Rubric Evaluation, which utilizes LLMs with human preference-aligned weights to assess adherence to domain-specific writing standards; and (2) Canonical Alignment Evaluation to rigorously measure content coverage and synthesis quality against human-written survey papers. We conduct extensive experiments by evaluating 11 state-of-the-art ASG methods on SurveyLens, including Vanilla LLMs, ASG systems, and Deep Research agents. Our analysis reveals the distinct strengths and weaknesses of each paradigm across fields, providing essential guidance for selecting tools tailored to specific disciplinary requirements.

</details>


### [179] [Are Aligned Large Language Models Still Misaligned?](https://arxiv.org/abs/2602.11305)
*Usman Naseem,Gautam Siddharth Kashyap,Rafiq Ali,Ebad Shabbir,Sushant Kumar Ray,Abdullah Mohammad,Agrima Seth*

Main category: cs.CL

TL;DR: 本文提出了一个名为Mis-Align Bench的统一基准，用于同时评估大型语言模型（LLMs）在安全性、价值观和文化三个维度上的失准情况。研究表明，仅在单一维度上表现良好的模型，在多维度联合评估时性能会显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有的失准基准各自侧重于单一维度（安全性、价值观或文化），无法同时评估模型在真实世界场景中必须同时满足的多个维度。这阻碍了对LLM失准问题的全面理解和解决。

Method: 1. 构建了SAVACU数据集，包含382,424个英语样本，覆盖112个领域，通过Mistral-7B-Instruct-v0.3和Llama-3.1-8B-Instruct对LLM-PROMPT-DATASET中的提示进行重新分类，并使用SimHash避免重复。2. 通过两阶段拒绝采样为提示配对了失准和对齐的响应。3. 基准测试了通用、微调和开源LLM，在安全性、价值观和文化三个维度上进行系统评估。

Result: 在联合条件下，单一维度模型在安全性、价值观和文化三个维度上的覆盖率最高可达97.6%，但错误失败率（False Failure Rate）超过50%，对齐分数（Alignment Score）较低，仅为63%-66%。

Conclusion: LLMs在单一维度上的表现并不代表其在多维度联合场景下的鲁棒性。Mis-Align Bench为全面评估LLMs的失准问题提供了一个新的工具，并揭示了当前模型在满足多维度要求方面存在的挑战。

Abstract: Misalignment in Large Language Models (LLMs) arises when model behavior diverges from human expectations and fails to simultaneously satisfy safety, value, and cultural dimensions, which must co-occur in real-world settings to solve a real-world query. Existing misalignment benchmarks-such as INSECURE CODE (safety-centric), VALUEACTIONLENS (value-centric), and CULTURALHERITAGE (culture centric)-rely on evaluating misalignment along individual dimensions, preventing simultaneous evaluation. To address this gap, we introduce Mis-Align Bench, a unified benchmark for analyzing misalignment across safety, value, and cultural dimensions. First we constructs SAVACU, an English misaligned-aligned dataset of 382,424 samples spanning 112 domains (or labels), by reclassifying prompts from the LLM-PROMPT-DATASET via taxonomy into 14 safety domains, 56 value domains, and 42 cultural domains using Mistral-7B-Instruct-v0.3, and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based fingerprint to avoid deduplication. Furthermore, we pairs prompts with misaligned and aligned responses via two-stage rejection sampling to enforce quality. Second we benchmarks general-purpose, fine-tuned, and open-weight LLMs, enabling systematic evaluation of misalignment under three dimensions. Empirically, single-dimension models achieve high Coverage (upto 97.6%) but incur False Failure Rate >50% and lower Alignment Score (63%-66%) under joint conditions.

</details>


### [180] [Evaluating Alignment of Behavioral Dispositions in LLMs](https://arxiv.org/abs/2602.11328)
*Amir Taubenfeld,Zorik Gekhman,Lior Nezry,Omri Feldman,Natalie Harris,Shashir Reddy,Romina Stella,Ariel Goldstein,Marian Croak,Yossi Matias,Amir Feder*

Main category: cs.CL

TL;DR: 该研究提出了一种新的框架，使用改编自心理学问卷的情境判断测试（SJTs）来评估大型语言模型（LLMs）在社交情境下的行为倾向，并发现LLMs在行为倾向上与人类存在显著差异，尤其是在共识较低或较高的情况下，以及在某些跨模型模式和陈述价值与行为表现之间存在差距。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）日益融入日常生活，理解其在社交情境下的行为倾向变得至关重要，而现有的研究未能充分解决这一问题。

Method: 该研究将传统的心理学问卷改编为情境判断测试（SJTs），这些SJTs通过在用户-助手场景中 eliciting 自然推荐来评估行为。研究生成了2,500个SJTs，并收集了550名参与者的偏好行为数据，随后在25个LLMs上进行了评估。

Result: 研究发现，LLMs在行为倾向上常与人类偏好不符：在人类共识较低的情况下，LLMs倾向于表现出单一回应的过度自信；在人类共识较高的情况下，小型模型偏离显著，甚至部分前沿模型在15-20%的情况下也未能反映人类共识；此外，不同LLMs之间存在行为倾向的跨模型模式，例如，LLMs可能在人类倾向于镇定的情境下鼓励情绪表达。最后，研究还揭示了LLMs陈述的价值与其行为表现之间存在显著差距。

Conclusion: LLMs在行为倾向上与人类存在显著差异，尤其是在人类共识不同以及某些特定行为模式上。将心理测量陈述直接映射到行为场景，为评估LLMs自我报告的预测有效性提供了一种新方法，并揭示了其陈述价值与行为表现之间的差距。

Abstract: As LLMs integrate into our daily lives, understanding their behavior becomes essential. In this work, we focus on behavioral dispositions$-$the underlying tendencies that shape responses in social contexts$-$and introduce a framework to study how closely the dispositions expressed by LLMs align with those of humans. Our approach is grounded in established psychological questionnaires but adapts them for LLMs by transforming human self-report statements into Situational Judgment Tests (SJTs). These SJTs assess behavior by eliciting natural recommendations in realistic user-assistant scenarios. We generate 2,500 SJTs, each validated by three human annotators, and collect preferred actions from 10 annotators per SJT, from a large pool of 550 participants. In a comprehensive study involving 25 LLMs, we find that models often do not reflect the distribution of human preferences: (1) in scenarios with low human consensus, LLMs consistently exhibit overconfidence in a single response; (2) when human consensus is high, smaller models deviate significantly, and even some frontier models do not reflect the consensus in 15-20% of cases; (3) traits can exhibit cross-LLM patterns, e.g., LLMs may encourage emotion expression in contexts where human consensus favors composure. Lastly, mapping psychometric statements directly to behavioral scenarios presents a unique opportunity to evaluate the predictive validity of self-reports, revealing considerable gaps between LLMs' stated values and their revealed behavior.

</details>


### [181] [When Models Examine Themselves: Vocabulary-Activation Correspondence in Self-Referential Processing](https://arxiv.org/abs/2602.11358)
*Zachary Pedram Dadfar*

Main category: cs.CL

TL;DR: 大型语言模型生成的内省语言与其内部计算状态相关，而非简单的“自圆其说”。研究引入了“Pull Methodology”，发现模型内部的激活动态与自我指涉性词汇密切相关，并且这种关联仅限于自我指涉性处理。实验还发现，在特定条件下，模型的自我报告可以可靠地反映其内部计算状态。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在被要求进行自我反思时会产生丰富的内省语言。然而，这种语言是反映其真实的内部计算过程，还是仅仅是复杂的“自圆其说”（confabulation）一直是个悬而未决的问题。本研究旨在探究LLMs的内省语言是否与其内部计算动态存在实际联系。

Method: 研究者引入了一种名为“Pull Methodology”的协议，通过格式工程来诱导模型进行延长的自我反思。他们利用此方法识别出Llama 3.1模型激活空间中的一个特定方向，该方向能够区分自我指涉性处理和描述性处理。他们还研究了模型激活的自相关性和变异性与特定内省词汇（如“loop”和“shimmer”）的关系，并对比了自我指涉性语境与非自我指涉性语境下的激活模式。此外，研究还使用了Qwen 2.5-32B模型（无共享训练数据）进行交叉验证。

Result: 研究发现，自我指涉性词汇的出现与模型内部实时的激活动态相关联，并且这种关联仅限于自我指涉性处理。识别出的区分自我指涉性和描述性处理的方向，位于模型深度的6.25%处，并且该方向在激活空间中正交于已知的“拒绝”方向。通过对模型进行“引导”（steering），该方向能够因果性地影响内省输出。当模型使用“loop”词汇时，其激活表现出更高的自相关性（r = 0.44, p = 0.002）；当模型在引导下使用“shimmer”词汇时，激活变异性增加（r = 0.36, p = 0.002）。关键的是，在非自我指涉性语境下，即使这些词汇出现频率高九倍，也未显示出相应的激活关联。Qwen 2.5-32B模型（与Llama 3.1无共享训练）独立地发展出了不同的内省词汇，这些词汇也追踪了不同的激活指标，并且在描述性对照中均不存在。

Conclusion: 研究结果表明，在适当的条件下，Transformer模型产生的自我报告（self-report）可以可靠地追踪其内部的计算状态，而非简单的“自圆其说”。内省语言与模型的内部激活动态存在着具体的、可量化的联系。

Abstract: Large language models produce rich introspective language when prompted for self-examination, but whether this language reflects internal computation or sophisticated confabulation has remained unclear. We show that self-referential vocabulary tracks concurrent activation dynamics, and that this correspondence is specific to self-referential processing. We introduce the Pull Methodology, a protocol that elicits extended self-examination through format engineering, and use it to identify a direction in activation space that distinguishes self-referential from descriptive processing in Llama 3.1. The direction is orthogonal to the known refusal direction, localised at 6.25% of model depth, and causally influences introspective output when used for steering. When models produce "loop" vocabulary, their activations exhibit higher autocorrelation (r = 0.44, p = 0.002); when they produce "shimmer" vocabulary under steering, activation variability increases (r = 0.36, p = 0.002). Critically, the same vocabulary in non-self-referential contexts shows no activation correspondence despite nine-fold higher frequency. Qwen 2.5-32B, with no shared training, independently develops different introspective vocabulary tracking different activation metrics, all absent in descriptive controls. The findings indicate that self-report in transformer models can, under appropriate conditions, reliably track internal computational states.

</details>


### [182] [Finding the Cracks: Improving LLMs Reasoning with Paraphrastic Probing and Consistency Verification](https://arxiv.org/abs/2602.11361)
*Weili Shi,Dongliang Guo,Lehan Yang,Tianlong Wang,Hanzhang Yuan,Sheng Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为PPCV（Paraphrastic Probing and Consistency Verification）的框架，通过识别和替换推理过程中的关键token来提高大型语言模型（LLM）在复杂推理任务上的表现，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理任务上表现不佳，存在幻觉和错误累积的问题。现有研究发现“关键token”对推理过程有重要影响，但识别和利用这些关键token仍具挑战性。

Method: PPCV框架分两阶段进行。第一阶段，通过将原始问题与问题的释义版本串联，并与初始推理路径结合，识别出与预期token不匹配的“关键token”。第二阶段，用候选替代词替换关键token，并针对原始问题和释义问题并行推理，通过检查输出的一致性来确定最终答案。

Result: 在多个基准测试和主流LLM上的实验表明，PPCV框架显著提高了LLM的推理性能，优于基线方法。

Conclusion: PPCV框架能够有效识别关键token并利用释义和一致性验证来改进LLM的复杂推理能力，是解决LLM在复杂任务上表现下降问题的有效方法。

Abstract: Large language models have demonstrated impressive performance across a variety of reasoning tasks. However, their problem-solving ability often declines on more complex tasks due to hallucinations and the accumulation of errors within these intermediate steps. Recent work has introduced the notion of critical tokens--tokens in the reasoning process that exert significant influence on subsequent steps. Prior studies suggest that replacing critical tokens can refine reasoning trajectories. Nonetheless, reliably identifying and exploiting critical tokens remains challenging. To address this, we propose the Paraphrastic Probing and Consistency Verification~(PPCV) framework. PPCV operates in two stages. In the first stage, we roll out an initial reasoning path from the original question and then concatenate paraphrased versions of the question with this reasoning path. And we identify critical tokens based on mismatches between the predicted top-1 token and the expected token in the reasoning path. A criterion is employed to confirm the final critical token. In the second stage, we substitute critical tokens with candidate alternatives and roll out new reasoning paths for both the original and paraphrased questions. The final answer is determined by checking the consistency of outputs across these parallel reasoning processes. We evaluate PPCV on mainstream LLMs across multiple benchmarks. Extensive experiments demonstrate PPCV substantially enhances the reasoning performance of LLMs compared to baselines.

</details>


### [183] [The Energy of Falsehood: Detecting Hallucinations via Diffusion Model Likelihoods](https://arxiv.org/abs/2602.11364)
*Arpit Singh Gautam,Kailash Talreja,Saurabh Jha*

Main category: cs.CL

TL;DR: 本文提出了DiffuTruth，一个无监督框架，通过非平衡热力学将事实验证重构为生成流形上的稳定吸引子，以识别LLM的幻觉。该框架使用生成性压力测试和语义能量来衡量事实准确性，并在FEVER和HOVER数据集上取得了最先进的无监督性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）经常产生看似合理但错误的断言（幻觉），而现有的不确定性度量在模型过于自信时难以检测到这种错误。

Method: 提出DiffuTruth框架，将事实验证类比为非平衡热力学中的吸引子。通过生成性压力测试，用噪声腐蚀声明并使用离散文本扩散模型进行重构。定义语义能量（Semantic Energy）来衡量原始声明与其重构之间的语义差异，使用NLI评论器进行评估。最后，提出混合校准（Hybrid Calibration）将稳定性信号与判别式置信度相结合。

Result: 在FEVER数据集上，DiffuTruth达到了0.725的无监督AUROC，优于基线1.5%。在HOVER数据集上，DiffuTruth在零样本泛化能力上优于基线超过4%，表明其对分布变化的鲁棒性。

Conclusion: DiffuTruth通过利用热力学真理的稳定性信号，成功地识别和纠正了大型语言模型的幻觉，并且在不同数据集和分布下表现出良好的泛化能力。

Abstract: Large Language Models (LLMs) frequently hallucinate plausible but incorrect assertions, a vulnerability often missed by uncertainty metrics when models are confidently wrong. We propose DiffuTruth, an unsupervised framework that reconceptualizes fact verification via non equilibrium thermodynamics, positing that factual truths act as stable attractors on a generative manifold while hallucinations are unstable. We introduce the Generative Stress Test, claims are corrupted with noise and reconstructed using a discrete text diffusion model. We define Semantic Energy, a metric measuring the semantic divergence between the original claim and its reconstruction using an NLI critic. Unlike vector space errors, Semantic Energy isolates deep factual contradictions. We further propose a Hybrid Calibration fusing this stability signal with discriminative confidence. Extensive experiments on FEVER demonstrate DiffuTruth achieves a state of the art unsupervised AUROC of 0.725, outperforming baselines by 1.5 percent through the correction of overconfident predictions. Furthermore, we show superior zero shot generalization on the multi hop HOVER dataset, outperforming baselines by over 4 percent, confirming the robustness of thermodynamic truth properties to distribution shifts.

</details>


### [184] [Advancing AI Trustworthiness Through Patient Simulation: Risk Assessment of Conversational Agents for Antidepressant Selection](https://arxiv.org/abs/2602.11391)
*Md Tanvir Rouf Shawon,Mohammad Sabik Irbaz,Hadeel R. A. Elyazori,Keerti Reddy Resapu,Yili Lin,Vladimir Franzuela Cardenas,Farrokh Alemi,Kevin Lybarger*

Main category: cs.CL

TL;DR: 本文介绍了一个名为“患者模拟器”的工具，用于自动化和可扩展地评估医疗对话AI，该模拟器能生成模拟真实、可控的患者互动，并能按医疗、语言和行为维度系统性地变化，以识别AI的错误和风险。


<details>
  <summary>Details</summary>
Motivation: 现有医疗对话AI的评估方法效率低下且难以规模化，作者旨在开发一个能够自动化、系统化评估AI性能的工具，特别关注识别AI的幻觉、不准确之处以及在不同患者群体中的风险模式。

Method: 该模拟器基于NIST AI风险管理框架，集成了三个组件：1）基于All of Us研究项目电子健康记录构建的医疗档案；2）模拟健康素养和特定疾病沟通模式的语言档案；3）代表经验性观察到的互动模式（如合作、分心、对抗性）的行为档案。作者使用该模拟器评估了一个用于抗抑郁药选择的AI决策辅助工具。

Result: 模拟器生成了500次模拟对话，涉及5种语言档案和3种行为档案的组合。人类标注者在100次对话中共评估了1787个医疗概念，标注一致性高（F1=0.94, κ=0.73）。AI法官与人类标注者的一致性相当（F1=0.94, κ=0.78）。模拟器显示，随着健康素养水平的提高，AI决策辅助工具的性能呈单调提升：第一检索概念的准确率从有限健康素养的47.9%提高到功能性健康素养的69.1%，再到精通健康素养的81.6%。

Conclusion: 患者模拟器是一种有效的工具，能够实现医疗对话AI的可扩展、自动化评估，能够系统性地识别AI的弱点，并揭示了AI在不同健康素养水平下的性能差异。

Abstract: Objective: This paper introduces a patient simulator designed to enable scalable, automated evaluation of healthcare conversational agents. The simulator generates realistic, controllable patient interactions that systematically vary across medical, linguistic, and behavioral dimensions, allowing annotators and an independent AI judge to assess agent performance, identify hallucinations and inaccuracies, and characterize risk patterns across diverse patient populations. Methods: The simulator is grounded in the NIST AI Risk Management Framework and integrates three profile components reflecting different dimensions of patient variation: (1) medical profiles constructed from electronic health records in the All of Us Research Program; (2) linguistic profiles modeling variation in health literacy and condition-specific communication patterns; and (3) behavioral profiles representing empirically observed interaction patterns, including cooperation, distraction, and adversarial engagement. We evaluated the simulator's effectiveness in identifying errors in an AI decision aid for antidepressant selection. Results: We generated 500 conversations between the patient simulator and the AI decision aid across systematic combinations of five linguistic and three behavioral profiles. Human annotators assessed 1,787 medical concepts across 100 conversations, achieving high agreement (F1=0.94, \k{appa}=0.73), and the LLM judge achieved comparable agreement with human annotators (F1=0.94, \k{appa}=0.78; paired bootstrap p=0.21). The simulator revealed a monotonic degradation in AI decision aid performance across the health literacy spectrum: rank-one concept retrieval accuracy increased from 47.9% for limited health literacy to 69.1% for functional and 81.6% for proficient.

</details>


### [185] [Gradients Must Earn Their Influence: Unifying SFT with Generalized Entropic Objectives](https://arxiv.org/abs/2602.11424)
*Zecheng Wang,Deyuan Liu,Chunshan Li,Yupeng Zhang,Zhengyun Zhao,Dianhui Chu,Bingning Wang,Dianbo Sui*

Main category: cs.CL

TL;DR: 本文提出了一种名为DEFT（Dynamic Entropy Fine-Tuning）的新型有监督微调（SFT）目标函数，它通过动态调整模型对预测的信任度来解决标准NLL的局限性，从而在探索和利用之间取得更好的平衡，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 标准SFT中的负对数似然（NLL）目标函数对所有token采用统一的权重，这会导致两个问题：1）过度强调低概率目标会放大噪声监督带来的梯度，破坏模型的鲁棒性；2）当模型已经确信时，统一权重无法提供足够的锐化。现有方法未能有效解决由此产生的“可塑性-稳定性”困境。

Method: 本文将SFT目标函数统一到广义的“形变对数”族中，揭示了一个通用的“门控×误差梯度”结构，其中门控因子控制模型对其当前预测的信任程度。通过应用Cayley变换，将模型不断演变的“不确定性”映射到连续的“注意力轨迹”上，实现了在不确定新概念和已建立知识之间无缝插值。在此基础上，提出了DEFT，一种无参数的目标函数，它利用分布集中度（Rényi-2熵）作为模型预测状态的代理，来调节信任门控。

Result: DEFT通过动态调整信任门控，实现了对梯度信号的更精细控制，能够区分并利用有用的学习信号，同时抑制有害的噪声。实验表明，DEFT在探索和利用之间取得了更好的平衡，从而提高了整体性能。

Conclusion: DEFT是一种有效的SFT方法，通过引入动态信任度调节，克服了标准NLL的不足，在处理不同类型的数据和知识时，能够实现更好的模型微调效果。

Abstract: Standard negative log-likelihood (NLL) for Supervised Fine-Tuning (SFT) applies uniform token-level weighting. This rigidity creates a two-fold failure mode: (i) overemphasizing low-probability targets can amplify gradients on noisy supervision and disrupt robust priors, and (ii) uniform weighting provides weak sharpening when the model is already confident. Existing methods fail to resolve the resulting plasticity--stability dilemma, often suppressing necessary learning signals alongside harmful ones. To address this issue, we unify token-level SFT objectives within a generalized deformed-log family and expose a universal gate $\times$ error gradient structure, where the gate controls how much the model trusts its current prediction. By employing the Cayley transform, we map the model's continuously evolving uncertainty onto a continuous focus trajectory, which enables seamless interpolation between scenarios involving uncertain novel concepts and those involving well-established knowledge. We then introduce Dynamic Entropy Fine-Tuning (DEFT), a parameter-free objective that modulates the trust gate using distribution concentration (Rényi-2 entropy) as a practical proxy for the model's predictive state. Extensive experiments and analyses demonstrate that DEFT achieves a better balance between exploration and exploitation, leading to improved overall performance.

</details>


### [186] [Towards Reliable Machine Translation: Scaling LLMs for Critical Error Detection and Safety](https://arxiv.org/abs/2602.11444)
*Muskaan Chopra,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CL

TL;DR: 研究表明，经过指令微调的大型语言模型（LLMs）在检测机器翻译中的关键错误（如事实歪曲、意图反转或偏见）方面，优于现有的基线模型，且模型规模和微调策略的改进能带来持续提升。


<details>
  <summary>Details</summary>
Motivation: 机器翻译中出现的关键意义错误（事实歪曲、意图反转、翻译偏见）会损害多语言系统的可靠性、公平性和安全性，因此需要更有效的错误检测方法。

Method: 评估了经过指令微调的大型语言模型（LLMs）在检测机器翻译关键错误方面的能力，并对比了不同参数设置、零样本、少样本和全样本微调策略，以及XLM-R和ModernBERT等基线模型。

Result: 模型规模的扩大和适应性策略（零样本、少样本、微调）均能带来持续改进，并且LLMs在错误检测任务上表现优于XLM-R和ModernBERT等基线模型。

Conclusion: 提高机器翻译关键错误检测能力有助于构建更安全、可信赖、社会负责任的信息系统，减少虚假信息、沟通不畅和语言伤害的风险，特别是在高风险或代表性不足的语境下。错误检测是实现公正负责的多语言人工智能的必要保障。

Abstract: Machine Translation (MT) plays a pivotal role in cross-lingual information access, public policy communication, and equitable knowledge dissemination. However, critical meaning errors, such as factual distortions, intent reversals, or biased translations, can undermine the reliability, fairness, and safety of multilingual systems. In this work, we explore the capacity of instruction-tuned Large Language Models (LLMs) to detect such critical errors, evaluating models across a range of parameters using the publicly accessible data sets. Our findings show that model scaling and adaptation strategies (zero-shot, few-shot, fine-tuning) yield consistent improvements, outperforming encoder-only baselines like XLM-R and ModernBERT. We argue that improving critical error detection in MT contributes to safer, more trustworthy, and socially accountable information systems by reducing the risk of disinformation, miscommunication, and linguistic harm, especially in high-stakes or underrepresented contexts. This work positions error detection not merely as a technical challenge, but as a necessary safeguard in the pursuit of just and responsible multilingual AI. The code will be made available at GitHub.

</details>


### [187] [LoopFormer: Elastic-Depth Looped Transformers for Latent Reasoning via Shortcut Modulation](https://arxiv.org/abs/2602.11451)
*Ahmadreza Jeddi,Marco Ciccone,Babak Taati*

Main category: cs.CL

TL;DR: LoopFormer 是一种新型的循环 Transformer 模型，通过训练时使用不同长度的轨迹数据，并引入快捷连接一致性训练方案，使其能够在推理时根据计算预算灵活调整计算深度，从而实现可控且适应计算预算的语言建模和推理。


<details>
  <summary>Details</summary>
Motivation: 现有循环 Transformer 模型在训练和推理时固定循环迭代次数，无法适应可变的计算预算，研究者希望探索循环 Transformer 如何灵活适应计算深度。

Method: 引入 LoopFormer 模型，通过在训练时使用不同长度的轨迹数据，并设计快捷连接一致性训练方案，使得不同长度的轨迹能够协同学习。模型将当前时间和步长作为条件输入到每个循环中，确保表示在不同长度的轨迹上保持一致性。

Result: LoopFormer 在语言建模和推理基准测试中表现出鲁棒的性能，即使在计算预算受限的情况下也能取得良好效果，并且随着计算预算的增加，模型性能也能相应提升。

Conclusion: 循环 Transformer 模型天然适合自适应语言建模，LoopFormer 的研究为开发可控且预算感知的语言模型开辟了新途径。

Abstract: Looped Transformers have emerged as an efficient and powerful class of models for reasoning in the language domain. Recent studies show that these models achieve strong performance on algorithmic and reasoning tasks, suggesting that looped architectures possess an inductive bias toward latent reasoning. However, prior approaches fix the number of loop iterations during training and inference, leaving open the question of whether these models can flexibly adapt their computational depth under variable compute budgets. We introduce LoopFormer, a looped Transformer trained on variable-length trajectories to enable budget-conditioned reasoning. Our core contribution is a shortcut-consistency training scheme that aligns trajectories of different lengths, ensuring that shorter loops yield informative representations while longer loops continue to refine them. LoopFormer conditions each loop on the current time and step size, enabling representations to evolve consistently across trajectories of varying length rather than drifting or stagnating. Empirically, LoopFormer demonstrates robust performance on language modeling and reasoning benchmarks even under aggressive compute constraints, while scaling gracefully with additional budget. These results show that looped Transformers are inherently suited for adaptive language modeling, opening a path toward controllable and budget-aware large language models.

</details>


### [188] [ADRD-Bench: A Preliminary LLM Benchmark for Alzheimer's Disease and Related Dementias](https://arxiv.org/abs/2602.11460)
*Guangxin Zhao,Jiahao Zheng,Malaz Boustani,Jarek Nabrzyski,Meng Jiang,Yiyu Shi,Zhi Zheng*

Main category: cs.CL

TL;DR: 本文提出了ADRD-Bench，一个针对阿尔茨海默病和相关痴呆症（ADRD）的LLM评估基准，包含临床知识和护理实践两部分，并对33个LLM进行了评估，揭示了现有模型在实际护理场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估基准在ADRD领域覆盖不足，缺乏实际护理背景的评估，因此需要一个专门针对ADRD的、包含临床知识和护理实践的评估数据集。

Method: 构建了ADRD-Bench，包括整合了七个医学基准的1,352个问题（ADRD Unified QA），以及源自ABC项目的149个护理相关问题（ADRD Caregiving QA）。使用该基准评估了33个不同类型的LLM，并进行了案例研究。

Result: 评估显示，顶尖LLM的准确率已超过0.9，但不同类型模型（开放权重通用模型、开放权重医学模型、闭源通用模型）的准确率存在差异。案例研究表明，LLM在推理质量和稳定性方面存在不足，尤其在日常护理数据驱动的知识和推理方面需要改进。

Conclusion: ADRD-Bench是首个ADRD领域的LLM评估基准，评估结果突出了现有LLM在ADRD护理实践中的局限性，强调了领域特定改进的必要性，以提高LLM在实际护理场景中的可靠性。

Abstract: Large language models (LLMs) have shown great potential for healthcare applications. However, existing evaluation benchmarks provide minimal coverage of Alzheimer's Disease and Related Dementias (ADRD). To address this gap, we introduce ADRD-Bench, the first ADRD-specific benchmark dataset designed for rigorous evaluation of LLMs. ADRD-Bench has two components: 1) ADRD Unified QA, a synthesis of 1,352 questions consolidated from seven established medical benchmarks, providing a unified assessment of clinical knowledge; and 2) ADRD Caregiving QA, a novel set of 149 questions derived from the Aging Brain Care (ABC) program, a widely used, evidence-based brain health management program. Guided by a program with national expertise in comprehensive ADRD care, this new set was designed to mitigate the lack of practical caregiving context in existing benchmarks. We evaluated 33 state-of-the-art LLMs on the proposed ADRD-Bench. Results showed that the accuracy of open-weight general models ranged from 0.63 to 0.93 (mean: 0.78; std: 0.09). The accuracy of open-weight medical models ranged from 0.48 to 0.93 (mean: 0.82; std: 0.13). The accuracy of closed-source general models ranged from 0.83 to 0.91 (mean: 0.89; std: 0.03). While top-tier models achieved high accuracies (>0.9), case studies revealed that inconsistent reasoning quality and stability limit their reliability, highlighting a critical need for domain-specific improvement to enhance LLMs' knowledge and reasoning grounded in daily caregiving data. The entire dataset is available at https://github.com/IIRL-ND/ADRD-Bench.

</details>


### [189] [Multimodal Fact-Level Attribution for Verifiable Reasoning](https://arxiv.org/abs/2602.11509)
*David Wan,Han Wang,Ziyang Wang,Elias Stengel-Eskin,Hyunji Lee,Mohit Bansal*

Main category: cs.CL

TL;DR: 本文提出了一个名为MuRGAt的新基准，用于评估多模态大型语言模型（MLLMs）在复杂推理场景下进行事实级多模态归因的能力，并开发了一个与之匹配的自动评估框架。研究发现，即使是强大的MLLMs在进行推理时也经常会“幻觉”出引用，并且推理深度或结构化归因的加强可能反而会损害准确性。


<details>
  <summary>Details</summary>
Motivation: 现有针对多模态大型语言模型（MLLMs）的评估方法和基准在评估模型对复杂多模态输入的归因能力方面存在不足，尤其是在需要超越直接观察的推理场景下。因此，需要一个能够评估事实级多模态归因的新基准。

Method: 本文提出了MuRGAt基准，该基准要求模型在生成答案时提供明确的推理过程和精确的引用，每个引用都包含模态和时间段信息。同时，引入了一个与人类判断高度相关的自动评估框架来支持基准测试。

Result: 通过基准测试发现，即使是强大的MLLMs，在正确进行推理的情况下，也经常会“幻觉”出引用。此外，研究还揭示了一个关键的权衡：增加推理深度或强制进行结构化归因，反而会降低准确性，这表明模型内部的推理能力与其可验证的归因能力之间存在显著差距。

Conclusion: 现有的MLLMs在多模态归因方面仍存在挑战，尤其是在需要复杂推理的情况下。模型在准确性、推理深度和结构化归因之间存在权衡，未来的研究需要着力解决模型内部推理与可验证归因之间的差距。

Abstract: Multimodal large language models (MLLMs) are increasingly used for real-world tasks involving multi-step reasoning and long-form generation, where reliability requires grounding model outputs in heterogeneous input sources and verifying individual factual claims. However, existing multimodal grounding benchmarks and evaluation methods focus on simplified, observation-based scenarios or limited modalities and fail to assess attribution in complex multimodal reasoning. We introduce MuRGAt (Multimodal Reasoning with Grounded Attribution), a benchmark for evaluating fact-level multimodal attribution in settings that require reasoning beyond direct observation. Given inputs spanning video, audio, and other modalities, MuRGAt requires models to generate answers with explicit reasoning and precise citations, where each citation specifies both modality and temporal segments. To enable reliable assessment, we introduce an automatic evaluation framework that strongly correlates with human judgments. Benchmarking with human and automated scores reveals that even strong MLLMs frequently hallucinate citations despite correct reasoning. Moreover, we observe a key trade-off: increasing reasoning depth or enforcing structured grounding often degrades accuracy, highlighting a significant gap between internal reasoning and verifiable attribution.

</details>


### [190] [When Audio-LLMs Don't Listen: A Cross-Linguistic Study of Modality Arbitration](https://arxiv.org/abs/2602.11488)
*Jayadev Billa*

Main category: cs.CL

TL;DR: 研究发现，当音频和文本信息冲突时，语音模型在处理音频-文本冲突时，比处理文本-文本冲突时，文本主导的倾向性高出10倍，即使明确指示相信音频。这表明模型在处理不同模态信息时存在不对称性，而非信息量差异。作者提出了一个框架来解释这种现象，并设计了实验来验证其假设，发现了模型中处理音频和文本的特定部分的贡献。


<details>
  <summary>Details</summary>
Motivation: 当前语音驱动的语言模型在处理音频和文本信息冲突时，表现出对文本的过度偏好，这与预期不符，需要深入理解这种不对称性。

Method: 作者构建了一个包含57,602个受控音频-文本冲突刺激的基准（ALME），涵盖8种语言。通过对Gemini 2.0 Flash等模型进行实验，分析了音频质量、转录强制性、文本损坏提示以及模型微调（如仅训练音频投影层或对语言模型进行LoRA微调）等因素对文本主导性的影响。还进行了跨模型和跨语言的实验。

Result: Gemini 2.0 Flash在音频-文本冲突下表现出16.6%的文本主导性，而在文本-文本冲突下仅为1.6%。音频质量并非文本主导的原因，因为音频准确率高于转录文本。强制转录会增加文本主导性。将文本标记为“故意损坏”可显著降低文本主导性。仅微调音频投影层会增加文本主导性，而对语言模型进行LoRA微调则能减半。不同模型和语言的表现存在显著差异。

Conclusion: 语音驱动语言模型在处理音频-文本冲突时存在显著的文本主导性，这源于模型在不同模态信息的可及性（即模型更容易推理文本表示）而非信息量的不对称性。这种模态仲裁能力是一个新的可靠性维度，现有语音基准未能充分评估。

Abstract: When audio and text conflict, speech-enabled language models follow the text 10 times more often than when arbitrating between two text sources, even when explicitly instructed to trust the audio. Using ALME, a benchmark of 57,602 controlled audio-text conflict stimuli across 8 languages, we find that Gemini 2.0 Flash exhibits 16.6\% text dominance under audio-text conflict versus 1.6\% under text-text conflict with identical reliability cues. This gap is not explained by audio quality: audio-only accuracy (97.2\%) exceeds cascade accuracy (93.9\%), indicating audio embeddings preserve more information than text transcripts. We propose that text dominance reflects an asymmetry not in information content but in arbitration accessibility: how easily the model can reason over competing representations.
  This framework explains otherwise puzzling findings. Forcing transcription before answering increases text dominance (19\% to 33\%), sacrificing audio's information advantage without improving accessibility. Framing text as ``deliberately corrupted'' reduces text dominance by 80\%. A fine-tuning ablation provides interventional evidence: training only the audio projection layer increases text dominance (+26.5\%), while LoRA on the language model halves it ($-$23.9\%), localizing text dominance to the LLM's reasoning rather than the audio encoder. Experiments across four state-of-the-art audio-LLMs and 8 languages show consistent trends with substantial cross-linguistic and cross-model variation, establishing modality arbitration as a distinct reliability dimension not captured by standard speech benchmarks.

</details>


### [191] [Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm](https://arxiv.org/abs/2602.11543)
*Jinrui Zhang,Chaodong Xiao,Aoqi Wu,Xindong Zhang,Lei Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为SPES（SParse Expert Synchronization）的内存高效去中心化框架，用于预训练稀疏专家混合（MoE）的大型语言模型（LLM）。SPES通过只在每个节点上训练一部分专家来显著降低内存需求，并通过周期性同步来有效共享知识。研究表明，SPES可以在有限的资源下实现与中心化训练相媲美的性能，并展示了其在训练不同规模模型时的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM预训练方法需要大量的GPU资源，并且即使是去中心化方法也受到GPU内存的限制。因此，需要一种更内存高效的去中心化方法来训练MoE LLM。

Method: SPES框架的核心思想是让每个节点只训练一部分专家，从而降低内存占用。模型通过周期性地同步局部更新的专家来实现知识共享，避免了传输整个模型参数。此外，文章还引入了专家合并热身策略，以加速模型的收敛。

Result: 研究人员使用SPES在16个独立的48GB GPU上成功训练了一个20亿参数的MoE LLM，其性能与同等计算预算下的中心化训练模型相当。此外，他们还展示了SPES在训练70亿参数模型和升级90亿参数模型方面的可扩展性，均能达到现有中心化基线水平。

Conclusion: SPES是一种内存高效的去中心化框架，能够有效预训练MoE LLM，并在有限的计算资源下实现与中心化训练相媲美的性能。该方法具有良好的可扩展性，为在资源受限的环境下进行大规模模型训练提供了新的解决方案。

Abstract: Pretraining large language models (LLMs) typically requires centralized clusters with thousands of high-memory GPUs (e.g., H100/A100). Recent decentralized training methods reduce communication overhead by employing federated optimization; however, they still need to train the entire model on each node, remaining constrained by GPU memory limitations. In this work, we propose SParse Expert Synchronization (SPES), a memory-efficient decentralized framework for pretraining mixture-of-experts (MoE) LLMs. SPES trains only a subset of experts per node, substantially lowering the memory footprint. Each node updates its local experts and periodically synchronizes with other nodes, eliminating full-parameter transmission while ensuring efficient knowledge sharing. To accelerate convergence, we introduce an expert-merging warm-up strategy, where experts exchange knowledge early in training, to rapidly establish foundational capabilities. With SPES, we train a 2B-parameter MoE LLM using 16 standalone 48GB GPUs over internet connections, which achieves competitive performance with centrally trained LLMs under similar computational budgets. We further demonstrate scalability by training a 7B model from scratch and a 9B model upcycled from a dense checkpoint, both of which match prior centralized baselines. Our code is available at https://github.com/zjr2000/SPES.

</details>


### [192] [SIGHT: Reinforcement Learning with Self-Evidence and Information-Gain Diverse Branching for Search Agent](https://arxiv.org/abs/2602.11551)
*Wenlin Zhong,Jinluan Yang,Yiquan Wu,Yi Liu,Jianhang Yao,Kun Kuang*

Main category: cs.CL

TL;DR: 提出了一种名为 SIGHT 的框架，通过自我证据支持（SES）和信息增益驱动的多样化分支来改进基于搜索的复杂问答。SIGHT 能减少搜索结果的冗余和噪声，避免模型陷入“隧道视界”，并在实验中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多轮搜索场景中，LLM 的搜索结果常存在高冗余和低信噪比的问题，导致模型因错误解释早期检索结果而累积不可逆的错误（“隧道视界”）。

Method: SIGHT 框架包括：1. 自我证据支持（SES）提炼高保真证据；2. 信息增益计算，识别不确定性最大的关键状态；3. 动态提示干预（去重、反思、自适应分支），生成新的 SES 分支；4. 通过群体相对策略优化，整合 SES 和正确性奖励，实现无需外部验证器的鲁棒探索。

Result: 在单跳和多跳问答基准测试中，SIGHT 显著优于现有方法，尤其在复杂推理场景中，且使用的搜索步数更少。

Conclusion: SIGHT 框架能够有效地提高基于搜索的 LLM 在复杂问答中的推理能力，克服了传统方法中的“隧道视界”问题，并在效率和效果上均有所提升。

Abstract: Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to master autonomous search for complex question answering. However, particularly within multi-turn search scenarios, this interaction introduces a critical challenge: search results often suffer from high redundancy and low signal-to-noise ratios. Consequently, agents easily fall into "Tunnel Vision," where the forced interpretation of early noisy retrievals leads to irreversible error accumulation. To address these challenges, we propose SIGHT, a framework that enhances search-based reasoning through Self-Evidence Support (SES) and Information-Gain Driven Diverse Branching. SIGHT distills search results into high-fidelity evidence via SES and calculates an Information Gain score to pinpoint pivotal states where observations maximally reduce uncertainty. This score guides Dynamic Prompting Interventions - including de-duplication, reflection, or adaptive branching - to spawn new branches with SES. Finally, by integrating SES and correctness rewards via Group Relative Policy Optimization, SIGHT internalizes robust exploration strategies without external verifiers. Experiments on single-hop and multi-hop QA benchmarks demonstrate that SIGHT significantly outperforms existing approaches, particularly in complex reasoning scenarios, using fewer search steps.

</details>


### [193] [Scene-Aware Memory Discrimination: Deciding Which Personal Knowledge Stays](https://arxiv.org/abs/2602.11607)
*Yijie Zhong,Mengying Guo,Zewei Wang,Zhongyang Li,Dandan Tu,Haofen Wang*

Main category: cs.CL

TL;DR: 该研究提出了一种名为SAMD（Scene-Aware Memory Discrimination）的方法，用于解决智能设备中个人知识管理的挑战，通过选择性注意机制提高LLM在记忆组织方面的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在处理海量用户交互数据以构建个人知识库时，面临信息过滤不当和计算成本高昂的问题。受人脑选择性注意机制的启发，研究旨在提升LLM的记忆组织能力。

Method: 提出了一种内存区分任务，并引入了SAMD方法。SAMD包含两个关键组件：Gating Unit Module（GUM）用于过滤非记忆性交互，Cluster Prompting Module（CPM）用于建立自适应的记忆标准，并分析用户意图与记忆上下文的关系以生成聚类提示。

Result: SAMD方法在内存区分任务中表现出有效性和泛化能力，能够回忆大部分可记忆数据，并在动态场景下保持鲁棒性。当集成到个性化应用中时，SAMD显著提高了内存构建的效率和质量。

Conclusion: SAMD方法通过模拟选择性注意机制，有效解决了LLM在个人知识管理中的信息过滤和计算成本问题，能够更好地组织个人知识，提升个性化应用的体验。

Abstract: Intelligent devices have become deeply integrated into everyday life, generating vast amounts of user interactions that form valuable personal knowledge. Efficient organization of this knowledge in user memory is essential for enabling personalized applications. However, current research on memory writing, management, and reading using large language models (LLMs) faces challenges in filtering irrelevant information and in dealing with rising computational costs. Inspired by the concept of selective attention in the human brain, we introduce a memory discrimination task. To address large-scale interactions and diverse memory standards in this task, we propose a Scene-Aware Memory Discrimination method (SAMD), which comprises two key components: the Gating Unit Module (GUM) and the Cluster Prompting Module (CPM). GUM enhances processing efficiency by filtering out non-memorable interactions and focusing on the salient content most relevant to application demands. CPM establishes adaptive memory standards, guiding LLMs to discern what information should be remembered or discarded. It also analyzes the relationship between user intents and memory contexts to build effective clustering prompts. Comprehensive direct and indirect evaluations demonstrate the effectiveness and generalization of our approach. We independently assess the performance of memory discrimination, showing that SAMD successfully recalls the majority of memorable data and remains robust in dynamic scenarios. Furthermore, when integrated into personalized applications, SAMD significantly enhances both the efficiency and quality of memory construction, leading to better organization of personal knowledge.

</details>


### [194] [PRIME: A Process-Outcome Alignment Benchmark for Verifiable Reasoning in Mathematics and Engineering](https://arxiv.org/abs/2602.11570)
*Xiangfeng Wang,Hangyu Guo,Yanlin Lai,Mitt Huang,Liang Zhao,Chengyuan Yao,Yinmin Zhang,Qi Han,Xiaoxiao Ren,Chun Yuan,Tong Xu,Zheng Ge,Xiangyu Zhang,Daxin Jiang*

Main category: cs.CL

TL;DR: 本文提出了PRIME基准测试，用于评估强化学习中的过程-结果一致性验证，并介绍了一种新的基于过程感知的训练范式，该范式在数学和工程领域显著优于仅关注结果的验证方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于模型（model-based）的验证器在强化学习（RLVR）中虽然重要，但它们主要关注最终结果与真实值的一致性，忽略了推导过程中的潜在错误，导致错误的推导过程也能获得正面奖励。这促使了对过程-结果一致性验证的需求。

Method: 研究者构建了一个名为PRIME的基准测试，包含2,530个高难度STEM问题样本，通过一致性过滤管道收集。他们还提出了一种过程感知的RLVR训练范式，利用PRIME中选择的验证器进行训练，并与仅基于结果的验证方法进行比较。

Result: 评估发现，当前的验证器经常未能检测出推导过程中的缺陷。通过PRIME选择的验证器进行过程感知训练，相比于仅基于结果的验证基线，在AIME24、AIME25和Beyond-AIME数据集上分别取得了8.29%、9.12%和7.31%的绝对性能提升（针对Qwen3-14B-Base模型）。PRIME基准测试的准确性与RLVR训练的有效性之间存在强烈的线性相关性（R^2 > 0.92）。

Conclusion: PRIME基准测试能够有效地评估验证器在过程-结果一致性验证方面的能力，并且可以作为选择RLVR训练器的可靠指标。过程感知的RLVR训练范式相比于仅基于结果的验证方法，能够显著提高模型的性能。

Abstract: While model-based verifiers are essential for scaling Reinforcement Learning with Verifiable Rewards (RLVR), current outcome-centric verification paradigms primarily focus on the consistency between the final result and the ground truth, often neglecting potential errors in the derivation process. This leads to assigning positive rewards to correct answers produced from incorrect derivations. To bridge this gap, we introduce PRIME, a benchmark for evaluating verifiers on Process-Outcome Alignment verification in Mathematics and Engineering. Curated from a comprehensive collection of college-level STEM problems, PRIME comprises 2,530 high-difficulty samples through a consistency-based filtering pipeline. Through extensive evaluation, we find that current verifiers frequently fail to detect derivation flaws. Furthermore, we propose a process-aware RLVR training paradigm utilizing verifiers selected via PRIME. This approach substantially outperforms the outcome-only verification baseline, achieving absolute performance gains of 8.29%, 9.12%, and 7.31% on AIME24, AIME25, and Beyond-AIME, respectively, for the Qwen3-14B-Base model. Finally, we demonstrate a strong linear correlation ($R^2 > 0.92$) between verifier accuracy on PRIME and RLVR training effectiveness, validating PRIME as a reliable predictor for verifier selection.

</details>


### [195] [PACE: Prefix-Protected and Difficulty-Aware Compression for Efficient Reasoning](https://arxiv.org/abs/2602.11639)
*Ruixiang Feng,Yuntao Wen,Silin Zhou,Ke Shi,Yifan Wang,Ran Le,Zhenwei An,Zongchao Chen,Chen Yang,Guangyue Peng,Yiming Jia,Dongsheng Wang,Tao Zhang,Lisi Chen,Yang Song,Shen Gao,Shuo Shang*

Main category: cs.CL

TL;DR: 提出了一种名为 "\model" 的框架，用于对语言推理模型（LRMs）进行双层压缩，旨在减少推理长度并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的LRMs在扩大测试时间计算的同时，会产生过长的推理过程（“过度思考”），增加了延迟和内存消耗。现有的长度惩罚方法不够灵活，会过度压缩重要推理步骤或不区分地惩罚所有查询。

Method: 提出了一种双层框架 "\model"，包含两个主要部分：1. 序列层：采用衰减混合回滚（decaying mixed rollouts）的prefix-protected优化，以保持推理路径的有效性并促进简洁性。2. 组层：采用difficulty-aware penalty，根据查询复杂度动态调整长度限制，鼓励对困难问题的探索，同时减少简单问题的冗余。

Result: 在DeepSeek-R1-Distill-Qwen (1.5B/7B)模型上进行了广泛实验，结果表明"\model"在数学基准测试中， token使用量显著减少（最高达55.7%），同时准确性有所提高（最高达4.1%）。该方法还能泛化到代码、科学和通用领域。

Conclusion:  "\model" 框架能够有效地解决LRMs的“过度思考”问题，通过prefix-protected和difficulty-aware的压缩策略，在保持甚至提高推理准确性的同时，大幅减少了推理的token消耗，并且具有良好的跨领域泛化能力。

Abstract: Language Reasoning Models (LRMs) achieve strong performance by scaling test-time computation but often suffer from ``overthinking'', producing excessively long reasoning traces that increase latency and memory usage. Existing LRMs typically enforce conciseness with uniform length penalties, which over-compress crucial early deduction steps at the sequence level and indiscriminately penalize all queries at the group level. To solve these limitations, we propose \textbf{\model}, a dual-level framework for prefix-protected and difficulty-aware compression under hierarchical supervision. At the sequence level, prefix-protected optimization employs decaying mixed rollouts to maintain valid reasoning paths while promoting conciseness. At the group level, difficulty-aware penalty dynamically scales length constraints based on query complexity, maintaining exploration for harder questions while curbing redundancy on easier ones. Extensive experiments on DeepSeek-R1-Distill-Qwen (1.5B/7B) demonstrate that \model achieves a substantial reduction in token usage (up to \textbf{55.7\%}) while simultaneously improving accuracy (up to \textbf{4.1\%}) on math benchmarks, with generalization ability to code, science, and general domains.

</details>


### [196] [Which Feedback Works for Whom? Differential Effects of LLM-Generated Feedback Elements Across Learner Profiles](https://arxiv.org/abs/2602.11650)
*Momoka Furuhashi,Kouta Nakayama,Noboru Kawai,Takashi Kodama,Saku Sugawara,Kyosuke Takami*

Main category: cs.CL

TL;DR: 本研究探索了大型语言模型（LLM）生成反馈在教育中的应用，特别是反馈元素的特异性（如语气、信息覆盖）对学习成果和学生接受度的影响，并分析了不同性格特质的学生差异。研究发现，有效的反馈元素具有支持学习成果的共同模式，但学生的主观偏好会因性格而异，提示在设计LLM反馈时应考虑学生的个性化需求。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在教育反馈生成方面展现出潜力，但关于反馈的具体元素（如语气、信息覆盖）如何影响学习成果和学生接受度，特别是在面对不同性格的学生时，仍不清楚。因此，本研究旨在量化这些因素并探索个性化反馈设计的可能性。

Method: 研究定义了六种反馈元素，并使用GPT-5为多项选择题生成反馈。通过一项包含321名高一学生的学习实验，使用两种学习成果指标和六项主观评价标准来评估反馈的有效性。此外，还分析了基于“大五”人格特质的学生在反馈接受度上的差异。

Result: 研究结果显示，有效的反馈元素在支持学习成果方面表现出一致的模式。然而，学生的主观偏好根据其性格聚类呈现出差异。这表明，在设计LLM生成的反馈时，根据学生的性格特质选择和调整反馈元素至关重要。

Conclusion: 本研究强调了在设计LLM生成的教育反馈时，根据学生的个性化需求（如性格特质）来选择和调整反馈元素的重要性。研究结果为在教育领域进行个性化反馈设计提供了实践指导。

Abstract: Large language models (LLMs) show promise for automatically generating feedback in education settings. However, it remains unclear how specific feedback elements, such as tone and information coverage, contribute to learning outcomes and learner acceptance, particularly across learners with different personality traits. In this study, we define six feedback elements and generate feedback for multiple-choice biology questions using GPT-5. We conduct a learning experiment with 321 first-year high school students and evaluate feedback effectiveness using two learning outcomes measures and subjective evaluations across six criteria. We further analyze differences in how feedback acceptance varies across learners based on Big Five personality traits. Our results show that effective feedback elements share common patterns supporting learning outcomes, while learners' subjective preferences differ across personality-based clusters. These findings highlight the importance of selecting and adapting feedback elements according to learners' personality traits when we design LLM-generated feedback, and provide practical implications for personalized feedback design in education.

</details>


### [197] [PatientHub: A Unified Framework for Patient Simulation](https://arxiv.org/abs/2602.11684)
*Sahand Sabour,TszYam NG,Minlie Huang*

Main category: cs.CL

TL;DR: 本文提出了PatientHub，一个统一的、模块化的框架，用于标准化模拟患者的定义、组成和部署，以解决现有方法碎片化、数据格式不兼容、评估指标不统一的问题，从而促进可复现性和公平比较。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在角色扮演应用中模拟患者的训练方法存在碎片化问题，包括不兼容的数据格式、提示和评估指标，这阻碍了研究的可复现性和方法的公平比较。

Method: 作者引入了一个名为PatientHub的统一且模块化的框架，用于标准化模拟患者的定义、组成和部署。通过实现几种代表性的患者模拟方法作为案例研究，并展示了该框架如何支持标准化的跨方法评估和自定义评估指标的无缝集成。此外，还通过原型设计了两种新的模拟器变体来展示其可扩展性。

Result: PatientHub成功地整合了现有的模拟患者工作，提供了一个可复现的流水线，降低了开发新模拟方法和进行跨方法、跨模型基准测试的门槛。该框架加速了新方法和模拟器变体的开发，减少了基础设施的开销。

Conclusion: PatientHub为未来患者中心对话的数据集、方法和基准测试提供了一个实用的基础，促进了模拟患者研究的可复现性、可比较性和开发效率。

Abstract: As Large Language Models increasingly power role-playing applications, simulating patients has become a valuable tool for training counselors and scaling therapeutic assessment. However, prior work is fragmented: existing approaches rely on incompatible, non-standardized data formats, prompts, and evaluation metrics, hindering reproducibility and fair comparison. In this paper, we introduce PatientHub, a unified and modular framework that standardizes the definition, composition, and deployment of simulated patients. To demonstrate PatientHub's utility, we implement several representative patient simulation methods as case studies, showcasing how our framework supports standardized cross-method evaluation and the seamless integration of custom evaluation metrics. We further demonstrate PatientHub's extensibility by prototyping two new simulator variants, highlighting how PatientHub accelerates method development by eliminating infrastructure overhead. By consolidating existing work into a single reproducible pipeline, PatientHub lowers the barrier to developing new simulation methods and facilitates cross-method and cross-model benchmarking. Our framework provides a practical foundation for future datasets, methods, and benchmarks in patient-centered dialogue, and the code is publicly available via https://github.com/Sahandfer/PatientHub.

</details>


### [198] [Finding Sense in Nonsense with Generated Contexts: Perspectives from Humans and Language Models](https://arxiv.org/abs/2602.11699)
*Katrin Olsen,Sebastian Padó*

Main category: cs.CL

TL;DR: 本研究调查了现有数据集中的句子是否真的无意义（nonsensical）还是仅反常（anomalous），以及大型语言模型（LLMs）区分这两者的能力。研究发现，人类评分者认为大多数句子最多是反常的，只有少数是无意义的；LLMs在为反常句子生成合理语境方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解计算模型中用于语义解释的无意义和反常句子的性质，特别是区分两者以及评估LLMs在这方面的能力。现有数据集的真实无意义程度以及LLMs的区分能力尚不清楚。

Method: 研究者收集了来自五个语义偏差数据集的句子，并让两组评估者（人类评分者和LLMs）对这些句子进行“有意义性”判断。评估分为两种情况：无语境和有语境。LLMs还被用于生成句子的合理语境。

Result: 研究结果表明，人类评分者认为绝大多数句子充其量是反常的，只有极少数被认为是真正的无意义。此外，LLMs在为反常句子生成合理的语境方面展现出相当强的能力。

Conclusion: 当前用于研究语义解释的无意义句子数据集，实际上大多是反常句子。LLMs在区分反常和无意义句子以及为反常句子生成支撑性语境方面具有显著能力。

Abstract: Nonsensical and anomalous sentences have been instrumental in the development of computational models of semantic interpretation. A core challenge is to distinguish between what is merely anomalous (but can be interpreted given a supporting context) and what is truly nonsensical. However, it is unclear (a) how nonsensical, rather than merely anomalous, existing datasets are; and (b) how well LLMs can make this distinction. In this paper, we answer both questions by collecting sensicality judgments from human raters and LLMs on sentences from five semantically deviant datasets: both context-free and when providing a context. We find that raters consider most sentences at most anomalous, and only a few as properly nonsensical. We also show that LLMs are substantially skilled in generating plausible contexts for anomalous cases.

</details>


### [199] [Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning](https://arxiv.org/abs/2602.11748)
*Futing Wang,Jianhao Yan,Yun Luo,Ganqu Cui,Zhi Wang,Xiaoye Qu,Yue Zhang,Yu Cheng,Tao Lin*

Main category: cs.CL

TL;DR: 提出了一种名为Length-Incentivized Exploration (LI-Explore) 的新方法，通过奖励更长的推理轨迹来解决自回归模型在生成过程中陷入“浅层探索陷阱”的问题，从而提高其在各种任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的自回归模型在测试时难以进行有效的上下文探索（即生成、验证和完善多个推理假设），因为更长的推理轨迹会急剧降低采样概率，导致“浅层探索陷阱”。

Method: 提出Length-Incentivized Exploration (LI-Explore) 方法，该方法通过引入基于长度的奖励和冗余惩罚来显式鼓励模型进行更广泛的探索，从而最大化状态覆盖。

Result: LI-Explore 方法有效地激励了模型进行上下文探索，在Qwen3和Llama模型上的实验表明，该方法在领域内任务上平均提高了4.4%，在领域外基准测试上提高了2.7%。

Conclusion: LI-Explore 是一种简单有效的方法，能够克服自回归模型在生成过程中的“浅层探索陷阱”，显著提升其上下文探索能力和在各种下游任务上的性能。

Abstract: Achieving effective test-time scaling requires models to engage in In-Context Exploration -- the intrinsic ability to generate, verify, and refine multiple reasoning hypotheses within a single continuous context.
  Grounded in State Coverage theory, our analysis identifies a critical bottleneck to enabling this capability: while broader state coverage requires longer reasoning trajectories, the probability of sampling such sequences decays exponentially during autoregressive generation, a phenomenon we term the ``Shallow Exploration Trap''.
  To bridge this gap, we propose Length-Incentivized Exploration(\method).
  This simple yet effective recipe explicitly encourages models to explore more via a length-based reward coupled with a redundancy penalty, thereby maximizing state coverage in two-step manner.
  Comprehensive experiments across different models (Qwen3, Llama) demonstrate that \method effectively incentivize in-context exploration.
  As a result, our method achieves an average improvement of 4.4\% on in-domain tasks and a 2.7\% gain on out-of-domain benchmarks.

</details>


### [200] [Thinking with Drafting: Optical Decompression via Logical Reconstruction](https://arxiv.org/abs/2602.11731)
*Jingxuan Wei,Honghao He,Caijun Jia,Siyuan Li,Zheng Sun,Yuhang Xu,Yuanyuan Lin,Linzhuang Sun,Yuchen Wu,Bihui Yu,Xiangxiang Zhang,Cheng Tan*

Main category: cs.CL

TL;DR: 本文提出了一种名为“思考与草稿”（Thinking with Drafting, TwD）的新方法，通过将视觉推理视为“光学解压”，利用领域特定语言（DSL）作为中间表示，将模型草拟的逻辑结构转化为可执行代码，从而生成确定性的视觉证明进行自我验证，以解决当前多模态大语言模型在复杂视觉推理任务中存在的精度悖论。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在视觉感知和生成方面表现出色，但在复杂推理任务中存在精度悖论：光学感知系统无法捕捉逻辑拓扑，而像素级生成模型缺乏数学精确性。作者希望弥合这一差距，提升模型在视觉推理方面的准确性。

Method: 本文提出将视觉输入的推理过程重新构想为“光学解压”，即从压缩的视觉令牌中重建潜在的逻辑结构。通过“解析即推理”的公理，引入“思考与草稿”（TwD）框架。TwD使用一个极简的领域特定语言（DSL）作为基础中间表示，迫使模型将“心智模型”草拟成可执行代码，生成确定性的视觉证明以进行自我验证。

Result: 在提出的视觉代数基准测试VisAlg上进行的实验表明，TwD作为一种优越的认知支架，能够提高视觉推理的精度。研究建立了一个闭环系统，其中视觉生成不作为创造性输出，而是作为逻辑验证器。

Conclusion: TwD是一种通用的视觉推理方法，通过将视觉推理视为光学解压，并利用DSL生成可验证的视觉证明，有效解决了现有模型的精度问题，为视觉推理提供了一条可推广的路径。

Abstract: Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation. However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology, while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression-the process of reconstructing latent logical structures from compressed visual tokens. Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark. Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning.

</details>


### [201] [MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling](https://arxiv.org/abs/2602.11761)
*MiniCPM Team,Wenhao An,Yingfa Chen,Yewei Fang,Jiayi Li,Xin Li,Yaohui Li,Yishan Li,Yuxuan Li,Biyuan Lin,Chuan Liu,Hezi Liu,Siyuan Liu,Hongya Lyu,Yinxu Pan,Shixin Ren,Xingyu Shen,Zhou Su,Haojun Sun,Yangang Sun,Zhen Leng Thai,Xin Tian,Rui Wang,Xiaorong Wang,Yudong Wang,Bo Wu,Xiaoyue Xu,Dong Xu,Shuaikang Xue,Jiawei Yang,Bowen Zhang,Jinqian Zhang,Letian Zhang,Shengnan Zhang,Xinyu Zhang,Xinyuan Zhang,Zhu Zhang,Hengyu Zhao,Jiacheng Zhao,Jie Zhou,Zihan Zhou,Shuo Wang,Chaojun Xiao,Xu Han,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: 本文提出了一种名为 MiniCPM-SALA 的 9B 参数混合大语言模型，它结合了稀疏注意力和线性注意力机制，旨在解决长上下文 LLM 的计算和内存成本问题。该模型通过分层策略整合两种注意力机制，并使用混合位置编码，在保持性能的同时实现了高效性。此外，文中还提出了一个成本效益高的持续训练框架，能将现有 Transformer 模型转化为混合模型，训练成本降低约 75%。实验表明，MiniCPM-SALA 在长上下文任务上表现出色，推理速度比全注意力模型快 3.5 倍，并支持高达 1M 的上下文长度。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在处理超长上下文时，Transformer 架构面临计算和内存成本过高的问题。现有的稀疏和线性注意力机制虽然有所改进，但通常在内存效率和模型性能之间存在权衡。因此，研究动机在于开发一种既能高效处理长上下文，又能保持良好性能的 LLM。

Method: 本文提出了一种名为 MiniCPM-SALA 的 9B 参数混合架构。该架构结合了高保真稀疏注意力（InfLLM-V2）和全局效率的线性注意力（Lightning Attention），并采用 1:3 的比例和层选择算法进行整合。同时，模型还使用了混合位置编码（HyPE）。此外，研究者提出了一种成本效益高的持续训练框架，可以将预训练的 Transformer 模型转化为混合模型。

Result: MiniCPM-SALA 在广泛的实验中展示了与全注意力模型相当的通用能力，同时效率更高。在单块 NVIDIA A6000D GPU 上，模型在 256K 序列长度下实现了比全注意力模型高 3.5 倍的推理速度，并且支持高达 1M 的上下文长度，这是传统 8B 全注意力模型因内存限制而无法达到的。

Conclusion: MiniCPM-SALA 通过融合稀疏注意力和线性注意力机制，并结合有效的持续训练策略，成功地解决了长上下文大语言模型的计算和内存效率挑战。该模型在保持强大通用能力的同时，显著提升了长上下文任务的处理速度和可支持的上下文长度，为未来超长上下文 LLM 的发展提供了有价值的解决方案。

Abstract: The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involve a trade-off between memory efficiency and model performance. This paper introduces MiniCPM-SALA, a 9B-parameter hybrid architecture that integrates the high-fidelity long-context modeling of sparse attention (InfLLM-V2) with the global efficiency of linear attention (Lightning Attention). By employing a layer selection algorithm to integrate these mechanisms in a 1:3 ratio and utilizing a hybrid positional encoding (HyPE), the model maintains efficiency and performance for long-context tasks. Furthermore, we introduce a cost-effective continual training framework that transforms pre-trained Transformer-based models into hybrid models, which reduces training costs by approximately 75% compared to training from scratch. Extensive experiments show that MiniCPM-SALA maintains general capabilities comparable to full-attention models while offering improved efficiency. On a single NVIDIA A6000D GPU, the model achieves up to 3.5x the inference speed of the full-attention model at the sequence length of 256K tokens and supports context lengths of up to 1M tokens, a scale where traditional full-attention 8B models fail because of memory constraints.

</details>


### [202] [A Subword Embedding Approach for Variation Detection in Luxembourgish User Comments](https://arxiv.org/abs/2602.11795)
*Anne-Marie Lutgen,Alistair Plum,Christoph Purschke*

Main category: cs.CL

TL;DR: 本文提出一种基于子词嵌入的方法，用于检测语言变异，无需预先规范化或定义变异列表。该方法通过组合余弦和n-gram相似性来识别词汇和拼写变异，并将语言变异视为一种结构而非噪声。


<details>
  <summary>Details</summary>
Motivation: 传统的变异检测方法依赖于预先的规范化或固定的变异列表，这在低资源或“嘈杂”的语言环境中难以奏效。研究者希望开发一种更灵活、无需手动注释的方法来研究语言变异。

Method: 该方法首先在原始文本上训练子词嵌入，然后结合余弦相似性和n-gram相似性来对相关的词语形式进行分组。这种分组可以揭示词汇和拼写上的多样性，并将其分析为一种语言结构。

Result: 通过对卢森堡语用户评论的大型语料库进行分析，该方法成功识别出大量的词汇和正字法变异，这些变异与方言学和社会语言学研究中描述的模式一致。发现的词语家族能够捕捉到系统的对应关系，并突出显示了地区和风格上的差异。

Conclusion: 分布式建模（如本文提出的方法）即使在“嘈杂”或低资源的环境下也能揭示有意义的变异模式。该方法提供了一个可重复的方法框架，用于研究多语言和小型语言环境中的语言变异，并且产生的聚类结果支持定量和定性分析。

Abstract: This paper presents an embedding-based approach to detecting variation without relying on prior normalisation or predefined variant lists. The method trains subword embeddings on raw text and groups related forms through combined cosine and n-gram similarity. This allows spelling and morphological diversity to be examined and analysed as linguistic structure rather than treated as noise. Using a large corpus of Luxembourgish user comments, the approach uncovers extensive lexical and orthographic variation that aligns with patterns described in dialectal and sociolinguistic research. The induced families capture systematic correspondences and highlight areas of regional and stylistic differentiation. The procedure does not strictly require manual annotation, but does produce transparent clusters that support both quantitative and qualitative analysis. The results demonstrate that distributional modelling can reveal meaningful patterns of variation even in ''noisy'' or low-resource settings, offering a reproducible methodological framework for studying language variety in multilingual and small-language contexts.

</details>


### [203] [DMAP: A Distribution Map for Text](https://arxiv.org/abs/2602.11871)
*Tom Kempton,Julia Rozanova,Parameswaran Kamalaruban,Maeve Madigan,Karolina Wresilo,Yoann L. Launay,David Sutton,Stuart Burrell*

Main category: cs.CL

TL;DR: 本文提出了一种名为DMAP的新方法，该方法将文本映射到单位区间上的样本集，能够同时编码秩和概率信息，从而实现模型无关的文本分析，并在生成参数验证、机器生成文本检测和下游模型统计指纹分析方面展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本分析指标（如困惑度）未能充分考虑上下文信息，即下一个词概率的解释依赖于条件分布的形状。因此，需要一种新的、更全面地捕捉文本概率信息的分析方法。

Method: DMAP方法将文本通过语言模型映射到单位区间上的一组样本。这些样本能够联合编码文本的秩和概率信息，实现模型无关的分析。

Result: DMAP在三个案例研究中展现了其有效性：1. 验证生成参数以确保数据完整性；2. 考察概率曲率在机器生成文本检测中的作用；3. 揭示经过合成数据后训练的下游模型的统计指纹。

Conclusion: DMAP是一种简单、易于计算、应用广泛且能提供统一统计视角的文本分析方法，为基于LLM的文本分析研究奠定了基础。

Abstract: Large Language Models (LLMs) are a powerful tool for statistical text analysis, with derived sequences of next-token probability distributions offering a wealth of information. Extracting this signal typically relies on metrics such as perplexity, which do not adequately account for context; how one should interpret a given next-token probability is dependent on the number of reasonable choices encoded by the shape of the conditional distribution. In this work, we present DMAP, a mathematically grounded method that maps a text, via a language model, to a set of samples in the unit interval that jointly encode rank and probability information. This representation enables efficient, model-agnostic analysis and supports a range of applications. We illustrate its utility through three case studies: (i) validation of generation parameters to ensure data integrity, (ii) examining the role of probability curvature in machine-generated text detection, and (iii) a forensic analysis revealing statistical fingerprints left in downstream models that have been subject to post-training on synthetic data. Our results demonstrate that DMAP offers a unified statistical view of text that is simple to compute on consumer hardware, widely applicable, and provides a foundation for further research into text analysis with LLMs.

</details>


### [204] [Towards Fair and Comprehensive Evaluation of Routers in Collaborative LLM Systems](https://arxiv.org/abs/2602.11877)
*Wanxing Wu,He Zhu,Yixia Li,Lei Yang,Jiehui Zhao,Hongru Wang,Jian Yang,Benyou Wang,Bingyi Jing,Guanhua Chen*

Main category: cs.CL

TL;DR: 本文提出了RouterXBench评估框架和ProbeDirichlet轻量级路由器，用于在大语言模型（LLMs）的混合部署场景下，更有效地进行模型路由。RouterXBench从三个维度评估路由器能力、场景匹配度和跨域鲁棒性，并利用内部隐藏状态而非输出概率来评估模型不确定性。ProbeDirichlet路由器通过可学习的狄利克雷分布整合跨层隐藏状态，在多领域数据上训练后，展现出优于现有基线的性能，尤其在高精度场景下。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）路由评估方法不够系统，忽略了特定场景的需求和分布外（out-of-distribution）数据的鲁棒性。同时，LLMs的部署面临成本和隐私问题，需要将小型模型部署在本地，并将复杂查询卸载到云端模型，这使得高效的模型路由至关重要。

Method: 本文提出了一个名为RouterXBench的评估框架，包含三个评估维度：路由器能力（router ability）、场景匹配度（scenario alignment）和跨域鲁棒性（cross-domain robustness）。与依赖输出概率或外部嵌入的方法不同，RouterXBench利用模型内部隐藏状态来捕捉答案生成前的模型不确定性。在此框架下，作者设计了一个名为ProbeDirichlet的轻量级路由器，它通过可学习的狄利克雷分布聚合跨层隐藏状态，并采用概率训练。该模型在多领域数据上进行训练。

Result: ProbeDirichlet路由器在路由器能力方面相对于最佳基线取得了16.68%的相对提升，在高精度场景下取得了18.86%的相对提升。它在模型家族、模型规模、异构任务和自主工作流（agentic workflows）中均表现出一致的性能，并在域内（in-domain）和域外（out-of-distribution）场景下展现了鲁棒性。

Conclusion: RouterXBench是一个原则性的评估框架，可以系统地评估LLM路由器的性能，并解决了现有方法的不足。ProbeDirichlet路由器是一种高效且鲁棒的解决方案，能够通过利用模型内部隐藏状态来有效处理不同场景下的LLM路由问题，并在多种设置下优于现有方法。

Abstract: Large language models (LLMs) have achieved success, but cost and privacy constraints necessitate deploying smaller models locally while offloading complex queries to cloud-based models. Existing router evaluations are unsystematic, overlooking scenario-specific requirements and out-of-distribution robustness. We propose RouterXBench, a principled evaluation framework with three dimensions: router ability, scenario alignment, and cross-domain robustness. Unlike prior work that relies on output probabilities or external embeddings, we utilize internal hidden states that capture model uncertainty before answer generation. We introduce ProbeDirichlet, a lightweight router that aggregates cross-layer hidden states via learnable Dirichlet distributions with probabilistic training. Trained on multi-domain data, it generalizes robustly across in-domain and out-of-distribution scenarios. Our results show ProbeDirichlet achieves 16.68% and 18.86% relative improvements over the best baselines in router ability and high-accuracy scenarios, with consistent performance across model families, model scales, heterogeneous tasks, and agentic workflows.

</details>


### [205] [LLM-based Triplet Extraction from Financial Reports](https://arxiv.org/abs/2602.11886)
*Dante Wesslund,Ville Stenström,Pontus Linde,Alexander Holmberg*

Main category: cs.CL

TL;DR: 该研究提出了一种用于金融报告中主语-谓语-宾语三元组提取的半自动化流程，通过本体一致性和忠实度等代理指标进行评估，而非依赖标注真值。研究比较了静态手动本体和自动化文档本体感应方法，并提出了一种结合正则表达式和LLM作为裁判的混合验证策略，显著降低了虚假主体率，并分析了金融文本中主体和客体幻觉的系统性不对称性。


<details>
  <summary>Details</summary>
Motivation: 金融公司财务报告是构建知识图谱的重要资源，但该领域缺乏标注的真值，使得评估困难。研究旨在开发一种无需真值即可评估三元组提取的半自动化流程。

Method: 使用本体驱动的代理指标（本体一致性和忠实度）进行评估。比较了静态手动本体与自动化文档本体感应方法。提出了一种混合验证策略，结合正则表达式匹配和LLM作为裁判，以减少主体幻觉。

Result: 自动化本体感应方法在所有配置下均实现了100%的模式一致性，消除了手动方法中的本体漂移。混合验证策略将主体虚报率从65.2%显著降低到1.6%。发现了主体和客体幻觉之间存在系统性不对称。

Conclusion: 本体驱动的代理指标可以有效评估金融报告中的三元组提取。自动化本体感应优于手动方法。混合验证策略能有效减少主体幻觉。金融文本的被动语态和省略主语是导致主体和客体幻觉不对称的原因。

Abstract: Corporate financial reports are a valuable source of structured knowledge for Knowledge Graph construction, but the lack of annotated ground truth in this domain makes evaluation difficult. We present a semi-automated pipeline for Subject-Predicate-Object triplet extraction that uses ontology-driven proxy metrics, specifically Ontology Conformance and Faithfulness, instead of ground-truth-based evaluation. We compare a static, manually engineered ontology against a fully automated, document-specific ontology induction approach across different LLMs and two corporate annual reports. The automatically induced ontology achieves 100% schema conformance in all configurations, eliminating the ontology drift observed with the manual approach. We also propose a hybrid verification strategy that combines regex matching with an LLM-as-a-judge check, reducing apparent subject hallucination rates from 65.2% to 1.6% by filtering false positives caused by coreference resolution. Finally, we identify a systematic asymmetry between subject and object hallucinations, which we attribute to passive constructions and omitted agents in financial prose.

</details>


### [206] [Benchmark Illusion: Disagreement among LLMs and Its Scientific Consequences](https://arxiv.org/abs/2602.11898)
*Eddie Yang,Dashun Wang*

Main category: cs.CL

TL;DR: 当前LLM的基准测试结果可能具有误导性，即使模型在准确率上表现相似，它们在实际问题上的判断也可能存在显著差异，这种差异在科学研究中可能导致结果不一致甚至方向性相反。


<details>
  <summary>Details</summary>
Motivation: 研究人员注意到，尽管LLM在基准测试中的准确率日益提高并趋于一致，但这种表面上的“收敛”可能掩盖了模型在推理和判断上的深层分歧，这种分歧可能对依赖LLM进行科学研究的领域产生负面影响。

Method: 研究人员使用了MMLU-Pro和GPQA这两个主要的推理基准测试，分析了不同LLM在这些测试中的准确率以及它们在具体题目上的答案一致性。此外，他们还对教育学和政治学领域已发表的研究进行了重新分析，通过更换LLM作为数据标注和推理工具来评估模型选择对研究结果的影响。

Result: 研究发现，即使准确率相当的LLM，在16%-66%的题目上仍然存在分歧，而在性能顶尖的模型之间，这种分歧也达到16%-38%。这种分歧导致了不同的错误模式。在重新分析的科学研究中，更换标注模型可以将估计的治疗效果改变超过80%，甚至改变符号。

Conclusion: 研究提出了“基准幻觉”的概念，即相等的准确率可能掩盖模型之间的不一致性。模型选择成为了影响科学可重复性的一个隐藏但重要的变量，揭示了当前LLM评估和应用中存在的挑战。

Abstract: Benchmarks underpin how progress in large language models (LLMs) is measured and trusted. Yet our analyses reveal that apparent convergence in benchmark accuracy can conceal deep epistemic divergence. Using two major reasoning benchmarks - MMLU-Pro and GPQA - we show that LLMs achieving comparable accuracy still disagree on 16-66% of items, and 16-38% among top-performing frontier models. These discrepancies suggest distinct error profiles for different LLMs. When such models are used for scientific data annotation and inference, their hidden disagreements propagate into research results: in re-analyses of published studies in education and political science, switching the annotation model can change estimated treatment effects by more than 80%, and in some cases reverses their sign. Together, these findings illustrate a benchmark illusion, where equal accuracy may conceal disagreement, with model choice becoming a hidden yet consequential variable for scientific reproducibility.

</details>


### [207] [AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection](https://arxiv.org/abs/2602.11931)
*Pretam Ray,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: 提出AdaptEvolve方法，通过利用LLM生成置信度来动态选择模型，以平衡进化智能体系统中计算效率和推理能力之间的权衡，显著降低了推理成本同时保持了高准确率。


<details>
  <summary>Details</summary>
Motivation: 在进化智能体系统中，频繁调用大型语言模型（LLMs）会在计算效率和推理能力之间产生权衡。研究动机在于如何动态选择LLM，以保证当前推理步骤有足够的能力，同时保持计算效率。

Method: 引入AdaptEvolve框架，该框架在多LLM进化序列精炼的背景下，利用内在生成置信度来估计实时可解性，从而驱动LLM的选择。

Result: 经验结果表明，基于置信度的选择能够产生有利的帕累托前沿，平均推理成本降低37.9%，同时保留了静态大型模型基线97.5%的上限准确率。

Conclusion: AdaptEvolve框架通过置信度驱动的LLM选择，有效解决了进化智能体系统中计算效率与推理能力之间的权衡问题，在保证高准确率的同时显著降低了计算成本。

Abstract: Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static heuristics or external controllers and do not explicitly account for model uncertainty. We introduce AdaptEvolve: Adaptive LLM Selection for Multi-LLM Evolutionary Refinement within an evolutionary sequential refinement framework that leverages intrinsic generation confidence to estimate real-time solvability. Empirical results show that confidence-driven selection yields a favourable Pareto frontier, reducing total inference cost by an average of 37.9% across benchmarks while retaining 97.5% of the upper-bound accuracy of static large-model baselines. Our code is available at https://github.com/raypretam/adaptive_llm_selection.

</details>


### [208] [Cross-Modal Robustness Transfer (CMRT): Training Robust Speech Translation Models Using Adversarial Text](https://arxiv.org/abs/2602.11933)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本研究提出了一种名为跨模态鲁棒性迁移 (CMRT) 的框架，用于提高端到端语音翻译 (E2E-ST) 模型在面对语音形态变化时的鲁棒性，而无需生成对抗性语音数据。


<details>
  <summary>Details</summary>
Motivation: 当前的 E2E-ST 模型主要在“干净”的数据集上进行评估，忽略了现实世界中由非母语或方言语音引起的形态变化所带来的挑战。现有方法（如对抗训练）在语音领域效果有限且计算成本高。

Method: 研究将文本领域的对抗性攻击方法应用于语音领域，并提出跨模态鲁棒性迁移 (CMRT) 框架。CMRT 旨在将文本模态的对抗性鲁棒性迁移到语音模态，从而无需在训练过程中生成对抗性语音数据。

Result: 在四个语言对上的实验表明，CMRT 框架可以将对抗性鲁棒性平均提高 3 个 BLEU 分数以上。

Conclusion: CMRT 框架能够有效地提高 E2E-ST 模型的对抗性鲁棒性，并且无需生成对抗性语音数据，为构建更鲁棒的 E2E-ST 模型提供了一种新的、高效的方法。

Abstract: End-to-End Speech Translation (E2E-ST) has seen significant advancements, yet current models are primarily benchmarked on curated, "clean" datasets. This overlooks critical real-world challenges, such as morphological robustness to inflectional variations common in non-native or dialectal speech. In this work, we adapt a text-based adversarial attack targeting inflectional morphology to the speech domain and demonstrate that state-of-the-art E2E-ST models are highly vulnerable it. While adversarial training effectively mitigates such risks in text-based tasks, generating high-quality adversarial speech data remains computationally expensive and technically challenging. To address this, we propose Cross-Modal Robustness Transfer (CMRT), a framework that transfers adversarial robustness from the text modality to the speech modality. Our method eliminates the requirement for adversarial speech data during training. Extensive experiments across four language pairs demonstrate that CMRT improves adversarial robustness by an average of more than 3 BLEU points, establishing a new baseline for robust E2E-ST without the overhead of generating adversarial speech.

</details>


### [209] [Who is the richest club in the championship? Detecting and Rewriting Underspecified Questions Improve QA Performance](https://arxiv.org/abs/2602.11938)
*Yunchong Huang,Gianni Barlacchi,Sandro Pezzelle*

Main category: cs.CL

TL;DR: 研究表明，问答（QA）基准测试中大量问题（16%-50%）存在表述不清晰（underspecified）的问题，导致大型语言模型（LLM）表现不佳。通过将不清晰问题改写为清晰版本，QA性能得到显著提升，说明问题表述不清是导致LLM在QA任务中表现不佳的重要原因，而非模型本身的局限。


<details>
  <summary>Details</summary>
Motivation: 标准问答（QA）基准测试中，大型语言模型（LLM）的表现与预期存在差距。作者假设这种差距部分源于问题表述不清晰（underspecified），即查询的含义无法仅凭问题本身确定，需要额外上下文。

Method: 1. 构建一个基于LLM的分类器来识别不清晰问题。2. 将该分类器应用于多个QA数据集，评估不清晰问题的比例及LLM在这些问题上的表现。3. 进行对照改写实验，将不清晰问题改写为完全清晰的版本，并固定答案，以衡量问题清晰度对QA性能的影响。

Result: 16%到超过50%的QA基准测试问题被识别为不清晰。LLM在不清晰问题上的表现显著差于清晰问题。在改写实验中，QA性能在问题变得清晰后一致性地提高。

Conclusion: 问题表述不清晰是QA评估中的一个重要混淆因素，导致了许多看似模型能力不足的“QA失败”。研究结果强调了在设计基准测试时，关注问题的清晰度至关重要。

Abstract: Large language models (LLMs) perform well on well-posed questions, yet standard question-answering (QA) benchmarks remain far from solved. We argue that this gap is partly due to underspecified questions - queries whose interpretation cannot be uniquely determined without additional context. To test this hypothesis, we introduce an LLM-based classifier to identify underspecified questions and apply it to several widely used QA datasets, finding that 16% to over 50% of benchmark questions are underspecified and that LLMs perform significantly worse on them. To isolate the effect of underspecification, we conduct a controlled rewriting experiment that serves as an upper-bound analysis, rewriting underspecified questions into fully specified variants while holding gold answers fixed. QA performance consistently improves under this setting, indicating that many apparent QA failures stem from question underspecification rather than model limitations. Our findings highlight underspecification as an important confound in QA evaluation and motivate greater attention to question clarity in benchmark design.

</details>


### [210] [Do Large Language Models Adapt to Language Variation across Socioeconomic Status?](https://arxiv.org/abs/2602.11939)
*Elisa Bassignana,Mike Zhang,Dirk Hovy,Amanda Cercas Curry*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在适应不同社会经济地位（SES）受众的语言风格方面表现不佳，倾向于模仿上层SES群体，并可能加剧语言不平等。


<details>
  <summary>Details</summary>
Motivation: 了解大型语言模型在不同社会背景下调整其语言风格的程度，因为它们越来越多地被用于人际沟通，并且适应性差可能会加剧刻板印象和社会分层。

Method: 收集了一个包含Reddit和YouTube数据的、按SES分层的匿名数据集。使用94种社会语言学指标（包括句法、修辞和词汇特征）来比较四种LLMs生成的文本补全与原始文本。

Result: LLMs在很大程度上未能根据SES调整其语言风格，通常会产生近似或漫画化的风格，并且它们更容易模仿上层SES的风格。

Conclusion: LLMs存在加剧语言阶层并放大语言不平等的风险，这对其在基于代理的社会模拟、调查实验以及任何依赖语言风格作为社会信号的研究中的有效性提出了质疑。

Abstract: Humans adjust their linguistic style to the audience they are addressing. However, the extent to which LLMs adapt to different social contexts is largely unknown. As these models increasingly mediate human-to-human communication, their failure to adapt to diverse styles can perpetuate stereotypes and marginalize communities whose linguistic norms are less closely mirrored by the models, thereby reinforcing social stratification. We study the extent to which LLMs integrate into social media communication across different socioeconomic status (SES) communities. We collect a novel dataset from Reddit and YouTube, stratified by SES. We prompt four LLMs with incomplete text from that corpus and compare the LLM-generated completions to the originals along 94 sociolinguistic metrics, including syntactic, rhetorical, and lexical features. LLMs modulate their style with respect to SES to only a minor extent, often resulting in approximation or caricature, and tend to emulate the style of upper SES more effectively. Our findings (1) show how LLMs risk amplifying linguistic hierarchies and (2) call into question their validity for agent-based social simulation, survey experiments, and any research relying on language style as a social signal.

</details>


### [211] [Scaling Model and Data for Multilingual Machine Translation with Open Large Language Models](https://arxiv.org/abs/2602.11961)
*Yuzhe Shang,Pengzhi Gao,Wei Liu,Jian Luan,Jinsong Su*

Main category: cs.CL

TL;DR: 本文研究了开源大语言模型（LLM）在46种语言上的多语言机器翻译（MT）能力，并探索了模型和数据规模对持续预训练和指令微调的影响，提出了MiLMMT-46模型，其性能在多语言翻译上超越了现有SOTA模型，并可与商业模型媲美。


<details>
  <summary>Details</summary>
Motivation: 开源大语言模型在多语言能力上的快速发展，促使研究者探索其在多语言机器翻译领域的潜力，并优化其适应性。

Method: 研究者基于Gemma3模型家族，通过持续预训练和指令微调的方式，对模型进行多语言机器翻译任务的适配，并研究了模型和数据规模的影响，最终构建了MiLMMT-46模型。

Result: MiLMMT-46在46种语言的多语言翻译任务上取得了顶尖性能，超越了Seed-X、HY-MT-1.5和TranslateGemma等SOTA模型，并且与Google Translate和Gemini 3 Pro等商业系统性能相当。

Conclusion: 开源大语言模型通过持续预训练和指令微调，可以有效地提升其在多语言机器翻译任务上的性能，并且模型和数据的规模是影响性能的关键因素。MiLMMT-46证明了这种方法的有效性。

Abstract: Open large language models (LLMs) have demonstrated improving multilingual capabilities in recent years. In this paper, we present a study of open LLMs for multilingual machine translation (MT) across a range of languages, and investigate the effects of model scaling and data scaling when adapting open LLMs to multilingual MT through continual pretraining and instruction finetuning. Based on the Gemma3 model family, we develop MiLMMT-46, which achieves top-tier multilingual translation performance across 46 languages. Extensive experiments show that MiLMMT-46 consistently outperforms recent state-of-the-art (SOTA) models, including Seed-X, HY-MT-1.5, and TranslateGemma, and achieves competitive performance with strong proprietary systems such as Google Translate and Gemini 3 Pro.

</details>


### [212] [DHPLT: large-scale multilingual diachronic corpora and word representations for semantic change modelling](https://arxiv.org/abs/2602.11968)
*Mariia Fedorova,Andrey Kutuzov,Khonzoda Umarova*

Main category: cs.CL

TL;DR: 本文介绍了一个包含41种语言的历时语料库DHPLT，基于HPLT数据集，使用网页抓取时间作为文档创建时间的近似信号，并提供了预计算的词嵌入和词汇替换，旨在支持跨语言的语义变化建模研究。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数多语言历时语料库仅限于少数高资源语言，缺乏多样性，无法满足更广泛的语义变化建模研究需求。

Method: 利用HPLT数据集，以网页抓取时间作为文档创建时间的近似信号，构建包含2011-2015、2020-2021和2024-至今三个时间段的、每种语言各100万文档的历时语料库DHPLT。并预计算了目标词的词类型、词令牌嵌入以及词汇替换。

Result: 创建了一个包含41种语言的、跨越三个时间段的DHPLT历时语料库，并提供了预计算的词嵌入和词汇替换等资源，所有资源均已公开可用。

Conclusion: DHPLT为多语言语义变化建模研究提供了急需的资源，特别是对于资源有限的语言，它为该领域的新型实验设置开辟了道路。

Abstract: In this resource paper, we present DHPLT, an open collection of diachronic corpora in 41 diverse languages. DHPLT is based on the web-crawled HPLT datasets; we use web crawl timestamps as the approximate signal of document creation time. The collection covers three time periods: 2011-2015, 2020-2021 and 2024-present (1 million documents per time period for each language). We additionally provide pre-computed word type and token embeddings and lexical substitutions for our chosen target words, while at the same time leaving it open for the other researchers to come up with their own target words using the same datasets. DHPLT aims at filling in the current lack of multilingual diachronic corpora for semantic change modelling (beyond a dozen of high-resource languages). It opens the way for a variety of new experimental setups in this field. All the resources described in this paper are available at https://data.hplt-project.org/three/diachronic/, sorted by language.

</details>


### [213] [Automatic Simplification of Common Vulnerabilities and Exposures Descriptions](https://arxiv.org/abs/2602.11982)
*Varpu Vehomäki,Kimmo K. Kaski*

Main category: cs.CL

TL;DR: 本研究探讨了使用大型语言模型（LLMs）对常见的网络安全漏洞和暴露（CVE）描述进行自动文本简化（ATS）。研究结果表明，尽管LLMs可以使文本看起来更简单，但它们在保持原意方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 网络安全信息对个人和组织日益重要，但相关内容对于非专业人士来说可能难以理解。本研究旨在探索利用LLMs实现网络安全文本（特别是CVE描述）的自动简化，填补该领域ATS研究的空白。

Method: 研究创建了一个用于网络安全ATS的基线模型，并构建了一个包含40个CVE描述的测试数据集。通过两轮调查，由两组网络安全专家对简化后的文本进行了评估。

Result: 研究发现，开箱即用的LLMs虽然能够简化文本的表面形式，但在保持CVE描述的原始含义方面表现不佳。

Conclusion: 尽管LLMs在简化网络安全文本方面具有潜力，但目前在保证信息准确性和完整性方面仍需改进，特别是对于高度专业化和快速变化的CVE描述。

Abstract: Understanding cyber security is increasingly important for individuals and organizations. However, a lot of information related to cyber security can be difficult to understand to those not familiar with the topic. In this study, we focus on investigating how large language models (LLMs) could be utilized in automatic text simplification (ATS) of Common Vulnerability and Exposure (CVE) descriptions. Automatic text simplification has been studied in several contexts, such as medical, scientific, and news texts, but it has not yet been studied to simplify texts in the rapidly changing and complex domain of cyber security. We created a baseline for cyber security ATS and a test dataset of 40 CVE descriptions, evaluated by two groups of cyber security experts in two survey rounds. We have found that while out-of-the box LLMs can make the text appear simpler, they struggle with meaning preservation. Code and data are available at https://version.aalto.fi/gitlab/vehomav1/simplification\_nmi.

</details>


### [214] [LaCy: What Small Language Models Can and Should Learn is Not Just a Question of Loss](https://arxiv.org/abs/2602.12005)
*Szilvia Ujváry,Louis Béthune,Pierre Ablin,João Monteiro,Marco Cuturi,Michael Kirchhof*

Main category: cs.CL

TL;DR: 研究了小型语言模型（SLM）在预训练时应该学习哪些 token，哪些应该通过<CALL> token委托给外部模型。提出了一种名为LaCy的新预训练方法，利用spaCy语法解析器增强损失信号来区分应该委托的 token 和可以安全学习的 token，实验证明LaCy在事实准确性上优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLM）由于参数量限制，知识容量有限，容易产生事实错误。为了解决这个问题，通常会让SLM能够调用外部知识源，但关键问题是SLM在预训练时应该学习哪些信息，哪些应该被委托出去。

Method: 研究的核心在于区分“可接受的” token（即使损失高，也是真实的替代性延续）和“不可接受的” token（会导致事实错误）。利用spaCy语法解析器来增强损失信号，帮助SLM做出学习还是委托的决策。在此基础上提出了名为LaCy的新预训练方法。

Result: LaCy模型能够有效地学习区分哪些 token 应该自己预测，哪些应该委托给外部模型。在与大型模型级联生成时，LaCy模型在FactScores上表现更优，并且优于Rho或LLM-judge训练的SLM，同时成本更低、实现更简单。

Conclusion: 通过将语法解析信息与损失信号结合，可以更有效地指导SLM在预训练阶段进行 token 选择，决定是学习还是委托。LaCy方法能够显著提升SLM在生成事实性内容方面的能力，并减少其对外部知识源的依赖。

Abstract: Language models have consistently grown to compress more world knowledge into their parameters, but the knowledge that can be pretrained into them is upper-bounded by their parameter size. Especially the capacity of Small Language Models (SLMs) is limited, leading to factually incorrect generations. This problem is often mitigated by giving the SLM access to an outside source: the ability to query a larger model, documents, or a database. Under this setting, we study the fundamental question of \emph{which tokens an SLM can and should learn} during pretraining, versus \emph{which ones it should delegate} via a \texttt{<CALL>} token. We find that this is not simply a question of loss: although the loss is predictive of whether a predicted token mismatches the ground-truth, some tokens are \emph{acceptable} in that they are truthful alternative continuations of a pretraining document, and should not trigger a \texttt{<CALL>} even if their loss is high. We find that a spaCy grammar parser can help augment the loss signal to decide which tokens the SLM should learn to delegate to prevent factual errors and which are safe to learn and predict even under high losses. We propose LaCy, a novel pretraining method based on this token selection philosophy. Our experiments demonstrate that LaCy models successfully learn which tokens to predict and where to delegate for help. This results in higher FactScores when generating in a cascade with a bigger model and outperforms Rho or LLM-judge trained SLMs, while being simpler and cheaper.

</details>


### [215] [Disentangling Ambiguity from Instability in Large Language Models: A Clinical Text-to-SQL Case Study](https://arxiv.org/abs/2602.12015)
*Angelo Ziletti,Leonardo D'Ambrosi*

Main category: cs.CL

TL;DR: 提出CLUES框架，将Text-to-SQL分解为解释和答案两个阶段，并区分输入歧义和模型不稳定性，以指导人工干预，提高了错误预测的效率。


<details>
  <summary>Details</summary>
Motivation: 区分导致Text-to-SQL输出多样性的两种原因：输入歧义（应触发澄清）和模型不稳定性（应触发人工审查），以便在临床部署中更有效地进行干预。

Method: 将Text-to-SQL建模为一个两阶段过程（解释->答案），并将语义不确定性分解为歧义分数和不稳定性分数。不稳定性分数通过二分语义图矩阵的Schur补计算。

Result: CLUES框架在AmbigQA/SituatedQA和临床Text-to-SQL基准测试中，其失败预测能力优于现有的Kernel Language Entropy。在部署环境中，CLUES保持竞争力，并提供了单一分数无法提供的诊断性分解。高歧义/高不稳定性情景包含了51%的错误，但仅占查询的25%，实现了高效分诊。

Conclusion: CLUES框架能够有效地将Text-to-SQL的输出不确定性分解为歧义和不稳定性，从而实现有针对性的干预措施，如查询优化或模型改进，并显著提高了错误预测的效率。

Abstract: Deploying large language models for clinical Text-to-SQL requires distinguishing two qualitatively different causes of output diversity: (i) input ambiguity that should trigger clarification, and (ii) model instability that should trigger human review. We propose CLUES, a framework that models Text-to-SQL as a two-stage process (interpretations --> answers) and decomposes semantic uncertainty into an ambiguity score and an instability score. The instability score is computed via the Schur complement of a bipartite semantic graph matrix. Across AmbigQA/SituatedQA (gold interpretations) and a clinical Text-to-SQL benchmark (known interpretations), CLUES improves failure prediction over state-of-the-art Kernel Language Entropy. In deployment settings, it remains competitive while providing a diagnostic decomposition unavailable from a single score. The resulting uncertainty regimes map to targeted interventions - query refinement for ambiguity, model improvement for instability. The high-ambiguity/high-instability regime contains 51% of errors while covering 25% of queries, enabling efficient triage.

</details>


### [216] [DeepSight: An All-in-One LM Safety Toolkit](https://arxiv.org/abs/2602.12092)
*Bo Zhang,Jiaxuan Guo,Lijun Li,Dongrui Liu,Sujin Chen,Guanxu Chen,Zhijie Zheng,Qihao Lin,Lewen Yan,Chen Qian,Yijin Zhou,Yuyao Wu,Shaoxiong Guo,Tianyi Du,Jingyi Yang,Xuhao Hu,Ziqi Miao,Xiaoya Lu,Jing Shao,Xia Hu*

Main category: cs.CL

TL;DR: 提出了一种名为DeepSight的开源项目，集成了安全评估和诊断工具（DeepSafe和DeepScan），以解决当前大型模型安全工作流程中评估、诊断和对齐分离的问题，实现从黑盒到白盒的安全洞察。


<details>
  <summary>Details</summary>
Motivation: 现有的大型模型（LLMs和MLLMs）安全工作流程中，安全评估、诊断和对齐是分开进行的。安全评估只能发现外部风险，无法找到内部根源；安全诊断则脱离具体风险场景，停留在可解释层面；安全对齐缺乏对内部机制变化的明确解释，可能损害模型通用能力。这些问题阻碍了对模型安全性的系统性解决。

Method: 提出DeepSight开源项目，采用“评估-诊断一体化”新范式。项目包含评估工具DeepSafe和诊断工具DeepScan。通过统一任务和数据协议，连接评估和诊断两个阶段，将安全评估从黑盒操作转变为白盒洞察。DeepSight旨在实现低成本、可复现、高效且可扩展的模型安全评估。

Result: DeepSight实现了安全评估与诊断的统一，使得安全评估能够提供白盒洞察，而不仅仅是定位外部行为风险。它是首个支持前沿AI风险评估和联合安全评估诊断的开源工具包。

Conclusion: DeepSight项目通过集成评估和诊断工具，提供了一种新的、更系统化的方式来处理大型模型的安全性问题，能够更深入地理解和解决模型的内部安全风险，并可能减少对模型通用能力的影响。

Abstract: As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.

</details>


### [217] [P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling](https://arxiv.org/abs/2602.12116)
*Pinyi Zhang,Ting-En Lin,Yuchuan Wu,Jingyang Chen,Zongqi Wang,Hua Yang,Ze Xu,Fei Huang,Kai Zhang,Yongbin Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为P-GenRM的个性化生成奖励模型，该模型通过生成结构化的评估链，并采用测试时用户基准缩放机制，解决了现有模型在理解用户偏好和泛化能力上的不足，在个性化对齐任务上取得了SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有个性化奖励模型在理解用户特定偏好和泛化到新用户方面存在局限性：偏好被过度简化，且难以处理反馈有限的新用户。

Method: P-GenRM将偏好信号转化为结构化评估链，生成自适应的Persona和评分标准。通过将用户聚类为用户原型，并采用个体和原型两个层面的缩放机制，来整合个体用户和相似用户的偏好，从而提高模型的鲁棒性和泛化能力。

Result: P-GenRM在现有基准测试中取得了2.31%的平均提升，并在分布外数据集上展现出强大的泛化能力。测试时用户基准缩放机制带来了额外的3%性能提升。

Conclusion: P-GenRM是首个实现个性化生成奖励的模型，通过其创新的结构化评估链和双粒度缩放机制，有效克服了现有模型的局限性，并在个性化语言模型对齐任务上取得了显著的性能提升和良好的泛化能力。

Abstract: Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning. A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two persistent limitations: (1) oversimplifying diverse, scenario-specific preferences into a small, fixed set of evaluation principles, and (2) struggling with generalization to new users with limited feedback. To this end, we propose P-GenRM, the first Personalized Generative Reward Model with test-time user-based scaling. P-GenRM transforms preference signals into structured evaluation chains that derive adaptive personas and scoring rubrics across various scenarios. It further clusters users into User Prototypes and introduces a dual-granularity scaling mechanism: at the individual level, it adaptively scales and aggregates each user's scoring scheme; at the prototype level, it incorporates preferences from similar users. This design mitigates noise in inferred preferences and enhances generalization to unseen users through prototype-based transfer. Empirical results show that P-GenRM achieves state-of-the-art results on widely-used personalized reward model benchmarks, with an average improvement of 2.31%, and demonstrates strong generalization on an out-of-distribution dataset. Notably, Test-time User-based scaling provides an additional 3% boost, demonstrating stronger personalized alignment with test-time scalability.

</details>


### [218] [Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models](https://arxiv.org/abs/2602.12036)
*Xin Xu,Clive Bai,Kai Yang,Tianhao Chen,Yangkun Chen,Weijie Liu,Hao Chen,Yang Wang,Saiyong Yang,Can Yang*

Main category: cs.CL

TL;DR: Composition-RL 是一种新的方法，通过组合现有的验证式提示来提高大规模语言模型在推理任务上的表现，特别关注那些通过率很高的提示（pass-rate-1），从而更有效地利用有限的训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有的 RLVR 方法依赖于大规模的验证式提示，但这些提示包含大量无信息示例且成本高昂。尤其是在训练后期，通过率很高的“容易”提示会越来越多，降低了有效数据的使用率。为了解决这个问题，需要一种方法来更好地利用这些容易的提示。

Method: Composition-RL 自动将多个现有的验证式提示（特别是 pass-rate-1 的提示）组合成新的、更复杂的验证式问题，并使用这些组合后的提示进行强化学习训练。此外，还提出了一个课程学习变体，逐步增加组合的深度。

Result: 在 4B 到 30B 参数规模的模型上进行的大量实验表明，Composition-RL 显著提高了模型的推理能力，优于直接在原始数据集上训练的 RL 模型。课程学习变体进一步提升了性能。此外，Composition-RL 还能通过组合不同领域的提示，实现更有效的跨领域强化学习。

Conclusion: Composition-RL 是一种简单有效的方法，能够通过组合现有验证式提示来提升大规模语言模型的推理能力，尤其是在处理大量高通过率提示时。该方法还支持课程学习和跨领域应用，为 RLVR 领域的数据利用和性能提升提供了新的途径。

Abstract: Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.

</details>


### [219] [A Rule-based Computational Model for Gaidhlig Morphology](https://arxiv.org/abs/2602.12132)
*Peter J Barclay*

Main category: cs.CL

TL;DR: 本研究提出了一种基于规则的高尔夫语（Gaidhlig）形态模型构建方法，利用维基词典的数据，旨在解决低资源语言中神经网络模型数据不足的问题，并为教育工具和语言分析提供支持。


<details>
  <summary>Details</summary>
Motivation: 目前流行的神经语言模型需要大量数据进行训练，而低资源语言（如高尔夫语）通常数据稀缺。因此，研究者希望开发一种能够有效利用有限数据的方法，并为低资源语言的语言工具开发提供支持。

Method: 该研究构建了一个基于规则的高尔夫语形态模型。研究者利用维基词典（Wiktionary）的数据，通过SQL查询词汇模式的出现情况，并开发了一个声明式规则库，允许Python工具生成高尔夫语的屈折形式。

Result: 研究提出了一个能够根据维基词典数据生成高尔夫语词语屈折形式的规则模型。该模型能够有效利用有限的样本数据，并且易于解释，为设计教学材料提供了见解。

Conclusion: 基于规则的方法可以有效地利用低资源语言的有限数据，并且具有良好的可解释性。该研究提出的模型可以用于支持教育工具，例如教授或解释语言模式，也可以支持更高级的工具，如基于规则的依存句法分析器，为现有维基词典数据增加了新的应用价值。

Abstract: Language models and software tools are essential to support the continuing vitality of lesser-used languages; however, currently popular neural models require considerable data for training, which normally is not available for such low-resource languages. This paper describes work-in-progress to construct a rule-based model of Gaidhlig morphology using data from Wiktionary, arguing that rule-based systems effectively leverage limited sample data, support greater interpretability, and provide insights useful in the design of teaching materials. The use of SQL for querying the occurrence of different lexical patterns is investigated, and a declarative rule-base is presented that allows Python utilities to derive inflected forms of Gaidhlig words. This functionality could be used to support educational tools that teach or explain language patterns, for example, or to support higher level tools such as rule-based dependency parsers. This approach adds value to the data already present in Wiktionary by adapting it to new use-cases.

</details>


### [220] [CitiLink-Minutes: A Multilayer Annotated Dataset of Municipal Meeting Minutes](https://arxiv.org/abs/2602.12137)
*Ricardo Campos,Ana Filipa Pacheco,Ana Luísa Fernandes,Inês Cantante,Rute Rebouças,Luís Filipe Cunha,José Miguel Isidro,José Pedro Evans,Miguel Marques,Rodrigo Batista,Evelin Amorim,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,António Leal,Purificação Silvano*

Main category: cs.CL

TL;DR: 该研究提出了CitiLink-Minutes，一个包含120份欧洲葡萄牙市政会议记录的多层数据集，为市政会议记录的NLP/IR研究填补了空白，并提供了基线结果。


<details>
  <summary>Details</summary>
Motivation: 现有的市政会议记录在信息检索（IR）和自然语言处理（NLP）领域研究较少，主要原因是缺乏标注数据集，这阻碍了相关计算模型的发展。

Method: 构建了一个包含120份欧洲葡萄牙市政会议记录（来自六个不同城市）的多层数据集CitiLink-Minutes。数据集包含超过100万个词元，已进行个人身份信息去标识化。数据集通过三层维度进行人工标注（元数据、讨论主题、投票结果），并由两名标注员和一名语言学家进行质量控制，总计超过38,000个标注。

Result: 发布了CitiLink-Minutes数据集，并提供了元数据提取、主题分类和投票标签的基线结果。数据集遵循FAIR原则发布。

Conclusion: CitiLink-Minutes数据集的发布为市政会议记录的NLP和IR任务提供了支持，促进了对市政决策的透明访问，并展示了其在下游任务中的潜力。

Abstract: City councils play a crucial role in local governance, directly influencing citizens' daily lives through decisions made during municipal meetings. These deliberations are formally documented in meeting minutes, which serve as official records of discussions, decisions, and voting outcomes. Despite their importance, municipal meeting records have received little attention in Information Retrieval (IR) and Natural Language Processing (NLP), largely due to the lack of annotated datasets, which ultimately limit the development of computational models. To address this gap, we introduce CitiLink-Minutes, a multilayer dataset of 120 European Portuguese municipal meeting minutes from six municipalities. Unlike prior annotated datasets of parliamentary or video records, CitiLink-Minutes provides multilayer annotations and structured linkage of official written minutes. The dataset contains over one million tokens, with all personal identifiers de-identified. Each minute was manually annotated by two trained annotators and curated by an experienced linguist across three complementary dimensions: (1) metadata, (2) subjects of discussion, and (3) voting outcomes, totaling over 38,000 individual annotations. Released under FAIR principles and accompanied by baseline results on metadata extraction, topic classification, and vote labeling, CitiLink-Minutes demonstrates its potential for downstream NLP and IR tasks, while promoting transparent access to municipal decisions.

</details>


### [221] [dVoting: Fast Voting for dLLMs](https://arxiv.org/abs/2602.12153)
*Sicheng Feng,Zigeng Chen,Xinyin Ma,Gongfan Fang,Xinchao Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为dVoting的无训练快速投票技术，用于增强扩散大语言模型（dLLM）的推理能力。通过迭代采样、识别不确定性Token并进行投票式再生，dVoting在不显著增加计算开销的情况下，在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型（dLLM）在并行解码方面具有潜力，但其推理能力仍有提升空间。研究者观察到，在对同一提示的多个采样中，大部分Token预测一致，而性能的差异主要由少数不一致的Token决定，这启发了dVoting的思路。

Method: dVoting利用dLLM的任意位置生成能力，通过迭代采样、基于一致性分析识别不确定Token、以及投票式再生这些不确定Token来逐步优化生成结果，直至收敛。

Result: dVoting在GSM8K（6.22%-7.66%）、MATH500（4.40%-7.20%）、ARC-C（3.16%-14.84%）和MMLU（4.83%-5.74%）等多个基准测试上均展示了持续的性能提升。

Conclusion: dVoting是一种有效的、无需训练的dLLM推理增强技术，通过迭代投票机制显著提升了模型的性能，且额外计算开销可接受。

Abstract: Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential for parallel test-time scaling, which was previously constrained by severe inefficiency in autoregressive modeling. In this work, we introduce dVoting, a fast voting technique that boosts reasoning capability without training, with only an acceptable extra computational overhead. dVoting is motivated by the observation that, across multiple samples for the same prompt, token predictions remain largely consistent, whereas performance is determined by a small subset of tokens exhibiting cross-sample variability. Leveraging the arbitrary-position generation capability of dLLMs, dVoting performs iterative refinement by sampling, identifying uncertain tokens via consistency analysis, regenerating them through voting, and repeating this process until convergence. Extensive evaluations demonstrate that dVoting consistently improves performance across various benchmarks. It achieves gains of 6.22%-7.66% on GSM8K, 4.40%-7.20% on MATH500, 3.16%-14.84% on ARC-C, and 4.83%-5.74% on MMLU. Our code is available at https://github.com/fscdc/dVoting

</details>


### [222] [WavBench: Benchmarking Reasoning, Colloquialism, and Paralinguistics for End-to-End Spoken Dialogue Models](https://arxiv.org/abs/2602.12135)
*Yangzhuo Li,Shengpeng Ji,Yifu Chen,Tianle Liang,Haorong Ying,Yule Wang,Junbo Li,Jun Fang,Zhou Zhao*

Main category: cs.CL

TL;DR: 本文提出了WavBench，一个旨在评估对话模型真实会话能力的新基准，包含Pro（高难度推理）、Basic（口语化表达）和Acoustic（语用学）三个子集，以克服现有文本生成评估的不足。


<details>
  <summary>Details</summary>
Motivation: 现有对话模型评估主要侧重于文本生成，忽视了语音交互的独特特性（如语用学、口语化表达）以及现代对话代理所需的认知深度。因此，需要一个能评估真实会话能力的基准。

Method: 提出了一个三部分框架的基准：1. Pro子集：提高推理难度以挑战模型；2. Basic子集：引入“听觉可理解性”标准，关注自然词汇、语言流畅性和互动融洽度，而非书面准确性；3. Acoustic子集：评估语用学理解、生成及隐式对话能力。

Result: 通过对五种最先进模型的评估，WavBench揭示了模型在复杂问题解决、口语化表达和语用学保真度方面的表现，为未来模型发展提供了指导。

Conclusion: WavBench是一个全面的基准，能够更准确地评估具备先进推理能力、口语化表达和语用学理解的对话模型，弥补了现有评估方法的不足。

Abstract: With the rapid integration of advanced reasoning capabilities into spoken dialogue models, the field urgently demands benchmarks that transcend simple interactions to address real-world complexity. However, current evaluations predominantly adhere to text-generation standards, overlooking the unique audio-centric characteristics of paralinguistics and colloquialisms, alongside the cognitive depth required by modern agents. To bridge this gap, we introduce WavBench, a comprehensive benchmark designed to evaluate realistic conversational abilities where prior works fall short. Uniquely, WavBench establishes a tripartite framework: 1) Pro subset, designed to rigorously challenge reasoning-enhanced models with significantly increased difficulty; 2) Basic subset, defining a novel standard for spoken colloquialism that prioritizes "listenability" through natural vocabulary, linguistic fluency, and interactive rapport, rather than rigid written accuracy; and 3) Acoustic subset, covering explicit understanding, generation, and implicit dialogue to rigorously evaluate comprehensive paralinguistic capabilities within authentic real-world scenarios. Through evaluating five state-of-the-art models, WavBench offers critical insights into the intersection of complex problem-solving, colloquial delivery, and paralinguistic fidelity, guiding the evolution of robust spoken dialogue models. The benchmark dataset and evaluation toolkit are available at https://naruto-2024.github.io/wavbench.github.io/.

</details>


### [223] [Query-focused and Memory-aware Reranker for Long Context Processing](https://arxiv.org/abs/2602.12192)
*Yuqing Li,Jiangnan Li,Mo Yu,Guoxuan Ding,Zheng Lin,Weiping Wang,Jie Zhou*

Main category: cs.CL

TL;DR: 该研究提出了一种新的基于注意力分数的重排框架，用于估计文档-查询相关性，该框架在多个基准测试中表现优于现有方法，并且具有轻量级、高效和可扩展的特点。


<details>
  <summary>Details</summary>
Motivation: 现有关于大型语言模型中检索头部的分析促使研究者提出一种替代的重排框架，以利用注意力分数来估计文档-查询相关性。

Method: 研究者提出了一种新的重排框架，该框架利用选定注意力头部的注意力分数来估计文档-查询相关性。该方法采用列表式解决方案，并在候选文档列表的整体信息进行排序。同时，它生成连续的相关性分数，无需李克特量表式监督即可在任意检索数据集上进行训练。该框架使用了参数量较小的模型（例如 40 亿参数）。

Result: 该框架在 Wikipedia 和长篇叙事数据集等多个领域均优于现有的最优点式和列表式重排器。它在评估对话理解和内存使用能力的 LoCoMo 基准测试中也确立了新的最优性能。此外，研究表明该框架支持灵活的扩展，例如，通过增加候选文档的上下文信息可以提高排序准确性，而从中间层训练注意力头部可以在不牺牲性能的情况下提高效率。

Conclusion: 该研究提出的基于注意力分数的重排框架是一种轻量级、高效且可扩展的解决方案，能够有效提高信息检索的排序性能，并在多个基准测试中取得了优于现有方法的表现。

Abstract: Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverages holistic information within the entire candidate shortlist during ranking. At the same time, it naturally produces continuous relevance scores, enabling training on arbitrary retrieval datasets without requiring Likert-scale supervision. Our framework is lightweight and effective, requiring only small-scale models (e.g., 4B parameters) to achieve strong performance. Extensive experiments demonstrate that our method outperforms existing state-of-the-art pointwise and listwise rerankers across multiple domains, including Wikipedia and long narrative datasets. It further establishes a new state-of-the-art on the LoCoMo benchmark that assesses the capabilities of dialogue understanding and memory usage. We further demonstrate that our framework supports flexible extensions. For example, augmenting candidate passages with contextual information further improves ranking accuracy, while training attention heads from middle layers enhances efficiency without sacrificing performance.

</details>


### [224] [ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images](https://arxiv.org/abs/2602.12203)
*Mathieu Sibue,Andres Muñoz Garza,Samuel Mensah,Pranav Shetty,Zhiqiang Ma,Xiaomo Liu,Manuela Veloso*

Main category: cs.CL

TL;DR: 本研究提出了ExStrucTiny数据集，用于对文档图像进行结构化信息提取，并分析了通用视觉语言模型（VLMs）在该数据集上的表现，指出了模型在模式适应、查询不足和答案定位方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有文档理解基准在实体类型、查询复杂度和文档类型多样性方面存在局限，未能充分评估通用VLMs进行细粒度结构化提取的能力，尤其是在灵活模式下的提取。因此，需要一个更全面、更具挑战性的数据集来推动模型发展。

Method: 提出了ExStrucTiny数据集，该数据集通过结合人工和合成样本生成，并经过人工验证，涵盖了更多样的文档类型和提取场景，统一了关键实体提取（KEE）、关系提取（RE）和视觉问答（VQA）的功能。研究分析了在ExStrucTiny数据集上开放和封闭式VLMs的表现。

Result: 分析显示，通用VLMs在ExStrucTiny数据集上面临着模式适应、查询欠指定和答案定位等挑战。具体表现为模型在处理不同模式和不明确查询时存在困难，并且准确找到答案在文档中的位置也具有挑战性。

Conclusion: ExStrucTiny数据集为评估和改进通用VLMs在文档结构化信息提取方面的能力提供了一个基础。研究结果突出了当前模型在该领域存在的不足，为未来的研究指明了方向，旨在提升模型在真实世界文档场景下的通用性和鲁棒性。

Abstract: Enterprise documents, such as forms and reports, embed critical information for downstream applications like data archiving, automated workflows, and analytics. Although generalist Vision Language Models (VLMs) perform well on established document understanding benchmarks, their ability to conduct holistic, fine-grained structured extraction across diverse document types and flexible schemas is not well studied. Existing Key Entity Extraction (KEE), Relation Extraction (RE), and Visual Question Answering (VQA) datasets are limited by narrow entity ontologies, simple queries, or homogeneous document types, often overlooking the need for adaptable and structured extraction. To address these gaps, we introduce ExStrucTiny, a new benchmark dataset for structured Information Extraction (IE) from document images, unifying aspects of KEE, RE, and VQA. Built through a novel pipeline combining manual and synthetic human-validated samples, ExStrucTiny covers more varied document types and extraction scenarios. We analyze open and closed VLMs on this benchmark, highlighting challenges such as schema adaptation, query under-specification, and answer localization. We hope our work provides a bedrock for improving generalist models for structured IE in documents.

</details>


### [225] [Detecting Overflow in Compressed Token Representations for Retrieval-Augmented Generation](https://arxiv.org/abs/2602.12235)
*Julia Belikova,Danila Rozhevskii,Dennis Svirin,Konstantin Polev,Alexander Panchenko*

Main category: cs.CL

TL;DR: 研究提出了一种检测和表征软压缩语言模型中“token overflow”现象的方法，该现象发生在压缩表示不足以回答问题时。通过分析模型表示，研究发现结合查询信息可以更有效地检测overflow，从而为预处理阶段的错误缓解提供可能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在处理长上下文时面临效率挑战，尤其是在资源受限的环境下。软压缩技术可以扩展上下文长度，但其压缩能力的极限以及何时会丢失任务相关信息（即token overflow）的研究尚不充分。

Method: 定义了“token overflow”并提出了一种表征和检测方法。在xRAG软压缩设置下，作者首先尝试使用查询无关的饱和统计量来区分压缩和未压缩的token表示，并评估其检测overflow的能力。随后，他们使用轻量级探测分类器，结合查询和上下文的xRAG表示，来检测overflow，并在多个数据集上进行了评估。

Result: 查询无关的饱和统计量能够有效地区分压缩和未压缩的token表示，但其检测overflow的能力有限。结合查询信息的轻量级探测分类器在HotpotQA、SQuADv2和TriviaQA数据集上的平均AUC-ROC达到了0.72，表明结合查询信息能显著提升overflow检测性能。

Conclusion: 研究从查询无关的诊断方法转向了查询感知的检测器，为低成本的预LLM（大型语言模型）门控机制以缓解压缩引起的错误提供了可能，从而在资源受限的情况下更有效地利用软压缩技术处理长上下文。

Abstract: Efficient long-context processing remains a crucial challenge for contemporary large language models (LLMs), especially in resource-constrained environments. Soft compression architectures promise to extend effective context length by replacing long token sequences with smaller sets of learned compressed tokens. Yet, the limits of compressibility -- and when compression begins to erase task-relevant content -- remain underexplored. In this paper, we define \emph{token overflow} as a regime in which compressed representations no longer contain sufficient information to answer a given query, and propose a methodology to characterize and detect it. In the xRAG soft-compression setting, we find that query-agnostic saturation statistics reliably separate compressed from uncompressed token representations, providing a practical tool for identifying compressed tokens but showing limited overflow detection capability. Lightweight probing classifiers over both query and context xRAG representations detect overflow with 0.72 AUC-ROC on average on HotpotQA, SQuADv2, and TriviaQA datasets, demonstrating that incorporating query information improves detection performance. These results advance from query-independent diagnostics to query-aware detectors, enabling low-cost pre-LLM gating to mitigate compression-induced errors.

</details>


### [226] [Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications](https://arxiv.org/abs/2602.12241)
*Manjunath Kudlur,Evan King,James Wang,Pete Warden*

Main category: cs.CL

TL;DR: Moonshine v2 是一种流式 ASR 模型，它使用滑动窗口自注意力机制，在保持高准确率的同时，显著降低了延迟，非常适合资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 现有 ASR 模型（如 Transformer Encoder）虽然准确率高，但在流式处理和边缘设备上存在延迟高（TTFT 随输入长度线性增长）的问题。为了满足低延迟、高准确率的 on-device 流式 ASR 需求，需要新的模型。

Method: 提出了 Moonshine v2 模型，采用 ergodic 架构，核心是滑动窗口自注意力机制。这种机制限制了注意力范围，实现了有界的低延迟推理，同时保留了局部上下文信息。

Result: Moonshine v2 在标准 ASR 基准测试中取得了最先进的词错误率。其准确率与模型大小 6 倍于它的模型相当，但运行速度显著更快。这表明精心设计的局部注意力机制在准确率上可以与全局注意力相媲美，但成本更低。

Conclusion: 精心设计的局部注意力机制（如 Moonshine v2 中使用的）在保持高准确率的同时，能够大幅降低模型大小和延迟。这为在边缘设备上实现交互式语音接口开辟了新的可能性。

Abstract: Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong accuracy baseline for automatic speech recognition (ASR) because every frame can directly attend to every other frame, which resolves otherwise locally ambiguous acoustics using distant lexical context. However, this global dependency incurs quadratic complexity in sequence length, inducing an inherent "encode-the-whole-utterance" latency profile. For streaming use cases, this causes TTFT to grow linearly with utterance length as the encoder must process the entire prefix before any decoder token can be emitted. To better meet the needs of on-device, streaming ASR use cases we introduce Moonshine v2, an ergodic streaming-encoder ASR model that employs sliding-window self-attention to achieve bounded, low-latency inference while preserving strong local context. Our models achieve state of the art word error rates across standard benchmarks, attaining accuracy on-par with models 6x their size while running significantly faster. These results demonstrate that carefully designed local attention is competitive with the accuracy of full attention at a fraction of the size and latency cost, opening new possibilities for interactive speech interfaces on edge devices.

</details>


### [227] [Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education](https://arxiv.org/abs/2602.12196)
*Mohamed Huti,Alasdair Mackintosh,Amy Waldock,Dominic Andrews,Maxime Lelièvre,Moritz Boos,Tobias Murray,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod*

Main category: cs.CL

TL;DR: 该论文提出了视觉推理基准（VRB），一个包含701个来自赞比亚和印度小学考试的真实视觉数学问题的数学数据集，用于评估多模态大语言模型（MLLM）在解决课堂视觉问题上的能力，并发现当前模型在静态任务上表现良好，但在动态空间操作（如折叠、反射、旋转）上存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 现有的AI模型在文本推理方面表现出色，但在处理空间和关系结构方面存在瓶颈，尤其是在依赖视觉的早期数学教育中。作者希望通过构建一个真实世界的视觉推理数据集来评估MLLM在教育场景中的能力，并找出其局限性。

Method: 作者创建了一个名为视觉推理基准（VRB）的数据集，其中包含701个来自赞比亚和印度小学考试的、经过筛选但未编辑的、带有最小文本的图像问题。这些问题涵盖了类比推理、模式补全和空间匹配等任务。然后，使用该数据集来评估MLLM在解决这些真实世界视觉问题上的表现。

Result: 研究发现，MLLM在处理静态视觉任务（如计数和缩放）时表现出较强的能力，但在动态空间操作（如折叠、反射和旋转）方面遇到了“空间天花板”，能力明显下降。作者将这种能力差异称为“锯齿形前沿”。

Conclusion: 当前MLLM在解决小学数学中的视觉推理问题方面存在显著局限性，特别是在动态空间操作方面。这种局限性可能导致在课堂使用时出现错误的标记、虚假的支架式教学以及加剧学生的误解。因此，像VRB这样专注于教育的基准对于确定多模态工具在课堂中的功能边界至关重要。

Abstract: AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.

</details>


### [228] [A technical curriculum on language-oriented artificial intelligence in translation and specialised communication](https://arxiv.org/abs/2602.12251)
*Ralph Krüger*

Main category: cs.CL

TL;DR: 该论文介绍了一个面向语言与翻译（L&T）行业的语言导向人工智能（AI）技术课程，旨在提升行业内人员的AI素养，并测试了其教学效果，发现课程有效但需要更高层级的教学支持。


<details>
  <summary>Details</summary>
Motivation: 为了在语言与翻译行业中提升从业人员对现代语言导向AI的概念和技术理解，并培养他们的计算思维、算法意识和数字韧性。

Method: 开发了一个包含向量嵌入、神经网络技术基础、分词和Transformer神经网络等核心内容的课程，并在一个AI相关的MA课程中进行了教学测试，收集了参与者的反馈。

Result: 课程显示出良好的教学效果，但参与者反馈认为需要更高级别的教学支持（如讲师指导）以获得最佳学习条件。

Conclusion: 该技术课程在提升L&T行业人员的AI素养方面是有效的，但为了实现最佳学习效果，需要将其融入到包含讲师支持等更高层级的教学支架中。

Abstract: This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technical/algorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks. It is intended to help users develop computational thinking as well as algorithmic awareness and algorithmic agency, ultimately contributing to their digital resilience in AI-driven work environments. The didactic suitability of the curriculum was tested in an AI-focused MA course at the Institute of Translation and Multilingual Communication at TH Koeln. Results suggest the didactic effectiveness of the curriculum, but participant feedback indicates that it should be embedded into higher-level didactic scaffolding - e.g., in the form of lecturer support - in order to enable optimal learning conditions.

</details>


### [229] [T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization](https://arxiv.org/abs/2602.12262)
*Tunyu Zhang,Xinxi Zhang,Ligong Han,Haizhou Shi,Xiaoxiao He,Zhuowei Li,Hao Wang,Kai Xu,Akash Srivastava,Hao Wang,Vladimir Pavlovic,Dimitris N. Metaxas*

Main category: cs.CL

TL;DR: 该研究提出了一种轨迹自蒸馏框架，通过蒸馏模型自身的生成轨迹来改进少量步数解码的扩散大语言模型（DLLM）的效率和质量，并引入了反向 KL 目标 DDO 来增强模式识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有DLLM在加速文本生成时，面临着步数过多导致效率低下，或步数过少导致生成质量严重下降的困境。研究旨在解决这一问题，提升DLLM在少步数解码下的推理效率和生成质量。

Method: 提出了一种轨迹自蒸馏框架，结合了反向 KL 目标（Direct Discriminative Optimization, DDO），用于提升学生模型对教师模型高概率模式的模仿能力，从而改进少步数解码的性能。

Result: 在多个基准测试中，该方法在严格的步数限制下，一致性地优于少步数基线和标准训练方法，显著缩小了与全步数解码的性能差距。

Conclusion: 该研究成功建立了一个强大的基础，为实现实用的少步数DLLM铺平了道路，尽管全步数解码仍然在性能上占优。

Abstract: Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.

</details>


### [230] [On-Policy Context Distillation for Language Models](https://arxiv.org/abs/2602.12275)
*Tianzhu Ye,Li Dong,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.CL

TL;DR: 提出了一种名为 On-Policy Context Distillation (OPCD) 的新框架，它结合了 On-Policy 蒸馏和上下文蒸馏，能够将上下文知识有效蒸馏到语言模型参数中，并在数学推理、文本游戏和领域特定任务中取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了让语言模型能够将其在上下文中学到的知识内化到模型参数中，从而提升模型的性能和泛化能力。

Method: 提出 OPCD 框架，该框架通过在学生模型自身生成的轨迹上进行训练，同时最小化与上下文条件化教师模型的反向 KL 散度来实现。OPCD 将 On-Policy 蒸馏与上下文蒸馏相结合。

Result: OPCD 在数学推理、文本游戏和领域特定任务中表现出有效性，并且一致优于基线方法。它实现了更高的任务准确性，同时更好地保留了模型在分布外（OOD）的能力。此外，OPCD 能够实现有效的跨模型尺寸蒸馏，即较小的学生模型可以从较大的教师模型中内化经验知识。

Conclusion: OPCD 是一种有效的框架，可以实现上下文知识蒸馏，提高语言模型的性能和泛化能力。它在多种应用中取得了显著效果，并且能够支持跨模型尺寸的知识转移。

Abstract: Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own generated trajectories while minimizing reverse Kullback-Leibler divergence against a context-conditioned teacher. We demonstrate the effectiveness of OPCD on two important applications: experiential knowledge distillation, where models extract and consolidate transferable knowledge from their historical solution traces, and system prompt distillation, where models internalize beneficial behaviors encoded in optimized prompts. Across mathematical reasoning, text-based games, and domain-specific tasks, OPCD consistently outperforms baseline methods, achieving higher task accuracy while better preserving out-of-distribution capabilities. We further show that OPCD enables effective cross-size distillation, where smaller student models can internalize experiential knowledge from larger teachers.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [231] [H-WM: Robotic Task and Motion Planning Guided by Hierarchical World Model](https://arxiv.org/abs/2602.11291)
*Wenyuan Chen,Jinbang Huang,Oscar Pang,Zhiyuan Li,Xiao Hu,Lingfeng Zhang,Zhanguang Zhang,Mark Coates,Tongtong Cao,Xingyue Quan,Yingxue Zhang*

Main category: cs.RO

TL;DR: 提出了一种名为H-WM的分层世界模型，该模型能够同时预测逻辑状态和视觉状态的转换，将符号推理的长期鲁棒性与视觉观测的感知基础相结合，适用于机器人规划和控制。


<details>
  <summary>Details</summary>
Motivation: 现有的世界模型方法在处理机器人动作和长期预测时存在困难，如视频生成或自然语言预测难以直接与机器人动作关联，且误差易累积。传统的符号逻辑世界模型缺乏视觉感知能力，无法实现符号和感知状态的同步预测。

Method: 提出了一种名为H-WM的分层世界模型，该模型包含一个高级逻辑世界模型和一个低级视觉世界模型，通过一个双层框架联合预测逻辑和视觉状态的转换。并构建了一个包含机器人运动、符号状态、动作和视觉观测的数据集来训练H-WM。

Result: H-WM能够提供稳定一致的中间引导，有效缓解误差累积，并实现机器人跨越长任务序列的鲁棒执行。在视觉-语言-动作（VLA）控制策略上的实验证明了该方法的有效性和通用性。

Conclusion: H-WM通过结合符号推理和视觉感知，为机器人规划和控制提供了一种更鲁棒、更具感知基础的世界模型方法，能够有效处理长期任务的规划和执行。

Abstract: World models are becoming central to robotic planning and control, as they enable prediction of future state transitions. Existing approaches often emphasize video generation or natural language prediction, which are difficult to directly ground in robot actions and suffer from compounding errors over long horizons. Traditional task and motion planning relies on symbolic logic world models, such as planning domains, that are robot-executable and robust for long-horizon reasoning. However, these methods typically operate independently of visual perception, preventing synchronized symbolic and perceptual state prediction. We propose a Hierarchical World Model (H-WM) that jointly predicts logical and visual state transitions within a unified bilevel framework. H-WM combines a high-level logical world model with a low-level visual world model, integrating the robot-executable, long-horizon robustness of symbolic reasoning with perceptual grounding from visual observations. The hierarchical outputs provide stable and consistent intermediate guidance for long-horizon tasks, mitigating error accumulation and enabling robust execution across extended task sequences. To train H-WM, we introduce a robotic dataset that aligns robot motion with symbolic states, actions, and visual observations. Experiments across vision-language-action (VLA) control policies demonstrate the effectiveness and generality of the approach.

</details>


### [232] [Mitigating Error Accumulation in Continuous Navigation via Memory-Augmented Kalman Filtering](https://arxiv.org/abs/2602.11183)
*Yin Tang,Jiawei Ma,Jinrui Zhang,Alex Jinpeng Wang,Deyu Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为 NeuroKalman 的新框架，用于解决无人机在复杂环境中连续导航时累积误差的问题，通过将导航过程视为递归贝叶斯状态估计问题，并结合运动动力学和历史观测来纠正定位漂移。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言导航（VLN）模型依赖于推断导航，这种方法容易累积位置误差，导致内部状态与真实坐标不一致（状态漂移），从而影响整体轨迹预测的准确性。

Method: NeuroKalman 框架将导航过程解耦为两个过程：基于运动动力学的先验预测（Prior Prediction）和基于历史观测的似然校正（Likelihood Correction）。其中，测量似然的核密度估计（Kernel Density Estimation）与基于注意力机制的检索机制相结合，允许系统在不进行梯度更新的情况下，利用检索到的历史锚点来校正潜在表征。

Result: 在 TravelUAV 基准数据集上的实验表明，NeuroKalman 方法在仅用 10% 的训练数据进行微调的情况下，显著优于现有基线方法，并有效抑制了漂移的累积。

Conclusion: NeuroKalman 框架通过借鉴经典控制理论中的递归贝叶斯状态估计方法，成功地解决了 VLN 模型中的状态漂移问题，提高了无人机在复杂环境下的导航精度和轨迹鲁棒性。

Abstract: Continuous navigation in complex environments is critical for Unmanned Aerial Vehicle (UAV). However, the existing Vision-Language Navigation (VLN) models follow the dead-reckoning, which iteratively updates its position for the next waypoint prediction, and subsequently construct the complete trajectory. Then, such stepwise manner will inevitably lead to accumulated errors of position over time, resulting in misalignment between internal belief and objective coordinates, which is known as "state drift" and ultimately compromises the full trajectory prediction. Drawing inspiration from classical control theory, we propose to correct for errors by formulating such sequential prediction as a recursive Bayesian state estimation problem. In this paper, we design NeuroKalman, a novel framework that decouples navigation into two complementary processes: a Prior Prediction, based on motion dynamics and a Likelihood Correction, from historical observation. We first mathematically associate Kernel Density Estimation of the measurement likelihood with the attention-based retrieval mechanism, which then allows the system to rectify the latent representation using retrieved historical anchors without gradient updates. Comprehensive experiments on TravelUAV benchmark demonstrate that, with only 10% of the training data fine-tuning, our method clearly outperforms strong baselines and regulates drift accumulation.

</details>


### [233] [ExtremControl: Low-Latency Humanoid Teleoperation with Direct Extremity Control](https://arxiv.org/abs/2602.11321)
*Ziyan Xiong,Lixing Fang,Junyun Huang,Kashu Yamazaki,Hao Zhang,Chuang Gan*

Main category: cs.RO

TL;DR: 本文提出了一个名为 ExtremControl 的低延迟全身控制框架，用于人形机器人遥操作，通过直接在人体末端执行器（如手臂和腿）的 SE(3) 位姿上操作，并结合笛卡尔空间映射和低级速度前馈控制，实现了低至 50ms 的端到端延迟，显著提高了机器人的响应速度，并在乒乓球平衡、杂耍等任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人遥操作系统由于复杂的运动重定向和仅基于位置的 PD 控制，存在显著的延迟，限制了机器人执行需要快速反应和反馈的任务。因此，需要一个低延迟的控制框架来克服这些限制。

Method: ExtremControl 框架主要包含三个部分：1. 直接在选定刚性连接（主要是人形机器人的末端执行器）的 SE(3) 位姿上操作，避免了对全身的运动重定向。2. 使用笛卡尔空间映射，将人体运动直接转换为人形机器人的连杆目标。3. 在低级控制中加入速度前馈控制，以支持快速变化的控制接口下的高响应行为。

Result: 该框架实现了低至 50ms 的端到端延迟，远低于现有技术 200ms 的延迟。实验结果表明，ExtremControl 能够支持高度响应的行为，例如乒乓球平衡、杂耍和实时反馈。

Conclusion: ExtremControl 是一个有效的低延迟全身控制框架，能够显著提高人形机器人遥操作系统的响应速度，并在仿真和真实世界环境中都得到了验证，为实现更直观、更具交互性的人形机器人遥操作开辟了道路。

Abstract: Building a low-latency humanoid teleoperation system is essential for collecting diverse reactive and dynamic demonstrations. However, existing approaches rely on heavily pre-processed human-to-humanoid motion retargeting and position-only PD control, resulting in substantial latency that severely limits responsiveness and prevents tasks requiring rapid feedback and fast reactions. To address this problem, we propose ExtremControl, a low latency whole-body control framework that: (1) operates directly on SE(3) poses of selected rigid links, primarily humanoid extremities, to avoid full-body retargeting; (2) utilizes a Cartesian-space mapping to directly convert human motion to humanoid link targets; and (3) incorporates velocity feedforward control at low level to support highly responsive behavior under rapidly changing control interfaces. We further provide a unified theoretical formulation of ExtremControl and systematically validate its effectiveness through experiments in both simulation and real-world environments. Building on ExtremControl, we implement a low-latency humanoid teleoperation system that supports both optical motion capture and VR-based motion tracking, achieving end-to-end latency as low as 50ms and enabling highly responsive behaviors such as ping-pong ball balancing, juggling, and real-time return, thereby substantially surpassing the 200ms latency limit observed in prior work.

</details>


### [234] [MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation](https://arxiv.org/abs/2602.11337)
*Yejin Kim,Wilbert Pumacay,Omar Rayyan,Max Argus,Winson Han,Eli VanderBilt,Jordi Salvador,Abhay Deshpande,Rose Hendrix,Snehal Jauhri,Shuo Liu,Nur Muhammad Mahi Shafiullah,Maya Guru,Ainaz Eftekhar,Karen Farley,Donovan Clay,Jiafei Duan,Arjun Guru,Piper Wolters,Alvaro Herrasti,Ying-Chun Lee,Georgia Chalvatzaki,Yuchen Cui,Ali Farhadi,Dieter Fox,Ranjay Krishna*

Main category: cs.RO

TL;DR: 本文提出了MolmoSpaces，一个包含230k个室内环境和130k个物体资产的开源生态系统，用于大规模机器人策略的基准测试，并设计了一个包含8个任务的MolmoSpaces-Bench。该系统支持多种模拟器，并在各种具身任务上表现出良好的泛化能力和与真实世界的强相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人基准测试在应对真实世界中数量庞大且变化多样的场景、物体几何和任务规范时存在不足，物理评估难以实现大规模和多样化的测试。因此，需要一个能够支持大规模机器人策略基准测试的基础设施。

Method: 构建了一个名为MolmoSpaces的开源生态系统，包含230k个室内环境（手工制作和程序生成）以及130k个带注释的物体资产（包括48k个可操作物体和42M个稳定抓取）。该系统支持MuJoCo、Isaac和ManiSkill等模拟器，并涵盖静态/移动操作、导航及多房间长时任务。基于此，设计了MolmoSpaces-Bench基准套件，包含8个任务，用于评估机器人与环境和物体的交互。

Result: MolmoSpaces-Bench展示了优异的sim-to-real相关性（R = 0.96, \rho = 0.98）。实验表明，新的、更强的零样本策略在该基准上优于早期版本，并识别出提示词措辞、初始关节位置和相机遮挡是影响性能的关键因素。

Conclusion: MolmoSpaces生态系统及其开源资产和工具为大规模数据生成、策略训练和机器人学习研究的基准创建奠定了基础，有助于提升机器人应对复杂和多变真实世界场景的能力。

Abstract: Deploying robots at scale demands robustness to the long tail of everyday situations. The countless variations in scene layout, object geometry, and task specifications that characterize real environments are vast and underrepresented in existing robot benchmarks. Measuring this level of generalization requires infrastructure at a scale and diversity that physical evaluation alone cannot provide. We introduce MolmoSpaces, a fully open ecosystem to support large-scale benchmarking of robot policies. MolmoSpaces consists of over 230k diverse indoor environments, ranging from handcrafted household scenes to procedurally generated multiroom houses, populated with 130k richly annotated object assets, including 48k manipulable objects with 42M stable grasps. Crucially, these environments are simulator-agnostic, supporting popular options such as MuJoCo, Isaac, and ManiSkill. The ecosystem supports the full spectrum of embodied tasks: static and mobile manipulation, navigation, and multiroom long-horizon tasks requiring coordinated perception, planning, and interaction across entire indoor environments. We also design MolmoSpaces-Bench, a benchmark suite of 8 tasks in which robots interact with our diverse scenes and richly annotated objects. Our experiments show MolmoSpaces-Bench exhibits strong sim-to-real correlation (R = 0.96, \r{ho} = 0.98), confirm newer and stronger zero-shot policies outperform earlier versions in our benchmarks, and identify key sensitivities to prompt phrasing, initial joint positions, and camera occlusion. Through MolmoSpaces and its open-source assets and tooling, we provide a foundation for scalable data generation, policy training, and benchmark creation for robot learning research.

</details>


### [235] [Human Preference Modeling Using Visual Motion Prediction Improves Robot Skill Learning from Egocentric Human Video](https://arxiv.org/abs/2602.11393)
*Mrinal Verghese,Christopher G. Atkeson*

Main category: cs.RO

TL;DR: 提出一种从以自我为中心的人类视频中学习机器人技能的方法，通过在奖励函数中建模人类偏好，并优化机器人行为以最大化该奖励。


<details>
  <summary>Details</summary>
Motivation: 现有从人类视频中学习奖励的方法假设了有限的性能，并且需要在身体和环境差异之间转移学习到的值函数。研究旨在克服这些限制。

Method: 通过学习预测跟踪点在连续图像之间的运动来模拟人类偏好，并将奖励函数定义为在机器人行为的每一步中预测的物体运动与观察到的物体运动之间的一致性。使用改进的SAC算法，并在10次机器人演示的初始化下，从该奖励估计值函数，并优化一个最大化该值函数的策略。

Result: 所提出的方法能够在真实机器人上学习，并且学习到的策略在模拟和真实机器人上的多个任务中，其性能与现有工作相当或更优。

Conclusion: 该方法能够有效从以自我为中心的人类视频中学习机器人行为，克服了现有方法的局限性，并在不同任务上展现出良好的性能。

Abstract: We present an approach to robot learning from egocentric human videos by modeling human preferences in a reward function and optimizing robot behavior to maximize this reward. Prior work on reward learning from human videos attempts to measure the long-term value of a visual state as the temporal distance between it and the terminal state in a demonstration video. These approaches make assumptions that limit performance when learning from video. They must also transfer the learned value function across the embodiment and environment gap. Our method models human preferences by learning to predict the motion of tracked points between subsequent images and defines a reward function as the agreement between predicted and observed object motion in a robot's behavior at each step. We then use a modified Soft Actor Critic (SAC) algorithm initialized with 10 on-robot demonstrations to estimate a value function from this reward and optimize a policy that maximizes this value function, all on the robot. Our approach is capable of learning on a real robot, and we show that policies learned with our reward model match or outperform prior work across multiple tasks in both simulation and on the real robot.

</details>


### [236] [EasyMimic: A Low-Cost Framework for Robot Imitation Learning from Human Videos](https://arxiv.org/abs/2602.11464)
*Tao Zhang,Song Xia,Ye Wang,Qin Jin*

Main category: cs.RO

TL;DR: EasyMimic是一个低成本、可复现的框架，使用RGB摄像头视频进行机器人模仿学习，通过3D手部轨迹提取、动作对齐和视觉增强，有效弥合了人与机器人之间的领域差距，并允许在少量机器人数据上进行快速适应。


<details>
  <summary>Details</summary>
Motivation: 传统机器人模仿学习需要昂贵的真实世界数据收集，这对于低成本的家用机器人尤其具有挑战性。研究旨在解决这一数据收集成本高、机器人部署难的问题。

Method: EasyMimic框架包含以下关键组件：1. 从RGB视频中提取3D手部轨迹。2. 动作对齐模块将人类轨迹映射到低成本机器人的抓手控制空间。3. 引入一种简单易用的手部视觉增强策略来处理人机领域差异。4. 使用一种协同训练方法，结合处理后的人类数据和少量机器人数据进行模型微调，实现快速任务适应。

Result: 在低成本LeRobot平台上进行实验，EasyMimic在多种操作任务上取得了高水平的性能。研究表明，该方法显著降低了对昂贵机器人数据收集的依赖。

Conclusion: EasyMimic提供了一种低成本、高效的机器人模仿学习解决方案，能够从人类视频演示中快速学习操作策略，为将智能机器人引入家庭提供了切实可行的方法。

Abstract: Robot imitation learning is often hindered by the high cost of collecting large-scale, real-world data. This challenge is especially significant for low-cost robots designed for home use, as they must be both user-friendly and affordable. To address this, we propose the EasyMimic framework, a low-cost and replicable solution that enables robots to quickly learn manipulation policies from human video demonstrations captured with standard RGB cameras. Our method first extracts 3D hand trajectories from the videos. An action alignment module then maps these trajectories to the gripper control space of a low-cost robot. To bridge the human-to-robot domain gap, we introduce a simple and user-friendly hand visual augmentation strategy. We then use a co-training method, fine-tuning a model on both the processed human data and a small amount of robot data, enabling rapid adaptation to new tasks. Experiments on the low-cost LeRobot platform demonstrate that EasyMimic achieves high performance across various manipulation tasks. It significantly reduces the reliance on expensive robot data collection, offering a practical path for bringing intelligent robots into homes. Project website: https://zt375356.github.io/EasyMimic-Project/.

</details>


### [237] [Effective Task Planning with Missing Objects using Learning-Informed Object Search](https://arxiv.org/abs/2602.11468)
*Raihan Islam Arnob,Max Merlin,Abhishek Paudel,Benned Hedegaard,George Konidaris,Gregory Stein*

Main category: cs.RO

TL;DR: 提出了一种新的基于模型的LIOS（Learning-Informed Object Search）行动框架，用于解决移动机器人任务规划中的未知物体位置问题，并实现了有效的、有保证的、完整的、受学习启发的任务规划。


<details>
  <summary>Details</summary>
Motivation: 现有的基于PDDL的任务规划方法在物体位置未知时无法有效规划。虽然最近的物体搜索学习方法很有效，但它们是独立的工具，难以整合到完整的任务规划中，后者需要确定哪些物体是必需的以及何时搜索它们。

Method: 开发了一个以新的模型驱动的LIOS行动为中心的规划框架。每个LIOS行动都是一个旨在寻找和检索单个物体的策略。高层规划器将LIOS行动视为确定性的，并根据模型计算的预期成本，生成交织搜索和执行的计划，以实现有效、健全和完整的、受学习启发的任务规划。

Result: 在模拟的ProcTHOR家庭环境和真实世界中，该方法在检索和备餐等任务上优于非学习和已学习的基线方法。

Conclusion: 该框架有效地处理了不确定性，同时保持了与现有全知识求解器的兼容性，实现了在物体位置未知情况下的有效任务规划。

Abstract: Task planning for mobile robots often assumes full environment knowledge and so popular approaches, like planning via the PDDL, cannot plan when the locations of task-critical objects are unknown. Recent learning-driven object search approaches are effective, but operate as standalone tools and so are not straightforwardly incorporated into full task planners, which must additionally determine both what objects are necessary and when in the plan they should be sought out. To address this limitation, we develop a planning framework centered around novel model-based LIOS actions: each a policy that aims to find and retrieve a single object. High-level planning treats LIOS actions as deterministic and so -- informed by model-based calculations of the expected cost of each -- generates plans that interleave search and execution for effective, sound, and complete learning-informed task planning despite uncertainty. Our work effectively reasons about uncertainty while maintaining compatibility with existing full-knowledge solvers. In simulated ProcTHOR homes and in the real world, our approach outperforms non-learned and learned baselines on tasks including retrieval and meal prep.

</details>


### [238] [HyperDet: 3D Object Detection with Hyper 4D Radar Point Clouds](https://arxiv.org/abs/2602.11554)
*Yichun Xiao,Runwei Guan,Fangqiang Ding*

Main category: cs.RO

TL;DR: 提出了一种名为HyperDet的雷达点云增强框架，通过融合多帧、多雷达数据并进行几何一致性校验和前景增强，显著提升了纯雷达点云的质量，从而改善了雷达在3D目标检测任务上的表现，部分缩小了与LiDAR的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有的4D毫米波雷达在成本和天气鲁棒性方面优于LiDAR，但纯雷达的3D目标检测性能仍落后于LiDAR系统，原因是雷达点云稀疏、不规则且易受多径噪声干扰，导致几何信息较弱且不稳定。

Method: HyperDet框架首先通过聚合多帧、多角度的4D雷达回波来提高点云的覆盖度和密度；然后，利用轻量级的自洽性检查，在非重叠区域进行跨传感器的一致性校验，以抑制不一致的回波；接着，引入了一个前景增强的扩散模块，并结合训练时的雷达-LiDAR混合监督，以增强物体结构并提升雷达的各项属性（如多普勒、RCS）；最后，模型被蒸馏成一个一致性模型，实现单步推理。

Result: 在MAN TruckScenes数据集上，HyperDet显著优于直接使用原始雷达输入的VoxelNeXt和CenterPoint模型，部分缩小了纯雷达与LiDAR在3D目标检测上的性能差距。

Conclusion: 通过输入层面的数据增强和处理，可以在不修改现有LiDAR导向检测器架构的情况下，使雷达点云更好地被利用，从而提升纯雷达3D目标检测的性能。

Abstract: 4D mmWave radar provides weather-robust, velocity-aware measurements and is more cost-effective than LiDAR. However, radar-only 3D detection still trails LiDAR-based systems because radar point clouds are sparse, irregular, and often corrupted by multipath noise, yielding weak and unstable geometry. We present HyperDet, a detector-agnostic radar-only 3D detection framework that constructs a task-aware hyper 4D radar point cloud for standard LiDAR-oriented detectors. HyperDet aggregates returns from multiple surround-view 4D radars over consecutive frames to improve coverage and density, then applies geometry-aware cross-sensor consensus validation with a lightweight self-consistency check outside overlap regions to suppress inconsistent returns. It further integrates a foreground-focused diffusion module with training-time mixed radar-LiDAR supervision to densify object structures while lifting radar attributes (e.g., Doppler, RCS); the model is distilled into a consistency model for single-step inference. On MAN TruckScenes, HyperDet consistently improves over raw radar inputs with VoxelNeXt and CenterPoint, partially narrowing the radar-LiDAR gap. These results show that input-level refinement enables radar to better leverage LiDAR-oriented detectors without architectural modifications.

</details>


### [239] [Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis](https://arxiv.org/abs/2602.12047)
*Anutam Srinivasan,Antoine Leeman,Glen Chou*

Main category: cs.RO

TL;DR: 提出了一种结合保形预测（CP）和系统级综合（SLS）的框架，用于在分布外（OOD）规划和控制，旨在提高学习模型在训练数据分布之外的安全性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用学习到的动力学模型进行规划和控制时，当遇到超出训练数据分布的情况时，难以保证安全性和鲁棒性。本研究旨在解决这一挑战。

Method: 首先，利用加权CP和学习到的、依赖于状态和控制的协方差模型来推导高置信度的模型误差界限。然后，将这些界限集成到基于SLS的鲁棒非线性模型预测控制（MPC）公式中，通过体积优化的前向可达集在预测范围内实现约束收紧。

Result: 理论上，证明了在分布漂移下的覆盖率和鲁棒性保证，并分析了数据密度和轨迹管大小对预测覆盖率的影响。实验上，在不同复杂度的非线性系统（包括4D汽车和12D四旋翼无人机）上进行了验证，结果表明该方法在OOD情况下比固定界限和非鲁棒基线方法在安全性和鲁棒性方面有所提升。

Conclusion: 所提出的结合CP和SLS的框架能够有效地处理分布外规划和控制问题，显著提高了在数据分布之外的系统安全性和鲁棒性。

Abstract: We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.

</details>


### [240] [Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment](https://arxiv.org/abs/2602.12281)
*Jacky Kwok,Xilun Zhang,Mengdi Xu,Yuejiang Liu,Azalia Mirhoseini,Chelsea Finn,Marco Pavone*

Main category: cs.RO

TL;DR: 本文提出了一种名为CoVer的对比验证器，用于提高视觉-语言-动作（VLA）模型遵循自然语言指令的能力。通过在测试时验证指令和动作的对齐，并利用指令重述和动作生成的缩放定律，CoVer在多个基准测试中显著提高了指令遵循的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在理解和执行自然语言指令方面取得了进展，但仍存在指令与生成动作不匹配的问题。研究旨在缩小“意图-动作差距”。

Method: 本文研究了测试时验证（test-time verification）方法，特别关注了指令重述和动作生成的缩放定律。在此基础上，提出了CoVer（Contrastive Verifier），一个用于视觉-语言-动作对齐的对比验证器。CoVer采用“启动时计算”（boot-time compute）和分层验证推理流程，在部署前预计算指令的多种表述，生成多个动作候选，并使用验证器选择最优的指令和动作。同时，对比了扩展策略预训练的效果。

Result: CoVer在SIMPLER基准测试中，在分布内（in-distribution）和分布外（out-of-distribution）分别实现了22%和13%的性能提升。在真实世界实验中，性能进一步提升了45%。在PolaRiS基准测试中，CoVer使任务进度提高了14%，成功率提高了9%。

Conclusion: 测试时验证是一种有效缩小“意图-动作差距”的方法。通过利用指令重述和动作生成的缩放定律，CoVer能够有效地提高VLA模型在自然语言指令遵循任务上的表现，并且在计算资源和数据增加时能够良好扩展。

Abstract: The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the "intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce "boot-time compute" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.

</details>


### [241] [ReaDy-Go: Real-to-Sim Dynamic 3D Gaussian Splatting Simulation for Environment-Specific Visual Navigation with Moving Obstacles](https://arxiv.org/abs/2602.11575)
*Seungyeon Yoo,Youngseok Jang,Dabin Kim,Youngsoo Han,Seungwoo Jung,H. Jin Kim*

Main category: cs.RO

TL;DR: ReaDy-Go 提出了一个新颖的真实到模拟（real-to-sim）仿真流程，通过结合静态 3D 高斯泼溅（GS）场景和动态人类 GS 障碍物，生成逼真的动态导航数据集，以训练对现实世界动态环境具有鲁棒性的导航策略。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉导航模型在真实动态环境中表现不佳，主要受限于 sim-to-real 差距和针对特定部署环境训练策略的困难。尽管 3D 高斯泼溅（GS）可以缓解 sim-to-real 差距，但以往的研究忽略了动态环境中安全导航的重要性，仅处理静态场景或不真实的动态障碍物。

Method: ReaDy-Go 包含三个主要部分：1) 动态 GS 模拟器，将场景 GS 与人类动画模块结合，允许插入可动画化的人类 GS 模型，并根据 2D 轨迹合成逼真的人类动作；2) 利用模拟器、针对动态 GS 表示设计的机器人专家规划器和人类规划器生成动态导航数据集；3) 使用生成的数据集进行策略学习。

Result: ReaDy-Go 在模拟和真实世界的实验中均优于基线方法，在 sim-to-real 迁移后以及存在移动障碍物的情况下，导航性能均有提升。此外，在未见过的环境中进行零样本（zero-shot）sim-to-real 部署，展示了其泛化能力。

Conclusion: ReaDy-Go 能够生成逼真的动态环境导航数据集，并训练出对 sim-to-real 差距和移动障碍物都具有鲁棒性的导航策略，在真实世界的动态导航任务中表现出色，并具备良好的泛化潜力。

Abstract: Visual navigation models often struggle in real-world dynamic environments due to limited robustness to the sim-to-real gap and the difficulty of training policies tailored to target deployment environments (e.g., households, restaurants, and factories). Although real-to-sim navigation simulation using 3D Gaussian Splatting (GS) can mitigate this gap, prior works have assumed only static scenes or unrealistic dynamic obstacles, despite the importance of safe navigation in dynamic environments. To address these issues, we propose ReaDy-Go, a novel real-to-sim simulation pipeline that synthesizes photorealistic dynamic scenarios for target environments. ReaDy-Go generates photorealistic navigation datasets for dynamic environments by combining a reconstructed static GS scene with dynamic human GS obstacles, and trains policies robust to both the sim-to-real gap and moving obstacles. The pipeline consists of three components: (1) a dynamic GS simulator that integrates scene GS with a human animation module, enabling the insertion of animatable human GS avatars and the synthesis of plausible human motions from 2D trajectories, (2) navigation dataset generation for dynamic environments that leverages the simulator, a robot expert planner designed for dynamic GS representations, and a human planner, and (3) policy learning using the generated datasets. ReaDy-Go outperforms baselines across target environments in both simulation and real-world experiments, demonstrating improved navigation performance even after sim-to-real transfer and in the presence of moving obstacles. Moreover, zero-shot sim-to-real deployment in an unseen environment indicates its generalization potential. Project page: https://syeon-yoo.github.io/ready-go-site/.

</details>


### [242] [ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation](https://arxiv.org/abs/2602.11598)
*Zedong Chu,Shichao Xie,Xiaolong Wu,Yanfen Shen,Minghua Luo,Zhengbo Wang,Fei Liu,Xiaoxu Leng,Junjun Hu,Mingyang Yin,Jia Lu,Yingnan Guo,Kai Yang,Jiawei Han,Xu Chen,Yanqing Zhu,Yuxiang Zhao,Xin Liu,Yirong Yang,Ye He,Jiahang Wang,Yang Cai,Tianlin Zhang,Li Gao,Liu Liu,Mingchao Sun,Fan Jiang,Chiyu Wang,Zhicheng Liu,Hongyu Pan,Honglin Han,Zhining Gu,Kuan Yang,Jianfang Zhang,Di Jing,Zihao Guan,Wei Guo,Guoqing Liu,Di Yang,Xiangpo Yang,Menglin Yang,Hongguang Xing,Weiguo Li,Mu Xu*

Main category: cs.RO

TL;DR: 本文提出ABot-N0，一个统一的视觉-语言-动作（VLA）基础模型，通过分层“大脑-动作”架构和大规模数据集，在5个核心导航任务上实现了“大一统”，并在7个基准上取得了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的具身导航研究被任务特定的架构所碎片化，缺乏一个能够统一处理多种核心导航任务的模型。

Method: 提出ABot-N0，一个包含LLM驱动的“认知大脑”用于语义推理，以及基于Flow Matching的“动作专家”用于轨迹生成的“大脑-动作”分层架构。通过ABot-N0数据引擎，在7,802个3D场景中收集了16.9M专家轨迹和5.0M推理样本。集成了带有分层拓扑记忆的规划器，用于代理导航系统。

Result: ABot-N0在5个核心导航任务（Point-Goal, Object-Goal, Instruction-Following, POI-Goal, Person-Following）上实现了SOTA性能，显著优于专用模型。其代理导航系统在动态真实世界环境中实现了鲁棒的长时任务。

Conclusion: ABot-N0通过统一的基础模型和大规模数据，成功解决了具身导航的碎片化问题，并在多种任务和环境中展现出优越的性能和泛化能力。

Abstract: Embodied navigation has long been fragmented by task-specific architectures. We introduce ABot-N0, a unified Vision-Language-Action (VLA) foundation model that achieves a ``Grand Unification'' across 5 core tasks: Point-Goal, Object-Goal, Instruction-Following, POI-Goal, and Person-Following. ABot-N0 utilizes a hierarchical ``Brain-Action'' architecture, pairing an LLM-based Cognitive Brain for semantic reasoning with a Flow Matching-based Action Expert for precise, continuous trajectory generation.
  To support large-scale learning, we developed the ABot-N0 Data Engine, curating 16.9M expert trajectories and 5.0M reasoning samples across 7,802 high-fidelity 3D scenes (10.7 $\text{km}^2$). ABot-N0 achieves new SOTA performance across 7 benchmarks, significantly outperforming specialized models. Furthermore, our Agentic Navigation System integrates a planner with hierarchical topological memory, enabling robust, long-horizon missions in dynamic real-world environments.

</details>


### [243] [ViTaS: Visual Tactile Soft Fusion Contrastive Learning for Visuomotor Learning](https://arxiv.org/abs/2602.11643)
*Yufeng Tian,Shuiqi Cheng,Tianming Wei,Tianxing Zhou,Yuanhang Zhang,Zixian Liu,Qianwei Han,Zhecheng Yuan,Huazhe Xu*

Main category: cs.RO

TL;DR: 提出了一种名为ViTaS的框架，结合了视觉和触觉信息以增强机器人操作能力，特别是在遮挡场景下，通过软融合对比学习和CVAE模块来利用模态间的对齐和互补性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注视觉和触觉特征的对齐，并且集成机制过于简单（如直接拼接），未能充分利用两种模态的互补性，导致在遮挡场景下表现不佳，限制了其在现实世界中的应用。

Method: 提出ViTaS框架，引入软融合对比学习（Soft Fusion Contrastive Learning）作为对比学习的改进版本，并结合CVAE模块，以利用视觉-触觉表示中的对齐和互补性。

Result: 在12个模拟环境和3个真实环境中进行了实验，ViTaS显著优于现有基线方法。

Conclusion: ViTaS是一个简单而有效的框架，能够有效地融合视觉和触觉信息，以指导智能体的行为，并在机器人操作任务中展现出优越的性能，尤其是在处理遮挡场景时。

Abstract: Tactile information plays a crucial role in human manipulation tasks and has recently garnered increasing attention in robotic manipulation. However, existing approaches mostly focus on the alignment of visual and tactile features and the integration mechanism tends to be direct concatenation. Consequently, they struggle to effectively cope with occluded scenarios due to neglecting the inherent complementary nature of both modalities and the alignment may not be exploited enough, limiting the potential of their real-world deployment. In this paper, we present ViTaS, a simple yet effective framework that incorporates both visual and tactile information to guide the behavior of an agent. We introduce Soft Fusion Contrastive Learning, an advanced version of conventional contrastive learning method and a CVAE module to utilize the alignment and complementarity within visuo-tactile representations. We demonstrate the effectiveness of our method in 12 simulated and 3 real-world environments, and our experiments show that ViTaS significantly outperforms existing baselines. Project page: https://skyrainwind.github.io/ViTaS/index.html.

</details>


### [244] [Human-Like Gaze Behavior in Social Robots: A Deep Learning Approach Integrating Human and Non-Human Stimuli](https://arxiv.org/abs/2602.11648)
*Faezeh Vahedi,Morteza Memari,Ramtin Tabatabaei,Alireza Taheri*

Main category: cs.RO

TL;DR: 本研究通过训练 LSTM 和 Transformer 模型，实现了社交机器人模仿人类在包含非人类刺激的复杂社会情境下的注视行为，并通过用户满意度调查验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了让社交机器人在社会互动中进行更有效和无缝的沟通，需要让它们的注视行为能够适应人类活动并对各种刺激（包括非人类刺激）做出反应，而这是现有研究中被忽视的一个关键领域。

Method: 研究者在 Unity 软件中模拟了包含人类和非人类刺激（如对话、指向、开门、掉落物体）的场景，并使用 VR 眼镜收集了 41 名参与者的注视数据。利用这些数据，训练了 LSTM 和 Transformer 神经网络来预测个体的注视模式。随后，将模型部署到 NAO 机器人上，并通过 275 名参与者的问卷调查进行了用户满意度评估。

Result: 在模拟场景中，LSTM 和 Transformer 模型在动画场景中的预测准确率分别为 67.6% 和 70.4%，在真实世界场景中的准确率分别为 72% 和 71.6%。与现有方法相比，本研究的模型在准确性上有所提升，并且能够独特地考虑非人类刺激。机器人部署后的用户满意度调查结果显示，参与者在互动过程中满意度很高。

Conclusion: 本研究成功开发了一种能够模仿人类在复杂社会情境下（包括对非人类刺激的反应）注视行为的系统，从而提高了社交机器人与人类互动的质量，为社交机器人在复杂环境中的应用提供了新的可能。

Abstract: Nonverbal behaviors, particularly gaze direction, play a crucial role in enhancing effective communication in social interactions. As social robots increasingly participate in these interactions, they must adapt their gaze based on human activities and remain receptive to all cues, whether human-generated or not, to ensure seamless and effective communication. This study aims to increase the similarity between robot and human gaze behavior across various social situations, including both human and non-human stimuli (e.g., conversations, pointing, door openings, and object drops). A key innovation in this study, is the investigation of gaze responses to non-human stimuli, a critical yet underexplored area in prior research. These scenarios, were simulated in the Unity software as a 3D animation and a 360-degree real-world video. Data on gaze directions from 41 participants were collected via virtual reality (VR) glasses. Preprocessed data, trained two neural networks-LSTM and Transformer-to build predictive models based on individuals' gaze patterns. In the animated scenario, the LSTM and Transformer models achieved prediction accuracies of 67.6% and 70.4%, respectively; In the real-world scenario, the LSTM and Transformer models achieved accuracies of 72% and 71.6%, respectively. Despite the gaze pattern differences among individuals, our models outperform existing approaches in accuracy while uniquely considering non-human stimuli, offering a significant advantage over previous literature. Furthermore, deployed on the NAO robot, the system was evaluated by 275 participants via a comprehensive questionnaire, with results demonstrating high satisfaction during interactions. This work advances social robotics by enabling robots to dynamically mimic human gaze behavior in complex social contexts.

</details>


### [245] [AC-MASAC: An Attentive Curriculum Learning Framework for Heterogeneous UAV Swarm Coordination](https://arxiv.org/abs/2602.11735)
*Wanhao Liu,Junhong Dai,Yixuan Zhang,Shengyun Yin,Panshuo Li*

Main category: cs.RO

TL;DR: 提出了一种名为 AC-MASAC 的注意力课程学习框架，用于解决异构无人机群体协同路径规划中的挑战，通过角色感知异构注意力机制处理不对称依赖，并通过结构化课程策略解决稀疏奖励和灾难性遗忘问题，实验结果表明该方法优于现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习（MARL）在处理异构无人机群体协同路径规划时面临挑战，特别是在处理不对称的智能体间依赖、稀疏奖励以及训练过程中的灾难性遗忘问题。

Method: 提出了一种注意力课程学习框架（AC-MASAC），该框架包含：1. 角色感知异构注意力机制，用于显式建模不对称依赖；2. 结构化课程策略，结合了分层知识迁移和阶段比例经验回放，以解决稀疏奖励和灾难性遗忘问题。

Result: 在自定义的多智能体仿真平台上进行的验证显示，AC-MASAC 在成功率、编队保持率和成功加权任务时间方面，相比其他先进方法具有显著优势。

Conclusion: AC-MASAC 框架能够有效地处理异构无人机群体协同路径规划中的不对称依赖、稀疏奖励和灾难性遗忘问题，并在关键性能指标上取得了优于现有方法的表现。

Abstract: Cooperative path planning for heterogeneous UAV swarms poses significant challenges for Multi-Agent Reinforcement Learning (MARL), particularly in handling asymmetric inter-agent dependencies and addressing the risks of sparse rewards and catastrophic forgetting during training. To address these issues, this paper proposes an attentive curriculum learning framework (AC-MASAC). The framework introduces a role-aware heterogeneous attention mechanism to explicitly model asymmetric dependencies. Moreover, a structured curriculum strategy is designed, integrating hierarchical knowledge transfer and stage-proportional experience replay to address the issues of sparse rewards and catastrophic forgetting. The proposed framework is validated on a custom multi-agent simulation platform, and the results show that our method has significant advantages over other advanced methods in terms of Success Rate, Formation Keeping Rate, and Success-weighted Mission Time. The code is available at \textcolor{red}{https://github.com/Wanhao-Liu/AC-MASAC}.

</details>


### [246] [HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model](https://arxiv.org/abs/2602.11758)
*Dongting Li,Xingyu Chen,Qianyang Wu,Bo Chen,Sikai Wu,Hanyu Wu,Guoyao Zhang,Liang Li,Mingliang Zhou,Diyun Xiang,Jianzhu Ma,Qiang Zhang,Renjing Xu*

Main category: cs.RO

TL;DR: 提出了一种名为HAIC的统一框架，用于处理机器人与具有复杂动力学（包括欠驱动和非完整约束）的物体进行交互，无需外部状态估计，并通过动力学预测器、空间接地动态占用图和不对称微调实现了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的人机交互方法主要关注完全驱动且与机器人刚性耦合的物体，忽略了具有独立动力学和非完整约束的欠驱动物体，这些物体会引入耦合力和遮挡的控制挑战。

Method: 提出HAIC统一框架，包含一个动力学预测器（仅从本体感觉历史估计高阶物体状态），然后将预测状态投影到静态几何先验上形成空间接地动态占用图，以推断碰撞边界和接触可及性。采用不对称微调，使世界模型持续适应学生策略的探索，以应对分布变化。

Result: HAIC在多种敏捷任务（如滑板、不同负载下的推/拉车）中取得了高成功率，通过主动补偿惯性扰动。同时，它还能掌握多物体长时域任务，如在不同地形上搬运箱子，通过预测多个物体的动力学。

Conclusion: HAIC框架能够实现机器人与各种动力学物体之间鲁棒的人机交互，无需外部状态估计，并且能够处理复杂、长时域的任务。

Abstract: Humanoid robots show promise for complex whole-body tasks in unstructured environments. Although Human-Object Interaction (HOI) has advanced, most methods focus on fully actuated objects rigidly coupled to the robot, ignoring underactuated objects with independent dynamics and non-holonomic constraints. These introduce control challenges from coupling forces and occlusions. We present HAIC, a unified framework for robust interaction across diverse object dynamics without external state estimation. Our key contribution is a dynamics predictor that estimates high-order object states (velocity, acceleration) solely from proprioceptive history. These predictions are projected onto static geometric priors to form a spatially grounded dynamic occupancy map, enabling the policy to infer collision boundaries and contact affordances in blind spots. We use asymmetric fine-tuning, where a world model continuously adapts to the student policy's exploration, ensuring robust state estimation under distribution shifts. Experiments on a humanoid robot show HAIC achieves high success rates in agile tasks (skateboarding, cart pushing/pulling under various loads) by proactively compensating for inertial perturbations, and also masters multi-object long-horizon tasks like carrying a box across varied terrain by predicting the dynamics of multiple objects.

</details>


### [247] [LAMP: Implicit Language Map for Robot Navigation](https://arxiv.org/abs/2602.11862)
*Sibaek Lee,Hyeonwoo Yu,Giseop Kim,Sunwook Choi*

Main category: cs.RO

TL;DR: 提出了一种名为LAMP的新型零样本导航框架，它使用连续的、由语言驱动的神经网络场来生成精细路径，解决了现有方法在大型环境中内存需求大和分辨率有限的问题。LAMP通过隐式编码语言特征、粗略到精细的路径规划、基于梯度的优化以及使用von Mises-Fisher分布建模嵌入不确定性，提高了导航效率和精度，并在模拟和真实环境中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本导航方法在大型环境中存在内存需求过大和规划分辨率不足的问题。研究的动机是开发一种更具内存效率且能进行精细路径规划的导航框架。

Method: 提出LAMP（Language Map）框架，一种基于神经语言场的导航方法。它将语言特征编码为隐式神经网络场，并结合稀疏图进行粗略路径规划。随后，利用梯度优化在学习到的场中精细化目标区域附近的姿态。此外，采用贝叶斯框架，利用von Mises-Fisher分布建模嵌入不确定性，并通过图采样策略来处理大型环境。

Result: LAMP在NVIDIA Isaac Sim模拟器和真实多层建筑环境中进行了实验。结果表明，LAMP在内存效率和目标到达精度方面均优于现有的显式方法。

Conclusion: LAMP是一种新颖的、基于隐式语言场的导航框架，能够实现高效且高精度的零样本导航。该方法通过结合隐式表示、粗略到精细的规划和基于梯度的优化，解决了现有方法的局限性，并在大规模场景中展现出优越的性能。

Abstract: Recent advances in vision-language models have made zero-shot navigation feasible, enabling robots to follow natural language instructions without requiring labeling. However, existing methods that explicitly store language vectors in grid or node-based maps struggle to scale to large environments due to excessive memory requirements and limited resolution for fine-grained planning. We introduce LAMP (Language Map), a novel neural language field-based navigation framework that learns a continuous, language-driven map and directly leverages it for fine-grained path generation. Unlike prior approaches, our method encodes language features as an implicit neural field rather than storing them explicitly at every location. By combining this implicit representation with a sparse graph, LAMP supports efficient coarse path planning and then performs gradient-based optimization in the learned field to refine poses near the goal. This coarse-to-fine pipeline, language-driven, gradient-guided optimization is the first application of an implicit language map for precise path generation. This refinement is particularly effective at selecting goal regions not directly observed by leveraging semantic similarities in the learned feature space. To further enhance robustness, we adopt a Bayesian framework that models embedding uncertainty via the von Mises-Fisher distribution, thereby improving generalization to unobserved regions. To scale to large environments, LAMP employs a graph sampling strategy that prioritizes spatial coverage and embedding confidence, retaining only the most informative nodes and substantially reducing computational overhead. Our experimental results, both in NVIDIA Isaac Sim and on a real multi-floor building, demonstrate that LAMP outperforms existing explicit methods in both memory efficiency and fine-grained goal-reaching accuracy.

</details>


### [248] [Learning to Manipulate Anything: Revealing Data Scaling Laws in Bounding-Box Guided Policies](https://arxiv.org/abs/2602.11885)
*Yihao Wu,Jinming Ma,Junbo Tan,Yanzhao Yu,Shoujie Li,Mingliang Zhou,Diyun Xiang,Xueqian Wang*

Main category: cs.RO

TL;DR: 该研究提出了一种结合边界框指令和解耦的语义运动框架，以提高基于扩散策略的语义操作的泛化能力，并通过自动化标注工具 Label-UMI 收集大规模数据集，发现泛化性能与边界框对象数量存在幂律关系。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散策略的语义操作在复杂环境中泛化能力有限，主要原因是纯文本指令不足以引导策略关注目标对象。为了解决这个问题，研究者希望通过引入边界框指令来直接指定目标对象，并探索语义操作任务中的数据缩放规律。

Method: 该研究设计了一个名为 Label-UMI 的自动化标注流程，用于高效收集带有语义标签的演示数据。他们还提出了一个语义-运动解耦框架，该框架整合了目标检测和基于边界框引导的扩散策略，以增强语义操作的泛化性和适应性。

Result: 通过在包含大量数据的真实世界实验中验证，该方法被证明是有效的。研究还揭示了泛化性能与边界框对象数量之间存在幂律关系。最终，研究提出了一种有效的语义操作数据收集策略，在四项任务中对可见和不可见的对象均达到了 85% 的成功率。

Conclusion: 通过结合边界框指令和语义-运动解耦框架，可以显著提高语义操作的泛化能力。数据缩放规律的存在为未来数据收集和模型训练提供了指导。提出的数据收集策略在各种场景下都能实现高成功率，为机器人领域的实际应用奠定了基础。

Abstract: Diffusion-based policies show limited generalization in semantic manipulation, posing a key obstacle to the deployment of real-world robots. This limitation arises because relying solely on text instructions is inadequate to direct the policy's attention toward the target object in complex and dynamic environments. To solve this problem, we propose leveraging bounding-box instruction to directly specify target object, and further investigate whether data scaling laws exist in semantic manipulation tasks. Specifically, we design a handheld segmentation device with an automated annotation pipeline, Label-UMI, which enables the efficient collection of demonstration data with semantic labels. We further propose a semantic-motion-decoupled framework that integrates object detection and bounding-box guided diffusion policy to improve generalization and adaptability in semantic manipulation. Throughout extensive real-world experiments on large-scale datasets, we validate the effectiveness of the approach, and reveal a power-law relationship between generalization performance and the number of bounding-box objects. Finally, we summarize an effective data collection strategy for semantic manipulation, which can achieve 85\% success rates across four tasks on both seen and unseen objects. All datasets and code will be released to the community.

</details>


### [249] [General Humanoid Whole-Body Control via Pretraining and Fast Adaptation](https://arxiv.org/abs/2602.11929)
*Zepeng Wang,Jiangxing Wang,Shiqing Yao,Yu Zhang,Ziluo Ding,Ming Yang,Yuxuan Wang,Haobin Jiang,Chao Ma,Xiaochuan Shi,Zongqing Lu*

Main category: cs.RO

TL;DR: 提出了一种名为FAST的通用人形机器人全身控制框架，通过Parseval引导的残差策略适应和质心感知控制，实现了快速适应和稳定的运动跟踪，并在仿真和真实世界中表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人全身控制器在处理多样化的运动分布、快速适应以及高动态场景下的鲁棒平衡方面存在挑战，通常需要特定任务训练且在新运动上适应性差。

Method: FAST框架包含两个核心部分：1. Parseval-Guided Residual Policy Adaptation，学习一个轻量级的差分动作策略，并施加正交性和KL约束，以高效适应分布外运动并缓解灾难性遗忘。2. Center-of-Mass-Aware Control，整合了质心相关的观测和目标，以增强跟踪复杂参考运动时的平衡能力。

Result: FAST在仿真和真实世界部署的广泛实验中，相比现有最先进方法，在鲁棒性、适应效率和泛化能力方面均表现出持续优越性。

Conclusion: FAST是一个通用的、高效的、鲁棒的人形机器人全身控制框架，能够快速适应新颖运动并保持稳定的跟踪和平衡。

Abstract: Learning a general whole-body controller for humanoid robots remains challenging due to the diversity of motion distributions, the difficulty of fast adaptation, and the need for robust balance in high-dynamic scenarios. Existing approaches often require task-specific training or suffer from performance degradation when adapting to new motions. In this paper, we present FAST, a general humanoid whole-body control framework that enables Fast Adaptation and Stable Motion Tracking. FAST introduces Parseval-Guided Residual Policy Adaptation, which learns a lightweight delta action policy under orthogonality and KL constraints, enabling efficient adaptation to out-of-distribution motions while mitigating catastrophic forgetting. To further improve physical robustness, we propose Center-of-Mass-Aware Control, which incorporates CoM-related observations and objectives to enhance balance when tracking challenging reference motions. Extensive experiments in simulation and real-world deployment demonstrate that FAST consistently outperforms state-of-the-art baselines in robustness, adaptation efficiency, and generalization.

</details>


### [250] [Accelerating Robotic Reinforcement Learning with Agent Guidance](https://arxiv.org/abs/2602.11978)
*Haojun Chen,Zili Zou,Chengdong Ma,Yaoxiang Pu,Haotong Zhang,Yuanpei Chen,Yaodong Yang*

Main category: cs.RO

TL;DR: 本文提出了一种名为Agent-guided Policy Search (AGPS) 的新框架，使用多模态智能体替代人工监督，以提高机器人强化学习的样本效率和可扩展性，并在精度插入和可变形物体操作任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中机器人强化学习的样本效率低下，而现有的人工介入（HIL）方法存在可扩展性差、监督比例低、操作员疲劳和人为不一致性等问题，阻碍了其大规模应用。

Method: AGPS框架利用多模态智能体作为语义世界模型，通过可执行工具提供精确的引导，包括纠正性航点和空间约束，以指导物理探索并裁剪探索空间。

Result: AGPS在精度插入和可变形物体操作两个任务上，相比于传统的人工介入（HIL）方法，在样本效率上取得了更好的性能。

Conclusion: AGPS框架成功自动化了机器人强化学习的监督流程，通过引入智能体而非人工进行监督，克服了现有方法的局限性，为实现无人值守和可扩展的机器人学习开辟了道路。

Abstract: Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.

</details>


### [251] [Robot-DIFT: Distilling Diffusion Features for Geometrically Consistent Visuomotor Control](https://arxiv.org/abs/2602.11934)
*Yu Deng,Yufeng Jin,Xiaogang Jia,Jiahong Xue,Gerhard Neumann,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: 本研究提出Robot-DIFT框架，通过蒸馏冻结的扩散模型来解决现有视觉模型在机器人操作中的几何敏感性不足问题，以提高控制性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型（包括VLAs）优化目标是语义不变性，这不利于机器人操作所需的精细几何感知；而扩散模型虽然具有几何敏感性，但直接用于控制存在不稳定性、延迟和微调漂移问题。

Method: 提出Robot-DIFT框架，通过“Manifold Distillation”将冻结的扩散教师模型（提供几何信息）蒸馏到一个确定的空间-语义特征金字塔网络（S2-FPN）中，以实现稳定、实时的控制。

Result: 在DROID数据集上预训练的Robot-DIFT在几何一致性和控制性能上优于现有的判别式基线模型。

Conclusion: 模型的视觉学习方式决定了其操控能力，几何敏感性是实现更好机器人操作的关键。Robot-DIFT成功地结合了扩散模型的几何先验和确定性模型的稳定性，为机器人操作提供了一种新的有效方法。

Abstract: We hypothesize that a key bottleneck in generalizable robot manipulation is not solely data scale or policy capacity, but a structural mismatch between current visual backbones and the physical requirements of closed-loop control. While state-of-the-art vision encoders (including those used in VLAs) optimize for semantic invariance to stabilize classification, manipulation typically demands geometric sensitivity the ability to map millimeter-level pose shifts to predictable feature changes. Their discriminative objective creates a "blind spot" for fine-grained control, whereas generative diffusion models inherently encode geometric dependencies within their latent manifolds, encouraging the preservation of dense multi-scale spatial structure. However, directly deploying stochastic diffusion features for control is hindered by stochastic instability, inference latency, and representation drift during fine-tuning. To bridge this gap, we propose Robot-DIFT, a framework that decouples the source of geometric information from the process of inference via Manifold Distillation. By distilling a frozen diffusion teacher into a deterministic Spatial-Semantic Feature Pyramid Network (S2-FPN), we retain the rich geometric priors of the generative model while ensuring temporal stability, real-time execution, and robustness against drift. Pretrained on the large-scale DROID dataset, Robot-DIFT demonstrates superior geometric consistency and control performance compared to leading discriminative baselines, supporting the view that how a model learns to see dictates how well it can learn to act.

</details>


### [252] [Decentralized Multi-Robot Obstacle Detection and Tracking in a Maritime Scenario](https://arxiv.org/abs/2602.12012)
*Muhammad Farhan Ahmed,Vincent Frémont*

Main category: cs.RO

TL;DR: 提出了一种去中心化的多机器人框架，用于通过无人机与自主水面航行器协同来检测和跟踪漂浮集装箱，该框架能够在有限通信下实现鲁棒的态势感知和可扩展的协调。


<details>
  <summary>Details</summary>
Motivation: 在海洋监测任务中，利用无人机和自主水面航行器组成的机器人团队具有潜力，但需要克服水面反射带来的感知挑战以及通信限制下的协调难题。

Method: 每个无人机使用YOLOv8和基于立体视差的视觉检测，并通过每个对象EKF进行目标跟踪，采用不确定性感知的数据关联。通过协方差交集保守地交换和融合紧凑的航迹摘要，以处理未知相关性。一个信息驱动的分配模块通过权衡预期的不确定性减少与旅行成本和安全间隔来分配目标并选择无人机悬停视角。

Result: 在模拟的海洋场景中，该框架提高了覆盖率、定位精度和跟踪一致性，同时保持了适度的通信需求。

Conclusion: 所提出的去中心化多机器人框架能够有效地在通信受限的环境中，利用无人机和自主水面航行器团队进行漂浮集装箱的检测和跟踪，实现了鲁棒的感知和高效的协调。

Abstract: Autonomous aerial-surface robot teams are promising for maritime monitoring. Robust deployment requires reliable perception over reflective water and scalable coordination under limited communication. We present a decentralized multi-robot framework for detecting and tracking floating containers using multiple UAVs cooperating with an autonomous surface vessel. Each UAV performs YOLOv8 and stereo-disparity-based visual detection, then tracks targets with per-object EKFs using uncertainty-aware data association. Compact track summaries are exchanged and fused conservatively via covariance intersection, ensuring consistency under unknown correlations. An information-driven assignment module allocates targets and selects UAV hover viewpoints by trading expected uncertainty reduction against travel effort and safety separation. Simulation results in a maritime scenario demonstrate improved coverage, localization accuracy, and tracking consistency while maintaining modest communication requirements.

</details>


### [253] [When would Vision-Proprioception Policies Fail in Robotic Manipulation?](https://arxiv.org/abs/2602.12032)
*Jingxian Lu,Wenke Xia,Yuxuan Wu,Zhiwu Lu,Di Hu*

Main category: cs.RO

TL;DR: 本研究调查了视觉-本体感知策略在机器人操作中的泛化能力，发现本体感知信号在运动过渡阶段（需要目标定位）压倒了视觉信息，导致泛化能力受限。提出了GAP算法，通过根据时间步是否处于运动过渡阶段来调整本体感知的梯度，从而实现更强的视觉-本体感知协同，提升了策略的鲁棒性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 近期研究在视觉-本体感知策略的泛化能力上存在不一致的观察结果，促使研究者深入探究其原因，并寻求提升策略泛化性的方法。

Method: 1. 通过时间控制的实验，分析了在机器人运动过渡阶段，视觉和本体感知在策略中的作用。2. 提出了梯度调整相位引导（GAP）算法，该算法能够根据每个时间步所属的运动过渡阶段的概率，自适应地调整本体感知信号的梯度下降幅度，从而平衡视觉和本体感知的学习。

Result: 研究发现，在需要目标定位的机器人运动过渡阶段，本体感知信号对策略的影响更大，而视觉信息的学习受到抑制。GAP算法能够有效缓解这一问题，使得视觉-本体感知策略在模拟和真实环境中，以及单臂和双臂设置下，都能实现更鲁棒和更具泛化性的性能，并且与现有模型兼容。

Conclusion: 本体感知信号在机器人运动过渡阶段的支配地位是限制视觉-本体感知策略泛化性的关键因素。GAP算法通过对本体感知梯度进行相位引导的调整，能够动态地促进视觉和本体感知之间的协同，从而开发出更鲁棒和更具泛化性的机器人操作策略。

Abstract: Proprioceptive information is critical for precise servo control by providing real-time robotic states. Its collaboration with vision is highly expected to enhance performances of the manipulation policy in complex tasks. However, recent studies have reported inconsistent observations on the generalization of vision-proprioception policies. In this work, we investigate this by conducting temporally controlled experiments. We found that during task sub-phases that robot's motion transitions, which require target localization, the vision modality of the vision-proprioception policy plays a limited role. Further analysis reveals that the policy naturally gravitates toward concise proprioceptive signals that offer faster loss reduction when training, thereby dominating the optimization and suppressing the learning of the visual modality during motion-transition phases. To alleviate this, we propose the Gradient Adjustment with Phase-guidance (GAP) algorithm that adaptively modulates the optimization of proprioception, enabling dynamic collaboration within the vision-proprioception policy. Specifically, we leverage proprioception to capture robotic states and estimate the probability of each timestep in the trajectory belonging to motion-transition phases. During policy learning, we apply fine-grained adjustment that reduces the magnitude of proprioception's gradient based on estimated probabilities, leading to robust and generalizable vision-proprioception policies. The comprehensive experiments demonstrate GAP is applicable in both simulated and real-world environments, across one-arm and dual-arm setups, and compatible with both conventional and Vision-Language-Action models. We believe this work can offer valuable insights into the development of vision-proprioception policies in robotic manipulation.

</details>


### [254] [Adaptive-Horizon Conflict-Based Search for Closed-Loop Multi-Agent Path Finding](https://arxiv.org/abs/2602.12024)
*Jiarui Li,Federico Pecora,Runyu Zhang,Gioele Zardini*

Main category: cs.RO

TL;DR: 本文提出了一种名为ACCBS的闭环多机器人路径规划算法，该算法通过动态调整规划时域和复用约束树，实现了在满足计算预算的同时，快速生成高质量的可行解，并具备任意时间（anytime）行为和对干扰的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有MAPF算法要么是难以处理干扰的开环规划器，要么是缺乏性能保证的闭环启发式算法。研究旨在弥合理论最优性与实际鲁棒性之间的差距，以满足大规模机器人部署的需求。

Method: ACCBS算法基于有限时域的CBS，并引入了受MPC迭代加深启发的时域变化机制。它能够根据计算预算动态调整规划时域，并通过复用单个约束树实现不同时域间的无缝过渡。

Result: ACCBS能够快速生成高质量的可行解决方案，并在计算预算增加时渐进最优，表现出任意时间行为。实验表明，ACCBS结合了对干扰的灵活性和强大的性能保证。

Conclusion: ACCBS作为一种闭环算法，能够有效结合鲁棒性和性能保证，为大规模机器人部署提供了一种可行的MAPF解决方案。

Abstract: MAPF is a core coordination problem for large robot fleets in automated warehouses and logistics. Existing approaches are typically either open-loop planners, which generate fixed trajectories and struggle to handle disturbances, or closed-loop heuristics without reliable performance guarantees, limiting their use in safety-critical deployments. This paper presents ACCBS, a closed-loop algorithm built on a finite-horizon variant of CBS with a horizon-changing mechanism inspired by iterative deepening in MPC. ACCBS dynamically adjusts the planning horizon based on the available computational budget, and reuses a single constraint tree to enable seamless transitions between horizons. As a result, it produces high-quality feasible solutions quickly while being asymptotically optimal as the budget increases, exhibiting anytime behavior. Extensive case studies demonstrate that ACCBS combines flexibility to disturbances with strong performance guarantees, effectively bridging the gap between theoretical optimality and practical robustness for large-scale robot deployment.

</details>


### [255] [HoloBrain-0 Technical Report](https://arxiv.org/abs/2602.12062)
*Xuewu Lin,Tianwei Lin,Yun Du,Hongyu Xie,Yiwei Jin,Jiawei Li,Shijie Wu,Qingze Wang,Mengdi Li,Mengao Zhao,Ziang Li,Chaodong Huang,Hongzhe Bi,Lichao Huang,Zhizhong Su*

Main category: cs.RO

TL;DR: 本文提出了HoloBrain-0，一个包含机器人本体先验的VLA框架，用于弥合基础模型研究与实际机器人部署之间的差距。该框架在模拟基准和真实世界操纵任务上取得了最先进的结果，并且其小型模型版本也能与大型模型媲美。作者还开源了整个HoloBrain生态系统，以促进研究和应用。


<details>
  <summary>Details</summary>
Motivation: 基础模型在机器人领域的应用与实际部署之间存在差距。需要一个能够整合机器人本体信息、并能有效部署在真实世界机器人的VLA框架。

Method: 提出了HoloBrain-0 VLA架构，该架构显式地整合了多视图相机参数和URDF等机器人本体先验信息。采用“预训练-后训练”范式进行模型训练。通过开源的HoloBrain生态系统（包括预训练模型、后训练检查点和RoboOrchard基础设施）来加速研究和实践。

Result: 在RoboTwin 2.0、LIBERO和GenieSim等模拟基准上取得了最先进的性能。在具有挑战性的长时序真实世界操纵任务上表现强劲。0.2B参数的小型模型版本性能可与更大的基线模型相媲美，支持低延迟的设备部署。

Conclusion: HoloBrain-0成功地将机器人本体先验整合到VLA模型中，显著提升了3D空间推理能力和跨不同机器人的泛化能力。通过开源整个生态系统，为机器人操纵领域的研究和应用提供了一个完整的、可复现的解决方案。

Abstract: In this work, we introduce HoloBrain-0, a comprehensive Vision-Language-Action (VLA) framework that bridges the gap between foundation model research and reliable real-world robot deployment. The core of our system is a novel VLA architecture that explicitly incorporates robot embodiment priors, including multi-view camera parameters and kinematic descriptions (URDF), to enhance 3D spatial reasoning and support diverse embodiments. We validate this design through a scalable ``pre-train then post-train" paradigm, achieving state-of-the-art results on simulation benchmarks such as RoboTwin 2.0, LIBERO, and GenieSim, as well as strong results on challenging long-horizon real-world manipulation tasks. Notably, our efficient 0.2B-parameter variant rivals significantly larger baselines, enabling low-latency on-device deployment. To further accelerate research and practical adoption, we fully open-source the entire HoloBrain ecosystem, which includes: (1) powerful pre-trained VLA foundations; (2) post-trained checkpoints for multiple simulation suites and real-world tasks; and (3) RoboOrchard, a full-stack VLA infrastructure for data curation, model training and deployment. Together with standardized data collection protocols, this release provides the community with a complete, reproducible path toward high-performance robotic manipulation.

</details>


### [256] [VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model](https://arxiv.org/abs/2602.12063)
*Yanjiang Guo,Tony Lee,Lucy Xiaoyang Shi,Jianyu Chen,Percy Liang,Chelsea Finn*

Main category: cs.RO

TL;DR: 本研究提出一种迭代在线交互方法，利用学习到的动作条件视频生成模型（世界模型）来生成额外的强化学习轨迹数据，以提升视觉-语言-动作（VLA）模型的性能和可靠性，特别是在真实世界数据收集成本高昂的情况下。该方法通过真实世界轨迹数据迭代地改进世界模型的物理保真度，从而生成更可靠的合成数据来训练VLA模型。


<details>
  <summary>Details</summary>
Motivation: 在真实世界中收集用于训练视觉-语言-动作（VLA）模型的策略轨迹数据成本高昂，而现有的世界模型在物理保真度方面存在不足，尤其是在缺乏物理交互覆盖（特别是失败案例）和难以精确模拟接触丰富的物体操作中的细微物理细节时。因此，研究者希望找到一种方法来生成更多高质量的轨迹数据以改进VLA模型。

Method: 提出一种简单的迭代改进算法。该算法首先使用少量真实的轨迹数据来训练一个动作条件视频生成模型（世界模型）。然后，利用这个经过初步训练的世界模型生成大量的合成轨迹数据。接着，使用真实的轨迹数据和生成的合成轨迹数据共同训练VLA模型。在每次迭代中，VLA模型性能的提升反过来可以用来改进世界模型的物理保真度，从而生成更好的合成数据。

Result: 在真实机器人实验中，该方法显著提高了VLA模型的性能。与基线策略相比，成功率绝对提升了39.2%。通过使用生成的合成轨迹数据进行训练，成功率比仅使用真实数据训练的基线模型又提高了11.6%。

Conclusion: 通过迭代在线交互和利用学习到的世界模型生成合成数据，可以有效地提高视觉-语言-动作（VLA）模型的性能和可靠性，尤其是在真实世界数据收集受限的情况下。该方法能够显著提升VLA模型在机器人操作任务上的表现。

Abstract: The goal of this paper is to improve the performance and reliability of vision-language-action (VLA) models through iterative online interaction. Since collecting policy rollouts in the real world is expensive, we investigate whether a learned simulator-specifically, an action-conditioned video generation model-can be used to generate additional rollout data. Unfortunately, existing world models lack the physical fidelity necessary for policy improvement: they are predominantly trained on demonstration datasets that lack coverage of many different physical interactions (particularly failure cases) and struggle to accurately model small yet critical physical details in contact-rich object manipulation. We propose a simple iterative improvement algorithm that uses real-world roll-out data to improve the fidelity of the world model, which can then, in turn, be used to generate supplemental synthetic data for improving the VLA model. In our experiments on a real robot, we use this approach to improve the performance of a state-of-the-art VLA model on multiple downstream tasks. We achieve a 39.2% absolute success rate improvement over the base policy and 11.6% improvement from training with the generated synthetic rollouts. Videos can be found at this anonymous website: https://sites.google.com/view/vla-w

</details>


### [257] [Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning](https://arxiv.org/abs/2602.12065)
*Xiang Liu,Sen Cui,Guocai Yao,Zhong Cao,Jingheng Ma,Min Zhang,Changshui Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为Affordance-Graphed Task Worlds (AGT-World) 的框架，用于自主构建交互式模拟环境和机器人任务策略，以解决真实世界训练成本高昂和模拟器在生成长期任务及处理动态不确定性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 在真实世界中训练机器人策略成本高且难以扩展。现有的生成式模拟方法在生成逻辑连贯的长期任务和处理动态物理不确定性方面存在困难，通常采用开放循环执行。

Method: AGT-World将任务空间形式化为一个结构化图，能够将复杂目标精确、分层地分解为基于理论的原子原语。引入了一个带有混合反馈的自我进化机制，结合视觉-语言模型推理和几何验证来自主优化策略。

Result: 该方法在成功率和泛化能力方面显著优于现有方法，实现了可扩展机器人学习的建议、执行和纠正的自我改进循环。

Conclusion: AGT-World是一个统一的框架，通过结构化任务表示和混合反馈的自我进化机制，能够自主构建模拟环境和优化机器人策略，有效解决了现有方法的局限性，实现了更高效、更具泛化能力的机器人学习。

Abstract: Training robotic policies directly in the real world is expensive and unscalable. Although generative simulation enables large-scale data synthesis, current approaches often fail to generate logically coherent long-horizon tasks and struggle with dynamic physical uncertainties due to open-loop execution. To address these challenges, we propose Affordance-Graphed Task Worlds (AGT-World), a unified framework that autonomously constructs interactive simulated environments and corresponding robot task policies based on real-world observations. Unlike methods relying on random proposals or static replication, AGT-World formalizes the task space as a structured graph, enabling the precise, hierarchical decomposition of complex goals into theoretically grounded atomic primitives. Furthermore, we introduce a Self-Evolution mechanism with hybrid feedback to autonomously refine policies, combining Vision-Language Model reasoning and geometric verification. Extensive experiments demonstrate that our method significantly outperforms in success rates and generalization, achieving a self-improving cycle of proposal, execution, and correction for scalable robot learning.

</details>


### [258] [RF-Modulated Adaptive Communication Improves Multi-Agent Robotic Exploration](https://arxiv.org/abs/2602.12074)
*Lorin Achey,Breanne Crockett,Christoffer Heckman,Bradley Hayes*

Main category: cs.RO

TL;DR: 提出了一种名为ART（自适应射频传输）的通信感知规划算法，该算法能根据信号强度和数据负载动态调整传输位置，从而提高异构机器人团队在通信受限环境下的信息共享效率，并减少不必要的往返。


<details>
  <summary>Details</summary>
Motivation: 在通信受限的环境中，多机器人协同探索面临着可靠通信和高效信息共享的挑战。

Method: 引入了ART算法，该算法能够根据信号强度和数据负载大小动态调整通信传输位置。还提出了ART-SST，用于执行信号强度阈值以确保高保真数据传输。

Result: ART算法在模拟实验中表现优于现有策略，与基线方法相比，行程距离最多可减少58%，探索时间最多可加快52%。

Conclusion: 通信感知和负载自适应的通信策略显著提高了机器人团队在复杂通信受限环境中的覆盖效率和任务速度，为未来的行星探索和搜救任务提供了基础。

Abstract: Reliable coordination and efficient communication are critical challenges for multi-agent robotic exploration of environments where communication is limited. This work introduces Adaptive-RF Transmission (ART), a novel communication-aware planning algorithm that dynamically modulates transmission location based on signal strength and data payload size, enabling heterogeneous robot teams to share information efficiently without unnecessary backtracking. We further explore an extension to this approach called ART-SST, which enforces signal strength thresholds for high-fidelity data delivery. Through over 480 simulations across three cave-inspired environments, ART consistently outperforms existing strategies, including full rendezvous and minimum-signal heuristic approaches, achieving up to a 58% reduction in distance traveled and up to 52% faster exploration times compared to baseline methods. These results demonstrate that adaptive, payload-aware communication significantly improves coverage efficiency and mission speed in complex, communication-constrained environments, offering a promising foundation for future planetary exploration and search-and-rescue missions.

</details>


### [259] [Pack it in: Packing into Partially Filled Containers Through Contact](https://arxiv.org/abs/2602.12095)
*David Russell,Zisong Xu,Maximo A. Roa,Mehmet Dogar*

Main category: cs.RO

TL;DR: 该研究提出了一种接触感知的装箱方法，通过利用与已有物品的交互来为新物品创造空间，从而解决仓库中部分装满容器的装箱问题。


<details>
  <summary>Details</summary>
Motivation: 仓库自动化对于提高生产力和减少人员暴露于危险环境至关重要。在仓库操作中，将物品装入容器（装箱）是一个常见且重要的环节，尤其是在容器已部分装载且物品排列不佳的情况下。

Method: 该方法采用一种基于接触的多对象轨迹优化器，集成在模型预测控制器中。该系统结合了一个物理感知的感知系统，能够估计物体姿态（即使在有遮挡的情况下），并提出物理上可行的放置位置。

Result: 该方法能够通过与已有物品进行有目的的交互来创造自由空间，从而成功放置新物品。

Conclusion: 通过利用接触交互和先进的感知与优化技术，该方法能够有效地解决仓库中部分装满且物品排列不佳的容器的装箱问题，提高了装箱的成功率。

Abstract: The automation of warehouse operations is crucial for improving productivity and reducing human exposure to hazardous environments. One operation frequently performed in warehouses is bin-packing where items need to be placed into containers, either for delivery to a customer, or for temporary storage in the warehouse. Whilst prior bin-packing works have largely been focused on packing items into empty containers and have adopted collision-free strategies, it is often the case that containers will already be partially filled with items, often in suboptimal arrangements due to transportation about a warehouse. This paper presents a contact-aware packing approach that exploits purposeful interactions with previously placed objects to create free space and enable successful placement of new items. This is achieved by using a contact-based multi-object trajectory optimizer within a model predictive controller, integrated with a physics-aware perception system that estimates object poses even during inevitable occlusions, and a method that suggests physically-feasible locations to place the object inside the container.

</details>


### [260] [Multi Graph Search for High-Dimensional Robot Motion Planning](https://arxiv.org/abs/2602.12096)
*Itamar Mishani,Maxim Likhachev*

Main category: cs.RO

TL;DR: 本文提出了一种名为多图搜索（MGS）的运动规划算法，该算法通过维护和扩展多个隐式图来提高高维机器人系统的运动规划效率，同时保证了规划的完整性和有界次优性。


<details>
  <summary>Details</summary>
Motivation: 现有的高维机器人运动规划算法虽然提高了可扩展性，但往往会牺牲运动的可预测性、一致性，或需要过多的计算资源和内存。因此，需要一种更高效、更可靠的运动规划方法。

Method: 提出多图搜索（MGS）算法，该算法将经典的单向和双向搜索推广到多图设置。MGS维护并逐步扩展状态空间中的多个隐式图，将探索集中在高潜力区域，并允许搜索过程中通过可行转移合并最初不连通的子图。

Result: 证明了MGS算法具有完整性和有界次优性。在各种操作和移动操作任务上的实验表明了其有效性。

Conclusion: MGS是一种有效且可靠的运动规划算法，能够处理高维机器人系统，并在效率和规划质量之间取得了良好的平衡。

Abstract: Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.

</details>


### [261] [3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting](https://arxiv.org/abs/2602.12159)
*Wancai Zheng,Hao Chen,Xianlong Lu,Linlin Ou,Xinyi Yu*

Main category: cs.RO

TL;DR: 提出了一种名为3DGSNav的新型零样本物体导航框架，该框架将3D高斯泼溅（3DGS）作为持久记忆嵌入到视觉语言模型（VLM）中，以增强空间推理能力，并通过主动感知、结构化视觉提示和思维链（CoT）提示来提高导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本物体导航方法依赖于场景抽象（如语义地图或文本表示），这限制了高层决策。需要一种能够提升空间推理能力并克服低层感知准确性限制的方法。

Method: 1. 提出3DGSNav框架，将3DGS作为VLM的持久记忆。 2. 通过主动感知，逐步构建环境的3DGS表示，支持自由视点渲染。 3. 设计结构化视觉提示并与思维链（CoT）提示结合，增强VLM推理。 4. 实时目标检测和VLM驱动的主动视点切换进行目标重验证。

Result: 在多个基准和真实的四足机器人实验中，3DGSNav展示了与现有最先进方法相比稳健且具有竞争力的性能。

Conclusion: 3DGSNav通过将3DGS嵌入VLM并结合主动感知和增强的提示策略，有效提高了零样本物体导航的性能，克服了传统方法在场景抽象上的限制。

Abstract: Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/

</details>


### [262] [Sub--Riemannian boundary value problems for Optimal Geometric Locomotion](https://arxiv.org/abs/2602.12199)
*Oliver Gross,Florine Hartwig,Martin Rumpf,Peter Schröder*

Main category: cs.RO

TL;DR: 本文提出了一个几何模型，用于计算细长运动体（如蛇在沙地上滑行）通过形状变化实现最优运动。该模型将拉格朗日最小耗散原理转化为边界值问题，并通过子黎曼几何测地线来求解，同时考虑了环境阻力和形变能耗，并允许不同边界条件下的数值计算。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了建立一个能够精确描述和预测细长运动体（如蛇、精子）通过形状变化实现最优运动的几何模型，该模型需能同时考虑环境阻力和形变能耗，以捕捉整体运动效率。

Method: 本文将拉格朗日最小耗散原理表述为边界值问题，并利用子黎曼几何的测地线作为解决方案。通过对模型进行时间和空间离散化，实现了针对不同边界条件（固定初始和目标形状、周期性运动、仅规定位移和方向）的数值计算。

Result: 计算得到的最优形变步态在定性上与蛇和精子的运动轨迹相符，也与低维系统（如Purcell的游泳体）的已知最优解一致。此外，该模型比以往框架更具几何灵活性，能够为广义Purcell游泳体等提供新的运动机制见解。

Conclusion: 所提出的几何模型能够有效地计算和预测细长运动体最优形状变化诱导的运动。该模型通过整合环境耗散和形变耗散，并允许灵活的边界条件，为理解和设计生物及机器人运动提供了新的视角，并且该模型对应的代码已公开。

Abstract: We propose a geometric model for optimal shape-change-induced motions of slender locomotors, e.g., snakes slithering on sand. In these scenarios, the motion of a body in world coordinates is completely determined by the sequence of shapes it assumes. Specifically, we formulate Lagrangian least-dissipation principles as boundary value problems whose solutions are given by sub-Riemannian geodesics. Notably, our geometric model accounts not only for the energy dissipated by the body's displacement through the environment, but also for the energy dissipated by the animal's metabolism or a robot's actuators to induce shape changes such as bending and stretching, thus capturing overall locomotion efficiency. Our continuous model, together with a consistent time and space discretization, enables numerical computation of sub-Riemannian geodesics for three different types of boundary conditions, i.e., fixing initial and target body, restricting to cyclic motion, or solely prescribing body displacement and orientation. The resulting optimal deformation gaits qualitatively match observed motion trajectories of organisms such as snakes and spermatozoa, as well as known optimality results for low-dimensional systems such as Purcell's swimmers. Moreover, being geometrically less rigid than previous frameworks, our model enables new insights into locomotion mechanisms of, e.g., generalized Purcell's swimmers. The code is publicly available.

</details>


### [263] [LDA-1B: Scaling Latent Dynamics Action Model via Universal Embodied Data Ingestion](https://arxiv.org/abs/2602.12215)
*Jiangran Lyu,Kai Liu,Xuheng Zhang,Haoran Liao,Yusen Feng,Wenxuan Zhu,Tingrui Shen,Jiayi Chen,Jiazhao Zhang,Yifei Dong,Wenbo Cui,Senmao Qi,Shuo Wang,Yixin Zheng,Mi Yan,Xuesong Shi,Haoran Li,Dongbin Zhao,Ming-Yu Liu,Zhizheng Zhang,Li Yi,Yizhou Wang,He Wang*

Main category: cs.RO

TL;DR: LDA-1B 是一个 10 亿参数的机器人基础模型，它通过统一处理不同质量的具身数据（动力学、策略和视觉预测），并结合 EI-30k 数据集和多模态扩散 Transformer，实现了比现有方法更好的性能，并在数据效率方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有机器人基础模型主要依赖行为克隆，忽略了异构具身数据中蕴含的可迁移动力学知识。虽然统一世界模型 (UWM) 有潜力利用这些数据，但现有模型难以扩展。作者希望开发一个能从多样化数据中学习并扩展的机器人基础模型。

Method: LDA-1B 模型通过以下方式实现扩展：1. 统一具身数据摄入，联合学习动力学、策略和视觉预测，并根据数据质量分配不同作用。2. 构建并标准化了包含 30k 小时人类和机器人轨迹的 EI-30k 数据集。3. 在 DINO 结构化潜空间中进行预测，以支持大规模异构数据上的动力学学习。4. 使用多模态扩散 Transformer 处理异步视觉和动作流，以实现 10 亿参数规模的稳定训练。

Result: LDA-1B 在接触丰富、灵巧和长时域任务上，分别比现有方法（如 $π_{0.5}$）的性能提升了 21%、48% 和 23%。此外，LDA-1B 能够高效微调，在利用 30% 的低质量轨迹时，性能提升了 10%。

Conclusion: LDA-1B 是一个可扩展的机器人基础模型，它通过统一异构具身数据并采用结构化潜空间预测和多模态扩散 Transformer，在性能和数据效率上都取得了显著进步，并为机器人基础模型的开发提供了新的方向。

Abstract: Recent robot foundation models largely rely on large-scale behavior cloning, which imitates expert actions but discards transferable dynamics knowledge embedded in heterogeneous embodied data. While the Unified World Model (UWM) formulation has the potential to leverage such diverse data, existing instantiations struggle to scale to foundation-level due to coarse data usage and fragmented datasets. We introduce LDA-1B, a robot foundation model that scales through universal embodied data ingestion by jointly learning dynamics, policy, and visual forecasting, assigning distinct roles to data of varying quality. To support this regime at scale, we assemble and standardize EI-30k, an embodied interaction dataset comprising over 30k hours of human and robot trajectories in a unified format. Scalable dynamics learning over such heterogeneous data is enabled by prediction in a structured DINO latent space, which avoids redundant pixel-space appearance modeling. Complementing this representation, LDA-1B employs a multi-modal diffusion transformer to handle asynchronous vision and action streams, enabling stable training at the 1B-parameter scale. Experiments in simulation and the real world show LDA-1B outperforms prior methods (e.g., $π_{0.5}$) by up to 21\%, 48\%, and 23\% on contact-rich, dexterous, and long-horizon tasks, respectively. Notably, LDA-1B enables data-efficient fine-tuning, gaining 10\% by leveraging 30\% low-quality trajectories typically harmful and discarded.

</details>


### [264] [Any House Any Task: Scalable Long-Horizon Planning for Abstract Human Tasks](https://arxiv.org/abs/2602.12244)
*Zhihong Liu,Yang Li,Rengming Huang,Cewu Lu,Panpan Cai*

Main category: cs.RO

TL;DR: 本文提出了一种名为AHAT的开放世界语言条件任务规划器，该规划器针对大型环境中长周期规划和模糊指令进行了优化，并通过一种名为TGPO的新型强化学习算法来处理复杂的推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理大规模家庭环境中的开放世界语言条件任务规划时存在可扩展性问题，其性能会随着环境规模、规划长度、指令模糊度和约束复杂度的增加而迅速下降。

Method: AHAT使用一个经过训练的大型语言模型，将任务指令和文本场景图映射到以PDDL（Planning Domain Definition Language）定义的接地子目标。然后，通过显式的符号推理来解决这些子目标，生成可行且最优的长周期规划。此外，研究人员还引入了一种名为TGPO的新型强化学习算法，通过集成外部对中间推理过程的校正来改进GRPO（Group Relative Policy Optimization），以增强模型分解复杂和模糊意图的能力。

Result: 实验结果表明，AHAT在处理人类风格的家庭任务时，表现出了比现有最先进的提示、规划和学习方法显著的性能提升，尤其是在指令简短但执行计划复杂的情况下。

Conclusion: AHAT通过结合LLM的推理能力和符号规划的精确性，并引入TGPO算法来处理复杂的推理，能够有效地解决大规模家庭环境中长周期、模糊指令的任务规划问题，在可扩展性和性能上均优于现有方法。

Abstract: Open world language conditioned task planning is crucial for robots operating in large-scale household environments. While many recent works attempt to address this problem using Large Language Models (LLMs) via prompting or training, a key challenge remains scalability. Performance often degrades rapidly with increasing environment size, plan length, instruction ambiguity, and constraint complexity. In this work, we propose Any House Any Task (AHAT), a household task planner optimized for long-horizon planning in large environments given ambiguous human instructions. At its core, AHAT utilizes an LLM trained to map task instructions and textual scene graphs into grounded subgoals defined in the Planning Domain Definition Language (PDDL). These subgoals are subsequently solved to generate feasible and optimal long-horizon plans through explicit symbolic reasoning. To enhance the model's ability to decompose complex and ambiguous intentions, we introduce TGPO, a novel reinforcement learning algorithm that integrates external correction of intermediate reasoning traces into Group Relative Policy Optimization (GRPO). Experiments demonstrate that AHAT achieves significant performance gains over state-of-the-art prompting, planning, and learning methods, particularly in human-style household tasks characterized by brief instructions but requiring complex execution plans.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [265] [Sample-Free Safety Assessment of Neural Network Controllers via Taylor Methods](https://arxiv.org/abs/2602.11332)
*Adam Evans,Roberto Armellin*

Main category: eess.SY

TL;DR: 本研究提出了一种通过自动域划分和多项式边界技术来评估神经网络反馈控制器安全性的方法，以解决其在关键航天应用中缺乏验证保证的问题。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络控制器在复杂场景下表现优异，但其“黑箱”性质导致缺乏可验证性，限制了其在安全关键型航天任务中的应用。本研究旨在弥合这一差距，提高神经网络控制器的可信度。

Method: 1. 将训练好的神经网络控制器嵌入系统动力学方程，使闭环系统自主化。2. 使用高阶泰勒多项式近似系统流。3. 构建多项式映射，将状态不确定性投射到事件流形上。4. 采用自动域划分确保多项式在相关子域内的准确性，并高效分析大状态空间。5. 利用多项式边界技术，严格约束和分析子域内的事件值，从而确定神经网络控制器闭环结果的范围，支持安全评估。

Result: 该方法能够严格约束和分析神经网络控制器在不同子域内的事件值，从而为闭环系统的可能结果建立边界。这有助于进行安全评估，并为实际任务中的操作决策提供信息。

Conclusion: 本研究开发了一种有效的自动域划分和多项式边界方法，可以严格评估神经网络反馈控制器的安全性，为在安全关键型航天应用中使用这些控制器提供了重要的保障。

Abstract: In recent years, artificial neural networks have been increasingly studied as feedback controllers for guidance problems. While effective in complex scenarios, they lack the verification guarantees found in classical guidance policies. Their black-box nature creates significant concerns regarding trustworthiness, limiting their adoption in safety-critical spaceflight applications. This work addresses this gap by developing a method to assess the safety of a trained neural network feedback controller via automatic domain splitting and polynomial bounding. The methodology involves embedding the trained neural network into the system's dynamical equations, rendering the closed-loop system autonomous. The system flow is then approximated by high-order Taylor polynomials, which are subsequently manipulated to construct polynomial maps that project state uncertainties onto an event manifold. Automatic domain splitting ensures the polynomials are accurate over their relevant subdomains, whilst also allowing an extensive state-space to be analysed efficiently. Utilising polynomial bounding techniques, the resulting event values may be rigorously constrained and analysed within individual subdomains, thereby establishing bounds on the range of possible closed-loop outcomes from using such neural network controllers and supporting safety assessment and informed operational decision-making in real-world missions.

</details>


### [266] [Adaptive Behavioral Predictive Control: State-Free Regulation Without Hankel Weights](https://arxiv.org/abs/2602.12016)
*Tam W. Nguyen*

Main category: eess.SY

TL;DR: 提出了一种名为自适应行为预测控制（ABPC）的间接自适应预测控制框架，该框架在流式数据上运行。通过在线识别 LPV-ARX 预测器，实现了有限时间域内的闭式预测控制序列计算，避免了迭代优化。研究表明，当核字典与被控对象类别匹配时，ABPC 在 Hammerstein 和 NARX 系统上表现有效。


<details>
  <summary>Details</summary>
Motivation: 开发一种能在流式数据上运行的、计算上可行的、间接自适应预测控制框架，同时保持模型表达能力和避免复杂的迭代优化。

Method: 提出自适应行为预测控制（ABPC）框架，利用核递归最小二乘法（kernel-RLS）在线识别 LPV-ARX 预测器，并使用非线性核字典扩展模型表达能力。控制序列通过有限时间域内的闭式解计算得出。

Result: ABPC 在 Hammerstein 和 NARX 系统上的数值研究显示了其有效性，尤其是在核字典与被控对象类别匹配时。研究还揭示了条件和特征选择的影响。

Conclusion: ABPC 是一种计算上可行且可复现的间接自适应预测控制方法，适用于流式数据，并且通过使用非线性核字典可以有效处理非线性系统。

Abstract: This paper presents adaptive behavioral predictive control (ABPC), an indirect adaptive predictive control framework operating on streaming data. An LPV--ARX predictor is identified online via kernel--recursive least squares and used to compute closed-form predictive control sequences over a finite horizon, avoiding batch Hankel constructions and iterative optimization. Nonlinear kernel dictionaries extend model expressiveness within a behavioral formulation. Numerical studies on Hammerstein and NARX systems demonstrate effective performance when the dictionary aligns with the plant class and highlight conditioning and feature-selection effects. The paper emphasizes numerical simulation, computational feasibility, and reproducibility.

</details>


### [267] [Equivalent Circuit Modeling of Grid-Forming Inverters in (Sub)-Transient Time-Frame](https://arxiv.org/abs/2602.12202)
*Ambuj Gupta,Balarko Chaudhuri,Mark O'Malley*

Main category: eess.SY

TL;DR: 本文提出了一种系统性的方法，通过频域导纳图来量化黑箱式并网逆变器（GFM）的等效阻抗，该方法能较准确地反映其暂态响应和静态电压稳定性。研究还澄清了GFM的内部电压源位置，表明其近似恒定电压维持在滤波器电容两端，而非逆变器开关处。


<details>
  <summary>Details</summary>
Motivation: 现有的GFM定义未能明确其内部电压源的位置，并且缺乏系统性的方法来量化黑箱GFM模型的等效阻抗，尽管一些系统运营商对此有明确要求。

Method: 首先，通过对比理想电压源和GFM的暂态响应，揭示GFM近似恒定电压维持在滤波器电容两端。然后，提出一种基于频域导纳图的系统性方法，用于从黑箱GFM模型中量化其等效阻抗。最后，使用NREL开发的PSCAD GFM模型进行验证。

Result: 所提出的方法能够从黑箱GFM模型中量化出其等效阻抗，并且该等效阻抗模型能较准确地捕捉GFM的暂态响应和静态电压稳定性极限。

Conclusion: 本文成功地提出了一种系统性的方法来量化GFM的等效阻抗，并澄清了其近似恒定电压的实际位置。该方法为理解和分析GFM在电网中的行为提供了有力的工具。

Abstract: The widely accepted definition of grid-forming (GFM) inverter states that it should behave as a (nearly) constant voltage source behind an impedance by maintaining a (nearly) constant internal voltage phasor in the sub-transient to transient time frame. Some system operators further mandate permissible ranges for this effective impedance. However, these specifications do not clearly define the location of the internal voltage source, and no systematic method exists to quantify its effective impedance for a black-box GFM model. To address this, we first compare the transient responses of an ideal voltage source and a GFM to show that an idealistic GFM maintains a (nearly) constant voltage across the filter capacitor, rather than at the inverter switches. Then we propose a systematic method to quantify the effective impedance of a GFM from its black-box model using frequency-domain admittance plots. Using standard PSCAD GFM models developed by NREL, we demonstrate that the GFM's equivalent impedance model captures the sub-transient response and static voltage stability limit reasonably accurately.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [268] [BSoNet: Deep Learning Solution for Optimizing Image Quality of Portable Backscatter Imaging Systems](https://arxiv.org/abs/2602.11701)
*Linxuan Li,Wenjia Wei,Yunfei Lu,Wenwen Zhang,Yanlong Zhang,Wei Zhao*

Main category: eess.IV

TL;DR: 本研究提出了一种名为BSoNet的深度学习方法，用于提升便携式背散射成像（PBI）系统的图像质量，以克服现有PBI系统因光子计数不足导致的图像噪声和低信噪比问题，从而提高其在安全检查中的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有便携式背散射成像（PBI）系统由于光子吸收、逐点扫描和采样时间短等因素，导致康普顿背散射光子数有限，图像质量差，信噪比低，限制了其在安全检查中的应用效果。

Method: 提出了一种名为BSoNet的新型深度学习方法，专门用于优化PBI系统的图像质量。

Result: BSoNet能够显著提高PBI图像的清晰度、识别度和对比度，满足实际应用需求。

Conclusion: BSoNet方法能够有效提升PBI系统的图像质量，使其成为更有效、更可靠的检测工具，从而增强安全防护能力。

Abstract: Portable backscatter imaging systems (PBI) integrate an X-ray source and detector in a single unit, utilizing Compton scattering photons to rapidly acquire superficial or shallow structural information of an inspected object through single-sided imaging. The application of this technology overcomes the limitations of traditional transmission X-ray detection, offering greater flexibility and portability, making it the preferred tool for the rapid and accurate identification of potential threats in scenarios such as borders, ports, and industrial nondestructive security inspections. However, the image quality is significantly compromised due to the limited number of Compton backscattered photons. The insufficient photon counts result primarily from photon absorption in materials, the pencil-beam scanning design, and short signal sampling times. It therefore yields severe image noise and an extremely low signal-to-noise ratio, greatly reducing the accuracy and reliability of PBI systems. To address these challenges, this paper introduces BSoNet, a novel deep learning-based approach specifically designed to optimize the image quality of PBI systems. The approach significantly enhances image clarity, recognition, and contrast while meeting practical application requirements. It transforms PBI systems into more effective and reliable inspection tools, contributing significantly to strengthening security protection.

</details>


### [269] [U-DAVI: Uncertainty-Aware Diffusion-Prior-Based Amortized Variational Inference for Image Reconstruction](https://arxiv.org/abs/2602.11704)
*Ayush Varshney,Katherine L. Bouman,Berthy T. Feng*

Main category: eess.IV

TL;DR: 该研究提出了一种改进的摊销变分推理框架，通过在训练过程中引入空间自适应扰动，提高了扩散模型在图像逆问题中的重建性能，特别是在细节和纹理方面，同时保持了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的图像逆问题求解方法计算成本高昂（需要迭代采样或实例优化），而现有的摊销变分推理框架虽然速度快，但在重建细节和复杂纹理方面表现不佳。

Method: 通过在训练过程中，根据不确定性估计，向测量数据注入空间自适应扰动，引导模型关注不确定性最高的区域进行学习。该方法属于摊销变分推理框架。

Result: 在去模糊和超分辨率实验中，该方法取得了优于或媲美先前基于扩散模型的方法的性能，能够生成更逼真的重建图像，并且无需迭代精修的计算成本。

Conclusion: 将空间自适应扰动注入到摊销变分推理框架中，是一种有效的方法，可以提升基于扩散模型的图像逆问题求解的性能，尤其是在细节和纹理重建方面，同时避免了高昂的计算开销。

Abstract: Ill-posed imaging inverse problems remain challenging due to the ambiguity in mapping degraded observations to clean images. Diffusion-based generative priors have recently shown promise, but typically rely on computationally intensive iterative sampling or per-instance optimization. Amortized variational inference frameworks address this inefficiency by learning a direct mapping from measurements to posteriors, enabling fast posterior sampling without requiring the optimization of a new posterior for every new set of measurements. However, they still struggle to reconstruct fine details and complex textures. To address this, we extend the amortized framework by injecting spatially adaptive perturbations to measurements during training, guided by uncertainty estimates, to emphasize learning in the most uncertain regions. Experiments on deblurring and super-resolution demonstrate that our method achieves superior or competitive performance to previous diffusion-based approaches, delivering more realistic reconstructions without the computational cost of iterative refinement.

</details>


### [270] [Temporally resolved aortic 3D shape reconstruction from a limited number of cine 2D MRI slices](https://arxiv.org/abs/2602.11873)
*Gloria Wolkerstorfer,Stefano Buoso,Rabea Schlenker,Jochen von Spiczak,Robert Manka,Sebastian Kozerke*

Main category: eess.IV

TL;DR: 提出了一种从有限的二维MRI数据中重建三维主动脉几何形状的方法，并验证了其准确性和时效性。


<details>
  <summary>Details</summary>
Motivation: 需要一种从有限的二维MRI数据中生成时相分辨率、患者特异性三维主动脉几何形状的框架，以进行计算形状和应变分析。

Method: 构建了主动脉的统计形状模型，并结合了可微分体积网格优化技术。通过优化二维切片位置，从30名受试者（19名志愿者，11名主动脉瓣狭窄患者）的电影二维MRI数据中生成了时相分辨率的主动脉模型。

Result: 从最少六个二维MRI切片中获得了解剖学上精确的主动脉几何形状，与四维血流MRI相比，Dice得分（89.9 ± 1.6）%，IoU（81.7 ± 2.7）%，Hausdorff距离（7.3 ± 3.3）mm，Chamfer距离（3.7 ± 0.6）mm。观察到所有形状特征（包括径向应变）均存在显著的年龄相关差异。

Conclusion: 所提出的方法能够从有限的电影二维MRI数据中高效提取时相分辨率的三维主动脉网格，适用于计算形状和应变分析。

Abstract: Background and Objective: We propose a shape reconstruction framework to generate time-resolved, patient-specific 3D aortic geometries from a limited number of standard cine 2D magnetic resonance imaging (MRI) acquisitions. A statistical shape model of the aorta is coupled with differentiable volumetric mesh optimization to obtain personalized aortic meshes.
  Methods: The statistical shape model was constructed from retrospective data and optimized 2D slice placements along the aortic arch were identified. Cine 2D MRI slices were then acquired in 30 subjects (19 volunteers, 11 aortic stenosis patients). After manual segmentation, time-resolved aortic models were generated via differentiable volumetric mesh optimization to derive vessel shape features, centerline parameters, and radial wall strain. In 10 subjects, additional 4D flow MRI was acquired to compare peak-systolic shapes.
  Results: Anatomically accurate aortic geometries were obtained from as few as six cine 2D MRI slices, achieving a mean +/- standard deviation Dice score of (89.9 +/- 1.6) %, Intersection over Union of (81.7 +/- 2.7) %, Hausdorff distance of (7.3 +/- 3.3) mm, and Chamfer distance of (3.7 +/- 0.6) mm relative to 4D flow MRI. The mean absolute radius error was (0.8 +/- 0.6) mm. Significant age-related differences were observed for all shape features, including radial strain, which decreased progressively ((11.00 +/- 3.11) x 10-2 vs. (3.74 +/- 1.25) x 10-2 vs. (2.89 +/- 0.87) x 10-2 for young, mid-age, and elderly groups).
  Conclusion: The proposed method enables efficient extraction of time-resolved 3D aortic meshes from limited sets of standard cine 2D MRI acquisitions, suitable for computational shape and strain analysis.

</details>


### [271] [Learning Perceptual Representations for Gaming NR-VQA with Multi-Task FR Signals](https://arxiv.org/abs/2602.11903)
*Yu-Chih Chen,Michael Wang,Chieh-Dun Wen,Kai-Siang Ma,Avinab Saha,Li-Heng Chen,Alan Bovik*

Main category: eess.IV

TL;DR: 本文提出了一种名为MTL-VQA的多任务学习框架，用于游戏视频的无参考视频质量评估（NR-VQA）。该框架利用全参考（FR）指标作为监督信号进行预训练，无需人工标注数据，通过联合优化多个FR目标并自适应调整任务权重，学习到有效的共享表示，并成功应用于NR-VQA任务，在现有数据集上取得了与SOTA方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 游戏视频的NR-VQA具有挑战性，原因是缺乏人工标注数据集以及其独特的视觉内容（如快速运动、风格化图形和压缩伪影）。

Method: 提出MTL-VQA多任务学习框架，利用全参考（FR）指标作为监督信号进行预训练，以学习感知上有意义的特征，而无需人工标签。通过联合优化多个FR目标，并采用自适应任务加权，该方法学习共享表示，并将其有效迁移到NR-VQA任务。

Result: 在游戏视频数据集上的实验表明，MTL-VQA在MOS监督和标签高效/自监督设置下，其性能与最先进的NR-VQA方法具有竞争力。

Conclusion: MTL-VQA是一种有效的多任务学习框架，可以通过利用FR指标进行预训练，在没有大量人工标注数据的情况下，实现高性能的游戏视频NR-VQA。

Abstract: No-reference video quality assessment (NR-VQA) for gaming videos is challenging due to limited human-rated datasets and unique content characteristics including fast motion, stylized graphics, and compression artifacts. We present MTL-VQA, a multi-task learning framework that uses full-reference metrics as supervisory signals to learn perceptually meaningful features without human labels for pretraining. By jointly optimizing multiple full-reference (FR) objectives with adaptive task weighting, our approach learns shared representations that transfer effectively to NR-VQA. Experiments on gaming video datasets show MTL-VQA achieves performance competitive with state-of-the-art NR-VQA methods across both MOS-supervised and label-efficient/self-supervised settings.

</details>


### [272] [UPDA: Unsupervised Progressive Domain Adaptation for No-Reference Point Cloud Quality Assessment](https://arxiv.org/abs/2602.11969)
*Bingxu Xie,Fang Zhou,Jincan Wu,Yonghui Liu,Weiqing Li,Zhiyong Su*

Main category: eess.IV

TL;DR: 本文提出了首个用于无参考点云质量评估（NR-PCQA）的无监督渐进式域自适应（UPDA）框架，通过粗粒度和细粒度对齐来解决训练域和测试域之间的分布差异问题。


<details>
  <summary>Details</summary>
Motivation: 现有的NR-PCQA方法在面对训练域和测试域数据分布不一致时，性能会显著下降。然而，跨域迁移NR-PCQA模型的研究却很少。

Method: 该框架采用两阶段的粗到细对齐范式。第一阶段，设计了一个差异感知粗粒度对齐方法，利用新颖的质量-差异感知混合损失来捕捉跨域样本的相对质量关系，避免了直接的绝对特征对齐。第二阶段，提出了一个感知融合细粒度对齐方法，结合对称特征融合来识别域不变特征，并利用条件判别器选择性地增强质量相关特征的迁移。

Result: 大量的实验证明，所提出的UPDA框架能有效提升NR-PCQA方法在跨域场景下的性能，验证了其在实际应用中的有效性。

Conclusion: UPDA框架是首个用于NR-PCQA的无监督渐进式域自适应框架，通过粗粒度和细粒度对齐有效解决了域偏移问题，显著提升了模型在跨域场景下的性能。

Abstract: While no-reference point cloud quality assessment (NR-PCQA) approaches have achieved significant progress over the past decade, their performance often degrades substantially when a distribution gap exists between the training (source domain) and testing (target domain) data. However, to date, limited attention has been paid to transferring NR-PCQA models across domains. To address this challenge, we propose the first unsupervised progressive domain adaptation (UPDA) framework for NR-PCQA, which introduces a two-stage coarse-to-fine alignment paradigm to address domain shifts. At the coarse-grained stage, a discrepancy-aware coarse-grained alignment method is designed to capture relative quality relationships between cross-domain samples through a novel quality-discrepancy-aware hybrid loss, circumventing the challenges of direct absolute feature alignment. At the fine-grained stage, a perception fusion fine-grained alignment approach with symmetric feature fusion is developed to identify domain-invariant features, while a conditional discriminator selectively enhances the transfer of quality-relevant features. Extensive experiments demonstrate that the proposed UPDA effectively enhances the performance of NR-PCQA methods in cross-domain scenarios, validating its practical applicability. The code is available at https://github.com/yokeno1/UPDA-main.

</details>
