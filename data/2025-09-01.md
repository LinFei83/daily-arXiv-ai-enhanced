<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 24]
- [cs.CV](#cs.CV) [Total: 59]
- [cs.CL](#cs.CL) [Total: 34]
- [cs.RO](#cs.RO) [Total: 19]
- [eess.SY](#eess.SY) [Total: 10]
- [eess.IV](#eess.IV) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding](https://arxiv.org/abs/2508.21204)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 本研究探讨了架构归纳偏见如何影响LLM在教学对话中的认知行为，发现符号支架和短期记忆机制能显著提升LLM的苏格拉底式辅导能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解架构归纳偏见如何影响大型语言模型（LLMs）在教学对话中的认知行为，特别是为了在苏格拉底式辅导中促进自适应、结构化的推理能力。

Method: 研究引入了符号支架机制和短期记忆方案，以促进LLM的自适应结构化推理。通过对五种系统变体进行受控消融实验，使用专家设计的评分标准（涵盖支架、响应性、符号推理和对话记忆）以及基于LLM的评估框架来评估模型输出。

Result: 初步结果显示，完整系统始终优于基线变体。分析表明，移除记忆或符号结构会损害关键的认知行为，包括抽象、自适应探究和概念连续性。

Conclusion: 这些发现支持了一种处理层面的解释，即架构支架可以可靠地塑造LLM中新兴的教学策略。

Abstract: We study how architectural inductive biases influence the cognitive behavior
of large language models (LLMs) in instructional dialogue. We introduce a
symbolic scaffolding mechanism paired with a short-term memory schema designed
to promote adaptive, structured reasoning in Socratic tutoring. Using
controlled ablation across five system variants, we evaluate model outputs via
expert-designed rubrics covering scaffolding, responsiveness, symbolic
reasoning, and conversational memory. We present preliminary results using an
LLM-based evaluation framework aligned to a cognitively grounded rubric. This
enables scalable, systematic comparisons across architectural variants in
early-stage experimentation. The preliminary results show that our full system
consistently outperforms baseline variants. Analysis reveals that removing
memory or symbolic structure degrades key cognitive behaviors, including
abstraction, adaptive probing, and conceptual continuity. These findings
support a processing-level account in which architectural scaffolds can
reliably shape emergent instructional strategies in LLMs.

</details>


### [2] [Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs](https://arxiv.org/abs/2508.21238)
*Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman*

Main category: cs.AI

TL;DR: 本文评估了GraphRAG系统在阿尔茨海默病等知识密集型科学研究领域中的回答质量和可追溯性，并将其与标准LLM（GPT-4o）进行比较。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在科学研究中面临幻觉、领域知识有限和缺乏可解释性/可追溯性等挑战。GraphRAG被认为是一种有前途的解决方案，但其在阿尔茨海默病等知识密集型特定领域中的评估研究有限。

Method: 研究编译了一个包含50篇论文和70个专家问题的阿尔茨海默病数据库，构建了GraphRAG知识库，并使用GPT-4o作为LLM。论文比较了GraphRAG与标准GPT-4o模型的回答质量，并讨论和评估了几种RAG和GraphRAG系统的可追溯性。此外，还提供了一个易于使用的界面。

Result: 论文评估了GraphRAG系统在阿尔茨海默病领域的回答质量和可追溯性，并与标准LLM进行了比较。同时，讨论并评估了RAG和GraphRAG系统的可追溯性。

Conclusion: 本文通过对GraphRAG在阿尔茨海默病领域的评估，为研究人员提供了关于其在知识密集型科学研究中应用潜力的见解，并提供了一个测试标准RAG和GraphRAG性能的数据库和界面。

Abstract: In the past two years, large language model (LLM)-based chatbots, such as
ChatGPT, have revolutionized various domains by enabling diverse task
completion and question-answering capabilities. However, their application in
scientific research remains constrained by challenges such as hallucinations,
limited domain-specific knowledge, and lack of explainability or traceability
for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has
emerged as a promising approach to improving chatbot reliability by integrating
domain-specific contextual information before response generation, addressing
some limitations of standard LLMs. Despite its potential, there are only
limited studies that evaluate GraphRAG on specific domains that require
intensive knowledge, like Alzheimer's disease or other biomedical domains. In
this paper, we assess the quality and traceability of two popular GraphRAG
systems. We compile a database of 50 papers and 70 expert questions related to
Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as
the LLM for answering queries. We then compare the quality of responses
generated by GraphRAG with those from a standard GPT-4o model. Additionally, we
discuss and evaluate the traceability of several Retrieval-Augmented Generation
(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a
pre-built Alzheimer's disease database for researchers to test the performance
of both standard RAG and GraphRAG.

</details>


### [3] [MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems](https://arxiv.org/abs/2508.21307)
*Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala*

Main category: cs.AI

TL;DR: MultiFluxAI是一个创新AI平台，旨在解决产品工程中管理和集成大量异构数据源的挑战，通过先进AI技术提供动态、上下文感知的用户查询响应。


<details>
  <summary>Details</summary>
Motivation: 解决产品工程中管理和集成大量、异构数据源的挑战，并增强数字生态系统中的用户参与度。

Method: 利用先进的AI技术，包括生成式AI（Generative AI）、向量化（vectorization）和代理编排（agentic orchestration）。

Result: 能够处理当前和新的服务相关查询，提供动态和上下文感知的响应以解决复杂的用户查询，从而增强数字生态系统中的用户参与度。

Conclusion: MultiFluxAI通过其创新的AI方法，有效地管理和集成复杂数据，提升了用户在数字生态系统中的交互体验和查询处理能力。

Abstract: MultiFluxAI is an innovative AI platform developed to address the challenges
of managing and integrating vast, disparate data sources in product engineering
across application domains. It addresses both current and new service related
queries that enhance user engagement in the digital ecosystem. This platform
leverages advanced AI techniques, such as Generative AI, vectorization, and
agentic orchestration to provide dynamic and context-aware responses to complex
user queries.

</details>


### [4] [Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation](https://arxiv.org/abs/2508.21320)
*Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao*

Main category: cs.AI

TL;DR: 本文提出了LINKO，一个由大型语言模型（LLM）增强的集成本体学习框架，通过在异构本体系统内部和之间进行双轴知识传播，来提升医学概念表示学习。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单一本体系统或孤立的多个本体系统（如疾病、药物、手术）中的领域知识整合，导致概念表示学习仅限于本体内部关系，忽略了跨本体连接。

Method: LINKO框架首先利用LLM提供图检索增强的本体概念嵌入初始化，通过包含概念描述和本体上下文的精心设计的提示词实现。其次，该方法通过双轴知识传播共同学习不同本体图中的医学概念：(1) 本体内垂直传播（跨层级本体级别）和 (2) 本体间水平传播（在每个级别内并行）。

Result: LINKO在两个公共数据集上的实验结果表明，其性能优于现有最先进的基线方法。作为一个可与现有电子健康记录（EHR）预测模型兼容的插件编码器，LINKO在数据可用性有限和罕见疾病预测场景中也表现出更强的鲁棒性。

Conclusion: LINKO通过整合多个本体图并利用LLM进行双轴知识传播，有效增强了医学概念表示学习，并在各种预测任务中展示了卓越的性能和鲁棒性。

Abstract: Medical ontology graphs map external knowledge to medical codes in electronic
health records via structured relationships. By leveraging domain-approved
connections (e.g., parent-child), predictive models can generate richer medical
concept representations by incorporating contextual information from related
concepts. However, existing literature primarily focuses on incorporating
domain knowledge from a single ontology system, or from multiple ontology
systems (e.g., diseases, drugs, and procedures) in isolation, without
integrating them into a unified learning structure. Consequently, concept
representation learning often remains limited to intra-ontology relationships,
overlooking cross-ontology connections. In this paper, we propose LINKO, a
large language model (LLM)-augmented integrative ontology learning framework
that leverages multiple ontology graphs simultaneously by enabling dual-axis
knowledge propagation both within and across heterogeneous ontology systems to
enhance medical concept representation learning. Specifically, LINKO first
employs LLMs to provide a graph-retrieval-augmented initialization for ontology
concept embedding, through an engineered prompt that includes concept
descriptions, and is further augmented with ontology context. Second, our
method jointly learns the medical concepts in diverse ontology graphs by
performing knowledge propagation in two axes: (1) intra-ontology vertical
propagation across hierarchical ontology levels and (2) inter-ontology
horizontal propagation within every level in parallel. Last, through extensive
experiments on two public datasets, we validate the superior performance of
LINKO over state-of-the-art baselines. As a plug-in encoder compatible with
existing EHR predictive models, LINKO further demonstrates enhanced robustness
in scenarios involving limited data availability and rare disease prediction.

</details>


### [5] [Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models](https://arxiv.org/abs/2508.21365)
*Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang*

Main category: cs.AI

TL;DR: TiG框架使大型语言模型（LLMs）通过与游戏环境的直接交互来学习程序性知识，将强化学习决策重新定义为语言建模任务，从而弥合了声明性知识和程序性知识之间的鸿沟，并提供了可解释的决策。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在复杂推理任务上表现出色，但在简单的交互任务上却很吃力，这凸显了声明性知识和程序性知识之间的关键差距。传统的强化学习（RL）代理虽然能获取程序性知识，但通常是黑箱且需要大量训练数据，而LLMs缺乏将静态知识转化为动态决策的能力。

Method: 提出了“Think in Games (TiG)”框架。TiG将基于RL的决策制定重新构想为语言建模任务：LLMs生成语言引导的策略，这些策略通过基于环境反馈的在线强化学习进行迭代优化。

Result: TiG成功弥合了声明性知识和程序性知识之间的差距，与传统RL方法相比，以极低的数据和计算需求实现了具有竞争力的性能。此外，TiG为其决策提供了分步的自然语言解释，显著提高了复杂交互任务的透明度和可解释性。

Conclusion: TiG框架有效地使LLMs通过直接交互获取程序性理解，同时保留其推理和解释能力，从而实现了高效、高性能和可解释的交互式智能体。

Abstract: Large language models (LLMs) excel at complex reasoning tasks such as
mathematics and coding, yet they frequently struggle with simple interactive
tasks that young children perform effortlessly. This discrepancy highlights a
critical gap between declarative knowledge (knowing about something) and
procedural knowledge (knowing how to do something). Although traditional
reinforcement learning (RL) agents can acquire procedural knowledge through
environmental interaction, they often operate as black boxes and require
substantial training data. In contrast, LLMs possess extensive world knowledge
and reasoning capabilities, but are unable to effectively convert this static
knowledge into dynamic decision-making in interactive settings. To address this
challenge, we propose Think in Games (TiG), a novel framework that empowers
LLMs to develop procedural understanding through direct interaction with game
environments, while retaining their inherent reasoning and explanatory
abilities. Specifically, TiG reformulates RL-based decision-making as a
language modeling task: LLMs generate language-guided policies, which are
refined iteratively through online reinforcement learning based on
environmental feedback. Our experimental results show that TiG successfully
bridges the gap between declarative and procedural knowledge, achieving
competitive performance with dramatically lower data and computational demands
compared to conventional RL methods. Moreover, TiG provides step-by-step
natural language explanations for its decisions, greatly improving transparency
and interpretability in complex interactive tasks.

</details>


### [6] [AHELM: A Holistic Evaluation of Audio-Language Models](https://arxiv.org/abs/2508.21376)
*Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang*

Main category: cs.AI

TL;DR: AHELM是一个新的多方面基准测试，旨在标准化和全面评估音频语言模型（ALMs），涵盖10个关键方面，并引入新数据集。它揭示了领先模型的公平性问题以及基线系统的意外良好表现。


<details>
  <summary>Details</summary>
Motivation: 当前的音频语言模型（ALMs）评估缺乏标准化基准，大多只衡量一两个能力，忽略了公平性或安全性等重要评估维度。此外，由于评估方法、提示和推理参数的不同，模型之间的比较也十分困难。

Method: 本文引入了AHELM基准测试，它整合了多个数据集，包括两个新的合成音频文本数据集：PARADE（评估避免刻板印象）和CoRe-Bench（通过推断性多轮问答测量会话音频推理）。AHELM全面衡量ALMs在10个方面（音频感知、知识、推理、情感检测、偏见、公平性、多语言性、鲁棒性、毒性和安全性）的表现。同时，论文还标准化了提示、推理参数和评估指标，以确保模型间公平比较。研究测试了14个开源和闭源API的ALMs以及3个由自动语音识别器和语言模型组成的简单基线系统。

Result: 研究结果显示，Gemini 2.5 Pro在10个方面中有5个排名第一，但在ASR任务中表现出群体不公平性（p=0.01），而大多数其他模型则没有。此外，基线系统在AHELM上表现良好，其中一个尽管只具备语音转文本能力，但总体排名第五。

Conclusion: AHELM提供了一个全面的、标准化的方法来评估音频语言模型，揭示了不同模型在多方面（包括公平性）的性能表现。研究发现，即使是领先的模型也可能存在公平性问题，而简单的基线系统也能取得令人惊讶的良好性能。AHELM旨在成为一个持续更新的基准测试。

Abstract: Evaluations of audio-language models (ALMs) -- multimodal models that take
interleaved audio and text as input and output text -- are hindered by the lack
of standardized benchmarks; most benchmarks measure only one or two
capabilities and omit evaluative aspects such as fairness or safety.
Furthermore, comparison across models is difficult as separate evaluations test
a limited number of models and use different prompting methods and inference
parameters. To address these shortfalls, we introduce AHELM, a benchmark that
aggregates various datasets -- including 2 new synthetic audio-text datasets
called PARADE, which evaluates the ALMs on avoiding stereotypes, and
CoRe-Bench, which measures reasoning over conversational audio through
inferential multi-turn question answering -- to holistically measure the
performance of ALMs across 10 aspects we have identified as important to the
development and usage of ALMs: audio perception, knowledge, reasoning, emotion
detection, bias, fairness, multilinguality, robustness, toxicity, and safety.
We also standardize the prompts, inference parameters, and evaluation metrics
to ensure equitable comparisons across models. We test 14 open-weight and
closed-API ALMs from 3 developers and 3 additional simple baseline systems each
consisting of an automatic speech recognizer and a language model. Our results
show that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits
group unfairness ($p=0.01$) on ASR tasks whereas most of the other models do
not. We also find that the baseline systems perform reasonably well on AHELM,
with one ranking 5th overall despite having only speech-to-text capabilities.
For transparency, all raw prompts, model generations, and outputs are available
on our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is
intended to be a living benchmark and new datasets and models will be added
over time.

</details>


### [7] [AI Compute Architecture and Evolution Trends](https://arxiv.org/abs/2508.21394)
*Bor-Sung Liang*

Main category: cs.AI

TL;DR: 本文提出一个七层AI计算架构模型（物理层到应用层），阐述了其通过大型语言模型（LLMs）演进的过程，并分析了各层级的关键技术、发展趋势以及AI发展面临的技术和经济挑战，并基于互联网行业经验对AI未来轨迹进行预测。


<details>
  <summary>Details</summary>
Motivation: AI发展已从学术研究转向实际应用，但面临多层面挑战。研究旨在通过结构化方法分析AI的机遇与挑战。

Method: 文章提出一个七层AI计算架构模型（物理层、链路层、神经网络层、上下文层、代理层、编排层和应用层），并解释了AI计算如何通过大型语言模型（LLMs）的三阶段演进形成此架构。对每一层都描述了其发展轨迹和关键技术，并分析了互联网行业以预测AI的未来发展。

Result: 提出了一个七层AI计算架构模型；解释了AI计算如何通过LLMs演进至此架构；详细阐述了各层级的关键技术、发展路径（如计算问题、LLMs发展路径、上下文记忆、AI代理和生态系统）；指出了AI发展不仅面临技术挑战，还需解决构建可持续生态系统的经济问题；通过分析互联网行业对AI未来发展轨迹进行了预测。

Conclusion: AI发展需从多层次架构角度应对技术和经济挑战。所提出的七层模型提供了一个结构化视角，大型语言模型驱动的AI代理和生态系统演进将深刻影响AI产业，其发展轨迹可借鉴互联网行业的经验。

Abstract: The focus of AI development has shifted from academic research to practical
applications. However, AI development faces numerous challenges at various
levels. This article will attempt to analyze the opportunities and challenges
of AI from several different perspectives using a structured approach. This
article proposes a seven-layer model for AI compute architecture, including
Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,
Orchestrator Layer, and Application Layer, from bottom to top. It also explains
how AI computing has evolved into this 7-layer architecture through the
three-stage evolution on large-scale language models (LLMs). For each layer, we
describe the development trajectory and key technologies. In Layers 1 and 2 we
discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies
on computing architecture. In Layer 3 we explore two different development
paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs
and compares it to traditional processor memory. In Layers 5 to 7 we discuss
the trends of AI agents and explore the issues in evolution from a single AI
agent to an AI-based ecosystem, and their impact on the AI industry.
Furthermore, AI development involves not only technical challenges but also the
economic issues to build self-sustainable ecosystem. This article analyzes the
internet industry to provide predictions on the future trajectory of AI
development.

</details>


### [8] [CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN](https://arxiv.org/abs/2508.21411)
*Leonard Frank Neis,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: CARJAN是一种新工具，用于在CARLA中半自动化生成和模拟包含行人、骑行者和自动驾驶汽车等多种交互代理的城市交通场景，通过可视化用户界面和基于SPARQL行为树的决策实现。


<details>
  <summary>Details</summary>
Motivation: 对包含行人、骑行者和自动驾驶汽车等不同类型交互代理的城市交通场景进行用户友好的建模和虚拟仿真仍然是一个挑战。

Method: 该研究提出了CARJAN工具，它基于多代理工程框架AJAN和驾驶模拟器CARLA。CARJAN提供了一个用于交通场景布局建模、存储和维护的可视化用户界面，并利用基于SPARQL行为树的决策和交互来实现CARLA中的动态场景仿真。

Result: CARJAN提供了一个集成的半自动化工具，用于在CARLA中生成和模拟包含智能代理的虚拟交通场景，支持交互式建模和动态仿真。

Conclusion: CARJAN首次为CARLA中交互式、基于智能代理的虚拟交通场景生成和仿真提供了一种集成方法。

Abstract: User-friendly modeling and virtual simulation of urban traffic scenarios with
different types of interacting agents such as pedestrians, cyclists and
autonomous vehicles remains a challenge. We present CARJAN, a novel tool for
semi-automated generation and simulation of such scenarios based on the
multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN
provides a visual user interface for the modeling, storage and maintenance of
traffic scenario layouts, and leverages SPARQL Behavior Tree-based
decision-making and interactions for agents in dynamic scenario simulations in
CARLA. CARJAN provides a first integrated approach for interactive, intelligent
agent-based generation and simulation of virtual traffic scenarios in CARLA.

</details>


### [9] [A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions](https://arxiv.org/abs/2508.21441)
*Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald*

Main category: cs.AI

TL;DR: 本文将遗忘操作从经典逻辑提升到认知层面，提出了五种认知遗忘类型和七种基于Spohn排序函数的具体操作，并根据源自逻辑编程和AGM理论的公理对它们进行了评估。


<details>
  <summary>Details</summary>
Motivation: 现有的遗忘操作（如变量消除和收缩）主要基于经典逻辑。研究动机在于探索在具有更丰富语义结构（但与命题逻辑有明确联系）的认知状态中，遗忘意味着什么，从而将遗忘操作提升到认知层面。

Method: 研究方法包括：1) 采用认知视角，在认知状态中研究遗忘操作。2) 提出五种通用类型的认知遗忘。3) 基于Spohn排序函数实例化了七种具体的遗忘操作。4) 借鉴逻辑编程和AGM理论中的遗忘公理，提出了一套丰富的公理体系用于评估遗忘操作。5) 根据这些公理对所有具体的遗忘操作进行评估。

Result: 本文提出了五种通用类型的认知遗忘和七种针对Spohn排序函数的具体遗忘操作。通过对这些具体操作进行全面评估，揭示了不同遗忘操作之间的差异和共性，形成了一个新颖且全面的概览。

Conclusion: 研究成功地将遗忘操作提升到认知层面，为评估认知遗忘操作提供了一个丰富的公理框架，并通过对具体操作的全面评估，深入理解了它们在认知背景下的行为和属性。

Abstract: Forgetting as a knowledge management operation deliberately ignores parts of
the knowledge and beliefs of an agent, for various reasons. Forgetting has many
facets, one may want to forget parts of the syntax, a proposition, or a
conditional. In the literature, two main operators suitable for performing
forgetting have been proposed and investigated in depth: First, variable
elimination is a syntactical method that blends out certain atomic variables to
focus on the rest of the language. It has been mainly used in the area of logic
programming and answer set programming. Second, contraction in AGM belief
revision theory effectively removes propositions from belief sets under logical
deduction. Both operations rely mainly on classical logics. In this article, we
take an epistemic perspective and study forgetting operations in epistemic
states with richer semantic structures, but with clear links to propositional
logic. This allows us to investigate what forgetting in the epistemic
background means, thereby lifting well-known and novel forgetting operations to
the epistemic level. We present five general types of epistemic forgetting and
instantiate them with seven concrete forgetting operations for Spohn's ranking
functions. We take inspiration from postulates of forgetting both from logic
programming and AGM theory to propose a rich landscape of axioms for evaluating
forgetting operations. Finally, we evaluate all concrete forgetting operations
according to all postulates, leading to a novel comprehensive overview
highlighting differences and commonalities among the forgetting operators.

</details>


### [10] [Learning Lifted Action Models From Traces of Incomplete Actions and States](https://arxiv.org/abs/2508.21449)
*Niklas Jansen,Jonas Gösgens,Hector Geffner*

Main category: cs.AI

TL;DR: 本文提出了一种学习滑动拼图游戏提升STRIPS模型的新方法，该模型从不完整的状态-动作轨迹中学习，引入了STRIPS+变体和名为SYNTH的学习算法。


<details>
  <summary>Details</summary>
Motivation: 传统的模型学习方法通常假设动作是完整的STRIPS动作或所有领域谓词都是可观察的。本文旨在解决一个更“现实”的问题：状态不包含所有谓词（如“空白”位置），动作也不揭示所有必需的对象参数，这在滑动拼图等问题中尤为明显。

Method: 本文引入了STRIPS+，这是STRIPS的一种变体，其中某些动作参数可以在前置条件中隐式存在，并且前置条件可以包含有限形式的量词。学习问题被重新定义为从STRIPS+状态-动作轨迹中学习STRIPS+模型。提出的学习算法SYNTH为每个动作构建分层的（查询）前置条件表达式序列，以识别状态中的唯一对象并实例化STRIPS+中隐式的动作参数。

Result: SYNTH算法的正确性和完备性得到了证实。该算法在从现有STRIPS领域导出的STRIPS+模型生成的状态-动作轨迹上进行了可伸缩性测试。

Conclusion: 本文成功地提出了STRIPS+框架和SYNTH算法，以应对从更现实、不完整状态-动作轨迹中学习规划模型的挑战。该方法通过理论证明和实验测试，展示了其在处理隐式信息时的有效性。

Abstract: Consider the problem of learning a lifted STRIPS model of the sliding-tile
puzzle from random state-action traces where the states represent the location
of the tiles only, and the actions are the labels up, down, left, and right,
with no arguments. Two challenges are involved in this problem. First, the
states are not full STRIPS states, as some predicates are missing, like the
atoms representing the position of the ``blank''. Second, the actions are not
full STRIPS either, as they do not reveal all the objects involved in the
actions effects and preconditions. Previous approaches have addressed different
versions of this model learning problem, but most assume that actions in the
traces are full STRIPS actions or that the domain predicates are all
observable. The new setting considered in this work is more ``realistic'', as
the atoms observed convey the state of the world but not full STRIPS states,
and the actions reveal the arguments needed for selecting the action but not
the ones needed for modeling it in STRIPS. For formulating and addressing the
learning problem, we introduce a variant of STRIPS, which we call STRIPS+,
where certain STRIPS action arguments can be left implicit in preconditions
which can also involve a limited form of existential quantification. The
learning problem becomes the problem of learning STRIPS+ models from STRIPS+
state-action traces. For this, the proposed learning algorithm, called SYNTH,
constructs a stratified sequence (conjunction) of precondition expressions or
``queries'' for each action, that denote unique objects in the state and ground
the implicit action arguments in STRIPS+. The correctness and completeness of
SYNTH is established, and its scalability is tested on state-action traces
obtained from STRIPS+ models derived from existing STRIPS domains.

</details>


### [11] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: 本文引入了MMSearch-Plus，一个包含311个任务的新基准，旨在挑战大型多模态语言模型（MLLMs）在网页代理场景下进行精细多模态理解、溯源验证和长周期工具使用的能力，并揭示了现有模型的显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态浏览基准可以通过浅层、固定的工作流程（依赖高召回率图像搜索和附近文本掩码）解决，未能真正考验MLLMs在精细视觉推理、溯源验证和长周期工具使用方面的多模态能力。

Method: 研究人员构建了MMSearch-Plus基准，包含311个高度要求多模态理解的任务。每个任务都设计为需要提取、通过迭代文本-图像搜索传播，并在检索噪声下交叉验证多个弱的、局部视觉信号。其策展过程“时空外推法”通过空间线索（微文本、部件级外观、布局、标牌）和时间痕迹（广播叠加、季节背景）来推断图像外事实（如事件、日期、地点）。此外，本文提供了一个模型无关的代理框架和浏览工具，并评估了一系列封闭和开放的MLLMs，同时评估了边界框生成和裁剪图像搜索，并进行了错误分析。

Result: 在所提出的框架下，最强的代理（o3）在没有搜索的情况下准确率为15.1%，在进行搜索后准确率为36.0%。一个强大的开源模型（Qwen-2.5-VL-72B-Instruct）在没有搜索的情况下准确率为0.0%，在20轮搜索后准确率为6.9%。错误分析揭示了模型在来源验证、基于部件的推理和长周期规划方面的失败。

Conclusion: MMSearch-Plus基准揭示了当前MLLMs在需要精细多模态理解、迭代搜索和交叉验证的复杂网页浏览任务中表现出显著不足，尤其是在来源验证、部件推理和长周期规划方面，为未来MLLM的发展指明了方向。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [12] [Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis](https://arxiv.org/abs/2508.21517)
*Sweta Kaman,Ankita Sharma,Romi Banerjee*

Main category: cs.AI

TL;DR: 该研究提出了一种基于Z数的模糊推理系统，用于计算智慧的双属性表示（智慧得分和置信度），旨在克服传统测量方法的局限性，并为心理学测量和人性化AI提供新的框架。


<details>
  <summary>Details</summary>
Motivation: 传统的推理模型过于僵化，采用二元思维，无法捕捉智慧中固有的模糊性、不确定性和谦逊性。现有智慧测量多依赖自我报告，未能充分反映智慧推理中的谦逊和不确定性。因此，需要一个能同时考虑多维度和置信度的计算框架来改进心理学研究并促进人性化AI发展。

Method: 研究采用了一个基于Z数的模糊推理系统，将每个决策表示为智慧得分（限制）和置信度得分（确定性）。100名参与者完成文化中立的图片道德困境任务，并生成有声思维语言回应，这些回应被映射到智慧的五个理论组件。通过21条规则和高斯核密度估计调整的隶属函数，将各个组件得分进行组合。

Result: 概念验证研究表明，该系统生成了双属性的智慧表示，这些表示与现有量表适度但显著相关（支持聚合效度），同时与不相关特质关系微弱（支持区分效度）。

Conclusion: 该研究将智慧形式化为一个多维度、不确定性感知的构建，并以Z数形式进行操作化。除了推动心理学测量进步外，它还展示了模糊Z数如何为AI系统提供可解释、置信度敏感的推理，从而在严格计算和类人判断之间提供一个安全的中间地带。

Abstract: Background: Wisdom is a superordinate construct that embraces perspective
taking, reflectiveness, prosocial orientation, reflective empathetic action,
and intellectual humility. Unlike conventional models of reasoning that are
rigidly bound by binary thinking, wisdom unfolds in shades of ambiguity,
requiring both graded evaluation and self-reflective humility. Current measures
depend on self-reports and seldom reflect the humility and uncertainty inherent
in wise reasoning. A computational framework that takes into account both
multidimensionality and confidence has the potential to improve psychological
science and allow humane AI. Method: We present a fuzzy inference system with Z
numbers, each of the decisions being expressed in terms of a wisdom score
(restriction) and confidence score (certainty). As part of this study,
participants (N = 100) were exposed to culturally neutral pictorial moral
dilemma tasks to which they generated think-aloud linguistic responses, which
were mapped into five theoretically based components of wisdom. The scores of
each individual component were combined using a base of 21 rules, with
membership functions tuned via Gaussian kernel density estimation. Results: In
a proof of concept study, the system produced dual attribute wisdom
representations that correlated modestly but significantly with established
scales while showing negligible relations with unrelated traits, supporting
convergent and divergent validity. Contribution: The contribution is to
formalize wisdom as a multidimensional, uncertainty-conscious construct,
operationalized in the form of Z-numbers. In addition to progressing
measurement in psychology, it calculates how fuzzy Z numbers can provide AI
systems with interpretable, confidence-sensitive reasoning that affords a safe,
middle ground between rigorous computation and human-like judgment.

</details>


### [13] [Counterfactual Scenarios for Automated Planning](https://arxiv.org/abs/2508.21521)
*Nicola Gigante,Francesco Leofante,Andrea Micheli*

Main category: cs.AI

TL;DR: 本文提出了一种基于反事实情景的新型解释范式，通过最小化修改规划问题本身，使其能够产生满足特定高层属性（LTLf公式）的计划，从而克服了传统反事实解释在规划中只关注计划修改的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化规划中的反事实解释（CEs）侧重于对现有计划进行最小修改以达到不同目标，但这未能捕捉到所解决问题的更高层次属性。研究动机是为了解决这一局限性。

Method: 提出了一种基于“反事实情景”的新型解释范式。给定规划问题P和定义期望计划属性的LTLf公式ψ，反事实情景识别对P的最小修改，使得P能够产生符合ψ的计划。论文提出了两种基于显式量化满足ψ的计划的定性反事实情景实例化，并分析了在允许不同类型P修改时生成此类反事实情景的计算复杂性。

Result: 生成反事实情景的计算成本通常与计算P的计划的成本相当，这表明了该提案的实际可行性。

Conclusion: 该研究提供了一个构建该领域实用算法的框架，并证明了其提出的反事实情景解释范式的实际可行性。

Abstract: Counterfactual Explanations (CEs) are a powerful technique used to explain
Machine Learning models by showing how the input to a model should be minimally
changed for the model to produce a different output. Similar proposals have
been made in the context of Automated Planning, where CEs have been
characterised in terms of minimal modifications to an existing plan that would
result in the satisfaction of a different goal. While such explanations may
help diagnose faults and reason about the characteristics of a plan, they fail
to capture higher-level properties of the problem being solved. To address this
limitation, we propose a novel explanation paradigm that is based on
counterfactual scenarios. In particular, given a planning problem $P$ and an
\ltlf formula $\psi$ defining desired properties of a plan, counterfactual
scenarios identify minimal modifications to $P$ such that it admits plans that
comply with $\psi$. In this paper, we present two qualitative instantiations of
counterfactual scenarios based on an explicit quantification over plans that
must satisfy $\psi$. We then characterise the computational complexity of
generating such counterfactual scenarios when different types of changes are
allowed on $P$. We show that producing counterfactual scenarios is often only
as expensive as computing a plan for $P$, thus demonstrating the practical
viability of our proposal and ultimately providing a framework to construct
practical algorithms in this area.

</details>


### [14] [HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining](https://arxiv.org/abs/2508.21540)
*Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi*

Main category: cs.AI

TL;DR: HealthProcessAI是一个GenAI框架，旨在通过整合LLMs简化医疗和流行病学中的过程挖掘应用，实现自动化解释和报告生成，使复杂分析结果更易于理解。


<details>
  <summary>Details</summary>
Motivation: 过程挖掘在医疗领域应用面临技术复杂性、缺乏标准化方法和培训资源有限等障碍。此外，其技术分析结果难以被不同背景的用户理解。

Method: 引入HealthProcessAI框架，它封装了现有的Python (PM4PY) 和 R (bupaR) 库。该框架集成了多个大型语言模型 (LLMs) 用于自动化过程图解释和报告生成。通过败血症进展数据进行概念验证，并使用OpenRouter平台比较了五种最先进的LLM模型的输出。

Result: 该框架成功处理了四种概念验证场景下的败血症数据，展示了强大的技术性能和通过自动化LLM分析生成报告的能力。LLM评估显示，Claude Sonnet-4和Gemini 2.5-Pro在自动化LLM评估器评估时，分别达到了最高的报告一致性分数（3.79/4.0和3.65/4.0）。

Conclusion: 通过集成多个LLMs进行自动化解释和报告生成，HealthProcessAI框架解决了对过程挖掘输出不熟悉的问题，使其更易于临床医生、数据科学家和研究人员理解。这种结构化分析与AI驱动解释的结合，代表了将复杂过程挖掘结果转化为医疗应用中潜在可操作洞察的新颖方法学进展。

Abstract: Process mining has emerged as a powerful analytical technique for
understanding complex healthcare workflows. However, its application faces
significant barriers, including technical complexity, a lack of standardized
approaches, and limited access to practical training resources. We introduce
HealthProcessAI, a GenAI framework designed to simplify process mining
applications in healthcare and epidemiology by providing a comprehensive
wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address
unfamiliarity and improve accessibility, the framework integrates multiple
Large Language Models (LLMs) for automated process map interpretation and
report generation, helping translate technical analyses into outputs that
diverse users can readily understand. We validated the framework using sepsis
progression data as a proof-of-concept example and compared the outputs of five
state-of-the-art LLM models through the OpenRouter platform. To test its
functionality, the framework successfully processed sepsis data across four
proof-of-concept scenarios, demonstrating robust technical performance and its
capability to generate reports through automated LLM analysis. LLM evaluation
using five independent LLMs as automated evaluators revealed distinct model
strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency
scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By
integrating multiple Large Language Models (LLMs) for automated interpretation
and report generation, the framework addresses widespread unfamiliarity with
process mining outputs, making them more accessible to clinicians, data
scientists, and researchers. This structured analytics and AI-driven
interpretation combination represents a novel methodological advance in
translating complex process mining results into potentially actionable insights
for healthcare applications.

</details>


### [15] [Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances](https://arxiv.org/abs/2508.21564)
*Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt*

Main category: cs.AI

TL;DR: 本文提出了一种新的泛化地标框架，通过使用独立于对象的通用状态函数来捕获领域内的重复模式，并构建包含循环的有向地标图。该图可作为启发式函数用于规划，显著提升了对大型问题实例的性能，尤其是在存在重复子计划时。


<details>
  <summary>Details</summary>
Motivation: 传统的规划地标提取算法在描述规划问题的中间目标时存在不足，尤其未能有效泛化到整个领域并捕获重复模式，导致在复杂规划问题中表现不佳。

Method: 研究者提出泛化地标框架，通过使用独立于特定对象的状态函数来描述地标，从而捕获领域内的重复模式。基于这些函数，构建了一个有向泛化地标图，该图定义了地标的进展，并包含了重复子计划的循环可能性。最后，将该图应用于启发式函数，以解决同领域的新问题实例。

Result: 结果表明，从少量小实例中学习到的泛化地标图对同领域内的大型实例同样有效。当识别出指示重复的循环时，启发式性能相对于基线有显著提升。泛化地标捕获了可解释且对自动化规划器有用的领域信息。

Conclusion: 该泛化地标框架能够从少量规划中学习到可解释且对自动化规划器有用的领域信息。通过有效捕获重复模式，它显著提升了规划器的启发式性能，为解决复杂规划问题提供了有效途径。

Abstract: We propose a new framework for discovering landmarks that automatically
generalize across a domain. These generalized landmarks are learned from a set
of solved instances and describe intermediate goals for planning problems where
traditional landmark extraction algorithms fall short. Our generalized
landmarks extend beyond the predicates of a domain by using state functions
that are independent of the objects of a specific problem and apply to all
similar objects, thus capturing repetition. Based on these functions, we
construct a directed generalized landmark graph that defines the landmark
progression, including loop possibilities for repetitive subplans. We show how
to use this graph in a heuristic to solve new problem instances of the same
domain. Our results show that the generalized landmark graphs learned from a
few small instances are also effective for larger instances in the same domain.
If a loop that indicates repetition is identified, we see a significant
improvement in heuristic performance over the baseline. Generalized landmarks
capture domain information that is interpretable and useful to an automated
planner. This information can be discovered from a small set of plans for the
same domain.

</details>


### [16] [Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics](https://arxiv.org/abs/2508.21595)
*Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes*

Main category: cs.AI

TL;DR: 本文提出了一种新的确定性多智能体规划模型——确定性去中心化部分可观测马尔可夫决策过程（Det-Dec-POMDP），并为此类大规模问题设计了一个名为IDPP的迭代求解器。


<details>
  <summary>Details</summary>
Motivation: 许多高级多智能体规划问题（如多机器人导航）可以用确定性动作和观测来有效建模。然而，现有的去中心化部分可观测马尔可夫决策过程（Dec-POMDP）求解器无法有效处理这类大规模问题。

Method: 作者引入了Det-Dec-POMDP，这是Dec-POMDP的一个子类，其特点是状态和联合动作决定的确定性转移和观测。然后，提出了一种实用的求解器，名为迭代确定性POMDP规划（IDPP），该方法基于经典的联合均衡策略搜索（JES）框架并进行了优化。

Result: IDPP方法专门优化，能够处理现有Dec-POMDP求解器无法高效解决的大规模Det-Dec-POMDP问题。

Conclusion: Det-Dec-POMDP模型和IDPP求解器为具有确定性动态和观测的大规模多智能体规划问题提供了一种有效的建模和求解方案。

Abstract: Many high-level multi-agent planning problems, including multi-robot
navigation and path planning, can be effectively modeled using deterministic
actions and observations.
  In this work, we focus on such domains and introduce the class of
Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of
Dec-POMDPs characterized by deterministic transitions and observations
conditioned on the state and joint actions.
  We then propose a practical solver called Iterative Deterministic POMDP
Planning (IDPP). This method builds on the classic Joint Equilibrium Search for
Policies framework and is specifically optimized to handle large-scale
Det-Dec-POMDPs that current Dec-POMDP solvers are unable to address
efficiently.

</details>


### [17] [Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study](https://arxiv.org/abs/2508.21622)
*Saravanan Venkatachalam*

Main category: cs.AI

TL;DR: 该论文提出一个集成框架，结合网络优化模型和大型语言模型（LLMs），为供应链规划提供交互式、可解释且角色感知的决策支持。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了弥合复杂运筹学输出与业务利益相关者理解之间的鸿沟，使决策支持系统更易于理解和使用。

Method: 方法包括：1) 一个核心的混合整数规划模型，用于多周期、多物品、跨配送中心的战术库存再分配；2) 利用LLMs生成自然语言摘要、情境化可视化和定制的关键绩效指标（KPIs）；3) 技术架构包含AI代理、RESTful API和动态用户界面，以支持实时交互、配置更新和基于仿真的洞察。

Result: 案例研究表明，该系统通过防止缺货、降低成本和维持服务水平，显著改善了规划结果。

Conclusion: 该集成系统能有效改善供应链规划成果。未来的工作将包括集成私有LLMs、迁移学习、强化学习和贝叶斯神经网络，以增强解释性、适应性和实时决策能力。

Abstract: This paper presents an integrated framework that combines traditional network
optimization models with large language models (LLMs) to deliver interactive,
explainable, and role-aware decision support for supply chain planning. The
proposed system bridges the gap between complex operations research outputs and
business stakeholder understanding by generating natural language summaries,
contextual visualizations, and tailored key performance indicators (KPIs). The
core optimization model addresses tactical inventory redistribution across a
network of distribution centers for multi-period and multi-item, using a
mixed-integer formulation. The technical architecture incorporates AI agents,
RESTful APIs, and a dynamic user interface to support real-time interaction,
configuration updates, and simulation-based insights. A case study demonstrates
how the system improves planning outcomes by preventing stockouts, reducing
costs, and maintaining service levels. Future extensions include integrating
private LLMs, transfer learning, reinforcement learning, and Bayesian neural
networks to enhance explainability, adaptability, and real-time
decision-making.

</details>


### [18] [A-MHA*: Anytime Multi-Heuristic A*](https://arxiv.org/abs/2508.21637)
*Ramkumar Natarajan,Muhammad Suhail Saleem,William Xiao,Sandip Aine,Howie Choset,Maxim Likhachev*

Main category: cs.AI

TL;DR: 本文提出了一种名为A-MHA*的算法，它将多启发式A* (MHA*) 扩展为一种随时（anytime）算法，使其能够快速找到次优解并持续改进，同时保留了MHA*的理论保证。


<details>
  <summary>Details</summary>
Motivation: 图搜索中设计良好的启发式函数需要领域知识，且启发式函数可能在某些区域表现良好但不全局可采纳。MHA*利用多个不可采纳的启发式函数来加速次优解的生成，但其原始版本是一次性算法，无法随时间推移改进解决方案。

Method: 通过将Anytime Repairing A* (ARA*) 算法的概念精确地应用于MHA*框架，将MHA*扩展为随时版本，命名为A-MHA*。

Result: A-MHA*在MHA*框架中保留了原始的次优性和完备性保证，并增强了MHA*以随时方式执行。在3D路径规划和滑动拼图领域，A-MHA*与MHA*及其他随时算法进行了性能比较。

Conclusion: A-MHA*成功地将MHA*扩展为一种随时算法，使其能够快速找到可行次优解并持续改进，同时保持了原有的理论保证，并在实验中展现了其性能。

Abstract: Designing good heuristic functions for graph search requires adequate domain
knowledge. It is often easy to design heuristics that perform well and
correlate with the underlying true cost-to-go values in certain parts of the
search space but these may not be admissible throughout the domain thereby
affecting the optimality guarantees of the search. Bounded suboptimal search
using several such partially good but inadmissible heuristics was developed in
Multi-Heuristic A* (MHA*). Although MHA* leverages multiple inadmissible
heuristics to potentially generate a faster suboptimal solution, the original
version does not improve the solution over time. It is a one shot algorithm
that requires careful setting of inflation factors to obtain a desired one time
solution. In this work, we tackle this issue by extending MHA* to an anytime
version that finds a feasible suboptimal solution quickly and continually
improves it until time runs out. Our work is inspired from the Anytime
Repairing A* (ARA*) algorithm. We prove that our precise adaptation of ARA*
concepts in the MHA* framework preserves the original suboptimal and
completeness guarantees and enhances MHA* to perform in an anytime fashion.
Furthermore, we report the performance of A-MHA* in 3-D path planning domain
and sliding tiles puzzle and compare against MHA* and other anytime algorithms.

</details>


### [19] [Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI](https://arxiv.org/abs/2508.21648)
*Farhad Abtahi,Mehdi Astaraki,Fernando Seoane*

Main category: cs.AI

TL;DR: MEDLEY是一个概念框架，旨在通过整合多个AI模型并保留其多样化输出（包括偏见和幻觉），而非消除它们，来增强医疗诊断，从而将AI的“缺陷”转化为临床监督下的资源。


<details>
  <summary>Details</summary>
Motivation: 传统上，医学AI中的偏见被视为必须消除的缺陷。然而，人类推理本身就包含受教育、文化和经验影响的偏见，这表明AI中偏见的存在可能是不可避免且潜在有价值的。

Method: 提出了MEDLEY（利用多样性的医疗集成诊断系统）概念框架。该框架协调多个AI模型，保留其多样化输出而非统一共识，将模型特定偏见视为潜在优势，并将幻觉视为待临床医生验证的临时假设。开发了一个概念验证演示器，使用了30多个大型语言模型，创建了一个最小可行产品。

Result: 该最小可行产品在合成案例中保留了共识和少数观点，使诊断不确定性和潜在偏见对临床监督透明化。尽管尚未经过临床验证，但演示表明结构化的多样性可以在临床医生监督下增强医疗推理。

Conclusion: MEDLEY通过将AI的不完善之处重新定义为一种资源，提供了一种范式转变，为开发可信赖的医学AI系统开辟了新的监管、伦理和创新途径。结构化的多样性能够在临床医生监督下增强医疗推理。

Abstract: Bias in medical artificial intelligence is conventionally viewed as a defect
requiring elimination. However, human reasoning inherently incorporates biases
shaped by education, culture, and experience, suggesting their presence may be
inevitable and potentially valuable. We propose MEDLEY (Medical Ensemble
Diagnostic system with Leveraged diversitY), a conceptual framework that
orchestrates multiple AI models while preserving their diverse outputs rather
than collapsing them into a consensus. Unlike traditional approaches that
suppress disagreement, MEDLEY documents model-specific biases as potential
strengths and treats hallucinations as provisional hypotheses for clinician
verification. A proof-of-concept demonstrator was developed using over 30 large
language models, creating a minimum viable product that preserved both
consensus and minority views in synthetic cases, making diagnostic uncertainty
and latent biases transparent for clinical oversight. While not yet a validated
clinical tool, the demonstration illustrates how structured diversity can
enhance medical reasoning under clinician supervision. By reframing AI
imperfection as a resource, MEDLEY offers a paradigm shift that opens new
regulatory, ethical, and innovation pathways for developing trustworthy medical
AI systems.

</details>


### [20] [Tree-Guided Diffusion Planner](https://arxiv.org/abs/2508.21800)
*Hyeonseong Jeon,Cheolhong Min,Jaesik Park*

Main category: cs.AI

TL;DR: 本文提出了一种名为TDP（Tree-guided Diffusion Planner）的零样本测试时规划框架，通过树形搜索和双层采样，利用预训练扩散模型解决非凸、不可微和多奖励等复杂控制问题，并在多个任务上超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度引导的扩散模型规划方法在非凸、不可微奖励函数或多奖励结构等真实世界场景中效果不佳。此外，近期监督规划方法需要任务特定训练或价值估计器，限制了测试时灵活性和零样本泛化能力。

Method: TDP将测试时规划构建为一个树形搜索问题，采用双层采样过程：1) 通过无训练的粒子引导生成多样化的父轨迹以鼓励广泛探索；2) 通过由任务目标引导的快速条件去噪来细化子轨迹。该方法仅使用预训练模型和测试时奖励信号，平衡了探索与利用。

Result: TDP在三个不同任务（迷宫捡金币、机械臂积木操作和AntMaze多目标探索）上进行了评估，结果显示它始终优于所有任务上的现有SOTA方法。

Conclusion: TDP通过探索多样化的轨迹区域并利用扩展解空间中的梯度信息，有效解决了梯度引导在复杂规划场景中的局限性，实现了卓越的零样本性能。

Abstract: Planning with pretrained diffusion models has emerged as a promising approach
for solving test-time guided control problems. However, standard gradient
guidance typically performs optimally under convex and differentiable reward
landscapes, showing substantially reduced effectiveness in real-world scenarios
involving non-convex objectives, non-differentiable constraints, and
multi-reward structures. Furthermore, recent supervised planning approaches
require task-specific training or value estimators, which limits test-time
flexibility and zero-shot generalization. We propose a Tree-guided Diffusion
Planner (TDP), a zero-shot test-time planning framework that balances
exploration and exploitation through structured trajectory generation. We frame
test-time planning as a tree search problem using a bi-level sampling process:
(1) diverse parent trajectories are produced via training-free particle
guidance to encourage broad exploration, and (2) sub-trajectories are refined
through fast conditional denoising guided by task objectives. TDP addresses the
limitations of gradient guidance by exploring diverse trajectory regions and
harnessing gradient information across this expanded solution space using only
pretrained models and test-time reward signals. We evaluate TDP on three
diverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze
multi-goal exploration. TDP consistently outperforms state-of-the-art
approaches on all tasks. The project page can be found at:
tree-diffusion-planner.github.io.

</details>


### [21] [PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation](https://arxiv.org/abs/2508.21720)
*Jiho Choi,Seojeong Park,Seongjong Song,Hyunjung Shim*

Main category: cs.AI

TL;DR: 本文提出了一个名为PosterForest的无需训练的自动化科学海报生成框架。该框架通过引入分层中间表示“Poster Tree”和多智能体协作策略，有效解决了科学文档的层级结构和图文语义整合问题，生成的海报质量接近专家水平。


<details>
  <summary>Details</summary>
Motivation: 以往的自动化海报生成方法大多忽略了科学文档的层级结构以及文本与视觉元素的语义整合，导致生成的海报在逻辑一致性、内容忠实度和视觉连贯性方面表现不佳。

Method: 该方法引入了“Poster Tree”作为分层的中间表示，共同编码文档结构和多层次的视觉-文本关系。框架采用多智能体协作策略，其中内容摘要和布局规划智能体迭代协调并相互提供反馈，从而联合优化逻辑一致性、内容忠实度和视觉连贯性。

Result: 在多个学术领域的广泛实验表明，PosterForest在定性和定量评估中均优于现有基线。生成的海报质量最接近专家设计，并展现出卓越的信息保留、结构清晰度和用户偏好。

Conclusion: PosterForest框架通过其创新的分层表示和多智能体协作机制，成功克服了自动化科学海报生成中的核心挑战，能够生成高质量、结构清晰且用户满意度高的海报，其效果与专家设计的海报最为接近。

Abstract: We present a novel training-free framework, \textit{PosterForest}, for
automated scientific poster generation. Unlike prior approaches, which largely
neglect the hierarchical structure of scientific documents and the semantic
integration of textual and visual elements, our method addresses both
challenges directly. We introduce the \textit{Poster Tree}, a hierarchical
intermediate representation that jointly encodes document structure and
visual-textual relationships at multiple levels. Our framework employs a
multi-agent collaboration strategy, where agents specializing in content
summarization and layout planning iteratively coordinate and provide mutual
feedback. This approach enables the joint optimization of logical consistency,
content fidelity, and visual coherence. Extensive experiments on multiple
academic domains show that our method outperforms existing baselines in both
qualitative and quantitative evaluations. The resulting posters achieve quality
closest to expert-designed ground truth and deliver superior information
preservation, structural clarity, and user preference.

</details>


### [22] [Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem](https://arxiv.org/abs/2508.21730)
*Fabrizio Fagiolo,Nicolo' Vescera*

Main category: cs.AI

TL;DR: 本文提出了一种针对旅行商问题（TSP）的变分算法，结合了紧凑的排列编码和“优化-冻结-重用”策略，在适中规模问题上表现出良好的泛化能力，但存在可扩展性限制。


<details>
  <summary>Details</summary>
Motivation: 为解决旅行商问题，并使其能够在当前的NISQ（噪声中等规模量子）硬件上有效实现，需要一种减少量子比特需求和降低测试阶段计算成本的方法，特别是避免昂贵的结构搜索。

Method: 该方法是一种变分算法，采用：1) 紧凑的排列编码以减少量子比特需求；2) “优化-冻结-重用”策略：首先使用模拟退火（SA）在训练实例上优化电路拓扑（Ansatz），然后“冻结”此Ansatz并在新实例上重复使用，仅需快速重新优化电路参数。

Result: 在4-7个城市的40个随机对称实例上测试：4城市案例的平均最优路径采样概率为100%；5城市案例为90%；6城市案例为80%。7城市案例的成功率显著下降至约20%，揭示了该方法的可扩展性限制。结果表明，对于中等规模问题具有鲁棒的泛化能力，并且冻结Ansatz能显著减少解决时间而不降低解决方案质量。

Conclusion: 该研究表明，所提出的变分算法在适中规模的旅行商问题上具有鲁棒的泛化能力，并且通过冻结Ansatz可以显著减少解决问题所需的时间，使其适用于NISQ硬件。尽管目前存在可扩展性限制，但该方法有望扩展到车辆路径和作业车间调度等更复杂的问题。

Abstract: In this paper we present a variational algorithm for the Traveling Salesman
Problem (TSP) that combines (i) a compact encoding of permutations, which
reduces the qubit requirement too, (ii) an optimize-freeze-reuse strategy:
where the circuit topology (``Ansatz'') is first optimized on a training
instance by Simulated Annealing (SA), then ``frozen'' and re-used on novel
instances, limited to a rapid re-optimization of only the circuit parameters.
This pipeline eliminates costly structural research in testing, making the
procedure immediately implementable on NISQ hardware.
  On a set of $40$ randomly generated symmetric instances that span $4 - 7$
cities, the resulting Ansatz achieves an average optimal trip sampling
probability of $100\%$ for 4 city cases, $90\%$ for 5 city cases and $80\%$ for
6 city cases. With 7 cities the success rate drops markedly to an average of
$\sim 20\%$, revealing the onset of scalability limitations of the proposed
method.
  The results show robust generalization ability for moderate problem sizes and
indicate how freezing the Ansatz can dramatically reduce time-to-solution
without degrading solution quality. The paper also discusses scalability
limitations, the impact of ``warm-start'' initialization of parameters, and
prospects for extension to more complex problems, such as Vehicle Routing and
Job-Shop Scheduling.

</details>


### [23] [Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions](https://arxiv.org/abs/2508.21742)
*Timothée Loranchet,Charles K. Assaad*

Main category: cs.AI

TL;DR: 本研究提出在已知专家提供的摘要因果图（SCG）的背景下，如何保证时间序列中微观层面因果边的可定向性，即使宏观层面存在循环或双向边。


<details>
  <summary>Details</summary>
Motivation: 时间序列中因果关系的理解极具挑战性，尤其当完整的因果结构未知时。专家虽然能提供高层次的摘要因果图，但如何利用这些信息来推断微观层面的因果细节是一个未解决的问题。

Method: 该研究提出了在给定摘要因果图作为背景知识，并假设可获得真实未知图的忠实且因果充分分布的情况下，保证时间变量之间微观层面边缘可定向性的条件。

Result: 研究结果为微观层面的边缘定向提供了理论保证，即使在宏观层面存在循环或双向边的情况下也适用。

Conclusion: 这些发现为利用摘要因果图（SCG）指导复杂时间系统中的因果发现提供了实用指导，并强调了结合专家知识以改进观测时间序列数据因果推断的价值。

Abstract: Understanding causal relations between temporal variables is a central
challenge in time series analysis, particularly when the full causal structure
is unknown. Even when the full causal structure cannot be fully specified,
experts often succeed in providing a high-level abstraction of the causal
graph, known as a summary causal graph, which captures the main causal
relations between different time series while abstracting away micro-level
details. In this work, we present conditions that guarantee the orientability
of micro-level edges between temporal variables given the background knowledge
encoded in a summary causal graph and assuming having access to a faithful and
causally sufficient distribution with respect to the true unknown graph. Our
results provide theoretical guarantees for edge orientation at the micro-level,
even in the presence of cycles or bidirected edges at the macro-level. These
findings offer practical guidance for leveraging SCGs to inform causal
discovery in complex temporal systems and highlight the value of incorporating
expert knowledge to improve causal inference from observational time series
data.

</details>


### [24] [Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture](https://arxiv.org/abs/2508.21803)
*Yeawon Lee,Xiaoyang Wang,Christopher C. Yang*

Main category: cs.AI

TL;DR: 该研究引入了一个协作式多智能体系统（MAS），模拟临床会诊团队，用于从SOAP笔记中识别临床问题。该系统在识别充血性心力衰竭、急性肾损伤和败血症方面优于单一智能体基线。


<details>
  <summary>Details</summary>
Motivation: 临床叙述的准确解读对患者护理至关重要，但其复杂性使得自动化面临挑战。大型语言模型（LLMs）虽有潜力，但单一模型方法在处理高风险临床任务时缺乏所需的鲁棒性。

Method: 研究引入了一个协作式多智能体系统（MAS），模拟临床会诊团队。该系统通过分析SOAP笔记的主观（S）和客观（O）部分来识别临床问题。一个“经理”智能体协调一个动态分配的专家智能体团队，这些智能体进行分层、迭代的辩论以达成共识。该系统在包含420份MIMIC-III笔记的精选数据集上，与单一智能体基线进行了评估。

Result: 动态多智能体配置在识别充血性心力衰竭、急性肾损伤和败血症方面表现出持续改进的性能。对智能体辩论的定性分析表明，这种结构能有效揭示和权衡冲突证据，尽管偶尔可能容易出现群体思维。

Conclusion: 通过模拟临床团队的推理过程，该系统为开发更准确、鲁棒和可解释的临床决策支持工具提供了一条有前景的途径。

Abstract: Accurate interpretation of clinical narratives is critical for patient care,
but the complexity of these notes makes automation challenging. While Large
Language Models (LLMs) show promise, single-model approaches can lack the
robustness required for high-stakes clinical tasks. We introduce a
collaborative multi-agent system (MAS) that models a clinical consultation team
to address this gap. The system is tasked with identifying clinical problems by
analyzing only the Subjective (S) and Objective (O) sections of SOAP notes,
simulating the diagnostic reasoning process of synthesizing raw data into an
assessment. A Manager agent orchestrates a dynamically assigned team of
specialist agents who engage in a hierarchical, iterative debate to reach a
consensus. We evaluated our MAS against a single-agent baseline on a curated
dataset of 420 MIMIC-III notes. The dynamic multi-agent configuration
demonstrated consistently improved performance in identifying congestive heart
failure, acute kidney injury, and sepsis. Qualitative analysis of the agent
debates reveals that this structure effectively surfaces and weighs conflicting
evidence, though it can occasionally be susceptible to groupthink. By modeling
a clinical team's reasoning process, our system offers a promising path toward
more accurate, robust, and interpretable clinical decision support tools.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [25] [2COOOL: 2nd Workshop on the Challenge Of Out-Of-Label Hazards in Autonomous Driving](https://arxiv.org/abs/2508.21080)
*Ali K. AlShami,Ryan Rabinowitz,Maged Shoman,Jianwu Fang,Lukas Picek,Shao-Yuan Lo,Steve Cruz,Khang Nhut Lam,Nachiket Kamod,Lei-Lei Li,Jugal Kalita,Terrance E. Boult*

Main category: cs.CV

TL;DR: 2COOOL研讨会旨在推动自动驾驶领域对新颖场景和标签外危险的处理能力，以提高安全性并促进实际部署。


<details>
  <summary>Details</summary>
Motivation: 尽管计算机视觉和传感器数据融合技术在自动驾驶中至关重要，但自动驾驶汽车仍未完全安全，主要障碍在于处理新颖场景和分布外危险。这促使了对异常处理方法的需求。

Method: 研讨会将探讨和鼓励以下方法：分布外危险检测、用于危险理解的视觉-语言模型、新的基准测试和方法论、安全的自动驾驶实践，并借鉴异常检测、开放集识别、开放词汇建模和域适应等领域的思想。

Result: 研讨会旨在激发开发新的危险规避算法和系统，推动新颖性处理的最新技术发展，并汇集学术界和工业界的参与者。

Conclusion: 解决自动驾驶中的新颖场景和标签外危险是实现完全安全自动驾驶的关键。2COOOL研讨会提供了一个专门的平台，以促进该领域的研究和技术进步。

Abstract: As the computer vision community advances autonomous driving algorithms,
integrating vision-based insights with sensor data remains essential for
improving perception, decision making, planning, prediction, simulation, and
control. Yet we must ask: Why don't we have entirely safe self-driving cars
yet? A key part of the answer lies in addressing novel scenarios, one of the
most critical barriers to real-world deployment. Our 2COOOL workshop provides a
dedicated forum for researchers and industry experts to push the state of the
art in novelty handling, including out-of-distribution hazard detection,
vision-language models for hazard understanding, new benchmarking and
methodologies, and safe autonomous driving practices. The 2nd Workshop on the
Challenge of Out-of-Label Hazards in Autonomous Driving (2COOOL) will be held
at the International Conference on Computer Vision (ICCV) 2025 in Honolulu,
Hawaii, on October 19, 2025. We aim to inspire the development of new
algorithms and systems for hazard avoidance, drawing on ideas from anomaly
detection, open-set recognition, open-vocabulary modeling, domain adaptation,
and related fields. Building on the success of its inaugural edition at the
Winter Conference on Applications of Computer Vision (WACV) 2025, the workshop
will feature a mix of academic and industry participation.

</details>


### [26] [Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks](https://arxiv.org/abs/2508.21715)
*Amirhossein Nazeri,Wael Hafez*

Main category: cs.CV

TL;DR: 该研究提出一种无需修改模型的新方法，通过监测卷积神经网络（CNN）激活层中的熵值变化，实时检测对抗性攻击，且不影响模型在正常数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管CNN在图像识别任务中表现出色，但它们容易受到对抗性扰动的攻击。现有的检测方法通常需要昂贵的再训练、修改网络架构或降低在干净输入上的性能，这些缺点促使研究人员寻找更有效的解决方案。

Method: 研究人员发现对抗性扰动会在CNN激活中产生可立即检测到的熵签名。他们使用并行熵监测技术在VGG-16网络上进行了实验，以观察对抗性输入对激活熵的影响。

Result: 实验表明，对抗性输入会使早期卷积层的激活熵持续偏移7%，从而实现90%的检测准确率，同时误报率和漏报率均低于20%。干净和对抗性输入之间的熵分布完全分离，揭示了CNN在激活模式中固有的分布偏移编码能力。

Conclusion: 该工作证明了仅通过激活熵就能评估CNN的可靠性，从而实现实用的自诊断视觉系统。这些系统能够在不损害原始模型性能的情况下，实时检测对抗性输入，具有重要的实际部署价值。

Abstract: Convolutional Neural Networks (CNNs) have become the foundation of modern
computer vision, achieving unprecedented accuracy across diverse image
recognition tasks. While these networks excel on in-distribution data, they
remain vulnerable to adversarial perturbations imperceptible input
modifications that cause misclassification with high confidence. However,
existing detection methods either require expensive retraining, modify network
architecture, or degrade performance on clean inputs. Here we show that
adversarial perturbations create immediate, detectable entropy signatures in
CNN activations that can be monitored without any model modification. Using
parallel entropy monitoring on VGG-16, we demonstrate that adversarial inputs
consistently shift activation entropy by 7% in early convolutional layers,
enabling 90% detection accuracy with false positives and false negative rates
below 20%. The complete separation between clean and adversarial entropy
distributions reveals that CNNs inherently encode distribution shifts in their
activation patterns. This work establishes that CNN reliability can be assessed
through activation entropy alone, enabling practical deployment of
self-diagnostic vision systems that detect adversarial inputs in real-time
without compromising original model performance.

</details>


### [27] [Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images](https://arxiv.org/abs/2508.21088)
*Alireza Golkarieh,Kiana Kiashemshaki,Sajjad Rezvani Boroujeni*

Main category: cs.CV

TL;DR: 本研究评估了深度学习方法在全景X射线图像中自动分类牙齿状况的性能，发现混合模型（CNN特征提取结合传统分类器）表现最佳，其中CNN-Random Forest模型准确率达到85.4%。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在开发一种自动化方法，用于全景X射线图像中牙齿状况的分类，以提供高效、可靠的牙科诊断支持。

Method: 研究使用了包含1512张X射线图像和11137个专家验证注释的数据集，涵盖龋齿、填充物、种植体和阻生齿四种牙齿状况。经过预处理和类别平衡后，评估了三种方法：自定义卷积神经网络（CNN）、结合CNN特征提取与传统分类器的混合模型，以及微调的预训练架构。实验采用5折交叉验证，并使用准确率、精确度、召回率和F1分数作为评估指标。

Result: 混合CNN-Random Forest模型表现最佳，准确率达到85.4%，显著优于自定义CNN基线（74.3%）。在预训练模型中，VGG16表现最好，准确率为82.3%，其次是Xception和ResNet50。结果表明，混合模型能提高形态相似状况的鉴别能力。

Conclusion: 结合CNN特征提取与集成分类器的混合模型为自动化牙科诊断支持提供了一条实用的途径，同时也强调了需要更大规模数据集和进一步临床验证的重要性。

Abstract: This study investigates deep learning methods for automated classification of
dental conditions in panoramic X-ray images. A dataset of 1,512 radiographs
with 11,137 expert-verified annotations across four conditions fillings,
cavities, implants, and impacted teeth was used. After preprocessing and class
balancing, three approaches were evaluated: a custom convolutional neural
network (CNN), hybrid models combining CNN feature extraction with traditional
classifiers, and fine-tuned pre-trained architectures. Experiments employed 5
fold cross validation with accuracy, precision, recall, and F1 score as
evaluation metrics. The hybrid CNN Random Forest model achieved the highest
performance with 85.4% accuracy, surpassing the custom CNN baseline of 74.3%.
Among pre-trained models, VGG16 performed best at 82.3% accuracy, followed by
Xception and ResNet50. Results show that hybrid models improve discrimination
of morphologically similar conditions and provide efficient, reliable
performance. These findings suggest that combining CNN-based feature extraction
with ensemble classifiers offers a practical path toward automated dental
diagnostic support, while also highlighting the need for larger datasets and
further clinical validation.

</details>


### [28] [Q-Align: Alleviating Attention Leakage in Zero-Shot Appearance Transfer via Query-Query Alignment](https://arxiv.org/abs/2508.21090)
*Namu Kim,Wonbin Kweon,Minsoo Kim,Hwanjo Yu*

Main category: cs.CV

TL;DR: 针对大规模图像生成模型在零样本外观迁移中出现的“注意力泄漏”问题，本文提出了Q-Align方法，通过查询-查询对齐、键值重排和注意力精炼来缓解泄漏，显著提升外观保真度并保持结构一致性。


<details>
  <summary>Details</summary>
Motivation: 大规模图像生成模型在零样本外观迁移中存在“注意力泄漏”的显著挑战，即语义映射被查询-键对齐捕获时导致的问题。

Method: 本文引入了Q-Align方法来解决注意力泄漏问题，其核心贡献包括：1) 查询-查询对齐，以促进两图像间复杂的空间语义映射；2) 键值重排，通过重新对齐增强特征对应；3) 使用重排后的键和值进行注意力精炼，以保持语义一致性。

Result: 通过广泛的实验和分析，Q-Align被验证是有效的，在外观保真度方面超越了现有最先进的方法，同时保持了有竞争力的结构保留能力。

Conclusion: Q-Align成功解决了零样本外观迁移中的注意力泄漏问题，显著提高了外观保真度，并有效保持了结构一致性。

Abstract: We observe that zero-shot appearance transfer with large-scale image
generation models faces a significant challenge: Attention Leakage. This
challenge arises when the semantic mapping between two images is captured by
the Query-Key alignment. To tackle this issue, we introduce Q-Align, utilizing
Query-Query alignment to mitigate attention leakage and improve the semantic
alignment in zero-shot appearance transfer. Q-Align incorporates three core
contributions: (1) Query-Query alignment, facilitating the sophisticated
spatial semantic mapping between two images; (2) Key-Value rearrangement,
enhancing feature correspondence through realignment; and (3) Attention
refinement using rearranged keys and values to maintain semantic consistency.
We validate the effectiveness of Q-Align through extensive experiments and
analysis, and Q-Align outperforms state-of-the-art methods in appearance
fidelity while maintaining competitive structure preservation.

</details>


### [29] [ERTACache: Error Rectification and Timesteps Adjustment for Efficient Diffusion](https://arxiv.org/abs/2508.21091)
*Xurui Peng,Hong Liu,Chenqian Yan,Rui Ma,Fangmin Chen,Xing Wang,Zhihua Wu,Songwei Liu,Mingbao Lin*

Main category: cs.CV

TL;DR: ERTACache是一种新的缓存框架，旨在通过纠正特征偏移和步长放大错误，显著加速扩散模型的推理过程，同时保持或提高生成质量，最高可达2倍提速。


<details>
  <summary>Details</summary>
Motivation: 扩散模型因其迭代推理过程而导致计算开销巨大。虽然特征缓存可以加速，但简单重用中间输出会导致明显的质量下降。研究旨在解决这一问题，同时保持生成质量。

Method: ERTACache通过正式分析累积误差（特征偏移误差和步长放大误差），并提出一个联合纠正这两种错误类型的框架。具体方法包括：离线残差分析以识别可重用步骤；通过轨迹感知校正系数动态调整积分间隔；以及通过闭式残差线性化模型分析性地近似缓存引起的误差。

Result: ERTACache在标准图像和视频生成基准上实现了高达2倍的推理加速，同时始终保持甚至提高了视觉质量。特别是在最先进的Wan2.1视频扩散模型上，它实现了2倍加速，而VBench退化最小，有效保持了基线保真度。

Conclusion: ERTACache是一个原则性的缓存框架，能够通过精确分析和纠正缓存引起的误差，在激进的缓存重用下实现准确高效的采样，显著提高了扩散模型的效率而没有牺牲生成质量。

Abstract: Diffusion models suffer from substantial computational overhead due to their
inherently iterative inference process. While feature caching offers a
promising acceleration strategy by reusing intermediate outputs across
timesteps, naive reuse often incurs noticeable quality degradation. In this
work, we formally analyze the cumulative error introduced by caching and
decompose it into two principal components: feature shift error, caused by
inaccuracies in cached outputs, and step amplification error, which arises from
error propagation under fixed timestep schedules. To address these issues, we
propose ERTACache, a principled caching framework that jointly rectifies both
error types. Our method employs an offline residual profiling stage to identify
reusable steps, dynamically adjusts integration intervals via a
trajectory-aware correction coefficient, and analytically approximates
cache-induced errors through a closed-form residual linearization model.
Together, these components enable accurate and efficient sampling under
aggressive cache reuse. Extensive experiments across standard image and video
generation benchmarks show that ERTACache achieves up to 2x inference speedup
while consistently preserving or even improving visual quality. Notably, on the
state-of-the-art Wan2.1 video diffusion model, ERTACache delivers 2x
acceleration with minimal VBench degradation, effectively maintaining baseline
fidelity while significantly improving efficiency. The code is available at
https://github.com/bytedance/ERTACache.

</details>


### [30] [Video-LLMs with Temporal Visual Screening](https://arxiv.org/abs/2508.21094)
*Zheyu Fan,Jiateng Liu,Yuji Zhang,Zihan Wang,Yi R.,Fung,Manling Li,Heng Ji*

Main category: cs.CV

TL;DR: 本文提出了一种名为“时序视觉筛选”（TVS）的新任务，旨在通过保留关键视频片段并同步重构查询，解决当前视频大语言模型（Video-LLMs）在捕获细粒度时序语义方面的不足，从而提高视频-语言理解能力。


<details>
  <summary>Details</summary>
Motivation: 人类自然地通过拖动进度条和关注显著时序片段来进行时序筛选，但当前的Video-LLMs由于稀疏帧采样和训练期间缺乏足够的帧间推理监督，难以捕捉细粒度时序语义。

Method: 受认知科学原理启发，本文提出了时序视觉筛选（TVS）任务，作为预处理视频问答和指令微调数据的通用方法。TVS通过以下方式实现：1) 保留焦点关键视频片段；2) 同步将查询重构为最直接的形式，同时保持答案一致性；3) 保持任何可能答案的不变性和一致性。TVS被设计为一个模块化的前端适配器任务，可无缝集成到Video指令微调（训练）和Video问答（推理）流程中。本文还策划了第一个TVS基准，并提出了ReSimplifyIt基线模型。

Result: ReSimplifyIt基线模型在视频剪辑任务上比现有方法高出0.47的F-1分数，并在查询重写方面表现出竞争力。实验表明，整合TVS在训练阶段带来了7.33%的相对增益，在推理阶段带来了34.6%的相对增益。

Conclusion: 时序信息筛选（TVS）对于提高视频-语言理解能力是有效的，通过优化推理负担和认知负荷，显著提升了Video-LLMs的性能。

Abstract: Humans naturally perform temporal screening by dragging the progress bar and
focusing on salient temporal segments, but current Video Large Language Models
(Video-LLMs) struggle to capture fine-grained temporal semantics due to sparse
frame sampling and insufficient inter-frame reasoning supervision during their
training. To address this, Inspired by well-established cognitive science
principles, we propose Temporal Visual Screening (TVS), a new task that
universally pre-processes video question answering and instruction tuning data
by: (1) retaining focus-critical video segments, (2) synchronously
reconstructing queries to their most direct form while preserving answer
consistency, and (3) keeping the invariance and consistency for any possible
answer. TVS is formulated as a modular front-end adapter task that can be
seamlessly integrated into both Video Instruction Tuning (training) and Video
Question Answering (inference) pipelines. TVS optimizes distribution of
reasoning burden and cognitive load; during training, it aligns queries with
focus-critical visual information; at inference, it enables query-aware segment
focus and streamlined query representations. In particular, we curate the first
benchmark for TVS and propose ReSimplifyIt, a baseline outperforming prior
approaches on seemingly similar tasks by 0.47 in F-1 score on video trimming
while achieving competitive query rewriting performance. Experiments
demonstrate that incorporating TVS yields relative gains of 7.33% (training)
and 34.6% (inference), demonstrating the effectiveness of temporal information
screening for improving video-language understanding.

</details>


### [31] [ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset for Laparoscopic Surgical Instruments](https://arxiv.org/abs/2508.21096)
*Zhe Han,Charlie Budd,Gongyu Zhang,Huanyu Tian,Christos Bergeles,Tom Vercauteren*

Main category: cs.CV

TL;DR: 该论文提出骨骼姿态标注作为手术工具定位的一种高效方法，解决了传统分割方法数据稀缺的问题。为此，作者发布了ROBUST-MIPS数据集、基准模型和标注软件，并展示了姿态标注的有效性。


<details>
  <summary>Details</summary>
Motivation: 计算机辅助介入技术中手术工具定位是基础，但当前基于深度学习的分割方法受限于多样化标注数据的可用性。作者认为骨骼姿态标注能更有效地平衡语义信息丰富性和标注便捷性，从而加速标注数据增长。

Method: 提出骨骼姿态标注方法。基于现有ROBUST-MIS数据集，构建了ROBUST-MIPS数据集，结合了工具姿态和工具实例分割。使用流行的姿态估计算法建立了简单的基准测试，以验证姿态标注的有效性。同时发布了数据集、基准模型和自定义工具姿态标注软件。

Result: 在基准测试中，使用姿态标注进行手术工具定位取得了高质量的结果，证明了其充分性。

Conclusion: 骨骼姿态标注是手术工具定位的一种高效且充分的标注方法，它在语义信息丰富性和标注便捷性之间取得了良好平衡，有助于加速可用标注数据的增长。发布的ROBUST-MIPS数据集和相关工具将促进该标注风格的采用和研究。

Abstract: Localisation of surgical tools constitutes a foundational building block for
computer-assisted interventional technologies. Works in this field typically
focus on training deep learning models to perform segmentation tasks.
Performance of learning-based approaches is limited by the availability of
diverse annotated data. We argue that skeletal pose annotations are a more
efficient annotation approach for surgical tools, striking a balance between
richness of semantic information and ease of annotation, thus allowing for
accelerated growth of available annotated data. To encourage adoption of this
annotation style, we present, ROBUST-MIPS, a combined tool pose and tool
instance segmentation dataset derived from the existing ROBUST-MIS dataset. Our
enriched dataset facilitates the joint study of these two annotation styles and
allow head-to-head comparison on various downstream tasks. To demonstrate the
adequacy of pose annotations for surgical tool localisation, we set up a simple
benchmark using popular pose estimation methods and observe high-quality
results. To ease adoption, together with the dataset, we release our benchmark
models and custom tool pose annotation software.

</details>


### [32] [Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models](https://arxiv.org/abs/2508.21099)
*Xiangtao Meng,Yingkai Dong,Ning Yu,Li Wang,Zheng Li,Shanqing Guo*

Main category: cs.CV

TL;DR: Safe-Control是一个即插即用的安全补丁，通过注入安全控制信号，有效减少Text-to-Image (T2I)模型中的不安全内容生成，同时保持图像质量，并显著优于现有安全机制。


<details>
  <summary>Details</summary>
Motivation: 尽管Text-to-Image (T2I)模型取得了进步，但其潜在的滥用引发了严重的安全问题。现有安全机制（无论是外部还是内部）在分布偏移下容易被规避，或者需要大量的模型特定调整。

Method: 本文引入了Safe-Control，一个创新的即插即用安全补丁。它采用数据驱动策略和安全感知条件，向锁定的T2I模型注入安全控制信号，以补丁的形式进行更新。该设计允许开发人员构建和合并多个安全补丁，并确保其与具有类似去噪架构的其他T2I模型兼容。

Result: 在六个不同的T2I模型上进行的广泛评估表明，Safe-Control能有效减少不安全内容生成，同时成功保持良性图像的质量和文本对齐。与七种最先进的安全机制相比，Safe-Control在减少不安全内容生成方面显著优于所有基线，例如在不安全提示和最新对抗性攻击下，将不安全内容生成概率降低到7%，而大多数基线方法约为20%。

Conclusion: Safe-Control提供了一个有效、灵活且可兼容的解决方案，用于减轻T2I模型中的不安全内容生成，克服了现有安全机制的局限性。

Abstract: Despite the advancements in Text-to-Image (T2I) generation models, their
potential for misuse or even abuse raises serious safety concerns. Model
developers have made tremendous efforts to introduce safety mechanisms that can
address these concerns in T2I models. However, the existing safety mechanisms,
whether external or internal, either remain susceptible to evasion under
distribution shifts or require extensive model-specific adjustments. To address
these limitations, we introduce Safe-Control, an innovative plug-and-play
safety patch designed to mitigate unsafe content generation in T2I models.
Using data-driven strategies and safety-aware conditions, Safe-Control injects
safety control signals into the locked T2I model, acting as an update in a
patch-like manner. Model developers can also construct various safety patches
to meet the evolving safety requirements, which can be flexibly merged into a
single, unified patch. Its plug-and-play design further ensures adaptability,
making it compatible with other T2I models of similar denoising architecture.
We conduct extensive evaluations on six diverse and public T2I models.
Empirical results highlight that Safe-Control is effective in reducing unsafe
content generation across six diverse T2I models with similar generative
architectures, yet it successfully maintains the quality and text alignment of
benign images. Compared to seven state-of-the-art safety mechanisms, including
both external and internal defenses, Safe-Control significantly outperforms all
baselines in reducing unsafe content generation. For example, it reduces the
probability of unsafe content generation to 7%, compared to approximately 20%
for most baseline methods, under both unsafe prompts and the latest adversarial
attacks.

</details>


### [33] [GENNAV: Polygon Mask Generation for Generalized Referring Navigable Regions](https://arxiv.org/abs/2508.21102)
*Kei Katsumata,Yui Iioka,Naoki Hosomi,Teruhisa Misu,Kentaro Yamada,Komei Sugiura*

Main category: cs.CV

TL;DR: 该研究提出了GENNAV，一种用于从自然语言指令和车载摄像头图像中识别目标区域（特别是边界模糊的“stuff-type”区域）的方法。GENNAV能预测目标是否存在并生成多个目标区域的分割掩码。通过构建新的GRiN-Drive基准和进行真实世界实验，GENNAV在性能和零样本迁移能力上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 从自然语言指令和前置摄像头图像中识别目标区域（包括存在预测和分割）是一项具有挑战性的任务，尤其对于边界模糊的“stuff-type”目标区域。现有方法在处理“stuff-type”目标、目标缺失或多个目标时表现不佳，这促使研究者开发更有效的方法。

Method: 本文提出了GENNAV模型，该模型能够预测目标是否存在，并为多个“stuff-type”目标区域生成分割掩码。为了评估GENNAV，研究者构建了一个名为GRiN-Drive的新基准，其中包含无目标、单目标和多目标三种样本类型。此外，还在五个不同地理区域的城市中，使用四辆汽车进行了真实世界实验，以验证其零样本迁移性能。

Result: GENNAV在GRiN-Drive基准上，使用标准评估指标，取得了优于基线方法的性能。在真实世界实验中，GENNAV同样超越了基线方法，并展示了其在多样化真实世界环境中的鲁棒性。

Conclusion: GENNAV有效解决了从自然语言指令和图像中识别“stuff-type”目标区域的挑战，并在合成基准和多样化的真实世界环境中均表现出卓越的性能和强大的零样本迁移能力，证明了其在实际应用中的鲁棒性。

Abstract: We focus on the task of identifying the location of target regions from a
natural language instruction and a front camera image captured by a mobility.
This task is challenging because it requires both existence prediction and
segmentation, particularly for stuff-type target regions with ambiguous
boundaries. Existing methods often underperform in handling stuff-type target
regions, in addition to absent or multiple targets. To overcome these
limitations, we propose GENNAV, which predicts target existence and generates
segmentation masks for multiple stuff-type target regions. To evaluate GENNAV,
we constructed a novel benchmark called GRiN-Drive, which includes three
distinct types of samples: no-target, single-target, and multi-target. GENNAV
achieved superior performance over baseline methods on standard evaluation
metrics. Furthermore, we conducted real-world experiments with four automobiles
operated in five geographically distinct urban areas to validate its zero-shot
transfer performance. In these experiments, GENNAV outperformed baseline
methods and demonstrated its robustness across diverse real-world environments.
The project page is available at https://gennav.vercel.app/.

</details>


### [34] [R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning](https://arxiv.org/abs/2508.21113)
*Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng*

Main category: cs.CV

TL;DR: R-4B是一种自适应思考的多模态大语言模型（MLLM），它能根据问题复杂性智能决定是否激活分步思考过程，从而提高效率并保持高性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM的分步思考能力虽然在复杂推理问题上表现出色，但对于简单问题而言，这种思考过程是冗余且低效的。

Method: R-4B通过双模态退火（bi-mode annealing）赋予模型思考和非思考两种能力，并采用双模态策略优化（Bi-mode Policy Optimization, BPO）来提高模型决定是否激活思考过程的准确性。具体方法包括：首先在一个包含思考和非思考模式样本的精心策划的数据集上进行训练；然后，在改进的GRPO框架下进行第二阶段训练，强制策略模型为每个输入查询生成两种模式的响应。

Result: R-4B在25个挑战性基准测试中取得了最先进的性能。它在大多数任务中超越了Qwen2.5-VL-7B，并在推理密集型基准测试上实现了与Kimi-VL-A3B-Thinking-2506（16B）等大型模型相当的性能，同时计算成本更低。

Conclusion: R-4B成功地解决了MLLM在处理不同复杂性问题时的效率问题，通过自适应地选择思考模式，在保持高推理能力的同时显著降低了计算冗余，展现了高效且强大的性能。

Abstract: Multimodal Large Language Models (MLLMs) equipped with step-by-step thinking
capabilities have demonstrated remarkable performance on complex reasoning
problems. However, this thinking process is redundant for simple problems
solvable without complex reasoning. To address this inefficiency, we propose
R-4B, an auto-thinking MLLM, which can adaptively decide when to think based on
problem complexity. The central idea of R-4B is to empower the model with both
thinking and non-thinking capabilities using bi-mode annealing, and apply
Bi-mode Policy Optimization~(BPO) to improve the model's accuracy in
determining whether to activate the thinking process. Specifically, we first
train the model on a carefully curated dataset spanning various topics, which
contains samples from both thinking and non-thinking modes. Then it undergoes a
second phase of training under an improved GRPO framework, where the policy
model is forced to generate responses from both modes for each input query.
Experimental results show that R-4B achieves state-of-the-art performance
across 25 challenging benchmarks. It outperforms Qwen2.5-VL-7B in most tasks
and achieves performance comparable to larger models such as
Kimi-VL-A3B-Thinking-2506 (16B) on reasoning-intensive benchmarks with lower
computational cost.

</details>


### [35] [HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection](https://arxiv.org/abs/2508.21135)
*Harris Song,Tuan-Anh Vu,Sanjith Menon,Sriram Narasimhan,M. Khalid Jawed*

Main category: cs.CV

TL;DR: 本研究提出了HiddenObject，一个基于Mamba的融合框架，整合RGB、热成像和深度数据，以增强在遮挡、伪装和光照变化等挑战性条件下对隐藏或部分遮蔽物体的检测能力，并取得了最先进或具有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 在多模态环境中，由于遮挡、伪装和光照变化等因素，检测隐藏或部分遮蔽的物体仍然是一个基本挑战。传统的基于RGB的检测方法在这些不利条件下常常失效，因此需要更鲁棒、与模态无关的方法。

Method: 本研究提出了HiddenObject，一个融合框架，它使用基于Mamba的融合机制整合了RGB、热成像和深度数据。该方法捕获跨模态的互补信号，识别模态特定特征，并将其融合为一个统一的表示，以实现对模糊或伪装目标的增强检测。

Result: HiddenObject在多个基准数据集上进行了验证，与现有方法相比，展示了最先进或具有竞争力的性能。这些结果突出了其融合设计的有效性，并揭示了当前单模态和朴素融合策略的关键局限性。

Conclusion: 研究结果表明，基于Mamba的融合架构可以显著推动多模态目标检测领域的发展，特别是在视觉退化或复杂条件下。

Abstract: Detecting hidden or partially concealed objects remains a fundamental
challenge in multimodal environments, where factors like occlusion, camouflage,
and lighting variations significantly hinder performance. Traditional RGB-based
detection methods often fail under such adverse conditions, motivating the need
for more robust, modality-agnostic approaches. In this work, we present
HiddenObject, a fusion framework that integrates RGB, thermal, and depth data
using a Mamba-based fusion mechanism. Our method captures complementary signals
across modalities, enabling enhanced detection of obscured or camouflaged
targets. Specifically, the proposed approach identifies modality-specific
features and fuses them in a unified representation that generalizes well
across challenging scenarios. We validate HiddenObject across multiple
benchmark datasets, demonstrating state-of-the-art or competitive performance
compared to existing methods. These results highlight the efficacy of our
fusion design and expose key limitations in current unimodal and na\"ive fusion
strategies. More broadly, our findings suggest that Mamba-based fusion
architectures can significantly advance the field of multimodal object
detection, especially under visually degraded or complex conditions.

</details>


### [36] [RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative Gaussians Reconstruction and 3D/3D Registration](https://arxiv.org/abs/2508.21154)
*Ao Shen,Xueming Fu,Junfeng Jiang,Qiang Zeng,Ye Tang,Zhengming Chen,Luming Nong,Feng Wang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: 本文提出RadGS-Reg，一个用于椎体级CT/X射线配准的新框架。它通过联合3D辐射高斯（RadGS）重建和3D/3D配准，解决了现有方法在空间信息丢失、域间隙、噪声鲁棒性差和密集视图要求等方面的局限性，并在内部数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 图像引导导航中的CT/X射线配准对精度和实时性要求高，但面临挑战。传统“渲染与比较”方法存在空间信息丢失和域间隙问题。基于双平面X射线的3D重建方法虽能补充信息，但受限于密集视图要求且难以处理噪声X射线。

Method: 本文引入RadGS-Reg框架，通过联合3D辐射高斯（RadGS）重建和3D/3D配准实现椎体级CT/X射线配准。具体方法包括：1) 双平面X射线椎体RadGS重建模块，采用基于学习的RadGS重建和反事实注意力学习（CAL）机制，以关注噪声X射线中的椎体区域。2) 患者特定预训练策略，逐步使RadGS-Reg从模拟数据适应真实数据，同时学习椎体形状先验知识。

Result: 在内部数据集上进行的实验表明，RadGS-Reg在RadGS重建和CT/X射线配准这两项任务中均表现出最先进的性能，超越了现有方法。

Conclusion: RadGS-Reg通过其创新的联合3D辐射高斯重建和3D/3D配准方法，并结合反事实注意力学习和患者特定预训练策略，有效克服了传统CT/X射线配准的挑战，实现了高精度、鲁棒的椎体级配准。

Abstract: Computed Tomography (CT)/X-ray registration in image-guided navigation
remains challenging because of its stringent requirements for high accuracy and
real-time performance. Traditional "render and compare" methods, relying on
iterative projection and comparison, suffer from spatial information loss and
domain gap. 3D reconstruction from biplanar X-rays supplements spatial and
shape information for 2D/3D registration, but current methods are limited by
dense-view requirements and struggles with noisy X-rays. To address these
limitations, we introduce RadGS-Reg, a novel framework for vertebral-level
CT/X-ray registration through joint 3D Radiative Gaussians (RadGS)
reconstruction and 3D/3D registration. Specifically, our biplanar X-rays
vertebral RadGS reconstruction module explores learning-based RadGS
reconstruction method with a Counterfactual Attention Learning (CAL) mechanism,
focusing on vertebral regions in noisy X-rays. Additionally, a patient-specific
pre-training strategy progressively adapts the RadGS-Reg from simulated to real
data while simultaneously learning vertebral shape prior knowledge. Experiments
on in-house datasets demonstrate the state-of-the-art performance for both
tasks, surpassing existing methods. The code is available at:
https://github.com/shenao1995/RadGS_Reg.

</details>


### [37] [SYNBUILD-3D: A large, multi-modal, and semantically rich synthetic dataset of 3D building models at Level of Detail 4](https://arxiv.org/abs/2508.21169)
*Kevin Mayer,Alex Vesel,Xinyi Zhao,Martin Fischer*

Main category: cs.CV

TL;DR: 本文介绍了SYNBUILD-3D，一个包含超过620万个合成LoD 4住宅建筑的大型、多样化、多模态数据集，旨在解决3D建筑模型自动生成中缺乏标注数据的问题。


<details>
  <summary>Details</summary>
Motivation: 3D建筑模型在建筑、能源模拟和导航等应用中至关重要。然而，由于公共领域缺乏大规模标注数据集，自动生成精确且语义丰富的3D建筑仍然是一个重大挑战。

Method: 受计算机视觉中合成数据成功的启发，作者引入了SYNBUILD-3D数据集。该数据集包含超过620万个合成的LoD 4住宅建筑，每个建筑通过三种模态表示：语义丰富的LoD 4 3D线框图、相应的平面图图像和类似LiDAR的屋顶点云。语义标注（房间、门、窗）从平面图图像中导出。

Result: 创建了一个大型（超过620万个建筑）、多样化、多模态的合成数据集SYNBUILD-3D。每个建筑都包含LoD 4线框图（带语义标注）、平面图图像和屋顶点云，实现了语义-几何一致性。

Conclusion: SYNBUILD-3D数据集的三模态特性，将支持未来开发新颖的生成式AI算法，以自动化创建LoD 4 3D建筑模型，这些模型将基于预定义的平面布局和屋顶几何结构，并能强制执行语义-几何一致性。

Abstract: 3D building models are critical for applications in architecture, energy
simulation, and navigation. Yet, generating accurate and semantically rich 3D
buildings automatically remains a major challenge due to the lack of
large-scale annotated datasets in the public domain. Inspired by the success of
synthetic data in computer vision, we introduce SYNBUILD-3D, a large, diverse,
and multi-modal dataset of over 6.2 million synthetic 3D residential buildings
at Level of Detail (LoD) 4. In the dataset, each building is represented
through three distinct modalities: a semantically enriched 3D wireframe graph
at LoD 4 (Modality I), the corresponding floor plan images (Modality II), and a
LiDAR-like roof point cloud (Modality III). The semantic annotations for each
building wireframe are derived from the corresponding floor plan images and
include information on rooms, doors, and windows. Through its tri-modal nature,
future work can use SYNBUILD-3D to develop novel generative AI algorithms that
automate the creation of 3D building models at LoD 4, subject to predefined
floor plan layouts and roof geometries, while enforcing semantic-geometric
consistency. Dataset and code samples are publicly available at
https://github.com/kdmayer/SYNBUILD-3D.

</details>


### [38] [Radially Distorted Homographies, Revisited](https://arxiv.org/abs/2508.21190)
*Mårten Wadenbäck,Marcus Valtonen Örnhag,Johan Edstedt*

Main category: cs.CV

TL;DR: 本文提出了一种新颖统一的方法，用于同时估计径向畸变同形变换，涵盖了三种不同的畸变配置。该方法构建了更快、更稳定、更准确的最小求解器，并在保持相似精度的前提下，显著提升了现有技术的速度。


<details>
  <summary>Details</summary>
Motivation: 同形变换估计是计算机视觉中的关键步骤，但真实图像常受相机镜头几何畸变（特别是径向畸变）影响。为获得有效估计，需要同时确定同形变换和径向畸变。现有方法通常分别处理三种径向畸变配置，缺乏统一方案。

Method: 本文提出了一种新颖且统一的方法来解决径向畸变同形变换的三种概念上不同的配置：（i）仅在一张图像中存在畸变，（ii）两张图像中存在相同畸变，以及（iii）两张图像中存在独立畸变。该方法被用于构建新的快速、稳定、准确的最小求解器。

Result: 在所有三种畸变配置下，本文提出的求解器比现有最先进的求解器更快，同时保持了相似的精度。这些求解器已在包括鱼眼相机图像在内的成熟基准测试中进行了验证。

Conclusion: 本文成功开发了一种统一、快速、稳定且准确的最小求解器，用于处理径向畸变同形变换的估计问题。该求解器在速度上优于现有技术，同时保持了高精度，有效解决了真实图像中同形变换和镜头畸变同时估计的挑战。

Abstract: Homographies are among the most prevalent transformations occurring in
geometric computer vision and projective geometry, and homography estimation is
consequently a crucial step in a wide assortment of computer vision tasks. When
working with real images, which are often afflicted with geometric distortions
caused by the camera lens, it may be necessary to determine both the homography
and the lens distortion-particularly the radial component, called radial
distortion-simultaneously to obtain anything resembling useful estimates. When
considering a homography with radial distortion between two images, there are
three conceptually distinct configurations for the radial distortion; (i)
distortion in only one image, (ii) identical distortion in the two images, and
(iii) independent distortion in the two images. While these cases have been
addressed separately in the past, the present paper provides a novel and
unified approach to solve all three cases. We demonstrate how the proposed
approach can be used to construct new fast, stable, and accurate minimal
solvers for radially distorted homographies. In all three cases, our proposed
solvers are faster than the existing state-of-the-art solvers while maintaining
similar accuracy. The solvers are tested on well-established benchmarks
including images taken with fisheye cameras. The source code for our solvers
will be made available in the event our paper is accepted for publication.

</details>


### [39] [GCAV: A Global Concept Activation Vector Framework for Cross-Layer Consistency in Interpretability](https://arxiv.org/abs/2508.21197)
*Zhenghao He,Sanchit Sinha,Guangzhi Xiong,Aidong Zhang*

Main category: cs.CV

TL;DR: 本文提出了全局概念激活向量（GCAV），通过对比学习和注意力融合机制，将深度神经网络中不同层的概念激活向量（CAVs）统一为语义一致的表示，从而解决了传统CAVs跨层不一致的问题，提供了更稳定和可靠的概念归因。


<details>
  <summary>Details</summary>
Motivation: 传统的概念激活向量（CAVs）在不同层独立计算时常表现出不一致性，导致跨层比较不可靠。这限制了对深度神经网络如何编码人类定义概念的全面理解。

Method: 研究者提出了全局概念激活向量（GCAV）框架，通过以下方式实现：1) 利用对比学习对齐跨层的概念表示；2) 采用注意力机制融合不同层的概念信息，构建一个全局集成的CAV。此外，还引入了TGCAV方法，将TCAV应用于基于GCAV的表示。

Result: GCAV显著降低了TCAV分数的方差，同时保留了概念相关性，确保了更稳定和可靠的概念归因。实验证明，该方法有效缓解了跨层概念不一致性，增强了概念定位能力，并提高了对抗性扰动的鲁棒性。

Conclusion: 通过将跨层信息整合到一个连贯的框架中，GCAV为理解深度学习模型如何编码人类定义的概念提供了一种更全面、更具解释性的方法。

Abstract: Concept Activation Vectors (CAVs) provide a powerful approach for
interpreting deep neural networks by quantifying their sensitivity to
human-defined concepts. However, when computed independently at different
layers, CAVs often exhibit inconsistencies, making cross-layer comparisons
unreliable. To address this issue, we propose the Global Concept Activation
Vector (GCAV), a novel framework that unifies CAVs into a single, semantically
consistent representation. Our method leverages contrastive learning to align
concept representations across layers and employs an attention-based fusion
mechanism to construct a globally integrated CAV. By doing so, our method
significantly reduces the variance in TCAV scores while preserving concept
relevance, ensuring more stable and reliable concept attributions. To evaluate
the effectiveness of GCAV, we introduce Testing with Global Concept Activation
Vectors (TGCAV) as a method to apply TCAV to GCAV-based representations. We
conduct extensive experiments on multiple deep neural networks, demonstrating
that our method effectively mitigates concept inconsistency across layers,
enhances concept localization, and improves robustness against adversarial
perturbations. By integrating cross-layer information into a coherent
framework, our method offers a more comprehensive and interpretable
understanding of how deep learning models encode human-defined concepts. Code
and models are available at https://github.com/Zhenghao-He/GCAV.

</details>


### [40] [Generalizable Object Re-Identification via Visual In-Context Prompting](https://arxiv.org/abs/2508.21222)
*Zhizhong Huang,Xiaoming Liu*

Main category: cs.CV

TL;DR: 本文提出了视觉上下文提示（VICP）框架，通过结合大型语言模型（LLM）和视觉基础模型（VFM），仅利用上下文示例就能使模型泛化到未见过的目标类别，无需参数适应或重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有目标重识别（ReID）方法通常针对特定领域（如行人或车辆），缺乏泛化能力，且在新类别上需要昂贵的标注数据。自监督学习虽然减少了标注需求，但难以捕获ReID所需的身份敏感特征。

Method: VICP框架通过以下方式实现：1) LLM利用少量正/负样本对，通过任务特定提示推断语义身份规则；2) 这些规则随后引导VFM（如DINO）通过动态视觉提示提取身份判别特征。通过对齐LLM导出的语义概念与VFM的预训练先验，VICP实现了向新类别的泛化。为支持评估，引入了ShopID10K数据集。

Result: 在ShopID10K和多个ReID基准测试上的实验表明，VICP在未见过的类别上明显优于现有基线方法。

Conclusion: VICP成功地将LLM和VFM结合起来，无需参数适应或特定数据集的再训练，即可使模型直接泛化到新的目标类别，有效解决了现有ReID方法的泛化性差和数据标注成本高的问题。

Abstract: Current object re-identification (ReID) methods train domain-specific models
(e.g., for persons or vehicles), which lack generalization and demand costly
labeled data for new categories. While self-supervised learning reduces
annotation needs by learning instance-wise invariance, it struggles to capture
\textit{identity-sensitive} features critical for ReID. This paper proposes
Visual In-Context Prompting~(VICP), a novel framework where models trained on
seen categories can directly generalize to unseen novel categories using only
\textit{in-context examples} as prompts, without requiring parameter
adaptation. VICP synergizes LLMs and vision foundation models~(VFM): LLMs infer
semantic identity rules from few-shot positive/negative pairs through
task-specific prompting, which then guides a VFM (\eg, DINO) to extract
ID-discriminative features via \textit{dynamic visual prompts}. By aligning
LLM-derived semantic concepts with the VFM's pre-trained prior, VICP enables
generalization to novel categories, eliminating the need for dataset-specific
retraining. To support evaluation, we introduce ShopID10K, a dataset of 10K
object instances from e-commerce platforms, featuring multi-view images and
cross-domain testing. Experiments on ShopID10K and diverse ReID benchmarks
demonstrate that VICP outperforms baselines by a clear margin on unseen
categories. Code is available at https://github.com/Hzzone/VICP.

</details>


### [41] [Lightweight MRI-Based Automated Segmentation of Pancreatic Cancer with Auto3DSeg](https://arxiv.org/abs/2508.21227)
*Keshav Jha,William Sharp,Dominic LaBella*

Main category: cs.CV

TL;DR: 本研究在2025年PANTHER挑战赛中，使用SegResNet模型对两种MRI序列（诊断性T1CE和MR-Linac T2）上的胰腺肿瘤进行自动分割。结果显示，由于数据集小和MRI序列差异，分割性能一般，但展示了自动化分割的潜力，并强调需要更大的标准化数据集。


<details>
  <summary>Details</summary>
Motivation: 胰腺肿瘤的精确描绘对于诊断、治疗计划和预后评估至关重要，但由于解剖变异性和数据集有限，自动分割仍然充满挑战。

Method: 研究采用Auto3DSeg架构中的SegResNet模型进行训练和评估。方法包括5折交叉验证，结合STAPLE集成，并专注于解剖学相关的感兴趣区域。任务1使用91例T1加权动脉期增强MRI，任务2使用50例T2加权MR-Linac MRI。性能评估指标包括Dice相似系数(DSC)、5毫米DSC、95% Hausdorff距离(HD95)、平均表面距离(MASD)和均方根误差(RMSE)。

Result: 任务1（T1CE MRI）的胰腺肿瘤分割表现为：DSC 0.56，5毫米DSC 0.73，HD95 41.1毫米，MASD 26.0毫米，RMSE 5164毫米。任务2（MR-Linac T2 MRI）的性能有所下降，表现为：DSC 0.33，5毫米DSC 0.50，HD95 20.1毫米，MASD 7.2毫米，RMSE 17203毫米。

Conclusion: 研究结果表明，基于MRI的胰腺肿瘤分割在小数据集下具有挑战性，且不同MRI序列引入了变异性。尽管性能一般，但结果展示了自动描绘的潜力，并强调需要更大、更标准化的MRI数据集以提高模型的鲁棒性和临床实用性。

Abstract: Accurate delineation of pancreatic tumors is critical for diagnosis,
treatment planning, and outcome assessment, yet automated segmentation remains
challenging due to anatomical variability and limited dataset availability. In
this study, SegResNet models, as part of the Auto3DSeg architecture, were
trained and evaluated on two MRI-based pancreatic tumor segmentation tasks as
part of the 2025 PANTHER Challenge. Algorithm methodology included 5-fold
cross-validation with STAPLE ensembling after focusing on an anatomically
relevant region-of-interest. The Pancreatic Tumor Segmentation on Diagnostic
MRI task 1 training set included 91 T1-weighted arterial contrast-enhanced MRI
with expert annotated pancreas and tumor labels. The Pancreatic Tumor
Segmentation on MR-Linac task 2 training set used 50 T2-weighted MR-Linac cases
with expert annotated pancreas and tumor labels. Algorithm-automated
segmentation performance of pancreatic tumor was assessed using Dice Similarity
Coefficient (DSC), 5 mm DSC, 95th percentile Hausdorff Distance (HD95), Mean
Average Surface Distance (MASD), and Root Mean Square Error (RMSE). For Task 1,
the algorithm achieved a DSC of 0.56, 5 mm DSC of 0.73, HD95 of 41.1 mm, MASD
of 26.0 mm, and RMSE of 5164 mm. For Task 2, performance decreased, with a DSC
of 0.33, 5 mm DSC of 0.50, HD95 of 20.1 mm, MASD of 7.2 mm, and RMSE of 17,203
mm. These findings illustrate the challenges of MRI-based pancreatic tumor
segmentation with small datasets, highlighting variability introduced by
different MRI sequences. Despite modest performance, the results demonstrate
potential for automated delineation and emphasize the need for larger,
standardized MRI datasets to improve model robustness and clinical utility.

</details>


### [42] [Reverse Imaging for Wide-spectrum Generalization of Cardiac MRI Segmentation](https://arxiv.org/abs/2508.21254)
*Yidong Zhao,Peter Kellman,Hui Xue,Tongyun Yang,Yi Zhang,Yuchi Han,Orlando Simonetti,Qian Tao*

Main category: cs.CV

TL;DR: 针对心脏MRI分割模型在不同成像序列间泛化能力差的问题，本文提出“逆向成像”方法，通过反向推断图像的底层自旋特性，实现跨对比度和协议的鲁棒分割。


<details>
  <summary>Details</summary>
Motivation: 预训练的心脏MRI分割模型由于成像协议导致的图像对比度显著差异，难以在不同成像序列之间泛化。然而，所有图像都受相同的基本自旋特性（质子密度、T1、T2值）支配。

Method: 引入“逆向成像”方法，这是一种物理驱动的数据增强和域适应技术。它通过解决由自旋特性先验分布正则化的病态非线性逆问题，从观察到的心脏MRI图像中反向推断底层自旋特性。自旋先验通过从多参数mSASHA数据集（提供T1和T2图）学习生成扩散模型获得。

Result: 该方法能够从MR图像中获得近似但有意义的自旋特性估计，这些估计提供了可解释的“潜在变量”，从而可以灵活地合成任意新序列图像。结果表明，“逆向成像”在各种不同的图像对比度和成像协议下都能实现高精度分割，实现了心脏MRI分割的广谱泛化。

Conclusion: “逆向成像”通过利用物理驱动的自旋特性推断，从根本上解决了心脏MRI分割模型的泛化问题，实现了在不同成像序列和协议下的高准确度分割，具有广泛的应用前景。

Abstract: Pretrained segmentation models for cardiac magnetic resonance imaging (MRI)
struggle to generalize across different imaging sequences due to significant
variations in image contrast. These variations arise from changes in imaging
protocols, yet the same fundamental spin properties, including proton density,
T1, and T2 values, govern all acquired images. With this core principle, we
introduce Reverse Imaging, a novel physics-driven method for cardiac MRI data
augmentation and domain adaptation to fundamentally solve the generalization
problem. Our method reversely infers the underlying spin properties from
observed cardiac MRI images, by solving ill-posed nonlinear inverse problems
regularized by the prior distribution of spin properties. We acquire this "spin
prior" by learning a generative diffusion model from the multiparametric
SAturation-recovery single-SHot acquisition sequence (mSASHA) dataset, which
offers joint cardiac T1 and T2 maps. Our method enables approximate but
meaningful spin-property estimates from MR images, which provide an
interpretable "latent variable" that lead to highly flexible image synthesis of
arbitrary novel sequences. We show that Reverse Imaging enables highly accurate
segmentation across vastly different image contrasts and imaging protocols,
realizing wide-spectrum generalization of cardiac MRI segmentation.

</details>


### [43] [PHD: Personalized 3D Human Body Fitting with Point Diffusion](https://arxiv.org/abs/2508.21257)
*Hsuan-I Ho,Chen Guo,Po-Chen Wu,Ivan Shugurov,Chengcheng Tang,Abhay Mittal,Sizhe An,Manuel Kaufmann,Linguang Zhang*

Main category: cs.CV

TL;DR: PHD是一种新颖的个性化3D人体网格恢复方法，它利用用户特定的身体形状和形状条件3D姿态先验来提高从视频中估计姿态的准确性，解决了传统方法过度依赖2D约束导致3D精度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的3D人体网格恢复(HMR)方法是用户无关的，旨在泛化，但通过过度依赖2D图像约束来细化姿态，导致在未能同时考虑个体身体形状和3D姿态合理性时，牺牲了3D精度。

Method: PHD方法首先校准用户的身体形状，然后基于该形状进行个性化的姿态拟合。它开发了一个身体形状条件的3D姿态先验，该先验被实现为一个点扩散Transformer，通过点蒸馏采样损失迭代地指导姿态拟合。该方法仅需合成数据进行训练，并且可以作为即插即用模块集成到现有3D姿态估计器中。

Result: PHD有效缓解了过度依赖2D约束导致的误差，不仅提高了骨盆对齐的姿态精度，还显著提高了通常被忽视的绝对姿态精度。此外，该方法数据效率高，且作为一个通用的即插即用模块，可以无缝集成以增强现有3D姿态估计器的性能。

Conclusion: PHD通过引入用户特定的形状信息和形状条件3D姿态先验，为个性化3D人体网格恢复提供了一种新颖且高效的方法，显著改善了3D姿态估计的准确性，特别是在绝对姿态精度方面，并解决了传统方法的局限性。

Abstract: We introduce PHD, a novel approach for personalized 3D human mesh recovery
(HMR) and body fitting that leverages user-specific shape information to
improve pose estimation accuracy from videos. Traditional HMR methods are
designed to be user-agnostic and optimized for generalization. While these
methods often refine poses using constraints derived from the 2D image to
improve alignment, this process compromises 3D accuracy by failing to jointly
account for person-specific body shapes and the plausibility of 3D poses. In
contrast, our pipeline decouples this process by first calibrating the user's
body shape and then employing a personalized pose fitting process conditioned
on that shape. To achieve this, we develop a body shape-conditioned 3D pose
prior, implemented as a Point Diffusion Transformer, which iteratively guides
the pose fitting via a Point Distillation Sampling loss. This learned 3D pose
prior effectively mitigates errors arising from an over-reliance on 2D
constraints. Consequently, our approach improves not only pelvis-aligned pose
accuracy but also absolute pose accuracy -- an important metric often
overlooked by prior work. Furthermore, our method is highly data-efficient,
requiring only synthetic data for training, and serves as a versatile
plug-and-play module that can be seamlessly integrated with existing 3D pose
estimators to enhance their performance. Project page:
https://phd-pose.github.io/

</details>


### [44] [Complete Gaussian Splats from a Single Image with Denoising Diffusion Models](https://arxiv.org/abs/2508.21542)
*Ziwei Liao,Mohamed Sayed,Steven L. Waslander,Sara Vicente,Daniyar Turmukhambetov,Michael Firman*

Main category: cs.CV

TL;DR: 该论文提出了一种基于潜在扩散模型的方法，仅通过单张图像即可重建包含遮挡区域的完整3D高斯场场景，解决了传统高斯场重建对密集观测的需求。


<details>
  <summary>Details</summary>
Motivation: 传统高斯场重建需要密集的场景观测，并且难以重建遮挡和未观测区域。现有方法通常采用回归方式预测单一“模式”，导致模糊、不真实，且无法捕捉多种可能的解释，限制了其在处理孤立物体、仅重建可见表面或远距离外推方面的能力。

Method: 本文提出了一种生成式方法，学习以单张输入图像为条件的高斯场3D表示分布。为解决缺乏真实训练数据的问题，作者引入了一个变分自重建器（Variational AutoReconstructor），以自监督方式仅从2D图像中学习一个潜在空间，并在此潜在空间上训练扩散模型。

Result: 该方法能够生成忠实的重建结果和多样化的样本，并具备完成遮挡表面以实现高质量360度渲染的能力。

Conclusion: 通过结合潜在扩散模型和自监督学习的变分自重建器，该研究成功实现了从单张图像重建包含遮挡区域的完整、高质量3D高斯场场景，克服了传统方法的局限性，并能生成多样化的场景解释。

Abstract: Gaussian splatting typically requires dense observations of the scene and can
fail to reconstruct occluded and unobserved areas. We propose a latent
diffusion model to reconstruct a complete 3D scene with Gaussian splats,
including the occluded parts, from only a single image during inference.
Completing the unobserved surfaces of a scene is challenging due to the
ambiguity of the plausible surfaces. Conventional methods use a
regression-based formulation to predict a single "mode" for occluded and
out-of-frustum surfaces, leading to blurriness, implausibility, and failure to
capture multiple possible explanations. Thus, they often address this problem
partially, focusing either on objects isolated from the background,
reconstructing only visible surfaces, or failing to extrapolate far from the
input views. In contrast, we propose a generative formulation to learn a
distribution of 3D representations of Gaussian splats conditioned on a single
input image. To address the lack of ground-truth training data, we propose a
Variational AutoReconstructor to learn a latent space only from 2D images in a
self-supervised manner, over which a diffusion model is trained. Our method
generates faithful reconstructions and diverse samples with the ability to
complete the occluded surfaces for high-quality 360-degree renderings.

</details>


### [45] [Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning](https://arxiv.org/abs/2508.21363)
*Yuquan Bi,Hongsong Wang,Xinli Shi,Zhipeng Gui,Jie Gui,Yuan Yan Tang*

Main category: cs.CV

TL;DR: 本文提出了一种名为分层时间剪枝（HTP）的高效扩散模型框架，用于3D人体姿态估计，通过在帧和语义级别剪枝冗余姿态token，显著降低了计算成本，同时保持了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成高保真3D人体姿态方面表现出色，但其迭代性质和多假设要求导致了巨大的计算成本。

Method: 该研究提出了一个带有分层时间剪枝（HTP）策略的高效扩散模型框架。HTP以分阶段、自上而下的方式运行：1) 帧间相关增强剪枝（TCEP）通过自适应时间图构建分析帧间运动相关性，识别关键帧；2) 稀疏聚焦时间MHSA（SFT MHSA）利用由此产生的帧级稀疏性减少注意力计算，专注于运动相关token；3) 掩码引导姿态token剪枝器（MGPTP）通过聚类进行细粒度语义剪枝，仅保留信息量最大的姿态token。

Result: 在Human3.6M和MPI-INF-3DHP数据集上的实验表明，与先前的基于扩散的方法相比，HTP将训练MACs减少了38.5%，推理MACs减少了56.8%，推理速度平均提高了81.1%，同时实现了最先进的性能。

Conclusion: 所提出的HTP框架能够显著提高扩散模型在3D人体姿态估计中的计算效率和推理速度，同时保持或超越了最先进的性能，解决了扩散模型计算成本高昂的问题。

Abstract: Diffusion models have demonstrated strong capabilities in generating
high-fidelity 3D human poses, yet their iterative nature and multi-hypothesis
requirements incur substantial computational cost. In this paper, we propose an
Efficient Diffusion-Based 3D Human Pose Estimation framework with a
Hierarchical Temporal Pruning (HTP) strategy, which dynamically prunes
redundant pose tokens across both frame and semantic levels while preserving
critical motion dynamics. HTP operates in a staged, top-down manner: (1)
Temporal Correlation-Enhanced Pruning (TCEP) identifies essential frames by
analyzing inter-frame motion correlations through adaptive temporal graph
construction; (2) Sparse-Focused Temporal MHSA (SFT MHSA) leverages the
resulting frame-level sparsity to reduce attention computation, focusing on
motion-relevant tokens; and (3) Mask-Guided Pose Token Pruner (MGPTP) performs
fine-grained semantic pruning via clustering, retaining only the most
informative pose tokens. Experiments on Human3.6M and MPI-INF-3DHP show that
HTP reduces training MACs by 38.5\%, inference MACs by 56.8\%, and improves
inference speed by an average of 81.1\% compared to prior diffusion-based
methods, while achieving state-of-the-art performance.

</details>


### [46] [Print2Volume: Generating Synthetic OCT-based 3D Fingerprint Volume from 2D Fingerprint Image](https://arxiv.org/abs/2508.21371)
*Qingran Miao,Haixia Wang,Haohao Sun,Yilong Zhang*

Main category: cs.CV

TL;DR: 该论文提出Print2Volume框架，通过三阶段方法从2D指纹图像生成逼真的合成3D OCT指纹数据，以解决真实OCT数据稀缺问题，并显著提升了指纹识别模型的性能。


<details>
  <summary>Details</summary>
Motivation: 高分辨率的3D OCT指纹数据能增强生物识别鲁棒性，但其采集成本高、耗时长，导致缺乏大规模公共数据集，严重阻碍了深度学习等先进算法的发展。

Method: 该研究引入了Print2Volume框架，包含三个顺序阶段：1) 2D风格迁移模块，将二值指纹转换为模拟OCT扫描Z轴平均投影的灰度图像；2) 3D结构扩展网络，将2D图像外推为合理的3D解剖体积；3) 基于3D GAN的OCT真实感细化器，为结构体积渲染真实的纹理、散斑噪声及其他成像特征。

Result: 使用Print2Volume生成了包含420,000个样本的大规模合成数据集。定量实验表明，合成数据质量高，对识别性能有显著影响。通过在合成数据上预训练识别模型，并在小型真实世界数据集上进行微调，在ZJUT-EIFD基准测试上，等错误率（EER）从15.62%显著降低至2.50%。

Conclusion: 该方法有效克服了数据稀缺性，显著提升了生物识别模型的性能，证明了其在解决OCT指纹数据不足方面的有效性。

Abstract: Optical Coherence Tomography (OCT) enables the acquisition of
high-resolution, three-dimensional fingerprint data, capturing rich subsurface
structures for robust biometric recognition. However, the high cost and
time-consuming nature of OCT data acquisition have led to a scarcity of
large-scale public datasets, significantly hindering the development of
advanced algorithms, particularly data-hungry deep learning models. To address
this critical bottleneck, this paper introduces Print2Volume, a novel framework
for generating realistic, synthetic OCT-based 3D fingerprints from 2D
fingerprint image. Our framework operates in three sequential stages: (1) a 2D
style transfer module that converts a binary fingerprint into a grayscale
images mimicking the style of a Z-direction mean-projected OCT scan; (2) a 3D
Structure Expansion Network that extrapolates the 2D im-age into a plausible 3D
anatomical volume; and (3) an OCT Realism Refiner, based on a 3D GAN, that
renders the structural volume with authentic textures, speckle noise, and other
imaging characteristics. Using Print2Volume, we generated a large-scale
synthetic dataset of 420,000 samples. Quantitative experiments demonstrate the
high quality of our synthetic data and its significant impact on recognition
performance. By pre-training a recognition model on our synthetic data and
fine-tuning it on a small real-world dataset, we achieved a remarkable
reduction in the Equal Error Rate (EER) from 15.62% to 2.50% on the ZJUT-EIFD
benchmark, proving the effectiveness of our approach in overcoming data
scarcity.

</details>


### [47] [GLENDA: Gynecologic Laparoscopy Endometriosis Dataset](https://arxiv.org/abs/2508.21398)
*Andreas Leibetseder,Sabrina Kletz,Klaus Schoeffmann,Simon Keckstein,Jörg Keckstein*

Main category: cs.CV

TL;DR: 本文发布了GLENDA数据集，这是一个包含子宫内膜异位症区域标注的妇科腹腔镜图像数据集，旨在解决医学领域计算机视觉和机器学习方法中数据稀缺的问题，以改进手术视频的自动化分析。


<details>
  <summary>Details</summary>
Motivation: 妇科腹腔镜手术视频的手动分析耗时且繁琐。为了改进这一现状，需要开发更先进的计算机视觉和机器学习方法。然而，这些方法严重依赖样本数据，而医学领域的数据通常非常稀缺。

Method: 本文通过与医学专家合作，创建并发布了妇科腹腔镜子宫内膜异位症数据集（GLENDA）。该数据集包含子宫内膜异位症（一种常见疾病）的区域性标注图像。

Result: 发布了GLENDA数据集，这是首个包含子宫内膜异位症区域标注的妇科腹腔镜图像数据集。该数据集的创建得到了该领域领先医学专家的协作。

Conclusion: GLENDA数据集的发布填补了医学领域妇科腹腔镜子宫内膜异位症标注数据稀缺的空白，为开发用于治疗计划、病例记录和教育等术后活动的自动化计算机视觉和机器学习方法提供了基础。

Abstract: Gynecologic laparoscopy as a type of minimally invasive surgery (MIS) is
performed via a live feed of a patient's abdomen surveying the insertion and
handling of various instruments for conducting treatment. Adopting this kind of
surgical intervention not only facilitates a great variety of treatments, the
possibility of recording said video streams is as well essential for numerous
post-surgical activities, such as treatment planning, case documentation and
education. Nonetheless, the process of manually analyzing surgical recordings,
as it is carried out in current practice, usually proves tediously
time-consuming. In order to improve upon this situation, more sophisticated
computer vision as well as machine learning approaches are actively developed.
Since most of such approaches heavily rely on sample data, which especially in
the medical field is only sparsely available, with this work we publish the
Gynecologic Laparoscopy ENdometriosis DAtaset (GLENDA) - an image dataset
containing region-based annotations of a common medical condition named
endometriosis, i.e. the dislocation of uterine-like tissue. The dataset is the
first of its kind and it has been created in collaboration with leading medical
experts in the field.

</details>


### [48] [Identifying Surgical Instruments in Laparoscopy Using Deep Learning Instance Segmentation](https://arxiv.org/abs/2508.21399)
*Sabrina Kletz,Klaus Schoeffmann,Jenny Benois-Pineau,Heinrich Husslein*

Main category: cs.CV

TL;DR: 本研究使用区域全卷积网络 (FCN) 对妇科腹腔镜手术视频中的手术器械进行实例分割和识别，发现器械定位和分割精度较高，但器械类型识别仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 手术视频是医疗内窥镜领域日益重要的信息源，但自动内容索引（医学视频档案中基于内容搜索的基础）因其特殊内容而极具挑战性。尽管视频录制已变得简单，但对手术器械的自动识别和分割仍是一个难题。

Method: 本研究采用区域全卷积网络 (FCN) 来实现实例感知的手术器械分割和识别。具体方法包括：1) 器械的二元分割（区分器械与背景），2) 器械的多类别识别（识别器械类型）。

Result: 评估结果表明，即使训练样本数量适中，也能以相当高的精度定位和分割器械区域。然而，结果也揭示，由于手术器械固有的高度相似性，确定特定器械类型仍然非常具有挑战性。

Conclusion: 区域全卷积网络在妇科腹腔镜手术视频中对手术器械的定位和分割表现出较高的准确性。尽管如此，由于器械之间的高度相似性，精确识别具体器械类型仍然是一个亟待解决的难题。

Abstract: Recorded videos from surgeries have become an increasingly important
information source for the field of medical endoscopy, since the recorded
footage shows every single detail of the surgery. However, while video
recording is straightforward these days, automatic content indexing - the basis
for content-based search in a medical video archive - is still a great
challenge due to the very special video content. In this work, we investigate
segmentation and recognition of surgical instruments in videos recorded from
laparoscopic gynecology. More precisely, we evaluate the achievable performance
of segmenting surgical instruments from their background by using a
region-based fully convolutional network for instance-aware (1) instrument
segmentation as well as (2) instrument recognition. While the first part
addresses only binary segmentation of instances (i.e., distinguishing between
instrument or background) we also investigate multi-class instrument
recognition (i.e., identifying the type of instrument). Our evaluation results
show that even with a moderately low number of training examples, we are able
to localize and segment instrument regions with a pretty high accuracy.
However, the results also reveal that determining the particular instrument is
still very challenging, due to the inherently high similarity of surgical
instruments.

</details>


### [49] [SatDINO: A Deep Dive into Self-Supervised Pretraining for Remote Sensing](https://arxiv.org/abs/2508.21402)
*Jakub Straka,Ivan Gruber*

Main category: cs.CV

TL;DR: 本文提出了SatDINO，一个基于DINO的自监督学习模型，用于遥感图像的表示学习。SatDINO在多个基准测试中超越了基于掩码自编码器(MAE)的SOTA方法，并取得了有竞争力的结果，同时引入了GSD编码和自适应视图采样等新颖增强。


<details>
  <summary>Details</summary>
Motivation: 遥感领域存在大量未标注数据，自监督学习是处理这些数据的强大工具。研究旨在为卫星图像开发一种更有效的预训练方法。

Method: 研究了DINO（一种对比自监督方法）在遥感图像预训练中的应用，并引入了为卫星图像表示学习量身定制的SatDINO模型。通过在多个数据集和测试设置上进行大量实验，并进行了严格的消融研究，评估了SatDINO的各个组件。此外，提出了包括GSD编码和自适应视图采样在内的新颖增强。

Result: SatDINO在多个基准测试中超越了其他基于掩码自编码器（MAE）的SOTA方法，并取得了有竞争力的结果。消融研究验证了SatDINO各个组件的有效性。提出的新颖增强（如GSD编码和自适应视图采样）可以独立应用于SatDINO模型。

Conclusion: SatDINO是一个在遥感图像表示学习中表现卓越的自监督预训练模型，其性能优于当前流行的MAE方法，并且通过引入新颖增强进一步提升了效果。

Abstract: Self-supervised learning has emerged as a powerful tool for remote sensing,
where large amounts of unlabeled data are available. In this work, we
investigate the use of DINO, a contrastive self-supervised method, for
pretraining on remote sensing imagery. We introduce SatDINO, a model tailored
for representation learning in satellite imagery. Through extensive experiments
on multiple datasets in multiple testing setups, we demonstrate that SatDINO
outperforms other state-of-the-art methods based on much more common masked
autoencoders (MAE) and achieves competitive results in multiple benchmarks.
  We also provide a rigorous ablation study evaluating SatDINO's individual
components. Finally, we propose a few novel enhancements, such as a new way to
incorporate ground sample distance (GSD) encoding and adaptive view sampling.
These enhancements can be used independently on our SatDINO model. Our code and
trained models are available at: https://github.com/strakaj/SatDINO.

</details>


### [50] [Standardized Multi-Layer Tissue Maps for Enhanced Artificial Intelligence Integration and Search in Large-Scale Whole Slide Image Archives](https://arxiv.org/abs/2508.21418)
*Gernot Fiala,Markus Plass,Robert Harb,Peter Regitnig,Kristijan Skok,Wael Al Zoughbi,Carmen Zerner,Paul Torke,Michaela Kargl,Heimo Müller,Tomas Brazdil,Matej Gallo,Jaroslav Kubín,Roman Stoklasa,Rudolf Nenutil,Norman Zerbe,Andreas Holzinger,Petr Holub*

Main category: cs.CV

TL;DR: 本文提出了一种通用的框架，用于生成全玻片图像（WSI）的2D索引图和特定应用领域的分析机制，以解决WSI内容元数据标准化缺失和人工检查效率低下的问题，尤其是在临床病理学中。


<details>
  <summary>Details</summary>
Motivation: 全玻片图像（WSI）广泛应用于诊断和研究，尤其在AI算法开发中。然而，在为AI算法训练或验证组建队列时，缺乏关于WSI内容的标准元数据。目前主要通过人工检查来筛选WSI，这对于数百万对象的庞大集合来说效率低下且不适用。

Method: 研究者提出了一种通用框架，用于生成WSI的2D索引图，并为特定应用领域提供分析机制。该方法通过详细的组织图增强每个WSI集合，提供细粒度的WSI内容信息。组织图分为三层：来源、组织类型和病理改变，每层将WSI的不同区域分配给特定类别。该方法在临床病理学领域进行了演示，使用通用语法和语义实现不同目录间的互操作性。

Result: 该方法成功为WSI集合提供了详细的组织图，该组织图包含三层（来源、组织类型、病理改变），能够将WSI的不同区域分配到特定类别，从而提供细粒度的内容信息。通过使用通用语法和语义，实现了不同目录间的互操作性。

Conclusion: 所提出的标准框架在WSI目录、机器学习和基于图的WSI表示中具有显著的优势和广泛的适用性，能够有效解决WSI内容元数据标准化和大规模数据处理的挑战。

Abstract: A Whole Slide Image (WSI) is a high-resolution digital image created by
scanning an entire glass slide containing a biological specimen, such as tissue
sections or cell samples, at multiple magnifications. These images can be
viewed, analyzed, shared digitally, and are used today for Artificial
Intelligence (AI) algorithm development. WSIs are used in a variety of fields,
including pathology for diagnosing diseases and oncology for cancer research.
They are also utilized in neurology, veterinary medicine, hematology,
microbiology, dermatology, pharmacology, toxicology, immunology, and forensic
science.
  When assembling cohorts for the training or validation of an AI algorithm, it
is essential to know what is present on such a WSI. However, there is currently
no standard for this metadata, so such selection has mainly been done through
manual inspection, which is not suitable for large collections with several
million objects.
  We propose a general framework to generate a 2D index map for WSI and a
profiling mechanism for specific application domains. We demonstrate this
approach in the field of clinical pathology, using common syntax and semantics
to achieve interoperability between different catalogs.
  Our approach augments each WSI collection with a detailed tissue map that
provides fine-grained information about the WSI content. The tissue map is
organized into three layers: source, tissue type, and pathological alterations,
with each layer assigning segments of the WSI to specific classes.
  We illustrate the advantages and applicability of the proposed standard
through specific examples in WSI catalogs, Machine Learning (ML), and
graph-based WSI representations.

</details>


### [51] [Unsupervised Incremental Learning Using Confidence-Based Pseudo-Labels](https://arxiv.org/abs/2508.21424)
*Lucas Rakotoarivony*

Main category: cs.CV

TL;DR: 本文提出了一种名为ICPL的无监督增量学习方法，通过置信度伪标签取代人工标注，使模型能从无标签数据中增量学习新类别，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的类增量学习（CIL）方法假设增量数据集是完全标注的，这在实际应用中是不现实的。研究动机是开发一种能够从无标签数据中增量学习新知识的方法。

Method: 该研究提出了一种基于置信度伪标签（Confidence-based Pseudo-labels）的无监督增量学习方法（ICPL）。它用伪标签替代了人工标注，并将其集成到各种CIL方法中，同时采用基于置信度的选择机制。方法在CIFAR100和ImageNet100数据集上评估了性能下降，并与流行的类增量新类别发现（class-iNCD）方法进行了比较。此外，还在细粒度数据集上进行了应用，并测量了计算复杂度。

Result: ICPL方法与有监督方法相比取得了有竞争力的结果，并且在最终准确率上比最先进的class-iNCD方法高出5%以上。该方法在实际场景中具有实用性，并且其计算复杂度表明它适用于资源受限的环境。

Conclusion: ICPL提供了一种有效且实用的解决方案，使模型能够从无标签数据中进行无监督增量学习，克服了传统CIL方法对完全标注数据的依赖，并在性能上超越了现有的一些先进方法，尤其适用于资源受限的真实世界场景。

Abstract: Deep learning models have achieved state-of-the-art performance in many
computer vision tasks. However, in real-world scenarios, novel classes that
were unseen during training often emerge, requiring models to acquire new
knowledge incrementally. Class-Incremental Learning (CIL) methods enable a
model to learn novel classes while retaining knowledge of previous classes.
However, these methods make the strong assumption that the incremental dataset
is fully labeled, which is unrealistic in practice. In this work, we propose an
unsupervised Incremental Learning method using Confidence-based Pseudo-labels
(ICPL), which replaces human annotations with pseudo-labels, enabling
incremental learning from unlabeled datasets. We integrate these pseudo-labels
into various CIL methods with confidence-based selection and evaluate
performance degradation on CIFAR100 and ImageNet100. Then, we compare our
approach to popular Class Incremental Novel Category Discovery (class-iNCD)
methods addressing similar challenges. Additionally, we apply our method to
fine-grained datasets to demonstrate its real-world practicality and measure
its computational complexity to validate its suitability for
resource-constrained environments. ICPL achieves competitive results compared
to supervised methods and outperforms state-of-the-art class-iNCD methods by
more than 5% in final accuracy.

</details>


### [52] [MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation](https://arxiv.org/abs/2508.21435)
*Francisco Caetano,Christiaan Viviers,Peter H. H. de With,Fons van der Sommen*

Main category: cs.CV

TL;DR: 该论文提出了MedShift，一个基于Flow Matching和Schrodinger Bridges的类条件生成模型，用于合成与真实X射线图像之间的高保真、无配对的跨域转换，有效弥合了领域差距，并提供了灵活的性能调整。


<details>
  <summary>Details</summary>
Motivation: 合成医疗数据在训练鲁棒模型方面具有可扩展性，但其与真实临床环境之间存在显著的领域差距（如衰减行为、噪声特征和软组织表示），限制了其泛化能力。本研究旨在解决合成与真实头部X射线图像之间的跨域转换挑战，以弥合这些差异。

Method: 本文提出了MedShift，一个统一的类条件生成模型，基于Flow Matching和Schrodinger Bridges。该模型能够实现高保真、无配对的多域图像转换，学习共享的领域无关潜在空间，并支持训练期间任何域对之间的无缝转换。此外，还引入了新的数据集X-DigiSkull，包含不同辐射剂量下的对齐合成和真实颅骨X射线图像，用于基准测试。

Result: 实验结果表明，尽管MedShift的模型尺寸小于基于扩散的方法，但它仍能提供强大的性能，并在推理时保持灵活性，可以根据需求优先考虑感知保真度或结构一致性。这使其成为医学图像领域适应的一种可扩展和可泛化的解决方案。

Conclusion: MedShift提供了一种可扩展且可泛化的解决方案，用于医学成像中的领域适应，通过其高效的跨域转换能力，有效弥合了合成与真实X射线数据之间的差距，并能根据应用需求调整输出质量。

Abstract: Synthetic medical data offers a scalable solution for training robust models,
but significant domain gaps limit its generalizability to real-world clinical
settings. This paper addresses the challenge of cross-domain translation
between synthetic and real X-ray images of the head, focusing on bridging
discrepancies in attenuation behavior, noise characteristics, and soft tissue
representation. We propose MedShift, a unified class-conditional generative
model based on Flow Matching and Schrodinger Bridges, which enables
high-fidelity, unpaired image translation across multiple domains. Unlike prior
approaches that require domain-specific training or rely on paired data,
MedShift learns a shared domain-agnostic latent space and supports seamless
translation between any pair of domains seen during training. We introduce
X-DigiSkull, a new dataset comprising aligned synthetic and real skull X-rays
under varying radiation doses, to benchmark domain translation models.
Experimental results demonstrate that, despite its smaller model size compared
to diffusion-based approaches, MedShift offers strong performance and remains
flexible at inference time, as it can be tuned to prioritize either perceptual
fidelity or structural consistency, making it a scalable and generalizable
solution for domain adaptation in medical imaging. The code and dataset are
available at https://caetas.github.io/medshift.html

</details>


### [53] [ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding](https://arxiv.org/abs/2508.21496)
*Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu*

Main category: cs.CV

TL;DR: 本研究引入了ELV-Halluc，首个针对长视频幻觉的基准，专注于调查“语义聚合幻觉”（SAH），发现SAH随语义复杂性增加，并提出了通过位置编码和DPO策略缓解SAH的方法，实现了显著的SAH降低。


<details>
  <summary>Details</summary>
Motivation: 视频多模态大语言模型（Video-MLLMs）在视频理解方面表现出色，但仍易产生与视频内容不符的幻觉。现有幻觉基准主要关注短视频，并简化了幻觉原因。然而，模型有时会生成帧级语义正确但事件级语义错误的输出，即语义聚合幻觉（SAH），这在语义复杂性更高的长视频中尤为关键，需要被独立研究。

Method: 本研究引入了ELV-Halluc，这是首个专门用于长视频幻觉的基准，以系统性地调查SAH。通过实验确认SAH的存在及其特性。此外，研究探讨了缓解SAH的潜在方法，包括采用位置编码策略，并进一步使用DPO（Direct Preference Optimization）策略来增强模型区分事件内外语义的能力。为此，作者还整理了一个包含8K对抗性数据对的数据集。

Result: 实验证实了SAH的存在，并发现其随语义复杂性增加而加剧。模型在语义快速变化的视频上更容易产生SAH。研究表明，位置编码策略有助于缓解SAH，而DPO策略进一步增强了模型区分语义的能力。通过所提出的方法，在ELV-Halluc和Video-MME上均取得了改进，其中SAH率显著降低了27.7%。

Conclusion: 语义聚合幻觉（SAH）是Video-MLLMs在长视频理解中特有且关键的幻觉类型。ELV-Halluc基准能够系统地研究SAH。通过采用位置编码和DPO策略并结合对抗性数据训练，可以有效缓解SAH，显著提升模型在长视频中的语义理解和一致性。

Abstract: Video multimodal large language models (Video-MLLMs) have achieved remarkable
progress in video understanding. However, they remain vulnerable to
hallucination-producing content inconsistent with or unrelated to video inputs.
Previous video hallucination benchmarks primarily focus on short-videos. They
attribute hallucinations to factors such as strong language priors, missing
frames, or vision-language biases introduced by the visual encoder. While these
causes indeed account for most hallucinations in short videos, they still
oversimplify the cause of hallucinations. Sometimes, models generate incorrect
outputs but with correct frame-level semantics. We refer to this type of
hallucination as Semantic Aggregation Hallucination (SAH), which arises during
the process of aggregating frame-level semantics into event-level semantic
groups. Given that SAH becomes particularly critical in long videos due to
increased semantic complexity across multiple events, it is essential to
separate and thoroughly investigate the causes of this type of hallucination.
To address the above issues, we introduce ELV-Halluc, the first benchmark
dedicated to long-video hallucination, enabling a systematic investigation of
SAH. Our experiments confirm the existence of SAH and show that it increases
with semantic complexity. Additionally, we find that models are more prone to
SAH on rapidly changing semantics. Moreover, we discuss potential approaches to
mitigate SAH. We demonstrate that positional encoding strategy contributes to
alleviating SAH, and further adopt DPO strategy to enhance the model's ability
to distinguish semantics within and across events. To support this, we curate a
dataset of 8K adversarial data pairs and achieve improvements on both
ELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio.

</details>


### [54] [Trees as Gaussians: Large-Scale Individual Tree Mapping](https://arxiv.org/abs/2508.21437)
*Dimitri Gominski,Martin Brandt,Xiaoye Tong,Siyu Liu,Maurice Mugabowindekwe,Sizhuo Li,Florian Reiner,Andrew Davies,Rasmus Fensholt*

Main category: cs.CV

TL;DR: 本研究提出了一种深度学习方法，利用3米分辨率的PlanetScope影像在全球范围内检测大型单棵树，并通过模拟树冠和使用大量激光雷达数据进行训练，实现了高精度和可扩展的树木监测。


<details>
  <summary>Details</summary>
Motivation: 树木是地球生物圈的关键组成部分，但在生态系统功能、气候调节和生物经济中的作用监测受限于现有模型。现有全球产品仅关注二元树木覆盖或冠层高度，无法明确识别单棵树木。

Method: 采用深度学习方法，利用3米分辨率的PlanetScope影像进行全球范围内的单棵树检测。通过可伸缩高斯核模拟树冠以提取冠心并生成二元树木覆盖图。训练数据来源于从机载激光雷达数据中自动提取的数十亿个点，使模型能够识别森林内外的树木。

Result: 与现有树木覆盖图和机载激光雷达数据相比，该方法表现出最先进的性能（分数覆盖率R²=0.81）。在不同生物群系中报告了平衡的检测指标，并证明通过手动标签进行微调可以进一步提高检测效果。

Conclusion: 本研究提供了一个可扩展的框架，用于全球高分辨率的树木监测，并可适应未来提供改进影像的卫星任务。

Abstract: Trees are key components of the terrestrial biosphere, playing vital roles in
ecosystem function, climate regulation, and the bioeconomy. However,
large-scale monitoring of individual trees remains limited by inadequate
modelling. Available global products have focused on binary tree cover or
canopy height, which do not explicitely identify trees at individual level. In
this study, we present a deep learning approach for detecting large individual
trees in 3-m resolution PlanetScope imagery at a global scale. We simulate tree
crowns with Gaussian kernels of scalable size, allowing the extraction of crown
centers and the generation of binary tree cover maps. Training is based on
billions of points automatically extracted from airborne lidar data, enabling
the model to successfully identify trees both inside and outside forests. We
compare against existing tree cover maps and airborne lidar with
state-of-the-art performance (fractional cover R$^2 = 0.81$ against aerial
lidar), report balanced detection metrics across biomes, and demonstrate how
detection can be further improved through fine-tuning with manual labels. Our
method offers a scalable framework for global, high-resolution tree monitoring,
and is adaptable to future satellite missions offering improved imagery.

</details>


### [55] [EZ-Sort: Efficient Pairwise Comparison via Zero-Shot CLIP-Based Pre-Ordering and Human-in-the-Loop Sorting](https://arxiv.org/abs/2508.21550)
*Yujin Park,Haejun Chung,Ikbeom Jang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为EZ-Sort的 pairwise 排序方法，通过结合CLIP模型进行零样本预排序和不确定性引导的人机协作MergeSort，显著降低了主观标注任务中的人工标注成本，同时保持或提高了可靠性。


<details>
  <summary>Details</summary>
Motivation: 在主观或困难的标注任务中，pairwise 比较因其更高的可靠性而优于绝对评分。然而，穷举比较需要大量的标注（O(n^2)）。尽管现有工作通过主动采样将标注负担降低到O(n log n)，但仍有进一步提高标注效率的需求。

Method: 所提出的EZ-Sort方法通过以下方式提高效率：1) 使用预训练的Contrastive Language-Image Pre-training (CLIP) 模型进行无训练的分层粗略预排序；2) 用自动化比较取代简单、明显的人工比较；3) 初始化桶感知Elo分数；4) 运行不确定性引导的人机协作MergeSort。该方法首先生成基于CLIP的零样本预排序，然后进行后续步骤。

Result: 在FGNET（人脸年龄估计）、DHCI（历史图像年代学）和EyePACS（视网膜图像质量评估）数据集上的验证结果显示，EZ-Sort与穷举pairwise比较相比，人工标注成本降低了90.5%；与现有工作相比（当n=100时），标注成本降低了19.8%，同时改善或保持了评估者间的一致性。

Conclusion: 结合基于CLIP的先验知识与不确定性感知的采样策略，为pairwise排序提供了一种高效且可扩展的解决方案。

Abstract: Pairwise comparison is often favored over absolute rating or ordinal
classification in subjective or difficult annotation tasks due to its improved
reliability. However, exhaustive comparisons require a massive number of
annotations (O(n^2)). Recent work has greatly reduced the annotation burden
(O(n log n)) by actively sampling pairwise comparisons using a sorting
algorithm. We further improve annotation efficiency by (1) roughly pre-ordering
items using the Contrastive Language-Image Pre-training (CLIP) model
hierarchically without training, and (2) replacing easy, obvious human
comparisons with automated comparisons. The proposed EZ-Sort first produces a
CLIP-based zero-shot pre-ordering, then initializes bucket-aware Elo scores,
and finally runs an uncertainty-guided human-in-the-loop MergeSort. Validation
was conducted using various datasets: face-age estimation (FGNET), historical
image chronology (DHCI), and retinal image quality assessment (EyePACS). It
showed that EZ-Sort reduced human annotation cost by 90.5% compared to
exhaustive pairwise comparisons and by 19.8% compared to prior work (when n =
100), while improving or maintaining inter-rater reliability. These results
demonstrate that combining CLIP-based priors with uncertainty-aware sampling
yields an efficient and scalable solution for pairwise ranking.

</details>


### [56] [Scale-GS: Efficient Scalable Gaussian Splatting via Redundancy-filtering Training on Streaming Content](https://arxiv.org/abs/2508.21444)
*Jiayu Yang,Weijian Su,Songqian Zhang,Yuqi Han,Jinli Suo,Qiang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为M-GS的可扩展高斯溅射（3DGS）框架，旨在解决动态场景下3DGS数据量大和训练时间长的问题，通过分层结构、混合形变与生成策略以及双向自适应掩码机制，实现了高效训练和高质量渲染。


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting (3DGS) 在沉浸式应用中实现了高保真实时渲染，但将其扩展到动态场景时，面临高斯点数据量庞大以及每帧训练时间过长的限制。

Method: 本文提出了M-GS框架：1) 高斯球体在基于锚点的结构中按比例分层组织，粗级别高斯表示场景低分辨率结构，细级别高斯负责高保真渲染并由粗级别高斯选择性激活。2) 引入混合形变与生成策略，通过高斯形变建模帧间运动，并通过高斯生成来表征大范围运动。3) 采用双向自适应掩码机制，通过移除静态区域和优先处理信息丰富的视角来提高训练效率。

Result: M-GS在实现卓越视觉质量的同时，与现有最先进方法相比，显著减少了训练时间。

Conclusion: M-GS框架为动态场景下的高斯溅射提供了一种可扩展且高效的解决方案，有效解决了数据量和训练时间瓶颈，并取得了优异的视觉效果。

Abstract: 3D Gaussian Splatting (3DGS) enables high-fidelity real-time rendering, a key
requirement for immersive applications. However, the extension of 3DGS to
dynamic scenes remains limitations on the substantial data volume of dense
Gaussians and the prolonged training time required for each frame. This paper
presents \M, a scalable Gaussian Splatting framework designed for efficient
training in streaming tasks. Specifically, Gaussian spheres are hierarchically
organized by scale within an anchor-based structure. Coarser-level Gaussians
represent the low-resolution structure of the scene, while finer-level
Gaussians, responsible for detailed high-fidelity rendering, are selectively
activated by the coarser-level Gaussians. To further reduce computational
overhead, we introduce a hybrid deformation and spawning strategy that models
motion of inter-frame through Gaussian deformation and triggers Gaussian
spawning to characterize wide-range motion. Additionally, a bidirectional
adaptive masking mechanism enhances training efficiency by removing static
regions and prioritizing informative viewpoints. Extensive experiments
demonstrate that \M~ achieves superior visual quality while significantly
reducing training time compared to state-of-the-art methods.

</details>


### [57] [Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR](https://arxiv.org/abs/2508.21693)
*Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora*

Main category: cs.CV

TL;DR: 本文提出了一种行级光学字符识别（OCR）方法，以解决传统词级OCR中词分割错误的问题，并提供更大的上下文来利用语言模型，从而显著提高准确性和效率。此外，还贡献了一个包含行级标注的新数据集。


<details>
  <summary>Details</summary>
Motivation: 传统的OCR技术容易出现字符分割错误且缺乏上下文。现代OCR虽然解决了字符分割问题，但将瓶颈转移到了词分割上。为了规避词分割错误并提供更大的句子上下文以更好地利用语言模型，研究者提出从词级OCR向行级OCR的自然演进。

Method: 提出了一种从词级OCR到行级OCR的逻辑演进方法，以绕过词检测错误并提供更大的句子上下文。为此，还创建了一个包含251张带有行级标注的英文页面图像的精心策划的数据集，用于训练和基准测试。

Result: 实验结果显示，所提出的技术不仅将端到端准确率提高了5.4%，而且与基于词的管道相比，效率提高了4倍，尤其适用于文档图像。该方法还具有利用大型语言模型持续改进的潜力。

Conclusion: 行级OCR是OCR技术的一个有前景的自然发展方向，能够显著提高准确性和效率，特别是在文档图像处理中。通过提供更大的上下文，它能更好地利用语言模型，并且随着大型语言模型的进步，其潜力将进一步增强。所贡献的数据集将有助于推动该领域的研究。

Abstract: Conventional optical character recognition (OCR) techniques segmented each
character and then recognized. This made them prone to error in character
segmentation, and devoid of context to exploit language models. Advances in
sequence to sequence translation in last decade led to modern techniques first
detecting words and then inputting one word at a time to a model to directly
output full words as sequence of characters. This allowed better utilization of
language models and bypass error-prone character segmentation step. We observe
that the above transition in style has moved the bottleneck in accuracy to word
segmentation. Hence, in this paper, we propose a natural and logical
progression from word level OCR to line-level OCR. The proposal allows to
bypass errors in word detection, and provides larger sentence context for
better utilization of language models. We show that the proposed technique not
only improves the accuracy but also efficiency of OCR. Despite our thorough
literature survey, we did not find any public dataset to train and benchmark
such shift from word to line-level OCR. Hence, we also contribute a
meticulously curated dataset of 251 English page images with line-level
annotations. Our experimentation revealed a notable end-to-end accuracy
improvement of 5.4%, underscoring the potential benefits of transitioning
towards line-level OCR, especially for document images. We also report a 4
times improvement in efficiency compared to word-based pipelines. With
continuous improvements in large language models, our methodology also holds
potential to exploit such advances. Project Website:
https://nishitanand.github.io/line-level-ocr-website

</details>


### [58] [One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist](https://arxiv.org/abs/2508.21451)
*Junha Song,Yongsik Jo,So Yeon Min,Quanting Xie,Taehwan Kim,Yonatan Bisk,Jaegul Choo*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级图像字幕专家模型，其性能可与大型多模态通用模型媲美，解决了设备端部署的计算挑战。针对模型存在的“视觉盲区”问题，通过分析其根本原因并开发了名为“锐眼细化”（Sharp-Eyed Refinement）的新框架，显著提升了视觉接地能力和字幕质量。


<details>
  <summary>Details</summary>
Motivation: 由于多模态大型语言模型（MLLMs）计算需求高，在本地设备上部署图像字幕模型极具挑战性。研究旨在探索轻量级解决方案，以实现设备端高效的图像字幕生成。

Method: 首先，实现了一个基于1.25亿参数语言模型的轻量级专家模型（比LLaMA-7B小56倍），并评估了其在单句和详细字幕任务上的表现。其次，通过玩具实验调查了模型视觉盲区（语义字幕错误）的根本原因，发现问题源于注意力机制效率低下和视觉表征有限。最后，开发了一种名为“锐眼细化”（Sharp-Eyed Refinement）的新型字幕框架，其核心是DeepLens模块，通过关注初始识别的信息区域来提取详细的视觉表征，从而增强视觉接地能力。

Result: 研究发现，所提出的轻量级模型能够实现与大型多模态通用模型相当的性能，显示了其作为设备端视觉专家的潜力。尽管如此，模型也表现出视觉盲区，导致语义字幕错误。实验确认这些问题源于注意力机制的低效和视觉表征的局限性。新开发的“锐眼细化”框架和DeepLens模块有效提升了字幕质量，并且该专家模型优于先前的轻量级字幕模型和大型通用模型，证明了框架的有效性。

Conclusion: 轻量级专家模型在设备端图像字幕应用中具有巨大潜力，其性能可与大型通用模型媲美。虽然存在视觉盲区，但通过深入分析其原因并开发“锐眼细化”框架，可以有效解决注意力机制和视觉表征的局限性，显著提升视觉接地能力和字幕质量。

Abstract: Image captioning is fundamental for applications like video instruction
systems and exploration robots, yet deploying such models on local devices is
challenging due to the high computational demands of multimodal large language
models (MLLMs). To address this, we first explore lightweight captioning by
implementing a specialist based on a 125M-parameter language model, 56 times
smaller than LLaMA-7B, and evaluating its performance on both single-sentence
and detailed captioning tasks. Surprisingly, we find that our model can achieve
performance comparable to large multimodal generalists, suggesting its
potential to serve as a strong visual specialist for on-device applications.
While promising, our model also exhibits a limitation: like other MLLMs, it
suffers from visual blindness, occasionally resulting in semantic captioning
errors. We carry out toy experiments and investigate the underlying causes,
where we observe that the problems arise from ineffective attention mechanisms
and limited visual representations. To alleviate them, we develop a novel
captioning framework, Sharp-Eyed Refinement, which enhances caption quality
through improved visual grounding. At its core, our DeepLens extracts detailed
visual representations by concentrating on informative regions identified
during the initial glance. Our experiments confirm both the advantages of our
specialist over prior small captioning models and large generalists and the
effectiveness of our framework.

</details>


### [59] [CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models](https://arxiv.org/abs/2508.21732)
*João Valente,Atabak Dehban,Rodrigo Ventura*

Main category: cs.CV

TL;DR: 该研究引入了CAD2DMD-SET工具，用于生成合成数据以训练大型视觉-语言模型（LVLMs）从数字测量设备（DMDs）中读取数值，并在真实世界挑战下显著提高了LVLMs的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉-语言模型（LVLMs）在多模态任务中表现出色，但它们在读取数字测量设备（DMDs）的简单场景中仍面临困难，尤其是在真实世界中常见的杂乱、遮挡、极端视角和运动模糊等挑战性条件下，这些在头戴式相机和增强现实（AR）应用中尤为普遍。

Method: 本研究引入了CAD2DMD-SET，一个利用3D CAD模型、高级渲染和高保真图像合成技术，生成用于DMD相关视觉问答（VQA）任务的合成VQA标注数据集的工具。此外，还提出了DMDBench，一个包含1,000张真实世界标注图像的验证集，用于评估模型在实际约束下的性能。研究通过使用平均归一化莱文斯坦相似度（ANLS）基准测试了三个最先进的LVLMs，并使用CAD2DMD-SET生成的数据集对这些模型的LoRA进行了微调。

Result: 使用CAD2DMD-SET生成的数据集对模型进行微调后，LVLMs的性能得到了显著提升。例如，InternVL的得分提高了200%，且未在其他任务上出现性能下降。这表明CAD2DMD-SET训练数据集显著提高了LVLMs在先前所述的挑战性条件下操作时的鲁棒性和性能。

Conclusion: CAD2DMD-SET训练数据集能够显著提高大型视觉-语言模型在处理数字测量设备相关任务时，面对复杂真实世界条件（如杂乱、遮挡、极端视角和运动模糊）时的鲁棒性和性能。该工具预计将开源，以促进社区扩展和生成更多数据集。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated
impressive capabilities across various multimodal tasks. They continue,
however, to struggle with trivial scenarios such as reading values from Digital
Measurement Devices (DMDs), particularly in real-world conditions involving
clutter, occlusions, extreme viewpoints, and motion blur; common in
head-mounted cameras and Augmented Reality (AR) applications. Motivated by
these limitations, this work introduces CAD2DMD-SET, a synthetic data
generation tool designed to support visual question answering (VQA) tasks
involving DMDs. By leveraging 3D CAD models, advanced rendering, and
high-fidelity image composition, our tool produces diverse, VQA-labelled
synthetic DMD datasets suitable for fine-tuning LVLMs. Additionally, we present
DMDBench, a curated validation set of 1,000 annotated real-world images
designed to evaluate model performance under practical constraints.
Benchmarking three state-of-the-art LVLMs using Average Normalised Levenshtein
Similarity (ANLS) and further fine-tuning LoRA's of these models with
CAD2DMD-SET's generated dataset yielded substantial improvements, with InternVL
showcasing a score increase of 200% without degrading on other tasks. This
demonstrates that the CAD2DMD-SET training dataset substantially improves the
robustness and performance of LVLMs when operating under the previously stated
challenging conditions. The CAD2DMD-SET tool is expected to be released as
open-source once the final version of this manuscript is prepared, allowing the
community to add different measurement devices and generate their own datasets.

</details>


### [60] [Federated Fine-tuning of SAM-Med3D for MRI-based Dementia Classification](https://arxiv.org/abs/2508.21458)
*Kaouther Mouheb,Marawan Elbatel,Janne Papma,Geert Jan Biessels,Jurgen Claassen,Huub Middelkoop,Barbara van Munster,Wiesje van der Flier,Inez Ramakers,Stefan Klein,Esther E. Bron*

Main category: cs.CV

TL;DR: 本研究系统评估了联邦学习中基础模型（FM）微调的关键设计选择（分类头架构、微调策略、聚合方法）对基于脑部MRI的痴呆诊断性能和效率的影响。


<details>
  <summary>Details</summary>
Motivation: 基础模型在AI辅助痴呆诊断方面潜力巨大，但它们与联邦学习（FL）系统的集成尚未得到充分探索。

Method: 通过一项基准研究，使用大型多队列数据集，系统评估了分类头架构、微调策略（例如冻结编码器与完全微调）和聚合方法（例如高级聚合方法与标准联邦平均）对联邦FM微调性能和效率的影响，数据源为脑部MRI。

Result: 研究发现分类头架构显著影响性能；冻结FM编码器能达到与完全微调相当的结果；高级聚合方法优于标准联邦平均。

Conclusion: 研究结果为在去中心化临床环境中部署基础模型提供了实用见解，并强调了应指导未来方法开发的权衡考量。

Abstract: While foundation models (FMs) offer strong potential for AI-based dementia
diagnosis, their integration into federated learning (FL) systems remains
underexplored. In this benchmarking study, we systematically evaluate the
impact of key design choices: classification head architecture, fine-tuning
strategy, and aggregation method, on the performance and efficiency of
federated FM tuning using brain MRI data. Using a large multi-cohort dataset,
we find that the architecture of the classification head substantially
influences performance, freezing the FM encoder achieves comparable results to
full fine-tuning, and advanced aggregation methods outperform standard
federated averaging. Our results offer practical insights for deploying FMs in
decentralized clinical settings and highlight trade-offs that should guide
future method development.

</details>


### [61] [Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering](https://arxiv.org/abs/2508.21773)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 本文提出了一种无监督视频持续学习（uVCL）的现实场景和非参数解决方案，无需任务边界和标签。它利用深度视频特征的核密度估计（KDE）进行数据表示，并通过新颖性检测动态扩展知识，显著提升了模型在连续学习多个任务时的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的持续学习研究主要集中在有监督场景，依赖于标签和任务边界，但这既昂贵又不切实际。无监督视频持续学习（uVCL）是一个未被充分探索的问题，尤其考虑到视频数据在计算和内存方面的额外挑战，因此需要填补这一空白。

Method: 本文提出了一个通用的uVCL基准实验协议，并引入了一种非参数学习解决方案。该方案使用无监督视频Transformer网络提取的深度嵌入视频特征的核密度估计（KDE）作为数据概率表示。它还引入了新颖性检测准则，用于识别新任务数据并动态扩展内存集群以捕获新知识，并利用先前任务的迁移学习作为当前学习任务的初始状态。

Result: 实验结果表明，所提出的方法在连续学习多个任务时，显著提升了模型的性能。在UCF101、HMDB51和Something-to-Something V2三个标准视频动作识别数据集上进行了深入评估，且全程未使用任何标签或类别边界。

Conclusion: 本文成功地提出了一个针对无监督视频持续学习的现实场景和非参数解决方案，通过结合KDE、新颖性检测和迁移学习，有效解决了在无监督环境下连续学习复杂视频数据的挑战，并取得了显著的性能提升。

Abstract: We propose a realistic scenario for the unsupervised video learning where
neither task boundaries nor labels are provided when learning a succession of
tasks. We also provide a non-parametric learning solution for the
under-explored problem of unsupervised video continual learning. Videos
represent a complex and rich spatio-temporal media information, widely used in
many applications, but which have not been sufficiently explored in
unsupervised continual learning. Prior studies have only focused on supervised
continual learning, relying on the knowledge of labels and task boundaries,
while having labeled data is costly and not practical. To address this gap, we
study the unsupervised video continual learning (uVCL). uVCL raises more
challenges due to the additional computational and memory requirements of
processing videos when compared to images. We introduce a general benchmark
experimental protocol for uVCL by considering the learning of unstructured
video data categories during each task. We propose to use the Kernel Density
Estimation (KDE) of deep embedded video features extracted by unsupervised
video transformer networks as a non-parametric probabilistic representation of
the data. We introduce a novelty detection criterion for the incoming new task
data, dynamically enabling the expansion of memory clusters, aiming to capture
new knowledge when learning a succession of tasks. We leverage the use of
transfer learning from the previous tasks as an initial state for the knowledge
transfer to the current learning task. We found that the proposed methodology
substantially enhances the performance of the model when successively learning
many tasks. We perform in-depth evaluations on three standard video action
recognition datasets, including UCF101, HMDB51, and Something-to-Something V2,
without using any labels or class boundaries.

</details>


### [62] [Multi-Method Ensemble for Out-of-Distribution Detection](https://arxiv.org/abs/2508.21463)
*Lucas Rakotoarivony*

Main category: cs.CV

TL;DR: 该论文提出了一种名为多方法集成（MME）的新型OOD检测分数，通过理论和实证证明了现有特征截断和评分函数的有效结合，并聚合多个评分函数以提高鲁棒性，在各类基准测试中显著超越了现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 在开放世界环境中，特别是安全关键应用中，检测分布外（OOD）样本对神经网络至关重要。现有方法主要侧重于单一技术家族或特定OOD数据集类型，忽略了结合多种现有解决方案的潜力，这促使研究者探索更有效的组合方法。

Method: 该研究理论和实证地证明了最先进的特征截断和评分函数可以有效结合。此外，它还展示了聚合多个评分函数能增强对各种OOD样本的鲁棒性。基于这些见解，论文提出了多方法集成（MME）分数，该分数将最先进的OOD检测器统一为一个更有效的评分函数。

Result: MME在涵盖近OOD和远OOD场景的大规模和小规模基准测试中，显著优于所有基准上的最新最先进方法。值得注意的是，使用BiT模型，该方法在具有挑战性的ImageNet-1K基准上实现了27.57%的平均FPR95，比现有最佳基线提高了6%。

Conclusion: 通过有效结合最先进的特征截断和评分函数，并聚合多个评分函数，所提出的多方法集成（MME）分数能够统一并显著提升OOD检测的性能和鲁棒性，在广泛的OOD场景中超越了现有技术。

Abstract: Detecting out-of-distribution (OOD) samples is essential for neural networks
operating in open-world settings, particularly in safety-critical applications.
Existing methods have improved OOD detection by leveraging two main techniques:
feature truncation, which increases the separation between in-distribution (ID)
and OOD samples, and scoring functions, which assign scores to distinguish
between ID and OOD data. However, most approaches either focus on a single
family of techniques or evaluate their effectiveness on a specific type of OOD
dataset, overlooking the potential of combining multiple existing solutions.
Motivated by this observation, we theoretically and empirically demonstrate
that state-of-the-art feature truncation and scoring functions can be
effectively combined. Moreover, we show that aggregating multiple scoring
functions enhances robustness against various types of OOD samples. Based on
these insights, we propose the Multi-Method Ensemble (MME) score, which unifies
state-of-the-art OOD detectors into a single, more effective scoring function.
Extensive experiments on both large-scale and small-scale benchmarks, covering
near-OOD and far-OOD scenarios, show that MME significantly outperforms recent
state-of-the-art methods across all benchmarks. Notably, using the BiT model,
our method achieves an average FPR95 of 27.57% on the challenging ImageNet-1K
benchmark, improving performance by 6% over the best existing baseline.

</details>


### [63] [Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight](https://arxiv.org/abs/2508.21777)
*Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz*

Main category: cs.CV

TL;DR: GPT-5在放射肿瘤学多项选择题基准测试中表现出色，优于早期模型，并在临床病例推荐中获得较高评价，但仍需专家监督。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在临床决策支持方面展现出巨大潜力，而GPT-5是专为肿瘤学应用设计的新型LLM系统。

Method: 研究采用两种互补的基准进行评估：(i) 包含300道多项选择题的ACR放射肿瘤学在职培训考试（TXIT, 2021）；(ii) 包含60个真实放射肿瘤学临床病例的精选集。对于临床病例，GPT-5被要求生成简洁的治疗方案，并由四位获得委员会认证的放射肿瘤学家评估其正确性、全面性和幻觉情况。使用Fleiss' kappa量化评估者间的一致性。

Result: 在TXIT基准测试中，GPT-5的平均准确率为92.8%，优于GPT-4（78.8%）和GPT-3.5（62.1%）。在临床病例评估中，GPT-5的治疗建议在正确性（平均3.24/4）和全面性（3.59/4）方面获得高度评价。幻觉情况罕见。评估者间一致性较低（Fleiss' kappa 0.083），反映了临床判断的固有变异性。错误主要集中在需要精确试验知识或详细临床适应的复杂场景。

Conclusion: GPT-5在放射肿瘤学多项选择题基准测试中明显优于先前的模型版本。尽管GPT-5在生成真实世界放射肿瘤学治疗建议方面表现良好，但正确性评分表明仍有改进空间。虽然幻觉不常见，但实质性错误的存在强调了GPT-5生成的建议在临床实施前需要严格的专家监督。

Abstract: Introduction: Large language models (LLM) have shown great potential in
clinical decision support. GPT-5 is a novel LLM system that has been
specifically marketed towards oncology use.
  Methods: Performance was assessed using two complementary benchmarks: (i) the
ACR Radiation Oncology In-Training Examination (TXIT, 2021), comprising 300
multiple-choice items, and (ii) a curated set of 60 authentic radiation
oncologic vignettes representing diverse disease sites and treatment
indications. For the vignette evaluation, GPT-5 was instructed to generate
concise therapeutic plans. Four board-certified radiation oncologists rated
correctness, comprehensiveness, and hallucinations. Inter-rater reliability was
quantified using Fleiss' \k{appa}.
  Results: On the TXIT benchmark, GPT-5 achieved a mean accuracy of 92.8%,
outperforming GPT-4 (78.8%) and GPT-3.5 (62.1%). Domain-specific gains were
most pronounced in Dose and Diagnosis. In the vignette evaluation, GPT-5's
treatment recommendations were rated highly for correctness (mean 3.24/4, 95%
CI: 3.11-3.38) and comprehensiveness (3.59/4, 95% CI: 3.49-3.69).
Hallucinations were rare with no case reaching majority consensus for their
presence. Inter-rater agreement was low (Fleiss' \k{appa} 0.083 for
correctness), reflecting inherent variability in clinical judgment. Errors
clustered in complex scenarios requiring precise trial knowledge or detailed
clinical adaptation.
  Discussion: GPT-5 clearly outperformed prior model variants on the radiation
oncology multiple-choice benchmark. Although GPT-5 exhibited favorable
performance in generating real-world radiation oncology treatment
recommendations, correctness ratings indicate room for further improvement.
While hallucinations were infrequent, the presence of substantive errors
underscores that GPT-5-generated recommendations require rigorous expert
oversight before clinical implementation.

</details>


### [64] [Adversarial Patch Attack for Ship Detection via Localized Augmentation](https://arxiv.org/abs/2508.21472)
*Chun Liu,Panpan Ding,Zheng Zheng,Hailong Wang,Bingqian Zhu,Tao Xu,Zhigang Han,Jiayao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种局部增强方法，通过仅对目标区域应用增强来减少背景干扰，从而提高对抗性补丁攻击对遥感图像舰船检测模型的成功率和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度神经网络的舰船检测技术易受对抗性补丁攻击。现有数据转换方法虽然能提高对抗样本的可迁移性，但过度增强图像背景或无关区域会引入不必要的干扰，导致检测模型出现与对抗补丁本身无关的错误检测。因此，需要一种更精确的增强方法来提高攻击效率并避免背景干扰。

Method: 本文提出了一种局部增强方法。该方法仅将增强应用于目标区域，避免对非目标区域产生任何影响。通过减少背景干扰，该方法使损失函数能够更直接地关注对抗性补丁对检测模型的影响。

Result: 在HRSC2016数据集上进行的实验表明，所提出的方法有效地提高了对抗性补丁攻击的成功率，并增强了其可迁移性。

Conclusion: 局部增强方法能够有效提升对抗性补丁攻击对舰船检测模型的成功率和可迁移性，其关键在于减少背景干扰，使攻击更聚焦于目标区域。

Abstract: Current ship detection techniques based on remote sensing imagery primarily
rely on the object detection capabilities of deep neural networks (DNNs).
However, DNNs are vulnerable to adversarial patch attacks, which can lead to
misclassification by the detection model or complete evasion of the targets.
Numerous studies have demonstrated that data transformation-based methods can
improve the transferability of adversarial examples. However, excessive
augmentation of image backgrounds or irrelevant regions may introduce
unnecessary interference, resulting in false detections of the object detection
model. These errors are not caused by the adversarial patches themselves but
rather by the over-augmentation of background and non-target areas. This paper
proposes a localized augmentation method that applies augmentation only to the
target regions, avoiding any influence on non-target areas. By reducing
background interference, this approach enables the loss function to focus more
directly on the impact of the adversarial patch on the detection model, thereby
improving the attack success rate. Experiments conducted on the HRSC2016
dataset demonstrate that the proposed method effectively increases the success
rate of adversarial patch attacks and enhances their transferability.

</details>


### [65] [TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection Models with a Text Memory Bank](https://arxiv.org/abs/2508.21795)
*Jiawei Liu,Jiahe Hou,Wei Wang,Jinsong Du,Yang Cong,Huijie Fan*

Main category: cs.CV

TL;DR: 本文提出了一种名为TMUAD的三记忆框架，用于统一结构和逻辑异常检测。它通过构建类级别文本记忆库、对象级别图像记忆库和补丁级别图像记忆库，整合多模态信息，实现了对工业和医疗领域异常的有效识别。


<details>
  <summary>Details</summary>
Motivation: 异常检测面临正常数据量有限的挑战，现有统一方法主要依赖图像特征提取器和记忆库来捕获对象间的逻辑关系。本文旨在通过引入文本记忆库来增强逻辑异常检测能力，并实现结构和逻辑异常的统一检测。

Method: 本文提出了TMUAD框架。首先，通过逻辑感知文本提取器构建类级别文本记忆库，用于逻辑异常检测。其次，通过从分割对象中提取特征，构建对象级别图像记忆库，以保留完整的对象轮廓。最后，利用视觉编码器提取补丁级别图像特征，构建补丁级别记忆库，用于结构异常检测。这三个互补的记忆库用于检索和比较与查询图像最相似的正常图像，计算多层次异常分数，并将其融合为最终异常分数。

Result: 通过协同记忆库统一结构和逻辑异常检测，TMUAD在七个公开的工业和医疗领域数据集中取得了最先进的性能。

Conclusion: TMUAD框架通过其独特的三记忆库设计，成功地统一了结构和逻辑异常检测，并在多个领域展示了卓越的性能，证明了多模态记忆库协同作用在异常检测中的有效性。

Abstract: Anomaly detection, which aims to identify anomalies deviating from normal
patterns, is challenging due to the limited amount of normal data available.
Unlike most existing unified methods that rely on carefully designed image
feature extractors and memory banks to capture logical relationships between
objects, we introduce a text memory bank to enhance the detection of logical
anomalies. Specifically, we propose a Three-Memory framework for Unified
structural and logical Anomaly Detection (TMUAD). First, we build a class-level
text memory bank for logical anomaly detection by the proposed logic-aware text
extractor, which can capture rich logical descriptions of objects from input
images. Second, we construct an object-level image memory bank that preserves
complete object contours by extracting features from segmented objects. Third,
we employ visual encoders to extract patch-level image features for
constructing a patch-level memory bank for structural anomaly detection. These
three complementary memory banks are used to retrieve and compare normal images
that are most similar to the query image, compute anomaly scores at multiple
levels, and fuse them into a final anomaly score. By unifying structural and
logical anomaly detection through collaborative memory banks, TMUAD achieves
state-of-the-art performance across seven publicly available datasets involving
industrial and medical domains. The model and code are available at
https://github.com/SIA-IDE/TMUAD.

</details>


### [66] [Maybe you don't need a U-Net: convolutional feature upsampling for materials micrograph segmentation](https://arxiv.org/abs/2508.21529)
*Ronan Docherty,Antonis Vamvakeros,Samuel J. Cooper*

Main category: cs.CV

TL;DR: 本文提出了一种卷积神经网络，用于上采样视觉基础模型在显微图像上的低分辨率特征，以解决现有模型在处理精细特征和大型图像时的不足，从而实现更高效、高质量的显微图像分割。


<details>
  <summary>Details</summary>
Motivation: 现有的特征基础模型（通常是视觉Transformer）的描述符是基于图像块的，这使得它们难以表示显微图像中常见的精细特征，并且难以处理材料和生物图像分析中的大型图像，导致计算效率低下。

Method: 研究人员训练了一个卷积神经网络（CNN），以输入图像为参考，上采样低分辨率（即大图像块尺寸）的基础模型特征。这个上采样网络在训练后无需进一步训练，即可用于特征化和分割多种显微图像。

Result: 该上采样网络能够高效地对植物细胞、锂离子电池阴极和有机晶体等多种显微图像进行特征化和分割。上采样特征的丰富性使得难以分割的相（如细微裂纹）也能被有效分离。此外，使用这些深度特征进行交互式分割，与训练或微调传统卷积网络相比，能以更少的标签更快地生成高质量的分割结果。

Conclusion: 所提出的上采样网络有效解决了现有基础模型在处理显微图像精细特征和大型图像时的局限性，显著提高了显微图像分割的效率和质量，尤其在交互式分割任务中表现出色。

Abstract: Feature foundation models - usually vision transformers - offer rich semantic
descriptors of images, useful for downstream tasks such as (interactive)
segmentation and object detection. For computational efficiency these
descriptors are often patch-based, and so struggle to represent the fine
features often present in micrographs; they also struggle with the large image
sizes present in materials and biological image analysis. In this work, we
train a convolutional neural network to upsample low-resolution (i.e, large
patch size) foundation model features with reference to the input image. We
apply this upsampler network (without any further training) to efficiently
featurise and then segment a variety of microscopy images, including plant
cells, a lithium-ion battery cathode and organic crystals. The richness of
these upsampled features admits separation of hard to segment phases, like
hairline cracks. We demonstrate that interactive segmentation with these deep
features produces high-quality segmentations far faster and with far fewer
labels than training or finetuning a more traditional convolutional network.

</details>


### [67] [The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning](https://arxiv.org/abs/2508.21816)
*Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin*

Main category: cs.CV

TL;DR: 本文指出场景识别（SR）中的动词分类本质上是多标签问题，现有方法将其视为单标签。作者提出了单正多标签学习（SPMLL）范式，并开发了结合图神经网络和对抗训练的GE-VerbMLP模型，同时设计了多标签评估基准，显著提升了多标签性能。


<details>
  <summary>Details</summary>
Motivation: 现有场景识别方法将动词分类视为单标签问题，未能解决视觉事件固有的模糊性，即同一图像可能被多个动词合理描述。此外，对大规模数据集进行完全多标签标注不切实际。

Method: 1. 经验性分析揭示动词分类本质上是多标签问题。2. 将动词分类重构为单正多标签学习（SPMLL）问题。3. 设计了一个全面的多标签评估基准。4. 开发了图增强动词多层感知机（GE-VerbMLP），结合图神经网络捕获标签关联性，并利用对抗训练优化决策边界。

Result: 在真实世界数据集上，该方法实现了超过3%的平均精度均值（MAP）提升，同时在传统的Top-1和Top-5准确率指标上保持竞争力。

Conclusion: 动词分类在场景识别中本质上是多标签问题。通过将动词分类重新定义为SPMLL问题，并引入GE-VerbMLP模型以及新的多标签评估基准，能够有效处理视觉事件识别中的多标签模糊性，显著提升多标签性能。

Abstract: Context recognition (SR) is a fundamental task in computer vision that aims
to extract structured semantic summaries from images by identifying key events
and their associated entities. Specifically, given an input image, the model
must first classify the main visual events (verb classification), then identify
the participating entities and their semantic roles (semantic role labeling),
and finally localize these entities in the image (semantic role localization).
Existing methods treat verb classification as a single-label problem, but we
show through a comprehensive analysis that this formulation fails to address
the inherent ambiguity in visual event recognition, as multiple verb categories
may reasonably describe the same image. This paper makes three key
contributions: First, we reveal through empirical analysis that verb
classification is inherently a multi-label problem due to the ubiquitous
semantic overlap between verb categories. Second, given the impracticality of
fully annotating large-scale datasets with multiple labels, we propose to
reformulate verb classification as a single positive multi-label learning
(SPMLL) problem - a novel perspective in SR research. Third, we design a
comprehensive multi-label evaluation benchmark for SR that is carefully
designed to fairly evaluate model performance in a multi-label setting. To
address the challenges of SPMLL, we futher develop the Graph Enhanced Verb
Multilayer Perceptron (GE-VerbMLP), which combines graph neural networks to
capture label correlations and adversarial training to optimize decision
boundaries. Extensive experiments on real-world datasets show that our approach
achieves more than 3\% MAP improvement while remaining competitive on
traditional top-1 and top-5 accuracy metrics.

</details>


### [68] [HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones](https://arxiv.org/abs/2508.21539)
*Hao Ruan,Jinliang Lin,Yingxin Lai,Zhiming Luo,Shaozi Li*

Main category: cs.CV

TL;DR: 针对自然语言引导无人机（NLGD）中宽视场和复杂组合语义带来的视觉-语言理解挑战，本文提出HCCM框架。该框架通过跨粒度对比与匹配学习，避免精确场景划分，增强组合推理，并引入MCD机制提升鲁棒性，在GeoText-1652和ERA数据集上均达到SOTA性能和强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自然语言引导无人机（NLGD）在目标匹配和导航等任务中面临挑战，主要原因包括：无人机场景的宽视场和复杂组合语义给视觉-语言理解带来困难；主流视觉-语言模型（VLM）侧重全局对齐而缺乏细粒度语义；现有分层方法依赖精确实体划分和严格包含，在动态环境中受限；无人机文本描述常不完整或模糊，导致对齐不稳定。

Method: 本文提出了分层跨粒度对比和匹配学习（HCCM）框架，包含两个核心组件：1. 区域-全局图像-文本对比学习（RG-ITC），通过对比局部视觉区域与全局文本（反之亦然）来避免精确场景划分，捕捉分层局部到全局的语义；2. 区域-全局图像-文本匹配（RG-ITM），通过评估全局跨模态表示中的局部语义一致性来增强组合推理，无需严格约束。此外，HCCM还引入了动量对比和蒸馏（MCD）机制，以提高对不完整或模糊文本描述的鲁棒性。

Result: HCCM在GeoText-1652数据集上取得了最先进的（SOTA）性能：图像检索的Recall@1达到28.8%，文本检索的Recall@1达到14.7%。在未见的ERA数据集上，HCCM展示了强大的零样本泛化能力，平均召回率（mR）为39.93%，优于经过微调的基线模型。

Conclusion: HCCM框架通过其独特的分层跨粒度对比和匹配学习方法，有效解决了自然语言引导无人机场景中视觉-语言理解的挑战。它在细粒度语义理解、组合推理和鲁棒性方面表现出色，并在基准数据集上取得了最先进的性能和强大的零样本泛化能力。

Abstract: Natural Language-Guided Drones (NLGD) provide a novel paradigm for tasks such
as target matching and navigation. However, the wide field of view and complex
compositional semantics in drone scenarios pose challenges for vision-language
understanding. Mainstream Vision-Language Models (VLMs) emphasize global
alignment while lacking fine-grained semantics, and existing hierarchical
methods depend on precise entity partitioning and strict containment, limiting
effectiveness in dynamic environments. To address this, we propose the
Hierarchical Cross-Granularity Contrastive and Matching learning (HCCM)
framework with two components: (1) Region-Global Image-Text Contrastive
Learning (RG-ITC), which avoids precise scene partitioning and captures
hierarchical local-to-global semantics by contrasting local visual regions with
global text and vice versa; (2) Region-Global Image-Text Matching (RG-ITM),
which dispenses with rigid constraints and instead evaluates local semantic
consistency within global cross-modal representations, enhancing compositional
reasoning. Moreover, drone text descriptions are often incomplete or ambiguous,
destabilizing alignment. HCCM introduces a Momentum Contrast and Distillation
(MCD) mechanism to improve robustness. Experiments on GeoText-1652 show HCCM
achieves state-of-the-art Recall@1 of 28.8% (image retrieval) and 14.7% (text
retrieval). On the unseen ERA dataset, HCCM demonstrates strong zero-shot
generalization with 39.93% mean recall (mR), outperforming fine-tuned
baselines.

</details>


### [69] [ECHO: Ego-Centric modeling of Human-Object interactions](https://arxiv.org/abs/2508.21556)
*Ilya A. Petrov,Vladimir Guzov,Riccardo Marin,Emre Aksan,Xu Chen,Daniel Cremers,Thabo Beeler,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: 本文提出ECHO框架，首次实现仅通过头部和手腕追踪数据，从第一人称视角重建人类姿态、物体运动和接触，并在该领域达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 随着智能眼镜和手表等可穿戴设备的普及，从第一人称视角建模人-物交互（HOI）变得日益重要，但这一领域尚未得到充分探索。研究人员旨在解决如何从最少的信息（仅头部和手腕追踪）中恢复交互细节的问题。

Method: ECHO是一个统一的框架，利用Diffusion Transformer架构和独特的三变量扩散过程，共同建模人体运动、物体轨迹和接触序列，从而恢复人体姿态、物体运动和接触这三种模态。该方法在以头部为中心的规范空间中操作，增强了对全局方向的鲁棒性，并引入了一种基于传送带的推理机制，以处理任意长度的序列。

Result: ECHO在第一人称视角HOI重建方面超越了现有方法，提供了更高的灵活性，并在此领域设定了最先进的性能标准。

Conclusion: ECHO首次提出了一种从极简观察（头部和手腕追踪）中恢复第一人称视角下人-物交互（包括姿态、物体运动和接触）的统一框架，其性能优于现有方法，为该领域树立了新的标杆。

Abstract: Modeling human-object interactions (HOI) from an egocentric perspective is a
largely unexplored yet important problem due to the increasing adoption of
wearable devices, such as smart glasses and watches. We investigate how much
information about interaction can be recovered from only head and wrists
tracking. Our answer is ECHO (Ego-Centric modeling of Human-Object
interactions), which, for the first time, proposes a unified framework to
recover three modalities: human pose, object motion, and contact from such
minimal observation. ECHO employs a Diffusion Transformer architecture and a
unique three-variate diffusion process, which jointly models human motion,
object trajectory, and contact sequence, allowing for flexible input
configurations. Our method operates in a head-centric canonical space,
enhancing robustness to global orientation. We propose a conveyor-based
inference, which progressively increases the diffusion timestamp with the frame
position, allowing us to process sequences of any length. Through extensive
evaluation, we demonstrate that ECHO outperforms existing methods that do not
offer the same flexibility, setting a state-of-the-art in egocentric HOI
reconstruction.

</details>


### [70] [How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images](https://arxiv.org/abs/2508.21565)
*Juneyoung Ro,Namwoo Kim,Yoonjin Yoon*

Main category: cs.CV

TL;DR: 本研究评估了通用视觉-语言模型（VLMs）在城市空间推理中的表现，并提出通过合成数据集和思维链（CoT）监督进行微调，可显著提升其在城市场景理解上的性能。


<details>
  <summary>Details</summary>
Motivation: 有效理解城市场景需要对物体、布局和深度线索进行细致的空间推理。然而，目前在通用场景上预训练的视觉-语言模型（VLMs）将这些能力转移到城市领域的表现尚未得到充分探索。

Method: 研究对比了BLIP-2、InstructBLIP和LLaVA-1.5三种现成VLM的零样本性能，并评估了使用合成VQA数据集进行微调的效果。该数据集通过街景图像的分割、深度和目标检测预测构建，并为每个问题配对由LLM生成的思维链（CoT）答案以提供分步推理监督。

Result: 结果显示，VLMs在零样本设置下表现尚可，但使用我们合成的、CoT监督的数据集进行微调能显著提升性能，尤其对于否定和反事实等挑战性问题类型。这表明微调对于提升模型在复杂城市推理任务上的能力至关重要。

Conclusion: 本研究将城市空间推理引入为VLM面临的新挑战，并证明了合成数据集的构建是使通用模型适应特定领域的实用途径。通过合成数据和CoT监督，可以有效增强VLM在专业领域，特别是城市场景理解中的推理能力。

Abstract: Effectively understanding urban scenes requires fine-grained spatial
reasoning about objects, layouts, and depth cues. However, how well current
vision-language models (VLMs), pretrained on general scenes, transfer these
abilities to urban domain remains underexplored. To address this gap, we
conduct a comparative study of three off-the-shelf VLMs-BLIP-2, InstructBLIP,
and LLaVA-1.5-evaluating both zero-shot performance and the effects of
fine-tuning with a synthetic VQA dataset specific to urban scenes. We construct
such dataset from segmentation, depth, and object detection predictions of
street-view images, pairing each question with LLM-generated Chain-of-Thought
(CoT) answers for step-by-step reasoning supervision. Results show that while
VLMs perform reasonably well in zero-shot settings, fine-tuning with our
synthetic CoT-supervised dataset substantially boosts performance, especially
for challenging question types such as negation and counterfactuals. This study
introduces urban spatial reasoning as a new challenge for VLMs and demonstrates
synthetic dataset construction as a practical path for adapting general-purpose
models to specialized domains.

</details>


### [71] [Temporal Flow Matching for Learning Spatio-Temporal Trajectories in 4D Longitudinal Medical Imaging](https://arxiv.org/abs/2508.21580)
*Nico Albert Disch,Yannick Kirchhoff,Robin Peretzke,Maximilian Rokuss,Saikat Roy,Constantin Ulrich,David Zimmerer,Klaus Maier-Hein*

Main category: cs.CV

TL;DR: 本文提出Temporal Flow Matching (TFM)，一种统一的生成轨迹方法，用于4D医学图像预测。它通过学习底层时间分布，支持3D体积、多重先验扫描和不规则采样，并在多个纵向数据集上超越现有方法，建立了新的基线。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的时间动态对于疾病进展建模、治疗规划和解剖发育跟踪至关重要。然而，现有深度学习方法大多只考虑单一时间背景，或专注于分类/回归等任务，限制了其精细空间预测能力。现有方法常局限于单一时间点、特定疾病或存在技术限制，导致存在根本性空白。

Method: 本文引入Temporal Flow Matching (TFM)，这是一种统一的生成轨迹方法。它旨在学习底层的医学影像时间分布；设计上可退化为最近图像预测器（预测最后一个上下文图像LCI）作为特例；并支持3D体积、多重先验扫描以及不规则采样。

Result: 在三个公共纵向数据集上进行的广泛基准测试表明，TFM持续超越了自然图像领域的时空方法，为4D医学图像预测建立了一个新的最先进且稳健的基线。

Conclusion: TFM有效解决了医学影像中精细空间预测的时间动态理解方面的根本性空白，为4D医学图像预测提供了一个新的最先进且稳健的解决方案。

Abstract: Understanding temporal dynamics in medical imaging is crucial for
applications such as disease progression modeling, treatment planning and
anatomical development tracking. However, most deep learning methods either
consider only single temporal contexts, or focus on tasks like classification
or regression, limiting their ability for fine-grained spatial predictions.
While some approaches have been explored, they are often limited to single
timepoints, specific diseases or have other technical restrictions. To address
this fundamental gap, we introduce Temporal Flow Matching (TFM), a unified
generative trajectory method that (i) aims to learn the underlying temporal
distribution, (ii) by design can fall back to a nearest image predictor, i.e.
predicting the last context image (LCI), as a special case, and (iii) supports
$3D$ volumes, multiple prior scans, and irregular sampling. Extensive
benchmarks on three public longitudinal datasets show that TFM consistently
surpasses spatio-temporal methods from natural imaging, establishing a new
state-of-the-art and robust baseline for $4D$ medical image prediction.

</details>


### [72] [Integrating Pathology and CT Imaging for Personalized Recurrence Risk Prediction in Renal Cancer](https://arxiv.org/abs/2508.21581)
*Daniël Boeke,Cedrik Blommestijn,Rebecca N. Wray,Kalina Chupetlovska,Shangqi Gao,Zeyu Gao,Regina G. H. Beets-Tan,Mireia Crispin-Ortuzar,James O. Jones,Wilson Silva,Ines P. Machado*

Main category: cs.CV

TL;DR: 本研究通过整合术前CT和术后病理全切片图像（WSI），利用多模态深度学习框架预测透明细胞肾细胞癌（ccRCC）的复发风险，并证明了其可行性。


<details>
  <summary>Details</summary>
Motivation: Leibovich评分在ccRCC复发风险评估中广泛应用，但其患者个体化分辨率有限且未纳入影像信息，促使研究人员寻求更全面、更个性化的预测方法。

Method: 研究采用了一个模块化的深度学习框架，该框架结合了预训练编码器和基于Cox的生存模型。它在单模态、后期融合和中期融合设置下，评估了术前CT和术后组织病理学WSI的整合效果。

Result: 基于WSI的模型始终优于仅基于CT的模型，凸显了病理学在预后判断中的强大作用。中期融合进一步提升了预测性能，其中最佳模型（TITAN-CONCH结合ResNet-18）的性能接近调整后的Leibovich评分。放射学信息主要通过融合贡献价值。

Conclusion: 研究结果表明，基于基础模型的多模态整合对于个性化ccRCC风险预测是可行的。未来的工作应探索更具表达力的融合策略、更大的多模态数据集和通用CT编码器，以进一步提升模型的性能。

Abstract: Recurrence risk estimation in clear cell renal cell carcinoma (ccRCC) is
essential for guiding postoperative surveillance and treatment. The Leibovich
score remains widely used for stratifying distant recurrence risk but offers
limited patient-level resolution and excludes imaging information. This study
evaluates multimodal recurrence prediction by integrating preoperative computed
tomography (CT) and postoperative histopathology whole-slide images (WSIs). A
modular deep learning framework with pretrained encoders and Cox-based survival
modeling was tested across unimodal, late fusion, and intermediate fusion
setups. In a real-world ccRCC cohort, WSI-based models consistently
outperformed CT-only models, underscoring the prognostic strength of pathology.
Intermediate fusion further improved performance, with the best model
(TITAN-CONCH with ResNet-18) approaching the adjusted Leibovich score. Random
tie-breaking narrowed the gap between the clinical baseline and learned models,
suggesting discretization may overstate individualized performance. Using
simple embedding concatenation, radiology added value primarily through fusion.
These findings demonstrate the feasibility of foundation model-based multimodal
integration for personalized ccRCC risk prediction. Future work should explore
more expressive fusion strategies, larger multimodal datasets, and
general-purpose CT encoders to better match pathology modeling capacity.

</details>


### [73] [Unfolding Framework with Complex-Valued Deformable Attention for High-Quality Computer-Generated Hologram Generation](https://arxiv.org/abs/2508.21657)
*Haomiao Zhang,Zhangyuan Li,Yanling Piao,Zhi Li,Xiaodong Wang,Miao Cao,Xiongfei Su,Qiang Song,Xin Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种深度展开网络（DUN），通过分解梯度下降为自适应带宽保持模型（ABPM）和相位域复值去噪器（PCD），解决了计算机生成全息图（CGH）中端到端网络、CNN和角谱法（ASM）模型的局限性，实现了更准确和稳定的重建。


<details>
  <summary>Details</summary>
Motivation: 深度学习驱动的CGH面临挑战：1) 端到端网络将重建视为黑箱，缺乏可解释性和灵活性；2) 基于CNN的算法感受野有限，难以捕获长距离依赖和全局上下文；3) 基于ASM的模型仅限于有限的近场。

Method: 提出了一种深度展开网络（DUN），将梯度下降分解为两个模块：1) 自适应带宽保持模型（ABPM），允许比ASM更宽的工作距离；2) 相位域复值去噪器（PCD），利用其复值可变形自注意力模块捕获全局特征并增强性能。

Result: 实验在模拟和真实数据上显示了最先进的结果，实现了超过35 dB的PSNR。

Conclusion: 所提出的DUN通过ABPM和PCD有效解决了现有CGH算法的局限性，提供了更灵活、准确且性能优越的全息图重建方法。

Abstract: Computer-generated holography (CGH) has gained wide attention with deep
learning-based algorithms. However, due to its nonlinear and ill-posed nature,
challenges remain in achieving accurate and stable reconstruction.
Specifically, ($i$) the widely used end-to-end networks treat the
reconstruction model as a black box, ignoring underlying physical
relationships, which reduces interpretability and flexibility. ($ii$) CNN-based
CGH algorithms have limited receptive fields, hindering their ability to
capture long-range dependencies and global context. ($iii$) Angular spectrum
method (ASM)-based models are constrained to finite near-fields.In this paper,
we propose a Deep Unfolding Network (DUN) that decomposes gradient descent into
two modules: an adaptive bandwidth-preserving model (ABPM) and a phase-domain
complex-valued denoiser (PCD), providing more flexibility. ABPM allows for
wider working distances compared to ASM-based methods. At the same time, PCD
leverages its complex-valued deformable self-attention module to capture global
features and enhance performance, achieving a PSNR over 35 dB. Experiments on
simulated and real data show state-of-the-art results.

</details>


### [74] [Towards Interactive Lesion Segmentation in Whole-Body PET/CT with Promptable Models](https://arxiv.org/abs/2508.21680)
*Maximilian Rokuss,Yannick Kirchhoff,Fabian Isensee,Klaus H. Maier-Hein*

Main category: cs.CV

TL;DR: 本文提出了一种基于nnU-Net的交互式PET/CT病灶分割方法，通过将用户点击（前景/背景）编码为附加输入通道，并采用欧氏距离变换（EDT）编码，实现了高效、用户引导的分割工作流，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 全身PET/CT肿瘤影像中，由于示踪剂异质性、生理性摄取和多中心变异性，准确的病灶分割仍具挑战。虽然全自动化方法已取得进展，但临床实践仍受益于允许人类高效精炼预测掩膜的方法。autoPET/CT IV挑战赛旨在通过模拟用户提示的交互式分割任务来解决这一需求。

Method: 本文基于获胜的autoPET III nnU-Net管线，通过将用户提供的前景和背景点击编码为额外的输入通道，扩展了框架的提示能力。系统性地研究了空间提示的表示方法，发现欧氏距离变换（EDT）编码始终优于高斯核。此外，提出了在线模拟用户交互和自定义点采样策略，以提高在实际提示条件下的鲁棒性。最终使用了基于EDT的模型集成，并结合有无外部数据进行训练。

Result: 基于EDT的模型集成，无论是否使用外部数据训练，都取得了最强的交叉验证性能，与基线模型相比，同时减少了假阳性（FP）和假阴性（FN）。

Conclusion: 这些结果突显了可提示模型在多示踪剂、多中心PET/CT中实现高效、用户引导分割工作流的潜力。

Abstract: Whole-body PET/CT is a cornerstone of oncological imaging, yet accurate
lesion segmentation remains challenging due to tracer heterogeneity,
physiological uptake, and multi-center variability. While fully automated
methods have advanced substantially, clinical practice benefits from approaches
that keep humans in the loop to efficiently refine predicted masks. The
autoPET/CT IV challenge addresses this need by introducing interactive
segmentation tasks based on simulated user prompts. In this work, we present
our submission to Task 1. Building on the winning autoPET III nnU-Net pipeline,
we extend the framework with promptable capabilities by encoding user-provided
foreground and background clicks as additional input channels. We
systematically investigate representations for spatial prompts and demonstrate
that Euclidean Distance Transform (EDT) encodings consistently outperform
Gaussian kernels. Furthermore, we propose online simulation of user
interactions and a custom point sampling strategy to improve robustness under
realistic prompting conditions. Our ensemble of EDT-based models, trained with
and without external data, achieves the strongest cross-validation performance,
reducing both false positives and false negatives compared to baseline models.
These results highlight the potential of promptable models to enable efficient,
user-guided segmentation workflows in multi-tracer, multi-center PET/CT. Code
is publicly available at https://github.com/MIC-DKFZ/autoPET-interactive

</details>


### [75] [Mapping like a Skeptic: Probabilistic BEV Projection for Online HD Mapping](https://arxiv.org/abs/2508.21689)
*Fatih Erdoğan,Merve Rabia Barın,Fatma Güney*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的概率投影机制，结合置信度分数，用于从图像空间到鸟瞰图（BEV）空间的高清地图构建，显著提高了地图绘制的准确性和泛化能力，尤其是在挑战性的感知范围。


<details>
  <summary>Details</summary>
Motivation: 现有高清地图绘制方法在将图像空间元素投影到BEV空间时，由于泛化问题，精度不足，常会“幻觉”出不存在的道路元素。这导致最终矢量化高清地图的质量受损。

Method: 核心思想是基于相机参数进行几何映射，并根据场景进行自适应调整，以从图像中提取相关地图信息。具体方法包括：1) 提出一种带有置信度分数的概率投影机制，用于细化映射以更好地与场景对齐，并过滤掉不相关的元素；2) 利用置信度分数选择性地累积可靠信息，从而改进时间处理。

Result: 在nuScenes和Argoverse2数据集的新分割上的实验表明，该方法优于现有最先进的方法，表现出更好的泛化能力。在nuScenes数据集和挑战性的长感知范围下，性能提升尤为显著。

Conclusion: 所提出的概率投影机制能够有效提高高清地图构建的精度和泛化能力，尤其是在复杂场景和远距离感知方面表现出色，解决了现有方法中精度不足和元素“幻觉”的问题。

Abstract: Constructing high-definition (HD) maps from sensory input requires accurately
mapping the road elements in image space to the Bird's Eye View (BEV) space.
The precision of this mapping directly impacts the quality of the final
vectorized HD map. Existing HD mapping approaches outsource the projection to
standard mapping techniques, such as attention-based ones. However, these
methods struggle with accuracy due to generalization problems, often
hallucinating non-existent road elements. Our key idea is to start with a
geometric mapping based on camera parameters and adapt it to the scene to
extract relevant map information from camera images. To implement this, we
propose a novel probabilistic projection mechanism with confidence scores to
(i) refine the mapping to better align with the scene and (ii) filter out
irrelevant elements that should not influence HD map generation. In addition,
we improve temporal processing by using confidence scores to selectively
accumulate reliable information over time. Experiments on new splits of the
nuScenes and Argoverse2 datasets demonstrate improved performance over
state-of-the-art approaches, indicating better generalization. The improvements
are particularly pronounced on nuScenes and in the challenging long perception
range. Our code and model checkpoints are available at
https://github.com/Fatih-Erdogan/mapping-like-skeptic .

</details>


### [76] [FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA](https://arxiv.org/abs/2508.21712)
*Alvaro Patricio,Atabak Dehban,Rodrigo Ventura*

Main category: cs.CV

TL;DR: 本文提出了FLORA，一种轻量级合成数据生成方法，通过使用LoRA对Flux 1.1 Dev扩散模型进行微调，显著降低了计算资源需求，并以更少的数据和计算成本实现了优于现有方法的物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的物体检测数据增强方法需要大量计算资源（如企业级GPU和数千张合成图像），这限制了其应用。研究旨在解决这一效率和可及性问题。

Method: 本文提出Flux LoRA Augmentation (FLORA) 方法，利用Flux 1.1 Dev扩散模型，并通过低秩适应 (LoRA) 进行独占式微调。这种方法显著降低了计算要求，允许使用消费级GPU（如NVIDIA RTX 4090）生成合成数据集。

Result: FLORA方法仅使用500张合成图像训练的物体检测器，在七个不同的物体检测数据集上表现优于使用ODGEN基线生成的5000张合成图像训练的模型，mAP@.50:.95最高提升了21.3%。这表明FLORA以十分之一的数据量和更低的计算成本达到了卓越的性能。

Conclusion: 研究表明，相比于蛮力生成，注重质量和效率的方法（如FLORA）在合成数据创建方面更为有效，使得先进的合成数据生成技术在实际场景中更具实用性和可及性。

Abstract: Recent advances in diffusion-based generative models have demonstrated
significant potential in augmenting scarce datasets for object detection tasks.
Nevertheless, most recent models rely on resource-intensive full fine-tuning of
large-scale diffusion models, requiring enterprise-grade GPUs (e.g., NVIDIA
V100) and thousands of synthetic images. To address these limitations, we
propose Flux LoRA Augmentation (FLORA), a lightweight synthetic data generation
pipeline. Our approach uses the Flux 1.1 Dev diffusion model, fine-tuned
exclusively through Low-Rank Adaptation (LoRA). This dramatically reduces
computational requirements, enabling synthetic dataset generation with a
consumer-grade GPU (e.g., NVIDIA RTX 4090). We empirically evaluate our
approach on seven diverse object detection datasets. Our results demonstrate
that training object detectors with just 500 synthetic images generated by our
approach yields superior detection performance compared to models trained on
5000 synthetic images from the ODGEN baseline, achieving improvements of up to
21.3% in mAP@.50:.95. This work demonstrates that it is possible to surpass
state-of-the-art performance with far greater efficiency, as FLORA achieves
superior results using only 10% of the data and a fraction of the computational
cost. This work demonstrates that a quality and efficiency-focused approach is
more effective than brute-force generation, making advanced synthetic data
creation more practical and accessible for real-world scenarios.

</details>


### [77] [Learning from Silence and Noise for Visual Sound Source Localization](https://arxiv.org/abs/2508.21761)
*Xavier Juanola,Giovana Morais,Magdalena Fuentes,Gloria Haro*

Main category: cs.CV

TL;DR: 本文提出了一种新的自监督训练策略（SSL-SaN），通过引入静音和噪声来改进视觉声源定位，使其在低音视频语义对应（如负面音频）情况下更鲁棒，并在定位和跨模态检索方面达到SOTA性能。同时，还提出了新的评估指标和包含负面音频的扩展数据集IS3+。


<details>
  <summary>Details</summary>
Motivation: 现有视觉声源定位方法存在两个主要缺点：1) 在低音视频语义对应（如静音、噪声、画外音等负面音频）情况下性能不佳；2) 大多数现有评估仅限于正面情况，即数据集中只有一个可见声源的场景。

Method: 1. 提出一种新的训练策略，融合了静音和噪声，以提高正面情况下的性能并增强对负面声音的鲁棒性，从而构建了自监督模型SSL-SaN。2. 提出一种新的度量指标，用于量化听觉和视觉特征在正负音视频对之间对齐和分离的权衡。3. 提出了IS3+，一个扩展并改进的合成数据集，其中包含了负面音频。

Result: 所提出的SSL-SaN模型在声源定位和跨模态检索方面均达到了现有自监督模型的最佳性能，并且对负面声音表现出更强的鲁棒性。

Conclusion: 通过引入新的训练策略、评估指标和扩展数据集，本研究显著提升了视觉声源定位在复杂真实场景（特别是存在负面音频时）的性能和鲁棒性，并为未来的研究提供了更全面的评估工具和数据。

Abstract: Visual sound source localization is a fundamental perception task that aims
to detect the location of sounding sources in a video given its audio. Despite
recent progress, we identify two shortcomings in current methods: 1) most
approaches perform poorly in cases with low audio-visual semantic
correspondence such as silence, noise, and offscreen sounds, i.e. in the
presence of negative audio; and 2) most prior evaluations are limited to
positive cases, where both datasets and metrics convey scenarios with a single
visible sound source in the scene. To address this, we introduce three key
contributions. First, we propose a new training strategy that incorporates
silence and noise, which improves performance in positive cases, while being
more robust against negative sounds. Our resulting self-supervised model,
SSL-SaN, achieves state-of-the-art performance compared to other
self-supervised models, both in sound localization and cross-modal retrieval.
Second, we propose a new metric that quantifies the trade-off between alignment
and separability of auditory and visual features across positive and negative
audio-visual pairs. Third, we present IS3+, an extended and improved version of
the IS3 synthetic dataset with negative audio.
  Our data, metrics and code are available on the
https://xavijuanola.github.io/SSL-SaN/.

</details>


### [78] [UItron: Foundational GUI Agent with Advanced Perception and Planning](https://arxiv.org/abs/2508.21767)
*Zhixiong Zeng,Jing Huang,Liming Zheng,Wenkang Han,Yufeng Zhong,Lei Chen,Longrong Yang,Yingjie Chu,Yuzhi He,Lin Ma*

Main category: cs.CV

TL;DR: UItron是一个开源的通用GUI代理基础模型，通过系统数据工程、交互式基础设施、监督微调和课程强化学习，显著提升了GUI感知、定位和规划能力，尤其在中文APP场景中表现优越。


<details>
  <summary>Details</summary>
Motivation: GUI代理是实现通用人工智能的重要一步，但其发展面临操作轨迹数据稀缺、交互基础设施不足以及基础模型初始能力有限的挑战。尽管VLM加速了发展，但这些挑战依然存在。

Method: 本文提出了UItron，一个开源的GUI代理基础模型。它强调系统性数据工程和交互式基础设施的重要性，并系统研究了一系列数据工程策略。UItron建立了一个连接移动和PC设备的交互式环境，并采用监督微调（针对感知和规划任务）与课程强化学习（用于在线环境中的复杂推理和探索）相结合的训练框架。此外，为解决中文能力不足的问题，UItron手动收集了超过一百万步的中文主流APP操作轨迹数据，并构建了离线和在线评估环境。

Result: UItron在GUI感知、定位和规划的基准测试中取得了卓越的性能。特别是在与顶级中文移动APP的交互熟练度方面表现突出，填补了现有解决方案中文能力普遍不足的空白。实验结果表明，UItron在中文APP场景中取得了显著进展。

Conclusion: UItron通过其先进的GUI感知、定位和规划能力，以及对系统数据工程和交互式基础设施的强调，显著推动了GUI代理的发展。尤其在中文APP场景中的卓越表现，使GUI代理离实际应用更近了一步。

Abstract: GUI agent aims to enable automated operations on Mobile/PC devices, which is
an important task toward achieving artificial general intelligence. The rapid
advancement of VLMs accelerates the development of GUI agents, owing to their
powerful capabilities in visual understanding and task planning. However,
building a GUI agent remains a challenging task due to the scarcity of
operation trajectories, the availability of interactive infrastructure, and the
limitation of initial capabilities in foundation models. In this work, we
introduce UItron, an open-source foundational model for automatic GUI agents,
featuring advanced GUI perception, grounding, and planning capabilities. UItron
highlights the necessity of systemic data engineering and interactive
infrastructure as foundational components for advancing GUI agent development.
It not only systematically studies a series of data engineering strategies to
enhance training effects, but also establishes an interactive environment
connecting both Mobile and PC devices. In training, UItron adopts supervised
finetuning over perception and planning tasks in various GUI scenarios, and
then develop a curriculum reinforcement learning framework to enable complex
reasoning and exploration for online environments. As a result, UItron achieves
superior performance in benchmarks of GUI perception, grounding, and planning.
In particular, UItron highlights the interaction proficiency with top-tier
Chinese mobile APPs, as we identified a general lack of Chinese capabilities
even in state-of-the-art solutions. To this end, we manually collect over one
million steps of operation trajectories across the top 100 most popular apps,
and build the offline and online agent evaluation environments. Experimental
results demonstrate that UItron achieves significant progress in Chinese app
scenarios, propelling GUI agents one step closer to real-world application.

</details>


### [79] [Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations](https://arxiv.org/abs/2508.21769)
*Ha Min Son,Zhe Zhao,Shahbaz Rezaei,Xin Liu*

Main category: cs.CV

TL;DR: 现有领域泛化(DG)评估对CLIP等基础模型不够具有挑战性。本文提出新的评估方法，并发现CLIP在域外(OOD)数据集上性能显著下降。为此，提出CLIP-DCA，通过增强领域感知并解耦分类，显著提升了CLIP在挑战性DG场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有对CLIP等基础模型的DG评估可能不够具有挑战性，无法充分测试真正未见过的数据场景，因为其预训练数据可能已覆盖许多现有基准。此外，标准领域不变性损失可能有害，因为它强制丢弃对泛化有益的领域感知表示。本研究旨在更好地评估CLIP在“野外”DG场景中的性能，并假设增强领域感知是基础模型中有效领域不变分类的先决条件。

Method: 本文采用两种方法评估CLIP的DG性能：1) 在ImageNet上微调CLIP后，使用33个具有量化OOD分数的不同数据集进行评估；2) 使用“遗忘学习”让CLIP“忘记”某些领域作为近似评估。为解决观察到的性能下降，本文提出了CLIP-DCA (Disentangling Classification from enhanced domain Aware representations)。该方法通过独立的领域头部和合成生成的多样领域数据，识别并增强CLIP编码器中的领域感知能力，同时通过与领域特征的解耦来鼓励领域不变的分类。

Result: 实验观察到CLIP在OOD程度更高的数据集上性能显著下降。相比现有方法，CLIP-DCA在本文提出的挑战性评估中显示出显著改进，尤其是在OOD程度更高的数据集上。

Conclusion: CLIP在面对高度OOD数据时存在显著的领域泛化挑战。CLIP-DCA通过增强基础模型的领域感知能力并将其与分类解耦，有效提升了在复杂“野外”DG场景中的性能，证明了增强领域感知对于实现有效领域不变分类的重要性。

Abstract: Evaluating domain generalization (DG) for foundational models like CLIP is
challenging, as web-scale pretraining data potentially covers many existing
benchmarks. Consequently, current DG evaluation may neither be sufficiently
challenging nor adequately test genuinely unseen data scenarios. To better
assess the performance of CLIP on DG in-the-wild, a scenario where CLIP
encounters challenging unseen data, we consider two approaches: (1) evaluating
on 33 diverse datasets with quantified out-of-distribution (OOD) scores after
fine-tuning CLIP on ImageNet, and (2) using unlearning to make CLIP `forget'
some domains as an approximation. We observe that CLIP's performance
deteriorates significantly on more OOD datasets. To address this, we present
CLIP-DCA (Disentangling Classification from enhanced domain Aware
representations). Our approach is motivated by the observation that while
standard domain invariance losses aim to make representations domain-invariant,
this can be harmful to foundation models by forcing the discarding of
domain-aware representations beneficial for generalization. We instead
hypothesize that enhancing domain awareness is a prerequisite for effective
domain-invariant classification in foundation models. CLIP-DCA identifies and
enhances domain awareness within CLIP's encoders using a separate domain head
and synthetically generated diverse domain data. Simultaneously, it encourages
domain-invariant classification through disentanglement from the domain
features. CLIP-DCA shows significant improvements within this challenging
evaluation compared to existing methods, particularly on datasets that are more
OOD.

</details>


### [80] [What Can We Learn from Harry Potter? An Exploratory Study of Visual Representation Learning from Atypical Videos](https://arxiv.org/abs/2508.21770)
*Qiyue Sun,Qiming Huang,Yang Yang,Hongjun Wang,Jianbo Jiao*

Main category: cs.CV

TL;DR: 本研究探讨了利用非典型视频数据（如科幻、动画）来提升开放世界学习（包括OOD检测、NCD和ZSAR）中视觉表征学习的能力，并发现其显著优势。


<details>
  <summary>Details</summary>
Motivation: 人类在开放世界中对不常见的新概念表现出卓越的泛化和发现能力，而现有研究大多关注封闭集中的常见典型数据。视频中的开放世界新颖发现仍未充分探索。本研究旨在回答：如果在学习过程中引入非典型、不寻常的视频会怎样？

Method: 1. 收集了一个包含各种非典型不寻常视频（如科幻、动画等）的新数据集。2. 将这些非典型数据用于模型训练，进行表征学习。3. 在开放世界学习的三个关键任务上进行评估：分布外检测（OOD）、新类别发现（NCD）和零样本动作识别（ZSAR）。

Result: 1. 即使是直接的学习方法，引入非典型数据也能持续提升OOD检测、NCD和ZSAR任务的性能。2. 增加非典型样本的类别多样性可以进一步提升OOD检测性能。3. 在NCD任务中，使用更小但语义更多样化的非典型样本集，比使用更大但更典型的样本集表现更好。4. 在ZSAR设置中，非典型视频的语义多样性有助于模型更好地泛化到未见过的动作类别。

Conclusion: 这些广泛的实验评估表明，非典型视频对于开放世界中的视觉表征学习具有显著益处。新提出的数据集以及这些发现鼓励了该方向的进一步研究。

Abstract: Humans usually show exceptional generalisation and discovery ability in the
open world, when being shown uncommon new concepts. Whereas most existing
studies in the literature focus on common typical data from closed sets,
open-world novel discovery is under-explored in videos. In this paper, we are
interested in asking: \textit{What if atypical unusual videos are exposed in
the learning process?} To this end, we collect a new video dataset consisting
of various types of unusual atypical data (\eg sci-fi, animation, \etc). To
study how such atypical data may benefit open-world learning, we feed them into
the model training process for representation learning. Focusing on three key
tasks in open-world learning: out-of-distribution (OOD) detection, novel
category discovery (NCD), and zero-shot action recognition (ZSAR), we found
that even straightforward learning approaches with atypical data consistently
improve performance across various settings. Furthermore, we found that
increasing the categorical diversity of the atypical samples further boosts OOD
detection performance. Additionally, in the NCD task, using a smaller yet more
semantically diverse set of atypical samples leads to better performance
compared to using a larger but more typical dataset. In the ZSAR setting, the
semantic diversity of atypical videos helps the model generalise better to
unseen action classes. These observations in our extensive experimental
evaluations reveal the benefits of atypical videos for visual representation
learning in the open world, together with the newly proposed dataset,
encouraging further studies in this direction.

</details>


### [81] [A Multi-Stage Fine-Tuning and Ensembling Strategy for Pancreatic Tumor Segmentation in Diagnostic and Therapeutic MRI](https://arxiv.org/abs/2508.21775)
*Omer Faruk Durugol,Maximilian Rokuss,Yannick Kirchhoff,Klaus H. Maier-Hein*

Main category: cs.CV

TL;DR: 该研究提出了一种基于nnU-Net的多阶段级联预训练和度量感知集成策略，用于在数据稀缺和对比度差的条件下，从MRI图像中自动分割胰腺导管腺癌(PDAC)，并取得了高精度。


<details>
  <summary>Details</summary>
Motivation: 自动从MRI中分割胰腺导管腺癌(PDAC)对临床工作流程至关重要，但由于肿瘤组织对比度差和带注释数据稀缺而面临挑战。

Method: 该方法基于nnU-Net框架，采用深度多阶段级联预训练策略：从通用解剖基础模型开始，顺序地在CT胰腺病变数据集和目标MRI模态上进行微调。通过广泛的五折交叉验证，系统评估了数据增强方案和训练计划。最终通过构建定制的、异构的专家模型集成（度量感知集成策略）来优化性能。

Result: 分析揭示了一个关键的权衡：激进的数据增强产生了最高的体积准确性，而默认增强则产生了卓越的边界精度（任务1达到了最先进的MASD 5.46毫米和HD95 17.33毫米）。最终的集成策略在任务1中实现了0.661的肿瘤Dice分数，在任务2中实现了0.523的肿瘤Dice分数。

Conclusion: 该工作提出了一种在数据有限和医学成像任务复杂背景下，开发专业化、高性能模型的稳健方法。

Abstract: Automated segmentation of Pancreatic Ductal Adenocarcinoma (PDAC) from MRI is
critical for clinical workflows but is hindered by poor tumor-tissue contrast
and a scarcity of annotated data. This paper details our submission to the
PANTHER challenge, addressing both diagnostic T1-weighted (Task 1) and
therapeutic T2-weighted (Task 2) segmentation. Our approach is built upon the
nnU-Net framework and leverages a deep, multi-stage cascaded pre-training
strategy, starting from a general anatomical foundation model and sequentially
fine-tuning on CT pancreatic lesion datasets and the target MRI modalities.
Through extensive five-fold cross-validation, we systematically evaluated data
augmentation schemes and training schedules. Our analysis revealed a critical
trade-off, where aggressive data augmentation produced the highest volumetric
accuracy, while default augmentations yielded superior boundary precision
(achieving a state-of-the-art MASD of 5.46 mm and HD95 of 17.33 mm for Task 1).
For our final submission, we exploited this finding by constructing custom,
heterogeneous ensembles of specialist models, essentially creating a mix of
experts. This metric-aware ensembling strategy proved highly effective,
achieving a top cross-validation Tumor Dice score of 0.661 for Task 1 and 0.523
for Task 2. Our work presents a robust methodology for developing specialized,
high-performance models in the context of limited data and complex medical
imaging tasks (Team MIC-DKFZ).

</details>


### [82] [VoCap: Video Object Captioning and Segmentation from Any Prompt](https://arxiv.org/abs/2508.21809)
*Jasper Uijlings,Xingyi Zhou,Xiuye Gu,Arsha Nagrani,Anurag Arnab,Alireza Fathi,David Ross,Cordelia Schmid*

Main category: cs.CV

TL;DR: 本文提出了VoCap模型，一个灵活的视频模型，能够根据多模态提示（文本、框、掩码）生成时空掩码和以对象为中心的描述，从而同时解决可提示视频对象分割、指代表达分割和对象描述任务。同时，他们还创建了SAV-Caption数据集。


<details>
  <summary>Details</summary>
Motivation: 在视频理解中，以细粒度定位掩码和详细语义属性来理解视频中的对象是一项基础任务。现有的方法可能无法同时满足这些需求，并且获取相关数据成本高昂。

Method: 本文提出了VoCap模型，该模型接收视频和多模态提示（文本、框或掩码），然后输出一个时空掩码（masklet）和相应的以对象为中心的描述。为了解决数据稀缺问题，作者通过使用大型视觉语言模型（VLM）处理现有的大规模分割数据集（SAV）的伪对象描述，创建了SAV-Caption数据集，并在验证集上进行了人工标注以确保无偏评估。VoCap模型在SAV-Caption以及其他图像和视频数据集的混合上进行了大规模训练。

Result: VoCap模型在指代表达视频对象分割任务上取得了最先进的结果，在半监督视频对象分割任务上表现具有竞争力，并为视频对象描述任务建立了新的基准。所创建的SAV-Caption数据集也将公开发布。

Conclusion: VoCap是一个多功能的视频模型，能够通过多模态提示实现全面的视频对象理解（包括分割和描述）。同时，新创建的SAV-Caption数据集为这一领域的研究提供了宝贵的资源，并推动了相关任务的性能基准。

Abstract: Understanding objects in videos in terms of fine-grained localization masks
and detailed semantic properties is a fundamental task in video understanding.
In this paper, we propose VoCap, a flexible video model that consumes a video
and a prompt of various modalities (text, box or mask), and produces a
spatio-temporal masklet with a corresponding object-centric caption. As such
our model addresses simultaneously the tasks of promptable video object
segmentation, referring expression segmentation, and object captioning. Since
obtaining data for this task is tedious and expensive, we propose to annotate
an existing large-scale segmentation dataset (SAV) with pseudo object captions.
We do so by preprocessing videos with their ground-truth masks to highlight the
object of interest and feed this to a large Vision Language Model (VLM). For an
unbiased evaluation, we collect manual annotations on the validation set. We
call the resulting dataset SAV-Caption. We train our VoCap model at scale on a
SAV-Caption together with a mix of other image and video datasets. Our model
yields state-of-the-art results on referring expression video object
segmentation, is competitive on semi-supervised video object segmentation, and
establishes a benchmark for video object captioning. Our dataset will be made
available at https://github.com/google-deepmind/vocap.

</details>


### [83] [DriveQA: Passing the Driving Knowledge Test](https://arxiv.org/abs/2508.21824)
*Maolin Wei,Wanzhou Liu,Eshed Ohn-Bar*

Main category: cs.CV

TL;DR: 本文提出了DriveQA，一个全面的文本和视觉驾驶知识基准，用于评估大型语言模型（LLMs）和多模态LLMs（MLLMs）在交通法规和场景理解方面的能力。研究发现现有模型在复杂推理和边缘案例上存在显著弱点，但通过在DriveQA上进行微调和预训练可以有效提升性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前的自动驾驶基准主要关注空间和视觉问答，但驾驶知识测试需要对所有交通规则、标志和路权原则有完整理解，包括现实世界数据中罕见的各种边缘情况。现有基准不足以评估LLMs能否通过此类测试。

Method: 研究人员创建了DriveQA，一个广泛的开源文本和视觉基准，全面覆盖了交通法规和场景。他们使用DriveQA对最先进的LLMs和MLLMs进行了实验，并在DriveQA上进行了模型微调和预训练，以评估其对模型性能和下游任务的影响。

Result: 1. 最先进的LLMs和MLLMs在基本交通规则上表现良好，但在数值推理、复杂路权场景、交通标志变体和空间布局方面表现出显著弱点。2. 在DriveQA上进行微调可以提高模型在多个类别上的准确性，尤其是在监管标志识别和交叉路口决策方面。3. DriveQA-V中的受控变体揭示了模型对光照、视角、距离和天气条件等环境因素的敏感性。4. 在DriveQA上进行预训练可以增强下游驾驶任务的性能，改善在nuScenes和BDD等真实世界数据集上的结果，并证明模型能够内化文本和合成交通知识以有效泛化到下游问答任务。

Conclusion: LLMs和MLLMs在理解复杂的驾驶知识和处理边缘案例方面仍有不足。DriveQA基准能够有效识别这些弱点，并通过微调和预训练显著提升模型在驾驶知识理解和下游驾驶任务中的表现，证明模型可以学习并泛化文本和合成交通知识。

Abstract: If a Large Language Model (LLM) were to take a driving knowledge test today,
would it pass? Beyond standard spatial and visual question-answering (QA) tasks
on current autonomous driving benchmarks, driving knowledge tests require a
complete understanding of all traffic rules, signage, and right-of-way
principles. To pass this test, human drivers must discern various edge cases
that rarely appear in real-world datasets. In this work, we present DriveQA, an
extensive open-source text and vision-based benchmark that exhaustively covers
traffic regulations and scenarios. Through our experiments using DriveQA, we
show that (1) state-of-the-art LLMs and Multimodal LLMs (MLLMs) perform well on
basic traffic rules but exhibit significant weaknesses in numerical reasoning
and complex right-of-way scenarios, traffic sign variations, and spatial
layouts, (2) fine-tuning on DriveQA improves accuracy across multiple
categories, particularly in regulatory sign recognition and intersection
decision-making, (3) controlled variations in DriveQA-V provide insights into
model sensitivity to environmental factors such as lighting, perspective,
distance, and weather conditions, and (4) pretraining on DriveQA enhances
downstream driving task performance, leading to improved results on real-world
datasets such as nuScenes and BDD, while also demonstrating that models can
internalize text and synthetic traffic knowledge to generalize effectively
across downstream QA tasks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [84] [CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples](https://arxiv.org/abs/2508.21083)
*Kyohoon Jin,Juhwan Choi,Jungmin Yun,Junho Lee,Soojin Jang,Youngbin Kim*

Main category: cs.CL

TL;DR: 本文提出了CoBA（CounterBias Augmentation），一个在语义三元组层面操作的反偏差数据增强框架。它通过分解文本、修改三元组以破坏虚假关联，然后重建文本，从而同时解决多种偏差并增强模型在分布外数据上的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型常利用训练数据中的虚假关联进行预测，导致在未见过的数据上性能下降和泛化能力差。现有方法不足以同时解决多种偏差。

Method: CoBA框架首先将文本分解为“主语-谓语-宾语”三元组，然后选择性地修改这些三元组以破坏虚假关联。最后，通过调整后的三元组重建文本，生成反偏差数据以缓解虚假模式。

Result: CoBA不仅提高了下游任务的性能，还有效减少了偏差并增强了模型在分布外数据上的鲁棒性。

Conclusion: CoBA为解决虚假关联带来的挑战提供了一个多功能且鲁棒的解决方案。

Abstract: Deep learning models often learn and exploit spurious correlations in
training data, using these non-target features to inform their predictions.
Such reliance leads to performance degradation and poor generalization on
unseen data. To address these limitations, we introduce a more general form of
counterfactual data augmentation, termed counterbias data augmentation, which
simultaneously tackles multiple biases (e.g., gender bias, simplicity bias) and
enhances out-of-distribution robustness. We present CoBA: CounterBias
Augmentation, a unified framework that operates at the semantic triple level:
first decomposing text into subject-predicate-object triples, then selectively
modifying these triples to disrupt spurious correlations. By reconstructing the
text from these adjusted triples, CoBA generates counterbias data that
mitigates spurious patterns. Through extensive experiments, we demonstrate that
CoBA not only improves downstream task performance, but also effectively
reduces biases and strengthens out-of-distribution resilience, offering a
versatile and robust solution to the challenges posed by spurious correlations.

</details>


### [85] [Mapping Toxic Comments Across Demographics: A Dataset from German Public Broadcasting](https://arxiv.org/abs/2508.21084)
*Jan Fillies,Michael Peter Hoffmann,Rebecca Reichel,Roman Salzwedel,Sven Bodemer,Adrian Paschke*

Main category: cs.CL

TL;DR: 该研究引入了首个大规模德语有毒言论数据集，包含平台提供的年龄估算，揭示了不同年龄群体在线交流中的有毒言论模式差异。


<details>
  <summary>Details</summary>
Motivation: 现有有毒言论数据集缺乏人口统计学背景（特别是年龄信息），限制了对不同年龄群体在线沟通方式的理解，并阻碍了开发更公平、更具年龄意识的内容审核系统。

Method: 研究与德国公共服务内容网络funk合作，构建了一个包含3,024条人工标注和30,024条LLM标注的匿名评论数据集，数据来源于Instagram、TikTok和YouTube，并富含平台提供的年龄估算。评论通过预定义有毒关键词进行筛选。标注流程结合了人工专业知识和先进语言模型，识别出侮辱、虚假信息和广播费用批评等关键类别。

Result: 数据集中有16.7%的评论被标记为有问题。结果显示，有毒言论模式存在基于年龄的差异：年轻用户倾向于使用表达性语言，而年长用户则更多地参与虚假信息和贬低性言论。

Conclusion: 该数据集为研究跨人口统计学群体的语言变异提供了新机会，并支持开发更公平、更具年龄意识的内容审核系统。

Abstract: A lack of demographic context in existing toxic speech datasets limits our
understanding of how different age groups communicate online. In collaboration
with funk, a German public service content network, this research introduces
the first large-scale German dataset annotated for toxicity and enriched with
platform-provided age estimates. The dataset includes 3,024 human-annotated and
30,024 LLM-annotated anonymized comments from Instagram, TikTok, and YouTube.
To ensure relevance, comments were consolidated using predefined toxic
keywords, resulting in 16.7\% labeled as problematic. The annotation pipeline
combined human expertise with state-of-the-art language models, identifying key
categories such as insults, disinformation, and criticism of broadcasting fees.
The dataset reveals age-based differences in toxic speech patterns, with
younger users favoring expressive language and older users more often engaging
in disinformation and devaluation. This resource provides new opportunities for
studying linguistic variation across demographics and supports the development
of more equitable and age-aware content moderation systems.

</details>


### [86] [Granite Embedding R2 Models](https://arxiv.org/abs/2508.21085)
*Parul Awasthy,Aashka Trivedi,Yulong Li,Meet Doshi,Riyaz Bhat,Vignesh P,Vishwajeet Kumar,Yushu Yang,Bhavani Iyer,Abraham Daniels,Rudra Murthy,Ken Barker,Martin Franz,Madison Lee,Todd Ward,Salim Roukos,David Cox,Luis Lastras,Jaydeep Sen,Radu Florian*

Main category: cs.CL

TL;DR: IBM发布了Granite Embedding R2模型家族，这是一套高性能、企业级的英文编码器嵌入模型，专为密集检索应用设计，具有更长的上下文长度、领先的性能、更快的速度和Apache 2.0开源许可。


<details>
  <summary>Details</summary>
Motivation: 在当前时代，检索速度和准确性对于企业获得竞争优势至关重要。研究旨在开发一套高性能、企业就绪且具备透明数据溯源的嵌入模型，以满足关键任务部署的需求。

Method: 该研究引入了基于编码器的Granite Embedding R2模型，包括双编码器（bi-encoder）和交叉编码器（cross-encoder）架构。模型包含一个高效的22层检索模型及其12层精简版，以及一个高质量的重排序模型。所有模型均使用符合企业规范的数据进行训练，并进行全面的治理监督。

Result: Granite R2模型实现了显著改进，包括将上下文长度扩展16倍（达到8,192个token），在文本、代码、长文档搜索、多轮对话和表格数据等多种检索领域达到最先进的性能。与领先的竞争对手相比，模型在保持卓越准确性的同时，速度提升了19-44%。这些模型在标准基准测试、IBM开发的评估套件和实际企业用例中均展现出卓越的通用性，为开源嵌入模型树立了新的性能标准。

Conclusion: Granite R2模型家族为企业级密集检索应用提供了尖端性能、企业就绪的许可和透明的数据溯源，满足了组织关键任务部署的需求。这些模型通过Apache 2.0许可公开可用，支持无限制的研究和商业用途，为开源嵌入模型设定了新的性能标准。

Abstract: We introduce the Granite Embedding R2 models, a comprehensive family of
high-performance English encoder-based embedding models engineered for
enterprise-scale dense retrieval applications. Building upon our
first-generation release, these models deliver substantial improvements,
including 16x expanded context length (8,192 tokens), state-of-the-art
performance across diverse retrieval domains - text, code, long-document
search, multi-turn conversational, and tabular data - and measurable speed
advantages of 19-44\% over leading competitors while maintaining superior
accuracy. Our release encompasses both bi-encoder and cross-encoder
architectures, featuring a highly effective 22-layer retriever model and its
efficient 12-layer counterpart, alongside a high-quality reranker model, all
trained exclusively on enterprise-appropriate data with comprehensive
governance oversight. The models demonstrate exceptional versatility across
standard benchmarks, IBM-developed evaluation suites, and real-world enterprise
use cases, establishing new performance standards for open-source embedding
models. In an era where retrieval speed and accuracy are paramount for
competitive advantage, the Granite R2 models deliver a compelling combination
of cutting-edge performance, enterprise-ready licensing, and transparent data
provenance that organizations require for mission-critical deployments. All
models are publicly available under the Apache 2.0 license at
https://huggingface.co/collections/ibm-granite, enabling unrestricted research
and commercial use.

</details>


### [87] [TrInk: Ink Generation with Transformer Network](https://arxiv.org/abs/2508.21098)
*Zezhong Jin,Shubhang Desai,Xu Chen,Biyi Fang,Zhuoyi Huang,Zhe Li,Chong-Xin Gan,Xiao Tu,Man-Wai Mak,Yan Lu,Shujie Liu*

Main category: cs.CL

TL;DR: 本文提出了TrInk，一个基于Transformer的墨迹生成模型，通过引入缩放位置嵌入和高斯记忆掩码来有效捕捉全局依赖并改善文本与笔画的对齐。该模型在IAM-OnDB数据集上显著降低了字符错误率和单词错误率。


<details>
  <summary>Details</summary>
Motivation: 现有墨迹生成模型在有效捕捉全局依赖以及输入文本与生成笔画点之间的对齐方面可能存在不足。

Method: 本文提出了TrInk模型，这是一个基于Transformer的墨迹生成模型。为了更好地促进输入文本与生成笔画点之间的对齐，该模型在交叉注意力模块中引入了缩放位置嵌入和高斯记忆掩码。此外，还设计了主观和客观评估流程来全面评估生成手写体的可读性和风格一致性。

Result: 实验表明，与现有方法相比，TrInk模型在IAM-OnDB数据集上将字符错误率（CER）降低了35.56%，将单词错误率（WER）降低了29.66%。

Conclusion: TrInk模型在墨迹生成方面表现出色，通过有效捕捉全局依赖和改进文本与笔画对齐，显著提高了生成手写体的准确性。

Abstract: In this paper, we propose TrInk, a Transformer-based model for ink
generation, which effectively captures global dependencies. To better
facilitate the alignment between the input text and generated stroke points, we
introduce scaled positional embeddings and a Gaussian memory mask in the
cross-attention module. Additionally, we design both subjective and objective
evaluation pipelines to comprehensively assess the legibility and style
consistency of the generated handwriting. Experiments demonstrate that our
Transformer-based model achieves a 35.56\% reduction in character error rate
(CER) and an 29.66% reduction in word error rate (WER) on the IAM-OnDB dataset
compared to previous methods. We provide an demo page with handwriting samples
from TrInk and baseline models at: https://akahello-a11y.github.io/trink-demo/

</details>


### [88] [How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations](https://arxiv.org/abs/2508.21137)
*Yoshiki Takenami,Yin Jou Huang,Yugo Murawaki,Chenhui Chu*

Main category: cs.CL

TL;DR: 本文研究了LLM在价格谈判中受锚定效应的影响，发现LLM像人类一样受其影响，推理能力可缓解该效应，但个性特征无显著相关性。


<details>
  <summary>Details</summary>
Motivation: 认知偏差在LLM中也存在，影响其在实际应用中的可靠性。本文旨在深入理解LLM中的认知偏差，特别是锚定效应，以实现LLM的安全和负责任应用。

Method: 研究通过指示卖方LLM代理应用锚定效应，在价格谈判中进行评估。评估不仅使用了客观指标，还使用了主观指标。此外，还调查了锚定效应与推理能力和个性特征之间的关系。

Result: 实验结果表明，LLM像人类一样受锚定效应的影响。推理模型更不易受锚定效应影响，表明长链思维可以缓解该效应。然而，个性特征与锚定效应的易感性之间没有发现显著相关性。

Conclusion: 这些发现有助于更深入地理解LLM中的认知偏差，并促进LLM在社会中的安全和负责任应用。

Abstract: Cognitive biases, well-studied in humans, can also be observed in LLMs,
affecting their reliability in real-world applications. This paper investigates
the anchoring effect in LLM-driven price negotiations. To this end, we
instructed seller LLM agents to apply the anchoring effect and evaluated
negotiations using not only an objective metric but also a subjective metric.
Experimental results show that LLMs are influenced by the anchoring effect like
humans. Additionally, we investigated the relationship between the anchoring
effect and factors such as reasoning and personality. It was shown that
reasoning models are less prone to the anchoring effect, suggesting that the
long chain of thought mitigates the effect. However, we found no significant
correlation between personality traits and susceptibility to the anchoring
effect. These findings contribute to a deeper understanding of cognitive biases
in LLMs and to the realization of safe and responsible application of LLMs in
society.

</details>


### [89] [Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?](https://arxiv.org/abs/2508.21143)
*Samrajnee Ghosh,Naman Agarwal,Hemanshu Garg,Chinmay Mittal,Mausam,Parag Singla*

Main category: cs.CL

TL;DR: 本研究引入了Percept-V数据集，用于评估多模态大语言模型（MLLMs）在基本视觉感知任务上的表现。结果显示，随着问题复杂性增加，MLLMs的性能显著下降，且在不同认知技能上表现出相似的准确性趋势。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在编码、数学和科学等复杂推理任务上取得了进展，但很少有实验评估它们在包含基本形状和结构的、无污染生成图像上的简单感知任务表现。

Method: 研究引入了Percept-V数据集，包含7200张程序生成的图像，分为30个类别，每个类别测试不同的视觉感知技能。该数据集包含不同复杂度的基本任务。研究人员使用GPT-4o、Gemini、Claude等最先进的MLLMs以及OpenAI o4-mini、DeepSeek R1等大型推理模型（LRMs）对数据集进行了测试。

Result: 实验发现，与MLLMs在许多复杂任务中表现出色相反，随着问题复杂性的增加，模型在所有类别中的性能都显著下降。对性能的分析还揭示，被测试的MLLMs在测试特定认知技能的类别中表现出相似的准确性趋势，并且发现某些技能比其他技能更难。

Conclusion: 尽管MLLMs在复杂任务上表现出色，但它们在基本的视觉感知任务中，随着问题复杂度的增加，性能会显著下降，这表明它们在基础感知技能方面存在局限性。

Abstract: The reasoning abilities of Multimodal Large Language Models (MLLMs) have
garnered a lot of attention in recent times, with advances made in frontiers
like coding, mathematics, and science. However, very limited experiments have
been done to assess their performance in simple perception tasks performed over
uncontaminated, generated images containing basic shapes and structures. To
address this issue, the paper introduces a dataset, Percept-V, containing a
total of 7200 program-generated images equally divided into 30 categories, each
testing a combination of visual perception skills. Unlike previously proposed
datasets, Percept-V comprises very basic tasks of varying complexity that test
the perception abilities of MLLMs. This dataset is then tested on
state-of-the-art MLLMs like GPT-4o, Gemini, and Claude as well as Large
Reasoning Models (LRMs) like OpenAI o4-mini and DeepSeek R1 to gauge their
performance. Contrary to the evidence that MLLMs excel in many complex tasks,
our experiments show a significant drop in the models' performance with
increasing problem complexity across all categories. An analysis of the
performances also reveals that the tested MLLMs exhibit a similar trend in
accuracy across categories, testing a particular cognitive skill and find some
skills to be more difficult than others.

</details>


### [90] [A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers](https://arxiv.org/abs/2508.21148)
*Ming Hu,Chenglong Ma,Wei Li,Wanghan Xu,Jiamin Wu,Jucheng Hu,Tianbin Li,Guohang Zhuang,Jiaqi Liu,Yingzhou Lu,Ying Chen,Chaoyang Zhang,Cheng Tan,Jie Ying,Guocheng Wu,Shujian Gao,Pengcheng Chen,Jiashi Lin,Haitao Wu,Lulu Chen,Fengxiang Wang,Yuanyuan Zhang,Xiangyu Zhao,Feilong Tang,Encheng Su,Junzhi Ning,Xinyao Liu,Ye Du,Changkai Ji,Cheng Tang,Huihui Xu,Ziyang Chen,Ziyan Huang,Jiyao Liu,Pengfei Jiang,Yizhou Wang,Chen Tang,Jianyu Wu,Yuchen Ren,Siyuan Yan,Zhonghua Wang,Zhongxing Xu,Shiyan Su,Shangquan Sun,Runkai Zhao,Zhisheng Zhang,Yu Liu,Fudi Wang,Yuanfeng Ji,Yanzhou Su,Hongming Shan,Chunmei Feng,Jiahao Xu,Jiangtao Yan,Wenhao Tang,Diping Song,Lihao Liu,Yanyan Huang,Lequan Yu,Bin Fu,Shujun Wang,Xiaomeng Li,Xiaowei Hu,Yun Gu,Ben Fei,Zhongying Deng,Benyou Wang,Yuewen Cao,Minjie Shen,Haodong Duan,Jie Xu,Yirong Chen,Fang Yan,Hongxia Hao,Jielan Li,Jiajun Du,Yanbo Wang,Imran Razzak,Chi Zhang,Lijun Wu,Conghui He,Zhaohui Lu,Jinhai Huang,Yihao Liu,Fenghua Ling,Yuqiang Li,Aoran Wang,Qihao Zheng,Nanqing Dong,Tianfan Fu,Dongzhan Zhou,Yan Lu,Wenlong Zhang,Jin Ye,Jianfei Cai,Wanli Ouyang,Yu Qiao,Zongyuan Ge,Shixiang Tang,Junjun He,Chunfeng Song,Lei Bai,Bowen Zhou*

Main category: cs.CL

TL;DR: 本调查报告全面审视了科学大型语言模型（Sci-LLMs）的发展，将其视为模型与底层科学数据共同演进的过程。报告提出了科学数据的统一分类法和知识模型，分析了科学数据特有的多模态、跨尺度、领域特异性等挑战，并系统回顾了当前的Sci-LLMs、训练数据集和评估基准，最终展望了迈向闭环自主智能系统的未来。


<details>
  <summary>Details</summary>
Motivation: Sci-LLMs正在变革科学研究，但其进展受限于科学数据的复杂性。本研究旨在通过以数据为中心的方法，综合分析Sci-LLMs的发展，阐明模型与数据之间的共演关系，并识别科学数据在训练和评估Sci-LLMs中带来的独特挑战和需求。

Method: 本研究采用调查综述的方法，具体包括：1) 制定科学数据的统一分类法和科学知识的层级模型；2) 系统回顾从通用到专业化的最新Sci-LLMs；3) 广泛分析超过270个预训练/后训练数据集，强调科学数据（异构、多尺度、不确定性）的特殊要求；4) 审查超过190个基准数据集和评估协议，追踪评估范式的转变；5) 讨论科学数据开发中的持续问题及半自动化标注和专家验证等新兴解决方案。

Result: Sci-LLMs的发展与底层科学数据共同演进。科学语料库与通用NLP数据集不同，具有多模态、跨尺度、领域特异性、异构、多尺度和不确定性等特点，需要保留领域不变性并实现跨模态推理的表示。评估方式正从静态考试转向以过程和发现为导向的先进评估协议。科学数据开发中存在持续性问题，但半自动化标注流程和专家验证等新兴解决方案正在出现。

Conclusion: 本研究为构建可信赖、持续进化的AI系统以加速科学发现提供了路线图。未来将出现基于Sci-LLMs的自主智能体，形成闭环系统，主动进行实验、验证并贡献于一个活态、演进的知识库，成为科学发现的真正伙伴。

Abstract: Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is
represented, integrated, and applied in scientific research, yet their progress
is shaped by the complex nature of scientific data. This survey presents a
comprehensive, data-centric synthesis that reframes the development of Sci-LLMs
as a co-evolution between models and their underlying data substrate. We
formulate a unified taxonomy of scientific data and a hierarchical model of
scientific knowledge, emphasizing the multimodal, cross-scale, and
domain-specific challenges that differentiate scientific corpora from general
natural language processing datasets. We systematically review recent Sci-LLMs,
from general-purpose foundations to specialized models across diverse
scientific disciplines, alongside an extensive analysis of over 270
pre-/post-training datasets, showing why Sci-LLMs pose distinct demands --
heterogeneous, multi-scale, uncertainty-laden corpora that require
representations preserving domain invariance and enabling cross-modal
reasoning. On evaluation, we examine over 190 benchmark datasets and trace a
shift from static exams toward process- and discovery-oriented assessments with
advanced evaluation protocols. These data-centric analyses highlight persistent
issues in scientific data development and discuss emerging solutions involving
semi-automated annotation pipelines and expert validation. Finally, we outline
a paradigm shift toward closed-loop systems where autonomous agents based on
Sci-LLMs actively experiment, validate, and contribute to a living, evolving
knowledge base. Collectively, this work provides a roadmap for building
trustworthy, continually evolving artificial intelligence (AI) systems that
function as a true partner in accelerating scientific discovery.

</details>


### [91] [Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations](https://arxiv.org/abs/2508.21164)
*Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型在进行自我或跨模型评估时，其判断会受到模型身份标签的显著影响，导致评分和排名出现偏差。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）越来越多地被用于评估输出，但它们的判断可能受到偏见的影响。本研究旨在探讨ChatGPT、Gemini和Claude在自我和跨模型评估中存在的偏见。

Method: 研究在四种标签条件下（无标签、真实标签、两种虚假标签情景）对ChatGPT、Gemini和Claude进行了评估。每个模型撰写的博客文章由所有三个模型进行评估，评估方式包括整体偏好投票和针对连贯性、信息量和简洁性的质量评分，所有分数均以百分比表示以便直接比较。

Result: 结果显示出显著的不对称性："Claude"标签始终能提高分数，而"Gemini"标签则始终会降低分数，无论实际内容如何。虚假标签经常逆转排名，导致偏好投票中出现高达50个百分点的变化，转换后的质量评分中出现高达12个百分点的变化。在真实标签下，Gemini的自我评分崩溃，而Claude的自我偏好则增强。

Conclusion: 这些发现表明，感知的模型身份会严重扭曲高层判断，并微妙地影响详细的质量评分，强调了在LLM基准测试中需要采用盲测或多模型评估协议以确保公平性。

Abstract: Large language models (LLMs) are increasingly used to evaluate outputs, yet
their judgments may be influenced. This study examines bias in self- and
cross-model evaluations by ChatGPT, Gemini, and Claude under four conditions:
no labels, true labels, and two false-label scenarios. Blog posts authored by
each model were evaluated by all three using both overall preference voting and
quality ratings for Coherence, Informativeness, and Conciseness, with all
scores expressed as percentages for direct comparison. Results reveal striking
asymmetries: the "Claude" label consistently boosts scores, while the "Gemini"
label consistently depresses them, regardless of actual content. False labels
frequently reversed rankings, producing shifts of up to 50 percentage points in
preference votes and up to 12 percentage points in converted quality ratings.
Gemini's self-scores collapsed under true labels, while Claude's
self-preference intensified. These findings show that perceived model identity
can heavily distort high-level judgments and subtly influence detailed quality
ratings, underscoring the need for blind or multimodel evaluation protocols to
ensure fairness in LLM benchmarking.

</details>


### [92] [BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design](https://arxiv.org/abs/2508.21184)
*Deepro Choudhury,Sinead Williamson,Adam Goliński,Ning Miao,Freddie Bickford Smith,Michael Kirchhof,Yizhe Zhang,Tom Rainforth*

Main category: cs.CL

TL;DR: 本文提出了一种名为BED-LLM的通用方法，通过序贯贝叶斯实验设计（BED）框架，显著提升大型语言模型（LLMs）智能且自适应地从用户或外部来源收集信息的能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机是使LLMs能够作为高效的多轮对话代理，并与外部环境进行交互，这需要它们能够智能且自适应地收集信息。

Method: BED-LLM方法基于迭代选择能够最大化预期信息增益（EIG）的问题或查询，该EIG通过LLM的信念分布导出的概率模型进行原理性公式化。关键创新包括精心设计的EIG估计器、不完全依赖上下文更新来条件化先前响应，以及有针对性地提出候选查询的策略。

Result: BED-LLM在基于“20个问题”游戏和LLM主动推断用户偏好等广泛测试中，相比直接提示LLM和其他自适应设计策略，实现了显著的性能提升。

Conclusion: BED-LLM通过引入贝叶斯实验设计，显著增强了LLMs智能和自适应信息收集的能力，使其在多轮对话和与外部环境交互方面表现更出色。

Abstract: We propose a general-purpose approach for improving the ability of Large
Language Models (LLMs) to intelligently and adaptively gather information from
a user or other external source using the framework of sequential Bayesian
experimental design (BED). This enables LLMs to act as effective multi-turn
conversational agents and interactively interface with external environments.
Our approach, which we call BED-LLM (Bayesian Experimental Design with Large
Language Models), is based on iteratively choosing questions or queries that
maximize the expected information gain (EIG) about the task of interest given
the responses gathered previously. We show how this EIG can be formulated in a
principled way using a probabilistic model derived from the LLM's belief
distribution and provide detailed insights into key decisions in its
construction. Further key to the success of BED-LLM are a number of specific
innovations, such as a carefully designed estimator for the EIG, not solely
relying on in-context updates for conditioning on previous responses, and a
targeted strategy for proposing candidate queries. We find that BED-LLM
achieves substantial gains in performance across a wide range of tests based on
the 20-questions game and using the LLM to actively infer user preferences,
compared to direct prompting of the LLM and other adaptive design strategies.

</details>


### [93] [Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization](https://arxiv.org/abs/2508.21201)
*Arash Ahmadi,Sarah Sharif,Yaser Banad*

Main category: cs.CL

TL;DR: 本研究引入了一个自动化HFACS分类框架，利用强化学习（GRPO）微调Llama-3.1模型，以解决航空事故分析中传统方法的可扩展性和一致性问题，并在关键指标上超越了现有最先进的大型语言模型，同时适用于资源受限的边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 分析航空事故背后的人为因素对于预防未来事故至关重要，但传统的人为因素分析与分类系统（HFACS）方法在可扩展性和一致性方面存在局限性。

Method: 开发了一个自动化HFACS分类框架，该框架利用带有群组相对策略优化（GRPO）的强化学习来微调Llama-3.1 8B语言模型。该方法结合了针对航空安全分析量身定制的多组件奖励系统，并集成了合成数据生成以克服事故数据集中的类别不平衡问题。

Result: GRPO优化的模型实现了显著的性能提升，包括精确匹配准确率提高了350%（从0.0400增至0.1800），部分匹配准确率达到0.8800。该专业模型在关键指标上优于现有最先进的LLM（包括GPT-5-mini和Gemini-2.5-flash）。研究还提出了在多标签HFACS分类问题中使用精确匹配准确率作为评估语言模型高级推理能力的新基准方法。

Conclusion: 经验证，更小、领域优化的模型可以为关键安全分析提供计算高效且更优的解决方案。这种方法使得在资源受限的边缘设备上实现强大、低延迟的部署成为可能。

Abstract: Analyzing the human factors behind aviation accidents is crucial for
preventing future incidents, yet traditional methods using the Human Factors
Analysis and Classification System (HFACS) are limited by scalability and
consistency. To address this, we introduce an automated HFACS classification
framework for aviation safety analysis that utilizes Reinforcement Learning
with Group Relative Policy Optimization (GRPO) to fine-tune a Llama-3.1 8B
language model. Our approach incorporates a multi-component reward system
tailored for aviation safety analysis and integrates synthetic data generation
to overcome class imbalance in accident datasets. The resulting GRPO-optimized
model achieved noticeable performance gains, including a 350% increase in exact
match accuracy (from 0.0400 to 0.1800) and an improved partial match accuracy
of 0.8800. Significantly, our specialized model outperforms state-of-the-art
LLMs (Large Language Models), including GPT-5-mini and Gemini-2.5-fiash, on key
metrics. This research also proposes exact match accuracy in multi-label HFACS
classification problem as a new benchmarking methodology to evaluate the
advanced reasoning capabilities of language models. Ultimately, our work
validates that smaller, domain-optimized models can provide a computationally
efficient and better solution for critical safety analysis. This approach makes
powerful, low-latency deployment on resource-constrained edge devices feasible.

</details>


### [94] [Enhancing Robustness of Autoregressive Language Models against Orthographic Attacks via Pixel-based Approach](https://arxiv.org/abs/2508.21206)
*Han Yang,Jian Lan,Yihong Liu,Hinrich Schütze,Thomas Seidl*

Main category: cs.CL

TL;DR: 该研究提出了一种基于像素的生成式语言模型，通过将单词渲染为图像，以解决自回归语言模型在正字法攻击下的脆弱性，并提高了多语言兼容性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型容易受到正字法攻击（即输入文本被多语言字母字符扰动），导致性能显著下降。这种脆弱性主要源于子词分词器及其嵌入固有的词汇外(OOV)问题。

Method: 提出了一种基于像素的生成式语言模型。该模型通过将单词渲染为独立图像，用像素级表示取代了传统的基于文本的嵌入。

Result: 在多语言LAMBADA数据集、WMT24数据集和SST-2基准测试上进行了评估。结果表明，该方法对正字法噪声具有更强的弹性，并在多语言设置中表现出有效性。

Conclusion: 基于像素的语言模型能够有效增强对正字法噪声的鲁棒性，并通过避免子词分词器的OOV问题，扩展了对多种书写系统多语言文本的兼容性。

Abstract: Autoregressive language models are vulnerable to orthographic attacks, where
input text is perturbed with characters from multilingual alphabets, leading to
substantial performance degradation. This vulnerability primarily stems from
the out-of-vocabulary issue inherent in subword tokenizers and their
embeddings. To address this limitation, we propose a pixel-based generative
language model that replaces the text-based embeddings with pixel-based
representations by rendering words as individual images. This design provides
stronger robustness to noisy inputs, while an extension of compatibility to
multilingual text across diverse writing systems. We evaluate the proposed
method on the multilingual LAMBADA dataset, WMT24 dataset and the SST-2
benchmark, demonstrating both its resilience to orthographic noise and its
effectiveness in multilingual settings.

</details>


### [95] [Do Self-Supervised Speech Models Exhibit the Critical Period Effects in Language Acquisition?](https://arxiv.org/abs/2508.21210)
*Yurie Koga,Shunsuke Kando,Yusuke Miyao*

Main category: cs.CL

TL;DR: 本研究发现，自监督语音模型（S3Ms）在语音习得方面不表现出人类语言习得中的“关键期效应”，延迟的二语（L2）暴露反而导致更好的L2表现，而延迟的一语（L1）暴露结束则导致L1遗忘。


<details>
  <summary>Details</summary>
Motivation: 人类语言习得中的“关键期效应”（CP effects）在二语习得中表现为延迟暴露导致习得困难，在一语习得中表现为延迟暴露结束导致更好地保留一语。虽然已有研究在文本语言模型中探讨了这些效应，但在语音模型中，尽管口语在人类语言习得中起着核心作用，但这一领域仍未得到充分探索。

Method: 研究人员训练了自监督语音模型（S3Ms），通过改变二语（L2）训练的开始时间（L2 exposure onset）和一语（L1）训练的结束时间（L1 exposure offset），并在儿童导向的语音数据上进行训练。随后，他们评估了这些模型在音素判别任务上的表现。

Result: 研究发现S3Ms没有表现出明显的、与人类相似的语音习得中的关键期效应。具体而言，延迟二语暴露开始的模型在二语表现上反而更好，而延迟一语暴露结束则导致了一语的遗忘。

Conclusion: 自监督语音模型在语音习得方面不展现出与人类语言习得相似的关键期效应。与人类观察到的现象相反，这些模型在延迟二语暴露时表现更佳，且延迟的一语暴露结束可能导致一语遗忘。

Abstract: This paper investigates whether the Critical Period (CP) effects in human
language acquisition are observed in self-supervised speech models (S3Ms). CP
effects refer to greater difficulty in acquiring a second language (L2) with
delayed L2 exposure onset, and greater retention of their first language (L1)
with delayed L1 exposure offset. While previous work has studied these effects
using textual language models, their presence in speech models remains
underexplored despite the central role of spoken language in human language
acquisition. We train S3Ms with varying L2 training onsets and L1 training
offsets on child-directed speech and evaluate their phone discrimination
performance. We find that S3Ms do not exhibit clear evidence of either CP
effects in terms of phonological acquisition. Notably, models with delayed L2
exposure onset tend to perform better on L2 and delayed L1 exposure offset
leads to L1 forgetting.

</details>


### [96] [Decoding Memories: An Efficient Pipeline for Self-Consistency Hallucination Detection](https://arxiv.org/abs/2508.21228)
*Weizhi Gao,Xiaorui Liu,Feiyi Wang,Dan Lu,Junqi Yin*

Main category: cs.CL

TL;DR: 本研究首次探讨了自洽性方法中的冗余（表现为生成中共享的前缀标记），并提出了一种名为“解码记忆管道”（DMP）的新型方法，通过选择性推理和退火解码来加速多响应生成，在不牺牲性能的情况下实现了高达3倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）存在幻觉问题。现有的幻觉检测方法在句子级别生成上表现不佳或高度依赖领域知识。自洽性方法虽能解决这些局限性，但由于重复生成而计算成本高昂。

Method: 本研究首先对自洽性方法中的冗余（即生成中共享的前缀标记）进行了首次研究，并观察到非精确答案标记对语义内容的贡献极小。基于这些发现，论文提出了一种新颖的“解码记忆管道”（DMP），通过选择性推理和退火解码来加速生成。DMP独立于模型、数据集、解码策略和自洽性基线。

Result: DMP持续提高了多响应生成的效率，实现了高达3倍的速度提升，同时没有牺牲AUROC性能。该方法还有望扩展到对齐和推理任务。

Conclusion: 通过识别自洽性方法中的冗余并利用选择性推理和退火解码，所提出的解码记忆管道（DMP）显著提高了多响应生成的效率，在幻觉检测等任务中实现了显著加速，且不影响性能，并具有广泛的应用潜力。

Abstract: Large language models (LLMs) have demonstrated impressive performance in both
research and real-world applications, but they still struggle with
hallucination. Existing hallucination detection methods often perform poorly on
sentence-level generation or rely heavily on domain-specific knowledge. While
self-consistency approaches help address these limitations, they incur high
computational costs due to repeated generation. In this paper, we conduct the
first study on identifying redundancy in self-consistency methods, manifested
as shared prefix tokens across generations, and observe that non-exact-answer
tokens contribute minimally to the semantic content. Based on these insights,
we propose a novel Decoding Memory Pipeline (DMP) that accelerates generation
through selective inference and annealed decoding. Being orthogonal to the
model, dataset, decoding strategy, and self-consistency baseline, our DMP
consistently improves the efficiency of multi-response generation and holds
promise for extension to alignment and reasoning tasks. Extensive experiments
show that our method achieves up to a 3x speedup without sacrificing AUROC
performance.

</details>


### [97] [Efficient Code Embeddings from Code Generation Models](https://arxiv.org/abs/2508.21290)
*Daria Kryvosheieva,Saba Sturua,Michael Günther,Scott Martens,Han Xiao*

Main category: cs.CL

TL;DR: Jina-code-embeddings 是一个新颖的代码嵌入模型套件，利用预训练的自回归骨干网络和末尾标记池化技术，在代码检索、问答和跨语言相似性识别任务上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一个能够从自然语言查询中检索代码、执行技术问答以及识别跨编程语言语义相似代码片段的模型。

Method: 该模型创新性地使用了在文本和代码上预训练的自回归骨干网络，并通过末尾标记池化（last-token pooling）生成嵌入。论文概述了其训练方法。

Result: 尽管模型规模相对较小，但Jina-code-embeddings 在各项任务上展现了最先进（state-of-the-art）的性能。

Conclusion: 该研究验证了这种代码嵌入模型构建方法是有效且成功的，能够以较小的模型实现卓越的性能。

Abstract: jina-code-embeddings is a novel code embedding model suite designed to
retrieve code from natural language queries, perform technical
question-answering, and identify semantically similar code snippets across
programming languages. It makes innovative use of an autoregressive backbone
pre-trained on both text and code, generating embeddings via last-token
pooling. We outline the training recipe and demonstrate state-of-the-art
performance despite the relatively small size of the models, validating this
approach to code embedding model construction.

</details>


### [98] [BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning](https://arxiv.org/abs/2508.21294)
*João Guilherme Alves Santos,Giovana Kerche Bonás,Thales Sales Almeida*

Main category: cs.CL

TL;DR: 本文介绍了BLUEX数据集的更新版本，增加了2024-2025年考试内容和自动生成的图像字幕，以增强其在多语言LLM评估和数据污染研究中的相关性，并通过评估LLM来验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）能力的增长，对鲁棒评估方法的需求也日益增加，尤其是在多语言和非英语环境中。此外，研究LLM预训练中的数据污染问题也是一个重要动机。

Method: 研究人员更新了BLUEX数据集，纳入了2024-2025年的考试内容。他们使用最先进的模型自动生成图像字幕，以提高文本模型对视觉内容的访问能力。随后，评估了商业和开源LLM利用通过字幕提供的视觉上下文的能力。

Result: 字幕策略使文本模型的可访问性提高了40%以上，产生了1,422个可用问题，是原始BLUEX数量的两倍多。这显著增强了数据集对LLM预训练中数据污染研究的相关性。

Conclusion: 更新后的BLUEX数据集（包含最新考试和自动生成的图像字幕）极大地提升了多语言LLM评估和数据污染研究的能力，通过字幕使视觉上下文对纯文本模型更易于访问。

Abstract: With the growing capabilities of Large Language Models (LLMs), there is an
increasing need for robust evaluation methods, especially in multilingual and
non-English contexts. We present an updated version of the BLUEX dataset, now
including 2024-2025 exams and automatically generated image captions using
state-of-the-art models, enhancing its relevance for data contamination studies
in LLM pretraining. Captioning strategies increase accessibility to text-only
models by more than 40%, producing 1,422 usable questions, more than doubling
the number in the original BLUEX. We evaluated commercial and open-source LLMs
and their ability to leverage visual context through captions.

</details>


### [99] [Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models](https://arxiv.org/abs/2508.21377)
*Shubham Sharma,Sneha Tuli,Narendra Badam*

Main category: cs.CL

TL;DR: 该调查回顾了构建和使用大型语言模型（LLMs）的16个关键挑战，并通过比较OpenAI的GPT-4o（闭源）和DeepSeek-V3-0324（开源MoE模型）来探讨解决方案、权衡和不同应用场景下的模型适用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的开发和部署仍然复杂，需要深入理解其能力、局限性及最佳实践，以指导AI研究人员、开发者和决策者。

Method: 通过审查16个关键挑战，并比较两种最先进的模型（OpenAI的闭源GPT-4o和开源的DeepSeek-V3-0324 MoE模型）如何应对这些挑战，同时探索LLM在不同领域的应用。

Result: 研究展示了闭源模型（鲁棒安全性、精细调优的可靠性）和开源模型（效率、适应性）之间的权衡，并指出哪些模型属性最适合特定的用例，涵盖从聊天机器人到医疗和教育等应用领域。

Conclusion: 本文旨在帮助AI研究人员、开发者和决策者理解当前LLM的能力、局限性及最佳实践，从而更好地应对LLM的开发和部署挑战。

Abstract: Large Language Models (LLMs) are transforming AI across industries, but their
development and deployment remain complex. This survey reviews 16 key
challenges in building and using LLMs and examines how these challenges are
addressed by two state-of-the-art models with unique approaches: OpenAI's
closed source GPT-4o (May 2024 update) and DeepSeek-V3-0324 (March 2025), a
large open source Mixture-of-Experts model. Through this comparison, we
showcase the trade-offs between closed source models (robust safety, fine-tuned
reliability) and open source models (efficiency, adaptability). We also explore
LLM applications across different domains (from chatbots and coding tools to
healthcare and education), highlighting which model attributes are best suited
for each use case. This article aims to guide AI researchers, developers, and
decision-makers in understanding current LLM capabilities, limitations, and
best practices.

</details>


### [100] [Normality and the Turing Test](https://arxiv.org/abs/2508.21382)
*Alexandre Kabbach*

Main category: cs.CL

TL;DR: 本文通过“常态”概念重新审视图灵测试，认为该测试旨在评估机器是否能展现出常态人类智能（包括犯错），并由多名评委的平均判断来衡量。据此，大型语言模型（如ChatGPT）因追求卓越而非常态智能，可能无法通过图灵测试，它们代表的是“人工聪明”而非真正意义上的“人工智能”。


<details>
  <summary>Details</summary>
Motivation: 重新审视图灵测试，并提出通过“常态”（在规范和数学意义上理解为平均）概念来深入理解其核心论点，尤其是在当前大型语言模型兴起的背景下。

Method: 概念分析法，通过对“常态”一词的统计学和规范性解释，重新解读图灵测试的两个方面：一是其评估目标是常态人类智能，二是其判断机制是一个统计性测试，由多位评委的平均判断构成。

Result: 1. 图灵测试旨在评估常态/平均人类智能，要求机器能像普通人一样犯错和表现出不完美行为。2. 图灵测试是一个统计性测试，智能判断由一个评委团而非单一“平均”评委完成，“平均人类提问者”指的是多个个体判断的标准化集合。3. 大型语言模型（如ChatGPT）不太可能通过图灵测试，因为它们追求的是卓越而非常态/平均人类智能，因此它们是“人工聪明”而非“人工智能”。4. 图灵测试能否有助于理解人类认知，取决于人类心智是否能简化为常态/平均心智，这超出了图灵测试本身的范畴。

Conclusion: 1. 大型语言模型（如ChatGPT）代表的是“人工聪明”而非“人工智能”，它们不太可能通过基于常态智能评估的图灵测试。2. 图灵测试对人类认知的贡献，最终取决于人类心智是否真的能简化为常态/平均心智，这触及了常态主义范式的概念基础。

Abstract: This paper proposes to revisit the Turing test through the concept of
normality. Its core argument is that the statistical interpretation of the
normal--understood as the average both in the normative and mathematical sense
of the term--proves useful for understanding the Turing test in at least two
ways. First, in the sense that the Turing test targets normal/average rather
than exceptional human intelligence, so that successfully passing the test
requires building machines that "make mistakes" and display imperfect behavior
just like normal/average humans. Second, in the sense that the Turing test is a
statistical test where judgments of intelligence are never carried out by a
single "average" judge (understood as non-expert) but always by a full jury. As
such, the notion of "average human interrogator" that Turing talks about in his
original paper should be understood primarily as referring to a mathematical
abstraction made of the normalized aggregate of individual judgments of
multiple judges. In short, this paper argues that the Turing test is a test of
normal intelligence as assessed by a normal judge characterizing the average
judgment of a pool of human interrogators. Its conclusions are twofold. First,
it argues that large language models such as ChatGPT are unlikely to pass the
Turing test as those models precisely target exceptional rather than
normal/average human intelligence. As such, they constitute models of what it
proposes to call artificial smartness rather than artificial intelligence per
se. Second, it argues that the core question of whether the Turing test can
contribute anything to the understanding of human cognition is that of whether
the human mind is really reducible to the normal/average mind--a question which
largely extends beyond the Turing test itself and questions the conceptual
underpinnings of the normalist paradigm it belongs to.

</details>


### [101] [AllSummedUp: un framework open-source pour comparer les metriques d'evaluation de resume](https://arxiv.org/abs/2508.21389)
*Tanguy Herserant,Vincent Guigue*

Main category: cs.CL

TL;DR: 本文调查了自动文本摘要评估中的可重现性挑战，发现现有指标（特别是基于LLM的）存在显著差异和稳定性问题，并提出了一个统一的开源框架，呼吁更严格的评估协议。


<details>
  <summary>Details</summary>
Motivation: 文献中报告的自动文本摘要评估指标性能与实际观察到的性能之间存在显著差异，尤其是在经典方法和新兴的基于大型语言模型（LLM）的方法之间，这促使研究者寻求更公平透明的比较和对可重现性问题的深入理解。

Method: 研究人员在六种代表性评估指标（从ROUGE等经典方法到G-Eval、SEval-Ex等LLM-based方法）上进行了实验。他们引入了一个统一的开源框架，并将其应用于SummEval数据集，旨在支持评估指标的公平透明比较。

Result: 实验结果显示，文献中报告的性能与实际观察到的性能之间存在显著差异。研究揭示了一个结构性权衡：与人类判断对齐度最高的指标往往计算密集且跨运行稳定性较差。此外，研究强调了依赖LLM进行评估的关键担忧，包括其随机性、技术依赖性和有限的可重现性。

Conclusion: 为了确保自动摘要评估的更高可靠性，研究呼吁采用更稳健的评估协议，包括详尽的文档和方法论标准化。强调了对LLM评估方法可重现性问题的关注，并建议改进实践。

Abstract: This paper investigates reproducibility challenges in automatic text
summarization evaluation. Based on experiments conducted across six
representative metrics ranging from classical approaches like ROUGE to recent
LLM-based methods (G-Eval, SEval-Ex), we highlight significant discrepancies
between reported performances in the literature and those observed in our
experimental setting. We introduce a unified, open-source framework, applied to
the SummEval dataset and designed to support fair and transparent comparison of
evaluation metrics. Our results reveal a structural trade-off: metrics with the
highest alignment with human judgments tend to be computationally intensive and
less stable across runs. Beyond comparative analysis, this study highlights key
concerns about relying on LLMs for evaluation, stressing their randomness,
technical dependencies, and limited reproducibility. We advocate for more
robust evaluation protocols including exhaustive documentation and
methodological standardization to ensure greater reliability in automatic
summarization assessment.

</details>


### [102] [Automatic Reviewers Fail to Detect Faulty Reasoning in Research Papers: A New Counterfactual Evaluation Framework](https://arxiv.org/abs/2508.21422)
*Nils Dycke,Iryna Gurevych*

Main category: cs.CL

TL;DR: 研究发现，大语言模型（LLMs）作为自动审稿生成器（ARGs）在检测论文研究逻辑缺陷（如结果与解释不一致）方面表现不佳，其输出审稿不受逻辑缺陷影响。


<details>
  <summary>Details</summary>
Motivation: LLMs在学术同行评审中潜力巨大，但作为自动审稿生成器（ARGs）可能引入偏见和系统性错误，对科学诚信构成风险。因此，理解当前ARGs在检测高质量同行评审核心技能——研究逻辑缺陷（即结果、解释和主张之间的内部一致性）方面的能力和局限性至关重要。

Method: 提出了一种全自动的反事实评估框架，在受控条件下隔离并测试了ARGs检测研究逻辑缺陷的能力。该框架通过测试一系列ARG方法来评估其性能。

Result: 与预期相反，研究发现论文中研究逻辑缺陷的存在对ARGs生成的审稿输出没有显著影响，表明ARGs未能有效识别这些缺陷。

Conclusion: 当前ARGs无法有效检测研究逻辑缺陷。基于此发现，论文提出了未来工作的三个可操作建议，并公开发布了反事实数据集和评估框架。

Abstract: Large Language Models (LLMs) have great potential to accelerate and support
scholarly peer review and are increasingly used as fully automatic review
generators (ARGs). However, potential biases and systematic errors may pose
significant risks to scientific integrity; understanding the specific
capabilities and limitations of state-of-the-art ARGs is essential. We focus on
a core reviewing skill that underpins high-quality peer review: detecting
faulty research logic. This involves evaluating the internal consistency
between a paper's results, interpretations, and claims. We present a fully
automated counterfactual evaluation framework that isolates and tests this
skill under controlled conditions. Testing a range of ARG approaches, we find
that, contrary to expectation, flaws in research logic have no significant
effect on their output reviews. Based on our findings, we derive three
actionable recommendations for future work and release our counterfactual
dataset and evaluation framework publicly.

</details>


### [103] [Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.21430)
*Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen*

Main category: cs.CL

TL;DR: Med-RewardBench是首个专门用于评估医学场景下多模态大语言模型(MLLM)奖励模型和判官的基准，旨在解决现有评估方法在诊断准确性和临床相关性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在医疗应用中潜力巨大，但需要高度准确、情境敏感和专业对齐的响应。现有的医学奖励模型和判官研究不足，缺乏专门针对临床需求的基准，无法有效评估诊断准确性和临床相关性。

Method: 引入了Med-RewardBench基准，包含一个涵盖13个器官系统和8个临床科室的多模态数据集，共1,026个专家标注病例。采用严格的三步流程，确保在六个关键临床维度上获得高质量评估数据。评估了32个最先进的MLLM，并开发了通过微调显著提高性能的基线模型。

Result: 评估结果揭示了现有MLLM在将输出与专家判断对齐方面存在巨大挑战。通过微调开发的基线模型展示了显著的性能提升。

Conclusion: Med-RewardBench填补了医学领域奖励模型和判官评估基准的空白，揭示了当前MLLM在医学对齐方面的不足，并为未来模型的改进提供了方向和基线。

Abstract: Multimodal large language models (MLLMs) hold significant potential in
medical applications, including disease diagnosis and clinical decision-making.
However, these tasks require highly accurate, context-sensitive, and
professionally aligned responses, making reliable reward models and judges
critical. Despite their importance, medical reward models (MRMs) and judges
remain underexplored, with no dedicated benchmarks addressing clinical
requirements. Existing benchmarks focus on general MLLM capabilities or
evaluate models as solvers, neglecting essential evaluation dimensions like
diagnostic accuracy and clinical relevance. To address this, we introduce
Med-RewardBench, the first benchmark specifically designed to evaluate MRMs and
judges in medical scenarios. Med-RewardBench features a multimodal dataset
spanning 13 organ systems and 8 clinical departments, with 1,026
expert-annotated cases. A rigorous three-step process ensures high-quality
evaluation data across six clinically critical dimensions. We evaluate 32
state-of-the-art MLLMs, including open-source, proprietary, and
medical-specific models, revealing substantial challenges in aligning outputs
with expert judgment. Additionally, we develop baseline models that demonstrate
substantial performance improvements through fine-tuning.

</details>


### [104] [Discovering Semantic Subdimensions through Disentangled Conceptual Representations](https://arxiv.org/abs/2508.21436)
*Yunhao Zhang,Shaonan Wang,Nan Lin,Xinyi Dong,Chong Li,Chengqing Zong*

Main category: cs.CL

TL;DR: 本文提出了一种名为DCSRM的新框架，用于从大型语言模型的词嵌入中解耦出更细粒度的语义子维度，并通过脑激活数据验证了其神经合理性，揭示了极性在语义维度分解中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 现有的语义维度方法依赖于预定义且宽泛的表示，忽略了概念上的精细区别。研究的动机在于深入理解语言和大脑中意义的组织方式，并发现粗粒度语义维度下的子维度。

Method: 引入了“解耦连续语义表示模型（Disentangled Continuous Semantic Representation Model, DCSRM）”，该模型将词嵌入分解为多个子嵌入，每个子嵌入编码特定的语义信息。利用这些子嵌入识别可解释的语义子维度。通过体素级编码模型将这些子维度映射到大脑激活，以评估其神经合理性。

Result: 研究识别出更细粒度、可解释的语义子维度。分析显示语义维度根据不同原则构建，其中“极性”是驱动其分解为子维度的关键因素。识别出的子维度的神经关联支持了其认知和神经科学的合理性。

Conclusion: 该工作提供了一个研究概念意义更细粒度可解释语义子维度的新框架，并揭示了语义维度结构的不同原则，特别是极性在维度分解中的重要作用，且这些子维度具有神经合理性。

Abstract: Understanding the core dimensions of conceptual semantics is fundamental to
uncovering how meaning is organized in language and the brain. Existing
approaches often rely on predefined semantic dimensions that offer only broad
representations, overlooking finer conceptual distinctions. This paper proposes
a novel framework to investigate the subdimensions underlying coarse-grained
semantic dimensions. Specifically, we introduce a Disentangled Continuous
Semantic Representation Model (DCSRM) that decomposes word embeddings from
large language models into multiple sub-embeddings, each encoding specific
semantic information. Using these sub-embeddings, we identify a set of
interpretable semantic subdimensions. To assess their neural plausibility, we
apply voxel-wise encoding models to map these subdimensions to brain
activation. Our work offers more fine-grained interpretable semantic
subdimensions of conceptual meaning. Further analyses reveal that semantic
dimensions are structured according to distinct principles, with polarity
emerging as a key factor driving their decomposition into subdimensions. The
neural correlates of the identified subdimensions support their cognitive and
neuroscientific plausibility.

</details>


### [105] [Beyond the Surface: Probing the Ideological Depth of Large Language Models](https://arxiv.org/abs/2508.21448)
*Shariar Kabir,Kevin Esterling,Yue Dong*

Main category: cs.CL

TL;DR: 本文研究大型语言模型（LLMs）的“意识形态深度”，发现其是可量化的属性，与内部政治表征的鲁棒性和复杂性相关，并可通过可操纵性和内部特征分析进行衡量。


<details>
  <summary>Details</summary>
Motivation: LLMs表现出明显的意识形态倾向，但这些立场的稳定性和深度尚不清楚。表面响应容易通过提示工程操纵，这引发了对其是否反映连贯底层意识形态的质疑。因此，有必要深入理解LLMs的“意识形态深度”。

Method: 本文定义“意识形态深度”为LLMs内部政治表征的鲁棒性和复杂性。研究采用双重方法：1. 测量两个开源LLMs的“可操纵性”，通过指令提示和激活引导实现。2. 使用稀疏自编码器（SAEs）探测模型的内部机制。

Result: 研究发现，一些模型易于在自由派和保守派观点之间切换，而另一些则表现出抵抗或拒绝率增加，表明其意识形态结构更为根深蒂固。初步SAE分析显示，可操纵性较低的模型拥有更独特和抽象的意识形态特征，一个模型比同等大小的另一个模型多7.3倍的政治特征。对“深层”模型的核心政治特征进行靶向消融，可导致其推理在相关主题上发生一致、逻辑性的转变；而对“浅层”模型进行相同干预，则导致拒绝输出增加。

Conclusion: 研究结果表明，意识形态深度是LLMs的一个可量化属性，并且可操纵性是理解其潜在政治架构的宝贵窗口。

Abstract: Large Language Models (LLMs) have demonstrated pronounced ideological
leanings, yet the stability and depth of these positions remain poorly
understood. Surface-level responses can often be manipulated through simple
prompt engineering, calling into question whether they reflect a coherent
underlying ideology. This paper investigates the concept of "ideological depth"
in LLMs, defined as the robustness and complexity of their internal political
representations. We employ a dual approach: first, we measure the
"steerability" of two well-known open-source LLMs using instruction prompting
and activation steering. We find that while some models can easily switch
between liberal and conservative viewpoints, others exhibit resistance or an
increased rate of refusal, suggesting a more entrenched ideological structure.
Second, we probe the internal mechanisms of these models using Sparse
Autoencoders (SAEs). Preliminary analysis reveals that models with lower
steerability possess more distinct and abstract ideological features. Our
evaluations reveal that one model can contain 7.3x more political features than
another model of similar size. This allows targeted ablation of a core
political feature in an ideologically "deep" model, leading to consistent,
logical shifts in its reasoning across related topics, whereas the same
intervention in a "shallow" model results in an increase in refusal outputs.
Our findings suggest that ideological depth is a quantifiable property of LLMs
and that steerability serves as a valuable window into their latent political
architecture.

</details>


### [106] [Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards](https://arxiv.org/abs/2508.21476)
*Xiaolong Wei,Bo Lu,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin*

Main category: cs.CL

TL;DR: 本研究通过RLAIF框架，探索了两种AI驱动的奖励策略，以提升小型语言模型（SLM）在生成中文问候语方面的创造性，发现基于原则引导的LLM-as-a-Judge方法效果最佳，且效率更高。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的创意写作能力虽强，但计算成本高昂。小型语言模型（SLMs）是替代方案，但现有方法如SFT缺乏新颖性，RLHF成本过高。因此，需要更有效且低成本的方法来激发SLMs的创造力。

Method: 本研究在RLAIF框架下，为7B参数的SLM（用于生成中文问候语）探索了两种AI驱动的奖励策略：1. 使用基于多智能体拒绝采样框架生成的高质量偏好数据训练的奖励模型（RM）。2. 一种更具创新性的策略，利用基于原则引导的LLM-as-a-Judge，其奖励函数通过带有反思机制的对抗性训练方案进行优化，直接提供奖励信号。

Result: 实验结果表明，两种方法都显著提升了基线模型的创意输出。其中，基于原则引导的LLM-as-a-Judge方法在生成质量上表现更优，并在训练效率和对人工标注数据的依赖性方面具有显著优势。此外，其自动化评估方法与人类判断高度一致。

Conclusion: 基于原则引导的LLM-as-a-Judge方法为实现具有创造力的小型语言模型提供了一条更具可扩展性和有效性的途径，它不仅能产出更高质量的内容，还能提高训练效率并减少对人工标注数据的需求。

Abstract: Large Language Models (LLMs) have demonstrated remarkable creative writing
capabilities, yet their substantial computational demands hinder widespread
use. Enhancing Small Language Models (SLMs) offers a promising alternative, but
current methods like Supervised Fine-Tuning (SFT) struggle with novelty, and
Reinforcement Learning from Human Feedback (RLHF) is costly. This paper
explores two distinct AI-driven reward strategies within a Reinforcement
Learning from AI Feedback (RLAIF) framework to ignite the creative writing of a
7B-parameter SLM, specifically for generating Chinese greetings. The first
strategy employs a RM trained on high-quality preference data curated by a
novel multi-agent rejection sampling framework designed for creative tasks. The
second, more novel strategy utilizes a principle-guided LLM-as-a-Judge, whose
reward function is optimized via an adversarial training scheme with a
reflection mechanism, to directly provide reward signals. Comprehensive
experiments reveal that while both approaches significantly enhance creative
output over baselines, the principle-guided LLM-as-a-Judge demonstrably yields
superior generation quality. Furthermore, it offers notable advantages in
training efficiency and reduced dependency on human-annotated data, presenting
a more scalable and effective path towards creative SLMs. Our automated
evaluation methods also exhibit strong alignment with human judgments. Our code
and data are publicly available at
https://github.com/weixiaolong94-hub/Igniting-Creative-Writing-in-Small-Language-Models.

</details>


### [107] [HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble](https://arxiv.org/abs/2508.21482)
*Sara B. Coutinho,Rafael M. O. Cruz,Francimaria R. S. Nascimento,George D. C. Cavalcanti*

Main category: cs.CL

TL;DR: 本文提出了一种名为HierarchySelect的新型自动分类器选择方法，旨在通过优先考虑多样性和性能来改进集成学习系统，以有效应对假新闻检测中的挑战。


<details>
  <summary>Details</summary>
Motivation: 心理偏见导致假新闻在社交媒体上广泛传播，对公共卫生和政治产生严重影响。机器学习事实核查系统，尤其是集成方法，在缓解此问题上表现出色，但其性能高度依赖于组成分类器的多样性。选择真正多样化的模型是一个关键挑战，尤其当模型倾向于学习冗余模式时。

Method: 该方法首先计算分类器之间的成对多样性，并应用层次聚类将它们组织成不同粒度级别的组。然后，一个名为HierarchySelect的机制探索这些层次级别，为每个级别选择一个分类器池，每个池代表不同的池内多样性。从中识别并选择最具多样性的池用于集成构建。选择过程还纳入了反映每个分类器性能的评估指标，以确保集成具有良好的泛化能力。

Result: 研究使用来自不同应用领域和不同类别数量的六个数据集，对40个异构分类器进行了实验。与Elbow启发式方法和最先进的基线方法相比，本文提出的方法在六个数据集中的两个上实现了最高的准确率。

Conclusion: 所提出的自动分类器选择方法通过有效结合多样性和性能，显著改进了集成学习系统在假新闻检测中的表现，尤其在处理模型多样性挑战方面展现出优越性。

Abstract: Psychological biases, such as confirmation bias, make individuals
particularly vulnerable to believing and spreading fake news on social media,
leading to significant consequences in domains such as public health and
politics. Machine learning-based fact-checking systems have been widely studied
to mitigate this problem. Among them, ensemble methods are particularly
effective in combining multiple classifiers to improve robustness. However,
their performance heavily depends on the diversity of the constituent
classifiers-selecting genuinely diverse models remains a key challenge,
especially when models tend to learn redundant patterns. In this work, we
propose a novel automatic classifier selection approach that prioritizes
diversity, also extended by performance. The method first computes pairwise
diversity between classifiers and applies hierarchical clustering to organize
them into groups at different levels of granularity. A HierarchySelect then
explores these hierarchical levels to select one pool of classifiers per level,
each representing a distinct intra-pool diversity. The most diverse pool is
identified and selected for ensemble construction from these. The selection
process incorporates an evaluation metric reflecting each classifiers's
performance to ensure the ensemble also generalises well. We conduct
experiments with 40 heterogeneous classifiers across six datasets from
different application domains and with varying numbers of classes. Our method
is compared against the Elbow heuristic and state-of-the-art baselines. Results
show that our approach achieves the highest accuracy on two of six datasets.
The implementation details are available on the project's repository:
https://github.com/SaraBCoutinho/HSFN .

</details>


### [108] [L3Cube-MahaSTS: A Marathi Sentence Similarity Dataset and Models](https://arxiv.org/abs/2508.21569)
*Aishwarya Mirashi,Ananya Joshi,Raviraj Joshi*

Main category: cs.CL

TL;DR: 本文提出了MahaSTS，一个用于马拉地语的人工标注句子文本相似度（STS）数据集，以及MahaSBERT-STS-v2，一个针对回归相似度评分优化的微调Sentence-BERT模型。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言环境下，需要高质量的句子文本相似度数据集和模型来支持马拉地语的STS任务。

Method: 构建了包含16,860对马拉地语句子的人工标注MahaSTS数据集，相似度分数范围为0-5，并确保了分数在不同区间内的均匀分布。在此数据集上微调了MahaSBERT模型，并将其性能与MahaBERT、MuRIL、IndicBERT和IndicSBERT等其他模型进行了基准测试。

Result: 实验证明，MahaSTS数据集能够有效训练马拉地语的句子相似度任务。研究强调了在低资源环境中，人工标注、有针对性的微调和结构化监督对模型性能的重要性。

Conclusion: MahaSTS数据集和MahaSBERT-STS-v2模型为马拉地语的句子相似度任务提供了有效的训练资源，并突出了高质量标注和微调在低资源语言处理中的关键作用。

Abstract: We present MahaSTS, a human-annotated Sentence Textual Similarity (STS)
dataset for Marathi, along with MahaSBERT-STS-v2, a fine-tuned Sentence-BERT
model optimized for regression-based similarity scoring. The MahaSTS dataset
consists of 16,860 Marathi sentence pairs labeled with continuous similarity
scores in the range of 0-5. To ensure balanced supervision, the dataset is
uniformly distributed across six score-based buckets spanning the full 0-5
range, thus reducing label bias and enhancing model stability. We fine-tune the
MahaSBERT model on this dataset and benchmark its performance against other
alternatives like MahaBERT, MuRIL, IndicBERT, and IndicSBERT. Our experiments
demonstrate that MahaSTS enables effective training for sentence similarity
tasks in Marathi, highlighting the impact of human-curated annotations,
targeted fine-tuning, and structured supervision in low-resource settings. The
dataset and model are publicly shared at
https://github.com/l3cube-pune/MarathiNLP

</details>


### [109] [A Survey on Current Trends and Recent Advances in Text Anonymization](https://arxiv.org/abs/2508.21587)
*Tobias Deußer,Lorenz Sparrenberg,Armin Berger,Max Hahnbück,Christian Bauckhage,Rafet Sifa*

Main category: cs.CL

TL;DR: 这篇综述全面概述了文本匿名化技术的当前趋势和最新进展，涵盖了从基础方法到大型语言模型的作用、特定领域挑战、高级方法及评估框架，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着包含敏感个人信息的文本数据在各领域激增，需要强大的匿名化技术来保护隐私、遵守法规，同时保持数据对下游任务的可用性。

Method: 本研究通过综述的方式，讨论了文本匿名化的基础方法（主要围绕命名实体识别）、大型语言模型（作为匿名器和去匿名化威胁的双重角色）、关键领域的特定挑战和解决方案（如医疗、法律、金融、教育）、结合形式化隐私模型和风险感知框架的先进方法、作者身份匿名化子领域，并回顾了评估框架、指标、基准和实用工具包。

Result: 综述整合了当前知识，识别了新兴趋势和持续挑战，包括不断演变的隐私-效用权衡、处理准标识符的需求以及大型语言模型能力的影响。它还提供了在文本匿名化领域学术界和从业者的未来研究方向。

Conclusion: 本综述旨在通过整合现有知识、识别趋势和挑战，为文本匿名化领域的未来研究提供指导，以应对数据隐私保护和可用性之间的平衡问题。

Abstract: The proliferation of textual data containing sensitive personal information
across various domains requires robust anonymization techniques to protect
privacy and comply with regulations, while preserving data usability for
diverse and crucial downstream tasks. This survey provides a comprehensive
overview of current trends and recent advances in text anonymization
techniques. We begin by discussing foundational approaches, primarily centered
on Named Entity Recognition, before examining the transformative impact of
Large Language Models, detailing their dual role as sophisticated anonymizers
and potent de-anonymization threats. The survey further explores
domain-specific challenges and tailored solutions in critical sectors such as
healthcare, law, finance, and education. We investigate advanced methodologies
incorporating formal privacy models and risk-aware frameworks, and address the
specialized subfield of authorship anonymization. Additionally, we review
evaluation frameworks, comprehensive metrics, benchmarks, and practical
toolkits for real-world deployment of anonymization solutions. This review
consolidates current knowledge, identifies emerging trends and persistent
challenges, including the evolving privacy-utility trade-off, the need to
address quasi-identifiers, and the implications of LLM capabilities, and aims
to guide future research directions for both academics and practitioners in
this field.

</details>


### [110] [Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning](https://arxiv.org/abs/2508.21589)
*Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu*

Main category: cs.CL

TL;DR: Middo是一个自演进的模型感知动态数据优化框架，通过模型诊断和自适应优化，持续提升SFT大型语言模型的训练数据质量和模型性能。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）大型语言模型（LLM）严重依赖高质量训练数据，但现有数据选择和合成方法通常是静态的，无法适应模型能力的变化。

Method: Middo框架建立了一个闭环优化系统：1) 自我诊断模块通过损失模式（复杂性）、嵌入聚类动态（多样性）和自对齐分数（质量）识别次优样本；2) 自适应优化引擎在保持语义完整性的前提下将次优样本转化为有价值的训练点；3) 优化过程通过动态学习原则随模型能力持续演进。

Result: 实验表明，Middo持续提升了原始数据质量，平均将LLM的准确性提高了7.15%，同时保持了数据集规模。

Conclusion: 该工作为通过数据和模型的动态人机协同演进，建立了可持续LLM训练的新范式。

Abstract: Supervised Fine-Tuning (SFT) Large Language Models (LLM) fundamentally rely
on high-quality training data. While data selection and data synthesis are two
common strategies to improve data quality, existing approaches often face
limitations in static dataset curation that fail to adapt to evolving model
capabilities. In this paper, we introduce Middo, a self-evolving Model-informed
dynamic data optimization framework that uses model-aware data selection and
context-preserving data refinement. Unlike conventional one-off
filtering/synthesis methods, our framework establishes a closed-loop
optimization system: (1) A self-referential diagnostic module proactively
identifies suboptimal samples through tri-axial model signals - loss patterns
(complexity), embedding cluster dynamics (diversity), and self-alignment scores
(quality); (2) An adaptive optimization engine then transforms suboptimal
samples into pedagogically valuable training points while preserving semantic
integrity; (3) This optimization process continuously evolves with model
capability through dynamic learning principles. Experiments on multiple
benchmarks demonstrate that our \method consistently enhances the quality of
seed data and boosts LLM's performance with improving accuracy by 7.15% on
average while maintaining the original dataset scale. This work establishes a
new paradigm for sustainable LLM training through dynamic human-AI co-evolution
of data and models. Our datasets, models, and code are coming soon.

</details>


### [111] [Personality Matters: User Traits Predict LLM Preferences in Multi-Turn Collaborative Tasks](https://arxiv.org/abs/2508.21628)
*Sarfaroz Yunusov,Kaige Chen,Kazi Nishat Anwar,Ali Emami*

Main category: cs.CL

TL;DR: 本研究发现，用户个性特质（如Keirsey类型）显著影响其对大型语言模型（如GPT-4和Claude 3.5）的偏好，尤其是在不同协作任务中。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）日益融入日常工作流程，用户通过多轮协作塑造结果，研究者们提出了一个关键问题：不同个性特质的用户是否系统性地偏好某些LLMs而非其他？

Method: 研究招募了32名参与者，他们均匀分布于四种Keirsey个性类型。参与者评估了与GPT-4和Claude 3.5在四种协作任务（数据分析、创意写作、信息检索和写作辅助）中的互动。研究还对定性反馈进行了情感分析。

Result: 结果显示出显著的个性驱动偏好：理性者（Rationals）强烈偏好GPT-4，尤其是在目标导向任务中；理想主义者（Idealists）则偏爱Claude 3.5，特别是在创意和分析任务中。其他个性类型表现出任务依赖的偏好。定性反馈的情感分析证实了这些模式。值得注意的是，模型的总体有用性评分相似，这表明基于个性的分析揭示了传统评估所忽视的LLM差异。

Conclusion: 用户个性特质在LLM偏好中扮演关键角色，基于个性的分析能够揭示传统评估方法无法捕捉到的LLM间差异。

Abstract: As Large Language Models (LLMs) increasingly integrate into everyday
workflows, where users shape outcomes through multi-turn collaboration, a
critical question emerges: do users with different personality traits
systematically prefer certain LLMs over others? We conducted a study with 32
participants evenly distributed across four Keirsey personality types,
evaluating their interactions with GPT-4 and Claude 3.5 across four
collaborative tasks: data analysis, creative writing, information retrieval,
and writing assistance. Results revealed significant personality-driven
preferences: Rationals strongly preferred GPT-4, particularly for goal-oriented
tasks, while idealists favored Claude 3.5, especially for creative and
analytical tasks. Other personality types showed task-dependent preferences.
Sentiment analysis of qualitative feedback confirmed these patterns. Notably,
aggregate helpfulness ratings were similar across models, showing how
personality-based analysis reveals LLM differences that traditional evaluations
miss.

</details>


### [112] [QZhou-Embedding Technical Report](https://arxiv.org/abs/2508.21632)
*Peng Yu,En Xu,Bin Chen,Haibiao Chen,Yinfei Xu*

Main category: cs.CL

TL;DR: QZhou-Embedding是一种基于Qwen2.5-7B-Instruct的通用上下文文本嵌入模型，通过统一多任务框架、多样化数据转换和两阶段训练策略，在MTEB和CMTEB基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个具有卓越文本表示能力的通用上下文文本嵌入模型，并探索高质量、多样化数据对检索模型性能提升的重要性。

Method: 该模型基于Qwen2.5-7B-Instruct基础模型，设计了一个统一的多任务框架，包括专门的数据转换和训练策略。数据转换方案允许整合更多样化的文本训练数据集。利用LLM API开发了数据合成管线，包含释义、增强和难负例生成。采用两阶段训练策略：先进行以检索为重点的预训练，然后进行全任务微调。

Result: QZhou-Embedding在MTEB和CMTEB基准测试中均取得最先进结果，排名第一（截至2025年8月27日），并在重排序、聚类等任务上同时实现最先进性能。

Conclusion: 更高质量、更多样化的数据对于提升检索模型性能至关重要，并且利用大型语言模型（LLMs）的生成能力可以进一步优化数据质量，从而推动嵌入模型的突破。

Abstract: We present QZhou-Embedding, a general-purpose contextual text embedding model
with exceptional text representation capabilities. Built upon the
Qwen2.5-7B-Instruct foundation model, we designed a unified multi-task
framework comprising specialized data transformation and training strategies.
The data transformation scheme enables the incorporation of more diverse
textual training datasets, while the task-specific training strategies enhance
model learning efficiency. We developed a data synthesis pipeline leveraging
LLM API, incorporating techniques such as paraphrasing, augmentation, and hard
negative example generation to improve the semantic richness and sample
difficulty of the training set. Additionally, we employ a two-stage training
strategy, comprising initial retrieval-focused pretraining followed by
full-task fine-tuning, enabling the embedding model to extend its capabilities
based on robust retrieval performance. Our model achieves state-of-the-art
results on the MTEB and CMTEB benchmarks, ranking first on both leaderboards
(August 27 2025), and simultaneously achieves state-of-the-art performance on
tasks including reranking, clustering, etc. Our findings demonstrate that
higher-quality, more diverse data is crucial for advancing retrieval model
performance, and that leveraging LLMs generative capabilities can further
optimize data quality for embedding model breakthroughs. Our model weights are
released on HuggingFace under Apache 2.0 license. For reproducibility, we
provide evaluation code and instructions on GitHub.

</details>


### [113] [Is this chart lying to me? Automating the detection of misleading visualizations](https://arxiv.org/abs/2508.21675)
*Jonathan Tonglet,Jan Zimny,Tinne Tuytelaars,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文介绍了Misviz和Misviz-synth两个大型数据集，用于检测误导性数据可视化，并对现有AI模型进行了评估，结果显示该任务仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 误导性可视化是社交媒体和网络上虚假信息的重要来源，它们通过违反图表设计原则来扭曲数据，导致读者得出不准确的结论。先前的研究表明，人类和多模态大型语言模型（MLLMs）都容易被此类可视化欺骗。然而，由于缺乏大型、多样化且公开可用的数据集，AI模型的训练和评估受到了限制。

Method: 本研究引入了Misviz，一个包含2,604个真实世界可视化并标注了12种误导类型的数据集。为了支持模型训练，还发布了Misviz-synth，一个包含81,814个使用Matplotlib基于真实数据表生成的合成可视化数据集。研究人员使用最先进的MLLMs、基于规则的系统和微调分类器对这两个数据集进行了全面评估。

Result: 评估结果表明，检测误导性可视化并识别其违反的设计规则这一任务仍然极具挑战性。

Conclusion: 本研究发布了Misviz、Misviz-synth数据集及配套代码，旨在推动误导性可视化检测领域的研究进展。

Abstract: Misleading visualizations are a potent driver of misinformation on social
media and the web. By violating chart design principles, they distort data and
lead readers to draw inaccurate conclusions. Prior work has shown that both
humans and multimodal large language models (MLLMs) are frequently deceived by
such visualizations. Automatically detecting misleading visualizations and
identifying the specific design rules they violate could help protect readers
and reduce the spread of misinformation. However, the training and evaluation
of AI models has been limited by the absence of large, diverse, and openly
available datasets. In this work, we introduce Misviz, a benchmark of 2,604
real-world visualizations annotated with 12 types of misleaders. To support
model training, we also release Misviz-synth, a synthetic dataset of 81,814
visualizations generated using Matplotlib and based on real-world data tables.
We perform a comprehensive evaluation on both datasets using state-of-the-art
MLLMs, rule-based systems, and fine-tuned classifiers. Our results reveal that
the task remains highly challenging. We release Misviz, Misviz-synth, and the
accompanying code.

</details>


### [114] [Not All Parameters Are Created Equal: Smart Isolation Boosts Fine-Tuning Performance](https://arxiv.org/abs/2508.21741)
*Yao Wang,Di Liang,Minlong Peng*

Main category: cs.CL

TL;DR: 针对SFT中存在的“跷跷板现象”，本文提出CPI-FT框架。它通过独立微调识别核心参数区域，对任务进行分组，然后融合参数（核心参数直接移植，非核心参数通过SLERP集成），最后进行轻量级SFT训练并冻结核心区域以防止灾难性遗忘，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）在使大型语言模型（LLM）适应下游任务时，常出现“跷跷板现象”，即不加区分的参数更新会导致在某些任务上取得进展，却以牺牲其他任务为代价，从而影响性能。

Method: 本文提出了核心参数隔离微调（CPI-FT）框架：1. 首先独立微调LLM，通过量化参数更新幅度来识别每个任务的核心参数区域。2. 根据核心区域的重叠度对相似任务进行分组，形成联合建模的簇。3. 引入参数融合技术：将每个任务独立微调模型的核参数直接移植到统一骨干网络中，而不同任务的非核参数通过球面线性插值（SLERP）平滑集成，以减轻破坏性干扰。4. 随后采用轻量级、流水线式的SFT训练阶段，使用混合任务数据，并冻结先前任务的核心区域以防止灾难性遗忘。

Result: 在多个公共基准测试上的大量实验表明，该方法显著缓解了任务干扰和遗忘问题，并持续优于传统的多种任务和多阶段微调基线方法。

Conclusion: CPI-FT框架通过识别、隔离和智能融合核心与非核心参数，有效解决了SFT中的“跷跷板现象”和灾难性遗忘问题，从而在多任务适应中取得了显著的性能提升。

Abstract: Supervised fine-tuning (SFT) is a pivotal approach to adapting large language
models (LLMs) for downstream tasks; however, performance often suffers from the
``seesaw phenomenon'', where indiscriminate parameter updates yield progress on
certain tasks at the expense of others. To address this challenge, we propose a
novel \emph{Core Parameter Isolation Fine-Tuning} (CPI-FT) framework.
Specifically, we first independently fine-tune the LLM on each task to identify
its core parameter regions by quantifying parameter update magnitudes. Tasks
with similar core regions are then grouped based on region overlap, forming
clusters for joint modeling. We further introduce a parameter fusion technique:
for each task, core parameters from its individually fine-tuned model are
directly transplanted into a unified backbone, while non-core parameters from
different tasks are smoothly integrated via Spherical Linear Interpolation
(SLERP), mitigating destructive interference. A lightweight, pipelined SFT
training phase using mixed-task data is subsequently employed, while freezing
core regions from prior tasks to prevent catastrophic forgetting. Extensive
experiments on multiple public benchmarks demonstrate that our approach
significantly alleviates task interference and forgetting, consistently
outperforming vanilla multi-task and multi-stage fine-tuning baselines.

</details>


### [115] [Reasoning-Intensive Regression](https://arxiv.org/abs/2508.21762)
*Diane Tchuindjo,Omar Khattab*

Main category: cs.CL

TL;DR: 本文提出了“推理密集型回归”（RiR）任务，并指出LLMs在此类任务中面临的挑战。研究人员建立了一个基准，并提出了MENTAT方法，该方法通过结合批反射提示优化和神经集成学习，显著提升了RiR任务的性能。


<details>
  <summary>Details</summary>
Motivation: AI研究人员越来越多地将大型语言模型（LLMs）应用于推理密集型回归（RiR）任务，即从文本中推断细微的数值属性。与标准语言回归任务不同，RiR通常出现在需要对文本进行更深层次分析的特定问题中（如基于评分标准的评分或领域特定检索），而这些问题往往只有有限的任务特定训练数据和计算资源。研究动机在于，现有的方法（如提示冻结LLMs和通过梯度下降微调Transformer编码器）在RiR任务中表现不佳。

Method: 1. 将三个现实问题转化为RiR任务，建立了一个初始基准。2. 利用该基准测试了现有方法（提示冻结LLMs和微调Transformer编码器）在RiR中表现不佳的假设。3. 提出了MENTAT方法，该方法结合了批反射提示优化（batch-reflective prompt optimization）和神经集成学习（neural ensemble learning）。

Result: MENTAT方法在RiR任务中，相对于两种基线方法（提示冻结LLMs和微调Transformer编码器）实现了高达65%的性能提升。

Conclusion: MENTAT方法显著提升了LLMs在推理密集型回归（RiR）任务中的表现，但该领域仍有巨大的进步空间，未来还有待进一步研究和发展。

Abstract: AI researchers and practitioners increasingly apply large language models
(LLMs) to what we call reasoning-intensive regression (RiR), i.e. deducing
subtle numerical properties from text. Unlike standard language regression
tasks, e.g. for sentiment or similarity, RiR often appears instead in ad-hoc
problems like rubric-based scoring or domain-specific retrieval, where much
deeper analysis of text is required while only limited task-specific training
data and computation are available. We cast three realistic problems as RiR
tasks to establish an initial benchmark, and use that to test our hypothesis
that prompting frozen LLMs and finetuning Transformer encoders via gradient
descent will both often struggle in RiR. We then propose MENTAT, a simple and
lightweight method that combines batch-reflective prompt optimization with
neural ensemble learning. MENTAT achieves up to 65% improvement over both
baselines, though substantial room remains for future advances in RiR.

</details>


### [116] [PiCSAR: Probabilistic Confidence Selection And Ranking](https://arxiv.org/abs/2508.21787)
*Joshua Ong Jun Leang,Zheng Zhao,Aryo Pradipta Gema,Sohee Yang,Wai-Chung Kwan,Xuanli He,Wenda Li,Pasquale Minervini,Eleonora Giunchiglia,Shay B. Cohen*

Main category: cs.CL

TL;DR: PiCSAR是一种无需训练的方法，通过结合推理和最终答案的联合对数似然来为LLM/LRM的最佳n选一采样评分，显著提高了推理任务的准确性，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型（LLMs）和大型推理模型（LRMs）的最佳n选一采样中，核心挑战是如何在没有真值答案的情况下，设计一个能够识别正确推理链的评分函数。

Method: 本文提出了概率置信度选择与排序（PiCSAR），这是一种简单、无需训练的方法。它通过使用推理和最终答案的联合对数似然来评估每个候选生成，该联合对数似然自然分解为推理置信度和答案置信度。

Result: PiCSAR在多个基准测试（如MATH500和AIME2025）上取得了显著提升（MATH500提高10.18，AIME2025提高9.81），在20项比较中的16项中，使用至少两倍少的样本优于基线。分析表明，正确的推理链展现出显著更高的推理和答案置信度。

Conclusion: PiCSAR的有效性在于，正确的推理链通常表现出更高的推理置信度和答案置信度，这证明了该方法的合理性。

Abstract: Best-of-n sampling improves the accuracy of large language models (LLMs) and
large reasoning models (LRMs) by generating multiple candidate solutions and
selecting the one with the highest reward. The key challenge for reasoning
tasks is designing a scoring function that can identify correct reasoning
chains without access to ground-truth answers. We propose Probabilistic
Confidence Selection And Ranking (PiCSAR): a simple, training-free method that
scores each candidate generation using the joint log-likelihood of the
reasoning and final answer. The joint log-likelihood of the reasoning and final
answer naturally decomposes into reasoning confidence and answer confidence.
PiCSAR achieves substantial gains across diverse benchmarks (+10.18 on MATH500,
+9.81 on AIME2025), outperforming baselines with at least 2x fewer samples in
16 out of 20 comparisons. Our analysis reveals that correct reasoning chains
exhibit significantly higher reasoning and answer confidence, justifying the
effectiveness of PiCSAR.

</details>


### [117] [Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing Fine Web for Problematic Content Search and Retrieval](https://arxiv.org/abs/2508.21788)
*Inés Altemir Marinas,Anastasiia Kucherenko,Andrei Kucharavy*

Main category: cs.CL

TL;DR: 本文提出了一个基于ElasticSearch的框架，用于索引和分析大型语言模型（LLM）的训练数据集，以解决数据质量、安全和伦理问题，并实现了快速查询性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型严重依赖网络规模数据集（如Common Crawl），但其无差别抓取导致数据质量、安全和伦理挑战。此前对有害内容的研究受限于计算能力，只能分析小样本，无法满足关键的训练数据质量需求。

Method: 项目开发了一个基于ElasticSearch的管道，用于索引和分析LLM训练数据集。

Result: 将该框架应用于SwissAI的FineWeb-2语料库（1.5TB，四种语言），实现了快速查询性能——大多数搜索在毫秒级完成，所有搜索均在2秒内完成。这证明了实时数据集分析的可行性。

Conclusion: 该工作展示了实时数据集分析能力，为构建更安全、更负责任的AI系统提供了实用工具。

Abstract: Large language models (LLMs) rely heavily on web-scale datasets like Common
Crawl, which provides over 80\% of training data for some modern models.
However, the indiscriminate nature of web crawling raises challenges in data
quality, safety, and ethics. Despite the critical importance of training data
quality, prior research on harmful content has been limited to small samples
due to computational constraints. This project presents a framework for
indexing and analyzing LLM training datasets using an ElasticSearch-based
pipeline. We apply it to SwissAI's FineWeb-2 corpus (1.5TB, four languages),
achieving fast query performance--most searches in milliseconds, all under 2
seconds. Our work demonstrates real-time dataset analysis, offering practical
tools for safer, more accountable AI systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [118] [EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control](https://arxiv.org/abs/2508.21112)
*Delin Qu,Haoming Song,Qizhi Chen,Zhaoqing Chen,Xianqiang Gao,Xinyi Ye,Qi Lv,Modi Shi,Guanghui Ren,Cheng Ruan,Maoqing Yao,Haoran Yang,Jiacheng Bao,Bin Zhao,Dong Wang*

Main category: cs.RO

TL;DR: 本文介绍了EO-Robotics，包含EO-1模型和EO-Data1.5M数据集，旨在通过统一架构和大规模交错式视觉-文本-动作预训练，实现卓越的多模态具身推理和机器人控制。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作（VLA）模型在通用机器人控制方面取得进展，但在交错式推理和交互方面仍未能达到人类水平的灵活性，这阻碍了通用具身智能系统在开放世界中无缝执行多模态推理和物理交互。

Method: 本文提出了EO-1模型和EO-Data1.5M数据集。EO-1是一个统一的具身基础模型，采用统一架构无差别处理多模态输入（图像、文本、视频、动作）。EO-Data1.5M是一个大规模、高质量的多模态具身推理数据集，包含超过150万个样本，强调交错式视觉-文本-动作理解。EO-1通过自回归解码和流匹配去噪的协同作用在EO-Data1.5M上进行预训练。

Result: EO-1在多模态具身推理和机器人控制方面表现出卓越性能，能够实现无缝的机器人动作生成和多模态具身推理。大量实验证明了交错式视觉-文本-动作学习对于开放世界理解和泛化的有效性，并在多种长程、灵巧操作任务中得到验证。

Conclusion: 本文详细介绍了EO-1的架构、EO-Data1.5M的数据构建策略和训练方法，为开发先进的具身基础模型提供了宝贵的见解，展示了交错式视觉-文本-动作学习在开放世界理解和泛化方面的有效性。

Abstract: The human ability to seamlessly perform multimodal reasoning and physical
interaction in the open world is a core goal for general-purpose embodied
intelligent systems. Recent vision-language-action (VLA) models, which are
co-trained on large-scale robot and visual-text data, have demonstrated notable
progress in general robot control. However, they still fail to achieve
human-level flexibility in interleaved reasoning and interaction. In this work,
introduce EO-Robotics, consists of EO-1 model and EO-Data1.5M dataset. EO-1 is
a unified embodied foundation model that achieves superior performance in
multimodal embodied reasoning and robot control through interleaved
vision-text-action pre-training. The development of EO-1 is based on two key
pillars: (i) a unified architecture that processes multimodal inputs
indiscriminately (image, text, video, and action), and (ii) a massive,
high-quality multimodal embodied reasoning dataset, EO-Data1.5M, which contains
over 1.5 million samples with emphasis on interleaved vision-text-action
comprehension. EO-1 is trained through synergies between auto-regressive
decoding and flow matching denoising on EO-Data1.5M, enabling seamless robot
action generation and multimodal embodied reasoning. Extensive experiments
demonstrate the effectiveness of interleaved vision-text-action learning for
open-world understanding and generalization, validated through a variety of
long-horizon, dexterous manipulation tasks across multiple embodiments. This
paper details the architecture of EO-1, the data construction strategy of
EO-Data1.5M, and the training methodology, offering valuable insights for
developing advanced embodied foundation models.

</details>


### [119] [Observer Design for Optical Flow-Based Visual-Inertial Odometry with Almost-Global Convergence](https://arxiv.org/abs/2508.21163)
*Tarek Bouazza,Soulaimane Berkane,Minh-Duc Hua,Tarek Hamel*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的级联观测器架构，通过融合光流和IMU测量，实现了连续单目视觉惯性里程计（VIO），能够同时估计体坐标系下的速度、重力方向和姿态。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于开发一种鲁棒、连续的单目视觉惯性里程计（VIO）解决方案，通过有效融合稀疏光流的速度方向信息与IMU数据，实现对速度、重力方向和姿态的同步高精度估计。

Method: 该方法采用级联观测器架构。首先，一个全局指数稳定的Riccati观测器融合光流测量的速度方向信息、陀螺仪和加速度计数据，在持续激励的平移运动条件下，同时估计体坐标系下的速度和重力方向。然后，利用估计的体坐标系重力方向（以及可选的磁力计测量），设计一个SO(3)上的互补观测器进行姿态估计。此外，还开发了一种梯度下降算法，用于在单位球面上解决约束最小化问题，以从稀疏光流数据中提取速度方向。

Result: 所提出的互连观测器架构被证明是几乎全局渐近稳定的。通过仿真结果验证了所提出算法的有效性。

Conclusion: 本文提出了一种新颖的、几乎全局渐近稳定的级联观测器架构，成功地将光流和IMU测量融合在一起，实现了连续的单目视觉惯性里程计，为同时估计速度、重力方向和姿态提供了一种有效且鲁棒的解决方案。

Abstract: This paper presents a novel cascaded observer architecture that combines
optical flow and IMU measurements to perform continuous monocular
visual-inertial odometry (VIO). The proposed solution estimates body-frame
velocity and gravity direction simultaneously by fusing velocity direction
information from optical flow measurements with gyro and accelerometer data.
This fusion is achieved using a globally exponentially stable Riccati observer,
which operates under persistently exciting translational motion conditions. The
estimated gravity direction in the body frame is then employed, along with an
optional magnetometer measurement, to design a complementary observer on
$\mathbf{SO}(3)$ for attitude estimation. The resulting interconnected observer
architecture is shown to be almost globally asymptotically stable. To extract
the velocity direction from sparse optical flow data, a gradient descent
algorithm is developed to solve a constrained minimization problem on the unit
sphere. The effectiveness of the proposed algorithms is validated through
simulation results.

</details>


### [120] [Multi-robot Path Planning and Scheduling via Model Predictive Optimal Transport (MPC-OT)](https://arxiv.org/abs/2508.21205)
*Usman A. Khan,Mouhacine Benosman,Wenliang Liu,Federico Pecora,Joseph W. Durham*

Main category: cs.RO

TL;DR: 本文提出了一种基于最优传输理论和模型预测控制的多机器人路径规划与调度新方法，旨在实现无碰撞的机器人导航。


<details>
  <summary>Details</summary>
Motivation: 传统的多机器人路径规划方法（先分配目标再规划路径）可能导致路径重叠和死锁。因此，需要一种能够保证无重叠轨迹的策略。

Method: 研究方法包括：1. 将兴趣空间离散化为K个单元格，并建立K×K的成本结构来描述单元格间的转换成本。2. 利用最优传输理论，从机器人到目标提供最小成本且无重叠的单元格转换。3. 对于可能重叠的轨迹（某些情况不可避免）和机器人动力学，通过“重新规划”和“模型预测控制”将时间结构整合到最优传输中。

Result: 该方法能够提供最优且无重叠的机器人到目标单元格转换。在最坏情况下，计算复杂度为O(K³log K)，对于良好问题为O(K²log K)。通过整合模型预测控制，该方法还能适应潜在的重叠轨迹和机器人动力学。

Conclusion: 本文提出了一种新颖的多机器人导航路径规划和调度方法，该方法基于最优传输理论，能够有效保证机器人轨迹的无重叠性。通过结合模型预测控制，该方案进一步增强了对复杂动态和不可避免的轨迹重叠情况的处理能力。

Abstract: In this paper, we propose a novel methodology for path planning and
scheduling for multi-robot navigation that is based on optimal transport theory
and model predictive control. We consider a setup where $N$ robots are tasked
to navigate to $M$ targets in a common space with obstacles. Mapping robots to
targets first and then planning paths can result in overlapping paths that lead
to deadlocks. We derive a strategy based on optimal transport that not only
provides minimum cost paths from robots to targets but also guarantees
non-overlapping trajectories. We achieve this by discretizing the space of
interest into $K$ cells and by imposing a ${K\times K}$ cost structure that
describes the cost of transitioning from one cell to another. Optimal transport
then provides \textit{optimal and non-overlapping} cell transitions for the
robots to reach the targets that can be readily deployed without any scheduling
considerations. The proposed solution requires $\unicode{x1D4AA}(K^3\log K)$
computations in the worst-case and $\unicode{x1D4AA}(K^2\log K)$ for
well-behaved problems. To further accommodate potentially overlapping
trajectories (unavoidable in certain situations) as well as robot dynamics, we
show that a temporal structure can be integrated into optimal transport with
the help of \textit{replans} and \textit{model predictive control}.

</details>


### [121] [Uncertainty-Aware Ankle Exoskeleton Control](https://arxiv.org/abs/2508.21221)
*Fatima Mumtaza Tourk,Bishoy Galoaa,Sanat Shajan,Aaron J. Young,Michael Everett,Max K. Shepherd*

Main category: cs.RO

TL;DR: 本文提出了一种不确定性感知控制框架，使踝关节外骨骼能够通过自动识别和脱离不熟悉动作，在多样化场景中安全辅助人体运动。


<details>
  <summary>Details</summary>
Motivation: 现有下肢外骨骼控制器仅限于在受控环境中执行离散、预定义的动作，这限制了它们在现实世界中的应用。研究旨在解决这一局限性，使外骨骼能在非结构化日常环境中安全运行。

Method: 该方法使用不确定性估计器将动作分类为已知（分布内）或未知（分布外）。离线评估了三种架构（模型集成、自编码器和生成对抗网络），并在线测试了表现最佳的集成步态相位估计器架构。

Result: 在线测试表明，不确定性估计器能够有效地在用户从分布内任务切换到分布外任务时开启和关闭辅助，F1分数为89.2。

Conclusion: 该框架为外骨骼在非结构化日常环境中安全、自主地辅助人体运动提供了新途径。

Abstract: Lower limb exoskeletons show promise to assist human movement, but their
utility is limited by controllers designed for discrete, predefined actions in
controlled environments, restricting their real-world applicability. We present
an uncertainty-aware control framework that enables ankle exoskeletons to
operate safely across diverse scenarios by automatically disengaging when
encountering unfamiliar movements. Our approach uses an uncertainty estimator
to classify movements as similar (in-distribution) or different
(out-of-distribution) relative to actions in the training set. We evaluated
three architectures (model ensembles, autoencoders, and generative adversarial
networks) on an offline dataset and tested the strongest performing
architecture (ensemble of gait phase estimators) online. The online test
demonstrated the ability of our uncertainty estimator to turn assistance on and
off as the user transitioned between in-distribution and out-of-distribution
tasks (F1: 89.2). This new framework provides a path for exoskeletons to safely
and autonomously support human movement in unstructured, everyday environments.

</details>


### [122] [Remarks on stochastic cloning and delayed-state filtering](https://arxiv.org/abs/2508.21260)
*Tara Mina,Lindsey Marinello,John Christian*

Main category: cs.RO

TL;DR: 本文重新审视了延迟状态卡尔曼滤波器，并证明其在处理延迟状态测量方面与随机克隆方法效果相同，但无需状态增强，且具有计算和内存效率优势，纠正了卡尔曼滤波器无法处理此类测量的常见误解。


<details>
  <summary>Details</summary>
Motivation: 机器人和导航中的许多估计问题涉及依赖于先前状态的测量（如里程计）。准确处理这些延迟状态测量需要捕捉它们与先前状态估计之间的相关性。随机克隆（SC）是常用方法，但需要状态增强，这可能带来计算和内存负担。

Method: 本文重新审视并正确推导了延迟状态卡尔曼滤波器（DSKF）。通过与随机克隆（SC）进行比较，分析了DSKF在状态和协方差更新方面的表现。

Result: 研究发现，一个正确推导的延迟状态卡尔曼滤波器（DSKF）能够产生与随机克隆（SC）完全相同的状态和协方差更新。此外，DSKF在不进行状态增强的情况下，提供了计算优势，并减少了高维状态的内存需求。

Conclusion: 卡尔曼滤波器变体并非天生无法处理相关的延迟状态测量。通过适当的公式推导，延迟状态卡尔曼滤波器能够更有效地实现与随机克隆相同的结果，纠正了这一常见误解。

Abstract: Many estimation problems in robotics and navigation involve measurements that
depend on prior states. A prominent example is odometry, which measures the
relative change between states over time. Accurately handling these
delayed-state measurements requires capturing their correlations with prior
state estimates, and a widely used approach is stochastic cloning (SC), which
augments the state vector to account for these correlations.
  This work revisits a long-established but often overlooked alternative--the
delayed-state Kalman filter--and demonstrates that a properly derived filter
yields exactly the same state and covariance update as SC, without requiring
state augmentation. Moreover, the generalized Kalman filter formulation
provides computational advantages, while also reducing memory requirements for
higher-dimensional states.
  Our findings clarify a common misconception that Kalman filter variants are
inherently unable to handle correlated delayed-state measurements,
demonstrating that an alternative formulation achieves the same results more
efficiently.

</details>


### [123] [Mini Autonomous Car Driving based on 3D Convolutional Neural Networks](https://arxiv.org/abs/2508.21271)
*Pablo Moraes,Monica Rodriguez,Kristofer S. Kappel,Hiago Sodre,Santiago Fernandez,Igor Nunes,Bruna Guterres,Ricardo Grando*

Main category: cs.RO

TL;DR: 本研究提出了一种基于RGB-D信息和3D CNNs的方法，用于模拟环境中的迷你自动驾驶汽车（MACs），并与RNNs进行比较，结果显示3D CNNs表现出更好的前景。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶应用对提高车辆安全性、效率和用户体验至关重要，但其开发面临高复杂性、训练周期长和不确定性等挑战。迷你自动驾驶汽车（MACs）提供了一个实用且经济高效的测试平台，用于快速评估和比较机器学习模型，尤其适用于需要在线训练的算法。

Method: 本研究提出了一种基于RGB-D信息和三维卷积神经网络（3D CNNs）的方法，用于模拟环境中的MACs自动驾驶。该方法在两个具有不同环境特征的模拟赛道上进行训练和测试，并与循环神经网络（RNNs）进行对比评估。性能评估指标包括任务完成成功率、圈速和驾驶一致性。

Result: 研究结果表明，架构修改和赛道复杂性会影响模型的泛化能力和车辆控制性能。与RNNs相比，所提出的3D CNN在评估中展现出有前景的结果。

Conclusion: 本研究提出了一种基于RGB-D和3D CNNs的MACs自动驾驶方法，并在模拟环境中展示了其优于RNNs的潜力，为解决自动驾驶系统的复杂性和不确定性挑战提供了新的思路。

Abstract: Autonomous driving applications have become increasingly relevant in the
automotive industry due to their potential to enhance vehicle safety,
efficiency, and user experience, thereby meeting the growing demand for
sophisticated driving assistance features. However, the development of reliable
and trustworthy autonomous systems poses challenges such as high complexity,
prolonged training periods, and intrinsic levels of uncertainty. Mini
Autonomous Cars (MACs) are used as a practical testbed, enabling validation of
autonomous control methodologies on small-scale setups. This simplified and
cost-effective environment facilitates rapid evaluation and comparison of
machine learning models, which is particularly useful for algorithms requiring
online training. To address these challenges, this work presents a methodology
based on RGB-D information and three-dimensional convolutional neural networks
(3D CNNs) for MAC autonomous driving in simulated environments. We evaluate the
proposed approach against recurrent neural networks (RNNs), with architectures
trained and tested on two simulated tracks with distinct environmental
features. Performance was assessed using task completion success, lap-time
metrics, and driving consistency. Results highlight how architectural
modifications and track complexity influence the models' generalization
capability and vehicle control performance. The proposed 3D CNN demonstrated
promising results when compared with RNNs.

</details>


### [124] [Learning to Assemble the Soma Cube with Legal-Action Masked DQN and Safe ZYZ Regrasp on a Doosan M0609](https://arxiv.org/abs/2508.21272)
*Jaehong Oh,Seungjun Jung,Sawoong Kim*

Main category: cs.RO

TL;DR: 本文首次将合法动作掩码的深度Q网络与安全的ZYZ重抓策略应用于欠驱动夹持器协作机器人，实现了索马立方体自主组装学习，并系统地集成了约束感知强化学习与奇异性安全运动规划。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中组合动作空间爆炸、不安全运动规划以及系统性组装策略学习等关键挑战。

Method: 采用合法动作掩码的深度Q网络（DQN），结合安全的ZYZ重抓策略。DQN采用分层架构，将Q函数估计分解为姿态和位置两部分，降低了计算复杂度。设计了鼓励“先着地、垂直可达”组装序列的机器人友好奖励函数，并使用了课程学习（2件、3件、7件）来提高训练效率。

Result: 计算复杂度从O(3,132)降低到O(116) + O(27)，同时保持解决方案完整性。在500个回合内，2件组装达到100%成功率；3件组装达到92.9%成功率；在总计105,300个训练回合中，7件组装（索马立方体）达到39.9%成功率。

Conclusion: 该方法成功地将约束感知强化学习与奇异性安全运动规划集成到协作机器人上，实现了索马立方体自主组装学习，显著提高了训练效率，并有效解决了机器人操作中的核心难题。

Abstract: This paper presents the first comprehensive application of legal-action
masked Deep Q-Networks with safe ZYZ regrasp strategies to an underactuated
gripper-equipped 6-DOF collaborative robot for autonomous Soma cube assembly
learning. Our approach represents the first systematic integration of
constraint-aware reinforcement learning with singularity-safe motion planning
on a Doosan M0609 collaborative robot. We address critical challenges in
robotic manipulation: combinatorial action space explosion, unsafe motion
planning, and systematic assembly strategy learning. Our system integrates a
legal-action masked DQN with hierarchical architecture that decomposes
Q-function estimation into orientation and position components, reducing
computational complexity from $O(3,132)$ to $O(116) + O(27)$ while maintaining
solution completeness. The robot-friendly reward function encourages
ground-first, vertically accessible assembly sequences aligned with
manipulation constraints. Curriculum learning across three progressive
difficulty levels (2-piece, 3-piece, 7-piece) achieves remarkable training
efficiency: 100\% success rate for Level 1 within 500 episodes, 92.9\% for
Level 2, and 39.9\% for Level 3 over 105,300 total training episodes.

</details>


### [125] [Observability-driven Assignment of Heterogeneous Sensors for Multi-Target Tracking](https://arxiv.org/abs/2508.21309)
*Seyed Ali Rakhshan,Mehdi Golestani,He Kong*

Main category: cs.RO

TL;DR: 本文提出了一种基于拟阵理论的贪婪算法，用于解决异构传感器在多目标跟踪中的分配问题，以优化跟踪质量并最小化不确定性。


<details>
  <summary>Details</summary>
Motivation: 在多目标跟踪中，如何有效地将具有不同感知能力的异构传感器（机器人）分配给目标，以最大化跟踪质量并最小化目标状态估计的不确定性，是一个重要的挑战。

Method: 将机器人分为两类：(1) 具有测距和测向能力的独立跟踪机器人；(2) 仅具有测距或测向能力，需要配对协作跟踪的机器人。利用拟阵理论，提出了一种贪婪分配算法，动态分配机器人以最大化跟踪质量。

Result: 该算法在多项式时间内运行，对于任意跟踪质量函数提供1/3的常数因子近似界限，对于子模函数提供1/2的常数因子近似界限。广泛仿真表明算法在长时间内有效估计和跟踪目标，并且性能接近最优分配。

Conclusion: 所提出的贪婪算法在异构传感器多目标跟踪中具有鲁棒性和实用性，能够有效提高跟踪质量并接近最优性能。

Abstract: This paper addresses the challenge of assigning heterogeneous sensors (i.e.,
robots with varying sensing capabilities) for multi-target tracking. We
classify robots into two categories: (1) sufficient sensing robots, equipped
with range and bearing sensors, capable of independently tracking targets, and
(2) limited sensing robots, which are equipped with only range or bearing
sensors and need to at least form a pair to collaboratively track a target. Our
objective is to optimize tracking quality by minimizing uncertainty in target
state estimation through efficient robot-to-target assignment. By leveraging
matroid theory, we propose a greedy assignment algorithm that dynamically
allocates robots to targets to maximize tracking quality. The algorithm
guarantees constant-factor approximation bounds of 1/3 for arbitrary tracking
quality functions and 1/2 for submodular functions, while maintaining
polynomial-time complexity. Extensive simulations demonstrate the algorithm's
effectiveness in accurately estimating and tracking targets over extended
periods. Furthermore, numerical results confirm that the algorithm's
performance is close to that of the optimal assignment, highlighting its
robustness and practical applicability.

</details>


### [126] [Robust Real-Time Coordination of CAVs: A Distributed Optimization Framework under Uncertainty](https://arxiv.org/abs/2508.21322)
*Haojie Bai,Yang Wang,Cong Guo,Xiongwei Zhao,Hai Zhu*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的协同车辆协调框架，通过直接控制轨迹分布、分布式轨迹协商算法和交互式注意力机制，在动态不确定环境中同时实现了安全保障和实时性能。


<details>
  <summary>Details</summary>
Motivation: 在动态和不确定环境中，实现合作车辆协调中的安全保障和实时性能仍然是一个基本挑战。

Method: 1) 将车辆轨迹分布的直接控制制定为鲁棒的合作规划问题，并采用自适应增强安全约束。2) 提出一种完全并行的基于ADMM的分布式轨迹协商(ADMM-DTN)算法，以平衡解质量和计算资源。3) 引入交互式注意力机制，选择性地关注关键交互参与者以提高计算效率。

Result: 该框架在安全性（在各种场景中碰撞率降低高达40.79%）和实时性能方面优于现有技术，并随着车辆数量的增加保持强大的可扩展性。交互式注意力机制进一步将计算需求降低了14.1%。通过真实世界实验验证了其在复杂环境（包括意外动态障碍物）中的鲁棒协调能力。

Conclusion: 所提出的框架在模拟和实际实验中均表现出在复杂动态环境中实现高安全性、实时性能和强大可扩展性的有效性，并通过交互式注意力机制进一步提升了计算效率和鲁棒性。

Abstract: Achieving both safety guarantees and real-time performance in cooperative
vehicle coordination remains a fundamental challenge, particularly in dynamic
and uncertain environments. This paper presents a novel coordination framework
that resolves this challenge through three key innovations: 1) direct control
of vehicles' trajectory distributions during coordination, formulated as a
robust cooperative planning problem with adaptive enhanced safety constraints,
ensuring a specified level of safety regarding the uncertainty of the
interactive trajectory, 2) a fully parallel ADMM-based distributed trajectory
negotiation (ADMM-DTN) algorithm that efficiently solves the optimization
problem while allowing configurable negotiation rounds to balance solution
quality and computational resources, and 3) an interactive attention mechanism
that selectively focuses on critical interactive participants to further
enhance computational efficiency. Both simulation results and practical
experiments demonstrate that our framework achieves significant advantages in
safety (reducing collision rates by up to 40.79\% in various scenarios) and
real-time performance compared to state-of-the-art methods, while maintaining
strong scalability with increasing vehicle numbers. The proposed interactive
attention mechanism further reduces the computational demand by 14.1\%. The
framework's effectiveness is further validated through real-world experiments
with unexpected dynamic obstacles, demonstrating robust coordination in complex
environments. The experiment demo could be found at
https://youtu.be/4PZwBnCsb6Q.

</details>


### [127] [Multi-Modal Model Predictive Path Integral Control for Collision Avoidance](https://arxiv.org/abs/2508.21364)
*Alberto Bertipaglia,Dariu M. Gavrila,Barys Shyrokau*

Main category: cs.RO

TL;DR: 本文提出了一种多模态模型预测路径积分（MPPI）控制算法，用于自动驾驶汽车的运动规划和决策。该方法通过Sobol序列采样和解析碰撞避免，探索多样化轨迹，并在高保真模拟中表现出优于标准MPPI的障碍物规避和车辆稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法可能导致自动驾驶汽车在运动规划和决策中产生次优解决方案，尤其是在需要规避障碍物或安全停车的复杂场景中，因此需要一种能探索多样化轨迹并降低风险的新方法。

Method: 该方法提出了一种多模态模型预测路径积分（MPPI）控制算法。它使用Sobol序列围绕先验输入进行采样，并结合解析解进行碰撞避免。通过利用多模态，算法可以探索多种轨迹（如绕过障碍物或安全停车）。预测模型采用带有Fiala轮胎的非线性单轨车辆模型，并强制执行摩擦圆内的轮胎力约束以确保车辆稳定性。最终计算优化的转向角和纵向加速度以生成无碰撞轨迹。

Result: 在高保真模拟环境中，所提出的算法成功地规避了障碍物，并在高摩擦和低摩擦路面上的双车道变换操作以及移动障碍物的遮挡场景中保持车辆稳定。该算法表现优于标准的模型预测路径积分方法。

Conclusion: 所提出的多模态模型预测路径积分控制算法能够有效地为自动驾驶汽车进行运动规划和决策，在复杂障碍物规避和保持车辆稳定方面表现出色，并优于传统MPPI方法。

Abstract: This paper proposes a novel approach to motion planning and decision-making
for automated vehicles, using a multi-modal Model Predictive Path Integral
control algorithm. The method samples with Sobol sequences around the prior
input and incorporates analytical solutions for collision avoidance. By
leveraging multiple modes, the multi-modal control algorithm explores diverse
trajectories, such as manoeuvring around obstacles or stopping safely before
them, mitigating the risk of sub-optimal solutions. A non-linear single-track
vehicle model with a Fiala tyre serves as the prediction model, and tyre force
constraints within the friction circle are enforced to ensure vehicle stability
during evasive manoeuvres. The optimised steering angle and longitudinal
acceleration are computed to generate a collision-free trajectory and to
control the vehicle. In a high-fidelity simulation environment, we demonstrate
that the proposed algorithm can successfully avoid obstacles, keeping the
vehicle stable while driving a double lane change manoeuvre on high and
low-friction road surfaces and occlusion scenarios with moving obstacles,
outperforming a standard Model Predictive Path Integral approach.

</details>


### [128] [The Rosario Dataset v2: Multimodal Dataset for Agricultural Robotics](https://arxiv.org/abs/2508.21635)
*Nicolas Soncini,Javier Cremona,Erica Vidal,Maximiliano García,Gastón Castro,Taihú Pire*

Main category: cs.RO

TL;DR: 本文介绍了一个在大豆田中收集的多模态数据集，包含立体红外相机、彩色相机、IMU、GNSS和轮式里程计等传感器数据，旨在支持农业机器人定位、建图、感知和导航算法的开发与基准测试，并揭示了现有SLAM方法在农业环境中的局限性。


<details>
  <summary>Details</summary>
Motivation: 农业机器人面临自然光照变化、运动模糊、崎岖地形和感知混叠等挑战，现有算法在此类环境中表现受限。因此，需要一个专门的数据集来支持和基准测试先进的定位、建图、感知和导航算法，以克服这些复杂性。

Method: 研究人员在大豆田中收集了一个超过两小时的多模态数据集，包含来自立体红外相机、彩色相机、加速度计、陀螺仪、磁力计、GNSS（单点定位、RTK和PPK）以及轮式里程计的数据。数据采集平台设计满足评估多模态SLAM系统的关键要求，包括传感器硬件同步、6-DOF真实值和长轨迹上的闭环。此外，研究人员还在该数据集上运行了多模态最先进的SLAM方法。

Result: 研究成果是一个公开的多模态数据集（RosarioV2），捕获了农业机器人环境中的关键挑战。通过在该数据集上运行最先进的SLAM方法，揭示了这些方法在农业环境应用中存在的局限性。

Conclusion: 该多模态数据集为农业机器人领域的定位、建图、感知和导航算法的开发和基准测试提供了宝贵的资源，并突出了当前最先进SLAM方法在复杂农业环境中的不足之处，为未来的研究指明了方向。

Abstract: We present a multi-modal dataset collected in a soybean crop field,
comprising over two hours of recorded data from sensors such as stereo infrared
camera, color camera, accelerometer, gyroscope, magnetometer, GNSS (Single
Point Positioning, Real-Time Kinematic and Post-Processed Kinematic), and wheel
odometry. This dataset captures key challenges inherent to robotics in
agricultural environments, including variations in natural lighting, motion
blur, rough terrain, and long, perceptually aliased sequences. By addressing
these complexities, the dataset aims to support the development and
benchmarking of advanced algorithms for localization, mapping, perception, and
navigation in agricultural robotics. The platform and data collection system is
designed to meet the key requirements for evaluating multi-modal SLAM systems,
including hardware synchronization of sensors, 6-DOF ground truth and loops on
long trajectories.
  We run multimodal state-of-the art SLAM methods on the dataset, showcasing
the existing limitations in their application on agricultural settings. The
dataset and utilities to work with it are released on
https://cifasis.github.io/rosariov2/.

</details>


### [129] [Dynamics-Compliant Trajectory Diffusion for Super-Nominal Payload Manipulation](https://arxiv.org/abs/2508.21375)
*Anuj Pasricha,Joewie Koh,Jay Vakil,Alessandro Roncone*

Main category: cs.RO

TL;DR: 本研究提出了一种基于去噪扩散模型的轨迹生成方法，使机器人能够在保持安全的前提下，携带远超标称容量的有效载荷，显著扩展了工作空间。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人标称有效载荷评级过于保守，导致机器人能力被严重低估和利用不足。现有规划方法（如基于采样的、基于优化的或运动学动力学规划器）效率低下或难以处理高维度问题，无法有效利用机器人在实际动态限制下的更高承载能力。

Method: 提出了一种新颖的基于去噪扩散模型的轨迹生成方法。该方法将有效载荷约束明确整合到规划过程中，能够在恒定时间内生成动态可行的关节空间轨迹，无需后处理即可直接在物理硬件上执行。

Result: 在7自由度Franka Emika Panda机器人上的实验验证表明，即使有效载荷超过标称容量的3倍，仍有高达67.6%的工作空间可访问。这显著扩展了机器人的操作范围。

Conclusion: 在运动规划算法中更细致地考虑有效载荷动力学至关重要，因为这能够显著扩大机器人的操作包络，充分发挥其潜在能力。

Abstract: Nominal payload ratings for articulated robots are typically derived from
worst-case configurations, resulting in uniform payload constraints across the
entire workspace. This conservative approach severely underutilizes the robot's
inherent capabilities -- our analysis demonstrates that manipulators can safely
handle payloads well above nominal capacity across broad regions of their
workspace while staying within joint angle, velocity, acceleration, and torque
limits. To address this gap between assumed and actual capability, we propose a
novel trajectory generation approach using denoising diffusion models that
explicitly incorporates payload constraints into the planning process. Unlike
traditional sampling-based methods that rely on inefficient trial-and-error,
optimization-based methods that are prohibitively slow, or kinodynamic planners
that struggle with problem dimensionality, our approach generates dynamically
feasible joint-space trajectories in constant time that can be directly
executed on physical hardware without post-processing. Experimental validation
on a 7 DoF Franka Emika Panda robot demonstrates that up to 67.6% of the
workspace remains accessible even with payloads exceeding 3 times the nominal
capacity. This expanded operational envelope highlights the importance of a
more nuanced consideration of payload dynamics in motion planning algorithms.

</details>


### [130] [RoboInspector: Unveiling the Unreliability of Policy Code for LLM-enabled Robotic Manipulation](https://arxiv.org/abs/2508.21378)
*Chenduo Ying,Linkang Du,Peng Cheng,Yuanchao Shu*

Main category: cs.RO

TL;DR: 本研究设计了RoboInspector，一个用于揭示和分析大语言模型（LLM）驱动机器人操作中策略代码不可靠性的管道，并提出了一种基于失败策略代码反馈的改进方法，将可靠性提高了35%。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在机器人操作中展现出卓越能力，但由于真实世界任务的多样性和用户指令的复杂性，生成可靠的策略代码仍然是一个重大挑战，不同用户对同一任务可能给出不同指令，导致策略代码生成不可靠。

Method: 研究设计了RoboInspector管道，从操作任务的复杂性和指令的粒度两个角度，分析LLM驱动机器人操作中策略代码的不可靠性。通过在两个主流框架中，对168种不同的任务、指令和LLM组合进行综合实验。此外，还引入了一种由失败策略代码反馈指导的改进方法。

Result: RoboInspector识别出导致操作失败的四种主要不可靠行为，并对其行为及其根本原因进行了详细的表征。改进方法在LLM驱动的机器人操作中，将策略代码生成的可靠性提高了高达35%，并在模拟和真实世界环境中进行了评估。

Conclusion: 本研究揭示并表征了LLM驱动机器人操作中策略代码的不可靠行为及其原因，为实际开发提供了减少不可靠性的见解。同时，提出的改进方法显著提升了策略代码生成的可靠性。

Abstract: Large language models (LLMs) demonstrate remarkable capabilities in reasoning
and code generation, enabling robotic manipulation to be initiated with just a
single instruction. The LLM carries out various tasks by generating policy code
required to control the robot. Despite advances in LLMs, achieving reliable
policy code generation remains a significant challenge due to the diverse
requirements of real-world tasks and the inherent complexity of user
instructions. In practice, different users may provide distinct instructions to
drive the robot for the same task, which may cause the unreliability of policy
code generation. To bridge this gap, we design RoboInspector, a pipeline to
unveil and characterize the unreliability of the policy code for LLM-enabled
robotic manipulation from two perspectives: the complexity of the manipulation
task and the granularity of the instruction. We perform comprehensive
experiments with 168 distinct combinations of tasks, instructions, and LLMs in
two prominent frameworks. The RoboInspector identifies four main unreliable
behaviors that lead to manipulation failure. We provide a detailed
characterization of these behaviors and their underlying causes, giving insight
for practical development to reduce unreliability. Furthermore, we introduce a
refinement approach guided by failure policy code feedback that improves the
reliability of policy code generation by up to 35% in LLM-enabled robotic
manipulation, evaluated in both simulation and real-world environments.

</details>


### [131] [Assessing Human Cooperation for Enhancing Social Robot Navigation](https://arxiv.org/abs/2508.21455)
*Hariharan Arunachalam,Phani Teja Singamaneni,Rachid Alami*

Main category: cs.RO

TL;DR: 本文提出了一种通过基于几何分析和人类合作性评估的有效沟通策略，来解决社交机器人导航中因人类意外行为而导致的困难，特别是在迎面交叉场景中。


<details>
  <summary>Details</summary>
Motivation: 现有的社交感知机器人导航策略，即使结合了人类预测模型，仍难以应对人类的意外行为。这主要是因为机器人无法理解人类的意图和合作性，同时人类也无法清晰了解机器人的规划，从而导致导航困难。

Method: 本文通过在适当时间进行有效沟通来弥补这一缺陷。方法包括：基于上下文的几何分析和人类合作性评估（针对迎面交叉场景），提供评估方法和指标来区分合作性与非合作性人类，并展示如何利用几何推理生成适当的语言响应或机器人动作。

Result: 论文提供了一套评估方法和评估指标，能够区分合作性人类与非合作性人类。此外，还展示了几何推理如何被用于生成恰当的口头响应或机器人动作，以改善人机交互。

Conclusion: 通过在适当时间进行基于几何分析和人类合作性评估的有效沟通，可以有效解决社交机器人导航中因人类意外行为而产生的挑战，提升机器人理解人类意图并做出相应反应的能力。

Abstract: Socially aware robot navigation is a planning paradigm where the robot
navigates in human environments and tries to adhere to social constraints while
interacting with the humans in the scene. These navigation strategies were
further improved using human prediction models, where the robot takes the
potential future trajectory of humans while computing its own. Though these
strategies significantly improve the robot's behavior, it faces difficulties
from time to time when the human behaves in an unexpected manner. This happens
as the robot fails to understand human intentions and cooperativeness, and the
human does not have a clear idea of what the robot is planning to do. In this
paper, we aim to address this gap through effective communication at an
appropriate time based on a geometric analysis of the context and human
cooperativeness in head-on crossing scenarios. We provide an assessment
methodology and propose some evaluation metrics that could distinguish a
cooperative human from a non-cooperative one. Further, we also show how
geometric reasoning can be used to generate appropriate verbal responses or
robot actions.

</details>


### [132] [Few-Shot Neuro-Symbolic Imitation Learning for Long-Horizon Planning and Acting](https://arxiv.org/abs/2508.21501)
*Pierrick Lorang,Hong Lu,Johannes Huemer,Patrik Zips,Matthias Scheutz*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的神经符号框架，通过少量技能演示共同学习连续控制策略和符号领域抽象，以克服现有模仿学习在长时序任务、泛化性和数据效率上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的模仿学习方法通常专注于短时序技能，需要大量数据集，难以解决长时序任务，也难以泛化到任务变体和分布变化中。

Method: 该框架将高层任务结构抽象为图，通过Answer Set Programming (ASP) 求解器发现符号规则，并使用扩散策略模仿学习训练低层控制器。一个高层预言机过滤任务相关信息，使每个控制器专注于最小的观察和动作空间。这种基于图的神经符号框架能够捕获复杂的状态转换，包括非空间和时间关系。

Result: 该方法在六个领域（包括四种机械臂环境和自动化叉车环境）中进行了验证。结果表明，该方法具有高数据效率（低至五次技能演示）、强大的零样本和少样本泛化能力，以及可解释的决策制定。

Conclusion: 该神经符号框架通过结合符号推理和扩散策略模仿学习，有效解决了模仿学习在长时序任务、数据效率和泛化性方面的挑战，并提供了可解释的决策过程。

Abstract: Imitation learning enables intelligent systems to acquire complex behaviors
with minimal supervision. However, existing methods often focus on
short-horizon skills, require large datasets, and struggle to solve
long-horizon tasks or generalize across task variations and distribution
shifts. We propose a novel neuro-symbolic framework that jointly learns
continuous control policies and symbolic domain abstractions from a few skill
demonstrations. Our method abstracts high-level task structures into a graph,
discovers symbolic rules via an Answer Set Programming solver, and trains
low-level controllers using diffusion policy imitation learning. A high-level
oracle filters task-relevant information to focus each controller on a minimal
observation and action space. Our graph-based neuro-symbolic framework enables
capturing complex state transitions, including non-spatial and temporal
relations, that data-driven learning or clustering techniques often fail to
discover in limited demonstration datasets. We validate our approach in six
domains that involve four robotic arms, Stacking, Kitchen, Assembly, and Towers
of Hanoi environments, and a distinct Automated Forklift domain with two
environments. The results demonstrate high data efficiency with as few as five
skill demonstrations, strong zero- and few-shot generalizations, and
interpretable decision making.

</details>


### [133] [Estimated Informed Anytime Search for Sampling-Based Planning via Adaptive Sampler](https://arxiv.org/abs/2508.21549)
*Liding Zhang,Kuanqi Cai,Yu Zhang,Zhenshan Bing,Chaoqun Wang,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: MIT*是一种新型机器人路径规划器，通过在找到初始解之前构建估计信息集、采用自适应采样器和稀疏碰撞检测，显著提高了初始收敛速度和整体效率，在R^4到R^16维度问题和实际机器人任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于采样的规划器在未找到初始解时，会重新采样并探索整个配置空间，这既耗时又计算昂贵，从而影响了初始收敛率。

Method: MIT*提出以下创新点：1. 在找到初始解之前，基于先前的可接受解成本构建估计信息集，以加速初始收敛。2. 采用自适应采样器，根据探索过程动态调整采样策略。3. 利用与长度相关的自适应稀疏碰撞检查来指导惰性逆向搜索。

Result: MIT*在R^4到R^16维度问题中，性能优于现有的单查询、基于采样的规划器，并在受限场景中保持高成功率。它成功应用于实际机器人操作任务，提高了路径成本效率和计算时间。

Conclusion: MIT*通过其创新的估计信息集、自适应采样和稀疏碰撞检查机制，显著提升了高维和受限场景下机器人路径规划的初始收敛速度、路径成本效率和计算时间，是一个有效且高效的解决方案。

Abstract: Path planning in robotics often involves solving continuously valued,
high-dimensional problems. Popular informed approaches include graph-based
searches, such as A*, and sampling-based methods, such as Informed RRT*, which
utilize informed set and anytime strategies to expedite path optimization
incrementally. Informed sampling-based planners define informed sets as subsets
of the problem domain based on the current best solution cost. However, when no
solution is found, these planners re-sample and explore the entire
configuration space, which is time-consuming and computationally expensive.
This article introduces Multi-Informed Trees (MIT*), a novel planner that
constructs estimated informed sets based on prior admissible solution costs
before finding the initial solution, thereby accelerating the initial
convergence rate. Moreover, MIT* employs an adaptive sampler that dynamically
adjusts the sampling strategy based on the exploration process. Furthermore,
MIT* utilizes length-related adaptive sparse collision checks to guide lazy
reverse search. These features enhance path cost efficiency and computation
times while ensuring high success rates in confined scenarios. Through a series
of simulations and real-world experiments, it is confirmed that MIT*
outperforms existing single-query, sampling-based planners for problems in R^4
to R^16 and has been successfully applied to real-world robot manipulation
tasks. A video showcasing our experimental results is available at:
https://youtu.be/30RsBIdexTU

</details>


### [134] [Learning Agile Gate Traversal via Analytical Optimal Policy Gradient](https://arxiv.org/abs/2508.21592)
*Tianchen Sun,Bingheng Wang,Longbin Tang,Yichao Gao,Lin Zhao*

Main category: cs.RO

TL;DR: 本文提出一种混合框架，通过离线训练的神经网络在线微调模型预测控制（MPC）参数，实现四旋翼飞行器快速精确地穿过狭窄的门，并在样本效率上显著优于端到端强化学习。


<details>
  <summary>Details</summary>
Motivation: 窄门穿越是四旋翼飞行器的重要挑战和基准。传统自主飞行堆栈需要大量设计和参数调整；端到端强化学习（RL）方法通常存在样本效率低和可解释性差的问题。

Method: 本研究提出一种混合框架：离线训练的神经网络（NN）根据门角坐标和当前无人机状态，联合预测参考姿态和成本函数权重，在线微调模型预测控制（MPC）参数。为实现高效训练，推导了MPC模块和基于优化的门穿越检测模块的分析策略梯度。此外，引入了一种新的姿态跟踪误差公式，以简化表示并促进带边界梯度的有效学习。

Result: 硬件实验表明，该方法使四旋翼飞行器能够在受限环境中快速准确地穿过狭窄的门。与朴素的端到端强化学习方法相比，样本效率提高了几个数量级。

Conclusion: 所提出的混合框架通过结合神经网络的在线参数调整和模型预测控制，成功解决了四旋翼飞行器窄门穿越的挑战，实现了高效、精确和敏捷的飞行，并在样本效率上表现出色。

Abstract: Traversing narrow gates presents a significant challenge and has become a
standard benchmark for evaluating agile and precise quadrotor flight.
Traditional modularized autonomous flight stacks require extensive design and
parameter tuning, while end-to-end reinforcement learning (RL) methods often
suffer from low sample efficiency and limited interpretability. In this work,
we present a novel hybrid framework that adaptively fine-tunes model predictive
control (MPC) parameters online using outputs from a neural network (NN)
trained offline. The NN jointly predicts a reference pose and cost-function
weights, conditioned on the coordinates of the gate corners and the current
drone state. To achieve efficient training, we derive analytical policy
gradients not only for the MPC module but also for an optimization-based gate
traversal detection module. Furthermore, we introduce a new formulation of the
attitude tracking error that admits a simplified representation, facilitating
effective learning with bounded gradients. Hardware experiments demonstrate
that our method enables fast and accurate quadrotor traversal through narrow
gates in confined environments. It achieves several orders of magnitude
improvement in sample efficiency compared to naive end-to-end RL approaches.

</details>


### [135] [Robust Convex Model Predictive Control with collision avoidance guarantees for robot manipulators](https://arxiv.org/abs/2508.21677)
*Bernhard Wullt,Johannes Köhler,Per Mattsson,Mikeal Norrlöf,Thomas B. Schön*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的基于鲁棒管MPC和走廊规划的凸MPC解决方案，用于工业机械臂在复杂且存在模型不确定性环境中的快速安全运动规划，并在仿真中验证其在更高不确定性下实现更快运动，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 工业机械臂在杂乱且存在模型不确定性的环境中，安全运动规划至关重要。为应对干扰，实际操作中速度常受限。因此，需要一种能保证快速安全运动的控制方法。

Method: 本文提出了一种新颖的模型预测控制（MPC）解决方案，其主要组成部分包括鲁棒管MPC和用于获得无碰撞运动的走廊规划算法。该解决方案形成一个凸MPC问题，可实现快速求解。

Result: 在具有模型参数不确定性的杂乱环境中，通过6自由度工业机器人的模拟验证，该方法能够工作在更高水平的模型不确定性下，并产生更快的运动，优于基准方法。

Conclusion: 所提出的MPC方法能够有效解决工业机械臂在复杂不确定环境下的快速安全运动规划问题，并在鲁棒性和运动速度方面均优于现有方法，具有实际应用价值。

Abstract: Industrial manipulators are normally operated in cluttered environments,
making safe motion planning important. Furthermore, the presence of
model-uncertainties make safe motion planning more difficult. Therefore, in
practice the speed is limited in order to reduce the effect of disturbances.
There is a need for control methods that can guarantee safe motions that can be
executed fast. We address this need by suggesting a novel model predictive
control (MPC) solution for manipulators, where our two main components are a
robust tube MPC and a corridor planning algorithm to obtain collision-free
motion. Our solution results in a convex MPC, which we can solve fast, making
our method practically useful. We demonstrate the efficacy of our method in a
simulated environment with a 6 DOF industrial robot operating in cluttered
environments with uncertainties in model parameters. We outperform benchmark
methods, both in terms of being able to work under higher levels of model
uncertainties, while also yielding faster motion.

</details>


### [136] [Can a mobile robot learn from a pedestrian model to prevent the sidewalk salsa?](https://arxiv.org/abs/2508.21690)
*Olger Siebinga,David Abbink*

Main category: cs.RO

TL;DR: 本研究利用强化学习（RL）与一个能模拟“人行道萨尔萨”现象的通信使能交互（CEI）模型，训练机器人学习如何与行人互动，以避免尴尬的碰撞，并展示了风险规避型RL代理在有效沟通意图方面的成功。


<details>
  <summary>Details</summary>
Motivation: 行人间的“人行道萨尔萨”现象（双方重复向同一侧避让）是隐性沟通失败的有趣案例。理解这种失败能揭示隐性沟通的机制，从而设计出安全可接受的机器人行为。现有的CEI模型能重现此现象，但因违反博弈论假设，无法直接用于机器人规划，因此需要一种新方法来利用该模型。

Method: 提出了一种概念验证方法，其中一个强化学习（RL）代理利用一个先前开发的、能够重现“人行道萨尔萨”现象的通信使能交互（CEI）模型来学习如何与行人互动。测试了两种RL代理：一个基础RL代理和一个能感知CEI模型感知风险的风险规避型RL代理。

Result: 基础RL代理成功学会了与CEI模型互动。风险规避型RL代理通过其运动学会了有效沟通意图，从而显著降低了CEI模型感知的风险，并显示出模型化行人所付出的努力。

Conclusion: 利用强化学习代理结合CEI模型来学习与行人互动是一个有前景的方法。该方法能够帮助机器人有效沟通意图，降低互动风险，并避免“人行道萨尔萨”等问题，鼓励进一步探索。

Abstract: Pedestrians approaching each other on a sidewalk sometimes end up in an
awkward interaction known as the "sidewalk salsa": they both (repeatedly)
deviate to the same side to avoid a collision. This provides an interesting use
case to study interactions between pedestrians and mobile robots because, in
the vast majority of cases, this phenomenon is avoided through a negotiation
based on implicit communication. Understanding how it goes wrong and how
pedestrians end up in the sidewalk salsa will therefore provide insight into
the implicit communication. This understanding can be used to design safe and
acceptable robotic behaviour. In a previous attempt to gain this understanding,
a model of pedestrian behaviour based on the Communication-Enabled Interaction
(CEI) framework was developed that can replicate the sidewalk salsa. However,
it is unclear how to leverage this model in robotic planning and
decision-making since it violates the assumptions of game theory, a much-used
framework in planning and decision-making. Here, we present a proof-of-concept
for an approach where a Reinforcement Learning (RL) agent leverages the model
to learn how to interact with pedestrians. The results show that a basic RL
agent successfully learned to interact with the CEI model. Furthermore, a
risk-averse RL agent that had access to the perceived risk of the CEI model
learned how to effectively communicate its intention through its motion and
thereby substantially lowered the perceived risk, and displayed effort by the
modelled pedestrian. These results show this is a promising approach and
encourage further exploration.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [137] [Traffic State Estimation in Congestion to Extend Applicability of DFOS](https://arxiv.org/abs/2508.21138)
*Yoshiyuki Yajima,Hemant Prasad,Daisuke Ikefuji,Hitoshi Sakurai,Manabu Otani*

Main category: eess.SY

TL;DR: 本文提出了一种基于数据同化的缺失值插补方法，以解决分布式光纤传感（DFOS）在严重拥堵时因车速过慢导致车辆轨迹和平均速度数据缺失的问题，从而提升DFOS在交通状态估计中的适用性。


<details>
  <summary>Details</summary>
Motivation: 分布式光纤传感（DFOS）能够提供实时、空间连续的交通监测数据，但在严重拥堵时，车辆速度过慢导致振动强度不足，无法获取车辆轨迹和平均速度，从而产生大量缺失值，限制了DFOS在拥堵情况下的应用。

Method: 提出了一种基于数据同化的缺失值插补方法，用于恢复DFOS在拥堵状态下缺失的平均速度数据。

Result: 在日本两条高速公路上的验证结果显示，插补后的平均速度与参考数据相比，平均绝对误差（MAE）仅比非缺失值的MAE增加了1.5 km/h，表明该方法能有效处理缺失数据。

Conclusion: 本研究通过有效处理缺失值问题，显著增强了DFOS在实际交通状态估计，特别是在拥堵场景下的广泛适用性。

Abstract: This paper presents a traffic state estimation (TSE) method in congestion for
distributed fiber-optic sensing (DFOS). DFOS detects vehicle driving vibrations
along the optical fiber and obtains their trajectories in the spatiotemporal
plane. From these trajectories, DFOS provides mean velocities for real-time
spatially continuous traffic monitoring without dead zones. However, when
vehicle vibration intensities are insufficiently low due to slow speed,
trajectories cannot be obtained, leading to missing values in mean velocity
data. It restricts DFOS applicability in severe congestion. Therefore, this
paper proposes a missing value imputation method based on data assimilation.
Our proposed method is validated on two expressways in Japan with the reference
data. The results show that the mean absolute error (MAE) of the imputed mean
velocities to the reference increases only by 1.5 km/h as compared with the MAE
of non-missing values. This study enhances the wide-range applicability of DFOS
in practical cases.

</details>


### [138] [$H_\infty$ Performance Analysis for Almost Periodic Piecewise Linear Systems with Application to Roll-to-Roll Manufacturing Control](https://arxiv.org/abs/2508.21199)
*Christopher Martin,Edward Kim,Enrique Velasquez,Wei Li,Dongmei Chen*

Main category: eess.SY

TL;DR: 本文提出了一种针对几乎周期分段线性系统（APPLS）的H∞性能分析方法和控制器合成算法，以实现扰动抑制，并在卷对卷（R2R）干转移系统中进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 几乎周期分段线性系统（APPLS）的扰动抑制对其性能至关重要，但目前尚缺乏能够保证扰动抑制效果的方法。

Method: 本研究首先开发了一种用于APPLS的H∞性能分析方法，并在此基础上提出了一种合成实用H∞控制器的算法。

Result: 实验结果表明，与未考虑系统切换结构基线H∞控制器相比，所提出的方法能够实现更不保守且性能显著优越的H∞控制器，并在先进制造系统（如R2R干转移）中得到了应用验证。

Conclusion: 所开发的H∞性能分析和控制器合成方法能够有效提高APPLS的扰动抑制能力，并为实际应用提供了更优的控制方案。

Abstract: An almost periodic piecewise linear system (APPLS) is a type of piecewise
linear system where the system cyclically switches between different modes,
each with an uncertain but bounded dwell-time. Process regulation, especially
disturbance rejection, is critical to the performance of these advanced
systems. However, a method to guarantee disturbance rejection has not been
developed. The objective of this study is to develop an $H_\infty$ performance
analysis method for APPLSs, building on which an algorithm to synthesize
practical $H_\infty$ controllers is proposed. As an application, the developed
methods are demonstrated with an advanced manufacturing system -- roll-to-roll
(R2R) dry transfer of two-dimensional materials and printed flexible
electronics. Experimental results show that the proposed method enables a less
conservative and much better performing $H_\infty$ controller compared with a
baseline $H_\infty$ controller that does not account for the uncertain system
switching structure.

</details>


### [139] [Cooperative Sensing Enhanced UAV Path-Following and Obstacle Avoidance with Variable Formation](https://arxiv.org/abs/2508.21316)
*Changheng Wang,Zhiqing Wei,Wangjun Jiang,Haoyue Jiang,Zhiyong Feng*

Main category: eess.SY

TL;DR: 本文提出了一种针对无人机（UAV）的高精度路径跟随、障碍物感知与避障方法，并设计了无冲突的任务融合调度策略，结合了深度强化学习、集成感知与通信技术和分层行为融合。


<details>
  <summary>Details</summary>
Motivation: 无人机在高机动性使其在救援和货物运输等民用领域具有广泛应用。为了安全高效地执行任务，路径跟随、感知和避障是至关重要的，同时需要解决这些子任务的冲突融合问题。

Method: 首先，开发了一种基于深度强化学习（DRL）的无人机编队路径跟随模型，并设计了带有自适应权重的奖励函数。其次，利用集成感知与通信（ISAC）信号进行障碍物检测，推导了克拉默-劳下界（CRLB），并提出了可变编队增强障碍物位置估计（VFEO）算法。此外，设计了一种无需预训练的在线避障方案来解决稀疏奖励问题。最后，借助基于零空间（NSB）的行为方法，提出了一种分层子任务融合策略。

Result: 仿真结果表明，所提出的子任务算法和分层融合策略均具有有效性和优越性。

Conclusion: 本文成功地实现了无人机的高效精确路径跟随、障碍物感知与避障，并提出了无冲突的子任务分层融合调度策略，有效解决了无人机安全飞行的关键挑战。

Abstract: The high mobility of unmanned aerial vehicles (UAVs) enables them to be used
in various civilian fields, such as rescue and cargo transport. Path-following
is a crucial way to perform these tasks while sensing and collision avoidance
are essential for safe flight. In this paper, we investigate how to efficiently
and accurately achieve path-following, obstacle sensing and avoidance subtasks,
as well as their conflict-free fusion scheduling. Firstly, a high precision
deep reinforcement learning (DRL)-based UAV formation path-following model is
developed, and the reward function with adaptive weights is designed from the
perspective of distance and velocity errors. Then, we use integrated sensing
and communication (ISAC) signals to detect the obstacle and derive the
Cramer-Rao lower bound (CRLB) for obstacle sensing by information-level fusion,
based on which we propose the variable formation enhanced obstacle position
estimation (VFEO) algorithm. In addition, an online obstacle avoidance scheme
without pretraining is designed to solve the sparse reward. Finally, with the
aid of null space based (NSB) behavioral method, we present a hierarchical
subtasks fusion strategy. Simulation results demonstrate the effectiveness and
superiority of the subtask algorithms and the hierarchical fusion strategy.

</details>


### [140] [State and Input Constrained Model Reference Adaptive Control with Robustness and Feasibility Analysis](https://arxiv.org/abs/2508.21584)
*Poulomee Ghosh,Shubhendu Bhasin*

Main category: eess.SY

TL;DR: 本文提出了一种针对不确定线性时不变(LTI)系统、存在未匹配有界扰动且具有用户定义状态和输入约束的模型参考自适应控制器(MRAC)，该控制器无需优化。


<details>
  <summary>Details</summary>
Motivation: 现有的基于优化的约束控制方法（如MPC和CBF）每一步都需要解决一个优化问题。本研究旨在开发一种无需优化且自适应的控制器，能同时处理不确定性、扰动以及状态和输入约束，并且是首次同时考虑这两种约束的方案。

Method: 该方法结合了饱和自适应控制器和基于障碍李雅普诺夫函数(BLF)的设计。它通过这种组合来确保植物状态和输入始终保持在预设范围内。

Result: 该控制器在存在未匹配扰动的情况下，能确保植物状态和输入始终保持在预设范围内。它还提供了足够的判别条件来检查可接受控制策略的存在性。仿真结果（包括与鲁棒MRAC的比较）证明了所提出算法的有效性。

Conclusion: 所提出的MRAC算法是一种有效、无需优化的自适应解决方案，适用于具有状态和输入约束、不确定性以及扰动的LTI系统，并且在保证系统性能方面表现出色。

Abstract: We propose a model reference adaptive controller (MRAC) for uncertain linear
time-invariant (LTI) plants with user-defined state and input constraints in
the presence of unmatched bounded disturbances. Unlike popular
optimization-based approaches for constrained control, such as model predictive
control (MPC) and control barrier function (CBF) that solve a constrained
optimization problem at each step using the system model, our approach is
optimization-free and adaptive; it combines a saturated adaptive controller
with a barrier Lyapunov function (BLF)-based design to ensure that the plant
state and input always stay within pre-specified bounds despite the presence of
unmatched disturbances. To the best of our knowledge, this is the first result
that considers both state and input constraints for control of uncertain
systems with disturbances and provides sufficient feasibility conditions to
check for the existence of an admissible control policy. Simulation results,
including a comparison with a robust MRAC, demonstrate the effectiveness of the
proposed algorithm.

</details>


### [141] [Model Reference Adaptive Control with Time-Varying State and Input Constraints](https://arxiv.org/abs/2508.21586)
*Poulomee Ghosh,Shubhendu Bhasin*

Main category: eess.SY

TL;DR: 本文提出了一种模型参考自适应控制（MRAC）框架，用于处理不确定线性时不变（LTI）系统中的时变状态和输入约束，且无需在线优化。


<details>
  <summary>Details</summary>
Motivation: 在不确定LTI系统中，同时处理用户定义的时变状态和输入约束是一个挑战，现有自适应控制方法通常需要在线优化来解决此类问题。

Method: 该方法将时变障碍李雅普诺夫函数（TVBLF）与时变饱和函数无缝集成，分别用于强制执行状态约束和处理输入限制。此外，还推导出了一个可验证的离线可行性条件，以检查给定约束下有效控制策略的存在性。

Result: 仿真结果验证了所提出的约束MRAC方案的有效性。据作者所知，这是首个无需在线优化即可同时处理时变状态和输入约束的自适应控制方法。

Conclusion: 该MRAC框架能够有效地在不确定LTI系统中处理用户定义的时变状态和输入约束，并通过离线可行性条件确保控制策略的存在，为相关应用提供了新的解决方案。

Abstract: This paper presents a model reference adaptive control (MRAC) framework for
uncertain linear time-invariant (LTI) systems subject to user-defined,
time-varying state and input constraints. The proposed design seamlessly
integrates a time-varying barrier Lyapunov function (TVBLF) to enforce state
constraints with a time-varying saturation function to handle input limits.
These time-varying constraints can be designed as performance functions to
shape transient and steady-state behaviors for both state and input. A key
contribution is the derivation of a verifiable, offline feasibility condition
to check the existence of a valid control policy for a given set of
constraints. To the best of our knowledge, this is the first adaptive control
methodology to simultaneously handle both time-varying state and input
constraints without resorting to online optimization. Simulation results
validate the efficacy of the proposed constrained MRAC scheme.

</details>


### [142] [Adaptive Dead-Zone Dual Sliding Mode Observer for Reliable Electrochemical Model-Based SOC Estimation](https://arxiv.org/abs/2508.21610)
*Guangdi Hu,Keyi Liao,Jian Ye,Feng Guo*

Main category: eess.SY

TL;DR: 本文提出了一种基于改进电化学单颗粒模型的自适应死区双滑模观测器（SMO），用于锂离子电池荷电状态（SOC）估计，实现了高精度、计算效率和对电池老化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 准确的SOC估算对于锂离子电池的安全、可靠性和效率至关重要。电化学模型虽然精度高，但面临参数变化、非线性和计算复杂性等挑战，需要解决这些问题以实现实际应用。

Method: 该研究提出了一种基于改进电化学单颗粒模型的自适应死区双滑模观测器。该算法集成了用于SOC估算的状态观测器和用于在线参数自适应的参数观测器。引入了基于Lyapunov导数的自适应死区机制，确保稳定性，并仅当端电压误差在严格定义的范围内时才激活参数更新。该方法在恒流和UDDS动态条件下以及通过循环老化模型进行了验证。

Result: 与传统双SMO和基于等效电路模型的EKF方法相比，所提出的自适应死区双SMO表现出卓越的精度，在正确初始化下SOC估算误差保持在0.2%以内，在30%初始SOC误差下低于1%，且收敛迅速。通过限制不必要的参数更新，该方法还降低了计算执行时间。此外，通过循环老化模型证实了其在电池老化下的鲁棒性，即使参数漂移也能保持稳定的SOC估算。

Conclusion: 所提出的自适应死区双滑模观测器为锂离子电池的SOC估算提供了一种可靠、准确且计算高效的解决方案，非常适用于实时电池管理应用。

Abstract: Accurate state of charge (SOC) estimation is critical for ensuring the
safety, reliability, and efficiency of lithium-ion batteries in electric
vehicles and energy storage systems. Electrochemical models provide high
fidelity for SOC estimation but introduce challenges due to parameter
variations, nonlinearities, and computational complexity. To address these
issues, this paper proposes an adaptive dead-zone dual sliding mode
observer(SMO) based on an improved electrochemical single-particle model. The
algorithm integrates a state observer for SOC estimation and a parameter
observer for online parameter adaptation. A Lyapunov-derived adaptive dead-zone
is introduced to ensure stability, activating parameter updates only when the
terminal voltage error lies within a rigorously defined bound. The proposed
method was validated under constant-current and UDDS dynamic conditions.
Results demonstrate that the adaptive dead-zone dual SMO achieves superior
accuracy compared with conventional dual SMO and equivalent circuit model-based
EKF methods, maintaining SOC estimation errors within 0.2% under correct
initialization and below 1% under a 30% initial SOC error, with rapid
convergence. Computational efficiency analysis further shows that the adaptive
dead-zone dual sliding mode observer reduces execution time compared with the
conventional dual SMO by limiting unnecessary parameter updates, highlighting
its suitability for real-time battery management applications. Moreover,
robustness under battery aging was confirmed using a cycle-aging model, where
the adaptive dead-zone dual SMO maintained stable SOC estimation despite
parameter drift. These findings indicate that the proposed method offers a
reliable, accurate, and computationally efficient solution for SOC estimation.

</details>


### [143] [Adapting to Change: A Comparison of Continual and Transfer Learning for Modeling Building Thermal Dynamics under Concept Drifts](https://arxiv.org/abs/2508.21615)
*Fabian Raisch,Max Langtry,Felix Koch,Ruchi Choudhary,Christoph Goebel,Benjamin Tischler*

Main category: eess.SY

TL;DR: 本研究比较了持续学习（CL）和迁移学习（TL）策略，用于在数据持续收集和概念漂移（如改造或占用变化）情况下更新建筑热力学模型，并提出了一种名为季节记忆学习（SML）的CL策略，该策略在准确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当数据有限时，迁移学习（TL）是建模建筑热力学最有效的方法。然而，随着时间推移收集到更多操作测量数据后，如何继续更新模型，尤其是在建筑动力学发生变化（例如改造或占用变化）时，仍不清楚。目前缺乏一项关于如何随时间整合新数据以提高预测准确性并解决概念漂移挑战的全面研究。

Method: 本研究比较了几种持续学习（CL）和迁移学习（TL）策略，以及从零开始训练的模型，用于建筑运行期间的热力学建模。方法通过5-7年的模拟数据进行评估，这些数据代表了中欧的独栋住宅，包括有概念漂移（改造和占用变化）的场景。研究提出了一种新的CL策略，即季节记忆学习（SML）。

Result: 提出的SML策略比现有的CL和TL方法提供了更大的准确性改进，同时保持了较低的计算量。在没有概念漂移的情况下，SML比初始微调基准提高了28.1%；在有概念漂移的情况下，提高了34.9%。

Conclusion: SML是一种有效的持续学习策略，能够随着时间的推移不断更新建筑热力学模型，显著提高预测准确性，并更好地应对概念漂移的挑战，优于现有的CL和TL方法。

Abstract: Transfer Learning (TL) is currently the most effective approach for modeling
building thermal dynamics when only limited data are available. TL uses a
pretrained model that is fine-tuned to a specific target building. However, it
remains unclear how to proceed after initial fine-tuning, as more operational
measurement data are collected over time. This challenge becomes even more
complex when the dynamics of the building change, for example, after a retrofit
or a change in occupancy. In Machine Learning literature, Continual Learning
(CL) methods are used to update models of changing systems. TL approaches can
also address this challenge by reusing the pretrained model at each update step
and fine-tuning it with new measurement data. A comprehensive study on how to
incorporate new measurement data over time to improve prediction accuracy and
address the challenges of concept drifts (changes in dynamics) for building
thermal dynamics is still missing.
  Therefore, this study compares several CL and TL strategies, as well as a
model trained from scratch, for thermal dynamics modeling during building
operation. The methods are evaluated using 5--7 years of simulated data
representative of single-family houses in Central Europe, including scenarios
with concept drifts from retrofits and changes in occupancy. We propose a CL
strategy (Seasonal Memory Learning) that provides greater accuracy improvements
than existing CL and TL methods, while maintaining low computational effort.
SML outperformed the benchmark of initial fine-tuning by 28.1\% without concept
drifts and 34.9\% with concept drifts.

</details>


### [144] [Chance-Constrained DC Optimal Power Flow Using Constraint-Informed Statistical Estimation](https://arxiv.org/abs/2508.21687)
*Tianyang Yi,D. Adrian Maldonado,Anirudh Subramanyam*

Main category: eess.SY

TL;DR: 本文提出一种新颖方法，通过利用约束结构对直流最优潮流（DC-OPF）模型中的不确定性进行降维建模与估计，显著提升了统计精度和优化性能。


<details>
  <summary>Details</summary>
Motivation: 机会约束优化是管理电力系统不确定性的有效框架，但现有方法在DC-OPF中对随机节点注入进行高维统计分布建模，效率不高。本研究旨在改进DC-OPF中的不确定性建模和估计。

Method: 提出一种替代方法，利用约束结构指导不确定性估计以实现显著降维。具体地，该方法直接建模一维聚合系统预测误差和二维加权电力传输分布因子线路误差，而非学习净负荷预测误差的联合分布。研究在高斯和非高斯分布下，使用合成和真实世界数据集评估了该方法。

Result: 与现有方法相比，在统计精度和优化性能方面均取得了显著改进。

Conclusion: 所提出的不确定性建模和估计方法通过降维和更有效的误差表征，显著提升了DC-OPF在不确定性管理方面的性能。

Abstract: Chance-constrained optimization has emerged as a promising framework for
managing uncertainties in power systems. This work advances its application to
the DC Optimal Power Flow (DC-OPF) model, developing a novel approach to
uncertainty modeling and estimation. Current methods typically tackle these
problems by first modeling random nodal injections using high-dimensional
statistical distributions that scale with the number of buses, followed by
deriving deterministic reformulations of the probabilistic constraints. We
propose an alternative methodology that exploits the constraint structure to
inform the uncertainties to be estimated, enabling significant dimensionality
reduction. Rather than learning joint distributions of net-load forecast errors
across units, we instead directly model the one-dimensional aggregate system
forecast error and two-dimensional line errors weighted by power transfer
distribution factors. We evaluate our approach under both Gaussian and
non-Gaussian distributions on synthetic and real-world datasets, demonstrating
significant improvements in statistical accuracy and optimization performance
compared to existing methods.

</details>


### [145] [Transferring the driveshaft inertia to the grid via the DC-link in MV drive systems](https://arxiv.org/abs/2508.21760)
*Catalin Arghir,Pieder Jörg,Silvia Mastellone*

Main category: eess.SY

TL;DR: 本文提出了一种控制方法，旨在使中压传动系统中的传动轴惯量完全可用于电网侧，并增强系统的故障穿越能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机是提高中压传动系统的故障穿越性能，并使传动轴的惯量能够有效地反馈到电网侧，以增强系统稳定性。

Method: 该方法主要包括两方面：一是通过修改速度控制参考信号和调整直流母线控制策略（包括传统的级联控制和基于同步电机模型匹配的两种方案），将传动轴的旋转惯量同步耦合到电网；二是通过“射线-圆互补性”将标准锁相环（PLL）和模型匹配控制解释为具有不同稳态映射的反馈优化方案，从而揭示模型匹配控制中嵌入的PLL及其限流和跟踪能力。

Result: 研究结果表明，通过所提出的控制方法，传动轴的旋转惯量可以同步耦合到电网。同时，模型匹配控制方法被证明内嵌了锁相环功能，并展示了其电流限制和跟踪能力。通过广泛的仿真研究验证了这些发现。

Conclusion: 该控制方法成功地将传动轴惯量应用于电网侧，显著提升了中压传动系统的故障穿越性能，并为锁相环和模型匹配控制提供了新的解释和理解，尤其突出了模型匹配控制的实用优势。

Abstract: This paper investigates a control approach that renders the driveshaft
inertia completely available on the grid side and enhances the fault
ride-through behavior of medium-voltage (MV) drive systems. Two main
contributions are presented. First, we show how the rotational inertia of the
driveline shaft can be synchronously coupled to the grid through a modification
of the speed control reference signal and through an adapted DC-link control
strategy. For the latter, we pursue two alternatives: one based on conventional
cascaded control and another based on synchronous machine (SM) model matching.
Second, we demonstrate that both the standard phase-locked loop (PLL) and the
matching control approach can be interpreted, via the ray-circle
complementarity, as feedback optimization schemes with distinct steady-state
maps. This perspective allows us to revisit matching control, reveal its
embedded PLL, highlight its current-limiting and tracking capabilities, and
provide an extensive simulation study.

</details>


### [146] [DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers](https://arxiv.org/abs/2508.21797)
*Navid Aftabi,Abhishek Hanchate,Satish Bukkapatnam,Dan Li*

Main category: eess.SY

TL;DR: DynaMark是一个基于强化学习的自适应动态水印框架，用于保护工业4.0机床控制器免受重放攻击，它能在线优化水印参数以平衡控制性能、能耗和检测置信度，并在数字孪生和物理测试台上展现出卓越的性能提升。


<details>
  <summary>Details</summary>
Motivation: 工业4.0中高度网络化的机床控制器（MTCs）容易遭受利用过时传感器数据操纵执行器的重放攻击。现有动态水印方案假设线性高斯动力学并使用恒定水印统计量，这使其无法应对MTCs时变、部分专有的行为。

Method: 本研究提出了DynaMark，一个将动态水印建模为马尔可夫决策过程（MDP）的强化学习框架。它在线学习自适应策略，根据可用测量和检测器反馈动态调整零均值高斯水印的协方差，无需系统知识。DynaMark最大化一个独特的奖励函数，以动态平衡控制性能、能耗和检测置信度。此外，还为线性系统开发了一种用于实时检测置信度的贝叶斯信念更新机制。

Result: 在西门子Sinumerik 828D控制器数字孪生上，与恒定方差基线相比，DynaMark在保持标称轨迹的同时，将水印能耗降低了70%，并保持了相当于一个采样间隔的平均检测延迟。物理步进电机测试台验证了这些发现，实现了更快的警报触发，同时控制性能下降更少，并超越了现有基准。

Conclusion: DynaMark提供了一种无需特定系统假设的自适应动态水印解决方案，能够有效检测工业4.0机床控制器中的重放攻击，显著降低水印能耗，同时保持或改进控制性能和检测速度，优于现有方法。

Abstract: Industry 4.0's highly networked Machine Tool Controllers (MTCs) are prime
targets for replay attacks that use outdated sensor data to manipulate
actuators. Dynamic watermarking can reveal such tampering, but current schemes
assume linear-Gaussian dynamics and use constant watermark statistics, making
them vulnerable to the time-varying, partly proprietary behavior of MTCs. We
close this gap with DynaMark, a reinforcement learning framework that models
dynamic watermarking as a Markov decision process (MDP). It learns an adaptive
policy online that dynamically adapts the covariance of a zero-mean Gaussian
watermark using available measurements and detector feedback, without needing
system knowledge. DynaMark maximizes a unique reward function balancing control
performance, energy consumption, and detection confidence dynamically. We
develop a Bayesian belief updating mechanism for real-time detection confidence
in linear systems. This approach, independent of specific system assumptions,
underpins the MDP for systems with linear dynamics. On a Siemens Sinumerik 828D
controller digital twin, DynaMark achieves a reduction in watermark energy by
70% while preserving the nominal trajectory, compared to constant variance
baselines. It also maintains an average detection delay equivalent to one
sampling interval. A physical stepper-motor testbed validates these findings,
rapidly triggering alarms with less control performance decline and exceeding
existing benchmarks.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [147] [Deep Active Learning for Lung Disease Severity Classification from Chest X-rays: Learning with Less Data in the Presence of Class Imbalance](https://arxiv.org/abs/2508.21263)
*Roy M. Gabriel,Mohammadreza Zandehshahvar,Marly van Assen,Nattakorn Kittisut,Kyle Peters,Carlo N. De Cecco,Ali Adibi*

Main category: eess.IV

TL;DR: 本研究利用深度主动学习结合贝叶斯神经网络（BNN）近似和加权损失函数，在类别不平衡下有效减少了胸部X光片（CXR）肺部疾病严重程度分类所需的标注数据量。


<details>
  <summary>Details</summary>
Motivation: 在胸部X光片上进行肺部疾病严重程度分类时，通常需要大量标注数据，并且面临类别不平衡问题。研究旨在减少所需标注数据的数量。

Method: 本研究回顾性收集了2,319张来自963名COVID-19患者的CXR图像，由3至6名放射科医生独立标注为正常、中度或重度。采用带有Monte Carlo Dropout的深度神经网络，通过主动学习进行疾病严重程度分类。使用多种采集函数从无标签池中迭代选择信息量最大的样本。性能评估指标包括准确率、AU ROC和AU PRC，并记录了训练时间和采集时间。统计分析包括描述性指标和不同采集策略的性能比较。

Result: 在二分类（正常 vs. 患病）任务中，熵采样（Entropy Sampling）仅使用15.4%的训练数据就达到了93.7%的准确率（AU ROC为0.91）。在多分类任务中，均值标准差采样（Mean STD sampling）使用23.1%的标注数据达到了70.3%的准确率（AU ROC为0.86）。这些方法优于更复杂、计算成本更高的采集函数，并显著减少了标注需求。

Conclusion: 结合BNN近似和加权损失的深度主动学习方法，能够有效减少标注数据需求，同时解决类别不平衡问题，并保持或超越诊断性能。

Abstract: To reduce the amount of required labeled data for lung disease severity
classification from chest X-rays (CXRs) under class imbalance, this study
applied deep active learning with a Bayesian Neural Network (BNN) approximation
and weighted loss function. This retrospective study collected 2,319 CXRs from
963 patients (mean age, 59.2 $\pm$ 16.6 years; 481 female) at Emory Healthcare
affiliated hospitals between January and November 2020. All patients had
clinically confirmed COVID-19. Each CXR was independently labeled by 3 to 6
board-certified radiologists as normal, moderate, or severe. A deep neural
network with Monte Carlo Dropout was trained using active learning to classify
disease severity. Various acquisition functions were used to iteratively select
the most informative samples from an unlabeled pool. Performance was evaluated
using accuracy, area under the receiver operating characteristic curve (AU
ROC), and area under the precision-recall curve (AU PRC). Training time and
acquisition time were recorded. Statistical analysis included descriptive
metrics and performance comparisons across acquisition strategies. Entropy
Sampling achieved 93.7% accuracy (AU ROC, 0.91) in binary classification
(normal vs. diseased) using 15.4% of the training data. In the multi-class
setting, Mean STD sampling achieved 70.3% accuracy (AU ROC, 0.86) using 23.1%
of the labeled data. These methods outperformed more complex and
computationally expensive acquisition functions and significantly reduced
labeling needs. Deep active learning with BNN approximation and weighted loss
effectively reduces labeled data requirements while addressing class imbalance,
maintaining or exceeding diagnostic performance.

</details>
