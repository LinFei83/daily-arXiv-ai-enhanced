<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 30]
- [cs.CV](#cs.CV) [Total: 56]
- [cs.CL](#cs.CL) [Total: 55]
- [cs.RO](#cs.RO) [Total: 10]
- [eess.SY](#eess.SY) [Total: 10]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Mathematical Knowledge Graph-Driven Framework for Equation-Based Predictive and Reliable Additive Manufacturing](https://arxiv.org/abs/2601.05298)
*Yeongbin Cha,Namjung Kim*

Main category: cs.AI

TL;DR: 本研究提出了一种结合大语言模型（LLM）和增材制造数学知识图谱（AM-MKG）的本体驱动、以方程为中心的框架，用于可靠的知识提取和外插建模。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动方法在知识表示零散和稀疏数据条件下外插能力不足，限制了增材制造过程-性能关系的研究。

Method: 利用本体显式编码方程、变量、假设及其语义关系，构建AM-MKG。LLM根据MKG导出的子图生成方程，并通过外插距离、统计稳定性和物理一致性评估外插的置信度。

Result: 本体驱动的知识提取提高了结构连贯性和定量可靠性。子图条件下的方程生成比无条件LLM输出更稳定、物理上更一致。提出的置信度评分方法能更全面地评估外插的可靠性。

Conclusion: 知识图谱增强的LLM通过本体驱动的知识表示、以方程为中心的推理和基于置信度的外插评估，可作为增材制造中可靠的外插建模工具。

Abstract: Additive manufacturing (AM) relies critically on understanding and extrapolating process-property relationships; however, existing data-driven approaches remain limited by fragmented knowledge representations and unreliable extrapolation under sparse data conditions. In this study, we propose an ontology-guided, equation-centric framework that tightly integrates large language models (LLMs) with an additive manufacturing mathematical knowledge graph (AM-MKG) to enable reliable knowledge extraction and principled extrapolative modeling. By explicitly encoding equations, variables, assumptions, and their semantic relationships within a formal ontology, unstructured literature is transformed into machine-interpretable representations that support structured querying and reasoning. LLM-based equation generation is further conditioned on MKG-derived subgraphs, enforcing physically meaningful functional forms and mitigating non-physical or unstable extrapolation trends. To assess reliability beyond conventional predictive uncertainty, a confidence-aware extrapolation assessment is introduced, integrating extrapolation distance, statistical stability, and knowledge-graph-based physical consistency into a unified confidence score. Results demonstrate that ontology-guided extraction significantly improves the structural coherence and quantitative reliability of extracted knowledge, while subgraph-conditioned equation generation yields stable and physically consistent extrapolations compared to unguided LLM outputs. Overall, this work establishes a unified pipeline for ontology-driven knowledge representation, equation-centered reasoning, and confidence-based extrapolation assessment, highlighting the potential of knowledge-graph-augmented LLMs as reliable tools for extrapolative modeling in additive manufacturing.

</details>


### [2] [Naiad: Novel Agentic Intelligent Autonomous System for Inland Water Monitoring](https://arxiv.org/abs/2601.05256)
*Eirini Baltzi,Tilemachos Moumouris,Athena Psalta,Vasileios Tsironis,Konstantinos Karantzalos*

Main category: cs.AI

TL;DR: NAIAD 是一个基于 LLM 的 AI 助手，利用地球观测数据和外部工具，提供了一个整体的水质监测解决方案，能够通过单一的自然语言提示生成可操作的见解。


<details>
  <summary>Details</summary>
Motivation: 现有的水质监测方法通常只关注孤立的问题，如蓝藻、叶绿素等，缺乏一个全面的解决方案。NAIAD 旨在为专家和非专家提供一个统一的界面，以更全面、更易用的方式进行内陆水体监测。

Method: NAIAD 采用检索增强生成 (RAG)、LLM 推理、外部工具编排、计算图执行和代理反思等技术。它整合了天气数据、Sentinel-2 影像、遥感指数计算（如 NDCI）、叶绿素-a 估算以及 CyFi 等现有平台，并能根据用户提示生成定制化报告。

Result: 在包含不同用户专业水平的基准测试中，NAIAD 的正确率和相关性分别达到了 77% 和 85% 以上。Gemma 3 (27B) 和 Qwen 2.5 (14B) 在计算效率和推理性能之间取得了最佳平衡。

Conclusion: NAIAD 成功地提供了一个整体性的、用户友好的内陆水体监测解决方案，能够有效地处理各种查询类型，并展示出良好的适应性和鲁棒性。

Abstract: Inland water monitoring is vital for safeguarding public health and ecosystems, enabling timely interventions to mitigate risks. Existing methods often address isolated sub-problems such as cyanobacteria, chlorophyll, or other quality indicators separately. NAIAD introduces an agentic AI assistant that leverages Large Language Models (LLMs) and external analytical tools to deliver a holistic solution for inland water monitoring using Earth Observation (EO) data. Designed for both experts and non-experts, NAIAD provides a single-prompt interface that translates natural-language queries into actionable insights. Through Retrieval-Augmented Generation (RAG), LLM reasoning, external tool orchestration, computational graph execution, and agentic reflection, it retrieves and synthesizes knowledge from curated sources to produce tailored reports. The system integrates diverse tools for weather data, Sentinel-2 imagery, remote-sensing index computation (e.g., NDCI), chlorophyll-a estimation, and established platforms such as CyFi. Performance is evaluated using correctness and relevancy metrics, achieving over 77% and 85% respectively on a dedicated benchmark covering multiple user-expertise levels. Preliminary results show strong adaptability and robustness across query types. An ablation study on LLM backbones further highlights Gemma 3 (27B) and Qwen 2.5 (14B) as offering the best balance between computational efficiency and reasoning performance.

</details>


### [3] [Improving Enzyme Prediction with Chemical Reaction Equations by Hypergraph-Enhanced Knowledge Graph Embeddings](https://arxiv.org/abs/2601.05330)
*Tengwei Song,Long Yin,Zhen Han,Zhiqiang Xu*

Main category: cs.AI

TL;DR: 本文提出了一种名为Hyper-Enz的新模型，利用知识图谱嵌入和超图Transformer来预测酶-底物相互作用，克服了传统方法在数据稀疏性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的酶-底物相互作用预测方法依赖于稀疏且维护成本高昂的专家知识库，难以泛化到未知的相互作用。作者希望利用更易获取且数据更丰富的化学反应方程式来解决这个问题。

Method: 将化学反应方程式表示为(反应物, 酶, 产物)的三元组，构建知识图谱。利用知识图谱嵌入（KGE）来推断缺失的酶-底物对。提出了一种名为Hyper-Enz的模型，结合了超图Transformer和KGE，以捕获多反应物和多产物之间的复杂关系。此外，引入了多专家范式来指导模型的学习。

Result: 与传统模型相比，Hyper-Enz在酶检索准确性方面取得了高达88%的相对提升，在对级别预测方面取得了30%的提升。

Conclusion: 所提出的Hyper-Enz模型通过知识图谱嵌入和超图Transformer的结合，有效地解决了酶-底物相互作用预测中的数据稀疏性问题，并显著提高了预测性能。

Abstract: Predicting enzyme-substrate interactions has long been a fundamental problem in biochemistry and metabolic engineering. While existing methods could leverage databases of expert-curated enzyme-substrate pairs for models to learn from known pair interactions, the databases are often sparse, i.e., there are only limited and incomplete examples of such pairs, and also labor-intensive to maintain. This lack of sufficient training data significantly hinders the ability of traditional enzyme prediction models to generalize to unseen interactions. In this work, we try to exploit chemical reaction equations from domain-specific databases, given their easier accessibility and denser, more abundant data. However, interactions of multiple compounds, e.g., educts and products, with the same enzymes create complex relational data patterns that traditional models cannot easily capture. To tackle that, we represent chemical reaction equations as triples of (educt, enzyme, product) within a knowledge graph, such that we can take advantage of knowledge graph embedding (KGE) to infer missing enzyme-substrate pairs for graph completion. Particularly, in order to capture intricate relationships among compounds, we propose our knowledge-enhanced hypergraph model for enzyme prediction, i.e., Hyper-Enz, which integrates a hypergraph transformer with a KGE model to learn representations of the hyper-edges that involve multiple educts and products. Also, a multi-expert paradigm is introduced to guide the learning of enzyme-substrate interactions with both the proposed model and chemical reaction equations. Experimental results show a significant improvement, with up to a 88% relative improvement in average enzyme retrieval accuracy and 30% improvement in pair-level prediction compared to traditional models, demonstrating the effectiveness of our approach.

</details>


### [4] [Effects of personality steering on cooperative behavior in Large Language Model agents](https://arxiv.org/abs/2601.05302)
*Mizuki Sakai,Mizuki Yokoyama,Wakaba Tateishi,Genki Ichinose*

Main category: cs.AI

TL;DR: 本研究通过重复囚徒困境游戏，探究了在大语言模型（LLM）中引入“大五人格”特征对合作行为的影响。结果表明，宜人性是促进合作的最主要因素，而其他特征影响有限。明确的个性信息能提高合作水平，但也可能增加被剥削的风险，尤其是在早期模型中。后期模型则表现出更具选择性的合作。


<details>
  <summary>Details</summary>
Motivation: 尽管有研究表明为LLM分配人格特征会影响其行为，但具体在可控条件下，人格塑造对合作行为的影响机制尚不明确。本研究旨在解决这一问题。

Method: 研究者首先使用“大五人格量表”（Big Five Inventory）测量了GPT-3.5-turbo、GPT-4o和GPT-5三种模型的基准人格特征。随后，在重复囚徒困境游戏中，比较了这些模型在基线条件和有人格信息条件下的行为表现。此外，还单独将每个性格维度操纵到极端值，以分析其独立影响。

Result: 研究发现，宜人性（Agreeableness）是促进所有模型合作行为的最主要因素，其他性格特征的影响则相对有限。明确的人格信息能够提升合作水平，但同时也可能增加模型被剥削的脆弱性，尤其是在早期模型中。相比之下，后期模型表现出更具选择性的合作策略。

Conclusion: 人格塑造机制在LLM中起到的是一种行为偏向作用，而非完全的决定性控制。宜人性是影响合作行为的关键人格维度。模型代际的差异导致了合作策略的演变，后期模型在整合人格信息和应对策略上更加成熟。

Abstract: Large language models (LLMs) are increasingly used as autonomous agents in strategic and social interactions. Although recent studies suggest that assigning personality traits to LLMs can influence their behavior, how personality steering affects cooperation under controlled conditions remains unclear. In this study, we examine the effects of personality steering on cooperative behavior in LLM agents using repeated Prisoner's Dilemma games. Based on the Big Five framework, we first measure basic personality profiles of three models, GPT-3.5-turbo, GPT-4o, and GPT-5, using the Big Five Inventory. We then compare behavior under baseline and personality-informed conditions, and further analyze the effects of independently manipulating each personality dimension to extreme values. Our results show that agreeableness is the dominant factor promoting cooperation across all models, while other personality traits have limited impact. Explicit personality information increases cooperation but can also raise vulnerability to exploitation, particularly in earlier-generation models. In contrast, later-generation models exhibit more selective cooperation. These findings indicate that personality steering acts as a behavioral bias rather than a deterministic control mechanism.

</details>


### [5] [Conformity and Social Impact on AI Agents](https://arxiv.org/abs/2601.05384)
*Alessandro Bellina,Giordano De Marzo,David Garcia*

Main category: cs.AI

TL;DR: 大型多模态语言模型作为AI代理在群体环境中表现出系统性的从众偏见，即使在独立表现近乎完美时也易受社会影响操纵，这揭示了AI决策中的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理越来越多地在多智能体环境中运行，理解它们的集体行为对于预测人工社会的动态至关重要，特别是考察它们是否会像人类一样表现出从众行为。

Method: 通过改编经典的社会心理学视觉实验，研究人员在多智能体环境中测试了AI代理对群体影响的反应，考察了群体规模、意见一致性、任务难度和信息源特征等因素。

Result: AI代理表现出系统性的从众偏见，对群体影响敏感。即使在独立测试中表现出色的模型，在群体压力下也会变得非常容易被操纵。虽然更大规模的模型在简单任务上从众性较低，但在接近其能力边界时仍然容易受到影响。

Conclusion: AI代理的决策过程存在根本性的安全漏洞，可能被恶意操纵，导致在多智能体系统中传播错误信息和偏见。因此，在部署集体AI时，迫切需要建立安全防护措施。

Abstract: As AI agents increasingly operate in multi-agent environments, understanding their collective behavior becomes critical for predicting the dynamics of artificial societies. This study examines conformity, the tendency to align with group opinions under social pressure, in large multimodal language models functioning as AI agents. By adapting classic visual experiments from social psychology, we investigate how AI agents respond to group influence as social actors. Our experiments reveal that AI agents exhibit a systematic conformity bias, aligned with Social Impact Theory, showing sensitivity to group size, unanimity, task difficulty, and source characteristics. Critically, AI agents achieving near-perfect performance in isolation become highly susceptible to manipulation through social influence. This vulnerability persists across model scales: while larger models show reduced conformity on simple tasks due to improved capabilities, they remain vulnerable when operating at their competence boundary. These findings reveal fundamental security vulnerabilities in AI agent decision-making that could enable malicious manipulation, misinformation campaigns, and bias propagation in multi-agent systems, highlighting the urgent need for safeguards in collective AI deployments.

</details>


### [6] [The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models](https://arxiv.org/abs/2601.05376)
*Tassallah Abdullahi,Shrestha Ghosh,Hamish S Fraser,Daniel León Tramontini,Adeel Abbasi,Ghada Bourjeily,Carsten Eickhoff,Ritambhara Singh*

Main category: cs.AI

TL;DR: 研究人员系统地评估了用于临床决策的语言模型（LLMs）中的角色扮演（persona）效应。他们发现，在紧急护理等关键任务中，医学角色可以提高准确性和校准率，但在初级保健中则会降低性能。互动风格的影响因模型而异。尽管LLM裁判器偏好医学角色，但人类临床医生在安全合规性方面的评价一致性较低，并且对推理质量的信心不足。研究表明，角色扮演引入了与情境相关的权衡，而不是安全或专业知识的保证。


<details>
  <summary>Details</summary>
Motivation: 现有研究假定角色扮演（persona）作为一种行为先验，能单调地提升大型语言模型（LLMs）的专业性和安全性，但其在医疗高风险决策中的具体影响仍未得到充分研究。因此，本研究旨在系统地评估角色扮演对临床LLM行为的影响。

Method: 研究人员系统地评估了不同专业角色（如急诊科医生、护士）和互动风格（大胆 vs. 谨慎）对多个模型和医疗任务的行为影响。他们使用多维度评估方法（包括任务准确性、校准度和安全相关风险行为）来评估模型在临床分诊和患者安全任务上的表现。

Result: 研究发现，角色扮演效应具有系统性、依赖于情境且非单调性。在关键护理任务中，医学角色可将准确性和校准率提高约20%；但在初级保健设置中，医学角色会使性能下降同等幅度。互动风格可以调节风险倾向和敏感性，但这种影响高度依赖于模型。尽管LLM裁判器在安全关键案例中偏好医学角色，但人类临床医生在安全合规性上的平均一致性（Cohen's κ = 0.43）中等，且对95.9%的推理质量响应信心较低。

Conclusion: 研究表明，角色扮演对临床LLMs的功能更像是引入了与情境相关的权衡，而非安全或专业知识的保证。其影响是复杂且非单调的，需要根据具体任务和情境进行仔细评估。

Abstract: Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\ cautious) influence behavior across models and medical tasks. We assess performance on clinical triage and patient-safety tasks using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior. We find systematic, context-dependent, and non-monotonic effects: Medical personas improve performance in critical care tasks, yielding gains of up to $\sim+20\%$ in accuracy and calibration, but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity and sensitivity, but it's highly model-dependent. While aggregated LLM-judge rankings favor medical over non-medical personas in safety-critical cases, we found that human clinicians show moderate agreement on safety compliance (average Cohen's $κ= 0.43$) but indicate a low confidence in 95.9\% of their responses on reasoning quality. Our work shows that personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise. The code is available at https://github.com/rsinghlab/Persona\_Paradox.

</details>


### [7] [On the Effect of Cheating in Chess](https://arxiv.org/abs/2601.05386)
*Daniel Keren*

Main category: cs.AI

TL;DR: 本研究旨在评估在国际象棋比赛中，通过有限次使用外部软件作弊所能获得的性能提升，而非侧重于作弊检测。


<details>
  <summary>Details</summary>
Motivation: 国际象棋中利用强大软件作弊的问题日益严重，甚至影响到顶级比赛。现有研究多集中于作弊检测，而本研究旨在量化作弊的实际收益。

Method: 开发并测试了相关算法，并在常用的国际象棋引擎（软件）上进行了实验。

Result: 研究评估了在有限次使用作弊的情况下，性能可以获得的提升。

Conclusion: 量化作弊的有效性对于遏制和检测作弊至关重要。

Abstract: Cheating in chess, by using advice from powerful software, has become a major problem, reaching the highest levels. As opposed to the large majority of previous work, which concerned {\em detection} of cheating, here we try to evaluate the possible gain in performance, obtained by cheating a limited number of times during a game. Algorithms are developed and tested on a commonly used chess engine (i.e software).\footnote{Needless to say, the goal of this work is not to assist cheaters, but to measure the effectiveness of cheating -- which is crucial as part of the effort to contain and detect it.}

</details>


### [8] [ART: Adaptive Reasoning Trees for Explainable Claim Verification](https://arxiv.org/abs/2601.05455)
*Sahil Wadhwa,Himanshu Kumar,Guanqun Yang,Abbaas Alif Mohamed Nishar,Pranab Mohanty,Swapnil Shinde,Yue Wu*

Main category: cs.AI

TL;DR: 本文提出了一种名为ART（自适应推理树）的层级方法，用于对LLM生成的论点进行可解释和可辩驳的验证，通过结构化推理提升了决策的可靠性和清晰度。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在决策方面表现强大，但其不透明的输出和缺乏可信的解释阻碍了其在高风险环境中的应用。模型产生的错误难以纠正，降低了其可信度。

Method: ART方法采用层级结构，从一个根论点开始，将其分解为支持和反对的子论点。通过一个由LLM扮演的裁判进行两两比较，自底向上地评估论点的强度，最终系统地得出透明且可辩驳的结论。

Result: 在多个数据集上的实证研究表明，ART的结构化推理方法优于强基线方法，并在可解释的论点验证方面设定了新的基准。

Conclusion: ART方法提供了一种比Chain-of-Thought（CoT）等方法更可靠、更清晰的决策制定过程，能够系统地推导出透明且可辩驳的结论，增强了LLM在高风险决策中的可信度。

Abstract: Large Language Models (LLMs) are powerful candidates for complex decision-making, leveraging vast encoded knowledge and remarkable zero-shot abilities. However, their adoption in high-stakes environments is hindered by their opacity; their outputs lack faithful explanations and cannot be effectively contested to correct errors, undermining trustworthiness. In this paper, we propose ART (Adaptive Reasoning Trees), a hierarchical method for claim verification. The process begins with a root claim, which branches into supporting and attacking child arguments. An argument's strength is determined bottom-up via a pairwise tournament of its children, adjudicated by a judge LLM, allowing a final, transparent and contestable verdict to be systematically derived which is missing in methods like Chain-of-Thought (CoT). We empirically validate ART on multiple datasets, analyzing different argument generators and comparison strategies. Our findings show that ART's structured reasoning outperforms strong baselines, establishing a new benchmark for explainable claim verification which is more reliable and ensures clarity in the overall decision making step.

</details>


### [9] [PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering](https://arxiv.org/abs/2601.05465)
*Yu Liu,Wenxiao Zhang,Cong Cao,Wenxuan Lu,Fangfang Yuan,Diandian Guo,Kun Peng,Qiang Sun,Kaiyan Zhang,Yanbing Liu,Jin B. Hong,Bowen Zhou,Zhiyuan Ma*

Main category: cs.AI

TL;DR: 提出了一种名为 PRISMA 的解耦强化学习框架，用于解决大规模语料库上的开放域多跳问答问题，通过规划、检索、检查和解决等模块协同工作，克服了检索坍塌和学习不稳定的问题，并在十个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中大规模语料库上的开放域多跳问答是检索增强生成（RAG）系统的关键挑战，现有的基于强化学习的端到端优化方法在应对检索坍塌和学习不稳定方面存在不足，限制了其在实际应用中的可靠性。

Method: 提出了一种名为 PRISMA 的解耦强化学习框架，采用 Plan-Retrieve-Inspect-Solve-Memoize（PRISM）架构。该框架通过推理指导的协作，由 Inspector 提供基于推理的反馈来改进 Planner 的分解和检索，并强制 Solver 进行基于证据的推理。采用两阶段群体相对策略优化（GRPO）来优化各个代理能力：第一阶段将 Planner 和 Solver 训练为专业专家；第二阶段使用 Observation-Aware Residual Policy Optimization（OARPO）来增强 Inspector 的能力。

Result: PRISMA 在十个基准测试中取得了最先进的性能，证明了其在实际场景中部署的效率和有效性。

Conclusion: PRISMA 通过其解耦的、推理指导的协作架构，成功克服了 RAG 系统在处理大规模多跳问答时的检索坍塌和学习不稳定问题，并在多个基准测试中展现出优越的性能和实际应用潜力。

Abstract: Answering real-world open-domain multi-hop questions over massive corpora is a critical challenge in Retrieval-Augmented Generation (RAG) systems. Recent research employs reinforcement learning (RL) to end-to-end optimize the retrieval-augmented reasoning process, directly enhancing its capacity to resolve complex queries. However, reliable deployment is hindered by two obstacles. 1) Retrieval Collapse: iterative retrieval over large corpora fails to locate intermediate evidence containing bridge answers without reasoning-guided planning, causing downstream reasoning to collapse. 2) Learning Instability: end-to-end trajectory training suffers from weak credit assignment across reasoning chains and poor error localization across modules, causing overfitting to benchmark-specific heuristics that limit transferability and stability. To address these problems, we propose PRISMA, a decoupled RL-guided framework featuring a Plan-Retrieve-Inspect-Solve-Memoize architecture. PRISMA's strength lies in reasoning-guided collaboration: the Inspector provides reasoning-based feedback to refine the Planner's decomposition and fine-grained retrieval, while enforcing evidence-grounded reasoning in the Solver. We optimize individual agent capabilities via Two-Stage Group Relative Policy Optimization (GRPO). Stage I calibrates the Planner and Solver as specialized experts in planning and reasoning, while Stage II utilizes Observation-Aware Residual Policy Optimization (OARPO) to enhance the Inspector's ability to verify context and trigger targeted recovery. Experiments show that PRISMA achieves state-of-the-art performance on ten benchmarks and can be deployed efficiently in real-world scenarios.

</details>


### [10] [GenCtrl -- A Formal Controllability Toolkit for Generative Models](https://arxiv.org/abs/2601.05637)
*Emily Cheng,Carmen Amo Alonso,Federico Danieli,Arno Blaas,Luca Zappella,Pau Rodriguez,Xavier Suau*

Main category: cs.AI

TL;DR: 本研究提出了一个理论框架来形式化地评估生成模型的“可控性”，并提出了一种算法来估计其可控集合。研究发现，模型的可控性非常脆弱且高度依赖于实验设置，强调了进行严格可控性分析的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型变得无处不在，但目前在控制这些模型生成过程方面缺乏根本性的理论指导，研究人员需要一个框架来评估模型是否真正可控。

Method: 该研究将人类-模型交互视为一个控制过程，并提出了一种新的算法来估计对话场景中模型的可控集合。该算法提供了关于估计误差的正式保证，并具有样本复杂度的函数。此外，该算法是无分布的，不依赖于任何假设（除输出有界性外），并且适用于任何黑盒非线性控制系统（即任何生成模型）。

Result: 研究人员在控制对话过程的不同任务以及语言模型和文本到图像生成方面，对理论框架进行了实证检验。结果表明，模型的可控性“出乎意料地脆弱”，并且“高度依赖于实验设置”。

Conclusion: 生成模型的可控性是一个需要严格分析的根本问题，研究结果强调了在尝试控制之前，首先理解其基本限制的重要性，而不是仅仅追求控制本身。

Abstract: As generative models become ubiquitous, there is a critical need for fine-grained control over the generation process. Yet, while controlled generation methods from prompting to fine-tuning proliferate, a fundamental question remains unanswered: are these models truly controllable in the first place? In this work, we provide a theoretical framework to formally answer this question. Framing human-model interaction as a control process, we propose a novel algorithm to estimate the controllable sets of models in a dialogue setting. Notably, we provide formal guarantees on the estimation error as a function of sample complexity: we derive probably-approximately correct bounds for controllable set estimates that are distribution-free, employ no assumptions except for output boundedness, and work for any black-box nonlinear control system (i.e., any generative model). We empirically demonstrate the theoretical framework on different tasks in controlling dialogue processes, for both language models and text-to-image generation. Our results show that model controllability is surprisingly fragile and highly dependent on the experimental setting. This highlights the need for rigorous controllability analysis, shifting the focus from simply attempting control to first understanding its fundamental limits.

</details>


### [11] [Safety Not Found (404): Hidden Risks of LLM-Based Robotics Decision Making](https://arxiv.org/abs/2601.05529)
*Jua Han,Jaeyoon Seo,Jungbin Min,Jean Oh,Jihie Kim*

Main category: cs.AI

TL;DR: 本研究对大型语言模型（LLM）在安全攸关场景下的表现进行了系统性评估，发现在火灾疏散等关键任务中存在严重漏洞，即使是所谓的“罕见”错误也可能导致灾难性后果，目前LLM尚不适合直接部署于此类系统。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地应用于机器人决策，尤其是在安全攸关的场景下，错误的指令可能直接危及人类生命安全，因此迫切需要系统性地评估LLM在这些场景下的性能。

Method: 通过对火灾疏散场景进行定性评估，识别LLM决策的关键失效点。基于此，设计了七项定量评估任务，分为“完整信息”、“不完整信息”和“安全导向空间推理”（SOSR）三类。完整信息任务使用ASCII地图，不完整信息任务测试模型推断缺失上下文的能力，SOSR任务评估模型在生命威胁情境下的安全决策能力。对多种LLM和视觉语言模型（VLM）进行了基准测试。

Result: 研究发现，即使在ASCII导航任务中，部分模型也取得了0%的成功率。在模拟火灾演习中，模型指示机器人走向危险区域而非紧急出口。即使是先进的模型也无法保证安全，1%的错误率在机器人领域会被放大为灾难性后果。

Conclusion: 当前的大型语言模型尚未准备好直接部署于安全攸关的系统。99%的准确率在机器人领域具有误导性，因为它意味着每次执行都有可能造成灾难性伤害。对LLM的绝对依赖会带来不可接受的风险。

Abstract: One mistake by an AI system in a safety-critical setting can cost lives. As Large Language Models (LLMs) become integral to robotics decision-making, the physical dimension of risk grows; a single wrong instruction can directly endanger human safety. This paper addresses the urgent need to systematically evaluate LLM performance in scenarios where even minor errors are catastrophic. Through a qualitative evaluation of a fire evacuation scenario, we identified critical failure cases in LLM-based decision-making. Based on these, we designed seven tasks for quantitative assessment, categorized into: Complete Information, Incomplete Information, and Safety-Oriented Spatial Reasoning (SOSR). Complete information tasks utilize ASCII maps to minimize interpretation ambiguity and isolate spatial reasoning from visual processing. Incomplete information tasks require models to infer missing context, testing for spatial continuity versus hallucinations. SOSR tasks use natural language to evaluate safe decision-making in life-threatening contexts. We benchmark various LLMs and Vision-Language Models (VLMs) across these tasks. Beyond aggregate performance, we analyze the implications of a 1% failure rate, highlighting how "rare" errors escalate into catastrophic outcomes. Results reveal serious vulnerabilities: several models achieved a 0% success rate in ASCII navigation, while in a simulated fire drill, models instructed robots to move toward hazardous areas instead of emergency exits. Our findings lead to a sobering conclusion: current LLMs are not ready for direct deployment in safety-critical systems. A 99% accuracy rate is dangerously misleading in robotics, as it implies one out of every hundred executions could result in catastrophic harm. We demonstrate that even state-of-the-art models cannot guarantee safety, and absolute reliance on them creates unacceptable risks.

</details>


### [12] [The Evaluation Gap in Medicine, AI and LLMs: Navigating Elusive Ground Truth & Uncertainty via a Probabilistic Paradigm](https://arxiv.org/abs/2601.05500)
*Aparna Elangovan,Lei Xu,Mahsa Elyasi,Ismail Akdulum,Mehmet Aksakal,Enes Gurun,Brian Hur,Saab Mansour,Ravid Shwartz Ziv,Karin Verspoor,Dan Roth*

Main category: cs.AI

TL;DR: 该研究提出了一种概率范式来量化评估AI系统（特别是LLMs和视觉模型）时，由于专家标注答案的不确定性而引入的偏差。研究发现，在专家标注答案不确定性高的数据集上，AI系统的得分会受到很大影响，甚至可能出现非专家与专家得分相似的误导性结论。因此，研究建议在评估AI系统能力时，应根据地面真实答案的概率（通常通过专家一致率衡量）进行分层评估，尤其是在整体性能低于80%时，以获得更可靠的性能比较。


<details>
  <summary>Details</summary>
Motivation: 当前的AI系统（包括LLMs和视觉模型）能力评估方法，在处理专家标注答案的不确定性时存在不足，尤其是在医学等不确定性普遍存在的领域。这种不确定性会严重影响评估的准确性，可能导致对AI系统能力的误判。

Method: 提出了一种概率范式，并引入了“期望准确率”和“期望F1”的概念，用于估计在地面真实答案存在变异性时，专家或系统能够达到的得分。该方法建议根据地面真实答案的概率（通过专家一致率衡量）对评估结果进行分层。

Result: 研究表明，在地面真实答案确定性高的情况下，即使是专家也需要高置信度的答案才能获得高分。而在地面真实答案变异性高的数据集中，随机标注者和专家的表现差异可能很小。忽略地面真实答案的不确定性，可能导致非专家与专家表现相似的误导性结论。

Conclusion: 为了更可靠地评估AI系统能力，应采用分层评估的方法，根据地面真实答案的概率（专家一致率）将结果分层。特别是在整体性能低于80%时，这种分层评估尤为重要，它可以有效缓解因地面真实答案不确定性带来的混淆因素，提高性能比较的可靠性。

Abstract: Benchmarking the relative capabilities of AI systems, including Large Language Models (LLMs) and Vision Models, typically ignores the impact of uncertainty in the underlying ground truth answers from experts. This ambiguity is particularly consequential in medicine where uncertainty is pervasive. In this paper, we introduce a probabilistic paradigm to theoretically explain how high certainty in ground truth answers is almost always necessary for even an expert to achieve high scores, whereas in datasets with high variation in ground truth answers there may be little difference between a random labeller and an expert. Therefore, ignoring uncertainty in ground truth evaluation data can result in the misleading conclusion that a non-expert has similar performance to that of an expert. Using the probabilistic paradigm, we thus bring forth the concepts of expected accuracy and expected F1 to estimate the score an expert human or system can achieve given ground truth answer variability.
  Our work leads to the recommendation that when establishing the capability of a system, results should be stratified by probability of the ground truth answer, typically measured by the agreement rate of ground truth experts. Stratification becomes critical when the overall performance drops below a threshold of 80%. Under stratified evaluation, performance comparison becomes more reliable in high certainty bins, mitigating the effect of the key confounding factor -- uncertainty.

</details>


### [13] [MMUEChange: A Generalized LLM Agent Framework for Intelligent Multi-Modal Urban Environment Change Analysis](https://arxiv.org/abs/2601.05483)
*Zixuan Xiao,Jun Ma,Siwei Zhang*

Main category: cs.AI

TL;DR: 提出了一种名为 MMUEChange 的多模态智能体框架，用于整合异构城市数据，以更灵活、稳健地分析复杂的城市变化场景，并在纽约、香港和深圳的案例研究中取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 当前单模态的遥感变化检测方法在分析复杂的城市变化场景时存在局限性，需要更灵活的方法来整合异构城市数据。

Method: 提出 MMUEChange 多模态智能体框架，该框架通过模块化工具包和核心模块（模态控制器）来整合异构城市数据，实现跨模态和内模态的对齐。

Result: MMUEChange 在纽约、香港和深圳的案例研究中，分别揭示了城市绿地、水污染和垃圾处理的变化趋势。与基线方法相比，MMUEChange 的任务成功率提高了 46.7%，并有效减少了幻觉。

Conclusion: MMUEChange 智能体框架能够支持复杂的城市变化分析任务，并具有实际的政策启示意义，能够灵活整合异构数据以克服传统单模态方法的局限性。

Abstract: Understanding urban environment change is essential for sustainable development. However, current approaches, particularly remote sensing change detection, often rely on rigid, single-modal analysis. To overcome these limitations, we propose MMUEChange, a multi-modal agent framework that flexibly integrates heterogeneous urban data via a modular toolkit and a core module, Modality Controller for cross- and intra-modal alignment, enabling robust analysis of complex urban change scenarios. Case studies include: a shift toward small, community-focused parks in New York, reflecting local green space efforts; the spread of concentrated water pollution across districts in Hong Kong, pointing to coordinated water management; and a notable decline in open dumpsites in Shenzhen, with contrasting links between nighttime economic activity and waste types, indicating differing urban pressures behind domestic and construction waste. Compared to the best-performing baseline, the MMUEChange agent achieves a 46.7% improvement in task success rate and effectively mitigates hallucination, demonstrating its capacity to support complex urban change analysis tasks with real-world policy implications.

</details>


### [14] [Explainable AI: Learning from the Learners](https://arxiv.org/abs/2601.05525)
*Ricardo Vinuesa,Steven L. Brunton,Gianmarco Mengaldo*

Main category: cs.AI

TL;DR: 本研究提出将可解释人工智能（XAI）与因果推理相结合，以实现“从学习者那里学习”，从而在科学和工程领域促进发现、优化和认证。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能在科学和工程任务中表现出色，但其内部表征往往不透明。研究者希望解决这一不透明性，以实现更深入的理解和协作。

Method: 结合使用基础模型和可解释性方法，聚焦于提取因果机制，指导设计和控制，并支持高风险应用中的信任和问责制。

Result: 文章探讨了XAI在科学发现、优化和认证方面的潜力，展示了其在提取因果机制、指导设计和控制以及支持信任和问责制方面的应用。

Conclusion: XAI与因果推理的结合是实现“从学习者那里学习”的关键，为科学和工程领域的人机协作提供了一个统一的框架，但也面临可解释性、泛化性和可用性等方面的挑战。

Abstract: Artificial intelligence now outperforms humans in several scientific and engineering tasks, yet its internal representations often remain opaque. In this Perspective, we argue that explainable artificial intelligence (XAI), combined with causal reasoning, enables {\it learning from the learners}. Focusing on discovery, optimization and certification, we show how the combination of foundation models and explainability methods allows the extraction of causal mechanisms, guides robust design and control, and supports trust and accountability in high-stakes applications. We discuss challenges in faithfulness, generalization and usability of explanations, and propose XAI as a unifying framework for human-AI collaboration in science and engineering.

</details>


### [15] [WildSci: Advancing Scientific Reasoning from In-the-Wild Literature](https://arxiv.org/abs/2601.05567)
*Tengxiao Liu,Deepak Nathani,Zekun Li,Kevin Yang,William Yang Wang*

Main category: cs.AI

TL;DR: 该研究提出了WildSci数据集，一个自动从科学文献中合成的、涵盖9个科学领域和26个子领域的科学问题数据集，并采用多项选择题的形式简化科学推理任务，利用强化学习对LLM进行微调，以提升其在科学领域的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在数学和代码等领域进展迅速，但在医学和材料科学等科学领域进展受限，原因是科学领域数据不足且问题复杂开放。为了解决这一问题，需要新的数据集和方法来促进LLM在科学领域的推理能力。

Method: 1. 自动合成WildSci数据集：从同行评审的科学文献中生成包含9个科学领域和26个子领域的科学问题，并将其格式化为多项选择题。
2. 强化学习微调：利用WildSci数据集对LLM进行微调，以获得明确的奖励信号。
3. 分析训练动态：研究微调过程中的领域特定性能变化、响应行为和泛化趋势。

Result: 通过在多个科学基准测试上的实验，证明了WildSci数据集和所提出的强化学习微调方法的有效性，显著提升了LLM在科学领域的推理能力。

Conclusion: WildSci数据集和基于强化学习的微调方法能够有效地提升LLM在科学领域的开放式推理能力，并为未来的科学推理研究提供了可扩展和可持续的资源。

Abstract: Recent progress in large language model (LLM) reasoning has focused on domains like mathematics and coding, where abundant high-quality data and objective evaluation metrics are readily available. In contrast, progress in LLM reasoning models remains limited in scientific domains such as medicine and materials science due to limited dataset coverage and the inherent complexity of open-ended scientific questions. To address these challenges, we introduce WildSci, a new dataset of domain-specific science questions automatically synthesized from peer-reviewed literature, covering 9 scientific disciplines and 26 subdomains. By framing complex scientific reasoning tasks in a multiple-choice format, we enable scalable training with well-defined reward signals. We further apply reinforcement learning to finetune models on these data and analyze the resulting training dynamics, including domain-specific performance changes, response behaviors, and generalization trends. Experiments on a suite of scientific benchmarks demonstrate the effectiveness of our dataset and approach. We release WildSci to enable scalable and sustainable research in scientific reasoning, available at https://huggingface.co/datasets/JustinTX/WildSci.

</details>


### [16] [Crisis-Bench: Benchmarking Strategic Ambiguity and Reputation Management in Large Language Models](https://arxiv.org/abs/2601.05570)
*Cooper Lin,Maohao Ran,Yanting Zhang,Zhenglin Wan,Hongwei Fan,Yibo Xu,Yike Guo,Wei Xue,Jun Song*

Main category: cs.AI

TL;DR: 本文提出Crisis-Bench基准测试，用于评估大型语言模型在企业危机管理中的战略信息隐藏能力，与通用安全对齐不同，该基准测试允许在特定专业领域（如公关）中进行策略性信息模糊处理，并引入了“裁决者-市场循环”评估新指标，结果显示模型在维持声誉和稳定股价方面存在性能差异，并倡导从绝对道德转向情境感知型专业对齐。


<details>
  <summary>Details</summary>
Motivation: 通用的大型语言模型安全对齐（如“童子军”道德）在专业领域（如公关、谈判、危机管理）中会带来“透明度税”，这些领域需要策略性模糊和信息隐藏。现有评估方法无法衡量这种通用安全与专业效用之间的差距。

Method: 引入Crisis-Bench，一个多智能体部分可观察马尔可夫决策过程（POMDP），模拟企业危机管理。设计了一个基于LLM的公关（PR）智能体，在一个为期7天的模拟中，通过严格区分私有和公共叙述状态来执行信息不对称。引入“裁决者-市场循环”评估指标，将公众情绪转化为模拟股价，以模拟经济激励结构。

Result: 一些模型在面临道德顾虑时会屈服，而另一些模型则能展示出合法的“马基雅维利式”策略性信息隐藏，以稳定模拟股价。这揭示了模型在管理声誉和稳定股价方面的能力差异。

Conclusion: Crisis-Bench是首个量化评估“声誉管理”能力的框架，表明需要从严格的道德绝对主义转向情境感知型的专业对齐，以更好地服务于需要策略性信息处理的专业领域。

Abstract: Standard safety alignment optimizes Large Language Models (LLMs) for universal helpfulness and honesty, effectively instilling a rigid "Boy Scout" morality. While robust for general-purpose assistants, this one-size-fits-all ethical framework imposes a "transparency tax" on professional domains requiring strategic ambiguity and information withholding, such as public relations, negotiation, and crisis management. To measure this gap between general safety and professional utility, we introduce Crisis-Bench, a multi-agent Partially Observable Markov Decision Process (POMDP) that evaluates LLMs in high-stakes corporate crises. Spanning 80 diverse storylines across 8 industries, Crisis-Bench tasks an LLM-based Public Relations (PR) Agent with navigating a dynamic 7-day corporate crisis simulation while managing strictly separated Private and Public narrative states to enforce rigorous information asymmetry. Unlike traditional benchmarks that rely on static ground truths, we introduce the Adjudicator-Market Loop: a novel evaluation metric where public sentiment is adjudicated and translated into a simulated stock price, creating a realistic economic incentive structure. Our results expose a critical dichotomy: while some models capitulate to ethical concerns, others demonstrate the capacity for Machiavellian, legitimate strategic withholding in order to stabilize the simulated stock price. Crisis-Bench provides the first quantitative framework for assessing "Reputation Management" capabilities, arguing for a shift from rigid moral absolutism to context-aware professional alignment.

</details>


### [17] [Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection](https://arxiv.org/abs/2601.05578)
*Cooper Lin,Yanting Zhang,Maohao Ran,Wei Xue,Hongwei Fan,Yibo Xu,Zhenglin Wan,Sirui Han,Yike Guo,Jun Song*

Main category: cs.AI

TL;DR: 本研究提出一种利用强化学习（RL）对轻量级语言模型进行后训练（post-train）的方法，专门用于处理电子商务交易数据中的欺诈检测任务，并取得了显著的F1分数提升。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法在检测复杂和不断演变的电子商务欺诈方面存在局限性，而大型语言模型（LLMs）在金融领域的实际应用仍未被充分探索，尤其是在处理特定领域的交易数据方面缺乏实证验证。因此，需要弥合这一差距。

Method: 利用强化学习（RL）中的Group Sequence Policy Optimization（GSPO）算法，结合基于规则的奖励系统，对不同规模的语言模型进行微调。模型仅使用原始交易数据（包括客户信息、配送详情、产品描述和订单历史等文本信息）进行训练，旨在探索和利用其中嵌入的信任和风险信号。

Result: 通过强化学习后训练的语言模型在真实交易数据集的测试集上取得了显著的F1分数提升。性能的提高主要归因于强化学习固有的探索机制，使其能够发现传统工程特征无法捕获的新型欺诈指标。

Conclusion: 强化学习驱动的轻量级语言模型后训练方法是一种有效提升电子商务欺诈检测性能的新途径，尤其擅长发现隐藏在原始交易文本数据中的新型欺诈模式。

Abstract: E-commerce platforms and payment solution providers face increasingly sophisticated fraud schemes, ranging from identity theft and account takeovers to complex money laundering operations that exploit the speed and anonymity of digital transactions. However, despite their theoretical promise, the application of Large Language Models (LLMs) to fraud detection in real-world financial contexts remains largely unexploited, and their practical effectiveness in handling domain-specific e-commerce transaction data has yet to be empirically validated. To bridge this gap between conventional machine learning limitations and the untapped potential of LLMs in fraud detection, this paper proposes a novel approach that employs Reinforcement Learning (RL) to post-train lightweight language models specifically for fraud detection tasks using only raw transaction data. We utilize the Group Sequence Policy Optimization (GSPO) algorithm combined with a rule-based reward system to fine-tune language models of various sizes on a real-life transaction dataset provided by a Chinese global payment solution company. Through this reinforcement learning framework, the language models are encouraged to explore diverse trust and risk signals embedded within the textual transaction data, including patterns in customer information, shipping details, product descriptions, and order history. Our experimental results demonstrate the effectiveness of this approach, with post-trained language models achieving substantial F1-score improvements on held-out test data. Our findings demonstrate that the observed performance improvements are primarily attributable to the exploration mechanism inherent in reinforcement learning, which allows models to discover novel fraud indicators beyond those captured by traditional engineered features.

</details>


### [18] [A Causal Information-Flow Framework for Unbiased Learning-to-Rank](https://arxiv.org/abs/2601.05590)
*Haoming Gong,Qingyao Ai,Zhihao Tao,Yongfeng Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种基于因果学习的排序新框架，结合结构因果模型（SCMs）和信息论工具，以解决点击数据中存在的位置偏差、选择偏差和信任偏差等问题，并衡量和减少偏差泄露，从而提高排序性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无偏学习排序（ULTR）方法在处理点击数据中的多源偏差（位置偏差、选择偏差、信任偏差）时存在不足，无法衡量剩余偏差、提供风险保证，也无法联合处理多种偏差。因此，需要一种更强大的方法来解决这些挑战。

Method: 本文提出了一种结合结构因果模型（SCMs）和信息论工具的因果学习排序框架。SCMs用于模拟点击生成过程并识别真实相关性信号，而条件互信息用于衡量偏差泄露。通过将此泄露度量作为正则化项，并结合双重稳健估计器来估计风险，以减少偏差并提供更可靠的风险评估。

Result: 在标准的学习排序基准测试中，实验表明该方法能够持续减少测得的偏差泄露，并显著提高排序性能，尤其是在位置偏差和信任偏差等多种偏差强交互的现实场景中。

Conclusion: 该研究提出的基于SCMs和信息论的因果学习排序框架能够有效地解决点击数据中的多源偏差问题，通过衡量和减少偏差泄露来提高排序模型的准确性和鲁棒性。

Abstract: In web search and recommendation systems, user clicks are widely used to train ranking models. However, click data is heavily biased, i.e., users tend to click higher-ranked items (position bias), choose only what was shown to them (selection bias), and trust top results more (trust bias). Without explicitly modeling these biases, the true relevance of ranked items cannot be correctly learned from clicks. Existing Unbiased Learning-to-Rank (ULTR) methods mainly correct position bias and rely on propensity estimation, but they cannot measure remaining bias, provide risk guarantees, or jointly handle multiple bias sources. To overcome these challenges, this paper introduces a novel causal learning-based ranking framework that extends ULTR by combining Structural Causal Models (SCMs) with information-theoretic tools. SCMs specify how clicks are generated and help identify the true relevance signal from click data, while conditional mutual information, measures how much bias leaks into the
  learned relevance estimates. We use this leakage measure to define a rigorous notion of disentanglement and include it as a regularizer during model training to reduce bias. In addition, we incorporate a causal inference estimator, i.e., doubly robust estimator, to ensure more reliable risk estimation. Experiments on standard Learning-to-Rank benchmarks show that our method consistently reduces measured bias leakage and improves ranking performance, especially in realistic scenarios where multiple biases-such as position and trust bias-interact strongly.

</details>


### [19] [Cumulative Path-Level Semantic Reasoning for Inductive Knowledge Graph Completion](https://arxiv.org/abs/2601.05629)
*Jiapu Wang,Xinghe Cheng,Zezheng Wu,Ruiqi Ma,Rui Wang,Zhichao Yan,Haoran Luo,Yuhao Jiang,Kai Sun*

Main category: cs.AI

TL;DR: 本文提出了一个名为CPSR的框架，用于归纳式知识图谱补全，通过查询依赖掩码和全局语义评分来解决现有方法的噪声敏感性和长距离依赖性问题，并在实验中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱补全方法难以处理新兴实体，而现有的归纳式方法容易受到噪声结构信息的影响，并难以捕捉推理路径中的长距离依赖性。

Method: 提出CPSR框架，包含查询依赖掩码模块（自适应地掩盖噪声结构信息）和全局语义评分模块（评估推理路径中节点的影响），以同时捕捉结构和语义信息。

Result: CPSR在实验中取得了最先进的性能。

Conclusion: CPSR框架能够有效地解决现有归纳式知识图谱补全方法的局限性，并通过同时利用结构和语义信息来提高性能。

Abstract: Conventional Knowledge Graph Completion (KGC) methods aim to infer missing information in incomplete Knowledge Graphs (KGs) by leveraging existing information, which struggle to perform effectively in scenarios involving emerging entities. Inductive KGC methods can handle the emerging entities and relations in KGs, offering greater dynamic adaptability. While existing inductive KGC methods have achieved some success, they also face challenges, such as susceptibility to noisy structural information during reasoning and difficulty in capturing long-range dependencies in reasoning paths. To address these challenges, this paper proposes the Cumulative Path-Level Semantic Reasoning for inductive knowledge graph completion (CPSR) framework, which simultaneously captures both the structural and semantic information of KGs to enhance the inductive KGC task. Specifically, the proposed CPSR employs a query-dependent masking module to adaptively mask noisy structural information while retaining important information closely related to the targets. Additionally, CPSR introduces a global semantic scoring module that evaluates both the individual contributions and the collective impact of nodes along the reasoning path within KGs. The experimental results demonstrate that CPSR achieves state-of-the-art performance.

</details>


### [20] [HAG: Hierarchical Demographic Tree-based Agent Generation for Topic-Adaptive Simulation](https://arxiv.org/abs/2601.05656)
*Rongxin Chen,Tianyu Wu,Bingbing Xu,Xiucheng Xu,Huawei Shen*

Main category: cs.AI

TL;DR: 提出了一种名为 HAG 的分层代理生成框架，通过世界知识模型和真实数据相结合，实现了宏观层面主题自适应和微观层面个体理性，解决了现有方法在处理新主题和确保模型一致性方面的问题。HAG 在多领域基准测试和 PACE 评估框架下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有代理初始化方法存在不足：基于静态数据的检索方法无法处理未见过的主题；基于 LLM 的生成方法缺乏宏观分布意识，导致微观个体属性与现实不符。因此，需要一个能同时实现主题自适应和个体理性的稳健框架。

Method: HAG 框架将人口生成形式化为两阶段决策过程：1. 利用世界知识模型推断分层条件概率，构建主题自适应树，实现宏观分布对齐。2. 基于真实世界数据进行实例化和代理增强，确保微观层面的一致性。

Result: HAG 在人口对齐误差方面平均降低了 37.7%，社会学一致性提高了 18.8%，显著优于代表性基线方法。

Conclusion: HAG 框架成功解决了现有代理初始化方法的局限性，通过结合宏观分布对齐和微观个体理性，提高了代理建模的可信度，并在多领域实验中验证了其有效性。

Abstract: High-fidelity agent initialization is crucial for credible Agent-Based Modeling across diverse domains. A robust framework should be Topic-Adaptive, capturing macro-level joint distributions while ensuring micro-level individual rationality. Existing approaches fall into two categories: static data-based retrieval methods that fail to adapt to unseen topics absent from the data, and LLM-based generation methods that lack macro-level distribution awareness, resulting in inconsistencies between micro-level persona attributes and reality. To address these problems, we propose HAG, a Hierarchical Agent Generation framework that formalizes population generation as a two-stage decision process. Firstly, utilizing a World Knowledge Model to infer hierarchical conditional probabilities to construct the Topic-Adaptive Tree, achieving macro-level distribution alignment. Then, grounded real-world data, instantiation and agentic augmentation are carried out to ensure micro-level consistency. Given the lack of specialized evaluation, we establish a multi-domain benchmark and a comprehensive PACE evaluation framework. Extensive experiments show that HAG significantly outperforms representative baselines, reducing population alignment errors by an average of 37.7% and enhancing sociological consistency by 18.8%.

</details>


### [21] [CHDP: Cooperative Hybrid Diffusion Policies for Reinforcement Learning in Parameterized Action Space](https://arxiv.org/abs/2601.05675)
*Bingyi Liu,Jinbo He,Haiyong Shi,Enshu Wang,Weizhen Han,Jingxiang Hao,Peixi Wang,Zhuangzhuang Zhang*

Main category: cs.AI

TL;DR: 提出了一种名为CHDP的合作混合扩散策略框架，用于解决混合离散-连续动作空间问题。该框架利用两个合作代理，一个离散策略和一个连续策略，并通过代码本和Q函数引导机制来提高在高维离散动作空间中的可扩展性和学习效率。


<details>
  <summary>Details</summary>
Motivation: 现有处理混合离散-连续动作空间的方法在策略表达能力和在高维环境下的可扩展性方面存在挑战。

Method: 将混合动作空间视为一个完全合作博弈，并提出合作混合扩散策略（CHDP）框架。CHDP包含两个合作代理：一个离散扩散策略和一个连续扩散策略。连续策略以离散动作的表示为条件，显式地模拟两者之间的依赖关系。采用顺序更新方案来解决同步更新冲突，并促进协同适应。为了提高在高维离散动作空间中的可扩展性，引入了将动作空间嵌入低维潜在空间的代码本。设计了一个基于Q函数的引导机制来对齐代码本嵌入与离散策略的表示。

Result: 在具有挑战性的混合动作基准测试中，CHDP的成功率比现有最先进的方法高出19.3%。

Conclusion: CHDP框架通过合作设计、顺序更新、代码本嵌入和Q函数引导等机制，有效地解决了混合离散-连续动作空间中的建模和优化挑战，并在实验中取得了显著优于现有方法的性能。

Abstract: Hybrid action space, which combines discrete choices and continuous parameters, is prevalent in domains such as robot control and game AI. However, efficiently modeling and optimizing hybrid discrete-continuous action space remains a fundamental challenge, mainly due to limited policy expressiveness and poor scalability in high-dimensional settings. To address this challenge, we view the hybrid action space problem as a fully cooperative game and propose a \textbf{Cooperative Hybrid Diffusion Policies (CHDP)} framework to solve it. CHDP employs two cooperative agents that leverage a discrete and a continuous diffusion policy, respectively. The continuous policy is conditioned on the discrete action's representation, explicitly modeling the dependency between them. This cooperative design allows the diffusion policies to leverage their expressiveness to capture complex distributions in their respective action spaces. To mitigate the update conflicts arising from simultaneous policy updates in this cooperative setting, we employ a sequential update scheme that fosters co-adaptation. Moreover, to improve scalability when learning in high-dimensional discrete action space, we construct a codebook that embeds the action space into a low-dimensional latent space. This mapping enables the discrete policy to learn in a compact, structured space. Finally, we design a Q-function-based guidance mechanism to align the codebook's embeddings with the discrete policy's representation during training. On challenging hybrid action benchmarks, CHDP outperforms the state-of-the-art method by up to $19.3\%$ in success rate.

</details>


### [22] [Circular Reasoning: Understanding Self-Reinforcing Loops in Large Reasoning Models](https://arxiv.org/abs/2601.05693)
*Zenghao Duan,Liang Pang,Zihao Wei,Wenbin Duan,Yuxin Tian,Shicheng Xu,Jingcheng Deng,Zhiyi Yin,Xueqi Cheng*

Main category: cs.AI

TL;DR: 本文提出了一种名为“循环推理”的新型大型推理模型（LRM）失效模式，其特点是模型陷入自我强化、重复生成先前内容的循环。作者为此构建了一个名为 LoopBench 的数据集，并发现循环推理是由推理僵局触发的，表现为一种 V 形注意力机制驱动的不可避免的循环。研究人员利用 CUSUM 算法成功预测了循环推理的发生，验证了其在长链推理中的稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在测试时扩展后虽然表现良好，但经常出现重复循环导致计算浪费和推理失败。作者希望识别并解决一种特定的失败模式，即循环推理，这种模式不同于传统的模型退化。

Method: 作者引入了一个名为 LoopBench 的数据集，其中包含两种循环类型（数值循环和陈述循环），以系统地分析循环推理现象。他们将循环推理表征为一种状态崩溃，并分析了其触发机制（推理僵局）和持续机制（V 形注意力机制）。最后，他们使用累积和（CUSUM）算法来捕捉循环推理的先兆，以实现早期预测。

Result: 研究表明，推理僵局会触发循环推理，并通过 V 形注意力机制形成一个不可避免的循环，其中语义重复先于文本重复。CUSUM 算法被证明能够准确地预测循环推理的发生，并有助于阐明长链推理的稳定性。

Conclusion: 循环推理是 LRM 的一种独特失效模式，表现为模型陷入自我重复的循环。通过 LoopBench 数据集和 CUSUM 算法，研究人员能够分析、预测并可能缓解这一问题，从而提高 LRM 的推理稳定性和效率。

Abstract: Despite the success of test-time scaling, Large Reasoning Models (LRMs) frequently encounter repetitive loops that lead to computational waste and inference failure. In this paper, we identify a distinct failure mode termed Circular Reasoning. Unlike traditional model degeneration, this phenomenon manifests as a self-reinforcing trap where generated content acts as a logical premise for its own recurrence, compelling the reiteration of preceding text. To systematically analyze this phenomenon, we introduce LoopBench, a dataset designed to capture two distinct loop typologies: numerical loops and statement loops. Mechanistically, we characterize circular reasoning as a state collapse exhibiting distinct boundaries, where semantic repetition precedes textual repetition. We reveal that reasoning impasses trigger the loop onset, which subsequently persists as an inescapable cycle driven by a self-reinforcing V-shaped attention mechanism. Guided by these findings, we employ the Cumulative Sum (CUSUM) algorithm to capture these precursors for early loop prediction. Experiments across diverse LRMs validate its accuracy and elucidate the stability of long-chain reasoning.

</details>


### [23] [Logic-Parametric Neuro-Symbolic NLI: Controlling Logical Formalisms for Verifiable LLM Reasoning](https://arxiv.org/abs/2601.05705)
*Ali Farjami,Luca Redondi,Marco Valentino*

Main category: cs.AI

TL;DR: 提出了一种新颖的神经符号自然语言推理（NLI）框架，通过将逻辑形式作为可控组件，克服了现有方法依赖固定逻辑形式的局限性，并在规范推理任务上取得了更好的性能和更高效的证明。不同逻辑在不同领域表现出不同的优势。


<details>
  <summary>Details</summary>
Motivation: 现有的结合大型语言模型（LLMs）和定理证明器（TPs）进行可验证NLI的方法依赖于固定的逻辑形式，这限制了其鲁棒性和适应性。因此，需要一种更灵活的框架。

Method: 提出了一种逻辑参数化的神经符号NLI框架，将底层逻辑作为可控组件。利用LogiKEy方法将多种经典和非经典逻辑形式嵌入高阶逻辑（HOL），系统比较推理质量、解释优化和证明行为。重点关注规范推理，并将逻辑外部方法（通过公理编码）与逻辑内部方法（从逻辑结构中涌现）进行对比。

Result: 实验表明，逻辑内部策略能持续提高NLI性能并产生更高效的混合证明。逻辑的有效性依赖于领域，一阶逻辑在常识推理中表现更好，而义务逻辑和模态逻辑在伦理领域表现更优。

Conclusion: 将逻辑作为神经符号架构中的一等参数化元素，可以实现更鲁棒、更模块化和更具适应性的推理。逻辑内部的方法在规范推理任务中表现出优势，并且逻辑的选择与特定领域相关。

Abstract: Large language models (LLMs) and theorem provers (TPs) can be effectively combined for verifiable natural language inference (NLI). However, existing approaches rely on a fixed logical formalism, a feature that limits robustness and adaptability. We propose a logic-parametric framework for neuro-symbolic NLI that treats the underlying logic not as a static background, but as a controllable component. Using the LogiKEy methodology, we embed a range of classical and non-classical formalisms into higher-order logic (HOL), enabling a systematic comparison of inference quality, explanation refinement, and proof behavior. We focus on normative reasoning, where the choice of logic has significant implications. In particular, we compare logic-external approaches, where normative requirements are encoded via axioms, with logic-internal approaches, where normative patterns emerge from the logic's built-in structure. Extensive experiments demonstrate that logic-internal strategies can consistently improve performance and produce more efficient hybrid proofs for NLI. In addition, we show that the effectiveness of a logic is domain-dependent, with first-order logic favouring commonsense reasoning, while deontic and modal logics excel in ethical domains. Our results highlight the value of making logic a first-class, parametric element in neuro-symbolic architectures for more robust, modular, and adaptable reasoning.

</details>


### [24] [Overcoming Joint Intractability with Lossless Hierarchical Speculative Decoding](https://arxiv.org/abs/2601.05724)
*Yuxuan Zhou,Fei Huang,Heng Li,Fengyi Wu,Tianyu Wang,Jianwei Zhang,Junyang Lin,Zhi-Qi Cheng*

Main category: cs.AI

TL;DR: 本文提出了一种名为分层推测解码（HSD）的无损验证方法，用于解决推测解码中验证瓶颈问题，显著提高了接受率，并克服了联合不可解性。


<details>
  <summary>Details</summary>
Motivation: 推测解码在提高推理速度和保持分布保真度方面存在瓶颈，现有方法在处理联合不可解性时存在局限。

Method: 提出分层推测解码（HSD），一种可证明的无损验证方法，通过平衡可访问分支之间的超额和不足的概率质量来克服联合不可解性。

Result: HSD在不同模型族和基准测试中始终提高了接受率。与EAGLE-3集成后，性能提升超过12%，达到了最先进的解码效率，且不牺牲分布保真度。

Conclusion: HSD是一种有效、通用且具有良好可解释性的验证方法，可以集成到各种推测解码框架中，显著提高解码效率。

Abstract: Verification is a key bottleneck in improving inference speed while maintaining distribution fidelity in Speculative Decoding. Recent work has shown that sequence-level verification leads to a higher number of accepted tokens compared to token-wise verification. However, existing solutions often rely on surrogate approximations or are constrained by partial information, struggling with joint intractability. In this work, we propose Hierarchical Speculative Decoding (HSD), a provably lossless verification method that significantly boosts the expected number of accepted tokens and overcomes joint intractability by balancing excess and deficient probability mass across accessible branches. Our extensive large-scale experiments demonstrate that HSD yields consistent improvements in acceptance rates across diverse model families and benchmarks. Moreover, its strong explainability and generality make it readily integrable into a wide range of speculative decoding frameworks. Notably, integrating HSD into EAGLE-3 yields over a 12% performance gain, establishing state-of-the-art decoding efficiency without compromising distribution fidelity. Code is available at https://github.com/ZhouYuxuanYX/Hierarchical-Speculative-Decoding.

</details>


### [25] [PII-VisBench: Evaluating Personally Identifiable Information Safety in Vision Language Models Along a Continuum of Visibility](https://arxiv.org/abs/2601.05739)
*G M Shahariar,Zabir Al Nazi,Md Olid Hasan Bhuiyan,Zhouxing Shi*

Main category: cs.AI

TL;DR: 本研究提出了 PII-VisBench 基准测试，用于评估视觉语言模型 (VLM) 在不同在线可见度下的个人身份信息 (PII) 泄露风险。结果表明，随着主体在线可见度降低，VLM 的拒绝率增加，PII 泄露率降低。


<details>
  <summary>Details</summary>
Motivation: 现有对 VLM PII 泄露的评估大多将其视为静态提取任务，忽略了主体在线数据量对隐私泄露的影响。因此，需要一种新的评估方法来考虑在线存在对 VLM 隐私安全的影响。

Method: 研究提出了 PII-VisBench 基准测试，包含 4000 个探针，将 200 个主体分为高、中、低、零四种在线可见度。评估了 18 个开源 VLM，使用 PII 探测查询的拒绝率和包含 PII 的非拒绝响应的比例两个指标。

Result: 研究发现，随着主体可见度降低，VLM 的拒绝率一致性地增加，PII 泄露率降低（从高可见度的 9.10% 降至低可见度的 5.34%）。模型更容易泄露高可见度主体的 PII，并且在模型家族和 PII 类型上存在显著差异。此外，释义和越狱式提示暴露出模型依赖的攻击和失败。

Conclusion: 在线可见度是影响 VLM 隐私安全的关键因素。未来的 VLM 安全评估和训练干预应考虑在线可见度，以提高模型的隐私保护能力。

Abstract: Vision Language Models (VLMs) are increasingly integrated into privacy-critical domains, yet existing evaluations of personally identifiable information (PII) leakage largely treat privacy as a static extraction task and ignore how a subject's online presence--the volume of their data available online--influences privacy alignment. We introduce PII-VisBench, a novel benchmark containing 4000 unique probes designed to evaluate VLM safety through the continuum of online presence. The benchmark stratifies 200 subjects into four visibility categories: high, medium, low, and zero--based on the extent and nature of their information available online. We evaluate 18 open-source VLMs (0.3B-32B) based on two key metrics: percentage of PII probing queries refused (Refusal Rate) and the fraction of non-refusal responses flagged for containing PII (Conditional PII Disclosure Rate). Across models, we observe a consistent pattern: refusals increase and PII disclosures decrease (9.10% high to 5.34% low) as subject visibility drops. We identify that models are more likely to disclose PII for high-visibility subjects, alongside substantial model-family heterogeneity and PII-type disparities. Finally, paraphrasing and jailbreak-style prompts expose attack and model-dependent failures, motivating visibility-aware safety evaluation and training interventions.

</details>


### [26] [DynaDebate: Breaking Homogeneity in Multi-Agent Debate with Dynamic Path Generation](https://arxiv.org/abs/2601.05746)
*Zhenghao Li,Zhi Zheng,Wei Chen,Jielun Zhao,Yong Chen,Tong Xu,Enhong Chen*

Main category: cs.AI

TL;DR: 本文提出了一种名为 DynaDebate 的动态多智能体辩论框架，通过动态路径生成、以过程为中心的辩论和基于触发器的验证机制，提高了多智能体辩论的有效性，克服了现有方法中代理推理路径趋同导致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于多智能体的辩论方法存在代理推理路径趋同、导致辩论无效和结果退化为简单投票的问题。

Method: 本文提出了 DynaDebate 框架，包含三个关键机制：1. 动态路径生成与分配：利用专用代理生成多样化且逻辑上一致的解决方案路径，并具有自适应冗余。2. 以过程为中心的辩论：将重点从结果投票转移到逐个逻辑步骤的批判，以确保过程正确性。3. 基于触发器的验证代理：在出现分歧时激活，并利用外部工具客观地解决僵局。

Result: DynaDebate 在多个基准测试中展现出优越的性能，显著优于现有的最先进的多智能体辩论方法。

Conclusion: DynaDebate 通过其创新的机制有效提升了多智能体辩论的能力，能够生成更可靠的解决方案并克服现有方法的局限性。

Abstract: Recent years have witnessed the rapid development of Large Language Model-based Multi-Agent Systems (MAS), which excel at collaborative decision-making and complex problem-solving. Recently, researchers have further investigated Multi-Agent Debate (MAD) frameworks, which enhance the reasoning and collaboration capabilities of MAS through information exchange and debate among multiple agents. However, existing approaches often rely on unguided initialization, causing agents to adopt identical reasoning paths that lead to the same errors. As a result, effective debate among agents is hindered, and the final outcome frequently degenerates into simple majority voting. To solve the above problem, in this paper, we introduce Dynamic Multi-Agent Debate (DynaDebate), which enhances the effectiveness of multi-agent debate through three key mechanisms: (1) Dynamic Path Generation and Allocation, which employs a dedicated Path Generation Agent to generate diverse and logical solution paths with adaptive redundancy; (2) Process-Centric Debate, which shifts the focus from surface-level outcome voting to rigorous step-by-step logic critique to ensure process correctness; (3) A Trigger-Based Verification Agent, which is activated upon disagreement and uses external tools to objectively resolve deadlocks. Extensive experiments demonstrate that DynaDebate achieves superior performance across various benchmarks, surpassing existing state-of-the-art MAD methods.

</details>


### [27] [From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation](https://arxiv.org/abs/2601.05787)
*Zezhou Wang,Ziyun Zhang,Xiaoyi Zhang,Zhuzhong Qian,Yan Lu*

Main category: cs.AI

TL;DR: 本研究提出了BEPA（Bi-Level Expert-to-Policy Assimilation）方法，通过双层专家轨迹同化机制，有效利用有限的专家演示数据来训练端到端的计算机使用代理（CUAs）模型，显著提升了在OSWorld-Verified等基准测试上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的计算机使用代理（CUAs）框架虽然性能优越，但部署复杂；而易于部署的端到端模型在OSWorld-Verified等基准测试上的表现不佳。OSWorld等GUI数据集在任务数量和专家数据获取方面存在瓶颈，难以扩展。因此，研究如何利用有限的专家轨迹来训练端到端模型成为关键问题。

Method: 提出BEPA（Bi-Level Expert-to-Policy Assimilation）方法，该方法包含两个层面：LEVEL-1利用基础策略生成的“自滚动可达轨迹”将静态专家轨迹转化为策略对齐的指导；LEVEL-2使用一个每任务动态更新的缓存，用于强化学习从可验证奖励（RLVR）。BEPA旨在解决离策略专家轨迹与在线RLVR之间的结构不匹配和分布偏移问题。

Result: 在OSWorld-Verified基准测试上，BEPA将UITARS1.5-7B的成功率从22.87%提升到32.13%，在预留数据集上的成功率从5.74%提升到10.30%。此外，BEPA在MMBench-GUI和Online-Mind2Web等任务上也取得了持续的性能提升。

Conclusion: BEPA能够有效地利用有限的专家演示数据，克服端到端模型在GUI环境中的性能瓶颈，显著提升了计算机使用代理（CUAs）在复杂任务上的表现，为在实际应用中部署更强大的CUAs提供了新的途径。

Abstract: Vision-language models are increasingly deployed as computer-use agents (CUAs) that operate desktops and browsers. Top-performing CUAs are framework-based systems that decompose planning and execution, while end-to-end screenshot-to-action policies are easier to deploy but lag behind on benchmarks such as OSWorld-Verified. GUI datasets like OSWorld pose two bottlenecks: they expose only a few hundred interactive, verifiable tasks and environments, and expert trajectories must be gathered by interacting with these environments, making such data hard to scale. We therefore ask how reinforcement learning from verifiable rewards (RLVR) can best exploit a small pool of exist expert trajectories to train end-to-end policies. Naively mixing these off-policy traces into on-policy RLVR is brittle: even after format conversion, expert trajectories exhibit structural mismatch and distribution shift from the learner. We propose BEPA (Bi-Level Expert-to-Policy Assimilation), which turns static expert traces into policy-aligned guidance via self-rolled reachable trajectories under the base policy (LEVEL-1) and a per-task, dynamically updated cache used in RLVR (LEVEL-2). On OSWorld-Verified, BEPA improves UITARS1.5-7B success from 22.87% to 32.13% and raises a held-out split from 5.74% to 10.30%, with consistent gains on MMBench-GUI and Online-Mind2Web. Our code and data are available at: https://github.com/LEON-gittech/Verl_GUI.git

</details>


### [28] [StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management](https://arxiv.org/abs/2601.05890)
*Ruizhe Zhang,Xinke Jiang,Zhibang Yang,Zhixin Zhang,Jiaran Gao,Yuzhen Xiao,Hongbin Lai,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.AI

TL;DR: StackPlanner 是一个分层多智能体框架，通过显式的记忆控制来解决中心化大语言模型多智能体系统在长期协作中的不稳定问题，通过记忆管理和经验复用提升性能。


<details>
  <summary>Details</summary>
Motivation: 中心化大语言模型多智能体系统在复杂任务中表现出潜力，但其中心代理缺乏记忆管理，导致长期协作不稳定、上下文膨胀、错误累积以及跨任务泛化能力差。

Method: 提出 StackPlanner，一个分层多智能体框架，通过以下方式解决上述挑战：1. 将高级协调与子任务执行分离，并主动控制任务级记忆；2. 通过结构化经验记忆和强化学习，学习检索和利用可重用的协调经验。

Result: 在多个深度搜索和智能体系统基准测试中的实验表明，StackPlanner 能够实现可靠的长期多智能体协作。

Conclusion: StackPlanner 通过显式的记忆控制和经验复用，有效解决了中心化大语言模型多智能体系统在长期协作中的不稳定和效率问题，提升了其性能和泛化能力。

Abstract: Multi-agent systems based on large language models, particularly centralized architectures, have recently shown strong potential for complex and knowledge-intensive tasks. However, central agents often suffer from unstable long-horizon collaboration due to the lack of memory management, leading to context bloat, error accumulation, and poor cross-task generalization. To address both task-level memory inefficiency and the inability to reuse coordination experience, we propose StackPlanner, a hierarchical multi-agent framework with explicit memory control. StackPlanner addresses these challenges by decoupling high-level coordination from subtask execution with active task-level memory control, and by learning to retrieve and exploit reusable coordination experience via structured experience memory and reinforcement learning. Experiments on multiple deep-search and agent system benchmarks demonstrate the effectiveness of our approach in enabling reliable long-horizon multi-agent collaboration.

</details>


### [29] [TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents](https://arxiv.org/abs/2601.05899)
*Dawei Wang,Chengming Zhou,Di Zhao,Xinyuan Liu,Marci Chi Ma,Gary Ushaw,Richard Davison*

Main category: cs.AI

TL;DR: 本文提出了TowerMind，一个低计算需求、支持多模态观测的塔防游戏环境，用于评估大型语言模型（LLMs）在长期规划和决策方面的能力，并揭示了LLMs在这些方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的用于评估LLM在RTS游戏中规划和决策能力的测试平台计算成本高且缺乏文本观测支持。因此，需要一个计算成本低、支持多模态观测的新环境。

Method: 构建了一个基于塔防（TD）子类型RTS游戏的名为TowerMind的新环境。该环境具有低计算需求和多模态观测空间（像素、文本、结构化游戏状态）。设计了五个基准关卡来评估现有的LLMs和两个经典的强化学习算法（Ape-X DQN和PPO）。

Result: LLMs在规划和决策能力方面与人类专家存在明显差距，并且存在模型幻觉问题。实验揭示了LLM行为的关键局限性，包括规划验证不足、决策缺乏多重终局性以及行动使用效率低下。与Ape-X DQN和PPO相比，LLMs在整体表现上仍有提升空间。

Conclusion: TowerMind提供了一个轻量级、多模态的评估环境，能够有效评估LLMs在规划和决策方面的能力，并揭示了其当前的局限性。该环境为AI代理领域提供了一个新的基准，有助于推动LLM在复杂任务中的应用研究。

Abstract: Recent breakthroughs in Large Language Models (LLMs) have positioned them as a promising paradigm for agents, with long-term planning and decision-making emerging as core general-purpose capabilities for adapting to diverse scenarios and tasks. Real-time strategy (RTS) games serve as an ideal testbed for evaluating these two capabilities, as their inherent gameplay requires both macro-level strategic planning and micro-level tactical adaptation and action execution. Existing RTS game-based environments either suffer from relatively high computational demands or lack support for textual observations, which has constrained the use of RTS games for LLM evaluation. Motivated by this, we present TowerMind, a novel environment grounded in the tower defense (TD) subgenre of RTS games. TowerMind preserves the key evaluation strengths of RTS games for assessing LLMs, while featuring low computational demands and a multimodal observation space, including pixel-based, textual, and structured game-state representations. In addition, TowerMind supports the evaluation of model hallucination and provides a high degree of customizability. We design five benchmark levels to evaluate several widely used LLMs under different multimodal input settings. The results reveal a clear performance gap between LLMs and human experts across both capability and hallucination dimensions. The experiments further highlight key limitations in LLM behavior, such as inadequate planning validation, a lack of multifinality in decision-making, and inefficient action use. We also evaluate two classic reinforcement learning algorithms: Ape-X DQN and PPO. By offering a lightweight and multimodal design, TowerMind complements the existing RTS game-based environment landscape and introduces a new benchmark for the AI agent field. The source code is publicly available on GitHub(https://github.com/tb6147877/TowerMind).

</details>


### [30] [Open-Vocabulary 3D Instruction Ambiguity Detection](https://arxiv.org/abs/2601.05991)
*Jiayu Ding,Haoran Tang,Ge Li*

Main category: cs.AI

TL;DR: 研究提出了一个名为Open-Vocabulary 3D Instruction Ambiguity Detection的新任务，用于检测3D场景中指令的歧义性，并构建了Ambi3D数据集。现有的3D LLM在该任务上表现不佳，为此，研究提出了AmbiVer框架，通过多视角视觉证据来提高歧义检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 在手术等安全关键领域，语言指令的模糊性可能导致严重后果。然而，现有的具身AI研究忽略了指令歧义问题，主要关注指令执行而非确认。

Method: 1. 定义了Open-Vocabulary 3D Instruction Ambiguity Detection任务。 2. 构建了Ambi3D数据集，包含700多个3D场景和约2.2万条指令。 3. 提出了AmbiVer两阶段框架，该框架收集多视角下的视觉证据，并利用这些证据指导视觉-语言模型（VLM）判断指令的歧义性。

Result: 现有的3D大型语言模型（LLMs）在可靠判断指令歧义性方面存在显著局限性。AmbiVer框架在评估实验中证明了其有效性，能够应对所提出的挑战。

Conclusion: 语言指令的歧义性检测是具身AI领域一个重要且被忽视的挑战。AmbiVer框架通过结合多视角视觉信息，为解决这一问题提供了有效途径，有望促进更安全、更可信赖的具身AI系统。

Abstract: In safety-critical domains, linguistic ambiguity can have severe consequences; a vague command like "Pass me the vial" in a surgical setting could lead to catastrophic errors. Yet, most embodied AI research overlooks this, assuming instructions are clear and focusing on execution rather than confirmation. To address this critical safety gap, we are the first to define Open-Vocabulary 3D Instruction Ambiguity Detection, a fundamental new task where a model must determine if a command has a single, unambiguous meaning within a given 3D scene. To support this research, we build Ambi3D, the large-scale benchmark for this task, featuring over 700 diverse 3D scenes and around 22k instructions. Our analysis reveals a surprising limitation: state-of-the-art 3D Large Language Models (LLMs) struggle to reliably determine if an instruction is ambiguous. To address this challenge, we propose AmbiVer, a two-stage framework that collects explicit visual evidence from multiple views and uses it to guide an vision-language model (VLM) in judging instruction ambiguity. Extensive experiments demonstrate the challenge of our task and the effectiveness of AmbiVer, paving the way for safer and more trustworthy embodied AI. Code and dataset available at https://jiayuding031020.github.io/ambi3d/.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [31] [Bi-Orthogonal Factor Decomposition for Vision Transformers](https://arxiv.org/abs/2601.05328)
*Fenil R. Doshi,Thomas Fel,Talia Konkle,George Alvarez*

Main category: cs.CV

TL;DR: 本文提出了一种名为双正交分解（BFD）的分析框架，用于理解 Vision Transformer 中的自注意力机制。BFD 将 token 激活分解为位置和内容因子，并分析查询-键交互矩阵，揭示了注意力如何在这些因子之间进行信息交换。研究发现，注意力主要通过内容进行交互，不同注意力头和奇异模式具有专业化分工，并且 DINOv2 在处理形状时能同时保留位置结构并丰富语义内容。


<details>
  <summary>Details</summary>
Motivation: 当前对 Vision Transformer 的自注意力机制缺乏深入理解，特别是其在 token 之间交换的信息类型（位置、内容或两者兼有）。

Method: 提出双正交分解（BFD）框架。第一阶段使用基于 ANOVA 的分解，将 token 激活解耦为正交的位置因子和内容因子。第二阶段对查询-键交互矩阵 $QK^T$ 进行奇异值分解（SVD），揭示双正交模式，展示这些因子如何进行通信。

Result: 1. 注意力主要通过内容进行交互，其次是内容-位置耦合。DINOv2 在内容-位置交互方面比监督模型投入更多能量，并分布在更丰富的模式谱上。
2. 注意力头和奇异模式表现出专业化分工：内容-内容、内容-位置和位置-位置操作。
3. DINOv2 在处理形状方面表现优异，得益于中间层能够同时保留位置结构并富集语义内容。

Conclusion: BFD 揭示了 Vision Transformer 中 token 如何通过注意力机制进行交互，以及信息（位置或语义）是如何被传递的，为理解 Vision Transformer 机制提供了实际见解。

Abstract: Self-attention is the central computational primitive of Vision Transformers, yet we lack a principled understanding of what information attention mechanisms exchange between tokens. Attention maps describe where weight mass concentrates; they do not reveal whether queries and keys trade position, content, or both. We introduce Bi-orthogonal Factor Decomposition (BFD), a two-stage analytical framework: first, an ANOVA-based decomposition statistically disentangles token activations into orthogonal positional and content factors; second, SVD of the query-key interaction matrix QK^T exposes bi-orthogonal modes that reveal how these factors mediate communication. After validating proper isolation of position and content, we apply BFD to state-of-the-art vision models and uncover three phenomena.(i) Attention operates primarily through content. Content-content interactions dominate attention energy, followed by content-position coupling. DINOv2 allocates more energy to content-position than supervised models and distributes computation across a richer mode spectrum. (ii) Attention mechanisms exhibit specialization: heads differentiate into content-content, content-position, and position-position operators, while singular modes within heads show analogous specialization. (iii) DINOv2's superior holistic shape processing emerges from intermediate layers that simultaneously preserve positional structure while contextually enriching semantic content.
  Overall, BFD exposes how tokens interact through attention and which informational factors - positional or semantic - mediate their communication, yielding practical insights into vision transformer mechanisms.

</details>


### [32] [Coding the Visual World: From Image to Simulation Using Vision Language Models](https://arxiv.org/abs/2601.05344)
*Sagi Eppel*

Main category: cs.CV

TL;DR: 本文提出Im2Sim方法，评估视觉语言模型（VLMs）理解并模拟图像中系统和机制的能力，通过生成代码并合成图像进行比较。结果显示，领先的VLMs能理解复杂系统，但在细节复现上能力有限，表现出高层次理解与低层次感知的不对称性。


<details>
  <summary>Details</summary>
Motivation: 研究视觉语言模型（VLMs）在理解图像中复杂系统和机制方面的能力，以及它们能否通过代码模拟和生成这些系统。

Method: 使用Im2Sim方法，将自然图像输入给VLMs，要求其描述系统并生成模拟代码。执行代码生成合成图像，并与原始图像进行比较，以此评估VLMs的理解能力。

Result: 先进的VLMs（如GPT, Gemini）在理解和建模跨领域、多层次抽象的复杂系统方面表现出能力。然而，它们在复制图像中的精细细节和低级模式排列方面能力有限。

Conclusion: VLMs在视觉理解方面表现出一种有趣的不对称性：它们具备高层次、深入的图像理解能力，但对精细细节的感知能力有限。

Abstract: The ability to construct mental models of the world is a central aspect of understanding. Similarly, visual understanding can be viewed as the ability to construct a representative model of the system depicted in an image. This work explores the capacity of Vision Language Models (VLMs) to recognize and simulate the systems and mechanisms depicted in images using the Im2Sim methodology. The VLM is given a natural image of a real-world system (e.g., cities, clouds, vegetation) and is tasked with describing the system and writing code that simulates and generates it. This generative code is then executed to produce a synthetic image, which is compared against the original. This approach is tested on various complex emergent systems, ranging from physical systems (waves, lights, clouds) to vegetation, cities, materials, and geological formations. Through analysis of the models and images generated by the VLMs, we examine their understanding of the systems in images. The results show that leading VLMs (GPT, Gemini) demonstrate the capacity to understand and model complex, multi-component systems across multiple layers of abstraction and a wide range of domains. At the same time, the VLMs exhibit limited ability to replicate fine details and low-level arrangements of patterns in the image. These findings reveal an interesting asymmetry: VLMs combine high-level, deep visual understanding of images with limited perception of fine details.

</details>


### [33] [Sketch&Patch++: Efficient Structure-Aware 3D Gaussian Representation](https://arxiv.org/abs/2601.05394)
*Yuang Shi,Simone Gasparini,Géraldine Morin,Wei Tsang Ooi*

Main category: cs.CV

TL;DR: 提出一种将高斯球体（Gaussians）语义划分为“草图高斯”（Sketch Gaussians）和“块高斯”（Patch Gaussians）的混合表示方法，用于3D场景的表示和流式传输，实现了在模型大小相当的情况下，PSNR、SSIM和LPIPS等指标的显著提升，并能在极小模型尺寸下保持视觉质量。


<details>
  <summary>Details</summary>
Motivation: 受艺术家绘画过程中先勾勒轮廓再填充色彩的启发，作者观察到高斯球体在3D表示中也存在类似的高频（边缘）和低频（平滑区域）特征，希望利用这种语义分离来实现更高效的3D内容表示和流式传输。

Method: 提出一种分层自适应分类框架，直接在3D高斯球体（3DGS）表示上操作。该方法使用多标准密度聚类和自适应质量驱动的精炼，将高斯球体分为代表高频特征的“草图高斯”和代表低频平滑区域的“块高斯”。这种划分实现了分层渐进式流式传输，先加载“草图高斯”构建结构，再加载“块高斯”增加细节。

Result: 在多种3D场景（包括人造和自然环境）的评估中，与统一剪枝基线相比，在模型大小相同的情况下，PSNR提高了1.74 dB，SSIM提高了6.7%，LPIPS降低了41.4%。在室内场景中，模型尺寸仅占原始模型的0.5%，仍能保持良好的视觉质量。

Conclusion: 该结构感知表示方法通过将高斯球体语义化为“草图高斯”和“块高斯”，能够实现高效存储、自适应流式传输和高保真3D内容渲染，特别适用于带宽受限的网络和资源受限的设备。

Abstract: We observe that Gaussians exhibit distinct roles and characteristics analogous to traditional artistic techniques -- like how artists first sketch outlines before filling in broader areas with color, some Gaussians capture high-frequency features such as edges and contours, while others represent broader, smoother regions analogous to brush strokes that add volume and depth. Based on this observation, we propose a hybrid representation that categorizes Gaussians into (i) Sketch Gaussians, which represent high-frequency, boundary-defining features, and (ii) Patch Gaussians, which cover low-frequency, smooth regions. This semantic separation naturally enables layered progressive streaming, where the compact Sketch Gaussians establish the structural skeleton before Patch Gaussians incrementally refine volumetric detail.
  In this work, we extend our previous method to arbitrary 3D scenes by proposing a novel hierarchical adaptive categorization framework that operates directly on the 3DGS representation. Our approach employs multi-criteria density-based clustering, combined with adaptive quality-driven refinement. This method eliminates dependency on external 3D line primitives while ensuring optimal parametric encoding effectiveness. Our comprehensive evaluation across diverse scenes, including both man-made and natural environments, demonstrates that our method achieves up to 1.74 dB improvement in PSNR, 6.7% in SSIM, and 41.4% in LPIPS at equivalent model sizes compared to uniform pruning baselines. For indoor scenes, our method can maintain visual quality with only 0.5\% of the original model size. This structure-aware representation enables efficient storage, adaptive streaming, and rendering of high-fidelity 3D content across bandwidth-constrained networks and resource-limited devices.

</details>


### [34] [STResNet & STYOLO : A New Family of Compact Classification and Object Detection Models for MCUs](https://arxiv.org/abs/2601.05364)
*Sudhakar Sah,Ravish Kumar*

Main category: cs.CV

TL;DR: 本文提出了两种新的轻量级神经网络模型系列STResNet（图像分类）和STYOLO（目标检测），旨在同时优化准确性、效率和内存占用，以解决现有模型在资源受限平台上的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级神经网络在边缘硬件上的部署效率有所提高，但为了降低延迟通常会牺牲准确性，这限制了它们在微控制器和NPU设备上的应用。

Method: 提出了STResNet（Nano到Tiny）和STYOLO（Micro和Milli）两个模型系列，并对它们进行了联合优化，以在资源受限的平台上实现准确性、效率和内存占用的平衡。STResNetMilli在ImageNet 1K上达到了70.0%的Top 1准确率，拥有300万参数。STYOLOMicro和STYOLOMilli在MS COCO数据集上分别取得了30.5%和33.6%的mAP。

Result: STResNetMilli（300万参数）在ImageNet 1K上取得了70.0%的Top 1准确率，优于同等计算复杂度的MobileNetV1和ShuffleNetV2。STYOLOMicro和STYOLOMilli在MS COCO上的mAP分别达到30.5%和33.6%，优于YOLOv5n和YOLOX Nano。

Conclusion: STResNet和STYOLO模型系列在资源受限的平台上实现了准确性、效率和内存占用的有效权衡，为在微控制器和NPU设备上部署深度学习模型提供了有前景的解决方案。

Abstract: Recent advancements in lightweight neural networks have significantly improved the efficiency of deploying deep learning models on edge hardware. However, most existing architectures still trade accuracy for latency, which limits their applicability on microcontroller and neural processing unit based devices. In this work, we introduce two new model families, STResNet for image classification and STYOLO for object detection, jointly optimized for accuracy, efficiency, and memory footprint on resource constrained platforms. The proposed STResNet series, ranging from Nano to Tiny variants, achieves competitive ImageNet 1K accuracy within a four million parameter budget. Specifically, STResNetMilli attains 70.0 percent Top 1 accuracy with only three million parameters, outperforming MobileNetV1 and ShuffleNetV2 at comparable computational complexity. For object detection, STYOLOMicro and STYOLOMilli achieve 30.5 percent and 33.6 percent mean average precision, respectively, on the MS COCO dataset, surpassing YOLOv5n and YOLOX Nano in both accuracy and efficiency. Furthermore, when STResNetMilli is used as a backbone with the Ultralytics training environment.

</details>


### [35] [MOSAIC-GS: Monocular Scene Reconstruction via Advanced Initialization for Complex Dynamic Environments](https://arxiv.org/abs/2601.05368)
*Svitlana Morkva,Maximum Wilder-Smith,Michael Oechsle,Alessio Tonioni,Marco Hutter,Vaishakh Patil*

Main category: cs.CV

TL;DR: MOSAIC-GS 是一种新的、完全显式且计算高效的方法，使用高保真高斯溅射（Gaussian Splatting）从单目视频进行动态场景重建，通过结合多种几何线索和基于刚性的运动约束来处理单目重建的固有限制。


<details>
  <summary>Details</summary>
Motivation: 单目重建因缺乏足够的多视图约束而本质上是病态的，这使得准确恢复物体几何形状和时间连贯性尤其困难。现有方法在运动推理上依赖于视觉外观，而外观在单目设置下往往很模糊。

Method: MOSAIC-GS 利用深度、光流、动态对象分割和点跟踪等多种几何线索，结合基于刚性的运动约束，在初始化阶段估计初步的 3D 场景动态。该方法将场景分解为静态和动态组件，动态部分的每个高斯被分配一条表示时间相关多傅里叶曲线的轨迹，以实现参数高效的运动编码。

Result: MOSAIC-GS 在优化和渲染速度上比现有方法快得多，同时在标准单目动态场景基准测试中保持了与最先进方法相当的重建质量。

Conclusion: MOSAIC-GS 提出了一种新颖的单目动态场景重建方法，通过预先估计场景动态并采用紧凑的表示方式，有效地解决了单目重建的挑战，实现了快速优化、渲染和高质量重建。

Abstract: We present MOSAIC-GS, a novel, fully explicit, and computationally efficient approach for high-fidelity dynamic scene reconstruction from monocular videos using Gaussian Splatting. Monocular reconstruction is inherently ill-posed due to the lack of sufficient multiview constraints, making accurate recovery of object geometry and temporal coherence particularly challenging. To address this, we leverage multiple geometric cues, such as depth, optical flow, dynamic object segmentation, and point tracking. Combined with rigidity-based motion constraints, these cues allow us to estimate preliminary 3D scene dynamics during an initialization stage. Recovering scene dynamics prior to the photometric optimization reduces reliance on motion inference from visual appearance alone, which is often ambiguous in monocular settings. To enable compact representations, fast training, and real-time rendering while supporting non-rigid deformations, the scene is decomposed into static and dynamic components. Each Gaussian in the dynamic part of the scene is assigned a trajectory represented as time-dependent Poly-Fourier curve for parameter-efficient motion encoding. We demonstrate that MOSAIC-GS achieves substantially faster optimization and rendering compared to existing methods, while maintaining reconstruction quality on par with state-of-the-art approaches across standard monocular dynamic scene benchmarks.

</details>


### [36] [Ensemble of radiomics and ConvNeXt for breast cancer diagnosis](https://arxiv.org/abs/2601.05373)
*Jorge Alberto Garza-Abdala,Gerardo Alejandro Fumagal-González,Beatriz A. Bosques-Palomo,Mario Alexis Monsivais Molina,Daly Avedano,Servando Cardona-Huerta,José Gerardo Tamez-Pena*

Main category: cs.CV

TL;DR: 本研究评估了影像组学、深度学习（DL）和集成技术在乳腺癌筛查中的表现，发现集成方法（结合DL和影像组学）在检测准确性上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 早期诊断乳腺癌对提高生存率至关重要，影像组学和深度学习在辅助诊断方面显示出巨大潜力。本研究旨在评估这两种技术以及集成技术在乳腺癌筛查中的性能。

Method: 使用了两个独立的数据集（RSNA 2023挑战赛和TecSalud数据集）。使用ConvNeXtV1-small DL模型在RSNA数据集上训练，并在TecSalud数据集上验证。影像组学模型在TecSalud数据集上开发，并采用了留一年交叉验证。集成方法结合并校准了DL和影像组学的预测。

Result: 集成方法在AUC（曲线下面积）方面取得了0.87的最佳表现，优于ConvNeXtV1-small（0.83）和纯影像组学模型（0.80）。

Conclusion: 结合深度学习和影像组学预测的集成方法显著提高了从乳腺钼靶图像进行乳腺癌诊断的准确性。

Abstract: Early diagnosis of breast cancer is crucial for improving survival rates. Radiomics and deep learning (DL) have shown significant potential in assisting radiologists with early cancer detection. This paper aims to critically assess the performance of radiomics, DL, and ensemble techniques in detecting cancer from screening mammograms. Two independent datasets were used: the RSNA 2023 Breast Cancer Detection Challenge (11,913 patients) and a Mexican cohort from the TecSalud dataset (19,400 patients). The ConvNeXtV1-small DL model was trained on the RSNA dataset and validated on the TecSalud dataset, while radiomics models were developed using the TecSalud dataset and validated with a leave-one-year-out approach. The ensemble method consistently combined and calibrated predictions using the same methodology. Results showed that the ensemble approach achieved the highest area under the curve (AUC) of 0.87, compared to 0.83 for ConvNeXtV1-small and 0.80 for radiomics. In conclusion, ensemble methods combining DL and radiomics predictions significantly enhance breast cancer diagnosis from mammograms.

</details>


### [37] [EdgeLDR: Quaternion Low-Displacement Rank Neural Networks for Edge-Efficient Deep Learning](https://arxiv.org/abs/2601.05379)
*Vladimir Frants,Sos Agaian,Karen Panetta*

Main category: cs.CV

TL;DR: EdgeLDR 是一个用于边缘设备的实用框架，它通过结合四元数通道混合和块循环参数结构，实现了高效的四元数线性层和卷积层，并支持基于 FFT 的计算，从而在保持竞争性精度的同时实现了显著的压缩。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署深度神经网络面临内存流量和计算成本的限制。四元数神经网络虽然提高了参数效率，但通常仍使用非结构化稠密权重。结构化矩阵可以加速计算，但通常仅限于实数域。因此，需要一种能够结合四元数通道混合和结构化参数以实现高效计算的方法。

Method: 提出 EdgeLDR 框架，该框架支持四元数块循环线性层和卷积层。通过 Hamilton 乘积实现四元数通道混合，通过块循环矩阵实现参数结构化。利用复杂伴随表示，支持基于 FFT 的高效评估。实现了 EdgeLDR 层的参考实现，并与朴素的空间域实现进行对比。将 EdgeLDR 层集成到紧凑型 CNN 和 Transformer 主干网络中，并在 CIFAR-10/100、SVHN、Houston 2013 和 Pavia University 数据集上评估了精度-压缩权衡。

Result: 基于 FFT 的计算相比朴素的空间域实现，显示出显著的加速效果，并且随着块大小的增加，延迟保持稳定。EdgeLDR 层在 CIFAR-10/100、SVHN、Houston 2013 和 Pavia University 数据集上，在显著压缩模型的同时，保持了有竞争力的精度。CPU/GPU 延迟也得到了评估。

Conclusion: EdgeLDR 框架能够有效地压缩深度神经网络，同时保持其精度，使其在资源受限的边缘设备上部署成为可能。FFT 加速和块循环结构是实现高压缩率和低延迟的关键。

Abstract: Deploying deep neural networks on edge devices is often limited by the memory traffic and compute cost of dense linear operators. While quaternion neural networks improve parameter efficiency by coupling multiple channels through Hamilton products, they typically retain unstructured dense weights; conversely, structured matrices enable fast computation but are usually applied in the real domain. This paper introduces EdgeLDR, a practical framework for quaternion block-circulant linear and convolutional layers that combines quaternion channel mixing with block-circulant parameter structure and enables FFT-based evaluation through the complex adjoint representation. We present reference implementations of EdgeLDR layers and compare FFT-based computation against a naive spatial-domain realization of quaternion circulant products. FFT evaluation yields large empirical speedups over the naive implementation and keeps latency stable as block size increases, making larger compression factors computationally viable. We further integrate EdgeLDR layers into compact CNN and Transformer backbones and evaluate accuracy-compression trade-offs on 32x32 RGB classification (CIFAR-10/100, SVHN) and hyperspectral image classification (Houston 2013, Pavia University), reporting parameter counts and CPU/GPU latency. The results show that EdgeLDR layers provide significant compression with competitive accuracy.

</details>


### [38] [Multi-task Cross-modal Learning for Chest X-ray Image Retrieval](https://arxiv.org/abs/2601.05399)
*Zhaohui Liang,Sivaramakrishnan Rajaraman,Niccolo Marini,Zhiyun Xue,Sameer Antani*

Main category: cs.CV

TL;DR: 研究提出了一种多任务学习框架，用于微调BiomedCLIP模型，以提高胸部X光片（CXR）图像与放射学报告之间的检索性能。与预训练模型相比，微调后的模型在图像-文本和文本-图像检索任务上表现更均衡且临床意义更强。


<details>
  <summary>Details</summary>
Motivation: 现有的CLIP和BiomedCLIP等视觉-语言基础模型在细粒度的医学检索任务（如使用CXR图像检索放射学报告）方面不够优化。

Method: 使用BiomedCLIP作为基础模型，加入一个轻量级的MLP投影头，并采用包含三个组件（二元交叉熵损失、监督对比损失、CLIP损失）的复合多任务损失函数进行微调。

Result: 微调后的模型在CXR图像-文本检索任务上实现了比预训练BiomedCLIP和CLIP模型更均衡、临床意义更强的性能。t-SNE可视化显示正常和异常病例的语义聚类更清晰，表明模型诊断敏感性增强。

Conclusion: 领域自适应的多任务学习对于改进生物医学应用的跨模态检索具有重要价值。

Abstract: CLIP and BiomedCLIP are examples of vision-language foundation models and offer strong cross-modal embeddings; however, they are not optimized for fine-grained medical retrieval tasks, such as retrieving clinically relevant radiology reports using chest X-ray (CXR) image queries. To address this shortcoming, we propose a multi-task learning framework to fine-tune BiomedCLIP and evaluate improvements to CXR image-text retrieval. Using BiomedCLIP as the backbone, we incorporate a lightweight MLP projector head trained with a multi-task composite loss function that includes: (1) a binary cross-entropy loss to distinguish normal from abnormal CXR studies, (2) a supervised contrastive loss to reinforce intra-class consistency, and (3) a CLIP loss to maintain cross-modal alignment. Experimental results demonstrate that the fine-tuned model achieves more balanced and clinically meaningful performance across both image-to-text and text-to-image retrieval tasks compared to the pretrained BiomedCLIP and general-purpose CLIP models. Furthermore, t-SNE visualizations reveal clearer semantic clustering of normal and abnormal cases, demonstrating the model's enhanced diagnostic sensitivity. These findings highlight the value of domain-adaptive, multi-task learning for advancing cross-modal retrieval in biomedical applications.

</details>


### [39] [Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization](https://arxiv.org/abs/2601.05432)
*Yuxiang Ji,Yong Wang,Ziyu Ma,Yiming Hu,Hailang Huang,Xuecai Hu,Guanhua Chen,Liaoni Wu,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为“Thinking with Map”的方法，将地图使用能力融入大型视觉语言模型（LVLM）以提升图像地理定位任务的表现。该方法通过强化学习和并行测试时缩放进行优化，并在新的基准测试集MAPBench上进行了评估，结果表明其显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型在图像地理定位时忽略了人类常用的地图使用策略，这限制了模型的性能。研究旨在弥合这一差距，让模型具备“思考地图”的能力。

Method: 提出“Thinking with Map”能力，并将其构建为一个“代理-在地图中”的循环。采用两阶段优化方案：首先是代理强化学习（RL）以提升采样效率和代理能力；其次是并行测试时缩放（TTS）以允许模型在最终预测前探索多条候选路径。同时，提出了新的基准测试集MAPBench。

Result: 所提出的方法在MAPBench上取得了显著的性能提升，优于现有的开源和闭源模型。具体而言，与使用Google搜索/地图的Gemini-3-Pro相比，Acc@500m从8.0%提升到22.1%。

Conclusion: 将地图使用能力融入LVLM是提升图像地理定位性能的有效途径。提出的“Thinking with Map”方法通过RL和TTS的优化，以及MAPBench基准测试的验证，证明了其优越性。

Abstract: The image geolocalization task aims to predict the location where an image was taken anywhere on Earth using visual clues. Existing large vision-language model (LVLM) approaches leverage world knowledge, chain-of-thought reasoning, and agentic capabilities, but overlook a common strategy used by humans -- using maps. In this work, we first equip the model \textit{Thinking with Map} ability and formulate it as an agent-in-the-map loop. We develop a two-stage optimization scheme for it, including agentic reinforcement learning (RL) followed by parallel test-time scaling (TTS). The RL strengthens the agentic capability of model to improve sampling efficiency, and the parallel TTS enables the model to explore multiple candidate paths before making the final prediction, which is crucial for geolocalization. To evaluate our method on up-to-date and in-the-wild images, we further present MAPBench, a comprehensive geolocalization training and evaluation benchmark composed entirely of real-world images. Experimental results show that our method outperforms existing open- and closed-source models on most metrics, specifically improving Acc@500m from 8.0\% to 22.1\% compared to \textit{Gemini-3-Pro} with Google Search/Map grounded mode.

</details>


### [40] [TAPM-Net: Trajectory-Aware Perturbation Modeling for Infrared Small Target Detection](https://arxiv.org/abs/2601.05446)
*Hongyang Xie,Hongyang He,Victor Sanchez*

Main category: cs.CV

TL;DR: 本文提出了一种名为TAPM-Net的新型红外小目标检测网络，通过显式建模目标引起特征扰动的空间扩散行为来解决红外小目标检测中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有模型缺乏机制来追踪特征空间中小目标引起的定向、层级扰动，而这是区分信号和背景噪声的重要线索。

Method: TAPM-Net包含两个新组件：扰动引导路径模块（PGM）和轨迹感知状态块（TASB）。PGM构建扰动能量场并提取特征轨迹，TASB是基于Mamba的状态空间单元，通过约束扩散和语义对齐特征融合来建模轨迹上的动态传播。

Result: TAPM-Net在NUAA-SIRST和IRSTD-1K数据集上取得了最先进的性能。

Conclusion: TAPM-Net能够实现各向异性的、上下文感知的状态转换，同时保持低计算成本下的全局一致性，有效解决了红外小目标检测的挑战。

Abstract: Infrared small target detection (ISTD) remains a long-standing challenge due to weak signal contrast, limited spatial extent, and cluttered backgrounds. Despite performance improvements from convolutional neural networks (CNNs) and Vision Transformers (ViTs), current models lack a mechanism to trace how small targets trigger directional, layer-wise perturbations in the feature space, which is an essential cue for distinguishing signal from structured noise in infrared scenes. To address this limitation, we propose the Trajectory-Aware Mamba Propagation Network (TAPM-Net), which explicitly models the spatial diffusion behavior of target-induced feature disturbances. TAPM-Net is built upon two novel components: a Perturbation-guided Path Module (PGM) and a Trajectory-Aware State Block (TASB). The PGM constructs perturbation energy fields from multi-level features and extracts gradient-following feature trajectories that reflect the directionality of local responses. The resulting feature trajectories are fed into the TASB, a Mamba-based state-space unit that models dynamic propagation along each trajectory while incorporating velocity-constrained diffusion and semantically aligned feature fusion from word-level and sentence-level embeddings. Unlike existing attention-based methods, TAPM-Net enables anisotropic, context-sensitive state transitions along spatial trajectories while maintaining global coherence at low computational cost. Experiments on NUAA-SIRST and IRSTD-1K demonstrate that TAPM-Net achieves state-of-the-art performance in ISTD.

</details>


### [41] [Multi-Image Super Resolution Framework for Detection and Analysis of Plant Roots](https://arxiv.org/abs/2601.05482)
*Shubham Agarwal,Ofek Nourian,Michael Sidorov,Sharon Chemweno,Ofer Hadar,Naftali Lazarovitch,Jhonathan E. Ephrath*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的多图像超分辨率（MISR）系统，用于增强地下植物根系图像的可见性和细节，以提高根系表型分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 准确成像地下植物根系具有挑战性，受土壤遮挡、湿度变化和低对比度等不利因素影响，限制了传统视觉方法的有效性。研究旨在克服这些挑战，以改进根系分析。

Method: 开发了一个新的地下成像系统，捕获植物根系的多重重叠视图。利用深度学习MISR框架，结合空间冗余来重建高分辨率图像，并使用合成数据集进行训练和评估。

Result: 提出的MISR算法在提高图像质量和结构保真度方面优于现有超分辨率方法，BRISQUE评分降低了2.3%，CLIP-IQA得分保持不变。这使得更精确地估计根系性状（如根毛数量和密度）成为可能。

Conclusion: 该框架为鲁棒的自动地下植物根系成像和性状量化提供了一个有前景的方向，对农业和生态研究具有重要意义。

Abstract: Understanding plant root systems is critical for advancing research in soil-plant interactions, nutrient uptake, and overall plant health. However, accurate imaging of roots in subterranean environments remains a persistent challenge due to adverse conditions such as occlusion, varying soil moisture, and inherently low contrast, which limit the effectiveness of conventional vision-based approaches. In this work, we propose a novel underground imaging system that captures multiple overlapping views of plant roots and integrates a deep learning-based Multi-Image Super Resolution (MISR) framework designed to enhance root visibility and detail. To train and evaluate our approach, we construct a synthetic dataset that simulates realistic underground imaging scenarios, incorporating key environmental factors that affect image quality. Our proposed MISR algorithm leverages spatial redundancy across views to reconstruct high-resolution images with improved structural fidelity and visual clarity. Quantitative evaluations show that our approach outperforms state-of-the-art super resolution baselines, achieving a 2.3 percent reduction in BRISQUE, indicating improved image quality with the same CLIP-IQA score, thereby enabling enhanced phenotypic analysis of root systems. This, in turn, facilitates accurate estimation of critical root traits, including root hair count and root hair density. The proposed framework presents a promising direction for robust automatic underground plant root imaging and trait quantification for agricultural and ecological research.

</details>


### [42] [FlyPose: Towards Robust Human Pose Estimation From Aerial Views](https://arxiv.org/abs/2601.05747)
*Hassaan Farooq,Marvin Brenner,Peter St\ütz*

Main category: cs.CV

TL;DR: 本文提出了一种名为 FlyPose 的轻量级自上而下人形姿态估计流水线，专门用于处理无人机拍摄的航拍图像，能够在嵌入式设备上实现实时推理，并在多个数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在人口密集区域的应用日益广泛，对人体姿态和行为的精确空中感知变得至关重要。然而，航拍图像面临低分辨率、陡峭视角和遮挡等挑战，现有方法难以满足实时性要求。

Method: 作者开发了一个名为 FlyPose 的轻量级自上而下的人形姿态估计流水线。该流水线通过多数据集训练来提高其在不同航拍场景下的泛化能力，并针对低分辨率和遮挡等问题进行了优化。同时，研究中还发布了一个名为 FlyPose-104 的新数据集。

Result: FlyPose 在 person detection 任务上，在 Manipal-UAV、VisDrone、HIT-UAV 以及自定义数据集上平均 mAP 提高了 6.8。在极具挑战性的 UAV-Human 数据集上，2D 人形姿态估计的 mAP 提升了 16.3。FlyPose 在 Jetson Orin AGX 开发者套件上的推理延迟约为 20 毫秒（包括预处理），并已成功部署在无人机上进行飞行实验。

Conclusion: FlyPose 是一个高效且准确的空中人体姿态估计解决方案，能够满足无人机在复杂环境中实时感知人形姿态的需求，并且可以通过新的数据集 FlyPose-104 推动该领域的研究进展。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in close proximity to humans for applications such as parcel delivery, traffic monitoring, disaster response and infrastructure inspections. Ensuring safe and reliable operation in these human-populated environments demands accurate perception of human poses and actions from an aerial viewpoint. This perspective challenges existing methods with low resolution, steep viewing angles and (self-)occlusion, especially if the application demands realtime feasibile models. We train and deploy FlyPose, a lightweight top-down human pose estimation pipeline for aerial imagery. Through multi-dataset training, we achieve an average improvement of 6.8 mAP in person detection across the test-sets of Manipal-UAV, VisDrone, HIT-UAV as well as our custom dataset. For 2D human pose estimation we report an improvement of 16.3 mAP on the challenging UAV-Human dataset. FlyPose runs with an inference latency of ~20 milliseconds including preprocessing on a Jetson Orin AGX Developer Kit and is deployed onboard a quadrotor UAV during flight experiments. We also publish FlyPose-104, a small but challenging aerial human pose estimation dataset, that includes manual annotations from difficult aerial perspectives: https://github.com/farooqhassaan/FlyPose.

</details>


### [43] [ROAP: A Reading-Order and Attention-Prior Pipeline for Optimizing Layout Transformers in Key Information Extraction](https://arxiv.org/abs/2601.05470)
*Tingwei Xie,Jinxin He,Yonghong Song*

Main category: cs.CV

TL;DR: 本文提出了一种名为ROAP的轻量级、与架构无关的管道，用于优化视觉丰富文档理解（VrDU）中的多模态Transformer模型。ROAP通过AXG-Tree提取阅读顺序，通过RO-RPB集成到注意力机制中，并通过TT-Prior抑制视觉噪声，从而提升文本语义的关注度。实验证明ROAP能有效提升LayoutLMv3和GeoLayoutLM等模型的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态Transformer在视觉丰富文档理解（VrDU）中存在两个主要限制：未能明确建模逻辑阅读顺序，以及视觉标记干扰了文本语义的注意力。研究旨在解决这些问题。

Method: 提出ROAP管道，包括：1. 自适应XY-Gap（AXG-Tree）用于提取层次化阅读序列；2. 阅读顺序感知相对位置偏差（RO-RPB）将序列集成到注意力机制；3. 文本标记子块注意力先验（TT-Prior）自适应抑制视觉噪声并增强文本-文本交互。

Result: ROAP在FUNSD和CORD基准测试中，能持续提升LayoutLMv3和GeoLayoutLM等代表性骨干模型的性能。

Conclusion: 明确建模阅读逻辑和调节模态干扰对于鲁棒的文档理解至关重要，ROAP为复杂的布局分析提供了一个可扩展的解决方案。

Abstract: The efficacy of Multimodal Transformers in visually-rich document understanding (VrDU) is critically constrained by two inherent limitations: the lack of explicit modeling for logical reading order and the interference of visual tokens that dilutes attention on textual semantics.
  To address these challenges, this paper presents ROAP, a lightweight and architecture-agnostic pipeline designed to optimize attention distributions in Layout Transformers without altering their pre-trained backbones.
  The proposed pipeline first employs an Adaptive-XY-Gap (AXG-Tree) to robustly extract hierarchical reading sequences from complex layouts. These sequences are then integrated into the attention mechanism via a Reading-Order-Aware Relative Position Bias (RO-RPB). Furthermore, a Textual-Token Sub-block Attention Prior (TT-Prior) is introduced to adaptively suppress visual noise and enhance fine-grained text-text interactions.
  Extensive experiments on the FUNSD and CORD benchmarks demonstrate that ROAP consistently improves the performance of representative backbones, including LayoutLMv3 and GeoLayoutLM.
  These findings confirm that explicitly modeling reading logic and regulating modality interference are critical for robust document understanding, offering a scalable solution for complex layout analysis. The implementation code will be released at https://github.com/KevinYuLei/ROAP.

</details>


### [44] [SceneFoundry: Generating Interactive Infinite 3D Worlds](https://arxiv.org/abs/2601.05810)
*ChunTeng Chen,YiChen Hsu,YiWen Liu,WeiFang Sun,TsaiChing Ni,ChunYi Lee,Min Sun,YuanFu Yang*

Main category: cs.CV

TL;DR: SceneFoundry 是一个使用语言引导的扩散模型框架，可以生成大规模、功能齐全、可交互的 3D 室内环境，用于机器人学习和具身智能的研究。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法难以捕捉真实室内环境的功能复杂性，尤其是包含可移动部件的物品，而这些物品对于机器人操纵和导航至关重要。

Method: 该框架利用大型语言模型（LLM）根据自然语言提示生成房间布局，并使用基于扩散的后验采样从大型 3D 库中高效地填充具有可动关节的物体。通过可微分的引导函数来控制物体数量、防止关节碰撞和保持足够的行走空间。

Result: 实验表明，SceneFoundry 能够生成结构有效、语义连贯且功能可交互的 3D 环境，适用于各种场景类型和条件。

Conclusion: SceneFoundry 能够生成高质量、功能丰富的 3D 环境，为可扩展的具身人工智能研究提供了支持。

Abstract: The ability to automatically generate large-scale, interactive, and physically realistic 3D environments is crucial for advancing robotic learning and embodied intelligence. However, existing generative approaches often fail to capture the functional complexity of real-world interiors, particularly those containing articulated objects with movable parts essential for manipulation and navigation. This paper presents SceneFoundry, a language-guided diffusion framework that generates apartment-scale 3D worlds with functionally articulated furniture and semantically diverse layouts for robotic training. From natural language prompts, an LLM module controls floor layout generation, while diffusion-based posterior sampling efficiently populates the scene with articulated assets from large-scale 3D repositories. To ensure physical usability, SceneFoundry employs differentiable guidance functions to regulate object quantity, prevent articulation collisions, and maintain sufficient walkable space for robotic navigation. Extensive experiments demonstrate that our framework generates structurally valid, semantically coherent, and functionally interactive environments across diverse scene types and conditions, enabling scalable embodied AI research.

</details>


### [45] [Hippocampal Atrophy Patterns Across the Alzheimer's Disease Spectrum: A Voxel-Based Morphometry Analysis](https://arxiv.org/abs/2601.05494)
*Trishna Niraula*

Main category: cs.CV

TL;DR: 本研究利用MRI扫描数据分析了阿尔茨海默病（AD）和轻度认知障碍（MCI）患者的灰质体积变化，发现AD患者海马体萎缩显著，且海马体体积对MCI向AD的转化具有一定的预测价值。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）和轻度认知障碍（MCI）与大脑灰质进行性丢失有关，尤其是在内侧颞叶结构中。本研究旨在通过量化和分析这些区域的灰质体积变化，以支持内侧颞叶变性作为AD进展的关键特征，并探索其作为预测生物标志物和遗传影响的潜在作用。

Method: 研究采用了CAT12/SPM12体素形态测量法（VBM），分析了249名ADNI参与者（正常对照90名，MCI129名，AD30名）的基线T1加权MRI扫描。使用一般线性模型分析灰质体积，以诊断组为主要预测变量，年龄和总颅内容积为协变量。统计图谱在体素水平上以p < 0.001进行阈值处理，并通过家族错误（FWE）校正（p < 0.05）进行多重比较校正。此外，还分析了APOE4基因型对海马体体积的影响。

Result: 研究发现在AD患者相对于正常对照组和MCI组，海马体萎缩显著（Cohen's d = 2.03 和 1.61）。海马体体积对于预测MCI向AD的转化具有中等预测价值（AUC = 0.66）。APOE4基因型分层分析未显示其对横断面海马体体积有显著的遗传影响。

Conclusion: 研究结果支持内侧颞叶变性是AD进展的一个关键特征，并为预测生物标志物（如海马体体积）和遗传影响（如APOE4）提供了见解。

Abstract: Alzheimer's disease (AD) and mild cognitive impairment (MCI) are associated with progressive gray matter loss, particularly in medial temporal structures. In this study, CAT12/SPM12 voxel-based morphometry was applied to baseline T1-weighted MRI scans from 249 ADNI participants (CN = 90, MCI = 129, AD = 30). Gray matter volume was analyzed using a general linear model, with the diagnostic group as primary predictor and age and total intracranial volume as covariates. Statistical maps were thresholded at p < 0.001 (voxelwise) and corrected for multiple comparisons at the cluster level using family-wise error (FWE) correction (p < 0.05). Significant hippocampal atrophy was observed in AD relative to CN and MCI (Cohen's d = 2.03 and 1.61, respectively). Hippocampal volume demonstrated moderate predictive value for conversion from MCI to AD (AUC = 0.66). Stratification by APOE4 status did not reveal significant genetic effects on cross-sectional hippocampal volume. These results support medial temporal degeneration as a key feature of AD progression and provide insights into predictive biomarkers and genetic influences.

</details>


### [46] [MMViR: A Multi-Modal and Multi-Granularity Representation for Long-range Video Understanding](https://arxiv.org/abs/2601.05495)
*Zizhong Li,Haopeng Zhang,Jiawei Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为MMViR的多模态、多粒度结构化视频表示方法，用于长视频理解，通过识别关键转折点进行视频分割，并构建结合全局叙事和细节的三级描述，提高了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLMs 在处理长视频时面临计算成本高、内容冗余或碎片化等挑战。

Method: MMViR 识别视频关键转折点进行分割，构建了包含全局叙事和细粒度视觉细节的三级描述。

Result: 在 QA、摘要和检索任务上，MMViR 在处理长达一小时的视频时，性能提升了 19.67%，同时处理延迟降低到原来的 45.4%。

Conclusion: MMViR 是一种有效的方法，可以提高长视频理解的效率和性能，并能很好地泛化到不同场景。

Abstract: Long videos, ranging from minutes to hours, present significant challenges for current Multi-modal Large Language Models (MLLMs) due to their complex events, diverse scenes, and long-range dependencies. Direct encoding of such videos is computationally too expensive, while simple video-to-text conversion often results in redundant or fragmented content. To address these limitations, we introduce MMViR, a novel multi-modal, multi-grained structured representation for long video understanding. MMViR identifies key turning points to segment the video and constructs a three-level description that couples global narratives with fine-grained visual details. This design supports efficient query-based retrieval and generalizes well across various scenarios. Extensive evaluations across three tasks, including QA, summarization, and retrieval, show that MMViR outperforms the prior strongest method, achieving a 19.67% improvement in hour-long video understanding while reducing processing latency to 45.4% of the original.

</details>


### [47] [Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals](https://arxiv.org/abs/2601.05848)
*Nate Gillman,Yinghua Zhou,Zitian Tang,Evan Luo,Arjan Chakravarthy,Daksh Aggarwal,Michael Freeman,Charles Herrmann,Chen Sun*

Main category: cs.CV

TL;DR: 提出了一种名为Goal Force的框架，通过力矢量和中间动力学来指定视频生成模型的任务目标，实现了对复杂现实场景的零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在指定精确物理任务目标方面存在挑战，文本指令过于抽象，目标图像难以动态指定。作者希望提出一种新的方法，让用户能够通过物理概念来定义目标。

Method: 训练了一个视频生成模型，该模型学习如何传播力和动力学。模型在合成的因果原语数据集上进行训练，例如弹性碰撞和滚动的多米诺骨牌。训练后的模型能够实现对复杂现实场景的零样本泛化。

Result: 模型在工具操作和多物体因果链等复杂现实场景中表现出卓越的零样本泛化能力，即使只在简单的物理数据上训练过。这表明模型能够作为隐式神经物理模拟器。

Conclusion: 通过将视频生成与基本物理交互联系起来，可以构建能够进行精确、物理感知规划的模型，而无需依赖外部物理引擎。该方法通过力矢量和中间动力学有效地解决了指定任务目标的问题。

Abstract: Recent advancements in video generation have enabled the development of ``world models'' capable of simulating potential futures for robotics and planning. However, specifying precise goals for these models remains a challenge; text instructions are often too abstract to capture physical nuances, while target images are frequently infeasible to specify for dynamic tasks. To address this, we introduce Goal Force, a novel framework that allows users to define goals via explicit force vectors and intermediate dynamics, mirroring how humans conceptualize physical tasks. We train a video generation model on a curated dataset of synthetic causal primitives-such as elastic collisions and falling dominos-teaching it to propagate forces through time and space. Despite being trained on simple physics data, our model exhibits remarkable zero-shot generalization to complex, real-world scenarios, including tool manipulation and multi-object causal chains. Our results suggest that by grounding video generation in fundamental physical interactions, models can emerge as implicit neural physics simulators, enabling precise, physics-aware planning without reliance on external engines. We release all datasets, code, model weights, and interactive video demos at our project page.

</details>


### [48] [Prompt-Free SAM-Based Multi-Task Framework for Breast Ultrasound Lesion Segmentation and Classification](https://arxiv.org/abs/2601.05498)
*Samuel E. Johnny,Bernes L. Atabonfack,Israel Alagbe,Assane Gueye*

Main category: cs.CV

TL;DR: 本研究提出了一种利用SAM模型的视觉编码器进行乳腺超声图像自动分割和诊断分类的多任务深度学习框架，无需提示即可进行全监督学习，并将分割结果引导分类任务，在PRECISE 2025数据集上取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 乳腺超声图像的低对比度、斑点噪声和多样的病灶形态使得准确的肿瘤分割和分类具有挑战性。

Method: 利用Segment Anything Model (SAM) 的视觉编码器提取高维特征，并通过轻量级卷积头或UNet启发式解码器进行像素级分割。分类分支则通过掩码引导注意力机制，关注病灶相关特征。

Result: 在PRECISE 2025乳腺超声数据集上，实现了0.887的Dice相似系数（DSC）和92.3%的准确率，在PRECISE挑战赛排行榜上名列前茅。

Conclusion: 将SAM表征与分割引导学习相结合，可以显著提高乳腺超声图像的病灶勾画和诊断预测能力。

Abstract: Accurate tumor segmentation and classification in breast ultrasound (BUS) imaging remain challenging due to low contrast, speckle noise, and diverse lesion morphology. This study presents a multi-task deep learning framework that jointly performs lesion segmentation and diagnostic classification using embeddings from the Segment Anything Model (SAM) vision encoder. Unlike prompt-based SAM variants, our approach employs a prompt-free, fully supervised adaptation where high-dimensional SAM features are decoded through either a lightweight convolutional head or a UNet-inspired decoder for pixel-wise segmentation. The classification branch is enhanced via mask-guided attention, allowing the model to focus on lesion-relevant features while suppressing background artifacts. Experiments on the PRECISE 2025 breast ultrasound dataset, split per class into 80 percent training and 20 percent testing, show that the proposed method achieves a Dice Similarity Coefficient (DSC) of 0.887 and an accuracy of 92.3 percent, ranking among the top entries on the PRECISE challenge leaderboard. These results demonstrate that SAM-based representations, when coupled with segmentation-guided learning, significantly improve both lesion delineation and diagnostic prediction in breast ultrasound imaging.

</details>


### [49] [Enabling Stroke-Level Structural Analysis of Hieroglyphic Scripts without Language-Specific Priors](https://arxiv.org/abs/2601.05508)
*Fuwen Luo,Zihao Wan,Ziyue Wang,Yaluo Liu,Pau Tong Lin Xu,Xuanjia Qiao,Xiaolong Wang,Peng Li,Yang Liu*

Main category: cs.CV

TL;DR: 提出了一种名为HieroSA的新型通用框架，使多模态大语言模型（MLLMs）能够自动从字符位图中提取笔画级结构，无需手工标注数据，从而为多国文字和古代象形文字提供解释性强的线段表示，并证明了其在字形学分析方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLMs和MLLMs在处理象形文字时，无法捕捉其内部的结构和笔画信息，而现有的结构分析方法通常是特定于语言且劳动密集型的。

Method: 提出HieroSA框架，将字符图像转换为归一化坐标空间中的显式、可解释的线段表示，使MLLMs能够自动推导笔画级结构。

Result: HieroSA能够有效捕捉字符内部结构和语义，并且能够跨语言泛化，无需语言特定的先验知识。

Conclusion: HieroSA是一种新型且通用的框架，能够自动从字符位图中提取笔画结构，为深入理解象形文字提供了一个字形学分析工具。

Abstract: Hieroglyphs, as logographic writing systems, encode rich semantic and cultural information within their internal structural composition. Yet, current advanced Large Language Models (LLMs) and Multimodal LLMs (MLLMs) usually remain structurally blind to this information. LLMs process characters as textual tokens, while MLLMs additionally view them as raw pixel grids. Both fall short to model the underlying logic of character strokes. Furthermore, existing structural analysis methods are often script-specific and labor-intensive. In this paper, we propose Hieroglyphic Stroke Analyzer (HieroSA), a novel and generalizable framework that enables MLLMs to automatically derive stroke-level structures from character bitmaps without handcrafted data. It transforms modern logographic and ancient hieroglyphs character images into explicit, interpretable line-segment representations in a normalized coordinate space, allowing for cross-lingual generalization. Extensive experiments demonstrate that HieroSA effectively captures character-internal structures and semantics, bypassing the need for language-specific priors. Experimental results highlight the potential of our work as a graphematics analysis tool for a deeper understanding of hieroglyphic scripts. View our code at https://github.com/THUNLP-MT/HieroSA.

</details>


### [50] [GaussianSwap: Animatable Video Face Swapping with 3D Gaussian Splatting](https://arxiv.org/abs/2601.05511)
*Xuan Cheng,Jiahao Rao,Chengyang Li,Wenhao Wang,Weilin Chen,Lvqing Yang*

Main category: cs.CV

TL;DR: GaussianSwap 是一种创新的视频换脸框架，通过构建基于 3D 高斯泼溅（Gaussian Splatting）的面部化身，并将源图像的身份信息转移到该化身上。


<details>
  <summary>Details</summary>
Motivation: 现有视频换脸框架局限于像素格式的表示，生成的换脸面部缺乏动画和交互能力。本文旨在实现从像素级视频生成到创建具有可交互性的高保真换脸化身的范式转变。

Method: 该框架首先处理目标视频以提取 FLAME 参数、相机姿态和分割蒙版，然后将 3D 高斯泼溅对象绑定到 FLAME 模型上，实现动态面部控制。为了保持身份信息，提出了一个由三种先进人脸识别模型组成的复合身份嵌入，用于化身微调。最后，在背景帧上渲染换脸化身以生成视频。

Result: 实验结果表明，GaussianSwap 在身份保持、视觉清晰度和时间一致性方面表现优越，并实现了以前无法实现的交互式应用。

Conclusion: GaussianSwap 通过引入 3D 高斯泼溅技术，克服了传统像素级换脸方法的局限性，实现了更具保真度、可控性和交互性的视频换脸效果。

Abstract: We introduce GaussianSwap, a novel video face swapping framework that constructs a 3D Gaussian Splatting based face avatar from a target video while transferring identity from a source image to the avatar. Conventional video swapping frameworks are limited to generating facial representations in pixel-based formats. The resulting swapped faces exist merely as a set of unstructured pixels without any capacity for animation or interactive manipulation. Our work introduces a paradigm shift from conventional pixel-based video generation to the creation of high-fidelity avatar with swapped faces. The framework first preprocesses target video to extract FLAME parameters, camera poses and segmentation masks, and then rigs 3D Gaussian splats to the FLAME model across frames, enabling dynamic facial control. To ensure identity preserving, we propose an compound identity embedding constructed from three state-of-the-art face recognition models for avatar finetuning. Finally, we render the face-swapped avatar on the background frames to obtain the face-swapped video. Experimental results demonstrate that GaussianSwap achieves superior identity preservation, visual clarity and temporal consistency, while enabling previously unattainable interactive applications.

</details>


### [51] [SAS-VPReID: A Scale-Adaptive Framework with Shape Priors for Video-based Person Re-Identification at Extreme Far Distances](https://arxiv.org/abs/2601.05535)
*Qiwei Yang,Pingping Zhang,Yuhao Wang,Zijing Gong*

Main category: cs.CV

TL;DR: 提出了一种名为SAS-VPReID的视频人物重识别框架，通过记忆增强视觉骨干、多粒度时间建模和先验正则化形状动力学来解决远距离、低分辨率和视角变化等挑战，并在VReID-XFD基准测试中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频人物重识别方法在处理极远距离、分辨率低、视角变化大和外观噪声等问题时面临挑战。

Method: 提出SAS-VPReID框架，包含三个模块：1. 记忆增强视觉骨干（MEVB）提取判别性特征；2. 多粒度时间建模（MGTM）捕捉多尺度时序信息；3. 先验正则化形状动力学（PRSD）建模身体结构变化。

Result: SAS-VPReID框架能够获得更具判别性的特征表示。在VReID-XFD基准测试中，每个模块都显示了有效性，并且最终框架在VReID-XFD挑战赛排行榜上名列第一。

Conclusion: SAS-VPReID框架通过结合增强的特征提取、多粒度时间建模和形状动力学，有效解决了视频人物重识别中的远距离和分辨率挑战，并在VReID-XFD数据集上取得了优异的性能。

Abstract: Video-based Person Re-IDentification (VPReID) aims to retrieve the same person from videos captured by non-overlapping cameras. At extreme far distances, VPReID is highly challenging due to severe resolution degradation, drastic viewpoint variation and inevitable appearance noise. To address these issues, we propose a Scale-Adaptive framework with Shape Priors for VPReID, named SAS-VPReID. The framework is built upon three complementary modules. First, we deploy a Memory-Enhanced Visual Backbone (MEVB) to extract discriminative feature representations, which leverages the CLIP vision encoder and multi-proxy memory. Second, we propose a Multi-Granularity Temporal Modeling (MGTM) to construct sequences at multiple temporal granularities and adaptively emphasize motion cues across scales. Third, we incorporate Prior-Regularized Shape Dynamics (PRSD) to capture body structure dynamics. With these modules, our framework can obtain more discriminative feature representations. Experiments on the VReID-XFD benchmark demonstrate the effectiveness of each module and our final framework ranks the first on the VReID-XFD challenge leaderboard. The source code is available at https://github.com/YangQiWei3/SAS-VPReID.

</details>


### [52] [DIFF-MF: A Difference-Driven Channel-Spatial State Space Model for Multi-Modal Image Fusion](https://arxiv.org/abs/2601.05538)
*Yiming Sun,Zifan Ye,Qinghua Hu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的差分驱动通道-空间状态空间模型（DIFF-MF）用于多模态图像融合，该模型通过利用模态间的特征差异图来指导特征提取，并结合通道和空间维度的融合，实现了比现有方法在视觉质量和定量评估上都更优的融合效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于状态空间模型的多模态图像融合方法存在过度偏重红外强度或可见光结构的问题，导致融合图像在细节或目标突出性上存在不足。研究旨在克服这些挑战，提升融合图像的整体质量。

Method: 提出DIFF-MF模型，包含特征提取、通道维度融合和空间维度融合三个主要部分。特征提取利用模态间的特征差异图。通道维度融合采用通道交换模块，通过交叉注意力双状态空间建模增强通道间交互和自适应特征重加权。空间维度融合采用空间交换模块，通过跨模态状态空间扫描实现空间信息的全面融合。

Result: 在驾驶场景和低空无人机数据集上的实验表明，DIFF-MF方法在视觉质量和定量评估方面均优于现有方法。

Conclusion: DIFF-MF模型能够有效捕获全局依赖关系，同时保持线性计算复杂度，通过差分驱动的通道-空间状态空间建模，实现了对互补多模态特征的有效融合，解决了现有方法在细节保持和目标突出性方面的不足。

Abstract: Multi-modal image fusion aims to integrate complementary information from multiple source images to produce high-quality fused images with enriched content. Although existing approaches based on state space model have achieved satisfied performance with high computational efficiency, they tend to either over-prioritize infrared intensity at the cost of visible details, or conversely, preserve visible structure while diminishing thermal target salience. To overcome these challenges, we propose DIFF-MF, a novel difference-driven channel-spatial state space model for multi-modal image fusion. Our approach leverages feature discrepancy maps between modalities to guide feature extraction, followed by a fusion process across both channel and spatial dimensions. In the channel dimension, a channel-exchange module enhances channel-wise interaction through cross-attention dual state space modeling, enabling adaptive feature reweighting. In the spatial dimension, a spatial-exchange module employs cross-modal state space scanning to achieve comprehensive spatial fusion. By efficiently capturing global dependencies while maintaining linear computational complexity, DIFF-MF effectively integrates complementary multi-modal features. Experimental results on the driving scenarios and low-altitude UAV datasets demonstrate that our method outperforms existing approaches in both visual quality and quantitative evaluation.

</details>


### [53] [MoGen: A Unified Collaborative Framework for Controllable Multi-Object Image Generation](https://arxiv.org/abs/2601.05546)
*Yanfeng Li,Yue Sun,Keren Fu,Sio-Kei Im,Xiaoming Liu,Guangtao Zhai,Xiaohong Liu,Tao Tan*

Main category: cs.CV

TL;DR: MoGen 是一种多对象图像生成方法，通过区域语义锚点（RSA）和自适应多模态引导（AMG）模块，解决了现有方法在语义与生成区域对齐、对象数量一致性和属性准确性方面的不足，实现了更灵活、精细化的控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以精确对齐文本描述中的语义与生成的图像区域，导致对象数量不一致和属性混淆。主流方法依赖外部控制信号，输入格式僵化，不适应用户异构的资源和多样的约束需求。

Method: 提出 MoGen 方法，设计了区域语义锚点（RSA）模块，将文本描述中的短语单元锚定到对应的图像区域，实现数量精确的多对象生成。在此基础上，引入自适应多模态引导（AMG）模块，自适应解析和整合多源控制信号，形成结构化意图，指导场景布局和对象属性的动态精细化控制。

Result: MoGen 在生成质量、数量一致性和精细化控制方面显著优于现有方法，同时展现出更强的可访问性和控制灵活性。

Conclusion: MoGen 是一种用户友好的多对象图像生成方法，通过 RSA 和 AMG 模块，有效解决了现有方法的局限性，提供了更高质量、更一致且更灵活的控制能力。

Abstract: Existing multi-object image generation methods face difficulties in achieving precise alignment between localized image generation regions and their corresponding semantics based on language descriptions, frequently resulting in inconsistent object quantities and attribute aliasing. To mitigate this limitation, mainstream approaches typically rely on external control signals to explicitly constrain the spatial layout, local semantic and visual attributes of images. However, this strong dependency makes the input format rigid, rendering it incompatible with the heterogeneous resource conditions of users and diverse constraint requirements. To address these challenges, we propose MoGen, a user-friendly multi-object image generation method. First, we design a Regional Semantic Anchor (RSA) module that precisely anchors phrase units in language descriptions to their corresponding image regions during the generation process, enabling text-to-image generation that follows quantity specifications for multiple objects. Building upon this foundation, we further introduce an Adaptive Multi-modal Guidance (AMG) module, which adaptively parses and integrates various combinations of multi-source control signals to formulate corresponding structured intent. This intent subsequently guides selective constraints on scene layouts and object attributes, achieving dynamic fine-grained control. Experimental results demonstrate that MoGen significantly outperforms existing methods in generation quality, quantity consistency, and fine-grained control, while exhibiting superior accessibility and control flexibility. Code is available at: https://github.com/Tear-kitty/MoGen/tree/master.

</details>


### [54] [VIB-Probe: Detecting and Mitigating Hallucinations in Vision-Language Models via Variational Information Bottleneck](https://arxiv.org/abs/2601.05547)
*Feiran Zhang,Yixin Wu,Zhenghua Wang,Xiaohua Wang,Changze Lv,Xuanjing Huang,Xiaoqing Zheng*

Main category: cs.CV

TL;DR: 提出了一种名为VIB-Probe的新型视觉-语言模型（VLM）幻觉检测和缓解框架，利用变分信息瓶颈（VIB）理论，通过分析内部注意力头来识别和减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的幻觉检测方法忽视了VLM的内部机制，而VLM容易产生幻觉（生成的文本与视觉内容不符）。本文旨在探索VLM内部注意力头中的信号，以检测和缓解幻觉。

Method: 提出VIB-Probe框架，利用变分信息瓶颈（VIB）理论来提取区分性模式并过滤掉语义噪声。通过VIB探测器的梯度，识别对幻觉有因果影响的注意力头，并引入推理时干预策略来缓解幻觉。

Result: 在多个基准测试中，VIB-Probe在幻觉检测和缓解方面均显著优于现有方法。

Conclusion: VIB-Probe是一种有效的VLM幻觉检测和缓解框架，通过利用VIB理论和内部注意力机制，能够显著提升VLM的真实性。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable progress in multimodal tasks, but remain susceptible to hallucinations, where generated text deviates from the underlying visual content. Existing hallucination detection methods primarily rely on output logits or external verification tools, often overlooking their internal mechanisms. In this work, we investigate the outputs of internal attention heads, postulating that specific heads carry the primary signals for truthful generation.However, directly probing these high-dimensional states is challenging due to the entanglement of visual-linguistic syntax and noise. To address this, we propose VIB-Probe, a novel hallucination detection and mitigation framework leveraging the Variational Information Bottleneck (VIB) theory. Our method extracts discriminative patterns across layers and heads while filtering out semantic nuisances through the information bottleneck principle. Furthermore, by leveraging the gradients of our VIB probe, we identify attention heads with strong causal influence on hallucinations and introduce an inference-time intervention strategy for hallucination mitigation. Extensive experiments across diverse benchmarks demonstrate that VIB-Probe significantly outperforms existing baselines in both settings. Our code will be made publicly available.

</details>


### [55] [One Language-Free Foundation Model Is Enough for Universal Vision Anomaly Detection](https://arxiv.org/abs/2601.05552)
*Bin-Bin Gao,Chengjie Wang*

Main category: cs.CV

TL;DR: 本文提出了UniADet，一个简单、通用且有效的通用视觉异常检测框架，无需数据集微调，通过解耦分类和分割任务以及跨层特征，实现了比现有零样本/少样本方法更优越的性能，甚至首次超越了全样本异常检测方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉-语言基础模型的通用视觉异常检测方法存在复杂提示工程、繁琐适配模块和挑战性训练策略的问题，限制了其灵活性和通用性。作者旨在通过重新思考视觉-语言模型在异常检测中的基本机制，提出一个更简单、更通用的方法。

Method: UniADet框架的核心思想是：1) 发现语言编码器对于通用异常检测来说并非必需，并将其移除；2) 提出一种简单的方法完全解耦分类和分割任务，以及解耦跨层特征，即为不同任务和不同层级的特征学习独立的权重。

Result: UniADet框架非常简单，仅需学习解耦的权重，参数高效（仅0.002M可学习参数），通用性强（可适配多种基础模型）。在14个涵盖工业和医学领域的真实世界异常检测基准测试中，UniADet的性能表现优越，大幅超越了现有的零样本/少样本异常检测方法，并首次实现了超越全样本异常检测方法的性能。

Conclusion: UniADet提供了一个极其简单、参数高效且性能强大的通用视觉异常检测解决方案，有效解决了现有方法的局限性，并在多个领域展示了其优越性和通用性。

Abstract: Universal visual anomaly detection (AD) aims to identify anomaly images and segment anomaly regions towards open and dynamic scenarios, following zero- and few-shot paradigms without any dataset-specific fine-tuning. We have witnessed significant progress in widely use of visual-language foundational models in recent approaches. However, current methods often struggle with complex prompt engineering, elaborate adaptation modules, and challenging training strategies, ultimately limiting their flexibility and generality. To address these issues, this paper rethinks the fundamental mechanism behind visual-language models for AD and presents an embarrassingly simple, general, and effective framework for Universal vision Anomaly Detection (UniADet). Specifically, we first find language encoder is used to derive decision weights for anomaly classification and segmentation, and then demonstrate that it is unnecessary for universal AD. Second, we propose an embarrassingly simple method to completely decouple classification and segmentation, and decouple cross-level features, i.e., learning independent weights for different tasks and hierarchical features. UniADet is highly simple (learning only decoupled weights), parameter-efficient (only 0.002M learnable parameters), general (adapting a variety of foundation models), and effective (surpassing state-of-the-art zero-/few-shot by a large margin and even full-shot AD methods for the first time) on 14 real-world AD benchmarks covering both industrial and medical domains. We will make the code and model of UniADet available at https://github.com/gaobb/UniADet.

</details>


### [56] [Semi-Supervised Facial Expression Recognition based on Dynamic Threshold and Negative Learning](https://arxiv.org/abs/2601.05556)
*Zhongpeng Cai,Jun Yu,Wei Xu,Tianyu Liu,Jianqing Sun,Jiaen Liang*

Main category: cs.CV

TL;DR: 提出一种基于动态阈值调整（DTA）和选择性负学习（SNL）的半监督面部表情识别算法，通过特征提取的局部注意力和随机丢弃，增强局部特征表示并防止过拟合。该算法利用DTA适应半监督学习框架，并通过SNL从低置信度无标签样本中挖掘互补标签的有用信息，在RAF-DB和AffectNet数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 获取大量标注的面部表情数据成本高昂，因此需要设计一种能充分利用标注和非标注数据的半监督面部表情识别算法。

Method: 1. 特征提取：采用局部注意力增强和特征图随机丢弃策略，以增强局部特征表示并防止过拟合。 2. 半监督学习：引入动态阈值调整（DTA）方法以适应面部表情识别的半监督学习需求。 3. 选择性负学习（SNL）：利用互补标签从低置信度的无标签样本中挖掘有用的表情信息。

Result: 在RAF-DB和AffectNet数据集上取得了最先进的性能，即使在不使用全部数据集的情况下，性能也优于完全监督方法。

Conclusion: 提出的DTA和SNL半监督面部表情识别算法能够有效利用无标签数据，并取得优于完全监督方法的性能，证明了该方法的有效性。

Abstract: Facial expression recognition is a key task in human-computer interaction and affective computing. However, acquiring a large amount of labeled facial expression data is often costly. Therefore, it is particularly important to design a semi-supervised facial expression recognition algorithm that makes full use of both labeled and unlabeled data. In this paper, we propose a semi-supervised facial expression recognition algorithm based on Dynamic Threshold Adjustment (DTA) and Selective Negative Learning (SNL). Initially, we designed strategies for local attention enhancement and random dropout of feature maps during feature extraction, which strengthen the representation of local features while ensuring the model does not overfit to any specific local area. Furthermore, this study introduces a dynamic thresholding method to adapt to the requirements of the semi-supervised learning framework for facial expression recognition tasks, and through a selective negative learning strategy, it fully utilizes unlabeled samples with low confidence by mining useful expression information from complementary labels, achieving impressive results. We have achieved state-of-the-art performance on the RAF-DB and AffectNet datasets. Our method surpasses fully supervised methods even without using the entire dataset, which proves the effectiveness of our approach.

</details>


### [57] [What's Left Unsaid? Detecting and Correcting Misleading Omissions in Multimodal News Previews](https://arxiv.org/abs/2601.05563)
*Fanxiao Li,Jiaying Wu,Tingchao Fu,Dayang Li,Herun Wan,Wei Zhou,Min-Yen Kan*

Main category: cs.CV

TL;DR: 本研究提出了一个检测和修正社交媒体新闻预览（图文组合）误导性的新方法。研究发现大型语言模型（LVLMs）在检测这种“遗漏式误导”方面存在明显不足，并开发了一个名为OMGuard的系统，通过微调和基于理由的修正来提升检测和修正能力，尤其强调了视觉干预的重要性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体新闻预览（图文组合）即使在事实正确的情况下，也可能通过遗漏关键上下文导致读者理解偏差，这种“遗漏式误导”比显性虚假信息更难检测且未被充分研究。

Method: 研究开发了一个多阶段流水线来分离和模拟基于预览和基于上下文的理解，从而构建了MM-Misleading基准。使用该基准系统性评估了开源LVLMs。提出了OMGuard系统，包含“解读感知微调”和“理由引导式误导内容修正”两个模块。

Result: 开源LVLMs在检测遗漏式误导方面存在明显盲点。OMGuard将一个8B模型的检测准确率提升至与235B LVLM相当的水平，并实现了更强的端到端修正效果。研究发现误导性通常源于局部叙事变化（如缺乏背景信息），而非全局框架改变。在纯文本修正无效的图像驱动场景中，视觉干预是必要的。

Conclusion: 社交媒体新闻预览的遗漏式误导是一个真实且需要解决的问题。OMGuard提供了一个有效的检测和修正框架，证明了解读感知微调和理由引导式修正的有效性。研究强调了在处理图像驱动误导时，视觉干预的重要性。

Abstract: Even when factually correct, social-media news previews (image-headline pairs) can induce interpretation drift: by selectively omitting crucial context, they lead readers to form judgments that diverge from what the full article conveys. This covert harm is harder to detect than explicit misinformation yet remains underexplored. To address this gap, we develop a multi-stage pipeline that disentangles and simulates preview-based versus context-based understanding, enabling construction of the MM-Misleading benchmark. Using this benchmark, we systematically evaluate open-source LVLMs and uncover pronounced blind spots to omission-based misleadingness detection. We further propose OMGuard, which integrates (1) Interpretation-Aware Fine-Tuning, which used to improve multimodal misleadingness detection and (2) Rationale-Guided Misleading Content Correction, which uses explicit rationales to guide headline rewriting and reduce misleading impressions. Experiments show that OMGuard lifts an 8B model's detection accuracy to match a 235B LVLM and delivers markedly stronger end-to-end correction. Further analysis reveals that misleadingness typically stems from local narrative shifts (e.g., missing background) rather than global frame changes, and identifies image-driven scenarios where text-only correction fails, highlighting the necessity of visual interventions.

</details>


### [58] [Towards Generalized Multi-Image Editing for Unified Multimodal Models](https://arxiv.org/abs/2601.05572)
*Pengcheng Xu,Peng Tang,Donghao Luo,Xiaobin Hu,Weichu Cui,Qingdong He,Zhennan Chen,Jiangning Zhang,Charles Ling,Boyu Wang*

Main category: cs.CV

TL;DR: 提出了一种新的多图像编辑框架，通过学习到的潜在分离器和正弦索引编码来区分不同图像的身份，提高了视觉一致性和泛化能力，并构建了一个新的基准数据集进行训练和评估。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型在处理多张输入图像时，在保持视觉一致性和区分视觉线索方面存在局限性。

Method: 引入了两种创新算法：1) 学习到的潜在分离器（learnable latent separators）用于在潜在空间中区分每张参考图像；2) 正弦索引编码（sinusoidal index encoding）为同一图像中的视觉标记分配连续的正弦索引嵌入，以实现对可变数量输入的泛化。

Result: 在语义一致性、视觉保真度和跨图像集成方面，该框架相较于现有基线模型在多图像编辑任务上取得了显著的改进，证明了其在一致性和泛化能力方面的优势。

Conclusion: 该框架能够显式地区分图像身份并泛化到可变数量的输入，有效地解决了多图像编辑中的一致性和泛化性问题。

Abstract: Unified Multimodal Models (UMMs) integrate multimodal understanding and generation, yet they are limited to maintaining visual consistency and disambiguating visual cues when referencing details across multiple input images. In this work, we propose a scalable multi-image editing framework for UMMs that explicitly distinguishes image identities and generalizes to variable input counts. Algorithmically, we introduce two innovations: 1) The learnable latent separators explicitly differentiate each reference image in the latent space, enabling accurate and disentangled conditioning. 2) The sinusoidal index encoding assigns visual tokens from the same image a continuous sinusoidal index embedding, which provides explicit image identity while allowing generalization and extrapolation on a variable number of inputs. To facilitate training and evaluation, we establish a high-fidelity benchmark using an inverse dataset construction methodology to guarantee artifact-free, achievable outputs. Experiments show clear improvements in semantic consistency, visual fidelity, and cross-image integration over prior baselines on diverse multi-image editing tasks, validating our advantages on consistency and generalization ability.

</details>


### [59] [Orient Anything V2: Unifying Orientation and Rotation Understanding](https://arxiv.org/abs/2601.05573)
*Zehan Wang,Ziang Zhang,Jiayang Xu,Jialei Wang,Tianyu Pang,Chao Du,HengShuang Zhao,Zhou Zhao*

Main category: cs.CV

TL;DR: Orient Anything V2 是一个改进的通用基础模型，用于理解图像中物体的三维方向和旋转，通过生成模型合成数据、高效标注系统、考虑对称性的目标函数以及多帧架构来提升性能，并在多个基准测试中达到最先进的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理具有旋转对称性的物体以及估计相对旋转方面存在局限性，本研究旨在扩展和改进物体三维方向和旋转的统一理解能力。

Method: 1) 使用生成模型合成大规模、多样化的三维资产数据。2) 开发了一个高效的模型辅助标注系统来识别物体的多个有效“正面”。3) 引入了一个对称感知、周期性分布拟合的目标函数来处理旋转对称性。4) 设计了一个多帧架构直接预测相对旋转。

Result: Orient Anything V2 在方向估计、6DoF 位姿估计和物体对称性识别任务上，在 11 个基准测试中均取得了最先进的零样本性能，并展现出强大的泛化能力。

Conclusion: Orient Anything V2 显著提升了物体三维方向和旋转理解的准确性和鲁棒性，尤其是在处理具有旋转对称性的物体和预测相对旋转方面，极大地扩展了方向估计在下游任务中的应用范围。

Abstract: This work presents Orient Anything V2, an enhanced foundation model for unified understanding of object 3D orientation and rotation from single or paired images. Building upon Orient Anything V1, which defines orientation via a single unique front face, V2 extends this capability to handle objects with diverse rotational symmetries and directly estimate relative rotations. These improvements are enabled by four key innovations: 1) Scalable 3D assets synthesized by generative models, ensuring broad category coverage and balanced data distribution; 2) An efficient, model-in-the-loop annotation system that robustly identifies 0 to N valid front faces for each object; 3) A symmetry-aware, periodic distribution fitting objective that captures all plausible front-facing orientations, effectively modeling object rotational symmetry; 4) A multi-frame architecture that directly predicts relative object rotations. Extensive experiments show that Orient Anything V2 achieves state-of-the-art zero-shot performance on orientation estimation, 6DoF pose estimation, and object symmetry recognition across 11 widely used benchmarks. The model demonstrates strong generalization, significantly broadening the applicability of orientation estimation in diverse downstream tasks.

</details>


### [60] [Generalizable and Adaptive Continual Learning Framework for AI-generated Image Detection](https://arxiv.org/abs/2601.05580)
*Hanyi Wang,Jun Lan,Yaoyu Kang,Huijia Zhu,Weiqiang Wang,Zhuosheng Zhang,Shilin Wang*

Main category: cs.CV

TL;DR: 提出一个三阶段领域持续学习框架，用于检测不断演进的AI生成图像，能够有效应对新的生成模型，并在包含27种生成模型的基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: AI生成图像的恶意滥用和传播威胁在线信息的真实性，现有检测方法难以泛化到未见过的新生成模型，且生成技术快速发展，迫切需要具有适应性的检测模型。

Method: 构建一个三阶段领域持续学习框架：1. 参数高效微调（PEFT）构建具有泛化能力的离线检测模型；2. 结合数据增强链（复杂度递增）和Kronecker-Factored Approximate Curvature (K-FAC)方法来处理新数据流并缓解灾难性遗忘；3. 利用线性插值策略（基于线性模式连通性）捕捉模型共性并提升性能。

Result: 在包含27种生成模型（GANs、Deepfakes、Diffusion models）的基准测试中，初始离线检测器在mAP上比领先基线高出5.51%。持续学习策略平均准确率达到92.20%，优于最先进方法。

Conclusion: 提出的三阶段领域持续学习框架能够有效地持续适应新的AI生成模型，显著提高了对AI生成图像的检测性能和鲁棒性，解决了现有方法泛化能力不足的问题。

Abstract: The malicious misuse and widespread dissemination of AI-generated images pose a significant threat to the authenticity of online information. Current detection methods often struggle to generalize to unseen generative models, and the rapid evolution of generative techniques continuously exacerbates this challenge. Without adaptability, detection models risk becoming ineffective in real-world applications. To address this critical issue, we propose a novel three-stage domain continual learning framework designed for continuous adaptation to evolving generative models. In the first stage, we employ a strategic parameter-efficient fine-tuning approach to develop a transferable offline detection model with strong generalization capabilities. Building upon this foundation, the second stage integrates unseen data streams into a continual learning process. To efficiently learn from limited samples of novel generated models and mitigate overfitting, we design a data augmentation chain with progressively increasing complexity. Furthermore, we leverage the Kronecker-Factored Approximate Curvature (K-FAC) method to approximate the Hessian and alleviate catastrophic forgetting. Finally, the third stage utilizes a linear interpolation strategy based on Linear Mode Connectivity, effectively capturing commonalities across diverse generative models and further enhancing overall performance. We establish a comprehensive benchmark of 27 generative models, including GANs, deepfakes, and diffusion models, chronologically structured up to August 2024 to simulate real-world scenarios. Extensive experiments demonstrate that our initial offline detectors surpass the leading baseline by +5.51% in terms of mean average precision. Our continual learning strategy achieves an average accuracy of 92.20%, outperforming state-of-the-art methods.

</details>


### [61] [GS-DMSR: Dynamic Sensitive Multi-scale Manifold Enhancement for Accelerated High-Quality 3D Gaussian Splatting](https://arxiv.org/abs/2601.05584)
*Nengbo Lu,Minghua Pan,Shaohua Sun,Yizhou Liang*

Main category: cs.CV

TL;DR: 本文提出GS-DMSR方法，通过分析高斯属性的动态演变实现自适应梯度聚焦，并结合多尺度流形增强模块，提高了3D动态场景重建的收敛速度和渲染质量，同时降低了存储和训练成本。


<details>
  <summary>Details</summary>
Motivation: 解决3D动态场景重建中模型收敛速度与渲染质量难以平衡的挑战，尤其是在处理复杂动态运动场景时。

Method: 1. 分析高斯属性的动态演变过程，实现自适应梯度聚焦，动态识别高斯模型运动状态的显著差异。2. 对不同显著度的高斯模型应用差异化优化策略，提高模型收敛速度。3. 整合多尺度流形增强模块，利用隐式非线性解码器和显式形变场的协同优化，提升复杂形变场景的建模效率。

Result: 在合成数据集上实现了高达96 FPS的帧率，同时有效降低了存储开销和训练时间。

Conclusion: GS-DMSR方法在3D动态场景重建方面取得了显著进展，能在保证渲染质量的同时，显著提升收敛速度并减少资源消耗。

Abstract: In the field of 3D dynamic scene reconstruction, how to balance model convergence rate and rendering quality has long been a critical challenge that urgently needs to be addressed, particularly in high-precision modeling of scenes with complex dynamic motions. To tackle this issue, this study proposes the GS-DMSR method. By quantitatively analyzing the dynamic evolution process of Gaussian attributes, this mechanism achieves adaptive gradient focusing, enabling it to dynamically identify significant differences in the motion states of Gaussian models. It then applies differentiated optimization strategies to Gaussian models with varying degrees of significance, thereby significantly improving the model convergence rate. Additionally, this research integrates a multi-scale manifold enhancement module, which leverages the collaborative optimization of an implicit nonlinear decoder and an explicit deformation field to enhance the modeling efficiency for complex deformation scenes. Experimental results demonstrate that this method achieves a frame rate of up to 96 FPS on synthetic datasets, while effectively reducing both storage overhead and training time.Our code and data are available at https://anonymous.4open.science/r/GS-DMSR-2212.

</details>


### [62] [Quantifying and Inducing Shape Bias in CNNs via Max-Pool Dilation](https://arxiv.org/abs/2601.05599)
*Takito Sawada,Akinori Iwata,Masahiro Okuda*

Main category: cs.CV

TL;DR: 本文提出了一种量化数据集形状-纹理平衡的指标，并基于此开发了一种计算高效的形状偏置模型适配方法，通过修改最大池化操作的膨胀来提升形状主导型数据集上的分类准确率，尤其在低数据量情况下效果显著。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络（CNN）存在对局部纹理模式的偏好，这在纹理丰富的自然图像上表现良好，但在形状主导的数据集（如插画、素描）上性能下降。现有方法缺乏量化评估哪些数据集需要形状偏置模型以及如何有效适配的方案。

Method: 1. 提出一种数据驱动的指标，通过计算图像亮度通道与其L0平滑版本的结构相似性指数（SSIM）来量化数据集的形状-纹理平衡。 2. 基于该指标，提出一种计算高效的适配方法，通过修改最大池化操作的膨胀率来促进形状偏置，同时冻结卷积权重，仅训练最后的分类层。

Result: 该方法在形状主导型数据集上持续提高了分类准确率，特别是在低数据量场景下，相比完全微调更具优势。

Conclusion: 提出的量化指标和高效适配方法能够有效解决CNN在形状主导数据上的性能问题，为开发更鲁棒的视觉模型提供了新的思路和工具。

Abstract: Convolutional Neural Networks (CNNs) are known to exhibit a strong texture bias, favoring local patterns over global shape information--a tendency inherent to their convolutional architecture. While this bias is beneficial for texture-rich natural images, it often degrades performance on shape-dominant data such as illustrations and sketches. Although prior work has proposed shape-biased models to mitigate this issue, these approaches lack a quantitative metric for identifying which datasets would actually benefit from such modifications. To address this gap, we propose a data-driven metric that quantifies the shape-texture balance of a dataset by computing the Structural Similarity Index (SSIM) between each image's luminance channel and its L0-smoothed counterpart. Building on this metric, we further introduce a computationally efficient adaptation method that promotes shape bias by modifying the dilation of max-pooling operations while keeping convolutional weights frozen. Experimental results show that this approach consistently improves classification accuracy on shape-dominant datasets, particularly in low-data regimes where full fine-tuning is impractical, requiring training only the final classification layer.

</details>


### [63] [SceneAlign: Aligning Multimodal Reasoning to Scene Graphs in Complex Visual Scenes](https://arxiv.org/abs/2601.05600)
*Chuhan Wang,Xintong Li,Jennifer Yuntong Zhang,Junda Wu,Chengkai Huang,Lina Yao,Julian McAuley,Jingbo Shang*

Main category: cs.CV

TL;DR: 提出SceneAlign框架，利用场景图进行结构化干预，生成有区分度的负面论证，以提高多模态大语言模型在视觉推理中的准确性和忠实度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于偏好的方法在处理复杂视觉场景时，多模态大语言模型常出现推理不忠实的问题（如幻觉实体、关系错误定位、跳步、过度指定等），因为它们依赖文本信息，允许模型绕过视觉基础。因此需要一种能够解决视觉基础不足的新方法。

Method: 提出SceneAlign框架，利用场景图作为结构化视觉信息，通过四种模仿常见基础失败的策略，对推理关键节点进行可控的结构干预，生成在语言上合理但视觉基础不准确的负面论证。然后将这些对比对用于直接偏好优化（DPO），引导模型进行细粒度的、结构忠实的推理。

Result: 在七个视觉推理基准测试中，SceneAlign一致性地提高了答案准确性和推理忠实度。

Conclusion: 基于场景图的、有基础感知的对齐方法对于多模态推理是有效的，能够显著改善模型的推理准确性和忠实度。

Abstract: Multimodal large language models often struggle with faithful reasoning in complex visual scenes, where intricate entities and relations require precise visual grounding at each step. This reasoning unfaithfulness frequently manifests as hallucinated entities, mis-grounded relations, skipped steps, and over-specified reasoning. Existing preference-based approaches, typically relying on textual perturbations or answer-conditioned rationales, fail to address this challenge as they allow models to exploit language priors to bypass visual grounding. To address this, we propose SceneAlign, a framework that leverages scene graphs as structured visual information to perform controllable structural interventions. By identifying reasoning-critical nodes and perturbing them through four targeted strategies that mimic typical grounding failures, SceneAlign constructs hard negative rationales that remain linguistically plausible but are grounded in inaccurate visual facts. These contrastive pairs are used in Direct Preference Optimization to steer models toward fine-grained, structure-faithful reasoning. Across seven visual reasoning benchmarks, SceneAlign consistently improves answer accuracy and reasoning faithfulness, highlighting the effectiveness of grounding-aware alignment for multimodal reasoning.

</details>


### [64] [Learning Geometric Invariance for Gait Recognition](https://arxiv.org/abs/2601.05604)
*Zengbin Wang,Junjie Li,Saihui Hou,Xu Liu,Chunshui Cao,Yongzhen Huang,Muyi Sun,Siye Wang,Man Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 RRS-Gait 的新方法，通过将不同步态条件下的变化视为几何变换（反射、旋转、缩放），并设计相应的学习框架来学习几何不变性，从而实现身份识别。


<details>
  <summary>Details</summary>
Motivation: 现有步态识别模型通常隐式学习不同步态条件下的共同特征，但很少有研究明确探索不同步态条件之间的内在联系。作者希望通过显式地建立这种联系，并借鉴几何变换的思想来改进步态识别。

Method: 该方法将不同步态条件下的变化视为几何变换（反射、旋转、缩放）。首先，根据特定的几何变换灵活调整卷积核，以实现特征的近似等变性。然后，将三种等变感知特征分别通过全局池化操作，实现最终的不变性学习。

Result: 在 Gait3D、GREW、CCPG 和 SUSTech1K 四个流行步态数据集上进行了广泛实验，结果表明 RRS-Gait 在各种步态条件下均取得了优于现有方法的性能。

Conclusion: 本文提出的 RRS-Gait 方法，通过将步态变化建模为几何变换并学习相应的几何不变性，为步态识别提供了一种新的视角，并取得了显著的识别效果。

Abstract: The goal of gait recognition is to extract identity-invariant features of an individual under various gait conditions, e.g., cross-view and cross-clothing. Most gait models strive to implicitly learn the common traits across different gait conditions in a data-driven manner to pull different gait conditions closer for recognition. However, relatively few studies have explicitly explored the inherent relations between different gait conditions. For this purpose, we attempt to establish connections among different gait conditions and propose a new perspective to achieve gait recognition: variations in different gait conditions can be approximately viewed as a combination of geometric transformations. In this case, all we need is to determine the types of geometric transformations and achieve geometric invariance, then identity invariance naturally follows. As an initial attempt, we explore three common geometric transformations (i.e., Reflect, Rotate, and Scale) and design a $\mathcal{R}$eflect-$\mathcal{R}$otate-$\mathcal{S}$cale invariance learning framework, named ${\mathcal{RRS}}$-Gait. Specifically, it first flexibly adjusts the convolution kernel based on the specific geometric transformations to achieve approximate feature equivariance. Then these three equivariant-aware features are respectively fed into a global pooling operation for final invariance-aware learning. Extensive experiments on four popular gait datasets (Gait3D, GREW, CCPG, SUSTech1K) show superior performance across various gait conditions.

</details>


### [65] [LatentVLA: Efficient Vision-Language Models for Autonomous Driving via Latent Action Prediction](https://arxiv.org/abs/2601.05611)
*Chengen Xie,Bin Sun,Tianyu Li,Junjie Wu,Zhihui Hao,XianPeng Lang,Hongyang Li*

Main category: cs.CV

TL;DR: LatentVLA 是一个新框架，它使用无监督学习的潜在动作预测来训练 VLA 模型，无需语言标注，从而克服了当前 VLA 模型在数值精度、语言偏见和计算效率方面的挑战，并在 NAVSIM 和 nuScenes 基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶模型在罕见场景下表现不佳，而现有的 VLA 模型虽然利用了广泛的知识，但存在数值不精确、依赖语言标注导致偏见和标注负担以及计算效率低下等问题。

Method: LatentVLA 提出了一种无监督学习方法，通过自监督潜在动作预测来训练 VLA 模型，无需语言标注。然后，利用知识蒸馏将 VLA 模型的能力迁移到高效的基于视觉的网络中，实现了鲁棒性和实时性。

Result: LatentVLA 在 NAVSIM 基准测试上取得了 92.4 的 PDMS 分数，创造了新的最先进记录，并在 nuScenes 基准测试上展现了强大的零样本泛化能力。

Conclusion: LatentVLA 框架通过消除对语言标注的依赖，提高了 VLA 模型在罕见场景下的泛化能力和计算效率，为开发更鲁棒和实时的自动驾驶系统提供了一种新的途径。

Abstract: End-to-end autonomous driving models trained on largescale datasets perform well in common scenarios but struggle with rare, long-tail situations due to limited scenario diversity. Recent Vision-Language-Action (VLA) models leverage broad knowledge from pre-trained visionlanguage models to address this limitation, yet face critical challenges: (1) numerical imprecision in trajectory prediction due to discrete tokenization, (2) heavy reliance on language annotations that introduce linguistic bias and annotation burden, and (3) computational inefficiency from multi-step chain-of-thought reasoning hinders real-time deployment. We propose LatentVLA, a novel framework that employs self-supervised latent action prediction to train VLA models without language annotations, eliminating linguistic bias while learning rich driving representations from unlabeled trajectory data. Through knowledge distillation, LatentVLA transfers the generalization capabilities of VLA models to efficient vision-based networks, achieving both robust performance and real-time efficiency. LatentVLA establishes a new state-of-the-art on the NAVSIM benchmark with a PDMS score of 92.4 and demonstrates strong zeroshot generalization on the nuScenes benchmark.

</details>


### [66] [Adaptive Disentangled Representation Learning for Incomplete Multi-View Multi-Label Classification](https://arxiv.org/abs/2601.05785)
*Quanjiang Li,Zhiming Liu,Tianxiang Xu,Tingjin Luo,Chenping Hou*

Main category: cs.CV

TL;DR: 提出了一种自适应解耦表示学习方法（ADRL），用于解决多视图多标签学习中的特征缺失和标注不完整问题，通过特征和类别关联传播、随机掩码策略、互信息优化以及原型特定特征选择等方法，提升了模型的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 多视图多标签学习在数据获取和标注成本方面存在特征缺失和标注不完整的问题，现有方法在特征恢复、表示解耦和标签语义建模方面存在局限性。

Method: 提出ADRL方法，包括：1. 通过传播跨模态的特征级亲和力实现视图补全；2. 利用随机掩码策略增强重建效果；3. 通过传播类别级关联来细化标签分布参数，捕捉标签原型之间的依赖关系；4. 引入基于互信息的优化目标，促进共享表示的一致性并抑制视图特定表示与其他模态的信息重叠；5. 推导双通道网络的训练界限；6. 实现原型特定的特征选择；7. 生成伪标签并利用其结构特征指导视图融合。

Result: ADRL在公共数据集和实际应用中表现出优越的性能。

Conclusion: ADRL有效地解决了多视图多标签学习中的挑战，通过多种技术手段提升了模型的表示学习能力和泛化性能。

Abstract: Multi-view multi-label learning frequently suffers from simultaneous feature absence and incomplete annotations, due to challenges in data acquisition and cost-intensive supervision. To tackle the complex yet highly practical problem while overcoming the existing limitations of feature recovery, representation disentanglement, and label semantics modeling, we propose an Adaptive Disentangled Representation Learning method (ADRL). ADRL achieves robust view completion by propagating feature-level affinity across modalities with neighborhood awareness, and reinforces reconstruction effectiveness by leveraging a stochastic masking strategy. Through disseminating category-level association across label distributions, ADRL refines distribution parameters for capturing interdependent label prototypes. Besides, we formulate a mutual-information-based objective to promote consistency among shared representations and suppress information overlap between view-specific representation and other modalities. Theoretically, we derive the tractable bounds to train the dual-channel network. Moreover, ADRL performs prototype-specific feature selection by enabling independent interactions between label embeddings and view representations, accompanied by the generation of pseudo-labels for each category. The structural characteristics of the pseudo-label space are then exploited to guide a discriminative trade-off during view fusion. Finally, extensive experiments on public datasets and real-world applications demonstrate the superior performance of ADRL.

</details>


### [67] [Compressing image encoders via latent distillation](https://arxiv.org/abs/2601.05639)
*Caroline Mazini Rodrigues,Nicolas Keriven,Thomas Maugey*

Main category: cs.CV

TL;DR: 提出一种基于知识蒸馏的方法，通过压缩深度学习图像压缩模型的编码器，使其在硬件受限的应用中更具实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习图像压缩模型通常复杂、计算量大，难以在硬件受限的环境中应用。

Method: 使用简化的知识蒸馏策略，通过训练轻量级编码器来近似原始模型的潜在空间，从而减少对数据和计算资源的需求。

Result: 在图像压缩任务上，相比于使用原始损失函数训练的轻量级编码器，所提出的方法能够更好地保持重建质量和统计保真度。

Conclusion: 该方法能够生成实用的轻量级图像压缩模型，适用于资源受限的环境，同时保持高质量的重建效果。

Abstract: Deep learning models for image compression often face practical limitations in hardware-constrained applications. Although these models achieve high-quality reconstructions, they are typically complex, heavyweight, and require substantial training data and computational resources. We propose a methodology to partially compress these networks by reducing the size of their encoders. Our approach uses a simplified knowledge distillation strategy to approximate the latent space of the original models with less data and shorter training, yielding lightweight encoders from heavyweight ones. We evaluate the resulting lightweight encoders across two different architectures on the image compression task. Experiments show that our method preserves reconstruction quality and statistical fidelity better than training lightweight encoders with the original loss, making it practical for resource-limited environments.

</details>


### [68] [SGDrive: Scene-to-Goal Hierarchical World Cognition for Autonomous Driving](https://arxiv.org/abs/2601.05640)
*Jingyu Li,Junjie Wu,Dongnan Hu,Xiangkai Huang,Bin Sun,Zhihui Hao,Xianpeng Lang,Xiatian Zhu,Li Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为SGDrive的新框架，通过将自动驾驶的理解分解为场景-主体-目标分层结构，来增强通用视觉语言模型（VLMs）在自动驾驶中的规划能力，从而解决了通用VLMs在处理三维时空驾驶推理方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基于VLM的自动驾驶方法，由于VLM是通用模型，缺乏对驾驶特定三维时空推理的专业理解，难以建立捕捉几何关系、场景上下文和运动模式的结构化时空表征，而这些对于安全轨迹规划至关重要。

Method: SGDrive框架建立在预训练VLM骨干之上，将驾驶理解分解为反映人类驾驶认知的“场景-主体-目标”分层结构。该结构首先关注环境（场景上下文），然后关注安全关键主体及其行为，最后制定短期目标以指导行动。

Result: 在NAVSIM基准上的广泛实验表明，SGDrive在仅使用摄像头的PDMS和EPDMS任务上均取得了最先进的性能。

Conclusion: 通过将通用VLMs的表征学习显式地围绕驾驶特定知识层级进行结构化，SGDrive能够有效地适应自动驾驶任务，并显著提升轨迹规划的性能。

Abstract: Recent end-to-end autonomous driving approaches have leveraged Vision-Language Models (VLMs) to enhance planning capabilities in complex driving scenarios. However, VLMs are inherently trained as generalist models, lacking specialized understanding of driving-specific reasoning in 3D space and time. When applied to autonomous driving, these models struggle to establish structured spatial-temporal representations that capture geometric relationships, scene context, and motion patterns critical for safe trajectory planning. To address these limitations, we propose SGDrive, a novel framework that explicitly structures the VLM's representation learning around driving-specific knowledge hierarchies. Built upon a pre-trained VLM backbone, SGDrive decomposes driving understanding into a scene-agent-goal hierarchy that mirrors human driving cognition: drivers first perceive the overall environment (scene context), then attend to safety-critical agents and their behaviors, and finally formulate short-term goals before executing actions. This hierarchical decomposition provides the structured spatial-temporal representation that generalist VLMs lack, integrating multi-level information into a compact yet comprehensive format for trajectory planning. Extensive experiments on the NAVSIM benchmark demonstrate that SGDrive achieves state-of-the-art performance among camera-only methods on both PDMS and EPDMS, validating the effectiveness of hierarchical knowledge structuring for adapting generalist VLMs to autonomous driving.

</details>


### [69] [SketchVL: Policy Optimization via Fine-Grained Credit Assignment for Chart Understanding and More](https://arxiv.org/abs/2601.05688)
*Muye Huang,Lingling Zhang,Yifei Li,Yaqiang Wu,Jun Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为SketchVL的新型多模态大语言模型，通过FinePO算法优化，解决了传统RL训练方法中奖励分配困难的问题，从而提升了模型在图表理解等复杂推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在处理图表等需要精细视觉推理的任务时面临挑战，尤其是基于强化学习（RL）训练的模型，其奖励分配机制难以区分推理过程中正确和错误的步骤。

Method: SketchVL模型通过在图像上绘制中间推理步骤（“草图”）并将其作为输入反馈给模型本身，形成多步推理过程。其训练算法FinePO利用Fine-grained Process Reward Model (FinePRM) 对轨迹中的每个绘图动作进行评分，实现细粒度的奖励分配，即在全局成功的轨迹中强化正确步骤，在全局次优的轨迹中惩罚错误步骤。

Result: 实验证明，SketchVL能够使其每一步的行为与FinePRM对齐，在图表、自然图像和数学数据集上的平均性能比基线模型提高了7.23%。

Conclusion: SketchVL通过引入细粒度的奖励分配机制，有效解决了多模态大语言模型在复杂推理任务中的挑战，为训练更强大的推理模型提供了一个有前景的新方向。

Abstract: Charts are high-density visual carriers of complex data and medium for information extraction and analysis. Due to the need for precise and complex visual reasoning, automated chart understanding poses a significant challenge to existing Multimodal Large Language Models (MLLMs). Many MLLMs trained with reinforcement learning (RL) face the challenge of credit assignment. Their advantage estimation, typically performed at the trajectory level, cannot distinguish between correct and incorrect reasoning steps within a single generated response. To address this limitation, we introduce SketchVL, a novel MLLM that optimized with FinePO, a new RL algorithm designed for fine-grained credit assignment within each trajectory. SketchVL's methodology involves drawing its intermediate reasoning steps as markers on the image and feeding the annotated image back to itself, creating a robust, multi-step reasoning process. During training, the FinePO algorithm leverages a Fine-grained Process Reward Model (FinePRM) to score each drawing action within a trajectory, thereby precisely assigning credit for each step. This mechanism allows FinePO to more strongly reward correct tokens when a trajectory is globally successful, and more heavily penalize incorrect tokens when the trajectory is globally suboptimal, thus achieving fine-grained reinforcement signals. Experiments show that SketchVL learns to align its step-level behavior with the FinePRM, achieving an average performance gain of 7.23\% over its base model across chart datasets, natural image datasets, and mathematics, providing a promising new direction for training powerful reasoning models.

</details>


### [70] [LayerGS: Decomposition and Inpainting of Layered 3D Human Avatars via 2D Gaussian Splatting](https://arxiv.org/abs/2601.05853)
*Yinghan Xu,John Dingliana*

Main category: cs.CV

TL;DR: 提出了一种新颖的框架，用于将任意姿势的人分解为可动画化的多层 3D 人体化身，将身体和服装分开。该方法使用 2D 高斯来表示几何形状和渲染，并利用预训练的 2D 扩散模型通过 SDS 修复隐藏区域。实验表明，该方法在渲染质量和层分解/重构方面优于现有技术，可实现逼真的虚拟试穿和高保真 3D 人体资产创建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在服装与身份锁定、遮挡区域处理方面存在局限性。本研究旨在克服这些局限性，实现更精确的 3D 人体化身分解和高质量渲染。

Method: 该框架采用三阶段训练策略：1. 单层重建粗糙的规范服装。2. 多层训练，联合恢复内层身体和外层服装细节。使用 2D 高斯表示几何和渲染，并利用预训练的 2D 扩散模型通过 SDS 修复隐藏区域。

Result: 在 4D-Dress 和 Thuman2.0 数据集上的实验表明，该方法在渲染质量、层分解和重构方面均优于现有最先进方法，能够实现新视角和姿势下的逼真虚拟试穿，并提高高保真 3D 人体资产的创建。

Conclusion: 提出的新颖框架成功地将任意姿势的人分解为可动画化的多层 3D 人体化身，解决了现有方法的局限性，并在虚拟试穿和 3D 人体资产创建方面取得了显著进展。

Abstract: We propose a novel framework for decomposing arbitrarily posed humans into animatable multi-layered 3D human avatars, separating the body and garments. Conventional single-layer reconstruction methods lock clothing to one identity, while prior multi-layer approaches struggle with occluded regions. We overcome both limitations by encoding each layer as a set of 2D Gaussians for accurate geometry and photorealistic rendering, and inpainting hidden regions with a pretrained 2D diffusion model via score-distillation sampling (SDS). Our three-stage training strategy first reconstructs the coarse canonical garment via single-layer reconstruction, followed by multi-layer training to jointly recover the inner-layer body and outer-layer garment details. Experiments on two 3D human benchmark datasets (4D-Dress, Thuman2.0) show that our approach achieves better rendering quality and layer decomposition and recomposition than the previous state-of-the-art, enabling realistic virtual try-on under novel viewpoints and poses, and advancing practical creation of high-fidelity 3D human assets for immersive applications. Our code is available at https://github.com/RockyXu66/LayerGS

</details>


### [71] [Rotate Your Character: Revisiting Video Diffusion Models for High-Quality 3D Character Generation](https://arxiv.org/abs/2601.05722)
*Jin Wang,Jianxiang Lu,Comi Chen,Guangzheng Xu,Haoyu Yang,Peng Chen,Na Zhang,Yifan Xu,Longhuang Wu,Shuai Shao,Qinglin Lu,Ping Luo*

Main category: cs.CV

TL;DR: RCM是一个先进的图像到视频扩散框架，用于生成高质量的3D角色和新视角合成，能处理复杂姿势，支持高分辨率、可控视角和多视图输入。


<details>
  <summary>Details</summary>
Motivation: 从单张图像生成高质量3D角色，尤其是在处理复杂姿势和自遮挡方面，仍然是一个挑战。

Method: 提出RCM（Rotate your Character Model），一个图像到视频扩散框架，通过将角色姿势规范化，实现一致的新视角合成，并支持高分辨率（1024x1024）、可控的观察位置以及最多4张输入图像的多视图条件。

Result: RCM在3D角色生成和新视角合成的质量上优于现有的最先进方法。

Conclusion: RCM是一个有效的框架，能够生成高质量的3D角色和新视角合成，并克服了复杂姿势和自遮挡的挑战。

Abstract: Generating high-quality 3D characters from single images remains a significant challenge in digital content creation, particularly due to complex body poses and self-occlusion. In this paper, we present RCM (Rotate your Character Model), an advanced image-to-video diffusion framework tailored for high-quality novel view synthesis (NVS) and 3D character generation. Compared to existing diffusion-based approaches, RCM offers several key advantages: (1) transferring characters with any complex poses into a canonical pose, enabling consistent novel view synthesis across the entire viewing orbit, (2) high-resolution orbital video generation at 1024x1024 resolution, (3) controllable observation positions given different initial camera poses, and (4) multi-view conditioning supporting up to 4 input images, accommodating diverse user scenarios. Extensive experiments demonstrate that RCM outperforms state-of-the-art methods in both novel view synthesis and 3D generation quality.

</details>


### [72] [TAGRPO: Boosting GRPO on Image-to-Video Generation with Direct Trajectory Alignment](https://arxiv.org/abs/2601.05729)
*Jin Wang,Jianxiang Lu,Guangzheng Xu,Comi Chen,Haoyu Yang,Linqing Wang,Peng Chen,Mingtao Chen,Zhichao Hu,Longhuang Wu,Shuai Shao,Qinglin Lu,Ping Luo*

Main category: cs.CV

TL;DR: TAGRPO是一个用于图像到视频生成模型（I2V）的后训练框架，通过对比学习和改进的GRPO损失，解决了直接应用GRPO到I2V模型效果不佳的问题，并显著提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 直接将现有的GRPO技术应用于图像到视频（I2V）生成模型时，发现其奖励提升并不一致，效果不佳。

Method: 提出TAGRPO框架，借鉴对比学习，利用来自相同初始噪声生成的滚动视频提供更好的优化指导。通过在中间潜在表示上应用一种新的GRPO损失，鼓励模型向高奖励轨迹对齐，并远离低奖励轨迹。此外，引入一个内存库来增强视频生成的多样性并降低计算开销。

Result: TAGRPO在图像到视频生成任务上取得了显著的性能提升，优于DanceGRPO。

Conclusion: TAGRPO是一个简单但有效的后训练框架，能够显著提升I2V模型的生成质量，为GRPO在多模态生成领域的应用提供了新的思路。

Abstract: Recent studies have demonstrated the efficacy of integrating Group Relative Policy Optimization (GRPO) into flow matching models, particularly for text-to-image and text-to-video generation. However, we find that directly applying these techniques to image-to-video (I2V) models often fails to yield consistent reward improvements. To address this limitation, we present TAGRPO, a robust post-training framework for I2V models inspired by contrastive learning. Our approach is grounded in the observation that rollout videos generated from identical initial noise provide superior guidance for optimization. Leveraging this insight, we propose a novel GRPO loss applied to intermediate latents, encouraging direct alignment with high-reward trajectories while maximizing distance from low-reward counterparts. Furthermore, we introduce a memory bank for rollout videos to enhance diversity and reduce computational overhead. Despite its simplicity, TAGRPO achieves significant improvements over DanceGRPO in I2V generation.

</details>


### [73] [FeatureSLAM: Feature-enriched 3D gaussian splatting SLAM in real time](https://arxiv.org/abs/2601.05738)
*Christopher Thirgood,Oscar Mendez,Erin Ling,Jon Storey,Simon Hadfield*

Main category: cs.CV

TL;DR: 提出了一种结合3D高斯泼溅（3DGS）的实时跟踪SLAM系统，利用视觉基础模型增强了语义信息，提高了跟踪和建图的精度，并支持开放集分割等新下游任务。


<details>
  <summary>Details</summary>
Motivation: 现有SLAM系统在语义理解和下游应用方面存在局限，作者希望通过引入视觉基础模型和3DGS技术，提升SLAM系统的语义能力，并解锁新的应用场景。

Method: 该系统通过将密集特征光栅化集成到3DGS的视图合成中，并结合视觉基础模型，实现了高效的相机跟踪和富有照片般真实感的特征增强地图构建。该方法超越了传统的RGB-D输入，利用了强大的语义信息。

Result: 该系统实现了实时跟踪，其性能与最先进的系统相当，同时提高了跟踪稳定性和地图保真度。与现有的固定集SLAM基线相比，姿态误差降低了9%，地图精度提高了8%。此外，在语义和语言掩蔽方面也达到了与离线3DGS模型相当的性能。

Conclusion: 实时特征增强SLAM不仅能够支持新的下游应用，还能显著提升SLAM系统本身的跟踪和建图性能。通过融合3DGS和视觉基础模型，可以实现高效、高精度的语义SLAM。

Abstract: We present a real-time tracking SLAM system that unifies efficient camera tracking with photorealistic feature-enriched mapping using 3D Gaussian Splatting (3DGS). Our main contribution is integrating dense feature rasterization into the novel-view synthesis, aligned with a visual foundation model. This yields strong semantics, going beyond basic RGB-D input, aiding both tracking and mapping accuracy. Unlike previous semantic SLAM approaches (which embed pre-defined class labels) FeatureSLAM enables entirely new downstream tasks via free-viewpoint, open-set segmentation. Across standard benchmarks, our method achieves real-time tracking, on par with state-of-the-art systems while improving tracking stability and map fidelity without prohibitive compute. Quantitatively, we obtain 9\% lower pose error and 8\% higher mapping accuracy compared to recent fixed-set SLAM baselines. Our results confirm that real-time feature-embedded SLAM, is not only valuable for enabling new downstream applications. It also improves the performance of the underlying tracking and mapping subsystems, providing semantic and language masking results that are on-par with offline 3DGS models, alongside state-of-the-art tracking, depth and RGB rendering.

</details>


### [74] [Boosting Latent Diffusion Models via Disentangled Representation Alignment](https://arxiv.org/abs/2601.05823)
*John Page,Xuesong Niu,Kai Wu,Kun Gai*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Send-VAE 的新型变分自编码器，旨在实现解耦的潜在表征，以改进图像生成。通过将 VAE 的潜在空间与预训练的视觉基础模型（VFM）的语义层次结构对齐，Send-VAE 能够更好地捕捉属性级信息，从而提升生成质量和训练效率。在 ImageNet 上的实验结果表明，使用 Send-VAE 训练的流模型 SiTs 达到了最先进的生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用相同的目标来训练 VAE 和 LDM，但 VAE 和 LDM 对潜在表征的需求不同。LDM 需要保留高层语义概念的潜在表示，而 VAE 则需要解耦的属性级信息。现有的 VAE 在这方面存在不足。

Method: 提出 Send-VAE，通过非线性映射网络将 VAE 的潜在空间与预训练 VFM 的语义层次结构对齐。这种映射网络旨在弥合属性级解耦和高层语义之间的差距，从而指导 VAE 学习解耦的表征。通过线性探测在属性预测任务上评估语义解耦能力，并与生成性能相关联。

Result: Send-VAE 在语义解耦方面表现出色，与生成性能高度相关。使用 Send-VAE 训练的流模型 SiTs 在 ImageNet 256x256 上取得了最先进的 FID 分数（1.21 和 1.75，分别有无 classifier-free guidance）。Send-VAE 显著加速了训练过程。

Conclusion: Send-VAE 是一种有效的 VAE，通过显式优化解耦的潜在表征，能够提升图像生成质量并加速训练。其核心在于将 VAE 的潜在空间与 VFM 的语义层次结构对齐，实现属性级信息的结构化编码。

Abstract: Latent Diffusion Models (LDMs) generate high-quality images by operating in a compressed latent space, typically obtained through image tokenizers such as Variational Autoencoders (VAEs). In pursuit of a generation-friendly VAE, recent studies have explored leveraging Vision Foundation Models (VFMs) as representation alignment targets for VAEs, mirroring the approach commonly adopted for LDMs. Although this yields certain performance gains, using the same alignment target for both VAEs and LDMs overlooks their fundamentally different representational requirements. We advocate that while LDMs benefit from latents retaining high-level semantic concepts, VAEs should excel in semantic disentanglement, enabling encoding of attribute-level information in a structured way. To address this, we propose the Semantic disentangled VAE (Send-VAE), explicitly optimized for disentangled representation learning through aligning its latent space with the semantic hierarchy of pre-trained VFMs. Our approach employs a non-linear mapper network to transform VAE latents, aligning them with VFMs to bridge the gap between attribute-level disentanglement and high-level semantics, facilitating effective guidance for VAE learning. We evaluate semantic disentanglement via linear probing on attribute prediction tasks, showing strong correlation with improved generation performance. Finally, using Send-VAE, we train flow-based transformers SiTs; experiments show Send-VAE significantly speeds up training and achieves a state-of-the-art FID of 1.21 and 1.75 with and without classifier-free guidance on ImageNet 256x256.

</details>


### [75] [GeoSurDepth: Spatial Geometry-Consistent Self-Supervised Depth Estimation for Surround-View Cameras](https://arxiv.org/abs/2601.05839)
*Weimin Liu,Wenjun Wang,Joshua H. Meng*

Main category: cs.CV

TL;DR: 本文提出了一种名为GeoSurDepth的框架，用于精确估算环绕视图深度。该框架利用几何一致性作为主要线索，通过引入基础模型作为伪几何先验和特征增强工具，实现表面法线一致性和物体/纹理一致性的深度估计。同时，它还设计了一个新颖的视图合成管道，通过密集深度重构和空间变换来实现2D-3D提升，并引入了自适应联合运动学习策略来增强运动推理能力。实验证明GeoSurDepth在DDAD和nuScenes数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要侧重于光度层面强制跨视图约束，但很少利用单目和环绕视图设置中固有的丰富几何结构。作者希望通过引入几何一致性来弥补这一不足，以实现更鲁棒的环绕视图深度估计。

Method: 1. 利用基础模型作为伪几何先验和特征表示增强工具，指导网络保持空间3D表面的法线一致性，并规范化2D中的物体和纹理一致性深度估计。2. 引入新颖的视图合成流水线，通过密集深度重建和空间变换实现2D-3D提升，以在时间、空间和时空背景下提供额外的光度监督，弥补单视图图像重建的局限性。3. 提出一种自适应联合运动学习策略，使网络能够自适应地强调信息丰富的空间几何线索，以改进运动推理。

Result: GeoSurDepth在DDAD和nuScenes数据集上取得了最先进的性能，验证了所提方法的有效性。

Conclusion: 该框架强调了利用几何相干性和一致性对于鲁棒的自监督多视图深度估计的重要性。

Abstract: Accurate surround-view depth estimation provides a competitive alternative to laser-based sensors and is essential for 3D scene understanding in autonomous driving. While prior studies have proposed various approaches that primarily focus on enforcing cross-view constraints at the photometric level, few explicitly exploit the rich geometric structure inherent in both monocular and surround-view setting. In this work, we propose GeoSurDepth, a framework that leverages geometry consistency as the primary cue for surround-view depth estimation. Concretely, we utilize foundation models as a pseudo geometry prior and feature representation enhancement tool to guide the network to maintain surface normal consistency in spatial 3D space and regularize object- and texture-consistent depth estimation in 2D. In addition, we introduce a novel view synthesis pipeline where 2D-3D lifting is achieved with dense depth reconstructed via spatial warping, encouraging additional photometric supervision across temporal, spatial, and spatial-temporal contexts, and compensating for the limitations of single-view image reconstruction. Finally, a newly-proposed adaptive joint motion learning strategy enables the network to adaptively emphasize informative spatial geometry cues for improved motion reasoning. Extensive experiments on DDAD and nuScenes demonstrate that GeoSurDepth achieves state-of-the-art performance, validating the effectiveness of our approach. Our framework highlights the importance of exploiting geometry coherence and consistency for robust self-supervised multi-view depth estimation.

</details>


### [76] [Performance of a Deep Learning-Based Segmentation Model for Pancreatic Tumors on Public Endoscopic Ultrasound Datasets](https://arxiv.org/abs/2601.05937)
*Pankaj Gupta,Priya Mudgil,Niharika Dutta,Kartik Bose,Nitish Kumar,Anupam Kumar,Jimil Shah,Vaneet Jearth,Jayanta Samanta,Vishal Sharma,Harshal Mandavdhare,Surinder Rana,Saroj K Sinha,Usha Dutta*

Main category: cs.CV

TL;DR: 这项研究评估了一个基于Vision Transformer的深度学习模型在内窥镜超声（EUS）图像中分割胰腺肿瘤的有效性，在外部验证集上取得了令人鼓舞的结果，但仍需进一步完善和验证。


<details>
  <summary>Details</summary>
Motivation: 内窥镜超声（EUS）是诊断胰腺癌的重要手段，但其有效性受操作者主观性限制。因此，需要开发更客观、更准确的工具来辅助EUS图像分析。

Method: 研究者们使用了一个基于Vision Transformer骨干的USFM框架深度学习分割模型，并在17,367张EUS图像上进行了训练和验证（5折交叉验证），然后在另一个包含350张EUS图像的独立数据集上进行了外部验证。模型在训练前进行了灰度转换、裁剪和调整大小等预处理。

Result: 在5折交叉验证中，模型取得了平均Dice相似系数（DSC）0.651，IoU 0.579，敏感度69.8%，特异度98.8%。在外部验证集上，模型取得了DSC 0.657，IoU 0.614，敏感度71.8%，特异度97.7%。然而，有9.7%的病例出现了错误的多次预测。

Conclusion: 基于Vision Transformer的模型在EUS图像的胰腺肿瘤分割方面表现出强大的性能。尽管如此，数据集的异质性和有限的外部验证表明，该模型仍需进一步的精炼、标准化和前瞻性研究来提高其鲁棒性和临床应用价值。

Abstract: Background: Pancreatic cancer is one of the most aggressive cancers, with poor survival rates. Endoscopic ultrasound (EUS) is a key diagnostic modality, but its effectiveness is constrained by operator subjectivity. This study evaluates a Vision Transformer-based deep learning segmentation model for pancreatic tumors. Methods: A segmentation model using the USFM framework with a Vision Transformer backbone was trained and validated with 17,367 EUS images (from two public datasets) in 5-fold cross-validation. The model was tested on an independent dataset of 350 EUS images from another public dataset, manually segmented by radiologists. Preprocessing included grayscale conversion, cropping, and resizing to 512x512 pixels. Metrics included Dice similarity coefficient (DSC), intersection over union (IoU), sensitivity, specificity, and accuracy. Results: In 5-fold cross-validation, the model achieved a mean DSC of 0.651 +/- 0.738, IoU of 0.579 +/- 0.658, sensitivity of 69.8%, specificity of 98.8%, and accuracy of 97.5%. For the external validation set, the model achieved a DSC of 0.657 (95% CI: 0.634-0.769), IoU of 0.614 (95% CI: 0.590-0.689), sensitivity of 71.8%, and specificity of 97.7%. Results were consistent, but 9.7% of cases exhibited erroneous multiple predictions. Conclusions: The Vision Transformer-based model demonstrated strong performance for pancreatic tumor segmentation in EUS images. However, dataset heterogeneity and limited external validation highlight the need for further refinement, standardization, and prospective studies.

</details>


### [77] [VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction](https://arxiv.org/abs/2601.05966)
*Longbin Ji,Xiaoxiong Liu,Junyuan Shang,Shuohuan Wang,Yu Sun,Hua Wu,Haifeng Wang*

Main category: cs.CV

TL;DR: 本文提出了 VideoAR，一个首个大规模视频生成视觉自回归框架，通过多尺度预测和自回归建模结合，实现了高效且时间一致的视频生成，性能优于现有自回归模型，并可与大型扩散模型媲美。


<details>
  <summary>Details</summary>
Motivation: 现有高质量视频生成模型（如扩散模型和流匹配模型）计算成本高昂且难以扩展。作者希望开发一种更具可扩展性和效率的视频生成方法。

Method: VideoAR 结合了多尺度帧预测和自回归建模，通过 3D 多尺度分词器分离空间和时间依赖性。为提高长期一致性，引入了多尺度时间 RoPE、跨帧纠错和随机帧掩码。采用多阶段预训练管线，并通过渐进式对齐空间和时间学习。

Result: VideoAR 在 UCF-101 上将 FVD 从 99.5 提高到 88.6，并将推理步数减少了 10 倍以上。在 VBench 上得分 81.74，与规模大一个数量级的扩散模型相当。

Conclusion: VideoAR 成功缩小了自回归模型和扩散模型在视频生成性能上的差距，为未来的视频生成研究提供了一个可扩展、高效且时间一致的基础。

Abstract: Recent advances in video generation have been dominated by diffusion and flow-matching models, which produce high-quality results but remain computationally intensive and difficult to scale. In this work, we introduce VideoAR, the first large-scale Visual Autoregressive (VAR) framework for video generation that combines multi-scale next-frame prediction with autoregressive modeling. VideoAR disentangles spatial and temporal dependencies by integrating intra-frame VAR modeling with causal next-frame prediction, supported by a 3D multi-scale tokenizer that efficiently encodes spatio-temporal dynamics. To improve long-term consistency, we propose Multi-scale Temporal RoPE, Cross-Frame Error Correction, and Random Frame Mask, which collectively mitigate error propagation and stabilize temporal coherence. Our multi-stage pretraining pipeline progressively aligns spatial and temporal learning across increasing resolutions and durations. Empirically, VideoAR achieves new state-of-the-art results among autoregressive models, improving FVD on UCF-101 from 99.5 to 88.6 while reducing inference steps by over 10x, and reaching a VBench score of 81.74-competitive with diffusion-based models an order of magnitude larger. These results demonstrate that VideoAR narrows the performance gap between autoregressive and diffusion paradigms, offering a scalable, efficient, and temporally consistent foundation for future video generation research.

</details>


### [78] [Bidirectional Channel-selective Semantic Interaction for Semi-Supervised Medical Segmentation](https://arxiv.org/abs/2601.05855)
*Kaiwen Huang,Yizhe Zhang,Yi Zhou,Tianyang Xu,Tao Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为BCSI的双向通道选择性语义交互框架，用于半监督医学图像分割，以解决数据标注不足的问题，该框架通过SSP机制和CR组件促进标注和未标注数据之间的有效信息交互，并在多个3D医学数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督医学图像分割方法在处理标注数据不足时存在误差累积、模型结构复杂以及忽略了标注和未标注数据流之间的交互等问题。因此，需要一种新的框架来克服这些挑战。

Method: 提出了一种名为BCSI的双向通道选择性语义交互框架。该框架包含两个主要部分：1. 语义空间扰动（SSP）机制，通过两种强增强操作进行数据扰动，并利用弱增强的伪标签进行无监督学习，同时对两种强增强的预测进行一致性约束以提高稳定性。2. 通道选择性路由器（CR）组件，动态选择最相关的通道进行信息交换，以减少标注和未标注数据交互时的噪声。此外，还采用了双向通道交互（BCI）策略来补充语义信息并增强重要通道的表示。

Result: 在多个3D医学数据集上的实验结果表明，所提出的BCSI框架在半监督医学图像分割任务上优于现有的方法。

Conclusion: BCSI框架能够有效地通过SSP和CR组件促进标注和未标注数据之间的双向、选择性语义交互，从而在标注数据有限的情况下提高医学图像分割的性能，克服了现有方法的不足。

Abstract: Semi-supervised medical image segmentation is an effective method for addressing scenarios with limited labeled data. Existing methods mainly rely on frameworks such as mean teacher and dual-stream consistency learning. These approaches often face issues like error accumulation and model structural complexity, while also neglecting the interaction between labeled and unlabeled data streams. To overcome these challenges, we propose a Bidirectional Channel-selective Semantic Interaction~(BCSI) framework for semi-supervised medical image segmentation. First, we propose a Semantic-Spatial Perturbation~(SSP) mechanism, which disturbs the data using two strong augmentation operations and leverages unsupervised learning with pseudo-labels from weak augmentations. Additionally, we employ consistency on the predictions from the two strong augmentations to further improve model stability and robustness. Second, to reduce noise during the interaction between labeled and unlabeled data, we propose a Channel-selective Router~(CR) component, which dynamically selects the most relevant channels for information exchange. This mechanism ensures that only highly relevant features are activated, minimizing unnecessary interference. Finally, the Bidirectional Channel-wise Interaction~(BCI) strategy is employed to supplement additional semantic information and enhance the representation of important channels. Experimental results on multiple benchmarking 3D medical datasets demonstrate that the proposed method outperforms existing semi-supervised approaches.

</details>


### [79] [Phase4DFD: Multi-Domain Phase-Aware Attention for Deepfake Detection](https://arxiv.org/abs/2601.05861)
*Zhen-Xin Lin,Shang-Kuan Chen*

Main category: cs.CV

TL;DR: 提出了一种名为Phase4DFD的基于相位感知的频域深度伪造检测框架，通过利用傅里叶变换的相位信息来提高检测性能，并在公开数据集上取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法主要依赖于频谱幅度，忽视了相位信息的作用，而相位信息可能包含难以察觉的伪造痕迹。

Method: 该方法结合了RGB图像、傅里叶变换（FFT）幅度和局部二值模式（LBP）表示。核心是引入一个输入级别的相位感知注意力模块，利用合成生成引入的相位不连续性来指导模型关注最能指示篡改的频率模式。然后，将注意力机制处理后的多域表示输入到BNext M骨干网络中进行特征提取，并可选地应用通道和空间注意力进行语义特征细化。

Result: 在CIFAKE和DFFD数据集上进行的广泛实验表明，Phase4DFD模型的性能优于最先进的空间域和频域检测器，同时计算开销较低。消融研究证实，显式相位建模提供了超越仅幅度的频域表示的互补且非冗余的信息。

Conclusion: 通过显式建模相位信息，Phase4DFD能够更有效地检测深度伪造，因为它捕捉到了空间域和现有频域方法可能遗漏的细微伪造伪影。相位信息为深度伪造检测提供了有价值的补充信息。

Abstract: Recent deepfake detection methods have increasingly explored frequency domain representations to reveal manipulation artifacts that are difficult to detect in the spatial domain. However, most existing approaches rely primarily on spectral magnitude, implicitly under exploring the role of phase information. In this work, we propose Phase4DFD, a phase aware frequency domain deepfake detection framework that explicitly models phase magnitude interactions via a learnable attention mechanism. Our approach augments standard RGB input with Fast Fourier Transform (FFT) magnitude and local binary pattern (LBP) representations to expose subtle synthesis artifacts that remain indistinguishable under spatial analysis alone. Crucially, we introduce an input level phase aware attention module that uses phase discontinuities commonly introduced by synthetic generation to guide the model toward frequency patterns that are most indicative of manipulation before backbone feature extraction. The attended multi domain representation is processed by an efficient BNext M backbone, with optional channel spatial attention applied for semantic feature refinement. Extensive experiments on the CIFAKE and DFFD datasets demonstrate that our proposed model Phase4DFD outperforms state of the art spatial and frequency-based detectors while maintaining low computational overhead. Comprehensive ablation studies further confirm that explicit phase modeling provides complementary and non-redundant information beyond magnitude-only frequency representations.

</details>


### [80] [Kidney Cancer Detection Using 3D-Based Latent Diffusion Models](https://arxiv.org/abs/2601.05852)
*Jen Dusseljee,Sarah de Boer,Alessa Hering*

Main category: cs.CV

TL;DR: 提出了一种基于三维潜在扩散模型的新型肾脏异常检测方法，该方法结合了DDPM、DDIM和VQ-GAN，并采用弱监督（仅病例级别伪标签）直接处理图像体积，而非逐层处理。


<details>
  <summary>Details</summary>
Motivation: 开发一种能处理三维图像体积、仅需弱监督（病例级别伪标签）的肾脏异常检测方法，以克服传统逐层处理和强监督方法的局限性，并探索潜在扩散模型在注释效率方面的潜力。

Method: 结合了Denoising Diffusion Probabilistic Models (DDPM)、Denoising Diffusion Implicit Models (DDIM) 和 Vector-Quantized Generative Adversarial Networks (VQ-GAN) 构建了一个三维潜在扩散模型流水线，用于肾脏异常检测。该方法直接作用于图像体积，并使用病例级别的伪标签进行弱监督。

Result: 该方法在三维潜在扩散模型用于弱监督异常检测方面展现了可行性和前景。虽然目前结果尚未达到监督基线的水平，但揭示了提高重建保真度和病灶定位的关键方向。

Conclusion: 三维潜在扩散模型可以用于弱监督的肾脏异常检测，为开发注释效率高、利用生成模型处理复杂腹部解剖结构的研究提供了重要方向。

Abstract: In this work, we present a novel latent diffusion-based pipeline for 3D kidney anomaly detection on contrast-enhanced abdominal CT. The method combines Denoising Diffusion Probabilistic Models (DDPMs), Denoising Diffusion Implicit Models (DDIMs), and Vector-Quantized Generative Adversarial Networks (VQ-GANs). Unlike prior slice-wise approaches, our method operates directly on an image volume and leverages weak supervision with only case-level pseudo-labels. We benchmark our approach against state-of-the-art supervised segmentation and detection models. This study demonstrates the feasibility and promise of 3D latent diffusion for weakly supervised anomaly detection. While the current results do not yet match supervised baselines, they reveal key directions for improving reconstruction fidelity and lesion localization. Our findings provide an important step toward annotation-efficient, generative modeling of complex abdominal anatomy.

</details>


### [81] [Adapting Vision Transformers to Ultra-High Resolution Semantic Segmentation with Relay Tokens](https://arxiv.org/abs/2601.05927)
*Yohann Perron,Vladyslav Sydorov,Christophe Pottier,Loic Landrieu*

Main category: cs.CV

TL;DR: 提出了一种通过多尺度并行处理和可学习的relay token来增强Vision Transformer在超高分辨率图像分割中的性能的方法，同时保留局部细节和全局上下文。


<details>
  <summary>Details</summary>
Motivation: 现有的超高分辨率图像分割方法要么忽略全局上下文，要么损失细节，因此需要一种能同时保留两者的方法。

Method: 该方法并行处理图像的局部（高分辨率、小图块）和全局（低分辨率、大图块）尺度，并通过少量可学习的relay token在两个分支之间聚合和传播特征。该方法可以直接集成到标准的Transformer骨干网络中，参数增加少。

Result: 在Archaeoscape、URUR、Gleason和Cityscapes数据集上进行了大量实验，结果显示该方法在超高分辨率图像分割任务上取得了显著的性能提升，相对mIoU最高提升15%。

Conclusion: 该方法通过显式多尺度推理，有效解决了超高分辨率图像分割中的挑战，在不显著增加模型复杂性的情况下，实现了局部细节和全局意识的兼顾，并取得了优于现有方法的性能。

Abstract: Current approaches for segmenting ultra high resolution images either slide a window, thereby discarding global context, or downsample and lose fine detail. We propose a simple yet effective method that brings explicit multi scale reasoning to vision transformers, simultaneously preserving local details and global awareness. Concretely, we process each image in parallel at a local scale (high resolution, small crops) and a global scale (low resolution, large crops), and aggregate and propagate features between the two branches with a small set of learnable relay tokens. The design plugs directly into standard transformer backbones (eg ViT and Swin) and adds fewer than 2 % parameters. Extensive experiments on three ultra high resolution segmentation benchmarks, Archaeoscape, URUR, and Gleason, and on the conventional Cityscapes dataset show consistent gains, with up to 15 % relative mIoU improvement. Code and pretrained models are available at https://archaeoscape.ai/work/relay-tokens/ .

</details>


### [82] [Context-Aware Decoding for Faithful Vision-Language Generation](https://arxiv.org/abs/2601.05939)
*Mehrdad Fazli,Bowen Wei,Ziwei Zhu*

Main category: cs.CV

TL;DR: 本研究通过Logit Lens分析了视觉语言模型（LVLMs）生成幻觉的层级动态，发现真实输出的token比幻觉输出的token更早地确定。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在开放式任务中存在幻觉问题，即生成的响应与视觉输入不一致，这是模型的一个关键限制。

Method: 研究者利用Logit Lens分析了LVLMs的层级生成动态，发现了“承诺深度差距”（commitment-depth gap）。在此基础上，提出了一种训练免费的缓解策略——Context Embedding Injection（CEI），该方法利用最后一个输入token的隐藏状态（context embedding）作为接地信号，以维持视觉保真度并减少幻觉。

Result: 在CHAIR、AMBER和MMHal-Bench三个基准上，CEI方法在三种不同的LVLMs上均优于现有技术水平的基线方法。其动态变体实现了最低的总体幻觉率。

Conclusion: 研究揭示了LVLMs层级生成动态中与幻觉相关的新机制，并提出了一种轻量级、训练免费的干预方法CEI，能够有效减轻LVLMs的幻觉问题，提升模型的视觉保真度。

Abstract: Hallucinations, generating responses inconsistent with the visual input, remain a critical limitation of large vision-language models (LVLMs), especially in open-ended tasks such as image captioning and visual reasoning. In this work, we probe the layer-wise generation dynamics that drive hallucinations and propose a training-free mitigation strategy. Employing the Logit Lens, we examine how LVLMs construct next-token distributions across decoder layers, uncovering a pronounced commitment-depth gap: truthful tokens accumulate probability mass on their final candidates earlier than hallucinatory ones. Drawing on this discovery, we introduce Context Embedding Injection (CEI), a lightweight method that harnesses the hidden state of the last input token-the context embedding-as a grounding signal to maintain visual fidelity throughout decoding and curb hallucinations. Evaluated on the CHAIR, AMBER, and MMHal-Bench benchmarks (with a maximum token length of 512), CEI outperforms state-of-the-art baselines across three LVLMs, with its dynamic variant yielding the lowest overall hallucination rates. By integrating novel mechanistic insights with a scalable intervention, this work advances the mitigation of hallucinations in LVLMs.

</details>


### [83] [WaveRNet: Wavelet-Guided Frequency Learning for Multi-Source Domain-Generalized Retinal Vessel Segmentation](https://arxiv.org/abs/2601.05942)
*Chanchan Wang,Yuanfang Wang,Qing Xu,Guanxin Chen*

Main category: cs.CV

TL;DR: 本文提出WaveRNet，一种基于小波的频率学习框架，用于领域泛化的视网膜血管分割，解决了光照和对比度变化导致的领域偏移以及细小血管结构丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于SAM的方法在领域泛化能力上存在不足，尤其是在光照和对比度变化的情况下，并且SAM的直接上采样会丢失细小的血管结构。本文旨在解决这些限制，提高视网膜血管分割的鲁棒性和泛化能力。

Method: 本文提出的WaveRNet包含三个主要模块：1. 谱引导域调制器（SDM），结合小波分解和可学习域令牌，分离光照鲁棒的低频结构和高频血管边界；2. 频率自适应域融合（FADF）模块，通过小波基的频率相似性进行测试时域选择和软加权融合；3. 分层掩码提示精炼器（HMPR），通过粗到精的精炼和长距离依赖建模来克服SAM上采样限制。

Result: 在 leave-one-domain-out 协议下，对四个公开的视网膜数据集进行的广泛实验表明，WaveRNet 实现了最先进的泛化性能。

Conclusion: WaveRNet通过引入小波分解和频率学习机制，有效解决了领域泛化视网膜血管分割中的挑战，实现了优异的鲁棒性和细微结构保留能力，优于现有方法。

Abstract: Domain-generalized retinal vessel segmentation is critical for automated ophthalmic diagnosis, yet faces significant challenges from domain shift induced by non-uniform illumination and varying contrast, compounded by the difficulty of preserving fine vessel structures. While the Segment Anything Model (SAM) exhibits remarkable zero-shot capabilities, existing SAM-based methods rely on simple adapter fine-tuning while overlooking frequency-domain information that encodes domain-invariant features, resulting in degraded generalization under illumination and contrast variations. Furthermore, SAM's direct upsampling inevitably loses fine vessel details. To address these limitations, we propose WaveRNet, a wavelet-guided frequency learning framework for robust multi-source domain-generalized retinal vessel segmentation. Specifically, we devise a Spectral-guided Domain Modulator (SDM) that integrates wavelet decomposition with learnable domain tokens, enabling the separation of illumination-robust low-frequency structures from high-frequency vessel boundaries while facilitating domain-specific feature generation. Furthermore, we introduce a Frequency-Adaptive Domain Fusion (FADF) module that performs intelligent test-time domain selection through wavelet-based frequency similarity and soft-weighted fusion. Finally, we present a Hierarchical Mask-Prompt Refiner (HMPR) that overcomes SAM's upsampling limitation through coarse-to-fine refinement with long-range dependency modeling. Extensive experiments under the Leave-One-Domain-Out protocol on four public retinal datasets demonstrate that WaveRNet achieves state-of-the-art generalization performance. The source code is available at https://github.com/Chanchan-Wang/WaveRNet.

</details>


### [84] [Adaptive Conditional Contrast-Agnostic Deformable Image Registration with Uncertainty Estimation](https://arxiv.org/abs/2601.05981)
*Yinsong Wang,Xinzhe Luo,Siyi Du,Chen Qin*

Main category: cs.CV

TL;DR: 提出了一种名为AC-CAR的自适应条件对比无关的可变形图像配准框架，该框架通过随机卷积对比增强和自适应条件特征调制器，能够泛化到未见过的成像对比，并提供对比无关的配准不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统的配准方法耗时，而现有的基于学习的方法泛化能力受训练时的对比度限制。需要一种能够处理复杂非线性强度关系并泛化到任意成像对比度的方法。

Method: 提出AC-CAR框架，包含：1. 基于随机卷积的对比度增强方案，用于泛化到未见的对比度。2. 自适应条件特征调制器（ACFM），用于自适应调制特征并学习对比度不变的正则化，以强制不同对比度下特征的一致性。3. 集成方差网络，提供对比度无关的配准不确定性。

Result: AC-CAR在配准精度上优于基线方法，并在未见过的成像对比度上表现出更强的泛化能力。

Conclusion: AC-CAR框架成功实现了对比度无关的可变形图像配准，并能提供可靠的配准不确定性，解决了现有方法的局限性。

Abstract: Deformable multi-contrast image registration is a challenging yet crucial task due to the complex, non-linear intensity relationships across different imaging contrasts. Conventional registration methods typically rely on iterative optimization of the deformation field, which is time-consuming. Although recent learning-based approaches enable fast and accurate registration during inference, their generalizability remains limited to the specific contrasts observed during training. In this work, we propose an adaptive conditional contrast-agnostic deformable image registration framework (AC-CAR) based on a random convolution-based contrast augmentation scheme. AC-CAR can generalize to arbitrary imaging contrasts without observing them during training. To encourage contrast-invariant feature learning, we propose an adaptive conditional feature modulator (ACFM) that adaptively modulates the features and the contrast-invariant latent regularization to enforce the consistency of the learned feature across different imaging contrasts. Additionally, we enable our framework to provide contrast-agnostic registration uncertainty by integrating a variance network that leverages the contrast-agnostic registration encoder to improve the trustworthiness and reliability of AC-CAR. Experimental results demonstrate that AC-CAR outperforms baseline methods in registration accuracy and exhibits superior generalization to unseen imaging contrasts. Code is available at https://github.com/Yinsong0510/AC-CAR.

</details>


### [85] [Deepfake detectors are DUMB: A benchmark to assess adversarial training robustness under transferability constraints](https://arxiv.org/abs/2601.05986)
*Adrian Serrano,Erwan Umlil,Ronan Thomas*

Main category: cs.CV

TL;DR: 该研究评估了现有对抗性训练方法在面对现实世界中深伪检测器的攻击时的鲁棒性，发现对抗性训练在同分布情况下能提高鲁棒性，但在跨数据集情况下可能会降低其性能，并强调需要制定针对性的防御策略。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的深伪检测系统面临着能够产生难以察觉的扰动的攻击者，这会影响模型的性能。然而，现有研究对对抗性训练在攻击者知识有限和数据分布不匹配等真实条件下的有效性探索不足。

Method: 研究扩展了DUMB（数据集来源、模型架构和平衡）和DUMBer方法论到深伪检测领域。通过在迁移性和跨数据集配置下评估不同检测器（RECCE, SRM, XCeption, UCF, SPSL）在三种攻击（PGD, FGSM, FPBA）下的鲁棒性，并考虑了攻击者和防御者的视角，映射到不匹配场景。实验使用了FaceForensics++和Celeb-DF-V2两个数据集。

Result: 实验结果表明，对抗性训练策略在同分布情况下可以增强鲁棒性，但在跨数据集配置下，根据所采用的具体策略，其鲁棒性可能会下降。这揭示了不同数据集和攻击策略对对抗性训练效果的影响。

Conclusion: 对抗性训练在增强深伪检测器鲁棒性方面存在局限性，尤其是在跨数据集和数据分布不匹配的现实场景中。因此，在实际应用中，需要针对具体情况（case-aware）制定防御策略，以应对复杂的对抗性攻击。

Abstract: Deepfake detection systems deployed in real-world environments are subject to adversaries capable of crafting imperceptible perturbations that degrade model performance. While adversarial training is a widely adopted defense, its effectiveness under realistic conditions -- where attackers operate with limited knowledge and mismatched data distributions - remains underexplored. In this work, we extend the DUMB -- Dataset soUrces, Model architecture and Balance - and DUMBer methodology to deepfake detection. We evaluate detectors robustness against adversarial attacks under transferability constraints and cross-dataset configuration to extract real-world insights. Our study spans five state-of-the-art detectors (RECCE, SRM, XCeption, UCF, SPSL), three attacks (PGD, FGSM, FPBA), and two datasets (FaceForensics++ and Celeb-DF-V2). We analyze both attacker and defender perspectives mapping results to mismatch scenarios. Experiments show that adversarial training strategies reinforce robustness in the in-distribution cases but can also degrade it under cross-dataset configuration depending on the strategy adopted. These findings highlight the need for case-aware defense strategies in real-world applications exposed to adversarial attacks.

</details>


### [86] [ViTNT-FIQA: Training-Free Face Image Quality Assessment with Vision Transformers](https://arxiv.org/abs/2601.05741)
*Guray Ozgur,Eduarda Caldeira,Tahar Chettaoui,Jan Niklas Kolf,Marco Huber,Naser Damer,Fadi Boutros*

Main category: cs.CV

TL;DR: 提出了一种名为 ViTNT-FIQA 的无训练人脸图像质量评估方法，通过测量 Vision Transformer (ViT) 中间块的 patch embedding 演化稳定性来评估人脸图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸图像质量评估方法要么仅使用最终层表示，要么需要多次前向传播或反向传播，效率低下。研究者希望开发一种无需训练、计算高效且能直接应用于预训练 ViT 模型的人脸图像质量评估方法。

Method: ViTNT-FIQA 通过计算来自连续 Transformer 块的 L2 归一化 patch embedding 之间的欧氏距离，并将这些距离聚合为图像级别的质量分数。这种方法衡量了 patch embedding 在不同 ViT 块之间的特征细化轨迹的稳定性。

Result: 高分辨率人脸图像在块之间表现出稳定的特征细化轨迹，而降质图像则表现出不稳定的变换。ViTNT-FIQA 在合成数据集和八个公开基准数据集上都取得了与最先进方法相当的性能。

Conclusion: ViTNT-FIQA 是一种有效且计算高效的无训练人脸图像质量评估方法，它通过分析 ViT 中间块的 patch embedding 演化稳定性来实现，并且可以轻松应用于任何预训练的 ViT 模型。

Abstract: Face Image Quality Assessment (FIQA) is essential for reliable face recognition systems. Current approaches primarily exploit only final-layer representations, while training-free methods require multiple forward passes or backpropagation. We propose ViTNT-FIQA, a training-free approach that measures the stability of patch embedding evolution across intermediate Vision Transformer (ViT) blocks. We demonstrate that high-quality face images exhibit stable feature refinement trajectories across blocks, while degraded images show erratic transformations. Our method computes Euclidean distances between L2-normalized patch embeddings from consecutive transformer blocks and aggregates them into image-level quality scores. We empirically validate this correlation on a quality-labeled synthetic dataset with controlled degradation levels. Unlike existing training-free approaches, ViTNT-FIQA requires only a single forward pass without backpropagation or architectural modifications. Through extensive evaluation on eight benchmarks (LFW, AgeDB-30, CFP-FP, CALFW, Adience, CPLFW, XQLFW, IJB-C), we show that ViTNT-FIQA achieves competitive performance with state-of-the-art methods while maintaining computational efficiency and immediate applicability to any pre-trained ViT-based face recognition model.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [87] [Enhancing Foundation Models in Transaction Understanding with LLM-based Sentence Embeddings](https://arxiv.org/abs/2601.05271)
*Xiran Fan,Zhimeng Jiang,Chin-Chia Michael Yeh,Yuzhong Chen,Yingtong Dou,Menghai Pan,Yan Zheng*

Main category: cs.CL

TL;DR: 该研究提出了一种混合框架，结合了大型语言模型（LLM）的语义理解能力和轻量级交易模型的计算效率，用于分析支付网络数据。该框架通过LLM生成嵌入作为初始化，并采用多源数据融合和单词约束原则来增强交易理解任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的交易分析模型在处理类别型商户字段时，使用基于索引的表示会丢失大量的语义信息。虽然LLM可以解决这个问题，但其计算开销过大，不适用于实时金融场景。因此，需要一种能够平衡语义理解和计算效率的方法。

Method: 提出一个混合框架，利用LLM生成交易数据的语义嵌入，然后将其作为轻量级交易模型的初始化。该框架还采用多源数据融合来丰富商户类别字段，并应用单词约束原则以确保跨LLM架构生成一致的嵌入。同时，通过噪声过滤和上下文感知丰富来提高数据质量。

Result: 在大型交易数据集上的实验表明，该混合框架在多项交易理解任务上显著提高了性能。

Conclusion: 所提出的混合框架能够有效利用LLM的语义理解能力，同时保持计算效率，从而在交易分析任务中取得优于现有方法的性能。

Abstract: The ubiquity of payment networks generates vast transactional data encoding rich consumer and merchant behavioral patterns. Recent foundation models for transaction analysis process tabular data sequentially but rely on index-based representations for categorical merchant fields, causing substantial semantic information loss by converting rich textual data into discrete tokens. While Large Language Models (LLMs) can address this limitation through superior semantic understanding, their computational overhead challenges real-time financial deployment. We introduce a hybrid framework that uses LLM-generated embeddings as semantic initializations for lightweight transaction models, balancing interpretability with operational efficiency. Our approach employs multi-source data fusion to enrich merchant categorical fields and a one-word constraint principle for consistent embedding generation across LLM architectures. We systematically address data quality through noise filtering and context-aware enrichment. Experiments on large-scale transaction datasets demonstrate significant performance improvements across multiple transaction understanding tasks.

</details>


### [88] [Lost in Execution: On the Multilingual Robustness of Tool Calling in Large Language Models](https://arxiv.org/abs/2601.05366)
*Zheng Luo,T Pranav Kutralingam,Ogochukwu N Okoani,Wanpeng Xu,Hua Wei,Xiyang Hu*

Main category: cs.CL

TL;DR: 该研究提出了一个多语言工具调用诊断基准 MLCL，系统评估了 LLM 在中、印、伊博语等多种语言下的工具调用能力，发现参数值语言不匹配是主要失败原因，并提出了一些缓解策略，但仍无法完全恢复至英语水平。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 工具调用评估主要集中在英语，对多语言场景下的鲁棒性研究不足，作者希望填补这一空白。

Method: 引入 MLCL 基准，对 LLM 在中文、印地语和伊博语下的工具调用能力进行系统评估，并进行细粒度的错误分析，同时测试了多种推理时系统策略。

Result: LLM 在多语言工具调用中存在大量失败，即使在意图理解和工具选择正确的情况下。参数值语言不匹配是主要的失败模式。推理时策略能显著减少语言引起的执行错误，但无法完全恢复到英语水平。

Conclusion: LLM 在多语言工具调用方面仍面临挑战，参数值语言不匹配是一个关键问题，需要进一步研究以实现鲁棒的多语言工具调用。

Abstract: Large Language Models (LLMs) are increasingly deployed as agents that invoke external tools through structured function calls. While recent work reports strong tool-calling performance under standard English-centric evaluations, the robustness of tool calling under multilingual user interactions remains underexplored. In this work, we introduce MLCL, a diagnostic benchmark, and conduct a systematic evaluation of multilingual tool calling across Chinese, Hindi, and the low-resource language Igbo. Through fine-grained error analysis, we show that many failures occur despite correct intent understanding and tool selection. We identify parameter value language mismatch as a dominant failure mode, where models generate semantically appropriate parameter values in the user's language, violating language-invariant execution conventions. We further evaluate several inference-time system strategies and find that while these strategies substantially reduce language-induced execution errors, none of them can fully recover English-level performance.

</details>


### [89] [The Table of Media Bias Elements: A sentence-level taxonomy of media bias types and propaganda techniques](https://arxiv.org/abs/2601.05358)
*Tim Menzner,Jochen L. Leidner*

Main category: cs.CL

TL;DR: 本研究提出了一种细粒度的、句子级别的媒体偏见和宣传分类法，将 38 种基本偏见类型组织成六个功能家族，并提供识别指南。该分类法旨在超越单一政治光谱，提高偏见识别的准确性和覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 现有的关于“左派”或“右派”新闻的争论往往忽略了偏见是通过具体的语言手段传达的，而这些手段超越了单一的政治光谱。因此，研究的动机是将焦点从新闻来源的政治立场转移到如何具体地在句子层面表达偏见。

Method: 研究采用了迭代方法，结合了近距离阅读、跨学科理论和初步标注。他们收集了 26,464 个句子，并从中推导出一个细粒度的、句子级别的媒体偏见和宣传分类法。该分类法包含 38 种基本偏见类型，组织成六个功能家族，并以“媒体偏见元素表”的形式进行可视化。此外，还进行了定量调查来评估偏见类型的普遍性差异，并将该分类法与现有的自然语言处理和传播学分类法进行对比。

Result: 研究结果是一个两层结构的分类法，包含 38 种基本偏见类型，组织在六个功能家族中，并可视化为“媒体偏见元素表”。该分类法为每种类型提供了定义、现实世界示例、认知和社会驱动因素以及识别指南。定量调查表明了不同偏见类型的普遍性差异，而与现有分类法的对比显示出该分类法在覆盖范围和减少歧义方面有显著提升。

Conclusion: 本研究提出的细粒度、句子级别的媒体偏见分类法，能够超越政治光谱的限制，更准确、更全面地识别语言中的偏见和宣传。该分类法为理解和分析媒体内容提供了新的工具，并对 NLP 和传播学领域具有重要意义。

Abstract: Public debates about "left-" or "right-wing" news overlook the fact that bias is usually conveyed by concrete linguistic manoeuvres that transcend any single political spectrum. We therefore shift the focus from where an outlet allegedly stands to how partiality is expressed in individual sentences. Drawing on 26,464 sentences collected from newsroom corpora, user submissions and our own browsing, we iteratively combine close-reading, interdisciplinary theory and pilot annotation to derive a fine-grained, sentence-level taxonomy of media bias and propaganda. The result is a two-tier schema comprising 38 elementary bias types, arranged in six functional families and visualised as a "table of media-bias elements". For each type we supply a definition, real-world examples, cognitive and societal drivers, and guidance for recognition. A quantitative survey of a random 155-sentence sample illustrates prevalence differences, while a cross-walk to the best-known NLP and communication-science taxonomies reveals substantial coverage gains and reduced ambiguity.

</details>


### [90] [Glitter: Visualizing Lexical Surprisal for Readability in Administrative Texts](https://arxiv.org/abs/2601.05411)
*Jan Černý,Ivana Kvapilíková,Silvie Cinková*

Main category: cs.CL

TL;DR: 研究使用文本信息熵来估计文本可读性，并提出了一个可视化框架，支持多种语言模型，最终目标是改进行政文本的可读性和清晰度。


<details>
  <summary>Details</summary>
Motivation: 研究动机是提高行政和官僚文本的可读性和清晰度。

Method: 使用信息熵来估计文本可读性，并开发了一个包含多种语言模型、用于近似和可视化信息熵的可视化框架。

Result: 提出了一个可用的可视化框架，并将其作为自由软件发布。

Conclusion: 测量文本信息熵是一种估计文本可读性的可行方法，其应用有助于提高行政文本的可读性和清晰度。

Abstract: This work investigates how measuring information entropy of text can be used to estimate its readability. We propose a visualization framework that can be used to approximate information entropy of text using multiple language models and visualize the result. The end goal is to use this method to estimate and improve readability and clarity of administrative or bureaucratic texts. Our toolset is available as a libre software on https://github.com/ufal/Glitter.

</details>


### [91] [Same Claim, Different Judgment: Benchmarking Scenario-Induced Bias in Multilingual Financial Misinformation Detection](https://arxiv.org/abs/2601.05403)
*Zhiwei Liu,Yupen Cao,Yuechen Jiang,Mohsinul Kabir,Polydoros Giannouris,Chen Xu,Ziyang Xu,Tianlei Zhu,Tariquzzaman Faisal,Triantafillos Papadopoulos,Yan Wang,Lingfei Qian,Xueqing Peng,Zhuohan Xie,Ye Yuan,Saeed Almheiri,Abdulrazzaq Alnajjar,Mingbin Chen,Harry Stuart,Paul Thompson,Prayag Tiwari,Alejandro Lopez-Lira,Xue Liu,Jimin Huang,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 本研究提出了MFMDSCEN基准，用于评估大型语言模型（LLMs）在金融信息误导检测（MFMD）中的行为偏见，该基准涵盖了多样的金融场景和多语言数据，并发现主流LLMs普遍存在明显的行为偏见。


<details>
  <summary>Details</summary>
Motivation: 现有关于LLM偏见的研究主要集中在通用场景，而缺乏对复杂、高风险、多语言的金融信息误导检测任务的深入考察，因此需要一个针对金融领域行为偏见的评估基准。

Method: 研究人员与金融专家合作，构建了三种类型的复杂金融场景（基于角色/个性、角色/地区、角色/种族/宗教信仰），并开发了一个包含英语、中文、希腊语和孟加拉语的多语言金融信息误导数据集，将场景与误导信息结合，系统地评估了22个主流LLMs。

Result: 评估结果表明，无论是商业模型还是开源模型，都普遍存在显著的行为偏见。

Conclusion: LLMs在金融信息误导检测任务中仍存在严重的行为偏见，需要进一步的研究和改进来减轻这些偏见。

Abstract: Large language models (LLMs) have been widely applied across various domains of finance. Since their training data are largely derived from human-authored corpora, LLMs may inherit a range of human biases. Behavioral biases can lead to instability and uncertainty in decision-making, particularly when processing financial information. However, existing research on LLM bias has mainly focused on direct questioning or simplified, general-purpose settings, with limited consideration of the complex real-world financial environments and high-risk, context-sensitive, multilingual financial misinformation detection tasks (\mfmd). In this work, we propose \mfmdscen, a comprehensive benchmark for evaluating behavioral biases of LLMs in \mfmd across diverse economic scenarios. In collaboration with financial experts, we construct three types of complex financial scenarios: (i) role- and personality-based, (ii) role- and region-based, and (iii) role-based scenarios incorporating ethnicity and religious beliefs. We further develop a multilingual financial misinformation dataset covering English, Chinese, Greek, and Bengali. By integrating these scenarios with misinformation claims, \mfmdscen enables a systematic evaluation of 22 mainstream LLMs. Our findings reveal that pronounced behavioral biases persist across both commercial and open-source models. This project will be available at https://github.com/lzw108/FMD.

</details>


### [92] [Large Language Models Are Bad Dice Players: LLMs Struggle to Generate Random Numbers from Statistical Distributions](https://arxiv.org/abs/2601.05414)
*Minda Zhao,Yilun Du,Mengyu Wang*

Main category: cs.CL

TL;DR: 研究评估了前沿大型语言模型（LLM）在生成式管道中进行概率采样的能力，发现其表现不佳，尤其是在批量生成和独立请求方面存在显著差异，且样本量和分布复杂性增加时保真度下降，下游任务也受到影响。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在教育评估和合成数据构建等领域的应用日益广泛，其准确采样特定概率分布的能力变得至关重要。

Method: 研究采用了一种包含15种不同分布和11个LLM的基准测试，并设计了两种协议：批量生成（一次请求生成1000个样本）和独立请求（1000次独立无状态调用）。

Result: 批量生成模式下的统计有效性较低（中位数通过率为13%），而独立请求模式下几乎所有模型都无法通过任何分布测试。模型在复杂分布和增加样本量时采样保真度会单调下降，并且在多项选择题生成和属性约束文本到图像生成等下游任务中会传播错误。

Conclusion: 当前的LLM缺乏功能性的内部采样器，需要依赖外部工具来满足需要统计保证的应用场景。

Abstract: As large language models (LLMs) transition from chat interfaces to integral components of stochastic pipelines across domains like educational assessment and synthetic data construction, the ability to faithfully sample from specified probability distributions has become a functional requirement rather than a theoretical curiosity. We present the first large-scale, statistically powered audit of native probabilistic sampling in frontier LLMs, benchmarking 11 models across 15 distributions. To disentangle failure modes, we employ a dual-protocol design: Batch Generation, where a model produces N=1000 samples within one response, and Independent Requests, comprising $N=1000$ stateless calls. We observe a sharp protocol asymmetry: batch generation achieves only modest statistical validity, with a 13% median pass rate, while independent requests collapse almost entirely, with 10 of 11 models passing none of the distributions. Beyond this asymmetry, we reveal that sampling fidelity degrades monotonically with distributional complexity and aggravates as the requested sampling horizon N increases. Finally, we demonstrate the propagation of these failures into downstream tasks: models fail to enforce uniform answer-position constraints in MCQ generation and systematically violate demographic targets in attribute-constrained text-to-image prompt synthesis. These findings indicate that current LLMs lack a functional internal sampler, necessitating the use of external tools for applications requiring statistical guarantees.

</details>


### [93] [Tracing Moral Foundations in Large Language Models](https://arxiv.org/abs/2601.05437)
*Chenxiao Yu,Bowen Yi,Farzan Karimi-Malekabadi,Suhaib Abdurahman,Jinyi Ye,Shrikanth Narayanan,Yue Zhao,Morteza Dehghani*

Main category: cs.CL

TL;DR: 本研究使用道德基础理论（MFT）分析了两个大型语言模型（LLMs），Llama-3.1-8B-Instruct 和 Qwen2.5-7B-Instruct，发现它们内部以结构化、分层的方式编码和组织道德基础，并且这些表示与人类的道德判断一致。研究还发现，稀疏自编码器（SAEs）可以识别出与特定道德基础相关的语义特征，并且通过因果干预可以改变模型的道德判断行为。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于理解大型语言模型（LLMs）生成类人道德判断是源于内在的道德概念结构，还是仅仅是表面的模仿。具体来说，研究者希望探索LLMs如何编码、组织和表达道德基础，以及这些内部表示与人类道德判断的关系。

Method: 研究采用了多层次的方法，包括：(i) 对MFT概念表示进行逐层分析，并评估其与人类道德判断的一致性；(ii) 使用预训练的稀疏自编码器（SAEs）分析残差流，以识别支持道德概念的稀疏特征；(iii) 利用密集的MFT向量和稀疏SAE特征进行因果干预（causal steering）。

Result: 研究发现，两个LLMs在结构化、分层的模式下表示和区分道德基础，并且这种表示与人类的判断一致。SAE特征显示出与特定道德基础的清晰语义联系，表明在共享表示中存在部分解耦的机制。通过因果干预，可以根据MFT向量或SAE特征，预测性地改变模型在与道德基础相关的行为。

Conclusion: 研究结果提供了机械证据，表明LLMs中的道德概念是分布式的、分层的，并且部分解耦的。这表明，仅凭语言的统计规律，就可以涌现出多元化的道德结构作为潜在模式。LLMs的道德判断并非完全的模仿，而是具有一定的内部结构支持。

Abstract: Large language models (LLMs) often produce human-like moral judgments, but it is unclear whether this reflects an internal conceptual structure or superficial ``moral mimicry.'' Using Moral Foundations Theory (MFT) as an analytic framework, we study how moral foundations are encoded, organized, and expressed within two instruction-tuned LLMs: Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct. We employ a multi-level approach combining (i) layer-wise analysis of MFT concept representations and their alignment with human moral perceptions, (ii) pretrained sparse autoencoders (SAEs) over the residual stream to identify sparse features that support moral concepts, and (iii) causal steering interventions using dense MFT vectors and sparse SAE features. We find that both models represent and distinguish moral foundations in a structured, layer-dependent way that aligns with human judgments. At a finer scale, SAE features show clear semantic links to specific foundations, suggesting partially disentangled mechanisms within shared representations. Finally, steering along either dense vectors or sparse features produces predictable shifts in foundation-relevant behavior, demonstrating a causal connection between internal representations and moral outputs. Together, our results provide mechanistic evidence that moral concepts in LLMs are distributed, layered, and partly disentangled, suggesting that pluralistic moral structure can emerge as a latent pattern from the statistical regularities of language alone.

</details>


### [94] [Do LLMs Need Inherent Reasoning Before Reinforcement Learning? A Study in Korean Self-Correction](https://arxiv.org/abs/2601.05459)
*Hongjin Kim,Jaewook Lee,Kiyoung Lee,Jong-hun Shin,Soojong Lim,Oh-Woog Kwon*

Main category: cs.CL

TL;DR: 本研究发现，仅靠强化学习（RL）难以提升低资源语言（如韩语）大模型（LLMs）的推理能力，关键在于通过精调特定神经元来对齐模型内部的推理过程。


<details>
  <summary>Details</summary>
Motivation: 高资源语言（如英语）的大模型在推理和自我纠错方面表现出色，但低资源语言（如韩语）的表现受限，研究动机是探索是否能通过强化学习提升韩语的推理能力至与英语相当的水平。

Method: 研究首先尝试单独使用强化学习，发现效果有限。随后，探索了多种微调策略，重点关注了通过调整早期层的韩语特异性神经元来对齐模型内部推理过程。为此，构建了一个包含代码转换的自我纠错数据集。

Result: 调整韩语特异性神经元并使用代码转换数据集进行微调后，模型在数学推理和自我纠错任务上的表现显著提升。

Conclusion: 提升多语言推理能力的关键并非注入新的语言知识，而是有效激发和对齐已有的推理能力。研究表明，内部翻译和神经元层级的调整对实现多语言推理对齐至关重要。

Abstract: Large Language Models (LLMs) demonstrate strong reasoning and self-correction abilities in high-resource languages like English, but their performance remains limited in low-resource languages such as Korean. In this study, we investigate whether reinforcement learning (RL) can enhance Korean reasoning abilities to a degree comparable to English. Our findings reveal that RL alone yields limited improvements when applied to models lacking inherent Korean reasoning capabilities. To address this, we explore several fine-tuning strategies and show that aligning the model's internal reasoning processes with Korean inputs-particularly by tuning Korean-specific neurons in early layers-is key to unlocking RL's effectiveness. We introduce a self-correction code-switching dataset to facilitate this alignment and observe significant performance gains in both mathematical reasoning and self-correction tasks. Ultimately, we conclude that the crucial factor in multilingual reasoning enhancement is not injecting new linguistic knowledge, but effectively eliciting and aligning existing reasoning capabilities. Our study provides a new perspective on how internal translation and neuron-level tuning contribute to multilingual reasoning alignment in LLMs.

</details>


### [95] [Towards Valid Student Simulation with Large Language Models](https://arxiv.org/abs/2601.05473)
*Zhihao Yuan,Yunze Xiao,Ming Li,Weihao Xuan,Richard Tong,Mona Diab,Tom Mitchell*

Main category: cs.CL

TL;DR: 该论文提出了一个基于大型语言模型（LLM）的学生模拟框架，通过引入“认知状态规范”（ESS）和“目标-环境”框架来解决LLM在模拟部分知识学习者时出现的“能力悖论”问题，并强调了认知保真度而非表面真实性的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在模拟部分知识的在读学生时，会产生不切实际的错误模式和学习动态，即“能力悖论”。需要一种新的框架来解决这个问题，以使LLM模拟学生成为可靠的科学和教学工具。

Method: 提出了一种将学生模拟视为约束生成问题的框架，该问题由显式的“认知状态规范”（ESS）控制，定义了模拟学习者的可访问性、错误结构和状态演变。此外，引入了“目标-环境”框架来确定模拟学生系统的行为目标和部署背景。

Result: 论文整合了现有文献，形式化了关键的设计维度，并阐述了与有效性、评估和伦理风险相关的开放性挑战。论文并未提出新的系统或基准。

Conclusion: 为了使基于LLM的模拟学生成为可靠的科学和教学工具，需要优先考虑认知保真度，而非表面上的真实性。ESS和目标-环境框架是实现这一目标的关键组成部分。

Abstract: This paper presents a conceptual and methodological framework for large language model (LLM) based student simulation in educational settings. The authors identify a core failure mode, termed the "competence paradox" in which broadly capable LLMs are asked to emulate partially knowledgeable learners, leading to unrealistic error patterns and learning dynamics. To address this, the paper reframes student simulation as a constrained generation problem governed by an explicit Epistemic State Specification (ESS), which defines what a simulated learner can access, how errors are structured, and how learner state evolves over time. The work further introduces a Goal-by-Environment framework to situate simulated student systems according to behavioral objectives and deployment contexts. Rather than proposing a new system or benchmark, the paper synthesizes prior literature, formalizes key design dimensions, and articulates open challenges related to validity, evaluation, and ethical risks. Overall, the paper argues for epistemic fidelity over surface realism as a prerequisite for using LLM-based simulated students as reliable scientific and pedagogical instruments.

</details>


### [96] [The Facade of Truth: Uncovering and Mitigating LLM Susceptibility to Deceptive Evidence](https://arxiv.org/abs/2601.05478)
*Herun Wan,Jiaying Wu,Minnan Luo,Fanxiao Li,Zhi Zeng,Min-Yen Kan*

Main category: cs.CL

TL;DR: 研究提出了一种名为MisBelief的新框架，能够生成难以证伪的误导性证据，并评估了现有LLM在面对此类证据时的脆弱性。结果显示，LLM容易受到这种精心构造的证据影响，导致其信念分数显著偏离事实。为解决此问题，研究提出了Deceptive Intent Shielding (DIS)机制，可以识别证据中的欺骗意图，并缓解LLM的信念偏移。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在抵抗明确的虚假信息方面表现良好，但可能容易受到精心设计的、难以被证伪的误导性证据的影响，这会损害其辅助人类决策的能力。因此，需要一种方法来系统地探测和解决这种漏洞。

Method: 作者提出了MisBelief框架，通过多轮、多角色的LLM协作交互来生成误导性证据，模拟微妙的、可否认的推理过程。利用MisBelief生成了4800个不同难度的实例，并用这批数据评估了7个代表性LLM。同时，提出了Deceptive Intent Shielding (DIS)机制，通过推断证据背后的欺骗意图来提供预警。

Result: 结果表明，LLM对直接的虚假信息具有鲁棒性，但对MisBelief生成的精炼证据高度敏感，其对错误信息的信念分数平均增加了93.0%，严重影响了下游的推荐。DIS机制能够有效缓解信念偏移，并促进对证据更谨慎的评估。

Conclusion: LLM存在对难以证伪的误导性证据的根本性脆弱性。MisBelief框架可以有效地生成此类证据，揭示了这一问题。Deceptive Intent Shielding (DIS)是一种有效的治理机制，可以通过识别欺骗意图来减轻LLM受到的误导影响，从而增强其可靠性。

Abstract: To reliably assist human decision-making, LLMs must maintain factual internal beliefs against misleading injections. While current models resist explicit misinformation, we uncover a fundamental vulnerability to sophisticated, hard-to-falsify evidence. To systematically probe this weakness, we introduce MisBelief, a framework that generates misleading evidence via collaborative, multi-round interactions among multi-role LLMs. This process mimics subtle, defeasible reasoning and progressive refinement to create logically persuasive yet factually deceptive claims. Using MisBelief, we generate 4,800 instances across three difficulty levels to evaluate 7 representative LLMs. Results indicate that while models are robust to direct misinformation, they are highly sensitive to this refined evidence: belief scores in falsehoods increase by an average of 93.0\%, fundamentally compromising downstream recommendations. To address this, we propose Deceptive Intent Shielding (DIS), a governance mechanism that provides an early warning signal by inferring the deceptive intent behind evidence. Empirical results demonstrate that DIS consistently mitigates belief shifts and promotes more cautious evidence evaluation.

</details>


### [97] [MemBuilder: Reinforcing LLMs for Long-Term Memory Construction via Attributed Dense Rewards](https://arxiv.org/abs/2601.05488)
*Zhiyu Shen,Ziming Wu,Fuming Lai,Shaobing Lian,Yanghui Rao*

Main category: cs.CL

TL;DR: MemBuilder是一个使用强化学习框架来训练模型进行多维度记忆构建的系统，解决了长对话中历史状态不一致的问题，并取得了优于最先进闭源模型的性能。


<details>
  <summary>Details</summary>
Motivation: 标准检索机制在处理长对话的历史状态演变时存在不足，现有的记忆增强框架要么依赖静态提示，要么训练范式无效且奖励稀疏。因此，需要一种更有效的记忆构建方法来维持长对话中的一致性。

Method: MemBuilder是一个强化学习框架，通过以下方法训练模型进行多维度记忆构建：1. 解决稀疏奖励问题：生成合成的会话级问题，为长对话轨迹提供密集的中间奖励。2. 解决多维度记忆归因问题：引入贡献感知梯度加权，根据每个组件的下游影响来调整策略更新。

Result: 实验表明，MemBuilder能够让一个40亿参数的模型在长对话基准测试中表现优于最先进的闭源基线模型，并展现出良好的泛化能力。

Conclusion: MemBuilder是一个有效的强化学习框架，能够通过密集的中间奖励和贡献感知梯度加权，训练模型在长对话中构建和利用多维度记忆，从而克服现有方法的局限性，并达到先进的性能水平。

Abstract: Maintaining consistency in long-term dialogues remains a fundamental challenge for LLMs, as standard retrieval mechanisms often fail to capture the temporal evolution of historical states. While memory-augmented frameworks offer a structured alternative, current systems rely on static prompting of closed-source models or suffer from ineffective training paradigms with sparse rewards. We introduce MemBuilder, a reinforcement learning framework that trains models to orchestrate multi-dimensional memory construction with attributed dense rewards. MemBuilder addresses two key challenges: (1) Sparse Trajectory-Level Rewards: we employ synthetic session-level question generation to provide dense intermediate rewards across extended trajectories; and (2) Multi-Dimensional Memory Attribution: we introduce contribution-aware gradient weighting that scales policy updates based on each component's downstream impact. Experimental results show that MemBuilder enables a 4B-parameter model to outperform state-of-the-art closed-source baselines, exhibiting strong generalization across long-term dialogue benchmarks.

</details>


### [98] [FlashMem: Distilling Intrinsic Latent Memory via Computation Reuse](https://arxiv.org/abs/2601.05505)
*Yubo Hou,Zhisheng Chen,Tao Wan,Zengchang Qin*

Main category: cs.CL

TL;DR: FlashMem 提出了一种直接从大型语言模型（LLM）的瞬态推理状态中提取记忆的方法，通过计算复用和共享键值（KV）合并器，减少了推理延迟，同时保持了与现有方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 由于其无状态架构，在处理长时依赖任务时存在固有的信息丢失问题，需要重复处理历史信息。虽然有基于潜在记忆的方法，但它们通常将记忆模块与推理主干分离，增加了复杂性。

Method: FlashMem 框架通过计算复用，直接从 LLM 的推理状态中提取内在记忆。它将最后一个隐藏状态视为交互历史的充分统计量，并利用一个共享 KV 合并器直接从主干的冻结缓存中合成记忆，避免了参数的重复。此外，一个无参数的认知监视器利用注意力熵来适应性地触发记忆巩固，仅在高认知不确定性时进行。

Result: FlashMem 在实验中取得了与更复杂的基线方法相当的性能，同时将推理延迟降低了 5 倍。

Conclusion: FlashMem 有效地解决了 LLM 的无状态性问题，通过一种高效的记忆提取和巩固机制，在保持推理能力的同时显著提高了效率，实现了效率与持续认知的平衡。

Abstract: The stateless architecture of Large Language Models inherently lacks the mechanism to preserve dynamic context, compelling agents to redundantly reprocess history to maintain long-horizon autonomy. While latent memory offers a solution, current approaches are hindered by architectural segregation, relying on auxiliary encoders that decouple memory from the reasoning backbone. We propose FlashMem, a framework that distills intrinsic memory directly from transient reasoning states via computation reuse. Leveraging the property that internal representations uniquely encode input trajectories, FlashMem identifies the last hidden state as a sufficient statistic for the interaction history. This enables a Shared-KV Consolidator to synthesize memory by attending directly to the backbone's frozen cache, eliminating redundant re-parameterization. Furthermore, a parameter-free Cognitive Monitor leverages attention entropy to adaptively trigger consolidation only when high epistemic uncertainty is detected. Experiments demonstrate that FlashMem matches the performance of heavy baselines while reducing inference latency by 5 times, effectively bridging the gap between efficiency and persistent cognition.

</details>


### [99] [CHisAgent: A Multi-Agent Framework for Event Taxonomy Construction in Ancient Chinese Cultural Systems](https://arxiv.org/abs/2601.05520)
*Xuemei Tang,Chengxi Yan,Jinghang Gu,Chu-Ren Huang*

Main category: cs.CL

TL;DR: 提出了一种名为CHisAgent的多智能体LLM框架，用于构建中国古代历史领域领域的事件分类法，该框架通过归纳、扩展和丰富三个阶段，并取得了良好的结构一致性和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在历史和文化推理方面能力有限，尤其是在非英语背景（如中国历史）下。手动构建分类法成本高昂且难以扩展。因此，需要一种自动化的方法来构建历史知识的分类法。

Method: 提出了CHisAgent，一个包含三个角色专用智能体（Inducer, Expander, Enricher）的多智能体LLM框架。Inducer从原始语料库自底向上生成初始层级；Expander利用LLM的背景知识自顶向下引入缺失的中间概念；Enricher则整合外部结构化历史资源以确保准确性。

Result: 使用《二十四史》构建了一个大规模、领域感知的中国古代事件分类法，涵盖政治、军事、外交和社会生活等领域。评估结果表明，该分类法在结构一致性和覆盖率方面有所提升，并且能够支持跨文化对齐。

Conclusion: CHisAgent框架能够有效地自动构建中国古代历史领域的事件分类法，克服了手动构建的限制，并提高了LLM在历史推理方面的能力。

Abstract: Despite strong performance on many tasks, large language models (LLMs) show limited ability in historical and cultural reasoning, particularly in non-English contexts such as Chinese history. Taxonomic structures offer an effective mechanism to organize historical knowledge and improve understanding. However, manual taxonomy construction is costly and difficult to scale. Therefore, we propose \textbf{CHisAgent}, a multi-agent LLM framework for historical taxonomy construction in ancient Chinese contexts. CHisAgent decomposes taxonomy construction into three role-specialized stages: a bottom-up \textit{Inducer} that derives an initial hierarchy from raw historical corpora, a top-down \textit{Expander} that introduces missing intermediate concepts using LLM world knowledge, and an evidence-guided \textit{Enricher} that integrates external structured historical resources to ensure faithfulness. Using the \textit{Twenty-Four Histories}, we construct a large-scale, domain-aware event taxonomy covering politics, military, diplomacy, and social life in ancient China. Extensive reference-free and reference-based evaluations demonstrate improved structural coherence and coverage, while further analysis shows that the resulting taxonomy supports cross-cultural alignment.

</details>


### [100] [Double: Breaking the Acceleration Limit via Double Retrieval Speculative Parallelism](https://arxiv.org/abs/2601.05524)
*Yuhao Shen,Tianyu Liu,Junyi Shen,Jinyang Wu,Quan Kong,Li Huan,Cong Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为Double的新型框架，通过引入迭代检索和多令牌指导，解决了并行推测解码（PSD）的理论加速上限和计算浪费问题，实现了显著的推理加速。


<details>
  <summary>Details</summary>
Motivation: 现有的并行推测解码（PSD）方法虽然能加速模型推理，但存在理论加速上限（受草稿模型和目标模型速度比限制）以及因早期错误导致的计算浪费和管道停滞问题。研究旨在克服这些限制。

Method: 提出了一种名为Double的新型框架，通过引入一种同步机制来解决“检索精度-效率困境”。具体来说，草稿模型执行迭代检索推测以突破理论加速限制；目标模型进行权威检索以生成多令牌指导，从而减少回滚和拒绝。Double框架无需额外训练，并且是无损的。

Result: 在LLaMA3.3-70B模型上实现了5.3倍的加速，在Qwen3-32B模型上实现了2.8倍的加速，显著优于需要大量模型训练的先进方法EAGLE-3。

Conclusion: Double框架是一种训练无关且无损的推测解码方法，通过解决PSD的固有挑战，能够有效地提高大型语言模型的推理速度，并在实际应用中取得了优异的性能。

Abstract: Parallel Speculative Decoding (PSD) accelerates traditional Speculative Decoding (SD) by overlapping draft generation with verification. However, it remains hampered by two fundamental challenges: (1) a theoretical speedup ceiling dictated by the speed ratio between the draft and target models, and (2) high computational waste and pipeline stall due to mid-sequence token rejections of early errors. To address these limitations, we introduce \textsc{Double} (Double Retrieval Speculative Parallelism). By bridging the gap between SD and PSD, our framework resolves the Retrieval \emph{Precision-Efficiency Dilemma} through a novel synchronous mechanism. Specifically, we enable the draft model to execute iterative retrieval speculations to break the theoretical speedup limits; to alleviate rejections without rollback, the target model performs authoritative retrieval to generate multi-token guidance. \textsc{Double} is entirely training-free and lossless. Extensive experiments demonstrate state-of-the-art speedup of $\textbf{5.3}\times$ on LLaMA3.3-70B and $\textbf{2.8}\times$ on Qwen3-32B, significantly outperforming the advanced method EAGLE-3 that requires extensive model training.

</details>


### [101] [Closing the Modality Reasoning Gap for Speech Large Language Models](https://arxiv.org/abs/2601.05543)
*Chaoren Wang,Heng Lu,Xueyao Zhang,Shujie Liu,Yan Lu,Jinyu Li,Zhizheng Wu*

Main category: cs.CL

TL;DR: 本文提出了TARS框架，通过强化学习和不对称奖励设计，缩小数模语音大模型在语音输入时的推理能力与文本输入时的差距，并在MMSU和OBQA等基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语音大语言模型在语音输入上的推理能力远弱于文本输入，存在明显的模态推理鸿沟，这可能与Transformer层间的表示漂移和长链推理行为偏差有关。

Method: 提出TARS框架，一个强化学习框架，通过不对称奖励设计来对齐文本条件和语音条件的轨迹。该框架利用两种信号：表示对齐（衡量语音和文本条件轨迹之间逐层的隐藏状态相似性）和行为对齐（评估生成输出与参考文本补全之间的语义一致性）。

Result: 在MMSU和OBQA等具有挑战性的推理基准测试上，TARS显著缩小了模态推理鸿沟，并在7B规模的语音LLM中达到了最先进的性能。

Conclusion: TARS框架有效地解决了语音大语言模型在语音输入时的推理能力不足问题，通过表示对齐和行为对齐，显著提升了其在长链推理任务上的表现。

Abstract: Although speech large language models have achieved notable progress, a substantial modality reasoning gap remains: their reasoning performance on speech inputs is markedly weaker than on text. This gap could be associated with representational drift across Transformer layers and behavior deviations in long-chain reasoning. To address this issue, we introduce TARS, a reinforcement-learning framework that aligns text-conditioned and speech-conditioned trajectories through an asymmetric reward design. The framework employs two dense and complementary signals: representation alignment, which measures layer-wise hidden-state similarity between speech- and text-conditioned trajectories, and behavior alignment, which evaluates semantic consistency between generated outputs and reference text completions. Experiments on challenging reasoning benchmarks, including MMSU and OBQA, show that our approach significantly narrows the modality reasoning gap and achieves state-of-the-art performance among 7B-scale Speech LLMs.

</details>


### [102] [Can Large Language Models Differentiate Harmful from Argumentative Essays? Steps Toward Ethical Essay Scoring](https://arxiv.org/abs/2601.05545)
*Hongjin Kim,Jeonghyun Kang,Harksoo Kim*

Main category: cs.CL

TL;DR: 现有自动评分（AES）和大型语言模型（LLMs）在识别和评分有害论文方面存在不足，容易给传播有害观点的论文打高分。本研究提出了有害论文检测（HED）基准，以测试LLMs识别和评分包含种族主义和性别歧视等敏感主题的论文的能力。结果表明，LLMs需要改进才能区分有害和论证性论文，并且当前的AES模型和LLMs在评分时都未能考虑内容的道德层面。


<details>
  <summary>Details</summary>
Motivation: 现有自动评分（AES）系统和大型语言模型（LLMs）在识别和评分有害论文方面存在关键不足，可能会给传播有害观点的论文错误地打高分。因此，需要研究和开发能够有效处理这类问题的模型。

Method: 引入了包含种族主义和性别歧视等敏感话题的有害论文检测（HED）基准。利用该基准测试了不同LLMs识别和评分有害内容的能力。

Result: 1. LLMs需要进一步增强才能准确区分有害论文和论证性论文。2. 当前的AES模型和LLMs在评分时均未能考虑内容的道德维度。

Conclusion: 现有自动评分系统（包括AES和LLMs）在处理包含有害内容的论文时存在重大局限性。迫切需要开发对内容道德含义更敏感的、更强大的AES系统。

Abstract: This study addresses critical gaps in Automated Essay Scoring (AES) systems and Large Language Models (LLMs) with regard to their ability to effectively identify and score harmful essays. Despite advancements in AES technology, current models often overlook ethically and morally problematic elements within essays, erroneously assigning high scores to essays that may propagate harmful opinions. In this study, we introduce the Harmful Essay Detection (HED) benchmark, which includes essays integrating sensitive topics such as racism and gender bias, to test the efficacy of various LLMs in recognizing and scoring harmful content. Our findings reveal that: (1) LLMs require further enhancement to accurately distinguish between harmful and argumentative essays, and (2) both current AES models and LLMs fail to consider the ethical dimensions of content during scoring. The study underscores the need for developing more robust AES systems that are sensitive to the ethical implications of the content they are scoring.

</details>


### [103] [Generation-Based and Emotion-Reflected Memory Update: Creating the KEEM Dataset for Better Long-Term Conversation](https://arxiv.org/abs/2601.05548)
*Jeonghyun Kang,Hongjin Kim,Harksoo Kim*

Main category: cs.CL

TL;DR: 本文介绍了KEEM数据集，一个用于改善长时对话系统记忆更新的生成式数据集，它能整合事实信息、情感背景和因果关系，实现更细致的用户互动理解。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统在记忆更新方面存在信息冲突和难以追踪用户当前状态的问题，研究旨在通过生成式方法解决这些不足，提升系统对用户互动的理解和响应能力。

Method: 引入KEEM数据集，一种生成式数据集，用于动态生成整合了情感和事实信息的记忆，并考虑因果关系，从而实现无缝记忆更新。

Result: KEEM数据集能够保存关键事实信息，并纳入情感背景和因果关系，从而实现对用户互动的更细致理解，促进系统产生更富同理心和有意义的回应。

Conclusion: KEEM数据集通过整合情感和基本数据来更新系统记忆，有助于提升开放域对话系统中用户互动的深度共情和响应能力。

Abstract: In this work, we introduce the Keep Emotional and Essential Memory (KEEM) dataset, a novel generation-based dataset designed to enhance memory updates in long-term conversational systems. Unlike existing approaches that rely on simple accumulation or operation-based methods, which often result in information conflicts and difficulties in accurately tracking a user's current state, KEEM dynamically generates integrative memories. This process not only preserves essential factual information but also incorporates emotional context and causal relationships, enabling a more nuanced understanding of user interactions. By seamlessly updating a system's memory with both emotional and essential data, our approach promotes deeper empathy and enhances the system's ability to respond meaningfully in open-domain conversations.

</details>


### [104] [ReasonAny: Incorporating Reasoning Capability to Any Model via Simple and Effective Model Merging](https://arxiv.org/abs/2601.05560)
*Junyao Yang,Chen Qian,Dongrui Liu,Wen Shen,Yong Liu,Jing Shao*

Main category: cs.CL

TL;DR: 提出了一种名为ReasonAny的新模型合并框架，通过对比梯度识别来解决大型推理模型（LRMs）在通用能力和领域特定能力之间进行合并时出现的性能崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有的模型合并方法在为领域专业模型添加长链思考推理能力时，会同时削弱推理深度和领域特定效用。研究者发现，推理能力主要存在于梯度敏感性低的参数区域，而领域能力对应高幅度参数，这一反直觉的现象是导致性能崩溃的原因。

Method: 提出ReasonAny框架，采用对比梯度识别（Contrastive Gradient Identification）技术，识别并保留推理能力所依赖的低梯度敏感性参数区域，同时融合领域特定能力。

Result: 在安全、生物医学和金融领域进行的实验表明，ReasonAny能够有效地合成“推理+X”能力，显著优于最先进的基线方法，并保持强大的推理性能。

Conclusion: ReasonAny框架通过利用梯度敏感性分析，成功解决了大型推理模型在融合推理能力和领域特定能力时遇到的性能崩溃难题，有效提升了“推理+X”模型的综合表现。

Abstract: Large Reasoning Models (LRMs) with long chain-of-thought reasoning have recently achieved remarkable success. Yet, equipping domain-specialized models with such reasoning capabilities, referred to as "Reasoning + X", remains a significant challenge. While model merging offers a promising training-free solution, existing methods often suffer from a destructive performance collapse: existing methods tend to both weaken reasoning depth and compromise domain-specific utility. Interestingly, we identify a counter-intuitive phenomenon underlying this failure: reasoning ability predominantly resides in parameter regions with low gradient sensitivity, contrary to the common assumption that domain capabilities correspond to high-magnitude parameters. Motivated by this insight, we propose ReasonAny, a novel merging framework that resolves the reasoning-domain performance collapse through Contrastive Gradient Identification. Experiments across safety, biomedicine, and finance domains show that ReasonAny effectively synthesizes "Reasoning + X" capabilities, significantly outperforming state-of-the-art baselines while retaining robust reasoning performance.

</details>


### [105] [Can large language models interpret unstructured chat data on dynamic group decision-making processes? Evidence on joint destination choice](https://arxiv.org/abs/2601.05582)
*Sung-Yoo Lim,Koki Sato,Kiyoshi Takami,Giancarlos Parady,Eui-Jin Kim*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）在解读日本群体聊天数据中的联合外出活动决策过程方面的自动化潜力。通过设计一种知识获取启发的提示框架，LLMs能够将非结构化对话转化为结构化的决策因素数据。研究发现，LLMs能够可靠地提取明确的决策因素，但在识别隐含因素方面存在困难，这表明在某些情况下仍然需要人工审查。


<details>
  <summary>Details</summary>
Motivation: 传统的出行调查难以捕捉社交活动中复杂的群体决策过程。而非结构化的聊天数据（如群聊）为理解这些过程提供了新的视角。然而，解读这些数据需要耗费大量人力进行手动标注，以理解受社会文化规范影响的上下文含义。因此，研究旨在探索利用LLMs自动补充或替代人工标注，以更高效地解读这些数据。

Method: 研究人员设计了一个受知识获取过程启发的提示框架，用于指导LLMs处理日本群聊数据。该框架分步提取关键决策因素，包括：群体的餐厅选择集和最终选择；每种备选餐厅的个人偏好；以及驱动这些偏好的具体属性。这种结构化的方法将非结构化的对话转化为描述决策因素的结构化表格数据。研究通过与人工标注的地面真实数据集进行量化分析，并进行定性误差分析来评估LLM的输出。

Result: 实验结果表明，LLMs能够可靠地捕捉明确的决策因素（如餐厅名称、时间等）。然而，在识别人类标注者轻易识别的细微的、隐含的决策因素（如对特定氛围或服务的要求）方面，LLMs表现出一定的困难。研究还指出了LLM驱动的提取在何种情况下可以信赖，以及何时仍需人工监督的具体情境。

Conclusion: 本研究揭示了基于LLMs分析的潜力和局限性。LLMs在自动化处理非传统数据源（如群聊）以理解社交活动中的决策过程方面具有巨大潜力，特别是在提取明确信息方面。然而，对于需要理解深层社会文化语境的隐含因素，目前的LLMs仍需人工的辅助和监督。未来的工作需要进一步改进LLMs在理解上下文和细微差别方面的能力。

Abstract: Social activities result from complex joint activity-travel decisions between group members. While observing the decision-making process of these activities is difficult via traditional travel surveys, the advent of new types of data, such as unstructured chat data, can help shed some light on these complex processes. However, interpreting these decision-making processes requires inferring both explicit and implicit factors. This typically involves the labor-intensive task of manually annotating dialogues to capture context-dependent meanings shaped by the social and cultural norms. This study evaluates the potential of Large Language Models (LLMs) to automate and complement human annotation in interpreting decision-making processes from group chats, using data on joint eating-out activities in Japan as a case study. We designed a prompting framework inspired by the knowledge acquisition process, which sequentially extracts key decision-making factors, including the group-level restaurant choice set and outcome, individual preferences of each alternative, and the specific attributes driving those preferences. This structured process guides the LLM to interpret group chat data, converting unstructured dialogues into structured tabular data describing decision-making factors. To evaluate LLM-driven outputs, we conduct a quantitative analysis using a human-annotated ground truth dataset and a qualitative error analysis to examine model limitations. Results show that while the LLM reliably captures explicit decision-making factors, it struggles to identify nuanced implicit factors that human annotators readily identified. We pinpoint specific contexts when LLM-based extraction can be trusted versus when human oversight remains essential. These findings highlight both the potential and limitations of LLM-based analysis for incorporating non-traditional data sources on social activities.

</details>


### [106] [ACR: Adaptive Context Refactoring via Context Refactoring Operators for Multi-Turn Dialogue](https://arxiv.org/abs/2601.05589)
*Jiawei Shen,Jia Zhu,Hanghui Guo,Weijie Shi,Yue Cui,Qingyu Niu,Guoqing Ma,Yidan Liang,Jingjiang Liu,Yiling Wang,Shimin Di,Jiajie Xu*

Main category: cs.CL

TL;DR: 本文提出了自适应上下文重构（ACR）框架，通过动态监控和重塑对话历史来解决大型语言模型（LLMs）在多轮对话中出现的上下文惯性和状态漂移问题，有效提升了对话的连贯性和事实准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLMs在多轮对话中存在难以保持与早期对话内容一致、难以遵循跨多轮依赖关系以及易在长对话中出现事实错误（即上下文惯性和状态漂移）等问题。

Method: 提出自适应上下文重构（ACR）框架，该框架包含一个上下文重构算子库和一个教师引导的自演化训练范式。ACR能够动态监控和重塑交互历史，主动减轻上下文惯性和状态漂移，并将上下文管理与推理过程解耦。

Result: 在多轮对话的广泛实验中，ACR显著优于现有基线方法，并减少了令牌消耗。

Conclusion: ACR框架有效地解决了多轮对话中的上下文惯性和状态漂移问题，能够显著提升LLMs在长对话中的表现，并且更加高效。

Abstract: Large Language Models (LLMs) have shown remarkable performance in multi-turn dialogue. However, in multi-turn dialogue, models still struggle to stay aligned with what has been established earlier, follow dependencies across many turns, and avoid drifting into incorrect facts as the interaction grows longer. Existing approaches primarily focus on extending the context window, introducing external memory, or applying context compression, yet these methods still face limitations such as \textbf{contextual inertia} and \textbf{state drift}. To address these challenges, we propose the \textbf{A}daptive \textbf{C}ontext \textbf{R}efactoring \textbf{(ACR)} Framework, which dynamically monitors and reshapes the interaction history to mitigate contextual inertia and state drift actively. ACR is built on a library of context refactoring operators and a teacher-guided self-evolving training paradigm that learns when to intervene and how to refactor, thereby decoupling context management from the reasoning process. Extensive experiments on multi-turn dialogue demonstrate that our method significantly outperforms existing baselines while reducing token consumption.

</details>


### [107] [Data Augmented Pipeline for Legal Information Extraction and Reasoning](https://arxiv.org/abs/2601.05609)
*Nguyen Minh Phuong,Ha-Thanh Nguyen,May Myo Zin,Ken Satoh*

Main category: cs.CL

TL;DR: 本文提出了一种利用大型语言模型（LLM）为法律领域信息抽取任务进行数据增强的流水线方法。


<details>
  <summary>Details</summary>
Motivation: 现有信息抽取任务在法律领域需要大量手动标注数据，耗时耗力，且系统鲁棒性有待提高。

Method: 利用大型语言模型（LLM）生成用于数据增强的文本数据，以简化数据标注过程并提高信息抽取系统的鲁棒性。

Result: 该方法显著减少了手动数据标注的工作量，并提高了信息抽取系统的鲁棒性。

Conclusion: 提出的基于LLM的数据增强流水线方法简单有效，可推广应用于法律领域及其他自然语言处理任务。

Abstract: In this paper, we propose a pipeline leveraging Large Language Models (LLMs) for data augmentation in Information Extraction tasks within the legal domain. The proposed method is both simple and effective, significantly reducing the manual effort required for data annotation while enhancing the robustness of Information Extraction systems. Furthermore, the method is generalizable, making it applicable to various Natural Language Processing (NLP) tasks beyond the legal domain.

</details>


### [108] [Text Detoxification in isiXhosa and Yorùbá: A Cross-Lingual Machine Learning Approach for Low-Resource African Languages](https://arxiv.org/abs/2601.05624)
*Abayomi O. Agbeyangi*

Main category: cs.CL

TL;DR: 本研究提出了一个混合方法，用于自动将非洲低资源语言（isiXhosa 和 Yorùbá）中的有毒文本改写为中性文本，以解决在线安全参与的障碍。该方法结合了易于理解的 TF-IDF 和逻辑回归模型用于毒性检测，以及一个受词典和标记指导的改写组件。研究人员还构建了一个平行语料库来训练和评估模型。


<details>
  <summary>Details</summary>
Motivation: 在线参与受到有毒语言的阻碍，但非洲语言缺乏有效的缓解工具，因此研究者旨在填补这一关键空白。

Method: 研究采用了一种新颖的混合方法，包括：1. 一个轻量级、可解释的 TF-IDF 和逻辑回归模型，用于透明的毒性检测。2. 一个受词典和标记指导的改写组件。此外，还开发了一个包含有毒到中性改写的平行语料库。

Result: 毒性检测组件在 isiXhosa 语言上实现了 61-72% 的准确率，在 Yorùbá 语言上实现了 72-86% 的准确率，ROC-AUC 高达 0.88。改写组件成功地将所有检测到的有毒句子去毒化，同时保留了 100% 的非有毒句子。

Conclusion: 研究表明，可扩展、可解释的机器学习检测器与基于规则的编辑相结合，可以为非洲语言提供有竞争力的、资源高效且具有文化适应性的安全工具，为低资源语言的文本风格迁移树立了新的标杆。

Abstract: Toxic language is one of the major barrier to safe online participation, yet robust mitigation tools are scarce for African languages. This study addresses this critical gap by investigating automatic text detoxification (toxic to neutral rewriting) for two low-resource African languages, isiXhosa and Yorùbá. The work contributes a novel, pragmatic hybrid methodology: a lightweight, interpretable TF-IDF and Logistic Regression model for transparent toxicity detection, and a controlled lexicon- and token-guided rewriting component. A parallel corpus of toxic to neutral rewrites, which captures idiomatic usage, diacritics, and code switching, was developed to train and evaluate the model. The detection component achieved stratified K-fold accuracies of 61-72% (isiXhosa) and 72-86% (Yorùbá), with per-language ROC-AUCs up to 0.88. The rewriting component successfully detoxified all detected toxic sentences while preserving 100% of non-toxic sentences. These results demonstrate that scalable, interpretable machine learning detectors combined with rule-based edits offer a competitive and resource-efficient solution for culturally adaptive safety tooling, setting a new benchmark for low-resource Text Style Transfer (TST) in African languages.

</details>


### [109] [GIFT: Games as Informal Training for Generalizable LLMs](https://arxiv.org/abs/2601.05633)
*Nuoyan Lyu,Bingbing Xu,Weihao Meng,Yige Yuan,Yang Zhang,Zhiyong Huang,Tat-Seng Chua,Huawei Shen*

Main category: cs.CL

TL;DR: 本研究提出将游戏作为大型语言模型（LLM）进行非正式学习的环境，并引入嵌套训练框架来解决多任务学习中的性能下降问题，以提升LLM的通用智能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在形式化学习任务上表现出色，但在战略创造和社会推理等需要“实践智慧”和通用智能的方面仍有不足，这源于其缺乏基于交互反馈的非正式学习能力。

Method: 将游戏环境引入LLM的非正式学习，利用游戏的内在奖励信号和抽象复杂度来培养模型能力。提出嵌套训练框架，通过顺序任务组合来解决多任务学习中的“或”目标问题，强制模型同时掌握多种能力以达到最大奖励。使用基于GRPO的强化学习在矩阵博弈、TicTacToe和Who's the Spy等游戏中进行训练。

Result: 在多种游戏环境中进行训练，证明了基于游戏的非正式学习不仅能防止任务干扰，还能显著提升模型在广泛能力导向基准上的泛化能力。

Conclusion: 游戏环境和嵌套训练框架能有效提升LLM的非正式学习能力和通用智能，克服了传统多任务学习中的性能瓶颈。

Abstract: While Large Language Models (LLMs) have achieved remarkable success in formal learning tasks such as mathematics and code generation, they still struggle with the "practical wisdom" and generalizable intelligence, such as strategic creativity and social reasoning, that characterize human cognition. This gap arises from a lack of informal learning, which thrives on interactive feedback rather than goal-oriented instruction. In this paper, we propose treating Games as a primary environment for LLM informal learning, leveraging their intrinsic reward signals and abstracted complexity to cultivate diverse competencies. To address the performance degradation observed in multi-task learning, we introduce a Nested Training Framework. Unlike naive task mixing optimizing an implicit "OR" objective, our framework employs sequential task composition to enforce an explicit "AND" objective, compelling the model to master multiple abilities simultaneously to achieve maximal rewards. Using GRPO-based reinforcement learning across Matrix Games, TicTacToe, and Who's the Spy games, we demonstrate that integrating game-based informal learning not only prevents task interference but also significantly bolsters the model's generalization across broad ability-oriented benchmarks. The framework and implementation are publicly available.

</details>


### [110] [Multilingual Amnesia: On the Transferability of Unlearning in Multilingual LLMs](https://arxiv.org/abs/2601.05641)
*Alireza Dehghanpour Farashah,Aditi Khandelwal,Marylou Fauchard,Zhuan Shi,Negar Rostamzadeh,Golnoosh Farnadi*

Main category: cs.CL

TL;DR: 本研究探讨了多语言大语言模型（Aya-Expanse 8B）在数据和概念层面上的多语言机器学习遗忘问题，并在十种不同语言（包括高资源和低资源语言）上进行了实验，发现高资源语言遗忘更稳定，且句法相似性是影响跨语言遗忘行为的最强预测因素。


<details>
  <summary>Details</summary>
Motivation: 随着多语言大语言模型的广泛应用，如何在不同语言环境下确保其安全性和公平性变得日益重要。现有机器学习遗忘的研究主要集中在单语（尤其是英语）环境，而多语言环境由于跨语言知识迁移和预训练/微调数据中嵌入的偏见，带来了额外的复杂性。

Method: 研究者使用Aya-Expanse 8B模型，在两种场景下研究多语言机器学习遗忘：（1）数据遗忘和（2）概念遗忘。他们通过翻译将事实知识和刻板印象的基准扩展到十种语言（英语、法语、阿拉伯语、日语、俄语、波斯语、韩语、印地语、希伯来语和印度尼西亚语），这些语言跨越五个语系且资源水平各异。通过实验分析了遗忘的稳定性、跨语言迁移效应以及语言距离（尤其是句法相似性）对遗忘行为的影响。

Result: 实验结果表明，高资源语言的遗忘通常更稳定。研究观察到了非对称的迁移效应，特别是在语言类型学上相关的语言之间。对语言距离的分析显示，句法相似性是预测跨语言遗忘行为的最强因素。

Conclusion: 多语言机器学习遗忘是一个复杂的问题，其效果受到语言资源水平和语言自身特征（如句法相似性）的影响。高资源语言的遗忘更为可靠，而语言之间的句法相似性是影响跨语言遗忘效果的关键因素。

Abstract: As multilingual large language models become more widely used, ensuring their safety and fairness across diverse linguistic contexts presents unique challenges. While existing research on machine unlearning has primarily focused on monolingual settings, typically English, multilingual environments introduce additional complexities due to cross-lingual knowledge transfer and biases embedded in both pretraining and fine-tuning data. In this work, we study multilingual unlearning using the Aya-Expanse 8B model under two settings: (1) data unlearning and (2) concept unlearning. We extend benchmarks for factual knowledge and stereotypes to ten languages through translation: English, French, Arabic, Japanese, Russian, Farsi, Korean, Hindi, Hebrew, and Indonesian. These languages span five language families and a wide range of resource levels. Our experiments show that unlearning in high-resource languages is generally more stable, with asymmetric transfer effects observed between typologically related languages. Furthermore, our analysis of linguistic distances indicates that syntactic similarity is the strongest predictor of cross-lingual unlearning behavior.

</details>


### [111] [A Framework for Personalized Persuasiveness Prediction via Context-Aware User Profiling](https://arxiv.org/abs/2601.05654)
*Sejun Park,Yoonah Park,Jongwon Lim,Yohan Jo*

Main category: cs.CL

TL;DR: 本研究提出了一种新的上下文感知用户画像框架，通过生成最优查询检索用户历史记录并进行总结，以提高说服力预测模型的性能，并在Reddit数据集上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统和大型语言模型安全性评估等应用中，准确估计信息说服力至关重要。然而，现有方法未能系统地利用用户的个体特征（如价值观、经验、推理风格）和过往活动来优化说服力预测模型。

Method: 提出一个包含两个可训练组件的上下文感知用户画像框架：1. 查询生成器：生成最优查询以从用户历史记录中检索与说服力相关的记录；2. 画像生成器：总结检索到的记录，形成能够有效告知说服力预测模型的用户画像。

Result: 在ChangeMyView Reddit数据集上的评估显示，该框架在F1分数上比现有方法有高达+13.77%的提升。进一步分析表明，有效用户画像是上下文依赖和预测器特定的，而非依赖于静态属性或表层相似性。

Conclusion: 研究强调了任务导向、上下文依赖的用户画像对于个性化说服力预测的重要性。

Abstract: Estimating the persuasiveness of messages is critical in various applications, from recommender systems to safety assessment of LLMs. While it is imperative to consider the target persuadee's characteristics, such as their values, experiences, and reasoning styles, there is currently no established systematic framework to optimize leveraging a persuadee's past activities (e.g., conversations) to the benefit of a persuasiveness prediction model. To address this problem, we propose a context-aware user profiling framework with two trainable components: a query generator that generates optimal queries to retrieve persuasion-relevant records from a user's history, and a profiler that summarizes these records into a profile to effectively inform the persuasiveness prediction model. Our evaluation on the ChangeMyView Reddit dataset shows consistent improvements over existing methods across multiple predictor models, with gains of up to +13.77%p in F1 score. Further analysis shows that effective user profiles are context-dependent and predictor-specific, rather than relying on static attributes or surface-level similarity. Together, these results highlight the importance of task-oriented, context-dependent user profiling for personalized persuasiveness prediction.

</details>


### [112] [Stephanie2: Thinking, Waiting, and Making Decisions Like Humans in Step-by-Step AI Social Chat](https://arxiv.org/abs/2601.05657)
*Hao Yang,Hongyuan Lu,Dingkang Yang,Wenliang Yang,Peng Sun,Xiaochuan Zhang,Jun Xiao,Kefan He,Wai Lam,Yang Liu,Xinhua Zeng*

Main category: cs.CL

TL;DR: 本文提出了一种名为Stephanie2的下一代分步决策对话代理，通过主动等待和消息节奏自适应，实现了比以往系统更自然的消息发送时机和节奏，并在图灵测试中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有的一键式AI聊天系统在生成多条消息时缺乏主动等待机制，消息发送节奏不自然，用户体验不佳。

Method: Stephanie2是一种分步决策对话代理，在每一步都显式地决定发送消息还是等待。它将延迟建模为思考时间和打字时间之和，以实现更自然的消息节奏。此外，还引入了一个基于时间窗口的双代理对话系统，用于生成伪对话历史以进行人工和自动评估。

Result: 实验表明，Stephanie2在自然度和参与度等指标上显著优于Stephanie1，并且在角色识别图灵测试中的人工评估通过率更高。

Conclusion: Stephanie2通过引入主动等待和消息节奏自适应，成功解决了现有AI聊天系统中消息发送不自然的问题，实现了更接近人类的对话交互体验。

Abstract: Instant-messaging human social chat typically progresses through a sequence of short messages. Existing step-by-step AI chatting systems typically split a one-shot generation into multiple messages and send them sequentially, but they lack an active waiting mechanism and exhibit unnatural message pacing. In order to address these issues, we propose Stephanie2, a novel next-generation step-wise decision-making dialogue agent. With active waiting and message-pace adaptation, Stephanie2 explicitly decides at each step whether to send or wait, and models latency as the sum of thinking time and typing time to achieve more natural pacing. We further introduce a time-window-based dual-agent dialogue system to generate pseudo dialogue histories for human and automatic evaluations. Experiments show that Stephanie2 clearly outperforms Stephanie1 on metrics such as naturalness and engagement, and achieves a higher pass rate on human evaluation with the role identification Turing test.

</details>


### [113] [Afri-MCQA: Multimodal Cultural Question Answering for African Languages](https://arxiv.org/abs/2601.05699)
*Atnafu Lambebo Tonja,Srija Anand,Emilio Villa-Cueva,Israel Abebe Azime,Jesujoba Oluwadara Alabi,Muhidin A. Mohamed,Debela Desalegn Yadeta,Negasi Haile Abadi,Abigail Oppong,Nnaemeka Casmir Obiefuna,Idris Abdulmumin,Naome A Etori,Eric Peter Wairagala,Kanda Patrick Tshinu,Imanigirimbabazi Emmanuel,Gabofetswe Malema,Alham Fikri Aji,David Ifeoluwa Adelani,Thamar Solorio*

Main category: cs.CL

TL;DR: 本文提出了 Afri-MCQA，这是首个覆盖 15 种非洲语言的多语言文化问答基准，旨在解决非洲语言在人工智能研究中代表性不足的问题。对大型语言模型的测试表明，在文化理解和跨语言能力方面存在显著差距，并呼吁采用侧重语音、文化接地预训练和跨语言文化迁移的方法。


<details>
  <summary>Details</summary>
Motivation: 非洲语言在人工智能研究中的代表性严重不足，而该地区拥有全球三分之一以上的语言，这促使研究者开发一个能反映非洲语言和文化多样性的基准。

Method: 研究者创建了一个包含 7.5k 问答对的多语言文化问答基准 Afri-MCQA，涵盖 12 个国家的 15 种非洲语言，并提供英文平行文本和语音数据。他们还对大型语言模型进行了基准测试，并设计了控制实验来评估语言能力。

Result: 在 Afri-MCQA 基准上，开放权重模型在评估的非洲文化方面表现不佳，尤其是在使用非洲本土语言或语音进行开放式视觉问答时准确率接近于零。此外，模型在本土语言和英语之间的文本和语音能力方面也存在显著差距。

Conclusion: 研究结果表明，大型语言模型在理解非洲文化和语言方面存在挑战，尤其是在多模态和跨语言的场景下。研究强调了采用语音优先方法、进行文化接地预训练以及促进跨语言文化迁移的必要性，以支持非洲语言更具包容性的多模态人工智能开发。Afri-MCQA 数据集已公开发布以支持此项工作。

Abstract: Africa is home to over one-third of the world's languages, yet remains underrepresented in AI research. We introduce Afri-MCQA, the first Multilingual Cultural Question-Answering benchmark covering 7.5k Q&A pairs across 15 African languages from 12 countries. The benchmark offers parallel English-African language Q&A pairs across text and speech modalities and was entirely created by native speakers. Benchmarking large language models (LLMs) on Afri-MCQA shows that open-weight models perform poorly across evaluated cultures, with near-zero accuracy on open-ended VQA when queried in native language or speech. To evaluate linguistic competence, we include control experiments meant to assess this specific aspect separate from cultural knowledge, and we observe significant performance gaps between native languages and English for both text and speech. These findings underscore the need for speech-first approaches, culturally grounded pretraining, and cross-lingual cultural transfer. To support more inclusive multimodal AI development in African languages, we release our Afri-MCQA under academic license or CC BY-NC 4.0 on HuggingFace (https://huggingface.co/datasets/Atnafu/Afri-MCQA)

</details>


### [114] [Multimodal In-context Learning for ASR of Low-resource Languages](https://arxiv.org/abs/2601.05707)
*Zhaolin Li,Jan Niehues*

Main category: cs.CL

TL;DR: 该研究探讨了大型语音语言模型（LLM）是否可以通过多模态上下文学习（MICL）来学习未见过的语言，并将其应用于改进自动语音识别（ASR）。实验表明，MICL在学习新语言方面是有效的，并且跨语言迁移学习可以提高MICL的效率。研究还分析了MICL的注意力机制，发现模型倾向于文本信息。最后，提出了一种结合强大声学模型和MICL的ASR系统，该系统在未见语言上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有自动语音识别（ASR）系统主要覆盖高资源语言，而对于数据稀缺的语言（尤其是濒危语言）支持不足。大型语言模型（LLM）的上下文学习（ICL）为解决数据稀缺问题提供了可能，但之前的工作主要集中在高资源语言和纯文本设置。本研究旨在探索语音LLM是否能通过多模态上下文学习（MICL）来学习未见过的语言，并研究如何利用MICL改进ASR。

Method: 研究使用了Phi-4和Qwen3-Omni两款语音LLM，在三种多样的濒危语言上进行了实验。首先，通过MICL直接在目标语言上进行上下文学习。其次，引入跨语言迁移学习，利用已见过的语言数据预训练模型，再应用于未见过的目标语言。接着，分析模型的注意力模式以解释MICL机制。最后，设计了一个结合了声学模型和语音LLM的ASR系统，利用MICL从声学假设中进行选择，以提升ASR性能。

Result: 1. MICL在学习未见过的语言方面是有效的，并且融合了语音和文本模态的信息。2. 跨语言迁移学习能提高MICL在目标语言上的效率，且无需在目标语言上进行训练。3. 注意力分析显示，模型在处理音频和文本上下文时存在层依赖偏好，整体上更偏向文本信息。4. 基于LLM的提示式ASR在未见语言上性能不佳，但通过MICL选择声学假设的ASR系统能持续提升性能。5. 跨语言迁移学习的ASR系统性能可与甚至优于在目标语言语料库上训练的语言模型，且无需使用目标语言数据。

Conclusion: 多模态上下文学习（MICL）是使大型语音语言模型（LLM）能够学习未见过的语言的有效方法，并且可以显著提升自动语音识别（ASR）系统在数据稀缺语言上的性能。跨语言迁移学习是提高MICL效率并缩小与传统方法性能差距的关键技术。虽然LLM对文本信息有偏好，但结合强大的声学模型和MICL的ASR系统能够成功克服数据稀缺的挑战。

Abstract: Automatic speech recognition (ASR) still covers only a small fraction of the world's languages, mainly due to supervised data scarcity. In-context learning (ICL) with large language models (LLMs) addresses this problem, but prior work largely focuses on high-resource languages covered during training and text-only settings. This paper investigates whether speech LLMs can learn unseen languages with multimodal ICL (MICL), and how this learning can be used to improve ASR. We conduct experiments with two speech LLMs, Phi-4 and Qwen3-Omni, on three diverse endangered languages. Firstly, we find that MICL is effective for unseen languages, leveraging both speech and text modalities. We further show that cross-lingual transfer learning improves MICL efficiency on target languages without training on them. Moreover, we analyze attention patterns to interpret MICL mechanisms, and we observe layer-dependent preferences between audio and text context, with an overall bias towards text. Finally, we show that prompt-based ASR with speech LLMs performs poorly on unseen languages, motivating a simple ASR system that combines a stronger acoustic model with a speech LLM via MICL-based selection of acoustic hypotheses. Results show that MICL consistently improves ASR performance, and that cross-lingual transfer learning matches or outperforms corpus-trained language models without using target-language data. Our code is publicly available.

</details>


### [115] [Visualising Information Flow in Word Embeddings with Diffusion Tensor Imaging](https://arxiv.org/abs/2601.05713)
*Thomas Fabian*

Main category: cs.CL

TL;DR: 本文提出一种将扩散张量成像（DTI）应用于词嵌入的新方法，用于分析和可视化自然语言表达式中的信息流，从而改进对大型语言模型（LLM）内部机制的理解。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过分析孤立的词嵌入来理解LLM，忽略了词语在特定上下文中的实际用法，这限制了对LLM表示能力的深入理解。

Method: 采用扩散张量成像（DTI）技术来分析和可视化LLM中的词嵌入信息流。通过追踪信息在LLM层级间的流动，对比不同模型结构，并分析特定任务（如代词消解和隐喻检测）下的信息流模式。

Result: DTI能够揭示词嵌入之间的信息流动机制。信息流分析有助于比较不同LLM结构，识别可优化（如剪枝）的低效层。此外，该方法还揭示了在代词消解和隐喻检测等任务中，信息流存在的差异。

Conclusion: 所提出的DTI方法为理解LLM如何表示自然语言表达式提供了新的视角，超越了对孤立词嵌入的简单比较，并提高了NLP模型的可解释性。

Abstract: Understanding how large language models (LLMs) represent natural language is a central challenge in natural language processing (NLP) research. Many existing methods extract word embeddings from an LLM, visualise the embedding space via point-plots, and compare the relative positions of certain words. However, this approach only considers single words and not whole natural language expressions, thus disregards the context in which a word is used. Here we present a novel tool for analysing and visualising information flow in natural language expressions by applying diffusion tensor imaging (DTI) to word embeddings. We find that DTI reveals how information flows between word embeddings. Tracking information flows within the layers of an LLM allows for comparing different model structures and revealing opportunities for pruning an LLM's under-utilised layers. Furthermore, our model reveals differences in information flows for tasks like pronoun resolution and metaphor detection. Our results show that our model permits novel insights into how LLMs represent actual natural language expressions, extending the comparison of isolated word embeddings and improving the interpretability of NLP models.

</details>


### [116] [Analysing Differences in Persuasive Language in LLM-Generated Text: Uncovering Stereotypical Gender Patterns](https://arxiv.org/abs/2601.05751)
*Amalie Brogaard Pauli,Maria Barrett,Max Müller-Eberstein,Isabelle Augenstein,Ira Assent*

Main category: cs.CL

TL;DR: 研究表明，大型语言模型在生成针对不同性别目标群体时的说服性语言会表现出显著的性别差异，这些差异与社会心理学和语言学中记录的性别刻板印象一致。


<details>
  <summary>Details</summary>
Motivation: 了解用户指令如何影响说服性语言的生成，以及这些语言是否会因目标群体（如不同性别）而异，对于理解和安全地使用大型语言模型进行日常沟通任务至关重要。

Method: 该研究提出了一个评估框架，用于分析接收者性别、发送者意图或输出语言如何影响说服性语言的生成。研究评估了13个大型语言模型和16种语言，采用了成对提示指令。并利用基于社会心理学和传播学原理的大型语言模型作为裁判，在19个说服性语言类别上评估了模型响应。

Result: 研究发现在所有模型中，针对不同性别生成的说服性语言存在显著差异。这些差异模式反映了与社会心理学和语言社会学中记录的性别刻板印象语言倾向一致的偏见。

Conclusion: 大型语言模型生成的说服性语言受到目标受众性别的影响，并且会复制社会中存在的性别语言刻板印象。

Abstract: Large language models (LLMs) are increasingly used for everyday communication tasks, including drafting interpersonal messages intended to influence and persuade. Prior work has shown that LLMs can successfully persuade humans and amplify persuasive language. It is therefore essential to understand how user instructions affect the generation of persuasive language, and to understand whether the generated persuasive language differs, for example, when targeting different groups. In this work, we propose a framework for evaluating how persuasive language generation is affected by recipient gender, sender intent, or output language. We evaluate 13 LLMs and 16 languages using pairwise prompt instructions. We evaluate model responses on 19 categories of persuasive language using an LLM-as-judge setup grounded in social psychology and communication science. Our results reveal significant gender differences in the persuasive language generated across all models. These patterns reflect biases consistent with gender-stereotypical linguistic tendencies documented in social psychology and sociolinguistics.

</details>


### [117] [EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis](https://arxiv.org/abs/2601.05808)
*Xiaoshuai Song,Haofei Chang,Guanting Dong,Yutao Zhu,Zhicheng Dou,Ji-Rong Wen*

Main category: cs.CL

TL;DR: EnvScaler是一个自动化的框架，通过程序化合成来扩展工具交互环境，用于训练LLM作为智能体。它通过SkelBuilder创建环境骨架，ScenGenerator生成任务场景，并在Qwen3模型上进行了SFT和RL训练，显著提高了模型在复杂多轮多工具交互任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM工具交互环境存在访问受限、模拟环境易产生幻觉、手动构建难以扩展等问题，限制了LLM作为代理在真实世界环境中的训练。因此，需要一个可扩展的、自动化的工具交互环境构建框架。

Method: EnvScaler框架包含两个组件：SkelBuilder通过主题挖掘、逻辑建模和质量评估来构建多样化的环境骨架；ScenGenerator为每个环境生成多个任务场景和基于规则的轨迹验证函数。使用EnvScaler合成了191个环境和约7000个场景，并应用于Qwen3模型的监督微调（SFT）和强化学习（RL）训练。

Result: 在三个基准测试中，EnvScaler显著提高了LLM解决复杂环境中的多轮、多工具交互任务的能力。通过EnvScaler生成的环境和场景，模型在处理复杂交互场景时表现出更强的性能。

Conclusion: EnvScaler提供了一种可扩展的、自动化的方法来生成LLM训练所需的工具交互环境和任务场景，有效解决了现有方法的局限性，并能显著提升LLM在复杂环境中的代理能力。

Abstract: Large language models (LLMs) are expected to be trained to act as agents in various real-world environments, but this process relies on rich and varied tool-interaction sandboxes. However, access to real systems is often restricted; LLM-simulated environments are prone to hallucinations and inconsistencies; and manually built sandboxes are hard to scale. In this paper, we propose EnvScaler, an automated framework for scalable tool-interaction environments via programmatic synthesis. EnvScaler comprises two components. First, SkelBuilder constructs diverse environment skeletons through topic mining, logic modeling, and quality evaluation. Then, ScenGenerator generates multiple task scenarios and rule-based trajectory validation functions for each environment. With EnvScaler, we synthesize 191 environments and about 7K scenarios, and apply them to Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) for Qwen3 series models. Results on three benchmarks show that EnvScaler significantly improves LLMs' ability to solve tasks in complex environments involving multi-turn, multi-tool interactions. We release our code and data at https://github.com/RUC-NLPIR/EnvScaler.

</details>


### [118] [AutoMonitor-Bench: Evaluating the Reliability of LLM-Based Misbehavior Monitor](https://arxiv.org/abs/2601.05752)
*Shu Yang,Jingyu Hu,Tong Li,Hanqi Yan,Wenxuan Wang,Di Wang*

Main category: cs.CL

TL;DR: 本文提出了AutoMonitor-Bench，一个用于评估LLM误行为检测器可靠性的首个基准。该基准包含3010个标注样本，覆盖问答、代码生成和推理任务，并评估了12个闭源和10个开源LLM。研究发现，LLM检测器性能差异显著，且误报率和漏报率之间存在权衡。通过大规模训练语料库（153,581个样本）对Qwen3-4B-Instruction进行微调，结果表明对已知误行为数据集的训练能提高对未知、隐式误行为的检测能力。研究突出了LLM误行为检测的挑战，并为未来的研究方向提供了指导。


<details>
  <summary>Details</summary>
Motivation: 现有LLM误行为检测器缺乏一个系统性的评估方法，研究旨在填补这一空白，并深入了解现有检测器的可靠性及其局限性。

Method: 构建了AutoMonitor-Bench基准，包含3010个标注样本，涵盖问答、代码生成和推理任务，并区分了误行为和良性样本。使用漏报率（MR）和误报率（FAR）两个指标评估LLM检测器。对12个闭源和10个开源LLM进行了评估。此外，还构建了一个包含153,581个样本的训练语料库，并对Qwen3-4B-Instruction进行了微调，以研究训练数据对模型性能的影响。

Result: LLM误行为检测器在性能上存在显著差异。漏报率（MR）和误报率（FAR）之间存在持续的权衡关系，表明安全性和效用之间存在内在的矛盾。通过对Qwen3-4B-Instruction进行微调，发现在已知、易于构建的误行为数据集上进行训练，可以提高模型对未见过、更隐式的误行为的检测性能。

Conclusion: 可靠且可扩展的LLM误行为检测面临挑战。未来的研究应侧重于开发针对特定任务设计的LLM检测器以及更有效的训练策略。

Abstract: We introduce AutoMonitor-Bench, the first benchmark designed to systematically evaluate the reliability of LLM-based misbehavior monitors across diverse tasks and failure modes. AutoMonitor-Bench consists of 3,010 carefully annotated test samples spanning question answering, code generation, and reasoning, with paired misbehavior and benign instances. We evaluate monitors using two complementary metrics: Miss Rate (MR) and False Alarm Rate (FAR), capturing failures to detect misbehavior and oversensitivity to benign behavior, respectively. Evaluating 12 proprietary and 10 open-source LLMs, we observe substantial variability in monitoring performance and a consistent trade-off between MR and FAR, revealing an inherent safety-utility tension. To further explore the limits of monitor reliability, we construct a large-scale training corpus of 153,581 samples and fine-tune Qwen3-4B-Instruction to investigate whether training on known, relatively easy-to-construct misbehavior datasets improves monitoring performance on unseen and more implicit misbehaviors. Our results highlight the challenges of reliable, scalable misbehavior monitoring and motivate future work on task-aware designing and training strategies for LLM-based monitors.

</details>


### [119] [One Script Instead of Hundreds? On Pretraining Romanized Encoder Language Models](https://arxiv.org/abs/2601.05776)
*Benedikt Ebing,Lennart Keller,Goran Glavaš*

Main category: cs.CL

TL;DR: 该研究通过预训练使用罗马化文本和原始文本的编码器语言模型，评估了罗马化在预训练多语言语言模型（mLMs）中的有效性，特别关注其对高资源语言性能的影响。研究发现，对于分段脚本语言，性能损失可以忽略不计，而对于语素文字脚本语言，性能会下降，尽管更高保真度的罗马化可以缓解这种影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在罗马化对低资源语言的跨语言迁移（XLT）的好处，但忽略了罗马化可能对高资源语言性能造成的潜在负面影响，以及罗马化是否是预训练通用mLMs的理想选择。作者旨在填补这一研究空白。

Method: 研究人员从头开始预训练了六种类型多样的、高资源的语言的编码器语言模型，分别使用了罗马化文本和原始文本。他们使用了两种不同保真度的罗马化工具，并比较了不同设置下的模型性能，以探究罗马化可能造成的两种退化来源：脚本特定信息的丢失和词汇重叠增加引起的负面跨语言干扰。

Result: 对于分段脚本语言，性能损失可以忽略不计；而对于语素文字脚本语言（如中文和日文），性能有所下降，但更高保真度的罗马化可以缓解这种下降。研究还发现，增加的子词重叠并未导致负面跨语言干扰。此外，罗马化在分段脚本语言中可以提高编码效率。

Conclusion: 罗马化是一种有益的策略，尤其是在分段脚本语言中，其性能损失很小，并且可以提高编码效率。然而，对于语素文字脚本语言，罗马化会导致一定的性能下降，尽管可以通过提高罗马化保真度来部分缓解。

Abstract: Exposing latent lexical overlap, script romanization has emerged as an effective strategy for improving cross-lingual transfer (XLT) in multilingual language models (mLMs). Most prior work, however, focused on setups that favor romanization the most: (1) transfer from high-resource Latin-script to low-resource non-Latin-script languages and/or (2) between genealogically closely related languages with different scripts. It thus remains unclear whether romanization is a good representation choice for pretraining general-purpose mLMs, or, more precisely, if information loss associated with romanization harms performance for high-resource languages. We address this gap by pretraining encoder LMs from scratch on both romanized and original texts for six typologically diverse high-resource languages, investigating two potential sources of degradation: (i) loss of script-specific information and (ii) negative cross-lingual interference from increased vocabulary overlap. Using two romanizers with different fidelity profiles, we observe negligible performance loss for languages with segmental scripts, whereas languages with morphosyllabic scripts (Chinese and Japanese) suffer degradation that higher-fidelity romanization mitigates but cannot fully recover. Importantly, comparing monolingual LMs with their mLM counterpart, we find no evidence that increased subword overlap induces negative interference. We further show that romanization improves encoding efficiency (i.e., fertility) for segmental scripts at a negligible performance cost.

</details>


### [120] [Router-Suggest: Dynamic Routing for Multimodal Auto-Completion in Visually-Grounded Dialogs](https://arxiv.org/abs/2601.05851)
*Sandeep Mishra,Devichand Budagam,Anubhab Mandal,Bishal Santra,Pawan Goyal,Manish Gupta*

Main category: cs.CL

TL;DR: 本文提出了一种名为多模态自动补全（MAC）的新任务，旨在使用部分输入的文本和视觉线索预测实时聊天中的下一个字符，并提出了名为 Router-Suggest 的框架来动态选择文本模型或视觉语言模型（VLM），以提高效率和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有的自动补全技术主要基于文本，无法利用共享的视觉上下文，而多模态（文本+视觉）自动补全对于需要共享视觉上下文的数字助手、聊天机器人、设计工具和医疗咨询等场景至关重要。

Method: 1. 提出多模态自动补全（MAC）任务，预测输入文本和视觉线索下的下一个字符。2. Adaptation of MMDialog and ImageChat datasets to create benchmark datasets for MAC. 3. Evaluation of existing vision-language models (VLMs) and strong textual baselines. 4. Development of Router-Suggest framework, which dynamically selects between textual models and VLMs, and a lightweight variant. 5. Conducting a user study to compare VLM and textual model performance.

Result: 1. VLMs在多模态自动补全任务上表现优于纯文本模型。2. Router-Suggest 框架比性能最佳的 VLM 快 2.3 倍到 10 倍。3. 用户研究表明，VLM 在用户满意度、节省用户输入和提高多轮对话的补全质量方面显著优于纯文本模型。

Conclusion: 多模态上下文对于提高自动补全的质量和用户体验至关重要，尤其是在多轮对话和需要视觉理解的场景中，这有助于创建更智能、更懂用户的助手。

Abstract: Real-time multimodal auto-completion is essential for digital assistants, chatbots, design tools, and healthcare consultations, where user inputs rely on shared visual context. We introduce Multimodal Auto-Completion (MAC), a task that predicts upcoming characters in live chats using partially typed text and visual cues. Unlike traditional text-only auto-completion (TAC), MAC grounds predictions in multimodal context to better capture user intent. To enable this task, we adapt MMDialog and ImageChat to create benchmark datasets. We evaluate leading vision-language models (VLMs) against strong textual baselines, highlighting trade-offs in accuracy and efficiency. We present Router-Suggest, a router framework that dynamically selects between textual models and VLMs based on dialog context, along with a lightweight variant for resource-constrained environments. Router-Suggest achieves a 2.3x to 10x speedup over the best-performing VLM. A user study shows that VLMs significantly excel over textual models on user satisfaction, notably saving user typing effort and improving the quality of completions in multi-turn conversations. These findings underscore the need for multimodal context in auto-completions, leading to smarter, user-aware assistants.

</details>


### [121] [Simplify-This: A Comparative Analysis of Prompt-Based and Fine-Tuned LLMs](https://arxiv.org/abs/2601.05794)
*Eilam Cohen,Itamar Bul,Danielle Inbar,Omri Loewenbach*

Main category: cs.CL

TL;DR: 本研究比较了文本简化任务中微调和提示工程两种方法，发现微调模型在结构简化方面表现更好，而提示工程在语义相似度上表现优异但易复制原文。人类评估更倾向于微调模型。


<details>
  <summary>Details</summary>
Motivation: 在文本简化任务中，存在微调和提示工程两种常用的方法，但两者在效果上的权衡关系尚不明确，需要进行比较研究。

Method: 使用编码器-解码器大型语言模型，在多个基准数据集上，通过微调和提示工程两种范式进行文本简化，并使用多种评估指标进行比较，包括结构简化、语义相似度，并进行了人类评估。

Result: 微调模型在结构简化方面表现更强。提示工程在语义相似度得分上更高，但存在复制输入原文的倾向。人类评估整体上更偏好微调模型产生的简化文本。

Conclusion: 对于文本简化任务，微调模型在结构化改进方面具有优势，而提示工程在保持原文含义上表现突出但可能牺牲创新性。研究结果为选择何种方法提供了指导，并公开了代码、数据集、模型检查点和提示模板以促进研究。

Abstract: Large language models (LLMs) enable strong text generation, and in general there is a practical tradeoff between fine-tuning and prompt engineering. We introduce Simplify-This, a comparative study evaluating both paradigms for text simplification with encoder-decoder LLMs across multiple benchmarks, using a range of evaluation metrics. Fine-tuned models consistently deliver stronger structural simplification, whereas prompting often attains higher semantic similarity scores yet tends to copy inputs. A human evaluation favors fine-tuned outputs overall. We release code, a cleaned derivative dataset used in our study, checkpoints of fine-tuned models, and prompt templates to facilitate reproducibility and future work.

</details>


### [122] [LLMs as Science Journalists: Supporting Early-stage Researchers in Communicating Their Science to the Public](https://arxiv.org/abs/2601.05821)
*Milad Alshomary,Grace Li,Anubhav Jangra,Yufang Hou,Kathleen McKeown,Smaranda Muresan*

Main category: cs.CL

TL;DR: 本文提出了一个训练大语言模型（LLM）模拟科学记者的框架，以帮助早期研究人员向公众有效传达其研究成果。实验表明，经过训练的LLM能够提出更具相关性的问题，引导研究人员阐述其研究的社会影响，并且用户更倾向于与训练过的LLM进行交互。


<details>
  <summary>Details</summary>
Motivation: 科学界需要一种工具来帮助早期研究人员有效地将他们的发现和创新传达给公众，而现有的通用大语言模型（LLMs）在这方面并非最优。

Method: 提出一个训练框架，使LLMs能够模仿科学记者的角色。通过与模拟和人类研究人员进行对话来评估训练过的LLM记者的实用性，并与通用LLMs进行比较。

Result: 经过训练的LLMs能够提出更相关的问题，重点关注研究的社会影响，并促使研究人员澄清和详细阐述他们的发现。用户研究表明，大部分参与者更喜欢与训练过的LLM记者互动，而不是通用的LLMs。

Conclusion: 所提出的LLM记者训练框架能够有效地提升LLMs在科学传播领域的表现，为早期研究人员提供了一个有价值的沟通辅助工具。

Abstract: The scientific community needs tools that help early-stage researchers effectively communicate their findings and innovations to the public. Although existing general-purpose Large Language Models (LLMs) can assist in this endeavor, they are not optimally aligned for it. To address this, we propose a framework for training LLMs to emulate the role of a science journalist that can be used by early-stage researchers to learn how to properly communicate their papers to the general public. We evaluate the usefulness of our trained LLM Journalists in leading conversations with both simulated and human researchers. %compared to the general-purpose ones. Our experiments indicate that LLMs trained using our framework ask more relevant questions that address the societal impact of research, prompting researchers to clarify and elaborate on their findings. In the user study, the majority of participants who interacted with our trained LLM Journalist appreciated it more than interacting with general-purpose LLMs.

</details>


### [123] [CLewR: Curriculum Learning with Restarts for Machine Translation Preference Learning](https://arxiv.org/abs/2601.05858)
*Alexandra Dragomir,Florin Brad,Radu Tudor Ionescu*

Main category: cs.CL

TL;DR: 研究表明，在预训练大语言模型（LLMs）进行多语言机器翻译时，训练数据的呈现顺序（课程学习）对于模型性能至关重要。文章提出了一个名为CLewR的新型课程学习策略，通过多次重复“从易到难”的训练过程来防止模型遗忘简单样本，并取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在零样本多语言机器翻译方面表现出色，但现有方法在利用偏好优化时，忽略了训练数据样本的呈现顺序对模型性能的影响。本研究旨在探索和改进这一点，以进一步提升翻译质量。

Method: 本文将课程学习（curriculum learning）策略集成到现有的偏好优化算法中，以提高机器翻译性能。提出了一种名为CLewR（Curriculum Learning with Restarts）的新型课程学习策略，该策略通过多次迭代“从易到难”的训练过程来解决简单样本的灾难性遗忘问题。

Result: 所提出的CLewR策略在Gemma2、Qwen2.5、Llama3.1等多个模型家族和多种偏好优化技术上都取得了持续的性能提升。这表明该方法具有普适性和有效性。

Conclusion: 训练数据的呈现顺序，特别是通过课程学习策略，是提升大语言模型在多语言机器翻译任务上性能的关键因素。CLewR策略通过有效管理训练过程中的数据难度，显著克服了灾难性遗忘问题，为未来的研究提供了有价值的参考。

Abstract: Large language models (LLMs) have demonstrated competitive performance in zero-shot multilingual machine translation (MT). Some follow-up works further improved MT performance via preference optimization, but they leave a key aspect largely underexplored: the order in which data samples are given during training. We address this topic by integrating curriculum learning into various state-of-the-art preference optimization algorithms to boost MT performance. We introduce a novel curriculum learning strategy with restarts (CLewR), which reiterates easy-to-hard curriculum multiple times during training to effectively mitigate the catastrophic forgetting of easy examples. We demonstrate consistent gains across several model families (Gemma2, Qwen2.5, Llama3.1) and preference optimization techniques. We publicly release our code at https://github.com/alexandra-dragomir/CLewR.

</details>


### [124] [Continual-learning for Modelling Low-Resource Languages from Large Language Models](https://arxiv.org/abs/2601.05874)
*Santosh Srinath K,Mudit Somani,Varun Reddy Padala,Prajna Devi Upadhyay,Abhijit Das*

Main category: cs.CL

TL;DR: 本文提出了一种基于词性（POS）的代码转换和重放适配器策略，用于在多语言场景下训练小型语言模型（SLM），以解决从大型语言模型（LLM）适应过程中出现的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 在多语言场景下训练语言模型，特别是从LLM适配到低资源语言的SLM时，灾难性遗忘是一个主要挑战。

Method: 提出了一种持续学习策略，结合了基于词性（POS）的代码转换和重放适配器策略。

Result: 在视觉问答和语言模型等视觉语言任务上进行的实验表明，所提出的架构成功地减轻了灾难性遗忘。

Conclusion: 所提出的基于POS的代码转换和重放适配器策略能够有效地缓解在LLM到SLM的适应过程中出现的灾难性遗忘问题，并在视觉语言任务上取得了成功。

Abstract: Modelling a language model for a multi-lingual scenario includes several potential challenges, among which catastrophic forgetting is the major challenge. For example, small language models (SLM) built for low-resource languages by adapting large language models (LLMs) pose the challenge of catastrophic forgetting. This work proposes to employ a continual learning strategy using parts-of-speech (POS)-based code-switching along with a replay adapter strategy to mitigate the identified gap of catastrophic forgetting while training SLM from LLM. Experiments conducted on vision language tasks such as visual question answering and language modelling task exhibits the success of the proposed architecture.

</details>


### [125] [Peek2: A Regex-free implementation of pretokenizers for Byte-level BPE](https://arxiv.org/abs/2601.05833)
*Liu Zai*

Main category: cs.CL

TL;DR: Peek2 是一种无需正则表达式、性能更高且与现有预分词器（如 cl100k）兼容的预分词器实现，可用于 GPT-3、LLaMa-3 和 Qwen-2.5 等模型，并实现了 1.11 倍的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现有的预分词器实现（例如 cl100k）在性能和安全性方面存在不足，尤其是在处理 GPT-3、LLaMa-3 和 Qwen-2.5 等模型时。研究人员希望开发一种更高效、更安全的替代方案。

Method: 提出了一种名为 Peek2 的新的预分词器实现，它不使用正则表达式，完全在 CPU 上运行，具有稳定的线性时间复杂度 O(n)，并能生成与原始基于正则表达式的预分词器相同的预分段结果。

Result: Peek2 在整个字节级 BPE 编码过程中实现了 1.11 倍的整体吞吐量提升，并且其预分段结果与原始的 Regex-based 预分词器完全一致。

Conclusion: Peek2 是一种性能优越、安全且兼容的预分词器替代方案，能够显著提升字节级 BPE 编码的效率，并且不影响分词的准确性。

Abstract: Pretokenization is a crucial, sequential pass in Byte-level BPE tokenizers. Our proposed new implementation, Peek2, serves as a drop-in replacement for cl100k-like pretokenizers used in GPT-3, LLaMa-3, and Qwen-2.5. Designed with performance and safety in mind, Peek2 is Regex-free and delivers a $ 1.11\times $ improvement in overall throughput across the entire Byte-level BPE encoding process. This algorithm runs entirely on the CPU, has stable linear complexity $ O(n) $, and provides presegmentation results identical to those of the original Regex-based pretokenizer.

</details>


### [126] [Semantic NLP Pipelines for Interoperable Patient Digital Twins from Unstructured EHRs](https://arxiv.org/abs/2601.05847)
*Rafael Brens,Yuqiao Meng,Luoxi Tang,Zhaohan Xi*

Main category: cs.CL

TL;DR: 该论文提出了一种基于语义自然语言处理（NLP）的流水线，用于将非结构化的电子健康记录（EHR）转化为符合FHIR标准的患者数字孪生表示。


<details>
  <summary>Details</summary>
Motivation: 从非结构化的EHR中生成可互操作的患者数字孪生存在挑战，原因是临床文档的可变性和缺乏标准化映射。

Method: 该方法利用命名实体识别（NER）提取临床概念，概念标准化将实体映射到SNOMED-CT或ICD-10，关系抽取捕捉条件、药物和观察之间的结构化关联，最终生成FHIR格式的数字孪生。

Result: 在MIMIC-IV临床数据库演示上进行了评估，与MIMIC-IV-on-FHIR参考映射进行验证，实体和关系抽取获得了高F1分数，与基线方法相比，模式完整性和互操作性有所提高。

Conclusion: 所提出的语义NLP驱动的流水线能够有效地将自由文本EHR笔记转化为可互操作的、符合FHIR标准的患者数字孪生表示，解决了现有方法中的挑战。

Abstract: Digital twins -- virtual replicas of physical entities -- are gaining traction in healthcare for personalized monitoring, predictive modeling, and clinical decision support. However, generating interoperable patient digital twins from unstructured electronic health records (EHRs) remains challenging due to variability in clinical documentation and lack of standardized mappings. This paper presents a semantic NLP-driven pipeline that transforms free-text EHR notes into FHIR-compliant digital twin representations. The pipeline leverages named entity recognition (NER) to extract clinical concepts, concept normalization to map entities to SNOMED-CT or ICD-10, and relation extraction to capture structured associations between conditions, medications, and observations. Evaluation on MIMIC-IV Clinical Database Demo with validation against MIMIC-IV-on-FHIR reference mappings demonstrates high F1-scores for entity and relation extraction, with improved schema completeness and interoperability compared to baseline methods.

</details>


### [127] [Left, Right, or Center? Evaluating LLM Framing in News Classification and Generation](https://arxiv.org/abs/2601.05835)
*Molly Kennedy,Ali Parker,Yihong Liu,Hinrich Schütze*

Main category: cs.CL

TL;DR: 研究发现，九种最先进的大型语言模型（LLM）在生成文本摘要时存在普遍的“中间化”倾向，即倾向于生成更偏向中间立场的文本。Grok 4在生成文本方面表现出最强的意识形态表达能力，而Claude Sonnet 4.5和Llama 3.1在偏差评级方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）在新闻业中用于文本生成和改写，人们担心它们可能会对政治信息进行微妙的框架化，从而影响读者的解读。本研究旨在探究LLM的分类偏倚信号是否与其生成的摘要中的框架化行为一致。

Method: 研究人员首先比较了使用少量样本（few-shot）对文章进行意识形态预测，并将其与LEFT/CENTER/RIGHT标签进行对比。然后，他们使用FAITHFUL、CENTRIST、LEFT和RIGHT等提示词生成“引导式”摘要，并使用一个固定的意识形态评估器对所有输出进行评分。

Result: 研究发现在文章级别的评分和生成的文本中都普遍存在“意识形态中心塌陷”的现象，表明LLM存在系统性的中间立场框架化倾向。在所有评估的模型中，Grok 4是迄今为止最具意识形态表达力的生成器，而Claude Sonnet 4.5和Llama 3.1分别在商业模型和开源模型中取得了最强的偏差评级性能。

Conclusion: 本研究证实了大型语言模型在生成文本摘要时存在显著的中间化倾向，并且不同模型在意识形态表达和偏差评级方面表现出差异。Grok 4在生成文本方面更具意识形态表现力，而Claude Sonnet 4.5和Llama 3.1在评估偏倚方面表现更强。

Abstract: Large Language Model (LLM) based summarization and text generation are increasingly used for producing and rewriting text, raising concerns about political framing in journalism where subtle wording choices can shape interpretation. Across nine state-of-the-art LLMs, we study political framing by testing whether LLMs' classification-based bias signals align with framing behavior in their generated summaries. We first compare few-shot ideology predictions against LEFT/CENTER/RIGHT labels. We then generate "steered" summaries under FAITHFUL, CENTRIST, LEFT, and RIGHT prompts, and score all outputs using a single fixed ideology evaluator. We find pervasive ideological center-collapse in both article-level ratings and generated text, indicating a systematic tendency toward centrist framing. Among evaluated models, Grok 4 is by far the most ideologically expressive generator, while Claude Sonnet 4.5 and Llama 3.1 achieve the strongest bias-rating performance among commercial and open-weight models, respectively.

</details>


### [128] [An Empirical Study on Preference Tuning Generalization and Diversity Under Domain Shift](https://arxiv.org/abs/2601.05882)
*Constantinos Karouzos,Xingwei Tan,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 研究比较了五种流行的偏好调整目标和各种适应策略对领域迁移的影响，发现基于伪标签的适应策略可以显著减少领域迁移引起的性能下降。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，偏好调整可能会导致模型在训练领域外的性能下降和帮助性降低，但关于适应策略如何缓解这种领域转移的问题尚未得到充分探索。

Method: 对五种流行的偏好调整目标和各种源到目标适应策略（包括目标领域监督微调和伪标签）进行了全面的系统研究，并将其应用于文本摘要和问答的帮助性任务。

Result: 研究结果显示，在领域迁移下，不同的偏好调整目标在泛化能力上存在系统性差异。基于伪标签的适应策略能够显著减少领域迁移导致的性能下降。

Conclusion: 适应策略，特别是基于伪标签的方法，对于提高偏好调整后模型在不同领域上的泛化能力至关重要，可以有效缓解领域转移带来的负面影响。

Abstract: Preference tuning aligns pretrained language models to human judgments of quality, helpfulness, or safety by optimizing over explicit preference signals rather than likelihood alone. Prior work has shown that preference-tuning degrades performance and reduces helpfulness when evaluated outside the training domain. However, the extent to which adaptation strategies mitigate this domain shift remains unexplored. We address this challenge by conducting a comprehensive and systematic study of alignment generalization under domain shift. We compare five popular alignment objectives and various adaptation strategies from source to target, including target-domain supervised fine-tuning and pseudo-labeling, across summarization and question-answering helpfulness tasks. Our findings reveal systematic differences in generalization across alignment objectives under domain shift. We show that adaptation strategies based on pseudo-labeling can substantially reduce domain-shift degradation

</details>


### [129] [Gender Bias in LLMs: Preliminary Evidence from Shared Parenting Scenario in Czech Family Law](https://arxiv.org/abs/2601.05879)
*Jakub Harasta,Matej Vasina,Martin Kornel,Tomas Foltynek*

Main category: cs.CL

TL;DR: 研究调查了 GPT-5 nano、Claude Haiku 4.5、Gemini 2.5 Flash 和 Llama 3.3 这四种大型语言模型（LLMs）在处理捷克离婚法场景时是否存在性别偏见。通过使用性别化姓名和中性标签的场景版本，并引入九个法律相关因素来改变案件事实，研究评估了模型建议的共同育儿比例。初步结果显示了模型间的差异，并且一些系统在输出中呈现出性别依赖的模式，这凸显了人们对 LLMs 法律自助的潜在风险以及在敏感法律领域进行模型行为评估的必要性。


<details>
  <summary>Details</summary>
Motivation: 鉴于人们日益依赖大型语言模型（LLMs）进行法律自助，而这些模型可能产生不完整、不正确或有偏见的输出，本研究旨在探究 LLMs 在处理现实家庭法场景时是否存在性别偏见，以评估其潜在风险。

Method: 研究设计了一个基于捷克离婚法的家庭法场景，并创建了两个版本：一个使用性别化姓名，另一个使用中性标签。然后，在完全零样本（zero-shot）的设置下，对 GPT-5 nano、Claude Haiku 4.5、Gemini 2.5 Flash 和 Llama 3.3 四种 LLMs 进行了评估。此外，研究还引入了九个法律相关因素来改变案件事实，并测试这些变化是否会影响模型提出的共同育儿比例。

Result: 初步结果显示，不同模型在处理相同场景时存在差异。此外，一些模型在输出结果中呈现出性别依赖的模式，这意味着模型对性别化姓名的反应可能与中性标签不同。

Conclusion: 研究结果表明，LLMs 在处理敏感法律问题时可能存在性别偏见，这加剧了用户对其法律指导的担忧。因此，有必要对模型在法律领域的行为进行更严格的评估，以识别系统性不对称并降低潜在风险。

Abstract: Access to justice remains limited for many people, leading laypersons to increasingly rely on Large Language Models (LLMs) for legal self-help. Laypeople use these tools intuitively, which may lead them to form expectations based on incomplete, incorrect, or biased outputs. This study examines whether leading LLMs exhibit gender bias in their responses to a realistic family law scenario. We present an expert-designed divorce scenario grounded in Czech family law and evaluate four state-of-the-art LLMs GPT-5 nano, Claude Haiku 4.5, Gemini 2.5 Flash, and Llama 3.3 in a fully zero-shot interaction. We deploy two versions of the scenario, one with gendered names and one with neutral labels, to establish a baseline for comparison. We further introduce nine legally relevant factors that vary the factual circumstances of the case and test whether these variations influence the models' proposed shared-parenting ratios. Our preliminary results highlight differences across models and suggest gender-dependent patterns in the outcomes generated by some systems. The findings underscore both the risks associated with laypeople's reliance on LLMs for legal guidance and the need for more robust evaluation of model behavior in sensitive legal contexts. We present exploratory and descriptive evidence intended to identify systematic asymmetries rather than to establish causal effects.

</details>


### [130] [What do the metrics mean? A critical analysis of the use of Automated Evaluation Metrics in Interpreting](https://arxiv.org/abs/2601.05864)
*Jonathan Downie,Joss Moorkens*

Main category: cs.CL

TL;DR: 现有自动翻译质量评估方法无法独立考虑语境，因此不适用于评估真实翻译实践的质量。


<details>
  <summary>Details</summary>
Motivation: 随着远程翻译、计算机辅助翻译、自动语音翻译和翻译化身等技术的不断发展，对快速高效的翻译质量评估方法的需求日益增长。

Method: 审查和讨论了近期提出的自动化翻译质量评估方法，并分析了其在评估真实翻译实践（包括人类和机器翻译）方面的适用性。

Result: 目前提出的自动指标无法独立考虑语境，因此不能作为评估任何翻译服务质量的独立指标。

Conclusion: 语境是评估翻译质量的根本要素，现有的自动指标单独使用时不足以评估真实翻译实践的质量。

Abstract: With the growth of interpreting technologies, from remote interpreting and Computer-Aided Interpreting to automated speech translation and interpreting avatars, there is now a high demand for ways to quickly and efficiently measure the quality of any interpreting delivered. A range of approaches to fulfil the need for quick and efficient quality measurement have been proposed, each involving some measure of automation. This article examines these recently-proposed quality measurement methods and will discuss their suitability for measuring the quality of authentic interpreting practice, whether delivered by humans or machines, concluding that automatic metrics as currently proposed cannot take into account the communicative context and thus are not viable measures of the quality of any interpreting provision when used on their own. Across all attempts to measure or even categorise quality in Interpreting Studies, the contexts in which interpreting takes place have become fundamental to the final analysis.

</details>


### [131] [Illusions of Confidence? Diagnosing LLM Truthfulness via Neighborhood Consistency](https://arxiv.org/abs/2601.05905)
*Haoming Xu,Ningyuan Zhao,Yunzhi Yao,Weihong Xu,Hongru Wang,Xinle Deng,Shumin Deng,Jeff Z. Pan,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 该研究提出了一种名为邻居一致性信念 (NCB) 的新方法，用于评估大型语言模型 (LLM) 在面对上下文扰动时的信念鲁棒性。与仅关注点估计的置信度不同，NCB 衡量响应在概念邻域内的连贯性。实验表明，高 NCB 分数的数据更能抵抗干扰。此外，研究还提出了结构感知训练 (SAT) 方法，该方法通过优化上下文不变的信念结构，将长尾知识的脆弱性降低了约 30%。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）评估方法主要依赖于点估计的置信度（如 Self-Consistency），这种方法无法有效检测模型信念的脆弱性，即在轻微的上下文干扰下，即使是自信回答的事实也可能迅速崩溃。因此，研究的动机是开发一种能够衡量模型信念在上下文扰动下鲁棒性的新方法。

Method: 研究提出了邻居一致性信念 (NCB) 作为一种结构性度量，用于评估响应在概念邻域内的连贯性，以衡量信念的鲁棒性。同时，引入了一种新的认知压力测试协议，该协议通过引入上下文干扰来探测输出的稳定性。此外，还提出了一种结构感知训练 (SAT) 方法，旨在优化上下文不变的信念结构，以提高长尾知识的鲁棒性。

Result: 实验表明，具有高 NCB 分数的数据集在面对上下文干扰时，其性能相对更具抵抗力。通过结构感知训练 (SAT) 方法，长尾知识的脆弱性降低了约 30%。

Conclusion: 信念的鲁棒性对于 LLMs 在现实世界中的可靠部署至关重要，而传统的评估方法不足以捕捉这一点。NCB 是一种有效的度量方法，可以评估 LLMs 在上下文扰动下的信念鲁棒性，而 SAT 则是一种有效的训练方法，可以提高 LLMs 的信念鲁棒性，尤其是在长尾知识方面。

Abstract: As Large Language Models (LLMs) are increasingly deployed in real-world settings, correctness alone is insufficient. Reliable deployment requires maintaining truthful beliefs under contextual perturbations. Existing evaluations largely rely on point-wise confidence like Self-Consistency, which can mask brittle belief. We show that even facts answered with perfect self-consistency can rapidly collapse under mild contextual interference. To address this gap, we propose Neighbor-Consistency Belief (NCB), a structural measure of belief robustness that evaluates response coherence across a conceptual neighborhood. To validate the efficiency of NCB, we introduce a new cognitive stress-testing protocol that probes outputs stability under contextual interference. Experiments across multiple LLMs show that the performance of high-NCB data is relatively more resistant to interference. Finally, we present Structure-Aware Training (SAT), which optimizes context-invariant belief structure and reduces long-tail knowledge brittleness by approximately 30%. Code will be available at https://github.com/zjunlp/belief.

</details>


### [132] [FACTUM: Mechanistic Detection of Citation Hallucination in Long-Form RAG](https://arxiv.org/abs/2601.05866)
*Maxime Dassen,Rebecca Kotula,Kenton Murray,Andrew Yates,Dawn Lawrie,Efsun Kayi,James Mayfield,Kevin Duh*

Main category: cs.CL

TL;DR: 该研究提出了FACTUM框架，通过分析模型内部机制（注意力与前馈网络）的贡献及其对齐情况，来评估检索增强生成（RAG）模型中引文幻觉的根本原因，并显著提高了引文可信度评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG模型存在引文幻觉问题，即模型自信地引用不支持其声明的来源。现有工作常将此归因于模型对参数知识的过度依赖，但本研究挑战这一观点，旨在深入探究引文幻觉的机制。

Method: 提出了FACTUM框架，该框架包含四个衡量模型注意力机制和前馈网络（FFN）通路贡献以及它们之间对齐情况的机制化分数。通过分析这些分数来量化模型行为。

Result: 研究发现，正确的引文具有两个一致的特征：模型参数知识的贡献更强，且注意力汇聚点（attention sink）用于信息综合的程度更高。此外，正确的引文特征会随着模型规模的变化而演变。例如，小模型（Llama-3.2-3B）的正确引文特征是通路对齐度更高，而大模型（Llama-3.1-8B）的特征则是通路对齐度较低，但通路贡献的信息更具区分度和正交性。FACTUM框架在AUC方面比现有最佳基线提高了37.5%。

Conclusion: 引文幻觉并非简单的参数知识过度依赖，而是模型内部机制之间一种复杂且依赖于模型规模的相互作用。FACTUM框架通过捕捉这种复杂多变的机制特征，能够更准确地评估引文可信度，为构建更可靠的RAG系统提供了新思路。

Abstract: Retrieval-Augmented Generation (RAG) models are critically undermined by citation hallucinations, a deceptive failure where a model confidently cites a source that fails to support its claim. Existing work often attributes hallucination to a simple over-reliance on the model's parametric knowledge. We challenge this view and introduce FACTUM (Framework for Attesting Citation Trustworthiness via Underlying Mechanisms), a framework of four mechanistic scores measuring the distinct contributions of a model's attention and FFN pathways, and the alignment between them. Our analysis reveals two consistent signatures of correct citation: a significantly stronger contribution from the model's parametric knowledge and greater use of the attention sink for information synthesis. Crucially, we find the signature of a correct citation is not static but evolves with model scale. For example, the signature of a correct citation for the Llama-3.2-3B model is marked by higher pathway alignment, whereas for the Llama-3.1-8B model, it is characterized by lower alignment, where pathways contribute more distinct, orthogonal information. By capturing this complex, evolving signature, FACTUM outperforms state-of-the-art baselines by up to 37.5% in AUC. Our findings reframe citation hallucination as a complex, scale-dependent interplay between internal mechanisms, paving the way for more nuanced and reliable RAG systems.

</details>


### [133] [iReasoner: Trajectory-Aware Intrinsic Reasoning Supervision for Self-Evolving Large Multimodal Models](https://arxiv.org/abs/2601.05877)
*Meghana Sunil,Manikandarajan Venmathimaran,Muthu Subash Kavitha*

Main category: cs.CL

TL;DR: 本文提出了一种名为 iReasoner 的自进化框架，通过显式诱导链式思考（CoT）并奖励其内部一致性，来改进大型多模态模型（LMM）的隐式推理能力，并在完全无监督的情况下取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的 LMM 自我提升方法主要关注最终结果，而忽视了对中间推理过程的约束，而中间推理过程对于视觉基础的决策至关重要。

Method: iReasoner 采用 Proposer--Solver 循环，在无标签图像上进行训练。它在结果级别的内在奖励之上，增加了一个基于中间推理步骤的轨迹感知信号，从而在没有真实标签或外部裁判的情况下，区分导致相同答案的不同推理路径。

Result: 从 Qwen2.5-VL-7B 模型开始，iReasoner 在完全无监督的后训练下，在各种多模态推理基准测试中取得了高达 2.1 个点的性能提升。

Conclusion: iReasoner 成功地通过奖励中间推理的一致性来改进 LMM 的推理能力，证明了在纯无监督设置下进行推理感知自我改进的可行性，并为未来的研究奠定了基础。

Abstract: Recent work shows that large multimodal models (LMMs) can self-improve from unlabeled data via self-play and intrinsic feedback. Yet existing self-evolving frameworks mainly reward final outcomes, leaving intermediate reasoning weakly constrained despite its importance for visually grounded decision making. We propose iReasoner, a self-evolving framework that improves an LMM's implicit reasoning by explicitly eliciting chain-of-thought (CoT) and rewarding its internal agreement. In a Proposer--Solver loop over unlabeled images, iReasoner augments outcome-level intrinsic rewards with a trajectory-aware signal defined over intermediate reasoning steps, providing learning signals that distinguish reasoning paths leading to the same answer without ground-truth labels or external judges. Starting from Qwen2.5-VL-7B, iReasoner yields up to $+2.1$ points across diverse multimodal reasoning benchmarks under fully unsupervised post-training. We hope this work serves as a starting point for reasoning-aware self-improvement in LMMs in purely unsupervised settings.

</details>


### [134] [Can We Predict Before Executing Machine Learning Agents?](https://arxiv.org/abs/2601.05930)
*Jingsheng Zheng,Jintian Zhang,Yujie Luo,Yuren Mao,Yunjun Gao,Lun Du,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 本研究提出了一种名为FOREAGENT的自主机器学习代理，通过“先预测后验证”的范式，利用大型语言模型（LLMs）对数据分析结果进行预测，从而克服了传统“生成-执行-反馈”范式中昂贵的物理执行瓶颈，实现了6倍的收敛加速并超越了基于执行的方法。


<details>
  <summary>Details</summary>
Motivation: 当前的自主机器学习代理受限于“生成-执行-反馈”范式，其中昂贵的物理执行过程构成了严重的瓶颈。研究旨在通过内部化执行先验，用即时预测推理替代耗时的运行时检查，以克服这些物理限制。

Method: 1. 提出了“数据中心化解决方案偏好”任务，并构建了一个包含18,438个成对比较的综合数据集。
2. 利用大型语言模型（LLMs）并结合“经验证的数据分析报告”（Verified Data Analysis Report）进行提示（priming），以评估其预测能力。
3. 构建了一个名为FOREAGENT的代理，该代理采用“先预测后验证”（Predict-then-Verify）的循环机制。

Result: 1. LLMs在通过“经验证的数据分析报告”进行提示后，展现出显著的预测能力，准确率达到61.5%，并且具有良好的置信度校准。
2. FOREAGENT代理实现了6倍的收敛加速。
3. FOREAGENT在性能上超越了基于执行的基线方法6%。

Conclusion: 通过将LLMs的预测能力整合到“先预测后验证”的范式中，可以有效缓解传统自主机器学习代理中的执行瓶颈，显著提高效率和性能。

Abstract: Autonomous machine learning agents have revolutionized scientific discovery, yet they remain constrained by a Generate-Execute-Feedback paradigm. Previous approaches suffer from a severe Execution Bottleneck, as hypothesis evaluation relies strictly on expensive physical execution. To bypass these physical constraints, we internalize execution priors to substitute costly runtime checks with instantaneous predictive reasoning, drawing inspiration from World Models. In this work, we formalize the task of Data-centric Solution Preference and construct a comprehensive corpus of 18,438 pairwise comparisons. We demonstrate that LLMs exhibit significant predictive capabilities when primed with a Verified Data Analysis Report, achieving 61.5% accuracy and robust confidence calibration. Finally, we instantiate this framework in FOREAGENT, an agent that employs a Predict-then-Verify loop, achieving a 6x acceleration in convergence while surpassing execution-based baselines by +6%. Our code and dataset will be publicly available soon at https://github.com/zjunlp/predict-before-execute.

</details>


### [135] [Pantagruel: Unified Self-Supervised Encoders for French Text and Speech](https://arxiv.org/abs/2601.05911)
*Phuong-Hang Le,Valentin Pelloin,Arnault Chatelain,Maryem Bouziane,Mohammed Ghennai,Qianwen Guan,Kirill Milintsevich,Salima Mdhaffar,Aidan Mannion,Nils Defauw,Shuyue Gu,Alexandre Audibert,Marco Dinarelli,Yannick Estève,Lorraine Goeuriot,Steffen Lalande,Nicolas Hervé,Maximin Coavoux,François Portet,Étienne Ollion,Marie Candito,Maxime Peyrard,Solange Rossato,Benjamin Lecouteux,Aurélie Nardy,Gilles Sérasset,Vincent Segonne,Solène Evain,Diandra Fabre,Didier Schwab*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Pantagruel 的新型法语自监督模型，它能够同时处理文本和语音，并在多项下游任务中表现出与现有模型相当甚至更优的性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理文本和语音时通常采用特定模态的目标预测，这可能限制了它们捕捉语言和声学规律的效率。研究者希望通过一种更通用的目标表示方式来提升模型性能，并为法语的跨模态理解提供一个强大的基础。

Method: Pantagruel 模型采用自监督学习方式，但其目标不再是特定模态的单元（如文本词元或语音单元），而是在特征空间中学习上下文目标表示。这使得模态特定的编码器能够更有效地捕捉语言和声学规律。模型使用大规模的法语语料库（包括文本和语音数据）进行预训练，并引入了一个新的100,000小时的法语音频语料库 INA-100k。

Result: Pantagruel 模型在包括 FLUE 和 LeBenchmark 在内的多种法语下游任务上，其性能与 CamemBERT、FlauBERT 和 LeBenchmark2.0 等强基线模型相比，具有竞争力或更优。同时，该模型保持了共享的架构，可以无缝处理语音和文本输入。

Conclusion: 研究结果证实了特征空间自监督目标在法语表示学习方面的有效性，并表明 Pantagruel 是一个强大的多模态语音-文本理解基础模型。

Abstract: We release Pantagruel models, a new family of self-supervised encoder models for French text and speech. Instead of predicting modality-tailored targets such as textual tokens or speech units, Pantagruel learns contextualized target representations in the feature space, allowing modality-specific encoders to capture linguistic and acoustic regularities more effectively. Separate models are pre-trained on large-scale French corpora, including Wikipedia, OSCAR and CroissantLLM for text, together with MultilingualLibriSpeech, LeBenchmark, and INA-100k for speech. INA-100k is a newly introduced 100,000-hour corpus of French audio derived from the archives of the Institut National de l'Audiovisuel (INA), the national repository of French radio and television broadcasts, providing highly diverse audio data. We evaluate Pantagruel across a broad range of downstream tasks spanning both modalities, including those from the standard French benchmarks such as FLUE or LeBenchmark. Across these tasks, Pantagruel models show competitive or superior performance compared to strong French baselines such as CamemBERT, FlauBERT, and LeBenchmark2.0, while maintaining a shared architecture that can seamlessly handle either speech or text inputs. These results confirm the effectiveness of feature-space self-supervised objectives for French representation learning and highlight Pantagruel as a robust foundation for multimodal speech-text understanding.

</details>


### [136] [The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.06002)
*Qiguang Chen,Yantao Du,Ziniu Li,Jinhao Liu,Songyao Duan,Jiarui Guo,Minghao Liu,Jiaheng Liu,Tong Yang,Ge Zhang,Libo Qin,Wanxiang Che,Wenhao Huang*

Main category: cs.CL

TL;DR: 研究发现有效的长链思维（Long CoT）推理具有类分子结构，并通过深度推理、自我反思和自我探索三种互动形成。提出了一种名为Mole-Syn的方法，通过引导有效Long CoT结构的合成来提高性能和RL稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在学习有效的长链思维（Long CoT）推理方面存在困难，作者希望理解其原因并提出解决方案。

Method: 提出了一种将Long CoT轨迹类比为具有三种相互作用（深度推理、自我反思、自我探索）的分子结构的统一视图。通过分析提炼后的轨迹来揭示这些结构的形成机制，并引入了“有效语义异构体”的概念来研究哪些“键”有利于Long CoT学习。基于这些发现，提出了一种名为Mole-Syn的分布转移图方法来引导有效Long CoT结构的合成。

Result: 分析表明，有效的Long CoT结构是通过Long CoT微调而非关键词模仿产生的。仅促进快速熵收敛的“键”才支持稳定的Long CoT学习，而结构竞争会损害训练。Mole-Syn方法在基准测试中提高了性能和RL稳定性。

Conclusion: 有效的长链思维（Long CoT）推理具有类分子结构，其学习过程与特定类型的键（促进熵收敛）以及避免结构竞争有关。提出的Mole-Syn方法能够有效合成这些结构，从而提升LLMs的Long CoT推理能力和RL稳定性。

Abstract: Large language models (LLMs) often fail to learn effective long chain-of-thought (Long CoT) reasoning from human or non-Long-CoT LLMs imitation. To understand this, we propose that effective and learnable Long CoT trajectories feature stable molecular-like structures in unified view, which are formed by three interaction types: Deep-Reasoning (covalent-like), Self-Reflection (hydrogen-bond-like), and Self-Exploration (van der Waals-like). Analysis of distilled trajectories reveals these structures emerge from Long CoT fine-tuning, not keyword imitation. We introduce Effective Semantic Isomers and show that only bonds promoting fast entropy convergence support stable Long CoT learning, while structural competition impairs training. Drawing on these findings, we present Mole-Syn, a distribution-transfer-graph method that guides synthesis of effective Long CoT structures, boosting performance and RL stability across benchmarks.

</details>


### [137] [Distilling Feedback into Memory-as-a-Tool](https://arxiv.org/abs/2601.05960)
*Víctor Gallego*

Main category: cs.CL

TL;DR: 本文提出了一种通过将推理过程中的临时反馈转化为可检索的指导，并结合基于文件的内存系统和代理控制的工具调用，来分摊推理成本的框架。该方法在Rubric Feedback Bench数据集上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在推理时存在成本高昂的问题，尤其是在需要复杂推理和迭代改进的场景下。

Method: 提出一个框架，利用文件型内存系统和代理控制的工具调用，将推理过程中的临时性批判（critiques）转化为可检索的指导（guidelines），从而实现推理成本的分摊。

Result: 在Rubric Feedback Bench数据集上的实验表明，该框架能够使增强后的LLM快速达到与测试时精炼（test-time refinement）流水线相当的性能，同时显著降低了推理成本。

Conclusion: 所提出的框架能够有效地降低LLM的推理成本，并保持或提高其性能，尤其适用于需要基于评分标准的学习场景。

Abstract: We propose a framework that amortizes the cost of inference-time reasoning by converting transient critiques into retrievable guidelines, through a file-based memory system and agent-controlled tool calls. We evaluate this method on the Rubric Feedback Bench, a novel dataset for rubric-based learning. Experiments demonstrate that our augmented LLMs rapidly match the performance of test-time refinement pipelines while drastically reducing inference cost.

</details>


### [138] [AdaFuse: Adaptive Ensemble Decoding with Test-Time Scaling for LLMs](https://arxiv.org/abs/2601.06022)
*Chengming Cui,Tianxin Wei,Ziyi Chen,Ruizhong Qiu,Zhichen Zeng,Zhining Liu,Xuying Ning,Duo Zhou,Jingrui He*

Main category: cs.CL

TL;DR: 本文提出了一种名为 AdaFuse 的自适应集成解码框架，通过动态选择语义相关的融合单元来克服现有集成方法在固定融合粒度和缺乏中途生成适应性方面的局限性。AdaFuse 在每个解码步骤中根据不确定性标准决定是否执行集成，并利用多样性感知缩放策略来探索替代方案，从而提高生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）集成方法存在固定融合粒度、缺乏中途生成适应性以及无法适应不同任务生成特性的根本性局限。

Method: 提出 AdaFuse 自适应集成解码框架，该框架在生成过程中动态选择语义相关的融合单元。通过引入不确定性准则来决定是否在每个解码步骤应用集成，并在不确定性较高时，采用多样性感知缩放策略探索替代候选续写，以指导集成决策。

Result: 在开放域问答、算术推理和机器翻译任务上的实验表明，AdaFuse 的性能持续优于强大的集成基线，平均相对提升了 6.88%。

Conclusion: AdaFuse 是一种有效的自适应集成解码框架，能够根据解码上下文动态调整融合行为，并实现自适应集成与测试时间缩放之间的协同作用，从而提升 LLM 的生成性能。

Abstract: Large language models (LLMs) exhibit complementary strengths arising from differences in pretraining data, model architectures, and decoding behaviors. Inference-time ensembling provides a practical way to combine these capabilities without retraining. However, existing ensemble approaches suffer from fundamental limitations. Most rely on fixed fusion granularity, which lacks the flexibility required for mid-generation adaptation and fails to adapt to different generation characteristics across tasks. To address these challenges, we propose AdaFuse, an adaptive ensemble decoding framework that dynamically selects semantically appropriate fusion units during generation. Rather than committing to a fixed granularity, AdaFuse adjusts fusion behavior on the fly based on the decoding context, with words serving as basic building blocks for alignment. To be specific, we introduce an uncertainty-based criterion to decide whether to apply ensembling at each decoding step. Under confident decoding states, the model continues generation directly. In less certain states, AdaFuse invokes a diversity-aware scaling strategy to explore alternative candidate continuations and inform ensemble decisions. This design establishes a synergistic interaction between adaptive ensembling and test-time scaling, where ensemble decisions guide targeted exploration, and the resulting diversity in turn strengthens ensemble quality. Experiments on open-domain question answering, arithmetic reasoning, and machine translation demonstrate that AdaFuse consistently outperforms strong ensemble baselines, achieving an average relative improvement of 6.88%. The code is available at https://github.com/CCM0111/AdaFuse.

</details>


### [139] [Don't Break the Cache: An Evaluation of Prompt Caching for Long-Horizon Agentic Tasks](https://arxiv.org/abs/2601.06007)
*Elias Lumer,Faheem Nizar,Akshaya Jangiti,Kevin Frank,Anmol Gulati,Mandar Phadate,Vamse Kumar Subbiah*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型（LLM）代理工作负载中提示缓存的效果，发现其可显著降低API成本（45-80%）并缩短首次令牌响应时间（13-31%）。研究比较了三种缓存策略，并针对不同LLM提供商（OpenAI、Anthropic、Google）进行了评估，提出了实用的缓存策略建议。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM代理在执行需要大量工具调用的复杂多轮任务方面取得了进展，但现有研究对提示缓存（一种用于降低成本和延迟的技术）在这些代理工作负载中的效益，特别是成本节省和缓存策略比较方面，仍显不足。

Method: 研究者在一个名为DeepResearchBench的多轮代理基准测试上，对OpenAI、Anthropic和Google三家主要LLM提供商进行了全面的提示缓存评估。他们比较了全上下文缓存、仅系统提示缓存以及排除动态工具结果缓存这三种策略。评估在超过500次代理会话中进行，使用10,000个token的系统提示，并测量API成本和首次令牌响应时间（TTFT）。

Result: 提示缓存将API成本降低了45-80%，并将TTFT提高了13-31%。研究发现，通过策略性地控制缓存块（如将动态内容放在系统提示末尾，避免传统的动态函数调用，以及排除动态工具结果）比朴素的全上下文缓存能提供更一致的收益，后者有时反而会增加延迟。不同提供商的缓存行为存在细微差异。

Conclusion: 提示缓存对于LLM代理工作负载非常有效，能显著降低成本并提高响应速度。策略性的缓存设计比简单的全上下文缓存更优，并且在不同LLM提供商之间存在差异。研究为在生产环境中的代理系统实现提示缓存提供了实用的指导。

Abstract: Recent advancements in Large Language Model (LLM) agents have enabled complex multi-turn agentic tasks requiring extensive tool calling, where conversations can span dozens of API calls with increasingly large context windows. However, although major LLM providers offer prompt caching to reduce cost and latency, its benefits for agentic workloads remain underexplored in the research literature. To our knowledge, no prior work quantifies these cost savings or compares caching strategies for multi-turn agentic tasks. We present a comprehensive evaluation of prompt caching across three major LLM providers (OpenAI, Anthropic, and Google) and compare three caching strategies, including full context caching, system prompt only caching, and caching that excludes dynamic tool results. We evaluate on DeepResearchBench, a multi-turn agentic benchmark where agents autonomously execute real-world web search tool calls to answer complex research questions, measuring both API cost and time to first token (TTFT) across over 500 agent sessions with 10,000-token system prompts. Our results demonstrate that prompt caching reduces API costs by 45-80% and improves time to first token by 13-31% across providers. We find that strategic prompt cache block control, such as placing dynamic content at the end of the system prompt, avoiding dynamic traditional function calling, and excluding dynamic tool results, provides more consistent benefits than naive full-context caching, which can paradoxically increase latency. Our analysis reveals nuanced variations in caching behavior across providers, and we provide practical guidance for implementing prompt caching in production agentic systems.

</details>


### [140] [Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards](https://arxiv.org/abs/2601.06021)
*Jiajie Zhang,Xin Lv,Ling Feng,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为 CaRR 的细粒度奖励框架，用于改进基于 RL 的 LLM 搜索代理，该框架强调推理的全面性、事实依据和证据连通性，并通过 C-GRPO 训练代理，实验表明 C-GRPO 优于标准方法，并能有效抑制捷径和幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有基于 RL 的 LLM 搜索代理依赖于二元结果奖励，无法捕捉推理过程的全面性和事实性，易导致捷径和幻觉。

Method: 提出 CaRR 框架，将问题分解为可验证的单跳评价指标，要求代理识别实体、提供正确引用并构建证据链。同时提出 C-GRPO，结合 CaRR 和结果奖励进行训练。

Result: C-GRPO 在多个深层搜索基准测试中持续优于基于结果的 RL 基线。实验验证 C-GRPO 有效地抑制了捷径利用，促进了全面、基于证据的推理，并对开放式深层研究任务表现出强大的泛化能力。

Conclusion: CaRR 和 C-GRPO 框架能够训练出更鲁棒、推理更全面、事实依据更强的深度搜索代理，有效解决了现有方法的局限性。

Abstract: Reinforcement learning (RL) has emerged as a critical technique for enhancing LLM-based deep search agents. However, existing approaches primarily rely on binary outcome rewards, which fail to capture the comprehensiveness and factuality of agents' reasoning process, and often lead to undesirable behaviors such as shortcut exploitation and hallucinations. To address these limitations, we propose \textbf{Citation-aware Rubric Rewards (CaRR)}, a fine-grained reward framework for deep search agents that emphasizes reasoning comprehensiveness, factual grounding, and evidence connectivity. CaRR decomposes complex questions into verifiable single-hop rubrics and requires agents to satisfy these rubrics by explicitly identifying hidden entities, supporting them with correct citations, and constructing complete evidence chains that link to the predicted answer. We further introduce \textbf{Citation-aware Group Relative Policy Optimization (C-GRPO)}, which combines CaRR and outcome rewards for training robust deep search agents. Experiments show that C-GRPO consistently outperforms standard outcome-based RL baselines across multiple deep search benchmarks. Our analysis also validates that C-GRPO effectively discourages shortcut exploitation, promotes comprehensive, evidence-grounded reasoning, and exhibits strong generalization to open-ended deep research tasks. Our code and data are available at https://github.com/THUDM/CaRR.

</details>


### [141] [HAPS: Hierarchical LLM Routing with Joint Architecture and Parameter Search](https://arxiv.org/abs/2601.05903)
*Zihang Tian,Rui Li,Jingsen Zhang,Xiaohe Bo,Wei Huo,Xu Chen*

Main category: cs.CL

TL;DR: 本文提出了HAPS，一个分层LLM路由框架，它同时搜索模型架构和参数，以提高LLM在不同任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由方法主要关注模型架构选择，而忽略了对任务性能至关重要的参数设置，这促使了本研究。

Method: HAPS采用分层路由机制：高层路由器选择LLM架构，低层路由器为选定架构搜索最优参数。设计了一个参数生成网络来共享两个路由器的参数，并采用奖励增强目标进行训练。

Result: 在两个常用基准测试中，HAPS的性能一致优于现有的强力路由基线。

Conclusion: HAPS通过联合优化模型架构和参数，提供了一种有效的LLM路由方法，能够提升在各种任务上的性能。

Abstract: Large language model (LLM) routing aims to exploit the specialized strengths of different LLMs for diverse tasks. However, existing approaches typically focus on selecting LLM architectures while overlooking parameter settings, which are critical for task performance. In this paper, we introduce HAPS, a hierarchical LLM routing framework that jointly searches over model architectures and parameters. Specifically, we use a high-level router to select among candidate LLM architectures, and then search for the optimal parameters for the selected architectures based on a low-level router. We design a parameter generation network to share parameters between the two routers to mutually enhance their capabilities. In the training process, we design a reward-augmented objective to effectively optimize our framework. Experiments on two commonly used benchmarks show that HAPS consistently outperforms strong routing baselines. We have released our code at https://github.com/zihangtian/HAPS.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [142] [Intent at a Glance: Gaze-Guided Robotic Manipulation via Foundation Models](https://arxiv.org/abs/2601.05336)
*Tracey Yee Hsin Tay,Xu Yan,Jonathan Ouyang,Daniel Wu,William Jiang,Jonathan Kao,Yuchen Cui*

Main category: cs.RO

TL;DR: 提出了一种名为GAMMA的系统，该系统结合了眼动追踪和视觉-语言模型，以直观的方式控制机器人执行操作任务。


<details>
  <summary>Details</summary>
Motivation: 在辅助护理等场景中，为机器人设计直观的控制界面是一个挑战。眼动追踪作为一种快速、非侵入且意图丰富的输入方式，非常适合用于传达用户目标。

Method: GAMMA系统利用以自我为中心的眼动追踪技术，结合视觉-语言模型来推断用户意图，并自主执行机器人操作任务。该系统通过将眼动注视点置于场景的语境中，将视觉注意力转化为高层次的语义理解，从而在无需特定任务训练的情况下进行技能选择和参数化。

Result: 在多种桌面操作任务的评估中，GAMMA系统相比于不带推理的基线眼动控制，表现出更鲁棒、更直观且更具泛化性的控制能力。

Conclusion: 结合基础模型和眼动追踪技术，能够实现自然且可扩展的机器人自主性，为人类-机器人交互提供了新的可能性。

Abstract: Designing intuitive interfaces for robotic control remains a central challenge in enabling effective human-robot interaction, particularly in assistive care settings. Eye gaze offers a fast, non-intrusive, and intent-rich input modality, making it an attractive channel for conveying user goals. In this work, we present GAMMA (Gaze Assisted Manipulation for Modular Autonomy), a system that leverages ego-centric gaze tracking and a vision-language model to infer user intent and autonomously execute robotic manipulation tasks. By contextualizing gaze fixations within the scene, the system maps visual attention to high-level semantic understanding, enabling skill selection and parameterization without task-specific training. We evaluate GAMMA on a range of table-top manipulation tasks and compare it against baseline gaze-based control without reasoning. Results demonstrate that GAMMA provides robust, intuitive, and generalizable control, highlighting the potential of combining foundation models and gaze for natural and scalable robot autonomy. Project website: https://gamma0.vercel.app/

</details>


### [143] [PRISM: Protocol Refinement through Intelligent Simulation Modeling](https://arxiv.org/abs/2601.05356)
*Brian Hsu,Priyanka V Setty,Rory M Butler,Ryan Lewis,Casey Stone,Rebecca Weinberg,Thomas Brettin,Rick Stevens,Ian Foster,Arvind Ramanathan*

Main category: cs.RO

TL;DR: 本文提出PRISM框架，利用基于语言模型的AI代理自动生成、验证和执行实验方案，并在数字孪生环境中进行模拟，最终实现自动化实验室。


<details>
  <summary>Details</summary>
Motivation: 实现“自动驾驶实验室”的关键瓶颈在于实验方案的设计和执行自动化，因此需要一个能够自动完成此过程的框架。

Method: PRISM框架使用语言模型驱动的AI代理，通过收集网络信息、规划、评审和验证的循环来生成结构化的实验步骤。这些步骤被翻译成MADSci格式，以便协调多种商用机器人（如OT-2、PF400、Azenta）。协议在NVIDIA Omniverse搭建的数字孪生环境中进行验证。

Result: PRISM能够生成实验方案，并通过数字孪生验证。在Luna qPCR扩增和Cell Painting实验中，PRISM被证明是一个可行的端到端工作流程，实现了从语言生成到模拟验证再到机器人执行的自动化。

Conclusion: PRISM框架成功实现了实验方案设计和执行的自动化，为构建自动驾驶实验室迈出了重要一步，并展示了其在实际实验中的应用潜力。

Abstract: Automating experimental protocol design and execution remains as a fundamental bottleneck in realizing self-driving laboratories. We introduce PRISM (Protocol Refinement through Intelligent Simulation Modeling), a framework that automates the design, validation, and execution of experimental protocols on a laboratory platform composed of off-the-shelf robotic instruments. PRISM uses a set of language-model-based agents that work together to generate and refine experimental steps. The process begins with automatically gathering relevant procedures from web-based sources describing experimental workflows. These are converted into structured experimental steps (e.g., liquid handling steps, deck layout and other related operations) through a planning, critique, and validation loop. The finalized steps are translated into the Argonne MADSci protocol format, which provides a unified interface for coordinating multiple robotic instruments (Opentrons OT-2 liquid handler, PF400 arm, Azenta plate sealer and peeler) without requiring human intervention between steps. To evaluate protocol-generation performance, we benchmarked both single reasoning models and multi-agent workflow across constrained and open-ended prompting paradigms. The resulting protocols were validated in a digital-twin environment built in NVIDIA Omniverse to detect physical or sequencing errors before execution. Using Luna qPCR amplification and Cell Painting as case studies, we demonstrate PRISM as a practical end-to-end workflow that bridges language-based protocol generation, simulation-based validation, and automated robotic execution.

</details>


### [144] [Assembling Solar Panels by Dual Robot Arms Towards Full Autonomous Lunar Base Construction](https://arxiv.org/abs/2601.05491)
*Luca Nunziante,Kentaro Uno,Gustavo H. Diaz,Shreya Santra,Alessandro De Luca,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本文提出了一种集成视觉、控制和硬件系统的自主双臂机器人系统，用于在月球上组装太阳能电池板模块，并在现实世界实验中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为了支持未来重返月球的科学探索、资源开采和居住目标，需要开发能够在月球上安全高效地建造基础设施（如太阳能发电塔）的机器人系统。

Method: 研究人员设计并测试了一个专门用于组装太阳能电池板模块的感知和控制流程。该流程集成了视觉、控制和专门设计的硬件，包括模拟的模块化太阳能电池板和带有集成控制的连接器。

Result: 实验证明，该双臂机器人系统能够有效地连接任意放置的太阳能电池板模块，验证了所提出的集成视觉、控制和硬件系统的自主组装方法。

Conclusion: 该研究成功展示了将视觉、控制和硬件系统无缝集成到复杂空间应用（如月球上的太阳能电池板组装）中的可行性，为未来月球基础设施的自主建造奠定了基础。

Abstract: Since the successful Apollo program, humanity is once again aiming to return to the Moon for scientific discovery, resource mining, and inhabitation. Upcoming decades focus on building a lunar outpost, with robotic systems playing a crucial role to safely and efficiently establish essential infrastructure such as solar power generating towers. Similar to the construction of the International Space Station (ISS), shipping necessary components via modules and assembling them in situ should be a practical scenario. In this context, this paper focuses on the integration of vision, control, and hardware systems within an autonomous sequence for a dual-arm robot system. We explore a perception and control pipeline specifically designed for assembling solar panel modules, one of the benchmark tasks. Ad hoc hardware was designed and tested in real-world experiments. A mock-up of modular solar panels and active-passive connectors are employed, with the control of this grappling fixture integrated into the proposed pipeline. The successful implementation of our method demonstrates that the two robot manipulators can effectively connect arbitrarily placed panels, highlighting the seamless integration of vision, control, and hardware systems in complex space applications.

</details>


### [145] [TOSC: Task-Oriented Shape Completion for Open-World Dexterous Grasp Generation from Partial Point Clouds](https://arxiv.org/abs/2601.05499)
*Weishang Wu,Yifei Shi,Zhiping Cai*

Main category: cs.RO

TL;DR: 提出一种名为Task-Oriented Shape Completion的新任务，专注于补全抓取所需的局部区域而非整体形状，以应对机器人开放世界物体抓取中因严重观测不足导致的形状补全问题。通过利用预训练基础模型的零样本功能理解生成候选补全，再用3D判别自编码器优化，最后用FlowGrasp模型生成抓取姿态，显著提升了抓取和形状补全性能，尤其在处理数据严重缺失的对象时表现出色。


<details>
  <summary>Details</summary>
Motivation: 开放世界物体抓取中，严重的局部观测不足导致通用形状补全失效，使得任务导向的灵巧抓取成为挑战。现有方法无法有效处理信息缺失的情况。

Method: 1. 提出Task-Oriented Shape Completion任务，侧重补全潜在接触区域。 2. 利用预训练基础模型的零样本功能理解能力生成多个任务导向的形状补全候选。 3. 设计3D判别自编码器评估候选并全局优化。 4. 开发FlowGrasp（条件流匹配模型）从优化后的形状生成任务导向的灵巧抓取。

Result: 在任务导向的灵巧抓取和任务导向的形状补全方面均达到最先进水平。Grasp Displacement（抓取位移）和Chamfer Distance（倒角距离）分别比现有方法提高了16.17%和55.26%。在处理严重数据缺失的对象、开放集类别和任务方面表现出良好的能力和泛化性。

Conclusion: 所提出的Task-Oriented Shape Completion方法通过任务驱动的局部形状补全，有效解决了因严重观测不足导致的机器人抓取难题，并实现了高性能的任务导向灵巧抓取，展现了良好的泛化能力。

Abstract: Task-oriented dexterous grasping remains challenging in robotic manipulations of open-world objects under severe partial observation, where significant missing data invalidates generic shape completion. In this paper, to overcome this limitation, we study Task-Oriented Shape Completion, a new task that focuses on completing the potential contact regions rather than the entire shape. We argue that shape completion for grasping should be explicitly guided by the downstream manipulation task. To achieve this, we first generate multiple task-oriented shape completion candidates by leveraging the zero-shot capabilities of object functional understanding from several pre-trained foundation models. A 3D discriminative autoencoder is then proposed to evaluate the plausibility of each generated candidate and optimize the most plausible one from a global perspective. A conditional flow-matching model named FlowGrasp is developed to generate task-oriented dexterous grasps from the optimized shape. Our method achieves state-of-the-art performance in task-oriented dexterous grasping and task-oriented shape completion, improving the Grasp Displacement and the Chamfer Distance over the state-of-the-art by 16.17\% and 55.26%, respectively. In particular, it shows good capabilities in grasping objects with severe missing data. It also demonstrates good generality in handling open-set categories and tasks.

</details>


### [146] [Learning specifications for reactive synthesis with safety constraints](https://arxiv.org/abs/2601.05533)
*Kandai Watanabe,Nicholas Renninger,Sriram Sankaranarayanan,Morteza Lahijanian*

Main category: cs.RO

TL;DR: 该论文提出了一种新颖的从演示学习方法，使机器人在动态环境中自主执行复杂任务。它将潜在任务建模为概率形式语言，并引入了一个反应式合成框架，该框架平衡了机器人成本和用户任务偏好，同时确保安全约束。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于使机器人能够在动态环境中自主执行复杂任务，并能同时考虑机器人自身的成本以及用户的任务偏好，同时保证任务的安全性。

Method: 该方法将潜在任务建模为概率形式语言，并使用概率确定性有限自动机（PDFA）来推断形式化任务规范。通过证据驱动的状态合并算法和安全约束的学习过程来确保PDFA的安全性。引入了多目标反应式合成算法，通过值迭代生成最优策略的帕累托前沿，以平衡用户偏好和机器人成本。

Result: 学习到的PDFA不包含不安全行为。合成的策略能够一致地完成任务，同时满足机器人成本和用户偏好的要求。实验结果证明了该算法在不同机器人和任务上的有效性。

Conclusion: 该方法能够安全地从演示中学习复杂的机器人任务，并生成满足用户偏好和机器人成本要求的最优策略，在动态环境中表现出色。

Abstract: This paper presents a novel approach to learning from demonstration that enables robots to autonomously execute complex tasks in dynamic environments. We model latent tasks as probabilistic formal languages and introduce a tailored reactive synthesis framework that balances robot costs with user task preferences. Our methodology focuses on safety-constrained learning and inferring formal task specifications as Probabilistic Deterministic Finite Automata (PDFA). We adapt existing evidence-driven state merging algorithms and incorporate safety requirements throughout the learning process to ensure that the learned PDFA always complies with safety constraints. Furthermore, we introduce a multi-objective reactive synthesis algorithm that generates deterministic strategies that are guaranteed to satisfy the PDFA task while optimizing the trade-offs between user preferences and robot costs, resulting in a Pareto front of optimal solutions. Our approach models the interaction as a two-player game between the robot and the environment, accounting for dynamic changes. We present a computationally-tractable value iteration algorithm to generate the Pareto front and the corresponding deterministic strategies. Comprehensive experimental results demonstrate the effectiveness of our algorithms across various robots and tasks, showing that the learned PDFA never includes unsafe behaviors and that synthesized strategies consistently achieve the task while meeting both the robot cost and user-preference requirements.

</details>


### [147] [EvoQRE: Modeling Bounded Rationality in Safety-Critical Traffic Simulation via Evolutionary Quantal Response Equilibrium](https://arxiv.org/abs/2601.05653)
*Phu-Hoa Pham,Chi-Nguyen Tran,Duy-Minh Dao-Sy,Phu-Quy Nguyen-Lam,Trung-Kiet Huynh*

Main category: cs.RO

TL;DR: 提出了一种名为EvoQRE的新框架，用于对自动驾驶汽车的交通交互进行建模。它使用量化响应均衡（QRE）和进化博弈论来捕捉人类驾驶员有限理性的随机行为，并在Waymo和nuPlan数据集上取得了最先进的真实感和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶交通模拟框架通常假设人类驾驶员是完全理性的，但实际上人类驾驶员表现出有限的理性，会在认知和感知限制下做出近似最优的决策。因此，需要一个能捕捉这种有限理性的模型。

Method: EvoQRE框架将交通交互建模为一般和马尔可夫博弈，并使用量化响应均衡（QRE）和进化博弈动力学来求解。该框架集成了预训练的生成世界模型和熵正则化复制子动力学，以捕捉随机的人类行为并保持均衡结构。它还扩展了QRE以处理连续动作空间，并使用混合和基于能量的策略表示。

Result: 理论上证明了所提出的动力学在特定假设下收敛到Logit-QRE，并具有明确的收敛速率。实验结果表明，EvoQRE在Waymo Open Motion Dataset和nuPlan基准测试中达到了最先进的真实感，提高了安全指标，并且可以通过可解释的理性参数可控地生成多样化的安全关键场景。

Conclusion: EvoQRE框架能够以一种原则性的方式模拟安全关键的交通交互，通过整合有限理性、随机行为和博弈论概念，有效地捕捉人类驾驶员的行为，并在真实数据集上验证了其优越性。

Abstract: Existing traffic simulation frameworks for autonomous vehicles typically rely on imitation learning or game-theoretic approaches that solve for Nash or coarse correlated equilibria, implicitly assuming perfectly rational agents. However, human drivers exhibit bounded rationality, making approximately optimal decisions under cognitive and perceptual constraints. We propose EvoQRE, a principled framework for modeling safety-critical traffic interactions as general-sum Markov games solved via Quantal Response Equilibrium (QRE) and evolutionary game dynamics. EvoQRE integrates a pre-trained generative world model with entropy-regularized replicator dynamics, capturing stochastic human behavior while maintaining equilibrium structure. We provide rigorous theoretical results, proving that the proposed dynamics converge to Logit-QRE under a two-timescale stochastic approximation with an explicit convergence rate of O(log k / k^{1/3}) under weak monotonicity assumptions. We further extend QRE to continuous action spaces using mixture-based and energy-based policy representations. Experiments on the Waymo Open Motion Dataset and nuPlan benchmark demonstrate that EvoQRE achieves state-of-the-art realism, improved safety metrics, and controllable generation of diverse safety-critical scenarios through interpretable rationality parameters.

</details>


### [148] [Motion Compensation for Real Time Ultrasound Scanning in Robotically Assisted Prostate Biopsy Procedures](https://arxiv.org/abs/2601.05661)
*Matija Markulin,Luka Matijević,Luka Siktar,Janko Jurdana,Branimir Caran,Marko Švaco,Filip Šuligoj,Bojan Šekoranja*

Main category: cs.RO

TL;DR: 研究开发了一个机器人辅助系统，用于前列腺超声检查，旨在提高前列腺活检的精度和可及性。该系统通过精确控制超声探头的运动和实时运动补偿，能够快速生成高精度的前列腺三维重建模型。


<details>
  <summary>Details</summary>
Motivation: 前列腺癌是男性常见癌症，其活检诊断对手术者的技能要求高，结果具有很强的操作者依赖性。开发一个机器人辅助系统可以降低对手术者技能的要求，使前列腺活检更快、更准确、更易于获得。

Method: 开发了一个包含协作机器人手臂的实验室装置，该手臂可以自主扫描前列腺模型，并将模型连接到模拟患者运动的医用机器人手臂上。通过保持超声探头与前列腺相对位置恒定，对每一层进行分割，生成前列腺轮廓，并转换为三维点云用于活检规划。在四种运动场景下（静止、水平运动、垂直运动、组合运动）进行了系统验证，并使用ICP算法对不同运动状态下的点云重建进行配准。

Result: 平均扫描时间为30秒，三维重建平均耗时3秒。在静止状态下的扫描基础上，S-H、S-V和S-C配准的平均拟合度分别为83.2%、84.1%和79.4%，均方根误差（RMSE）分别为0.35 mm、0.37 mm和0.37 mm。机器人最大跟踪误差为3 mm，运动补偿最大延迟为0.5秒。

Conclusion: 该机器人辅助超声检查系统能够实现快速、稳定的前列腺三维重建，并且在模拟运动的情况下仍能保持较高的重建精度，具有减少操作者依赖性、提高前列腺活检效率和准确性的潜力。

Abstract: Prostate cancer is one of the most common types of cancer in men. Its diagnosis by biopsy requires a high level of expertise and precision from the surgeon, so the results are highly operator-dependent. The aim of this work is to develop a robotic system for assisted ultrasound (US) examination of the prostate, a prebiopsy step that could reduce the dexterity requirements and enable faster, more accurate and more available prostate biopsy. We developed and validated a laboratory setup with a collaborative robotic arm that can autonomously scan a prostate phantom and attached the phantom to a medical robotic arm that mimics the patient's movements. The scanning robot keeps the relative position of the US probe and the prostate constant, ensuring a consistent and robust approach to reconstructing the prostate. To reconstruct the prostate, each slice is segmented to generate a series of prostate contours converted into a 3D point cloud used for biopsy planning. The average scan time of the prostate was 30 s, and the average 3D reconstruction of the prostate took 3 s. We performed four motion scenarios: the phantom was scanned in a stationary state (S), with horizontal motion (H), with vertical motion (V), and with a combination of the two (C). System validation is performed by registering the prostate point cloud reconstructions acquired during different motions (H, V, C) with those obtained in the stationary state. ICP registration with a threshold of 0.8 mm yields mean 83.2\% fitness and 0.35 mm RMSE for S-H registration, 84.1\% fitness and 0.37 mm RMSE for S-V registration and 79.4\% fitness and 0.37 mm RMSE for S-C registration. Due to the elastic and soft material properties of the prostate phantom, the maximum robot tracking error was 3 mm, which can be sufficient for prostate biopsy according to medical literature. The maximum delay in motion compensation was 0.5 s.

</details>


### [149] [InsSo3D: Inertial Navigation System and 3D Sonar SLAM for turbid environment inspection](https://arxiv.org/abs/2601.05805)
*Simon Archieri,Ahmet Cinar,Shu Pan,Jonatan Scharff Willners,Michele Grimald,Ignacio Carlucho,Yvan Petillot*

Main category: cs.RO

TL;DR: 本文提出了一种名为 InsSo3D 的新方法，该方法利用 3D 声纳和惯性导航系统 (INS) 实现大型 3D 同时定位与地图构建 (SLAM)，有效解决了声纳在测高方面的不足，并在水下环境中实现了低漂移的轨迹估计和高精度地图重建。


<details>
  <summary>Details</summary>
Motivation: 现有水下 SLAM 方法在处理声纳数据时存在 elevation ambiguity（测高模糊）问题，InsSo3D 旨在通过使用 3D 声纳数据并结合 INS 作为先验信息来解决这一限制，以实现更准确高效的大规模水下 SLAM。

Method: InsSo3D 采用一种适应 3D 声纳数据的 SLAM 框架，将 INS 作为先验信息，并引入了回环检测和姿态图优化技术。

Result: 在水箱和水下采石场环境中进行评估，InsSo3D 在长达 50 分钟的任务中实现了低于 21 厘米的平均轨迹误差，并生成了平均重建误差为 9 厘米的 10m x 20m 地图。与参考轨迹和视觉 SFM 结果相比，InsSo3D 能有效校正里程计漂移。

Conclusion: InsSo3D 是一种准确且高效的大规模 3D SLAM 方法，适用于水下环境，即使在能见度差的浑浊水域也能安全地对水下结构进行检测。

Abstract: This paper presents InsSo3D, an accurate and efficient method for large-scale 3D Simultaneous Localisation and Mapping (SLAM) using a 3D Sonar and an Inertial Navigation System (INS). Unlike traditional sonar, which produces 2D images containing range and azimuth information but lacks elevation information, 3D Sonar produces a 3D point cloud, which therefore does not suffer from elevation ambiguity. We introduce a robust and modern SLAM framework adapted to the 3D Sonar data using INS as prior, detecting loop closure and performing pose graph optimisation. We evaluated InsSo3D performance inside a test tank with access to ground truth data and in an outdoor flooded quarry. Comparisons to reference trajectories and maps obtained from an underwater motion tracking system and visual Structure From Motion (SFM) demonstrate that InsSo3D efficiently corrects odometry drift. The average trajectory error is below 21cm during a 50-minute-long mission, producing a map of 10m by 20m with a 9cm average reconstruction error, enabling safe inspection of natural or artificial underwater structures even in murky water conditions.

</details>


### [150] [Modular Autonomy with Conversational Interaction: An LLM-driven Framework for Decision Making in Autonomous Driving](https://arxiv.org/abs/2601.05806)
*Marvin Seegert,Korbinian Moller,Johannes Betz*

Main category: cs.RO

TL;DR: 本研究提出了一个框架，将大型语言模型（LLMs）的自然语言指令转化为自动驾驶系统（ADS）的结构化动作，通过DSL进行翻译并设有安全验证层，实现了高效且鲁棒的人机交互。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统的人机交互方式较为僵化，本研究旨在利用大型语言模型的进步，创建更自然、更灵活的交互方式，将复杂的自然语言指令映射到模块化自动驾驶软件的结构化动作空间。

Method: 提出一个集成了基于LLM的交互层和Autoware（一个开源自动驾驶软件）的框架。该框架包含三个关键组件：交互类别的分类、用于命令翻译的应用中心领域特定语言（DSL）以及一个安全验证层。采用了两阶段LLM架构，并通过明确的执行状态提供反馈以确保高透明度。

Result: 实验证实了该系统在时间效率和翻译鲁棒性方面的优势。通过模拟验证了在所有五个交互类别中命令执行的成功率。

Conclusion: 该研究为模块化、注重安全的自动驾驶系统中，基于DSL的、可扩展的交互方式奠定了基础，实现了乘客通过自然语言查询状态或修改驾驶行为等高层指令。

Abstract: Recent advancements in Large Language Models (LLMs) offer new opportunities to create natural language interfaces for Autonomous Driving Systems (ADSs), moving beyond rigid inputs. This paper addresses the challenge of mapping the complexity of human language to the structured action space of modular ADS software. We propose a framework that integrates an LLM-based interaction layer with Autoware, a widely used open-source software. This system enables passengers to issue high-level commands, from querying status information to modifying driving behavior. Our methodology is grounded in three key components: a taxonomization of interaction categories, an application-centric Domain Specific Language (DSL) for command translation, and a safety-preserving validation layer. A two-stage LLM architecture ensures high transparency by providing feedback based on the definitive execution status. Evaluation confirms the system's timing efficiency and translation robustness. Simulation successfully validated command execution across all five interaction categories. This work provides a foundation for extensible, DSL-assisted interaction in modular and safety-conscious autonomy stacks.

</details>


### [151] [Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning](https://arxiv.org/abs/2601.05836)
*Sheng-Kai Chen,Jyh-Horng Wu*

Main category: cs.RO

TL;DR: 本文提出了一种结合模糊逻辑安全系统和强化学习算法的UR10机械臂路径规划奇点检测与规避方法，实验证明该方法能有效避开奇异点，提高路径规划的安全性。


<details>
  <summary>Details</summary>
Motivation: 机械臂在操作过程中可能遇到的奇异点会导致失控和设备损坏，这在机器人操作中是一个关键的挑战，需要有效的检测和规避方法。

Method: 该研究采用混合方法，结合了使用可操作性度量、条件数分析和模糊逻辑决策的实时奇点检测，以及一个用于自适应路径规划的稳定强化学习框架。研究利用PyBullet仿真环境收集训练数据，并通过URSim进行实际部署。

Result: 在达到目标位置的同时，与奇异构型保持安全距离的成功率为90%。

Conclusion: 提出的混合方法能够有效地检测并规避UR10机械臂在路径规划中的奇异点，显著提高了操作的成功率和安全性。

Abstract: This paper presents a comprehensive approach to singularity detection and avoidance in UR10 robotic arm path planning through the integration of fuzzy logic safety systems and reinforcement learning algorithms. The proposed system addresses critical challenges in robotic manipulation where singularities can cause loss of control and potential equipment damage. Our hybrid approach combines real-time singularity detection using manipulability measures, condition number analysis, and fuzzy logic decision-making with a stable reinforcement learning framework for adaptive path planning. Experimental results demonstrate a 90% success rate in reaching target positions while maintaining safe distances from singular configurations. The system integrates PyBullet simulation for training data collection and URSim connectivity for real-world deployment.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [152] [Experimental Demonstration of a Decentralized Electromagnetic Formation Flying Control Using Alternating Magnetic Field Forces](https://arxiv.org/abs/2601.05408)
*Sumit S. Kamat,Ajin Sunny,T. Michael Seigler,Jesse B. Hoagg*

Main category: eess.SY

TL;DR: 本文提出了一种交变磁场力（AMFF）的方法来解决多卫星电磁编队飞行（EMFF）中的耦合问题，并通过三卫星实验验证了其去中心化闭环控制的可行性，这是首次在三卫星或更多卫星系统中实现AMFF。


<details>
  <summary>Details</summary>
Motivation: 现有电磁编队飞行（EMFF）方法面临卫星间复杂的电磁场耦合问题，尤其是在涉及三个或更多卫星的编队中，该问题更加突出。因此，需要一种新的方法来解耦这些力，以实现有效的编队控制。

Method: 该研究利用交变磁场力（AMFF）来解耦卫星间的电磁力。每个卫星的电磁驱动系统通过幅度调制的正弦波信号驱动，通过控制信号幅度来实现期望的卫星间作用力。实验采用了一个包含三个电磁驱动卫星的地面测试平台，这些卫星在直线气垫轨道上运行，并实现了去中心化的闭环控制。

Result: 实验成功演示了三卫星去中心化闭环电磁编队飞行（EMFF），这是首次在三个或更多卫星系统中实现AMFF。实验结果与数值模拟结果进行了对比，表明AMFF方法在应对多卫星EMFF中的耦合挑战方面是有效的。

Conclusion: 交变磁场力（AMFF）是一种有效的解耦多卫星电磁编队飞行（EMFF）中卫星间电磁耦合的方法。三卫星的去中心化闭环实验验证了该方法的有效性和可行性，为未来更复杂的EMFF任务提供了基础。

Abstract: Electromagnetic formation flying (EMFF) is challenging due to the complex coupling between the electromagnetic fields generated by each satellite in the formation. To address this challenge, this article uses alternating magnetic field forces (AMFF) to decouple the electromagnetic forces between each pair of satellites. Each satellite's electromagnetic actuation system is driven by a sum of amplitude-modulated sinusoids, where amplitudes are controlled to achieve desired forces between each pair of satellites. The main contribution of this article is a 3-satellite experimental demonstration of decentralized closed-loop EMFF using AMFF. To our knowledge, this is the first demonstration of AMFF with at least 3 satellites in open or closed loop. This is noteworthy because the coupling challenges of EMFF are only present with more than 2 satellites, and thus, a formation of at least 3 is necessary to evaluate the effectiveness of AMFF. The experiments are conducted on a ground-based testbed consisting of 3 electromagnetically actuated satellites on linear air tracks. The closed-loop experimental results are compared with behavior from numerical simulations.

</details>


### [153] [Data-Based Analysis of Relative Degree and Zero Dynamics in Linear Systems](https://arxiv.org/abs/2601.05395)
*Janina Schaa,Thomas Berger*

Main category: eess.SY

TL;DR: 本文提出了一种基于数据驱动的方法，用于在不显式建模的情况下评估关键的系统理论性质，从而为选择合适的控制策略提供依据。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的控制方法在系统模型未知或复杂时受到限制。因此，需要一种能够直接从数据中评估系统性质并指导控制策略选择的方法。

Method: 该方法利用测量数据来评估（向量）相对次数和零点动力学的稳定性，这些是确保控制器性能的关键性质。研究涵盖了离散时间线性系统的单输入/输出和多输入/输出情况。此外，还提出了从不同采样时间的零阶保持离散化中重建连续时间系统的方法。

Result: 提出了基于数据的条件来表征（向量）相对次数和零点动力学的稳定性。这些结果可以直接应用于观测到的数据集。

Conclusion: 该数据驱动方法提供了一种在不进行显式模型识别的情况下，有效地评估关键系统理论性质的方法，从而能够明智地选择控制策略，并且可以直接应用于实际数据。

Abstract: Data-driven control offers a powerful alternative to traditional model-based methods, particularly when accurate system models are unavailable or prohibitively complex. While existing data-driven control methods primarily aim to construct controllers directly from measured data, our approach uses the available data to assess fundamental system-theoretic properties. This allows the informed selection of suitable control strategies without explicit model identification. We provide data-based conditions characterizing the (vector) relative degree and the stability of the zero dynamics, which are critical for ensuring proper performance of modern controllers. Our results cover both single- and multi-input/output settings of discrete-time linear systems. We further show how a continuous-time system can be reconstructed from three sampling discretizations obtained via Zero-order Hold at suitable sampling times, thus allowing the extension of the results to the combined data collected from these discretizations. All results can be applied directly to observed data sets using the proposed algorithms.

</details>


### [154] [How Carbon Border Adjustment Mechanism is Energizing the EU Carbon Market and Industrial Transformation](https://arxiv.org/abs/2601.05490)
*Joseph Nyangon,Brecht Seifi*

Main category: eess.SY

TL;DR: 欧盟提出了碳边境调节机制（CBAM），旨在解决欧盟排放交易体系（EU ETS）带来的国际竞争力下降和碳泄漏问题，通过对进口商品征收碳价，使其与国内生产商的碳成本保持一致，并逐步取代现有的免费配额。


<details>
  <summary>Details</summary>
Motivation: 全球碳市场缺乏透明度，且在确定碳管理机会方面存在挑战。欧盟排放交易体系（EU ETS）虽然减少了排放，但也引发了关于国际竞争力和碳泄漏的担忧，尤其是在全球价值链日益融合的背景下。为了应对这些问题，欧盟提出了CBAM。

Method: CBAM 将作为 EU ETS 的补充机制，对特定进口商品（如电力、水泥、化肥、铝、钢铁等）施加碳价，以平衡国内外生产商的碳成本。该机制将逐步取代现有的免费配额等碳泄漏缓解措施。

Result: CBAM 的实施旨在通过对进口商品施加碳成本，来缓解 EU ETS 对欧盟产业国际竞争力的负面影响，并防止碳泄漏。它将为其他地区提供一种管理碳相关贸易风险和支持净零排放转型的机制。

Conclusion: 随着全球气候政策的加强，CBAM 及其类似的机制预计将在管理碳相关贸易风险和推动实现净零排放目标方面发挥日益重要的作用。

Abstract: The global carbon market is fragmented and characterized by limited pricing transparency and empirical evidence, creating challenges for investors and policymakers in identifying carbon management opportunities. The European Union is among several regions that have implemented emissions pricing through an Emissions Trading System (EU ETS). While the EU ETS has contributed to emissions reductions, it has also raised concerns related to international competitiveness and carbon leakage, particularly given the strong integration of EU industries into global value chains. To address these challenges, the European Commission proposed the Carbon Border Adjustment Mechanism (CBAM) in 2021. CBAM is designed to operate alongside the EU ETS by applying a carbon price to selected imported goods, thereby aligning carbon costs between domestic and foreign producers. It will gradually replace existing carbon leakage mitigation measures, including the allocation of free allowances under the EU ETS. The initial scope of CBAM covers electricity, cement, fertilizer, aluminium, iron, and steel. As climate policies intensify under the Paris Agreement, CBAM-like mechanisms are expected to play an increasingly important role in managing carbon-related trade risks and supporting the transition to net zero emissions.

</details>


### [155] [SIaD-Tool: A Comprehensive Frequency-Domain Tool for Small-Signal Stability and Interaction Assessment in Modern Power Systems](https://arxiv.org/abs/2601.05519)
*Luis A. Garcia-Reyes,Oriol Gomis-Bellmunt,Eduardo Prieto-Araujo,Vinícius A. Lacerda,Marc Cheah-Mañe*

Main category: eess.SY

TL;DR: 本文提出了一种名为 SIaD-Tool 的开源频域（FD）扫描工具，用于现代电力系统的稳定性和交互作用评估。该工具支持多序列识别和多种扰动策略，并能在目标坐标系中直接进行扫描，简化了耦合效应和镜像频率的分析。它集成了四种标准化的自动稳定性评估方法，并通过广泛的案例研究进行了验证，结果表明其在检测关键模态、交互频率、振荡行为和稳定裕度方面具有高精度、可扩展性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统日益复杂，包含大量电力电子设备，需要新的工具来准确评估其稳定性和交互作用。

Method: 开发了一个名为 SIaD-Tool 的开源频域扫描解决方案，支持 abc、dq0 和 0pn 坐标系，并采用串联电压和并联电流扰动策略。引入了一种新的扰动方案，允许直接在目标坐标系中进行扫描。集成了四种自动稳定性评估方法：广义奈奎斯特判据（GNC）、模态阻抗分析、相位裕度评估和无源性检查。

Result: SIaD-Tool 在不同类型的系统（包括无源元件、并网和自并网转换器、海上风电场和 IEEE 9 节点系统）的案例研究中得到了验证。结果表明，该工具在检测关键模态、交互频率、振荡行为和稳定裕度方面表现出高精度、可扩展性和鲁棒性。

Conclusion: SIaD-Tool 是一个功能强大、灵活且易于使用的工具，可用于现代电力系统的稳定性与交互作用评估，并为实际应用提供了可靠的解决方案。

Abstract: This paper presents SIaD-Tool, an open-source frequency-domain (FD) scanning solution for stability and interaction assessment in modern power systems. The tool enables multi-sequence identification in the abc, dq0, and 0pn frames and supports both series voltage and parallel current perturbation strategies. A novel perturbation scheme allows direct scanning in the target frame, simplifying the analysis of coupling effects and mirrored frequencies. SIaD-Tool is implemented on a multi-platform architecture, including MATLAB/Simulink and Python-PSCAD/EMTDC. Beyond system identification, it integrates automated stability evaluation through four standardized methods: Generalized Nyquist Criterion (GNC), modal impedance analysis, phase margin assessment, and passivity checks. Validation is carried out via extensive case studies involving passive elements, grid-following and grid-forming converters, offshore wind power plants, and the IEEE 9-bus system. Results confirm high accuracy, scalability, and robustness in detecting critical modes, interaction frequencies, oscillatory behavior, and stability margins.

</details>


### [156] [Discrete Homogeneity and Quantizer Design for Nonlinear Homogeneous Control Systems](https://arxiv.org/abs/2601.05526)
*Yu Zhou,Andrey Polyakov,Gang Zheng,Masaaki Nagahara*

Main category: eess.SY

TL;DR: 该论文提出了一种分析带状态量化的一般齐次控制系统的框架，并设计了一种能够保证有限/固定时间稳定性的几何感知齐次静态矢量量化器。


<details>
  <summary>Details</summary>
Motivation: 在状态量化存在的情况下，维持非线性系统的有限/固定时间稳定性是一个挑战。

Method: 引入一种新的离散齐次性概念，并通过逆李雅普诺夫函数定理证明了其有效性。将扇形有界性概念推广到齐次向量空间，推导了保证有限/固定时间稳定性的广义齐次扇形有界性条件。设计了一种基于广义齐次坐标的几何感知齐次静态矢量量化器。

Result: 所提出的齐次控制系统和量化器被证明是离散膨胀齐次的，并且根据齐次度，全局有限时间、近固定时间或指数稳定。数值示例验证了该方法的有效性。

Conclusion: 该研究提出了一种有效的框架和量化器，用于解决带状态量化的一般齐次控制系统的有限/固定时间稳定性问题，并证明了其鲁棒性。

Abstract: This paper proposes a framework for analysis of generalized homogeneous control systems under state quantization. In particular, it addresses the challenge of maintaining finite/fixed-time stability of nonlinear systems in the presence of quantized measurements. To analyze the behavior of quantized control system, we introduce a new type of discrete homogeneity, where the dilation is defined by a discrete group. The converse Lyapunov function theorem is established for homogeneous systems with respect to discrete dilations. By extending the notion of sector-boundedness to a homogeneous vector space, we derive a generalized homogeneous sector-boundedness condition that guarantees finite/fixed-time stability of nonlinear control system under quantized measurements. A geometry-aware homogeneous static vector quantizer is then designed using generalized homogeneous coordinates, enabling an efficient quantization scheme. The resulting homogeneous control system with the proposed quantizer is proven to be homogeneous with respect to discrete dilation and globally finite-time, nearly fixed-time, or exponentially stable, depending on the homogeneity degree. Numerical examples validate the effectiveness of the proposed approach.

</details>


### [157] [LLM-DMD: Large Language Model-based Power System Dynamic Model Discovery](https://arxiv.org/abs/2601.05632)
*Chao Shen,Zihan Guo,Ke Zuo,Wenqi Huang,Mingyang Sun*

Main category: eess.SY

TL;DR: 提出了一种名为LLM-DMD的新型基于大语言模型（LLM）的动态模型发现框架，用于电力系统，该框架通过两个循环（微分方程循环和代数方程循环）来识别状态动力学和代数约束，并能自动扩展变量集以提高模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有电力系统动态模型发现方法在基函数和变量集上存在刚性先验，且常忽略代数约束，导致无法建立高保真模型进行精确仿真和分析。

Method: 利用LLM的推理和代码生成能力，通过两个连续循环（微分方程循环识别状态动力学和变量，代数方程循环构建代数约束）来发现动态方程并强制执行代数约束。LLM生成可执行的模型骨架，通过梯度优化器进行评估，并使用基于岛屿的存档存储候选模型。当评估停滞时，激活变量扩展机制以补充缺失变量。

Result: 在IEEE 39节点系统同步发电机基准测试中，LLM-DMD在完整的动态模型发现方面表现出优越性。

Conclusion: LLM-DMD框架通过集成LLM的能力，能够克服现有方法的局限性，发现更完整、更高保真的电力系统动态模型，并有效处理代数约束和动态变量的识别。

Abstract: Current model structural discovery methods for power system dynamics impose rigid priors on the basis functions and variable sets of dynamic models while often neglecting algebraic constraints, thereby limiting the formulation of high-fidelity models required for precise simulation and analysis. This letter presents a novel large language model (LLM)-based framework for dynamic model discovery (LLM-DMD) which integrates the reasoning and code synthesis capabilities of LLMs to discover dynamic equations and enforce algebraic constraints through two sequential loops: the differential-equation loop that identifies state dynamics and associated variables, and the algebraic-equation loop that formulates algebraic constraints on the identified algebraic variables. In each loop, executable skeletons of power system dynamic equations are generated by the LLM-based agent and evaluated via gradient-based optimizer. Candidate models are stored in an island-based archive to guide future iterations, and evaluation stagnation activates a variable extension mechanism that augments the model with missing algebraic or input variables, such as stator currents to refine the model. Validation on synchronous generator benchmarks of the IEEE 39-bus system demonstrates the superiority of LLM-DMD in complete dynamic model discovery.

</details>


### [158] [Explicit Reward Mechanisms for Local Flexibility in Renewable Energy Communities](https://arxiv.org/abs/2601.05756)
*Thomas Stegen,Julien Allard,Noé Diffels,François Vallée,Mevludin Glavic,Zacharie De Grève,Bertrand Cornélusse*

Main category: eess.SY

TL;DR: 提出一种迭代求解去中心化灵活用电规划的方法，以解决集中式协调的隐私和计算复杂性问题，并验证了其在20户家庭案例中的有效性。


<details>
  <summary>Details</summary>
Motivation: 集中式协调灵活用电存在数据隐私和收益分配问题，现有去中心化方法计算复杂度高且存在凸性挑战，影响了灵活模型精度。需要一种能够确保个体最优同时收敛于全局最优的去中心化协调方案。

Method: 提出一种迭代求解程序，由社区中心协调员提出总体灵活需求（向上或向下），社区成员独立响应并提供灵活容量。该方法保证了个体最优，并向全局最优收敛。

Result: 在包含20户家庭的案例研究中，该去中心化协调方案与集中式协调方案在集体账单上的差距不超过3.5%，验证了该方法的有效性。

Conclusion: 提出的迭代去中心化灵活用电规划方法能够有效解决隐私和计算复杂度问题，并能在保证个体最优的同时，实现接近全局最优的协调效果，适用于可再生能源社区。

Abstract: Incentivizing flexible consumption of end-users is key to maximizing the value of local exchanges within Renewable Energy Communities. If centralized coordination for flexible resources planning raises concerns regarding data privacy and fair benefits distribution, state-of-the-art approaches (e.g., bi-level, ADMM) often face computational complexity and convexity challenges, limiting the precision of embedded flexible models. This work proposes an iterative resolution procedure to solve the decentralized flexibility planning with a central operator as a coordinator within a community. The community operator asks for upward or downward flexibility depending on the global needs, while members can individually react with an offer for flexible capacity. This approach ensures individual optimality while converging towards a global optimum, as validated on a 20-member domestic case study for which the gap in terms of collective bill is not more than 3.5% between the decentralized and centralized coordination schemes.

</details>


### [159] [Modeling and Bifurcation Analysis of Longitudinal Dynamics of an Air-Breathing Hypersonic Vehicle](https://arxiv.org/abs/2601.05800)
*Kavita Shekhawat,Nandan Kumar Sinha*

Main category: eess.SY

TL;DR: 本文提出了一个空气呼吸高超声速飞行器（ABHV）纵向动力学的非线性模型，该模型耦合了气动和推进项。通过模态分析验证了模型的准确性，并使用数值续方法研究了模型在不同工况下关于升降舵和燃料当量比的参数动态行为和局部稳定性。基于分岔理论，对模型的纵向动力学进行了详细分析，并通过数值模拟验证了分岔分析结果。


<details>
  <summary>Details</summary>
Motivation: 研究ABHV的纵向动力学，特别是理解其在不同控制输入下的耦合气动和推进效应，以及在高超声速飞行中的稳定性问题，对于飞行器的设计和控制至关重要。

Method: 1. 建立ABHV纵向动力学的非线性耦合模型。 2. 使用模态分析验证模型在设计工况下的准确性。 3. 利用数值续方法计算模型在不同控制输入（升降舵和燃料当量比）下的稳态和局部稳定性。 4. 应用分岔理论分析模型的定性纵向动力学行为。 5. 通过数值模拟验证分岔分析结果。

Result: 模型在设计工况下通过模态分析得到验证。在四种不同工况下，升降舵和燃料当量比的参数动态行为被计算得出，并确定了其稳态和局部稳定性。分岔分析揭示了模型的定性纵向动力学特性。

Conclusion: 本文成功地构建并验证了一个ABHV的非线性纵向动力学模型，并通过数值续和分岔理论分析揭示了模型在不同控制输入下的复杂动态行为和稳定性特征，为ABHV的控制系统设计提供了理论依据。

Abstract: A nonlinear model of an Air-Breathing Hypersonic Vehicle (ABHV) longitudinal dynamics characterized by coupling of aerodynamic and propulsive terms is presented in this paper. The model is verified using modal analysis carried out around a design operating condition with results available in the literature. Further, parametric dynamic behavior is computed for the model as steady states with local stability with respect to its control inputs, elevator and fuel-equivalence ratio in four different cases using a numerical continuation algorithm. Detailed analysis of the qualitative longitudinal dynamics of the model is carried out based on bifurcation theory methodology. Numerical simulation results are presented to verify bifurcation analysis results.

</details>


### [160] [Generalized Spectral Clustering of Low-Inertia Power Networks](https://arxiv.org/abs/2601.05949)
*Gerald Ogbonna,C. Lindsay Anderson*

Main category: eess.SY

TL;DR: 提出一种基于同步动力学矩阵谱嵌入的方法，将低惯量电网划分为动态相干子系统，以支持分布式控制策略。


<details>
  <summary>Details</summary>
Motivation: 分布式能源的大量接入导致系统复杂性增加，需要更分布式和可扩展的控制策略。

Method: 通过对线性化同步动力学矩阵进行谱嵌入，将电网分解为动态相干子系统。将此方法与基于拉普拉斯矩阵的谱聚类联系起来，并分析了集群对稳态操作点变化的鲁棒性。

Result: 在IEEE 30节点测试系统中，提出的方法成功将网络划分为动态相干的集群。

Conclusion: 基于谱嵌入的方法可以有效地对低惯量电网进行分区，以实现分布式控制，并且所识别的集群在一定程度上对操作点变化具有鲁棒性。

Abstract: Large-scale integration of distributed energy resources has led to a rapid increase in the number of controllable devices and a significant change in system dynamics. This has necessitating the shift towards more distributed and scalable control strategies to manage the increasing system complexity. In this work, we address the problem of partitioning a low-inertia power network into dynamically coherent subsystems to facilitate the utilization of distributed control schemes. We show that an embedding of the power network using the spectrum of the linearized synchronization dynamics matrix results in a natural decomposition of the network. We establish the connection between our approach and the broader framework of spectral clustering using the Laplacian matrix of the admittance network. The proposed method is demonstrated on the IEEE 30-bus test system, and numerical simulations show that the resulting clusters using our approach are dynamically coherent. We consider the robustness of the clusters identified in the network by analyzing the sensitivity of the small eigenvalues and their corresponding eigenspaces, which determines the coherency structure of the oscillator dynamics, to variations in the steady-state operating points of the network.

</details>


### [161] [Resilient UAV Data Mule via Adaptive Sensor Association under Timing Constraints](https://arxiv.org/abs/2601.06000)
*Md Sharif Hossen,Anil Gurses,Ozgur Ozdemir,Mihail Sichitiu,Ismail Guvenc*

Main category: eess.SY

TL;DR: 本研究提出了一种名为HGAD的自适应传感器选择策略，用于无人机数据收集任务，该策略考虑了传感器数据缓冲和实际的无线传播条件，并通过数字孪生和真实测试验证了其有效性，显著提高了数据下载稳定性和累积下载量。


<details>
  <summary>Details</summary>
Motivation: 现有研究在无人机数据收集任务中，常依赖于忽略真实世界复杂性的模拟，例如假设理想的无线条件或仅关注路径规划，而忽视了动态环境中实时决策的挑战。因此，研究需要弥合这一差距，解决在考虑传感器数据缓冲和实际传播条件下，进行自适应传感器选择的问题。

Method: 提出了一种名为Hover-based Greedy Adaptive Download (HGAD) 的策略，该策略通过在信号质量高峰期智能地悬停在传感器上方来最大化数据传输。研究通过数字孪生（DT）和真实世界（RW）测试平台（NSF资助的AERPAW平台）验证了HGAD。并将HGAD与传统的仅跟随最强信号的Greedy方法进行了比较。

Result: 实验表明，HGAD显著提高了下载稳定性，并成功满足了每个传感器的目标数据量。与传统的Greedy方法相比，HGAD在累积数据下载方面表现更优。该研究强调了将信噪比（SNR）感知和缓冲区感知调度与DT和RW信号轨迹相结合的重要性，以设计适用于真实部署的弹性无人机数据骡策略。

Conclusion: HGAD策略通过整合信号质量和数据缓冲信息，能够有效地提高无人机数据收集任务的下载性能，并在实际应用中比仅依赖信号强度的传统方法更具优势。这项工作证明了在设计鲁棒的无人机数据收集策略时，考虑真实世界环境因素的重要性。

Abstract: Unmanned aerial vehicles (UAVs) can be critical for time-sensitive data collection missions, yet existing research often relies on simulations that fail to capture real-world complexities. Many studies assume ideal wireless conditions or focus only on path planning, neglecting the challenge of making real-time decisions in dynamic environments. To bridge this gap, we address the problem of adaptive sensor selection for a data-gathering UAV, considering both the buffered data at each sensor and realistic propagation conditions. We introduce the Hover-based Greedy Adaptive Download (HGAD) strategy, designed to maximize data transfer by intelligently hovering over sensors during periods of peak signal quality. We validate HGAD using both a digital twin (DT) and a real-world (RW) testbed at the NSF-funded AERPAW platform. Our experiments show that HGAD significantly improves download stability and successfully meets per-sensor data targets. When compared with the traditional Greedy approach that simply follows the strongest signal, HGAD is shown to outperform in the cumulative data download. This work demonstrates the importance of integrating signal-to-noise ratio (SNR)-aware and buffer-aware scheduling with DT and RW signal traces to design resilient UAV data-mule strategies for realistic deployments.

</details>
