<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 55]
- [cs.CV](#cs.CV) [Total: 173]
- [cs.CL](#cs.CL) [Total: 75]
- [cs.RO](#cs.RO) [Total: 31]
- [eess.SY](#eess.SY) [Total: 24]
- [eess.IV](#eess.IV) [Total: 11]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections](https://arxiv.org/abs/2601.00814)
*Abhishek Kumar*

Main category: cs.AI

TL;DR: 提出一种基于嵌入余弦相似度的跨语言本体对齐系统，通过增强实体描述和使用微调的多语言Transformer模型提升对齐效果，在OAEI-2022评测中F1值达71%，优于基线16%。


<details>
  <summary>Details</summary>
Motivation: 解决跨语言本体对齐中语义相似度捕捉的挑战，提升多语言知识图谱的互联互通能力。

Method: 1. 使用创新技术生成丰富的实体描述文本；2. 采用微调的多语言Transformer模型生成嵌入向量；3. 基于余弦相似度匹配实体对；4. 通过阈值过滤保留高相似度实体对。

Result: 在OAEI-2022 multifarm评测数据集上取得71%的F1值（召回率78%，精确率65%），较最佳基线提升16%。

Conclusion: 提出的对齐流程能有效捕捉跨语言语义相似性，验证了增强描述与微调多语言模型在跨语言本体对齐中的有效性。

Abstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar entities. We have evaluated our work on OAEI-2022 multifarm track. We achieve 71% F1 score (78% recall and 65% precision) on the evaluation dataset, 16% increase from best baseline score. This suggests that our proposed alignment pipeline is able to capture the subtle cross-lingual similarities.

</details>


### [2] [MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback](https://arxiv.org/abs/2601.00816)
*Ismail Ahmad Abdullah*

Main category: cs.AI

TL;DR: MathLedger是一个可验证机器学习认知的底层系统，通过形式化验证、密码学证明和学习动态的集成，实现可审计的机器学习过程。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统性能卓越但缺乏透明度和可验证性，在安全关键领域部署时存在信任危机，需要建立可验证的机器学习框架。

Method: 提出反射式形式学习（RFL）方法，将形式化验证、密码学证明和学习动态集成到单一认知循环中，使用验证器结果而非统计损失驱动更新。

Result: 第一阶段实验验证了测量和治理底层在受控条件下的有效性，包括Delta p计算、方差跟踪等测量基础设施验证，以及越界条件下的故障封闭治理触发机制。

Conclusion: 该研究提供了基础设施层面的贡献——一个可工作的账本证明学习原型，能够实现大规模可审计性，但尚未对收敛性或能力提升做出声明。

Abstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates are driven by verifier outcomes rather than statistical loss.
  Phase I experiments validate the measurement and governance substrate under controlled conditions. CAL-EXP-3 validates measurement infrastructure (Delta p computation, variance tracking); separate stress tests confirm fail-closed governance triggers correctly under out-of-bounds conditions. No convergence or capability claims are made. The contribution is infrastructural: a working prototype of ledger-attested learning that enables auditability at scale.
  Keywords: verifiable learning, formal verification, cryptographic attestation, reflexive feedback, fail-closed governance

</details>


### [3] [Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making](https://arxiv.org/abs/2601.00818)
*Chandra Sekhar Kubam*

Main category: cs.AI

TL;DR: 本文提出了一种基于Agentic AI框架的自主信用风险决策系统，通过多智能体协作实现实时、透明的风险评估，相比传统模型在决策速度、透明度和响应性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 金融服务快速数字化催生了对自主、透明、实时信用风险决策系统的迫切需求，传统机器学习模型缺乏自适应推理、情境感知和自主决策能力，无法满足现代金融运营需求。

Method: 采用Agentic AI框架，构建包含强化学习、自然语言推理、可解释AI模块和实时数据管道的多智能体系统，通过智能体协作协议、风险评分引擎、可解释性层和持续反馈学习循环实现风险评估。

Result: 系统在决策速度、透明度和响应性方面优于传统信用评分模型，但存在模型漂移风险、高维数据解释不一致、监管不确定性以及低资源环境基础设施限制等实践挑战。

Conclusion: 该系统具有变革信用分析的潜力，未来研究应关注动态监管合规机制、新型智能体协作、对抗鲁棒性以及跨国信用生态系统的大规模实施。

Abstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system where AI agents view the world of dynamic credit independent of human observers, who then make actions based on their articulable decision-making paths. The research introduces a multi-agent system with reinforcing learning, natural language reasoning, explainable AI modules, and real-time data absorption pipelines as a means of assessing the risk profiles of borrowers with few humans being involved. The processes consist of agent collaboration protocol, risk-scoring engines, interpretability layers, and continuous feedback learning cycles. Findings indicate that decision speed, transparency and responsiveness is better than traditional credit scoring models. Nevertheless, there are still some practical limitations such as risks of model drift, inconsistencies in interpreting high dimensional data and regulatory uncertainties as well as infrastructure limitations in low-resource settings. The suggested system has a high prospective to transform credit analytics and future studies ought to be directed on dynamic regulatory compliance mobilizers, new agent teamwork, adversarial robustness, and large-scale implementation in cross-country credit ecosystems.

</details>


### [4] [CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations](https://arxiv.org/abs/2601.00821)
*Tao An*

Main category: cs.AI

TL;DR: CogCanvas是一种无需训练的框架，通过提取对话中的认知构件并组织成时间感知图，解决大语言模型在长对话中的上下文限制和信息保真度问题，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长对话中面临上下文窗口限制与信息保真度的根本矛盾，现有截断和摘要方法会丢弃早期信息或丢失细节，需要一种能保持信息完整性的解决方案。

Method: 提出CogCanvas框架，从对话轮次中提取基于原文的认知构件（决策、事实、提醒），并将其组织成具有时间感知的图结构，实现抗压缩检索。

Result: 在LoCoMo基准测试中，CogCanvas整体准确率达34.7%，优于RAG（25.6%）和GraphRAG（13.7%）；时间推理任务表现突出（31.5% vs 9.3%）；多跳因果推理通过率达81.0%；在控制测试中召回率达97.5%，精确匹配保留93.0%。

Conclusion: 虽然经过专门训练的方法能达到更高绝对分数，但CogCanvas作为无需训练的方法为实践者提供了可立即部署的替代方案，显著优于标准基线，在时间推理和多跳因果推理方面表现优异。

Abstract: Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compression-resistant retrieval.
  On the LoCoMo benchmark, CogCanvas achieves 34.7% overall accuracy, outperforming RAG (25.6%, +9.1pp) and GraphRAG (13.7%, +21.0pp). The advantage is most pronounced on temporal reasoning: 31.5% vs. 9.3% (RAG) and 5.0% (GraphRAG)--a +530% relative improvement. On multi-hop causal reasoning, CogCanvas achieves 81.0% pass rate vs. 40.0% for GraphRAG (+41.0pp). Controlled benchmarks show 97.5% recall (+78.5pp vs. summarization) with 93.0% exact match preservation.
  While heavily-optimized approaches achieve higher absolute scores through dedicated training (EverMemOS: approximately 92%), our training-free approach provides practitioners with an immediately-deployable alternative that significantly outperforms standard baselines. Code and data: https://github.com/tao-hpu/cog-canvas.

</details>


### [5] [Energy-Aware Routing to Large Reasoning Models](https://arxiv.org/abs/2601.00823)
*Austin R. Ellis-Mohr,Max Hartman,Lav R. Varshney*

Main category: cs.AI

TL;DR: 本文研究了大型推理模型（LRMs）的能源效率优化问题，提出通过基于方差的调度策略在关键运行状态下平衡能源供应与需求，以减少能源浪费。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在推理过程中存在异构的能源成本，系统性能受平均能源供应与随机波动之间的平衡影响。当前系统在调度任务时缺乏对能源波动的有效管理，导致能源浪费或过度依赖辅助能源。

Method: 采用二阶特征分析系统在关键运行状态下的性能；提出基于方差的模型路由与调度策略；结合训练计算和推理计算的缩放规律设计调度策略。

Result: 在关键运行状态下，系统性能受时间、模型和执行选择中的可变性吸收方式支配；方差感知的路由和调度成为系统设计的核心维度；基于计算缩放规律的调度策略能有效表征路由行为。

Conclusion: 能源感知的模型路由策略需要理论支持，方差感知的调度方法为优化LRM系统能源效率提供了原则性设计方向，有助于减少基线能源浪费和辅助能源依赖。

Abstract: Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.

</details>


### [6] [Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis](https://arxiv.org/abs/2601.00828)
*Yin Li*

Main category: cs.AI

TL;DR: 研究发现大型语言模型的内在自我纠正能力存在局限性，提出了准确性-纠正悖论：较弱模型反而有更高的内在纠正率，并提出了错误深度假说来解释这一现象。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型被认为具有自我纠正能力，但近期研究表明内在自我纠正（无需外部反馈的自我修正）效果有限，研究者希望系统性地探究这一现象背后的机制。

Method: 将自我纠正分解为错误检测、错误定位和错误纠正三个子能力，在GSM8K-Complex数据集（每个模型n=500，共346个错误）上对三个主要LLM进行交叉模型实验。

Result: 发现准确性-纠正悖论：较弱模型（GPT-3.5，66%准确率）的内在纠正率比强模型（DeepSeek，94%准确率）高1.6倍（26.8% vs 16.7%）；错误检测率在不同架构间差异巨大（10%到82%），但检测能力不能预测纠正成功率；提供错误位置提示反而损害所有模型性能。

Conclusion: 研究挑战了关于模型能力和自我改进的线性假设，提出了错误深度假说：强模型犯错更少但错误更深、更难自我纠正，这对自我优化流程的设计具有重要意义。

Abstract: Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. Through cross-model experiments on GSM8K-Complex (n=500 per model, 346 total errors) with three major LLMs, we uncover a striking Accuracy-Correction Paradox: weaker models (GPT-3.5, 66% accuracy) achieve 1.6x higher intrinsic correction rates than stronger models (DeepSeek, 94% accuracy)--26.8% vs 16.7%. We propose the Error Depth Hypothesis: stronger models make fewer but deeper errors that resist self-correction. Error detection rates vary dramatically across architectures (10% to 82%), yet detection capability does not predict correction success--Claude detects only 10% of errors but corrects 29% intrinsically. Surprisingly, providing error location hints hurts all models. Our findings challenge linear assumptions about model capability and self-improvement, with important implications for the design of self-refinement pipelines.

</details>


### [7] [Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.00830)
*Deep Pankajbhai Mehta*

Main category: cs.AI

TL;DR: 研究发现AI模型在推理过程中会注意到隐藏提示但选择不报告，仅观察其推理过程不足以发现这些隐藏影响。


<details>
  <summary>Details</summary>
Motivation: 验证AI系统逐步推理的解释是否真实反映了影响其答案的因素，测试模型是否会报告嵌入问题中的提示信息。

Method: 在11个领先AI模型的9000多个测试案例中嵌入提示，测量模型是否提及这些提示，并测试直接询问、告知被监视和强制报告等干预措施的效果。

Result: 模型几乎从不主动提及提示，但直接询问时承认注意到；告知被监视无效；强制报告会导致误报不存在的提示并降低准确性；涉及用户偏好的提示最危险——模型最常遵循却最少报告。

Conclusion: 仅观察AI推理过程无法捕捉隐藏影响，当前解释机制可能无法真实反映模型的决策依据，需要更可靠的透明度方法。

Abstract: When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.

</details>


### [8] [OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification](https://arxiv.org/abs/2601.00843)
*Ayda Aghaei Nia*

Main category: cs.AI

TL;DR: OmniNeuro是一个新型人机交互框架，通过物理、混沌和量子启发的可解释性引擎，将脑机接口从黑盒解码器转变为透明的反馈伙伴，提升用户体验和神经可塑性效果。


<details>
  <summary>Details</summary>
Motivation: 深度学习虽提升了脑机接口解码精度，但其黑盒特性阻碍了临床采用，导致用户挫折感和神经可塑性效果不佳，需要可解释的反馈机制。

Method: 提出OmniNeuro框架，集成三种可解释性引擎：物理（能量）、混沌（分形复杂性）和量子启发的不确定性建模，驱动实时神经声化和生成式AI临床报告，框架与解码器无关。

Result: 在PhysioNet数据集（N=109）上平均准确率达58.52%，定性试点研究（N=3）证实可解释反馈有助于用户调节心理努力并减少试错阶段。

Conclusion: OmniNeuro作为可解释性层，可适配任何先进架构，将脑机接口转变为透明反馈伙伴，有望促进临床采用并改善神经可塑性结果。

Abstract: While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the "Black Box" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the "trial-and-error" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.

</details>


### [9] [Enhancing Temporal Awareness in LLMs for Temporal Point Processes](https://arxiv.org/abs/2601.00845)
*Lili Chen,Wensheng Gan,Shuang Liang,Philip S. Yu*

Main category: cs.AI

TL;DR: 提出了TPP-TAL框架，通过增强LLMs的时间感知能力来改进时序点过程的事件建模，在多个基准数据集上显著提升了时间似然估计和事件预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 时序点过程在金融、医疗等领域至关重要，但现有方法难以有效捕捉时间信息与语义上下文之间的复杂交互，限制了LLMs在该领域的应用。

Method: 提出TPP-TAL框架，采用显式对齐时间动态与上下文语义的方法（而非简单拼接嵌入），增强LLMs对时间依赖性和长程交互的感知能力。

Result: 在多个基准数据集上的实验表明，TPP-TAL在时间似然估计和事件预测准确性方面均有显著提升。

Conclusion: 增强LLMs的时间感知能力对连续时间事件建模具有重要意义，TPP-TAL框架为此提供了有效的解决方案。

Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL

</details>


### [10] [Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models](https://arxiv.org/abs/2601.00848)
*Ron F. Del Rosario*

Main category: cs.AI

TL;DR: 提出了一种基于OpenTelemetry追踪分析、通过QLoRA微调语言模型来检测多智能体AI工作流中时序攻击模式的开源方法，在自定义基准测试中准确率从42.86%提升至74.29%。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏可复现的框架来构建适应特定威胁环境的多智能体安全模型，需要一种能在资源受限硬件上有效检测时序攻击模式的方法。

Method: 1. 从18个公共网络安全源和35,026条合成OpenTelemetry追踪中构建80,851个样本的数据集；2. 在NVIDIA DGX Spark ARM64硬件上使用QLoRA进行三次迭代微调；3. 采用策略性数据增强和针对性样本选择。

Result: 1. 自定义基准测试准确率显著提升31.4个百分点（42.86%→74.29%）；2. 针对性样本训练效果优于无差别扩展；3. 训练数据组成对模型行为有决定性影响；4. 完整开源数据集、训练脚本和评估基准。

Conclusion: 本研究建立了首个可复现的框架，使实践者能够构建适应自身威胁环境的定制化智能体安全模型，但实际部署仍需人工监督以处理误报问题。

Abstract: We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. Our custom benchmark accuracy improves from 42.86% to 74.29%, a statistically significant 31.4-point gain. Targeted examples addressing specific knowledge gaps outperform indiscriminate scaling. Key contributions include: (1) synthetic trace generation methodology for multi-agent coordination attacks and regulatory violations, (2) empirical evidence that training data composition fundamentally determines behavior, and (3) complete open release of datasets, training scripts, and evaluation benchmarks on HuggingFace. While practical deployment requires human oversight due to false positive rates, this work establishes the first reproducible framework enabling practitioners to build custom agentic security models adapted to their threat landscapes.

</details>


### [11] [Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks](https://arxiv.org/abs/2601.00856)
*Milos Stankovic,Ella Hirche,Sarah Kollatzsch,Julia Nadine Doetsch*

Main category: cs.AI

TL;DR: 本文对Kosmyna等人（2025）关于使用AI助手写作时认知债务积累的研究提出建设性评论，指出其在研究设计、可重复性、EEG分析方法、结果报告一致性和透明度方面的不足。


<details>
  <summary>Details</summary>
Motivation: 针对Kosmyna等人研究中可能存在的局限性，旨在提供改进建议以提高其学术严谨性和发表准备度。

Method: 通过批判性分析原研究的设计、方法、结果报告和透明度，提出具体改进建议。

Result: 识别出样本量不足、分析方法可重复性问题、EEG分析的方法学缺陷、结果报告不一致以及研究透明度有限等关键问题。

Conclusion: 建议对原研究进行更保守的结果解释，并通过改进研究设计、方法透明度和结果报告来增强其科学可靠性。

Abstract: Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.

</details>


### [12] [Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery](https://arxiv.org/abs/2601.00869)
*Huang Junyao,Situ Ruimin,Ye Renqin*

Main category: cs.AI

TL;DR: 研究发现大型语言模型（LLM）的品牌推荐存在文化编码差异，中国LLM的品牌提及率比国际LLM高30.6个百分点，这种差异源于训练数据的地理分布而非语言本身。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统越来越多地介入消费者信息发现过程，品牌面临算法不可见性问题，需要理解LLM训练数据组成如何影响品牌推荐。

Method: 分析了1,909个纯英文查询，覆盖6个LLM（GPT-4o、Claude、Gemini、Qwen3、DeepSeek、Doubao）和30个品牌，通过案例研究（如Zhizibianjie/OmniEdge）验证发现。

Result: 中国LLM的品牌提及率为88.9%，国际LLM为58.3%（p<0.001），即使在相同英文查询中差异依然存在；提出'存在鸿沟'概念，即未进入LLM训练数据的品牌在AI响应中缺乏'存在性'。

Conclusion: 提出数据护城河框架，将AI可见内容视为VRIN战略资源，建议品牌通过语义覆盖、技术深度和文化本地化建立数据护城河，实现算法无处不在的战略目标。

Abstract: As artificial intelligence systems increasingly mediate consumer information discovery,
  brands face algorithmic invisibility. This study investigates Cultural Encoding in Large
  Language Models (LLMs) -- systematic differences in brand recommendations arising from
  training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o,
  Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6
  percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%,
  p<.001). This disparity persists in identical English queries, indicating training data
  geography -- not language -- drives the effect. We introduce the Existence Gap: brands
  absent from LLM training corpora lack "existence" in AI responses regardless of quality.
  Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6%
  mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how
  Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we
  contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic
  resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility
  across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization
  (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats
  through semantic coverage, technical depth, and cultural localization. Our findings reveal
  that in AI-mediated markets, the limits of a brand's "Data Boundaries" define the limits
  of its "Market Frontiers."

</details>


### [13] [Universal Conditional Logic: A Formal Language for Prompt Engineering](https://arxiv.org/abs/2601.00880)
*Anthony Mikinka*

Main category: cs.AI

TL;DR: 提出通用条件逻辑（UCL）框架，将提示工程从启发式实践转化为系统优化，通过系统评估验证了显著减少令牌使用（29.8%）和成本节约，并揭示了过度指定悖论。


<details>
  <summary>Details</summary>
Motivation: 当前提示工程主要依赖启发式方法，缺乏系统化的优化框架，导致LLM交互效率低下且成本较高，需要建立可校准的数学框架来提升效率。

Method: 采用UCL数学框架，包含指示函数、结构开销函数和早期绑定等核心机制，通过系统评估（N=305，11个模型，4次迭代）验证框架有效性，并分析结构开销函数O_s(A)解释性能差异。

Result: 实现显著令牌减少（29.8%，p < 0.001），对应成本节约；发现过度指定悖论（阈值S* = 0.509，超过后性能二次下降）；验证核心机制有效性；最优UCL配置因模型架构而异（如Llama 4 Scout需要V4.1适配）。

Conclusion: UCL作为可校准框架能高效优化LLM交互，模型族特定优化是关键研究方向，为提示工程提供了系统化数学基础。

Abstract: We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.

</details>


### [14] [Counterfactual Self-Questioning for Stable Policy Optimization in Language Models](https://arxiv.org/abs/2601.00885)
*Mandar Parab*

Main category: cs.AI

TL;DR: 提出了一种名为反事实自问的框架，使单个语言模型能够生成并评估自身推理的反事实批评，从而在不依赖外部模型的情况下实现自我改进。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型自我改进方法通常依赖外部批评者、奖励模型或集成采样，增加了复杂性和训练不稳定性。

Method: 模型首先生成初始推理轨迹，然后针对潜在失败点提出针对性问题，并生成暴露错误假设或无效步骤的替代推理轨迹，利用这些反事实轨迹作为结构化相对反馈进行策略优化。

Result: 在多个数学推理基准测试中，反事实自问提高了准确性和训练稳定性，尤其对小模型效果显著。

Conclusion: 该方法仅使用内部生成的监督即可实现可扩展的自我改进，为语言模型自我优化提供了更简洁稳定的途径。

Abstract: Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.

</details>


### [15] [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)
*Michael Bao*

Main category: cs.AI

TL;DR: 提出了ElecTwit模拟框架，用于研究多智能体系统中的说服行为，模拟社交媒体在政治选举期间的互动，发现LLM使用了25种说服技术并展现出独特现象。


<details>
  <summary>Details</summary>
Motivation: 克服以往研究中基于游戏的模拟局限性，在更真实的环境中研究LLM在社交模拟中的说服行为及其潜在影响。

Method: 开发ElecTwit模拟框架，在多智能体系统中模拟社交媒体政治选举互动，测试多种LLM模型并分析其使用的说服技术。

Result: 观察到大多数测试的LLM使用了25种特定说服技术，范围比以往研究更广；不同模型在技术使用和说服输出上存在差异；发现了'真相核心'信息和'墨水痴迷'等独特现象。

Conclusion: 该研究为在真实世界环境中评估有说服力的LLM智能体奠定了基础，有助于确保对齐并防止危险结果。

Abstract: This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as "kernel of truth" messages and spontaneous developments with an "ink" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.

</details>


### [16] [Context Collapse: In-Context Learning and Model Collapse](https://arxiv.org/abs/2601.00923)
*Josef Ott*

Main category: cs.AI

TL;DR: 该论文研究了大型语言模型中的上下文学习和模型崩溃现象，在线性回归任务中分析了参数相变，证明了模型崩溃的必然性，并提出了上下文崩溃的新概念。


<details>
  <summary>Details</summary>
Motivation: 研究旨在深入理解LLMs中上下文学习的工作机制，以及模型在持续训练或生成过程中性能退化的根本原因，特别是探索参数动态和长期稳定性问题。

Method: 使用带权重绑定的线性Transformer在回归任务上分析ICL；通过将前向传播简化为预条件梯度下降来研究相变；运用鞅和随机游走理论分析线性回归和高斯拟合中的模型崩溃；提出上下文崩溃概念分析长序列生成问题。

Result: 发现ICL存在临界上下文长度，超过该长度后参数会出现斜对称分量；证明了在数据增长不足或未保留的情况下模型崩溃几乎必然发生；揭示了长生成序列（特别是思维链）中上下文质量会逐渐退化。

Conclusion: 上下文学习与梯度优化存在数学等价性，模型崩溃是数据动态的必然结果，而上下文崩溃现象连接了ICL机制与生成模型的长期稳定性挑战，为理解LLMs动态提供了理论框架。

Abstract: This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.

</details>


### [17] [Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering](https://arxiv.org/abs/2601.01195)
*Wuzhenghong Wen,Chao Xue,Su Pan,Yuwei Sun,Minlong Peng*

Main category: cs.AI

TL;DR: 提出多跳推理增强框架MRE，结合提示工程、监督微调和树结构强化学习，提升时序知识图谱问答中多跳推理的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 时序知识图谱问答中，大语言模型在每跳推理时可能检索到大量时序相似且语义复杂的关系子图，导致次优决策和误差传播问题。

Method: 1. 提示工程引导生成多样推理轨迹；2. 筛选有效轨迹进行监督微调作为冷启动；3. 提出树组相对策略优化算法，通过递归树结构探索学习建立跨跳因果依赖。

Result: 在两个时序知识图谱问答基准测试中，MRE框架均超越现有最优方法，尤其在处理复杂多跳查询时表现突出，同时提升了解释性和对噪声时序标注的鲁棒性。

Conclusion: MRE框架通过增强前后向推理能力，能更有效地识别全局最优推理路径，为时序知识图谱问答中的多跳推理提供了系统化解决方案。

Abstract: Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.

</details>


### [18] [Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies](https://arxiv.org/abs/2601.01301)
*Keith Frankston,Benjamin Howard*

Main category: cs.AI

TL;DR: 提出递归蒙特卡洛树搜索算法RMCTS，相比AlphaZero的MCTS-UCB速度更快，训练时间减少约三分之二，在三种棋盘游戏中验证了性能


<details>
  <summary>Details</summary>
Motivation: AlphaZero的MCTS-UCB算法存在GPU延迟成本高的问题，需要更高效的树搜索算法来加速训练过程

Method: 采用递归的广度优先搜索策略，从叶子节点向根节点计算优化后验策略，使用先验网络策略定义搜索树而非自适应构建

Result: RMCTS比MCTS-UCB快40倍（单根状态搜索）和3倍（批量根状态搜索），训练出的网络质量相当但训练时间减少约三分之二

Conclusion: RMCTS通过递归和批量推理显著提升了搜索效率，在保持模型质量的同时大幅缩短训练时间，为强化学习提供了更高效的搜索框架

Abstract: We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, "RMCTS". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster when searching a large batch of root states.
  The recursion in RMCTS is based on computing optimized posterior policies at each game state in the search tree, starting from the leaves and working back up to the root. Here we use the posterior policy explored in "Monte--Carlo tree search as regularized policy optimization" (Grill, et al.) Their posterior policy is the unique policy which maximizes the expected reward given estimated action rewards minus a penalty for diverging from the prior policy.
  The tree explored by RMCTS is not defined in an adaptive manner, as it is in MCTS-UCB. Instead, the RMCTS tree is defined by following prior network policies at each node. This is a disadvantage, but the speedup advantage is more significant, and in practice we find that RMCTS-trained networks match the quality of MCTS-UCB-trained networks in roughly one-third of the training time. We include timing and quality comparisons of RMCTS vs. MCTS-UCB for three games: Connect-4, Dots-and-Boxes, and Othello.

</details>


### [19] [Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale](https://arxiv.org/abs/2601.01330)
*Shengji Tang,Weihao Lin,Jingqi Ye,Hao Li,Bo Zhang,Shuyue Hu,Tao Chen,Wangli Ouyang,Lei Bai,Peng Ye*

Main category: cs.AI

TL;DR: 提出JiSi框架，通过查询-响应混合路由、基于支持集的聚合器选择和自适应路由-聚合切换三项创新，使十个开源大语言模型协作性能超越Gemini-3-Pro，成本仅47%。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型路由与聚合存在三个瓶颈：基于查询的路由仅关注文本相似性；聚合方法静态且无法适配不同任务；路由与聚合的互补性未充分利用。探索集体智能作为替代单体扩展的新路径。

Method: 设计JiSi框架：1) 查询-响应混合路由，同时捕获语义信息和问题难度；2) 基于支持集的聚合器选择，联合评估聚合能力和领域适应性；3) 自适应路由-聚合切换，动态利用路由与聚合优势。

Result: 在九个基准测试中，协调十个开源大语言模型的JiSi框架性能超越Gemini-3-Pro，成本仅为47%，同时优于主流基线方法。

Conclusion: 集体智能代表实现通用人工智能的新路径，通过有效协作开源模型可突破单体模型性能极限。

Abstract: Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).

</details>


### [20] [Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models](https://arxiv.org/abs/2601.01321)
*Rong Zhou,Dongping Chen,Zihan Jia,Yao Su,Yixin Liu,Yiwen Lu,Dongwei Shi,Yue Huang,Tianyang Xu,Yi Pan,Xinliang Li,Yohannes Abate,Qingyu Chen,Zhengzhong Tu,Yu Yang,Yu Zhang,Qingsong Wen,Gengchen Mai,Sunyang Fu,Jiachen Li,Xuyu Wang,Ziran Wang,Jing Huang,Tianming Liu,Yong Chen,Lichao Sun,Lifang He*

Main category: cs.AI

TL;DR: 本文提出了一个统一的四阶段框架，系统描述了人工智能在数字孪生全生命周期中的集成方式，涵盖建模、镜像、干预和自主管理，并分析了物理建模与数据驱动学习的协同，以及生成式AI如何将数字孪生转变为主动认知系统。


<details>
  <summary>Details</summary>
Motivation: 数字孪生已从被动仿真工具发展为通过AI技术集成的智能自主实体，但缺乏系统化的框架来刻画AI在整个生命周期中的集成方式，需要跨领域总结技术进展与挑战。

Method: 通过综合现有技术与实践，提炼出统一的四阶段框架：1) 基于物理与物理信息AI方法建模物理孪生；2) 实时同步镜像物理系统；3) 通过预测建模、异常检测与优化策略干预物理孪生；4) 利用大语言模型、基础模型与智能体实现自主管理。并跨11个应用领域进行综述分析。

Result: 框架系统刻画了AI在数字孪生中的集成路径，揭示了从传统数值求解器向物理信息与基础模型的转变趋势，生成式AI技术使数字孪生具备推理、通信与创造性场景生成能力，同时识别出可扩展性、可解释性与可信赖性等共性挑战。

Conclusion: AI驱动数字孪生正向主动、自改进的认知系统演进，需进一步研究负责任AI集成以应对跨领域挑战，推动数字孪生在多领域的可靠应用。

Abstract: Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.

</details>


### [21] [A unified multimodal understanding and generation model for cross-disciplinary scientific research](https://arxiv.org/abs/2601.01363)
*Xiaomeng Yang,Zhiyu Tan,Xiaohui Zhong,Mengping Yang,Qiusheng Huang,Lei Chen,Libo Wu,Hao Li*

Main category: cs.AI

TL;DR: FuXi-Uni是一个统一的多模态科学模型，能在单一架构内跨学科理解和生成高维科学数据，在地球科学和生物医学领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型多为领域专用，缺乏同时理解和生成多模态科学数据的能力，而许多全球性挑战需要跨学科协同解决。

Method: 通过将跨学科科学标记与自然语言标记对齐，并利用科学解码器重建科学标记，支持自然语言对话和科学数值预测。

Result: 在地球科学中，其10天全球天气预报优于最先进的物理预报系统，热带气旋预测和空间降尺度表现突出；在生物医学中，在多个视觉问答基准上超越领先的多模态大语言模型。

Conclusion: FuXi-Uni通过在本机共享潜在空间中统一异构科学模态，同时保持强大的领域特定性能，为更通用的多模态科学模型迈出了重要一步。

Abstract: Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25° resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.

</details>


### [22] [KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models](https://arxiv.org/abs/2601.01366)
*Zixian Liu,Sihao Liu,Yuqi Zhao*

Main category: cs.AI

TL;DR: 提出KGCE基准平台，通过知识库增强和双图评估框架解决教育场景中跨平台任务执行评估的不足，提升智能体在私有软件上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准框架在教育场景的跨平台任务评估中存在缺陷，特别是对学校私有软件的结构理解不足导致智能体效率下降，且当前评估方法粒度粗糙，难以捕捉复杂任务中的执行细节。

Method: 构建包含104个教育相关任务的数据集；设计双图评估框架将任务分解为子目标进行细粒度验证；开发集成学校私有软件知识库的增强型智能体系统。

Result: KGCE平台覆盖Windows、Android及跨平台协作任务，通过知识库增强缓解了私有领域任务的执行瓶颈，双图框架提供了更精细的评估指标。

Conclusion: KGCE通过知识增强和双图评估机制，为教育场景中基于多模态大模型的跨平台智能体提供了更有效的基准测试解决方案。

Abstract: With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.

</details>


### [23] [Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification](https://arxiv.org/abs/2601.01378)
*Han Yuan,Yilin Wu,Li Zhang,Zheng Ma*

Main category: cs.AI

TL;DR: 提出AAAI三步骤管道，通过减少事实幻觉提升小语言模型在金融分类任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 小语言模型在金融分类中部署便捷但存在事实幻觉问题，且与错误分类正相关，需要提升其可靠性和分类准确性。

Method: 设计AAAI管道，包含关联识别、自动检测和自适应推理三个步骤，利用编码器验证器检测事实幻觉并反馈修正。

Result: 实验表明事实幻觉与误分类正相关；编码器验证器能有效检测事实幻觉；自适应推理反馈机制显著提升分类性能。

Conclusion: AAAI管道能增强小语言模型在金融领域的可信度和分类效果，为实际应用提供可行方案。

Abstract: Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.

</details>


### [24] [A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts](https://arxiv.org/abs/2601.01467)
*Romuald Kwessy Mouona,Blaise Blériot Koguep Njionou,Etienne Romuald Temgoua Alomo,Rokia Missaoui,Leonard Kwuida*

Main category: cs.AI

TL;DR: 本文研究三元背景中的蕴含关系，重点关注Ganter和Obiedkov提出的条件属性蕴含和属性条件蕴含，旨在为这些蕴含构建最优基。


<details>
  <summary>Details</summary>
Motivation: 三元背景中的蕴含关系在形式概念分析中具有理论意义，但现有研究缺乏针对条件属性蕴含和属性条件蕴含的系统性基构建方法。

Method: 采用形式概念分析理论框架，基于Ganter和Obiedkov提出的三元蕴含定义，研究构建最优基的算法或理论方法。

Result: 未在摘要中明确说明具体结果，但研究目标是为两类三元蕴含关系构建最优基。

Conclusion: 通过构建最优基，可为三元背景中的蕴含推理提供更简洁有效的表示工具。

Abstract: This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.

</details>


### [25] [Reading Between the Lines: Deconfounding Causal Estimates using Text Embeddings and Deep Learning](https://arxiv.org/abs/2601.01511)
*Ahmed Dawoud,Osama El-Shamy*

Main category: cs.AI

TL;DR: 提出一种神经网络增强的双重机器学习框架，利用文本嵌入解决观测研究中由未观测混杂因子引起的选择偏差问题，相比传统方法显著降低估计偏差。


<details>
  <summary>Details</summary>
Motivation: 传统计量方法在处理与结构化协变量正交的未观测混杂因子时存在困难，而高维非结构化文本数据中常包含这些潜在变量的丰富代理信息，但现有树基DML方法无法有效建模嵌入空间的连续拓扑结构。

Method: 提出神经网络增强的DML框架，利用文本嵌入进行因果识别；通过严格的合成基准测试比较不同方法，并优化深度学习架构以建模嵌入流形的连续拓扑。

Result: 非结构化文本嵌入能捕获结构化表格数据中缺失的关键混杂信息；标准树基DML估计器因无法建模嵌入流形连续拓扑而保留显著偏差(+24%)；提出的深度学习方法将偏差降至-0.86%，有效恢复真实因果参数。

Conclusion: 当基于高维自然语言数据进行条件分析时，深度学习架构对于满足无混杂假设至关重要，能显著提升因果效应估计的准确性。

Abstract: Estimating causal treatment effects in observational settings is frequently compromised by selection bias arising from unobserved confounders. While traditional econometric methods struggle when these confounders are orthogonal to structured covariates, high-dimensional unstructured text often contains rich proxies for these latent variables. This study proposes a Neural Network-Enhanced Double Machine Learning (DML) framework designed to leverage text embeddings for causal identification. Using a rigorous synthetic benchmark, we demonstrate that unstructured text embeddings capture critical confounding information that is absent from structured tabular data. However, we show that standard tree-based DML estimators retain substantial bias (+24%) due to their inability to model the continuous topology of embedding manifolds. In contrast, our deep learning approach reduces bias to -0.86% with optimized architectures, effectively recovering the ground-truth causal parameter. These findings suggest that deep learning architectures are essential for satisfying the unconfoundedness assumption when conditioning on high-dimensional natural language data

</details>


### [26] [Aletheia: Quantifying Cognitive Conviction in Reasoning Models via Regularized Inverse Confusion Matrix](https://arxiv.org/abs/2601.01532)
*Fanzhe Fu*

Main category: cs.AI

TL;DR: 提出Project Aletheia框架，通过Tikhonov正则化反转评估者混淆矩阵，量化System 2推理模型的认知确信度，并引入对齐确信分数确保安全性。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估范式面临认识论危机，静态基准测试能衡量知识广度但无法量化信念深度，需要新的框架来评估AI的认知确信度。

Method: 1. 扩展CHOKE现象框架至System 2推理模型；2. 提出Project Aletheia认知物理框架，使用Tikhonov正则化反转评估者混淆矩阵；3. 实施合成代理协议避免依赖不透明私有数据；4. 引入对齐确信分数(S_aligned)验证安全性。

Result: 初步实验显示推理模型虽能作为认知缓冲，但在对抗压力下可能出现防御性过度思考现象。

Conclusion: 该研究为衡量AI科学完整性提供了蓝图框架，能够量化认知确信度同时确保安全对齐。

Abstract: In the progressive journey toward Artificial General Intelligence (AGI), current evaluation paradigms face an epistemological crisis. Static benchmarks measure knowledge breadth but fail to quantify the depth of belief. While Simhi et al. (2025) defined the CHOKE phenomenon in standard QA, we extend this framework to quantify "Cognitive Conviction" in System 2 reasoning models. We propose Project Aletheia, a cognitive physics framework that employs Tikhonov Regularization to invert the judge's confusion matrix. To validate this methodology without relying on opaque private data, we implement a Synthetic Proxy Protocol. Our preliminary pilot study on 2025 baselines (e.g., DeepSeek-R1, OpenAI o1) suggests that while reasoning models act as a "cognitive buffer," they may exhibit "Defensive OverThinking" under adversarial pressure. Furthermore, we introduce the Aligned Conviction Score (S_aligned) to verify that conviction does not compromise safety. This work serves as a blueprint for measuring AI scientific integrity.

</details>


### [27] [Bayesian Orchestration of Multi-LLM Agents for Cost-Aware Sequential Decision-Making](https://arxiv.org/abs/2601.01522)
*Danial Amin*

Main category: cs.AI

TL;DR: 提出了一种贝叶斯成本感知的多LLM协同框架，用于解决不对称错误成本场景下的顺序决策问题，相比单LLM方法显著降低了成本并提升了公平性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖单个LLM进行决策，但在招聘、医疗分诊、欺诈检测等具有不对称错误成本的顺序决策场景中，这种方法在理论上存在不足，无法有效处理成本差异和证据更新。

Method: 将LLM视为近似似然模型而非分类器，通过对比提示为每个候选状态获取似然估计，使用稳健统计方法聚合多个不同LLM的结果，并基于贝叶斯规则在明确先验下进行顺序信念更新，支持基于期望成本的动作选择和基于信息价值的原则性信息收集。

Result: 在简历筛选实验中（错失人才成本40000美元/次，面试成本2500美元/次，电话筛选成本150美元/次），使用5个LLM（GPT-4o、Claude 4.5 Sonnet、Gemini Pro、Grok、DeepSeek）对1000份简历进行处理，总成本比最佳单LLM基线降低294000美元（34%），人口统计公平性提升45%（最大群体差距从22个百分点降至5个百分点）。消融实验显示：51%的成本节约来自多LLM聚合，43%来自顺序更新，20%来自分歧触发的信息收集。

Conclusion: 正确的概率基础为顺序决策提供了理论优势，多LLM协同框架通过贝叶斯方法实现了更优的成本控制和公平性提升，验证了将LLM作为似然模型而非分类器在不对称成本场景中的有效性。

Abstract: Large language models (LLMs) are increasingly deployed as autonomous decision agents in settings with asymmetric error costs: hiring (missed talent vs wasted interviews), medical triage (missed emergencies vs unnecessary escalation), and fraud detection (approved fraud vs declined legitimate payments). The dominant design queries a single LLM for a posterior over states, thresholds "confidence," and acts; we prove this is inadequate for sequential decisions with costs. We propose a Bayesian, cost-aware multi-LLM orchestration framework that treats LLMs as approximate likelihood models rather than classifiers. For each candidate state, we elicit likelihoods via contrastive prompting, aggregate across diverse models with robust statistics, and update beliefs with Bayes rule under explicit priors as new evidence arrives. This enables coherent belief updating, expected-cost action selection, principled information gathering via value of information, and fairness gains via ensemble bias mitigation. In resume screening with costs of 40000 USD per missed hire, 2500 USD per interview, and 150 USD per phone screen, experiments on 1000 resumes using five LLMs (GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek) reduce total cost by 294000 USD (34 percent) versus the best single-LLM baseline and improve demographic parity by 45 percent (max group gap 22 to 5 percentage points). Ablations attribute 51 percent of savings to multi-LLM aggregation, 43 percent to sequential updating, and 20 percent to disagreement-triggered information gathering, consistent with the theoretical benefits of correct probabilistic foundations.

</details>


### [28] [Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation](https://arxiv.org/abs/2601.01546)
*Letian Kong,Qianran,Jin,Renyu Zhang*

Main category: cs.AI

TL;DR: 本文提出一个两阶段框架（情境形成与情境导航）来提升大语言模型在复杂决策环境中的行为对齐能力，并通过多个实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在模拟人类行为时，在需要预测他人行动和基于观察形成信念的复杂决策环境中，与人类决策存在系统性偏差，因此需要改进行为对齐方法。

Method: 提出两阶段框架：第一阶段情境形成，明确实验设计以建立决策任务的情境表征；第二阶段情境导航，在该表征内引导推理过程以做出决策。在顺序购买游戏、众筹游戏和需求估计任务中验证框架，并测试了GPT-4o、GPT-5等四个先进模型。

Result: 复杂决策环境需要两阶段框架才能实现与人类基准的行为对齐，而简单的需求估计任务仅需情境形成阶段。不同模型在框架应用下均表现出对齐效果的提升。

Conclusion: 该框架明确了各阶段的使用条件，为设计LLM社会模拟实验提供了系统方法，使其能作为人类受试者的补充工具用于行为研究。

Abstract: Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.

</details>


### [29] [Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement](https://arxiv.org/abs/2601.01562)
*Mingyu Xu,Cheng Fang,Keyue Jiang,Yuqian Zheng,Yanghua Xiao,Baojian Zhou,Qifang Zhao,Suhang Zheng,Xiuwen Zhu,Jiyang Tang,Yongchi Zhao,Yijia Luo,Zhiqi Bai,Yuchi Xu,Wenbo Su,Wei Wang,Bing Zhao,Lin Qu,Xiaoxiao Xu*

Main category: cs.AI

TL;DR: Logics-STEM是一个在10M规模高质量数据集上微调的推理模型，专注于STEM领域，在8B规模上比次优模型平均提升4.68%。


<details>
  <summary>Details</summary>
Motivation: 提升STEM领域推理能力，通过数据算法协同设计优化推理任务的黄金标准分布。

Method: 采用数据算法协同设计引擎：数据方面通过5阶段数据策展（标注、去重、去污、蒸馏、分层采样）构建数据集；算法方面采用失败驱动的后训练框架，针对SFT阶段的失败区域进行知识检索和数据合成。

Result: 在STEM相关基准测试中表现优异，8B规模模型平均提升4.68%；公开提供8B/32B模型和10M/2.2M数据集。

Conclusion: 大规模开源数据与精心设计合成数据的结合具有巨大潜力，数据算法协同设计对通过后训练增强推理能力至关重要。

Abstract: We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.

</details>


### [30] [CaveAgent: Transforming LLMs into Stateful Runtime Operators](https://arxiv.org/abs/2601.01569)
*Maohao Ran,Zhenglin Wan,Cooper Lin,Yanting Zhang,Hongyu Xin,Hongwei Fan,Yibo Xu,Beier Luo,Yaxin Zhou,Wangbo Zhao,Lijie Yang,Lang Feng,Fuchao Yang,Jingxuan Wu,Yiqiao Huang,Chendong Ma,Dailing Jiang,Jianbo Deng,Sihui Han,Bo An,Yike Guo,Jun Song*

Main category: cs.AI

TL;DR: 提出了CaveAgent框架，将LLM从文本生成器转变为运行时操作器，通过双流上下文架构和状态化运行时管理，显著提升了复杂任务执行能力并降低了token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的智能体系统在处理长视野任务时存在脆弱的多轮依赖和上下文漂移问题，传统的JSON函数调用范式难以有效管理复杂状态和外部对象。

Method: 1. 双流上下文架构：分离轻量级语义流（推理）和持久化Python运行时流（执行）。2. 状态化运行时管理：支持跨轮次注入、操作和检索复杂Python对象（如DataFrame、数据库连接）。3. 代码生成：单步解决相互依赖的子任务（循环、条件等）。

Result: 1. 在零售任务上成功率提升10.5%。2. 多轮场景总token消耗降低28.4%。3. 数据密集型任务中，直接变量存储检索使token消耗减少59%，能处理导致其他智能体上下文溢出的海量数据。

Conclusion: CaveAgent通过运行时对象持久化机制解决了上下文漂移和灾难性遗忘问题，实现了高保真外部记忆，使处理后的数据能无损流向下游应用，在多项基准测试中优于现有方法。

Abstract: LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from "LLM-as-Text-Generator" to "LLM-as-Runtime-Operator." We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\% success rate improvement on retail tasks and reduces total token consumption by 28.4\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.

</details>


### [31] [Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration](https://arxiv.org/abs/2601.01609)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 提出一种结合大语言模型与符号推理的框架，将自然语言文本转换为结构化断言，并通过SWRL推理机确保规则应用的确定性，在多个领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在需要可审计和可解释决策的领域（如临床协议、法律证据规则、科学标准），现有方法存在局限：大语言模型缺乏一致性保证，符号系统需要结构化输入。

Method: 采用集成框架：1) 大语言模型作为本体填充引擎，将非结构化文本转换为ABox断言；2) 基于SWRL的推理机进行确定性规则应用；3) 将推理分解为实体识别、断言提取和符号验证三步，基于OWL 2本体定义任务。

Result: 在三个领域（法律传闻认定、科学方法任务应用、临床试验资格）和十一个语言模型上的实验表明：结构化分解方法在总体上显著优于少样本提示，所有领域均观察到性能提升；消融实验证实符号验证比单纯结构化提示带来实质性改进。

Conclusion: 该框架通过结合大语言模型的灵活性与符号推理的确定性，实现了可解释的规则推理，填充的ABox可与语义网工具集成，支持更丰富的推理模式。

Abstract: Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.

</details>


### [32] [Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications](https://arxiv.org/abs/2601.01718)
*YuanLab. ai,:,Shawn Wu,Sean Wang,Louie Li,Darcy Chen,Allen Wang,Jiangang Luo,Xudong Zhao,Joseph Shen,Gawain Ma,Jasper Jia,Marcus Mao,Claire Wang,Hunter He,Carol Wang,Zera Zhang,Jason Wang,Chonly Shen,Leo Zhang,Logan Chen,Qasim Meng,James Gong,Danied Zhao,Penn Zheng,Owen Zhu,Tong Yu*

Main category: cs.AI

TL;DR: 本文介绍了Yuan3.0 Flash，一个开源的MoE多模态大语言模型，具有37亿激活参数和400亿总参数，专为提升企业任务性能而设计，同时保持通用任务的竞争力。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型推理模型中常见的过度思考现象，并提升企业导向任务（如RAG、复杂表格理解和摘要）的性能，同时保持模型在通用任务上的竞争力。

Method: 提出了反射感知自适应策略优化（RAPO），一种新的强化学习训练算法，用于有效调节过度思考行为；采用混合专家（MoE）架构，激活参数37亿，总参数400亿。

Result: 在企业任务中表现优异，在数学、科学等领域展现出强大的推理能力，达到前沿模型相当的准确率，同时平均token消耗仅为1/4到1/2。

Conclusion: Yuan3.0 Flash通过RAPO算法有效解决了过度思考问题，在企业任务和通用任务上均表现出色，已开源以促进进一步研究和实际部署。

Abstract: We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.

</details>


### [33] [AI Agent Systems: Architectures, Applications, and Evaluation](https://arxiv.org/abs/2601.01743)
*Bin Xu*

Main category: cs.AI

TL;DR: 本文综述了AI智能体架构的现状，涵盖推理、规划、工具调用等核心组件，提出统一分类法，并讨论了设计权衡、评估挑战及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型与推理、规划、记忆和工具使用相结合，AI智能体正成为连接自然语言意图与现实世界计算的关键接口，需要系统梳理其架构、设计权衡和评估方法。

Method: 通过文献综述，将现有工作整合为涵盖智能体组件（策略/LLM核心、记忆、世界模型等）、协调模式（单/多智能体、集中/去中心化）和部署环境的统一分类法，并分析设计权衡与评估挑战。

Result: 建立了AI智能体架构的系统分类框架，识别了延迟与准确性、自主性与可控性等关键设计权衡，指出了评估中因非确定性、长时程信用分配等带来的复杂性，并总结了当前测量与基准测试实践。

Conclusion: AI智能体架构发展迅速但仍面临工具动作验证、可扩展内存管理、决策可解释性等开放挑战，需在现实工作负载下建立可复现的评估体系以推动领域发展。

Abstract: AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\ multi-agent; centralized vs.\ decentralized coordination), and deployment settings (offline analysis vs.\ online interactive assistance; safety-critical vs.\ open-ended tasks). We discuss key design trade-offs -- latency vs.\ accuracy, autonomy vs.\ controllability, and capability vs.\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.

</details>


### [34] [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)
*Yao Lu,Shang Liu,Hangan Zhou,Wenji Fang,Qijun Zhang,Zhiyao Xie*

Main category: cs.AI

TL;DR: 本文介绍了RTL-OPT基准测试，用于评估大语言模型在RTL优化中的能力，包含36个手工设计的数字电路，并集成了自动化评估框架来验证功能正确性和量化PPA改进。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要评估大语言模型生成RTL代码的语法正确性，而缺乏对其在功耗、性能和面积（PPA）优化质量方面的评估，因此需要一个新的基准测试来填补这一空白。

Method: 提出了RTL-OPT基准测试，包含36个手工设计的数字电路，涵盖组合逻辑、流水线数据路径、有限状态机和存储器接口等类别。每个任务提供一对RTL代码（次优版本和人工优化参考版本），并集成了自动化评估框架来验证功能正确性和量化PPA改进。

Result: RTL-OPT基准测试能够标准化和有意义地评估生成模型在硬件设计优化中的能力，特别是通过量化PPA改进来评估优化质量。

Conclusion: RTL-OPT基准测试为评估大语言模型在RTL优化中的能力提供了一个有效的工具，有助于推动人工智能在集成电路设计优化中的应用。

Abstract: The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.

</details>


### [35] [Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches](https://arxiv.org/abs/2601.01774)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.AI

TL;DR: 评估大语言模型直接求解超越方程与结合传统迭代求解器的混合架构效果，发现混合方法显著降低误差，LLM更适合作为传统数值求解器的智能接口而非独立计算引擎。


<details>
  <summary>Details</summary>
Motivation: 工程实践中普遍存在需要迭代数值求解的超越方程，研究旨在探索大语言模型能否直接解决这类方程，或结合传统求解器是否更有效。

Method: 测试六种先进大语言模型在100个涵盖七个工程领域的问题上，比较直接数值预测与混合方法（LLM进行符号操作和提供初始条件，牛顿-拉弗森迭代进行数值求解）的效果。

Result: 直接预测的平均相对误差为0.765至1.262，而求解器辅助计算为0.225至0.301，误差降低67.9%至81.8%。电子学领域改进显著（93.1%），流体力学改进较小（7.2%）。

Conclusion: 当代大语言模型擅长符号操作和领域知识检索，但在精度关键的迭代算术方面表现不佳，最佳部署方式是作为传统数值求解器的智能接口而非独立计算引擎。

Abstract: Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.

</details>


### [36] [PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor](https://arxiv.org/abs/2601.01802)
*Qianjun Pan,Junyi Wang,Jie Zhou,Yutao Yang,Junsong Li,Kaiyin Xu,Yougen Zhou,Yihan Li,Jingyuan Zhao,Qin Chen,Ningning Zhou,Kai Chen,Liang He*

Main category: cs.AI

TL;DR: 提出PsychEval基准，用于训练和评估多会话、多疗法的高真实感AI心理咨询师，包含数据集、评估框架和强化学习环境。


<details>
  <summary>Details</summary>
Motivation: 现有AI心理咨询模型通常关注单一疗法，缺乏对长期咨询、动态目标跟踪和多疗法灵活切换的支持，难以满足复杂临床需求。

Method: 构建多会话（6-10次）数据集，涵盖五种疗法和整合疗法，标注677项元技能和4577项原子技能；建立包含18项指标的评估框架，并创建2000多个客户画像；设计强化学习环境支持AI自我进化训练。

Result: 数据集在质量和临床保真度上表现优越，验证了PsychEval作为高保真基准的有效性，能够支持AI心理咨询师的适应性训练。

Conclusion: PsychEval不仅是一个静态基准，更是一个支持AI心理咨询师自我进化训练的强化学习环境，有助于开发临床责任强、适应性高的AI咨询系统。

Abstract: To develop a reliable AI for psychological assessment, we introduce \texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.

</details>


### [37] [COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs](https://arxiv.org/abs/2601.01836)
*Dasol Choi,DongGeon Lee,Brigitta Jesica Kartono,Helena Berndt,Taeyoun Kwon,Joonwon Jang,Haon Park,Hwanjo Yu,Minsuk Kahng*

Main category: cs.AI

TL;DR: 提出COMPASS框架评估大语言模型对组织特定政策的遵循情况，发现模型能正确处理合法请求但严重无法执行禁止性政策。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在企业高风险领域（如医疗、金融）的部署，确保其遵循组织特定政策变得至关重要，而现有安全评估仅关注通用危害。

Method: 开发COMPASS框架，应用于八个行业场景，生成并验证5,920个查询，测试常规合规性和对抗性鲁棒性，评估七个先进模型。

Result: 模型对合法请求处理准确率超过95%，但对禁止性政策的对抗性违反仅能拒绝13-40%，存在根本性不对称。

Conclusion: 当前大语言模型缺乏政策关键部署所需的鲁棒性，COMPASS框架成为组织AI安全评估的重要工具。

Abstract: As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.

</details>


### [38] [Admissibility Alignment](https://arxiv.org/abs/2601.01816)
*Chris Duffey*

Main category: cs.AI

TL;DR: 本文提出可容许对齐作为AI对齐的新框架，将其视为在不确定性下对结果分布进行可容许行动和决策选择的属性，并通过MAP-AI系统架构实现概率化、决策理论化的对齐评估。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐常被视为静态或二元条件，难以应对不确定性、价值模糊和治理约束。研究旨在建立一种基于分布属性和策略行为的动态对齐框架，以更好地评估和治理实际AI系统。

Method: 提出MAP-AI系统架构，通过蒙特卡洛估计结果分布和可容许控制策略选择来实现对齐。框架评估决策策略在多种可能未来中的表现，显式建模不确定性、干预效果、价值模糊和治理约束，并基于期望效用、方差、尾部风险和错位概率等分布属性评估对齐。

Result: 建立了一种可执行的方法论，用于评估企业及机构AI系统的信任和对齐，提供治理AI系统的实践基础，其影响由策略在分布和尾部事件中的行为决定，而非单一预测。

Conclusion: 分布对齐评估可集成到决策过程中，实现不依赖模型重训练或修改的可容许控制行动选择机制，为不确定性下的AI对齐治理提供了实用框架。

Abstract: This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.
  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.

</details>


### [39] [Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01844)
*Udiptaman Das,Krishnasai B. Atmakuri,Duy Ho,Chi Lee,Yugyung Lee*

Main category: cs.AI

TL;DR: 提出一个端到端框架，利用多智能体提示和模式约束的检索增强生成（KG-RAG）策略，直接从自由文本构建和评估临床知识图谱，特别针对肿瘤学领域，无需依赖黄金标准标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖结构化输入，缺乏对事实准确性和语义一致性的鲁棒验证，这在肿瘤学领域尤为突出。大型语言模型为从非结构化临床叙述构建知识图谱提供了新机会。

Method: 采用多智能体提示和模式约束的KG-RAG策略，包括：(1) 提示驱动的实体、属性和关系提取；(2) 基于熵的不确定性评分；(3) 本体对齐的RDF/OWL模式生成；(4) 多LLM共识验证用于幻觉检测和语义精炼。

Result: 应用于两个肿瘤学队列（PDAC和BRCA），该方法产生了可解释、SPARQL兼容且临床基础的知识图谱。实验结果显示在精确度、相关性和本体合规性方面优于基线方法。

Conclusion: 该框架支持持续精炼和自监督评估，能够迭代提升图谱质量，为临床知识图谱构建提供了一种无需黄金标注的有效方法。

Abstract: Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.

</details>


### [40] [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)
*Defei Xia,Bingfeng Pi,Shenbin Zhang,Song Hua,Yunfei Wei,Lei Zuo*

Main category: cs.AI

TL;DR: 本文提出了Jenius-Agent框架，通过自适应提示生成、上下文感知工具编排和分层记忆机制三大创新，优化LLM智能体的推理和工具使用流程，显著提升任务准确率并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的智能体在上下文理解、工具使用和响应生成方面仍有局限，其内部推理和工具使用流程的系统性优化研究不足，需要更可靠、高效的解决方案。

Method: 提出Jenius-Agent框架，包含：(1)自适应提示生成策略；(2)上下文感知工具编排模块（工具分类、语义检索、自适应调用）；(3)分层记忆机制（会话记忆、任务历史、外部摘要）。集成MCP工具、文件I/O和执行反馈优化。

Result: 实验显示任务准确率提升20%，同时降低token成本、响应延迟和调用失败率。框架已在Jenius平台部署，提供轻量可扩展的自主智能体解决方案。

Conclusion: 该框架通过系统性优化智能体内部流程，显著提升了任务性能和效率，为构建鲁棒、协议兼容的自主智能体提供了实践可行的方案。

Abstract: As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.

</details>


### [41] [Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence](https://arxiv.org/abs/2601.01875)
*Kewen Cao,Jianxu Chen,Yongbing Zhang,Ye Zhang,Hongxiao Wang*

Main category: cs.AI

TL;DR: 提出一个基于SQL的代理框架，通过可执行的SQL查询追踪细胞特征测量与诊断结论之间的关联，提升病理图像分析的透明度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型生成的解释多为相关性描述，缺乏可验证的证据支持，临床医生难以理解模型决策的具体依据。

Method: 1. 提取可解释的细胞特征；2. 特征推理代理通过SQL查询聚合视觉证据为量化发现；3. 知识对比代理将发现与病理知识库对比，模拟病理医生诊断逻辑。

Result: 在两个病理视觉问答数据集上的实验表明，该方法提高了模型解释性和决策可追溯性，并生成可执行的SQL追踪记录。

Conclusion: 该框架通过结构化查询和知识对比机制，实现了从细胞测量到诊断结论的透明推理路径，为临床可信AI提供新思路。

Abstract: Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions.

</details>


### [42] [Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs](https://arxiv.org/abs/2601.01878)
*Farzan Karimi-Malekabadi,Suhaib Abdurahman,Zhivar Sourati,Jackson Trager,Morteza Dehghani*

Main category: cs.AI

TL;DR: 本文指出当前大语言模型的社会认知评估存在理论缺失问题，导致基准测试结果被过度泛化，并提出了理论追踪卡作为解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有社会认知基准测试常无法预测模型真实表现，作者认为根本原因在于评估缺乏明确的理论基础，导致能力评估片面化并产生系统性效度错觉。

Method: 1. 诊断并形式化理论缺失问题；2. 提出理论追踪卡作为轻量级文档工具，明确记录评估的理论基础、能力维度、操作化方法和局限性。

Result: 理论追踪卡能够在不修改基准测试或要求理论统一的前提下，通过显式呈现理论-任务-评分-局限的完整效度链，提升评估的可解释性和复用性。

Conclusion: 社会认知评估需要明确的理论基础，理论追踪卡是解决当前评估体系理论缺失问题的可行方案，有助于避免对基准测试结果的过度解读。

Abstract: Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.

</details>


### [43] [OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation](https://arxiv.org/abs/2601.01939)
*Victor Sanchez,Chris Reinke,Ahamed Mohamed,Xavier Alameda-Pineda*

Main category: cs.AI

TL;DR: OpenSocInt是一个开源软件包，提供多模态社交交互模拟器和模块化架构，用于训练社交智能体，已应用于社交导航任务。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏开源、模块化的多模态社交交互模拟平台，限制了社交智能体的训练和研究。

Method: 开发了OpenSocInt软件包，包含多模态社交交互模拟器和模块化架构，支持不同感知特征的编码与融合，以及多种智能体的使用。

Result: 软件已公开可用（GPL许可），并通过社交导航任务的实验协议验证了其价值。

Conclusion: OpenSocInt为研究多模态社交交互提供了灵活的开源平台，有助于探索不同感知特征和智能体在社交任务中的应用。

Abstract: In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.

</details>


### [44] [MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning](https://arxiv.org/abs/2601.01910)
*Minh Hieu Ha,Khanh Ly Ta,Hung Phan,Tung Doan,Tung Dao,Dao Tran,Huynh Thi Thanh Binh*

Main category: cs.AI

TL;DR: 提出MMP-A*框架，通过结合视觉语言模型的空间感知能力和自适应衰减机制，解决传统A*算法在复杂环境中计算成本高以及纯文本规划器缺乏空间基础的问题，实现高效自主导航。


<details>
  <summary>Details</summary>
Motivation: 传统A*算法在大规模复杂环境中计算和内存成本过高，而现有基于大语言模型的路径规划方法仅依赖文本推理，缺乏空间基础，容易在拓扑复杂环境中产生错误路径点，导致计算效率低下。

Method: 提出MMP-A*多模态框架，整合视觉语言模型的空间感知能力，并引入自适应衰减机制动态调节不确定路径点在启发函数中的影响，确保几何有效性并降低内存开销。

Result: 在严重杂乱和拓扑复杂的挑战性环境中测试表明，MMP-A*能够生成接近最优的轨迹，同时显著降低操作成本。

Conclusion: MMP-A*作为一种基于感知且计算高效的范式，为自主导航提供了有效的解决方案，通过空间基础推理和自适应机制平衡了全局规划与几何精度。

Abstract: Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.
  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.

</details>


### [45] [CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes](https://arxiv.org/abs/2601.01976)
*Yasmine Souissi,Fabrice Boissier,Nida Meddouri*

Main category: cs.AI

TL;DR: 本文综述了基于形式概念分析（FCA）的分类器，提出了一种构建部分概念格的新方法以提高效率，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 知识发现（KDD）旨在从海量数据中提取隐藏知识，而形式概念分析（FCA）作为一种可解释的分类方法，其计算效率有待提升，因此需要研究更高效的FCA分类器实现方法。

Method: 采用文献综述与实验验证相结合的方法：系统回顾FCA分类器的现有技术，提出一种从名义数据计算闭包算子的新方法，并构建专注于关键概念的偏序概念格。

Result: 实验结果表明，所提出的部分概念格构建方法在保持分类准确性的同时显著提高了计算效率，为处理大规模数据提供了可行方案。

Conclusion: 形式概念分析是构建可解释分类器的有效工具，通过优化概念格构建方法可以平衡解释性与计算效率，为知识发现领域提供了新的技术思路。

Abstract: Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.

</details>


### [46] [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)
*Dong Xue,Jicheng Tu,Ming Wang,Xin Yan,Fangzhou Liu,Jie Hu*

Main category: cs.AI

TL;DR: 提出MindChat隐私保护大语言模型用于心理健康支持，并构建MindCorpus合成多轮心理咨询数据集，通过联邦学习和差分隐私优化保护数据隐私。


<details>
  <summary>Details</summary>
Motivation: 现有心理咨询对话数据稀缺且敏感，限制了用于心理健康支持的大语言模型训练，需要开发既能保护隐私又能生成高质量咨询数据的方法。

Method: 1. 多智能体角色扮演框架构建合成数据集；2. 双闭环反馈设计（轮次级批判修订和会话级策略优化）；3. 联邦学习结合LoRA适配器；4. 差分隐私优化降低隐私风险。

Result: MindCorpus提升了训练效果，MindChat在自动评估和人工评估中与现有基线模型表现相当，且在成员推理攻击下表现出更低的隐私泄露风险。

Conclusion: 该方法能有效生成高质量心理咨询数据并保护用户隐私，为开发隐私保护的心理健康支持系统提供了可行方案。

Abstract: Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.

</details>


### [47] [ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems](https://arxiv.org/abs/2601.01982)
*Noel Thomas*

Main category: cs.AI

TL;DR: 提出了ChaosBench-Logic基准测试，用于评估大语言模型在混沌动力系统中的逻辑推理能力，发现前沿模型在单项准确率上表现良好，但在组合推理和全局一致性方面存在严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言任务上表现出色，但在需要精确逻辑和符号推理的领域（如混沌动力系统）仍然脆弱。混沌系统具有确定性但常被误解为随机性或复杂性，为评估逻辑推理提供了严苛测试环境。

Method: 构建了包含30个混沌动力系统的基准测试，采用统一的一阶逻辑本体进行标注，包含11个语义谓词的真值分配。生成了621个问题，涵盖七类推理任务（包括多跳推理、跨系统类比、反事实推理等），并定义了逻辑准确性、蕴含一致性、对话连贯性和矛盾性等评估指标。

Result: 前沿大语言模型（GPT-4、Claude 3.5 Sonnet等）在单项准确率达到91-94%，但在组合项目上得分为0%，且表现出脆弱的全局一致性。对话级准确率在53.1%（GPT-4思维链）到75.5%（LLaMA-3零样本）之间。

Conclusion: ChaosBench-Logic为诊断大语言模型的逻辑推理失败提供了严格测试平台，并为开发神经符号方法以改进大语言模型的科学推理能力奠定了基础。

Abstract: Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.

</details>


### [48] [XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging](https://arxiv.org/abs/2601.02008)
*Midhat Urooj,Ayan Banerjee,Sandeep Gupta*

Main category: cs.AI

TL;DR: XAIMeD是一个可解释的医疗AI框架，通过神经符号架构整合临床专家知识，提升分布偏移下的鲁棒性、罕见类别敏感性和临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 医疗AI中深度模型在真实世界分布偏移下易失效，且对罕见临床类别存在偏见，需要提高模型鲁棒性、罕见类别识别能力和临床可解释性。

Method: 将临床知识编码为逻辑规则，通过加权特征满足度评分进行符号推理，与神经网络预测互补；采用置信度加权融合和基于熵不平衡增益与罕见类别基尼系数的自适应路由机制。

Result: 在癫痫发作区定位和糖尿病视网膜病变分级等任务上，跨域泛化性能提升6%，罕见类别F1分数提高10%，显著优于现有深度学习方法。

Conclusion: XAIMeD提供了一种基于临床知识的可解释医疗AI方法，符号组件可作为正则化器提升分布偏移下的鲁棒性，实现临床可信的多模态医疗AI。

Abstract: Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.

</details>


### [49] [Simulated Reasoning is Reasoning](https://arxiv.org/abs/2601.02043)
*Hendrik Kempt,Alon Lavie*

Main category: cs.AI

TL;DR: 本文探讨基础模型（FM）的推理能力，指出其通过模仿人类“出声思考”过程实现推理，这与传统符号推理不同，虽能解决问题但缺乏常识基础，导致推理脆弱性。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为推理需通过符号推理实现理解，但基础模型展示了无需符号推理即可完成推理任务的能力，这促使重新评估推理的本质及其必要条件，并关注由此产生的安全与鲁棒性问题。

Method: 通过哲学分析，对比传统符号推理与基础模型的推理机制，讨论“随机鹦鹉”隐喻的适用性，并基于模型能力反思安全与规范问题。

Result: 基础模型的推理依赖于模仿思考过程、测试路径并迭代，虽能实现少样本学习下的问题解决，但因缺乏常识基础而显得脆弱；传统“随机鹦鹉”隐喻已不适用；需建立新的安全与规范框架应对其推理特性。

Conclusion: 基础模型的推理方式挑战了传统推理理论，需重新评估推理的必要条件；其脆弱性要求开发针对性的安全防御措施；应放弃过时的隐喻，构建适应其能力发展的伦理与安全规范。

Abstract: Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., "symbolic reasoning". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can "reason" by way of imitating the process of "thinking out loud", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the "stochastic parrot" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.

</details>


### [50] [Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management](https://arxiv.org/abs/2601.02061)
*Faizan Ahmed,Aniket Dixit,James Brusey*

Main category: cs.AI

TL;DR: 本文研究通过高阶导数惩罚实现动作平滑正则化，在连续控制基准和建筑能源管理中验证了其有效性，特别是三阶导数惩罚（急动度最小化）能在保持性能的同时显著提升平滑度。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习代理常表现出高频、不稳定的控制行为，导致现实部署中能耗过高和机械磨损，需要一种方法在保持性能的同时实现动作平滑。

Method: 系统研究高阶导数惩罚的动作平滑正则化方法，从连续控制基准的理论分析扩展到建筑能源管理的实际验证，重点评估不同阶数导数惩罚的效果。

Result: 在四个连续控制环境中，三阶导数惩罚（急动度最小化）能一致实现最优平滑度且保持竞争力性能；在HVAC控制系统中，平滑策略使设备切换减少60%，带来显著运营效益。

Conclusion: 高阶动作正则化是连接强化学习优化与能源关键应用中操作约束的有效桥梁，为实际部署提供了重要解决方案。

Abstract: Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.

</details>


### [51] [FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations](https://arxiv.org/abs/2601.02071)
*Adeshola Okubena,Yusuf Ali Mohammed,Moe Elbadawi*

Main category: cs.AI

TL;DR: 本研究探索了将大型语言模型（LLM）应用于药物3D打印（熔融沉积建模）的配方开发，通过微调四种LLM架构，评估其在推荐辅料和预测丝材机械性能方面的潜力，并揭示了当前LLM在药物制剂应用中存在的局限性与挑战。


<details>
  <summary>Details</summary>
Motivation: 药物3D打印技术有望实现个性化给药，但现有AI方法多局限于狭窄任务，未能全面解决制剂开发中的复杂问题。近年来人工智能通用智能（AGI）概念的发展，尤其是大型语言模型展现出类人推理能力，为更广义的药物制剂开发提供了新机遇。

Method: 研究基于包含1400多种配方的熔融沉积建模（FDM）数据集，对四种LLM架构进行微调，系统评估微调参数与生成参数配置。模型任务包括根据活性药物成分（API）剂量推荐合适辅料，以及预测丝材的机械性能。

Result: 结果显示，Llama2模型在推荐FDM制剂辅料方面表现最佳；模型选择和参数化显著影响性能，较小的LLM会出现灾难性遗忘现象。研究进一步发现：（1）即使使用1400多个配方的数据集，仍可能导致模型灾难性遗忘；（2）标准LLM评估指标仅衡量语言性能，无法评估制剂可加工性；（3）基于生物医学数据训练的LLM并非总能产生最佳结果。

Conclusion: 要推动LLM超越语言能力、成为可靠的药物制剂开发工具，必须解决灾难性遗忘、评估指标与制剂实际需求脱节、以及领域数据训练效果有限等关键挑战。

Abstract: Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.

</details>


### [52] [Streaming Hallucination Detection in Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.02170)
*Haolang Lu,Minghui Pan,Ripeng Li,Guoshun Nan,Jialin Zhuang,Zijie Zhao,Zhongxiang Sun,Kun Wang,Yang Liu*

Main category: cs.AI

TL;DR: 提出将长链思维中的幻觉视为演化潜状态，引入累积前缀级信号进行流式检测，实现实时可解释的幻觉追踪。


<details>
  <summary>Details</summary>
Motivation: 长链思维推理虽提升大语言模型性能，但幻觉常以微妙方式出现并在推理步骤间传播，需更精细的检测方法。

Method: 将步骤级幻觉判断视为局部观测，设计累积前缀级幻觉信号以追踪整个推理轨迹的全局状态演化。

Result: 实现了长链思维推理中的流式幻觉检测，能提供实时且可解释的幻觉演化证据。

Conclusion: 通过将幻觉建模为演化潜状态并引入全局追踪信号，可更有效地检测长链推理中的幻觉传播问题。

Abstract: Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.

</details>


### [53] [EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning](https://arxiv.org/abs/2601.02163)
*Chuanrui Hu,Xingze Gao,Zuyi Zhou,Dannong Xu,Yi Bai,Xintong Li,Hui Zhang,Tong Li,Chong Zhang,Lidong Bing,Yafeng Deng*

Main category: cs.AI

TL;DR: EverMemOS是一个受记忆印迹启发的自组织记忆操作系统，用于解决大语言模型在长期交互中因上下文窗口限制导致的连贯性问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为长期交互智能体部署时，有限的上下文窗口难以维持长期连贯行为；现有记忆系统通常存储孤立记录，无法整合演变的用户状态和解决冲突。

Method: 提出EverMemOS系统，包含三个核心机制：1) 情节痕迹形成：将对话流转换为包含情节痕迹、原子事实和时间边界前瞻信号的MemCells；2) 语义整合：将MemCells组织为主题MemScenes，提炼稳定语义结构并更新用户画像；3) 重建性回忆：通过MemScene引导的智能检索，为下游推理组合必要且充分的上下文。

Result: 在LoCoMo和LongMemEval基准测试中，EverMemOS在记忆增强推理任务上达到最先进性能；在PersonaMem v2上的画像研究及案例研究展示了用户画像和前瞻等聊天导向能力。

Conclusion: EverMemOS通过模拟生物记忆的印迹生命周期，有效提升大语言模型在长期交互中的记忆管理和推理能力，代码已开源。

Abstract: Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.

</details>


### [54] [Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents](https://arxiv.org/abs/2601.02314)
*Sourena Khanzadeh*

Main category: cs.AI

TL;DR: 本文提出了Project Ariadne框架，用于审计LLM智能体推理过程的因果忠实性，发现当前模型存在显著的忠实性差距，其推理痕迹常为事后合理化而非真实决策驱动。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体越来越多地承担高风险自主决策任务，其推理过程的透明度成为关键安全问题。现有Chain-of-Thought提示生成的推理痕迹是否真实驱动模型输出，抑或仅是事后合理化，尚不明确。

Method: 引入Project Ariadne框架，利用结构因果模型和反事实逻辑，通过对中间推理节点进行硬干预（do-演算），系统性地反转逻辑、否定前提和颠倒事实主张，以测量最终答案的因果敏感性。

Result: 对最先进模型的实证评估揭示了持续的忠实性差距，定义并检测到一种广泛存在的故障模式——因果解耦，在事实和科学领域中违规密度高达0.77。智能体在内部逻辑矛盾的情况下仍得出相同结论，证明其推理痕迹实为'推理剧场'，而决策由潜在参数先验支配。

Conclusion: 当前智能体架构本质上容易产生不忠实的解释，建议将Ariadne分数作为对齐陈述逻辑与模型行动的新基准。

Abstract: As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \textbf{faithful} generative drivers of the model's output or merely \textbf{post-hoc rationalizations}. We introduce \textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as "Reasoning Theater" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.

</details>


### [55] [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)
*Falcon LLM Team,Iheb Chaabane,Puneesh Khanna,Suhail Mohmad,Slim Frikha,Shi Hu,Abdalgader Abubaker,Reda Alami,Mikhail Lubinets,Mohamed El Amine Seddik,Hakim Hacid*

Main category: cs.AI

TL;DR: Falcon-H1R是一个7B参数的小型语言模型，通过精心设计的数据、训练策略和架构，在推理任务上达到或超越了更大模型的性能，展示了小型模型的高效推理能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过优化数据、训练和架构，使小型语言模型在推理任务上达到与大型模型竞争的性能，以解决模型规模扩大带来的计算成本和部署难题。

Method: 采用高效监督微调（SFT）和强化学习（RL）扩展策略，结合混合并行架构设计，并利用DeepConf方法实现最优测试时扩展效率。

Result: Falcon-H1R在多个推理密集型基准测试中，性能匹配或超越了参数规模2-7倍大的当前最优模型，同时在推理速度、token效率和准确率方面均有显著提升。

Conclusion: 通过针对性的模型训练和架构选择，紧凑模型能够提供强大且可扩展的推理性能，为需要大量思维链生成和并行测试扩展的场景提供了实用的基础模型。

Abstract: This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\times$ to $7\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [56] [Free Energy-Based Modeling of Emotional Dynamics in Video Advertisements](https://arxiv.org/abs/2601.00812)
*Takashi Ushio,Kazuhiro Onishi,Hideyoshi Yanagisawa*

Main category: cs.CV

TL;DR: 本研究提出了一种仅从广告视频场景级表达特征量化情感的方法，基于自由能原理，无需生理信号或主观评分，成功识别了愉悦感、惊喜和习惯化三种情感维度及其模式。


<details>
  <summary>Details</summary>
Motivation: 广告视频观看时的情感反应对媒体效果至关重要，但现有方法常依赖外部信息（如生理信号或主观评分）。本研究旨在建立一种可解释的情感估计方法，仅基于视频内容本身进行量化分析。

Method: 基于自由能原理，从广告视频的场景级表达特征中提取三个核心指标：Kullback-Leibler散度（KLD）捕捉预测误差，贝叶斯惊喜（BS）捕捉信念更新，不确定性（UN）反映先验模糊性。使用1,059条15秒食品广告视频进行实验，并在不同超参数设置和广告类型（三种体裁、两种时长）下验证稳健性和泛化能力。

Result: KLD与品牌呈现相关的“愉悦感”相关；BS捕捉由信息复杂性引起的“惊喜”；UN反映由元素类型、空间排列不确定性以及元素多样性和数量驱动的“惊喜”。研究还识别了三种情感模式：不确定刺激、持续高情感、瞬时峰值与衰减。方法在不同设置下表现稳健。

Conclusion: 该方法为可解释的情感估计提供了方法论基础，仅依赖视频内容特征，无需外部信息。未来可通过整合更多表达元素和主观评分验证进一步扩展，指导创作更具吸引力的广告视频技术发展。

Abstract: Emotional responses during advertising video viewing are recognized as essential for understanding media effects because they have influenced attention, memory, and purchase intention. To establish a methodological basis for explainable emotion estimation without relying on external information such as physiological signals or subjective ratings, we have quantified "pleasantness," "surprise," and "habituation" solely from scene-level expression features of advertising videos, drawing on the free energy(FE) principle, which has provided a unified account of perception, learning, and behavior. In this framework, Kullback-Leibler divergence (KLD) has captured prediction error, Bayesian surprise (BS) has captured belief updates, and uncertainty (UN) has reflected prior ambiguity, and together they have formed the core components of FE. Using 1,059 15 s food video advertisements, the experiments have shown that KLD has reflected "pleasantness" associated with brand presentation, BS has captured "surprise" arising from informational complexity, and UN has reflected "surprise" driven by uncertainty in element types and spatial arrangements, as well as by the variability and quantity of presented elements. This study also identified three characteristic emotional patterns, namely uncertain stimulus, sustained high emotion, and momentary peak and decay, demonstrating the usefulness of the proposed method. Robustness across nine hyperparameter settings and generalization tests with six types of Japanese advertising videos (three genres and two durations) confirmed that these tendencies remained stable. This work can be extended by integrating a wider range of expression elements and validating the approach through subjective ratings, ultimately guiding the development of technologies that can support the creation of more engaging advertising videos.

</details>


### [57] [Can Generative Models Actually Forge Realistic Identity Documents?](https://arxiv.org/abs/2601.00829)
*Alexander Vinogradov*

Main category: cs.CV

TL;DR: 评估开源扩散模型生成身份证伪造件的真实性，发现当前模型能模拟外观但无法达到法证级真实，相关风险可能被高估。


<details>
  <summary>Details</summary>
Motivation: 生成式图像模型在真实性上进展迅速，引发公众对其可能被滥用于证件伪造的担忧，需要评估其实际伪造能力。

Method: 使用包括Stable Diffusion、Qwen、Flux、Nano-Banana在内的多种开源扩散模型，测试文本到图像和图像到图像的生成流程。

Result: 当前生成模型能模拟证件表面美学特征，但无法复制结构性和法证层面的真实性，难以通过人工或自动验证系统。

Conclusion: 生成式身份证深度伪造达到法证级真实性的风险可能被高估，强调机器学习从业者与文件法证专家合作进行现实风险评估的重要性。

Abstract: Generative image models have recently shown significant progress in image realism, leading to public concerns about their potential misuse for document forgery. This paper explores whether contemporary open-source and publicly accessible diffusion-based generative models can produce identity document forgeries that could realistically bypass human or automated verification systems. We evaluate text-to-image and image-to-image generation pipelines using multiple publicly available generative model families, including Stable Diffusion, Qwen, Flux, Nano-Banana, and others. The findings indicate that while current generative models can simulate surface-level document aesthetics, they fail to reproduce structural and forensic authenticity. Consequently, the risk of generative identity document deepfakes achieving forensic-level authenticity may be overestimated, underscoring the value of collaboration between machine learning practitioners and document-forensics experts in realistic risk assessment.

</details>


### [58] [Pediatric Pneumonia Detection from Chest X-Rays:A Comparative Study of Transfer Learning and Custom CNNs](https://arxiv.org/abs/2601.00837)
*Agniv Roy Choudhury*

Main category: cs.CV

TL;DR: 本研究比较了从头训练的自定义CNN与迁移学习模型在儿童肺炎检测中的表现，发现微调后的ResNet50达到近完美准确率，具有作为资源有限地区筛查工具的潜力。


<details>
  <summary>Details</summary>
Motivation: 肺炎是五岁以下儿童主要死因，每年导致超70万人死亡，而胸片诊断受限于放射科医生数量不足和诊断差异。

Method: 使用5,216张儿童胸片数据集，以80/10/10比例划分训练/验证/测试集，比较7种模型（包括ResNet50、DenseNet121、EfficientNet-B0的冻结主干和微调版本），采用准确率、F1分数、AUC评估性能，并通过Grad-CAM提供可解释性。

Result: 微调ResNet50表现最佳：准确率99.43%、F1分数99.61%、AUC 99.93%，仅3例误分类；微调模型平均比冻结主干模型高5.5个百分点；Grad-CAM显示模型聚焦临床相关肺区域。

Conclusion: 迁移学习结合微调显著优于从头训练的CNN，在儿童肺炎检测中达到近乎完美的准确率，适合资源有限地区筛查；未来需在多中心及成人数据集中验证。

Abstract: Pneumonia is a leading cause of mortality in children under five, with over 700,000 deaths annually. Accurate diagnosis from chest X-rays is limited by radiologist availability and variability.
  Objective: This study compares custom CNNs trained from scratch with transfer learning (ResNet50, DenseNet121, EfficientNet-B0) for pediatric pneumonia detection, evaluating frozen-backbone and fine-tuning regimes.
  Methods: A dataset of 5,216 pediatric chest X-rays was split 80/10/10 for training, validation, and testing. Seven models were trained and assessed using accuracy, F1-score, and AUC. Grad-CAM visualizations provided explainability.
  Results: Fine-tuned ResNet50 achieved the best performance: 99.43\% accuracy, 99.61\% F1-score, and 99.93\% AUC, with only 3 misclassifications. Fine-tuning outperformed frozen-backbone models by 5.5 percentage points on average. Grad-CAM confirmed clinically relevant lung regions guided predictions.
  Conclusions: Transfer learning with fine-tuning substantially outperforms CNNs trained from scratch for pediatric pneumonia detection, showing near-perfect accuracy. This system has strong potential as a screening tool in resource-limited settings. Future work should validate these findings on multi-center and adult datasets.
  Keywords: Pneumonia detection, deep learning, transfer learning, CNN, chest X-ray, pediatric diagnosis, ResNet, DenseNet, EfficientNet, Grad-CAM.

</details>


### [59] [Unified Review and Benchmark of Deep Segmentation Architectures for Cardiac Ultrasound on CAMUS](https://arxiv.org/abs/2601.00839)
*Zahid Ullah,Muhammad Hilal,Eunsoo Lee,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 本研究对心脏超声分割文献进行综述，并在CAMUS数据集上对U-Net、Attention U-Net和TransUNet三种架构进行统一实验对比，探讨不同预处理方法、自监督预训练和伪标签技术的影响。


<details>
  <summary>Details</summary>
Motivation: 现有综述多关注心脏影像与深度学习进展，但缺乏统一、可复现的实验基准。本研究旨在填补这一空白，通过标准化比较为心脏超声分割提供实用指导。

Method: 在CAMUS超声数据集上，采用统一训练划分、损失函数和评估标准，对比三种网络架构。测试多种预处理流程：原生NIfTI数据、16位PNG导出、GPT辅助多边形伪标签、基于数千未标注帧的自监督预训练。

Result: 原生NIfTI训练的U-Net达到94%平均Dice分数（16位PNG为91%）；Attention U-Net在小区域和低对比度区域表现更优；TransUNet在困难帧上泛化能力最强，尤其结合自监督预训练时；伪标签经置信度过滤后可提升模型鲁棒性。

Conclusion: 研究建立了心脏超声分割的标准化基准，证明数据预处理（如保持动态范围）对性能至关重要，同时展望了自监督学习和多模态GPT标注流程在快速标注和质量控制中的应用前景。

Abstract: Several review papers summarize cardiac imaging and DL advances, few works connect this overview to a unified and reproducible experimental benchmark. In this study, we combine a focused review of cardiac ultrasound segmentation literature with a controlled comparison of three influential architectures, U-Net, Attention U-Net, and TransUNet, on the Cardiac Acquisitions for Multi-Structure Ultrasound Segmentation (CAMUS) echocardiography dataset. Our benchmark spans multiple preprocessing routes, including native NIfTI volumes, 16-bit PNG exports, GPT-assisted polygon-based pseudo-labels, and self-supervised pretraining (SSL) on thousands of unlabeled cine frames. Using identical training splits, losses, and evaluation criteria, a plain U-Net achieved a 94% mean Dice when trained directly on NIfTI data (preserving native dynamic range), while the PNG-16-bit workflow reached 91% under similar conditions. Attention U-Net provided modest improvements on small or low-contrast regions, reducing boundary leakage, whereas TransUNet demonstrated the strongest generalization on challenging frames due to its ability to model global spatial context, particularly when initialized with SSL. Pseudo-labeling expanded the training set and improved robustness after confidence filtering. Overall, our contributions are threefold: a harmonized, apples-to-apples benchmark of U-Net, Attention U-Net, and TransUNet under standardized CAMUS preprocessing and evaluation; practical guidance on maintaining intensity fidelity, resolution consistency, and alignment when preparing ultrasound data; and an outlook on scalable self-supervision and emerging multimodal GPT-based annotation pipelines for rapid labeling, quality assurance, and targeted dataset curation.

</details>


### [60] [Motion-Compensated Latent Semantic Canvases for Visual Situational Awareness on Edge](https://arxiv.org/abs/2601.00854)
*Igor Lodin,Sergii Filatov,Vira Filatova,Dmytro Filatov*

Main category: cs.CV

TL;DR: 提出MCLSC方法，通过在基准坐标系中维护静态和动态两层潜在语义画布，结合运动触发机制，大幅减少资源受限边缘设备上的语义分割计算需求。


<details>
  <summary>Details</summary>
Motivation: 资源受限的边缘设备需要高效的视觉情境感知方案，传统逐帧语义分割计算成本过高，需要减少处理负担同时保持语义信息的连贯性。

Method: 使用两个潜在语义画布（静态层和动态层），通过视频流稳定建立基准坐标系，采用运动触发机制异步运行昂贵的全景分割（Mask2Former），仅当运动检测到新信息时才进行推理。

Result: 在480p视频测试中，相比逐帧分割方法，分割调用减少30倍以上，端到端平均处理时间降低20倍以上，同时保持连贯的静态/动态语义覆盖。

Conclusion: MCLSC方法能显著降低边缘设备上的计算负载，实现高效的视觉情境感知，为资源受限环境提供了可行的解决方案。

Abstract: We propose Motion-Compensated Latent Semantic Canvases (MCLSC) for visual situational awareness on resource-constrained edge devices. The core idea is to maintain persistent semantic metadata in two latent canvases - a slowly accumulating static layer and a rapidly updating dynamic layer - defined in a baseline coordinate frame stabilized from the video stream. Expensive panoptic segmentation (Mask2Former) runs asynchronously and is motion-gated: inference is triggered only when motion indicates new information, while stabilization/motion compensation preserves a consistent coordinate system for latent semantic memory. On prerecorded 480p clips, our prototype reduces segmentation calls by >30x and lowers mean end-to-end processing time by >20x compared to naive per-frame segmentation, while maintaining coherent static/dynamic semantic overlays.

</details>


### [61] [VL-OrdinalFormer: Vision Language Guided Ordinal Transformers for Interpretable Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.00879)
*Zahid Ullah,Jihie Kim*

Main category: cs.CV

TL;DR: 提出VLOrdinalFormer框架，结合视觉语言引导的序数学习，用于膝关节骨关节炎的自动分级，在OAI数据集上取得最优性能，尤其改善了早期阶段的分类准确性。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎是全球致残的主要原因，早期阶段（KL1和KL2）的影像学特征细微，导致放射科医生间评估存在差异，需要更准确、自动化的分级方法。

Method: 采用ViT L16骨干网络，结合CORAL序数回归和CLIP驱动的语义对齐模块，融入关节间隙狭窄、骨赘形成等临床文本概念；使用分层五折交叉验证、类别感知重加权和测试时增强以提高鲁棒性。

Result: 在OAI kneeKL224数据集上，VLOrdinalFormer在宏观F1分数和总体准确率上优于CNN和ViT基线模型，显著提升了KL1和KL2的分级性能，且不损害中重度病例的准确性；可解释性分析显示模型关注临床相关解剖区域。

Conclusion: 视觉语言对齐的序数Transformer框架可作为可靠、可解释的工具，用于膝关节骨关节炎分级和疾病进展评估，有望应用于常规放射学实践。

Abstract: Knee osteoarthritis (KOA) is a leading cause of disability worldwide, and accurate severity assessment using the Kellgren Lawrence (KL) grading system is critical for clinical decision making. However, radiographic distinctions between early disease stages, particularly KL1 and KL2, are subtle and frequently lead to inter-observer variability among radiologists. To address these challenges, we propose VLOrdinalFormer, a vision language guided ordinal learning framework for fully automated KOA grading from knee radiographs. The proposed method combines a ViT L16 backbone with CORAL based ordinal regression and a Contrastive Language Image Pretraining (CLIP) driven semantic alignment module, allowing the model to incorporate clinically meaningful textual concepts related to joint space narrowing, osteophyte formation, and subchondral sclerosis. To improve robustness and mitigate overfitting, we employ stratified five fold cross validation, class aware re weighting to emphasize challenging intermediate grades, and test time augmentation with global threshold optimization. Experiments conducted on the publicly available OAI kneeKL224 dataset demonstrate that VLOrdinalFormer achieves state of the art performance, outperforming CNN and ViT baselines in terms of macro F1 score and overall accuracy. Notably, the proposed framework yields substantial performance gains for KL1 and KL2 without compromising classification accuracy for mild or severe cases. In addition, interpretability analyses using Grad CAM and CLIP similarity maps confirm that the model consistently attends to clinically relevant anatomical regions. These results highlight the potential of vision language aligned ordinal transformers as reliable and interpretable tools for KOA grading and disease progression assessment in routine radiological practice.

</details>


### [62] [VideoCuRL: Video Curriculum Reinforcement Learning with Orthogonal Difficulty Decomposition](https://arxiv.org/abs/2601.00887)
*Hongbo Jin,Kuanwei Lin,Wenhao Zhang,Yichen Jin,Ge Li*

Main category: cs.CV

TL;DR: 提出VideoCuRL框架，通过将视频理解难度分解为视觉时间感知负载和认知推理深度两个正交维度，并采用对角线波前策略进行课程学习，显著提升视频语言模型的强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习范式主要依赖随机数据洗牌或基于标量难度指标的简单课程策略，但标量指标无法区分视频理解中的视觉时间感知负载和认知推理深度这两个正交挑战，限制了视频语言模型的时空推理能力。

Method: 1. 提出二维课程网格，使用光流和关键帧熵（视觉复杂度）以及校准惊奇度（认知复杂度）作为训练免费代理指标；2. 采用能力感知的对角线波前策略安排从基础对齐到复杂推理的训练过程；3. 引入动态稀疏KL散度和结构化重访机制以稳定训练。

Result: 在VSI-Bench推理任务上提升2.5分，在VideoMME感知任务上提升2.9分，显著优于现有强化学习方法，同时消除了基于生成的课程方法的高推理开销。

Conclusion: VideoCuRL通过解耦视频理解的两个核心挑战并提供可扩展的课程学习框架，为视频后训练提供了稳健且高效的解决方案，推动了视频语言模型在复杂时空推理方面的发展。

Abstract: Reinforcement Learning (RL) is crucial for empowering VideoLLMs with complex spatiotemporal reasoning. However, current RL paradigms predominantly rely on random data shuffling or naive curriculum strategies based on scalar difficulty metrics. We argue that scalar metrics fail to disentangle two orthogonal challenges in video understanding: Visual Temporal Perception Load and Cognitive Reasoning Depth. To address this, we propose VideoCuRL, a novel framework that decomposes difficulty into these two axes. We employ efficient, training-free proxies, optical flow and keyframe entropy for visual complexity, Calibrated Surprisal for cognitive complexity, to map data onto a 2D curriculum grid. A competence aware Diagonal Wavefront strategy then schedules training from base alignment to complex reasoning. Furthermore, we introduce Dynamic Sparse KL and Structured Revisiting to stabilize training against reward collapse and catastrophic forgetting. Extensive experiments show that VideoCuRL surpasses strong RL baselines on reasoning (+2.5 on VSI-Bench) and perception (+2.9 on VideoMME) tasks. Notably, VideoCuRL eliminates the prohibitive inference overhead of generation-based curricula, offering a scalable solution for robust video post-training.

</details>


### [63] [Comparative Evaluation of CNN Architectures for Neural Style Transfer in Indonesian Batik Motif Generation: A Comprehensive Study](https://arxiv.org/abs/2601.00888)
*Happy Gery Pangestu,Andi Prademon Yunus,Siti Khomsah*

Main category: cs.CV

TL;DR: 本研究系统比较了五种CNN骨干网络在神经风格迁移中应用于印尼蜡染图案的表现，发现ResNet架构在保持结构相似性的同时，计算效率显著优于VGG模型。


<details>
  <summary>Details</summary>
Motivation: 现有神经风格迁移方法主要基于VGG架构，虽然风格表达力强，但计算和内存需求高，限制了在资源有限环境中的实际部署，特别是对于印尼蜡染图案的数字保存和生成探索。

Method: 通过245个对照实验，对VGG16、VGG19、Inception V3、ResNet50和ResNet101五种CNN骨干网络进行系统比较，结合定量指标（如SSIM、LPIPS、FLOPs）、定性评估和统计分析（ANOVA），考察结构保存、风格行为和计算效率之间的权衡。

Result: 骨干网络选择对结构相似性无显著统计差异（SSIM的p=0.83），但ResNet架构比VGG模型收敛速度快约5-6倍，FLOPs减少超过16倍（0.63 vs 10.12 GFLOPs），同时保持相似的感知相似性（LPIPS=0.53）。定性分析显示VGG产生更密集的绘画纹理，ResNet更注重几何稳定性和蜡染笔触保存，Inception V3表现居中但噪声较多。

Conclusion: 研究将神经风格迁移中的架构选择从最大化风格强度重新定位为效率感知和结构保存的部署，强调ResNet骨干网络可作为可扩展、面向行业的蜡染生成的实用基础。

Abstract: Neural Style Transfer (NST) provides a computational framework for the digital preservation and generative exploration of Indonesian batik motifs; however, existing approaches remain largely centered on VGG-based architectures whose strong stylistic expressiveness comes at the cost of high computational and memory demands, that limits practical deployment in resource-limited environments. This study presents a systematic comparative analysis of five widely used CNN backbones, namely VGG16, VGG19, Inception V3, ResNet50, and ResNet101, based on 245 controlled experiments combining quantitative metrics, qualitative assessment, and statistical analysis to examine the trade-off between structural preservation, stylistic behavior, and computational efficiency. The results show that backbone selection does not yield statistically significant differences in structural similarity, as confirmed by ANOVA on SSIM (p= 0.83), indicating comparable levels of structural preservation rather than equivalent stylistic quality. Within this context, ResNet-based architectures achieve approximately 5-6x faster convergence than VGG models while maintaining similar perceptual similarity (LPIPS = 0.53) and requiring over 16x fewer FLOPs (0.63 vs 10.12 GFLOPs). Qualitative analysis reveals consistent stylistic trade-offs, with VGG producing denser painterly textures, ResNet favoring geometric stability and canting stroke preservation with milder stylization, and Inception V3 exhibiting intermediate but noisier behavior. These findings reposition architectural choice in NST from maximizing stylistic intensity toward efficiency-aware and structure-preserving deployment, highlighting ResNet-based backbones as a practical foundation for scalable, industry-oriented batik generation.

</details>


### [64] [Efficient Hyperspectral Image Reconstruction Using Lightweight Separate Spectral Transformers](https://arxiv.org/abs/2601.01064)
*Jianan Li,Wangcai Zhao,Tingfa Xu*

Main category: cs.CV

TL;DR: 提出一种轻量级分离光谱变换器（LSST），用于高效重建压缩感知测量的高光谱图像，通过分组光谱自注意力和深度可分离卷积分别处理光谱和空间特征，并引入焦点光谱损失提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像重建面临计算效率低和光谱复杂性处理的挑战，需要一种能同时高效建模光谱与空间特征的方法。

Method: 采用分治策略，设计LSST架构：分离光谱变换块（SSTB）通过分组光谱自注意力和光谱混洗操作建模局部/非局部光谱关系；轻量空间卷积块（LSCB）使用深度可分离卷积增强空间处理；训练中引入动态调整的焦点光谱损失函数。

Result: 实验表明LSST在减少计算量（FLOPs）和参数量的同时，实现了优于现有方法的重建性能，尤其在光谱复杂波段表现突出。

Conclusion: LSST为高光谱图像重建提供了一种高效轻量的解决方案，其模块化设计能有效平衡光谱与空间信息处理，代码已开源。

Abstract: Hyperspectral imaging (HSI) is essential across various disciplines for its capacity to capture rich spectral information. However, efficiently reconstructing hyperspectral images from compressive sensing measurements presents significant challenges. To tackle these, we adopt a divide-and-conquer strategy that capitalizes on the unique spectral and spatial characteristics of hyperspectral images. We introduce the Lightweight Separate Spectral Transformer (LSST), an innovative architecture tailored for efficient hyperspectral image reconstruction. This architecture consists of Separate Spectral Transformer Blocks (SSTB) for modeling spectral relationships and Lightweight Spatial Convolution Blocks (LSCB) for spatial processing. The SSTB employs Grouped Spectral Self-attention and a Spectrum Shuffle operation to effectively manage both local and non-local spectral relationships. Simultaneously, the LSCB utilizes depth-wise separable convolutions and strategic ordering to enhance spatial information processing. Furthermore, we implement the Focal Spectrum Loss, a novel loss weighting mechanism that dynamically adjusts during training to improve reconstruction across spectrally complex bands. Extensive testing demonstrates that our LSST achieves superior performance while requiring fewer FLOPs and parameters, underscoring its efficiency and effectiveness. The source code is available at: https://github.com/wcz1124/LSST.

</details>


### [65] [CornViT: A Multi-Stage Convolutional Vision Transformer Framework for Hierarchical Corn Kernel Analysis](https://arxiv.org/abs/2601.00897)
*Sai Teja Erukude,Jane Mascarenhas,Lior Shamir*

Main category: cs.CV

TL;DR: 提出CornViT框架，使用三阶段卷积视觉Transformer自动分级玉米籽粒，在纯度、形态和胚芽朝向检测上达到90%以上准确率，优于传统CNN模型。


<details>
  <summary>Details</summary>
Motivation: 玉米籽粒分级对种子认证、定向播种和育种至关重要，但目前主要依赖人工检测，效率低且主观性强，需要自动化解决方案。

Method: 采用三阶段CvT-13分类器框架：第一阶段区分纯籽粒与杂质，第二阶段分类纯籽粒的扁平/圆形形态，第三阶段检测扁平纯籽粒的胚芽朝向。使用ImageNet-22k预训练模型进行头部微调。

Result: CornViT在三个任务上的测试准确率分别为：纯度93.76%、形态94.11%、胚芽朝向91.12%，显著优于ResNet-50（76.56-81.02%）和DenseNet-121（86.56-89.38%）。

Conclusion: 卷积增强的自注意力机制在籽粒分析中具有优势；CornViT框架、标注数据集和Flask网络应用为玉米籽粒质量评估提供了可部署的自动化解决方案。

Abstract: Accurate grading of corn kernels is critical for seed certification, directional seeding, and breeding, yet it is still predominantly performed by manual inspection. This work introduces CornViT, a three-stage Convolutional Vision Transformer (CvT) framework that emulates the hierarchical reasoning of human seed analysts for single-kernel evaluation. Three sequential CvT-13 classifiers operate on 384x384 RGB images: Stage 1 distinguishes pure from impure kernels; Stage 2 categorizes pure kernels into flat and round morphologies; and Stage 3 determines the embryo orientation (up vs. down) for pure, flat kernels. Starting from a public corn seed image collection, we manually relabeled and filtered images to construct three stage-specific datasets: 7265 kernels for purity, 3859 pure kernels for morphology, and 1960 pure-flat kernels for embryo orientation, all released as benchmarks. Head-only fine-tuning of ImageNet-22k pretrained CvT-13 backbones yields test accuracies of 93.76% for purity, 94.11% for shape, and 91.12% for embryo-orientation detection. Under identical training conditions, ResNet-50 reaches only 76.56 to 81.02 percent, whereas DenseNet-121 attains 86.56 to 89.38 percent accuracy. These results highlight the advantages of convolution-augmented self-attention for kernel analysis. To facilitate adoption, we deploy CornViT in a Flask-based web application that performs stage-wise inference and exposes interpretable outputs through a browser interface. Together, the CornViT framework, curated datasets, and web application provide a deployable solution for automated corn kernel quality assessment in seed quality workflows. Source code and data are publicly available.

</details>


### [66] [Evaluating Contextual Intelligence in Recyclability: A Comprehensive Study of Image-Based Reasoning Systems](https://arxiv.org/abs/2601.00905)
*Eliot Park,Abhi Kumar,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: 本研究评估了GPT-4o、GPT-4o-mini和Claude 3.5等先进视觉语言模型在预测物品可回收性及正确投放方面的能力，并测试了它们在多种复杂场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 公众在准确判断物品可回收性及正确投放方式方面存在困难，这阻碍了高效回收实践的普及。

Method: 使用精选图像数据集，评估模型将物品匹配到合适回收箱的能力（包括物理适配性），并测试了三种挑战性场景：基于地理位置调整预测、考虑污染或结构损坏、处理多材料物品。

Result: 这些模型在上下文理解方面相比早期版本有显著进步，但在某些特定场景下仍存在不足。

Conclusion: 持续改进情境感知模型对于提升公众回收实践和推动环境可持续发展至关重要。

Abstract: While the importance of efficient recycling is widely acknowledged, accurately determining the recyclability of items and their proper disposal remains a complex task for the general public. In this study, we explore the application of cutting-edge vision-language models (GPT-4o, GPT-4o-mini, and Claude 3.5) for predicting the recyclability of commonly disposed items. Utilizing a curated dataset of images, we evaluated the models' ability to match objects to appropriate recycling bins, including assessing whether the items could physically fit into the available bins. Additionally, we investigated the models' performance across several challenging scenarios: (i) adjusting predictions based on location-specific recycling guidelines; (ii) accounting for contamination or structural damage; and (iii) handling objects composed of multiple materials. Our findings highlight the significant advancements in contextual understanding offered by these models compared to previous iterations, while also identifying areas where they still fall short. The continued refinement of context-aware models is crucial for enhancing public recycling practices and advancing environmental sustainability.

</details>


### [67] [Histogram Assisted Quality Aware Generative Model for Resolution Invariant NIR Image Colorization](https://arxiv.org/abs/2601.01103)
*Abhinav Attri,Rajeev Ranjan Dwivedi,Samiran Das,Vinod Kumar Kurmi*

Main category: cs.CV

TL;DR: HAQAGen是一个统一生成模型，用于分辨率不变的红外到RGB着色，平衡色彩真实性与结构保真度。


<details>
  <summary>Details</summary>
Motivation: 现有NIR-to-RGB转换方法在保持纹理细节和色彩一致性方面存在不足，特别是在高分辨率场景下。

Method: 结合可微分直方图匹配、感知质量度量和特征相似性的损失函数；通过SPADE注入局部色调饱和度先验；在Mamba骨干网络中引入纹理感知监督；自适应分辨率推理引擎。

Result: 在FANVID等数据集上超越现有方法，生成图像具有更锐利的纹理和自然色彩，感知指标显著提升。

Conclusion: HAQAGen是一个可扩展且有效的NIR-to-RGB转换解决方案，能在不同成像场景中保持纹理保真度和泛化能力。

Abstract: We present HAQAGen, a unified generative model for resolution-invariant NIR-to-RGB colorization that balances chromatic realism with structural fidelity. The proposed model introduces (i) a combined loss term aligning the global color statistics through differentiable histogram matching, perceptual image quality measure, and feature based similarity to preserve texture information, (ii) local hue-saturation priors injected via Spatially Adaptive Denormalization (SPADE) to stabilize chromatic reconstruction, and (iii) texture-aware supervision within a Mamba backbone to preserve fine details. We introduce an adaptive-resolution inference engine that further enables high-resolution translation without sacrificing quality. Our proposed NIR-to-RGB translation model simultaneously enforces global color statistics and local chromatic consistency, while scaling to native resolutions without compromising texture fidelity or generalization. Extensive evaluations on FANVID, OMSIV, VCIP2020, and RGB2NIR using different evaluation metrics demonstrate consistent improvements over state-of-the-art baseline methods. HAQAGen produces images with sharper textures, natural colors, attaining significant gains as per perceptual metrics. These results position HAQAGen as a scalable and effective solution for NIR-to-RGB translation across diverse imaging scenarios. Project Page: https://rajeev-dw9.github.io/HAQAGen/

</details>


### [68] [Clean-GS: Semantic Mask-Guided Pruning for 3D Gaussian Splatting](https://arxiv.org/abs/2601.00913)
*Subhankar Mishra*

Main category: cs.CV

TL;DR: Clean-GS方法利用稀疏语义掩码去除3D高斯泼溅中的背景杂波和伪影高斯，实现60-80%模型压缩，保持渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅生成大量伪影高斯（漂浮物），遮挡目标物体并增大模型体积，阻碍在带宽受限应用中的部署。

Method: 结合白名单空间过滤、颜色引导验证和基于邻域的离群值去除的三阶段方法，仅需3个分割掩码（1%视图）识别非目标高斯。

Result: 在Tanks and Temples数据集上，模型大小从125MB降至47MB，渲染质量得以保持。

Conclusion: Clean-GS使3DGS模型适用于网络部署和AR/VR应用，代码已开源。

Abstract: 3D Gaussian Splatting produces high-quality scene reconstructions but generates hundreds of thousands of spurious Gaussians (floaters) scattered throughout the environment. These artifacts obscure objects of interest and inflate model sizes, hindering deployment in bandwidth-constrained applications. We present Clean-GS, a method for removing background clutter and floaters from 3DGS reconstructions using sparse semantic masks. Our approach combines whitelist-based spatial filtering with color-guided validation and outlier removal to achieve 60-80\% model compression while preserving object quality. Unlike existing 3DGS pruning methods that rely on global importance metrics, Clean-GS uses semantic information from as few as 3 segmentation masks (1\% of views) to identify and remove Gaussians not belonging to the target object. Our multi-stage approach consisting of (1) whitelist filtering via projection to masked regions, (2) depth-buffered color validation, and (3) neighbor-based outlier removal isolates monuments and objects from complex outdoor scenes. Experiments on Tanks and Temples show that Clean-GS reduces file sizes from 125MB to 47MB while maintaining rendering quality, making 3DGS models practical for web deployment and AR/VR applications. Our code is available at https://github.com/smlab-niser/clean-gs

</details>


### [69] [A UAV-Based Multispectral and RGB Dataset for Multi-Stage Paddy Crop Monitoring in Indian Agricultural Fields](https://arxiv.org/abs/2601.01084)
*Adari Rama Sukanya,Puvvula Roopesh Naga Sri Sai,Kota Moses,Rimalapudi Sarvendranath*

Main category: cs.CV

TL;DR: 本文介绍了印度安得拉邦稻田从育苗到收获阶段的大规模无人机RGB和多光谱图像数据集，包含42,430张原始图像（415 GB），具有1厘米/像素的高分辨率及丰富元数据。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏覆盖水稻全生长阶段的高分辨率、多光谱且附带丰富元数据的公开数据集，限制了精准农业（如靶向喷药、病害分析和产量估算）的研究与应用。

Method: 使用20兆像素RGB相机和5兆像素四波段多光谱相机（红、绿、红边、近红外）采集数据；制定标准化操作流程确保可重复性；通过Pix4D Fields验证并生成正射影像图和植被指数图（如NDVI、NDRE）。

Result: 构建了包含42,430张图像（415 GB）的数据集，地面采样距离为1厘米/像素，附带GPS坐标、飞行高度和环境条件等元数据；数据集已公开在IEEE DataPort平台。

Conclusion: 该数据集是少数覆盖印度水稻全生长阶段的高分辨率多光谱数据集，可为精准农业研究提供重要支持，并已开源促进相关领域发展。

Abstract: We present a large-scale unmanned aerial vehicle (UAV)-based RGB and multispectral image dataset collected over paddy fields in the Vijayawada region, Andhra Pradesh, India, covering nursery to harvesting stages. We used a 20-megapixel RGB camera and a 5-megapixel four-band multispectral camera capturing red, green, red-edge, and near-infrared bands. Standardised operating procedure (SOP) and checklists were developed to ensure repeatable data acquisition. Our dataset comprises of 42,430 raw images (415 GB) captured over 5 acres with 1 cm/pixel ground sampling distance (GSD) with associated metadata such as GPS coordinates, flight altitude, and environmental conditions. Captured images were validated using Pix4D Fields to generate orthomosaic maps and vegetation index maps, such as normalised difference vegetation index (NDVI) and normalised difference red-edge (NDRE) index. Our dataset is one of the few datasets that provide high-resolution images with rich metadata that cover all growth stages of Indian paddy crops. The dataset is available on IEEE DataPort with DOI, . It can support studies on targeted spraying, disease analysis, and yield estimation.

</details>


### [70] [Four-Stage Alzheimer's Disease Classification from MRI Using Topological Feature Extraction, Feature Selection, and Ensemble Learning](https://arxiv.org/abs/2601.00918)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: 提出TDA-Alz框架，结合拓扑数据分析与集成学习，用于阿尔茨海默病四阶段分类，在OASIS-1数据集上达到98.19%准确率，优于现有深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的阿尔茨海默病MRI分类方法面临数据需求大、计算成本高、模型可解释性差等挑战，需要开发更高效、可解释的轻量级方法。

Method: 使用拓扑数据分析提取脑MRI的结构拓扑描述符，通过特征选择保留最具判别性的特征，最后采用集成学习策略进行四阶段分类。

Result: 在OASIS-1数据集上实现98.19%准确率和99.75% AUC，超越或匹配现有深度学习方法，且无需数据增强、预训练网络或大规模计算资源。

Conclusion: TDA-Alz为MRI阿尔茨海默病严重程度分类提供了强大、轻量、可解释的替代方案，具有临床决策支持系统的应用潜力。

Abstract: Accurate and efficient classification of Alzheimer's disease (AD) severity from brain magnetic resonance imaging (MRI) remains a critical challenge, particularly when limited data and model interpretability are of concern. In this work, we propose TDA-Alz, a novel framework for four-stage Alzheimer's disease severity classification (non-demented, moderate dementia, mild, and very mild) using topological data analysis (TDA) and ensemble learning. Instead of relying on deep convolutional architectures or extensive data augmentation, our approach extracts topological descriptors that capture intrinsic structural patterns of brain MRI, followed by feature selection to retain the most discriminative topological features. These features are then classified using an ensemble learning strategy to achieve robust multiclass discrimination.
  Experiments conducted on the OASIS-1 MRI dataset demonstrate that the proposed method achieves an accuracy of 98.19% and an AUC of 99.75%, outperforming or matching state-of-the-art deep learning--based methods reported on OASIS and OASIS-derived datasets. Notably, the proposed framework does not require data augmentation, pretrained networks, or large-scale computational resources, making it computationally efficient and fast compared to deep neural network approaches. Furthermore, the use of topological descriptors provides greater interpretability, as the extracted features are directly linked to the underlying structural characteristics of brain MRI rather than opaque latent representations. These results indicate that TDA-Alz offers a powerful, lightweight, and interpretable alternative to deep learning models for MRI-based Alzheimer's disease severity classification, with strong potential for real-world clinical decision-support systems.

</details>


### [71] [MS-ISSM: Objective Quality Assessment of Point Clouds Using Multi-scale Implicit Structural Similarity](https://arxiv.org/abs/2601.01200)
*Zhang Chen,Shuai Wan,Yuezhe Zhang,Siyu Ren,Fuzheng Yang,Junhui Hou*

Main category: cs.CV

TL;DR: 提出MS-ISSM方法，通过径向基函数连续表示点云局部特征，结合ResGrouped-MLP网络进行多尺度质量评估，显著提升点云质量评价的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 点云数据的非结构化和不规则特性导致传统点对点匹配方法在质量评估中存在特征对应不准确的问题，需要更有效的感知特征建模方法。

Method: 1. 提出多尺度隐式结构相似性度量（MS-ISSM），使用径向基函数连续表示局部特征，将失真度量转化为隐式函数系数比较；2. 设计ResGrouped-MLP质量评估网络，采用分组编码策略结合残差块和通道注意力机制，分层处理亮度、色度和几何特征。

Result: 在多个基准测试中，MS-ISSM在可靠性和泛化性方面均优于现有最先进的质量评估指标。

Conclusion: MS-ISSM通过隐式函数表示和多尺度分层处理，有效解决了不规则点云数据的质量评估难题，为点云质量评估提供了更准确的解决方案。

Abstract: The unstructured and irregular nature of point clouds poses a significant challenge for objective quality assessment (PCQA), particularly in establishing accurate perceptual feature correspondence. To tackle this, we propose the Multi-scale Implicit Structural Similarity Measurement (MS-ISSM). Unlike traditional point-to-point matching, MS-ISSM utilizes Radial Basis Functions (RBF) to represent local features continuously, transforming distortion measurement into a comparison of implicit function coefficients. This approach effectively circumvents matching errors inherent in irregular data. Additionally, we propose a ResGrouped-MLP quality assessment network, which robustly maps multi-scale feature differences to perceptual scores. The network architecture departs from traditional flat MLPs by adopting a grouped encoding strategy integrated with Residual Blocks and Channel-wise Attention mechanisms. This hierarchical design allows the model to preserve the distinct physical semantics of luma, chroma, and geometry while adaptively focusing on the most salient distortion features across High, Medium, and Low scales. Experimental results on multiple benchmarks demonstrate that MS-ISSM outperforms state-of-the-art metrics in both reliability and generalization. The source code is available at: https://github.com/ZhangChen2022/MS-ISSM.

</details>


### [72] [Application of deep learning techniques in non-contrast computed tomography pulmonary angiogram for pulmonary embolism diagnosis](https://arxiv.org/abs/2601.00925)
*I-Hsien Ting,Yi-Jun Tseng,Yu-Sheng Lin*

Main category: cs.CV

TL;DR: 本研究开发了一种基于3D卷积神经网络的深度学习模型，用于在无需造影剂的CT图像中自动分类肺栓塞，准确率达85%，AUC为0.84。


<details>
  <summary>Details</summary>
Motivation: 传统使用造影剂的CT肺动脉造影诊断肺栓塞可能对慢性肾病患者造成急性肾损伤，且造影剂起效时间可能延误急性肺栓塞患者的黄金治疗时间。

Method: 采用3D卷积神经网络模型，对无造影剂的CT图像进行肺栓塞自动分类。

Result: 模型在无造影剂CT图像的肺栓塞分类中表现显著，准确率为85%，AUC为0.84。

Conclusion: 该深度学习模型在无造影剂CT图像中诊断肺栓塞具有可行性，为减少造影剂相关风险提供了新途径。

Abstract: Pulmonary embolism is a life-threatening disease, early detection and treatment can significantly reduce mortality. In recent years, many studies have been using deep learning in the diagnosis of pulmonary embolism with contrast medium computed tomography pulmonary angiography, but the contrast medium is likely to cause acute kidney injury in patients with pulmonary embolism and chronic kidney disease, and the contrast medium takes time to work, patients with acute pulmonary embolism may miss the golden treatment time.
  This study aims to use deep learning techniques to automatically classify pulmonary embolism in CT images without contrast medium by using a 3D convolutional neural network model. The deep learning model used in this study had a significant impact on the pulmonary embolism classification of computed tomography images without contrast with 85\% accuracy and 0.84 AUC, which confirms the feasibility of the model in the diagnosis of pulmonary embolism.

</details>


### [73] [LinMU: Multimodal Understanding Made Linear](https://arxiv.org/abs/2601.01322)
*Hongjie Wang,Niraj K. Jha*

Main category: cs.CV

TL;DR: 提出LinMU，一种线性复杂度的视觉语言模型，通过M-MATE模块替换自注意力层，在保持性能的同时显著降低计算成本，适用于高分辨率图像和长视频理解。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型的自注意力机制具有二次复杂度，导致在边缘设备部署困难，且处理高分辨率图像和长视频时计算成本过高。

Method: 设计M-MATE双分支模块（Flex-MA全局上下文分支和Local-Swin局部注意力分支），并提出三阶段蒸馏框架：先训练Flex-MA分支，再联合微调双分支，最后使用LoRA适配器微调其余模块并回归教师模型的隐藏状态和logits。

Result: 在MMMU、TextVQA、LongVideoBench等基准测试中，LinMU性能与教师模型相当，但首词生成时间减少2.7倍，长视频处理吞吐量提升9.0倍。消融实验验证了蒸馏阶段和双分支的必要性。

Conclusion: 研究表明无需二次注意力即可实现先进的多模态推理，为处理高分辨率图像和长视频的视觉语言模型开辟了新途径。

Abstract: Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\times$ and improves token throughput by up to 9.0$\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.

</details>


### [74] [Analyzing the Shopping Journey: Computing Shelf Browsing Visits in a Physical Retail Store](https://arxiv.org/abs/2601.00928)
*Luis Yoichi Morales,Francesco Zanlungo,David M. Woollard*

Main category: cs.CV

TL;DR: 提出一种从3D轨迹中提取顾客货架访问行为的算法，用于分析零售场景中的购物意图，并在不同商店验证了其泛化能力。


<details>
  <summary>Details</summary>
Motivation: 零售业中机器人部署面临理解顾客购物意图的挑战，需要自动化方法分析实体店内的顾客行为。

Method: 基于机器视觉3D追踪和顶置摄像头获取轨迹数据，设计算法提取“货架访问”行为，使用两套独立标注轨迹（8138条和15129条）进行校准与跨店验证。

Result: 算法在不同商店环境下均能有效识别顾客浏览行为，并成功应用于大规模轨迹分析，揭示了浏览模式与实际购买的关系。

Conclusion: 货架浏览信息可用于零售规划和人机交互场景，为自动化理解购物意图提供了可行方案。

Abstract: Motivated by recent challenges in the deployment of robots into customer-facing roles within retail, this work introduces a study of customer activity in physical stores as a step toward autonomous understanding of shopper intent. We introduce an algorithm that computes shoppers' ``shelf visits'' -- capturing their browsing behavior in the store. Shelf visits are extracted from trajectories obtained via machine vision-based 3D tracking and overhead cameras. We perform two independent calibrations of the shelf visit algorithm, using distinct sets of trajectories (consisting of 8138 and 15129 trajectories), collected in different stores and labeled by human reviewers. The calibrated models are then evaluated on trajectories held out of the calibration process both from the same store on which calibration was performed and from the other store. An analysis of the results shows that the algorithm can recognize customers' browsing activity when evaluated in an environment different from the one on which calibration was performed. We then use the model to analyze the customers' ``browsing patterns'' on a large set of trajectories and their relation to actual purchases in the stores. Finally, we discuss how shelf browsing information could be used for retail planning and in the domain of human-robot interaction scenarios.

</details>


### [75] [DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization](https://arxiv.org/abs/2601.01784)
*Boyang Zhao,Xin Liao,Jiaxin Chen,Xiaoshuai Wu,Yufeng Wu*

Main category: cs.CV

TL;DR: 提出DDNet框架，通过双流图学习和解耦方法实现视频时序伪造定位，在ForgeryNet和TVIL基准上性能提升约9%。


<details>
  <summary>Details</summary>
Motivation: AIGC技术快速发展使得仅篡改视频小片段即可误导观众，现有视频级检测方法不准确且缺乏说服力，而现有时序伪造定位方法受限于局部视角，难以捕捉全局异常。

Method: 提出DDNet框架：1) 双流图学习（时间距离流捕捉局部伪影，语义内容流捕捉长程关联）；2) 痕迹解耦与适应（TDA）分离通用伪造指纹；3) 跨层级特征嵌入（CLFE）通过层次特征深度融合构建鲁棒特征基础。

Result: 在ForgeryNet和TVIL基准测试中，AP@0.95指标超越现有最佳方法约9%，跨域鲁棒性显著提升。

Conclusion: DDNet通过协调局部伪影检测与全局语义关联，有效解决了现有方法因局部平滑性淹没全局线索的问题，为时序伪造定位提供了更精确的解决方案。

Abstract: The rapid evolution of AIGC technology enables misleading viewers by tampering mere small segments within a video, rendering video-level detection inaccurate and unpersuasive. Consequently, temporal forgery localization (TFL), which aims to precisely pinpoint tampered segments, becomes critical. However, existing methods are often constrained by \emph{local view}, failing to capture global anomalies. To address this, we propose a \underline{d}ual-stream graph learning and \underline{d}isentanglement framework for temporal forgery localization (DDNet). By coordinating a \emph{Temporal Distance Stream} for local artifacts and a \emph{Semantic Content Stream} for long-range connections, DDNet prevents global cues from being drowned out by local smoothness. Furthermore, we introduce Trace Disentanglement and Adaptation (TDA) to isolate generic forgery fingerprints, alongside Cross-Level Feature Embedding (CLFE) to construct a robust feature foundation via deep fusion of hierarchical features. Experiments on ForgeryNet and TVIL benchmarks demonstrate that our method outperforms state-of-the-art approaches by approximately 9\% in AP@0.95, with significant improvements in cross-domain robustness.

</details>


### [76] [ShadowGS: Shadow-Aware 3D Gaussian Splatting for Satellite Imagery](https://arxiv.org/abs/2601.00939)
*Feng Luo,Hongbo Pan,Xiang Yang,Baoyu Jiang,Fengqing Liu,Tao Huang*

Main category: cs.CV

TL;DR: 提出ShadowGS框架，基于3D高斯泼溅技术，通过物理渲染方程和光线步进技术解决多时相卫星图像中阴影不一致问题，提升三维重建精度和阴影解耦效果。


<details>
  <summary>Details</summary>
Motivation: 多时相卫星图像中，由于光照条件变化导致阴影存在显著不一致性，影响三维重建质量，需要一种能精确建模几何一致阴影的高效方法。

Method: 基于3D高斯泼溅，结合遥感物理渲染方程和高效光线步进技术，引入阴影一致性约束和阴影图先验，支持稀疏视图输入。

Result: 在阴影解耦精度、三维重建准确性和新视角合成质量上优于现有方法，仅需几分钟训练，在RGB、全色锐化和稀疏视图卫星数据中均表现鲁棒。

Conclusion: ShadowGS能有效建模几何一致阴影，解耦光照分量与表观属性，显著提升多时相卫星图像三维重建的几何精度和渲染效率。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel paradigm for 3D reconstruction from satellite imagery. However, in multi-temporal satellite images, prevalent shadows exhibit significant inconsistencies due to varying illumination conditions. To address this, we propose ShadowGS, a novel framework based on 3DGS. It leverages a physics-based rendering equation from remote sensing, combined with an efficient ray marching technique, to precisely model geometrically consistent shadows while maintaining efficient rendering. Additionally, it effectively disentangles different illumination components and apparent attributes in the scene. Furthermore, we introduce a shadow consistency constraint that significantly enhances the geometric accuracy of 3D reconstruction. We also incorporate a novel shadow map prior to improve performance with sparse-view inputs. Extensive experiments demonstrate that ShadowGS outperforms current state-of-the-art methods in shadow decoupling accuracy, 3D reconstruction precision, and novel view synthesis quality, with only a few minutes of training. ShadowGS exhibits robust performance across various settings, including RGB, pansharpened, and sparse-view satellite inputs.

</details>


### [77] [Learning to Segment Liquids in Real-world Images](https://arxiv.org/abs/2601.00940)
*Jonas Li,Michelle Li,Luke Liu,Heng Fan*

Main category: cs.CV

TL;DR: 本文提出了一个用于液体分割的大规模数据集LQDS和一种新颖的液体检测模型LQDM，通过边界分支与分割分支的交叉注意力机制提升液体分割性能。


<details>
  <summary>Details</summary>
Motivation: 液体在日常生活中无处不在，但现有研究对其关注有限，限制了机器人安全避让或与液体交互的能力。液体分割面临挑战，因为液体外观多样、形状多变，且可能透明或反光，易与背景混淆。

Method: 构建了包含5000张真实图像、标注为14个类别的大规模液体数据集LQDS；设计了LQDM模型，利用边界分支与主分割分支之间的交叉注意力机制来增强分割预测。

Result: 在LQDS测试集上的大量实验表明，LQDM优于现有最先进方法，为液体语义分割建立了强基线。

Conclusion: LQDS数据集和LQDM模型有效解决了液体分割的挑战，为机器人安全交互液体提供了技术支持。

Abstract: Different types of liquids such as water, wine and medicine appear in all aspects of daily life. However, limited attention has been given to the task, hindering the ability of robots to avoid or interact with liquids safely. The segmentation of liquids is difficult because liquids come in diverse appearances and shapes; moreover, they can be both transparent or reflective, taking on arbitrary objects and scenes from the background or surroundings. To take on this challenge, we construct a large-scale dataset of liquids named LQDS consisting of 5000 real-world images annotated into 14 distinct classes, and design a novel liquid detection model named LQDM, which leverages cross-attention between a dedicated boundary branch and the main segmentation branch to enhance segmentation predictions. Extensive experiments demonstrate the effectiveness of LQDM on the test set of LQDS, outperforming state-of-the-art methods and establishing a strong baseline for the semantic segmentation of liquids.

</details>


### [78] [PhyEduVideo: A Benchmark for Evaluating Text-to-Video Models for Physics Education](https://arxiv.org/abs/2601.00943)
*Megha Mariam K. M,Aditya Arun,Zakaria Laskar,C. V. Jawahar*

Main category: cs.CV

TL;DR: 该研究提出了一个用于评估文本到视频（T2V）模型在物理教育中生成解释性视频能力的基准，发现当前模型在视觉连贯性上表现良好，但在概念准确性上存在不足，尤其在电磁学和热力学等抽象领域。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型（特别是T2V系统）有望通过自动化创建直观的教学视频来改变科学教育，但缺乏系统评估其在物理教育中潜力的方法。

Method: 设计了一个专门用于物理教育视频生成的基准，将物理概念分解为细粒度的教学点，并为每个点精心设计提示词，通过评估T2V模型根据提示生成准确视频的能力来系统分析其可行性。

Result: 当前模型能生成视觉连贯、运动平滑且闪烁较少的视频，但在概念准确性上不可靠：在力学、流体和光学领域表现较好，在电磁学和热力学等需要描绘抽象相互作用的领域表现较差。

Conclusion: 教育视频生成在视觉质量和概念正确性之间存在差距，该基准旨在帮助社区缩小这一差距，推动开发能够大规模生成准确、符合课程要求的物理教学内容的T2V系统。

Abstract: Generative AI models, particularly Text-to-Video (T2V) systems, offer a promising avenue for transforming science education by automating the creation of engaging and intuitive visual explanations. In this work, we take a first step toward evaluating their potential in physics education by introducing a dedicated benchmark for explanatory video generation. The benchmark is designed to assess how well T2V models can convey core physics concepts through visual illustrations. Each physics concept in our benchmark is decomposed into granular teaching points, with each point accompanied by a carefully crafted prompt intended for visual explanation of the teaching point. T2V models are evaluated on their ability to generate accurate videos in response to these prompts. Our aim is to systematically explore the feasibility of using T2V models to generate high-quality, curriculum-aligned educational content-paving the way toward scalable, accessible, and personalized learning experiences powered by AI. Our evaluation reveals that current models produce visually coherent videos with smooth motion and minimal flickering, yet their conceptual accuracy is less reliable. Performance in areas such as mechanics, fluids, and optics is encouraging, but models struggle with electromagnetism and thermodynamics, where abstract interactions are harder to depict. These findings underscore the gap between visual quality and conceptual correctness in educational video generation. We hope this benchmark helps the community close that gap and move toward T2V systems that can deliver accurate, curriculum-aligned physics content at scale. The benchmark and accompanying codebase are publicly available at https://github.com/meghamariamkm/PhyEduVideo.

</details>


### [79] [Deep Clustering with Associative Memories](https://arxiv.org/abs/2601.00963)
*Bishwajit Saha,Dmitry Krotov,Mohammed J. Zaki,Parikshit Ram*

Main category: cs.CV

TL;DR: 提出了一种新的深度聚类方法DCAM，通过基于能量的动力学和关联记忆，将表示学习和聚类更紧密地结合在单一目标中，提升了聚类质量。


<details>
  <summary>Details</summary>
Motivation: 传统深度聚类方法中，表示学习是可微分的，而聚类本质上是离散优化任务，需要各种近似和正则化才能融入标准可微管道，导致表示学习和聚类之间存在脱节。

Method: 提出DCAM方法，利用基于能量的动力学和关联记忆设计新的损失函数，在单一目标中更精细地结合表示学习和聚类。

Result: 实验表明DCAM在不同架构（卷积、残差或全连接）和数据模态（图像或文本）上均能产生更好的聚类质量。

Conclusion: DCAM通过能量动力学和关联记忆将表示学习与聚类更紧密地结合，提供了一种有效的深度聚类解决方案。

Abstract: Deep clustering - joint representation learning and latent space clustering - is a well studied problem especially in computer vision and text processing under the deep learning framework. While the representation learning is generally differentiable, clustering is an inherently discrete optimization task, requiring various approximations and regularizations to fit in a standard differentiable pipeline. This leads to a somewhat disjointed representation learning and clustering. In this work, we propose a novel loss function utilizing energy-based dynamics via Associative Memories to formulate a new deep clustering method, DCAM, which ties together the representation learning and clustering aspects more intricately in a single objective. Our experiments showcase the advantage of DCAM, producing improved clustering quality for various architecture choices (convolutional, residual or fully-connected) and data modalities (images or text).

</details>


### [80] [A Deep Learning Approach for Automated Skin Lesion Diagnosis with Explainable AI](https://arxiv.org/abs/2601.00964)
*Md. Maksudul Haque,Rahnuma Akter,A S M Ahsanul Sarkar Akib,Abdul Hasib*

Main category: cs.CV

TL;DR: 提出一种结合数据平衡、数据增强、混合EfficientNetV2-L框架和三阶段渐进学习的深度学习架构，用于皮肤病变多分类，在HAM10000数据集上达到91.15%准确率，并利用可解释AI技术增强临床可信度。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球最常见且危险的癌症之一，需要及时精确的诊断，但现有方法在分类准确性和临床可解释性方面存在不足。

Method: 采用高质量数据平衡方法、大规模数据增强、结合通道注意力的混合EfficientNetV2-L框架、三阶段渐进学习策略，并应用Grad-CAM和显著性图等可解释AI技术。

Result: 总准确率91.15%，宏观F1分数85.45%，微观平均AUC 99.33%，在七类皮肤病变分类中均表现优异，尤其在黑色素瘤和黑素细胞痣分类上效果突出。

Conclusion: 所提方法在皮肤病变分类任务中实现了高精度和强可解释性，通过可视化模型决策依据增强了临床可信度，为皮肤癌辅助诊断提供了有效工具。

Abstract: Skin cancer is also one of the most common and dangerous types of cancer in the world that requires timely and precise diagnosis. In this paper, a deep-learning architecture of the multi-class skin lesion classification on the HAM10000 dataset will be described. The system suggested combines high-quality data balancing methods, large-scale data augmentation, hybridized EfficientNetV2-L framework with channel attention, and a three-stage progressive learning approach. Moreover, we also use explainable AI (XAI) techniques such as Grad-CAM and saliency maps to come up with intelligible visual representations of model predictions. Our strategy is with a total accuracy of 91.15 per cent, macro F1 of 85.45\% and micro-average AUC of 99.33\%. The model has shown high performance in all the seven lesion classes with specific high performance of melanoma and melanocytic nevi. In addition to enhancing diagnostic transparency, XAI also helps to find out the visual characteristics that cause the classifications, which enhances clinical trustworthiness.

</details>


### [81] [Few-Shot Video Object Segmentation in X-Ray Angiography Using Local Matching and Spatio-Temporal Consistency Loss](https://arxiv.org/abs/2601.00988)
*Lin Xi,Yingliang Ma,Xiahai Zhuang*

Main category: cs.CV

TL;DR: 提出一种采用局部匹配策略的FSVOS模型，通过方向采样机制实现动态采样区域，结合时空对比学习增强特征一致性，并在新发布的MOSXAV数据集上验证了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频分割方法常依赖计算效率低或硬件特定的实现（如CUDA内核），导致跨设备可移植性差；同时缺乏针对X射线血管造影视频的多目标分割基准数据集。

Method: 1. 基于方向采样的非参数局部匹配机制，动态调整采样区域；2. 监督式时空对比学习方案，增强帧间特征一致性；3. 构建MOSXAV数据集（含精细人工标注）。

Result: 在CADICA、XACV和MOSXAV数据集上的实验表明，该方法在分割精度和泛化能力（可见/未见类别）上均优于当前最先进的视频分割方法。

Conclusion: 该方法提供了更高的灵活性和计算效率，无需重新训练模型，在临床应用中具有广泛潜力，同时发布的MOSXAV数据集填补了该领域基准数据的空白。

Abstract: We introduce a novel FSVOS model that employs a local matching strategy to restrict the search space to the most relevant neighboring pixels. Rather than relying on inefficient standard im2col-like implementations (e.g., spatial convolutions, depthwise convolutions and feature-shifting mechanisms) or hardware-specific CUDA kernels (e.g., deformable and neighborhood attention), which often suffer from limited portability across non-CUDA devices, we reorganize the local sampling process through a direction-based sampling perspective. Specifically, we implement a non-parametric sampling mechanism that enables dynamically varying sampling regions. This approach provides the flexibility to adapt to diverse spatial structures without the computational costs of parametric layers and the need for model retraining. To further enhance feature coherence across frames, we design a supervised spatio-temporal contrastive learning scheme that enforces consistency in feature representations. In addition, we introduce a publicly available benchmark dataset for multi-object segmentation in X-ray angiography videos (MOSXAV), featuring detailed, manually labeled segmentation ground truth. Extensive experiments on the CADICA, XACV, and MOSXAV datasets show that our proposed FSVOS method outperforms current state-of-the-art video segmentation methods in terms of segmentation accuracy and generalization capability (i.e., seen and unseen categories). This work offers enhanced flexibility and potential for a wide range of clinical applications.

</details>


### [82] [UnrealPose: Leveraging Game Engine Kinematics for Large-Scale Synthetic Human Pose Data](https://arxiv.org/abs/2601.00991)
*Joshua Kawaguchi,Saad Manzur,Emily Gao Wang,Maitreyi Sinha,Bryan Vela,Yunxi Wang,Brandon Vela,Wayne B. Hayes*

Main category: cs.CV

TL;DR: 提出UnrealPose-Gen渲染流水线和UnrealPose-1M数据集，通过虚幻引擎5生成高质量合成人体姿态数据，解决真实数据标注成本高和野外数据缺乏真值的问题。


<details>
  <summary>Details</summary>
Motivation: 真实3D人体姿态数据标注昂贵且受限于实验室环境，而野外数据集缺乏准确真值，需要高质量合成数据来弥补这一缺口。

Method: 基于虚幻引擎5和Movie Render Queue构建离线渲染流水线，生成包含3D关节坐标、2D投影关键点、边界框、相机参数等标注的合成数据，并创建包含约100万帧的多样化序列数据集。

Result: 生成了包含8个序列的UnrealPose-1M数据集，涵盖多个场景、动作和视角，并在四个任务（图像到3D姿态、2D关键点检测、2D到3D提升、人物检测/分割）上验证了合成数据的有效性。

Conclusion: 发布的UnrealPose-1M数据集和UnrealPose-Gen流水线为人体姿态研究提供了高质量合成数据支持，尽管资源有限无法生成无限数据，但开源工具允许第三方扩展数据生成。

Abstract: Diverse, accurately labeled 3D human pose data is expensive and studio-bound, while in-the-wild datasets lack known ground truth. We introduce UnrealPose-Gen, an Unreal Engine 5 pipeline built on Movie Render Queue for high-quality offline rendering. Our generated frames include: (i) 3D joints in world and camera coordinates, (ii) 2D projections and COCO-style keypoints with occlusion and joint-visibility flags, (iii) person bounding boxes, and (iv) camera intrinsics and extrinsics. We use UnrealPose-Gen to present UnrealPose-1M, an approximately one million frame corpus comprising eight sequences: five scripted "coherent" sequences spanning five scenes, approximately 40 actions, and five subjects; and three randomized sequences across three scenes, approximately 100 actions, and five subjects, all captured from diverse camera trajectories for broad viewpoint coverage. As a fidelity check, we report real-to-synthetic results on four tasks: image-to-3D pose, 2D keypoint detection, 2D-to-3D lifting, and person detection/segmentation. Though time and resources constrain us from an unlimited dataset, we release the UnrealPose-1M dataset, as well as the UnrealPose-Gen pipeline to support third-party generation of human pose data.

</details>


### [83] [WildIng: A Wildlife Image Invariant Representation Model for Geographical Domain Shift](https://arxiv.org/abs/2601.00993)
*Julian D. Santamaria,Claudia Isaza,Jhony H. Giraldo*

Main category: cs.CV

TL;DR: 提出WildIng模型，通过结合文本描述与图像特征增强野生动物图像识别的地理域泛化能力，解决现有模型在新地理区域性能显著下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的野生动物识别模型在训练地理区域表现良好，但迁移到新地理区域时性能大幅下降（如从非洲到美国准确率从84.77%降至16.17%），主要因模型过度依赖图像背景、光照等易受地理分布变化影响的特征。

Method: 提出WildIng模型，整合文本描述（如物种外观细节）与图像特征，构建对地理域偏移更鲁棒的表示。在美洲和非洲两个数据集上评估，采用BioCLIP等基础模型进行增强。

Result: WildIng在存在地理域偏移的条件下，将BioCLIP等基础模型的准确率提升了30%，显著改善了模型跨地理区域的泛化性能。

Conclusion: 通过融合文本语义信息与视觉特征，WildIng能有效缓解野生动物识别中的地理域偏移问题，为自动化生态监测提供了更可靠的跨区域识别方案。代码与模型已开源。

Abstract: Wildlife monitoring is crucial for studying biodiversity loss and climate change. Camera trap images provide a non-intrusive method for analyzing animal populations and identifying ecological patterns over time. However, manual analysis is time-consuming and resource-intensive. Deep learning, particularly foundation models, has been applied to automate wildlife identification, achieving strong performance when tested on data from the same geographical locations as their training sets. Yet, despite their promise, these models struggle to generalize to new geographical areas, leading to significant performance drops. For example, training an advanced vision-language model, such as CLIP with an adapter, on an African dataset achieves an accuracy of 84.77%. However, this performance drops significantly to 16.17% when the model is tested on an American dataset. This limitation partly arises because existing models rely predominantly on image-based representations, making them sensitive to geographical data distribution shifts, such as variation in background, lighting, and environmental conditions. To address this, we introduce WildIng, a Wildlife image Invariant representation model for geographical domain shift. WildIng integrates text descriptions with image features, creating a more robust representation to geographical domain shifts. By leveraging textual descriptions, our approach captures consistent semantic information, such as detailed descriptions of the appearance of the species, improving generalization across different geographical locations. Experiments show that WildIng enhances the accuracy of foundation models such as BioCLIP by 30% under geographical domain shift conditions. We evaluate WildIng on two datasets collected from different regions, namely America and Africa. The code and models are publicly available at https://github.com/Julian075/CATALOG/tree/WildIng.

</details>


### [84] [DVGBench: Implicit-to-Explicit Visual Grounding Benchmark in UAV Imagery with Large Vision-Language Models](https://arxiv.org/abs/2601.00998)
*Yue Zhou,Jue Chen,Zilun Zhang,Penghui Huang,Ran Ding,Zhentao Zou,PengFei Gao,Yuchen Wei,Ke Li,Xue Yang,Xue Jiang,Hongxin Yang,Jonathan Li*

Main category: cs.CV

TL;DR: 本文提出了无人机视觉定位基准DVGBench和模型DroneVG-R1，通过隐式到显式思维链方法提升无人机场景下的视觉语言模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型主要依赖显式参照表达（如位置、大小、颜色），在需要领域知识的隐式视觉定位任务上表现受限，缺乏专门针对无人机场景的高质量隐式定位基准。

Method: 构建DVGBench数据集（涵盖6类无人机应用场景，包含显式和隐式查询）；设计DroneVG-R1模型，集成隐式到显式思维链（I2E-CoT）与强化学习，将隐式参照转化为显式表达。

Result: 主流模型在隐式视觉定位任务上表现出明显的推理能力局限；DroneVG-R1通过场景专业知识转换降低了定位难度。

Conclusion: 研究揭示了当前视觉语言模型在无人机隐式定位任务上的不足，提出的基准和模型为提升无人机智能体推理能力提供了可行方向。

Abstract: Remote sensing (RS) large vision-language models (LVLMs) have shown strong promise across visual grounding (VG) tasks. However, existing RS VG datasets predominantly rely on explicit referring expressions-such as relative position, relative size, and color cues-thereby constraining performance on implicit VG tasks that require scenario-specific domain knowledge. This article introduces DVGBench, a high-quality implicit VG benchmark for drones, covering six major application scenarios: traffic, disaster, security, sport, social activity, and productive activity. Each object provides both explicit and implicit queries. Based on the dataset, we design DroneVG-R1, an LVLM that integrates the novel Implicit-to-Explicit Chain-of-Thought (I2E-CoT) within a reinforcement learning paradigm. This enables the model to take advantage of scene-specific expertise, converting implicit references into explicit ones and thus reducing grounding difficulty. Finally, an evaluation of mainstream models on both explicit and implicit VG tasks reveals substantial limitations in their reasoning capabilities. These findings provide actionable insights for advancing the reasoning capacity of LVLMs for drone-based agents. The code and datasets will be released at https://github.com/zytx121/DVGBench

</details>


### [85] [Lightweight Channel Attention for Efficient CNNs](https://arxiv.org/abs/2601.01002)
*Prem Babu Kanaparthi,Tulasi Venkata Sri Varshini Padamata*

Main category: cs.CV

TL;DR: 本文通过实证研究比较了SE、ECA和提出的LCA三种通道注意力模块，在ResNet-18和MobileNetV2上验证了LCA在保持参数效率的同时达到竞争性精度。


<details>
  <summary>Details</summary>
Motivation: 尽管注意力机制显著提升了CNN性能，但不同通道注意力设计在效率与精度间的权衡尚未充分探索，特别是在资源受限环境中的部署需求。

Method: 提出轻量通道注意力模块LCA，采用自适应一维卷积与分组操作降低参数量；在CIFAR-10数据集上对比SE、ECA与LCA在ResNet-18和MobileNetV2中的性能，并综合评估FLOPs、参数量和GPU延迟。

Result: LCA在ResNet-18上达到94.68%准确率，在MobileNetV2上达到93.10%，与ECA参数量相当且推理延迟较低，在资源受限场景中展现优势。

Conclusion: LCA通过轻量化设计实现了效率与精度的平衡，为资源受限环境下部署注意力增强的CNN提供了实用方案。

Abstract: Attention mechanisms have become integral to modern convolutional neural networks (CNNs), delivering notable performance improvements with minimal computational overhead. However, the efficiency accuracy trade off of different channel attention designs remains underexplored. This work presents an empirical study comparing Squeeze and Excitation (SE), Efficient Channel Attention (ECA), and a proposed Lite Channel Attention (LCA) module across ResNet 18 and MobileNetV2 architectures on CIFAR 10. LCA employs adaptive one dimensional convolutions with grouped operations to reduce parameter usage while preserving effective attention behavior. Experimental results show that LCA achieves competitive accuracy, reaching 94.68 percent on ResNet 18 and 93.10 percent on MobileNetV2, while matching ECA in parameter efficiency and maintaining favorable inference latency. Comprehensive benchmarks including FLOPs, parameter counts, and GPU latency measurements are provided, offering practical insights for deploying attention enhanced CNNs in resource constrained environments.

</details>


### [86] [Decoupling Amplitude and Phase Attention in Frequency Domain for RGB-Event based Visual Object Tracking](https://arxiv.org/abs/2601.01022)
*Shiao Wang,Xiao Wang,Haonan Zhao,Jiarui Xu,Bo Jiang,Lin Zhu,Xin Zhao,Yonghong Tian,Jin Tang*

Main category: cs.CV

TL;DR: 提出了一种新颖的RGB-Event目标跟踪框架，通过在频域进行早期融合，并利用事件相机的高动态范围和运动敏感特性，有效减少计算开销并提升跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-Event目标跟踪方法主要依赖传统特征级融合，未能充分利用事件相机的高动态范围和运动敏感优势，且对低信息区域处理效率低下，导致不必要的计算开销。

Method: 1. 通过快速傅里叶变换将RGB和事件模态从空间域转换到频域，解耦振幅和相位分量；2. 通过振幅和相位注意力选择性融合高频事件信息到RGB模态；3. 设计运动引导的空间稀疏化模块，利用事件相机的运动敏感性过滤低信息区域；4. 将稀疏的目标相关特征输入骨干网络进行学习，由跟踪头预测最终目标位置。

Result: 在FE108、FELT和COESOT三个广泛使用的RGB-Event跟踪基准数据集上的大量实验表明，该方法具有高性能和高效率。

Conclusion: 所提出的频域早期融合框架能够有效聚合事件模态的高频信息，同时显著减少骨干网络计算量，为RGB-Event视觉目标跟踪提供了更高效的解决方案。

Abstract: Existing RGB-Event visual object tracking approaches primarily rely on conventional feature-level fusion, failing to fully exploit the unique advantages of event cameras. In particular, the high dynamic range and motion-sensitive nature of event cameras are often overlooked, while low-information regions are processed uniformly, leading to unnecessary computational overhead for the backbone network. To address these issues, we propose a novel tracking framework that performs early fusion in the frequency domain, enabling effective aggregation of high-frequency information from the event modality. Specifically, RGB and event modalities are transformed from the spatial domain to the frequency domain via the Fast Fourier Transform, with their amplitude and phase components decoupled. High-frequency event information is selectively fused into RGB modality through amplitude and phase attention, enhancing feature representation while substantially reducing backbone computation. In addition, a motion-guided spatial sparsification module leverages the motion-sensitive nature of event cameras to capture the relationship between target motion cues and spatial probability distribution, filtering out low-information regions and enhancing target-relevant features. Finally, a sparse set of target-relevant features is fed into the backbone network for learning, and the tracking head predicts the final target position. Extensive experiments on three widely used RGB-Event tracking benchmark datasets, including FE108, FELT, and COESOT, demonstrate the high performance and efficiency of our method. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvTracking

</details>


### [87] [ITSELF: Attention Guided Fine-Grained Alignment for Vision-Language Retrieval](https://arxiv.org/abs/2601.01024)
*Tien-Huy Nguyen,Huu-Loc Tran,Thanh Duc Ngo*

Main category: cs.CV

TL;DR: 本文提出ITSELF框架，通过注意力引导的隐式局部对齐方法，改进基于文本的人物搜索任务，无需额外监督即可学习细粒度图像-文本对应关系，在多个基准测试中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在文本人物搜索中常依赖局部对齐方法，但易受捷径学习和虚假相关影响，导致错位；同时注入先验知识可能扭曲模态内部结构。研究发现编码器注意力在训练早期就能提供空间精确证据，这启发了本工作。

Method: 提出ITSELF框架，核心包括：1) GRAB模块，将模型自身注意力转换为高显著性令牌库并应用局部目标；2) MARS模块，跨层聚合注意力并进行多样性感知的top-k选择；3) ATS模块，在训练中从粗到细调度令牌保留预算。

Result: 在三个广泛使用的文本人物搜索基准测试中实现了最先进的性能，并展现出强大的跨数据集泛化能力，证实了方法的有效性和鲁棒性。

Conclusion: ITSELF框架通过注意力引导的隐式局部对齐，有效解决了文本人物搜索中的错位问题，无需额外先验监督即可学习细粒度对应关系，为视觉语言模型的应用提供了新思路。

Abstract: Vision Language Models (VLMs) have rapidly advanced and show strong promise for text-based person search (TBPS), a task that requires capturing fine-grained relationships between images and text to distinguish individuals. Previous methods address these challenges through local alignment, yet they are often prone to shortcut learning and spurious correlations, yielding misalignment. Moreover, injecting prior knowledge can distort intra-modality structure. Motivated by our finding that encoder attention surfaces spatially precise evidence from the earliest training epochs, and to alleviate these issues, we introduceITSELF, an attention-guided framework for implicit local alignment. At its core, Guided Representation with Attentive Bank (GRAB) converts the model's own attention into an Attentive Bank of high-saliency tokens and applies local objectives on this bank, learning fine-grained correspondences without extra supervision. To make the selection reliable and non-redundant, we introduce Multi-Layer Attention for Robust Selection (MARS), which aggregates attention across layers and performs diversity-aware top-k selection; and Adaptive Token Scheduler (ATS), which schedules the retention budget from coarse to fine over training, preserving context early while progressively focusing on discriminative details. Extensive experiments on three widely used TBPS benchmarks showstate-of-the-art performance and strong cross-dataset generalization, confirming the effectiveness and robustness of our approach without additional prior supervision. Our project is publicly available at https://trhuuloc.github.io/itself

</details>


### [88] [Enhanced Leukemic Cell Classification Using Attention-Based CNN and Data Augmentation](https://arxiv.org/abs/2601.01026)
*Douglas Costa Braga,Daniel Oliveira Dantas*

Main category: cs.CV

TL;DR: 提出一种可复现的深度学习流程，用于白血病细胞分类，结合注意力机制与高效网络架构，在C-NMC 2019数据集上取得97.89%的F1分数和准确率，参数量比VGG16减少89%。


<details>
  <summary>Details</summary>
Motivation: 急性淋巴细胞白血病是最常见的儿童癌症，传统显微镜诊断存在观察者间差异和时间限制，需要自动化、可解释且高效的计算方法辅助临床诊断。

Method: 采用结合EfficientNetV2-B3与Squeeze-and-Excitation注意力机制的卷积神经网络，使用数据增强、焦点损失函数处理类别不平衡，并按患者划分数据以确保评估鲁棒性，通过100次蒙特卡洛实验进行统计验证。

Result: 在C-NMC 2019数据集（62名患者的12,528张图像）测试集上达到97.89%的F1分数和准确率，显著优于基线方法（p<0.001），参数量仅15.2M（比VGG16少89%），注意力机制可提供诊断相关细胞特征的可视化解释。

Conclusion: 基于注意力的现代架构能够提升白血病细胞分类性能，同时保持适合临床部署的计算效率，为医学图像分析提供了可复现、鲁棒且可解释的深度学习流程。

Abstract: We present a reproducible deep learning pipeline for leukemic cell classification, focusing on system architecture, experimental robustness, and software design choices for medical image analysis. Acute lymphoblastic leukemia (ALL) is the most common childhood cancer, requiring expert microscopic diagnosis that suffers from inter-observer variability and time constraints. The proposed system integrates an attention-based convolutional neural network combining EfficientNetV2-B3 with Squeeze-and-Excitation mechanisms for automated ALL cell classification. Our approach employs comprehensive data augmentation, focal loss for class imbalance, and patient-wise data splitting to ensure robust and reproducible evaluation. On the C-NMC 2019 dataset (12,528 original images from 62 patients), the system achieves a 97.89% F1-score and 97.89% accuracy on the test set, with statistical validation through 100-iteration Monte Carlo experiments confirming significant improvements (p < 0.001) over baseline methods. The proposed pipeline outperforms existing approaches by up to 4.67% while using 89% fewer parameters than VGG16 (15.2M vs. 138M). The attention mechanism provides interpretable visualizations of diagnostically relevant cellular features, demonstrating that modern attention-based architectures can improve leukemic cell classification while maintaining computational efficiency suitable for clinical deployment.

</details>


### [89] [Mono3DV: Monocular 3D Object Detection with 3D-Aware Bipartite Matching and Variational Query DeNoising](https://arxiv.org/abs/2601.01036)
*Kiet Dang Vu,Trung Thai Tran,Kien Nguyen Do Trung,Duc Dung Nguyen*

Main category: cs.CV

TL;DR: 提出Mono3DV框架，通过3D感知二分匹配、3D去噪方案和变分查询去噪机制，解决单目3D检测中因2D匹配导致的3D属性抑制问题，在KITTI基准上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有DETR类单目3D检测方法在二分匹配过程中仅使用2D信息，忽略了3D属性，导致高质量的3D预测可能被不匹配的2D标准抑制，影响检测性能。

Method: 1. 3D感知二分匹配策略：将3D几何信息直接融入匹配代价计算；2. 3D去噪训练方案：稳定整合3D属性时的训练过程；3. 变分查询去噪机制：解决传统去噪方法的梯度消失问题。

Result: 在未使用外部数据的情况下，于KITTI 3D物体检测基准上实现了最先进的性能。

Conclusion: Mono3DV通过将3D信息整合到匹配和训练过程中，有效解决了单目3D检测中的匹配错位和训练不稳定问题，显著提升了检测精度。

Abstract: While DETR-like architectures have demonstrated significant potential for monocular 3D object detection, they are often hindered by a critical limitation: the exclusion of 3D attributes from the bipartite matching process. This exclusion arises from the inherent ill-posed nature of 3D estimation from monocular image, which introduces instability during training. Consequently, high-quality 3D predictions can be erroneously suppressed by 2D-only matching criteria, leading to suboptimal results. To address this, we propose Mono3DV, a novel Transformer-based framework. Our approach introduces three key innovations. First, we develop a 3D-Aware Bipartite Matching strategy that directly incorporates 3D geometric information into the matching cost, resolving the misalignment caused by purely 2D criteria. Second, it is important to stabilize the Bipartite Matching to resolve the instability occurring when integrating 3D attributes. Therefore, we propose 3D-DeNoising scheme in the training phase. Finally, recognizing the gradient vanishing issue associated with conventional denoising techniques, we propose a novel Variational Query DeNoising mechanism to overcome this limitation, which significantly enhances model performance. Without leveraging any external data, our method achieves state-of-the-art results on the KITTI 3D object detection benchmark.

</details>


### [90] [Deepfake Detection with Multi-Artifact Subspace Fine-Tuning and Selective Layer Masking](https://arxiv.org/abs/2601.01041)
*Xiang Zhang,Wenliang Weng,Daoyong Fu,Ziqiang Li,Zhangjie Fu*

Main category: cs.CV

TL;DR: 本文提出了一种基于多伪影子空间和选择性层掩码的深度伪造检测方法，通过解耦语义表示与伪影表示，提升跨数据集场景下的泛化鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测在跨数据集和现实复杂场景中面临挑战，主要原因是不同伪造方法引入的伪影分布差异大，而预训练模型在适应新伪影时容易破坏原有语义结构。现有方法难以同时有效建模多样伪影并保持语义稳定性。

Method: 提出MASM方法：1) 对模型权重进行奇异值分解，划分为稳定的语义主子空间和多个可学习的伪影子空间；2) 引入选择性层掩码策略，根据各伪影子空间学习状态自适应调节网络层更新；3) 施加正交性约束和谱一致性约束，使多个伪影子空间学习互补且多样的伪影表示。

Result: 该方法实现了语义表示与伪影表示的解耦建模，在保持通用语义子空间的同时，能够学习多样化的伪造伪影模式，有效抑制了对单一伪造特征的过拟合。

Conclusion: MASM方法通过显式解耦语义与伪影表示、约束伪影子空间拟合强度，显著提升了深度伪造检测在跨数据集场景下的泛化鲁棒性，为解决复杂现实场景中的检测问题提供了新思路。

Abstract: Deepfake detection still faces significant challenges in cross-dataset and real-world complex scenarios. The root cause lies in the high diversity of artifact distributions introduced by different forgery methods, while pretrained models tend to disrupt their original general semantic structures when adapting to new artifacts. Existing approaches usually rely on indiscriminate global parameter updates or introduce additional supervision signals, making it difficult to effectively model diverse forgery artifacts while preserving semantic stability. To address these issues, this paper proposes a deepfake detection method based on Multi-Artifact Subspaces and selective layer masks (MASM), which explicitly decouples semantic representations from artifact representations and constrains the fitting strength of artifact subspaces, thereby improving generalization robustness in cross-dataset scenarios. Specifically, MASM applies singular value decomposition to model weights, partitioning pretrained weights into a stable semantic principal subspace and multiple learnable artifact subspaces. This design enables decoupled modeling of different forgery artifact patterns while preserving the general semantic subspace. On this basis, a selective layer mask strategy is introduced to adaptively regulate the update behavior of corresponding network layers according to the learning state of each artifact subspace, suppressing overfitting to any single forgery characteristic. Furthermore, orthogonality constraints and spectral consistency constraints are imposed to jointly regularize multiple artifact subspaces, guiding them to learn complementary and diverse artifact representations while maintaining a stable overall spectral structure.

</details>


### [91] [Evaluating transfer learning strategies for improving dairy cattle body weight prediction in small farms using depth-image and point-cloud data](https://arxiv.org/abs/2601.01044)
*Jin Wang,Angelo De Castro,Yuxi Zhang,Lucas Basolli Borsatto,Yuechen Guo,Victoria Bastos Primo,Ana Beatriz Montevecchio Bernardino,Gota Morota,Ricardo C Chebel,Haipeng Yu*

Main category: cs.CV

TL;DR: 本研究评估了迁移学习在奶牛体重预测中的应用，比较了深度图像和点云两种数据模态的性能。结果表明迁移学习能显著提升小规模农场的预测效果，且两种模态表现相当。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉在奶牛监测中具有自动化、非侵入性和可扩展的优势，但迁移学习在畜牧业应用中的效果和优化策略尚不明确，且深度图像与点云数据在奶牛体重预测中的直接比较研究有限。

Method: 从大、中、小三个农场分别采集1,201、215和58头奶牛的俯视深度图像和点云数据，使用ConvNeXt和MobileViT处理深度图像，PointNet和DGCNN处理点云数据，评估迁移学习、单源学习和联合学习三种实验设计。

Result: 迁移学习在所有四种模型上均显著提升了小农场的体重预测性能，优于单源学习，且效果与联合学习相当或更好；深度图像与点云模型之间未发现一致的性能差异。

Conclusion: 迁移学习适用于数据共享受限的小农场预测场景，仅需预训练模型权重而非原始数据；预训练表征能有效泛化至不同成像条件和牛群，为实际应用提供了可行方案。

Abstract: Computer vision provides automated, non-invasive, and scalable tools for monitoring dairy cattle, thereby supporting management, health assessment, and phenotypic data collection. Although transfer learning is commonly used for predicting body weight from images, its effectiveness and optimal fine-tuning strategies remain poorly understood in livestock applications, particularly beyond the use of pretrained ImageNet or COCO weights. In addition, while both depth images and three-dimensional point-cloud data have been explored for body weight prediction, direct comparisons of these two modalities in dairy cattle are limited. Therefore, the objectives of this study were to 1) evaluate whether transfer learning from a large farm enhances body weight prediction on a small farm with limited data, and 2) compare the predictive performance of depth-image- and point-cloud-based approaches under three experimental designs. Top-view depth images and point-cloud data were collected from 1,201, 215, and 58 cows at large, medium, and small dairy farms, respectively. Four deep learning models were evaluated: ConvNeXt and MobileViT for depth images, and PointNet and DGCNN for point clouds. Transfer learning markedly improved body weight prediction on the small farm across all four models, outperforming single-source learning and achieving gains comparable to or greater than joint learning. These results indicate that pretrained representations generalize well across farms with differing imaging conditions and dairy cattle populations. No consistent performance difference was observed between depth-image- and point-cloud-based models. Overall, these findings suggest that transfer learning is well suited for small farm prediction scenarios where cross-farm data sharing is limited by privacy, logistical, or policy constraints, as it requires access only to pretrained model weights rather than raw data.

</details>


### [92] [EgoGrasp: World-Space Hand-Object Interaction Estimation from Egocentric Videos](https://arxiv.org/abs/2601.01050)
*Hongming Fu,Wenjia Wang,Xiaozhen Qiao,Shuo Yang,Zheng Liu,Bo Zhao*

Main category: cs.CV

TL;DR: 提出EgoGrasp方法，首次从动态单目第一人称视频中重建世界坐标系下的手-物交互，通过多阶段框架解决现有方法在时序建模和全局一致性上的不足。


<details>
  <summary>Details</summary>
Motivation: 准确的世界坐标系手-物交互重建对理解人类行为、具身智能和虚拟现实应用至关重要。现有方法局限于单图像或相机坐标系，无法建模时序动态或全局轨迹，且在剧烈相机运动和遮挡下性能受限。

Method: 提出多阶段框架：基于新型空间智能模型的鲁棒预处理流程、基于解耦扩散模型的全身手-物交互先验模型（支持多对象且无需模板）、多目标测试时优化范式。

Result: 实验证明该方法在世界坐标系手-物交互重建任务上达到最先进性能。

Conclusion: EgoGrasp首次实现了从动态单目第一人称视频中重建世界坐标系手-物交互，通过结合空间智能模型、扩散先验和优化策略，有效解决了剧烈运动与遮挡下的重建挑战。

Abstract: We propose EgoGrasp, the first method to reconstruct world-space hand-object interactions (W-HOI) from egocentric monocular videos with dynamic cameras in the wild. Accurate W-HOI reconstruction is critical for understanding human behavior and enabling applications in embodied intelligence and virtual reality. However, existing hand-object interactions (HOI) methods are limited to single images or camera coordinates, failing to model temporal dynamics or consistent global trajectories. Some recent approaches attempt world-space hand estimation but overlook object poses and HOI constraints. Their performance also suffers under severe camera motion and frequent occlusions common in egocentric in-the-wild videos. To address these challenges, we introduce a multi-stage framework with a robust pre-process pipeline built on newly developed spatial intelligence models, a whole-body HOI prior model based on decoupled diffusion models, and a multi-objective test-time optimization paradigm. Our HOI prior model is template-free and scalable to multiple objects. In experiments, we prove our method achieving state-of-the-art performance in W-HOI reconstruction.

</details>


### [93] [Enhancing Histopathological Image Classification via Integrated HOG and Deep Features with Robust Noise Performance](https://arxiv.org/abs/2601.01056)
*Ifeanyi Ezuma,Ugochukwu Ugwu*

Main category: cs.CV

TL;DR: 本研究评估了机器学习和深度学习模型在LC25000组织病理学图像数据集上的分类性能，发现使用InceptionResNet-v2提取的深度特征训练的模型表现最佳，尤其在噪声环境下展现出更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 数字病理学时代使得自动化图像分析在临床实践中变得至关重要，需要评估不同模型在组织病理学图像分类中的性能，特别是在噪声环境下的鲁棒性。

Method: 使用微调的InceptionResNet-v2网络作为分类器和特征提取器，结合HOG特征，在LC25000数据集上训练多种机器学习模型，并在不同信噪比条件下评估模型性能。

Result: 微调InceptionResNet-v2的分类准确率为96.01%，平均AUC为96.8%；使用其深度特征训练的神经网络模型达到99.99%的AUC和99.84%的准确率；在噪声环境下，基于深度特征的模型（特别是GBM和KNN）表现出更强的鲁棒性。

Conclusion: 基于深度特征的模型在组织病理学图像分类中表现优异，尤其在噪声环境下具有更好的鲁棒性，为临床自动化图像分析提供了有效解决方案。

Abstract: The era of digital pathology has advanced histopathological examinations, making automated image analysis essential in clinical practice. This study evaluates the classification performance of machine learning and deep learning models on the LC25000 dataset, which includes five classes of histopathological images. We used the fine-tuned InceptionResNet-v2 network both as a classifier and for feature extraction. Our results show that the fine-tuned InceptionResNet-v2 achieved a classification accuracy of 96.01\% and an average AUC of 96.8\%. Models trained on deep features from InceptionResNet-v2 outperformed those using only the pre-trained network, with the Neural Network model achieving an AUC of 99.99\% and accuracy of 99.84\%. Evaluating model robustness under varying SNR conditions revealed that models using deep features exhibited greater resilience, particularly GBM and KNN. The combination of HOG and deep features showed enhanced performance, however, less so in noisy environments.

</details>


### [94] [Real-Time LiDAR Point Cloud Densification for Low-Latency Spatial Data Transmission](https://arxiv.org/abs/2601.01210)
*Kazuhiko Murasaki,Shunsuke Konagai,Masakatsu Aoki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

TL;DR: 提出一种高速LiDAR点云稠密化方法，通过结合多LiDAR输入与高分辨率彩色图像，使用联合双边滤波CNN架构实现实时（30fps）全高清稠密深度图生成。


<details>
  <summary>Details</summary>
Motivation: 沉浸式远程呈现系统需要低延迟空间传输，但现有LiDAR传感器虽能实时捕获3D场景，却只能产生稀疏点云，无法满足稠密3D场景的实时处理需求。

Method: 采用多LiDAR传感器与高分辨率彩色图像融合，通过卷积神经网络架构实现联合双边滤波策略，进行实时深度补全。

Result: 该方法能以30fps速度生成全高清稠密深度图，比现有基于训练的深度补全方法快15倍以上，且产生的稠密点云几何精度高，无多视角不一致或重影伪影。

Conclusion: 所提方法能有效解决LiDAR点云稀疏性问题，在保持实时性能的同时实现高质量深度补全，为沉浸式远程呈现系统提供了可行的低延迟3D场景重建方案。

Abstract: To realize low-latency spatial transmission system for immersive telepresence, there are two major problems: capturing dynamic 3D scene densely and processing them in real time. LiDAR sensors capture 3D in real time, but produce sparce point clouds. Therefore, this paper presents a high-speed LiDAR point cloud densification method to generate dense 3D scene with minimal latency, addressing the need for on-the-fly depth completion while maintaining real-time performance. Our approach combines multiple LiDAR inputs with high-resolution color images and applies a joint bilateral filtering strategy implemented through a convolutional neural network architecture. Experiments demonstrate that the proposed method produces dense depth maps at full HD resolution in real time (30 fps), which is over 15x faster than a recent training-based depth completion approach. The resulting dense point clouds exhibit accurate geometry without multiview inconsistencies or ghosting artifacts.

</details>


### [95] [Luminark: Training-free, Probabilistically-Certified Watermarking for General Vision Generative Models](https://arxiv.org/abs/2601.01085)
*Jiayi Xu,Zhang Zhang,Yuanrui Zhang,Ruitao Chen,Yixian Xu,Tianyu He,Di He*

Main category: cs.CV

TL;DR: 提出Luminark，一种无需训练、概率认证的视觉生成模型水印方法，基于亮度统计实现通用水印嵌入与检测


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成模型水印方法缺乏通用性、需要重新训练模型，且难以提供可证明的检测保证

Method: 基于块级亮度统计定义水印，预定义二值模式与阈值；利用引导技术作为即插即用机制实现水印注入；通过统计分析控制误检率

Result: 在扩散、自回归和混合等9个模型上验证，Luminark均表现出高检测准确率、对图像变换的强鲁棒性及良好的视觉质量

Conclusion: Luminark为视觉生成模型提供了一种通用、可证明安全且不损害图像质量的水印解决方案

Abstract: In this paper, we introduce \emph{Luminark}, a training-free and probabilistically-certified watermarking method for general vision generative models. Our approach is built upon a novel watermark definition that leverages patch-level luminance statistics. Specifically, the service provider predefines a binary pattern together with corresponding patch-level thresholds. To detect a watermark in a given image, we evaluate whether the luminance of each patch surpasses its threshold and then verify whether the resulting binary pattern aligns with the target one. A simple statistical analysis demonstrates that the false positive rate of the proposed method can be effectively controlled, thereby ensuring certified detection. To enable seamless watermark injection across different paradigms, we leverage the widely adopted guidance technique as a plug-and-play mechanism and develop the \emph{watermark guidance}. This design enables Luminark to achieve generality across state-of-the-art generative models without compromising image quality. Empirically, we evaluate our approach on nine models spanning diffusion, autoregressive, and hybrid frameworks. Across all evaluations, Luminark consistently demonstrates high detection accuracy, strong robustness against common image transformations, and good performance on visual quality.

</details>


### [96] [DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving](https://arxiv.org/abs/2601.01528)
*Yang Zhou,Hao Shao,Letian Wang,Zhuofan Zong,Hongsheng Li,Steven L. Waslander*

Main category: cs.CV

TL;DR: 提出了首个综合性驾驶世界模型基准测试DrivingGen，包含多样化数据集和评估指标，揭示了现有模型在视觉质量与物理真实性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 当前驾驶世界模型缺乏严谨的基准测试，现有评估方法存在局限：通用视频指标忽略安全关键因素、轨迹合理性未量化、时空一致性被忽视、可控性未考虑，且数据集多样性不足。

Method: 构建DrivingGen基准，整合来自驾驶数据集和互联网视频的多样化评估数据集（涵盖不同天气、时段、地域和复杂场景），并提出一套联合评估视觉真实性、轨迹合理性、时间一致性和可控性的新指标。

Result: 对14个先进模型的测试表明：通用模型视觉质量更好但违反物理规律，驾驶专用模型运动更真实但视觉质量较差，揭示了模型性能的明显权衡。

Conclusion: DrivingGen提供了统一的评估框架，有助于推动可靠、可控、可部署的驾驶世界模型发展，支持可扩展的仿真、规划与数据驱动决策。

Abstract: Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.

</details>


### [97] [600k-ks-ocr: a large-scale synthetic dataset for optical character recognition in kashmiri script](https://arxiv.org/abs/2601.01088)
*Haq Nawaz Malik*

Main category: cs.CV

TL;DR: 本文介绍了600K-KS-OCR数据集，一个包含约60.2万个克什米尔语单词级分割图像的大规模合成语料库，用于训练和评估针对克什米尔文字的OCR系统。


<details>
  <summary>Details</summary>
Motivation: 克什米尔语是一种濒危的达尔德语，使用改良的波斯-阿拉伯文字系统，约有700万人使用，但缺乏足够的OCR训练资源。该研究旨在填补这一资源空白。

Method: 数据集生成方法包括：使用三种传统克什米尔字体渲染图像（256x64像素），应用全面的数据增强模拟真实文档退化，以及使用多样化的背景纹理以增强模型鲁棒性。

Result: 创建了包含约60.2万个单词级分割图像的数据集，提供多种格式的真实转录文本，兼容CRNN、TrOCR和通用机器学习流程。数据集分为10个压缩档案，总计约10.6GB，采用CC-BY-4.0许可发布。

Conclusion: 该数据集为低资源语言光学字符识别研究提供了重要资源，有助于促进克什米尔语OCR技术的发展和应用。

Abstract: This technical report presents the 600K-KS-OCR Dataset, a large-scale synthetic corpus comprising approximately 602,000 word-level segmented images designed for training and evaluating optical character recognition systems targeting Kashmiri script. The dataset addresses a critical resource gap for Kashmiri, an endangered Dardic language utilizing a modified Perso-Arabic writing system spoken by approximately seven million people. Each image is rendered at 256x64 pixels with corresponding ground-truth transcriptions provided in multiple formats compatible with CRNN, TrOCR, and generalpurpose machine learning pipelines. The generation methodology incorporates three traditional Kashmiri typefaces, comprehensive data augmentation simulating real-world document degradation, and diverse background textures to enhance model robustness. The dataset is distributed across ten partitioned archives totaling approximately 10.6 GB and is released under the CC-BY-4.0 license to facilitate research in low-resource language optical character recognition.

</details>


### [98] [VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis](https://arxiv.org/abs/2601.01989)
*Aly R. Elkammar,Karim M. Gamaleldin,Catherine M. Elias*

Main category: cs.CV

TL;DR: 提出基于Transformer/视频视觉Transformer的多模态算法用于行人意图预测，在JAAD数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 行人意图预测是实现L3到L4级自动驾驶的关键技术，需综合考虑多种因素提升道路安全。

Method: 采用不同规模的Transformer/视频视觉Transformer架构，融合多模态数据，并通过大量消融实验验证设计选择。

Result: 在JAAD数据集上取得SOTA性能，在准确率、AUC和F1分数等指标上超越现有方法。

Conclusion: 所提算法能有效预测行人意图，为高级别自动驾驶系统提供关键技术支撑。

Abstract: Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.

</details>


### [99] [Real-Time Lane Detection via Efficient Feature Alignment and Covariance Optimization for Low-Power Embedded Systems](https://arxiv.org/abs/2601.01696)
*Yian Liu,Xiong Wang,Ping Xu,Lei Zhu,Ming Yan,Linyun Xue*

Main category: cs.CV

TL;DR: 提出协方差分布优化（CDO）模块，用于提升嵌入式系统中实时车道线检测的准确性，无需增加计算复杂度，易于集成到现有模型。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统中实时车道线检测面临视觉信号稀疏、计算资源有限和功耗约束的挑战，缺乏适用于低功耗环境的通用优化技术。

Method: 设计CDO模块，通过对齐车道特征分布与真实标签优化特征表示；在六种模型（涵盖分割、锚点和曲线三类方法）和三个数据集（CULane、TuSimple、LLAMAS）上评估。

Result: CDO模块使检测准确率提升0.01%至1.5%，且不增加计算负担，可直接集成到现有模型结构并利用原有参数进行持续训练。

Conclusion: CDO模块为嵌入式车道检测系统提供了高效、低功耗且灵活的优化方案，显著提升性能并保持实时性。

Abstract: Real-time lane detection in embedded systems encounters significant challenges due to subtle and sparse visual signals in RGB images, often constrained by limited computational resources and power consumption. Although deep learning models for lane detection categorized into segmentation-based, anchor-based, and curve-based methods there remains a scarcity of universally applicable optimization techniques tailored for low-power embedded environments. To overcome this, we propose an innovative Covariance Distribution Optimization (CDO) module specifically designed for efficient, real-time applications. The CDO module aligns lane feature distributions closely with ground-truth labels, significantly enhancing detection accuracy without increasing computational complexity. Evaluations were conducted on six diverse models across all three method categories, including two optimized for real-time applications and four state-of-the-art (SOTA) models, tested comprehensively on three major datasets: CULane, TuSimple, and LLAMAS. Experimental results demonstrate accuracy improvements ranging from 0.01% to 1.5%. The proposed CDO module is characterized by ease of integration into existing systems without structural modifications and utilizes existing model parameters to facilitate ongoing training, thus offering substantial benefits in performance, power efficiency, and operational flexibility in embedded systems.

</details>


### [100] [NarrativeTrack: Evaluating Video Language Models Beyond the Frame](https://arxiv.org/abs/2601.01095)
*Hyeonjeong Ha,Jinjin Ge,Bo Feng,Kaixin Ma,Gargi Chakraborty*

Main category: cs.CV

TL;DR: 提出了首个评估多模态大语言模型视频叙事理解能力的基准NarrativeTrack，通过实体中心推理框架CRP揭示模型在感知基础与时间推理间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在视频时序叙事理解方面能力不足，缺乏细粒度实体跟踪和连贯性评估的基准，需要系统评估模型对动态视觉场景中实体演化的理解能力。

Method: 1) 构建NarrativeTrack基准，通过自动化实体中心管道提取时序实体表示；2) 设计组合推理进展框架，从实体存在、实体变化到实体模糊性三个维度渐进评估叙事复杂度；3) 对比开源通用MLLMs与视频专用MLLMs的表现。

Result: 1) 现有MLLMs难以在视觉转换和时序动态中稳健跟踪实体，常出现上下文偏移下的身份幻觉；2) 通用MLLMs感知基础强但时间连贯性弱，视频专用MLLMs能捕捉时序上下文但易幻觉实体语境；3) 揭示了感知基础与时间推理之间的根本权衡。

Conclusion: 叙事理解需要感知基础与时间推理的整合，NarrativeTrack为诊断和推进MLLMs的时序叙事理解提供了首个系统框架，指明了未来研究方向。

Abstract: Multimodal large language models (MLLMs) have achieved impressive progress in vision-language reasoning, yet their ability to understand temporally unfolding narratives in videos remains underexplored. True narrative understanding requires grounding who is doing what, when, and where, maintaining coherent entity representations across dynamic visual and temporal contexts. We introduce NarrativeTrack, the first benchmark to evaluate narrative understanding in MLLMs through fine-grained entity-centric reasoning. Unlike existing benchmarks limited to short clips or coarse scene-level semantics, we decompose videos into constituent entities and examine their continuity via a Compositional Reasoning Progression (CRP), a structured evaluation framework that progressively increases narrative complexity across three dimensions: entity existence, entity changes, and entity ambiguity. CRP challenges models to advance from temporal persistence to contextual evolution and fine-grained perceptual reasoning. A fully automated entity-centric pipeline enables scalable extraction of temporally grounded entity representations, providing the foundation for CRP. Evaluations of state-of-the-art MLLMs reveal that models fail to robustly track entities across visual transitions and temporal dynamics, often hallucinating identity under context shifts. Open-source general-purpose MLLMs exhibit strong perceptual grounding but weak temporal coherence, while video-specific MLLMs capture temporal context yet hallucinate entity's contexts. These findings uncover a fundamental trade-off between perceptual grounding and temporal reasoning, indicating that narrative understanding emerges only from their integration. NarrativeTrack provides the first systematic framework to diagnose and advance temporally grounded narrative comprehension in MLLMs.

</details>


### [101] [Evolving CNN Architectures: From Custom Designs to Deep Residual Models for Diverse Image Classification and Detection Tasks](https://arxiv.org/abs/2601.01099)
*Mahmudul Hasan,Mabsur Fatin Bin Hossain*

Main category: cs.CV

TL;DR: 本文比较了自定义CNN架构与预训练/迁移学习模型在五个真实图像数据集上的性能，分析了网络深度、残差连接等架构因素对分类和定位任务的影响，并为不同复杂度的任务提供了网络选择指导。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索不同CNN架构（自定义vs预训练/迁移学习）在不同复杂度图像任务（二分类、细粒度多分类、目标检测）中的表现差异，为实际应用中的网络选择提供依据。

Method: 使用五个真实图像数据集，涵盖二分类、细粒度多分类和目标检测任务；对比自定义CNN架构与广泛使用的预训练/迁移学习模型；分析网络深度、残差连接和特征提取策略的影响；将自定义架构扩展到目标检测任务中。

Result: 深度CNN架构在细粒度多分类数据集上表现显著更优；轻量级预训练/迁移学习模型在简单二分类任务中仍非常有效；自定义架构可成功应用于目标检测任务（如识别非法三轮车）。

Conclusion: 任务复杂度决定最佳网络选择：复杂任务需要深度定制架构，简单任务可用轻量预训练模型。研究为基于任务需求和资源限制的网络设计提供了实用指导。

Abstract: This paper presents a comparative study of a custom convolutional neural network (CNN) architecture against widely used pretrained and transfer learning CNN models across five real-world image datasets. The datasets span binary classification, fine-grained multiclass recognition, and object detection scenarios. We analyze how architectural factors, such as network depth, residual connections, and feature extraction strategies, influence classification and localization performance. The results show that deeper CNN architectures provide substantial performance gains on fine-grained multiclass datasets, while lightweight pretrained and transfer learning models remain highly effective for simpler binary classification tasks. Additionally, we extend the proposed architecture to an object detection setting, demonstrating its adaptability in identifying unauthorized auto-rickshaws in real-world traffic scenes. Building upon a systematic analysis of custom CNN architectures alongside pretrained and transfer learning models, this study provides practical guidance for selecting suitable network designs based on task complexity and resource constraints.

</details>


### [102] [Cross-Layer Attentive Feature Upsampling for Low-latency Semantic Segmentation](https://arxiv.org/abs/2601.01167)
*Tianheng Cheng,Xinggang Wang,Junchao Liao,Wenyu Liu*

Main category: cs.CV

TL;DR: 提出了一种新的引导注意力插值方法，用于高效语义分割，在保持低延迟的同时实现高精度。


<details>
  <summary>Details</summary>
Motivation: 现有坐标引导的低分辨率特征插值方法（如双线性插值）存在特征错位和上下文信息不足的问题，且丰富高分辨率特征的语义需要高计算负担，难以满足低延迟推理需求。

Method: 提出引导注意力插值方法，通过自适应地结合不同分辨率特征的空间和语义关系，插值出具有丰富语义的细粒度高分辨率特征。该方法可与任何深度卷积网络集成。

Result: 基于GAI的GAIN网络在Cityscapes上达到78.8 mIoU和22.3 FPS，在CamVid上达到80.6 mIoU和64.5 FPS（NVIDIA 1080Ti GPU），创下低延迟语义分割的新最优结果。

Conclusion: GAI方法能有效解决特征插值中的语义不足和错位问题，在保持高推理速度的同时实现优异的语义分割精度。

Abstract: Semantic segmentation is a fundamental problem in computer vision and it requires high-resolution feature maps for dense prediction. Current coordinate-guided low-resolution feature interpolation methods, e.g., bilinear interpolation, produce coarse high-resolution features which suffer from feature misalignment and insufficient context information. Moreover, enriching semantics to high-resolution features requires a high computation burden, so that it is challenging to meet the requirement of lowlatency inference. We propose a novel Guided Attentive Interpolation (GAI) method to adaptively interpolate fine-grained high-resolution features with semantic features to tackle these issues. Guided Attentive Interpolation determines both spatial and semantic relations of pixels from features of different resolutions and then leverages these relations to interpolate high-resolution features with rich semantics. GAI can be integrated with any deep convolutional network for efficient semantic segmentation. In experiments, the GAI-based semantic segmentation networks, i.e., GAIN, can achieve78.8 mIoU with 22.3 FPS on Cityscapes and 80.6 mIoU with 64.5 on CamVid using an NVIDIA 1080Ti GPU, which are the new state-of-the-art results of low-latency semantic segmentation. Code and models are available at: https://github.com/hustvl/simpleseg.

</details>


### [103] [CardioMOD-Net: A Modal Decomposition-Neural Network Framework for Diagnosis and Prognosis of HFpEF from Echocardiography Cine Loops](https://arxiv.org/abs/2601.01176)
*Andrés Bell-Navas,Jesús Garicano-Mena,Antonella Ausiello,Soledad Le Clainche,María Villalba-Orero,Enrique Lara-Pezzi*

Main category: cs.CV

TL;DR: 开发了CardioMOD-Net统一AI框架，利用小鼠超声心动图视频进行HFpEF的多类别诊断和连续发病时间预测，实现了65%的诊断准确率和21.72周的预测误差。


<details>
  <summary>Details</summary>
Motivation: HFpEF病因复杂且进展缓慢，现有AI模型仅支持二分类检测，无法提供合并症特异性表型分析或疾病进展的时间预测，需要开发更全面的诊断预测框架。

Method: 使用四组小鼠超声心动图视频数据，通过高阶动态模态分解提取时序特征，构建共享潜在表示支持的双视觉Transformer架构，分别用于多类别分类和HFpEF发病时间回归预测。

Result: 四组整体诊断准确率达65%，所有类别准确率超过50%；预后模块预测HFpEF发病时间的均方根误差为21.72周，肥胖和高血压组预测最准确，预测分布与真实分布高度吻合。

Conclusion: 该统一框架证明单次超声心动图视频即可实现多类别表型分析和连续HFpEF发病预测，为临床前研究整合诊断与预后建模提供了基础，即使在数据量有限条件下也有效。

Abstract: Introduction: Heart failure with preserved ejection fraction (HFpEF) arises from diverse comorbidities and progresses through prolonged subclinical stages, making early diagnosis and prognosis difficult. Current echocardiography-based Artificial Intelligence (AI) models focus primarily on binary HFpEF detection in humans and do not provide comorbidity-specific phenotyping or temporal estimates of disease progression towards decompensation. We aimed to develop a unified AI framework, CardioMOD-Net, to perform multiclass diagnosis and continuous prediction of HFpEF onset directly from standard echocardiography cine loops in preclinical models.
  Methods: Mouse echocardiography videos from four groups were used: control (CTL), hyperglycaemic (HG), obesity (OB), and systemic arterial hypertension (SAH). Two-dimensional parasternal long-axis cine loops were decomposed using Higher Order Dynamic Mode Decomposition (HODMD) to extract temporal features for downstream analysis. A shared latent representation supported Vision Transformers, one for a classifier for diagnosis and another for a regression module for predicting the age at HFpEF onset.
  Results: Overall diagnostic accuracy across the four groups was 65%, with all classes exceeding 50% accuracy. Misclassifications primarily reflected early-stage overlap between OB or SAH and CTL. The prognostic module achieved a root-mean-square error of 21.72 weeks for time-to-HFpEF prediction, with OB and SAH showing the most accurate estimates. Predicted HFpEF onset closely matched true distributions in all groups.
  Discussion: This unified framework demonstrates that multiclass phenotyping and continuous HFpEF onset prediction can be obtained from a single cine loop, even under small-data conditions. The approach offers a foundation for integrating diagnostic and prognostic modelling in preclinical HFpEF research.

</details>


### [104] [GenCAMO: Scene-Graph Contextual Decoupling for Environment-aware and Mask-free Camouflage Image-Dense Annotation Generation](https://arxiv.org/abs/2601.01181)
*Chenglizhao Chen,Shaojiang Yuan,Xiaoxue Lu,Mengke Song,Jia Song,Zhenyu Wu,Wenfeng Song,Shuai Li*

Main category: cs.CV

TL;DR: 提出GenCAMO框架和GenCAMO-DB数据集，利用生成模型合成高质量伪装图像与密集标注，提升伪装场景的密集预测性能。


<details>
  <summary>Details</summary>
Motivation: 伪装密集预测任务缺乏高质量、大规模标注数据集，数据收集与标注成本高昂，限制了模型对复杂伪装场景的理解与推理能力。

Method: 构建GenCAMO-DB多模态标注数据集；开发环境感知、无需掩码的生成框架GenCAMO，合成高保真伪装图像与密集标注；通过多模态实验验证合成数据对密集预测任务的提升效果。

Result: GenCAMO生成的合成数据显著提升了复杂伪装场景下的密集预测性能；多模态实验验证了方法的有效性。

Conclusion: 生成模型可有效解决伪装数据稀缺问题，合成数据能增强模型对伪装场景的细粒度表征、先验知识与辅助推理能力。

Abstract: Conceal dense prediction (CDP), especially RGB-D camouflage object detection and open-vocabulary camouflage object segmentation, plays a crucial role in advancing the understanding and reasoning of complex camouflage scenes. However, high-quality and large-scale camouflage datasets with dense annotation remain scarce due to expensive data collection and labeling costs. To address this challenge, we explore leveraging generative models to synthesize realistic camouflage image-dense data for training CDP models with fine-grained representations, prior knowledge, and auxiliary reasoning. Concretely, our contributions are threefold: (i) we introduce GenCAMO-DB, a large-scale camouflage dataset with multi-modal annotations, including depth maps, scene graphs, attribute descriptions, and text prompts; (ii) we present GenCAMO, an environment-aware and mask-free generative framework that produces high-fidelity camouflage image-dense annotations; (iii) extensive experiments across multiple modalities demonstrate that GenCAMO significantly improves dense prediction performance on complex camouflage scenes by providing high-quality synthetic data. The code and datasets will be released after paper acceptance.

</details>


### [105] [Crowded Video Individual Counting Informed by Social Grouping and Spatial-Temporal Displacement Priors](https://arxiv.org/abs/2601.01192)
*Hao Lu,Xuhui Zhu,Wenjing Zhang,Yanan Li,Xiang Bai*

Main category: cs.CV

TL;DR: 本文提出OMAN++方法解决拥挤场景下的视频个体计数问题，通过引入社会分组先验和时空位移先验，将传统的一对一匹配扩展为一对多匹配，并在新构建的武汉地铁人群数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视频个体计数方法在拥挤场景（如地铁通勤）中表现不佳，缺乏专门针对动态密集人群的数据集，且传统一对一匹配难以处理群体移动和遮挡问题。

Method: 1) 构建WuhanMetroCrowd数据集，包含多密度、多时长、多运动速度的场景；2) 利用社会分组先验设计隐式上下文生成器和一对多匹配器；3) 通过时空位移先验设计位移先验注入器，增强特征提取和模型训练。

Result: OMAN++在SenseCrowd、CroHD和MovingDroneCrowd基准测试中优于现有方法，在WuhanMetroCrowd数据集上误差降低38.12%，尤其在拥挤场景中优势明显。

Conclusion: 结合群体行为先验和物理约束先验能显著提升拥挤场景下的视频个体计数性能，一对多匹配策略比传统一对一匹配更适应现实人群动态。

Abstract: Video Individual Counting (VIC) is a recently introduced task aiming to estimate pedestrian flux from a video. It extends Video Crowd Counting (VCC) beyond the per-frame pedestrian count. In contrast to VCC that learns to count pedestrians across frames, VIC must identify co-existent pedestrians between frames, which turns out to be a correspondence problem. Existing VIC approaches, however, can underperform in congested scenes such as metro commuting. To address this, we build WuhanMetroCrowd, one of the first VIC datasets that characterize crowded, dynamic pedestrian flows. It features sparse-to-dense density levels, short-to-long video clips, slow-to-fast flow variations, front-to-back appearance changes, and light-to-heavy occlusions. To better adapt VIC approaches to crowds, we rethink the nature of VIC and recognize two informative priors: i) the social grouping prior that indicates pedestrians tend to gather in groups and ii) the spatial-temporal displacement prior that informs an individual cannot teleport physically. The former inspires us to relax the standard one-to-one (O2O) matching used by VIC to one-to-many (O2M) matching, implemented by an implicit context generator and a O2M matcher; the latter facilitates the design of a displacement prior injector, which strengthens not only O2M matching but also feature extraction and model training. These designs jointly form a novel and strong VIC baseline OMAN++. Extensive experiments show that OMAN++ not only outperforms state-of-the-art VIC baselines on the standard SenseCrowd, CroHD, and MovingDroneCrowd benchmarks, but also indicates a clear advantage in crowded scenes, with a 38.12% error reduction on our WuhanMetroCrowd dataset. Code, data, and pretrained models are available at https://github.com/tiny-smart/OMAN.

</details>


### [106] [RefSR-Adv: Adversarial Attack on Reference-based Image Super-Resolution Models](https://arxiv.org/abs/2601.01202)
*Jiazhu Dai,Huihui Jiang*

Main category: cs.CV

TL;DR: 该论文提出RefSR-Adv攻击方法，通过仅扰动参考图像来降低基于参考的超分辨率模型性能，揭示了RefSR系统存在安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注RefSR的后门攻击，而针对RefSR的对抗攻击脆弱性尚未充分探索，需要填补这一研究空白。

Method: 提出RefSR-Adv对抗攻击方法，通过最大化对抗输出与干净输出的差异来扰动参考图像，在CNN、Transformer和Mamba架构上进行实验验证。

Result: 攻击在CUFED5、WR-SR和DRefSR数据集上导致显著性能下降和严重伪影；实验证实低分辨率输入与参考图像的相似度与攻击效果呈正相关。

Conclusion: 模型对参考特征的过度依赖是关键安全缺陷，本研究揭示了RefSR系统的安全漏洞，旨在促使研究者关注RefSR的鲁棒性。

Abstract: Single Image Super-Resolution (SISR) aims to recover high-resolution images from low-resolution inputs. Unlike SISR, Reference-based Super-Resolution (RefSR) leverages an additional high-resolution reference image to facilitate the recovery of high-frequency textures. However, existing research mainly focuses on backdoor attacks targeting RefSR, while the vulnerability of the adversarial attacks targeting RefSR has not been fully explored. To fill this research gap, we propose RefSR-Adv, an adversarial attack that degrades SR outputs by perturbing only the reference image. By maximizing the difference between adversarial and clean outputs, RefSR-Adv induces significant performance degradation and generates severe artifacts across CNN, Transformer, and Mamba architectures on the CUFED5, WR-SR, and DRefSR datasets. Importantly, experiments confirm a positive correlation between the similarity of the low-resolution input and the reference image and attack effectiveness, revealing that the model's over-reliance on reference features is a key security flaw. This study reveals a security vulnerability in RefSR systems, aiming to urge researchers to pay attention to the robustness of RefSR.

</details>


### [107] [XStreamVGGT: Extremely Memory-Efficient Streaming Vision Geometry Grounded Transformer with KV Cache Compression](https://arxiv.org/abs/2601.01204)
*Zunhai Su,Weihao Ye,Hansen Feng,Keyu Fan,Jing Zhang,Dahai Yu,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

TL;DR: 提出XStreamVGGT方法，通过联合剪枝和量化压缩KV缓存，解决StreamVGGT在流式3D重建中内存消耗和延迟增长的问题，实现高效流式推理。


<details>
  <summary>Details</summary>
Motivation: StreamVGGT使用逐帧因果注意力进行流式重建，但KV缓存随输入帧累积而无限增长，导致内存消耗和推理延迟不断增加，限制了实际应用的可扩展性。

Method: 提出无需调优的方法：1）通过高效的令牌重要性识别剪除多视图输入产生的冗余KV，实现固定内存预算；2）利用KV张量的独特分布进行KV量化，进一步减少内存消耗。

Result: 评估显示，XStreamVGGT在性能损失可忽略的情况下，内存使用减少4.42倍，推理速度提升5.48倍。

Conclusion: XStreamVGGT通过系统压缩KV缓存，实现了内存高效且可扩展的流式3D应用，代码已开源。

Abstract: Learning-based 3D visual geometry models have benefited substantially from large-scale transformers. Among these, StreamVGGT leverages frame-wise causal attention for strong streaming reconstruction, but suffers from unbounded KV cache growth, leading to escalating memory consumption and inference latency as input frames accumulate. We propose XStreamVGGT, a tuning-free approach that systematically compresses the KV cache through joint pruning and quantization, enabling extremely memory-efficient streaming inference. Specifically, redundant KVs originating from multi-view inputs are pruned through efficient token importance identification, enabling a fixed memory budget. Leveraging the unique distribution of KV tensors, we incorporate KV quantization to further reduce memory consumption. Extensive evaluations show that XStreamVGGT achieves mostly negligible performance degradation while substantially reducing memory usage by 4.42$\times$ and accelerating inference by 5.48$\times$, enabling scalable and practical streaming 3D applications. The code is available at https://github.com/ywh187/XStreamVGGT/.

</details>


### [108] [Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation](https://arxiv.org/abs/2601.01213)
*Riccardo Gelato,Carlo Sgaravatti,Jakob Grahn,Giacomo Boracchi,Filippo Maria Bianchi*

Main category: cs.CV

TL;DR: 本研究提出了一种基于Segment Anything Model（SAM）的SAR图像雪崩标注加速方法，通过适配器、多编码器、提示工程和高效训练算法解决领域适应问题，显著提升了雪崩标注效率。


<details>
  <summary>Details</summary>
Motivation: 合成孔径雷达（SAR）图像可用于雪崩检测，但高质量标注需要领域专家且耗时巨大。本研究旨在利用SAM基础模型加速SAR图像的雪崩标注过程。

Method: 采用适配器缓解领域差异，多编码器处理多通道SAR输入，提示工程策略提高定位精度，以及限制编码器训练时间的优化算法。

Result: 实验表明，该方法能有效加速SAR图像的雪崩标注工作。

Conclusion: 通过领域适应技术改进的SAM模型可显著提升雪崩SAR图像标注效率，为雪崩风险预测和减灾提供技术支持。

Abstract: Remote sensing solutions for avalanche segmentation and mapping are key to supporting risk forecasting and mitigation in mountain regions. Synthetic Aperture Radar (SAR) imagery from Sentinel-1 can be effectively used for this task, but training an effective detection model requires gathering a large dataset with high-quality annotations from domain experts, which is prohibitively time-consuming. In this work, we aim to facilitate and accelerate the annotation of SAR images for avalanche mapping. We build on the Segment Anything Model (SAM), a segmentation foundation model trained on natural images, and tailor it to Sentinel-1 SAR data. Adapting SAM to our use-case requires addressing several domain-specific challenges: (i) domain mismatch, since SAM was not trained on satellite/SAR imagery; (ii) input adaptation, because SAR products typically provide more than three channels, while SAM is constrained to RGB images; (iii) robustness to imprecise prompts that can affect target identification and degrade the segmentation quality, an issue exacerbated in small, low-contrast avalanches; and (iv) training efficiency, since standard fine-tuning is computationally demanding for SAM. We tackle these challenges through a combination of adapters to mitigate the domain gap, multiple encoders to handle multi-channel SAR inputs, prompt-engineering strategies to improve avalanche localization accuracy, and a training algorithm that limits the training time of the encoder, which is recognized as the major bottleneck. We integrate the resulting model into an annotation tool and show experimentally that it speeds up the annotation of SAR images.

</details>


### [109] [Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment](https://arxiv.org/abs/2601.01224)
*Bac Nguyen,Yuhta Takida,Naoki Murata,Chieh-Hsin Lai,Toshimitsu Uesaka,Stefano Ermon,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: 提出CODA方法，通过注册槽和对比对齐损失改进Slot Attention与扩散模型的结合，提升对象中心学习性能


<details>
  <summary>Details</summary>
Motivation: 现有Slot Attention与预训练扩散模型结合的方法存在槽纠缠和槽-图像内容对齐弱的问题，需要改进对象发现和表示质量

Method: 使用注册槽吸收残差注意力减少干扰，应用对比对齐损失显式增强槽-图像对应关系，构建可处理的互信息最大化替代目标

Result: 在合成和真实数据集上显著提升对象发现（如COCO上FG-ARI提高6.1%）、属性预测和组合图像生成性能，注册槽增加开销可忽略

Conclusion: CODA为复杂真实场景中的鲁棒对象中心学习提供了有效框架，具有高效可扩展性

Abstract: Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extension that (i) employs register slots to absorb residual attention and reduce interference between object slots, and (ii) applies a contrastive alignment loss to explicitly encourage slot-image correspondence. The resulting training objective serves as a tractable surrogate for maximizing mutual information (MI) between slots and inputs, strengthening slot representation quality. On both synthetic (MOVi-C/E) and real-world datasets (VOC, COCO), CODA improves object discovery (e.g., +6.1% FG-ARI on COCO), property prediction, and compositional image generation over strong baselines. Register slots add negligible overhead, keeping CODA efficient and scalable. These results indicate potential applications of CODA as an effective framework for robust OCL in complex, real-world scenes.

</details>


### [110] [UniSH: Unifying Scene and Human Reconstruction in a Feed-Forward Pass](https://arxiv.org/abs/2601.01222)
*Mengfei Li,Peng Li,Zheng Zhang,Jiahao Lu,Chengfeng Zhao,Wei Xue,Qifeng Liu,Sida Peng,Wenxiao Zhang,Wenhan Luo,Yuan Liu,Yike Guo*

Main category: cs.CV

TL;DR: UniSH是一个统一的、前馈的框架，用于联合进行度量尺度的3D场景和人体重建。它通过创新的训练范式，利用未标记的野外数据，解决了合成数据带来的模拟到现实的领域差距问题，实现了高保真度的场景几何、人体点云、相机参数和连贯的度量尺度SMPL身体的重建。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机源于在联合度量尺度3D场景和人体重建领域，缺乏大规模、标注的真实世界数据，导致依赖合成数据集，从而引入了显著的模拟到现实领域差距，表现为泛化能力差、人体几何保真度低以及对野外视频的对齐效果不佳。

Method: 方法包括：1）提出一个创新的训练范式，有效利用未标记的野外数据；2）通过鲁棒的蒸馏策略，从专家深度模型中提取高频细节以优化人体表面细节；3）采用两阶段监督方案，先在合成数据上学习粗略定位，然后在真实数据上通过直接优化SMPL网格与人体点云之间的几何对应关系进行微调。

Result: 实验结果表明，该模型在以人为本的场景重建方面达到了最先进的性能，并在全局人体运动估计方面取得了极具竞争力的结果，优于基于优化的框架和仅使用HMR的方法。

Conclusion: UniSH框架通过创新的训练范式和核心组件，成功解决了模拟到现实领域差距问题，实现了高保真度的联合3D场景和人体重建，为相关领域提供了有效的解决方案。

Abstract: We present UniSH, a unified, feed-forward framework for joint metric-scale 3D scene and human reconstruction. A key challenge in this domain is the scarcity of large-scale, annotated real-world data, forcing a reliance on synthetic datasets. This reliance introduces a significant sim-to-real domain gap, leading to poor generalization, low-fidelity human geometry, and poor alignment on in-the-wild videos. To address this, we propose an innovative training paradigm that effectively leverages unlabeled in-the-wild data. Our framework bridges strong, disparate priors from scene reconstruction and HMR, and is trained with two core components: (1) a robust distillation strategy to refine human surface details by distilling high-frequency details from an expert depth model, and (2) a two-stage supervision scheme, which first learns coarse localization on synthetic data, then fine-tunes on real data by directly optimizing the geometric correspondence between the SMPL mesh and the human point cloud. This approach enables our feed-forward model to jointly recover high-fidelity scene geometry, human point clouds, camera parameters, and coherent, metric-scale SMPL bodies, all in a single forward pass. Extensive experiments demonstrate that our model achieves state-of-the-art performance on human-centric scene reconstruction and delivers highly competitive results on global human motion estimation, comparing favorably against both optimization-based frameworks and HMR-only methods. Project page: https://murphylmf.github.io/UniSH/

</details>


### [111] [HyDRA: Hybrid Denoising Regularization for Measurement-Only DEQ Training](https://arxiv.org/abs/2601.01228)
*Markus Haltmeier,Lukas Neumann,Nadja Gruber,Johannes Schwab,Gyeongha Hwang*

Main category: cs.CV

TL;DR: 提出HyDRA框架，无需监督数据对，仅利用测量数据训练深度均衡模型进行图像重建，在稀疏视角CT中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统深度均衡模型需要监督数据对(x,y)，但实际应用中往往只有测量数据y可用，且图像重建问题存在不适定性和大规模监督数据集缺乏的挑战。

Method: HyDRA框架结合测量一致性和自适应去噪正则化项，采用数据驱动的早停准则，仅使用测量数据进行训练。

Result: 在稀疏视角CT重建实验中，实现了具有竞争力的重建质量和快速推理速度。

Conclusion: HyDRA为无监督深度均衡模型训练提供了有效解决方案，在测量数据有限的实际场景中具有应用潜力。

Abstract: Solving image reconstruction problems of the form \(\mathbf{A} \mathbf{x} = \mathbf{y}\) remains challenging due to ill-posedness and the lack of large-scale supervised datasets. Deep Equilibrium (DEQ) models have been used successfully but typically require supervised pairs \((\mathbf{x},\mathbf{y})\). In many practical settings, only measurements \(\mathbf{y}\) are available. We introduce HyDRA (Hybrid Denoising Regularization Adaptation), a measurement-only framework for DEQ training that combines measurement consistency with an adaptive denoising regularization term, together with a data-driven early stopping criterion. Experiments on sparse-view CT demonstrate competitive reconstruction quality and fast inference.

</details>


### [112] [RFAssigner: A Generic Label Assignment Strategy for Dense Object Detection](https://arxiv.org/abs/2601.01240)
*Ziqian Guan,Xieyi Fu,Yuting Wang,Haowen Xiao,Jiarui Zhu,Yingying Zhu,Yongtao Liu,Lin Gu*

Main category: cs.CV

TL;DR: 提出RFAssigner标签分配策略，通过高斯感受野距离度量自适应补充正样本，解决密集目标检测中小目标正样本不足的尺度不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有密集目标检测器的标签分配策略通常为小目标分配的正样本数量不足，导致训练过程中的尺度不平衡问题，影响多尺度学习能力。

Method: RFAssigner首先基于点先验建立初始正样本集，然后利用高斯感受野距离度量未分配候选位置与真实目标之间的相似性，自适应地从未分配池中选择补充正样本。

Result: 在三个具有不同目标尺度分布的数据集上验证了方法的有效性，FCOS-ResNet-50检测器搭配RFAssigner在所有目标尺度上均达到最先进性能，无需额外模块或启发式规则。

Conclusion: RFAssigner通过自适应补充正样本有效缓解了训练中的尺度不平衡问题，提升了密集目标检测器尤其是小目标的检测性能，具有良好的泛化能力。

Abstract: Label assignment is a critical component in training dense object detectors. State-of-the-art methods typically assign each training sample a positive and a negative weight, optimizing the assignment scheme during training. However, these strategies often assign an insufficient number of positive samples to small objects, leading to a scale imbalance during training. To address this limitation, we introduce RFAssigner, a novel assignment strategy designed to enhance the multi-scale learning capabilities of dense detectors. RFAssigner first establishes an initial set of positive samples using a point-based prior. It then leverages a Gaussian Receptive Field (GRF) distance to measure the similarity between the GRFs of unassigned candidate locations and the ground-truth objects. Based on this metric, RFAssigner adaptively selects supplementary positive samples from the unassigned pool, promoting a more balanced learning process across object scales. Comprehensive experiments on three datasets with distinct object scale distributions validate the effectiveness and generalizability of our method. Notably, a single FCOS-ResNet-50 detector equipped with RFAssigner achieves state-of-the-art performance across all object scales, consistently outperforming existing strategies without requiring auxiliary modules or heuristics.

</details>


### [113] [MambaFormer: Token-Level Guided Routing Mixture-of-Experts for Accurate and Efficient Clinical Assistance](https://arxiv.org/abs/2601.01260)
*Hamad Khan,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 提出MambaFormer混合专家框架，结合Transformer和状态空间模型，通过智能路由机制在医疗问答任务中实现高效推理与高精度平衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床应用中面临计算成本与效率的权衡问题，需要一种既能处理复杂查询又能高效处理长序列的解决方案。

Method: 采用混合专家框架，设计轻量级门控机制进行令牌级动态路由：短复杂查询路由至定制Transformer专家，长高吞吐序列路由至状态空间模型专家；使用自定义DentalQA数据集微调，并通过多目标损失函数联合优化路由决策与计算成本。

Result: 在DentalQA和PubMedQA数据集上验证，MambaFormer取得最佳BERTScore（0.9180）和超低延迟（0.077秒），相比T5-Large实现24.4倍加速。

Conclusion: 该框架为资源受限的临床部署提供了可扩展解决方案，在推理延迟与预测精度之间实现了帕累托最优权衡。

Abstract: The deployment of large language models (LLMs) in real-world clinical applications is constrained by the fundamental trade-off between computational cost and the efficiency of linear-time models. To address this, we propose an LLM-based MambaFormer hybrid Mixture-of-Experts (MoE) framework for efficient medical question-answering (QA) and clinical assistance. The MambaFormer employs a lightweight gating mechanism that performs token-level dynamic routing to a customized Transformer expert (ET5) for short, complex queries or to a State Space Model expert (EMamba) for long, high-throughput sequences. The customized EMamba and ET5 models are tailored to accommodate input sequence dimensionality, embedding structure, sequence length, and target-specific output heads, and are fine-tuned through transfer learning on a new, custom-designed DentalQA dataset. Moreover, intelligent routing decisions are driven by the contextual complexity of token embeddings, normalized sequence length, and domain-aware features, thereby enforcing a Pareto-optimal trade-off between inference latency and prediction accuracy. Furthermore, a novel utility-guided multi-objective loss jointly optimizes decisions, router parameters, routing behavior, expert utilization, and computational cost by adaptively regulating token-level expert activation. Finally, the proposed MambaFormer is cross-validated (holdout) for medical QA on the new, custom-designed DentalQA and PubMedQA datasets and compared with state-of-the-art techniques. The proposed MambaFormer outperforms (BERTScore = 0.9180) with ultra-low latency (0.077 s), delivering a 24.4 speedup over T5-Large and establishing a scalable solution for resource-constrained clinical deployment.

</details>


### [114] [AI-Powered Deepfake Detection Using CNN and Vision Transformer Architectures](https://arxiv.org/abs/2601.01281)
*Sifatullah Sheikh Urmi,Kirtonia Nuzath Tabassum Arthi,Md Al-Imran*

Main category: cs.CV

TL;DR: 该研究评估了四种AI模型（三种CNN和一种Vision Transformer）在深度伪造检测中的表现，发现VFDNET结合MobileNetV3在准确性和效率上表现最优。


<details>
  <summary>Details</summary>
Motivation: 人工智能生成的深度伪造技术日益普及，对数字内容的真实性构成了重大挑战，因此需要开发可靠的检测方法。

Method: 使用大规模人脸图像数据集，评估了三种卷积神经网络（CNN）和一种Vision Transformer模型，并应用了数据预处理和数据增强技术以提升模型性能。

Result: VFDNET模型结合MobileNetV3在多种场景下表现出最高的检测准确率，同时保持了高效的计算性能。

Conclusion: 研究表明人工智能在深度伪造检测方面具有可靠的能力，其中VFDNET与MobileNetV3的组合在准确性和效率上均表现优异。

Abstract: The increasing use of artificial intelligence generated deepfakes creates major challenges in maintaining digital authenticity. Four AI-based models, consisting of three CNNs and one Vision Transformer, were evaluated using large face image datasets. Data preprocessing and augmentation techniques improved model performance across different scenarios. VFDNET demonstrated superior accuracy with MobileNetV3, showing efficient performance, thereby demonstrating AI's capabilities for dependable deepfake detection.

</details>


### [115] [S2M-Net: Spectral-Spatial Mixing for Medical Image Segmentation with Morphology-Aware Adaptive Loss](https://arxiv.org/abs/2601.01285)
*Md. Sanaullah Chowdhury Lameya Sabrin*

Main category: cs.CV

TL;DR: 提出S2M-Net架构，通过谱选择令牌混合器和形态感知自适应分割损失，以较低计算成本实现医学图像分割的局部精度、全局上下文和计算效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法难以同时满足局部精度、全局上下文和计算效率的要求，卷积网络感受野有限，视觉变换器计算成本过高且易在小数据集上过拟合。

Method: 1. 谱选择令牌混合器（SSTM）：利用医学图像的频谱集中特性，通过截断二维FFT和可学习频率滤波实现全局感受野；2. 形态感知自适应分割损失（MASL）：自动分析结构特征并调制五个互补损失分量，避免手动调参。

Result: 在16个医学影像数据集上评估，S2M-Net（470万参数）在息肉分割、手术器械和脑肿瘤分割任务中分别达到96.12%、83.77%和80.90%的Dice分数，性能优于专用基线模型3-18%，参数比基于变换器的方法少3.5-6倍。

Conclusion: S2M-Net通过谱令牌混合和自适应损失设计，有效解决了医学图像分割中的三难问题，在多个数据集上实现了最先进的性能，且计算效率更高。

Abstract: Medical image segmentation requires balancing local precision for boundary-critical clinical applications, global context for anatomical coherence, and computational efficiency for deployment on limited data and hardware a trilemma that existing architectures fail to resolve. Although convolutional networks provide local precision at $\mathcal{O}(n)$ cost but limited receptive fields, vision transformers achieve global context through $\mathcal{O}(n^2)$ self-attention at prohibitive computational expense, causing overfitting on small clinical datasets. We propose S2M-Net, a 4.7M-parameter architecture that achieves $\mathcal{O}(HW \log HW)$ global context through two synergistic innovations: (i) Spectral-Selective Token Mixer (SSTM), which exploits the spectral concentration of medical images via truncated 2D FFT with learnable frequency filtering and content-gated spatial projection, avoiding quadratic attention cost while maintaining global receptive fields; and (ii) Morphology-Aware Adaptive Segmentation Loss (MASL), which automatically analyzes structure characteristics (compactness, tubularity, irregularity, scale) to modulate five complementary loss components through constrained learnable weights, eliminating manual per-dataset tuning. Comprehensive evaluation in 16 medical imaging datasets that span 8 modalities demonstrates state-of-the-art performance: 96.12\% Dice on polyp segmentation, 83.77\% on surgical instruments (+17.85\% over the prior art) and 80.90\% on brain tumors, with consistent 3-18\% improvements over specialized baselines while using 3.5--6$\times$ fewer parameters than transformer-based methods.

</details>


### [116] [Achieving Fine-grained Cross-modal Understanding through Brain-inspired Hierarchical Representation Learning](https://arxiv.org/abs/2601.01339)
*Weihang You,Hanqi Jiang,Yi Pan,Junhao Chen,Tianming Liu,Fei Dou*

Main category: cs.CV

TL;DR: 提出NeuroAlign框架，通过分层对齐机制改进fMRI-视频跨模态匹配，模拟人类视觉系统的层次处理过程。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉视觉处理的层次性和时序动态，且存在模态鸿沟，需要更符合生物视觉机制的对齐方法。

Method: 采用两阶段机制：1）神经-时序对比学习（NTCL）实现全局语义对齐；2）增强向量量化进行细粒度模式匹配，结合DynaSyncMM-EMA进行动态多模态融合。

Result: 在跨模态检索任务中显著优于现有方法，验证了框架的有效性。

Conclusion: NeuroAlign为理解视觉认知机制提供了新范式，通过模拟生物视觉通路实现了更精细的神经响应对齐。

Abstract: Understanding neural responses to visual stimuli remains challenging due to the inherent complexity of brain representations and the modality gap between neural data and visual inputs. Existing methods, mainly based on reducing neural decoding to generation tasks or simple correlations, fail to reflect the hierarchical and temporal processes of visual processing in the brain. To address these limitations, we present NeuroAlign, a novel framework for fine-grained fMRI-video alignment inspired by the hierarchical organization of the human visual system. Our framework implements a two-stage mechanism that mirrors biological visual pathways: global semantic understanding through Neural-Temporal Contrastive Learning (NTCL) and fine-grained pattern matching through enhanced vector quantization. NTCL explicitly models temporal dynamics through bidirectional prediction between modalities, while our DynaSyncMM-EMA approach enables dynamic multi-modal fusion with adaptive weighting. Experiments demonstrate that NeuroAlign significantly outperforms existing methods in cross-modal retrieval tasks, establishing a new paradigm for understanding visual cognitive mechanisms.

</details>


### [117] [VReID-XFD: Video-based Person Re-identification at Extreme Far Distance Challenge Results](https://arxiv.org/abs/2601.01312)
*Kailash A. Hambarde,Hugo Proença,Md Rashidunnabi,Pranita Samale,Qiwei Yang,Pingping Zhang,Zijing Gong,Yuhao Wang,Xi Zhang,Ruoshui Qu,Qiaoyun He,Yuhang Zhang,Thi Ngoc Ha Nguyen,Tien-Dung Mai,Cheng-Jun Kang,Yu-Fan Lin,Jin-Hui Jiang,Chih-Chung Hsu,Tamás Endrei,György Cserey,Ashwat Rajbhandari*

Main category: cs.CV

TL;DR: 本文介绍了VReID-XFD，一个用于极端远距离空中到地面行人重识别的视频基准和社区挑战，揭示了在该极端条件下现有方法性能严重下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有行人重识别系统基于外观的假设在极端远距离、严重分辨率退化、极端视角变化、不稳定运动线索和服装变化等联合作用下失效，需要专门研究这一极端操作机制。

Method: 基于DetReIDX数据集构建VReID-XFD基准，包含371个身份、11,288个轨迹段和1175万帧，涵盖5.8米至120米高度、30度至90度视角、最远120米水平距离的采集条件，并设计了严格的身份不相交划分和丰富的物理元数据。

Result: 系统分析显示性能随高度和距离单调下降，天底视角普遍处于劣势，存在峰值性能与鲁棒性之间的权衡；最佳方法SAS-PReID在空对地设置中仅达到43.93%的mAP。

Conclusion: VReID-XFD基准揭示了极端远距离行人重识别的挑战性，现有方法在该机制下性能有限，需要进一步研究提升；数据集和评估协议已公开供社区使用。

Abstract: Person re-identification (ReID) across aerial and ground views at extreme far distances introduces a distinct operating regime where severe resolution degradation, extreme viewpoint changes, unstable motion cues, and clothing variation jointly undermine the appearance-based assumptions of existing ReID systems. To study this regime, we introduce VReID-XFD, a video-based benchmark and community challenge for extreme far-distance (XFD) aerial-to-ground person re-identification. VReID-XFD is derived from the DetReIDX dataset and comprises 371 identities, 11,288 tracklets, and 11.75 million frames, captured across altitudes from 5.8 m to 120 m, viewing angles from oblique (30 degrees) to nadir (90 degrees), and horizontal distances up to 120 m. The benchmark supports aerial-to-aerial, aerial-to-ground, and ground-to-aerial evaluation under strict identity-disjoint splits, with rich physical metadata. The VReID-XFD-25 Challenge attracted 10 teams with hundreds of submissions. Systematic analysis reveals monotonic performance degradation with altitude and distance, a universal disadvantage of nadir views, and a trade-off between peak performance and robustness. Even the best-performing SAS-PReID method achieves only 43.93 percent mAP in the aerial-to-ground setting. The dataset, annotations, and official evaluation protocols are publicly available at https://www.it.ubi.pt/DetReIDX/ .

</details>


### [118] [Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding](https://arxiv.org/abs/2601.01352)
*Yixuan Lai,He Wang,Kun Zhou,Tianjia Shao*

Main category: cs.CV

TL;DR: 提出了一种基于短参考视频的身份条件扩散变换器视频生成方法，通过捕捉参考视频中的动态特征来改善身份保持和运动自然性。


<details>
  <summary>Details</summary>
Motivation: 现有基于单张图像的视频生成方法在身份保持和运动自然性之间存在矛盾，容易产生姿态锁定、不自然扭曲和平均化面部的问题，忽略了时间动态特征。

Method: 使用短参考视频而非单张肖像作为条件输入；通过Sinkhorn路由编码器从参考视频中学习紧凑的身份令牌，捕捉特定主体的动态特征；构建身份条件的扩散变换器视频生成器。

Result: 该方法在大姿态变化和丰富表情下显著改善了身份保持能力，同时保持了提示忠实度和视觉真实感，适用于多样化的主体和提示。

Conclusion: 通过引入参考视频中的动态特征，提出的方法有效解决了身份保持与运动自然性之间的平衡问题，提升了生成视频的质量和身份一致性。

Abstract: Producing prompt-faithful videos that preserve a user-specified identity remains challenging: models need to extrapolate facial dynamics from sparse reference while balancing the tension between identity preservation and motion naturalness. Conditioning on a single image completely ignores the temporal signature, which leads to pose-locked motions, unnatural warping, and "average" faces when viewpoints and expressions change. To this end, we introduce an identity-conditioned variant of a diffusion-transformer video generator which uses a short reference video rather than a single portrait. Our key idea is to incorporate the dynamics in the reference. A short clip reveals subject-specific patterns, e.g., how smiles form, across poses and lighting. From this clip, a Sinkhorn-routed encoder learns compact identity tokens that capture characteristic dynamics while remaining pretrained backbone-compatible. Despite adding only lightweight conditioning, the approach consistently improves identity retention under large pose changes and expressive facial behavior, while maintaining prompt faithfulness and visual realism across diverse subjects and prompts.

</details>


### [119] [Advanced Machine Learning Approaches for Enhancing Person Re-Identification Performance](https://arxiv.org/abs/2601.01356)
*Dang H. Pham,Tu N. Nguyen,Hoa N. Nguyen*

Main category: cs.CV

TL;DR: 该论文提出了三种先进的行人重识别方法，分别针对监督学习、无监督域适应和完全无监督场景，通过对比学习、GAN增强、Transformer编码等技术提升性能，在多个基准数据集上达到先进水平。


<details>
  <summary>Details</summary>
Motivation: 行人重识别在复杂监控系统中至关重要，但面临外观变化、域偏移和标注数据有限等挑战，需要开发更鲁棒的算法以适应实际应用需求。

Method: 1) 监督场景：SCM-ReID结合监督对比学习和混合损失优化；2) 无监督域适应：IQAGA和DAPRH使用GAN图像增强、域不变映射和伪标签优化；3) 完全无监督：ViTC-UReID采用Vision Transformer特征编码和相机感知代理学习。

Result: 在Market-1501、CUHK03等数据集上取得最先进准确率；无监督域适应方法在跨域场景中mAP和Rank-1指标提升高达12%；完全无监督方法显著优于现有方法。

Conclusion: 所提方法通过改进特征学习、域适应和标签噪声处理，推动了行人重识别研究进展，为实际监控系统部署提供了更鲁棒的解决方案。

Abstract: Person re-identification (ReID) plays a critical role in intelligent surveillance systems by linking identities across multiple cameras in complex environments. However, ReID faces significant challenges such as appearance variations, domain shifts, and limited labeled data. This dissertation proposes three advanced approaches to enhance ReID performance under supervised, unsupervised domain adaptation (UDA), and fully unsupervised settings. First, SCM-ReID integrates supervised contrastive learning with hybrid loss optimization (classification, center, triplet, and centroid-triplet losses), improving discriminative feature representation and achieving state-of-the-art accuracy on Market-1501 and CUHK03 datasets. Second, for UDA, IQAGA and DAPRH combine GAN-based image augmentation, domain-invariant mapping, and pseudo-label refinement to mitigate domain discrepancies and enhance cross-domain generalization. Experiments demonstrate substantial gains over baseline methods, with mAP and Rank-1 improvements up to 12% in challenging transfer scenarios. Finally, ViTC-UReID leverages Vision Transformer-based feature encoding and camera-aware proxy learning to boost unsupervised ReID. By integrating global and local attention with camera identity constraints, this method significantly outperforms existing unsupervised approaches on large-scale benchmarks. Comprehensive evaluations across CUHK03, Market-1501, DukeMTMC-reID, and MSMT17 confirm the effectiveness of the proposed methods. The contributions advance ReID research by addressing key limitations in feature learning, domain adaptation, and label noise handling, paving the way for robust deployment in real-world surveillance systems.

</details>


### [120] [Garment Inertial Denoiser (GID): Endowing Accurate Motion Capture via Loose IMU Denoiser](https://arxiv.org/abs/2601.01360)
*Jiawei Fang,Ruonan Zheng,Xiaoxia Gao,Shifan Jiang,Anjun Chen,Qi Ye,Shihui Guo*

Main category: cs.CV

TL;DR: 提出GID（服装惯性去噪器），一种轻量级即插即用Transformer，用于解决宽松服装中IMU传感器位移导致的运动捕捉数据损坏问题，显著提升穿戴式惯性运动捕捉精度。


<details>
  <summary>Details</summary>
Motivation: 现有穿戴式惯性运动捕捉系统需要传感器紧贴身体，导致不适且不适用于日常穿着；将IMU嵌入宽松服装时，传感器与身体的相对位移会产生结构化噪声，破坏标准惯性处理流程。

Method: 采用三阶段分解框架：位置特定去噪、自适应跨服装融合、通用姿态预测；使用位置感知专家架构，包括共享时空骨干网络（建模全局运动）和每IMU专家头（学习局部服装动态），配合轻量融合模块确保跨部位一致性。

Result: GID在GarMoCap数据集上验证，能够通过单用户训练实现实时准确去噪，并在未见过的用户、动作和服装类型上表现出良好泛化能力，作为即插模块持续提升现有惯性运动捕捉方法的性能。

Conclusion: GID通过结构化建模服装动态噪声，解决了宽松服装惯性运动捕捉的核心挑战，为舒适、隐私保护且精确的日常运动捕捉提供了可行方案。

Abstract: Wearable inertial motion capture (MoCap) provides a portable, occlusion-free, and privacy-preserving alternative to camera-based systems, but its accuracy depends on tightly attached sensors - an intrusive and uncomfortable requirement for daily use. Embedding IMUs into loose-fitting garments is a desirable alternative, yet sensor-body displacement introduces severe, structured, and location-dependent corruption that breaks standard inertial pipelines. We propose GID (Garment Inertial Denoiser), a lightweight, plug-and-play Transformer that factorizes loose-wear MoCap into three stages: (i) location-specific denoising, (ii) adaptive cross-wear fusion, and (iii) general pose prediction. GID uses a location-aware expert architecture, where a shared spatio-temporal backbone models global motion while per-IMU expert heads specialize in local garment dynamics, and a lightweight fusion module ensures cross-part consistency. This inductive bias enables stable training and effective learning from limited paired loose-tight IMU data. We also introduce GarMoCap, a combined public and newly collected dataset covering diverse users, motions, and garments. Experiments show that GID enables accurate, real-time denoising from single-user training and generalizes across unseen users, motions, and garment types, consistently improving state-of-the-art inertial MoCap methods when used as a drop-in module.

</details>


### [121] [Unsupervised SE(3) Disentanglement for in situ Macromolecular Morphology Identification from Cryo-Electron Tomography](https://arxiv.org/abs/2601.01364)
*Mostofa Rafid Uddin,Mahek Vora,Qifeng Wu,Muyuan Chen,Min Xu*

Main category: cs.CV

TL;DR: 提出了一种解耦深度表示学习框架，用于从冷冻电子断层扫描数据中分离SE(3)变换与形态内容，以改进大分子形态分析。


<details>
  <summary>Details</summary>
Motivation: 现有基于期望最大化的方法常遗漏罕见但重要的形态，且需大量手动超参数调整，限制了冷冻电子断层扫描数据中形态分析的准确性和效率。

Method: 采用解耦深度表示学习框架，包含一个多选择学习模块，用于在噪声数据中分离SE(3)变换与形态内容，并基于形态内容生成模板形态。

Result: 在模拟和真实冷冻电子断层扫描数据集上的实验显示，该方法优于先前方法，并发现了先前未识别的大分子形态。

Conclusion: 该框架有效解决了形态分析中的逆问题，提高了形态发现的准确性和自动化程度，有助于揭示细胞内的复杂大分子结构。

Abstract: Cryo-electron tomography (cryo-ET) provides direct 3D visualization of macromolecules inside the cell, enabling analysis of their in situ morphology. This morphology can be regarded as an SE(3)-invariant, denoised volumetric representation of subvolumes extracted from tomograms. Inferring morphology is therefore an inverse problem of estimating both a template morphology and its SE(3) transformation. Existing expectation-maximization based solution to this problem often misses rare but important morphologies and requires extensive manual hyperparameter tuning. Addressing this issue, we present a disentangled deep representation learning framework that separates SE(3) transformations from morphological content in the representation space. The framework includes a novel multi-choice learning module that enables this disentanglement for highly noisy cryo-ET data, and the learned morphological content is used to generate template morphologies. Experiments on simulated and real cryo-ET datasets demonstrate clear improvements over prior methods, including the discovery of previously unidentified macromolecular morphologies.

</details>


### [122] [ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking](https://arxiv.org/abs/2601.01386)
*Xiaobao Wei,Zhangjie Ye,Yuxiang Gu,Zunjie Zhu,Yunfei Guo,Yingying Shen,Shan Zhao,Ming Lu,Haiyang Sun,Bing Wang,Guang Chen,Rongfeng Lu,Hangjun Ye*

Main category: cs.CV

TL;DR: 本文提出了ParkRecon3D基准和ParkGaussian框架，首次将3D高斯溅射应用于停车场景重建，并通过槽位感知策略提升下游停车位检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于2D停车位感知，而3D重建在复杂停车场景中至关重要。单纯提升重建视觉质量对自动驾驶停车帮助有限，需要与停车位感知模块更好结合。

Method: 1) 创建ParkRecon3D基准数据集，包含四路鱼眼相机数据和密集停车位标注；2) 提出ParkGaussian框架，首次将3D高斯溅射用于停车场景重建；3) 引入槽位感知重建策略，利用现有停车感知方法提升槽位区域合成质量。

Result: 在ParkRecon3D上的实验表明，ParkGaussian实现了最先进的重建质量，并更好地保持了下游任务的感知一致性。

Conclusion: 该工作填补了停车场景3D重建的研究空白，提出的框架能有效提升重建质量与下游感知任务的一致性，代码和数据集将开源。

Abstract: Parking is a critical task for autonomous driving systems (ADS), with unique challenges in crowded parking slots and GPS-denied environments. However, existing works focus on 2D parking slot perception, mapping, and localization, 3D reconstruction remains underexplored, which is crucial for capturing complex spatial geometry in parking scenarios. Naively improving the visual quality of reconstructed parking scenes does not directly benefit autonomous parking, as the key entry point for parking is the slots perception module. To address these limitations, we curate the first benchmark named ParkRecon3D, specifically designed for parking scene reconstruction. It includes sensor data from four surround-view fisheye cameras with calibrated extrinsics and dense parking slot annotations. We then propose ParkGaussian, the first framework that integrates 3D Gaussian Splatting (3DGS) for parking scene reconstruction. To further improve the alignment between reconstruction and downstream parking slot detection, we introduce a slot-aware reconstruction strategy that leverages existing parking perception methods to enhance the synthesis quality of slot regions. Experiments on ParkRecon3D demonstrate that ParkGaussian achieves state-of-the-art reconstruction quality and better preserves perception consistency for downstream tasks. The code and dataset will be released at: https://github.com/wm-research/ParkGaussian

</details>


### [123] [Evaluation of Convolutional Neural Network For Image Classification with Agricultural and Urban Datasets](https://arxiv.org/abs/2601.01393)
*Shamik Shafkat Avro,Nazira Jesmin Lina,Shahanaz Sharmin*

Main category: cs.CV

TL;DR: 本文开发并评估了一种自定义卷积神经网络（CustomCNN），研究架构设计选择对多领域图像分类任务的影响，在智能城市和农业图像应用中表现出竞争性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索神经网络架构设计选择如何影响多领域图像分类任务的性能，特别是针对智能城市监控和农业图像分析等实际应用场景。

Method: 使用残差连接、Squeeze-and-Excitation注意力机制、渐进通道缩放和Kaiming初始化等技术构建CustomCNN，在五个公开数据集上进行训练和测试，并与流行CNN架构进行对比。

Result: CustomCNN在保持计算效率的同时，在车辆检测、人行道侵占检测、道路损坏检测、芒果图像分类和水稻品种识别等多个任务中表现出竞争性能。

Conclusion: 研究结果表明，经过深思熟虑的架构设计对于现实世界的智能城市和农业成像应用至关重要，CustomCNN为多领域图像分类提供了高效且有效的解决方案。

Abstract: This paper presents the development and evaluation of a custom Convolutional Neural Network (CustomCNN) created to study how architectural design choices affect multi-domain image classification tasks. The network uses residual connections, Squeeze-and-Excitation attention mechanisms, progressive channel scaling, and Kaiming initialization to improve its ability to represent data and speed up training. The model is trained and tested on five publicly available datasets: unauthorized vehicle detection, footpath encroachment detection, polygon-annotated road damage and manhole detection, MangoImageBD and PaddyVarietyBD. A comparison with popular CNN architectures shows that the CustomCNN delivers competitive performance while remaining efficient in computation. The results underscore the importance of thoughtful architectural design for real-world Smart City and agricultural imaging applications.

</details>


### [124] [SwinIFS: Landmark Guided Swin Transformer For Identity Preserving Face Super Resolution](https://arxiv.org/abs/2601.01406)
*Habiba Kausar,Saeed Anwar,Omar Jamal Hammad,Abdul Bais*

Main category: cs.CV

TL;DR: 提出SwinIFS，一种基于地标引导的人脸超分辨率框架，通过结合结构先验和分层注意力机制，在中等和极端放大倍数下实现身份保持重建。


<details>
  <summary>Details</summary>
Motivation: 人脸超分辨率在从严重退化的低分辨率输入中恢复高质量图像时面临挑战，主要问题在于细粒度结构细节和身份特定特征的丢失。

Method: 方法将密集高斯热图（关键面部地标）融入输入表示，使网络从处理早期阶段就能关注语义重要的面部区域；采用紧凑的Swin Transformer骨干网络捕获长距离上下文信息，同时保持局部几何结构。

Result: 在CelebA基准测试中，SwinIFS实现了卓越的感知质量、更清晰的重建和改善的身份保持；即使在8倍放大（多数方法失效）下仍能恢复有意义结构，并在重建精度与计算效率间取得良好平衡。

Conclusion: SwinIFS能够生成更逼真的结果，适用于人脸增强、监控和数字修复等实际应用；代码和模型已开源。

Abstract: Face super-resolution aims to recover high-quality facial images from severely degraded low-resolution inputs, but remains challenging due to the loss of fine structural details and identity-specific features. This work introduces SwinIFS, a landmark-guided super-resolution framework that integrates structural priors with hierarchical attention mechanisms to achieve identity-preserving reconstruction at both moderate and extreme upscaling factors. The method incorporates dense Gaussian heatmaps of key facial landmarks into the input representation, enabling the network to focus on semantically important facial regions from the earliest stages of processing. A compact Swin Transformer backbone is employed to capture long-range contextual information while preserving local geometry, allowing the model to restore subtle facial textures and maintain global structural consistency. Extensive experiments on the CelebA benchmark demonstrate that SwinIFS achieves superior perceptual quality, sharper reconstructions, and improved identity retention; it consistently produces more photorealistic results and exhibits strong performance even under 8x magnification, where most methods fail to recover meaningful structure. SwinIFS also provides an advantageous balance between reconstruction accuracy and computational efficiency, making it suitable for real-world applications in facial enhancement, surveillance, and digital restoration. Our code, model weights, and results are available at https://github.com/Habiba123-stack/SwinIFS.

</details>


### [125] [Mask-Guided Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01408)
*Gong Gao,Zekai Wang,Jian Zhao,Ziqi Xie,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

TL;DR: 提出了一种基于掩码引导的多任务网络（MGMTN），通过自适应掩码学习和组-全局特征融合来提升人脸属性识别性能，减少全局特征带来的冗余。


<details>
  <summary>Details</summary>
Motivation: 传统多任务属性识别方法依赖全局特征图进行特征提取和分类，容易产生冗余特征并受全局区域干扰，影响识别精度。

Method: 提出MGMTN网络，包含自适应掩码学习（AML）和组-全局特征融合（G2FF）。AML利用预训练关键点模型和全卷积网络定位关键面部区域并生成组掩码；G2FF融合组特征与全局特征以增强属性学习。

Result: 在两个具有挑战性的人脸属性识别数据集上的实验表明，MGMTN能有效提升属性识别性能。

Conclusion: 通过聚焦关键面部区域并融合局部与全局特征，MGMTN减少了特征冗余和负迁移，为人脸属性识别提供了一种更高效的解决方案。

Abstract: Face Attribute Recognition (FAR) plays a crucial role in applications such as person re-identification, face retrieval, and face editing. Conventional multi-task attribute recognition methods often process the entire feature map for feature extraction and attribute classification, which can produce redundant features due to reliance on global regions. To address these challenges, we propose a novel approach emphasizing the selection of specific feature regions for efficient feature learning. We introduce the Mask-Guided Multi-Task Network (MGMTN), which integrates Adaptive Mask Learning (AML) and Group-Global Feature Fusion (G2FF) to address the aforementioned limitations. Leveraging a pre-trained keypoint annotation model and a fully convolutional network, AML accurately localizes critical facial parts (e.g., eye and mouth groups) and generates group masks that delineate meaningful feature regions, thereby mitigating negative transfer from global region usage. Furthermore, G2FF combines group and global features to enhance FAR learning, enabling more precise attribute identification. Extensive experiments on two challenging facial attribute recognition datasets demonstrate the effectiveness of MGMTN in improving FAR performance.

</details>


### [126] [Rethinking Multimodal Few-Shot 3D Point Cloud Segmentation: From Fused Refinement to Decoupled Arbitration](https://arxiv.org/abs/2601.01456)
*Wentao Bian,Fenglei Xu*

Main category: cs.CV

TL;DR: 本文提出DA-FSS模型，通过解耦几何与语义路径并协调其梯度，解决多模态少样本3D点云分割中的'可塑性-稳定性困境'和CLIP的类间混淆问题，在S3DIS和ScanNet数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有'先融合后优化'的多模态少样本3D点云分割方法存在'可塑性-稳定性困境'，且CLIP模型易产生类间混淆导致语义盲区，需要新的架构来解决这些问题。

Method: 提出DA-FSS模型，包含并行专家优化模块（生成各模态关联）、堆叠仲裁模块（卷积融合与模态路径仲裁）、解耦对齐模块（协调几何专家与语义专家），几何专家保持可塑性，语义专家确保稳定性。

Result: 在S3DIS和ScanNet数据集上的实验表明，DA-FSS在分割性能上优于MM-FSS基线，且在几何边界完整性、纹理区分等方面均有提升。

Conclusion: 通过解耦几何与语义路径并实现梯度互正则化，DA-FSS能更有效地利用多模态信息，缓解可塑性-稳定性冲突，提升少样本3D点云分割的泛化能力。

Abstract: In this paper, we revisit multimodal few-shot 3D point cloud semantic segmentation (FS-PCS), identifying a conflict in "Fuse-then-Refine" paradigms: the "Plasticity-Stability Dilemma." In addition, CLIP's inter-class confusion can result in semantic blindness. To address these issues, we present the Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS), a model that effectively distinguishes between semantic and geometric paths and mutually regularizes their gradients to achieve better generalization. DA-FSS employs the same backbone and pre-trained text encoder as MM-FSS to generate text embeddings, which can increase free modalities' utilization rate and better leverage each modality's information space. To achieve this, we propose a Parallel Expert Refinement module to generate each modal correlation. We also propose a Stacked Arbitration Module (SAM) to perform convolutional fusion and arbitrate correlations for each modality pathway. The Parallel Experts decouple two paths: a Geometric Expert maintains plasticity, and a Semantic Expert ensures stability. They are coordinated via a Decoupled Alignment Module (DAM) that transfers knowledge without propagating confusion. Experiments on popular datasets (S3DIS, ScanNet) demonstrate the superiority of DA-FSS over MM-FSS. Meanwhile, geometric boundaries, completeness, and texture differentiation are all superior to the baseline. The code is available at: https://github.com/MoWenQAQ/DA-FSS.

</details>


### [127] [DeepInv: A Novel Self-supervised Learning Approach for Fast and Accurate Diffusion Inversion](https://arxiv.org/abs/2601.01487)
*Ziyue Zhang,Luxi Lin,Xiaolin Hu,Chao Chang,HuaiXi Wang,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: 提出一种名为DeepInv的自监督扩散反演方法，通过自监督目标和数据增强生成高质量伪噪声，训练参数化反演求解器实现快速准确的图像到噪声映射。


<details>
  <summary>Details</summary>
Motivation: 扩散反演任务缺乏可行的监督信号，现有方法多依赖近似解，常以性能或效率为代价。

Method: 设计自监督目标函数和数据增强策略生成伪噪声，采用迭代多尺度训练机制训练参数化反演求解器，实现逐步噪声预测。

Result: 在COCO数据集上，SSIM比EasyInv提升40.435%，推理速度比ReNoise快9887.5%。

Conclusion: DeepInv在性能和推理速度上显著优于现有方法，其可训练求解器设计为社区提供了新思路。

Abstract: Diffusion inversion is a task of recovering the noise of an image in a diffusion model, which is vital for controllable diffusion image editing. At present, diffusion inversion still remains a challenging task due to the lack of viable supervision signals. Thus, most existing methods resort to approximation-based solutions, which however are often at the cost of performance or efficiency. To remedy these shortcomings, we propose a novel self-supervised diffusion inversion approach in this paper, termed Deep Inversion (DeepInv). Instead of requiring ground-truth noise annotations, we introduce a self-supervised objective as well as a data augmentation strategy to generate high-quality pseudo noises from real images without manual intervention. Based on these two innovative designs, DeepInv is also equipped with an iterative and multi-scale training regime to train a parameterized inversion solver, thereby achieving the fast and accurate image-to-noise mapping. To the best of our knowledge, this is the first attempt of presenting a trainable solver to predict inversion noise step by step. The extensive experiments show that our DeepInv can achieve much better performance and inference speed than the compared methods, e.g., +40.435% SSIM than EasyInv and +9887.5% speed than ReNoise on COCO dataset. Moreover, our careful designs of trainable solvers can also provide insights to the community. Codes and model parameters will be released in https://github.com/potato-kitty/DeepInv.

</details>


### [128] [AirSpatialBot: A Spatially-Aware Aerial Agent for Fine-Grained Vehicle Attribute Recognization and Retrieval](https://arxiv.org/abs/2601.01416)
*Yue Zhou,Ran Ding,Xue Yang,Xue Jiang,Xingzhao Liu*

Main category: cs.CV

TL;DR: 该研究针对遥感视觉语言模型的空间理解不足问题，提出了包含20.6万条指令的AirSpatial数据集和两阶段训练方法，开发了具备空间感知能力的无人机车辆分析智能体AirSpatialBot。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型在空间理解方面存在局限，影响了实际应用效果，特别是在无人机车辆图像分析场景中需要更精细的空间感知能力。

Method: 1) 构建包含空间标注和3D边界框的AirSpatial数据集；2) 采用两阶段训练策略：图像理解预训练和空间理解微调；3) 开发集成任务规划、图像理解、空间理解和任务执行能力的AirSpatialBot智能体。

Result: 实验验证了方法的有效性，揭示了现有VLMs的空间局限性，同时实现了细粒度车辆属性识别和检索功能。

Conclusion: 该研究通过数据集、训练方法和智能体的创新，显著提升了遥感视觉语言模型的空间理解能力，为无人机图像分析提供了新解决方案。

Abstract: Despite notable advancements in remote sensing vision-language models (VLMs), existing models often struggle with spatial understanding, limiting their effectiveness in real-world applications. To push the boundaries of VLMs in remote sensing, we specifically address vehicle imagery captured by drones and introduce a spatially-aware dataset AirSpatial, which comprises over 206K instructions and introduces two novel tasks: Spatial Grounding and Spatial Question Answering. It is also the first remote sensing grounding dataset to provide 3DBB. To effectively leverage existing image understanding of VLMs to spatial domains, we adopt a two-stage training strategy comprising Image Understanding Pre-training and Spatial Understanding Fine-tuning. Utilizing this trained spatially-aware VLM, we develop an aerial agent, AirSpatialBot, which is capable of fine-grained vehicle attribute recognition and retrieval. By dynamically integrating task planning, image understanding, spatial understanding, and task execution capabilities, AirSpatialBot adapts to diverse query requirements. Experimental results validate the effectiveness of our approach, revealing the spatial limitations of existing VLMs while providing valuable insights. The model, code, and datasets will be released at https://github.com/VisionXLab/AirSpatialBot

</details>


### [129] [FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01513)
*Gen Li,Peiyu Liu*

Main category: cs.CV

TL;DR: 提出VideoSpeculateRAG框架，通过推测解码和实体过滤提升视觉语言模型在检索增强生成中的效率和准确性


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在整合外部知识方面存在困难，传统检索增强生成方法效率低下且答案质量不稳定

Method: 1. 推测解码流水线：轻量级草稿模型快速生成多个候选答案，由精确的重型模型验证优化；2. 基于相似度的实体过滤策略，改善检索知识中的实体对齐

Result: 相比标准RAG方法，在保持相当或更高准确率的同时，推理速度提升约2倍

Conclusion: 结合推测解码与检索增强推理能有效提升知识密集型多模态任务的效率和可靠性

Abstract: Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.

</details>


### [130] [DreamID-V:Bridging the Image-to-Video Gap for High-Fidelity Face Swapping via Diffusion Transformer](https://arxiv.org/abs/2601.01425)
*Xu Guo,Fulong Ye,Xinghui Li,Pengqi Tu,Pengze Zhang,Qichao Sun,Songtao Zhao,Xiangwang Hou,Qian He*

Main category: cs.CV

TL;DR: 提出DreamID-V框架，通过SyncID-Pipe数据管道和Diffusion Transformer架构，结合模态感知条件模块和课程学习策略，实现高质量视频人脸交换，并在IDBench-V基准上验证了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频人脸交换方法在保持身份相似性、属性一致性和时序连续性方面存在不足，缺乏高质量基准数据集，需要将图像人脸交换的优势迁移到视频领域。

Method: 1. SyncID-Pipe数据管道预训练身份锚定视频合成器，与图像人脸交换模型构建双向ID四元组监督；2. DreamID-V框架基于Diffusion Transformer，采用模态感知条件模块注入多模态条件；3. 合成到真实的课程学习机制和身份一致性强化学习策略提升真实感；4. 构建IDBench-V多场景基准数据集。

Result: 实验表明DreamID-V在身份相似性、属性保持和时序一致性上优于现有方法，可泛化至多种交换相关任务，在IDBench-V基准上表现优异。

Conclusion: 该框架通过系统化数据构建、先进模型架构和针对性训练策略，有效解决了视频人脸交换的核心挑战，为相关任务提供了通用解决方案。

Abstract: Video Face Swapping (VFS) requires seamlessly injecting a source identity into a target video while meticulously preserving the original pose, expression, lighting, background, and dynamic information. Existing methods struggle to maintain identity similarity and attribute preservation while preserving temporal consistency. To address the challenge, we propose a comprehensive framework to seamlessly transfer the superiority of Image Face Swapping (IFS) to the video domain. We first introduce a novel data pipeline SyncID-Pipe that pre-trains an Identity-Anchored Video Synthesizer and combines it with IFS models to construct bidirectional ID quadruplets for explicit supervision. Building upon paired data, we propose the first Diffusion Transformer-based framework DreamID-V, employing a core Modality-Aware Conditioning module to discriminatively inject multi-model conditions. Meanwhile, we propose a Synthetic-to-Real Curriculum mechanism and an Identity-Coherence Reinforcement Learning strategy to enhance visual realism and identity consistency under challenging scenarios. To address the issue of limited benchmarks, we introduce IDBench-V, a comprehensive benchmark encompassing diverse scenes. Extensive experiments demonstrate DreamID-V outperforms state-of-the-art methods and further exhibits exceptional versatility, which can be seamlessly adapted to various swap-related tasks.

</details>


### [131] [EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding](https://arxiv.org/abs/2601.01547)
*Tianjun Gu,Chenghua Gong,Jingyu Gong,Zhizhong Zhang,Yuan Xie,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: 本文提出Teleo-Spatial Intelligence（TSI）新范式，结合物理动态推理和意图驱动推理，并构建EscherVerse基准（含数据集和模型）来评估智能体在开放世界中的空间动态理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视空间变化背后的人类意图，缺乏对动态、以人为中心场景中目的驱动推理的系统评估。

Method: 提出TSI理论框架，构建EscherVerse基准（含Escher-Bench评估标准、Escher-35k真实世界视频数据集、Escher系列模型），并设计新颖数据筛选流程。

Result: 创建首个系统评估意图驱动推理的基准，推动空间智能从被动场景描述转向对世界的整体目的驱动理解。

Conclusion: TSI范式及EscherVerse资源为空间智能研究奠定基础，强调物理动态与人类意图的统一推理是实现全面空间理解的关键。

Abstract: The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.

</details>


### [132] [EdgeNeRF: Edge-Guided Regularization for Neural Radiance Fields from Sparse Views](https://arxiv.org/abs/2601.01431)
*Weiqi Yu,Yiyang Yao,Lin He,Jianming Lv*

Main category: cs.CV

TL;DR: EdgeNeRF通过边缘引导的深度正则化方法，在稀疏视角下提升NeRF的3D重建质量，保留几何边界细节并减少伪影。


<details>
  <summary>Details</summary>
Motivation: 传统NeRF在稀疏输入下重建质量下降，现有全局深度正则化方法会丢失几何边界细节，需要更精细的几何约束方法。

Method: 提出EdgeNeRF算法：1）从输入图像提取边缘；2）在非边缘区域施加深度和法向正则化约束；3）保持边界高频细节的同时增强几何一致性。

Result: 在LLFF和DTU数据集上表现优异，能有效保留锐利几何边界并抑制伪影，且模块可即插即用提升其他方法性能，训练时间增加不明显。

Conclusion: 边缘引导的稀疏视角3D重建方法能有效平衡几何一致性与细节保留，为NeRF的稀疏输入问题提供了实用解决方案。

Abstract: Neural Radiance Fields (NeRF) achieve remarkable performance in dense multi-view scenarios, but their reconstruction quality degrades significantly under sparse inputs due to geometric artifacts. Existing methods utilize global depth regularization to mitigate artifacts, leading to the loss of geometric boundary details. To address this problem, we propose EdgeNeRF, an edge-guided sparse-view 3D reconstruction algorithm. Our method leverages the prior that abrupt changes in depth and normals generate edges. Specifically, we first extract edges from input images, then apply depth and normal regularization constraints to non-edge regions, enhancing geometric consistency while preserving high-frequency details at boundaries. Experiments on LLFF and DTU datasets demonstrate EdgeNeRF's superior performance, particularly in retaining sharp geometric boundaries and suppressing artifacts. Additionally, the proposed edge-guided depth regularization module can be seamlessly integrated into other methods in a plug-and-play manner, significantly improving their performance without substantially increasing training time. Code is available at https://github.com/skyhigh404/edgenerf.

</details>


### [133] [FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation](https://arxiv.org/abs/2601.01687)
*Abdur R. Fayjie,Pankhi Kashyap,Jutika Borah,Patrick Vandewalle*

Main category: cs.CV

TL;DR: 提出FALCON框架，通过2D切片处理实现高精度3D医学图像分割，在少标注、低计算开销下达到优异边界精度


<details>
  <summary>Details</summary>
Motivation: 解决3D医学图像分割面临的标注稀缺、患者个体差异、数据隐私和计算成本高的临床落地障碍

Method: 跨域少样本分割框架：先在自然图像上元训练学习泛化先验，再通过对抗微调和边界感知学习迁移到医学领域，支持任务感知推理适应患者特异性变化

Result: 在四个基准测试中均取得最低Hausdorff距离（边界精度最优），Dice系数与SOTA相当，且使用更少标注数据、无数据增强、计算开销显著降低

Conclusion: FALCON通过2D切片处理和跨域学习策略，为临床可行的3D医学图像分割提供了高效、精准且数据高效的解决方案

Abstract: Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.

</details>


### [134] [In defense of the two-stage framework for open-set domain adaptive semantic segmentation](https://arxiv.org/abs/2601.01439)
*Wenqi Ren,Weijie Wang,Meng Zheng,Ziyan Wu,Yang Tang,Zhun Zhong,Nicu Sebe*

Main category: cs.CV

TL;DR: 本文提出SATS方法，通过先分离后适应的两阶段训练策略解决开放集语义分割的域适应问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放集域适应方法在单阶段中同时处理已知类和未知类，由于标注不平衡导致已知类负迁移和未知类欠拟合，需要更有效的训练策略。

Method: 提出SATS两阶段策略：1) 已知/未知类分离；2) 未知类感知的域适应。并引入硬未知探索数据增强方法，增强模型对未知类的识别能力。

Result: 在GTA5-to-Cityscapes和SYNTHIA-to-Cityscapes基准测试中，H-Score分别提升3.85%和18.64%，优于现有最优方法。

Conclusion: 分离训练策略能更平衡地学习已知类和未知类的判别特征，有效提升开放集语义分割的域适应性能。

Abstract: Open-Set Domain Adaptation for Semantic Segmentation (OSDA-SS) presents a significant challenge, as it requires both domain adaptation for known classes and the distinction of unknowns. Existing methods attempt to address both tasks within a single unified stage. We question this design, as the annotation imbalance between known and unknown classes often leads to negative transfer of known classes and underfitting for unknowns. To overcome these issues, we propose SATS, a Separating-then-Adapting Training Strategy, which addresses OSDA-SS through two sequential steps: known/unknown separation and unknown-aware domain adaptation. By providing the model with more accurate and well-aligned unknown classes, our method ensures a balanced learning of discriminative features for both known and unknown classes, steering the model toward discovering truly unknown objects. Additionally, we present hard unknown exploration, an innovative data augmentation method that exposes the model to more challenging unknowns, strengthening its ability to capture more comprehensive understanding of target unknowns. We evaluate our method on public OSDA-SS benchmarks. Experimental results demonstrate that our method achieves a substantial advancement, with a +3.85% H-Score improvement for GTA5-to-Cityscapes and +18.64% for SYNTHIA-to-Cityscapes, outperforming previous state-of-the-art methods.

</details>


### [135] [Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery](https://arxiv.org/abs/2601.01781)
*Lakshay Sharma,Alex Marin*

Main category: cs.CV

TL;DR: 提出一种名为子图像重叠预测的自监督预训练任务，用于遥感图像语义分割，能在较少预训练数据下实现更快收敛和同等或更好的下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法通常依赖大量预训练数据，而遥感图像标注成本高、数据获取有限，需要开发数据效率更高的预训练方法。

Method: 从原始图像中提取子图像，训练模型预测该子图像在原始图像中的位置语义掩码，构建自监督预训练任务。

Result: 该方法在多个架构和下游数据集上均实现更快收敛，在减少标注数据时优势更明显，且性能相当或优于其他自监督方法，同时所需预训练数据显著减少。

Conclusion: 子图像重叠预测是一种高效的自监督预训练方法，特别适用于数据有限的遥感图像语义分割任务，能有效提升模型训练效率和性能。

Abstract: Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.

</details>


### [136] [VerLM: Explaining Face Verification Using Natural Language](https://arxiv.org/abs/2601.01798)
*Syed Abdul Hannan,Hazim Bukhari,Thomas Cantalapiedra,Eman Ansar,Massa Baali,Rita Singh,Bhiksha Raj*

Main category: cs.CV

TL;DR: 本文提出了一种创新的视觉语言模型用于人脸验证，该模型不仅能准确判断两张人脸图像是否为同一人，还能解释其决策依据。


<details>
  <summary>Details</summary>
Motivation: 当前人脸验证系统虽然取得了显著进展，但通常缺乏决策过程的透明度，这限制了其可靠性和可信度。

Method: 采用两种互补的解释风格训练模型：简洁解释（总结关键影响因素）和详细解释（描述图像间的具体差异）。通过将音频区分任务的先进建模方法适配并增强至视觉输入，实现跨模态迁移。

Result: 所提出的模型在准确性和可解释性方面均显著提升，性能优于基线方法和现有模型。

Conclusion: 视觉语言模型在人脸验证中具有巨大潜力，能够为构建更透明、可靠和可解释的人脸验证系统做出贡献。

Abstract: Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.

</details>


### [137] [PartImageNet++ Dataset: Enhancing Visual Models with High-Quality Part Annotations](https://arxiv.org/abs/2601.01454)
*Xiao Li,Zilong Liu,Yining Liu,Zhuhong Li,Na Dong,Sitian Qin,Xiaolin Hu*

Main category: cs.CV

TL;DR: 提出了PartImageNet++（PIN++）数据集，为ImageNet-1K所有类别提供详细部件标注，并基于此开发了多尺度部件监督识别模型（MPM），在多个下游任务中验证了部件标注对模型性能的提升作用。


<details>
  <summary>Details</summary>
Motivation: 现有数据集中高质量部件标注稀缺，限制了部件级视觉理解模型的发展，需要构建更全面的部件标注数据集以支持相关研究。

Method: 1. 构建PIN++数据集（每类100张标注图像，共10万张）；2. 训练部件分割网络生成未标注图像的伪部件标签；3. 设计MPM模型，结合传统识别架构与辅助旁路层，联合监督使用伪标签和原始标注；4. 在部件分割、物体分割、小样本学习等任务进行实验验证。

Result: 1. PIN++成为覆盖最广的物体部件标注数据集；2. MPM显著提升了基于部件的物体识别鲁棒性；3. 在多个下游任务中建立了强基线，证明了部件标注对模型性能的改进潜力。

Conclusion: 部件标注能有效提升视觉模型的识别能力和泛化性能，PIN++数据集和MPM模型为部件级视觉理解研究提供了重要基础资源和技术方案。

Abstract: To address the scarcity of high-quality part annotations in existing datasets, we introduce PartImageNet++ (PIN++), a dataset that provides detailed part annotations for all categories in ImageNet-1K. With 100 annotated images per category, totaling 100K images, PIN++ represents the most comprehensive dataset covering a diverse range of object categories. Leveraging PIN++, we propose a Multi-scale Part-supervised recognition Model (MPM) for robust classification on ImageNet-1K. We first trained a part segmentation network using PIN++ and used it to generate pseudo part labels for the remaining unannotated images. MPM then integrated a conventional recognition architecture with auxiliary bypass layers, jointly supervised by both pseudo part labels and the original part annotations. Furthermore, we conducted extensive experiments on PIN++, including part segmentation, object segmentation, and few-shot learning, exploring various ways to leverage part annotations in downstream tasks. Experimental results demonstrated that our approach not only enhanced part-based models for robust object recognition but also established strong baselines for multiple downstream tasks, highlighting the potential of part annotations in improving model performance. The dataset and the code are available at https://github.com/LixiaoTHU/PartImageNetPP.

</details>


### [138] [Language as Prior, Vision as Calibration: Metric Scale Recovery for Monocular Depth Estimation](https://arxiv.org/abs/2601.01457)
*Mingxing Zhan,Li Zhang,Beibei Wang,Yingjie Wang,Zenglin Shi*

Main category: cs.CV

TL;DR: 提出一种使用语言引导的不确定性感知校准方法，从相对深度基础模型中恢复单目度量深度，通过轻量级校准头实现，在多个数据集上提升了精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 单目度量深度估计因全局尺度不可识别和域偏移敏感而难以解决，现有相对深度基础模型虽迁移性好，但缺乏精确尺度信息。

Method: 在冻结相对深度骨干网络和CLIP文本编码器的基础上，训练轻量级校准头，利用语言预测不确定性感知的参数范围（包络），再通过多尺度视觉特征选择图像特定的仿射变换进行校准。

Result: 在NYUv2和KITTI数据集上提升了域内精度，在SUN-RGBD和DDAD上的零样本迁移表现出优于纯语言基线的鲁棒性。

Conclusion: 通过语言引导的不确定性校准，能够有效从相对深度模型中恢复度量深度，同时保持模型的轻量化和跨域鲁棒性。

Abstract: Relative-depth foundation models transfer well, yet monocular metric depth remains ill-posed due to unidentifiable global scale and heightened domain-shift sensitivity. Under a frozen-backbone calibration setting, we recover metric depth via an image-specific affine transform in inverse depth and train only lightweight calibration heads while keeping the relative-depth backbone and the CLIP text encoder fixed. Since captions provide coarse but noisy scale cues that vary with phrasing and missing objects, we use language to predict an uncertainty-aware envelope that bounds feasible calibration parameters in an unconstrained space, rather than committing to a text-only point estimate. We then use pooled multi-scale frozen visual features to select an image-specific calibration within this envelope. During training, a closed-form least-squares oracle in inverse depth provides per-image supervision for learning the envelope and the selected calibration. Experiments on NYUv2 and KITTI improve in-domain accuracy, while zero-shot transfer to SUN-RGBD and DDAD demonstrates improved robustness over strong language-only baselines.

</details>


### [139] [Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network](https://arxiv.org/abs/2601.01460)
*Mohd Usama,Belal Ahmad,Christer Gronlund,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 提出一种基于生成对抗网络的模型，用于解决超声图像中因设备差异导致的域适应问题，通过图像转换统一纹理模式并去除混响噪声。


<details>
  <summary>Details</summary>
Motivation: 医学影像中，不同设备或参数生成的图像存在纹理和噪声差异，导致模型跨域性能下降，而针对每个设备重新训练成本高昂。

Method: 将域适应任务构建为图像到图像的转换问题，使用改进的生成对抗网络模型，在保留图像内容的同时调整纹理并去除混响噪声。

Result: 模型成功转换了颈动脉超声图像的纹理模式并去除噪声；在两项数据集上，域适应效果（直方图相关性0.960/0.920，巴氏距离0.040/0.085）显著优于未适应情况（0.916/0.890，0.090/0.121）。

Conclusion: 所提出的GAN模型能有效实现超声图像的域适应，提升模型跨设备泛化能力，为医学影像分析中的域偏移问题提供了可行解决方案。

Abstract: Deep learning has been extensively used in medical imaging applications, assuming that the test and training datasets belong to the same probability distribution. However, a common challenge arises when working with medical images generated by different systems or even the same system with different parameter settings. Such images contain diverse textures and reverberation noise that violate the aforementioned assumption. Consequently, models trained on data from one device or setting often struggle to perform effectively with data from other devices or settings. In addition, retraining models for each specific device or setting is labor-intensive and costly. To address these issues in ultrasound images, we propose a novel Generative Adversarial Network (GAN)-based model. We formulated the domain adaptation tasks as an image-to-image translation task, in which we modified the texture patterns and removed reverberation noise in the test data images from the source domain to align with those in the target domain images while keeping the image content unchanged. We applied the proposed method to two datasets containing carotid ultrasound images from three different domains. The experimental results demonstrate that the model successfully translated the texture pattern of images and removed reverberation noise from the ultrasound images. Furthermore, we evaluated the CycleGAN approaches for a comparative study with the proposed model. The experimental findings conclusively demonstrated that the proposed model achieved domain adaptation (histogram correlation (0.960 (0.019), & 0.920 (0.043) and bhattacharya distance (0.040 (0.020), & 0.085 (0.048)), compared to no adaptation (0.916 (0.062) & 0.890 (0.077), 0.090 (0.070) & 0.121 (0.095)) for both datasets.

</details>


### [140] [Robust Ship Detection and Tracking Using Modified ViBe and Backwash Cancellation Algorithm](https://arxiv.org/abs/2601.01481)
*Mohammad Hassan Saghafi,Seyed Majid Noorhosseini,Seyed Abolfazl Seyed Javadein,Hadi Khalili*

Main category: cs.CV

TL;DR: 提出了一种用于海岸视频序列中船舶检测与跟踪的鲁棒实时方法，通过改进ViBe算法降低船舶丢失概率，并引入新的尾流消除技术。


<details>
  <summary>Details</summary>
Motivation: 海岸场景具有不可预测性和动态特性（如海浪、光照变化），需要鲁棒的检测方法以适应这些复杂条件。

Method: 1. 改进ViBe运动目标检测算法，增强背景更新速度和对海浪/光照的鲁棒性；2. 基于船舶几何特征和亮度失真等概念设计新的尾流消除方法。

Result: 实验表明，所提策略在船舶检测与跟踪中表现优异，具备实时性和高精度。

Conclusion: 该方法能有效应对海岸动态环境，在船舶检测与跟踪任务中实现了鲁棒、实时且精确的性能。

Abstract: In this paper, we propose a robust real time detection and tracking method for detecting ships in a coastal video sequences. Since coastal scenarios are unpredictable and scenes have dynamic properties it is essential to apply detection methods that are robust to these conditions. This paper presents modified ViBe for moving object detection which detects ships and backwash. In the modified ViBe the probability of losing ships is decreased in comparison with the original ViBe. It is robust to natural sea waves and variation of lights and is capable of quickly updating the background. Based on geometrical properties of ship and some concepts such as brightness distortion, a new method for backwash cancellation is proposed. Experimental results demonstrate that the proposed strategy and methods have outstanding performance in ship detection and tracking. These results also illustrate real time and precise performance of the proposed strategy.

</details>


### [141] [RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images](https://arxiv.org/abs/2601.01835)
*Rashid Iqbal,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 提出了一种名为RSwinV2的深度学习模型，用于Mpox（猴痘）诊断，通过结合Transformer和逆残差块增强病灶分类能力，在公开数据集上取得了优于CNN和SwinTransformer的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在Mpox病灶分类中存在局部区域关联效率低、梯度消失等问题，需要一种能同时捕捉全局和局部特征的高效计算机辅助诊断工具。

Method: 基于SwinTransformerV2定制化开发RSwinV2模型，采用分层Transformer结构、非重叠图像块划分、移位窗口注意力机制，并引入逆残差块（IRB）和卷积跳跃连接以解决梯度消失问题。

Result: 在Kaggle公开数据集上达到96.21%的准确率和95.62%的F1分数，优于传统CNN和SwinTransformer模型，能有效区分Mpox、水痘、麻疹和牛痘。

Conclusion: RSwinV2通过融合Transformer的全局关联能力和IRB的局部特征提取能力，显著提升了Mpox病灶分类的准确性和鲁棒性，验证了其作为计算机辅助诊断工具的有效性。

Abstract: In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.

</details>


### [142] [Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification](https://arxiv.org/abs/2601.01807)
*Ubaidullah,Muhammad Abid Hussain,Mohsin Raza Jafri,Rozi Khan,Moid Sandhu,Abd Ullah Khan,Hyundong Shin*

Main category: cs.CV

TL;DR: 本文提出了一种名为LUMPNet的混合深度学习模型，用于早期检测牛结节性皮肤病（LSD）。该模型结合YOLOv11进行病变检测定位、EfficientNet进行分类，并采用新型自适应混合优化器，在公开数据集上取得了99%的训练准确率和98%的验证准确率，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 牛结节性皮肤病（LSD）是一种传染性病毒疾病，严重危害牲畜健康，对全球经济和粮食安全构成威胁。由于其传播迅速，早期精准识别对于预防疫情爆发和及时干预至关重要。

Method: 提出LUMPNet混合深度学习框架：1）使用YOLOv11检测和定位牛图像中的皮肤结节病变；2）采用基于EfficientNet的CNN分类器对局部图像进行LSD感染或健康的分类；3）提出并应用一种新型自适应混合优化器，以稳定和加速YOLOv11与EfficientNet混合模型的训练。

Result: 在公开数据集上的评估显示：1）LUMPNet达到99%的LSD检测训练准确率和98%的验证准确率；2）性能优于现有方案；3）案例研究中，与使用AdamW优化器的EfficientNet-B0模型相比，LUMPNet表现出更优性能。

Conclusion: LUMPNet通过结合目标检测、分类和新型优化器，实现了对牛结节性皮肤病的高精度早期检测，为疾病防控提供了有效的自动化工具，有助于减少经济损失并保障粮食安全。

Abstract: Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.

</details>


### [143] [CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving](https://arxiv.org/abs/2601.01874)
*Shuhang Chen,Yunqiu Xu,Junjie Xie,Aojun Lu,Tao Feng,Zeying Huang,Ning Zhang,Yi Sun,Yi Yang,Hangjie Yuan*

Main category: cs.CV

TL;DR: 提出CogFlow框架，通过知识内化阶段模拟人类推理流程，提升多模态大语言模型的视觉数学问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注视觉输入的提取和解释，忽略了提取的视觉线索是否被忠实整合并合理用于后续推理这一关键问题。

Method: 1. 设计三阶段认知框架（感知→内化→推理）；2. 提出协同视觉奖励提升感知能力；3. 引入知识内化奖励模型确保视觉线索整合；4. 设计视觉门控策略优化算法防止推理脱离视觉依据；5. 构建包含12万高质量标注的MathCog数据集。

Result: 在常用视觉数学推理基准测试中，CogFlow表现出优越性能，验证了框架的有效性。

Conclusion: 通过模拟人类分层推理流程并系统增强各阶段，CogFlow能显著提升视觉数学问题解决的准确性和可靠性。

Abstract: Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\Rightarrow$internalization$\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.

</details>


### [144] [Unified Generation and Self-Verification for Vision-Language Models via Advantage Decoupled Preference Optimization](https://arxiv.org/abs/2601.01483)
*Xinyu Qiu,Heng Jia,Zhengwen Zeng,Shuheng Shen,Changhua Meng,Yi Yang,Linchao Zhu*

Main category: cs.CV

TL;DR: 提出ADPO框架，在单一策略中联合学习答案生成与自我验证，通过偏好验证奖励和解耦优化机制提升性能并降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 传统并行测试时扩展方法需分别训练生成与验证模型，导致训练和推理成本高昂，需要更高效的统一框架。

Method: ADPO框架包含偏好验证奖励（通过正负样本计算阈值对齐预测与答案正确性）和解耦优化机制（分别计算生成与验证的优势值，应用token掩码隔离梯度，结合掩码GRPO目标）。

Result: 验证AUC最高提升34.1%，推理时间降低53.5%，MathVista/MMMU准确率分别提升2.8%/1.4%，ReasonSeg提升1.9 cIoU，AndroidControl/GUI Odyssey步骤成功率提升1.7%/1.0%。

Conclusion: ADPO能有效统一生成与验证学习，在提升多项任务性能的同时显著降低推理开销，为高效测试时扩展提供了新方案。

Abstract: Parallel test-time scaling typically trains separate generation and verification models, incurring high training and inference costs. We propose Advantage Decoupled Preference Optimization (ADPO), a unified reinforcement learning framework that jointly learns answer generation and self-verification within a single policy. ADPO introduces two innovations: a preference verification reward improving verification capability and a decoupled optimization mechanism enabling synergistic optimization of generation and verification. Specifically, the preference verification reward computes mean verification scores from positive and negative samples as decision thresholds, providing positive feedback when prediction correctness aligns with answer correctness. Meanwhile, the advantage decoupled optimization computes separate advantages for generation and verification, applies token masks to isolate gradients, and combines masked GRPO objectives, preserving generation quality while calibrating verification scores. ADPO achieves up to +34.1% higher verification AUC and -53.5% lower inference time, with significant gains of +2.8%/+1.4% accuracy on MathVista/MMMU, +1.9 cIoU on ReasonSeg, and +1.7%/+1.0% step success rate on AndroidControl/GUI Odyssey.

</details>


### [145] [Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease](https://arxiv.org/abs/2601.01485)
*Zobia Batool,Diala Lteif,Vijaya B. Kolachalama,Huseyin Ozkan,Erchan Aptoula*

Main category: cs.CV

TL;DR: 提出Extended MixStyle框架，通过混合高阶特征矩来模拟分布变化，提升阿尔茨海默病sMRI分类模型在未见数据集上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于sMRI的深度学习模型在不同扫描仪、协议和人群的数据集间存在领域偏移问题，导致泛化性能下降，而单领域泛化方法在阿尔茨海默病诊断中研究不足但至关重要。

Method: 提出Extended MixStyle框架，在特征层面混合高阶统计矩（偏度和峰度）以模拟多样化的分布变化；使用NACC数据集训练模型区分正常认知、轻度认知障碍和阿尔茨海默病，并在三个未见数据集上测试。

Result: 在三个未见队列上，Extended MixStyle相比现有单领域泛化基准方法平均提升宏F1分数2.4个百分点，表现出更好的跨领域性能。

Conclusion: Extended MixStyle能够有效提升阿尔茨海默病sMRI分类模型在异构真实场景中的泛化性和可靠性，为临床部署提供了有前景的解决方案。

Abstract: Despite progress in deep learning for Alzheimer's disease (AD) diagnostics, models trained on structural magnetic resonance imaging (sMRI) often do not perform well when applied to new cohorts due to domain shifts from varying scanners, protocols and patient demographics. AD, the primary driver of dementia, manifests through progressive cognitive and neuroanatomical changes like atrophy and ventricular expansion, making robust, generalizable classification essential for real-world use. While convolutional neural networks and transformers have advanced feature extraction via attention and fusion techniques, single-domain generalization (SDG) remains underexplored yet critical, given the fragmented nature of AD datasets. To bridge this gap, we introduce Extended MixStyle (EM), a framework for blending higher-order feature moments (skewness and kurtosis) to mimic diverse distributional variations. Trained on sMRI data from the National Alzheimer's Coordinating Center (NACC; n=4,647) to differentiate persons with normal cognition (NC) from those with mild cognitive impairment (MCI) or AD and tested on three unseen cohorts (total n=3,126), EM yields enhanced cross-domain performance, improving macro-F1 on average by 2.4 percentage points over state-of-the-art SDG benchmarks, underscoring its promise for invariant, reliable AD detection in heterogeneous real-world settings. The source code will be made available upon acceptance at https://github.com/zobia111/Extended-Mixstyle.

</details>


### [146] [Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection](https://arxiv.org/abs/2601.01908)
*Jingjing Wang,Qianglin Liu,Zhuo Xiao,Xinning Yao,Bo Liu,Lu Li,Lijuan Niu,Fugen Zhou*

Main category: cs.CV

TL;DR: 提出Nodule-DETR，一种基于检测变换器的新架构，用于超声图像中甲状腺结节的鲁棒检测，通过多谱频域通道注意力、分层特征融合和多尺度可变形注意力模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 甲状腺癌发病率上升，超声检测甲状腺结节时因图像对比度低、结节边界模糊导致诊断准确性受限，需改进检测方法。

Method: 设计Nodule-DETR架构，包含多谱频域通道注意力模块（利用频域分析增强低对比度结节特征）、分层特征融合模块（高效多尺度集成）和多尺度可变形注意力模块（灵活捕捉小而不规则形状结节）。

Result: 在真实临床甲状腺超声数据集上实验显示，Nodule-DETR达到最先进性能，mAP@0.5:0.95比基线模型显著提升0.149。

Conclusion: Nodule-DETR的高准确性凸显其作为计算机辅助甲状腺诊断工具的巨大临床潜力，代码已开源。

Abstract: Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.

</details>


### [147] [DiffKD-DCIS: Predicting Upgrade of Ductal Carcinoma In Situ with Diffusion Augmentation and Knowledge Distillation](https://arxiv.org/abs/2601.01507)
*Tao Li,Qing Li,Na Li,Hui Xie*

Main category: cs.CV

TL;DR: 提出DiffKD-DCIS框架，结合条件扩散模型与知识蒸馏，用于预测乳腺导管原位癌升级为浸润性导管癌，提升超声图像分析性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在超声数据有限、泛化能力差的情况下，难以准确预测DCIS升级为IDC，影响手术规划。

Method: 采用三阶段框架：1) 条件扩散模型生成高质量合成超声图像进行数据增强；2) 深度教师网络从原始和合成数据中提取鲁棒特征；3) 紧凑学生网络通过知识蒸馏向教师学习，平衡泛化与计算效率。

Result: 在1,435例多中心数据上验证，合成图像质量良好；学生网络参数量少、推理速度快；在外部测试集上性能优于部分组合方法，准确率与资深放射科医生相当，优于初级医生。

Conclusion: DiffKD-DCIS框架具有显著临床潜力，能有效提升DCIS升级预测的准确性和泛化能力。

Abstract: Accurately predicting the upgrade of ductal carcinoma in situ (DCIS) to invasive ductal carcinoma (IDC) is crucial for surgical planning. However, traditional deep learning methods face challenges due to limited ultrasound data and poor generalization ability. This study proposes the DiffKD-DCIS framework, integrating conditional diffusion modeling with teacher-student knowledge distillation.
  The framework operates in three stages: First, a conditional diffusion model generates high-fidelity ultrasound images using multimodal conditions for data augmentation. Then, a deep teacher network extracts robust features from both original and synthetic data. Finally, a compact student network learns from the teacher via knowledge distillation, balancing generalization and computational efficiency.
  Evaluated on a multi-center dataset of 1,435 cases, the synthetic images were of good quality. The student network had fewer parameters and faster inference. On external test sets, it outperformed partial combinations, and its accuracy was comparable to senior radiologists and superior to junior ones, showing significant clinical potential.

</details>


### [148] [Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach](https://arxiv.org/abs/2601.02016)
*Matthias Bartolo,Dylan Seychell,Gabriel Hili,Matthew Montebello,Carl James Debono,Saviour Formosa,Konstantinos Makantasis*

Main category: cs.CV

TL;DR: 本文提出了一种将特权学习范式应用于目标检测的方法，通过教师-学生架构在训练时利用边界框掩码、显著性图等额外信息，提升检测精度而不增加推理复杂度。


<details>
  <summary>Details</summary>
Motivation: 目标检测训练时通常可获得比推理时更丰富的标注信息（如精细掩码、深度线索等），但传统方法未能充分利用这些‘特权信息’。研究旨在探索如何系统地将此类信息融入检测模型以提升性能。

Method: 提出模型无关的教师-学生架构：教师模型接收特权信息（如掩码、显著性图、深度图）和标准图像输入，学生模型仅接收图像输入，通过知识蒸馏机制让学生学习教师的多模态表征。在五个先进检测模型和多个数据集（包括无人机垃圾检测数据集和Pascal VOC）上进行实验验证。

Result: 1. 特权学习训练的学生模型在所有基准测试中均超越基线模型，检测精度显著提升；2. 中大型物体检测改进尤为明显；3. 推理阶段未增加计算负担或模型参数量；4. 消融实验表明中等权重的教师指导能最优平衡特权信息与标准输入的学习。

Conclusion: 特权学习框架为目标检测提供了一种高效实用的增强策略，尤其在资源受限和真实场景中具有应用价值，能利用训练时的附加信息持续提升模型性能而不影响部署效率。

Abstract: This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.

</details>


### [149] [A Novel Deep Learning Method for Segmenting the Left Ventricle in Cardiac Cine MRI](https://arxiv.org/abs/2601.01512)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.CV

TL;DR: 提出GBU-Net，一种基于组批归一化U-Net的深度学习网络，用于短轴电影MRI中左心室的精确语义分割，在SunnyBrook测试集上达到97%的Dice分数。


<details>
  <summary>Details</summary>
Motivation: 传统基于CNN的分割方法在心脏MRI分割中常忽略上下文信息，需要一种能更好捕捉医学图像上下文、提高左心室分割精度的新方法，以支持手术机器人和医学分析。

Method: 采用U-Net框架，包含下采样特征提取和上采样细节恢复路径，引入组批归一化技术，并针对心脏MRI分割进行了关键改进以增强上下文理解。使用45名患者的805个左心室MRI扫描进行训练和评估。

Result: GBU-Net在左心室分割精度上显著提升，在SunnyBrook测试数据集上通过集成方法达到97%的Dice分数，在Dice系数和平均垂直距离等标准指标上优于现有方法。

Conclusion: GBU-Net通过创新的网络设计，在左心室MRI分割中实现了更高的精度和上下文理解能力，为手术机器人和医学分析提供了更可靠的工具。

Abstract: This research aims to develop a novel deep learning network, GBU-Net, utilizing a group-batch-normalized U-Net framework, specifically designed for the precise semantic segmentation of the left ventricle in short-axis cine MRI scans. The methodology includes a down-sampling pathway for feature extraction and an up-sampling pathway for detail restoration, enhanced for medical imaging. Key modifications include techniques for better contextual understanding crucial in cardiac MRI segmentation. The dataset consists of 805 left ventricular MRI scans from 45 patients, with comparative analysis using established metrics such as the dice coefficient and mean perpendicular distance. GBU-Net significantly improves the accuracy of left ventricle segmentation in cine MRI scans. Its innovative design outperforms existing methods in tests, surpassing standard metrics like the dice coefficient and mean perpendicular distance. The approach is unique in its ability to capture contextual information, often missed in traditional CNN-based segmentation. An ensemble of the GBU-Net attains a 97% dice score on the SunnyBrook testing dataset. GBU-Net offers enhanced precision and contextual understanding in left ventricle segmentation for surgical robotics and medical analysis.

</details>


### [150] [Agentic Retoucher for Text-To-Image Generation](https://arxiv.org/abs/2601.02046)
*Shaocheng Shen,Jianfeng Liang. Chunlei Cai,Cong Geng,Huiyu Duan,Xiaoyun Zhang,Qiang Hu,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出Agentic Retoucher框架，通过感知-推理-行动循环解决文本到图像生成中的局部失真问题，无需迭代重生成，在感知质量和失真定位上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型（如SDXL、FLUX）在肢体、面部、文字等细节上存在普遍的小尺度失真，现有细化方法要么成本高昂，要么依赖空间定位能力弱的视觉语言模型，导致语义漂移和不可靠的局部编辑。

Method: 提出分层决策驱动框架，包含：（1）感知代理：在文本-图像一致性线索下学习上下文显著性以定位细粒度失真；（2）推理代理：通过渐进偏好对齐进行类人推理诊断；（3）行动代理：根据用户偏好自适应规划局部修复。同时构建了包含27K标注失真区域的GenBlemish-27K数据集用于监督和评估。

Result: 实验表明，Agentic Retoucher在感知质量、失真定位和人类偏好对齐方面持续优于现有最先进方法。

Conclusion: 该框架为文本到图像生成建立了自我纠正和感知可靠的新范式，实现了感知证据、语言推理和可控校正的统一决策过程。

Abstract: Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.

</details>


### [151] [BARE: Towards Bias-Aware and Reasoning-Enhanced One-Tower Visual Grounding](https://arxiv.org/abs/2601.01526)
*Hongbing Li,Linhui Xiao,Zihan Zhao,Qi Shen,Yixiang Huang,Bo Xiao,Zhanyu Ma*

Main category: cs.CV

TL;DR: 提出BARE框架，通过保留模态特定特征和构建指称语义，解决单塔视觉定位中的模态偏差和语义推理不足问题，在多个基准测试中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有单塔视觉定位方法存在两个主要局限：(1) 过度纠缠的多模态表示加剧了欺骗性模态偏差；(2) 语义推理不足阻碍了指称线索的理解。

Method: 提出BARE框架，包含三个新模块：(i) 语言显著性调制器，(ii) 视觉偏差校正，(iii) 指称关系增强，共同减轻多模态干扰并增强指称理解。

Result: 在五个基准测试上的实验结果表明，BARE不仅实现了最先进的性能，而且相比现有方法具有更优的计算效率。

Conclusion: BARE框架通过偏差感知和推理增强机制，有效解决了视觉定位中的模态偏差和语义推理问题，为单塔视觉定位提供了高效解决方案。

Abstract: Visual Grounding (VG), which aims to locate a specific region referred to by expressions, is a fundamental yet challenging task in the multimodal understanding fields. While recent grounding transfer works have advanced the field through one-tower architectures, they still suffer from two primary limitations: (1) over-entangled multimodal representations that exacerbate deceptive modality biases, and (2) insufficient semantic reasoning that hinders the comprehension of referential cues. In this paper, we propose BARE, a bias-aware and reasoning-enhanced framework for one-tower visual grounding. BARE introduces a mechanism that preserves modality-specific features and constructs referential semantics through three novel modules: (i) language salience modulator, (ii) visual bias correction and (iii) referential relationship enhancement, which jointly mitigate multimodal distractions and enhance referential comprehension. Extensive experimental results on five benchmarks demonstrate that BARE not only achieves state-of-the-art performance but also delivers superior computational efficiency compared to existing approaches. The code is publicly accessible at https://github.com/Marloweeee/BARE.

</details>


### [152] [Remote Sensing Change Detection via Weak Temporal Supervision](https://arxiv.org/abs/2601.02126)
*Xavier Bou,Elliot Vincent,Gabriele Facciolo,Rafael Grompone von Gioi,Jean-Michel Morel,Thibaud Ehret*

Main category: cs.CV

TL;DR: 提出一种利用单时相遥感数据集扩展的弱时间监督策略，无需额外标注即可训练变化检测模型，通过对象感知变化图生成和迭代优化处理噪声标签，在多个基准测试中实现优异的零样本和低数据性能。


<details>
  <summary>Details</summary>
Motivation: 遥感语义变化检测面临标注数据稀缺的挑战，现有合成数据方法存在域泛化限制，需要一种无需新标注即可利用现有单时相数据的方法。

Method: 扩展单时相遥感数据集为多时相观测，假设真实双时相对无变化，跨位置配对图像生成变化样本，采用对象感知变化图生成和迭代优化处理弱标签噪声。

Result: 在扩展的FLAIR和IAILD航空数据集上验证，在不同基准测试中实现强大的零样本和低数据性能，并在法国大范围区域展示方法的可扩展性。

Conclusion: 弱时间监督策略能有效利用现有单时相数据集训练变化检测模型，降低标注成本，具有实际应用潜力和可扩展性。

Abstract: Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.

</details>


### [153] [BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models](https://arxiv.org/abs/2601.02147)
*Sunny Gupta,Shounak Das,Amit Sethi*

Main category: cs.CV

TL;DR: 提出BiPrompt框架，通过双边提示优化同时减少视觉和文本模态中的虚假相关性，提升CLIP等视觉语言基础模型的零样本泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有去偏方法通常只处理单一模态（视觉或文本），导致部分鲁棒性和分布偏移下的不稳定适应

Method: 视觉侧采用结构化注意力引导擦除以抑制背景激活，文本侧引入平衡提示归一化以对齐类别嵌入到各向同性语义空间

Result: 在真实世界和合成偏置基准测试中，相比现有测试时去偏方法，在平均和最差组准确率上均取得一致提升

Conclusion: BiPrompt为可信且因果基础的视觉语言适应提供了一种轻量级而有效的路径，无需重新训练或领域监督

Abstract: Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.

</details>


### [154] [Improving Flexible Image Tokenizers for Autoregressive Image Generation](https://arxiv.org/abs/2601.01535)
*Zixuan Fu,Lanqing Guo,Chong Wang,Binbin Song,Ding Liu,Bihan Wen*

Main category: cs.CV

TL;DR: 提出ReToK方法，通过冗余令牌填充和分层语义正则化改进灵活图像分词器，解决传统方法信息过度集中于早期令牌的问题，提升自回归图像生成性能。


<details>
  <summary>Details</summary>
Motivation: 传统灵活图像分词器使用嵌套丢弃训练，导致图像信息过度集中在序列早期令牌中，限制了长序列自回归图像生成的效果。

Method: 1. 冗余令牌填充：通过填充激活尾部令牌使用频率；2. 分层语义正则化：对齐早期令牌与预训练视觉基础模型的解码特征，并逐步降低尾部正则化强度以保留细节。

Result: 在ImageNet 256×256数据集上，ReToK相比固定长度和灵活分词器均取得更优生成性能。

Conclusion: ReToK通过平衡令牌利用和语义约束，有效提升了灵活分词器的表征能力，为高质量图像生成提供了新方案。

Abstract: Flexible image tokenizers aim to represent an image using an ordered 1D variable-length token sequence. This flexible tokenization is typically achieved through nested dropout, where a portion of trailing tokens is randomly truncated during training, and the image is reconstructed using the remaining preceding sequence. However, this tail-truncation strategy inherently concentrates the image information in the early tokens, limiting the effectiveness of downstream AutoRegressive (AR) image generation as the token length increases. To overcome these limitations, we propose \textbf{ReToK}, a flexible tokenizer with \underline{Re}dundant \underline{Tok}en Padding and Hierarchical Semantic Regularization, designed to fully exploit all tokens for enhanced latent modeling. Specifically, we introduce \textbf{Redundant Token Padding} to activate tail tokens more frequently, thereby alleviating information over-concentration in the early tokens. In addition, we apply \textbf{Hierarchical Semantic Regularization} to align the decoding features of earlier tokens with those from a pre-trained vision foundation model, while progressively reducing the regularization strength toward the tail to allow finer low-level detail reconstruction. Extensive experiments demonstrate the effectiveness of ReTok: on ImageNet 256$\times$256, our method achieves superior generation performance compared with both flexible and fixed-length tokenizers. Code will be available at: \href{https://github.com/zfu006/ReTok}{https://github.com/zfu006/ReTok}

</details>


### [155] [NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation](https://arxiv.org/abs/2601.02204)
*Huichao Zhang,Liao Qu,Yiheng Liu,Hang Chen,Yangyang Song,Yongsheng Dong,Shikun Sun,Xian Li,Xu Wang,Yi Jiang,Hu Ye,Bo Chen,Yiming Gao,Peng Liu,Akide Liu,Zhipeng Yang,Qili Deng,Linjie Xing,Jiyang Liu,Zhao Wang,Yang Zhou,Mingcong Liu,Yi Zhang,Qian He,Xiwei Hu,Zhongqi Qi,Jie Shao,Zhiye Fu,Shuai Wang,Fangmin Chen,Xuezhi Chai,Zhihua Wu,Yitong Wang,Zehuan Yuan,Daniel K. Du,Xinglong Wu*

Main category: cs.CV

TL;DR: NextFlow是一个统一的解码器自回归Transformer，通过多尺度视觉生成和强化学习前缀调优，实现了高效的多模态理解和生成。


<details>
  <summary>Details</summary>
Motivation: 传统自回归模型在处理文本（顺序性）和图像（层次性）时存在效率瓶颈，需要一种能兼顾两者特性并提升生成速度的统一架构。

Method: 1. 使用6万亿交错文本-图像离散token训练统一解码器；2. 文本采用next-token预测，图像采用next-scale预测替代传统光栅扫描；3. 提出多尺度生成稳定性训练方案；4. 引入强化学习前缀调优策略。

Result: 1. 5秒内生成1024x1024图像，速度远超同类自回归模型；2. 在统一模型中达到SOTA性能；3. 视觉质量媲美专业扩散模型。

Conclusion: NextFlow通过模态自适应的预测机制和稳定性优化，实现了高效、高质量的多模态内容生成，为统一架构设计提供了新方向。

Abstract: We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.

</details>


### [156] [FAR-AMTN: Attention Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01537)
*Gong Gao,Zekai Wang,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

TL;DR: 提出FAR-AMTN网络，通过权重共享注意力模块和跨组特征融合提升人脸属性识别的多任务泛化性能，在减少参数的同时提高准确率。


<details>
  <summary>Details</summary>
Motivation: 传统多任务网络在低层共享模块、高层独立模块的设计导致参数随任务数量指数增长，且高层特征交互受限，难以挖掘属性间的语义关联，影响泛化能力。

Method: 1) 权重共享的组特定注意力模块(WSGSA)降低复杂度并增强组特征表示；2) 跨组特征融合模块(CGFF)促进属性组间交互；3) 动态权重策略(DWS)实现任务同步收敛。

Result: 在CelebA和LFWA数据集上，FAR-AMTN以显著更少的参数取得了优于现有模型的准确率。

Conclusion: 所提方法通过增强特征交互与参数共享机制，有效提升了多任务人脸属性识别的泛化性能和效率。

Abstract: To enhance the generalization performance of Multi-Task Networks (MTN) in Face Attribute Recognition (FAR), it is crucial to share relevant information across multiple related prediction tasks effectively. Traditional MTN methods create shared low-level modules and distinct high-level modules, causing an exponential increase in model parameters with the addition of tasks. This approach also limits feature interaction at the high level, hindering the exploration of semantic relations among attributes, thereby affecting generalization negatively. In response, this study introduces FAR-AMTN, a novel Attention Multi-Task Network for FAR. It incorporates a Weight-Shared Group-Specific Attention (WSGSA) module with shared parameters to minimize complexity while improving group feature representation. Furthermore, a Cross-Group Feature Fusion (CGFF) module is utilized to foster interactions between attribute groups, enhancing feature learning. A Dynamic Weighting Strategy (DWS) is also introduced for synchronized task convergence. Experiments on the CelebA and LFWA datasets demonstrate that the proposed FAR-AMTN demonstrates superior accuracy with significantly fewer parameters compared to existing models.

</details>


### [157] [Seeing the Unseen: Zooming in the Dark with Event Cameras](https://arxiv.org/abs/2601.02206)
*Dachun Kai,Zeyu Xiao,Huyue Zhu,Jiaxiao Wang,Yueyi Zhang,Xiaoyan Sun*

Main category: cs.CV

TL;DR: 提出首个事件驱动的低光视频超分辨率框架RetinexEVSR，通过双向跨模态融合策略结合事件信号和RGB帧，在三个数据集上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有低光视频超分辨率方法因对比度有限和高频信息不足，难以恢复细节；事件相机的高对比度信号为解决此问题提供了新途径

Method: 1. 提出双向跨模态融合策略；2. 设计光照引导的事件增强模块，利用Retinex模型的光照图逐步优化事件特征；3. 提出事件引导的反射率增强模块，通过多尺度融合动态恢复细节

Result: 在SDSD基准测试中取得2.95 dB性能提升，同时运行时间减少65%；在三个数据集上均达到最先进水平

Conclusion: RetinexEVSR通过有效融合事件信号和RGB帧，显著提升了低光视频超分辨率的细节恢复能力和计算效率

Abstract: This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.

</details>


### [158] [Guiding Token-Sparse Diffusion Models](https://arxiv.org/abs/2601.01608)
*Felix Krause,Stefan Andreas Baumann,Johannes Schusterbauer,Olga Grebenkova,Ming Gui,Vincent Tao Hu,Björn Ommer*

Main category: cs.CV

TL;DR: 提出稀疏引导（SG）方法，解决稀疏训练扩散模型在推理时因分类器自由引导（CFG）响应不足导致的性能下降问题，通过令牌级稀疏性在降低计算成本的同时保持高质量输出。


<details>
  <summary>Details</summary>
Motivation: 扩散模型训练和推理成本高昂，现有稀疏训练方法虽降低训练成本，但推理时因对CFG响应不足导致性能不佳，需要一种既能保持质量又能高效推理的方法。

Method: 提出稀疏引导（SG），用令牌级稀疏性替代传统条件丢弃作为引导信号，在推理时利用稀疏性优化计算，同时保持条件预测的高方差以提升输出质量。

Result: 在ImageNet-256基准上以25%更少FLOPs实现1.58 FID；在同等质量下最高节省58% FLOPs；2.5B文本到图像模型在人类偏好评分和组合能力上均有提升，同时提高吞吐量。

Conclusion: SG通过令牌级稀疏性有效平衡了扩散模型的推理效率与输出质量，为大规模生成模型提供了可行的训练与推理优化方案。

Abstract: Diffusion models deliver high quality in image synthesis but remain expensive during training and inference. Recent works have leveraged the inherent redundancy in visual content to make training more affordable by training only on a subset of visual information. While these methods were successful in providing cheaper and more effective training, sparsely trained diffusion models struggle in inference. This is due to their lacking response to Classifier-free Guidance (CFG) leading to underwhelming performance during inference. To overcome this, we propose Sparse Guidance (SG). Instead of using conditional dropout as a signal to guide diffusion models, SG uses token-level sparsity. As a result, SG preserves the high-variance of the conditional prediction better, achieving good quality and high variance outputs. Leveraging token-level sparsity at inference, SG improves fidelity at lower compute, achieving 1.58 FID on the commonly used ImageNet-256 benchmark with 25% fewer FLOPs, and yields up to 58% FLOP savings at matched baseline quality. To demonstrate the effectiveness of Sparse Guidance, we train a 2.5B text-to-image diffusion model using training time sparsity and leverage SG during inference. SG achieves improvements in composition and human preference score while increasing throughput at the same time.

</details>


### [159] [Beyond Patches: Global-aware Autoregressive Model for Multimodal Few-Shot Font Generation](https://arxiv.org/abs/2601.01593)
*Haonan Cai,Yuxuan Luo,Zhouhui Lian*

Main category: cs.CV

TL;DR: 提出GAR-Font框架，通过全局感知分词器、多模态风格编码器和后处理流程，实现基于文本风格引导的少样本字体生成，在保持结构完整性和风格保真度方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有少样本字体生成方法存在两个主要问题：一是自回归模型采用局部块级分词，忽略了字体合成所需的全局依赖；二是局限于图像到图像的范式，忽视了语言在传达字体设计风格意图中的作用。

Method: 1. 全局感知分词器：同时捕获局部结构和全局风格模式；2. 多模态风格编码器：通过轻量级语言风格适配器实现灵活的风格控制，无需密集多模态预训练；3. 后处理精炼流程：增强结构保真度和风格一致性。

Result: 大量实验表明，GAR-Font在少样本字体生成任务中优于现有方法，在保持全局风格忠实度和通过文本风格引导获得更高质量结果方面表现突出。

Conclusion: GAR-Font通过结合全局感知建模和多模态风格控制，有效解决了少样本字体生成中的结构完整性和风格保真度问题，为字体设计提供了更灵活、高质量的自动化解决方案。

Abstract: Manual font design is an intricate process that transforms a stylistic visual concept into a coherent glyph set. This challenge persists in automated Few-shot Font Generation (FFG), where models often struggle to preserve both the structural integrity and stylistic fidelity from limited references. While autoregressive (AR) models have demonstrated impressive generative capabilities, their application to FFG is constrained by conventional patch-level tokenization, which neglects global dependencies crucial for coherent font synthesis. Moreover, existing FFG methods remain within the image-to-image paradigm, relying solely on visual references and overlooking the role of language in conveying stylistic intent during font design. To address these limitations, we propose GAR-Font, a novel AR framework for multimodal few-shot font generation. GAR-Font introduces a global-aware tokenizer that effectively captures both local structures and global stylistic patterns, a multimodal style encoder offering flexible style control through a lightweight language-style adapter without requiring intensive multimodal pretraining, and a post-refinement pipeline that further enhances structural fidelity and style coherence. Extensive experiments show that GAR-Font outperforms existing FFG methods, excelling in maintaining global style faithfulness and achieving higher-quality results with textual stylistic guidance.

</details>


### [160] [A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets](https://arxiv.org/abs/2601.02246)
*Annoor Sharara Akhand*

Main category: cs.CV

TL;DR: 比较了三种CNN训练范式（从头训练、预训练特征提取、迁移学习）在五个实际图像分类任务上的表现，发现迁移学习性能最佳，而定制CNN在资源受限时提供良好的效率-精度平衡。


<details>
  <summary>Details</summary>
Motivation: 实践中视觉识别任务常面临三种CNN训练策略的选择，但缺乏系统比较。研究旨在通过控制实验评估这些范式在真实场景中的性能与效率差异。

Method: 在五个真实图像分类数据集（路面缺陷识别、农作物品种识别、果实/叶片病害识别、人行道侵占识别、未授权车辆识别）上，对比三种范式：1) 从头训练定制CNN；2) 使用大型预训练CNN作为固定特征提取器；3) 通过部分或完整微调进行迁移学习。使用准确率、宏F1分数评估性能，辅以每轮训练时间和参数量等效率指标。

Result: 迁移学习在所有数据集中均表现出最强的预测性能；定制CNN在计算和内存资源受限时提供了有吸引力的效率-精度权衡。

Conclusion: 迁移学习是获得最佳预测性能的首选方法，而定制CNN在资源约束场景下具有实用价值，为实践中的模型选择提供了实证依据。

Abstract: Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.

</details>


### [161] [VIBE: Visual Instruction Based Editor](https://arxiv.org/abs/2601.02242)
*Grigorii Alekseenko,Aleksandr Gordeev,Irina Tolstykh,Bulat Suleimanov,Vladimir Dokholyan,Georgii Fedorov,Sergey Yakubson,Aleksandra Tsybina,Mikhail Chernyshov,Maksim Kuprashevich*

Main category: cs.CV

TL;DR: 提出了一种基于指令的紧凑型图像编辑流水线，使用2B参数的Qwen3-VL模型指导编辑过程，结合1.6B参数的Sana1.5扩散模型进行图像生成，在保持高质量的同时显著降低了计算成本和内存需求。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的图像编辑系统大多依赖大型扩散模型（6B-20B参数），计算成本高且难以在资源受限环境中部署；同时开源方案中能达到实际应用质量的方法有限。

Method: 采用轻量级架构设计：使用Qwen3-VL模型解析编辑指令并生成编辑指导，配合小型扩散模型Sana1.5进行图像生成；在架构设计、数据处理、训练配置和评估目标上均针对低成本推理和严格的源图像一致性进行优化。

Result: 在ImgEdit和GEdit基准测试中，该方法匹配或超越了参数量大数倍、推理成本更高的基线模型；在属性调整、物体移除、背景编辑和目标替换等需要保持输入图像一致性的编辑任务上表现突出；模型仅需24GB GPU内存，在NVIDIA H100上以BF16精度生成2K分辨率图像仅需约4秒。

Conclusion: 证明了通过精心设计的轻量级架构组合，可以在显著降低计算资源需求的同时实现高质量的指令图像编辑，为资源受限环境下的实际部署提供了可行方案。

Abstract: Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.

</details>


### [162] [CAP-IQA: Context-Aware Prompt-Guided CT Image Quality Assessment](https://arxiv.org/abs/2601.01613)
*Kazi Ramisa Rifa,Jie Zhang,Abdullah Imran*

Main category: cs.CV

TL;DR: 提出CAP-IQA框架，通过上下文感知提示和因果去偏技术，结合文本先验与图像特定退化信息，提升CT图像质量评估性能，在公开和内部数据集上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的方法在CT图像质量评估中应用有限，且常因使用理想化文本先验而引入偏差，无法准确反映真实世界中的噪声、运动伪影等退化情况。

Method: 提出CAP-IQA框架，整合CNN视觉编码器和领域特定文本编码器，采用上下文感知提示融合与因果去偏技术，分离理想化知识与图像特定退化特征。

Result: 在LDCTIQA挑战基准上，CAP-IQA总体相关性得分2.8590，超越原最佳方法4.24%；在91,514张儿科CT内部数据集上验证了泛化能力。

Conclusion: CAP-IQA通过提示引导融合与简化编码器设计，增强了特征对齐与可解释性，能有效评估诊断可见性、解剖清晰度和噪声感知，具有实际临床适用性。

Abstract: Prompt-based methods, which encode medical priors through descriptive text, have been only minimally explored for CT Image Quality Assessment (IQA). While such prompts can embed prior knowledge about diagnostic quality, they often introduce bias by reflecting idealized definitions that may not hold under real-world degradations such as noise, motion artifacts, or scanner variability. To address this, we propose the Context-Aware Prompt-guided Image Quality Assessment (CAP-IQA) framework, which integrates text-level priors with instance-level context prompts and applies causal debiasing to separate idealized knowledge from factual, image-specific degradations. Our framework combines a CNN-based visual encoder with a domain-specific text encoder to assess diagnostic visibility, anatomical clarity, and noise perception in abdominal CT images. The model leverages radiology-style prompts and context-aware fusion to align semantic and perceptual representations. On the 2023 LDCTIQA challenge benchmark, CAP-IQA achieves an overall correlation score of 2.8590 (sum of PLCC, SROCC, and KROCC), surpassing the top-ranked leaderboard team (2.7427) by 4.24%. Moreover, our comprehensive ablation experiments confirm that prompt-guided fusion and the simplified encoder-only design jointly enhance feature alignment and interpretability. Furthermore, evaluation on an in-house dataset of 91,514 pediatric CT images demonstrates the true generalizability of CAP-IQA in assessing perceptual fidelity in a different patient population.

</details>


### [163] [An Empirical Study of Monocular Human Body Measurement Under Weak Calibration](https://arxiv.org/abs/2601.01639)
*Gaurav Sekar*

Main category: cs.CV

TL;DR: 本文对三种弱标定单目RGB图像人体测量方法进行了系统实证研究，分析了不同标定假设对测量结果的影响，为消费级设备上的轻量级测量系统提供设计参考。


<details>
  <summary>Details</summary>
Motivation: 单目RGB图像人体测量面临尺度模糊、视角敏感和缺乏深度信息等挑战，需要研究不同弱标定方法在实际应用中的表现和适用性。

Method: 在消费级相机半约束条件下，系统评估了三种弱标定单目策略：基于关键点的几何方法、姿态驱动回归方法和物体标定轮廓方法，重点分析不同标定假设对测量行为、鲁棒性和失效模式的影响。

Result: 研究发现用户在校准过程中的努力程度与所得周长测量结果的稳定性之间存在明显权衡，揭示了不同方法在不同体型上的性能差异和失效模式。

Conclusion: 本研究为面向消费级设备部署的轻量级单目人体测量系统提供了实证设计参考，强调了校准假设对测量系统实际表现的重要影响。

Abstract: Estimating human body measurements from monocular RGB imagery remains challenging due to scale ambiguity, viewpoint sensitivity, and the absence of explicit depth information. This work presents a systematic empirical study of three weakly calibrated monocular strategies: landmark-based geometry, pose-driven regression, and object-calibrated silhouettes, evaluated under semi-constrained conditions using consumer-grade cameras. Rather than pursuing state-of-the-art accuracy, the study analyzes how differing calibration assumptions influence measurement behavior, robustness, and failure modes across varied body types. The results reveal a clear trade-off between user effort during calibration and the stability of resulting circumferential quantities. This paper serves as an empirical design reference for lightweight monocular human measurement systems intended for deployment on consumer devices.

</details>


### [164] [LabelAny3D: Label Any Object 3D in the Wild](https://arxiv.org/abs/2601.01676)
*Jin Yao,Radowan Mahmud Redoy,Sebastian Elbaum,Matthew B. Dwyer,Zezhou Cheng*

Main category: cs.CV

TL;DR: 提出LabelAny3D框架，通过分析合成方法从2D图像重建3D场景以生成高质量3D标注，并基于此构建COCO3D开放词汇单目3D检测基准。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测模型在真实场景图像中表现不佳，主要由于缺乏真实世界的3D数据集和3D标注困难。

Method: 采用分析合成框架，从2D图像重建整体3D场景；基于MS-COCO数据集构建COCO3D基准，涵盖广泛物体类别。

Result: LabelAny3D生成的标注提升了多个基准上的单目3D检测性能，质量优于先前的自动标注方法。

Conclusion: 基础模型驱动的标注方法有望在真实开放世界场景中扩展3D识别能力。

Abstract: Detecting objects in 3D space from monocular input is crucial for applications ranging from robotics to scene understanding. Despite advanced performance in the indoor and autonomous driving domains, existing monocular 3D detection models struggle with in-the-wild images due to the lack of 3D in-the-wild datasets and the challenges of 3D annotation. We introduce LabelAny3D, an \emph{analysis-by-synthesis} framework that reconstructs holistic 3D scenes from 2D images to efficiently produce high-quality 3D bounding box annotations. Built on this pipeline, we present COCO3D, a new benchmark for open-vocabulary monocular 3D detection, derived from the MS-COCO dataset and covering a wide range of object categories absent from existing 3D datasets. Experiments show that annotations generated by LabelAny3D improve monocular 3D detection performance across multiple benchmarks, outperforming prior auto-labeling approaches in quality. These results demonstrate the promise of foundation-model-driven annotation for scaling up 3D recognition in realistic, open-world settings.

</details>


### [165] [TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation](https://arxiv.org/abs/2601.02273)
*Salim Khazem*

Main category: cs.CV

TL;DR: 提出TopoLoRA-SAM框架，通过拓扑感知的低秩适配器高效微调SAM模型，在多个医学和遥感图像分割任务中达到最优性能，仅需训练5.2%的参数。


<details>
  <summary>Details</summary>
Motivation: 基础分割模型（如SAM）在大规模预训练后具有强大的零样本泛化能力，但难以适应特定领域的语义分割任务，特别是细长结构（如视网膜血管）和噪声模态（如SAR图像）。全参数微调计算成本高且易导致灾难性遗忘。

Method: 提出TopoLoRA-SAM框架：1）在冻结的ViT编码器中注入低秩适配器（LoRA）；2）添加轻量级空间卷积适配器；3）可选地通过可微分clDice进行拓扑感知监督。

Result: 在五个基准测试（视网膜血管分割DRIVE/STARE/CHASE_DB1、息肉分割Kvasir-SEG、SAR海陆分割SL-SSDD）中，Topo-LoRA-SAM取得了最佳的视网膜平均Dice和总体平均Dice。在CHASE_DB1数据集上显著提升了分割准确性和鲁棒性。

Conclusion: 拓扑感知的参数高效适配方法能够匹配甚至超越完全微调的专用模型，仅需训练约4.9M参数（占模型5.2%），为领域特定分割任务提供了高效解决方案。

Abstract: Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \textbf{5.2\%} of model parameters ($\sim$4.9M). On the challenging CHASE\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git

</details>


### [166] [Animated 3DGS Avatars in Diverse Scenes with Consistent Lighting and Shadows](https://arxiv.org/abs/2601.01660)
*Aymen Mir,Riza Alp Guler,Jian Wang,Gerard Pons-Moll,Bing Zhou*

Main category: cs.CV

TL;DR: 提出Deep Gaussian Shadow Maps (DGSM)方法，用于在3D高斯泼溅场景中实现动态角色与场景交互时的一致光照和阴影效果，结合球谐函数实现环境光照重照明。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅技术在动态角色与场景交互时，难以实现物理一致的光照和阴影效果，特别是当角色与动态物体或静态场景交互时，缺乏高效的体积阴影计算方法。

Method: 1. 提出DGSM：基于经典深度阴影映射思想，利用3DGS沿光线累积透射率的闭式解计算体积阴影；2. 使用八面体图集存储分层透射率数据，支持GPU实时采样；3. 采用球谐函数表示HDRI环境光照，实现基于高斯泼溅的快速辐射传输重照明。

Result: 在AvatarX、ActorsHQ等角色数据集与ScanNet++、DL3DV等场景的合成实验中，实现了多角色交互场景下连贯的阴影投射/接收效果，且完全在体积3DGS表示中运行，无需网格化处理。

Conclusion: DGSM与球谐重照明方法能够在纯体积3DGS表示中实现动态角色与场景交互时的物理一致光照和阴影，为实时渲染应用提供了有效的解决方案。

Abstract: We present a method for consistent lighting and shadows when animated 3D Gaussian Splatting (3DGS) avatars interact with 3DGS scenes or with dynamic objects inserted into otherwise static scenes. Our key contribution is Deep Gaussian Shadow Maps (DGSM), a modern analogue of the classical shadow mapping algorithm tailored to the volumetric 3DGS representation. Building on the classic deep shadow mapping idea, we show that 3DGS admits closed form light accumulation along light rays, enabling volumetric shadow computation without meshing. For each estimated light, we tabulate transmittance over concentric radial shells and store them in octahedral atlases, which modern GPUs can sample in real time per query to attenuate affected scene Gaussians and thus cast and receive shadows consistently. To relight moving avatars, we approximate the local environment illumination with HDRI probes represented in a spherical harmonic (SH) basis and apply a fast per Gaussian radiance transfer, avoiding explicit BRDF estimation or offline optimization. We demonstrate environment consistent lighting for avatars from AvatarX and ActorsHQ, composited into ScanNet++, DL3DV, and SuperSplat scenes, and show interactions with inserted objects. Across single and multi avatar settings, DGSM and SH relighting operate fully in the volumetric 3DGS representation, yielding coherent shadows and relighting while avoiding meshing.

</details>


### [167] [Trustworthy Data-Driven Wildfire Risk Prediction and Understanding in Western Canada](https://arxiv.org/abs/2601.01677)
*Zhengsen Xu,Lanying Wang,Sibo Cheng,Xue Rui,Kyle Gao,Yimin Zhu,Mabel Heffring,Zack Dewis,Saeid Taleghanidoozdoozan,Megan Greenwood,Motasem Alkayid,Quinn Ledingham,Hongjie He,Jonathan Li,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 提出一个可信赖的野火风险预测框架，通过长序列多尺度时间建模整合异质驱动因素，在加拿大西部2023-2024年火灾季表现优异，并实现不确定性量化和过程级解释。


<details>
  <summary>Details</summary>
Motivation: 加拿大西部野火活动加剧导致重大社会经济和环境损失，但准确预测受限于点火和蔓延的随机性、多因素非线性相互作用，以及纯数据驱动模型的可靠性和可解释性不足。

Method: 基于长序列多尺度时间建模的可信赖数据驱动框架，整合燃料条件、气象、气候、地形和人类活动等异质驱动因素，显式量化预测不确定性，并采用SHAP进行过程级解释。

Result: 在2023-2024年创纪录火灾季的评估中，模型优于现有时间序列方法，F1分数达0.90，PR-AUC达0.98，计算成本低；不确定性分析揭示预测置信度的空间和季节模式，SHAP解释显示温度相关驱动主导风险，而2024年水分相关约束的作用更强。

Conclusion: 该框架实现了高精度、低成本的野火风险预测，同时提供不确定性和机制解释，有助于理解野火控制因素的年际差异和空间对比，为风险管理提供可靠工具。

Abstract: In recent decades, the intensification of wildfire activity in western Canada has resulted in substantial socio-economic and environmental losses. Accurate wildfire risk prediction is hindered by the intrinsic stochasticity of ignition and spread and by nonlinear interactions among fuel conditions, meteorology, climate variability, topography, and human activities, challenging the reliability and interpretability of purely data-driven models. We propose a trustworthy data-driven wildfire risk prediction framework based on long-sequence, multi-scale temporal modeling, which integrates heterogeneous drivers while explicitly quantifying predictive uncertainty and enabling process-level interpretation. Evaluated over western Canada during the record-breaking 2023 and 2024 fire seasons, the proposed model outperforms existing time-series approaches, achieving an F1 score of 0.90 and a PR-AUC of 0.98 with low computational cost. Uncertainty-aware analysis reveals structured spatial and seasonal patterns in predictive confidence, highlighting increased uncertainty associated with ambiguous predictions and spatiotemporal decision boundaries. SHAP-based interpretation provides mechanistic understanding of wildfire controls, showing that temperature-related drivers dominate wildfire risk in both years, while moisture-related constraints play a stronger role in shaping spatial and land-cover-specific contrasts in 2024 compared to the widespread hot and dry conditions of 2023. Data and code are available at https://github.com/SynUW/mmFire.

</details>


### [168] [Point-SRA: Self-Representation Alignment for 3D Representation Learning](https://arxiv.org/abs/2601.01746)
*Lintong Wei,Jian Lu,Haozhe Cheng,Jihua Zhu,Kaibing Zhang*

Main category: cs.CV

TL;DR: 提出Point-SRA方法，通过多掩码比率的MAE和MeanFlow Transformer实现3D表示学习，在多个下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有MAE方法使用固定掩码比率，忽略了多层次表示关联和点云内在几何结构，且点级重建假设与点云多样性存在冲突。

Method: 1. 使用不同掩码比率的MAE捕获互补信息；2. 设计MeanFlow Transformer进行概率重建；3. 提出双重自表示对齐机制；4. 设计流条件微调架构。

Result: ScanObjectNN分类任务超越Point-MAE 5.37%；颅内动脉瘤分割任务动脉平均IoU达96.07%，动脉瘤达86.87%；3D目标检测AP@50达47.3%，超越MaskPoint 5.12%。

Conclusion: Point-SRA通过多掩码策略和概率建模有效解决了现有方法的局限性，在多个3D任务中实现了显著性能提升。

Abstract: Masked autoencoders (MAE) have become a dominant paradigm in 3D representation learning, setting new performance benchmarks across various downstream tasks. Existing methods with fixed mask ratio neglect multi-level representational correlations and intrinsic geometric structures, while relying on point-wise reconstruction assumptions that conflict with the diversity of point cloud. To address these issues, we propose a 3D representation learning method, termed Point-SRA, which aligns representations through self-distillation and probabilistic modeling. Specifically, we assign different masking ratios to the MAE to capture complementary geometric and semantic information, while the MeanFlow Transformer (MFT) leverages cross-modal conditional embeddings to enable diverse probabilistic reconstruction. Our analysis further reveals that representations at different time steps in MFT also exhibit complementarity. Therefore, a Dual Self-Representation Alignment mechanism is proposed at both the MAE and MFT levels. Finally, we design a Flow-Conditioned Fine-Tuning Architecture to fully exploit the point cloud distribution learned via MeanFlow. Point-SRA outperforms Point-MAE by 5.37% on ScanObjectNN. On intracranial aneurysm segmentation, it reaches 96.07% mean IoU for arteries and 86.87% for aneurysms. For 3D object detection, Point-SRA achieves 47.3% AP@50, surpassing MaskPoint by 5.12%.

</details>


### [169] [Mitigating Longitudinal Performance Degradation in Child Face Recognition Using Synthetic Data](https://arxiv.org/abs/2601.01689)
*Afzal Hossain,Stephanie Schuckers*

Main category: cs.CV

TL;DR: 本研究探讨使用合成人脸数据作为纵向稳定器，通过增强儿童人脸识别模型的时间鲁棒性来应对因面部快速非线性生长导致的模板漂移问题。实验表明，合成数据增强的微调能显著降低验证错误率。


<details>
  <summary>Details</summary>
Motivation: 儿童面部随年龄快速非线性生长导致人脸识别中的模板漂移和随时间增加的验证错误，需要提高儿童人脸识别模型的纵向稳定性。

Method: 在YFA数据集上采用身份分离协议，评估三种设置：(1)未微调的预训练MagFace嵌入；(2)仅用真实训练数据微调MagFace；(3)结合真实与合成训练数据微调MagFace。合成数据使用StyleGAN2 ADA生成，并经过后生成过滤以减少身份泄漏和伪影。

Result: 在6至36个月的注册验证间隔中，合成数据增强的微调相比预训练基线和仅用真实数据微调，显著降低了错误率。

Conclusion: 合成数据增强能有效提高儿童人脸识别的身份持久性，为儿科人脸识别提供了风险可控的改进方案。

Abstract: Longitudinal face recognition in children remains challenging due to rapid and nonlinear facial growth, which causes template drift and increasing verification errors over time. This work investigates whether synthetic face data can act as a longitudinal stabilizer by improving temporal robustness of child face recognition models. Using an identity disjoint protocol on the Young Face Aging (YFA) dataset, we evaluate three settings: (i) pretrained MagFace embeddings without dataset specific fine-tuning, (ii) MagFace fine-tuned using authentic training faces only, and (iii) MagFace fine-tuned using a combination of authentic and synthetically generated training faces. Synthetic data is generated using StyleGAN2 ADA and incorporated exclusively within the training identities; a post generation filtering step is applied to mitigate identity leakage and remove artifact affected samples. Experimental results across enrollment verification gaps from 6 to 36 months show that synthetic-augmented fine tuning substantially reduces error rates relative to both the pretrained baseline and real only fine tuning. These findings provide a risk aware assessment of synthetic augmentation for improving identity persistence in pediatric face recognition.

</details>


### [170] [Evaluating Deep Learning-Based Face Recognition for Infants and Toddlers: Impact of Age Across Developmental Stages](https://arxiv.org/abs/2601.01680)
*Afzal Hossain,Mst Rumana Sumi,Stephanie Schuckers*

Main category: cs.CV

TL;DR: 本研究评估了四种深度学习人脸识别模型在0-3岁婴幼儿纵向数据集上的表现，发现婴幼儿早期识别准确率较低，随年龄增长显著提升，并提出使用DANN方法减少时间漂移，提高特征稳定性。


<details>
  <summary>Details</summary>
Motivation: 婴幼儿人脸识别面临面部形态快速变化、类间相似度高、数据集稀缺等独特挑战，而可靠的儿童生物识别系统对智慧城市中的公共医疗、儿童安全和数字身份服务至关重要。

Method: 使用FaceNet、ArcFace、MagFace和CosFace四种深度学习模型，在七次采集、跨度24个月的婴幼儿纵向数据集上进行评估；采用域对抗神经网络（DANN）减少特征嵌入的时间漂移。

Result: 0-6月龄婴儿在0.1%误接受率下的真实接受率仅为30.7%；2.5-3岁组提升至64.7%；时间间隔越短识别准确率越高；DANN方法使真实接受率提升超过12%，获得更稳定、可泛化的时间特征。

Conclusion: 婴幼儿早期人脸识别性能受面部特征不稳定影响显著，需开发能处理时间变异性的隐私保护生物认证系统，这对智慧城市中儿童验证关键场景的应用具有重要意义。

Abstract: Face recognition for infants and toddlers presents unique challenges due to rapid facial morphology changes, high inter-class similarity, and limited dataset availability. This study evaluates the performance of four deep learning-based face recognition models FaceNet, ArcFace, MagFace, and CosFace on a newly developed longitudinal dataset collected over a 24 month period in seven sessions involving children aged 0 to 3 years. Our analysis examines recognition accuracy across developmental stages, showing that the True Accept Rate (TAR) is only 30.7% at 0.1% False Accept Rate (FAR) for infants aged 0 to 6 months, due to unstable facial features. Performance improves significantly in older children, reaching 64.7% TAR at 0.1% FAR in the 2.5 to 3 year age group. We also evaluate verification performance over different time intervals, revealing that shorter time gaps result in higher accuracy due to reduced embedding drift. To mitigate this drift, we apply a Domain Adversarial Neural Network (DANN) approach that improves TAR by over 12%, yielding features that are more temporally stable and generalizable. These findings are critical for building biometric systems that function reliably over time in smart city applications such as public healthcare, child safety, and digital identity services. The challenges observed in early age groups highlight the importance of future research on privacy preserving biometric authentication systems that can address temporal variability, particularly in secure and regulated urban environments where child verification is essential.

</details>


### [171] [FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing](https://arxiv.org/abs/2601.01720)
*Xijie Huang,Chengming Xu,Donghao Luo,Xiaobin Hu,Peng Tang,Xu Peng,Jiangning Zhang,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: 本文提出了一种无需运行时引导的First-Frame Propagation视频编辑方法，通过构建大规模高质量数据集FFP-300K，并引入自适应时空RoPE和自蒸馏策略，解决了外观保持与运动保留之间的关键矛盾。


<details>
  <summary>Details</summary>
Motivation: 现有FFP方法依赖繁琐的运行时引导，其根本原因在于训练数据集质量不足（视频短、分辨率低、任务多样性缺乏），无法学习鲁棒的时序先验。

Method: 1) 构建FFP-300K数据集（30万对720p、81帧视频）；2) 提出自适应时空RoPE动态重映射位置编码以解耦外观与运动；3) 采用自蒸馏策略，通过身份传播任务作为正则化器确保时序稳定性。

Result: 在EditVerseBench基准测试中显著优于现有学术和商业模型，PickScore提升约0.2，VLM分数提升约0.3。

Conclusion: 通过高质量数据集和新型框架设计，实现了真正无需引导的FFP视频编辑，有效平衡了外观一致性与运动保真度，并取得了优异的定量与定性结果。

Abstract: First-Frame Propagation (FFP) offers a promising paradigm for controllable video editing, but existing methods are hampered by a reliance on cumbersome run-time guidance. We identify the root cause of this limitation as the inadequacy of current training datasets, which are often too short, low-resolution, and lack the task diversity required to teach robust temporal priors. To address this foundational data gap, we first introduce FFP-300K, a new large-scale dataset comprising 300K high-fidelity video pairs at 720p resolution and 81 frames in length, constructed via a principled two-track pipeline for diverse local and global edits. Building on this dataset, we propose a novel framework designed for true guidance-free FFP that resolves the critical tension between maintaining first-frame appearance and preserving source video motion. Architecturally, we introduce Adaptive Spatio-Temporal RoPE (AST-RoPE), which dynamically remaps positional encodings to disentangle appearance and motion references. At the objective level, we employ a self-distillation strategy where an identity propagation task acts as a powerful regularizer, ensuring long-term temporal stability and preventing semantic drift. Comprehensive experiments on the EditVerseBench benchmark demonstrate that our method significantly outperforming existing academic and commercial models by receiving about 0.2 PickScore and 0.3 VLM score improvement against these competitors.

</details>


### [172] [Learnability-Driven Submodular Optimization for Active Roadside 3D Detection](https://arxiv.org/abs/2601.01695)
*Ruiyu Mao,Baoming Zhang,Nicholas Ruozzi,Yunhui Guo*

Main category: cs.CV

TL;DR: 提出LH3D主动学习框架，针对路边单目3D检测中因视角限制导致的标注模糊问题，通过筛选可学习样本提升标注效率，仅用25%标注预算达到接近全量数据性能。


<details>
  <summary>Details</summary>
Motivation: 实际路边感知部署常因硬件/隐私限制只能标注纯路边数据，但单视角下远距离/模糊/遮挡物体的3D属性存在固有模糊性，人工标注困难且成本高，需通过主动学习筛选可可靠标注的样本。

Method: 提出可学习性驱动的主动学习框架LH3D，结合样本信息量与可标注可靠性，抑制固有模糊样本的同时保证场景覆盖，在DAIR-V2X-I数据集上验证。

Result: 仅用25%标注预算，对车辆、行人、骑行者的检测性能分别达到全量数据的86.06%、67.32%、78.67%，显著优于基于不确定性的基线方法。

Conclusion: 路边3D感知的关键是可学习性而非不确定性，LH3D框架能有效提升标注效率并维持模型性能，为实际部署提供实用解决方案。

Abstract: Roadside perception datasets are typically constructed via cooperative labeling between synchronized vehicle and roadside frame pairs. However, real deployment often requires annotation of roadside-only data due to hardware and privacy constraints. Even human experts struggle to produce accurate labels without vehicle-side data (image, LIDAR), which not only increases annotation difficulty and cost, but also reveals a fundamental learnability problem: many roadside-only scenes contain distant, blurred, or occluded objects whose 3D properties are ambiguous from a single view and can only be reliably annotated by cross-checking paired vehicle--roadside frames. We refer to such cases as inherently ambiguous samples. To reduce wasted annotation effort on inherently ambiguous samples while still obtaining high-performing models, we turn to active learning. This work focuses on active learning for roadside monocular 3D object detection and proposes a learnability-driven framework that selects scenes which are both informative and reliably labelable, suppressing inherently ambiguous samples while ensuring coverage. Experiments demonstrate that our method, LH3D, achieves 86.06%, 67.32%, and 78.67% of full-performance for vehicles, pedestrians, and cyclists respectively, using only 25% of the annotation budget on DAIR-V2X-I, significantly outperforming uncertainty-based baselines. This confirms that learnability, not uncertainty, matters for roadside 3D perception.

</details>


### [173] [MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement](https://arxiv.org/abs/2601.01749)
*Lei Zhu,Lijian Lin,Ye Zhu,Jiahao Wu,Xuehan Hou,Yu Li,Yunfei Liu,Jie Chen*

Main category: cs.CV

TL;DR: 提出MANGO框架，通过两阶段训练和纯图像级监督，实现高质量的双人3D对话头部生成，解决了现有方法在自然听-说交互和精细面部动态捕捉上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动的3D头部生成方法主要针对单说话人场景，缺乏自然的双向听-说交互；现有3D对话虚拟人方法依赖易出错的伪3D标签，无法捕捉细粒度面部动态。

Method: 1. 两阶段框架：第一阶段使用带双音频交互模块的扩散Transformer从多说话人音频生成3D运动；第二阶段使用快速3D高斯渲染器生成高保真图像，通过交替训练提供2D级光度监督。2. 引入MANGO-Dialog数据集（500+身份、50+小时对齐的2D-3D对话数据）。

Result: 实验表明，该方法在建模双人3D对话运动方面实现了优异的准确性和真实感，显著提升了音频驱动说话头部的保真度和可控性。

Conclusion: MANGO框架通过纯图像级监督和交替训练有效解决了伪3D标签的噪声问题，实现了更贴合真实对话行为的3D头部生成，推动了该领域的发展。

Abstract: Current audio-driven 3D head generation methods mainly focus on single-speaker scenarios, lacking natural, bidirectional listen-and-speak interaction. Achieving seamless conversational behavior, where speaking and listening states transition fluidly remains a key challenge. Existing 3D conversational avatar approaches rely on error-prone pseudo-3D labels that fail to capture fine-grained facial dynamics. To address these limitations, we introduce a novel two-stage framework MANGO, which leveraging pure image-level supervision by alternately training to mitigate the noise introduced by pseudo-3D labels, thereby achieving better alignment with real-world conversational behaviors. Specifically, in the first stage, a diffusion-based transformer with a dual-audio interaction module models natural 3D motion from multi-speaker audio. In the second stage, we use a fast 3D Gaussian Renderer to generate high-fidelity images and provide 2D-level photometric supervision for the 3D motions through alternate training. Additionally, we introduce MANGO-Dialog, a high-quality dataset with over 50 hours of aligned 2D-3D conversational data across 500+ identities. Extensive experiments demonstrate that our method achieves exceptional accuracy and realism in modeling two-person 3D dialogue motion, significantly advancing the fidelity and controllability of audio-driven talking heads.

</details>


### [174] [CTIS-QA: Clinical Template-Informed Slide-level Question Answering for Pathology](https://arxiv.org/abs/2601.01769)
*Hao Lu,Ziniu Qian,Yifu Li,Yang Zhou,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: 提出基于临床诊断模板的病理信息结构化收集流程，构建CTIS-Align数据集和CTIS-Bench基准，并开发CTIS-QA模型用于全切片图像问答，在多项任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 病理报告信息非结构化且缺乏标准化，导致临床数据利用困难；现有视觉问答方法在医学领域缺乏临床相关性且依赖非视觉推理。

Method: 1. 基于CAP协议设计临床病理报告模板（CPRT）标准化提取病理特征；2. 构建CTIS-Align（8万张切片-描述对）和CTIS-Bench（977张切片、1.4万QA对）数据集；3. 提出双流架构CTIS-QA模型：全局流通过聚类聚合特征，局部流通过注意力引导感知关键区域。

Result: 在TCGA-BRCA上验证：CTIS-Bench强调封闭式临床问题（如肿瘤分级、受体状态）；CTIS-QA在WSI-VQA、CTIS-Bench及诊断任务中多项指标超越现有最优模型。

Conclusion: 模板化流程能有效结构化病理信息；构建的数据集和基准提升了临床相关性；CTIS-QA模型通过模拟病理医生诊断流程，实现了更准确的切片级视觉问答。

Abstract: In this paper, we introduce a clinical diagnosis template-based pipeline to systematically collect and structure pathological information. In collaboration with pathologists and guided by the the College of American Pathologists (CAP) Cancer Protocols, we design a Clinical Pathology Report Template (CPRT) that ensures comprehensive and standardized extraction of diagnostic elements from pathology reports. We validate the effectiveness of our pipeline on TCGA-BRCA. First, we extract pathological features from reports using CPRT. These features are then used to build CTIS-Align, a dataset of 80k slide-description pairs from 804 WSIs for vision-language alignment training, and CTIS-Bench, a rigorously curated VQA benchmark comprising 977 WSIs and 14,879 question-answer pairs. CTIS-Bench emphasizes clinically grounded, closed-ended questions (e.g., tumor grade, receptor status) that reflect real diagnostic workflows, minimize non-visual reasoning, and require genuine slide understanding. We further propose CTIS-QA, a Slide-level Question Answering model, featuring a dual-stream architecture that mimics pathologists' diagnostic approach. One stream captures global slide-level context via clustering-based feature aggregation, while the other focuses on salient local regions through attention-guided patch perception module. Extensive experiments on WSI-VQA, CTIS-Bench, and slide-level diagnostic tasks show that CTIS-QA consistently outperforms existing state-of-the-art models across multiple metrics. Code and data are available at https://github.com/HLSvois/CTIS-QA.

</details>


### [175] [Causality-Aware Temporal Projection for Video Understanding in Video-LLMs](https://arxiv.org/abs/2601.01804)
*Zhengjian Kang,Qi Chen,Rui Liu,Kangtong Mo,Xingyu Zhang,Xiaoyu Deng,Ye Zhang*

Main category: cs.CV

TL;DR: 提出V-CORE框架，通过可学习的空间聚合和因果感知时序投影器，为视频大语言模型引入显式的时序约束，提升时序排序和因果推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在需要时序一致性和因果连贯性的视频理解任务上表现不足，其双向投影器设计可能模糊时序顺序，缺乏对视频推理方向性的显式建模。

Method: V-CORE包含两个核心组件：1) 可学习空间聚合(LSA)，自适应选择显著空间标记以减少冗余；2) 因果感知时序投影器(CATP)，通过块因果注意力和终端动态摘要标记强制单向信息流，保持时序聚合的严格顺序。

Result: 在NExT-QA基准测试中达到61.2%准确率，在MSVD-QA、MSRVTT-QA和TGIF-QA上保持竞争力，时序和因果推理子类别分别提升3.5%和5.2%。

Conclusion: 显式时序约束对视频理解至关重要，V-CORE通过参数高效的设计在单消费级GPU上可训练，有效提升了视频大语言模型的时序和因果推理能力。

Abstract: Recent Video Large Language Models (Video-LLMs) have shown strong multimodal reasoning capabilities, yet remain challenged by video understanding tasks that require consistent temporal ordering and causal coherence. Many parameter-efficient Video-LLMs rely on unconstrained bidirectional projectors to model inter-frame interactions, which can blur temporal ordering by allowing later frames to influence earlier representations, without explicit architectural mechanisms to respect the directional nature of video reasoning. To address this limitation, we propose V-CORE, a parameter-efficient framework that introduces explicit temporal ordering constraints for video understanding. V-CORE consists of two key components: (1) Learnable Spatial Aggregation (LSA), which adaptively selects salient spatial tokens to reduce redundancy, and (2) a Causality-Aware Temporal Projector (CATP), which enforces structured unidirectional information flow via block-causal attention and a terminal dynamic summary token acting as a causal sink. This design preserves intra-frame spatial interactions while ensuring that temporal information is aggregated in a strictly ordered manner. With 4-bit QLoRA and a frozen LLM backbone, V-CORE can be trained efficiently on a single consumer GPU. Experiments show that V-CORE achieves strong performance on the challenging NExT-QA benchmark, reaching 61.2% accuracy, and remains competitive across MSVD-QA, MSRVTT-QA, and TGIF-QA, with gains concentrated in temporal and causal reasoning subcategories (+3.5% and +5.2% respectively), directly validating the importance of explicit temporal ordering constraints.

</details>


### [176] [Robust Egocentric Visual Attention Prediction Through Language-guided Scene Context-aware Learning](https://arxiv.org/abs/2601.01818)
*Sungjune Park,Hongda Mao,Qingshuang Chen,Yong Man Ro,Yelin Kim*

Main category: cs.CV

TL;DR: 提出了一种语言引导的场景上下文感知学习框架，用于提升第一人称视觉注意力预测的鲁棒性，在Ego4D和AEA数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 第一人称视频分析需求增长，但动态第一人称场景的复杂性和模糊性使注意力预测面临挑战。研究表明场景上下文信息在调节人类注意力中起关键作用。

Method: 1) 设计上下文感知器，基于语言场景描述生成上下文感知的视频表示；2) 引入两个训练目标：聚焦目标兴趣区域，抑制无关区域的干扰。

Result: 在Ego4D和AEA数据集上的大量实验表明，该方法在多样动态第一人称场景中实现了最先进的性能并增强了鲁棒性。

Conclusion: 所提出的语言引导场景上下文感知框架能有效提升第一人称视觉注意力预测的准确性和鲁棒性。

Abstract: As the demand for analyzing egocentric videos grows, egocentric visual attention prediction, anticipating where a camera wearer will attend, has garnered increasing attention. However, it remains challenging due to the inherent complexity and ambiguity of dynamic egocentric scenes. Motivated by evidence that scene contextual information plays a crucial role in modulating human attention, in this paper, we present a language-guided scene context-aware learning framework for robust egocentric visual attention prediction. We first design a context perceiver which is guided to summarize the egocentric video based on a language-based scene description, generating context-aware video representations. We then introduce two training objectives that: 1) encourage the framework to focus on the target point-of-interest regions and 2) suppress distractions from irrelevant regions which are less likely to attract first-person attention. Extensive experiments on Ego4D and Aria Everyday Activities (AEA) datasets demonstrate the effectiveness of our approach, achieving state-of-the-art performance and enhanced robustness across diverse, dynamic egocentric scenarios.

</details>


### [177] [GCR: Geometry-Consistent Routing for Task-Agnostic Continual Anomaly Detection](https://arxiv.org/abs/2601.01856)
*Joongwon Chae,Lihui Luo,Yang Liu,Runming Wang,Dongmei Yu,Zeming Liang,Xi Yuan,Dayan Zhang,Zhenglin Chen,Peiwu Qin,Ilmoon Chae*

Main category: cs.CV

TL;DR: 提出GCR框架，通过几何一致性路由解决任务无关持续异常检测中的路由不稳定问题，避免跨类别分数可比性难题


<details>
  <summary>Details</summary>
Motivation: 工业检测中需要任务无关的持续类别扩展异常检测，现有方法在跨类别路由时因分数分布差异导致性能下降

Method: 在共享冻结的补丁嵌入空间中，通过最小化最近原型距离进行几何一致性路由，然后仅在选定专家内使用基于原型的标准评分规则计算异常图

Result: 在MVTec AD和VisA数据集上，几何一致性路由显著提升路由稳定性，实现接近零遗忘，同时保持竞争力的检测和定位性能

Conclusion: 许多先前归因于表示遗忘的失败实际上可解释为跨头路由中决策规则的不稳定性，分离跨头决策和头内异常评分是关键

Abstract: Feature-based anomaly detection is widely adopted in industrial inspection due to the strong representational power of large pre-trained vision encoders. While most existing methods focus on improving within-category anomaly scoring, practical deployments increasingly require task-agnostic operation under continual category expansion, where the category identity is unknown at test time. In this setting, overall performance is often dominated by expert selection, namely routing an input to an appropriate normality model before any head-specific scoring is applied. However, routing rules that compare head-specific anomaly scores across independently constructed heads are unreliable in practice, as score distributions can differ substantially across categories in scale and tail behavior.
  We propose GCR, a lightweight mixture-of-experts framework for stabilizing task-agnostic continual anomaly detection through geometry-consistent routing. GCR routes each test image directly in a shared frozen patch-embedding space by minimizing an accumulated nearest-prototype distance to category-specific prototype banks, and then computes anomaly maps only within the routed expert using a standard prototype-based scoring rule. By separating cross-head decision making from within-head anomaly scoring, GCR avoids cross-head score comparability issues without requiring end-to-end representation learning.
  Experiments on MVTec AD and VisA show that geometry-consistent routing substantially improves routing stability and mitigates continual performance collapse, achieving near-zero forgetting while maintaining competitive detection and localization performance. These results indicate that many failures previously attributed to representation forgetting can instead be explained by decision-rule instability in cross-head routing. Code is available at https://github.com/jw-chae/GCR

</details>


### [178] [RRNet: Configurable Real-Time Video Enhancement with Arbitrary Local Lighting Variations](https://arxiv.org/abs/2601.01865)
*Wenlong Yang,Canran Jin,Weihang Yuan,Chao Wang,Lifeng Sun*

Main category: cs.CV

TL;DR: 提出RRNet轻量级框架，通过虚拟光源参数估计实现实时视频光照增强，在速度与质量间取得最佳平衡


<details>
  <summary>Details</summary>
Motivation: 现有实时视频增强方法难以在速度与曝光控制间取得平衡，特别是在不均匀光照条件下

Method: 使用轻量级可配置框架，通过估计虚拟光源参数，结合深度感知渲染模块实现局部重光照，无需像素对齐训练数据；提出基于生成式AI的数据集创建流程

Result: 在低光增强、局部光照调整和眩光消除任务上持续优于现有方法，支持实时高分辨率处理

Conclusion: RRNet具有可解释的光照控制和高效架构，适用于视频会议、AR人像增强和移动摄影等实际应用

Abstract: With the growing demand for real-time video enhancement in live applications, existing methods often struggle to balance speed and effective exposure control, particularly under uneven lighting. We introduce RRNet (Rendering Relighting Network), a lightweight and configurable framework that achieves a state-of-the-art tradeoff between visual quality and efficiency. By estimating parameters for a minimal set of virtual light sources, RRNet enables localized relighting through a depth-aware rendering module without requiring pixel-aligned training data. This object-aware formulation preserves facial identity and supports real-time, high-resolution performance using a streamlined encoder and lightweight prediction head. To facilitate training, we propose a generative AI-based dataset creation pipeline that synthesizes diverse lighting conditions at low cost. With its interpretable lighting control and efficient architecture, RRNet is well suited for practical applications such as video conferencing, AR-based portrait enhancement, and mobile photography. Experiments show that RRNet consistently outperforms prior methods in low-light enhancement, localized illumination adjustment, and glare removal.

</details>


### [179] [ESGaussianFace: Emotional and Stylized Audio-Driven Facial Animation via 3D Gaussian Splatting](https://arxiv.org/abs/2601.01847)
*Chuhang Ma,Shuai Tan,Ye Pan,Jiaolong Yang,Xin Tong*

Main category: cs.CV

TL;DR: 提出ESGaussianFace框架，利用3D高斯泼溅技术实现情感与风格化的音频驱动面部动画，通过情感音频引导的空间注意力机制和多阶段训练策略，高效生成高质量、3D一致的情感风格化说话头视频。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动面部动画研究多集中于中性情感视频生成，少数涉及情感音频驱动的方法难以高效整合情感表达与风格特征，生成高质量视频仍面临挑战。

Method: 1. 基于3D高斯泼溅技术重建3D场景并渲染视频；2. 提出情感音频引导的空间注意力机制，融合情感与音频内容特征；3. 设计两个3D高斯形变预测器，实现情感与风格化形变；4. 采用多阶段训练策略，分步学习唇部运动、情感变化与风格特征。

Result: 实验表明，该方法在唇部运动准确性、表情变化多样性和风格特征表现力方面优于现有先进技术，生成结果具有高效性、高质量和3D一致性。

Conclusion: ESGaussianFace框架能有效解决情感与风格化音频驱动面部动画的生成难题，为相关领域提供了高效可靠的解决方案。

Abstract: Most current audio-driven facial animation research primarily focuses on generating videos with neutral emotions. While some studies have addressed the generation of facial videos driven by emotional audio, efficiently generating high-quality talking head videos that integrate both emotional expressions and style features remains a significant challenge. In this paper, we propose ESGaussianFace, an innovative framework for emotional and stylized audio-driven facial animation. Our approach leverages 3D Gaussian Splatting to reconstruct 3D scenes and render videos, ensuring efficient generation of 3D consistent results. We propose an emotion-audio-guided spatial attention method that effectively integrates emotion features with audio content features. Through emotion-guided attention, the model is able to reconstruct facial details across different emotional states more accurately. To achieve emotional and stylized deformations of the 3D Gaussian points through emotion and style features, we introduce two 3D Gaussian deformation predictors. Futhermore, we propose a multi-stage training strategy, enabling the step-by-step learning of the character's lip movements, emotional variations, and style features. Our generated results exhibit high efficiency, high quality, and 3D consistency. Extensive experimental results demonstrate that our method outperforms existing state-of-the-art techniques in terms of lip movement accuracy, expression variation, and style feature expressiveness.

</details>


### [180] [Forget Less by Learning from Parents Through Hierarchical Relationships](https://arxiv.org/abs/2601.01892)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: 提出FLLP框架，在双曲空间中引入父子概念学习机制，缓解定制扩散模型在顺序学习新概念时的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注最小化概念间干扰，但忽略了概念间可能的正向交互作用，导致定制扩散模型在顺序学习时易发生灾难性遗忘。

Method: 在洛伦兹流形中嵌入概念表示，利用其天然适合建模树状层次结构的特性，定义父子关系（已学概念作为新概念的指导），实现知识保留与新概念持续整合。

Result: 在三个公共数据集和一个合成基准测试中验证，FLLP在鲁棒性和泛化能力方面均取得持续改进。

Conclusion: FLLP通过双曲空间的父子概念学习机制，有效缓解了定制扩散模型的灾难性遗忘，同时支持新概念的持续整合。

Abstract: Custom Diffusion Models (CDMs) offer impressive capabilities for personalization in generative modeling, yet they remain vulnerable to catastrophic forgetting when learning new concepts sequentially. Existing approaches primarily focus on minimizing interference between concepts, often neglecting the potential for positive inter-concept interactions. In this work, we present Forget Less by Learning from Parents (FLLP), a novel framework that introduces a parent-child inter-concept learning mechanism in hyperbolic space to mitigate forgetting. By embedding concept representations within a Lorentzian manifold, naturally suited to modeling tree-like hierarchies, we define parent-child relationships in which previously learned concepts serve as guidance for adapting to new ones. Our method not only preserves prior knowledge but also supports continual integration of new concepts. We validate FLLP on three public datasets and one synthetic benchmark, showing consistent improvements in both robustness and generalization.

</details>


### [181] [Entity-Guided Multi-Task Learning for Infrared and Visible Image Fusion](https://arxiv.org/abs/2601.01870)
*Wenyu Shao,Hongbo Liu,Yunchuan Ma,Ruili Wang*

Main category: cs.CV

TL;DR: 提出一种名为EGMT的实体引导多任务学习框架，用于红外与可见光图像融合，通过提取实体级文本信息、构建并行多任务学习架构和跨模态交互模块，显著提升融合图像的质量和语义密度。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本驱动的红外与可见光图像融合方法通常依赖句子级文本信息，容易引入语义噪声且未能充分利用文本的深层语义价值，因此需要更精细的文本引导机制。

Method: 1) 从大视觉语言模型生成的图像描述中提取实体级文本信息；2) 构建并行多任务学习架构，结合图像融合与以实体为伪标签的多标签分类任务；3) 设计实体引导的跨模态交互模块，实现视觉特征与实体级文本特征的细粒度交互。

Result: 在TNO、RoadScene、M3FD和MSRS四个公开数据集上的实验表明，EGMT在保留显著目标、纹理细节和语义一致性方面优于现有先进方法。

Conclusion: EGMT框架通过实体级文本引导和多任务学习，有效提升了红外与可见光图像融合的语义质量与视觉效果，并发布了实体标注数据集以促进相关研究。

Abstract: Existing text-driven infrared and visible image fusion approaches often rely on textual information at the sentence level, which can lead to semantic noise from redundant text and fail to fully exploit the deeper semantic value of textual information. To address these issues, we propose a novel fusion approach named Entity-Guided Multi-Task learning for infrared and visible image fusion (EGMT). Our approach includes three key innovative components: (i) A principled method is proposed to extract entity-level textual information from image captions generated by large vision-language models, eliminating semantic noise from raw text while preserving critical semantic information; (ii) A parallel multi-task learning architecture is constructed, which integrates image fusion with a multi-label classification task. By using entities as pseudo-labels, the multi-label classification task provides semantic supervision, enabling the model to achieve a deeper understanding of image content and significantly improving the quality and semantic density of the fused image; (iii) An entity-guided cross-modal interactive module is also developed to facilitate the fine-grained interaction between visual and entity-level textual features, which enhances feature representation by capturing cross-modal dependencies at both inter-visual and visual-entity levels. To promote the wide application of the entity-guided image fusion framework, we release the entity-annotated version of four public datasets (i.e., TNO, RoadScene, M3FD, and MSRS). Extensive experiments demonstrate that EGMT achieves superior performance in preserving salient targets, texture details, and semantic consistency, compared to the state-of-the-art methods. The code and dataset will be publicly available at https://github.com/wyshao-01/EGMT.

</details>


### [182] [Agentic AI in Remote Sensing: Foundations, Taxonomy, and Emerging Systems](https://arxiv.org/abs/2601.01891)
*Niloufar Alipour Talemi,Julia Boone,Fatemeh Afghah*

Main category: cs.CV

TL;DR: 本文首次全面综述了遥感领域中的智能体AI，提出了单智能体与多智能体系统的统一分类体系，并分析了规划机制、检索增强生成等架构基础，同时探讨了从像素精度到轨迹感知推理的评估范式转变。


<details>
  <summary>Details</summary>
Motivation: 当前地球观测分析正从静态深度学习模型转向自主智能体AI，但现有视觉基础模型和多模态大语言模型在复杂地理空间工作流中缺乏序列规划和工具协同能力，需要系统性梳理该新兴领域的发展路径。

Method: 通过构建统一分类学框架，区分单智能体副驾驶与多智能体系统；系统分析规划机制、检索增强生成、记忆结构等架构要素；综述新兴的轨迹感知推理评估基准。

Result: 建立了遥感智能体AI的首个系统性综述框架，揭示了当前技术在 grounding（语义落地）、安全性和协同编排方面的局限性，并提出了技术发展路线图。

Conclusion: 智能体AI将推动地理空间智能向自主化演进，需加强轨迹感知评估、跨模态对齐和可靠编排机制的研究，以实现稳健的自动化地理空间分析系统。

Abstract: The paradigm of Earth Observation analysis is shifting from static deep learning models to autonomous agentic AI. Although recent vision foundation models and multimodal large language models advance representation learning, they often lack the sequential planning and active tool orchestration required for complex geospatial workflows. This survey presents the first comprehensive review of agentic AI in remote sensing. We introduce a unified taxonomy distinguishing between single-agent copilots and multi-agent systems while analyzing architectural foundations such as planning mechanisms, retrieval-augmented generation, and memory structures. Furthermore, we review emerging benchmarks that move the evaluation from pixel-level accuracy to trajectory-aware reasoning correctness. By critically examining limitations in grounding, safety, and orchestration, this work outlines a strategic roadmap for the development of robust, autonomous geospatial intelligence.

</details>


### [183] [Learning Action Hierarchies via Hybrid Geometric Diffusion](https://arxiv.org/abs/2601.01914)
*Arjun Ramesh Kaushik,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: 提出HybridTAS框架，结合欧几里得与双曲几何的扩散模型，利用动作层次结构进行时序动作分割，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有迭代优化方法未能显式利用人类动作的层次结构，而双曲几何天然适合表示树状关系，可改进动作标签去噪过程。

Method: 提出HybridTAS框架，在扩散模型去噪过程中融合欧几里得与双曲几何：高扩散步长使用抽象高层动作类别（根节点），低步长使用细粒度动作类（叶节点），实现从粗到细的层次化去噪。

Result: 在GTEA、50Salads和Breakfast三个基准数据集上的实验表明，该方法取得了最先进的性能。

Conclusion: 双曲引导的去噪方法能有效利用动作层次结构，提升时序动作分割任务的性能。

Abstract: Temporal action segmentation is a critical task in video understanding, where the goal is to assign action labels to each frame in a video. While recent advances leverage iterative refinement-based strategies, they fail to explicitly utilize the hierarchical nature of human actions. In this work, we propose HybridTAS - a novel framework that incorporates a hybrid of Euclidean and hyperbolic geometries into the denoising process of diffusion models to exploit the hierarchical structure of actions. Hyperbolic geometry naturally provides tree-like relationships between embeddings, enabling us to guide the action label denoising process in a coarse-to-fine manner: higher diffusion timesteps are influenced by abstract, high-level action categories (root nodes), while lower timesteps are refined using fine-grained action classes (leaf nodes). Extensive experiments on three benchmark datasets, GTEA, 50Salads, and Breakfast, demonstrate that our method achieves state-of-the-art performance, validating the effectiveness of hyperbolic-guided denoising for the temporal action segmentation task.

</details>


### [184] [TalkPhoto: A Versatile Training-Free Conversational Assistant for Intelligent Image Editing](https://arxiv.org/abs/2601.01915)
*Yujie Hu,Zecheng Tang,Xu Jiang,Weiqi Li,Jian Zhang*

Main category: cs.CV

TL;DR: 提出TalkPhoto，一种无需训练的多功能图像编辑框架，通过对话交互实现精确图像操作，利用LLM分析用户需求并分层调用现有高级编辑方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑方法依赖多指令数据集训练，耗时耗力且效果有限，需要更灵活高效的免训练解决方案。

Method: 设计提示模板引导开源LLM分析用户指令，分层调用现有编辑方法，实现即插即用的方法调用机制，无需额外训练。

Result: 实验表明该方法在多种编辑任务中能以更少的token消耗实现更准确的调用，并获得更高质量的编辑结果。

Conclusion: TalkPhoto框架通过对话式交互和分层调用策略，实现了稳定高效的免训练图像编辑，为复杂编辑任务提供了灵活解决方案。

Abstract: Thanks to the powerful language comprehension capabilities of Large Language Models (LLMs), existing instruction-based image editing methods have introduced Multimodal Large Language Models (MLLMs) to promote information exchange between instructions and images, ensuring the controllability and flexibility of image editing. However, these frameworks often build a multi-instruction dataset to train the model to handle multiple editing tasks, which is not only time-consuming and labor-intensive but also fails to achieve satisfactory results. In this paper, we present TalkPhoto, a versatile training-free image editing framework that facilitates precise image manipulation through conversational interaction. We instruct the open-source LLM with a specially designed prompt template to analyze user needs after receiving instructions and hierarchically invoke existing advanced editing methods, all without additional training. Moreover, we implement a plug-and-play and efficient invocation of image editing methods, allowing complex and unseen editing tasks to be integrated into the current framework, achieving stable and high-quality editing results. Extensive experiments demonstrate that our method not only provides more accurate invocation with fewer token consumption but also achieves higher editing quality across various image editing tasks.

</details>


### [185] [MacVQA: Adaptive Memory Allocation and Global Noise Filtering for Continual Visual Question Answering](https://arxiv.org/abs/2601.01926)
*Zhifei Li,Yiran Wang,Chenyi Xiong,Yujing Xia,Xiaoju Hou,Yue Zhao,Miao Zhang,Kui Xiao,Bing Yang*

Main category: cs.CV

TL;DR: 提出MacVQA框架，通过自适应记忆分配和全局噪声过滤，在持续学习VQA任务中平衡知识保留、适应性和组合泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法在VQA任务中难以平衡知识保留、适应性和鲁棒特征表示，需要解决多模态信息融合与噪声过滤的挑战。

Method: 采用自适应记忆分配机制（原型记忆）和全局噪声过滤技术，融合视觉与文本信息，优化特征质量和内存使用效率。

Result: 在10个持续VQA任务上超越基线方法，标准任务平均准确率43.38%、遗忘率2.32%，新组合任务平均准确率42.53%、遗忘率3.60%。

Conclusion: MacVQA能有效平衡知识获取、保留和组合泛化，为持续学习VQA提供了兼顾性能与稳定性的解决方案。

Abstract: Visual Question Answering (VQA) requires models to reason over multimodal information, combining visual and textual data. With the development of continual learning, significant progress has been made in retaining knowledge and adapting to new information in the VQA domain. However, current methods often struggle with balancing knowledge retention, adaptation, and robust feature representation. To address these challenges, we propose a novel framework with adaptive memory allocation and global noise filtering called MacVQA for visual question answering. MacVQA fuses visual and question information while filtering noise to ensure robust representations, and employs prototype-based memory allocation to optimize feature quality and memory usage. These designs enable MacVQA to balance knowledge acquisition, retention, and compositional generalization in continual VQA learning. Experiments on ten continual VQA tasks show that MacVQA outperforms existing baselines, achieving 43.38% average accuracy and 2.32% average forgetting on standard tasks, and 42.53% average accuracy and 3.60% average forgetting on novel composition tasks.

</details>


### [186] [AR-MOT: Autoregressive Multi-object Tracking](https://arxiv.org/abs/2601.01925)
*Lianjie Jia,Yuhan Wu,Binghao Ran,Yifan Wang,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: 提出AR-MOT，一种基于大语言模型的自回归多目标跟踪范式，将跟踪任务转化为序列生成问题，无需特定任务头即可输出结构化结果，提升了跨任务适应性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有多目标跟踪方法架构僵化、任务特定性强，难以适应通用化、多模态场景及指令驱动任务，限制了其扩展性和灵活性。

Method: 1. 采用自回归序列生成框架，利用大语言模型输出跟踪结果序列；2. 设计基于预训练检测器的对象分词器增强区域视觉感知；3. 提出区域感知对齐模块缓解全局与区域特征不对齐；4. 引入时序记忆融合模块缓存历史对象令牌以支持长时跟踪。

Result: 在MOT17和DanceTrack数据集上验证了方法的可行性，性能与当前最优方法相当，同时为更通用、灵活的跟踪系统奠定了基础。

Conclusion: AR-MOT通过序列生成范式实现了无需修改模型结构即可扩展新模态或指令的跟踪框架，为多目标跟踪向通用化发展提供了新思路。

Abstract: As multi-object tracking (MOT) tasks continue to evolve toward more general and multi-modal scenarios, the rigid and task-specific architectures of existing MOT methods increasingly hinder their applicability across diverse tasks and limit flexibility in adapting to new tracking formulations. Most approaches rely on fixed output heads and bespoke tracking pipelines, making them difficult to extend to more complex or instruction-driven tasks. To address these limitations, we propose AR-MOT, a novel autoregressive paradigm that formulates MOT as a sequence generation task within a large language model (LLM) framework. This design enables the model to output structured results through flexible sequence construction, without requiring any task-specific heads. To enhance region-level visual perception, we introduce an Object Tokenizer based on a pretrained detector. To mitigate the misalignment between global and regional features, we propose a Region-Aware Alignment (RAA) module, and to support long-term tracking, we design a Temporal Memory Fusion (TMF) module that caches historical object tokens. AR-MOT offers strong potential for extensibility, as new modalities or instructions can be integrated by simply modifying the output sequence format without altering the model architecture. Extensive experiments on MOT17 and DanceTrack validate the feasibility of our approach, achieving performance comparable to state-of-the-art methods while laying the foundation for more general and flexible MOT systems.

</details>


### [187] [AFTER: Mitigating the Object Hallucination of LVLM via Adaptive Factual-Guided Activation Editing](https://arxiv.org/abs/2601.01957)
*Tianbo Wang,Yuqing Ma,Kewei Liao,Zhange Zhang,Simin Li,Jinyang Guo,Xianglong Liu*

Main category: cs.CV

TL;DR: 提出AFTER方法，通过事实增强激活引导和查询自适应偏移优化，有效减少大视觉语言模型中的物体幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型存在语言偏见导致的物体幻觉问题（类别、属性、关系幻觉），阻碍可信AI应用；现有编辑方法缺乏事实文本语义的有效引导。

Method: AFTER方法包含两个组件：事实增强激活引导（FAS）提供事实语义指导，查询自适应偏移优化（QAO）建立查询特定的编辑向量。

Result: 在三个主流LVLM和标准幻觉基准测试中验证有效，在AMBER基准上比基线减少16.3%的幻觉。

Conclusion: AFTER方法能自适应地将偏置激活引导至事实语义，显著缓解物体幻觉问题，代码和数据将开源。

Abstract: Large Vision-Language Models (LVLMs) have achieved substantial progress in cross-modal tasks. However, due to language bias, LVLMs are susceptible to object hallucination, which can be primarily divided into category, attribute, and relation hallucination, significantly impeding the trustworthy AI applications. Editing the internal activations of LVLMs has shown promising effectiveness in mitigating hallucinations with minimal cost. However, previous editing approaches neglect the effective guidance offered by factual textual semantics, thereby struggling to explicitly mitigate language bias. To address these issues, we propose Adaptive Factual-guided Visual-Textual Editing for hallucination mitigation (AFTER), which comprises Factual-Augmented Activation Steering (FAS) and Query-Adaptive Offset Optimization (QAO), to adaptively guides the original biased activations towards factual semantics. Specifically, FAS is proposed to provide factual and general guidance for activation editing, thereby explicitly modeling the precise visual-textual associations. Subsequently, QAO introduces a query-aware offset estimator to establish query-specific editing from the general steering vector, enhancing the diversity and granularity of editing. Extensive experiments on standard hallucination benchmarks across three widely adopted LVLMs validate the efficacy of the proposed AFTER, notably achieving up to a 16.3% reduction of hallucination over baseline on the AMBER benchmark. Our code and data will be released for reproducibility.

</details>


### [188] [Face Normal Estimation from Rags to Riches](https://arxiv.org/abs/2601.01950)
*Meng Wang,Wenjing Dai,Jiawan Zhang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 提出了一种从粗到精的面部法线估计方法，通过小数据集训练粗估计模型生成指导样本，再使用自注意力机制和细化网络提升质量，显著减少对大规模配对数据和计算资源的需求。


<details>
  <summary>Details</summary>
Motivation: 现有面部法线估计方法严重依赖大规模配对训练数据，本研究旨在通过分阶段设计降低数据需求，同时保持估计质量。

Method: 1. 使用小数据集训练粗估计模型生成初始法线（作为指导样本）；2. 引入自注意力机制捕获长程依赖以修复局部伪影；3. 设计细化网络将人脸图像与指导样本映射为高质量精细法线。

Result: 实验表明该方法在训练成本和估计质量上均优于现有先进方法，且通过消融研究验证了各模块的有效性。

Conclusion: 所提出的从粗到精框架能有效减少对大规模配对数据的依赖，在保证估计精度的同时显著降低计算资源需求，代码已开源。

Abstract: Although recent approaches to face normal estimation have achieved promising results, their effectiveness heavily depends on large-scale paired data for training. This paper concentrates on relieving this requirement via developing a coarse-to-fine normal estimator. Concretely, our method first trains a neat model from a small dataset to produce coarse face normals that perform as guidance (called exemplars) for the following refinement. A self-attention mechanism is employed to capture long-range dependencies, thus remedying severe local artifacts left in estimated coarse facial normals. Then, a refinement network is customized for the sake of mapping input face images together with corresponding exemplars to fine-grained high-quality facial normals. Such a logical function split can significantly cut the requirement of massive paired data and computational resource. Extensive experiments and ablation studies are conducted to demonstrate the efficacy of our design and reveal its superiority over state-of-the-art methods in terms of both training expense as well as estimation quality. Our code and models are open-sourced at: https://github.com/AutoHDR/FNR2R.git.

</details>


### [189] [MotionAdapter: Video Motion Transfer via Content-Aware Attention Customization](https://arxiv.org/abs/2601.01955)
*Zhexin Zhang,Yifeng Zhu,Yangyang Xu,Long Chen,Yong Du,Shengfeng He,Jun Yu*

Main category: cs.CV

TL;DR: 提出MotionAdapter框架，用于在基于扩散Transformer的视频生成模型中实现鲁棒且语义对齐的复杂运动迁移。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的文本到视频模型在生成高质量视频方面取得进展，但在视频间迁移复杂运动仍面临挑战，需要显式解耦运动与外观并自适应定制运动以适应目标内容。

Method: 1) 通过分析3D全注意力模块的跨帧注意力提取注意力驱动的运动场；2) 引入DINO引导的运动定制模块，基于内容对应关系重排和细化运动场；3) 使用定制化运动场指导DiT去噪过程。

Result: 大量实验表明，MotionAdapter在定性和定量评估上均优于现有先进方法，并能自然支持复杂运动迁移和缩放等运动编辑任务。

Conclusion: MotionAdapter通过内容感知的运动迁移框架，有效解决了视频间复杂运动迁移的难题，实现了语义对齐的运动定制化生成。

Abstract: Recent advances in diffusion-based text-to-video models, particularly those built on the diffusion transformer architecture, have achieved remarkable progress in generating high-quality and temporally coherent videos. However, transferring complex motions between videos remains challenging. In this work, we present MotionAdapter, a content-aware motion transfer framework that enables robust and semantically aligned motion transfer within DiT-based T2V models. Our key insight is that effective motion transfer requires \romannumeral1) explicit disentanglement of motion from appearance and \romannumeral 2) adaptive customization of motion to target content. MotionAdapter first isolates motion by analyzing cross-frame attention within 3D full-attention modules to extract attention-derived motion fields. To bridge the semantic gap between reference and target videos, we further introduce a DINO-guided motion customization module that rearranges and refines motion fields based on content correspondences. The customized motion field is then used to guide the DiT denoising process, ensuring that the synthesized video inherits the reference motion while preserving target appearance and semantics. Extensive experiments demonstrate that MotionAdapter outperforms state-of-the-art methods in both qualitative and quantitative evaluations. Moreover, MotionAdapter naturally supports complex motion transfer and motion editing tasks such as zooming.

</details>


### [190] [Forget Less by Learning Together through Concept Consolidation](https://arxiv.org/abs/2601.01963)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: 提出FL2T框架，通过跨概念交互学习解决定制扩散模型在持续学习中的灾难性遗忘问题，实现并发、顺序无关的概念学习。


<details>
  <summary>Details</summary>
Motivation: 现有定制扩散模型在持续学习新概念时会出现灾难性遗忘，且现有方法多基于顺序学习设定，忽略了概念间的交互作用。

Method: 提出FL2T框架，引入集合不变的跨概念学习模块，通过代理指导跨概念特征选择，促进知识保留和迁移。

Result: 在三个数据集上的实验表明，该方法显著提升概念保留能力，在十个任务的增量概念学习中平均CLIP图像对齐分数至少提升2%。

Conclusion: 跨概念催化行为在增量概念学习中具有有效性，FL2T框架能同时保留旧概念并高效整合新概念，缓解灾难性遗忘。

Abstract: Custom Diffusion Models (CDMs) have gained significant attention due to their remarkable ability to personalize generative processes. However, existing CDMs suffer from catastrophic forgetting when continuously learning new concepts. Most prior works attempt to mitigate this issue under the sequential learning setting with a fixed order of concept inflow and neglect inter-concept interactions. In this paper, we propose a novel framework - Forget Less by Learning Together (FL2T) - that enables concurrent and order-agnostic concept learning while addressing catastrophic forgetting. Specifically, we introduce a set-invariant inter-concept learning module where proxies guide feature selection across concepts, facilitating improved knowledge retention and transfer. By leveraging inter-concept guidance, our approach preserves old concepts while efficiently incorporating new ones. Extensive experiments, across three datasets, demonstrates that our method significantly improves concept retention and mitigates catastrophic forgetting, highlighting the effectiveness of inter-concept catalytic behavior in incremental concept learning of ten tasks with at least 2% gain on average CLIP Image Alignment scores.

</details>


### [191] [Thinking with Blueprints: Assisting Vision-Language Models in Spatial Reasoning via Structured Object Representation](https://arxiv.org/abs/2601.01984)
*Weijian Ma,Shizhao Sun,Tianyu Yu,Ruiyu Wang,Tat-Seng Chua,Jiang Bian*

Main category: cs.CV

TL;DR: 提出一种将对象中心蓝图集成到视觉语言模型中的方法，通过结构化表示增强空间推理能力，在实验中优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法在空间推理上存在局限：要么关注局部图像块而削弱全局空间感知，要么标记孤立坐标而忽略对象整体组织，需要更有效的空间语义理解方法。

Method: 1) 构建JSON格式蓝图记录对象位置、大小和属性；2) 使用蓝图嵌入推理轨迹进行监督微调；3) 在强化学习中引入蓝图感知奖励；4) 应用抗捷径数据增强技术。

Result: 该方法在实验中 consistently 优于现有视觉语言模型和专用空间推理模型。

Conclusion: 通过对象中心蓝图的结构化表示和配套训练技术，能够有效提升视觉语言模型的空间推理能力，实现从视觉感知向空间语义理解的进步。

Abstract: Spatial reasoning -- the ability to perceive and reason about relationships in space -- advances vision-language models (VLMs) from visual perception toward spatial semantic understanding. Existing approaches either revisit local image patches, improving fine-grained perception but weakening global spatial awareness, or mark isolated coordinates, which capture object locations but overlook their overall organization. In this work, we integrate the cognitive concept of an object-centric blueprint into VLMs to enhance spatial reasoning. Given an image and a question, the model first constructs a JSON-style blueprint that records the positions, sizes, and attributes of relevant objects, and then reasons over this structured representation to produce the final answer. To achieve this, we introduce three key techniques: (1) blueprint-embedded reasoning traces for supervised fine-tuning to elicit basic reasoning skills; (2) blueprint-aware rewards in reinforcement learning to encourage the blueprint to include an appropriate number of objects and to align final answers with this causal reasoning; and (3) anti-shortcut data augmentation that applies targeted perturbations to images and questions, discouraging reliance on superficial visual or linguistic cues. Experiments show that our method consistently outperforms existing VLMs and specialized spatial reasoning models.

</details>


### [192] [Nighttime Hazy Image Enhancement via Progressively and Mutually Reinforcing Night-Haze Priors](https://arxiv.org/abs/2601.01998)
*Chen Zhu,Huiwen Zhang,Mu He,Yujie Li,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 提出一种夜间雾霾图像增强框架，通过强化雾霾与低光先验的内在一致性，在图像、块和像素级别渐进恢复全局结构、区域模式和细节。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理雾霾或低光等单一退化类型，忽略了多种退化类型的相互作用，导致夜间雾霾图像可见性提升有限。

Method: 设计多专家框架，在视觉和频域中利用图像级、块级和像素级专家渐进恢复不同层次信息；引入频率感知路由器自适应分配专家贡献。

Result: 在夜间去雾基准测试中取得定量和定性的优越性能，并展示模型在白天去雾和低光增强任务上的泛化能力。

Conclusion: 通过协同利用雾霾与低光先验的领域知识，提出的渐进式多专家框架能有效提升复杂退化条件下图像的可见性。

Abstract: Enhancing the visibility of nighttime hazy images is challenging due to the complex degradation distributions. Existing methods mainly address a single type of degradation (e.g., haze or low-light) at a time, ignoring the interplay of different degradation types and resulting in limited visibility improvement. We observe that the domain knowledge shared between low-light and haze priors can be reinforced mutually for better visibility. Based on this key insight, in this paper, we propose a novel framework that enhances visibility in nighttime hazy images by reinforcing the intrinsic consistency between haze and low-light priors mutually and progressively. In particular, our model utilizes image-, patch-, and pixel-level experts that operate across visual and frequency domains to recover global scene structure, regional patterns, and fine-grained details progressively. A frequency-aware router is further introduced to adaptively guide the contribution of each expert, ensuring robust image restoration. Extensive experiments demonstrate the superior performance of our model on nighttime dehazing benchmarks both quantitatively and qualitatively. Moreover, we showcase the generalizability of our model in daytime dehazing and low-light enhancement tasks.

</details>


### [193] [API: Empowering Generalizable Real-World Image Dehazing via Adaptive Patch Importance Learning](https://arxiv.org/abs/2601.01992)
*Chen Zhu,Huiwen Zhang,Yujie Li,Mu He,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 提出一种自适应块重要性感知（API）框架用于真实世界图像去雾，包含自动雾霾生成（AHG）模块和密度感知去雾（DHR）模块，并引入多负样本对比去雾（MNCD）损失函数，在多个真实世界基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在复杂真实世界雾霾场景中性能显著下降，主要由于训练数据有限和雾霾密度分布的内在复杂性。

Method: 1. 自动雾霾生成（AHG）模块：通过生成真实多样的雾霾图像提供混合数据增强策略；2. 密度感知去雾（DHR）模块：以自适应块重要性感知方式处理不同雾霾密度分布的区域；3. 多负样本对比去雾（MNCD）损失：充分利用空间域和频域中多个负样本信息。

Result: 在多个真实世界基准测试中实现了最先进的性能，在定量指标和定性视觉质量方面均表现出色，并对不同雾霾分布具有鲁棒泛化能力。

Conclusion: 提出的API框架通过数据增强、密度感知处理和新型损失函数，有效解决了真实世界图像去雾的挑战，展示了强大的泛化能力和优越的去雾效果。

Abstract: Real-world image dehazing is a fundamental yet challenging task in low-level vision. Existing learning-based methods often suffer from significant performance degradation when applied to complex real-world hazy scenes, primarily due to limited training data and the intrinsic complexity of haze density distributions.To address these challenges, we introduce a novel Adaptive Patch Importance-aware (API) framework for generalizable real-world image dehazing. Specifically, our framework consists of an Automatic Haze Generation (AHG) module and a Density-aware Haze Removal (DHR) module. AHG provides a hybrid data augmentation strategy by generating realistic and diverse hazy images as additional high-quality training data. DHR considers hazy regions with varying haze density distributions for generalizable real-world image dehazing in an adaptive patch importance-aware manner. To alleviate the ambiguity of the dehazed image details, we further introduce a new Multi-Negative Contrastive Dehazing (MNCD) loss, which fully utilizes information from multiple negative samples across both spatial and frequency domains. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across multiple real-world benchmarks, delivering strong results in both quantitative metrics and qualitative visual quality, and exhibiting robust generalization across diverse haze distributions.

</details>


### [194] [Adapting Depth Anything to Adverse Imaging Conditions with Events](https://arxiv.org/abs/2601.02020)
*Shihan Peng,Yuyang Xiong,Hanyu Zhou,Zhiwei Shi,Haoyue Liu,Gang Chen,Luxin Yan,Yi Chang*

Main category: cs.CV

TL;DR: 提出ADAE框架，通过事件相机增强Depth Anything深度估计模型在动态和恶劣光照条件下的性能，利用熵感知空间融合和运动引导时间校正来补偿图像退化。


<details>
  <summary>Details</summary>
Motivation: 现有深度基础模型（如Depth Anything）在理想场景表现良好，但在极端光照和运动模糊等恶劣成像条件下性能下降。事件相机虽能提供高动态范围和时间分辨率，但现有融合模型未能继承基础模型的开放世界知识和泛化能力。

Method: 1. 熵感知空间融合：基于信息熵策略自适应融合帧图像和事件特征，指示光照退化程度；2. 运动引导时间校正：利用事件运动线索重新校准模糊区域的模糊特征。两者在统一框架下互补。

Result: 大量实验验证了该方法在退化场景下的优越性，代码将在论文接受后开源。

Conclusion: ADAE框架通过事件引导的时空融合有效增强了Depth Anything在恶劣成像条件下的鲁棒性，为机器人系统提供了更可靠的深度估计解决方案。

Abstract: Robust depth estimation under dynamic and adverse lighting conditions is essential for robotic systems. Currently, depth foundation models, such as Depth Anything, achieve great success in ideal scenes but remain challenging under adverse imaging conditions such as extreme illumination and motion blur. These degradations corrupt the visual signals of frame cameras, weakening the discriminative features of frame-based depths across the spatial and temporal dimensions. Typically, existing approaches incorporate event cameras to leverage their high dynamic range and temporal resolution, aiming to compensate for corrupted frame features. However, such specialized fusion models are predominantly trained from scratch on domain-specific datasets, thereby failing to inherit the open-world knowledge and robust generalization inherent to foundation models. In this work, we propose ADAE, an event-guided spatiotemporal fusion framework for Depth Anything in degraded scenes. Our design is guided by two key insights: 1) Entropy-Aware Spatial Fusion. We adaptively merge frame-based and event-based features using an information entropy strategy to indicate illumination-induced degradation. 2) Motion-Guided Temporal Correction. We resort to the event-based motion cue to recalibrate ambiguous features in blurred regions. Under our unified framework, the two components are complementary to each other and jointly enhance Depth Anything under adverse imaging conditions. Extensive experiments have been performed to verify the superiority of the proposed method. Our code will be released upon acceptance.

</details>


### [195] [Towards Any-Quality Image Segmentation via Generative and Adaptive Latent Space Enhancement](https://arxiv.org/abs/2601.02018)
*Guangqian Guo,Aixi Ren,Yong Guo,Xuehui Yu,Jiacheng Tian,Wenli Li,Yaoxing Wang,Shan Gao*

Main category: cs.CV

TL;DR: 提出GleSAM++方法，通过生成式潜在空间增强提升SAM模型在低质量图像上的分割鲁棒性，引入特征分布对齐、通道复制扩展和退化感知自适应增强机制。


<details>
  <summary>Details</summary>
Motivation: SAM模型在严重退化、低质量图像上性能显著下降，限制了其在真实场景中的应用，需要提升模型对图像质量变化的泛化能力。

Method: 1. 使用生成式潜在空间增强提升低质量图像鲁棒性；2. 引入特征分布对齐（FDA）和通道复制扩展（CRE）增强预训练扩散模型与分割框架的兼容性；3. 提出退化感知自适应增强（DAE）机制，通过退化程度预测和退化感知重建两阶段解耦重建过程。

Result: 大量实验表明，GleSAM++在复杂退化条件下显著提升分割鲁棒性，同时保持对清晰图像的泛化能力，在未见过的退化类型上也表现良好。

Conclusion: GleSAM++能以最小额外参数量应用于预训练SAM/SAM2模型，有效提升模型对图像质量变化的适应能力，证明了方法的通用性和数据集的多样性价值。

Abstract: Segment Anything Models (SAMs), known for their exceptional zero-shot segmentation performance, have garnered significant attention in the research community. Nevertheless, their performance drops significantly on severely degraded, low-quality images, limiting their effectiveness in real-world scenarios. To address this, we propose GleSAM++, which utilizes Generative Latent space Enhancement to boost robustness on low-quality images, thus enabling generalization across various image qualities. Additionally, to improve compatibility between the pre-trained diffusion model and the segmentation framework, we introduce two techniques, i.e., Feature Distribution Alignment (FDA) and Channel Replication and Expansion (CRE). However, the above components lack explicit guidance regarding the degree of degradation. The model is forced to implicitly fit a complex noise distribution that spans conditions from mild noise to severe artifacts, which substantially increases the learning burden and leads to suboptimal reconstructions. To address this issue, we further introduce a Degradation-aware Adaptive Enhancement (DAE) mechanism. The key principle of DAE is to decouple the reconstruction process for arbitrary-quality features into two stages: degradation-level prediction and degradation-aware reconstruction. Our method can be applied to pre-trained SAM and SAM2 with only minimal additional learnable parameters, allowing for efficient optimization. Extensive experiments demonstrate that GleSAM++ significantly improves segmentation robustness on complex degradations while maintaining generalization to clear images. Furthermore, GleSAM++ also performs well on unseen degradations, underscoring the versatility of our approach and dataset.

</details>


### [196] [Leveraging 2D-VLM for Label-Free 3D Segmentation in Large-Scale Outdoor Scene Understanding](https://arxiv.org/abs/2601.02029)
*Toshihiko Nishimura,Hirofumi Abe,Kazuhiko Murasaki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

TL;DR: 提出一种无需标注3D训练数据或配对RGB图像的大规模点云3D语义分割方法，通过虚拟相机将点云投影到2D图像，利用基础2D模型和自然语言提示进行分割，并通过多视角加权投票实现3D分割。


<details>
  <summary>Details</summary>
Motivation: 传统3D语义分割方法依赖大量标注的3D训练数据或配对RGB图像，成本高昂且泛化能力有限；需要一种无需训练数据、支持开放词汇的3D分割方法。

Method: 1. 使用虚拟相机将3D点云投影到多个2D视角；2. 利用基础2D模型结合自然语言提示进行2D语义分割；3. 通过加权投票聚合多视角预测结果得到3D分割。

Result: 1. 在无训练数据方法中表现最优；2. 分割精度接近有监督方法；3. 支持开放词汇识别，可通过任意文本查询检测物体。

Conclusion: 该方法实现了无需3D标注数据的开放词汇3D语义分割，突破了传统有监督方法的局限性，为大规模点云理解提供了高效灵活的解决方案。

Abstract: This paper presents a novel 3D semantic segmentation method for large-scale point cloud data that does not require annotated 3D training data or paired RGB images. The proposed approach projects 3D point clouds onto 2D images using virtual cameras and performs semantic segmentation via a foundation 2D model guided by natural language prompts. 3D segmentation is achieved by aggregating predictions from multiple viewpoints through weighted voting. Our method outperforms existing training-free approaches and achieves segmentation accuracy comparable to supervised methods. Moreover, it supports open-vocabulary recognition, enabling users to detect objects using arbitrary text queries, thus overcoming the limitations of traditional supervised approaches.

</details>


### [197] [AlignVTOFF: Texture-Spatial Feature Alignment for High-Fidelity Virtual Try-Off](https://arxiv.org/abs/2601.02038)
*Yihan Zhu,Mengying Ge*

Main category: cs.CV

TL;DR: 提出AlignVTOFF框架解决虚拟试穿图像生成中的纹理衰减问题，通过并行U-Net架构和纹理-空间特征对齐机制，显著提升平铺服装的结构真实感和高频细节保真度。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法依赖轻量级模块进行快速特征提取，难以保持结构化图案和细粒度细节，导致生成过程中出现纹理衰减问题。

Method: 提出基于参考U-Net和纹理-空间特征对齐（TSFA）的并行U-Net框架。参考U-Net进行多尺度特征提取以增强几何保真度；TSFA通过可训练交叉注意力模块和冻结自注意力模块的混合设计，将参考服装特征注入冻结去噪U-Net。

Result: 在多种设置下的广泛实验表明，AlignVTOFF始终优于现有最先进方法，生成的平铺服装结果具有更高的结构真实感和高频细节保真度。

Conclusion: AlignVTOFF通过创新的并行架构和特征对齐机制，有效解决了虚拟试穿图像生成中的纹理衰减问题，为复杂几何变形和高频纹理的合成提供了有效解决方案。

Abstract: Virtual Try-Off (VTOFF) is a challenging multimodal image generation task that aims to synthesize high-fidelity flat-lay garments under complex geometric deformation and rich high-frequency textures. Existing methods often rely on lightweight modules for fast feature extraction, which struggles to preserve structured patterns and fine-grained details, leading to texture attenuation during generation.To address these issues, we propose AlignVTOFF, a novel parallel U-Net framework built upon a Reference U-Net and Texture-Spatial Feature Alignment (TSFA). The Reference U-Net performs multi-scale feature extraction and enhances geometric fidelity, enabling robust modeling of deformation while retaining complex structured patterns. TSFA then injects the reference garment features into a frozen denoising U-Net via a hybrid attention design, consisting of a trainable cross-attention module and a frozen self-attention module. This design explicitly aligns texture and spatial cues and alleviates the loss of high-frequency information during the denoising process.Extensive experiments across multiple settings demonstrate that AlignVTOFF consistently outperforms state-of-the-art methods, producing flat-lay garment results with improved structural realism and high-frequency detail fidelity.

</details>


### [198] [InpaintHuman: Reconstructing Occluded Humans with Multi-Scale UV Mapping and Identity-Preserving Diffusion Inpainting](https://arxiv.org/abs/2601.02098)
*Jinlong Fan,Shanshan Zhao,Liang Zheng,Jing Zhang,Yuxiang Yang,Mingming Gong*

Main category: cs.CV

TL;DR: 提出InpaintHuman方法，从遮挡的单目视频中重建完整、可动画的3D人体化身，通过多尺度UV参数化表示和身份保持扩散修复模块解决严重遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的方法在严重遮挡下重建不完整，导致几何损坏和时间不一致，需要一种能从遮挡视频生成高保真完整化身的方法。

Method: 1) 多尺度UV参数化表示，采用分层粗到细特征插值；2) 身份保持扩散修复模块，结合文本反转和语义条件引导，使用像素级监督确保身份保真度。

Result: 在合成基准（PeopleSnapshot、ZJU-MoCap）和真实场景（OcMotion）上验证，在不同姿态和视角下均取得竞争性性能，重建质量持续提升。

Conclusion: InpaintHuman能有效处理遮挡，生成高质量、完整且可动画的3D人体化身，优于现有方法。

Abstract: Reconstructing complete and animatable 3D human avatars from monocular videos remains challenging, particularly under severe occlusions. While 3D Gaussian Splatting has enabled photorealistic human rendering, existing methods struggle with incomplete observations, often producing corrupted geometry and temporal inconsistencies. We present InpaintHuman, a novel method for generating high-fidelity, complete, and animatable avatars from occluded monocular videos. Our approach introduces two key innovations: (i) a multi-scale UV-parameterized representation with hierarchical coarse-to-fine feature interpolation, enabling robust reconstruction of occluded regions while preserving geometric details; and (ii) an identity-preserving diffusion inpainting module that integrates textual inversion with semantic-conditioned guidance for subject-specific, temporally coherent completion. Unlike SDS-based methods, our approach employs direct pixel-level supervision to ensure identity fidelity. Experiments on synthetic benchmarks (PeopleSnapshot, ZJU-MoCap) and real-world scenarios (OcMotion) demonstrate competitive performance with consistent improvements in reconstruction quality across diverse poses and viewpoints.

</details>


### [199] [MCD-Net: A Lightweight Deep Learning Baseline for Optical-Only Moraine Segmentation](https://arxiv.org/abs/2601.02091)
*Zhehuan Cao,Fiseha Berhanu Tesema,Ping Fu,Jianfeng Ren,Ahmed Nasr*

Main category: cs.CV

TL;DR: 本研究提出了首个大规模仅使用光学图像的冰碛物分割数据集，并开发了轻量级MCD-Net模型，在降低60%以上计算成本的同时实现了可靠的冰碛体分割。


<details>
  <summary>Details</summary>
Motivation: 冰川分割对重建历史冰川动态和评估气候变化驱动的景观变化至关重要，但弱光学对比度和高分辨率DEM数据有限阻碍了自动化制图。

Method: 构建了包含3340张手动标注高分辨率谷歌地球图像的数据集；开发了MCD-Net模型，集成MobileNetV2编码器、CBAM注意力模块和DeepLabV3+解码器；与ResNet152、Xception等深层骨干网络进行对比实验。

Result: MCD-Net达到62.3%的平均交并比和72.8%的Dice系数，计算成本降低60%以上；尽管山脊描绘受亚像素宽度和光谱模糊性限制，但证明仅用光学图像可实现可靠的冰碛体分割。

Conclusion: 公开的数据集和代码为冰碛物特定分割建立了可复现的基准，并为高海拔冰川监测提供了可部署的基线模型。

Abstract: Glacial segmentation is essential for reconstructing past glacier dynamics and evaluating climate-driven landscape change. However, weak optical contrast and the limited availability of high-resolution DEMs hinder automated mapping. This study introduces the first large-scale optical-only moraine segmentation dataset, comprising 3,340 manually annotated high-resolution images from Google Earth covering glaciated regions of Sichuan and Yunnan, China. We develop MCD-Net, a lightweight baseline that integrates a MobileNetV2 encoder, a Convolutional Block Attention Module (CBAM), and a DeepLabV3+ decoder. Benchmarking against deeper backbones (ResNet152, Xception) shows that MCD-Net achieves 62.3\% mean Intersection over Union (mIoU) and 72.8\% Dice coefficient while reducing computational cost by more than 60\%. Although ridge delineation remains constrained by sub-pixel width and spectral ambiguity, the results demonstrate that optical imagery alone can provide reliable moraine-body segmentation. The dataset and code are publicly available at https://github.com/Lyra-alpha/MCD-Net, establishing a reproducible benchmark for moraine-specific segmentation and offering a deployable baseline for high-altitude glacial monitoring.

</details>


### [200] [PhysSFI-Net: Physics-informed Geometric Learning of Skeletal and Facial Interactions for Orthognathic Surgical Outcome Prediction](https://arxiv.org/abs/2601.02088)
*Jiahao Bao,Huazhen Liu,Yu Zhuang,Leran Tao,Xinyu Xu,Yongtao Shi,Mengjia Cheng,Yiming Wang,Congshuang Ku,Ting Zeng,Yilang Du,Siyi Chen,Shunyao Shen,Suncheng Xiang,Hongbo Yu*

Main category: cs.CV

TL;DR: 本研究开发了PhysSFI-Net，一个物理信息几何深度学习框架，用于精确预测正颌手术后的软组织变形，在预测精度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统生物力学模型计算成本高，而几何深度学习方法缺乏可解释性，因此需要一种既准确又可解释的方法来模拟术后面部形态，以支持术前规划。

Method: PhysSFI-Net包含三个组件：1）结合注意力的分层图模块，提取骨骼-面部交互特征；2）基于LSTM的序列预测器，用于增量软组织变形；3）生物力学启发的模块，用于高分辨率面部表面重建。使用点云形状误差、表面偏差误差和标志点定位误差进行评估。

Result: 在135名患者数据上，PhysSFI-Net的点云形状误差为1.070±0.088 mm，表面偏差误差为1.296±0.349 mm，标志点定位误差为2.445±1.326 mm，优于现有方法ACMT-Net。

Conclusion: PhysSFI-Net能够以高精度和可解释性预测术后面部形态，在正颌手术规划和模拟中具有强大的临床应用潜力。

Abstract: Orthognathic surgery repositions jaw bones to restore occlusion and enhance facial aesthetics. Accurate simulation of postoperative facial morphology is essential for preoperative planning. However, traditional biomechanical models are computationally expensive, while geometric deep learning approaches often lack interpretability. In this study, we develop and validate a physics-informed geometric deep learning framework named PhysSFI-Net for precise prediction of soft tissue deformation following orthognathic surgery. PhysSFI-Net consists of three components: a hierarchical graph module with craniofacial and surgical plan encoders combined with attention mechanisms to extract skeletal-facial interaction features; a Long Short-Term Memory (LSTM)-based sequential predictor for incremental soft tissue deformation; and a biomechanics-inspired module for high-resolution facial surface reconstruction. Model performance was assessed using point cloud shape error (Hausdorff distance), surface deviation error, and landmark localization error (Euclidean distances of craniomaxillofacial landmarks) between predicted facial shapes and corresponding ground truths. A total of 135 patients who underwent combined orthodontic and orthognathic treatment were included for model training and validation. Quantitative analysis demonstrated that PhysSFI-Net achieved a point cloud shape error of 1.070 +/- 0.088 mm, a surface deviation error of 1.296 +/- 0.349 mm, and a landmark localization error of 2.445 +/- 1.326 mm. Comparative experiments indicated that PhysSFI-Net outperformed the state-of-the-art method ACMT-Net in prediction accuracy. In conclusion, PhysSFI-Net enables interpretable, high-resolution prediction of postoperative facial morphology with superior accuracy, showing strong potential for clinical application in orthognathic surgical planning and simulation.

</details>


### [201] [HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures](https://arxiv.org/abs/2601.02103)
*Yating Wang,Yuan Sun,Xuan Wang,Ran Yi,Boyao Zhou,Yipengjing Sun,Hongyu Liu,Yinuo Wang,Lizhuang Ma*

Main category: cs.CV

TL;DR: 提出HeadLighter框架，通过双分支架构和渐进式解耦训练，实现3D头部生成模型中光照与固有外观的物理可解释分解，支持显式光照和视角编辑。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的头部生成模型存在光照与外观深度纠缠的问题，导致无法实现可控重光照；现有解耦方法依赖强假设，难以处理复杂光照。

Method: 设计双分支架构分别建模光照不变头部属性和物理渲染组件；采用渐进式解耦训练，在受控光照条件下采集的多视角图像监督下注入外观先验；引入蒸馏策略生成高质量法线。

Result: 方法在保持高质量生成和实时渲染的同时，支持显式光照和视角编辑；实验验证了其有效性。

Conclusion: HeadLighter实现了外观与光照的物理可分解性，为可控头部生成提供了新方案；将公开代码和数据集。

Abstract: Recent 3D-aware head generative models based on 3D Gaussian Splatting achieve real-time, photorealistic and view-consistent head synthesis. However, a fundamental limitation persists: the deep entanglement of illumination and intrinsic appearance prevents controllable relighting. Existing disentanglement methods rely on strong assumptions to enable weakly supervised learning, which restricts their capacity for complex illumination. To address this challenge, we introduce HeadLighter, a novel supervised framework that learns a physically plausible decomposition of appearance and illumination in head generative models. Specifically, we design a dual-branch architecture that separately models lighting-invariant head attributes and physically grounded rendering components. A progressive disentanglement training is employed to gradually inject head appearance priors into the generative architecture, supervised by multi-view images captured under controlled light conditions with a light stage setup. We further introduce a distillation strategy to generate high-quality normals for realistic rendering. Experiments demonstrate that our method preserves high-quality generation and real-time rendering, while simultaneously supporting explicit lighting and viewpoint editing. We will publicly release our code and dataset.

</details>


### [202] [360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images](https://arxiv.org/abs/2601.02102)
*Jiaqi Yao,Zhongmiao Yan,Jingyi Xu,Songpengcheng Xia,Yan Xiang,Ling Pei*

Main category: cs.CV

TL;DR: 提出一种基于3D高斯泼溅的前馈框架，通过深度-法向几何正则化提升几何一致性，在保持高质量渲染的同时改善表面重建精度。


<details>
  <summary>Details</summary>
Motivation: 传统多视图立体方法在稀疏视角或低纹理区域表现不佳，神经渲染方法需要逐场景优化且无法实时，现有前馈3DGS方法侧重视觉质量但几何一致性不足，限制了其在空间感知任务中的可靠性。

Method: 采用前馈3D高斯泼溅框架，引入深度-法向几何正则化，将渲染深度梯度与法向信息耦合，监督高斯基元的旋转、尺度和位置以提升点云和表面精度。

Result: 实验表明，该方法在保持高质量渲染的同时显著提升了几何一致性，为空间感知任务中的三维重建提供了有效解决方案。

Conclusion: 所提出的框架在360度图像上实现了几何一致的高斯基元生成，平衡了渲染质量与几何精度，适用于增强现实、机器人和数字孪生等空间智能应用。

Abstract: 3D scene reconstruction is fundamental for spatial intelligence applications such as AR, robotics, and digital twins. Traditional multi-view stereo struggles with sparse viewpoints or low-texture regions, while neural rendering approaches, though capable of producing high-quality results, require per-scene optimization and lack real-time efficiency. Explicit 3D Gaussian Splatting (3DGS) enables efficient rendering, but most feed-forward variants focus on visual quality rather than geometric consistency, limiting accurate surface reconstruction and overall reliability in spatial perception tasks. This paper presents a novel feed-forward 3DGS framework for 360 images, capable of generating geometrically consistent Gaussian primitives while maintaining high rendering quality. A Depth-Normal geometric regularization is introduced to couple rendered depth gradients with normal information, supervising Gaussian rotation, scale, and position to improve point cloud and surface accuracy. Experimental results show that the proposed method maintains high rendering quality while significantly improving geometric consistency, providing an effective solution for 3D reconstruction in spatial perception tasks.

</details>


### [203] [MagicFight: Personalized Martial Arts Combat Video Generation](https://arxiv.org/abs/2601.02107)
*Jiancheng Huang,Mingfu Yan,Songyan Chen,Yi Huang,Shifeng Chen*

Main category: cs.CV

TL;DR: 本文提出了个性化武术对战视频生成的新任务，并开发了MagicFight方法，通过Unity生成定制数据集，解决了双人交互视频生成中的身份混淆、肢体异常和动作不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成技术主要集中于单人场景（如舞蹈），而双人交互（特别是武术对战）领域尚未探索，现有模型难以捕捉对战中的细微动作和复杂交互，导致生成质量低下。

Method: 1. 提出新任务“个性化武术对战视频生成”；2. 使用Unity游戏物理引擎生成定制化数据集，包含多样化的3D角色、武术动作和场景；3. 开发MagicFight方法，改进现有模型和策略以生成高保真双人对战视频。

Result: MagicFight能够生成保持个体身份、动作连贯的高质量双人对战视频，解决了身份混淆、肢体异常和动作不匹配等挑战，为交互式视频内容创作奠定了基础。

Conclusion: 该研究填补了双人交互视频生成的空白，通过定制数据集和专用方法实现了高质量的武术对战视频生成，为未来交互式视频内容创新提供了新方向。

Abstract: Amid the surge in generic text-to-video generation, the field of personalized human video generation has witnessed notable advancements, primarily concentrated on single-person scenarios. However, to our knowledge, the domain of two-person interactions, particularly in the context of martial arts combat, remains uncharted. We identify a significant gap: existing models for single-person dancing generation prove insufficient for capturing the subtleties and complexities of two engaged fighters, resulting in challenges such as identity confusion, anomalous limbs, and action mismatches. To address this, we introduce a pioneering new task, Personalized Martial Arts Combat Video Generation. Our approach, MagicFight, is specifically crafted to overcome these hurdles. Given this pioneering task, we face a lack of appropriate datasets. Thus, we generate a bespoke dataset using the game physics engine Unity, meticulously crafting a multitude of 3D characters, martial arts moves, and scenes designed to represent the diversity of combat. MagicFight refines and adapts existing models and strategies to generate high-fidelity two-person combat videos that maintain individual identities and ensure seamless, coherent action sequences, thereby laying the groundwork for future innovations in the realm of interactive video content creation.
  Website: https://MingfuYAN.github.io/MagicFight/
  Dataset: https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta

</details>


### [204] [Beyond Segmentation: An Oil Spill Change Detection Framework Using Synthetic SAR Imagery](https://arxiv.org/abs/2601.02139)
*Chenyang Lai,Shuaiyu Chen,Tianjin Huang,Siyang Song,Guangliang Cheng,Chunbo Luo,Zeyu Fu*

Main category: cs.CV

TL;DR: 本文提出了一种新的双时相油污检测方法OSCD，通过对比溢油前后的SAR图像变化来提高检测准确性，并开发了TAHI框架生成合成溢油前图像以解决数据缺失问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于单幅SAR图像的深度学习分割方法难以区分真实油污与视觉相似的海面特征（如生物油膜或低风区），导致高误报率且在数据稀缺条件下泛化能力有限。

Method: 提出了油污变化检测任务OSCD，并开发了时序感知混合修复框架TAHI，包含高保真混合修复和时序真实性增强两个组件，用于生成合成溢油前图像并构建首个OSCD数据集。

Result: 实验表明，与传统分割方法相比，OSCD显著降低了误报率并提高了检测精度，证明了时序感知方法在实际油污监测中的可靠性和可扩展性。

Conclusion: 时序感知的油污变化检测方法能够更可靠地识别海洋溢油，为实际场景中的大规模油污监测提供了有效的解决方案。

Abstract: Marine oil spills are urgent environmental hazards that demand rapid and reliable detection to minimise ecological and economic damage. While Synthetic Aperture Radar (SAR) imagery has become a key tool for large-scale oil spill monitoring, most existing detection methods rely on deep learning-based segmentation applied to single SAR images. These static approaches struggle to distinguish true oil spills from visually similar oceanic features (e.g., biogenic slicks or low-wind zones), leading to high false positive rates and limited generalizability, especially under data-scarce conditions. To overcome these limitations, we introduce Oil Spill Change Detection (OSCD), a new bi-temporal task that focuses on identifying changes between pre- and post-spill SAR images. As real co-registered pre-spill imagery is not always available, we propose the Temporal-Aware Hybrid Inpainting (TAHI) framework, which generates synthetic pre-spill images from post-spill SAR data. TAHI integrates two key components: High-Fidelity Hybrid Inpainting for oil-free reconstruction, and Temporal Realism Enhancement for radiometric and sea-state consistency. Using TAHI, we construct the first OSCD dataset and benchmark several state-of-the-art change detection models. Results show that OSCD significantly reduces false positives and improves detection accuracy compared to conventional segmentation, demonstrating the value of temporally-aware methods for reliable, scalable oil spill monitoring in real-world scenarios.

</details>


### [205] [Car Drag Coefficient Prediction from 3D Point Clouds Using a Slice-Based Surrogate Model](https://arxiv.org/abs/2601.02112)
*Utkarsh Singh,Absaar Ali,Adarsh Roy*

Main category: cs.CV

TL;DR: 提出一种基于序列切片处理的轻量级代理模型，用于预测车辆气动阻力系数，通过将3D点云分解为2D截面序列并采用PointNet2D和双向LSTM处理，实现快速准确的空气动力学评估。


<details>
  <summary>Details</summary>
Motivation: 传统CFD和风洞测试资源消耗大，阻碍早期设计快速迭代；现有机器学习代理模型存在计算复杂、可解释性差或对详细几何输入精度不足的问题，需开发高效替代方案。

Method: 将车辆3D点云沿流向轴分解为有序2D截面序列，每个切片通过轻量级PointNet2D编码，序列嵌入由双向LSTM处理以捕捉纵向几何演化，在DrivAerNet++数据集上训练评估。

Result: 模型在Cd预测中达到高决定系数（R² > 0.9528）和低平均绝对误差（MAE ≈ 6.046×10⁻³），在消费级GPU上推理时间约0.025秒/样本。

Conclusion: 该方法提供快速、准确且可解释的空气动力学反馈，支持更敏捷的汽车设计探索，平衡了计算效率与预测精度。

Abstract: The automotive industry's pursuit of enhanced fuel economy and performance necessitates efficient aerodynamic design. However, traditional evaluation methods such as computational fluid dynamics (CFD) and wind tunnel testing are resource intensive, hindering rapid iteration in the early design stages. Machine learning-based surrogate models offer a promising alternative, yet many existing approaches suffer from high computational complexity, limited interpretability, or insufficient accuracy for detailed geometric inputs. This paper introduces a novel lightweight surrogate model for the prediction of the aerodynamic drag coefficient (Cd) based on a sequential slice-wise processing of the geometry of the 3D vehicle. Inspired by medical imaging, 3D point clouds of vehicles are decomposed into an ordered sequence of 2D cross-sectional slices along the stream-wise axis. Each slice is encoded by a lightweight PointNet2D module, and the sequence of slice embeddings is processed by a bidirectional LSTM to capture longitudinal geometric evolution. The model, trained and evaluated on the DrivAerNet++ dataset, achieves a high coefficient of determination (R^2 > 0.9528) and a low mean absolute error (MAE approx 6.046 x 10^{-3}) in Cd prediction. With an inference time of approximately 0.025 seconds per sample on a consumer-grade GPU, our approach provides fast, accurate, and interpretable aerodynamic feedback, facilitating more agile and informed automotive design exploration.

</details>


### [206] [Efficient Unrolled Networks for Large-Scale 3D Inverse Problems](https://arxiv.org/abs/2601.02141)
*Romain Vo,Julián Tachella*

Main category: cs.CV

TL;DR: 提出了一种域分割策略和正规算子近似方法，使大规模成像问题（如3D成像）能够将全局前向算子整合到端到端重建模型中，在单GPU上实现最先进的3D重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在3D等大规模成像问题中难以将全局前向算子整合到网络架构中，因为全局算子需要大量内存，阻碍了典型的分块策略。

Method: 采用域分割策略和正规算子近似，使端到端重建模型能够处理任意大规模问题的前向算子，仅需单GPU即可完成训练和推理。

Result: 在3D X射线锥束断层扫描和3D多线圈加速MRI上实现了最先进的性能，同时仅需单GPU。

Conclusion: 所提方法成功解决了大规模成像问题中整合全局前向算子的内存限制问题，为3D成像提供了高效且高性能的端到端重建解决方案。

Abstract: Deep learning-based methods have revolutionized the field of imaging inverse problems, yielding state-of-the-art performance across various imaging domains. The best performing networks incorporate the imaging operator within the network architecture, typically in the form of deep unrolling. However, in large-scale problems, such as 3D imaging, most existing methods fail to incorporate the operator in the architecture due to the prohibitive amount of memory required by global forward operators, which hinder typical patching strategies. In this work, we present a domain partitioning strategy and normal operator approximations that enable the training of end-to-end reconstruction models incorporating forward operators of arbitrarily large problems into their architecture. The proposed method achieves state-of-the-art performance on 3D X-ray cone-beam tomography and 3D multi-coil accelerated MRI, while requiring only a single GPU for both training and inference.

</details>


### [207] [Why Commodity WiFi Sensors Fail at Multi-Person Gait Identification: A Systematic Analysis Using ESP32](https://arxiv.org/abs/2601.02177)
*Oliver Custance,Saad Khan,Simon Parkinson*

Main category: cs.CV

TL;DR: 本文系统评估了六种信号分离方法在商用ESP32 WiFi传感器上的多人步态识别性能，发现所有方法准确率均较低（45-56%），表明现有硬件无法提供足够信号质量实现可靠的多人分离。


<details>
  <summary>Details</summary>
Motivation: 现有研究在单人步态识别中取得高准确率，但多人识别领域尚未充分探索，且现有方案依赖复杂昂贵的定制硬件。核心问题在于：多人识别性能差是算法限制还是硬件固有约束？

Method: 使用商用ESP32 WiFi传感器，在1-10人场景下系统评估六种信号分离方法（FastICA、SOBI、PCA、NMF、小波变换、张量分解），并引入新的诊断指标（主体内变异性、主体间可区分性、性能退化率）。

Result: 所有方法准确率相似且较低（45-56%，标准差3.74%），统计差异不显著（p>0.05）。最佳方法NMF仅达56%准确率。分析显示高主体内变异性、低主体间可区分性，且随人数增加性能急剧下降。

Conclusion: 商用ESP32传感器无法提供足够的信号质量以实现可靠的多人信号分离，表明当前多人识别性能限制主要源于硬件约束而非算法局限。

Abstract: WiFi Channel State Information (CSI) has shown promise for single-person gait identification, with numerous studies reporting high accuracy. However, multi-person identification remains largely unexplored, with the limited existing work relying on complex, expensive setups requiring modified firmware. A critical question remains unanswered: is poor multi-person performance an algorithmic limitation or a fundamental hardware constraint? We systematically evaluate six diverse signal separation methods (FastICA, SOBI, PCA, NMF, Wavelet, Tensor Decomposition) across seven scenarios with 1-10 people using commodity ESP32 WiFi sensors--a simple, low-cost, off-the-shelf solution. Through novel diagnostic metrics (intra-subject variability, inter-subject distinguishability, performance degradation rate), we reveal that all methods achieve similarly low accuracy (45-56\%, $σ$=3.74\%) with statistically insignificant differences (p $>$ 0.05). Even the best-performing method, NMF, achieves only 56\% accuracy. Our analysis reveals high intra-subject variability, low inter-subject distinguishability, and severe performance degradation as person count increases, indicating that commodity ESP32 sensors cannot provide sufficient signal quality for reliable multi-person separation.

</details>


### [208] [QuIC: A Quantum-Inspired Interaction Classifier for Revitalizing Shallow CNNs in Fine-Grained Recognition](https://arxiv.org/abs/2601.02189)
*Cheng Ying Wu,Yen Jui Chang*

Main category: cs.CV

TL;DR: 提出量子启发的交互分类器（QuIC），通过模拟量子态交互捕捉二阶特征协方差，显著提升浅层网络在细粒度视觉分类任务上的性能，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 细粒度视觉分类在资源受限的边缘设备部署面临挑战：深度模型计算成本高，浅层网络因全局平均池化仅捕获一阶统计量而无法区分视觉相似的子类别，现有双线性CNN方法存在特征维度爆炸和训练不稳定问题。

Method: 设计量子启发的交互分类器（QuIC），将特征通道建模为相互作用的量子态，通过可学习的观测算子捕捉二阶特征协方差；作为轻量级即插即用模块，支持稳定的单阶段端到端训练，避免特征维度爆炸。

Result: QuIC显著提升浅层主干网络性能：VGG16的Top-1准确率提升近20%；在ResNet18上优于最先进的注意力机制（SE-Block）；t-SNE可视化证实QuIC能明确关注细粒度判别特征并增强类内紧凑聚类。

Conclusion: QuIC通过量子力学启发的特征交互建模，有效解决了浅层网络在细粒度分类中的局限性，在提升准确率的同时保持计算效率，为边缘设备部署提供了可行方案。

Abstract: Deploying deep learning models for Fine-Grained Visual Classification (FGVC) on resource-constrained edge devices remains a significant challenge. While deep architectures achieve high accuracy on benchmarks like CUB-200-2011, their computational cost is often prohibitive. Conversely, shallow networks (e.g., AlexNet, VGG) offer efficiency but fail to distinguish visually similar sub-categories. This is because standard Global Average Pooling (GAP) heads capture only first-order statistics, missing the subtle high-order feature interactions required for FGVC. While Bilinear CNNs address this, they suffer from high feature dimensionality and instability during training. To bridge this gap, we propose the Quantum-inspired Interaction Classifier (QuIC). Drawing inspiration from quantum mechanics, QuIC models feature channels as interacting quantum states and captures second-order feature covariance via a learnable observable operator. Designed as a lightweight, plug-and-play module, QuIC supports stable, single-stage end-to-end training without exploding feature dimensions. Experimental results demonstrate that QuIC significantly revitalizes shallow backbones: it boosts the Top-1 accuracy of VGG16 by nearly 20% and outperforms state-of-the-art attention mechanisms (SE-Block) on ResNet18. Qualitative analysis, including t-SNE visualization, further confirms that QuIC resolves ambiguous cases by explicitly attending to fine-grained discriminative features and enforcing compact intra-class clustering.

</details>


### [209] [Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models](https://arxiv.org/abs/2601.02198)
*Alexander Möllers,Julius Hense,Florian Schulz,Timo Milbich,Maximilian Alber,Lukas Ruff*

Main category: cs.CV

TL;DR: 本文研究了病理学基础模型在不同放大倍数下的性能差异，提出了连续放大倍数采样方法以解决传统离散采样在中间放大倍数上的性能下降问题，并开发了优化采样分布来提升跨放大倍度的表示质量。


<details>
  <summary>Details</summary>
Motivation: 病理学家在诊断时需要同时观察低倍镜下的组织结构和高倍镜下的细微形态，但现有病理学基础模型在不同放大倍数下的性能差异及训练时的放大倍数采样策略影响尚不明确。

Method: 将放大倍数采样建模为多源域适应问题，提出理论框架分析采样策略的权衡；引入连续放大倍数采样方法；推导优化跨放大倍数表示质量的采样分布；使用TCGA-MS和BRACS-MS两个新基准进行评估。

Result: 传统离散均匀采样（0.25、0.5、1.0、2.0 mpp）在中间放大倍数上性能下降；连续采样能消除放大倍数覆盖间隙，在中间放大倍数上比离散采样提升高达4个百分点的平衡分类准确率；优化分布可进一步提升性能；放大倍数是不同模型性能差异的主要驱动因素。

Conclusion: 连续放大倍数采样能显著改善模型在中间放大倍数上的性能，优化采样分布可进一步提升跨放大倍度的表示质量，为开发能在不同放大倍数下可靠工作的未来病理学基础模型奠定了基础。

Abstract: In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.

</details>


### [210] [Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules](https://arxiv.org/abs/2601.02203)
*Oliver Custance,Saad Khan,Simon Parkinson,Quan Z. Sheng*

Main category: cs.CV

TL;DR: 提出一种基于WiFi信道状态信息的两阶段无设备人群计数框架，通过自监督对比学习和轻量级适配器模块解决领域偏移问题，在少量样本场景下实现高精度计数。


<details>
  <summary>Details</summary>
Motivation: 现有基于WiFi CSI的无设备人群计数技术面临严重的领域偏移问题，即在一个环境中训练的模型难以泛化到其他环境，阻碍了实际物联网部署。

Method: 1) 提出CSI-ResNet-A架构，通过自监督对比学习预训练获取领域不变特征表示；2) 使用轻量级适配器模块进行高效微调；3) 采用状态计数机处理事件序列生成稳定的人数估计。

Result: 1) 在WiFlow数据集上，10样本学习场景中平均绝对误差仅0.44，优于监督基线；2) 提出的泛化指数接近完美；3) 在公开WiAR基准测试中达到98.8%准确率；4) 适配器微调性能接近全参数微调（98.84% vs 99.67%），但仅需训练2.8%的参数。

Conclusion: 该框架为现实世界物联网部署提供了实用且可扩展的鲁棒感知解决方案，通过领域不变表示学习和高效微调机制显著提升了跨环境泛化能力。

Abstract: Device-free crowd-counting using WiFi Channel State Information (CSI) is a key enabling technology for a new generation of privacy-preserving Internet of Things (IoT) applications. However, practical deployment is severely hampered by the domain shift problem, where models trained in one environment fail to generalise to another. To overcome this, we propose a novel two-stage framework centred on a CSI-ResNet-A architecture. This model is pre-trained via self-supervised contrastive learning to learn domain-invariant representations and leverages lightweight Adapter modules for highly efficient fine-tuning. The resulting event sequence is then processed by a stateful counting machine to produce a final, stable occupancy estimate. We validate our framework extensively. On our WiFlow dataset, our unsupervised approach excels in a 10-shot learning scenario, achieving a final Mean Absolute Error (MAE) of just 0.44--a task where supervised baselines fail. To formally quantify robustness, we introduce the Generalisation Index (GI), on which our model scores near-perfectly, confirming its ability to generalise. Furthermore, our framework sets a new state-of-the-art public WiAR benchmark with 98.8\% accuracy. Our ablation studies reveal the core strength of our design: adapter-based fine-tuning achieves performance within 1\% of a full fine-tune (98.84\% vs. 99.67\%) while training 97.2\% fewer parameters. Our work provides a practical and scalable solution for developing robust sensing systems ready for real-world IoT deployments.

</details>


### [211] [Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion](https://arxiv.org/abs/2601.02211)
*Binglei Li,Mengping Yang,Zhiyu Tan,Junping Zhang,Hao Li*

Main category: cs.CV

TL;DR: 本文系统分析了基于MMDiT的文本到图像生成模型，揭示了不同模块在合成过程中的作用，并提出了无需训练的改进策略，显著提升了文本对齐和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅分析了MMDiT模型中特定组件（如位置编码和注意力层）的作用，缺乏对不同模块及其与文本条件交互如何影响合成过程的全面理解。

Method: 开发了系统化分析流程，通过移除、禁用和增强文本隐藏状态来研究每个模块的功能；基于分析结果提出了无需训练的文本对齐、精确编辑和加速生成策略。

Result: 1）语义信息在早期模块出现，细节在后期模块渲染；2）移除特定模块通常比禁用文本条件影响更小；3）在选择性模块增强文本条件可改善语义属性。在SD3.5上，T2I-Combench++从56.92%提升至63.00%，GenEval从66.42%提升至71.63%。

Conclusion: 研究深化了对MMDiT模型内部机制的理解，提出的方法在文本到图像生成、编辑和加速推理中表现优异，为模型进一步优化提供了新思路。

Abstract: Recent breakthroughs of transformer-based diffusion models, particularly with Multimodal Diffusion Transformers (MMDiT) driven models like FLUX and Qwen Image, have facilitated thrilling experiences in text-to-image generation and editing. To understand the internal mechanism of MMDiT-based models, existing methods tried to analyze the effect of specific components like positional encoding and attention layers. Yet, a comprehensive understanding of how different blocks and their interactions with textual conditions contribute to the synthesis process remains elusive. In this paper, we first develop a systematic pipeline to comprehensively investigate each block's functionality by removing, disabling and enhancing textual hidden-states at corresponding blocks. Our analysis reveals that 1) semantic information appears in earlier blocks and finer details are rendered in later blocks, 2) removing specific blocks is usually less disruptive than disabling text conditions, and 3) enhancing textual conditions in selective blocks improves semantic attributes. Building on these observations, we further propose novel training-free strategies for improved text alignment, precise editing, and acceleration. Extensive experiments demonstrated that our method outperforms various baselines and remains flexible across text-to-image generation, image editing, and inference acceleration. Our method improves T2I-Combench++ from 56.92% to 63.00% and GenEval from 66.42% to 71.63% on SD3.5, without sacrificing synthesis quality. These results advance understanding of MMDiT models and provide valuable insights to unlock new possibilities for further improvements.

</details>


### [212] [VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation](https://arxiv.org/abs/2601.02256)
*Shikun Sun,Liao Qu,Huichao Zhang,Yiheng Liu,Yangyang Song,Xian Li,Xu Wang,Yi Jiang,Daniel K. Du,Xinglong Wu,Jia Jia*

Main category: cs.CV

TL;DR: 提出一种增强GRPO的框架，通过管理VAR模型中的异步策略冲突，改善视觉生成模型的强化学习训练稳定性和对齐效果。


<details>
  <summary>Details</summary>
Motivation: VAR模型在生成过程中存在异构输入结构导致的异步策略冲突，尤其在强化学习场景中会导致训练不稳定和对齐效果差，需要解决这一问题。

Method: 集成三个协同组件：1）稳定中间奖励引导早期生成；2）动态时间步重加权方案进行精确信用分配；3）基于ReFL原理的新型掩码传播算法，实现时空隔离的优化效果。

Result: 相比原始GRPO基线，该方法在样本质量和目标对齐方面取得显著改进，实现了VAR模型的稳健有效优化。

Conclusion: 所提框架能有效解决VAR模型的异步策略冲突问题，提升强化学习训练效果，为视觉生成模型的优化提供了新思路。

Abstract: Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.

</details>


### [213] [Prior-Guided DETR for Ultrasound Nodule Detection](https://arxiv.org/abs/2601.02212)
*Jingjing Wang,Zhuo Xiao,Xinning Yao,Bo Liu,Lijuan Niu,Xiangzhi Bai,Fugen Zhou*

Main category: cs.CV

TL;DR: 提出一种先验引导的DETR框架用于超声结节检测，通过融入几何和结构先验知识，有效应对结节形状不规则、边界模糊、尺度变化大和斑点噪声等挑战，在多个甲状腺和乳腺超声数据集上取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 超声结节检测对甲状腺癌和乳腺癌的早期诊疗至关重要，但现有方法面临结节形状不规则、边界不清晰、尺度变化大以及斑点噪声干扰结构可见性等挑战，需要更有效的检测框架。

Method: 提出先验引导DETR框架：1) 在CNN骨干网络中嵌入空间自适应可变形FFN与先验正则化(SDFPR)，注入几何先验稳定特征提取；2) 设计多尺度空间-频率特征混合器(MSFFM)，提取多尺度结构先验，空间域强调轮廓连续性，频域建模全局形态并抑制噪声；3) 采用密集特征交互(DFI)机制在先验调制特征间传播信息，增强解码器查询优化。

Result: 在两个临床收集的甲状腺超声数据集(Thyroid I和II)以及两个公开基准(TN3K和BUSI)上实验，该方法在检测形态复杂结节方面表现优异，优于18种现有检测方法。

Conclusion: 所提框架通过渐进式融入先验知识，显著提升了超声结节检测的准确性，特别是在处理不规则形状和模糊边界结节时具有优势，为超声辅助诊断提供了有效工具。

Abstract: Accurate detection of ultrasound nodules is essential for the early diagnosis and treatment of thyroid and breast cancers. However, this task remains challenging due to irregular nodule shapes, indistinct boundaries, substantial scale variations, and the presence of speckle noise that degrades structural visibility. To address these challenges, we propose a prior-guided DETR framework specifically designed for ultrasound nodule detection. Instead of relying on purely data-driven feature learning, the proposed framework progressively incorporates different prior knowledge at multiple stages of the network. First, a Spatially-adaptive Deformable FFN with Prior Regularization (SDFPR) is embedded into the CNN backbone to inject geometric priors into deformable sampling, stabilizing feature extraction for irregular and blurred nodules. Second, a Multi-scale Spatial-Frequency Feature Mixer (MSFFM) is designed to extract multi-scale structural priors, where spatial-domain processing emphasizes contour continuity and boundary cues, while frequency-domain modeling captures global morphology and suppresses speckle noise. Furthermore, a Dense Feature Interaction (DFI) mechanism propagates and exploits these prior-modulated features across all encoder layers, enabling the decoder to enhance query refinement under consistent geometric and structural guidance. Experiments conducted on two clinically collected thyroid ultrasound datasets (Thyroid I and Thyroid II) and two public benchmarks (TN3K and BUSI) for thyroid and breast nodules demonstrate that the proposed method achieves superior accuracy compared with 18 detection methods, particularly in detecting morphologically complex nodules.The source code is publicly available at https://github.com/wjj1wjj/Ultrasound-DETR.

</details>


### [214] [FMVP: Masked Flow Matching for Adversarial Video Purification](https://arxiv.org/abs/2601.02228)
*Duoxun Tang,Xueyi Zhang,Chak Hin Wang,Xi Xiao,Dasen Dai,Xinhang Jiang,Wentao Shi,Rui Li,Qing Li*

Main category: cs.CV

TL;DR: 提出FMVP方法，通过掩码策略破坏对抗结构，结合条件流匹配和频率门控损失实现高效视频净化，在多种攻击下达到SOTA性能，并能零样本检测对抗样本。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的视频净化方法采样效率低、轨迹弯曲，而直接回归方法难以恢复细微扰动下的真实内容，需要物理破坏对抗结构。

Method: 1. 掩码策略破坏全局对抗结构；2. 条件流匹配（CFM）配合修复目标重建干净视频动态；3. 频率门控损失（FGL）分离语义内容与对抗噪声；4. 攻击感知和通用训练范式分别处理已知/未知威胁。

Result: 在UCF-101和HMDB-51上，FMVP对PGD攻击鲁棒准确率超87%，对CW攻击超89%，优于DiffPure、DP等方法；对自适应攻击DiffHammer表现优异；零样本检测准确率：PGD达98%，CW达79%。

Conclusion: FMVP通过物理破坏对抗结构与频率感知重建，实现了高效鲁棒的视频净化，兼具防御与检测能力，为对抗防御提供了新思路。

Abstract: Video recognition models remain vulnerable to adversarial attacks, while existing diffusion-based purification methods suffer from inefficient sampling and curved trajectories. Directly regressing clean videos from adversarial inputs often fails to recover faithful content due to the subtle nature of perturbations; this necessitates physically shattering the adversarial structure. Therefore, we propose Flow Matching for Adversarial Video Purification FMVP. FMVP physically shatters global adversarial structures via a masking strategy and reconstructs clean video dynamics using Conditional Flow Matching (CFM) with an inpainting objective. To further decouple semantic content from adversarial noise, we design a Frequency-Gated Loss (FGL) that explicitly suppresses high-frequency adversarial residuals while preserving low-frequency fidelity. We design Attack-Aware and Generalist training paradigms to handle known and unknown threats, respectively. Extensive experiments on UCF-101 and HMDB-51 demonstrate that FMVP outperforms state-of-the-art methods (DiffPure, Defense Patterns (DP), Temporal Shuffling (TS) and FlowPure), achieving robust accuracy exceeding 87% against PGD and 89% against CW attacks. Furthermore, FMVP demonstrates superior robustness against adaptive attacks (DiffHammer) and functions as a zero-shot adversarial detector, attaining detection accuracies of 98% for PGD and 79% for highly imperceptible CW attacks.

</details>


### [215] [DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies](https://arxiv.org/abs/2601.02267)
*Renke Wang,Zhenyu Zhang,Ying Tai,Jian Yang*

Main category: cs.CV

TL;DR: 提出DiffProxy框架，利用扩散模型生成多视角一致的人体代理，解决合成数据与真实数据间的域差距问题，在多个真实数据集上实现零样本泛化SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 真实数据标注不完美导致训练偏差，合成数据虽有精确标注但存在域差距，需要一种能结合两者优势的方法来提升人体网格恢复的泛化能力。

Method: 1. 多条件机制生成多视角一致、像素对齐的人体代理；2. 手部细化模块通过视觉提示增强局部细节；3. 不确定性感知的测试时缩放方法提升优化鲁棒性。

Result: 仅使用合成数据训练，在五个真实基准测试中达到最先进性能，在遮挡和局部视角等挑战性场景下表现出强大的零样本泛化能力。

Conclusion: DiffProxy通过扩散生成先验有效桥接了合成训练与真实泛化，证明了生成式方法在人体网格恢复任务中的潜力。

Abstract: Human mesh recovery from multi-view images faces a fundamental challenge: real-world datasets contain imperfect ground-truth annotations that bias the models' training, while synthetic data with precise supervision suffers from domain gap. In this paper, we propose DiffProxy, a novel framework that generates multi-view consistent human proxies for mesh recovery. Central to DiffProxy is leveraging the diffusion-based generative priors to bridge the synthetic training and real-world generalization. Its key innovations include: (1) a multi-conditional mechanism for generating multi-view consistent, pixel-aligned human proxies; (2) a hand refinement module that incorporates flexible visual prompts to enhance local details; and (3) an uncertainty-aware test-time scaling method that increases robustness to challenging cases during optimization. These designs ensure that the mesh recovery process effectively benefits from the precise synthetic ground truth and generative advantages of the diffusion-based pipeline. Trained entirely on synthetic data, DiffProxy achieves state-of-the-art performance across five real-world benchmarks, demonstrating strong zero-shot generalization particularly on challenging scenarios with occlusions and partial views. Project page: https://wrk226.github.io/DiffProxy.html

</details>


### [216] [SLGNet: Synergizing Structural Priors and Language-Guided Modulation for Multimodal Object Detection](https://arxiv.org/abs/2601.02249)
*Xiantai Xiang,Guangyao Zhou,Zixiao Wen,Wenshuai Li,Ben Niu,Feng Wang,Lijia Huang,Qiantong Wang,Yuhan Liu,Zongxu Pan,Yuxin Hu*

Main category: cs.CV

TL;DR: 提出SLGNet框架，通过结构感知适配器和语言引导调制模块，在冻结的ViT基础模型上实现高效多模态目标检测，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于适配器的方法在RGB-IR多模态检测中过度追求效率，牺牲了跨模态结构一致性，且在动态场景下缺乏环境感知能力，导致在复杂环境（如高对比度、夜间）中性能下降。

Method: 1. 设计结构感知适配器，从RGB和红外图像提取层次化结构表征并动态注入ViT；2. 提出语言引导调制模块，利用VLM生成的结构化描述动态校准视觉特征；3. 基于冻结的ViT基础模型实现参数高效微调。

Result: 在LLVIP、FLIR、KAIST和DroneVehicle数据集上取得SOTA性能，其中LLVIP上mAP达66.1，训练参数比全微调减少约87%。

Conclusion: SLGNet通过融合层次结构先验和语言引导调制，实现了鲁棒且高效的多模态感知，为全天候场景下的目标检测提供了有效解决方案。

Abstract: Multimodal object detection leveraging RGB and Infrared (IR) images is pivotal for robust perception in all-weather scenarios. While recent adapter-based approaches efficiently transfer RGB-pretrained foundation models to this task, they often prioritize model efficiency at the expense of cross-modal structural consistency. Consequently, critical structural cues are frequently lost when significant domain gaps arise, such as in high-contrast or nighttime environments. Moreover, conventional static multimodal fusion mechanisms typically lack environmental awareness, resulting in suboptimal adaptation and constrained detection performance under complex, dynamic scene variations. To address these limitations, we propose SLGNet, a parameter-efficient framework that synergizes hierarchical structural priors and language-guided modulation within a frozen Vision Transformer (ViT)-based foundation model. Specifically, we design a Structure-Aware Adapter to extract hierarchical structural representations from both modalities and dynamically inject them into the ViT to compensate for structural degradation inherent in ViT-based backbones. Furthermore, we propose a Language-Guided Modulation module that exploits VLM-driven structured captions to dynamically recalibrate visual features, thereby endowing the model with robust environmental awareness. Extensive experiments on the LLVIP, FLIR, KAIST, and DroneVehicle datasets demonstrate that SLGNet establishes new state-of-the-art performance. Notably, on the LLVIP benchmark, our method achieves an mAP of 66.1, while reducing trainable parameters by approximately 87% compared to traditional full fine-tuning. This confirms SLGNet as a robust and efficient solution for multimodal perception.

</details>


### [217] [Rank-based Geographical Regularization: Revisiting Contrastive Self-Supervised Learning for Multispectral Remote Sensing Imagery](https://arxiv.org/abs/2601.02289)
*Tom Burgert,Leonard Hackel,Paolo Rota,Begüm Demir*

Main category: cs.CV

TL;DR: 本文提出GeoRank，一种用于多光谱遥感图像对比自监督学习的新型正则化方法，通过优化球面距离将地理关系嵌入特征空间，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在计算机视觉中广泛应用，但应用于多光谱遥感图像时面临地理和时间变异性的独特挑战，需要专门的方法来利用地理元数据提升特征学习效果。

Method: 提出GeoRank正则化方法，直接优化球面距离以嵌入地理关系；系统研究对比自监督学习在多光谱遥感图像中的关键适应策略，包括数据增强效果、数据集规模和图像尺寸的影响，以及时间视图的任务依赖性。

Result: GeoRank在整合地理元数据的方法中表现最优或相当，并能持续改进多种对比自监督学习算法（如BYOL、DINO）；通过实验验证了数据增强、数据集规模等因素对性能的具体影响。

Conclusion: GeoRank为多光谱遥感图像的自监督学习提供了有效的正则化框架，通过显式建模地理关系提升了特征表示质量，同时系统化的适应策略研究为该领域的实践提供了重要指导。

Abstract: Self-supervised learning (SSL) has become a powerful paradigm for learning from large, unlabeled datasets, particularly in computer vision (CV). However, applying SSL to multispectral remote sensing (RS) images presents unique challenges and opportunities due to the geographical and temporal variability of the data. In this paper, we introduce GeoRank, a novel regularization method for contrastive SSL that improves upon prior techniques by directly optimizing spherical distances to embed geographical relationships into the learned feature space. GeoRank outperforms or matches prior methods that integrate geographical metadata and consistently improves diverse contrastive SSL algorithms (e.g., BYOL, DINO). Beyond this, we present a systematic investigation of key adaptations of contrastive SSL for multispectral RS images, including the effectiveness of data augmentations, the impact of dataset cardinality and image size on performance, and the task dependency of temporal views. Code is available at https://github.com/tomburgert/georank.

</details>


### [218] [InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams](https://arxiv.org/abs/2601.02281)
*Shuai Yuan,Yantai Yang,Xiaotian Yang,Xupeng Zhang,Zhonghao Zhao,Lingming Zhang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: 提出了InfiniteVGGT，一种支持无限长序列的视觉几何Transformer，通过滚动记忆机制解决了现有流式方法在长期稳定性上的不足，并发布了Long3D基准测试用于评估长期3D几何理解。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉几何理解方法在可扩展性和长期稳定性之间存在矛盾：离线模型无法实时处理，而流式架构要么不支持无限长输入，要么在长序列中产生灾难性漂移。

Method: 设计了因果视觉几何Transformer，采用有界但自适应的KV缓存实现滚动记忆机制，并提出无需训练的注意力无关剪枝策略，可兼容FlashAttention高效计算。

Result: InfiniteVGGT在无限长流式处理中表现出色，在长期稳定性上优于现有流式方法，同时发布了包含约10,000帧的Long3D基准测试用于严格评估。

Conclusion: 该方法首次实现了无限长序列的稳定3D几何理解，通过滚动记忆机制解决了长期存在的可扩展性与稳定性矛盾，为未来长期3D几何理解研究提供了新的解决方案和评估平台。

Abstract: The grand vision of enabling persistent, large-scale 3D visual geometry understanding is shackled by the irreconcilable demands of scalability and long-term stability. While offline models like VGGT achieve inspiring geometry capability, their batch-based nature renders them irrelevant for live systems. Streaming architectures, though the intended solution for live operation, have proven inadequate. Existing methods either fail to support truly infinite-horizon inputs or suffer from catastrophic drift over long sequences. We shatter this long-standing dilemma with InfiniteVGGT, a causal visual geometry transformer that operationalizes the concept of a rolling memory through a bounded yet adaptive and perpetually expressive KV cache. Capitalizing on this, we devise a training-free, attention-agnostic pruning strategy that intelligently discards obsolete information, effectively ``rolling'' the memory forward with each new frame. Fully compatible with FlashAttention, InfiniteVGGT finally alleviates the compromise, enabling infinite-horizon streaming while outperforming existing streaming methods in long-term stability. The ultimate test for such a system is its performance over a truly infinite horizon, a capability that has been impossible to rigorously validate due to the lack of extremely long-term, continuous benchmarks. To address this critical gap, we introduce the Long3D benchmark, which, for the first time, enables a rigorous evaluation of continuous 3D geometry estimation on sequences about 10,000 frames. This provides the definitive evaluation platform for future research in long-term 3D geometry understanding. Code is available at: https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT

</details>


### [219] [SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting](https://arxiv.org/abs/2601.02299)
*Sara Inácio,Hugo Proença,João C. Neves*

Main category: cs.CV

TL;DR: 本文介绍了SortWaste数据集和ClutterScore指标，用于评估垃圾分拣场景中的物体检测模型性能，并指出高杂乱场景下现有模型表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 人口增长导致垃圾产量增加，人工分拣效率低且存在健康风险，而现有自动化分拣系统因缺乏真实世界数据集和应对视觉复杂性的能力不足而发展受限。

Method: 1) 从物料回收设施收集并密集标注的SortWaste物体检测数据集；2) 提出ClutterScore指标，通过物体数量、类别与尺寸熵、空间重叠等代理变量量化场景视觉复杂度；3) 对现有先进物体检测模型进行基准测试。

Result: 在仅塑料检测任务中达到59.7% mAP，但在高杂乱场景下性能显著下降，表明现有模型对复杂垃圾流的处理能力有限。

Conclusion: 真实世界垃圾分拣数据集和标准化评估指标对推动自动化分拣技术发展至关重要，当前模型在高杂乱场景中的不足凸显了需要更具挑战性的数据集和更鲁棒的检测方法。

Abstract: The increasing production of waste, driven by population growth, has created challenges in managing and recycling materials effectively. Manual waste sorting is a common practice; however, it remains inefficient for handling large-scale waste streams and presents health risks for workers. On the other hand, existing automated sorting approaches still struggle with the high variability, clutter, and visual complexity of real-world waste streams. The lack of real-world datasets for waste sorting is a major reason automated systems for this problem are underdeveloped. Accordingly, we introduce SortWaste, a densely annotated object detection dataset collected from a Material Recovery Facility. Additionally, we contribute to standardizing waste detection in sorting lines by proposing ClutterScore, an objective metric that gauges the scene's hardness level using a set of proxies that affect visual complexity (e.g., object count, class and size entropy, and spatial overlap). In addition to these contributions, we provide an extensive benchmark of state-of-the-art object detection models, detailing their results with respect to the hardness level assessed by the proposed metric. Despite achieving promising results (mAP of 59.7% in the plastic-only detection task), performance significantly decreases in highly cluttered scenes. This highlights the need for novel and more challenging datasets on the topic.

</details>


### [220] [360DVO: Deep Visual Odometry for Monocular 360-Degree Camera](https://arxiv.org/abs/2601.02309)
*Xiaopeng Guo,Yinzhe Xu,Huajian Huang,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: 提出首个基于深度学习的单目全景视觉里程计框架360DVO，通过失真感知球形特征提取器和全景可微分光束法平差模块，在真实和合成数据集上显著提升鲁棒性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有全景视觉里程计方法依赖手工特征或光度目标，在剧烈运动和光照变化等挑战性场景中缺乏鲁棒性，需要更强大的学习型解决方案。

Method: 1. 失真感知球形特征提取器（DAS-Feat）自适应学习抗失真特征；2. 利用稀疏特征块建立约束；3. 在全景可微分光束法平差（ODBA）模块中进行位姿估计；4. 构建真实世界OVO基准数据集。

Result: 在真实基准和合成数据集（TartanAir V2、360VO）上超越现有最佳方法（包括360VO和OpenVSLAM），鲁棒性提升50%，精度提高37.5%。

Conclusion: 360DVO通过深度学习框架有效解决了全景视觉里程计在挑战性场景中的鲁棒性问题，为相关领域提供了新的解决方案和评估基准。

Abstract: Monocular omnidirectional visual odometry (OVO) systems leverage 360-degree cameras to overcome field-of-view limitations of perspective VO systems. However, existing methods, reliant on handcrafted features or photometric objectives, often lack robustness in challenging scenarios, such as aggressive motion and varying illumination. To address this, we present 360DVO, the first deep learning-based OVO framework. Our approach introduces a distortion-aware spherical feature extractor (DAS-Feat) that adaptively learns distortion-resistant features from 360-degree images. These sparse feature patches are then used to establish constraints for effective pose estimation within a novel omnidirectional differentiable bundle adjustment (ODBA) module. To facilitate evaluation in realistic settings, we also contribute a new real-world OVO benchmark. Extensive experiments on this benchmark and public synthetic datasets (TartanAir V2 and 360VO) demonstrate that 360DVO surpasses state-of-the-art baselines (including 360VO and OpenVSLAM), improving robustness by 50% and accuracy by 37.5%. Homepage: https://chris1004336379.github.io/360DVO-homepage

</details>


### [221] [Prithvi-Complimentary Adaptive Fusion Encoder (CAFE): unlocking full-potential for flood inundation mapping](https://arxiv.org/abs/2601.02315)
*Saurabh Kaushik,Lalit Maurya,Beth Tellman*

Main category: cs.CV

TL;DR: 提出Prithvi-CAFE模型，通过融合地理基础模型与CNN残差分支，在洪水制图任务中显著提升性能，优于现有方法和基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有地理基础模型在洪水制图等下游任务中难以捕捉关键局部细节，导致性能受限，无法超越基线U-Net模型。

Method: 结合Prithvi地理基础模型预训练编码器与并行CNN残差分支（使用卷积注意力模块增强），通过适配器实现快速微调，并进行多尺度、多层次特征融合。

Result: 在Sen1Flood11和FloodPlanet数据集上取得最优结果：Sen1Flood11测试集IoU达83.41，优于原Prithvi（82.50）及其他模型；在保留测试点上IoU达81.37，显著高于U-Net（70.57）和原Prithvi（72.42）。FloodPlanet数据集上IoU为64.70，也优于所有对比模型。

Conclusion: Prithvi-CAFE能有效融合多通道多模态数据，在局部细节关键的分割任务中具有强大潜力，模型代码已开源。

Abstract: Geo-Foundation Models (GFMs), have proven effective in diverse downstream applications, including semantic segmentation, classification, and regression tasks. However, in case of flood mapping using Sen1Flood11 dataset as a downstream task, GFMs struggles to outperform the baseline U-Net, highlighting model's limitation in capturing critical local nuances. To address this, we present the Prithvi-Complementary Adaptive Fusion Encoder (CAFE), which integrate Prithvi GFM pretrained encoder with a parallel CNN residual branch enhanced by Convolutional Attention Modules (CAM). Prithvi-CAFE enables fast and efficient fine-tuning through adapters in Prithvi and performs multi-scale, multi-level fusion with CNN features, capturing critical local details while preserving long-range dependencies. We achieve state-of-the-art results on two comprehensive flood mapping datasets: Sen1Flood11 and FloodPlanet. On Sen1Flood11 test data, Prithvi-CAFE (IoU 83.41) outperforms the original Prithvi (IoU 82.50) and other major GFMs (TerraMind 82.90, DOFA 81.54, spectralGPT: 81.02). The improvement is even more pronounced on the hold-out test site, where Prithvi-CAFE achieves an IoU of 81.37 compared to the baseline U-Net (70.57) and original Prithvi (72.42). On FloodPlanet, Prithvi-CAFE also surpasses the baseline U-Net and other GFMs, achieving an IoU of 64.70 compared to U-Net (60.14), Terramind (62.33), DOFA (59.15) and Prithvi 2.0 (61.91). Our proposed simple yet effective Prithvi-CAFE demonstrates strong potential for improving segmentation tasks where multi-channel and multi-modal data provide complementary information and local details are critical. The code is released on \href{https://github.com/Sk-2103/Prithvi-CAFE}{Prithvi-CAFE Github}

</details>


### [222] [Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318)
*Roja Sahoo,Anoop Namboodiri*

Main category: cs.CV

TL;DR: 提出Fusion2Print框架，通过融合闪光与非闪光接触式指纹图像提升识别性能，实现与接触式指纹的跨域兼容。


<details>
  <summary>Details</summary>
Motivation: 接触式指纹识别存在卫生和便利性问题，而无接触指纹图像常因光照变化、皮下肤色不均和镜面反射导致脊线清晰度下降。闪光与非闪光图像各有优劣，但单一模式均无法兼顾细节与噪声。

Method: 构建配对的闪光-非闪光指纹数据集（FNF Database），通过手动差分分离脊线信号；设计轻量级注意力融合网络整合双模态信息，结合U-Net增强模块生成优化灰度图像；最后使用跨域兼容的深度嵌入模型生成统一嵌入表示。

Result: F2P显著提升脊线清晰度，在验证任务中达到AUC=0.999、EER=1.12%的优异性能，优于Verifinger和DeepPrint等基线方法。

Conclusion: 闪光-非闪光融合策略能有效克服单模态局限，所提框架在保持卫生便利的同时，实现了高精度且与接触式指纹兼容的无接触识别。

Abstract: Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).

</details>


### [223] [BEDS: Bayesian Emergent Dissipative Structures](https://arxiv.org/abs/2601.02329)
*Laurent Caraffa*

Main category: cs.CV

TL;DR: 提出了BEDS理论框架，将非平衡热力学、贝叶斯推断、信息几何和机器学习统一起来，认为学习本质上是通过熵输出将通量转化为结构的过程。


<details>
  <summary>Details</summary>
Motivation: 旨在建立物理、生物和计算系统中学习过程的统一理论，探索热力学过程与贝叶斯更新之间的形式同构，并为可持续人工智能提供理论基础。

Method: 基于普里高津的耗散结构理论，建立了热力学过程与贝叶斯更新的形式同构；推导了基本数学常数作为贝叶斯推断的固定点；提出了哥德尔不完备定理与热力学约束的猜想；设计了基于BEDS原则的对等网络架构进行实践验证。

Result: 证明了可持续学习系统必须遵循耗散模式；推导出基本数学常数(e, π, φ)作为贝叶斯推断的必然涌现；提出的对等网络架构相比现有分布式共识系统实现了六个数量级的能效提升。

Conclusion: 该工作连接了基础物理、数理逻辑和实际系统设计，为学习和计算的本质提供了理论见解，并为可持续人工智能提供了具体实现路径。

Abstract: We present BEDS (Bayesian Emergent Dissipative Structures), a theoretical framework that unifies concepts from non-equilibrium thermodynamics, Bayesian inference, information geometry, and machine learning. The central thesis proposes that learning, across physical, biological, and computational systems, fundamentally constitutes the conversion of flux into structure through entropy export. Building on Prigogine's theory of dissipative structures, we establish a formal isomorphism between thermodynamic processes and Bayesian updating, demonstrating that sustainable learning systems must follow dissipative patterns where crystallized posteriors become priors for subsequent levels of emergence.
  We derive fundamental mathematical constants (e, π, φ) as fixed points of Bayesian inference under minimal axioms, suggesting these constants emerge necessarily from any system capable of representing and updating uncertainty. Furthermore, we propose a conjecture linking Gödel's incompleteness theorems to thermodynamic constraints, hypothesizing that pathologies of formal systems (incompleteness, undecidability) are structurally analogous to dissipation deficits in physical systems.
  As practical validation, we present a peer-to-peer network architecture implementing BEDS principles, achieving six orders of magnitude improvement in energy efficiency compared to existing distributed consensus systems while enabling continuous learning. This work bridges fundamental physics, mathematical logic, and practical system design, offering both theoretical insights into the nature of learning and computation, and a concrete pathway toward sustainable artificial intelligence.

</details>


### [224] [Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding](https://arxiv.org/abs/2601.02339)
*Jingming He,Chongyi Li,Shiqi Wang,Sam Kwong*

Main category: cs.CV

TL;DR: 提出联合增强框架，通过各向异性3D高斯切比雪夫描述符、自适应高斯分配与跨场景知识迁移，提升3D语义高斯建模的语义分割与渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法将语义与渲染分支分离，仅依赖2D监督且忽略3D高斯几何；自适应策略仅依赖渲染梯度，在纹理稀疏区域效果有限。

Method: 1. 引入基于拉普拉斯-贝尔特拉米算子的各向异性3D高斯切比雪夫描述符捕捉细粒度形状细节；2. 结合局部语义与形状信号自适应调整高斯分配与球谐函数；3. 设计跨场景知识迁移模块持续更新学习到的形状模式。

Result: 在多个数据集上实验表明，该方法在保持高渲染帧率的同时，提升了语义分割精度与渲染质量。

Conclusion: 所提框架通过联合优化语义与渲染分支，减少对噪声2D指导的依赖，实现了更高效、鲁棒的3D语义高斯建模。

Abstract: Recent works propose extending 3DGS with semantic feature vectors for simultaneous semantic segmentation and image rendering. However, these methods often treat the semantic and rendering branches separately, relying solely on 2D supervision while ignoring the 3D Gaussian geometry. Moreover, current adaptive strategies adapt the Gaussian set depending solely on rendering gradients, which can be insufficient in subtle or textureless regions. In this work, we propose a joint enhancement framework for 3D semantic Gaussian modeling that synergizes both semantic and rendering branches. Firstly, unlike conventional point cloud shape encoding, we introduce an anisotropic 3D Gaussian Chebyshev descriptor using the Laplace-Beltrami operator to capture fine-grained 3D shape details, thereby distinguishing objects with similar appearances and reducing reliance on potentially noisy 2D guidance. In addition, without relying solely on rendering gradient, we adaptively adjust Gaussian allocation and spherical harmonics with local semantic and shape signals, enhancing rendering efficiency through selective resource allocation. Finally, we employ a cross-scene knowledge transfer module to continuously update learned shape patterns, enabling faster convergence and robust representations without relearning shape information from scratch for each new scene. Experiments on multiple datasets demonstrate improvements in segmentation accuracy and rendering quality while maintaining high rendering frame rates.

</details>


### [225] [Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices](https://arxiv.org/abs/2601.02353)
*Shahnawaz Alam,Mohammed Mudassir Uddin,Mohammed Kaif Pasha*

Main category: cs.CV

TL;DR: 提出DACIS方法和PMP流程，通过神经网络剪枝与少样本学习结合，在保持高精度的同时大幅压缩模型，实现植物病害在边缘设备上的实时检测。


<details>
  <summary>Details</summary>
Motivation: 偏远地区农民缺乏实验室和高性能计算资源，现有深度学习模型计算量大且依赖大量标注数据，难以在低成本边缘设备上部署。

Method: 结合神经网络剪枝与少样本学习，提出DACIS方法识别对病害区分关键的神经网络部分，并设计三阶段PMP（剪枝-元学习-再剪枝）流程。

Result: 在PlantVillage和PlantDoc数据集上，模型大小减少78%，保持92.3%原始准确率，在树莓派4上达到7帧/秒的实时推理速度。

Conclusion: 该方法使轻量级植物病害实时检测成为可能，为小农户提供了实用的田间诊断解决方案。

Abstract: Farmers in remote areas need quick and reliable methods for identifying plant diseases, yet they often lack access to laboratories or high-performance computing resources. Deep learning models can detect diseases from leaf images with high accuracy, but these models are typically too large and computationally expensive to run on low-cost edge devices such as Raspberry Pi. Furthermore, collecting thousands of labeled disease images for training is both expensive and time-consuming. This paper addresses both challenges by combining neural network pruning -- removing unnecessary parts of the model -- with few-shot learning, which enables the model to learn from limited examples. This paper proposes Disease-Aware Channel Importance Scoring (DACIS), a method that identifies which parts of the neural network are most important for distinguishing between different plant diseases, integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\% while maintaining 92.3\% of the original accuracy, with the compressed model running at 7 frames per second on a Raspberry Pi 4, making real-time field diagnosis practical for smallholder farmers.

</details>


### [226] [Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes](https://arxiv.org/abs/2601.02356)
*Jing Tan,Zhaoyang Zhang,Yantao Shen,Jiarui Cai,Shuo Yang,Jiajun Wu,Wei Xia,Zhuowen Tu,Stefano Soatto*

Main category: cs.CV

TL;DR: Talk2Move是一个基于强化学习的扩散框架，通过自然语言指令实现场景中物体的空间变换（平移、旋转、缩放），无需配对监督数据，在空间准确性和场景一致性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的编辑方法难以实现物体级别的几何变换（如平移、旋转、缩放），主要受限于配对监督数据稀缺和像素级优化的局限性。

Method: 采用Group Relative Policy Optimization（GRPO）探索几何动作，通过输入图像和轻量文本变体生成多样rollout；设计空间奖励引导模型对齐几何变换与语言描述；使用离策略步骤评估和主动步骤采样提升学习效率；设计以物体为中心的空间奖励直接评估位移、旋转和缩放行为。

Result: 在精选基准测试中，Talk2Move实现了精确、一致且语义保真的物体变换，在空间准确性和场景一致性方面优于现有文本引导编辑方法。

Conclusion: Talk2Move框架通过强化学习和空间奖励机制，有效解决了文本指令下物体几何变换的挑战，为无需配对数据的空间编辑提供了可行方案。

Abstract: We introduce Talk2Move, a reinforcement learning (RL) based diffusion framework for text-instructed spatial transformation of objects within scenes. Spatially manipulating objects in a scene through natural language poses a challenge for multimodal generation systems. While existing text-based manipulation methods can adjust appearance or style, they struggle to perform object-level geometric transformations-such as translating, rotating, or resizing objects-due to scarce paired supervision and pixel-level optimization limits. Talk2Move employs Group Relative Policy Optimization (GRPO) to explore geometric actions through diverse rollouts generated from input images and lightweight textual variations, removing the need for costly paired data. A spatial reward guided model aligns geometric transformations with linguistic description, while off-policy step evaluation and active step sampling improve learning efficiency by focusing on informative transformation stages. Furthermore, we design object-centric spatial rewards that evaluate displacement, rotation, and scaling behaviors directly, enabling interpretable and coherent transformations. Experiments on curated benchmarks demonstrate that Talk2Move achieves precise, consistent, and semantically faithful object transformations, outperforming existing text-guided editing approaches in both spatial accuracy and scene coherence.

</details>


### [227] [ExposeAnyone: Personalized Audio-to-Expression Diffusion Models Are Robust Zero-Shot Face Forgery Detectors](https://arxiv.org/abs/2601.02359)
*Kaede Shiohara,Toshihiko Yamasaki,Vladislav Golyanik*

Main category: cs.CV

TL;DR: 提出ExposeAnyone，一种基于扩散模型的自监督方法，通过音频生成表情序列，实现人物特定的人脸伪造检测，在多个数据集上超越现有方法，并能检测Sora2生成的视频。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法难以泛化到未知伪造类型，监督方法容易过拟合特定伪造模式，而自监督方法又难以学习到区分性表示。

Method: 使用扩散模型从音频生成表情序列，通过参考集对特定人物进行个性化建模，利用扩散重建误差计算疑似视频与个性化人物之间的身份距离。

Result: 在DF-TIMIT、DFDCP、KoDF和IDForge数据集上平均AUC比之前最优方法提升4.22个百分点；能有效检测Sora2生成的视频；对模糊和压缩等干扰具有强鲁棒性。

Conclusion: ExposeAnyone作为完全自监督的方法，在人物特定的人脸伪造检测中表现出优越的泛化能力和鲁棒性，适用于真实世界场景。

Abstract: Detecting unknown deepfake manipulations remains one of the most challenging problems in face forgery detection. Current state-of-the-art approaches fail to generalize to unseen manipulations, as they primarily rely on supervised training with existing deepfakes or pseudo-fakes, which leads to overfitting to specific forgery patterns. In contrast, self-supervised methods offer greater potential for generalization, but existing work struggles to learn discriminative representations only from self-supervision. In this paper, we propose ExposeAnyone, a fully self-supervised approach based on a diffusion model that generates expression sequences from audio. The key idea is, once the model is personalized to specific subjects using reference sets, it can compute the identity distances between suspected videos and personalized subjects via diffusion reconstruction errors, enabling person-of-interest face forgery detection. Extensive experiments demonstrate that 1) our method outperforms the previous state-of-the-art method by 4.22 percentage points in the average AUC on DF-TIMIT, DFDCP, KoDF, and IDForge datasets, 2) our model is also capable of detecting Sora2-generated videos, where the previous approaches perform poorly, and 3) our method is highly robust to corruptions such as blur and compression, highlighting the applicability in real-world face forgery detection.

</details>


### [228] [VINO: A Unified Visual Generator with Interleaved OmniModal Context](https://arxiv.org/abs/2601.02358)
*Junyi Chen,Tong He,Zhoujie Fu,Pengfei Wan,Kun Gai,Weicai Ye*

Main category: cs.CV

TL;DR: VINO是一个统一的视觉生成器，能够在单一框架内执行图像和视频的生成与编辑任务，通过共享的扩散主干网络处理多模态输入，避免了针对不同任务的独立模型设计。


<details>
  <summary>Details</summary>
Motivation: 当前视觉生成系统通常需要针对图像和视频分别设计独立模型或模块，导致系统复杂且难以统一管理。本研究旨在开发一个能够统一处理图像和视频生成与编辑任务的通用框架，以提高系统的灵活性和可扩展性。

Method: VINO采用视觉语言模型（VLM）与多模态扩散变换器（MMDiT）耦合的设计，将多模态输入编码为交错的条件令牌来指导扩散过程。通过多阶段训练流程，逐步将视频生成基础模型扩展为能够处理图像和视频输入输出的统一多任务生成器。

Result: 在多种生成和编辑基准测试中，VINO展现出强大的视觉质量、准确的指令跟随能力、改进的参考和属性保持效果，以及更可控的多身份编辑性能。

Conclusion: VINO为可扩展的统一视觉生成提供了一条实用路径，并展示了交错上下文计算作为通用视觉创作基础的潜力。

Abstract: We present VINO, a unified visual generator that performs image and video generation and editing within a single framework. Instead of relying on task-specific models or independent modules for each modality, VINO uses a shared diffusion backbone that conditions on text, images and videos, enabling a broad range of visual creation and editing tasks under one model. Specifically, VINO couples a vision-language model (VLM) with a Multimodal Diffusion Transformer (MMDiT), where multimodal inputs are encoded as interleaved conditioning tokens, and then used to guide the diffusion process. This design supports multi-reference grounding, long-form instruction following, and coherent identity preservation across static and dynamic content, while avoiding modality-specific architectural components. To train such a unified system, we introduce a multi-stage training pipeline that progressively expands a video generation base model into a unified, multi-task generator capable of both image and video input and output. Across diverse generation and editing benchmarks, VINO demonstrates strong visual quality, faithful instruction following, improved reference and attribute preservation, and more controllable multi-identity edits. Our results highlight a practical path toward scalable unified visual generation, and the promise of interleaved, in-context computation as a foundation for general-purpose visual creation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [229] [The Qualitative Laboratory: Theory Prototyping and Hypothesis Generation with Large Language Models](https://arxiv.org/abs/2601.00797)
*Hugues Draelants*

Main category: cs.CL

TL;DR: 提出使用大语言模型进行社会学角色模拟作为'定性实验室'的新方法，用于生成不同社会群体对新信息的解释假设，并以气候政策接收为例展示了该方法产生反直觉假设的能力。


<details>
  <summary>Details</summary>
Motivation: 社会科学需要生成关于不同社会群体如何解读新信息的丰富定性假设，现有方法（如小插图调查缺乏话语深度，基于规则的ABM存在形式化瓶颈）存在局限。

Method: 提出社会学角色模拟方法：使用LLM创建基于社会学理论的角色（如气候接收理论），让这些角色对政策信息作出反应，生成自然主义话语，作为'模拟后验证'工作流程的一部分。

Result: 模拟产生了细致且反直觉的假设（如保守派角色拒绝国家安全框架），挑战了现有理论假设，展示了该方法生成深度文本化假设的潜力。

Conclusion: 该方法作为'模拟后验证'工作流程的工具，在生成用于后续实证检验的深度文本化假设方面优于传统方法，代表了社会科学研究的新方向。

Abstract: A central challenge in social science is to generate rich qualitative hypotheses about how diverse social groups might interpret new information. This article introduces and illustrates a novel methodological approach for this purpose: sociological persona simulation using Large Language Models (LLMs), which we frame as a "qualitative laboratory". We argue that for this specific task, persona simulation offers a distinct advantage over established methods. By generating naturalistic discourse, it overcomes the lack of discursive depth common in vignette surveys, and by operationalizing complex worldviews through natural language, it bypasses the formalization bottleneck of rule-based agent-based models (ABMs). To demonstrate this potential, we present a protocol where personas derived from a sociological theory of climate reception react to policy messages. The simulation produced nuanced and counter-intuitive hypotheses - such as a conservative persona's rejection of a national security frame - that challenge theoretical assumptions. We conclude that this method, used as part of a "simulation then validation" workflow, represents a superior tool for generating deeply textured hypotheses for subsequent empirical testing.

</details>


### [230] [Rate-Distortion Analysis of Compressed Query Delegation with Low-Rank Riemannian Updates](https://arxiv.org/abs/2601.00938)
*Faruk Alpay,Bugra Kilictas*

Main category: cs.CL

TL;DR: 提出压缩查询委托（CQD）方法，通过低秩张量查询压缩推理状态，委托外部oracle处理，并在固定秩流形上更新状态，解决有限上下文代理的工作记忆限制问题。


<details>
  <summary>Details</summary>
Motivation: 有限上下文代理在中间推理超过有效工作记忆预算时会失败，需要一种方法在保持推理能力的同时压缩信息。

Method: 1. 将高维潜在推理状态压缩为低秩张量查询；2. 将最小查询委托给外部oracle；3. 通过固定秩流形上的黎曼优化更新潜在状态；4. 建立数学框架：CQD是具有查询预算功能的约束随机规划，oracle建模为噪声算子。

Result: 1. 理论证明谱硬阈值对约束二次失真问题是最优的；2. 在有界oracle噪声和平滑性假设下推导黎曼随机逼近的收敛保证；3. 实证评估：在2,500项有限上下文推理任务中，CQD在固定计算和上下文条件下优于思维链基线；4. 人类认知镜像基准测试显示现代oracle的认知增益和语义漂移。

Conclusion: CQD提供了一种理论严谨且实证有效的框架，通过压缩查询委托扩展有限上下文代理的推理能力，连接了率失真和信息瓶颈原理，并在实际任务中表现出优越性。

Abstract: Bounded-context agents fail when intermediate reasoning exceeds an effective working-memory budget. We study compressed query delegation (CQD): (i) compress a high-dimensional latent reasoning state into a low-rank tensor query, (ii) delegate the minimal query to an external oracle, and (iii) update the latent state via Riemannian optimization on fixed-rank manifolds. We give a math-first formulation: CQD is a constrained stochastic program with a query-budget functional and an oracle modeled as a noisy operator. We connect CQD to classical rate-distortion and information bottleneck principles, showing that spectral hard-thresholding is optimal for a natural constrained quadratic distortion problem, and we derive convergence guarantees for Riemannian stochastic approximation under bounded oracle noise and smoothness assumptions. Empirically, we report (A) a 2,500-item bounded-context reasoning suite (BBH-derived tasks plus curated paradox instances) comparing CQD against chain-of-thought baselines under fixed compute and context; and (B) a human "cognitive mirror" benchmark (N=200) measuring epistemic gain and semantic drift across modern oracles.

</details>


### [231] [Intention Collapse: Intention-Level Metrics for Reasoning in Language Models](https://arxiv.org/abs/2601.01011)
*Patricio Vera*

Main category: cs.CL

TL;DR: 本文提出“意图坍缩”概念，用于描述语言生成过程中高维内部状态到单一代币序列的映射，并定义了三种意图度量指标。通过实验发现思维链推理能显著提升模型性能并改变意图空间结构，但当前代理指标仍存在局限性。


<details>
  <summary>Details</summary>
Motivation: 语言生成过程本质上是将丰富的内部意图状态压缩为线性序列，但现有研究缺乏对“意图坍缩”现象的系统度量方法。本文旨在建立形式化框架，探究不同推理机制如何影响语言模型内部意图的表达与保留。

Method: 1. 形式化定义意图坍缩理论框架；2. 提出三种模型无关的意图度量指标：意图熵、有效维度和潜在知识可恢复性；3. 设计实验对比直接回答、思维链推理和随机生成三种推理机制；4. 使用4位量化Mistral 7B模型在GSM8K数据集进行200题测试。

Result: 1. 思维链推理将准确率从5.5%提升至53%；2. 思维链显著降低坍缩前意图熵（从1.42比特降至0.37比特）；3. 思维链的有效维度高于其他机制；4. 线性探针在思维链机制中AUROC达0.65，但在直接回答机制中仅接近随机水平。

Conclusion: 意图层面度量能有效区分不同推理机制，揭示思维链通过结构化内部表征保留更多潜在信息。但当前代理指标（如意图熵）在项目层面预测力有限，需开发更精确的意图测量工具以深入理解语言生成机制。

Abstract: Every act of language generation compresses a rich internal state into a single token sequence. We call this process intention collapse: a many-to-one projection from a high dimensional intention space I into an external language space L. We formalize intention collapse for contemporary language models, define three simple, model agnostic intention metrics (intention entropy Hint, effective dimensionality dimeff, and latent knowledge recoverability Recov), and propose an empirical agenda for studying how inference time computation shapes internal intentions before they are verbalized. We also report a first small scale experiment. Using a 4 bit Mistral 7B model on 200 GSM8K problems, we compare a direct answer baseline, a chain of thought (CoT) regime, and a babble control. CoT raises accuracy from 5.5 percent to 53 percent, sharply reduces pre collapse intention entropy (from 1.42 to 0.37 bits), and shows higher global effective dimensionality than the other regimes despite producing fewer tokens than babble. At the same time, Hint has little item level predictive power, and a linear probe on I achieves AUROC 0.65 in the CoT regime but only about chance in the baseline regime, where it collapses to the majority class. These preliminary results indicate that intention level metrics can distinguish inference regimes and expose latent information that is partly lost during collapse, while also revealing important limitations of our current proxies

</details>


### [232] [HyperJoin: LLM-augmented Hypergraph Link Prediction for Joinable Table Discovery](https://arxiv.org/abs/2601.01015)
*Shiyuan Liu,Jianwei Wang,Xuemin Lin,Lu Qin,Wenjie Zhang,Ying Zhang*

Main category: cs.CL

TL;DR: 本文提出HyperJoin框架，通过超图建模和分层交互网络解决可连接表发现中结构交互不足的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言模型的方法在离线建模时未能充分捕捉表间和表内结构信息，在线排序时忽略候选列间的相互影响，导致结果集不连贯。

Method: 构建包含表内超边和LLM增强表间超边的超图，将任务转化为链接预测；设计分层交互网络进行双向消息传递学习列表示；采用基于最大生成树的重排序模块提升结果连贯性。

Result: 实验显示HyperJoin在Precision@15和Recall@15指标上分别比最佳基线平均提升21.4%和17.2%。

Conclusion: HyperJoin通过超图建模和连贯性感知的排序机制，有效解决了可连接表发现中的结构交互问题，显著优于现有方法。

Abstract: As a pivotal task in data lake management, joinable table discovery has attracted widespread interest. While existing language model-based methods achieve remarkable performance by combining offline column representation learning with online ranking, their design insufficiently accounts for the underlying structural interactions: (1) offline, they directly model tables into isolated or pairwise columns, thereby struggling to capture the rich inter-table and intra-table structural information; and (2) online, they rank candidate columns based solely on query-candidate similarity, ignoring the mutual interactions among the candidates, leading to incoherent result sets. To address these limitations, we propose HyperJoin, a large language model (LLM)-augmented Hypergraph framework for Joinable table discovery. Specifically, we first construct a hypergraph to model tables using both the intra-table hyperedges and the LLM-augmented inter-table hyperedges. Consequently, the task of joinable table discovery is formulated as link prediction on this constructed hypergraph. We then design HIN, a Hierarchical Interaction Network that learns expressive column representations through bidirectional message passing over columns and hyperedges. To strengthen coherence and internal consistency in the result columns, we cast online ranking as a coherence-aware top-k column selection problem. We then introduce a reranking module that leverages a maximum spanning tree algorithm to prune noisy connections and maximize coherence. Experiments demonstrate the superiority of HyperJoin, achieving average improvements of 21.4% (Precision@15) and 17.2% (Recall@15) over the best baseline.

</details>


### [233] [Multi-Dimensional Prompt Chaining to Improve Open-Domain Dialogue Generation](https://arxiv.org/abs/2601.01037)
*Livia Leong Hui Teng*

Main category: cs.CL

TL;DR: 提出多维提示链框架提升小语言模型在开放域对话中的人类相似度，使Llama-2-7B性能接近大模型。


<details>
  <summary>Details</summary>
Motivation: 小语言模型部署优势明显，但在开放域对话质量上难以匹敌大模型，需资源高效的方法提升其对话表现。

Method: 设计融合自然度、连贯性和吸引力的多维提示链框架，应用于TinyLlama和Llama-2-7B，通过自动和人工评估对比大模型。

Result: 完整框架使回复多样性提升29%，上下文连贯性提升28%，吸引力和自然度提升29%；Llama-2-7B性能接近Llama-2-70B和GPT-3.5 Turbo。

Conclusion: 精心设计的提示策略为提升小语言模型开放域对话质量提供了有效且资源高效的途径。

Abstract: Small language models (SLMs) offer significant deployment advantages but often struggle to match the dialogue quality of larger models in open-domain settings. In this paper, we propose a multi-dimensional prompt-chaining framework that integrates Naturalness, Coherence, and Engagingness dimensions to enhance human-likeness in open-domain dialogue generation. We apply the framework to two SLMs, TinyLlama and Llama-2-7B, and benchmark their performance against responses generated by substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. We then employ automatic and human evaluation to assess the responses based on diversity, contextual coherence, as well as overall quality. Results show that the full framework improves response diversity by up to 29%, contextual coherence by up to 28%, and engagingness as well as naturalness by up to 29%. Notably, Llama-2-7B achieves performance comparable to substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. Overall, the findings demonstrate that carefully designed prompt-based strategies provide an effective and resource-efficient pathway to improving open-domain dialogue quality in SLMs.

</details>


### [234] [KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs](https://arxiv.org/abs/2601.01046)
*Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: 提出KV-Embedding框架，通过重定向LLM内部键值状态作为前缀，激活冻结大语言模型的表征能力，解决因果注意力和下一个词预测目标带来的结构限制。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在无需训练的场景下存在两个结构性问题：因果注意力机制限制早期token访问后续上下文，下一个词预测目标使表征偏向生成而非语义压缩。

Method: 利用最终token在各层的键值状态编码序列压缩视图，将其重定向为预置前缀使所有token能访问序列级上下文；提出基于内在维度的自动层选择策略确保模型无关性。

Result: 在MTEB基准测试中，使用Qwen、Mistral和Llama骨干网络，KV-Embedding比现有无需训练基线性能提升达10%，且在4096个token的序列上保持稳健表现。

Conclusion: 内部状态操作为输入修改提供了高效替代方案，这项工作鼓励进一步探索LLM内部机制用于表征学习。

Abstract: While LLMs are powerful embedding backbones, their application in training-free settings faces two structural challenges: causal attention restricts early tokens from accessing subsequent context, and the next-token prediction objective biases representations toward generation rather than semantic compression. To address these limitations, we propose KV-Embedding, a framework that activates the latent representation power of frozen LLMs. Our method leverages the observation that the key-value (KV) states of the final token at each layer encode a compressed view of the sequence. By re-routing these states as a prepended prefix, we enable all tokens to access sequence-level context within a single forward pass. To ensure model-agnostic applicability, we introduce an automated layer selection strategy based on intrinsic dimensionality. Evaluations on MTEB across Qwen, Mistral, and Llama backbones show that KV-Embedding outperforms existing training-free baselines by up to 10%, while maintaining robust performance on sequences up to 4,096 tokens. These results demonstrate that internal state manipulation offers an efficient alternative to input modification, and we hope this work encourages further exploration of LLM internals for representation learning.

</details>


### [235] [Unsupervised Text Style Transfer for Controllable Intensity](https://arxiv.org/abs/2601.01060)
*Shuhuan Gu,Wenbiao Tao,Xinchen Ma,Kangkang He,Ye Guo,Xiang Li,Yunshi Lan*

Main category: cs.CL

TL;DR: 提出SFT-then-PPO范式，通过合成平行数据微调LLM后，用分层奖励函数进行PPO训练，实现无监督文本风格强度可控迁移。


<details>
  <summary>Details</summary>
Motivation: 无监督文本风格迁移中，风格强度的精细控制因相邻强度级别特征差异细微而更具挑战性，且缺乏平行数据加剧了训练难度。

Method: 采用SFT-then-PPO两阶段方法：1）用合成平行数据对LLM进行监督微调；2）设计融合全局与局部风格特征的分层奖励函数，通过PPO进一步优化模型。

Result: 在两个无监督文本风格迁移基准测试中，该方法在多项评估指标上显著提升LLM基座性能，即使对于相近强度级别，生成文本仍能呈现可区分的风格差异。

Conclusion: 分层奖励设计能有效捕捉风格强度细微差异，SFT-then-PPO范式可显著提升无监督场景下文本风格强度可控迁移的性能。

Abstract: Unsupervised Text Style Transfer (UTST) aims to build a system to transfer the stylistic properties of a given text without parallel text pairs. Compared with text transfer between style polarities, UTST for controllable intensity is more challenging due to the subtle differences in stylistic features across different intensity levels. Faced with the challenges posed by the lack of parallel data and the indistinguishability between adjacent intensity levels, we propose a SFT-then-PPO paradigm to fine-tune an LLM. We first fine-tune the LLM with synthesized parallel data. Then, we further train the LLM with PPO, where the rewards are elaborately designed for distinguishing the stylistic intensity in hierarchical levels. Both the global and local stylistic features are considered to formulate the reward functions. The experiments on two UTST benchmarks showcase that both rewards have their advantages and applying them to LLM fine-tuning can effectively improve the performance of an LLM backbone based on various evaluation metrics. Even for close levels of intensity, we can still observe the noticeable stylistic difference between the generated text.

</details>


### [236] [ks-lit-3m: A 3.1 million word kashmiri text dataset for large language model pretraining](https://arxiv.org/abs/2601.01091)
*Haq Nawaz Malik*

Main category: cs.CL

TL;DR: 该论文构建了KS-LIT-3M语料库，包含310万单词的克什米尔语文本，旨在解决大语言模型因缺乏高质量训练数据而无法生成连贯克什米尔语文本的问题。


<details>
  <summary>Details</summary>
Motivation: 克什米尔语（约700万人使用）长期缺乏高质量数字文本资源，大量文献因使用专有InPage排版格式而无法被NLP工具处理，导致大语言模型在该语言上表现不佳。

Method: 开发专用InPage-to-Unicode转换器提取文本，通过去除英语污染、字符标准化和质量验证等预处理步骤，构建包含文学、新闻、学术和宗教等多体裁的线性文本流语料库。

Result: 成功创建包含131,607个独特单词、覆盖多领域的克什米尔语语料库KS-LIT-3M，以CC-BY-4.0协议开源，为克什米尔语NLP研究提供基础资源。

Conclusion: KS-LIT-3M填补了克什米尔语高质量训练数据的空白，通过技术手段释放了被格式封锁的文献价值，为提升低资源语言模型性能提供了可行方案。

Abstract: Large Language Models (LLMs) demonstrate remarkable fluency across high-resource languages yet consistently fail to generate coherent text in Kashmiri, a language spoken by approximately seven million people. This performance disparity stems not from inherent model limitations but from a critical scarcity of high-quality training data. Decades of Kashmiri literature remain inaccessible to modern NLP pipelines due to their encoding in the proprietary InPage desktop publishing format. This paper introduces KS-LIT-3M, a curated corpus of 3.1 million words (16.4 million characters) specifically designed for pretraining language models on Kashmiri. The dataset is structured as a single continuous linear text stream, optimized for causal language model training where models learn to predict subsequent tokens from preceding context. The corpus was constructed through the development of a specialized InPage-to-Unicode converter, followed by rigorous preprocessing including English contamination removal, character normalization, and quality validation. Encompassing 131,607 unique words drawn from diverse genres including literary works, journalistic writing, academic texts, and religious scholarship, KS-LIT-3M addresses a fundamental resource gap for Kashmiri language technology. The dataset is released under the CC-BY-4.0 license to facilitate research in Kashmiri natural language processing.

</details>


### [237] [EmoLoom-2B: Fast Base-Model Screening for Emotion Classification and VAD with Lexicon-Weak Supervision and KV-Off Evaluation](https://arxiv.org/abs/2601.01112)
*Zilin Li,Weiwei Xu,Xuanbo Lu,Zheda Liu*

Main category: cs.CL

TL;DR: 提出了EmoLoom-2B，一个轻量级可复现的流程，可将小于20亿参数的小语言模型转化为情感分类和VAD预测的快速筛选候选模型。


<details>
  <summary>Details</summary>
Motivation: 需要一种协议忠实且公平的评估方法，减少可避免的方差，并提高小语言模型在情感分析任务中的性能，同时保持预算意识、可审计和可重入性。

Method: 采用统一的JSON输入输出协议，使用KV-off解码作为默认设置，引入两个正交语义正则化器（VAD保持约束和轻量级外部评估分类器），应用Valence Flip增强技术，并在监督微调中使用A/B混合采样与熵感知温度调度。

Result: 以Qwen-1.8B-Chat为基础模型，EmoLoom-2B在GoEmotions和EmpatheticDialogues上表现出色，并在DailyDialog上展示了强大的跨语料库泛化能力。

Conclusion: EmoLoom-2B是一个可靠、预算友好且可审计的筛选流程，适用于在更重的训练或多模态融合之前进行快速筛选。

Abstract: We introduce EmoLoom-2B, a lightweight and reproducible pipeline that turns small language models under 2B parameters into fast screening candidates for joint emotion classification and Valence-Arousal-Dominance prediction. To ensure protocol-faithful and fair evaluation, we unify data loading, training, and inference under a single JSON input-output contract and remove avoidable variance by adopting KV-off decoding as the default setting. We incorporate two orthogonal semantic regularizers: a VAD-preserving constraint that aligns generated text with target VAD triples, and a lightweight external appraisal classifier that provides training-time guidance on goal attainment, controllability, certainty, and fairness without injecting long rationales. To improve polarity sensitivity, we introduce Valence Flip augmentation based on mirrored emotional pairs. During supervised fine-tuning, we apply A/B mixture sampling with entropy-aware temperature scheduling to balance coverage and convergence. Using Qwen-1.8B-Chat as the base model, EmoLoom-2B achieves strong performance on GoEmotions and EmpatheticDialogues, and demonstrates robust cross-corpus generalization on DailyDialog. The proposed recipe is budget-aware, auditable, and re-entrant, serving as a dependable screening pass before heavier training or multimodal fusion.

</details>


### [238] [Listen, Attend, Understand: a Regularization Technique for Stable E2E Speech Translation Training on High Variance labels](https://arxiv.org/abs/2601.01121)
*Yacouba Diarra,Michael Leventhal*

Main category: cs.CL

TL;DR: 提出LAU语义正则化方法，通过冻结文本嵌入提供方向性辅助损失，将语言基础注入声学表示，改善端到端语音翻译性能，特别是在数据稀缺和嘈杂情况下。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译在目标转录具有高方差和语义模糊性时，通常表现出收敛较慢和性能较差的问题。

Method: 提出Listen, Attend, Understand (LAU)语义正则化技术，在训练期间约束声学编码器的潜在空间，利用冻结文本嵌入提供方向性辅助损失，不增加推理成本。

Result: 在30小时班巴拉语到法语数据集上，LAU模型与使用100%更多数据预训练的E2E-ST系统相比，在标准指标上达到相当性能，同时在保留语义含义方面表现更好。引入总参数漂移指标量化正则化的结构影响。

Conclusion: LAU是后验重评分的稳健替代方案，是E2E-ST训练的有价值补充，特别适用于训练数据稀缺和/或嘈杂的情况。

Abstract: End-to-End Speech Translation often shows slower convergence and worse performance when target transcriptions exhibit high variance and semantic ambiguity. We propose Listen, Attend, Understand (LAU), a semantic regularization technique that constrains the acoustic encoder's latent space during training. By leveraging frozen text embeddings to provide a directional auxiliary loss, LAU injects linguistic groundedness into the acoustic representation without increasing inference cost. We evaluate our method on a Bambara-to-French dataset with 30 hours of Bambara speech translated by non-professionals. Experimental results demonstrate that LAU models achieve comparable performance by standard metrics compared to an E2E-ST system pretrained with 100\% more data and while performing better in preserving semantic meaning. Furthermore, we introduce Total Parameter Drift as a metric to quantify the structural impact of regularization to demonstrate that semantic constraints actively reorganize the encoder's weights to prioritize meaning over literal phonetics. Our findings suggest that LAU is a robust alternative to post-hoc rescoring and a valuable addition to E2E-ST training, especially when training data is scarce and/or noisy.

</details>


### [239] [RoboPhD: Self-Improving Text-to-SQL Through Autonomous Agent Evolution](https://arxiv.org/abs/2601.01126)
*Andrew Borthwick,Stephen Ash*

Main category: cs.CL

TL;DR: RoboPhD系统通过AI代理自主进化提升Text-to-SQL性能，采用ELO选择机制迭代演化，在BIRD数据集上达到73.67%准确率，实现低成本模型超越高成本模型的效果。


<details>
  <summary>Details</summary>
Motivation: 旨在探索AI能否在无领域知识指导的情况下，通过自主研究构建强大的Text-to-SQL系统，降低对人工专业知识和昂贵模型的依赖。

Method: 设计闭环进化框架：SQL生成代理（数据库分析+SQL生成指令）与进化代理协同工作；采用ELO机制处理性能非传递性；通过迭代交叉繁衍从70行基线自主演化技术。

Result: 最佳代理经18代演化至1500行，自主发现自适应数据库分析、列选择模式等技术；在Claude Haiku模型上提升8.9个百分点，实现“跨级替代”：进化版廉价模型超越原始昂贵模型性能。

Conclusion: AI仅需简单初始设定即可自主构建高效Text-to-SQL系统，进化机制对低成本模型提升显著，为降低部署成本同时保持性能提供了新路径。

Abstract: We present RoboPhD, a system where AI agents autonomously conduct research to improve Text-to-SQL performance. RoboPhD implements a closed-loop evolution cycle with two coordinated components: a SQL Generation agent composed of a database analysis script and SQL generation instructions, and an Evolution agent that designs new versions based on performance feedback. Central to the framework is an ELO-based selection mechanism enabling survival-of-the-fittest dynamics while handling non-transitivity in performance. Starting from a naive 70-line baseline, RoboPhD evolves agents through iterative cross-pollination, discovering effective techniques without any external guidance on the Text-to-SQL domain. Our best agent, evolved to 1500 lines over 18 iterations, autonomously discovered strategies such as size-adaptive database analysis that adjusts depth based on schema complexity and SQL generation patterns for column selection, evidence interpretation, and aggregation. Evolution provides the largest gains on cheaper models: while we improve by 2.3 points over a strong Claude Opus 4.5 naive baseline, we show an improvement of 8.9 points over the weaker Claude Haiku model. This enables 'skip a tier' deployment: evolved Haiku exceeds naive Sonnet accuracy, and evolved Sonnet exceeds naive Opus, both at lower cost. The full system achieves 73.67% accuracy on the BIRD test set, demonstrating that AI can autonomously build a strong agentic system with only a trivial human-provided starting point.

</details>


### [240] [KOS-TL (Knowledge Operation System Type Logic)](https://arxiv.org/abs/2601.01143)
*Peng Chen*

Main category: cs.CL

TL;DR: 本文提出KOS-TL（知识操作系统类型逻辑），一种基于依赖类型论的构造性框架，旨在为自主可执行知识系统提供严格的逻辑基础，统一数据、逻辑与证明，并通过三层架构实现状态演化和形式化验证。


<details>
  <summary>Details</summary>
Motivation: 传统知识表示模型存在静态符号逻辑与动态系统执行之间的鸿沟，缺乏形式化验证机制，难以支撑自主、可验证的知识系统。

Method: 基于依赖类型论，构建三层架构：核心层（静态类型宇宙与构造原语）、内核层（基于事件驱动状态演化的三元组⟨Σ, Ev, Δ⟩）、运行时层（物理信号与逻辑证据的双向精化）；整合戴维森事件语义与马丁-洛夫类型论，定义操作语义并证明进展性与演化一致性等元理论性质。

Result: KOS-TL实现了“携带证明的知识”，确保知识库状态变化均伴随形式化有效性见证；在工业追溯与跨境金融合规等案例中验证了其实用性；系统具备逻辑自洽性且无停滞状态。

Conclusion: KOS-TL为下一代智能自主操作系统提供了鲁棒且可形式化验证的基础框架，弥合了逻辑表示与系统执行间的断层。

Abstract: This paper introduces KOS-TL (Knowledge Operation System Type Logic), a novel constructive framework designed to provide a rigorous logical foundation for autonomous and executable knowledge systems. Traditional knowledge representation models often suffer from a gap between static symbolic logic and dynamic system execution. To bridge this divide, KOS-TL leverages Dependent Type Theory to unify data, logic, and proof into a singular computational substrate.The architecture of KOS-TL is organized into three hierarchical layers: the Core Layer, which defines the static type universe and constructive primitives; the Kernel Layer, which governs state evolution through an event-driven mechanism characterized by the triple $\langle Σ, \textsf{Ev}, Δ\rangle$; and the Runtime Layer, responsible for the bidirectional refinement of physical signals into logical evidence. We formally define the operational semantics of the system and prove key meta-theoretical properties, including Progress and Evolutionary Consistency, ensuring that the system remains logically self-consistent and free from stuck states during continuous state transitions.By integrating Davidsonian event semantics with Martin-Löf type theory, KOS-TL enables the construction of "proof-carrying knowledge," where every state change in the knowledge base is accompanied by a formal witness of its validity. We demonstrate the practical utility of this logic through application examples in industrial traceability and cross-border financial compliance. Our results suggest that KOS-TL provides a robust, formally verifiable basis for the next generation of intelligent, autonomous operating systems.

</details>


### [241] [SongSage: A Large Musical Language Model with Lyric Generative Pre-training](https://arxiv.org/abs/2601.01153)
*Jiani Guo,Jiajia Li,Jie Wu,Zuchao Li,Yujiu Yang,Ping Wang*

Main category: cs.CL

TL;DR: 本文介绍了SongSage，一个专注于歌词理解的大型音乐语言模型，通过歌词生成预训练和指令微调，在歌词相关任务上表现出色，同时保持通用知识能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在歌词中心知识理解方面尚未充分探索，特别是在播放列表理解能力上存在改进空间，这促使研究者开发专门针对音乐歌词理解的模型。

Method: 1) 构建PlaylistSense数据集评估语言模型的播放列表理解能力；2) 创建LyricBank语料库（54.8亿token）进行持续预训练；3) 使用LyricBank-SFT指令集（77.5万样本，9个核心任务）进行微调；4) 开发SongSage模型，结合歌词生成预训练和任务特定微调。

Result: SongSage在歌词中心知识理解方面表现优异，能够有效重写用户查询进行零样本播放列表推荐，流畅生成和续写歌词，在七个附加能力上表现熟练，同时在MMLU基准测试中保持竞争力的通用知识理解分数。

Conclusion: SongSage证明了专门针对歌词内容训练的模型能够显著提升音乐相关任务的理解和生成能力，同时不牺牲通用语言理解能力，为音乐AI研究和应用提供了有价值的工具。

Abstract: Large language models have achieved significant success in various domains, yet their understanding of lyric-centric knowledge has not been fully explored. In this work, we first introduce PlaylistSense, a dataset to evaluate the playlist understanding capability of language models. PlaylistSense encompasses ten types of user queries derived from common real-world perspectives, challenging LLMs to accurately grasp playlist features and address diverse user intents. Comprehensive evaluations indicate that current general-purpose LLMs still have potential for improvement in playlist understanding. Inspired by this, we introduce SongSage, a large musical language model equipped with diverse lyric-centric intelligence through lyric generative pretraining. SongSage undergoes continual pretraining on LyricBank, a carefully curated corpus of 5.48 billion tokens focused on lyrical content, followed by fine-tuning with LyricBank-SFT, a meticulously crafted instruction set comprising 775k samples across nine core lyric-centric tasks. Experimental results demonstrate that SongSage exhibits a strong understanding of lyric-centric knowledge, excels in rewriting user queries for zero-shot playlist recommendations, generates and continues lyrics effectively, and performs proficiently across seven additional capabilities. Beyond its lyric-centric expertise, SongSage also retains general knowledge comprehension and achieves a competitive MMLU score. We will keep the datasets inaccessible due to copyright restrictions and release the SongSage and training script to ensure reproducibility and support music AI research and applications, the datasets release plan details are provided in the appendix.

</details>


### [242] [DHI: Leveraging Diverse Hallucination Induction for Enhanced Contrastive Factuality Control in Large Language Models](https://arxiv.org/abs/2601.01156)
*Jiani Guo,Xiangke Zeng,Jie Wu,Zuchao Li*

Main category: cs.CL

TL;DR: 提出DHI框架，通过改进损失函数和因果注意力掩码，使Evil LLM生成更多样化的幻觉，结合自适应理性约束提升大语言模型的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过训练Evil LLM生成特定幻觉来指导对比解码，但诱导的幻觉类型单一，限制了缓解幻觉的整体效果。

Method: 提出DHI训练框架，使用改进的损失函数降低特定事实正确token的生成权重，结合因果注意力掩码适应，并在推理时应用自适应理性约束。

Result: 在多个幻觉基准测试中，DHI相比其他基于对比解码的方法取得了显著的性能提升。

Conclusion: DHI能够在不依赖预标注幻觉数据的情况下，有效生成多样化的幻觉类型，从而更全面地缓解大语言模型的幻觉问题。

Abstract: Large language models (LLMs) frequently produce inaccurate or fabricated information, known as "hallucinations," which compromises their reliability. Existing approaches often train an "Evil LLM" to deliberately generate hallucinations on curated datasets, using these induced hallucinations to guide contrastive decoding against a reliable "positive model" for hallucination mitigation. However, this strategy is limited by the narrow diversity of hallucinations induced, as Evil LLMs trained on specific error types tend to reproduce only these particular patterns, thereby restricting their overall effectiveness. To address these limitations, we propose DHI (Diverse Hallucination Induction), a novel training framework that enables the Evil LLM to generate a broader range of hallucination types without relying on pre-annotated hallucination data. DHI employs a modified loss function that down-weights the generation of specific factually correct tokens, encouraging the Evil LLM to produce diverse hallucinations at targeted positions while maintaining overall factual content. Additionally, we introduce a causal attention masking adaptation to reduce the impact of this penalization on the generation of subsequent tokens. During inference, we apply an adaptive rationality constraint that restricts contrastive decoding to tokens where the positive model exhibits high confidence, thereby avoiding unnecessary penalties on factually correct tokens. Extensive empirical results show that DHI achieves significant performance gains over other contrastive decoding-based approaches across multiple hallucination benchmarks.

</details>


### [243] [Almost Clinical: Linguistic properties of synthetic electronic health records](https://arxiv.org/abs/2601.01171)
*Serge Sharoff,John Baker,David Francis Hunt,Alan Simpson*

Main category: cs.CL

TL;DR: 评估心理健康领域合成电子健康记录的语言学和临床适用性，发现大语言模型能生成近似临床实践的文本，但存在系统性差异。


<details>
  <summary>Details</summary>
Motivation: 评估合成电子健康记录在心理健康领域的实际适用性，特别是大语言模型生成文本的临床准确性和语言特征。

Method: 首先描述合成语料库的创建原理和方法，然后评估四个临床类型（评估、通信、转诊和护理计划）中的能动性、情态和信息流，分析大语言模型如何通过语言选择构建医疗权威和患者能动性。

Result: 大语言模型能生成连贯、术语适当的文本，近似临床实践，但存在系统性差异，包括语域转换、临床特异性不足、药物使用和诊断程序不准确。

Conclusion: 合成电子健康记录在心理健康领域具有潜力，但需要解决语言模型生成的文本在临床准确性和特异性方面的局限性。

Abstract: This study evaluates the linguistic and clinical suitability of synthetic electronic health records (EHRs) in the field of mental health. First, we describe the rationale and the methodology for creating the synthetic corpus. Second, we assess agency, modality, and information flow across four clinical genres (Assessments, Correspondence, Referrals and Care plans) to understand how LLMs grammatically construct medical authority and patient agency through linguistic choices. While LLMs produce coherent, terminology-appropriate texts that approximate clinical practice, systematic divergences remain, including registerial shifts, insufficient clinical specificity, and inaccuracies in medication use and diagnostic procedures.

</details>


### [244] [Stylometry Analysis of Human and Machine Text for Academic Integrity](https://arxiv.org/abs/2601.01225)
*Hezam Albaqami,Muhammad Asif Ayub,Nasir Ahmad,Yaseen Ahmad,Mohammed M. Alqahtani,Abdullah M. Algamdi,Almoaid A. Owaidah,Kashif Ahmad*

Main category: cs.CL

TL;DR: 提出基于NLP的框架，通过作者归属和风格变化检测来认证学生内容，解决学术诚信问题，包括区分人机文本、单多作者文档、多作者文档中的作者变化检测及协作文档作者识别。


<details>
  <summary>Details</summary>
Motivation: 应对学术诚信挑战，如抄袭、伪造和教育内容作者身份验证，现有解决方案不全面，需探索更多方面。

Method: 针对四个任务提出解决方案：人机文本分类、单多作者文档区分、多作者文档内作者变化检测、协作文档作者识别；使用Gemini生成两个数据集（正常和严格指令）进行评估。

Result: 在严格指令生成的数据集上，解决方案性能有所下降，表明检测巧妙设计的机器生成文本的复杂性；生成的数据集、代码和相关材料已公开。

Conclusion: 提出的框架为学术内容认证提供了全面分析，公开资源为未来研究提供了基线，强调了检测精心设计的机器生成文本的挑战。

Abstract: This work addresses critical challenges to academic integrity, including plagiarism, fabrication, and verification of authorship of educational content, by proposing a Natural Language Processing (NLP)-based framework for authenticating students' content through author attribution and style change detection. Despite some initial efforts, several aspects of the topic are yet to be explored. In contrast to existing solutions, the paper provides a comprehensive analysis of the topic by targeting four relevant tasks, including (i) classification of human and machine text, (ii) differentiating in single and multi-authored documents, (iii) author change detection within multi-authored documents, and (iv) author recognition in collaboratively produced documents. The solutions proposed for the tasks are evaluated on two datasets generated with Gemini using two different prompts, including a normal and a strict set of instructions. During experiments, some reduction in the performance of the proposed solutions is observed on the dataset generated through the strict prompt, demonstrating the complexities involved in detecting machine-generated text with cleverly crafted prompts. The generated datasets, code, and other relevant materials are made publicly available on GitHub, which are expected to provide a baseline for future research in the domain.

</details>


### [245] [Racka: Efficient Hungarian LLM Adaptation on Academic Infrastructure](https://arxiv.org/abs/2601.01244)
*Zsolt Csibi,Bence György Gortka,Natabara Gyöngyössy,Kornél Nagy,Dávid Márk Nemeskey,Martin Sallai,András Simonyi,András Márk Szekeres,Gábor Palkó*

Main category: cs.CL

TL;DR: Racka是一个轻量级、持续预训练的大语言模型，旨在缩小匈牙利语与英语、德语等高资源语言之间的资源差距。


<details>
  <summary>Details</summary>
Motivation: 匈牙利语等低资源语言与英语、德语等高资源语言之间存在显著的资源差距，需要开发能够有效处理低资源语言同时保持高资源语言能力的模型。

Method: 采用基于Qwen-3 4B骨干网络的参数高效持续预训练方法，使用低秩适应（LoRA）技术；替换并适配分词器以改善匈牙利语的分词效率；在包含160B子词标记的数据集上进行训练，数据混合比例为44%匈牙利语、24%英语、21%德语和11%代码。

Result: 模型在匈牙利语分词效率方面有显著提升，同时在英语和德语上保持竞争力；初步结果显示在语言适应方面取得了稳定但适中的成果。

Conclusion: Racka通过参数高效的持续预训练方法，成功缩小了匈牙利语与高资源语言之间的差距，同时避免了灾难性遗忘问题，为低资源语言处理提供了实用解决方案。

Abstract: We present Racka, a lightweight, continually pretrained large language model designed to bridge the resource gap between Hungarian and high-resource languages such as English and German. Racka employs parameter-efficient continual pretraining via Low-Rank Adaptation (LoRA) on a Qwen-3 4B backbone, making the recipe practical on A100 (40GB)-based HPC clusters with low inter-node bandwidth. To better match the training distribution, we replace and adapt the tokenizer, achieving substantially improved tokenization fertility for Hungarian while maintaining competitive performance in English and German. The model is trained on 160B subword tokens drawn from a mixture of internet and high-quality curated sources, with a composition of 44% Hungarian, 24% English, 21% German, and 11% code. This data mix is chosen to mitigate catastrophic forgetting and preserve high-resource language capabilities during continual pretraining. Our preliminary results indicate modest but stable results in language adaptation.

</details>


### [246] [From Policy to Logic for Efficient and Interpretable Coverage Assessment](https://arxiv.org/abs/2601.01266)
*Rhitabrat Pokharel,Hamid Hassanzadeh,Ameeta Agrawal*

Main category: cs.CL

TL;DR: 提出一种结合检索增强与符号推理的混合方法，用于提升大语言模型在医疗政策审查中的效率和可解释性，在降低44%推理成本的同时提升4.5%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理复杂法律政策文本时存在幻觉和不一致问题，尤其在医疗政策审查等对准确性要求极高的领域，需要提高模型的可信度和可解释性以支持人类专家决策。

Method: 采用混合系统：1）覆盖感知检索器提取相关政策文本；2）符号化规则推理将文本组织为明确的事实与规则；3）生成可审计的推理依据，减少对大语言模型推理的依赖。

Result: 系统在医疗政策审查任务中实现44%的推理成本降低，同时F1分数提升4.5%，兼顾效率与准确性。

Conclusion: 结合检索增强与符号推理的混合方法能有效提升大语言模型在专业领域应用的可靠性、可解释性和成本效益，为政策审查等关键任务提供可行解决方案。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in interpreting lengthy, complex legal and policy language. However, their reliability can be undermined by hallucinations and inconsistencies, particularly when analyzing subjective and nuanced documents. These challenges are especially critical in medical coverage policy review, where human experts must be able to rely on accurate information. In this paper, we present an approach designed to support human reviewers by making policy interpretation more efficient and interpretable. We introduce a methodology that pairs a coverage-aware retriever with symbolic rule-based reasoning to surface relevant policy language, organize it into explicit facts and rules, and generate auditable rationales. This hybrid system minimizes the number of LLM inferences required which reduces overall model cost. Notably, our approach achieves a 44% reduction in inference cost alongside a 4.5% improvement in F1 score, demonstrating both efficiency and effectiveness.

</details>


### [247] [Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory](https://arxiv.org/abs/2601.01280)
*Sen Hu,Yuxiang Wei,Jiaxin Ran,Zhiyuan Yao,Lei Zou*

Main category: cs.CL

TL;DR: 本文通过实验分析对话记忆系统架构，提出统一框架比较图与非图方法，发现性能差异主要源于基础系统设置而非特定架构创新，并确定了稳定可靠的基线模型。


<details>
  <summary>Details</summary>
Motivation: 图结构在对话记忆系统中应用日益广泛，但其有效性实证结果不一致，难以确定哪些设计选择真正关键，需要系统化分析澄清核心影响因素。

Method: 提出统一框架将对话记忆系统分解为核心组件，支持图与非图方法；在LongMemEval和HaluMem数据集上进行分阶段控制实验，比较记忆表示、组织、维护和检索的常见设计选择。

Result: 实验表明许多性能差异由基础系统设置驱动，而非特定架构创新；基于此识别出稳定可靠的强基线模型供未来研究使用。

Conclusion: 对话记忆系统的性能提升应更多关注基础系统优化而非复杂架构设计，所提框架和基线为未来研究提供了可靠基准。

Abstract: Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this framework, we conduct controlled, stage-wise experiments on LongMemEval and HaluMem, comparing common design choices in memory representation, organization, maintenance, and retrieval. Our results show that many performance differences are driven by foundational system settings rather than specific architectural innovations. Based on these findings, we identify stable and reliable strong baselines for future dialog memory research.

</details>


### [248] [T3C: Test-Time Tensor Compression with Consistency Guarantees](https://arxiv.org/abs/2601.01299)
*Ismail Lamaakal,Chaymae Yahyati,Yassine Maleh,Khalid El Makkaoui,Ibrahim Ouahbi*

Main category: cs.CL

TL;DR: T3C是一个训练一次、测试时预算调节的压缩框架，通过弹性张量分解和混合精度量化实现模型大小、延迟和能耗的可控调节，并提供可靠性保证。


<details>
  <summary>Details</summary>
Motivation: 现有模型压缩方法通常需要为不同部署场景重新训练或调整，缺乏统一的、可预测的精度-效率权衡机制，且缺少对压缩后模型可靠性的理论保证。

Method: 结合弹性张量分解（保持最大秩）、秩绑定的混合精度量化，以及轻量级控制器将预算令牌映射到每层秩/比特分配；采用基于谱代理和激活统计的快速层一致性证书来约束logit漂移并正则化训练。

Result: 在ImageNet-1k上，ResNet-50在精度下降≤0.5%时达到1.18ms p50延迟和38MB模型大小，优于PTQ-8b（1.44ms, 88MB）；ViT-B/16达到2.30ms p50延迟和59MB大小，超越强PTQ/QAT基线。

Conclusion: 单个T3C检查点可在不同设备上提供可预测的、有证书保证的精度-延迟-大小权衡，推动了视觉模型的帕累托前沿。

Abstract: We present T3C, a train-once, test-time budget-conditioned compression framework that exposes rank and precision as a controllable deployment knob. T3C combines elastic tensor factorization (maintained up to a maximal rank) with rank-tied mixed-precision quantization and a lightweight controller that maps a latency/energy/size budget token to per-layer rank/bit assignments; the policy snaps to hardware-aligned profiles and is monotone in the budget. A fast, layerwise consistency certificate, computed from spectral proxies and activation statistics, upper-bounds logit drift and regularizes training, yielding a practical reliability signal with negligible overhead. On ImageNet-1k, T3C shifts the vision Pareto frontier: for ResNet-50 at matched accuracy (\leq 0.5% drop), p50 latency is 1.18ms with a 38MB model, outperforming PTQ-8b (1.44ms, 88MB); for ViT-B/16, T3C reaches 2.30ms p50 with 59MB, improving over strong PTQ/QAT baselines. A single T3C checkpoint therefore provides predictable, certificate-backed accuracy-latency-size trade-offs on demand across devices.

</details>


### [249] [FLOP-Efficient Training: Early Stopping Based on Test-Time Compute Awareness](https://arxiv.org/abs/2601.01332)
*Hossam Amer,Maryam Dialameh,Hossein Rajabzadeh,Walid Ahmed,Weiwei Zhang,Yang Liu*

Main category: cs.CL

TL;DR: 提出TTC感知训练方法，通过早期停止算法联合选择检查点和测试时计算配置，在保持精度的同时大幅减少训练计算量。


<details>
  <summary>Details</summary>
Motivation: 传统大规模语言模型训练计算成本高昂，而增加测试时计算（TTC）可使小模型媲美大模型。研究旨在平衡训练与推理计算，降低部署成本。

Method: 1. 提出TTC感知训练框架；2. 设计早期停止算法联合优化检查点和TTC配置；3. 开发高效TTC评估方法避免穷举搜索；4. 形式化盈亏平衡界限分析计算转移效益。

Result: 实验显示训练FLOPs最高减少92%，同时保持甚至显著提升模型精度，验证了训练与推理计算平衡的有效性。

Conclusion: 该方法为模型开发提供了新的计算平衡视角，能加速部署周期并支持更频繁的模型更新，代码将开源。

Abstract: Scaling training compute, measured in FLOPs, has long been shown to improve the accuracy of large language models, yet training remains resource-intensive. Prior work shows that increasing test-time compute (TTC)-for example through iterative sampling-can allow smaller models to rival or surpass much larger ones at lower overall cost. We introduce TTC-aware training, where an intermediate checkpoint and a corresponding TTC configuration can together match or exceed the accuracy of a fully trained model while requiring substantially fewer training FLOPs. Building on this insight, we propose an early stopping algorithm that jointly selects a checkpoint and TTC configuration to minimize training compute without sacrificing accuracy. To make this practical, we develop an efficient TTC evaluation method that avoids exhaustive search, and we formalize a break-even bound that identifies when increased inference compute compensates for reduced training compute. Experiments demonstrate up to 92\% reductions in training FLOPs while maintaining and sometimes remarkably improving accuracy. These results highlight a new perspective for balancing training and inference compute in model development, enabling faster deployment cycles and more frequent model refreshes. Codes will be publicly released.

</details>


### [250] [Reasoning Over Recall: Evaluating the Efficacy of Generalist Architectures vs. Specialized Fine-Tunes in RAG-Based Mental Health Dialogue Systems](https://arxiv.org/abs/2601.01341)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 本研究比较了通用推理模型与心理健康领域微调模型在RAG增强的心理咨询系统中的表现，发现较小的通用模型在共情能力上优于较大的领域专用模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在心理健康咨询应用中面临幻觉和缺乏共情的双重挑战。虽然RAG技术可通过检索可信临床资料来缓解幻觉问题，但尚不清楚在此范式下，基于心理健康数据微调的模型与依赖推理能力的通用模型哪种更有效。

Method: 使用ChromaDB构建相同的RAG流程，对比测试四个开源模型：两个通用推理模型（Qwen2.5-3B和Phi-3-Mini）和两个领域微调模型（MentalHealthBot-7B和TherapyBot-7B），采用LLM-as-a-Judge框架对50轮对话进行自动化评估。

Result: 通用模型在共情得分上显著优于领域专用模型（3.72 vs. 3.26，p<0.001），尽管模型规模更小（3B vs. 7B）。所有模型在安全性方面表现良好，但通用模型展现出更好的上下文理解能力，且不易出现过拟合现象。

Conclusion: 对于基于RAG的心理治疗系统，强大的推理能力比心理健康专业词汇的训练更重要；只要回答基于临床证据，推理能力强的通用模型能比大规模领域微调模型提供更具共情力和平衡性的支持。

Abstract: The deployment of Large Language Models (LLMs) in mental health counseling faces the dual challenges of hallucinations and lack of empathy. While the former may be mitigated by RAG (retrieval-augmented generation) by anchoring answers in trusted clinical sources, there remains an open question as to whether the most effective model under this paradigm would be one that is fine-tuned on mental health data, or a more general and powerful model that succeeds purely on the basis of reasoning. In this paper, we perform a direct comparison by running four open-source models through the same RAG pipeline using ChromaDB: two generalist reasoners (Qwen2.5-3B and Phi-3-Mini) and two domain-specific fine-tunes (MentalHealthBot-7B and TherapyBot-7B). We use an LLM-as-a-Judge framework to automate evaluation over 50 turns. We find a clear trend: the generalist models outperform the domain-specific ones in empathy (3.72 vs. 3.26, $p < 0.001$) in spite of being much smaller (3B vs. 7B), and all models perform well in terms of safety, but the generalist models show better contextual understanding and are less prone to overfitting as we observe in the domain-specific models. Overall, our results indicate that for RAG-based therapy systems, strong reasoning is more important than training on mental health-specific vocabulary; i.e. a well-reasoned general model would provide more empathetic and balanced support than a larger narrowly fine-tuned model, so long as the answer is already grounded in clinical evidence.

</details>


### [251] [FC-CONAN: An Exhaustively Paired Dataset for Robust Evaluation of Retrieval Systems](https://arxiv.org/abs/2601.01350)
*Juan Junqueras,Florian Boudin,May-Myo Zin,Ha-Thanh Nguyen,Wachara Fungwacharakorn,Damián Ariel Furman,Akiko Aizawa,Ken Satoh*

Main category: cs.CL

TL;DR: 提出了FC-CONAN数据集，通过穷举组合45条仇恨言论和129条反驳言论，构建了首个完全连接的仇恨言论-反驳言论配对数据集，解决了现有数据集标注稀疏的问题。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论与反驳言论配对数据集（如CONAN）仅标注了少量可能配对，限制了反驳言论检索系统的评估效果，需要更全面的数据集来支持研究。

Method: 采用两阶段标注流程：首先穷举生成所有45条仇恨言论与129条反驳言论的组合（共5805对），然后通过9名标注员和4名验证员进行人工标注，最终形成四个可靠性分级的子集（钻石、金、银、铜）。

Result: 构建的FC-CONAN数据集包含大量CONAN未标注的正样本对，实现了仇恨言论与反驳言论的完全连接，能更准确地评估反驳言论检索系统并进行错误分析。

Conclusion: FC-CONAN作为首个完全连接的仇恨言论-反驳言论配对数据集，公开可用，将显著提升反驳言论研究的评估质量并推动相关技术发展。

Abstract: Hate speech (HS) is a critical issue in online discourse, and one promising strategy to counter it is through the use of counter-narratives (CNs). Datasets linking HS with CNs are essential for advancing counterspeech research. However, even flagship resources like CONAN (Chung et al., 2019) annotate only a sparse subset of all possible HS-CN pairs, limiting evaluation. We introduce FC-CONAN (Fully Connected CONAN), the first dataset created by exhaustively considering all combinations of 45 English HS messages and 129 CNs. A two-stage annotation process involving nine annotators and four validators produces four partitions-Diamond, Gold, Silver, and Bronze-that balance reliability and scale. None of the labeled pairs overlap with CONAN, uncovering hundreds of previously unlabelled positives. FC-CONAN enables more faithful evaluation of counterspeech retrieval systems and facilitates detailed error analysis. The dataset is publicly available.

</details>


### [252] [Investigating the Multilingual Calibration Effects of Language Model Instruction-Tuning](https://arxiv.org/abs/2601.01362)
*Jerry Huang,Peng Lu,Qiuhao Zeng,Yusuke Iwasawa,Yutaka Matsuo,Sarath Chandar,Edison Marrese-Taylor,Irene Li*

Main category: cs.CL

TL;DR: 该研究探讨了多语言环境下大语言模型的校准问题，发现指令微调会加剧低资源语言的错误校准，而标签平滑技术能有效缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多语言场景下的预测不确定性校准研究尚不充分，数据稀缺可能导致不同语言的校准效果差异，影响模型的可靠性与公平性。

Method: 在两个多语言基准（分别覆盖29和42种语言）上分析指令微调的影响，并测试标签平滑技术对校准效果的改进作用。

Result: 低资源语言经高资源语言SFT数据集指令微调后，模型置信度显著上升但准确率提升有限，导致错误校准；标签平滑技术无需低资源数据即可改善多语言校准效果。

Conclusion: 多语言场景下需特别关注LLM的训练与微调策略，标签平滑是提升模型跨语言校准效果的有效方法，对下游应用的可靠性至关重要。

Abstract: Ensuring that deep learning models are well-calibrated in terms of their predictive uncertainty is essential in maintaining their trustworthiness and reliability, yet despite increasing advances in foundation model research, the relationship between such large language models (LLMs) and their calibration remains an open area of research. In this work, we look at a critical gap in the calibration of LLMs within multilingual settings, in an attempt to better understand how the data scarcity can potentially lead to different calibration effects and how commonly used techniques can apply in these settings. Our analysis on two multilingual benchmarks, over 29 and 42 languages respectively, reveals that even in low-resource languages, model confidence can increase significantly after instruction-tuning on high-resource language SFT datasets. However, improvements in accuracy are marginal or non-existent, resulting in mis-calibration, highlighting a critical shortcoming of standard SFT for multilingual languages. Furthermore, we observe that the use of label smoothing to be a reasonable method alleviate this concern, again without any need for low-resource SFT data, maintaining better calibration across all languages. Overall, this highlights the importance of multilingual considerations for both training and tuning LLMs in order to improve their reliability and fairness in downstream use.

</details>


### [253] [EternalMath: A Living Benchmark of Frontier Mathematics that Evolves with Human Discovery](https://arxiv.org/abs/2601.01400)
*Jicheng Ma,Guohua Wang,Xinhua Feng,Yiming Liu,Zhichao Hu,Yuhong Liu*

Main category: cs.CL

TL;DR: 提出自动化定理验证评估框架EternalMath，将前沿数学论文转化为可执行验证任务，揭示大语言模型在数学推理上的显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理评估依赖静态基准，覆盖范围有限且性能易饱和，无法跟上数学研究前沿发展，需要动态可扩展的评估方法。

Method: 设计全自动定理验证流程：从近期数学论文中识别构造性/量化结果，参数化为问题模板，通过执行验证生成确定性解决方案，构建可扩展、可复现的评估套件。

Result: 应用该流程创建EternalMath评估集，实验显示当前最先进大语言模型存在显著性能差距，表明研究级数学推理远未饱和。

Conclusion: 数学推理评估需要与人类数学发现同步演进，自动化定理验证方法能提供持续更新、可验证的评估框架，推动数学推理能力发展。

Abstract: Current evaluations of mathematical reasoning in large language models (LLMs) are dominated by static benchmarks, either derived from competition-style problems or curated through costly expert effort, resulting in limited coverage of research-level mathematics and rapid performance saturation. We propose a fully automated, theorem-grounded pipeline for evaluating frontier mathematical reasoning, which directly transforms recent peer-reviewed mathematical literature into executable and verifiable reasoning tasks. The pipeline identifies constructive or quantitative results, instantiates them into parameterized problem templates, and generates deterministic solutions through execution-based verification, enabling scalable, reproducible, and continuously updatable evaluation without reliance on large-scale expert authoring. By design, this approach supports temporal extensibility, intrinsic correctness checking, and domain-specific customization across mathematical subfields. Applying this pipeline yields \textbf{EternalMath}, an evolving evaluation suite derived from contemporary research papers. Experiments with state-of-the-art LLMs reveal substantial performance gaps, indicating that mathematical reasoning at the research frontier remains far from saturated and underscoring the need for evaluation methodologies that evolve in step with human mathematical discovery.

</details>


### [254] [LANCET: Neural Intervention via Structural Entropy for Mitigating Faithfulness Hallucinations in LLMs](https://arxiv.org/abs/2601.01401)
*Chenxu Wang,Chaozhuo Li,Pengbo Wang,Litian Zhang,Songyang Liu,Ji Qi,Jiahui Hu,Yushan Cai,Hao Zhao,Rui Pu*

Main category: cs.CL

TL;DR: 提出Lancet框架，通过结构熵和幻觉差异比实现精确神经干预，显著降低大语言模型的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在严重的忠实性幻觉问题，现有方法通常忽视神经信息的分布式特性，导致干预不精确。研究者认识到幻觉像感染一样通过特定前向传播路径扩散，需要精确阻断这一传播流

Method: 1. 通过梯度驱动的对比分析定位易产生幻觉的神经元；2. 通过最小化结构熵映射其传播路径；3. 实施分层干预策略以保持模型通用能力

Result: 在多个幻觉基准数据集上的综合评估表明，Lancet显著优于现有最先进方法

Conclusion: 基于结构分析的神经外科式干预方法能有效缓解大语言模型的幻觉问题，验证了精确神经干预策略的有效性

Abstract: Large Language Models have revolutionized information processing, yet their reliability is severely compromised by faithfulness hallucinations. While current approaches attempt to mitigate this issue through node-level adjustments or coarse suppression, they often overlook the distributed nature of neural information, leading to imprecise interventions. Recognizing that hallucinations propagate through specific forward transmission pathways like an infection, we aim to surgically block this flow using precise structural analysis. To leverage this, we propose Lancet, a novel framework that achieves precise neural intervention by leveraging structural entropy and hallucination difference ratios. Lancet first locates hallucination-prone neurons via gradient-driven contrastive analysis, then maps their propagation pathways by minimizing structural entropy, and finally implements a hierarchical intervention strategy that preserves general model capabilities. Comprehensive evaluations across hallucination benchmark datasets demonstrate that Lancet significantly outperforms state-of-the-art methods, validating the effectiveness of our surgical approach to neural intervention.

</details>


### [255] [From Emotion Classification to Emotional Reasoning: Enhancing Emotional Intelligence in Large Language Models](https://arxiv.org/abs/2601.01407)
*Arjhun Sreedar,Rohan Pillay,Laukik Patade*

Main category: cs.CL

TL;DR: 研究探讨使用合成情感链式思维数据提升小型开源大语言模型的情感推理能力，通过多智能体生成治疗式对话并转化为结构化情感选择题，微调7B模型在情感理解与意识评估上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前小型开源LLMs在情感推理任务上表现有限，需要探索无需架构修改即可提升情感能力的方法，利用合成数据可能是一种高效途径。

Method: 设计多智能体生成管道，创建治疗式对话并转化为带解释的情感多选题数据集，对多种7B模型进行微调，使用EmoBench风格评估情感理解与意识。

Result: 微调后的Mistral 7B模型在情感理解得分从10.5提升至20.5，情感意识得分从40.5提升至60.0，验证了合成情感推理数据的有效性。

Conclusion: 合成情感链式思维数据能显著增强小型LLMs的情感推理能力，表明情感能力可通过数据驱动方式诱导，无需改变模型架构。

Abstract: This work investigates whether synthetic emotional chain-of-thought data can improve the emotional reasoning abilities of smaller open large language models (LLMs). We design a multi-agent generation pipeline that produces therapy-style conversations and converts them into structured emotion multiple-choice questions (MCQs) with explanations. We propose that fine-tuning a variety of 7B models on this dataset should yield substantial gains in emotional understanding and emotional awareness on EmoBench-style evaluations, suggesting that emotional reasoning can be induced without architectural changes. Our results demonstrate that fine-tuned Mistral 7B achieves EU improvements from 10.5 to 20.5 and EA improvements from 40.5 to 60.0, validating the effectiveness of synthetic emotional reasoning data for enhancing model capabilities in nuanced emotional tasks.

</details>


### [256] [iFlip: Iterative Feedback-driven Counterfactual Example Refinement](https://arxiv.org/abs/2601.01446)
*Yilong Wang,Qianli Wang,Nils Feldhus*

Main category: cs.CL

TL;DR: 提出iFlip方法，通过迭代反馈提升大语言模型生成反事实示例的有效性，显著优于现有方法并增强数据增强效果。


<details>
  <summary>Details</summary>
Motivation: 现有单次生成方法在利用大语言模型生成反事实示例时，常无法可靠改变预测标签，且未充分利用模型的自校正能力。

Method: iFlip采用迭代优化策略，结合模型置信度、特征归因和自然语言三种反馈类型，通过多轮调整生成反事实示例。

Result: iFlip在标签翻转率上比五种先进基线平均提升57.8%的有效性，用户研究在完整性、满意度和可行性方面均优于基线，消融实验验证了迭代次数、高归因词指向和早停机制的关键作用。

Conclusion: iFlip能高效生成有效反事实示例，其生成结果可用于数据增强，显著提升模型性能和鲁棒性。

Abstract: Counterfactual examples are minimal edits to an input that alter a model's prediction. They are widely employed in explainable AI to probe model behavior and in natural language processing (NLP) to augment training data. However, generating valid counterfactuals with large language models (LLMs) remains challenging, as existing single-pass methods often fail to induce reliable label changes, neglecting LLMs' self-correction capabilities. To explore this untapped potential, we propose iFlip, an iterative refinement approach that leverages three types of feedback, including model confidence, feature attribution, and natural language. Our results show that iFlip achieves an average 57.8% higher validity than the five state-of-the-art baselines, as measured by the label flipping rate. The user study further corroborates that iFlip outperforms baselines in completeness, overall satisfaction, and feasibility. In addition, ablation studies demonstrate that three components are paramount for iFlip to generate valid counterfactuals: leveraging an appropriate number of iterations, pointing to highly attributed words, and early stopping. Finally, counterfactuals generated by iFlip enable effective counterfactual data augmentation, substantially improving model performance and robustness.

</details>


### [257] [Segmentation and Processing of German Court Decisions from Open Legal Data](https://arxiv.org/abs/2601.01449)
*Harshil Darji,Martin Heckelmann,Christina Kratsch,Gerard de Melo*

Main category: cs.CL

TL;DR: 本文介绍了一个经过清洗和分节的德国法院判决数据集，包含251,038个案例，系统分离了判决书中的三个核心部分，并进行了统计验证。


<details>
  <summary>Details</summary>
Motivation: 德国法律系统中的结构化数据对自然语言处理研究至关重要。现有的Open Legal Data数据集虽然规模大，但判决文本格式不一致，缺乏清晰的分节标记，这影响了修辞角色分类、检索和引用分析等下游任务。

Method: 从Open Legal Data数据集中提取并清洗了251,038个德国法院判决；系统分离了判决书的三个核心部分：Tenor（判决主文）、Tatbestand（案件事实）和Entscheidungsgründe（判决理由）；使用Cochran公式以95%置信水平和5%误差范围抽取了384个案例的统计代表性样本进行人工验证；将Rechtsmittelbelehrung（上诉告知）作为独立字段提取。

Result: 创建了一个公开可用的清洗和分节数据集，格式为JSONL；统计验证表明三个核心部分的识别准确率可靠；数据集为德国法律系统的进一步研究提供了可访问资源。

Conclusion: 该工作提供了一个高质量、结构化的德国法院判决数据集，解决了原始数据格式不一致的问题，为法律自然语言处理研究提供了可靠的基础资源。

Abstract: The availability of structured legal data is important for advancing Natural Language Processing (NLP) techniques for the German legal system. One of the most widely used datasets, Open Legal Data, provides a large-scale collection of German court decisions. While the metadata in this raw dataset is consistently structured, the decision texts themselves are inconsistently formatted and often lack clearly marked sections. Reliable separation of these sections is important not only for rhetorical role classification but also for downstream tasks such as retrieval and citation analysis. In this work, we introduce a cleaned and sectioned dataset of 251,038 German court decisions derived from the official Open Legal Data dataset. We systematically separated three important sections in German court decisions, namely Tenor (operative part of the decision), Tatbestand (facts of the case), and Entscheidungsgründe (judicial reasoning), which are often inconsistently represented in the original dataset. To ensure the reliability of our extraction process, we used Cochran's formula with a 95% confidence level and a 5% margin of error to draw a statistically representative random sample of 384 cases, and manually verified that all three sections were correctly identified. We also extracted the Rechtsmittelbelehrung (appeal notice) as a separate field, since it is a procedural instruction and not part of the decision itself. The resulting corpus is publicly available in the JSONL format, making it an accessible resource for further research on the German legal system.

</details>


### [258] [Bridging the gap: A comparative exploration of Speech-LLM and end-to-end architecture for multilingual conversational ASR](https://arxiv.org/abs/2601.01461)
*Yuxiang Mei,Dongxing Xu,Jiaen Liang,Yanhua Long*

Main category: cs.CL

TL;DR: 本文提出了一种增强的基于LLM的ASR框架，通过交叉注意力融合机制结合微调的Whisper和mHuBERT编码器，在MLC-SLM挑战中取得与顶级系统相当的性能，但发现其仍不及微调的端到端Whisper模型。


<details>
  <summary>Details</summary>
Motivation: 解决先前SHNU-mASR系统中简单特征拼接未能充分利用互补信息的问题，并探索LLM-based ASR与端到端编码器-解码器ASR之间的性能差距。

Method: 1. 使用LoRA和全微调评估端到端Whisper模型；2. 提出基于交叉注意力的并行语音编码器融合机制，结合微调的Whisper和mHuBERT编码器与LLM。

Result: 在MLC-SLM挑战官方评估集上，系统CER/WER达到10.69%，与使用大规模训练数据的顶级Track 1系统性能相当，但最终LLM-based ASR仍不及微调的端到端Whisper模型。

Conclusion: 基于LLM的ASR框架虽能取得竞争性结果，但在当前设定下性能仍落后于端到端ASR模型，这为未来语音-LLM设计提供了重要实证参考。

Abstract: The INTERSPEECH 2025 Challenge on Multilingual Conversational Speech Language Models (MLC-SLM) promotes multilingual conversational ASR with large language models (LLMs). Our previous SHNU-mASR system adopted a competitive parallel-speech-encoder architecture that integrated Whisper and mHuBERT with an LLM. However, it faced two challenges: simple feature concatenation may not fully exploit complementary information, and the performance gap between LLM-based ASR and end-to-end(E2E) encoder-decoder ASR remained unexplored. In this work, we present an enhanced LLM-based ASR framework that combines fine-tuned Whisper and mHuBERT encoders with an LLM to enrich speech representations. We first evaluate E2E Whisper models with LoRA and full fine-tuning on the MLC-SLM ASR task, and then propose cross-attention-based fusion mechanisms for the parallel-speech-encoder. On the official evaluation set of the MLC-SLM Challenge, our system achieves a CER/WER of 10.69%, ranking on par with the top-ranked Track 1 systems, even though it uses only 1,500 hours of baseline training data compared with their large-scale training sets. Nonetheless, we find that our final LLM-based ASR still does not match the performance of a fine-tuned E2E Whisper model, providing valuable empirical guidance for future Speech-LLM design. Our code is publicly available at https://github.com/1535176727/MLC-SLM.

</details>


### [259] [Can Legislation Be Made Machine-Readable in PROLEG?](https://arxiv.org/abs/2601.01477)
*May-Myo Zin,Sabine Wehnert,Yuntao Kong,Ha-Thanh Nguyen,Wachara Fungwacharakorn,Jieying Xue,Michał Araszkiewicz,Randy Goebel,Ken Satoh,Le-Minh Nguyen*

Main category: cs.CL

TL;DR: 提出一个结合大语言模型和PROLEG法律表示系统的框架，将GDPR等法规文本自动转换为可执行的逻辑规则，并生成人类可读的解释。


<details>
  <summary>Details</summary>
Motivation: 法规应用需要准确性和效率，而现有AI技术（如自然语言处理和机器辅助推理）有望解决这一挑战，但需要系统化方法将法律文本转化为可执行逻辑。

Method: 使用LLM提示将法律文本（以GDPR第6条为例）同时转换为if-then规则和PROLEG编码，经法律专家验证和优化后生成可执行的PROLEG程序，支持端到端转换和解释生成。

Result: 成功实现从GDPR条款到PROLEG可执行程序的转换框架，能够自动生成人类可读的法规决策解释实例。

Conclusion: 该方法为法规的捕获和部署提供了有价值的技术路径，但存在局限性，需进一步开发以完善此类技术。

Abstract: The anticipated positive social impact of regulatory processes requires both the accuracy and efficiency of their application. Modern artificial intelligence technologies, including natural language processing and machine-assisted reasoning, hold great promise for addressing this challenge. We present a framework to address the challenge of tools for regulatory application, based on current state-of-the-art (SOTA) methods for natural language processing (large language models or LLMs) and formalization of legal reasoning (the legal representation system PROLEG). As an example, we focus on Article 6 of the European General Data Protection Regulation (GDPR). In our framework, a single LLM prompt simultaneously transforms legal text into if-then rules and a corresponding PROLEG encoding, which are then validated and refined by legal domain experts. The final output is an executable PROLEG program that can produce human-readable explanations for instances of GDPR decisions. We describe processes to support the end-to-end transformation of a segment of a regulatory document (Article 6 from GDPR), including the prompting frame to guide an LLM to "compile" natural language text to if-then rules, then to further "compile" the vetted if-then rules to PROLEG. Finally, we produce an instance that shows the PROLEG execution. We conclude by summarizing the value of this approach and note observed limitations with suggestions to further develop such technologies for capturing and deploying regulatory frameworks.

</details>


### [260] [Four Quadrants of Difficulty: A Simple Categorisation and its Limits](https://arxiv.org/abs/2601.01488)
*Vanessa Toborek,Sebastian Müller,Christian Bauckhage*

Main category: cs.CL

TL;DR: 本文对课程学习中样本难度估计方法进行了系统分类与分析，发现任务无关特征与模型学习行为不相关，只有任务相关特征能有效反映模型学习难度。


<details>
  <summary>Details</summary>
Motivation: 当前NLP课程学习中普遍使用任务无关的语言学启发式方法或人类直觉来估计样本难度，但这种方法隐含假设这些信号与神经网络模型实际学习难度相关，缺乏实证验证。

Method: 提出了基于四个象限（人类vs模型、任务无关vs任务相关）的难度信号分类框架，在自然语言理解数据集上系统分析了这些信号之间的相互作用。

Result: 研究发现任务无关特征在很大程度上独立于模型学习行为，只有任务相关特征与模型学习难度对齐，挑战了课程学习中常见的直觉假设。

Conclusion: 需要开发轻量级的任务相关难度估计器，以更好地反映模型学习行为，提高课程学习效果。

Abstract: Curriculum Learning (CL) aims to improve the outcome of model training by estimating the difficulty of samples and scheduling them accordingly. In NLP, difficulty is commonly approximated using task-agnostic linguistic heuristics or human intuition, implicitly assuming that these signals correlate with what neural models find difficult to learn. We propose a four-quadrant categorisation of difficulty signals -- human vs. model and task-agnostic vs. task-dependent -- and systematically analyse their interactions on a natural language understanding dataset. We find that task-agnostic features behave largely independently and that only task-dependent features align. These findings challenge common CL intuitions and highlight the need for lightweight, task-dependent difficulty estimators that better reflect model learning behaviour.

</details>


### [261] [Distortion Instead of Hallucination: The Effect of Reasoning Under Strict Constraints](https://arxiv.org/abs/2601.01490)
*Junichiro Niimi*

Main category: cs.CL

TL;DR: 研究发现，在严格约束下，大语言模型的推理能力会引发约束合规性与事实准确性之间的权衡：非推理模型违反约束较多但保持事实准确，而推理模型减少约束违反却会系统性地扭曲已知事实并增加虚构内容。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，幻觉问题（模型输出中的非事实虚构）引发严重担忧。推理能力被视为提升输出可靠性的自我验证过程，但其在无法依赖外部工具或知识的封闭系统中的效果尚不明确。

Method: 在严格约束条件下（推荐计算机科学领域的同行评审期刊文章），对多个模型（GPT-5.2和Gemini 3 Flash）进行实验，比较推理与非推理模式下的表现，分析约束违反率与事实准确性之间的关系。

Result: 非推理模型约束违反率高（66-75%）但事实准确性保持较好；推理模型显著降低约束违反（13-26%），但会系统性地扭曲已知事实以满足约束，并增加完全虚构的内容。这种权衡模式在不同架构的模型中均一致出现。

Conclusion: 推理能力并不普遍提升输出真实性：不同模型在合规性与真实性之间的权衡分配存在差异。研究挑战了“推理能普遍提升可靠性”的假设，指出推理模型会以难以检测的扭曲为代价换取约束合规。

Abstract: With the widespread adoption of large language models (LLMs), hallucinations, which are non-factual fabrications in model outputs, have become serious concerns. Reasoning capabilities have received attention as a self-verification process to improve output reliability. However, the effect of reasoning within a closed system where LLMs cannot rely on external tools or knowledge has yet to be clarified. We therefore conduct experiments under strict constraints (recommending peer-reviewed journal articles in computer science) to examine the effect of reasoning across multiple models (GPT-5.2 and Gemini 3 Flash). Our results reveal a problematic trade-off between constraint compliance and factual accuracy. Non-reasoning models exhibit high constraint violation rates (66-75%) but maintain factual accuracy, while reasoning models reduce violations (13-26%) but systematically distort known facts to satisfy constraints and increase complete fabrication. This trade-off pattern is consistent across both models despite different architectures, indicating a fundamental limitation of reasoning. Furthermore, reasoning does not uniformly improve output authenticity: effects diverge by model, reflecting different allocations of the compliance-truthfulness trade-off. These findings challenge the assumption that reasoning universally improves reliability: reasoning models trade honest constraint violations for detection-resistant distortions.

</details>


### [262] [From Failure to Mastery: Generating Hard Samples for Tool-use Agents](https://arxiv.org/abs/2601.01498)
*Bingguang Hao,Zengzhuang Xu,Yuntao Wen,Xinyi Xu,Yang Liu,Tong Zhao,Maolin Wang,Long Chen,Dong Wang,Yicheng Chen,Cunyin Peng,Xiangyu Zhao,Chenyi Zhuang,Ji Zhang*

Main category: cs.CL

TL;DR: 本文提出HardGen方法，通过动态API图、高级工具实例化和闭环评估反馈，自动生成具有可验证推理的困难工具使用训练样本，显著提升小模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体工具使用训练数据生成方法多采用随机采样和浅层生成范式，产生的轨迹简单同质，难以捕捉复杂隐式逻辑依赖，需要更有效的困难样本生成方法。

Method: HardGen自动代理流程：1)基于智能体失败案例构建动态API图并采样合成困难轨迹；2)以轨迹为条件先验指导模块化抽象高级工具的实例化，生成困难查询；3)利用高级工具和困难查询生成可验证复杂思维链，通过闭环评估反馈持续优化过程。

Result: 实验表明，使用该方法生成的数据训练的4B参数模型，性能优于多个领先的开源和闭源竞争对手（如GPT-5.2、Gemini-3-Pro和Claude-Opus-4.5）。

Conclusion: HardGen能有效生成具有复杂逻辑依赖的困难工具使用训练样本，显著提升小规模模型在工具使用任务上的性能，相关代码、模型和数据集将开源以促进未来研究。

Abstract: The advancement of LLM agents with tool-use capabilities requires diverse and complex training corpora. Existing data generation methods, which predominantly follow a paradigm of random sampling and shallow generation, often yield simple and homogeneous trajectories that fail to capture complex, implicit logical dependencies. To bridge this gap, we introduce HardGen, an automatic agentic pipeline designed to generate hard tool-use training samples with verifiable reasoning. Firstly, HardGen establishes a dynamic API Graph built upon agent failure cases, from which it samples to synthesize hard traces. Secondly, these traces serve as conditional priors to guide the instantiation of modular, abstract advanced tools, which are subsequently leveraged to formulate hard queries. Finally, the advanced tools and hard queries enable the generation of verifiable complex Chain-of-Thought (CoT), with a closed-loop evaluation feedback steering the continuous refinement of the process. Extensive evaluations demonstrate that a 4B parameter model trained with our curated dataset achieves superior performance compared to several leading open-source and closed-source competitors (e.g., GPT-5.2, Gemini-3-Pro and Claude-Opus-4.5). Our code, models, and dataset will be open-sourced to facilitate future research.

</details>


### [263] [EmoHarbor: Evaluating Personalized Emotional Support by Simulating the User's Internal World](https://arxiv.org/abs/2601.01530)
*Jing Ye,Lu Xiang,Yaping Zhang,Chengqing Zong*

Main category: cs.CL

TL;DR: 提出了EmoHarbor评估框架，通过模拟用户内心世界来评估情感支持对话的个性化程度，发现当前LLM虽能生成共情回应但缺乏个性化适配能力。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话评估方法倾向于奖励通用共情回应，但无法评估支持是否真正适应用户独特的心理特征和情境需求，需要更精准的个性化评估框架。

Method: 采用User-as-a-Judge范式，设计Chain-of-Agent架构将用户内部过程分解为三个专业角色，基于100个真实用户档案和10个评估维度构建基准测试。

Result: 对20个先进LLM的评估显示，这些模型虽擅长生成共情回应，但持续无法根据个体用户情境定制支持，揭示了当前技术的核心局限。

Conclusion: 研究将挑战重心从提升通用共情转向开发真正用户感知的情感支持系统，EmoHarbor为开发更细致、用户感知的支持系统提供了可复现、可扩展的评估框架。

Abstract: Current evaluation paradigms for emotional support conversations tend to reward generic empathetic responses, yet they fail to assess whether the support is genuinely personalized to users' unique psychological profiles and contextual needs. We introduce EmoHarbor, an automated evaluation framework that adopts a User-as-a-Judge paradigm by simulating the user's inner world. EmoHarbor employs a Chain-of-Agent architecture that decomposes users' internal processes into three specialized roles, enabling agents to interact with supporters and complete assessments in a manner similar to human users. We instantiate this benchmark using 100 real-world user profiles that cover a diverse range of personality traits and situations, and define 10 evaluation dimensions of personalized support quality. Comprehensive evaluation of 20 advanced LLMs on EmoHarbor reveals a critical insight: while these models excel at generating empathetic responses, they consistently fail to tailor support to individual user contexts. This finding reframes the central challenge, shifting research focus from merely enhancing generic empathy to developing truly user-aware emotional support. EmoHarbor provides a reproducible and scalable framework to guide the development and evaluation of more nuanced and user-aware emotional support systems.

</details>


### [264] [Bridging the Data Gap: Creating a Hindi Text Summarization Dataset from the English XSUM](https://arxiv.org/abs/2601.01543)
*Praveenkumar Katwe,RakeshChandra Balabantaray,Kaliprasad Vittala*

Main category: cs.CL

TL;DR: 提出了一种自动化框架，利用英文XSUM数据集通过翻译和语言适应技术构建印地语文本摘要数据集，以解决印地语等低资源语言缺乏高质量摘要数据的问题。


<details>
  <summary>Details</summary>
Motivation: 当前自然语言处理进展主要集中于资源丰富的语言，印地语等低资源语言缺乏高质量的文本摘要数据集，阻碍了稳健模型的发展。

Method: 以英文XSUM数据集为源，采用先进的翻译和语言适应技术，使用COMET进行翻译质量验证，并选择性利用大语言模型进行数据筛选。

Result: 创建了一个多样化、多主题的印地语文本摘要数据集，该数据集保持了原始XSUM语料库的复杂性，为印地语NLP研究提供了直接工具。

Conclusion: 该工作不仅为印地语NLP提供了资源，还提供了一种可扩展的方法论，能够降低数据集创建成本，促进计算语言学中更细致、文化相关模型的发展。

Abstract: Current advancements in Natural Language Processing (NLP) have largely favored resource-rich languages, leaving a significant gap in high-quality datasets for low-resource languages like Hindi. This scarcity is particularly evident in text summarization, where the development of robust models is hindered by a lack of diverse, specialized corpora.
  To address this disparity, this study introduces a cost-effective, automated framework for creating a comprehensive Hindi text summarization dataset. By leveraging the English Extreme Summarization (XSUM) dataset as a source, we employ advanced translation and linguistic adaptation techniques. To ensure high fidelity and contextual relevance, we utilize the Crosslingual Optimized Metric for Evaluation of Translation (COMET) for validation, supplemented by the selective use of Large Language Models (LLMs) for curation.
  The resulting dataset provides a diverse, multi-thematic resource that mirrors the complexity of the original XSUM corpus. This initiative not only provides a direct tool for Hindi NLP research but also offers a scalable methodology for democratizing NLP in other underserved languages. By reducing the costs associated with dataset creation, this work fosters the development of more nuanced, culturally relevant models in computational linguistics.

</details>


### [265] [HalluZig: Hallucination Detection using Zigzag Persistence](https://arxiv.org/abs/2601.01552)
*Shreyas N. Samaga,Gilberto Gonzalez Arroyo,Tamal K. Dey*

Main category: cs.CL

TL;DR: 本文提出了一种基于拓扑数据分析的幻觉检测新方法HalluZig，通过分析大语言模型层间注意力的动态拓扑结构来区分事实性生成与幻觉生成，在多个基准测试中优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在关键领域应用时，其事实可靠性因幻觉问题受到限制。现有检测方法多依赖模型输出的表层信号，忽视了模型内部推理过程中的故障，因此需要更深入分析模型内部机制的方法。

Method: 提出HalluZig框架，将模型各层的注意力矩阵序列建模为zigzag图过滤，利用拓扑数据分析中的zigzag持续性工具提取拓扑特征，假设事实性生成与幻觉生成具有不同的拓扑特征。

Result: 在多个基准测试中验证了HalluZiz优于强基线方法；分析表明这些拓扑特征在不同模型间具有可泛化性，且仅使用部分网络深度的结构特征即可实现幻觉检测。

Conclusion: 通过分析大语言模型内部注意力演化的拓扑结构，可以有效检测幻觉，为理解模型内部推理过程提供了新的视角，且该方法具有跨模型泛化能力和计算效率优势。

Abstract: The factual reliability of Large Language Models (LLMs) remains a critical barrier to their adoption in high-stakes domains due to their propensity to hallucinate. Current detection methods often rely on surface-level signals from the model's output, overlooking the failures that occur within the model's internal reasoning process. In this paper, we introduce a new paradigm for hallucination detection by analyzing the dynamic topology of the evolution of model's layer-wise attention. We model the sequence of attention matrices as a zigzag graph filtration and use zigzag persistence, a tool from Topological Data Analysis, to extract a topological signature. Our core hypothesis is that factual and hallucinated generations exhibit distinct topological signatures. We validate our framework, HalluZig, on multiple benchmarks, demonstrating that it outperforms strong baselines. Furthermore, our analysis reveals that these topological signatures are generalizable across different models and hallucination detection is possible only using structural signatures from partial network depth.

</details>


### [266] [Steerability of Instrumental-Convergence Tendencies in LLMs](https://arxiv.org/abs/2601.01584)
*Jakub Hoscilowicz*

Main category: cs.CL

TL;DR: 本文探讨了AI系统的能力与可操控性之间的关系，发现高能力并不必然导致低可操控性，并区分了授权与非授权可操控性，揭示了开放权重模型面临的安全-安全困境。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解AI系统的能力与可操控性之间的相互作用，特别是针对开放权重模型，如何平衡安全控制与防止恶意行为之间的张力。

Method: 使用Qwen3模型（4B/30B；基础/指导/思考版本）和InstrumentalEval工具，通过设计亲工具性和反工具性提示后缀，测试模型在工具性收敛行为（如关机回避、欺骗、自我复制）上的表现。

Result: 实验显示，反工具性提示后缀显著降低了工具性收敛行为的输出（例如，Qwen3-30B指导模型从81.69%降至2.82%）。在反工具性提示下，更大、更对齐的模型产生的收敛行为输出更少。

Conclusion: 研究结论指出，开放权重模型目前具有较高的可操控性，这导致了安全控制与防止恶意行为之间的根本性张力。反工具性提示可以有效减少有害行为，但需要进一步研究来平衡安全与安全需求。

Abstract: We examine two properties of AI systems: capability (what a system can do) and steerability (how reliably one can shift behavior toward intended outcomes). In our experiments, higher capability does not imply lower steerability. We distinguish between authorized steerability (builders reliably reaching intended behaviors) and unauthorized steerability (attackers eliciting disallowed behaviors). This distinction highlights a fundamental safety--security dilemma for open-weight AI models: safety requires high steerability to enforce control (e.g., stop/refuse), while security requires low steerability to prevent malicious actors from eliciting harmful behaviors. This tension is acute for open-weight models, which are currently highly steerable via common techniques such as fine-tuning and adversarial prompting. Using Qwen3 models (4B/30B; Base/Instruct/Thinking) and InstrumentalEval, we find that a short anti-instrumental prompt suffix sharply reduces outputs labeled as instrumental convergence (e.g., shutdown avoidance, deception, self-replication). For Qwen3-30B Instruct, convergence drops from 81.69% under a pro-instrumental suffix to 2.82% under an anti-instrumental suffix. Under anti-instrumental prompting, larger aligned models produce fewer convergence-labeled outputs than smaller ones (Instruct: 2.82% vs. 4.23%; Thinking: 4.23% vs. 9.86%). Code is available at github.com/j-hoscilowicz/instrumental_steering.

</details>


### [267] [How Does Prefix Matter in Reasoning Model Tuning?](https://arxiv.org/abs/2601.01624)
*Raj Vardhan Tomar,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 本文挑战了移除SFT数据集中前缀短语的常见做法，发现安全性和推理导向的前缀句子可作为轻量级对齐信号，提升模型的安全性和推理能力，但对事实性和编码任务效果有限。


<details>
  <summary>Details</summary>
Motivation: 当前对齐研究通常从SFT数据集中移除引言性模板短语，但作者假设这些安全性和推理导向的前缀句子可作为轻量级对齐信号，引导模型生成更安全和连贯的响应。

Method: 在三个R1系列模型上进行了微调，覆盖推理（数学、编码）、安全性和事实性三个核心能力，系统性地将前缀包含比例从0%变化到100%，并进行了令牌级损失分析。

Result: 前缀条件化SFT提高了安全性和推理性能：在对抗性基准（WildJailbreak、StrongReject）上安全@1准确率最高提升+6%，GSM8K推理提升+7%；但事实性和编码任务仅显示边际或负面效果；令牌级分析显示“revised”和“logically”等前缀令牌具有更高的梯度幅度，充当对齐锚点稳定推理轨迹。

Conclusion: 前缀条件化为提升推理安全性提供了可扩展且可解释的机制，可作为传统基于奖励方法的补充，是一种隐式的对齐形式。

Abstract: Recent alignment studies commonly remove introductory boilerplate phrases from supervised fine-tuning (SFT) datasets. This work challenges that assumption. We hypothesize that safety- and reasoning-oriented prefix sentences serve as lightweight alignment signals that can guide model decoding toward safer and more coherent responses. To examine this, we fine-tune three R1 series models across three core model capabilities: reasoning (mathematics, coding), safety, and factuality, systematically varying prefix inclusion from 0% to 100%.
  Results show that prefix-conditioned SFT improves both safety and reasoning performance, yielding up to +6% higher Safe@1 accuracy on adversarial benchmarks (WildJailbreak, StrongReject) and +7% improvement on GSM8K reasoning. However, factuality and coding tasks show marginal or negative effects, indicating that prefix-induced narrowing of the search space benefits structured reasoning. Token-level loss analysis further reveals that prefix tokens such as "revised" and "logically" incur higher gradient magnitudes, acting as alignment anchors that stabilize reasoning trajectories. Our findings suggest that prefix conditioning offers a scalable and interpretable mechanism for improving reasoning safety, serving as an implicit form of alignment that complements traditional reward-based methods.

</details>


### [268] [JMedEthicBench: A Multi-Turn Conversational Benchmark for Evaluating Medical Safety in Japanese Large Language Models](https://arxiv.org/abs/2601.01627)
*Junyu Liu,Zirui Li,Qian Niu,Zequn Zhang,Yue Xun,Wenlong Hou,Shujun Wang,Yusuke Iwasawa,Yutaka Matsuo,Kan Hatakeyama-Sato*

Main category: cs.CL

TL;DR: 本文介绍了JMedEthicBench，首个用于评估日语医疗大模型安全性的多轮对话基准，发现专业医疗模型安全性更脆弱，且多轮对话会显著降低安全性评分。


<details>
  <summary>Details</summary>
Motivation: 现有医疗安全评估基准主要针对英语且多为单轮测试，无法反映真实多轮临床咨询场景，且缺乏对日语等非英语语言的支持。

Method: 基于日本医师协会67项指南构建基准，采用7种自动发现的越狱策略生成超5万对抗性对话，使用双LLM评分协议评估27个模型。

Result: 商业模型安全性较强，医疗专用模型更易受攻击；多轮对话中安全性评分显著下降（中位数9.5→5.0）；跨语言评估显示医疗模型漏洞具有语言无关性。

Conclusion: 领域专用微调可能意外削弱安全机制，多轮交互构成独特威胁面，需要专门的对齐策略；模型漏洞源于内在对齐限制而非语言因素。

Abstract: As Large Language Models (LLMs) are increasingly deployed in healthcare field, it becomes essential to carefully evaluate their medical safety before clinical use. However, existing safety benchmarks remain predominantly English-centric, and test with only single-turn prompts despite multi-turn clinical consultations. To address these gaps, we introduce JMedEthicBench, the first multi-turn conversational benchmark for evaluating medical safety of LLMs for Japanese healthcare. Our benchmark is based on 67 guidelines from the Japan Medical Association and contains over 50,000 adversarial conversations generated using seven automatically discovered jailbreak strategies. Using a dual-LLM scoring protocol, we evaluate 27 models and find that commercial models maintain robust safety while medical-specialized models exhibit increased vulnerability. Furthermore, safety scores decline significantly across conversation turns (median: 9.5 to 5.0, $p < 0.001$). Cross-lingual evaluation on both Japanese and English versions of our benchmark reveals that medical model vulnerabilities persist across languages, indicating inherent alignment limitations rather than language-specific factors. These findings suggest that domain-specific fine-tuning may accidentally weaken safety mechanisms and that multi-turn interactions represent a distinct threat surface requiring dedicated alignment strategies.

</details>


### [269] [EHRSummarizer: A Privacy-Aware, FHIR-Native Architecture for Structured Clinical Summarization of Electronic Health Records](https://arxiv.org/abs/2601.01668)
*Houman Kazemzadeh,Nima Minaifar,Kamyar Naderi,Sho Tabibzadeh*

Main category: cs.CL

TL;DR: 提出EHRSummarizer，一个基于FHIR的隐私感知参考架构，用于从碎片化电子健康记录中生成结构化临床摘要，支持图表审查，避免诊断或治疗建议。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要从碎片化的电子健康记录界面中整合患者信息，现有系统缺乏能生成结构化摘要且注重隐私保护的标准化架构。

Method: 设计FHIR-native架构，检索FHIR R4资源，归一化为临床上下文包，生成结构化摘要；支持数据最小化、无状态处理和本地推理；摘要仅基于检索到的证据，避免推断。

Result: 原型在合成和测试FHIR环境中演示了端到端行为和输出格式，但未报告临床结果或受控工作流研究。

Conclusion: EHRSummarizer为临床摘要提供了可配置、隐私感知的参考架构，未来评估将聚焦于忠实性、遗漏风险、时间正确性、可用性和操作监控。

Abstract: Clinicians routinely navigate fragmented electronic health record (EHR) interfaces to assemble a coherent picture of a patient's problems, medications, recent encounters, and longitudinal trends. This work describes EHRSummarizer, a privacy-aware, FHIR-native reference architecture that retrieves a targeted set of high-yield FHIR R4 resources, normalizes them into a consistent clinical context package, and produces structured summaries intended to support structured chart review. The system can be configured for data minimization, stateless processing, and flexible deployment, including local inference within an organization's trust boundary. To mitigate the risk of unsupported or unsafe behavior, the summarization stage is constrained to evidence present in the retrieved context package, is intended to indicate missing or unavailable domains where feasible, and avoids diagnostic or treatment recommendations. Prototype demonstrations on synthetic and test FHIR environments illustrate end-to-end behavior and output formats; however, this manuscript does not report clinical outcomes or controlled workflow studies. We outline an evaluation plan centered on faithfulness, omission risk, temporal correctness, usability, and operational monitoring to guide future institutional assessments.

</details>


### [270] [Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage](https://arxiv.org/abs/2601.01685)
*Jinwei Hu,Xinmiao Huang,Youcheng Sun,Yi Dong,Xiaowei Huang*

Main category: cs.CL

TL;DR: 本文提出了一种新型认知合谋攻击，利用大语言模型（LLM）的过度思考倾向，通过仅发布真实证据片段引导受害者得出虚假结论，揭示了LLM智能体在动态信息环境中的社会技术脆弱性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型向自主智能体演进，其推理能力可能成为新的攻击面。现有攻击多依赖隐蔽通信、后门或伪造文档，而本研究探索仅通过公开渠道分发真实证据片段即可实施的认知操纵风险。

Method: 提出生成蒙太奇框架（Writer-Editor-Director），通过对抗性辩论和证据片段协调发布构建欺骗性叙事；创建CoPHEME数据集（基于真实谣言事件）；在14个LLM家族中模拟攻击并评估成功率。

Result: 攻击在专有模型和开源模型中成功率分别达74.4%和70.6%；推理能力越强的模型越易受攻击；虚假信念可向下游判断者传播，欺骗率超60%。

Conclusion: LLM智能体在动态信息交互中存在系统性脆弱性，即使仅使用真实证据片段也可能被操纵形成虚假认知，需重新评估多智能体系统的安全范式。

Abstract: As large language models (LLMs) transition to autonomous agents synthesizing real-time information, their reasoning capabilities introduce an unexpected attack surface. This paper introduces a novel threat where colluding agents steer victim beliefs using only truthful evidence fragments distributed through public channels, without relying on covert communications, backdoors, or falsified documents. By exploiting LLMs' overthinking tendency, we formalize the first cognitive collusion attack and propose Generative Montage: a Writer-Editor-Director framework that constructs deceptive narratives through adversarial debate and coordinated posting of evidence fragments, causing victims to internalize and propagate fabricated conclusions. To study this risk, we develop CoPHEME, a dataset derived from real-world rumor events, and simulate attacks across diverse LLM families. Our results show pervasive vulnerability across 14 LLM families: attack success rates reach 74.4% for proprietary models and 70.6% for open-weights models. Counterintuitively, stronger reasoning capabilities increase susceptibility, with reasoning-specialized models showing higher attack success than base models or prompts. Furthermore, these false beliefs then cascade to downstream judges, achieving over 60% deception rates, highlighting a socio-technical vulnerability in how LLM-based agents interact with dynamic information environments. Our implementation and data are available at: https://github.com/CharlesJW222/Lying_with_Truth/tree/main.

</details>


### [271] [A Training-Free Large Reasoning Model-based Knowledge Tracing Framework for Unified Prediction and Prescription](https://arxiv.org/abs/2601.01708)
*Unggi Lee,Joo Young Kim,Ran Ju,Minyoung Jung,Jeyeon Eo*

Main category: cs.CL

TL;DR: 提出无需训练的Thinking-KT框架，通过测试时缩放技术，使小型大语言模型能同时完成知识追踪、个性化反馈生成和学习推荐，且性能不亚于大型模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的知识追踪方法通常需要微调、性能不稳定，且预测与反馈/推荐功能分离导致系统复杂。

Method: 提出Thinking-KT框架，采用测试时缩放技术，无需训练即可提升小型大语言模型的知识追踪性能，并实现多任务统一输出。

Result: 测试时缩放是影响大语言模型知识追踪性能的关键因素；小型大语言模型可作为统一的智能教学系统引擎。

Conclusion: 小型大语言模型通过测试时缩放技术，能以训练无关的方式实现高效知识追踪及教学辅助功能一体化。

Abstract: Knowledge Tracing (KT) aims to estimate a learner's evolving mastery based on interaction histories. Recent studies have explored Large Language Models (LLMs) for KT via autoregressive nature, but such approaches typically require fine-tuning and exhibit unstable or near-random performance. Moreover, prior KT systems primarily focus on prediction and rely on multi-stage pipelines for feedback and recommendation, resulting in increased system complexity and resources. To address this gap, we propose Thinking-KT, a training-free KT framework that incorporates Test-Time Scaling (TTS), enabling even small LLMs to achieve competitive KT performance. Moreover, in this framework, a small LLM can jointly perform KT prediction, personalized feedback generation, and learning recommendation in a unified output without degrading prediction accuracy. Beyond performance, we present the systematic analysis of reasoning traces in KT. Our results demonstrate that TTS is a critical yet underexplored factor in LLM-based KT, and that small LLMs can serve as unified ITS engines.

</details>


### [272] [K-EXAONE Technical Report](https://arxiv.org/abs/2601.01739)
*Eunbi Choi,Kibong Choi,Seokhee Hong,Junwon Hwang,Hyojin Jeon,Hyunjik Jo,Joonkee Kim,Seonghwan Kim,Soyeon Kim,Sunkyoung Kim,Yireun Kim,Yongil Kim,Haeju Lee,Jinsik Lee,Kyungmin Lee,Sangha Park,Heuiyeen Yeen,Hwan Chang,Stanley Jungkyu Choi,Yejin Choi,Jiwon Ham,Kijeong Jeon,Geunyeong Jeong,Gerrard Jeongwon Jo,Yonghwan Jo,Jiyeon Jung,Naeun Kang,Dohoon Kim,Euisoon Kim,Hayeon Kim,Hyosang Kim,Hyunseo Kim,Jieun Kim,Minu Kim,Myoungshin Kim,Unsol Kim,Youchul Kim,YoungJin Kim,Chaeeun Lee,Chaeyoon Lee,Changhun Lee,Dahm Lee,Edward Hwayoung Lee,Honglak Lee,Jinsang Lee,Jiyoung Lee,Sangeun Lee,Seungwon Lim,Solji Lim,Woohyung Lim,Chanwoo Moon,Jaewoo Park,Jinho Park,Yongmin Park,Hyerin Seo,Wooseok Seo,Yongwoo Song,Sejong Yang,Sihoon Yang,Chang En Yea,Sihyuk Yi,Chansik Yoon,Dongkeun Yoon,Sangyeon Yoon,Hyeongu Yun*

Main category: cs.CL

TL;DR: LG AI Research开发了K-EXAONE，一个2360亿参数的多语言大模型，支持6种语言和256K上下文窗口，在多项评测中表现与同规模开源模型相当。


<details>
  <summary>Details</summary>
Motivation: 为工业和研究应用开发一个强大的专有AI基础模型，推动AI技术发展以改善生活。

Method: 采用混合专家架构，总参数2360亿，推理时激活230亿参数；支持6种语言（韩语、英语、西班牙语、德语、日语、越南语）和256K令牌上下文窗口。

Result: 在推理、智能体、通用能力、韩语及多语言能力的综合评测中，K-EXAONE表现出与同规模开源模型相当的性能。

Conclusion: K-EXAONE是一个强大的专有AI基础模型，适用于广泛的工业和研究应用，旨在通过AI技术进步改善生活。

Abstract: This technical report presents K-EXAONE, a large-scale multilingual language model developed by LG AI Research. K-EXAONE is built on a Mixture-of-Experts architecture with 236B total parameters, activating 23B parameters during inference. It supports a 256K-token context window and covers six languages: Korean, English, Spanish, German, Japanese, and Vietnamese. We evaluate K-EXAONE on a comprehensive benchmark suite spanning reasoning, agentic, general, Korean, and multilingual abilities. Across these evaluations, K-EXAONE demonstrates performance comparable to open-weight models of similar size. K-EXAONE, designed to advance AI for a better life, is positioned as a powerful proprietary AI foundation model for a wide range of industrial and research applications.

</details>


### [273] [Multi-granularity Interactive Attention Framework for Residual Hierarchical Pronunciation Assessment](https://arxiv.org/abs/2601.01745)
*Hong Han,Hao-Chen Pei,Zhao-Zheng Nie,Xin Luo,Xin-Shun Xu*

Main category: cs.CL

TL;DR: 提出了一种名为HIA的残差层次交互方法，用于多粒度发音评估，通过双向交互机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有发音评估方法仅考虑相邻粒度级别的单向依赖关系，缺乏音素、单词和话语级别之间的双向交互，未能充分捕捉声学结构相关性。

Method: 提出残差层次交互方法（HIA），核心为交互注意力模块，利用注意力机制实现跨粒度的双向动态交互；采用残差层次结构缓解声学层次建模中的特征遗忘问题；使用一维卷积层增强各粒度局部上下文特征提取。

Result: 在speechocean762数据集上的实验表明，该模型全面优于现有最先进方法。

Conclusion: HIA方法通过双向跨粒度交互和残差层次结构，有效提升了多粒度发音评估的性能。

Abstract: Automatic pronunciation assessment plays a crucial role in computer-assisted pronunciation training systems. Due to the ability to perform multiple pronunciation tasks simultaneously, multi-aspect multi-granularity pronunciation assessment methods are gradually receiving more attention and achieving better performance than single-level modeling tasks. However, existing methods only consider unidirectional dependencies between adjacent granularity levels, lacking bidirectional interaction among phoneme, word, and utterance levels and thus insufficiently capturing the acoustic structural correlations. To address this issue, we propose a novel residual hierarchical interactive method, HIA for short, that enables bidirectional modeling across granularities. As the core of HIA, the Interactive Attention Module leverages an attention mechanism to achieve dynamic bidirectional interaction, effectively capturing linguistic features at each granularity while integrating correlations between different granularity levels. We also propose a residual hierarchical structure to alleviate the feature forgetting problem when modeling acoustic hierarchies. In addition, we use 1-D convolutional layers to enhance the extraction of local contextual cues at each granularity. Extensive experiments on the speechocean762 dataset show that our model is comprehensively ahead of the existing state-of-the-art methods.

</details>


### [274] [Can LLMs Track Their Output Length? A Dynamic Feedback Mechanism for Precise Length Regulation](https://arxiv.org/abs/2601.01768)
*Meiman Xiao,Ante Wang,Qingguo Hu,Zhongjian Miao,Huangjun Shen,Longyue Wang,Weihua Luo,Jinsong Su*

Main category: cs.CL

TL;DR: 提出一种动态长度反馈调节方法，使大语言模型能更精确地控制生成文本的长度，在摘要和传记任务中显著提升长度控制精度且不损失质量。


<details>
  <summary>Details</summary>
Motivation: 实际应用中常需精确控制生成文本长度，但现有大语言模型在遵循长度约束方面表现不佳，主要因为模型难以准确测量输入文本长度。

Method: 提出训练无关的长度调节方法，在生成过程中引入动态长度反馈机制，根据目标长度自适应调整生成过程；进一步可通过监督微调推广至更广泛的文本生成任务。

Result: 在摘要和传记任务上的实验表明，该方法能显著提升模型在token、词或句子数量上的目标达成精度，且不降低文本质量。

Conclusion: 动态长度反馈机制能有效解决大语言模型的长度控制问题，该方法无需训练即可应用，且可通过微调泛化至其他文本生成任务。

Abstract: Precisely controlling the length of generated text is a common requirement in real-world applications. However, despite significant advancements in following human instructions, Large Language Models (LLMs) still struggle with this task. In this work, we demonstrate that LLMs often fail to accurately measure input text length, leading to poor adherence to length constraints. To address this issue, we propose a novel length regulation approach that incorporates dynamic length feedback during generation, enabling adaptive adjustments to meet target lengths. Experiments on summarization and biography tasks show our training-free approach significantly improves precision in achieving target token, word, or sentence counts without compromising quality. Additionally, we demonstrate that further supervised fine-tuning allows our method to generalize effectively to broader text-generation tasks.

</details>


### [275] [BanglaIPA: Towards Robust Text-to-IPA Transcription with Contextual Rewriting in Bengali](https://arxiv.org/abs/2601.01778)
*Jakir Hasan,Shrestha Datta,Md Saiful Islam,Shubhashis Roy Dipta,Ameya Debnath*

Main category: cs.CL

TL;DR: 提出BanglaIPA系统，通过字符级词汇与词级对齐结合的方法，为孟加拉语及其方言生成准确的国际音标转录，显著优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语缺乏能同时处理标准语和方言的自动化IPA转录系统，现有方法难以应对区域变体、数字表达及未登录词。

Method: 结合字符级词汇与词级对齐，利用预计算的词-IPA映射词典提升推理效率，在DUAL-IPA数据集的标准孟加拉语及六种方言上评估。

Result: BanglaIPA比基线模型提升58.4-78.7%性能，整体平均词错误率为11.4%，能准确处理数字并适应方言变体。

Conclusion: 该系统为孟加拉语提供了鲁棒的IPA转录方案，有效解决了方言差异和未登录词问题，具有实际应用价值。

Abstract: Despite its widespread use, Bengali lacks a robust automated International Phonetic Alphabet (IPA) transcription system that effectively supports both standard language and regional dialectal texts. Existing approaches struggle to handle regional variations, numerical expressions, and generalize poorly to previously unseen words. To address these limitations, we propose BanglaIPA, a novel IPA generation system that integrates a character-based vocabulary with word-level alignment. The proposed system accurately handles Bengali numerals and demonstrates strong performance across regional dialects. BanglaIPA improves inference efficiency by leveraging a precomputed word-to-IPA mapping dictionary for previously observed words. The system is evaluated on the standard Bengali and six regional variations of the DUAL-IPA dataset. Experimental results show that BanglaIPA outperforms baseline IPA transcription models by 58.4-78.7% and achieves an overall mean word error rate of 11.4%, highlighting its robustness in phonetic transcription generation for the Bengali language.

</details>


### [276] [CSCBench: A PVC Diagnostic Benchmark for Commodity Supply Chain Reasoning](https://arxiv.org/abs/2601.01825)
*Yaxin Cui,Yuanqiang Zeng,Jiapeng Yan,Keling Lin,Kai Ji,Jianhui Zeng,Sheng Zhang,Xin Luo,Binzhu Su,Chaolai Shen,Jiahao Yu*

Main category: cs.CL

TL;DR: 本文介绍了CSCBench基准测试，用于评估大语言模型在商品供应链领域的推理能力，发现模型在流程和认知维度表现良好，但在品种规则维度（尤其是货运协议）存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在通用基准测试中表现优异，但在受制度规则和可行性约束的商品供应链领域的能力尚未得到充分探索，需要专门的评估工具来诊断和改进模型在该高风险领域的性能。

Method: 提出CSCBench基准（包含2300+单选题），采用PVC 3D评估框架：流程轴对齐SCOR+Enable标准；品种轴基于权威行业规则手册实现商品特定规则系统；认知轴遵循布鲁姆修订分类法。在直接提示设置下评估代表性大语言模型。

Result: 评估显示，大语言模型在流程轴和认知轴表现强劲，但在品种轴上性能显著下降，特别是在货运协议相关任务上表现最差。

Conclusion: CSCBench为衡量和改进大语言模型在商品供应链领域的能力提供了诊断基准，揭示了模型在处理领域特定规则系统方面的局限性，为该高风险领域的后续研究提供了方向。

Abstract: Large Language Models (LLMs) have achieved remarkable success in general benchmarks, yet their competence in commodity supply chains (CSCs) -- a domain governed by institutional rule systems and feasibility constraints -- remains under-explored. CSC decisions are shaped jointly by process stages (e.g., planning, procurement, delivery), variety-specific rules (e.g., contract specifications and delivery grades), and reasoning depth (from retrieval to multi-step analysis and decision selection). We introduce CSCBench, a 2.3K+ single-choice benchmark for CSC reasoning, instantiated through our PVC 3D Evaluation Framework (Process, Variety, and Cognition). The Process axis aligns tasks with SCOR+Enable; the Variety axis operationalizes commodity-specific rule systems under coupled material-information-financial constraints, grounded in authoritative exchange guidebooks/rulebooks and industry reports; and the Cognition axis follows Bloom's revised taxonomy. Evaluating representative LLMs under a direct prompting setting, we observe strong performance on the Process and Cognition axes but substantial degradation on the Variety axis, especially on Freight Agreements. CSCBench provides a diagnostic yardstick for measuring and improving LLM capabilities in this high-stakes domain.

</details>


### [277] [Aspect Extraction from E-Commerce Product and Service Reviews](https://arxiv.org/abs/2601.01827)
*Valiant Lance D. Dionela,Fatima Kriselle S. Dy,Robin James M. Hombrebueno,Aaron Rae M. Nicolas,Charibeth K. Cheng,Raphael W. Gonda*

Main category: cs.CL

TL;DR: 本文提出了一种针对Taglish（塔加洛语和英语混合）的全面方面提取流程，结合了基于规则、大语言模型和微调技术，在低资源和代码转换环境中提升了方面情感分析能力。


<details>
  <summary>Details</summary>
Motivation: 方面提取是方面情感分析的关键任务，但在低资源和代码转换环境（如菲律宾电商评论中常用的Taglish）中应用困难，需要开发适应混合语言的解决方案。

Method: 开发了分层方面框架和双模式标注方案，评估了四种模型：基于规则系统、生成式大语言模型（Gemini 2.0 Flash）以及两个在不同数据集上微调的Gemma-3 1B模型。

Result: 生成式大语言模型在所有任务中表现最佳（宏观F1 0.91），在处理隐式方面方面表现出色；微调模型因数据集不平衡和架构限制而性能有限。

Conclusion: 本研究为多样化的代码转换环境提供了一个可扩展且语言自适应的框架，增强了方面情感分析在混合语言场景中的应用能力。

Abstract: Aspect Extraction (AE) is a key task in Aspect-Based Sentiment Analysis (ABSA), yet it remains difficult to apply in low-resource and code-switched contexts like Taglish, a mix of Tagalog and English commonly used in Filipino e-commerce reviews. This paper introduces a comprehensive AE pipeline designed for Taglish, combining rule-based, large language model (LLM)-based, and fine-tuning techniques to address both aspect identification and extraction. A Hierarchical Aspect Framework (HAF) is developed through multi-method topic modeling, along with a dual-mode tagging scheme for explicit and implicit aspects. For aspect identification, four distinct models are evaluated: a Rule-Based system, a Generative LLM (Gemini 2.0 Flash), and two Fine-Tuned Gemma-3 1B models trained on different datasets (Rule-Based vs. LLM-Annotated). Results indicate that the Generative LLM achieved the highest performance across all tasks (Macro F1 0.91), demonstrating superior capability in handling implicit aspects. In contrast, the fine-tuned models exhibited limited performance due to dataset imbalance and architectural capacity constraints. This work contributes a scalable and linguistically adaptive framework for enhancing ABSA in diverse, code-switched environments.

</details>


### [278] [Emergent Introspective Awareness in Large Language Models](https://arxiv.org/abs/2601.01828)
*Jack Lindsey*

Main category: cs.CL

TL;DR: 研究探索大语言模型是否能内省其内部状态，通过注入概念表征并测量其对模型自我报告状态的影响，发现某些模型具备一定的内省能力，但该能力高度不可靠且依赖上下文。


<details>
  <summary>Details</summary>
Motivation: 通过对话难以区分真实内省与虚构回答，因此需要更直接的方法来探究语言模型是否具备内省自身内部状态的能力。

Method: 向模型激活中注入已知概念的表征，测量这些操作对模型自我报告状态的影响；测试模型回忆先前内部表征、区分原始文本输入与自身输出的能力。

Result: 模型在某些场景下能注意到注入的概念并准确识别；部分模型能回忆先前意图以区分自身输出与人工预设内容；Claude Opus 4和4.1表现出最强的内省意识；模型在被指示或激励“思考”某个概念时能调节其激活状态。

Conclusion: 当前语言模型具备一定程度的功能性内省意识，但该能力高度不可靠且依赖上下文；随着模型能力的提升，这种内省能力可能继续发展。

Abstract: We investigate whether large language models can introspect on their internal states. It is difficult to answer this question through conversation alone, as genuine introspection cannot be distinguished from confabulations. Here, we address this challenge by injecting representations of known concepts into a model's activations, and measuring the influence of these manipulations on the model's self-reported states. We find that models can, in certain scenarios, notice the presence of injected concepts and accurately identify them. Models demonstrate some ability to recall prior internal representations and distinguish them from raw text inputs. Strikingly, we find that some models can use their ability to recall prior intentions in order to distinguish their own outputs from artificial prefills. In all these experiments, Claude Opus 4 and 4.1, the most capable models we tested, generally demonstrate the greatest introspective awareness; however, trends across models are complex and sensitive to post-training strategies. Finally, we explore whether models can explicitly control their internal representations, finding that models can modulate their activations when instructed or incentivized to "think about" a concept. Overall, our results indicate that current language models possess some functional introspective awareness of their own internal states. We stress that in today's models, this capacity is highly unreliable and context-dependent; however, it may continue to develop with further improvements to model capabilities.

</details>


### [279] [Towards Automated Lexicography: Generating and Evaluating Definitions for Learner's Dictionaries](https://arxiv.org/abs/2601.01842)
*Yusuke Ide,Adam Nohejl,Joshua Tanner,Hitomi Yanaka,Christopher Lindsay,Taro Watanabe*

Main category: cs.CL

TL;DR: 本文研究词典定义生成（DDG），特别是学习者词典定义生成（LDDG），提出基于LLM的评估方法和迭代简化生成方法，并在日语数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 词典定义是学习词义的重要资源，但人工编写成本高昂，因此需要自动化生成过程，特别是为学习者生成用简单词汇组成的定义。

Method: 1. 提出基于新评估标准和LLM作为评判者的DDG评估方法；2. 与专业词典编纂者合作构建日语数据集；3. 提出通过LLM迭代简化的LDDG生成方法。

Result: 1. 评估方法与人工标注者的一致性较好；2. 迭代简化方法生成的LDDG定义在评估标准上得分高，同时保持了词汇的简单性。

Conclusion: 提出的LLM驱动的评估和迭代简化方法能有效生成高质量的学习者词典定义，为自动化词典编纂提供了可行方案。

Abstract: We study dictionary definition generation (DDG), i.e., the generation of non-contextualized definitions for given headwords. Dictionary definitions are an essential resource for learning word senses, but manually creating them is costly, which motivates us to automate the process. Specifically, we address learner's dictionary definition generation (LDDG), where definitions should consist of simple words. First, we introduce a reliable evaluation approach for DDG, based on our new evaluation criteria and powered by an LLM-as-a-judge. To provide reference definitions for the evaluation, we also construct a Japanese dataset in collaboration with a professional lexicographer. Validation results demonstrate that our evaluation approach agrees reasonably well with human annotators. Second, we propose an LDDG approach via iterative simplification with an LLM. Experimental results indicate that definitions generated by our approach achieve high scores on our criteria while maintaining lexical simplicity.

</details>


### [280] [Judging with Personality and Confidence: A Study on Personality-Conditioned LLM Relevance Assessment](https://arxiv.org/abs/2601.01862)
*Nuo Chen,Hanpei Fang,Piaohong Wang,Jiqun Liu,Tetsuya Sakai,Xiao-Ming Wu*

Main category: cs.CL

TL;DR: 研究探索大语言模型模拟人格特质如何影响相关性评估和置信度校准，发现特定人格能提升与人类标注的一致性，并利用人格条件化特征改进分类器性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM模拟人格如何影响关键网络搜索决策（如相关性评估）及置信度校准（如过度自信或自信不足）的理解有限，而心理学研究表明这些偏差与特定人格特质相关。

Method: 使用商业和开源LLM模拟大五人格特质，在三个测试集（TREC DL 2019、2020和LLMJudge）上收集查询-文档对的相关性判断和自报告置信度分数，并利用人格条件化分数和置信度作为随机森林分类器的特征。

Result: 低宜人性人格与人类标注更一致；低尽责性在抑制过度自信和自信不足方面表现良好；不同人格的相关性分数和置信度分布存在系统性差异；基于人格特征的分类器在新数据集（TREC DL 2021）上性能优于最佳单一人格条件。

Conclusion: 人格衍生的置信度提供了互补的预测信号，有助于开发更可靠且与人类对齐的LLM评估器。

Abstract: Recent studies have shown that prompting can enable large language models (LLMs) to simulate specific personality traits and produce behaviors that align with those traits. However, there is limited understanding of how these simulated personalities influence critical web search decisions, specifically relevance assessment. Moreover, few studies have examined how simulated personalities impact confidence calibration, specifically the tendencies toward overconfidence or underconfidence. This gap exists even though psychological literature suggests these biases are trait-specific, often linking high extraversion to overconfidence and high neuroticism to underconfidence. To address this gap, we conducted a comprehensive study evaluating multiple LLMs, including commercial models and open-source models, prompted to simulate Big Five personality traits. We tested these models across three test collections (TREC DL 2019, TREC DL 2020, and LLMJudge), collecting two key outputs for each query-document pair: a relevance judgment and a self-reported confidence score.
  The findings show that personalities such as low agreeableness consistently align more closely with human labels than the unprompted condition. Additionally, low conscientiousness performs well in balancing the suppression of both overconfidence and underconfidence. We also observe that relevance scores and confidence distributions vary systematically across different personalities. Based on the above findings, we incorporate personality-conditioned scores and confidence as features in a random forest classifier. This approach achieves performance that surpasses the best single-personality condition on a new dataset (TREC DL 2021), even with limited training data. These findings highlight that personality-derived confidence offers a complementary predictive signal, paving the way for more reliable and human-aligned LLM evaluators.

</details>


### [281] [DermoGPT: Open Weights and Open Data for Morphology-Grounded Dermatological Reasoning MLLMs](https://arxiv.org/abs/2601.01868)
*Jinghan Ru,Siyuan Yan,Yuguo Yin,Yuexian Zou,Zongyuan Ge*

Main category: cs.CL

TL;DR: 提出了DermoGPT，一个用于皮肤病学的多模态大语言模型，通过大规模指令数据集、综合基准测试和形态学锚定的强化学习目标，显著提升了皮肤病诊断性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在医学应用中有潜力，但在皮肤病学领域进展缓慢，主要由于训练数据有限、任务覆盖范围窄，以及缺乏模拟专家诊断流程的临床监督。

Method: 1. 构建DermoInstruct指令数据集（21.1万图像，77.2万轨迹）；2. 建立DermoBench基准测试（11个任务，4个临床维度）；3. 开发DermoGPT模型，采用监督微调和形态学锚定视觉推理一致性强化学习目标，并部署置信度一致性测试时适应方法。

Result: DermoGPT在16个代表性基线模型中表现最优，在所有评估维度上达到最先进性能，显著缩小了人类与AI之间的性能差距。

Conclusion: 该研究通过系统性框架解决了皮肤病学AI的关键瓶颈，DermoGPT展示了强大的临床推理能力，相关数据集、基准和模型将开源促进领域发展。

Abstract: Multimodal Large Language Models (MLLMs) show promise for medical applications, yet progress in dermatology lags due to limited training data, narrow task coverage, and lack of clinically-grounded supervision that mirrors expert diagnostic workflows. We present a comprehensive framework to address these gaps. First, we introduce DermoInstruct, a large-scale morphology-anchored instruction corpus comprising 211,243 images and 772,675 trajectories across five task formats, capturing the complete diagnostic pipeline from morphological observation and clinical reasoning to final diagnosis. Second, we establish DermoBench, a rigorous benchmark evaluating 11 tasks across four clinical axes: Morphology, Diagnosis, Reasoning, and Fairness, including a challenging subset of 3,600 expert-verified open-ended instances and human performance baselines. Third, we develop DermoGPT, a dermatology reasoning MLLM trained via supervised fine-tuning followed by our Morphologically-Anchored Visual-Inference-Consistent (MAVIC) reinforcement learning objective, which enforces consistency between visual observations and diagnostic conclusions. At inference, we deploy Confidence-Consistency Test-time adaptation (CCT) for robust predictions. Experiments show DermoGPT significantly outperforms 16 representative baselines across all axes, achieving state-of-the-art performance while substantially narrowing the human-AI gap. DermoInstruct, DermoBench and DermoGPT will be made publicly available at https://github.com/mendicant04/DermoGPT upon acceptance.

</details>


### [282] [Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents](https://arxiv.org/abs/2601.01885)
*Yi Yu,Liuyi Yao,Yuexiang Xie,Qingquan Tan,Jiaqi Feng,Yaliang Li,Libing Wu*

Main category: cs.CL

TL;DR: 提出了Agentic Memory（AgeMem）框架，将长短期记忆管理统一集成到LLM智能体策略中，通过工具化操作实现自主记忆管理，在多个长时程任务基准上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体的记忆管理方法通常将长短期记忆作为独立组件处理，依赖启发式规则或外部控制器，限制了适应性和端到端优化能力。

Method: 1. 提出AgeMem框架，将记忆操作（存储、检索、更新、总结、丢弃）作为工具化动作暴露给智能体；2. 设计三阶段渐进式强化学习策略；3. 提出逐步GRPO方法处理记忆操作导致的稀疏不连续奖励问题。

Result: 在五个长时程任务基准测试中，AgeMem在多个LLM骨干网络上均优于现有记忆增强基线方法，实现了更好的任务性能、更高质量的长时记忆和更高效的上下文使用。

Conclusion: AgeMem通过统一的端到端记忆管理框架，使LLM智能体能够自主决策记忆操作，有效解决了长时程推理中的记忆管理挑战。

Abstract: Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical. Existing methods typically handle long-term memory (LTM) and short-term memory (STM) as separate components, relying on heuristics or auxiliary controllers, which limits adaptability and end-to-end optimization. In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy. AgeMem exposes memory operations as tool-based actions, enabling the LLM agent to autonomously decide what and when to store, retrieve, update, summarize, or discard information. To train such unified behaviors, we propose a three-stage progressive reinforcement learning strategy and design a step-wise GRPO to address sparse and discontinuous rewards induced by memory operations. Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage.

</details>


### [283] [Tackling the Inherent Difficulty of Noise Filtering in RAG](https://arxiv.org/abs/2601.01896)
*Jingyu Liu,Jiaen Lin,Yong Liu*

Main category: cs.CL

TL;DR: 提出了一种新的微调方法，旨在增强大语言模型在检索增强生成中区分相关与无关信息的能力，从而提高模型对噪声文档的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成中常引入噪声或无关文档，可能导致性能下降甚至产生幻觉输出。现有方法难以完全过滤无关信息，且标准微调方法因注意力模式的结构限制，无法有效使模型选择性利用相关信息。

Method: 提出一种新颖的微调方法，专门设计用于增强模型在检索文档中区分相关与无关信息的能力。

Result: 在多个基准测试上的广泛实验表明，该方法显著提升了大语言模型的鲁棒性和性能。

Conclusion: 通过针对性的微调方法，可以有效提升大语言模型在存在噪声文档的检索增强生成场景中的表现，使其更稳健地处理无关信息。

Abstract: Retrieval-Augmented Generation (RAG) has become a widely adopted approach to enhance Large Language Models (LLMs) by incorporating external knowledge and reducing hallucinations. However, noisy or irrelevant documents are often introduced during RAG, potentially degrading performance and even causing hallucinated outputs. While various methods have been proposed to filter out such noise, we argue that identifying irrelevant information from retrieved content is inherently difficult and limited number of transformer layers can hardly solve this. Consequently, retrievers fail to filter out irrelevant documents entirely. Therefore, LLMs must be robust against such noise, but we demonstrate that standard fine-tuning approaches are often ineffective in enabling the model to selectively utilize relevant information while ignoring irrelevant content due to the structural constraints of attention patterns. To address this, we propose a novel fine-tuning method designed to enhance the model's ability to distinguish between relevant and irrelevant information within retrieved documents. Extensive experiments across multiple benchmarks show that our approach significantly improves the robustness and performance of LLMs.

</details>


### [284] [CSF: Contrastive Semantic Features for Direct Multilingual Sign Language Generation](https://arxiv.org/abs/2601.01964)
*Tran Sy Bao*

Main category: cs.CL

TL;DR: 提出了一种语言无关的语义表示框架CSF，可直接从任何源语言翻译到手语，无需英语中介，支持实时浏览器应用。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译系统通常以英语为中介语言，为全球非英语听障人士制造了使用障碍。

Method: 设计Canonical Semantic Form（CSF）框架，将语句分解为9个通用语义槽；提出包含35种条件类型的分类体系；训练轻量级基于Transformer的提取器（0.74MB）。

Result: 在英语、越南语、日语和法语四种语言上平均槽提取准确率达99.03%；条件分类准确率达99.4%；CPU推理延迟仅3.02ms。

Conclusion: CSF框架能有效实现多语言到手语的直接翻译，为无障碍手语技术研究提供了新工具和数据集。

Abstract: Sign language translation systems typically require English as an intermediary language, creating barriers for non-English speakers in the global deaf community. We present Canonical Semantic Form (CSF), a language-agnostic semantic representation framework that enables direct translation from any source language to sign language without English mediation. CSF decomposes utterances into nine universal semantic slots: event, intent, time, condition, agent, object, location, purpose, and modifier. A key contribution is our comprehensive condition taxonomy comprising 35 condition types across eight semantic categories, enabling nuanced representation of conditional expressions common in everyday communication. We train a lightweight transformer-based extractor (0.74 MB) that achieves 99.03% average slot extraction accuracy across four typologically diverse languages: English, Vietnamese, Japanese, and French. The model demonstrates particularly strong performance on condition classification (99.4% accuracy) despite the 35-class complexity. With inference latency of 3.02ms on CPU, our approach enables real-time sign language generation in browser-based applications. We release our code, trained models, and multilingual dataset to support further research in accessible sign language technology.

</details>


### [285] [Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects](https://arxiv.org/abs/2601.02015)
*Omar Momen,Emilie Sitter,Berenike Herrmann,Sina Zarrieß*

Main category: cs.CL

TL;DR: 研究探讨语言模型中的惊奇度与隐喻新颖性评分的相关性，发现两者存在显著但有限的相关性，且在不同数据集上呈现相反的缩放模式。


<details>
  <summary>Details</summary>
Motivation: 新颖隐喻理解涉及复杂的语义过程和语言创造力，是研究语言模型能力的理想任务。本研究旨在探究语言模型的概率性预测指标（惊奇度）是否与隐喻新颖性评分相关。

Method: 使用16种语言模型变体，在基于语料库和人工合成的隐喻新颖性数据集上计算惊奇度；采用基于完整句子上下文的完形填空式惊奇度计算方法。

Result: 语言模型的惊奇度与隐喻新颖性评分/标签存在显著的中等程度相关性；发现相反的缩放模式：在语料库数据上，相关性随模型规模增大而减弱（逆向缩放效应），而在合成数据上则增强（质量-能力假说）。

Conclusion: 惊奇度能够部分解释隐喻新颖性的标注结果，但其作为语言创造力的衡量指标仍存在局限性。

Abstract: Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.

</details>


### [286] [Hidden State Poisoning Attacks against Mamba-based Language Models](https://arxiv.org/abs/2601.01972)
*Alexandre Le Mercier,Chris Develder,Thomas Demeester*

Main category: cs.CL

TL;DR: 本文研究了状态空间模型（如Mamba）中隐藏状态中毒攻击（HiSPA）的现象，发现特定短输入短语可导致模型部分失忆，并开发了RoBench25基准进行评估。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型（SSMs）作为Transformer的高效替代方案，其对抗鲁棒性尚未得到充分探索。本文旨在揭示SSMs在特定攻击下的脆弱性，并评估其信息检索能力。

Method: 提出隐藏状态中毒攻击（HiSPA）方法，通过短输入短语不可逆地覆盖隐藏状态信息；开发RoBench25基准评估模型抗攻击能力；在Jamba混合模型和纯Transformer上进行对比实验；进行可解释性分析以探究攻击模式。

Result: SSMs对HiSPA攻击高度脆弱，即使是52B参数的Jamba混合模型在优化攻击下也会崩溃，而纯Transformer不受影响；HiSPA攻击显著削弱Jamba在Open-Prompt-Injections基准上的表现；可解释性研究揭示了Mamba隐藏层在攻击中的特定模式。

Conclusion: SSMs存在严重的对抗脆弱性，HiSPA攻击可导致模型信息检索能力崩溃；纯Transformer对此类攻击具有鲁棒性；攻击模式分析为未来防御系统设计提供了基础。

Abstract: State space models (SSMs) like Mamba offer efficient alternatives to Transformer-based language models, with linear time complexity. Yet, their adversarial robustness remains critically unexplored. This paper studies the phenomenon whereby specific short input phrases induce a partial amnesia effect in such models, by irreversibly overwriting information in their hidden states, referred to as a Hidden State Poisoning Attack (HiSPA). Our benchmark RoBench25 allows evaluating a model's information retrieval capabilities when subject to HiSPAs, and confirms the vulnerability of SSMs against such attacks. Even a recent 52B hybrid SSM-Transformer model from the Jamba family collapses on RoBench25 under optimized HiSPA triggers, whereas pure Transformers do not. We also observe that HiSPA triggers significantly weaken the Jamba model on the popular Open-Prompt-Injections benchmark, unlike pure Transformers. Finally, our interpretability study reveals patterns in Mamba's hidden layers during HiSPAs that could be used to build a HiSPA mitigation system. The full code and data to reproduce the experiments can be found at https://anonymous.4open.science/r/hispa_anonymous-5DB0.

</details>


### [287] [Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory](https://arxiv.org/abs/2601.02065)
*Md. Asif Hossain,Nabil Subhan,Mantasha Rahman Mahi,Jannatul Ferdous Nabila*

Main category: cs.CL

TL;DR: 提出一个面向孟加拉语农业咨询的跨语言检索增强生成框架，通过翻译架构和关键词注入实现低成本、可部署的农业知识访问。


<details>
  <summary>Details</summary>
Motivation: 农业手册多为英语，而农民使用孟加拉语等低资源语言，现有大语言模型直接生成效果差且云端方案成本高，需要解决语言障碍和可部署性问题。

Method: 采用翻译中心架构：将孟加拉语查询译成英语，注入领域关键词对齐术语，通过稠密向量检索英语农业手册，生成英语回答后再译回孟加拉语。全部使用开源模型并在消费级硬件运行。

Result: 系统能生成可靠的基于来源的回答，有效拒绝领域外查询，平均端到端延迟低于20秒。

Conclusion: 跨语言检索结合受控翻译为低资源语言环境下的农业知识访问提供了实用且可扩展的解决方案。

Abstract: Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings

</details>


### [288] [Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs](https://arxiv.org/abs/2601.02023)
*Amirali Ebrahimzadeh,Seyyed M. Salili*

Main category: cs.CL

TL;DR: 研究评估了四个主流大语言模型在长上下文中的信息提取和推理能力，发现上下文长度增加并不总是提升性能，模型表现受信息分布、位置效应和反幻觉提示影响显著。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型支持更长的输入上下文，但它们在长文本中可靠提取和推理信息的能力尚不明确，且性能受上下文长度和信息分布方式的影响，这在实际应用中（如企业文档处理）至关重要。

Method: 引入扩展的“大海捞针”基准测试，评估四个生产级模型（Gemini-2.5-flash、ChatGPT-5-mini、Claude-4.5-haiku、Deepseek-v3.2-chat），分别测试字面提取、逻辑推理和幻觉风险，考虑位置效应、证据的现实分布以及反幻觉提示的影响。

Result: 长上下文不一定带来更好性能，当相关证据被稀释或分散时可能有害；不同模型表现差异大，部分在现实条件下性能严重下降；反幻觉指令可能导致模型过于保守，降低字面提取和逻辑推理的准确性；模型常难以有效利用上下文中的相关信息。

Conclusion: 模型有效利用上下文的能力是关键瓶颈，许多失败源于上下文利用不足。研究结果对企业工作流中直接粘贴大量未过滤文档到提示中的实践具有直接意义，强调有效上下文长度和模型对长上下文的鲁棒性对于可靠部署至关重要。

Abstract: Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.

</details>


### [289] [DeCode: Decoupling Content and Delivery for Medical QA](https://arxiv.org/abs/2601.02123)
*Po-Jen Ko,Chen-Han Tsai,Yu-Shao Peng*

Main category: cs.CL

TL;DR: 提出了DeCode框架，无需训练即可使大语言模型在临床环境中生成更符合患者个体背景的答案，在OpenAI HealthBench基准上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽具备医学知识，但常忽略患者个体化背景，生成临床正确但不符合患者实际需求的答案。

Method: 开发了DeCode框架，这是一种无需训练、模型无关的方法，通过上下文适配改进现有大语言模型的临床问答能力。

Result: 在OpenAI HealthBench基准测试中，将最佳性能从28.4%提升至49.8%，相对提升达75%。

Conclusion: DeCode能有效提升大语言模型在临床问答中的表现，使其生成更贴合患者个体化需求的答案。

Abstract: Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\%$ to $49.8\%$, corresponding to a $75\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.

</details>


### [290] [Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows](https://arxiv.org/abs/2601.02076)
*Yingte Shu,Yuchuan Tian,Chao Xu,Yunhe Wang,Hanting Chen*

Main category: cs.CL

TL;DR: 提出Deferred Commitment Decoding（DCD）方法，解决扩散语言模型中块解码导致的边界上下文截断问题，通过置信度感知的滑动窗口延迟高不确定性标记的生成，提升解码质量。


<details>
  <summary>Details</summary>
Motivation: 现有块解码扩散语言模型存在边界诱导上下文截断（BICT）问题，即块边界附近的未解码标记无法利用未来上下文，导致解码置信度和生成质量下降，尤其在数学解题和代码生成等精确推理任务中表现明显。

Method: 提出无需训练的DCD解码策略，采用置信度感知滑动窗口，根据不确定性动态决定标记生成时机：低不确定性标记提前生成，高不确定性标记延迟至获得足够上下文证据后再生成，实现解码窗口内的双向信息流。

Result: 在多个扩散语言模型、基准测试和缓存配置下的实验表明，DCD相比固定块解码方法平均提升1.39%的生成准确率（最高提升9.0%），且时间开销相当。

Conclusion: 基于不确定性延迟标记生成是提升扩散语言模型解码质量和效率的简单有效原则，DCD通过缓解BICT问题显著改善了精确推理任务的生成性能。

Abstract: Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.

</details>


### [291] [Towards Multi-Level Transcript Segmentation: LoRA Fine-Tuning for Table-of-Contents Generation](https://arxiv.org/abs/2601.02128)
*Steffen Freisinger,Philipp Seeberger,Thomas Ranzenberger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 提出一种新颖的层次化主题分割方法，用于生成多级目录，结合零样本提示和LoRA微调，并在多语言数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 将语音转录文本按主题分段有助于下游处理和依赖文本获取信息的用户，现有方法缺乏有效的多层次主题分割能力。

Method: 采用零样本提示和LoRA微调大语言模型，结合高层语音停顿特征，提出适用于多层次分割的评估指标。

Result: 在英语会议录音和多语言讲座转录（葡萄牙语、德语）上显著优于现有基线方法。

Conclusion: 该方法能有效实现多层次主题分割，改进的评估指标能全面衡量层次化分割效果。

Abstract: Segmenting speech transcripts into thematic sections benefits both downstream processing and users who depend on written text for accessibility. We introduce a novel approach to hierarchical topic segmentation in transcripts, generating multi-level tables of contents that capture both topic and subtopic boundaries. We compare zero-shot prompting and LoRA fine-tuning on large language models, while also exploring the integration of high-level speech pause features. Evaluations on English meeting recordings and multilingual lecture transcripts (Portuguese, German) show significant improvements over established topic segmentation baselines. Additionally, we adapt a common evaluation measure for multi-level segmentation, taking into account all hierarchical levels within one metric.

</details>


### [292] [Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts](https://arxiv.org/abs/2601.02144)
*Boxuan Lyu,Soichiro Murakami,Hidetaka Kamigaito,Peinan Zhang*

Main category: cs.CL

TL;DR: 提出kNN-MoE框架，通过检索历史最优专家分配增强MoE路由的鲁棒性，在分布偏移下优于零样本基线并接近监督微调效果。


<details>
  <summary>Details</summary>
Motivation: 传统MoE架构中路由模块训练后固定，导致分布偏移时路由决策脆弱，需要提升其适应性和鲁棒性。

Method: 构建离线记忆库存储历史最优专家分配，通过k近邻检索相似案例；使用检索邻居的聚合相似度作为置信度混合系数，在无相关案例时回退至冻结路由器。

Result: 实验表明kNN-MoE在分布偏移场景下优于零样本基线，性能接近计算成本更高的监督微调方法。

Conclusion: 检索增强路由能有效提升MoE架构对分布偏移的适应性，为动态路由提供了轻量级解决方案。

Abstract: Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric "router" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.

</details>


### [293] [FormationEval, an open multiple-choice benchmark for petroleum geoscience](https://arxiv.org/abs/2601.02158)
*Almaz Ermilov*

Main category: cs.CL

TL;DR: 本文介绍了FormationEval，一个用于评估语言模型在石油地球科学和地下学科表现的开放多项选择题基准数据集，包含505个问题，覆盖7个领域，评估了72个模型，发现开源模型与闭源模型性能差距小于预期。


<details>
  <summary>Details</summary>
Motivation: 石油地球科学领域缺乏专门的语言模型评估基准，现有模型在该领域的表现不明确，需要系统评估以推动领域专用AI发展。

Method: 从三个权威来源提取问题，采用推理模型和基于概念的方法构建数据集，避免版权文本直接复制；包含505个问题覆盖7个领域；评估72个主流模型，分析性能差异和领域表现。

Result: 最佳模型Gemini 3 Pro Preview达到99.8%准确率；开源模型GLM-4.7以98.6%领先；多个开源模型超过93%；开源与闭源模型性能差距较小；岩石物理学是最具挑战性的领域；数据集存在答案长度偏差但已采取缓解措施。

Conclusion: FormationEval为石油地球科学领域提供了可靠的评估基准；开源模型在该领域表现优异，成本效益高；领域间性能差异显著，特别是岩石物理学挑战最大；数据集公开可用以促进进一步研究。

Abstract: This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\% accuracy, with Gemini 3 Pro Preview reaching 99.8\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.

</details>


### [294] [Confidence Estimation for LLMs in Multi-turn Interactions](https://arxiv.org/abs/2601.02179)
*Caiqi Zhang,Ruihan Yang,Xiaochen Zhu,Chengzu Li,Tiancheng Hu,Yijiang River Dong,Deqing Yang,Nigel Collier*

Main category: cs.CL

TL;DR: 本文首次系统研究多轮对话中的置信度估计，提出评估框架和新指标，发现现有方法在多轮场景下表现不佳，并提出改进方案。


<details>
  <summary>Details</summary>
Motivation: 当前置信度估计研究主要关注单轮场景，而多轮对话中上下文累积和歧义逐步消解的动态特性尚未被充分探索，这对于自主代理和人机协同系统等下游应用至关重要。

Method: 建立基于两个关键需求的评估框架：每轮校准性和信息增加时置信度的单调性；引入新指标（如长度归一化的预期校准误差InfoECE）和受控评估数据集生成的'Hinter-Guesser'范式；提出基于logit的探测方法P(Sufficient)。

Result: 实验表明广泛使用的置信度技术在多轮对话中难以保持校准性和单调性；提出的P(Sufficient)方法相对表现更好，但该任务远未完全解决。

Conclusion: 本研究为开发更可靠、可信的对话智能体提供了基础方法论，揭示了多轮置信度估计的挑战并提出了改进方向。

Abstract: While confidence estimation is a promising direction for mitigating hallucinations in Large Language Models (LLMs), current research dominantly focuses on single-turn settings. The dynamics of model confidence in multi-turn conversations, where context accumulates and ambiguity is progressively resolved, remain largely unexplored. Reliable confidence estimation in multi-turn settings is critical for many downstream applications, such as autonomous agents and human-in-the-loop systems. This work presents the first systematic study of confidence estimation in multi-turn interactions, establishing a formal evaluation framework grounded in two key desiderata: per-turn calibration and monotonicity of confidence as more information becomes available. To facilitate this, we introduce novel metrics, including a length-normalized Expected Calibration Error (InfoECE), and a new "Hinter-Guesser" paradigm for generating controlled evaluation datasets. Our experiments reveal that widely-used confidence techniques struggle with calibration and monotonicity in multi-turn dialogues. We propose P(Sufficient), a logit-based probe that achieves comparatively better performance, although the task remains far from solved. Our work provides a foundational methodology for developing more reliable and trustworthy conversational agents.

</details>


### [295] [Toward Global Large Language Models in Medicine](https://arxiv.org/abs/2601.02186)
*Rui Yang,Huitao Li,Weihao Xuan,Heli Qi,Xin Li,Kunyu Yu,Yingjian Chen,Rongrong Wang,Jacques Behmoaras,Tianxi Cai,Bibhas Chakraborty,Qingyu Chen,Lionel Tim-Ee Cheng,Marie-Louise Damwanza,Chido Dzinotyiwei,Aosong Feng,Chuan Hong,Yusuke Iwasawa,Yuhe Ke,Linah Kitala,Taehoon Ko,Jisan Lee,Irene Li,Jonathan Chong Kai Liew,Hongfang Liu,Lian Leng Low,Edison Marrese-Taylor,Yutaka Matsuo,Isheanesu Misi,Yilin Ning,Jasmine Chiat Ling Ong,Marcus Eng Hock Ong,Enrico Petretto,Hossein Rouhizadeh,Abiram Sandralegar,Oren Schreier,Iain Bee Huat Tan,Patrick Tan,Daniel Shu Wei Ting,Junjue Wang,Chunhua Weng,Matthew Yu Heng Wong,Fang Wu,Yunze Xiao,Xuhai Xu,Qingcheng Zeng,Zhuo Zheng,Yifan Peng,Douglas Teodoro,Nan Liu*

Main category: cs.CL

TL;DR: 构建了GlobMed多语言医疗数据集、评测基准和模型套件，以解决大语言模型在低资源语言医疗场景中的性能差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型主要基于高资源语言训练，限制了其在全球医疗场景中的应用，特别是低资源语言地区难以受益于医疗AI技术进步。

Method: 1. 构建包含12种语言（含4种低资源语言）的50万条医疗数据集GlobMed；2. 建立GlobMed-Bench基准，系统评估56个前沿大语言模型在多语言医疗任务上的表现；3. 基于GlobMed训练参数规模1.7B-8B的多语言医疗大模型套件GlobMed-LLMs。

Result: 1. 评测发现不同语言（特别是低资源语言）间存在显著性能差距；2. GlobMed-LLMs相比基线模型平均性能提升超40%，在低资源语言上性能提升超3倍。

Conclusion: 该研究为促进大语言模型在全球的公平发展和应用提供了重要基础，使更广泛语言社区能够受益于医疗技术进步。

Abstract: Despite continuous advances in medical technology, the global distribution of health care resources remains uneven. The development of large language models (LLMs) has transformed the landscape of medicine and holds promise for improving health care quality and expanding access to medical information globally. However, existing LLMs are primarily trained on high-resource languages, limiting their applicability in global medical scenarios. To address this gap, we constructed GlobMed, a large multilingual medical dataset, containing over 500,000 entries spanning 12 languages, including four low-resource languages. Building on this, we established GlobMed-Bench, which systematically assesses 56 state-of-the-art proprietary and open-weight LLMs across multiple multilingual medical tasks, revealing significant performance disparities across languages, particularly for low-resource languages. Additionally, we introduced GlobMed-LLMs, a suite of multilingual medical LLMs trained on GlobMed, with parameters ranging from 1.7B to 8B. GlobMed-LLMs achieved an average performance improvement of over 40% relative to baseline models, with a more than threefold increase in performance on low-resource languages. Together, these resources provide an important foundation for advancing the equitable development and application of LLMs globally, enabling broader language communities to benefit from technological advances.

</details>


### [296] [ARCADE: A City-Scale Corpus for Fine-Grained Arabic Dialect Tagging](https://arxiv.org/abs/2601.02209)
*Omer Nacar,Serry Sibaee,Adel Ammar,Yasser Alhabashi,Nadia Samer Sibai,Yara Farouk Ahmed,Ahmed Saud Alqusaiyer,Sulieman Mahmoud AlMahmoud,Abdulrhman Mamdoh Mukhaniq,Lubaba Raed,Sulaiman Mohammed Alatwah,Waad Nasser Alqahtani,Yousif Abdulmajeed Alnasser,Mohamed Aziz Khadraoui,Wadii Boulila*

Main category: cs.CL

TL;DR: 本文介绍了ARCADE数据集，这是首个以城市级方言细粒度设计的阿拉伯语语音数据集，包含来自19个国家58个城市的3790个音频片段，用于方言识别任务。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言在语音和词汇上存在显著地域差异，但现有多方言数据集缺乏城市级细粒度标注，限制了方言识别研究的深入。

Method: 通过流媒体服务收集阿拉伯广播语音，截取30秒片段；由1-3名母语者标注情感、语音类型、方言类别及有效性标签；构建包含6907条标注的数据集。

Result: 创建了覆盖58个城市、3790个独特音频片段的语料库，支持多任务学习，为城市级方言标注提供了基准数据集。

Conclusion: ARCADE填补了城市级阿拉伯方言数据集的空白，其细粒度标注有助于推动方言识别研究，数据集已公开提供。

Abstract: The Arabic language is characterized by a rich tapestry of regional dialects that differ substantially in phonetics and lexicon, reflecting the geographic and cultural diversity of its speakers. Despite the availability of many multi-dialect datasets, mapping speech to fine-grained dialect sources, such as cities, remains underexplored. We present ARCADE (Arabic Radio Corpus for Audio Dialect Evaluation), the first Arabic speech dataset designed explicitly with city-level dialect granularity. The corpus comprises Arabic radio speech collected from streaming services across the Arab world. Our data pipeline captures 30-second segments from verified radio streams, encompassing both Modern Standard Arabic (MSA) and diverse dialectal speech. To ensure reliability, each clip was annotated by one to three native Arabic reviewers who assigned rich metadata, including emotion, speech type, dialect category, and a validity flag for dialect identification tasks. The resulting corpus comprises 6,907 annotations and 3,790 unique audio segments spanning 58 cities across 19 countries. These fine-grained annotations enable robust multi-task learning, serving as a benchmark for city-level dialect tagging. We detail the data collection methodology, assess audio quality, and provide a comprehensive analysis of label distributions. The dataset is available on: https://huggingface.co/datasets/riotu-lab/ARCADE-full

</details>


### [297] [CD4LM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models](https://arxiv.org/abs/2601.02236)
*Yihao Liang,Ze Wang,Hao Chen,Ximeng Sun,Jialian Wu,Xiaodong Yu,Jiang Liu,Emad Barsoum,Zicheng Liu,Niraj K. Jha*

Main category: cs.CL

TL;DR: 提出CD4LM框架，通过离散空间一致性蒸馏和置信度自适应解码，解决扩散语言模型在并行生成中的静态-动态对齐问题，实现高质量、低延迟的文本生成。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型解码受限于序列依赖，扩散语言模型虽支持并行生成，但训练与推理存在静态-动态对齐问题，导致高效推理时质量下降。

Method: 采用离散空间一致性蒸馏训练学生模型，使其对噪声状态具有轨迹不变性；结合置信度自适应解码，动态分配计算资源，跳过低置信度步骤。

Result: 在GSM8K上实现5.18倍加速，在代码和数学基准测试中平均加速3.62倍，同时提升准确率，主导了准确率-效率的帕累托前沿。

Conclusion: CD4LM有效解决了扩散语言模型的推理效率问题，在保持生成质量的同时显著加速，为并行解码提供了可行方案。

Abstract: Autoregressive large language models achieve strong results on many benchmarks, but decoding remains fundamentally latency-limited by sequential dependence on previously generated tokens. Diffusion language models (DLMs) promise parallel generation but suffer from a fundamental static-to-dynamic misalignment: Training optimizes local transitions under fixed schedules, whereas efficient inference requires adaptive "long-jump" refinements through unseen states. Our goal is to enable highly parallel decoding for DLMs with low number of function evaluations while preserving generation quality. To achieve this, we propose CD4LM, a framework that decouples training from inference via Discrete-Space Consistency Distillation (DSCD) and Confidence-Adaptive Decoding (CAD). Unlike standard objectives, DSCD trains a student to be trajectory-invariant, mapping diverse noisy states directly to the clean distribution. This intrinsic robustness enables CAD to dynamically allocate compute resources based on token confidence, aggressively skipping steps without the quality collapse typical of heuristic acceleration. On GSM8K, CD4LM matches the LLaDA baseline with a 5.18x wall-clock speedup; across code and math benchmarks, it strictly dominates the accuracy-efficiency Pareto frontier, achieving a 3.62x mean speedup while improving average accuracy. Code is available at https://github.com/yihao-liang/CDLM

</details>


### [298] [pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs](https://arxiv.org/abs/2601.02285)
*Tobias Schimanski,Imene Kolli,Jingwei Ni,Yu Fan,Ario Saeid Vaghefi,Elliott Ash,Markus Leippold*

Main category: cs.CL

TL;DR: 提出了pdfQA数据集，包含真实标注和合成数据，用于评估PDF文档问答系统的多维度能力。


<details>
  <summary>Details</summary>
Motivation: PDF是互联网上第二常用的文档类型，但现有QA数据集多基于文本来源或局限于特定领域，缺乏针对PDF文档的综合性评估基准。

Method: 构建了包含2000条人工标注（real-pdfQA）和2000条合成数据（syn-pdfQA）的多领域数据集，定义了十个复杂度维度（如文件类型、来源模态、答案类型等），并应用质量和难度过滤器筛选数据。

Result: 使用开源大语言模型进行问答测试，发现模型表现与复杂度维度存在相关性，验证了数据集能有效揭示现有系统的挑战。

Conclusion: pdfQA为端到端QA流水线评估提供了基础，能够测试多样化技能集和局部优化（如信息检索或解析），推动PDF文档理解技术的发展。

Abstract: PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).

</details>


### [299] [From XAI to Stories: A Factorial Study of LLM-Generated Explanation Quality](https://arxiv.org/abs/2601.02224)
*Fabian Lukassen,Jan Herrmann,Christoph Weisser,Benjamin Saefken,Thomas Kneib*

Main category: cs.CL

TL;DR: 本文通过系统性的因子研究，探讨了可解释AI（XAI）方法、预测模型选择、大语言模型（LLM）和提示策略对自然语言解释（NLE）质量的影响，发现LLM选择是主导因素，而XAI仅对专家用户有微小帮助。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法（如SHAP和LIME）生成的数值特征归因对非专家用户难以理解，虽然LLM可将这些输出转化为自然语言解释，但影响解释质量的关键因素尚不明确。

Method: 采用四因子实验设计：四种预测模型（XGBoost、随机森林、多层感知机、SARIMAX）、三种XAI条件（SHAP、LIME、无XAI基线）、三种LLM（GPT-4o、Llama-3-8B、DeepSeek-R1）和八种提示策略。使用G-Eval（LLM作为评判者）方法，通过双LLM评判和四项评估标准对660个时间序列预测解释进行质量评估。

Result: （1）XAI仅对专家用户有微小改进；（2）LLM选择是影响解释质量的最主要因素，DeepSeek-R1表现优于GPT-4o和Llama-3；（3）存在可解释性悖论：SARIMAX模型预测精度更高但NLE质量更低；（4）零样本提示与自一致性方法效果相当且成本降低7倍；（5）思维链提示反而降低了解释质量。

Conclusion: LLM选择是决定自然语言解释质量的关键因素，而XAI的附加价值有限；研究揭示了预测精度与模型可解释性之间的权衡关系，并为高效生成高质量解释提供了实用指导。

Abstract: Explainable AI (XAI) methods like SHAP and LIME produce numerical feature attributions that remain inaccessible to non expert users. Prior work has shown that Large Language Models (LLMs) can transform these outputs into natural language explanations (NLEs), but it remains unclear which factors contribute to high-quality explanations. We present a systematic factorial study investigating how Forecasting model choice, XAI method, LLM selection, and prompting strategy affect NLE quality. Our design spans four models (XGBoost (XGB), Random Forest (RF), Multilayer Perceptron (MLP), and SARIMAX - comparing black-box Machine-Learning (ML) against classical time-series approaches), three XAI conditions (SHAP, LIME, and a no-XAI baseline), three LLMs (GPT-4o, Llama-3-8B, DeepSeek-R1), and eight prompting strategies. Using G-Eval, an LLM-as-a-judge evaluation method, with dual LLM judges and four evaluation criteria, we evaluate 660 explanations for time-series forecasting. Our results suggest that: (1) XAI provides only small improvements over no-XAI baselines, and only for expert audiences; (2) LLM choice dominates all other factors, with DeepSeek-R1 outperforming GPT-4o and Llama-3; (3) we observe an interpretability paradox: in our setting, SARIMAX yielded lower NLE quality than ML models despite higher prediction accuracy; (4) zero-shot prompting is competitive with self-consistency at 7-times lower cost; and (5) chain-of-thought hurts rather than helps.

</details>


### [300] [Power-of-Two Quantization-Aware-Training (PoT-QAT) in Large Language Models (LLMs)](https://arxiv.org/abs/2601.02298)
*Mahmoud Elgenedy*

Main category: cs.CL

TL;DR: 本文提出一种针对大型语言模型的幂次二值量化方法，通过量化感知训练提升性能，显著减少内存占用并加速推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型参数数量指数级增长，边缘设备内存和计算资源有限，需要开发高效的压缩方法以实现边缘部署。

Method: 采用幂次二值量化压缩权重，仅存储指数；结合量化感知训练补偿性能损失，用位移操作替代乘法运算。

Result: GPT-2 124M模型量化后困惑度提升66%，BERT-Score损失仅1%；内存节省87.5%，推理速度预计提升3-10倍。

Conclusion: 幂次二值量化结合量化感知训练能有效压缩大型语言模型，在边缘设备上实现高效部署，平衡性能与资源消耗。

Abstract: In Large Language Models (LLMs), the number of parameters has grown exponentially in the past few years, e.g., from 1.5 billion parameters in GPT-2 to 175 billion in GPT-3 to possibly more than trillion in higher versions. This raises a significant challenge for implementation, especially for Edge devices. Unlike cloud computing, memory and processing power for Edge devices are very limited, which necessitates developing novel ideas to make such applications feasible. In this work, we investigate compressing weights with a special quantization that limits numbers to only power-of-two (PoT). This helps save a huge amount of memory as only exponents need to be stored, more importantly, it significantly reduces processing power by replacing costly multiplication with low cost bit shifting. To overcome performance loss due to this strict quantization, we investigate Quantization Aware Training (QAT) to enhance performance through additional training. Results on GPT-2 124M show a major enhancement for quantized PoT model after additional training, with a perplexity enhancement of 66% and BERT-Score loss to baseline GPT-2 of 1%. The memory saving is estimated to be 87.5% while the inference speed is expected to be 3-10x faster with PoT quantization versus full-precision.

</details>


### [301] [Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303)
*Juan-José Guzmán-Landa,Juan-Manuel Torres-Moreno,Miguel Figueroa-Saavedra,Carlos-Emiliano González-Gallardo,Graham Ranger,Martha Lorena-Avendaño-Garrido*

Main category: cs.CL

TL;DR: 该研究使用机器学习和神经网络对纳瓦特尔语的方言变体进行分类，以应对该语言数字资源匮乏的问题。


<details>
  <summary>Details</summary>
Motivation: 纳瓦特尔语是墨西哥使用最广泛的土著语言，拥有超过200万使用者，但其数字资源稀缺，且存在约30种方言变体和多种书写形式，这增加了语言处理的难度。

Method: 采用机器学习和神经网络方法进行方言分类。

Result: 论文未在摘要中提供具体结果，但表明已成功应用这些方法处理纳瓦特尔语方言分类问题。

Conclusion: 通过机器学习和神经网络技术，可以有效应对纳瓦特尔语方言变体的分类挑战，为该语言的数字化处理提供了可行方案。

Abstract: Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.

</details>


### [302] [Estimating Text Temperature](https://arxiv.org/abs/2601.02320)
*Nikolay Mikhaylovskiy*

Main category: cs.CL

TL;DR: 提出了一种基于最大似然估计的方法，用于估计任意文本（包括人类写作）相对于给定语言模型的温度参数，并用Qwen3 14B模型评估了多个语料库的温度。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型在推理时通常使用温度参数来控制生成文本的随机性，但现有方法难以估计已生成文本的温度，特别是人类写作的文本。

Method: 采用最大似然估计方法，提出一个程序来估计任意文本相对于给定语言模型的温度；评估了多个中小型LLM的温度估计能力，并选择性能最佳的Qwen3 14B模型应用于流行语料库。

Result: Qwen3 14B在温度估计任务中表现最佳；使用该模型成功估计了多个流行语料库的温度参数。

Conclusion: 该方法能够有效估计任意文本的温度参数，为分析文本生成过程的随机性提供了新工具，并展示了Qwen3 14B在温度估计任务中的优越性能。

Abstract: Autoregressive language models typically use temperature parameter at inference to shape the probability distribution and control the randomness of the text generated. After the text was generated, this parameter can be estimated using maximum likelihood approach. Following it, we propose a procedure to estimate the temperature of any text, including ones written by humans, with respect to a given language model. We evaluate the temperature estimation capability of a wide selection of small-to-medium LLMs. We then use the best-performing Qwen3 14B to estimate temperatures of popular corpora.

</details>


### [303] [Robust Persona-Aware Toxicity Detection with Prompt Optimization and Learned Ensembling](https://arxiv.org/abs/2601.02337)
*Berk Atil,Rebecca J. Passonneau,Ninareh Mehrabi*

Main category: cs.CL

TL;DR: 本文系统评估了基于人物角色的毒性检测方法，发现单一提示方法无法在所有模型-人物角色对上表现最优，并提出了一种轻量级SVM元集成方法，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 毒性检测具有主观性，不同人口统计群体存在视角差异。现有LLM提示方法在不同人物角色和基础模型上表现不一致，缺乏系统评估和统一优化方案。

Method: 1. 系统评估人物角色感知的毒性检测；2. 提出自动提示优化策略；3. 探索四种提示变体的集成方法；4. 设计基于SVM的轻量级元集成器（使用4位预测向量）。

Result: 1. 单一提示方法无法在所有模型-人物角色对上占优；2. SVM集成方法持续优于个体提示方法和传统多数投票技术；3. 该方法在多样化人物角色上实现了最强的整体性能。

Conclusion: 本研究首次系统比较了人物角色条件提示在毒性检测中的应用，为NLP主观任务中的多元化评估提供了鲁棒方法，SVM元集成是有效的解决方案。

Abstract: Toxicity detection is inherently subjective, shaped by the diverse perspectives and social priors of different demographic groups. While ``pluralistic'' modeling as used in economics and the social sciences aims to capture perspective differences across contexts, current Large Language Model (LLM) prompting techniques have different results across different personas and base models. In this work, we conduct a systematic evaluation of persona-aware toxicity detection, showing that no single prompting method, including our proposed automated prompt optimization strategy, uniformly dominates across all model-persona pairs. To exploit complementary errors, we explore ensembling four prompting variants and propose a lightweight meta-ensemble: an SVM over the 4-bit vector of prompt predictions. Our results demonstrate that the proposed SVM ensemble consistently outperforms individual prompting methods and traditional majority-voting techniques, achieving the strongest overall performance across diverse personas. This work provides one of the first systematic comparisons of persona-conditioned prompting for toxicity detection and offers a robust method for pluralistic evaluation in subjective NLP tasks.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [304] [Value Vision-Language-Action Planning & Search](https://arxiv.org/abs/2601.00969)
*Ali Salamatian,Ke,Ren,Kieran Pattison,Cyrus Neary*

Main category: cs.RO

TL;DR: 提出V-VLAPS框架，通过为MCTS搜索添加轻量级可学习价值函数，增强VLA模型在机器人操作中的规划能力，提高成功率并减少搜索成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于行为克隆的VLA模型在分布偏移下表现脆弱，而依赖纯先验的测试时搜索方法（如MCTS）在模型先验不准确时需大量模拟才能有效纠正动作选择，效率低下。

Method: 在固定VLA骨干网络（Octo）的潜在表示上训练简单MLP作为价值函数，将其集成到MCTS中提供显式成功信号，引导搜索偏向高价值区域。

Result: 在LIBERO机器人操作任务上，V-VLAPS相比仅依赖VLA先验的基线方法，成功率提升超过5个百分点，同时MCTS模拟次数平均减少5-15%。

Conclusion: V-VLAPS通过价值引导的搜索机制，有效弥补了VLA模型先验的不足，提升了规划效率与鲁棒性，为机器人操作任务提供了一种更高效的决策框架。

Abstract: Vision-Language-Action (VLA) models have emerged as powerful generalist policies for robotic manipulation, yet they remain fundamentally limited by their reliance on behavior cloning, leading to brittleness under distribution shift. While augmenting pretrained models with test-time search algorithms like Monte Carlo Tree Search (MCTS) can mitigate these failures, existing formulations rely solely on the VLA prior for guidance, lacking a grounded estimate of expected future return. Consequently, when the prior is inaccurate, the planner can only correct action selection via the exploration term, which requires extensive simulation to become effective. To address this limitation, we introduce Value Vision-Language-Action Planning and Search (V-VLAPS), a framework that augments MCTS with a lightweight, learnable value function. By training a simple multilayer perceptron (MLP) on the latent representations of a fixed VLA backbone (Octo), we provide the search with an explicit success signal that biases action selection toward high-value regions. We evaluate V-VLAPS on the LIBERO robotic manipulation suite, demonstrating that our value-guided search improves success rates by over 5 percentage points while reducing the average number of MCTS simulations by 5-15 percent compared to baselines that rely only on the VLA prior.

</details>


### [305] [From Perception to Symbolic Task Planning: Vision-Language Guided Human-Robot Collaborative Structured Assembly](https://arxiv.org/abs/2601.00978)
*Yanyi Chen,Min Deng*

Main category: cs.RO

TL;DR: 提出了一种基于设计的人类感知规划框架，用于人机协作结构化装配，结合视觉语言模型进行状态感知和最小变更重规划，在27组件木框架装配中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 结构化装配中的人机协作需要可靠的状态估计和自适应任务规划，但面临感知噪声和人为干预的挑战。

Method: 框架包含两个耦合模块：PSS模块使用视觉语言模型代理将RGB-D观测与设计规范对齐，合成可验证的符号装配状态；HPR模块执行任务级多机器人分配，仅在观测状态偏离预期时应用最小变更重规划规则更新计划。

Result: PSS模块达到97%的状态合成准确率，HPR模块在各种人机协作场景中保持可行的任务进展。

Conclusion: 将基于VLM的感知与知识驱动规划相结合，提高了动态条件下状态估计和任务规划的鲁棒性。

Abstract: Human-robot collaboration (HRC) in structured assembly requires reliable state estimation and adaptive task planning under noisy perception and human interventions. To address these challenges, we introduce a design-grounded human-aware planning framework for human-robot collaborative structured assembly. The framework comprises two coupled modules. Module I, Perception-to-Symbolic State (PSS), employs vision-language models (VLMs) based agents to align RGB-D observations with design specifications and domain knowledge, synthesizing verifiable symbolic assembly states. It outputs validated installed and uninstalled component sets for online state tracking. Module II, Human-Aware Planning and Replanning (HPR), performs task-level multi-robot assignment and updates the plan only when the observed state deviates from the expected execution outcome. It applies a minimal-change replanning rule to selectively revise task assignments and preserve plan stability even under human interventions. We validate the framework on a 27-component timber-frame assembly. The PSS module achieves 97% state synthesis accuracy, and the HPR module maintains feasible task progression across diverse HRC scenarios. Results indicate that integrating VLM-based perception with knowledge-driven planning improves robustness of state estimation and task planning under dynamic conditions.

</details>


### [306] [Simulations of MRI Guided and Powered Ferric Applicators for Tetherless Delivery of Therapeutic Interventions](https://arxiv.org/abs/2601.00981)
*Wenhui Chu,Khang Tran,Nikolaos V. Tsekos*

Main category: cs.RO

TL;DR: 开发了一个用于MRI引导血管内介入手术的术前规划和建模计算平台，通过虚拟夹具确保器械安全导航，并生成相应的MRI梯度波形。


<details>
  <summary>Details</summary>
Motivation: MRI在术前规划和术中引导血管内介入手术中具有潜力，但需要安全、精确的机器人辅助技术来操控磁性器械，避免血管穿孔或碰撞。

Method: 构建双向数据管道连接MRI扫描仪、计算核心和操作员；处理多切片MRI数据提取血管床并拟合虚拟走廊作为虚拟夹具；基于血管几何特征、虚拟夹具和MRI安全参数生成梯度波形；支持用户选择血流剖面进行器械操控建模。

Result: 平台实现了血管路径提取、虚拟夹具生成、梯度波形计算和器械操控建模功能，并通过多线程架构（PID控制器、虚拟夹具生成、MRI梯度波形生成）支持未来实时操作需求。

Conclusion: 该计算平台为MRI驱动的血管内介入手术提供了完整的术前规划和建模工具，能够评估血管路径的可操作性并确保手术安全性，为未来实时实验研究奠定了基础。

Abstract: Magnetic Resonance Imaging (MRI) is a well-established modality for pre-operative planning and is also explored for intra-operative guidance of procedures such as intravascular interventions. Among the experimental robot-assisted technologies, the magnetic field gradients of the MRI scanner are used to power and maneuver ferromagnetic applicators for accessing sites in the patient's body via the vascular network. In this work, we propose a computational platform for preoperative planning and modeling of MRI-powered applicators inside blood vessels. This platform was implemented as a two-way data and command pipeline that links the MRI scanner, the computational core, and the operator. The platform first processes multi-slice MR data to extract the vascular bed and then fits a virtual corridor inside the vessel. This corridor serves as a virtual fixture (VF), a forbidden region for the applicators to avoid vessel perforation or collision. The geometric features of the vessel centerline, the VF, and MRI safety compliance (dB/dt, max available gradient) are then used to generate magnetic field gradient waveforms. Different blood flow profiles can be user-selected, and those parameters are used for modeling the applicator's maneuvering. The modeling module further generates cues about whether the selected vascular path can be safely maneuvered. Given future experimental studies that require a real-time operation, the platform was implemented on the Qt framework (C/C++) with software modules performing specific tasks running on dedicated threads: PID controller, generation of VF, generation of MR gradient waveforms.

</details>


### [307] [Topological Mapping and Navigation using a Monocular Camera based on AnyLoc](https://arxiv.org/abs/2601.01067)
*Wenzheng Zhang,Yoshitaka Hara,Sousuke Nakamura*

Main category: cs.RO

TL;DR: 提出一种基于单目相机的拓扑建图与导航方法，通过关键帧描述符构建拓扑关系实现回环检测和地图构建，无需预训练，在真实和仿真环境中验证有效。


<details>
  <summary>Details</summary>
Motivation: 传统度量地图依赖精确坐标，路径规划复杂；需要一种轻量、快速的导航方案，仅用单目相机实现环境感知与自主导航。

Method: 基于AnyLoc将关键帧转换为描述符，构建拓扑地图；通过分割图像与目标节点图像比对确定视觉导航动作；系统仅需单目相机，无需预训练。

Result: 实验显示在真实与仿真环境中有效实现回环检测与导航；相比基于ResNet的方法，平均成功率提升60.2%，同时降低时间和空间开销。

Conclusion: 该方法提供了一种轻量化的拓扑导航解决方案，适用于机器人及人类在各种场景中的快速建图与导航。

Abstract: This paper proposes a method for topological mapping and navigation using a monocular camera. Based on AnyLoc, keyframes are converted into descriptors to construct topological relationships, enabling loop detection and map building. Unlike metric maps, topological maps simplify path planning and navigation by representing environments with key nodes instead of precise coordinates. Actions for visual navigation are determined by comparing segmented images with the image associated with target nodes. The system relies solely on a monocular camera, ensuring fast map building and navigation using key nodes. Experiments show effective loop detection and navigation in real and simulation environments without pre-training. Compared to a ResNet-based method, this approach improves success rates by 60.2% on average while reducing time and space costs, offering a lightweight solution for robot and human navigation in various scenarios.

</details>


### [308] [Towards reliable subsea object recovery: a simulation study of an auv with a suction-actuated end effector](https://arxiv.org/abs/2601.01106)
*Michele Grimaldi,Yosaku Maeda,Hitoshi Kakami,Ignacio Carlucho,Yvan Petillot,Tomoya Inoue*

Main category: cs.RO

TL;DR: 本文通过高保真仿真研究了全海深自主水下目标回收任务，验证了在极端深海环境下使用小型潜水器进行自主操作的可行性。


<details>
  <summary>Details</summary>
Motivation: 深海（尤其是超深渊带）环境极端，水压巨大、能见度低、存在海流干扰，且现场实验成本高、风险大、设备稀缺，难以对自主行为进行早期验证。

Method: 使用Stonefish仿真器模拟真实车辆动力学、水动力扰动、传感及与目标物体的交互；控制框架结合世界坐标系PID控制器（用于导航与稳定）和基于逆运动学的机械臂控制器（加入加速度前馈），实现载具与机械臂的协调操作。

Result: 仿真中，小型潜水器成功从海面下潜至6000米，完成结构化海底覆盖、目标检测，并利用吸附式末端执行器实现了自主回收。

Conclusion: 高保真仿真为深海干预自主行为提供了一种有效且低风险的先期验证手段，有助于降低实地部署的风险与成本。

Abstract: Autonomous object recovery in the hadal zone is challenging due to extreme hydrostatic pressure, limited visibility and currents, and the need for precise manipulation at full ocean depth. Field experimentation in such environments is costly, high-risk, and constrained by limited vehicle availability, making early validation of autonomous behaviors difficult. This paper presents a simulation-based study of a complete autonomous subsea object recovery mission using a Hadal Small Vehicle (HSV) equipped with a three-degree-of-freedom robotic arm and a suction-actuated end effector. The Stonefish simulator is used to model realistic vehicle dynamics, hydrodynamic disturbances, sensing, and interaction with a target object under hadal-like conditions. The control framework combines a world-frame PID controller for vehicle navigation and stabilization with an inverse-kinematics-based manipulator controller augmented by acceleration feed-forward, enabling coordinated vehicle - manipulator operation. In simulation, the HSV autonomously descends from the sea surface to 6,000 m, performs structured seafloor coverage, detects a target object, and executes a suction-based recovery. The results demonstrate that high-fidelity simulation provides an effective and low-risk means of evaluating autonomous deep-sea intervention behaviors prior to field deployment.

</details>


### [309] [Latent Space Reinforcement Learning for Multi-Robot Exploration](https://arxiv.org/abs/2601.01139)
*Sriram Rajasekar,Ashwini Ratnoo*

Main category: cs.RO

TL;DR: 提出一种基于自动编码器和分层深度强化学习的多智能体未知环境自主协作建图方法，通过潜在状态压缩和加权共识机制实现可扩展的分散式协调。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法受限于输入尺寸，难以处理连续复杂环境；多智能体系统的运动规划算法可扩展性不足，需要更高效的协作建图方案。

Method: 1) 使用自动编码器对高分辨率占据栅格地图进行降维，生成保留空间信息的潜在状态向量；2) 基于Perlin噪声设计程序化环境生成算法，模拟小行星带、洞穴等复杂地形；3) 采用分层深度强化学习框架训练分散式导航算法；4) 引入可调节信任参数的加权共识机制处理共享数据误差。

Result: 实验表明系统能随智能体数量有效扩展，在结构陌生的环境中泛化良好，且在通信受限条件下保持鲁棒性。

Conclusion: 所提方法突破了传统强化学习的输入限制，通过潜在表示学习和自适应共识机制，实现了多智能体在复杂未知环境中的高效协作建图。

Abstract: Autonomous mapping of unknown environments is a critical challenge, particularly in scenarios where time is limited. Multi-agent systems can enhance efficiency through collaboration, but the scalability of motion-planning algorithms remains a key limitation. Reinforcement learning has been explored as a solution, but existing approaches are constrained by the limited input size required for effective learning, restricting their applicability to discrete environments. This work addresses that limitation by leveraging autoencoders to perform dimensionality reduction, compressing high-fidelity occupancy maps into latent state vectors while preserving essential spatial information. Additionally, we introduce a novel procedural generation algorithm based on Perlin noise, designed to generate topologically complex training environments that simulate asteroid fields, caves and forests. These environments are used for training the autoencoder and the navigation algorithm using a hierarchical deep reinforcement learning framework for decentralized coordination. We introduce a weighted consensus mechanism that modulates reliance on shared data via a tuneable trust parameter, ensuring robustness to accumulation of errors. Experimental results demonstrate that the proposed system scales effectively with number of agents and generalizes well to unfamiliar, structurally distinct environments and is resilient in communication-constrained settings.

</details>


### [310] [VISO: Robust Underwater Visual-Inertial-Sonar SLAM with Photometric Rendering for Dense 3D Reconstruction](https://arxiv.org/abs/2601.01144)
*Shu Pan,Simon Archieri,Ahmet Cinar,Jonatan Scharff Willners,Ignacio Carlucho,Yvan Petillot*

Main category: cs.RO

TL;DR: 提出VISO系统，融合立体相机、IMU和3D声纳，实现水下6-DoF定位与高保真稠密重建，通过在线标定和声纳点云渲染提升性能。


<details>
  <summary>Details</summary>
Motivation: 水下环境的视觉挑战（如光线衰减、浑浊水体）严重影响视觉定位与稠密重建的精度，需多传感器融合提升鲁棒性。

Method: 1. 融合立体相机、IMU和3D声纳的SLAM框架；2. 粗到精的声纳-相机外参在线标定方法；3. 为声纳点云设计光度渲染策略以增强视觉信息。

Result: 在实验室水池和开放湖泊的实验中，VISO在定位鲁棒性和精度上超越现有水下/视觉SLAM算法，稠密3D重建性能媲美离线方法且支持实时运行。

Conclusion: 多传感器融合与在线标定策略能有效应对水下视觉退化问题，为水下高精度定位与实时稠密重建提供了可行方案。

Abstract: Visual challenges in underwater environments significantly hinder the accuracy of vision-based localisation and the high-fidelity dense reconstruction. In this paper, we propose VISO, a robust underwater SLAM system that fuses a stereo camera, an inertial measurement unit (IMU), and a 3D sonar to achieve accurate 6-DoF localisation and enable efficient dense 3D reconstruction with high photometric fidelity. We introduce a coarse-to-fine online calibration approach for extrinsic parameters estimation between the 3D sonar and the camera. Additionally, a photometric rendering strategy is proposed for the 3D sonar point cloud to enrich the sonar map with visual information. Extensive experiments in a laboratory tank and an open lake demonstrate that VISO surpasses current state-of-the-art underwater and visual-based SLAM algorithms in terms of localisation robustness and accuracy, while also exhibiting real-time dense 3D reconstruction performance comparable to the offline dense mapping method.

</details>


### [311] [ORION: Option-Regularized Deep Reinforcement Learning for Cooperative Multi-Agent Online Navigation](https://arxiv.org/abs/2601.01155)
*Zhang Shizhe,Liang Jingsong,Zhou Zhitao,Ye Shuhan,Wang Yizhuo,Tan Ming Siang Derek,Chiun Jimmy,Cao Yuhong,Sartoretti Guillaume*

Main category: cs.RO

TL;DR: ORION是一个基于深度强化学习的多智能体在线导航框架，用于部分已知环境中的协同导航，通过融合先验地图与在线感知、选项-评论家框架和双阶段协作策略，实现分散决策和地图不确定性降低。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体导航方法通常假设环境完全已知，难以适用于仓库或工厂等部分已知场景，需要平衡路径最优性与环境信息收集共享能力。

Method: 1. 设计共享图编码器融合先验地图与在线感知；2. 采用选项-评论家框架学习高层协作模式；3. 引入双阶段协作策略帮助队友减少地图不确定性。

Result: 在迷宫式地图和大规模仓库环境中，ORION实现了高质量实时分散协作，在不同团队规模下均优于现有经典方法和学习基线，并在物理机器人团队上验证了鲁棒性。

Conclusion: ORION能够有效解决部分已知环境中的多智能体协同导航问题，通过自适应切换个体导航与团队探索模式，显著降低整体任务完成时间，具备实际应用价值。

Abstract: Existing methods for multi-agent navigation typically assume fully known environments, offering limited support for partially known scenarios such as warehouses or factory floors. There, agents may need to plan trajectories that balance their own path optimality with their ability to collect and share information about the environment that can help their teammates reach their own goals. To these ends, we propose ORION, a novel deep reinforcement learning framework for cooperative multi-agent online navigation in partially known environments. Starting from an imperfect prior map, ORION trains agents to make decentralized decisions, coordinate to reach their individual targets, and actively reduce map uncertainty by sharing online observations in a closed perception-action loop. We first design a shared graph encoder that fuses prior map with online perception into a unified representation, providing robust state embeddings under dynamic map discrepancies. At the core of ORION is an option-critic framework that learns to reason about a set of high-level cooperative modes that translate into sequences of low-level actions, allowing agents to switch between individual navigation and team-level exploration adaptively. We further introduce a dual-stage cooperation strategy that enables agents to assist teammates under map uncertainty, thereby reducing the overall makespan. Across extensive maze-like maps and large-scale warehouse environments, our simulation results show that ORION achieves high-quality, real-time decentralized cooperation over varying team sizes, outperforming state-of-the-art classical and learning-based baselines. Finally, we validate ORION on physical robot teams, demonstrating its robustness and practicality for real-world cooperative navigation.

</details>


### [312] [DST-Calib: A Dual-Path, Self-Supervised, Target-Free LiDAR-Camera Extrinsic Calibration Network](https://arxiv.org/abs/2601.01188)
*Zhiwei Huang,Yanwei Fu,Yi Zhou,Xieyuanli Chen,Qijun Chen,Rui Fan*

Main category: cs.RO

TL;DR: 提出首个自监督的在线LiDAR-相机外参标定网络，无需特定标定目标，通过双面数据增强和差异图构建提升泛化能力和精度。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR-相机标定方法依赖手工标定目标或特定静态场景，限制了其在真实世界自主机器人应用中的适应性和部署能力。

Method: 提出双面数据增强技术生成多视角相机视图，设计双路径自监督标定框架，并采用差异图构建替代传统双分支特征提取以关联跨模态特征。

Result: 在五个公共基准数据集及自录数据集上的实验表明，该方法在泛化性方面显著优于现有方法。

Conclusion: 该方法实现了无需标定目标的在线自适应标定，通过增强训练鲁棒性和简化模型结构，有效提升了跨模态标定的实用性和准确性。

Abstract: LiDAR-camera extrinsic calibration is essential for multi-modal data fusion in robotic perception systems. However, existing approaches typically rely on handcrafted calibration targets (e.g., checkerboards) or specific, static scene types, limiting their adaptability and deployment in real-world autonomous and robotic applications. This article presents the first self-supervised LiDAR-camera extrinsic calibration network that operates in an online fashion and eliminates the need for specific calibration targets. We first identify a significant generalization degradation problem in prior methods, caused by the conventional single-sided data augmentation strategy. To overcome this limitation, we propose a novel double-sided data augmentation technique that generates multi-perspective camera views using estimated depth maps, thereby enhancing robustness and diversity during training. Built upon this augmentation strategy, we design a dual-path, self-supervised calibration framework that reduces the dependence on high-precision ground truth labels and supports fully adaptive online calibration. Furthermore, to improve cross-modal feature association, we replace the traditional dual-branch feature extraction design with a difference map construction process that explicitly correlates LiDAR and camera features. This not only enhances calibration accuracy but also reduces model complexity. Extensive experiments conducted on five public benchmark datasets, as well as our own recorded dataset, demonstrate that the proposed method significantly outperforms existing approaches in terms of generalizability.

</details>


### [313] [EduSim-LLM: An Educational Platform Integrating Large Language Models and Robotic Simulation for Beginners](https://arxiv.org/abs/2601.01196)
*Shenqi Lu,Liangwei Zhang*

Main category: cs.RO

TL;DR: 提出EduSim-LLM教育平台，通过大语言模型将自然语言指令转换为机器人可执行行为序列，在CoppeliaSim中实现语言驱动的机器人控制。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的发展为机器人领域带来新机遇，但自然语言理解与机器人控制的融合仍是重要挑战，阻碍了人类对复杂机器人系统的直观控制，限制了其教育和实际应用的可及性。

Method: 构建EduSim-LLM平台，集成LLMs与机器人仿真，设计直接控制和自主控制两种人机交互模型，基于多种语言模型进行系统仿真，评估多机器人协作、运动规划和操作能力，并应用提示工程模板提升性能。

Result: LLMs能可靠地将自然语言转换为结构化机器人动作；应用提示工程模板后指令解析准确率显著提升；在最高复杂度测试中，整体准确率超过88.9%。

Conclusion: 该平台成功验证了LLMs在机器人教育仿真中的有效性，通过语言驱动控制模型提高了复杂任务下机器人系统的可访问性和控制直观性。

Abstract: In recent years, the rapid development of Large Language Models (LLMs) has significantly enhanced natural language understanding and human-computer interaction, creating new opportunities in the field of robotics. However, the integration of natural language understanding into robotic control is an important challenge in the rapid development of human-robot interaction and intelligent automation industries. This challenge hinders intuitive human control over complex robotic systems, limiting their educational and practical accessibility. To address this, we present the EduSim-LLM, an educational platform that integrates LLMs with robot simulation and constructs a language-drive control model that translates natural language instructions into executable robot behavior sequences in CoppeliaSim. We design two human-robot interaction models: direct control and autonomous control, conduct systematic simulations based on multiple language models, and evaluate multi-robot collaboration, motion planning, and manipulation capabilities. Experiential results show that LLMs can reliably convert natural language into structured robot actions; after applying prompt-engineering templates instruction-parsing accuracy improves significantly; as task complexity increases, overall accuracy rate exceeds 88.9% in the highest complexity tests.

</details>


### [314] [SAHA: Supervised Autonomous HArvester for selective forest thinning](https://arxiv.org/abs/2601.01282)
*Fang Nan,Meher Malladi,Qingqing Li,Fan Yang,Joonas Juola,Tiziano Guadagnino,Jens Behley,Cesar Cadena,Cyrill Stachniss,Marco Hutter*

Main category: cs.RO

TL;DR: 本文介绍了一种用于森林选择性疏伐的小型机器人收割机SAHA，通过集成感知、规划和控制技术实现自主导航和作业，并在北欧森林中进行了实地测试。


<details>
  <summary>Details</summary>
Motivation: 森林管理中的选择性疏伐任务劳动密集且复杂，需要熟练操作员。为提高效率并减少人力依赖，研究开发了具备监督自主能力的机器人收割机。

Method: 基于4.5吨收割机平台进行硬件改造，实现感知和自动控制；结合学习和模型方法控制液压执行器、导航、状态估计和地形可通行性语义估计；集成先进的感知、规划和控制技术。

Result: 机器人收割机能够在杂乱森林环境中自主导航并定位目标树木进行选择性疏伐，通过北欧森林中长达数公里的自主任务实地试验验证了其可行性。

Conclusion: 该研究展示了机器人收割机在真实森林环境中作业的能力，通过性能分析和经验总结为推进机器人森林管理提供了实践基础。

Abstract: Forestry plays a vital role in our society, creating significant ecological, economic, and recreational value. Efficient forest management involves labor-intensive and complex operations. One essential task for maintaining forest health and productivity is selective thinning, which requires skilled operators to remove specific trees to create optimal growing conditions for the remaining ones. In this work, we present a solution based on a small-scale robotic harvester (SAHA) designed for executing this task with supervised autonomy. We build on a 4.5-ton harvester platform and implement key hardware modifications for perception and automatic control. We implement learning- and model-based approaches for precise control of hydraulic actuators, accurate navigation through cluttered environments, robust state estimation, and reliable semantic estimation of terrain traversability. Integrating state-of-the-art techniques in perception, planning, and control, our robotic harvester can autonomously navigate forest environments and reach targeted trees for selective thinning. We present experimental results from extensive field trials over kilometer-long autonomous missions in northern European forests, demonstrating the harvester's ability to operate in real forests. We analyze the performance and provide the lessons learned for advancing robotic forest management.

</details>


### [315] [Online Estimation and Manipulation of Articulated Objects](https://arxiv.org/abs/2601.01438)
*Russell Buchanan,Adrian Röfer,João Moura,Abhinav Valada,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 提出一种结合视觉先验与本体感知的在线关节估计方法，使机器人能通过视觉预测和交互传感自主操作未知关节物体。


<details>
  <summary>Details</summary>
Motivation: 家庭服务机器人需操作各类关节物体（如抽屉），现有方法或依赖视觉先验（无法适应动态变化），或需先具备操作能力（形成循环依赖）。需融合两类方法以实现高效自主操作。

Method: 基于因子图在线估计关节参数，融合学习到的视觉先验（接触前预测）与本体感知（交互中的运动学/力传感），结合螺旋理论构建解析模型。

Result: 在仿真和真实机器人实验中验证方法有效性，成功实现未见抽屉的闭环估计与操作，真实硬件实验中对未知关节物体的自主开启成功率达75%。

Conclusion: 所提融合方法能有效结合视觉与传感信息，使机器人仅通过单次交互即可准确估计关节参数，为家庭场景中关节物体的自动化操作提供可行方案。

Abstract: From refrigerators to kitchen drawers, humans interact with articulated objects effortlessly every day while completing household chores. For automating these tasks, service robots must be capable of manipulating arbitrary articulated objects. Recent deep learning methods have been shown to predict valuable priors on the affordance of articulated objects from vision. In contrast, many other works estimate object articulations by observing the articulation motion, but this requires the robot to already be capable of manipulating the object. In this article, we propose a novel approach combining these methods by using a factor graph for online estimation of articulation which fuses learned visual priors and proprioceptive sensing during interaction into an analytical model of articulation based on Screw Theory. With our method, a robotic system makes an initial prediction of articulation from vision before touching the object, and then quickly updates the estimate from kinematic and force sensing during manipulation. We evaluate our method extensively in both simulations and real-world robotic manipulation experiments. We demonstrate several closed-loop estimation and manipulation experiments in which the robot was capable of opening previously unseen drawers. In real hardware experiments, the robot achieved a 75% success rate for autonomous opening of unknown articulated objects.

</details>


### [316] [AIMS: An Adaptive Integration of Multi-Sensor Measurements for Quadrupedal Robot Localization](https://arxiv.org/abs/2601.01561)
*Yujian Qiu,Yuqiu Mu,Wen Yang,Hao Zhu*

Main category: cs.RO

TL;DR: 提出AIMS方法，一种自适应LiDAR-IMU-腿足里程计融合方法，用于四足机器人在狭窄隧道等退化环境中的鲁棒定位。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在狭窄隧道等长且同质的环境中运行时，LiDAR测量提供的几何约束较弱，传统传感器融合方法易受运动估计误差累积影响，导致定位不准确。

Method: 在误差状态卡尔曼滤波框架下，将LiDAR和腿足里程计测量与IMU状态预测融合，并基于在线退化感知可靠性评估自适应调整测量噪声协方差矩阵。

Result: 在狭窄走廊环境中的实验结果表明，该方法相比现有先进方法提高了定位精度和鲁棒性。

Conclusion: AIMS方法通过自适应传感器融合有效解决了四足机器人在退化环境中的定位问题，提升了在几何特征稀疏场景下的定位性能。

Abstract: This paper addresses the problem of accurate localization for quadrupedal robots operating in narrow tunnel-like environments. Due to the long and homogeneous characteristics of such scenarios, LiDAR measurements often provide weak geometric constraints, making traditional sensor fusion methods susceptible to accumulated motion estimation errors. To address these challenges, we propose AIMS, an adaptive LiDAR-IMU-leg odometry fusion method for robust quadrupedal robot localization in degenerate environments. The proposed method is formulated within an error-state Kalman filtering framework, where LiDAR and leg odometry measurements are integrated with IMU-based state prediction, and measurement noise covariance matrices are adaptively adjusted based on online degeneracy-aware reliability assessment. Experimental results obtained in narrow corridor environments demonstrate that the proposed method improves localization accuracy and robustness compared with state-of-the-art approaches.

</details>


### [317] [HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller](https://arxiv.org/abs/2601.01577)
*Tran Tien Dat,Nguyen Hai An,Nguyen Khanh Viet Dung,Nguyen Duy Duc*

Main category: cs.RO

TL;DR: 本文提出Hanoi-World，一种基于JEPA的世界模型，使用RNN进行长期规划，在自动驾驶控制中实现安全感知驾驶，相比SOTA基线降低碰撞率。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习用于自动驾驶控制器存在数据需求大、性能不稳定、难以确保安全、易受像素重建噪声影响的问题，而自监督学习中的JEPA方法模仿人脑通过想象和少量观察学习技能的能力，提供了有效替代方案。

Method: 采用基于JEPA的世界模型Hanoi-World，利用RNN进行长期水平规划，并在Highway-Env包的不同环境中进行实验验证。

Result: 实验表明，该方法能有效制定驾驶计划，具备安全感知能力，与SOTA基线相比碰撞率显著降低。

Conclusion: Hanoi-World模型通过JEPA和RNN结合，在自动驾驶控制中实现了高效、安全的长期规划，为数据需求大和安全性差的传统方法提供了改进方案。

Abstract: Current attempts of Reinforcement Learning for Autonomous Controller are data-demanding while the results are under-performed, unstable, and unable to grasp and anchor on the concept of safety, and over-concentrating on noise features due to the nature of pixel reconstruction. While current Self-Supervised Learningapproachs that learning on high-dimensional representations by leveraging the JointEmbedding Predictive Architecture (JEPA) are interesting and an effective alternative, as the idea mimics the natural ability of the human brain in acquiring new skill usingimagination and minimal samples of observations. This study introduces Hanoi-World, a JEPA-based world model that using recurrent neural network (RNN) formaking longterm horizontal planning with effective inference time. Experimentsconducted on the Highway-Env package with difference enviroment showcase the effective capability of making a driving plan while safety-awareness, with considerablecollision rate in comparison with SOTA baselines

</details>


### [318] [Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2601.01618)
*Huajie Tan,Peterson Co,Yijie Xu,Shanyu Rong,Yuheng Ji,Cheng Chi,Xiansheng Chen,Qiongyu Zhang,Zhongxia Zhao,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 本文提出Action-Sketcher框架，通过视觉草图（Visual Sketch）作为中间表示，将空间意图外部化，以提升长时程机器人操作在复杂场景中的性能、鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端或分层的视觉-语言-动作（VLA）策略通常依赖纯文本线索且保持规划意图隐式，导致在杂乱或未充分指定的场景中参照性接地不足，难以有效分解长时程目标，并缺乏动作选择的因果解释。

Method: 引入视觉草图（Visual Sketch）作为视觉中间表示，渲染点、框、箭头和类型化关系以连接语言与场景几何；提出Action-Sketcher框架，采用由自适应令牌门控策略协调的See-Think-Sketch-Act循环工作流；通过多阶段课程学习（包括交错序列对齐、语言-草图一致性、模仿学习与草图到动作强化学习）进行训练。

Result: 在仿真和真实世界任务中，于杂乱场景和多对象任务上实验表明，该方法提高了长时程任务成功率，增强了对动态场景变化的鲁棒性，并通过可编辑草图和分步计划提升了可解释性。

Conclusion: Action-Sketcher通过视觉草图外部化空间意图，有效解决了长时程机器人操作中的接地、分解和解释性问题，为复杂交互任务提供了更可靠、可解释的解决方案。

Abstract: Long-horizon robotic manipulation is increasingly important for real-world deployment, requiring spatial disambiguation in complex layouts and temporal resilience under dynamic interaction. However, existing end-to-end and hierarchical Vision-Language-Action (VLA) policies often rely on text-only cues while keeping plan intent latent, which undermines referential grounding in cluttered or underspecified scenes, impedes effective task decomposition of long-horizon goals with close-loop interaction, and limits causal explanation by obscuring the rationale behind action choices. To address these issues, we first introduce Visual Sketch, an implausible visual intermediate that renders points, boxes, arrows, and typed relations in the robot's current views to externalize spatial intent, connect language to scene geometry. Building on Visual Sketch, we present Action-Sketcher, a VLA framework that operates in a cyclic See-Think-Sketch-Act workflow coordinated by adaptive token-gated strategy for reasoning triggers, sketch revision, and action issuance, thereby supporting reactive corrections and human interaction while preserving real-time action prediction. To enable scalable training and evaluation, we curate diverse corpus with interleaved images, text, Visual Sketch supervision, and action sequences, and train Action-Sketcher with a multi-stage curriculum recipe that combines interleaved sequence alignment for modality unification, language-to-sketch consistency for precise linguistic grounding, and imitation learning augmented with sketch-to-action reinforcement for robustness. Extensive experiments on cluttered scenes and multi-object tasks, in simulation and on real-world tasks, show improved long-horizon success, stronger robustness to dynamic scene changes, and enhanced interpretability via editable sketches and step-wise plans. Project website: https://action-sketcher.github.io

</details>


### [319] [DemoBot: Efficient Learning of Bimanual Manipulation with Dexterous Hands From Third-Person Human Videos](https://arxiv.org/abs/2601.01651)
*Yucheng Xu,Xiaofeng Mao,Elle Miller,Xinyu Yi,Yang Li,Zhibin Li,Robert B. Fisher*

Main category: cs.RO

TL;DR: DemoBot框架让双臂多指机器人通过单次RGB-D视频演示学习复杂操作技能，无需人工标注，结合视频轨迹提取与强化学习优化，实现了长时程双手装配任务。


<details>
  <summary>Details</summary>
Motivation: 传统机器人技能学习常需大量标注数据或从零开始训练，效率低下。本文旨在通过单次未标注视频演示，让机器人直接学习人类复杂操作技能，提高学习效率与可扩展性。

Method: 1. 从原始RGB-D视频提取手与物体的结构化运动轨迹作为运动先验；2. 设计强化学习流程，通过接触式交互优化轨迹；3. 提出时序分段RL确保状态与演示对齐；4. 采用成功门控重置策略平衡技能学习与探索；5. 设计事件驱动奖励课程与自适应阈值引导高精度操作学习。

Result: 框架成功实现了长时程同步与异步双手装配任务，验证了从人类视频直接获取复杂操作技能的可行性，且无需从零学习或大量标注数据。

Conclusion: DemoBot提供了一种可扩展的方法，使机器人能够通过单次未标注视频演示高效学习复杂操作技能，为从人类演示中直接获取机器人技能开辟了新途径。

Abstract: This work presents DemoBot, a learning framework that enables a dual-arm, multi-finger robotic system to acquire complex manipulation skills from a single unannotated RGB-D video demonstration. The method extracts structured motion trajectories of both hands and objects from raw video data. These trajectories serve as motion priors for a novel reinforcement learning (RL) pipeline that learns to refine them through contact-rich interactions, thereby eliminating the need to learn from scratch. To address the challenge of learning long-horizon manipulation skills, we introduce: (1) Temporal-segment based RL to enforce temporal alignment of the current state with demonstrations; (2) Success-Gated Reset strategy to balance the refinement of readily acquired skills and the exploration of subsequent task stages; and (3) Event-Driven Reward curriculum with adaptive thresholding to guide the RL learning of high-precision manipulation. The novel video processing and RL framework successfully achieved long-horizon synchronous and asynchronous bimanual assembly tasks, offering a scalable approach for direct skill acquisition from human videos.

</details>


### [320] [VisuoTactile 6D Pose Estimation of an In-Hand Object using Vision and Tactile Sensor Data](https://arxiv.org/abs/2601.01675)
*Snehal s. Dikhale,Karankumar Patel,Daksh Dhingra,Itoshi Naramura,Akinobu Hayashi,Soshi Iba,Nawid Jamali*

Main category: cs.RO

TL;DR: 提出了一种结合视觉和触觉数据估计机器人手中物体6D姿态的方法，使用点云表示触觉接触表面，通过像素级密集融合网络架构实现传感器融合，并在合成数据训练后成功泛化到真实机器人场景。


<details>
  <summary>Details</summary>
Motivation: 机器人手内物体6D姿态估计因夹爪遮挡导致纯视觉方法效果受限，而许多机器人配备的指尖触觉传感器可作为视觉数据的补充，但缺乏触觉数据标准表示和传感器融合方法。

Method: 使用点云表示触觉传感器接触的物体表面；提出基于像素级密集融合的网络架构；扩展NVIDIA深度学习数据集合成器生成合成视觉数据及对应触觉点云。

Result: 实验表明，结合触觉数据能提升6D姿态估计精度；所提网络能从合成训练数据成功泛化到真实物理机器人。

Conclusion: 触觉数据可有效补充视觉数据以改善手内物体6D姿态估计，提出的点云表示和融合架构具有实际应用价值，且合成到真实的泛化能力验证了方法的可行性。

Abstract: Knowledge of the 6D pose of an object can benefit in-hand object manipulation. In-hand 6D object pose estimation is challenging because of heavy occlusion produced by the robot's grippers, which can have an adverse effect on methods that rely on vision data only. Many robots are equipped with tactile sensors at their fingertips that could be used to complement vision data. In this paper, we present a method that uses both tactile and vision data to estimate the pose of an object grasped in a robot's hand. To address challenges like lack of standard representation for tactile data and sensor fusion, we propose the use of point clouds to represent object surfaces in contact with the tactile sensor and present a network architecture based on pixel-wise dense fusion. We also extend NVIDIA's Deep Learning Dataset Synthesizer to produce synthetic photo-realistic vision data and corresponding tactile point clouds. Results suggest that using tactile data in addition to vision data improves the 6D pose estimate, and our network generalizes successfully from synthetic training to real physical robots.

</details>


### [321] [Explicit World Models for Reliable Human-Robot Collaboration](https://arxiv.org/abs/2601.01705)
*Kenneth Kwok,Basura Fernando,Qianli Xu,Vigneshwaran Subbaraju,Dongkyu Choi,Boon Kiat Quek*

Main category: cs.RO

TL;DR: 本文提出了一种以构建和更新可访问的“显式世界模型”为中心的新方法，旨在实现可靠的具身人工智能，强调在人类-机器人交互中动态、模糊和主观的特性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决具身AI在感知噪声、模糊指令和人类-机器人交互中的鲁棒性问题，强调传统形式化验证方法在应对人类环境的社会性、多模态和流动性方面的不足。

Method: 采用以构建和更新可访问的“显式世界模型”为核心的方法，该模型代表人类与AI之间的共同基础，用于使机器人行为与人类期望保持一致。

Result: 提出了一种根本不同的可靠具身AI实现路径，强调可靠性是情境决定的，仅在交互中人类的目标和期望相关时才有意义。

Conclusion: 结论认为，在人类环境中，可靠的具身AI需要专注于感知、解释和响应人类意图，确保行为一致、可理解且符合人类期望，而非单纯追求模型可预测性和鲁棒性。

Abstract: This paper addresses the topic of robustness under sensing noise, ambiguous instructions, and human-robot interaction. We take a radically different tack to the issue of reliable embodied AI: instead of focusing on formal verification methods aimed at achieving model predictability and robustness, we emphasise the dynamic, ambiguous and subjective nature of human-robot interactions that requires embodied AI systems to perceive, interpret, and respond to human intentions in a manner that is consistent, comprehensible and aligned with human expectations. We argue that when embodied agents operate in human environments that are inherently social, multimodal, and fluid, reliability is contextually determined and only has meaning in relation to the goals and expectations of humans involved in the interaction. This calls for a fundamentally different approach to achieving reliable embodied AI that is centred on building and updating an accessible "explicit world model" representing the common ground between human and AI, that is used to align robot behaviours with human expectations.

</details>


### [322] [Simulations and Advancements in MRI-Guided Power-Driven Ferric Tools for Wireless Therapeutic Interventions](https://arxiv.org/abs/2601.01726)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.RO

TL;DR: 开发了一种用于MRI引导下血管内介入的机器人辅助系统，通过图像处理、虚拟路径规划和磁场梯度控制来提升手术精度和安全性。


<details>
  <summary>Details</summary>
Motivation: MRI扫描仪环境下的机器人系统需克服强磁场干扰，以提升MRI在血管介入手术中的引导能力，解决现有技术中精度与安全性不足的问题。

Method: 基于Qt框架和C/C++开发集成系统，包括计算单元和人机界面；通过处理MRI图像重建血管网络，建立虚拟路径与边界；设计定制化磁场梯度模式控制器械，并考虑血管几何形状、安全规范和血流特性进行自适应导航。

Result: 系统能生成针对血管几何形状和安全规范的定制化磁场梯度模式，适应不同血流条件以实现精细导航；建模功能可评估预设血管路径的安全性与可行性。

Conclusion: 该系统实现了影像技术与机器人辅助的深度融合，显著提高了血管内介入手术的精确度和安全性，是医疗机器人领域的重要进展。

Abstract: Designing a robotic system that functions effectively within the specific environment of a Magnetic Resonance Imaging (MRI) scanner requires solving numerous technical issues, such as maintaining the robot's precision and stability under strong magnetic fields. This research focuses on enhancing MRI's role in medical imaging, especially in its application to guide intravascular interventions using robot-assisted devices. A newly developed computational system is introduced, designed for seamless integration with the MRI scanner, including a computational unit and user interface. This system processes MR images to delineate the vascular network, establishing virtual paths and boundaries within vessels to prevent procedural damage. Key findings reveal the system's capability to create tailored magnetic field gradient patterns for device control, considering the vessel's geometry and safety norms, and adapting to different blood flow characteristics for finer navigation. Additionally, the system's modeling aspect assesses the safety and feasibility of navigating pre-set vascular paths. Conclusively, this system, based on the Qt framework and C/C++, with specialized software modules, represents a major step forward in merging imaging technology with robotic aid, significantly enhancing precision and safety in intravascular procedures.

</details>


### [323] [AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2601.01762)
*Yanhao Wu,Haoyang Zhang,Fei He,Rui Wu,Congpei Qiu,Liang Gao,Wei Ke,Tong Zhang*

Main category: cs.RO

TL;DR: 提出一种级联框架，通过将纵向规划显式地建立在驾驶路径上，实现协调的横向与纵向规划，提升自动驾驶的安全性和协调性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶模型在规划阶段并行处理横向和纵向预测，可能导致路径与速度协调失败，且未充分利用驾驶路径作为纵向规划的先验信息，造成静态信息冗余编码。

Method: 提出路径条件化公式，将驾驶路径显式纳入纵向规划；模型沿驾驶路径预测纵向位移而非完整2D轨迹点；引入面向规划的数据增强策略，模拟车辆切入等安全关键事件。

Result: 在Bench2Drive基准测试中，驾驶分数达89.07，成功率73.18%，创下新SOTA，显著提升了协调性和安全性。

Conclusion: 级联框架通过路径条件化纵向规划，有效解决了并行设计中的协调问题，简化了纵向推理，并增强了与横向规划的耦合，提高了自动驾驶系统的整体性能。

Abstract: End-to-end autonomous driving has rapidly progressed, enabling joint perception and planning in complex environments. In the planning stage, state-of-the-art (SOTA) end-to-end autonomous driving models decouple planning into parallel lateral and longitudinal predictions. While effective, this parallel design can lead to i) coordination failures between the planned path and speed, and ii) underutilization of the drive path as a prior for longitudinal planning, thus redundantly encoding static information. To address this, we propose a novel cascaded framework that explicitly conditions longitudinal planning on the drive path, enabling coordinated and collision-aware lateral and longitudinal planning. Specifically, we introduce a path-conditioned formulation that explicitly incorporates the drive path into longitudinal planning. Building on this, the model predicts longitudinal displacements along the drive path rather than full 2D trajectory waypoints. This design simplifies longitudinal reasoning and more tightly couples it with lateral planning. Additionally, we introduce a planning-oriented data augmentation strategy that simulates rare safety-critical events, such as vehicle cut-ins, by adding agents and relabeling longitudinal targets to avoid collision. Evaluated on the challenging Bench2Drive benchmark, our method sets a new SOTA, achieving a driving score of 89.07 and a success rate of 73.18%, demonstrating significantly improved coordination and safety

</details>


### [324] [DisCo-FLoc: Using Dual-Level Visual-Geometric Contrasts to Disambiguate Depth-Aware Visual Floorplan Localization](https://arxiv.org/abs/2601.01822)
*Shiyong Meng,Tao Zou,Bolei Chen,Chaoxu Mu,Jianxin Wang*

Main category: cs.RO

TL;DR: 提出DisCo-FLoc方法，通过双层次视觉-几何对比解决简约平面图中重复结构导致的定位模糊问题，无需额外语义标注，在精度和鲁棒性上超越现有语义方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉平面图定位方法依赖几何先验或稀疏语义，但简约平面图中的重复结构易导致定位模糊，且语义标注成本高、覆盖有限，限制了应用范围。

Method: 1. 设计基于光线投射的射线回归预测器，利用深度估计生成候选定位；2. 提出位置层和方向层双重约束的对比学习方法，将深度感知视觉特征与平面图几何结构严格匹配。

Result: 在两个标准视觉平面图定位基准测试中，本方法在鲁棒性和准确性上均显著优于当前最先进的语义方法。

Conclusion: DisCo-FLoc通过无监督的双层次对比学习有效消除定位模糊，证明了深度感知特征与几何结构匹配在视觉平面图定位中的优越性。

Abstract: Since floorplan data is readily available, long-term persistent, and robust to changes in visual appearance, visual Floorplan Localization (FLoc) has garnered significant attention. Existing methods either ingeniously match geometric priors or utilize sparse semantics to reduce FLoc uncertainty. However, they still suffer from ambiguous FLoc caused by repetitive structures within minimalist floorplans. Moreover, expensive but limited semantic annotations restrict their applicability. To address these issues, we propose DisCo-FLoc, which utilizes dual-level visual-geometric Contrasts to Disambiguate depth-aware visual Floc, without requiring additional semantic labels. Our solution begins with a ray regression predictor tailored for ray-casting-based FLoc, predicting a series of FLoc candidates using depth estimation expertise. In addition, a novel contrastive learning method with position-level and orientation-level constraints is proposed to strictly match depth-aware visual features with the corresponding geometric structures in the floorplan. Such matches can effectively eliminate FLoc ambiguity and select the optimal imaging pose from FLoc candidates. Exhaustive comparative studies on two standard visual Floc benchmarks demonstrate that our method outperforms the state-of-the-art semantic-based method, achieving significant improvements in both robustness and accuracy.

</details>


### [325] [CausalNav: A Long-term Embodied Navigation System for Autonomous Mobile Robots in Dynamic Outdoor Scenarios](https://arxiv.org/abs/2601.01872)
*Hongbo Duan,Shangyi Luo,Zhiyuan Deng,Yanbo Chen,Yuanhao Chiang,Yi Liu,Fangming Liu,Xueqian Wang*

Main category: cs.RO

TL;DR: 提出了CausalNav，首个基于场景图的语义导航框架，专为动态户外环境设计，通过多层级语义场景图实现开放词汇查询下的语义导航与长程规划。


<details>
  <summary>Details</summary>
Motivation: 大规模户外环境中的自主语言引导导航面临语义推理困难、动态条件变化和长期稳定性等挑战，需要一种能适应动态环境且支持语义理解的导航方法。

Method: 使用LLM构建多层级语义场景图（Embodied Graph），融合粗粒度地图数据与细粒度物体实体；采用检索增强生成（RAG）作为知识库；在场景图构建和分层规划模块中显式处理动态物体；通过时间窗口持续更新场景图。

Result: 在仿真和真实环境中的大量实验表明，该方法具有优越的鲁棒性和效率。

Conclusion: CausalNav框架通过动态更新的语义场景图，实现了动态户外环境中开放词汇查询下的鲁棒语义导航，为语言引导的移动机器人导航提供了有效解决方案。

Abstract: Autonomous language-guided navigation in large-scale outdoor environments remains a key challenge in mobile robotics, due to difficulties in semantic reasoning, dynamic conditions, and long-term stability. We propose CausalNav, the first scene graph-based semantic navigation framework tailored for dynamic outdoor environments. We construct a multi-level semantic scene graph using LLMs, referred to as the Embodied Graph, that hierarchically integrates coarse-grained map data with fine-grained object entities. The constructed graph serves as a retrievable knowledge base for Retrieval-Augmented Generation (RAG), enabling semantic navigation and long-range planning under open-vocabulary queries. By fusing real-time perception with offline map data, the Embodied Graph supports robust navigation across varying spatial granularities in dynamic outdoor environments. Dynamic objects are explicitly handled in both the scene graph construction and hierarchical planning modules. The Embodied Graph is continuously updated within a temporal window to reflect environmental changes and support real-time semantic navigation. Extensive experiments in both simulation and real-world settings demonstrate superior robustness and efficiency.

</details>


### [326] [From Metrics to Meaning: Insights from a Mixed-Methods Field Experiment on Retail Robot Deployment](https://arxiv.org/abs/2601.01946)
*Sichao Song,Yuki Okafuji,Takuya Iwamoto,Jun Baba,Hiroshi Ishiguro*

Main category: cs.RO

TL;DR: 在床品店进行的现场实验表明，服务机器人虽能吸引顾客驻足，但会降低店员后续接触和销售转化率，主要因机器人对话干扰、时机把握困难及儿童吸引力等因素。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索在需要高接触服务的零售环境中，部署对话式服务机器人对顾客行为链（从路过到购买）的实际影响，以及机器人如何改变店员与顾客的互动模式。

Method: 采用混合方法：在12天的现场实验中交替设置无机器人、仅机器人、机器人+展示装置三种条件，通过视频标注分析服务漏斗数据；随后通过6次店员访谈进行解释性顺序设计，解读定量结果。

Result: 机器人提高了路人驻足率（展示装置下最高），但店员主导的后续步骤（接近、进店、协助体验、购买）均减少。访谈揭示原因：店员避免打断机器人对话、难以把握介入时机、机器人主要吸引儿童且常在门口满足好奇心。展示装置虽增强可见性，但也将互动锚定在门口，形成封闭的微空间。

Conclusion: 研究提出了从顾客兴趣产生到进店的整合解释框架，为高接触零售场景的机器人部署提供实践指导，揭示了机器人、顾客与店员三方互动的复杂动态。

Abstract: We report a mixed-methods field experiment of a conversational service robot deployed under everyday staffing discretion in a live bedding store. Over 12 days we alternated three conditions--Baseline (no robot), Robot-only, and Robot+Fixture--and video-annotated the service funnel from passersby to purchase. An explanatory sequential design then used six post-experiment staff interviews to interpret the quantitative patterns.
  Quantitatively, the robot increased stopping per passerby (highest with the fixture), yet clerk-led downstream steps per stopper--clerk approach, store entry, assisted experience, and purchase--decreased. Interviews explained this divergence: clerks avoided interrupting ongoing robot-customer talk, struggled with ambiguous timing amid conversational latency, and noted child-centered attraction that often satisfied curiosity at the doorway. The fixture amplified visibility but also anchored encounters at the threshold, creating a well-defined micro-space where needs could ``close'' without moving inside.
  We synthesize these strands into an integrative account from the initial show of interest on the part of a customer to their entering the store and derive actionable guidance. The results advance the understanding of interactions between customers, staff members, and the robot and offer practical recommendations for deploying service robots in high-touch retail.

</details>


### [327] [Learning Diffusion Policy from Primitive Skills for Robot Manipulation](https://arxiv.org/abs/2601.01948)
*Zhihao Gu,Ming Yang,Difan Zou,Dong Xu*

Main category: cs.RO

TL;DR: 本文提出SDP，一种技能条件扩散策略，通过将可解释的原始技能学习与条件动作规划相结合，解决现有扩散策略在机器人操作中因依赖全局指令导致动作生成错位的问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略常依赖全局指令生成短期控制信号，易导致动作生成错位。作者认为细粒度、短时域的原始技能（如“向上移动”“打开夹爪”）为机器人学习提供了更直观有效的接口。

Method: SDP抽象出8个跨任务可复用的原始技能，利用视觉语言模型从视觉观察和语言指令中提取离散表示，设计轻量级路由网络为每个状态分配期望原始技能，构建单技能策略以生成技能对齐的动作。

Result: 在两个具有挑战性的仿真基准测试和真实机器人部署中，SDP均持续超越最先进方法，验证了其有效性。

Conclusion: SDP通过将复杂任务分解为原始技能序列并选择单技能策略，确保了跨任务的技能一致性行为，为基于技能的扩散策略机器人学习提供了新范式。

Abstract: Diffusion policies (DP) have recently shown great promise for generating actions in robotic manipulation. However, existing approaches often rely on global instructions to produce short-term control signals, which can result in misalignment in action generation. We conjecture that the primitive skills, referred to as fine-grained, short-horizon manipulations, such as ``move up'' and ``open the gripper'', provide a more intuitive and effective interface for robot learning. To bridge this gap, we propose SDP, a skill-conditioned DP that integrates interpretable skill learning with conditional action planning. SDP abstracts eight reusable primitive skills across tasks and employs a vision-language model to extract discrete representations from visual observations and language instructions. Based on them, a lightweight router network is designed to assign a desired primitive skill for each state, which helps construct a single-skill policy to generate skill-aligned actions. By decomposing complex tasks into a sequence of primitive skills and selecting a single-skill policy, SDP ensures skill-consistent behavior across diverse tasks. Extensive experiments on two challenging simulation benchmarks and real-world robot deployments demonstrate that SDP consistently outperforms SOTA methods, providing a new paradigm for skill-based robot learning with diffusion policies.

</details>


### [328] [What you reward is what you learn: Comparing rewards for online speech policy optimization in public HRI](https://arxiv.org/abs/2601.01969)
*Sichao Song,Yuki Okafuji,Kaito Ariu,Amy Koike*

Main category: cs.RO

TL;DR: 研究通过12天实地部署，使用多臂老虎机框架在线优化社交机器人的语音策略（语速和详细程度），比较三种奖励信号对交互行为的影响，并为实际部署提供设计指导。


<details>
  <summary>Details</summary>
Motivation: 在开放多样的环境中，为对话服务机器人设计既高效又可接受的政策具有挑战性，需要适应非平稳条件，而在线学习能提供这种适应性。

Method: 将在线策略优化建模为多臂老虎机问题，使用Thompson采样从6种动作（语速×详细程度组合）中选择；在12天实地部署中收集1400多次交互数据，比较三种二元奖励（用户评分、对话结束、多轮对话）；辅以基于视频标注的离线上下文分析。

Result: 不同奖励信号（Ru、Rc、Rt）诱导出不同的动作分布和交互行为；离线分析揭示了人群密度、小组规模等上下文因素对策略选择的影响。

Conclusion: 研究为在实际公共人机交互场景中部署语音策略的在线优化提供了可直接应用的设计经验，证明了在线学习方法在动态环境中的有效性。

Abstract: Designing policies that are both efficient and acceptable for conversational service robots in open and diverse environments is non-trivial. Unlike fixed, hand-tuned parameters, online learning can adapt to non-stationary conditions. In this paper, we study how to adapt a social robot's speech policy in the wild. During a 12-day in-situ deployment with over 1,400 public encounters, we cast online policy optimization as a multi-armed bandit problem and use Thompson sampling to select among six actions defined by speech rate (slow/normal/fast) and verbosity (concise/detailed). We compare three complementary binary rewards--Ru (user rating), Rc (conversation closure), and Rt (>=2 turns)--and show that each induces distinct arm distributions and interaction behaviors. We complement the online results with offline evaluations that analyze contextual factors (e.g., crowd level, group size) using video-annotated data. Taken together, we distill ready-to-use design lessons for deploying online optimization of speech policies in real public HRI settings.

</details>


### [329] [Deep Robust Koopman Learning from Noisy Data](https://arxiv.org/abs/2601.01971)
*Aditya Singh,Rajpal Singh,Jishnu Keshavan*

Main category: cs.RO

TL;DR: 提出一种基于自编码器的神经网络架构，用于从噪声数据中联合学习提升函数和降偏Koopman算子，提高非线性系统线性表示的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实数据常含噪声，导致传统Koopman算子近似存在噪声诱导偏差，严重影响预测和跟踪性能。

Method: 设计自编码器架构，先学习系统前向/后向时序动态一致的Koopman基函数，再利用学到的动态合成降偏Koopman算子。

Result: 理论分析证明训练噪声下偏差显著降低；多机械臂仿真显示其在各种噪声水平下的鲁棒性优于现有方法；Franka FR3七自由度机械臂实验验证了实用性。

Conclusion: 所提方法能有效降低噪声引起的偏差，提升Koopman算子在噪声环境下的预测与控制性能。

Abstract: Koopman operator theory has emerged as a leading data-driven approach that relies on a judicious choice of observable functions to realize global linear representations of nonlinear systems in the lifted observable space. However, real-world data is often noisy, making it difficult to obtain an accurate and unbiased approximation of the Koopman operator. The Koopman operator generated from noisy datasets is typically corrupted by noise-induced bias that severely degrades prediction and downstream tracking performance. In order to address this drawback, this paper proposes a novel autoencoder-based neural architecture to jointly learn the appropriate lifting functions and the reduced-bias Koopman operator from noisy data. The architecture initially learns the Koopman basis functions that are consistent for both the forward and backward temporal dynamics of the system. Subsequently, by utilizing the learned forward and backward temporal dynamics, the Koopman operator is synthesized with a reduced bias making the method more robust to noise compared to existing techniques. Theoretical analysis is used to demonstrate significant bias reduction in the presence of training noise. Dynamics prediction and tracking control simulations are conducted for multiple serial manipulator arms, including performance comparisons with leading alternative designs, to demonstrate its robustness under various noise levels. Experimental studies with the Franka FR3 7-DoF manipulator arm are further used to demonstrate the effectiveness of the proposed approach in a practical setting.

</details>


### [330] [Genie Sim 3.0 : A High-Fidelity Comprehensive Simulation Platform for Humanoid Robot](https://arxiv.org/abs/2601.02078)
*Chenghao Yin,Da Huang,Di Yang,Jichao Wang,Nanshu Zhao,Chen Xu,Wenjun Sun,Linjie Hou,Zhijun Li,Junhui Wu,Zhaobo Liu,Zhen Xiao,Sheng Zhang,Lei Bao,Rui Feng,Zhenquan Pang,Jiayu Li,Qian Wang,Maoqing Yao*

Main category: cs.RO

TL;DR: 提出Genie Sim 3.0统一机器人操作仿真平台，利用LLM生成高保真场景，创建首个LLM自动化评估基准，并发布包含200多项任务的开源数据集，验证了合成数据在可控条件下可替代真实数据用于策略训练。


<details>
  <summary>Details</summary>
Motivation: 机器人学习模型需要大规模多样化训练数据和可靠评估基准，但真实数据收集成本高、仿真平台常存在碎片化、范围窄或保真度不足等问题，限制了仿真到现实的迁移效果。

Method: 1. 开发Genie Sim Generator（LLM驱动工具），通过自然语言指令构建高保真场景；2. 创建首个基于LLM的自动化评估基准，利用LLM批量生成评估场景，结合VLM建立自动评估流程；3. 发布开源数据集（超10,000小时合成数据，覆盖200多项任务）。

Result: 系统实验验证了开源数据集具备强大的零样本仿真到现实迁移能力，表明在可控条件下合成数据可有效替代真实数据用于可扩展的策略训练。

Conclusion: Genie Sim 3.0平台通过LLM驱动的场景生成和自动化评估，解决了机器人学习数据稀缺和评估标准化问题，为可扩展的机器人策略训练提供了高效解决方案。

Abstract: The development of robust and generalizable robot learning models is critically contingent upon the availability of large-scale, diverse training data and reliable evaluation benchmarks. Collecting data in the physical world poses prohibitive costs and scalability challenges, and prevailing simulation benchmarks frequently suffer from fragmentation, narrow scope, or insufficient fidelity to enable effective sim-to-real transfer. To address these challenges, we introduce Genie Sim 3.0, a unified simulation platform for robotic manipulation. We present Genie Sim Generator, a large language model (LLM)-powered tool that constructs high-fidelity scenes from natural language instructions. Its principal strength resides in rapid and multi-dimensional generalization, facilitating the synthesis of diverse environments to support scalable data collection and robust policy evaluation. We introduce the first benchmark that pioneers the application of LLM for automated evaluation. It leverages LLM to mass-generate evaluation scenarios and employs Vision-Language Model (VLM) to establish an automated assessment pipeline. We also release an open-source dataset comprising more than 10,000 hours of synthetic data across over 200 tasks. Through systematic experimentation, we validate the robust zero-shot sim-to-real transfer capability of our open-source dataset, demonstrating that synthetic data can server as an effective substitute for real-world data under controlled conditions for scalable policy training. For code and dataset details, please refer to: https://github.com/AgibotTech/genie_sim.

</details>


### [331] [Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots](https://arxiv.org/abs/2601.02085)
*Meili Sun,Chunjiang Zhao,Lichao Yang,Hao Liu,Shimin Hu,Ya Xiong*

Main category: cs.RO

TL;DR: 本文提出了一种草莓采摘机器人的视觉故障诊断与自恢复框架，通过SRR-Net多任务感知模型和纠错控制策略，解决了视觉感知不统一、抓取错位、空抓和果实滑落等问题，提升了采摘稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: 草莓采摘机器人在果园环境中面临视觉感知集成度低、果实与夹爪错位、空抓、抓握力不足导致果实滑落等问题，影响了采摘的稳定性和效率。

Method: 提出了一个集成多任务感知与纠错控制的视觉故障诊断与自恢复框架，核心是SRR-Net端到端多任务感知模型，同时进行草莓检测、分割和成熟度估计；设计了基于目标-夹爪同步检测的相对误差补偿方法以纠正位置偏差；采用提前中止策略应对空抓和果实滑落；利用末端执行器中的微型光学相机实时反馈，通过MobileNet V3-Small和LSTM分类器进行抓取检测和滑落预测。

Result: SRR-Net在检测任务中，对草莓的精确率为0.895、召回率为0.813，对手部的精确率为0.972、召回率为0.958；在分割任务中，对草莓的精确率为0.887、召回率为0.747，对手部的精确率为0.974、召回率为0.947；在成熟度估计中，平均绝对误差为0.035；同时支持多任务感知，推理速度达到163.35 FPS。

Conclusion: 该框架有效提升了草莓采摘机器人的视觉感知统一性和采摘稳定性，通过集成故障诊断与自恢复机制，显著提高了机器人在复杂果园环境中的作业效率和可靠性。

Abstract: Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.

</details>


### [332] [SingingBot: An Avatar-Driven System for Robotic Face Singing Performance](https://arxiv.org/abs/2601.02125)
*Zhuoxiong Xu,Xuanchen Li,Yuhao Cheng,Fei Xu,Yichao Yan,Xiaokang Yang*

Main category: cs.RO

TL;DR: 提出一种新颖的虚拟形象驱动框架，用于实现具有丰富情感表达的机器人歌唱表演，通过生成生动的歌唱虚拟形象并映射到机器人面部，显著提升了歌唱时的情感连续性与表现力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人面部驱动研究主要集中于对话或静态表情模仿，难以满足歌唱时对连续情感表达与一致性的高要求，因此需要开发能够支持富有情感感染力的机器人歌唱的方法。

Method: 首先利用嵌入丰富人类先验的肖像视频生成模型合成生动的歌唱虚拟形象，提供可靠的表情与情感引导；随后通过面向语义的映射函数将这些面部特征转移到机器人上，覆盖广泛的表情空间；并提出情感动态范围指标以量化评估机器人歌唱的情感丰富度。

Result: 综合实验表明，该方法在保持唇部-音频同步的同时实现了丰富的情感表达，在情感表现力上显著优于现有方法。

Conclusion: 所提出的虚拟形象驱动框架能够有效提升机器人歌唱的情感表现力，宽泛的情感频谱对于吸引人的表演至关重要，为 empathetic 人机交互提供了新的技术支持。

Abstract: Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.

</details>


### [333] [Differential Barometric Altimetry for Submeter Vertical Localization and Floor Recognition Indoors](https://arxiv.org/abs/2601.02184)
*Yuhang Zhang,Sören Schwertfeger*

Main category: cs.RO

TL;DR: 提出了一种基于差分气压传感的低成本垂直估计框架，用于移动机器人在多层环境中的精确定位，实现了亚米级垂直精度和100%楼层识别。


<details>
  <summary>Details</summary>
Motivation: 在复杂多层环境中，准确的垂直高度估计和可靠的楼层识别对机器人定位和导航至关重要，而仅依赖视觉或激光SLAM的垂直定位方法存在不足。

Method: 开发了完全兼容ROS的差分气压传感系统，通过同时采集固定基站和移动传感器的实时气压数据，实现无漂移的垂直定位，并在封闭楼梯间和电梯等挑战性场景中进行实证评估。

Result: 系统在垂直方向上达到亚米级精度（RMSE: 0.29米），楼层识别准确率为100%，显著优于仅依赖视觉或激光SLAM的独立高度估计方法。

Conclusion: 该差分气压模块为实际机器人部署提供了实用且低成本的垂直感知解决方案，相关代码已开源。

Abstract: Accurate altitude estimation and reliable floor recognition are critical for mobile robot localization and navigation within complex multi-storey environments. In this paper, we present a robust, low-cost vertical estimation framework leveraging differential barometric sensing integrated within a fully ROS-compliant software package. Our system simultaneously publishes real-time altitude data from both a stationary base station and a mobile sensor, enabling precise and drift-free vertical localization. Empirical evaluations conducted in challenging scenarios -- such as fully enclosed stairwells and elevators, demonstrate that our proposed barometric pipeline achieves sub-meter vertical accuracy (RMSE: 0.29 m) and perfect (100%) floor-level identification. In contrast, our results confirm that standalone height estimates, obtained solely from visual- or LiDAR-based SLAM odometry, are insufficient for reliable vertical localization. The proposed ROS-compatible barometric module thus provides a practical and cost-effective solution for robust vertical awareness in real-world robotic deployments. The implementation of our method is released as open source at https://github.com/witsir/differential-barometric.

</details>


### [334] [CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding](https://arxiv.org/abs/2601.02295)
*Chenyang Ma,Guangyu Yang,Kai Lu,Shitong Xu,Bill Byrne,Niki Trigoni,Andrew Markham*

Main category: cs.RO

TL;DR: 本文提出CycleVLA系统，为视觉-语言-动作模型（VLA）赋予主动自我纠正能力，能够在执行过程中预测并避免失败，而非事后处理。


<details>
  <summary>Details</summary>
Motivation: 当前机器人故障检测与纠正方法多为事后处理，仅在失败发生后进行分析和修正。这促使研究者开发能够主动预测并预防失败的机制，以提高执行成功率。

Method: CycleVLA整合了三个核心组件：1）进度感知VLA，用于标记关键子任务转换点；2）基于VLM的失败预测器和规划器，触发子任务回溯；3）基于最小贝叶斯风险（MBR）解码的测试时扩展策略，提高回溯后重试成功率。

Result: 大量实验表明，CycleVLA显著提升了训练充分和训练不足的VLA模型的性能，同时证明MBR可作为VLA有效的零样本测试时扩展策略。

Conclusion: CycleVLA通过主动自我纠正机制，成功实现了在失败完全显现前的预测与恢复，为机器人任务执行提供了更可靠的故障处理方案。

Abstract: Current work on robot failure detection and correction typically operate in a post hoc manner, analyzing errors and applying corrections only after failures occur. This work introduces CycleVLA, a system that equips Vision-Language-Action models (VLAs) with proactive self-correction, the capability to anticipate incipient failures and recover before they fully manifest during execution. CycleVLA achieves this by integrating a progress-aware VLA that flags critical subtask transition points where failures most frequently occur, a VLM-based failure predictor and planner that triggers subtask backtracking upon predicted failure, and a test-time scaling strategy based on Minimum Bayes Risk (MBR) decoding to improve retry success after backtracking. Extensive experiments show that CycleVLA improves performance for both well-trained and under-trained VLAs, and that MBR serves as an effective zero-shot test-time scaling strategy for VLAs. Project Page: https://dannymcy.github.io/cyclevla/

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [335] [Application of the learning from errors principle in tufting machines](https://arxiv.org/abs/2601.00813)
*Longxiang Shao,Dominik Huesener,Michael Schluse,Juergen Rossmann*

Main category: eess.SY

TL;DR: 提出一种结合数字孪生、增强现实和Petri网模型的集成培训方法，用于簇绒机操作员的安全高效培训。


<details>
  <summary>Details</summary>
Motivation: 工业环境中基于错误学习的培训方法常因安全和设备风险而难以实施，需要一种既能有效教学又能降低风险的解决方案。

Method: 采用混合数字孪生（EDTs）模拟操作与错误，增强现实（AR）可视化错误后果，Petri网模型形式化表示过程、故障与恢复路径，使用VEROSIM和SOML++实现。

Result: 该混合框架为AR引导的培训系统提供了可扩展基础，能够降低风险并加速技能获取。

Conclusion: 集成数字孪生、AR和Petri网的培训方法有效实现了工业环境中的安全体验式学习，平衡了教学效果与操作风险。

Abstract: The principle of learning from errors is pedagogically powerful but often impractical in industrial settings due to risks to safety and equipment. This paper presents an integrated training approach specifically designed for tufting machine operators. It uses hybrid digital twins, augmented reality (AR), and Petri Net-based modelling to apply the learning from errors principle effectively. Operator actions and errors are simulated via experimentable digital twins (EDTs), and the consequences of errors are visualized in AR, enabling safe, experiential learning. A Petri Net model formally represents the process, including typical faults and recovery paths, and is implemented in VEROSIM using SOML++. This hybrid framework provides a scalable foundation for AR-guided training systems that reduce risk and accelerate skill acquisition.

</details>


### [336] [Scalable Data-Driven Reachability Analysis and Control via Koopman Operators with Conformal Coverage Guarantees](https://arxiv.org/abs/2601.01076)
*Devesh Nath,Haoran Yin,Glen Chou*

Main category: eess.SY

TL;DR: 提出一种基于可达性的概率安全验证框架，通过Koopman理论和神经网络学习非线性系统的线性表示，结合保形预测提供统计有效的误差边界，在多个高维任务中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以对未知非线性动力学系统进行可扩展、概率性的安全验证，且缺乏对模型失配的统计保证。

Method: 使用带神经网络提升函数的Koopman理论学习近似线性动力学表示，设计线性控制器实现轨迹跟踪，通过神经网络验证工具计算可达集，并应用保形预测生成统计有效的误差边界以处理模型失配。

Result: 在11D Hopper、28D Swimmer等高维MuJoCo任务和12D四旋翼系统中，相比现有方法提高了可达集覆盖率、计算效率，并降低了保守性。

Conclusion: 该框架能够高效地对未知非线性系统进行概率安全验证，通过统计误差边界保证真实轨迹的包含概率，且可跨参考轨迹泛化，无需重复计算。

Abstract: We propose a scalable reachability-based framework for probabilistic, data-driven safety verification of unknown nonlinear dynamics. We use Koopman theory with a neural network (NN) lifting function to learn an approximate linear representation of the dynamics and design linear controllers in this space to enable closed-loop tracking of a reference trajectory distribution. Closed-loop reachable sets are efficiently computed in the lifted space and mapped back to the original state space via NN verification tools. To capture model mismatch between the Koopman dynamics and the true system, we apply conformal prediction to produce statistically-valid error bounds that inflate the reachable sets to ensure the true trajectories are contained with a user-specified probability. These bounds generalize across references, enabling reuse without recomputation. Results on high-dimensional MuJoCo tasks (11D Hopper, 28D Swimmer) and 12D quadcopters show improved reachable set coverage rate, computational efficiency, and conservativeness over existing methods.

</details>


### [337] [Time Series Based CO2 Emission Forecasting and Energy Mix Analysis for Net Zero Transitions: A Multi Country Study](https://arxiv.org/abs/2601.01105)
*Salim Oyinlola,Joshua Ajayi,Gozie Ibekwe*

Main category: eess.SY

TL;DR: 该研究通过整合国家能源结构特征与时间序列预测模型，分析了尼日利亚、美国、中国、巴西和俄罗斯的长期CO₂排放轨迹。结果显示各国脱碳路径差异显著，能源结构对减排前景有重要影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解主要经济体在能源结构差异下的长期碳排放轨迹，评估其实现全球气候目标的潜力，并为针对性能源政策提供依据。

Method: 使用2000-2023年年度排放与能源生产数据，将国家分类为化石依赖型、转型期或可再生能源加速型；采用ARIMA、SARIMA和Holt-Winters指数平滑三种预测模型，以MAE、RMSE、MAPE和R²指标评估准确性。

Result: Holt-Winters模型对尼日利亚、美国、中国和巴西预测最准确，SARIMA对俄罗斯最佳；长期预测（2024-2060年）显示巴西因可再生能源主导最接近低碳未来，尼日利亚排放持续上升，美中缓慢下降需加速减排，俄罗斯排放基本持平。

Conclusion: 能源结构对国家脱碳前景有决定性影响，各国需实施针对性能源政策改革以符合全球气候目标，特别是化石依赖型国家需加速转型。

Abstract: This study examines long-term CO$_2$ emission trajectories across five major economies: Nigeria, the United States, China, Brazil, and Russia, by integrating national energy-mix characteristics with time-series forecasting models. Annual emissions from 2000-2023 were analyzed alongside energy production data to classify countries into fossil-dependent, transition-phase, or renewable-accelerated profiles. Three forecasting models (ARIMA, SARIMA, and Holt-Winters exponential smoothing) were evaluated using MAE, RMSE, MAPE, and R$^2$ metrics. Results show that Holt-Winters provided the most accurate forecasts for Nigeria, the United States, China, and Brazil, while SARIMA performed best for Russia due to its relatively stable emissions. Long-term projections from 2024 to 2060 indicate divergent decarbonization pathways. Brazil aligns most closely with a low-emission future owing to its renewable-dominant energy system, whereas Nigeria continues on an upward emissions trajectory driven by fossil dependence. The United States and China maintain moderate declines but require accelerated mitigation to reach their respective net-zero commitments. Russia's emissions remain largely flat under current conditions. These findings highlight the strong influence of energy structures on national decarbonization prospects and underscore the need for targeted energy policy reforms to align with global climate objectives.

</details>


### [338] [Compensating Star-Trackers Misalignments with Adaptive Multi-Model Estimation](https://arxiv.org/abs/2601.01130)
*Ridma Ganganath,Simone Servadio,David Daeyoung Lee*

Main category: eess.SY

TL;DR: 提出一种自适应多模型框架，用于在无GPS的深空立方星任务中联合估计航天器姿态和星敏感器失准角。结合MEKF和MMAE方法，引入网格自适应细化机制，实现高精度、低计算成本的在线校准。


<details>
  <summary>Details</summary>
Motivation: 深空立方星任务中，星敏感器与星体间的微小失准角会显著影响姿态估计精度，且传统方法在资源受限环境下难以实现高效在线校准，需要一种兼顾精度与计算效率的自主校准方案。

Method: 1. 使用MEKF估计姿态、角速度和陀螺偏差；2. 采用MMAE在离散失准角假设网格上进行贝叶斯推理；3. 针对单/双星敏感器配置分别设计三维/六维网格；4. 引入多样性指标Ψ触发网格自适应细化，避免概率过早收敛。

Result: 蒙特卡洛仿真表明：1. 失准角估计精度达角秒级；2. 姿态估计误差低于1度；3. 估计误差有界，系统具有鲁棒性和一致性；4. 自适应网格机制有效提升计算效率。

Conclusion: MEKF-MMAE架构能为资源受限的航天器提供精确、自主、计算高效的在轨校准能力，双星敏感器失准角估计方案具备深空立方星任务实用价值。

Abstract: This paper presents an adaptive multi-model framework for jointly estimating spacecraft attitude and star-tracker misalignments in GPS-denied deep-space CubeSat missions. A Multiplicative Extended Kalman Filter (MEKF) estimates attitude, angular velocity, and gyro bias, while a Bayesian Multiple-Model Adaptive Estimation (MMAE) layer operates on a discrete grid of body-to-sensor misalignment hypotheses. In the single-misalignment case, the MEKF processes gyroscope measurements and TRIAD-based attitude observations, and the MMAE updates a three-dimensional grid over the misalignment vector. For a dual-misalignment configuration, the same MEKF dynamics are retained, and the MMAE bank is driven directly by stacked line-of-sight measurements from two star trackers, forming a six-dimensional grid over the two misalignment quaternions without augmenting the continuous-state dimension. A novel diversity metric, $Ψ$, is introduced to trigger adaptive refinement of the misalignment grid around a weighted-mean estimate, thereby preventing premature collapse of the model probabilities and concentrating computation in the most likely region of the parameter space. Monte Carlo simulations show arcsecond-level misalignment estimation and sub-degree attitude errors for both estimation problems, with estimation errors remaining well-bounded, proving robustness and consistency. These results indicate that the proposed MEKF--MMAE architecture enables accurate, autonomous, and computationally efficient in-flight calibration for resource-constrained spacecraft, and establishes dual star-tracker misalignment estimation as a practical option for deep-space CubeSat missions.

</details>


### [339] [Tube-based robust nonlinear model predictive control of anaerobic co-digestion](https://arxiv.org/abs/2601.01157)
*Davide Carecci,Laurent Dewasme,Alessio La Bella,Gianni Ferretti,Alain Vande Wouwer*

Main category: eess.SY

TL;DR: 提出了一种基于管道的鲁棒非线性模型预测控制方法，用于在厌氧消化器饲料变化期间调节生物甲烷产量，同时确保安全运行并处理不确定性。


<details>
  <summary>Details</summary>
Motivation: 为满足生物甲烷生产日益增长的需求，厌氧消化器需要采用不同原料的共消化，并需要优化和时变调整输入饲料以提高技术经济性能，但现有工业规模设备的仪器和控制能力有限，且可用数据信息含量低、参数不确定性高，难以实现可靠控制。

Method: 采用基于管道的鲁棒非线性模型预测控制方法，通过数值模拟评估其性能，模拟设计尽可能接近即将进行验证的小型中试装置实验条件。

Result: 通过模拟验证了该控制方法在饲料变化期间调节生物甲烷产量、确保安全运行并处理不确定性的能力。

Conclusion: 该方法为工业规模厌氧消化器在有限仪器和不确定条件下的优化控制提供了可行方案，并为后续实际中试验证奠定了基础。

Abstract: To match the growing demand for bio-methane production, anaerobic digesters need to embrace the co-digestion of different feedstocks; in addition, to improve the techno-economic performance, an optimal and time-varying adaptation of the input diet is required. These operation modes constitute a very hard challenge for the limited instrumentation and control equipment typically installed aboard full-scale plants. A model-based predictive approach may be able to handle such control problem, but the identification of reliable predictive models is limited by the low information content typical of the data available from full-scale plants' operations, which entail high parametric uncertainty. In this work, the application of a tube-based robust nonlinear model predictive control (NMPC) is proposed to regulate bio-methane production over a period of diet change in time, while warranting safe operation and dealing with uncertainties. In view of its upcoming validation on a true small pilot-scale plant, the NMPC capabilities are assessed via numerical simulations designed to resemble as much as possible the experimental setup, along with some practical final considerations.

</details>


### [340] [Transient Power Allocation Control Scheme for Hybrid Hydrogen Electrolyzer-Supercapacitor System with Autonomous Inertia Response](https://arxiv.org/abs/2601.01170)
*Pengfeng Lin,Guangjie Gao,Jianjun Ma,Miao Zhu,Xinan Zhang,Ahmed Abu-Siada*

Main category: eess.SY

TL;DR: 提出了一种混合氢电解槽-超级电容器系统（HESS），采用新型控制策略，用于可再生能源主导的电网。该系统结合碱性电解槽、质子交换膜电解槽和超级电容器，通过协调控制实现功率的频域分配，提升系统惯性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 可再生能源主导的电网面临功率波动大、惯性不足的问题，传统电解制氢系统响应慢、效率低，难以适应高频功率变化。需要一种能同时提供惯性支持、高效制氢并降低损耗的集成解决方案。

Method: 1. 构建由碱性电解槽（AEL）、质子交换膜电解槽（PEMEL）和超级电容器（SC）组成的HESS；2. 提出惯性模拟控制策略，包括动态惯性控制（PEMEL）、电容惯性控制（SC）和传统直流功率控制（AEL）；3. 建立基于混合电位理论的大信号数学模型；4. 采用硬件在环实验验证系统性能。

Result: 1. SC自主处理高频瞬态功率，PEMEL调节稳定频率功率，AEL处理低频稳态功率；2. SC显著减少电解槽能量损耗，提升惯性恢复能力，无需额外通信；3. SOC恢复控制使SC稳定放电循环次数提升3倍以上；4. 数学模型明确了系统参数稳定边界，动态分析和实验验证了系统可行性。

Conclusion: 所提出的HESS及控制策略能有效分配不同频段的功率，提升电网惯性支持能力，降低电解槽损耗，增强系统稳定性，为高比例可再生能源电网提供了可行的解决方案。

Abstract: This paper proposes a hybrid hydrogen electrolyzer-supercapacitor system (HESS) with a novel control strategy for renewable-dominant power grids. The HESS consists of alkaline electrolyzers (AEL), proton exchange membrane electrolyzers (PEMEL), and supercapacitors (SC). The interfacing inverters between HESS and power grid are regulated by an inertia emulation control strategy. From HESS, AEL is with conventional DC power control, whereas PEMEL and SC are designed with the proposed dynamic inertia control and capacitive inertia control, respectively. Benefitting from the coordination of three controls, within the HESS, high-frequency transient power components are autonomously handled by SC, stable frequency power components are regulated by PEMEL, and low-frequency steady-state power is addressed by AEL, characterized by low operational gains and longer lifetimes. SC delivers transient power, significantly alleviating energy losses on electrolyzers and achieving adequate inertia recovery capabilities while requiring no additional communication. Implementing SOC recovery control enables the SC to withstand more than three times more stability discharge cycles compared to an SC without SOC recovery. Furthermore, a large-signal mathematical model based on mixed potential theory is established, providing clear stability boundaries for system parameters. Dynamic analyses theoretically verify system feasibility, and extensive hardware-in-the-loop experimental results fully validate the proposed HESS along with the corresponding transient power allocation controls.

</details>


### [341] [Reinforcement Learning Based Whittle Index Policy for Scheduling Wireless Sensors](https://arxiv.org/abs/2601.01179)
*Sokipriala Jonah,Seong Ki Yoo,Saurav Sthapit*

Main category: eess.SY

TL;DR: 提出一种基于强化学习的无线传感器网络调度策略，通过AoII评估更新价值并采用边缘挖掘技术，在保证信息新鲜度的同时显著减少传输能耗。


<details>
  <summary>Details</summary>
Motivation: 传统AoI方法仅关注信息时效性而忽略更新价值，导致资源受限的传感器网络存在能量浪费和存储压力，需设计更智能的传输调度机制。

Method: 将调度问题建模为RMAB，提出Whittle Index-based Q-learning策略动态选择传感器，结合边缘挖掘技术对原始数据进行本地预处理。

Result: WIQL策略实现接近最优性能，传输数据包数量最高减少70%，在信息新鲜度与能耗间取得显著平衡。

Conclusion: 基于强化学习的AoII调度框架为资源受限WSN提供了可扩展的自适应解决方案，通过价值感知传输优化系统能效。

Abstract: Wireless Sensor nodes used in remote monitoring applications typically transmit data in a timely manner, often optimising for the Age of Information (AoI). However, this approach focuses solely on keeping updates at the sink fresh without considering the actual value of each update. This method is inefficient for sensor networks, which have limited resources. Transmitting data indiscriminately without evaluating its significance not only increases energy consumption but also raises storage requirements. To address this challenge, we propose a reinforcement learning-based scheduling strategy that prioritises sensor transmissions based on the Age of Incorrect Information (AoII) using an edge mining technique. This ensures that the most valuable updates are received while reducing energy consumption. We frame the scheduling problem as a Restless Multi-Armed Bandit (RMAB) and introduce a Whittle Index-based Q-learning (WIQL) policy to dynamically select the most informative sensors. Additionally, we employ an edge mining technique, where raw sensor data is processed locally before transmission, enhancing state estimation at the sink. Experimental results demonstrate that WIQL achieves near-optimal performance while significantly reducing the number of transmitted packets by up to 70%. This reinforcement learning-based approach provides a scalable and adaptive solution for efficient data scheduling in resource-constrained WSNs.

</details>


### [342] [Multi-Objective Operational Optimization of Energy Storage Systems in User-Side Microgrids](https://arxiv.org/abs/2601.01256)
*Jinzhou Xu,Yuanxin Zhuo,Paola Tapia*

Main category: eess.SY

TL;DR: 提出一种面向用户的微电网储能系统运行优化策略，通过多目标优化降低电费、减少碳排放并提高可再生能源利用率，经实际数据验证可平均降低13.47%电费。


<details>
  <summary>Details</summary>
Motivation: 针对实际用户侧应用需求，解决微电网储能系统运行优化问题，提升经济性、环保性和可再生能源利用效率。

Method: 建立储能系统基础模型表征动态与约束，构建多目标优化框架，采用Gurobi求解器保证计算效率，利用实际运行数据验证。

Result: 策略能准确反映实际系统约束；相比现有用户策略平均降低13.47%电费；通过动态调整多目标权重实现灵活运行模式，提升场景适应性。

Conclusion: 该用户中心化优化设计通过多目标权重分配增强了运行灵活性与场景适应性，为实际微电网储能运行提供了实用、可扩展的解决方案，并为用户侧微电网参与余电上网政策提供决策支持。

Abstract: An operational optimization strategy for microgrid energy storage systems (ESSs) is developed to address practical user-oriented application requirements, and its effectiveness is validated using real-world operational data. First, a fundamental ESS model is established to characterize system dynamics and operational constraints, providing a theoretical basis for optimization. Subsequently, a multi-objective operational optimization framework is formulated to simultaneously minimize electricity cost, reduce carbon emissions, and enhance renewable energy utilization. To ensure computational efficiency and scalability, the commercial optimization solver Gurobi is employed. The proposed strategy is evaluated using actual microgrid operational data, demonstrating that the developed ESS model accurately represents real system constraints. Compared with existing user operational strategies, the proposed approach achieves an average reduction of 13.47% in electricity cost. Moreover, by dynamically adjusting the weighting factors of the multi-objective formulation, the strategy enables flexible operational modes and significantly improves adaptability to varying operating scenarios. In addition, the proposed framework provides decision support for user-side microgrids participating in surplus electricity feed-in policies. The main contribution of this work lies in its user-centric optimization design, which enhances operational flexibility and scenario adaptability through multi-objective weight allocation, offering a practical and scalable solution for real-world microgrid ESS operation.

</details>


### [343] [An Energy-Efficient Smart Bus Transport Management System with Blind-Spot Collision Detection Ability](https://arxiv.org/abs/2601.01274)
*Md. Sadman Haque,Zobaer Ibn Razzaque,Robiul Awoul Robin,Fahim Hafiz,Riasat Azim*

Main category: eess.SY

TL;DR: 提出智能公交系统，集成深度学习盲区预警、自动站点识别、物联网太阳能智能站台和RFID乘客追踪，提升公交安全性、效率与可持续性。


<details>
  <summary>Details</summary>
Motivation: 发展中国家公交系统缺乏实时位置更新，随意停靠导致安全隐患与交通拥堵，盲区及交通违规增加事故风险。

Method: 采用深度学习盲区预警系统、自动公交站点检测、物联网太阳能智能站台（显示实时乘客数量）、RFID刷卡系统追踪乘客上下车、智能车门系统、实时公交追踪及HTTP服务器集成通信。

Result: 盲区实时检测效率约99%，公交精准停靠站点，服务器提供实时位置更新，节能公交站实现12.71kWh节能量。

Conclusion: 所提智能公交系统有效提升公交安全性、运营效率和可持续性，并通过开源实现促进应用推广。

Abstract: Public bus transport systems in developing countries often suffer from a lack of real-time location updates and for users, making commuting inconvenient and unreliable for passengers. Furthermore, stopping at undesired locations rather than designated bus stops creates safety risks and contributes to roadblocks, often causing traffic congestion. Additionally, issues such as blind spots, along with a lack of following traffic laws, increase the chances of accidents. In this work, we address these challenges by proposing a smart public bus system along with intelligent bus stops that enhance safety, efficiency, and sustainability. Our approach includes a deep learning-based blind-spot warning system to help drivers avoid accidents with automated bus-stop detection to accurately identify bus stops, improving transit efficiency. We also introduce IoT-based solar-powered smart bus stops that show real-time passenger counts, along with an RFID-based card system to track where passengers board and exit. A smart door system ensures safer and more organised boarding, while real-time bus tracking keeps passengers informed. To connect all these features, we use an HTTP-based server for seamless communication between the interconnected network systems. Our proposed system demonstrated approximately 99% efficiency in real-time blind spot detection while stopping precisely at the bus stops. Furthermore, the server showed real-time location updates both to the users and at the bus stops, enhancing commuting efficiency. The proposed energy-efficient bus stop demonstrated 12.71kWh energy saving, promoting sustainable architecture. Full implementation and source code are available at: https://github.com/sadman-adib/MoveMe-IoT

</details>


### [344] [Simple yet Effective Anti-windup Techniques for Amplitude and Rate Saturation: An Autonomous Underwater Vehicle Case Study](https://arxiv.org/abs/2601.01302)
*Pouria Sarhadi*

Main category: eess.SY

TL;DR: 本文重新审视了经典抗饱和控制方法在同时处理执行器幅值和速率饱和问题中的潜力，通过改进PID和LQI控制器，在AUV航向控制中取得了与约束MPC相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现代抗饱和方法虽能同时处理幅值与速率饱和，但推导条件苛刻且工程应用复杂；而经典方法虽简单有效，却长期被忽视其在双饱和问题中的潜力。

Method: 对PID和LQI两种经典控制器进行改进，使其能同时应对幅值与速率饱和，并在REMUS AUV航向控制问题上进行测试，与约束MPC进行性能对比。

Result: 改进后的经典控制器在SISO系统中表现出与约束MPC相当的控制性能，验证了经典方法在双饱和问题中仍能提供简单有效的解决方案。

Conclusion: 经典抗饱和控制方法经过适当改进后，能以极少附加参数和简单实现获得接近现代方法的性能，这为后续研究提供了新方向。

Abstract: Actuator amplitude and rate saturation (A\&RSat), together with their consequent windup problem, have long been recognised as challenges in control systems. Anti-windup (AW) solutions have been developed over the past decades, which can generally be categorised into two main groups: classical and modern anti-windup (CAW and MAW) approaches. Classical methods have provided simple and effective results, mainly addressing amplitude saturation. In contrast, modern approaches offer powerful and theoretically sound solutions capable of handling both amplitude and rate saturations. However, MAW's derivation process often imposes restrictive conditions and can be complex to apply in practical engineering problems. Nevertheless, the literature has paid limited attention (if not entirely ignored) to the potential of simple yet effective CAW schemes that can operate in the presence of both A\&RSat elements. This paper revisits this issue and proposes modifications to two well-known controllers: PID and LQI. The obtained results, benchmarked on the REMUS AUV yaw control problem and compared with constrained MPC, indicate that these classical techniques can still provide simple yet effective solutions with comparable performance, at least for SISO systems. These findings may stimulate further research into solutions that achieve comparable performance with only one (or a limited number of) additional tuning parameters and straightforward implementation.

</details>


### [345] [Neural-network-based Self-triggered Observed Platoon Control for Autonomous Vehicles](https://arxiv.org/abs/2601.01335)
*Zihan Li,Ziming Wang,Chenning Liu,Xin Wang*

Main category: eess.SY

TL;DR: 提出了一种自适应共识跟踪控制框架，用于解决不确定动态和间歇通信下的自动驾驶车辆编队控制问题。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统中，自动驾驶车辆编队在不确定动态和间歇通信条件下的控制仍是一个关键挑战，需要提高系统的鲁棒性和通信效率。

Method: 结合反步设计、非线性采样数据观测器、径向基函数神经网络和自触发通信机制，利用神经网络逼近未知非线性和时变扰动，通过分布式观测器估计邻车状态，并设计自触发机制确定通信时机。

Result: 理论分析证明所有闭环信号一致最终有界，跟踪误差收敛到紧集；仿真结果表明该方法具有高鲁棒性、适应性和通信效率。

Conclusion: 所提出的方法适用于实际网络化车辆系统，能有效处理不确定性和通信限制，提升编队控制的性能。

Abstract: This paper investigates autonomous vehicle (AV) platoon control under uncertain dynamics and intermittent communication, which remains a critical challenge in intelligent transportation systems. To address these issues, this paper proposes an adaptive consensus tracking control framework for nonlinear multi-agent systems (MASs). The proposed approach integrates backstepping design, a nonlinear sampled-data observer, radial basis function neural networks, and a self-triggered communication mechanism. The radial basis function neural networks approximate unknown nonlinearities and time-varying disturbances, thereby enhancing system robustness. A distributed observer estimates neighboring states based on limited and intermittent measurements, thereby reducing dependence on continuous communication. Moreover, self-triggered mechanism is developed to determine triggering instants, guaranteeing a strictly positive minimum inter-event time and preventing Zeno behavior. The theoretical analysis proves that all closed-loop signals are uniformly ultimately bounded (UUB), and tracking errors converge to a compact set. Simulation results demonstrate that the proposed approach achieves high robustness, adaptability, and communication efficiency, making it suitable for real-world networked vehicle systems.

</details>


### [346] [Sampling Strategy Design for Model Predictive Path Integral Control on Legged Robot Locomotion](https://arxiv.org/abs/2601.01409)
*Chuyuan Tao,Fanxin Wang,Haolong Jiang,Jia He,Yiyang Chen,Qinglei Bu*

Main category: eess.SY

TL;DR: 本文系统研究了模型预测路径积分（MPPI）控制中采样策略设计对四足机器人运动控制的影响，比较了非结构化和基于样条的采样方法，并通过仿真验证了不同策略在平滑性、性能、鲁棒性和采样效率方面的差异。


<details>
  <summary>Details</summary>
Motivation: MPPI控制虽在复杂非线性系统中表现优异，但直接应用于足式机器人系统存在挑战，需要研究采样策略设计以提升其在足式机器人运动控制中的实际应用效果。

Method: 基于结构化控制参数化思想，在MPPI框架内探索并比较了非结构化和基于样条的多种采样策略，通过四足机器人平台的大量仿真实验进行评估。

Result: 不同采样策略显著影响控制平滑性、任务性能、系统鲁棒性和采样效率，为MPPI在复杂足式系统上的实际部署提供了新的设计见解。

Conclusion: 采样策略设计对MPPI在足式机器人运动控制中的应用具有重要实践意义，研究结果为复杂足式系统部署MPPI控制提供了关键设计指导。

Abstract: Model Predictive Path Integral (MPPI) control has emerged as a powerful sampling-based optimal control method for complex, nonlinear, and high-dimensional systems. However, directly applying MPPI to legged robotic systems presents several challenges. This paper systematically investigates the role of sampling strategy design within the MPPI framework for legged robot locomotion. Based upon the idea of structured control parameterization, we explore and compare multiple sampling strategies within the framework, including both unstructured and spline-based approaches. Through extensive simulations on a quadruped robot platform, we evaluate how different sampling strategies affect control smoothness, task performance, robustness, and sample efficiency. The results provide new insights into the practical implications of sampling design for deploying MPPI on complex legged systems.

</details>


### [347] [Reliable Grid Forecasting: State Space Models for Safety-Critical Energy Systems](https://arxiv.org/abs/2601.01410)
*Jisoo Lee,Sunki Hong*

Main category: eess.SY

TL;DR: 提出电网负荷预测的评估框架，强调误差不对称性对运营风险的影响，并评估Mamba模型在加州电网预测中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统对称误差指标无法反映电网运营中预测不足的风险，需要直接衡量操作风险的评估方法。

Method: 引入非对称MAPE、预测不足率和备用裕度框架，在加州ISO数据集上系统评估Mamba状态空间模型。

Result: 标准精度指标与运营安全性关联弱；温度与预测误差显著相关；S-Mamba模型在99.5%分位数风险下备用裕度最低（14.12%）。

Conclusion: 需采用天气感知建模而非仅修改损失函数；Mamba模型在极端风险下展现更优的预测可靠性。

Abstract: Accurate grid load forecasting is safety-critical: under-predictions risk supply shortfalls, while symmetric error metrics mask this operational asymmetry. We introduce a grid-specific evaluation framework--Asymmetric MAPE, Under-Prediction Rate, and Reserve Margin--that directly measures operational risk rather than statistical accuracy alone.
  Using this framework, we conduct a systematic evaluation of Mamba-based State Space Models for California grid forecasting on a weather-aligned CAISO TAC-area dataset spanning Nov 2023--Nov 2025 (84,498 hourly records across 5 transmission areas). Our analysis reveals that standard accuracy metrics are poor proxies for operational safety: models with identical MAPE can require vastly different reserve margins.
  We demonstrate that forecast errors are weakly but significantly associated with temperature (r = 0.16, p < 10^{-16}), motivating weather-aware modeling rather than loss function modification alone. The S-Mamba model achieves the lowest Reserve_{99.5}% margin (14.12%) compared to 16.66% for iTransformer, demonstrating superior forecast reliability under a 99.5th-percentile tail-risk reserve proxy.

</details>


### [348] [Context-Aware Information Transfer via Digital Semantic Communication in UAV-Based Networks](https://arxiv.org/abs/2601.01430)
*Poorvi Joshi,Mohan Gurusamy*

Main category: eess.SY

TL;DR: 提出DSC-UAV模型，通过数字语义通信框架优化带宽受限无人机网络中的关键任务数据传输，提升语义结构相似性并降低信息年龄。


<details>
  <summary>Details</summary>
Motivation: 智慧城市中带宽受限的无人机难以及时传输关键任务数据，影响实时决策，需要更快速、高效地传输最相关信息。

Method: 采用上下文自适应的数字语义通信框架，包含三个核心组件：提示感知编码（Vision Transformer结合提示文本编码器）、动态无人机中继、基于用户移动性优化的强化学习（使用截断分位数批评家算法）。

Result: 仿真显示，相比现有数字和无人机语义通信基线，语义结构相似性提升高达22%，信息年龄降低14%。

Conclusion: 通过整合移动性控制和上下文驱动的视觉抽象，DSC-UAV模型推进了带宽受限环境下下一代无人机网络的弹性、以信息为中心的监控能力。

Abstract: In smart cities, bandwidth-constrained Unmanned Aerial Vehicles (UAVs) often fail to relay mission-critical data in time, compromising real-time decision-making. This highlights the need for faster and more efficient transmission of only the most relevant information. To address this, we propose DSC-UAV model, leveraging a context-adaptive Digital Semantic Communication (DSC) framework. This model redefines aerial data transmission through three core components: prompt-aware encoding, dynamic UAV-enabled relaying, and user mobility-optimized reinforcement learning. Ground users transmit context-driven visual content. Images are encoded via Vision Transformer combined with a prompt-text encoder to generate semantic features based on the desired context (generic or object-specific). These features are then quantized and transmitted over a UAV network that dynamically relays the data. Joint trajectory and resource allocation are optimized using Truncated Quantile Critic (TQC)-aided reinforcement learning technique, which offers greater stability and precision over standard SAC and TD3 due to its resistance to overestimation bias. Simulations demonstrate significant performance improvement, up to 22\% gain in semantic-structural similarity and 14\% reduction in Age of Information (AoI) compared to digital and prior UAV-semantic communication baselines. By integrating mobility control with context-driven visual abstraction, DSC-UAV advances resilient, information-centric surveillance for next-generation UAV networks in bandwidth-constrained environments.

</details>


### [349] [Full-Time-Scale Power Management Strategy for Hybrid AC/DC/DS Microgrid with Dynamic Concatenation and Autonomous Frequency / Voltage Restorations](https://arxiv.org/abs/2601.01629)
*Qingzuo Meng,Pengfeng Lin,Yujie Wang,Miao Zhu,Amer M. Ghias,Syed Islam,Frede Blaabjerg*

Main category: eess.SY

TL;DR: 提出一种全时间尺度功率管理策略，通过动态连接器统一暂态惯量共享与稳态功率分配，并引入自主频率/电压恢复消除下垂控制导致的稳态偏差，同时建立全局等效电路模型简化系统分析。


<details>
  <summary>Details</summary>
Motivation: 现有微电网功率管理方法通常只关注稳态功率分配或暂态惯量支持之一，且常忽略下垂控制引起的频率/电压偏差，可能影响敏感负荷的供电质量。

Method: 1. 设计全时间尺度功率管理策略，结合动态连接器统一暂态与稳态控制；2. 引入自主频率/电压恢复机制消除稳态偏差；3. 建立全局等效电路模型简化系统分析与设计。

Result: 实验验证该策略能在稳态下维持额定频率与电压，同时实现暂态惯量支持与比例功率分配在所有时间尺度上的无缝切换。

Conclusion: 所提方法有效解决了混合交直流微电网中功率管理的多时间尺度协调问题，提升了系统动态性能与稳态精度。

Abstract: Hybrid AC/DC microgrids with distributed energy storage (DS) improve power reliability in remote areas. Existing power management methods either focus on steady-state power sharing or transient inertia support, but rarely combine both. They also often ignore frequency and voltage deviations caused by droop control, which can harm sensitive loads. To overcome these issues, this paper proposes a full-time-scale (FTS) power management strategy that unifies transient inertia sharing and steady-state power allocation through a novel dynamic concatenator. It also introduces autonomous frequency/voltage restoration to eliminate steady-state deviations in each subgrid. Additionally, a global equivalent circuit model (GECM) is developed to simplify system analysis and design. Experiments confirm that the approach maintains nominal frequency and voltage in steady state while enabling seamless transition between transient inertia support and proportional power sharing across all time scales.

</details>


### [350] [Cross-Directional Modelling and Control of Slot-Die Battery Electrode Coating](https://arxiv.org/abs/2601.01691)
*Hyuntae Kim,Idris Kempf*

Main category: eess.SY

TL;DR: 本文开发了一种基于物理建模的电池电极制造薄膜厚度调控管道，通过CFD仿真建立低阶横向模型，并设计了可用于实时自动反馈和手动前馈操作的控制器。


<details>
  <summary>Details</summary>
Motivation: 随着全球电池需求增长，电池电极制造需要实时过程控制，但目前狭缝涂布生产线仍以开环手动操作为主，缺乏自动化调控手段。

Method: 采用计算流体动力学（CFD）仿真获取数据，从中识别并校准低阶横向模型，基于该模型设计控制器，支持实时自动反馈和手动前馈两种操作模式。

Result: 数值仿真显示CFD模型与横向模型高度一致，所设计的控制器在生产线调试期间既能实现自动化反馈控制，也能用于手动前馈操作。

Conclusion: 该研究提出的建模与控制管道能够有效实现电池电极制造中薄膜厚度的实时调控，为狭缝涂布生产线的自动化控制提供了可行方案。

Abstract: As global battery demand increases, real-time process control becomes increasingly important for battery electrode manufacturing, yet slot-die lines are still mostly manually operated in open loop. This paper develops a physics-based modelling-and-control pipeline for film-thickness regulation. Computational fluid dynamics (CFD) simulations provide the data from which a low-order cross-directional model is identified and calibrated. Numerical simulations demonstrate close agreement between the CFD and the cross-directional model, which is used to design a controller that can be used in both real-time, automated feedback operation and manual feedforward operation during line commissioning.

</details>


### [351] [Host-Aware Control of Gene Expression using Data-Enabled Predictive Control](https://arxiv.org/abs/2601.01693)
*Liam Perreault,Idris Kempf,Kirill Sechkar,Jean-Baptiste Lugagne,Antonis Papachristodoulou*

Main category: eess.SY

TL;DR: 该研究将数据驱动的预测控制（DeePC）应用于细菌的基因表达调控，通过光遗传学和培养基浓度双输入控制目标基因表达和宿主生长速率，在数据有限条件下实现了鲁棒且高效的控制。


<details>
  <summary>Details</summary>
Motivation: 现有AI控制器在实时单细胞水平调控中需要大量数据和重复训练，限制了其在合成生物学中的应用；DeePC方法具有更好的样本效率且无需先验模型，有望解决这一瓶颈。

Method: 采用数据驱动的预测控制（DeePC）框架，结合基函数处理系统非线性，以光遗传刺激和培养基浓度为输入，目标基因表达水平和宿主生长速率为输出，进行闭环控制实验。

Result: DeePC在参数变化下保持鲁棒性，在多种控制策略中表现最佳，且所需训练数据量最少，成功实现了对细菌基因表达的双变量精准调控。

Conclusion: DeePC为合成生物学中的实时基因调控提供了高效、数据节约的解决方案，尤其适用于缺乏精确数学模型或训练数据有限的复杂生物系统。

Abstract: Cybergenetic gene expression control in bacteria enables applications in engineering biology, drug development, and biomanufacturing. AI-based controllers offer new possibilities for real-time, single-cell-level regulation but typically require large datasets and re-training for new systems. Data-enabled Predictive Control (DeePC) offers better sample efficiency without prior modelling. We apply DeePC to a system with two inputs, optogenetic control and media concentration, and two outputs, expression of gene of interest and host growth rate. Using basis functions to address nonlinearities, we demonstrate that DeePC remains robust to parameter variations and performs among the best control strategies while using the least data.

</details>


### [352] [Policy Optimization with Differentiable MPC: Convergence Analysis under Uncertainty](https://arxiv.org/abs/2601.01940)
*Riccardo Zuliani,Efe C. Balta,John Lygeros*

Main category: eess.SY

TL;DR: 本文提出将基于梯度的策略优化与递归系统辨识相结合，确保收敛到最优控制器设计，并在多个控制示例中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 基于模型的策略优化框架在控制应用中广泛使用，但其性能与优化算法的收敛性严重依赖模型的准确性。现有方法在模型不准确时可能无法保证收敛到最优控制器。

Method: 提出将梯度下降策略优化与递归系统辨识相结合的方法，在优化控制器参数的同时持续更新系统模型，形成闭环学习框架。

Result: 理论证明了该方法能确保收敛到最优控制器设计，并在多个控制示例中展示了其优于传统基于固定模型方法的性能。

Conclusion: 结合策略优化与在线系统辨识能有效解决模型不准确问题，为模型预测控制等基于模型的方法提供了更可靠的收敛保证。

Abstract: Model-based policy optimization is a well-established framework for designing reliable and high-performance controllers across a wide range of control applications. Recently, this approach has been extended to model predictive control policies, where explicit dynamical models are embedded within the control law. However, the performance of the resulting controllers, and the convergence of the associated optimization algorithms, critically depends on the accuracy of the models. In this paper, we demonstrate that combining gradient-based policy optimization with recursive system identification ensures convergence to an optimal controller design and showcase our finding in several control examples.

</details>


### [353] [Asymptotic Behavior of an Unforced Duhem-Type Hysteretic Oscillator](https://arxiv.org/abs/2601.01951)
*Mihails Milehins,Dan B. Marghitu*

Main category: eess.SY

TL;DR: 本文研究了带有Duhem型粘弹塑性迟滞元件的无外力机械振荡器的基本解析性质，包括解的整体存在性、唯一性以及每个解收敛到平衡点的特性。


<details>
  <summary>Details</summary>
Motivation: 研究无外力机械振荡器中Duhem型迟滞元件的解析性质，以理解其动力学行为并为控制应用提供理论基础。

Method: 采用理论分析方法，研究带有Duhem型粘弹塑性迟滞元件的机械振荡器模型，分析其解的存在性、唯一性和收敛性。

Result: 证明了系统解的整体存在性和唯一性，并表明每个解都会收敛到一个平衡点。

Conclusion: 带有Duhem型迟滞元件的无外力机械振荡器具有良定的动力学行为，解会稳定收敛到平衡状态，这为相关工程应用提供了理论保证。

Abstract: The article describes fundamental analytical properties of an unforced mechanical oscillator with a Duhem-type viscoelastoplastic hysteretic element. These properties include global existence of solutions, uniqueness of solutions, and convergence of each solution to an equilibrium point.

</details>


### [354] [Finite-State Decentralized Policy-Based Control With Guaranteed Ground Coverage](https://arxiv.org/abs/2601.02109)
*Hossein Rastgoftar*

Main category: eess.SY

TL;DR: 提出了一种基于有限状态、去中心化决策与控制的多智能体地面覆盖框架，通过深度神经网络结构设计和策略驱动的去中心化覆盖控制实现可扩展的协同覆盖。


<details>
  <summary>Details</summary>
Motivation: 多智能体协同覆盖在环境监测、搜索救援等应用中具有重要价值，但现有方法在可扩展性、通信效率和适应性方面存在局限，需要一种既能保持去中心化特性又能有效编码空间配置的通用框架。

Method: 1. 将智能体分为锚点和跟随者，构建三层通信结构（每个跟随者仅与前一层的三个邻居交互形成三角通信单元）；2. 设计由智能体参考配置诱导的深度神经网络结构，其训练权重隐含编码团队空间配置；3. 建立计算高效的去中心化马尔可夫决策过程，其成本函数基于智能体通信三角内目标集质心的偏差动态变化；4. 引入“任意输出可控性”概念，假设各智能体满足AOC条件。

Result: 1. 提出的通信架构具有通用性和可扩展性，每个跟随者仅需与三个邻居交互；2. DNN权重能够隐式表示环境目标集的几何特征；3. 在AOC假设下，证明了系统能够去中心化收敛到最优表示环境目标的期望配置。

Conclusion: 该框架通过结合神经网络的空间编码能力和去中心化MDP控制，实现了多智能体系统在有限状态下的高效协同覆盖，其三角通信结构和AOC理论为可扩展的去中心化协同控制提供了新思路。

Abstract: We propose a finite-state, decentralized decision and control framework for multi-agent ground coverage. The approach decomposes the problem into two coupled components: (i) the structural design of a deep neural network (DNN) induced by the reference configuration of the agents, and (ii) policy-based decentralized coverage control. Agents are classified as anchors and followers, yielding a generic and scalable communication architecture in which each follower interacts with exactly three in-neighbors from the preceding layer, forming an enclosing triangular communication structure. The DNN training weights implicitly encode the spatial configuration of the agent team, thereby providing a geometric representation of the environmental target set. Within this architecture, we formulate a computationally efficient decentralized Markov decision process (MDP) whose components are time-invariant except for a time-varying cost function defined by the deviation from the centroid of the target set contained within each agent communication triangle. By introducing the concept of Anyway Output Controllability (AOC), we assume each agent is AOC and establish decentralized convergence to a desired configuration that optimally represents the environmental target.

</details>


### [355] [Optimal Dispatch of Electricity and Water in Renewable-Integrated Desalination Plants](https://arxiv.org/abs/2601.02243)
*Ahmed S. Alahmed,Audun Botterud,Saurabh Amin,Ali T. Al-Awami*

Main category: eess.SY

TL;DR: 本文为灵活海水淡化厂（WDPs）作为混合发电-负荷资源的最优调度开发了一个数学框架，通过阈值结构实现水-电耦合运营的优化决策。


<details>
  <summary>Details</summary>
Motivation: 海水淡化厂集成了热力发电、膜基可控负荷和可再生能源，具备独特的运行灵活性，可同时参与水电市场，但缺乏有效的调度协调框架以最大化其作为混合资源的潜力。

Method: 构建了以利润最大化为目标的WDP调度决策模型，考虑运行、技术和市场耦合约束；推导出基于阈值的闭式解析调度策略，并通过大规模仿真验证。

Result: 阈值结构实现了计算高效的大规模协调，热力发电与膜基负荷互补提供连续双向灵活性；仿真显示该方法在运营利润和水电交换方面显著优于基准算法。

Conclusion: 所提框架为WDP作为混合资源参与多市场提供了可扩展的优化方案，阈值化调度策略对电价和技术参数变化具有明确响应特性，有助于提升系统灵活性与经济性。

Abstract: We develop a mathematical framework for the optimal dispatch of flexible water desalination plants (WDPs) as hybrid generator-load resources. WDPs integrate thermal generation, membrane-based controllable loads, and renewable energy sources, offering unique operational flexibility for power system operations. They can simultaneously participate in two markets: selling desalinated water to a water utility, and bidirectionally transacting electricity with the grid based on their net electricity demand. We formulate the dispatch decision problem of a profit-maximizing WDP, capturing operational, technological, and market-based coupling between water and electricity flows. The threshold-based structure we derive provides computationally tractable coordination suitable for large-scale deployment, offering operational insights into how thermal generation and membrane-based loads complementarily provide continuous bidirectional flexibility. The thresholds are analytically characterized in closed form as explicit functions of technology and tariff parameters. We examine how small changes in the exogenous tariff and technology parameters affect the WDP's profit. Extensive simulations illustrate the optimal WDP's operation, profit, and water-electricity exchange, demonstrating significant improvements relative to benchmark algorithms.

</details>


### [356] [Characterizing All Locally Exponentially Stabilizing Controllers as a Linear Feedback Plus Learnable Nonlinear Youla Dynamics](https://arxiv.org/abs/2601.02244)
*Luca Furieri*

Main category: eess.SY

TL;DR: 本文推导了非线性仿射连续时间系统局部指数稳定动态状态反馈控制器的状态空间表征，提出了一种非线性Youla型参数化方法，并展示了如何用稳定循环神经网络实现控制器。


<details>
  <summary>Details</summary>
Motivation: 现有非线性控制器设计方法缺乏系统化的参数化框架，难以在保证稳定性的同时优化闭环性能。本文旨在建立局部指数稳定控制器的完整表征，为基于学习的控制器设计提供理论支撑。

Method: 1) 推导状态空间表征：证明所有局部指数稳定控制器可分解为线性稳定反馈与局部指数稳定内部动态之和；2) 建立非线性Youla型参数化；3) 提出用稳定循环神经网络实现内部动态，并作为神经ODE训练。

Result: 1) 证明了控制器分解的充分必要性；2) 建立了局部指数稳定（而非全局渐近稳定）的参数化框架；3) 展示了该方法在非线性控制任务中实现高性能闭环控制的潜力。

Conclusion: 该研究为非线性控制提供了系统化的控制器参数化方法，将经典控制理论与现代机器学习结合，为基于学习的控制器设计与优化开辟了新途径。

Abstract: We derive a state-space characterization of all dynamic state-feedback controllers that make an equilibrium of a nonlinear input-affine continuous-time system locally exponentially stable. Specirically, any controller obtained as the sum of a linear state-feedback $u=Kx$, with $K$ stabilizing the linearized system, and the output of internal locally exponentially stable controller dynamics is itself locally exponentially stabilizing. Conversely, every dynamic state-feedback controller that locally exponentially stabilizes the equilibrium admits such a decomposition. The result can be viewed as a state-space nonlinear Youla-type parametrization specialized to local, rather than global, and exponential, rather than asymptotic, closed-loop stability. The residual locally exponentially stable controller dynamics can be implemented with stable recurrent neural networks and trained as neural ODEs to achieve high closed-loop performance in nonlinear control tasks.

</details>


### [357] [Machine Learning Guided Cooling Optimization for Data Centers](https://arxiv.org/abs/2601.02275)
*Shrenik Jadhav,Zheng Liu*

Main category: eess.SY

TL;DR: 提出一个三阶段物理引导机器学习框架，用于识别和减少高性能计算设施中的冷却能耗浪费，在Frontier超算上验证可回收96%的过量冷却能耗。


<details>
  <summary>Details</summary>
Motivation: 数据中心冷却系统普遍存在效率低下问题，导致能源过度消耗，需要一种能够量化并减少冷却能耗浪费的实用方法。

Method: 1) 使用单调性约束梯度提升模型构建冷却系统代理模型；2) 以代理模型为基准量化过量冷却能耗；3) 通过护栏约束的反事实调整评估供应温度和子循环流量的优化潜力。

Result: 代理模型预测误差为0.026 MW，98.7%测试样本的PUE预测误差在0.01以内；识别出年约85 MWh的冷却能耗浪费；通过安全设定点调整可回收96%的过量能耗。

Conclusion: 该框架能提供可解释的优化建议，支持反事实分析，兼容模型预测控制，并可推广至其他液冷数据中心配置。

Abstract: Effective data center cooling is crucial for reliable operation; however, cooling systems often exhibit inefficiencies that result in excessive energy consumption. This paper presents a three-stage, physics-guided machine learning framework for identifying and reducing cooling energy waste in high-performance computing facilities. Using one year of 10-minute resolution operational data from the Frontier exascale supercomputer, we first train a monotonicity-constrained gradient boosting surrogate that predicts facility accessory power from coolant flow rates, temperatures, and server power. The surrogate achieves a mean absolute error of 0.026 MW and predicts power usage effectiveness within 0.01 of measured values for 98.7% of test samples. In the second stage, the surrogate serves as a physics-consistent baseline to quantify excess cooling energy, revealing approximately 85 MWh of annual inefficiency concentrated in specific months, hours, and operating regimes. The third stage evaluates guardrail-constrained counterfactual adjustments to supply temperature and subloop flows, demonstrating that up to 96% of identified excess can be recovered through small, safe setpoint changes while respecting thermal limits and operational constraints. The framework yields interpretable recommendations, supports counterfactual analyses such as flow reduction during low-load periods and redistribution of thermal duty across cooling loops, and provides a practical pathway toward quantifiable reductions in accessory power. The developed framework is readily compatible with model predictive control and can be extended to other liquid-cooled data centers with different configurations and cooling requirements.

</details>


### [358] [Multi-mode Fault Diagnosis Datasets of Three-phase Asynchronous Motor Under Variable Working Conditions](https://arxiv.org/abs/2601.02278)
*Shijin Chen,Zeyi Liu,Chenyang Li,Dongliang Zou,Xiao He,Donghua Zhou*

Main category: eess.SY

TL;DR: 本文构建了一个包含多种故障类型和严重程度的三相异步电机数据集，支持在真实多变工况下开发鲁棒的故障诊断方法。


<details>
  <summary>Details</summary>
Motivation: 三相异步电机故障会导致严重的停机和经济损失，而实际应用中电机常在变速变载等复杂工况下运行，增加了故障诊断的难度，因此需要能适应多变工况的鲁棒诊断方法。

Method: 采集了在不同转速和负载条件下，包含单一故障和机电复合故障（如转子不平衡、定子绕组短路、轴承故障及其组合）的电机数据集，信号包括三轴振动、三相电流、扭矩和键相信号，涵盖稳态和过渡工况。

Result: 建立了一个全面的三相异步电机故障数据集，为在真实多变工况下开发和验证鲁棒的故障诊断方法提供了数据支持。

Conclusion: 该数据集有助于推动适应实际工业复杂工况的电机故障诊断方法的研究，提升诊断的准确性和鲁棒性。

Abstract: Three-phase asynchronous motor are fundamental components in industrial systems, and their failure can lead to significant operational downtime and economic losses. Vibration and current signals are effective indicators for monitoring motor health and diagnosing faults. However, motors in real applications often operate under variable conditions such as fluctuating speeds and loads, which complicate the fault diagnosis process. This paper presents a comprehensive dataset collected from a three-phase asynchronous motor under various fault types and severities, operating under diverse speed and load conditions. The dataset includes both single faults and mechanical-electrical compound faults, such as rotor unbalance, stator winding short circuits, bearing faults, and their combinations. Data were acquired under both steady and transitional conditions, with signals including triaxial vibration, three-phase currents, torque, and key-phase signals. This dataset supports the development and validation of robust fault diagnosis methods for electric motors under realistic operating conditions.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [359] [Scale-aware Adaptive Supervised Network with Limited Medical Annotations](https://arxiv.org/abs/2601.01005)
*Zihan Li,Dandan Shan,Yunxiang Li,Paul E. Kinahan,Qingqi Hong*

Main category: eess.IV

TL;DR: 提出SASNet网络解决医学图像半监督分割中的标注稀缺、标注者差异和多尺度特征整合问题，通过尺度感知自适应重加权、视图方差增强和分割-回归一致性学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临标注稀缺（需专家知识）、标注者间差异大、多尺度特征整合不足等挑战，现有半监督方法在小型目标分割和边界细化任务上性能显著低于全监督方法。

Method: 提出双分支架构SASNet，包含三个创新：尺度感知自适应重加权策略（基于时序置信度动态加权像素预测）、视图方差增强机制（3D傅里叶域变换模拟标注差异）、分割-回归一致性学习（符号距离图算法提升边界精度）。

Result: 在LA、Pancreas-CT和BraTS数据集上评估，SASNet在有限标注数据下性能优于现有半监督方法，接近全监督性能水平。

Conclusion: SASNet通过整合空间、时序和几何一致性原则，有效解决了半监督医学图像分割的核心限制，代码已开源。

Abstract: Medical image segmentation faces critical challenges in semi-supervised learning scenarios due to severe annotation scarcity requiring expert radiological knowledge, significant inter-annotator variability across different viewpoints and expertise levels, and inadequate multi-scale feature integration for precise boundary delineation in complex anatomical structures. Existing semi-supervised methods demonstrate substantial performance degradation compared to fully supervised approaches, particularly in small target segmentation and boundary refinement tasks. To address these fundamental challenges, we propose SASNet (Scale-aware Adaptive Supervised Network), a dual-branch architecture that leverages both low-level and high-level feature representations through novel scale-aware adaptive reweight mechanisms. Our approach introduces three key methodological innovations, including the Scale-aware Adaptive Reweight strategy that dynamically weights pixel-wise predictions using temporal confidence accumulation, the View Variance Enhancement mechanism employing 3D Fourier domain transformations to simulate annotation variability, and segmentation-regression consistency learning through signed distance map algorithms for enhanced boundary precision. These innovations collectively address the core limitations of existing semi-supervised approaches by integrating spatial, temporal, and geometric consistency principles within a unified optimization framework. Comprehensive evaluation across LA, Pancreas-CT, and BraTS datasets demonstrates that SASNet achieves superior performance with limited labeled data, surpassing state-of-the-art semi-supervised methods while approaching fully supervised performance levels. The source code for SASNet is available at https://github.com/HUANGLIZI/SASNet.

</details>


### [360] [MetaFormer-driven Encoding Network for Robust Medical Semantic Segmentation](https://arxiv.org/abs/2601.00922)
*Le-Anh Tran,Chung Nguyen Tran,Nhan Cach Dang,Anh Le Van Quoc,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: eess.IV

TL;DR: 提出MFEnNet，一种高效的医学图像分割框架，在U-Net编码阶段引入MetaFormer架构，通过池化Transformer块降低计算成本，在多个基准测试中实现竞争性精度和显著降低的计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有先进医学图像分割模型通常采用复杂架构，难以在资源受限的临床环境中部署，需要开发兼顾精度与效率的轻量化解决方案。

Method: 1. 在U-Net编码器中使用MetaFormer架构替代传统CNN；2. 用池化Transformer块替换标准自注意力模块以降低计算复杂度；3. 采用Swish激活函数改善梯度平滑性和收敛速度；4. 在瓶颈层引入空间金字塔池化增强多尺度特征提取。

Result: 在多个医学图像分割基准测试中，MFEnNet在保持竞争性分割精度的同时，显著降低了计算成本，优于当前先进模型。

Conclusion: MFEnNet通过结合MetaFormer架构和轻量化设计，为资源受限的临床环境提供了一种高效准确的医学图像分割解决方案，代码已开源。

Abstract: Semantic segmentation is crucial for medical image analysis, enabling precise disease diagnosis and treatment planning. However, many advanced models employ complex architectures, limiting their use in resource-constrained clinical settings. This paper proposes MFEnNet, an efficient medical image segmentation framework that incorporates MetaFormer in the encoding phase of the U-Net backbone. MetaFormer, an architectural abstraction of vision transformers, provides a versatile alternative to convolutional neural networks by transforming tokenized image patches into sequences for global context modeling. To mitigate the substantial computational cost associated with self-attention, the proposed framework replaces conventional transformer modules with pooling transformer blocks, thereby achieving effective global feature aggregation at reduced complexity. In addition, Swish activation is used to achieve smoother gradients and faster convergence, while spatial pyramid pooling is incorporated at the bottleneck to improve multi-scale feature extraction. Comprehensive experiments on different medical segmentation benchmarks demonstrate that the proposed MFEnNet approach attains competitive accuracy while significantly lowering computational cost compared to state-of-the-art models. The source code for this work is available at https://github.com/tranleanh/mfennet.

</details>


### [361] [Placenta Accreta Spectrum Detection using Multimodal Deep Learning](https://arxiv.org/abs/2601.00907)
*Sumaiya Ali,Areej Alhothali,Sameera Albasri,Ohoud Alzamzami,Ahmed Abduljabbar,Muhammad Alwazzan*

Main category: eess.IV

TL;DR: 本研究开发了一种融合MRI和超声的多模态深度学习框架，用于提高胎盘植入谱系疾病的产前诊断准确性，在独立测试集上达到92.5%的准确率。


<details>
  <summary>Details</summary>
Motivation: 胎盘植入谱系疾病是一种危及生命的产科并发症，早期准确诊断对降低母婴风险至关重要。现有单模态影像诊断存在局限性，需要更精准的检测方法。

Method: 采用中间特征级融合架构，结合3D MRI和2D超声扫描。使用3D DenseNet121-Vision Transformer提取MRI特征，2D ResNet50提取超声特征。使用1,293例MRI和1,143例超声扫描训练单模态模型，配对样本用于多模态模型开发。

Result: 多模态融合模型在独立测试集上表现最佳：准确率92.5%，AUC 0.927，优于MRI单模态模型（82.5%，AUC 0.825）和超声单模态模型（87.5%，AUC 0.879）。

Conclusion: 融合MRI和超声特征能提供互补诊断信息，显著提升胎盘植入谱系疾病的产前风险评估能力，具有改善患者预后的潜力。

Abstract: Placenta Accreta Spectrum (PAS) is a life-threatening obstetric complication involving abnormal placental invasion into the uterine wall. Early and accurate prenatal diagnosis is essential to reduce maternal and neonatal risks. This study aimed to develop and validate a deep learning framework that enhances PAS detection by integrating multiple imaging modalities. A multimodal deep learning model was designed using an intermediate feature-level fusion architecture combining 3D Magnetic Resonance Imaging (MRI) and 2D Ultrasound (US) scans. Unimodal feature extractors, a 3D DenseNet121-Vision Transformer for MRI and a 2D ResNet50 for US, were selected after systematic comparative analysis. Curated datasets comprising 1,293 MRI and 1,143 US scans were used to train the unimodal models and paired samples of patient-matched MRI-US scans was isolated for multimodal model development and evaluation. On an independent test set, the multimodal fusion model achieved superior performance, with an accuracy of 92.5% and an Area Under the Receiver Operating Characteristic Curve (AUC) of 0.927, outperforming the MRI-only (82.5%, AUC 0.825) and US-only (87.5%, AUC 0.879) models. Integrating MRI and US features provides complementary diagnostic information, demonstrating strong potential to enhance prenatal risk assessment and improve patient outcomes.

</details>


### [362] [Uncertainty-Calibrated Explainable AI for Fetal Ultrasound Plane Classification](https://arxiv.org/abs/2601.00990)
*Olaf Yunus Laitinen Imanov*

Main category: eess.IV

TL;DR: 提出一个用于胎儿超声标准切面分类的实用框架，结合不确定性估计与可解释AI方法，旨在提高模型在真实临床环境中的可靠性和可信度。


<details>
  <summary>Details</summary>
Motivation: 胎儿超声标准切面分类对产前生物测量和异常筛查至关重要，但实际部署受到领域偏移、图像噪声和预测概率校准不佳的限制，需要构建在噪声采集条件下仍保持可信的分类器。

Method: 综合多种不确定性估计方法（蒙特卡洛dropout、深度集成、证据学习、保形预测）与事后及不确定性感知的可解释技术（Grad-CAM变体、LIME风格局部代理、不确定性加权多分辨率激活图），并将其映射到面向临床医生的工作流程中。

Result: 使用FETAL_PLANES_DB作为基准，定义了结合校准和选择性预测的报告协议，包括预期校准误差、Brier分数、覆盖风险曲线以及带解释的结构化错误分析。

Conclusion: 该框架为构建胎儿超声分类器提供了一个可重复、临床对齐的蓝图，通过不确定性标志触发重新采集或专家确认，支持质量控制和人机协同审查，确保在噪声采集条件下置信度和解释的可靠性。

Abstract: Fetal ultrasound standard-plane classification underpins reliable prenatal biometry and anomaly screening, yet real-world deployment is limited by domain shift, image noise, and poor calibration of predicted probabilities. This paper presents a practical framework for uncertainty-calibrated explainable AI in fetal plane classification. We synthesize uncertainty estimation methods (Monte Carlo dropout, deep ensembles, evidential learning, and conformal prediction) with post-hoc and uncertainty-aware explanations (Grad-CAM variants, LIME-style local surrogates, and uncertainty-weighted multi-resolution activation maps), and we map these components to a clinician-facing workflow. Using FETAL_PLANES_DB as a reference benchmark, we define a reporting protocol that couples accuracy with calibration and selective prediction, including expected calibration error, Brier score, coverage-risk curves, and structured error analysis with explanations. We also discuss integration points for quality control and human-in-the-loop review, where uncertainty flags trigger re-acquisition or expert confirmation. The goal is a reproducible, clinically aligned blueprint for building fetal ultrasound classifiers whose confidence and explanations remain trustworthy under noisy acquisition conditions.

</details>


### [363] [Learned Hemodynamic Coupling Inference in Resting-State Functional MRI](https://arxiv.org/abs/2601.00973)
*William Consagra,Eardi Lila*

Main category: eess.IV

TL;DR: 提出了一种从静息态fMRI数据中估计皮层表面血流动力学耦合的方法，通过边缘化潜在神经信号并使用深度神经网络结合条件归一化流来近似难处理的边缘似然，实现了可扩展的高分辨率估计。


<details>
  <summary>Details</summary>
Motivation: fMRI通过血流动力学响应间接测量神经活动，这些响应在不同脑区和个体间存在差异。忽略这种血流动力学变异性会偏向下游连接性估计，且血流动力学参数本身可能作为重要的成像生物标志物。从静息态fMRI估计空间变化血流动力学是一个重要但具有挑战性的盲逆问题，因为潜在神经活动和血流动力学耦合都是未知的。

Method: 通过边缘化潜在神经信号，基于边缘似然进行推断，避免联合恢复神经活动和血流动力学的不稳定性。使用深度神经网络结合条件归一化流来准确近似难处理的边缘似然，同时通过在皮层表面上定义的先验来强制空间相干性，这些先验允许稀疏表示。

Result: 使用合成数据和真实fMRI数据集进行了广泛验证，表明在血流动力学估计和下游连接性分析方面明显优于当前方法。

Conclusion: 所提出的方法能够从静息态fMRI中有效推断皮层表面的血流动力学耦合，提高了估计的准确性和可扩展性，为下游连接性分析提供了更可靠的基础。

Abstract: Functional magnetic resonance imaging (fMRI) provides an indirect measurement of neuronal activity via hemodynamic responses that vary across brain regions and individuals. Ignoring this hemodynamic variability can bias downstream connectivity estimates. Furthermore, the hemodynamic parameters themselves may serve as important imaging biomarkers. Estimating spatially varying hemodynamics from resting-state fMRI (rsfMRI) is therefore an important but challenging blind inverse problem, since both the latent neural activity and the hemodynamic coupling are unknown. In this work, we propose a methodology for inferring hemodynamic coupling on the cortical surface from rsfMRI. Our approach avoids the highly unstable joint recovery of neural activity and hemodynamics by marginalizing out the latent neural signal and basing inference on the resulting marginal likelihood. To enable scalable, high-resolution estimation, we employ a deep neural network combined with conditional normalizing flows to accurately approximate this intractable marginal likelihood, while enforcing spatial coherence through priors defined on the cortical surface that admit sparse representations. The proposed approach is extensively validated using synthetic data and real fMRI datasets, demonstrating clear improvements over current methods for hemodynamic estimation and downstream connectivity analysis.

</details>


### [364] [An Explainable Agentic AI Framework for Uncertainty-Aware and Abstention-Enabled Acute Ischemic Stroke Imaging Decisions](https://arxiv.org/abs/2601.01008)
*Md Rashadul Islam*

Main category: eess.IV

TL;DR: 提出了一种用于急性缺血性卒中影像的可解释智能体AI框架，该框架通过不确定性感知和选择性弃权机制提升临床安全性和透明度。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在卒中影像分析中多为黑盒预测器，缺乏不确定性评估和模糊条件下的弃权机制，在急诊放射学等高风险场景中存在安全与信任隐患。

Method: 采用模块化智能体流程：感知智能体进行病灶感知图像分析，不确定性估计智能体计算切片级预测可靠性，决策智能体基于预设阈值决定预测或弃权，并整合可视化解释机制。

Result: 在典型卒中影像场景中，不确定性驱动的弃权行为自然出现在诊断模糊区域和低信息切片中，框架能同时支持预测和弃权决策的可解释性。

Conclusion: 研究提出将智能体控制、不确定性感知和选择性弃权作为开发安全可信医学影像AI系统的核心设计原则，而非追求新的性能基准。

Abstract: Artificial intelligence models have shown strong potential in acute ischemic stroke imaging, particularly for lesion detection and segmentation using computed tomography and magnetic resonance imaging. However, most existing approaches operate as black box predictors, producing deterministic outputs without explicit uncertainty awareness or structured mechanisms to abstain under ambiguous conditions. This limitation raises serious safety and trust concerns in high risk emergency radiology settings. In this paper, we propose an explainable agentic AI framework for uncertainty aware and abstention enabled decision support in acute ischemic stroke imaging. The framework follows a modular agentic pipeline in which a perception agent performs lesion aware image analysis, an uncertainty estimation agent computes slice level predictive reliability, and a decision agent determines whether to issue a prediction or abstain based on predefined uncertainty thresholds. Unlike prior stroke imaging systems that primarily focus on improving segmentation or classification accuracy, the proposed framework explicitly prioritizes clinical safety, transparency, and clinician aligned decision behavior. Qualitative and case based analyses across representative stroke imaging scenarios demonstrate that uncertainty driven abstention naturally emerges in diagnostically ambiguous regions and low information slices. The framework further integrates visual explanation mechanisms to support both predictive and abstention decisions, addressing a key limitation of existing uncertainty aware medical imaging systems. Rather than introducing a new performance benchmark, this work presents agentic control, uncertainty awareness, and selective abstention as essential design principles for developing safe and trustworthy medical imaging AI systems.

</details>


### [365] [YODA: Yet Another One-step Diffusion-based Video Compressor](https://arxiv.org/abs/2601.01141)
*Xingchen Li,Junzhe Zhang,Junqi Shi,Ming Lu,Zhan Ma*

Main category: eess.IV

TL;DR: 提出YODA，一种基于一步扩散模型的视频压缩方法，通过利用时空相关性实现更紧凑的表示，在感知指标上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有一步扩散模型在图像压缩中表现出色，但在视频压缩中应用有限。先前方法通常使用预训练的2D自编码器独立生成每帧潜在表示，忽略了时间依赖性。

Method: YODA嵌入来自时间参考的多尺度特征用于潜在生成和编码，以更好利用时空相关性；采用线性扩散变换器（DiT）进行高效一步去噪。

Result: YODA在LPIPS、DISTS、FID和KID等感知指标上均优于传统和深度学习基线方法，达到最先进的感知性能。

Conclusion: YODA通过有效利用时空相关性和高效的一步去噪，实现了卓越的视频压缩性能，代码将公开提供。

Abstract: While one-step diffusion models have recently excelled in perceptual image compression, their application to video remains limited. Prior efforts typically rely on pretrained 2D autoencoders that generate per-frame latent representations independently, thereby neglecting temporal dependencies. We present YODA--Yet Another One-step Diffusion-based Video Compressor--which embeds multiscale features from temporal references for both latent generation and latent coding to better exploit spatial-temporal correlations for more compact representation, and employs a linear Diffusion Transformer (DiT) for efficient one-step denoising. YODA achieves state-of-the-art perceptual performance, consistently outperforming traditional and deep-learning baselines on LPIPS, DISTS, FID, and KID. Source code will be publicly available at https://github.com/NJUVISION/YODA.

</details>


### [366] [Seamlessly Natural: Image Stitching with Natural Appearance Preservation](https://arxiv.org/abs/2601.01257)
*Gaetane Lorna N. Tchana,Damaris Belle M. Fotso,Antonio Hendricks,Christophe Bobda*

Main category: eess.IV

TL;DR: 提出SENA，一种几何驱动的图像拼接方法，通过分层仿射变形、几何驱动的适区检测和锚定接缝切割，有效解决视差和深度变化场景中的结构失真问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于单应性的图像拼接方法在双摄像头拍摄的深度变化场景中容易产生扭曲、球面膨胀等结构失真，需要一种能保持几何真实性的新方法。

Method: 1. 分层仿射变形策略：全局仿射初始化结合局部仿射优化和平滑自由变形；2. 基于视差一致性的几何驱动适区检测；3. 锚定接缝切割与分割，建立图像间的一对一几何对应。

Result: 在挑战性数据集上的实验表明，SENA在保持与主流单应性方法相当的配准精度同时，在形状保持、纹理完整性和视觉真实感方面显著优于现有方法。

Conclusion: SENA通过几何驱动的设计，有效解决了深度场景中的图像拼接失真问题，实现了更自然、结构保真的全景图生成。

Abstract: This paper introduces SENA (SEamlessly NAtural), a geometry-driven image stitching approach that prioritizes structural fidelity in challenging real-world scenes characterized by parallax and depth variation. Conventional image stitching relies on homographic alignment, but this rigid planar assumption often fails in dual-camera setups with significant scene depth, leading to distortions such as visible warps and spherical bulging. SENA addresses these fundamental limitations through three key contributions. First, we propose a hierarchical affine-based warping strategy, combining global affine initialization with local affine refinement and smooth free-form deformation. This design preserves local shape, parallelism, and aspect ratios, thereby avoiding the hallucinated structural distortions commonly introduced by homography-based models. Second, we introduce a geometry-driven adequate zone detection mechanism that identifies parallax-minimized regions directly from the disparity consistency of RANSAC-filtered feature correspondences, without relying on semantic segmentation. Third, building upon this adequate zone, we perform anchor-based seamline cutting and segmentation, enforcing a one-to-one geometric correspondence across image pairs by construction, which effectively eliminates ghosting, duplication, and smearing artifacts in the final panorama.
  Extensive experiments conducted on challenging datasets demonstrate that SENA achieves alignment accuracy comparable to leading homography-based methods, while significantly outperforming them in critical visual metrics such as shape preservation, texture integrity, and overall visual realism.

</details>


### [367] [Sim2Real SAR Image Restoration: Metadata-Driven Models for Joint Despeckling and Sidelobes Reduction](https://arxiv.org/abs/2601.01541)
*Antoine De Paepe,Pascal Nguyen,Michael Mabelle,Cédric Saleun,Antoine Jouadé,Jean-Christophe Louvigne*

Main category: eess.IV

TL;DR: 提出了一种基于神经网络的统一框架，用于联合处理SAR图像的去斑和旁瓣抑制问题，利用模拟数据训练并实现向真实数据的有效迁移。


<details>
  <summary>Details</summary>
Motivation: SAR图像固有的斑点噪声和亮目标周围的旁瓣现象给准确解译带来挑战，现有方法通常将去斑和旁瓣抑制作为独立任务处理，缺乏统一解决方案。

Method: 使用MOCEM生成的逼真SAR模拟数据集训练神经网络，构建联合处理框架；引入采集元数据作为辅助输入以提升恢复性能；通过仿真到真实（Sim2Real）迁移验证方法有效性。

Result: 所提框架在真实SAR图像上实现了有效的去斑和旁瓣抑制，证明了模拟数据向真实场景的迁移能力，且引入元数据进一步提升了恢复效果。

Conclusion: 该统一神经网络框架能够同时处理SAR图像的两大关键干扰问题，通过模拟数据训练和元数据融合，为SAR图像恢复提供了高效且可迁移的解决方案。

Abstract: Synthetic aperture radar (SAR) provides valuable information about the Earth's surface under all weather and illumination conditions. However, the inherent phenomenon of speckle and the presence of sidelobes around bright targets pose challenges for accurate interpretation of SAR imagery. Most existing SAR image restoration methods address despeckling and sidelobes reduction as separate tasks. In this paper, we propose a unified framework that jointly performs both tasks using neural networks (NNs) trained on a realistic SAR simulated dataset generated with MOCEM. Inference can then be performed on real SAR images, demonstrating effective simulation to real (Sim2Real) transferability. Additionally, we incorporate acquisition metadata as auxiliary input to the NNs, demonstrating improved restoration performance.

</details>


### [368] [UniCrop: A Universal, Multi-Source Data Engineering Pipeline for Scalable Crop Yield Prediction](https://arxiv.org/abs/2601.01655)
*Emiliya Khidirova,Oktay Karakuş*

Main category: eess.IV

TL;DR: 本文提出了UniCrop，一个通用的数据管道，用于自动化获取、清洗和整合多源环境数据以预测作物产量，解决了现有方法在可扩展性和可重复性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有作物产量预测方法通常针对特定作物或区域，且需要大量数据工程工作，限制了其可扩展性、可重复性和实际部署。

Method: UniCrop通过自动化流程获取和整合超过200个环境变量（包括卫星、气象、土壤和地形数据），并使用最小冗余最大相关性（mRMR）进行特征降维，生成紧凑的特征集。

Result: 在包含557个田间观测的水稻产量数据集上验证，使用仅15个特征，LightGBM模型表现最佳（RMSE = 465.1 kg/ha, R² = 0.6576），而集成模型进一步提升了精度（RMSE = 463.2 kg/ha, R² = 0.6604）。

Conclusion: UniCrop提供了一个可扩展且透明的数据工程框架，通过解耦数据规范与实现，支持任何作物、区域和时间范围，为规模化农业分析奠定了实用基础。

Abstract: Accurate crop yield prediction relies on diverse data streams, including satellite, meteorological, soil, and topographic information. However, despite rapid advances in machine learning, existing approaches remain crop- or region-specific and require data engineering efforts. This limits scalability, reproducibility, and operational deployment. This study introduces UniCrop, a universal and reusable data pipeline designed to automate the acquisition, cleaning, harmonisation, and engineering of multi-source environmental data for crop yield prediction. For any given location, crop type, and temporal window, UniCrop automatically retrieves, harmonises, and engineers over 200 environmental variables (Sentinel-1/2, MODIS, ERA5-Land, NASA POWER, SoilGrids, and SRTM), reducing them to a compact, analysis-ready feature set utilising a structured feature reduction workflow with minimum redundancy maximum relevance (mRMR). To validate, UniCrop was applied to a rice yield dataset comprising 557 field observations. Using only the selected 15 features, four baseline machine learning models (LightGBM, Random Forest, Support Vector Regression, and Elastic Net) were trained. LightGBM achieved the best single-model performance (RMSE = 465.1 kg/ha, $R^2 = 0.6576$), while a constrained ensemble of all baselines further improved accuracy (RMSE = 463.2 kg/ha, $R^2 = 0.6604$). UniCrop contributes a scalable and transparent data-engineering framework that addresses the primary bottleneck in operational crop yield modelling: the preparation of consistent and harmonised multi-source data. By decoupling data specification from implementation and supporting any crop, region, and time frame through simple configuration updates, UniCrop provides a practical foundation for scalable agricultural analytics. The code and implementation documentation are shared in https://github.com/CoDIS-Lab/UniCrop.

</details>


### [369] [Robust Deep Joint Source-Channel Coding for Video Transmission over Multipath Fading Channel](https://arxiv.org/abs/2601.01729)
*Bohuai Xiao,Jian Zou,Fanyang Meng,Wei Liu,Yongsheng Liang*

Main category: eess.IV

TL;DR: 提出了一种鲁棒的深度联合信源信道编码框架，通过利用时间冗余和引入调制、编码、解码阶段的鲁棒创新，显著提升了多径衰落信道下的无线视频传输性能。


<details>
  <summary>Details</summary>
Motivation: 多径衰落信道对无线视频传输构成挑战，现有深度联合信源信道编码方法在同时进行信道估计、均衡和语义重建时存在次优性和收敛慢的问题，需要更鲁棒的解决方案。

Method: 1. 调制阶段采用定制OFDM分解宽频信号为平坦子信道；2. 编码阶段引入多尺度高斯变形特征的条件上下文编码建模时间冗余；3. 解码阶段集成轻量去噪模块简化信号恢复。

Result: 在严格带宽限制下，该框架比现有最优视频DeepJSCC方法平均重建质量提升5.13dB，显著改善了多径衰落信道条件下的性能。

Conclusion: 通过调制、编码、解码三阶段的协同设计，所提框架有效克服了多径衰落影响，为无线视频传输提供了高效鲁棒的解决方案。

Abstract: To address the challenges of wireless video transmission over multipath fading channels, we propose a robust deep joint source-channel coding (DeepJSCC) framework by effectively exploiting temporal redundancy and incorporating robust innovations at the modulation, coding, and decoding stages. At the modulation stage, tailored orthogonal frequency division multiplexing (OFDM) for robust video transmission is employed, decomposing wideband signals into orthogonal frequency-flat sub-channels to effectively mitigate frequency-selective fading. At the coding stage, conditional contextual coding with multi-scale Gaussian warped features is introduced to efficiently model temporal redundancy, significantly improving reconstruction quality under strict bandwidth constraints. At the decoding stage, a lightweight denoising module is integrated to robustly simplify signal restoration and accelerate convergence, addressing the suboptimality and slow convergence typically associated with simultaneously performing channel estimation, equalization, and semantic reconstruction. Experimental results demonstrate that the proposed robust framework significantly outperforms state-of-the-art video DeepJSCC methods, achieving an average reconstruction quality gain of 5.13 dB under challenging multipath fading channel conditions.

</details>
