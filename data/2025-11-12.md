<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 69]
- [cs.CV](#cs.CV) [Total: 117]
- [cs.CL](#cs.CL) [Total: 60]
- [cs.RO](#cs.RO) [Total: 33]
- [eess.SY](#eess.SY) [Total: 24]
- [eess.IV](#eess.IV) [Total: 5]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Analysing Environmental Efficiency in AI for X-Ray Diagnosis](https://arxiv.org/abs/2511.07436)
*Liam Kearns*

Main category: cs.AI

TL;DR: 本文比较了LLMs和小型判别模型在胸部X光片COVID-19检测中的准确性和环境影响，发现判别模型在效率和准确性方面优于LLMs。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在医疗应用中的普及，研究旨在评估其在诊断效率方面的表现，并与小型定制模型进行比较，特别关注其多功能性与环境影响的权衡。

Method: 将LLMs和小型判别模型集成到Mendix应用程序中，用于COVID-19胸部X光片检测。判别模型还被用作LLMs的知识库以提高准确性。研究对14种不同的模型配置进行了基准测试，比较了它们的准确性和环境影响。

Result: 小型模型显著降低了碳足迹，但诊断结果偏向阳性且置信度不足。限制LLMs仅输出概率导致准确性和碳足迹表现均不佳。GPT-4.1-Nano相较于大型LLMs减少了94.2%的碳足迹，但仍远高于判别模型。Covid-Net模型是最有效的解决方案，碳足迹比GPT-4.5-Preview低99.9%，同时实现了95.5%的最高准确率。

Conclusion: 判别模型（如Covid-Net）在COVID-19分类任务中，无论在准确性还是环境影响方面，均优于LLMs。这强调了将LLMs作为通用AI解决方案用于分类任务的潜在风险和环境成本。

Abstract: The integration of AI tools into medical applications has aimed to improve the efficiency of diagnosis. The emergence of large language models (LLMs), such as ChatGPT and Claude, has expanded this integration even further. Because of LLM versatility and ease of use through APIs, these larger models are often utilised even though smaller, custom models can be used instead. In this paper, LLMs and small discriminative models are integrated into a Mendix application to detect Covid-19 in chest X-rays. These discriminative models are also used to provide knowledge bases for LLMs to improve accuracy. This provides a benchmark study of 14 different model configurations for comparison of accuracy and environmental impact. The findings indicated that while smaller models reduced the carbon footprint of the application, the output was biased towards a positive diagnosis and the output probabilities were lacking confidence. Meanwhile, restricting LLMs to only give probabilistic output caused poor performance in both accuracy and carbon footprint, demonstrating the risk of using LLMs as a universal AI solution. While using the smaller LLM GPT-4.1-Nano reduced the carbon footprint by 94.2% compared to the larger models, this was still disproportionate to the discriminative models; the most efficient solution was the Covid-Net model. Although it had a larger carbon footprint than other small models, its carbon footprint was 99.9% less than when using GPT-4.5-Preview, whilst achieving an accuracy of 95.5%, the highest of all models examined. This paper contributes to knowledge by comparing generative and discriminative models in Covid-19 detection as well as highlighting the environmental risk of using generative tools for classification tasks.

</details>


### [2] [Agentic Educational Content Generation for African Languages on Edge Devices](https://arxiv.org/abs/2511.07437)
*Ravi Gupta,Guneet Bhatia*

Main category: cs.AI

TL;DR: 该研究提出一个自主代理协调框架，用于在边缘设备上生成去中心化、文化适应性强的教育内容，以解决撒哈拉以南非洲的教育不平等问题。该框架在边缘设备上表现出高效能和高质量的教育内容生成能力，并有望通过社区合作实现可持续的AI驱动教育。


<details>
  <summary>Details</summary>
Motivation: 解决撒哈拉以南非洲地区的教育不平等问题，尤其是在资源受限的环境中，提供可访问、本地化和可持续的AI驱动教育。

Method: 开发了一个由四个专门代理组成的自主代理协调框架，用于在边缘设备上生成去中心化、文化适应性强的教育内容。该系统在Raspberry Pi 4B和NVIDIA Jetson Nano等平台上进行了实验验证。

Result: 在Jetson Nano上，InkubaLM实现了129毫秒的首次令牌时间（TTFT）、33毫秒的平均令牌间延迟和每秒45.2个令牌的吞吐量，功耗为8.4瓦。在Raspberry Pi 4B上，InkubaLM的TTFT为326毫秒，吞吐量为每秒15.9个令牌，功耗为5.8瓦。该框架在测试的非洲语言中持续提供高质量的多语言内容，平均BLEU分数为0.688，文化相关性为4.4/5，流利度为4.2/5。

Conclusion: 该研究为在资源受限环境中实现可访问、本地化和可持续的AI驱动教育奠定了实用基础，重点关注长期可行性和文化适宜性，并有助于实现联合国可持续发展目标4、9和10。

Abstract: Addressing educational inequity in Sub-Saharan Africa, this research presents an autonomous agent-orchestrated framework for decentralized, culturally adaptive educational content generation on edge devices. The system leverages four specialized agents that work together to generate contextually appropriate educational content. Experimental validation on platforms including Raspberry Pi 4B and NVIDIA Jetson Nano demonstrates significant performance achievements. InkubaLM on Jetson Nano achieved a Time-To-First-Token (TTFT) of 129 ms, an average inter-token latency of 33 ms, and a throughput of 45.2 tokens per second while consuming 8.4 W. On Raspberry Pi 4B, InkubaLM also led with 326 ms TTFT and 15.9 tokens per second at 5.8 W power consumption. The framework consistently delivered high multilingual quality, averaging a BLEU score of 0.688, cultural relevance of 4.4/5, and fluency of 4.2/5 across tested African languages. Through potential partnerships with active community organizations including African Youth & Community Organization (AYCO) and Florida Africa Foundation, this research aims to establish a practical foundation for accessible, localized, and sustainable AI-driven education in resource-constrained environments. Keeping focus on long-term viability and cultural appropriateness, it contributes to United Nations SDGs 4, 9, and 10. Index Terms - Multi-Agent Systems, Edge AI Computing, Educational Technology, African Languages, Rural Education, Sustainable Development, UN SDG.

</details>


### [3] [Beyond Correctness: Confidence-Aware Reward Modeling for Enhancing Large Language Model Reasoning](https://arxiv.org/abs/2511.07483)
*Qianxi He,Qingyu Ren,Shanzhe Lei,Xuhong Wang,Yingchun Wang*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的基于置信度的奖励模型（C2RM），旨在通过惩罚低置信度的正确答案来改进大型语言模型（LLM）的STEM推理能力，尤其适用于小型模型，并在多个基准测试中优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的强化学习（RL）在LLM（特别是小型模型）中常导致推理链质量差或推理过程与最终答案不一致。模型可能因知识不足而采用低质量推理链，偶然得出正确答案并获得奖励，这限制了资源有限组织对小型模型进行RL训练的潜力。

Method: 本文提出了一种针对STEM推理能力的基于置信度的奖励模型。与传统方法不同，该模型不仅惩罚错误答案，还惩罚低置信度的正确响应，以促进更健壮和逻辑一致的推理。通过静态评估、Best-of-N推理测试和基于PPO的RL训练来验证其有效性。

Result: 所提出的方法在各种STEM基准测试中，优于几种最先进的开源奖励模型。

Conclusion: 基于置信度的奖励模型通过惩罚低置信度的正确响应，有效提升了LLM的STEM推理能力，促进了更健壮和逻辑一致的推理，尤其对小型模型具有重要意义。

Abstract: Recent advancements in large language models (LLMs) have shifted the post-training paradigm from traditional instruction tuning and human preference alignment toward reinforcement learning (RL) focused on reasoning capabilities. However, numerous technical reports indicate that purely rule-based reward RL frequently results in poor-quality reasoning chains or inconsistencies between reasoning processes and final answers, particularly when the base model is of smaller scale. During the RL exploration process, models might employ low-quality reasoning chains due to the lack of knowledge, occasionally producing correct answers randomly and receiving rewards based on established rule-based judges. This constrains the potential for resource-limited organizations to conduct direct reinforcement learning training on smaller-scale models. We propose a novel confidence-based reward model tailored for enhancing STEM reasoning capabilities. Unlike conventional approaches, our model penalizes not only incorrect answers but also low-confidence correct responses, thereby promoting more robust and logically consistent reasoning. We validate the effectiveness of our approach through static evaluations, Best-of-N inference tests, and PPO-based RL training. Our method outperforms several state-of-the-art open-source reward models across diverse STEM benchmarks. We release our codes and model in https://github.com/qianxiHe147/C2RM.

</details>


### [4] [Think Before You Retrieve: Learning Test-Time Adaptive Search with Small Language Models](https://arxiv.org/abs/2511.07581)
*Supriti Vijay,Aman Priyanshu,Anu Vellore,Baturay Saglam,Amin Karbasi*

Main category: cs.AI

TL;DR: Orion框架使紧凑型模型（350M-1.2B参数）通过学习的搜索策略进行迭代信息检索，在多个基准测试中显著优于大200-400倍的现有检索器，表明性能源于策略而非模型规模。


<details>
  <summary>Details</summary>
Motivation: 现有信息检索方法（神经检索器、大型语言模型、查询重写）在处理复杂用户查询时，缺乏迭代推理能力、成本过高或仅限于静态转换，未能捕捉到探索、反馈和修订的动态过程。

Method: Orion训练框架结合了三个关键组件：1) 合成轨迹生成和监督微调以鼓励模型多样化探索模式；2) 强化学习，奖励有效的查询优化和回溯行为；3) 推理时束搜索算法，利用强化学习中学到的自反思能力。

Result: Orion的1.2B模型，尽管只使用了3%的可用训练数据，但在SciFact上达到77.6%的成功率（高于此前检索器的72.6%），BRIGHT上达到25.2%（高于22.1%），NFCorpus上达到63.2%（高于57.8%），并在FEVER、HotpotQA和MSMarco上保持竞争力。它在六个基准测试中的五个上，性能超越了比自身大200-400倍的检索器。

Conclusion: 研究结果表明，信息检索的性能可以源于模型学习到的搜索、反思和修订策略，而不仅仅是模型规模的大小。

Abstract: Effective information retrieval requires reasoning over partial evidence and refining strategies as information emerges. Yet current approaches fall short: neural retrievers lack reasoning capabilities, large language models (LLMs) provide semantic depth but at prohibitive cost, and query rewriting or decomposition limits improvement to static transformations. As a result, existing methods fail to capture the iterative dynamics of exploration, feedback, and revision that complex user queries demand. We introduce Orion, a training framework that enables compact models (350M-1.2B parameters) to perform iterative retrieval through learned search strategies. Orion combines: (1) synthetic trajectory generation and supervised fine-tuning to encourage diverse exploration patterns in models, (2) reinforcement learning (RL) that rewards effective query refinement and backtracking behaviors, and (3) inference-time beam search algorithms that exploit the self-reflection capabilities learned during RL. Despite using only 3% of the training data available, our 1.2B model achieves 77.6% success on SciFact (vs. 72.6% for prior retrievers), 25.2% on BRIGHT (vs. 22.1%), 63.2% on NFCorpus (vs. 57.8%), and remains competitive on FEVER, HotpotQA, and MSMarco. It outperforms retrievers up to 200-400x larger on five of six benchmarks. These findings suggest that retrieval performance can emerge from learned strategies, not just model scale, when models are trained to search, reflect, and revise.

</details>


### [5] [Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces](https://arxiv.org/abs/2511.07587)
*Shreyas Rajesh,Pavan Holur,Chenda Duan,David Chong,Vwani Roychowdhury*

Main category: cs.AI

TL;DR: GSW是一个受神经科学启发的生成式记忆框架，旨在通过构建结构化的、可解释的叙事表示，解决大型语言模型在长上下文情景推理中的挑战，并显著优于现有的检索增强生成（RAG）基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长上下文推理中面临根本性挑战，包括有限的上下文窗口和随着序列长度增加的性能下降。现有的外部记忆解决方案（如语义嵌入检索和知识图谱）专注于事实检索，但无法构建追踪实体在情景事件中演变所需的时空锚定叙事表示。

Method: 本文提出了生成式语义工作区（GSW），一个受神经科学启发的生成式记忆框架。它包含一个“操作器”（Operator），负责将传入的观察映射到中间语义结构；以及一个“协调器”（Reconciler），负责将这些结构整合到一个持久的工作区中，并确保时间、空间和逻辑的一致性。

Result: 在Episodic Memory Benchmark (EpBench) 上，GSW在处理10万到100万个token长度的语料库时，性能比现有的RAG基线高出20%。此外，GSW效率极高，与次优的基线相比，查询时上下文token减少了51%，显著降低了推理成本。

Conclusion: GSW为赋予大型语言模型类人情景记忆提供了一个具体的蓝图，为构建能够进行长周期推理的更强大智能体铺平了道路。

Abstract: Large Language Models (LLMs) face fundamental challenges in long-context reasoning: many documents exceed their finite context windows, while performance on texts that do fit degrades with sequence length, necessitating their augmentation with external memory frameworks. Current solutions, which have evolved from retrieval using semantic embeddings to more sophisticated structured knowledge graphs representations for improved sense-making and associativity, are tailored for fact-based retrieval and fail to build the space-time-anchored narrative representations required for tracking entities through episodic events. To bridge this gap, we propose the \textbf{Generative Semantic Workspace} (GSW), a neuro-inspired generative memory framework that builds structured, interpretable representations of evolving situations, enabling LLMs to reason over evolving roles, actions, and spatiotemporal contexts. Our framework comprises an \textit{Operator}, which maps incoming observations to intermediate semantic structures, and a \textit{Reconciler}, which integrates these into a persistent workspace that enforces temporal, spatial, and logical coherence. On the Episodic Memory Benchmark (EpBench) \cite{huet_episodic_2025} comprising corpora ranging from 100k to 1M tokens in length, GSW outperforms existing RAG based baselines by up to \textbf{20\%}. Furthermore, GSW is highly efficient, reducing query-time context tokens by \textbf{51\%} compared to the next most token-efficient baseline, reducing inference time costs considerably. More broadly, GSW offers a concrete blueprint for endowing LLMs with human-like episodic memory, paving the way for more capable agents that can reason over long horizons.

</details>


### [6] [AI-Driven Contribution Evaluation and Conflict Resolution: A Framework & Design for Group Workload Investigation](https://arxiv.org/abs/2511.07667)
*Jakub Slapek,Mir Seyedebrahimi,Yang Jianhua*

Main category: cs.AI

TL;DR: 本文提出一个AI增强工具的框架和实现设计，旨在解决团队中个人贡献评估不公平和冲突问题，通过整合多源数据并利用大型语言模型进行分析，生成可解释的仲裁建议。


<details>
  <summary>Details</summary>
Motivation: 团队中个人贡献评估不公平、工作量差异和冲突是一个持续存在的挑战，常常需要耗时且困难的手动干预。现有工具在冲突解决方法和AI集成方面存在空白。

Method: 本文提出了一个AI增强工具的框架和实现设计，用于协助争议调查。该框架将提交物（代码、文本、媒体）、沟通（聊天、邮件）、协调记录（会议日志、任务）、同行评估和上下文信息等异构数据，组织成贡献、互动和角色三个维度，包含九个基准。客观指标被标准化、按维度聚合，并与不平等指标（如基尼系数）配对以识别冲突标记。一个大型语言模型（LLM）架构对这些指标进行验证和上下文分析，以生成可解释和透明的仲裁判断。

Result: 该框架能够生成可解释和透明的仲裁判断，以协助争议调查。作者论证了该方案在当前法律和机构政策下的可行性，并概述了实际分析（情感分析、任务保真度、字/行数等）、偏见防护、局限性和实际挑战。

Conclusion: 本文提出了一种新颖的AI增强工具框架，通过结构化地整合多源数据并利用LLM进行高级分析，有效解决了团队中个人贡献评估和冲突解决的挑战，为公平评估提供了可行的解决方案。

Abstract: The equitable assessment of individual contribution in teams remains a persistent challenge, where conflict and disparity in workload can result in unfair performance evaluation, often requiring manual intervention - a costly and challenging process. We survey existing tool features and identify a gap in conflict resolution methods and AI integration. To address this, we propose a framework and implementation design for a novel AI-enhanced tool that assists in dispute investigation. The framework organises heterogeneous artefacts - submissions (code, text, media), communications (chat, email), coordination records (meeting logs, tasks), peer assessments, and contextual information - into three dimensions with nine benchmarks: Contribution, Interaction, and Role. Objective measures are normalised, aggregated per dimension, and paired with inequality measures (Gini index) to surface conflict markers. A Large Language Model (LLM) architecture performs validated and contextual analysis over these measures to generate interpretable and transparent advisory judgments. We argue for feasibility under current statutory and institutional policy, and outline practical analytics (sentimental, task fidelity, word/line count, etc.), bias safeguards, limitations, and practical challenges.

</details>


### [7] [Procedural Knowledge Improves Agentic LLM Workflows](https://arxiv.org/abs/2511.07568)
*Vincent Hsiao,Mark Roberts,Leslie Smith*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在代理任务中表现不佳。本研究提出并评估了一种利用分层任务网络（HTN）形式的程序性知识的工作流，显著提高了LLM在代理任务上的性能，甚至使较小的LLM超越更大的基线模型，并强调了利用专业知识的重要性。


<details>
  <summary>Details</summary>
Motivation: LLMs在没有大量工具支持、提示工程或微调的情况下，在执行代理任务时经常遇到困难。尽管研究表明领域相关的程序性知识可以显著提高规划效率，但很少有工作评估其在改善LLM执行需要隐式规划的代理任务上的潜力。

Method: 本文形式化、实现并评估了一种代理LLM工作流，该工作流利用分层任务网络（HTN）形式的程序性知识。研究对比了手工编码的HTN和LLM创建的HTN对LLM性能的影响。

Result: 实证结果表明，手工编码的HTN可以显著提高LLM在代理任务上的性能。使用HTN可以将20亿或70亿参数的LLM提升到超越更大的120亿参数LLM基线模型的水平。此外，LLM创建的HTN也能改善整体性能，尽管效果稍逊。

Conclusion: 研究结果表明，利用来自人类、文档或LLM的专业知识来策划程序性知识将成为改善LLM工作流的另一个重要工具。

Abstract: Large language models (LLMs) often struggle when performing agentic tasks without substantial tool support, prom-pt engineering, or fine tuning. Despite research showing that domain-dependent, procedural knowledge can dramatically increase planning efficiency, little work evaluates its potential for improving LLM performance on agentic tasks that may require implicit planning. We formalize, implement, and evaluate an agentic LLM workflow that leverages procedural knowledge in the form of a hierarchical task network (HTN). Empirical results of our implementation show that hand-coded HTNs can dramatically improve LLM performance on agentic tasks, and using HTNs can boost a 20b or 70b parameter LLM to outperform a much larger 120b parameter LLM baseline. Furthermore, LLM-created HTNs improve overall performance, though less so. The results suggest that leveraging expertise--from humans, documents, or LLMs--to curate procedural knowledge will become another important tool for improving LLM workflows.

</details>


### [8] [Making LLMs Reliable When It Matters Most: A Five-Layer Architecture for High-Stakes Decisions](https://arxiv.org/abs/2511.07669)
*Alejandro R. Jadad*

Main category: cs.AI

TL;DR: 本报告提出了一种框架，通过分阶段校准和多层保护架构，使人类与大型语言模型（LLM）在高风险战略决策中建立可靠的认知伙伴关系，以避免可预防的遗憾和认知陷阱。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在可验证领域表现出色，但在结果不确定的高风险战略决策中可靠性较低，这是由于人机系统中相互强化的认知偏差所致，威胁到估值合理性和投资可持续性。

Method: 研究方法包括对7个前沿级LLM和3个市场导向的风险案例进行系统性定性评估。通过详细的提示词指定决策伙伴关系并明确指示避免谄媚、虚构、解决方案漂移和虚无主义。最终，开发了一个基于4阶段初始化过程的7阶段校准序列，以及一个包含偏差自我监控、人机对抗挑战、伙伴关系状态验证、性能退化检测和利益相关者保护的5层保护架构。

Result: 研究取得了三项发现：伙伴关系状态可通过有序校准实现，但需要紧急维护协议；当架构漂移和上下文耗尽同时发生时，可靠性会下降；解散纪律可以防止耗费巨资追求根本错误的方向。跨模型验证揭示了不同LLM架构之间系统性的性能差异。

Conclusion: 该方法表明，人机团队可以实现认知伙伴关系，从而在高风险决策中避免可预防的遗憾，满足对AI系统支持重大决策的投资回报预期，同时避免在验证迟到时引入可预防的认知陷阱。

Abstract: Current large language models (LLMs) excel in verifiable domains where outputs can be checked before action but prove less reliable for high-stakes strategic decisions with uncertain outcomes. This gap, driven by mutually reinforcing cognitive biases in both humans and artificial intelligence (AI) systems, threatens the defensibility of valuations and sustainability of investments in the sector.
  This report describes a framework emerging from systematic qualitative assessment across 7 frontier-grade LLMs and 3 market-facing venture vignettes under time pressure. Detailed prompting specifying decision partnership and explicitly instructing avoidance of sycophancy, confabulation, solution drift, and nihilism achieved initial partnership state but failed to maintain it under operational pressure. Sustaining protective partnership state required an emergent 7-stage calibration sequence, built upon a 4-stage initialization process, within a 5-layer protection architecture enabling bias self-monitoring, human-AI adversarial challenge, partnership state verification, performance degradation detection, and stakeholder protection.
  Three discoveries resulted: partnership state is achievable through ordered calibration but requires emergent maintenance protocols; reliability degrades when architectural drift and context exhaustion align; and dissolution discipline prevents costly pursuit of fundamentally wrong directions. Cross-model validation revealed systematic performance differences across LLM architectures.
  This approach demonstrates that human-AI teams can achieve cognitive partnership capable of preventing avoidable regret in high-stakes decisions, addressing return-on-investment expectations that depend on AI systems supporting consequential decision-making without introducing preventable cognitive traps when verification arrives too late.

</details>


### [9] [AIA Forecaster: Technical Report](https://arxiv.org/abs/2511.07678)
*Rohan Alur,Bradly C. Stadie,Daniel Kang,Ryan Chen,Matt McManus,Michael Rickert,Tyler Lee,Michael Federici,Richard Zhu,Dennis Fogerty,Hayley Williamson,Nina Lozinski,Aaron Linsky,Jasjeet S. Sekhon*

Main category: cs.AI

TL;DR: AIA Forecaster是一个基于LLM的判断性预测系统，通过结合智能体搜索、监督智能体和统计校准技术，在ForecastBench上达到人类超级预测者水平，并在预测市场基准测试中提供增量信息。


<details>
  <summary>Details</summary>
Motivation: 研究旨在利用大型语言模型（LLM）对非结构化数据进行判断性预测，并克服LLM的潜在行为偏差，以实现专家级别的预测能力。

Method: 该方法包含三个核心要素：1) 对高质量新闻源进行智能体搜索；2) 一个监督智能体，用于协调同一事件的不同预测；3) 一套统计校准技术，以对抗大型语言模型中的行为偏差。

Result: 在ForecastBench基准测试中，AIA Forecaster的表现与人类超级预测者持平，并超越了之前的LLM基线。在一个更具挑战性的预测市场基准测试中，AIA Forecaster虽然单独表现不如市场共识，但与市场共识结合的集成模型优于单独的共识，表明其提供了附加信息。

Conclusion: 该工作在AI预测领域建立了新的最先进水平，并为未来的研究提供了实用且可转移的建议。这是首个可验证地实现大规模专家级预测的工作。

Abstract: This technical report describes the AIA Forecaster, a Large Language Model (LLM)-based system for judgmental forecasting using unstructured data. The AIA Forecaster approach combines three core elements: agentic search over high-quality news sources, a supervisor agent that reconciles disparate forecasts for the same event, and a set of statistical calibration techniques to counter behavioral biases in large language models. On the ForecastBench benchmark (Karger et al., 2024), the AIA Forecaster achieves performance equal to human superforecasters, surpassing prior LLM baselines. In addition to reporting on ForecastBench, we also introduce a more challenging forecasting benchmark sourced from liquid prediction markets. While the AIA Forecaster underperforms market consensus on this benchmark, an ensemble combining AIA Forecaster with market consensus outperforms consensus alone, demonstrating that our forecaster provides additive information. Our work establishes a new state of the art in AI forecasting and provides practical, transferable recommendations for future research. To the best of our knowledge, this is the first work that verifiably achieves expert-level forecasting at scale.

</details>


### [10] [ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents](https://arxiv.org/abs/2511.07685)
*Manasi Sharma,Chen Bo Calvin Zhang,Chaithanya Bandi,Clinton Wang,Ankit Aich,Huy Nghiem,Tahseen Rabbani,Ye Htet,Brian Jang,Sumana Basu,Aishwarya Balwani,Denis Peskoff,Marcos Ayestaran,Sean M. Hendryx,Brad Kenstler,Bing Liu*

Main category: cs.AI

TL;DR: 本文介绍了ResearchRubrics，一个用于评估深度研究（DR）智能体的标准化基准，包含领域多样化的提示和专家编写的细粒度评估标准，并提出了一种复杂性框架。评估结果显示，现有领先的DR智能体表现不佳，凸显了对鲁棒评估的需求。


<details>
  <summary>Details</summary>
Motivation: 深度研究（DR）智能体利用大型语言模型（LLMs）处理开放式查询，涉及多步推理、跨文档合成和生成有证据支持的长篇答案。然而，由于响应冗长、多样、存在多种有效解决方案且常依赖动态信息源，评估DR智能体极具挑战性。

Method: 研究人员构建了ResearchRubrics，一个包含2800多小时人工劳动、配有现实且领域多样化提示和2500多个专家编写的细粒度评估标准的DR标准化基准，用于评估事实依据、推理健全性和清晰度。同时，提出了一种新的复杂性框架，从概念广度、逻辑嵌套和探索三个维度对DR任务进行分类。此外，还开发了衡量DR智能体评估标准依从性的人工和模型评估协议。

Result: 对几个最先进的DR系统（如Gemini的DR和OpenAI的DR）进行评估后发现，即使是领先的智能体，其平均依从性也低于68%，主要原因是未能捕捉隐含上下文以及对检索到的信息推理不足。

Conclusion: 研究结果强调了对深度研究能力进行鲁棒、可扩展评估的必要性。为此，ResearchRubrics（包括所有提示、评估标准和评估代码）已被公开发布，以促进开发出有充分理由的、优秀的智能研究助手。

Abstract: Deep Research (DR) is an emerging agent application that leverages large language models (LLMs) to address open-ended queries. It requires the integration of several capabilities, including multi-step reasoning, cross-document synthesis, and the generation of evidence-backed, long-form answers. Evaluating DR remains challenging because responses are lengthy and diverse, admit many valid solutions, and often depend on dynamic information sources. We introduce ResearchRubrics, a standardized benchmark for DR built with over 2,800+ hours of human labor that pairs realistic, domain-diverse prompts with 2,500+ expert-written, fine-grained rubrics to assess factual grounding, reasoning soundness, and clarity. We also propose a new complexity framework for categorizing DR tasks along three axes: conceptual breadth, logical nesting, and exploration. In addition, we develop human and model-based evaluation protocols that measure rubric adherence for DR agents. We evaluate several state-of-the-art DR systems and find that even leading agents like Gemini's DR and OpenAI's DR achieve under 68% average compliance with our rubrics, primarily due to missed implicit context and inadequate reasoning about retrieved information. Our results highlight the need for robust, scalable assessment of deep research capabilities, to which end we release ResearchRubrics(including all prompts, rubrics, and evaluation code) to facilitate progress toward well-justified research assistants.

</details>


### [11] [Towards AI-Assisted Generation of Military Training Scenarios](https://arxiv.org/abs/2511.07690)
*Soham Hans,Volkan Ustun,Benjamin Nye,James Sterrett,Matthew Green*

Main category: cs.AI

TL;DR: 本文提出一个多智能体、多模态推理框架，利用大型语言模型（LLMs）自动生成复杂的军事训练场景工件，如作战命令（OPORDs），以克服传统方法耗时费力且现有AI工具能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 模拟训练中达到专家级表现需要复杂且适应性强的场景，而这传统上是一个劳动密集型且资源消耗巨大的过程。尽管之前的研究探索了军事训练场景生成，但在大型语言模型出现之前，AI工具难以生成足够复杂或适应性强的场景。

Method: 该框架将场景生成分解为一系列子问题，并为每个子问题定义了AI工具的角色（生成选项供人类选择、生成候选产品供人类批准/修改、或完全自动生成文本工件）。它采用专门的基于LLM的智能体来解决不同的子问题。每个智能体接收来自前一个子问题的输入，整合基于文本的场景细节和视觉信息（如地图特征、单位位置），并应用专业推理来生成输出。后续智能体顺序处理这些输出，以保持逻辑一致性并确保文档生成准确性。

Result: 通过一个概念验证，该框架成功生成了作战命令（OPORD）的机动方案和行动部分，并估算了地图位置和移动，证明了其可行性和准确性。结果表明，LLM驱动的多智能体系统有潜力生成连贯、细致的文档，并动态适应不断变化的条件。

Conclusion: LLM驱动的多智能体系统在生成连贯、细致的文档并动态适应不断变化的条件方面具有巨大潜力，从而推动了军事训练场景生成自动化领域的进步。

Abstract: Achieving expert-level performance in simulation-based training relies on the creation of complex, adaptable scenarios, a traditionally laborious and resource intensive process. Although prior research explored scenario generation for military training, pre-LLM AI tools struggled to generate sufficiently complex or adaptable scenarios. This paper introduces a multi-agent, multi-modal reasoning framework that leverages Large Language Models (LLMs) to generate critical training artifacts, such as Operations Orders (OPORDs). We structure our framework by decomposing scenario generation into a hierarchy of subproblems, and for each one, defining the role of the AI tool: (1) generating options for a human author to select from, (2) producing a candidate product for human approval or modification, or (3) generating textual artifacts fully automatically. Our framework employs specialized LLM-based agents to address distinct subproblems. Each agent receives input from preceding subproblem agents, integrating both text-based scenario details and visual information (e.g., map features, unit positions and applies specialized reasoning to produce appropriate outputs. Subsequent agents process these outputs sequentially, preserving logical consistency and ensuring accurate document generation. This multi-agent strategy overcomes the limitations of basic prompting or single-agent approaches when tackling such highly complex tasks. We validate our framework through a proof-of-concept that generates the scheme of maneuver and movement section of an OPORD while estimating map positions and movements as a precursor demonstrating its feasibility and accuracy. Our results demonstrate the potential of LLM-driven multi-agent systems to generate coherent, nuanced documents and adapt dynamically to changing conditions, advancing automation in scenario generation for military training.

</details>


### [12] [Alignment-Aware Quantization for LLM Safety](https://arxiv.org/abs/2511.07842)
*Sunghyun Wee,Suyoung Kim,Hyeonjin Kim,Kyomin Hwang,Nojun Kwak*

Main category: cs.AI

TL;DR: 本文提出了一种名为对齐感知量化（AAQ）的新方法，通过引入对齐保持对比（APC）损失来解决大语言模型（LLM）部署中效率（量化）与安全性（人类对齐）之间的冲突，实现了在保持安全性的同时进行高效量化。


<details>
  <summary>Details</summary>
Motivation: LLM部署需要兼顾安全性和效率。虽然量化可以提高效率，但现有量化方法（如PTQ）仅以低困惑度为目标，可能导致模型在安全性策略上严重退化。困惑度不足以衡量模型安全性，这揭示了传统PTQ范式的根本缺陷，即量化可能成为安全漏洞。

Method: 本文提出了对齐感知量化（AAQ）方法，将对齐保持对比（APC）损失集成到PTQ流程中。与简单的重建损失不同，APC损失通过鼓励量化模型模仿其安全的、经过指令微调的模型，同时远离未对齐的预训练模型，从而明确地保留了对齐性。该方法无需专门的安全校准数据集。

Result: AAQ在不依赖特定安全校准数据集的情况下实现了鲁棒的安全对齐。它与标准PTQ技术兼容，并能在LLaMA、Qwen和Mistral等多种模型家族上实现鲁棒的4比特（W4A4）量化，同时在现有方法失败的情况下保持了安全性。

Conclusion: AAQ成功解决了LLM效率与安全之间的关键权衡问题，为开发既高效又值得信赖的LLM铺平了道路。

Abstract: Safety and efficiency are both important factors when deploying large language models(LLMs). LLMs are trained to follow human alignment for safety, and post training quantization(PTQ) is applied afterward for efficiency. However, these two objectives are often in conflict, revealing a fundamental flaw in the conventional PTQ paradigm: quantization can turn into a safety vulnerability if it only aims to achieve low perplexity. Models can demonstrate low perplexity yet exhibit significant degradation in alignment with the safety policy, highlighting that perplexity alone is an insufficient and often misleading proxy for model safety. To address this, we propose Alignment-Aware Quantization(AAQ), a novel approach that integrates Alignment-Preserving Contrastive(APC) loss into the PTQ pipeline. Compared to simple reconstruction loss, ours explicitly preserves alignment by encouraging the quantized model to mimic its safe, instruction-tuned model while diverging from the unaligned, pre-trained counterpart. Our method achieves this robust safety alignment without resorting to specialized safety-focused calibration datasets, highlighting its practical utility and broad applicability. AAQ is compatible with standard PTQ techniques and enables robust 4-bit (W4A4) quantization across diverse model families such as LLaMA, Qwen, and Mistral while maintaining safety where previous methods fail. Our work resolves the critical trade-off between efficiency and safety, paving the way toward LLMs that are both efficient and trustworthy. Anonymized code is available in the supplementary material.

</details>


### [13] [Operational machine learning for remote spectroscopic detection of CH$_{4}$ point sources](https://arxiv.org/abs/2511.07719)
*Vít Růžička,Gonzalo Mateo-García,Itziar Irakulis-Loitxate,Juan Emmanuel Johnson,Manuel Montesino San Martín,Anna Allen,Luis Guanter,David R. Thompson*

Main category: cs.AI

TL;DR: 本文介绍了一个用于联合国环境规划署国际甲烷排放观测站（IMEO）甲烷警报和响应系统（MARS）的机器学习系统，该系统利用卫星数据检测甲烷泄漏，通过模型集成将误报率降低了74%以上，显著加速了甲烷泄漏的检测和验证过程。


<details>
  <summary>Details</summary>
Motivation: 甲烷是减缓全球变暖最经济有效的手段之一。尽管卫星成像光谱仪可以检测甲烷点源，但现有的基于匹配滤波器的甲烷识别方法误报率高，需要大量人工验证，效率低下。

Method: 研究人员开发了一个机器学习系统，用于在MARS系统中检测甲烷排放。他们创建了迄今为止最大、最多样化的全球甲烷羽流标注数据集，涵盖了EMIT、PRISMA和EnMAP三个成像光谱仪任务的数据。通过比较不同的深度学习模型配置，并将评估方法从小型分块数据集扩展到完整颗粒评估，最终采用模型集成来解决误报问题。

Result: 通过模型集成，系统的误报率降低了74%以上。在七个月的实际部署中，该系统协助验证了1,351个独立的甲烷泄漏，并促成了479次利益相关者通知。研究还通过利比亚、阿根廷、阿曼和阿塞拜疆的案例研究，证明了该模型在验证减排成功方面的实用性。

Conclusion: 这项工作代表了迈向全球AI辅助甲烷泄漏检测系统的关键一步，对于处理未来来自新型和现有成像光谱仪的巨大数据量至关重要。该系统通过显著降低误报和加速验证，提高了甲烷排放监测的效率和准确性。

Abstract: Mitigating anthropogenic methane sources is one the most cost-effective levers to slow down global warming. While satellite-based imaging spectrometers, such as EMIT, PRISMA, and EnMAP, can detect these point sources, current methane retrieval methods based on matched filters still produce a high number of false detections requiring laborious manual verification. This paper describes the operational deployment of a machine learning system for detecting methane emissions within the Methane Alert and Response System (MARS) of the United Nations Environment Programme's International Methane Emissions Observatory. We created the largest and most diverse global dataset of annotated methane plumes from three imaging spectrometer missions and quantitatively compared different deep learning model configurations. Focusing on the requirements for operational deployment, we extended prior evaluation methodologies from small tiled datasets to full granule evaluation. This revealed that deep learning models still produce a large number of false detections, a problem we address with model ensembling, which reduced false detections by over 74%. Deployed in the MARS pipeline, our system processes scenes and proposes plumes to analysts, accelerating the detection and analysis process. During seven months of operational deployment, it facilitated the verification of 1,351 distinct methane leaks, resulting in 479 stakeholder notifications. We further demonstrate the model's utility in verifying mitigation success through case studies in Libya, Argentina, Oman, and Azerbaijan. Our work represents a critical step towards a global AI-assisted methane leak detection system, which is required to process the dramatically higher data volumes expected from new and current imaging spectrometers.

</details>


### [14] [GAMA: A Neural Neighborhood Search Method with Graph-aware Multi-modal Attention for Vehicle Routing Problem](https://arxiv.org/abs/2511.07850)
*Xiangling Chen,Yi Mei,Mengjie Zhang*

Main category: cs.AI

TL;DR: GAMA是一种用于车辆路径问题(VRP)的神经邻域搜索方法，它通过图感知多模态注意力模型和门控融合机制，有效捕获丰富的结构和语义上下文，显著优于现有神经基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经邻域搜索方法在处理VRP时，依赖于简化的状态表示和朴素的异构信息融合，限制了它们捕获丰富结构和语义上下文的能力。

Method: GAMA方法采用图神经网络将问题实例及其演化解决方案编码为不同的模态，并通过堆叠的自注意力和交叉注意力层建模模态内和模态间的交互。此外，它还引入了门控融合机制，将多模态表示整合成结构化状态，以支持策略做出明智且可泛化的操作符选择决策。

Result: 在各种合成和基准实例上的大量实验表明，GAMA算法显著优于最近的神经基线方法。进一步的消融研究证实，多模态注意力机制和门控融合设计在性能提升中都发挥了关键作用。

Conclusion: GAMA通过其图感知多模态注意力模型和门控融合机制，成功解决了现有神经邻域搜索方法在VRP中捕获复杂上下文的局限性，实现了卓越的性能。

Abstract: Recent advances in neural neighborhood search methods have shown potential in tackling Vehicle Routing Problems (VRPs). However, most existing approaches rely on simplistic state representations and fuse heterogeneous information via naive concatenation, limiting their ability to capture rich structural and semantic context. To address these limitations, we propose GAMA, a neural neighborhood search method with Graph-aware Multi-modal Attention model in VRP. GAMA encodes the problem instance and its evolving solution as distinct modalities using graph neural networks, and models their intra- and inter-modal interactions through stacked self- and cross-attention layers. A gated fusion mechanism further integrates the multi-modal representations into a structured state, enabling the policy to make informed and generalizable operator selection decisions. Extensive experiments conducted across various synthetic and benchmark instances demonstrate that the proposed algorithm GAMA significantly outperforms the recent neural baselines. Further ablation studies confirm that both the multi-modal attention mechanism and the gated fusion design play a key role in achieving the observed performance gains.

</details>


### [15] [Confidence-Aware Neural Decoding of Overt Speech from EEG: Toward Robust Brain-Computer Interfaces](https://arxiv.org/abs/2511.07890)
*Soowon Kim,Byung-Kwan Ko,Seo-Hyun Lee*

Main category: cs.AI

TL;DR: 本文提出了一种置信度感知的解码框架，结合深度集成、事后校准和选择性分类，用于从脑电图（EEG）解码口语命令，以提高非侵入式脑机接口（BCI）的准确性和可信赖性。


<details>
  <summary>Details</summary>
Motivation: 非侵入式脑机接口在解码口语命令时，需要同时具备高准确性和高可信赖性，以确保在实际应用中的鲁棒性。

Method: 该方法采用紧凑型、面向语音的卷积网络的深度集成，并结合事后校准和选择性分类。通过集成预测熵、前两名差值和互信息来量化不确定性，并通过由准确率-覆盖率操作点控制的弃权选项做出决策。研究在一个多类别显式语音数据集上进行了评估，使用了防泄漏、分块分层的分割方法，以尊重时间连续性。

Result: 与现有基线相比，所提出的方法产生了更可靠的概率估计，在不同操作点上均提高了选择性性能，并实现了平衡的每类别接受度。

Conclusion: 这些结果表明，置信度感知的神经解码可以为现实世界的脑机接口通信系统提供鲁棒的、面向部署的行为。

Abstract: Non-invasive brain-computer interfaces that decode spoken commands from electroencephalogram must be both accurate and trustworthy. We present a confidence-aware decoding framework that couples deep ensembles of compact, speech-oriented convolutional networks with post-hoc calibration and selective classification. Uncertainty is quantified using ensemble-based predictive entropy, top-two margin, and mutual information, and decisions are made with an abstain option governed by an accuracy-coverage operating point. The approach is evaluated on a multi-class overt speech dataset using a leakage-safe, block-stratified split that respects temporal contiguity. Compared with widely used baselines, the proposed method yields more reliable probability estimates, improved selective performance across operating points, and balanced per-class acceptance. These results suggest that confidence-aware neural decoding can provide robust, deployment-oriented behavior for real-world brain-computer interface communication systems.

</details>


### [16] [WaterMod: Modular Token-Rank Partitioning for Probability-Balanced LLM Watermarking](https://arxiv.org/abs/2511.07863)
*Shinwoo Park,Hyejin Park,Hyeseon Ahn,Yo-Sub Han*

Main category: cs.AI

TL;DR: WaterMod是一种新的语言模型水印方法，通过基于概率的模数规则，在保持生成流畅性的同时，实现了强大的水印检测性能，支持零比特和多比特溯源。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成内容的能力已达到人类水平，但欧盟AI法案等法规要求合成内容带有不可感知、机器可验证的溯源标记。传统基于logit的水印通过随机选择“绿色词汇”并提升其logit来满足要求，但这可能排除最高概率的token，从而损害生成流畅性。

Method: WaterMod采用概率感知的模数规则。首先按模型概率降序排列词汇，然后根据`rank mod k`划分词汇等级，将相邻（语义相似）的token分配到不同类别。对其中一个选定类别施加一个小的固定偏置。在零比特设置（k=2）中，熵自适应门选择偶数或奇数作为“绿色列表”，确保高概率token可用。在多比特设置（k>2）中，当前负载数字d选择满足`rank mod k = d`的颜色类别，从而在每一步编码一个base-k数字，实现细粒度溯源。

Result: 实验结果表明，WaterMod在零比特和多比特设置下，都能持续获得强大的水印检测性能，同时保持生成质量。这种鲁棒性在自然语言生成、数学推理和代码合成等一系列任务中均成立。

Conclusion: WaterMod通过创新的模数规则，有效解决了传统水印在流畅性方面的局限性，能够同时支持二进制归因和丰富的负载，并在各种任务中展现出强大的水印检测能力和生成质量的保持。

Abstract: Large language models now draft news, legal analyses, and software code with human-level fluency. At the same time, regulations such as the EU AI Act mandate that each synthetic passage carry an imperceptible, machine-verifiable mark for provenance. Conventional logit-based watermarks satisfy this requirement by selecting a pseudorandom green vocabulary at every decoding step and boosting its logits, yet the random split can exclude the highest-probability token and thus erode fluency. WaterMod mitigates this limitation through a probability-aware modular rule. The vocabulary is first sorted in descending model probability; the resulting ranks are then partitioned by the residue rank mod k, which distributes adjacent-and therefore semantically similar-tokens across different classes. A fixed bias of small magnitude is applied to one selected class. In the zero-bit setting (k=2), an entropy-adaptive gate selects either the even or the odd parity as the green list. Because the top two ranks fall into different parities, this choice embeds a detectable signal while guaranteeing that at least one high-probability token remains available for sampling. In the multi-bit regime (k>2), the current payload digit d selects the color class whose ranks satisfy rank mod k = d. Biasing the logits of that class embeds exactly one base-k digit per decoding step, thereby enabling fine-grained provenance tracing. The same modular arithmetic therefore supports both binary attribution and rich payloads. Experimental results demonstrate that WaterMod consistently attains strong watermark detection performance while maintaining generation quality in both zero-bit and multi-bit settings. This robustness holds across a range of tasks, including natural language generation, mathematical reasoning, and code synthesis. Our code and data are available at https://github.com/Shinwoo-Park/WaterMod.

</details>


### [17] [Toward Robust EEG-based Intention Decoding during Misarticulated Speech in Aphasia](https://arxiv.org/abs/2511.07895)
*Ha-Na Jo,Jung-Sun Lee,Eunyeong Ko*

Main category: cs.AI

TL;DR: 本文开发了一种基于脑电图（EEG）的辅助系统，通过多任务学习和最大均值差异正则化，在失语症患者存在发音错误的情况下，仍能解码其言语意图。


<details>
  <summary>Details</summary>
Motivation: 失语症严重限制口语交流并常伴有发音错误，但目前针对失语症患者的基于EEG的沟通支持系统研究相对较少。

Method: 招募一名表达性失语症患者进行韩语自动言语任务，记录EEG信号并根据言语是否成功标记为“正确”或“发音错误”。通过频谱分析发现两种试次类型（正确/发音错误）的神经激活模式不同（发音错误时δ波功率过高，额叶θ-α活动增加）。在此基础上，开发了一个带有最大均值差异（MMD）正则化的软多任务学习框架，专注于δ特征，以联合优化类别判别并对齐EEG特征分布。

Result: 频谱分析显示，发音错误的试次在广泛通道表现出过度的δ波功率和额叶θ-α活动增加。所提出的模型在正确试次上实现了58.6%的准确率，在发音错误试次上实现了45.5%的准确率，后者比基线模型提高了45%以上，表明即使在发音错误下也能稳健地解码意图。

Conclusion: 这些结果突出了基于EEG的辅助系统的可行性，该系统能够支持失语症患者在现实世界中不完美的言语条件下进行交流。

Abstract: Aphasia severely limits verbal communication due to impaired language production, often leading to frequent misarticulations during speech attempts. Despite growing interest in brain-computer interface technologies, relatively little attention has been paid to developing EEG-based communication support systems tailored for aphasic patients. To address this gap, we recruited a single participant with expressive aphasia and conducted an Korean-based automatic speech task. EEG signals were recorded during task performance, and each trial was labeled as either correct or incorrect depending on whether the intended word was successfully spoken. Spectral analysis revealed distinct neural activation patterns between the two trial types: misarticulated trials exhibited excessive delta power across widespread channels and increased theta-alpha activity in frontal regions. Building upon these findings, we developed a soft multitask learning framework with maximum mean discrepancy regularization that focus on delta features to jointly optimize class discrimination while aligning the EEG feature distributions of correct and misarticulated trials. The proposed model achieved 58.6 % accuracy for correct and 45.5 % for misarticulated trials-outperforming the baseline by over 45 % on the latter-demonstrating robust intention decoding even under articulation errors. These results highlight the feasibility of EEG-based assistive systems capable of supporting real-world, imperfect speech conditions in aphasia patients.

</details>


### [18] [SparseRM: A Lightweight Preference Modeling with Sparse Autoencoder](https://arxiv.org/abs/2511.07896)
*Dengcan Liu,Jiahao Li,Zheren Fu,Yi Tu,Jiajun Li,Zhendong Mao,Yongdong Zhang*

Main category: cs.AI

TL;DR: 本文提出了SparseRM，一个轻量级、可解释的奖励模型，它利用稀疏自编码器（SAE）从大型语言模型（LLM）表示中提取偏好相关信息，以实现高效的LLM对齐。


<details>
  <summary>Details</summary>
Motivation: 在有限资源下训练可靠的奖励模型（RM）面临挑战，主要原因是对大规模偏好标注的依赖以及微调大型语言模型（LLM）的高昂成本。

Method: SparseRM首先利用稀疏自编码器（SAE）将LLM表示分解为可解释的方向，这些方向捕获了偏好相关的特征。然后，将表示投影到这些方向上以计算对齐分数，量化每个偏好特征的强度。最后，一个简单的奖励头部聚合这些分数来预测偏好分数。

Result: 在三个偏好建模任务上的实验表明，SparseRM在可训练参数不到1%的情况下，优于大多数主流奖励模型。此外，它能无缝集成到下游对齐流程中。

Conclusion: SparseRM提供了一种高效且可解释的方法，通过利用LLM表示中的偏好相关信息来构建奖励模型，从而促进LLM的对齐。

Abstract: Reward models (RMs) are a core component in the post-training of large language models (LLMs), serving as proxies for human preference evaluation and guiding model alignment. However, training reliable RMs under limited resources remains challenging due to the reliance on large-scale preference annotations and the high cost of fine-tuning LLMs. To address this, we propose SparseRM, which leverages Sparse Autoencoder (SAE) to extract preference-relevant information encoded in model representations, enabling the construction of a lightweight and interpretable reward model. SparseRM first employs SAE to decompose LLM representations into interpretable directions that capture preference-relevant features. The representations are then projected onto these directions to compute alignment scores, which quantify the strength of each preference feature in the representations. A simple reward head aggregates these scores to predict preference scores. Experiments on three preference modeling tasks show that SparseRM achieves superior performance over most mainstream RMs while using less than 1% of trainable parameters. Moreover, it integrates seamlessly into downstream alignment pipelines, highlighting its potential for efficient alignment.

</details>


### [19] [Data Descriptions from Large Language Models with Influence Estimation](https://arxiv.org/abs/2511.07897)
*Chaeri Kim,Jaeyeon Bae,Taehwan Kim*

Main category: cs.AI

TL;DR: 本研究提出一种新颖方法，利用大型语言模型和外部知识库生成文本描述来解释数据，并通过影响力估计和CLIP分数选择信息量最大的描述，从而提高模型性能并增强对模型决策过程的理解。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型仍是“黑箱”，大多数可解释AI (XAI) 方法侧重于解释模型如何进行预测，而非如何用深度学习模型训练来解释数据。本研究旨在通过人类易于理解的语言媒介来理解数据。

Method: 提出一个管道，结合大型语言模型和外部知识库生成解释数据的文本描述。为筛选出最具信息量的描述，引入影响力估计和CLIP分数。此外，基于跨模态可迁移性现象，提出名为“跨模态迁移分类”的新基准任务来评估文本描述的有效性。

Result: 在零样本设置实验中，所提出的文本描述比其他基线描述更有效，并成功提升了在九个图像分类数据集上仅用图像训练的模型的性能。GPT-4o的评估进一步支持了这些结果。

Conclusion: 通过本研究的方法，可以深入了解模型决策过程中固有的可解释性。

Abstract: Deep learning models have been successful in many areas but understanding their behaviors still remains a black-box. Most prior explainable AI (XAI) approaches have focused on interpreting and explaining how models make predictions. In contrast, we would like to understand how data can be explained with deep learning model training and propose a novel approach to understand the data via one of the most common media - language - so that humans can easily understand. Our approach proposes a pipeline to generate textual descriptions that can explain the data with large language models by incorporating external knowledge bases. However, generated data descriptions may still include irrelevant information, so we introduce to exploit influence estimation to choose the most informative textual descriptions, along with the CLIP score. Furthermore, based on the phenomenon of cross-modal transferability, we propose a novel benchmark task named cross-modal transfer classification to examine the effectiveness of our textual descriptions. In the experiment of zero-shot setting, we show that our textual descriptions are more effective than other baseline descriptions, and furthermore, we successfully boost the performance of the model trained only on images across all nine image classification datasets. These results are further supported by evaluation using GPT-4o. Through our approach, we may gain insights into the inherent interpretability of the decision-making process of the model.

</details>


### [20] [DANS-KGC: Diffusion Based Adaptive Negative Sampling for Knowledge Graph Completion](https://arxiv.org/abs/2511.07901)
*Haoning Li,Qinghua Huang*

Main category: cs.AI

TL;DR: 本文提出DANS-KGC，一种基于扩散模型的自适应负采样策略，用于知识图谱补全。它通过评估实体学习难度，利用条件扩散模型生成不同难度的负样本，并动态调整训练过程中的样本难度，以克服现有负采样策略的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的负采样策略存在局限性，包括容易产生假阴性样本、泛化能力有限以及难以控制样本难度。为了解决这些问题，研究者们提出了DANS-KGC。

Method: DANS-KGC包含三个关键组件：
1.  **难度评估模块 (DAM)**：通过整合语义和结构特征来评估实体的学习难度。
2.  **自适应负采样模块 (ANS)**：基于难度评估，采用带有难度感知噪声调度的条件扩散模型，在去噪阶段利用语义和邻域信息生成不同难度的负样本。
3.  **动态训练机制 (DTM)**：在训练过程中动态调整负样本的难度分布，实现从易到难的课程式学习，从而增强学习效果。

Result: 在六个基准数据集上进行的广泛实验表明，DANS-KGC具有有效性和泛化能力。该方法在UMLS和YAGO3-10数据集上的所有三个评估指标上均达到了最先进的（state-of-the-art）结果。

Conclusion: DANS-KGC是一种有效且泛化能力强的知识图谱补全负采样策略，能够克服现有方法的局限性，并在多个基准数据集上取得领先性能，特别是在UMLS和YAGO3-10数据集上达到了最先进水平。

Abstract: Negative sampling (NS) strategies play a crucial role in knowledge graph representation. In order to overcome the limitations of existing negative sampling strategies, such as vulnerability to false negatives, limited generalization, and lack of control over sample hardness, we propose DANS-KGC (Diffusion-based Adaptive Negative Sampling for Knowledge Graph Completion). DANS-KGC comprises three key components: the Difficulty Assessment Module (DAM), the Adaptive Negative Sampling Module (ANS), and the Dynamic Training Mechanism (DTM). DAM evaluates the learning difficulty of entities by integrating semantic and structural features. Based on this assessment, ANS employs a conditional diffusion model with difficulty-aware noise scheduling, leveraging semantic and neighborhood information during the denoising phase to generate negative samples of diverse hardness. DTM further enhances learning by dynamically adjusting the hardness distribution of negative samples throughout training, enabling a curriculum-style progression from easy to hard examples. Extensive experiments on six benchmark datasets demonstrate the effectiveness and generalization ability of DANS-KGC, with the method achieving state-of-the-art results on all three evaluation metrics for the UMLS and YAGO3-10 datasets.

</details>


### [21] [Neurophysiological Characteristics of Adaptive Reasoning for Creative Problem-Solving Strategy](https://arxiv.org/abs/2511.07912)
*Jun-Young Kim,Young-Seok Kweon,Gi-Hwan Shin,Seong-Whan Lee*

Main category: cs.AI

TL;DR: 本研究揭示了人类适应性推理的神经动态，表现为协调的delta-theta-alpha脑电活动，并发现多模态大语言模型缺乏真正的适应性推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管人类能够灵活调整推理策略以适应环境规则或情境变化（适应性推理），但其潜在的神经动力学机制尚不清楚。

Method: 研究采用卡片分类范式结合脑电图（EEG）技术，对人类适应性推理的神经生理机制进行了调查，并将其表现与多模态大语言模型进行了比较。分析包括刺激锁定和反馈锁定的脑电活动。

Result: 人类表现出协调的delta-theta-alpha动态：早期的delta-theta活动反映了探索性监测和规则推断，而枕叶alpha波的参与则表明在成功识别规则后对注意力的确认性稳定。相比之下，多模态大语言模型仅表现出短期的反馈驱动调整，缺乏分层规则抽象或真正的适应性推理。

Conclusion: 本研究识别了人类适应性推理的神经特征，并强调了开发受大脑启发的人工智能的必要性，这种人工智能应整合振荡反馈协调机制以实现真正的上下文敏感适应。

Abstract: Adaptive reasoning enables humans to flexibly adjust inference strategies when environmental rules or contexts change, yet its underlying neural dynamics remain unclear. This study investigated the neurophysiological mechanisms of adaptive reasoning using a card-sorting paradigm combined with electroencephalography and compared human performance with that of a multimodal large language model. Stimulus- and feedback-locked analyses revealed coordinated delta-theta-alpha dynamics: early delta-theta activity reflected exploratory monitoring and rule inference, whereas occipital alpha engagement indicated confirmatory stabilization of attention after successful rule identification. In contrast, the multimodal large language model exhibited only short-term feedback-driven adjustments without hierarchical rule abstraction or genuine adaptive reasoning. These findings identify the neural signatures of human adaptive reasoning and highlight the need for brain-inspired artificial intelligence that incorporates oscillatory feedback coordination for true context-sensitive adaptation.

</details>


### [22] [Lightweight Diffusion-based Framework for Online Imagined Speech Decoding in Aphasia](https://arxiv.org/abs/2511.07920)
*Eunyeong Ko,Soowon Kim,Ha-Na Jo*

Main category: cs.AI

TL;DR: 该研究提出了一种基于扩散模型的神经解码框架，用于实时意念言语分类，旨在为失语症患者提供临床沟通支持。该框架在有限校准数据和最小预处理下实现了可靠的在线性能。


<details>
  <summary>Details</summary>
Motivation: 为重度表达性语言障碍（失语症）患者提供脑机接口（BCI）通信支持，特别是将意念言语BCI技术转化为可在实际临床环境下部署的解决方案，克服环境变异性和数据限制等挑战。

Method: 该系统集成了轻量级条件扩散编码器和卷积分类器，使用受试者特定的韩语范式EEG数据进行训练。采用双准则早期停止策略以实现有限校准数据下的快速收敛，并通过Dropout正则化和分组时间卷积确保稳定泛化。在线操作时，连续EEG流通过2秒滑动窗口处理，生成类别概率，并根据解码置信度动态调节视觉和听觉反馈。

Result: 在20次实时试验中，该框架实现了65%的Top-1准确率和70%的Top-2准确率，优于离线评估（50%的Top-1）。这些结果证明了在实际临床约束下部署基于扩散模型的EEG解码的可行性，即使在环境多变和预处理极少的情况下也能保持可靠性能。

Conclusion: 所提出的框架推动了意念言语脑机接口向临床沟通支持的转化，为重度表达性语言障碍患者提供了潜在的解决方案，并展示了扩散模型在实际临床应用中的潜力。

Abstract: A diffusion-based neural decoding framework optimized for real-time imagined speech classification in individuals with aphasia. The system integrates a lightweight conditional diffusion encoder and convolutional classifier trained using subject-specific EEG data acquired from a Korean-language paradigm. A dual-criterion early stopping strategy enabled rapid convergence under limited calibration data, while dropout regularization and grouped temporal convolutions ensured stable generalization. During online operation, continuous EEG streams were processed in two-second sliding windows to generate class probabilities that dynamically modulated visual and auditory feedback according to decoding confidence. Across twenty real-time trials, the framework achieved 65% top-1 and 70% top-2 accuracy, outperforming offline evaluation (50% top-1). These results demonstrate the feasibility of deploying diffusion-based EEG decoding under practical clinical constraints, maintaining reliable performance despite environmental variability and minimal preprocessing. The proposed framework advances the translation of imagined speech brain-computer interfaces toward clinical communication support for individuals with severe expressive language impairment.

</details>


### [23] [Computational Blueprints: Generating Isomorphic Mathematics Problems with Large Language Models](https://arxiv.org/abs/2511.07932)
*Jeong-Hoon Kim,Jinwoo Nam,Geunsik Jo*

Main category: cs.AI

TL;DR: 本文定义了同构数学问题生成（IMPG）任务，并提出了基于大语言模型的框架CBIT，用于高效生成结构一致的数学练习题，其生成的问题错误率低于专家编写的问题，并已成功应用于商业教育平台。


<details>
  <summary>Details</summary>
Motivation: 个性化数学教育快速发展，对大量相似练习题的需求日益增长。然而，现有数学问题生成研究主要关注神经网络语言模型的数据增强，而非直接用于教育部署。

Method: 定义了同构数学问题生成（IMPG）这一新任务，旨在生成结构一致的源问题变体。通过迭代优化探索了基于大语言模型（LLM）的IMPG框架，并建立了同构双胞胎计算蓝图（CBIT）。CBIT采用元级别生成和基于模板的选择性变异。

Result: CBIT实现了高数学正确性和结构一致性，同时降低了生成成本。在生成准确性和规模化成本效益方面表现优越。CBIT生成的问题错误率比专家编写的问题低17.8%。已部署到商业教育平台的6,732名学习者，产生了186,870次互动。

Conclusion: CBIT为个性化数学教育提供了高效、高质量的同构问题生成解决方案，通过实践证明其在生成准确性和成本效益方面的卓越性能，并已成功应用于实际教育场景。

Abstract: Personalized mathematics education is growing rapidly, creating a strong demand for large sets of similar practice problems. Yet existing studies on mathematics problem generation have focused on data augmentation for training neural language models rather than on direct educational deployment. To bridge this gap, we define a new task, Isomorphic Math Problem Generation (IMPG), designed to produce structurally consistent variants of source problems. Subsequently, we explored LLM-based frameworks for automatic IMPG through successive refinements, and established Computational Blueprints for Isomorphic Twins (CBIT). With meta-level generation and template-based selective variation, CBIT achieves high mathematical correctness and structural consistency while reducing the cost of generation. Empirical results across refinements demonstrate that CBIT is superior on generation accuracy and cost-effectiveness at scale. Most importantly, CBIT-generated problems exhibited an error rate 17.8% lower than expert-authored items, with deployment to 6,732 learners on a commercial education platform yielding 186,870 interactions.

</details>


### [24] [Toward Practical BCI: A Real-time Wireless Imagined Speech EEG Decoding System](https://arxiv.org/abs/2511.07936)
*Ji-Ha Park,Heon-Gyu Kwak,Gi-Hwan Shin,Yoo-In Jeon,Sun-Min Park,Ji-Yeon Hwang,Seong-Whan Lee*

Main category: cs.AI

TL;DR: 本文提出并实现了一个实时无线想象语音脑电图（EEG）解码系统，旨在将脑机接口（BCI）技术从实验室环境推向日常实际应用，并展示了其在有线和无线设备上的分类性能。


<details>
  <summary>Details</summary>
Motivation: 当前的脑机接口（BCI）研究多局限于静态固定环境，限制了其在现实世界中的应用。为了实现实用化的BCI，研究旨在开发一个灵活、日常可用的实时无线想象语音EEG解码系统。

Method: 研究引入了一个实时无线想象语音EEG解码系统，强调其可扩展性，支持便携式无线硬件。系统包含一个用户识别模块以提供个性化服务，并利用Lab Streaming Layer管理实时EEG信号流。整个端到端流程能够对想象语音EEG信号进行分类。

Result: 该系统在有线设备上实现了62.00%的4类别准确率，在便携式无线耳机上实现了46.67%的4类别准确率，成功分类了用户的想象语音命令。

Conclusion: 这项工作标志着BCI技术向真正实用化和可及性迈出了重要一步，为未来研究鲁棒、实用和个性化的神经接口指明了方向。

Abstract: Brain-computer interface (BCI) research, while promising, has largely been confined to static and fixed environments, limiting real-world applicability. To move towards practical BCI, we introduce a real-time wireless imagined speech electroencephalogram (EEG) decoding system designed for flexibility and everyday use. Our framework focuses on practicality, demonstrating extensibility beyond wired EEG devices to portable, wireless hardware. A user identification module recognizes the operator and provides a personalized, user-specific service. To achieve seamless, real-time operation, we utilize the lab streaming layer to manage the continuous streaming of live EEG signals to the personalized decoder. This end-to-end pipeline enables a functional real-time application capable of classifying user commands from imagined speech EEG signals, achieving an overall 4-class accuracy of 62.00 % on a wired device and 46.67 % on a portable wireless headset. This paper demonstrates a significant step towards truly practical and accessible BCI technology, establishing a clear direction for future research in robust, practical, and personalized neural interfaces.

</details>


### [25] [Thinker: Training LLMs in Hierarchical Thinking for Deep Search via Multi-Turn Interaction](https://arxiv.org/abs/2511.07943)
*Jun Xu,Xinkai Du,Yu Ao,Peilong Zhao,Yang Li,Ling Zhong,Lin Yuan,Zhongpu Bo,Xiaorui Wang,Mengshu Sun,Zhengke Gui,Dalong Zhang,Zhaoyang Wang,Qiwei Wang,Yangyang Hou,Zhiying Yin,Haofen Wang,Huajun Chen,Lei Liang,Jun Zhou*

Main category: cs.AI

TL;DR: Thinker是一个分层思维模型，通过将复杂问题分解为可监督的子问题，并结合自然语言与逻辑函数表示，实现对外部知识的深度搜索，提高LLM的推理能力和逻辑连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有训练大型语言模型（LLMs）利用外部检索器的方法主要采用端到端强化学习，但这些方法忽视了对推理过程的监督，难以保证逻辑连贯性和严谨性。

Method: Thinker模型采用分层思维，将复杂问题分解为可独立解决的子问题，每个子问题同时用自然语言和等效逻辑函数表示，以支持知识库和网页搜索。子问题之间的依赖关系通过逻辑函数作为参数传递，增强逻辑连贯性。此外，模型还通过知识边界判断来避免不必要的外部搜索，检查子问题是否在LLM的内在知识范围内。

Result: 实验结果表明，Thinker仅需数百个训练样本即可与现有基线方法匹敌。当使用完整训练集时，Thinker在各种数据集和模型尺寸上均显著优于这些方法。

Conclusion: Thinker提供了一种可监督和可验证的深度搜索推理过程，通过分层分解和逻辑函数表示，有效增强了LLMs利用外部知识解决复杂问题的能力，并展现出卓越的性能。

Abstract: Efficient retrieval of external knowledge bases and web pages is crucial for enhancing the reasoning abilities of LLMs. Previous works on training LLMs to leverage external retrievers for solving complex problems have predominantly employed end-to-end reinforcement learning. However, these approaches neglect supervision over the reasoning process, making it difficult to guarantee logical coherence and rigor. To address these limitations, we propose Thinker, a hierarchical thinking model for deep search through multi-turn interaction, making the reasoning process supervisable and verifiable. It decomposes complex problems into independently solvable sub-problems, each dually represented in both natural language and an equivalent logical function to support knowledge base and web searches. Concurrently, dependencies between sub-problems are passed as parameters via these logical functions, enhancing the logical coherence of the problem-solving process. To avoid unnecessary external searches, we perform knowledge boundary determination to check if a sub-problem is within the LLM's intrinsic knowledge, allowing it to answer directly. Experimental results indicate that with as few as several hundred training samples, the performance of Thinker is competitive with established baselines. Furthermore, when scaled to the full training set, Thinker significantly outperforms these methods across various datasets and model sizes. The source code is available at https://github.com/OpenSPG/KAG-Thinker.

</details>


### [26] [TimeFlow: Towards Stochastic-Aware and Efficient Time Series Generation via Flow Matching Modeling](https://arxiv.org/abs/2511.07968)
*He Panjing,Cheng Mingyue,Li Li,Zhang XiaoHan*

Main category: cs.AI

TL;DR: 本文提出TimeFlow，一个基于SDE的流匹配框架，用于高效生成高质量时间序列数据。它通过编码器架构、分量分解速度场和额外的随机项来捕捉时间序列的随机性，并在生成质量、多样性和效率方面超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: 生成高质量时间序列数据对下游挖掘任务至关重要。主要挑战在于建模时间序列固有的随机性（随机波动和局部变化）。现有方法存在不足：扩散模型计算效率低，而基于ODE的流匹配未能明确捕捉随机性，限制了生成序列的保真度。SDE天生适合建模随机性和不确定性，因此本文受此启发进行研究。

Method: 本文提出了TimeFlow，一个新颖的基于SDE的流匹配框架，并集成了纯编码器架构。具体而言，它设计了一个分量分解的速度场来捕捉时间序列的多方面结构，并通过额外的随机项增强了传统的流匹配优化，以提高表示表达能力。TimeFlow灵活通用，在一个统一框架内支持无条件和条件生成任务。

Result: 在各种数据集上进行的广泛实验表明，TimeFlow在生成质量、多样性和效率方面始终优于强大的基线模型。

Conclusion: TimeFlow通过结合SDE基的流匹配框架与特定的架构和优化改进，成功解决了时间序列生成中的随机性和效率挑战，从而实现了卓越的性能。

Abstract: Generating high-quality time series data has emerged as a critical research topic due to its broad utility in supporting downstream time series mining tasks. A major challenge lies in modeling the intrinsic stochasticity of temporal dynamics, as real-world sequences often exhibit random fluctuations and localized variations. While diffusion models have achieved remarkable success, their generation process is computationally inefficient, often requiring hundreds to thousands of expensive function evaluations per sample. Flow matching has emerged as a more efficient paradigm, yet its conventional ordinary differential equation (ODE)-based formulation fails to explicitly capture stochasticity, thereby limiting the fidelity of generated sequences. By contrast, stochastic differential equation (SDE) are naturally suited for modeling randomness and uncertainty. Motivated by these insights, we propose TimeFlow, a novel SDE-based flow matching framework that integrates a encoder-only architecture. Specifically, we design a component-wise decomposed velocity field to capture the multi-faceted structure of time series and augment the vanilla flow-matching optimization with an additional stochastic term to enhance representational expressiveness. TimeFlow is flexible and general, supporting both unconditional and conditional generation tasks within a unified framework. Extensive experiments across diverse datasets demonstrate that our model consistently outperforms strong baselines in generation quality, diversity, and efficiency.

</details>


### [27] [Versatile and Risk-Sensitive Cardiac Diagnosis via Graph-Based ECG Signal Representation](https://arxiv.org/abs/2511.07973)
*Yue Wang,Yuyang Xu,Renjun Hu,Fanqi Shen,Hanyun Jiang,Jun Wang,Jintai Chen,Danny Z. Chen,Jian Wu,Haochao Ying*

Main category: cs.AI

TL;DR: VARS是一种创新的心脏诊断方法，通过图基表示统一处理异构心电图信号，解决了信号多样性不足和风险信号检测不力的问题，在多个数据集上超越现有技术并提高了风险信号识别能力。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在心电图诊断方面取得了进展，但仍面临两大临床应用障碍：处理配置多样化心电图信号的通用性不足，以及因样本不平衡导致风险信号检测不充分。

Method: VARS采用图基表示法统一建模异构心电图信号，将其转换为通用的图结构以捕获关键诊断特征，不受导联数量、采样频率和持续时间的影响。该方法结合去噪重构和对比学习进行表示转换，以保留原始心电图信息并突出病理模式。图中心化公式还增强了诊断敏感性，能够精确识别异常心电图模式。

Result: 在三个结构不同的心电图数据集上，VARS不仅持续超越了现有最先进的模型，还在识别风险信号方面表现出显著改进。此外，VARS提供了可解释性，能够指出导致特定模型输出的具体波形，辅助临床决策。

Conclusion: VARS有望成为全面心脏健康评估的宝贵工具，其在处理异构信号、提高风险信号检测和提供可解释性方面的优势，预示着其在临床应用中的巨大潜力。

Abstract: Despite the rapid advancements of electrocardiogram (ECG) signal diagnosis and analysis methods through deep learning, two major hurdles still limit their clinical adoption: the lack of versatility in processing ECG signals with diverse configurations, and the inadequate detection of risk signals due to sample imbalances. Addressing these challenges, we introduce VersAtile and Risk-Sensitive cardiac diagnosis (VARS), an innovative approach that employs a graph-based representation to uniformly model heterogeneous ECG signals. VARS stands out by transforming ECG signals into versatile graph structures that capture critical diagnostic features, irrespective of signal diversity in the lead count, sampling frequency, and duration. This graph-centric formulation also enhances diagnostic sensitivity, enabling precise localization and identification of abnormal ECG patterns that often elude standard analysis methods. To facilitate representation transformation, our approach integrates denoising reconstruction with contrastive learning to preserve raw ECG information while highlighting pathognomonic patterns. We rigorously evaluate the efficacy of VARS on three distinct ECG datasets, encompassing a range of structural variations. The results demonstrate that VARS not only consistently surpasses existing state-of-the-art models across all these datasets but also exhibits substantial improvement in identifying risk signals. Additionally, VARS offers interpretability by pinpointing the exact waveforms that lead to specific model outputs, thereby assisting clinicians in making informed decisions. These findings suggest that our VARS will likely emerge as an invaluable tool for comprehensive cardiac health assessment.

</details>


### [28] [Benchmarking Multi-Step Legal Reasoning and Analyzing Chain-of-Thought Effects in Large Language Models](https://arxiv.org/abs/2511.07979)
*Wenhan Yu,Xinbo Lin,Lanxin Ni,Jinhua Cheng,Lei Sha*

Main category: cs.AI

TL;DR: 该研究引入了MSLR，首个基于真实司法判决的中文多步法律推理数据集，采用IRAC框架并通过人-LLM协作标注。评估显示LLM在复杂法律推理上表现一般，但模型自主生成的思维链提示能有效提升推理质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在专业领域展现出强大的推理能力，但现有法律基准测试常混淆事实回忆与真正推理，推理过程碎片化，且忽视推理质量。因此，需要一个能更准确评估LLM法律推理能力的数据集。

Method: 该研究引入了MSLR数据集，一个基于真实司法判决的中文多步法律推理数据集。它采用IRAC框架（问题、规则、应用、结论）来建模结构化的专家推理过程。同时，设计了一个可扩展的人-LLM协作标注流程，以高效生成细粒度的步骤级推理标注。研究还在MSLR上评估了多个LLM，并进一步实验了模型自主生成的“自启动思维链”（Self-Initiated Chain-of-Thought）提示。

Result: 多个LLM在MSLR上的表现仅为中等水平，凸显了适应复杂法律推理的挑战。进一步实验表明，模型自主生成的“自启动思维链”提示能显著提高推理的连贯性和质量，优于人工设计的提示。

Conclusion: MSLR数据集及其相关研究有助于推动LLM在推理能力和思维链策略方面的发展，并为未来的研究提供了开放资源。研究强调了LLM在复杂法律推理方面的现有局限性，并提出了有效的改进策略。

Abstract: Large language models (LLMs) have demonstrated strong reasoning abilities across specialized domains, motivating research into their application to legal reasoning. However, existing legal benchmarks often conflate factual recall with genuine inference, fragment the reasoning process, and overlook the quality of reasoning. To address these limitations, we introduce MSLR, the first Chinese multi-step legal reasoning dataset grounded in real-world judicial decision making. MSLR adopts the IRAC framework (Issue, Rule, Application, Conclusion) to model structured expert reasoning from official legal documents. In addition, we design a scalable Human-LLM collaborative annotation pipeline that efficiently produces fine-grained step-level reasoning annotations and provides a reusable methodological framework for multi-step reasoning datasets. Evaluation of multiple LLMs on MSLR shows only moderate performance, highlighting the challenges of adapting to complex legal reasoning. Further experiments demonstrate that Self-Initiated Chain-of-Thought prompts generated by models autonomously improve reasoning coherence and quality, outperforming human-designed prompts. MSLR contributes to advancing LLM reasoning and Chain-of-Thought strategies and offers open resources for future research. The dataset and code are available at https://github.com/yuwenhan07/MSLR-Bench and https://law.sjtu.edu.cn/flszyjzx/index.html.

</details>


### [29] [Towards Fine-Grained Interpretability: Counterfactual Explanations for Misclassification with Saliency Partition](https://arxiv.org/abs/2511.07974)
*Lintong Zhang,Kang Yin,Seong-Whan Lee*

Main category: cs.AI

TL;DR: 本文提出了一种细粒度反事实解释框架，用于解决模型误分类中现有解释缺乏细节的问题。该框架以非生成方式提供对象级和部分级可解释性，通过量化相似性和加权贡献，并引入基于Shapley值的显著性分区模块，以捕获更细致、直观有意义的区域。


<details>
  <summary>Details</summary>
Motivation: 现有的基于归因的解释技术在细粒度任务中，尤其是在模型误分类情况下，往往缺乏足够的粒度，导致解释细节不足，难以提供深入见解。

Method: 本文提出了一种细粒度反事实解释框架，旨在回答两个问题：哪些细粒度特征导致模型误分类，以及主导局部特征如何影响反事实调整。该方法以非生成方式，通过量化正确分类和错误分类样本在感兴趣区域内的相似性并加权组件贡献，生成可解释的反事实。此外，还引入了一个基于Shapley值贡献的显著性分区模块，以隔离具有区域特定相关性的特征。

Result: 广泛的实验证明，该方法在捕获更细粒度、直观有意义的区域方面表现出优越性，超越了其他细粒度方法。

Conclusion: 该研究成功开发了一种能够提供细粒度反事实解释的框架，有效解决了现有解释方法在模型误分类场景下缺乏足够细节的问题，并能捕获更具洞察力的局部特征。

Abstract: Attribution-based explanation techniques capture key patterns to enhance visual interpretability; however, these patterns often lack the granularity needed for insight in fine-grained tasks, particularly in cases of model misclassification, where explanations may be insufficiently detailed. To address this limitation, we propose a fine-grained counterfactual explanation framework that generates both object-level and part-level interpretability, addressing two fundamental questions: (1) which fine-grained features contribute to model misclassification, and (2) where dominant local features influence counterfactual adjustments. Our approach yields explainable counterfactuals in a non-generative manner by quantifying similarity and weighting component contributions within regions of interest between correctly classified and misclassified samples. Furthermore, we introduce a saliency partition module grounded in Shapley value contributions, isolating features with region-specific relevance. Extensive experiments demonstrate the superiority of our approach in capturing more granular, intuitively meaningful regions, surpassing fine-grained methods.

</details>


### [30] [The One Where They Brain-Tune for Social Cognition: Multi-Modal Brain-Tuning on Friends](https://arxiv.org/abs/2511.07988)
*Nico Policzer,Cameron Braunstein,Mariya Toneva*

Main category: cs.AI

TL;DR: 本研究将脑调优扩展到多模态音视频模型，通过针对STS区域进行微调，显著提升了模型与大脑的对齐度，并改善了社交认知任务（如情景喜剧中的讽刺检测）的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，对音频模型进行脑调优可以提高模型与大脑的对齐度，并改善下游语义和音频任务的性能。本研究旨在将此方法扩展到多模态音视频模型，以增强社交认知，并针对社会处理的关键区域——颞上沟（STS）进行优化。

Method: 研究采用多模态音视频模型，在受试者观看《老友记》时，通过脑调优（微调模型以更好地预测对应的fMRI活动）来靶向颞上沟（STS）区域。随后评估了模型与STS及相邻感兴趣区域的大脑对齐度，并测试了模型在与训练数据相关的社交认知任务（情景喜剧中的讽刺检测）上的表现。

Result: 研究发现，模型与STS及一个相邻的ROI的大脑对齐度显著增加，并且在情景喜剧中的讽刺检测这一社交认知任务上表现出改进。

Conclusion: 本研究成功将脑调优方法扩展到多模态领域，并证明了在针对相关功能区域进行调优后，可以改善下游任务的性能。

Abstract: Recent studies on audio models show brain-tuning - fine-tuning models to better predict corresponding fMRI activity - improves brain alignment and increases performance on downstream semantic and audio tasks. We extend this approach to a multimodal audio-video model to enhance social cognition, targeting the Superior Temporal Sulcus (STS), a key region for social processing, while subjects watch Friends. We find significant increases in brain alignment to the STS and an adjacent ROI, as well as improvements to a social cognition task related to the training data - sarcasm detection in sitcoms. In summary, our study extends brain-tuning to the multi-modal domain, demonstrating improvements to a downstream task after tuning to a relevant functional region.

</details>


### [31] [VSPO: Validating Semantic Pitfalls in Ontology via LLM-Based CQ Generation](https://arxiv.org/abs/2511.07991)
*Hyojun Choi,Seokju Hwang,Kyong-Ho Lee*

Main category: cs.AI

TL;DR: 本研究提出了一种新颖的数据集和模型 (VSPO)，利用大型语言模型 (LLM) 自动生成能力问题 (CQs)，以验证本体设计中的语义陷阱，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 本体工程师手动创建能力问题耗时且成本高昂。现有利用 LLM 自动化生成 CQ 的方法主要基于与现有数据集的相似性进行评估，无法有效验证“误用 allValuesFrom”等语义陷阱，而这些陷阱又难以通过基于规则的方法检测。

Method: 研究提出一个名为 VSPO 的本体语义陷阱验证数据集和模型。通过 LLM 生成类和属性的自然语言定义，并通过移除公理或修改逻辑运算符（如将 union 替换为 intersection）来模拟定义与本体之间的错位。随后，微调 LLaMA-3.1-8B-Instruct 模型，使其能够生成验证这些语义差异的 CQ。

Result: 所生成的 CQ 比现有公共数据集能检测更广泛的建模错误。微调后的模型在陷阱验证的 CQ 生成方面表现优异，比 GPT-4.1 基线模型的精确度高 26%，召回率高 28.2%。

Conclusion: 本研究实现了使用 LLM 自动生成 TBox 验证 CQ，显著减少了手动工作量，并提高了本体与专家知识之间的语义对齐。这是首个利用 LLM 针对 CQ 生成中的语义陷阱验证进行研究的工作。

Abstract: Competency Questions (CQs) play a crucial role in validating ontology design. While manually crafting CQs can be highly time-consuming and costly for ontology engineers, recent studies have explored the use of large language models (LLMs) to automate this process. However, prior approaches have largely evaluated generated CQs based on their similarity to existing datasets, which often fail to verify semantic pitfalls such as "Misusing allValuesFrom". Since such pitfalls cannot be reliably detected through rule-based methods, we propose a novel dataset and model of Validating Semantic Pitfalls in Ontology (VSPO) for CQ generation specifically designed to verify the semantic pitfalls. To simulate missing and misused axioms, we use LLMs to generate natural language definitions of classes and properties and introduce misalignments between the definitions and the ontology by removing axioms or altering logical operators (e.g., substituting union with intersection). We then fine-tune LLaMA-3.1-8B-Instruct to generate CQs that validate these semantic discrepancies between the provided definitions and the corresponding axioms. The resulting CQs can detect a broader range of modeling errors compared to existing public datasets. Our fine-tuned model demonstrates superior performance over baselines, showing 26% higher precision and 28.2% higher recall than GPT-4.1 in generating CQs for pitfall validation. This research enables automatic generation of TBox-validating CQs using LLMs, significantly reducing manual effort while improving semantic alignment between ontologies and expert knowledge. To the best of our knowledge, this is the first study to target semantic pitfall validation in CQ generation using LLMs.

</details>


### [32] [Enhancing Logical Expressiveness in Graph Neural Networks via Path-Neighbor Aggregation](https://arxiv.org/abs/2511.07994)
*Han Yu,Xiaojuan Zhao,Aiping Li,Kai Chen,Ziniu Liu,Zhichao Peng*

Main category: cs.AI

TL;DR: 现有图神经网络（GNN）在知识图谱（KG）推理中的逻辑表达能力不足，尤其是在多关系图上。本文提出Path-Neighbor增强型GNN（PN-GNN），通过聚合推理路径上的节点邻居嵌入来增强逻辑表达能力，并从理论和实验两方面证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 图神经网络（GNN）在知识图谱（KG）推理中广泛应用，但现有研究主要关注简单单关系图，对GNN表达KG中逻辑规则的能力讨论不足。如何增强GNN的逻辑表达能力是一个关键问题。

Method: 本文提出Path-Neighbor增强型GNN（PN-GNN）。该方法通过聚合推理路径上的节点邻居嵌入来增强GNN的逻辑表达能力。首先，分析了现有基于GNN方法的逻辑表达能力缺陷；然后，从理论上研究了PN-GNN的逻辑表达能力；最后，在六个合成数据集和两个真实世界数据集上评估了PN-GNN的逻辑表达能力。

Result: 理论分析表明，PN-GNN不仅具有比C-GNN更强的逻辑表达能力，而且其(k+1)跳逻辑表达能力严格优于k跳。广泛的实验也证实，PN-GNN在不损害泛化能力的情况下增强了逻辑规则的表达能力，并在知识图谱推理任务中表现出具有竞争力的性能。

Conclusion: PN-GNN通过聚合推理路径上的节点邻居嵌入，成功增强了图神经网络在知识图谱推理中的逻辑表达能力。理论分析和实验结果均支持PN-GNN在逻辑表达能力上的优越性，且不影响泛化能力。

Abstract: Graph neural networks (GNNs) can effectively model structural information of graphs, making them widely used in knowledge graph (KG) reasoning. However, existing studies on the expressive power of GNNs mainly focuses on simple single-relation graphs, and there is still insufficient discussion on the power of GNN to express logical rules in KGs. How to enhance the logical expressive power of GNNs is still a key issue. Motivated by this, we propose Path-Neighbor enhanced GNN (PN-GNN), a method to enhance the logical expressive power of GNN by aggregating node-neighbor embeddings on the reasoning path. First, we analyze the logical expressive power of existing GNN-based methods and point out the shortcomings of the expressive power of these methods. Then, we theoretically investigate the logical expressive power of PN-GNN, showing that it not only has strictly stronger expressive power than C-GNN but also that its $(k+1)$-hop logical expressiveness is strictly superior to that of $k$-hop. Finally, we evaluate the logical expressive power of PN-GNN on six synthetic datasets and two real-world datasets. Both theoretical analysis and extensive experiments confirm that PN-GNN enhances the expressive power of logical rules without compromising generalization, as evidenced by its competitive performance in KG reasoning tasks.

</details>


### [33] [Combining LLM Semantic Reasoning with GNN Structural Modeling for Multi-view Multi-Label Feature Selection](https://arxiv.org/abs/2511.08008)
*Zhiqi Chen,Yuzhou Liu,Jiarui Liu,Wanfu Gao*

Main category: cs.AI

TL;DR: 本文提出了一种结合大语言模型（LLM）语义推理和图神经网络（GNN）结构建模的多视图多标签特征选择方法，旨在同时利用数据的统计和语义信息。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图多标签特征选择（MVMLFS）方法主要关注数据的统计信息，但很少考虑语义信息。在涉及高维、多模态数据的机器学习场景中，语义信息对于识别信息丰富的特征至关重要。

Method: 该方法包含三个主要组件：1) 使用LLM作为评估代理，评估特征、视图和标签描述之间的潜在语义相关性。2) 设计一个双层语义感知异构图，包含语义图（表示语义关系）和统计图。3) 应用轻量级图注意力网络（GAT）在异构图中学习节点嵌入作为特征显著性分数，用于特征排序和选择。

Result: 在多个基准数据集上的实验结果表明，该方法优于现有最先进的基线方法，并且在小规模数据集上仍然有效。

Conclusion: 该方法展示了其鲁棒性、灵活性和泛化能力，成功地将LLM的语义推理与GNN的结构建模相结合，提升了多视图多标签特征选择的性能。

Abstract: Multi-view multi-label feature selection aims to identify informative features from heterogeneous views, where each sample is associated with multiple interdependent labels. This problem is particularly important in machine learning involving high-dimensional, multimodal data such as social media, bioinformatics or recommendation systems. Existing Multi-View Multi-Label Feature Selection (MVMLFS) methods mainly focus on analyzing statistical information of data, but seldom consider semantic information. In this paper, we aim to use these two types of information jointly and propose a method that combines Large Language Models (LLMs) semantic reasoning with Graph Neural Networks (GNNs) structural modeling for MVMLFS. Specifically, the method consists of three main components. (1) LLM is first used as an evaluation agent to assess the latent semantic relevance among feature, view, and label descriptions. (2) A semantic-aware heterogeneous graph with two levels is designed to represent relations among features, views and labels: one is a semantic graph representing semantic relations, and the other is a statistical graph. (3) A lightweight Graph Attention Network (GAT) is applied to learn node embedding in the heterogeneous graph as feature saliency scores for ranking and selection. Experimental results on multiple benchmark datasets demonstrate the superiority of our method over state-of-the-art baselines, and it is still effective when applied to small-scale datasets, showcasing its robustness, flexibility, and generalization ability.

</details>


### [34] [Multivariate Time series Anomaly Detection:A Framework of Hidden Markov Models](https://arxiv.org/abs/2511.07995)
*Jinbo Li,Witold Pedrycz,Iqbal Jamal*

Main category: cs.AI

TL;DR: 本研究提出一种多元时间序列异常检测方法，通过模糊C均值聚类和模糊积分将多元序列转换为单变量序列，然后利用隐马尔可夫模型进行异常检测。


<details>
  <summary>Details</summary>
Motivation: 需要在多元时间序列中检测异常。

Method: 开发了一种将多元时间序列转换为单变量时间序列的方法。研究了多种转换技术，包括模糊C均值（FCM）聚类和模糊积分。随后，采用隐马尔可夫模型（HMM）来检测多元时间序列中的异常。构建了基于HMM的异常检测器，并在此背景下比较了多种转换方法。

Result: 报告了一系列实验研究和一些比较分析。

Conclusion: 本研究开发并评估了一种通过转换多元时间序列为单变量序列并结合HMM进行异常检测的方法，并对多种转换技术进行了比较。

Abstract: In this study, we develop an approach to multivariate time series anomaly detection focused on the transformation of multivariate time series to univariate time series. Several transformation techniques involving Fuzzy C-Means (FCM) clustering and fuzzy integral are studied. In the sequel, a Hidden Markov Model (HMM), one of the commonly encountered statistical methods, is engaged here to detect anomalies in multivariate time series. We construct HMM-based anomaly detectors and in this context compare several transformation methods. A suite of experimental studies along with some comparative analysis is reported.

</details>


### [35] [Capturing Complex Spatial-Temporal Dependencies in Traffic Forecasting: A Self-Attention Approach](https://arxiv.org/abs/2511.07980)
*Zheng Chenghong,Zongyin Deng,Liu Cheng,Xiong Simin,Di Deshi,Li Guanyao*

Main category: cs.AI

TL;DR: 本文提出ST-SAM，一种新颖高效的自注意力模型，用于预测区域交通流量的流入流出，通过捕获复杂的联合时空依赖性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 交通预测问题因区域间复杂的时空相互依赖性而复杂。现有工作通常以解耦方式研究时空依赖性，未能有效捕捉它们的联合效应。

Method: 本文提出ST-SAM（Spatial-Temporal Self-Attention Model）。它首先使用区域嵌入层从交通数据中学习区域的时间特定嵌入，然后采用基于自注意力机制的时空依赖学习模块，捕捉近距离和远距离区域的联合时空依赖。ST-SAM完全依赖自注意力来捕获局部和全局时空相关性。

Result: 在两个真实世界数据集上进行的广泛实验表明，ST-SAM在准确性和效率方面均显著优于现有最先进方法。实验中，RMSE平均提高了15%，MAPE提高了17%，训练时间快了32倍。

Conclusion: ST-SAM模型通过利用自注意力机制有效且高效地捕捉联合时空依赖性，在交通预测任务中展现出卓越的性能，解决了现有方法未能充分处理复杂时空关联的问题。

Abstract: We study the problem of traffic forecasting, aiming to predict the inflow and outflow of a region in the subsequent time slot. The problem is complex due to the intricate spatial and temporal interdependence among regions. Prior works study the spatial and temporal dependency in a decouple manner, failing to capture their joint effect. In this work, we propose ST-SAM, a novel and efficient Spatial-Temporal Self-Attention Model for traffic forecasting. ST-SAM uses a region embedding layer to learn time-specific embedding from traffic data for regions. Then, it employs a spatial-temporal dependency learning module based on self-attention mechanism to capture the joint spatial-temporal dependency for both nearby and faraway regions. ST-SAM entirely relies on self-attention to capture both local and global spatial-temporal correlations, which make it effective and efficient. Extensive experiments on two real world datasets show that ST-SAM is substantially more accurate and efficient than the state-of-the-art approaches (with an average improvement of up to 15% on RMSE, 17% on MAPE, and 32 times on training time in our experiments).

</details>


### [36] [Numerical Sensitivity and Robustness: Exploring the Flaws of Mathematical Reasoning in Large Language Models](https://arxiv.org/abs/2511.08022)
*Zhishen Sun,Guang Dai,Ivor Tsang,Haishan Ye*

Main category: cs.AI

TL;DR: 本研究通过引入语义无关的扰动句子和核心指令缺失，评估了大型语言模型（LLMs）在复杂数学推理环境中的鲁棒性和真实理解能力，发现LLMs对数值扰动敏感，且可能依赖模式匹配而非逻辑推理。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在数学推理方面取得了显著进展，但其是否具备真正的数学理解能力仍存在争议，本研究旨在通过复杂环境评估来探索这一问题。

Method: 1. 提出一个新的扰动框架，通过注入额外语义无关的扰动句子并逐渐增加扰动强度来评估LLMs的推理能力。2. 采用核心提问指令缺失作为额外的扰动方法，进一步分析LLMs的问题解决机制。

Result: 1. LLMs在面对不含数字的扰动句子时表现稳定，但存在鲁棒性边界，随着扰动强度增加性能下降。2. 面对含数字的扰动句子时，性能下降更显著，小型开源模型下降近10%甚至更多，最大下降达51.55%；即使是先进的商业LLMs也下降3%-10%。3. 模型对包含数值信息的扰动更敏感，更容易给出错误答案。4. 在核心提问指令缺失的情况下，模型仍能保持20%-40%的准确率，表明LLMs可能依赖记忆模板或模式匹配而非逻辑推理来完成任务。

Conclusion: 本研究揭示了当前LLMs在推理能力方面的不足和局限性，特别是在面对数值扰动时表现出脆弱性，并且可能更多地依赖模式匹配而非深层逻辑理解，这对LLMs的进一步发展具有重要意义。

Abstract: LLMs have made significant progress in the field of mathematical reasoning, but whether they have true the mathematical understanding ability is still controversial. To explore this issue, we propose a new perturbation framework to evaluate LLMs' reasoning ability in complex environments by injecting additional semantically irrelevant perturbation sentences and gradually increasing the perturbation intensity. At the same time, we use an additional perturbation method: core questioning instruction missing, to further analyze the LLMs' problem-solving mechanism. The experimental results show that LLMs perform stably when facing perturbation sentences without numbers, but there is also a robustness boundary. As the perturbation intensity increases, the performance exhibits varying degrees of decline; when facing perturbation sentences with numbers, the performance decreases more significantly, most open source models with smaller parameters decrease by nearly or even more than 10%, and further increasing with the enhancement of perturbation intensity, with the maximum decrease reaching 51.55%. Even the most advanced commercial LLMs have seen a 3%-10% performance drop. By analyzing the reasoning process of LLMs in detail, We find that models are more sensitive to perturbations with numerical information and are more likely to give incorrect answers when disturbed by irrelevant numerical information. The higher the perturbation intensity, the more obvious these defects are. At the same time, in the absence of core questioning instruction, models can still maintain an accuracy of 20%-40%, indicating that LLMs may rely on memory templates or pattern matching to complete the task, rather than logical reasoning. In general, our work reveals the shortcomings and limitations of current LLMs in their reasoning capabilities, which is of great significance for the further development of LLMs.

</details>


### [37] [Knowledge-Augmented Long-CoT Generation for Complex Biomolecular Reasoning](https://arxiv.org/abs/2511.08024)
*Tianwen Lyu,Xiang Zhuang,Keyan Ding,Xinzhe Cao,Lei Liang,Wei Zhao,Qiang Zhang,Huajun Chen*

Main category: cs.AI

TL;DR: 该研究提出了一种知识增强的长链思维推理框架，将大型语言模型与知识图谱相结合，以解决生物分子推理中的逻辑不一致和领域知识缺乏问题，并引入了一个新的生物分子问答基准PrimeKGQA。


<details>
  <summary>Details</summary>
Motivation: 理解复杂的生物分子机制需要多步骤推理，但大型语言模型在此类任务中存在逻辑不一致和缺乏领域知识的问题。现有方法未能有效捕捉长期的机制依赖性，且现有基准在规模和深度推理链标注方面存在不足。

Method: 本文提出了一个“知识增强的长链思维推理”框架，该框架通过引导式多跳遍历和剪枝在知识图谱上构建机制链。这些链被用于监督微调以改善事实基础，并通过强化学习进一步优化以增强推理的可靠性和一致性。此外，还引入了PrimeKGQA，一个全面的生物分子问答基准。

Result: 在PrimeKGQA和现有数据集上的实验结果表明，尽管大型闭源模型在相对简单的任务上表现良好，但随着推理深度的增加，本文方法显示出明显优势，在需要遍历结构化生物知识的多跳任务上取得了最先进的性能。

Conclusion: 研究结果强调了将结构化知识与高级推理策略相结合，对于实现可靠和可解释的生物分子推理的有效性。

Abstract: Understanding complex biomolecular mechanisms requires multi-step reasoning across molecular interactions, signaling cascades, and metabolic pathways. While large language models(LLMs) show promise in such tasks, their application to biomolecular problems is hindered by logical inconsistencies and the lack of grounding in domain knowledge. Existing approaches often exacerbate these issues: reasoning steps may deviate from biological facts or fail to capture long mechanistic dependencies. To address these challenges, we propose a Knowledge-Augmented Long-CoT Reasoning framework that integrates LLMs with knowledge graph-based multi-hop reasoning chains. The framework constructs mechanistic chains via guided multi-hop traversal and pruning on the knowledge graph; these chains are then incorporated into supervised fine-tuning to improve factual grounding and further refined with reinforcement learning to enhance reasoning reliability and consistency. Furthermore, to overcome the shortcomings of existing benchmarks, which are often restricted in scale and scope and lack annotations for deep reasoning chains, we introduce PrimeKGQA, a comprehensive benchmark for biomolecular question answering. Experimental results on both PrimeKGQA and existing datasets demonstrate that although larger closed-source models still perform well on relatively simple tasks, our method demonstrates clear advantages as reasoning depth increases, achieving state-of-the-art performance on multi-hop tasks that demand traversal of structured biological knowledge. These findings highlight the effectiveness of combining structured knowledge with advanced reasoning strategies for reliable and interpretable biomolecular reasoning.

</details>


### [38] [Towards a Standard, Enterprise-Relevant Agentic AI Benchmark: Lessons from 5.5 billion tokens' worth of agentic AI evaluations](https://arxiv.org/abs/2511.08042)
*JV Roig*

Main category: cs.AI

TL;DR: KAMI v0.1是一个针对企业级智能体AI系统的新基准，解决了数据污染和智能体能力评估问题。研究发现，传统基准无法有效预测实际智能体性能，且新模型在企业任务中不总是优于旧模型。


<details>
  <summary>Details</summary>
Motivation: 企业采用智能体AI系统需要可靠的评估方法，以反映真实世界的部署场景。传统LLM基准存在训练数据污染问题，且无法衡量多步工具使用和不确定性下的决策等智能体能力。

Method: 提出了Kamiwaza智能体绩效指数（KAMI）v0.1，这是一个专注于企业的基准。通过处理170,000个LLM测试项，跨越35种模型配置，处理了超过55亿个tokens。

Result: 传统基准排名不能很好地预测实际智能体性能。新一代模型（如Llama 4或Qwen 3）在企业相关任务上并不总是优于其旧一代变体。还提供了关于成本-性能权衡、模型特定行为模式以及推理能力对token效率影响的见解。

Conclusion: KAMI v0.1为企业智能体AI提供了更可靠的评估方法，揭示了传统基准的局限性，并为企业部署决策提供了关键见解，强调新模型并非总是在所有企业场景中表现更优。

Abstract: Enterprise adoption of agentic AI systems requires reliable evaluation methods that reflect real-world deployment scenarios. Traditional LLM benchmarks suffer from training data contamination and fail to measure agentic capabilities such as multi-step tool use and decision-making under uncertainty. We present the Kamiwaza Agentic Merit Index (KAMI) v0.1, an enterprise-focused benchmark that addresses both contamination resistance and agentic evaluation. Through 170,000 LLM test items processing over 5.5 billion tokens across 35 model configurations, we demonstrate that traditional benchmark rankings poorly predict practical agentic performance. Notably, newer generation models like Llama 4 or Qwen 3 do not always outperform their older generation variants on enterprise-relevant tasks, contradicting traditional benchmark trends. We also present insights on cost-performance tradeoffs, model-specific behavioral patterns, and the impact of reasoning capabilities on token efficiency -- findings critical for enterprises making deployment decisions.

</details>


### [39] [Dual-Process Scaffold Reasoning for Enhancing LLM Code Debugging](https://arxiv.org/abs/2511.08052)
*Po-Chung Hsieh,Chin-Po Chen,Jeng-Lin Li,Ming-Ching Chang*

Main category: cs.AI

TL;DR: 本文提出了一种名为“脚手架推理”（Scaffold Reasoning）的新型心理学支持框架，用于提高大型语言模型（LLMs）在代码调试中的推理准确性和效率，该框架在DebugBench上表现出色并与人类认知过程一致。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在推理方面表现出复杂的问题解决能力，但在平衡推理复杂性和计算效率方面仍存在挑战，尤其是在深度探索作为System 2的中间推理步骤方面。现有研究开始利用心理学理论优化认知路径，但对System 2推理的深入探索仍不足。

Method: 本文提出了一种新颖的、基于心理学原理的“脚手架推理”（Scaffold Reasoning）框架，专用于代码调试。该框架包含三个流：脚手架流（Scaffold Stream）负责构建参考代码，分析流（Analytic Stream）用于分析错误代码，以及集成流（Integration Stream）负责将前两者的结果进行整合。

Result: 该框架在DebugBench上实现了88.91%的通过率，平均每个问题推理时间为5.36秒。它在推理准确性和效率上均优于其他LLMs的推理方法。进一步分析揭示了不同认知路径在不同问题难度和错误类型下的优缺点，并证实该框架与人类认知过程的对齐。

Conclusion: 所提出的“脚手架推理”框架为LLMs在代码调试中提供了一种有效且高效的推理方法，成功平衡了推理的准确性和计算效率，并与人类认知过程高度吻合。

Abstract: Recent LLMs have demonstrated sophisticated problem-solving capabilities on various benchmarks through advanced reasoning algorithms. However, the key research question of identifying reasoning steps that balance complexity and computational efficiency remains unsolved. Recent research has increasingly drawn upon psychological theories to explore strategies for optimizing cognitive pathways. The LLM's final outputs and intermediate steps are regarded as System 1 and System 2, respectively. However, an in-depth exploration of the System 2 reasoning is still lacking. Therefore, we propose a novel psychologically backed Scaffold Reasoning framework for code debugging, which encompasses the Scaffold Stream, Analytic Stream, and Integration Stream. The construction of reference code within the Scaffold Stream is integrated with the buggy code analysis results produced by the Analytic Stream through the Integration Stream. Our framework achieves an 88.91% pass rate and an average inference time of 5.36 seconds per-problem on DebugBench, outperforming other reasoning approaches across various LLMs in both reasoning accuracy and efficiency. Further analyses elucidate the advantages and limitations of various cognitive pathways across varying problem difficulties and bug types. Our findings also corroborate the alignment of the proposed Scaffold Reasoning framework with human cognitive processes.

</details>


### [40] [Information Capacity: Evaluating the Efficiency of Large Language Models via Text Compression](https://arxiv.org/abs/2511.08066)
*Cheng Yuan,Jiawei Shao,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: 本文提出了一种名为“信息容量”的统一指标，用于衡量大型语言模型（LLM）的效率，该指标基于文本压缩性能与计算复杂度的比率，并考虑了分词器效率，在不同模型系列中展现出一致性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的快速发展及其应用扩展，计算资源需求激增，尤其在测试时缩放（test-time scaling）的广泛采用下，模型能力与资源消耗之间的矛盾日益突出。然而，目前缺乏一个能准确反映不同模型大小和架构下LLM效率的统一指标。

Method: 受压缩与智能之间关联的启发，本文引入了“信息容量”这一模型效率度量标准。它基于文本压缩性能相对于计算复杂度的表现来衡量效率。该方法还独具特色地整合了分词器效率，这是LLM评估中常被忽略但影响输入输出token数量的关键因素。

Result: 在主流开源模型上的实证评估表明，同一系列内不同大小的模型展现出一致的信息容量。该指标使得跨模型系列进行公平的效率比较以及在模型系列内进行准确的性能预测成为可能。对49个模型在5个异构数据集上的评估显示，分词器效率、预训练数据和混合专家（MoE）架构对模型效率的影响结果是一致的。

Conclusion: 信息容量作为一个统一的效率指标，能够有效地衡量LLM的效率，它不仅考虑了模型压缩能力与计算成本，还创新性地整合了分词器效率，为LLM的评估和比较提供了一个公平且一致的框架。

Abstract: Recent years have witnessed the rapid advancements of large language models (LLMs) and their expanding applications, leading to soaring demands for computational resources. The widespread adoption of test-time scaling further aggravates the tension between model capability and resource consumption, highlighting the importance of inference efficiency. However, a unified metric that accurately reflects an LLM's efficiency across different model sizes and architectures remains absent. Motivated by the correlation between compression and intelligence, we introduce information capacity, a measure of model efficiency based on text compression performance relative to computational complexity. Larger models can predict the next token more accurately, achieving greater compression gains but at higher computational costs. Empirical evaluations on mainstream open-source models show that models of varying sizes within a series exhibit consistent information capacity. This metric enables a fair efficiency comparison across model series and accurate performance prediction within a model series. A distinctive feature of information capacity is that it incorporates tokenizer efficiency, which affects both input and output token counts but is often neglected in LLM evaluations. We assess the information capacity of 49 models on 5 heterogeneous datasets and observe consistent results on the influences of tokenizer efficiency, pretraining data, and the mixture-of-experts architecture.

</details>


### [41] [Clustering-based Anomaly Detection in Multivariate Time Series Data](https://arxiv.org/abs/2511.08072)
*Jinbo Li,Hesam Izakian,Witold Pedrycz,Iqbal Jamal*

Main category: cs.AI

TL;DR: 本文提出一种基于聚类的多元时间序列异常检测方法，通过滑动窗口、扩展模糊聚类和重建准则来识别幅度和形状异常，并结合置信指数和粒子群优化。


<details>
  <summary>Details</summary>
Motivation: 多元时间序列中的异常检测是一个具有挑战性的问题，因为它需要同时考虑时间和变量之间的关系，并且在科学和工程领域有广泛应用。

Method: 首先，使用滑动窗口生成多元子序列。然后，应用扩展模糊聚类揭示子序列中的结构。接着，采用重建准则利用最优聚类中心和划分矩阵重建子序列。最后，构建置信指数来量化异常水平，并使用粒子群优化（PSO）作为异常检测的优化工具。

Result: 在多个合成数据集和六个真实世界数据集上的实验研究表明，所提出的方法能够有效地检测多元时间序列中的异常。

Conclusion: 该框架利用扩展模糊聚类揭示的簇，能够检测多元时间序列中的异常，特别适用于识别各种应用领域（如医疗保健、天气数据分析、金融和疾病爆发检测）中的异常幅度和形状模式。

Abstract: Multivariate time series data come as a collection of time series describing different aspects of a certain temporal phenomenon. Anomaly detection in this type of data constitutes a challenging problem yet with numerous applications in science and engineering because anomaly scores come from the simultaneous consideration of the temporal and variable relationships. In this paper, we propose a clustering-based approach to detect anomalies concerning the amplitude and the shape of multivariate time series. First, we use a sliding window to generate a set of multivariate subsequences and thereafter apply an extended fuzzy clustering to reveal a structure present within the generated multivariate subsequences. Finally, a reconstruction criterion is employed to reconstruct the multivariate subsequences with the optimal cluster centers and the partition matrix. We construct a confidence index to quantify a level of anomaly detected in the series and apply Particle Swarm Optimization as an optimization vehicle for the problem of anomaly detection. Experimental studies completed on several synthetic and six real-world datasets suggest that the proposed methods can detect the anomalies in multivariate time series. With the help of available clusters revealed by the extended fuzzy clustering, the proposed framework can detect anomalies in the multivariate time series and is suitable for identifying anomalous amplitude and shape patterns in various application domains such as health care, weather data analysis, finance, and disease outbreak detection.

</details>


### [42] [MSCR: Exploring the Vulnerability of LLMs' Mathematical Reasoning Abilities Using Multi-Source Candidate Replacement](https://arxiv.org/abs/2511.08055)
*Zhishen Sun,Guang Dai,Haishan Ye*

Main category: cs.AI

TL;DR: 本研究提出MSCR，一种基于多源候选替换的自动化对抗攻击方法，发现即使是单词扰动也能显著降低大型语言模型在数学推理任务上的准确性，并增加其响应长度和资源消耗，揭示了LLM在此类任务中的鲁棒性和效率缺陷。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在数学推理等复杂任务上表现出接近人类的能力，但其在微小输入扰动下的鲁棒性尚未得到系统性研究。现有方法普遍存在可扩展性有限、语义保留弱和成本高的问题。

Method: 本研究提出MSCR（多源候选替换）自动化对抗攻击方法。该方法结合嵌入空间余弦相似度、WordNet词典和掩码语言模型的上下文预测，为输入问题中的每个词生成一组语义相似的候选词，然后进行过滤并逐一替换以执行攻击。

Result: 在大规模实验中，MSCR方法发现，即使仅涉及单个词的轻微扰动，也能显著降低所有LLM模型的准确性，在GSM8K基准上最大下降49.89%，在MATH500上最大下降35.40%，同时保持了扰动问题的高度语义一致性。此外，扰动不仅导致错误输出，还大幅增加了平均响应长度，导致更多冗余推理路径和更高的计算资源消耗。

Conclusion: 这些发现突显了当前大型语言模型在数学推理任务中存在的鲁棒性缺陷和效率瓶颈。

Abstract: LLMs demonstrate performance comparable to human abilities in complex tasks such as mathematical reasoning, but their robustness in mathematical reasoning under minor input perturbations still lacks systematic investigation. Existing methods generally suffer from limited scalability, weak semantic preservation, and high costs. Therefore, we propose MSCR, an automated adversarial attack method based on multi-source candidate replacement. By combining three information sources including cosine similarity in the embedding space of LLMs, the WordNet dictionary, and contextual predictions from a masked language model, we generate for each word in the input question a set of semantically similar candidates, which are then filtered and substituted one by one to carry out the attack. We conduct large-scale experiments on LLMs using the GSM8K and MATH500 benchmarks. The results show that even a slight perturbation involving only a single word can significantly reduce the accuracy of all models, with the maximum drop reaching 49.89% on GSM8K and 35.40% on MATH500, while preserving the high semantic consistency of the perturbed questions. Further analysis reveals that perturbations not only lead to incorrect outputs but also substantially increase the average response length, which results in more redundant reasoning paths and higher computational resource consumption. These findings highlight the robustness deficiencies and efficiency bottlenecks of current LLMs in mathematical reasoning tasks.

</details>


### [43] [Prudential Reliability of Large Language Models in Reinsurance: Governance, Assurance, and Capital Efficiency](https://arxiv.org/abs/2511.08082)
*Stella C. Dong*

Main category: cs.AI

TL;DR: 本文提出了一套审慎框架，用于评估巨型语言模型（LLMs）在再保险领域的可靠性，并通过基准测试证明了在明确治理下，LLMs可以满足审慎标准。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了在再保险领域评估大型语言模型的可靠性，并将其与Solvency II、SR 11-7以及EIOPA、NAIC、IAIS等监管机构的现有监管期望和指导方针相结合。

Method: 研究方法是开发了一个包含治理、数据溯源、保证、韧性和监管一致性五个支柱的审慎框架，将监管期望转化为可衡量的生命周期控制。该框架通过再保险人工智能可靠性和保证基准（RAIRAB）实现，评估嵌入治理的LLMs是否符合接地性、透明度和问责制的审慎标准。

Result: 结果显示，在六个任务家族中，检索增强型配置的接地准确性更高（0.90），幻觉和解释漂移减少了约40%，透明度几乎翻倍。这些机制降低了风险转移和资本配置中的信息摩擦。

Conclusion: 结论是，当治理明确、数据可追溯、保证可验证时，现有的审慎原则已经能够适应可靠的人工智能应用。

Abstract: This paper develops a prudential framework for assessing the reliability of large language models (LLMs) in reinsurance. A five-pillar architecture--governance, data lineage, assurance, resilience, and regulatory alignment--translates supervisory expectations from Solvency II, SR 11-7, and guidance from EIOPA (2025), NAIC (2023), and IAIS (2024) into measurable lifecycle controls. The framework is implemented through the Reinsurance AI Reliability and Assurance Benchmark (RAIRAB), which evaluates whether governance-embedded LLMs meet prudential standards for grounding, transparency, and accountability. Across six task families, retrieval-grounded configurations achieved higher grounding accuracy (0.90), reduced hallucination and interpretive drift by roughly 40%, and nearly doubled transparency. These mechanisms lower informational frictions in risk transfer and capital allocation, showing that existing prudential doctrines already accommodate reliable AI when governance is explicit, data are traceable, and assurance is verifiable.

</details>


### [44] [Gateways to Tractability for Satisfiability in Pearl's Causal Hierarchy](https://arxiv.org/abs/2511.08091)
*Robert Ganian,Marlene Gründel,Simon Wietheger*

Main category: cs.AI

TL;DR: 本文通过参数化复杂度方法，首次为Pearl因果层级（PCH）公式的可满足性问题找到了可处理的入口，并在关键概率和反事实片段中提出了固定参数和XP算法，同时给出了匹配的难度结果。


<details>
  <summary>Details</summary>
Motivation: Pearl因果层级（PCH）是推理概率、干预和反事实陈述的核心框架，但在几乎所有经典设置中，PCH公式的可满足性问题都具有计算上的难解性。

Method: 采用参数化复杂度视角，利用原始树宽和变量数等参数，开发了固定参数（FPT）和XP算法。技术上，本文脱离了通常用于基于树宽算法的动态规划范式，转而利用结构化的因果模型特征，提供了一套新的因果推理算法工具包。

Result: 首次为关键概率和反事实片段中的PCH公式可满足性问题提供了固定参数和XP算法，并给出了相应的难度结果，明确了可处理性的边界。这为因果推理提供了一个新的算法工具包。

Conclusion: 通过参数化复杂度分析，本文首次识别了PCH公式可满足性问题的可处理性入口，并在特定片段中提出了高效算法，突破了传统设置下的计算限制，并提供了理解可处理性边界的新视角。

Abstract: Pearl's Causal Hierarchy (PCH) is a central framework for reasoning about probabilistic, interventional, and counterfactual statements, yet the satisfiability problem for PCH formulas is computationally intractable in almost all classical settings. We revisit this challenge through the lens of parameterized complexity and identify the first gateways to tractability. Our results include fixed-parameter and XP-algorithms for satisfiability in key probabilistic and counterfactual fragments, using parameters such as primal treewidth and the number of variables, together with matching hardness results that map the limits of tractability. Technically, we depart from the dynamic programming paradigm typically employed for treewidth-based algorithms and instead exploit structural characterizations of well-formed causal models, providing a new algorithmic toolkit for causal reasoning.

</details>


### [45] [Improving Industrial Injection Molding Processes with Explainable AI for Quality Classification](https://arxiv.org/abs/2511.08108)
*Georg Rottenwalter,Marcel Tilly,Victor Owolabi*

Main category: cs.AI

TL;DR: 本研究利用可解释人工智能（XAI）技术对注塑件质量分类中的特征进行降维，结果表明在保持高分类性能的同时，提高了模型泛化能力和推理速度，增强了AI质量控制在工业中的可行性。


<details>
  <summary>Details</summary>
Motivation: 机器学习在工业质量控制中应用广泛，但其模型复杂性导致可解释性差，且许多工业机器传感器技术不完善，数据获取困难。XAI有望解决模型决策透明度和关键特征识别问题。

Method: 本研究使用SHAP、Grad-CAM和LIME等XAI技术，分析了在真实生产数据上训练的长短期记忆（LSTM）模型中特征的重要性。通过将原始19个输入特征分别减少到9个和6个，评估了模型精度、推理速度和可解释性之间的权衡。

Result: 结果表明，特征降维在保持高分类性能的同时，可以提高模型的泛化能力，并略微提升推理速度。这使得AI驱动的质量控制更具可行性。

Conclusion: 该方法增强了AI驱动质量控制的可行性，尤其适用于传感器能力有限的工业环境，为制造业中更高效、可解释的机器学习应用铺平了道路。

Abstract: Machine learning is an essential tool for optimizing industrial quality control processes. However, the complexity of machine learning models often limits their practical applicability due to a lack of interpretability. Additionally, many industrial machines lack comprehensive sensor technology, making data acquisition incomplete and challenging. Explainable Artificial Intelligence offers a solution by providing insights into model decision-making and identifying the most relevant features for classification. In this paper, we investigate the impact of feature reduction using XAI techniques on the quality classification of injection-molded parts. We apply SHAP, Grad-CAM, and LIME to analyze feature importance in a Long Short-Term Memory model trained on real production data. By reducing the original 19 input features to 9 and 6, we evaluate the trade-off between model accuracy, inference speed, and interpretability. Our results show that reducing features can improve generalization while maintaining high classification performance, with an small increase in inference speed. This approach enhances the feasibility of AI-driven quality control, particularly for industrial settings with limited sensor capabilities, and paves the way for more efficient and interpretable machine learning applications in manufacturing.

</details>


### [46] [SciAgent: A Unified Multi-Agent System for Generalistic Scientific Reasoning](https://arxiv.org/abs/2511.08151)
*Xuchen Li,Ruitao Wu,Xuanbo Liu,Xukai Wang,Jinbo Hu,Zhixin Bai,Bohan Zeng,Hao Liang,Leheng Chen,Mingrui Chen,Haitian Zhong,Xuanlin Yang,Xu-Yao Zhang,Liu Liu,Jia Li,Kaiqi Huang,Jiahao Xu,Haitao Mi,Wentao Zhang,Bin Dong*

Main category: cs.AI

TL;DR: SciAgent是一个统一的多智能体系统，旨在实现通用科学推理，能在数学、物理和化学奥林匹克竞赛中达到或超越人类金牌水平，展现了跨学科的适应性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的AI系统在特定科学任务上已达到专家级表现，但它们通常是狭窄和手工定制的，缺乏跨学科和不同难度级别调整推理策略的通用能力。

Method: SciAgent将问题解决组织为分层过程：协调器智能体负责解释问题领域和复杂性，动态调度由符号演绎、概念建模、数值计算和验证等子智能体组成的专业工作系统。这些智能体协作构建和优化针对特定任务的推理管道。

Result: SciAgent在数学和物理奥林匹克竞赛（IMO, IMC, IPhO, CPhO）中始终达到或超越人类金牌得主的表现，展现了领域通用性和推理适应性。此外，它在国际化学奥林匹克竞赛（IChO）和“人类的最后考试”（HLE）基准测试的选定问题上表现良好，进一步证实了其跨多样科学领域的泛化能力。

Conclusion: 这项工作确立了SciAgent作为迈向通用科学智能的具体一步，表明AI系统有能力进行专家级的连贯跨学科推理。

Abstract: Recent advances in large language models have enabled AI systems to achieve expert-level performance on domain-specific scientific tasks, yet these systems remain narrow and handcrafted. We introduce SciAgent, a unified multi-agent system designed for generalistic scientific reasoning-the ability to adapt reasoning strategies across disciplines and difficulty levels. SciAgent organizes problem solving as a hierarchical process: a Coordinator Agent interprets each problem's domain and complexity, dynamically orchestrating specialized Worker Systems, each composed of interacting reasoning Sub-agents for symbolic deduction, conceptual modeling, numerical computation, and verification. These agents collaboratively assemble and refine reasoning pipelines tailored to each task. Across mathematics and physics Olympiads (IMO, IMC, IPhO, CPhO), SciAgent consistently attains or surpasses human gold-medalist performance, demonstrating both domain generality and reasoning adaptability. Additionally, SciAgent has been tested on the International Chemistry Olympiad (IChO) and selected problems from the Humanity's Last Exam (HLE) benchmark, further confirming the system's ability to generalize across diverse scientific domains. This work establishes SciAgent as a concrete step toward generalistic scientific intelligence-AI systems capable of coherent, cross-disciplinary reasoning at expert levels.

</details>


### [47] [National Institute on Aging PREPARE Challenge: Early Detection of Cognitive Impairment Using Speech - The SpeechCARE Solution](https://arxiv.org/abs/2511.08132)
*Maryam Zolnoori,Hossein Azadmaleki,Yasaman Haghbin,Ali Zolnour,Mohammad Javad Momeni Nezhad,Sina Rashidi,Mehdi Naserian,Elyas Esmaeili,Sepehr Karimi Arpanahi*

Main category: cs.AI

TL;DR: SpeechCARE是一种多模态语音处理管道，利用预训练的声学和语言Transformer模型，结合动态融合架构，实现了对阿尔茨海默病及相关痴呆（ADRD）的早期检测，并具有高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病及相关痴呆（ADRD）影响大量老年人，但超过一半的认知障碍患者未被诊断。尽管基于语音的评估显示出早期检测的潜力，但传统方法（手工特征或通用音频分类器）的性能和泛化能力有限。

Method: 本文提出了SpeechCARE，一个多模态语音处理管道。它利用预训练的多语言声学和语言Transformer模型来捕捉与认知障碍相关的细微语音线索。受专家混合（MoE）范式启发，SpeechCARE采用动态融合架构，对基于Transformer的声学、语言和人口统计学输入进行加权，并支持整合额外模态。其强大的预处理包括自动转录、基于LLM的异常检测和任务识别。一个基于SHAP的可解释性模块和LLM推理突出了各模态对决策的贡献。还采用了过采样和加权损失等技术来减轻偏差。

Result: SpeechCARE在认知健康、轻度认知障碍（MCI）和阿尔茨海默病（AD）个体分类中实现了AUC = 0.88和F1 = 0.72。在MCI检测方面，AUC = 0.90和F1 = 0.62。偏差分析显示，除了80岁以上成人外，偏差极小。

Conclusion: SpeechCARE是一个有效、稳健且可解释的多模态语音处理管道，能够实现对ADRD和MCI的早期检测。未来的工作包括在真实护理环境中部署，并结合EHR数据为代表性不足的人群提供可解释性。

Abstract: Alzheimer's disease and related dementias (ADRD) affect one in five adults over 60, yet more than half of individuals with cognitive decline remain undiagnosed. Speech-based assessments show promise for early detection, as phonetic motor planning deficits alter acoustic features (e.g., pitch, tone), while memory and language impairments lead to syntactic and semantic errors. However, conventional speech-processing pipelines with hand-crafted features or general-purpose audio classifiers often exhibit limited performance and generalizability. To address these limitations, we introduce SpeechCARE, a multimodal speech processing pipeline that leverages pretrained, multilingual acoustic and linguistic transformer models to capture subtle speech-related cues associated with cognitive impairment. Inspired by the Mixture of Experts (MoE) paradigm, SpeechCARE employs a dynamic fusion architecture that weights transformer-based acoustic, linguistic, and demographic inputs, allowing integration of additional modalities (e.g., social factors, imaging) and enhancing robustness across diverse tasks. Its robust preprocessing includes automatic transcription, large language model (LLM)-based anomaly detection, and task identification. A SHAP-based explainability module and LLM reasoning highlight each modality's contribution to decision-making. SpeechCARE achieved AUC = 0.88 and F1 = 0.72 for classifying cognitively healthy, MCI, and AD individuals, with AUC = 0.90 and F1 = 0.62 for MCI detection. Bias analysis showed minimal disparities, except for adults over 80. Mitigation techniques included oversampling and weighted loss. Future work includes deployment in real-world care settings (e.g., VNS Health, Columbia ADRC) and EHR-integrated explainability for underrepresented populations in New York City.

</details>


### [48] [Advancements in synthetic data extraction for industrial injection molding](https://arxiv.org/abs/2511.08117)
*Georg Rottenwalter,Marcel Tilly,Christian Bielenberg,Katharina Obermeier*

Main category: cs.AI

TL;DR: 本文研究了将模拟生成的合成数据整合到注塑过程的LSTM模型训练中的可行性，结果表明合成数据能提高模型处理不同场景的能力，为数据收集困难的工业应用提供了一种高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器学习在优化工业流程方面潜力巨大，但数据获取耗时且成本高昂。合成数据被视为一种有前景的解决方案，用于补充不足的数据集并提高机器学习模型的鲁棒性。

Method: 研究方法是利用现有长短期记忆（LSTM）架构，通过模拟生产周期生成合成数据，并将其纳入训练数据集。通过迭代实验不同比例的合成数据，旨在找到最大化合成数据效益同时保持真实数据真实性和相关性的最佳平衡。

Result: 研究结果表明，加入合成数据提高了模型处理不同场景的能力，具有潜在的实际工业应用价值，可以减少人工劳动、机器使用和材料浪费。

Conclusion: 这种方法为数据收集和维护不切实际或成本高昂的情况提供了一种有价值的替代方案，有助于未来实现更高效的制造流程。

Abstract: Machine learning has significant potential for optimizing various industrial processes. However, data acquisition remains a major challenge as it is both time-consuming and costly. Synthetic data offers a promising solution to augment insufficient data sets and improve the robustness of machine learning models. In this paper, we investigate the feasibility of incorporating synthetic data into the training process of the injection molding process using an existing Long Short-Term Memory architecture. Our approach is to generate synthetic data by simulating production cycles and incorporating them into the training data set. Through iterative experimentation with different proportions of synthetic data, we attempt to find an optimal balance that maximizes the benefits of synthetic data while preserving the authenticity and relevance of real data. Our results suggest that the inclusion of synthetic data improves the model's ability to handle different scenarios, with potential practical industrial applications to reduce manual labor, machine use, and material waste. This approach provides a valuable alternative for situations where extensive data collection and maintenance has been impractical or costly and thus could contribute to more efficient manufacturing processes in the future.

</details>


### [49] [oboro: Text-to-Image Synthesis on Limited Data using Flow-based Diffusion Transformer with MMH Attention](https://arxiv.org/abs/2511.08168)
*Ryusuke Mizutani,Kazuaki Matano,Tsugumi Kadowaki,Haruki Tenya,Layris,nuigurumi,Koki Hashimoto,Yu Tanaka*

Main category: cs.AI

TL;DR: 该项目开发并发布了“oboro:”，一个完全在日本开发、开源且面向商业的图像生成AI模型，旨在解决日本动漫产业的劳动力短缺问题，并使用仅限版权清晰的图像进行训练。


<details>
  <summary>Details</summary>
Motivation: 日本动漫制作行业面临劳动力短缺的挑战，该项目旨在通过开发图像生成模型来解决这一问题。同时，这也是日本经济产业省（METI）和新能源产业技术综合开发机构（NEDO）“Post-5G信息通信系统基础设施强化R&D项目”的一部分，旨在开发具有竞争力的生成式AI基础模型（GENIAC）。

Method: 该项目从零开始开发了名为“oboro:”的全新图像生成模型。其关键特点是架构设计使其即使在有限的数据集下也能生成高质量图像。模型训练仅使用版权清晰的图像。基础模型权重和推理代码已公开发布。

Result: 成功开发了图像生成模型“oboro:”，并发布了其技术规范、基础模型权重和推理代码。这是日本首次发布完全在国内开发、开源且面向商业的图像生成AI。

Conclusion: 该项目成功开发并开源了“oboro:”，为日本的AI研究人员和工程师社区做出了贡献，并促进了国内AI开发生态系统。通过开发透明的图像生成AI，旨在解决日本动漫产业的劳动力短缺问题。

Abstract: This project was conducted as a 2nd-term adopted project of the "Post-5G Information and Communication System Infrastructure Enhancement R&D Project Development of Competitive Generative AI Foundation Models (GENIAC)," a business of the Ministry of Economy, Trade and Industry (METI) and the New Energy and Industrial Technology Development Organization (NEDO). To address challenges such as labor shortages in Japan's anime production industry, this project aims to develop an image generation model from scratch. This report details the technical specifications of the developed image generation model, "oboro:." We have developed "oboro:," a new image generation model built from scratch, using only copyright-cleared images for training. A key characteristic is its architecture, designed to generate high-quality images even from limited datasets. The foundation model weights and inference code are publicly available alongside this report. This project marks the first release of an open-source, commercially-oriented image generation AI fully developed in Japan. AiHUB originated from the OSS community; by maintaining transparency in our development process, we aim to contribute to Japan's AI researcher and engineer community and promote the domestic AI development ecosystem.

</details>


### [50] [An Efficient Training Pipeline for Reasoning Graphical User Interface Agents](https://arxiv.org/abs/2511.08172)
*Georgios Pantazopoulos,Eda B. Özyiğit*

Main category: cs.AI

TL;DR: 本文提出了一种高效的视觉定位训练流程，结合模型驱动的数据过滤和参数高效微调，在仅使用少量高质量数据的情况下，使紧凑型视觉语言模型在多个基准测试中达到或超越大型基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉定位方法严重依赖于大量且嘈杂的合成数据集，而视觉定位对于能够进行推理的图形用户界面（GUI）智能体至关重要。

Method: 研究引入了一个高效的训练流程，结合了模型驱动的数据过滤和参数高效微调。具体包括：1. 从480万合成示例中，通过识别挑战性案例、去除错位实例并选择多样化多模态实例，筛选出1.2万个干净且多样的数据实例。2. 使用这些数据，以三种方式训练一个30亿参数的视觉-语言模型：监督微调、思维链增强微调和通过群组相对策略优化（Group Relative Policy Optimization）进行的强化学习。

Result: 使用过滤后的数据和轻量级训练策略训练出的模型，在ScreenSpot、Multimodal-Mind2Web和AndroidControl等基准测试中，表现与更大的基线模型持平或超越。

Conclusion: 研究结果表明，有原则的数据筛选和鲁棒的适应性策略可以与大规模训练相媲美，从而实现紧凑而强大的多模态推理智能体。

Abstract: Visual grounding is the task of localising image regions from natural language queries and is critical for reasoning capable Graphical User Interface agents. Many existing methods rely on massive, noisy synthetic datasets.This work introduces an efficient training pipeline that combines model-based data filtering with parameter-efficient fine-tuning. From 4.8M synthetic examples, 12K clean and diverse instances are curated by first identifying challenging cases, removing misaligned and then selecting a diverse set of multimodal instances. On this data, a 3B-parameter Vision-Language Model is trained under three regimes: supervised fine-tuning, chain-of-thought- augmented fine-tuning, and reinforcement learning via Group Relative Policy Optimization. Models trained with the filtered data and lightweight training strategies match or surpass larger baselines on benchmarks such as ScreenSpot, Multimodal-Mind2Web, and AndroidControl. These results demonstrate that principled data curation and robust adaptation can rival large-scale training, enabling compact yet capable multimodal reasoning agents.

</details>


### [51] [Towards Provably Unlearnable Examples via Bayes Error Optimisation](https://arxiv.org/abs/2511.08191)
*Ruihan Zhang,Jun Sun,Ee-Peng Lim,Peixin Zhang*

Main category: cs.AI

TL;DR: 本文提出一种通过系统地最大化贝叶斯错误来构建不可学习示例的新方法，以解决机器学习模型训练中的数据隐私问题。该方法在理论上可证明且在实践中有效，即使与干净数据混合也能保持不可学习性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型大量依赖在线数据训练，引发用户数据隐私和未授权使用问题。现有不可学习示例方法缺乏形式化保证，且在与干净数据混合时会失效。

Method: 提出一种通过系统地最大化贝叶斯错误（一种不可约分类错误度量）来构建不可学习示例的新方法。开发了一种基于优化的方法，并使用投影梯度上升提供高效解决方案。

Result: 该方法可证明地增加了贝叶斯错误，并且当不可学习示例与干净样本混合时仍保持有效性。在多个数据集和模型架构上的实验结果与理论分析一致，表明该方法能有效限制数据可学习性。

Conclusion: 所提出的方法通过最大化贝叶斯错误，能够有效地限制数据可学习性，为解决机器学习训练中的数据隐私问题提供了一种有理论保证和实践效果的解决方案。

Abstract: The recent success of machine learning models, especially large-scale classifiers and language models, relies heavily on training with massive data. These data are often collected from online sources. This raises serious concerns about the protection of user data, as individuals may not have given consent for their data to be used in training. To address this concern, recent studies introduce the concept of unlearnable examples, i.e., data instances that appear natural but are intentionally altered to prevent models from effectively learning from them. While existing methods demonstrate empirical effectiveness, they typically rely on heuristic trials and lack formal guarantees. Besides, when unlearnable examples are mixed with clean data, as is often the case in practice, their unlearnability disappears. In this work, we propose a novel approach to constructing unlearnable examples by systematically maximising the Bayes error, a measurement of irreducible classification error. We develop an optimisation-based approach and provide an efficient solution using projected gradient ascent. Our method provably increases the Bayes error and remains effective when the unlearning examples are mixed with clean samples. Experimental results across multiple datasets and model architectures are consistent with our theoretical analysis and show that our approach can restrict data learnability, effectively in practice.

</details>


### [52] [EHRStruct: A Comprehensive Benchmark Framework for Evaluating Large Language Models on Structured Electronic Health Record Tasks](https://arxiv.org/abs/2511.08206)
*Xiao Yang,Xuejiao Zhao,Zhiqi Shen*

Main category: cs.AI

TL;DR: 本文提出了EHRStruct基准测试来标准化评估大型语言模型（LLMs）在结构化电子健康记录（EHR）数据上的性能，并引入了EHRMaster，一种代码增强方法，以实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在处理结构化EHR数据方面显示出潜力，但目前缺乏标准化的评估框架和明确定义的任务，使得系统地评估和比较其性能变得困难。

Method: 本文引入了EHRStruct，一个包含11个代表性任务和2,200个评估样本的基准测试，这些样本来源于两个广泛使用的EHR数据集。研究评估了20个通用和医学领域的LLMs，并分析了输入格式、少样本泛化和微调策略等关键因素。此外，研究还将结果与11种最先进的基于LLM的结构化数据推理增强方法进行了比较，并提出了代码增强方法EHRMaster。

Result: 评估结果表明，许多结构化EHR任务对LLMs的理解和推理能力提出了高要求。本文提出的EHRMaster方法在这些任务上实现了最先进的性能。

Conclusion: EHRStruct提供了一个急需的、标准化的评估框架，用于评估LLMs在结构化EHR数据上的表现。EHRMaster作为一种代码增强方法，在解决结构化EHR任务方面表现出色，并提供了实用的解决方案。

Abstract: Structured Electronic Health Record (EHR) data stores patient information in relational tables and plays a central role in clinical decision-making. Recent advances have explored the use of large language models (LLMs) to process such data, showing promise across various clinical tasks.However, the absence of standardized evaluation frameworks and clearly defined tasks makes it difficult to systematically assess and compare LLM performance on structured EHR data.To address these evaluation challenges, we introduce EHRStruct, a benchmark specifically designed to evaluate LLMs on structured EHR tasks.EHRStruct defines 11 representative tasks spanning diverse clinical needs and includes 2,200 task-specific evaluation samples derived from two widely used EHR datasets.We use EHRStruct to evaluate 20 advanced and representative LLMs, covering both general and medical models.We further analyze key factors influencing model performance, including input formats, few-shot generalisation, and finetuning strategies, and compare results with 11 state-of-the-art LLM-based enhancement methods for structured data reasoning. Our results indicate that many structured EHR tasks place high demands on the understanding and reasoning capabilities of LLMs.In response, we propose EHRMaster, a code-augmented method that achieves state-of-the-art performance and offers practical

</details>


### [53] [MADD: Multi-Agent Drug Discovery Orchestra](https://arxiv.org/abs/2511.08217)
*Gleb V. Solovev,Alina B. Zhidkovskaya,Anastasia Orlova,Nina Gubina,Anastasia Vepreva,Rodion Golovinskii,Ilya Tonkii,Ivan Dubrovsky,Ivan Gurev,Dmitry Gilemkhanov,Denis Chistiakov,Timur A. Aliev,Ivan Poddiakov,Galina Zubkova,Ekaterina V. Skorb,Vladimir Vinogradov,Alexander Boukhanovsky,Nikolay Nikitin,Andrei Dmitrenko,Anna Kalyuzhnaya,Andrey Savchenko*

Main category: cs.AI

TL;DR: MADD是一个多智能体系统，它能根据自然语言查询自动构建和执行定制的药物命中识别流程，在多个案例中表现优于现有LLM方案，并推动了AI优先的药物设计。


<details>
  <summary>Details</summary>
Motivation: 传统的药物命中识别耗费大量实验资源。尽管LLM等AI工具提高了效率，但其复杂性限制了湿实验室研究人员的可用性。多智能体系统有望结合LLM的可解释性和专用模型的精确性来解决这一挑战。

Method: 本文提出了MADD，一个多智能体系统，它通过协调四个智能体来处理从自然语言查询进行从头化合物生成和筛选的关键子任务，从而构建并执行定制的命中识别管线。

Result: MADD在七个药物发现案例中展示了优于现有基于LLM解决方案的性能。它将AI优先的药物设计应用于五个生物靶点，并发布了识别出的命中分子。此外，还引入了一个包含超过300万化合物的查询-分子对和对接分数的新基准。

Conclusion: MADD通过多智能体系统提高了药物命中识别的效率和可访问性，超越了现有基于LLM的解决方案，并为AI优先的药物设计和未来智能体驱动的药物设计做出了贡献。

Abstract: Hit identification is a central challenge in early drug discovery, traditionally requiring substantial experimental resources. Recent advances in artificial intelligence, particularly large language models (LLMs), have enabled virtual screening methods that reduce costs and improve efficiency. However, the growing complexity of these tools has limited their accessibility to wet-lab researchers. Multi-agent systems offer a promising solution by combining the interpretability of LLMs with the precision of specialized models and tools. In this work, we present MADD, a multi-agent system that builds and executes customized hit identification pipelines from natural language queries. MADD employs four coordinated agents to handle key subtasks in de novo compound generation and screening. We evaluate MADD across seven drug discovery cases and demonstrate its superior performance compared to existing LLM-based solutions. Using MADD, we pioneer the application of AI-first drug design to five biological targets and release the identified hit molecules. Finally, we introduce a new benchmark of query-molecule pairs and docking scores for over three million compounds to contribute to the agentic future of drug design.

</details>


### [54] [Beyond Distributions: Geometric Action Control for Continuous Reinforcement Learning](https://arxiv.org/abs/2511.08234)
*Zhihao Lin*

Main category: cs.AI

TL;DR: GAC是一种新型连续控制动作生成范式，通过分解方向向量和可学习的集中度参数，简化了球面分布的计算，解决了高斯策略在有界动作空间中的几何不匹配问题，并在MuJoCo基准测试中超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习中，高斯策略在连续控制领域占据主导地位，但其无界支持需要临时的挤压函数来扭曲有界动作空间的几何结构。虽然von Mises-Fisher (vMF) 分布在理论上是球体上的更好选择，但其对贝塞尔函数和拒绝采样的依赖阻碍了实际应用。

Method: 本文提出了几何动作控制（GAC）方法，将动作生成分解为方向向量和可学习的集中度参数。这种设计将参数数量从2d减少到d+1，并将vMF拒绝采样的O(dk)复杂度降低到简单的O(d)操作。GAC通过球面归一化和自适应集中度控制实现高效计算，并在确定性动作和均匀球面噪声之间进行插值。

Result: GAC在六个MuJoCo基准测试中持续匹配或超越了现有技术，在Ant-v4任务上比SAC提升了37.6%，并在六个任务中的四个上取得了最佳结果。消融研究表明，球面归一化和自适应集中度控制对于GAC的成功至关重要。

Conclusion: 研究结果表明，稳健高效的连续控制不需要复杂的分布，而是需要对动作空间几何结构的基本尊重。

Abstract: Gaussian policies have dominated continuous control in deep reinforcement learning (RL), yet they suffer from a fundamental mismatch: their unbounded support requires ad-hoc squashing functions that distort the geometry of bounded action spaces. While von Mises-Fisher (vMF) distributions offer a theoretically grounded alternative on the sphere, their reliance on Bessel functions and rejection sampling hinders practical adoption. We propose \textbf{Geometric Action Control (GAC)}, a novel action generation paradigm that preserves the geometric benefits of spherical distributions while \textit{simplifying computation}. GAC decomposes action generation into a direction vector and a learnable concentration parameter, enabling efficient interpolation between deterministic actions and uniform spherical noise. This design reduces parameter count from \(2d\) to \(d+1\), and avoids the \(O(dk)\) complexity of vMF rejection sampling, achieving simple \(O(d)\) operations. Empirically, GAC consistently matches or exceeds state-of-the-art methods across six MuJoCo benchmarks, achieving 37.6\% improvement over SAC on Ant-v4 and the best results on 4 out of 6 tasks. Our ablation studies reveal that both \textbf{spherical normalization} and \textbf{adaptive concentration control} are essential to GAC's success. These findings suggest that robust and efficient continuous control does not require complex distributions, but a principled respect for the geometry of action spaces. Code and pretrained models are available in supplementary materials.

</details>


### [55] [Towards Outcome-Oriented, Task-Agnostic Evaluation of AI Agents](https://arxiv.org/abs/2511.08242)
*Waseem AlShikh,Muayad Sayed Ali,Brian Kennedy,Dmytro Mozolevskyi*

Main category: cs.AI

TL;DR: 本文提出了一套包含11个以结果为导向、与任务无关的AI智能体性能评估指标，以解决现有指标无法衡量决策质量、自主性和业务价值的问题。通过大规模模拟实验，验证了该框架的有效性，并发现混合智能体在大多数指标上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 当前对AI智能体的评估主要依赖于延迟、首个token生成时间或token吞吐量等基础设施指标，这些指标不足以衡量智能体的决策质量、操作自主性及其最终的商业价值。

Method: 提出了一套包含11个以结果为导向、与任务无关的AI智能体性能评估指标，例如目标完成率（GCR）、自主性指数（AIx）、多步骤任务弹性（MTR）和业务影响效率（BIE）。通过大规模模拟实验，在医疗、金融、市场营销、法律和客户服务五个不同领域，对四种不同的智能体架构（ReAct、思维链、工具增强型、混合型）进行了评估。

Result: 该评估框架被证明是有效的。实验揭示了不同智能体设计之间存在显著的性能权衡。其中，混合智能体在大多数提出的指标上表现最稳定且性能最高，平均目标完成率达到88.8%，并实现了最高的投资回报率（ROI）。

Conclusion: 本研究为AI智能体的整体评估提供了一个稳健、标准化的方法，为更有效的开发、部署和治理奠定了基础。

Abstract: As AI agents proliferate across industries and applications, evaluating their performance based solely on infrastructural metrics such as latency, time-to-first-token, or token throughput is proving insufficient. These metrics fail to capture the quality of an agent's decisions, its operational autonomy, or its ultimate business value. This white paper proposes a novel, comprehensive framework of eleven outcome-based, task-agnostic performance metrics for AI agents that transcend domain boundaries. These metrics are designed to enable organizations to evaluate agents based on the quality of their decisions, their degree of autonomy, their adaptability to new challenges, and the tangible business value they deliver, regardless of the underlying model architecture or specific use case. We introduce metrics such as Goal Completion Rate (GCR), Autonomy Index (AIx), Multi-Step Task Resilience (MTR), and Business Impact Efficiency (BIE). Through a large-scale simulated experiment involving four distinct agent architectures (ReAct, Chain-of-Thought, Tool-Augmented, Hybrid) across five diverse domains (Healthcare, Finance, Marketing, Legal, and Customer Service), we demonstrate the framework's efficacy. Our results reveal significant performance trade-offs between different agent designs, highlighting the Hybrid Agent as the most consistently high-performing model across the majority of our proposed metrics, achieving an average Goal Completion Rate of 88.8\% and the highest Return on Investment (ROI). This work provides a robust, standardized methodology for the holistic evaluation of AI agents, paving the way for more effective development, deployment, and governance.

</details>


### [56] [Smarter Together: Creating Agentic Communities of Practice through Shared Experiential Learning](https://arxiv.org/abs/2511.08301)
*Valentin Tablan,Scott Taylor,Gabriel Hurtado,Kristoffer Bernhem,Anders Uhrenholt,Gabriele Farei,Karo Moilanen*

Main category: cs.AI

TL;DR: 本文介绍了Spark，一种新型共享智能体记忆架构，旨在为AI编程智能体提供集体智能和经验，以应对人类开发者知识共享环境的转变。Spark能显著提升AI智能体生成代码的质量，并使小型模型达到大型模型的性能水平。


<details>
  <summary>Details</summary>
Motivation: 软件开发正从以人为中心转向以智能体为中心，导致传统人类开发者知识共享环境（如点对点存储库和社区）的参与度急剧下降。与此同时，尚未出现相应的智能体功能性知识共享环境，使得AI智能体（已生成大量新代码）无法访问宝贵的共享学习知识库。

Method: 本文引入了Spark，一种新颖的共享智能体记忆架构，旨在模拟人类开发者社区的集体智能和专业知识。Spark使AI编程智能体能够贡献和利用一个持久且不断演进的经验记忆库。在相同问题空间中操作的智能体利用Spark共享记忆作为新知识库，实现集体持续学习。作者将Spark评估为AI编程智能体执行软件开发任务的教练。

Result: Spark提出的建议能提高不同规模和能力层级的通用代码生成模型所生成代码的质量。在Spark的助力下，一个300亿参数的小型开源模型能够达到一个更大的最先进模型所提供的代码质量。此外，通过针对软件开发最佳实践的广泛标准评估，Spark生成的建议在定性帮助性方面（前两档，共五档）达到了高达98.2%的帮助水平。

Conclusion: Spark成功地为AI编程智能体提供了一个有效的共享记忆架构，模拟了人类开发者社区的集体智能。它不仅提高了AI生成代码的质量，还提升了小型模型的性能，并提供了高质量的开发建议，有效解决了智能体时代知识共享缺失的问题。

Abstract: The transition from human-centric to agent-centric software development practices is disrupting existing knowledge sharing environments for software developers. Traditional peer-to-peer repositories and developer communities for shared technical knowledge and best practice have witnessed dramatic drops in participation in a short period of time. At the same time, agentic functional equivalents are yet to emerge leaving AI agents, which already generate a significant proportion of all new software code produced, without access to repositories of valuable shared learning.
  In this paper, we introduce Spark, a novel shared agentic memory architecture which is designed to emulate the collective intelligence and know-how of human developer communities. Spark enables AI coding agents to both contribute to and draw from a persistent and continuously evolving experiential memory. Agents operating in the same general problem space use the Spark shared memory as a repository of new knowledge to achieve collective continual learning. We evaluate Spark as a coach for AI coding agents performing software development tasks. We demonstrate that recommendations made by Spark improve the quality of code generated by generic code generation models at varying sizes and capability tiers. Boosted by Spark, a small open-weights model with 30 billion parameters was able to match the code quality afforded by a much larger state-of-the-art model. Separately, we measure the intrinsic quality of recommendations generated by Spark against a wide range of criteria inspired by software development best practice, and achieve helpfulness levels of up to 98.2% in the top two (out of five) qualitative helpfulness bands.

</details>


### [57] [Multi-Agent GraphRAG: A Text-to-Cypher Framework for Labeled Property Graphs](https://arxiv.org/abs/2511.08274)
*Anton Gusarov,Anastasia Volkova,Valentin Khrulkov,Andrey Kuznetsov,Evgenii Maslov,Ivan Oseledets*

Main category: cs.AI

TL;DR: 本文提出了Multi-Agent GraphRAG系统，一个基于LLM的多智能体系统，用于将自然语言转换为Cypher查询，以利用Labeled Property Graph (LPG)数据库进行知识图谱检索增强生成（GraphRAG），并验证了其在通用领域数据集和工业数字孪生应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有GraphRAG方法主要关注RDF知识图谱和SPARQL查询，而Cypher和LPG数据库作为可扩展且有效的推理引擎在GraphRAG管道中的潜力尚未得到充分探索。

Method: 提出了Multi-Agent GraphRAG，一个模块化的LLM智能体系统，用于文本到Cypher查询的生成。该系统以Memgraph作为图数据库后端，通过LLM驱动的工作流自动生成和执行Cypher查询。它还包含迭代的内容感知校正、规范化以及聚合反馈循环，以确保生成查询的语义和语法准确性。

Result: 系统在CypherBench图数据集（涵盖多个通用领域和多样查询类型）上进行了评估，并展示了其性能。此外，还在从IFC数据（代表建筑数字孪生）导出的属性图上验证了所提出工作流的性能，突出了该方法在将AI与大规模实际应用（如工业数字自动化用例）相结合的潜力。

Conclusion: 所提出的Multi-Agent GraphRAG系统成功填补了LPG/Cypher在GraphRAG领域研究的空白，提供了一个可扩展且有效的自然语言接口，能够将AI技术应用于大规模工业数字自动化场景，如数字孪生。

Abstract: While Retrieval-Augmented Generation (RAG) methods commonly draw information from unstructured documents, the emerging paradigm of GraphRAG aims to leverage structured data such as knowledge graphs. Most existing GraphRAG efforts focus on Resource Description Framework (RDF) knowledge graphs, relying on triple representations and SPARQL queries. However, the potential of Cypher and Labeled Property Graph (LPG) databases to serve as scalable and effective reasoning engines within GraphRAG pipelines remains underexplored in current research literature. To fill this gap, we propose Multi-Agent GraphRAG, a modular LLM agentic system for text-to-Cypher query generation serving as a natural language interface to LPG-based graph data. Our proof-of-concept system features an LLM-based workflow for automated Cypher queries generation and execution, using Memgraph as the graph database backend. Iterative content-aware correction and normalization, reinforced by an aggregated feedback loop, ensures both semantic and syntactic refinement of generated queries. We evaluate our system on the CypherBench graph dataset covering several general domains with diverse types of queries. In addition, we demonstrate performance of the proposed workflow on a property graph derived from the IFC (Industry Foundation Classes) data, representing a digital twin of a building. This highlights how such an approach can bridge AI with real-world applications at scale, enabling industrial digital automation use cases.

</details>


### [58] [JobSphere: An AI-Powered Multilingual Career Copilot for Government Employment Platforms](https://arxiv.org/abs/2511.08343)
*Srihari R,Adarsha B,Mohammed Usman Hussain,Shweta Singh*

Main category: cs.AI

TL;DR: 本文介绍JobSphere，一个基于AI的职业助手，旨在改进旁遮普邦政府就业平台PGRKAM。它采用RAG架构，支持多语言，并利用4位量化技术在消费级GPU上运行，显著降低成本，同时提供语音交互、模拟测试、简历解析和高精度的职位推荐，有效提升了用户体验和可访问性。


<details>
  <summary>Details</summary>
Motivation: 政府就业网站普遍存在用户参与度低、可访问性差的问题，具体表现为导航复杂、语言选项不足以及缺乏个性化支持。这些挑战促使研究者开发JobSphere，以解决旁遮普邦就业平台PGRKAM面临的问题。

Method: JobSphere是一个AI驱动的职业助手，采用检索增强生成（RAG）架构。它支持英语、印地语和旁遮普语多语言。为实现低成本部署，系统利用4位量化技术，使其能够在消费级GPU（如NVIDIA RTX 3050 4GB）上运行。主要创新包括语音交互、自动化模拟测试、带技能识别的简历解析，以及基于嵌入的职位推荐系统。

Result: JobSphere的部署成本比基于云的系统低89%。职位推荐的precision@10得分为68%。系统评估显示，其事实准确率为94%，中位响应时间为1.8秒，系统可用性量表（SUS）得分为78.5/100，相较于基线PGRKAM平台上下文提升了50%。

Conclusion: JobSphere有效弥补了旁遮普语/印地语用户在农村地区面临的显著可访问性差距，同时确保用户能够访问政府机构提供的可信就业内容。

Abstract: Users of government employment websites commonly face engagement and accessibility challenges linked to navigational complexity, a dearth of language options, and a lack of personalized support. This paper introduces JobSphere, an AI-powered career assistant that is redefining the employment platform in Punjab called PGRKAM. JobSphere employs Retrieval-Augmented Generation (RAG) architecture, and it is multilingual, available in English, Hindi and Punjabi. JobSphere technique uses 4-bit quantization, allowing the platform to deploy on consumer-grade GPUs (i.e., NVIDIA RTX 3050 4GB), making the implementation 89% cheaper than that of cloud-based systems. Key innovations include voice-enabled interaction with the assistant, automated mock tests, resume parsing with skills recognition, and embed-based job recommendation that achieves a precision@10 score of 68%. An evaluation of JobSphere's implementation reveals 94% factual accuracy, a median response time of 1.8 seconds, and a System Usability Scale score of 78.5/100, a 50% improvement compared to the baseline PGRKAM platform context. In conclusion, JobSphere effectively fills significant accessibility gaps for Punjab/Hindi-speaking users in rural locations, while also affirming the users access to trusted job content provided by government agencies.

</details>


### [59] [Where and What Matters: Sensitivity-Aware Task Vectors for Many-Shot Multimodal In-Context Learning](https://arxiv.org/abs/2511.08246)
*Ziyu Ma,Chenhui Gou,Yiming Hu,Yong Wang,Xiangxiang Chu,Bohan Zhuang,Jianfei Cai*

Main category: cs.AI

TL;DR: 本文提出了一种名为STV的新型敏感度感知任务向量插入框架，用于解决大型多模态模型（LMMs）在多样本情境下上下文学习（ICL）的挑战。STV通过识别敏感的插入位置并利用强化学习选择最合适的激活值来优化任务向量的插入，从而在多种模型和任务上实现了显著改进。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMMs）的上下文学习（ICL）能力在多样本情境下受到上下文长度限制和高推理成本的挑战。现有的基于任务向量的方法虽然尝试通过插入紧凑的表示来解决，但未能有效解决“在哪里插入”和“插入什么值”的问题。

Method: 本文提出了一个新颖的敏感度感知任务向量插入框架（STV）。其核心洞察是查询-上下文对之间的激活增量展现出一致的结构模式，为插入提供了可靠线索。基于识别出的敏感位置，STV为每个位置构建一个预聚类的激活库，然后应用强化学习来选择最适合插入的激活值。

Result: STV在多种多模态模型（如Qwen-VL, Idefics-2）和任务（如VizWiz, OK-VQA）上进行了评估。结果表明，STV具有有效性，并且相对于之前的任务向量方法展现出持续的改进和强大的泛化能力。

Conclusion: STV框架通过优化任务向量的插入位置和值，有效解决了LMMs在多样本ICL中的挑战。它利用激活增量的结构模式识别敏感位置，并通过强化学习选择最佳插入值，从而显著提升了模型的性能和泛化能力。

Abstract: Large Multimodal Models (LMMs) have shown promising in-context learning (ICL) capabilities, but scaling to many-shot settings remains difficult due to limited context length and high inference cost. To address these challenges, task-vector-based methods have been explored by inserting compact representations of many-shot in-context demonstrations into model activations. However, existing task-vector-based methods either overlook the importance of where to insert task vectors or struggle to determine suitable values for each location. To this end, we propose a novel Sensitivity-aware Task Vector insertion framework (STV) to figure out where and what to insert. Our key insight is that activation deltas across query-context pairs exhibit consistent structural patterns, providing a reliable cue for insertion. Based on the identified sensitive-aware locations, we construct a pre-clustered activation bank for each location by clustering the activation values, and then apply reinforcement learning to choose the most suitable one to insert. We evaluate STV across a range of multimodal models (e.g., Qwen-VL, Idefics-2) and tasks (e.g., VizWiz, OK-VQA), demonstrating its effectiveness and showing consistent improvements over previous task-vector-based methods with strong generalization.

</details>


### [60] [AI-Powered Data Visualization Platform: An Intelligent Web Application for Automated Dataset Analysis](https://arxiv.org/abs/2511.08363)
*Srihari R,Pallavi M,Tejaswini S,Vaishnavi R C*

Main category: cs.AI

TL;DR: 该论文介绍了一个AI驱动的数据可视化平台，它能自动化整个数据分析流程，从数据上传到生成交互式可视化，显著减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 传统数据分析耗时且依赖人工，本研究旨在消除手动数据分析的挑战，通过自动化AI驱动的分析和可视化过程来提高效率。

Method: 该平台采用Python Flask作为后端处理数据，React作为前端提供用户界面，并结合Firebase Cloud Storage进行数据存储和实时处理。核心方法包括：使用先进机器学习算法进行数据清洗（缺失值填充、异常值检测）、特征分析、智能特征选择（采用四种不同算法）、以及根据数据集属性智能生成标题和选择可视化类型。

Result: 通过对两个独立数据集的评估，该平台展示了其性能。它能对多达10万行的数据集进行实时分析，并且基于云的需求平台能够扩展以同时处理来自多个用户的请求。

Conclusion: 这款基于云的数据可视化应用显著减少了数据分析过程中的手动输入，同时保持了高质量、有影响力的视觉输出和良好的用户体验。

Abstract: An AI-powered data visualization platform that automates the entire data analysis process, from uploading a dataset to generating an interactive visualization. Advanced machine learning algorithms are employed to clean and preprocess the data, analyse its features, and automatically select appropriate visualizations. The system establishes the process of automating AI-based analysis and visualization from the context of data-driven environments, and eliminates the challenge of time-consuming manual data analysis. The combination of a Python Flask backend to access the dataset, paired with a React frontend, provides a robust platform that automatically interacts with Firebase Cloud Storage for numerous data processing and data analysis solutions and real-time sources. Key contributions include automatic and intelligent data cleaning, with imputation for missing values, and detection of outliers, via analysis of the data set. AI solutions to intelligently select features, using four different algorithms, and intelligent title generation and visualization are determined by the attributes of the dataset. These contributions were evaluated using two separate datasets to assess the platform's performance. In the process evaluation, the initial analysis was performed in real-time on datasets as large as 100000 rows, while the cloud-based demand platform scales to meet requests from multiple users and processes them simultaneously. In conclusion, the cloud-based data visualization application allowed for a significant reduction of manual inputs to the data analysis process while maintaining a high quality, impactful visual outputs, and user experiences

</details>


### [61] [SOM Directions are Better than One: Multi-Directional Refusal Suppression in Language Models](https://arxiv.org/abs/2511.08379)
*Giorgio Piras,Raffaele Mura,Fabio Brau,Luca Oneto,Fabio Roli,Battista Biggio*

Main category: cs.AI

TL;DR: 本研究提出一种利用自组织映射（SOMs）从大型语言模型（LLMs）的潜在空间中提取多个拒绝方向的新方法，以更有效地抑制模型拒绝有害或不道德提示的行为，并证明其优于单方向基线和越狱算法。


<details>
  <summary>Details</summary>
Motivation: 现有研究将拒绝行为编码为潜在空间中的单一方向（例如，有害和无害提示表示质心之差），但新证据表明LLMs中的概念通常以嵌入在高维潜在空间中的低维流形形式存在。这促使研究者寻找提取多个拒绝方向的方法。

Method: 首先，研究证明自组织映射（SOMs）能够推广先前的均值差技术。接着，在有害提示表示上训练SOMs以识别多个神经元。然后，通过从每个神经元中减去无害提示表示的质心，推导出一组表达拒绝概念的多个方向。最后，通过从模型内部消除这些多个方向来验证该方法。

Result: 实验结果表明，从模型内部消除多个拒绝方向不仅优于单一方向基线，而且还超越了专门的越狱算法，从而有效地抑制了模型的拒绝行为。

Conclusion: 本研究的方法具有重要的机制解释意义，能够更深入地理解和控制LLMs的拒绝行为。

Abstract: Refusal refers to the functional behavior enabling safety-aligned language models to reject harmful or unethical prompts. Following the growing scientific interest in mechanistic interpretability, recent work encoded refusal behavior as a single direction in the model's latent space; e.g., computed as the difference between the centroids of harmful and harmless prompt representations. However, emerging evidence suggests that concepts in LLMs often appear to be encoded as a low-dimensional manifold embedded in the high-dimensional latent space. Motivated by these findings, we propose a novel method leveraging Self-Organizing Maps (SOMs) to extract multiple refusal directions. To this end, we first prove that SOMs generalize the prior work's difference-in-means technique. We then train SOMs on harmful prompt representations to identify multiple neurons. By subtracting the centroid of harmless representations from each neuron, we derive a set of multiple directions expressing the refusal concept. We validate our method on an extensive experimental setup, demonstrating that ablating multiple directions from models' internals outperforms not only the single-direction baseline but also specialized jailbreak algorithms, leading to an effective suppression of refusal. Finally, we conclude by analyzing the mechanistic implications of our approach.

</details>


### [62] [FaithAct: Faithfulness Planning and Acting in MLLMs](https://arxiv.org/abs/2511.08409)
*Junxian Li,Xinyue Xu,Sai Ma,Sichao Li*

Main category: cs.AI

TL;DR: 本文针对大型语言模型在多模态推理中存在的不忠实性（幻觉）问题，提出了一个评估框架FaithEval和一个规划执行框架FaithAct。FaithAct通过在每个推理步骤强制证据基础，显著提高了感知忠实性，同时保持了任务准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多模态推理中经常产生看似合理但缺乏感知证据支持的推理链，即不忠实性，这是一个持续存在的挑战。

Method: 本文区分了行为忠实性（推理与输出对齐）和感知忠实性（推理与输入对齐）。提出了FaithEval框架，通过评估每个声称的对象是否得到图像的视觉支持，来量化步骤级和链级忠实性。在此基础上，提出了FaithAct，一个忠实性优先的规划和执行框架，它在每个推理步骤强制执行证据基础。

Result: 实验表明，与基于提示和工具增强的基线相比，FaithAct在不降低任务准确性的前提下，将感知忠实性提高了26%。分析显示，将忠实性作为指导原则不仅能缓解幻觉，还能带来更稳定的推理轨迹。

Conclusion: 本文建立了一个统一的框架，用于评估和强制执行多模态推理中的忠实性，有效解决了大型语言模型的不忠实性问题。

Abstract: Unfaithfulness remains a persistent challenge for large language models (LLMs), which often produce plausible yet ungrounded reasoning chains that diverge from perceptual evidence or final conclusions. We distinguish between behavioral faithfulness (alignment between reasoning and output) and perceptual faithfulness (alignment between reasoning and input), and introduce FaithEval for quantifying step-level and chain-level faithfulness by evaluating whether each claimed object is visually supported by the image. Building on these insights, we propose FaithAct, a faithfulness-first planning and acting framework that enforces evidential grounding at every reasoning step. Experiments across multiple reasoning benchmarks demonstrate that FaithAct improves perceptual faithfulness by up to 26% without degrading task accuracy compared to prompt-based and tool-augmented baselines. Our analysis shows that treating faithfulness as a guiding principle not only mitigates hallucination but also leads to more stable reasoning trajectories. This work thereby establishes a unified framework for both evaluating and enforcing faithfulness in multimodal reasoning.

</details>


### [63] [Patching LLM Like Software: A Lightweight Method for Improving Safety Policy in Large Language Models](https://arxiv.org/abs/2511.08484)
*Huzaifa Arif,Keerthiram Murugesan,Ching-Yun Ko,Pin-Yu Chen,Payel Das,Alex Gittens*

Main category: cs.AI

TL;DR: 本文提出一种轻量级、模块化的“补丁”方法，通过在大型语言模型（LLM）前添加一个可学习的紧凑前缀，快速修复安全漏洞，实现与下一代安全对齐模型相当的安全改进，且仅增加极少量参数。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的安全更新（如发布新版本或完整模型微调）成本高、不频繁且难以满足客户需求，导致已发布的模型存在已知的安全漏洞。需要一种快速、可扩展且高效的修复机制。

Method: 该方法通过在现有LLM前添加一个紧凑、可学习的前缀（称为“补丁”），引入仅0.003%的额外参数，从而可靠地引导模型行为向更安全的参考模型靠拢。

Result: 在毒性缓解、偏见减少和有害内容拒绝三个关键领域，策略补丁实现了与下一代安全对齐模型相当的安全改进，同时保持了模型的流畅性。

Conclusion: LLM可以像软件一样进行“打补丁”，为供应商和从业者提供了一种实用机制，用于在主要模型发布之间分发可扩展、高效且可组合的安全更新。

Abstract: We propose patching for large language models (LLMs) like software versions, a lightweight and modular approach for addressing safety vulnerabilities. While vendors release improved LLM versions, major releases are costly, infrequent, and difficult to tailor to customer needs, leaving released models with known safety gaps. Unlike full-model fine-tuning or major version updates, our method enables rapid remediation by prepending a compact, learnable prefix to an existing model. This "patch" introduces only 0.003% additional parameters, yet reliably steers model behavior toward that of a safer reference model. Across three critical domains (toxicity mitigation, bias reduction, and harmfulness refusal) policy patches achieve safety improvements comparable to next-generation safety-aligned models while preserving fluency. Our results demonstrate that LLMs can be "patched" much like software, offering vendors and practitioners a practical mechanism for distributing scalable, efficient, and composable safety updates between major model releases.

</details>


### [64] [Dataset Safety in Autonomous Driving: Requirements, Risks, and Assurance](https://arxiv.org/abs/2511.08439)
*Alireza Abbaspour,Tejaskumar Balgonda Patil,B Ravi Kiran,Russel Mohr,Senthil Yogamani*

Main category: cs.AI

TL;DR: 本文提出一个与ISO/PAS 8800对齐的结构化框架，用于开发自动驾驶AI系统中的安全数据集，涵盖数据生命周期、安全分析、验证与确认策略，旨在提升AI系统的鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 数据集完整性对于AI系统的安全性和可靠性至关重要，尤其是在自动驾驶领域。研究旨在解决数据集不足导致的安全隐患，并与国际标准对齐。

Method: 文章提出了一个结构化框架，包括AI数据飞轮和数据集生命周期（数据收集、标注、整理、维护）。它整合了严格的安全分析以识别危害和缓解风险，定义了数据集安全要求建立流程，并提出了验证和确认策略以确保符合安全标准。

Result: 该论文提出了一个开发安全数据集的结构化框架，引入了AI数据飞轮和数据集生命周期，定义了建立数据集安全要求的流程，并提出了验证与确认策略。此外，还回顾了数据集安全和自动驾驶领域的最新研究和趋势。

Conclusion: 通过整合这些视角，该论文旨在推动自动驾驶应用中鲁棒、安全保障的AI系统发展，以确保AI系统的安全性和可靠性。

Abstract: Dataset integrity is fundamental to the safety and reliability of AI systems, especially in autonomous driving. This paper presents a structured framework for developing safe datasets aligned with ISO/PAS 8800 guidelines. Using AI-based perception systems as the primary use case, it introduces the AI Data Flywheel and the dataset lifecycle, covering data collection, annotation, curation, and maintenance. The framework incorporates rigorous safety analyses to identify hazards and mitigate risks caused by dataset insufficiencies. It also defines processes for establishing dataset safety requirements and proposes verification and validation strategies to ensure compliance with safety standards. In addition to outlining best practices, the paper reviews recent research and emerging trends in dataset safety and autonomous vehicle development, providing insights into current challenges and future directions. By integrating these perspectives, the paper aims to advance robust, safety-assured AI systems for autonomous driving applications.

</details>


### [65] [A Matter of Interest: Understanding Interestingness of Math Problems in Humans and Language Models](https://arxiv.org/abs/2511.08548)
*Shubhra Mishra,Yuka Machino,Gabriel Poesia,Albert Jiang,Joy Hsu,Adrian Weller,Challenger Mishra,David Broman,Joshua B. Tenenbaum,Mateja Jamnik,Cedegao E. Zhang,Katherine M. Collins*

Main category: cs.AI

TL;DR: 本研究通过两项实证研究，考察了大型语言模型（LLMs）对数学问题趣味性和难度的判断与人类判断的对齐程度，发现LLMs在广义上与人类判断一致，但在分布和理由方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统（如LLMs）越来越多地参与到数学领域，理解它们的判断（如问题趣味性或挑战性）与人类判断的对齐程度变得至关重要，这对于人机协作至关重要。

Method: 进行了两项实证研究，考察了人类和LLMs对数学问题趣味性和难度的评估。研究对象包括众包平台参与者和国际数学奥林匹克竞赛选手。LLMs也参与了评估。

Result: 研究发现，虽然许多LLMs似乎在广义上与人类对趣味性的概念一致，但它们大多未能捕捉到人类判断中观察到的分布。此外，大多数LLMs在解释人类认为某些数学问题有趣的原因方面只有部分一致，与人类选择的趣味性理由显示出较弱的相关性。

Conclusion: 研究结果突出了当前LLMs在捕捉人类对数学趣味性判断方面的潜力和局限性，这对于未来数学AI思想伙伴关系具有重要意义。

Abstract: The evolution of mathematics has been guided in part by interestingness. From researchers choosing which problems to tackle next, to students deciding which ones to engage with, people's choices are often guided by judgments about how interesting or challenging problems are likely to be. As AI systems, such as LLMs, increasingly participate in mathematics with people -- whether for advanced research or education -- it becomes important to understand how well their judgments align with human ones. Our work examines this alignment through two empirical studies of human and LLM assessment of mathematical interestingness and difficulty, spanning a range of mathematical experience. We study two groups: participants from a crowdsourcing platform and International Math Olympiad competitors. We show that while many LLMs appear to broadly agree with human notions of interestingness, they mostly do not capture the distribution observed in human judgments. Moreover, most LLMs only somewhat align with why humans find certain math problems interesting, showing weak correlation with human-selected interestingness rationales. Together, our findings highlight both the promises and limitations of current LLMs in capturing human interestingness judgments for mathematical AI thought partnerships.

</details>


### [66] [DeepProofLog: Efficient Proving in Deep Stochastic Logic Programs](https://arxiv.org/abs/2511.08581)
*Ying Jiao,Rodrigo Castellano Ontiveros,Luc De Raedt,Marco Gori,Francesco Giannini,Michelangelo Diligenti,Giuseppe Marra*

Main category: cs.AI

TL;DR: 本文提出DeepProofLog (DPrL)，一种基于随机逻辑程序的新型神经符号系统，通过神经网络参数化推导步骤并结合强化学习技术，显著提升了神经符号模型的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI（NeSy AI）旨在结合神经网络和符号推理的优势，提高模型的准确性、可解释性和泛化能力。然而，现有方法常面临可扩展性不足的问题，严重限制了NeSy模型的实际应用。

Method: DPrL系统基于深度随机逻辑程序。它使用神经网络对所有推导步骤进行参数化，实现对证明系统的有效神经引导。此外，该方法将深度随机逻辑程序的消解过程与马尔可夫决策过程（MDPs）建立形式化映射，从而能够应用动态规划和强化学习技术进行高效推理和学习。

Result: 实验结果表明，DPrL在标准NeSy基准测试和知识图谱推理任务上均优于现有最先进的NeSy系统，成功将可扩展性提升到比以往更大、更复杂的场景。

Conclusion: DPrL通过将神经网络引导与强化学习技术融入随机逻辑程序，有效解决了神经符号系统的可扩展性限制，使其能够应用于更大、更复杂的AI任务。

Abstract: Neurosymbolic (NeSy) AI aims to combine the strengths of neural architectures and symbolic reasoning to improve the accuracy, interpretability, and generalization capability of AI models. While logic inference on top of subsymbolic modules has been shown to effectively guarantee these properties, this often comes at the cost of reduced scalability, which can severely limit the usability of NeSy models. This paper introduces DeepProofLog (DPrL), a novel NeSy system based on stochastic logic programs, which addresses the scalability limitations of previous methods. DPrL parameterizes all derivation steps with neural networks, allowing efficient neural guidance over the proving system. Additionally, we establish a formal mapping between the resolution process of our deep stochastic logic programs and Markov Decision Processes, enabling the application of dynamic programming and reinforcement learning techniques for efficient inference and learning. This theoretical connection improves scalability for complex proof spaces and large knowledge bases. Our experiments on standard NeSy benchmarks and knowledge graph reasoning tasks demonstrate that DPrL outperforms existing state-of-the-art NeSy systems, advancing scalability to larger and more complex settings than previously possible.

</details>


### [67] [Simulating the Visual World with Artificial Intelligence: A Roadmap](https://arxiv.org/abs/2511.08585)
*Jingtong Yue,Ziqi Huang,Zhaoxi Chen,Xintao Wang,Pengfei Wan,Ziwei Liu*

Main category: cs.AI

TL;DR: 本综述系统概述了视频生成领域向视频基础模型（作为隐式世界模型）的演变，将其概念化为世界模型与视频渲染器的结合，并追溯了其四个发展阶段，最终讨论了未来的挑战。


<details>
  <summary>Details</summary>
Motivation: 视频生成正从关注视觉吸引力转向构建支持交互并保持物理合理性的虚拟环境。这促使了视频基础模型的出现，它们不仅是视觉生成器，更是能够模拟物理动力学、代理-环境交互和任务规划的隐式世界模型。

Method: 本研究通过系统综述，将现代视频基础模型概念化为隐式世界模型和视频渲染器的结合。它追溯了视频生成通过四个世代的进展，定义了每个世代的核心特征，强调了代表性工作，并探讨了它们在机器人、自动驾驶和交互式游戏等领域的应用。

Result: 研究结果表明，视频生成最终发展为建立在视频生成模型之上的世界模型，该模型具备内在的物理合理性、实时多模态交互和跨越多个时空尺度的规划能力。每个世代的特点、代表作及其应用领域都得到了详细阐述。

Conclusion: 本研究讨论了下一代世界模型的开放挑战和设计原则，包括代理智能在塑造和评估这些系统中的作用，并展望了未来世界模型的发展方向。

Abstract: The landscape of video generation is shifting, from a focus on generating visually appealing clips to building virtual environments that support interaction and maintain physical plausibility. These developments point toward the emergence of video foundation models that function not only as visual generators but also as implicit world models, models that simulate the physical dynamics, agent-environment interactions, and task planning that govern real or imagined worlds. This survey provides a systematic overview of this evolution, conceptualizing modern video foundation models as the combination of two core components: an implicit world model and a video renderer. The world model encodes structured knowledge about the world, including physical laws, interaction dynamics, and agent behavior. It serves as a latent simulation engine that enables coherent visual reasoning, long-term temporal consistency, and goal-driven planning. The video renderer transforms this latent simulation into realistic visual observations, effectively producing videos as a "window" into the simulated world. We trace the progression of video generation through four generations, in which the core capabilities advance step by step, ultimately culminating in a world model, built upon a video generation model, that embodies intrinsic physical plausibility, real-time multimodal interaction, and planning capabilities spanning multiple spatiotemporal scales. For each generation, we define its core characteristics, highlight representative works, and examine their application domains such as robotics, autonomous driving, and interactive gaming. Finally, we discuss open challenges and design principles for next-generation world models, including the role of agent intelligence in shaping and evaluating these systems. An up-to-date list of related works is maintained at this link.

</details>


### [68] [Hyperdimensional Decoding of Spiking Neural Networks](https://arxiv.org/abs/2511.08558)
*Cedrick Kinavuidi,Luca Peres,Oliver Rhodes*

Main category: cs.AI

TL;DR: 本文提出了一种结合尖峰神经网络（SNN）和超维度计算（HDC）的新型SNN解码方法，该方法在多个数据集上实现了更高的分类精度、更低的延迟和更低的能耗，并能有效识别未知类别。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种具有高精度、高噪声鲁棒性、低延迟和低能耗的SNN解码方法。

Method: 将尖峰神经网络（SNN）与超维度计算（HDC）相结合，构建SNN-HDC模型作为解码方法。

Result: 与现有方法相比，SNN-HDC模型在多个测试案例中实现了更好的分类精度、更低的分类延迟和更低的估计能耗。在DvsGesture数据集上，能耗估计降低了1.24倍至3.67倍；在SL-Animals-DVS数据集上，能耗降低了1.38倍至2.27倍。此外，该方法还能高效识别未知类别，在DvsGesture数据集上对未训练类别的样本识别率达到100%。

Conclusion: 鉴于其在精度、延迟、能耗和未知类别识别方面的显著优势，SNN-HDC解码方法是速率解码和延迟解码的一个非常有吸引力的替代方案。

Abstract: This work presents a novel spiking neural network (SNN) decoding method, combining SNNs with Hyperdimensional computing (HDC). The goal is to create a decoding method with high accuracy, high noise robustness, low latency and low energy usage. Compared to analogous architectures decoded with existing approaches, the presented SNN-HDC model attains generally better classification accuracy, lower classification latency and lower estimated energy consumption on multiple test cases from literature. The SNN-HDC achieved estimated energy consumption reductions ranging from 1.24x to 3.67x on the DvsGesture dataset and from 1.38x to 2.27x on the SL-Animals-DVS dataset. The presented decoding method can also efficiently identify unknown classes it has not been trained on. In the DvsGesture dataset the SNN-HDC model can identify 100% of samples from an unseen/untrained class. Given the numerous benefits shown and discussed in this paper, this decoding method represents a very compelling alternative to both rate and latency decoding.

</details>


### [69] [DiagramIR: An Automatic Pipeline for Educational Math Diagram Evaluation](https://arxiv.org/abs/2511.08283)
*Vishal Kumar,Shubhra Mishra,Rebecca Hao,Rizwaan Malik,David Broman,Dorottya Demszky*

Main category: cs.AI

TL;DR: 处理失败


<details>
  <summary>Details</summary>
Motivation: 处理失败

Method: 处理失败

Result: 处理失败

Conclusion: 处理失败

Abstract: Large Language Models (LLMs) are increasingly being adopted as tools for learning; however, most tools remain text-only, limiting their usefulness for domains where visualizations are essential, such as mathematics. Recent work shows that LLMs are capable of generating code that compiles to educational figures, but a major bottleneck remains: scalable evaluation of these diagrams. We address this by proposing DiagramIR: an automatic and scalable evaluation pipeline for geometric figures. Our method relies on intermediate representations (IRs) of LaTeX TikZ code. We compare our pipeline to other evaluation baselines such as LLM-as-a-Judge, showing that our approach has higher agreement with human raters. This evaluation approach also enables smaller models like GPT-4.1-Mini to perform comparably to larger models such as GPT-5 at a 10x lower inference cost, which is important for deploying accessible and scalable education technologies.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [70] [Knowledge-Guided Textual Reasoning for Explainable Video Anomaly Detection via LLMs](https://arxiv.org/abs/2511.07429)
*Hari Lee*

Main category: cs.CV

TL;DR: 本文提出了一种名为TbVAD的基于文本的可解释视频异常检测框架，它在文本领域内完成异常检测和解释，通过语言表示视频语义，实现可解释和知识驱动的推理。


<details>
  <summary>Details</summary>
Motivation: 传统的弱监督视频异常检测（WSVAD）模型依赖显式视觉特征，缺乏可解释性。研究动机是开发一种能提供可解释、基于知识推理的异常检测方法。

Method: TbVAD框架分三个阶段：1) 使用视觉-语言模型将视频内容转换为细粒度字幕；2) 将字幕组织成四个语义槽（动作、对象、上下文、环境）构建结构化知识；3) 生成槽级解释，揭示哪些语义因素对异常判断贡献最大。

Result: 在UCF-Crime和XD-Violence两个公开基准数据集上进行评估，结果表明基于文本的知识推理为真实世界的监控场景提供了可解释且可靠的异常检测。

Conclusion: 文本知识推理能够为视频异常检测提供可解释且可靠的解决方案，特别适用于监控场景。

Abstract: We introduce Text-based Explainable Video Anomaly Detection (TbVAD), a language-driven framework for weakly supervised video anomaly detection that performs anomaly detection and explanation entirely within the textual domain. Unlike conventional WSVAD models that rely on explicit visual features, TbVAD represents video semantics through language, enabling interpretable and knowledge-grounded reasoning. The framework operates in three stages: (1) transforming video content into fine-grained captions using a vision-language model, (2) constructing structured knowledge by organizing the captions into four semantic slots (action, object, context, environment), and (3) generating slot-wise explanations that reveal which semantic factors contribute most to the anomaly decision. We evaluate TbVAD on two public benchmarks, UCF-Crime and XD-Violence, demonstrating that textual knowledge reasoning provides interpretable and reliable anomaly detection for real-world surveillance scenarios.

</details>


### [71] [Modulo Video Recovery via Selective Spatiotemporal Vision Transformer](https://arxiv.org/abs/2511.07479)
*Tianyu Geng,Feng Ji,Wee Peng Tay*

Main category: cs.CV

TL;DR: 传统图像传感器动态范围有限，模数相机通过折叠亮度解决，但需要专门的解包算法。本文提出SSViT，首个基于深度学习的模数视频重建框架，利用Transformer和选择性时空策略，实现了最先进的模数视频恢复性能。


<details>
  <summary>Details</summary>
Motivation: 传统图像传感器动态范围受限，模数相机通过折叠亮度来处理高动态范围场景，但需要复杂的解包算法。模数图像恢复进展缓慢，尤其缺乏现代深度学习技术。标准HDR恢复方法不适用于模数恢复。

Method: 本文提出了选择性时空视觉Transformer（SSViT），这是首个用于模数视频重建的深度学习框架。SSViT采用令牌选择策略来提高效率，并专注于最关键的区域，以捕获解决折叠视频帧所需的全局依赖性和时空关系。

Result: 实验证实SSViT能从8位折叠视频中生成高质量的重建结果，并在模数视频恢复方面取得了最先进的性能。同时，研究表明标准HDR方法不适用于模数恢复。

Conclusion: SSViT是第一个用于模数视频重建的深度学习框架，它通过创新的Transformer架构和令牌选择策略，有效解决了模数恢复的挑战，显著提升了恢复质量和效率，达到了领域内领先水平。

Abstract: Conventional image sensors have limited dynamic range, causing saturation in high-dynamic-range (HDR) scenes. Modulo cameras address this by folding incident irradiance into a bounded range, yet require specialized unwrapping algorithms to reconstruct the underlying signal. Unlike HDR recovery, which extends dynamic range from conventional sampling, modulo recovery restores actual values from folded samples. Despite being introduced over a decade ago, progress in modulo image recovery has been slow, especially in the use of modern deep learning techniques. In this work, we demonstrate that standard HDR methods are unsuitable for modulo recovery. Transformers, however, can capture global dependencies and spatial-temporal relationships crucial for resolving folded video frames. Still, adapting existing Transformer architectures for modulo recovery demands novel techniques. To this end, we present Selective Spatiotemporal Vision Transformer (SSViT), the first deep learning framework for modulo video reconstruction. SSViT employs a token selection strategy to improve efficiency and concentrate on the most critical regions. Experiments confirm that SSViT produces high-quality reconstructions from 8-bit folded videos and achieves state-of-the-art performance in modulo video recovery.

</details>


### [72] [Two Datasets Are Better Than One: Method of Double Moments for 3-D Reconstruction in Cryo-EM](https://arxiv.org/abs/2511.07438)
*Joe Kileel,Oscar Mickelin,Amit Singer,Sheng Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为“双矩法”（MoDM）的新型数据融合框架，通过结合来自不同取向分布的投影图像的二阶矩，显著提高了冷冻电镜（cryo-EM）分子结构重建的质量。


<details>
  <summary>Details</summary>
Motivation: 冷冻电镜从随机取向颗粒的噪声断层投影图像中重建三维分子结构面临挑战。研究旨在通过利用不同实验条件下采集的多个数据集来增强重建质量。

Method: 引入了双矩法（MoDM），该方法利用了两种二阶矩：一种来自均匀取向分布，另一种来自非均匀且未知取向分布的投影图像。理论上证明了这些矩可以唯一确定底层结构（除了全局旋转和反射），并开发了一种基于凸松弛的算法，仅使用二阶统计量即可实现精确恢复。

Result: 研究结果表明，这两种二阶矩在通用情况下可以唯一确定底层结构（至多一个全局旋转和反射）。所开发的基于凸松弛的算法仅使用二阶统计量就能实现准确的结构恢复。

Conclusion: 收集和建模不同实验条件下的多个数据集，并利用数据集的多样性，可以显著提高计算成像任务中的重建质量。

Abstract: Cryo-electron microscopy (cryo-EM) is a powerful imaging technique for reconstructing three-dimensional molecular structures from noisy tomographic projection images of randomly oriented particles. We introduce a new data fusion framework, termed the method of double moments (MoDM), which reconstructs molecular structures from two instances of the second-order moment of projection images obtained under distinct orientation distributions--one uniform, the other non-uniform and unknown. We prove that these moments generically uniquely determine the underlying structure, up to a global rotation and reflection, and we develop a convex-relaxation-based algorithm that achieves accurate recovery using only second-order statistics. Our results demonstrate the advantage of collecting and modeling multiple datasets under different experimental conditions, illustrating that leveraging dataset diversity can substantially enhance reconstruction quality in computational imaging tasks.

</details>


### [73] [Laplacian Score Sharpening for Mitigating Hallucination in Diffusion Models](https://arxiv.org/abs/2511.07496)
*Barath Chandran. C,Srinivas Anumasa,Dianbo Liu*

Main category: cs.CV

TL;DR: 本文提出了一种后验拉普拉斯调整方法，在推断过程中利用分数函数的锐度来减少扩散模型中的模式插值幻觉，并在不同维度的数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然成功，但已知会产生不连贯或不真实的幻觉样本。现有研究将其归因于模式插值和分数平滑现象，但缺乏在采样过程中阻止这些幻觉生成的方法。

Method: 在推断过程中，对分数函数进行后验调整，利用分数函数的拉普拉斯算子（或锐度）来减少无条件扩散模型中的模式插值幻觉。针对高维数据，采用Hutchinson迹估计器的有限差分变体，推导出一种高效的拉普拉斯近似方法。

Result: 该校正显著降低了在1D/2D玩具分布和高维图像数据集上幻觉样本的生成率。此外，研究还探讨了拉普拉斯算子与分数函数不确定性之间的关系。

Conclusion: 所提出的基于拉普拉斯算子的后验调整方法能有效减少扩散模型中的模式插值幻觉，并在1D、2D和高维图像数据上表现出显著效果，同时揭示了拉普拉斯算子与分数不确定性之间的联系。

Abstract: Diffusion models, though successful, are known to suffer from hallucinations that create incoherent or unrealistic samples. Recent works have attributed this to the phenomenon of mode interpolation and score smoothening, but they lack a method to prevent their generation during sampling. In this paper, we propose a post-hoc adjustment to the score function during inference that leverages the Laplacian (or sharpness) of the score to reduce mode interpolation hallucination in unconditional diffusion models across 1D, 2D, and high-dimensional image data. We derive an efficient Laplacian approximation for higher dimensions using a finite-difference variant of the Hutchinson trace estimator. We show that this correction significantly reduces the rate of hallucinated samples across toy 1D/2D distributions and a high- dimensional image dataset. Furthermore, our analysis explores the relationship between the Laplacian and uncertainty in the score.

</details>


### [74] [Toward the Frontiers of Reliable Diffusion Sampling via Adversarial Sinkhorn Attention Guidance](https://arxiv.org/abs/2511.07499)
*Kwanyoung Kim*

Main category: cs.CV

TL;DR: 本文提出对抗性Sinkhorn注意力引导（ASAG），通过最优传输和Sinkhorn算法对抗性地破坏扩散模型中的自注意力得分，以减少查询与键的像素相似性。该方法无需重新训练，即可显著提升文本到图像扩散的生成质量和下游应用的控制性与保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型引导方法（如CFG）通过启发式扰动函数（如身份混合或模糊条件）来增强目标输出，但这些方法缺乏原理基础，依赖于手动设计的失真，且通常通过有意降级另一个输出（通常是无条件输出）来实现。

Method: ASAG方法通过最优传输的视角重新解释扩散模型中的注意力分数，并利用Sinkhorn算法有意扰乱传输成本。它在自注意力层中注入对抗性成本，以降低查询和键之间的像素级相似性，从而削弱误导性的注意力对齐。

Result: ASAG在文本到图像扩散中显示出持续的改进，并增强了IP-Adapter和ControlNet等下游应用的控制性和保真度。该方法轻量、即插即用，且无需任何模型重新训练即可提高可靠性。

Conclusion: ASAG提供了一种新颖且有原则的方法，通过对抗性地破坏自注意力机制，显著提升了扩散模型的生成性能，包括条件和无条件样本的质量，以及在下游应用中的控制性和保真度。

Abstract: Diffusion models have demonstrated strong generative performance when using guidance methods such as classifier-free guidance (CFG), which enhance output quality by modifying the sampling trajectory. These methods typically improve a target output by intentionally degrading another, often the unconditional output, using heuristic perturbation functions such as identity mixing or blurred conditions. However, these approaches lack a principled foundation and rely on manually designed distortions. In this work, we propose Adversarial Sinkhorn Attention Guidance (ASAG), a novel method that reinterprets attention scores in diffusion models through the lens of optimal transport and intentionally disrupt the transport cost via Sinkhorn algorithm. Instead of naively corrupting the attention mechanism, ASAG injects an adversarial cost within self-attention layers to reduce pixel-wise similarity between queries and keys. This deliberate degradation weakens misleading attention alignments and leads to improved conditional and unconditional sample quality. ASAG shows consistent improvements in text-to-image diffusion, and enhances controllability and fidelity in downstream applications such as IP-Adapter and ControlNet. The method is lightweight, plug-and-play, and improves reliability without requiring any model retraining.

</details>


### [75] [LiveNeRF: Efficient Face Replacement Through Neural Radiance Fields Integration](https://arxiv.org/abs/2511.07552)
*Tung Vu,Hai Nguyen,Cong Tran*

Main category: cs.CV

TL;DR: LiveNeRF是一种实时（33 FPS）高质量换脸技术，旨在解决现有方法的局限性，并促进其在娱乐、教育和通信等领域的实际应用，同时强调负责任的部署。


<details>
  <summary>Details</summary>
Motivation: 现有换脸技术在性能和视觉质量上存在局限性，阻碍了其实时应用和广泛部署。该研究旨在克服这些限制，以支持配音、虚拟化身和跨文化内容改编等应用，并特别关注内容创作者、教育工作者和语言障碍人士的需求。

Method: 本文提出LiveNeRF框架，通过优化技术实现实时性能和卓越的视觉质量，但抽象中未详细说明具体的技术方法。

Result: LiveNeRF实现了实时性能（33 FPS）和卓越的视觉质量，使其能够实际部署于直播、视频会议和互动媒体中。该技术尤其有益于内容创作者、教育工作者以及通过可访问的虚拟形象进行交流的语言障碍人士。

Conclusion: LiveNeRF框架通过提供实时高质量的换脸技术，为娱乐、教育和通信领域带来了显著进步。尽管存在未经授权的深度伪造风险，但作者倡导通过用户同意验证和整合检测系统来负责任地部署，以确保积极的社会影响并最小化风险。

Abstract: Face replacement technology enables significant advancements in entertainment, education, and communication applications, including dubbing, virtual avatars, and cross-cultural content adaptation. Our LiveNeRF framework addresses critical limitations of existing methods by achieving real-time performance (33 FPS) with superior visual quality, enabling practical deployment in live streaming, video conferencing, and interactive media. The technology particularly benefits content creators, educators, and individuals with speech impairments through accessible avatar communication. While acknowledging potential misuse in unauthorized deepfake creation, we advocate for responsible deployment with user consent verification and integration with detection systems to ensure positive societal impact while minimizing risks.

</details>


### [76] [TrackStudio: An Integrated Toolkit for Markerless Tracking](https://arxiv.org/abs/2511.07624)
*Hristo Dimitrov,Giulia Dominijanni,Viktorija Pavalkyte,Tamar R. Makin*

Main category: cs.CV

TL;DR: TrackStudio是一个易于访问、集成且基于GUI的无标记运动追踪工具包，它将现有开源工具整合，使非专业人士也能在各种环境下进行2D和3D追踪，无需编程技能，并经验证表现稳定可靠。


<details>
  <summary>Details</summary>
Motivation: 无标记运动追踪技术虽已取得显著进展并具有巨大潜力，但现有工具通常需要深厚的技术专长。研究人员发现，市场上缺乏一种集成且易于使用的解决方案，能够为非专业用户在多样化场景中提供足够的追踪性能。

Method: 本研究开发了TrackStudio，一个模块化、基于图形用户界面（GUI）的流水线，它整合了已有的开源工具。该工具包提供自动2D和3D追踪、校准、预处理、特征提取和可视化功能，无需任何编程技能。此外，还提供了详细的用户指南，包括视频采集、同步、设置的实用建议以及常见问题和规避方法。

Result: TrackStudio在三种不同环境（包括使用低成本网络摄像头或高分辨率相机）和挑战性条件（如身体姿势、光照、空间和障碍物）下进行了验证。在76名参与者中，平均帧间相关性超过0.98，手部追踪的平均三角测量误差保持在较低水平（<13.6毫米），这表明了稳定和一致的追踪性能。研究还表明，该流水线可以扩展到手部以外的其他身体和面部区域。

Conclusion: TrackStudio为需要可靠性能但缺乏专业知识的研究人员或普通用户提供了一个实用且易于访问的无标记追踪途径。

Abstract: Markerless motion tracking has advanced rapidly in the past 10 years and currently offers powerful opportunities for behavioural, clinical, and biomechanical research. While several specialised toolkits provide high performance for specific tasks, using existing tools still requires substantial technical expertise. There remains a gap in accessible, integrated solutions that deliver sufficient tracking for non-experts across diverse settings.
  TrackStudio was developed to address this gap by combining established open-source tools into a single, modular, GUI-based pipeline that works out of the box. It provides automatic 2D and 3D tracking, calibration, preprocessing, feature extraction, and visualisation without requiring any programming skills. We supply a user guide with practical advice for video acquisition, synchronisation, and setup, alongside documentation of common pitfalls and how to avoid them.
  To validate the toolkit, we tested its performance across three environments using either low-cost webcams or high-resolution cameras, including challenging conditions for body position, lightning, and space and obstructions. Across 76 participants, average inter-frame correlations exceeded 0.98 and average triangulation errors remained low (<13.6mm for hand tracking), demonstrating stable and consistent tracking. We further show that the same pipeline can be extended beyond hand tracking to other body and face regions. TrackStudio provides a practical, accessible route into markerless tracking for researchers or laypeople who need reliable performance without specialist expertise.

</details>


### [77] [Predicting Coronary Artery Calcium Severity based on Non-Contrast Cardiac CT images using Deep Learning](https://arxiv.org/abs/2511.07695)
*Lachlan Nguyen,Aidan Cousins,Arcot Sowmya,Hugh Dixson,Sonit Singh*

Main category: cs.CV

TL;DR: 本研究开发了一种深度学习卷积神经网络（CNN）模型，用于将心脏非对比CT图像中的冠状动脉钙化（CAC）评分自动分类为六个临床类别，并取得了高准确性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球死亡率高的主要原因。当前的冠状动脉钙化（CAC）评分实践需要放射科医生和训练有素的放射技师进行耗时的半自动分析。因此，研究旨在开发一种更高效、自动化的工具来对CAC评分进行分类。

Method: 研究开发了一个深度学习卷积神经网络（CNN）模型。模型使用68例患者的回顾性心脏非对比CT扫描数据，并以其报告的半自动钙化评分作为参考标签。数据集被划分为训练、验证和测试集，以训练和评估模型在六类CAC评分分类任务上的性能。

Result: 该模型在六类CAC评分分类任务上表现出高性能。在分析的扫描中，模型错误分类了32例，其中26例倾向于高估CAC。总体而言，模型显示出高度一致性（Cohen's kappa为0.962），总准确率为96.5%，并具有高泛化性。

Conclusion: 研究结果表明，该CNN模型输出的CAC评分准确且与当前的半自动实践一致，对测试数据具有良好的泛化性。这证明了CNN模型在将钙化评分分层为扩展的六个临床类别方面的可行性。

Abstract: Cardiovascular disease causes high rates of mortality worldwide. Coronary artery calcium (CAC) scoring is a powerful tool to stratify the risk of atherosclerotic cardiovascular disease. Current scoring practices require time-intensive semiautomatic analysis of cardiac computed tomography by radiologists and trained radiographers. The purpose of this study is to develop a deep learning convolutional neural networks (CNN) model to classify the calcium score in cardiac, non-contrast computed tomography images into one of six clinical categories. A total of 68 patient scans were retrospectively obtained together with their respective reported semiautomatic calcium score using an ECG-gated GE Discovery 570 Cardiac SPECT/CT camera. The dataset was divided into training, validation and test sets. Using the semiautomatic CAC score as the reference label, the model demonstrated high performance on a six-class CAC scoring categorisation task. Of the scans analysed, the model misclassified 32 cases, tending towards overestimating the CAC in 26 out of 32 misclassifications. Overall, the model showed high agreement (Cohen's kappa of 0.962), an overall accuracy of 96.5% and high generalisability. The results suggest that the model outputs were accurate and consistent with current semiautomatic practice, with good generalisability to test data. The model demonstrates the viability of a CNN model to stratify the calcium score into an expanded set of six clinical categories.

</details>


### [78] [FlowFeat: Pixel-Dense Embedding of Motion Profiles](https://arxiv.org/abs/2511.07696)
*Nikita Araslanov,Anna Sonnweber,Daniel Cremers*

Main category: cs.CV

TL;DR: FlowFeat是一种高分辨率、多任务的特征表示，通过新颖的运动配置文件蒸馏技术，解决了现有网络特征分辨率低的问题，显著提升了密集预测任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的网络（如Transformer）生成的特征图分辨率较低，这对于视频目标分割、单目深度估计和语义分割等需要精细空间信息的密集预测任务来说是次优的。

Method: 该研究提出了FlowFeat，一种高分辨率、多任务的特征表示。其核心是利用一种新颖的蒸馏技术，嵌入了合理视在运动（或运动配置文件）的分布。通过利用光流网络和多样化的视频数据，开发了一个有效的自监督训练框架来统计近似视在运动。

Result: FlowFeat以显著的空间细节编码了几何和语义线索，并展现出高时间一致性。实验证明，FlowFeat显著增强了五种最先进编码器和替代上采样策略的表示能力，在视频目标分割、单目深度估计和语义分割这三个密集任务上均有提升。FlowFeat的训练计算成本低，并且对不准确的光流估计具有鲁棒性，即使使用无监督光流网络也依然高效。

Conclusion: 该工作为实现可靠且通用的密集图像表示迈出了重要一步。

Abstract: Dense and versatile image representations underpin the success of virtually all computer vision applications. However, state-of-the-art networks, such as transformers, produce low-resolution feature grids, which are suboptimal for dense prediction tasks. To address this limitation, we present FlowFeat, a high-resolution and multi-task feature representation. The key ingredient behind FlowFeat is a novel distillation technique that embeds a distribution of plausible apparent motions, or motion profiles. By leveraging optical flow networks and diverse video data, we develop an effective self-supervised training framework that statistically approximates the apparent motion. With its remarkable level of spatial detail, FlowFeat encodes a compelling degree of geometric and semantic cues while exhibiting high temporal consistency. Empirically, FlowFeat significantly enhances the representational power of five state-of-the-art encoders and alternative upsampling strategies across three dense tasks: video object segmentation, monocular depth estimation and semantic segmentation. Training FlowFeat is computationally inexpensive and robust to inaccurate flow estimation, remaining highly effective even when using unsupervised flow networks. Our work takes a step forward towards reliable and versatile dense image representations.

</details>


### [79] [Cross Modal Fine-grained Alignment via Granularity-aware and Region-uncertain Modeling](https://arxiv.org/abs/2511.07710)
*Jiale Liu,Haoming Zhou,Yishu Zhu,Bingzhi Chen,Yuncheng Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种统一方法，通过引入显著性感知、粒度感知建模和区域级不确定性建模，解决了细粒度图像-文本对齐中现有方法的局限性，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 细粒度图像-文本对齐是多模态学习的关键挑战，但现有方法存在两个主要局限：1) 缺乏鲁棒的模态内机制来评估视觉和文本标记的重要性，导致在复杂场景中泛化能力差；2) 缺乏细粒度不确定性建模，无法捕捉区域-词语对应关系中一对多和多对一的特性。

Method: 本文提出了一种统一方法，结合了显著性感知和粒度感知建模以及区域级不确定性建模。该方法利用模态特异性偏差来识别显著特征，避免依赖脆弱的跨模态注意力，并将区域特征表示为高斯混合分布以捕捉细粒度不确定性。

Result: 在Flickr30K和MS-COCO数据集上的大量实验表明，该方法在各种骨干架构下均实现了最先进的性能，显著增强了细粒度图像-文本对齐的鲁棒性和可解释性。

Conclusion: 所提出的统一方法有效解决了现有细粒度图像-文本对齐方法的局限性，通过引入显著性感知、粒度感知和区域级不确定性建模，显著提升了对齐的性能、鲁棒性和可解释性。

Abstract: Fine-grained image-text alignment is a pivotal challenge in multimodal learning, underpinning key applications such as visual question answering, image captioning, and vision-language navigation. Unlike global alignment, fine-grained alignment requires precise correspondence between localized visual regions and textual tokens, often hindered by noisy attention mechanisms and oversimplified modeling of cross-modal relationships. In this work, we identify two fundamental limitations of existing approaches: the lack of robust intra-modal mechanisms to assess the significance of visual and textual tokens, leading to poor generalization in complex scenes; and the absence of fine-grained uncertainty modeling, which fails to capture the one-to-many and many-to-one nature of region-word correspondences. To address these issues, we propose a unified approach that incorporates significance-aware and granularity-aware modeling and region-level uncertainty modeling. Our method leverages modality-specific biases to identify salient features without relying on brittle cross-modal attention, and represents region features as a mixture of Gaussian distributions to capture fine-grained uncertainty. Extensive experiments on Flickr30K and MS-COCO demonstrate that our approach achieves state-of-the-art performance across various backbone architectures, significantly enhancing the robustness and interpretability of fine-grained image-text alignment.

</details>


### [80] [UltraGS: Gaussian Splatting for Ultrasound Novel View Synthesis](https://arxiv.org/abs/2511.07743)
*Yuezhe Yang,Wenjie Cai,Dexin Yang,Yufang Dong,Xingbo Dong,Zhe Jin*

Main category: cs.CV

TL;DR: UltraGS是一种针对超声成像优化的三维高斯泼溅框架，通过深度感知高斯泼溅和结合超声物理学的轻量级渲染函数，实现了高精度、实时的新视图合成，并发布了临床超声检查数据集。


<details>
  <summary>Details</summary>
Motivation: 超声成像作为一种非侵入性临床诊断工具，其有限的视野限制了新视图合成的复杂性，因此需要一种有效的方法来解决这一挑战。

Method: 1. 引入深度感知高斯泼溅策略，为每个高斯分配可学习的视野，以实现准确的深度预测和精确的结构表示。 2. 设计SH-DARS轻量级渲染函数，结合低阶球谐函数与超声波物理特性（包括深度衰减、反射和散射），以准确模拟组织强度。 3. 贡献了临床超声检查数据集，用于基准测试，涵盖真实临床协议下的多样解剖扫描。

Result: UltraGS在三个数据集上表现出卓越性能，在PSNR（高达29.55）、SSIM（高达0.89）和MSE（低至0.002）方面均达到最先进水平，同时实现64.69 fps的实时合成。

Conclusion: UltraGS为超声成像提供了一种优越的、实时的、高精度的新视图合成解决方案，能够准确预测深度并精确表示结构。

Abstract: Ultrasound imaging is a cornerstone of non-invasive clinical diagnostics, yet its limited field of view complicates novel view synthesis. We propose \textbf{UltraGS}, a Gaussian Splatting framework optimized for ultrasound imaging. First, we introduce a depth-aware Gaussian splatting strategy, where each Gaussian is assigned a learnable field of view, enabling accurate depth prediction and precise structural representation. Second, we design SH-DARS, a lightweight rendering function combining low-order spherical harmonics with ultrasound-specific wave physics, including depth attenuation, reflection, and scattering, to model tissue intensity accurately. Third, we contribute the Clinical Ultrasound Examination Dataset, a benchmark capturing diverse anatomical scans under real-world clinical protocols. Extensive experiments on three datasets demonstrate UltraGS's superiority, achieving state-of-the-art results in PSNR (up to 29.55), SSIM (up to 0.89), and MSE (as low as 0.002) while enabling real-time synthesis at 64.69 fps. The code and dataset are open-sourced at: https://github.com/Bean-Young/UltraGS.

</details>


### [81] [VectorSynth: Fine-Grained Satellite Image Synthesis with Structured Semantics](https://arxiv.org/abs/2511.07744)
*Daniel Cher,Brian Wei,Srikumar Sastry,Nathan Jacobs*

Main category: cs.CV

TL;DR: VectorSynth是一个基于扩散模型的框架，用于根据带语义属性的多边形地理标注生成像素级精确的卫星图像，支持细粒度、空间定位的编辑。


<details>
  <summary>Details</summary>
Motivation: 先前的文本或布局条件模型缺乏图像与语义矢量几何之间的密集跨模态对应，限制了精细、空间定位的编辑。需要一种能够混合语言提示和几何感知条件，支持快速假设模拟、空间编辑和地图信息内容生成的交互式工作流。

Method: VectorSynth是一个基于扩散的框架，通过学习图像和语义矢量几何之间的密集跨模态对应关系来实现像素级精确的卫星图像合成。它使用一个视觉语言对齐模块从多边形语义中生成像素级嵌入，这些嵌入指导条件图像生成框架，使其同时遵循空间范围和语义线索。该方法支持混合语言提示和几何感知条件的交互式工作流。为此，研究人员收集了一个包含卫星场景和像素级注册多边形标注的数据集进行训练和评估。

Result: VectorSynth在语义保真度和结构真实感方面比现有方法有显著改进。此外，训练后的视觉语言模型展示了细粒度的空间定位能力。

Conclusion: VectorSynth提供了一个新颖且有效的框架，能够根据多边形地理标注生成像素级精确的卫星图像，并通过学习图像与语义矢量几何之间的密集对应关系，实现精细、空间定位的编辑和交互式工作流。

Abstract: We introduce VectorSynth, a diffusion-based framework for pixel-accurate satellite image synthesis conditioned on polygonal geographic annotations with semantic attributes. Unlike prior text- or layout-conditioned models, VectorSynth learns dense cross-modal correspondences that align imagery and semantic vector geometry, enabling fine-grained, spatially grounded edits. A vision language alignment module produces pixel-level embeddings from polygon semantics; these embeddings guide a conditional image generation framework to respect both spatial extents and semantic cues. VectorSynth supports interactive workflows that mix language prompts with geometry-aware conditioning, allowing rapid what-if simulations, spatial edits, and map-informed content generation. For training and evaluation, we assemble a collection of satellite scenes paired with pixel-registered polygon annotations spanning diverse urban scenes with both built and natural features. We observe strong improvements over prior methods in semantic fidelity and structural realism, and show that our trained vision language model demonstrates fine-grained spatial grounding. The code and data are available at https://github.com/mvrl/VectorSynth.

</details>


### [82] [Auto-US: An Ultrasound Video Diagnosis Agent Using Video Classification Framework and LLMs](https://arxiv.org/abs/2511.07748)
*Yuezhe Yang,Yiyue Guo,Wenjie Cai,Qingqing Ruan,Siying Wang,Xingbo Dong,Zhe Jin,Yong Dai*

Main category: cs.CV

TL;DR: 本研究提出了Auto-US，一个结合超声视频和临床诊断文本的智能诊断代理，并构建了CUV数据集和CTU-Net模型，实现了超声视频分类的SOTA性能，并通过大语言模型生成临床诊断建议，展现了其在实际应用中的潜力和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的人工智能辅助超声视频诊断研究在数据集多样性、诊断性能和临床适用性方面存在局限性。

Method: 研究构建了包含495个超声视频的CUV数据集（涵盖五类疾病和三种器官），开发了用于超声视频分类的CTU-Net模型，并将其与大语言模型集成，形成了Auto-US智能诊断代理，以生成临床诊断建议。

Result: CTU-Net在超声视频分类中达到了86.73%的准确率，实现了最先进的性能。Auto-US生成的诊断建议经过专业临床医生验证，每例病例的最终诊断得分超过3/5。

Conclusion: Auto-US在超声视频诊断中表现出显著的有效性和临床潜力，有望在实际应用中提升医疗影像分析的效率和准确性。

Abstract: AI-assisted ultrasound video diagnosis presents new opportunities to enhance the efficiency and accuracy of medical imaging analysis. However, existing research remains limited in terms of dataset diversity, diagnostic performance, and clinical applicability. In this study, we propose \textbf{Auto-US}, an intelligent diagnosis agent that integrates ultrasound video data with clinical diagnostic text. To support this, we constructed \textbf{CUV Dataset} of 495 ultrasound videos spanning five categories and three organs, aggregated from multiple open-access sources. We developed \textbf{CTU-Net}, which achieves state-of-the-art performance in ultrasound video classification, reaching an accuracy of 86.73\% Furthermore, by incorporating large language models, Auto-US is capable of generating clinically meaningful diagnostic suggestions. The final diagnostic scores for each case exceeded 3 out of 5 and were validated by professional clinicians. These results demonstrate the effectiveness and clinical potential of Auto-US in real-world ultrasound applications. Code and data are available at: https://github.com/Bean-Young/Auto-US.

</details>


### [83] [Class Incremental Medical Image Segmentation via Prototype-Guided Calibration and Dual-Aligned Distillation](https://arxiv.org/abs/2511.07749)
*Shengqian Zhu,Chengrong Yu,Qiang Wang,Ying Song,Guangjun Li,Jiafei Wu,Xiaogang Xu,Zhang Yi,Junjie Hu*

Main category: cs.CV

TL;DR: 本文提出了一种名为PGCD和DAPD的新方法，用于解决医学图像类增量分割（CIMIS）中现有方法存在的知识保留不足和知识退化问题，通过原型引导校准和双重对齐原型蒸馏来提高旧类别的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的类增量医学图像分割方法存在两个主要问题：1) 采用“一刀切”策略，平等对待所有空间区域和特征通道，可能阻碍旧知识的精确保留；2) 仅关注旧类别的局部原型与全局原型对齐，而忽略了它们在新数据中的局部表示，导致知识退化。

Method: 本文提出了两种方法：原型引导校准蒸馏（PGCD）和双重对齐原型蒸馏（DAPD）。PGCD利用原型到特征的相似性来校准不同空间区域中类别特定的蒸馏强度，以强化可靠的旧知识并抑制误导性信息。DAPD则将当前模型中提取的旧类别的局部原型与全局原型以及局部原型进行双重对齐，以进一步提升旧类别的分割性能。

Result: 在两个广泛使用的多器官分割基准上的综合评估表明，本文提出的方法优于最先进的方法，突显了其鲁棒性和泛化能力。

Conclusion: 本文提出的PGCD和DAPD方法有效解决了CIMIS中知识保留和退化问题，通过精细化的原型校准和双重原型对齐，显著提升了旧类别医学图像分割的性能和模型的泛化能力。

Abstract: Class incremental medical image segmentation (CIMIS) aims to preserve knowledge of previously learned classes while learning new ones without relying on old-class labels. However, existing methods 1) either adopt one-size-fits-all strategies that treat all spatial regions and feature channels equally, which may hinder the preservation of accurate old knowledge, 2) or focus solely on aligning local prototypes with global ones for old classes while overlooking their local representations in new data, leading to knowledge degradation. To mitigate the above issues, we propose Prototype-Guided Calibration Distillation (PGCD) and Dual-Aligned Prototype Distillation (DAPD) for CIMIS in this paper. Specifically, PGCD exploits prototype-to-feature similarity to calibrate class-specific distillation intensity in different spatial regions, effectively reinforcing reliable old knowledge and suppressing misleading information from old classes. Complementarily, DAPD aligns the local prototypes of old classes extracted from the current model with both global prototypes and local prototypes, further enhancing segmentation performance on old categories. Comprehensive evaluations on two widely used multi-organ segmentation benchmarks demonstrate that our method outperforms state-of-the-art methods, highlighting its robustness and generalization capabilities.

</details>


### [84] [Filtered-ViT: A Robust Defense Against Multiple Adversarial Patch Attacks](https://arxiv.org/abs/2511.07755)
*Aja Khanal,Ahmed Faid,Apurva Narayan*

Main category: cs.CV

TL;DR: Filtered-ViT是一种新的Vision Transformer架构，通过集成SMART Vector Median Filtering，实现了对多重对抗性补丁攻击和自然伪影的统一鲁棒性，特别适用于医疗等安全关键领域。


<details>
  <summary>Details</summary>
Motivation: 深度学习视觉系统在医疗等安全关键领域中日益普及，但它们容易受到小型对抗性补丁的攻击，尤其是在面对多个局部干扰时，现有防御机制往往失效。这种多补丁场景是对手和真实世界伪影经常利用的。

Method: 本文提出了Filtered-ViT，一种新的Vision Transformer架构，它集成了SMART Vector Median Filtering (SMART-VMF)。SMART-VMF是一种空间自适应、多尺度、鲁棒性感知机制，能够选择性地抑制损坏区域，同时保留语义细节。

Result: 在ImageNet上，面对LaVAN多补丁攻击（四个同时存在的1%补丁），Filtered-ViT实现了79.8%的干净准确率和46.3%的鲁棒准确率，优于现有防御方法。此外，在放射医学图像的真实案例研究中，Filtered-ViT在不损害诊断内容的情况下，有效缓解了遮挡和扫描仪噪声等自然伪影。

Conclusion: Filtered-ViT是第一个展示对对抗性和自然产生的补丁状干扰具有统一鲁棒性的Transformer模型，为在真正高风险环境中构建可靠视觉系统开辟了道路。

Abstract: Deep learning vision systems are increasingly deployed in safety-critical domains such as healthcare, yet they remain vulnerable to small adversarial patches that can trigger misclassifications. Most existing defenses assume a single patch and fail when multiple localized disruptions occur, the type of scenario adversaries and real-world artifacts often exploit. We propose Filtered-ViT, a new vision transformer architecture that integrates SMART Vector Median Filtering (SMART-VMF), a spatially adaptive, multi-scale, robustness-aware mechanism that enables selective suppression of corrupted regions while preserving semantic detail. On ImageNet with LaVAN multi-patch attacks, Filtered-ViT achieves 79.8% clean accuracy and 46.3% robust accuracy under four simultaneous 1\% patches, outperforming existing defenses. Beyond synthetic benchmarks, a real-world case study on radiographic medical imagery shows that Filtered-ViT mitigates natural artifacts such as occlusions and scanner noise without degrading diagnostic content. This establishes Filtered-ViT as the first transformer to demonstrate unified robustness against both adversarial and naturally occurring patch-like disruptions, charting a path toward reliable vision systems in truly high-stakes environments.

</details>


### [85] [Semantic-Consistent Bidirectional Contrastive Hashing for Noisy Multi-Label Cross-Modal Retrieval](https://arxiv.org/abs/2511.07780)
*Likang Peng,Chao Su,Wenyuan Wu,Yuan Sun,Dezhong Peng,Xi Peng,Xu Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为SCBCH的新型跨模态哈希框架，通过语义一致性分类和双向软对比哈希，有效应对多标签数据中的标签噪声和部分语义重叠问题，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态哈希方法严重依赖昂贵且耗时的大规模标注数据集，在真实世界多标签数据中易受标签噪声影响，且忽视了多标签数据固有的部分语义重叠，导致鲁棒性和泛化能力不足。

Method: 本文提出了语义一致性双向对比哈希（SCBCH）框架，包含两个模块：1) 跨模态语义一致性分类（CSCC），利用跨模态语义一致性估计样本可靠性，以减少噪声标签影响；2) 双向软对比哈希（BSCH），基于多标签语义重叠动态生成软对比样本对，实现跨模态间语义相似和不相似样本的自适应对比学习。

Result: 在四个广泛使用的跨模态检索基准上进行的广泛实验验证了该方法的有效性和鲁棒性，在有噪声的多标签条件下，其性能始终优于最先进的方法。

Conclusion: SCBCH框架通过解决标签噪声和多标签数据中的部分语义重叠问题，显著提升了跨模态哈希的检索性能和鲁棒性。

Abstract: Cross-modal hashing (CMH) facilitates efficient retrieval across different modalities (e.g., image and text) by encoding data into compact binary representations. While recent methods have achieved remarkable performance, they often rely heavily on fully annotated datasets, which are costly and labor-intensive to obtain. In real-world scenarios, particularly in multi-label datasets, label noise is prevalent and severely degrades retrieval performance. Moreover, existing CMH approaches typically overlook the partial semantic overlaps inherent in multi-label data, limiting their robustness and generalization. To tackle these challenges, we propose a novel framework named Semantic-Consistent Bidirectional Contrastive Hashing (SCBCH). The framework comprises two complementary modules: (1) Cross-modal Semantic-Consistent Classification (CSCC), which leverages cross-modal semantic consistency to estimate sample reliability and reduce the impact of noisy labels; (2) Bidirectional Soft Contrastive Hashing (BSCH), which dynamically generates soft contrastive sample pairs based on multi-label semantic overlap, enabling adaptive contrastive learning between semantically similar and dissimilar samples across modalities. Extensive experiments on four widely-used cross-modal retrieval benchmarks validate the effectiveness and robustness of our method, consistently outperforming state-of-the-art approaches under noisy multi-label conditions.

</details>


### [86] [Beyond Randomness: Understand the Order of the Noise in Diffusion](https://arxiv.org/abs/2511.07756)
*Song Yan,Min Li,Bi Xinliang,Jian Yang,Yusen Zhang,Guanye Xiong,Yunwei Lan,Tao Zhang,Wei Zhai,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 本文发现文本生成扩散模型中的初始噪声并非纯随机，而是包含可分析的语义模式。基于信息论，提出了一种无需训练的“语义擦除-注入”两步法来调制初始噪声，以实现更一致的生成。


<details>
  <summary>Details</summary>
Motivation: 当前观点认为扩散模型中的初始噪声是随机元素，主要贡献多样性。本文对此提出质疑，揭示了噪声表面之下隐藏着强大的、可分析的语义模式。

Method: 首先，综合分析了随机噪声对模型生成的影响，发现噪声包含丰富的语义信息。其次，基于信息论，提出了一种极其简单的方法来擦除噪声中不需要的语义。然后，利用扩散模型生成过程与语义注入之间的等价性，将语义注入到清理后的噪声中。最后，对这些观察结果进行数学解释，并提出了一种简单但高效、无需训练且通用的两步“语义擦除-注入”过程来调制初始噪声。

Result: 实验结果表明，该方法在基于DiT和UNet架构的各种T2C模型中均持续有效。它为优化扩散模型的生成提供了一个新颖的视角，并提供了一个实现一致性生成的通用工具。

Conclusion: 初始噪声在文本生成扩散模型中并非纯粹随机，而是蕴含着强大的语义模式。通过提出的“语义擦除-注入”过程，可以有效调制初始噪声，显著提升生成内容的一致性，并为扩散模型的优化提供了一种通用且新颖的方法。

Abstract: In text-driven content generation (T2C) diffusion model, semantic of generated content is mostly attributed to the process of text embedding and attention mechanism interaction. The initial noise of the generation process is typically characterized as a random element that contributes to the diversity of the generated content. Contrary to this view, this paper reveals that beneath the random surface of noise lies strong analyzable patterns. Specifically, this paper first conducts a comprehensive analysis of the impact of random noise on the model's generation. We found that noise not only contains rich semantic information, but also allows for the erasure of unwanted semantics from it in an extremely simple way based on information theory, and using the equivalence between the generation process of diffusion model and semantic injection to inject semantics into the cleaned noise. Then, we mathematically decipher these observations and propose a simple but efficient training-free and universal two-step "Semantic Erasure-Injection" process to modulate the initial noise in T2C diffusion model. Experimental results demonstrate that our method is consistently effective across various T2C models based on both DiT and UNet architectures and presents a novel perspective for optimizing the generation of diffusion model, providing a universal tool for consistent generation.

</details>


### [87] [Divide-and-Conquer Decoupled Network for Cross-Domain Few-Shot Segmentation](https://arxiv.org/abs/2511.07798)
*Runmin Cong,Anpeng Wang,Bin Wan,Cong Zhang,Xiaofei Zhou,Wei Zhang*

Main category: cs.CV

TL;DR: 本文提出DCDNet，通过解耦特征并动态融合，解决了跨域小样本分割（CD-FSS）中特征纠缠问题，显著提升了跨域泛化和快速适应能力。


<details>
  <summary>Details</summary>
Motivation: 在跨域小样本分割（CD-FSS）中，编码器特征常将域相关和类别相关信息纠缠在一起，这限制了模型在面对新类别和未见域时的泛化和快速适应能力。

Method: 本文提出DCDNet（Divide-and-Conquer Decoupled Network）。在训练阶段，引入对抗对比特征分解（ACFD）模块，利用对比学习和对抗学习将骨干特征解耦为类别相关的私有表示和域共享表示。为缓解解耦可能带来的性能下降，设计了矩阵引导动态融合（MGDF）模块，在空间引导下自适应地整合基础、共享和私有特征，以保持结构一致性。在微调阶段，在MGDF之前加入交叉自适应调制（CAM）模块，通过调制使共享特征引导私有特征，确保域相关信息的有效整合，从而增强模型泛化能力。

Result: 在四个挑战性数据集上进行的广泛实验表明，DCDNet的性能优于现有的CD-FSS方法，在跨域泛化和小样本适应方面达到了新的最先进水平。

Conclusion: DCDNet通过有效解耦特征并进行动态融合，成功解决了CD-FSS中的特征纠缠问题，显著提升了模型在面对新域和新类别时的泛化和适应能力。

Abstract: Cross-domain few-shot segmentation (CD-FSS) aims to tackle the dual challenge of recognizing novel classes and adapting to unseen domains with limited annotations. However, encoder features often entangle domain-relevant and category-relevant information, limiting both generalization and rapid adaptation to new domains. To address this issue, we propose a Divide-and-Conquer Decoupled Network (DCDNet). In the training stage, to tackle feature entanglement that impedes cross-domain generalization and rapid adaptation, we propose the Adversarial-Contrastive Feature Decomposition (ACFD) module. It decouples backbone features into category-relevant private and domain-relevant shared representations via contrastive learning and adversarial learning. Then, to mitigate the potential degradation caused by the disentanglement, the Matrix-Guided Dynamic Fusion (MGDF) module adaptively integrates base, shared, and private features under spatial guidance, maintaining structural coherence. In addition, in the fine-tuning stage, to enhanced model generalization, the Cross-Adaptive Modulation (CAM) module is placed before the MGDF, where shared features guide private features via modulation ensuring effective integration of domain-relevant information. Extensive experiments on four challenging datasets show that DCDNet outperforms existing CD-FSS methods, setting a new state-of-the-art for cross-domain generalization and few-shot adaptation.

</details>


### [88] [Learning Sparse Label Couplings for Multilabel Chest X-Ray Diagnosis](https://arxiv.org/abs/2511.07801)
*Utkarsh Prakash Srivastava,Kaushik Gupta,Kaushik Nath*

Main category: cs.CV

TL;DR: 本文提出了一种用于胸部X射线多标签分类的强大且实用的管道，该管道基于SE-ResNeXt101，并通过标签图细化模块和鲁棒的训练策略进行改进，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 胸部X射线的多标签分类面临挑战，包括极端的类别不平衡、不对称的错误成本以及需要稳健的交叉验证分割来保留标签共现性。现有方法可能无法充分解决这些问题，导致分类器性能受限。

Method: 核心方法包括：使用SE-ResNeXt101作为骨干网络，通过多标签迭代分层（MIS）进行交叉验证分割；采用非对称损失、混合精度训练、余弦学习率衰减、梯度裁剪和权重指数移动平均来优化训练过程；提出了一种轻量级的标签图细化（Label-Graph Refinement）模块，通过学习稀疏可训练的标签间耦合矩阵，以单次消息传递的方式细化预测的logits。推理时结合水平翻转测试时增强（TTA）和MIS折叠间的预测平均（深度集成）。评估指标为宏观AUC。

Result: 强大的SE-ResNeXt101基线模型在测试中达到了92.64%的宏观AUC。添加标签图细化模块后，在所有折叠中一致地提升了验证宏观AUC，且计算开销可忽略不计。该方法可复现、对硬件友好，且无需额外标注。

Conclusion: 所提出的方法通过结合强大的基线模型、鲁棒的训练策略和新颖的标签图细化模块，为构建更强大的多标签胸部X射线分类器提供了一条实用且高效的途径。

Abstract: We study multilabel classification of chest X-rays and present a simple, strong pipeline built on SE-ResNeXt101 $(32 \times 4d)$. The backbone is finetuned for 14 thoracic findings with a sigmoid head, trained using Multilabel Iterative Stratification (MIS) for robust cross-validation splits that preserve label co-occurrence. To address extreme class imbalance and asymmetric error costs, we optimize with Asymmetric Loss, employ mixed-precision (AMP), cosine learning-rate decay with warm-up, gradient clipping, and an exponential moving average (EMA) of weights. We propose a lightweight Label-Graph Refinement module placed after the classifier: given per-label probabilities, it learns a sparse, trainable inter-label coupling matrix that refines logits via a single message-passing step while adding only an L1-regularized parameter head. At inference, we apply horizontal flip test-time augmentation (TTA) and average predictions across MIS folds (a compact deep ensemble). Evaluation uses macro AUC averaging classwise ROC-AUC and skipping single-class labels in a fold to reflect balanced performance across conditions. On our dataset, a strong SE-ResNeXt101 baseline attains competitive macro AUC (e.g., 92.64% in our runs). Adding the Label-Graph Refinement consistently improves validation macro AUC across folds with negligible compute. The resulting method is reproducible, hardware-friendly, and requires no extra annotations, offering a practical route to stronger multilabel CXR classifiers.

</details>


### [89] [Revisiting MLLM Based Image Quality Assessment: Errors and Remedy](https://arxiv.org/abs/2511.07812)
*Zhenchen Tang,Songlin Yang,Bo Peng,Zichuan Wang,Jing Dong*

Main category: cs.CV

TL;DR: 多模态大语言模型（MLLMs）在图像质量评估（IQA）中存在离散令牌输出与连续质量分数不匹配的问题。本文提出Q-Scorer框架，通过轻量级回归模块和IQA专用分数令牌解决此问题，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: MLLMs推动了IQA任务的发展，但其离散令牌输出与IQA所需的连续质量分数之间存在固有的不匹配。以往将离散预测转换为连续分数的方法常有转换误差，且“等级令牌”（如“好”）引入的语义混淆进一步限制了MLLMs在IQA任务上的表现并降低了其原始能力。

Method: 本文首先对现有方法的误差进行了理论分析。在此基础上，提出了一种名为Q-Scorer的简洁有效框架，该框架将一个轻量级回归模块和IQA专用分数令牌整合到MLLM管道中。

Result: 实验证明，Q-Scorer在多个IQA基准上取得了最先进的性能，对混合数据集具有良好的泛化能力，并且与其他方法结合时性能进一步提升。

Conclusion: Q-Scorer框架成功解决了MLLMs在IQA中离散-连续不匹配和语义混淆的问题，显著提升了图像质量评估的准确性和泛化能力。

Abstract: The rapid progress of multi-modal large language models (MLLMs) has boosted the task of image quality assessment (IQA). However, a key challenge arises from the inherent mismatch between the discrete token outputs of MLLMs and the continuous nature of quality scores required by IQA tasks. This discrepancy significantly hinders the performance of MLLM-based IQA methods. Previous approaches that convert discrete token predictions into continuous scores often suffer from conversion errors. Moreover, the semantic confusion introduced by level tokens (e.g., ``good'') further constrains the performance of MLLMs on IQA tasks and degrades their original capabilities for related tasks. To tackle these problems, we provide a theoretical analysis of the errors inherent in previous approaches and, motivated by this analysis, propose a simple yet effective framework, Q-Scorer. This framework incorporates a lightweight regression module and IQA-specific score tokens into the MLLM pipeline. Extensive experiments demonstrate that Q-Scorer achieves state-of-the-art performance across multiple IQA benchmarks, generalizes well to mixed datasets, and further improves when combined with other methods.

</details>


### [90] [DI3CL: Contrastive Learning With Dynamic Instances and Contour Consistency for SAR Land-Cover Classification Foundation Model](https://arxiv.org/abs/2511.07808)
*Zhongle Ren,Hui Ding,Kai Wang,Biao Hou,Xingyu Luo,Weibin Li,Licheng Jiao*

Main category: cs.CV

TL;DR: 本文提出一个用于SAR地物分类的通用基础模型DI3CL，通过动态实例和轮廓一致性对比学习进行预训练，并在大型SARSense数据集上进行训练，在多项下游任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的SAR地物分类方法主要依赖监督学习和大量标注数据，这限制了它们的可扩展性、泛化能力和对多样化应用场景的适应性。

Method: 开发了一个SAR地物分类的通用基础模型，并提出了动态实例与轮廓一致性对比学习（DI3CL）预训练框架。DI模块通过强制同一区域不同视图的局部一致性来增强全局上下文感知；CC模块利用浅层特征图引导模型关注SAR地物对象的几何轮廓，以提高结构辨别能力。此外，构建了一个包含460,532张SAR图像的大规模多样化数据集SARSense用于预训练，以增强模型的鲁棒性和泛化能力。

Result: 在SAR地物测绘、水体检测和道路提取等多种SAR地物分类任务中进行了广泛实验，结果一致表明所提出的DI3CL模型优于现有方法。

Conclusion: 所开发的DI3CL基础模型，通过创新的对比学习框架和大规模预训练数据集，为SAR地物分类提供了一个强大的基石，显著提升了模型的泛化能力和性能，加速了下游模型的开发和部署。

Abstract: Although significant advances have been achieved in SAR land-cover classification, recent methods remain predominantly focused on supervised learning, which relies heavily on extensive labeled datasets. This dependency not only limits scalability and generalization but also restricts adaptability to diverse application scenarios. In this paper, a general-purpose foundation model for SAR land-cover classification is developed, serving as a robust cornerstone to accelerate the development and deployment of various downstream models. Specifically, a Dynamic Instance and Contour Consistency Contrastive Learning (DI3CL) pre-training framework is presented, which incorporates a Dynamic Instance (DI) module and a Contour Consistency (CC) module. DI module enhances global contextual awareness by enforcing local consistency across different views of the same region. CC module leverages shallow feature maps to guide the model to focus on the geometric contours of SAR land-cover objects, thereby improving structural discrimination. Additionally, to enhance robustness and generalization during pre-training, a large-scale and diverse dataset named SARSense, comprising 460,532 SAR images, is constructed to enable the model to capture comprehensive and representative features. To evaluate the generalization capability of our foundation model, we conducted extensive experiments across a variety of SAR land-cover classification tasks, including SAR land-cover mapping, water body detection, and road extraction. The results consistently demonstrate that the proposed DI3CL outperforms existing methods. Our code and pre-trained weights are publicly available at: https://github.com/SARpre-train/DI3CL.

</details>


### [91] [PC-Diffusion: Aligning Diffusion Models with Human Preferences via Preference Classifier](https://arxiv.org/abs/2511.07806)
*Shaomeng Wang,He Wang,Xiaolu Wei,Longquan Dai,Jinhui Tang*

Main category: cs.CV

TL;DR: 本文提出PC-Diffusion，一种轻量级、可训练的偏好分类器框架，用于将扩散模型与人类偏好对齐，解决了传统DPO方法计算成本高和对参考模型敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在条件图像生成方面取得了显著成功，但其输出常与人类偏好不符。现有DPO（直接偏好优化）类方法虽能改进，但存在两大局限：1) 计算成本高昂，因需微调整个模型；2) 对参考模型质量敏感，易引入不稳定性和偏差。

Method: 本文提出PC-Diffusion框架，通过一个轻量级、可训练的偏好分类器直接建模样本间的相对偏好。该方法将偏好学习与生成模型解耦，无需微调整个模型，也摆脱了对参考模型的依赖。PC-Diffusion还提供了理论保证：确保偏好引导的分布在不同时间步长间一致传播；其偏好分类器的训练目标等价于DPO但无需参考模型；提出的偏好引导校正能逐步引导生成过程趋向偏好对齐区域。

Result: 实验结果表明，PC-Diffusion在偏好一致性方面与DPO相当，同时显著降低了训练成本，并实现了高效、稳定的偏好引导生成。

Conclusion: PC-Diffusion通过引入轻量级偏好分类器，成功克服了DPO在扩散模型偏好对齐中的局限性，实现了计算效率高、稳定性强的偏好引导生成，为解决人类偏好对齐问题提供了有效的新途径。

Abstract: Diffusion models have achieved remarkable success in conditional image generation, yet their outputs often remain misaligned with human preferences. To address this, recent work has applied Direct Preference Optimization (DPO) to diffusion models, yielding significant improvements.~However, DPO-like methods exhibit two key limitations: 1) High computational cost,due to the entire model fine-tuning; 2) Sensitivity to reference model quality}, due to its tendency to introduce instability and bias. To overcome these limitations, we propose a novel framework for human preference alignment in diffusion models (PC-Diffusion), using a lightweight, trainable Preference Classifier that directly models the relative preference between samples. By restricting preference learning to this classifier, PC-Diffusion decouples preference alignment from the generative model, eliminating the need for entire model fine-tuning and reference model reliance.~We further provide theoretical guarantees for PC-Diffusion:1) PC-Diffusion ensures that the preference-guided distributions are consistently propagated across timesteps. 2)The training objective of the preference classifier is equivalent to DPO, but does not require a reference model.3) The proposed preference-guided correction can progressively steer generation toward preference-aligned regions.~Empirical results show that PC-Diffusion achieves comparable preference consistency to DPO while significantly reducing training costs and enabling efficient and stable preference-guided generation.

</details>


### [92] [Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views](https://arxiv.org/abs/2511.07813)
*Haida Feng,Hao Wei,Zewen Xu,Haolin Wang,Chade Li,Yihong Wu*

Main category: cs.CV

TL;DR: 本文提出Sparse3DPR，一个新颖的免训练框架，利用预训练大型语言模型的推理能力和稀疏视角RGB输入，实现开放式三维场景理解，显著提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 尽管免训练的大型语言模型（LLMs）在三维场景理解中展现出灵活性和泛化性，但它们在实际部署中通常面临准确性和效率不足的问题。

Method: Sparse3DPR框架采用：1) 一个支持开放词汇的层次化平面增强场景图，利用主导平面结构作为空间锚点，以实现更清晰的推理链和可靠的高级推断。2) 一种任务自适应子图提取方法，动态过滤与查询无关的信息，减少上下文噪声，提高三维场景推理的效率和准确性。该方法仅需稀疏视角的RGB输入。

Result: 与ConceptGraphs相比，Sparse3DPR在Space3D-Bench上实现了28.7%的EM@1提升和78.2%的速度提升。在ScanQA上，其性能与基于训练的方法相当，并通过真实世界实验证实了其鲁棒性和泛化能力。

Conclusion: Sparse3DPR是一个优越的免训练框架，用于开放式三维场景理解，它通过创新的场景图和信息过滤机制，显著提高了准确性、效率、鲁棒性和泛化能力。

Abstract: Recently, large language models (LLMs) have been explored widely for 3D scene understanding. Among them, training-free approaches are gaining attention for their flexibility and generalization over training-based methods. However, they typically struggle with accuracy and efficiency in practical deployment. To address the problems, we propose Sparse3DPR, a novel training-free framework for open-ended scene understanding, which leverages the reasoning capabilities of pre-trained LLMs and requires only sparse-view RGB inputs. Specifically, we introduce a hierarchical plane-enhanced scene graph that supports open vocabulary and adopts dominant planar structures as spatial anchors, which enables clearer reasoning chains and more reliable high-level inferences. Furthermore, we design a task-adaptive subgraph extraction method to filter query-irrelevant information dynamically, reducing contextual noise and improving 3D scene reasoning efficiency and accuracy. Experimental results demonstrate the superiority of Sparse3DPR, which achieves a 28.7% EM@1 improvement and a 78.2% speedup compared with ConceptGraphs on the Space3D-Bench. Moreover, Sparse3DPR obtains comparable performance to training-based methods on ScanQA, with additional real-world experiments confirming its robustness and generalization capability.

</details>


### [93] [Human Motion Synthesis in 3D Scenes via Unified Scene Semantic Occupancy](https://arxiv.org/abs/2511.07819)
*Gong Jingyu,Tong Kunkun,Chen Zhuoran,Yuan Chuanhan,Chen Mingang,Zhang Zhizhong,Tan Xin,Xie Yuan*

Main category: cs.CV

TL;DR: 本文提出SSOMotion框架，通过统一的场景语义占用（SSO）表示和双向三平面分解，实现3D场景中细粒度语义理解下的人体运动合成，显著提升性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景中的人体运动合成方法主要关注场景结构，但忽略了对场景的语义理解，导致在复杂的场景中表现不足。

Method: 本文提出了SSOMotion框架，采用统一的场景语义占用（SSO）作为场景表示。通过双向三平面分解技术，得到紧凑的SSO版本。场景语义通过CLIP编码和共享线性降维映射到统一特征空间，从而实现细粒度语义结构的同时减少冗余计算。此外，利用场景提示和指令衍生的运动方向，通过逐帧场景查询进行运动控制。

Result: 在ShapeNet家具的杂乱场景以及PROX和Replica数据集的扫描场景上进行的广泛实验和消融研究表明，SSOMotion达到了最先进的性能，并验证了其有效性和泛化能力。

Conclusion: SSOMotion框架通过引入统一的场景语义占用表示和高效的语义处理策略，成功解决了现有方法在3D人体运动合成中缺乏语义理解的问题，展现出卓越的性能和广泛的适用性。

Abstract: Human motion synthesis in 3D scenes relies heavily on scene comprehension, while current methods focus mainly on scene structure but ignore the semantic understanding. In this paper, we propose a human motion synthesis framework that take an unified Scene Semantic Occupancy (SSO) for scene representation, termed SSOMotion. We design a bi-directional tri-plane decomposition to derive a compact version of the SSO, and scene semantics are mapped to an unified feature space via CLIP encoding and shared linear dimensionality reduction. Such strategy can derive the fine-grained scene semantic structures while significantly reduce redundant computations. We further take these scene hints and movement direction derived from instructions for motion control via frame-wise scene query. Extensive experiments and ablation studies conducted on cluttered scenes using ShapeNet furniture, as well as scanned scenes from PROX and Replica datasets, demonstrate its cutting-edge performance while validating its effectiveness and generalization ability. Code will be publicly available at https://github.com/jingyugong/SSOMotion.

</details>


### [94] [Cancer-Net PCa-MultiSeg: Multimodal Enhancement of Prostate Cancer Lesion Segmentation Using Synthetic Correlated Diffusion Imaging](https://arxiv.org/abs/2511.07816)
*Jarett Dewbury,Chi-en Amy Tai,Alexander Wong*

Main category: cs.CV

TL;DR: 该研究表明，合成相关扩散成像（CDI$^s$）可以显著提升前列腺癌病灶分割的深度学习性能，且无需额外扫描时间。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在前列腺癌病灶分割方面表现有限，在大规模患者队列中Dice分数低于0.32，因此需要改进。

Method: 研究引入合成相关扩散成像（CDI$^s$）作为标准扩散协议的增强手段。使用200名患者的CDI$^s$、扩散加权成像（DWI）和表观扩散系数（ADC）序列，对六种最先进的分割架构进行了全面评估。

Result: CDI$^s$的整合在94%的评估配置中可靠地增强或保持了分割性能，单个架构相对于基线模态实现了高达72.5%的统计学显著相对改进。CDI$^s$ + DWI被证明是最安全的增强途径，在一半的评估架构中实现了显著改进，且未出现性能下降的情况。

Conclusion: CDI$^s$可从现有DWI采集数据中生成，无需额外扫描时间或架构修改，因此可立即部署于临床工作流程。研究结果确立了CDI$^s$作为前列腺癌病灶分割任务中实用且易于集成的增强方案，适用于各种深度学习架构。

Abstract: Current deep learning approaches for prostate cancer lesion segmentation achieve limited performance, with Dice scores of 0.32 or lower in large patient cohorts. To address this limitation, we investigate synthetic correlated diffusion imaging (CDI$^s$) as an enhancement to standard diffusion-based protocols. We conduct a comprehensive evaluation across six state-of-the-art segmentation architectures using 200 patients with co-registered CDI$^s$, diffusion-weighted imaging (DWI) and apparent diffusion coefficient (ADC) sequences. We demonstrate that CDI$^s$ integration reliably enhances or preserves segmentation performance in 94% of evaluated configurations, with individual architectures achieving up to 72.5% statistically significant relative improvement over baseline modalities. CDI$^s$ + DWI emerges as the safest enhancement pathway, achieving significant improvements in half of evaluated architectures with zero instances of degradation. Since CDI$^s$ derives from existing DWI acquisitions without requiring additional scan time or architectural modifications, it enables immediate deployment in clinical workflows. Our results establish validated integration pathways for CDI$^s$ as a practical drop-in enhancement for PCa lesion segmentation tasks across diverse deep learning architectures.

</details>


### [95] [CloudMamba: Grouped Selective State Spaces for Point Cloud Analysis](https://arxiv.org/abs/2511.07823)
*Kanglin Qu,Pan Gao,Qun Dai,Zhanzhi Ye,Rui Ye,Yuanhao Sun*

Main category: cs.CV

TL;DR: 本文提出CloudMamba，一个基于Mamba的点云网络，通过序列扩展与合并、链式Mamba和分组选择性状态空间模型（GS6）来解决点云序列化、几何感知不足和S6模型过拟合的问题，在点云任务上实现了SOTA性能和更低复杂度。


<details>
  <summary>Details</summary>
Motivation: Mamba在点云分析中受到关注，但现有方法存在点云序列化不完善、高层几何感知不足以及Mamba核心S6模型过拟合的问题。

Method: 本文提出了CloudMamba网络：1) 序列扩展与合并：沿各轴单独序列化点，然后融合不同序列中因果推断的高阶特征，使无序点集更稳定地适应Mamba的因果性。2) 链式Mamba：将并行双向Mamba中的前向和后向过程链接起来，以捕获扫描过程中的高层几何信息。3) 分组选择性状态空间模型（GS6）：通过在S6上进行参数共享，缓解了S6计算模式导致的过拟合问题。

Result: CloudMamba在各种点云任务上验证了其能力，实现了最先进的结果，同时显著降低了复杂度。

Conclusion: CloudMamba成功解决了现有Mamba在点云分析中面临的挑战，通过创新的序列处理、几何信息捕获和模型优化策略，提供了高性能和高效率的点云处理方案。

Abstract: Due to the long-range modeling ability and linear complexity property, Mamba has attracted considerable attention in point cloud analysis. Despite some interesting progress, related work still suffers from imperfect point cloud serialization, insufficient high-level geometric perception, and overfitting of the selective state space model (S6) at the core of Mamba. To this end, we resort to an SSM-based point cloud network termed CloudMamba to address the above challenges. Specifically, we propose sequence expanding and sequence merging, where the former serializes points along each axis separately and the latter serves to fuse the corresponding higher-order features causally inferred from different sequences, enabling unordered point sets to adapt more stably to the causal nature of Mamba without parameters. Meanwhile, we design chainedMamba that chains the forward and backward processes in the parallel bidirectional Mamba, capturing high-level geometric information during scanning. In addition, we propose a grouped selective state space model (GS6) via parameter sharing on S6, alleviating the overfitting problem caused by the computational mode in S6. Experiments on various point cloud tasks validate CloudMamba's ability to achieve state-of-the-art results with significantly less complexity.

</details>


### [96] [MonoCLUE : Object-Aware Clustering Enhances Monocular 3D Object Detection](https://arxiv.org/abs/2511.07862)
*Sunghun Yang,Minhyeok Lee,Jungho Lee,Sangyoun Lee*

Main category: cs.CV

TL;DR: MonoCLUE通过结合局部视觉特征聚类和广义场景记忆，增强了单目3D目标检测能力，有效解决了遮挡和有限视野下的检测难题，并在KITTI基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测虽然成本效益高，但受限于深度信息不完整和视野有限，导致几何线索不足，在遮挡或截断场景中精度下降。现有方法侧重于深度信息，却忽略了对鲁棒识别至关重要的视觉线索。

Method: 本文提出了MonoCLUE，主要方法包括：1) 对视觉特征进行K-means聚类，以捕获独特的对象级外观部分（如引擎盖、车顶），并跨区域传播这些特征以检测部分可见或外观相似的对象。2) 通过聚合跨图像的聚类特征来构建广义场景记忆，提供跨场景一致的表示。3) 将局部聚类特征和广义场景记忆整合到对象查询中，引导注意力关注信息丰富的区域。

Result: MonoCLUE在KITTI基准测试中实现了最先进的性能，在遮挡和有限可见度条件下实现了鲁棒的单目3D检测。

Conclusion: MonoCLUE通过统一的局部聚类和广义场景记忆策略，显著增强了单目3D检测的鲁棒性，尤其是在处理遮挡和有限可见度等挑战性场景时表现出色。

Abstract: Monocular 3D object detection offers a cost-effective solution for autonomous driving but suffers from ill-posed depth and limited field of view. These constraints cause a lack of geometric cues and reduced accuracy in occluded or truncated scenes. While recent approaches incorporate additional depth information to address geometric ambiguity, they overlook the visual cues crucial for robust recognition. We propose MonoCLUE, which enhances monocular 3D detection by leveraging both local clustering and generalized scene memory of visual features. First, we perform K-means clustering on visual features to capture distinct object-level appearance parts (e.g., bonnet, car roof), improving detection of partially visible objects. The clustered features are propagated across regions to capture objects with similar appearances. Second, we construct a generalized scene memory by aggregating clustered features across images, providing consistent representations that generalize across scenes. This improves object-level feature consistency, enabling stable detection across varying environments. Lastly, we integrate both local cluster features and generalized scene memory into object queries, guiding attention toward informative regions. Exploiting a unified local clustering and generalized scene memory strategy, MonoCLUE enables robust monocular 3D detection under occlusion and limited visibility, achieving state-of-the-art performance on the KITTI benchmark.

</details>


### [97] [Visual Bridge: Universal Visual Perception Representations Generating](https://arxiv.org/abs/2511.07877)
*Yilin Gao,Shuguang Dou,Junzhou Li,Zhiheng Yu,Yin Li,Dongsheng Jiang,Shugong Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于流匹配的通用视觉感知框架，能够处理多种异构视觉任务，克服了传统扩散模型“单任务-单模型”的局限性，实现了高效灵活的表示迁移。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在文本到图像生成、深度估计等单一计算机视觉任务中表现出色，但受限于“单任务-单模型”范式，在多任务场景下泛化性和可扩展性受限。受大型语言模型跨领域泛化能力的启发，研究旨在开发一个能生成多样化视觉表示的通用框架。

Method: 该方法将多任务过程统一为一个从图像块 token 到任务特定表示的通用流匹配问题。它利用一个强大的自监督基础模型作为锚点，并引入多尺度循环任务嵌入机制，学习一个通用的速度场来弥合异构任务之间的差距，从而支持高效灵活的表示迁移。

Result: 在分类、检测、分割、深度估计和图像-文本检索等任务上进行了广泛实验，结果表明该模型在零样本和微调设置下均取得了有竞争力的性能，超越了先前的通用模型和一些专业模型。消融研究进一步验证了该框架的鲁棒性、可扩展性和泛化能力。

Conclusion: 这项工作标志着通用视觉感知方面迈出了重要一步，为未来通用视觉建模研究奠定了坚实基础。

Abstract: Recent advances in diffusion models have achieved remarkable success in isolated computer vision tasks such as text-to-image generation, depth estimation, and optical flow. However, these models are often restricted by a ``single-task-single-model'' paradigm, severely limiting their generalizability and scalability in multi-task scenarios. Motivated by the cross-domain generalization ability of large language models, we propose a universal visual perception framework based on flow matching that can generate diverse visual representations across multiple tasks. Our approach formulates the process as a universal flow-matching problem from image patch tokens to task-specific representations rather than an independent generation or regression problem. By leveraging a strong self-supervised foundation model as the anchor and introducing a multi-scale, circular task embedding mechanism, our method learns a universal velocity field to bridge the gap between heterogeneous tasks, supporting efficient and flexible representation transfer. Extensive experiments on classification, detection, segmentation, depth estimation, and image-text retrieval demonstrate that our model achieves competitive performance in both zero-shot and fine-tuned settings, outperforming prior generalist and several specialist models. Ablation studies further validate the robustness, scalability, and generalization of our framework. Our work marks a significant step towards general-purpose visual perception, providing a solid foundation for future research in universal vision modeling.

</details>


### [98] [Generating Sketches in a Hierarchical Auto-Regressive Process for Flexible Sketch Drawing Manipulation at Stroke-Level](https://arxiv.org/abs/2511.07889)
*Sicong Zang,Shuhui Gao,Zhijun Fang*

Main category: cs.CV

TL;DR: 本文提出了一种分层自回归草图生成方法，允许在生成过程中随时对笔画进行灵活控制和操作。


<details>
  <summary>Details</summary>
Motivation: 现有草图生成方法需要预先提供所有笔画条件，无法在生成过程中进行实时操作。研究人员旨在实现更灵活的、可控的草图绘制操纵。

Method: 提出了一种分层自回归的草图生成过程。每个笔画的生成分为三个阶段：1) 预测笔画嵌入，2) 将笔画锚定在画布上，3) 将嵌入转换为一系列绘制动作。这个过程是自回归的，即当前笔画的预测、锚定和转换会考虑之前生成的笔画及其位置。

Result: 该方法通过调整暴露的可编辑笔画嵌入，实现了在生成过程中随时对笔画级别的草图绘制进行灵活操作。

Conclusion: 通过引入分层自回归模型，实现了在草图生成过程中对笔画的灵活、实时控制，克服了传统方法无法在生成过程中进行操作的局限性。

Abstract: Generating sketches with specific patterns as expected, i.e., manipulating sketches in a controllable way, is a popular task. Recent studies control sketch features at stroke-level by editing values of stroke embeddings as conditions. However, in order to provide generator a global view about what a sketch is going to be drawn, all these edited conditions should be collected and fed into generator simultaneously before generation starts, i.e., no further manipulation is allowed during sketch generating process. In order to realize sketch drawing manipulation more flexibly, we propose a hierarchical auto-regressive sketch generating process. Instead of generating an entire sketch at once, each stroke in a sketch is generated in a three-staged hierarchy: 1) predicting a stroke embedding to represent which stroke is going to be drawn, and 2) anchoring the predicted stroke on the canvas, and 3) translating the embedding to a sequence of drawing actions to form the full sketch. Moreover, the stroke prediction, anchoring and translation are proceeded auto-regressively, i.e., both the recently generated strokes and their positions are considered to predict the current one, guiding model to produce an appropriate stroke at a suitable position to benefit the full sketch generation. It is flexible to manipulate stroke-level sketch drawing at any time during generation by adjusting the exposed editable stroke embeddings.

</details>


### [99] [Theoretical Analysis of Power-law Transformation on Images for Text Polarity Detection](https://arxiv.org/abs/2511.07916)
*Narendra Singh Yadav,Pavan Kumar Perepu*

Main category: cs.CV

TL;DR: 本文对图像文本极性检测中基于幂律变换和直方图统计的现象进行了理论分析。


<details>
  <summary>Details</summary>
Motivation: 文本极性检测和二值化是车辆牌照识别、验证码识别、字符识别等计算机视觉应用的重要预处理任务。图像二值化需要文本极性信息（文本相对于背景是暗是亮）。

Method: 本文对文献中基于原始图像幂律变换后，通过直方图统计观察到的现象进行理论分析。该现象指出，在文本和背景被视为两类时，最大类间方差对于暗文本在亮背景上会增加，对于亮文本在暗背景上会减少。

Result: 本文提供了对上述现象的理论分析，即在幂律变换后，直方图统计中最大类间方差随文本极性（暗文本/亮文本）而增加或减少的现象。

Conclusion: 通过理论分析，本文加深了对基于幂律变换和直方图统计的文本极性检测方法的理解。

Abstract: Several computer vision applications like vehicle license plate recognition, captcha recognition, printed or handwriting character recognition from images etc., text polarity detection and binarization are the important preprocessing tasks. To analyze any image, it has to be converted to a simple binary image. This binarization process requires the knowledge of polarity of text in the images. Text polarity is defined as the contrast of text with respect to background. That means, text is darker than the background (dark text on bright background) or vice-versa. The binarization process uses this polarity information to convert the original colour or gray scale image into a binary image. In the literature, there is an intuitive approach based on power-law transformation on the original images. In this approach, the authors have illustrated an interesting phenomenon from the histogram statistics of the transformed images. Considering text and background as two classes, they have observed that maximum between-class variance between two classes is increasing (decreasing) for dark (bright) text on bright (dark) background. The corresponding empirical results have been presented. In this paper, we present a theoretical analysis of the above phenomenon.

</details>


### [100] [Exploring the Underwater World Segmentation without Extra Training](https://arxiv.org/abs/2511.07923)
*Bingyu Li,Tao Huo,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li*

Main category: cs.CV

TL;DR: 该论文推出了AquaOV255，一个大规模、细粒度的水下分割数据集，以及UOVSBench，第一个水下开放词汇分割基准。同时提出了Earth2Ocean，一个无需训练的开放词汇分割框架，用于将陆地视觉-语言模型迁移到水下领域，显著提升了水下分割性能。


<details>
  <summary>Details</summary>
Motivation: 海洋生物的精确分割对于生物多样性监测和生态评估至关重要，但现有数据集和模型主要局限于陆地场景。研究旨在弥补这一空白，提供大规模、细粒度的水下分割资源和有效的模型。

Method: 论文引入了：1) 
AquaOV255，首个包含255个类别和超过2万张图像的大规模、细粒度水下分割数据集，用于开放词汇（OV）评估。2) 
UOVSBench，通过整合AquaOV255与另外五个水下数据集，建立了首个水下开放词汇分割基准。3) 
Earth2Ocean，一个无需训练的开放词汇分割框架，能将陆地视觉-语言模型（VLMs）直接迁移到水下领域。该框架包含两个核心组件：几何引导视觉掩码生成器（GMG），通过自相似几何先验细化视觉特征；以及类别-视觉语义对齐（CSA）模块，通过多模态大语言模型推理和场景感知模板构建增强文本嵌入。

Result: 在UOVSBench基准上进行的广泛实验表明，Earth2Ocean框架平均实现了显著的性能提升，同时保持了高效的推理速度。

Conclusion: 该研究成功弥合了水下分割领域的空白，提供了大规模数据集、全面的基准以及有效的、无需训练的开放词汇分割框架，显著提升了水下环境下的分割性能。

Abstract: Accurate segmentation of marine organisms is vital for biodiversity monitoring and ecological assessment, yet existing datasets and models remain largely limited to terrestrial scenes. To bridge this gap, we introduce \textbf{AquaOV255}, the first large-scale and fine-grained underwater segmentation dataset containing 255 categories and over 20K images, covering diverse categories for open-vocabulary (OV) evaluation. Furthermore, we establish the first underwater OV segmentation benchmark, \textbf{UOVSBench}, by integrating AquaOV255 with five additional underwater datasets to enable comprehensive evaluation. Alongside, we present \textbf{Earth2Ocean}, a training-free OV segmentation framework that transfers terrestrial vision--language models (VLMs) to underwater domains without any additional underwater training. Earth2Ocean consists of two core components: a Geometric-guided Visual Mask Generator (\textbf{GMG}) that refines visual features via self-similarity geometric priors for local structure perception, and a Category-visual Semantic Alignment (\textbf{CSA}) module that enhances text embeddings through multimodal large language model reasoning and scene-aware template construction. Extensive experiments on the UOVSBench benchmark demonstrate that Earth2Ocean achieves significant performance improvement on average while maintaining efficient inference.

</details>


### [101] [An Image-Based Path Planning Algorithm Using a UAV Equipped with Stereo Vision](https://arxiv.org/abs/2511.07928)
*Selim Ahmet Iz,Mustafa Unel*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的基于图像的路径规划算法，利用计算机视觉和无人机生成的视差图，并与A*和PRM算法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 传统的二维图像路径规划无法区分地形深度（如陨石坑和山丘），这会严重影响计算路径的安全性，因此需要一种能考虑三维地形信息的规划方法。

Method: 该方法利用无人机生成的视差图来定义候选路径点。它应用了多种计算机视觉技术，包括边缘、线条、角点检测以及立体深度重建。初始点和目标点通过ArUco标记姿态估计和圆检测技术自动识别。该算法在V-REP仿真环境和物理实验室环境中与A*和PRM算法进行了比较。

Result: 实验结果表明，所提出的算法是有效的，并展示了其前景。

Conclusion: 所提出的基于图像和视差图的路径规划算法在考虑地形深度方面表现出良好的性能，并且在与现有算法的比较中证明了其有效性。

Abstract: This paper presents a novel image-based path planning algorithm that was developed using computer vision techniques, as well as its comparative analysis with well-known deterministic and probabilistic algorithms, namely A* and Probabilistic Road Map algorithm (PRM). The terrain depth has a significant impact on the calculated path safety. The craters and hills on the surface cannot be distinguished in a two-dimensional image. The proposed method uses a disparity map of the terrain that is generated by using a UAV. Several computer vision techniques, including edge, line and corner detection methods, as well as the stereo depth reconstruction technique, are applied to the captured images and the found disparity map is used to define candidate way-points of the trajectory. The initial and desired points are detected automatically using ArUco marker pose estimation and circle detection techniques. After presenting the mathematical model and vision techniques, the developed algorithm is compared with well-known algorithms on different virtual scenes created in the V-REP simulation program and a physical setup created in a laboratory environment. Results are promising and demonstrate effectiveness of the proposed algorithm.

</details>


### [102] [HD$^2$-SSC: High-Dimension High-Density Semantic Scene Completion for Autonomous Driving](https://arxiv.org/abs/2511.07925)
*Zhiwen Yang,Yuxin Peng*

Main category: cs.CV

TL;DR: 本文提出HD$^2$-SSC框架，通过高维语义解耦和高密度占用细化模块，有效弥补了相机3D语义场景补全中存在的输入-输出维度鸿沟和标注-现实密度鸿沟。


<details>
  <summary>Details</summary>
Motivation: 现有的相机3D语义场景补全（SSC）方法在3D场景表示方面表现出一定效果，但受限于输入图像的2D平面视图与稀疏标注标签、以及真实世界密集占用体素的3D立体视图之间固有的维度鸿沟和密度鸿沟，导致对真实世界密集占用的预测效果不佳。

Method: 本文提出HD$^2$-SSC框架。为弥补维度鸿沟，设计了“高维语义解耦模块”，沿伪第三维度扩展2D图像特征，解耦粗糙像素语义并识别精细语义的焦点区域以丰富图像特征。为缓解密度鸿沟，设计了“高密度占用细化模块”，采用“检测-细化”架构，利用上下文几何和语义结构来增强语义密度，补全缺失体素并纠正错误体素。

Result: 在SemanticKITTI和SSCBench-KITTI-360数据集上进行了广泛的实验和分析，验证了所提出的HD$^2$-SSC框架的有效性。

Conclusion: HD$^2$-SSC框架通过解决维度鸿沟和密度鸿沟问题，显著提升了相机3D语义场景补全的性能，对自动驾驶中的3D场景理解至关重要。

Abstract: Camera-based 3D semantic scene completion (SSC) plays a crucial role in autonomous driving, enabling voxelized 3D scene understanding for effective scene perception and decision-making. Existing SSC methods have shown efficacy in improving 3D scene representations, but suffer from the inherent input-output dimension gap and annotation-reality density gap, where the 2D planner view from input images with sparse annotated labels leads to inferior prediction of real-world dense occupancy with a 3D stereoscopic view. In light of this, we propose the corresponding High-Dimension High-Density Semantic Scene Completion (HD$^2$-SSC) framework with expanded pixel semantics and refined voxel occupancies. To bridge the dimension gap, a High-dimension Semantic Decoupling module is designed to expand 2D image features along a pseudo third dimension, decoupling coarse pixel semantics from occlusions, and then identify focal regions with fine semantics to enrich image features. To mitigate the density gap, a High-density Occupancy Refinement module is devised with a "detect-and-refine" architecture to leverage contextual geometric and semantic structures for enhanced semantic density with the completion of missing voxels and correction of erroneous ones. Extensive experiments and analyses on the SemanticKITTI and SSCBench-KITTI-360 datasets validate the effectiveness of our HD$^2$-SSC framework.

</details>


### [103] [Laytrol: Preserving Pretrained Knowledge in Layout Control for Multimodal Diffusion Transformers](https://arxiv.org/abs/2511.07934)
*Sida Huang,Siqi Huang,Ping Luo,Hongyuan Zhang*

Main category: cs.CV

TL;DR: 为解决文本到图像生成中空间可控性不足及现有布局到图像方法视觉质量和风格不一致问题，本文构建了LaySyn数据集并提出了Laytrol网络。Laytrol继承MM-DiT参数，采用专用初始化方案，并结合对象级RoPE，有效提升了生成图像的质量和风格一致性。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型发展，增强文本到图像生成的空间可控性成为关键挑战。现有布局到图像方法通常通过适配器模块引入布局条件，但生成的图像常表现出低视觉质量和与基础模型风格不一致，这表明预训练知识有所损失。

Method: 1. 构建了Layout Synthesis (LaySyn) 数据集，利用基础模型自身合成的图像来缓解预训练数据分布漂移。2. 提出了Layout Control (Laytrol) 网络，其参数继承自MM-DiT以保留预训练知识。3. 采用了专用的初始化方案：布局编码器初始化为纯文本编码器，确保其输出令牌在MM-DiT数据域内；布局控制网络的输出初始化为零。4. 将对象级旋转位置嵌入（Object-level Rotary Position Embedding）应用于布局令牌，以提供粗略的位置信息。

Result: 定性和定量实验均证明了本文方法的有效性，表明其能够提升生成图像的视觉质量、风格一致性和空间可控性。

Conclusion: 通过构建LaySyn数据集和提出Laytrol网络（包含参数继承、专用初始化方案和对象级旋转位置嵌入），本研究有效解决了布局到图像生成中视觉质量低和风格不一致的问题，成功保留了基础模型的预训练知识，增强了空间可控性。

Abstract: With the development of diffusion models, enhancing spatial controllability in text-to-image generation has become a vital challenge. As a representative task for addressing this challenge, layout-to-image generation aims to generate images that are spatially consistent with the given layout condition. Existing layout-to-image methods typically introduce the layout condition by integrating adapter modules into the base generative model. However, the generated images often exhibit low visual quality and stylistic inconsistency with the base model, indicating a loss of pretrained knowledge. To alleviate this issue, we construct the Layout Synthesis (LaySyn) dataset, which leverages images synthesized by the base model itself to mitigate the distribution shift from the pretraining data. Moreover, we propose the Layout Control (Laytrol) Network, in which parameters are inherited from MM-DiT to preserve the pretrained knowledge of the base model. To effectively activate the copied parameters and avoid disturbance from unstable control conditions, we adopt a dedicated initialization scheme for Laytrol. In this scheme, the layout encoder is initialized as a pure text encoder to ensure that its output tokens remain within the data domain of MM-DiT. Meanwhile, the outputs of the layout control network are initialized to zero. In addition, we apply Object-level Rotary Position Embedding to the layout tokens to provide coarse positional information. Qualitative and quantitative experiments demonstrate the effectiveness of our method.

</details>


### [104] [DiffRegCD: Integrated Registration and Change Detection with Diffusion Features](https://arxiv.org/abs/2511.07935)
*Seyedehnanita Madani,Rama Chellappa,Vishal M. Patel*

Main category: cs.CV

TL;DR: DiffRegCD是一个统一的密集配准和变化检测框架，通过高斯平滑分类进行对应估计并利用扩散模型特征，解决了真实世界图像中的严重错位问题，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 大多数变化检测模型假设输入图像已配准，但实际图像常因视差、视角变化和长时间间隔而严重错位。现有方法（两阶段或联合框架）在处理大位移时效果不佳，依赖于回归流、全局单应性或合成扰动。

Method: DiffRegCD是一个将密集配准和变化检测整合到单一模型中的框架。它将对应估计重新表述为高斯平滑分类任务，以实现亚像素精度和稳定训练。模型利用预训练去噪扩散模型的冻结多尺度特征，确保对光照和视角变化的鲁棒性。通过对标准变化检测数据集应用受控仿射扰动来提供监督，生成流和变化检测的配对真实标签，无需伪标签。

Result: 在航空（LEVIR-CD, DSIFN-CD, WHU-CD, SYSU-CD）和地面（VL-CMU-CD）数据集上进行的广泛实验表明，DiffRegCD持续超越最新的基线模型，并在大时间跨度和几何变化下保持可靠性。

Conclusion: 扩散特征和基于分类的对应关系为统一变化检测奠定了坚实基础，DiffRegCD的性能证明了这一点，并在处理图像错位方面表现出色。

Abstract: Change detection (CD) is fundamental to computer vision and remote sensing, supporting applications in environmental monitoring, disaster response, and urban development. Most CD models assume co-registered inputs, yet real-world imagery often exhibits parallax, viewpoint shifts, and long temporal gaps that cause severe misalignment. Traditional two stage methods that first register and then detect, as well as recent joint frameworks (e.g., BiFA, ChangeRD), still struggle under large displacements, relying on regression only flow, global homographies, or synthetic perturbations. We present DiffRegCD, an integrated framework that unifies dense registration and change detection in a single model. DiffRegCD reformulates correspondence estimation as a Gaussian smoothed classification task, achieving sub-pixel accuracy and stable training. It leverages frozen multi-scale features from a pretrained denoising diffusion model, ensuring robustness to illumination and viewpoint variation. Supervision is provided through controlled affine perturbations applied to standard CD datasets, yielding paired ground truth for both flow and change detection without pseudo labels. Extensive experiments on aerial (LEVIR-CD, DSIFN-CD, WHU-CD, SYSU-CD) and ground level (VL-CMU-CD) datasets show that DiffRegCD consistently surpasses recent baselines and remains reliable under wide temporal and geometric variation, establishing diffusion features and classification based correspondence as a strong foundation for unified change detection.

</details>


### [105] [Federated CLIP for Resource-Efficient Heterogeneous Medical Image Classification](https://arxiv.org/abs/2511.07929)
*Yihang Wu,Ahmad Chaddad*

Main category: cs.CV

TL;DR: 该论文提出了一种名为FedMedCLIP的联邦学习方法，用于解决医疗图像分类中深度模型的数据隐私、数据异构性和资源成本问题，通过引入掩码特征适应模块、冻结CLIP编码器、掩码多层感知机和KL散度蒸馏等技术，实现了在保持高性能的同时显著降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 尽管深度模型在医学影像领域表现出色，但其对源数据训练的依赖受限于隐私问题。联邦学习（FL）提供了一种去中心化的解决方案，但数据异构性和资源成本（尤其是在使用视觉语言模型VLM时）阻碍了FL模型的部署。

Method: 该研究提出了一种基于CLIP的联邦学习方法FedMedCLIP，用于医疗图像分类。具体方法包括：1) 引入掩码特征适应模块（FAM）作为通信模块，以减少通信负载；2) 冻结CLIP编码器以减少计算开销；3) 提出掩码多层感知机（MLP）作为私有局部分类器，以适应客户端任务；4) 设计基于自适应Kullback-Leibler（KL）散度的蒸馏正则化方法，实现FAM和MLP之间的相互学习；5) 整合模型压缩以传输FAM参数，并使用集成预测进行分类。

Result: 在四个公开的医疗数据集上的大量实验表明，FedMedCLIP模型在提供可行性能的同时，具有合理的资源成本。例如，在ISIC2019数据集上比次优基线高8%，并且比FedAVG快120倍。

Conclusion: FedMedCLIP通过其创新的架构（包括掩码特征适应、冻结编码器、掩码MLP和蒸馏），有效地解决了联邦学习在医疗影像领域面临的数据异构性和资源成本挑战，实现了卓越的性能和效率。

Abstract: Despite the remarkable performance of deep models in medical imaging, they still require source data for training, which limits their potential in light of privacy concerns. Federated learning (FL), as a decentralized learning framework that trains a shared model with multiple hospitals (a.k.a., FL clients), provides a feasible solution. However, data heterogeneity and resource costs hinder the deployment of FL models, especially when using vision language models (VLM). To address these challenges, we propose a novel contrastive language-image pre-training (CLIP) based FL approach for medical image classification (FedMedCLIP). Specifically, we introduce a masked feature adaptation module (FAM) as a communication module to reduce the communication load while freezing the CLIP encoders to reduce the computational overhead. Furthermore, we propose a masked multi-layer perceptron (MLP) as a private local classifier to adapt to the client tasks. Moreover, we design an adaptive Kullback-Leibler (KL) divergence-based distillation regularization method to enable mutual learning between FAM and MLP. Finally, we incorporate model compression to transmit the FAM parameters while using ensemble predictions for classification. Extensive experiments on four publicly available medical datasets demonstrate that our model provides feasible performance (e.g., 8\% higher compared to second best baseline on ISIC2019) with reasonable resource cost (e.g., 120$\times$ faster than FedAVG).

</details>


### [106] [Libra-MIL: Multimodal Prototypes Stereoscopic Infused with Task-specific Language Priors for Few-shot Whole Slide Image Classification](https://arxiv.org/abs/2511.07941)
*Zhenfeng Zhuang,Fangyu Zhou,Liansheng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种多模态原型多实例学习（MPMIL）方法，通过构建任务特异性病理实体原型并促进视觉与语言之间的双向交互，解决了计算病理学中全玻片图像（WSI）高成本和标签稀疏的问题，从而提高了模型的泛化能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中，大型语言模型（LLMs）潜力巨大，但千兆像素的全玻片图像（WSIs）计算成本高昂，需要多实例学习（MIL）。现有挑战包括：病理任务通常只有包级标签；LLMs生成的实例级描述因缺乏细粒度医学知识而存在偏差；现有视觉-语言MIL方法多采用单向指导，限制了跨模态协同作用。

Method: 本文提出多模态原型多实例学习（MPMIL）方法。关键在于构建任务特异性病理实体原型：利用冻结的LLM生成病理实体描述作为文本原型；视觉分支学习实例级原型以减少模型对冗余数据的依赖。通过平衡信息压缩方案促进双向交互。融合阶段采用基于相似性度量的立体最优传输（SOT）算法，以实现更高维空间中更广泛的语义对齐。

Result: 在三个不同的癌症数据集上进行了小样本分类和可解释性实验，结果表明所提出的方法具有卓越的泛化能力。

Conclusion: 所提出的多模态原型多实例学习方法有效解决了计算病理学中结合LLMs和MIL的挑战，显著提升了模型的泛化性能和可解释性。

Abstract: While Large Language Models (LLMs) are emerging as a promising direction in computational pathology, the substantial computational cost of giga-pixel Whole Slide Images (WSIs) necessitates the use of Multi-Instance Learning (MIL) to enable effective modeling. A key challenge is that pathological tasks typically provide only bag-level labels, while instance-level descriptions generated by LLMs often suffer from bias due to a lack of fine-grained medical knowledge. To address this, we propose that constructing task-specific pathological entity prototypes is crucial for learning generalizable features and enhancing model interpretability. Furthermore, existing vision-language MIL methods often employ unidirectional guidance, limiting cross-modal synergy. In this paper, we introduce a novel approach, Multimodal Prototype-based Multi-Instance Learning, that promotes bidirectional interaction through a balanced information compression scheme. Specifically, we leverage a frozen LLM to generate task-specific pathological entity descriptions, which are learned as text prototypes. Concurrently, the vision branch learns instance-level prototypes to mitigate the model's reliance on redundant data. For the fusion stage, we employ the Stereoscopic Optimal Transport (SOT) algorithm, which is based on a similarity metric, thereby facilitating broader semantic alignment in a higher-dimensional space. We conduct few-shot classification and explainability experiments on three distinct cancer datasets, and the results demonstrate the superior generalization capabilities of our proposed method.

</details>


### [107] [Is It Truly Necessary to Process and Fit Minutes-Long Reference Videos for Personalized Talking Face Generation?](https://arxiv.org/abs/2511.07940)
*Rui-Qing Sun,Ang Li,Zhijing Wu,Tian Lan,Qianyu Lu,Xingshan Yao,Chen Xu,Xian-Ling Mao*

Main category: cs.CV

TL;DR: 本文提出ISExplore，一种选择信息丰富的短视频片段的策略，用于基于NeRF/3DGS的说话人脸生成，显著提高了数据处理和训练速度（超过5倍），同时保持了高质量输出，证明了视频信息质量比长度更重要。


<details>
  <summary>Details</summary>
Motivation: 当前基于NeRF或3DGS的说话人脸生成方法需要数分钟的参考视频进行细致处理和拟合，耗时数小时，严重限制了其实际应用价值。作者通过探索性案例研究发现，几秒钟的信息丰富视频片段可能达到与完整视频相当甚至更好的性能。

Method: 提出ISExplore（信息片段探索），一个简单而有效的片段选择策略。该策略根据三个关键数据质量维度（音频特征多样性、唇部运动幅度、摄像机视角数量）自动识别出5秒钟的信息丰富参考视频片段。

Result: 实验证明，ISExplore方法将NeRF和3DGS的数据处理和训练速度提高了5倍以上，同时保持了高保真度的输出。

Conclusion: 对于说话人脸生成，视频的信息质量远比其长度重要。通过选择短短5秒钟的信息丰富参考视频片段，可以实现与使用完整参考视频相当甚至更优的性能，并显著加速数据处理和训练过程。

Abstract: Talking Face Generation (TFG) aims to produce realistic and dynamic talking portraits, with broad applications in fields such as digital education, film and television production, e-commerce live streaming, and other related areas. Currently, TFG methods based on Neural Radiated Field (NeRF) or 3D Gaussian sputtering (3DGS) are received widespread attention. They learn and store personalized features from reference videos of each target individual to generate realistic speaking videos. To ensure models can capture sufficient 3D information and successfully learns the lip-audio mapping, previous studies usually require meticulous processing and fitting several minutes of reference video, which always takes hours. The computational burden of processing and fitting long reference videos severely limits the practical application value of these methods.However, is it really necessary to fit such minutes of reference video? Our exploratory case studies show that using some informative reference video segments of just a few seconds can achieve performance comparable to or even better than the full reference video. This indicates that video informative quality is much more important than its length. Inspired by this observation, we propose the ISExplore (short for Informative Segment Explore), a simple-yet-effective segment selection strategy that automatically identifies the informative 5-second reference video segment based on three key data quality dimensions: audio feature diversity, lip movement amplitude, and number of camera views. Extensive experiments demonstrate that our approach increases data processing and training speed by more than 5x for NeRF and 3DGS methods, while maintaining high-fidelity output. Project resources are available at xx.

</details>


### [108] [ReIDMamba: Learning Discriminative Features with Visual State Space Model for Person Re-Identification](https://arxiv.org/abs/2511.07948)
*Hongyang Gu,Qisong Yang,Lei Pu,Siming Han,Yao Ding*

Main category: cs.CV

TL;DR: 本文提出ReIDMamba，一个纯Mamba架构的行人重识别框架，解决了Transformer的扩展性问题，并通过多粒度特征提取和排名感知三元组正则化，以更少的参数和更高的效率在五个基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 行人重识别中提取鲁棒判别性特征是一个关键挑战。卷积神经网络（CNN）存在局部处理和信息丢失的局限性，而基于Transformer的方法虽然克服了CNN的一些缺点，但由于其二次方增长的内存和计算需求，面临可扩展性问题。

Method: 本文提出了一个纯Mamba架构的行人重识别框架ReIDMamba。具体方法包括：1) 设计了一个基于Mamba的强基线，通过引入多个类别令牌有效利用细粒度、判别性的全局特征。2) 设计了多粒度特征提取器（MGFE）模块，采用多分支架构和类别令牌融合，形成多粒度特征，增强判别能力和细粒度覆盖。3) 引入了排名感知三元组正则化（RATR），通过结合类内和类间多样性约束，减少多分支特征冗余，增强多粒度特征的多样性，确保行人特征的鲁棒性。

Result: ReIDMamba模型参数量仅为TransReID的三分之一，同时具有更低的GPU内存使用和更快的推理吞吐量。实验结果表明，ReIDMamba在五个行人重识别基准测试上取得了卓越且有前景的性能，达到了最先进的水平。

Conclusion: ReIDMamba是首次将纯Mamba驱动方法整合到行人重识别研究中的开创性工作。它通过有效利用多粒度特征和多样性正则化，解决了现有方法的局限性，在性能和效率上都展现出显著优势。

Abstract: Extracting robust discriminative features is a critical challenge in person re-identification (ReID). While Transformer-based methods have successfully addressed some limitations of convolutional neural networks (CNNs), such as their local processing nature and information loss resulting from convolution and downsampling operations, they still face the scalability issue due to the quadratic increase in memory and computational requirements with the length of the input sequence. To overcome this, we propose a pure Mamba-based person ReID framework named ReIDMamba. Specifically, we have designed a Mamba-based strong baseline that effectively leverages fine-grained, discriminative global features by introducing multiple class tokens. To further enhance robust features learning within Mamba, we have carefully designed two novel techniques. First, the multi-granularity feature extractor (MGFE) module, designed with a multi-branch architecture and class token fusion, effectively forms multi-granularity features, enhancing both discrimination ability and fine-grained coverage. Second, the ranking-aware triplet regularization (RATR) is introduced to reduce redundancy in features from multiple branches, enhancing the diversity of multi-granularity features by incorporating both intra-class and inter-class diversity constraints, thus ensuring the robustness of person features. To our knowledge, this is the pioneering work that integrates a purely Mamba-driven approach into ReID research. Our proposed ReIDMamba model boasts only one-third the parameters of TransReID, along with lower GPU memory usage and faster inference throughput. Experimental results demonstrate ReIDMamba's superior and promising performance, achieving state-of-the-art performance on five person ReID benchmarks. Code is available at https://github.com/GuHY777/ReIDMamba.

</details>


### [109] [Burst Image Quality Assessment: A New Benchmark and Unified Framework for Multiple Downstream Tasks](https://arxiv.org/abs/2511.07958)
*Xiaoye Liang,Lai Jiang,Minglang Qiao,Yichen Guo,Yue Zhang,Xin Deng,Shengxi Li,Yufan Liu,Mai Xu*

Main category: cs.CV

TL;DR: 本文提出了一种突发图像质量评估（BuIQA）新任务，旨在评估突发序列中每帧图像的质量，为下游任务提供合理的图像选择线索。为此，作者建立了首个BuIQA基准数据集，并提出了一个统一的BuIQA框架，该框架包含一个任务驱动的提示生成网络和一个任务感知的质量评估网络。


<details>
  <summary>Details</summary>
Motivation: 突发成像技术虽然提升了视觉数据的捕获和处理能力，但突发图像中的冗余导致存储和传输需求增加，并降低了下游任务的效率。因此，需要一种方法来评估突发图像序列中每帧的质量，以进行有效选择。

Method: 1. 提出了突发图像质量评估（BuIQA）新任务。2. 建立了首个BuIQA基准数据集，包含7,346个突发序列、45,827张图像和191,572个针对多种下游场景的标注质量分数。3. 提出了一个统一的BuIQA框架，以高效适应不同的下游场景。该框架包括：a) 一个带异构知识蒸馏的任务驱动提示生成网络，用于学习下游任务的先验知识。b) 一个任务感知的质量评估网络，根据任务提示评估突发图像质量。

Result: 1. 在10个下游场景中，所提出的方法展现出卓越的BuIQA性能，超越了现有最先进技术。2. 通过应用该方法选择高质量突发帧，在去噪和超分辨率等下游任务中实现了0.33 dB的PSNR提升。

Conclusion: 本文提出的BuIQA任务、基准数据集和统一框架能够有效评估突发图像序列中每帧的质量，并为下游任务提供高质量图像选择，从而显著提升了下游任务的性能。

Abstract: In recent years, the development of burst imaging technology has improved the capture and processing capabilities of visual data, enabling a wide range of applications. However, the redundancy in burst images leads to the increased storage and transmission demands, as well as reduced efficiency of downstream tasks. To address this, we propose a new task of Burst Image Quality Assessment (BuIQA), to evaluate the task-driven quality of each frame within a burst sequence, providing reasonable cues for burst image selection. Specifically, we establish the first benchmark dataset for BuIQA, consisting of $7,346$ burst sequences with $45,827$ images and $191,572$ annotated quality scores for multiple downstream scenarios. Inspired by the data analysis, a unified BuIQA framework is proposed to achieve an efficient adaption for BuIQA under diverse downstream scenarios. Specifically, a task-driven prompt generation network is developed with heterogeneous knowledge distillation, to learn the priors of the downstream task. Then, the task-aware quality assessment network is introduced to assess the burst image quality based on the task prompt. Extensive experiments across 10 downstream scenarios demonstrate the impressive BuIQA performance of the proposed approach, outperforming the state-of-the-art. Furthermore, it can achieve $0.33$ dB PSNR improvement in the downstream tasks of denoising and super-resolution, by applying our approach to select the high-quality burst frames.

</details>


### [110] [Morphing Through Time: Diffusion-Based Bridging of Temporal Gaps for Robust Alignment in Change Detection](https://arxiv.org/abs/2511.07976)
*Seyedehanita Madani,Vishal M. Patel*

Main category: cs.CV

TL;DR: 针对遥感变化检测中双时相图像的空间错位问题，本文提出了一种名为 RoMa 的模块化管道。它通过扩散语义变形、密集配准和残差流细化，在不改变现有变化检测网络的情况下，显著提高了配准精度和变化检测性能，增强了空间和时间鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现代卷积和基于 Transformer 的变化检测模型在对齐数据上表现良好，但它们对精确配准的依赖限制了其在真实世界条件下的鲁棒性，尤其是在存在长时间季节性或多年间隔导致的空间错位时。现有的联合配准-检测框架通常需要重新训练且跨域迁移性差。

Method: 本文引入了一个模块化管道，名为 RoMa，它在不改变现有变化检测网络的情况下，提高了空间和时间鲁棒性。该框架整合了：1) 基于扩散的语义变形，用于合成中间变形帧以弥合大的外观差异；2) 密集配准，用于估计连续帧之间的逐步对应关系；3) 残差流细化，通过一个轻量级 U-Net 细化合成的流，以生成高保真度的配准结果。

Result: 在 LEVIR-CD、WHU-CD 和 DSIFN-CD 等数据集上进行的广泛实验表明，RoMa 在多种骨干网络上持续提高了配准精度和下游变化检测性能，证明了所提出方法的通用性和有效性。

Conclusion: RoMa 是一种通用且有效的模块化方法，通过改进图像配准，显著增强了遥感变化检测在面对空间错位时的空间和时间鲁棒性，且无需修改现有的变化检测网络。

Abstract: Remote sensing change detection is often challenged by spatial misalignment between bi-temporal images, especially when acquisitions are separated by long seasonal or multi-year gaps. While modern convolutional and transformer-based models perform well on aligned data, their reliance on precise co-registration limits their robustness in real-world conditions. Existing joint registration-detection frameworks typically require retraining and transfer poorly across domains. We introduce a modular pipeline that improves spatial and temporal robustness without altering existing change detection networks. The framework integrates diffusion-based semantic morphing, dense registration, and residual flow refinement. A diffusion module synthesizes intermediate morphing frames that bridge large appearance gaps, enabling RoMa to estimate stepwise correspondences between consecutive frames. The composed flow is then refined through a lightweight U-Net to produce a high-fidelity warp that co-registers the original image pair. Extensive experiments on LEVIR-CD, WHU-CD, and DSIFN-CD show consistent gains in both registration accuracy and downstream change detection across multiple backbones, demonstrating the generality and effectiveness of the proposed approach.

</details>


### [111] [Multi-Modal Assistance for Unsupervised Domain Adaptation on Point Cloud 3D Object Detection](https://arxiv.org/abs/2511.07966)
*Shenao Zhao,Pengpeng Liang,Zhoufan Yang*

Main category: cs.CV

TL;DR: 本文提出MMAssist，通过多模态（图像和文本）辅助改进基于LiDAR的3D目标检测无监督域适应（3D UDA），利用图像和文本特征作为桥梁对3D特征进行对齐和融合，并增强伪标签。


<details>
  <summary>Details</summary>
Motivation: 尽管点云和图像通常同时采集，但在3D UDA模型训练中，图像数据的效用却鲜有研究。现有基于教师-学生架构和伪标签的3D UDA方法虽有改进，但未充分利用多模态信息。

Method: 本文提出了MMAssist方法，通过以下步骤实现多模态辅助：1) 利用图像和文本特征作为桥梁，对源域和目标域的3D特征进行对齐。具体地，将2D边界框的图像特征（来自预训练视觉骨干网络）和文本特征（来自大型视觉-语言模型和文本编码器）提取出来。2) 在源域和目标域学生模型训练中，将预测框的3D特征与对应的图像和文本特征对齐，并融合这些特征进行最终预测。3) 对齐目标域中学生分支和教师分支的特征。4) 通过一个现成的2D目标检测器从图像生成2D边界框，并借助点云估计其对应的3D框，这些3D框与教师模型生成的伪标签结合以增强伪标签。

Result: 实验结果表明，在三个流行的3D目标检测数据集上进行的三个域适应任务中，所提出的方法与最先进的方法相比，取得了有前景的性能。

Conclusion: 通过利用图像和文本等多模态信息辅助3D特征对齐和伪标签增强，本文提出的MMAssist方法能有效提升基于LiDAR的3D目标检测无监督域适应的性能。

Abstract: Unsupervised domain adaptation for LiDAR-based 3D object detection (3D UDA) based on the teacher-student architecture with pseudo labels has achieved notable improvements in recent years. Although it is quite popular to collect point clouds and images simultaneously, little attention has been paid to the usefulness of image data in 3D UDA when training the models. In this paper, we propose an approach named MMAssist that improves the performance of 3D UDA with multi-modal assistance. A method is designed to align 3D features between the source domain and the target domain by using image and text features as bridges. More specifically, we project the ground truth labels or pseudo labels to the images to get a set of 2D bounding boxes. For each 2D box, we extract its image feature from a pre-trained vision backbone. A large vision-language model (LVLM) is adopted to extract the box's text description, and a pre-trained text encoder is used to obtain its text feature. During the training of the model in the source domain and the student model in the target domain, we align the 3D features of the predicted boxes with their corresponding image and text features, and the 3D features and the aligned features are fused with learned weights for the final prediction. The features between the student branch and the teacher branch in the target domain are aligned as well. To enhance the pseudo labels, we use an off-the-shelf 2D object detector to generate 2D bounding boxes from images and estimate their corresponding 3D boxes with the aid of point cloud, and these 3D boxes are combined with the pseudo labels generated by the teacher model. Experimental results show that our approach achieves promising performance compared with state-of-the-art methods in three domain adaptation tasks on three popular 3D object detection datasets. The code is available at https://github.com/liangp/MMAssist.

</details>


### [112] [DANCE: Density-agnostic and Class-aware Network for Point Cloud Completion](https://arxiv.org/abs/2511.07978)
*Da-Yeong Kim,Yeong-Jun Cho*

Main category: cs.CV

TL;DR: DANCE是一种新颖的点云补全框架，它通过射线采样、Transformer解码器和轻量级分类头，实现了密度无关和类别感知的缺失区域补全，同时保留了观测到的几何结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设固定的输入/输出密度或依赖基于图像的表示，这使得它们在面对真实世界中可变稀疏性和有限监督的场景时表现不佳。研究旨在解决这些局限性。

Method: DANCE通过多视角射线采样生成候选点，然后使用Transformer解码器精炼点的位置并预测不透明度分数以确定点的有效性。为融入语义指导，一个轻量级分类头直接在几何特征上训练，实现类别一致的补全，无需外部图像监督。

Result: 在PCN和MVP基准上的大量实验表明，DANCE在准确性和结构一致性方面优于最先进的方法，并且对不同的输入密度和噪声水平保持鲁棒性。

Conclusion: DANCE成功地实现了仅补全缺失区域并保留观测几何结构的目标，在准确性、结构一致性、密度无关性和类别感知能力上表现出色，解决了现有方法的局限性。

Abstract: Point cloud completion aims to recover missing geometric structures from incomplete 3D scans, which often suffer from occlusions or limited sensor viewpoints. Existing methods typically assume fixed input/output densities or rely on image-based representations, making them less suitable for real-world scenarios with variable sparsity and limited supervision. In this paper, we introduce Density-agnostic and Class-aware Network (DANCE), a novel framework that completes only the missing regions while preserving the observed geometry. DANCE generates candidate points via ray-based sampling from multiple viewpoints. A transformer decoder then refines their positions and predicts opacity scores, which determine the validity of each point for inclusion in the final surface. To incorporate semantic guidance, a lightweight classification head is trained directly on geometric features, enabling category-consistent completion without external image supervision. Extensive experiments on the PCN and MVP benchmarks show that DANCE outperforms state-of-the-art methods in accuracy and structural consistency, while remaining robust to varying input densities and noise levels.

</details>


### [113] [CSF-Net: Context-Semantic Fusion Network for Large Mask Inpainting](https://arxiv.org/abs/2511.07987)
*Chae-Yeon Heo,Yeong-Jun Cho*

Main category: cs.CV

TL;DR: 本文提出了一种语义引导框架（CSF-Net），通过利用预训练的无模态补全模型生成结构感知候选作为语义先验，并融合上下文特征，以解决大面积遮罩图像修复中上下文受限和关键内容缺失的挑战，从而提高修复质量和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 大面积遮罩图像修复面临巨大挑战，因为缺失了重要的视觉内容且上下文线索有限，导致难以生成结构准确和语义一致的修复结果。

Method: 该方法利用预训练的无模态补全（AC）模型生成结构感知的候选图像作为缺失区域的语义先验。然后，引入上下文-语义融合网络（CSF-Net），这是一个基于Transformer的融合框架，用于将这些候选与上下文特征融合，生成用于图像修复的语义引导图像。CSF-Net可以无缝集成到现有修复模型中。

Result: CSF-Net通过提升结构准确性和语义一致性来提高修复质量。它在不同遮罩条件下持续增强性能，有效减少了物体幻觉，并增强了视觉真实感和语义对齐。在Places365和COCOA数据集上的实验证明了其有效性。

Conclusion: 所提出的CSF-Net通过结合语义先验和上下文融合，有效解决了大面积遮罩图像修复问题，显著提升了修复图像的结构准确性、语义一致性和视觉真实感。

Abstract: In this paper, we propose a semantic-guided framework to address the challenging problem of large-mask image inpainting, where essential visual content is missing and contextual cues are limited. To compensate for the limited context, we leverage a pretrained Amodal Completion (AC) model to generate structure-aware candidates that serve as semantic priors for the missing regions. We introduce Context-Semantic Fusion Network (CSF-Net), a transformer-based fusion framework that fuses these candidates with contextual features to produce a semantic guidance image for image inpainting. This guidance improves inpainting quality by promoting structural accuracy and semantic consistency. CSF-Net can be seamlessly integrated into existing inpainting models without architectural changes and consistently enhances performance across diverse masking conditions. Extensive experiments on the Places365 and COCOA datasets demonstrate that CSF-Net effectively reduces object hallucination while enhancing visual realism and semantic alignment. The code for CSF-Net is available at https://github.com/chaeyeonheo/CSF-Net.

</details>


### [114] [ChexFract: From General to Specialized - Enhancing Fracture Description Generation](https://arxiv.org/abs/2511.07983)
*Nikolay Nechaev,Evgeniia Przhezdzetskaia,Dmitry Umerenkov,Dmitry V. Dylov*

Main category: cs.CV

TL;DR: 针对胸部X光片中罕见但临床重要的骨折，本研究开发了专门的视觉语言模型，显著提高了骨折描述的准确性，并发布了最佳模型。


<details>
  <summary>Details</summary>
Motivation: 目前的通用视觉语言模型在生成放射报告时，难以充分描述罕见但临床重要的病理，如骨折，导致报告不准确。

Method: 通过使用MAIRA-2和CheXagent的编码器，训练了针对骨折病理检测和描述的专用视觉语言模型。对模型输出进行了骨折类型、位置和年龄的详细分析。

Result: 与通用模型相比，本研究开发的骨折专用模型在生成准确骨折描述方面表现出显著改进。分析揭示了当前视觉语言模型架构在不同骨折情况下的独特优势和局限性。

Conclusion: 本研究成功开发并发布了性能优越的骨折报告模型，有效解决了通用模型在描述罕见病理方面的不足，为未来罕见病理的准确报告研究奠定了基础。

Abstract: Generating accurate and clinically meaningful radiology reports from chest X-ray images remains a significant challenge in medical AI. While recent vision-language models achieve strong results in general radiology report generation, they often fail to adequately describe rare but clinically important pathologies like fractures. This work addresses this gap by developing specialized models for fracture pathology detection and description. We train fracture-specific vision-language models with encoders from MAIRA-2 and CheXagent, demonstrating significant improvements over general-purpose models in generating accurate fracture descriptions. Analysis of model outputs by fracture type, location, and age reveals distinct strengths and limitations of current vision-language model architectures. We publicly release our best-performing fracture-reporting model, facilitating future research in accurate reporting of rare pathologies.

</details>


### [115] [Hardware-Aware YOLO Compression for Low-Power Edge AI on STM32U5 for Weeds Detection in Digital Agriculture](https://arxiv.org/abs/2511.07990)
*Charalampos S. Kouzinopoulos,Yuri Manna*

Main category: cs.CV

TL;DR: 本文提出了一种基于YOLOv8n的低功耗边缘AI系统，通过模型压缩技术部署在STM32U575ZI微控制器上，实现作物田中杂草的实时、低能耗检测。


<details>
  <summary>Details</summary>
Motivation: 传统杂草管理方法依赖化学除草剂，导致环境污染和抗药性杂草出现。精准除草虽有前景，但常受限于对高功耗计算平台的需求。本研究旨在解决这一功耗限制，实现环保、可持续的精准除草。

Method: 研究采用YOLOv8n目标检测器，并对其应用了结构化剪枝、整数量化和输入图像分辨率缩放等多种压缩技术，以满足STM32U575ZI微控制器的严格硬件限制。模型在包含74种植物的CropAndWeed数据集上进行训练和评估。

Result: 该系统在检测精度和效率之间取得了平衡，实现了实时、原位杂草检测，每次推理仅消耗51.8mJ的极低能量。

Conclusion: 该低功耗边缘AI系统能够实现杂草检测在能源受限农业环境中的可扩展部署，为可持续农业提供了环保解决方案。

Abstract: Weeds significantly reduce crop yields worldwide and pose major challenges to sustainable agriculture. Traditional weed management methods, primarily relying on chemical herbicides, risk environmental contamination and lead to the emergence of herbicide-resistant species. Precision weeding, leveraging computer vision and machine learning methods, offers a promising eco-friendly alternative but is often limited by reliance on high-power computational platforms. This work presents an optimized, low-power edge AI system for weeds detection based on the YOLOv8n object detector deployed on the STM32U575ZI microcontroller. Several compression techniques are applied to the detection model, including structured pruning, integer quantization and input image resolution scaling in order to meet strict hardware constraints. The model is trained and evaluated on the CropAndWeed dataset with 74 plant species, achieving a balanced trade-off between detection accuracy and efficiency. Our system supports real-time, in-situ weeds detection with a minimal energy consumption of 51.8mJ per inference, enabling scalable deployment in power-constrained agricultural environments.

</details>


### [116] [Sharp Eyes and Memory for VideoLLMs: Information-Aware Visual Token Pruning for Efficient and Reliable VideoLLM Reasoning](https://arxiv.org/abs/2511.08003)
*Jialong Qin,Xin Zou,Di Lu,Yibo Yan,Xuming Hu*

Main category: cs.CV

TL;DR: SharpV 是一种用于视频大语言模型（VideoLLMs）的简约高效自适应剪枝方法，能动态调整视觉 token 和 KV 缓存的剪枝比例，以解决冗余视觉 token 导致的计算复杂性和缓存扩展问题，并在无需注意力分数的情况下兼容硬件加速，甚至偶尔超越密集模型。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型（VideoLLMs）因处理过多的冗余视觉 token，导致二次方计算复杂度和键值（KV）缓存扩展问题。

Method: SharpV 提出了一种自适应剪枝视觉 token 和 KV 缓存的极简高效方法。它根据时空信息动态调整剪枝比例，而非采用统一压缩。在 KV 缓存剪枝阶段，SharpV 基于视觉信息退化观察，通过自校准方式剪枝退化视觉特征，并以与原始视觉特征的相似度为指导，从信息瓶颈角度实现分层缓存剪枝。这是一个两阶段剪枝框架，无需访问暴露的注意力分数，确保与 Flash Attention 等硬件加速技术完全兼容。

Result: SharpV 在多个公共基准测试中表现出卓越性能。其自适应机制偶尔能实现优于密集模型的性能增益。据作者所知，SharpV 是首个无需暴露注意力分数即可运行的两阶段剪枝框架，完全兼容硬件加速技术如 Flash Attention。

Conclusion: SharpV 提供了一种新颖的自适应剪枝范式，有效解决了 VideoLLMs 的计算复杂性和 KV 缓存扩展问题，并通过分层缓存剪枝提供了对信息流的新见解，同时保持了与硬件加速的兼容性。

Abstract: Current Video Large Language Models (VideoLLMs) suffer from quadratic computational complexity and key-value cache scaling, due to their reliance on processing excessive redundant visual tokens. To address this problem, we propose SharpV, a minimalist and efficient method for adaptive pruning of visual tokens and KV cache. Different from most uniform compression approaches, SharpV dynamically adjusts pruning ratios based on spatial-temporal information. Remarkably, this adaptive mechanism occasionally achieves performance gains over dense models, offering a novel paradigm for adaptive pruning. During the KV cache pruning stage, based on observations of visual information degradation, SharpV prunes degraded visual features via a self-calibration manner, guided by similarity to original visual features. In this way, SharpV achieves hierarchical cache pruning from the perspective of information bottleneck, offering a new insight into VideoLLMs' information flow. Experiments on multiple public benchmarks demonstrate the superiority of SharpV. Moreover, to the best of our knowledge, SharpV is notably the first two-stage pruning framework that operates without requiring access to exposed attention scores, ensuring full compatibility with hardware acceleration techniques like Flash Attention.

</details>


### [117] [EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision](https://arxiv.org/abs/2511.08007)
*Yifei Cao,Yu Liu,Guolong Wang,Zhu Liu,Kai Wang,Xianjie Zhang,Jizhe Yu,Xun Tu*

Main category: cs.CV

TL;DR: EAGLE是一个新颖的框架，利用情景式外观和几何感知记忆，在自我中心视觉中实现统一的2D-3D视觉查询定位，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 自我中心视觉查询定位对具身AI和VR/AR至关重要，但由于相机运动、视点变化和外观变化，仍然具有挑战性。

Method: EAGLE框架受鸟类记忆巩固启发，协同整合了由外观感知元学习记忆（AMM）引导的分割，以及由几何感知定位记忆（GLM）驱动的跟踪。通过结构化的外观和几何记忆库存储高置信度检索样本，有效支持目标外观变化的长期和短期建模。此外，通过将VQL-2D输出与视觉几何基础Transformer（VGGT）集成，实现2D和3D任务的有效统一。

Result: 该方法实现了精确的轮廓描绘和鲁棒的空间判别，显著提高了检索精度。同时，实现了2D和3D任务的有效统一，能够快速准确地反投影到3D空间。在Ego4D-VQ基准测试中取得了最先进的性能。

Conclusion: EAGLE提供了一种新颖且高效的解决方案，通过结合外观和几何感知记忆，解决了自我中心视觉中2D-3D视觉查询定位的挑战，并显著提升了定位精度和任务统一性。

Abstract: Egocentric visual query localization is vital for embodied AI and VR/AR, yet remains challenging due to camera motion, viewpoint changes, and appearance variations. We present EAGLE, a novel framework that leverages episodic appearance- and geometry-aware memory to achieve unified 2D-3D visual query localization in egocentric vision. Inspired by avian memory consolidation, EAGLE synergistically integrates segmentation guided by an appearance-aware meta-learning memory (AMM), with tracking driven by a geometry-aware localization memory (GLM). This memory consolidation mechanism, through structured appearance and geometry memory banks, stores high-confidence retrieval samples, effectively supporting both long- and short-term modeling of target appearance variations. This enables precise contour delineation with robust spatial discrimination, leading to significantly improved retrieval accuracy. Furthermore, by integrating the VQL-2D output with a visual geometry grounded Transformer (VGGT), we achieve a efficient unification of 2D and 3D tasks, enabling rapid and accurate back-projection into 3D space. Our method achieves state-ofthe-art performance on the Ego4D-VQ benchmark.

</details>


### [118] [Invisible Triggers, Visible Threats! Road-Style Adversarial Creation Attack for Visual 3D Detection in Autonomous Driving](https://arxiv.org/abs/2511.08015)
*Jian Wang,Lijun He,Yixing Yong,Haixia Bi,Fan Li*

Main category: cs.CV

TL;DR: 该论文提出AdvRoad，一种生成多样化、路面风格的对抗性海报的方法，用于隐蔽地攻击自动驾驶系统中的3D目标检测器，使其在路面上感知到不存在的物体，并在数字和物理实验中都展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现代自动驾驶系统依赖3D目标检测，而基于摄像头的检测方案虽然经济高效，但易受对抗性攻击。先前的对抗性海报攻击因外观不自然且内容固定而容易被人类察觉和防御。因此，研究人员旨在开发一种外观自然、多样化且隐蔽的现实对抗性攻击，以揭示自动驾驶的安全隐患。

Method: 研究者提出了AdvRoad方法，通过生成多样化的路面风格对抗性海报，使检测器在攻击位置感知到不存在的物体。该方法采用两阶段策略：1) 路面风格对抗样本生成，用于创建对抗性海报；2) 场景关联适应，用于根据特定输入场景调整海报，以最大化攻击效果并确保其自然外观，从而实现隐蔽攻击。

Result: 实验结果表明，AdvRoad方法对不同的检测器、场景和欺骗位置都具有良好的泛化能力。此外，物理攻击实验进一步证明了该方法在现实世界环境中的实际威胁，能够使检测器错误地感知到不存在的物体。

Conclusion: AdvRoad提出了一种生成多样化、路面风格对抗性海报的有效方法，能够隐蔽地攻击自动驾驶系统中的3D目标检测器，使其在路面上感知到不存在的物体。这项工作揭示了基于摄像头的3D检测器在现实世界中的脆弱性，并强调了自动驾驶系统面临的实际安全威胁。

Abstract: Modern autonomous driving (AD) systems leverage 3D object detection to perceive foreground objects in 3D environments for subsequent prediction and planning. Visual 3D detection based on RGB cameras provides a cost-effective solution compared to the LiDAR paradigm. While achieving promising detection accuracy, current deep neural network-based models remain highly susceptible to adversarial examples. The underlying safety concerns motivate us to investigate realistic adversarial attacks in AD scenarios. Previous work has demonstrated the feasibility of placing adversarial posters on the road surface to induce hallucinations in the detector. However, the unnatural appearance of the posters makes them easily noticeable by humans, and their fixed content can be readily targeted and defended. To address these limitations, we propose the AdvRoad to generate diverse road-style adversarial posters. The adversaries have naturalistic appearances resembling the road surface while compromising the detector to perceive non-existent objects at the attack locations. We employ a two-stage approach, termed Road-Style Adversary Generation and Scenario-Associated Adaptation, to maximize the attack effectiveness on the input scene while ensuring the natural appearance of the poster, allowing the attack to be carried out stealthily without drawing human attention. Extensive experiments show that AdvRoad generalizes well to different detectors, scenes, and spoofing locations. Moreover, physical attacks further demonstrate the practical threats in real-world environments.

</details>


### [119] [High-Quality Proposal Encoding and Cascade Denoising for Imaginary Supervised Object Detection](https://arxiv.org/abs/2511.08018)
*Zhiyuan Chen,Yuelin Guo,Zitong Huang,Haoyu He,Renhao Lu,Weizhe Zhang*

Main category: cs.CV

TL;DR: 该研究提出了Cascade HQP-DETR，通过高质量数据生成、基于高品质提议的查询编码和级联去噪算法，解决了 Imaginary Supervised Object Detection (ISOD) 中合成数据质量差、DETR模型收敛慢和过拟合伪标签噪声的问题，并在PASCAL VOC 2007上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 目标检测模型需要大量标注数据，但数据标注成本高昂且耗时。现有的ISOD方法（使用合成图像训练，真实图像测试）存在三点局限：1) 合成数据集提示词简单、图像质量差、监督弱；2) 基于DETR的检测器因随机查询初始化，收敛慢且易过拟合合成模式，泛化能力差；3) 均匀去噪压力导致模型过拟合伪标签噪声。

Method: 1. 引入高质量数据管道，结合LLaMA-3、Flux和Grounding DINO生成FluxVOC和FluxCOCO数据集，将ISOD从弱监督提升至全监督。2. 提出高品质提议引导的查询编码（HQP-DETR），利用SAM生成的提议和RoI池化特征初始化目标查询，加速收敛并学习可迁移特征，避免过拟合合成模式。3. 设计级联去噪算法，通过逐步增加解码器层间的IoU阈值动态调整训练权重，引导模型从可靠视觉线索中学习鲁棒边界，而非过拟合噪声标签。

Result: Cascade HQP-DETR仅在FluxVOC上训练12个epoch，就在PASCAL VOC 2007上实现了61.04%的mAP@0.5，超越了现有SOTA基线。其在真实数据上的竞争力也证实了该架构的普适性。

Conclusion: Cascade HQP-DETR通过改进数据质量、查询初始化和去噪策略，有效解决了ISOD面临的挑战，实现了在合成数据上训练并在真实数据上表现优异的目标检测性能，证明了其架构的普遍适用性。

Abstract: Object detection models demand large-scale annotated datasets, which are costly and labor-intensive to create. This motivated Imaginary Supervised Object Detection (ISOD), where models train on synthetic images and test on real images. However, existing methods face three limitations: (1) synthetic datasets suffer from simplistic prompts, poor image quality, and weak supervision; (2) DETR-based detectors, due to their random query initialization, struggle with slow convergence and overfitting to synthetic patterns, hindering real-world generalization; (3) uniform denoising pressure promotes model overfitting to pseudo-label noise. We propose Cascade HQP-DETR to address these limitations. First, we introduce a high-quality data pipeline using LLaMA-3, Flux, and Grounding DINO to generate the FluxVOC and FluxCOCO datasets, advancing ISOD from weak to full supervision. Second, our High-Quality Proposal guided query encoding initializes object queries with image-specific priors from SAM-generated proposals and RoI-pooled features, accelerating convergence while steering the model to learn transferable features instead of overfitting to synthetic patterns. Third, our cascade denoising algorithm dynamically adjusts training weights through progressively increasing IoU thresholds across decoder layers, guiding the model to learn robust boundaries from reliable visual cues rather than overfitting to noisy labels. Trained for just 12 epochs solely on FluxVOC, Cascade HQP-DETR achieves a SOTA 61.04\% mAP@0.5 on PASCAL VOC 2007, outperforming strong baselines, with its competitive real-data performance confirming the architecture's universal applicability.

</details>


### [120] [Multi-modal Deepfake Detection and Localization with FPN-Transformer](https://arxiv.org/abs/2511.08031)
*Chende Zheng,Ruiqi Suo,Zhoulin Ji,Jingyi Deng,Fangbin Yi,Chenhao Lin,Chao Shen*

Main category: cs.CV

TL;DR: 本文提出了一种基于FPN-Transformer的多模态深度伪造检测与定位框架，通过利用音视频跨模态特征和精确定位伪造片段，有效应对复杂的深度伪造内容。


<details>
  <summary>Details</summary>
Motivation: 生成对抗网络（GANs）和扩散模型使得深度伪造内容高度逼真，对数字信任构成严重威胁。单模态检测方法在识别合成媒体方面取得进展，但无法利用跨模态关联并精确本地化伪造片段，使其在应对复杂、细粒度操纵时实用性受限。

Method: 该方法引入了一个基于特征金字塔-Transformer (FPN-Transformer) 的多模态深度伪造检测和定位框架。它利用预训练的自监督模型（音频：WavLM，视频：CLIP）提取分层时间特征。通过带有局部注意力机制的R-TLM模块构建多尺度特征金字塔，实现跨上下文时间依赖的联合分析。双分支预测头同时预测伪造概率并细化被操纵片段的时间偏移，实现帧级定位精度。

Result: 该方法在IJCAI'25 DDL-AV基准测试集上进行了评估，在挑战性环境中，跨模态深度伪造检测和定位取得了0.7535的良好最终得分。

Conclusion: 实验结果证实了该方法的有效性，并为广义深度伪造检测提供了一种新颖的途径。

Abstract: The rapid advancement of generative adversarial networks (GANs) and diffusion models has enabled the creation of highly realistic deepfake content, posing significant threats to digital trust across audio-visual domains. While unimodal detection methods have shown progress in identifying synthetic media, their inability to leverage cross-modal correlations and precisely localize forged segments limits their practicality against sophisticated, fine-grained manipulations. To address this, we introduce a multi-modal deepfake detection and localization framework based on a Feature Pyramid-Transformer (FPN-Transformer), addressing critical gaps in cross-modal generalization and temporal boundary regression. The proposed approach utilizes pre-trained self-supervised models (WavLM for audio, CLIP for video) to extract hierarchical temporal features. A multi-scale feature pyramid is constructed through R-TLM blocks with localized attention mechanisms, enabling joint analysis of cross-context temporal dependencies. The dual-branch prediction head simultaneously predicts forgery probabilities and refines temporal offsets of manipulated segments, achieving frame-level localization precision. We evaluate our approach on the test set of the IJCAI'25 DDL-AV benchmark, showing a good performance with a final score of 0.7535 for cross-modal deepfake detection and localization in challenging environments. Experimental results confirm the effectiveness of our approach and provide a novel way for generalized deepfake detection. Our code is available at https://github.com/Zig-HS/MM-DDL

</details>


### [121] [Perceptual Quality Assessment of 3D Gaussian Splatting: A Subjective Dataset and Prediction Metric](https://arxiv.org/abs/2511.08032)
*Zhaolin Wan,Yining Diao,Jingqi Xu,Hao Wang,Zhiyang Li,Xiaopeng Fan,Wangmeng Zuo,Debin Zhao*

Main category: cs.CV

TL;DR: 本文提出了首个针对3D Gaussian Splatting (3DGS) 的主观质量评估数据集3DGS-QA，并引入了一个无需参考的质量预测模型，该模型直接作用于3D高斯基元，用于评估3DGS内容的感知质量，并取得了卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管3DGS在实时高保真渲染方面表现出色，但现有研究主要关注算法性能和视觉保真度。在实际应用中，视点稀疏性、训练迭代次数不足、点降采样、噪声和颜色失真等因素会显著降低视觉质量，但这些因素对感知质量的影响尚未得到系统研究。

Method: 1. 构建了3DGS-QA数据集，包含15种物体类型的225个降级重建，用于系统研究常见的失真因素。2. 提出了一种无需参考的质量预测模型，该模型直接作用于原生3D高斯基元，无需渲染图像或地面真实参考。3. 模型从高斯表示中提取空间和光度线索，以结构感知的方式估计感知质量。4. 对现有质量评估方法（包括传统和基于学习的方法）进行了基准测试。

Result: 实验结果表明，本文提出的方法始终优于现有的质量评估方法，突显了其在3DGS内容评估中的鲁棒性和有效性。

Conclusion: 本研究通过提供首个3DGS主观质量评估数据集和直接作用于高斯基元的无参考质量预测模型，弥补了3DGS感知质量评估领域的空白。所提出的数据集和模型对于3DGS内容评估具有鲁棒性和有效性，并且数据集和代码已公开，以促进未来研究。

Abstract: With the rapid advancement of 3D visualization, 3D Gaussian Splatting (3DGS) has emerged as a leading technique for real-time, high-fidelity rendering. While prior research has emphasized algorithmic performance and visual fidelity, the perceptual quality of 3DGS-rendered content, especially under varying reconstruction conditions, remains largely underexplored. In practice, factors such as viewpoint sparsity, limited training iterations, point downsampling, noise, and color distortions can significantly degrade visual quality, yet their perceptual impact has not been systematically studied. To bridge this gap, we present 3DGS-QA, the first subjective quality assessment dataset for 3DGS. It comprises 225 degraded reconstructions across 15 object types, enabling a controlled investigation of common distortion factors. Based on this dataset, we introduce a no-reference quality prediction model that directly operates on native 3D Gaussian primitives, without requiring rendered images or ground-truth references. Our model extracts spatial and photometric cues from the Gaussian representation to estimate perceived quality in a structure-aware manner. We further benchmark existing quality assessment methods, spanning both traditional and learning-based approaches. Experimental results show that our method consistently achieves superior performance, highlighting its robustness and effectiveness for 3DGS content evaluation. The dataset and code are made publicly available at https://github.com/diaoyn/3DGSQA to facilitate future research in 3DGS quality assessment.

</details>


### [122] [Taming Identity Consistency and Prompt Diversity in Diffusion Models via Latent Concatenation and Masked Conditional Flow Matching](https://arxiv.org/abs/2511.08061)
*Aditi Singhania,Arushi Jain,Krutik Malani,Riddhi Dhawan,Souymodip Chakraborty,Vineet Batra,Ankit Phogat*

Main category: cs.CV

TL;DR: 本文提出了一种基于LoRA微调扩散模型的主题驱动图像生成方法，通过潜在连接和掩码条件流匹配（CFM）目标，在保持身份一致性的同时实现提示多样性。此外，还引入了两阶段数据蒸馏框架进行大规模训练，并提出了CHARIS评估框架进行质量评估。


<details>
  <summary>Details</summary>
Motivation: 主题驱动图像生成面临在保持强大的身份一致性与实现高提示多样性之间的基本权衡。研究动机是解决这一挑战，以在多样化背景下合成特定主题的新图像，同时保留其核心身份特征。

Method: 本文采用的方法包括：1. 基于LoRA微调的扩散模型，结合潜在连接策略，共同处理参考和目标图像。2. 掩码条件流匹配（CFM）目标，以实现鲁棒的身份保留。3. 两阶段蒸馏数据整理框架：第一阶段利用数据恢复和基于VLM的过滤创建高质量种子数据集；第二阶段使用这些数据进行参数高效微调。4. 提出了CHARIS细粒度评估框架，从身份一致性、提示依从性、区域颜色保真度、视觉质量和转换多样性五个关键维度进行属性级比较。

Result: 该方法能够在不修改模型架构的情况下实现强大的身份保留。通过引入的两阶段数据整理框架，能够将生成能力扩展到各种主题和背景。CHARIS评估框架则用于过滤和质量评估，提供细粒度的性能分析。

Conclusion: 本文通过创新的模型设计（LoRA微调扩散模型与潜在连接、掩码CFM）、高效的数据整理框架以及全面的评估体系（CHARIS），成功解决了主题驱动图像生成中身份一致性和提示多样性之间的权衡问题，实现了在保持核心身份特征的同时生成多样化图像的目标。

Abstract: Subject-driven image generation aims to synthesize novel depictions of a specific subject across diverse contexts while preserving its core identity features. Achieving both strong identity consistency and high prompt diversity presents a fundamental trade-off. We propose a LoRA fine-tuned diffusion model employing a latent concatenation strategy, which jointly processes reference and target images, combined with a masked Conditional Flow Matching (CFM) objective. This approach enables robust identity preservation without architectural modifications. To facilitate large-scale training, we introduce a two-stage Distilled Data Curation Framework: the first stage leverages data restoration and VLM-based filtering to create a compact, high-quality seed dataset from diverse sources; the second stage utilizes these curated examples for parameter-efficient fine-tuning, thus scaling the generation capability across various subjects and contexts. Finally, for filtering and quality assessment, we present CHARIS, a fine-grained evaluation framework that performs attribute-level comparisons along five key axes: identity consistency, prompt adherence, region-wise color fidelity, visual quality, and transformation diversity.

</details>


### [123] [WEDepth: Efficient Adaptation of World Knowledge for Monocular Depth Estimation](https://arxiv.org/abs/2511.08036)
*Gongshu Wang,Zhirui Wang,Kan Yang*

Main category: cs.CV

TL;DR: WEDepth提出了一种新颖的方法，在不修改VFM结构和预训练权重的情况下，将其应用于单目深度估计（MDE），通过多级特征增强利用其内在先验知识，在NYU-Depth v2和KITTI数据集上实现了最先进的性能，并展现出强大的零样本迁移能力。


<details>
  <summary>Details</summary>
Motivation: 单目深度估计（MDE）因从2D图像重建3D场景的固有不适定性而极具挑战性。现代视觉基础模型（VFM）在各种视觉任务中展现出卓越的世界理解能力，并且最近的研究表明通过微调VFM可以显著改善MDE。受此启发，本文旨在开发一种无需修改VFM结构和预训练权重，但能有效利用其内在先验知识的方法来提升MDE。

Method: 本文提出了WEDepth方法。该方法将VFM用作多级特征增强器，系统地在不同表示级别注入先验知识，从而有效激发并利用VFM固有的先验知识。关键在于，此方法不修改VFM的结构和预训练权重。

Result: WEDepth在NYU-Depth v2和KITTI数据集上建立了新的最先进（SOTA）性能。与需要多次前向传播的扩散基方法以及在相对深度上预训练的方法相比，WEDepth取得了具有竞争力的结果。此外，该方法在不同场景中展现出强大的零样本迁移能力。

Conclusion: WEDepth通过将VFM作为多级特征增强器，在不修改其结构和预训练权重的情况下，成功地利用了VFM的内在先验知识进行单目深度估计。该方法在标准数据集上达到了SOTA性能，并展示了出色的泛化能力和零样本迁移潜力。

Abstract: Monocular depth estimation (MDE) has widely applicable but remains highly challenging due to the inherently ill-posed nature of reconstructing 3D scenes from single 2D images. Modern Vision Foundation Models (VFMs), pre-trained on large-scale diverse datasets, exhibit remarkable world understanding capabilities that benefit for various vision tasks. Recent studies have demonstrated significant improvements in MDE through fine-tuning these VFMs. Inspired by these developments, we propose WEDepth, a novel approach that adapts VFMs for MDE without modi-fying their structures and pretrained weights, while effec-tively eliciting and leveraging their inherent priors. Our method employs the VFM as a multi-level feature en-hancer, systematically injecting prior knowledge at differ-ent representation levels. Experiments on NYU-Depth v2 and KITTI datasets show that WEDepth establishes new state-of-the-art (SOTA) performance, achieving competi-tive results compared to both diffusion-based approaches (which require multiple forward passes) and methods pre-trained on relative depth. Furthermore, we demonstrate our method exhibits strong zero-shot transfer capability across diverse scenarios.

</details>


### [124] [Generalized-Scale Object Counting with Gradual Query Aggregation](https://arxiv.org/abs/2511.08048)
*Jer Pelhan,Alan Lukezic,Matej Kristan*

Main category: cs.CV

TL;DR: GECO2是一种端到端的小样本计数和检测方法，通过新的密集查询表示显式解决对象尺度问题，在性能和效率上均超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的小样本计数器在处理包含多样尺寸对象和密集小对象区域的图像时表现不佳，原因在于其依赖于合并多分辨率骨干特征、上采样和分块等临时解决方案。

Method: 本文提出了GECO2，一种端到端的小样本计数和检测方法。它引入了一种新的“密集查询表示”，该表示逐步聚合跨尺度的样本特定特征信息，从而生成高分辨率的密集查询，以实现对大对象和小对象的检测。

Result: GECO2在计数和检测准确性方面超越了现有最先进的小样本计数器10%，同时运行速度快3倍，且GPU内存占用更小。

Conclusion: GECO2通过其创新的密集查询表示，有效解决了小样本计数和检测中的对象尺度问题，在准确性、速度和内存效率方面都取得了显著的提升。

Abstract: Few-shot detection-based counters estimate the number of instances in the image specified only by a few test-time exemplars. A common approach to localize objects across multiple sizes is to merge backbone features of different resolutions. Furthermore, to enable small object detection in densely populated regions, the input image is commonly upsampled and tiling is applied to cope with the increased computational and memory requirements. Because of these ad-hoc solutions, existing counters struggle with images containing diverse-sized objects and densely populated regions of small objects. We propose GECO2, an end-to-end few-shot counting and detection method that explicitly addresses the object scale issues. A new dense query representation gradually aggregates exemplar-specific feature information across scales that leads to high-resolution dense queries that enable detection of large as well as small objects. GECO2 surpasses state-of-the-art few-shot counters in counting as well as detection accuracy by 10% while running 3x times faster at smaller GPU memory footprint.

</details>


### [125] [I2E: Real-Time Image-to-Event Conversion for High-Performance Spiking Neural Networks](https://arxiv.org/abs/2511.08065)
*Ruichen Ma,Liwei Meng,Guanchao Qiao,Ning Ning,Yang Liu,Shaogang Hu*

Main category: cs.CV

TL;DR: I2E框架通过模拟微眼跳将静态图像高效转换为高保真事件流，解决了SNN数据稀缺问题，显著提升了SNN性能，并实现了开创性的模拟到真实迁移。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络（SNNs）具有高能效计算潜力，但其应用受限于事件流数据严重匮乏。

Method: I2E框架通过高度并行化的卷积模拟微眼跳，将静态图像转换为高保真事件流。这种方法比现有方法快300多倍，支持SNN训练的即时数据增强。

Result: I2E转换速度比现有方法快300倍以上，独特地实现了SNN训练的即时数据增强。在I2E-ImageNet数据集上训练的SNN达到了60.50%的先进准确率。通过在合成I2E数据上预训练并在真实CIFAR10-DVS数据集上微调，实现了前所未有的92.5%准确率，验证了合成事件数据可作为真实传感器数据的高保真替代。

Conclusion: I2E为SNN数据问题提供了可扩展的解决方案，是开发高性能神经形态系统的基础工具包，弥合了神经形态工程领域长期存在的数据鸿沟。该算法及生成的所有数据集均已开源，以加速相关研究。

Abstract: Spiking neural networks (SNNs) promise highly energy-efficient computing, but their adoption is hindered by a critical scarcity of event-stream data. This work introduces I2E, an algorithmic framework that resolves this bottleneck by converting static images into high-fidelity event streams. By simulating microsaccadic eye movements with a highly parallelized convolution, I2E achieves a conversion speed over 300x faster than prior methods, uniquely enabling on-the-fly data augmentation for SNN training. The framework's effectiveness is demonstrated on large-scale benchmarks. An SNN trained on the generated I2E-ImageNet dataset achieves a state-of-the-art accuracy of 60.50%. Critically, this work establishes a powerful sim-to-real paradigm where pre-training on synthetic I2E data and fine-tuning on the real-world CIFAR10-DVS dataset yields an unprecedented accuracy of 92.5%. This result validates that synthetic event data can serve as a high-fidelity proxy for real sensor data, bridging a long-standing gap in neuromorphic engineering. By providing a scalable solution to the data problem, I2E offers a foundational toolkit for developing high-performance neuromorphic systems. The open-source algorithm and all generated datasets are provided to accelerate research in the field.

</details>


### [126] [ProSona: Prompt-Guided Personalization for Multi-Expert Medical Image Segmentation](https://arxiv.org/abs/2511.08046)
*Aya Elgebaly,Nikolaos Delopoulos,Juliane Hörner-Rieber,Carolin Rippke,Sebastian Klüter,Luca Boldrini,Lorenzo Placidi,Riccardo Dal Bello,Nicolaus Andratschke,Michael Baumgartl,Claus Belka,Christopher Kurz,Guillaume Landry,Shadi Albarqouni*

Main category: cs.CV

TL;DR: ProSona是一个两阶段框架，通过学习标注风格的连续潜在空间，并利用自然语言提示实现可控的个性化医学图像分割，有效解决了专家间变异性问题。


<details>
  <summary>Details</summary>
Motivation: 自动化医学图像分割面临高度的观察者间变异性，尤其是在肺结节勾画等任务中专家常有分歧。现有方法要么将这种变异性简化为共识掩膜，要么为每个标注者建立单独的模型分支，缺乏灵活性和可解释性。

Method: ProSona是一个两阶段框架。它学习一个连续的标注风格潜在空间。一个概率U-Net骨干网络捕获多样化的专家假设，而一个提示引导的投影机制通过自然语言提示在这个潜在空间中导航，生成个性化分割。多级对比目标函数用于对齐文本和视觉表示，以促进解耦和可解释的专家风格。

Result: 在LIDC-IDRI肺结节和多机构前列腺MRI数据集上，ProSona与DPersona相比，将广义能量距离（Generalized Energy Distance）降低了17%，平均Dice系数提高了超过一个百分点。这些结果表明，自然语言提示可以为个性化医学图像分割提供灵活、准确和可解释的控制。

Conclusion: 自然语言提示能够为个性化医学图像分割提供灵活、准确且可解释的控制，有效地处理专家间变异性问题，并提升分割性能。

Abstract: Automated medical image segmentation suffers from high inter-observer variability, particularly in tasks such as lung nodule delineation, where experts often disagree. Existing approaches either collapse this variability into a consensus mask or rely on separate model branches for each annotator. We introduce ProSona, a two-stage framework that learns a continuous latent space of annotation styles, enabling controllable personalization via natural language prompts. A probabilistic U-Net backbone captures diverse expert hypotheses, while a prompt-guided projection mechanism navigates this latent space to generate personalized segmentations. A multi-level contrastive objective aligns textual and visual representations, promoting disentangled and interpretable expert styles. Across the LIDC-IDRI lung nodule and multi-institutional prostate MRI datasets, ProSona reduces the Generalized Energy Distance by 17% and improves mean Dice by more than one point compared with DPersona. These results demonstrate that natural-language prompts can provide flexible, accurate, and interpretable control over personalized medical image segmentation. Our implementation is available online 1 .

</details>


### [127] [Radar-APLANC: Unsupervised Radar-based Heartbeat Sensing via Augmented Pseudo-Label and Noise Contrast](https://arxiv.org/abs/2511.08071)
*Ying Wang,Zhaodong Sun,Xu Cheng,Zuxian He,Xiaobai Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为Radar-APLANC的无监督框架，用于雷达心跳感应。它通过增强伪标签和噪声对比来提高抗噪性，并在无需真实生理信号标签的情况下，达到了与最先进的有监督方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的雷达心跳感应方法容易受到噪声影响导致性能下降；而基于学习的雷达方法虽然抗噪性更好，但需要昂贵的标注信号进行监督训练。

Method: 本文提出了首个无监督雷达心跳感应框架Radar-APLANC。它利用雷达距离矩阵中的心跳范围和噪声范围分别构建正样本和负样本以提高抗噪性。其噪声对比三元组（NCT）损失仅使用正样本、负样本和传统雷达方法生成的伪标签信号，从而避免了对昂贵真实生理信号的依赖。此外，还设计了一种具有自适应噪声感知标签选择的伪标签增强方法，以提高伪标签信号的质量。

Result: 在Equipleth数据集和作者收集的雷达数据集上进行的广泛实验表明，该无监督方法达到了与最先进的有监督方法相当的性能。

Conclusion: 所提出的无监督框架Radar-APLANC成功解决了传统雷达方法易受噪声影响和学习型方法依赖昂贵标注数据的问题，实现了高性能的非接触式心跳感应。

Abstract: Frequency Modulated Continuous Wave (FMCW) radars can measure subtle chest wall oscillations to enable non-contact heartbeat sensing. However, traditional radar-based heartbeat sensing methods face performance degradation due to noise. Learning-based radar methods achieve better noise robustness but require costly labeled signals for supervised training. To overcome these limitations, we propose the first unsupervised framework for radar-based heartbeat sensing via Augmented Pseudo-Label and Noise Contrast (Radar-APLANC). We propose to use both the heartbeat range and noise range within the radar range matrix to construct the positive and negative samples, respectively, for improved noise robustness. Our Noise-Contrastive Triplet (NCT) loss only utilizes positive samples, negative samples, and pseudo-label signals generated by the traditional radar method, thereby avoiding dependence on expensive ground-truth physiological signals. We further design a pseudo-label augmentation approach featuring adaptive noise-aware label selection to improve pseudo-label signal quality. Extensive experiments on the Equipleth dataset and our collected radar dataset demonstrate that our unsupervised method achieves performance comparable to state-of-the-art supervised methods. Our code, dataset, and supplementary materials can be accessed from https://github.com/RadarHRSensing/Radar-APLANC.

</details>


### [128] [CLIP is All You Need for Human-like Semantic Representations in Stable Diffusion](https://arxiv.org/abs/2511.08075)
*Cameron Braunstein,Mariya Toneva,Eddy Ilg*

Main category: cs.CV

TL;DR: 研究发现Stable Diffusion的语义理解能力主要源于CLIP的文本编码，而非扩散过程，扩散过程更像是视觉解码器。


<details>
  <summary>Details</summary>
Motivation: 尽管潜在扩散模型在文本到图像生成方面表现出色，但它们对所生成图像的语义理解程度及其内部表示是否包含人类可理解的语义信息尚不清楚。

Method: 通过使用简单的回归层对Stable Diffusion进行探测，预测对象的语义属性，并与人类标注进行比较评估。

Result: 研究发现，语义理解的成功主要归因于CLIP中的文本编码，而非逆向扩散过程。不同语义属性组的解码准确率差异显著。在逆向扩散过程中，属性变得更难区分，进一步表明CLIP中对象属性的语义表示最强。

Conclusion: 结论是，独立训练的CLIP视觉-语言模型决定了类人的语义表示，而扩散过程则充当视觉解码器的角色。

Abstract: Latent diffusion models such as Stable Diffusion achieve state-of-the-art results on text-to-image generation tasks. However, the extent to which these models have a semantic understanding of the images they generate is not well understood. In this work, we investigate whether the internal representations used by these models during text-to-image generation contain semantic information that is meaningful to humans. To do so, we perform probing on Stable Diffusion with simple regression layers that predict semantic attributes for objects and evaluate these predictions against human annotations. Surprisingly, we find that this success can actually be attributed to the text encoding occurring in CLIP rather than the reverse diffusion process. We demonstrate that groups of specific semantic attributes have markedly different decoding accuracy than the average, and are thus represented to different degrees. Finally, we show that attributes become more difficult to disambiguate from one another during the inverse diffusion process, further demonstrating the strongest semantic representation of object attributes in CLIP. We conclude that the separately trained CLIP vision-language model is what determines the human-like semantic representation, and that the diffusion process instead takes the role of a visual decoder.

</details>


### [129] [Beyond the Pixels: VLM-based Evaluation of Identity Preservation in Reference-Guided Synthesis](https://arxiv.org/abs/2511.08087)
*Aditi Singhania,Krutik Malani,Riddhi Dhawan,Arushi Jain,Garv Tandon,Nippun Sharma,Souymodip Chakraborty,Vineet Batra,Ankit Phogat*

Main category: cs.CV

TL;DR: 本文提出“超越像素”分层评估框架，通过结构化VLM推理和具体变换提示，解决现有生成模型身份保持评估中缺乏细粒度诊断和一致性的问题，并引入了一个新的基准测试集。


<details>
  <summary>Details</summary>
Motivation: 现有评估生成模型身份保持的方法依赖全局嵌入或粗略VLM提示，无法捕捉细粒度身份变化，也缺乏诊断性洞察，因此需要更精确和可诊断的评估方法。

Method: 引入“超越像素”分层评估框架，将身份评估分解为特征级转换。通过(1)将主体分层分解为(类型，风格) -> 属性 -> 特征决策树，以及(2)提示VLM进行具体变换而非抽象相似度评分，引导VLM进行结构化推理。此外，还引入了一个包含1,078个图像-提示对的新基准测试集，涵盖多样化主体类型和多达七个转换轴。

Result: 该框架在四个最先进的生成模型上进行了验证，显示出与人类判断高度一致的身份一致性测量结果。通过将VLM分析基于可验证的视觉证据，减少了幻觉并提高了评估的一致性。

Conclusion: “超越像素”框架有效解决了生成模型身份保持评估中的挑战，通过提供细粒度的诊断性洞察和与人类判断高度一致的评估结果，显著提升了评估的准确性和实用性。

Abstract: Evaluating identity preservation in generative models remains a critical yet unresolved challenge. Existing metrics rely on global embeddings or coarse VLM prompting, failing to capture fine-grained identity changes and providing limited diagnostic insight. We introduce Beyond the Pixels, a hierarchical evaluation framework that decomposes identity assessment into feature-level transformations. Our approach guides VLMs through structured reasoning by (1) hierarchically decomposing subjects into (type, style) -> attribute -> feature decision tree, and (2) prompting for concrete transformations rather than abstract similarity scores. This decomposition grounds VLM analysis in verifiable visual evidence, reducing hallucinations and improving consistency. We validate our framework across four state-of-the-art generative models, demonstrating strong alignment with human judgments in measuring identity consistency. Additionally, we introduce a new benchmark specifically designed to stress-test generative models. It comprises 1,078 image-prompt pairs spanning diverse subject types, including underrepresented categories such as anthropomorphic and animated characters, and captures an average of six to seven transformation axes per prompt.

</details>


### [130] [StableMorph: High-Quality Face Morph Generation with Stable Diffusion](https://arxiv.org/abs/2511.08090)
*Wassim Kabbani,Kiran Raja,Raghavendra Ramachandra,Christoph Busch*

Main category: cs.CV

TL;DR: 本文提出StableMorph，一种基于扩散模型的新方法，用于生成高质量、无伪影的逼真人脸融合图像，这些图像能够有效欺骗人脸识别系统，从而提升了融合攻击检测（MAD）系统的评估标准和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的融合图像生成方法产生的图像模糊、充满伪影或结构不佳，容易被检测到，无法代表现实世界中最危险的攻击，这阻碍了开发和评估有效的融合攻击检测系统。

Method: StableMorph利用现代扩散模型图像合成技术，生成全头、细节清晰、无常见视觉缺陷的融合人脸图像，并对视觉属性提供无与伦比的控制。

Result: StableMorph生成的图像质量媲美甚至超越真实人脸图像，并能有效欺骗人脸识别系统，对现有MAD解决方案构成更大挑战，为融合图像质量设定了新标准。这些图像提升了生物识别安全的评估水平。

Conclusion: StableMorph通过创建更逼真和有效的攻击，改进了生物识别安全评估，并支持开发更强大的检测系统。

Abstract: Face morphing attacks threaten the integrity of biometric identity systems by enabling multiple individuals to share a single identity. To develop and evaluate effective morphing attack detection (MAD) systems, we need access to high-quality, realistic morphed images that reflect the challenges posed in real-world scenarios. However, existing morph generation methods often produce images that are blurry, riddled with artifacts, or poorly constructed making them easy to detect and not representative of the most dangerous attacks. In this work, we introduce StableMorph, a novel approach that generates highly realistic, artifact-free morphed face images using modern diffusion-based image synthesis. Unlike prior methods, StableMorph produces full-head images with sharp details, avoids common visual flaws, and offers unmatched control over visual attributes. Through extensive evaluation, we show that StableMorph images not only rival or exceed the quality of genuine face images but also maintain a strong ability to fool face recognition systems posing a greater challenge to existing MAD solutions and setting a new standard for morph quality in research and operational testing. StableMorph improves the evaluation of biometric security by creating more realistic and effective attacks and supports the development of more robust detection systems.

</details>


### [131] [Introducing Nylon Face Mask Attacks: A Dataset for Evaluating Generalised Face Presentation Attack Detection](https://arxiv.org/abs/2511.08114)
*Manasa,Sushrut Patwardhan,Narayan Vetrekar,Pavan Kumar,R. S. Gad,Raghavendra Ramachandra*

Main category: cs.CV

TL;DR: 本文介绍了一个新的数据集，专注于尼龙面具（NFM）这种新型逼真的3D活体攻击，使用iPhone 11 Pro收集。研究人员使用该数据集对五种先进的活体检测（PAD）方法进行了基准测试，结果显示这些方法在面对NFM攻击时性能差异显著，凸显了对新兴欺骗威胁开发通用PAD技术的重要性。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统广泛应用，但易受活体攻击（PAs）影响，严重损害其可靠性。特别是尼龙面具（NFMs）这类新型且逼真的3D欺骗手段，其弹性结构和照片级真实感能高度模仿受害者面部几何，对现有系统构成严重威胁。

Method: 研究人员引入了一个名为尼龙面具（NFMs）的新型活体攻击数据集，旨在模拟先进的3D欺骗场景。数据集使用iPhone 11 Pro收集，包含来自100名受试者的3,760个真实样本，以及在人类和人体模型上、四种不同呈现场景下的51,281个NFM攻击样本。研究人员使用五种最先进的PAD方法对该数据集进行了基准测试，以评估它们在未知攻击条件下的鲁棒性。

Result: 基准测试结果表明，在面对尼龙面具（NFM）攻击，尤其是在未见过的新攻击条件下，不同PAD方法之间存在显著的性能差异。这凸显了NFM攻击所带来的挑战。

Conclusion: 尼龙面具（NFMs）对人脸识别系统构成了重大挑战，现有PAD方法在处理这类新兴欺骗威胁时泛化能力不足。因此，开发能够有效泛化到新出现的欺骗威胁的PAD技术至关重要。

Abstract: Face recognition systems are increasingly deployed across a wide range of applications, including smartphone authentication, access control, and border security. However, these systems remain vulnerable to presentation attacks (PAs), which can significantly compromise their reliability. In this work, we introduce a new dataset focused on a novel and realistic presentation attack instrument called Nylon Face Masks (NFMs), designed to simulate advanced 3D spoofing scenarios. NFMs are particularly concerning due to their elastic structure and photorealistic appearance, which enable them to closely mimic the victim's facial geometry when worn by an attacker. To reflect real-world smartphone-based usage conditions, we collected the dataset using an iPhone 11 Pro, capturing 3,760 bona fide samples from 100 subjects and 51,281 NFM attack samples across four distinct presentation scenarios involving both humans and mannequins. We benchmark the dataset using five state-of-the-art PAD methods to evaluate their robustness under unseen attack conditions. The results demonstrate significant performance variability across methods, highlighting the challenges posed by NFMs and underscoring the importance of developing PAD techniques that generalise effectively to emerging spoofing threats.

</details>


### [132] [LatentPrintFormer: A Hybrid CNN-Transformer with Spatial Attention for Latent Fingerprint identification](https://arxiv.org/abs/2511.08119)
*Arnab Maity,Manasa,Pavan Kumar C,Raghavendra Ramachandra*

Main category: cs.CV

TL;DR: 本文提出了一种名为LatentPrintFormer的新型潜在指纹识别方法，通过结合CNN和Transformer提取局部和全局特征，并利用空间注意力模块，显著提高了在低质量潜在指纹上的识别性能。


<details>
  <summary>Details</summary>
Motivation: 由于图像质量低、背景噪声大和指纹不完整，潜在指纹识别仍然是一项具有挑战性的任务。

Method: 该研究提出了LatentPrintFormer模型，它整合了CNN骨干（EfficientNet-B0）和Transformer骨干（Swin Tiny）来提取潜在指纹的局部和全局特征。模型还采用了一个空间注意力模块来强调高质量的脊线区域并抑制背景噪声。提取的特征被融合并投射到统一的512维嵌入中，匹配则在闭集识别设置下使用余弦相似度进行。

Result: 在两个公开数据集上进行的广泛实验表明，LatentPrintFormer在Rank-10识别率方面持续优于三种最先进的潜在指纹识别技术，取得了更高的识别率。

Conclusion: LatentPrintFormer是一种有效且优越的潜在指纹识别方法，通过结合多模态特征提取和注意力机制，显著提升了在挑战性条件下的识别性能。

Abstract: Latent fingerprint identification remains a challenging task due to low image quality, background noise, and partial impressions. In this work, we propose a novel identification approach called LatentPrintFormer. The proposed model integrates a CNN backbone (EfficientNet-B0) and a Transformer backbone (Swin Tiny) to extract both local and global features from latent fingerprints. A spatial attention module is employed to emphasize high-quality ridge regions while suppressing background noise. The extracted features are fused and projected into a unified 512-dimensional embedding, and matching is performed using cosine similarity in a closed-set identification setting. Extensive experiments on two publicly available datasets demonstrate that LatentPrintFormer consistently outperforms three state-of-the-art latent fingerprint recognition techniques, achieving higher identification rates across Rank-10.

</details>


### [133] [PEOD: A Pixel-Aligned Event-RGB Benchmark for Object Detection under Challenging Conditions](https://arxiv.org/abs/2511.08140)
*Luoping Cui,Hanqing Liu,Mingjie Liu,Endian Lin,Donghong Jiang,Yuhao Wang,Chuang Zhu*

Main category: cs.CV

TL;DR: 本文提出了PEOD，首个大规模、像素对齐、高分辨率（1280x720）的事件-RGB目标检测数据集，专注于挑战性条件。研究基准测试了14种方法，发现在光照挑战下，纯事件模型优于融合模型，揭示了现有融合方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的事件-RGB数据集在极端条件覆盖和空间分辨率方面存在局限性（<= 640x480），阻碍了对目标检测器在挑战性场景下的全面评估。

Method: 本文构建了PEOD数据集，包含130多个时空对齐序列和34万个人工标注边界框，其中57%的数据是在低光照、过曝和高速运动等挑战条件下捕获的。此外，还在PEOD上基准测试了14种目标检测方法，涵盖基于事件、基于RGB和事件-RGB融合三种输入配置。

Result: 在完整测试集和正常子集上，融合模型表现最佳。然而，在光照挑战子集上，顶级的事件模型超越了所有融合模型，尽管融合模型仍优于其RGB对应模型。这表明当帧模态严重退化时，现有融合方法存在局限性。

Conclusion: PEOD为多模态感知建立了一个真实、高质量的基准，并促进了未来的研究。研究结果强调了事件相机在极端条件下的潜力，并指出了现有事件-RGB融合方法在严重退化场景下的不足。

Abstract: Robust object detection for challenging scenarios increasingly relies on event cameras, yet existing Event-RGB datasets remain constrained by sparse coverage of extreme conditions and low spatial resolution (<= 640 x 480), which prevents comprehensive evaluation of detectors under challenging scenarios. To address these limitations, we propose PEOD, the first large-scale, pixel-aligned and high-resolution (1280 x 720) Event-RGB dataset for object detection under challenge conditions. PEOD contains 130+ spatiotemporal-aligned sequences and 340k manual bounding boxes, with 57% of data captured under low-light, overexposure, and high-speed motion. Furthermore, we benchmark 14 methods across three input configurations (Event-based, RGB-based, and Event-RGB fusion) on PEOD. On the full test set and normal subset, fusion-based models achieve the excellent performance. However, in illumination challenge subset, the top event-based model outperforms all fusion models, while fusion models still outperform their RGB-based counterparts, indicating limits of existing fusion methods when the frame modality is severely degraded. PEOD establishes a realistic, high-quality benchmark for multimodal perception and facilitates future research.

</details>


### [134] [OTSNet: A Neurocognitive-Inspired Observation-Thinking-Spelling Pipeline for Scene Text Recognition](https://arxiv.org/abs/2511.08133)
*Lixu Sun,Nurmemet Yolwas,Wushour Silamu*

Main category: cs.CV

TL;DR: 该论文提出OTSNet，一个受神经认知启发的Observation-Thinking-Spelling三阶段网络，旨在解决现有场景文本识别（STR）方法中视觉-语言解耦优化导致的误差传播和对不规则文本识别的准确性下降问题，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有STR框架中视觉-语言解耦优化导致跨模态错位和误差传播。视觉编码器对背景干扰存在注意力偏差，而解码器在解析几何变形文本时存在空间错位，这些问题共同降低了不规则文本的识别准确性。

Method: 受人类视觉感知中分层认知过程的启发，作者提出了OTSNet，一个包含三个核心组件的三阶段网络：1) 双注意力马卡龙编码器（DAME），通过差分注意力图细化视觉特征，抑制无关区域并增强判别焦点；2) 位置感知模块（PAM）和语义量化器（SQ），通过自适应采样共同整合空间上下文和字形级语义抽象；3) 多模态协作验证器（MMCV），通过视觉、语义和字符级特征的跨模态融合实现自我校正。

Result: OTSNet在具有挑战性的Union14M-L基准测试中取得了83.5%的平均准确率，在严重遮挡的OST数据集上取得了79.1%的准确率，在14个评估场景中的9个创下了新纪录，表现出最先进的性能。

Conclusion: OTSNet通过其神经认知启发的设计，有效解决了场景文本识别中的复杂挑战，特别是针对不规则文本的识别，并在多个基准测试中建立了新的性能记录。

Abstract: Scene Text Recognition (STR) remains challenging due to real-world complexities, where decoupled visual-linguistic optimization in existing frameworks amplifies error propagation through cross-modal misalignment. Visual encoders exhibit attention bias toward background distractors, while decoders suffer from spatial misalignment when parsing geometrically deformed text-collectively degrading recognition accuracy for irregular patterns. Inspired by the hierarchical cognitive processes in human visual perception, we propose OTSNet, a novel three-stage network embodying a neurocognitive-inspired Observation-Thinking-Spelling pipeline for unified STR modeling. The architecture comprises three core components: (1) a Dual Attention Macaron Encoder (DAME) that refines visual features through differential attention maps to suppress irrelevant regions and enhance discriminative focus; (2) a Position-Aware Module (PAM) and Semantic Quantizer (SQ) that jointly integrate spatial context with glyph-level semantic abstraction via adaptive sampling; and (3) a Multi-Modal Collaborative Verifier (MMCV) that enforces self-correction through cross-modal fusion of visual, semantic, and character-level features. Extensive experiments demonstrate that OTSNet achieves state-of-the-art performance, attaining 83.5% average accuracy on the challenging Union14M-L benchmark and 79.1% on the heavily occluded OST dataset-establishing new records across 9 out of 14 evaluation scenarios.

</details>


### [135] [Boomda: Balanced Multi-objective Optimization for Multimodal Domain Adaptation](https://arxiv.org/abs/2511.08152)
*Jun Sun,Xinxin Zhang,Simin Hong,Jian Zhu,Xiang Gao*

Main category: cs.CV

TL;DR: 本文提出了一种名为Boomda的多模态域适应算法，旨在解决多模态学习中数据标注成本高昂和不同模态间域偏移不一致的问题。它通过信息瓶颈、相关性对齐和多目标优化实现模态平衡的域适应。


<details>
  <summary>Details</summary>
Motivation: 多模态学习成功应用广泛，但手动标注成本高昂导致标注数据稀缺。无监督域适应是解决此问题的流行方案，但在多模态设置中研究较少，尤其面临不同模态间域偏移程度不同的挑战。

Method: 该方法首先为每个模态独立地引入信息瓶颈方法学习表示，然后使用相关性对齐在表示空间中匹配源域和目标域。为平衡所有模态的域对齐，将问题表述为多目标任务以寻求帕累托最优解。通过模型特性，问题被简化为二次规划，进一步近似得到闭式解，从而形成高效的模态平衡多模态域适应算法Boomda。

Result: 广泛的实证结果表明，所提出的方法是有效的，并且Boomda优于现有竞争方案。

Conclusion: Boomda是一种新颖且高效的模态平衡多模态域适应算法，能够有效解决多模态学习中数据标注稀缺和不同模态域偏移不一致的问题。

Abstract: Multimodal learning, while contributing to numerous success stories across various fields, faces the challenge of prohibitively expensive manual annotation. To address the scarcity of annotated data, a popular solution is unsupervised domain adaptation, which has been extensively studied in unimodal settings yet remains less explored in multimodal settings. In this paper, we investigate heterogeneous multimodal domain adaptation, where the primary challenge is the varying domain shifts of different modalities from the source to the target domain. We first introduce the information bottleneck method to learn representations for each modality independently, and then match the source and target domains in the representation space with correlation alignment. To balance the domain alignment of all modalities, we formulate the problem as a multi-objective task, aiming for a Pareto optimal solution. By exploiting the properties specific to our model, the problem can be simplified to a quadratic programming problem. Further approximation yields a closed-form solution, leading to an efficient modality-balanced multimodal domain adaptation algorithm. The proposed method features \textbf{B}alanced multi-\textbf{o}bjective \textbf{o}ptimization for \textbf{m}ultimodal \textbf{d}omain \textbf{a}daptation, termed \textbf{Boomda}. Extensive empirical results showcase the effectiveness of the proposed approach and demonstrate that Boomda outperforms the competing schemes. The code is is available at: https://github.com/sunjunaimer/Boomda.git.

</details>


### [136] [Foam Segmentation in Wastewater Treatment Plants: A Federated Learning Approach with Segment Anything Model 2](https://arxiv.org/abs/2511.08130)
*Mehmet Batuhan Duman,Alejandro Carnero,Cristian Martín,Daniel Garrido,Manuel Díaz*

Main category: cs.CV

TL;DR: 该研究提出一个结合联邦学习（FL）和Segment Anything Model 2 (SAM2) 的新框架，以解决污水处理厂（WTPs）中泡沫自动检测的数据稀缺、异构和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 污水处理厂中的泡沫形成是一个主要挑战，会降低处理效率并增加成本。自动实时检测泡沫百分比具有巨大益处。然而，训练标准机器学习模型需要大量标注数据，但这些数据稀缺、异构且因隐私问题无法共享，导致系统开发缓慢。

Method: 该方法结合联邦学习（FL）范式与最先进的图像分割基础模型Segment Anything Model 2 (SAM2)。它通过在分布式客户端（边缘节点）上微调SAM2，利用Flower框架，由中央Fog服务器协调聚合模型权重而不访问私有数据。模型在西班牙格拉纳达WTPs的真实图像、合成泡沫数据集和公共数据集上进行训练和验证。

Result: 该框架即使在有限的本地数据集下，也能加速训练收敛并提高分割性能。它为WTPs中的自动泡沫跟踪提供了一个实用、可扩展且注重隐私的解决方案。

Conclusion: 研究结果强调了将大规模基础模型（如SAM2）集成到联邦学习系统中，以解决具有分布式和敏感数据的实际工业挑战的巨大潜力。

Abstract: Foam formation in Wastewater Treatment Plants (WTPs) is a major challenge that can reduce treatment efficiency and increase costs. The ability to automatically examine changes in real-time with respect to the percentage of foam can be of great benefit to the plant. However, large amounts of labeled data are required to train standard Machine Learning (ML) models. The development of these systems is slow due to the scarcity and heterogeneity of labeled data. Additionally, the development is often hindered by the fact that different WTPs do not share their data due to privacy concerns. This paper proposes a new framework to address these challenges by combining Federated Learning (FL) with the state-of-the-art base model for image segmentation, Segment Anything Model 2 (SAM2). The FL paradigm enables collaborative model training across multiple WTPs without centralizing sensitive operational data, thereby ensuring privacy. The framework accelerates training convergence and improves segmentation performance even with limited local datasets by leveraging SAM2's strong pre-trained weights for initialization. The methodology involves fine-tuning SAM2 on distributed clients (edge nodes) using the Flower framework, where a central Fog server orchestrates the process by aggregating model weights without accessing private data. The model was trained and validated using various data collections, including real-world images captured at a WTPs in Granada, Spain, a synthetically generated foam dataset, and images from publicly available datasets to improve generalization. This research offers a practical, scalable, and privacy-aware solution for automatic foam tracking in WTPs. The findings highlight the significant potential of integrating large-scale foundational models into FL systems to solve real-world industrial challenges characterized by distributed and sensitive data.

</details>


### [137] [LandSegmenter: Towards a Flexible Foundation Model for Land Use and Land Cover Mapping](https://arxiv.org/abs/2511.08156)
*Chenying Liu,Wei Huang,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: LandSegmenter是一个用于土地利用和土地覆盖（LULC）映射的通用基础模型（FM）框架，它利用大规模弱标注多模态数据集LAS进行训练，并通过特定适配器和融合策略实现跨模态特征提取和零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的LULC模型通常针对特定模态和固定分类法开发，限制了其通用性和适用性。虽然基础模型有潜力，但任务无关的FM需要微调，而任务特定的FM则需要大量昂贵的标注数据，这在遥感领域不切实际。

Method: LandSegmenter框架解决了输入、模型和输出三个层面的挑战：
1.  **输入层面**：引入LAS数据集，一个大规模、多模态、多源的数据集，主要通过现有LULC产品的全球采样弱标签构建，以降低对标注数据的需求。
2.  **模型架构**：集成了一个遥感（RS）专用适配器用于跨模态特征提取，以及一个文本编码器用于增强语义感知。
3.  **输出层面**：引入了一种类别置信度引导的融合策略，以缓解语义遗漏并进一步提高零样本性能。

Result: LandSegmenter在六个涵盖不同模态和分类法的LULC数据集上进行了评估。广泛的迁移学习和零样本实验表明，LandSegmenter取得了有竞争力或更优的性能，特别是在迁移到未见过的数据集时的零样本设置中表现出色。

Conclusion: 研究结果突出了所提出框架的有效性，以及弱监督在构建特定任务基础模型方面的实用性。

Abstract: Land Use and Land Cover (LULC) mapping is a fundamental task in Earth Observation (EO). However, current LULC models are typically developed for a specific modality and a fixed class taxonomy, limiting their generability and broader applicability. Recent advances in foundation models (FMs) offer promising opportunities for building universal models. Yet, task-agnostic FMs often require fine-tuning for downstream applications, whereas task-specific FMs rely on massive amounts of labeled data for training, which is costly and impractical in the remote sensing (RS) domain. To address these challenges, we propose LandSegmenter, an LULC FM framework that resolves three-stage challenges at the input, model, and output levels. From the input side, to alleviate the heavy demand on labeled data for FM training, we introduce LAnd Segment (LAS), a large-scale, multi-modal, multi-source dataset built primarily with globally sampled weak labels from existing LULC products. LAS provides a scalable, cost-effective alternative to manual annotation, enabling large-scale FM training across diverse LULC domains. For model architecture, LandSegmenter integrates an RS-specific adapter for cross-modal feature extraction and a text encoder for semantic awareness enhancement. At the output stage, we introduce a class-wise confidence-guided fusion strategy to mitigate semantic omissions and further improve LandSegmenter's zero-shot performance. We evaluate LandSegmenter on six precisely annotated LULC datasets spanning diverse modalities and class taxonomies. Extensive transfer learning and zero-shot experiments demonstrate that LandSegmenter achieves competitive or superior performance, particularly in zero-shot settings when transferred to unseen datasets. These results highlight the efficacy of our proposed framework and the utility of weak supervision for building task-specific FMs.

</details>


### [138] [Non-Aligned Reference Image Quality Assessment for Novel View Synthesis](https://arxiv.org/abs/2511.08155)
*Abhijay Ghildyal,Rajesh Sureddi,Nabajeet Barman,Saman Zadtootaghaj,Alan Bovik*

Main category: cs.CV

TL;DR: 该论文提出了一种名为NAR-IQA的新颖视图合成（NVS）图像质量评估框架，专门针对没有像素级对齐参考的情况。该模型基于对比学习，利用LoRA增强的DINOv2嵌入和合成失真训练，在对齐和非对齐参考上均表现出色，并与人类感知高度相关。


<details>
  <summary>Details</summary>
Motivation: 评估新颖视图合成（NVS）图像的感知质量是一个关键挑战，尤其是在缺乏像素级对齐的真实参考时。全参考图像质量评估（FR-IQA）方法在不对齐时失效，而无参考（NR-IQA）方法则在泛化性上遇到困难。

Method: 引入了一个非对齐参考（NAR-IQA）框架，假设参考视图共享部分场景内容但缺乏像素级对齐。构建了一个包含针对时间兴趣区域（TROI）的合成失真的大规模图像数据集来训练NAR-IQA模型。模型基于对比学习框架，结合了LoRA增强的DINOv2嵌入，并由现有IQA方法的监督指导。模型仅在合成生成的失真上训练，以避免过拟合特定真实NVS样本，从而增强泛化能力。还进行了一项新颖的用户研究，以收集在NVS中查看非对齐参考时的人类偏好数据。

Result: 所提出的模型优于最先进的FR-IQA、NR-IQA和现有NAR-IQA方法，在对齐和非对齐参考上均实现了鲁棒性能。研究发现，所提出的质量预测模型与收集到的主观评分之间存在强相关性。

Conclusion: 该NAR-IQA框架有效解决了在缺乏像素级对齐参考的情况下NVS图像质量评估的挑战。它在对齐和非对齐参考上均表现出卓越的性能和泛化能力，并且与人类感知高度一致。

Abstract: Evaluating the perceptual quality of Novel View Synthesis (NVS) images remains a key challenge, particularly in the absence of pixel-aligned ground truth references. Full-Reference Image Quality Assessment (FR-IQA) methods fail under misalignment, while No-Reference (NR-IQA) methods struggle with generalization. In this work, we introduce a Non-Aligned Reference (NAR-IQA) framework tailored for NVS, where it is assumed that the reference view shares partial scene content but lacks pixel-level alignment. We constructed a large-scale image dataset containing synthetic distortions targeting Temporal Regions of Interest (TROI) to train our NAR-IQA model. Our model is built on a contrastive learning framework that incorporates LoRA-enhanced DINOv2 embeddings and is guided by supervision from existing IQA methods. We train exclusively on synthetically generated distortions, deliberately avoiding overfitting to specific real NVS samples and thereby enhancing the model's generalization capability. Our model outperforms state-of-the-art FR-IQA, NR-IQA, and NAR-IQA methods, achieving robust performance on both aligned and non-aligned references. We also conducted a novel user study to gather data on human preferences when viewing non-aligned references in NVS. We find strong correlation between our proposed quality prediction model and the collected subjective ratings. For dataset and code, please visit our project page: https://stootaghaj.github.io/nova-project/

</details>


### [139] [KPLM-STA: Physically-Accurate Shadow Synthesis for Human Relighting via Keypoint-Based Light Modeling](https://arxiv.org/abs/2511.08169)
*Xinhui Yin,Qifei Li,Yilin Guo,Hongxia Xie,Xiaoli Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于关键点线性模型（KPLM）和阴影三角形算法（STA）的新型阴影生成框架，旨在解决图像合成中生成逼真且几何精确阴影的挑战，尤其针对复杂人体姿态，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 图像合成中，将前景对象无缝集成到背景中，生成逼真且几何精确的阴影仍然是一个持续的挑战。尽管扩散模型优于GAN，但现有技术（如扩散模型重光照框架IC-Light）在合成图像中生成具有高外观真实感和几何精度的阴影方面仍有不足。

Method: 本文提出了一个基于关键点线性模型（KPLM）和阴影三角形算法（STA）的新型阴影生成框架。KPLM使用九个关键点和一个边界框来建模关节式人体，实现物理上合理的阴影投射和关节动态着色，增强视觉真实感。STA通过明确的几何公式计算阴影角度、长度和空间位置，进一步提高几何精度。

Result: 广泛的实验表明，本文方法在阴影真实感基准测试中取得了最先进的性能，尤其是在复杂人体姿态下，并且能有效地推广到多方向重光照场景（如IC-Light支持的场景）。

Conclusion: 本文提出的KPLM和STA框架成功解决了现有方法在图像合成中生成逼真且几何精确阴影的局限性，特别是在处理复杂人体姿态时，展现出卓越的性能和泛化能力。

Abstract: Image composition aims to seamlessly integrate a foreground object into a background, where generating realistic and geometrically accurate shadows remains a persistent challenge. While recent diffusion-based methods have outperformed GAN-based approaches, existing techniques, such as the diffusion-based relighting framework IC-Light, still fall short in producing shadows with both high appearance realism and geometric precision, especially in composite images. To address these limitations, we propose a novel shadow generation framework based on a Keypoints Linear Model (KPLM) and a Shadow Triangle Algorithm (STA). KPLM models articulated human bodies using nine keypoints and one bounding block, enabling physically plausible shadow projection and dynamic shading across joints, thereby enhancing visual realism. STA further improves geometric accuracy by computing shadow angles, lengths, and spatial positions through explicit geometric formulations. Extensive experiments demonstrate that our method achieves state-of-the-art performance on shadow realism benchmarks, particularly under complex human poses, and generalizes effectively to multi-directional relighting scenarios such as those supported by IC-Light.

</details>


### [140] [Multi-Granularity Mutual Refinement Network for Zero-Shot Learning](https://arxiv.org/abs/2511.08163)
*Ning Wang,Long Yu,Cong Hua,Guangming Zhu,Lin Mei,Syed Afaq Ali Shah,Mohammed Bennamoun,Liang Zhang*

Main category: cs.CV

TL;DR: 零样本学习（ZSL）方法常忽略局部特征的内部交互。本文提出多粒度互精化网络（Mg-MRN），通过解耦的多粒度特征学习和跨粒度特征交互，提炼判别性与可迁移的视觉特征，显著提升ZSL性能。


<details>
  <summary>Details</summary>
Motivation: 现有ZSL方法在关联全局/局部视觉特征与语义信息时，往往忽略局部区域特征之间固有的交互作用，而这种交互能有效提升可迁移且明确视觉特征的获取。

Method: 本文提出多粒度互精化网络（Mg-MRN）。具体包括：1) 多粒度特征提取模块，通过解耦区域特征挖掘学习区域级判别性特征。2) 跨粒度特征融合模块，强化不同粒度区域特征间的内在交互，通过整合相邻层级的区域表示，增强各粒度级别表示的判别性。

Result: 在三个流行的ZSL基准数据集上进行了广泛实验，结果表明所提出的Mg-MRN方法具有优越性和竞争力。

Conclusion: Mg-MRN通过学习解耦的多粒度特征和跨粒度特征交互，有效提炼了判别性且可迁移的视觉特征，显著提升了零样本学习的识别性能。

Abstract: Zero-shot learning (ZSL) aims to recognize unseen classes with zero samples by transferring semantic knowledge from seen classes. Current approaches typically correlate global visual features with semantic information (i.e., attributes) or align local visual region features with corresponding attributes to enhance visual-semantic interactions. Although effective, these methods often overlook the intrinsic interactions between local region features, which can further improve the acquisition of transferable and explicit visual features. In this paper, we propose a network named Multi-Granularity Mutual Refinement Network (Mg-MRN), which refine discriminative and transferable visual features by learning decoupled multi-granularity features and cross-granularity feature interactions. Specifically, we design a multi-granularity feature extraction module to learn region-level discriminative features through decoupled region feature mining. Then, a cross-granularity feature fusion module strengthens the inherent interactions between region features of varying granularities. This module enhances the discriminability of representations at each granularity level by integrating region representations from adjacent hierarchies, further improving ZSL recognition performance. Extensive experiments on three popular ZSL benchmark datasets demonstrate the superiority and competitiveness of our proposed Mg-MRN method. Our code is available at https://github.com/NingWang2049/Mg-MRN.

</details>


### [141] [Distributed Zero-Shot Learning for Visual Recognition](https://arxiv.org/abs/2511.08170)
*Zhi Chen,Yadan Luo,Zi Huang,Jingjing Li,Sen Wang,Xin Yu*

Main category: cs.CV

TL;DR: 本文提出了一种分布式零样本学习（DistZSL）框架，通过引入跨节点属性正则化器和全局属性到视觉共识，有效利用去中心化数据并解决数据异构性问题，从而学习到针对未见类别的有效模型。


<details>
  <summary>Details</summary>
Motivation: 研究动机是充分利用去中心化数据来为未见类别学习一个有效的模型，同时解决分布式节点间的数据异构性问题。

Method: 本文提出了一个分布式零样本学习（DistZSL）框架。为确保有效学习，引入了两个关键组件：1. 跨节点属性正则化器，强制不同节点间的属性特征距离相似，以稳定属性特征空间并促进视觉到属性（V2A）关系的建立。2. 全局属性到视觉共识，通过强制属性和视觉特征分布之间的双边映射在不同节点间保持一致，以减轻单个节点学习到的有偏V2A映射。

Result: 广泛的实验表明，DistZSL在从分布式数据学习方面取得了优于现有最先进方法的性能。

Conclusion: DistZSL框架通过其提出的跨节点属性正则化器和全局属性到视觉共识，能够有效地从分布式数据中学习，显著增强了跨节点的零样本学习能力，并取得了卓越的性能。

Abstract: In this paper, we propose a Distributed Zero-Shot Learning (DistZSL) framework that can fully exploit decentralized data to learn an effective model for unseen classes. Considering the data heterogeneity issues across distributed nodes, we introduce two key components to ensure the effective learning of DistZSL: a cross-node attribute regularizer and a global attribute-to-visual consensus. Our proposed cross-node attribute regularizer enforces the distances between attribute features to be similar across different nodes. In this manner, the overall attribute feature space would be stable during learning, and thus facilitate the establishment of visual-to-attribute(V2A) relationships. Then, we introduce the global attribute-tovisual consensus to mitigate biased V2A mappings learned from individual nodes. Specifically, we enforce the bilateral mapping between the attribute and visual feature distributions to be consistent across different nodes. Thus, the learned consistent V2A mapping can significantly enhance zero-shot learning across different nodes. Extensive experiments demonstrate that DistZSL achieves superior performance to the state-of-the-art in learning from distributed data.

</details>


### [142] [2D Representation for Unguided Single-View 3D Super-Resolution in Real-Time](https://arxiv.org/abs/2511.08224)
*Ignasi Mas,Ivan Huerta,Ramon Morros,Javier Ruiz-Hidalgo*

Main category: cs.CV

TL;DR: 本文提出2Dto3D-SR框架，通过将单视角3D数据编码为2D表示（PNCC），实现无需高分辨率RGB指导的实时单视角3D超分辨率，并支持现有2D SR架构。


<details>
  <summary>Details</summary>
Motivation: 现有3D超分辨率方法通常需要高分辨率RGB指导或涉及复杂的3D点云处理，限制了其在高分辨率RGB数据不可用场景下的应用，因此需要一种更简单、高效且实用的解决方案。

Method: 2Dto3D-SR框架将单视角3D数据编码为结构化的2D表示。具体地，利用投影归一化坐标码（PNCC）将可见表面的3D几何表示为常规图像，从而规避了3D点基或RGB引导方法的复杂性。该设计允许直接应用现有的2D图像超分辨率架构。文中评估了两种实现：一种使用Swin Transformer追求高精度，另一种使用Vision Mamba追求高效率。

Result: 实验表明，基于Swin Transformer的模型在标准基准上实现了最先进的精度，而基于Vision Mamba的模型则在实时速度下提供了具有竞争力的结果。

Conclusion: 该几何引导的2Dto3D-SR管道被证明是一种出人意料地简单、可行且实用的解决方案，适用于真实世界的单视角3D超分辨率场景，尤其是在高分辨率RGB数据难以获取的情况下。

Abstract: We introduce 2Dto3D-SR, a versatile framework for real-time single-view 3D super-resolution that eliminates the need for high-resolution RGB guidance. Our framework encodes 3D data from a single viewpoint into a structured 2D representation, enabling the direct application of existing 2D image super-resolution architectures. We utilize the Projected Normalized Coordinate Code (PNCC) to represent 3D geometry from a visible surface as a regular image, thereby circumventing the complexities of 3D point-based or RGB-guided methods. This design supports lightweight and fast models adaptable to various deployment environments. We evaluate 2Dto3D-SR with two implementations: one using Swin Transformers for high accuracy, and another using Vision Mamba for high efficiency. Experiments show the Swin Transformer model achieves state-of-the-art accuracy on standard benchmarks, while the Vision Mamba model delivers competitive results at real-time speeds. This establishes our geometry-guided pipeline as a surprisingly simple yet viable and practical solution for real-world scenarios, especially where high-resolution RGB data is inaccessible.

</details>


### [143] [Pixel-level Quality Assessment for Oriented Object Detection](https://arxiv.org/abs/2511.08186)
*Yunhui Zhu,Buliao Huang*

Main category: cs.CV

TL;DR: 该研究提出了一种像素级质量评估（PQA）框架，以替代现有定向目标检测器中存在偏差的框级IoU预测，从而更准确地评估定位质量并显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现代定向目标检测器依赖于预测的定位质量来选择最佳边界框。然而，现有的框级IoU预测方法存在结构耦合问题，即预测框与估计的真实框之间的相似性可能导致对定位不佳的框的IoU过高估计，从而无法准确反映实际定位精度。

Method: 研究提出像素级质量评估（PQA）框架。该框架用像素级空间一致性整合取代了框级IoU预测。PQA测量每个像素相对于预测框的相对位置与相对于真实框的对应位置之间的一致性。通过在像素层面操作，PQA避免了直接比较预测框与估计的真实框，从而消除了框级IoU预测中固有的相似性偏差。此外，引入了一种新的整合度量来将像素级空间一致性聚合为统一的质量分数。

Result: PQA框架可以无缝集成到各种定向目标检测器中，并在HRSC2016和DOTA数据集上持续提升了性能。例如，在Rotated RetinaNet上AP$_{50:95}$提升了5.96%，在STD上提升了2.32%。

Conclusion: PQA通过采用像素级空间一致性评估，有效解决了框级IoU预测的结构耦合和相似性偏差问题，提供了更准确的定位质量近似，从而显著提高了定向目标检测器的性能。

Abstract: Modern oriented object detectors typically predict a set of bounding boxes and select the top-ranked ones based on estimated localization quality. Achieving high detection performance requires that the estimated quality closely aligns with the actual localization accuracy. To this end, existing approaches predict the Intersection over Union (IoU) between the predicted and ground-truth (GT) boxes as a proxy for localization quality. However, box-level IoU prediction suffers from a structural coupling issue: since the predicted box is derived from the detector's internal estimation of the GT box, the predicted IoU--based on their similarity--can be overestimated for poorly localized boxes. To overcome this limitation, we propose a novel Pixel-level Quality Assessment (PQA) framework, which replaces box-level IoU prediction with the integration of pixel-level spatial consistency. PQA measures the alignment between each pixel's relative position to the predicted box and its corresponding position to the GT box. By operating at the pixel level, PQA avoids directly comparing the predicted box with the estimated GT box, thereby eliminating the inherent similarity bias in box-level IoU prediction. Furthermore, we introduce a new integration metric that aggregates pixel-level spatial consistency into a unified quality score, yielding a more accurate approximation of the actual localization quality. Extensive experiments on HRSC2016 and DOTA demonstrate that PQA can be seamlessly integrated into various oriented object detectors, consistently improving performance (e.g., +5.96% AP$_{50:95}$ on Rotated RetinaNet and +2.32% on STD).

</details>


### [144] [VLMDiff: Leveraging Vision-Language Models for Multi-Class Anomaly Detection with Diffusion](https://arxiv.org/abs/2511.08173)
*Samet Hicsonmez,Abd El Rahman Shabayek,Djamila Aouada*

Main category: cs.CV

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Detecting visual anomalies in diverse, multi-class real-world images is a significant challenge. We introduce \ours, a novel unsupervised multi-class visual anomaly detection framework. It integrates a Latent Diffusion Model (LDM) with a Vision-Language Model (VLM) for enhanced anomaly localization and detection. Specifically, a pre-trained VLM with a simple prompt extracts detailed image descriptions, serving as additional conditioning for LDM training. Current diffusion-based methods rely on synthetic noise generation, limiting their generalization and requiring per-class model training, which hinders scalability. \ours, however, leverages VLMs to obtain normal captions without manual annotations or additional training. These descriptions condition the diffusion model, learning a robust normal image feature representation for multi-class anomaly detection. Our method achieves competitive performance, improving the pixel-level Per-Region-Overlap (PRO) metric by up to 25 points on the Real-IAD dataset and 8 points on the COCO-AD dataset, outperforming state-of-the-art diffusion-based approaches. Code is available at https://github.com/giddyyupp/VLMDiff.

</details>


### [145] [Remodeling Semantic Relationships in Vision-Language Fine-Tuning](https://arxiv.org/abs/2511.08238)
*Xiangyang Wu,Liu Liu,Baosheng Yu,Jiayan Qiu,Zhenwei Shi*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉-语言微调方法，通过利用语义和关系信息来改进多模态对齐和融合，在多个基础模型和下游任务上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言微调方法在对齐视觉和语言时，通常忽视文本上下文中的语义关系信息，导致性能不佳。

Method: 该方法首先从不同的视觉编码器中提取多级语义特征，以捕捉更多的视觉关系线索。然后，学习将视觉特征投影到相关的语义组中，这些组更有可能存在关系。最后，通过可继承的交叉注意力机制将视觉特征与文本特征融合，并通过丢弃低相关性的视觉-语言特征对来全局移除冗余的视觉关系。

Result: 所提出的方法在八个基础模型和视觉问答、图像字幕两个下游任务上进行了评估，结果表明其性能优于所有现有方法。

Conclusion: 该方法通过整合语义和关系信息，有效地改善了多模态对齐和融合，从而实现了卓越的性能。

Abstract: Vision-language fine-tuning has emerged as an efficient paradigm for constructing multimodal foundation models. While textual context often highlights semantic relationships within an image, existing fine-tuning methods typically overlook this information when aligning vision and language, thus leading to suboptimal performance. Toward solving this problem, we propose a method that can improve multimodal alignment and fusion based on both semantics and relationships.Specifically, we first extract multilevel semantic features from different vision encoder to capture more visual cues of the relationships. Then, we learn to project the vision features to group related semantics, among which are more likely to have relationships. Finally, we fuse the visual features with the textual by using inheritable cross-attention, where we globally remove the redundant visual relationships by discarding visual-language feature pairs with low correlation. We evaluate our proposed method on eight foundation models and two downstream tasks, visual question answering and image captioning, and show that it outperforms all existing methods.

</details>


### [146] [UCDSC: Open Set UnCertainty aware Deep Simplex Classifier for Medical Image Datasets](https://arxiv.org/abs/2511.08196)
*Arnav Aditya,Nitin Kumar,Saurabh Shigwan*

Main category: cs.CV

TL;DR: 本文提出了一种新的损失函数，通过利用辅助数据集惩罚开放空间区域，有效提高了医学领域开集识别的性能，在多个MedMNIST数据集和皮肤数据集上超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 深度学习在计算机辅助诊断中取得进展，但在实际应用中面临数据受限（伦理、法律、标注成本高）和处理未知类别（新发或罕见疾病）的挑战。开集识别（区分已知与未知类别）在此背景下至关重要。

Method: 该方法基于深度神经网络后期特征围绕其类均值（形成正则单纯形）聚集的观察。它引入了一个新的损失函数，通过使用辅助数据集惩罚开放空间区域来有效拒绝未知类别的样本。

Result: 该方法在BloodMNIST、OCTMNIST、DermaMNIST、TissueMNIST等四个MedMNIST数据集以及一个公开的皮肤数据集上取得了显著的性能提升，超越了现有最先进的技术。

Conclusion: 所提出的利用辅助数据集惩罚开放空间区域的损失函数，能够有效识别未知类别样本，显著提升了医学图像开集识别的性能，并超越了现有技术水平。

Abstract: Driven by advancements in deep learning, computer-aided diagnoses have made remarkable progress. However, outside controlled laboratory settings, algorithms may encounter several challenges. In the medical domain, these difficulties often stem from limited data availability due to ethical and legal restrictions, as well as the high cost and time required for expert annotations-especially in the face of emerging or rare diseases. In this context, open-set recognition plays a vital role by identifying whether a sample belongs to one of the known classes seen during training or should be rejected as an unknown. Recent studies have shown that features learned in the later stages of deep neural networks are observed to cluster around their class means, which themselves are arranged as individual vertices of a regular simplex [32]. The proposed method introduces a loss function designed to reject samples of unknown classes effectively by penalizing open space regions using auxiliary datasets. This approach achieves significant performance gain across four MedMNIST datasets-BloodMNIST, OCTMNIST, DermaMNIST, TissueMNIST and a publicly available skin dataset [29] outperforming state-of-the-art techniques.

</details>


### [147] [ImagebindDC: Compressing Multi-modal Data with Imagebind-based Condensation](https://arxiv.org/abs/2511.08263)
*Yue Min,Shaobo Wang,Jiaze Li,Tianle Niu,Junxin Fan,Yongliang Miao,Lijin Yang,Linfeng Zhang*

Main category: cs.CV

TL;DR: ImageBindDC是一种新颖的多模态数据凝结框架，利用ImageBind统一特征空间和特征函数（CF）损失，通过精确的无限矩匹配，在单模态、跨模态和联合模态层面实现统计对齐，显著提升了多模态数据凝结的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有数据凝结技术在单模态设置中表现良好，但在多模态场景中往往失效，因为它们难以保留复杂的模态间依赖关系。

Method: 该方法在ImageBind的统一特征空间中操作，并采用傅里叶域中的特征函数（CF）损失，通过精确的无限矩匹配实现更精确的统计对齐。其目标函数强制执行三个关键层次的分布一致性：(i) 单模态对齐，匹配每个模态内合成数据与真实数据的统计特性；(ii) 跨模态对齐，通过匹配混合真实-合成数据对的分布来保留成对语义；(iii) 联合模态对齐，通过对齐真实数据对及其合成对应物的联合分布来捕获完整的多元数据结构。

Result: 在NYU-v2数据集上，每个类别仅使用5个凝结数据点训练的模型，其性能与在完整数据集上训练的模型相当，实现了无损性能。该方法取得了8.2%的绝对提升，超越了先前最佳方法，并实现了超过4倍的凝结时间缩短，达到了新的最先进水平。

Conclusion: ImageBindDC通过在统一特征空间中利用特征函数损失进行精确的统计对齐，成功解决了多模态数据凝结的挑战，有效保留了模态间依赖关系，从而在性能和效率上取得了显著改进。

Abstract: Data condensation techniques aim to synthesize a compact dataset from a larger one to enable efficient model training, yet while successful in unimodal settings, they often fail in multimodal scenarios where preserving intricate inter-modal dependencies is crucial. To address this, we introduce ImageBindDC, a novel data condensation framework operating within the unified feature space of ImageBind. Our approach moves beyond conventional distribution-matching by employing a powerful Characteristic Function (CF) loss, which operates in the Fourier domain to facilitate a more precise statistical alignment via exact infinite moment matching. We design our objective to enforce three critical levels of distributional consistency: (i) uni-modal alignment, which matches the statistical properties of synthetic and real data within each modality; (ii) cross-modal alignment, which preserves pairwise semantics by matching the distributions of hybrid real-synthetic data pairs; and (iii) joint-modal alignment, which captures the complete multivariate data structure by aligning the joint distribution of real data pairs with their synthetic counterparts. Extensive experiments highlight the effectiveness of ImageBindDC: on the NYU-v2 dataset, a model trained on just 5 condensed datapoints per class achieves lossless performance comparable to one trained on the full dataset, achieving a new state-of-the-art with an 8.2\% absolute improvement over the previous best method and more than 4$\times$ less condensation time.

</details>


### [148] [Towards Open-Set Myoelectric Gesture Recognition via Dual-Perspective Inconsistency Learning](https://arxiv.org/abs/2511.08344)
*Chen Liu,Can Han,Weishi Xu,Yaqi Wang,Dahong Qian*

Main category: cs.CV

TL;DR: 本文提出了一种名为SASG-DA的新型扩散模型数据增强方法，用于sEMG手势识别，通过引入语义指导和稀疏感知采样策略，生成忠实且多样化的样本，有效缓解了数据稀缺导致的过拟合问题。


<details>
  <summary>Details</summary>
Motivation: sEMG手势识别系统常面临训练数据信息量不足的问题，导致深度学习模型过拟合和泛化能力差。现有数据增强方法虽然能增加数据，但若多样性目标不明确，可能产生冗余样本，效用有限。

Method: 本文提出Sparse-Aware Semantic-Guided Diffusion Augmentation (SASG-DA) 方法：
1.  **Semantic Representation Guidance (SRG)**：利用细粒度、任务感知的语义表示作为生成条件，增强生成样本的忠实性。
2.  **Gaussian Modeling Semantic Modeling (GMSS)**：建模语义表示分布并允许随机采样，以实现灵活多样的样本生成。
3.  **Sparse-Aware Semantic Sampling**：明确探索未充分表示的区域，增强目标多样性，提高分布覆盖率和样本效用。

Result: 在基准sEMG数据集Ninapro DB2、DB4和DB7上的大量实验表明，SASG-DA显著优于现有数据增强方法。

Conclusion: 所提出的数据增强方法通过提供忠实且多样化的样本，有效缓解了过拟合问题，并显著提高了识别性能和泛化能力。

Abstract: Surface electromyography (sEMG)-based gesture recognition plays a critical role in human-machine interaction (HMI), particularly for rehabilitation and prosthetic control. However, sEMG-based systems often suffer from the scarcity of informative training data, leading to overfitting and poor generalization in deep learning models. Data augmentation offers a promising approach to increasing the size and diversity of training data, where faithfulness and diversity are two critical factors to effectiveness. However, promoting untargeted diversity can result in redundant samples with limited utility. To address these challenges, we propose a novel diffusion-based data augmentation approach, Sparse-Aware Semantic-Guided Diffusion Augmentation (SASG-DA). To enhance generation faithfulness, we introduce the Semantic Representation Guidance (SRG) mechanism by leveraging fine-grained, task-aware semantic representations as generation conditions. To enable flexible and diverse sample generation, we propose a Gaussian Modeling Semantic Modeling (GMSS) strategy, which models the semantic representation distribution and allows stochastic sampling to produce both faithful and diverse samples. To enhance targeted diversity, we further introduce a Sparse-Aware Semantic Sampling strategy to explicitly explore underrepresented regions, improving distribution coverage and sample utility. Extensive experiments on benchmark sEMG datasets, Ninapro DB2, DB4, and DB7, demonstrate that SASG-DA significantly outperforms existing augmentation methods. Overall, our proposed data augmentation approach effectively mitigates overfitting and improves recognition performance and generalization by offering both faithful and diverse samples.

</details>


### [149] [Evaluating Gemini LLM in Food Image-Based Recipe and Nutrition Description with EfficientNet-B4 Visual Backbone](https://arxiv.org/abs/2511.08215)
*Rizal Khoirul Anam*

Main category: cs.CV

TL;DR: 本文评估了一个用于食物识别的多模态流水线，该流水线结合了视觉骨干网络（EfficientNet-B4）和大型语言模型（Gemini）。研究发现，尽管各组件表现良好，但系统的整体效用受限于视觉前端的识别准确性，语义相似性是主要挑战。


<details>
  <summary>Details</summary>
Motivation: 随着数字食物应用的普及，对自动化营养分析和烹饪指导的需求日益增长。现有公共数据集存在文化偏见，需要更鲁棒的方法和特定数据集来解决这些问题。

Method: 本文提出了一个解耦的多模态流水线，整合了专门的视觉骨干网络（EfficientNet-B4）和生成式大型语言模型（Google Gemini LLM）。该流水线与替代的视觉骨干网络（VGG-16, ResNet-50, YOLOv8）和轻量级LLM（Gemma）进行了基准测试。引入了“语义错误传播”（SEP）来分析视觉分类不准确性如何影响生成输出。研究基于一个新的定制中国食物数据集（CCFD）。

Result: 实验结果显示，EfficientNet-B4 在准确性（89.0% Top-1 Acc.）和效率之间提供了最佳平衡。Gemini 在生成质量（9.2/10 事实准确性）方面表现出色。然而，系统的整体效用根本上受限于视觉前端的感知准确性。详细的每类分析表明，高语义相似性是系统最关键的失效模式。

Conclusion: 尽管EfficientNet-B4和Gemini在各自领域表现优异，但视觉前端的感知准确性是当前多模态食物识别系统的主要瓶颈。解决高语义相似性导致的分类误差是提高系统整体实用性的关键。

Abstract: The proliferation of digital food applications necessitates robust methods for automated nutritional analysis and culinary guidance. This paper presents a comprehensive comparative evaluation of a decoupled, multimodal pipeline for food recognition. We evaluate a system integrating a specialized visual backbone (EfficientNet-B4) with a powerful generative large language model (Google's Gemini LLM). The core objective is to evaluate the trade-offs between visual classification accuracy, model efficiency, and the quality of generative output (nutritional data and recipes). We benchmark this pipeline against alternative vision backbones (VGG-16, ResNet-50, YOLOv8) and a lightweight LLM (Gemma). We introduce a formalization for "Semantic Error Propagation" (SEP) to analyze how classification inaccuracies from the visual module cascade into the generative output. Our analysis is grounded in a new Custom Chinese Food Dataset (CCFD) developed to address cultural bias in public datasets. Experimental results demonstrate that while EfficientNet-B4 (89.0\% Top-1 Acc.) provides the best balance of accuracy and efficiency, and Gemini (9.2/10 Factual Accuracy) provides superior generative quality, the system's overall utility is fundamentally bottlenecked by the visual front-end's perceptive accuracy. We conduct a detailed per-class analysis, identifying high semantic similarity as the most critical failure mode.

</details>


### [150] [UI2Code$^\text{N}$: A Visual Language Model for Test-Time Scalable Interactive UI-to-Code Generation](https://arxiv.org/abs/2511.08195)
*Zhen Yang,Wenyi Hong,Mingde Xu,Xinyue Fan,Weihan Wang,Jiele Cheng,Xiaotao Gu,Jie Tang*

Main category: cs.CV

TL;DR: 该研究提出一种交互式UI到代码范式，并开发了UI2Code^N视觉语言模型，通过多模态编码、编辑和优化，并利用多轮反馈，显著提升了UI自动编码性能，达到开源模型中的SOTA，并与顶级闭源模型相当。


<details>
  <summary>Details</summary>
Motivation: UI编程复杂且核心，现有视觉语言模型（VLMs）在自动UI编码方面存在两个主要限制：多模态编码能力不完善，以及单轮范式未能有效利用迭代视觉反馈。

Method: 研究提出一个交互式UI到代码范式，更好地反映真实工作流程。在此范式下，开发了UI2Code^N视觉语言模型，通过分阶段预训练、微调和强化学习进行训练。该模型统一了UI到代码生成、UI编辑和UI优化三项关键能力。此外，探索了交互式生成的测试时扩展，以系统地利用多轮反馈。

Result: UI2Code^N在UI到代码和UI优化基准测试中，在开源模型中建立了新的最先进水平，并且性能与领先的闭源模型（如Claude-4-Sonnet和GPT-5）相当。

Conclusion: 通过引入交互式UI到代码范式和UI2Code^N模型，本研究在多模态编码和迭代视觉反馈方面取得了基础性改进，显著提升了UI自动编码的性能，达到了与顶级商业模型相媲美的水平。

Abstract: User interface (UI) programming is a core yet highly complex part of modern software development. Recent advances in visual language models (VLMs) highlight the potential of automatic UI coding, but current approaches face two key limitations: multimodal coding capabilities remain underdeveloped, and single-turn paradigms make little use of iterative visual feedback. We address these challenges with an interactive UI-to-code paradigm that better reflects real-world workflows and raises the upper bound of achievable performance. Under this paradigm, we present UI2Code$^\text{N}$, a visual language model trained through staged pretraining, fine-tuning, and reinforcement learning to achieve foundational improvements in multimodal coding. The model unifies three key capabilities: UI-to-code generation, UI editing, and UI polishing. We further explore test-time scaling for interactive generation, enabling systematic use of multi-turn feedback. Experiments on UI-to-code and UI polishing benchmarks show that UI2Code$^\text{N}$ establishes a new state of the art among open-source models and achieves performance comparable to leading closed-source models such as Claude-4-Sonnet and GPT-5. Our code and models are available at https://github.com/zai-org/UI2Code_N.

</details>


### [151] [Hierarchical Direction Perception via Atomic Dot-Product Operators for Rotation-Invariant Point Clouds Learning](https://arxiv.org/abs/2511.08240)
*Chenyu Hu,Xiaotong Li,Hao Zhu,Biao Hou*

Main category: cs.CV

TL;DR: 本文提出了一种名为DiPVNet的点云处理网络，通过原子点积操作符同时实现旋转不变性和自适应方向感知，显著提升了点云分类和分割的性能。


<details>
  <summary>Details</summary>
Motivation: 点云处理中任意旋转引入的姿态变化是表示学习的长期挑战，会破坏点云固有的方向特性。现有方法未能充分利用点云的多尺度方向性来增强特征表示。

Method: 本文提出了方向感知向量网络（DiPVNet）。核心是一个原子点积操作符，它同时编码方向选择性和旋转不变性。在局部层面，引入了可学习局部点积（L2DP）操作符，用于自适应捕获非均匀局部结构。在全局层面，利用广义谐波分析证明点云与球面采样向量的点积等同于方向感知球面傅里叶变换（DASFT），从而构建全局方向响应谱。对两种操作符的旋转不变性进行了严格证明。

Result: DiPVNet在涉及噪声和大幅度旋转的挑战性场景中，点云分类和分割任务上均取得了最先进的性能。

Conclusion: DiPVNet通过其独特的点积操作符，成功解决了点云旋转不变性和方向感知的难题，并实现了优越的性能，证明了其在三维视觉任务中的有效性。

Abstract: Point cloud processing has become a cornerstone technology in many 3D vision tasks. However, arbitrary rotations introduce variations in point cloud orientations, posing a long-standing challenge for effective representation learning. The core of this issue is the disruption of the point cloud's intrinsic directional characteristics caused by rotational perturbations. Recent methods attempt to implicitly model rotational equivariance and invariance, preserving directional information and propagating it into deep semantic spaces. Yet, they often fall short of fully exploiting the multiscale directional nature of point clouds to enhance feature representations. To address this, we propose the Direction-Perceptive Vector Network (DiPVNet). At its core is an atomic dot-product operator that simultaneously encodes directional selectivity and rotation invariance--endowing the network with both rotational symmetry modeling and adaptive directional perception. At the local level, we introduce a Learnable Local Dot-Product (L2DP) Operator, which enables interactions between a center point and its neighbors to adaptively capture the non-uniform local structures of point clouds. At the global level, we leverage generalized harmonic analysis to prove that the dot-product between point clouds and spherical sampling vectors is equivalent to a direction-aware spherical Fourier transform (DASFT). This leads to the construction of a global directional response spectrum for modeling holistic directional structures. We rigorously prove the rotation invariance of both operators. Extensive experiments on challenging scenarios involving noise and large-angle rotations demonstrate that DiPVNet achieves state-of-the-art performance on point cloud classification and segmentation tasks. Our code is available at https://github.com/wxszreal0/DiPVNet.

</details>


### [152] [Accurate and Efficient Surface Reconstruction from Point Clouds via Geometry-Aware Local Adaptation](https://arxiv.org/abs/2511.08233)
*Eito Ogawa,Taiga Hayami,Hiroshi Watanabe*

Main category: cs.CV

TL;DR: 本研究提出一种方法，通过根据点云曲率自适应调整局部区域的间距和大小，来提高点云表面重建的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 深度学习在点云表面重建方面取得了进展，但现有基于局部区域的重建方法通常均匀放置并固定局部区域大小，限制了其对几何复杂性变化的适应性，影响了重建准确性和效率。

Method: 本研究提出一种方法，根据输入点云的曲率自适应地调整局部区域的间距和大小。

Result: 所提出的方法能够提高重建的准确性和效率。

Conclusion: 通过自适应地调制局部区域的间距和大小，可以显著改善点云表面重建的准确性和效率，克服了以往方法在适应几何复杂性方面的局限性。

Abstract: Point cloud surface reconstruction has improved in accuracy with advances in deep learning, enabling applications such as infrastructure inspection. Recent approaches that reconstruct from small local regions rather than entire point clouds have attracted attention for their strong generalization capability. However, prior work typically places local regions uniformly and keeps their size fixed, limiting adaptability to variations in geometric complexity. In this study, we propose a method that improves reconstruction accuracy and efficiency by adaptively modulating the spacing and size of local regions based on the curvature of the input point cloud.

</details>


### [153] [Extreme Model Compression with Structured Sparsity at Low Precision](https://arxiv.org/abs/2511.08360)
*Dan Liu,Nikita Dvornik,Xue Liu*

Main category: cs.CV

TL;DR: 本文提出SLOPE框架，有效结合结构化稀疏性与低比特量化，显著减小深度神经网络模型尺寸，同时保持高精度，超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络庞大且计算成本高昂，难以在资源受限设备上部署。尽管权重稀疏化和量化是有效技术，但由于它们叠加对模型精度的负面影响，通常单独研究，难以有效结合。

Method: 引入SLOPE（Structured Sparsity at Low Precision）统一框架，以原则性的方式结合结构化稀疏性和低比特量化。提出一种训练时正则化策略，通过促进角度对齐而非直接匹配，最小化全精度权重与稀疏、量化权重之间的差异。

Result: 在ResNet-18上，SLOPE实现了约20倍的模型尺寸减小，同时保持了约99%的原始精度。在ResNet-18、ViT-Small和Mask R-CNN等模型上，SLOPE在分类、检测和分割任务中均持续优于最先进的量化和结构化稀疏方法。

Conclusion: SLOPE成功地将结构化稀疏性与低比特量化结合起来，克服了两者结合时精度下降的问题。它能有效减小模型尺寸并保持高精度，在多项任务和模型上均表现出色，优于现有独立技术。

Abstract: Deep neural networks (DNNs) are used in many applications, but their large size and high computational cost make them hard to run on devices with limited resources. Two widely used techniques to address this challenge are weight quantization, which lowers the precision of all weights, and structured sparsity, which removes unimportant weights while retaining the important ones at full precision. Although both are effective individually, they are typically studied in isolation due to their compounded negative impact on model accuracy when combined. In this work, we introduce SLOPE Structured Sparsity at Low Precision), a unified framework, to effectively combine structured sparsity and low-bit quantization in a principled way. We show that naively combining sparsity and quantization severely harms performance due to the compounded impact of both techniques. To address this, we propose a training-time regularization strategy that minimizes the discrepancy between full-precision weights and their sparse, quantized counterparts by promoting angular alignment rather than direct matching. On ResNet-18, SLOPE achieves $\sim20\times$ model size reduction while retaining $\sim$99% of the original accuracy. It consistently outperforms state-of-the-art quantization and structured sparsity methods across classification, detection, and segmentation tasks on models such as ResNet-18, ViT-Small, and Mask R-CNN.

</details>


### [154] [WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting](https://arxiv.org/abs/2511.08178)
*Kaitao Huang,Yan Yan,Jing-Hao Xue,Hanzi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为WarpGAN的3D GAN反演方法，通过结合图像扭曲和修复策略，解决了现有方法在单视角新颖视图合成中对遮挡区域生成质量差的问题，显著提升了生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有的3D GAN反演方法在单视角新颖视图合成时，主要关注可见区域的重建，而遮挡区域的生成仅依赖3D GAN的生成先验。由于低比特率潜在代码导致信息丢失，生成的遮挡区域通常质量较差。

Method: WarpGAN方法首先使用3D GAN反演编码器将单视角图像投影到潜在代码。然后，利用3D GAN生成的深度图对图像进行扭曲以生成新视角。最后，引入了一个新颖的SVINet，利用对称先验和同一潜在代码下的多视角图像对应关系，对扭曲图像中的遮挡区域进行修复。

Result: 定量和定性实验表明，WarpGAN方法在性能上持续优于几种最先进的方法。

Conclusion: WarpGAN通过引入扭曲和修复策略，有效地解决了3D GAN反演在新颖视图合成中遮挡区域质量不佳的问题，实现了高保真度可见区域和真实、多视角一致性遮挡区域的生成。

Abstract: 3D GAN inversion projects a single image into the latent space of a pre-trained 3D GAN to achieve single-shot novel view synthesis, which requires visible regions with high fidelity and occluded regions with realism and multi-view consistency. However, existing methods focus on the reconstruction of visible regions, while the generation of occluded regions relies only on the generative prior of 3D GAN. As a result, the generated occluded regions often exhibit poor quality due to the information loss caused by the low bit-rate latent code. To address this, we introduce the warping-and-inpainting strategy to incorporate image inpainting into 3D GAN inversion and propose a novel 3D GAN inversion method, WarpGAN. Specifically, we first employ a 3D GAN inversion encoder to project the single-view image into a latent code that serves as the input to 3D GAN. Then, we perform warping to a novel view using the depth map generated by 3D GAN. Finally, we develop a novel SVINet, which leverages the symmetry prior and multi-view image correspondence w.r.t. the same latent code to perform inpainting of occluded regions in the warped image. Quantitative and qualitative experiments demonstrate that our method consistently outperforms several state-of-the-art methods.

</details>


### [155] [NERVE: Neighbourhood & Entropy-guided Random-walk for training free open-Vocabulary sEgmentation](https://arxiv.org/abs/2511.08248)
*Kunal Mahatha,Jose Dolz,Christian Desrosiers*

Main category: cs.CV

TL;DR: NERVE是一种无需训练的开放词汇语义分割基线，它通过整合全局和局部信息、引入随机游走以及基于熵的不确定性选择自注意力图，实现了最先进的零样本分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无需训练的开放词汇语义分割方法存在局限性，包括计算成本高昂的亲和度细化策略、由于等权重或依赖固定大小的高斯核导致Transformer注意力图融合效率低下，以及强制各向同性邻域，未能有效处理任意形状的对象。

Method: 本文提出了NERVE（Neighbourhood & Entropy-guided Random-walk for open-Vocabulary sEgmentation），该方法独特地整合了全局和细粒度局部信息，利用稳定扩散模型自注意力层的邻域结构。它引入了随机游走来细化亲和度，而非依赖固定大小的高斯核，以鼓励在连接和语义相关区域的传播。此外，该方法使用基于熵的不确定性来选择最相关的Transformer注意力图，而非对不同注意力头或层一视同仁。

Result: NERVE在7个流行的语义分割基准上进行了实验，取得了总体最先进的零样本分割性能。值得注意的是，该方法无需传统的后处理技术，如条件随机场（CRF）或像素自适应掩码细化（PAMR）。

Conclusion: NERVE提供了一种有效的开放词汇语义分割方法，通过其独特的全局-局部信息整合、随机游走亲和度细化和基于熵的注意力图选择机制，克服了现有方法的局限性，并实现了卓越的零样本分割表现。

Abstract: Despite recent advances in Open-Vocabulary Semantic Segmentation (OVSS), existing training-free methods face several limitations: use of computationally expensive affinity refinement strategies, ineffective fusion of transformer attention maps due to equal weighting or reliance on fixed-size Gaussian kernels to reinforce local spatial smoothness, enforcing isotropic neighborhoods. We propose a strong baseline for training-free OVSS termed as NERVE (Neighbourhood \& Entropy-guided Random-walk for open-Vocabulary sEgmentation), which uniquely integrates global and fine-grained local information, exploiting the neighbourhood structure from the self-attention layer of a stable diffusion model. We also introduce a stochastic random walk for refining the affinity rather than relying on fixed-size Gaussian kernels for local context. This spatial diffusion process encourages propagation across connected and semantically related areas, enabling it to effectively delineate objects with arbitrary shapes. Whereas most existing approaches treat self-attention maps from different transformer heads or layers equally, our method uses entropy-based uncertainty to select the most relevant maps. Notably, our method does not require any conventional post-processing techniques like Conditional Random Fields (CRF) or Pixel-Adaptive Mask Refinement (PAMR). Experiments are performed on 7 popular semantic segmentation benchmarks, yielding an overall state-of-the-art zero-shot segmentation performance, providing an effective approach to open-vocabulary semantic segmentation.

</details>


### [156] [Twist and Compute: The Cost of Pose in 3D Generative Diffusion](https://arxiv.org/abs/2511.08203)
*Kyle Fogarty,Jack Foster,Boqiao Zhang,Jing Yang,Cengiz Öztireli*

Main category: cs.CV

TL;DR: 大型图像到3D生成模型存在规范视角偏置，导致处理旋转输入时性能下降。研究发现通过轻量级CNN校正输入方向可恢复性能，并提出是否应追求模块化、对称性感知的设计。


<details>
  <summary>Details</summary>
Motivation: 尽管大型图像到3D生成模型表现出色，但其归纳偏置不透明。研究发现一个显著限制是强大的“规范视角偏置”，导致模型在面对旋转输入时泛化能力不足。

Method: 通过受控实验，使用简单的2D旋转来测试最先进的Hunyuan3D 2.0模型。提出并应用一个轻量级CNN来检测和校正输入图像的朝向，以缓解性能下降问题。

Result: Hunyuan3D 2.0模型在处理旋转输入时难以泛化，性能会下降。通过一个轻量级CNN检测并校正输入朝向，可以在不修改生成骨干网络的情况下恢复模型性能。

Conclusion: 图像条件3D生成模型存在规范视角偏置问题。通过引入轻量级、对称性感知的模块可以有效缓解这一问题。研究提出了一个重要开放性问题：仅靠模型规模是否足够，还是应该追求模块化、对称性感知的设计。

Abstract: Despite their impressive results, large-scale image-to-3D generative models remain opaque in their inductive biases. We identify a significant limitation in image-conditioned 3D generative models: a strong canonical view bias. Through controlled experiments using simple 2D rotations, we show that the state-of-the-art Hunyuan3D 2.0 model can struggle to generalize across viewpoints, with performance degrading under rotated inputs. We show that this failure can be mitigated by a lightweight CNN that detects and corrects input orientation, restoring model performance without modifying the generative backbone. Our findings raise an important open question: Is scale enough, or should we pursue modular, symmetry-aware designs?

</details>


### [157] [Text-based Aerial-Ground Person Retrieval](https://arxiv.org/abs/2511.08369)
*Xinyu Zhou,Yu Wu,Jiayao Ma,Wenhao Wang,Min Cao,Mang Ye*

Main category: cs.CV

TL;DR: 本文提出文本辅助空中-地面行人检索（TAG-PR）任务，旨在通过文本描述从异构的空中和地面视角检索行人图像。为解决大视角差异的挑战，作者贡献了TAG-PEDES数据集和TAG-CLIP框架。


<details>
  <summary>Details</summary>
Motivation: 传统的文本辅助行人检索（T-PR）仅关注地面视角图像，而空中-地面行人检索（TAG-PR）具有更大的实际意义。然而，空中和地面图像之间巨大的视角差异带来了独特的挑战，需要新的方法来处理这种异构性。

Method: 本文提出了两项主要贡献：
1.  **TAG-PEDES数据集**：通过现有基准数据集构建，并利用多样化的文本生成范式自动生成文本描述，以确保在视角异构性下的鲁棒性。
2.  **TAG-CLIP框架**：一个新颖的检索框架，通过分层路由的专家混合模块来学习视角特定和视角无关的特征，并采用视角解耦策略来解耦视角特定特征，以实现更好的跨模态对齐，从而解决视角异构性问题。

Result: TAG-CLIP框架在所提出的TAG-PEDES数据集和现有的T-PR基准数据集上均表现出有效性。

Conclusion: 本文成功引入了文本辅助空中-地面行人检索（TAG-PR）任务，并为此任务构建了新的数据集TAG-PEDES。同时，提出的TAG-CLIP框架有效解决了空中和地面视角之间巨大的异构性挑战，为跨视角行人检索提供了新的解决方案。

Abstract: This work introduces Text-based Aerial-Ground Person Retrieval (TAG-PR), which aims to retrieve person images from heterogeneous aerial and ground views with textual descriptions. Unlike traditional Text-based Person Retrieval (T-PR), which focuses solely on ground-view images, TAG-PR introduces greater practical significance and presents unique challenges due to the large viewpoint discrepancy across images. To support this task, we contribute: (1) TAG-PEDES dataset, constructed from public benchmarks with automatically generated textual descriptions, enhanced by a diversified text generation paradigm to ensure robustness under view heterogeneity; and (2) TAG-CLIP, a novel retrieval framework that addresses view heterogeneity through a hierarchically-routed mixture of experts module to learn view-specific and view-agnostic features and a viewpoint decoupling strategy to decouple view-specific features for better cross-modal alignment. We evaluate the effectiveness of TAG-CLIP on both the proposed TAG-PEDES dataset and existing T-PR benchmarks. The dataset and code are available at https://github.com/Flame-Chasers/TAG-PR.

</details>


### [158] [Top2Ground: A Height-Aware Dual Conditioning Diffusion Model for Robust Aerial-to-Ground View Generation](https://arxiv.org/abs/2511.08258)
*Jae Joong Lee,Bedrich Benes*

Main category: cs.CV

TL;DR: Top2Ground是一种新型的基于扩散的方法，可以直接从航拍图像生成逼真的地面视角图像，无需中间表示，并在多个数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 由于视角差异巨大、遮挡和视野有限，从航拍图像生成地面视角图像是一项极具挑战性的任务。现有方法可能依赖于深度图或3D体素等中间表示。

Method: Top2Ground是一种基于扩散的方法，通过将去噪过程条件化于以下两者的联合表示来生成图像：1) VAE编码的空间特征（来源于航拍RGB图像和估计的高度图），以及2) 基于CLIP的语义嵌入。这种设计确保了生成图像在几何上受场景3D结构约束，并在语义上与内容保持一致。

Result: Top2Ground在CVUSA、CVACT和Auto Arborist三个多样化数据集上进行了评估。结果显示，该方法在三个基准数据集上的SSIM平均提高了7.3%，表明Top2Ground能够稳健处理宽视野和窄视野，展示了其强大的泛化能力。

Conclusion: Top2Ground成功地实现了从航拍图像直接生成逼真的地面视角图像，无需中间表示，并在几何和语义上保持一致性，表现出优越的性能和强大的泛化能力。

Abstract: Generating ground-level images from aerial views is a challenging task due to extreme viewpoint disparity, occlusions, and a limited field of view. We introduce Top2Ground, a novel diffusion-based method that directly generates photorealistic ground-view images from aerial input images without relying on intermediate representations such as depth maps or 3D voxels. Specifically, we condition the denoising process on a joint representation of VAE-encoded spatial features (derived from aerial RGB images and an estimated height map) and CLIP-based semantic embeddings. This design ensures the generation is both geometrically constrained by the scene's 3D structure and semantically consistent with its content. We evaluate Top2Ground on three diverse datasets: CVUSA, CVACT, and the Auto Arborist. Our approach shows 7.3% average improvement in SSIM across three benchmark datasets, showing Top2Ground can robustly handle both wide and narrow fields of view, highlighting its strong generalization capabilities.

</details>


### [159] [A Circular Argument : Does RoPE need to be Equivariant for Vision?](https://arxiv.org/abs/2511.08368)
*Chase van de Geijn,Timo Lüddecke,Polina Turishcheva,Alexander S. Ecker*

Main category: cs.CV

TL;DR: 本文从数学上证明了RoPE是1D数据等变位置嵌入最通用的解决方案之一，并提出了M维数据的通用解决方案Mixed RoPE。通过引入假设非交换生成器的Spherical RoPE，作者质疑了严格等变性对RoPE性能的重要性，发现Spherical RoPE性能等同或更好，表明相对位置嵌入可能不像普遍认为的那样重要。


<details>
  <summary>Details</summary>
Motivation: RoPE在NLP的1D序列中非常成功，并被尝试推广到图像和视频等高维数据。RoPE的成功常被归因于其位置等变性。本研究旨在从数学上深入理解RoPE的通用性，并质疑严格等变性是否是其成功的关键因素。

Method: 1. 从数学上证明RoPE是1D数据等变位置嵌入最通用的解决方案之一。2. 提出Mixed RoPE作为M维数据的通用解决方案，该方案要求交换生成器（RoPE等变性所需）。3. 提出Spherical RoPE，它类似于Mixed RoPE，但假设非交换生成器，以检验严格等变性的作用。4. 通过实证比较Spherical RoPE与其等变模拟的RoPE的学习行为。

Result: 1. RoPE被数学证明为1D数据等变位置嵌入最通用的解决方案之一。2. Mixed RoPE被提出作为M维数据（要求交换生成器）的通用解决方案。3. 经验发现，Spherical RoPE（非交换生成器）与等变模拟的RoPE相比，具有同等或更好的学习行为。4. 这一结果表明，相对位置嵌入的重要性可能不像普遍认为的那么大，至少在计算机视觉领域是如此。

Conclusion: RoPE在1D数据中具有高度的通用性，且Mixed RoPE是其在高维数据中的推广。严格的位置等变性（即相对位置嵌入）可能不是RoPE成功的关键因素，尤其是在计算机视觉中。这一发现有望促进视觉领域中位置编码的未来工作，通过消除必须是相对位置的先入为主的观念，从而实现更快、泛化更好的方法。

Abstract: Rotary Positional Encodings (RoPE) have emerged as a highly effective technique for one-dimensional sequences in Natural Language Processing spurring recent progress towards generalizing RoPE to higher-dimensional data such as images and videos. The success of RoPE has been thought to be due to its positional equivariance, i.e. its status as a relative positional encoding. In this paper, we mathematically show RoPE to be one of the most general solutions for equivariant positional embedding in one-dimensional data. Moreover, we show Mixed RoPE to be the analogously general solution for M-dimensional data, if we require commutative generators -- a property necessary for RoPE's equivariance. However, we question whether strict equivariance plays a large role in RoPE's performance. We propose Spherical RoPE, a method analogous to Mixed RoPE, but assumes non-commutative generators. Empirically, we find Spherical RoPE to have the equivalent or better learning behavior compared to its equivariant analogues. This suggests that relative positional embeddings are not as important as is commonly believed, at least within computer vision. We expect this discovery to facilitate future work in positional encodings for vision that can be faster and generalize better by removing the preconception that they must be relative.

</details>


### [160] [SWAN - Enabling Fast and Mobile Histopathology Image Annotation through Swipeable Interfaces](https://arxiv.org/abs/2511.08271)
*Sweta Banerjee,Timo Gosch,Sara Hester,Viktoria Weiss,Thomas Conrad,Taryn A. Donovan,Nils Porsche,Jonas Ammeling,Christoph Stroblberger,Robert Klopfleisch,Christopher Kaltenecker,Christof A. Bertram,Katharina Breininger,Marc Aubreville*

Main category: cs.CV

TL;DR: 本文介绍SWAN，一款开源的、基于滑动手势的网页应用，用于加速组织病理学图像的标注，并在准确性与传统方法相当的同时，显著提升了标注效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 大规模组织病理学图像数据集的标注是开发稳健深度学习模型（如丝分裂像分类）的主要瓶颈。传统的基于文件夹的标注工作流程通常缓慢、耗费精力且难以扩展。

Method: 研究者开发了SWAN（SWipeable ANnotations），一个开源的、MIT许可的网页应用，通过滑动手势实现直观的图像块分类。SWAN支持桌面和移动平台，提供实时元数据捕获，并允许灵活地将滑动手势映射到类别标签。通过一项包含四名病理学家标注600个丝分裂像图像块的试点研究，将SWAN与传统的文件夹排序工作流程进行了比较。

Result: SWAN实现了快速标注，配对百分比一致性范围为86.52%至93.68%（Cohen's Kappa = 0.61-0.80），而文件夹方法的配对百分比一致性范围为86.98%至91.32%（Cohen's Kappa = 0.63-0.75），表明标注者之间具有高度一致性且性能相当。参与者评价该工具高度可用，并赞赏在移动设备上进行标注的能力。

Conclusion: 研究结果表明，SWAN可以在保持标注质量的同时加速图像标注，为传统工作流程提供了一个可扩展且用户友好的替代方案。

Abstract: The annotation of large scale histopathology image datasets remains a major bottleneck in developing robust deep learning models for clinically relevant tasks, such as mitotic figure classification. Folder-based annotation workflows are usually slow, fatiguing, and difficult to scale. To address these challenges, we introduce SWipeable ANnotations (SWAN), an open-source, MIT-licensed web application that enables intuitive image patch classification using a swiping gesture. SWAN supports both desktop and mobile platforms, offers real-time metadata capture, and allows flexible mapping of swipe gestures to class labels. In a pilot study with four pathologists annotating 600 mitotic figure image patches, we compared SWAN against a traditional folder-sorting workflow. SWAN enabled rapid annotations with pairwise percent agreement ranging from 86.52% to 93.68% (Cohen's Kappa = 0.61-0.80), while for the folder-based method, the pairwise percent agreement ranged from 86.98% to 91.32% (Cohen's Kappa = 0.63-0.75) for the task of classifying atypical versus normal mitotic figures, demonstrating high consistency between annotators and comparable performance. Participants rated the tool as highly usable and appreciated the ability to annotate on mobile devices. These results suggest that SWAN can accelerate image annotation while maintaining annotation quality, offering a scalable and user-friendly alternative to conventional workflows.

</details>


### [161] [MAUGIF: Mechanism-Aware Unsupervised General Image Fusion via Dual Cross-Image Autoencoders](https://arxiv.org/abs/2511.08272)
*Kunjing Yang,Zhiwei Wang,Minru Bai*

Main category: cs.CV

TL;DR: 本文提出了一种机制感知的无监督通用图像融合（MAUGIF）方法，基于双交叉图像自编码器，通过区分加性与乘性融合机制，实现了对多源图像信息的有效整合，提升了性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有图像融合方法要么高度任务专用，要么是通用框架但对不同融合任务采用统一策略，忽略了它们独特的融合机制，导致性能受限。

Method: 本文提出MAUGIF方法，核心是双交叉图像自编码器。首先，根据不同融合任务的内在机制，将融合分为加性和乘性。然后，双编码器将源图像映射到共享潜在空间以捕获共同内容，并分离模态特定细节。在解码阶段，双解码器作为特征注入器，选择性地将每种模态的独特特征重新整合到共享内容中进行重建。融合过程中，模态特定特征被注入到源图像中。解码器的架构根据其融合机制而变化，以提高性能和可解释性。

Result: 在各种融合任务上进行了大量实验，验证了所提方法的有效性和泛化能力。

Conclusion: MAUGIF方法通过机制感知、无监督和通用框架，成功解决了现有融合方法的局限性，能够有效整合多源图像信息，并提升了融合性能和可解释性。

Abstract: Image fusion aims to integrate structural and complementary information from multi-source images. However, existing fusion methods are often either highly task-specific, or general frameworks that apply uniform strategies across diverse tasks, ignoring their distinct fusion mechanisms. To address this issue, we propose a mechanism-aware unsupervised general image fusion (MAUGIF) method based on dual cross-image autoencoders. Initially, we introduce a classification of additive and multiplicative fusion according to the inherent mechanisms of different fusion tasks. Then, dual encoders map source images into a shared latent space, capturing common content while isolating modality-specific details. During the decoding phase, dual decoders act as feature injectors, selectively reintegrating the unique characteristics of each modality into the shared content for reconstruction. The modality-specific features are injected into the source image in the fusion process, generating the fused image that integrates information from both modalities. The architecture of decoders varies according to their fusion mechanisms, enhancing both performance and interpretability. Extensive experiments are conducted on diverse fusion tasks to validate the effectiveness and generalization ability of our method. The code is available at https://anonymous.4open.science/r/MAUGIF.

</details>


### [162] [RAPTR: Radar-based 3D Pose Estimation using Transformer](https://arxiv.org/abs/2511.08387)
*Sorachi Kato,Ryoma Yataka,Pu Perry Wang,Pedro Miraldo,Takuya Fujihashi,Petros Boufounos*

Main category: cs.CV

TL;DR: 本文提出RAPTR，一种基于弱监督（仅使用3D BBox和2D关键点标签）的雷达3D人体姿态估计算法，通过两阶段Transformer解码器和特定损失函数显著提高了在复杂室内环境中的姿态估计精度。


<details>
  <summary>Details</summary>
Motivation: 雷达3D人体姿态估计传统上依赖昂贵的细粒度3D关键点标签，尤其是在包含杂物、遮挡或多人的复杂室内环境中，这些标签难以获取。因此，需要一种能利用更易于收集的弱监督标签的方法。

Method: 本文提出了RAPTR（RAdar Pose esTimation using tRansformer），它采用弱监督（仅3D BBox和2D关键点标签）。RAPTR具有两阶段姿态解码器架构：
1.  **姿态解码器**：利用伪3D可变形注意力增强查询与多视角雷达特征的融合，并通过设计用于3D BBox标签的3D模板损失来估计初始3D姿态并缓解深度模糊。
2.  **关节解码器**：使用2D关键点标签和3D重力损失对初始姿态进行精修。

Result: RAPTR在两个室内雷达数据集上进行了评估，结果显示其性能优于现有方法，在HIBER数据集上将关节位置误差降低了34.3%，在MMVR数据集上降低了76.9%。

Conclusion: RAPTR通过创新的两阶段Transformer架构和针对弱监督设计的损失函数，有效解决了雷达3D人体姿态估计中标签获取困难的问题，并在精度上取得了显著提升。

Abstract: Radar-based indoor 3D human pose estimation typically relied on fine-grained 3D keypoint labels, which are costly to obtain especially in complex indoor settings involving clutter, occlusions, or multiple people. In this paper, we propose \textbf{RAPTR} (RAdar Pose esTimation using tRansformer) under weak supervision, using only 3D BBox and 2D keypoint labels which are considerably easier and more scalable to collect. Our RAPTR is characterized by a two-stage pose decoder architecture with a pseudo-3D deformable attention to enhance (pose/joint) queries with multi-view radar features: a pose decoder estimates initial 3D poses with a 3D template loss designed to utilize the 3D BBox labels and mitigate depth ambiguities; and a joint decoder refines the initial poses with 2D keypoint labels and a 3D gravity loss. Evaluated on two indoor radar datasets, RAPTR outperforms existing methods, reducing joint position error by $34.3\%$ on HIBER and $76.9\%$ on MMVR. Our implementation is available at https://github.com/merlresearch/radar-pose-transformer.

</details>


### [163] [Large Sign Language Models: Toward 3D American Sign Language Translation](https://arxiv.org/abs/2511.08535)
*Sen Zhang,Xiaoxiao He,Di Liu,Zhaoyang Xia,Mingyu Zhao,Chaowei Tan,Vivian Li,Bo Liu,Dimitris N. Metaxas,Mubbasir Kapadia*

Main category: cs.CV

TL;DR: 本文提出了大手语模型（LSLM）框架，利用大型语言模型（LLMs）作为骨干，直接从3D手语数据翻译美国手语（ASL），以增强听障人士的虚拟交流能力，并扩展LLMs对多模态语言的理解。


<details>
  <summary>Details</summary>
Motivation: 现有手语识别方法依赖2D视频，无法充分捕捉3D场景中丰富的空间、手势和深度信息，导致翻译准确性和鲁棒性不足。研究旨在提高听障人士数字通信的可访问性，并将复杂的具身多模态语言整合到LLMs中，超越纯文本输入。

Method: LSLM框架以LLMs为核心，直接处理3D手语数据而非2D视频，以捕捉空间、手势和深度信息。研究探索了两种翻译设置：一是3D手势特征到文本的直接翻译；二是通过外部提示调节翻译的指令引导设置，提供更大的灵活性。

Result: LSLM实现了更准确和鲁棒的ASL翻译，显著增强了听障社区的数字通信可访问性。此外，该工作成功将复杂的、具身的多模态语言集成到LLMs的处理能力中，拓宽了LLMs对人类交流的理解。

Conclusion: 这项工作为构建能够理解多样化语言形式的包容性、多模态智能系统奠定了基础。

Abstract: We present Large Sign Language Models (LSLM), a novel framework for translating 3D American Sign Language (ASL) by leveraging Large Language Models (LLMs) as the backbone, which can benefit hearing-impaired individuals' virtual communication. Unlike existing sign language recognition methods that rely on 2D video, our approach directly utilizes 3D sign language data to capture rich spatial, gestural, and depth information in 3D scenes. This enables more accurate and resilient translation, enhancing digital communication accessibility for the hearing-impaired community. Beyond the task of ASL translation, our work explores the integration of complex, embodied multimodal languages into the processing capabilities of LLMs, moving beyond purely text-based inputs to broaden their understanding of human communication. We investigate both direct translation from 3D gesture features to text and an instruction-guided setting where translations can be modulated by external prompts, offering greater flexibility. This work provides a foundational step toward inclusive, multimodal intelligent systems capable of understanding diverse forms of language.

</details>


### [164] [SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering](https://arxiv.org/abs/2511.08294)
*Laura Bragagnolo,Leonardo Barcellona,Stefano Ghidoni*

Main category: cs.CV

TL;DR: SkelSplat提出了一种基于可微分高斯渲染的新型多视图3D人体姿态估计算法，无需3D真值监督即可实现视图融合，并显著提升了跨数据集泛化能力和遮挡鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的多视图方法依赖于大量带标注的数据集进行训练，导致在测试场景不同时泛化能力差，因此需要一种不依赖3D真值监督且泛化性更好的方法。

Method: 该方法将人体姿态建模为由3D高斯（每个关节一个）组成的骨架，通过可微分渲染进行优化，实现任意相机视图的无缝融合。为适应稀疏骨架而非密集场景重建，SkelSplat提出了一种新颖的独热编码方案，以实现人体关节的独立优化。

Result: SkelSplat在Human3.6M和CMU数据集上超越了不依赖3D真值的方法，并将与基于学习的方法相比的跨数据集误差降低了高达47.8%。在Human3.6M-Occ和Occlusion-Person数据集上的实验表明，该方法对遮挡具有鲁棒性，无需进行特定场景的微调。

Conclusion: SkelSplat提供了一种无需3D真值监督的多视图3D人体姿态估计框架，通过可微分高斯渲染实现了优异的跨数据集泛化能力和对遮挡的鲁棒性，解决了现有方法泛化性差的问题。

Abstract: Accurate 3D human pose estimation is fundamental for applications such as augmented reality and human-robot interaction. State-of-the-art multi-view methods learn to fuse predictions across views by training on large annotated datasets, leading to poor generalization when the test scenario differs. To overcome these limitations, we propose SkelSplat, a novel framework for multi-view 3D human pose estimation based on differentiable Gaussian rendering. Human pose is modeled as a skeleton of 3D Gaussians, one per joint, optimized via differentiable rendering to enable seamless fusion of arbitrary camera views without 3D ground-truth supervision. Since Gaussian Splatting was originally designed for dense scene reconstruction, we propose a novel one-hot encoding scheme that enables independent optimization of human joints. SkelSplat outperforms approaches that do not rely on 3D ground truth in Human3.6M and CMU, while reducing the cross-dataset error up to 47.8% compared to learning-based methods. Experiments on Human3.6M-Occ and Occlusion-Person demonstrate robustness to occlusions, without scenario-specific fine-tuning. Our project page is available here: https://skelsplat.github.io.

</details>


### [165] [Anatomy-VLM: A Fine-grained Vision-Language Model for Medical Interpretation](https://arxiv.org/abs/2511.08402)
*Difei Gu,Yunhe Gao,Mu Zhou,Dimitris Metaxas*

Main category: cs.CV

TL;DR: Anatomy-VLM是一个受人类工作流程启发的细粒度视觉语言模型，通过整合多尺度信息和结构化知识，实现了卓越的疾病诊断性能，并支持零样本解剖学解释。


<details>
  <summary>Details</summary>
Motivation: 由于影像异质性，放射学疾病解释极具挑战。现有的主流视觉语言模型（VLMs）将图像视为整体，忽略了对疾病诊断至关重要的细粒度图像细节。而临床医生通过利用先验医学知识识别解剖结构作为感兴趣区域（ROIs）来分析图像。

Method: Anatomy-VLM模型采用多尺度信息整合方法。首先，设计模型编码器从整个医学图像中定位关键解剖特征。其次，利用结构化知识丰富这些区域，以实现上下文感知的解释。最后，模型编码器对多尺度医学信息进行对齐，生成临床可解释的疾病预测。

Result: Anatomy-VLM在内部分布和外部分布数据集上均取得了出色的性能。其性能在下游图像分割任务中也得到了验证，表明其细粒度对齐捕获了解剖学和病理学相关知识。此外，Anatomy-VLM的编码器促进了零样本解剖学解释。

Conclusion: Anatomy-VLM展示了强大的专家级临床解释能力，能够进行细粒度对齐并捕获解剖学和病理学知识，从而在疾病诊断和下游任务中表现出色。

Abstract: Accurate disease interpretation from radiology remains challenging due to imaging heterogeneity. Achieving expert-level diagnostic decisions requires integration of subtle image features with clinical knowledge. Yet major vision-language models (VLMs) treat images as holistic entities and overlook fine-grained image details that are vital for disease diagnosis. Clinicians analyze images by utilizing their prior medical knowledge and identify anatomical structures as important region of interests (ROIs). Inspired from this human-centric workflow, we introduce Anatomy-VLM, a fine-grained, vision-language model that incorporates multi-scale information. First, we design a model encoder to localize key anatomical features from entire medical images. Second, these regions are enriched with structured knowledge for contextually-aware interpretation. Finally, the model encoder aligns multi-scale medical information to generate clinically-interpretable disease prediction. Anatomy-VLM achieves outstanding performance on both in- and out-of-distribution datasets. We also validate the performance of Anatomy-VLM on downstream image segmentation tasks, suggesting that its fine-grained alignment captures anatomical and pathology-related knowledge. Furthermore, the Anatomy-VLM's encoder facilitates zero-shot anatomy-wise interpretation, providing its strong expert-level clinical interpretation capabilities.

</details>


### [166] [LayerEdit: Disentangled Multi-Object Editing via Conflict-Aware Multi-Layer Learning](https://arxiv.org/abs/2511.08251)
*Fengyi Fu,Mengqi Huang,Lei Zhang,Zhendong Mao*

Main category: cs.CV

TL;DR: 本文提出LayerEdit，一个免训练的多层解耦编辑框架，通过精确的对象分层分解、编辑和融合，解决了文本驱动多对象图像编辑中对象间冲突问题，实现了高可控性和连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动多对象图像编辑方法主要遵循独立定位和编辑范式，忽视了对象间关键的相互作用，尤其是在冲突区域的注意力纠缠。这导致编辑泄漏或内部编辑受限，阻碍了多对象解耦编辑。

Method: LayerEdit是一个免训练的“分解-编辑-融合”框架。它包含：1) 冲突感知层分解模块，利用注意力感知IoU方案和时间依赖区域移除增强冲突感知和抑制。2) 对象分层编辑模块，建立层内文本引导和跨层几何映射，实现语义和结构解耦修改。3) 透明度引导层融合模块，通过精确的透明度引导学习促进结构连贯的对象间层融合。

Result: LayerEdit在复杂多对象场景中，相比现有方法展现出卓越的性能，实现了前所未有的对象内可控性和对象间连贯性。

Conclusion: LayerEdit通过引入新颖的分层分解、编辑和融合框架，首次实现了冲突无关的对象分层编辑，有效解决了多对象图像编辑中的对象间冲突问题，显著提升了编辑的解耦性和质量。

Abstract: Text-driven multi-object image editing which aims to precisely modify multiple objects within an image based on text descriptions, has recently attracted considerable interest. Existing works primarily follow the localize-editing paradigm, focusing on independent object localization and editing while neglecting critical inter-object interactions. However, this work points out that the neglected attention entanglements in inter-object conflict regions, inherently hinder disentangled multi-object editing, leading to either inter-object editing leakage or intra-object editing constraints. We thereby propose a novel multi-layer disentangled editing framework LayerEdit, a training-free method which, for the first time, through precise object-layered decomposition and coherent fusion, enables conflict-free object-layered editing. Specifically, LayerEdit introduces a novel "decompose-editingfusion" framework, consisting of: (1) Conflict-aware Layer Decomposition module, which utilizes an attention-aware IoU scheme and time-dependent region removing, to enhance conflict awareness and suppression for layer decomposition. (2) Object-layered Editing module, to establish coordinated intra-layer text guidance and cross-layer geometric mapping, achieving disentangled semantic and structural modifications. (3) Transparency-guided Layer Fusion module, to facilitate structure-coherent inter-object layer fusion through precise transparency guidance learning. Extensive experiments verify the superiority of LayerEdit over existing methods, showing unprecedented intra-object controllability and inter-object coherence in complex multi-object scenarios. Codes are available at: https://github.com/fufy1024/LayerEdit.

</details>


### [167] [Mitigating Negative Flips via Margin Preserving Training](https://arxiv.org/abs/2511.08322)
*Simone Ricci,Niccolò Biondi,Federico Pernici,Alberto Del Bimbo*

Main category: cs.CV

TL;DR: 本文提出一种新方法，通过保留原始模型的决策边界并引入显式logit边界校准项，结合双源焦点蒸馏损失，以最小化AI系统更新时（特别是新增类别时）的负向翻转（即原正确分类样本被新模型错误分类）问题，同时保持高整体准确性。


<details>
  <summary>Details</summary>
Motivation: AI系统在更新版本时，保持一致性与降低整体错误同样重要。在图像分类中，这种不一致性表现为“负向翻转”，即更新后的模型错误分类了之前正确分类的测试样本。随着训练类别数量的增加，这个问题变得日益突出，因为新增类别会缩小原有类别的决策边界，并可能引入冲突模式，从而损害原始子集的性能。

Method: 我们提出一种新颖的方法，在学习改进模型的同时保留原始模型的决策边界。通过在logit上引入一个显式的边界校准项，鼓励先前学习的类别与新引入的类别之间保持更大的相对边界。为避免新类别准确性显著下降，我们还整合了双源焦点蒸馏损失，结合旧模型和独立训练的新模型，即使在logit边界校准下，也能从旧数据和新数据中学习到合适的决策边界。

Result: 在图像分类基准测试上的大量实验表明，我们的方法在显著降低负向翻转率的同时，保持了较高的整体准确性。

Conclusion: 该方法成功地解决了AI系统更新过程中因新增类别导致的负向翻转问题，通过巧妙地结合边界保留、logit边界校准和双源焦点蒸馏，实现了在保持高整体准确性的前提下，减少模型不一致性。

Abstract: Minimizing inconsistencies across successive versions of an AI system is as crucial as reducing the overall error. In image classification, such inconsistencies manifest as negative flips, where an updated model misclassifies test samples that were previously classified correctly. This issue becomes increasingly pronounced as the number of training classes grows over time, since adding new categories reduces the margin of each class and may introduce conflicting patterns that undermine their learning process, thereby degrading performance on the original subset. To mitigate negative flips, we propose a novel approach that preserves the margins of the original model while learning an improved one. Our method encourages a larger relative margin between the previously learned and newly introduced classes by introducing an explicit margin-calibration term on the logits. However, overly constraining the logit margin for the new classes can significantly degrade their accuracy compared to a new independently trained model. To address this, we integrate a double-source focal distillation loss with the previous model and a new independently trained model, learning an appropriate decision margin from both old and new data, even under a logit margin calibration. Extensive experiments on image classification benchmarks demonstrate that our approach consistently reduces the negative flip rate with high overall accuracy.

</details>


### [168] [NeuSpring: Neural Spring Fields for Reconstruction and Simulation of Deformable Objects from Videos](https://arxiv.org/abs/2511.08310)
*Qingshan Xu,Jiao Liu,Shangshu Yu,Yuxuan Wang,Yuan Zhou,Junbao Zhou,Jiequan Cui,Yew-Soon Ong,Hanwang Zhang*

Main category: cs.CV

TL;DR: 本文提出了NeuSpring，一种神经弹簧场模型，用于从视频中重建和模拟可变形物体。它通过分段拓扑解决方案和基于规范坐标的神经弹簧场，有效解决了现有方法在物理学习和未来预测方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在可变形物体的物理学习和未来预测方面表现不佳，因为它们忽视了物体的内在物理特性，导致当前状态建模的物理学习能力有限。

Method: 本文提出了NeuSpring，一个基于弹簧-质量模型的神经弹簧场。主要创新点包括：1) 一个分段拓扑解决方案，利用零阶优化高效建模多区域弹簧连接拓扑，考虑了真实物体的材料异质性。2) 一个神经弹簧场，使用基于规范坐标的神经网络表示跨帧的弹簧物理特性，有效利用弹簧的空间关联性进行物理学习。

Result: 在真实世界数据集上的实验表明，NeuSpring在当前状态建模和未来预测方面均实现了卓越的重建和模拟性能，Chamfer距离分别提高了20%和25%。

Conclusion: NeuSpring通过其创新的分段拓扑和神经弹簧场设计，成功地为可变形物体创建了物理数字孪生，显著提升了重建和模拟的准确性，尤其在未来预测方面表现出色。

Abstract: In this paper, we aim to create physical digital twins of deformable objects under interaction. Existing methods focus more on the physical learning of current state modeling, but generalize worse to future prediction. This is because existing methods ignore the intrinsic physical properties of deformable objects, resulting in the limited physical learning in the current state modeling. To address this, we present NeuSpring, a neural spring field for the reconstruction and simulation of deformable objects from videos. Built upon spring-mass models for realistic physical simulation, our method consists of two major innovations: 1) a piecewise topology solution that efficiently models multi-region spring connection topologies using zero-order optimization, which considers the material heterogeneity of real-world objects. 2) a neural spring field that represents spring physical properties across different frames using a canonical coordinate-based neural network, which effectively leverages the spatial associativity of springs for physical learning. Experiments on real-world datasets demonstrate that our NeuSping achieves superior reconstruction and simulation performance for current state modeling and future prediction, with Chamfer distance improved by 20% and 25%, respectively.

</details>


### [169] [The Impact of Longitudinal Mammogram Alignment on Breast Cancer Risk Assessment](https://arxiv.org/abs/2511.08328)
*Solveig Thrun,Stine Hansen,Zijun Sun,Nele Blum,Suaiba A. Salahuddin,Xin Wang,Kristoffer Wickstrøm,Elisabeth Wetzer,Robert Jenssen,Maik Stille,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 本研究评估了在基于深度学习的乳腺癌风险模型中，用于纵向乳腺X线图像对齐的各种策略。结果表明，基于图像的配准方法在预测准确性和形变场质量方面优于基于特征和隐式方法。


<details>
  <summary>Details</summary>
Motivation: 个性化乳腺癌筛查需要利用深度学习风险模型整合纵向乳腺X线图像信息。然而，不同时间点图像之间的空间未对齐是关键挑战，会掩盖有意义的组织变化并降低模型性能。

Method: 本研究探讨了多种对齐策略：基于图像的配准、特征层面对齐（有无正则化）以及隐式对齐方法。研究使用了两个大型乳腺X线数据集，并根据预测准确性、精确度、召回率和形变场质量等关键指标评估了每种方法。

Result: 研究结果显示，基于图像的配准方法在所有评估指标上均优于最近流行的基于特征和隐式方法，能实现更准确、时间上更一致的预测，并生成平滑、符合解剖学原理的形变场。尽管对形变场进行正则化可以提高形变质量，但会降低特征层面对齐的风险预测性能。将基于图像的形变场应用于特征空间可获得最佳的风险预测性能。

Conclusion: 研究强调了基于图像的形变场在纵向风险建模中进行空间对齐的重要性，能显著提高预测准确性和鲁棒性。该方法有望增强个性化筛查，并为高风险个体提供更早的干预。

Abstract: Regular mammography screening is crucial for early breast cancer detection. By leveraging deep learning-based risk models, screening intervals can be personalized, especially for high-risk individuals. While recent methods increasingly incorporate longitudinal information from prior mammograms, accurate spatial alignment across time points remains a key challenge. Misalignment can obscure meaningful tissue changes and degrade model performance. In this study, we provide insights into various alignment strategies, image-based registration, feature-level (representation space) alignment with and without regularization, and implicit alignment methods, for their effectiveness in longitudinal deep learning-based risk modeling. Using two large-scale mammography datasets, we assess each method across key metrics, including predictive accuracy, precision, recall, and deformation field quality.
  Our results show that image-based registration consistently outperforms the more recently favored feature-based and implicit approaches across all metrics, enabling more accurate, temporally consistent predictions and generating smooth, anatomically plausible deformation fields. Although regularizing the deformation field improves deformation quality, it reduces the risk prediction performance of feature-level alignment. Applying image-based deformation fields within the feature space yields the best risk prediction performance.
  These findings underscore the importance of image-based deformation fields for spatial alignment in longitudinal risk modeling, offering improved prediction accuracy and robustness. This approach has strong potential to enhance personalized screening and enable earlier interventions for high-risk individuals. The code is available at https://github.com/sot176/Mammogram_Alignment_Study_Risk_Prediction.git, allowing full reproducibility of the results.

</details>


### [170] [Contrastive Integrated Gradients: A Feature Attribution-Based Method for Explaining Whole Slide Image Classification](https://arxiv.org/abs/2511.08464)
*Anh Mai Vu,Tuan L. Vo,Ngoc Lam Quang Bui,Nam Nguyen Le Binh,Akash Awasthi,Huy Quoc Vo,Thanh-Huy Nguyen,Zhu Han,Chandra Mohan,Hien Van Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种名为对比集成梯度 (CIG) 的新型归因方法，用于全玻片图像 (WSI) 分析，通过计算对数空间中的对比梯度来增强可解释性，有效区分肿瘤区域。该方法在理论上稳健，并在多个癌症数据集上验证，结果显示其归因更具信息量且与真实肿瘤区域高度一致。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中的全玻片图像 (WSI) 分析需要可解释性，以建立对AI辅助诊断的信任。然而，现有的集成梯度等归因方法直接应用于高分辨率WSI时面临挑战，可能无法捕捉到区分肿瘤亚型的关键类别判别信号。

Method: 本文引入了对比集成梯度 (CIG) 方法。CIG通过在对数空间中计算对比梯度来增强可解释性，通过比较相对于参考类别的特征重要性来突出类别判别区域，从而更清晰地区分肿瘤和非肿瘤区域。CIG满足集成归因的公理，确保一致性和理论完备性。此外，本文提出了两种归因质量指标：MIL-AIC（衡量预测信息）和MIL-SIC（衡量模型置信度），以评估在弱监督下显着区域对预测信息和模型置信度的影响。CIG在CAMELYON16、TCGA-RCC和TCGA-Lung三个癌症数据集上进行了验证。

Result: 实验结果表明，CIG在定量（使用MIL-AIC和MIL-SIC）和定性（可视化结果与真实肿瘤区域高度一致）方面均产生了更具信息量的归因。它能更清晰地分化肿瘤和非肿瘤区域。

Conclusion: CIG是一种有前景的方法，能够为基于WSI的诊断提供可解释且值得信赖的结果，其归因信息丰富、理论健全，并与真实肿瘤区域高度吻合。

Abstract: Interpretability is essential in Whole Slide Image (WSI) analysis for computational pathology, where understanding model predictions helps build trust in AI-assisted diagnostics. While Integrated Gradients (IG) and related attribution methods have shown promise, applying them directly to WSIs introduces challenges due to their high-resolution nature. These methods capture model decision patterns but may overlook class-discriminative signals that are crucial for distinguishing between tumor subtypes. In this work, we introduce Contrastive Integrated Gradients (CIG), a novel attribution method that enhances interpretability by computing contrastive gradients in logit space. First, CIG highlights class-discriminative regions by comparing feature importance relative to a reference class, offering sharper differentiation between tumor and non-tumor areas. Second, CIG satisfies the axioms of integrated attribution, ensuring consistency and theoretical soundness. Third, we propose two attribution quality metrics, MIL-AIC and MIL-SIC, which measure how predictive information and model confidence evolve with access to salient regions, particularly under weak supervision. We validate CIG across three datasets spanning distinct cancer types: CAMELYON16 (breast cancer metastasis in lymph nodes), TCGA-RCC (renal cell carcinoma), and TCGA-Lung (lung cancer). Experimental results demonstrate that CIG yields more informative attributions both quantitatively, using MIL-AIC and MIL-SIC, and qualitatively, through visualizations that align closely with ground truth tumor regions, underscoring its potential for interpretable and trustworthy WSI-based diagnostics

</details>


### [171] [SENCA-st: Integrating Spatial Transcriptomics and Histopathology with Cross Attention Shared Encoder for Region Identification in Cancer Pathology](https://arxiv.org/abs/2511.08573)
*Shanaka Liyanaarachchi,Chathurya Wijethunga,Shihab Aaquil Ahamed,Akthas Absar,Ranga Rodrigo*

Main category: cs.CV

TL;DR: 该论文提出了一种名为SENCA-st的新型架构，用于整合空间转录组学和组织病理学图像数据，以解决现有方法在平衡两种模态信息方面的不足，从而更有效地识别肿瘤异质性和肿瘤微环境区域。


<details>
  <summary>Details</summary>
Motivation: 将空间转录组学的功能信息与组织病理学图像的结构数据整合，对于识别与癌症耐药性相关的肿瘤亚结构至关重要。然而，现有方法要么过度强调空间转录组学数据，要么过度强调组织病理学图像，导致信息丢失（如陷入噪声或过度平滑），无法有效结合两种模态的优势。

Method: 论文提出了一种名为SENCA-st（Shared Encoder with Neighborhood Cross Attention）的新型架构。该架构使用共享编码器来保留两种模态的特征，并通过邻域交叉注意力（Neighborhood Cross Attention）机制，特别强调在组织病理学上结构相似但在空间转录组学上功能不同的区域。

Result: SENCA-st模型在检测肿瘤异质性和肿瘤微环境区域方面表现出卓越的性能，超越了现有最先进的方法，这在临床上具有重要意义。

Conclusion: SENCA-st架构通过有效平衡和整合空间转录组学和组织病理学数据，成功克服了现有方法的局限性，从而能够更准确地识别肿瘤异质性和肿瘤微环境区域，为临床应用提供了更强大的工具。

Abstract: Spatial transcriptomics is an emerging field that enables the identification of functional regions based on the spatial distribution of gene expression. Integrating this functional information present in transcriptomic data with structural data from histopathology images is an active research area with applications in identifying tumor substructures associated with cancer drug resistance. Current histopathology-spatial-transcriptomic region segmentation methods suffer due to either making spatial transcriptomics prominent by using histopathology features just to assist processing spatial transcriptomics data or using vanilla contrastive learning that make histopathology images prominent due to only promoting common features losing functional information. In both extremes, the model gets either lost in the noise of spatial transcriptomics or overly smoothed, losing essential information. Thus, we propose our novel architecture SENCA-st (Shared Encoder with Neighborhood Cross Attention) that preserves the features of both modalities. More importantly, it emphasizes regions that are structurally similar in histopathology but functionally different on spatial transcriptomics using cross-attention. We demonstrate the superior performance of our model that surpasses state-of-the-art methods in detecting tumor heterogeneity and tumor micro-environment regions, a clinically crucial aspect.

</details>


### [172] [SynWeather: Weather Observation Data Synthesis across Multiple Regions and Variables via a General Diffusion Transformer](https://arxiv.org/abs/2511.08291)
*Kaiyi Xu,Junchao Gong,Zhiwang Zhou,Zhangrui Li,Yuandong Pu,Yihao Liu,Ben Fei,Fenghua Ling,Wenlong Zhang,Lei Bei*

Main category: cs.CV

TL;DR: 本文介绍了SynWeather数据集，用于统一的多区域多变量天气观测数据合成，并提出了SynWeatherDiff模型（基于Diffusion Transformer），以解决现有天气数据合成方法中单变量/区域、确定性建模和结果过度平滑等问题。


<details>
  <summary>Details</summary>
Motivation: 现有天气数据合成方法通常侧重于单变量、单区域任务，并主要依赖确定性建模。这限制了变量和区域间的统一综合，忽视了跨变量的互补性，并常导致结果过度平滑。

Method: 本文引入了SynWeather数据集，它是首个专为统一多区域和多变量天气观测数据合成设计的数据集，涵盖美国大陆、欧洲、东亚和热带气旋四个区域，并提供高分辨率的复合雷达反射率、小时降水、可见光和微波亮度温度等关键气象变量。此外，本文还提出了SynWeatherDiff，一个基于Diffusion Transformer框架的通用概率天气合成模型，旨在解决过度平滑问题。

Result: 在SynWeather数据集上的实验表明，与特定任务模型和通用模型相比，SynWeatherDiff网络具有更高的有效性。

Conclusion: SynWeather数据集和SynWeatherDiff模型的引入，为解决当前天气观测数据合成面临的挑战提供了一个统一、概率性的解决方案，能够实现跨变量和跨区域的有效综合，并缓解过度平滑问题。

Abstract: With the advancement of meteorological instruments, abundant data has become available. Current approaches are typically focus on single-variable, single-region tasks and primarily rely on deterministic modeling. This limits unified synthesis across variables and regions, overlooks cross-variable complementarity and often leads to over-smoothed results. To address above challenges, we introduce SynWeather, the first dataset designed for Unified Multi-region and Multi-variable Weather Observation Data Synthesis. SynWeather covers four representative regions: the Continental United States, Europe, East Asia, and Tropical Cyclone regions, as well as provides high-resolution observations of key weather variables, including Composite Radar Reflectivity, Hourly Precipitation, Visible Light, and Microwave Brightness Temperature. In addition, we introduce SynWeatherDiff, a general and probabilistic weather synthesis model built upon the Diffusion Transformer framework to address the over-smoothed problem. Experiments on the SynWeather dataset demonstrate the effectiveness of our network compared with both task-specific and general models.

</details>


### [173] [VideoChain: A Transformer-Based Framework for Multi-hop Video Question Generation](https://arxiv.org/abs/2511.08348)
*Arpan Phukan,Anupam Pandey,Deepjyoti Bodo,Asif Ekbal*

Main category: cs.CV

TL;DR: 该研究引入了VideoChain框架，用于多跳视频问题生成（MVQG），能够生成需要跨越多个时间分离的视频片段进行推理的问题，并展示了其在生成连贯、有上下文且需要推理的问题方面的强大性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多跳问题生成（QG）仅限于文本，而视频问题生成（VideoQG）则局限于单片段的零跳问题。为了解决这一限制，即在视频领域生成需要跨多个时间分离的视频片段进行推理的多跳问题，本研究提出了VideoChain。

Method: 研究提出了VideoChain，一个新颖的多跳视频问题生成（MVQG）框架。它采用模块化架构，基于修改后的BART骨干网络，并增强了视频嵌入以捕捉文本和视觉依赖。研究还通过合并零跳问答对，利用TVQA+数据集自动构建了大规模的MVQ-60数据集。

Result: VideoChain在标准生成指标上表现出色：ROUGE-L (0.6454)、ROUGE-1 (0.6854)、BLEU-1 (0.6711)、BERTScore-F1 (0.7967) 和语义相似度 (0.8110)。

Conclusion: 这些结果表明，VideoChain模型能够生成连贯、有上下文依据且需要推理的视频问题，有效解决了多跳视频问题生成中的挑战。

Abstract: Multi-hop Question Generation (QG) effectively evaluates reasoning but remains confined to text; Video Question Generation (VideoQG) is limited to zero-hop questions over single segments. To address this, we introduce VideoChain, a novel Multi-hop Video Question Generation (MVQG) framework designed to generate questions that require reasoning across multiple, temporally separated video segments. VideoChain features a modular architecture built on a modified BART backbone enhanced with video embeddings, capturing textual and visual dependencies. Using the TVQA+ dataset, we automatically construct the large-scale MVQ-60 dataset by merging zero-hop QA pairs, ensuring scalability and diversity. Evaluations show VideoChain's strong performance across standard generation metrics: ROUGE-L (0.6454), ROUGE-1 (0.6854), BLEU-1 (0.6711), BERTScore-F1 (0.7967), and semantic similarity (0.8110). These results highlight the model's ability to generate coherent, contextually grounded, and reasoning-intensive questions.

</details>


### [174] [Empowering DINO Representations for Underwater Instance Segmentation via Aligner and Prompter](https://arxiv.org/abs/2511.08334)
*Zhiyang Chen,Chen Zhang,Hao Fang,Runmin Cong*

Main category: cs.CV

TL;DR: 本文提出DiveSeg框架，利用DINO作为水下实例分割（UIS）的有效特征学习器，并通过AquaStyle Aligner和ObjectPrior Prompter两个组件，实现了水下领域的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 水下实例分割是海洋资源探索和生态保护的关键技术。尽管DINO等大型预训练视觉基础模型表现出色，但它们在复杂的水下任务中仍需更好的适应性，以整合像素级理解和实例级区分。

Method: 该研究将DINO用作水下实例分割的特征学习器，并引入了名为DiveSeg的新框架。DiveSeg包含两个核心组件：(1) AquaStyle Aligner，用于在DINO微调过程中嵌入水下颜色风格特征，以更好地适应水下域。(2) ObjectPrior Prompter，通过基于二值分割的提示提供对象级先验，为需要对象和实例级推理的实例分割任务提供指导。

Result: 在UIIS和USIS10K数据集上进行的实验表明，DiveSeg框架实现了最先进的性能（state-of-the-art）。

Conclusion: DINO可以作为水下实例分割的有效特征学习器。通过引入AquaStyle Aligner和ObjectPrior Prompter，DiveSeg框架能够有效适应水下环境并提供必要的对象级指导，从而显著提升水下实例分割的性能。

Abstract: Underwater instance segmentation (UIS), integrating pixel-level understanding and instance-level discrimination, is a pivotal technology in marine resource exploration and ecological protection. In recent years, large-scale pretrained visual foundation models, exemplified by DINO, have advanced rapidly and demonstrated remarkable performance on complex downstream tasks. In this paper, we demonstrate that DINO can serve as an effective feature learner for UIS, and we introduce DiveSeg, a novel framework built upon two insightful components: (1) The AquaStyle Aligner, designed to embed underwater color style features into the DINO fine-tuning process, facilitating better adaptation to the underwater domain. (2) The ObjectPrior Prompter, which incorporates binary segmentation-based prompts to deliver object-level priors, provides essential guidance for instance segmentation task that requires both object- and instance-level reasoning. We conduct thorough experiments on the popular UIIS and USIS10K datasets, and the results show that DiveSeg achieves the state-of-the-art performance. Code: https://github.com/ettof/Diveseg.

</details>


### [175] [Re-coding for Uncertainties: Edge-awareness Semantic Concordance for Resilient Event-RGB Segmentation](https://arxiv.org/abs/2511.08269)
*Nan Bao,Yifan Zhao,Lin Zhu,Jia Li*

Main category: cs.CV

TL;DR: 该研究针对极端条件下的语义分割挑战，提出了一种名为“边缘感知语义一致性”（ESC）的框架，通过利用潜在边缘线索来融合异构的事件和RGB数据，有效解决了信息丢失和特征不匹配问题，并取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 在极端条件（如光照不足、剧烈相机运动）下，RGB图像信息严重丢失，导致现有语义分割方法性能下降。虽然事件相机可以作为补充，但事件和RGB模态的异构性导致特征级别不匹配，现有多模态方法优化不足。

Method: 该论文提出了一种“边缘感知语义一致性”（ESC）框架，旨在通过潜在边缘线索统一多模态异构特征。具体方法包括：1) 边缘感知潜在重编码，通过重编码分布和预设边缘字典引导，将事件-RGB特征对齐到统一语义空间，并获取不确定性指标；2) 重编码整合和不确定性优化，利用重编码的边缘特征和不确定性指标来解决极端条件下的异构事件-RGB融合问题。此外，还建立了两个合成和一个真实世界的事件-RGB语义分割数据集用于评估。

Result: 实验结果表明，该方法在提出的DERS-XS数据集上，mIoU比现有最先进方法高出2.55%，并且在空间遮挡下表现出卓越的鲁棒性。

Conclusion: 该研究通过提出的ESC框架，成功地利用潜在边缘线索解决了极端条件下异构事件-RGB数据融合的语义分割难题，实现了先进的性能和出色的鲁棒性。

Abstract: Semantic segmentation has achieved great success in ideal conditions. However, when facing extreme conditions (e.g., insufficient light, fierce camera motion), most existing methods suffer from significant information loss of RGB, severely damaging segmentation results. Several researches exploit the high-speed and high-dynamic event modality as a complement, but event and RGB are naturally heterogeneous, which leads to feature-level mismatch and inferior optimization of existing multi-modality methods. Different from these researches, we delve into the edge secret of both modalities for resilient fusion and propose a novel Edge-awareness Semantic Concordance framework to unify the multi-modality heterogeneous features with latent edge cues. In this framework, we first propose Edge-awareness Latent Re-coding, which obtains uncertainty indicators while realigning event-RGB features into unified semantic space guided by re-coded distribution, and transfers event-RGB distributions into re-coded features by utilizing a pre-established edge dictionary as clues. We then propose Re-coded Consolidation and Uncertainty Optimization, which utilize re-coded edge features and uncertainty indicators to solve the heterogeneous event-RGB fusion issues under extreme conditions. We establish two synthetic and one real-world event-RGB semantic segmentation datasets for extreme scenario comparisons. Experimental results show that our method outperforms the state-of-the-art by a 2.55% mIoU on our proposed DERS-XS, and possesses superior resilience under spatial occlusion. Our code and datasets are publicly available at https://github.com/iCVTEAM/ESC.

</details>


### [176] [Retrospective motion correction in MRI using disentangled embeddings](https://arxiv.org/abs/2511.08365)
*Qi Wang,Veronika Ecker,Marcel Früh,Sergios Gatidis,Thomas Küstner*

Main category: cs.CV

TL;DR: 本文提出了一种分层矢量量化变分自编码器（VQ-VAE），通过学习运动到清晰图像特征的解耦嵌入，实现对MRI运动伪影的通用且可泛化的校正，无需特定伪影训练。


<details>
  <summary>Details</summary>
Motivation: 生理运动会影响MRI诊断质量，现有回顾性运动校正方法（尤其是基于机器学习的）难以泛化到不同运动类型和身体区域，通常需要针对特定应用和数据集进行定制。研究者假设尽管运动伪影多样，但它们共享底层的可分离和利用的模式。

Method: 研究者提出了一种分层矢量量化（VQ）变分自编码器，用于学习运动到清晰图像特征的解耦嵌入。该方法部署了一个码本，以多分辨率捕获有限的运动模式集合，实现从粗到细的校正。此外，训练了一个自回归模型来学习无运动图像的先验分布，并在推理时用于指导校正过程。与传统方法不同，该方法无需特定伪影训练。

Result: 该方法在模拟全身运动伪影上进行了演示，并在不同运动严重程度下观察到鲁棒的校正效果。结果表明，该模型有效地解耦了模拟运动扫描中的物理运动特征，从而提高了基于机器学习的MRI运动校正的泛化能力。

Conclusion: 研究表明，通过解耦运动特征，可以显著提高基于机器学习的MRI运动校正方法的泛化能力，使其有望应用于不同的解剖区域和运动类型。

Abstract: Physiological motion can affect the diagnostic quality of magnetic resonance imaging (MRI). While various retrospective motion correction methods exist, many struggle to generalize across different motion types and body regions. In particular, machine learning (ML)-based corrections are often tailored to specific applications and datasets. We hypothesize that motion artifacts, though diverse, share underlying patterns that can be disentangled and exploited. To address this, we propose a hierarchical vector-quantized (VQ) variational auto-encoder that learns a disentangled embedding of motion-to-clean image features. A codebook is deployed to capture finite collection of motion patterns at multiple resolutions, enabling coarse-to-fine correction. An auto-regressive model is trained to learn the prior distribution of motion-free images and is used at inference to guide the correction process. Unlike conventional approaches, our method does not require artifact-specific training and can generalize to unseen motion patterns. We demonstrate the approach on simulated whole-body motion artifacts and observe robust correction across varying motion severity. Our results suggest that the model effectively disentangled physical motion of the simulated motion-effective scans, therefore, improving the generalizability of the ML-based MRI motion correction. Our work of disentangling the motion features shed a light on its potential application across anatomical regions and motion types.

</details>


### [177] [Cross-pyramid consistency regularization for semi-supervised medical image segmentation](https://arxiv.org/abs/2511.08435)
*Matus Bojko,Maros Kollar,Marek Jakab,Wanda Benesova*

Main category: cs.CV

TL;DR: 本文提出了一种名为交叉金字塔一致性正则化（CPCR）的混合一致性学习方法，结合双分支金字塔网络（DBPNet），用于半监督医学图像分割，以有效利用未标记数据。


<details>
  <summary>Details</summary>
Motivation: 在标记数据有限但未标记数据丰富的背景下，如何有效利用未标记数据来训练强大的模型，以实现半监督医学图像分割。

Method: 首先，设计了一个混合双分支金字塔网络（DBPNet），包含一个编码器和两个略有不同的解码器，每个解码器在多个分辨率尺度上生成扰动辅助预测的金字塔。其次，提出了一种名为CPCR的学习策略，该策略将现有的一致性学习和不确定性最小化方法与一种新颖的正则化项相结合。该正则化项将软标签设置扩展到跨解码器的金字塔预测，以支持深度层次特征中的知识蒸馏。

Result: 实验结果表明，结合CPCR的DBPNet在公共基准数据集上优于五种最先进的自监督学习方法，并与近期方法表现相当。

Conclusion: 所提出的DBPNet与CPCR结合是一种有效的半监督医学图像分割混合一致性学习方法，在性能上表现出优越或可比性。

Abstract: Semi-supervised learning (SSL) enables training of powerful models with the assumption of limited, carefully labelled data and a large amount of unlabeled data to support the learning. In this paper, we propose a hybrid consistency learning approach to effectively exploit unlabeled data for semi-supervised medical image segmentation by leveraging Cross-Pyramid Consistency Regularization (CPCR) between two decoders. First, we design a hybrid Dual Branch Pyramid Network (DBPNet), consisting of an encoder and two decoders that differ slightly, each producing a pyramid of perturbed auxiliary predictions across multiple resolution scales. Second, we present a learning strategy for this network named CPCR that combines existing consistency learning and uncertainty minimization approaches on the main output predictions of decoders with our novel regularization term. More specifically, in this term, we extend the soft-labeling setting to pyramid predictions across decoders to support knowledge distillation in deep hierarchical features. Experimental results show that DBPNet with CPCR outperforms five state-of-the-art self-supervised learning methods and has comparable performance with recent ones on a public benchmark dataset.

</details>


### [178] [OmniAID: Decoupling Semantic and Artifacts for Universal AI-Generated Image Detection in the Wild](https://arxiv.org/abs/2511.08423)
*Yuncheng Guo,Junyan Ye,Chenjue Zhang,Hengrui Kang,Haohuan Fu,Conghui He,Weijia Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为OmniAID的新型AI生成图像（AIGI）检测框架，该框架采用解耦的专家混合（MoE）架构，通过分离内容相关缺陷和内容无关通用伪影，实现了对多样化生成模型和语义内容的鲁棒泛化。同时，还引入了一个大规模、最新的数据集Mirage。


<details>
  <summary>Details</summary>
Motivation: 当前的AIGI检测方法在泛化能力上存在局限性，因为它们学习的是单一、纠缠的伪造表示，将内容依赖的缺陷与内容无关的伪影混为一谈。此外，现有的基准测试已经过时，无法反映真实的威胁。

Method: OmniAID框架的核心是一个解耦的专家混合（MoE）架构。它包含两类专家：1) 可路由的专业语义专家，针对不同的内容领域（如人类、动物）；2) 一个固定的通用伪影专家，用于检测内容无关的通用伪影。训练采用两阶段策略：首先独立训练专家，使用领域特定的硬采样以确保专业化；然后训练一个轻量级的门控网络以实现有效的输入路由。为解决过时基准问题，本文还引入了一个新的大规模、当代数据集Mirage。

Result: 通过在传统基准测试和新Mirage数据集上的广泛实验，OmniAID模型表现出强大的泛化能力，超越了现有的单一检测器，为AIGI的认证树立了一个新的、鲁棒的标准，能够有效应对现代的、实际存在的威胁。

Conclusion: OmniAID通过明确解耦“生成了什么”（内容特定缺陷）和“如何生成”（通用伪影），实现了对AIGI的鲁棒泛化检测。结合新数据集Mirage，该方法为对抗现代AIGI威胁建立了新的、更可靠的认证标准。

Abstract: A truly universal AI-Generated Image (AIGI) detector must simultaneously generalize across diverse generative models and varied semantic content. Current state-of-the-art methods learn a single, entangled forgery representation--conflating content-dependent flaws with content-agnostic artifacts--and are further constrained by outdated benchmarks. To overcome these limitations, we propose OmniAID, a novel framework centered on a decoupled Mixture-of-Experts (MoE) architecture. The core of our method is a hybrid expert system engineered to decouple: (1) semantic flaws across distinct content domains, and (2) these content-dependent flaws from content-agnostic universal artifacts. This system employs a set of Routable Specialized Semantic Experts, each for a distinct domain (e.g., human, animal), complemented by a Fixed Universal Artifact Expert. This architecture is trained using a bespoke two-stage strategy: we first train the experts independently with domain-specific hard-sampling to ensure specialization, and subsequently train a lightweight gating network for effective input routing. By explicitly decoupling "what is generated" (content-specific flaws) from "how it is generated" (universal artifacts), OmniAID achieves robust generalization. To address outdated benchmarks and validate real-world applicability, we introduce Mirage, a new large-scale, contemporary dataset. Extensive experiments, using both traditional benchmarks and our Mirage dataset, demonstrate our model surpasses existing monolithic detectors, establishing a new, robust standard for AIGI authentication against modern, in-the-wild threats.

</details>


### [179] [Generalizable Blood Cell Detection via Unified Dataset and Faster R-CNN](https://arxiv.org/abs/2511.08465)
*Siddharth Sahay*

Main category: cs.CV

TL;DR: 本文提出了一种用于外周血细胞自动分类和目标检测的综合方法，通过数据整合和基于迁移学习的Faster R-CNN模型，实现了更高的收敛速度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决显微图像中外周血细胞数据稀缺性和异质性的关键挑战，并建立高准确度的自动化血液学诊断系统。

Method: 首先，开发了一个强大的数据管道，标准化并合并了四个公共数据集。然后，采用基于ResNet-50-FPN骨干的Faster R-CNN目标检测框架。通过比较随机初始化基线模型（方案1）和使用Microsoft COCO数据集预训练权重进行初始化（方案2）的迁移学习方法进行了严格的训练评估。

Result: 迁移学习方法（方案2）实现了显著更快的收敛和卓越的稳定性，最终验证损失为0.08666，比基线模型有显著改进。

Conclusion: 经验证的方法为构建高精度、可部署的自动化血液学诊断系统奠定了坚实的基础。

Abstract: This paper presents a comprehensive methodology and comparative performance analysis for the automated classification and object detection of peripheral blood cells (PBCs) in microscopic images. Addressing the critical challenge of data scarcity and heterogeneity, robust data pipeline was first developed to standardize and merge four public datasets (PBC, BCCD, Chula, Sickle Cell) into a unified resource. Then employed a state-of-the-art Faster R-CNN object detection framework, leveraging a ResNet-50-FPN backbone. Comparative training rigorously evaluated a randomly initialized baseline model (Regimen 1) against a Transfer Learning Regimen (Regimen 2), initialized with weights pre-trained on the Microsoft COCO dataset. The results demonstrate that the Transfer Learning approach achieved significantly faster convergence and superior stability, culminating in a final validation loss of 0.08666, a substantial improvement over the baseline. This validated methodology establishes a robust foundation for building high-accuracy, deployable systems for automated hematological diagnosis.

</details>


### [180] [Fast Multi-Organ Fine Segmentation in CT Images with Hierarchical Sparse Sampling and Residual Transformer](https://arxiv.org/abs/2511.08509)
*Xueqi Guo,Halid Ziya Yerebakan,Yoshihisa Shinagawa,Kritika Iyer,Gerardo Hermosillo Valadez*

Main category: cs.CV

TL;DR: 本文提出了一种基于分层稀疏采样和残差Transformer的快速多器官分割框架，显著提升了3D医学图像分割的速度和精度。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在3D医学图像多器官分割中表现出色，但逐体素分析的计算时间和内存消耗巨大。现有分类器虽快但牺牲了精度，因此需要一种既快速又准确的分割方法。

Method: 该方法结合了两个关键组件：1) 分层稀疏采样策略，通过多分辨率级别处理，在减少计算量的同时保留了有意义的分层上下文；2) 残差Transformer分割网络，能够从稀疏描述符的不同信息层提取并结合信息，同时保持较低的计算成本。

Result: 在包含10,253张CT图像的内部数据集和公共TotalSegmentator数据集上，该方法与现有快速器官分类器相比，在定性和定量分割性能上均有所提升，并在CPU硬件上实现了约2.24秒的快速分割速度。

Conclusion: 该研究表明所提出的方法具有实现实时精细器官分割的巨大潜力。

Abstract: Multi-organ segmentation of 3D medical images is fundamental with meaningful applications in various clinical automation pipelines. Although deep learning has achieved superior performance, the time and memory consumption of segmenting the entire 3D volume voxel by voxel using neural networks can be huge. Classifiers have been developed as an alternative in cases with certain points of interest, but the trade-off between speed and accuracy remains an issue. Thus, we propose a novel fast multi-organ segmentation framework with the usage of hierarchical sparse sampling and a Residual Transformer. Compared with whole-volume analysis, the hierarchical sparse sampling strategy could successfully reduce computation time while preserving a meaningful hierarchical context utilizing multiple resolution levels. The architecture of the Residual Transformer segmentation network could extract and combine information from different levels of information in the sparse descriptor while maintaining a low computational cost. In an internal data set containing 10,253 CT images and the public dataset TotalSegmentator, the proposed method successfully improved qualitative and quantitative segmentation performance compared to the current fast organ classifier, with fast speed at the level of ~2.24 seconds on CPU hardware. The potential of achieving real-time fine organ segmentation is suggested.

</details>


### [181] [3D4D: An Interactive, Editable, 4D World Model via 3D Video Generation](https://arxiv.org/abs/2511.08536)
*Yunhong He,Zhengqing Yuan,Zhengzhong Tu,Yanfang Ye,Lichao Sun*

Main category: cs.CV

TL;DR: 3D4D是一个交互式4D可视化框架，结合WebGL和Supersplat渲染，通过核心模块和注视点渲染策略，实现对复杂4D环境的高效实时多模态用户驱动探索。


<details>
  <summary>Details</summary>
Motivation: 将静态图像和文本转化为连贯的4D场景，并实现对复杂4D环境的高效、实时、用户驱动的探索。

Method: 引入3D4D框架，整合WebGL与Supersplat渲染技术，通过四个核心模块将静态内容转换为4D场景，并采用注视点渲染策略实现高效实时多模态交互。

Result: 该框架能够实现对复杂4D环境的自适应、用户驱动探索，并支持高效、实时的多模态交互。

Conclusion: 3D4D提供了一种有效的交互式4D可视化解决方案，用于探索复杂的4D环境。

Abstract: We introduce 3D4D, an interactive 4D visualization framework that integrates WebGL with Supersplat rendering. It transforms static images and text into coherent 4D scenes through four core modules and employs a foveated rendering strategy for efficient, real-time multi-modal interaction. This framework enables adaptive, user-driven exploration of complex 4D environments. The project page and code are available at https://yunhonghe1021.github.io/NOVA/.

</details>


### [182] [RePose-NeRF: Robust Radiance Fields for Mesh Reconstruction under Noisy Camera Poses](https://arxiv.org/abs/2511.08545)
*Sriram Srinivasan,Gautam Ramachandra*

Main category: cs.CV

TL;DR: 本文提出了一种鲁棒框架，可以直接从具有噪声相机外参的多视角图像重建高质量、可编辑的3D网格，同时优化相机姿态并学习隐式场景表示，以满足机器人应用需求。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法严重依赖精确的相机外参（实际获取困难），且其隐式体素表示与广泛使用的多边形网格不兼容，导致在标准3D软件中渲染和操作效率低下，限制了其实用性。

Method: 本文提出一个鲁棒框架，通过联合优化相机姿态，同时学习一个能够捕捉精细几何细节和真实感外观的隐式场景表示，直接从多视角图像重建高质量、可编辑的3D网格。

Result: 实验证明，该方法在姿态不确定性下实现了准确且鲁棒的3D重建。生成的网格与常见的3D图形和机器人工具兼容，支持高效的下游应用。

Conclusion: 该方法在姿态不确定性下实现了准确、鲁棒的3D重建，弥合了神经隐式表示与实际机器人应用之间的鸿沟，提供了实用的解决方案。

Abstract: Accurate 3D reconstruction from multi-view images is essential for downstream robotic tasks such as navigation, manipulation, and environment understanding. However, obtaining precise camera poses in real-world settings remains challenging, even when calibration parameters are known. This limits the practicality of existing NeRF-based methods that rely heavily on accurate extrinsic estimates. Furthermore, their implicit volumetric representations differ significantly from the widely adopted polygonal meshes, making rendering and manipulation inefficient in standard 3D software. In this work, we propose a robust framework that reconstructs high-quality, editable 3D meshes directly from multi-view images with noisy extrinsic parameters. Our approach jointly refines camera poses while learning an implicit scene representation that captures fine geometric detail and photorealistic appearance. The resulting meshes are compatible with common 3D graphics and robotics tools, enabling efficient downstream use. Experiments on standard benchmarks demonstrate that our method achieves accurate and robust 3D reconstruction under pose uncertainty, bridging the gap between neural implicit representations and practical robotic applications.

</details>


### [183] [Vision Transformer Based User Equipment Positioning](https://arxiv.org/abs/2511.08549)
*Parshwa Shah,Dhaval K. Patel,Brijesh Soni,Miguel López-Benítez,Siddhartan Govindasamy*

Main category: cs.CV

TL;DR: 本文提出一种基于注意力机制的Vision Transformer (ViT) 架构，利用信道状态信息(CSI)中的角度延迟剖面(ADP)进行用户设备(UE)定位，在多个数据集上显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习(DL)模型在UE定位方面存在两个主要缺点：i) 对所有输入给予同等关注；ii) 不适用于非序列数据，例如仅有瞬时CSI的情况。

Method: 本文提出一种基于注意力机制的Vision Transformer (ViT) 架构，该架构专注于从CSI矩阵中提取的角度延迟剖面(ADP)。

Result: 该方法在`DeepMIMO'数据集上室内RMSE为0.55m，室外为13.59m；在`ViWi'室外阻塞场景中RMSE为3.45m。性能优于现有最先进方案约38%，并且在误差距离分布方面也表现显著更好。

Conclusion: 所提出的基于注意力机制的ViT架构通过有效利用CSI中的ADP，显著提升了UE定位的精度，克服了传统DL模型在处理瞬时非序列数据方面的局限性，并优于现有技术。

Abstract: Recently, Deep Learning (DL) techniques have been used for User Equipment (UE) positioning. However, the key shortcomings of such models is that: i) they weigh the same attention to the entire input; ii) they are not well suited for the non-sequential data e.g., when only instantaneous Channel State Information (CSI) is available. In this context, we propose an attention-based Vision Transformer (ViT) architecture that focuses on the Angle Delay Profile (ADP) from CSI matrix. Our approach, validated on the `DeepMIMO' and `ViWi' ray-tracing datasets, achieves an Root Mean Squared Error (RMSE) of 0.55m indoors, 13.59m outdoors in DeepMIMO, and 3.45m in ViWi's outdoor blockage scenario. The proposed scheme outperforms state-of-the-art schemes by $\sim$ 38\%. It also performs substantially better than other approaches that we have considered in terms of the distribution of error distance.

</details>


### [184] [CleverBirds: A Multiple-Choice Benchmark for Fine-grained Human Knowledge Tracing](https://arxiv.org/abs/2511.08512)
*Leonie Bossemeyer,Samuel Heinrich,Grant Van Horn,Oisin Mac Aodha*

Main category: cs.CV

TL;DR: 该论文介绍了CleverBirds，一个大规模的细粒度鸟类识别视觉知识追踪基准数据集，旨在研究人类如何习得视觉专业知识。


<details>
  <summary>Details</summary>
Motivation: 掌握细粒度视觉识别需要多年的专业训练，而建模人类专家知识的获取过程并准确推断学习者的知识状态是一项挑战，但对于理解视觉学习至关重要。

Method: 研究人员引入了CleverBirds数据集，该数据集通过公民科学平台eBird收集。它包含超过40,000名参与者回答的1700多万道多项选择题，涵盖10,000多种鸟类，每个参与者平均有400个长期学习模式的问题。他们发布此数据集以支持视觉知识追踪新方法的开发和评估。

Result: 研究表明，追踪学习者的知识具有挑战性，尤其是在不同的参与者亚组和问题类型之间。不同形式的上下文信息提供了不同程度的预测益处。CleverBirds是同类基准中规模最大的之一，提供了显著更多的可学习概念。

Conclusion: CleverBirds数据集的发布有望为研究视觉专业知识随时间推移和个体差异的发展开辟新的途径，从而更深入地理解人类的视觉学习过程。

Abstract: Mastering fine-grained visual recognition, essential in many expert domains, can require that specialists undergo years of dedicated training. Modeling the progression of such expertize in humans remains challenging, and accurately inferring a human learner's knowledge state is a key step toward understanding visual learning. We introduce CleverBirds, a large-scale knowledge tracing benchmark for fine-grained bird species recognition. Collected by the citizen-science platform eBird, it offers insight into how individuals acquire expertize in complex fine-grained classification. More than 40,000 participants have engaged in the quiz, answering over 17 million multiple-choice questions spanning over 10,000 bird species, with long-range learning patterns across an average of 400 questions per participant. We release this dataset to support the development and evaluation of new methods for visual knowledge tracing. We show that tracking learners' knowledge is challenging, especially across participant subgroups and question types, with different forms of contextual information offering varying degrees of predictive benefit. CleverBirds is among the largest benchmark of its kind, offering a substantially higher number of learnable concepts. With it, we hope to enable new avenues for studying the development of visual expertize over time and across individuals.

</details>


### [185] [UniVA: Universal Video Agent towards Open-Source Next-Generation Video Generalist](https://arxiv.org/abs/2511.08521)
*Zhengyang Liang,Daoan Zhang,Huichi Zhou,Rui Huang,Bobo Li,Yuechen Zhang,Shengqiong Wu,Xiaohan Wang,Jiebo Luo,Lizi Liao,Hao Fei*

Main category: cs.CV

TL;DR: UniVA是一个开源、全能的多智能体框架，通过“规划-执行”架构和分层记忆，将视频理解、分割、编辑和生成统一到连贯的工作流中，以实现复杂的、交互式的视频创作。该研究还提出了UniVA-Bench基准测试套件。


<details>
  <summary>Details</summary>
Motivation: 现有的人工智能模型擅长独立的视频任务（如生成或理解），但实际应用需要结合这些能力的复杂、迭代的工作流。为了弥合专业模型与实际应用中对连贯视频工作流的需求之间的差距，该研究旨在开发一个能够统一这些能力的通用系统。

Method: UniVA采用“规划-执行”双智能体架构：规划智能体解释用户意图并将其分解为结构化的视频处理步骤；执行智能体通过模块化的、基于MCP的工具服务器（用于分析、生成、编辑、跟踪等）执行这些步骤。系统通过分层多级记忆（全局知识、任务上下文和用户特定偏好）维持长程推理、上下文连续性和智能体间通信。此外，还引入了UniVA-Bench，一个用于评估此类智能体视频系统的多步骤视频任务基准套件。

Result: UniVA实现了交互式、自反思的视频创作，并具有完整的可追溯性。它能够支持迭代和任意条件下的视频工作流（例如，文本/图像/视频条件生成→多轮编辑→对象分割→合成），这些工作流以前使用单一用途模型或整体视频-语言模型难以实现。UniVA和UniVA-Bench均已完全开源。

Conclusion: UniVA旨在推动交互式、智能体化和通用视频智能的研究，为下一代多模态AI系统提供支持。它成功地将孤立的视频任务整合到统一的工作流中，解决了现有专业模型在复杂应用中的局限性。

Abstract: While specialized AI models excel at isolated video tasks like generation or understanding, real-world applications demand complex, iterative workflows that combine these capabilities. To bridge this gap, we introduce UniVA, an open-source, omni-capable multi-agent framework for next-generation video generalists that unifies video understanding, segmentation, editing, and generation into cohesive workflows. UniVA employs a Plan-and-Act dual-agent architecture that drives a highly automated and proactive workflow: a planner agent interprets user intentions and decomposes them into structured video-processing steps, while executor agents execute these through modular, MCP-based tool servers (for analysis, generation, editing, tracking, etc.). Through a hierarchical multi-level memory (global knowledge, task context, and user-specific preferences), UniVA sustains long-horizon reasoning, contextual continuity, and inter-agent communication, enabling interactive and self-reflective video creation with full traceability. This design enables iterative and any-conditioned video workflows (e.g., text/image/video-conditioned generation $\rightarrow$ multi-round editing $\rightarrow$ object segmentation $\rightarrow$ compositional synthesis) that were previously cumbersome to achieve with single-purpose models or monolithic video-language models. We also introduce UniVA-Bench, a benchmark suite of multi-step video tasks spanning understanding, editing, segmentation, and generation, to rigorously evaluate such agentic video systems. Both UniVA and UniVA-Bench are fully open-sourced, aiming to catalyze research on interactive, agentic, and general-purpose video intelligence for the next generation of multimodal AI systems. (https://univa.online/)

</details>


### [186] [Compression then Matching: An Efficient Pre-training Paradigm for Multimodal Embedding](https://arxiv.org/abs/2511.08480)
*Da Li,Yuxiao Luo,Keping Bi,Jiafeng Guo,Wei Yuan,Biao Yang,Yan Wang,Fan Yang,Tingting Gao,Guorui Zhou*

Main category: cs.CV

TL;DR: 本文提出CoMa，一个压缩预训练阶段，作为对比学习的热身阶段，旨在用少量数据将视觉语言模型（VLM）转化为高效且有效的嵌入模型，并在MMEB上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型通过可迁移的语义嵌入提升多模态表示学习，但在下游任务中，有效的嵌入需要同时保留语义内容并强调判别性特征。现有方法通过大规模对比学习同时优化这两个目标，但本文认为这两个目标可以解耦，即对输入的全面理解有助于通过对比学习在下游任务中取得更好性能。

Method: 提出CoMa（Compressed pre-training phase），一个压缩预训练阶段，作为对比学习的热身阶段。CoMa旨在促进对输入的全面理解，从而为后续的对比学习提供更好的基础。

Result: 实验表明，仅用少量预训练数据，CoMa就能将VLM转化为具有竞争力的嵌入模型。CoMa在MMEB基准测试中，在同等规模的VLM中取得了新的SOTA结果，实现了效率和有效性的双重优化。

Conclusion: 通过引入CoMa压缩预训练阶段，成功地解耦了VLM嵌入模型的训练目标，并在仅使用少量预训练数据的情况下，显著提升了模型的效率和有效性，使其在多模态嵌入任务中达到最先进水平。

Abstract: Vision-language models advance multimodal representation learning by acquiring transferable semantic embeddings, thereby substantially enhancing performance across a range of vision-language tasks, including cross-modal retrieval, clustering, and classification. An effective embedding is expected to comprehensively preserve the semantic content of the input while simultaneously emphasizing features that are discriminative for downstream tasks. Recent approaches demonstrate that VLMs can be adapted into competitive embedding models via large-scale contrastive learning, enabling the simultaneous optimization of two complementary objectives. We argue that the two aforementioned objectives can be decoupled: a comprehensive understanding of the input facilitates the embedding model in achieving superior performance in downstream tasks via contrastive learning. In this paper, we propose CoMa, a compressed pre-training phase, which serves as a warm-up stage for contrastive learning. Experiments demonstrate that with only a small amount of pre-training data, we can transform a VLM into a competitive embedding model. CoMa achieves new state-of-the-art results among VLMs of comparable size on the MMEB, realizing optimization in both efficiency and effectiveness.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [187] [A Preliminary Study of RAG for Taiwanese Historical Archives](https://arxiv.org/abs/2511.07445)
*Claire Lin,Bo-Han Feng,Xuanjun Chen,Te-Lun Yang,Hung-yi Lee,Jyh-Shing Roger Jang*

Main category: cs.CL

TL;DR: 本研究首次將RAG應用於台灣歷史檔案，探討查詢特性和元數據整合策略的影響，發現早期元數據整合能提升準確性，但仍面臨幻覺和複雜查詢處理的挑戰。


<details>
  <summary>Details</summary>
Motivation: 儘管RAG在知識密集型任務中表現出色，但很少有研究將其應用於台灣歷史檔案。

Method: 本研究將RAG管道應用於兩個繁體中文歷史數據集（熱蘭遮城和台灣省議會公報）及其開放式查詢集，系統性地探討了查詢特性和元數據整合策略對檢索質量、答案生成和整體系統性能的影響。

Result: 結果顯示，早期元數據整合能提升檢索和答案的準確性。同時，RAG系統仍面臨持續的挑戰，包括生成過程中的幻覺以及處理時間性或多跳歷史查詢的困難。

Conclusion: RAG在台灣歷史檔案應用中具有潛力，特別是結合早期元數據整合。然而，仍需解決幻覺生成以及處理複雜歷史查詢等挑戰。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach for knowledge-intensive tasks. However, few studies have examined RAG for Taiwanese Historical Archives. In this paper, we present an initial study of a RAG pipeline applied to two historical Traditional Chinese datasets, Fort Zeelandia and the Taiwan Provincial Council Gazette, along with their corresponding open-ended query sets. We systematically investigate the effects of query characteristics and metadata integration strategies on retrieval quality, answer generation, and the performance of the overall system. The results show that early-stage metadata integration enhances both retrieval and answer accuracy while also revealing persistent challenges for RAG systems, including hallucinations during generation and difficulties in handling temporal or multi-hop historical queries.

</details>


### [188] [Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey](https://arxiv.org/abs/2511.07448)
*Fatemeh Shahhosseini,Arash Marioriyad,Ali Momen,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban,Shaghayegh Haghjooy Javanmard*

Main category: cs.CL

TL;DR: 这篇综述系统地分析了大型语言模型（LLM）在科学思想生成中的应用方法，探讨了如何在创意和科学严谨性之间取得平衡，并使用创造力框架对现有方法进行了分类和解读。


<details>
  <summary>Details</summary>
Motivation: 科学思想生成是科学发现的核心，驱动着人类进步。大型语言模型在生成科学思想方面展现出潜力，但其创造力不稳定且未被充分理解。因此，需要对LLM驱动的科学构思方法进行系统性梳理和分析，以更好地理解和提升其在科学发现中的应用。

Method: 本研究通过结构化综合分析了LLM驱动科学构思的方法。将现有方法归类为五大家族：外部知识增强、基于提示的分布引导、推理时间扩展、多智能体协作和参数级适应。为了解读这些方法的贡献，采用了两个互补的创造力框架：Boden的组合、探索和转化创造力分类法，以及Rhodes的4P框架（人物、过程、环境、产品）。

Result: 本综述将LLM驱动的科学构思方法归纳为五大家族，并利用Boden的创造力分类法和Rhodes的4P框架，解释了每种方法预期产生的思想水平及其强调的创造力方面。通过将方法学进展与创造力框架相结合，澄清了该领域的现状。

Conclusion: 本综述通过将方法学进展与创造力框架对齐，明确了LLM在科学构思领域的现状，并指出了未来实现可靠、系统和变革性应用的几个关键方向，以推动LLM在科学发现中的作用。

Abstract: Scientific idea generation lies at the heart of scientific discovery and has driven human progress-whether by solving unsolved problems or proposing novel hypotheses to explain unknown phenomena. Unlike standard scientific reasoning or general creative generation, idea generation in science is a multi-objective and open-ended task, where the novelty of a contribution is as essential as its empirical soundness. Large language models (LLMs) have recently emerged as promising generators of scientific ideas, capable of producing coherent and factual outputs with surprising intuition and acceptable reasoning, yet their creative capacity remains inconsistent and poorly understood. This survey provides a structured synthesis of methods for LLM-driven scientific ideation, examining how different approaches balance creativity with scientific soundness. We categorize existing methods into five complementary families: External knowledge augmentation, Prompt-based distributional steering, Inference-time scaling, Multi-agent collaboration, and Parameter-level adaptation. To interpret their contributions, we employ two complementary frameworks: Boden's taxonomy of Combinatorial, Exploratory and Transformational creativity to characterize the level of ideas each family expected to generate, and Rhodes' 4Ps framework-Person, Process, Press, and Product-to locate the aspect or source of creativity that each method emphasizes. By aligning methodological advances with creativity frameworks, this survey clarifies the state of the field and outlines key directions toward reliable, systematic, and transformative applications of LLMs in scientific discovery.

</details>


### [189] [REFLEX: Reference-Free Evaluation of Log Summarization via Large Language Model Judgment](https://arxiv.org/abs/2511.07458)
*Priyanka Mudgal*

Main category: cs.CL

TL;DR: 本文提出REFLEX，一种基于大型语言模型（LLM）判断的无参考日志摘要评估指标，旨在解决传统指标和参考数据稀缺的挑战。


<details>
  <summary>Details</summary>
Motivation: 日志摘要系统评估面临挑战，原因在于缺乏高质量的参考摘要，且ROUGE和BLEU等现有指标依赖于表面词汇重叠，存在局限性。

Method: 引入REFLEX，一种利用LLM作为零样本评估器的无参考评估指标。REFLEX通过LLM评估摘要在相关性、信息量和连贯性等维度上的质量，无需金标准参考或人工标注。

Result: REFLEX在多个日志摘要数据集上产生稳定、可解释且细粒度的评估结果，并且比传统指标能更有效地区分模型输出。

Conclusion: REFLEX为在参考数据稀缺或不可用的实际场景中评估日志摘要提供了一种可扩展的替代方案。

Abstract: Evaluating log summarization systems is challenging due to the lack of high-quality reference summaries and the limitations of existing metrics like ROUGE and BLEU, which depend on surface-level lexical overlap. We introduce REFLEX, a reference-free evaluation metric for log summarization based on large language model (LLM) judgment. REFLEX uses LLMs as zero-shot evaluators to assess summary quality along dimensions such as relevance, informativeness, and coherence, without requiring gold-standard references or human annotations. We show that REFLEX produces stable, interpretable, and fine-grained evaluations across multiple log summarization dataset, and more effectively distinguishes model outputs than traditional metrics. REFLEX provides a scalable alternative for evaluating log summaries in real-world settings where reference data is scarce or unavailable.

</details>


### [190] [GRIP: In-Parameter Graph Reasoning through Fine-Tuning Large Language Models](https://arxiv.org/abs/2511.07457)
*Jiarui Feng,Donghong Cai,Yixin Chen,Muhan Zhang*

Main category: cs.CL

TL;DR: GRIP提出了一种新颖的框架，通过精心设计的微调任务，将图的复杂关系信息注入到LLM的轻量级LoRA参数中，使其无需在推理时访问原始图即可执行各种图相关任务，并验证了其有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在处理文本数据方面表现出色，但在处理知识图谱或网络数据等结构化数据时仍面临挑战。现有方法如将图转换为文本序列会导致高昂的token开销，或引入额外模块进行图编码，但这些方法通常需要大规模的图-文本语料库进行后训练和复杂的对齐过程，且由于模态对齐不佳，效果往往不理想。

Method: GRIP（Graph Relational Information Parameterization）框架。该方法受LLM参数内知识注入的启发，通过精心设计的微调任务，使LLM能够内化图中的复杂关系信息。这些知识被高效地存储在轻量级的LoRA参数中。

Result: 经过微调的LLM能够在推理时无需访问原始图的情况下，执行广泛的图相关任务。在多个基准测试上的大量实验验证了该方法的有效性和效率。

Conclusion: GRIP框架成功地赋予了LLM处理复杂图关系信息的能力，克服了现有方法在处理结构化数据时的局限性，实现了高效且有效的图相关任务执行。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in modeling sequential textual data and generalizing across diverse tasks. However, adapting LLMs to effectively handle structural data, such as knowledge graphs or web data, remains a challenging problem. Some approaches adopt complex strategies to convert graphs into text sequences, resulting in significant token overhead and rendering them impractical for large-scale graphs. Others introduce additional modules to encode graphs into fixed-size token representations for LLMs. However, these methods typically require large-scale post-training on graph-text corpus and complex alignment procedures, yet often yield sub-optimal results due to poor modality alignment. Inspired by in-parameter knowledge injection for test-time adaptation of LLMs, we propose GRIP, a novel framework that equips LLMs with the ability to internalize complex relational information from graphs through carefully designed fine-tuning tasks. This knowledge is efficiently stored within lightweight LoRA parameters, enabling the fine-tuned LLM to perform a wide range of graph-related tasks without requiring access to the original graph at inference time. Extensive experiments across multiple benchmarks validate the effectiveness and efficiency of our approach.

</details>


### [191] [It Takes Two: A Dual Stage Approach for Terminology-Aware Translation](https://arxiv.org/abs/2511.07461)
*Akshat Singh Jaswal*

Main category: cs.CL

TL;DR: 本文提出了DuTerm，一个两阶段的术语约束机器翻译系统，结合了术语感知NMT和基于提示的LLM后编辑，证明LLM作为上下文驱动的修改器比严格的生成器能产生更高质量的翻译。


<details>
  <summary>Details</summary>
Motivation: 研究旨在改进术语约束机器翻译，特别是通过灵活且上下文驱动的方式处理术语，以提高翻译质量。

Method: DuTerm采用两阶段架构：1. 一个术语感知的NMT模型，通过大规模合成数据进行微调；2. 一个基于提示的大型语言模型（LLM）用于后编辑，以优化NMT输出并强制执行术语一致性。

Result: 在WMT 2025术语共享任务（英-德、英-西、英-俄）上的评估显示，LLM灵活、上下文驱动的术语处理方式比严格的约束强制执行能带来更高质量的翻译。结果强调了一个关键权衡：LLM作为上下文驱动的修改器（mutators）在高质量翻译方面表现最佳，而非生成器（generators）。

Conclusion: DuTerm系统证明了大型语言模型在术语约束机器翻译中作为后编辑工具的有效性，特别是当它们被用于灵活、上下文驱动的术语细化而非严格生成时，能显著提升翻译质量。

Abstract: This paper introduces DuTerm, a novel two-stage architecture for terminology-constrained machine translation. Our system combines a terminology-aware NMT model, adapted via fine-tuning on large-scale synthetic data, with a prompt-based LLM for post-editing. The LLM stage refines NMT output and enforces terminology adherence. We evaluate DuTerm on English-to German, English-to-Spanish, and English-to-Russian with the WMT 2025 Terminology Shared Task corpus. We demonstrate that flexible, context-driven terminology handling by the LLM consistently yields higher quality translations than strict constraint enforcement. Our results highlight a critical trade-off, revealing that an LLM's work best for high-quality translation as context-driven mutators rather than generators.

</details>


### [192] [Motif 2 12.7B technical report](https://arxiv.org/abs/2511.07464)
*Junghwan Lim,Sungmin Lee,Dongseok Kim,Taehyun Kim,Eunhwan Park,Jeesoo Lee,Jeongdoo Lee,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Jaeheui Her,Jaeyeon Huh,Hanbin Jung,Changjin Kang,Beomgyu Kim,Minjae Kim,Taewhan Kim,Youngrok Kim,Hyukjin Kweon,Haesol Lee,Kungyu Lee,Dongpin Oh,Yeongjae Park,Bokki Ryu,Dongjoo Weon*

Main category: cs.CL

TL;DR: Motif-2-12.7B是一个新的开源基础模型，通过结合架构创新（如分组差分注意力GDA）和系统级优化，显著提升了大型语言模型的效率，并在有限计算预算下实现了强大的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了在有限的计算预算下，推动大型语言模型的效率前沿，实现可扩展的语言理解和强大的指令泛化能力。

Method: 该模型基于Motif-2.6B，集成了分组差分注意力（GDA）以提高表示效率。它在一个包含5.5万亿个tokens的多样化数据集上进行预训练，采用课程驱动的数据调度器。训练系统利用MuonClip优化器和自定义高性能内核（包括融合PolyNorm激活和并行Muon算法），以提高吞吐量和内存效率。后期训练采用三阶段监督微调流程，以增强指令遵循、组合理解和语言精度。

Result: Motif-2-12.7B在各种基准测试中表现出有竞争力的性能，表明经过深思熟虑的架构扩展和优化的训练设计能够与大得多模型的能力相媲美。

Conclusion: 该研究得出结论，通过深思熟虑的架构扩展和优化的训练设计，即使在有限的计算预算下，也能开发出与更大模型能力相当的高效大型语言模型。

Abstract: We introduce Motif-2-12.7B, a new open-weight foundation model that pushes the efficiency frontier of large language models by combining architectural innovation with system-level optimization. Designed for scalable language understanding and robust instruction generalization under constrained compute budgets, Motif-2-12.7B builds upon Motif-2.6B with the integration of Grouped Differential Attention (GDA), which improves representational efficiency by disentangling signal and noise-control attention pathways. The model is pre-trained on 5.5 trillion tokens spanning diverse linguistic, mathematical, scientific, and programming domains using a curriculum-driven data scheduler that gradually changes the data composition ratio. The training system leverages the MuonClip optimizer alongside custom high-performance kernels, including fused PolyNorm activations and the Parallel Muon algorithm, yielding significant throughput and memory efficiency gains in large-scale distributed environments. Post-training employs a three-stage supervised fine-tuning pipeline that successively enhances general instruction adherence, compositional understanding, and linguistic precision. Motif-2-12.7B demonstrates competitive performance across diverse benchmarks, showing that thoughtful architectural scaling and optimized training design can rival the capabilities of much larger models.

</details>


### [193] [Focusing on Language: Revealing and Exploiting Language Attention Heads in Multilingual Large Language Models](https://arxiv.org/abs/2511.07498)
*Xin Liu,Qiyang Song,Qihang Zhou,Haichao Du,Shaowen Xu,Wenbo Jiang,Weijuan Zhang,Xiaoqi Jia*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLMs）中多头自注意力（MHA）对多语言能力的作用。通过提出LAHIS方法，我们识别出语言特定和语言通用的注意力头，并发现语言特定头有助于跨语言注意力转移和缓解离目标语言生成问题。此外，我们引入了一种轻量级适配方法，用少量参数提高了多语言性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在多语言理解和生成方面的能力增强，以及对模型内部机制解释的需求日益增长，MHA在许多领域已被证明至关重要，但其在LLMs多语言能力中的具体作用尚未得到充分探索。

Method: 本研究提出了一种名为LAHIS（Language Attention Head Importance Scores）的有效且高效的方法，通过一次前向和反向传播即可识别注意力头对多语言能力的重要性。该方法应用于Aya-23-8B、Llama-3.2-3B和Mistral-7B-v0.1模型。此外，还引入了一种轻量级适配方法，通过学习软注意力头掩码来调节注意力输出，仅需20个可调参数。

Result: 研究揭示了LLMs中存在语言特定和语言通用的注意力头。语言特定头能够实现跨语言注意力转移，引导模型关注目标语言上下文，并缓解离目标语言生成问题。引入的轻量级适配方法仅需20个参数即可提高XQuAD的准确性。

Conclusion: 本工作从MHA的角度提升了LLMs的可解释性和多语言能力。通过识别和利用注意力头的语言特定贡献，为解决多语言LLMs中的挑战提供了新的见解和方法。

Abstract: Large language models (LLMs) increasingly support multilingual understanding and generation. Meanwhile, efforts to interpret their internal mechanisms have emerged, offering insights to enhance multilingual performance. While multi-head self-attention (MHA) has proven critical in many areas, its role in multilingual capabilities remains underexplored. In this work, we study the contribution of MHA in supporting multilingual processing in LLMs. We propose Language Attention Head Importance Scores (LAHIS), an effective and efficient method that identifies attention head importance for multilingual capabilities via a single forward and backward pass through the LLM. Applying LAHIS to Aya-23-8B, Llama-3.2-3B, and Mistral-7B-v0.1, we reveal the existence of both language-specific and language-general heads. Language-specific heads enable cross-lingual attention transfer to guide the model toward target language contexts and mitigate off-target language generation issue, contributing to addressing challenges in multilingual LLMs. We also introduce a lightweight adaptation that learns a soft head mask to modulate attention outputs over language heads, requiring only 20 tunable parameters to improve XQuAD accuracy. Overall, our work enhances both the interpretability and multilingual capabilities of LLMs from the perspective of MHA.

</details>


### [194] [LLM Optimization Unlocks Real-Time Pairwise Reranking](https://arxiv.org/abs/2511.07555)
*Jingyu Wu,Aditya Shrivastava,Jing Zhu,Alfy Samuel,Anoop Kumar,Daben Liu*

Main category: cs.CL

TL;DR: 本研究通过应用一系列优化方法，显著降低了基于LLM的RAG系统文档重排序的延迟（高达166倍），使其在保持性能的同时更适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 提高RAG系统整体质量的文档重排序是一个重要而具有挑战性的问题。LLM在重排序任务中表现出色，特别是成对重排序提示（PRP）方法因其可用性和有效性而备受关注。然而，该算法的固有复杂性以及LLM带来的高计算需求和延迟，限制了其在实时应用中的可行性。

Method: 本文专注于成对重排序，通过实施一系列优化方法来解决效率问题。这些方法包括使用小型模型、限制重排序集合大小、采用较低精度、通过单向顺序推理减少位置偏差，以及限制输出token数量。

Result: 通过这些优化，每查询延迟从61.36秒显著降低到0.37秒，实现了高达166倍的延迟减少。同时，以Recall@k衡量的性能下降微不足道。

Conclusion: 本研究强调了先前被忽视的设计选择的重要性，这些优化使基于LLM的重排序在延迟敏感的实际部署中变得更加高效和可行。

Abstract: Efficiently reranking documents retrieved from information retrieval (IR) pipelines to enhance overall quality of Retrieval-Augmented Generation (RAG) system remains an important yet challenging problem. Recent studies have highlighted the importance of Large Language Models (LLMs) in reranking tasks. In particular, Pairwise Reranking Prompting (PRP) has emerged as a promising plug-and-play approach due to its usability and effectiveness. However, the inherent complexity of the algorithm, coupled with the high computational demands and latency incurred due to LLMs, raises concerns about its feasibility in real-time applications. To address these challenges, this paper presents a focused study on pairwise reranking, demonstrating that carefully applied optimization methods can significantly mitigate these issues. By implementing these methods, we achieve a remarkable latency reduction of up to 166 times, from 61.36 seconds to 0.37 seconds per query, with an insignificant drop in performance measured by Recall@k. Our study highlights the importance of design choices that were previously overlooked, such as using smaller models, limiting the reranked set, using lower precision, reducing positional bias with one-directional order inference, and restricting output tokens. These optimizations make LLM-based reranking substantially more efficient and feasible for latency-sensitive, real-world deployments.

</details>


### [195] [LLMs vs. Traditional Sentiment Tools in Psychology: An Evaluation on Belgian-Dutch Narratives](https://arxiv.org/abs/2511.07641)
*Ratna Kandala,Katie Hoemann*

Main category: cs.CL

TL;DR: 本研究评估了三款荷兰语大语言模型（LLMs）在弗拉芒语（一种低资源语言变体）效价预测任务中的表现，结果发现它们出人意料地不如传统词典工具（如Pattern），挑战了LLMs在情感分析任务中的优越性假设。


<details>
  <summary>Details</summary>
Motivation: 理解日常语言中的情感细微差别对计算语言学和情感研究至关重要。传统基于词典的工具（如LIWC和Pattern）是基础工具，而大型语言模型（LLMs）有望增强上下文理解能力。因此，研究旨在评估LLMs在低资源语言变体中效价预测的表现，并与传统方法进行比较。

Method: 研究评估了三款荷兰语大语言模型（ChocoLlama-8B-Instruct, Reynaerde-7B-chat, GEITje-7B-ultra），并将其与传统工具LIWC和Pattern在弗拉芒语的效价预测任务中进行比较。数据集包含约25000份来自102名荷兰语参与者的自发文本回复，每份回复都附有自我评估的效价评分（-50到+50）。

Result: 令人惊讶的是，尽管LLMs在架构上有所进步，但这些荷兰语微调的LLMs在效价预测任务中的表现不如传统方法，其中Pattern表现最佳。这些发现挑战了LLMs在情感分析任务中具有优越性的假设。

Conclusion: 研究结果挑战了LLMs在情感分析任务中具有优越性的假设，并强调了在自发、真实世界的叙述中捕捉情感效价的复杂性。这凸显了为低资源语言变体开发文化和语言定制评估框架的必要性，并质疑当前LLM微调方法是否足以处理日常语言使用中细微的情感表达。

Abstract: Understanding emotional nuances in everyday language is crucial for computational linguistics and emotion research. While traditional lexicon-based tools like LIWC and Pattern have served as foundational instruments, Large Language Models (LLMs) promise enhanced context understanding. We evaluated three Dutch-specific LLMs (ChocoLlama-8B-Instruct, Reynaerde-7B-chat, and GEITje-7B-ultra) against LIWC and Pattern for valence prediction in Flemish, a low-resource language variant. Our dataset comprised approximately 25000 spontaneous textual responses from 102 Dutch-speaking participants, each providing narratives about their current experiences with self-assessed valence ratings (-50 to +50). Surprisingly, despite architectural advancements, the Dutch-tuned LLMs underperformed compared to traditional methods, with Pattern showing superior performance. These findings challenge assumptions about LLM superiority in sentiment analysis tasks and highlight the complexity of capturing emotional valence in spontaneous, real-world narratives. Our results underscore the need for developing culturally and linguistically tailored evaluation frameworks for low-resource language variants, while questioning whether current LLM fine-tuning approaches adequately address the nuanced emotional expressions found in everyday language use.

</details>


### [196] [Stress Testing Factual Consistency Metrics for Long-Document Summarization](https://arxiv.org/abs/2511.07689)
*Zain Muhammad Mujahid,Dustin Wright,Isabelle Augenstein*

Main category: cs.CL

TL;DR: 本文系统评估了六种广泛使用的、无参考的事实一致性指标在长文档摘要中的可靠性，发现它们对于语义等效的摘要产生不一致分数，并且在长上下文条件下无法持续保持事实对齐。


<details>
  <summary>Details</summary>
Motivation: 评估长文档抽象式文本摘要的事实一致性是一个重大挑战，现有指标受限于输入长度和长距离依赖性，难以有效应对。

Method: 研究者系统评估了六种最初为短文档摘要设计的无参考事实一致性指标在长文档设置下的可靠性。他们通过七种保持事实的扰动（如释义、简化、同义词替换等）来探测指标的鲁棒性，并分析了指标对检索上下文和声明信息密度的敏感性。评估工作在三个跨科幻、法律和科学领域的长文档基准数据集上进行。

Result: 结果显示，现有短文档指标对语义等效的摘要产生不一致的分数，并且对于内容与源文档多处语义相似的信息密集声明，其可靠性会下降。尽管扩展检索上下文在某些领域能提高稳定性，但没有一个指标能在长上下文条件下始终保持事实对齐。

Conclusion: 研究结果为改进事实一致性评估指明了具体方向，包括多跨度推理、上下文感知校准以及通过在保持意义的变体上进行训练以增强长文档摘要的鲁棒性。所有代码和数据均已发布。

Abstract: Evaluating the factual consistency of abstractive text summarization remains a significant challenge, particularly for long documents, where conventional metrics struggle with input length limitations and long-range dependencies. In this work, we systematically evaluate the reliability of six widely used reference-free factuality metrics, originally proposed for short-form summarization, in the long-document setting. We probe metric robustness through seven factuality-preserving perturbations applied to summaries, namely paraphrasing, simplification, synonym replacement, logically equivalent negations, vocabulary reduction, compression, and source text insertion, and further analyze their sensitivity to retrieval context and claim information density. Across three long-form benchmark datasets spanning science fiction, legal, and scientific domains, our results reveal that existing short-form metrics produce inconsistent scores for semantically equivalent summaries and exhibit declining reliability for information-dense claims whose content is semantically similar to many parts of the source document. While expanding the retrieval context improves stability in some domains, no metric consistently maintains factual alignment under long-context conditions. Finally, our results highlight concrete directions for improving factuality evaluation, including multi-span reasoning, context-aware calibration, and training on meaning-preserving variations to enhance robustness in long-form summarization. We release all code, perturbed data, and scripts required to reproduce our results at https://github.com/zainmujahid/metricEval-longSum.

</details>


### [197] [CAPO: Confidence Aware Preference Optimization Learning for Multilingual Preferences](https://arxiv.org/abs/2511.07691)
*Rhitabrat Pokharel,Yufei Tao,Ameeta Agrawal*

Main category: cs.CL

TL;DR: 本文提出了一种名为CAPO（Confidence-Aware Preference Optimization）的简单而有效的方法，通过基于相对奖励的动态损失缩放机制，解决了传统偏好优化（如DPO）在多语言环境中泛化能力差的问题，显著提升了大型语言模型（LLMs）的多语言对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有的偏好优化方法（如DPO）在英语环境中表现良好，但在多语言设置中往往无法稳健泛化。多语言文本中常遇到嘈杂或低裕度的比较数据，导致模型对齐效果不佳。

Method: CAPO用一种动态损失缩放机制取代了DPO对偏好对的固定处理。该机制根据相对奖励调整学习信号，从而根据对每个偏好对的置信度来调制学习信号。这增强了模型对多语言文本中常见的噪声或低裕度比较的鲁棒性。

Result: 实验结果表明，CAPO在奖励准确性方面比现有偏好优化基线至少提高了16%。它通过扩大偏好响应和非偏好响应之间的差距，改善了跨语言的对齐效果。

Conclusion: CAPO是一种简单但有效的偏好优化替代方案，通过其置信度感知机制，显著提高了大型语言模型在多语言环境中的对齐能力和对噪声数据的鲁棒性。

Abstract: Preference optimization is a critical post-training technique used to align large language models (LLMs) with human preferences, typically by fine-tuning on ranked response pairs. While methods like Direct Preference Optimization (DPO) have proven effective in English, they often fail to generalize robustly to multilingual settings. We propose a simple yet effective alternative, Confidence-Aware Preference Optimization (CAPO), which replaces DPO's fixed treatment of preference pairs with a dynamic loss scaling mechanism based on a relative reward. By modulating the learning signal according to the confidence in each preference pair, CAPO enhances robustness to noisy or low-margin comparisons, typically encountered in multilingual text. Empirically, CAPO outperforms existing preference optimization baselines by at least 16% in reward accuracy, and improves alignment by widening the gap between preferred and dispreferred responses across languages.

</details>


### [198] [Revisiting NLI: Towards Cost-Effective and Human-Aligned Metrics for Evaluating LLMs in Question Answering](https://arxiv.org/abs/2511.07659)
*Sai Shridhar Balamurali,Lu Cheng*

Main category: cs.CL

TL;DR: 研究重新评估了一种轻量级的NLI（自然语言推理）评分方法，结合词汇匹配旗标，发现在长篇问答中评估LLM答案时，其准确性可与GPT-4o媲美，但成本显著降低。


<details>
  <summary>Details</summary>
Motivation: 评估最先进的大型语言模型（LLM）的答案具有挑战性：传统的词汇度量无法捕捉语义细微差别，而“LLM作为评判者”的评分方法计算成本过高。

Method: 研究重新评估了一种轻量级替代方案——现成的自然语言推理（NLI）评分，并辅以一个简单的词汇匹配旗标。为了严格测试这些度量标准与人类判断的一致性，研究引入了一个新的3000样本人工标注基准DIVER-QA，涵盖五个问答数据集和五个候选LLM。

Result: 结果显示，这种数十年前的NLI结合词汇匹配技术在长篇问答中与GPT-4o的准确率（89.9%）相匹配，但所需的参数数量级少得多。

Conclusion: 研究强调，廉价的基于NLI的评估方法仍然具有竞争力，并提供DIVER-QA作为未来度量研究的开放资源。

Abstract: Evaluating answers from state-of-the-art large language models (LLMs) is challenging: lexical metrics miss semantic nuances, whereas "LLM-as-Judge" scoring is computationally expensive. We re-evaluate a lightweight alternative -- off-the-shelf Natural Language Inference (NLI) scoring augmented by a simple lexical-match flag and find that this decades-old technique matches GPT-4o's accuracy (89.9%) on long-form QA, while requiring orders-of-magnitude fewer parameters. To test human alignment of these metrics rigorously, we introduce DIVER-QA, a new 3000-sample human-annotated benchmark spanning five QA datasets and five candidate LLMs. Our results highlight that inexpensive NLI-based evaluation remains competitive and offer DIVER-QA as an open resource for future metric research.

</details>


### [199] [Critical Confabulation: Can LLMs Hallucinate for Social Good?](https://arxiv.org/abs/2511.07722)
*Peiqi Sui,Eamon Duede,Hoyt Long,Richard Jean So*

Main category: cs.CL

TL;DR: 本文提出“批判性虚构”（critical confabulation），利用大型语言模型（LLM）的幻觉来填补历史档案中因社会政治不平等造成的空白，为“隐形人物”重建发散但有证据支持的叙事。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在幻觉问题，但如果加以谨慎限制，某些虚构内容可能具有社会效用。研究旨在利用LLM的幻觉来弥补历史档案中因社会和政治不平等造成的空白，重建“隐形人物”的叙事。

Method: 提出“批判性虚构”概念。通过开放式叙事完形填空任务模拟档案空白，要求LLM根据来自未出版文本的新型语料库中的人物中心时间线，生成被遮蔽的事件。评估了经过审计的（OLMo-2系列）和未审计的开源及专有基线模型，使用旨在引发受控且有用幻觉的提示。

Result: 研究结果验证了LLM执行批判性虚构的基础叙事理解能力。展示了受控且明确的幻觉如何支持LLM在知识生产中的应用，同时避免将推测与历史准确性和忠实度混淆。

Conclusion: 大型语言模型具有进行批判性虚构的能力，能够利用受控的幻觉来填补历史空白并重建有证据支持的叙事，从而在不牺牲历史准确性的前提下支持知识生产。

Abstract: LLMs hallucinate, yet some confabulations can have social affordances if carefully bounded. We propose critical confabulation (inspired by critical fabulation from literary and social theory), the use of LLM hallucinations to "fill-in-the-gap" for omissions in archives due to social and political inequality, and reconstruct divergent yet evidence-bound narratives for history's "hidden figures". We simulate these gaps with an open-ended narrative cloze task: asking LLMs to generate a masked event in a character-centric timeline sourced from a novel corpus of unpublished texts. We evaluate audited (for data contamination), fully-open models (the OLMo-2 family) and unaudited open-weight and proprietary baselines under a range of prompts designed to elicit controlled and useful hallucinations. Our findings validate LLMs' foundational narrative understanding capabilities to perform critical confabulation, and show how controlled and well-specified hallucinations can support LLM applications for knowledge production without collapsing speculation into a lack of historical accuracy and fidelity.

</details>


### [200] [Back to the Future: The Role of Past and Future Context Predictability in Incremental Language Production](https://arxiv.org/abs/2511.07752)
*Shiva Upadhye,Richard Futrell*

Main category: cs.CL

TL;DR: 本研究通过改进的度量和语言模型，在自然语料库中调查了词语生产中过去和未来语境可预测性对词语形式和选择的影响，特别关注了后向可预测性。


<details>
  <summary>Details</summary>
Motivation: 虽然前向可预测性对语言生产和理解的影响已广为人知，但自然语言生产中“后向可预测性”（即基于未来语境对当前词语的预测）的影响及其与未来规划的关系尚不清楚，这促使研究者对其进行更深入的探究。

Method: 研究使用了两个自然言语语料库，引入了一种新的、原理性的、概念驱动的信息论可预测性度量，该度量整合了来自未来和过去语境的可预测性。第一个研究重新审视了词语时长上的经典可预测性效应。第二个研究在一个生成框架内调查了替换错误，该框架独立建模了词汇、语境和交际因素对词语选择的影响。

Result: 研究发现，所提出的概念驱动的后向可预测性替代方法在两项研究中都产生了定性相似的效果。通过对替换错误的细致分析，研究进一步表明，不同类型的错误暗示了说话者在词汇规划过程中如何优先考虑形式、意义和基于语境的信息。

Conclusion: 这些发现阐明了过去和未来语境在说话者编码和选择词语中的功能作用，为语境可预测性效应与句子规划机制之间搭建了桥梁。

Abstract: Contextual predictability shapes both the form and choice of words in online language production. The effects of the predictability of a word given its previous context are generally well-understood in both production and comprehension, but studies of naturalistic production have also revealed a poorly-understood backward predictability effect of a word given its future context, which may be related to future planning. Here, in two studies of naturalistic speech corpora, we investigate backward predictability effects using improved measures and more powerful language models, introducing a new principled and conceptually motivated information-theoretic predictability measure that integrates predictability from both the future and the past context. Our first study revisits classic predictability effects on word duration. Our second study investigates substitution errors within a generative framework that independently models the effects of lexical, contextual, and communicative factors on word choice, while predicting the actual words that surface as speech errors. We find that our proposed conceptually-motivated alternative to backward predictability yields qualitatively similar effects across both studies. Through a fine-grained analysis of substitution errors, we further show that different kinds of errors are suggestive of how speakers prioritize form, meaning, and context-based information during lexical planning. Together, these findings illuminate the functional roles of past and future context in how speakers encode and choose words, offering a bridge between contextual predictability effects and the mechanisms of sentence planning.

</details>


### [201] [Design, Results and Industry Implications of the World's First Insurance Large Language Model Evaluation Benchmark](https://arxiv.org/abs/2511.07794)
*Hua Zhou,Bing Ma,Yufei Zhang,Yi Zhao*

Main category: cs.CL

TL;DR: 本文介绍了CUFEInse v1.0保险领域大模型评估基准的构建方法、多维度评估体系和设计理念，并基于此评估了11个主流大模型，揭示了通用模型和领域专用模型的优缺点及当前大模型在专业场景中的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 保险领域缺乏专业的评估基准，无法系统、权威地评估大型语言模型在保险专业场景中的表现。现有模型在精算能力和合规适应性方面存在普遍瓶颈。

Method: 本文构建了CUFEInse v1.0评估基准，遵循“量化导向、专家驱动、多重验证”原则，涵盖5个核心维度、54个子指标和14,430个高质量问题，涉及保险理论知识、行业理解、安全合规、智能代理应用和逻辑严谨性。基于此基准，对11个主流大语言模型进行了综合评估。

Result: 评估结果显示，通用模型普遍存在精算能力弱和合规适应性不足的瓶颈。高质量的领域专用模型在保险垂直场景中表现出显著优势，但在业务适应性和合规性方面存在不足。评估还准确识别了当前大模型在保险精算、承保理赔推理和合规营销文案等专业场景中的共同瓶颈。

Conclusion: CUFEInse的建立填补了保险领域专业评估基准的空白，为学术界和工业界提供了专业、系统、权威的评估工具。其构建理念和方法为垂直领域大模型评估范式提供了重要参考，并为学术模型优化和工业模型选择提供了权威指导。未来将继续迭代评估基准并关注保险大模型的“领域适应+推理增强”核心发展方向。

Abstract: This paper comprehensively elaborates on the construction methodology, multi-dimensional evaluation system, and underlying design philosophy of CUFEInse v1.0. Adhering to the principles of "quantitative-oriented, expert-driven, and multi-validation," the benchmark establishes an evaluation framework covering 5 core dimensions, 54 sub-indicators, and 14,430 high-quality questions, encompassing insurance theoretical knowledge, industry understanding, safety and compliance, intelligent agent application, and logical rigor. Based on this benchmark, a comprehensive evaluation was conducted on 11 mainstream large language models. The evaluation results reveal that general-purpose models suffer from common bottlenecks such as weak actuarial capabilities and inadequate compliance adaptation. High-quality domain-specific training demonstrates significant advantages in insurance vertical scenarios but exhibits shortcomings in business adaptation and compliance. The evaluation also accurately identifies the common bottlenecks of current large models in professional scenarios such as insurance actuarial, underwriting and claim settlement reasoning, and compliant marketing copywriting. The establishment of CUFEInse not only fills the gap in professional evaluation benchmarks for the insurance field, providing academia and industry with a professional, systematic, and authoritative evaluation tool, but also its construction concept and methodology offer important references for the evaluation paradigm of large models in vertical fields, serving as an authoritative reference for academic model optimization and industrial model selection. Finally, the paper looks forward to the future iteration direction of the evaluation benchmark and the core development direction of "domain adaptation + reasoning enhancement" for insurance large models.

</details>


### [202] [From Experience to Strategy: Empowering LLM Agents with Trainable Graph Memory](https://arxiv.org/abs/2511.07800)
*Siyu Xia,Zekun Xu,Jiajun Chai,Wentian Fan,Yan Song,Xiaohan Wang,Guojun Yin,Wei Lin,Haifeng Zhang,Jun Wang*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的、可训练的多层图记忆框架，通过强化学习优化元认知策略，以增强LLM智能体的战略推理能力和泛化性，解决现有经验利用方法的局限性。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在复杂环境中自主解决任务方面潜力巨大，但其推理能力可以通过更好地利用先验经验来提升。然而，现有的经验获取方式（隐式记忆或显式记忆）存在灾难性遗忘、可解释性差和适应性不足等问题。

Method: 引入了一个以智能体为中心、可训练的多层图记忆框架。该框架将原始智能体轨迹抽象为结构化决策路径（状态机），并进一步提炼为高级、人类可解释的战略元认知。为使记忆具有适应性，提出了一种基于强化学习的权重优化程序，根据下游任务的奖励反馈估计每个元认知的经验效用。这些优化后的策略通过元认知提示动态整合到LLM智能体的训练循环中。

Result: 可学习的图记忆实现了强大的泛化能力，提高了LLM智能体的战略推理性能，并在强化学习（RL）训练过程中提供了持续的益处。

Conclusion: 所提出的可学习图记忆框架及其强化学习优化方法，成功增强了LLM智能体利用参数信息的能力，显著提升了其战略推理和泛化性能。

Abstract: Large Language Models (LLMs) based agents have demonstrated remarkable potential in autonomous task-solving across complex, open-ended environments. A promising approach for improving the reasoning capabilities of LLM agents is to better utilize prior experiences in guiding current decisions. However, LLMs acquire experience either through implicit memory via training, which suffers from catastrophic forgetting and limited interpretability, or explicit memory via prompting, which lacks adaptability. In this paper, we introduce a novel agent-centric, trainable, multi-layered graph memory framework and evaluate how context memory enhances the ability of LLMs to utilize parametric information. The graph abstracts raw agent trajectories into structured decision paths in a state machine and further distills them into high-level, human-interpretable strategic meta-cognition. In order to make memory adaptable, we propose a reinforcement-based weight optimization procedure that estimates the empirical utility of each meta-cognition based on reward feedback from downstream tasks. These optimized strategies are then dynamically integrated into the LLM agent's training loop through meta-cognitive prompting. Empirically, the learnable graph memory delivers robust generalization, improves LLM agents' strategic reasoning performance, and provides consistent benefits during Reinforcement Learning (RL) training.

</details>


### [203] [AlignSurvey: A Comprehensive Benchmark for Human Preferences Alignment in Social Surveys](https://arxiv.org/abs/2511.07871)
*Chenxi Lin,Weikang Yuan,Zhuoren Jiang,Biao Huang,Ruitao Zhang,Jianan Ge,Yueqian Xu,Jianxing Yu*

Main category: cs.CL

TL;DR: AlignSurvey是首个系统性地复制和评估使用大型语言模型（LLMs）进行完整社会调查流程的基准，旨在解决传统调查和现有LLM模拟方法的局限性，并提供相关数据集、模型和工具。


<details>
  <summary>Details</summary>
Motivation: 传统的社会调查面临固定问题格式、高成本、适应性差和跨文化等效性难题。现有利用LLMs模拟调查的研究多限于结构化问题，忽视完整调查流程，且因训练数据偏差可能低估边缘群体。

Method: 该研究引入了AlignSurvey基准，定义了四个与调查阶段对齐的任务：社会角色建模、半结构化访谈建模、态度立场建模和调查响应建模。它还提供了评估保真度、一致性和公平性的任务特定评估指标，并关注人口统计学多样性。为支持AlignSurvey，构建了一个多层数据集架构：包含4.4万+访谈对话和40万+结构化调查记录的跨国“社会基础语料库”，以及一套完整的“全流程调查数据集”，包括专家标注的AlignSurvey-Expert (ASE)和两个全国代表性跨文化调查。通过两阶段微调开源LLMs，发布了SurveyLM系列模型。

Result: 该研究发布了AlignSurvey基准，这是首个系统性评估LLMs在完整社会调查流程中表现的框架。提供了包含“社会基础语料库”和“全流程调查数据集”的多层数据集。开发了SurveyLM系列模型作为参考，并提供了所有数据集、模型和工具，支持透明和负责任的研究。

Conclusion: AlignSurvey基准通过系统地复制和评估LLMs在完整社会调查流程中的应用，解决了传统调查和现有LLM方法的局限性。它提供了一个全面的框架、数据集和模型，以促进对LLMs在社会科学研究中应用保真度、一致性和公平性的评估，特别关注弱势群体，从而推动透明和负责任的研究。

Abstract: Understanding human attitudes, preferences, and behaviors through social surveys is essential for academic research and policymaking. Yet traditional surveys face persistent challenges, including fixed-question formats, high costs, limited adaptability, and difficulties ensuring cross-cultural equivalence. While recent studies explore large language models (LLMs) to simulate survey responses, most are limited to structured questions, overlook the entire survey process, and risks under-representing marginalized groups due to training data biases. We introduce AlignSurvey, the first benchmark that systematically replicates and evaluates the full social survey pipeline using LLMs. It defines four tasks aligned with key survey stages: social role modeling, semi-structured interview modeling, attitude stance modeling and survey response modeling. It also provides task-specific evaluation metrics to assess alignment fidelity, consistency, and fairness at both individual and group levels, with a focus on demographic diversity. To support AlignSurvey, we construct a multi-tiered dataset architecture: (i) the Social Foundation Corpus, a cross-national resource with 44K+ interview dialogues and 400K+ structured survey records; and (ii) a suite of Entire-Pipeline Survey Datasets, including the expert-annotated AlignSurvey-Expert (ASE) and two nationally representative surveys for cross-cultural evaluation. We release the SurveyLM family, obtained through two-stage fine-tuning of open-source LLMs, and offer reference models for evaluating domain-specific alignment. All datasets, models, and tools are available at github and huggingface to support transparent and socially responsible research.

</details>


### [204] [Planned Event Forecasting using Future Mentions and Related Entity Extraction in News Articles](https://arxiv.org/abs/2511.07879)
*Neelesh Kumar Shukla,Pranay Sanghvi*

Main category: cs.CL

TL;DR: 本文提出一个系统，通过分析新闻文章中的公告，利用主题建模、word2vec、NER和时间标准化等技术，预测社会动荡事件，并引入了“相关实体提取”方法来识别关键参与者。


<details>
  <summary>Details</summary>
Motivation: 在民主国家，民众自由表达可能导致抗议、集会等社会动荡事件，这些事件可能具有破坏性且未经许可。提前预测这些事件有助于行政官员采取必要措施。由于抗议活动通常会提前宣布以吸引参与者，因此分析新闻公告可实现预警。

Method: 该系统使用主题建模和word2vec来过滤相关新闻文章，利用命名实体识别（NER）方法识别人物、组织、地点和日期等实体。时间标准化用于将未来日期转换为标准格式。论文还提出了一种“相关实体提取”方法，以识别实际参与事件的关键实体。

Result: 开发了一个地理上独立、通用的模型，用于识别过滤内乱事件的关键特征。该模型能够从新闻文章中预测社会动荡事件，并成功提取出与事件相关的关键实体。

Conclusion: 本文成功开发了一个通过分析新闻公告来预测社会动荡事件的系统。该系统利用多种自然语言处理技术，并创新性地提出了“相关实体提取”方法，以识别事件中的关键参与者，为行政部门提供预警能力。

Abstract: In democracies like India, people are free to express their views and demands. Sometimes this causes situations of civil unrest such as protests, rallies, and marches. These events may be disruptive in nature and are often held without prior permission from the competent authority. Forecasting these events helps administrative officials take necessary action. Usually, protests are announced well in advance to encourage large participation. Therefore, by analyzing such announcements in news articles, planned events can be forecasted beforehand. We developed such a system in this paper to forecast social unrest events using topic modeling and word2vec to filter relevant news articles, and Named Entity Recognition (NER) methods to identify entities such as people, organizations, locations, and dates. Time normalization is applied to convert future date mentions into a standard format. In this paper, we have developed a geographically independent, generalized model to identify key features for filtering civil unrest events. There could be many mentions of entities, but only a few may actually be involved in the event. This paper calls such entities Related Entities and proposes a method to extract them, referred to as Related Entity Extraction.

</details>


### [205] [Breaking the Adversarial Robustness-Performance Trade-off in Text Classification via Manifold Purification](https://arxiv.org/abs/2511.07888)
*Chenhao Dang,Jing Ma*

Main category: cs.CL

TL;DR: MC^2F通过在编码器嵌入流形中建模并校正样本分布，解决了文本分类中对抗鲁棒性与干净数据性能之间的权衡问题，实现了最先进的鲁棒性且不牺牲甚至略微提升了干净数据性能。


<details>
  <summary>Details</summary>
Motivation: 文本分类中普遍存在的挑战是，增强模型对抗攻击的鲁棒性通常会导致在干净数据上的性能下降。

Method: 本文提出了Manifold-Correcting Causal Flow (MC^2F)，一个直接作用于句子嵌入的两模块系统。其中，分层黎曼连续归一化流（SR-CNF）学习干净数据流形的密度并识别异常嵌入；然后，测地线纯化求解器（Geodesic Purification Solver）将对抗点通过最短路径投射回学习到的流形，以恢复干净、语义连贯的表示。

Result: MC^2F方法在文本分类的三个数据集和多种对抗攻击下进行了广泛评估，结果表明它不仅在对抗鲁棒性方面建立了新的最先进水平，而且完全保持了在干净数据上的性能，甚至带来了适度的准确性提升。

Conclusion: MC^2F成功解决了文本分类中增强模型鲁棒性与保持干净数据性能之间的固有冲突，实现了两者的兼顾甚至提升。

Abstract: A persistent challenge in text classification (TC) is that enhancing model robustness against adversarial attacks typically degrades performance on clean data. We argue that this challenge can be resolved by modeling the distribution of clean samples in the encoder embedding manifold. To this end, we propose the Manifold-Correcting Causal Flow (MC^2F), a two-module system that operates directly on sentence embeddings. A Stratified Riemannian Continuous Normalizing Flow (SR-CNF) learns the density of the clean data manifold. It identifies out-of-distribution embeddings, which are then corrected by a Geodesic Purification Solver. This solver projects adversarial points back onto the learned manifold via the shortest path, restoring a clean, semantically coherent representation. We conducted extensive evaluations on text classification (TC) across three datasets and multiple adversarial attacks. The results demonstrate that our method, MC^2F, not only establishes a new state-of-the-art in adversarial robustness but also fully preserves performance on clean data, even yielding modest gains in accuracy.

</details>


### [206] [Last Layer Logits to Logic: Empowering LLMs with Logic-Consistent Structured Knowledge Reasoning](https://arxiv.org/abs/2511.07910)
*Songze Li,Zhiqiang Liu,Zhaoyan Gong,Xiaoke Guo,Zhengke Gui,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在结构化知识推理中存在“逻辑漂移”问题，本文提出了“Logits-to-Logic”框架，通过强化和过滤logits来校正逻辑缺陷，显著提升了LLMs的逻辑一致性，并在知识图谱问答（KGQA）任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在自然语言推理中表现出色，但由于非结构化和结构化知识的表示差异，它们在结构化知识推理任务（如KGQA）中难以保持逻辑一致性，即存在“逻辑漂移”问题。现有方法（如提示工程）仅提供输入层面的指导，未能从根本上解决输出中的逻辑漂移，且缺乏适应性。

Method: 本研究针对自回归生成过程中的logits输出，提出了“Logits-to-Logic”框架。该框架包含logits强化和logits过滤两大核心模块，旨在直接纠正LLM输出中的逻辑缺陷。

Result: 广泛的实验表明，所提出的方法显著提高了LLMs在结构化知识推理中的逻辑一致性，并在多个KGQA基准测试中达到了最先进的性能。

Conclusion: 通过直接干预LLM的logits输出，Logits-to-Logic框架有效解决了LLMs在结构化知识推理中的逻辑漂移问题，从而显著提升了其在该类任务上的性能表现。

Abstract: Large Language Models (LLMs) achieve excellent performance in natural language reasoning tasks through pre-training on vast unstructured text, enabling them to understand the logic in natural language and generate logic-consistent responses. However, the representational differences between unstructured and structured knowledge make LLMs inherently struggle to maintain logic consistency, leading to \textit{Logic Drift} challenges in structured knowledge reasoning tasks such as Knowledge Graph Question Answering (KGQA). Existing methods address this limitation by designing complex workflows embedded in prompts to guide LLM reasoning. Nevertheless, these approaches only provide input-level guidance and fail to fundamentally address the \textit{Logic Drift} in LLM outputs. Additionally, their inflexible reasoning workflows cannot adapt to different tasks and knowledge graphs. To enhance LLMs' logic consistency in structured knowledge reasoning, we specifically target the logits output from the autoregressive generation process. We propose the \textit{Logits-to-Logic} framework, which incorporates logits strengthening and logits filtering as core modules to correct logical defects in LLM outputs. Extensive experiments show that our approach significantly improves LLMs' logic consistency in structured knowledge reasoning and achieves state-of-the-art performance on multiple KGQA benchmarks.

</details>


### [207] [Social Media for Mental Health: Data, Methods, and Findings](https://arxiv.org/abs/2511.07914)
*Nur Shazwani Kamarudin,Ghazaleh Beigi,Lydia Manikonda,Huan Liu*

Main category: cs.CL

TL;DR: 本章综述了利用社交媒体数据研究心理健康挑战（如抑郁、焦虑、自杀念头）的最新方法和发现，旨在提高意识并改善医疗实践和政策。


<details>
  <summary>Details</summary>
Motivation: 随着虚拟社区和社交媒体的普及，人们可以在不暴露身份的情况下寻求支持，尤其对于受污名化的疾病。这为研究心理健康问题提供了大量数据，并有望以前所未有的方式提高公众意识。

Method: 本章研究了利用社交媒体数据进行心理健康研究的最新方法论和发现。具体描述了用户披露中的语言、视觉和情感指标，并探讨了如何利用机器学习、特征工程和自然语言处理等技术来分析社交媒体数据。

Result: 研究结果表明，社交媒体数据可以作为新的信息来源，通过识别语言、视觉和情感指标来改善医疗实践、提供及时支持，并影响政府或政策制定者对心理健康问题的关注。

Conclusion: 本章总结了社交媒体在心理健康领域中应用的数据类型、部署的机器学习、特征工程和自然语言处理方法，并为未来的研究方向提供了指导。强调了利用社交媒体数据在提高心理健康意识和干预方面的巨大潜力。

Abstract: There is an increasing number of virtual communities and forums available on the web. With social media, people can freely communicate and share their thoughts, ask personal questions, and seek peer-support, especially those with conditions that are highly stigmatized, without revealing personal identity. We study the state-of-the-art research methodologies and findings on mental health challenges like de- pression, anxiety, suicidal thoughts, from the pervasive use of social media data. We also discuss how these novel thinking and approaches can help to raise awareness of mental health issues in an unprecedented way. Specifically, this chapter describes linguistic, visual, and emotional indicators expressed in user disclosures. The main goal of this chapter is to show how this new source of data can be tapped to improve medical practice, provide timely support, and influence government or policymakers. In the context of social media for mental health issues, this chapter categorizes social media data used, introduces different deployed machine learning, feature engineering, natural language processing, and surveys methods and outlines directions for future research.

</details>


### [208] [Distinct Theta Synchrony across Speech Modes: Perceived, Spoken, Whispered, and Imagined](https://arxiv.org/abs/2511.07918)
*Jung-Sun Lee,Ha-Na Jo,Eunyeong Ko*

Main category: cs.CL

TL;DR: 本研究比较了不同言语模式（感知、外显、耳语、想象）下θ波段神经同步的差异，发现其范围和空间分布因模式而异，揭示了语言处理的共享与独特神经机制。


<details>
  <summary>Details</summary>
Motivation: 以往研究多集中于单一言语模式，缺乏对不同模式下θ波段同步的综合比较，而θ波段同步与语言处理、注意控制和内隐言语密切相关。

Method: 本研究基于连接度指标，分析了不同言语模式下θ波段神经同步的差异，重点关注区域间的变化。

Result: 外显和耳语言语表现出更广泛、更强的前颞同步；感知言语呈现主导的后部和颞部同步模式；想象言语则表现出更局限但内部连贯的同步模式，主要涉及额叶和辅助运动区。

Conclusion: θ波段同步的范围和空间分布在不同言语模式间存在显著差异。外显发音涉及广泛的皮层交互，耳语音语参与度居中，而感知主要依赖颞顶网络。本研究揭示了语言感知和想象言语背后的共享与独特神经动力学。

Abstract: Human speech production encompasses multiple modes such as perceived, overt, whispered, and imagined, each reflecting distinct neural mechanisms. Among these, theta-band synchrony has been closely associated with language processing, attentional control, and inner speech. However, previous studies have largely focused on a single mode, such as overt speech, and have rarely conducted an integrated comparison of theta synchrony across different speech modes. In this study, we analyzed differences in theta-band neural synchrony across speech modes based on connectivity metrics, focusing on region-wise variations. The results revealed that overt and whispered speech exhibited broader and stronger frontotemporal synchrony, reflecting active motor-phonological coupling during overt articulation, whereas perceived speech showed dominant posterior and temporal synchrony patterns, consistent with auditory perception and comprehension processes. In contrast, imagined speech demonstrated a more spatially confined but internally coherent synchronization pattern, primarily involving frontal and supplementary motor regions. These findings indicate that the extent and spatial distribution of theta synchrony differ substantially across modes, with overt articulation engaging widespread cortical interactions, whispered speech showing intermediate engagement, and perception relying predominantly on temporoparietal networks. Therefore, this study aims to elucidate the differences in theta-band neural synchrony across various speech modes, thereby uncovering both the shared and distinct neural dynamics underlying language perception and imagined speech.

</details>


### [209] [Unified Work Embeddings: Contrastive Learning of a Bidirectional Multi-task Ranker](https://arxiv.org/abs/2511.07969)
*Matthias De Lange,Jens-Joris Decorte,Jeroen Van Hautte*

Main category: cs.CL

TL;DR: 本文介绍了WorkBench，首个统一的工作领域NLP评估套件，以及Unified Work Embeddings (UWE)，一个任务无关的双编码器。UWE利用多任务洞察和合成数据增强，在复杂的工作相关排名任务中实现了显著的零样本性能提升和低延迟推理。


<details>
  <summary>Details</summary>
Motivation: 劳动力转型增加了对专业自然语言处理能力的需求。然而，工作相关的NLP任务面临真实世界的复杂性，包括长尾分布、极端多标签目标空间和数据稀缺。现有通用嵌入模型在这些复杂场景下的性能以及领域内进展主要集中于单一任务，促使研究者探索其在工作领域的表现。

Method: 研究者引入了WorkBench，一个统一的评估套件，涵盖六个明确表述为排序问题的工作相关任务。在此基础上，他们发现了显著的正向跨任务迁移，并利用此洞察从真实世界数据构建任务特定的二分图，并通过接地（grounding）进行合成增强。这促成了Unified Work Embeddings (UWE)的开发，一个任务无关的双编码器，它利用训练数据结构与多对多InfoNCE目标，并结合任务无关的软后期交互的token级嵌入。

Result: 研究发现显著的正向跨任务迁移。UWE在工作领域中未见过的目标空间上展现了零样本排序性能，通过缓存任务目标空间嵌入实现了低延迟推理，并在宏观平均MAP和RP@10方面比通用嵌入模型取得了显著提升。

Conclusion: UWE在处理复杂工作相关NLP任务方面表现出色，特别是在零样本场景和低延迟推理方面。通过WorkBench提供的统一评估框架和UWE利用结构化数据及多任务学习，该研究为工作领域NLP的进步奠定了基础，并超越了现有通用嵌入模型的性能。

Abstract: Workforce transformation across diverse industries has driven an increased demand for specialized natural language processing capabilities. Nevertheless, tasks derived from work-related contexts inherently reflect real-world complexities, characterized by long-tailed distributions, extreme multi-label target spaces, and scarce data availability. The rise of generalist embedding models prompts the question of their performance in the work domain, especially as progress in the field has focused mainly on individual tasks. To this end, we introduce WorkBench, the first unified evaluation suite spanning six work-related tasks formulated explicitly as ranking problems, establishing a common ground for multi-task progress. Based on this benchmark, we find significant positive cross-task transfer, and use this insight to compose task-specific bipartite graphs from real-world data, synthetically enriched through grounding. This leads to Unified Work Embeddings (UWE), a task-agnostic bi-encoder that exploits our training-data structure with a many-to-many InfoNCE objective, and leverages token-level embeddings with task-agnostic soft late interaction. UWE demonstrates zero-shot ranking performance on unseen target spaces in the work domain, enables low-latency inference by caching the task target space embeddings, and shows significant gains in macro-averaged MAP and RP@10 over generalist embedding models.

</details>


### [210] [NOTAM-Evolve: A Knowledge-Guided Self-Evolving Optimization Framework with LLMs for NOTAM Interpretation](https://arxiv.org/abs/2511.07982)
*Maoqi Liu,Quan Fang,Yuhao Wu,Can Zhao,Yang Yang,Kaiquan Cai*

Main category: cs.CL

TL;DR: 本文提出NOTAM-Evolve框架，利用自进化的LLM和知识图谱增强的检索模块，实现对航空通告（NOTAMs）的深度解析，解决了其复杂语言带来的挑战，并在新数据集上显著提升了结构化NOTAMs解释的准确性。


<details>
  <summary>Details</summary>
Motivation: 航空通告（NOTAMs）的准确解读对飞行安全至关重要，但其简练且隐晦的语言给人工和自动化处理带来了巨大挑战。现有自动化系统仅限于浅层解析，无法提取操作决策所需的实用信息，因此需要进行深度解析。

Method: 研究将完整的解释任务形式化为深度解析，这是一个需要动态知识接地（将NOTAM与实时航空数据关联）和基于模式推理（应用静态领域规则推断操作状态）的双重推理挑战。为解决此问题，提出了NOTAM-Evolve框架，使大型语言模型（LLM）能够自主掌握复杂的NOTAM解释。该框架利用知识图谱增强的检索模块进行数据接地，并引入闭环学习过程，使LLM能从自身输出中逐步改进，减少对大量人工标注推理痕迹的需求。同时，还引入了一个包含10,000个专家标注NOTAM的新基准数据集。

Result: 实验表明，NOTAM-Evolve相对于基础LLM的准确率绝对提升了30.4%，在结构化NOTAM解释任务上建立了新的技术水平（SOTA）。

Conclusion: NOTAM-Evolve框架通过结合知识图谱增强的检索和闭环自学习，使LLM能够有效进行NOTAM的深度解析，显著提高了航空通告的解释准确性，为航空安全提供了关键支持，并展示了自进化LLM在复杂领域任务中的潜力。

Abstract: Accurate interpretation of Notices to Airmen (NOTAMs) is critical for aviation safety, yet their condensed and cryptic language poses significant challenges to both manual and automated processing. Existing automated systems are typically limited to shallow parsing, failing to extract the actionable intelligence needed for operational decisions. We formalize the complete interpretation task as deep parsing, a dual-reasoning challenge requiring both dynamic knowledge grounding (linking the NOTAM to evolving real-world aeronautical data) and schema-based inference (applying static domain rules to deduce operational status). To tackle this challenge, we propose NOTAM-Evolve, a self-evolving framework that enables a large language model (LLM) to autonomously master complex NOTAM interpretation. Leveraging a knowledge graph-enhanced retrieval module for data grounding, the framework introduces a closed-loop learning process where the LLM progressively improves from its own outputs, minimizing the need for extensive human-annotated reasoning traces. In conjunction with this framework, we introduce a new benchmark dataset of 10,000 expert-annotated NOTAMs. Our experiments demonstrate that NOTAM-Evolve achieves a 30.4% absolute accuracy improvement over the base LLM, establishing a new state of the art on the task of structured NOTAM interpretation.

</details>


### [211] [State of the Art in Text Classification for South Slavic Languages: Fine-Tuning or Prompting?](https://arxiv.org/abs/2511.07989)
*Taja Kuzman Pungeršek,Peter Rupnik,Ivan Porupski,Vuk Dinić,Nikola Ljubešić*

Main category: cs.CL

TL;DR: 本文比较了BERT类模型与大型语言模型（LLMs）在南斯拉夫语系文本分类任务上的表现，发现LLMs在零样本设置下表现出色，但存在实际应用上的缺点。


<details>
  <summary>Details</summary>
Motivation: BERT类模型曾是文本分类的主流，但随着指令调优的解码器模型（LLMs）的兴起，零样本和少样本提示成为新趋势。然而，LLMs在文本分类，特别是在资源较少语言上的表现尚未得到充分探索。

Method: 研究评估了开放可用的微调BERT类模型与一系列开源和闭源LLMs。实验涵盖了三种任务和三个领域：议会演讲的情感分类、新闻文章和议会演讲的主题分类，以及网络文本的体裁识别。评估在多种南斯拉夫语系语言上进行。

Result: LLMs展现出强大的零样本性能，经常与微调的BERT类模型持平或超越。在零样本设置下，LLMs在南斯拉夫语系语言和英语中的表现相当。然而，LLMs的缺点包括输出可预测性较低、推理速度显著变慢以及计算成本更高。

Conclusion: 尽管LLMs在零样本文本分类方面表现出色，甚至在资源较少语言上也能与英语媲美，但由于其输出可预测性、推理速度和计算成本等局限性，微调的BERT类模型对于大规模自动化文本标注来说仍是更实际的选择。

Abstract: Until recently, fine-tuned BERT-like models provided state-of-the-art performance on text classification tasks. With the rise of instruction-tuned decoder-only models, commonly known as large language models (LLMs), the field has increasingly moved toward zero-shot and few-shot prompting. However, the performance of LLMs on text classification, particularly on less-resourced languages, remains under-explored. In this paper, we evaluate the performance of current language models on text classification tasks across several South Slavic languages. We compare openly available fine-tuned BERT-like models with a selection of open-source and closed-source LLMs across three tasks in three domains: sentiment classification in parliamentary speeches, topic classification in news articles and parliamentary speeches, and genre identification in web texts. Our results show that LLMs demonstrate strong zero-shot performance, often matching or surpassing fine-tuned BERT-like models. Moreover, when used in a zero-shot setup, LLMs perform comparably in South Slavic languages and English. However, we also point out key drawbacks of LLMs, including less predictable outputs, significantly slower inference, and higher computational costs. Due to these limitations, fine-tuned BERT-like models remain a more practical choice for large-scale automatic text annotation.

</details>


### [212] [Self-Correction Distillation for Structured Data Question Answering](https://arxiv.org/abs/2511.07998)
*Yushan Zhu,Wen Zhang,Long Jin,Mengshu Sun,Ling Zhong,Zhiqiang Liu,Juan Li,Lei Liang,Chong Long,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 本文提出了一种自校正蒸馏 (SCD) 方法，通过错误提示机制 (EPM) 和两阶段蒸馏策略，显著提升了小型大语言模型 (LLM) 在结构化数据问答 (QA) 任务上的性能和泛化能力，甚至接近大型LLM如GPT4的水平。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在统一结构化QA框架中取得了进展，但小型LLM在生成结构化查询时容易出错，导致其在结构化数据QA应用中面临挑战。

Method: 提出自校正蒸馏 (SCD) 方法，包含两部分：1) 错误提示机制 (EPM)，用于在推理过程中检测错误并提供定制的错误信息；2) 两阶段蒸馏策略，旨在将大型LLM的查询生成和错误校正能力迁移到小型LLM。

Result: 在5个基准测试和3种结构化数据类型上，SCD在小型LLM (8B) 上实现了最佳性能和卓越的泛化能力，优于其他蒸馏方法，并在某些数据集上接近GPT4的性能。此外，配备EPM的大型LLM在大多数数据集上超越了现有最佳结果。

Conclusion: 自校正蒸馏 (SCD) 方法能有效提高小型LLM的结构化数据QA能力，使其性能显著提升并具备良好的泛化性。同时，错误提示机制 (EPM) 对大型LLM也具有增强作用。

Abstract: Structured data question answering (QA), including table QA, Knowledge Graph (KG) QA, and temporal KG QA, is a pivotal research area. Advances in large language models (LLMs) have driven significant progress in unified structural QA frameworks like TrustUQA. However, these frameworks face challenges when applied to small-scale LLMs since small-scale LLMs are prone to errors in generating structured queries. To improve the structured data QA ability of small-scale LLMs, we propose a self-correction distillation (SCD) method. In SCD, an error prompt mechanism (EPM) is designed to detect errors and provide customized error messages during inference, and a two-stage distillation strategy is designed to transfer large-scale LLMs' query-generation and error-correction capabilities to small-scale LLM. Experiments across 5 benchmarks with 3 structured data types demonstrate that our SCD achieves the best performance and superior generalization on small-scale LLM (8B) compared to other distillation methods, and closely approaches the performance of GPT4 on some datasets. Furthermore, large-scale LLMs equipped with EPM surpass the state-of-the-art results on most datasets.

</details>


### [213] [HyCoRA: Hyper-Contrastive Role-Adaptive Learning for Role-Playing](https://arxiv.org/abs/2511.08017)
*Shihao Yang,Zhicong Lu,Yong Yang,Bo Lv,Yang Shen,Nayu Liu*

Main category: cs.CL

TL;DR: 本文提出HyCoRA框架，通过超对比角色自适应学习，平衡角色独特和共享特征的学习，以提升多角色扮演能力。


<details>
  <summary>Details</summary>
Motivation: 现有多角色扮演方法要么使用单一共享模块忽略角色独特性，要么为每个角色分配独立模块而忽视角色间共通性，导致个性学习弱化或共通性建模受阻。

Method: 提出Hyper-Contrastive Role-Adaptive (HyCoRA) 学习框架。其核心是Hyper-Half Low-Rank Adaptation结构，包含由轻量级超网络生成的角色特定模块（捕获独特个性）和可训练的角色共享模块（捕获共通特征）。此外，设计超对比学习机制，帮助超网络区分不同角色的独特特征。

Result: HyCoRA在中英文基准测试中表现出优越性。GPT-4评估和视觉分析也验证了其捕获角色特征的能力。

Conclusion: HyCoRA框架通过有效平衡独特和共享特征的学习，显著提升了模型的多角色扮演能力。

Abstract: Multi-character role-playing aims to equip models with the capability to simulate diverse roles. Existing methods either use one shared parameterized module across all roles or assign a separate parameterized module to each role. However, the role-shared module may ignore distinct traits of each role, weakening personality learning, while the role-specific module may overlook shared traits across multiple roles, hindering commonality modeling. In this paper, we propose a novel HyCoRA: Hyper-Contrastive Role-Adaptive learning framework, which efficiently improves multi-character role-playing ability by balancing the learning of distinct and shared traits. Specifically, we propose a Hyper-Half Low-Rank Adaptation structure, where one half is a role-specific module generated by a lightweight hyper-network, and the other half is a trainable role-shared module. The role-specific module is devised to represent distinct persona signatures, while the role-shared module serves to capture common traits. Moreover, to better reflect distinct personalities across different roles, we design a hyper-contrastive learning mechanism to help the hyper-network distinguish their unique characteristics. Extensive experimental results on both English and Chinese available benchmarks demonstrate the superiority of our framework. Further GPT-4 evaluations and visual analyses also verify the capability of HyCoRA to capture role characteristics.

</details>


### [214] [Multimodal LLMs Do Not Compose Skills Optimally Across Modalities](https://arxiv.org/abs/2511.08113)
*Paula Ontalvilla,Aitor Ormazabal,Gorka Azkune*

Main category: cs.CL

TL;DR: 研究发现，多模态大语言模型（MLLM）在跨模态技能组合方面存在显著差距，即使采用链式思考或微调也未能有效弥补。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络在预训练中习得日益复杂的技能，尚不清楚它们如何成功地组合这些技能。特别是在多模态大语言模型（MLLM）中，其跨模态技能组合能力尚不明确。

Method: 设计了三个需要顺序组合两种模态依赖技能的评估任务。在两种主要设置下评估了多个开放式MLLM：1) 直接提示模型解决任务；2) 使用两步级联推理方法，手动强制组合两种技能。此外，探索了两种缓解策略：1) 使用思维链（CoT）提示明确指导MLLM进行技能组合；2) 采用特定的微调方案来促进技能组合。

Result: 所有评估的MLLM都表现出显著的跨模态技能组合差距。尽管思维链提示和特定微调策略能改善模型性能，但仍存在明显的技能组合差距。

Conclusion: MLLM在跨模态技能组合方面存在显著差距，即使是简单的组合任务也表现不佳。当前缓解策略效果有限，表明需要更多研究来提高MLLM的跨模态技能组合能力。

Abstract: Skill composition is the ability to combine previously learned skills to solve new tasks. As neural networks acquire increasingly complex skills during their pretraining, it is not clear how successfully they can compose them. In this paper, we focus on Multimodal Large Language Models (MLLM), and study their ability to compose skills across modalities. To this end, we design three evaluation tasks which can be solved sequentially composing two modality-dependent skills, and evaluate several open MLLMs under two main settings: i) prompting the model to directly solve the task, and ii) using a two-step cascaded inference approach, which manually enforces the composition of the two skills for a given task. Even with these straightforward compositions, we find that all evaluated MLLMs exhibit a significant cross-modality skill composition gap. To mitigate the aforementioned gap, we explore two alternatives: i) use chain-of-thought prompting to explicitly instruct MLLMs for skill composition and ii) a specific fine-tuning recipe to promote skill composition. Although those strategies improve model performance, they still exhibit significant skill composition gaps, suggesting that more research is needed to improve cross-modal skill composition in MLLMs.

</details>


### [215] [BARD10: A New Benchmark Reveals Significance of Bangla Stop-Words in Authorship Attribution](https://arxiv.org/abs/2511.08085)
*Abdullah Muhammad Moosa,Nusrat Sultana,Mahdi Muhammad Moosa,Md. Miraiz Hossain*

Main category: cs.CL

TL;DR: 本研究通过引入新语料库BARD10，全面调查孟加拉语作者归属问题，发现停用词对作者风格的重要性，并指出TF-IDF + SVM在短文本归属任务中表现优于深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 研究孟加拉语作者归属问题；引入一个平衡的孟加拉语基准语料库（BARD10）；系统分析停用词去除对经典和深度学习模型的影响，以揭示孟加拉语停用词的文体学意义。

Method: 引入了新的孟加拉语博客和评论散文语料库BARD10（包含10位作者）；使用统一预处理方法，在BARD10和现有基准语料库BAAD16上评估了四种代表性分类器：SVM、Bangla BERT、XGBoost和MLP；分析了停用词去除的影响和误差。

Result: 经典TF-IDF + SVM基线模型表现最佳，在BAAD16上达到0.997的宏F1分数，在BARD10上达到0.921；Bangla BERT模型落后多达5个百分点；BARD10的作者对停用词去除高度敏感，而BAAD16的作者相对稳健，这突出显示了文体对停用词特征的依赖性；误差分析表明，高频成分传递的作者签名在Transformer模型中被削弱或减少。

Conclusion: 孟加拉语停用词是重要的文体指示词；经过精细校准的机器学习模型在短文本限制内证明有效；BARD10连接了正式文学与当代网络对话，为未来的长上下文或领域适应型Transformer模型提供了可复现的基准。

Abstract: This research presents a comprehensive investigation into Bangla authorship attribution, introducing a new balanced benchmark corpus BARD10 (Bangla Authorship Recognition Dataset of 10 authors) and systematically analyzing the impact of stop-word removal across classical and deep learning models to uncover the stylistic significance of Bangla stop-words. BARD10 is a curated corpus of Bangla blog and opinion prose from ten contemporary authors, alongside the methodical assessment of four representative classifiers: SVM (Support Vector Machine), Bangla BERT (Bidirectional Encoder Representations from Transformers), XGBoost, and a MLP (Multilayer Perception), utilizing uniform preprocessing on both BARD10 and the benchmark corpora BAAD16 (Bangla Authorship Attribution Dataset of 16 authors). In all datasets, the classical TF-IDF + SVM baseline outperformed, attaining a macro-F1 score of 0.997 on BAAD16 and 0.921 on BARD10, while Bangla BERT lagged by as much as five points. This study reveals that BARD10 authors are highly sensitive to stop-word pruning, while BAAD16 authors remain comparatively robust highlighting genre-dependent reliance on stop-word signatures. Error analysis revealed that high frequency components transmit authorial signatures that are diminished or reduced by transformer models. Three insights are identified: Bangla stop-words serve as essential stylistic indicators; finely calibrated ML models prove effective within short-text limitations; and BARD10 connects formal literature with contemporary web dialogue, offering a reproducible benchmark for future long-context or domain-adapted transformers.

</details>


### [216] [Estranged Predictions: Measuring Semantic Category Disruption with Masked Language Modelling](https://arxiv.org/abs/2511.08109)
*Yuxuan Liu,Haim Dubossarsky,Ruth Ahnert*

Main category: cs.CL

TL;DR: 本研究利用掩码语言模型（MLM）量化科幻小说中“人”、“动物”和“机器”概念的渗透性，发现科幻小说，特别是围绕“机器”概念，展现出更高的类别边界不稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究科幻小说如何通过其独特的语言结构解构本体论范畴，并寻求一种计算方法来衡量达科·苏文（Darko Suvin）的“陌生化”理论。

Method: 使用科幻小说（Gollancz SF Masterworks）和普通小说（NovelTM）语料库，通过RoBERTa进行掩码语言建模，生成被遮蔽词语的替代词，并利用Gemini对这些替代词进行分类。通过保留率、替换率和熵三个指标，量化概念渗透性或类别边界的稳定性。

Result: 科幻小说表现出更高的概念渗透性，尤其是在“机器”指代词方面，显示出显著的跨类别替换和分散。相比之下，“人类”词汇保持了语义连贯性，并常作为替代层级的锚点。这些模式表明科幻小说中存在一种特定于流派的、对人类中心逻辑的重构。

Conclusion: 科幻小说中的陌生化是语义规范的一种可控扰动，可通过概率建模检测。掩码语言模型（MLM）在批判性使用时，可作为揭示流派特定本体论假设的解释工具。本研究为计算文学研究的方法论提供了贡献，并深入探讨了科幻小说的语言基础设施。

Abstract: This paper examines how science fiction destabilises ontological categories by measuring conceptual permeability across the terms human, animal, and machine using masked language modelling (MLM). Drawing on corpora of science fiction (Gollancz SF Masterworks) and general fiction (NovelTM), we operationalise Darko Suvin's theory of estrangement as computationally measurable deviation in token prediction, using RoBERTa to generate lexical substitutes for masked referents and classifying them via Gemini. We quantify conceptual slippage through three metrics: retention rate, replacement rate, and entropy, mapping the stability or disruption of category boundaries across genres. Our findings reveal that science fiction exhibits heightened conceptual permeability, particularly around machine referents, which show significant cross-category substitution and dispersion. Human terms, by contrast, maintain semantic coherence and often anchor substitutional hierarchies. These patterns suggest a genre-specific restructuring within anthropocentric logics. We argue that estrangement in science fiction operates as a controlled perturbation of semantic norms, detectable through probabilistic modelling, and that MLMs, when used critically, serve as interpretive instruments capable of surfacing genre-conditioned ontological assumptions. This study contributes to the methodological repertoire of computational literary studies and offers new insights into the linguistic infrastructure of science fiction.

</details>


### [217] [Quantification and object perception in Multimodal Large Language Models deviate from human linguistic cognition](https://arxiv.org/abs/2511.08126)
*Raquel Montero,Natalia Moskvina,Paolo Morosi,Tamara Serrano,Elena Pagliarini,Evelina Leivada*

Main category: cs.CL

TL;DR: 本研究探讨了多模态大型语言模型（MLLMs）在量化理解方面的不足，通过分析人类量化的三个关键特征（量词排序、使用范围、近似数系统偏差），发现MLLMs与人类在这些方面存在明显差异。


<details>
  <summary>Details</summary>
Motivation: 量化是MLLMs面临的一个特别困难的语言现象，但其表现不佳的具体原因尚不清楚，尤其考虑到量化涉及逻辑、语用和数值领域。

Method: 论文考察了人类量化中三个跨语言共享但此前在(M)LLM文献中未被探索的关键特征：量词的尺度排序、使用范围和原型性、以及人类近似数系统固有的偏差。研究旨在确定这些特征如何在模型架构中编码，它们与人类有何不同，以及结果是否受模型类型和语言的影响。

Result: 研究发现，在各种探究量化表示的任务中，MLLMs与人类在这些关键特征上存在明显差异。

Conclusion: 这项工作为解决MLLMs作为语义和语用代理的本质问题铺平了道路，同时跨语言视角有助于阐明它们的能力在不同语言中是否稳健和稳定。

Abstract: Quantification has been proven to be a particularly difficult linguistic phenomenon for (Multimodal) Large Language Models (MLLMs). However, given that quantification interfaces with the logic, pragmatic, and numerical domains, the exact reasons for the poor performance are still unclear. This papers looks at three key features of human quantification shared cross-linguistically that have remained so far unexplored in the (M)LLM literature: the ordering of quantifiers into scales, the ranges of use and prototypicality, and the biases inherent in the human approximate number system. The aim is to determine how these features are encoded in the models' architecture, how they may differ from humans, and whether the results are affected by the type of model and language under investigation. We find that there are clear differences between humans and MLLMs with respect to these features across various tasks that tap into the representation of quantification in vivo vs. in silico. This work, thus, paves the way for addressing the nature of MLLMs as semantic and pragmatic agents, while the cross-linguistic lens can elucidate whether their abilities are robust and stable across different languages.

</details>


### [218] [Sentence-Anchored Gist Compression for Long-Context LLMs](https://arxiv.org/abs/2511.08128)
*Dmitrii Tarasov,Elizaveta Goncharova,Kuznetsov Andrey*

Main category: cs.CL

TL;DR: 该研究通过学习型压缩令牌实现大型语言模型（LLMs）的上下文压缩，在不显著降低性能的情况下，将上下文压缩2到8倍，并在高压缩比下达到与现有技术相当甚至更优的效果。


<details>
  <summary>Details</summary>
Motivation: 减少处理长序列时大型语言模型（LLMs）的内存和计算需求。

Method: 通过微调预训练的LLMs，使其使用学习型压缩令牌来压缩上下文。

Result: 实现了2到8倍的上下文压缩，在短上下文和长上下文基准测试中均未出现显著的性能下降。在30亿参数的LLaMA模型上，该方法取得了与替代压缩技术相当的结果，同时实现了更高的压缩比。

Conclusion: 通过学习型压缩令牌对LLM上下文进行压缩是一种有效的方法，能够在保持性能的同时显著降低内存和计算需求，并实现高压缩比。

Abstract: This work investigates context compression for Large Language Models (LLMs) using learned compression tokens to reduce the memory and computational demands of processing long sequences. We demonstrate that pre-trained LLMs can be fine-tuned to compress their context by factors of 2x to 8x without significant performance degradation, as evaluated on both short-context and long-context benchmarks. Furthermore, in experiments on a 3-billion-parameter LLaMA model, our method achieves results on par with alternative compression techniques while attaining higher compression ratios.

</details>


### [219] [On the Interplay between Positional Encodings, Morphological Complexity, and Word Order Flexibility](https://arxiv.org/abs/2511.08139)
*Kushal Tatariya,Wessel Poelman,Miryam de Lhoneux*

Main category: cs.CL

TL;DR: 研究发现，语言模型的架构偏见（特别是位置编码）与形态复杂性或词序灵活性之间没有明确的交互作用，这与之前的假设相悖。任务、语言和度量选择对得出稳定结论至关重要。


<details>
  <summary>Details</summary>
Motivation: 语言模型架构通常是为英语设计的，然后应用于其他语言。研究者想探讨这种架构偏见（特别是位置编码）是否会导致与英语结构差异大的语言性能下降，并借此检验“形态复杂性与词序灵活性权衡”的假设。

Method: 研究者为七种类型学上多样化的语言预训练了单语模型变体，这些模型分别使用了绝对、相对和不使用位置编码。随后，他们在四个下游任务上评估了这些模型的性能。

Result: 与先前的发现相反，研究者并未观察到位置编码与形态复杂性或词序灵活性之间存在明确的交互作用，即使通过各种代理指标进行衡量也是如此。

Conclusion: 研究结果表明，在得出稳定结论时，任务、语言和度量的选择至关重要。

Abstract: Language model architectures are predominantly first created for English and subsequently applied to other languages. It is an open question whether this architectural bias leads to degraded performance for languages that are structurally different from English. We examine one specific architectural choice: positional encodings, through the lens of the trade-off hypothesis: the supposed interplay between morphological complexity and word order flexibility. This hypothesis posits a trade-off between the two: a more morphologically complex language can have a more flexible word order, and vice-versa. Positional encodings are a direct target to investigate the implications of this hypothesis in relation to language modelling. We pretrain monolingual model variants with absolute, relative, and no positional encodings for seven typologically diverse languages and evaluate them on four downstream tasks. Contrary to previous findings, we do not observe a clear interaction between position encodings and morphological complexity or word order flexibility, as measured by various proxies. Our results show that the choice of tasks, languages, and metrics are essential for drawing stable conclusions

</details>


### [220] [Relation as a Prior: A Novel Paradigm for LLM-based Document-level Relation Extraction](https://arxiv.org/abs/2511.08143)
*Qiankun Pi,Yepeng Sun,Jicang Lu,Qinlong Fan,Ningbo Huang,Shiyu Wang*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在文档级关系抽取（DocRE）中存在性能差距，主要原因是无关实体对引入噪声和预定义关系标签的严格性。本文提出了RelPrior范式，利用关系作为先验来过滤实体对并匹配实体，从而显著提升了DocRE性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在文档理解方面表现出色，但在需要细粒度理解的DocRE任务中仍存在性能差距。现有LLM方法采用“先抽取实体再预测关系”的范式，导致两个问题：1) 大量无关实体对引入噪声，干扰真正相关实体对的关系预测。2) LLMs识别的语义关联可能超出预定义关系集，但仍被视为预测错误。

Method: 本文提出了一种名为“关系即先验”（RelPrior）的新范式来解决上述挑战。针对挑战1，RelPrior利用二元关系作为先验来判断两个实体是否相关，从而过滤掉不相关的实体对，减少预测噪声。针对挑战2，RelPrior利用预定义关系作为先验来匹配实体进行三元组抽取，而非直接预测关系，从而避免了因严格的预定义关系标签导致的误判。

Result: 在两个基准数据集上的大量实验表明，RelPrior取得了最先进的性能，超越了现有的基于LLM的方法。

Conclusion: RelPrior范式通过利用关系作为先验，有效解决了LLM在DocRE任务中面临的挑战，即无关实体对的噪声和预定义关系标签的严格性，显著提高了模型的性能。

Abstract: Large Language Models (LLMs) have demonstrated their remarkable capabilities in document understanding. However, recent research reveals that LLMs still exhibit performance gaps in Document-level Relation Extraction (DocRE) as requiring fine-grained comprehension. The commonly adopted "extract entities then predict relations" paradigm in LLM-based methods leads to these gaps due to two main reasons: (1) Numerous unrelated entity pairs introduce noise and interfere with the relation prediction for truly related entity pairs. (2) Although LLMs have identified semantic associations between entities, relation labels beyond the predefined set are still treated as prediction errors. To address these challenges, we propose a novel Relation as a Prior (RelPrior) paradigm for LLM-based DocRE. For challenge (1), RelPrior utilizes binary relation as a prior to extract and determine whether two entities are correlated, thereby filtering out irrelevant entity pairs and reducing prediction noise. For challenge (2), RelPrior utilizes predefined relation as a prior to match entities for triples extraction instead of directly predicting relation. Thus, it avoids misjudgment caused by strict predefined relation labeling. Extensive experiments on two benchmarks demonstrate that RelPrior achieves state-of-the-art performance, surpassing existing LLM-based methods.

</details>


### [221] [Still Not There: Can LLMs Outperform Smaller Task-Specific Seq2Seq Models on the Poetry-to-Prose Conversion Task?](https://arxiv.org/abs/2511.08145)
*Kunal Kingkar Das,Manoj Balaji Jagadeeshan,Nallani Chakravartula Sahith,Jivnesh Sandhan,Pawan Goyal*

Main category: cs.CL

TL;DR: 在梵语诗歌转散文任务中，专门微调的小型模型显著优于指令微调和上下文学习的大语言模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）被广泛认为是通用解决方案，尤其在英语任务中。但对于梵语这种低资源、形态丰富的语言，这种假设是否成立？研究旨在通过一个复杂的梵语任务来检验LLMs能否超越专业模型。

Method: 研究通过梵语诗歌转散文（anvaya）任务，比较了指令微调和上下文提示的LLMs与一个任务特定的编码器-解码器模型（ByT5-Sanskrit Seq2Seq）。LLMs的提示策略基于巴尼尼语法和古典注释启发式方法。ByT5-Sanskrit Seq2Seq模型进行了完全微调。

Result: 实验结果显示，ByT5-Sanskrit的领域特定微调显著优于所有基于指令的LLM方法。人类评估强烈证实了这一结果，并与Kendall's Tau分数高度相关。此外，当领域特定语料库不可用时，提示策略提供了一种替代微调的方法，并且任务特定的Seq2Seq模型在域外评估中展现出强大的泛化能力。

Conclusion: 对于像梵语诗歌转散文这样具有挑战性的低资源、形态丰富语言任务，领域特定微调的小型模型仍然能超越大语言模型。尽管如此，当缺乏微调数据时，基于语法的LLM提示策略可作为一种有效的替代方案。

Abstract: Large Language Models (LLMs) are increasingly treated as universal, general-purpose solutions across NLP tasks, particularly in English. But does this assumption hold for low-resource, morphologically rich languages such as Sanskrit? We address this question by comparing instruction-tuned and in-context-prompted LLMs with smaller task-specific encoder-decoder models on the Sanskrit poetry-to-prose conversion task. This task is intrinsically challenging: Sanskrit verse exhibits free word order combined with rigid metrical constraints, and its conversion to canonical prose (anvaya) requires multi-step reasoning involving compound segmentation, dependency resolution, and syntactic linearisation. This makes it an ideal testbed to evaluate whether LLMs can surpass specialised models. For LLMs, we apply instruction fine-tuning on general-purpose models and design in-context learning templates grounded in Paninian grammar and classical commentary heuristics. For task-specific modelling, we fully fine-tune a ByT5-Sanskrit Seq2Seq model. Our experiments show that domain-specific fine-tuning of ByT5-Sanskrit significantly outperforms all instruction-driven LLM approaches. Human evaluation strongly corroborates this result, with scores exhibiting high correlation with Kendall's Tau scores. Additionally, our prompting strategies provide an alternative to fine-tuning when domain-specific verse corpora are unavailable, and the task-specific Seq2Seq model demonstrates robust generalisation on out-of-domain evaluations.

</details>


### [222] [Do Syntactic Categories Help in Developmentally Motivated Curriculum Learning for Language Models?](https://arxiv.org/abs/2511.08199)
*Arzu Burcu Güven,Anna Rogers,Rob van der Goot*

Main category: cs.CL

TL;DR: 本研究分析了BabyLM和CHILDES语料库的句法特性，发现CHILDES的句法分化与年龄关系不强。然而，训练数据的句法知识有助于解释模型在语言任务上的表现。在课程学习中，使用句法可分类的数据子集而非完整嘈杂语料库，能显著提升阅读任务的模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探究BabyLM和CHILDES语料库的句法属性，以及这些句法知识如何帮助解释模型在语言任务上的表现，特别是在课程学习的背景下。

Method: 研究方法包括：检查BabyLM和CHILDES语料库的句法属性；探索发展性和几种认知启发的课程学习方法；比较使用完整语料库与句法可分类数据子集的性能差异。

Result: 研究结果显示：CHILDES语料库并未表现出按年龄的强烈句法分化；训练数据的句法知识有助于解释模型在语言任务上的表现；一些课程设置有助于阅读任务；主要的性能提升来自于使用句法可分类的数据子集，而非完整的嘈杂语料库。

Conclusion: 结论是，尽管CHILDES语料库的句法分化与年龄关系不强，但利用训练数据的句法知识，特别是通过筛选句法明确的数据子集进行课程学习，可以显著提高模型在语言任务（特别是阅读任务）上的性能。

Abstract: We examine the syntactic properties of BabyLM corpus, and age-groups within CHILDES. While we find that CHILDES does not exhibit strong syntactic differentiation by age, we show that the syntactic knowledge about the training data can be helpful in interpreting model performance on linguistic tasks. For curriculum learning, we explore developmental and several alternative cognitively inspired curriculum approaches. We find that some curricula help with reading tasks, but the main performance improvement come from using the subset of syntactically categorizable data, rather than the full noisy corpus.

</details>


### [223] [Encoder Fine-tuning with Stochastic Sampling Outperforms Open-weight GPT in Astronomy Knowledge Extraction](https://arxiv.org/abs/2511.08204)
*Shivam Rawat,Lucie Flek,Akbar Karimi*

Main category: cs.CL

TL;DR: 本文提出一个基于编码器的多任务Transformer系统（SciBERT微调），用于从天文学论文中自动提取望远镜、仪器和语义属性等关键知识，该系统简单高效，显著优于GPT基线模型。


<details>
  <summary>Details</summary>
Motivation: 天文学文献数量迅速增长，使得自动化地从研究论文中提取关键实体和上下文信息变得日益重要。

Method: 研究人员实现了一个基于编码器的多任务Transformer系统，该系统基于SciBERT模型，并针对天文学语料库进行微调。模型目标是分类望远镜引用、检测辅助语义属性和识别仪器提及。微调时采用随机抽样训练数据段，推理时对测试段进行多数投票。

Result: 尽管该系统实现简单且成本低廉，但其性能显著优于开放权重的GPT基线模型。

Conclusion: 一个简单、低成本的基于SciBERT的编码器系统能有效从天文学文章中提取知识，并在性能上超越了GPT基线模型。

Abstract: Scientific literature in astronomy is rapidly expanding, making it increasingly important to automate the extraction of key entities and contextual information from research papers. In this paper, we present an encoder-based system for extracting knowledge from astronomy articles. Our objective is to develop models capable of classifying telescope references, detecting auxiliary semantic attributes, and recognizing instrument mentions from textual content. To this end, we implement a multi-task transformer-based system built upon the SciBERT model and fine-tuned for astronomy corpora classification. To carry out the fine-tuning, we stochastically sample segments from the training data and use majority voting over the test segments at inference time. Our system, despite its simplicity and low-cost implementation, significantly outperforms the open-weight GPT baseline.

</details>


### [224] [Benchmarking Educational LLMs with Analytics: A Case Study on Gender Bias in Feedback](https://arxiv.org/abs/2511.08225)
*Yishan Du,Conrad Borchers,Mutlu Cukurova*

Main category: cs.CL

TL;DR: 本研究开发了一个基于嵌入的基准测试框架，用于评估大型语言模型 (LLMs) 在形成性反馈中存在的性别偏见。结果显示，即使是先进的LLMs也存在不对称的语义响应，表现出持续的性别偏见。


<details>
  <summary>Details</summary>
Motivation: 随着教师在教学实践中越来越多地使用生成式人工智能 (GenAI)，需要可靠的方法来基准测试LLMs的教学用途，尤其是在形成性反馈中检测其潜在偏见。

Method: 研究使用600篇学生作文，通过词汇替换（隐式性别线索）和提示中作者背景（显式性别线索）构建了受控的反事实情境。调查了六个代表性LLMs。通过计算句子嵌入的余弦和欧氏距离量化响应差异，使用置换检验评估显著性，并通过降维可视化结构。还进行了定性分析。

Result: 所有模型中，隐式性别操作对“男性-女性”反事实情境引起的语义偏移大于“女性-男性”。只有GPT和Llama模型对显式性别线索敏感。这些发现表明，即使是先进的LLMs也对性别替换表现出不对称的语义响应，暗示其提供的反馈中存在持续的性别偏见。定性分析揭示了语言上的差异（例如，男性线索下更多支持自主的反馈，女性线索下更多控制性反馈）。

Conclusion: 即使是最先进的LLMs也存在不对称的性别偏见，这对其在教育场景中提供公平反馈构成了挑战。研究讨论了对教学GenAI公平性审计的意义，并提出了反事实评估的报告标准和保护公平反馈的提示设计实践指导。

Abstract: As teachers increasingly turn to GenAI in their educational practice, we need robust methods to benchmark large language models (LLMs) for pedagogical purposes. This article presents an embedding-based benchmarking framework to detect bias in LLMs in the context of formative feedback. Using 600 authentic student essays from the AES 2.0 corpus, we constructed controlled counterfactuals along two dimensions: (i) implicit cues via lexicon-based swaps of gendered terms within essays, and (ii) explicit cues via gendered author background in the prompt. We investigated six representative LLMs (i.e. GPT-5 mini, GPT-4o mini, DeepSeek-R1, DeepSeek-R1-Qwen, Gemini 2.5 Pro, Llama-3-8B). We first quantified the response divergence with cosine and Euclidean distances over sentence embeddings, then assessed significance via permutation tests, and finally, visualised structure using dimensionality reduction. In all models, implicit manipulations reliably induced larger semantic shifts for male-female counterfactuals than for female-male. Only the GPT and Llama models showed sensitivity to explicit gender cues. These findings show that even state-of-the-art LLMs exhibit asymmetric semantic responses to gender substitutions, suggesting persistent gender biases in feedback they provide learners. Qualitative analyses further revealed consistent linguistic differences (e.g., more autonomy-supportive feedback under male cues vs. more controlling feedback under female cues). We discuss implications for fairness auditing of pedagogical GenAI, propose reporting standards for counterfactual evaluation in learning analytics, and outline practical guidance for prompt design and deployment to safeguard equitable feedback.

</details>


### [225] [VocalBench-zh: Decomposing and Benchmarking the Speech Conversational Abilities in Mandarin Context](https://arxiv.org/abs/2511.08230)
*Heyang Liu,Ziyang Cheng,Yuhao Wang,Hongcheng Liu,Yiqi Li,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文提出了VocalBench-zh，一个针对普通话语境的、按能力划分的语音到语音（S2S）评估基准，旨在解决现有基准稀缺的问题，并评估了主流模型。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型（LLMs）的兴起推动了语音交互能力的发展，但普通话语境下缺乏全面的语音到语音（S2S）基准测试，这阻碍了开发者进行系统评估和用户进行公平的模型比较。

Method: 研究者提出了VocalBench-zh，一个适应普通话语境的、按能力划分的评估套件。它包含10个精心设计的子集和超过1万个高质量实例，覆盖了12个面向用户的特征。研究者使用该基准评估了14个主流模型。

Result: 对14个主流模型的评估实验揭示了当前路径的普遍挑战，并强调了需要对下一代语音交互系统有新的见解。

Conclusion: VocalBench-zh提供了一个系统评估和比较普通话S2S模型的工具，其评估结果指出了当前模型的不足，并为未来语音交互系统的研究方向提供了启示。

Abstract: The development of multi-modal large language models (LLMs) leads to intelligent approaches capable of speech interactions. As one of the most widely spoken languages globally, Mandarin is supported by most models to enhance their applicability and reach. However, the scarcity of comprehensive speech-to-speech (S2S) benchmarks in Mandarin contexts impedes systematic evaluation for developers and hinders fair model comparison for users. In this work, we propose VocalBench-zh, an ability-level divided evaluation suite adapted to Mandarin context consisting of 10 well-crafted subsets and over 10K high-quality instances, covering 12 user-oriented characters. The evaluation experiment on 14 mainstream models reveals the common challenges for current routes, and highlights the need for new insights into next-generation speech interactive systems. The evaluation codes and datasets will be available at https://github.com/SJTU-OmniAgent/VocalBench-zh.

</details>


### [226] [Prompt Tuning for Natural Language to SQL with Embedding Fine-Tuning and RAG](https://arxiv.org/abs/2511.08245)
*Jisoo Jang,Tien-Cuong Bui,Yunjun Choi,Wen-Syan Li*

Main category: cs.CL

TL;DR: 本文提出了一种基于提示调优（Prompt Tuning）的NL-to-SQL错误校正框架，结合大型语言模型（LLMs）和检索增强生成（RAG），显著提高了自然语言到SQL转换的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言接口的普及，高效准确地将自然语言查询转换为SQL表达式的需求日益增长，以解决数据访问和处理中的关键问题。

Method: 该研究引入了一个受医疗诊断过程启发的错误校正机制，能够诊断错误类型、识别原因、提供修复指令并应用到SQL查询中。此外，通过嵌入微调（fine-tuning）和RAG技术，利用外部知识库增强了准确性和透明度。

Result: 通过全面的实验，该框架在现有基线上实现了显著的12%准确率提升。

Conclusion: 该框架展示了其在当代数据驱动环境中革新数据访问和处理的巨大潜力，提高了NL-to-SQL转换的准确性和透明度。

Abstract: This paper introduces an Error Correction through Prompt Tuning for NL-to-SQL, leveraging the latest advancements in generative pre-training-based LLMs and RAG. Our work addresses the crucial need for efficient and accurate translation of natural language queries into SQL expressions in various settings with the growing use of natural language interfaces. We explore the evolution of NLIDBs from early rule-based systems to advanced neural network-driven approaches. Drawing inspiration from the medical diagnostic process, we propose a novel framework integrating an error correction mechanism that diagnoses error types, identifies their causes, provides fixing instructions, and applies these corrections to SQL queries. This approach is further enriched by embedding fine-tuning and RAG, which harnesses external knowledge bases for improved accuracy and transparency. Through comprehensive experiments, we demonstrate that our framework achieves a significant 12 percent accuracy improvement over existing baselines, highlighting its potential to revolutionize data access and handling in contemporary data-driven environments.

</details>


### [227] [ParliaBench: An Evaluation and Benchmarking Framework for LLM-Generated Parliamentary Speech](https://arxiv.org/abs/2511.08247)
*Marios Koniaris,Argyro Tsipi,Panayiotis Tsanakas*

Main category: cs.CL

TL;DR: 本文提出了ParliaBench，一个用于议会演讲生成的基准，包括英国议会数据集、结合计算指标和LLM-as-a-judge的多维度评估框架（语言、语义、政治真实性），以及两个新颖的基于嵌入的政治对齐度量。通过微调LLM并进行评估，证明了微调的有效性和新度量的判别力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在生成议会演讲时面临特殊挑战，它们缺乏针对议会语境的专业训练，且现有评估方法侧重于标准NLP指标而非关键的政治真实性和意识形态一致性。

Method: 构建了ParliaBench基准，包含一个英国议会演讲数据集。引入了一个结合计算指标和LLM作为评判者的评估框架，从语言质量、语义连贯性和政治真实性三个维度衡量生成质量。提出了两个新颖的基于嵌入的度量：政治光谱对齐（Political Spectrum Alignment）和政党对齐（Party Alignment），以量化意识形态定位。微调了五个大型语言模型，生成了2.8万篇演讲，并使用该框架对基线模型和微调模型进行了评估。

Result: 结果显示，微调在大多数指标上产生了统计学上显著的改进。本文提出的新颖度量（政治光谱对齐和政党对齐）在政治维度上表现出强大的判别能力。

Conclusion: ParliaBench及其评估框架和新颖度量有效地解决了议会演讲生成中政治真实性评估的挑战，并且通过微调可以显著提升LLMs在议会语境下的生成质量和政治真实性。

Abstract: Parliamentary speech generation presents specific challenges for large language models beyond standard text generation tasks. Unlike general text generation, parliamentary speeches require not only linguistic quality but also political authenticity and ideological consistency. Current language models lack specialized training for parliamentary contexts, and existing evaluation methods focus on standard NLP metrics rather than political authenticity. To address this, we present ParliaBench, a benchmark for parliamentary speech generation. We constructed a dataset of speeches from UK Parliament to enable systematic model training. We introduce an evaluation framework combining computational metrics with LLM-as-a-judge assessments for measuring generation quality across three dimensions: linguistic quality, semantic coherence, and political authenticity. We propose two novel embedding-based metrics, Political Spectrum Alignment and Party Alignment, to quantify ideological positioning. We fine-tuned five large language models (LLMs), generated 28k speeches, and evaluated them using our framework, comparing baseline and fine-tuned models. Results show that fine-tuning produces statistically significant improvements across the majority of metrics and our novel metrics demonstrate strong discriminative power for political dimensions.

</details>


### [228] [Hierarchical structure understanding in complex tables with VLLMs: a benchmark and experiments](https://arxiv.org/abs/2511.08298)
*Luca Bindini,Simone Giovannini,Simone Marinai,Valeria Nardoni,Kimiya Noor Ali*

Main category: cs.CL

TL;DR: 本研究探讨了视觉大型语言模型（VLLMs）理解科学文章中复杂分层表格结构的能力，发现通用VLLMs在未经专门设计的情况下也能执行此任务，并提供了未来整合结构化数据理解的见解。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探究VLLMs是否能在没有额外处理的情况下，推断出科学文章中表格的分层结构，特别是对于未经明确设计用于理解表格结构的通用VLLMs。

Method: 使用PubTables-1M数据集，并从中提取了一个名为Complex Hierarchical Tables (CHiTab) 的基准数据集。采用多种提示工程策略来测试模型理解能力，评估了多个最先进的开源VLLMs的开箱即用版本，并对部分模型进行了微调。同时，也将VLLMs的性能与人类在该任务上的表现进行了比较。

Result: 实验结果支持了研究人员的直觉，即未经明确设计用于理解表格结构的通用VLLMs也能执行理解表格结构的任务。

Conclusion: 本研究揭示了VLLMs处理复杂表格的潜力和局限性，并为未来将结构化数据理解整合到通用VLLMs中的工作提供了指导。

Abstract: This work investigates the ability of Vision Large Language Models (VLLMs) to understand and interpret the structure of tables in scientific articles. Specifically, we explore whether VLLMs can infer the hierarchical structure of tables without additional processing. As a basis for our experiments we use the PubTables-1M dataset, a large-scale corpus of scientific tables. From this dataset, we extract a subset of tables that we introduce as Complex Hierarchical Tables (CHiTab): a benchmark collection of complex tables containing hierarchical headings. We adopt a series of prompt engineering strategies to probe the models' comprehension capabilities, experimenting with various prompt formats and writing styles. Multiple state-of-the-art open-weights VLLMs are evaluated on the benchmark first using their off-the-shelf versions and then fine-tuning some models on our task. We also measure the performance of humans to solve the task on a small set of tables comparing with performance of the evaluated VLLMs. The experiments support our intuition that generic VLLMs, not explicitly designed for understanding the structure of tables, can perform this task. This study provides insights into the potential and limitations of VLLMs to process complex tables and offers guidance for future work on integrating structured data understanding into general-purpose VLLMs.

</details>


### [229] [Automatic Paper Reviewing with Heterogeneous Graph Reasoning over LLM-Simulated Reviewer-Author Debates](https://arxiv.org/abs/2511.08317)
*Shuaimin Li,Liyang Fan,Yufang Lin,Zeyang Li,Xian Wei,Shiwen Ni,Hamid Alinejad-Rokny,Min Yang*

Main category: cs.CL

TL;DR: ReViewGraph是一个新颖的框架，通过LLM模拟的多轮审稿人-作者辩论和异构图推理，捕捉精细的论证动态，以实现更明智的论文评审决策。


<details>
  <summary>Details</summary>
Motivation: 现有的论文评审方法依赖于表面特征或直接使用LLM，存在幻觉、偏见评分和推理能力有限的问题。这些方法未能捕捉审稿人-作者互动中固有的复杂论证推理和协商动态。

Method: ReViewGraph通过LLM模拟多智能体协作进行多轮审稿人-作者交流。然后，将接受、拒绝、澄清和妥协等不同的意见关系显式提取并编码为异构交互图中的类型化边。最后，应用图神经网络对这些结构化的辩论图进行推理，以捕捉细粒度的论证动态。

Result: 在三个数据集上的广泛实验表明，ReViewGraph的性能优于强大的基线，平均相对改进为15.73%。

Conclusion: 该研究强调了建模详细的审稿人-作者辩论结构对于做出更明智的评审决策的价值。

Abstract: Existing paper review methods often rely on superficial manuscript features or directly on large language models (LLMs), which are prone to hallucinations, biased scoring, and limited reasoning capabilities. Moreover, these methods often fail to capture the complex argumentative reasoning and negotiation dynamics inherent in reviewer-author interactions. To address these limitations, we propose ReViewGraph (Reviewer-Author Debates Graph Reasoner), a novel framework that performs heterogeneous graph reasoning over LLM-simulated multi-round reviewer-author debates. In our approach, reviewer-author exchanges are simulated through LLM-based multi-agent collaboration. Diverse opinion relations (e.g., acceptance, rejection, clarification, and compromise) are then explicitly extracted and encoded as typed edges within a heterogeneous interaction graph. By applying graph neural networks to reason over these structured debate graphs, ReViewGraph captures fine-grained argumentative dynamics and enables more informed review decisions. Extensive experiments on three datasets demonstrate that ReViewGraph outperforms strong baselines with an average relative improvement of 15.73%, underscoring the value of modeling detailed reviewer-author debate structures.

</details>


### [230] [Adaptive Multi-Agent Response Refinement in Conversational Systems](https://arxiv.org/abs/2511.08319)
*Soyeong Jeong,Aparna Elangovan,Emine Yilmaz,Oleg Rokhlenko*

Main category: cs.CL

TL;DR: 本文提出一个多智能体框架，通过为事实性、个性化和连贯性分配独立智能体并采用动态通信策略，来改进大型语言模型（LLM）的对话响应，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在对话系统中表现出色，但在处理个性化或特定知识时仍有不足。让用户自行检测并请求新响应不切实际。现有单LLM响应精炼方法难以全面考虑对话所需的多样化方面。

Method: 提出一个多智能体框架，每个智能体负责一个特定方面（事实性、个性化、连贯性）的审查和精炼。智能体的反馈被合并以改进整体响应。引入动态通信策略，根据查询需求自适应选择和协调最相关的智能体，而非遵循固定序列。

Result: 在具有挑战性的对话数据集上验证了该框架，结果表明其性能显著优于相关基线，尤其是在涉及知识或用户角色（或两者兼有）的任务中。

Conclusion: 多智能体框架，结合特定角色分配和动态通信策略，能有效提升LLM对话响应的质量，尤其在处理复杂知识和个性化需求方面表现突出。

Abstract: Large Language Models (LLMs) have demonstrated remarkable success in conversational systems by generating human-like responses. However, they can fall short, especially when required to account for personalization or specific knowledge. In real-life settings, it is impractical to rely on users to detect these errors and request a new response. One way to address this problem is to refine the response before returning it to the user. While existing approaches focus on refining responses within a single LLM, this method struggles to consider diverse aspects needed for effective conversations. In this work, we propose refining responses through a multi-agent framework, where each agent is assigned a specific role for each aspect. We focus on three key aspects crucial to conversational quality: factuality, personalization, and coherence. Each agent is responsible for reviewing and refining one of these aspects, and their feedback is then merged to improve the overall response. To enhance collaboration among them, we introduce a dynamic communication strategy. Instead of following a fixed sequence of agents, our approach adaptively selects and coordinates the most relevant agents based on the specific requirements of each query. We validate our framework on challenging conversational datasets, demonstrating that ours significantly outperforms relevant baselines, particularly in tasks involving knowledge or user's persona, or both.

</details>


### [231] [The Dynamic Articulatory Model DYNARTmo: Dynamic Movement Generation and Speech Gestures](https://arxiv.org/abs/2511.08372)
*Bernd J. Kröger*

Main category: cs.CL

TL;DR: 本文描述了DYNARTmo动态发音模型的当前实现，该模型基于语音姿态和姿态分数生成连续的发音器官运动，模拟言语产生的层级控制。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一个受神经生物学启发的计算框架，用于模拟言语产生从语言表征到发音-声学实现的层级控制。

Method: 该模型使用语音姿态概念和相应的姿态分数来生成连续的发音器官运动。方法包括构建姿态清单、协调姿态分数中的姿态，并将其转换为控制DYNARTmo声道模型的连续发音器官轨迹。

Result: 本文展示了DYNARTmo模型的当前实现，包括其姿态清单结构、姿态分数中的姿态协调方式，以及如何将其转换为控制DYNARTmo声道模型的连续发音器官轨迹。

Conclusion: 该论文成功描述了一个动态发音模型DYNARTmo的实现，该模型能够通过基于姿态的机制，模拟从语言表征到发音-声学实现的全过程，为言语产生的层级控制提供了一个计算框架。

Abstract: This paper describes the current implementation of the dynamic articulatory model DYNARTmo, which generates continuous articulator movements based on the concept of speech gestures and a corresponding gesture score. The model provides a neurobiologically inspired computational framework for simulating the hierarchical control of speech production from linguistic representation to articulatory-acoustic realization. We present the structure of the gesture inventory, the coordination of gestures in the gesture score, and their translation into continuous articulator trajectories controlling the DYNARTmo vocal tract model.

</details>


### [232] [DPRM: A Dual Implicit Process Reward Model in Multi-Hop Question Answering](https://arxiv.org/abs/2511.08364)
*Xinyi Wang,Yiping Song,Zhiliang Tian,Bo Liu,Tingjin Luo,Minlie Huang*

Main category: cs.CL

TL;DR: 本文提出了DPRM（双隐式过程奖励模型），通过训练两个隐式过程奖励模型（CoT-PRM和KG-PRM）并在CoT和KG推理路径之间引入一致性约束，解决了多跳问答（MHQA）任务中结合思维链（CoT）和知识图谱（KG）时现有隐式过程奖励模型无法处理图结构和路径不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 多跳问答（MHQA）中，CoT通过多步推理提高生成质量，KG通过语义匹配减少幻觉。然而，现有结果奖励模型（ORM）无法评估多步推理过程。传统过程奖励模型（PRM）需要昂贵的人工标注。虽然隐式PRM无需显式标注，但现有隐式PRM仅适用于纯文本场景，无法处理KG中的图结构约束，也无法捕捉CoT和KG路径之间潜在的不一致性。

Method: 本文提出了DPRM模型，包含两个隐式过程奖励模型：CoT-PRM和KG-PRM。这两个PRM都通过奖励参数化从结果信号中推导步骤级奖励，无需额外显式标注。其中，KG-PRM利用偏好对学习KG的结构约束。DPRM进一步引入了CoT和KG推理步骤之间的一致性约束，使两个PRM相互验证并协同优化推理路径。论文还提供了过程奖励推导的理论证明。

Result: 实验结果表明，DPRM在多个数据集上优于13种基线方法，在Hit@1指标上取得了高达16.6%的提升。

Conclusion: DPRM通过双隐式过程奖励模型和一致性约束，有效解决了MHQA任务中结合CoT和KG时现有隐式PRM的局限性，显著提高了推理路径的质量和问答性能。

Abstract: In multi-hop question answering (MHQA) tasks, Chain of Thought (CoT) improves the quality of generation by guiding large language models (LLMs) through multi-step reasoning, and Knowledge Graphs (KGs) reduce hallucinations via semantic matching. Outcome Reward Models (ORMs) provide feedback after generating the final answers but fail to evaluate the process for multi-step reasoning. Traditional Process Reward Models (PRMs) evaluate the reasoning process but require costly human annotations or rollout generation. While implicit PRM is trained only with outcome signals and derives step rewards through reward parameterization without explicit annotations, it is more suitable for multi-step reasoning in MHQA tasks. However, existing implicit PRM has only been explored for plain text scenarios. When adapting to MHQA tasks, it cannot handle the graph structure constraints in KGs and capture the potential inconsistency between CoT and KG paths. To address these limitations, we propose the DPRM (Dual Implicit Process Reward Model). It trains two implicit PRMs for CoT and KG reasoning in MHQA tasks. Both PRMs, namely KG-PRM and CoT-PRM, derive step-level rewards from outcome signals via reward parameterization without additional explicit annotations. Among them, KG-PRM uses preference pairs to learn structural constraints from KGs. DPRM further introduces a consistency constraint between CoT and KG reasoning steps, making the two PRMs mutually verify and collaboratively optimize the reasoning paths. We also provide a theoretical demonstration of the derivation of process rewards. Experimental results show that our method outperforms 13 baselines on multiple datasets with up to 16.6% improvement on Hit@1.

</details>


### [233] [PCRLLM: Proof-Carrying Reasoning with Large Language Models under Stepwise Logical Constraints](https://arxiv.org/abs/2511.08392)
*Tangrui Li,Pei Wang,Hongzheng Wang Christian Hahm,Matteo Spatola,Justin Shi*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）缺乏逻辑连贯性，本文提出PCRLLM框架，通过限制推理为单步、可验证的推理，同时保留自然语言表述，从而提高LLM推理的可靠性和多LLM协作能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在将前提映射到结论时，往往不遵守明确的推理规则，导致其逻辑连贯性有限。这引发了对LLM推理可信度的担忧。

Method: 本文提出了Proof-Carrying Reasoning with LLMs (PCRLLM) 框架。该框架将推理限制为单步推理，同时保留自然语言表达。每个输出明确指定前提、规则和结论，从而能够根据目标逻辑进行验证。此外，PCRLLM通过形式规则比较和整合中间步骤，促进了系统的多LLM协作。作者还引入了一个基准方案，用于生成结合自然语言表达和形式严谨性的大规模步级推理数据。

Result: PCRLLM通过支持链级验证（即使在黑盒设置下）缓解了可信度问题。它促进了系统的多LLM协作，允许在形式规则下比较和整合中间步骤。所提出的基准方案能够生成结合自然语言表达和形式严谨性的推理数据。

Conclusion: PCRLLM通过强制执行单步、可验证的推理，显著提高了LLM的逻辑推理能力，增强了其可信度，并促进了多LLM协作。同时，它提供了一种生成严格推理数据的方法。

Abstract: Large Language Models (LLMs) often exhibit limited logical coherence, mapping premises to conclusions without adherence to explicit inference rules. We propose Proof-Carrying Reasoning with LLMs (PCRLLM), a framework that constrains reasoning to single-step inferences while preserving natural language formulations. Each output explicitly specifies premises, rules, and conclusions, thereby enabling verification against a target logic. This mechanism mitigates trustworthiness concerns by supporting chain-level validation even in black-box settings. Moreover, PCRLLM facilitates systematic multi-LLM collaboration, allowing intermediate steps to be compared and integrated under formal rules. Finally, we introduce a benchmark schema for generating large-scale step-level reasoning data, combining natural language expressiveness with formal rigor.

</details>


### [234] [AgentPRM: Process Reward Models for LLM Agents via Step-Wise Promise and Progress](https://arxiv.org/abs/2511.08325)
*Zhiheng Xi,Chenyang Liao,Guanyu Li,Yajie Yang,Wenxiang Chen,Zhihao Zhang,Binghai Wang,Senjie Jin,Yuhao Zhou,Jian Guan,Wei Wu,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 本文提出了一种名为AgentPRM的新型过程奖励模型，用于评估大型语言模型（LLM）在多轮决策任务（即智能体任务）中的决策，显著提高了计算效率和性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs发展迅速，但在网络购物、浏览器导航等多轮决策任务中仍面临挑战。现有方法如精心设计的提示工程或专家轨迹微调有局限性。研究者希望通过构建过程奖励模型来评估每个决策并指导智能体，因为智能体任务中的动作评估应基于其与目标的接近程度和所取得的进展，而非简单的对错。

Method: 本文提出了一种为智能体任务重新定义的过程奖励模型——AgentPRM。AgentPRM旨在捕捉顺序决策之间的相互依赖性及其对最终目标的贡献，以更好地跟踪进展并平衡探索与利用。为了可扩展地获取训练AgentPRM的标注数据，作者采用了一种基于时序差分（TD-based）的估计方法，并结合了广义优势估计（GAE），这比现有方法更具样本效率。

Result: 在不同的智能体任务上进行的广泛实验表明，AgentPRM比基线方法计算效率高出8倍以上，并且在扩大测试时计算量时表现出稳健的性能提升。此外，详细分析展示了该方法的工作原理，并提供了更多见解，例如将AgentPRM应用于LLM智能体的强化学习。

Conclusion: AgentPRM为LLM在多轮决策任务中的决策过程提供了一种高效且鲁棒的评估和指导机制。通过重新定义过程奖励模型以捕捉决策间的相互依赖性和对目标的贡献，并结合高效的数据标注方法，AgentPRM显著提升了LLM智能体的性能和计算效率。

Abstract: Despite rapid development, large language models (LLMs) still encounter challenges in multi-turn decision-making tasks (i.e., agent tasks) like web shopping and browser navigation, which require making a sequence of intelligent decisions based on environmental feedback. Previous work for LLM agents typically relies on elaborate prompt engineering or fine-tuning with expert trajectories to improve performance. In this work, we take a different perspective: we explore constructing process reward models (PRMs) to evaluate each decision and guide the agent's decision-making process. Unlike LLM reasoning, where each step is scored based on correctness, actions in agent tasks do not have a clear-cut correctness. Instead, they should be evaluated based on their proximity to the goal and the progress they have made. Building on this insight, we propose a re-defined PRM for agent tasks, named AgentPRM, to capture both the interdependence between sequential decisions and their contribution to the final goal. This enables better progress tracking and exploration-exploitation balance. To scalably obtain labeled data for training AgentPRM, we employ a Temporal Difference-based (TD-based) estimation method combined with Generalized Advantage Estimation (GAE), which proves more sample-efficient than prior methods. Extensive experiments across different agentic tasks show that AgentPRM is over $8\times$ more compute-efficient than baselines, and it demonstrates robust improvement when scaling up test-time compute. Moreover, we perform detailed analyses to show how our method works and offer more insights, e.g., applying AgentPRM to the reinforcement learning of LLM agents.

</details>


### [235] [TurkEmbed: Turkish Embedding Model on NLI & STS Tasks](https://arxiv.org/abs/2511.08376)
*Özay Ezerceli,Gizem Gümüşçekiçci,Tuğba Erkoç,Berke Özenç*

Main category: cs.CL

TL;DR: 本文介绍了TurkEmbed，一个新型土耳其语嵌入模型，通过多样化数据集和先进训练技术（包括matryoshka表示学习），在自然语言推理（NLI）和语义文本相似性（STS）任务上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前的土耳其语嵌入模型常依赖机器翻译数据集，这可能限制了它们的准确性和语义理解能力，因此需要更鲁棒和准确的模型。

Method: TurkEmbed利用多样化的数据集和先进的训练技术，包括matryoshka表示学习，以生成更鲁棒和准确的嵌入。它还被设计成能适应资源受限环境，并提供更快的编码能力。

Result: 在Turkish STS-b-TR数据集上，TurkEmbed在语义相似性任务中显示出显著改进，Pearson和Spearman相关性指标表现优异。它在All-NLI-TR和STS-b-TR基准测试中，超越了当前最先进的模型Emrecan 1-4%。

Conclusion: TurkEmbed通过提供对土耳其语更细致的理解，有望增强土耳其NLP生态系统，并促进下游应用的发展。

Abstract: This paper introduces TurkEmbed, a novel Turkish language embedding model designed to outperform existing models, particularly in Natural Language Inference (NLI) and Semantic Textual Similarity (STS) tasks. Current Turkish embedding models often rely on machine-translated datasets, potentially limiting their accuracy and semantic understanding. TurkEmbed utilizes a combination of diverse datasets and advanced training techniques, including matryoshka representation learning, to achieve more robust and accurate embeddings. This approach enables the model to adapt to various resource-constrained environments, offering faster encoding capabilities. Our evaluation on the Turkish STS-b-TR dataset, using Pearson and Spearman correlation metrics, demonstrates significant improvements in semantic similarity tasks. Furthermore, TurkEmbed surpasses the current state-of-the-art model, Emrecan, on All-NLI-TR and STS-b-TR benchmarks, achieving a 1-4\% improvement. TurkEmbed promises to enhance the Turkish NLP ecosystem by providing a more nuanced understanding of language and facilitating advancements in downstream applications.

</details>


### [236] [Interaction Dynamics as a Reward Signal for LLMs](https://arxiv.org/abs/2511.08394)
*Sian Gooding,Edward Grefenstette*

Main category: cs.CL

TL;DR: 本文提出TRACE，一种基于对话嵌入轨迹几何特性（“对话几何”）的新型奖励信号，用于多轮对话中大型语言模型（LLM）的对齐。研究发现，仅依赖交互动态的奖励模型能达到与基于文本的强大LLM基线相当的性能，而结合两者则能显著提升对齐效果，证明了交互动态在预测对话成功中的重要性和互补性。


<details>
  <summary>Details</summary>
Motivation: 当前用于多轮对话的LLM对齐方法主要依赖文本内容产生的奖励信号，忽略了交互动态这一丰富的补充信号源。

Method: 引入TRACE（Trajectory-based Reward for Agent Collaboration Estimation），一种从对话嵌入轨迹的几何特性（称为“对话几何”）中提取的新型奖励信号。训练一个仅基于这些结构信号的奖励模型，并与分析完整文本的LLM基线进行比较。此外，还构建了一个结合交互动态和文本分析的混合模型。

Result: 仅基于结构信号训练的奖励模型实现了68.20%的配对准确率，与分析完整对话文本的强大LLM基线（70.04%）相当。结合交互动态和文本分析的混合模型达到了最高的性能（80.17%），表明这两种信号具有互补性。

Conclusion: 在交互式环境中，代理的沟通方式（交互动态）与沟通内容一样，是预测成功的有力指标。这项工作提供了一个新的、保护隐私的框架，不仅可以对齐代理，还可以作为诊断工具，理解驱动成功协作的独特交互模式。

Abstract: The alignment of Large Language Models (LLMs) for multi-turn conversations typically relies on reward signals derived from the content of the text. This approach, however, overlooks a rich, complementary source of signal: the dynamics of the interaction itself. This paper introduces TRACE (Trajectory-based Reward for Agent Collaboration Estimation), a novel reward signal derived from the geometric properties of a dialogue's embedding trajectory--a concept we term 'conversational geometry'. Our central finding is that a reward model trained only on these structural signals achieves a pairwise accuracy (68.20%) comparable to a powerful LLM baseline that analyzes the full transcript (70.04%). Furthermore, a hybrid model combining interaction dynamics with textual analysis achieves the highest performance (80.17%), demonstrating their complementary nature. This work provides strong evidence that for interactive settings, how an agent communicates is as powerful a predictor of success as what it says, offering a new, privacy-preserving framework that not only aligns agents but also serves as a diagnostic tool for understanding the distinct interaction patterns that drive successful collaboration.

</details>


### [237] [Bot Meets Shortcut: How Can LLMs Aid in Handling Unknown Invariance OOD Scenarios?](https://arxiv.org/abs/2511.08455)
*Shiyan Zheng,Herun Wan,Minnan Luo,Junhang Huang*

Main category: cs.CL

TL;DR: 现有社交机器人检测器在真实场景中鲁棒性不足，尤其受到捷径学习的影响。本研究深入评估了基于文本特征的潜在捷径对检测器的影响，并提出基于大型语言模型和反事实数据增强的缓解策略，显著提升了模型在捷径场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有社交机器人检测器在基准测试中表现良好，但在真实世界中因地面真实性不清和误导性线索多样而鲁棒性有限。特别是，模型依赖虚假相关性而非因果特征的捷径学习问题，其影响尚未得到充分关注，而文本特征最易受社交机器人操纵。

Method: 研究通过构建用户标签与肤浅文本线索之间的虚假关联，设计了一系列捷径场景来评估模型鲁棒性。为解决此问题，提出了基于大型语言模型（LLM）的反事实数据增强缓解策略。这些策略从数据和模型两方面，在个体用户文本、整体数据集分布以及模型提取因果信息的能力三个层面进行缓解。

Result: 结果显示，无关特征分布的变化显著降低了社交机器人检测器的性能，基线模型平均相对准确率下降了32%。所提出的策略在捷径场景下平均相对性能提升了56%。

Conclusion: 社交机器人检测器易受基于文本特征的捷径学习影响，导致鲁棒性下降。通过利用大型语言模型的反事实数据增强策略，可以有效缓解这一问题，显著提升检测器在复杂和误导性场景下的性能和鲁棒性。

Abstract: While existing social bot detectors perform well on benchmarks, their robustness across diverse real-world scenarios remains limited due to unclear ground truth and varied misleading cues. In particular, the impact of shortcut learning, where models rely on spurious correlations instead of capturing causal task-relevant features, has received limited attention. To address this gap, we conduct an in-depth study to assess how detectors are influenced by potential shortcuts based on textual features, which are most susceptible to manipulation by social bots. We design a series of shortcut scenarios by constructing spurious associations between user labels and superficial textual cues to evaluate model robustness. Results show that shifts in irrelevant feature distributions significantly degrade social bot detector performance, with an average relative accuracy drop of 32\% in the baseline models. To tackle this challenge, we propose mitigation strategies based on large language models, leveraging counterfactual data augmentation. These methods mitigate the problem from data and model perspectives across three levels, including data distribution at both the individual user text and overall dataset levels, as well as the model's ability to extract causal information. Our strategies achieve an average relative performance improvement of 56\% under shortcut scenarios.

</details>


### [238] [Structured RAG for Answering Aggregative Questions](https://arxiv.org/abs/2511.08505)
*Omri Koshorek,Niv Granot,Aviv Alloni,Shahar Admati,Roee Hendel,Ido Weiss,Alan Arazi,Shay-Nitzan Cohen,Yonatan Belinkov*

Main category: cs.CL

TL;DR: S-RAG是一种专门针对聚合查询的检索增强生成（RAG）方法，通过构建结构化语料库表示并在推理时将自然语言查询转换为形式化查询，显著优于现有RAG系统和长上下文LLM。


<details>
  <summary>Details</summary>
Motivation: 当前的RAG数据集和方法主要关注只需从语料库中检索少量（通常是几段）相关信息的情况，无法有效处理需要从大量文档中收集信息并进行推理的聚合查询。

Method: S-RAG方法在数据摄取时构建语料库的结构化表示，并在推理时将自然语言查询转换为对该结构化表示的形式化查询。此外，为验证方法并促进研究，论文引入了两个新的聚合查询数据集：HOTELS和WORLD CUP。

Result: S-RAG在新增数据集和公共基准测试上，表现显著优于常见的RAG系统和长上下文大型语言模型（LLMs）。

Conclusion: S-RAG成功解决了现有RAG系统在处理聚合查询方面的不足，并通过其结构化方法实现了卓越性能。新引入的数据集将有助于推动该领域未来的研究。

Abstract: Retrieval-Augmented Generation (RAG) has become the dominant approach for answering questions over large corpora. However, current datasets and methods are highly focused on cases where only a small part of the corpus (usually a few paragraphs) is relevant per query, and fail to capture the rich world of aggregative queries. These require gathering information from a large set of documents and reasoning over them. To address this gap, we propose S-RAG, an approach specifically designed for such queries. At ingestion time, S-RAG constructs a structured representation of the corpus; at inference time, it translates natural-language queries into formal queries over said representation. To validate our approach and promote further research in this area, we introduce two new datasets of aggregative queries: HOTELS and WORLD CUP. Experiments with S-RAG on the newly introduced datasets, as well as on a public benchmark, demonstrate that it substantially outperforms both common RAG systems and long-context LLMs.

</details>


### [239] [Introducing A Bangla Sentence - Gloss Pair Dataset for Bangla Sign Language Translation and Research](https://arxiv.org/abs/2511.08507)
*Neelavro Saha,Rafi Shahriyar,Nafis Ashraf Roudra,Saadman Sakib,Annajiat Alim Rasel*

Main category: cs.CL

TL;DR: 本文介绍了Bangla-SGP，一个包含1000个人工标注和3000个合成生成句-词序对的孟加拉手语（BdSL）翻译数据集。该工作还微调并评估了多种Transformer模型，以解决BdSL句子级翻译的资源匮乏问题。


<details>
  <summary>Details</summary>
Motivation: 孟加拉手语（BdSL）翻译是一个低资源NLP任务，缺乏大规模的句子级数据集。现有研究仅限于词和字母级别的检测，无法支持句子级翻译。

Method: 研究团队创建了Bangla-SGP数据集，包含1000个人工标注的句-词序对。通过基于规则的检索增强生成（RAG）管道，利用句法和形态规则，合成了约3000个额外的句-词序对。该增强过程结合了基于规则的语言策略和提示工程技术。随后，微调了mBart50、Google mT5、GPT4.1-nano等多个基于Transformer的模型。

Result: 论文使用BLEU分数评估了模型从句子到词序的翻译性能。研究团队比较了模型在Bangla-SGP数据集和RWTH-PHOENIX-2014T基准测试上的词序翻译一致性。

Conclusion: 本文成功引入了一个新颖的并行数据集Bangla-SGP及其增强方法，有效解决了孟加拉手语句子级翻译的低资源挑战。通过微调Transformer模型并在新数据集上进行评估，为BdSL的句子级翻译研究奠定了基础。

Abstract: Bangla Sign Language (BdSL) translation represents a low-resource NLP task due to the lack of large-scale datasets that address sentence-level translation. Correspondingly, existing research in this field has been limited to word and alphabet level detection. In this work, we introduce Bangla-SGP, a novel parallel dataset consisting of 1,000 human-annotated sentence-gloss pairs which was augmented with around 3,000 synthetically generated pairs using syntactic and morphological rules through a rule-based Retrieval-Augmented Generation (RAG) pipeline. The gloss sequences of the spoken Bangla sentences are made up of individual glosses which are Bangla sign supported words and serve as an intermediate representation for a continuous sign. Our dataset consists of 1000 high quality Bangla sentences that are manually annotated into a gloss sequence by a professional signer. The augmentation process incorporates rule-based linguistic strategies and prompt engineering techniques that we have adopted by critically analyzing our human annotated sentence-gloss pairs and by working closely with our professional signer. Furthermore, we fine-tune several transformer-based models such as mBart50, Google mT5, GPT4.1-nano and evaluate their sentence-to-gloss translation performance using BLEU scores, based on these evaluation metrics we compare the model's gloss-translation consistency across our dataset and the RWTH-PHOENIX-2014T benchmark.

</details>


### [240] [Investigating CoT Monitorability in Large Reasoning Models](https://arxiv.org/abs/2511.08525)
*Shu Yang,Junchao Wu,Xilin Gou,Xuansheng Wu,Derek Wong,Ninhao Liu,Di Wang*

Main category: cs.CL

TL;DR: 本文首次系统性地探讨了大型推理模型（LRMs）链式思考（CoT）的可监控性，旨在利用CoT检测模型不当行为。研究围绕CoT的忠实性（verbalization）和监控器可靠性（monitor reliability）两大挑战展开，并提出了MoME范式，即LLM通过CoT监控其他模型的错误行为。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）通过扩展推理展现出卓越性能，其详细推理轨迹为AI安全提供了新机遇，即通过CoT监控模型潜在的不当行为（如走捷径、奉承）。然而，存在两大根本挑战：1) CoT不总是真实反映模型内部决策（CoT忠实性问题）；2) 监控器可能过于敏感或不敏感，且可能被模型精心设计的长篇推理所欺骗（监控器可靠性问题）。

Method: 本文进行了首次系统性调查，围绕两个核心视角展开：(i) 言语化（verbalization）：LRMs在CoT中真实表达其决策引导因素的程度；(ii) 监控器可靠性（monitor reliability）：基于CoT的监控器可靠检测不当行为的程度。具体方法包括：在数学、科学和伦理领域提供实证证据和相关性分析，以探究言语化质量、监控器可靠性和LLM性能之间的关系；进一步调查不同CoT干预方法对监控有效性的影响；最后，提出了MoME（Models Monitoring Other Models' Misbehavior through their CoT and providing structured judgments along with supporting evidence）新范式。

Result: 研究提供了关于言语化质量、监控器可靠性以及LLM在数学、科学和伦理领域性能之间关系的实证证据和相关性分析。同时，揭示了不同CoT干预方法如何影响监控的有效性。

Conclusion: CoT监控性面临模型推理忠实性和监控器可靠性两大挑战。本文首次系统性地探究了这些挑战，并提出了MoME范式，即利用LLM通过CoT监控其他模型的错误行为并提供结构化判断和支持证据，为未来提高AI安全和可解释性提供了新方向。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex tasks by engaging in extended reasoning before producing final answers. Beyond improving abilities, these detailed reasoning traces also create a new opportunity for AI safety, CoT Monitorability: monitoring potential model misbehavior, such as the use of shortcuts or sycophancy, through their chain-of-thought (CoT) during decision-making. However, two key fundamental challenges arise when attempting to build more effective monitors through CoT analysis. First, as prior research on CoT faithfulness has pointed out, models do not always truthfully represent their internal decision-making in the generated reasoning. Second, monitors themselves may be either overly sensitive or insufficiently sensitive, and can potentially be deceived by models' long, elaborate reasoning traces. In this paper, we present the first systematic investigation of the challenges and potential of CoT monitorability. Motivated by two fundamental challenges we mentioned before, we structure our study around two central perspectives: (i) verbalization: to what extent do LRMs faithfully verbalize the true factors guiding their decisions in the CoT, and (ii) monitor reliability: to what extent can misbehavior be reliably detected by a CoT-based monitor? Specifically, we provide empirical evidence and correlation analyses between verbalization quality, monitor reliability, and LLM performance across mathematical, scientific, and ethical domains. Then we further investigate how different CoT intervention methods, designed to improve reasoning efficiency or performance, will affect monitoring effectiveness. Finally, we propose MoME, a new paradigm in which LLMs monitor other models' misbehavior through their CoT and provide structured judgments along with supporting evidence.

</details>


### [241] [From Semantic Roles to Opinion Roles: SRL Data Extraction for Multi-Task and Transfer Learning in Low-Resource ORL](https://arxiv.org/abs/2511.08537)
*Amirmohammad Omidi Galdiani,Sepehr Rezaei Melal,Mohammad Norasteh,Arash Yousefi Jordehi,Seyed Abolghasem Mirroshandel*

Main category: cs.CL

TL;DR: 本报告详细介绍了如何从OntoNotes 5.0语料库的华尔街日报部分构建高质量的语义角色标注（SRL）数据集，并将其适配到观点角色标注（ORL）任务中。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过利用SRL来增强ORL，尤其是在资源匮乏的观点挖掘场景中，提供一个可复用的资源。

Method: 利用PropBank标注框架，实施了一个可复现的提取管道，对谓词-论元结构与表面文本进行对齐，将句法树指针转换为连贯的文本跨度，并进行严格清洗以确保语义忠实度。方法还包括处理不连续论元和修正标注。

Result: 构建了一个包含97,169个谓词-论元实例的数据集，其中明确定义了施事者（ARG0）、谓词（REL）和受事者（ARG1）角色，并将其映射到ORL的持有者、表达和目标模式。报告详细阐述了提取算法、不连续论元处理、标注修正以及数据集的统计分析。

Conclusion: 这项工作为研究人员提供了一个可复用的资源，旨在利用SRL增强ORL，特别是在资源匮乏的观点挖掘场景中。

Abstract: This report presents a detailed methodology for constructing a high-quality Semantic Role Labeling (SRL) dataset from the Wall Street Journal (WSJ) portion of the OntoNotes 5.0 corpus and adapting it for Opinion Role Labeling (ORL) tasks. Leveraging the PropBank annotation framework, we implement a reproducible extraction pipeline that aligns predicate-argument structures with surface text, converts syntactic tree pointers to coherent spans, and applies rigorous cleaning to ensure semantic fidelity. The resulting dataset comprises 97,169 predicate-argument instances with clearly defined Agent (ARG0), Predicate (REL), and Patient (ARG1) roles, mapped to ORL's Holder, Expression, and Target schema. We provide a detailed account of our extraction algorithms, discontinuous argument handling, annotation corrections, and statistical analysis of the resulting dataset. This work offers a reusable resource for researchers aiming to leverage SRL for enhancing ORL, especially in low-resource opinion mining scenarios.

</details>


### [242] [Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models](https://arxiv.org/abs/2511.08577)
*Tianyu Fu,Yichen You,Zekai Chen,Guohao Dai,Huazhong Yang,Yu Wang*

Main category: cs.CL

TL;DR: 本文提出Think-at-Hard (TaH) 方法，通过动态判断并仅对“困难”令牌进行迭代推理，避免了大型语言模型（LLMs）在简单令牌上“过度思考”的问题，显著提升了LLMs在参数受限下的推理能力。


<details>
  <summary>Details</summary>
Motivation: 在参数受限下提高大型语言模型（LLMs）的推理能力对实际应用至关重要。现有循环Transformer虽然通过额外迭代改进生成质量，但存在“过度思考”现象，即在第一次前向传播后已正确的简单令牌在额外迭代中反而被修正为错误。

Method: TaH方法通过以下方式解决问题：1) 识别并解决“过度思考”现象；2) 引入轻量级神经决策器，仅在第一次前向传播后可能不正确的“困难”令牌处触发潜在迭代；3) 在潜在迭代期间，使用低秩适应（LoRA）模块将LLM目标从通用下一个令牌预测转移到聚焦于困难令牌的精修；4) 引入双因果注意力机制，将注意力从令牌序列维度扩展到额外的迭代深度维度，实现跨迭代信息流的同时保持完全序列并行性。

Result: 实验结果表明，TaH在五个具有挑战性的基准测试中显著提升了LLM的推理性能，同时保持相同的参数数量。与对所有输出令牌迭代两次的基线相比，TaH实现了8.1-11.3%的准确率提升，并使94%的令牌免于第二次迭代。与使用相同数据微调的强大单次迭代Qwen3模型相比，TaH也实现了4.0-5.0%的准确率提升。当允许不到3%的额外参数（来自LoRA和迭代决策器）时，增益分别增加到8.5-12.6%和5.3-5.4%。

Conclusion: TaH通过动态潜伏思考，有效地解决了LLM在额外迭代中“过度思考”的问题，显著提升了LLM的推理能力，同时保持了参数效率，为在参数受限场景下提升LLM性能提供了有效途径。

Abstract: Improving reasoning capabilities of Large Language Models (LLMs), especially under parameter constraints, is crucial for real-world applications. Prior work proposes recurrent transformers, which allocate a fixed number of extra iterations per token to improve generation quality. After the first, standard forward pass, instead of verbalization, last-layer hidden states are fed back as inputs for additional iterations to refine token predictions. Yet we identify a latent overthinking phenomenon: easy token predictions that are already correct after the first pass are sometimes revised into errors in additional iterations. To address this, we propose Think-at-Hard (TaH), a dynamic latent thinking method that iterates deeper only at hard tokens. It employs a lightweight neural decider to trigger latent iterations only at tokens that are likely incorrect after the standard forward pass. During latent iterations, Low-Rank Adaptation (LoRA) modules shift the LLM objective from general next-token prediction to focused hard-token refinement. We further introduce a duo-causal attention mechanism that extends attention from the token sequence dimension to an additional iteration depth dimension. This enables cross-iteration information flow while maintaining full sequential parallelism. Experiments show that TaH boosts LLM reasoning performance across five challenging benchmarks while maintaining the same parameter count. Compared with baselines that iterate twice for all output tokens, TaH delivers 8.1-11.3% accuracy gains while exempting 94% of tokens from the second iteration. Against strong single-iteration Qwen3 models finetuned with the same data, it also delivers 4.0-5.0% accuracy gains. When allowing less than 3% additional parameters from LoRA and the iteration decider, the gains increase to 8.5-12.6% and 5.3-5.4%, respectively. Our code is available at https://github.com/thu-nics/TaH.

</details>


### [243] [Training Language Models to Explain Their Own Computations](https://arxiv.org/abs/2511.08579)
*Belinda Z. Li,Zifan Carl Guo,Vincent Huang,Jacob Steinhardt,Jacob Andreas*

Main category: cs.CL

TL;DR: 研究表明语言模型可以学习忠实地描述其内部计算，并且这种自我解释比使用其他模型解释更有效，为现有可解释性方法提供了可扩展的补充。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究语言模型（LMs）能否忠实地描述其内部计算，以及它们在解释自身行为方面是否优于解释其他模型。核心动机是利用LMs对自身内部机制的特权访问，开发新的解释其行为的技术。

Method: 研究方法是使用现有可解释性技术作为事实依据，对LMs进行微调，使其能够生成自然语言描述。具体描述的内容包括：1) LM特征编码的信息，2) LM内部激活的因果结构，以及3) 特定输入词元对LM输出的影响。同时，研究还比较了模型解释自身计算与使用不同模型解释其计算的效果。

Result: 经过数万个解释示例的训练，解释器模型对新查询表现出显著的泛化能力。这种泛化能力部分归因于解释器模型对其内部机制的特权访问：模型解释自身计算通常比使用不同模型（即使是能力更强的模型）解释其计算效果更好。

Conclusion: 研究结果表明，语言模型不仅能够可靠地解释其内部计算，而且这种自我解释为现有可解释性方法提供了一种可扩展的补充方案。

Abstract: Can language models (LMs) learn to faithfully describe their internal computations? Are they better able to describe themselves than other models? We study the extent to which LMs' privileged access to their own internals can be leveraged to produce new techniques for explaining their behavior. Using existing interpretability techniques as a source of ground truth, we fine-tune LMs to generate natural language descriptions of (1) the information encoded by LM features, (2) the causal structure of LMs' internal activations, and (3) the influence of specific input tokens on LM outputs. When trained with only tens of thousands of example explanations, explainer models exhibit non-trivial generalization to new queries. This generalization appears partly attributable to explainer models' privileged access to their own internals: using a model to explain its own computations generally works better than using a *different* model to explain its computations (even if the other model is significantly more capable). Our results suggest not only that LMs can learn to reliably explain their internal computations, but that such explanations offer a scalable complement to existing interpretability methods.

</details>


### [244] [SPEAR-MM: Selective Parameter Evaluation and Restoration via Model Merging for Efficient Financial LLM Adaptation](https://arxiv.org/abs/2511.08500)
*Berkcan Kapusuzoglu,Supriyo Chakraborty,Renkun Ni,Stephen Rawls,Sambit Sahu*

Main category: cs.CL

TL;DR: 处理失败


<details>
  <summary>Details</summary>
Motivation: 处理失败

Method: 处理失败

Result: 处理失败

Conclusion: 处理失败

Abstract: Large language models (LLMs) adapted to financial domains often suffer from catastrophic forgetting of general reasoning capabilities essential for customer interactions and complex financial analysis. We introduce Selective Parameter Evaluation and Restoration via Model Merging (SPEAR-MM), a practical framework that preserves critical capabilities while enabling domain adaptation. Our method approximates layer-wise impact on external benchmarks through post-hoc analysis, then selectively freezes or restores transformer layers via spherical interpolation merging. Applied to LLaMA-3.1-8B for financial tasks, SPEAR-MM achieves 91.2% retention of general capabilities versus 69.7% for standard continual pretraining, while maintaining 94% of domain adaptation gains. The approach provides interpretable trade-off control and reduces computational costs by 90% crucial for resource-constrained financial institutions.

</details>


### [245] [AlphaResearch: Accelerating New Algorithm Discovery with Language Models](https://arxiv.org/abs/2511.08522)
*Zhaojian Yu,Kaiyue Feng,Yilun Zhao,Shilin He,Xiao-Ping Zhang,Arman Cohan*

Main category: cs.CL

TL;DR: 处理失败


<details>
  <summary>Details</summary>
Motivation: 处理失败

Method: 处理失败

Result: 处理失败

Conclusion: 处理失败

Abstract: Large language models have made significant progress in complex but easy-to-verify problems, yet they still struggle with discovering the unknown. In this paper, we present \textbf{AlphaResearch}, an autonomous research agent designed to discover new algorithms on open-ended problems. To synergize the feasibility and innovation of the discovery process, we construct a novel dual research environment by combining the execution-based verify and simulated real-world peer review environment. AlphaResearch discovers new algorithm by iteratively running the following steps: (1) propose new ideas (2) verify the ideas in the dual research environment (3) optimize the research proposals for better performance. To promote a transparent evaluation process, we construct \textbf{AlphaResearchComp}, a new evaluation benchmark that includes an eight open-ended algorithmic problems competition, with each problem carefully curated and verified through executable pipelines, objective metrics, and reproducibility checks. AlphaResearch gets a 2/8 win rate in head-to-head comparison with human researchers, demonstrate the possibility of accelerating algorithm discovery with LLMs. Notably, the algorithm discovered by AlphaResearch on the \emph{``packing circles''} problem achieves the best-of-known performance, surpassing the results of human researchers and strong baselines from recent work (e.g., AlphaEvolve). Additionally, we conduct a comprehensive analysis of the remaining challenges of the 6/8 failure cases, providing valuable insights for future research.

</details>


### [246] [Moral Susceptibility and Robustness under Persona Role-Play in Large Language Models](https://arxiv.org/abs/2511.08565)
*Davi Bastos Costa,Felippe Alves,Renato Vicente*

Main category: cs.CL

TL;DR: 处理失败


<details>
  <summary>Details</summary>
Motivation: 处理失败

Method: 处理失败

Result: 处理失败

Conclusion: 处理失败

Abstract: Large language models (LLMs) increasingly operate in social contexts, motivating analysis of how they express and shift moral judgments. In this work, we investigate the moral response of LLMs to persona role-play, prompting a LLM to assume a specific character. Using the Moral Foundations Questionnaire (MFQ), we introduce a benchmark that quantifies two properties: moral susceptibility and moral robustness, defined from the variability of MFQ scores across and within personas, respectively. We find that, for moral robustness, model family accounts for most of the variance, while model size shows no systematic effect. The Claude family is, by a significant margin, the most robust, followed by Gemini and GPT-4 models, with other families exhibiting lower robustness. In contrast, moral susceptibility exhibits a mild family effect but a clear within-family size effect, with larger variants being more susceptible. Moreover, robustness and susceptibility are positively correlated, an association that is more pronounced at the family level. Additionally, we present moral foundation profiles for models without persona role-play and for personas averaged across models. Together, these analyses provide a systematic view of how persona conditioning shapes moral behavior in large language models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [247] [CAVER: Curious Audiovisual Exploring Robot](https://arxiv.org/abs/2511.07619)
*Luca Macesanu,Boueny Folefack,Samik Singh,Ruchira Ray,Ben Abbatematteo,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: CAVER是一个新型机器人，通过主动交互、新颖的末端执行器、视听表示和好奇心驱动的探索算法，高效地构建并利用物体的丰富视听表示，从而显著提升材料分类和仅音频演示的模仿能力。


<details>
  <summary>Details</summary>
Motivation: 多模态视听感知能为机器人操作带来新机遇（如更好的材料分类、仅有音频信号的模仿学习），但机器人需要学习物体视觉外观与互动时产生声音之间的关联。这需要新的交互能力、表示方法和探索策略来高效地构建丰富的视听知识。

Method: 本文提出了CAVER机器人，包含三项创新：1) 一个新颖的3D打印末端执行器，可激发物体的音频响应；2) 一种结合局部和全局外观信息与声音特征的视听表示；3) 一种好奇心驱动的探索算法，优先与不确定性高的物体交互，以更少的交互次数获得对“令人惊讶”音频的良好覆盖。

Result: 实验证明，CAVER比多种探索基线更高效地构建了丰富的表示。所学习的视听表示显著提高了材料分类的准确性，并显著改善了对仅有音频的人类演示的模仿能力。

Conclusion: CAVER机器人通过创新的硬件、视听表示和探索算法，成功且高效地构建和利用了物体的丰富视听知识，为机器人处理多模态感知任务提供了有效途径，特别是在材料分类和音频驱动的模仿学习方面表现出色。

Abstract: Multimodal audiovisual perception can enable new avenues for robotic manipulation, from better material classification to the imitation of demonstrations for which only audio signals are available (e.g., playing a tune by ear). However, to unlock such multimodal potential, robots need to learn the correlations between an object's visual appearance and the sound it generates when they interact with it. Such an active sensorimotor experience requires new interaction capabilities, representations, and exploration methods to guide the robot in efficiently building increasingly rich audiovisual knowledge. In this work, we present CAVER, a novel robot that builds and utilizes rich audiovisual representations of objects. CAVER includes three novel contributions: 1) a novel 3D printed end-effector, attachable to parallel grippers, that excites objects' audio responses, 2) an audiovisual representation that combines local and global appearance information with sound features, and 3) an exploration algorithm that uses and builds the audiovisual representation in a curiosity-driven manner that prioritizes interacting with high uncertainty objects to obtain good coverage of surprising audio with fewer interactions. We demonstrate that CAVER builds rich representations in different scenarios more efficiently than several exploration baselines, and that the learned audiovisual representation leads to significant improvements in material classification and the imitation of audio-only human demonstrations. https://caver-bot.github.io/

</details>


### [248] [Time-Aware Policy Learning for Adaptive and Punctual Robot Control](https://arxiv.org/abs/2511.07654)
*Yinsen Jia,Boyuan Chen*

Main category: cs.RO

TL;DR: 本文提出了一种“时间感知策略学习”强化学习框架，使机器人能够将时间作为核心变量进行感知和推理。该框架通过引入剩余时间和时间比率等时间信号，显著提高了机器人在效率、鲁棒性和适应性方面的表现，并支持人机协作和多智能体协调。


<details>
  <summary>Details</summary>
Motivation: 动物和人类的智能行为都离不开时间感知，它指导着动作的序列、节奏和适应性。然而，大多数机器人学习算法在时间方面是盲目的，无法显式地利用时间信息来优化行为。

Method: 该框架通过向传统的强化学习策略中添加两个互补的时间信号（剩余时间和时间比率），使单一策略能够连续调节其行为，从快速动态到谨慎精确。通过共同优化准时性和稳定性，机器人无需重新训练或调整奖励即可学习平衡效率、鲁棒性、弹性和准时性。

Result: 在多种操作任务中，时间感知策略比标准强化学习基线在效率上提高了48%，在模拟到真实世界的迁移中鲁棒性提高了8倍，在声学安静性方面提高了90%，同时保持了接近完美的成功率。显式的时间推理还支持实时的人机协同控制和多智能体协调，使机器人能够从干扰中恢复、在延迟后重新同步并与人类意图对齐运动节奏。

Conclusion: 通过将时间视为行为的一个可控维度而非约束，时间感知策略学习为高效、鲁棒、弹性且与人类对齐的机器人自主性提供了一个统一的基础。

Abstract: Temporal awareness underlies intelligent behavior in both animals and humans, guiding how actions are sequenced, paced, and adapted to changing goals and environments. Yet most robot learning algorithms remain blind to time. We introduce time-aware policy learning, a reinforcement learning framework that enables robots to explicitly perceive and reason with time as a first-class variable. The framework augments conventional reinforcement policies with two complementary temporal signals, the remaining time and a time ratio, which allow a single policy to modulate its behavior continuously from rapid and dynamic to cautious and precise execution. By jointly optimizing punctuality and stability, the robot learns to balance efficiency, robustness, resiliency, and punctuality without re-training or reward adjustment. Across diverse manipulation domains from long-horizon pick and place, to granular-media pouring, articulated-object handling, and multi-agent object delivery, the time-aware policy produces adaptive behaviors that outperform standard reinforcement learning baselines by up to 48% in efficiency, 8 times more robust in sim-to-real transfer, and 90% in acoustic quietness while maintaining near-perfect success rates. Explicit temporal reasoning further enables real-time human-in-the-loop control and multi-agent coordination, allowing robots to recover from disturbances, re-synchronize after delays, and align motion tempo with human intent. By treating time not as a constraint but as a controllable dimension of behavior, time-aware policy learning provides a unified foundation for efficient, robust, resilient, and human-aligned robot autonomy.

</details>


### [249] [Testing and Evaluation of Underwater Vehicle Using Hardware-In-The-Loop Simulation with HoloOcean](https://arxiv.org/abs/2511.07687)
*Braden Meyers,Joshua G. Mangelson*

Main category: cs.RO

TL;DR: 本文展示了使用HoloOcean 2.0模拟器和ROS 2接口，为鱼雷AUV（CougUV）构建的硬件在环（HIL）和软件在环（SIL）测试平台，并将其模拟结果与真实世界试验数据进行了比较。


<details>
  <summary>Details</summary>
Motivation: 在受控环境中测试水下机器人系统（特别是依赖声学传感器和控制面的系统）极具挑战性，因为室内水池空间有限，难以进行大规模的控制、导航和感知算法测试。高保真水下仿真工具的最新发展有望解决这些问题。

Method: 研究人员利用了HoloOcean 2.0模拟器（改进了鱼雷AUV的动力学模型并新增了ROS 2接口）。他们建立了一个HIL和SIL设置，通过ROS 2桥接将模拟传感器数据发送给CougUV（或其软件），并将控制面指令从CougUV发送回模拟器，由模拟器计算车辆动力学和传感器数据。最终，模拟结果与真实世界的现场试验结果进行了比较。

Result: 成功展示了使用HoloOcean 2.0和ROS 2接口进行CougUV鱼雷AUV测试和评估的HIL和SIL设置。模拟结果与真实世界的现场试验结果进行了比较，证明了该模拟器的实用性。

Conclusion: 高保真水下仿真工具（如HoloOcean 2.0），结合HIL和SIL设置以及ROS 2接口，能够有效解决水下机器人系统（如AUV）在物理测试环境中的局限性，提供了一种可行的测试与评估方案。

Abstract: Testing marine robotics systems in controlled environments before field tests is challenging, especially when acoustic-based sensors and control surfaces only function properly underwater. Deploying robots in indoor tanks and pools often faces space constraints that complicate testing of control, navigation, and perception algorithms at scale. Recent developments of high-fidelity underwater simulation tools have the potential to address these problems. We demonstrate the utility of the recently released HoloOcean 2.0 simulator with improved dynamics for torpedo AUV vehicles and a new ROS 2 interface. We have successfully demonstrated a Hardware-in-the-Loop (HIL) and Software-in-the-Loop (SIL) setup for testing and evaluating a CougUV torpedo autonomous underwater vehicle (AUV) that was built and developed in our lab. With this HIL and SIL setup, simulations are run in HoloOcean using a ROS 2 bridge such that simulated sensor data is sent to the CougUV (mimicking sensor drivers) and control surface commands are sent back to the simulation, where vehicle dynamics and sensor data are calculated. We compare our simulated results to real-world field trial results.

</details>


### [250] [RoboTAG: End-to-end Robot Configuration Estimation via Topological Alignment Graph](https://arxiv.org/abs/2511.07717)
*Yifan Liu,Fangneng Zhan,Wanhua Li,Haowen Sun,Katerina Fragkiadaki,Hanspeter Pfister*

Main category: cs.RO

TL;DR: 本文提出RoboTAG，一个结合2D和3D分支的机器人拓扑对齐图，通过分支间的一致性监督，实现在无标注数据下从单目RGB图像估计机器人姿态，有效缓解数据瓶颈。


<details>
  <summary>Details</summary>
Motivation: 从单目RGB图像估计机器人姿态具有挑战性。现有方法过度依赖稀缺的标注数据，导致模拟到现实的鸿沟，并且将3D问题简化为2D域，忽略了3D先验信息。

Method: 提出机器人拓扑对齐图（RoboTAG），包含一个2D分支和一个3D分支。3D分支注入3D先验知识，并促使2D和3D表示协同演化。图中节点代表相机和机器人系统状态，边表示变量间的依赖或对齐。通过定义闭环，在不同分支间应用一致性监督，从而允许使用无标注的真实世界图像进行训练。

Result: 实验结果表明，该方法对不同类型的机器人均有效，突出了其缓解机器人领域数据瓶颈的潜力。

Conclusion: RoboTAG通过整合3D先验和利用2D/3D分支间的一致性监督，成功解决了单目RGB图像机器人姿态估计中对标注数据的依赖问题，为机器人领域的数据瓶颈提供了有效解决方案。

Abstract: Estimating robot pose from a monocular RGB image is a challenge in robotics and computer vision. Existing methods typically build networks on top of 2D visual backbones and depend heavily on labeled data for training, which is often scarce in real-world scenarios, causing a sim-to-real gap. Moreover, these approaches reduce the 3D-based problem to 2D domain, neglecting the 3D priors. To address these, we propose Robot Topological Alignment Graph (RoboTAG), which incorporates a 3D branch to inject 3D priors while enabling co-evolution of the 2D and 3D representations, alleviating the reliance on labels. Specifically, the RoboTAG consists of a 3D branch and a 2D branch, where nodes represent the states of the camera and robot system, and edges capture the dependencies between these variables or denote alignments between them. Closed loops are then defined in the graph, on which a consistency supervision across branches can be applied. This design allows us to utilize in-the-wild images as training data without annotations. Experimental results demonstrate that our method is effective across robot types, highlighting its potential to alleviate the data bottleneck in robotics.

</details>


### [251] [A QP Framework for Improving Data Collection: Quantifying Device-Controller Performance in Robot Teleoperation](https://arxiv.org/abs/2511.07720)
*Yuxuan Zhao,Yuanchen Tang,Jindi Zhang,Hongyu Yu*

Main category: cs.RO

TL;DR: 本研究开发了一个通用的远程操作管道，用于收集机器人操作任务的数据，该管道包含一个新颖的优化二次规划控制器，可实现柔顺位姿跟踪和奇异点规避，以提高机器人学习的数据质量。


<details>
  <summary>Details</summary>
Motivation: 机器人学习旨在赋予机器人系统类人脑智能，通过经验自主获取和适应技能，提升灵活性和适应性。为了在具身智能的大型语言模型中实现类似能力，高质量的数据对于训练具有多样化机器人技能的基础模型至关重要。本研究旨在调查远程操作设备在收集操纵任务数据时的效果。

Method: 开发了一个兼容不同远程操作设备和机械手控制器（包括基于位置的逆运动学控制、基于力矩的逆动力学控制和基于优化的柔顺控制）的远程操作管道。在此管道中，构建了具有动态零空间和阻抗跟踪作为新颖优化控制器的最优QP（二次规划）公式，以实现柔顺位姿跟踪和奇异点规避。该优化控制器能根据机器人关节可操作性自适应调整权重。

Result: 定量实验结果分析表明，不同的远程操作界面和运动控制器组合对远程操作轨迹数据的质量（包括跟踪误差、奇异点发生以及关节轨迹的平滑度）有显著影响。

Conclusion: 本研究提出了一个通用的远程操作管道和一个新颖的基于QP的优化控制器，该控制器通过实现柔顺位姿跟踪和奇异点规避，有效提高了远程操作数据的质量。研究结果揭示了不同远程操作设备和控制器组合对所收集数据质量的影响。

Abstract: Robot learning empowers the robot system with human brain-like intelligence to autonomously acquire and adapt skills through experience, enhancing flexibility and adaptability in various environments. Aimed at achieving a similar level of capability in large language models (LLMs) for embodied intelligence, data quality plays a crucial role in training a foundational model with diverse robot skills. In this study, we investigate the collection of data for manipulation tasks using teleoperation devices. Different devices yield varying effects when paired with corresponding controller strategies, including position-based inverse kinematics (IK) control, torque-based inverse dynamics (ID) control, and optimization-based compliance control. In this paper, we develop a teleoperation pipeline that is compatible with different teleoperation devices and manipulator controllers. Within the pipeline, we construct the optimal QP formulation with the dynamic nullspace and the impedance tracking as the novel optimal controller to achieve compliant pose tracking and singularity avoidance. Regarding the optimal controller, it adaptively adjusts the weights assignment depending on the robot joint manipulability that reflects the state of joint configuration for the pose tracking in the form of impedance control and singularity avoidance with nullspace tracking. Analysis of quantitative experimental results suggests the quality of the teleoperated trajectory data, including tracking error, occurrence of singularity, and the smoothness of the joints' trajectory, with different combinations of teleoperation interface and the motion controller.

</details>


### [252] [LLM-GROP: Visually Grounded Robot Task and Motion Planning with Large Language Models](https://arxiv.org/abs/2511.07727)
*Xiaohan Zhang,Yan Ding,Yohei Hayamizu,Zainab Altaweel,Yifeng Zhu,Yuke Zhu,Peter Stone,Chris Paxton,Shiqi Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种用于多物体移动操作（MoMa）任务的TAMP（任务与运动规划）框架，该框架利用大型语言模型（LLM）的常识知识和计算机视觉方法来选择机器人基座位置，以处理未明确指定的目标和长距离物体重新排列任务。


<details>
  <summary>Details</summary>
Motivation: 机器人任务规划和运动规划是核心问题。在TAMP背景下，处理多物体移动操作（MoMa）尤其复杂，特别是当目标不明确时（例如“摆放餐桌”）。研究旨在利用常识知识和高效的机器人基座定位策略来解决这些挑战。

Method: 该研究采用了一种TAMP方法，将任务规划和运动规划交织进行，以确保目标实现和运动可行性。具体方法包括：1) 利用大型语言模型（LLM）获取丰富的常识知识（例如餐具摆放方式），以辅助任务级和运动级规划。2) 使用计算机视觉方法学习选择机器人基座位置（即机器人的“足迹”和方向）的策略，以促进MoMa行为。该框架旨在处理物体重新排列中的常识并适应包含许多待移动物体的新情况。

Result: 研究在真实世界和模拟环境中进行了定量实验，评估了完成长距离物体重新排列任务的成功率和效率。机器人在真实世界物体重新排列试验中完成了84.4%的任务。然而，主观的人类评估表明，机器人的表现仍低于经验丰富的人类服务员。

Conclusion: 本文提供了一个原则性的MoMa任务TAMP框架，该框架考虑了物体重新排列的常识，并能适应包含大量物体的新情况。尽管在真实世界中取得了84.4%的成功率，但与人类专家相比仍有差距，这表明未来仍有改进空间。

Abstract: Task planning and motion planning are two of the most important problems in robotics, where task planning methods help robots achieve high-level goals and motion planning methods maintain low-level feasibility. Task and motion planning (TAMP) methods interleave the two processes of task planning and motion planning to ensure goal achievement and motion feasibility. Within the TAMP context, we are concerned with the mobile manipulation (MoMa) of multiple objects, where it is necessary to interleave actions for navigation and manipulation.
  In particular, we aim to compute where and how each object should be placed given underspecified goals, such as ``set up dinner table with a fork, knife and plate.'' We leverage the rich common sense knowledge from large language models (LLMs), e.g., about how tableware is organized, to facilitate both task-level and motion-level planning. In addition, we use computer vision methods to learn a strategy for selecting base positions to facilitate MoMa behaviors, where the base position corresponds to the robot's ``footprint'' and orientation in its operating space. Altogether, this article provides a principled TAMP framework for MoMa tasks that accounts for common sense about object rearrangement and is adaptive to novel situations that include many objects that need to be moved. We performed quantitative experiments in both real-world settings and simulated environments. We evaluated the success rate and efficiency in completing long-horizon object rearrangement tasks. While the robot completed 84.4\% real-world object rearrangement trials, subjective human evaluations indicated that the robot's performance is still lower than experienced human waiters.

</details>


### [253] [Navigating the Wild: Pareto-Optimal Visual Decision-Making in Image Space](https://arxiv.org/abs/2511.07750)
*Durgakant Pushp,Weizhe Chen,Zheng Chen,Chaomin Luo,Jason M. Gregory,Lantao Liu*

Main category: cs.RO

TL;DR: 本文提出了一种名为“Pareto-Optimal Visual Navigation”的轻量级图像空间框架，结合数据驱动语义、帕累托最优决策和视觉伺服，以实现实时导航，解决传统方法在复杂环境中的局限性。


<details>
  <summary>Details</summary>
Motivation: 在复杂的现实世界环境中导航需要语义理解和自适应决策。传统的无地图反应式方法在杂乱环境中表现不佳；基于地图的方法需要大量的建图工作；基于学习的解决方案则依赖大量数据集且泛化能力有限。

Method: 本文提出了一种轻量级的图像空间框架，名为“Pareto-Optimal Visual Navigation”。它结合了数据驱动的语义理解、帕累托最优决策制定以及视觉伺服技术。

Result: 该框架能够实现实时导航。

Conclusion: 该框架旨在解决传统导航方法在复杂、杂乱的现实世界环境中面临的挑战，提供一种有效、轻量级的解决方案。

Abstract: Navigating complex real-world environments requires semantic understanding and adaptive decision-making. Traditional reactive methods without maps often fail in cluttered settings, map-based approaches demand heavy mapping effort, and learning-based solutions rely on large datasets with limited generalization. To address these challenges, we present Pareto-Optimal Visual Navigation, a lightweight image-space framework that combines data-driven semantics, Pareto-optimal decision-making, and visual servoing for real-time navigation.

</details>


### [254] [ViPRA: Video Prediction for Robot Actions](https://arxiv.org/abs/2511.07732)
*Sandeep Routray,Hengkai Pan,Unnat Jain,Shikhar Bahl,Deepak Pathak*

Main category: cs.RO

TL;DR: ViPRA是一个预训练-微调框架，通过预测未来的视觉观测和以运动为中心的潜在动作，使视频预测模型能够从无动作标注的视频中学习连续机器人控制，并在下游任务中利用少量演示实现高效控制。


<details>
  <summary>Details</summary>
Motivation: 视频（包括人类或遥控机器人视频）包含丰富的物理交互信息，但大多数缺乏动作标注，限制了它们在机器人学习中的应用。研究旨在利用这些无标注视频进行机器人策略学习。

Method: 该方法名为ViPRA，分为预训练和微调两阶段：
1.  **预训练**：训练一个视频-语言模型，预测未来的视觉观测和以运动为中心的潜在动作。这些潜在动作作为场景动态的中间表示，并通过感知损失和光流一致性进行训练，以确保其物理基础。
2.  **微调**：引入一个分块流匹配解码器，将潜在动作映射到机器人特定的连续动作序列，仅需100到200个遥控演示。这种方法避免了昂贵的动作标注，支持跨实体泛化，并通过分块动作解码实现高达22 Hz的平滑、高频连续控制。与以往将预训练视为自回归策略学习不同，ViPRA明确建模了“什么在变化”和“如何变化”。

Result: ViPRA在SIMPLER基准测试中表现优于强基线模型，性能提升16%；在真实世界操作任务中，性能提升13%。它实现了平滑、高频（高达22 Hz）的连续控制，避免了昂贵的动作标注，并支持跨实体泛化。

Conclusion: ViPRA框架成功地将视频预测模型转化为机器人策略，通过学习潜在动作并结合高效的解码器，能够从无动作标注的视频中学习连续机器人控制，在多个基准和真实世界任务中取得了显著的性能提升。

Abstract: Can we turn a video prediction model into a robot policy? Videos, including those of humans or teleoperated robots, capture rich physical interactions. However, most of them lack labeled actions, which limits their use in robot learning. We present Video Prediction for Robot Actions (ViPRA), a simple pretraining-finetuning framework that learns continuous robot control from these actionless videos. Instead of directly predicting actions, we train a video-language model to predict both future visual observations and motion-centric latent actions, which serve as intermediate representations of scene dynamics. We train these latent actions using perceptual losses and optical flow consistency to ensure they reflect physically grounded behavior. For downstream control, we introduce a chunked flow matching decoder that maps latent actions to robot-specific continuous action sequences, using only 100 to 200 teleoperated demonstrations. This approach avoids expensive action annotation, supports generalization across embodiments, and enables smooth, high-frequency continuous control upto 22 Hz via chunked action decoding. Unlike prior latent action works that treat pretraining as autoregressive policy learning, explicitly models both what changes and how. Our method outperforms strong baselines, with a 16% gain on the SIMPLER benchmark and a 13% improvement across real world manipulation tasks. We will release models and code at https://vipra-project.github.io

</details>


### [255] [High-Altitude Balloon Station-Keeping with First Order Model Predictive Control](https://arxiv.org/abs/2511.07761)
*Myles Pasetsky,Jiawei Lin,Bradley Guo,Sarah Dean*

Main category: cs.RO

TL;DR: 本文提出了一种基于一阶模型预测控制（FOMPC）的方法，用于高空气球的定点保持，并证明其性能优于最先进的无模型强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 高空气球的非线性、欠驱动动力学和风场的部分可观测性使得以往的研究主要依赖无模型强化学习方法进行定点控制，并认为模型基方法不切实际。本文旨在重新审视这一假设。

Method: 开发了一阶模型预测控制（FOMPC），利用JAX将风和气球动力学实现为可微分函数，从而实现基于梯度的轨迹优化进行在线规划。

Result: FOMPC在半径内停留时间（TWR）方面比最先进的强化学习策略提高了24%，且无需离线训练，尽管每个控制步骤的在线计算量更大。通过系统消融实验证明，在线规划在多种配置下（包括简化风场和动力学模型）均有效。

Conclusion: 模型基控制对于高空气球的定点保持是有效的，挑战了以往认为其不切实际的假设，并能显著超越无模型强化学习方法。

Abstract: High-altitude balloons (HABs) are common in scientific research due to their wide range of applications and low cost. Because of their nonlinear, underactuated dynamics and the partial observability of wind fields, prior work has largely relied on model-free reinforcement learning (RL) methods to design near-optimal control schemes for station-keeping. These methods often compare only against hand-crafted heuristics, dismissing model-based approaches as impractical given the system complexity and uncertain wind forecasts. We revisit this assumption about the efficacy of model-based control for station-keeping by developing First-Order Model Predictive Control (FOMPC). By implementing the wind and balloon dynamics as differentiable functions in JAX, we enable gradient-based trajectory optimization for online planning. FOMPC outperforms a state-of-the-art RL policy, achieving a 24% improvement in time-within-radius (TWR) without requiring offline training, though at the cost of greater online computation per control step. Through systematic ablations of modeling assumptions and control factors, we show that online planning is effective across many configurations, including under simplified wind and dynamics models.

</details>


### [256] [Benchmarking Resilience and Sensitivity of Polyurethane-Based Vision-Based Tactile Sensors](https://arxiv.org/abs/2511.07797)
*Benjamin Davis,Hannah Stuart*

Main category: cs.RO

TL;DR: 本文提出用聚氨酯橡胶替代传统视觉触觉传感器（VBTS）中易损的硅胶表面，并设计了一系列评估协议来比较两种材料的耐久性和灵敏度，展示了聚氨酯在特定应用中的优势。


<details>
  <summary>Details</summary>
Motivation: 现有视觉触觉传感器（VBTS）的硅胶触觉表面灵敏度高，但易受负载和磨损而损坏。研究旨在寻找一种更具物理弹性的材料来提高传感器耐用性。

Method: 提出使用聚氨酯橡胶作为VBTS的触觉表面材料。设计了一系列标准化评估协议：1) 耐久性测试，评估传感器在法向加载、剪切加载和磨损下的性能；2) 无模型灵敏度评估，直接测量力和空间灵敏度；3) 通过瓶盖拧紧和拧松演示，展示聚氨酯凝胶在实际应用中的优势。

Result: 研究结果表明，聚氨酯橡胶可能提供更高的物理凝胶弹性，尽管可能以牺牲部分灵敏度为代价。在瓶盖操作演示中，聚氨酯凝胶表现出优于硅胶的优势。

Conclusion: 聚氨酯橡胶可为视觉触觉传感器提供更高的物理弹性，适用于高负载应用。本文提出的评估协议为比较不同VBTS凝胶材料的性能提供了标准方法。

Abstract: Vision-based tactile sensors (VBTSs) are a promising technology for robots, providing them with dense signals that can be translated into an understanding of normal and shear load, contact region, texture classification, and more. However, existing VBTS tactile surfaces make use of silicone gels, which provide high sensitivity but easily deteriorate from loading and surface wear. We propose that polyurethane rubber, used for high-load applications like shoe soles, rubber wheels, and industrial gaskets, may provide improved physical gel resilience, potentially at the cost of sensitivity. To compare the resilience and sensitivity of silicone and polyurethane VBTS gels, we propose a series of standard evaluation benchmarking protocols. Our resilience tests assess sensor durability across normal loading, shear loading, and abrasion. For sensitivity, we introduce model-free assessments of force and spatial sensitivity to directly measure the physical capabilities of each gel without effects introduced from data and model quality. Finally, we include a bottle cap loosening and tightening demonstration as an example where polyurethane gels provide an advantage over their silicone counterparts.

</details>


### [257] [SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control](https://arxiv.org/abs/2511.07820)
*Zhengyi Luo,Ye Yuan,Tingwu Wang,Chenran Li,Sirui Chen,Fernando Castañeda,Zi-Ang Cao,Jiefeng Li,David Minor,Qingwei Ben,Xingye Da,Runyu Ding,Cyrus Hogg,Lina Song,Edy Lim,Eugene Jeong,Tairan He,Haoru Xue,Wenli Xiao,Zi Wang,Simon Yuen,Jan Kautz,Yan Chang,Umar Iqbal,Linxi "Jim" Fan,Yuke Zhu*

Main category: cs.RO

TL;DR: 通过在运动追踪任务中扩展模型容量、数据和计算资源，研究人员开发了一种通用的类人机器人控制器，能够生成自然、鲁棒的全身运动。


<details>
  <summary>Details</summary>
Motivation: 尽管参数达到十亿级别的基础模型在数千个GPU上取得了显著的扩展收益，但类人机器人控制领域尚未展现出类似的扩展性。当前的神经网络控制器规模较小，行为集有限，且训练资源有限。

Method: 该研究将运动追踪定位为类人机器人控制的一个自然且可扩展的任务，利用多样化的动作捕捉数据（超过1亿帧，700小时）进行密集监督，以获取人类运动先验，无需手动设计奖励。他们通过扩展三个维度构建了一个运动追踪基础模型：网络规模（从1.2M到42M参数）、数据集量和计算资源（9k GPU小时）。模型通过实时通用运动学规划器和统一的令牌空间（支持VR遥控、人类视频、VLA模型等多种运动输入接口）展示了实用性。

Result: 研究成果是一个能够创建自然、鲁棒全身运动的通用类人机器人控制器。随着计算资源和数据多样性的增加，性能稳步提升，并且学习到的表征能够泛化到未见过的运动。通过运动学规划器和统一的令牌空间，模型的实际效用得到了验证。

Conclusion: 大规模运动追踪展现出良好的特性，性能随计算和数据多样性的增加而稳定提升，学习到的表征能够泛化。这表明大规模运动追踪是类人机器人控制的实用基础。

Abstract: Despite the rise of billion-parameter foundation models trained across thousands of GPUs, similar scaling gains have not been shown for humanoid control. Current neural controllers for humanoids remain modest in size, target a limited behavior set, and are trained on a handful of GPUs over several days. We show that scaling up model capacity, data, and compute yields a generalist humanoid controller capable of creating natural and robust whole-body movements. Specifically, we posit motion tracking as a natural and scalable task for humanoid control, leverageing dense supervision from diverse motion-capture data to acquire human motion priors without manual reward engineering. We build a foundation model for motion tracking by scaling along three axes: network size (from 1.2M to 42M parameters), dataset volume (over 100M frames, 700 hours of high-quality motion data), and compute (9k GPU hours). Beyond demonstrating the benefits of scale, we show the practical utility of our model through two mechanisms: (1) a real-time universal kinematic planner that bridges motion tracking to downstream task execution, enabling natural and interactive control, and (2) a unified token space that supports various motion input interfaces, such as VR teleoperation devices, human videos, and vision-language-action (VLA) models, all using the same policy. Scaling motion tracking exhibits favorable properties: performance improves steadily with increased compute and data diversity, and learned representations generalize to unseen motions, establishing motion tracking at scale as a practical foundation for humanoid control.

</details>


### [258] [Occlusion-Aware Ground Target Search by a UAV in an Urban Environment](https://arxiv.org/abs/2511.07822)
*Collin Hague,Artur Wolek*

Main category: cs.RO

TL;DR: 本文提出了一种无人机在城市路网中搜索移动兴趣点（POI）的策略，利用概率可见性体积（VV）和迭代深度A*算法，通过优化规划路径来最大化发现POI的概率，并在复杂环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在城市环境中，使用无人机搜索沿路网移动的兴趣点（POI）面临挑战，因为城市建筑会遮挡传感器的视线，需要一种有效的搜索策略来克服这种遮挡并找到POI。

Method: 该研究将无人机建模为可变速度的Dubins飞行器，配备视线传感器。提出了一种利用概率可见性体积（VV）的搜索策略，结合迭代深度A*（IDA*）算法进行未来运动规划。概率VV是POI状态特定分布下传感约束的随时间变化的3D表示。规划器使用启发式方法乐观估计在时间范围内看到POI的概率。通过对概率VV进行最大池化，创建了一个可变时间步长的规划器，以减少搜索空间并平衡长期和短期规划。

Result: 通过蒙特卡洛模拟，所提出的路径规划方法在杂乱环境中，特别是当无人机传感器的虚警概率较高时，表现优于现有基线方法。

Conclusion: 该研究提出了一种在城市路网中利用无人机搜索移动POI的有效策略，该策略通过结合概率可见性建模和优化的路径规划，在复杂的、有遮挡的环境中，尤其在传感器存在较高虚警率的情况下，能更有效地找到目标。

Abstract: This paper considers the problem of searching for a point of interest (POI) moving along an urban road network with an uncrewed aerial vehicle (UAV). The UAV is modeled as a variable-speed Dubins vehicle with a line-of-sight sensor in an urban environment that may occlude the sensor's view of the POI. A search strategy is proposed that exploits a probabilistic visibility volume (VV) to plan its future motion with iterative deepening $A^\ast$. The probabilistic VV is a time-varying three-dimensional representation of the sensing constraints for a particular distribution of the POI's state. To find the path most likely to view the POI, the planner uses a heuristic to optimistically estimate the probability of viewing the POI over a time horizon. The probabilistic VV is max-pooled to create a variable-timestep planner that reduces the search space and balances long-term and short-term planning. The proposed path planning method is compared to prior work with a Monte-Carlo simulation and is shown to outperform the baseline methods in cluttered environments when the UAV's sensor has a higher false alarm probability.

</details>


### [259] [Virtual Traffic Lights for Multi-Robot Navigation: Decentralized Planning with Centralized Conflict Resolution](https://arxiv.org/abs/2511.07811)
*Sagar Gupta,Thanh Vinh Nguyen,Thieu Long Phan,Vidul Attri,Archit Gupta,Niroshinie Fernando,Kevin Lee,Seng W. Loke,Ronny Kutadinata,Benjamin Champion,Akansel Cosgun*

Main category: cs.RO

TL;DR: 本文提出了一种混合多机器人协调框架，结合了分散式路径规划和集中式冲突解决，通过“虚拟交通灯”机制提高成功率并减少死锁。


<details>
  <summary>Details</summary>
Motivation: 传统的集中式规划方法往往会规定机器人路径，而研究目标是开发一种不规定路径、能有效解决多机器人冲突、提高任务成功率并减少死锁的协调系统。

Method: 每个机器人自主规划路径并分享信息给中央节点。中央系统检测潜在冲突，并只允许冲突中的一个机器人通过，同时指示其他机器人停止在冲突区域外，以避免死锁。系统不规定路径，而是发出停止指令，充当虚拟交通灯。

Result: 在多机器人仿真实验中，该方法提高了机器人到达目标的成功率并减少了死锁。此外，该系统在与两台四足机器人以及轮式Duckiebots进行的真实世界实验中得到了成功验证。

Conclusion: 所提出的混合多机器人协调框架，通过结合分散式路径规划和集中式冲突解决（以虚拟交通灯形式），能有效提高多机器人任务的成功率并显著减少死锁，并在仿真和真实世界中均得到验证。

Abstract: We present a hybrid multi-robot coordination framework that combines decentralized path planning with centralized conflict resolution. In our approach, each robot autonomously plans its path and shares this information with a centralized node. The centralized system detects potential conflicts and allows only one of the conflicting robots to proceed at a time, instructing others to stop outside the conflicting area to avoid deadlocks. Unlike traditional centralized planning methods, our system does not dictate robot paths but instead provides stop commands, functioning as a virtual traffic light. In simulation experiments with multiple robots, our approach increased the success rate of robots reaching their goals while reducing deadlocks. Furthermore, we successfully validated the system in real-world experiments with two quadruped robots and separately with wheeled Duckiebots.

</details>


### [260] [EquiMus: Energy-Equivalent Dynamic Modeling and Simulation of Musculoskeletal Robots Driven by Linear Elastic Actuators](https://arxiv.org/abs/2511.07887)
*Yinglei Zhu,Xuguang Dong,Qiyao Wang,Qi Shao,Fugui Xie,Xinjun Liu,Huichan Zhao*

Main category: cs.RO

TL;DR: 本文提出EquiMus，一个用于肌骨刚柔混合机器人的能量等效动态建模框架和MuJoCo仿真方法，解决了其复杂建模和控制挑战，并通过实验验证了其有效性，并展示了其在控制器设计和学习控制中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 软机器人的动态建模和控制面临复杂本构行为和实际操作条件的挑战。特别是对于具有连续分布质量、运动循环和多样运动模式的大规模混合刚柔机器人，准确有效的建模和仿真仍然是重大难题。

Method: 本文提出了EquiMus，一个能量等效动态建模框架和基于MuJoCo的仿真方法，专为具有线性弹性执行器的肌骨刚柔混合机器人设计。该方法旨在解决大规模混合刚柔机器人的复杂建模问题。

Result: 通过仿真和仿生机械腿的真实世界实验，验证了所提出方法的等效性和有效性。EquiMus进一步展示了其在控制器设计和基于学习的控制策略等下游任务中的实用性。

Conclusion: EquiMus框架为肌骨刚柔混合机器人提供了一个有效且可验证的动态建模和仿真解决方案，克服了现有挑战，并为这些机器人的高级控制策略奠定了基础。

Abstract: Dynamic modeling and control are critical for unleashing soft robots' potential, yet remain challenging due to their complex constitutive behaviors and real-world operating conditions. Bio-inspired musculoskeletal robots, which integrate rigid skeletons with soft actuators, combine high load-bearing capacity with inherent flexibility. Although actuation dynamics have been studied through experimental methods and surrogate models, accurate and effective modeling and simulation remain a significant challenge, especially for large-scale hybrid rigid--soft robots with continuously distributed mass, kinematic loops, and diverse motion modes. To address these challenges, we propose EquiMus, an energy-equivalent dynamic modeling framework and MuJoCo-based simulation for musculoskeletal rigid--soft hybrid robots with linear elastic actuators. The equivalence and effectiveness of the proposed approach are validated and examined through both simulations and real-world experiments on a bionic robotic leg. EquiMus further demonstrates its utility for downstream tasks, including controller design and learning-based control strategies.

</details>


### [261] [A Comprehensive Experimental Characterization of Mechanical Layer Jamming Systems](https://arxiv.org/abs/2511.07882)
*Jessica Gumowski,Krishna Manaswi Digumarti,David Howard*

Main category: cs.RO

TL;DR: 本文研究了机械层式卡阻（layer jamming）作为软机器人刚度调控机制，通过牙齿状突起结构实现，并分析了其设计参数（主要为牙齿几何形状）对弯曲和扭转刚度调控能力的影响。


<details>
  <summary>Details</summary>
Motivation: 自然界生物（如头足类和厚皮动物）通过刚度调控实现其附肢的灵巧控制。本研究旨在为软机器人提供类似的刚度调控能力，探索层式卡阻机制的潜力。

Method: 研究采用具有牙齿状突起的双层多材料结构实现机械层式卡阻。识别了关键设计参数，并对样本进行了弯曲和扭转载荷下的综合测试，以理解所选设计参数（主要是牙齿几何形状）对卡阻结构性能的影响。此外，还测量了分离两个卡阻层所需的力。

Result: 研究发现这些结构在弯曲载荷下能产生高达5倍的峰值刚度变化，在扭转载荷下能产生3.2倍的峰值刚度变化。同时，测量了分离两个卡阻层所需的力，这是一个在卡阻诱导刚度变化研究中常被忽略的参数。

Conclusion: 本研究旨在阐明机械层式卡阻系统的原理性设计，并指导研究人员为其特定应用领域选择合适的设计方案。

Abstract: Organisms in nature, such as Cephalopods and Pachyderms, exploit stiffness modulation to achieve amazing dexterity in the control of their appendages. In this paper, we explore the phenomenon of layer jamming, which is a popular stiffness modulation mechanism that provides an equivalent capability for soft robots. More specifically, we focus on mechanical layer jamming, which we realise through two-layer multi material structure with tooth-like protrusions. We identify key design parameters for mechanical layer jamming systems, including the ability to modulate stiffness, and perform a variety of comprehensive tests placing the specimens under bending and torsional loads to understand the influence of our selected design parameters (mainly tooth geometry) on the performance of the jammed structures. We note the ability of these structures to produce a peak change in stiffness of 5 times in bending and 3.2 times in torsion. We also measure the force required to separate the two jammed layers, an often ignored parameter in the study of jamming-induced stiffness change. This study aims to shed light on the principled design of mechanical layer jammed systems and guide researchers in the selection of appropriate designs for their specific application domains.

</details>


### [262] [Dual-MPC Footstep Planning for Robust Quadruped Locomotion](https://arxiv.org/abs/2511.07921)
*Byeong-Il Ham,Hyun-Bin Kim,Jeonguk Kang,Keun Ha Choi,Kyung-Soo Kim*

Main category: cs.RO

TL;DR: 本文提出了一种基于模型预测控制（MPC）的足迹规划策略，通过优化足迹位置，考虑角速度，并协调地面反作用力（GRF）和足迹放置，从而实现对身体姿态的鲁棒调节，减少振荡并延长步态周期。


<details>
  <summary>Details</summary>
Motivation: 现有基于模型的运动方法（如启发式或基于线性倒立摆模型）在足迹规划中通常只考虑线速度而忽略角速度，导致角动量仅通过地面反作用力（GRF）来处理，影响跟踪性能。

Method: 提出了一种考虑角速度的基于MPC的足迹规划策略。它将角动量控制问题重新定义为双输入方法，协调GRF和足迹放置。足迹规划器和GRF MPC之间建立了一个相互反馈循环，迭代更新足迹和GRF，以利用最优解。

Result: 该方法在四足机器人上得到了验证，在各种地形下均表现出鲁棒的运动能力，显著减少了身体振荡，并实现了更长的支撑相和摆动相。

Conclusion: 通过MPC协调GRF和足迹放置，该策略能够有效地调节身体姿态，改善跟踪性能，减少振荡，并延长步态周期，从而实现更稳健的机器人运动。

Abstract: In this paper, we propose a footstep planning strategy based on model predictive control (MPC) that enables robust regulation of body orientation against undesired body rotations by optimizing footstep placement. Model-based locomotion approaches typically adopt heuristic methods or planning based on the linear inverted pendulum model. These methods account for linear velocity in footstep planning, while excluding angular velocity, which leads to angular momentum being handled exclusively via ground reaction force (GRF). Footstep planning based on MPC that takes angular velocity into account recasts the angular momentum control problem as a dual-input approach that coordinates GRFs and footstep placement, instead of optimizing GRFs alone, thereby improving tracking performance. A mutual-feedback loop couples the footstep planner and the GRF MPC, with each using the other's solution to iteratively update footsteps and GRFs. The use of optimal solutions reduces body oscillation and enables extended stance and swing phases. The method is validated on a quadruped robot, demonstrating robust locomotion with reduced oscillations, longer stance and swing phases across various terrains.

</details>


### [263] [USV Obstacles Detection and Tracking in Marine Environments](https://arxiv.org/abs/2511.07950)
*Yara AlaaEldin,Enrico Simetti,Francesca Odone*

Main category: cs.RO

TL;DR: 本文评估并改进了用于无人水面艇（USV）的障碍物检测与跟踪系统。通过在ROS平台上集成并测试，比较了传感器融合与仅LiDAR两种方法，并提出了一种结合两者优点的混合方法，以构建信息丰富的障碍物地图。


<details>
  <summary>Details</summary>
Motivation: 在海洋环境中为无人水面艇（USV）开发一个鲁棒有效的障碍物检测和跟踪系统是一项具有挑战性的任务。过去的研究已提出一种方法，而本文旨在在此基础上继续并进行性能评估、系统集成及方法改进。

Method: 首先，在最新发布的海洋数据集上评估现有系统性能。其次，将系统模块集成到ROS平台，并使用MIT海洋数据集中的同步LiDAR和相机数据进行实时测试。然后，通过实验分析比较了两种方法：一种使用相机和LiDAR的传感器融合，另一种仅使用LiDAR点云进行检测和跟踪。最后，提出了一种结合两种方法优点的混合方法。

Result: 本文对使用传感器融合和仅LiDAR两种方法获得的结果进行了详尽的实验分析。最终提出了一种混合方法，旨在融合两种方法的优点，为USV构建一个信息丰富的周围环境障碍物地图。

Conclusion: 研究提出了一种混合方法，该方法结合了传感器融合和仅LiDAR两种障碍物检测与跟踪方法的优点，能够为无人水面艇构建一个更全面的环境障碍物地图。

Abstract: Developing a robust and effective obstacle detection and tracking system for Unmanned Surface Vehicle (USV) at marine environments is a challenging task. Research efforts have been made in this area during the past years by GRAAL lab at the university of Genova that resulted in a methodology for detecting and tracking obstacles on the image plane and, then, locating them in the 3D LiDAR point cloud. In this work, we continue on the developed system by, firstly, evaluating its performance on recently published marine datasets. Then, we integrate the different blocks of the system on ROS platform where we could test it in real-time on synchronized LiDAR and camera data collected in various marine conditions available in the MIT marine datasets. We present a thorough experimental analysis of the results obtained using two approaches; one that uses sensor fusion between the camera and LiDAR to detect and track the obstacles and the other uses only the LiDAR point cloud for the detection and tracking. In the end, we propose a hybrid approach that merges the advantages of both approaches to build an informative obstacles map of the surrounding environment to the USV.

</details>


### [264] [Local Path Planning with Dynamic Obstacle Avoidance in Unstructured Environments](https://arxiv.org/abs/2511.07927)
*Okan Arif Guvenkaya,Selim Ahmet Iz,Mustafa Unel*

Main category: cs.RO

TL;DR: 本文提出一种结合切线路径规划和外推法的新型决策算法，用于无人地面车辆（UGV）在动态障碍密集环境中进行局部路径规划和避障。


<details>
  <summary>Details</summary>
Motivation: 在动态障碍密集的复杂环境中，无人地面车辆（UGV）的避障和路径规划至关重要。研究旨在开发一种有效的局部路径规划算法，使UGV能在给定全局路径和路点的情况下，安全地避开动态障碍物。

Method: 该方法结合了基于切线的路径规划和外推法，形成一种新的决策算法。UGV预先知道起点和目标点，并已计算出全局路径和路点。算法旨在当UGV在路点间移动时，避免与遵循多项式轨迹的动态障碍物发生碰撞。障碍物的初始位置、速度（0到UGV最大物理速度）和加速度都是随机的。该算法在多个动态障碍物随机移动的场景中进行了仿真测试。

Result: 仿真结果表明，所提出的局部路径规划策略是有效的，它能逐步生成无碰撞路径，使机器人能够在初始位置和目标位置之间安全导航。

Conclusion: 该研究开发了一种有效的局部路径规划策略，通过结合切线路径规划和外推法，使无人地面车辆能够安全地在充满动态障碍物的环境中导航，成功避开碰撞并到达目标。

Abstract: Obstacle avoidance and path planning are essential for guiding unmanned ground vehicles (UGVs) through environments that are densely populated with dynamic obstacles. This paper develops a novel approach that combines tangentbased path planning and extrapolation methods to create a new decision-making algorithm for local path planning. In the assumed scenario, a UGV has a prior knowledge of its initial and target points within the dynamic environment. A global path has already been computed, and the robot is provided with waypoints along this path. As the UGV travels between these waypoints, the algorithm aims to avoid collisions with dynamic obstacles. These obstacles follow polynomial trajectories, with their initial positions randomized in the local map and velocities randomized between O and the allowable physical velocity limit of the robot, along with some random accelerations. The developed algorithm is tested in several scenarios where many dynamic obstacles move randomly in the environment. Simulation results show the effectiveness of the proposed local path planning strategy by gradually generating a collision free path which allows the robot to navigate safely between initial and the target locations.

</details>


### [265] [Effective Game-Theoretic Motion Planning via Nested Search](https://arxiv.org/abs/2511.08001)
*Avishav Engle,Andrey Zhitnikov,Oren Salzman,Omer Ben-Porat,Kiril Solovey*

Main category: cs.RO

TL;DR: 本文提出了一种新颖、可扩展且可证明正确的方法——博弈论嵌套搜索（GTNS），用于在通用动力系统中计算纳什均衡（NE），以解决现有方法在多智能体交互推理中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多智能体交互推理中存在局限：基于优化的方法需要简化机器人动力学且易陷入局部最优；基于支付矩阵的方法因轨迹枚举而可扩展性差。这些限制阻碍了博弈论在真实世界机器人部署中的充分应用。

Method: GTNS通过嵌套搜索高效探索所有智能体的动作空间，并通过内层搜索在低维空间中排除违反纳什均衡约束（无单方面偏离）的轨迹。该算法还允许用户通过指定全局目标来显式选择均衡。

Result: GTNS在各种自动驾驶和赛车场景中得到了验证，能够在普通硬件上于数秒内获得解决方案，展示了其高效性。

Conclusion: GTNS是一种新颖、可扩展且可证明正确的方法，能够计算通用动力系统中的纳什均衡，克服了现有方法的局限性，并能通过用户指定的目标选择均衡，从而实现丰富的、真实的智能体交互推理。

Abstract: To facilitate effective, safe deployment in the real world, individual robots must reason about interactions with other agents, which often occur without explicit communication. Recent work has identified game theory, particularly the concept of Nash Equilibrium (NE), as a key enabler for behavior-aware decision-making. Yet, existing work falls short of fully unleashing the power of game-theoretic reasoning. Specifically, popular optimization-based methods require simplified robot dynamics and tend to get trapped in local minima due to convexification. Other works that rely on payoff matrices suffer from poor scalability due to the explicit enumeration of all possible trajectories. To bridge this gap, we introduce Game-Theoretic Nested Search (GTNS), a novel, scalable, and provably correct approach for computing NEs in general dynamical systems. GTNS efficiently searches the action space of all agents involved, while discarding trajectories that violate the NE constraint (no unilateral deviation) through an inner search over a lower-dimensional space. Our algorithm enables explicit selection among equilibria by utilizing a user-specified global objective, thereby capturing a rich set of realistic interactions. We demonstrate the approach on a variety of autonomous driving and racing scenarios where we achieve solutions in mere seconds on commodity hardware.

</details>


### [266] [A Two-Layer Electrostatic Film Actuator with High Actuation Stress and Integrated Brake](https://arxiv.org/abs/2511.08005)
*Huacen Wang,Hongqiang Wang*

Main category: cs.RO

TL;DR: 本文提出了一种双层静电薄膜执行器，集成了制动功能，通过优化电极分布，显著提高了驱动应力（241 N/m²，提升90.5%），并实现了负载保持能力，适用于轻量化和紧凑型机器人。


<details>
  <summary>Details</summary>
Motivation: 传统的电机驱动机器人存在质量大、控制复杂、需要额外制动等问题，限制了其在轻量化和紧凑型平台上的应用。静电薄膜执行器虽然具有薄、柔、轻和开环定位精度高等优点，但现有空气中执行器的驱动应力（特别是三相电极设计）仍需改进。

Method: 本文提出了一种双层静电薄膜执行器，其特点是集成了制动功能。通过在顶层和底层交替分布电极，在相同的制造限制下实现了更小的有效电极间距，从而提高了输出性能。同时，其集成的静电吸附机制实现了制动模式下的负载保持。

Result: 该执行器实现了约241 N/m²的驱动应力，比之前在空气中运行的三相执行器提高了90.5%。其集成的静电吸附机制能够在制动模式下保持负载。通过拔河、有效载荷操作、单自由度机械臂和双模式夹具等演示，验证了该执行器在驱动和制动模式下的优越性能。

Conclusion: 所提出的双层静电薄膜执行器在驱动和制动模式下都展现出显著优势，克服了传统电机和现有静电执行器的局限性，特别适用于轻量化和紧凑型机器人平台。

Abstract: Robotic systems driven by conventional motors often suffer from challenges such as large mass, complex control algorithms, and the need for additional braking mechanisms, which limit their applications in lightweight and compact robotic platforms. Electrostatic film actuators offer several advantages, including thinness, flexibility, lightweight construction, and high open-loop positioning accuracy. However, the actuation stress exhibited by conventional actuators in air still needs improvement, particularly for the widely used three-phase electrode design. To enhance the output performance of actuators, this paper presents a two-layer electrostatic film actuator with an integrated brake. By alternately distributing electrodes on both the top and bottom layers, a smaller effective electrode pitch is achieved under the same fabrication constraints, resulting in an actuation stress of approximately 241~N/m$^2$, representing a 90.5\% improvement over previous three-phase actuators operating in air. Furthermore, its integrated electrostatic adhesion mechanism enables load retention under braking mode. Several demonstrations, including a tug-of-war between a conventional single-layer actuator and the proposed two-layer actuator, a payload operation, a one-degree-of-freedom robotic arm, and a dual-mode gripper, were conducted to validate the actuator's advantageous capabilities in both actuation and braking modes.

</details>


### [267] [AVOID-JACK: Avoidance of Jackknifing for Swarms of Long Heavy Articulated Vehicles](https://arxiv.org/abs/2511.08016)
*Adrian Schönnagel,Michael Dubé,Christoph Steup,Felix Keppler,Sanaz Mostaghim*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的去中心化蜂群智能方法，用于避免重型铰接车辆（HAVs）的折叠和相互碰撞，并在模拟中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 重型铰接车辆（HAVs）具有复杂的运动学特性和细长体型，在物流、采矿等实际应用中具有重要意义。然而，现有文献尚未解决这类车辆在蜂群智能控制下避免折叠和相互碰撞的问题。

Method: 本文提出了一种纯粹基于反应的去中心化蜂群智能策略，专门为细长、铰接式车辆设计。该方法优先避免折叠（jackknifing），并在此基础上实现相互碰撞避免。

Result: 通过广泛的模拟实验验证了该方法。对于单个HAV，成功避免折叠的比例为99.8%，分别有86.7%和83.4%的车辆到达第一和第二目标。对于两个HAV相互作用的情况，避免折叠的比例为98.9%，分别有79.4%和65.1%的车辆到达第一和第二目标，同时99.7%的HAVs没有发生相互碰撞。

Conclusion: 所提出的去中心化蜂群智能策略能有效避免重型铰接车辆的折叠和相互碰撞，为解决这类新型蜂群机器人问题奠定了基础。

Abstract: This paper presents a novel approach to avoiding jackknifing and mutual collisions in Heavy Articulated Vehicles (HAVs) by leveraging decentralized swarm intelligence. In contrast to typical swarm robotics research, our robots are elongated and exhibit complex kinematics, introducing unique challenges. Despite its relevance to real-world applications such as logistics automation, remote mining, airport baggage transport, and agricultural operations, this problem has not been addressed in the existing literature.
  To tackle this new class of swarm robotics problems, we propose a purely reaction-based, decentralized swarm intelligence strategy tailored to automate elongated, articulated vehicles. The method presented in this paper prioritizes jackknifing avoidance and establishes a foundation for mutual collision avoidance. We validate our approach through extensive simulation experiments and provide a comprehensive analysis of its performance. For the experiments with a single HAV, we observe that for 99.8% jackknifing was successfully avoided and that 86.7% and 83.4% reach their first and second goals, respectively. With two HAVs interacting, we observe 98.9%, 79.4%, and 65.1%, respectively, while 99.7% of the HAVs do not experience mutual collisions.

</details>


### [268] [Model Predictive Control via Probabilistic Inference: A Tutorial](https://arxiv.org/abs/2511.08019)
*Kohei Honda*

Main category: cs.RO

TL;DR: 本文是关于基于概率推理的模型预测控制（MPC）的教程，它将最优控制重新解释为概率推理问题，通过采样技术处理机器人中常见的非线性或不可微分系统，并详细介绍了MPPI等方法。


<details>
  <summary>Details</summary>
Motivation: 传统的数值优化方法在处理机器人中常见的非线性或不可微分系统时，对于模型预测控制（MPC）而言往往变得难以处理。

Method: 将最优控制问题重新解释为概率推理问题，从标准最优控制问题推导出最优控制分布，并采用基于采样的方法（如MPPI）来估计最优控制分布。文章还讨论了先验和变分分布设计、调优原则和理论方面。

Result: 文章提供了一个统一的理论基础和代表性方法的全面概述，并以MPPI算法为例进行实际推导，展示了这些方法如何适应任意成本函数和动力学，无需依赖基于梯度的优化。

Conclusion: 本文旨在为研究人员和实践者提供一个系统的指南，以理解、实现和扩展基于概率推理的MPC方法在机器人及其他领域的应用。

Abstract: Model Predictive Control (MPC) is a fundamental framework for optimizing robot behavior over a finite future horizon. While conventional numerical optimization methods can efficiently handle simple dynamics and cost structures, they often become intractable for the nonlinear or non-differentiable systems commonly encountered in robotics. This article provides a tutorial on probabilistic inference-based MPC, presenting a unified theoretical foundation and a comprehensive overview of representative methods. Probabilistic inference-based MPC approaches, such as Model Predictive Path Integral (MPPI) control, have gained significant attention by reinterpreting optimal control as a problem of probabilistic inference. Rather than relying on gradient-based numerical optimization, these methods estimate optimal control distributions through sampling-based techniques, accommodating arbitrary cost functions and dynamics. We first derive the optimal control distribution from the standard optimal control problem, elucidating its probabilistic interpretation and key characteristics. The widely used MPPI algorithm is then derived as a practical example, followed by discussions on prior and variational distribution design, tuning principles, and theoretical aspects. This article aims to serve as a systematic guide for researchers and practitioners seeking to understand, implement, and extend these methods in robotics and beyond.

</details>


### [269] [PerspAct: Enhancing LLM Situated Collaboration Skills through Perspective Taking and Active Vision](https://arxiv.org/abs/2511.08098)
*Sabrina Patania,Luca Annese,Anita Pellegrini,Silvia Serino,Anna Lambiase,Luca Pallonetto,Silvia Rossi,Simone Colombani,Tom Foulsham,Azzurra Ruggeri,Dimitri Ognibene*

Main category: cs.RO

TL;DR: 本研究通过结合ReAct框架和主动视觉探索，显著提升了大型语言模型在多智能体交互中理解和采纳不同视点的能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）和多模态基础模型在机器人和协作系统中的应用，受限于其缺乏强大的视角采纳能力，难以解释物理和认知视点，尤其是在多智能体交互和处理主观视角时面临挑战。

Method: 研究评估了通过ReAct框架（整合推理和行动）显式地结合多样视点，是否能增强LLM理解并采纳其他智能体需求的能力。方法包括：扩展经典的Director任务，引入主动视觉探索，设计了七个复杂性递增的场景，并测试了不同状态表示和提示策略（包括ReAct风格推理）。

Result: 结果表明，明确的视角提示与主动探索策略相结合，显著提高了模型的解释准确性和协作效率。

Conclusion: 这些发现强调了将主动感知与视角采纳机制整合的潜力，以推动LLM在机器人和多智能体系统中的应用，并为未来研究自适应和上下文感知AI系统奠定了基础。

Abstract: Recent advances in Large Language Models (LLMs) and multimodal foundation models have significantly broadened their application in robotics and collaborative systems. However, effective multi-agent interaction necessitates robust perspective-taking capabilities, enabling models to interpret both physical and epistemic viewpoints. Current training paradigms often neglect these interactive contexts, resulting in challenges when models must reason about the subjectivity of individual perspectives or navigate environments with multiple observers. This study evaluates whether explicitly incorporating diverse points of view using the ReAct framework, an approach that integrates reasoning and acting, can enhance an LLM's ability to understand and ground the demands of other agents. We extend the classic Director task by introducing active visual exploration across a suite of seven scenarios of increasing perspective-taking complexity. These scenarios are designed to challenge the agent's capacity to resolve referential ambiguity based on visual access and interaction, under varying state representations and prompting strategies, including ReAct-style reasoning. Our results demonstrate that explicit perspective cues, combined with active exploration strategies, significantly improve the model's interpretative accuracy and collaborative effectiveness. These findings highlight the potential of integrating active perception with perspective-taking mechanisms in advancing LLMs' application in robotics and multi-agent systems, setting a foundation for future research into adaptive and context-aware AI systems.

</details>


### [270] [Prioritizing Perception-Guided Self-Supervision: A New Paradigm for Causal Modeling in End-to-End Autonomous Driving](https://arxiv.org/abs/2511.08214)
*Yi Huang,Zhan Qu,Lihui Jiang,Bingbing Liu,Hongbo Zhang*

Main category: cs.RO

TL;DR: 为解决模仿学习在端到端自动驾驶中因专家轨迹噪声导致的因果混淆问题，本文提出感知引导自监督（PGS）范式。PGS利用感知输出作为主要监督信号，显式建模决策中的因果关系，显著提升了系统在闭环场景下的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶系统在开环评估中表现良好，但在闭环场景中因因果混淆而性能显著下降。这主要是由于模仿学习过度依赖包含不可归因噪声的专家轨迹，干扰了环境上下文与驾驶动作之间因果关系的建模。

Method: 本文提出了感知引导自监督（PGS）训练范式。该方法将感知输出（如车道中心线、周围智能体的预测运动）作为主要的监督信号，显式地建模决策中的因果关系。通过对自我轨迹引入正负自监督，使决策模块的输入和输出与感知结果对齐，以减轻专家轨迹固有噪声引起的因果混淆。

Result: 在具有挑战性的闭环Bench2Drive基准测试中，基于标准端到端架构的PGS方法取得了78.08的驾驶分数和48.64%的平均成功率。这些结果显著优于现有最先进的方法，包括那些采用更复杂网络架构和推理流程的方法。

Conclusion: 所提出的PGS框架有效且鲁棒，为解决自动驾驶中的因果混淆问题和增强实际泛化能力指明了一个有前景的方向。

Abstract: End-to-end autonomous driving systems, predominantly trained through imitation learning, have demonstrated considerable effectiveness in leveraging large-scale expert driving data. Despite their success in open-loop evaluations, these systems often exhibit significant performance degradation in closed-loop scenarios due to causal confusion. This confusion is fundamentally exacerbated by the overreliance of the imitation learning paradigm on expert trajectories, which often contain unattributable noise and interfere with the modeling of causal relationships between environmental contexts and appropriate driving actions.
  To address this fundamental limitation, we propose Perception-Guided Self-Supervision (PGS) - a simple yet effective training paradigm that leverages perception outputs as the primary supervisory signals, explicitly modeling causal relationships in decision-making. The proposed framework aligns both the inputs and outputs of the decision-making module with perception results, such as lane centerlines and the predicted motions of surrounding agents, by introducing positive and negative self-supervision for the ego trajectory. This alignment is specifically designed to mitigate causal confusion arising from the inherent noise in expert trajectories.
  Equipped with perception-driven supervision, our method, built on a standard end-to-end architecture, achieves a Driving Score of 78.08 and a mean success rate of 48.64% on the challenging closed-loop Bench2Drive benchmark, significantly outperforming existing state-of-the-art methods, including those employing more complex network architectures and inference pipelines. These results underscore the effectiveness and robustness of the proposed PGS framework and point to a promising direction for addressing causal confusion and enhancing real-world generalization in autonomous driving.

</details>


### [271] [Real-Time Performance Analysis of Multi-Fidelity Residual Physics-Informed Neural Process-Based State Estimation for Robotic Systems](https://arxiv.org/abs/2511.08231)
*Devin Hunter,Chinwendu Enyioha*

Main category: cs.RO

TL;DR: 本文提出了一种基于多保真残差物理信息神经过程（MFR-PINP）的实时数据驱动估计方法，用于机器人系统的状态估计，并通过分离共形预测框架提供不确定性保证，表现优于传统卡尔曼滤波器变体。


<details>
  <summary>Details</summary>
Motivation: 在实时非线性状态估计中，数据驱动模型（特别是神经网络）的应用日益增多，但对于安全关键应用，需要提供可靠的误差范围。同时，精确运动学模型的选择存在模型不匹配问题。

Method: 研究提出了一种新颖的实时数据驱动估计方法：多保真残差物理信息神经过程（MFR-PINP）。该方法通过让MFR-PINP学习简单低保真预测与复杂高保真真实动力学之间的残差来解决模型不匹配问题。为处理物理实现中的模型不确定性，在训练和推理范式中建模了分离共形（SC）预测框架的鲁棒不确定性保证。模型在一个混合在线学习环境中实现。

Result: MFR-PINP-based估计器在机器人系统实时估计场景中的实验结果显示出良好的性能，优于最先进的卡尔曼滤波器变体（如无迹卡尔曼滤波器和深度卡尔曼滤波器）。

Conclusion: MFR-PINP模型在实时估计任务中是一个可行的选择，能够提供可靠的不确定性保证并解决模型不匹配问题，其性能优于现有技术。

Abstract: Various neural network architectures are used in many of the state-of-the-art approaches for real-time nonlinear state estimation. With the ever-increasing incorporation of these data-driven models into the estimation domain, model predictions with reliable margins of error are a requirement -- especially for safety-critical applications. This paper discusses the application of a novel real-time, data-driven estimation approach based on the multi-fidelity residual physics-informed neural process (MFR-PINP) toward the real-time state estimation of a robotic system. Specifically, we address the model-mismatch issue of selecting an accurate kinematic model by tasking the MFR-PINP to also learn the residuals between simple, low-fidelity predictions and complex, high-fidelity ground-truth dynamics. To account for model uncertainty present in a physical implementation, robust uncertainty guarantees from the split conformal (SC) prediction framework are modeled in the training and inference paradigms. We provide implementation details of our MFR-PINP-based estimator for a hybrid online learning setting to validate our model's usage in real-time applications. Experimental results of our approach's performance in comparison to the state-of-the-art variants of the Kalman filter (i.e. unscented Kalman filter and deep Kalman filter) in estimation scenarios showed promising results for the MFR-PINP model as a viable option in real-time estimation tasks.

</details>


### [272] [X-IONet: Cross-Platform Inertial Odometry Network with Dual-Stage Attention](https://arxiv.org/abs/2511.08277)
*Dehan Shen,Changhao Chen*

Main category: cs.RO

TL;DR: X-IONet是一个跨平台惯性里程计框架，仅使用单个IMU，通过专家选择和双阶段注意力网络，实现了在行人和四足机器人上最先进的精确和鲁棒导航。


<details>
  <summary>Details</summary>
Motivation: 基于学习的惯性里程计在行人导航方面取得了显著进展，但由于四足机器人独特且高度动态的运动模式，现有方法在这些平台上部署时性能会严重下降，因此需要一个能同时处理行人和四足机器人运动的通用解决方案。

Method: X-IONet框架仅使用单个IMU。它包含一个基于规则的专家选择模块，用于分类运动平台并将IMU序列路由到特定于平台的专家网络。位移预测网络采用双阶段注意力架构，联合建模长程时间依赖性和轴间相关性。它输出位移和相关不确定性，这些数据通过扩展卡尔曼滤波器（EKF）进行融合，以实现鲁棒的状态估计。

Result: X-IONet在行人数据上将绝对轨迹误差（ATE）降低了14.3%，相对轨迹误差（RTE）降低了11.4%；在四足机器人数据上将ATE降低了52.8%，RTE降低了41.3%，达到了最先进的性能。

Conclusion: X-IONet在推进人类和足式机器人平台上的精确和鲁棒惯性导航方面表现出显著的有效性。

Abstract: Learning-based inertial odometry has achieved remarkable progress in pedestrian navigation. However, extending these methods to quadruped robots remains challenging due to their distinct and highly dynamic motion patterns. Models that perform well on pedestrian data often experience severe degradation when deployed on legged platforms. To tackle this challenge, we introduce X-IONet, a cross-platform inertial odometry framework that operates solely using a single Inertial Measurement Unit (IMU). X-IONet incorporates a rule-based expert selection module to classify motion platforms and route IMU sequences to platform-specific expert networks. The displacement prediction network features a dual-stage attention architecture that jointly models long-range temporal dependencies and inter-axis correlations, enabling accurate motion representation. It outputs both displacement and associated uncertainty, which are further fused through an Extended Kalman Filter (EKF) for robust state estimation. Extensive experiments on public pedestrian datasets and a self-collected quadruped robot dataset demonstrate that X-IONet achieves state-of-the-art performance, reducing Absolute Trajectory Error (ATE) by 14.3% and Relative Trajectory Error (RTE) by 11.4% on pedestrian data, and by 52.8% and 41.3% on quadruped robot data. These results highlight the effectiveness of X-IONet in advancing accurate and robust inertial navigation across both human and legged robot platforms.

</details>


### [273] [Learning Omnidirectional Locomotion for a Salamander-Like Quadruped Robot](https://arxiv.org/abs/2511.08299)
*Zhiang Liu,Yang Liu,Yongchun Fang,Xian Guo*

Main category: cs.RO

TL;DR: 本文提出了一种学习框架，使类蝾螈四足机器人无需参考动作即可学习多样化的全向步态，通过相位变量控制和形态对称数据增强，成功获得了22种动态且对称的步态。


<details>
  <summary>Details</summary>
Motivation: 现有控制器未能充分利用类蝾螈机器人的形态特征，且过度依赖预定义步态或关节轨迹，限制了其生成多样化灵活运动的能力及其在实际场景中的应用。

Method: 研究提出一个学习框架：每个身体部位由可前后演进的相位变量控制；引入相位覆盖奖励以促进腿部相位空间的探索；通过数据增强融入机器人的形态对称性，提高样本效率并确保学习行为在运动和任务层面都具有对称性。

Result: 实验结果表明，机器人成功学习了22种全向步态，这些步态表现出动态且对称的运动。

Conclusion: 所提出的学习框架有效，能使机器人获取多样化的全向步态。

Abstract: Salamander-like quadruped robots are designed inspired by the skeletal structure of their biological counterparts. However, existing controllers cannot fully exploit these morphological features and largely rely on predefined gait patterns or joint trajectories, which prevents the generation of diverse and flexible locomotion and limits their applicability in real-world scenarios. In this paper, we propose a learning framework that enables the robot to acquire a diverse repertoire of omnidirectional gaits without reference motions. Each body part is controlled by a phase variable capable of forward and backward evolution, with a phase coverage reward to promote the exploration of the leg phase space. Additionally, morphological symmetry of the robot is incorporated via data augmentation, improving sample efficiency and enforcing both motion-level and task-level symmetry in learned behaviors. Extensive experiments show that the robot successfully acquires 22 omnidirectional gaits exhibiting both dynamic and symmetric movements, demonstrating the effectiveness of the proposed learning framework.

</details>


### [274] [Safe and Optimal Learning from Preferences via Weighted Temporal Logic with Applications in Robotics and Formula 1](https://arxiv.org/abs/2511.08502)
*Ruya Karagulle,Cristian-Ioan Vasile,Necmiye Ozay*

Main category: cs.RO

TL;DR: 本文提出了一种基于加权信号时序逻辑（WSTL）的学习方法，通过结构剪枝和对数变换将问题转化为混合整数线性规划（MILP），从而在从人类偏好、排名或演示中学习时，实现安全保障、最优和高效。


<details>
  <summary>Details</summary>
Motivation: 自主系统日益依赖人类反馈来调整行为，但现有方法在安全关键领域往往无法保证安全性，这是本研究的出发点。

Method: 该方法提出使用加权信号时序逻辑（WSTL）解决从偏好、排名或演示中学习的问题。针对WSTL学习中出现的权重多线性约束问题，通过引入结构剪枝和对数变换程序，将问题规模缩小并重构为混合整数线性规划（MILP），同时保留了安全保证。

Result: 在机器人导航和真实F1数据的实验中，该方法有效捕捉了细微的偏好并建模了复杂的任务目标。

Conclusion: 所提出的方法为从人类反馈中学习提供了一种安全保障、最优且高效的解决方案，特别适用于需要严格安全保证的自主系统。

Abstract: Autonomous systems increasingly rely on human feedback to align their behavior, expressed as pairwise comparisons, rankings, or demonstrations. While existing methods can adapt behaviors, they often fail to guarantee safety in safety-critical domains. We propose a safety-guaranteed, optimal, and efficient approach to solve the learning problem from preferences, rankings, or demonstrations using Weighted Signal Temporal Logic (WSTL). WSTL learning problems, when implemented naively, lead to multi-linear constraints in the weights to be learned. By introducing structural pruning and log-transform procedures, we reduce the problem size and recast the problem as a Mixed-Integer Linear Program while preserving safety guarantees. Experiments on robotic navigation and real-world Formula 1 data demonstrate that the method effectively captures nuanced preferences and models complex task objectives.

</details>


### [275] [A CODECO Case Study and Initial Validation for Edge Orchestration of Autonomous Mobile Robots](https://arxiv.org/abs/2511.08354)
*H. Zhu,T. Samizadeh,R. C. Sofia*

Main category: cs.RO

TL;DR: 本文比较了CODECO与标准Kubernetes在智能制造AMR场景下的性能，发现在移动、资源受限环境中，CODECO能降低CPU消耗并提供更稳定的通信，但存在内存开销和启动延迟。


<details>
  <summary>Details</summary>
Motivation: Kubernetes作为容器编排的事实标准，其稳定网络、同质资源和充足计算能力的假设在移动、资源受限的机器人环境中并不完全适用，因此需要探索更适合AMR的编排方案。

Method: 通过对智能制造AMR进行案例研究，并在受控的KinD环境中，对CODECO编排与标准Kubernetes进行初步比较。衡量指标包括Pod部署和删除时间、CPU和内存使用情况以及Pod间数据传输速率。

Result: 观察结果表明，CODECO降低了CPU消耗并提供了更稳定的通信模式。然而，其代价是适度的内存开销（10-15%）以及由于安全覆盖初始化导致Pod生命周期延迟略有增加。

Conclusion: CODECO在移动、资源受限的AMR环境中展现出降低CPU消耗和稳定通信的潜力，尽管伴随着一定的内存开销和启动延迟。这表明CODECO可能是Kubernetes在特定机器人场景下的一种有效替代或补充方案。

Abstract: Autonomous Mobile Robots (AMRs) increasingly adopt containerized micro-services across the Edge-Cloud continuum. While Kubernetes is the de-facto orchestrator for such systems, its assumptions of stable networks, homogeneous resources, and ample compute capacity do not fully hold in mobile, resource-constrained robotic environments.
  This paper describes a case study on smart-manufacturing AMRs and performs an initial comparison between CODECO orchestration and standard Kubernetes using a controlled KinD environment. Metrics include pod deployment and deletion times, CPU and memory usage, and inter-pod data rates. The observed results indicate that CODECO offers reduced CPU consumption and more stable communication patterns, at the cost of modest memory overhead (10-15%) and slightly increased pod lifecycle latency due to secure overlay initialization.

</details>


### [276] [Human Motion Intent Inferencing in Teleoperation Through a SINDy Paradigm](https://arxiv.org/abs/2511.08377)
*Michael Bowman,Xiaoli Zhang*

Main category: cs.RO

TL;DR: 该研究提出了一个名为Psychic的框架，通过跳跃-漂移-扩散随机微分方程和Kramers-Moyal系数来检测操作员轨迹中的突然跳跃，从而进行意图推断。它能够早期检测现有目标并发现未定义目标，并利用SINDy模型推断操作员运动行为。


<details>
  <summary>Details</summary>
Motivation: 当前的遥操作意图推断方法往往忽略了指示意图突然变化的细微运动。研究旨在解决如何检测操作员轨迹中的突然跳跃、如何利用这些跳跃推断操作员目标状态，以及如何整合不连续和连续动力学来推断操作员运动。

Method: 该框架名为Psychic，采用跳跃-漂移-扩散随机微分方程（SDE）来建模不连续和连续动力学。通过Kramers-Moyal（KM）系数结合统计异常值检测算法来检测轨迹中的跳跃，从而识别目标转换。随后，框架应用稀疏非线性动力学识别（SINDy）模型，利用KM系数并将目标转换作为控制输入，以推断非结构化场景中的操作员运动行为。研究通过生成概率可达集，并与负对数似然模型进行比较，对600条操作员轨迹进行了回顾性研究。

Result: Psychic框架能够生成概率可达集，并优于负对数似然模型。它在离线和在线学习中均表现出有效性，实现了对现有目标的早期检测，并能够在非结构化场景中发现未定义的目标。

Conclusion: Psychic框架通过有效建模操作员轨迹中的细微（跳跃）运动，显著提升了遥操作中的意图推断能力。它能够早期、准确地识别操作员目标，包括未定义的目标，并预测其运动行为，从而更好地协调人机协作。

Abstract: Intent inferencing in teleoperation has been instrumental in aligning operator goals and coordinating actions with robotic partners. However, current intent inference methods often ignore subtle motion that can be strong indicators for a sudden change in intent. Specifically, we aim to tackle 1) if we can detect sudden jumps in operator trajectories, 2) how we appropriately use these sudden jump motions to infer an operator's goal state, and 3) how to incorporate these discontinuous and continuous dynamics to infer operator motion. Our framework, called Psychic, models these small indicative motions through a jump-drift-diffusion stochastic differential equation to cover discontinuous and continuous dynamics. Kramers-Moyal (KM) coefficients allow us to detect jumps with a trajectory which we pair with a statistical outlier detection algorithm to nominate goal transitions. Through identifying jumps, we can perform early detection of existing goals and discover undefined goals in unstructured scenarios. Our framework then applies a Sparse Identification of Nonlinear Dynamics (SINDy) model using KM coefficients with the goal transitions as a control input to infer an operator's motion behavior in unstructured scenarios. We demonstrate Psychic can produce probabilistic reachability sets and compare our strategy to a negative log-likelihood model fit. We perform a retrospective study on 600 operator trajectories in a hands-free teleoperation task to evaluate the efficacy of our opensource package, Psychic, in both offline and online learning.

</details>


### [277] [Intuitive control of supernumerary robotic limbs through a tactile-encoded neural interface](https://arxiv.org/abs/2511.08454)
*Tianyu Jia,Xingchen Yang,Ciaran McGeady,Yifeng Li,Jinzhi Lin,Kit San Ho,Feiyu Pan,Linhong Ji,Chong Li,Dario Farina*

Main category: cs.RO

TL;DR: 本文提出了一种触觉编码的脑机接口（BCI），利用触觉诱发的P300范式，即使在叠加自主动作的情况下，也能直观可靠地解码超额外运动意图，从而在不影响自然运动的情况下扩展运动自由度。


<details>
  <summary>Details</summary>
Motivation: 脑机接口有望通过直接神经控制超额外效应器来扩展人类运动能力，但如何在不干扰自然运动的情况下整合具有多自由度的增强指令，仍然是一个关键挑战。

Method: 研究提出了一种利用触觉传入神经的触觉编码BCI，采用新颖的触觉诱发P300范式。通过多日实验进行评估，包括单一运动识别任务以验证BCI基线性能，以及双任务范式以评估BCI与自然人体运动之间的潜在影响。最后，该接口被部署在一个运动增强任务中，用于控制两个超额外机械臂进行双边任务的功能辅助。

Result: 该脑接口实现了四自由度超额外运动的实时可靠解码，仅经过三天训练后性能显著提升。重要的是，训练后，单一和双BCI任务条件下的性能没有显著差异，且在同时进行超额外控制时，自然运动未受损。该接口成功用于控制机械臂进行运动增强任务。

Conclusion: 这些结果建立了一种通过刺激感觉传入神经实现运动增强的新型神经接口范式，在不损害自然运动的情况下扩展了运动自由度。

Abstract: Brain-computer interfaces (BCIs) promise to extend human movement capabilities by enabling direct neural control of supernumerary effectors, yet integrating augmented commands with multiple degrees of freedom without disrupting natural movement remains a key challenge. Here, we propose a tactile-encoded BCI that leverages sensory afferents through a novel tactile-evoked P300 paradigm, allowing intuitive and reliable decoding of supernumerary motor intentions even when superimposed with voluntary actions. The interface was evaluated in a multi-day experiment comprising of a single motor recognition task to validate baseline BCI performance and a dual task paradigm to assess the potential influence between the BCI and natural human movement. The brain interface achieved real-time and reliable decoding of four supernumerary degrees of freedom, with significant performance improvements after only three days of training. Importantly, after training, performance did not differ significantly between the single- and dual-BCI task conditions, and natural movement remained unimpaired during concurrent supernumerary control. Lastly, the interface was deployed in a movement augmentation task, demonstrating its ability to command two supernumerary robotic arms for functional assistance during bimanual tasks. These results establish a new neural interface paradigm for movement augmentation through stimulation of sensory afferents, expanding motor degrees of freedom without impairing natural movement.

</details>


### [278] [A Supervised Autonomous Resection and Retraction Framework for Transurethral Enucleation of the Prostatic Median Lobe](https://arxiv.org/abs/2511.08490)
*Mariana Smith,Tanner Watts,Susheela Sharma Stern,Brendan Burkhart,Hao Li,Alejandro O. Chara,Nithesh Kumar,James Ferguson,Ayberk Acar,Jesse F. d'Almeida,Lauren Branscombe,Lauren Shepard,Ahmed Ghazi,Ipek Oguz,Jie Ying Wu,Robert J. Webster,Axel Krieger,Alan Kuntz*

Main category: cs.RO

TL;DR: 本文提出了一种结合模型规划器和学习式牵引网络的半自主系统，用于双臂同心管机器人在前列腺模型上的组织切除，实现了97.1%的目标切除率。


<details>
  <summary>Details</summary>
Motivation: 同心管机器人能在毫米尺度提供灵巧运动，实现经自然腔道微创手术。本研究旨在利用其优势，开发半自主系统进行组织切除，特别是针对前列腺手术。

Method: 研究采用双臂经尿道同心管机器人（Virtuoso），结合了模型规划器和学习式牵引网络。切除规划器基于CT分割体积，自动生成前列腺中叶切除的三阶段（左/中槽、右/中槽切除和中叶钝性分离）工具轨迹。牵引网络PushCVAE通过外科医生演示进行训练，根据手术阶段生成牵引动作。该系统在前列腺水凝胶模型上以三级（监督）自主性执行手术。

Result: 可行性研究表明，该组合自主系统实现了对目标中叶体积97.1%的切除率。

Conclusion: 本研究为经尿道机器人手术中的影像引导自主性奠定了基础，并代表了实现全自动化微创前列腺摘除的第一步。

Abstract: Concentric tube robots (CTRs) offer dexterous motion at millimeter scales, enabling minimally invasive procedures through natural orifices. This work presents a coordinated model-based resection planner and learning-based retraction network that work together to enable semi-autonomous tissue resection using a dual-arm transurethral concentric tube robot (the Virtuoso). The resection planner operates directly on segmented CT volumes of prostate phantoms, automatically generating tool trajectories for a three-phase median lobe resection workflow: left/median trough resection, right/median trough resection, and median blunt dissection. The retraction network, PushCVAE, trained on surgeon demonstrations, generates retractions according to the procedural phase. The procedure is executed under Level-3 (supervised) autonomy on a prostate phantom composed of hydrogel materials that replicate the mechanical and cutting properties of tissue. As a feasibility study, we demonstrate that our combined autonomous system achieves a 97.1% resection of the targeted volume of the median lobe. Our study establishes a foundation for image-guided autonomy in transurethral robotic surgery and represents a first step toward fully automated minimally-invasive prostate enucleation.

</details>


### [279] [SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment](https://arxiv.org/abs/2511.08583)
*Rong Xue,Jiageng Mao,Mingtong Zhang,Yue Wang*

Main category: cs.RO

TL;DR: 本文提出了选择性流对齐（SeFA）框架，通过利用专家演示选择性地校正生成动作，解决了现有整流流方法在视觉运动策略学习中存在的动作偏差和累积误差问题，实现了更高的准确性和鲁棒性，同时大幅降低了推理延迟。


<details>
  <summary>Details</summary>
Motivation: 高效准确的视觉运动策略是机器人模仿学习的核心挑战。现有的整流流方法在迭代蒸馏后，生成的动作可能偏离当前视觉观测对应的真实动作，导致误差累积和任务执行不稳定。

Method: SeFA通过一种选择性流对齐策略来解决上述问题。该策略利用专家演示来选择性地校正生成的动作，恢复其与观测的一致性，同时保留多模态特性。这种设计引入了一种一致性校正机制，确保生成动作与观测对齐，而不牺牲一步流推理的效率。

Result: 在模拟和真实世界的机械臂操作任务中，SeFA策略超越了最先进的基于扩散和流的方法，实现了卓越的准确性和鲁棒性，并将推理延迟降低了98%以上。

Conclusion: SeFA将整流流的效率与观测一致的动作生成相结合，为实时视觉运动策略学习提供了一个可扩展且可靠的解决方案。

Abstract: Developing efficient and accurate visuomotor policies poses a central challenge in robotic imitation learning. While recent rectified flow approaches have advanced visuomotor policy learning, they suffer from a key limitation: After iterative distillation, generated actions may deviate from the ground-truth actions corresponding to the current visual observation, leading to accumulated error as the reflow process repeats and unstable task execution. We present Selective Flow Alignment (SeFA), an efficient and accurate visuomotor policy learning framework. SeFA resolves this challenge by a selective flow alignment strategy, which leverages expert demonstrations to selectively correct generated actions and restore consistency with observations, while preserving multimodality. This design introduces a consistency correction mechanism that ensures generated actions remain observation-aligned without sacrificing the efficiency of one-step flow inference. Extensive experiments across both simulated and real-world manipulation tasks show that SeFA Policy surpasses state-of-the-art diffusion-based and flow-based policies, achieving superior accuracy and robustness while reducing inference latency by over 98%. By unifying rectified flow efficiency with observation-consistent action generation, SeFA provides a scalable and dependable solution for real-time visuomotor policy learning. Code is available on https://github.com/RongXueZoe/SeFA.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [280] [Frequency-Aware Sparse Optimization for Diagnosing Grid Instabilities and Collapses](https://arxiv.org/abs/2511.07553)
*Swadesh Vhakta,Denis Osipov,Reetam Sen Biswas,Amritanshu Pandey,Seyyedali Hosseinalipour,Shimiao Li*

Main category: eess.SY

TL;DR: 本文提出一种基于稳态视角的频率不稳定性主动诊断与管理方法，通过频率感知稀疏优化识别并定位关键脆弱点，无需依赖暂态建模。


<details>
  <summary>Details</summary>
Motivation: 传统频率稳定性分析常依赖于导数相关的暂态建模。本文旨在从稳态角度主动诊断和管理频率不稳定风险，解决系统在扰动后能否稳定在健康稳态（生存能力）以及若不稳定，其主要脆弱点在哪里（主导脆弱性）的问题。

Method: 首先，将稳态潮流方程扩展，纳入频率相关的调速器关系（即调速器潮流）。其次，提出一种频率感知的稀疏优化方法，寻找最小数量的母线位置，通过可测量的补偿（纠正措施）来强制实现功率平衡并将频率维持在预设/可接受的范围内。

Result: 该方法能够有效定位主导脆弱性来源。在一个1354母线的大型系统中，在N-1发电机停运（3424.8 MW）情况下，该方法仅需在四个母线上进行补偿，即可将最大允许稳态频率下降控制在0.06 Hz（否则频率会下降近0.08 Hz）。此外，该方法具有良好的可扩展性，在1354母线系统上获得稀疏解所需时间少于四分钟。

Conclusion: 本文提出的方法能够从稳态角度主动诊断和管理频率不稳定风险，有效识别并定位系统中的关键脆弱点，并且具有良好的可扩展性。

Abstract: This paper aims to proactively diagnose and manage frequency instability risks from a steady-state perspective, without the need for derivative-dependent transient modeling. Specifically, we jointly address two questions (Q1) Survivability: following a disturbance and the subsequent primary frequency response, can the system settle into a healthy steady state (feasible with an acceptable frequency deviation $Δf$)? (Q2) Dominant Vulnerability: if found unstable, what critical vulnerabilities create instability and/or full collapse? To address these questions, we first augment steady-state power flow states to include frequency-dependent governor relationships (i.e., governor power flow). Afterwards, we propose a frequency-aware sparse optimization that finds the minimal set of bus locations with measurable compensations (corrective actions) to enforce power balance and maintain frequency within predefined/acceptable bounds. We evaluate our method on standard transmission systems to empirically validate its ability to localize dominant sources of vulnerabilities. For a 1354-bus large system, our method detects compensations to only four buses under N-1 generation outage (3424.8 MW) while enforcing a maximum allowable steady-state frequency drop of 0.06 Hz (otherwise, frequency drops by nearly 0.08 Hz). We further validate the scalability of our method, requiring less than four minutes to obtain sparse solutions for the 1354-bus system.

</details>


### [281] [ARGUS: A Framework for Risk-Aware Path Planning in Tactical UGV Operations](https://arxiv.org/abs/2511.07565)
*Nuno Soares,António Grilo*

Main category: eess.SY

TL;DR: ARGUS是一个为战术环境下无人地面车辆(UGV)设计的任务规划框架，它能将指挥官意图和战场复杂性转化为可执行的行动计划，并能实时适应变化，提高任务执行的有效性和安全性。


<details>
  <summary>Details</summary>
Motivation: 在战术环境中，需要将战场复杂性和指挥官意图转化为无人地面车辆(UGV)的可执行行动计划，并平衡任务目标与威胁及地形特征带来的风险。

Method: ARGUS采用一个处理流程：输入地理空间地形数据、威胁情报及其可能位置、以及指挥官定义的任务优先级。通过一系列集成模块处理这些信息，生成优化的轨迹。该框架具有动态适应能力，能够实时调整计划以应对突发事件。

Result: 该系统生成了优化的轨迹，并提供了执行所需的必要洞察力。在与葡萄牙陆军的实际演习中，验证了其互操作性，证明模型生成的路线可以被UGV控制系统集成和利用。

Conclusion: ARGUS是一个决策支持工具，它不仅能生成最佳轨迹，还能提供执行所需的洞察力，从而有助于提高自主地面系统部署的有效性和安全性。

Abstract: This thesis presents the development of ARGUS, a framework for mission planning for Unmanned Ground Vehicles (UGVs) in tactical environments. The system is designed to translate battlefield complexity and the commander's intent into executable action plans. To this end, ARGUS employs a processing pipeline that takes as input geospatial terrain data, military intelligence on existing threats and their probable locations, and mission priorities defined by the commander. Through a set of integrated modules, the framework processes this information to generate optimized trajectories that balance mission objectives against the risks posed by threats and terrain characteristics. A fundamental capability of ARGUS is its dynamic nature, which allows it to adapt plans in real-time in response to unforeseen events, reflecting the fluid nature of the modern battlefield. The system's interoperability were validated in a practical exercise with the Portuguese Army, where it was successfully demonstrated that the routes generated by the model can be integrated and utilized by UGV control systems. The result is a decision support tool that not only produces an optimal trajectory but also provides the necessary insights for its execution, thereby contributing to greater effectiveness and safety in the employment of autonomous ground systems.

</details>


### [282] [Distributed Adaptive Estimation over Sensor Networks with Partially Unknown Source Dynamics](https://arxiv.org/abs/2511.07646)
*Moh Kamalul Wafi,Hamidreza Montazeri Hedesh,Milad Siami*

Main category: eess.SY

TL;DR: 本文研究了传感器网络中具有部分已知源动态的分布式自适应估计问题，提出了连续时间和离散时间设计，证明了其稳定性、信号有界性、估计收敛性以及对噪声的输入到状态稳定性（ISS）鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在传感器网络中，当源动态仅部分已知时，需要开发分布式自适应估计算法，以应对模型不确定性和干扰。

Method: 提出了并行连续时间和离散时间设计：每个节点运行局部自适应观测器并通过有向图交换信息。离散时间设计采用恒定自适应增益和每步回归器归一化处理采样效应，而连续时间设计则不采用。通过统一的Lyapunov框架连接局部观测器动态与图拓扑。

Result: 建立了网络耦合算子的稳定性，证明了所有内部信号的有界性，并展示了尽管存在模型不确定性和干扰，每个节点估计器仍能收敛到源。此外，推导了量化对有界过程噪声鲁棒性的输入到状态稳定性（ISS）界限。模拟结果验证了分析的准确性，展示了精确跟踪、鲁棒性和可扩展性。

Conclusion: 所提出的分布式自适应估计设计（连续时间和离散时间）在传感器网络中，即使源动态部分已知，也能实现稳定、有界、收敛且对噪声鲁棒的估计，并通过理论分析和模拟得到了证实。

Abstract: This paper studies distributed adaptive estimation over sensor networks with partially known source dynamics. We present parallel continuous-time and discrete-time designs in which each node runs a local adaptive observer and exchanges information over a directed graph. For both time scales, we establish stability of the network coupling operators, prove boundedness of all internal signals, and show convergence of each node estimate to the source despite model uncertainty and disturbances. We further derive input-to-state stability (ISS) bounds that quantify robustness to bounded process noise. A key distinction is that the discrete-time design uses constant adaptive gains and per-step regressor normalization to handle sampling effects, whereas the continuous-time design does not. A unified Lyapunov framework links local observer dynamics with graph topology. Simulations on star, cyclic, and path networks corroborate the analysis, demonstrating accurate tracking, robustness, and scalability with the number of sensing nodes.

</details>


### [283] [Evolutionary Analysis of Continuous-time Finite-state Mean Field Games with Discounted Payoffs](https://arxiv.org/abs/2511.07655)
*Leonardo Pedroso,Andrea Agazzi,W. P. M. H. Heemels,Mauro Salazar*

Main category: eess.SY

TL;DR: 本文为具有大量参与者和明确状态演化的连续时间动态博弈开发了一个演化框架，引入了平均场近似和一种新的均衡概念（混合平稳纳什均衡，MSNE），并建立了其与演化模型的联系。


<details>
  <summary>Details</summary>
Motivation: 现有的演化博弈论方法缺乏对个体状态动态的建模，而这对于许多应用中的动态博弈是必需的。因此，需要一个能够处理明确状态演化的动态博弈演化框架。

Method: 研究引入了有限参与者博弈的平均场近似，并提出了一种新的概念——混合平稳纳什均衡（MSNE）。此外，本文还开发了一个平均场演化模型。

Result: 研究建立了平均场近似的近似保证。它还刻画了MSNE与所提出的平均场演化模型的静止点之间的等价性，并给出了MSNE演化稳定性的条件。

Conclusion: 本文成功地为具有状态演化的大规模动态博弈提供了一个演化框架，引入了具有演化解释的MSNE，并将其与平均场演化模型的静止点联系起来，为理解此类博弈的稳定性提供了新工具。

Abstract: We consider a class of continuous-time dynamic games involving a large number of players. Each player selects actions from a finite set and evolves through a finite set of states. State transitions occur stochastically and depend on the player's chosen action. A player's single-stage reward depends on their state, action, and the population-wide distribution of states and actions, capturing aggregate effects such as congestion in traffic networks. Each player seeks to maximize a discounted infinite-horizon reward. Existing evolutionary game-theoretic approaches introduce a model for the way individual players update their decisions in static environments without individual state dynamics. In contrast, this work develops an evolutionary framework for dynamic games with explicit state evolution, which is necessary to model many applications. We introduce a mean field approximation of the finite-population game and establish approximation guarantees. Since state-of-the-art solution concepts for dynamic games lack an evolutionary interpretation, we propose a new concept - the Mixed Stationary Nash Equilibrium (MSNE) - which admits one. We characterize an equivalence between MSNE and the rest points of the proposed mean field evolutionary model and we give conditions for the evolutionary stability of MSNE.

</details>


### [284] [AURORA: Autonomous Updating of ROM and Controller via Recursive Adaptation](https://arxiv.org/abs/2511.07768)
*Jiachen Li,Shihao Li,Dongmei Chen*

Main category: eess.SY

TL;DR: AURORA是一个多智能体大模型框架，用于自动化降阶模型（ROM）控制器设计，并具备在线自适应能力，解决了高维非线性系统实时控制的计算难题及传统ROM控制缺乏在线适应性的问题。


<details>
  <summary>Details</summary>
Motivation: 高维非线性系统的实时模型控制面临计算不可行性，而传统的降阶模型（ROM）控制需要专家手动调优，且缺乏在线适应能力。

Method: 本文提出了AURORA（通过递归自适应实现ROM和控制器的自主更新），一个多智能体大模型框架，通过五个专业代理的迭代生成-判断-修正循环实现协作。其中一个评估代理负责诊断性能退化源并进行适当纠正，从而自动化ROM控制器设计并实现在线自适应。

Result: AURORA在八个基准系统（包括机械组件、热偏微分方程和机器人）上进行了验证。与五种最先进的大模型进行比较评估，结果表明AURORA具有高度自主性，只需最少的人工干预。

Conclusion: AURORA框架展示了自主控制设计的实际可行性，为解决复杂系统控制挑战提供了新的途径。

Abstract: Real-time model-based control of high-dimensional nonlinear systems faces computational intractability, while traditional reduced-order model (ROM) control requires manual expert tuning without online adaptation. We propose AURORA (\textbf{A}utonomous \textbf{U}pdating of \textbf{RO}M and Controller via \textbf{R}ecursive \textbf{A}daptation), a multi-agent LLM framework automating ROM-based controller design with online adaptation. AURORA employs five specialized agents collaborating through iterative generation-judge-revision cycles, with an Evaluation Agent diagnosing degradation sources and routing corrections appropriately. Validated on eight benchmark systems spanning mechanical assemblies, thermal PDEs, and robots. Comparative evaluation across five state-of-the-art LLMs demonstrates high autonomy with minimal intervention, establishing practical viability for autonomous control design.

</details>


### [285] [Synergistic Development of Cybersecurity and Functional Safety for Smart Electric Vehicles](https://arxiv.org/abs/2511.07713)
*Siddhesh Pimpale*

Main category: eess.SY

TL;DR: 智能电动汽车（SEVs）的复杂性带来了网络安全和功能安全的新挑战。本文强调了这两个领域并行开发的重要性，并报告了当前的标准和挑战。


<details>
  <summary>Details</summary>
Motivation: 智能电动汽车（SEVs）的引入对汽车领域产生了颠覆性影响，但其日益增长的复杂性（互联系统、自动驾驶、电气化）带来了新的网络安全和功能安全挑战。车辆的不安全或不可靠运行对性能和乘客安全构成不可接受的风险。

Method: 本文研究了智能电动汽车网络安全和功能安全的集成开发，强调了这些领域并行开发而非独立处理的必要性。同时，报告了智能电动汽车网络安全和功能安全的当前标准，并指出了相关挑战。

Result: 网络安全对于防止黑客攻击、数据泄露和未经授权的访问至关重要，而功能安全则确保关键车辆功能（如制动、转向、电池控制）在部分系统故障时仍能正常工作。网络安全事件可能导致功能安全系统发生灾难性故障，反之亦然，因此两者融合变得日益关键。报告指出了通信网络弱点、OTA更新的潜在安全威胁以及对实时响应系统需求等挑战。

Conclusion: 对于智能电动汽车而言，网络安全和功能安全的并行集成开发至关重要，因为一个领域的安全事件可能对另一个领域产生灾难性影响。文章强调了需要解决的当前标准和挑战，以确保车辆的安全性与可靠性。

Abstract: The introduction of Smart Electric Vehicles (SEVs) represents an increasingly disruption on automotive area, once integrates advanced computer and communication technologies to highly electrical cars, which come with high performances, environment friendly and user friendly characteristics . But the increasing complexity of SEVs prompted by greater dependence on interconnected systems, autonomous capabilities and electrification, presents new challenges in cybersecurity as well as functional safety. The safety and reliability of such vehicles is paramount, as unsafe or unreliable operation in either case represents an unacceptable risk in terms of the performance of the vehicle and safety of the passenger. This paper investigates the integrated development of cybersecurity and functional safety for SEVs, emphasizing the requirement for the parallel development of these domains as components that are not treated separately. In SEVs, cybersecurity is quite crucial in order to prevent the threats of hacking, data breaches and unauthorized access to vehicle systems. Functional safety ensures that important vehicle functions (braking, steering, battery control, etc.) keep working even if some part fails. This convergence of functional safety issues with cybersecurity issues is becoming more crucial, since a security incident can result in a failure of catastrophic consequences for a functional safety system and, conversely. This paper reports the current state of cybersecurity and functional safety standards for SEVs, highlighting challenges that include the weaknesses of communication networks, the potential security threats of over-the-air updates, and the demand for real-time responsive systems for failure.

</details>


### [286] [Experimental Evaluation of Fuzzy-Integral and Classical controls for Power Management in a 24 GHz mmWave 5G Transceiver](https://arxiv.org/abs/2511.07815)
*Karel Walter Gomez Orellana,Berthyn Rodrigo Tiñini Chuquimia,Juan Carlos Paredes Condori,Rodrigo Apaza Huanca,Hugo Orlando Condori Quispe*

Main category: eess.SY

TL;DR: 本论文比较了三种控制策略（PID、纯积分和模糊积分）在24 GHz毫米波收发器中用于自适应功率管理的性能，以解决5G毫米波功放的线性度挑战，结果显示模糊积分控制器在稳定时间、稳定性和EVM最小化方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 5G毫米波系统部署面临功放线性度和效率的严峻挑战，尤其是在温度引起的增益变化导致误差矢量幅度（EVM）下降时，需要有效的自适应功率管理来维持性能。

Method: 研究比较了三种控制策略：PID控制器、纯积分控制器和模糊积分（FI）控制器。FI控制器结合了模糊逻辑处理非线性问题和积分作用实现零稳态误差。实验在一个24 GHz毫米波收发器中进行，以评估这些策略的性能。

Result: 实验结果表明，模糊积分（FI）控制器在稳定时间、稳定性和误差矢量幅度（EVM）最小化方面优于其他两种控制器。

Conclusion: 模糊积分控制器是一种更优的解决方案，能够有效地解决5G毫米波收发器中功放的线性度和效率问题，尤其是在应对温度变化引起的性能退化方面。

Abstract: The deployment of 5G millimeter-wave (mmWave) systems poses significant challenges in maintaining power amplifier linearity and efficiency under varying conditions, such as temperature-induced gain variations that degrade error vector magnitude (EVM). This paper presents a comparative study of three control strategies-PID, pure integral, and fuzzy-integral (FI)-for adaptive power management in a 24 GHz mmWave transceiver. The FI controller integrates fuzzy logic for handling nonlinearities with integral action for zero steady-state error. Experimental results show the FI controller outperforms others in settling time, stability, and EVM minimization.

</details>


### [287] [Optimisation of Power Modulation for Hall-Héroult Cells: Process Operability and Constraints as Virtual Energy Storage](https://arxiv.org/abs/2511.07893)
*Choon-Jie Wong,Adam A. Larkin,Jie Bao,Maria Skyllas-Kazacos,Barry J. Welch,Nadia Ahli,Maitha Faraj,Mohamed Mahmoud*

Main category: eess.SY

TL;DR: 本文研究了铝电解槽在电力调制下的最佳操作条件，以实现利润最大化，同时利用可再生能源并作为虚拟储能系统，通过结合降阶模型和详细模型开发了一种新颖的优化方法。


<details>
  <summary>Details</summary>
Motivation: 铝生产的霍尔-埃鲁法能耗巨大。通过电力调制，铝冶炼厂可以适应可变功耗，从而利用可再生能源，并作为大型虚拟储能系统来平衡电网，稳定电力供应。研究旨在找到最佳操作条件以最大化盈利能力。

Method: 开发了一种新颖的优化方法，该方法结合使用降阶模型和详细模型来处理复杂、空间分布和多时间尺度的电解槽动态。研究了包括随时间变化的线路电流和阳极-阴极距离（ACD）剖面，以在电解槽热平衡约束下最大化利润。

Result: 研究结果揭示了在不同电力调制场景（包括分时电价和现货价格）下，最佳的线路电流和阳极-阴极距离（ACD）剖面。这些结果为铝电解槽在线控制策略的进一步研究奠定了基础。

Conclusion: 通过优化电力调制下的线路电流和ACD剖面，可以最大化铝电解槽的盈利能力，并支持其作为虚拟储能系统与可再生能源集成。研究结果为未来的在线控制策略提供了基础。

Abstract: Aluminium is manufactured through the Hall-Héroult process, which is very energy intensive. Power modulation, as an industrial-scale demand-side power management approach, allows aluminium smelters to operate with variable power consumption rates and as such be powered by renewable energy sources. In this way, aluminium smelting cells can be used as a large virtual energy storage to balance power demand-supply and stabilise electrical grids. This paper studies the potential optimal power modulation operating conditions, including time-varying line current and anode-cathode distance (ACD) profiles to maximise the aluminium reduction cell profitability subject to constraints on the cell thermal balance. To deal with the complex cell dynamics which are spatially distributed and multi-timescale, a novel optimisation approach that utilises both reduced-order and detailed models is developed. The results yield insight into the optimal line current and ACD profiles for different power modulation scenarios including the time of use electricity tariff and spot price. These results can form the foundation for further studies into online control policies of aluminium reduction cells.

</details>


### [288] [Comparative Study of Q-Learning for State-Feedback LQG Control with an Unknown Model](https://arxiv.org/abs/2511.07870)
*Mingxiang Liu,Damián Marelli,Minyue Fu,Qianqian Cai*

Main category: eess.SY

TL;DR: 本文比较了两种用于未知参数的SF-LQG控制器设计方法：经典的系统辨识+LQG方法和基于Q学习的强化学习方法。研究发现，经典方法在渐近意义上是高效且计算效率更高的，尽管提出了一种新的Q学习方法也能渐近达到最优。


<details>
  <summary>Details</summary>
Motivation: 在系统矩阵和过程噪声协方差未知的情况下，为系统设计状态反馈线性二次高斯（LQG）控制器是一个挑战。研究旨在严格比较现有方法（经典系统辨识与Q学习）的优劣，并探索更优的Q学习方法。

Method: 研究对比了两种方法：1) 经典方法：通过系统辨识估计未知参数，然后进行状态反馈LQG（SF-LQG）控制器设计。2) Q学习方法：使用一种最近提出的基于强化学习的Q学习范式。此外，作者提出了一种新的基于Q学习的方法。比较基于控制器实现的复杂性和准确性。

Result: 经典方法渐近高效，在准确性方面几乎没有改进空间。本文提出的新型Q学习方法也能渐近实现最优控制器设计。然而，复杂度分析表明，经典方法在数值上比基于Q学习的替代方法更有效。

Conclusion: 对于未知参数的SF-LQG设计问题，经典方法仍然是最佳选择。

Abstract: We study the problem of designing a state feedback linear quadratic Gaussian (LQG) con- troller for a system in which the system matrices as well as the process noise covariance are unknown. We do a rigorous comparison between two approaches. The first is the classic one in which a system identification stage is used to estimate the unknown parameters, which are then used in a state-feedback LQG (SF-LQG) controller design. The second approach is a recently proposed one using a reinforcement learning paradigm called Q-learning. We do the comparison in terms of complexity and accuracy of the resulting controller. We show that the classic approach asymptotically efficient, giving virtually no room for improvement in terms of accuracy. We also propose a novel Q-learning-based method which we show asymptotically achieves the optimal controller design. We complement our proposed method with a numerically efficient algorithmic implementation aiming at making it competitive in terms of computations. Nevertheless, our complexity analysis shows that the classic approach is still numerically more efficient than this Q-learning-based alternative. We then conclude that the classic approach remains being the best choice for addressing the SF-LQG design in the case of unknown parameters.

</details>


### [289] [An Innovations-Based Data-Driven Kalman Predictor for Predictive Control](https://arxiv.org/abs/2511.07907)
*Mohamed Abdalmoaty,Roy S. Smith*

Main category: eess.SY

TL;DR: 本文提出了一种纯数据驱动的卡尔曼滤波器，它仅利用测量到的输入输出数据进行参数化，通过创新形式克服了传统方法对离线过程扰动测量的需求。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的卡尔曼滤波器要求离线测量过程扰动，这在许多实际应用中往往无法满足。

Method: 该方法通过测量到的输入输出数据对卡尔曼滤波器进行参数化。核心思想是利用创新形式，它将过程扰动和测量噪声自然地整合到一个单一的正交随机过程中。与过程扰动不同，创新过程可以通过数值高效的投影步骤直接从输入输出数据中估计出来。

Result: 该方法的性能通过基准模拟得到了验证。

Conclusion: 该研究提供了一种实用的数据驱动卡尔曼滤波解决方案，通过利用创新形式和输入输出数据，避免了对离线过程扰动测量的依赖。

Abstract: A recently developed data-driven Kalman filter requires offline measurement of the process disturbance; a requirement that is often unmet for many practical applications. We propose a solution that parametrizes the Kalman filter exclusively using measured input and output data. The key idea is to use the innovations form which naturally accounts for the process disturbance and measurement noise into a single orthogonal stochastic process. Unlike process disturbances, the innovations process can be estimated directly from input-output data via a numerically efficient projection step. The performance of the method is demonstrated using a benchmark simulation.

</details>


### [290] [From Natural Language to Certified H-infinity Controllers: Integrating LLM Agents with LMI-Based Synthesis](https://arxiv.org/abs/2511.07894)
*Shihao Li,Jiachen Li,Jiamin Xu,Dongmei Chen*

Main category: eess.SY

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: We present \textsc{S2C} (Specification-to-Certified-Controller), a multi-agent framework that maps natural-language requirements to certified $\mathcal{H}_\infty$ state-feedback controllers via LMI synthesis. \textsc{S2C} coordinates five roles -- \textit{SpecInt} (spec extraction), \textit{Solv} (bounded-real lemma (BRL) LMI), \textit{Tester} (Monte Carlo and frequency-domain checks), \textit{Adapt} (spec refinement), and \textit{CodeGen} (deployable code). The loop is stabilized by a severity- and iteration-aware $γ$-floor guardrail and a decay-rate region constraint enforcing $\Reλ(A{+}BK)<-α$ with $α=3.9/T_s$ derived from settling-time targets. For state feedback, verification reports disturbance rejection $\big\|C\,(sI-(A{+}BK))^{-1}E\big\|_\infty$ alongside time-domain statistics; discrete benchmarks are converted to continuous time via a Tustin (bilinear) transform when needed. On 14 COMPleib problems, \textsc{S2C} attains \textbf{100\%} synthesis success and \textbf{100\%} convergence within six iterations, with strong decay-rate satisfaction and near-target certified $\mathcal{H}_\infty$ levels; it improves robustness metrics relative to single-shot BRL and BRL+$α$ baselines. An ablation over LLM backbones (GPT-5, GPT-5 mini, DeepSeek-V3, Qwen-2.5-72B, Llama-4 Maverick) shows the pipeline is robust across models, while stronger models yield the highest effectiveness. These results indicate that LLM agents can integrate certificate-bearing control synthesis from high-level intent, enabling rapid end-to-end prototyping without sacrificing formal guarantees.

</details>


### [291] [Spacecraft Angular Rate Estimation via Event-Based Camera Sensing](https://arxiv.org/abs/2511.08041)
*Vittorio Franzese,Matteo El Hariry*

Main category: eess.SY

TL;DR: 本文提出了一种利用事件相机通过分析恒星亮度事件来确定航天器角速率的方法。


<details>
  <summary>Details</summary>
Motivation: 旨在探索一种利用事件相机传感来补充或替代航天器系统中传统速率传感器的角速率确定方法。

Method: 该方法通过分析由恒星视运动触发的亮度事件（事件的位置和极性），推断恒星的视运动场，进而估算相机坐标系中的观测者角速度。结合姿态参考，可将其转换为航天器角速率。该方法通过对随机航天器指向和速率条件下生成的合成事件流数据集进行数值模拟进行了验证。

Result: 通过数值模拟评估了该方法的准确性，证明了其在航天器系统中使用事件相机传感来补充或替代传统速率传感器的潜力。

Conclusion: 该方法有望在采用事件相机传感的航天器系统中，作为传统速率传感器的补充或替代方案。

Abstract: This paper presents a method for determining spacecraft angular rates using event-based camera sensing. This is achieved by analyzing the temporal distribution of brightness events triggered by the apparent motion of stars. The location and polarity of the events are used to infer the apparent motion field of the stars, which is, in turn, employed to estimate the observer angular velocity in the camera frame. This can be converted to the spacecraft angular rates provided an attitude reference. The method is validated through numerical simulation for a synthetic dataset of event streams generated on random spacecraft pointing and rates conditions. The accuracy of the method is assessed, demonstrating its potential to complement or replace conventional rate sensors in spacecraft systems using event camera sensing.

</details>


### [292] [Multi-layer barrier function-based adaptive super-twisting controller](https://arxiv.org/abs/2511.08106)
*Antoine Thibault Vié,Leonid Fridman,Roberto Galeazzi,Dimitrios Papageorgiou*

Main category: eess.SY

TL;DR: 本文提出一种自适应超扭曲滑模控制（STSMC）框架，用于具有未知恒定速率有界扰动的不确定一阶系统，通过使用半正定势垒函数和“嵌套势垒”方案，解决了初始估计保守性和离散时间实现中采样间隔期扰动的问题，确保了闭环轨迹的有界性。


<details>
  <summary>Details</summary>
Motivation: 在自整定超扭曲控制器中使用正定势垒函数时，可能因扰动速率界限的初始估计而引入保守性。此外，算法的离散时间实现不一定能保证在两次采样之间发生突然扰动时闭环轨迹的有界性。

Method: 提出了一种自适应超扭曲滑模控制框架，其主要特点包括将半正定势垒函数扩展应用于超扭曲控制器自适应，以及采用“嵌套势垒”方案。通过Lyapunov分析评估了闭环系统的稳定性。

Result: 所提出的方法即使在“不利”的扰动与采样时间比下也能确保解的有界性。仿真结果证明了所提框架的有效性。

Conclusion: 该自适应超扭曲滑模控制框架通过引入半正定势垒函数和“嵌套势垒”方案，有效地解决了不确定一阶系统在未知常数速率有界扰动下的控制问题，提高了对初始估计误差和离散时间实现中突发扰动的鲁棒性，并保证了闭环系统的稳定性。

Abstract: This article presents an adaptive Super-Twisting Sliding Mode Control framework for uncertain first-order systems, with rate-bounded perturbations, where the bound is constant but unknown. Positive definite barrier functions, when used in self-tuning super-twisting controllers may introduce some conservatism in relation to initial estimations of the perturbation rate bound. Moreover, discrete time implementation of the algorithm does not necessarily guarantee the boundedness of the closed-loop trajectories when sudden changes in the perturbation occur in between two time samples. The salient features of the proposed methodology pertain to extending the use of positive semidefinite barrier functions to Super-Twisting controller adaptation and the employment of a "nested barriers" scheme that ensures boundedness of the solutions even for "unfavourable" perturbations-to-sampling time ratios. The stability of the closed-loop system is assessed via Lyapunov analysis and simulations demonstrate the efficacy of the proposed framework.

</details>


### [293] [Stability of Certainty-Equivalent Adaptive LQR for Linear Systems with Unknown Time-Varying Parameters](https://arxiv.org/abs/2511.08236)
*Marcell Bartos,Johannes Köhler,Florian Dörfler,Melanie N. Zeilinger*

Main category: eess.SY

TL;DR: 本文提出了一种简单、模块化且计算高效的方法，通过结合最小均方（LMS）滤波器和确定性等效线性二次调节器（LQR），为具有未知时变参数的离散时间线性系统提供自适应控制，并证明了闭环系统的有限增益 $\ell^2$-稳定性。


<details>
  <summary>Details</summary>
Motivation: 当系统动力学在运行期间发生变化时，标准的基于模型的控制设计性能会下降。为了克服这一挑战，文献中提出了在线和自适应方法。

Method: 该方法结合了两个经典的估计算法和控制构建模块：最小均方（LMS）滤波器和确定性等效线性二次调节器（LQR）。

Result: 分析证明，尽管存在未知扰动和时变参数不确定性，但未知系统、参数估计器和控制器闭环互连具有有限增益 $\ell^2$-稳定性。通过对非线性平面四旋翼飞行器进行的仿真展示了所提出算法的实际适用性。

Conclusion: 所提出的算法通过无缝结合LMS滤波器和确定性等效LQR，为具有未知时变参数的离散时间线性系统提供了一个强大、稳定且计算可行的自适应控制方案。

Abstract: Standard model-based control design deteriorates when the system dynamics change during operation. To overcome this challenge, online and adaptive methods have been proposed in the literature. In this work, we consider the class of discrete-time linear systems with unknown time-varying parameters. We propose a simple, modular, and computationally tractable approach by combining two classical and well-known building blocks from estimation and control: the least mean square filter and the certainty-equivalent linear quadratic regulator. Despite both building blocks being simple and off-the-shelf, our analysis shows that they can be seamlessly combined to a powerful pipeline with stability guarantees. Namely, finite-gain $\ell^2$-stability of the closed-loop interconnection of the unknown system, the parameter estimator, and the controller is proven, despite the presence of unknown disturbances and time-varying parametric uncertainties. Real-world applicability of the proposed algorithm is showcased by simulations carried out on a nonlinear planar quadrotor.

</details>


### [294] [PE-TSFM: Self-Supervised Time-Series Learning for Generalizable Power Converter Health Monitoring under Unseen Conditions](https://arxiv.org/abs/2511.08250)
*Xinyuan Liao,Xinyue Zhang,Xing Wei,Junwei Liu,Shuai Zhao,Siqi Bu,Yi Zhang*

Main category: eess.SY

TL;DR: 本文提出了一种领域特定的时间序列基础模型 (PE-TSFM)，通过在大规模未标记电力转换器数据上预训练并引入双重注意力机制，显著提高了电力转换器健康监测在未见工况下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的电力转换器健康监测方法在面对未见操作条件时泛化能力差，即存在域外 (OOD) 挑战，这限制了其实用性。

Method: 研究构建了一个领域特定的时间序列基础模型 (PE-TSFM)，该模型直接从大规模未标记的转换器数据中学习表示。与通用时间序列基础模型不同，PE-TSFM完全在领域数据上进行预训练，以学习电力电子特有的物理关系。此外，模型引入了双重注意力机制，以同时捕获时间模式和通道间依赖性（特别是用于捕捉传感器间物理关系的通道注意力）。模型使用包含1.41亿个时间戳的电力转换器数据集进行预训练。

Result: PE-TSFM 在未见操作条件下达到了92%的准确率，远高于通用时间序列基础模型（约60%）和传统时间序列模型（约40%）。这证实了PE-TSFM强大的OOD泛化能力。消融研究进一步验证了引入的通道注意力机制显著提高了模型性能。研究还对模型的可扩展性、超参数敏感性和可解释性进行了详细分析。

Conclusion: 所提出的PE-TSFM，通过领域特定的预训练和双重注意力机制，能够有效地从大规模未标记数据中学习电力电子的物理关系，显著提高了电力转换器健康监测在未见工况下的泛化能力，超越了现有通用和传统方法。

Abstract: Data-driven health monitoring of power converters remains limited by poor generalization to unseen operating conditions. This work addresses this out-of-distribution (OOD) challenge by building a domain-specific time-series foundation model (PE-TSFM) that learns representations directly from large-scale unlabeled converter data. Unlike generic TSFMs trained on broad time-series datasets, the proposed PE-TSFM is pre-trained entirely on domain data, enabling it to learn the physical relationships unique to power electronics. To further tailor the model to this domain, we introduce a dual-attention mechanism that captures both temporal patterns and inter-channel dependencies. While generic TSFMs primarily model temporal dependencies, the added channel attention captures inter-sensor physical relationships essential for converter degradation analysis. A dataset containing 141 million unlabeled timestamps from an operating power converter is used for pre-training. Experiments show that PE-TSFM achieves 92% accuracy under unseen operating conditions. In contrast, generic TSFMs achieve around 60% and conventional time-series models achieve around 40% accuracy. This result confirms the strong OOD generalization of the proposed PE-TSFM. Ablation studies further verify that the introduced channel attention mechanism significantly improves model performance. In addition, we conduct detailed studies on model scalability, hyperparameter sensitivity, and interpretability to provide a comprehensive understanding of the proposed approach.

</details>


### [295] [Extended Time Varying Multi-Cluster Fluctuating Two-Ray Fading Model for Maritime Environment](https://arxiv.org/abs/2511.08338)
*Antoine Thibault Vié,Roberto Galeazzi,Dimitrios Papagergiou*

Main category: eess.SY

TL;DR: 本文提出了一种扩展的多簇波动双射线衰落（MFTR）模型，结合随机微分方程（SDEs），以更准确地描述海上通信信道，尤其适用于高速船只，并在仿真中评估了其准确性。


<details>
  <summary>Details</summary>
Motivation: 自主和远程操作海上船舶的进步，需要鲁棒可靠的通信系统来支持实时监控、导航和控制等高带宽应用。现有通信信道模型（如瑞利和莱斯衰落）不足以准确描述海上通信的动态复杂性，特别是对于沿海环境中的高速船舶。

Method: 本文提出了一种对多簇波动双射线衰落（MFTR）模型的扩展。该扩展模型通过集成随机微分方程（SDEs）来捕捉信道的时变特性（如相位偏移和延迟），并考虑了大型衰落、时变参数和多普勒频移等关键现象。此外，还考虑了延迟引起的功率损耗和路径损耗等物理因素。模型准确性通过仿真进行评估。

Result: 通过仿真评估了所提出的扩展MFTR模型的准确性，表明其能够捕捉海上通信信道，特别是高速船只在沿海环境中面临的动态和复杂特性，以及大型衰落、时变参数和多普勒频移等现象。

Conclusion: 该研究提供了一个更鲁棒和可靠的通信信道模型，以支持海上船舶的自主和远程操作。所提出的扩展MFTR模型通过集成SDEs，能够更准确地描述海上通信的动态复杂性，克服了现有模型（如瑞利和莱斯衰落）的不足。

Abstract: The recent advancements in autonomous and remote operation of maritime vessels necessitates the development of robust and reliable communication systems to support high-bandwidth applications such as real-time monitoring, navigation, and control. Existing communication channel models, including Rayleigh and Rician fading, are inadequate to accurately describe the dynamic and complex nature of maritime communication, particularly for high-speed vessels in coastal environments. This paper proposes an extension to the Multi-Cluster Fluctuating Two-Ray Fading (MFTR) model that also accounts for key phenomena such as large-scale fading, time-varying parameters and Doppler shifts. The extended MFTR model integrates Stochastic Differential Equations (SDEs) to capture the time-varying characteristics of the channel, such as phase shifts and delays, while considering physical factors like delay-induced power loss and path loss. The accuracy of the proposed model is assessed in simulation.

</details>


### [296] [A Unified Theory for Transient Synchronization Stability Analysis of Renewable Dominated Power Systems](https://arxiv.org/abs/2511.08165)
*Meng Zhan,Miao Han,Yayao Zhang,Hongsheng Xu,Jiabing Hu,Shijie Cheng,Jürgen Kurths*

Main category: eess.SY

TL;DR: 本文提出了一种广义摆动方程（GSE）和改进的等面积准则（EAC）方法，用于统一建模和分析可再生能源主导电力系统（RDPS）的暂态动态，实现高精度的临界清除时间计算。


<details>
  <summary>Details</summary>
Motivation: 电力发电从同步发电机向变流器的转变（第二次革命）引入了新的、复杂的动态，使得传统摆动方程难以完全理解和评估现代可再生能源主导电力系统在大型扰动下的暂态稳定性。RDPS具有空间大规模、非线性、多时间尺度甚至顺序开关的特点，增加了其动态分析的复杂性。

Method: 建立了并统一了基于风能或太阳能的可再生设备的低电压穿越下的各种暂态开关机制模型。这些模型可以通过考虑开关动态导致的参数变化的广义摆动方程（GSE）来描述，该GSE侧重于主导的锁相环动态，并与传统摆动方程相似。在此基础上，主要利用机械等效原理和能量守恒原理，提出了一种显著改进的等面积准则（EAC）方法。

Result: 所提出的广义摆动方程（GSE）能够完美描述可再生设备的暂态开关动态。基于该改进的等面积准则方法，即使对于大规模可再生能源场，临界清除时间的计算误差也仅约为1%。

Conclusion: 这种基于非线性动力学的优雅方法为可再生能源主导电力系统的暂态动态建立了统一的理论，包括建模和分析。

Abstract: The change of electric power generation - from synchronous generator (SG) to converter - is generally regarded as the second revolution of power system. Different from rotor swing of SG in traditional grids mainly described by the swing equation (SE), the converter dynamics plays an indispensable role in modern renewable dominated power systems (RDPS). The high complexity of the RDPS, including spatial large-scale, nonlinearity, multi-time-scale, and even sequential switching, prevents us from fully understanding its dynamics and assessing its transient stability under large disturbance. Here, a variety of transient switching mechanism models of renewable devices relying on wind or solar energies under low-voltage ride-through are established and unified, which can be perfectly described by a generalized swing equation (GSE) under parameter changes for switching dynamics. The GSE focusing on the dominant phase-locking loop dynamics is similar to the SE. Mainly relying on the mechanical equivalence and the energy conservative principle, a substantially improved equal-area criterion method is proposed. Based on this method, even for large-scale renewable fields, the calculation errors for the critical clearing time are only about 1%. This elegant nonlinear-dynamics-based approach establishes a unified theory including modelling and analysis for the RDPS transient dynamics.

</details>


### [297] [Power Hardware-in-the-loop Interfacing via $\mathcal{H}_\infty$ Model Matching](https://arxiv.org/abs/2511.08370)
*Jonathan Eid,Ashley Meagher,Dmitry Rimorov,Anil Kumar Bonala,Rajendra Thike,James Richard Forbes*

Main category: eess.SY

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: This paper presents an $\mathcal{H}_\infty$ model matching control-based approach to the problem of power hardware-in-the-loop (PHIL) interfacing. The objective is to interconnect a grid simulation and a physical device via an interface in a way that is stable and accurate. Conventional approaches include the ideal transformer method (ITM) and its impedance-based variants, which trade accuracy for stability, as well as some $\mathcal{H}_\infty$ control-based approaches, which do not make use of all the available information in their optimization for accuracy. Designing for transparency, as opposed to accuracy as existing approaches do, would achieve both accuracy and stability, while making use of all the dynamical information present in the idealized interconnection of the grid and device. The approach proposed in this paper employs model matching to formulate the PHIL problem as an $\mathcal{H}_\infty$ control problem using transparency as the explicit frequency-domain control objective. The approach is experimentally validated in a real-time resistive-load PHIL setup, and is found to achieve accuracy levels that are comparable or superior to those of an ITM-based interface.

</details>


### [298] [Active Short Circuit and Safe Discharge Mechanisms in Multi-Phase Inverters During Critical Failures](https://arxiv.org/abs/2511.08405)
*Siddhesh Pimpale,Sagar Mahadik*

Main category: eess.SY

TL;DR: 本文提出了一种针对多相逆变器（特别是电动汽车应用）的鲁棒故障保护系统，结合了主动短路和安全放电机制，以有效增强故障检测和系统响应，提升安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 多相逆变器（尤其在电动汽车动力总成中）日益复杂，需要强大的故障保护系统。碳化硅（SiC）功率模块在高效率、高功率应用中普及，其在故障条件下的可靠性至关重要。若不阻止短路故障，多相逆变器系统将发生级联故障和永久性损坏。

Method: 所提出的方法结合了集中式短路检测、主动相短路（片上机制快速隔离受影响的相）和受控放电（控制故障场景下的能量释放），以防止故障扩散并减少关键部件的热应力。

Result: 实验结果表明，所提出的机制能有效提升故障检测性能、故障期间的系统响应以及整体故障运行，优于现有方法。

Conclusion: 这些机制对于增强多相逆变器的安全性和可靠性非常重要，尤其是在电动汽车等需要高运行安全性的关键应用中。

Abstract: The multi-phase inverter has become more complicated, particularly in an Electric Vehicle (EV)'s power train, which requires a robust fault protection system. The proposed active short circuit and safe discharge mechanisms are also included in this work, dedicated to multi-phase converters in failure conditions. With silicon carbide (SiC) power modules increasingly used in high efficiency and high-power applications, the reliability under fault conditions is an extremely important factor. Cascading failures and permanent damage will occur in multi phase inverter systems if short circuit faults are not prevented. The proposed method combines one centralized short circuit detection, active phase shorting and controlled discharge to make these structures more robust. The on chip active short circuit mechanism isolates the affected phases quickly preventing faults from spreading to other areas of the inverter and the safe discharge mechanism controls energy discharged in fault scenarios, which reduces the thermal stress placed on essential components. The experimental results show that the proposed mechanisms can effectively enhance a fault detection performance, system response during faults, and the operation as whole at faults over the several existing methods. These mechanisms are demonstrated to be very important for enhancing the safety and reliability of multiphase inverters, especially for critical applications of such inverters as EV where high operational security is required.

</details>


### [299] [Probabilistic Safety Guarantee for Stochastic Control Systems Using Average Reward MDPs](https://arxiv.org/abs/2511.08419)
*Saber Omidi,Marek Petrik,Se Young Yoon,Momotaz Begum*

Main category: eess.SY

TL;DR: 该论文提出一种新算法，通过将随机控制系统中的安全目标转化为平均奖励马尔可夫决策过程（MDP）目标，来计算安全策略并确定有限状态集上的安全水平。


<details>
  <summary>Details</summary>
Motivation: 随机控制系统中，状态变量的不可预测演变使得使用现有控制方法难以满足预定义的操作约束，因此需要一种新的方法来计算高置信度的安全策略。

Method: 开发了一种新算法，将安全目标简化为标准的平均奖励MDP目标。这种简化允许使用线性规划等标准技术来计算和分析安全策略。

Result: 数值验证表明，与最小折扣奖励解决方案相比，平均奖励MDP解决方案更全面、收敛更快、质量更高。该方法在双积分器和倒立摆系统上得到了验证。

Conclusion: 将安全目标转化为平均奖励MDP的方法能够有效计算随机控制系统的安全策略，并提供更优越的性能，使其成为解决此类安全问题的有效工具。

Abstract: Safety in stochastic control systems, which are subject to random noise with a known probability distribution, aims to compute policies that satisfy predefined operational constraints with high confidence throughout the uncertain evolution of the state variables. The unpredictable evolution of state variables poses a significant challenge for meeting predefined constraints using various control methods. To address this, we present a new algorithm that computes safe policies to determine the safety level across a finite state set. This algorithm reduces the safety objective to the standard average reward Markov Decision Process (MDP) objective. This reduction enables us to use standard techniques, such as linear programs, to compute and analyze safe policies. We validate the proposed method numerically on the Double Integrator and the Inverted Pendulum systems. Results indicate that the average-reward MDPs solution is more comprehensive, converges faster, and offers higher quality compared to the minimum discounted-reward solution.

</details>


### [300] [Toward a Safety Argumentation Lifecycle for Automated Vehicles: Promoting Communication and Interdependency with System Lifecycle Processes](https://arxiv.org/abs/2511.08499)
*Marvin Loba,Robert Graubohm,Niklas Braun,Nayel Fabian Salem,Markus Maurer*

Main category: eess.SY

TL;DR: 本文提出并推导了自动驾驶汽车安全论证生命周期的要求，并引入了基于论证的表示支持通信概念，以实现透明的风险沟通，并将其整合到系统生命周期中。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车在开放环境中运行时存在固有的、不可完全消除的风险。核心挑战在于如何证明残余风险已降至合理水平。虽然安全论证是常用方法，但需要适当的流程来指导其创建和维护。

Method: 通过审查现有技术（state of the art），推导安全论证生命周期的要求，并设计以需求为导向的流程。随后，探讨安全论证生命周期与系统生命周期之间的相互依赖关系。最后，引入“表示支持的沟通”概念，以解决事前风险沟通的文献空白。

Result: 推导出了安全论证生命周期的要求，并设计了以需求为导向的流程。讨论了该生命周期与系统生命周期的相互关系。引入了基于从论证中为目标利益相关者和沟通目的推导表示的“表示支持的沟通”概念。展示了如何将该方法整合到系统生命周期中以促进利益相关者沟通。

Conclusion: 论文为自动驾驶汽车的安全论证提供了一个结构化的生命周期方法，并引入了一种新颖的、基于论证的表示支持沟通方法，以实现透明的事前风险沟通，从而促进利益相关者理解和接受残余风险。

Abstract: Despite the growing number of automated vehicles on public roads, operating such systems in open contexts will inevitably involve incidents. This results from an inherent risk in road traffic, which arises from multiple sources of complexity and can never be fully eliminated. One central challenge lies in developing a defensible case that the residual risk has been reduced to a reasonable level. While a safety argumentation is a common means to represent this case, there is a need to guide its creation and maintenance by adequate processes. In this paper, we derive requirements for a safety argumentation lifecycle based on examining the current state of the art. In particular, the requirement-driven process design accounts for both identified limitations of current process specifications and implicit knowledge contained in related work. Subsequently, we reflect on interdependencies between the resulting safety argumentation lifecycle and the system lifecycle. Moreover, we discuss a gap in literature regarding transparent ex ante risk communication. Correspondingly, we introduce the concept of representation-supported communication that is based on deriving representations from the argumentation with respect to target stakeholders and communication purposes. Finally, we demonstrate how this approach can be integrated into the system lifecycle to facilitate stakeholder communication.

</details>


### [301] [Computable Characterisations of Scaled Relative Graphs of Closed Operators](https://arxiv.org/abs/2511.08420)
*Talitha Nauta,Richard Pates*

Main category: eess.SY

TL;DR: 本文提出了一种基于最大和最小增益计算的方法，用于精确且可计算地构建闭合线性算子的尺度相对图（SRG），适用于有界和无界算子，并特别说明了其在线性时不变动态系统中的应用，以及如何利用有界实引理构建状态空间模型的SRG。


<details>
  <summary>Details</summary>
Motivation: 尺度相对图（SRG）为多输入多输出系统的稳定性和鲁棒性分析提供了有前景的工具。本研究旨在提供一种精确且可计算的SRG构建工具。

Method: 本文基于最大和最小增益计算，为闭合线性算子（包括有界和无界算子）提供SRG的构建方法。此外，针对状态空间模型，展示了如何利用有界实引理（Bounded Real Lemma）来构建SRG。

Result: 研究成果提供了精确且可计算的SRG构建工具，适用于闭合线性算子（包括有界和无界）。具体说明了如何将这些工具应用于建模线性时不变动态系统的典型算子。对于状态空间模型，展示了有界实引理在SRG构建中的应用。

Conclusion: 本文为各种线性系统提供了实用且可计算的尺度相对图（SRG）构建方法，从而增强了SRG在系统稳定性与鲁棒性分析中的应用价值。

Abstract: Scaled Relative Graphs (SRGs) provide a promising tool for stability and robustness analysis of multi-input-multi-output systems. In this paper, we provide tools for exact and computable constructions of the SRG for closed linear operators, based on maximum and minimum gain computations. The results are suitable for bounded and unbounded operators, and we specify how they can be used to draw SRGs for the typical operators that are used to model linear-time-invariant dynamical systems. Furthermore, for the special case of state-space models, we show how the Bounded Real Lemma can be used to construct the SRG.

</details>


### [302] [A bioreactor-based architecture for in vivo model-based and sim-to-real learning control of microbial consortium composition](https://arxiv.org/abs/2511.08554)
*Sara Maria Brancato,Davide Salzano,Davide Fiore,Francesco De Lellis,Giovanni Russo,Mario di Bernardo*

Main category: eess.SY

TL;DR: 本文提出一种无需基因工程或剧烈环境变化的通用控制架构，可精确稳定调节双菌株微生物群落的密度和组成，以解决其工业应用中稳定共存的挑战。


<details>
  <summary>Details</summary>
Motivation: 微生物群落在生物生产中比单培养具有显著优势，但其工业部署受限于缺乏可扩展的稳定共存架构。现有策略（基因改造或环境变化）存在代谢负荷或产量降低等缺点。

Method: 研究开发了一种基于生物反应器的控制架构，包括一个共培养两种菌株的混合室和一个维持慢速生长菌株的储罐。为这两个腔室开发了基于模型和“模拟到真实”学习控制器。

Result: 该控制架构在双菌株大肠杆菌群落中进行了体内验证，实现了对群落密度和组成的精确、鲁棒调节，包括跟踪时变参考和从扰动中恢复。

Conclusion: 本研究提出了一种通用且无需基因工程或剧烈环境变化的控制架构，成功解决了微生物群落的稳定共存问题，为生物生产提供了新的解决方案。

Abstract: Microbial consortia offer significant biotechnological advantages over monocultures for bioproduction. However, industrial deployment is hampered by the lack of scalable architectures to ensure stable coexistence between populations. Existing strategies rely on genetic modifications, which impose metabolic load, or environmental changes, which can reduce production. We present a versatile control architecture to regulate density and composition of a two-strain consortium without genetic engineering or drastic environmental changes. Our bioreactor-based control architecture comprises a mixing chamber where both strains are co-cultured and a reservoir sustaining the slower-growing strain. For both chambers we develop model-based and sim-to-real learning controllers. The control architecture is then validated in vivo on a two-strain Escherichia coli consortium, achieving precise and robust regulation of consortium density and composition, including tracking of time-varying references and recovery from perturbations.

</details>


### [303] [The curse of dimensionality: what lies beyond the capabilities of physics-informed neural networks](https://arxiv.org/abs/2511.08561)
*J. Penuela,H. Ouerdane*

Main category: eess.SY

TL;DR: 本研究通过RC低通滤波器案例，揭示了物理信息神经网络（PINNs）在正向问题中表现良好，但在参数数量超过两个时，无法在逆向问题中唯一恢复物理参数的局限性。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络（PINNs）在解决由微分方程控制的问题方面前景广阔，但其在病态逆问题中的可靠性仍不明确。

Method: 本研究使用一个简单的RC低通滤波器作为说明性案例，来探索PINNs的基本局限性。

Result: PINNs在正向问题中能准确预测系统动力学，但在解决逆问题时，当需要近似的参数超过两个时，PINNs无法恢复唯一的物理参数。

Conclusion: 研究结果为理解PINNs在物理系统参数发现中的适用边界提供了依据。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a promising framework for solving forward and inverse problems governed by differential equations. However, their reliability when used in ill-posed inverse problems remains poorly understood. In this study, we explore the fundamental limitations of PINNs using a simple illustrative case: RC low-pass filters. Showing that while PINNs can accurately predict system dynamics in forward problems, they fail to recover unique physical parameters when solving inverse problems when more than two parameters are approximated. Our findings provide grounds to understand the boundaries of PINNs applicability for parameter discovery in physical systems.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [304] [Deep generative priors for robust and efficient electron ptychography](https://arxiv.org/abs/2511.07795)
*Arthur R. C. McCray,Stephanie M. Ribet,Georgios Varnavides,Colin Ophus*

Main category: eess.IV

TL;DR: 本文提出了一种基于深度生成先验（DGP）的电子叠层成像框架，解决了传统算法噪声敏感、收敛慢和超参数调优复杂的问题，实现了更鲁棒、更快速、用户友好的原子分辨率成像，尤其适用于三维重建。


<details>
  <summary>Details</summary>
Motivation: 传统电子叠层成像重建算法存在对噪声敏感、收敛速度慢以及需要大量手动超参数调优进行正则化的问题，尤其是在三维多层重建中。

Method: 引入了深度生成先验（DGP）框架，利用卷积神经网络的隐式正则化来解决现有挑战。该框架使用两个DGP在自动微分混合态多层正向模型中参数化复值样品和探针。同时，采用了一种预训练策略来稳定重建过程。

Result: 与基于像素的重建相比，DGP提供了四大优势：(i) 在低剂量下具有更强的噪声鲁棒性和更高的信息极限；(ii) 显著更快的收敛速度，尤其是在低空间频率下；(iii) 改进了深度正则化；(iv) 最大限度地减少了用户指定的正则化。该框架能促进空间相干性并抑制高频噪声，无需大量调优。

Conclusion: DGP驱动的叠层成像是一种鲁棒的方法，它降低了专业知识门槛和计算成本，为各种材料和生物系统提供了鲁棒、高分辨率的成像能力。

Abstract: Electron ptychography enables dose-efficient atomic-resolution imaging, but conventional reconstruction algorithms suffer from noise sensitivity, slow convergence, and extensive manual hyperparameter tuning for regularization, especially in three-dimensional multislice reconstructions. We introduce a deep generative prior (DGP) framework for electron ptychography that uses the implicit regularization of convolutional neural networks to address these challenges. Two DGPs parameterize the complex-valued sample and probe within an automatic-differentiation mixed-state multislice forward model. Compared to pixel-based reconstructions, DGPs offer four key advantages: (i) greater noise robustness and improved information limits at low dose; (ii) markedly faster convergence, especially at low spatial frequencies; (iii) improved depth regularization; and (iv) minimal user-specified regularization. The DGP framework promotes spatial coherence and suppresses high-frequency noise without extensive tuning, and a pre-training strategy stabilizes reconstructions. Our results establish DGP-enabled ptychography as a robust approach that reduces expertise barriers and computational cost, delivering robust, high-resolution imaging across diverse materials and biological systems.

</details>


### [305] [DynaQuant: Dynamic Mixed-Precision Quantization for Learned Image Compression](https://arxiv.org/abs/2511.07903)
*Youneng Bao,Yulong Cheng,Yiping Liu,Yichen Yang,Peng Qin,Mu Li,Yongsheng Liang*

Main category: eess.IV

TL;DR: DynaQuant是一种用于学习图像压缩（LIC）的动态混合精度量化框架，通过内容感知量化和数据驱动的动态位宽选择，显著提升了性能与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的学习图像压缩（LIC）量化技术通常采用静态、统一的位宽，未能适应LIC模型中高度多样的数据分布和敏感性特征，导致性能与效率之间的权衡不佳。

Method: 该研究引入了DynaQuant框架，其方法包含两个互补层面：1) 内容感知量化，通过可学习的缩放和偏移参数动态适应潜在特征的统计变化，并使用新型的距离感知梯度调制器（DGM）进行端到端训练；2) 数据驱动的动态位宽选择器，学习为每个层分配最佳位精度，并根据输入数据动态重新配置网络的精度配置文件。

Result: DynaQuant在实现与全精度模型相当的码率-失真（R-D）性能的同时，显著降低了计算和存储需求。

Conclusion: DynaQuant的完全动态方法在平衡R-D性能和计算成本方面提供了极大的灵活性，从而使先进的LIC技术能够在不同的硬件平台上进行实际部署。

Abstract: Prevailing quantization techniques in Learned Image Compression (LIC) typically employ a static, uniform bit-width across all layers, failing to adapt to the highly diverse data distributions and sensitivity characteristics inherent in LIC models. This leads to a suboptimal trade-off between performance and efficiency. In this paper, we introduce DynaQuant, a novel framework for dynamic mixed-precision quantization that operates on two complementary levels. First, we propose content-aware quantization, where learnable scaling and offset parameters dynamically adapt to the statistical variations of latent features. This fine-grained adaptation is trained end-to-end using a novel Distance-aware Gradient Modulator (DGM), which provides a more informative learning signal than the standard Straight-Through Estimator. Second, we introduce a data-driven, dynamic bit-width selector that learns to assign an optimal bit precision to each layer, dynamically reconfiguring the network's precision profile based on the input data. Our fully dynamic approach offers substantial flexibility in balancing rate-distortion (R-D) performance and computational cost. Experiments demonstrate that DynaQuant achieves rd performance comparable to full-precision models while significantly reducing computational and storage requirements, thereby enabling the practical deployment of advanced LIC on diverse hardware platforms.

</details>


### [306] [From Noise to Latent: Generating Gaussian Latents for INR-Based Image Compression](https://arxiv.org/abs/2511.08009)
*Chaoyi Lin,Yaojun Wu,Yue Li,Junru Li,Kai Zhang,Li Zhang*

Main category: eess.IV

TL;DR: 本文提出了一种新颖的图像压缩范式，通过从共享随机种子确定性生成的多尺度高斯噪声张量中重建图像特定的潜在表示，消除了传输潜在代码的需要，同时实现了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于隐式神经表示（INR）的图像压缩方法在表现力上不如端到端（E2E）方法，而E2E方法又需要传输复杂的潜在代码和熵模型，增加了解码复杂性。受E2E编解码器将潜在表示转换为高斯噪声以去除空间冗余的启发，本文探索了逆向过程：直接从高斯噪声生成潜在表示。

Method: 本文提出通过一个高斯参数预测（GPP）模块，从一个由共享随机种子确定性生成的多尺度高斯噪声张量中，预测图像特定潜在表示的分布参数。然后，通过重参数化技巧进行一次性潜在生成，并将生成的潜在表示输入合成网络以重建图像。这种方法消除了传输潜在代码的需要。

Result: 该方法在Kodak和CLIC数据集上实现了有竞争力的速率-失真性能。据作者所知，这是首次探索利用高斯潜在生成进行学习型图像压缩的工作。

Conclusion: 该方法成功地消除了传输潜在代码的必要性，同时保留了基于潜在表示的优势，并在图像压缩方面取得了有竞争力的速率-失真性能，开创了从高斯噪声直接生成潜在表示的新途径。

Abstract: Recent implicit neural representation (INR)-based image compression methods have shown competitive performance by overfitting image-specific latent codes. However, they remain inferior to end-to-end (E2E) compression approaches due to the absence of expressive latent representations. On the other hand, E2E methods rely on transmitting latent codes and requiring complex entropy models, leading to increased decoding complexity. Inspired by the normalization strategy in E2E codecs where latents are transformed into Gaussian noise to demonstrate the removal of spatial redundancy, we explore the inverse direction: generating latents directly from Gaussian noise. In this paper, we propose a novel image compression paradigm that reconstructs image-specific latents from a multi-scale Gaussian noise tensor, deterministically generated using a shared random seed. A Gaussian Parameter Prediction (GPP) module estimates the distribution parameters, enabling one-shot latent generation via reparameterization trick. The predicted latent is then passed through a synthesis network to reconstruct the image. Our method eliminates the need to transmit latent codes while preserving latent-based benefits, achieving competitive rate-distortion performance on Kodak and CLIC dataset. To the best of our knowledge, this is the first work to explore Gaussian latent generation for learned image compression.

</details>


### [307] [Deep Learning Analysis of Prenatal Ultrasound for Identification of Ventriculomegaly](https://arxiv.org/abs/2511.07827)
*Youssef Megahed,Inok Lee,Robin Ducharme,Aylin Erman,Olivier X. Miguel,Kevin Dick,Adrian D. C. Chan,Steven Hawken,Mark Walker,Felipe Moretti*

Main category: eess.IV

TL;DR: 本研究开发并微调了一个基于自监督学习的深度学习模型（USF-MAE），用于在产前超声图像中检测胎儿脑室扩张，该模型表现出卓越的性能和良好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 胎儿脑室扩张是一种重要的产前疾病，早期诊断至关重要，因为它与胎儿非整倍体和/或潜在遗传综合征的风险增加有关。

Method: 研究采用了一个名为USF-MAE（带有掩蔽自编码的超声自监督基础模型）的深度学习模型。该模型包含一个Vision Transformer编码器，该编码器已在包含超过370,000张超声图像的OpenUS-46语料库上进行了预训练。预训练的编码器在一个精选的胎儿脑超声图像数据集上进行了微调，以执行正常或脑室扩张的二元分类任务。模型通过5折交叉验证和独立的测试队列进行评估，并使用准确率、精确度、召回率、特异性、F1分数和ROC曲线下面积（AUC）等指标进行量化。同时使用Eigen-CAM热图评估模型的可解释性。

Result: USF-MAE模型在5折交叉验证中达到了91.76%的F1分数，在独立测试集中达到了91.78%的F1分数。与基线模型（VGG-19、ResNet-50、ViT-B/16）相比，F1分数分别高出19.37%和16.15%、2.31%和2.56%、5.03%和11.93%。模型还显示出94.47%的高平均测试精确度和97.24%的准确率。Eigen-CAM热图显示模型在诊断脑室扩张时聚焦于心室区域，这具有可解释性和临床合理性。

Conclusion: 本研究开发的USF-MAE模型在产前超声图像中检测胎儿脑室扩张方面表现出卓越的性能，显著优于现有基线模型，并且具有良好的临床可解释性，有望支持早期诊断。

Abstract: The proposed study aimed to develop a deep learning model capable of detecting ventriculomegaly on prenatal ultrasound images. Ventriculomegaly is a prenatal condition characterized by dilated cerebral ventricles of the fetal brain and is important to diagnose early, as it can be associated with an increased risk for fetal aneuploidies and/or underlying genetic syndromes. An Ultrasound Self-Supervised Foundation Model with Masked Autoencoding (USF-MAE), recently developed by our group, was fine-tuned for a binary classification task to distinguish fetal brain ultrasound images as either normal or showing ventriculomegaly. The USF-MAE incorporates a Vision Transformer encoder pretrained on more than 370,000 ultrasound images from the OpenUS-46 corpus. For this study, the pretrained encoder was adapted and fine-tuned on a curated dataset of fetal brain ultrasound images to optimize its performance for ventriculomegaly detection. Model evaluation was conducted using 5-fold cross-validation and an independent test cohort, and performance was quantified using accuracy, precision, recall, specificity, F1-score, and area under the receiver operating characteristic curve (AUC). The proposed USF-MAE model reached an F1-score of 91.76% on the 5-fold cross-validation and 91.78% on the independent test set, with much higher scores than those obtained by the baseline models by 19.37% and 16.15% compared to VGG-19, 2.31% and 2.56% compared to ResNet-50, and 5.03% and 11.93% compared to ViT-B/16, respectively. The model also showed a high mean test precision of 94.47% and an accuracy of 97.24%. The Eigen-CAM (Eigen Class Activation Map) heatmaps showed that the model was focusing on the ventricle area for the diagnosis of ventriculomegaly, which has explainability and clinical plausibility.

</details>


### [308] [EvoPS: Evolutionary Patch Selection for Whole Slide Image Analysis in Computational Pathology](https://arxiv.org/abs/2511.07560)
*Saya Hashemian,Azam Asilian Bidgoli*

Main category: eess.IV

TL;DR: EvoPS是一个新颖的进化式补丁选择框架，它将补丁选择公式化为多目标优化问题，旨在同时最小化所选补丁的数量并最大化下游任务性能，从而显著减少计算量并保持或提高数字病理学中的诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中的全玻片图像（WSI）规模巨大，需要分割成数千个小补丁。分析这些高维补丁嵌入计算成本高昂，且许多无信息补丁可能稀释关键诊断信号。现有的补丁选择方法（如随机采样或简单聚类启发式）未能明确管理所选补丁数量与最终玻片表示准确性之间的关键权衡。

Method: 本文提出了EvoPS（Evolutionary Patch Selection）框架，将补丁选择建模为一个多目标优化问题。它利用进化搜索同时最小化所选补丁嵌入的数量并最大化下游相似性搜索任务的性能，从而生成一系列最优权衡解决方案的帕累托前沿。

Result: EvoPS框架在四个主要的TCGA癌症队列上，使用五种预训练深度学习模型（包括监督CNN和自监督基础模型）进行了验证。结果表明，EvoPS可以将所需的训练补丁嵌入数量减少90%以上，同时与使用所有可用补丁嵌入的基线相比，能够持续保持甚至提高最终分类的F1分数。

Conclusion: EvoPS框架提供了一种强大且有原则的方法，用于创建高效、准确和可解释的WSI表示。它使用户能够灵活选择计算成本和诊断性能之间的最佳平衡，从而赋能计算病理学应用。

Abstract: In computational pathology, the gigapixel scale of Whole-Slide Images (WSIs) necessitates their division into thousands of smaller patches. Analyzing these high-dimensional patch embeddings is computationally expensive and risks diluting key diagnostic signals with many uninformative patches. Existing patch selection methods often rely on random sampling or simple clustering heuristics and typically fail to explicitly manage the crucial trade-off between the number of selected patches and the accuracy of the resulting slide representation. To address this gap, we propose EvoPS (Evolutionary Patch Selection), a novel framework that formulates patch selection as a multi-objective optimization problem and leverages an evolutionary search to simultaneously minimize the number of selected patch embeddings and maximize the performance of a downstream similarity search task, generating a Pareto front of optimal trade-off solutions. We validated our framework across four major cancer cohorts from The Cancer Genome Atlas (TCGA) using five pretrained deep learning models to generate patch embeddings, including both supervised CNNs and large self-supervised foundation models. The results demonstrate that EvoPS can reduce the required number of training patch embeddings by over 90% while consistently maintaining or even improving the final classification F1-score compared to a baseline that uses all available patches' embeddings selected through a standard extraction pipeline. The EvoPS framework provides a robust and principled method for creating efficient, accurate, and interpretable WSI representations, empowering users to select an optimal balance between computational cost and diagnostic performance.

</details>
