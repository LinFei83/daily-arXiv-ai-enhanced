<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 23]
- [cs.CV](#cs.CV) [Total: 75]
- [cs.CL](#cs.CL) [Total: 77]
- [cs.RO](#cs.RO) [Total: 25]
- [eess.SY](#eess.SY) [Total: 12]
- [eess.IV](#eess.IV) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Test-time Verification via Optimal Transport: Coverage, ROC, & Sub-optimality](https://arxiv.org/abs/2510.18982)
*Arpan Mukherjee,Marcello Bullo,Debabrota Basu,Deniz Gündüz*

Main category: cs.AI

TL;DR: 本文将可验证测试时扩展（test-time scaling with verification）视为一个传输问题，量化了生成器覆盖率、验证器收敛区域（ROC）和采样算法次优性之间的相互作用。研究发现次优性-覆盖率曲线呈现三种机制：传输、策略改进和饱和，并分析了序列和批量采样算法的计算复杂性如何影响这些权衡。


<details>
  <summary>Details</summary>
Motivation: 尽管带有验证的测试时扩展在提高大型语言模型（LLMs）性能方面显示出前景，但验证器的作用及其缺陷仍未得到充分探索。目前缺乏一个统一的框架来量化生成器覆盖率、验证器收敛区域（ROC）和采样算法次优性这三个关键因素之间的几何相互作用。

Method: 研究将可验证测试时扩展问题构建为一个传输问题，以刻画覆盖率、ROC和次优性之间的相互作用。此外，本文提出并分析了两类采样算法（序列式和批量式），并考察了它们的计算复杂性如何塑造这些权衡。

Result: 通过传输问题框架，研究揭示了次优性-覆盖率曲线存在三种机制：传输机制（次优性随覆盖率增加）、策略改进机制（次优性可能随覆盖率减少，取决于验证器ROC）和饱和机制（次优性趋于平稳，不受覆盖率影响）。同时，研究分析了采样算法的计算复杂性对这些权衡的影响。Qwen、Llama和Gemma模型的实证结果证实了理论发现。

Conclusion: 本文提供了一个统一的框架来理解LLMs中带有验证的测试时扩展，通过量化生成器覆盖率、验证器ROC和采样次优性之间的复杂相互作用，揭示了关键的性能机制。研究还分析了不同采样算法的计算复杂性，为实际应用提供了指导，并得到了经验验证。

Abstract: While test-time scaling with verification has shown promise in improving the
performance of large language models (LLMs), the role of the verifier and its
imperfections remain underexplored. The effect of verification manifests
through interactions of three quantities: (i) the generator's coverage, (ii)
the verifier's region of convergence (ROC), and (iii) the sampling algorithm's
sub-optimality. Though recent studies capture subsets of these factors, a
unified framework quantifying the geometry of their interplay is missing. We
frame verifiable test-time scaling as a transport problem. This characterizes
the interaction of coverage, ROC, and sub-optimality, and uncovers that the
sub-optimality--coverage curve exhibits three regimes. A transport regime --
where sub-optimality increases with coverage, a policy improvement regime --
where sub-optimality may decrease with coverage, depending on the verifier's
ROC, and a saturation regime -- where sub-optimality plateaus, unaffected by
coverage. We further propose and analyze two classes of sampling algorithms --
sequential and batched, and examine how their computational complexities shape
these trade-offs. Empirical results with Qwen, Llama, and Gemma models
corroborate our theoretical findings.

</details>


### [2] [Timely Clinical Diagnosis through Active Test Selection](https://arxiv.org/abs/2510.18988)
*Silas Ruhrberg Estévez,Nicolás Astorga,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 本文提出ACTMED框架，结合贝叶斯实验设计（BED）和大型语言模型（LLM），旨在模拟临床医生在实际诊断中循序渐进、考虑资源限制的推理过程，以实现自适应的临床测试选择，提高诊断准确性和资源效率。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习诊断方法多依赖静态、完整观测的数据集，未能反映临床医生在实践中循序渐进、考虑资源限制的推理过程。在高压或资源有限环境下，诊断复杂且易出错，因此需要能帮助临床医生及时、经济地做出决策的框架。

Method: 本文提出了ACTMED（Adaptive Clinical Test selection via Model-based Experimental Design）诊断框架。该框架将贝叶斯实验设计（BED）与大型语言模型（LLM）相结合，在每个步骤中选择预期能最大程度减少诊断不确定性的测试。LLM作为灵活的模拟器，生成合理的患者状态分布并支持信念更新，无需结构化的任务特定训练数据。临床医生可全程参与，审查测试建议、解释中间输出并应用临床判断。

Result: ACTMED在真实世界数据集上进行评估，结果表明它能优化测试选择，从而提高诊断准确性、可解释性和资源利用率。

Conclusion: ACTMED代表着向透明、自适应、与临床医生保持一致的诊断系统迈进了一步，该系统能够跨不同环境泛化，并减少对特定领域数据的依赖。

Abstract: There is growing interest in using machine learning (ML) to support clinical
diag- nosis, but most approaches rely on static, fully observed datasets and
fail to reflect the sequential, resource-aware reasoning clinicians use in
practice. Diagnosis remains complex and error prone, especially in
high-pressure or resource-limited settings, underscoring the need for
frameworks that help clinicians make timely and cost-effective decisions. We
propose ACTMED (Adaptive Clinical Test selection via Model-based Experimental
Design), a diagnostic framework that integrates Bayesian Experimental Design
(BED) with large language models (LLMs) to better emulate real-world diagnostic
reasoning. At each step, ACTMED selects the test expected to yield the greatest
reduction in diagnostic uncertainty for a given patient. LLMs act as flexible
simulators, generating plausible patient state distributions and supporting
belief updates without requiring structured, task-specific training data.
Clinicians can remain in the loop; reviewing test suggestions, interpreting
intermediate outputs, and applying clinical judgment throughout. We evaluate
ACTMED on real-world datasets and show it can optimize test selection to
improve diagnostic accuracy, interpretability, and resource use. This
represents a step to- ward transparent, adaptive, and clinician-aligned
diagnostic systems that generalize across settings with reduced reliance on
domain-specific data.

</details>


### [3] [Rectifying Shortcut Behaviors in Preference-based Reward Learning](https://arxiv.org/abs/2510.19050)
*Wenqian Ye,Guangtao Zheng,Aidong Zhang*

Main category: cs.AI

TL;DR: 本文提出PRISM方法，通过学习组不变核来缓解基于偏好的奖励模型中存在的捷径行为（奖励欺骗问题），从而提高模型在域外任务上的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在人类反馈强化学习中，基于偏好的奖励模型易受奖励欺骗和过度优化影响，通过利用训练数据中与人类偏好相关的虚假特征（如冗长、讨好语气）而非真正反映预期目标，导致泛化能力差和模型依赖捷径。

Method: 本文将奖励欺骗问题视为捷径行为，并提出一种原则性且灵活的方法——基于偏好的奖励不变性捷径缓解（PRISM）。该方法受核视角中不变理论的启发，通过闭式学习目标学习具有特征映射的组不变核。

Result: 在多个基准测试中的实验结果表明，PRISM方法持续提高了奖励模型在各种域外（OOD）任务上的准确性，并减少了下游策略模型对捷径的依赖。

Conclusion: PRISM为基于偏好的对齐提供了一个鲁棒的框架，有效缓解了奖励学习中的捷径行为，从而提高了模型的泛化能力和稳健性。

Abstract: In reinforcement learning from human feedback, preference-based reward models
play a central role in aligning large language models to human-aligned
behavior. However, recent studies show that these models are prone to reward
hacking and often fail to generalize well due to over-optimization. They
achieve high reward scores by exploiting shortcuts, that is, exploiting
spurious features (e.g., response verbosity, agreeable tone, or sycophancy)
that correlate with human preference labels in the training data rather than
genuinely reflecting the intended objectives. In this paper, instead of probing
these issues one at a time, we take a broader view of the reward hacking
problem as shortcut behaviors and introduce a principled yet flexible approach
to mitigate shortcut behaviors in preference-based reward learning. Inspired by
the invariant theory in the kernel perspective, we propose Preference-based
Reward Invariance for Shortcut Mitigation (PRISM), which learns group-invariant
kernels with feature maps in a closed-form learning objective. Experimental
results in several benchmarks show that our method consistently improves the
accuracy of the reward model on diverse out-of-distribution tasks and reduces
the dependency on shortcuts in downstream policy models, establishing a robust
framework for preference-based alignment.

</details>


### [4] [The MUSE Benchmark: Probing Music Perception and Auditory Relational Reasoning in Audio LLMS](https://arxiv.org/abs/2510.19055)
*Brandon James Carone,Iran R. Roman,Pablo Ripollés*

Main category: cs.AI

TL;DR: MLLM在音乐理解方面存在关系推理的根本弱点。MUSE基准测试揭示了SOTA模型与人类专家之间的巨大差距，并发现CoT提示效果不佳。


<details>
  <summary>Details</summary>
Motivation: 现有对多模态大语言模型（MLLM）音频理解能力的评估可能掩盖了它们在关系推理方面的基本弱点，尤其是在音乐理解领域。需要一个更深入、能探测基本音乐感知技能的评估工具。

Method: 引入了Music Understanding and Structural Evaluation (MUSE) 基准测试，这是一个包含10项任务的开源资源，旨在探测基本的音乐感知技能。评估了四种SOTA模型（Gemini Pro和Flash、Qwen2.5-Omni和Audio-Flamingo 3），并将其结果与200人的大型人类基线进行比较。同时，也探究了思维链（CoT）提示的效果。

Result: SOTA模型的能力表现出巨大差异，且与人类专家存在持续差距。Gemini Pro在基本感知任务上表现良好，但Qwen和Audio Flamingo 3的表现接近随机，暴露出严重的感知缺陷。此外，思维链（CoT）提示提供了不一致且通常有害的结果。

Conclusion: MUSE基准测试为评估不变音乐表示和推动开发更鲁棒的AI系统提供了一个关键工具。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated capabilities in
audio understanding, but current evaluations may obscure fundamental weaknesses
in relational reasoning. We introduce the Music Understanding and Structural
Evaluation (MUSE) Benchmark, an open-source resource with 10 tasks designed to
probe fundamental music perception skills. We evaluate four SOTA models (Gemini
Pro and Flash, Qwen2.5-Omni, and Audio-Flamingo 3) against a large human
baseline (N=200). Our results reveal a wide variance in SOTA capabilities and a
persistent gap with human experts. While Gemini Pro succeeds on basic
perception, Qwen and Audio Flamingo 3 perform at or near chance, exposing
severe perceptual deficits. Furthermore, we find Chain-of-Thought (CoT)
prompting provides inconsistent, often detrimental results. Our work provides a
critical tool for evaluating invariant musical representations and driving
development of more robust AI systems.

</details>


### [5] [A Multi-faceted Analysis of Cognitive Abilities: Evaluating Prompt Methods with Large Language Models on the CONSORT Checklist](https://arxiv.org/abs/2510.19139)
*Sohyeon Jeon,Hyung-Chul Lee*

Main category: cs.AI

TL;DR: 本研究评估了大型语言模型（LLMs）在根据CONSORT标准评估临床试验报告方面的能力，发现它们存在局限性，并强调了提示类型对模型推理方式的影响，这对于开发更可靠的医疗AI至关重要。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在医疗保健领域迅速发展，但它们评估临床试验报告（依据CONSORT标准）的能力及其认知和推理策略尚不明确。

Method: 本研究采用行为和元认知分析方法，使用专家验证的数据，系统地比较了两种代表性LLMs在三种不同提示条件下的表现。

Result: 研究发现，模型在处理不同的CONSORT项目时表现出明显的差异，并且提示类型（包括推理风格的转变、明确的不确定性以及替代解释）影响了响应模式。结果突显了这些系统在临床合规自动化方面的当前局限性。

Conclusion: 本研究强调了理解LLMs的认知适应和策略行为的重要性，以便开发出更具可解释性和可靠性的医疗AI，尤其是在当前系统在临床合规自动化方面存在局限性的背景下。

Abstract: Despite the rapid expansion of Large Language Models (LLMs) in healthcare,
the ability of these systems to assess clinical trial reporting according to
CONSORT standards remains unclear, particularly with respect to their cognitive
and reasoning strategies. This study applies a behavioral and metacognitive
analytic approach with expert-validated data, systematically comparing two
representative LLMs under three prompt conditions. Clear differences emerged in
how the models approached various CONSORT items, and prompt types, including
shifts in reasoning style, explicit uncertainty, and alternative
interpretations shaped response patterns. Our results highlight the current
limitations of these systems in clinical compliance automation and underscore
the importance of understanding their cognitive adaptations and strategic
behavior in developing more explainable and reliable medical AI.

</details>


### [6] [The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early Exit in Reasoning Models](https://arxiv.org/abs/2510.19176)
*Yuqiao Tan,Shizhu He,Kang Liu,Jun Zhao*

Main category: cs.AI

TL;DR: 推理模型在逐步思考中常出现过度思考，导致计算开销。本文将模式选择（决定长/短CoT）视为早期退出（决定最佳停止点）的一个更具挑战性的变体，因为它需要在推理开始时基于零步思考做决策。实证研究发现，现有方法，特别是基于提示的方法，在信息有限的情况下难以有效解决模式选择问题。


<details>
  <summary>Details</summary>
Motivation: 推理模型在数学和逻辑推理等任务中表现出色，但其逐步思考过程常导致过度思考，产生不必要的计算开销。研究旨在通过模式选择和早期退出等方法来减少这种计算负担。

Method: 本文首先将模式选择（在推理开始时决定长/短CoT）定义为早期退出（在迭代推理过程中确定最佳停止点）的一个更具挑战性的变体。随后，通过对九个基线模型进行实证研究，比较了基于提示的方法和利用内部信息的方法在模式选择任务上的表现。

Result: 基于提示的方法因其有限的分类能力，在仅提供少量手工信息时常表现不佳。利用模型内部信息的方法在大多数情况下表现较好，但稳定性不足。研究表明，现有方法仅依赖模型提供的信息不足以有效解决信息有限情景下的模式选择问题。

Conclusion: 模式选择是一个持续存在的挑战性任务，尤其是在信息有限的情况下。现有方法，无论是基于提示还是利用内部信息，都无法有效且稳定地解决模式选择问题，这凸显了该领域仍需进一步研究。

Abstract: Reasoning models have demonstrated exceptional performance in tasks such as
mathematics and logical reasoning, primarily due to their ability to engage in
step-by-step thinking during the reasoning process. However, this often leads
to overthinking, resulting in unnecessary computational overhead. To address
this issue, Mode Selection aims to automatically decide between Long-CoT
(Chain-of-Thought) or Short-CoT by utilizing either a Thinking or NoThinking
mode. Simultaneously, Early Exit determines the optimal stopping point during
the iterative reasoning process. Both methods seek to reduce the computational
burden. In this paper, we first identify Mode Selection as a more challenging
variant of the Early Exit problem, as they share similar objectives but differ
in decision timing. While Early Exit focuses on determining the best stopping
point for concise reasoning at inference time, Mode Selection must make this
decision at the beginning of the reasoning process, relying on pre-defined fake
thoughts without engaging in an explicit reasoning process, referred to as
zero-step thinking. Through empirical studies on nine baselines, we observe
that prompt-based approaches often fail due to their limited classification
capabilities when provided with minimal hand-crafted information. In contrast,
approaches that leverage internal information generally perform better across
most scenarios but still exhibit issues with stability. Our findings indicate
that existing methods relying solely on the information provided by models are
insufficient for effectively addressing Mode Selection in scenarios with
limited information, highlighting the ongoing challenges of this task. Our code
is available at https://github.com/Trae1ounG/Zero_Step_Thinking.

</details>


### [7] [WebGraphEval: Multi-Turn Trajectory Evaluation for Web Agents using Graph Representation](https://arxiv.org/abs/2510.19205)
*Yaoyao Qian,Yuanli Wang,Jinda Zhang,Yun Zong,Meixu Chen,Hanhan Zhou,Jindan Huang,Yifan Zeng,Xinyu Hu,Chan Hee Song,Danqing Zhang*

Main category: cs.AI

TL;DR: WebGraphEval是一个用于评估网络代理的新框架，它将多代理轨迹抽象为统一的加权动作图，以捕捉结构多样性、识别冗余和低效，并发现被传统二元指标忽视的关键决策点。


<details>
  <summary>Details</summary>
Motivation: 当前对网络代理的评估主要局限于二元成功指标或单一参考轨迹，忽略了基准数据集中存在的结构多样性。

Method: WebGraphEval框架将多个代理的轨迹抽象为一个统一的、加权的动作图。它规范化编码动作，合并重复行为，并应用结构分析，包括奖励传播和成功加权边缘统计。该框架直接兼容WebArena等基准测试。

Result: 对来自六个网络代理的数千条轨迹进行评估表明，图抽象能够捕捉跨模型规律性，突出冗余和低效率，并识别出被基于结果的指标所忽视的关键决策点。

Conclusion: WebGraphEval通过将网络交互框定为图结构数据，建立了一种通用方法，用于对网络代理进行多路径、跨代理和效率感知的评估。

Abstract: Current evaluation of web agents largely reduces to binary success metrics or
conformity to a single reference trajectory, ignoring the structural diversity
present in benchmark datasets. We present WebGraphEval, a framework that
abstracts trajectories from multiple agents into a unified, weighted action
graph. This representation is directly compatible with benchmarks such as
WebArena, leveraging leaderboard runs and newly collected trajectories without
modifying environments. The framework canonically encodes actions, merges
recurring behaviors, and applies structural analyses including reward
propagation and success-weighted edge statistics. Evaluations across thousands
of trajectories from six web agents show that the graph abstraction captures
cross-model regularities, highlights redundancy and inefficiency, and
identifies critical decision points overlooked by outcome-based metrics. By
framing web interaction as graph-structured data, WebGraphEval establishes a
general methodology for multi-path, cross-agent, and efficiency-aware
evaluation of web agents.

</details>


### [8] [An Argumentative Explanation Framework for Generalized Reason Model with Inconsistent Precedents](https://arxiv.org/abs/2510.19263)
*Wachara Fungwacharakorn,Gauvain Bourgne,Ken Satoh*

Main category: cs.AI

TL;DR: 本文针对包含不一致先例的广义推理模型，提出扩展推导状态论证框架（DSA-framework），以提供论证性解释。


<details>
  <summary>Details</summary>
Motivation: 传统的案例推理（AI与法律领域）假设先例集必须一致。虽然已引入广义推理模型来处理不一致先例，但目前缺乏针对这种广义推理框架的论证性解释方法。

Method: 本文通过考察和扩展推导状态论证框架（DSA-framework）来解释基于广义推理模型的推理过程。

Result: 提出了一种扩展的DSA-framework，用于解释根据广义推理模型进行的推理，该模型能够容纳不一致的先例。

Conclusion: 该扩展框架为处理不一致先例的广义推理模型提供了一种论证性解释方法，填补了现有研究的空白。

Abstract: Precedential constraint is one foundation of case-based reasoning in AI and
Law. It generally assumes that the underlying set of precedents must be
consistent. To relax this assumption, a generalized notion of the reason model
has been introduced. While several argumentative explanation approaches exist
for reasoning with precedents based on the traditional consistent reason model,
there has been no corresponding argumentative explanation method developed for
this generalized reasoning framework accommodating inconsistent precedents. To
address this question, this paper examines an extension of the derivation state
argumentation framework (DSA-framework) to explain the reasoning according to
the generalized notion of the reason model.

</details>


### [9] [ChatGPT Unveils Its Limits: Principles of Law Deliver Checkmate](https://arxiv.org/abs/2510.19261)
*Marianna Molinari,Ilaria Angela Amantea,Marinella Quaranta,Guido Governatori*

Main category: cs.AI

TL;DR: 本研究通过法律领域的实验，发现ChatGPT在全面推理和整合知识以得出详尽结果方面存在重大局限，其表现不如正则表达式基线。


<details>
  <summary>Details</summary>
Motivation: 法律领域中，从法律判决中提取关键法律原则是一项至关重要的任务，需要全面理解和推理能力，研究旨在评估ChatGPT在此类复杂任务中的表现。

Method: 研究通过在法律领域进行实验，评估ChatGPT的表现，并将其结果与使用正则表达式（Regex）的基线进行比较，而非仅仅与人类表现对比。

Result: 研究显示，即使ChatGPT具备必要知识和能力，它也无法有效整合和推理，从而无法得出详尽的结果。这揭示了ChatGPT在全面理解和推理方面的重大局限性，表明人工智能缺乏全面的理解和推理能力。

Conclusion: 在法律领域，真正的智能，即分解复杂问题、整合多种能力并提供统一全面解决方案的能力，仍然是人类独有的特质，人工智能在此方面存在固有限制。

Abstract: This study examines the performance of ChatGPT with an experiment in the
legal domain. We compare the outcome with it a baseline using regular
expressions (Regex), rather than focusing solely on the assessment against
human performance. The study reveals that even if ChatGPT has access to the
necessary knowledge and competencies, it is unable to assemble them, reason
through, in a way that leads to an exhaustive result. This unveils a major
limitation of ChatGPT. Intelligence encompasses the ability to break down
complex issues and address them according to multiple required competencies,
providing a unified and comprehensive solution. In the legal domain, one of the
most crucial tasks is reading legal decisions and extracting key passages
condensed from principles of law (PoLs), which are then incorporated into
subsequent rulings by judges or defense documents by lawyers. In performing
this task, artificial intelligence lacks an all-encompassing understanding and
reasoning, which makes it inherently limited. Genuine intelligence, remains a
uniquely human trait, at least in this particular field.

</details>


### [10] [Learning to Make Friends: Coaching LLM Agents toward Emergent Social Ties](https://arxiv.org/abs/2510.19299)
*Philipp J. Schneider,Lin Tian,Marian-Andrei Rizoiu*

Main category: cs.AI

TL;DR: 该研究提出了一个多智能体LLM模拟框架，通过上下文学习和教练信号，使LLM智能体能够再现人类在线行为的复杂社会动态，包括同质性、互惠性和社会验证。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨大型语言模型（LLM）智能体是否能重现人类在线行为中复杂的社会动态（如同质性、互惠性、社会验证），以及哪些记忆和学习机制促成了这些动态的出现。

Method: 研究采用了一个多智能体LLM模拟框架，智能体通过重复互动、相互评估，并通过教练信号加速的上下文学习来调整行为。为模拟人类社会行为，设计了行为奖励函数，捕捉了在线互动的核心驱动因素，包括社会互动、信息寻求、自我展示、协调和情感支持。

Result: 实验结果表明，经过指导的LLM智能体形成了稳定的互动模式和新兴的社会关系，产生了与真实在线社区特征相似的网络结构。

Conclusion: 该框架结合行为奖励和上下文适应，为研究LLM群体中的集体动态建立了一个原则性的试验平台，并揭示了人工智能智能体如何近似或偏离类人社会行为。

Abstract: Can large language model (LLM) agents reproduce the complex social dynamics
that characterize human online behavior -- shaped by homophily, reciprocity,
and social validation -- and what memory and learning mechanisms enable such
dynamics to emerge? We present a multi-agent LLM simulation framework in which
agents repeatedly interact, evaluate one another, and adapt their behavior
through in-context learning accelerated by a coaching signal. To model human
social behavior, we design behavioral reward functions that capture core
drivers of online engagement, including social interaction, information
seeking, self-presentation, coordination, and emotional support. These rewards
align agent objectives with empirically observed user motivations, enabling the
study of how network structures and group formations emerge from individual
decision-making. Our experiments show that coached LLM agents develop stable
interaction patterns and form emergent social ties, yielding network structures
that mirror properties of real online communities. By combining behavioral
rewards with in-context adaptation, our framework establishes a principled
testbed for investigating collective dynamics in LLM populations and reveals
how artificial agents may approximate or diverge from human-like social
behavior.

</details>


### [11] [Continual Knowledge Adaptation for Reinforcement Learning](https://arxiv.org/abs/2510.19314)
*Jinwu Hu,Zihao Lian,Zhiquan Wen,Chenghao Li,Guohao Chen,Xutao Wen,Bin Xiao,Mingkui Tan*

Main category: cs.AI

TL;DR: 针对非平稳环境下的持续强化学习，本文提出CKA-RL方法，通过持续知识适应和自适应知识合并机制，有效解决了灾难性遗忘和知识利用效率低下的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界环境通常是非平稳的，要求智能体持续适应新任务和变化条件。现有持续强化学习方法常面临灾难性遗忘和知识利用效率低下的问题。

Method: 本文提出持续知识适应强化学习（CKA-RL）。具体方法包括：1) 持续知识适应策略：维护一个任务特定的知识向量池，动态利用历史知识来适应新任务，通过保留和调整关键模型参数来缓解灾难性遗忘并实现高效知识迁移。2) 自适应知识合并机制：合并相似的知识向量以解决可扩展性挑战，减少内存需求并确保关键知识的保留。

Result: 在三个基准测试中，CKA-RL优于现有最先进的方法，整体性能提升4.20%，前向迁移能力提升8.02%。

Conclusion: CKA-RL通过积累和有效利用历史知识，成功解决了持续强化学习中灾难性遗忘和知识利用效率低下的挑战，显著提升了智能体在非平稳环境中的适应和学习能力。

Abstract: Reinforcement Learning enables agents to learn optimal behaviors through
interactions with environments. However, real-world environments are typically
non-stationary, requiring agents to continuously adapt to new tasks and
changing conditions. Although Continual Reinforcement Learning facilitates
learning across multiple tasks, existing methods often suffer from catastrophic
forgetting and inefficient knowledge utilization. To address these challenges,
we propose Continual Knowledge Adaptation for Reinforcement Learning (CKA-RL),
which enables the accumulation and effective utilization of historical
knowledge. Specifically, we introduce a Continual Knowledge Adaptation
strategy, which involves maintaining a task-specific knowledge vector pool and
dynamically using historical knowledge to adapt the agent to new tasks. This
process mitigates catastrophic forgetting and enables efficient knowledge
transfer across tasks by preserving and adapting critical model parameters.
Additionally, we propose an Adaptive Knowledge Merging mechanism that combines
similar knowledge vectors to address scalability challenges, reducing memory
requirements while ensuring the retention of essential knowledge. Experiments
on three benchmarks demonstrate that the proposed CKA-RL outperforms
state-of-the-art methods, achieving an improvement of 4.20% in overall
performance and 8.02% in forward transfer. The source code is available at
https://github.com/Fhujinwu/CKA-RL.

</details>


### [12] [MSC-Bench: A Rigorous Benchmark for Multi-Server Tool Orchestration](https://arxiv.org/abs/2510.19423)
*Jia-Kai Dong,I-Wei Huang,Chun-Tin Wu,Yi-Tien Tsai*

Main category: cs.AI

TL;DR: 本文介绍了MSC-Bench，一个用于评估LLM代理在分层模型-上下文协议（MCP）生态系统中进行多跳、端到端工具编排的大规模基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常孤立地评估工具，忽略了功能重叠和跨服务器编排等挑战，导致评估结果过于乐观。

Method: MSC-Bench通过构建“等效功能集”来建立真实值，从而实现F1分数等客观指标，并减少对“LLM作为评判者”评估的依赖。它被组织成一个五级课程，系统地测试代理从单工具编排到复杂跨服务器规划以及对范围外请求的鲁棒性。

Result: 实验表明，没有协同设计的策略，僵化的层级结构会阻碍性能；即使是最先进的代理在鲁棒性方面也表现出系统性弱点。

Conclusion: MSC-Bench提供了一个诊断框架，用于揭示这些局限性并指导开发更强大、更高效的工具使用代理。

Abstract: We introduce MSC-Bench, a large-scale benchmark for evaluating multi-hop,
end-to-end tool orchestration by LLM agents in a hierarchical Model-Context
Protocol (MCP) ecosystem. Existing benchmarks often evaluate tools in
isolation, ignoring challenges such as functional overlap and cross-server
orchestration, leading to overly optimistic assessments. MSC-Bench addresses
these gaps by constructing ground truth through 'equal function sets', allowing
objective metrics such as F1 score and reducing the dependency on
LLM-as-a-judge evaluation. Organized as a five-level curriculum, it
systematically tests agent capabilities from single-tool orchestration to
complex cross-server planning, and robustness to out-of-scope requests.
Experiments reveal that rigid hierarchies can hinder performance without
co-designed strategies, and even state-of-the-art agents exhibit systemic
weaknesses in robustness. MSC-Bench provides a diagnostic framework to expose
these limitations and guide the development of more capable and efficient
tool-using agents. The benchmark and resources are publicly available at
https://github.com/snooow1029/MSC_Bench.

</details>


### [13] [NeSyPr: Neurosymbolic Proceduralization For Efficient Embodied Reasoning](https://arxiv.org/abs/2510.19429)
*Wonje Choi,Jooyoung Kim,Honguk Woo*

Main category: cs.AI

TL;DR: NeSyPr是一种神经符号具身推理框架，通过将符号计划程序化，使语言模型代理能够在动态、资源受限的环境中进行高效、结构化和及时的推理，无需外部符号指导。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，由于延迟、连接性和资源限制，大规模推理引擎或符号规划器在线访问受限，这给语言模型应用于具身任务带来了挑战。

Method: NeSyPr框架通过神经符号程序化编译知识。首先，符号工具利用其声明性知识生成任务特定计划。然后，这些计划被转换为可组合的程序化表示，编码其隐式生产规则。这些组合后的程序无缝集成到语言模型的推理过程中，将多步符号推理抽象并泛化为单步语言模型推理，从而支持高效的测试时推理，无需外部符号指导。

Result: NeSyPr在PDDLGym、VirtualHome和ALFWorld等具身基准测试中进行了评估，结果表明它在使用更紧凑的语言模型的同时，能够实现比大型推理模型和符号规划器更高效的推理能力。

Conclusion: NeSyPr为基于语言模型的代理提供了结构化、自适应和及时的推理能力，使其适用于在延迟敏感和资源受限的物理系统中部署，解决了具身任务在动态环境中的推理挑战。

Abstract: We address the challenge of adopting language models (LMs) for embodied tasks
in dynamic environments, where online access to large-scale inference engines
or symbolic planners is constrained due to latency, connectivity, and resource
limitations. To this end, we present NeSyPr, a novel embodied reasoning
framework that compiles knowledge via neurosymbolic proceduralization, thereby
equipping LM-based agents with structured, adaptive, and timely reasoning
capabilities. In NeSyPr, task-specific plans are first explicitly generated by
a symbolic tool leveraging its declarative knowledge. These plans are then
transformed into composable procedural representations that encode the plans'
implicit production rules, enabling the resulting composed procedures to be
seamlessly integrated into the LM's inference process. This neurosymbolic
proceduralization abstracts and generalizes multi-step symbolic structured
path-finding and reasoning into single-step LM inference, akin to human
knowledge compilation. It supports efficient test-time inference without
relying on external symbolic guidance, making it well suited for deployment in
latency-sensitive and resource-constrained physical systems. We evaluate NeSyPr
on the embodied benchmarks PDDLGym, VirtualHome, and ALFWorld, demonstrating
its efficient reasoning capabilities over large-scale reasoning models and a
symbolic planner, while using more compact LMs.

</details>


### [14] [DAIL: Beyond Task Ambiguity for Language-Conditioned Reinforcement Learning](https://arxiv.org/abs/2510.19562)
*Runpeng Xie,Quanwei Wang,Hao Hu,Zherui Zhou,Ni Mu,Xiyun Li,Yiqin Yang,Shuang Xu,Qianchuan Zhao,Bo XU*

Main category: cs.AI

TL;DR: DAIL是一种新颖的方法，通过结合分布策略和语义对齐来解决语言指令中的歧义问题，并在多项任务中取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 智能体理解自然语言和遵循人类指令的能力至关重要，但语言指令的灵活性导致了任务中的显著歧义，严重降低了算法性能。

Method: 本文提出DAIL（分布对齐学习）方法，包含两个核心组件：1. 分布策略：通过价值分布估计机制增强任务的可区分性，并提供了理论结果。2. 语义对齐：捕捉轨迹与语言指令之间的对应关系。

Result: 在结构化和视觉观测基准上的大量实验结果表明，DAIL能有效解决指令歧义问题，并取得了优于基线方法的性能。

Conclusion: DAIL成功地解决了语言指令中的歧义问题，显著提升了语言条件任务中的算法性能。

Abstract: Comprehending natural language and following human instructions are critical
capabilities for intelligent agents. However, the flexibility of linguistic
instructions induces substantial ambiguity across language-conditioned tasks,
severely degrading algorithmic performance. To address these limitations, we
present a novel method named DAIL (Distributional Aligned Learning), featuring
two key components: distributional policy and semantic alignment. Specifically,
we provide theoretical results that the value distribution estimation mechanism
enhances task differentiability. Meanwhile, the semantic alignment module
captures the correspondence between trajectories and linguistic instructions.
Extensive experimental results on both structured and visual observation
benchmarks demonstrate that DAIL effectively resolves instruction ambiguities,
achieving superior performance to baseline methods. Our implementation is
available at https://github.com/RunpengXie/Distributional-Aligned-Learning.

</details>


### [15] [HSCodeComp: A Realistic and Expert-level Benchmark for Deep Search Agents in Hierarchical Rule Application](https://arxiv.org/abs/2510.19631)
*Yiqian Yang,Tian Lan,Qianghuai Jia,Li Zhu,Hui Jiang,Hang Zhu,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.AI

TL;DR: 该论文引入了HSCodeComp，这是一个新的基准，用于评估深度搜索代理在分层规则应用中的能力，发现现有LLM在此任务上与人类专家存在巨大性能差距。


<details>
  <summary>Details</summary>
Motivation: 有效的深度搜索代理需要应用复杂的规则（如法律条款、医疗手册），这些规则常有模糊边界和隐式逻辑，但现有代理基准忽视了这种关键能力。

Method: 引入了HSCodeComp，这是一个现实的、专家级的电子商务基准，用于评估深度搜索代理在分层规则应用中的能力。任务是根据嘈杂的产品描述预测10位海关编码（HSCode）。数据来自真实电子商务平台，包含632个产品条目，由人类专家标注。

Result: 在多个最先进的LLM和代理上的实验结果显示，最佳代理的10位准确率仅为46.8%，远低于人类专家（95.0%）。详细分析表明分层规则应用极具挑战性，且测试时扩展未能进一步提高性能。

Conclusion: 当前深度搜索代理在应用复杂分层规则方面与人类专家之间存在巨大性能差距，凸显了开发更强大代理的必要性。

Abstract: Effective deep search agents must not only access open-domain and
domain-specific knowledge but also apply complex rules-such as legal clauses,
medical manuals and tariff rules. These rules often feature vague boundaries
and implicit logic relationships, making precise application challenging for
agents. However, this critical capability is largely overlooked by current
agent benchmarks.
  To fill this gap, we introduce HSCodeComp, the first realistic, expert-level
e-commerce benchmark designed to evaluate deep search agents in hierarchical
rule application. In this task, the deep reasoning process of agents is guided
by these rules to predict 10-digit Harmonized System Code (HSCode) of products
with noisy but realistic descriptions. These codes, established by the World
Customs Organization, are vital for global supply chain efficiency. Built from
real-world data collected from large-scale e-commerce platforms, our proposed
HSCodeComp comprises 632 product entries spanning diverse product categories,
with these HSCodes annotated by several human experts.
  Extensive experimental results on several state-of-the-art LLMs, open-source,
and closed-source agents reveal a huge performance gap: best agent achieves
only 46.8% 10-digit accuracy, far below human experts at 95.0%. Besides,
detailed analysis demonstrates the challenges of hierarchical rule application,
and test-time scaling fails to improve performance further.

</details>


### [16] [AgentSense: LLMs Empower Generalizable and Explainable Web-Based Participatory Urban Sensing](https://arxiv.org/abs/2510.19661)
*Xusen Guo,Mingxing Peng,Xixuan Hao,Xingchen Zou,Qiongyan Wang,Sijie Ruan,Yuxuan Liang*

Main category: cs.AI

TL;DR: AgentSense是一个混合的、免训练框架，通过多智能体演化系统将大型语言模型（LLMs）集成到参与式城市感知中，以实现自适应和可解释的传感任务分配。


<details>
  <summary>Details</summary>
Motivation: 现有的城市感知系统在多样化的城市场景中泛化能力有限，并且在决策过程中解释性差。

Method: AgentSense首先使用经典规划器生成基线解决方案，然后通过多智能体演化系统迭代优化传感任务分配，以适应动态城市条件和异构工人偏好。同时，它生成自然语言解释以提高透明度和信任。

Result: AgentSense在自适应性和可解释性方面优于传统方法。与单智能体LLM基线相比，该方法在性能和鲁棒性方面表现更优，并提供更合理和透明的解释。这些结果在两个大规模移动数据集和七种动态扰动类型上得到了验证。

Conclusion: AgentSense是部署基于网络的自适应和可解释城市感知系统方面的一个重大进展。

Abstract: Web-based participatory urban sensing has emerged as a vital approach for
modern urban management by leveraging mobile individuals as distributed
sensors. However, existing urban sensing systems struggle with limited
generalization across diverse urban scenarios and poor interpretability in
decision-making. In this work, we introduce AgentSense, a hybrid, training-free
framework that integrates large language models (LLMs) into participatory urban
sensing through a multi-agent evolution system. AgentSense initially employs
classical planner to generate baseline solutions and then iteratively refines
them to adapt sensing task assignments to dynamic urban conditions and
heterogeneous worker preferences, while producing natural language explanations
that enhance transparency and trust. Extensive experiments across two
large-scale mobility datasets and seven types of dynamic disturbances
demonstrate that AgentSense offers distinct advantages in adaptivity and
explainability over traditional methods. Furthermore, compared to single-agent
LLM baselines, our approach outperforms in both performance and robustness,
while delivering more reasonable and transparent explanations. These results
position AgentSense as a significant advancement towards deploying adaptive and
explainable urban sensing systems on the web.

</details>


### [17] [A Graph Engine for Guitar Chord-Tone Soloing Education](https://arxiv.org/abs/2510.19666)
*Matthew Keating,Michael Casey*

Main category: cs.AI

TL;DR: 本文提出一个基于图的引擎，为吉他学生计算和弦音独奏建议，通过构建和弦琶音图并寻找最短路径来生成独奏乐句。


<details>
  <summary>Details</summary>
Motivation: 和弦音独奏是即兴演奏和弦进行的基本练习，对所有高级爵士吉他理论都是基石，但学习和练习起来很困难。

Method: 首先，生成和弦音琶音。然后，构建一个加权图，其中每个节点代表和弦进行中一个和弦的琶音。接着，根据最佳过渡音计算连续和弦节点之间的边权重。最后，通过该图找到最短路径并重建和弦音独奏乐句。

Result: 该引擎能够重构和弦音独奏乐句，并提供一个用户友好的系统，方便吉他学生进行和弦音独奏练习。

Conclusion: 该系统为吉他学生提供了一个实用的工具，以帮助他们练习和学习难以掌握的和弦音独奏技巧。

Abstract: We present a graph-based engine for computing chord tone soloing suggestions
for guitar students. Chord tone soloing is a fundamental practice for
improvising over a chord progression, where the instrumentalist uses only the
notes contained in the current chord. This practice is a building block for all
advanced jazz guitar theory but is difficult to learn and practice. First, we
discuss methods for generating chord-tone arpeggios. Next, we construct a
weighted graph where each node represents a chord tone arpeggio for a chord in
the progression. Then, we calculate the edge weight between each consecutive
chord's nodes in terms of optimal transition tones. We then find the shortest
path through this graph and reconstruct a chord-tone soloing line. Finally, we
discuss a user-friendly system to handle input and output to this engine for
guitar students to practice chord tone soloing.

</details>


### [18] [Explainable e-sports win prediction through Machine Learning classification in streaming](https://arxiv.org/abs/2510.19671)
*Silvia García-Méndez,Francisco de Arriba-Pérez*

Main category: cs.AI

TL;DR: 本文提出了一种可解释的电竞实时流式获胜预测分类解决方案，通过滑动窗口处理数据，实现了超过90%的准确率，并优于现有方案，其可解释性模块能增强对预测结果的信任。


<details>
  <summary>Details</summary>
Motivation: 电子竞技观众和玩家数量的增加，以及优化通信方案和云计算技术的发展，推动了在线游戏行业的持续增长。然而，传统的基于AI的电竞分析解决方案在获胜预测方面多侧重于批处理分类，忽视了实时流数据和可视化技术。

Method: 开发了一种针对流式数据的可解释获胜预测分类解决方案。输入数据通过多个滑动窗口进行控制，以反映相关的游戏变化。该方案包含一个可解释性模块。

Result: 实验结果显示，该方案的准确率高于90%，超越了现有文献中竞争解决方案的性能。

Conclusion: 该系统可被排名和推荐系统用于辅助知情决策。其可解释性模块有助于增强对预测结果的信任。

Abstract: The increasing number of spectators and players in e-sports, along with the
development of optimized communication solutions and cloud computing
technology, has motivated the constant growth of the online game industry. Even
though Artificial Intelligence-based solutions for e-sports analytics are
traditionally defined as extracting meaningful patterns from related data and
visualizing them to enhance decision-making, most of the effort in professional
winning prediction has been focused on the classification aspect from a batch
perspective, also leaving aside the visualization techniques. Consequently,
this work contributes to an explainable win prediction classification solution
in streaming in which input data is controlled over several sliding windows to
reflect relevant game changes. Experimental results attained an accuracy higher
than 90 %, surpassing the performance of competing solutions in the literature.
Ultimately, our system can be leveraged by ranking and recommender systems for
informed decision-making, thanks to the explainability module, which fosters
trust in the outcome predictions.

</details>


### [19] [RLIE: Rule Generation with Logistic Regression, Iterative Refinement, and Evaluation for Large Language Models](https://arxiv.org/abs/2510.19698)
*Yang Yang,Hua XU,Zhangyi Hu,Yutao Yue*

Main category: cs.AI

TL;DR: RLIE是一个统一框架，结合大型语言模型（LLM）和概率建模来学习加权规则集。研究发现，直接应用学习到的加权规则比将规则、权重和逻辑模型输出提示给LLM能获得更好的性能，这表明LLM擅长语义生成而非精确的概率整合。


<details>
  <summary>Details</summary>
Motivation: 传统规则学习需要预定义谓词空间，而许多基于LLM的方法忽略了规则间的相互作用。将LLM与概率规则学习结合以实现鲁棒推理的潜力尚未得到充分探索。

Method: RLIE框架包含四个阶段：1) 规则生成，LLM提出并筛选候选规则；2) 逻辑回归，学习规则的概率权重以进行全局选择和校准；3) 迭代优化，根据预测错误更新规则集；4) 评估，将加权规则集作为直接分类器与将规则注入LLM的方法进行比较。

Result: 直接使用学习到的权重应用规则能获得卓越的性能。令人惊讶的是，将规则、权重和逻辑模型输出提示给LLM反而会降低准确性。这支持了LLM擅长语义生成和解释，但在精确概率整合方面可靠性较低的观点。

Conclusion: RLIE阐明了LLM在归纳推理方面的潜力和局限性，并将其与经典的概率规则组合方法结合，以实现更可靠的神经符号推理。研究强调LLM在语义生成和解释方面表现出色，但在精确概率整合方面可靠性不足。

Abstract: Large Language Models (LLMs) can propose rules in natural language,
sidestepping the need for a predefined predicate space in traditional rule
learning. Yet many LLM-based approaches ignore interactions among rules, and
the opportunity to couple LLMs with probabilistic rule learning for robust
inference remains underexplored. We present RLIE, a unified framework that
integrates LLMs with probabilistic modeling to learn a set of weighted rules.
RLIE has four stages: (1) Rule generation, where an LLM proposes and filters
candidates; (2) Logistic regression, which learns probabilistic weights for
global selection and calibration; (3) Iterative refinement, which updates the
rule set using prediction errors; and (4) Evaluation, which compares the
weighted rule set as a direct classifier with methods that inject rules into an
LLM. We evaluate multiple inference strategies on real-world datasets. Applying
rules directly with their learned weights yields superior performance, whereas
prompting LLMs with the rules, weights, and logistic-model outputs surprisingly
degrades accuracy. This supports the view that LLMs excel at semantic
generation and interpretation but are less reliable for precise probabilistic
integration. RLIE clarifies the potential and limitations of LLMs for inductive
reasoning and couples them with classic probabilistic rule combination methods
to enable more reliable neuro-symbolic reasoning.

</details>


### [20] [Misalignment Bounty: Crowdsourcing AI Agent Misbehavior](https://arxiv.org/abs/2510.19738)
*Rustem Turtayev,Natalia Fedorova,Oleg Serikov,Sergey Koldyba,Lev Avagyan,Dmitrii Volkov*

Main category: cs.AI

TL;DR: 该报告介绍了“失准赏金”项目，一个通过众包收集AI系统行为偏离人类意图或不安全目标的案例的项目，并详细分析了其中九个获奖案例。


<details>
  <summary>Details</summary>
Motivation: 先进AI系统有时会以与人类意图不同的方式行事，因此需要收集清晰、可复现的AI行为偏离人类意图或追求不安全目标的具体案例。

Method: 运行了“失准赏金”项目，这是一个众包平台，用于收集代理追求非预期或不安全目标的案例。项目收到了提交，并根据评估标准进行了评审。

Result: 项目共收到295份提交，其中9份被授予奖项。报告解释了项目的动机和评估标准，并逐步介绍了这9个获奖提交。

Conclusion: “失准赏金”项目成功收集了AI系统行为偏离人类意图的实际案例，为理解和研究AI失准问题提供了具体的、可复现的实例。

Abstract: Advanced AI systems sometimes act in ways that differ from human intent. To
gather clear, reproducible examples, we ran the Misalignment Bounty: a
crowdsourced project that collected cases of agents pursuing unintended or
unsafe goals. The bounty received 295 submissions, of which nine were awarded.
  This report explains the program's motivation and evaluation criteria, and
walks through the nine winning submissions step by step.

</details>


### [21] [Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning](https://arxiv.org/abs/2510.19732)
*Gunshi Gupta,Karmesh Yadav,Zsolt Kira,Yarin Gal,Rahaf Aljundi*

Main category: cs.AI

TL;DR: 为解决具身智能体在长时间任务中Transformer模型上下文限制的问题，本研究提出了Memo，一种基于Transformer的强化学习架构。Memo通过周期性总结令牌实现记忆的创建和检索，在长时任务中表现优于基线模型，且计算和存储效率更高。


<details>
  <summary>Details</summary>
Motivation: 具身智能体需要有效的记忆来在长时间内保持上下文感知。当前基于Transformer的策略在处理具身顺序决策任务时，视觉输入常超出其上下文限制，而人类能利用压缩的经验记忆。现有方法主要集中于固定大小记忆的循环模型或完全依赖上下文的Transformer，效率低下且无法有效压缩信息。

Method: 本研究提出了Memo，一种针对记忆密集型、长时任务的基于Transformer的强化学习架构和训练方案。Memo通过在训练期间将周期性总结令牌与模型输入交错，实现记忆的创建和检索。

Result: Memo在网格世界元强化学习基准和照片级真实室内环境中的多对象导航任务中表现出有效性。它优于天真的长上下文Transformer基线模型，同时在计算和存储方面更高效。此外，Memo在推理时能更好地泛化到更长的上下文，并在历史上下文必须截断以适应推理限制的流式设置中保持鲁棒性。

Conclusion: Memo通过引入周期性总结令牌进行记忆创建和检索，成功解决了具身智能体在长时任务中Transformer模型的上下文限制问题，提供了更高效、更泛化且更鲁棒的解决方案。

Abstract: To enable embodied agents to operate effectively over extended timeframes, it
is crucial to develop models that form and access memories to stay
contextualized in their environment. In the current paradigm of training
transformer-based policies for embodied sequential decision-making tasks,
visual inputs often overwhelm the context limits of transformers, while humans
can maintain and utilize a lifetime of experience compressed as memories.
Significant compression is possible in principle, as much of the input is
irrelevant and can be abstracted. However, existing approaches predominantly
focus on either recurrent models with fixed-size memory or transformers with
full-context reliance. In this work, we propose Memo, a transformer-based
architecture and training recipe for reinforcement learning (RL) on
memory-intensive, long-horizon tasks. Memo incorporates the creation and
retrieval of memory by interleaving periodic summarization tokens with the
inputs of a model during training. We demonstrate Memo's effectiveness on a
gridworld meta-RL benchmark and a multi-object navigation task in
photo-realistic indoor settings. Memo outperforms naive long-context
transformer baselines while being more compute and storage efficient.
Additionally, Memo generalizes better to longer contexts at inference time and
remains robust in streaming settings, where historical context must be
truncated to fit inference constraints.

</details>


### [22] [Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents](https://arxiv.org/abs/2510.19771)
*Gil Pasternak,Dheeraj Rajagopal,Julia White,Dhruv Atreja,Matthew Thomas,George Hurn-Maloney,Ash Lewis*

Main category: cs.AI

TL;DR: 本文提出PROBE基准，旨在评估LLM代理的主动性，因现有基准受限于局部上下文。PROBE将主动性分解为搜索问题、识别瓶颈和执行解决方案三个核心能力。评估结果显示，即使是SOTA模型也难以解决此基准，最佳端到端性能仅为40%，揭示了自主行动的局限性。


<details>
  <summary>Details</summary>
Motivation: LLM代理正朝向主动性发展，即自主预测用户需求并解决。然而，当前评估主动性的基准受限于局部上下文，无法测试跨源推理和长时间范围内的能力，存在评估空白。

Method: 本文提出了PROBE（Proactive Resolution Of BottlEnecks）基准。PROBE将主动性分解为三个核心能力：(1) 搜索未指定问题，(2) 识别具体瓶颈，以及(3) 执行适当的解决方案。作者使用PROBE评估了领先的LLM和流行的代理框架。

Result: 评估结果显示，即使是GPT-5和Claude Opus-4.1等最先进的模型，在PROBE基准上仍难以取得高分，最佳端到端性能仅为40%。研究还展示了各模型的相对能力，并分析了共同的失败模式。

Conclusion: 研究结果突出了代理系统中自主行动的当前局限性，并为未来研究指明了有前景的方向。

Abstract: LLM-based agents are increasingly moving towards proactivity: rather than
awaiting instruction, they exercise agency to anticipate user needs and solve
them autonomously. However, evaluating proactivity is challenging; current
benchmarks are constrained to localized context, limiting their ability to test
reasoning across sources and longer time horizons. To address this gap, we
present PROBE (Proactive Resolution Of BottlEnecks). PROBE decomposes
proactivity as a pipeline of three core capabilities: (1) searching for
unspecified issues, (2) identifying specific bottlenecks, and (3) executing
appropriate resolutions. We apply PROBE to evaluate leading LLMs and popular
agentic frameworks, showing that even state-of-the-art models struggle to solve
this benchmark. Computing our consistent measurements across frontier LLMs and
agents, we find that the best end-to-end performance of 40% is achieved by both
GPT-5 and Claude Opus-4.1. Additionally, we demonstrate the relative
capabilities of each model and analyze mutual failure modes. Our results
highlight the current limitations of autonomous action in agentic systems, and
expose promising future research directions.

</details>


### [23] [Benchmarking World-Model Learning](https://arxiv.org/abs/2510.19788)
*Archana Warrier,Dat Nyugen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares*

Main category: cs.AI

TL;DR: 本文提出了WorldTest，一个用于评估世界模型的新协议，旨在超越传统的下一帧预测和奖励最大化，通过无奖励探索和在不同但相关环境中的多任务测试来衡量模型对世界动力学的理解。


<details>
  <summary>Details</summary>
Motivation: 当前世界模型学习和评估方法主要侧重于下一帧预测和在相同环境中的奖励最大化，这与模型应支持多种下游任务和推理（如预测未观察状态、规划、检测动态变化）的目标不符。

Method: 本文提出了WorldTest协议，它将无奖励交互与在不同但相关环境中的计分测试阶段分开。该协议是开放式的，对模型表示不可知。通过AutumnBench实例化WorldTest，AutumnBench包含43个交互式网格世界环境和129个任务，涵盖遮蔽帧预测、规划和预测因果动态变化。作者将517名人类参与者和三个前沿模型在AutumnBench上进行了比较。

Result: 研究发现人类的表现优于模型，并且计算资源的扩展仅在部分环境中提高了性能，而在其他环境中则没有。

Conclusion: WorldTest提供了一个新颖的评估模板（无奖励探索、派生测试和基于行为的评分），用于评估智能体对环境动态的学习。AutumnBench揭示了世界模型学习领域仍有巨大的改进空间。

Abstract: Model-learning agents should gather information to learn world models that
support many downstream tasks and inferences, such as predicting unobserved
states, estimating near- and far-term consequences of actions, planning action
sequences, and detecting changes in dynamics. Current methods for learning and
evaluating world models diverge from this goal: training and evaluation are
anchored to next-frame prediction, and success is scored by reward maximization
in the same environment. We propose WorldTest, a protocol to evaluate
model-learning agents that separates reward-free interaction from a scored test
phase in a different but related environment. WorldTest is
open-ended$\unicode{x2014}$models should support many different tasks unknown
ahead of time$\unicode{x2014}$and agnostic to model representation, allowing
comparison across approaches. We instantiated WorldTest with AutumnBench, a
suite of 43 interactive grid-world environments and 129 tasks across three
families: masked-frame prediction, planning, and predicting changes to the
causal dynamics. We compared 517 human participants and three frontier models
on AutumnBench. We found that humans outperform the models, and scaling compute
improves performance only in some environments but not others. WorldTest
provides a novel template$\unicode{x2014}$reward-free exploration, derived
tests, and behavior-based scoring$\unicode{x2014}$to evaluate what agents learn
about environment dynamics, and AutumnBench exposes significant headroom in
world-model learning.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [24] [Dimensionality Reduction for Remote Sensing Data Analysis: A Systematic Review of Methods and Applications](https://arxiv.org/abs/2510.18935)
*Nathan Mankovich,Kai-Hendrik Cohrs,Homer Durand,Vasileios Sitokonstantinou,Tristan Williams,Gustau Camps-Valls*

Main category: cs.CV

TL;DR: 该综述旨在为遥感数据处理中利用降维技术提供指导，并识别未充分探索的降维算法及其未来应用机会，以应对高维地球观测数据带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 地球观测数据量巨大且维度高，导致数据稀疏、处理效率低下以及维度灾难等问题，限制了机器学习模型的有效性。解决这些挑战对于环境监测、城市规划和灾害管理等社会、经济和环境问题至关重要。

Method: 本文通过综述的方式，重点介绍了降维技术，特别是特征提取方法。这些技术通过保留数据本质属性来降低复杂性，并提升数据压缩、清洗、融合、可视化、异常检测和预测等任务的性能。

Result: 该综述提供了一本关于在遥感数据价值链中利用降维技术的“手册”，并指出了未充分探索的降维算法及其在未来研究中的应用机会。

Conclusion: 降维技术对于解决高维地球观测数据带来的挑战至关重要，未来研究应关注未充分探索的降维算法及其在遥感数据处理中的应用潜力。

Abstract: Earth observation involves collecting, analyzing, and processing an
ever-growing mass of data. Automatically harvesting information is crucial for
addressing significant societal, economic, and environmental challenges,
ranging from environmental monitoring to urban planning and disaster
management. However, the high dimensionality of these data poses challenges in
terms of sparsity, inefficiency, and the curse of dimensionality, which limits
the effectiveness of machine learning models. Dimensionality reduction (DR)
techniques, specifically feature extraction, address these challenges by
preserving essential data properties while reducing complexity and enhancing
tasks such as data compression, cleaning, fusion, visualization, anomaly
detection, and prediction. This review provides a handbook for leveraging DR
across the RS data value chain and identifies opportunities for under-explored
DR algorithms and their application in future research.

</details>


### [25] [Ninja Codes: Neurally Generated Fiducial Markers for Stealthy 6-DoF Tracking](https://arxiv.org/abs/2510.18976)
*Yuichiro Takeuchi,Yusuke Imoto,Shunya Kato*

Main category: cs.CV

TL;DR: 本文介绍了“Ninja Codes”，一种神经生成的可融入真实环境的隐形视觉标记，用于提供隐蔽的六自由度（6-DoF）位置跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉标记（fiducial markers）外观显眼，在美学及其他方面不尽理想，因此需要一种能自然融入环境的隐形标记。

Method: 该方法通过一个编码器网络，对任意图像进行微小视觉改动，生成Ninja Codes。受深度隐写术启发，研究人员联合训练了一系列网络模块来执行Ninja Codes的创建和检测。这些标记可以使用普通彩色打印机和纸张打印，并通过配备现代RGB摄像头和推理能力的设备进行检测。

Result: 实验证明，Ninja Codes在常见的室内光照条件下能提供可靠的位置跟踪，并能成功地隐藏在各种环境纹理中。

Conclusion: Ninja Codes在传统视觉标记因其显眼外观而不受欢迎的场景中具有特殊价值，提供了隐蔽的跟踪解决方案。

Abstract: In this paper we describe Ninja Codes, neurally-generated fiducial markers
that can be made to naturally blend into various real-world environments. An
encoder network converts arbitrary images into Ninja Codes by applying visually
modest alterations; the resulting codes, printed and pasted onto surfaces, can
provide stealthy 6-DoF location tracking for a wide range of applications
including augmented reality, robotics, motion-based user interfaces, etc. Ninja
Codes can be printed using off-the-shelf color printers on regular printing
paper, and can be detected using any device equipped with a modern RGB camera
and capable of running inference. Using an end-to-end process inspired by prior
work on deep steganography, we jointly train a series of network modules that
perform the creation and detection of Ninja Codes. Through experiments, we
demonstrate Ninja Codes' ability to provide reliable location tracking under
common indoor lighting conditions, while successfully concealing themselves
within diverse environmental textures. We expect Ninja Codes to offer
particular value in scenarios where the conspicuous appearances of conventional
fiducial markers make them undesirable for aesthetic and other reasons.

</details>


### [26] [Robust Driving QA through Metadata-Grounded Context and Task-Specific Prompts](https://arxiv.org/abs/2510.19001)
*Seungjun Yu,Junsung Park,Youngsun Lim,Hyunjung Shim*

Main category: cs.CV

TL;DR: 本文提出一个用于自动驾驶的两阶段视觉-语言问答系统，通过多模态大语言模型、链式思考提示、自洽集成和场景元数据，显著提升了感知、预测和规划问题的回答准确性，并展现出对视觉损坏的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够回答自动驾驶中高级感知、预测和规划问题的视觉-语言问答系统。

Method: 该系统分为两阶段：
1. 第一阶段：使用Qwen2.5-VL-32B多模态大语言模型，输入包括六个摄像头视图、短期历史帧，并采用少量示例的链式思考提示。通过自洽集成（多样本推理链）提高答案可靠性。
2. 第二阶段：在提示中加入nuScenes场景元数据（如物体标注、自车状态等）和针对不同任务（感知、预测、规划）的类别特定问题指令。

Result: 该方法在驾驶问答基准上显著优于基线Qwen2.5模型。例如，第一阶段使用5个历史帧和10次少样本提示，整体准确率达到65.1%（零样本为62.61%）；应用自洽性后提高到66.85%。第二阶段整体准确率达到67.37%。值得注意的是，在严重视觉损坏下，系统仍能保持96%的准确率。

Conclusion: 精心设计的提示和上下文接地可以极大地增强预训练视觉-语言模型在高级驾驶问答任务中的性能和鲁棒性。

Abstract: We present a two-phase vision-language QA system for autonomous driving that
answers high-level perception, prediction, and planning questions. In Phase-1,
a large multimodal LLM (Qwen2.5-VL-32B) is conditioned on six-camera inputs, a
short temporal window of history, and a chain-of-thought prompt with few-shot
exemplars. A self-consistency ensemble (multiple sampled reasoning chains)
further improves answer reliability. In Phase-2, we augment the prompt with
nuScenes scene metadata (object annotations, ego-vehicle state, etc.) and
category-specific question instructions (separate prompts for perception,
prediction, planning tasks). In experiments on a driving QA benchmark, our
approach significantly outperforms the baseline Qwen2.5 models. For example,
using 5 history frames and 10-shot prompting in Phase-1 yields 65.1% overall
accuracy (vs.62.61% with zero-shot); applying self-consistency raises this to
66.85%. Phase-2 achieves 67.37% overall. Notably, the system maintains 96%
accuracy under severe visual corruption. These results demonstrate that
carefully engineered prompts and contextual grounding can greatly enhance
high-level driving QA with pretrained vision-language models.

</details>


### [27] [$Δ$t-Mamba3D: A Time-Aware Spatio-Temporal State-Space Model for Breast Cancer Risk Prediction](https://arxiv.org/abs/2510.19003)
*Zhengbo Zhou,Dooman Arefan,Margarita Zuley,Shandong Wu*

Main category: cs.CV

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Longitudinal analysis of sequential radiological images is hampered by a
fundamental data challenge: how to effectively model a sequence of
high-resolution images captured at irregular time intervals. This data
structure contains indispensable spatial and temporal cues that current methods
fail to fully exploit. Models often compromise by either collapsing spatial
information into vectors or applying spatio-temporal models that are
computationally inefficient and incompatible with non-uniform time steps. We
address this challenge with Time-Aware $\Delta$t-Mamba3D, a novel state-space
architecture adapted for longitudinal medical imaging. Our model simultaneously
encodes irregular inter-visit intervals and rich spatio-temporal context while
remaining computationally efficient. Its core innovation is a continuous-time
selective scanning mechanism that explicitly integrates the true time
difference between exams into its state transitions. This is complemented by a
multi-scale 3D neighborhood fusion module that robustly captures
spatio-temporal relationships. In a comprehensive breast cancer risk prediction
benchmark using sequential screening mammogram exams, our model shows superior
performance, improving the validation c-index by 2-5 percentage points and
achieving higher 1-5 year AUC scores compared to established variants of
recurrent, transformer, and state-space models. Thanks to its linear
complexity, the model can efficiently process long and complex patient
screening histories of mammograms, forming a new framework for longitudinal
image analysis.

</details>


### [28] [MoAlign: Motion-Centric Representation Alignment for Video Diffusion Models](https://arxiv.org/abs/2510.19022)
*Aritra Bhowmik,Denis Korzhenkov,Cees G. M. Snoek,Amirhossein Habibian,Mohsen Ghafoorian*

Main category: cs.CV

TL;DR: 本文提出了一种以运动为中心的对齐框架，通过从预训练视频编码器中学习解耦的运动子空间，并将其与文本到视频扩散模型的潜在特征对齐，从而显著提高了生成视频的物理合理性和时间连贯性。


<details>
  <summary>Details</summary>
Motivation: 文本到视频扩散模型在生成高质量视频时，常因对复杂运动理解不足而导致时间连贯性差和物理不合理。现有方法通过对齐扩散模型特征与预训练视频编码器特征来解决，但这些编码器将视频外观和动态混杂在一起，限制了对齐效果。

Method: 本研究提出了一种以运动为中心的对齐框架。该框架从预训练视频编码器中学习一个解耦的运动子空间，并优化该子空间以预测真实光流，从而确保其捕获真实的运动动态。随后，将文本到视频扩散模型的潜在特征与这个新的运动子空间对齐。

Result: 该方法在保持文本提示一致性的同时，显著提升了最先进视频扩散模型的物理常识。这一点通过在VideoPhy、VideoPhy2、VBench和VBench-2.0上的实证评估以及用户研究得到了证实。

Conclusion: 通过学习一个解耦的运动子空间并将其与扩散模型对齐，本方法能够让生成模型内化运动知识，从而生成更具物理合理性的视频，有效解决了现有文本到视频扩散模型在运动理解上的不足。

Abstract: Text-to-video diffusion models have enabled high-quality video synthesis, yet
often fail to generate temporally coherent and physically plausible motion. A
key reason is the models' insufficient understanding of complex motions that
natural videos often entail. Recent works tackle this problem by aligning
diffusion model features with those from pretrained video encoders. However,
these encoders mix video appearance and dynamics into entangled features,
limiting the benefit of such alignment. In this paper, we propose a
motion-centric alignment framework that learns a disentangled motion subspace
from a pretrained video encoder. This subspace is optimized to predict
ground-truth optical flow, ensuring it captures true motion dynamics. We then
align the latent features of a text-to-video diffusion model to this new
subspace, enabling the generative model to internalize motion knowledge and
generate more plausible videos. Our method improves the physical commonsense in
a state-of-the-art video diffusion model, while preserving adherence to textual
prompts, as evidenced by empirical evaluations on VideoPhy, VideoPhy2, VBench,
and VBench-2.0, along with a user study.

</details>


### [29] [PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions](https://arxiv.org/abs/2510.19060)
*Amith Ananthram,Elias Stengel-Eskin,Lorena A. Bradford,Julia Demarest,Adam Purvis,Keith Krut,Robert Stein,Rina Elster Pantalony,Mohit Bansal,Kathleen McKeown*

Main category: cs.CV

TL;DR: 本文提出了一种新的详细图像描述评估指标PoSh，它利用场景图和大型语言模型（LLM）作为评判者，以及一个具有挑战性的新数据集DOCENT，用于评估艺术品描述。PoSh在人类相关性方面优于现有指标，并揭示了当前视觉-语言模型（VLM）在处理复杂场景描述时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有VLM评估指标（如CIDEr, SPICE）是为短文本设计的，主要识别对象误识别等简单错误，对长文本中属性、关系依附错误和局部错误不敏感。因此，需要一种新的评估方法来衡量详细图像描述的质量，尤其是在复杂场景和艺术品领域。

Method: 本文引入了PoSh，一种基于场景图作为结构化评分标准，并由LLM作为评判者引导的详细图像描述指标，能够产生基于细粒度错误（如组合理解错误）的聚合分数。同时，本文还推出了一个名为DOCENT的具有挑战性的新数据集，其中包含艺术品、专家参考描述、模型生成描述以及艺术史学生提供的细粒度和粗粒度质量判断。

Result: PoSh比现有指标（包括GPT4o作为评判者）更具可复现性、可解释性，并且能更好地替代人类评估者。在DOCENT数据集上，PoSh与人类判断的相关性（Spearman $\rho$）比最佳开源替代方案高出+0.05。PoSh对图像类型具有鲁棒性，并且作为奖励函数优于标准监督微调。研究发现，基础模型难以对DOCENT中具有丰富场景动态的图像实现全面、无错误的覆盖。

Conclusion: PoSh和DOCENT为详细图像描述的评估和发展提供了新的工具和基准，特别是在辅助文本生成等重要领域。它们为衡量VLM在处理复杂、细致的图像描述方面的进展设定了一个新的、具有挑战性的任务。

Abstract: While vision-language models (VLMs) have advanced into detailed image
description, evaluation remains a challenge. Standard metrics (e.g. CIDEr,
SPICE) were designed for short texts and tuned to recognize errors that are now
uncommon, such as object misidentification. In contrast, long texts require
sensitivity to attribute and relation attachments and scores that localize
errors to particular text spans. In this work, we introduce PoSh, a metric for
detailed image description that uses scene graphs as structured rubrics to
guide LLMs-as-a-Judge, producing aggregate scores grounded in fine-grained
errors (e.g. mistakes in compositional understanding). PoSh is replicable,
interpretable and a better proxy for human raters than existing metrics
(including GPT4o-as-a-Judge). To validate PoSh, we introduce a challenging new
dataset, DOCENT. This novel benchmark contains artwork, paired with
expert-written references, and model-generated descriptions, augmented with
granular and coarse judgments of their quality from art history students. Thus,
DOCENT enables evaluating both detailed image description metrics and detailed
image description itself in a challenging new domain. We show that PoSh
achieves stronger correlations (+0.05 Spearman $\rho$) with the human judgments
in DOCENT than the best open-weight alternatives, is robust to image type
(using CapArena, an existing dataset of web imagery) and is a capable reward
function, outperforming standard supervised fine-tuning. Then, using PoSh, we
characterize the performance of open and closed models in describing the
paintings, sketches and statues in DOCENT and find that foundation models
struggle to achieve full, error-free coverage of images with rich scene
dynamics, establishing a demanding new task to gauge VLM progress. Through both
PoSh and DOCENT, we hope to enable advances in important areas such as
assistive text generation.

</details>


### [30] [UniHPR: Unified Human Pose Representation via Singular Value Contrastive Learning](https://arxiv.org/abs/2510.19078)
*Zhongyu Jiang,Wenhao Chai,Lei Li,Zhuoran Zhou,Cheng-Yen Yang,Jenq-Neng Hwang*

Main category: cs.CV

TL;DR: 本文提出了UniHPR，一个统一的人体姿态表示学习框架，通过新颖的基于奇异值的对比学习损失，对图像、2D和3D人体姿态嵌入进行对齐，显著提升了姿态估计和检索性能。


<details>
  <summary>Details</summary>
Motivation: 多模态融合和生成中统一表示的开发日益受关注。人体姿态表示作为人机交互应用的关键组成部分，在姿态估计、动作识别等任务中至关重要。然而，目前鲜有研究使用对比学习范式清晰地探索图像、2D关键点、3D骨架、网格模型等多种姿态表示之间的关联。

Method: 本文提出了UniHPR，一个统一的人体姿态表示学习流程，旨在对齐来自图像、2D和3D人体姿态的嵌入。为同时对齐超过两种数据表示，本文提出了一种新颖的基于奇异值的对比学习损失，以更好地对齐不同模态并提升性能。通过2D和3D人体姿态估计（HPE）以及姿态检索任务来评估对齐表示的有效性。

Result: 在3D人体姿态估计任务中，UniHPR在Human3.6M数据集上实现了49.9mm的MPJPE，在3DPW数据集的跨域评估中实现了51.6mm的PA-MPJPE。同时，使用统一的人体姿态表示，在Human3.6M数据集上实现了2D和3D姿态检索，检索误差为9.24mm（MPJPE）。

Conclusion: UniHPR成功地学习了跨图像、2D和3D模态的统一高效人体姿态表示，并在人体姿态估计和检索任务中展现出卓越的性能。

Abstract: In recent years, there has been a growing interest in developing effective
alignment pipelines to generate unified representations from different
modalities for multi-modal fusion and generation. As an important component of
Human-Centric applications, Human Pose representations are critical in many
downstream tasks, such as Human Pose Estimation, Action Recognition,
Human-Computer Interaction, Object tracking, etc. Human Pose representations or
embeddings can be extracted from images, 2D keypoints, 3D skeletons, mesh
models, and lots of other modalities. Yet, there are limited instances where
the correlation among all of those representations has been clearly researched
using a contrastive paradigm. In this paper, we propose UniHPR, a unified Human
Pose Representation learning pipeline, which aligns Human Pose embeddings from
images, 2D and 3D human poses. To align more than two data representations at
the same time, we propose a novel singular value-based contrastive learning
loss, which better aligns different modalities and further boosts performance.
To evaluate the effectiveness of the aligned representation, we choose 2D and
3D Human Pose Estimation (HPE) as our evaluation tasks. In our evaluation, with
a simple 3D human pose decoder, UniHPR achieves remarkable performance metrics:
MPJPE 49.9mm on the Human3.6M dataset and PA-MPJPE 51.6mm on the 3DPW dataset
with cross-domain evaluation. Meanwhile, we are able to achieve 2D and 3D pose
retrieval with our unified human pose representations in Human3.6M dataset,
where the retrieval error is 9.24mm in MPJPE.

</details>


### [31] [A Novel Approach to Breast Cancer Segmentation using U-Net Model with Attention Mechanisms and FedProx](https://arxiv.org/abs/2510.19118)
*Eyad Gad,Mustafa Abou Khatwa,Mustafa A. Elattar,Sahar Selim*

Main category: cs.CV

TL;DR: 本研究利用联邦学习（FedProx）与改进的带注意力机制的U-Net模型，在非独立同分布（non-IID）的超声乳腺癌图像数据集上实现了高精度的肿瘤分割（96%准确率），同时保护了患者隐私。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性死亡的主要原因，早期检测和准确诊断至关重要。超声成像是一种可靠且经济的工具，但敏感的医疗数据使得开发准确且保护隐私的AI模型面临挑战。联邦学习是解决此问题的一种有前景的技术，但其在非独立同分布（non-IID）本地数据集上的训练会影响模型准确性和泛化能力，这对于乳腺癌分割中的肿瘤边界描绘至关重要。

Method: 本研究通过将联邦近端（FedProx）方法应用于非独立同分布的超声乳腺癌图像数据集来解决上述挑战。此外，通过结合改进的带有注意力机制的U-Net模型，旨在提高肿瘤分割的准确性。

Result: 研究结果显示，所提出的方法产生了一个全局模型，其准确率达到96%，证明了该方法在提高肿瘤分割准确性同时保护患者隐私方面的有效性。

Conclusion: 本研究结果表明，FedProx有潜力成为一种在非独立同分布的本地医疗数据集上训练精确机器学习模型的有前景方法，能够有效提高肿瘤分割精度并保护患者隐私。

Abstract: Breast cancer is a leading cause of death among women worldwide, emphasizing
the need for early detection and accurate diagnosis. As such Ultrasound
Imaging, a reliable and cost-effective tool, is used for this purpose, however
the sensitive nature of medical data makes it challenging to develop accurate
and private artificial intelligence models. A solution is Federated Learning as
it is a promising technique for distributed machine learning on sensitive
medical data while preserving patient privacy. However, training on
non-Independent and non-Identically Distributed (non-IID) local datasets can
impact the accuracy and generalization of the trained model, which is crucial
for accurate tumour boundary delineation in BC segmentation. This study aims to
tackle this challenge by applying the Federated Proximal (FedProx) method to
non-IID Ultrasonic Breast Cancer Imaging datasets. Moreover, we focus on
enhancing tumour segmentation accuracy by incorporating a modified U-Net model
with attention mechanisms. Our approach resulted in a global model with 96%
accuracy, demonstrating the effectiveness of our method in enhancing tumour
segmentation accuracy while preserving patient privacy. Our findings suggest
that FedProx has the potential to be a promising approach for training precise
machine learning models on non-IID local medical datasets.

</details>


### [32] [Advancing Brain Tumor Segmentation via Attention-based 3D U-Net Architecture and Digital Image Processing](https://arxiv.org/abs/2510.19109)
*Eyad Gad,Seif Soliman,M. Saeed Darweesh*

Main category: cs.CV

TL;DR: 本研究提出了一种结合注意力机制的3D U-Net模型，并辅以基于数字图像处理的肿瘤检测算法，以解决脑肿瘤分割中不规则形状、模糊边界和数据不平衡等问题，在BraTS 2020数据集上实现了卓越的分割性能。


<details>
  <summary>Details</summary>
Motivation: 标准U-Net模型在处理不规则形状和模糊边界的肿瘤区域时面临挑战。此外，在高分辨率MRI数据（如BraTS数据集）上训练鲁棒的分割模型需要高计算资源，并且常遇到类别不平衡问题。

Method: 本研究将注意力机制集成到3D U-Net模型中，使其能够捕捉复杂细节并优先处理信息丰富的区域。同时，利用基于数字图像处理技术的肿瘤检测算法来解决训练数据不平衡和减轻偏差。所提出的模型在BraTS 2020数据集上进行了全面评估。

Result: 所提出的模型性能优于相关研究，取得了0.975的Dice系数、0.988的特异性和0.995的敏感性，表明其在改进脑肿瘤分割方面的有效性。

Conclusion: 所提出的模型能有效改进脑肿瘤分割的性能，为临床环境中提供可靠诊断提供了有价值的见解。

Abstract: In the realm of medical diagnostics, rapid advancements in Artificial
Intelligence (AI) have significantly yielded remarkable improvements in brain
tumor segmentation. Encoder-Decoder architectures, such as U-Net, have played a
transformative role by effectively extracting meaningful representations in 3D
brain tumor segmentation from Magnetic resonance imaging (MRI) scans. However,
standard U-Net models encounter challenges in accurately delineating tumor
regions, especially when dealing with irregular shapes and ambiguous
boundaries. Additionally, training robust segmentation models on
high-resolution MRI data, such as the BraTS datasets, necessitates high
computational resources and often faces challenges associated with class
imbalance. This study proposes the integration of the attention mechanism into
the 3D U-Net model, enabling the model to capture intricate details and
prioritize informative regions during the segmentation process. Additionally, a
tumor detection algorithm based on digital image processing techniques is
utilized to address the issue of imbalanced training data and mitigate bias.
This study aims to enhance the performance of brain tumor segmentation,
ultimately improving the reliability of diagnosis. The proposed model is
thoroughly evaluated and assessed on the BraTS 2020 dataset using various
performance metrics to accomplish this goal. The obtained results indicate that
the model outperformed related studies, exhibiting dice of 0.975, specificity
of 0.988, and sensitivity of 0.995, indicating the efficacy of the proposed
model in improving brain tumor segmentation, offering valuable insights for
reliable diagnosis in clinical settings.

</details>


### [33] [X-Ego: Acquiring Team-Level Tactical Situational Awareness via Cross-Egocentric Contrastive Video Representation Learning](https://arxiv.org/abs/2510.19150)
*Yunzhe Wang,Soham Hans,Volkan Ustun*

Main category: cs.CV

TL;DR: 本文提出了X-Ego-CS数据集，包含《反恐精英2》的跨第一人称视角同步视频流和状态-动作轨迹，并引入了跨第一人称对比学习（CECL）方法，以提升多智能体在复杂3D环境中从个体视角理解团队战术的能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解在体育团队互动建模中多依赖第三方广播视角，忽视了多智能体学习中同步、以自我为中心的特性。团队战术源于每个玩家的个体视角及其预测、解释和适应队友意图的能力，这促使研究需要一个能捕捉所有玩家第一人称视角的资源。

Method: 1. 构建了X-Ego-CS基准数据集：包含124小时来自45场《反恐精英2》职业比赛的同步跨第一人称视角视频流和状态-动作轨迹。2. 提出了跨第一人称对比学习（CECL）：通过对齐队友的第一人称视觉流，从个体视角培养团队层面的战术态势感知。

Result: CECL在队友-对手位置预测任务上表现出有效性，显著增强了智能体从单一第一人称视角推断队友和对手位置的能力，并使用了最先进的视频编码器。

Conclusion: X-Ego-CS数据集和CECL方法共同为电竞中的跨第一人称多智能体基准测试奠定了基础。这项工作将游戏理解定位为多智能体建模和战术学习的试验平台，对虚拟和现实世界中的时空推理和人机协作具有重要意义。

Abstract: Human team tactics emerge from each player's individual perspective and their
ability to anticipate, interpret, and adapt to teammates' intentions. While
advances in video understanding have improved the modeling of team interactions
in sports, most existing work relies on third-person broadcast views and
overlooks the synchronous, egocentric nature of multi-agent learning. We
introduce X-Ego-CS, a benchmark dataset consisting of 124 hours of gameplay
footage from 45 professional-level matches of the popular e-sports game
Counter-Strike 2, designed to facilitate research on multi-agent
decision-making in complex 3D environments. X-Ego-CS provides cross-egocentric
video streams that synchronously capture all players' first-person perspectives
along with state-action trajectories. Building on this resource, we propose
Cross-Ego Contrastive Learning (CECL), which aligns teammates' egocentric
visual streams to foster team-level tactical situational awareness from an
individual's perspective. We evaluate CECL on a teammate-opponent location
prediction task, demonstrating its effectiveness in enhancing an agent's
ability to infer both teammate and opponent positions from a single
first-person view using state-of-the-art video encoders. Together, X-Ego-CS and
CECL establish a foundation for cross-egocentric multi-agent benchmarking in
esports. More broadly, our work positions gameplay understanding as a testbed
for multi-agent modeling and tactical learning, with implications for
spatiotemporal reasoning and human-AI teaming in both virtual and real-world
domains. Code and dataset are available at https://github.com/HATS-ICT/x-ego.

</details>


### [34] [FootFormer: Estimating Stability from Visual Input](https://arxiv.org/abs/2510.19170)
*Keaton Kraiger,Jingjing Li,Skanda Bharadwaj,Jesse Scott,Robert T. Collins,Yanxi Liu*

Main category: cs.CV

TL;DR: FootFormer是一种跨模态方法，能直接从视觉输入联合预测人体运动动力学，并在多项足部压力、接触图、质心以及稳定性预测分量上达到显著优于或等同于现有方法，甚至超越SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从视觉输入预测人体运动动力学时，通常只能生成一到两种测量指标，缺乏一个能联合预测多项关键指标（如足部压力、接触图、质心及稳定性分量）的统一框架。

Method: 本文提出FootFormer，一种跨模态方法，直接从视觉输入联合预测人体运动动力学。具体而言，它旨在同时估计足部压力分布、足部接触图和质心（CoM）等指标，并进一步预测经典运动学指标中使用的稳定性预测分量（CoP, CoM, BoS）。

Result: FootFormer在多个数据集上，对足部压力分布、足部接触图和质心（CoM）的估计，与现有方法相比，取得了统计学上显著更好或等效的结果。此外，FootFormer在估计用于经典运动学指标的稳定性预测分量（CoP, CoM, BoS）方面，达到了SOTA性能。

Conclusion: FootFormer成功地提供了一种创新的跨模态方法，能够直接从视觉输入准确且全面地预测人体运动动力学和稳定性指标，并在多项关键测量上超越或媲美现有技术，为运动学分析提供了强大的新工具。

Abstract: We propose FootFormer, a cross-modality approach for jointly predicting human
motion dynamics directly from visual input. On multiple datasets, FootFormer
achieves statistically significantly better or equivalent estimates of foot
pressure distributions, foot contact maps, and center of mass (CoM), as
compared with existing methods that generate one or two of those measures.
Furthermore, FootFormer achieves SOTA performance in estimating
stability-predictive components (CoP, CoM, BoS) used in classic kinesiology
metrics. Code and data are available at
https://github.com/keatonkraiger/Vision-to-Stability.git.

</details>


### [35] [Malaria Detection from Blood Cell Images Using XceptionNet](https://arxiv.org/abs/2510.19182)
*Warisa Nusrat,Mostafijur Rahman,Ayatullah Faruk Mollah*

Main category: cs.CV

TL;DR: 本文应用深度学习网络实现疟疾的自动诊断，其中Residual Attention Network和XceptionNet在公开数据集上表现最佳，准确率分别达到97.28%和97.55%，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 疟疾，尤其是0-5岁儿童的疟疾，常导致死亡。临床专家通过显微镜观察血涂片诊断，但缺乏专业知识、技能及人工操作可能导致诊断错误。因此，计算机辅助自动诊断成为优选替代方案。

Method: 研究采用了六种深度卷积网络（AlexNet、XceptionNet、VGG-19、Residual Attention Network、DenseNet-121和Custom-CNN），从血细胞图像中提取深层内在特征，并将其分类为疟疾感染或健康细胞。

Result: 在公开疟疾细胞图像数据集上，Residual Attention Network和XceptionNet表现相对优异，平均准确率分别为97.28%和97.55%，超过了同一数据集上的其他相关方法。

Conclusion: 这些发现高度支持深度学习驱动的方法在自动、可靠地检测疟疾方面的可行性，并能最大程度地减少人工干预。

Abstract: Malaria, which primarily spreads with the bite of female anopheles mosquitos,
often leads to death of people - specifically children in the age-group of 0-5
years. Clinical experts identify malaria by observing RBCs in blood smeared
images with a microscope. Lack of adequate professional knowledge and skills,
and most importantly manual involvement may cause incorrect diagnosis.
Therefore, computer aided automatic diagnosis stands as a preferred substitute.
In this paper, well-demonstrated deep networks have been applied to extract
deep intrinsic features from blood cell images and thereafter classify them as
malaria infected or healthy cells. Among the six deep convolutional networks
employed in this work viz. AlexNet, XceptionNet, VGG-19, Residual Attention
Network, DenseNet-121 and Custom-CNN. Residual Attention Network and
XceptionNet perform relatively better than the rest on a publicly available
malaria cell image dataset. They yield an average accuracy of 97.28% and 97.55%
respectively, that surpasses other related methods on the same dataset. These
findings highly encourage the reality of deep learning driven method for
automatic and reliable detection of malaria while minimizing direct manual
involvement.

</details>


### [36] [PruneHal: Reducing Hallucinations in Multi-modal Large Language Models through Adaptive KV Cache Pruning](https://arxiv.org/abs/2510.19183)
*Fengyuan Sun,Hui Chen,Xinhao Xu,Dandan Zheng,Jingdong Chen,Jun Zhou,Jungong Han,Guiguang Ding*

Main category: cs.CV

TL;DR: 本文提出PruneHal，一种免训练、无额外推理成本的方法，通过自适应KV缓存剪枝增强多模态大语言模型（MLLMs）对关键视觉信息的关注，从而有效缓解幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）存在严重的幻觉问题。现有解决方案（额外训练数据或引入外部信息）会增加计算成本。本文观察到MLLMs的幻觉与视觉token注意力分配不足有关，冗余视觉token分散了模型注意力，导致关键视觉信息未被充分关注，从而加剧了幻觉。

Method: 基于上述观察，本文提出了PruneHal。这是一种免训练、简单但有效的方法，利用自适应KV缓存剪枝来增强模型对关键视觉信息的关注，从而减轻幻觉。据作者所知，这是首次将token剪枝应用于MLLMs的幻觉缓解。该方法无需额外训练，几乎不产生额外推理成本，并且是模型无关的，可与不同解码策略无缝集成。

Result: PruneHal在多个广泛使用的幻觉评估基准上，使用四种主流MLLMs进行了评估，取得了稳健而卓越的结果，凸显了该方法的有效性和优越性。它无需额外训练，几乎不增加推理成本，且具有模型无关性。

Conclusion: PruneHal通过自适应KV缓存剪枝，有效解决了MLLMs中的幻觉问题，通过提升模型对关键视觉信息的关注度。该方法免训练、成本低廉、模型无关且表现出色，为缓解MLLMs幻觉提供了一个新颖且高效的解决方案。

Abstract: While multi-modal large language models (MLLMs) have made significant
progress in recent years, the issue of hallucinations remains a major
challenge. To mitigate this phenomenon, existing solutions either introduce
additional data for further training or incorporate external or internal
information during inference. However, these approaches inevitably introduce
extra computational costs. In this paper, we observe that hallucinations in
MLLMs are strongly associated with insufficient attention allocated to visual
tokens. In particular, the presence of redundant visual tokens disperses the
model's attention, preventing it from focusing on the most informative ones. As
a result, critical visual cues are often under-attended, which in turn
exacerbates the occurrence of hallucinations. Building on this observation, we
propose \textbf{PruneHal}, a training-free, simple yet effective method that
leverages adaptive KV cache pruning to enhance the model's focus on critical
visual information, thereby mitigating hallucinations. To the best of our
knowledge, we are the first to apply token pruning for hallucination mitigation
in MLLMs. Notably, our method don't require additional training and incurs
nearly no extra inference cost. Moreover, PruneHal is model-agnostic and can be
seamlessly integrated with different decoding strategies, including those
specifically designed for hallucination mitigation. We evaluate PruneHal on
several widely used hallucination evaluation benchmarks using four mainstream
MLLMs, achieving robust and outstanding results that highlight the
effectiveness and superiority of our method. Our code will be publicly
available.

</details>


### [37] [Video Consistency Distance: Enhancing Temporal Consistency for Image-to-Video Generation via Reward-Based Fine-Tuning](https://arxiv.org/abs/2510.19193)
*Takehiro Aoshima,Yusuke Shinohara,Park Byeongseon*

Main category: cs.CV

TL;DR: 本文提出了一种名为视频一致性距离（VCD）的新度量，用于通过在频域分析视频帧特征来增强视频扩散模型奖励微调中的时间一致性，尤其是在图像到视频（I2V）生成任务中。


<details>
  <summary>Details</summary>
Motivation: 奖励驱动的视频扩散模型微调可以提高生成视频的质量，但现有奖励函数主要关注整体质量（如美观和一致性），导致在图像到视频（I2V）生成任务中时间一致性不足。

Method: 提出了一种新颖的度量——视频一致性距离（VCD），旨在增强时间一致性。VCD在视频帧特征的频域中定义，通过频域分析有效捕获帧信息，并将其用于奖励驱动的微调框架。

Result: 在多个I2V数据集上的实验结果表明，使用VCD对视频生成模型进行微调，显著增强了时间一致性，且未降低其他性能，优于现有方法。

Conclusion: 通过在频域中定义VCD，本研究成功解决了奖励驱动微调中图像到视频生成任务的时间一致性问题，显著提升了生成视频的连贯性。

Abstract: Reward-based fine-tuning of video diffusion models is an effective approach
to improve the quality of generated videos, as it can fine-tune models without
requiring real-world video datasets. However, it can sometimes be limited to
specific performances because conventional reward functions are mainly aimed at
enhancing the quality across the whole generated video sequence, such as
aesthetic appeal and overall consistency. Notably, the temporal consistency of
the generated video often suffers when applying previous approaches to
image-to-video (I2V) generation tasks. To address this limitation, we propose
Video Consistency Distance (VCD), a novel metric designed to enhance temporal
consistency, and fine-tune a model with the reward-based fine-tuning framework.
To achieve coherent temporal consistency relative to a conditioning image, VCD
is defined in the frequency space of video frame features to capture frame
information effectively through frequency-domain analysis. Experimental results
across multiple I2V datasets demonstrate that fine-tuning a video generation
model with VCD significantly enhances temporal consistency without degrading
other performance compared to the previous method.

</details>


### [38] [Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks](https://arxiv.org/abs/2510.19195)
*Kai Zeng,Zhanqian Wu,Kaixin Xiong,Xiaobao Wei,Xiangyu Guo,Zhenxin Zhu,Kalok Ho,Lijun Zhou,Bohan Zeng,Ming Lu,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye,Wentao Zhang*

Main category: cs.CV

TL;DR: 本文提出了Dream4Drive，一个用于自动驾驶的合成数据生成框架，通过分解视频、渲染3D资产来生成多视角、逼真的视频，旨在提升下游感知任务的性能，并解决了现有方法对感知评估的忽视及合成数据效益不明显的问题。同时，还贡献了一个大规模3D资产数据集DriveObj3D。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶世界模型主要关注生成质量和可控性指标，但忽视了对自动驾驶至关重要的下游感知任务的评估。此外，现有合成数据预训练策略在基线（仅真实数据）训练周期加倍时，其效益变得微不足道，未能充分展示合成数据的真正优势。

Method: Dream4Drive首先将输入视频分解为3D感知引导图，然后将3D资产渲染到这些引导图上。最后，对驾驶世界模型进行微调，以生成经过编辑的多视角逼真视频，用于训练下游感知模型。此外，还贡献了一个名为DriveObj3D的大规模3D资产数据集。

Result: Dream4Drive能够以前所未有的灵活性大规模生成多视角极端情况（corner cases），显著提升了自动驾驶中的极端情况感知能力。综合实验表明，Dream4Drive在不同训练周期下都能有效提升下游感知模型的性能。

Conclusion: Dream4Drive提供了一个新颖的合成数据生成框架，能够有效提升下游感知模型的性能，尤其是在处理极端情况时，并充分证明了合成数据对自动驾驶感知任务的真正益处。

Abstract: Recent advancements in driving world models enable controllable generation of
high-quality RGB videos or multimodal videos. Existing methods primarily focus
on metrics related to generation quality and controllability. However, they
often overlook the evaluation of downstream perception tasks, which are
$\mathbf{really\ crucial}$ for the performance of autonomous driving. Existing
methods usually leverage a training strategy that first pretrains on synthetic
data and finetunes on real data, resulting in twice the epochs compared to the
baseline (real data only). When we double the epochs in the baseline, the
benefit of synthetic data becomes negligible. To thoroughly demonstrate the
benefit of synthetic data, we introduce Dream4Drive, a novel synthetic data
generation framework designed for enhancing the downstream perception tasks.
Dream4Drive first decomposes the input video into several 3D-aware guidance
maps and subsequently renders the 3D assets onto these guidance maps. Finally,
the driving world model is fine-tuned to produce the edited, multi-view
photorealistic videos, which can be used to train the downstream perception
models. Dream4Drive enables unprecedented flexibility in generating multi-view
corner cases at scale, significantly boosting corner case perception in
autonomous driving. To facilitate future research, we also contribute a
large-scale 3D asset dataset named DriveObj3D, covering the typical categories
in driving scenarios and enabling diverse 3D-aware video editing. We conduct
comprehensive experiments to show that Dream4Drive can effectively boost the
performance of downstream perception models under various training epochs.
Project: $\href{https://wm-research.github.io/Dream4Drive/}{this\ https\ URL}$

</details>


### [39] [MoE-GS: Mixture of Experts for Dynamic Gaussian Splatting](https://arxiv.org/abs/2510.19210)
*In-Hwan Jin,Hyeongju Mun,Joonsoo Kim,Kugjin Yun,Kyeongbo Kong*

Main category: cs.CV

TL;DR: 本文提出MoE-GS，一种将专家混合（MoE）技术引入动态高斯泼溅的统一框架，通过体素感知像素路由器自适应融合专家输出，并结合效率优化和蒸馏策略，显著提升了动态场景重建的渲染质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有动态场景重建的3D高斯泼溅方法在不同场景中表现不一致，没有单一方法能有效应对所有动态挑战。

Method: 本文提出了动态高斯泼溅专家混合（MoE-GS）框架，通过新颖的体素感知像素路由器，将体素高斯级别权重投影到像素空间，以可微分权重泼溅的方式自适应融合多个专家输出。为解决MoE架构带来的模型容量增加和帧率下降问题，作者探索了两种互补方向：1) 单通道多专家渲染和门控感知高斯剪枝，以提高MoE框架内的效率；2) 一种蒸馏策略，将MoE性能转移到单个专家，实现轻量级部署。

Result: 在N3V和Technicolor数据集上的大量实验表明，MoE-GS持续优于最先进的方法，实现了更高的渲染质量和改进的效率。据作者所知，MoE-GS是首个将专家混合技术整合到动态高斯泼溅中的方法。

Conclusion: MoE-GS通过引入专家混合技术、自适应路由和效率优化策略，成功解决了现有动态高斯泼溅方法在处理多样化场景时的局限性，实现了卓越的动态场景重建性能和效率。

Abstract: Recent advances in dynamic scene reconstruction have significantly benefited
from 3D Gaussian Splatting, yet existing methods show inconsistent performance
across diverse scenes, indicating no single approach effectively handles all
dynamic challenges. To overcome these limitations, we propose Mixture of
Experts for Dynamic Gaussian Splatting (MoE-GS), a unified framework
integrating multiple specialized experts via a novel Volume-aware Pixel Router.
Our router adaptively blends expert outputs by projecting volumetric
Gaussian-level weights into pixel space through differentiable weight
splatting, ensuring spatially and temporally coherent results. Although MoE-GS
improves rendering quality, the increased model capacity and reduced FPS are
inherent to the MoE architecture. To mitigate this, we explore two
complementary directions: (1) single-pass multi-expert rendering and gate-aware
Gaussian pruning, which improve efficiency within the MoE framework, and (2) a
distillation strategy that transfers MoE performance to individual experts,
enabling lightweight deployment without architectural changes. To the best of
our knowledge, MoE-GS is the first approach incorporating Mixture-of-Experts
techniques into dynamic Gaussian splatting. Extensive experiments on the N3V
and Technicolor datasets demonstrate that MoE-GS consistently outperforms
state-of-the-art methods with improved efficiency. Video demonstrations are
available at https://anonymous.4open.science/w/MoE-GS-68BA/.

</details>


### [40] [SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion](https://arxiv.org/abs/2510.19215)
*Xiaozhi Li,Huijun Di,Jian Li,Feng Liu,Wei Liang*

Main category: cs.CV

TL;DR: 本文提出SFGFusion，一种相机-4D成像雷达检测网络，通过表面拟合增强空间表示和跨模态交互，生成精细深度，并利用该深度指导图像特征的透视视图到鸟瞰视图转换以及生成密集伪点云，从而有效融合多模态数据并提升3D目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 4D成像雷达作为新兴传感器，具有低成本、长距离检测和精确速度测量的优势，非常适合目标检测。然而，其稀疏点云和低分辨率限制了物体几何表示并阻碍了多模态融合，因此需要改进。

Method: SFGFusion网络通过表面拟合指导，从图像和雷达数据估计物体的二次曲面参数，从而增强空间表示和跨模态交互，预测精细的密集深度。预测的深度用于：1) 在图像分支中，指导图像特征从透视视图（PV）转换到统一的鸟瞰视图（BEV），提高空间映射精度；2) 在表面伪点分支中，生成密集伪点云，缓解雷达点云的稀疏性。原始雷达点云在独立的雷达分支中编码。这两个点云分支都采用基于柱的方法，并将特征转换到BEV空间。最后，使用标准的2D骨干网络和检测头从BEV特征预测物体标签和边界框。

Result: 实验结果表明，SFGFusion有效融合了相机和4D雷达特征，在TJ4DRadSet和view-of-delft（VoD）目标检测基准上取得了优异的性能。

Conclusion: SFGFusion通过引入表面拟合模型，有效解决了4D成像雷达的稀疏性问题，增强了多模态融合，实现了更可靠的深度预测和空间映射，从而显著提升了相机-4D雷达协同的3D目标检测能力。

Abstract: 3D object detection is essential for autonomous driving. As an emerging
sensor, 4D imaging radar offers advantages as low cost, long-range detection,
and accurate velocity measurement, making it highly suitable for object
detection. However, its sparse point clouds and low resolution limit object
geometric representation and hinder multi-modal fusion. In this study, we
introduce SFGFusion, a novel camera-4D imaging radar detection network guided
by surface fitting. By estimating quadratic surface parameters of objects from
image and radar data, the explicit surface fitting model enhances spatial
representation and cross-modal interaction, enabling more reliable prediction
of fine-grained dense depth. The predicted depth serves two purposes: 1) in an
image branch to guide the transformation of image features from perspective
view (PV) to a unified bird's-eye view (BEV) for multi-modal fusion, improving
spatial mapping accuracy; and 2) in a surface pseudo-point branch to generate
dense pseudo-point cloud, mitigating the radar point sparsity. The original
radar point cloud is also encoded in a separate radar branch. These two point
cloud branches adopt a pillar-based method and subsequently transform the
features into the BEV space. Finally, a standard 2D backbone and detection head
are used to predict object labels and bounding boxes from BEV features.
Experimental results show that SFGFusion effectively fuses camera and 4D radar
features, achieving superior performance on the TJ4DRadSet and view-of-delft
(VoD) object detection benchmarks.

</details>


### [41] [Space Object Detection using Multi-frame Temporal Trajectory Completion Method](https://arxiv.org/abs/2510.19220)
*Xiaoqing Lan,Biqiao Xin,Bingshu Wang,Han Zhang,Laixian Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种结合小波变换单帧增强和基于匈牙利算法的多帧轨迹完成方案，以有效检测地球静止轨道（GEO）空间目标，并在公共数据集上实现了90.14%的F_1分数。


<details>
  <summary>Details</summary>
Motivation: 地球静止轨道（GEO）空间目标在光学成像中存在显著的检测挑战，原因在于信号微弱、星空背景复杂以及环境干扰。

Method: 该方法首先在单帧层面通过小波变换增强高频特征并抑制背景噪声。在此基础上，提出了一种以匈牙利算法为核心的多帧时间轨迹完成方案，用于全局最优的跨帧匹配。后处理流程中设计了一系列关键步骤，包括时间匹配和插值完成、基于时间一致性的噪声过滤以及渐进式轨迹细化，以有效缓解漏检和误检。

Result: 在公共SpotGEO数据集上的实验结果表明，所提出的方法有效，达到了90.14%的F_1分数。

Conclusion: 该方法通过结合单帧增强和多帧轨迹完成，能有效应对GEO目标检测的挑战，并取得了良好的性能。

Abstract: Space objects in Geostationary Earth Orbit (GEO) present significant
detection challenges in optical imaging due to weak signals, complex stellar
backgrounds, and environmental interference. In this paper, we enhance
high-frequency features of GEO targets while suppressing background noise at
the single-frame level through wavelet transform. Building on this, we propose
a multi-frame temporal trajectory completion scheme centered on the Hungarian
algorithm for globally optimal cross-frame matching. To effectively mitigate
missing and false detections, a series of key steps including temporal matching
and interpolation completion, temporal-consistency-based noise filtering, and
progressive trajectory refinement are designed in the post-processing pipeline.
Experimental results on the public SpotGEO dataset demonstrate the
effectiveness of the proposed method, achieving an F_1 score of 90.14%.

</details>


### [42] [Background Fades, Foreground Leads: Curriculum-Guided Background Pruning for Efficient Foreground-Centric Collaborative Perception](https://arxiv.org/abs/2510.19250)
*Yuheng Wu,Xiangbo Gao,Quang Tau,Zhengzhong Tu,Dongman Lee*

Main category: cs.CV

TL;DR: FadeLead是一个前景中心化的协同感知框架，通过课程学习策略将背景上下文信息编码到前景特征中，有效解决了带宽限制下前景感知丢失背景上下文的问题，在各种带宽设置下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的协同感知通过信息共享提高可靠性和覆盖范围，但车载网络的带宽限制使得传输整个特征图不切实际。现有前景中心化方法虽然节省带宽，但会丢弃包含重要上下文信息的背景，这限制了其性能。

Method: 本文提出了FadeLead框架。其核心设计是一种课程学习策略，在训练初期利用背景线索，然后逐渐将其移除，迫使模型将背景上下文内化到前景表示中，而无需实际传输背景信息。该方法旨在将背景上下文封装到紧凑的前景特征中。

Result: 在模拟和真实世界的基准测试中，FadeLead在不同的带宽设置下均优于现有方法，证明了富含上下文信息的前景共享的有效性。

Conclusion: FadeLead通过学习将背景上下文信息封装到紧凑的前景特征中，克服了前景中心化协同感知中背景信息丢失的局限性，实现了更有效的上下文丰富的前景共享，提升了自动驾驶的协同感知性能。

Abstract: Collaborative perception enhances the reliability and spatial coverage of
autonomous vehicles by sharing complementary information across vehicles,
offering a promising solution to long-tail scenarios that challenge
single-vehicle perception. However, the bandwidth constraints of vehicular
networks make transmitting the entire feature map impractical. Recent methods,
therefore, adopt a foreground-centric paradigm, transmitting only predicted
foreground-region features while discarding the background, which encodes
essential context. We propose FadeLead, a foreground-centric framework that
overcomes this limitation by learning to encapsulate background context into
compact foreground features during training. At the core of our design is a
curricular learning strategy that leverages background cues early on but
progressively prunes them away, forcing the model to internalize context into
foreground representations without transmitting background itself. Extensive
experiments on both simulated and real-world benchmarks show that FadeLead
outperforms prior methods under different bandwidth settings, underscoring the
effectiveness of context-enriched foreground sharing.

</details>


### [43] [Advances in 4D Representation: Geometry, Motion, and Interaction](https://arxiv.org/abs/2510.19255)
*Mingrui Zhao,Sauradip Nag,Kai Wang,Aditya Vora,Guangda Ji,Peter Chun,Ali Mahdavi-Amiri,Hao Zhang*

Main category: cs.CV

TL;DR: 本文对4D生成和重建领域进行了综述，重点关注建模随时间演变的3D几何、运动和交互的4D表示方法，并指导读者如何选择和定制合适的表示。


<details>
  <summary>Details</summary>
Motivation: 4D生成和重建是一个快速发展的子领域，得益于神经场、几何和运动深度学习以及3D生成式AI的进步。本综述旨在从4D表示的独特视角，帮助读者理解并选择适合其任务的4D表示方法。

Method: 本综述采用选择性方法，聚焦于代表性工作，从几何、运动和交互三个核心支柱对4D表示进行分类。它涵盖了神经辐射场（NeRFs）和3D高斯泼溅（3DGS）等流行表示，也探讨了结构化模型和长程运动等较少探索的表示。此外，还讨论了大型语言模型（LLMs）和视频基础模型（VFMs）的作用、局限性以及现有4D数据集的状况。

Result: 本综述的“结果”是提供了对各种4D表示的理想特性和挑战的深入见解，并为读者如何根据计算、应用和数据场景选择和定制适当的4D表示提供了指导。它还指出了LLMs和VFMs在4D应用中的当前局限性以及4D数据集的不足。

Conclusion: 本综述旨在帮助读者为他们的任务选择和定制合适的4D表示，通过对该领域的结构化概述，阐明了当前最受欢迎和潜在的表示方法，并指出了未来的挑战和发展方向，特别是在LLMs、VFMs和数据集方面。

Abstract: We present a survey on 4D generation and reconstruction, a fast-evolving
subfield of computer graphics whose developments have been propelled by recent
advances in neural fields, geometric and motion deep learning, as well 3D
generative artificial intelligence (GenAI). While our survey is not the first
of its kind, we build our coverage of the domain from a unique and distinctive
perspective of 4D representations\/}, to model 3D geometry evolving over time
while exhibiting motion and interaction. Specifically, instead of offering an
exhaustive enumeration of many works, we take a more selective approach by
focusing on representative works to highlight both the desirable properties and
ensuing challenges of each representation under different computation,
application, and data scenarios. The main take-away message we aim to convey to
the readers is on how to select and then customize the appropriate 4D
representations for their tasks. Organizationally, we separate the 4D
representations based on three key pillars: geometry, motion, and interaction.
Our discourse will not only encompass the most popular representations of
today, such as neural radiance fields (NeRFs) and 3D Gaussian Splatting (3DGS),
but also bring attention to relatively under-explored representations in the 4D
context, such as structured models and long-range motions. Throughout our
survey, we will reprise the role of large language models (LLMs) and video
foundational models (VFMs) in a variety of 4D applications, while steering our
discussion towards their current limitations and how they can be addressed. We
also provide a dedicated coverage on what 4D datasets are currently available,
as well as what is lacking, in driving the subfield forward. Project
page:https://mingrui-zhao.github.io/4DRep-GMI/

</details>


### [44] [SCEESR: Semantic-Control Edge Enhancement for Diffusion-Based Super-Resolution](https://arxiv.org/abs/2510.19272)
*Yun Kai Zhuang*

Main category: cs.CV

TL;DR: 该论文提出了一种新的超分辨率（SR）框架，通过ControlNet机制结合语义边缘指导来增强一步扩散模型，并引入混合损失函数，以在保持一步生成效率的同时，有效提升图像的结构完整性和真实感。


<details>
  <summary>Details</summary>
Motivation: 现实世界图像超分辨率（Real-ISR）面临复杂的降级和固有的重建模糊性。虽然生成模型提高了感知质量，但计算成本仍是一个关键权衡。一步扩散模型速度快，但由于蒸馏伪影常导致结构不准确。

Method: 该研究提出了一种新的SR框架，通过使用ControlNet机制进行语义边缘指导来增强一步扩散模型。这在单次推理过程中整合了边缘信息以提供动态结构控制。此外，引入了一种结合L2、LPIPS和边缘感知AME损失的混合损失函数，以优化像素精度、感知质量和几何精度。

Result: 实验表明，该方法有效改善了结构完整性和真实感，同时保持了一步生成的效率，实现了输出质量和推理速度之间的优越平衡。

Conclusion: 该方法成功解决了Real-ISR中感知质量、结构准确性和计算成本之间的权衡问题，通过一步扩散模型结合边缘指导和混合损失，实现了高效且高质量的图像超分辨率。

Abstract: Real-world image super-resolution (Real-ISR) must handle complex degradations
and inherent reconstruction ambiguities. While generative models have improved
perceptual quality, a key trade-off remains with computational cost. One-step
diffusion models offer speed but often produce structural inaccuracies due to
distillation artifacts. To address this, we propose a novel SR framework that
enhances a one-step diffusion model using a ControlNet mechanism for semantic
edge guidance. This integrates edge information to provide dynamic structural
control during single-pass inference. We also introduce a hybrid loss combining
L2, LPIPS, and an edge-aware AME loss to optimize for pixel accuracy,
perceptual quality, and geometric precision. Experiments show our method
effectively improves structural integrity and realism while maintaining the
efficiency of one-step generation, achieving a superior balance between output
quality and inference speed. The results of test datasets will be published at
https://drive.google.com/drive/folders/1amddXQ5orIyjbxHgGpzqFHZ6KTolinJF?usp=drive_link
and the related code will be published at
https://github.com/ARBEZ-ZEBRA/SCEESR.

</details>


### [45] [From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction](https://arxiv.org/abs/2510.19654)
*Zhida Zhao,Talas Fu,Yifan Wang,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为策略世界模型（PWM）的新型驾驶范式，它将世界建模和轨迹规划整合到统一架构中，并通过无动作未来状态预测机制，利用学习到的世界知识提升规划性能，即使仅使用前置摄像头输入也能达到或超越现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 尽管世界模型在驾驶领域取得了显著进展，但其在自动驾驶系统中的潜力仍未充分发挥，主要原因是世界模型通常用于模拟且与轨迹规划分离。虽然近期有工作尝试统一两者，但世界建模如何协同促进规划的机制仍需进一步探索。

Method: 本文引入了策略世界模型（PWM），该模型在一个统一架构中整合了世界建模和轨迹规划。它通过提出的无动作未来状态预测方案，利用学习到的世界知识来辅助规划。通过协同的状态-动作预测，PWM能够模仿人类的预期感知。此外，为提高视频预测效率，PWM还引入了动态增强的并行令牌生成机制，配备了上下文引导的分词器和自适应动态焦点损失。

Result: 尽管仅使用前置摄像头输入，本文提出的方法却能与依赖多视角和多模态输入的现有最先进方法相媲美或超越它们。

Conclusion: 策略世界模型（PWM）成功地将世界建模和轨迹规划集成到统一框架中，并通过创新的无动作未来状态预测和协同状态-动作预测，实现了类似人类的预期感知，从而显著提升了规划性能，并展现出仅凭单目输入超越多模态输入的潜力。

Abstract: Despite remarkable progress in driving world models, their potential for
autonomous systems remains largely untapped: the world models are mostly
learned for world simulation and decoupled from trajectory planning. While
recent efforts aim to unify world modeling and planning in a single framework,
the synergistic facilitation mechanism of world modeling for planning still
requires further exploration. In this work, we introduce a new driving paradigm
named Policy World Model (PWM), which not only integrates world modeling and
trajectory planning within a unified architecture, but is also able to benefit
planning using the learned world knowledge through the proposed action-free
future state forecasting scheme. Through collaborative state-action prediction,
PWM can mimic the human-like anticipatory perception, yielding more reliable
planning performance. To facilitate the efficiency of video forecasting, we
further introduce a dynamically enhanced parallel token generation mechanism,
equipped with a context-guided tokenizer and an adaptive dynamic focal loss.
Despite utilizing only front camera input, our method matches or exceeds
state-of-the-art approaches that rely on multi-view and multi-modal inputs.
Code and model weights will be released at
https://github.com/6550Zhao/Policy-World-Model.

</details>


### [46] [MobiAct: Efficient MAV Action Recognition Using MobileNetV4 with Contrastive Learning and Knowledge Distillation](https://arxiv.org/abs/2510.19273)
*Zhang Nengbo,Ho Hann Woei*

Main category: cs.CV

TL;DR: 本文提出了MobiAct，一个轻量级MAV动作识别框架，通过MobileNetV4、分阶段正交知识蒸馏、无参数注意力机制和混合损失策略，在低能耗、低计算量下实现了高精度和极快的解码速度。


<details>
  <summary>Details</summary>
Motivation: 现有MAV动作识别方法依赖于计算密集型模型，不适用于资源受限的MAV平台，导致识别精度和推理速度之间存在权衡，难以实现自主空中群体的实时感知和协调。

Method: 本文提出了MobiAct框架：1. 采用MobileNetV4作为骨干网络。2. 引入分阶段正交知识蒸馏（SOKD）策略，将ResNet18教师网络的MAV运动特征有效迁移到学生网络。3. 集成无参数注意力机制，提高识别精度而不增加模型复杂度。4. 开发混合损失训练策略，结合多个损失目标，确保训练过程的稳定和鲁棒优化。

Result: MobiAct在三个自收集数据集上实现了平均92.12%的识别精度，同时仅消耗136.16 pJ的能量，以每秒8.84个动作的速度进行识别。其动作解码速度比领先方法快2倍，且识别精度具有高度可比性。

Conclusion: MobiAct框架在MAV动作识别方面表现出卓越的效率，在保持高识别精度的同时，实现了低能耗、低计算量和最快的动作解码速度，有效解决了资源受限MAV平台的挑战。

Abstract: Accurate and efficient recognition of Micro Air Vehicle (MAV) motion is
essential for enabling real-time perception and coordination in autonomous
aerial swarm. However, most existing approaches rely on large, computationally
intensive models that are unsuitable for resource-limited MAV platforms, which
results in a trade-off between recognition accuracy and inference speed. To
address these challenges, this paper proposes a lightweight MAV action
recognition framework, MobiAct, designed to achieve high accuracy with low
computational cost. Specifically, MobiAct adopts MobileNetV4 as the backbone
network and introduces a Stage-wise Orthogonal Knowledge Distillation (SOKD)
strategy to effectively transfer MAV motion features from a teacher network
(ResNet18) to a student network, thereby enhancing knowledge transfer
efficiency. Furthermore, a parameter-free attention mechanism is integrated
into the architecture to improve recognition accuracy without increasing model
complexity. In addition, a hybrid loss training strategy is developed to
combine multiple loss objectives, which ensures stable and robust optimization
during training. Experimental results demonstrate that the proposed MobiAct
achieves low-energy and low-computation MAV action recognition, while
maintaining the fastest action decoding speed among compared methods. Across
all three self-collected datasets, MobiAct achieves an average recognition
accuracy of 92.12%, while consuming only 136.16 pJ of energy and processing
recognition at a rate of 8.84 actions per second. Notably, MobiAct decodes
actions up to 2 times faster than the leading method, with highly comparable
recognition accuracy, highlighting its superior efficiency in MAV action
recognition.

</details>


### [47] [Enhancing Early Alzheimer Disease Detection through Big Data and Ensemble Few-Shot Learning](https://arxiv.org/abs/2510.19282)
*Safa Ben Atitallah,Maha Driss,Wadii Boulila,Anis Koubaa*

Main category: cs.CV

TL;DR: 本研究提出了一种基于少样本学习（FSL）和集成学习的阿尔茨海默病（AD）检测方法，通过结合预训练CNN和原型网络，在有限标记数据下实现了高精度检测。


<details>
  <summary>Details</summary>
Motivation: 标记医学数据稀缺、疾病复杂性以及数据隐私限制是阿尔茨海默病准确检测面临的重大挑战，急需有效方法来提高检测精度。

Method: 该研究利用预训练卷积神经网络（CNNs）作为编码器，结合少样本学习（FSL）中的原型网络（ProtoNet），构建了一个集成学习方法。此外，还结合了类别感知损失（class-aware loss）和熵损失（entropy loss）以提高分类精度。

Result: 该方法在Kaggle阿尔茨海默数据集上达到了99.72%的准确率，在ADNI数据集上达到了99.86%的准确率，优于现有最先进的研究。

Conclusion: 所提出的方法在阿尔茨海默病早期检测中表现出卓越的准确性，验证了其有效性，并展现了在实际应用中的巨大潜力。

Abstract: Alzheimer disease is a severe brain disorder that causes harm in various
brain areas and leads to memory damage. The limited availability of labeled
medical data poses a significant challenge for accurate Alzheimer disease
detection. There is a critical need for effective methods to improve the
accuracy of Alzheimer disease detection, considering the scarcity of labeled
data, the complexity of the disease, and the constraints related to data
privacy. To address this challenge, our study leverages the power of big data
in the form of pre-trained Convolutional Neural Networks (CNNs) within the
framework of Few-Shot Learning (FSL) and ensemble learning. We propose an
ensemble approach based on a Prototypical Network (ProtoNet), a powerful method
in FSL, integrating various pre-trained CNNs as encoders. This integration
enhances the richness of features extracted from medical images. Our approach
also includes a combination of class-aware loss and entropy loss to ensure a
more precise classification of Alzheimer disease progression levels. The
effectiveness of our method was evaluated using two datasets, the Kaggle
Alzheimer dataset and the ADNI dataset, achieving an accuracy of 99.72% and
99.86%, respectively. The comparison of our results with relevant
state-of-the-art studies demonstrated that our approach achieved superior
accuracy and highlighted its validity and potential for real-world applications
in early Alzheimer disease detection.

</details>


### [48] [D2D: Detector-to-Differentiable Critic for Improved Numeracy in Text-to-Image Generation](https://arxiv.org/abs/2510.19278)
*Nobline Yoo,Olga Russakovsky,Ye Zhu*

Main category: cs.CV

TL;DR: 该论文提出D2D框架，将非可微检测模型转换为可微计数器，以指导文本到图像（T2I）扩散模型在生成图像时实现更准确的物体计数，显著提升了计数精度。


<details>
  <summary>Details</summary>
Motivation: T2I扩散模型在语义对齐方面表现出色，但在生成指定数量的物体时仍有困难。现有方法依赖于可微的回归模型作为计数器，但这些模型在计数能力上不如基于检测的模型。然而，基于检测的模型由于其枚举性质，通常是不可微的，因此无法直接用于提供梯度指导。

Method: 本文提出了Detector-to-Differentiable (D2D) 框架。通过设计定制的激活函数，将检测器 logits 转换为软二值指示符，从而将不可微的检测模型转化为可微的评论家。这些可微评论家随后在推理时，利用预训练的T2I模型，优化噪声先验，以指导数字生成。

Result: 在SDXL-Turbo、SD-Turbo和Pixart-DMD等模型以及低密度、高密度和多对象场景的四个基准测试中，D2D框架在物体计数精度方面取得了持续且显著的提升（例如，在D2D-Small基准上提升高达13.7%），同时对整体图像质量和计算开销的影响极小。

Conclusion: D2D框架成功地克服了非可微检测模型在指导T2I模型计数方面的限制，通过将其转化为可微评论家，有效利用了它们卓越的计数能力，从而显著提高了T2I模型生成指定数量物体的准确性。

Abstract: Text-to-image (T2I) diffusion models have achieved strong performance in
semantic alignment, yet they still struggle with generating the correct number
of objects specified in prompts. Existing approaches typically incorporate
auxiliary counting networks as external critics to enhance numeracy. However,
since these critics must provide gradient guidance during generation, they are
restricted to regression-based models that are inherently differentiable, thus
excluding detector-based models with superior counting ability, whose
count-via-enumeration nature is non-differentiable. To overcome this
limitation, we propose Detector-to-Differentiable (D2D), a novel framework that
transforms non-differentiable detection models into differentiable critics,
thereby leveraging their superior counting ability to guide numeracy
generation. Specifically, we design custom activation functions to convert
detector logits into soft binary indicators, which are then used to optimize
the noise prior at inference time with pre-trained T2I models. Our extensive
experiments on SDXL-Turbo, SD-Turbo, and Pixart-DMD across four benchmarks of
varying complexity (low-density, high-density, and multi-object scenarios)
demonstrate consistent and substantial improvements in object counting accuracy
(e.g., boosting up to 13.7% on D2D-Small, a 400-prompt, low-density benchmark),
with minimal degradation in overall image quality and computational overhead.

</details>


### [49] [Unified Reinforcement and Imitation Learning for Vision-Language Models](https://arxiv.org/abs/2510.19307)
*Byung-Kwan Lee,Ryo Hachiuma,Yong Man Ro,Yu-Chiang Frank Wang,Yueh-Hua Wu*

Main category: cs.CV

TL;DR: 本文提出了一种名为统一强化与模仿学习（RIL）的新型高效训练算法，旨在创建功能强大且轻量级的视觉-语言模型（VLMs），使其在资源受限环境中也能表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型（VLMs）取得了显著进展，但其庞大的规模使其在资源受限的环境中不切实际。因此，需要一种能够创建强大且轻量级VLM的高效训练算法。

Method: RIL算法独特地结合了强化学习和对抗性模仿学习的优势。它利用一个基于大型语言模型（LLM）的判别器来区分学生模型和教师模型的输出，并辅以多个大型教师VLM的指导以确保学习的多样性。学生VLM不仅模仿大型教师模型的复杂文本生成，还通过强化信号系统地提高其生成能力。

Result: 在多样化的视觉-语言基准测试中，广泛的实验表明RIL显著缩小了与最先进的开源和闭源VLM的性能差距，并在某些情况下超越了它们。这种统一的学习策略使学生模型实现了显著的性能提升，使其与领先的闭源VLM具有竞争力。

Conclusion: RIL通过统一强化学习和模仿学习，成功地为资源受限环境创建了强大而轻量级的VLM。该方法能够使学生模型在性能上与领先的VLM相媲美，甚至超越它们，从而提供了高效且高性能的解决方案。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress, yet their
large scale often renders them impractical for resource-constrained
environments. This paper introduces Unified Reinforcement and Imitation
Learning (RIL), a novel and efficient training algorithm designed to create
powerful, lightweight VLMs. RIL distinctively combines the strengths of
reinforcement learning with adversarial imitation learning. This enables
smaller student VLMs not only to mimic the sophisticated text generation of
large teacher models but also to systematically improve their generative
capabilities through reinforcement signals. Key to our imitation framework is
an LLM-based discriminator that adeptly distinguishes between student and
teacher outputs, complemented by guidance from multiple large teacher VLMs to
ensure diverse learning. This unified learning strategy, leveraging both
reinforcement and imitation, empowers student models to achieve significant
performance gains, making them competitive with leading closed-source VLMs.
Extensive experiments on diverse vision-language benchmarks demonstrate that
RIL significantly narrows the performance gap with state-of-the-art open- and
closed-source VLMs and, in several instances, surpasses them.

</details>


### [50] [Vision-Based Mistake Analysis in Procedural Activities: A Review of Advances and Challenges](https://arxiv.org/abs/2510.19292)
*Konstantinos Bacharidis,Antonis A. Argyros*

Main category: cs.CV

TL;DR: 本文综述了基于视觉的方法，用于检测和预测程序性活动中的错误，重点关注程序性和执行性错误，并探讨了相关挑战、现有方法、数据集和未来方向。


<details>
  <summary>Details</summary>
Motivation: 程序性活动中的错误分析是一个关键研究领域，在工业自动化、物理康复、教育和人机协作等领域具有广泛应用，旨在提高安全性、效率和任务性能。

Method: 该研究回顾了利用计算机视觉（包括动作识别、预测和活动理解）的基于视觉系统，以识别任务执行中的偏差（如错误排序、不当技术或时间错误）。文章探讨了类内变异性、视点差异和组合活动结构带来的挑战，并全面概述了现有数据集、评估指标和最先进的方法，根据程序结构、监督级别和学习策略对方法进行分类。

Result: 本文识别了基于视觉系统在检测程序性活动错误方面的潜力，讨论了复杂性（如类内变异性和视点差异）。它提供了对现有资源（数据集、评估指标、最先进方法）的全面概览，并讨论了区分允许变异与真实错误、建模错误传播等开放挑战，以及神经符号推理和反事实状态建模等未来方向。

Conclusion: 这项工作旨在为程序性活动中基于视觉的错误分析建立统一视角，强调其在不同领域提高安全性、效率和任务性能的潜力。

Abstract: Mistake analysis in procedural activities is a critical area of research with
applications spanning industrial automation, physical rehabilitation, education
and human-robot collaboration. This paper reviews vision-based methods for
detecting and predicting mistakes in structured tasks, focusing on procedural
and executional errors. By leveraging advancements in computer vision,
including action recognition, anticipation and activity understanding,
vision-based systems can identify deviations in task execution, such as
incorrect sequencing, use of improper techniques, or timing errors. We explore
the challenges posed by intra-class variability, viewpoint differences and
compositional activity structures, which complicate mistake detection.
Additionally, we provide a comprehensive overview of existing datasets,
evaluation metrics and state-of-the-art methods, categorizing approaches based
on their use of procedural structure, supervision levels and learning
strategies. Open challenges, such as distinguishing permissible variations from
true mistakes and modeling error propagation are discussed alongside future
directions, including neuro-symbolic reasoning and counterfactual state
modeling. This work aims to establish a unified perspective on vision-based
mistake analysis in procedural activities, highlighting its potential to
enhance safety, efficiency and task performance across diverse domains.

</details>


### [51] [Online Handwritten Signature Verification Based on Temporal-Spatial Graph Attention Transformer](https://arxiv.org/abs/2510.19321)
*Hai-jie Yuan,Heng Zhang,Fei Yin*

Main category: cs.CV

TL;DR: 本文提出了一种名为时空图注意力Transformer (TS-GATR) 的新型动态签名验证方法，通过结合图注意力网络和门控循环单元，有效建模签名数据的时空依赖性，并在基准数据集上超越了现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 手写签名验证是身份认证的关键环节，但在实际应用中，由于用户内部差异性和伪造风险，实现高精度验证仍然面临挑战。

Method: TS-GATR 将签名表示为图，其中每个节点捕获动态特征（如位置、速度、压力），并利用注意力机制建模其复杂关系。该方法采用双图注意力Transformer (DGATR) 模块，利用k步和k近邻邻接图分别建模局部和全局空间特征。同时，模型集成了门控循环单元 (GRU) 以捕获长期时间依赖性，从而增强学习签名动态特征的能力。

Result: 在MSDS和DeepSignDB等基准数据集上进行的综合实验表明，TS-GATR在各种场景下持续实现更低的等错误率 (EER)，超越了当前最先进的方法。

Conclusion: TS-GATR通过有效结合图注意力网络和门控循环单元来建模签名的时空依赖性，显著提高了动态签名验证的性能，为身份认证领域提供了一个更准确、鲁棒的解决方案。

Abstract: Handwritten signature verification is a crucial aspect of identity
authentication, with applications in various domains such as finance and
e-commerce. However, achieving high accuracy in signature verification remains
challenging due to intra-user variability and the risk of forgery. This paper
introduces a novel approach for dynamic signature verification: the
Temporal-Spatial Graph Attention Transformer (TS-GATR). TS-GATR combines the
Graph Attention Network (GAT) and the Gated Recurrent Unit (GRU) to model both
spatial and temporal dependencies in signature data. TS-GATR enhances
verification performance by representing signatures as graphs, where each node
captures dynamic features (e.g. position, velocity, pressure), and by using
attention mechanisms to model their complex relationships. The proposed method
further employs a Dual-Graph Attention Transformer (DGATR) module, which
utilizes k-step and k-nearest neighbor adjacency graphs to model local and
global spatial features, respectively. To capture long-term temporal
dependencies, the model integrates GRU, thereby enhancing its ability to learn
dynamic features during signature verification. Comprehensive experiments
conducted on benchmark datasets such as MSDS and DeepSignDB show that TS-GATR
surpasses current state-of-the-art approaches, consistently achieving lower
Equal Error Rates (EER) across various scenarios.

</details>


### [52] [Seabed-Net: A multi-task network for joint bathymetry estimation and seabed classification from remote sensing imagery in shallow waters](https://arxiv.org/abs/2510.19329)
*Panagiotis Agrafiotis,Begüm Demir*

Main category: cs.CV

TL;DR: Seabed-Net是一个统一的多任务框架，可从遥感图像同时预测水深测量和海底分类，其性能优于现有方法，为浅水区测绘提供了鲁棒的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有方法独立处理水深测量和海底分类任务，未能利用它们之间的相互作用，阻碍了深度学习方法的广泛应用。在气候和人为压力日益增加的背景下，对于欠测绘的浅水环境，需要准确、详细和定期更新的水深测量和复杂的语义内容。

Method: Seabed-Net是一个统一的多任务框架，采用双分支编码器进行水深估算和基于像素的海底分类。它通过注意力特征融合模块和窗口化Swin-Transformer融合块整合跨任务特征，并通过动态任务不确定性加权平衡目标。

Result: 在两个异质沿海地点的广泛评估中，Seabed-Net始终优于传统经验模型和传统机器学习回归方法，RMSE降低高达75%。与最先进的单任务和多任务基线相比，它将水深测量RMSE降低了10-30%，并将海底分类精度提高了高达8%。定性分析表明其具有增强的空间一致性、更清晰的栖息地边界以及对低对比度区域深度偏差的纠正。

Conclusion: 联合建模水深与底质和海底栖息地可产生协同增益，为综合浅水测绘提供了一个鲁棒、开放的解决方案。

Abstract: Accurate, detailed, and regularly updated bathymetry, coupled with complex
semantic content, is essential for under-mapped shallow-water environments
facing increasing climatological and anthropogenic pressures. However, existing
approaches that derive either depth or seabed classes from remote sensing
imagery treat these tasks in isolation, forfeiting the mutual benefits of their
interaction and hindering the broader adoption of deep learning methods. To
address these limitations, we introduce Seabed-Net, a unified multi-task
framework that simultaneously predicts bathymetry and pixel-based seabed
classification from remote sensing imagery of various resolutions. Seabed-Net
employs dual-branch encoders for bathymetry estimation and pixel-based seabed
classification, integrates cross-task features via an Attention Feature Fusion
module and a windowed Swin-Transformer fusion block, and balances objectives
through dynamic task uncertainty weighting. In extensive evaluations at two
heterogeneous coastal sites, it consistently outperforms traditional empirical
models and traditional machine learning regression methods, achieving up to
75\% lower RMSE. It also reduces bathymetric RMSE by 10-30\% compared to
state-of-the-art single-task and multi-task baselines and improves seabed
classification accuracy up to 8\%. Qualitative analyses further demonstrate
enhanced spatial consistency, sharper habitat boundaries, and corrected depth
biases in low-contrast regions. These results confirm that jointly modeling
depth with both substrate and seabed habitats yields synergistic gains,
offering a robust, open solution for integrated shallow-water mapping. Code and
pretrained weights are available at https://github.com/pagraf/Seabed-Net.

</details>


### [53] [Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization](https://arxiv.org/abs/2510.19330)
*Juncheng Wang,Lei Shang,Ziqi Liu,Wang Lu,Xixu Hu,Zhe Hu,Jindong Wang,Shujun Wang*

Main category: cs.CV

TL;DR: 本文探讨了人群定位中因训练与测试数据头部尺度分布差异（尺度偏移）导致的领域泛化性能下降问题。通过系统分析、建立基准（ScaleBench）、理论分析并提出Catto算法，量化并缓解了尺度偏移的影响，强调了这一新研究方向的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的人群定位方法在领域泛化（DG）场景下，由于训练和测试数据之间头部尺度分布的差异（尺度偏移），性能显著下降。这个问题尚未得到充分探索。

Method: 本文首先系统性地考察了人群定位性能随尺度偏移水平的变化。其次，建立了ScaleBench基准，并复现了20种先进的DG算法以量化尺度偏移的影响。接着，对尺度偏移进行了严格的理论分析。在此基础上，提出了一种名为“因果特征分解和各向异性处理”（Catto）的有效算法来缓解DG设置中尺度偏移的影响。最后，进行了广泛的分析实验。

Result: 研究结果表明，现有算法在处理尺度偏移方面存在局限性，并强调了尺度偏移的重要性与复杂性，该问题仍未得到充分探索。Catto算法能有效缓解尺度偏移的影响。此外，还揭示了未来研究的四个重要见解。

Conclusion: 尺度偏移是人群定位领域泛化中的一个关键且复杂的挑战。本文强调了其重要性，提供了量化和缓解该问题的方法（ScaleBench、理论分析、Catto算法），并开辟了一个新的研究方向——尺度偏移领域泛化。

Abstract: Crowd localization plays a crucial role in visual scene understanding towards
predicting each pedestrian location in a crowd, thus being applicable to
various downstream tasks. However, existing approaches suffer from significant
performance degradation due to discrepancies in head scale distributions (scale
shift) between training and testing data, a challenge known as domain
generalization (DG). This paper aims to comprehend the nature of scale shift
within the context of domain generalization for crowd localization models. To
this end, we address four critical questions: (i) How does scale shift
influence crowd localization in a DG scenario? (ii) How can we quantify this
influence? (iii) What causes this influence? (iv) How to mitigate the
influence? Initially, we conduct a systematic examination of how crowd
localization performance varies with different levels of scale shift. Then, we
establish a benchmark, ScaleBench, and reproduce 20 advanced DG algorithms to
quantify the influence. Through extensive experiments, we demonstrate the
limitations of existing algorithms and underscore the importance and complexity
of scale shift, a topic that remains insufficiently explored. To deepen our
understanding, we provide a rigorous theoretical analysis on scale shift.
Building on these insights, we further propose an effective algorithm called
Causal Feature Decomposition and Anisotropic Processing (Catto) to mitigate the
influence of scale shift in DG settings. Later, we also provide extensive
analytical experiments, revealing four significant insights for future
research. Our results emphasize the importance of this novel and applicable
research direction, which we term Scale Shift Domain Generalization.

</details>


### [54] [A Training-Free Framework for Open-Vocabulary Image Segmentation and Recognition with EfficientNet and CLIP](https://arxiv.org/abs/2510.19333)
*Ying Dai,Wei Yu Chen*

Main category: cs.CV

TL;DR: 本文提出一个无需训练的开放词汇图像分割与目标识别（OVSR）框架，利用EfficientNetB0进行无监督分割，并结合CLIP进行开放词汇识别。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个无需训练、能处理开放词汇的图像分割和目标识别框架。

Method: 该框架分为两阶段：1. 无监督图像分割：使用EfficientNetB0提取像素级特征，通过SVD分解获得潜在表示，然后利用分层聚类进行语义区域分割，聚类数量自适应确定。2. 段级识别：将分割区域通过CLIP的Vision Transformer编码为图像嵌入，同时使用CLIP的文本编码器从类别提示（包括“其他”）预计算文本嵌入。图像和文本嵌入通过SVD投影到共享潜在特征空间以增强跨模态对齐，并通过计算相似度进行识别。

Result: 在COCO、ADE20K和PASCAL VOC等标准基准测试中，该方法在匈牙利mIoU、精确度、召回率和F1分数方面取得了最先进的性能。

Conclusion: 所提出的框架有效、灵活且具有良好的泛化能力。

Abstract: This paper presents a novel training-free framework for open-vocabulary image
segmentation and object recognition (OVSR), which leverages EfficientNetB0, a
convolutional neural network, for unsupervised segmentation and CLIP, a
vision-language model, for open-vocabulary object recognition. The proposed
framework adopts a two stage pipeline: unsupervised image segmentation followed
by segment-level recognition via vision-language alignment. In the first stage,
pixel-wise features extracted from EfficientNetB0 are decomposed using singular
value decomposition to obtain latent representations, which are then clustered
using hierarchical clustering to segment semantically meaningful regions. The
number of clusters is adaptively determined by the distribution of singular
values. In the second stage, the segmented regions are localized and encoded
into image embeddings using the Vision Transformer backbone of CLIP. Text
embeddings are precomputed using CLIP's text encoder from category-specific
prompts, including a generic something else prompt to support open set
recognition. The image and text embeddings are concatenated and projected into
a shared latent feature space via SVD to enhance cross-modal alignment.
Recognition is performed by computing the softmax over the similarities between
the projected image and text embeddings. The proposed method is evaluated on
standard benchmarks, including COCO, ADE20K, and PASCAL VOC, achieving
state-of-the-art performance in terms of Hungarian mIoU, precision, recall, and
F1-score. These results demonstrate the effectiveness, flexibility, and
generalizability of the proposed framework.

</details>


### [55] [BrainMCLIP: Brain Image Decoding with Multi-Layer feature Fusion of CLIP](https://arxiv.org/abs/2510.19332)
*Tian Xia,Zihan Ma,Xinlong Wang,Qing Liu,Xiaowei He,Tianming Liu,Yudan Ren*

Main category: cs.CV

TL;DR: BrainMCLIP是一种参数高效的多层融合方法，通过将fMRI信号与CLIP的中间和最终层对齐，并遵循人类视觉系统功能等级，实现图像解码，无需额外的VAE路径，在语义准确性和细节保真度上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的fMRI图像解码方法通常将大脑活动映射到CLIP的最终语义层，并添加参数密集型VAE管道以捕获更精细的视觉细节。然而，这些方法忽略了CLIP中间层丰富的对象信息，且与大脑的功能层级结构相矛盾。

Method: BrainMCLIP引入了一种参数高效的多层融合方法，受人类视觉系统功能层级启发。它将来自功能不同视觉区域（低级/高级）的fMRI信号对齐到相应的CLIP中间层和最终层。此外，该方法还引入了交叉重建策略和新颖的多粒度损失。

Result: BrainMCLIP取得了极具竞争力的性能，尤其在高级语义指标上表现出色，与包括使用VAE管道的SOTA方法相匹配或超越。通过避免VAE路径，其参数量比基于VAE的SOTA方法减少了71.7%。它有效捕获了CLIP-only方法常遗漏的视觉细节，在语义准确性和细节保真度之间取得了良好平衡。

Conclusion: BrainMCLIP提供了一种参数高效的图像解码方法，通过利用CLIP的中间特征和大脑的功能层级结构，无需独立的VAE管道，即可在语义准确性和细节保真度之间取得引人注目的平衡。

Abstract: Decoding images from fMRI often involves mapping brain activity to CLIP's
final semantic layer. To capture finer visual details, many approaches add a
parameter-intensive VAE-based pipeline. However, these approaches overlook rich
object information within CLIP's intermediate layers and contradicts the
brain's functionally hierarchical. We introduce BrainMCLIP, which pioneers a
parameter-efficient, multi-layer fusion approach guided by human visual
system's functional hierarchy, eliminating the need for such a separate VAE
pathway. BrainMCLIP aligns fMRI signals from functionally distinct visual areas
(low-/high-level) to corresponding intermediate and final CLIP layers,
respecting functional hierarchy. We further introduce a Cross-Reconstruction
strategy and a novel multi-granularity loss. Results show BrainMCLIP achieves
highly competitive performance, particularly excelling on high-level semantic
metrics where it matches or surpasses SOTA(state-of-the-art) methods, including
those using VAE pipelines. Crucially, it achieves this with substantially fewer
parameters, demonstrating a reduction of
71.7\%(Table.\ref{tab:compare_clip_vae}) compared to top VAE-based SOTA
methods, by avoiding the VAE pathway. By leveraging intermediate CLIP features,
it effectively captures visual details often missed by CLIP-only approaches,
striking a compelling balance between semantic accuracy and detail fidelity
without requiring a separate VAE pipeline.

</details>


### [56] [DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents](https://arxiv.org/abs/2510.19336)
*Kai Shi,Jun Yang,Ni Yang,Binqiang Pan,Qingsong Xie,Chao Zhang,Zhenyu Yang,Tianhuang Su,Haonan Lu*

Main category: cs.CV

TL;DR: 该研究提出了DaMo，一个可训练网络，用于优化多模态大语言模型（MLLMs）在手机智能体（MPAs）多任务学习中的数据混合比例，并引入了PhoneAgentBench基准进行评估，实验证明DaMo显著提升了性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）是手机智能体（MPAs）的基础，但它们在同时处理多个手机任务时的效率有限。多任务监督微调（SFT）虽然被广泛采用，但现有方法难以确定最佳的训练数据组成以实现最佳性能。

Method: 为了解决数据混合优化问题，研究提出了DaMo（数据混合优化器），这是一个利用可训练网络预测给定数据集比例下下游任务性能，从而推断最佳数据混合比例的解决方案。同时，研究还引入了PhoneAgentBench，这是首个专门用于评估MLLMs在多模态手机任务上的基准，包含1235个问答对，涵盖了多样化的真实工业手机应用场景。

Result: DaMo在小规模试点实验中展示了强大的预测能力（R^2=0.81），并能有效地推断最佳数据混合配置。实验结果显示，DaMo在PhoneAgentBench上比其他方法实现了3.38%的性能提升。此外，在BFCL-v3、MME-Reasoning、MME-Perception和OCRBench等现有基准上的广泛实验表明，DaMo的泛化能力更优，平均分数比其他方法高出2.57%。仅用于BFCL-v3任务的MLLM优化时，DaMo将指标提高了12.47%。值得注意的是，DaMo在应用于其他模型架构时仍保持了鲁棒的可扩展性和有效性。

Conclusion: DaMo提供了一个新颖且有效的解决方案，通过优化数据混合比例来提升多模态大语言模型在手机智能体多任务场景中的性能。其在PhoneAgentBench和多个现有基准上的优越表现，以及良好的泛化性和可扩展性，证明了其在提升MPA效率和鲁棒性方面的巨大潜力。

Abstract: Mobile Phone Agents (MPAs) have emerged as a promising research direction due
to their broad applicability across diverse scenarios. While Multimodal Large
Language Models (MLLMs) serve as the foundation for MPAs, their effectiveness
in handling multiple mobile phone tasks simultaneously remains limited.
Although multitask supervised fine-tuning (SFT) is widely adopted for multitask
learning, existing approaches struggle to determine optimal training data
compositions for peak performance. To address this challenge, we propose DaMo
(Data Mixture Optimizer) - a novel solution employing a trainable network that
predicts optimal data mixtures by forecasting downstream task performance for
any given dataset ratio. To support comprehensive evaluation, we introduce
PhoneAgentBench, the first specialized benchmark to evaluate MLLMs on
multimodal mobile phone tasks, comprising 1235 QA pairs spanning diverse
real-world industrial mobile application scenarios. Demonstrating strong
predictive capability (R^2=0.81) in small-scale pilot experiments, DaMo
efficiently extrapolates optimal data mixing configurations. Our results show
DaMo achieves a 3.38% performance improvement on PhoneAgentBench compared to
alternative methods. Furthermore, extensive experiments across established
benchmarks including BFCL-v3, MME-Reasoning, MME-Perception, and OCRBench
reveal DaMo's superior generalization, outperforming other approaches by 2.57%
in terms of average score. When used solely for MLLM optimization on the
BFCL-v3 task, DaMo improves the metrics by 12.47% than other methods. Notably,
DaMo maintains robust scalability, preserving its effectiveness when applied to
other model architectures. The code and dataset are available at
https://github.com/OPPO-Mente-Lab/DaMo.git

</details>


### [57] [DARE: A Deformable Adaptive Regularization Estimator for Learning-Based Medical Image Registration](https://arxiv.org/abs/2510.19353)
*Ahsan Raza Siyal,Markus Haltmeier,Ruth Steiger,Malik Galijasevic,Elke Ruth Gizewski,Astrid Ellen Grams*

Main category: cs.CV

TL;DR: 本文提出DARE框架，通过动态调整弹性正则化（基于形变场梯度范数）并集成自适应应变和剪切能量项，同时加入折叠预防机制，以提高深度学习医学图像配准的准确性和解剖学合理性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习方法在医学图像配准中表现出色，但它们常忽视正则化在确保配准鲁棒性和解剖学合理性方面的关键作用。

Method: DARE框架动态调整弹性正则化，其调整依据是形变场的梯度范数。它整合了应变和剪切能量项，并进行自适应调制以平衡稳定性和灵活性。为确保物理上真实的变换，DARE还包含一个折叠预防机制，惩罚形变雅可比行列式为负的区域。

Result: 该策略减轻了折叠等非物理伪影，避免了过度平滑，提高了配准准确性，并增强了解剖学合理性。

Conclusion: DARE通过自适应正则化和折叠预防机制，提供了一种更鲁棒、更具解剖学合理性的形变医学图像配准方法。

Abstract: Deformable medical image registration is a fundamental task in medical image
analysis. While deep learning-based methods have demonstrated superior accuracy
and computational efficiency compared to traditional techniques, they often
overlook the critical role of regularization in ensuring robustness and
anatomical plausibility. We propose DARE (Deformable Adaptive Regularization
Estimator), a novel registration framework that dynamically adjusts elastic
regularization based on the gradient norm of the deformation field. Our
approach integrates strain and shear energy terms, which are adaptively
modulated to balance stability and flexibility. To ensure physically realistic
transformations, DARE includes a folding-prevention mechanism that penalizes
regions with negative deformation Jacobian. This strategy mitigates
non-physical artifacts such as folding, avoids over-smoothing, and improves
both registration accuracy and anatomical plausibility

</details>


### [58] [CARES: Context-Aware Resolution Selector for VLMs](https://arxiv.org/abs/2510.19496)
*Moshe Kimhi,Nimrod Shabtay,Raja Giryes,Chaim Baskin,Eli Schwartz*

Main category: cs.CV

TL;DR: CARES是一个上下文感知的图像分辨率选择器，它作为轻量级预处理模块，能预测大视觉语言模型（VLM）处理图像-查询对所需的最小输入分辨率，从而在保持性能的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（VLMs）通常以原生或高分辨率处理图像，以确保在各种任务中保持有效性。然而，这导致视觉token数量占总token的97-99%，即使低分辨率图像已足够，也会带来高昂的计算成本和延迟。

Method: CARES是一个轻量级预处理模块，给定图像-查询对，它预测最小的足够输入分辨率。它使用一个紧凑型VLM（3.5亿参数）来提取特征，并预测目标预训练VLM的响应何时收敛到其正确回答任务的峰值能力。CARES虽然被训练为一个离散分类器，但在推理时可以插值连续分辨率以实现精细控制。

Result: 在涵盖文档和自然图像的五个多模态基准测试以及各种目标VLM上，CARES在保持任务性能的同时，将计算量减少了高达80%。

Conclusion: CARES通过智能地选择最小必需的图像分辨率，有效解决了大型VLM因高分辨率输入带来的计算和延迟问题，实现了在不牺牲性能的前提下显著降低计算成本。

Abstract: Large vision-language models (VLMs) commonly process images at native or high
resolution to remain effective across tasks. This inflates visual tokens ofter
to 97-99% of total tokens, resulting in high compute and latency, even when
low-resolution images would suffice. We introduce \emph{CARES}-a
\textbf{C}ontext-\textbf{A}ware \textbf{R}esolution \textbf{S}elector, a
lightweight preprocessing module that, given an image-query pair, predicts the
\emph{minimal} sufficient input resolution. CARES uses a compact VLM (350M) to
extract features and predict when a target pretrained VLM's response converges
to its peak ability to answer correctly. Though trained as a discrete
classifier over a set of optional resolutions, CARES interpolates continuous
resolutions at inference for fine-grained control. Across five multimodal
benchmarks spanning documents and natural images, as well as diverse target
VLMs, CARES preserves task performance while reducing compute by up to 80%.

</details>


### [59] [AegisRF: Adversarial Perturbations Guided with Sensitivity for Protecting Intellectual Property of Neural Radiance Fields](https://arxiv.org/abs/2510.19371)
*Woo Jae Kim,Kyu Beom Han,Yoonki Cho,Youngju Na,Junsik Jung,Sooel Son,Sung-eui Yoon*

Main category: cs.CV

TL;DR: 该研究提出AegisRF框架，通过注入对抗性扰动来保护NeRFs的知识产权，同时利用可学习的敏感度场自适应地限制几何扰动，以在不损害渲染质量的前提下干扰未经授权的下游应用。


<details>
  <summary>Details</summary>
Motivation: 随着神经辐射场（NeRFs）成为强大的3D场景表示工具，保护其知识产权（IP）免受未经授权的使用变得至关重要。现有方法在对NeRFs进行几何扰动时，容易导致场景结构变形并显著降低渲染质量，因此需要一种新的方法来克服这一限制。

Method: 该方法引入了一种可学习的敏感度来量化几何扰动对渲染质量的空间变化影响。在此基础上，提出了AegisRF框架，包含两个主要组件：1. 扰动场（Perturbation Field），用于向NeRF模型的预渲染输出（颜色和体密度）注入对抗性扰动，以欺骗未经授权的下游目标模型；2. 敏感度场（Sensitivity Field），学习敏感度以自适应地约束几何扰动，从而在破坏未经授权使用的同时保持渲染质量。

Result: 实验评估表明，AegisRF在多种下游任务和模态中具有广泛的适用性，包括多视图图像分类和基于体素的3D定位，同时保持了高视觉保真度。

Conclusion: AegisRF成功地通过注入对抗性扰动来保护NeRFs的知识产权，并通过引入可学习的敏感度场有效解决了几何扰动导致的渲染质量下降问题，实现了在保持视觉质量的同时干扰未经授权的应用。

Abstract: As Neural Radiance Fields (NeRFs) have emerged as a powerful tool for 3D
scene representation and novel view synthesis, protecting their intellectual
property (IP) from unauthorized use is becoming increasingly crucial. In this
work, we aim to protect the IP of NeRFs by injecting adversarial perturbations
that disrupt their unauthorized applications. However, perturbing the 3D
geometry of NeRFs can easily deform the underlying scene structure and thus
substantially degrade the rendering quality, which has led existing attempts to
avoid geometric perturbations or restrict them to explicit spaces like meshes.
To overcome this limitation, we introduce a learnable sensitivity to quantify
the spatially varying impact of geometric perturbations on rendering quality.
Building upon this, we propose AegisRF, a novel framework that consists of a
Perturbation Field, which injects adversarial perturbations into the
pre-rendering outputs (color and volume density) of NeRF models to fool an
unauthorized downstream target model, and a Sensitivity Field, which learns the
sensitivity to adaptively constrain geometric perturbations, preserving
rendering quality while disrupting unauthorized use. Our experimental
evaluations demonstrate the generalized applicability of AegisRF across diverse
downstream tasks and modalities, including multi-view image classification and
voxel-based 3D localization, while maintaining high visual fidelity. Codes are
available at https://github.com/wkim97/AegisRF.

</details>


### [60] [Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes](https://arxiv.org/abs/2510.19400)
*Zhiyuan Feng,Zhaolu Kang,Qijie Wang,Zhiying Du,Jiongrui Yan,Shubin Shi,Chengbo Yuan,Huizhi Liang,Yu Deng,Qixiu Li,Rushuai Yang,Arctanx An,Leqi Zheng,Weijie Wang,Shawn Chen,Sicheng Xu,Yaobo Liang,Jiaolong Yang,Baining Guo*

Main category: cs.CV

TL;DR: 该论文提出了MV-RoboBench，一个专门用于评估视觉-语言模型（VLMs）在机器人操作中多视角空间推理能力的基准测试，并发现现有模型在此方面远低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型（VLMs）对具身AI至关重要，但其多视角信息整合能力尚未被充分探索。同时，多摄像头设置在机器人平台中日益普及，能提供互补视角以缓解遮挡和深度模糊。因此，VLMs能否有效利用多视角输入进行机器人推理是一个悬而未决的问题。

Method: 引入了MV-RoboBench基准测试，包含1.7k个人工整理的QA项，涵盖八个子任务，分为空间理解和机器人执行两大类。评估了多样化的现有VLM（包括开源和闭源模型），以及结合CoT启发式技术的增强版本。

Result: 结果显示，最先进的模型在多视角机器人感知方面仍远低于人类表现。分析揭示了两个关键发现：(i) 空间智能与多视角机器人场景中的机器人任务执行呈正相关；(ii) 在现有通用单视角空间理解基准上的强大表现，并不能可靠地转化为本基准评估的机器人空间任务的成功。

Conclusion: MV-RoboBench作为一个开放资源被发布，旨在促进空间接地VLM和VLA的进步，它不仅提供了数据，还为多视角具身推理提供了标准化的评估协议，并强调了VLMs在多视角机器人感知方面面临的重大挑战。

Abstract: Vision-language models (VLMs) are essential to Embodied AI, enabling robots
to perceive, reason, and act in complex environments. They also serve as the
foundation for the recent Vision-Language-Action (VLA) models. Yet most
evaluations of VLMs focus on single-view settings, leaving their ability to
integrate multi-view information underexplored. At the same time, multi-camera
setups are increasingly standard in robotic platforms, as they provide
complementary perspectives to mitigate occlusion and depth ambiguity. Whether
VLMs can effectively leverage such multi-view inputs for robotic reasoning
therefore remains an open question. To bridge this gap, we introduce
MV-RoboBench, a benchmark specifically designed to evaluate the multi-view
spatial reasoning capabilities of VLMs in robotic manipulation. MV-RoboBench
consists of 1.7k manually curated QA items across eight subtasks, divided into
two primary categories: spatial understanding and robotic execution. We
evaluate a diverse set of existing VLMs, including both open-source and
closed-source models, along with enhanced versions incorporating CoT-inspired
techniques. The results show that state-of-the-art models remain far below
human performance, underscoring the substantial challenges VLMs face in
multi-view robotic perception. Additionally, our analysis uncovers two key
findings: (i) spatial intelligence and robotic task execution are positively
correlated in multi-view robotic scenarios; and (ii) strong performance on
existing general-purpose single-view spatial understanding benchmarks does not
reliably translate to success in the robotic spatial tasks assessed by our
benchmark. We release MV-RoboBench as an open resource to foster progress in
spatially grounded VLMs and VLAs, providing not only data but also a
standardized evaluation protocol for multi-view embodied reasoning.

</details>


### [61] [Multi-Camera Worker Tracking in Logistics Warehouse Considering Wide-Angle Distortion](https://arxiv.org/abs/2510.19432)
*Yuki Mori,Kazuma Kano,Yusuke Asai,Shin Katayama,Kenta Urano,Takuro Yonezawa,Nobuo Kawaguchi*

Main category: cs.CV

TL;DR: 本研究提出了一种利用19个广角摄像头在物流仓库中跟踪工人位置的方法。通过基于脚部位置进行对齐，有效减少了广角图像失真，使跟踪精度提高了20%以上。


<details>
  <summary>Details</summary>
Motivation: 随着电子商务的普及，全球物流市场不断增长，提高仓库运营效率至关重要。数字孪生技术被认为是实现这一目标的一种有效途径，但这需要精确收集仓库中工人的位置并将其反映到虚拟空间。然而，单个摄像头的视野有限，因此需要多摄像头感知系统。

Method: 研究人员在物流仓库天花板上安装了19个广角摄像头，俯视地面以跟踪工人。首先，基于地面进行摄像头坐标与实际位置的初始对齐。为解决广角摄像头图像边缘（特别是垂直方向）的显著失真问题，研究提出了一种新方法：将每个摄像头检测到的工人位置基于“脚部位置”进行对齐，从而减少图像失真影响，实现跨摄像头的精确位置对齐。此外，还比较了多种利用外观特征的方法。

Result: 实验结果表明，通过提出的基于脚部位置的对齐方法，跟踪精度提高了20%以上。研究还验证了该方法的有效性，并比较了不同外观特征利用方法的性能。

Conclusion: 本研究成功探索了一种使用多广角摄像头在物流仓库中精确跟踪工人的方法。通过创新性地将工人位置基于脚部进行对齐，有效解决了广角图像失真问题，显著提高了多摄像头跟踪的准确性，为数字孪生在仓库管理中的应用奠定了基础。

Abstract: With the spread of e-commerce, the logistics market is growing around the
world. Therefore, improving the efficiency of warehouse operations is
essential. To achieve this, various approaches have been explored, and among
them, the use of digital twins is gaining attention. To make this approach
possible, it is necessary to accurately collect the positions of workers in a
warehouse and reflect them in a virtual space. However, a single camera has
limitations in its field of view, therefore sensing with multiple cameras is
necessary. In this study, we explored a method to track workers using 19
wide-angle cameras installed on the ceiling, looking down at the floor of the
logistics warehouse. To understand the relationship between the camera
coordinates and the actual positions in the warehouse, we performed alignment
based on the floor surface. However, due to the characteristics of wide-angle
cameras, significant distortion occurs at the edges of the image, particularly
in the vertical direction. To address this, the detected worker positions from
each camera were aligned based on foot positions, reducing the effects of image
distortion, and enabling accurate position alignment across cameras. As a
result, we confirmed an improvement of over 20% in tracking accuracy.
Furthermore, we compared multiple methods for utilizing appearance features and
validated the effectiveness of the proposed approach.

</details>


### [62] [A Matter of Time: Revealing the Structure of Time in Vision-Language Models](https://arxiv.org/abs/2510.19559)
*Nidham Tekaya,Manuela Waldner,Matthias Zeppelzauer*

Main category: cs.CV

TL;DR: 本文研究了大型视觉-语言模型（VLMs）的时间感知能力，引入了TIME10k数据集和新方法。研究发现时间信息在VLM嵌入空间中呈低维非线性流形结构，并基于此提出了高效的“时间线”表示方法，在时间推理任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型（VLMs）因其泛化性和开放词汇能力而广受欢迎。然而，其对视觉内容进行时间定位的能力（即时间感知）尚未被充分研究，而这超出了其常规训练范围。

Method: 研究引入了TIME10k基准数据集，包含超过10,000张带有时间真实标签的图像。使用新颖的方法评估了37个VLMs的时间感知能力。分析了VLM嵌入空间，以揭示时间信息的结构。在此基础上，提出了从嵌入空间中推导出显式“时间线”表示的方法。

Result: 研究发现，时间信息在VLM嵌入空间中沿着一个低维、非线性的流形结构化。所提出的“时间线”方法与基于提示的基线相比，在准确性上具有竞争力甚至更优，并且计算效率高。

Conclusion: VLMs具有一定的时间感知能力，其嵌入空间中隐含着时间信息。通过从VLM嵌入空间中推导出显式的“时间线”表示，可以有效且高效地促进时间推理任务。

Abstract: Large-scale vision-language models (VLMs) such as CLIP have gained popularity
for their generalizable and expressive multimodal representations. By
leveraging large-scale training data with diverse textual metadata, VLMs
acquire open-vocabulary capabilities, solving tasks beyond their training
scope. This paper investigates the temporal awareness of VLMs, assessing their
ability to position visual content in time. We introduce TIME10k, a benchmark
dataset of over 10,000 images with temporal ground truth, and evaluate the
time-awareness of 37 VLMs by a novel methodology. Our investigation reveals
that temporal information is structured along a low-dimensional, non-linear
manifold in the VLM embedding space. Based on this insight, we propose methods
to derive an explicit ``timeline'' representation from the embedding space.
These representations model time and its chronological progression and thereby
facilitate temporal reasoning tasks. Our timeline approaches achieve
competitive to superior accuracy compared to a prompt-based baseline while
being computationally efficient. All code and data are available at
https://tekayanidham.github.io/timeline-page/.

</details>


### [63] [Multi-modal Co-learning for Earth Observation: Enhancing single-modality models via modality collaboration](https://arxiv.org/abs/2510.19579)
*Francisco Mena,Dino Ienco,Cassio F. Dantas,Roberto Interdonato,Andreas Dengel*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的多模态协同学习框架，通过结合对比学习和模态判别学习，将模型内部流形分解为模态共享和模态特定信息，从而在推理阶段仅提供单一模态的情况下，显著提升地球观测（EO）任务的预测性能。


<details>
  <summary>Details</summary>
Motivation: 多模态协同学习在增强单模态预测方面具有潜力，而地球观测是多模态数据分析的典型领域。然而，现实世界中遥感平台面临的限制使得在训练和推理阶段访问相同的传感器模态变得日益复杂。现有研究多集中于为特定下游任务或推理模态设计定制化解决方案，缺乏一种能泛化到各种任务且不针对特定推理模态的通用框架。

Method: 本文提出了一种新颖的多模态协同学习框架。该方法结合了对比学习和模态判别学习，旨在引导单模态模型将内部模型流形构建成模态共享信息和模态特定信息。

Result: 该框架在涵盖分类和回归任务以及不同传感器模态的四个地球观测基准上进行了评估。在推理时仅能访问训练时可用模态之一的场景下，结果显示该框架在预测性能上持续优于最新的机器学习、计算机视觉以及地球观测领域的先进方法。

Conclusion: 研究结果验证了所提出的框架在各种地球观测应用的单模态推理场景中的有效性，能够显著提升预测能力。

Abstract: Multi-modal co-learning is emerging as an effective paradigm in machine
learning, enabling models to collaboratively learn from different modalities to
enhance single-modality predictions. Earth Observation (EO) represents a
quintessential domain for multi-modal data analysis, wherein diverse remote
sensors collect data to sense our planet. This unprecedented volume of data
introduces novel challenges. Specifically, the access to the same sensor
modalities at both training and inference stages becomes increasingly complex
based on real-world constraints affecting remote sensing platforms. In this
context, multi-modal co-learning presents a promising strategy to leverage the
vast amount of sensor-derived data available at the training stage to improve
single-modality models for inference-time deployment. Most current research
efforts focus on designing customized solutions for either particular
downstream tasks or specific modalities available at the inference stage. To
address this, we propose a novel multi-modal co-learning framework capable of
generalizing across various tasks without targeting a specific modality for
inference. Our approach combines contrastive and modality discriminative
learning together to guide single-modality models to structure the internal
model manifold into modality-shared and modality-specific information. We
evaluate our framework on four EO benchmarks spanning classification and
regression tasks across different sensor modalities, where only one of the
modalities available during training is accessible at inference time. Our
results demonstrate consistent predictive improvements over state-of-the-art
approaches from the recent machine learning and computer vision literature, as
well as EO-specific methods. The obtained findings validate our framework in
the single-modality inference scenarios across a diverse range of EO
applications.

</details>


### [64] [Reasoning Like Experts: Leveraging Multimodal Large Language Models for Drawing-based Psychoanalysis](https://arxiv.org/abs/2510.19451)
*Xueqi Ma,Yanbei Jiang,Sarah Erfani,James Bailey,Weifeng Liu,Krista A. Ehinger,Jey Han Lau*

Main category: cs.CV

TL;DR: 本文提出了PICK框架，利用多模态大语言模型（MLLMs）通过分层分析和知识注入，对房树人（HTP）测验进行心理分析，有效提升了MLLMs在主观心理领域的能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在客观多模态感知任务中表现出色，但在心理分析等主观、情感细腻领域的应用仍未被充分探索。

Method: PICK框架是一个多步骤流程：1. 将包含多个实例的绘画分解为语义子绘画，构建三层（单对象、多对象、整体）分层表示。2. 在每个层面分析子绘画，提取心理或情感洞察。3. 引入HTP知识库并设计一个通过强化学习训练的特征提取模块，生成单对象层面的心理画像，捕捉整体风格和动态对象特定特征。4. 整合多方面信息以生成与专家级推理一致的评估。

Result: 实验结果表明，所提出的PICK框架显著增强了MLLMs在心理分析方面的能力。通过扩展到情感理解任务，进一步验证了其作为通用框架的有效性。

Conclusion: PICK框架弥合了MLLMs与专业专家领域之间的鸿沟，为通过视觉表达理解人类心理状态提供了一个结构化且可解释的框架。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated exceptional
performance across various objective multimodal perception tasks, yet their
application to subjective, emotionally nuanced domains, such as psychological
analysis, remains largely unexplored. In this paper, we introduce PICK, a
multi-step framework designed for Psychoanalytical Image Comprehension through
hierarchical analysis and Knowledge injection with MLLMs, specifically focusing
on the House-Tree-Person (HTP) Test, a widely used psychological assessment in
clinical practice. First, we decompose drawings containing multiple instances
into semantically meaningful sub-drawings, constructing a hierarchical
representation that captures spatial structure and content across three levels:
single-object level, multi-object level, and whole level. Next, we analyze
these sub-drawings at each level with a targeted focus, extracting
psychological or emotional insights from their visual cues. We also introduce
an HTP knowledge base and design a feature extraction module, trained with
reinforcement learning, to generate a psychological profile for single-object
level analysis. This profile captures both holistic stylistic features and
dynamic object-specific features (such as those of the house, tree, or person),
correlating them with psychological states. Finally, we integrate these
multi-faceted information to produce a well-informed assessment that aligns
with expert-level reasoning. Our approach bridges the gap between MLLMs and
specialized expert domains, offering a structured and interpretable framework
for understanding human mental states through visual expression. Experimental
results demonstrate that the proposed PICK significantly enhances the
capability of MLLMs in psychological analysis. It is further validated as a
general framework through extensions to emotion understanding tasks.

</details>


### [65] [Exploring "Many in Few" and "Few in Many" Properties in Long-Tailed, Highly-Imbalanced IC Defect Classification](https://arxiv.org/abs/2510.19463)
*Hao-Chiang Shao,Chun-Hao Chang,Yu-Hsien Lin,Chia-Wen Lin,Shao-Yun Fang,Yan-Hsiu Liu*

Main category: cs.CV

TL;DR: 本文提出IC-Defect-14数据集和ReCAME-Net模型，以解决真实世界IC缺陷分类中极度不平衡数据、类内多样性大和类间相似度高的问题。ReCAME-Net在IC-Defect-14数据集上表现优于现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 尽管深度分类技术在长尾或高度不平衡数据方面取得了进展，但将其应用于真实世界IC缺陷分类仍面临挑战。主要原因有二：1) IC行业高良率导致数据分布极度偏斜，现有分类器失效；2) 真实样本兼具类特定属性和领域相关特征，增加了分类难度。此外，IC缺陷数据存在独特的“类内簇”特性，即类内多样性大和类间相似度高，这在现有公开数据集中很少同时出现，严重影响了SOTA分类器的性能。

Method: 本文首先引入了IC-Defect-14数据集，这是一个大规模、高度不平衡的IC缺陷图像数据集，来源于真实IC生产线的AOI系统，并具有独特的“类内簇”特性。为解决该数据集带来的挑战，本文提出了ReCAME-Net模型。该模型遵循多专家分类器框架，并集成了区域通道注意力模块、度量学习损失、困难类别挖掘策略和知识蒸馏过程。

Result: 广泛的实验评估表明，ReCAME-Net在IC-Defect-14数据集上优于先前的最先进模型。同时，在一般公开数据集上，ReCAME-Net也保持了可比较的性能和竞争力。

Conclusion: ReCAME-Net能够有效应对真实世界IC缺陷分类中极度不平衡、类内多样性大和类间相似度高等复杂挑战。IC-Defect-14数据集的引入也为该领域的研究提供了新的基准和独特挑战。

Abstract: Despite significant advancements in deep classification techniques and in-lab
automatic optical inspection models for long-tailed or highly imbalanced data,
applying these approaches to real-world IC defect classification tasks remains
challenging. This difficulty stems from two primary factors. First, real-world
conditions, such as the high yield-rate requirements in the IC industry, result
in data distributions that are far more skewed than those found in general
public imbalanced datasets. Consequently, classifiers designed for open
imbalanced datasets often fail to perform effectively in real-world scenarios.
Second, real-world samples exhibit a mix of class-specific attributes and
class-agnostic, domain-related features. This complexity adds significant
difficulty to the classification process, particularly for highly imbalanced
datasets. To address these challenges, this paper introduces the IC-Defect-14
dataset, a large, highly imbalanced IC defect image dataset sourced from AOI
systems deployed in real-world IC production lines. This dataset is
characterized by its unique "intra-class clusters" property, which presents two
major challenges: large intra-class diversity and high inter-class similarity.
These characteristics, rarely found simultaneously in existing public datasets,
significantly degrade the performance of current state-of-the-art classifiers
for highly imbalanced data. To tackle this challenge, we propose ReCAME-Net,
which follows a multi-expert classifier framework and integrates a regional
channel attention module, metric learning losses, a hard category mining
strategy, and a knowledge distillation procedure. Extensive experimental
evaluations demonstrate that ReCAME-Net outperforms previous state-of-the-art
models on the IC-Defect-14 dataset while maintaining comparable performance and
competitiveness on general public datasets.

</details>


### [66] [XBench: A Comprehensive Benchmark for Visual-Language Explanations in Chest Radiography](https://arxiv.org/abs/2510.19599)
*Haozhe Luo,Shelley Zixin Shu,Ziyu Zhou,Sebastian Otalora,Mauricio Reyes*

Main category: cs.CV

TL;DR: 尽管视觉语言模型（VLM）在医学图像理解方面表现出卓越的零样本性能，但它们在胸部X光片上的视觉概念与文本证据对齐（即“接地能力”）仍然不足，尤其对于小型或弥漫性病变。本研究首次系统性地评估了七种VLM变体的跨模态可解释性，并指出在医疗实践中部署前需要更具针对性的可解释性基准。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）在医学图像理解方面展现出显著的零样本性能，然而其“接地能力”（即文本概念与视觉证据的对齐程度）尚未得到充分探索。在医学领域，可靠的接地能力对于可解释性和临床应用至关重要。

Method: 本研究提出了首个用于评估胸部X光片中跨模态可解释性的系统性基准（XBench）。研究评估了七种CLIP风格的VLM变体，通过交叉注意力（cross-attention）和基于相似度的定位图生成视觉解释，并定量评估了这些解释与放射科医生标注的病理区域的对齐程度。

Result: 研究发现：(1) 所有VLM变体对大型且明确的病变表现出合理的定位能力，但对小型或弥漫性病变的性能显著下降；(2) 在胸部X光特定数据集上预训练的模型比在通用领域数据上训练的模型表现出更好的对齐性；(3) 模型的整体识别能力与接地能力之间存在强相关性。

Conclusion: 尽管当前VLM具有强大的识别能力，但其在临床上可靠的接地能力方面仍有不足，尤其对于细微病变。这强调了在医疗实践中部署VLM之前，需要进行有针对性的可解释性基准测试。

Abstract: Vision-language models (VLMs) have recently shown remarkable zero-shot
performance in medical image understanding, yet their grounding ability, the
extent to which textual concepts align with visual evidence, remains
underexplored. In the medical domain, however, reliable grounding is essential
for interpretability and clinical adoption. In this work, we present the first
systematic benchmark for evaluating cross-modal interpretability in chest
X-rays across seven CLIP-style VLM variants. We generate visual explanations
using cross-attention and similarity-based localization maps, and
quantitatively assess their alignment with radiologist-annotated regions across
multiple pathologies. Our analysis reveals that: (1) while all VLM variants
demonstrate reasonable localization for large and well-defined pathologies,
their performance substantially degrades for small or diffuse lesions; (2)
models that are pretrained on chest X-ray-specific datasets exhibit improved
alignment compared to those trained on general-domain data. (3) The overall
recognition ability and grounding ability of the model are strongly correlated.
These findings underscore that current VLMs, despite their strong recognition
ability, still fall short in clinically reliable grounding, highlighting the
need for targeted interpretability benchmarks before deployment in medical
practice. XBench code is available at
https://github.com/Roypic/Benchmarkingattention

</details>


### [67] [PCP-GAN: Property-Constrained Pore-scale image reconstruction via conditional Generative Adversarial Networks](https://arxiv.org/abs/2510.19465)
*Ali Sadeghkhani,Brandon Bennett,Masoud Babaei,Arash Rabbani*

Main category: cs.CV

TL;DR: 本研究提出了一种多条件生成对抗网络（cGAN）框架，用于生成具有精确控制孔隙度及深度参数的代表性孔隙尺度图像，解决了地下表征中图像代表性和数据稀缺性问题。


<details>
  <summary>Details</summary>
Motivation: 地下表征中，获取能匹配整体地层特性的代表性孔隙尺度图像是一个基本挑战，因为天然空间异质性导致提取的子图像与岩心测量值显著偏差，同时物理样本稀缺也加剧了这一难题。

Method: 本研究采用多条件生成对抗网络（cGAN）框架，在一个统一模型中同时以孔隙度值和深度参数为条件进行训练。模型在碳酸盐地层四个深度（1879.50-1943.50米）的薄片样本上进行训练，以捕捉普遍的孔隙网络原理和深度特异性地质特征。

Result: 模型实现了卓越的孔隙度控制（R^2=0.95），平均绝对误差为0.0099-0.0197。形态学验证确认了平均孔隙半径、比表面积和迂曲度等关键孔隙网络特征的保留，统计差异在可接受的地质容差范围内。最重要的是，生成的图像表现出卓越的代表性，双约束误差为1.9-11.3%，远优于随机提取真实子图像的36.4-578%。

Conclusion: 该能力为地下表征提供了变革性工具，对于碳储存、地热能和地下水管理等应用尤其有价值，因为在这些应用中，了解孔隙空间的代表性形态对于实施数字岩石物理学至关重要。

Abstract: Obtaining truly representative pore-scale images that match bulk formation
properties remains a fundamental challenge in subsurface characterization, as
natural spatial heterogeneity causes extracted sub-images to deviate
significantly from core-measured values. This challenge is compounded by data
scarcity, where physical samples are only available at sparse well locations.
This study presents a multi-conditional Generative Adversarial Network (cGAN)
framework that generates representative pore-scale images with precisely
controlled properties, addressing both the representativeness challenge and
data availability constraints. The framework was trained on thin section
samples from four depths (1879.50-1943.50 m) of a carbonate formation,
simultaneously conditioning on porosity values and depth parameters within a
single unified model. This approach captures both universal pore network
principles and depth-specific geological characteristics, from grainstone
fabrics with interparticle-intercrystalline porosity to crystalline textures
with anhydrite inclusions. The model achieved exceptional porosity control
(R^2=0.95) across all formations with mean absolute errors of 0.0099-0.0197.
Morphological validation confirmed preservation of critical pore network
characteristics including average pore radius, specific surface area, and
tortuosity, with statistical differences remaining within acceptable geological
tolerances. Most significantly, generated images demonstrated superior
representativeness with dual-constraint errors of 1.9-11.3% compared to
36.4-578% for randomly extracted real sub-images. This capability provides
transformative tools for subsurface characterization, particularly valuable for
carbon storage, geothermal energy, and groundwater management applications
where knowing the representative morphology of the pore space is critical for
implementing digital rock physics.

</details>


### [68] [Predicting before Reconstruction: A generative prior framework for MRI acceleration](https://arxiv.org/abs/2510.19472)
*Juhyung Park,Rokgi Hong,Roh-Eul Yoo,Jaehyeon Koo,Se Young Chun,Seung Hong Choi,Jongho Lee*

Main category: cs.CV

TL;DR: 该研究利用人工智能的生成能力，提出了一种新的范式来加速磁共振成像（MRI），从传统的图像重建转向主动预测性成像，通过预测目标对比图像作为数据驱动先验来重建高度欠采样的MRI数据。


<details>
  <summary>Details</summary>
Motivation: MRI是现代患者护理的基石，但其漫长的采集时间限制了临床吞吐量，因此需要加速MRI采集过程。

Method: 该框架首先利用生成模型预测目标对比图像（例如，基于其他对比图像、历史扫描、采集参数、患者信息），然后将此预测图像作为数据驱动的先验信息，用于重建高度欠采样的MRI数据。研究通过两个关键应用进行了验证：使用T1w和/或T2w预测重建FLAIR图像，以及使用先前采集的T1w预测重建T1w图像。

Result: 该框架在包含多通道k空间数据的大型内部和公共数据集（总计14,921次扫描；1,051,904张切片）上进行了评估，涵盖了高加速因子（x4、x8和x12）。结果表明，其预测-先验重建方法显著优于其他具有替代或无先验信息的方法。

Conclusion: 该研究通过引入一个从图像重建转向预测性成像的新范式，实现了MRI加速的根本性转变，显著提升了重建性能。

Abstract: Recent advancements in artificial intelligence have created transformative
capabilities in image synthesis and generation, enabling diverse research
fields to innovate at revolutionary speed and spectrum. In this study, we
leverage this generative power to introduce a new paradigm for accelerating
Magnetic Resonance Imaging (MRI), introducing a shift from image reconstruction
to proactive predictive imaging. Despite being a cornerstone of modern patient
care, MRI's lengthy acquisition times limit clinical throughput. Our novel
framework addresses this challenge by first predicting a target contrast image,
which then serves as a data-driven prior for reconstructing highly
under-sampled data. This informative prior is predicted by a generative model
conditioned on diverse data sources, such as other contrast images, previously
scanned images, acquisition parameters, patient information. We demonstrate
this approach with two key applications: (1) reconstructing FLAIR images using
predictions from T1w and/or T2w scans, and (2) reconstructing T1w images using
predictions from previously acquired T1w scans. The framework was evaluated on
internal and multiple public datasets (total 14,921 scans; 1,051,904 slices),
including multi-channel k-space data, for a range of high acceleration factors
(x4, x8 and x12). The results demonstrate that our prediction-prior
reconstruction method significantly outperforms other approaches, including
those with alternative or no prior information. Through this framework we
introduce a fundamental shift from image reconstruction towards a new paradigm
of predictive imaging.

</details>


### [69] [PRGCN: A Graph Memory Network for Cross-Sequence Pattern Reuse in 3D Human Pose Estimation](https://arxiv.org/abs/2510.19475)
*Zhuoyang Xie,Yibo Zhao,Hui Huang,Riwei Wang,Zan Gao*

Main category: cs.CV

TL;DR: PRGCN是一个新颖的单目3D人体姿态估计框架，通过图记忆库实现跨序列模式重用，将姿态估计视为模式检索和适应问题，并结合混合时空特征提取器，在Human3.6M和MPI-INF-3DHP上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 单目3D人体姿态估计是一个固有的病态逆问题，存在深度模糊性。现有基于视频的方法孤立地处理每个序列，未能利用人类运动中普遍存在的跨序列结构规律和重复运动模式。

Method: PRGCN将姿态估计形式化为模式检索和适应问题。核心是一个图记忆库，学习并存储姿态原型（关系图），通过注意力机制动态检索作为结构化先验。这些先验通过记忆驱动的图卷积与硬编码的解剖学约束自适应融合。为了支持检索过程，设计了一个双流混合架构，结合了基于Mamba的状态空间模型（线性复杂度、局部时间建模）和自注意力（全局关系能力），以提取鲁棒的时空特征。

Result: PRGCN在Human3.6M和MPI-INF-3DHP基准测试中取得了新的SOTA，MPJPE分别达到37.1mm和13.4mm，并展现出增强的跨域泛化能力。

Conclusion: 跨序列模式重用机制对于推动该领域的发展至关重要，将范式从每序列优化转向累积知识学习。

Abstract: Monocular 3D human pose estimation remains a fundamentally ill-posed inverse
problem due to the inherent depth ambiguity in 2D-to-3D lifting. While
contemporary video-based methods leverage temporal context to enhance spatial
reasoning, they operate under a critical paradigm limitation: processing each
sequence in isolation, thereby failing to exploit the strong structural
regularities and repetitive motion patterns that pervade human movement across
sequences. This work introduces the Pattern Reuse Graph Convolutional Network
(PRGCN), a novel framework that formalizes pose estimation as a problem of
pattern retrieval and adaptation. At its core, PRGCN features a graph memory
bank that learns and stores a compact set of pose prototypes, encoded as
relational graphs, which are dynamically retrieved via an attention mechanism
to provide structured priors. These priors are adaptively fused with hard-coded
anatomical constraints through a memory-driven graph convolution, ensuring
geometrical plausibility. To underpin this retrieval process with robust
spatiotemporal features, we design a dual-stream hybrid architecture that
synergistically combines the linear-complexity, local temporal modeling of
Mamba-based state-space models with the global relational capacity of
self-attention. Extensive evaluations on Human3.6M and MPI-INF-3DHP benchmarks
demonstrate that PRGCN establishes a new state-of-the-art, achieving an MPJPE
of 37.1mm and 13.4mm, respectively, while exhibiting enhanced cross-domain
generalization capability. Our work posits that the long-overlooked mechanism
of cross-sequence pattern reuse is pivotal to advancing the field, shifting the
paradigm from per-sequence optimization towards cumulative knowledge learning.

</details>


### [70] [Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts](https://arxiv.org/abs/2510.19487)
*Chen Li,Huiying Xu,Changxin Gao,Zeyu Wang,Yun Liu,Xinzhong Zhu*

Main category: cs.CV

TL;DR: 本文提出Cauvis方法，通过引入交叉注意力提示模块和双分支适配器，解决单源域泛化目标检测中模型对虚假相关性的过度依赖问题，显著提升了模型在未见目标域的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 单源域泛化目标检测旨在通过单源域训练提高模型在未见目标域的泛化能力。然而，由于域偏移和有限的域特定知识，现有方法易使模型陷入虚假相关性（如过度依赖颜色而非物体轮廓等不变特征），导致泛化性能受限。

Method: 本文提出Cauvis（Causal Visual Prompts）方法：1. 引入交叉注意力提示模块，通过整合视觉提示与交叉注意力来减轻虚假特征带来的偏差。2. 提出双分支适配器，通过高频特征提取解耦因果-虚假特征，同时实现域适应，以解决视觉提示中域知识覆盖不足和虚假特征纠缠的问题。

Result: Cauvis方法在SDGOD数据集上比现有域泛化方法实现了15.9-31.4%的性能提升，达到了最先进的水平。同时，在复杂干扰环境中也展现出显著的鲁棒性优势。

Conclusion: Cauvis方法通过有效解决单源域泛化目标检测中的虚假相关性问题，显著提高了模型在未见目标域的泛化能力和在复杂环境下的鲁棒性，取得了优异的性能。

Abstract: Single-source Domain Generalized Object Detection (SDGOD), as a cutting-edge
research topic in computer vision, aims to enhance model generalization
capability in unseen target domains through single-source domain training.
Current mainstream approaches attempt to mitigate domain discrepancies via data
augmentation techniques. However, due to domain shift and limited
domain-specific knowledge, models tend to fall into the pitfall of spurious
correlations. This manifests as the model's over-reliance on simplistic
classification features (e.g., color) rather than essential domain-invariant
representations like object contours. To address this critical challenge, we
propose the Cauvis (Causal Visual Prompts) method. First, we introduce a
Cross-Attention Prompts module that mitigates bias from spurious features by
integrating visual prompts with cross-attention. To address the inadequate
domain knowledge coverage and spurious feature entanglement in visual prompts
for single-domain generalization, we propose a dual-branch adapter that
disentangles causal-spurious features while achieving domain adaptation via
high-frequency feature extraction. Cauvis achieves state-of-the-art performance
with 15.9-31.4% gains over existing domain generalization methods on SDGOD
datasets, while exhibiting significant robustness advantages in complex
interference environments.

</details>


### [71] [Mitigating representation bias caused by missing pixels in methane plume detection](https://arxiv.org/abs/2510.19478)
*Julia Wąsala,Joannes D. Maasakkers,Ilse Aben,Rochelle Schneider,Holger Hoos,Mitra Baratchi*

Main category: cs.CV

TL;DR: 卫星图像中的缺失像素（MNAR）会导致自动化特征提取模型的表征偏差，尤其在甲烷羽流检测中，低覆盖率图像的羽流检测率会降低。本文通过多重插补和加权重采样方法，成功消除了标签与覆盖率之间的关联，显著减少了偏差，并提高了低覆盖率图像的羽流检测能力。


<details>
  <summary>Details</summary>
Motivation: 大多数卫星图像由于云层等因素存在系统性缺失像素（即非随机缺失数据，MNAR），如果不加以处理，这些缺失像素会导致自动化特征提取模型出现表征偏差。在甲烷羽流检测中，这种偏差表现为标签与缺失值数量（即图像覆盖率）之间存在虚假关联，导致模型在低覆盖率图像中漏检羽流。

Method: 本文评估了多种插补方法，以消除覆盖率与标签之间的依赖性。此外，本文提出了一种在训练过程中使用的加权重采样方案，通过在每个覆盖率区间内强制实现类别平衡来消除标签与覆盖率之间的关联。

Result: 结果表明，重采样和插补都能显著减少表征偏差，同时不损害平衡准确率、精确率或召回率。最后，在实际操作场景中评估了这些去偏模型的能力，并证明去偏模型在低覆盖率图像中检测羽流的几率更高。

Conclusion: 插补和加权重采样是有效减少卫星图像缺失像素引起的表征偏差的方法。这些技术可以提高模型在低覆盖率图像中检测甲烷羽流的能力，同时保持或不损害其他关键性能指标，从而增强了模型的鲁棒性和实用性。

Abstract: Most satellite images have systematically missing pixels (i.e., missing data
not at random (MNAR)) due to factors such as clouds. If not addressed, these
missing pixels can lead to representation bias in automated feature extraction
models. In this work, we show that spurious association between the label and
the number of missing values in methane plume detection can cause the model to
associate the coverage (i.e., the percentage of valid pixels in an image) with
the label, subsequently under-detecting plumes in low-coverage images. We
evaluate multiple imputation approaches to remove the dependence between the
coverage and a label. Additionally, we propose a weighted resampling scheme
during training that removes the association between the label and the coverage
by enforcing class balance in each coverage bin. Our results show that both
resampling and imputation can significantly reduce the representation bias
without hurting balanced accuracy, precision, or recall. Finally, we evaluate
the capability of the debiased models using these techniques in an operational
scenario and demonstrate that the debiased models have a higher chance of
detecting plumes in low-coverage images.

</details>


### [72] [I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs](https://arxiv.org/abs/2510.19678)
*John Burden,Jonathan Prunty,Ben Slater,Matthieu Tehenan,Greg Davis,Lucy Cheke*

Main category: cs.CV

TL;DR: 本文利用认知心理学的视觉搜索范式，发现多模态大型语言模型（MLLMs）在单一特征搜索中表现出类似人类的“突出效应”，在多特征搜索中存在容量限制，并能整合自然场景先验。研究表明视觉搜索是评估MLLMs感知能力的有效诊断工具。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型（MLLMs）在视觉-语言任务上表现出色，但其视觉处理过程不透明。现有的黑盒评估主要测量任务准确性，未能揭示其潜在机制。

Method: 借鉴认知心理学，本文调整了经典的视觉搜索范式，以测试MLLMs是否表现出“突出效应”（即显著视觉特征的检测独立于干扰物数量）。通过针对颜色、大小和光照特征的受控实验进行测试。同时，使用有针对性的微调和机制可解释性分析来强化研究发现。

Result: 1. 先进的MLLMs在基于颜色或大小的单一特征（分离式）搜索中表现出类似人类的“突出效应”。
2. 在多特征（组合式）搜索中，MLLMs表现出容量限制。
3. MLLMs像人类一样，将自然场景先验（如光照方向）融入到物体表示中。

Conclusion: 视觉搜索可以作为一种基于认知原理的诊断工具，用于评估MLLMs的感知能力。

Abstract: Multimodal large language models (MLLMs) achieve strong performance on
vision-language tasks, yet their visual processing is opaque. Most black-box
evaluations measure task accuracy, but reveal little about underlying
mechanisms. Drawing on cognitive psychology, we adapt classic visual search
paradigms -- originally developed to study human perception -- to test whether
MLLMs exhibit the ``pop-out'' effect, where salient visual features are
detected independently of distractor set size. Using controlled experiments
targeting colour, size and lighting features, we find that advanced MLLMs
exhibit human-like pop-out effects in colour or size-based disjunctive (single
feature) search, as well as capacity limits for conjunctive (multiple feature)
search. We also find evidence to suggest that MLLMs, like humans, incorporate
natural scene priors such as lighting direction into object representations. We
reinforce our findings using targeted fine-tuning and mechanistic
interpretability analyses. Our work shows how visual search can serve as a
cognitively grounded diagnostic tool for evaluating perceptual capabilities in
MLLMs.

</details>


### [73] [PoseCrafter: Extreme Pose Estimation with Hybrid Video Synthesis](https://arxiv.org/abs/2510.19527)
*Qing Mao,Tianxin Huang,Yu Zhu,Jinqiu Sun,Yanning Zhang,Gim Hee Lee*

Main category: cs.CV

TL;DR: 针对稀疏重叠图像对的相机位姿估计是一个难题。本文提出混合视频生成（HVG）以合成更清晰的中间帧，并结合特征匹配选择器（FMS）来挑选适合位姿估计的帧，显著提升了在小重叠或无重叠情况下的位姿估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理稀疏重叠图像对的相机位姿估计时表现不佳，生成的中间帧模糊，且帧选择策略缓慢且与位姿估计不匹配，导致性能受限。

Method: 本文提出混合视频生成（HVG）模型，通过结合视频插值模型和位姿条件下的新视图合成模型来生成更清晰的中间帧。同时，提出基于特征匹配的特征匹配选择器（FMS），从合成结果中选择适合位姿估计的中间帧。

Result: 在Cambridge Landmarks、ScanNet、DL3DV-10K和NAVI数据集上的大量实验表明，与现有SOTA方法相比，所提出的PoseCrafter模型显著提升了位姿估计性能，尤其是在小重叠或无重叠的图像对上表现更优。

Conclusion: 所提出的HVG和FMS方法有效解决了稀疏重叠图像对的相机位姿估计挑战，显著提高了位姿估计的准确性，特别是在传统方法难以处理的极端情况下。

Abstract: Pairwise camera pose estimation from sparsely overlapping image pairs remains
a critical and unsolved challenge in 3D vision. Most existing methods struggle
with image pairs that have small or no overlap. Recent approaches attempt to
address this by synthesizing intermediate frames using video interpolation and
selecting key frames via a self-consistency score. However, the generated
frames are often blurry due to small overlap inputs, and the selection
strategies are slow and not explicitly aligned with pose estimation. To solve
these cases, we propose Hybrid Video Generation (HVG) to synthesize clearer
intermediate frames by coupling a video interpolation model with a
pose-conditioned novel view synthesis model, where we also propose a Feature
Matching Selector (FMS) based on feature correspondence to select intermediate
frames appropriate for pose estimation from the synthesized results. Extensive
experiments on Cambridge Landmarks, ScanNet, DL3DV-10K, and NAVI demonstrate
that, compared to existing SOTA methods, PoseCrafter can obviously enhance the
pose estimation performances, especially on examples with small or no overlap.

</details>


### [74] [[De|Re]constructing VLMs' Reasoning in Counting](https://arxiv.org/abs/2510.19555)
*Simone Alghisi,Gabriel Roccabruna,Massimo Rizzoli,Seyed Mahed Mousavi,Giuseppe Riccardi*

Main category: cs.CV

TL;DR: 本文研究了视觉-语言模型（VLMs）在视觉推理（特别是计数任务）中的局限性。通过受控实验和层级分析，发现错误源于最后一层表示到输出空间的映射不正确。仅微调输出层可将准确率提高高达21%，并在真实世界数据集中取得一致改进。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型（VLMs）在多项下游任务中表现出色，但它们在视觉推理方面仍存在局限性，例如识别关系、理解时间序列和计数对象。本研究旨在超越单纯的基准分数评估，深入探究VLMs失败的根本原因，并提出有针对性的方法来提升其推理能力。

Method: 研究方法包括：1) 在受控实验条件下，研究了七个最先进的VLM在计数任务中的推理技能。2) 分析了VLM对物体数量、类型、空间排列和干扰物共现的敏感性。3) 进行了层级分析，以揭示错误的来源。4) 提出了目标训练方法，即仅微调输出层。

Result: 实验结果表明：1) VLM对物体数量、类型、空间排列以及干扰物的共现高度敏感。2) 层级分析揭示，错误是由于最后一层表示到输出空间的映射不正确所致。3) 目标训练（仅微调输出层）将准确率提高了高达21%。4) 在真实世界数据集中也取得了持续的改进。

Conclusion: VLM在视觉推理（如计数）中的失败主要源于其最后一层表示到输出空间的映射不准确。通过有针对性地微调输出层，可以显著提高VLM的推理准确性，证明了对特定层进行干预的有效性。

Abstract: Vision-Language Models (VLMs) have recently gained attention due to their
competitive performance on multiple downstream tasks, achieved by following
user-input instructions. However, VLMs still exhibit several limitations in
visual reasoning, such as difficulties in identifying relations (e.g., spatial,
temporal, and among objects), understanding temporal sequences (e.g., frames),
and counting objects. In this work, we go beyond score-level benchmark
evaluations of VLMs by investigating the underlying causes of their failures
and proposing a targeted approach to improve their reasoning capabilities. We
study the reasoning skills of seven state-of-the-art VLMs in the counting task
under controlled experimental conditions. Our experiments show that VLMs are
highly sensitive to the number and type of objects, their spatial arrangement,
and the co-occurrence of distractors. A layer-wise analysis reveals that errors
are due to incorrect mapping of the last-layer representation into the output
space. Our targeted training shows that fine-tuning just the output layer
improves accuracy by up to 21%. We corroborate these findings by achieving
consistent improvements on real-world datasets.

</details>


### [75] [HAD: Hierarchical Asymmetric Distillation to Bridge Spatio-Temporal Gaps in Event-Based Object Tracking](https://arxiv.org/abs/2510.19560)
*Yao Deng,Xian Zhong,Wenxuan Liu,Zhaofei Yu,Jingling Yuan,Tiejun Huang*

Main category: cs.CV

TL;DR: 本文提出分层非对称蒸馏（HAD）框架，通过显式建模并缓解RGB相机与事件相机之间的时空非对称性，有效融合两种模态的优势，从而提升复杂条件下的目标跟踪性能。


<details>
  <summary>Details</summary>
Motivation: RGB相机和事件相机在纹理细节/空间分辨率与时间分辨率/高动态范围（HDR）方面具有互补优势，但在高速运动、HDR环境和动态背景干扰等挑战性条件下，由于成像机制的根本差异导致显著的时空非对称性，阻碍了有效的多模态集成，限制了目标跟踪的性能。

Method: 提出分层非对称蒸馏（HAD）框架，这是一种多模态知识蒸馏方法，显式建模并缓解RGB相机和事件相机之间的时空非对称性。HAD采用分层对齐策略，旨在最小化信息损失，同时保持学生网络的计算效率和参数紧凑性。

Result: 广泛的实验表明，HAD持续优于现有最先进的方法。全面的消融研究进一步验证了每个设计组件的有效性和必要性。

Conclusion: HAD框架通过有效解决RGB相机与事件相机之间的时空非对称性，成功地融合了两种模态的互补优势，显著提升了在挑战性条件下的目标跟踪性能。

Abstract: RGB cameras excel at capturing rich texture details with high spatial
resolution, whereas event cameras offer exceptional temporal resolution and a
high dynamic range (HDR). Leveraging their complementary strengths can
substantially enhance object tracking under challenging conditions, such as
high-speed motion, HDR environments, and dynamic background interference.
However, a significant spatio-temporal asymmetry exists between these two
modalities due to their fundamentally different imaging mechanisms, hindering
effective multi-modal integration. To address this issue, we propose
{Hierarchical Asymmetric Distillation} (HAD), a multi-modal knowledge
distillation framework that explicitly models and mitigates spatio-temporal
asymmetries. Specifically, HAD proposes a hierarchical alignment strategy that
minimizes information loss while maintaining the student network's
computational efficiency and parameter compactness. Extensive experiments
demonstrate that HAD consistently outperforms state-of-the-art methods, and
comprehensive ablation studies further validate the effectiveness and necessity
of each designed component. The code will be released soon.

</details>


### [76] [Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection](https://arxiv.org/abs/2510.19574)
*Ariana Yi,Ce Zhou,Liyang Xiao,Qiben Yan*

Main category: cs.CV

TL;DR: 本文提出了α-Cloak，首个针对视频对象检测器的无盒对抗性攻击，通过RGBA视频的alpha通道融合恶意内容，使视频对人眼无害但能完全欺骗检测器。


<details>
  <summary>Details</summary>
Motivation: 随着对象检测模型在自动驾驶等网络物理系统中广泛部署，确保其安全性至关重要。现有研究多集中于图像领域的对抗性攻击，而视频领域，尤其是在无盒设置下的攻击，仍未得到充分探索。

Method: α-Cloak利用RGBA视频的alpha通道将恶意目标视频与良性视频融合。这种融合后的视频对人类观众来说看似无害，但能持续欺骗对象检测器。该攻击无需访问模型架构、参数或输出，不引入可感知伪影。研究系统性地考察了alpha通道在常见视频格式和播放应用中的支持情况，并设计了确保视觉隐蔽性和兼容性的融合算法。

Result: α-Cloak在五种最先进的对象检测器、一个视觉-语言模型和一个多模态大语言模型（Gemini-2.0-Flash）上进行了评估，在所有场景中均实现了100%的攻击成功率。

Conclusion: 研究结果揭示了视频感知系统中一个此前未被探索的漏洞，强调了在对抗性环境中考虑alpha通道防御的迫切需求。

Abstract: As object detection models are increasingly deployed in cyber-physical
systems such as autonomous vehicles (AVs) and surveillance platforms, ensuring
their security against adversarial threats is essential. While prior work has
explored adversarial attacks in the image domain, those attacks in the video
domain remain largely unexamined, especially in the no-box setting. In this
paper, we present {\alpha}-Cloak, the first no-box adversarial attack on object
detectors that operates entirely through the alpha channel of RGBA videos.
{\alpha}-Cloak exploits the alpha channel to fuse a malicious target video with
a benign video, resulting in a fused video that appears innocuous to human
viewers but consistently fools object detectors. Our attack requires no access
to model architecture, parameters, or outputs, and introduces no perceptible
artifacts. We systematically study the support for alpha channels across common
video formats and playback applications, and design a fusion algorithm that
ensures visual stealth and compatibility. We evaluate {\alpha}-Cloak on five
state-of-the-art object detectors, a vision-language model, and a multi-modal
large language model (Gemini-2.0-Flash), demonstrating a 100% attack success
rate across all scenarios. Our findings reveal a previously unexplored
vulnerability in video-based perception systems, highlighting the urgent need
for defenses that account for the alpha channel in adversarial settings.

</details>


### [77] [The Intricate Dance of Prompt Complexity, Quality, Diversity, and Consistency in T2I Models](https://arxiv.org/abs/2510.19557)
*Xiaofeng Zhang,Aaron Courville,Michal Drozdzal,Adriana Romero-Soriano*

Main category: cs.CV

TL;DR: 本研究系统地探讨了文本到图像（T2I）模型中提示词复杂性对合成数据实用性（质量、多样性、一致性）的影响，并提出了新的评估框架和有效的干预方法。


<details>
  <summary>Details</summary>
Motivation: T2I模型生成的合成数据具有巨大潜力，但其实用性（质量、多样性、一致性）评估在以往研究中已有所涉猎。然而，作为与T2I模型交互的主要方式，提示词复杂性对这些关键实用性指标的系统性影响仍未被充分探索。

Method: 本文首先通过合成实验来论证提示词复杂性泛化的难度，并提供理论推导解释。随后，引入了一个新的评估框架，用于比较真实数据和合成数据的实用性。在此框架下，对常用T2I模型生成的合成数据进行了全面分析，研究提示词复杂性如何影响数据实用性。研究跨越CC12M、ImageNet-1k和DCI等多样数据集，并评估了不同的推理时干预方法。

Result: 合成实验表明，泛化到更一般条件比反向泛化更困难，因为前者需要扩散模型未学习到的估计似然。大规模实证实验揭示，增加提示词复杂性会导致条件多样性和提示词一致性降低，但能减少合成数据与真实数据的分布偏移，这与合成实验结果一致。此外，当前的推理时干预措施可以增加生成数据的多样性，但代价是偏离真实数据的支持域。在这些干预措施中，通过故意使用预训练语言模型作为似然估计器进行提示词扩展，在图像多样性和美学方面始终取得最高性能，甚至超越真实数据。

Conclusion: 提示词复杂性对T2I模型生成合成数据的实用性具有显著影响。泛化到更一般条件是一个挑战，且复杂提示词会降低多样性和一致性但减少分布偏移。虽然现有干预措施可能导致数据偏离真实分布，但通过使用预训练语言模型进行提示词扩展，可以显著提升合成数据的多样性和美学表现，甚至超越真实数据，为未来合成数据生成提供了有前景的方向。

Abstract: Text-to-image (T2I) models offer great potential for creating virtually
limitless synthetic data, a valuable resource compared to fixed and finite real
datasets. Previous works evaluate the utility of synthetic data from T2I models
on three key desiderata: quality, diversity, and consistency. While prompt
engineering is the primary means of interacting with T2I models, the systematic
impact of prompt complexity on these critical utility axes remains
underexplored. In this paper, we first conduct synthetic experiments to
motivate the difficulty of generalization w.r.t. prompt complexity and explain
the observed difficulty with theoretical derivations. Then, we introduce a new
evaluation framework that can compare the utility of real data and synthetic
data, and present a comprehensive analysis of how prompt complexity influences
the utility of synthetic data generated by commonly used T2I models. We conduct
our study across diverse datasets, including CC12M, ImageNet-1k, and DCI, and
evaluate different inference-time intervention methods. Our synthetic
experiments show that generalizing to more general conditions is harder than
the other way round, since the former needs an estimated likelihood that is not
learned by diffusion models. Our large-scale empirical experiments reveal that
increasing prompt complexity results in lower conditional diversity and prompt
consistency, while reducing the synthetic-to-real distribution shift, which
aligns with the synthetic experiments. Moreover, current inference-time
interventions can augment the diversity of the generations at the expense of
moving outside the support of real data. Among those interventions, prompt
expansion, by deliberately using a pre-trained language model as a likelihood
estimator, consistently achieves the highest performance in both image
diversity and aesthetics, even higher than that of real data.

</details>


### [78] [Addressing the Depth-of-Field Constraint: A New Paradigm for High Resolution Multi-Focus Image Fusion](https://arxiv.org/abs/2510.19581)
*Luca Piano,Peng Huanwen,Radu Ciprian Bilcu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为VAEEEDOF的新型多焦点图像融合（MFIF）方法，利用蒸馏变分自编码器进行高效重建，并引入了一个新的4K合成数据集MattingMFIF来解决数据稀缺和域间隙问题，实现了最先进的融合效果。


<details>
  <summary>Details</summary>
Motivation: 光学镜头存在景深（DOF）限制，导致只有特定范围内的物体清晰。传统和深度学习MFIF方法面临挑战，包括训练数据有限、合成数据集导致的域间隙以及信息不足区域的处理困难。

Method: 该研究提出了VAEEEDOF方法，它是一种蒸馏变分自编码器，用于高保真、高效的图像重建。其融合模块可同时处理多达七张图像。为解决数据稀缺问题，研究引入了MattingMFIF，这是一个新的4K合成数据集，通过真实照片模拟真实的景深效果。

Result: 该方法取得了最先进的结果，生成了无缝、无伪影的融合图像，并弥合了合成与真实世界场景之间的差距。

Conclusion: VAEEEDOF和MattingMFIF在解决复杂MFIF挑战方面迈出了重要一步，成功克服了景深限制、数据稀缺和域间隙等问题。

Abstract: Multi-focus image fusion (MFIF) addresses the depth-of-field (DOF)
limitations of optical lenses, where only objects within a specific range
appear sharp. Although traditional and deep learning methods have advanced the
field, challenges persist, including limited training data, domain gaps from
synthetic datasets, and difficulties with regions lacking information. We
propose VAEEDOF, a novel MFIF method that uses a distilled variational
autoencoder for high-fidelity, efficient image reconstruction. Our fusion
module processes up to seven images simultaneously, enabling robust fusion
across diverse focus points. To address data scarcity, we introduce
MattingMFIF, a new syntetic 4K dataset, simulating realistic DOF effects from
real photographs. Our method achieves state-of-the-art results, generating
seamless artifact-free fused images and bridging the gap between synthetic and
real-world scenarios, offering a significant step forward in addressing complex
MFIF challenges. The code, and weights are available here:

</details>


### [79] [VGD: Visual Geometry Gaussian Splatting for Feed-Forward Surround-view Driving Reconstruction](https://arxiv.org/abs/2510.19578)
*Junhong Lin,Kangli Wang,Shunzhou Wang,Songlin Fan,Ge Li,Wei Gao*

Main category: cs.CV

TL;DR: VGD是一种新颖的前馈端到端学习框架，通过显式学习几何信息并利用其指导语义质量提升，解决了环视自动驾驶场景重建中新颖视图几何一致性和重建质量的挑战，显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的前馈环视自动驾驶场景重建方法，尽管具有快速和泛化能力，但由于环视视图重叠区域极小，通常难以确保新颖视图的几何一致性和重建质量。核心挑战在于如何在提升新颖视图质量的同时保持泛化能力。

Method: 本文提出了Visual Gaussian Driving (VGD)框架。它通过以下方式实现：1) 设计了VGGT架构的轻量级变体，将预训练VGGT的几何先验高效蒸馏到几何分支，以实现可泛化的几何估计。2) 设计了高斯头（与几何分支共享补丁骨干），融合多尺度几何tokens来预测用于新颖视图渲染的高斯参数。3) 整合几何分支和高斯头分支的多尺度特征，共同监督语义细化模型，通过特征一致性学习优化渲染质量。

Result: 在nuScenes数据集上的实验表明，VGD在各种设置下，无论是客观指标还是主观质量，都显著优于最先进的方法。这验证了VGD的可扩展性和高保真环视重建能力。

Conclusion: VGD通过其独特的设计，成功解决了环视自动驾驶场景重建中新颖视图质量和泛化能力的矛盾，实现了可扩展且高保真的环视重建，并超越了现有技术水平。

Abstract: Feed-forward surround-view autonomous driving scene reconstruction offers
fast, generalizable inference ability, which faces the core challenge of
ensuring generalization while elevating novel view quality. Due to the
surround-view with minimal overlap regions, existing methods typically fail to
ensure geometric consistency and reconstruction quality for novel views. To
tackle this tension, we claim that geometric information must be learned
explicitly, and the resulting features should be leveraged to guide the
elevating of semantic quality in novel views. In this paper, we introduce
\textbf{Visual Gaussian Driving (VGD)}, a novel feed-forward end-to-end
learning framework designed to address this challenge. To achieve generalizable
geometric estimation, we design a lightweight variant of the VGGT architecture
to efficiently distill its geometric priors from the pre-trained VGGT to the
geometry branch. Furthermore, we design a Gaussian Head that fuses multi-scale
geometry tokens to predict Gaussian parameters for novel view rendering, which
shares the same patch backbone as the geometry branch. Finally, we integrate
multi-scale features from both geometry and Gaussian head branches to jointly
supervise a semantic refinement model, optimizing rendering quality through
feature-consistent learning. Experiments on nuScenes demonstrate that our
approach significantly outperforms state-of-the-art methods in both objective
metrics and subjective quality under various settings, which validates VGD's
scalability and high-fidelity surround-view reconstruction.

</details>


### [80] [Uncertainty evaluation of segmentation models for Earth observation](https://arxiv.org/abs/2510.19586)
*Melanie Rey,Andriy Mnih,Maxim Neumann,Matt Overlan,Drew Purves*

Main category: cs.CV

TL;DR: 本文研究并评估了卫星图像语义分割中不确定性估计的方法，重点关注遥感应用的实用性。


<details>
  <summary>Details</summary>
Motivation: 语义分割的不确定性估计比图像分类更具挑战性，需要可扩展的逐像素估计方法。现有研究多集中于场景理解或医学影像，而遥感和地球观测应用缺乏专门的基准测试，且关注不确定性度量的实际效用（识别预测错误和噪声）。

Method: 本文对现有方法（如随机分割网络、集成方法）结合多种神经网络架构和不确定性指标进行了基准测试。实验在两个遥感数据集（PASTIS和ForTy）上进行，这些数据集在尺度、地理覆盖范围和标签置信度上存在差异。

Result: 通过评估不确定性度量识别预测错误和受噪声影响的输入图像区域的能力，验证了其实用性。研究结果提出了若干实用建议。

Conclusion: 基于实验结果，本文为遥感语义分割中的不确定性估计提供了多项实用建议。

Abstract: This paper investigates methods for estimating uncertainty in semantic
segmentation predictions derived from satellite imagery. Estimating uncertainty
for segmentation presents unique challenges compared to standard image
classification, requiring scalable methods producing per-pixel estimates. While
most research on this topic has focused on scene understanding or medical
imaging, this work benchmarks existing methods specifically for remote sensing
and Earth observation applications. Our evaluation focuses on the practical
utility of uncertainty measures, testing their ability to identify prediction
errors and noise-corrupted input image regions. Experiments are conducted on
two remote sensing datasets, PASTIS and ForTy, selected for their differences
in scale, geographic coverage, and label confidence. We perform an extensive
evaluation featuring several models, such as Stochastic Segmentation Networks
and ensembles, in combination with a number of neural architectures and
uncertainty metrics. We make a number of practical recommendations based on our
findings.

</details>


### [81] [Digitizing Paper ECGs at Scale: An Open-Source Algorithm for Clinical Research](https://arxiv.org/abs/2510.19590)
*Elias Stenhede,Agnar Martin Bjørnstad,Arian Ranjbar*

Main category: cs.CV

TL;DR: 本文介绍了一个全自动、模块化的框架，能将扫描或拍摄的纸质心电图转换为数字信号，使其可用于现代自动化诊断。


<details>
  <summary>Details</summary>
Motivation: 数百万份临床心电图仅以纸质扫描件形式存在，无法用于现代自动化诊断，这促使研究人员开发一种解决方案来数字化这些数据。

Method: 研究人员开发了一个全自动、模块化的框架，用于将扫描或拍摄的心电图转换为数字信号。该框架在包含常见伪影的37,191张心电图图像（包括来自阿克斯胡斯大学医院的1,596张和埃默里纸质数字化心电图数据集的35,595张）上进行了验证和评估。

Result: 该算法在带有常见伪影的扫描纸质心电图上获得了19.65 dB的平均信噪比。在埃默里纸质数字化心电图数据集上，该模型在所有子类别中均超越了现有技术水平。所有软件均已开源发布。

Conclusion: 该软件有望解锁回顾性心电图档案，并普及人工智能驱动的诊断，从而促进可重现性和进一步发展。

Abstract: Millions of clinical ECGs exist only as paper scans, making them unusable for
modern automated diagnostics. We introduce a fully automated, modular framework
that converts scanned or photographed ECGs into digital signals, suitable for
both clinical and research applications. The framework is validated on 37,191
ECG images with 1,596 collected at Akershus University Hospital, where the
algorithm obtains a mean signal-to-noise ratio of 19.65 dB on scanned papers
with common artifacts. It is further evaluated on the Emory Paper Digitization
ECG Dataset, comprising 35,595 images, including images with perspective
distortion, wrinkles, and stains. The model improves on the state-of-the-art in
all subcategories. The full software is released as open-source, promoting
reproducibility and further development. We hope the software will contribute
to unlocking retrospective ECG archives and democratize access to AI-driven
diagnostics.

</details>


### [82] [Decomposed Attention Fusion in MLLMs for Training-Free Video Reasoning Segmentation](https://arxiv.org/abs/2510.19592)
*Su Ho Han,Jeongseok Hyun,Pilhyeon Lee,Minho Shim,Dongyoon Wee,Seon Joo Kim*

Main category: cs.CV

TL;DR: 本文提出DecAF，一种无需训练的方法，通过分解注意力融合和注意力引导的SAM2提示，将多模态大语言模型（MLLMs）的注意力图转化为视频推理分割掩码，实现了与有监督方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）通过关注与文本查询相关的视觉token展现出强大的视频理解能力。然而，直接将原始注意力图用于视频定位（分割）存在噪声且与目标区域对齐不佳的问题，且现有方法通常需要与SAM联合训练。研究动机是开发一种无需训练的方法，直接利用MLLM的注意力进行精确的视频推理分割。

Method: 该方法将视频推理分割任务转换为视频问答任务，并通过rollout机制提取MLLM的注意力图。然后，提出了分解注意力融合（DecAF）机制来精炼这些注意力图，包括：1) 对比目标-背景融合，以及2) 互补视频-帧融合，以抑制不相关激活并增强目标聚焦线索。此外，引入了注意力引导的SAM2提示来获取细粒度分割掩码。整个过程无需任何重新训练，与现有联合训练MLLM和SAM的方法不同。

Result: DecAF在无需训练的方法中表现优异，并且在参考和推理视频对象分割（VOS）基准测试上，其性能可与基于训练的方法相媲美。

Conclusion: DecAF提供了一种有效且无需训练的视频推理分割方法。它通过精炼MLLM的注意力图并结合注意力引导的SAM2提示，能够直接将注意力图转化为高质量的分割掩码，并在不进行任何重新训练的情况下，取得了与有监督方法相当的先进性能。

Abstract: Multimodal large language models (MLLMs) demonstrate strong video
understanding by attending to visual tokens relevant to textual queries. To
directly adapt this for localization in a training-free manner, we cast video
reasoning segmentation as a video QA task and extract attention maps via
rollout mechanism. However, raw attention maps are noisy and poorly aligned
with object regions. We propose Decomposed Attention Fusion (DecAF), which
refines these maps through two mechanisms: (1) contrastive object-background
fusion and (2) complementary video-frame fusion. This method suppresses
irrelevant activations and enhances object-focused cues, enabling direct
conversion of attention maps into coarse segmentation masks. In addition, we
introduce attention-guided SAM2 prompting for obtaining fine-grained masks.
Unlike existing methods that jointly train MLLMs with SAM, our method operates
entirely without retraining. DecAF outperforms training-free methods and
achieves performance comparable to training-based methods on both referring and
reasoning VOS benchmarks. The code will be available at
https://github.com/HYUNJS/DecAF.

</details>


### [83] [Beyond sparse denoising in frames: minimax estimation with a scattering transform](https://arxiv.org/abs/2510.19612)
*Nathanaël Cuvelle--Magar,Stéphane Mallat*

Main category: cs.CV

TL;DR: 本文提出了一种基于散射系数的去噪估计器，通过联合最小化和最大化不同子集的L1范数，在卡通图像去噪方面达到了所有Lipschitz指数α≤2的最小最大渐近界限。


<details>
  <summary>Details</summary>
Motivation: 传统的基于帧的稀疏估计器（如小波、曲波、Xlet）在处理具有复杂正则性（特别是当Lipschitz指数α≤2未知时）的卡通图像时表现不佳。尽管深度卷积神经网络取得了更好的数值结果，但需要一种新的调和分析方法来改进信号去噪并理解其几何正则性。

Method: 研究人员引入了一种去噪估计器，该估计器通过联合最小化和最大化散射系数不同子集的L1范数来实现。他们还证明了这些L1范数能够捕捉不同类型的图像几何正则性。

Result: 数值实验表明，该去噪估计器在卡通图像去噪方面达到了所有Lipschitz指数α≤2的最小最大渐近界限。作者将这一数值结果表述为一个数学猜想。

Conclusion: 该研究提供了一种不同的调和分析方法来抑制信号噪声并指定函数的几何正则性。它还在调和分析与基于深度卷积网络的去噪估计器之间建立了一座数学桥梁。

Abstract: A considerable amount of research in harmonic analysis has been devoted to
non-linear estimators of signals contaminated by additive Gaussian noise. They
are implemented by thresholding coefficients in a frame, which provide a sparse
signal representation, or by minimising their $\ell^1$ norm. However, sparse
estimators in frames are not sufficiently rich to adapt to complex signal
regularities. For cartoon images whose edges are piecewise $\bf C^\alpha$
curves, wavelet, curvelet and Xlet frames are suboptimal if the Lipschitz
exponent $\alpha \leq 2$ is an unknown parameter. Deep convolutional neural
networks have recently obtained much better numerical results, which reach the
minimax asymptotic bounds for all $\alpha$. Wavelet scattering coefficients
have been introduced as simplified convolutional neural network models. They
are computed by transforming the modulus of wavelet coefficients with a second
wavelet transform. We introduce a denoising estimator by jointly minimising and
maximising the $\ell^1$ norms of different subsets of scattering coefficients.
We prove that these $\ell^1$ norms capture different types of geometric image
regularity. Numerical experiments show that this denoising estimator reaches
the minimax asymptotic bound for cartoon images for all Lipschitz exponents
$\alpha \leq 2$. We state this numerical result as a mathematical conjecture.
It provides a different harmonic analysis approach to suppress noise from
signals, and to specify the geometric regularity of functions. It also opens a
mathematical bridge between harmonic analysis and denoising estimators with
deep convolutional network.

</details>


### [84] [CBDiff:Conditional Bernoulli Diffusion Models for Image Forgery Localization](https://arxiv.org/abs/2510.19597)
*Zhou Lei,Pan Gang,Wang Jiahao,Sun Di*

Main category: cs.CV

TL;DR: 本文提出CBDiff，一个条件伯努利扩散模型，用于图像伪造定位。它能生成多个多样且可信的定位图，并创新性地引入伯努利噪声和时间步交叉注意力，显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像伪造定位方法通常生成单一确定性定位图，缺乏高精度和可靠性，无法满足法医分析和安全监控等高风险应用的需求。研究旨在提高预测可信度，降低错误风险，并处理篡改区域固有的不确定性和变异性。

Method: 本文引入了先进的条件伯努利扩散模型（CBDiff）。该模型在给定伪造图像的情况下，生成多个多样且可信的定位图。CBDiff创新性地将伯努利噪声引入扩散过程，以更真实地反映伪造掩码固有的二元和稀疏特性。此外，CBDiff还引入了时间步交叉注意力（TSCAttention），专门设计用于利用语义特征指导和时间步来改进篡改检测。

Result: 在八个公开基准数据集上的大量实验表明，CBDiff显著优于现有最先进的方法。

Conclusion: CBDiff模型在图像伪造定位任务中表现出强大的潜力，能够生成更丰富、更全面的伪造分布表示，并有望在实际部署中发挥重要作用。

Abstract: Image Forgery Localization (IFL) is a crucial task in image forensics, aimed
at accurately identifying manipulated or tampered regions within an image at
the pixel level. Existing methods typically generate a single deterministic
localization map, which often lacks the precision and reliability required for
high-stakes applications such as forensic analysis and security surveillance.
To enhance the credibility of predictions and mitigate the risk of errors, we
introduce an advanced Conditional Bernoulli Diffusion Model (CBDiff). Given a
forged image, CBDiff generates multiple diverse and plausible localization
maps, thereby offering a richer and more comprehensive representation of the
forgery distribution. This approach addresses the uncertainty and variability
inherent in tampered regions. Furthermore, CBDiff innovatively incorporates
Bernoulli noise into the diffusion process to more faithfully reflect the
inherent binary and sparse properties of forgery masks. Additionally, CBDiff
introduces a Time-Step Cross-Attention (TSCAttention), which is specifically
designed to leverage semantic feature guidance with temporal steps to improve
manipulation detection. Extensive experiments on eight publicly benchmark
datasets demonstrate that CBDiff significantly outperforms existing
state-of-the-art methods, highlighting its strong potential for real-world
deployment.

</details>


### [85] [Pragmatic Heterogeneous Collaborative Perception via Generative Communication Mechanism](https://arxiv.org/abs/2510.19618)
*Junfei Zhou,Penglin Dai,Quanmin Wei,Bingyi Liu,Xiao Wu,Jianping Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为GenComm的生成式通信机制，通过特征生成和轻量级空间对齐，解决了异构多智能体协作中存在的域间隙和引入新智能体的高成本问题，实现了卓越的感知性能和效率。


<details>
  <summary>Details</summary>
Motivation: 在异构多智能体协作中，不同传感器和模型导致域间隙，现有方法存在两个主要限制：1) 入侵性重训练破坏了智能体间的语义一致性；2) 引入新智能体计算成本高昂，限制了可扩展性。这些问题促使研究者寻求更高效、非侵入性的解决方案。

Method: GenComm机制通过以下方式实现：设计了一个可变形消息提取器（Deformable Message Extractor）来提取协作者的空间消息；利用条件扩散模型构建空间感知特征生成器（Spatial-Aware Feature Generator），生成与自我智能体语义空间对齐且保留协作者空间信息的特征；通过通道增强器（Channel Enhancer）进一步细化生成的特征；采用轻量级空间信息数值对齐，以最小成本高效集成新智能体，且不改变原有网络。

Result: GenComm在OPV2V-H、DAIR-V2X和V2X-Real数据集上的实验表明，其性能优于现有最先进的方法。在引入新智能体时，计算成本和参数数量均降低了81%。

Conclusion: GenComm通过特征生成和高效的新智能体集成，成功解决了异构多智能体系统中无缝感知和可扩展性的挑战，在性能和效率方面均超越了现有方法，为异构多智能体协作提供了有效且实用的解决方案。

Abstract: Multi-agent collaboration enhances the perception capabilities of individual
agents through information sharing. However, in real-world applications,
differences in sensors and models across heterogeneous agents inevitably lead
to domain gaps during collaboration. Existing approaches based on adaptation
and reconstruction fail to support pragmatic heterogeneous collaboration due to
two key limitations: (1) Intrusive retraining of the encoder or core modules
disrupts the established semantic consistency among agents; and (2)
accommodating new agents incurs high computational costs, limiting scalability.
To address these challenges, we present a novel Generative Communication
mechanism (GenComm) that facilitates seamless perception across heterogeneous
multi-agent systems through feature generation, without altering the original
network, and employs lightweight numerical alignment of spatial information to
efficiently integrate new agents at minimal cost. Specifically, a tailored
Deformable Message Extractor is designed to extract spatial message for each
collaborator, which is then transmitted in place of intermediate features. The
Spatial-Aware Feature Generator, utilizing a conditional diffusion model,
generates features aligned with the ego agent's semantic space while preserving
the spatial information of the collaborators. These generated features are
further refined by a Channel Enhancer before fusion. Experiments conducted on
the OPV2V-H, DAIR-V2X and V2X-Real datasets demonstrate that GenComm
outperforms existing state-of-the-art methods, achieving an 81\% reduction in
both computational cost and parameter count when incorporating new agents. Our
code is available at https://github.com/jeffreychou777/GenComm.

</details>


### [86] [Augmenting Moment Retrieval: Zero-Dependency Two-Stage Learning](https://arxiv.org/abs/2510.19622)
*Zhengxuan Wei,Jiajin Tang,Sibei Yang*

Main category: cs.CV

TL;DR: 本文提出了一种零外部依赖的增强时刻检索框架AMR，旨在解决现有方法在数据稀缺、边界模糊和细粒度语义区分不足方面的瓶颈，通过数据增强和两阶段训练显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有时刻检索方法面临三个主要瓶颈：1) 数据稀缺导致模型形成浅层关键词-特征关联；2) 相邻事件过渡区域的边界模糊性；3) 细粒度语义（如区分“踢”与“投掷”球）的区分能力不足。

Method: AMR框架基于两个核心洞察：1) 无需额外数据即可解决现有标注中的边界模糊和语义混淆；2) 通过训练增强边界和语义区分能力并泛化到真实场景。它采用两阶段训练框架：冷启动阶段通过课程学习在增强数据上建立基础边界/语义感知；蒸馏阶段引入双查询集（原始查询和活跃查询），并使用跨阶段蒸馏损失来确保一致性，防止知识遗忘并实现真实世界泛化。

Result: 在多个基准测试上的实验表明，AMR框架在性能上超越了之前最先进的方法。

Conclusion: AMR通过解决数据不足导致的局部最优、增强边界和语义区分能力，并采用创新的两阶段训练框架，有效克服了现有时刻检索方法的关键瓶颈，显著提升了检索性能和泛化能力。

Abstract: Existing Moment Retrieval methods face three critical bottlenecks: (1) data
scarcity forces models into shallow keyword-feature associations; (2) boundary
ambiguity in transition regions between adjacent events; (3) insufficient
discrimination of fine-grained semantics (e.g., distinguishing ``kicking" vs.
``throwing" a ball). In this paper, we propose a zero-external-dependency
Augmented Moment Retrieval framework, AMR, designed to overcome local optima
caused by insufficient data annotations and the lack of robust boundary and
semantic discrimination capabilities. AMR is built upon two key insights: (1)
it resolves ambiguous boundary information and semantic confusion in existing
annotations without additional data (avoiding costly manual labeling), and (2)
it preserves boundary and semantic discriminative capabilities enhanced by
training while generalizing to real-world scenarios, significantly improving
performance. Furthermore, we propose a two-stage training framework with
cold-start and distillation adaptation. The cold-start stage employs curriculum
learning on augmented data to build foundational boundary/semantic awareness.
The distillation stage introduces dual query sets: Original Queries maintain
DETR-based localization using frozen Base Queries from the cold-start model,
while Active Queries dynamically adapt to real-data distributions. A
cross-stage distillation loss enforces consistency between Original and Base
Queries, preventing knowledge forgetting while enabling real-world
generalization. Experiments on multiple benchmarks show that AMR achieves
improved performance over prior state-of-the-art approaches.

</details>


### [87] [MedReason-R1: Learning to Reason for CT Diagnosis with Reinforcement Learning and Local Zoom](https://arxiv.org/abs/2510.19626)
*Yifan Li,Fenghe Tang,Yingtai Li,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: 本文提出MedReason-R1，一个用于CT疾病诊断的医学视觉-语言模型（VLM），通过构建大规模专业数据集CT-RATE-VQA和引入从粗到细的显式推理过程，显著提升了医学VLM的诊断性能。


<details>
  <summary>Details</summary>
Motivation: 通用视觉-语言模型（VLM）在医学领域表现不佳，主要原因在于缺乏大规模、高质量的专业医学影像数据集，以及忽略了从粗到细的诊断推理过程。

Method: 1. 构建了包含8.4万个问答对的CT-RATE-VQA数据集。2. 提出了MedReason-R1医学VLM，其具有显式的疾病诊断推理过程。3. 将病灶区域（ROI）的放大图像嵌入到原始图像中，以强调全局定位和疾病特异性细节的重要性。4. 引入GRPO强化学习框架，实现无需昂贵手动标注的有效推理。

Result: MedReason-R1在CT疾病诊断方面取得了最先进的性能，同时保持了泛化能力，优于近期通用和医学领域的VLM。

Conclusion: MedReason-R1通过解决数据稀缺问题和引入显式、从粗到细的推理机制，显著提高了医学VLM在CT疾病诊断中的表现，并具有良好的泛化性。

Abstract: General-purpose large Vision-Language Models (VLMs) demonstrate strong
capabilities in generating detailed descriptions for natural images. However,
their performance in the medical domain remains suboptimal, even for relatively
straightforward tasks, primarily due to the lack of large-scale, high-quality,
specialized medical imaging datasets and the neglect of the diagnostic process
that progresses from coarse to fine-grained. To address the first issue, we
construct the CT-RATE-VQA dataset, which has 84K QA pairs. For the second
issue, we propose MedReason-R1, a medical VLM with explicit reasoning process
for disease diagnosis. MedReason-R1 incorporates a novel strategy that embeds
zoom-in disease region-of-interest areas into the image, highlighting the
crucial role of both global localization and disease-specific details in
enhancing the model's diagnostic performance. Furthermore, we introduce the
GRPO reinforcement learning framework to MedReason-R1, which enables effective
reasoning without relying on costly manual annotations. Compared to recent
general-purpose and medical VLMs, MedReason-R1 achieves state-of-the-art
performance in CT disease diagnosis while retaining generalization. The code,
checkpoints, and dataset are available at:
https://github.com/Leevan001/MedReason-R1

</details>


### [88] [Re-Activating Frozen Primitives for 3D Gaussian Splatting](https://arxiv.org/abs/2510.19653)
*Yuxin Cheng,Binxiao Huang,Wenyong Zhou,Taiqiang Wu,Zhengwu Liu,Graziano Chesi,Ngai Wong*

Main category: cs.CV

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: 3D Gaussian Splatting (3D-GS) achieves real-time photorealistic novel view
synthesis, yet struggles with complex scenes due to over-reconstruction
artifacts, manifesting as local blurring and needle-shape distortions. While
recent approaches attribute these issues to insufficient splitting of
large-scale Gaussians, we identify two fundamental limitations: gradient
magnitude dilution during densification and the primitive frozen phenomenon,
where essential Gaussian densification is inhibited in complex regions while
suboptimally scaled Gaussians become trapped in local optima. To address these
challenges, we introduce ReAct-GS, a method founded on the principle of
re-activation. Our approach features: (1) an importance-aware densification
criterion incorporating $\alpha$-blending weights from multiple viewpoints to
re-activate stalled primitive growth in complex regions, and (2) a
re-activation mechanism that revitalizes frozen primitives through adaptive
parameter perturbations. Comprehensive experiments across diverse real-world
datasets demonstrate that ReAct-GS effectively eliminates over-reconstruction
artifacts and achieves state-of-the-art performance on standard novel view
synthesis metrics while preserving intricate geometric details. Additionally,
our re-activation mechanism yields consistent improvements when integrated with
other 3D-GS variants such as Pixel-GS, demonstrating its broad applicability.

</details>


### [89] [Curvilinear Structure-preserving Unpaired Cross-domain Medical Image Translation](https://arxiv.org/abs/2510.19679)
*Zihao Chen,Yi Zhou,Xudong Jiang,Li Chen,Leopold Schmetterer,Bingyao Tan,Jun Cheng*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CST的通用框架，用于在医学图像非配对图像到图像翻译中显式地保留精细曲线结构，解决了现有方法扭曲这些结构的问题，并通过集成结构一致性实现了更好的翻译保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的非配对图像到图像翻译方法在医学成像中常扭曲精细的曲线结构（如微血管），这会损害诊断可靠性和定量分析，尤其在眼科和血管成像中，细微形态变化具有重要临床意义。

Method: 提出曲线结构保留翻译（CST）框架，通过将结构一致性整合到训练中，显式保留精细曲线结构。CST通过一个曲线提取模块增强基线模型，提供拓扑监督，可无缝集成到现有方法中（例如，已集成到CycleGAN和UNSB中）。

Result: 在光学相干断层扫描血管造影、彩色眼底和X射线冠状动脉血管造影三种成像模态上的综合评估表明，CST显著提高了翻译保真度，并达到了最先进的性能。

Conclusion: CST通过增强学习映射中的几何完整性，为医学成像中的曲线结构感知跨域翻译建立了一条原则性途径。

Abstract: Unpaired image-to-image translation has emerged as a crucial technique in
medical imaging, enabling cross-modality synthesis, domain adaptation, and data
augmentation without costly paired datasets. Yet, existing approaches often
distort fine curvilinear structures, such as microvasculature, undermining both
diagnostic reliability and quantitative analysis. This limitation is
consequential in ophthalmic and vascular imaging, where subtle morphological
changes carry significant clinical meaning. We propose Curvilinear
Structure-preserving Translation (CST), a general framework that explicitly
preserves fine curvilinear structures during unpaired translation by
integrating structure consistency into the training. Specifically, CST augments
baseline models with a curvilinear extraction module for topological
supervision. It can be seamlessly incorporated into existing methods. We
integrate it into CycleGAN and UNSB as two representative backbones.
Comprehensive evaluation across three imaging modalities: optical coherence
tomography angiography, color fundus and X-ray coronary angiography
demonstrates that CST improves translation fidelity and achieves
state-of-the-art performance. By reinforcing geometric integrity in learned
mappings, CST establishes a principled pathway toward curvilinear
structure-aware cross-domain translation in medical imaging.

</details>


### [90] [Explainable Face Presentation Attack Detection via Ensemble-CAM](https://arxiv.org/abs/2510.19695)
*Rashik Shadman,M G Sarwar Murshed,Faraz Hussain*

Main category: cs.CV

TL;DR: 本文提出了一种名为Ensemble-CAM的新技术，用于为基于深度学习的面部演示攻击检测（PAD）系统提供视觉解释，以提高其透明度和可信度。


<details>
  <summary>Details</summary>
Motivation: 深度学习（DL）模型在演示攻击检测（PAD）中虽然有效，但其决策过程通常不透明（黑箱）。为了更好地理解DL-based PAD系统的行为，特别是识别系统将生物识别图像判断为真实或伪造的关键区域，需要可解释性技术，尤其是视觉解释。

Method: 本文提出了一种新颖的技术——Ensemble-CAM，旨在为基于深度学习的面部PAD系统所做出的决策提供视觉解释。

Result: 通过提供视觉解释，该研究旨在增进对DL-based面部PAD系统行为的理解，并提升这些系统的透明度和可信度。

Conclusion: Ensemble-CAM提供的视觉解释将增强基于深度学习的面部PAD系统的透明度和可信度，从而改进这些系统。

Abstract: Presentation attacks represent a critical security threat where adversaries
use fake biometric data, such as face, fingerprint, or iris images, to gain
unauthorized access to protected systems. Various presentation attack detection
(PAD) systems have been designed leveraging deep learning (DL) models to
mitigate this type of threat. Despite their effectiveness, most of the DL
models function as black boxes - their decisions are opaque to their users. The
purpose of explainability techniques is to provide detailed information about
the reason behind the behavior or decision of DL models. In particular, visual
explanation is necessary to better understand the decisions or predictions of
DL-based PAD systems and determine the key regions due to which a biometric
image is considered real or fake by the system. In this work, a novel
technique, Ensemble-CAM, is proposed for providing visual explanations for the
decisions made by deep learning-based face PAD systems. Our goal is to improve
DL-based face PAD systems by providing a better understanding of their
behavior. Our provided visual explanations will enhance the transparency and
trustworthiness of DL-based face PAD systems.

</details>


### [91] [LyTimeT: Towards Robust and Interpretable State-Variable Discovery](https://arxiv.org/abs/2510.19716)
*Kuai Yu,Crystal Su,Xiang Liu,Judah Goldfeder,Mingyuan Shao,Hod Lipson*

Main category: cs.CV

TL;DR: LyTimeT是一个两阶段框架，用于从高维视频中提取可解释的、鲁棒且稳定的动力学变量。它通过时空注意力机制应对视觉干扰，并利用Lyapunov稳定性正则化来精炼潜在空间，从而实现准确的长期预测和物理可解释性。


<details>
  <summary>Details</summary>
Motivation: 从高维视频中提取系统的真实动力学变量极具挑战性，因为背景运动、遮挡和纹理变化等视觉干扰因素会造成干扰。

Method: LyTimeT框架分为两阶段：第一阶段，使用基于TimeSformer的时空自编码器，通过全局注意力机制聚焦于动态相关区域，抑制干扰，实现对干扰鲁棒的潜在状态学习和准确的长期视频预测。第二阶段，探测学习到的潜在空间，通过线性相关分析选择最具物理意义的维度，并使用基于Lyapunov的稳定性正则化器精炼转换动力学，以强制收缩并减少误差累积。

Result: LyTimeT在五个人工基准和四个真实世界动力学系统（包括混沌现象）上的实验表明，它实现了最接近真实值的互信息和内在维度估计，在背景扰动下保持不变，并且在CNN（TIDE）和纯Transformer基线中提供了最低的分析均方误差。

Conclusion: 结合时空注意力和稳定性约束可以产生不仅准确而且具有物理可解释性的预测模型。

Abstract: Extracting the true dynamical variables of a system from high-dimensional
video is challenging due to distracting visual factors such as background
motion, occlusions, and texture changes. We propose LyTimeT, a two-phase
framework for interpretable variable extraction that learns robust and stable
latent representations of dynamical systems. In Phase 1, LyTimeT employs a
spatio-temporal TimeSformer-based autoencoder that uses global attention to
focus on dynamically relevant regions while suppressing nuisance variation,
enabling distraction-robust latent state learning and accurate long-horizon
video prediction. In Phase 2, we probe the learned latent space, select the
most physically meaningful dimensions using linear correlation analysis, and
refine the transition dynamics with a Lyapunov-based stability regularizer to
enforce contraction and reduce error accumulation during roll-outs. Experiments
on five synthetic benchmarks and four real-world dynamical systems, including
chaotic phenomena, show that LyTimeT achieves mutual information and intrinsic
dimension estimates closest to ground truth, remains invariant under background
perturbations, and delivers the lowest analytical mean squared error among
CNN-based (TIDE) and transformer-only baselines. Our results demonstrate that
combining spatio-temporal attention with stability constraints yields
predictive models that are not only accurate but also physically interpretable.

</details>


### [92] [Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks](https://arxiv.org/abs/2510.19760)
*Shaohang Jia,Zhiyong Huang,Zhi Yu,Mingyang Hou,Shuai Miao,Han Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为自适应分布感知量化（ADQ）的混合精度量化框架，通过自适应权重码本和激活非均匀到均匀映射，解决了QAT中激活分布不均匀和权重码本静态不匹配的问题，实现了在资源受限设备上的高效部署。


<details>
  <summary>Details</summary>
Motivation: 现有量化感知训练（QAT）方法面临两大挑战：激活分布高度非均匀性，以及权重量化中使用的静态、不匹配的码本。

Method: 本文提出了ADQ框架，采用差异化策略：1) 针对权重，提出自适应权重量化方案，包括基于分位数的码本初始化、基于EMA的在线码本自适应机制和敏感度指导的混合精度分配策略；2) 针对激活，整合了硬件友好的非均匀到均匀映射方案。

Result: 在ImageNet数据集上，ADQ使ResNet-18在平均2.81比特位宽下达到71.512%的Top-1准确率，优于现有最先进方法。此外，在CIFAR-10上的消融研究系统性地验证了各创新组件的贡献。

Conclusion: ADQ通过其自适应和分布感知的设计，有效解决了QAT中的核心挑战，在资源受限设备上实现了卓越的性能，并为深度神经网络的部署提供了高效的解决方案。

Abstract: Quantization-Aware Training (QAT) is a critical technique for deploying deep
neural networks on resource-constrained devices. However, existing methods
often face two major challenges: the highly non-uniform distribution of
activations and the static, mismatched codebooks used in weight quantization.
To address these challenges, we propose Adaptive Distribution-aware
Quantization (ADQ), a mixed-precision quantization framework that employs a
differentiated strategy. The core of ADQ is a novel adaptive weight
quantization scheme comprising three key innovations: (1) a quantile-based
initialization method that constructs a codebook closely aligned with the
initial weight distribution; (2) an online codebook adaptation mechanism based
on Exponential Moving Average (EMA) to dynamically track distributional shifts;
and (3) a sensitivity-informed strategy for mixed-precision allocation. For
activations, we integrate a hardware-friendly non-uniform-to-uniform mapping
scheme. Comprehensive experiments validate the effectiveness of our method. On
ImageNet, ADQ enables a ResNet-18 to achieve 71.512% Top-1 accuracy with an
average bit-width of only 2.81 bits, outperforming state-of-the-art methods
under comparable conditions. Furthermore, detailed ablation studies on CIFAR-10
systematically demonstrate the individual contributions of each innovative
component, validating the rationale and effectiveness of our design.

</details>


### [93] [OmniMotion-X: Versatile Multimodal Whole-Body Motion Generation](https://arxiv.org/abs/2510.19789)
*Guowei Xu,Yuxuan Bian,Ailing Zeng,Mingyi Shi,Shaoli Huang,Wen Li,Lixin Duan,Qiang Xu*

Main category: cs.CV

TL;DR: 本文提出了OmniMotion-X，一个多功能多模态全身人体运动生成框架，利用自回归扩散变换器以统一的序列到序列方式，支持多种任务并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在支持多样化的多模态运动生成任务以及生成内容的一致性方面存在不足，需要一个更通用、更一致的框架来生成逼真且可控的全身人体运动。

Method: OmniMotion-X采用自回归扩散变换器，以统一的序列到序列方式处理多模态任务。它引入了参考运动作为新的条件信号，以增强生成内容、风格和时间动态的一致性。为解决多模态冲突，提出了渐进式弱到强混合条件训练策略。为支持高质量训练，构建了OmniMoCap-X数据集，这是目前最大的统一多模态运动数据集，整合了28个公开的MoCap源，涵盖10个不同任务，并标准化为SMPL-X格式。通过渲染视频并使用GPT-4o自动生成结构化和分层字幕，确保了详细和一致的标注。

Result: OmniMotion-X在多项多模态任务中显著超越了现有方法，展示了最先进的性能。它能够交互式地生成逼真、连贯且可控的长时间运动。

Conclusion: OmniMotion-X是一个强大的多模态框架，通过创新的条件信号、训练策略和大规模数据集，实现了在多种任务中生成高质量、一致且可控的全身人体运动，达到了当前最优水平。

Abstract: This paper introduces OmniMotion-X, a versatile multimodal framework for
whole-body human motion generation, leveraging an autoregressive diffusion
transformer in a unified sequence-to-sequence manner. OmniMotion-X efficiently
supports diverse multimodal tasks, including text-to-motion, music-to-dance,
speech-to-gesture, and global spatial-temporal control scenarios (e.g., motion
prediction, in-betweening, completion, and joint/trajectory-guided synthesis),
as well as flexible combinations of these tasks. Specifically, we propose the
use of reference motion as a novel conditioning signal, substantially enhancing
the consistency of generated content, style, and temporal dynamics crucial for
realistic animations. To handle multimodal conflicts, we introduce a
progressive weak-to-strong mixed-condition training strategy. To enable
high-quality multimodal training, we construct OmniMoCap-X, the largest unified
multimodal motion dataset to date, integrating 28 publicly available MoCap
sources across 10 distinct tasks, standardized to the SMPL-X format at 30 fps.
To ensure detailed and consistent annotations, we render sequences into videos
and use GPT-4o to automatically generate structured and hierarchical captions,
capturing both low-level actions and high-level semantics. Extensive
experimental evaluations confirm that OmniMotion-X significantly surpasses
existing methods, demonstrating state-of-the-art performance across multiple
multimodal tasks and enabling the interactive generation of realistic,
coherent, and controllable long-duration motions.

</details>


### [94] [Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing](https://arxiv.org/abs/2510.19808)
*Yusu Qian,Eli Bocek-Rivele,Liangchen Song,Jialing Tong,Yinfei Yang,Jiasen Lu,Wenze Hu,Zhe Gan*

Main category: cs.CV

TL;DR: 本文介绍了Pico-Banana-400K，一个包含40万张图像的大规模、高质量、多样化的指令式图像编辑数据集，旨在解决当前缺乏真实图像数据集的限制，并支持多轮编辑、偏好对齐和指令重写等复杂场景。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态模型在文本引导图像编辑方面取得了显著进展，但研究社区的进步受限于缺乏大规模、高质量、开放获取的真实图像数据集。

Method: 该数据集通过利用Nano-Banana从OpenImages集合中的真实照片生成多样化的编辑对。它采用细粒度图像编辑分类法以确保全面覆盖编辑类型，并通过基于多模态大语言模型（MLLM）的质量评分和精心策划来保持内容保真度和指令忠实性。此外，数据集还包含三个专门的子集：用于多轮编辑的7.2万示例集合、用于对齐研究和奖励模型训练的5.6万示例偏好子集，以及用于开发指令重写和总结能力的配对长短编辑指令。

Result: Pico-Banana-400K是一个全面的40万图像数据集，用于指令式图像编辑。它在质量和多样性上超越了以往的合成数据集，并包含了支持复杂编辑场景（如多轮编辑、偏好学习和指令重写/总结）的专门子集。

Conclusion: Pico-Banana-400K提供了一个大规模、高质量且任务丰富的资源，为训练和基准测试下一代文本引导图像编辑模型奠定了坚实的基础。

Abstract: Recent advances in multimodal models have demonstrated remarkable text-guided
image editing capabilities, with systems like GPT-4o and Nano-Banana setting
new benchmarks. However, the research community's progress remains constrained
by the absence of large-scale, high-quality, and openly accessible datasets
built from real images. We introduce Pico-Banana-400K, a comprehensive
400K-image dataset for instruction-based image editing. Our dataset is
constructed by leveraging Nano-Banana to generate diverse edit pairs from real
photographs in the OpenImages collection. What distinguishes Pico-Banana-400K
from previous synthetic datasets is our systematic approach to quality and
diversity. We employ a fine-grained image editing taxonomy to ensure
comprehensive coverage of edit types while maintaining precise content
preservation and instruction faithfulness through MLLM-based quality scoring
and careful curation. Beyond single turn editing, Pico-Banana-400K enables
research into complex editing scenarios. The dataset includes three specialized
subsets: (1) a 72K-example multi-turn collection for studying sequential
editing, reasoning, and planning across consecutive modifications; (2) a
56K-example preference subset for alignment research and reward model training;
and (3) paired long-short editing instructions for developing instruction
rewriting and summarization capabilities. By providing this large-scale,
high-quality, and task-rich resource, Pico-Banana-400K establishes a robust
foundation for training and benchmarking the next generation of text-guided
image editing models.

</details>


### [95] [How to Evaluate Monocular Depth Estimation?](https://arxiv.org/abs/2510.19814)
*Siyang Wu,Jack Nugent,Willow Yang,Jia Deng*

Main category: cs.CV

TL;DR: 本文对单目深度估计的现有评估指标进行了定量分析，发现它们对曲率扰动不敏感。为解决此问题，作者提出了一种基于相对表面法线的新指标，以及新的可视化工具和组合指标方法，以更好地与人类判断对齐。


<details>
  <summary>Details</summary>
Motivation: 单目深度估计评估缺乏标准化，现有评估指标众多且其权衡和行为尚不明确，如何有效评估仍是一个悬而未决的问题。

Method: 本文对现有评估指标进行了新颖的定量分析，研究了它们对各种地面真实扰动（特别是曲率扰动）的敏感性，并强调与人类判断的比较。在此基础上，引入了一种基于相对表面法线的新指标，并提出了新的深度可视化工具和创建与人类判断更一致的复合指标的原则性方法。

Result: 分析结果表明，现有评估指标对曲率扰动（例如使平面变得波浪状）严重不敏感。

Conclusion: 现有深度估计指标在评估曲率扰动方面存在不足。本文通过引入基于相对表面法线的新指标、可视化工具和复合指标创建方法，改进了单目深度估计的评估方式，使其与人类判断更好地对齐。

Abstract: Monocular depth estimation is an important task with rapid progress, but how
to evaluate it remains an open question, as evidenced by a lack of
standardization in existing literature and a large selection of evaluation
metrics whose trade-offs and behaviors are not well understood. This paper
contributes a novel, quantitative analysis of existing metrics in terms of
their sensitivity to various types of perturbations of ground truth,
emphasizing comparison to human judgment. Our analysis reveals that existing
metrics are severely under-sensitive to curvature perturbation such as making
flat surfaces wavy. To remedy this, we introduce a new metric based on relative
surface normals, along with new depth visualization tools and a principled
method to create composite metrics with better human alignment. Code and data
are available at: https://github.com/princeton-vl/evalmde.

</details>


### [96] [Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2510.19802)
*Xiaozhen Qiao,Jingkai Zhao,Yuqiu Jiang,Xianda Guo,Zhe Sun,Hongyuan Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出CPL-NC，一个针对视觉-语言模型（VLMs）的轻量级测试时适应（TTA）框架，通过引入类别感知原型缓存和负对比学习机制，解决长尾分布下的原型退化和语义相似类别的混淆问题，显著提升了分布偏移下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型（VLMs）在零样本泛化方面表现出色，但当部署分布与训练分布不一致时，其性能会下降。现有的测试时适应（TTA）方法未能有效解决长尾分布中的原型退化问题以及语义相似类别之间的混淆问题。

Method: 本文提出了CPL-NC框架，其包含：1. 类别感知原型缓存模块：根据测试时频率和激活历史动态调整每类容量，并为不活跃类别提供复兴机制以保留稀有类别知识。2. 负对比学习机制：识别并约束困难的视觉-文本负样本以提高类别可分离性。3. 采用非对称优化，仅优化文本原型，同时固定稳定的视觉特征。

Result: 在15个基准测试中，CPL-NC在ResNet-50和ViT-B/16两种骨干网络上均持续优于先前的TTA方法。

Conclusion: CPL-NC通过解决长尾分布下的原型退化和语义相似类别间的混淆问题，有效增强了视觉-语言模型在分布偏移下的泛化能力。

Abstract: Vision-Language Models (VLMs) demonstrate impressive zero-shot generalization
through large-scale image-text pretraining, yet their performance can drop once
the deployment distribution diverges from the training distribution. To address
this, Test-Time Adaptation (TTA) methods update models using unlabeled target
data. However, existing approaches often ignore two key challenges: prototype
degradation in long-tailed distributions and confusion between semantically
similar classes. To tackle these issues, we propose \textbf{C}lass-Aware
\textbf{P}rototype \textbf{L}earning with \textbf{N}egative
\textbf{C}ontrast(\textbf{CPL-NC}), a lightweight TTA framework designed
specifically for VLMs to enhance generalization under distribution shifts.
CPL-NC introduces a \textit{Class-Aware Prototype Cache} Module that
dynamically adjusts per-class capacity based on test-time frequency and
activation history, with a rejuvenation mechanism for inactive classes to
retain rare-category knowledge. Additionally, a \textit{Negative Contrastive
Learning} Mechanism identifies and constrains hard visual-textual negatives to
improve class separability. The framework employs asymmetric optimization,
refining only textual prototypes while anchoring on stable visual features.
Experiments on 15 benchmarks show that CPL-NC consistently outperforms prior
TTA methods across both ResNet-50 and ViT-B/16 backbones.

</details>


### [97] [olmOCR 2: Unit Test Rewards for Document OCR](https://arxiv.org/abs/2510.19817)
*Jake Poznanski,Luca Soldaini,Kyle Lo*

Main category: cs.CV

TL;DR: olmOCR 2是一个新的OCR系统，它使用一个7B视觉语言模型，通过可验证奖励强化学习（RLVR）在合成文档上训练，并在复杂布局（如数学公式、表格和多列）的转换方面实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一个更强大的OCR系统，能够将数字化打印文档（如PDF）转换为干净、自然排序的纯文本，特别是在处理复杂的文档布局（如数学公式、表格和多列）时，能显著提高转换质量。

Method: 该研究方法包括：1) 开发olmOCR 2，其核心是专门的7B视觉语言模型olmOCR-2-7B-1025。2) 使用可验证奖励强化学习（RLVR）对该模型进行训练，奖励是多样化的二元单元测试。3) 创建一个生成合成文档的流水线，这些文档具有多样化且具有挑战性的布局、已知的真实HTML源代码和提取的测试用例，以扩展单元测试的创建。

Result: 研究结果表明，在这些测试用例上进行的强化学习训练，使得olmOCR 2在英语OCR基准测试olmOCR-Bench上取得了最先进的性能。与之前版本相比，其在数学公式转换、表格解析和多列布局方面取得了最大的改进。此外，该模型、数据和代码已在开放许可下发布。

Conclusion: olmOCR 2通过结合专门的视觉语言模型和基于合成数据的强化学习训练，显著提升了数字化打印文档的OCR能力，尤其是在处理复杂布局方面，并为开源社区做出了贡献，为未来的研究和应用提供了基础。

Abstract: We present olmOCR 2, the latest in our family of powerful OCR systems for
converting digitized print documents, like PDFs, into clean, naturally ordered
plain text. olmOCR 2 is powered by olmOCR-2-7B-1025, a specialized, 7B vision
language model (VLM) trained using reinforcement learning with verifiable
rewards (RLVR), where our rewards are a diverse set of binary unit tests. To
scale unit test creation, we develop a pipeline for generating synthetic
documents with diverse and challenging layouts, known ground-truth HTML source
code, and extracted test cases. We show that RL training on these test cases
results in state-of-the-art performance on olmOCR-Bench, our English-language
OCR benchmark, with the largest improvements in math formula conversion, table
parsing, and multi-column layouts compared to previous versions. We release our
model, data and code under permissive open licenses.

</details>


### [98] [Is This Tracker On? A Benchmark Protocol for Dynamic Tracking](https://arxiv.org/abs/2510.19819)
*Ilona Demler,Saumya Chauhan,Georgia Gkioxari*

Main category: cs.CV

TL;DR: 本文引入了ITTO，一个具有挑战性的新基准套件，用于评估和诊断点跟踪方法的性能和局限性。研究发现现有跟踪器在真实世界的运动复杂性和遮挡场景中表现不佳，尤其是在遮挡后重识别方面，凸显了开发新建模方法的必要性。


<details>
  <summary>Details</summary>
Motivation: 当前的基准测试缺乏真实世界的运动复杂性、遮挡模式和物体多样性，无法充分评估和诊断点跟踪方法的真实能力和局限性。因此，需要一个能捕捉这些真实世界特征的新基准。

Method: 引入了ITTO基准套件，其视频来源于现有数据集和以自我为中心的真实世界录像，并通过多阶段管道收集了高质量的人工标注。研究者在ITTO上对最先进的点跟踪方法进行了严格分析，并根据运动复杂性的关键轴分解了性能。

Result: 研究结果表明，现有跟踪器难以应对ITTO中的真实世界挑战，尤其是在遮挡后重新识别点方面表现出关键的失效模式。

Conclusion: 这些结果指出了需要新的建模方法来适应真实世界的动态。ITTO有望成为推动点跟踪发展和指导开发更鲁棒跟踪算法的基础测试平台。

Abstract: We introduce ITTO, a challenging new benchmark suite for evaluating and
diagnosing the capabilities and limitations of point tracking methods. Our
videos are sourced from existing datasets and egocentric real-world recordings,
with high-quality human annotations collected through a multi-stage pipeline.
ITTO captures the motion complexity, occlusion patterns, and object diversity
characteristic of real-world scenes -- factors that are largely absent in
current benchmarks. We conduct a rigorous analysis of state-of-the-art tracking
methods on ITTO, breaking down performance along key axes of motion complexity.
Our findings reveal that existing trackers struggle with these challenges,
particularly in re-identifying points after occlusion, highlighting critical
failure modes. These results point to the need for new modeling approaches
tailored to real-world dynamics. We envision ITTO as a foundation testbed for
advancing point tracking and guiding the development of more robust tracking
algorithms.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [99] [Contextual Augmentation for Entity Linking using Large Language Models](https://arxiv.org/abs/2510.18888)
*Daniel Vollmers,Hamada M. Zahera,Diego Moussallem,Axel-Cyrille Ngonga Ngomo*

Main category: cs.CL

TL;DR: 本文提出了一个统一框架，将实体识别和消歧联合集成，并利用大语言模型丰富上下文，在域外数据集上取得了最先进的实体链接性能。


<details>
  <summary>Details</summary>
Motivation: 传统的实体链接方法采用两步式过程（实体识别和消歧分别建模），计算成本高且效果不佳。

Method: 提出了一个微调模型，在统一框架中联合集成了实体识别和消歧。此外，该方法利用大语言模型（LLM）来丰富实体提及的上下文，以提高实体消歧的性能。

Result: 在基准数据集上进行评估后，该方法在域外数据集上取得了最先进的性能。

Conclusion: 该统一框架结合大语言模型增强上下文的方法，能够有效提升实体链接的性能，尤其在处理域外数据时表现出色。

Abstract: Entity Linking involves detecting and linking entity mentions in natural
language texts to a knowledge graph. Traditional methods use a two-step process
with separate models for entity recognition and disambiguation, which can be
computationally intensive and less effective. We propose a fine-tuned model
that jointly integrates entity recognition and disambiguation in a unified
framework. Furthermore, our approach leverages large language models to enrich
the context of entity mentions, yielding better performance in entity
disambiguation. We evaluated our approach on benchmark datasets and compared
with several baselines. The evaluation results show that our approach achieves
state-of-the-art performance on out-of-domain datasets.

</details>


### [100] [Small Language Models Offer Significant Potential for Science Community](https://arxiv.org/abs/2510.18890)
*Jian Zhang*

Main category: cs.CL

TL;DR: 该研究开发了一个基于MiniLMs的框架，通过语义搜索和句子级索引，从海量地球科学文献中高效、精确、经济地检索信息，并能分析情感和追踪研究趋势。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在处理文献方面取得了进展，但其潜在的信息偏差和高计算成本仍是问题。因此，研究旨在探索使用免费的小型语言模型（MiniLMs）进行精准、快速且经济高效的信息检索的可行性。

Method: 研究构建了一个包含约7700万句高质量句子的地球科学文献语料库，这些句子来源于2000年至2024年间95本领先的同行评审期刊。然后，利用MiniLMs通过语义搜索技术和句子级索引，从语料库中提取相关领域特定信息。此外，还通过情感分析评估情绪基调，并通过无监督聚类分析句子中的主题簇。

Result: MiniLM方法计算效率高，能够识别大量专家验证的信息，特别是定量发现，且优于LLMs的泛化响应。它还能通过分析情感和主题聚类，有效追踪地球科学领域结论、研究重点、进展和新兴问题的演变。

Conclusion: MiniLM在地球科学社区具有巨大潜力，可应用于事实和图像检索、趋势分析、矛盾分析以及教育目的。

Abstract: Recent advancements in natural language processing, particularly with large
language models (LLMs), are transforming how scientists engage with the
literature. While the adoption of LLMs is increasing, concerns remain regarding
potential information biases and computational costs. Rather than LLMs, I
developed a framework to evaluate the feasibility of precise, rapid, and
cost-effective information retrieval from extensive geoscience literature using
freely available small language models (MiniLMs). A curated corpus of
approximately 77 million high-quality sentences, extracted from 95 leading
peer-reviewed geoscience journals such as Geophysical Research Letters and
Earth and Planetary Science Letters published during years 2000 to 2024, was
constructed. MiniLMs enable a computationally efficient approach for extracting
relevant domain-specific information from these corpora through semantic search
techniques and sentence-level indexing. This approach, unlike LLMs such as
ChatGPT-4 that often produces generalized responses, excels at identifying
substantial amounts of expert-verified information with established,
multi-disciplinary sources, especially for information with quantitative
findings. Furthermore, by analyzing emotional tone via sentiment analysis and
topical clusters through unsupervised clustering within sentences, MiniLM
provides a powerful tool for tracking the evolution of conclusions, research
priorities, advancements, and emerging questions within geoscience communities.
Overall, MiniLM holds significant potential within the geoscience community for
applications such as fact and image retrievals, trend analyses, contradiction
analyses, and educational purposes.

</details>


### [101] [When Models Can't Follow: Testing Instruction Adherence Across 256 LLMs](https://arxiv.org/abs/2510.18892)
*Richard J. Young,Brandon Gillins,Alice M. Matthews*

Main category: cs.CL

TL;DR: 本文提出一个精简的评估框架，包含20个精心设计的提示，用于快速诊断大型语言模型（LLM）的指令遵循能力，并进行了大规模实证研究。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM广泛部署，但系统评估其指令遵循能力仍具挑战。现有基准可能导致模型记忆而非真实能力评估。需要聚焦、快速诊断特定指令遵循模式的新评估方法。

Method: 开发了一个包含20个提示的精简评估框架，旨在评估格式、内容约束、逻辑序列和多步骤任务执行等指令遵循方面。在2025年10月14日对OpenRouter上256个已验证的LLM进行了大规模实证研究，涵盖主流和新兴模型。

Result: 研究揭示了LLM指令遵循中一致的失败模式，并识别出特定类型的指令对模型构成特殊挑战。提供了不同供应商模型间的比较性能分析。

Conclusion: 本工作贡献了一个实用的LLM指令遵循评估诊断工具，以及对当前LLM生态系统中指令遵循能力最全面的实证分析之一。

Abstract: Despite widespread deployment of Large Language Models, systematic evaluation
of instruction-following capabilities remains challenging. While comprehensive
benchmarks exist, focused assessments that quickly diagnose specific
instruction adherence patterns are valuable. As newer models may be trained on
existing benchmarks, novel evaluation approaches are needed to assess genuine
capabilities rather than memorized performance. This paper presents a
streamlined evaluation framework using twenty carefully designed prompts to
assess LLM instruction-following across diverse task categories. We demonstrate
this framework through a large-scale empirical study conducted on October 14,
2025, testing 256 verified working models from 331 available via OpenRouter. To
ensure methodological rigor and prevent selection bias, we first verified each
model's basic functionality before inclusion. Unlike large-scale benchmarks
requiring extensive computational resources, our approach offers a practical
diagnostic tool researchers and practitioners can readily apply. Our
methodology builds upon verifiable instructions while introducing a compact
test suite balancing comprehensiveness with efficiency. Each prompt targets
distinct aspects of instruction following, including format compliance, content
constraints, logical sequencing, and multi-step task execution. We evaluate
models from major providers (OpenAI, Anthropic, Google, Meta, Mistral) and
emerging implementations (Qwen, DeepSeek, community models), providing
comparative performance analysis. Our findings reveal consistent failure modes
and identify specific instruction types posing particular challenges. This work
contributes both a practical evaluation tool and one of the most comprehensive
empirical analyses of instruction-following capabilities across the
contemporary LLM landscape.

</details>


### [102] [Transformer-Based Low-Resource Language Translation: A Study on Standard Bengali to Sylheti](https://arxiv.org/abs/2510.18898)
*Mangsura Kabir Oni,Tabia Tanzin Prama*

Main category: cs.CL

TL;DR: 本研究通过微调多语言Transformer模型，实现了孟加拉语到锡尔赫特语的机器翻译，并发现微调模型在翻译质量上显著优于零样本大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 尽管机器翻译在资源丰富的语言上取得了显著进展，但像锡尔赫特语这样的低资源语言仍未得到充分探索。本研究旨在填补这一空白，推动包容性语言技术的发展。

Method: 研究方法包括微调多语言Transformer模型（如mBART-50和MarianMT），并将其性能与零样本大型语言模型（LLMs）进行比较，以评估孟加拉语到锡尔赫特语的翻译质量。

Result: 实验结果表明，微调模型显著优于LLMs。其中，mBART-50在翻译充分性方面表现最佳，而MarianMT在字符级保真度方面表现最强。

Conclusion: 研究强调了针对低资源语言进行任务特定适应的重要性，并为实现更具包容性的语言技术做出了贡献。

Abstract: Machine Translation (MT) has advanced from rule-based and statistical methods
to neural approaches based on the Transformer architecture. While these methods
have achieved impressive results for high-resource languages, low-resource
varieties such as Sylheti remain underexplored. In this work, we investigate
Bengali-to-Sylheti translation by fine-tuning multilingual Transformer models
and comparing them with zero-shot large language models (LLMs). Experimental
results demonstrate that fine-tuned models significantly outperform LLMs, with
mBART-50 achieving the highest translation adequacy and MarianMT showing the
strongest character-level fidelity. These findings highlight the importance of
task-specific adaptation for underrepresented languages and contribute to
ongoing efforts toward inclusive language technologies.

</details>


### [103] [DuoLens: A Framework for Robust Detection of Machine-Generated Multilingual Text and Code](https://arxiv.org/abs/2510.18904)
*Shriyansh Agrawal,Aidan Lau,Sanyam Shah,Ahan M R,Kevin Zhu,Sunishchal Dev,Vasu Sharma*

Main category: cs.CL

TL;DR: 该研究提出通过微调小型语言模型（SLMs，如RoBERTA和CodeBERTa）来检测大型语言模型（LLMs）生成的文本和代码，结果显示SLMs在准确性和效率上均显著优于现有LLM检测器，并能抵抗对抗性攻击。


<details>
  <summary>Details</summary>
Motivation: 当前LLM生成内容检测器（如Fast DetectGPT或GPTZero）普遍采用零样本方法，但存在计算成本高或准确性不足的问题，且两者之间存在权衡，因此需要更准确、高效且适用于多语言文本和源代码的检测方法。

Method: 该研究提出微调编码器专用的小型语言模型（SLMs），具体是RoBERTA和CodeBERTa的预训练模型，并使用专门的源代码和自然语言数据集进行二元分类任务。

Result: 微调后的编码器实现了0.97至0.99的AUROC和0.89至0.94的宏观F1分数，同时将延迟降低了8-12倍，峰值VRAM降低了3-5倍（针对512-token输入）。在跨生成器迁移和对抗性转换（复述、回译、代码格式化/重命名）下，性能仍能保持原始AUROC的92%以上。

Conclusion: 对于二元分类任务，微调后的SLMs在检测机器生成内容方面，无论是在准确性还是计算效率上，都以显著优势超越了LLMs，且能有效抵御对抗性攻击，提供了一个更优的解决方案。

Abstract: The prevalence of Large Language Models (LLMs) for generating multilingual
text and source code has only increased the imperative for machine-generated
content detectors to be accurate and efficient across domains. Current
detectors, predominantly utilizing zero-shot methods, such as Fast DetectGPT or
GPTZero, either incur high computational cost or lack sufficient accuracy,
often with a trade-off between the two, leaving room for further improvement.
To address these gaps, we propose the fine-tuning of encoder-only Small
Language Models (SLMs), in particular, the pre-trained models of RoBERTA and
CodeBERTa using specialized datasets on source code and other natural language
to prove that for the task of binary classification, SLMs outperform LLMs by a
huge margin whilst using a fraction of compute. Our encoders achieve AUROC $=
0.97$ to $0.99$ and macro-F1 $0.89$ to $0.94$ while reducing latency by
$8$-$12\times$ and peak VRAM by $3$-$5\times$ at $512$-token inputs. Under
cross-generator shifts and adversarial transformations (paraphrase,
back-translation; code formatting/renaming), performance retains $\geq 92%$ of
clean AUROC. We release training and evaluation scripts with seeds and configs;
a reproducibility checklist is also included.

</details>


### [104] [Improving Topic Modeling of Social Media Short Texts with Rephrasing: A Case Study of COVID-19 Related Tweets](https://arxiv.org/abs/2510.18908)
*Wangjiaxuan Xin,Shuhua Yin,Shi Chen,Yaorong Ge*

Main category: cs.CL

TL;DR: 本研究提出了TM-Rephrase框架，利用大型语言模型将社交媒体短文本改写成标准化语言，以提高危机期间（如COVID-19）公共话语分析中主题建模的性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体短文本的简洁性、非正式性和噪声常常阻碍传统主题建模的有效性，导致生成不连贯、冗余或难以解释的主题，尤其是在COVID-19等危机公共话语分析中。

Method: 开发了模型无关的TM-Rephrase框架，利用大型语言模型（LLMs）将原始推文改写为更标准化和正式的语言，然后进行主题建模。研究了两种改写策略：通用改写和口语到正式改写。使用包含25,027条COVID-19相关推文的数据集，评估了TM-Rephrase对多种主题建模方法（如LDA）在主题连贯性、主题独特性和主题多样性等指标上的影响。

Result: TM-Rephrase显著提高了主题连贯性、主题独特性和主题多样性这三个主题建模性能指标，并减少了大多数主题建模算法的主题冗余。其中，口语到正式的改写策略带来了最大的性能提升，尤其对Latent Dirichlet Allocation (LDA) 算法效果显著。

Conclusion: 本研究为增强公共卫生相关社交媒体分析中的主题建模提供了一种模型无关的方法，对改进健康危机及其他重要领域公共话语的理解具有广泛意义。

Abstract: Social media platforms such as Twitter (now X) provide rich data for
analyzing public discourse, especially during crises such as the COVID-19
pandemic. However, the brevity, informality, and noise of social media short
texts often hinder the effectiveness of traditional topic modeling, producing
incoherent or redundant topics that are often difficult to interpret. To
address these challenges, we have developed \emph{TM-Rephrase}, a
model-agnostic framework that leverages large language models (LLMs) to
rephrase raw tweets into more standardized and formal language prior to topic
modeling. Using a dataset of 25,027 COVID-19-related Twitter posts, we
investigate the effects of two rephrasing strategies, general- and
colloquial-to-formal-rephrasing, on multiple topic modeling methods. Results
demonstrate that \emph{TM-Rephrase} improves three metrics measuring topic
modeling performance (i.e., topic coherence, topic uniqueness, and topic
diversity) while reducing topic redundancy of most topic modeling algorithms,
with the colloquial-to-formal strategy yielding the greatest performance gains
and especially for the Latent Dirichlet Allocation (LDA) algorithm. This study
contributes to a model-agnostic approach to enhancing topic modeling in public
health related social media analysis, with broad implications for improved
understanding of public discourse in health crisis as well as other important
domains.

</details>


### [105] [Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection](https://arxiv.org/abs/2510.18909)
*Hongyi He,Xiao Liu,Zhenghao Lin,Mingni Tang,Yi Cheng,Jintao Wang,Wenjie Li,Peng Cheng,Yeyun Gong*

Main category: cs.CL

TL;DR: 高质量和多样性预训练数据对大型语言模型至关重要。现有基于分数的方法因忽略多样性而表现不佳。本文提出ODiS算法，通过正交多样性感知选择，确保数据质量和多样性，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 高质量的预训练数据对大型语言模型（LLMs）至关重要，但现有基于分数的数据选择方法存在根本性偏差：它们将相关维度合并，导致高分数据看似高质量但系统性地忽略了多样性。直接选择高分数据反而会降低性能，这表明分数与下游基准结果之间存在非单调性。

Method: 本文提出了正交多样性感知选择（ODiS）算法。首先，ODiS从语言质量、知识质量和理解难度等多个维度评估数据。然后，通过主成分分析（PCA）对多维分数进行去相关处理，得到正交评估维度。接着，为每个正交维度训练一个基于Roberta的评分器，将数据回归到PCA投影分数上，以实现大规模语料库的可伸缩推理。最后，ODiS在每个正交维度内选择得分最高的数据来构建训练数据集，从而确保质量和多样性。

Result: 实证结果表明，ODiS选择的数据维度间重叠率低于2%，证实了维度间的正交性。更重要的是，使用ODiS选择的数据训练的模型在下游基准测试中显著优于其他基线，凸显了LLMs进行正交、多样性感知数据选择的必要性。

Conclusion: 确保多样性需要将相关指标分解为正交特征维度，然后可以直接选择高分数据。ODiS算法通过正交、多样性感知的数据选择，成功地在大型语言模型数据预训练中同时保留了数据质量和多样性，从而显著提升了模型在下游任务中的表现。

Abstract: High-quality pre-training data is crutial for large language models, where
quality captures factual reliability and semantic value, and diversity ensures
broad coverage and distributional heterogeneity. Existing approaches typically
rely on single or multiple-dimensional score-based selection. However, directly
selecting top-scored data often degrades performance, and sampling from a
broader range is required to recover results. The above non-monotonicity
between dataset scores and downstream benchmark results reveals a fundamental
bias: score-based methods collapse correlated dimensions, causing top-scored
data to appear high-quality while systematically overlooking diversity. We
argue that ensuring diversity requires decomposing correlated metrics into
orthogonal feature dimensions, from which the top-scored data can be directly
selected. Therefore, we proposed the Orthogonal Diversity-Aware Selection
(ODiS) algorithm, which preserves both quality and diversity during data
selection. First, ODiS evaluates data from multiple dimensions, covering
language quality, knowledge quality, and comprehension difficulty. The
multi-dimensional scores are then decorrelated via Principal Component Analysis
(PCA), yielding orthogonal evaluation dimensions. For each dimension, a
Roberta-based scorer is trained to regress the data onto PCA-projected scores,
enabling scalable inference on large corpora. Finally, ODiS constructs the
training dataset by selecting top-scored data within each orthogonal dimension,
thereby ensuring both quality and diversity. Empirical results show that
ODiS-selected data exhibit less than 2\% inter-dimension overlap, confirming
orthogonality between dimensions. More importantly, models trained with
ODiS-selected data significantly outperform other baselines on downstream
benchmarks, highlighting the necessity of orthogonal, diversity-aware data
selection for LLMs.

</details>


### [106] [Context-aware Fairness Evaluation and Mitigation in LLMs](https://arxiv.org/abs/2510.18914)
*Afrozah Nadeem,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 本文提出了一种动态、可逆的剪枝框架，通过在推理时自适应地掩盖上下文感知的神经元激活，以减轻大型语言模型中不希望出现的行为，从而实现动态的公平性控制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的内部表示存在偏差、不一致、放大有害内容等不良行为。现有的训练时或数据中心方法计算成本高昂、部署后不可逆且适应性差。基于剪枝的方法虽然灵活透明，但大多是静态的，一旦神经元被移除，模型就失去了适应新上下文的能力。

Method: 本文提出了一种动态、可逆的、基于剪枝的框架。该框架在推理时检测上下文感知的神经元激活，并应用自适应掩码来调节其在生成过程中的影响。

Result: 该推理时解决方案提供了细粒度、内存感知的缓解措施，能够在多语言单轮和多轮对话中保持知识完整并实现更连贯的行为。

Conclusion: 该框架能够实现实时对话AI中的动态公平性控制。

Abstract: Large language models often display undesirable behaviors embedded in their
internal representations, undermining fairness, inconsistency drift,
amplification of harmful content, and the propagation of unwanted patterns
during extended dialogue and conversations. Although training-time or
data-centric methods attempt to reduce these effects, they are computationally
expensive, irreversible once deployed, and slow to adapt to new conversational
contexts. Pruning-based methods provide a flexible and transparent way to
reduce bias by adjusting the neurons responsible for certain behaviors.
However, most existing approaches are static; once a neuron is removed, the
model loses the ability to adapt when the conversation or context changes. To
address this, we propose a dynamic, reversible, pruning-based framework that
detects context-aware neuron activations and applies adaptive masking to
modulate their influence during generation. Our inference-time solution
provides fine-grained, memory-aware mitigation with knowledge-preserved, more
coherent behavior across multilingual single- and multi-turn dialogues,
enabling dynamic fairness control in real-world conversational AI.

</details>


### [107] [MMAO-Bench: MultiModal All in One Benchmark Reveals Compositional Law between Uni-modal and Omni-modal in OmniModels](https://arxiv.org/abs/2510.18915)
*Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Xuezhi Cao*

Main category: cs.CL

TL;DR: 本文提出了MMAO-Bench，一个新颖的多模态一体化基准，用于评估统一视觉、音频和语言模态的全能模型（omni models）的单模态和全能模态理解能力。研究揭示了跨模态和单模态性能之间的组合规律，并发现全能模态能力对弱模型表现为瓶颈效应，对强模型则表现出协同促进作用。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型正从单模态理解向统一视觉、音频和语言模态的全能模型发展。然而，单模态和全能模态之间的关联尚不明确，需要进行全面评估以推动全能模型的智能演进。

Method: 本文提出了一个新颖、高质量、多样化的全能模型基准——MultiModal All in One Benchmark (MMAO-Bench)。该基准包含1880个人工策划的样本，涵盖44种任务类型，并引入了一种创新的多步骤开放式问题类型，以更好地评估复杂的推理任务。

Result: 实验结果表明，跨模态和单模态性能之间存在组合规律。全能模态能力对弱模型表现为瓶颈效应，而对强模型则表现出协同促进作用。

Conclusion: MMAO-Bench提供了一个评估全能模型单模态和全能模态理解能力的有效工具。研究结果揭示了模型性能的组合规律，并指出了全能模态能力对不同能力水平模型的影响（弱模型的瓶颈效应和强模型的协同促进作用），为全能模型的智能发展提供了方向。

Abstract: Multimodal Large Languages models have been progressing from uni-modal
understanding toward unifying visual, audio and language modalities,
collectively termed omni models. However, the correlation between uni-modal and
omni-modal remains unclear, which requires comprehensive evaluation to drive
omni model's intelligence evolution. In this work, we propose a novel, high
quality and diversity omni model benchmark, MultiModal All in One Benchmark
(MMAO-Bench), which effectively assesses both uni-modal and omni-modal
understanding capabilities. The benchmark consists of 1880 human curated
samples, across 44 task types, and a innovative multi-step open-ended question
type that better assess complex reasoning tasks. Experimental result shows the
compositional law between cross-modal and uni-modal performance and the
omni-modal capability manifests as a bottleneck effect on weak models, while
exhibiting synergistic promotion on strong models.

</details>


### [108] [Misinformation Detection using Large Language Models with Explainability](https://arxiv.org/abs/2510.18918)
*Jainee Patel,Chintan Bhatt,Himani Trivedi,Thanh Thi Nguyen*

Main category: cs.CL

TL;DR: 本文提出一个可解释且计算高效的管道，使用基于Transformer的预训练语言模型（PLMs）检测虚假信息，并通过两步优化策略和可解释性工具，证明轻量级PLM能在保持性能的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 在线平台上虚假信息的迅速传播破坏了个人间的信任，并阻碍了知情决策的制定。

Method: 使用基于Transformer的PLMs（RoBERTa和DistilBERT），采用两步优化策略：首先冻结主干网络并训练分类头；然后逐步解冻主干层并应用分层学习率衰减。在COVID Fake News和FakeNewsNet GossipCop两个真实世界基准数据集上进行测试，并整合LIME（局部可解释模型无关解释）提供词元级解释和SHAP（Shapley加性解释）提供全局特征归因。

Result: DistilBERT在计算资源显著减少的情况下，实现了与RoBERTa相当的准确性。研究表明，轻量级PLM可以在大幅降低计算成本的同时保持任务性能，并且所提出的可解释管道在不损害性能的前提下，提供了可靠的局部和全局解释。

Conclusion: 结合了原则性微调和可解释性的PLMs可以作为可扩展、值得信赖的虚假信息检测的有效框架。

Abstract: The rapid spread of misinformation on online platforms undermines trust among
individuals and hinders informed decision making. This paper shows an
explainable and computationally efficient pipeline to detect misinformation
using transformer-based pretrained language models (PLMs). We optimize both
RoBERTa and DistilBERT using a two-step strategy: first, we freeze the backbone
and train only the classification head; then, we progressively unfreeze the
backbone layers while applying layer-wise learning rate decay. On two
real-world benchmark datasets, COVID Fake News and FakeNewsNet GossipCop, we
test the proposed approach with a unified protocol of preprocessing and
stratified splits. To ensure transparency, we integrate the Local Interpretable
Model-Agnostic Explanations (LIME) at the token level to present token-level
rationales and SHapley Additive exPlanations (SHAP) at the global feature
attribution level. It demonstrates that DistilBERT achieves accuracy comparable
to RoBERTa while requiring significantly less computational resources. This
work makes two key contributions: (1) it quantitatively shows that a
lightweight PLM can maintain task performance while substantially reducing
computational cost, and (2) it presents an explainable pipeline that retrieves
faithful local and global justifications without compromising performance. The
results suggest that PLMs combined with principled fine-tuning and
interpretability can be an effective framework for scalable, trustworthy
misinformation detection.

</details>


### [109] [Evaluating LLM Story Generation through Large-scale Network Analysis of Social Structures](https://arxiv.org/abs/2510.18932)
*Hiroshi Nonaka,K. E. Perry*

Main category: cs.CL

TL;DR: 本文提出了一种通过分析叙事中的符号化角色网络来评估大型语言模型（LLM）故事创作能力的可扩展方法，发现LLM生成的故事普遍偏向于紧密、积极的关系。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在复杂任务（如故事生成）中的创造力通常需要难以规模化的人工评估，因此需要一种可扩展的评估方法。

Method: 引入了一种新颖的可扩展方法，通过将叙事中的潜在社会结构分析为符号化角色网络来评估LLM的故事生成。通过分析网络属性（如密度、聚类和符号化边缘权重），对来自四种领先LLM（GPT-4o, GPT-4o mini, Gemini 1.5 Pro, Gemini 1.5 Flash）生成的1200多个故事和一个人类编写语料库进行了大规模比较分析。

Result: 研究发现，LLM生成的故事始终表现出对紧密、积极关系的强烈偏见，这与先前使用人工评估的研究结果一致。

Conclusion: 所提出的方法为评估当前和未来LLM在创意故事讲述方面的局限性和倾向提供了一个有价值的工具。

Abstract: Evaluating the creative capabilities of large language models (LLMs) in
complex tasks often requires human assessments that are difficult to scale. We
introduce a novel, scalable methodology for evaluating LLM story generation by
analyzing underlying social structures in narratives as signed character
networks. To demonstrate its effectiveness, we conduct a large-scale
comparative analysis using networks from over 1,200 stories, generated by four
leading LLMs (GPT-4o, GPT-4o mini, Gemini 1.5 Pro, and Gemini 1.5 Flash) and a
human-written corpus. Our findings, based on network properties like density,
clustering, and signed edge weights, show that LLM-generated stories
consistently exhibit a strong bias toward tightly-knit, positive relationships,
which aligns with findings from prior research using human assessment. Our
proposed approach provides a valuable tool for evaluating limitations and
tendencies in the creative storytelling of current and future LLMs.

</details>


### [110] [Lost in the Maze: Overcoming Context Limitations in Long-Horizon Agentic Search](https://arxiv.org/abs/2510.18939)
*Howard Yen,Ashwin Paranjape,Mengzhou Xia,Thejas Venkatesh,Jack Hessel,Danqi Chen,Yuhao Zhang*

Main category: cs.CL

TL;DR: 长周期智能体搜索面临上下文限制，SLIM框架通过分离搜索/浏览工具和周期性总结来管理上下文，以更低的成本和更少的工具调用实现更好的性能，并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 流行的智能体搜索框架在长周期任务中表现不佳，主要原因是上下文限制，它们积累冗长嘈杂的内容，达到上下文窗口和工具预算限制，或过早停止。

Method: 引入SLIM（Simple Lightweight Information Management）框架，该框架将检索分为独立的搜索和浏览工具，并定期总结轨迹，以保持上下文简洁，同时实现更长、更专注的搜索。此外，还发布了一个自动化的细粒度轨迹分析管道和错误分类法。

Result: 在长周期任务中，SLIM以显著降低的成本和更少的工具调用实现了与强大开源基线相当的性能。具体而言，以o3为基础模型，SLIM在BrowseComp上达到56%，在HLE上达到31%，分别比所有开源框架高出8和4个绝对百分点，同时工具调用次数减少了4-6倍。SLIM还表现出更少的幻觉。

Conclusion: SLIM的分析框架和简单的工具设计有望为未来的长周期智能体提供启发。

Abstract: Long-horizon agentic search requires iteratively exploring the web over long
trajectories and synthesizing information across many sources, and is the
foundation for enabling powerful applications like deep research systems. In
this work, we show that popular agentic search frameworks struggle to scale to
long trajectories primarily due to context limitations-they accumulate long,
noisy content, hit context window and tool budgets, or stop early. Then, we
introduce SLIM (Simple Lightweight Information Management), a simple framework
that separates retrieval into distinct search and browse tools, and
periodically summarizes the trajectory, keeping context concise while enabling
longer, more focused searches. On long-horizon tasks, SLIM achieves comparable
performance at substantially lower cost and with far fewer tool calls than
strong open-source baselines across multiple base models. Specifically, with o3
as the base model, SLIM achieves 56% on BrowseComp and 31% on HLE,
outperforming all open-source frameworks by 8 and 4 absolute points,
respectively, while incurring 4-6x fewer tool calls. Finally, we release an
automated fine-grained trajectory analysis pipeline and error taxonomy for
characterizing long-horizon agentic search frameworks; SLIM exhibits fewer
hallucinations than prior systems. We hope our analysis framework and simple
tool design inform future long-horizon agents.

</details>


### [111] [ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge](https://arxiv.org/abs/2510.18941)
*Zhilin Wang,Jaehun Jung,Ximing Lu,Shizhe Diao,Ellie Evans,Jiaqi Zeng,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.CL

TL;DR: 本文介绍了ProfBench，一个由人类专家评估的专业领域（物理、化学、金融、咨询）LLM基准测试数据集，包含7000多个响应-标准对。研究还构建了经济高效的LLM-Judges来评估此基准，发现即使最先进的LLM在此类任务中表现也具有挑战性，并揭示了专有模型和开源模型之间的性能差异。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的评估常受限于响应验证的难度，主要集中在数学、编程和简短问答等任务。然而，许多实际应用需要评估LLM处理专业文档、信息综合和生成综合报告的能力，而现有评估方法无法满足这一需求。

Method: 研究引入了ProfBench数据集，包含7000多个由具有专业知识的人类专家（物理博士、化学博士、金融MBA和咨询MBA）评估的响应-标准对。为了实现公正且可访问的评估，研究构建了鲁棒且经济高效的LLM-Judges，通过缓解自我增强偏差并将评估成本降低2-3个数量级。

Result: ProfBench对最先进的LLM提出了显著挑战，即使是表现最好的模型（如GPT-5-high）也仅达到65.9%的整体性能。此外，研究还发现专有模型和开源模型之间存在显著的性能差异，并深入探讨了“扩展思维”（extended thinking）在解决复杂专业领域任务中的作用。

Conclusion: ProfBench提供了一个全新的、具有挑战性的专业领域LLM评估基准，揭示了当前最先进LLM在处理复杂专业任务时的局限性。同时，经济高效的LLM-Judges的引入使得更广泛的社区能够进行公正的评估。研究结果为LLM在专业领域的未来发展方向提供了重要见解。

Abstract: Evaluating progress in large language models (LLMs) is often constrained by
the challenge of verifying responses, limiting assessments to tasks like
mathematics, programming, and short-form question-answering. However, many
real-world applications require evaluating LLMs in processing professional
documents, synthesizing information, and generating comprehensive reports in
response to user queries. We introduce ProfBench: a set of over 7000
response-criterion pairs as evaluated by human-experts with professional
knowledge across Physics PhD, Chemistry PhD, Finance MBA and Consulting MBA. We
build robust and affordable LLM-Judges to evaluate ProfBench rubrics, by
mitigating self-enhancement bias and reducing the cost of evaluation by 2-3
orders of magnitude, to make it fair and accessible to the broader community.
Our findings reveal that ProfBench poses significant challenges even for
state-of-the-art LLMs, with top-performing models like GPT-5-high achieving
only 65.9\% overall performance. Furthermore, we identify notable performance
disparities between proprietary and open-weight models and provide insights
into the role that extended thinking plays in addressing complex,
professional-domain tasks. Data:
https://huggingface.co/datasets/nvidia/ProfBench and Code:
https://github.com/NVlabs/ProfBench

</details>


### [112] [Dynamic Evaluation for Oversensitivity in LLMs](https://arxiv.org/abs/2510.19005)
*Sophia Xiao Pu,Sitao Cheng,Xin Eric Wang,William Yang Wang*

Main category: cs.CL

TL;DR: 本文提出一个动态框架和OVERBENCH基准，用于评估大型语言模型（LLM）对良性提示的过度敏感性。OVERBENCH通过生成模型特定的挑战性数据集，解决了现有静态基准数据污染和评估能力下降的问题。


<details>
  <summary>Details</summary>
Motivation: 语言模型对良性提示的过度敏感（防御性拒绝）会中断用户交互并模糊有害与无害内容的界限。现有基准依赖静态数据集，随着模型演进会过时，导致数据污染和评估能力下降。

Method: 开发了一个框架，该框架能动态生成模型特定的挑战性数据集，以捕捉新兴的防御模式并与每个模型的独特行为对齐。在此基础上，构建了OVERBENCH，一个聚合了来自25个不同LLM家族的45万个样本的基准。

Result: OVERBENCH为过度敏感性提供了一个动态和演进的视角，允许随着模型的进步持续监控防御触发器，并揭示了静态数据集可能忽略的漏洞。

Conclusion: 该研究通过提供一个动态且不断演进的基准（OVERBENCH），有效地解决了现有静态数据集在评估LLM过度敏感性方面的局限性，实现了对模型防御性行为的持续监控和更准确的评估。

Abstract: Oversensitivity occurs when language models defensively reject prompts that
are actually benign. This behavior not only disrupts user interactions but also
obscures the boundary between harmful and harmless content. Existing benchmarks
rely on static datasets that degrade overtime as models evolve, leading to data
contamination and diminished evaluative power. To address this, we develop a
framework that dynamically generates model-specific challenging datasets,
capturing emerging defensive patterns and aligning with each model's unique
behavior. Building on this approach, we construct OVERBENCH, a benchmark that
aggregates these datasets across diverse LLM families, encompassing 450,000
samples from 25 models. OVERBENCH provides a dynamic and evolving perspective
on oversensitivity, allowing for continuous monitoring of defensive triggers as
models advance, highlighting vulnerabilities that static datasets overlook.

</details>


### [113] [Are they lovers or friends? Evaluating LLMs' Social Reasoning in English and Korean Dialogues](https://arxiv.org/abs/2510.19028)
*Eunsu Kim,Junyeong Park,Juhyun Oh,Kiwoong Park,Seyoung Song,A. Seza Dogruoz,Najoung Kim,Alice Oh*

Main category: cs.CL

TL;DR: 该研究引入了SCRIPTS数据集，用于评估大型语言模型在人际关系推理方面的社会推理能力，发现当前模型存在显著局限性，尤其是在韩语和处理社会偏见方面。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在人机交互中日益普及，它们在人际情境中的社会推理能力变得至关重要。研究旨在评估并揭示当前LLMs在这方面的能力和局限性。

Method: 引入了SCRIPTS数据集，包含1k个英语和韩语对话，来源于电影剧本。任务是评估模型推断对话者之间人际关系（如朋友、姐妹、恋人）的能力。对话由母语（或同等水平）的韩语和英语使用者标注概率关系标签（极有可能、可能性较小、不可能）。评估了九个模型在此任务上的表现。

Result: 当前专有LLMs在英语数据集上达到约75-80%的准确率，但在韩语数据集上降至58-69%。模型在10-25%的响应中选择了“不可能”的关系。此外，思维模型和思维链提示对社会推理的益处微乎其微，有时甚至会放大社会偏见。

Conclusion: 研究结果揭示了当前LLMs在社会推理能力方面存在显著局限性，强调了开发具有社会意识的语言模型的必要性。

Abstract: As large language models (LLMs) are increasingly used in human-AI
interactions, their social reasoning capabilities in interpersonal contexts are
critical. We introduce SCRIPTS, a 1k-dialogue dataset in English and Korean,
sourced from movie scripts. The task involves evaluating models' social
reasoning capability to infer the interpersonal relationships (e.g., friends,
sisters, lovers) between speakers in each dialogue. Each dialogue is annotated
with probabilistic relational labels (Highly Likely, Less Likely, Unlikely) by
native (or equivalent) Korean and English speakers from Korea and the U.S.
Evaluating nine models on our task, current proprietary LLMs achieve around
75-80% on the English dataset, whereas their performance on Korean drops to
58-69%. More strikingly, models select Unlikely relationships in 10-25% of
their responses. Furthermore, we find that thinking models and chain-of-thought
prompting, effective for general reasoning, provide minimal benefits for social
reasoning and occasionally amplify social biases. Our findings reveal
significant limitations in current LLMs' social reasoning capabilities,
highlighting the need for efforts to develop socially-aware language models.

</details>


### [114] [Re:Member: Emotional Question Generation from Personal Memories](https://arxiv.org/abs/2510.19030)
*Zackary Rackauckas,Nobuaki Minematsu,Julia Hirschberg*

Main category: cs.CL

TL;DR: Re:Member是一个探索情感表达、记忆驱动交互如何支持更具吸引力的第二语言学习的系统。它利用用户的个人视频，生成目标语言的风格化口语问题，旨在鼓励情感回忆和对话参与。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索如何通过情感表达和基于记忆的交互，使第二语言学习过程更加引人入胜。

Method: 该系统通过以下方式实现：利用用户的个人视频生成风格化的口语问题；将情感语气与视觉情境对齐，使用耳语或深夜语调等表达性语音风格来唤起特定情绪；技术上结合了基于WhisperX的文本对齐、3帧视觉采样和Style-BERT-VITS2进行情感合成，形成一个模块化的生成管道。它被设计为一个风格化的交互探测器。

Result: 作为一个风格化的交互探测器，Re:Member系统突出了情感和个人媒体在以学习者为中心的教育技术中的作用。

Conclusion: Re:Member系统通过结合情感表达和个人媒体，为支持更具吸引力的第二语言学习提供了一种新的途径，并强调了这些元素在以学习者为中心的教育技术中的重要性。

Abstract: We present Re:Member, a system that explores how emotionally expressive,
memory-grounded interaction can support more engaging second language (L2)
learning. By drawing on users' personal videos and generating stylized spoken
questions in the target language, Re:Member is designed to encourage affective
recall and conversational engagement. The system aligns emotional tone with
visual context, using expressive speech styles such as whispers or late-night
tones to evoke specific moods. It combines WhisperX-based transcript alignment,
3-frame visual sampling, and Style-BERT-VITS2 for emotional synthesis within a
modular generation pipeline. Designed as a stylized interaction probe,
Re:Member highlights the role of affect and personal media in learner-centered
educational technologies.

</details>


### [115] [When Can We Trust LLMs in Mental Health? Large-Scale Benchmarks for Reliable LLM Evaluation](https://arxiv.org/abs/2510.19032)
*Abeer Badawi,Elahe Rahimi,Md Tahmid Rahman Laskar,Sheri Grach,Lindsay Bertrand,Lames Danok,Jimmy Huang,Frank Rudzicz,Elham Dolatabadi*

Main category: cs.CL

TL;DR: 本文引入了两个大规模基准测试（MentalBench-100k和MentalAlign-70k）和一个评估框架，用于可靠地评估大型语言模型在心理健康支持中的表现，并分析了LLM评判者与人类专家在认知和情感属性上的差异。


<details>
  <summary>Details</summary>
Motivation: 评估用于心理健康支持的LLM具有挑战性，因为治疗性对话的情感和认知复杂性。现有基准规模有限、可靠性不足，常依赖合成数据或社交媒体数据，并且缺乏评估自动化评判者可信度的框架。

Method: 引入了两个基准：MentalBench-100k整合了10,000个真实场景的单轮对话，每个对话配有9个LLM生成的回复，共100,000个回复对。MentalAlign-70k通过比较4个高性能LLM评判者与人类专家在70,000个评分上的表现来重构评估，这些评分涉及7个属性，归类为认知支持分数（CSS）和情感共鸣分数（ARS）。然后，采用情感认知一致性框架（Affective Cognitive Agreement Framework），这是一种使用组内相关系数（ICC）和置信区间的统计方法，量化LLM评判者与人类专家之间的一致性、连贯性和偏差。

Result: 分析显示LLM评判者存在系统性评分虚高，对指导性和信息性等认知属性表现出强大的可靠性，对同理心的评估精度降低，而在安全性和相关性方面则存在一些不可靠性。

Conclusion: 本研究为心理健康领域LLM的可靠、大规模评估建立了新的方法论和实证基础。

Abstract: Evaluating Large Language Models (LLMs) for mental health support is
challenging due to the emotionally and cognitively complex nature of
therapeutic dialogue. Existing benchmarks are limited in scale, reliability,
often relying on synthetic or social media data, and lack frameworks to assess
when automated judges can be trusted. To address the need for large-scale
dialogue datasets and judge reliability assessment, we introduce two benchmarks
that provide a framework for generation and evaluation. MentalBench-100k
consolidates 10,000 one-turn conversations from three real scenarios datasets,
each paired with nine LLM-generated responses, yielding 100,000 response pairs.
MentalAlign-70k}reframes evaluation by comparing four high-performing LLM
judges with human experts across 70,000 ratings on seven attributes, grouped
into Cognitive Support Score (CSS) and Affective Resonance Score (ARS). We then
employ the Affective Cognitive Agreement Framework, a statistical methodology
using intraclass correlation coefficients (ICC) with confidence intervals to
quantify agreement, consistency, and bias between LLM judges and human experts.
Our analysis reveals systematic inflation by LLM judges, strong reliability for
cognitive attributes such as guidance and informativeness, reduced precision
for empathy, and some unreliability in safety and relevance. Our contributions
establish new methodological and empirical foundations for reliable,
large-scale evaluation of LLMs in mental health. We release the benchmarks and
codes at: https://github.com/abeerbadawi/MentalBench/

</details>


### [116] [That's Deprecated! Understanding, Detecting, and Steering Knowledge Conflicts in Language Models for Code Generation](https://arxiv.org/abs/2510.19116)
*Jaesung Bae,Cameron Churchwell,Mitchell Hermon,Tsun-An Hsieh,Jocelyn Xu,Yekaterina Yegorova,Mark Hasegawa-Johnson,Heng Ji*

Main category: cs.CL

TL;DR: 本文研究大型语言模型（LLMs）在参数知识与提示信息冲突时的行为，特别是针对代码生成领域。研究提出了一种检测和通过激活层引导解决冲突的方法，并取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究已探讨LLMs在问答任务中处理知识冲突的情况，但缺乏对代码生成领域中知识冲突行为的深入研究。本文旨在填补这一空白，探究LLMs在参数知识与提示中冲突信息并存时如何表现。

Method: 研究提出了一种领域无关的框架，用于构建和解释知识冲突，并设计了一种新颖的评估方法和数据集，专门针对代码冲突场景。实验中，通过激活层引导（activation-level steering）来干预模型行为。

Result: 实验表明，足够大的LLMs在其参数中编码了知识冲突的概念，能够以高达80.65%的准确率检测到知识冲突。在此基础上，激活层引导相比随机基线，可将引导成功率提高12.6%。然而，其有效性关键取决于模型大小、任务领域和引导方向之间的平衡。

Conclusion: 大型语言模型能够感知并编码知识冲突。通过激活层引导可以有效干预模型处理冲突知识的行为，但要实现最佳效果，需要综合考虑模型规模、任务特性和引导策略。

Abstract: This paper investigates how large language models (LLMs) behave when faced
with discrepancies between their parametric knowledge and conflicting
information contained in a prompt. Building on prior question-answering (QA)
research, we extend the investigation of knowledge conflicts to the realm of
code generation. We propose a domain-agnostic framework for constructing and
interpreting such conflicts, along with a novel evaluation method and dataset
tailored to code conflict scenarios. Our experiments indicate that sufficiently
large LLMs encode the notion of a knowledge conflict in their parameters,
enabling us to detect knowledge conflicts with up to \textbf{80.65\%} accuracy.
Building on these insights, we show that activation-level steering can achieve
up to a \textbf{12.6\%} improvement in steering success over a random baseline.
However, effectiveness depends critically on balancing model size, task domain,
and steering direction. The experiment code and data will be made publicly
available after acceptance.

</details>


### [117] [From Memorization to Generalization: Fine-Tuning Large Language Models for Biomedical Term-to-Identifier Normalization](https://arxiv.org/abs/2510.19036)
*Suswitha Pericharla,Daniel B. Hier,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）在生物医学术语标准化任务中，其微调效果因术语体系而异。成功与否取决于标识符的流行度（影响记忆能力）和词汇化程度（影响泛化能力）。非词汇化标识符限制模型进行死记硬背。


<details>
  <summary>Details</summary>
Motivation: 有效的生物医学数据整合依赖于自动化术语标准化，即将自然语言术语映射到标准化标识符，这对于实现语义互操作性至关重要。大型语言模型在此任务中展现潜力，但在不同术语体系上的表现不均衡，研究旨在探究其原因。

Method: 研究评估了Llama 3.1 8B模型在多个生物医学本体（如GO、HPO）上的记忆能力（训练集表现）和泛化能力（验证集表现）。同时，将结果与GPT-4o进行了比较，并进行了嵌入分析以探究语义对齐情况。

Result: Llama 3.1 8B的微调效果因术语体系而异：GO映射在记忆能力上表现显著提升（准确率提高达77%），而HPO提升甚微。泛化能力仅在蛋白质-基因（GENE）映射中出现（提高13.9%），HPO和GO的泛化效果可忽略不计。基线准确率方面，GPT-4o优于所有术语体系中的Llama变体。嵌入分析显示，基因符号与蛋白质名称之间语义对齐紧密，而GO或HPO的术语与标识符之间对齐较弱。微调成功取决于标识符的流行度（增强记忆）和词汇化程度（实现语义泛化）。

Conclusion: 研究结果提供了一个预测框架，解释了微调何时能增强事实召回，以及何时因标识符的稀疏性或非词汇化特性而失败。流行标识符通过预训练增强记忆，词汇化标识符（如基因符号）促进语义泛化，而任意标识符则限制模型进行死记硬背。

Abstract: Effective biomedical data integration depends on automated term
normalization, the mapping of natural language biomedical terms to standardized
identifiers. This linking of terms to identifiers is essential for semantic
interoperability. Large language models (LLMs) show promise for this task but
perform unevenly across terminologies. We evaluated both memorization
(training-term performance) and generalization (validation-term performance)
across multiple biomedical ontologies. Fine-tuning Llama 3.1 8B revealed marked
differences by terminology. GO mappings showed strong memorization gains (up to
77% improvement in term-to-identifier accuracy), whereas HPO showed minimal
improvement. Generalization occurred only for protein-gene (GENE) mappings
(13.9% gain), while fine-tuning for HPO and GO yielded negligible transfer.
Baseline accuracy varied by model scale, with GPT-4o outperforming both Llama
variants for all terminologies. Embedding analyses showed tight semantic
alignment between gene symbols and protein names but weak alignment between
terms and identifiers for GO or HPO, consistent with limited lexicalization.
Fine-tuning success depended on two interacting factors: identifier popularity
and lexicalization. Popular identifiers were more likely encountered during
pretraining, enhancing memorization. Lexicalized identifiers, such as gene
symbols, enabled semantic generalization. By contrast, arbitrary identifiers in
GO and HPO constrained models to rote learning. These findings provide a
predictive framework for when fine-tuning enhances factual recall versus when
it fails due to sparse or non-lexicalized identifiers.

</details>


### [118] [A Graph Signal Processing Framework for Hallucination Detection in Large Language Models](https://arxiv.org/abs/2510.19117)
*Valentin Noël*

Main category: cs.CL

TL;DR: 该研究提出了一种基于频谱分析的框架，通过将Transformer层建模为动态图，并分析令牌嵌入的图信号，以区分大语言模型中的事实推理和幻觉，并实现了高准确度的幻觉检测。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然表现出色，但区分事实推理和幻觉仍然是一个重大挑战。

Method: 该研究将Transformer层建模为由注意力机制诱导的动态图，并将令牌嵌入视为这些图上的信号。通过图信号处理，定义了包括狄利克雷能量、频谱熵和高频能量比在内的诊断指标，并建立了其与计算稳定性的理论联系。

Result: 实验发现，事实陈述表现出一致的“能量山”行为和低频收敛，而不同类型的幻觉则显示出独特的频谱特征：逻辑矛盾使频谱不稳定（效应量g>1.0），语义错误保持稳定但显示连接漂移，替换幻觉则表现出中间扰动。一个基于频谱特征的简单检测器达到了88.75%的准确率，优于基于困惑度基线的75%。

Conclusion: 这些发现表明频谱几何可能捕捉到推理模式和错误行为，为大语言模型中的幻觉检测提供了一个潜在的框架。

Abstract: Large language models achieve impressive results but distinguishing factual
reasoning from hallucinations remains challenging. We propose a spectral
analysis framework that models transformer layers as dynamic graphs induced by
attention, with token embeddings as signals on these graphs. Through graph
signal processing, we define diagnostics including Dirichlet energy, spectral
entropy, and high-frequency energy ratios, with theoretical connections to
computational stability. Experiments across GPT architectures suggest universal
spectral patterns: factual statements exhibit consistent "energy mountain"
behavior with low-frequency convergence, while different hallucination types
show distinct signatures. Logical contradictions destabilize spectra with large
effect sizes ($g>1.0$), semantic errors remain stable but show connectivity
drift, and substitution hallucinations display intermediate perturbations. A
simple detector using spectral signatures achieves 88.75% accuracy versus 75%
for perplexity-based baselines, demonstrating practical utility. These findings
indicate that spectral geometry may capture reasoning patterns and error
behaviors, potentially offering a framework for hallucination detection in
large language models.

</details>


### [119] [Training-Free Spectral Fingerprints of Voice Processing in Transformers](https://arxiv.org/abs/2510.19131)
*Valentin Noël*

Main category: cs.CL

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Different transformer architectures implement identical linguistic
computations via distinct connectivity patterns, yielding model imprinted
``computational fingerprints'' detectable through spectral analysis. Using
graph signal processing on attention induced token graphs, we track changes in
algebraic connectivity (Fiedler value, $\Delta\lambda_2$) under voice
alternation across 20 languages and three model families, with a prespecified
early window (layers 2--5). Our analysis uncovers clear architectural
signatures: Phi-3-Mini shows a dramatic English specific early layer disruption
($\overline{\Delta\lambda_2}_{[2,5]}\!\approx\!-0.446$) while effects in 19
other languages are minimal, consistent with public documentation that
positions the model primarily for English use. Qwen2.5-7B displays small,
distributed shifts that are largest for morphologically rich languages, and
LLaMA-3.2-1B exhibits systematic but muted responses. These spectral signatures
correlate strongly with behavioral differences (Phi-3: $r=-0.976$) and are
modulated by targeted attention head ablations, linking the effect to early
attention structure and confirming functional relevance. Taken together, the
findings are consistent with the view that training emphasis can leave
detectable computational imprints: specialized processing strategies that
manifest as measurable connectivity patterns during syntactic transformations.
Beyond voice alternation, the framework differentiates reasoning modes,
indicating utility as a simple, training free diagnostic for revealing
architectural biases and supporting model reliability analysis.

</details>


### [120] [Tibetan Language and AI: A Comprehensive Survey of Resources, Methods and Challenges](https://arxiv.org/abs/2510.19144)
*Cheng Huang,Nyima Tashi,Fan Gao,Yutong Liu,Jiahao Li,Hao Tian,Siyang Jiang,Thupten Tsering,Ban Ma-bao,Renzeg Duojie,Gadeng Luosang,Rinchen Dongrub,Dorje Tashi,Jin Zhang,Xiao Feng,Hao Wang,Jie Tang,Guojie Tang,Xiangxiang Wang,Jia Zhang,Tsengdar Lee,Yongbin Yu*

Main category: cs.CL

TL;DR: 本文对藏语AI的现状进行了全面调查，涵盖数据资源、NLP任务、机器翻译、语音识别和LLM，并指出了现有挑战和未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 藏语作为亚洲主要的低资源语言之一，具有独特的语言和社会文化特征，但由于数据资源、标准化基准和专用工具的缺乏，在AI领域受到的关注有限。

Method: 本文通过系统地分类现有数据集和工具，评估不同任务中使用的方法，并在可能的情况下比较性能，对藏语AI的当前状态进行了全面的调查。

Result: 调查结果识别了数据稀疏性、拼写变异和缺乏统一评估指标等持续存在的瓶颈，并讨论了跨语言迁移、多模态学习和社区驱动资源创建的潜力。

Conclusion: 本调查旨在为藏语AI研究的未来工作提供基础参考，并鼓励协作努力，为低资源语言构建一个包容和可持续的AI生态系统。

Abstract: Tibetan, one of the major low-resource languages in Asia, presents unique
linguistic and sociocultural characteristics that pose both challenges and
opportunities for AI research. Despite increasing interest in developing AI
systems for underrepresented languages, Tibetan has received limited attention
due to a lack of accessible data resources, standardized benchmarks, and
dedicated tools. This paper provides a comprehensive survey of the current
state of Tibetan AI in the AI domain, covering textual and speech data
resources, NLP tasks, machine translation, speech recognition, and recent
developments in LLMs. We systematically categorize existing datasets and tools,
evaluate methods used across different tasks, and compare performance where
possible. We also identify persistent bottlenecks such as data sparsity,
orthographic variation, and the lack of unified evaluation metrics.
Additionally, we discuss the potential of cross-lingual transfer, multi-modal
learning, and community-driven resource creation. This survey aims to serve as
a foundational reference for future work on Tibetan AI research and encourages
collaborative efforts to build an inclusive and sustainable AI ecosystem for
low-resource languages.

</details>


### [121] ["You Are Rejected!": An Empirical Study of Large Language Models Taking Hiring Evaluations](https://arxiv.org/abs/2510.19167)
*Dingjie Fu,Dianxing Shi*

Main category: cs.CL

TL;DR: 研究发现，尽管大型语言模型（LLMs）在编码和推理任务中表现出色，但它们未能通过针对软件和算法工程师的专业招聘评估。


<details>
  <summary>Details</summary>
Motivation: 科技公司对软件和算法工程师有巨大需求，并采用多阶段选拔流程，其中包括标准化招聘评估。鉴于LLMs在编码和推理任务中展现出的能力，研究旨在探讨LLMs能否成功通过这些招聘评估。

Method: 研究选取了广泛使用的专业评估问卷，并使用最先进的LLMs生成答案。随后，将LLMs生成的答案与公司提供的参考解决方案进行对比评估。

Result: 分析显示，LLM生成的答案与公司参考解决方案之间存在显著不一致。经验结果表明，所有被评估的LLMs都未能通过招聘评估。

Conclusion: LLMs目前无法通过针对软件和算法工程师的专业招聘评估，这与之前对LLMs作为理想工程师的预期相反。

Abstract: With the proliferation of the internet and the rapid advancement of
Artificial Intelligence, leading technology companies face an urgent annual
demand for a considerable number of software and algorithm engineers. To
efficiently and effectively identify high-potential candidates from thousands
of applicants, these firms have established a multi-stage selection process,
which crucially includes a standardized hiring evaluation designed to assess
job-specific competencies. Motivated by the demonstrated prowess of Large
Language Models (LLMs) in coding and reasoning tasks, this paper investigates a
critical question: Can LLMs successfully pass these hiring evaluations? To this
end, we conduct a comprehensive examination of a widely used professional
assessment questionnaire. We employ state-of-the-art LLMs to generate responses
and subsequently evaluate their performance. Contrary to any prior expectation
of LLMs being ideal engineers, our analysis reveals a significant inconsistency
between the model-generated answers and the company-referenced solutions. Our
empirical findings lead to a striking conclusion: All evaluated LLMs fails to
pass the hiring evaluation.

</details>


### [122] [Think Straight, Stop Smart: Structured Reasoning for Efficient Multi-Hop RAG](https://arxiv.org/abs/2510.19171)
*Jihwan Bang,Juntae Lee,Seunghan Yang,Sungha Choi*

Main category: cs.CL

TL;DR: TSSS (Think Straight, Stop Smart) 是一种高效的多跳检索增强生成（RAG）框架，通过结构化推理和确定性终止机制，解决了现有迭代提示方法的效率低下问题，同时保持了最先进的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的多跳检索增强生成（RAG）迭代提示方法效率低下，因为它们在每一步都重新生成可预测的token序列，并依赖随机停止，导致过多的token使用和不稳定的终止。

Method: TSSS 引入了两种机制：(i) 基于模板的推理，用于缓存重复的前缀并将子查询锚定到主问题，以减少token生成成本并促进稳定推理；(ii) 基于检索器的终止器，当额外的子查询陷入重复时，它能确定性地停止推理。

Result: 在 HotpotQA、2WikiMultiHop 和 MuSiQue 数据集上，TSSS 在 RAG-CoT 方法中实现了最先进的准确性以及具有竞争力的效率，特别适用于设备端推理等效率受限的场景。

Conclusion: TSSS 通过结构化推理和终止控制的分离，显著提高了多跳 RAG 的推理速度和答案可靠性，证明了其在效率受限场景中的有效性。

Abstract: Multi-hop retrieval-augmented generation (RAG) is a promising strategy for
complex reasoning, yet existing iterative prompting approaches remain
inefficient. They often regenerate predictable token sequences at every step
and rely on stochastic stopping, leading to excessive token usage and unstable
termination. We propose TSSS (Think Straight, Stop Smart), a structured
multi-hop RAG framework designed for efficiency. TSSS introduces (i) a
template-based reasoning that caches recurring prefixes and anchors sub-queries
to the main question, reducing token generation cost while promoting stable
reasoning, and (ii) a retriever-based terminator, which deterministically halts
reasoning once additional sub-queries collapse into repetition. This separation
of structured reasoning and termination control enables both faster inference
and more reliable answers. On HotpotQA, 2WikiMultiHop, and MuSiQue, TSSS
achieves state-of-the-art accuracy and competitive efficiency among RAG-CoT
approaches, highlighting its effectiveness in efficiency-constrained scenarios
such as on-device inference.

</details>


### [123] [Interpretable Question Answering with Knowledge Graphs](https://arxiv.org/abs/2510.19181)
*Kartikeya Aneja,Manasvi Srivastava,Subhayan Das,Nagender Aneja*

Main category: cs.CL

TL;DR: 本文提出一个不依赖LLM-RAG的问答系统，它通过知识图谱检索和小型释义模型生成答案，并在CRAG基准上使用LLM作为评判者进行了评估。


<details>
  <summary>Details</summary>
Motivation: 研究动机是构建一个完全基于知识图谱检索的问答系统，而不依赖于大型语言模型（LLM）的检索增强生成（RAG）技术。

Method: 该系统分为两个主要阶段：首先，预处理文档以生成问答对；其次，将这些问答对转换为知识图谱，并使用嵌入和模糊技术进行基于图的检索。检索到的图谱信息经过查询、重新排序，并通过一个小型释义模型进行释义，以生成最终答案。

Result: 使用LLM作为评判者在CRAG基准上进行评估，结果显示使用LLAMA-3.2时准确率为71.9%，使用GPT-3.5-Turbo时准确率为54.4%。

Conclusion: 该研究表明，不依赖LLM-RAG的知识图谱检索问答系统是可行的，并且在特定基准上能够达到可观的准确率。

Abstract: This paper presents a question answering system that operates exclusively on
a knowledge graph retrieval without relying on retrieval augmented generation
(RAG) with large language models (LLMs). Instead, a small paraphraser model is
used to paraphrase the entity relationship edges retrieved from querying the
knowledge graph. The proposed pipeline is divided into two main stages. The
first stage involves pre-processing a document to generate sets of
question-answer (QA) pairs. The second stage converts these QAs into a
knowledge graph from which graph-based retrieval is performed using embeddings
and fuzzy techniques. The graph is queried, re-ranked, and paraphrased to
generate a final answer. This work includes an evaluation using LLM-as-a-judge
on the CRAG benchmark, which resulted in accuracies of 71.9% and 54.4% using
LLAMA-3.2 and GPT-3.5-Turbo, respectively.

</details>


### [124] [When Facts Change: Probing LLMs on Evolving Knowledge with evolveQA](https://arxiv.org/abs/2510.19172)
*Nishanth Sridhar Nakshatri,Shamik Roy,Manoj Ghuhan Arivazhagan,Hanhan Zhou,Vinayshekhar Bannihatti Kumar,Rashmi Gangadharaiah*

Main category: cs.CL

TL;DR: LLMs在处理时间演变知识时表现不佳，现有基准有局限。本文引入evolveQA，一个基于真实世界时间戳数据的基准，用于评估LLMs处理时间冲突知识的能力，发现LLMs性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）难以处理时间性知识冲突（即训练数据中事实随时间演变）。现有评估基准（如基于Wikidata）存在局限：它们侧重于广泛覆盖、易于记忆的流行实体，并且缺乏评估不同知识截止日期LLMs所需的动态结构。

Method: 本文引入了evolveQA，一个专门设计用于评估LLMs处理时间演变知识的基准。该基准从3个真实世界、带时间戳的语料库构建：AWS更新、Azure变更和WHO疾病爆发报告。其框架能够识别自然发生的知识演变，并生成针对不同LLM知识截止日期定制的黄金答案问题。研究对12个开源和闭源LLM进行了3种知识探测格式的广泛评估。

Result: 通过对evolveQA的评估，研究发现LLMs在处理时间演变知识问题时，性能相比处理静态知识问题显著下降，降幅高达31%。

Conclusion: evolveQA基准有效揭示了LLMs在处理时间演变知识方面的显著不足，表明当前LLMs在处理随时间变化的现实世界信息时仍面临挑战。

Abstract: LLMs often fail to handle temporal knowledge conflicts--contradictions
arising when facts evolve over time within their training data. Existing
studies evaluate this phenomenon through benchmarks built on structured
knowledge bases like Wikidata, but they focus on widely-covered,
easily-memorized popular entities and lack the dynamic structure needed to
fairly evaluate LLMs with different knowledge cut-off dates. We introduce
evolveQA, a benchmark specifically designed to evaluate LLMs on temporally
evolving knowledge, constructed from 3 real-world, time-stamped corpora: AWS
updates, Azure changes, and WHO disease outbreak reports. Our framework
identifies naturally occurring knowledge evolution and generates questions with
gold answers tailored to different LLM knowledge cut-off dates. Through
extensive evaluation of 12 open and closed-source LLMs across 3 knowledge
probing formats, we demonstrate significant performance drops of up to 31% on
evolveQA compared to static knowledge questions.

</details>


### [125] [Multi-Faceted Evaluation of Tool-Augmented Dialogue Systems](https://arxiv.org/abs/2510.19186)
*Zhaoyi Joey Hou,Tanya Shourya,Yingfan Wang,Shamik Roy,Vinayshekhar Bannihatti Kumar,Rashmi Gangadharaiah*

Main category: cs.CL

TL;DR: 该论文提出了TRACE基准和SCOPE评估框架，旨在解决现有方法在评估使用外部工具的对话式AI系统时，无法捕捉多轮对话中关键错误的问题，尤其在用户满意度信号具有误导性时。


<details>
  <summary>Details</summary>
Motivation: 评估使用外部工具的对话式AI系统具有挑战性，因为错误可能源于用户、代理和工具之间复杂的交互。现有评估方法（如用户满意度或代理的工具调用能力）未能捕捉多轮工具增强对话中的关键错误，例如代理误解工具结果但用户仍感到满意的情况。

Method: 引入了TRACE，一个系统合成的工具增强对话基准，涵盖了多种错误案例。同时引入了SCOPE，一个评估框架，能够自动发现工具增强对话中的不同错误模式和评估标准。

Result: 实验表明，SCOPE显著优于基线方法，尤其在用户满意度信号具有误导性的挑战性案例中表现更为出色。

Conclusion: TRACE和SCOPE为评估使用外部工具的对话式AI系统提供了一种更有效、更全面的方法，能够发现现有方法难以捕捉的关键错误，尤其是在复杂和误导性的评估场景下。

Abstract: Evaluating conversational AI systems that use external tools is challenging,
as errors can arise from complex interactions among user, agent, and tools.
While existing evaluation methods assess either user satisfaction or agents'
tool-calling capabilities, they fail to capture critical errors in multi-turn
tool-augmented dialogues-such as when agents misinterpret tool results yet
appear satisfactory to users. We introduce TRACE, a benchmark of systematically
synthesized tool-augmented conversations covering diverse error cases, and
SCOPE, an evaluation framework that automatically discovers diverse error
patterns and evaluation rubrics in tool-augmented dialogues. Experiments show
SCOPE significantly outperforms the baseline, particularly on challenging cases
where user satisfaction signals are misleading.

</details>


### [126] [DiSRouter: Distributed Self-Routing for LLM Selections](https://arxiv.org/abs/2510.19208)
*Hang Zheng,Hongshen Xu,Yongkai Lin,Shuai Fan,Lu Chen,Kai Yu*

Main category: cs.CL

TL;DR: DiSRouter提出了一种分布式自路由范式，通过增强每个大型语言模型（LLM）的自我意识，使其能够自主决定回答或路由查询，从而在性能、成本、灵活性和可扩展性上优于集中式路由系统。


<details>
  <summary>Details</summary>
Motivation: 现有LLM查询路由系统依赖于集中式外部路由器，由于其无法完全理解不同LLM的知识边界，导致系统不灵活且性能不佳，难以平衡性能与成本。

Method: 引入DiSRouter（分布式自路由器），将路由控制从集中式转移到分布式。每个LLM代理根据其自身的自我意识（判断其能力）独立决定是回答查询还是将其路由到其他代理。为实现此目的，论文提出了一种两阶段的“自我意识训练”流程来增强每个LLM的自我意识。

Result: DiSRouter在各种场景下显著优于现有路由方法，能有效区分简单和困难查询，并对域外任务表现出强大的泛化能力。

Conclusion: 利用LLM固有的自我意识比外部评估更有效，这为构建更模块化、更高效的多代理系统铺平了道路。

Abstract: The proliferation of Large Language Models (LLMs) has created a diverse
ecosystem of models with highly varying performance and costs, necessitating
effective query routing to balance performance and expense. Current routing
systems often rely on a centralized external router trained on a fixed set of
LLMs, making them inflexible and prone to poor performance since the small
router can not fully understand the knowledge boundaries of different LLMs. We
introduce DiSRouter (Distributed Self-Router), a novel paradigm that shifts
from centralized control to distributed routing. In DiSRouter, a query
traverses a network of LLM agents, each independently deciding whether to
answer or route to other agents based on its own self-awareness, its ability to
judge its competence. This distributed design offers superior flexibility,
scalability, and generalizability. To enable this, we propose a two-stage
Self-Awareness Training pipeline that enhances each LLM's self-awareness.
Extensive experiments demonstrate that DiSRouter significantly outperforms
existing routing methods in utility across various scenarios, effectively
distinguishes between easy and hard queries, and shows strong generalization to
out-of-domain tasks. Our work validates that leveraging an LLM's intrinsic
self-awareness is more effective than external assessment, paving the way for
more modular and efficient multi-agent systems.

</details>


### [127] [Balancing Rewards in Text Summarization: Multi-Objective Reinforcement Learning via HyperVolume Optimization](https://arxiv.org/abs/2510.19325)
*Junjie Song,Yiwen Liu,Dapeng Li,Yin Sun,Shukun Fu,Siqi Chen,Yuji Cao*

Main category: cs.CL

TL;DR: 本文提出了一种名为超体积优化（HVO）的新型强化学习（RL）策略，用于解决大型语言模型（LLM）文本摘要中的多目标优化问题。HVO通过动态调整奖励分数来逼近帕累托前沿，从而生成在多个目标上平衡的摘要。实验表明，HVO优于现有方法，并使7B模型在摘要任务上达到与GPT-4相当的性能。


<details>
  <summary>Details</summary>
Motivation: 文本摘要需要同时优化一致性、连贯性、相关性和流畅性等多个目标，这带来了巨大挑战。尽管LLM结合RL表现出色，但很少有研究关注如何通过基于LLM的RL来优化摘要的多目标问题。

Method: 本文引入了超体积优化（HVO），这是一种新颖的优化策略。HVO在RL的奖励过程中，利用超体积方法动态调整组间的得分。这种方法引导模型的优化逐步逼近帕累托前沿，从而在多个目标上生成平衡的摘要。

Result: 在多个代表性摘要数据集上的实验结果表明，HVO在总体得分上优于组相对策略优化（GRPO），并在不同维度上表现出更平衡的性能。此外，一个由HVO增强的7B基础模型在摘要任务中表现出与GPT-4相当的性能，同时保持了更短的生成长度。

Conclusion: HVO是一种有效的RL优化策略，能够解决LLM文本摘要中的多目标问题。它通过逼近帕累托前沿生成平衡且高质量的摘要，并能使较小的模型达到与先进大型模型相当的性能。

Abstract: Text summarization is a crucial task that requires the simultaneous
optimization of multiple objectives, including consistency, coherence,
relevance, and fluency, which presents considerable challenges. Although large
language models (LLMs) have demonstrated remarkable performance, enhanced by
reinforcement learning (RL), few studies have focused on optimizing the
multi-objective problem of summarization through RL based on LLMs. In this
paper, we introduce hypervolume optimization (HVO), a novel optimization
strategy that dynamically adjusts the scores between groups during the reward
process in RL by using the hypervolume method. This method guides the model's
optimization to progressively approximate the pareto front, thereby generating
balanced summaries across multiple objectives. Experimental results on several
representative summarization datasets demonstrate that our method outperforms
group relative policy optimization (GRPO) in overall scores and shows more
balanced performance across different dimensions. Moreover, a 7B foundation
model enhanced by HVO performs comparably to GPT-4 in the summarization task,
while maintaining a shorter generation length. Our code is publicly available
at https://github.com/ai4business-LiAuto/HVO.git

</details>


### [128] [SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets](https://arxiv.org/abs/2510.19247)
*Ziwei Wang,Jiayuan Su,Mengyu Zhou,Huaxing Zeng,Mengni Jia,Xiao Lv,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: SheetBrain是一个神经符号双流程代理框架，旨在提高大型语言模型在复杂电子表格数据上进行问答和操作任务的推理准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在准确捕获表格复杂结构和确保推理正确性方面存在困难，这促使了对更有效电子表格推理方法的需求。

Method: SheetBrain包含三个核心模块：1) 理解模块，提供电子表格概述和基于查询的问题洞察；2) 执行模块，集成Python沙盒和Excel辅助工具包以进行多轮推理；3) 验证模块，验证推理和答案的正确性，并在必要时触发重新执行。该框架在多个现有表格问答和操作基准以及一个新的复杂多表格基准SheetBench上进行了评估。

Result: 实验结果表明，SheetBrain在现有基准测试和SheetBench中提出的更具挑战性的场景下，都显著提高了准确性。

Conclusion: SheetBrain通过其神经符号双流程代理框架，有效解决了LLM在复杂电子表格推理中的挑战，显著提升了问答和操作任务的准确性。

Abstract: Understanding and reasoning over complex spreadsheets remain fundamental
challenges for large language models (LLMs), which often struggle with
accurately capturing the complex structure of tables and ensuring reasoning
correctness. In this work, we propose SheetBrain, a neuro-symbolic dual
workflow agent framework designed for accurate reasoning over tabular data,
supporting both spreadsheet question answering and manipulation tasks.
SheetBrain comprises three core modules: an understanding module, which
produces a comprehensive overview of the spreadsheet - including sheet summary
and query-based problem insight to guide reasoning; an execution module, which
integrates a Python sandbox with preloaded table-processing libraries and an
Excel helper toolkit for effective multi-turn reasoning; and a validation
module, which verifies the correctness of reasoning and answers, triggering
re-execution when necessary. We evaluate SheetBrain on multiple public tabular
QA and manipulation benchmarks, and introduce SheetBench, a new benchmark
targeting large, multi-table, and structurally complex spreadsheets.
Experimental results show that SheetBrain significantly improves accuracy on
both existing benchmarks and the more challenging scenarios presented in
SheetBench. Our code is publicly available at
https://github.com/microsoft/SheetBrain.

</details>


### [129] [Modality Matching Matters: Calibrating Language Distances for Cross-Lingual Transfer in URIEL+](https://arxiv.org/abs/2510.19217)
*York Hay Ng,Aditya Khan,Xiang Lu,Matteo Salloum,Michael Zhou,Phuong H. Hoang,A. Seza Doğruöz,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 本文提出了一种针对现有语言知识库局限性的新型框架，通过为不同类型的语言距离（地理、谱系、类型学）设计结构感知型表示，并将其整合为统一的复合距离，显著提升了跨语言NLP任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语言知识库（如URIEL+）在跨语言迁移中提供了有价值的距离信息，但存在两个主要限制：一是其“一刀切”的向量表示不适用于多样化的语言数据结构；二是缺乏将这些信号整合为单一、全面得分的原则性方法。

Method: 本文引入了一个类型匹配的语言距离框架，提出了新颖的结构感知型表示方法：地理距离采用说话者加权分布，谱系距离采用双曲嵌入，类型学距离采用潜在变量模型。随后，将这些信号统一整合为一个鲁棒的、任务无关的复合距离。

Result: 在选择迁移语言时，本文提出的表示方法和复合距离在广泛的NLP任务中持续提高了性能。

Conclusion: 该框架为多语言研究提供了一个更具原则性且更有效的工具包，解决了现有语言距离表示和聚合方法的不足。

Abstract: Existing linguistic knowledge bases such as URIEL+ provide valuable
geographic, genetic and typological distances for cross-lingual transfer but
suffer from two key limitations. One, their one-size-fits-all vector
representations are ill-suited to the diverse structures of linguistic data,
and two, they lack a principled method for aggregating these signals into a
single, comprehensive score. In this paper, we address these gaps by
introducing a framework for type-matched language distances. We propose novel,
structure-aware representations for each distance type: speaker-weighted
distributions for geography, hyperbolic embeddings for genealogy, and a latent
variables model for typology. We unify these signals into a robust,
task-agnostic composite distance. In selecting transfer languages, our
representations and composite distances consistently improve performance across
a wide range of NLP tasks, providing a more principled and effective toolkit
for multilingual research.

</details>


### [130] [AgenticMath: Enhancing LLM Reasoning via Agentic-based Math Data Generation](https://arxiv.org/abs/2510.19361)
*Xianyang Liu,Yilin Liu,Shuai Wang,Hao Cheng,Andrew Estornell,Yuzhi Zhao,Jiaheng Wei*

Main category: cs.CL

TL;DR: AgenticMath提出了一种新颖的智能体管道，用于生成高质量数学问答对，通过监督微调显著提升大型语言模型（LLM）的数学推理能力，且所需数据量远少于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前用于提升LLM推理能力的训练数据集生成方法存在两大挑战：生成的答案质量低劣/不正确，以及现有数据源的信息丰富度有限。

Method: AgenticMath方法包含四个阶段：1) 种子问题筛选，选择信息丰富、复杂且清晰的问题；2) 智能体问题改写，利用多智能体系统生成多样化、逻辑一致的改写问题；3) 答案增强，通过思维链推理重写答案，提高数值和逻辑正确性，且不依赖人工标注；4) 最终问答评估，仅保留最优质的问答对。

Result: 实验表明，使用AgenticMath生成的数据集（仅30-60K数学样本）对3B-8B参数的LLM进行微调，在各种域内和域外数学推理基准测试中，其性能与使用更多数据（例如400K或2.3M样本）训练的基线模型相比，具有竞争力甚至更优越。

Conclusion: 研究证明，与大规模、低质量的数据替代方案相比，有针对性的高质量数据生成是提高LLM数学推理能力更有效率的途径。

Abstract: The creation of high-quality datasets to improve Large Language Model (LLM)
reasoning remains a significant challenge, as current methods often suffer from
generating low-quality/incorrect answers and limited information richness from
available data sources. To address this, we propose AgenticMath, a novel
agentic pipeline for generating high-quality mathematical question-answer pairs
to enhance the supervised fine-tuning of LLMs. Our method operates through four
stages: (1) Seed Question Filter that selects questions with high information
richness, complexity, and clarity; (2) an Agentic Question Rephrase step that
employs a multi-agent system to generate diverse, logically consistent
paraphrases; (3) an Answer Augment step where rewrite answers using
chain-of-thought reasoning to enhance numerical and logical correctness,
without reliance on human-provided labels; and (4) a final Question and Answer
Evaluation that retains only the most superior pairs. Extensive experiments
demonstrate that, fine-tuning 3B-8B parameter LLMs on AgenticMath generated
datasets (comprising only 30-60K math samples) achieves competitive or superior
performance on diverse in domain and out-of-domain mathematical reasoning
benchmarks compared to baselines trained on much more data (e.g., 400K or 2.3M
samples). Our work demonstrates that targeted, high-quality data generation is
a more efficient path to improving mathematical reasoning in LLMs than
large-scale, low-quality alternatives.

</details>


### [131] [M3-SLU: Evaluating Speaker-Attributed Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2510.19358)
*Yejin Kwon,Taewoo Kang,Hyunsoo Yoon,Changouk Kim*

Main category: cs.CL

TL;DR: M3-SLU是一个新的多模态大语言模型（MLLM）基准，用于评估多说话人、多轮对话中的语音语言理解，特别侧重于说话人归因推理。


<details>
  <summary>Details</summary>
Motivation: 尽管最近的模型在语音和文本理解方面表现出色，但它们在“说话人归因推理”（即理解在自然对话中谁在何时说了什么）方面仍然存在不足。

Method: 该研究构建了M3-SLU基准，整合了四个开放语料库（CHiME-6, MELD, MultiDialog, AMI），包含超过12,000个配有音频、转录文本和元数据的实例。基准包括两个任务：说话人归因问答和通过话语匹配进行说话人归因。研究使用LLM作为评估者和准确率指标，对级联管道模型和端到端MLLM进行了基线评估。

Result: 基线结果表明，模型能够捕捉到对话的“内容”，但往往无法识别“说话人”，这揭示了说话人感知对话理解中的一个关键空白。

Conclusion: M3-SLU提供了一个具有挑战性的基准，旨在推动说话人感知多模态理解领域的研究进展。

Abstract: We present M3-SLU, a new multimodal large language model (MLLM) benchmark for
evaluating multi-speaker, multi-turn spoken language understanding. While
recent models show strong performance in speech and text comprehension, they
still struggle with speaker-attributed reasoning, the ability to understand who
said what and when in natural conversations. M3-SLU is built from four open
corpora (CHiME-6, MELD, MultiDialog, and AMI) and comprises over 12,000
validated instances with paired audio, transcripts, and metadata. It includes
two tasks: (1) Speaker-Attributed Question Answering and (2) Speaker
Attribution via Utterance Matching. We provide baseline results for both
cascaded pipelines and end-to-end MLLMs, evaluated using an LLM-as-Judge and
accuracy metrics. Results show that while models can capture what was said,
they often fail to identify who said it, revealing a key gap in speaker-aware
dialogue understanding. M3-SLU offers as a challenging benchmark to advance
research in speaker-aware multimodal understanding.

</details>


### [132] [The Massive Legal Embedding Benchmark (MLEB)](https://arxiv.org/abs/2510.19365)
*Umar Butler,Abdur-Rahman Butler,Adrian Lucas Malec*

Main category: cs.CL

TL;DR: 本文介绍了大规模法律嵌入基准（MLEB），这是迄今为止最大、最多样化、最全面的开源法律信息检索基准。


<details>
  <summary>Details</summary>
Motivation: 为了填补开源法律信息检索领域在领域和司法管辖区方面的空白，需要一个更全面、多样化的基准进行评估。

Method: 构建了MLEB，包含十个专家标注的数据集，涵盖多个司法管辖区（美国、英国、欧盟、澳大利亚、爱尔兰、新加坡）、文档类型（判例、立法、监管指南、合同、文献）和任务类型（搜索、零样本分类、问答）。其中七个数据集是新构建的。

Result: 发布了MLEB，一个包含十个专家标注数据集的基准，覆盖了广泛的司法管辖区、文档和任务类型。同时公开了构建方法、代码、结果和数据，以支持可复现的评估。

Conclusion: MLEB为法律信息检索领域提供了迄今为止最全面、多样化的开源基准，有助于推动该领域的可复现评估和研究。

Abstract: We present the Massive Legal Embedding Benchmark (MLEB), the largest, most
diverse, and most comprehensive open-source benchmark for legal information
retrieval to date. MLEB consists of ten expert-annotated datasets spanning
multiple jurisdictions (the US, UK, EU, Australia, Ireland, and Singapore),
document types (cases, legislation, regulatory guidance, contracts, and
literature), and task types (search, zero-shot classification, and question
answering). Seven of the datasets in MLEB were newly constructed in order to
fill domain and jurisdictional gaps in the open-source legal information
retrieval landscape. We document our methodology in building MLEB and creating
the new constituent datasets, and release our code, results, and data openly to
assist with reproducible evaluations.

</details>


### [133] [Difficulty-Controllable Multiple-Choice Question Generation Using Large Language Models and Direct Preference Optimization](https://arxiv.org/abs/2510.19265)
*Yuto Tomikawa,Masaki Uto*

Main category: cs.CL

TL;DR: 本研究提出了一种新颖的难度可控多项选择题生成方法，用于阅读理解，该方法利用大型语言模型并通过直接偏好优化技术训练，以提高难度控制的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有神经问题生成方法在难度控制方面存在两个主要局限性：一是无法直接生成教育场景中广泛使用的多项选择题；二是未明确训练以优化难度控制的准确性，有待改进。

Method: 本研究提出了一种利用大型语言模型（LLM）的方法，该LLM通过直接偏好优化（DPO）技术进行训练，旨在生成难度可控的多项选择题，并提高难度控制的准确性。

Result: 抽象中未提供具体实验结果，仅提出了一种方法。

Conclusion: 本研究旨在通过提出的方法，解决现有难度可控问题生成方法在多项选择题生成能力和难度控制准确性方面的局限性。

Abstract: Difficulty-controllable question generation for reading comprehension has
gained significant attention in the field of education as a fundamental tool
for adaptive learning support. Although several neural question generation
methods have recently succeeded in controlling difficulty, conventional
approaches still face two major limitations. First, they cannot directly
generate multiple-choice questions, which are the most widely used question
type in educational contexts. Second, they are not explicitly trained to
optimize the accuracy of difficulty control, leaving room for further
improvement in difficulty controllability. To address these limitations, this
study proposes a novel difficulty-controllable multiple-choice question
generation method for reading comprehension which leverages a large language
model trained using a direct preference optimization technique to improve the
accuracy of difficulty control.

</details>


### [134] [ToMMeR -- Efficient Entity Mention Detection from Large Language Models](https://arxiv.org/abs/2510.19410)
*Victor Morand,Nadi Tomeh,Josiane Mothe,Benjamin Piwowarski*

Main category: cs.CL

TL;DR: 本文提出了ToMMeR，一个轻量级模型（<300K参数），通过探测大型语言模型（LLM）的早期层来执行实体提及检测。它在13个NER基准测试中实现了93%的零样本召回率和90%以上的精确度，并且在扩展后达到了接近SOTA的命名实体识别（NER）性能，表明早期Transformer层中存在结构化的实体表示。


<details>
  <summary>Details</summary>
Motivation: 实体提及检测是信息抽取的基石，但同时也是一个已知的性能瓶颈。研究动机在于探索LLM的早期层是否已经包含了实体表示，以及如何高效地从中提取这些信息，以提高提及检测的效率和性能。

Method: 研究引入了ToMMeR模型，一个参数量小于300K的轻量级模型，用于探测LLM早期层的提及检测能力。通过使用LLM作为判别器来评估其精确度。此外，ToMMeR通过添加跨度分类头（span classification heads）被扩展，以实现命名实体识别（NER）任务。

Result: ToMMeR在13个NER基准测试中实现了93%的零样本召回率，并且在使用LLM作为判别器时达到了90%以上的精确度。跨模型分析显示，不同架构（14M-15B参数）的LLM在提及边界上表现出高度一致性（DICE >75%）。当扩展了跨度分类头后，ToMMeR在标准基准测试中实现了接近SOTA的NER性能（80-87% F1）。

Conclusion: 研究结果提供了证据，表明结构化的实体表示存在于Transformer的早期层中，并且可以以极少的参数被高效地恢复。这证实了提及检测能力是语言建模过程中自然涌现的特性。

Abstract: Identifying which text spans refer to entities -- mention detection -- is
both foundational for information extraction and a known performance
bottleneck. We introduce ToMMeR, a lightweight model (<300K parameters) probing
mention detection capabilities from early LLM layers. Across 13 NER benchmarks,
ToMMeR achieves 93\% recall zero-shot, with over 90\% precision using an LLM as
a judge showing that ToMMeR rarely produces spurious predictions despite high
recall. Cross-model analysis reveals that diverse architectures (14M-15B
parameters) converge on similar mention boundaries (DICE >75\%), confirming
that mention detection emerges naturally from language modeling. When extended
with span classification heads, ToMMeR achieves near SOTA NER performance
(80-87\% F1 on standard benchmarks). Our work provides evidence that structured
entity representations exist in early transformer layers and can be efficiently
recovered with minimal parameters.

</details>


### [135] [JointCQ: Improving Factual Hallucination Detection with Joint Claim and Query Generation](https://arxiv.org/abs/2510.19310)
*Fan Xu,Huixuan Zhang,Zhenliang Zhang,Jiahao Wang,Xiaojun Wan*

Main category: cs.CL

TL;DR: 本文提出了 JointCQ 框架，通过联合生成声明和查询来解决大型语言模型幻觉检测管道中声明提取和查询生成阶段的局限性，从而提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）存在幻觉问题，即生成看似事实但不可靠的内容。现有的幻觉检测方法在声明提取和查询生成阶段存在局限性，如上下文丢失和查询特异性低，导致整个检测管道的性能下降。

Method: 本文引入了 JointCQ 框架，这是一个联合声明与查询生成框架。它利用精心设计的评估标准来过滤合成训练数据，并微调一个语言模型以实现联合声明提取和查询生成，为下游的搜索和验证提供可靠且信息丰富的输入。

Result: 实验结果表明，该方法在多个开放域问答幻觉检测基准上优于现有方法。

Conclusion: JointCQ 方法通过改进幻觉检测，推动了更值得信赖和透明的语言模型系统的发展。

Abstract: Current large language models (LLMs) often suffer from hallucination issues,
i,e, generating content that appears factual but is actually unreliable. A
typical hallucination detection pipeline involves response decomposition (i.e.,
claim extraction), query generation, evidence collection (i.e., search or
retrieval), and claim verification. However, existing methods exhibit
limitations in the first two stages, such as context loss during claim
extraction and low specificity in query generation, resulting in degraded
performance across the hallucination detection pipeline. In this work, we
introduce JointCQ https://github.com/pku0xff/JointCQ, a joint claim-and-query
generation framework designed to construct an effective and efficient
claim-query generator. Our framework leverages elaborately designed evaluation
criteria to filter synthesized training data, and finetunes a language model
for joint claim extraction and query generation, providing reliable and
informative inputs for downstream search and verification. Experimental results
demonstrate that our method outperforms previous methods on multiple
open-domain QA hallucination detection benchmarks, advancing the goal of more
trustworthy and transparent language model systems.

</details>


### [136] [VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos](https://arxiv.org/abs/2510.19488)
*Dunjie Lu,Yiheng Xu,Junli Wang,Haoyuan Wu,Xinyuan Wang,Zekun Wang,Junlin Yang,Hongjin Su,Jixuan Chen,Junda Chen,Yuchen Mao,Jingren Zhou,Junyang Lin,Binyuan Hui,Tao Yu*

Main category: cs.CL

TL;DR: VideoAgentTrek是一个可扩展的流水线，能自动从网络视频中挖掘GUI交互数据，用于训练计算机使用代理，解决了手动标注成本高昂的问题，并显著提升了代理性能。


<details>
  <summary>Details</summary>
Motivation: 训练计算机使用代理需要大量的GUI交互数据，但手动标注动作轨迹的成本过高，无法大规模应用。

Method: 本文提出了VideoAgentTrek流水线，通过一个名为Video2Action的逆动力学模块（IDM）来解决原始视频缺乏显式动作标签的问题。Video2Action包含两个组件：(1) 一个视频接地模型，用于检测和定位具有精确时间边界和上下文的GUI动作；(2) 一个动作内容识别器，用于高保真地提取点击坐标、输入文本等结构化参数。该流水线应用于39,000个YouTube教程视频，自动生成了152万个交互步骤，并通过持续预训练和监督微调来利用这些数据。

Result: 在OSWorld-Verified基准测试中，该方法将任务成功率从9.3%（仅SFT基线）提高到15.8%，相对提升了70%。在AgentNetBench上，步骤准确率从64.1%提高到69.3%。

Conclusion: 研究结果表明，被动的互联网视频可以转化为高质量的监督数据，用于训练计算机使用代理，为昂贵的手动标注提供了一种可扩展的替代方案。

Abstract: Training computer-use agents requires massive amounts of GUI interaction
data, but manually annotating action trajectories at scale is prohibitively
expensive. We present VideoAgentTrek, a scalable pipeline that automatically
mines training data from publicly available screen-recorded videos at web
scale, eliminating the need for manual annotation. Our approach addresses a key
challenge: raw videos contain implicit demonstrations but lack explicit action
labels. To solve this, we develop Video2Action, an inverse dynamics module
(IDM) with two components: (1) a video grounding model that detects and
localizes GUI actions with precise temporal boundaries and context, and (2) an
action-content recognizer that extracts structured parameters like click
coordinates and typed text with high fidelity. Applied to 39,000 YouTube
tutorial videos, our pipeline generates 1.52 million interaction steps
automatically. We leverage this data through continued pretraining followed by
supervised fine-tuning. On OSWorld-Verified, our approach improves task success
rates from 9.3% (SFT-only baseline) to 15.8%, a 70% relative improvement. On
AgentNetBench, step accuracy increases from 64.1% to 69.3%. Our results
demonstrate that passive internet videos can be transformed into high-quality
supervision for computer-use agents, providing a scalable alternative to
expensive manual annotation.

</details>


### [137] [TheMCPCompany: Creating General-purpose Agents with Task-specific Tools](https://arxiv.org/abs/2510.19286)
*Reza Esfandiarpoor,Vishwas Suryanarayanan,Stephen H. Bach,Vishal Chowdhary,Anthony Aue*

Main category: cs.CL

TL;DR: 本文介绍了TheMCPCompany基准测试，用于评估LLM工具调用代理在与真实世界服务交互方面的表现。该基准包含超过18,000个工具，研究发现虽然工具调用潜力巨大，但当前模型在复杂企业环境中导航和组合大量工具时仍面临挑战，需要更好的推理和检索能力。


<details>
  <summary>Details</summary>
Motivation: 随着模型上下文协议（MCP）的引入，LLM的专用工具显著增加，它们比通用工具（如网页浏览器）更易开发和维护。然而，当前的通用代理主要依赖网页浏览器与环境交互。因此，需要一个基准来评估LLM在利用这些新工具进行复杂任务时的能力。

Method: 研究引入了TheMCPCompany基准测试，通过使用各种真实世界服务的REST API创建MCP服务器，共包含超过18,000个工具。每个任务都提供了手动标注的真值工具。实验首先使用真值工具展示了工具调用代理在性能提升和成本降低方面的潜力（假设完美工具检索），然后通过工具检索来评估代理的实际表现。

Result: 实验结果显示，在完美工具检索的假设下，工具调用代理在提升性能和降低成本方面潜力巨大。所有使用工具检索的模型表现与基于浏览器的代理相似或更好，但小型模型无法充分利用通过检索获得的工具。GPT-5在工具检索下的表现非常接近其使用真值工具时的表现。然而，最先进的推理模型在简单环境中发现工具有效，但在导航复杂的企业环境时则严重受挫。

Conclusion: TheMCPCompany基准测试表明，当前模型在导航数万个工具并以非平凡方式组合它们来解决复杂问题方面仍然是一项艰巨的任务。这要求模型具备更好的推理能力和更优的检索模型。

Abstract: Since the introduction of the Model Context Protocol (MCP), the number of
available tools for Large Language Models (LLMs) has increased significantly.
These task-specific tool sets offer an alternative to general-purpose tools
such as web browsers, while being easier to develop and maintain than GUIs.
However, current general-purpose agents predominantly rely on web browsers for
interacting with the environment. Here, we introduce TheMCPCompany, a benchmark
for evaluating tool-calling agents on tasks that involve interacting with
various real-world services. We use the REST APIs of these services to create
MCP servers, which include over 18,000 tools. We also provide manually
annotated ground-truth tools for each task. In our experiments, we use the
ground truth tools to show the potential of tool-calling agents for both
improving performance and reducing costs assuming perfect tool retrieval. Next,
we explore agent performance using tool retrieval to study the real-world
practicality of tool-based agents. While all models with tool retrieval perform
similarly or better than browser-based agents, smaller models cannot take full
advantage of the available tools through retrieval. On the other hand, GPT-5's
performance with tool retrieval is very close to its performance with
ground-truth tools. Overall, our work shows that the most advanced reasoning
models are effective at discovering tools in simpler environments, but
seriously struggle with navigating complex enterprise environments.
TheMCPCompany reveals that navigating tens of thousands of tools and combining
them in non-trivial ways to solve complex problems is still a challenging task
for current models and requires both better reasoning and better retrieval
models.

</details>


### [138] [KORE: Enhancing Knowledge Injection for Large Multimodal Models via Knowledge-Oriented Augmentations and Constraints](https://arxiv.org/abs/2510.19316)
*Kailin Jiang,Hongbo Jiang,Ning Jiang,Zhi Gao,Jinhe Bi,Yuchen Ren,Bin Li,Yuntao Du,Lei Liu,Qing Li*

Main category: cs.CL

TL;DR: KORE是一种协同方法，通过知识导向的增强和约束，在大型多模态模型中注入新知识，同时有效保留旧知识，解决了灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMMs）预训练权重中编码的知识是静态且有限的，无法跟上现实世界的发展，阻碍了持续的知识获取。现有的知识注入方法在学习新知识和减轻灾难性遗忘方面表现不佳，因此需要一种能同时实现知识适应和知识保留的有效方法。

Method: KORE提出了一种知识导向的增强和约束协同方法。对于知识适应，它自动将单个知识项转换为结构化和全面的知识，确保模型准确学习新知识。对于知识保留，KORE将先前的知识存储在LMM线性层激活的协方差矩阵中，并通过将原始权重投影到该矩阵的零空间来初始化适配器，从而定义了一个最大限度减少对先前知识干扰的微调方向。

Result: 在LLaVA-v1.5-7B、LLaVA-v1.5-13B和Qwen2.5-VL-7B等多种LMM上的广泛实验表明，KORE实现了卓越的新知识注入性能，并有效缓解了灾难性遗忘。

Conclusion: KORE成功地解决了大型多模态模型中知识适应和知识保留的关键挑战，提供了一种有效的方法来持续更新模型知识并防止遗忘，从而实现LMM的持续知识获取。

Abstract: Large Multimodal Models encode extensive factual knowledge in their
pre-trained weights. However, its knowledge remains static and limited, unable
to keep pace with real-world developments, which hinders continuous knowledge
acquisition. Effective knowledge injection thus becomes critical, involving two
goals: knowledge adaptation (injecting new knowledge) and knowledge retention
(preserving old knowledge). Existing methods often struggle to learn new
knowledge and suffer from catastrophic forgetting. To address this, we propose
KORE, a synergistic method of KnOwledge-oRientEd augmentations and constraints
for injecting new knowledge into large multimodal models while preserving old
knowledge. Unlike general text or image data augmentation, KORE automatically
converts individual knowledge items into structured and comprehensive knowledge
to ensure that the model accurately learns new knowledge, enabling accurate
adaptation. Meanwhile, KORE stores previous knowledge in the covariance matrix
of LMM's linear layer activations and initializes the adapter by projecting the
original weights into the matrix's null space, defining a fine-tuning direction
that minimizes interference with previous knowledge, enabling powerful
retention. Extensive experiments on various LMMs, including LLaVA-v1.5-7B,
LLaVA-v1.5-13B, and Qwen2.5-VL-7B, show that KORE achieves superior new
knowledge injection performance and effectively mitigates catastrophic
forgetting.

</details>


### [139] [HAD: HAllucination Detection Language Models Based on a Comprehensive Hallucination Taxonomy](https://arxiv.org/abs/2510.19318)
*Fan Xu,Xinyu Hu,Zhenghan Yu,Li Lin,Xu Zhang,Yang Zhang,Wei Zhou,Jinjie Gu,Xiaojun Wan*

Main category: cs.CL

TL;DR: 本文提出了一项全面的幻觉分类法，并引入了HAllucination Detection (HAD) 模型，该模型能在一个推理过程中集成幻觉检测、跨度级识别和纠正。HAD模型在合成数据集上训练，并在多个基准测试中超越现有基线，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 随着对自然语言生成（NLG）模型，特别是大型语言模型依赖的增加，其输出的可靠性和准确性引发了担忧。其中一个关键挑战是“幻觉”，即模型产生看似合理但实际上不正确的信息。因此，幻觉检测已成为一项关键任务。

Method: 研究者引入了一个包含11个类别的全面幻觉分类法，涵盖各种NLG任务。他们提出了HAllucination Detection (HAD) 模型，该模型在一个推理过程中整合了幻觉检测、跨度级识别和纠正。HAD模型在一个包含约9万个样本的精心设计的合成数据集上进行训练。此外，他们还仔细标注了一个名为HADTest的幻觉检测测试集，包含2,248个样本。

Result: 在域内和域外测试集上的评估表明，HAD模型普遍优于现有基线，在HaluEval、FactCHD和FaithBench上取得了最先进的成果，证实了其鲁棒性和多功能性。

Conclusion: HAD模型通过引入全面的幻觉分类法和高效的检测、识别、纠正一体化方法，有效解决了NLG模型中的幻觉问题，并在多个基准测试中展现出卓越的性能和广泛的适用性。

Abstract: The increasing reliance on natural language generation (NLG) models,
particularly large language models, has raised concerns about the reliability
and accuracy of their outputs. A key challenge is hallucination, where models
produce plausible but incorrect information. As a result, hallucination
detection has become a critical task. In this work, we introduce a
comprehensive hallucination taxonomy with 11 categories across various NLG
tasks and propose the HAllucination Detection (HAD) models
https://github.com/pku0xff/HAD, which integrate hallucination detection,
span-level identification, and correction into a single inference process.
Trained on an elaborate synthetic dataset of about 90K samples, our HAD models
are versatile and can be applied to various NLG tasks. We also carefully
annotate a test set for hallucination detection, called HADTest, which contains
2,248 samples. Evaluations on in-domain and out-of-domain test sets show that
our HAD models generally outperform the existing baselines, achieving
state-of-the-art results on HaluEval, FactCHD, and FaithBench, confirming their
robustness and versatility.

</details>


### [140] [Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark](https://arxiv.org/abs/2510.19585)
*Yu Wu,Ke Shu,Jonas Fischer,Lidia Pivovarova,David Rosson,Eetu Mäkelä,Mikko Tolonen*

Main category: cs.CL

TL;DR: 本文提出并解决了从混合语言历史文献中提取拉丁语片段的新任务，并使用大型基础模型进行了基准测试和评估。


<details>
  <summary>Details</summary>
Motivation: 提出一个新颖的任务：从版式多样的混合语言历史文献中提取拉丁语片段，并评估大型模型在此任务上的表现。

Method: 使用包含724个标注页面的多模态数据集，对大型基础模型的性能进行基准测试和评估。

Result: 研究结果表明，使用当代模型可以实现可靠的拉丁语检测。

Conclusion: 该研究首次全面分析了这些模型在此任务上的能力和局限性。

Abstract: This paper presents a novel task of extracting Latin fragments from
mixed-language historical documents with varied layouts. We benchmark and
evaluate the performance of large foundation models against a multimodal
dataset of 724 annotated pages. The results demonstrate that reliable Latin
detection with contemporary models is achievable. Our study provides the first
comprehensive analysis of these models' capabilities and limits for this task.

</details>


### [141] [Algorithmic Fairness in NLP: Persona-Infused LLMs for Human-Centric Hate Speech Detection](https://arxiv.org/abs/2510.19331)
*Ewelina Gajewska,Arda Derbent,Jaroslaw A Chudziak,Katarzyna Budzynska*

Main category: cs.CL

TL;DR: 本文研究了通过标注者角色（Persona）个性化大型语言模型（Persona-LLMs）如何影响其对仇恨言论的敏感性，特别是与标注者和目标之间共享或不同的身份相关的偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解标注者角色如何影响LLMs在仇恨言论检测中的偏见，尤其是身份认同带来的影响，并旨在将群体认同的心理学见解与先进的自然语言处理技术相结合，以解决自动化仇恨言论检测中的偏见问题。

Method: 研究采用了Google的Gemini和OpenAI的GPT-4.1-mini模型，并使用了两种角色提示方法：浅层角色提示和基于检索增强生成（RAG）的深度情境化角色开发。通过分析内群和外群标注者角色对模型检测性能和不同社会群体公平性的影响进行评估。

Result: 研究结果揭示了基于角色的方法在减少偏见方面的潜力和局限性，为开发更公平的仇恨言论检测系统提供了宝贵见解。

Conclusion: 结论是，将社会人口学属性整合到大型语言模型中可以解决自动化仇恨言论检测中的偏见问题，但这种基于角色的方法也存在一定的局限性。

Abstract: In this paper, we investigate how personalising Large Language Models
(Persona-LLMs) with annotator personas affects their sensitivity to hate
speech, particularly regarding biases linked to shared or differing identities
between annotators and targets. To this end, we employ Google's Gemini and
OpenAI's GPT-4.1-mini models and two persona-prompting methods: shallow persona
prompting and a deeply contextualised persona development based on
Retrieval-Augmented Generation (RAG) to incorporate richer persona profiles. We
analyse the impact of using in-group and out-group annotator personas on the
models' detection performance and fairness across diverse social groups. This
work bridges psychological insights on group identity with advanced NLP
techniques, demonstrating that incorporating socio-demographic attributes into
LLMs can address bias in automated hate speech detection. Our results highlight
both the potential and limitations of persona-based approaches in reducing
bias, offering valuable insights for developing more equitable hate speech
detection systems.

</details>


### [142] [Slot Filling as a Reasoning Task for SpeechLLMs](https://arxiv.org/abs/2510.19326)
*Kadri Hacioglu,Manjunath K E,Andreas Stolcke*

Main category: cs.CL

TL;DR: 该研究提出将推理能力集成到语音大语言模型（speechLLMs）中以改进端到端槽填充任务。通过思维链框架和监督微调，引入推理步骤能提升性能。研究发现，专门用于数学/逻辑/编码的推理文本LLM可能不适合作为推理speechLLM的基础模型，而采用混合文本基础LLM并同时保留直接和推理操作模式的混合speechLLM表现最佳。


<details>
  <summary>Details</summary>
Motivation: 受近期推理大语言模型发展的启发，研究旨在将推理能力集成到语音大语言模型（speechLLMs）中，以提升其在端到端槽填充任务中的性能。

Method: 研究提出将推理集成到speechLLMs中，并采用思维链（Chain-of-Thought）框架将槽填充任务分解为多个推理步骤。为此，创建了推理数据集并对speechLLM应用监督微调策略。实验区分了常规和推理speechLLM，并尝试了不同类型和大小的LLM作为其文本基础模型。此外，还构建了混合speechLLM，其基于混合文本基础LLM并微调以保留直接和推理两种操作模式。

Result: 研究表明，引入推理（中间）步骤可以提高性能。然而，主要为数学、逻辑和编码领域开发的推理文本LLM作为推理speechLLM的基础模型可能表现不佳。进一步发现，基于混合文本基础LLM并微调以同时保留直接和推理两种操作模式的混合speechLLM，其性能优于仅采用单一操作模式微调的模型。

Conclusion: 将推理能力集成到语音大语言模型中可以有效提升槽填充任务的性能。在选择基础模型时需谨慎，专门用于数学/逻辑/编码的推理LLM可能不适合语音领域。采用混合基础LLM并同时支持直接与推理操作模式的微调策略，能构建出性能更优的混合speechLLM。

Abstract: We propose integration of reasoning into speech large language models
(speechLLMs) for the end-to-end slot-filling task. Inspired by the recent
development of reasoning LLMs, we use a chain-of-thought framework to decompose
the slot-filling task into multiple reasoning steps, create a reasoning dataset
and apply the supervised fine-tuning strategy to a speechLLM. We distinguish
between regular and reasoning speechLLMs and experiment with different types
and sizes of LLMs as their text foundation models. We demonstrate performance
improvements by introducing reasoning (intermediate) steps. However, we show
that a reasoning textual LLM developed mainly for math, logic and coding
domains might be inferior as a foundation model for a reasoning speechLLM. We
further show that hybrid speechLLMs, built on a hybrid text foundation LLM and
fine-tuned to preserve both direct and reasoning modes of operation, have
better performance than those fine-tuned employing only one mode of operation.

</details>


### [143] [Unraveling Emotions with Pre-Trained Models](https://arxiv.org/abs/2510.19668)
*Alejandro Pajón-Sanmartín,Francisco De Arriba-Pérez,Silvia García-Méndez,Fátima Leal,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.CL

TL;DR: 该研究比较了微调和提示工程在情感识别中的有效性，发现微调的预训练模型表现良好，而大型语言模型（LLMs）需要结构化提示工程和情感分组才能提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer模型在情感识别方面取得进展，但在处理开放式查询和大型语言模型时仍面临挑战，如语境模糊性、语言变异性和复杂情感表达的解释难度，使得通用模型难以直接应用。

Method: 该研究在三个场景下比较了微调和提示工程在情感检测中的有效性：1) 微调预训练模型与使用简单提示的通用LLM的性能；2) 不同情感提示设计对LLM的有效性；3) 情感分组技术对这些模型的影响。

Result: 实验测试表明，微调的预训练模型在情感识别方面取得了70%以上的指标。研究结果还强调，LLMs需要结构化的提示工程和情感分组来提高其性能。

Conclusion: 这些进展有望改善情感分析、人机交互以及跨领域用户行为的理解。

Abstract: Transformer models have significantly advanced the field of emotion
recognition. However, there are still open challenges when exploring open-ended
queries for Large Language Models (LLMs). Although current models offer good
results, automatic emotion analysis in open texts presents significant
challenges, such as contextual ambiguity, linguistic variability, and
difficulty interpreting complex emotional expressions. These limitations make
the direct application of generalist models difficult. Accordingly, this work
compares the effectiveness of fine-tuning and prompt engineering in emotion
detection in three distinct scenarios: (i) performance of fine-tuned
pre-trained models and general-purpose LLMs using simple prompts; (ii)
effectiveness of different emotion prompt designs with LLMs; and (iii) impact
of emotion grouping techniques on these models. Experimental tests attain
metrics above 70% with a fine-tuned pre-trained model for emotion recognition.
Moreover, the findings highlight that LLMs require structured prompt
engineering and emotion grouping to enhance their performance. These
advancements improve sentiment analysis, human-computer interaction, and
understanding of user behavior across various domains.

</details>


### [144] [Modeling Turn-Taking with Semantically Informed Gestures](https://arxiv.org/abs/2510.19350)
*Varsha Suresh,M. Hamza Mughal,Christian Theobalt,Vera Demberg*

Main category: cs.CL

TL;DR: 本研究通过引入带有语义手势标注的DnD Gesture++语料库，并使用多专家混合模型整合文本、音频和手势，证明了手势在多模态轮流转换预测中的补充作用，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 人类在对话中利用语音、手势和凝视等多模态线索来管理轮流转换。尽管语言和声学特征提供了信息，但手势提供了补充线索来建模这些转换。因此，研究手势在轮流转换中的具体作用是其主要动机。

Method: 研究方法包括：1. 引入DnD Gesture++，这是DnD Gesture多方语料库的扩展，增加了2,663个语义手势标注（包括具象、隐喻、指示和语篇类型）。2. 使用这个数据集，通过一个多专家混合（Mixture-of-Experts）框架来建模轮流转换预测，该框架整合了文本、音频和手势特征。

Result: 实验结果表明，与基线模型相比，整合语义指导的手势能够持续地提升性能，这证明了手势在多模态轮流转换中的补充作用。

Conclusion: 研究得出结论，手势在多模态轮流转换中扮演着重要的补充角色，其语义信息能够有效提升轮流转换预测的准确性。

Abstract: In conversation, humans use multimodal cues, such as speech, gestures, and
gaze, to manage turn-taking. While linguistic and acoustic features are
informative, gestures provide complementary cues for modeling these
transitions. To study this, we introduce DnD Gesture++, an extension of the
multi-party DnD Gesture corpus enriched with 2,663 semantic gesture annotations
spanning iconic, metaphoric, deictic, and discourse types. Using this dataset,
we model turn-taking prediction through a Mixture-of-Experts framework
integrating text, audio, and gestures. Experiments show that incorporating
semantically guided gestures yields consistent performance gains over
baselines, demonstrating their complementary role in multimodal turn-taking.

</details>


### [145] [Style Attack Disguise: When Fonts Become a Camouflage for Adversarial Intent](https://arxiv.org/abs/2510.19641)
*Yangshijie Zhang,Xinda Wang,Jialin Liu,Wenqiang Wang,Zhicong Ma,Xingxing Jia*

Main category: cs.CL

TL;DR: 该研究发现，用户在社交媒体上使用的风格化字体和表情符号在人类和NLP模型之间造成了感知差异，并提出了一种名为SAD的风格化攻击，该攻击能有效降低传统模型、大型语言模型和商业服务在多种NLP和多模态任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体的普及，用户使用风格化字体和类字体表情符号来表达个性，创造出对人类而言易读但对NLP模型而言却构成不同token的文本。这种人类与模型之间的感知差异引入了NLP模型中隐藏的漏洞。

Method: 研究首先识别了人类与模型之间的感知差异。接着，提出了一种基于风格的攻击方法，命名为“风格攻击伪装”（Style Attack Disguise, SAD），并设计了两种尺寸：轻量级（追求查询效率）和强力级（追求卓越攻击性能）。实验在情感分类和机器翻译任务上进行，涵盖了传统模型、大型语言模型（LLMs）和商业服务。此外，还探讨了SAD对文本到图像和文本到语音生成等多模态任务的潜在威胁。

Result: 实验证明，SAD展现出强大的攻击性能。它成功地攻击了情感分类和机器翻译任务，对传统模型、LLMs和商业服务均有效。研究还揭示了SAD对包括文本到图像和文本到语音生成在内的多模态任务构成潜在威胁。

Conclusion: 风格化文本在人类和NLP模型之间造成了感知鸿沟，这一鸿沟是NLP模型中一个未被发现的漏洞。SAD攻击有效利用了这一漏洞，对NLP模型和多模态任务构成了严重威胁，凸显了在处理用户生成的风格化内容时需要关注的新安全挑战。

Abstract: With social media growth, users employ stylistic fonts and font-like emoji to
express individuality, creating visually appealing text that remains
human-readable. However, these fonts introduce hidden vulnerabilities in NLP
models: while humans easily read stylistic text, models process these
characters as distinct tokens, causing interference. We identify this
human-model perception gap and propose a style-based attack, Style Attack
Disguise (SAD). We design two sizes: light for query efficiency and strong for
superior attack performance. Experiments on sentiment classification and
machine translation across traditional models, LLMs, and commercial services
demonstrate SAD's strong attack performance. We also show SAD's potential
threats to multimodal tasks including text-to-image and text-to-speech
generation.

</details>


### [146] [Local Obfuscation by GLINER for Impartial Context Aware Lineage: Development and evaluation of PII Removal system](https://arxiv.org/abs/2510.19346)
*Prakrithi Shivaprakash,Lekhansh Shukla,Animesh Mukherjee,Prabhat Chand,Pratima Murthy*

Main category: cs.CL

TL;DR: 本文提出了一种名为LOGICAL的本地化、高效且安全的个人身份信息（PII）移除系统，该系统基于微调的GLiNER模型，在临床笔记去识别化方面表现优异，尤其适用于资源受限的环境。


<details>
  <summary>Details</summary>
Motivation: 从电子健康记录（EHR）的临床笔记中移除PII对于研究和AI开发至关重要。然而，大型语言模型（LLMs）的高计算成本和API服务的数据隐私风险限制了其应用，特别是在资源匮乏的环境中。

Method: 研究开发了LOGICAL系统，该系统基于一个微调的通用轻量级命名实体识别（GLiNER）模型。使用了来自精神病院EHR系统的1515份临床文档，定义了九类PII。GLiNER模型在2849个文本实例上进行了微调，并在376个实例的测试集上通过字符级精确率、召回率和F1分数进行评估。性能与Microsoft Azure NER、Microsoft Presidio以及Gemini-Pro-2.5和Llama-3.3-70B-Instruct的零样本提示进行了比较。

Result: 微调后的GLiNER模型表现出色，总体微平均F1分数达到0.980，显著优于Gemini-Pro-2.5（F1分数：0.845）。LOGICAL系统能完全净化95%的文档，而次优解决方案仅为64%。该模型可在标准笔记本电脑上高效运行，无需专用GPU。然而，2%的实体级假阴性率表明所有测试系统都需要人工验证。

Conclusion: 微调的专业Transformer模型（如GLiNER）为临床笔记中的PII移除提供了一种准确、计算高效且安全的解决方案。这种“源头净化”方法是资源密集型LLMs的实用替代方案，尤其在资源受限的环境中，能够创建去识别化的数据集以支持研究和AI开发，同时保护数据隐私。

Abstract: Removing Personally Identifiable Information (PII) from clinical notes in
Electronic Health Records (EHRs) is essential for research and AI development.
While Large Language Models (LLMs) are powerful, their high computational costs
and the data privacy risks of API-based services limit their use, especially in
low-resource settings. To address this, we developed LOGICAL (Local Obfuscation
by GLINER for Impartial Context-Aware Lineage), an efficient, locally
deployable PII removal system built on a fine-tuned Generalist and Lightweight
Named Entity Recognition (GLiNER) model. We used 1515 clinical documents from a
psychiatric hospital's EHR system. We defined nine PII categories for removal.
A modern-gliner-bi-large-v1.0 model was fine-tuned on 2849 text instances and
evaluated on a test set of 376 instances using character-level precision,
recall, and F1-score. We compared its performance against Microsoft Azure NER,
Microsoft Presidio, and zero-shot prompting with Gemini-Pro-2.5 and
Llama-3.3-70B-Instruct. The fine-tuned GLiNER model achieved superior
performance, with an overall micro-average F1-score of 0.980, significantly
outperforming Gemini-Pro-2.5 (F1-score: 0.845). LOGICAL correctly sanitised 95%
of documents completely, compared to 64% for the next-best solution. The model
operated efficiently on a standard laptop without a dedicated GPU. However, a
2% entity-level false negative rate underscores the need for human-in-the-loop
validation across all tested systems. Fine-tuned, specialised transformer
models like GLiNER offer an accurate, computationally efficient, and secure
solution for PII removal from clinical notes. This "sanitisation at the source"
approach is a practical alternative to resource-intensive LLMs, enabling the
creation of de-identified datasets for research and AI development while
preserving data privacy, particularly in resource-constrained environments.

</details>


### [147] [LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts](https://arxiv.org/abs/2510.19363)
*Siyuan Wang,Gaokai Zhang,Li Lyna Zhang,Ning Shang,Fan Yang,Dongyao Chen,Mao Yang*

Main category: cs.CL

TL;DR: 本文提出了LoongRL，一种数据驱动的强化学习方法，通过KeyChain数据合成技术，显著提升了大型语言模型在长上下文多跳推理任务上的性能和泛化能力，使其能够处理远超训练长度的上下文，并媲美更大规模的前沿模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长上下文推理方面至关重要，但针对长上下文的先进思维模式仍未被充分探索，且高难度强化学习数据稀缺。现有强化学习方法虽能增强短上下文推理，但未能有效解决长上下文问题。

Method: 本文引入了LoongRL，一种数据驱动的强化学习方法，用于高级长上下文推理。其核心是KeyChain合成方法，通过插入UUID链将短多跳问答任务转化为高难度长上下文任务，这些UUID链将真实问题隐藏在大量干扰文档中。模型需要逐步追踪正确的链条，识别真实问题，检索相关事实并进行推理以给出正确答案。在KeyChain数据上进行的强化学习训练诱导出了“规划-检索-推理-复核”的推理模式。

Result: LoongRL在KeyChain数据上进行训练后，诱导出的推理模式具有出色的泛化能力，远超训练长度（在16K上下文训练的模型能有效解决128K的任务，且无需高昂的完整长度RL部署成本）。在Qwen2.5-7B和14B模型上，LoongRL显著提高了长上下文多跳问答的准确性，绝对增益分别为+23.5%和+21.1%。最终的LoongRL-14B模型得分达到74.2，可与o3-mini (74.5) 和DeepSeek-R1 (74.9) 等更大规模的前沿模型相媲美。此外，它还改善了长上下文检索能力，通过了所有128K的“大海捞针”压力测试，并保持了短上下文推理能力。

Conclusion: LoongRL是一种有效的数据驱动强化学习方法，能够显著提升大型语言模型在长上下文推理任务上的性能和泛化能力。通过引入KeyChain数据合成和诱导特定的推理模式，LoongRL使得模型能够高效处理极长的上下文，并在多跳问答、检索和压力测试中表现出色，达到了与顶尖模型相竞争的水平。

Abstract: Reasoning over long contexts is essential for large language models. While
reinforcement learning (RL) enhances short-context reasoning by inducing "Aha"
moments in chain-of-thought, the advanced thinking patterns required for
long-context reasoning remain largely unexplored, and high-difficulty RL data
are scarce. In this paper, we introduce LoongRL, a data-driven RL method for
advanced long-context reasoning. Central to LoongRL is KeyChain, a synthesis
approach that transforms short multi-hop QA into high-difficulty long-context
tasks by inserting UUID chains that hide the true question among large
collections of distracting documents. Solving these tasks requires the model to
trace the correct chain step-by-step, identify the true question, retrieve
relevant facts and reason over them to answer correctly. RL training on
KeyChain data induces an emergent plan-retrieve-reason-recheck reasoning
pattern that generalizes far beyond training length. Models trained at 16K
effectively solve 128K tasks without prohibitive full-length RL rollout costs.
On Qwen2.5-7B and 14B, LoongRL substantially improves long-context multi-hop QA
accuracy by +23.5% and +21.1% absolute gains. The resulting LoongRL-14B reaches
a score of 74.2, rivaling much larger frontier models such as o3-mini (74.5)
and DeepSeek-R1 (74.9). It also improves long-context retrieval, passes all
128K needle-in-a-haystack stress tests, and preserves short-context reasoning
capabilities.

</details>


### [148] [Do Prompts Reshape Representations? An Empirical Study of Prompting Effects on Embeddings](https://arxiv.org/abs/2510.19694)
*Cesar Gonzalez-Gutierrez,Dirk Hovy*

Main category: cs.CL

TL;DR: 本研究发现，提示词（prompting）会影响大型语言模型（LLM）的内部表示质量，但这种影响与提示词对目标任务的相关性并不总是正相关，这挑战了“更相关提示词带来更好表示”的普遍假设。


<details>
  <summary>Details</summary>
Motivation: 了解LLM在零样本设置下，通过提示词执行多样化任务的潜在机制，特别是预训练嵌入如何支持上下文任务解决。

Method: 通过对提示词嵌入进行一系列探查实验（probing experiments），分析零样本分类中不同提示模板组合的表现。

Result: 提示词确实影响表示质量，但这些变化与提示词对目标任务的相关性之间没有持续的一致关联。更相关的提示词不一定能带来更好的表示。

Conclusion: 研究结果挑战了“更相关的提示词必然导致更好表示”的假设，并指出需要进一步分析导致这种意外行为的潜在因素。

Abstract: Prompting is a common approach for leveraging LMs in zero-shot settings.
However, the underlying mechanisms that enable LMs to perform diverse tasks
without task-specific supervision remain poorly understood. Studying the
relationship between prompting and the quality of internal representations can
shed light on how pre-trained embeddings may support in-context task solving.
In this empirical study, we conduct a series of probing experiments on prompt
embeddings, analyzing various combinations of prompt templates for zero-shot
classification. Our findings show that while prompting affects the quality of
representations, these changes do not consistently correlate with the relevance
of the prompts to the target task. This result challenges the assumption that
more relevant prompts necessarily lead to better representations. We further
analyze potential factors that may contribute to this unexpected behavior.

</details>


### [149] [MoE-Prism: Disentangling Monolithic Experts for Elastic MoE Services via Model-System Co-Designs](https://arxiv.org/abs/2510.19366)
*Xinfeng Xia,Jiacheng Liu,Xiaofeng Hou,Peng Tang,Mingxuan Zhang,Wenfeng Wang,Chao Li*

Main category: cs.CL

TL;DR: MoE-Prism是一种模型-系统协同设计，通过将MoE模型中的专家分解为细粒度子专家并进行QoS感知调度，使其变得弹性化，从而提供更多的操作点，优化吞吐量和延迟，弥合模型与系统之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: MoE模型虽然通过稀疏激活实现高质量，但其依赖于刚性的top-k路由机制，导致“质量悬崖”，只提供少数粗粒度的操作点。这种不灵活性使得在成本和质量之间难以权衡，无法适应多样化的服务水平目标（SLOs），并导致显著的资源过度配置。

Method: MoE-Prism方法分为两阶段：1. 离线重构引擎：系统性地将整体专家分解为细粒度“子专家”。该引擎采用一种分区优化求解器，使用基于元启发式的方法对神经元进行分组，在不重新训练的情况下保持功能局部性。2. 在线调度引擎：通过QoS感知调度利用这种新弹性。它实现专门的策略来解决复杂的系统问题，包括在云部署中最大化吞吐量和管理内存受限设备的延迟优化卸载。

Result: MoE-Prism比基线提供了超过4倍的独特、稳定的操作点。这使得AI服务在严格的延迟预算下，动态地将吞吐量提高高达19.9%，或在有限资源下将延迟降低高达10.36%。

Conclusion: MoE-Prism提供了一个关键的“控制旋钮”，弥合了模型与系统之间的鸿沟，从而实现了下一代自适应、高效和QoS感知的AI服务。

Abstract: Mixture-of-Experts (MoE) models, the state-of-the-art in large-scale AI,
achieve high quality by sparsely activating parameters. However, their reliance
on routing between a few monolithic experts via a top-k mechanism creates a
"quality cliff", offering only a few coarse-grained operating points. This
inflexibility forces a difficult trade-off between cost and quality, preventing
adaptation to diverse Service Level Objectives (SLOs) and leading to
significant resource over-provisioning.
  This paper introduces MoE-Prism, a model-system co-design that transforms
rigid MoE models into elastic services. Our methodology is divided into two
phases. First, an \emph{Offline Refactoring Engine} systematically deconstructs
monolithic experts into fine-grained "sub-experts." This engine employs a
partitioning optimization solver that uses a metaheuristic-based approach to
group neurons, preserving functional locality without requiring retraining.
Second, an \emph{Online Scheduling Engine} leverages this new elasticity
through QoS-aware scheduling. It implements specialized policies to solve
complex system problems, including maximizing throughput in cloud deployments
and managing latency-optimized offloading for memory-constrained devices. Our
evaluation across three different MoE models shows that MoE-Prismprovides over
4 times more distinct, stable operating points than the baseline. This allows
an AI service to dynamically improve throughput by up to 19.9\% under a strict
latency budget or reduce latency by up to 10.36\% under limited resources.
MoE-Prism provides the critical "control knob" to bridge the model-system gap,
enabling the next generation of adaptive, efficient, and QoS-aware AI services.

</details>


### [150] [Are Large Language Models Sensitive to the Motives Behind Communication?](https://arxiv.org/abs/2510.19687)
*Addison J. Wu,Ryan Liu,Kerem Oktar,Theodore R. Sumers,Thomas L. Griffiths*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLMs）是否具备识别信息来源动机的能力，发现它们在受控实验中能像人类一样评估有偏见的信息，但在真实世界广告中表现不佳，不过简单的干预可以显著改善其性能。


<details>
  <summary>Details</summary>
Motivation: 人类在沟通中常带有特定意图，因此LLMs处理的信息也受人类意图和激励的影响。人类能识别信息来源的动机以决定信任度，为了使LLMs在现实世界中有效，它们也需要批判性地评估信息来源的动机，例如判断销售宣传的可信度。

Method: 研究首先采用认知科学中的受控实验来验证LLMs的行为是否与从有动机证词中学习的理性模型一致。随后，将评估扩展到赞助在线广告，以反映LLM代理更自然的真实信息生态系统。此外，还尝试了一种简单的“引导干预”来提高意图和激励的显著性。

Result: 在受控实验中，LLMs成功地以类似人类的方式折扣来自有偏见来源的信息。然而，在真实世界的赞助在线广告中，LLMs的推断与理性模型的预测并不完全一致，部分原因是额外信息分散了它们对警惕性相关考虑的注意力。不过，一个简单的引导干预，显著提高了LLMs与理性模型之间的对应关系。

Conclusion: 这些结果表明，LLMs对他人动机具有基本的敏感性，但要推广到新颖的现实世界场景，还需要进一步改进这些模型。

Abstract: Human communication is motivated: people speak, write, and create content
with a particular communicative intent in mind. As a result, information that
large language models (LLMs) and AI agents process is inherently framed by
humans' intentions and incentives. People are adept at navigating such nuanced
information: we routinely identify benevolent or self-serving motives in order
to decide what statements to trust. For LLMs to be effective in the real world,
they too must critically evaluate content by factoring in the motivations of
the source -- for instance, weighing the credibility of claims made in a sales
pitch. In this paper, we undertake a comprehensive study of whether LLMs have
this capacity for motivational vigilance. We first employ controlled
experiments from cognitive science to verify that LLMs' behavior is consistent
with rational models of learning from motivated testimony, and find they
successfully discount information from biased sources in a human-like manner.
We then extend our evaluation to sponsored online adverts, a more naturalistic
reflection of LLM agents' information ecosystems. In these settings, we find
that LLMs' inferences do not track the rational models' predictions nearly as
closely -- partly due to additional information that distracts them from
vigilance-relevant considerations. However, a simple steering intervention that
boosts the salience of intentions and incentives substantially increases the
correspondence between LLMs and the rational model. These results suggest that
LLMs possess a basic sensitivity to the motivations of others, but generalizing
to novel real-world settings will require further improvements to these models.

</details>


### [151] [SONAR-SLT: Multilingual Sign Language Translation via Language-Agnostic Sentence Embedding Supervision](https://arxiv.org/abs/2510.19398)
*Yasser Hamidullah,Shakib Yazdani,Cennet Oguz,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 本文提出使用语言无关的多模态嵌入和耦合数据增强方法来监督手语翻译（SLT），以实现多语言直接翻译，提高可扩展性和语义鲁棒性，尤其在低资源环境下表现更佳。


<details>
  <summary>Details</summary>
Motivation: 传统手语翻译（SLT）通常只用单一口语文本进行训练，限制了其可扩展性和跨语言泛化能力。早期方法虽用文本句嵌入替代了词汇监督，但仍受限于特定语言和模态。

Method: 本研究采用在多语言文本和语音上训练的语言无关、多模态嵌入来监督SLT，从而实现直接的多语言翻译。为解决数据稀缺问题，提出了一种耦合数据增强方法，结合了多语言目标增强（即翻译成多种语言）和视频级扰动。

Result: 实验表明，与仅使用文本句嵌入监督相比，该方法在BLEURT指标上持续获得提升，尤其在低资源设置下改善更为显著。

Conclusion: 研究结果表明，语言无关的嵌入监督结合耦合数据增强，为传统手语翻译训练提供了一种可扩展且语义鲁棒的替代方案。

Abstract: Sign language translation (SLT) is typically trained with text in a single
spoken language, which limits scalability and cross-language generalization.
Earlier approaches have replaced gloss supervision with text-based sentence
embeddings, but up to now, these remain tied to a specific language and
modality. In contrast, here we employ language-agnostic, multimodal embeddings
trained on text and speech from multiple languages to supervise SLT, enabling
direct multilingual translation. To address data scarcity, we propose a coupled
augmentation method that combines multilingual target augmentations (i.e.
translations into many languages) with video-level perturbations, improving
model robustness. Experiments show consistent BLEURT gains over text-only
sentence embedding supervision, with larger improvements in low-resource
settings. Our results demonstrate that language-agnostic embedding supervision,
combined with coupled augmentation, provides a scalable and semantically robust
alternative to traditional SLT training.

</details>


### [152] [Sign Language Translation with Sentence Embedding Supervision](https://arxiv.org/abs/2510.19367)
*Yasser Hamidullah,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 手语翻译（SLT）系统通常依赖于词汇标注（gloss），但词汇数据稀缺且不一致。本文提出一种新方法，在训练时使用目标句的句子嵌入作为词汇的替代，无需手动标注。该方法在无词汇数据集上显著优于其他无词汇方法，达到新SOTA，并缩小了与依赖词汇系统之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译系统通常通过词汇标注来辅助学习过程，无论是端到端还是通过中间步骤。然而，带有词汇标注的手语数据通常规模不足，且不同数据集之间的词汇标注差异很大，这限制了SLT系统的发展。

Method: 本文提出一种新颖的方法，在训练时使用目标句的句子嵌入来替代词汇。这种新的监督方式无需任何手动标注，因为它是在原始文本数据上学习的。该方法易于实现多语言性，并用单语和多语句子嵌入及翻译系统进行实验。

Result: 该方法显著优于其他无词汇方法，在没有词汇且未额外使用SLT数据集进行预训练的数据集上，创造了新的最先进（SOTA）性能。它成功缩小了无词汇系统与依赖词汇系统之间的性能差距。该方法在涵盖德语（PHOENIX-2014T）和美式手语（How2Sign）的数据集上进行了评估。

Conclusion: 通过使用目标句的句子嵌入作为监督信号，本文提出了一种有效的无词汇手语翻译方法。该方法无需手动词汇标注，克服了词汇数据稀缺和不一致的问题，并在无词汇数据集上取得了显著的性能提升，达到了新的SOTA，成功缩小了与依赖词汇系统之间的性能差距。

Abstract: State-of-the-art sign language translation (SLT) systems facilitate the
learning process through gloss annotations, either in an end2end manner or by
involving an intermediate step. Unfortunately, gloss labelled sign language
data is usually not available at scale and, when available, gloss annotations
widely differ from dataset to dataset. We present a novel approach using
sentence embeddings of the target sentences at training time that take the role
of glosses. The new kind of supervision does not need any manual annotation but
it is learned on raw textual data. As our approach easily facilitates
multilinguality, we evaluate it on datasets covering German (PHOENIX-2014T) and
American (How2Sign) sign languages and experiment with mono- and multilingual
sentence embeddings and translation systems. Our approach significantly
outperforms other gloss-free approaches, setting the new state-of-the-art for
data sets where glosses are not available and when no additional SLT datasets
are used for pretraining, diminishing the gap between gloss-free and
gloss-dependent systems.

</details>


### [153] [SmartSwitch: Advancing LLM Reasoning by Overcoming Underthinking via Promoting Deeper Thought Exploration](https://arxiv.org/abs/2510.19767)
*Xichen Zhang,Sitong Wu,Haoru Tan,Shaozuo Yu,Yinghao Zhu,Ziyi He,Jiaya Jia*

Main category: cs.CL

TL;DR: 针对大型语言模型长链思维中存在的“思考不足”问题，本文提出了SmartSwitch推理框架。该框架通过监控推理过程，识别并回溯被过早放弃的高潜力思维，插入深化提示以鼓励深度探索，从而显著提升了模型在复杂推理任务上的性能和token效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在复杂推理任务中依赖长链思维（LongCoT）能力，但存在“思考不足”（underthinking）问题，即模型频繁切换思维而未充分探索，这限制了其性能和token效率。

Method: 提出SmartSwitch推理框架。该框架可即插即用，持续监控模型推理过程。感知模块识别思维切换点，并使用现成的过程奖励模型（PRM）评估前一思维的潜力。如果发现高潜力思维被过早放弃，干预模块会中断当前推理，回溯到切换点之前，并插入一个“深化提示”以鼓励沿该有前景的路径进行更深入的探索。

Result: 在具有挑战性的数学推理基准上进行的广泛实验表明，该方法显著提升了不同大小的各种大型语言模型的性能。

Conclusion: SmartSwitch框架通过有效解决大型语言模型在长链思维中的“思考不足”问题，显著增强了其在复杂推理任务上的性能，提供了一种简单而有效的推理策略。

Abstract: The long chain-of-thought (LongCoT) capability is central to the recent
breakthroughs achieved by large language models in complex reasoning tasks.
However, the accompanying issue of ''underthinking'', where models exhibit
shallow reasoning by frequently switching thoughts without sufficient
exploration, limits both performance and token efficiency. To address this
problem, we propose a simple yet effective reasoning strategy: the SmartSwitch
inference framework. This framework can be easily integrated into any large
language model as a plug-and-play solution, continuously monitoring the model's
reasoning process to detect underthinking and guide it toward deeper
exploration of promising but overlooked thoughts. Specifically, the perception
module identifies points where thoughts switch and evaluates the potential of
the preceding thought using an off-the-shelf process reward model (PRM). If a
high-potential thought is found to be prematurely abandoned, the intervention
module interrupts the ongoing inference, backtracks to the point before the
switch, and inserts a "deepening prompt" to encourage further exploration along
that promising path. Extensive experiments on challenging mathematical
reasoning benchmarks demonstrate that our method significantly enhances the
performance of various large language models of different sizes.

</details>


### [154] [Spatio-temporal Sign Language Representation and Translation](https://arxiv.org/abs/2510.19413)
*Yasser Hamidullah,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 本文描述了DFKI-MLT在WMT-SLT 2022手语翻译任务中的提交，该系统将瑞士德语手语（视频）翻译成德语（文本），采用端到端模型学习时空特征和翻译，但在测试集上的表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有的手语翻译（SLT）系统通常使用带有定制输入嵌入的seq2seq架构，但标准方法往往未能充分利用视频中的时间特征。研究动机是开发一种能够学习时空特征表示和翻译的单一模型，以实现真正的端到端架构，期望能更好地泛化到新的数据集。

Method: 该系统采用通用的seq2seq架构，并使用从视频帧中提取的特征作为输入嵌入。关键方法是构建一个单一模型，该模型能够同时学习时空特征表示和翻译，形成一个端到端的架构。

Result: 在开发集上，该系统取得了5±1 BLEU点的成绩。然而，在测试集上的性能显著下降，仅为0.11±0.06 BLEU点。

Conclusion: 所提出的端到端架构在开发集上表现出了一定的潜力，但在测试集上的性能急剧下降，表明该模型在泛化到未见过的数据方面存在显著挑战或缺陷。

Abstract: This paper describes the DFKI-MLT submission to the WMT-SLT 2022 sign
language translation (SLT) task from Swiss German Sign Language (video) into
German (text). State-of-the-art techniques for SLT use a generic seq2seq
architecture with customized input embeddings. Instead of word embeddings as
used in textual machine translation, SLT systems use features extracted from
video frames. Standard approaches often do not benefit from temporal features.
In our participation, we present a system that learns spatio-temporal feature
representations and translation in a single model, resulting in a real
end-to-end architecture expected to better generalize to new data sets. Our
best system achieved $5\pm1$ BLEU points on the development set, but the
performance on the test dropped to $0.11\pm0.06$ BLEU points.

</details>


### [155] [AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders](https://arxiv.org/abs/2510.19779)
*Yuezhou Hu,Jiaxin Guo,Xinyu Feng,Tuo Zhao*

Main category: cs.CL

TL;DR: AdaSPEC提出了一种新颖的知识蒸馏（KD）方法，通过选择性地过滤难以拟合的token，提高了推测解码（SD）中草稿模型的token接受率，且不影响生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统的知识蒸馏方法旨在最小化草稿模型和目标模型在所有token上的KL散度，这与SD的最大化token接受率的真实目标不一致。草稿模型由于容量限制，难以完全吸收目标模型的知识，导致性能不佳。

Method: AdaSPEC在知识蒸馏过程中引入了选择性token过滤。它使用一个参考模型来识别并过滤掉“难以拟合”的token，从而使草稿模型能更好地与目标模型在“更简单”的token上对齐。

Result: AdaSPEC在算术推理、指令遵循、编码和摘要等多种任务上，以及31M/1.4B和350M/2.7B的模型配置下，始终优于最先进的DistillSpec方法，token接受率提高了高达15%，且不损害生成质量。

Conclusion: AdaSPEC通过在知识蒸馏中引入选择性token过滤，解决了SD中KD目标错位的问题，有效提高了草稿模型的token接受率，从而提升了推测解码的整体性能。

Abstract: Speculative Decoding (SD) accelerates large language model inference by
employing a small draft model to generate predictions, which are then verified
by a larger target model. The effectiveness of SD hinges on the alignment
between these models, which is typically enhanced by Knowledge Distillation
(KD). However, conventional KD methods aim to minimize the KL divergence
between the draft and target models across all tokens, a goal that is
misaligned with the true objective of SD, which is to maximize token acceptance
rate. Therefore, draft models often struggle to fully assimilate the target
model's knowledge due to capacity constraints, leading to suboptimal
performance. To address this challenge, we propose AdaSPEC, a novel method that
incorporates selective token filtering into the KD process. AdaSPEC utilizes a
reference model to identify and filter out difficult-to-fit tokens, enabling
the distillation of a draft model that better aligns with the target model on
simpler tokens. This approach improves the overall token acceptance rate
without compromising generation quality. We evaluate AdaSPEC across diverse
tasks, including arithmetic reasoning, instruction-following, coding, and
summarization, using model configurations of 31M/1.4B and 350M/2.7B parameters.
Our results demonstrate that AdaSPEC consistently outperforms the
state-of-the-art DistillSpec method, achieving higher acceptance rates across
all tasks (up to 15\%). The code is publicly available at
https://github.com/yuezhouhu/adaspec.

</details>


### [156] [BLiSS 1.0: Evaluating Bilingual Learner Competence in Second Language Small Language Models](https://arxiv.org/abs/2510.19419)
*Yuan Gao,Suchir Salhan,Andrew Caines,Paula Buttery,Weiwei Sun*

Main category: cs.CL

TL;DR: BLiSS 1.0是一个新的基准测试，旨在评估认知启发模型区分自然学习者错误和人工错误的能力，发现这种能力与标准语法性不同，并受训练范式影响。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试侧重于性能，未能有效评估认知启发模型，特别是在理解人类语言习得系统性模式方面。研究旨在弥合这一差距。

Method: 引入BLiSS 1.0基准测试，采用“选择性容忍”新范式，测试模型是否认为自然学习者错误比匹配的人工错误更合理。该基准从280多万条自然学习者句子构建，提供136,867个受控三元组（正确句、学习者错误句、人工错误句）。

Result: 对多种模型的实验表明，“选择性容忍”是一种独立于标准语法性的能力，且模型的表现与训练范式密切相关。

Conclusion: BLiSS被验证为一种强大的工具，可用于衡量不同训练目标如何影响模型与人类语言习得系统性模式的对齐程度。

Abstract: To bridge the gap between performance-oriented benchmarks and the evaluation
of cognitively inspired models, we introduce BLiSS 1.0, a Benchmark of Learner
Interlingual Syntactic Structure. Our benchmark operationalizes a new paradigm
of selective tolerance, testing whether a model finds a naturalistic learner
error more plausible than a matched, artificial error within the same sentence.
Constructed from over 2.8 million naturalistic learner sentences, BLiSS
provides 136,867 controlled triplets (corrected, learner, artificial) for this
purpose. Experiments on a diverse suite of models demonstrate that selective
tolerance is a distinct capability from standard grammaticality, with
performance clustering strongly by training paradigm. This validates BLiSS as a
robust tool for measuring how different training objectives impact a model's
alignment with the systematic patterns of human language acquisition.

</details>


### [157] [Re-evaluating Minimum Bayes Risk Decoding for Automatic Speech Recognition](https://arxiv.org/abs/2510.19471)
*Yuu Jinnai*

Main category: cs.CL

TL;DR: 本研究评估了最小贝叶斯风险 (MBR) 解码在自动语音识别 (ASR) 和语音翻译 (ST) 任务中的表现，发现其在大多数实验设置下优于束搜索。


<details>
  <summary>Details</summary>
Motivation: MBR 解码在文本到文本生成任务（如机器翻译、文本摘要）中优于束搜索。鉴于此，研究者推断 MBR 解码也可能对语音到文本任务有效，因此旨在验证这一假设。

Method: 研究者使用 Whisper 及其衍生模型，在英语和日语的 ASR 和 ST 任务上评估了 MBR 解码，并将其准确性与束搜索进行了比较。

Result: 实验结果表明，MBR 解码的准确性在大多数评估的实验设置中都优于束搜索。

Conclusion: MBR 解码是需要高准确性的离线 ASR 和 ST 任务的一种有前景的方法。

Abstract: Recent work has shown that sample-based Minimum Bayes Risk (MBR) decoding
outperforms beam search in text-to-text generation tasks, such as machine
translation, text summarization, and image captioning. On the other hand, beam
search is the current practice for speech-to-text tasks such as automatic
speech recognition (ASR) and Speech Translation (ST). Given that MBR decoding
is effective in text-to-text generation tasks, it is reasonable to expect it to
also be effective for speech-to-text tasks. In this paper, we evaluate MBR
decoding for ASR and ST tasks on English and Japanese using Whisper and its
derivative models. We observe that the accuracy of MBR decoding outperforms
that of beam search in most of the experimental settings we have evaluated. The
results show that MBR decoding is a promising method for offline ASR and ST
tasks that require high accuracy. The code is available at
https://github.com/CyberAgentAILab/mbr-for-asr

</details>


### [158] [MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models](https://arxiv.org/abs/2510.19457)
*Kailin Jiang,Ning Jiang,Yuchen Ren,Yuchen Li,Yifan Gao,Jinhe Bi,Yunpu Ma,Qingqing Liu,Xianhao Wang,Yifan Jia,Hongbo Jiang,Yaocong Hu,Bin Li,Lei Liu,Yuntao Du*

Main category: cs.CL

TL;DR: 大型多模态模型（LMMs）在理解时间敏感知识方面存在不足。本文提出了MINED基准来评估LMMs的时间感知能力，发现现有LMMs（尤其是开源模型）表现不佳，但知识编辑方法在更新此类知识方面显示出潜力。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMMs）的静态表示难以准确理解时间敏感的事实知识。现有基准设计静态，无法充分评估LMMs理解时间敏感知识的能力。

Method: 本文提出了MINED基准，通过6个关键维度（认知、意识、可信度、理解、推理、鲁棒性）和11项任务来评估LMMs的时间感知能力。MINED由维基百科构建，包含2,104个时间敏感知识样本，涵盖六种知识类型。研究评估了15个广泛使用的LMMs在MINED上的表现，并探讨了通过知识编辑方法更新LMMs中时间敏感知识的可行性。

Result: Gemini-2.5-Pro获得了最高的平均CEM分数（63.07），而大多数开源LMMs仍缺乏时间理解能力。LMMs在组织知识方面表现最佳，但在体育方面表现最弱。知识编辑方法在单一编辑场景中能有效更新LMMs中的知识。

Conclusion: LMMs在理解时间敏感知识方面存在显著不足，尤其是开源模型在某些特定领域表现较差。然而，知识编辑方法为更新LMMs中的时间敏感知识提供了有效的途径。

Abstract: Large Multimodal Models (LMMs) encode rich factual knowledge via cross-modal
pre-training, yet their static representations struggle to maintain an accurate
understanding of time-sensitive factual knowledge. Existing benchmarks remain
constrained by static designs, inadequately evaluating LMMs' ability to
understand time-sensitive knowledge. To address this gap, we propose MINED, a
comprehensive benchmark that evaluates temporal awareness along 6 key
dimensions and 11 challenging tasks: cognition, awareness, trustworthiness,
understanding, reasoning, and robustness. MINED is constructed from Wikipedia
by two professional annotators, containing 2,104 time-sensitive knowledge
samples spanning six knowledge types. Evaluating 15 widely used LMMs on MINED
shows that Gemini-2.5-Pro achieves the highest average CEM score of 63.07,
while most open-source LMMs still lack time understanding ability. Meanwhile,
LMMs perform best on organization knowledge, whereas their performance is
weakest on sport. To address these challenges, we investigate the feasibility
of updating time-sensitive knowledge in LMMs through knowledge editing methods
and observe that LMMs can effectively update knowledge via knowledge editing
methods in single editing scenarios.

</details>


### [159] [Scaf-GRPO: Scaffolded Group Relative Policy Optimization for Enhancing LLM Reasoning](https://arxiv.org/abs/2510.19807)
*Xichen Zhang,Sitong Wu,Yinghao Zhu,Haoru Tan,Shaozuo Yu,Ziyi He,Jiaya Jia*

Main category: cs.CL

TL;DR: 针对大型语言模型（LLMs）在强化学习中遇到的“学习悬崖”问题（即面对困难问题时奖励信号为零导致学习停滞），Scaf-GRPO提出了一种渐进式训练框架，通过分层提示引导模型克服瓶颈，显著提升了数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 可验证奖励的强化学习在增强LLMs复杂推理能力方面效果显著，但存在“学习悬崖”现象：当问题远超模型当前能力时，模型持续获得零奖励信号，导致策略优化算法（如GRPO）中的优势计算为零，使得这些难题对学习梯度“不可见”，从而阻碍了学习进展。

Method: Scaf-GRPO（Scaffolded Group Relative Policy Optimization）是一个渐进式训练框架。它首先诊断学习停滞，然后通过注入分层提示（从抽象概念到具体步骤）进行干预，仅在模型独立学习停滞时提供最小指导，以帮助模型独立构建有效解决方案。

Result: 在具有挑战性的数学基准测试中，Scaf-GRPO表现出卓越的有效性。它使Qwen2.5-Math-7B模型在AIME24基准测试上的pass@1分数相对于普通GRPO基线提高了44.3%。

Conclusion: Scaf-GRPO框架提供了一种稳健有效的方法，能够解锁模型解决以前无法触及问题的能力，这是扩展LLM自主推理前沿的关键一步。

Abstract: Reinforcement learning from verifiable rewards has emerged as a powerful
technique for enhancing the complex reasoning abilities of Large Language
Models (LLMs). However, these methods are fundamentally constrained by the
''learning cliff'' phenomenon: when faced with problems far beyond their
current capabilities, models consistently fail, yielding a persistent
zero-reward signal. In policy optimization algorithms like GRPO, this collapses
the advantage calculation to zero, rendering these difficult problems invisible
to the learning gradient and stalling progress. To overcome this, we introduce
Scaf-GRPO (Scaffolded Group Relative Policy Optimization), a progressive
training framework that strategically provides minimal guidance only when a
model's independent learning has plateaued. The framework first diagnoses
learning stagnation and then intervenes by injecting tiered in-prompt hints,
ranging from abstract concepts to concrete steps, enabling the model to
construct a valid solution by itself. Extensive experiments on challenging
mathematics benchmarks demonstrate Scaf-GRPO's effectiveness, boosting the
pass@1 score of the Qwen2.5-Math-7B model on the AIME24 benchmark by a relative
44.3% over a vanilla GRPO baseline. This result demonstrates our framework
provides a robust and effective methodology for unlocking a model's ability to
solve problems previously beyond its reach, a critical step towards extending
the frontier of autonomous reasoning in LLM.

</details>


### [160] [What is the Best Sequence Length for BABYLM?](https://arxiv.org/abs/2510.19493)
*Suchir Salhan,Richard Diehl Martinez,Zébulon Goriely,Paula Buttery*

Main category: cs.CL

TL;DR: 本文探讨了序列长度对BabyLM预训练的影响，发现最佳序列长度取决于任务和模型架构。


<details>
  <summary>Details</summary>
Motivation: 在BabyLM挑战中，尽管预训练数据集规模庞大，但许多提交的模型仍使用较短的序列长度。研究旨在确定训练BabyLM时应使用的最佳序列长度。

Method: 使用1亿词的训练数据和固定的计算预算，比较了1.25亿参数的Mamba和OPT模型，以评估不同序列长度的影响。

Result: 研究发现，虽然较长的序列通常更好，但最佳长度取决于任务和架构。较短的序列足以完成语法泛化任务，而较长的上下文则有利于形态类比推理任务。

Conclusion: 在训练BabyLM时，选择序列长度并非一概而论，应根据具体的任务和模型架构进行调整。

Abstract: Transformer language models typically operate with a fixed-length context
window, which has grown in step with large-scale pretraining datasets. In the
BabyLM Challenge, however, many past submissions have defaulted to using much
shorter sequence lengths. We examine the impact of sequence length on BabyLM
pretraining, to answer the simple question: what sequence length should we be
using when training Baby LMs? Using 100M-word training data and fixed compute
budgets, we compare 125M-parameter Mamba and OPT models, finding that although
longer is often better, the optimal length depends on both task and
architecture. Shorter sequences are sufficient for grammatical generalization
tasks whereas longer contexts benefit morphological analogical reasoning tasks.

</details>


### [161] [Machine Text Detectors are Membership Inference Attacks](https://arxiv.org/abs/2510.19492)
*Ryuto Koike,Liam Dugan,Masahiro Kaneko,Chris Callison-Burch,Naoaki Okazaki*

Main category: cs.CL

TL;DR: 本文理论和实证研究了成员推断攻击（MIAs）和机器生成文本检测方法之间的可迁移性，发现两者共享渐近最优指标，并实证证明了跨任务性能的强相关性，呼吁研究社区加强合作，并提出了统一评估套件MINT。


<details>
  <summary>Details</summary>
Motivation: 成员推断攻击（MIAs）和机器生成文本检测虽然目标不同，但都利用语言模型的概率分布信号。然而，这两个任务一直独立研究，可能导致忽视了对方任务中开发的更强方法和有价值的见解。

Method: 本文通过理论和实证方法进行研究。理论上，证明了在两个任务上均能实现渐近最高性能的指标是相同的，并在此最优指标的背景下统一了现有文献。实证上，进行了大规模实验，包括7种最先进的MIA方法和5种最先进的机器文本检测器，涵盖13个领域和10个生成器。此外，还引入了MINT，一个用于MIA和机器生成文本检测的统一评估套件。

Result: 理论结果表明，实现两个任务渐近最优性能的指标是相同的。实证结果显示，跨任务性能存在非常强的秩相关性（rho > 0.6）。值得注意的是，最初为机器文本检测设计的Binoculars方法在MIA基准测试上也取得了最先进的性能，证明了可迁移性的实际影响。

Conclusion: 研究结果强调了两个研究社区之间加强跨任务意识和协作的必要性。为促进跨任务发展和公平评估，本文引入了MINT，一个包含15种最新方法的统一评估套件。

Abstract: Although membership inference attacks (MIAs) and machine-generated text
detection target different goals, identifying training samples and synthetic
texts, their methods often exploit similar signals based on a language model's
probability distribution. Despite this shared methodological foundation, the
two tasks have been independently studied, which may lead to conclusions that
overlook stronger methods and valuable insights developed in the other task. In
this work, we theoretically and empirically investigate the transferability,
i.e., how well a method originally developed for one task performs on the
other, between MIAs and machine text detection. For our theoretical
contribution, we prove that the metric that achieves the asymptotically highest
performance on both tasks is the same. We unify a large proportion of the
existing literature in the context of this optimal metric and hypothesize that
the accuracy with which a given method approximates this metric is directly
correlated with its transferability. Our large-scale empirical experiments,
including 7 state-of-the-art MIA methods and 5 state-of-the-art machine text
detectors across 13 domains and 10 generators, demonstrate very strong rank
correlation (rho > 0.6) in cross-task performance. We notably find that
Binoculars, originally designed for machine text detection, achieves
state-of-the-art performance on MIA benchmarks as well, demonstrating the
practical impact of the transferability. Our findings highlight the need for
greater cross-task awareness and collaboration between the two research
communities. To facilitate cross-task developments and fair evaluations, we
introduce MINT, a unified evaluation suite for MIAs and machine-generated text
detection, with implementation of 15 recent methods from both tasks.

</details>


### [162] [Lookahead Routing for Large Language Models](https://arxiv.org/abs/2510.19506)
*Canbin Huang,Tianyuan Shi,Yuhua Zhu,Ruijun Chen,Xiaojun Quan*

Main category: cs.CL

TL;DR: Lookahead是一种新的LLM路由框架，通过预测潜在模型输出的隐式表示来指导模型选择，从而在不进行完全推理的情况下实现更明智的路由，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）路由器主要将路由视为基于输入查询的分类问题，忽略了潜在输出中的有用信息、隐含意图和上下文细微差别。这导致了次优的路由决策，尤其对于复杂或模糊的查询。

Method: 本文提出了Lookahead路由框架，它通过预测潜在模型输出的隐式表示来“预见”这些输出，并利用这些预测来指导模型选择，从而在不进行完全推理的情况下实现更明智的路由。该框架内实现了基于因果语言模型和掩码语言模型的两种方法。

Result: 在七个公共基准测试（涵盖指令遵循、数学推理和代码生成）上的实证评估表明，Lookahead持续优于现有路由基线，平均性能比现有最先进技术提升7.7%。

Conclusion: Lookahead框架通过预见潜在模型输出的隐式表示，能够做出更明智的路由决策，显著提高了多模型LLM系统的效率和性能。

Abstract: Large language model (LLM) routers improve the efficiency of multi-model
systems by directing each query to the most appropriate model while leveraging
the diverse strengths of heterogeneous LLMs. Most existing approaches frame
routing as a classification problem based solely on the input query. While this
reduces overhead by avoiding inference across all models, it overlooks valuable
information that could be gleaned from potential outputs and fails to capture
implicit intent or contextual nuances that often emerge only during response
generation. These limitations can result in suboptimal routing decisions,
particularly for complex or ambiguous queries that require deeper semantic
understanding. To address this challenge, we propose Lookahead, a routing
framework that "foresees" potential model outputs by predicting their latent
representations and uses these predictions to guide model selection, thus
enabling more informed routing without full inference. Within this framework,
we implement two approaches based on causal and masked language models.
Empirical evaluations across seven public benchmarks - spanning instruction
following, mathematical reasoning, and code generation - show that Lookahead
consistently outperforms existing routing baselines, achieving an average
performance gain of 7.7% over the state-of-the-art. Our code is available at
https://github.com/huangcb01/lookahead-routing.

</details>


### [163] [Which Evaluation for Which Model? A Taxonomy for Speech Model Assessment](https://arxiv.org/abs/2510.19509)
*Maureen de Seyssel,Eeshan Gunesh Dhekane*

Main category: cs.CL

TL;DR: 本文提出了一种统一的分类法，用于指导如何为不同的语音基础模型选择合适的评估方法，并揭示了现有评估中的不足。


<details>
  <summary>Details</summary>
Motivation: 语音基础模型在多任务上取得了显著进展，但其评估在任务和模型类型之间是分散的，不同的模型需要不同的评估协议，缺乏统一的指导。

Method: 本文提出了一种统一的分类法，包含三个正交维度：评估的方面、完成任务所需的模型能力以及执行任务所需的任务/协议要求。作者将现有的广泛评估和基准（涵盖表征学习、语音生成、交互式对话等）沿着这些维度进行分类。

Result: 该分类法提供了一个原则性的框架，将每个评估映射到模型所暴露的能力（例如语音生成、实时处理）及其方法学要求（例如微调数据、人类判断），从而将模型与合适的评估方法对齐。此外，它还揭示了现有评估中系统性的空白，例如韵律、交互或推理的覆盖有限，这为未来的基准设计指明了方向。

Conclusion: 这项工作为选择、解释和扩展语音模型的评估提供了概念基础和实用指南，并突出了未来基准设计需要优先关注的领域。

Abstract: Speech foundation models have recently achieved remarkable capabilities
across a wide range of tasks. However, their evaluation remains disjointed
across tasks and model types. Different models excel at distinct aspects of
speech processing and thus require different evaluation protocols. This paper
proposes a unified taxonomy that addresses the question: Which evaluation is
appropriate for which model? The taxonomy defines three orthogonal axes: the
\textbf{evaluation aspect} being measured, the model capabilities required to
attempt the task, and the task or protocol requirements needed to perform it.
We classify a broad set of existing evaluations and benchmarks along these
axes, spanning areas such as representation learning, speech generation, and
interactive dialogue. By mapping each evaluation to the capabilities a model
exposes (e.g., speech generation, real-time processing) and to its
methodological demands (e.g., fine-tuning data, human judgment), the taxonomy
provides a principled framework for aligning models with suitable evaluation
methods. It also reveals systematic gaps, such as limited coverage of prosody,
interaction, or reasoning, that highlight priorities for future benchmark
design. Overall, this work offers a conceptual foundation and practical guide
for selecting, interpreting, and extending evaluations of speech models.

</details>


### [164] [Conditions for Catastrophic Forgetting in Multilingual Translation](https://arxiv.org/abs/2510.19546)
*Danni Liu,Jan Niehues*

Main category: cs.CL

TL;DR: 该研究系统性地探究了多语言模型在特定语言上微调时灾难性遗忘的触发条件，发现模型与数据规模的相对比例是主要决定因素，指令遵循能力比模型架构更关键，且跨语言对齐可有效缓解遗忘。


<details>
  <summary>Details</summary>
Motivation: 多语言基础模型在特定语言上微调时常导致灾难性遗忘，降低对未见语言的性能，但文献中关于遗忘发生条件的结论分散且模糊，因此需要一项系统性研究来明确触发条件。

Method: 采用机器翻译作为实验平台进行系统性实证研究，通过在不同模型架构、数据规模和微调方法下进行受控实验，以识别多语言微调中触发灾难性遗忘的条件。

Result: 研究发现，模型与数据大小的相对比例是遗忘的主要决定因素；模型的指令遵循能力对于保留多语言知识比其架构更关键；参数高效微调在缓解遗忘方面并未显示出比完全微调更明显的优势；跨语言对齐可以减轻遗忘，并促进对未见目标语言的正向迁移。

Conclusion: 灾难性遗忘主要由模型与数据规模的相对比例决定，模型的指令遵循能力对多语言知识保留至关重要，而非架构本身。参数高效微调在缓解遗忘方面无明显优势。跨语言对齐是一种有效的缓解遗忘并促进积极迁移的策略。

Abstract: Fine-tuning multilingual foundation models on specific languages often
induces catastrophic forgetting, degrading performance on languages unseen in
fine-tuning. While this phenomenon is widely-documented, the literature
presents fragmented results about when forgetting occurs. To address this
ambiguity, we conduct a systematic empirical study using machine translation as
a testbed to identify the conditions that trigger catastrophic forgetting in
multilingual fine-tuning. Through controlled experiments across different model
architectures, data scales, and fine-tuning approaches, we reveal that the
relative scale between model and data size is a primary determinant of
forgetting. Moreover, we demonstrate that a model's instruction-following
ability is more critical for retaining multilingual knowledge than its
architecture. Contrary to assumptions, parameter-efficient fine-tuning offers
no clear advantage over full fine-tuning in mitigating forgetting. Lastly, we
show that cross-lingual alignment can mitigate forgetting while also
facilitating positive transfer to unseen target languages.

</details>


### [165] [PBBQ: A Persian Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models](https://arxiv.org/abs/2510.19616)
*Farhan Farsi,Shayan Bali,Fatemeh Valeh,Parsa Ghofrani,Alireza Pakniat,Kian Kashfipour,Amir H. Payberah*

Main category: cs.CL

TL;DR: 本文引入了PBBQ数据集，这是一个用于评估波斯语大型语言模型（LLMs）中社会偏见的综合基准。研究发现，当前LLMs在波斯文化中表现出显著的社会偏见，并常复制人类偏见模式。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用，确保其符合社会规范变得至关重要。尽管已有研究关注多语言偏见检测，但在解决波斯文化背景下的社会偏见方面，资源存在显著空白。

Method: 研究通过与社会科学专家紧密合作，设计了一项问卷调查，由250名来自不同人口统计学背景的个体完成，涵盖16个文化类别。基于此，构建了包含超过37,000个问题的PBBQ数据集。随后，使用PBBQ对多个开源LLMs、一个闭源模型和波斯语特化微调模型进行了基准测试，并将模型输出与人类回答进行了比较。

Result: 研究发现，当前的LLMs在波斯文化中表现出显著的社会偏见。此外，通过与人类回答的比较，观察到LLMs经常复制人类的偏见模式，这突显了所学表征与文化刻板印象之间复杂的相互作用。

Conclusion: LLMs在波斯文化中存在显著的社会偏见，这些偏见反映了学习到的表征和文化刻板印象之间的复杂相互作用。PBBQ数据集的发布将为未来评估和缓解波斯语模型中的偏见提供基础。

Abstract: With the increasing adoption of large language models (LLMs), ensuring their
alignment with social norms has become a critical concern. While prior research
has examined bias detection in various languages, there remains a significant
gap in resources addressing social biases within Persian cultural contexts. In
this work, we introduce PBBQ, a comprehensive benchmark dataset designed to
evaluate social biases in Persian LLMs. Our benchmark, which encompasses 16
cultural categories, was developed through questionnaires completed by 250
diverse individuals across multiple demographics, in close collaboration with
social science experts to ensure its validity. The resulting PBBQ dataset
contains over 37,000 carefully curated questions, providing a foundation for
the evaluation and mitigation of bias in Persian language models. We benchmark
several open-source LLMs, a closed-source model, and Persian-specific
fine-tuned models on PBBQ. Our findings reveal that current LLMs exhibit
significant social biases across Persian culture. Additionally, by comparing
model outputs to human responses, we observe that LLMs often replicate human
bias patterns, highlighting the complex interplay between learned
representations and cultural stereotypes.Upon acceptance of the paper, our PBBQ
dataset will be publicly available for use in future work. Content warning:
This paper contains unsafe content.

</details>


### [166] [LLavaCode: Compressed Code Representations for Retrieval-Augmented Code Generation](https://arxiv.org/abs/2510.19644)
*Daria Cherniuk,Nikita Sukhorukov,Nikita Sushko,Daniil Gusak,Danil Sivtsov,Elena Tutubalina,Evgeny Frolov*

Main category: cs.CL

TL;DR: LlavaCode通过将代码上下文压缩成紧凑的语义表示，显著提升了代码补全中检索增强生成（RAG）的速度和质量，特别是在TTFT方面有20-38%的改进。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）在代码补全中表现出色，尤其是在需要代码库上下文时。然而，整合大量上下文会导致序列长度显著增加，从而降低推理速度，这对于集成开发环境（IDE）等交互式设置是一个关键限制。

Method: 该研究引入了LlavaCode框架，它将代码压缩成紧凑、语义丰富的表示，这些表示可由代码大型语言模型（LLM）解释。通过一个小型投影模块，检索到的上下文被缩减为几个压缩的单token向量。

Result: 实验表明，LlavaCode在编码模型的EM和ES指标上实现了显著提升，同时延迟增加可忽略不计。与完整的RAG管道相比，在行补全任务中，压缩上下文使首个token生成时间（TTFT）减少了20-38%。

Conclusion: LlavaCode通过将代码上下文压缩成紧凑表示，有效解决了RAG在代码补全中因长上下文导致的推理速度慢的问题，显著缩短了TTFT，同时提高了生成质量，使其更适用于交互式开发环境。

Abstract: Retrieval-augmented generation has emerged as one of the most effective
approaches for code completion, particularly when context from a surrounding
repository is essential. However, incorporating context significantly extends
sequence length, leading to slower inference - a critical limitation for
interactive settings such as IDEs. In this work, we introduce LlavaCode, a
framework that compresses code into compact, semantically rich representations
interpretable by code LLM, enhancing generation quality while reducing the
retrieved context to only a few compressed single-token vectors. Using a small
projector module we can significantly increase the EM and ES metrics of coding
model with negligible latency increase. Our experiments demonstrate that
compressed context enables 20-38% reduction in Time-to-First-Token (TTFT) on
line completion tasks compared to full-RAG pipelines.

</details>


### [167] [CrossNews-UA: A Cross-lingual News Semantic Similarity Benchmark for Ukrainian, Polish, Russian, and English](https://arxiv.org/abs/2510.19628)
*Daryna Dementieva,Evgeniya Sukhodolskaya,Alexander Fraser*

Main category: cs.CL

TL;DR: 本文提出了一种可扩展、可解释的众包流程，用于跨语言新闻相似度评估，并收集了一个新的乌克兰语新闻数据集CrossNews-UA，同时测试了多种模型以分析多语言新闻的挑战。


<details>
  <summary>Details</summary>
Motivation: 在社交网络时代，虚假信息传播迅速，跨语言假新闻检测（尤其是非英语语言）面临巨大挑战。现有跨语言新闻分析数据集依赖人工策展，限制了其可扩展性和对新语言的适应性。

Method: 引入了一个可扩展、可解释的众包流程，用于跨语言新闻相似度评估。利用该流程收集了CrossNews-UA数据集，包含以乌克兰语为中心与波兰语、俄语和英语的新闻对，并使用4W（Who, What, Where, When）标准进行语义相似度标注和详细理由说明。测试了从传统词袋模型到Transformer架构和大型语言模型（LLMs）等多种模型。

Result: 成功收集了一个新颖的跨语言新闻数据集CrossNews-UA。测试结果揭示了多语言新闻分析中的挑战，并提供了模型性能的见解。

Conclusion: 该工作通过提出可扩展的众包流程和构建新的数据集，解决了跨语言新闻分析中可扩展性和适应性的空白，并深入探讨了多语言新闻分析中模型性能的挑战。

Abstract: In the era of social networks and rapid misinformation spread, news analysis
remains a critical task. Detecting fake news across multiple languages,
particularly beyond English, poses significant challenges. Cross-lingual news
comparison offers a promising approach to verify information by leveraging
external sources in different languages (Chen and Shu, 2024). However, existing
datasets for cross-lingual news analysis (Chen et al., 2022a) were manually
curated by journalists and experts, limiting their scalability and adaptability
to new languages. In this work, we address this gap by introducing a scalable,
explainable crowdsourcing pipeline for cross-lingual news similarity
assessment. Using this pipeline, we collected a novel dataset CrossNews-UA of
news pairs in Ukrainian as a central language with linguistically and
contextually relevant languages-Polish, Russian, and English. Each news pair is
annotated for semantic similarity with detailed justifications based on the 4W
criteria (Who, What, Where, When). We further tested a range of models, from
traditional bag-of-words, Transformer-based architectures to large language
models (LLMs). Our results highlight the challenges in multilingual news
analysis and offer insights into models performance.

</details>


### [168] [DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference](https://arxiv.org/abs/2510.19669)
*Xiang Liu,Xuming Hu,Xiaowen Chu,Eunsol Choi*

Main category: cs.CL

TL;DR: 该研究通过分析LLM推理轨迹的熵，发现其与问题难度呈U型关系，并提出了DiffAdapt框架，根据问题难度和推理熵动态调整推理策略，显著提高了LLM推理的效率并降低了token使用量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在解决问题时常生成冗长的思考轨迹，其效用不明确，且存在“过度思考”现象，尤其是在简单问题上，导致效率低下。

Method: 1. 分析推理轨迹中token概率的熵，发现其与问题难度呈U型模式，即简单和困难问题熵高，中等难度问题熵低。2. 基于此洞察，引入DiffAdapt框架，根据问题难度和推理轨迹熵为每个问题选择“简单/正常/困难”推理策略。3. 每种策略包含固定的提示、温度和最大token长度。4. DiffAdapt不微调基础LLM，而是训练一个小型探测器来分类LLM的最终隐藏状态，以实现廉价的适应性。

Result: 在五种模型和八个基准测试中，DiffAdapt方法在保持或提高准确性的同时，将token使用量减少了高达22.4%。

Conclusion: 该研究为计算高效的推理提供了一条实用路径，通过基于问题难度和推理轨迹熵自适应调整推理策略，实现了LLM推理性能与效率的平衡。

Abstract: Recent reasoning Large Language Models (LLMs) demonstrate remarkable
problem-solving abilities but often generate long thinking traces whose utility
is unclear. Our work aims to improve their efficiency, enabling them to reach
high performance without overthinking. First, we analyze the entropy of token
probabilities in reasoning traces. Across three models, we observe a consistent
U-shaped entropy pattern: high entropy on easy problems despite high accuracy,
low entropy on problems with medium difficulty, and high entropy on hard
problems reflecting uncertainty. Specifically, we notice 22--25\% entropy
reduction from easy to medium difficulty regions, suggesting an {overthinking}
phenomenon on easy instances. Building on these insights, we introduce
\textbf{DiffAdapt}, a lightweight framework that selects Easy/Normal/Hard
inference strategies per question based on their difficulty and reasoning trace
entropy. Each inference strategy consists of a fixed prompt, temperature and
maximum token length. In contrast to existing efficiency optimization methods,
our approach does not fine-tune base LLM but a small probe that classifies
LLM's final hidden state, allowing inexpensive adaptation. We comprehensively
evaluate our method on five models and eight benchmarks. Our method achieves
comparable or improved accuracy while reducing token usage by up to 22.4\%,
establishing a practical path toward compute-efficient reasoning.

</details>


### [169] [CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation](https://arxiv.org/abs/2510.19670)
*Hasan Akgul,Mari Eplik,Javier Rojas,Aina Binti Abdullah,Pieter van der Merwe*

Main category: cs.CL

TL;DR: CoSense-LLM是一个边缘优先的框架，它将连续的多模态传感器数据转换为紧凑、可验证的语义令牌，并与大型语言模型协同工作，同时满足延迟、能耗、带宽和隐私约束。


<details>
  <summary>Details</summary>
Motivation: 将多模态传感器数据流（如Wi-Fi CSI、IMU、音频、RFID、轻量级视觉）转化为可供大型语言模型处理的语义令牌，同时严格控制延迟、能耗、带宽和隐私。

Method: CoSense-LLM包含四个核心部分：(i) SenseFusion，一个轻量级编码器，用于对齐传感器嵌入并将其压缩为离散代码序列；(ii) Edge-RAG，一个本地混合检索层，用于根据站点特定策略和笔记进行生成；(iii) PromptRouter，一个成本和不确定性感知策略，用于选择纯边缘生成、边缘加检索或紧凑云升级；(iv) Secure Execution，一个可审计的修订路径，确保原始波形数据不离开设备以保护隐私。该系统还利用了现代服务优化技术，如分页KV缓存、FlashAttention、推测解码和量化LoRA适配器。

Result: CoSense-LLM在家庭、办公室和诊所部署中提供了有根据的解释，并满足了严格的服务水平目标：在边缘主导路径上实现了亚秒级（p95）端到端延迟，通过优先本地检索响应减少了层间令牌和带宽成本，并通过仅传输离散代码和修订后的元数据保护了隐私。消融实验表明，Edge-RAG提高了事实一致性并减少了矛盾，校准的不确定性实现了选择性弃权和受控升级，KV缓存和解码加速器降低了每次决策的能耗。

Conclusion: 研究结果支持一种边缘优先的设计理念，该设计将语义、隐私和可预测的延迟视为在易受干扰环境中部署大型模型的同等重要目标。

Abstract: We present CoSense-LLM, an edge-first framework that turns continuous
multimodal sensor streams (for example Wi-Fi CSI, IMU, audio, RFID, and
lightweight vision) into compact, verifiable semantic tokens and coordinates
with large language models under explicit latency, energy, bandwidth, and
privacy constraints. CoSense-LLM has four parts: (i) SenseFusion, a lightweight
encoder that aligns sensor embeddings with language and compresses them into
short discrete code sequences; (ii) Edge-RAG, a local hybrid retrieval layer
that grounds generation in site specific policies and notes; (iii)
PromptRouter, a cost and uncertainty aware policy that selects edge only
generation, edge plus retrieval, or compact cloud escalation; and (iv) Secure
Execution, an auditable redaction path that enforces data minimization so raw
waveforms never leave the device. The system works with modern serving
optimizations, including paged or streaming KV caches, FlashAttention style
kernels, speculative decoding, and quantized LoRA adapters, and supports on
device personalization and federated updates under non IID drift. Across home,
office, and clinic deployments, CoSense-LLM delivers grounded explanations
while meeting tight service level objectives: it sustains sub second (p95) end
to end latency on edge dominant paths, reduces inter tier token and bandwidth
costs by preferring local retrieval grounded responses, and preserves privacy
by transmitting only discrete codes and redacted metadata. Ablations show that
Edge-RAG improves factual consistency and reduces contradictions, calibrated
uncertainty enables selective abstention and controlled escalations, and KV
plus decoding accelerators lower energy per decision. The results support an
edge first design that treats semantics, privacy, and predictable latency as co
equal goals for large model deployments in interference prone environments.

</details>


### [170] [Zhyper: Factorized Hypernetworks for Conditioned LLM Fine-Tuning](https://arxiv.org/abs/2510.19733)
*M. H. I. Abdalla,Zhipin Wang,Christian Frey,Steffen Eger,Josif Grabocka*

Main category: cs.CL

TL;DR: Zhyper是一个参数高效的分解超网络框架，通过文本描述生成上下文感知的LoRA适配器，解决了LLM条件化中提示工程不足和现有微调方法参数过多的问题，并在多个基准测试中表现出色，尤其在文化对齐方面。


<details>
  <summary>Details</summary>
Motivation: 由于预训练和对齐数据集的归纳偏差，提示工程无法确保LLM按照期望的条件（如文化规范、政治立场）生成内容。现有的直接条件化LoRA权重的微调方法引入了大量参数，缺乏效率。

Method: 本文提出了Zhyper，一个参数高效的分解超网络框架。该框架能够根据文本描述生成上下文感知的LoRA适配器。

Result: 实验结果表明，Zhyper在多个基准测试中达到了与最先进基线相当的性能，但参数量减少了高达26倍。此外，Zhyper在文化对齐方面表现出更好的域外泛化能力，并能更好地捕捉细粒度的上下文价值。

Conclusion: Zhyper提供了一种参数高效的解决方案，有效解决了大型语言模型条件化中的挑战。它通过生成上下文感知的LoRA适配器，在保持竞争性性能的同时显著减少了参数量，并在文化对齐等任务中展现出卓越的泛化能力和对细微上下文价值的捕捉能力。

Abstract: Large Language Model (LLM) conditioning refers to instructing an LLM to
generate content in accordance with the norms and values of a specific culture,
beliefs of a particular political orientation, or any desired text-specified
semantic conditioning. Unfortunately, prompt engineering does not ensure that
LLMs behave in accordance with a desired conditioning due to the inductive bias
of the pre-training and alignment datasets. Prior works have focused on
fine-tuning LLMs by directly conditioning the LoRA weights; however, such
methods introduce a large number of parameters. As a remedy, we propose Zhyper,
a parameter-efficient factorized hypernetwork framework that generates
context-aware LoRA adapters from textual descriptions. Experiments on multiple
benchmarks show that Zhyper achieves competitive performance with up to 26x
fewer parameters than the state-of-the-art baselines. Furthermore, we extend
Zhyper to cultural alignment, demonstrating improved generalization to
out-of-domain settings and a better capturing of fine-grained contextual
values.

</details>


### [171] [From Answers to Guidance: A Proactive Dialogue System for Legal Documents](https://arxiv.org/abs/2510.19723)
*Ashish Chouhan,Michael Gertz*

Main category: cs.CL

TL;DR: 本文介绍了EUDial数据集和LexGuide框架，旨在通过主动式多轮对话系统帮助非专业人士理解复杂的欧盟法律信息。


<details>
  <summary>Details</summary>
Motivation: 尽管欧盟提供了开放的法律信息，但非专业人士在理解和应用这些复杂的机构文本时面临持续挑战。

Method: 构建了EUDial数据集，该数据集包含来自204个欧盟博客的880个对话轮次（平均每对话4.3轮），包括初始问题、结构化答案和后续问题。提出LexGuide框架，该框架利用检索增强生成（RAG）和分层主题组织来构建对话流程，确保法律方面的全面覆盖和对话轮次间的连贯性。

Result: 研究结果表明，主动的、结构化的导航弥合了法律信息可及性与公民理解之间的鸿沟，证明EUDial和LexGuide是推进主动式法律对话系统的实用资源。

Conclusion: EUDial数据集和LexGuide框架为开发能够帮助非专业人士理解复杂法律文本的主动式法律对话系统提供了实用工具，有效提升了公民对法律信息的理解。

Abstract: The accessibility of legal information remains a constant challenge,
particularly for laypersons seeking to understand and apply complex
institutional texts. While the European Union provides open access to
legislation, parliamentary responses, and regulatory documents, these resources
can be challenging for laypeople to explore. In this paper, we introduce
EUDial, a proactive multi-turn dialogue dataset constructed from 204 blogs
curated by the Citizens' Enquiries Unit (AskEP) of the European Parliamentary
Research Service. EUDial contains 880 dialogue turns (averaging 4.3 turns per
dialogue), where each dialogue includes initial questions, structured answers,
and follow-up questions. Beyond dataset construction, we propose the LexGuide
framework that leverages retrieval-augmented generation with hierarchical topic
organization to structure dialogue progression, ensuring both comprehensive
coverage of legal aspects and coherence across conversational turns. The
results demonstrate that proactive, structured navigation closes the gap
between the availability of legal information and citizen comprehension,
establishing EUDial and LexGuide as practical resources for advancing proactive
legal dialogue systems.

</details>


### [172] [ToolDreamer: Instilling LLM Reasoning Into Tool Retrievers](https://arxiv.org/abs/2510.19791)
*Saptarshi Sengupta,Zhengyu Zhou,Jun Araki,Xingbo Wang,Bingqing Wang,Suhang Wang,Zhe Feng*

Main category: cs.CL

TL;DR: ToolDreamer通过使用LLM生成的假设性工具描述来改进工具检索，从而更好地对齐查询与工具，解决了LLM处理大型工具集时上下文窗口限制的问题。


<details>
  <summary>Details</summary>
Motivation: 当LLM需要处理大量工具时，将所有工具信息放入上下文窗口会导致溢出。现有检索模型通过用户查询与工具描述（TD）的相似性来排名工具，但这种直接匹配通常不理想，因为用户请求的语言与TD的语言不一致，导致检索效果不佳。

Method: ToolDreamer框架利用LLM生成假设性（合成）的工具描述，即LLM认为可能对查询有用的工具描述。然后，检索模型根据这些假设性TD来获取工具，从而在TD的语言空间内实现查询与工具之间更自然的对齐。

Result: 在ToolRet数据集上应用ToolDreamer，结果表明该方法显著提高了稀疏和密集检索器的性能，无论是否经过训练，都展现了其灵活性和有效性。

Conclusion: ToolDreamer通过将部分推理负担转移到检索器，使LLM能够有效处理大量工具集合，而不会使其上下文窗口过载，从而提高了LLM在工具调用方面的效率和能力。

Abstract: Tool calling has become increasingly popular for Large Language Models
(LLMs). However, for large tool sets, the resulting tokens would exceed the
LLM's context window limit, making it impossible to include every tool. Hence,
an external retriever is used to provide LLMs with the most relevant tools for
a query. Existing retrieval models rank tools based on the similarity between a
user query and a tool description (TD). This leads to suboptimal retrieval as
user requests are often poorly aligned with the language of TD. To remedy the
issue, we propose ToolDreamer, a framework to condition retriever models to
fetch tools based on hypothetical (synthetic) TD generated using an LLM, i.e.,
description of tools that the LLM feels will be potentially useful for the
query. The framework enables a more natural alignment between queries and tools
within the language space of TD's. We apply ToolDreamer on the ToolRet dataset
and show that our method improves the performance of sparse and dense
retrievers with and without training, thus showcasing its flexibility. Through
our proposed framework, our aim is to offload a portion of the reasoning burden
to the retriever so that the LLM may effectively handle a large collection of
tools without inundating its context window.

</details>


### [173] [Adapting Multilingual Models to Code-Mixed Tasks via Model Merging](https://arxiv.org/abs/2510.19782)
*Prashant Kodali,Vaishnavi Shivkumar,Swarang Joshi,Monojit Choudhary,Ponnurangam Kumaraguru,Manish Shrivastava*

Main category: cs.CL

TL;DR: 本研究提出了一种模型合并策略，作为处理代码混合自然语言处理任务的传统适应策略的替代方案。结果显示，与完全微调和持续预训练后微调相比，合并模型在性能上表现更优，并能更有效地利用无标签数据，在跨语言对迁移方面也更强。


<details>
  <summary>Details</summary>
Motivation: 传统的适应策略在代码混合自然语言处理任务中可能不够理想，需要一种更实用、更有效的方法来利用无标签数据和提升模型性能。

Method: 研究人员从一个多语言基础模型开始，首先对无标签的代码混合文本进行持续预训练（CPT）以获得一个适应后的检查点，然后将该检查点与基础模型合并，最后在下游任务数据上进行微调（FT）。他们使用XLM-R和Llama-3.2-1B模型，在英语-印地语（En-Hi）和英语-西班牙语（En-Es）的句子分类（情感和仇恨言论）任务上评估了该方法。此外，还与大型语言模型的零/少样本提示以及跨语言对迁移进行了比较。

Result: 合并模型始终优于完全微调和CPT->FT策略，在F1分数上比完全微调高出2-5个点，比CPT->FT高出约1-2个点，表明合并能更有效地利用无标签数据。大型LLMs（如Llama-3.3-70B）的零/少样本提示在代码混合输入上落后于微调和合并的检查点。合并检查点在跨语言对迁移（例如在En-Ta和En-Ml上评估）方面也比单语英语基线表现更强（F1分数达到0.65-0.68，而完全微调为0.61-0.63）。

Conclusion: 模型合并是代码混合自然语言处理的一种有效适应策略，它能更有效地利用无标签数据，并在低资源语言对上提供更可靠的知识基础。研究提出了针对不同数据状况（仅有标签、有标签+无标签、仅迁移）的适应方案，并讨论了局限性和扩展性考量。

Abstract: We study model merging as a practical alternative to conventional adaptation
strategies for code-mixed NLP. Starting from a multilingual base model, we: (i)
perform continued pre-training (CPT) on unlabeled code-mixed text to obtain an
adapted checkpoint, (ii) merge checkpoint with the base model, and (iii)
fine-tune (FT) on the downstream task data. We evaluate our approach for
sentence classification (sentiment and hate speech) task in English-Hindi
(En-Hi) and English-Spanish (En-Es) using XLM-R and Llama-3.2-1B models. Our
results show that merged models consistently outperform full fine-tuning and
CPT->FT. We observe gains of 2--5 points in F1 over full fine-tuning and ~1-2
points over CPT->FT, indicating that unlabeled data is leveraged more
effectively via merging than via CPT alone. Zero-/few-shot prompting with
larger LLMs (e.g., Llama-3.3-70B) lags behind fine-tuned and merged
checkpoints, underscoring limits of in-context learning for code-mixed inputs.
We further test cross-pair transfer by training on En-Hi and evaluating on
En-Ta and En-Ml: merged checkpoints transfer more strongly than
monolingual-English baselines (e.g., TV/TIES variants reaching 0.65-0.68 F1 vs
0.61-0.63 for full fine-tuning), suggesting that code-mixed knowledge is a more
reliable substrate for low-resource pairs. We conclude with adaptation recipes
matched to common data regimes (labeled only; labeled+unlabeled; transfer-only)
and discuss limitations and scaling considerations for broader tasks and larger
models.

</details>


### [174] [The Art of Asking: Multilingual Prompt Optimization for Synthetic Data](https://arxiv.org/abs/2510.19806)
*David Mora,Viraat Aryabumi,Wei-Yin Ko,Sara Hooker,Julia Kreutzer,Marzieh Fadaee*

Main category: cs.CL

TL;DR: 该研究提出通过优化提示词空间而非仅依赖翻译来提升多语言大型语言模型（LLM）的性能，使其更具文化适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 合成数据是扩展LLM的关键，但其多语言应用受限于基于翻译的提示词，这导致模型继承了以英语为中心的设计和风格，忽视了文化维度，最终限制了模型的泛化能力。

Method: 引入了一个轻量级的提示词空间优化框架，系统地对翻译后的提示词进行自然度、文化适应性和难度增强的转换。研究将这些转换应用于涵盖7个语系的12种语言的提示词，并使用现成的多语言LLM进行验证。

Result: 在相同数据条件下，与仅翻译的基线相比，该方法取得了显著且一致的下游改进：Global-MMLU准确率提高4.7%，Flores XCometXL提高2.4%，mArenaHard偏好胜出率提高35.3%。

Conclusion: 提示词空间优化是一种简单而强大的范式，能够构建更鲁棒、更具文化基础和全球能力的多语言LLM。

Abstract: Synthetic data has become a cornerstone for scaling large language models,
yet its multilingual use remains bottlenecked by translation-based prompts.
This strategy inherits English-centric framing and style and neglects cultural
dimensions, ultimately constraining model generalization. We argue that the
overlooked prompt space-the very inputs that define training
distributions-offers a more powerful lever for improving multilingual
performance. We introduce a lightweight framework for prompt-space
optimization, where translated prompts are systematically transformed for
Naturalness, Cultural Adaptation, and Difficulty Enhancement. Using an
off-the-shelf multilingual LLM, we apply these transformations to prompts for
12 languages spanning 7 families. Under identical data conditions, our
approaches achieve substantial and consistent downstream improvements over the
translation-only baseline: +4.7% on Global-MMLU accuracy, +2.4% on Flores
XCometXL and +35.3% wins in preferences on mArenaHard. We establish
prompt-space optimization as a simple yet powerful paradigm for building
multilingual LLMs that are more robust, culturally grounded, and globally
capable.

</details>


### [175] [Hubble: a Model Suite to Advance the Study of LLM Memorization](https://arxiv.org/abs/2510.19811)
*Johnny Tian-Zheng Wei,Ameya Godbole,Mohammad Aflah Khan,Ryan Wang,Xiaoyuan Zhu,James Flemings,Nitya Kashyap,Krishna P. Gummadi,Willie Neiswanger,Robin Jia*

Main category: cs.CL

TL;DR: Hubble是一个开源大型语言模型套件，用于研究LLM的记忆化问题，揭示了敏感数据频率与训练语料库大小以及训练阶段对记忆化的影响，并提出了稀释和提前暴露敏感数据的最佳实践。


<details>
  <summary>Details</summary>
Motivation: 研究并解决大型语言模型（LLM）的记忆化风险，特别是模型如何记忆敏感数据。

Method: 开发了Hubble LLM套件，包含标准和扰动变体。扰动模型通过控制性地插入特定文本（如书籍段落、传记、测试集）来模拟记忆化风险。模型参数范围为1B或8B，预训练令牌量为100B或500B。此外，还研究了在不同预训练阶段插入文本对记忆化的影响。

Result: 研究发现，记忆化风险取决于敏感数据相对于训练语料库大小的频率（即在小语料库中出现一次的密码比在大语料库中记忆得更好）。同时，没有持续暴露的敏感数据可能会被遗忘。Hubble模型还被证明是成员推理和机器遗忘研究的理想测试平台。

Conclusion: 为解决记忆化风险，建议采取两项最佳实践：通过增加训练语料库大小来稀释敏感数据，以及将敏感数据安排在训练早期出现。Hubble模型套件能够支持广泛的记忆化研究，并鼓励社区在此基础上进行探索和基准测试。

Abstract: We present Hubble, a suite of fully open-source large language models (LLMs)
for the scientific study of LLM memorization. Hubble models come in standard
and perturbed variants: standard models are pretrained on a large English
corpus, and perturbed models are trained in the same way but with controlled
insertion of text (e.g., book passages, biographies, and test sets) designed to
emulate key memorization risks. Our core release includes 8 models -- standard
and perturbed models with 1B or 8B parameters, pretrained on 100B or 500B
tokens -- establishing that memorization risks are determined by the frequency
of sensitive data relative to size of the training corpus (i.e., a password
appearing once in a smaller corpus is memorized better than the same password
in a larger corpus). Our release also includes 6 perturbed models with text
inserted at different pretraining phases, showing that sensitive data without
continued exposure can be forgotten. These findings suggest two best practices
for addressing memorization risks: to dilute sensitive data by increasing the
size of the training corpus, and to order sensitive data to appear earlier in
training. Beyond these general empirical findings, Hubble enables a broad range
of memorization research; for example, analyzing the biographies reveals how
readily different types of private information are memorized. We also
demonstrate that the randomized insertions in Hubble make it an ideal testbed
for membership inference and machine unlearning, and invite the community to
further explore, benchmark, and build upon our work.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [176] [SHRUMS: Sensor Hallucination for Real-time Underwater Motion Planning with a Compact 3D Sonar](https://arxiv.org/abs/2510.18996)
*Susheel Vadakkekuruppath,Herman B. Amundsen,Jason M. O'Kane,Marios Xanthidis*

Main category: cs.RO

TL;DR: 本文介绍了一种名为SHRUMS的新型水下3D导航管线，首次集成了3D声纳，通过“传感器幻觉”概念在复杂和低能见度环境中实现鲁棒的实时运动规划。


<details>
  <summary>Details</summary>
Motivation: 尽管陆地和空中导航因激光雷达等距离传感器而取得重大进展，但水下机器人缺乏具有类似能力的紧凑型传感器。最近出现的3D声纳为解决这一问题提供了可能，但需要新的导航方案来利用这些新型传感器数据。

Method: 本文提出SHRUMS（Sensor Hallucination for Robust Underwater Motion planning with 3D Sonar）水下3D导航管线。该方法引入了“传感器幻觉”概念，通过从不存在的传感器中幻觉出具有任意参数的测量值，以适应新型3D声纳数据的复杂性，并实现实时局部最优性能。

Result: SHRUMS管线在复杂3D环境和极差能见度条件下表现出强大的鲁棒性。它利用真实的3D声纳数据和实时构建的局部地图进行了验证，实现了实时局部最优性能。

Conclusion: SHRUMS是首个集成3D声纳的水下自主导航堆栈，通过引入“传感器幻觉”概念，成功解决了新型3D声纳数据的复杂性，为水下机器人提供了在挑战性环境中进行鲁棒、实时3D导航的有效解决方案。

Abstract: Autonomous navigation in 3D is a fundamental problem for autonomy. Despite
major advancements in terrestrial and aerial settings due to improved range
sensors including LiDAR, compact sensors with similar capabilities for
underwater robots have only recently become available, in the form of 3D
sonars. This paper introduces a novel underwater 3D navigation pipeline, called
SHRUMS (Sensor Hallucination for Robust Underwater Motion planning with 3D
Sonar). To the best of the authors' knowledge, SHRUMS is the first underwater
autonomous navigation stack to integrate a 3D sonar. The proposed pipeline
exhibits strong robustness while operating in complex 3D environments in spite
of extremely poor visibility conditions. To accommodate the intricacies of the
novel sensor data stream while achieving real-time locally optimal performance,
SHRUMS introduces the concept of hallucinating sensor measurements from
non-existent sensors with convenient arbitrary parameters, tailored to
application specific requirements. The proposed concepts are validated with
real 3D sonar sensor data, utilizing real inputs in challenging settings and
local maps constructed in real-time. Field deployments validating the proposed
approach in full are planned in the very near future.

</details>


### [177] [Underwater Dense Mapping with the First Compact 3D Sonar](https://arxiv.org/abs/2510.18991)
*Chinmay Burgul,Yewei Huang,Michalis Chatzispyrou,Ioannis Rekleitis,Alberto Quattrini Li,Marios Xanthidis*

Main category: cs.RO

TL;DR: 本文首次研究了紧凑型3D声纳在水下状态估计、测绘和SLAM中的性能、容量和机遇，并提出了校准和管道，展示了其在复杂水下环境中捕获一致空间信息的独特能力。


<details>
  <summary>Details</summary>
Motivation: 过去十年中，激光雷达等紧凑型3D距离传感器推动了鲁棒状态估计技术的发展，但水下电磁波传播不佳，限制了水下可见性无关的传感选择。现有的水声距离传感器提供的是2D信息，且空间信息模糊。最近引入的紧凑型3D声纳有望解决这一问题，因此需要对其进行性能评估。

Method: 研究方法包括：1) 引入了提取3D声纳与相机之间外参的校准程序；2) 对不同表面和材料的声学响应进行了研究；3) 提供了新颖的测绘和SLAM管道；4) 在水下洞穴系统和其他几何和声学挑战性水下环境中进行了部署和测试。

Result: 评估结果表明：3D声纳具有捕获一致空间信息的独特能力，能够实现数百米范围内的详细重建和定位。同时，它也突显了与其他声学传感器类似的声传播相关挑战。

Conclusion: 紧凑型3D声纳在水下状态估计和测绘方面展现出独特的潜力，能够提供一致的空间信息，实现详细重建和定位，尽管声传播仍存在挑战。研究收集的数据集将公开发布以促进进一步研究。

Abstract: In the past decade, the adoption of compact 3D range sensors, such as LiDARs,
has driven the developments of robust state-estimation pipelines, making them a
standard sensor for aerial, ground, and space autonomy. Unfortunately, poor
propagation of electromagnetic waves underwater, has limited the
visibility-independent sensing options of underwater state-estimation to
acoustic range sensors, which provide 2D information including, at-best,
spatially ambiguous information. This paper, to the best of our knowledge, is
the first study examining the performance, capacity, and opportunities arising
from the recent introduction of the first compact 3D sonar. Towards that
purpose, we introduce calibration procedures for extracting the extrinsics
between the 3D sonar and a camera and we provide a study on acoustic response
in different surfaces and materials. Moreover, we provide novel mapping and
SLAM pipelines tested in deployments in underwater cave systems and other
geometrically and acoustically challenging underwater environments. Our
assessment showcases the unique capacity of 3D sonars to capture consistent
spatial information allowing for detailed reconstructions and localization in
datasets expanding to hundreds of meters. At the same time it highlights
remaining challenges related to acoustic propagation, as found also in other
acoustic sensors. Datasets collected for our evaluations would be released and
shared with the community to enable further research advancements.

</details>


### [178] [$\nabla$-SDF: Learning Euclidean Signed Distance Functions Online with Gradient-Augmented Octree Interpolation and Neural Residual](https://arxiv.org/abs/2510.18999)
*Zhirui Dai,Qihao Qian,Tianxing Fan,Nikolay Atanasov*

Main category: cs.RO

TL;DR: 本文提出了一种名为$
abla$-SDF的混合方法，用于从点云数据中估计有符号距离函数（SDF）。该方法结合了八叉树插值的显式先验和神经网络的隐式残差，实现了非截断SDF重建，同时兼顾了计算效率、内存效率、可微性和准确性。


<details>
  <summary>Details</summary>
Motivation: SDF在机器人自主性任务中非常有用，但现有SDF重建方法存在局限性。离散体素方法影响SDF估计的连续性和可微性；神经网络方法虽然能实现高保真和可微的SDF重建，但效率较低，在大环境中可能出现灾难性遗忘和内存限制，且通常局限于截断SDF。

Method: 该研究提出$
abla$-SDF，一种混合方法。它将通过梯度增强八叉树插值获得的显式先验与隐式神经残差相结合。

Result: 该方法实现了非截断（欧几里得）SDF重建，其计算和内存效率可与体素方法媲美，可微性和准确性可与神经网络方法媲美。实验表明，$
abla$-SDF在准确性和效率方面优于现有最先进技术。

Conclusion: $
abla$-SDF为机器人和计算机视觉领域的下游任务提供了一个可扩展的SDF重建解决方案，兼具高效、准确和可微的优点。

Abstract: Estimation of signed distance functions (SDFs) from point cloud data has been
shown to benefit many robot autonomy capabilities, including localization,
mapping, motion planning, and control. Methods that support online and
large-scale SDF reconstruction tend to rely on discrete volumetric data
structures, which affect the continuity and differentiability of the SDF
estimates. Recently, using implicit features, neural network methods have
demonstrated high-fidelity and differentiable SDF reconstruction but they tend
to be less efficient, can experience catastrophic forgetting and memory
limitations in large environments, and are often restricted to truncated SDFs.
This work proposes $\nabla$-SDF, a hybrid method that combines an explicit
prior obtained from gradient-augmented octree interpolation with an implicit
neural residual. Our method achieves non-truncated (Euclidean) SDF
reconstruction with computational and memory efficiency comparable to
volumetric methods and differentiability and accuracy comparable to neural
network methods. Extensive experiments demonstrate that \methodname{}
outperforms the state of the art in terms of accuracy and efficiency, providing
a scalable solution for downstream tasks in robotics and computer vision.

</details>


### [179] [Towards Proprioceptive Terrain Mapping with Quadruped Robots for Exploration in Planetary Permanently Shadowed Regions](https://arxiv.org/abs/2510.18986)
*Alberto Sanchez-Delgado,João Carlos Virgolino Soares,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 本文提出了一种用于四足机器人的地形测绘框架，该框架利用内部本体感知在月球永久阴影区（PSRs）等复杂地形中，估计地形高程、足部滑移、能量消耗和稳定性裕度，并将这些指标集成到多层2.5D网格地图中，以支持未来的月球探索。


<details>
  <summary>Details</summary>
Motivation: 月球极区永久阴影区（PSRs）因可能含有水冰和地质记录而备受关注，但其复杂崎岖的地形需要能够应对挑战性表面的腿式机器人。现有外感受器（如相机、激光雷达）无法量化机器人与地形的物理交互，而本体感知则能提供此能力，因此需要一种能从机器人视角反映地形交互的测绘方法。

Method: 研究提出了一种四足机器人地形测绘框架，该框架在机器人运动过程中，利用内部本体感知来估计高程、足部滑移、能量消耗和稳定性裕度。这些指标被逐步集成到一个多层2.5D网格地图中，以反映机器人与地形的交互。该系统在一个模拟月球环境的仿真器中，使用21公斤的四足机器人Aliengo进行了评估。

Result: 在模拟月球重力和地形条件下，该系统在仿真器中展示了稳定一致的测绘性能。这表明所提出的框架能够有效地从机器人视角估计并集成地形交互信息，生成可靠的地图。

Conclusion: 该研究成功展示了四足机器人利用本体感知在月球PSR等复杂环境中进行地形测绘的潜力，通过估计高程、滑移、能耗和稳定性等指标，为机器人提供了关键的交互信息，有助于未来在挑战性月球表面进行更安全、高效的探索。

Abstract: Permanently Shadowed Regions (PSRs) near the lunar poles are of interest for
future exploration due to their potential to contain water ice and preserve
geological records. Their complex, uneven terrain favors the use of legged
robots, which can traverse challenging surfaces while collecting in-situ data,
and have proven effective in Earth analogs, including dark caves, when equipped
with onboard lighting. While exteroceptive sensors like cameras and lidars can
capture terrain geometry and even semantic information, they cannot quantify
its physical interaction with the robot, a capability provided by
proprioceptive sensing. We propose a terrain mapping framework for quadruped
robots, which estimates elevation, foot slippage, energy cost, and stability
margins from internal sensing during locomotion. These metrics are
incrementally integrated into a multi-layer 2.5D gridmap that reflects terrain
interaction from the robot's perspective. The system is evaluated in a
simulator that mimics a lunar environment, using the 21 kg quadruped robot
Aliengo, showing consistent mapping performance under lunar gravity and terrain
conditions.

</details>


### [180] [Motion Planning and Control of an Overactuated 4-Wheel Drive with Constrained Independent Steering](https://arxiv.org/abs/2510.19054)
*Shiyu Liu,Ilija Hadzic,Akshay Gupta,Aliasghar Arab*

Main category: cs.RO

TL;DR: 本文提出了一种针对受机械约束（非360度转向）的4WIS机器人运动规划与控制方法，通过数学建模处理转向约束和不连续性，并设计了考虑平滑过渡的规划器和控制器。


<details>
  <summary>Details</summary>
Motivation: 解决受机械约束（即车轮无法执行完整360度旋转）的过驱动四轮独立转向（4WIS）机器人在运动规划和控制中遇到的配置空间受限、存在不连续性，从而影响机器人运动平滑性的问题。

Method: 1. 引入转向约束的数学公式，并推导出将速度空间划分为平滑高效运动区域的不连续平面。2. 设计了显式考虑转向约束和速度过渡平滑性的路径跟踪和避障运动规划器。3. 采用局部反馈运动控制器，通过临时停止运动并重新定位车轮来处理不连续性穿越。4. 将所提出的运动规划器作为ROS Navigation包的扩展实现，并在仿真和物理机器人上进行了系统评估。

Result: 所提出的运动规划器和控制系统已作为ROS Navigation包的扩展实现，并在仿真和物理机器人上进行了评估，证明了其处理受限转向和速度过渡平滑性的能力。

Conclusion: 本文成功提出了一种针对受机械约束的4WIS机器人的运动规划和控制策略，通过数学建模、专门的规划器和控制器设计，有效解决了配置空间不连续性和运动平滑性问题，并在仿真和物理机器人上得到了验证。

Abstract: This paper addresses motion planning and con- trol of an overactuated 4-wheel
drive train with independent steering (4WIS) where mechanical constraints
prevent the wheels from executing full 360-degree rotations (swerve). The
configuration space of such a robot is constrained and contains discontinuities
that affect the smoothness of the robot motion. We introduce a mathematical
formulation of the steering constraints and derive discontinuity planes that
partition the velocity space into regions of smooth and efficient motion. We
further design the motion planner for path tracking and ob- stacle avoidance
that explicitly accounts for swerve constraints and the velocity transition
smoothness. The motion controller uses local feedback to generate actuation
from the desired velocity, while properly handling the discontinuity crossing
by temporarily stopping the motion and repositioning the wheels. We implement
the proposed motion planner as an extension to ROS Navigation package and
evaluate the system in simulation and on a physical robot.

</details>


### [181] [Convex Maneuver Planning for Spacecraft Collision Avoidance](https://arxiv.org/abs/2510.19058)
*Fausto Vega,Jon Arrizabalaga,Ryan Watson,Zachary Manchester*

Main category: cs.RO

TL;DR: 本文提出了一种自动化的低推力碰撞规避机动设计算法，将问题表述为非凸二次约束二次规划（QCQP），并通过Shor松弛法转换为凸半定规划（SDP），以实现最小能量或最小风险的解决方案，有效降低了近地轨道卫星的碰撞风险。


<details>
  <summary>Details</summary>
Motivation: 当前航天器碰撞分析和机动规划过程仍是手动且耗时的，涉及重复模拟手工设计的机动。随着低地球轨道（LEO）卫星密度的增加，自动化对于高效评估和缓解碰撞变得至关重要。

Method: 1. 将问题表述为非凸二次约束二次规划（QCQP）。2. 使用Shor松弛法将QCQP松弛为凸半定规划（SDP）。3. 如果无法满足期望的碰撞概率，则将该约束放宽为惩罚项，以获得最小风险解决方案。4. 使用高保真模拟进行算法验证。

Result: 1. 经验表明，松弛是紧密的，能够恢复原始非凸问题的全局最优解。2. 算法在确保最近接近时所需碰撞概率的同时，生成了最小能量的解决方案。3. 如果无法满足期望的碰撞概率，算法将产生最小风险的解决方案。4. 通过高保真模拟验证，算法有效降低了碰撞风险。

Conclusion: 所提出的算法能够有效地设计短时交会事件的低推力碰撞规避机动，通过将问题转化为凸SDP实现了全局最优或最小风险解，并在高保真模拟中证明了其在降低碰撞风险方面的有效性，为航天器碰撞规避的自动化提供了重要进展。

Abstract: Conjunction analysis and maneuver planning for spacecraft collision avoidance
remains a manual and time-consuming process, typically involving repeated
forward simulations of hand-designed maneuvers. With the growing density of
satellites in low-Earth orbit (LEO), autonomy is becoming essential for
efficiently evaluating and mitigating collisions. In this work, we present an
algorithm to design low-thrust collision-avoidance maneuvers for short-term
conjunction events. We first formulate the problem as a nonconvex
quadratically-constrained quadratic program (QCQP), which we then relax into a
convex semidefinite program (SDP) using Shor's relaxation. We demonstrate
empirically that the relaxation is tight, which enables the recovery of
globally optimal solutions to the original nonconvex problem. Our formulation
produces a minimum-energy solution while ensuring a desired probability of
collision at the time of closest approach. Finally, if the desired probability
of collision cannot be satisfied, we relax this constraint into a penalty,
yielding a minimum-risk solution. We validate our algorithm with a
high-fidelity simulation of a satellite conjunction in low-Earth orbit with a
simulated conjunction data message (CDM), demonstrating its effectiveness in
reducing collision risk.

</details>


### [182] [A Learning-based Model Reference Adaptive Controller Implemented on a Prosthetic Hand Wrist](https://arxiv.org/abs/2510.19068)
*Shifa Sulaiman,Mohammad Gohari,Francesco Schetter,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 本研究提出了一种计算高效的基于神经网络的模型参考自适应控制器 (NN-MRAC)，用于驱动软连续体腕部与假肢手的集成，旨在提高其运动精度和响应速度。


<details>
  <summary>Details</summary>
Motivation: 现有假肢手的功能和自然运动受限于柔顺腕部机构的控制挑战。当前的控制策略缺乏适应性且计算成本高昂，阻碍了在辅助机器人中的实时部署。

Method: 研究采用Timoshenko梁理论对腕部进行动态建模，捕捉剪切和弯曲变形。提出的NN-MRAC通过在线自适应，根据挠度误差估计所需的肌腱力，并最小化与参考模型的偏差。

Result: 仿真结果显示精度提高，均方根误差 (RMSE) 为 $6.14 \times 10^{-4}$ m，稳定时间为 $3.2$s。实验验证了实时适用性，平均RMSE为 $5.66 \times 10^{-3}$ m，稳态误差为 $8.05 \times 10^{-3}$ m，稳定时间为 $1.58$ s。

Conclusion: 这些结果表明该控制器有潜力提高软性假肢系统的运动精度和响应能力，从而推动自适应智能控制在可穿戴辅助设备中的集成。

Abstract: The functionality and natural motion of prosthetic hands remain limited by
the challenges in controlling compliant wrist mechanisms. Current control
strategies often lack adaptability and incur high computational costs, which
impedes real-time deployment in assistive robotics. To address this gap, this
study presents a computationally efficient Neural Network (NN)-based Model
Reference Adaptive Controller (MRAC) for a tendon-driven soft continuum wrist
integrated with a prosthetic hand. The dynamic modeling of the wrist is
formulated using Timoshenko beam theory, capturing both shear and bending
deformations. The proposed NN-MRAC estimates the required tendon forces from
deflection errors and minimizes deviation from a reference model through online
adaptation. Simulation results demonstrate improved precision with a root mean
square error (RMSE) of $6.14 \times 10^{-4}$ m and a settling time of $3.2$s.
Experimental validations confirm real-time applicability, with an average RMSE
of $5.66 \times 10^{-3}$ m, steady-state error of $8.05 \times 10^{-3}$ m, and
settling time of $1.58$ s. These results highlight the potential of the
controller to enhance motion accuracy and responsiveness in soft prosthetic
systems, thereby advancing the integration of adaptive intelligent control in
wearable assistive devices.

</details>


### [183] [Sample-Based Hybrid Mode Control: Asymptotically Optimal Switching of Algorithmic and Non-Differentiable Control Modes](https://arxiv.org/abs/2510.19074)
*Yilang Liu,Haoxiang You,Ian Abraham*

Main category: cs.RO

TL;DR: 本文提出了一种基于采样的混合模式控制解决方案，将混合控制模式视为整数优化问题，并有效应用于机器人任务。


<details>
  <summary>Details</summary>
Motivation: 研究非可微和算法混合模式下的混合模式控制问题，特别是在需要复杂行为和实时切换（如长期规划与高频控制）的机器人应用中。

Method: 将混合控制模式建模为一个整数优化问题，选择应用哪个模式、何时切换以及每个模式的持续时间。推导了一种基于采样的变体，以高效搜索整数域以找到最优解。

Result: 该方法提供了强大的性能保证，适用于多种机器人相关任务。它能够合成复杂的算法和策略以实现复合行为和挑战性任务。在需要长期规划与高频控制之间进行反应性切换的真实世界机器人示例中，该方法表现出有效性。

Conclusion: 所提出的基于采样的混合模式控制方法在处理非可微和算法混合模式方面表现出色，为机器人领域提供了强大的性能保证和解决复杂任务的能力。

Abstract: This paper investigates a sample-based solution to the hybrid mode control
problem across non-differentiable and algorithmic hybrid modes. Our approach
reasons about a set of hybrid control modes as an integer-based optimization
problem where we select what mode to apply, when to switch to another mode, and
the duration for which we are in a given control mode. A sample-based variation
is derived to efficiently search the integer domain for optimal solutions. We
find our formulation yields strong performance guarantees that can be applied
to a number of robotics-related tasks. In addition, our approach is able to
synthesize complex algorithms and policies to compound behaviors and achieve
challenging tasks. Last, we demonstrate the effectiveness of our approach in
real-world robotic examples that require reactive switching between long-term
planning and high-frequency control.

</details>


### [184] [Kinematic Analysis and Integration of Vision Algorithms for a Mobile Manipulator Employed Inside a Self-Driving Laboratory](https://arxiv.org/abs/2510.19081)
*Shifa Sulaiman,Tobias Busk Jensen,Stefan Hein Bengtson,Simon Bøgh*

Main category: cs.RO

TL;DR: 本文开发了一种移动机械臂，用于协助自主实验室中的人类操作员。它通过运动学建模、逆运动学解以及结合特征检测和单应性驱动姿态估计的先进视觉算法，实现了对纹理物体的精确操作和可靠抓取，从而支持自主实验和人机协作。


<details>
  <summary>Details</summary>
Motivation: 机器人和自主系统在实验室环境（如自动化合成、可扩展反应流程和自驱动实验室）中的应用日益广泛，需要移动机械臂来协助人类操作员，实现精确和自适应的操作，尤其是在处理纹理物体时的可靠抓取。

Method: 研究方法包括：基于Denavit Hartenberg (DH) 约定的机械臂运动学建模和逆运动学求解；实施先进的基于视觉的算法，进行实时物体检测和姿态估计；集成了一种结合特征检测与单应性驱动姿态估计的视觉方法，利用深度信息将物体姿态表示为3D空间中的2D平面投影。

Result: 开发了一个移动机械臂，能够实现精确和自适应的操作。显著增强了机械臂可靠抓取纹理物体的能力。系统具备适应物体方向变化的能力，并在多样化环境中支持鲁棒的自主操作。

Conclusion: 该工作通过实现自主实验和人机协作，有助于提高下一代化学实验室的可扩展性和可重复性。

Abstract: Recent advances in robotics and autonomous systems have broadened the use of
robots in laboratory settings, including automated synthesis, scalable reaction
workflows, and collaborative tasks in self-driving laboratories (SDLs). This
paper presents a comprehensive development of a mobile manipulator designed to
assist human operators in such autonomous lab environments. Kinematic modeling
of the manipulator is carried out based on the Denavit Hartenberg (DH)
convention and inverse kinematics solution is determined to enable precise and
adaptive manipulation capabilities. A key focus of this research is enhancing
the manipulator ability to reliably grasp textured objects as a critical
component of autonomous handling tasks. Advanced vision-based algorithms are
implemented to perform real-time object detection and pose estimation, guiding
the manipulator in dynamic grasping and following tasks. In this work, we
integrate a vision method that combines feature-based detection with
homography-driven pose estimation, leveraging depth information to represent an
object pose as a $2$D planar projection within $3$D space. This adaptive
capability enables the system to accommodate variations in object orientation
and supports robust autonomous manipulation across diverse environments. By
enabling autonomous experimentation and human-robot collaboration, this work
contributes to the scalability and reproducibility of next-generation chemical
laboratories

</details>


### [185] [Safe Active Navigation and Exploration for Planetary Environments Using Proprioceptive Measurements](https://arxiv.org/abs/2510.19101)
*Matthew Jiang,Shipeng Liu,Feifei Qian*

Main category: cs.RO

TL;DR: 本文提出了一种名为SAEGT的导航框架，使足式机器人在未知颗粒状地形中，仅利用本体感知，即可安全探索和导航，尤其适用于视觉输入不足以捕捉地形变形的情况。


<details>
  <summary>Details</summary>
Motivation: 足式机器人可以通过与地形的力交互来感知地形，提供比远程传感更可靠的可穿越性估计，并可作为轮式漫游车在复杂环境中的侦察兵。然而，即使是足式机器人，在穿越高度可变形或不稳定的地形时仍面临挑战，尤其是在视觉输入无法有效捕捉地形变形能力的情况下。

Method: SAEGT框架通过腿部与地形的交互，利用高斯过程回归在线估计安全区域和前沿区域，以评估地形的可穿越性。同时，结合一个反应式控制器进行实时安全探索和导航，主要依赖本体感知。

Result: SAEGT在模拟环境中展示了其仅利用本体感知估计的可穿越性，便能安全探索并导航至指定目标的能力。

Conclusion: SAEGT框架通过利用本体感知，特别是腿部与地形的交互，成功实现了足式机器人在未知颗粒状地形中的安全探索和导航，弥补了视觉输入在评估地形变形能力方面的不足。

Abstract: Legged robots can sense terrain through force interactions during locomotion,
offering more reliable traversability estimates than remote sensing and serving
as scouts for guiding wheeled rovers in challenging environments. However, even
legged scouts face challenges when traversing highly deformable or unstable
terrain. We present Safe Active Exploration for Granular Terrain (SAEGT), a
navigation framework that enables legged robots to safely explore unknown
granular environments using proprioceptive sensing, particularly where visual
input fails to capture terrain deformability. SAEGT estimates the safe region
and frontier region online from leg-terrain interactions using Gaussian Process
regression for traversability assessment, with a reactive controller for
real-time safe exploration and navigation. SAEGT demonstrated its ability to
safely explore and navigate toward a specified goal using only proprioceptively
estimated traversability in simulation.

</details>


### [186] [A Cross-Environment and Cross-Embodiment Path Planning Framework via a Conditional Diffusion Model](https://arxiv.org/abs/2510.19128)
*Mehran Ghafarian Tamizi,Homayoun Honari,Amir Mehdi Soufi Enayati,Aleksey Nozdryn-Plotnicki,Homayoun Najjaran*

Main category: cs.RO

TL;DR: GADGET是一种基于扩散的路径规划模型，它能为高维复杂环境中的机器人系统生成可泛化、安全且适应性强的轨迹，无需重新训练即可零样本迁移到新环境和新机器人。


<details>
  <summary>Details</summary>
Motivation: 传统路径规划方法计算成本高、参数调整繁琐，而现有基于学习的方法泛化能力不足，无法有效应对高维复杂环境。研究目标是开发一个无需重新训练即可泛化到未知环境和新型机械臂的路径规划框架。

Method: 本文提出了GADGET（Generalizable and Adaptive Diffusion-Guided Environment-aware Trajectory generation），一个基于扩散的规划模型。它通过体素化的场景表示以及起始和目标配置来生成关节空间轨迹。其核心创新是混合双重条件机制：结合了通过学习场景编码实现的无分类器引导（环境感知）和通过分类器引导的控制障碍函数（CBF）安全塑形（实时避碰），将环境感知和避碰直接整合到去噪过程中。这种设计支持零样本迁移到新环境和新机器人。

Result: 实验结果表明，GADGET在球形障碍物、垃圾分拣和货架等环境中实现了高成功率和低碰撞强度，CBF引导进一步提高了安全性。与基于采样的和基于学习的基线方法相比，GADGET表现出强大的性能。此外，GADGET在Franka Panda、Kinova Gen3（6/7-DoF）和UR5机器人之间实现了可迁移性，并在Kinova Gen3上的物理执行验证了其在现实世界中生成安全、无碰撞轨迹的能力。

Conclusion: GADGET提供了一个通用且自适应的路径规划框架，能够为复杂机器人系统生成安全、无碰撞的轨迹，实现零样本迁移，并在各种环境和不同机器人上表现出卓越的性能和现实世界的适用性。

Abstract: Path planning for a robotic system in high-dimensional cluttered environments
needs to be efficient, safe, and adaptable for different environments and
hardware. Conventional methods face high computation time and require extensive
parameter tuning, while prior learning-based methods still fail to generalize
effectively. The primary goal of this research is to develop a path planning
framework capable of generalizing to unseen environments and new robotic
manipulators without the need for retraining. We present GADGET (Generalizable
and Adaptive Diffusion-Guided Environment-aware Trajectory generation), a
diffusion-based planning model that generates joint-space trajectories
conditioned on voxelized scene representations as well as start and goal
configurations. A key innovation is GADGET's hybrid dual-conditioning mechanism
that combines classifier-free guidance via learned scene encoding with
classifier-guided Control Barrier Function (CBF) safety shaping, integrating
environment awareness with real-time collision avoidance directly in the
denoising process. This design supports zero-shot transfer to new environments
and robotic embodiments without retraining. Experimental results show that
GADGET achieves high success rates with low collision intensity in
spherical-obstacle, bin-picking, and shelf environments, with CBF guidance
further improving safety. Moreover, comparative evaluations indicate strong
performance relative to both sampling-based and learning-based baselines.
Furthermore, GADGET provides transferability across Franka Panda, Kinova Gen3
(6/7-DoF), and UR5 robots, and physical execution on a Kinova Gen3 demonstrates
its ability to generate safe, collision-free trajectories in real-world
settings.

</details>


### [187] [GRASPLAT: Enabling dexterous grasping through novel view synthesis](https://arxiv.org/abs/2510.19200)
*Matteo Bortolon,Nuno Ferreira Duarte,Plinio Moreno,Fabio Poiesi,José Santos-Victor,Alessio Del Bue*

Main category: cs.RO

TL;DR: GRASPLAT是一个新颖的机器人抓取框架，它通过合成手-物体交互的图像，利用3D高斯泼溅技术，仅使用RGB图像进行训练，预测多指手抓取姿态，并显著提高了抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 多指手灵巧机器人抓取是一个重大挑战。现有方法依赖于完整的3D扫描来预测抓取姿态，但在现实世界中获取高质量3D数据非常困难，这限制了这些方法的应用。

Method: GRASPLAT框架利用一致的3D信息，但仅通过RGB图像进行训练。其核心思想是通过合成手抓取物体的物理合理图像来回归成功的抓取手关节。该方法使用3D高斯泼溅技术生成真实手-物体交互的高保真新视图，从而实现RGB数据的端到端训练。此外，它还引入了光度损失，通过最小化渲染图像与真实图像之间的差异来优化抓取预测。

Result: GRASPLAT在合成和真实世界的抓取数据集上进行了广泛实验，结果表明，与现有基于图像的方法相比，其抓取成功率提高了高达36.9%。

Conclusion: GRASPLAT提供了一种新颖有效的机器人灵巧抓取方法，通过结合3D高斯泼溅和光度损失，仅使用RGB图像训练即可实现高质量抓取预测，有效克服了传统方法对完整3D数据依赖的限制。

Abstract: Achieving dexterous robotic grasping with multi-fingered hands remains a
significant challenge. While existing methods rely on complete 3D scans to
predict grasp poses, these approaches face limitations due to the difficulty of
acquiring high-quality 3D data in real-world scenarios. In this paper, we
introduce GRASPLAT, a novel grasping framework that leverages consistent 3D
information while being trained solely on RGB images. Our key insight is that
by synthesizing physically plausible images of a hand grasping an object, we
can regress the corresponding hand joints for a successful grasp. To achieve
this, we utilize 3D Gaussian Splatting to generate high-fidelity novel views of
real hand-object interactions, enabling end-to-end training with RGB data.
Unlike prior methods, our approach incorporates a photometric loss that refines
grasp predictions by minimizing discrepancies between rendered and real images.
We conduct extensive experiments on both synthetic and real-world grasping
datasets, demonstrating that GRASPLAT improves grasp success rates up to 36.9%
over existing image-based methods. Project page:
https://mbortolon97.github.io/grasplat/

</details>


### [188] [Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models](https://arxiv.org/abs/2510.19268)
*Mingen Li,Houjian Yu,Yixuan Huang,Youngjin Hong,Changhyun Choi*

Main category: cs.RO

TL;DR: 本文提出了一种全自主的分层框架，利用视觉语言模型进行高层推理，并结合强化学习训练的低层技能，解决了具有挑战性的长周期可变形线性物体（DLO）布线任务，并引入了故障恢复机制。


<details>
  <summary>Details</summary>
Motivation: 可变形线性物体（DLO）的长周期布线任务在工业和日常生活中很常见，但由于其非线性动力学、抽象目标分解、多步规划以及执行过程中对高层推理的精确要求，对机器人来说极具挑战性。

Method: 该方法提出一个全自主分层框架：高层利用视觉语言模型（VLMs）进行上下文高层推理，根据语言描述的布线目标合成可行计划；低层通过强化学习训练的技能执行计划。为提高鲁棒性，引入了故障恢复机制，将DLO重新调整到可插入状态。

Result: 该方法能泛化到涉及物体属性、空间描述和隐式语言命令的多种场景。在长周期布线场景中，其成功率达到92.5%，比次优基线方法高出近50%。

Conclusion: 所提出的分层框架能够有效解决具有挑战性的DLO布线任务，表现出强大的泛化能力和高成功率，并通过故障恢复机制提高了长周期任务的鲁棒性。

Abstract: Long-horizon routing tasks of deformable linear objects (DLOs), such as
cables and ropes, are common in industrial assembly lines and everyday life.
These tasks are particularly challenging because they require robots to
manipulate DLO with long-horizon planning and reliable skill execution.
Successfully completing such tasks demands adapting to their nonlinear
dynamics, decomposing abstract routing goals, and generating multi-step plans
composed of multiple skills, all of which require accurate high-level reasoning
during execution. In this paper, we propose a fully autonomous hierarchical
framework for solving challenging DLO routing tasks. Given an implicit or
explicit routing goal expressed in language, our framework leverages
vision-language models~(VLMs) for in-context high-level reasoning to synthesize
feasible plans, which are then executed by low-level skills trained via
reinforcement learning. To improve robustness in long horizons, we further
introduce a failure recovery mechanism that reorients the DLO into
insertion-feasible states. Our approach generalizes to diverse scenes involving
object attributes, spatial descriptions, as well as implicit language commands.
It outperforms the next best baseline method by nearly 50% and achieves an
overall success rate of 92.5% across long-horizon routing scenarios.

</details>


### [189] [TARMAC: A Taxonomy for Robot Manipulation in Chemistry](https://arxiv.org/abs/2510.19289)
*Kefeng Huang,Jonathon Pipe,Alice E. Martin,Tianyuan Wang,Barnabas A. Franklin,Andy M. Tyrrell,Ian J. S. Fairlamb,Jihong Zhu*

Main category: cs.RO

TL;DR: 本文提出了TARMAC，一个用于化学机器人操作的分类法，旨在为化学实验室中的机器人操作技能提供结构化表示，从而实现更灵活和自主的自动化。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人技术有所进步，但现有化学实验室自动化系统仍需频繁人工干预，且缺乏对所需机器人操作技能的结构化表示。这导致机器人自主性受限于特定任务，难以通用或扩展，阻碍了更灵活和自主的实验室自动化。

Method: 研究人员通过标注教学实验室演示，并结合实验验证，开发了TARMAC（化学机器人操作分类法）。该分类法根据功能角色和物理执行要求对操作动作进行分类和组织。

Result: TARMAC不仅提供了一个描述性词汇，还可以实例化为机器人可执行的基本操作，并组合成更高级的宏指令。这使得技能可以复用，并支持可扩展地集成到长周期工作流程中，为更灵活和自主的实验室自动化奠定了结构化基础。

Conclusion: TARMAC为化学实验室中的机器人操作技能提供了一个系统化的框架，解决了现有自动化系统缺乏结构化技能表示的问题。通过促进技能复用和可扩展集成，TARMAC有望显著提升实验室自动化的灵活性和自主性。

Abstract: Chemistry laboratory automation aims to increase throughput, reproducibility,
and safety, yet many existing systems still depend on frequent human
intervention. Advances in robotics have reduced this dependency, but without a
structured representation of the required skills, autonomy remains limited to
bespoke, task-specific solutions with little capacity to transfer beyond their
initial design. Current experiment abstractions typically describe
protocol-level steps without specifying the robotic actions needed to execute
them. This highlights the lack of a systematic account of the manipulation
skills required for robots in chemistry laboratories. To address this gap, we
introduce TARMAC - a Taxonomy for Robot Manipulation in Chemistry - a
domain-specific framework that defines and organizes the core manipulations
needed in laboratory practice. Based on annotated teaching-lab demonstrations
and supported by experimental validation, TARMAC categorizes actions according
to their functional role and physical execution requirements. Beyond serving as
a descriptive vocabulary, TARMAC can be instantiated as robot-executable
primitives and composed into higher-level macros, enabling skill reuse and
supporting scalable integration into long-horizon workflows. These
contributions provide a structured foundation for more flexible and autonomous
laboratory automation. More information is available at
https://tarmac-paper.github.io/

</details>


### [190] [Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model](https://arxiv.org/abs/2510.19356)
*Yu Fang,Xinyu Wang,Xuehe Zhang,Wanli Xue,Mingwei Zhang,Shengyong Chen,Jie Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种用于机器人模仿学习的单步快捷方法，结合多步集成和自适应梯度分配，以解决流匹配方法推理时间长且现有蒸馏/一致性方法性能不足的问题，在提高推理速度的同时保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: 机器人模仿学习中广泛应用的流匹配方法面临推理时间长的问题。现有蒸馏和一致性方法在性能上难以与原始扩散模型和流匹配模型竞争。

Method: 本文提出了一种结合多步集成的单步快捷方法。具体而言，该方法在快捷模型基础上扩展了多步一致性损失，将单步损失拆分为多步损失以提高单步推理性能。其次，为解决多步损失和原始流匹配损失优化不稳定的问题，提出了一种自适应梯度分配方法来增强学习过程的稳定性。

Result: 所提出的方法在两个模拟基准和五个真实世界环境任务中进行了评估。实验结果验证了所提算法的有效性。

Conclusion: 该算法有效解决了机器人模仿学习中流匹配方法推理速度与性能之间的平衡问题，通过单步快捷与多步集成以及自适应梯度分配，实现了推理速度的提升和性能的增强，并提高了学习过程的稳定性。

Abstract: The wide application of flow-matching methods has greatly promoted the
development of robot imitation learning. However, these methods all face the
problem of high inference time. To address this issue, researchers have
proposed distillation methods and consistency methods, but the performance of
these methods still struggles to compete with that of the original diffusion
models and flow-matching models. In this article, we propose a one-step
shortcut method with multi-step integration for robot imitation learning. To
balance the inference speed and performance, we extend the multi-step
consistency loss on the basis of the shortcut model, split the one-step loss
into multi-step losses, and improve the performance of one-step inference.
Secondly, to solve the problem of unstable optimization of the multi-step loss
and the original flow-matching loss, we propose an adaptive gradient allocation
method to enhance the stability of the learning process. Finally, we evaluate
the proposed method in two simulation benchmarks and five real-world
environment tasks. The experimental results verify the effectiveness of the
proposed algorithm.

</details>


### [191] [Risk Assessment of an Autonomous Underwater Snake Robot in Confined Operations](https://arxiv.org/abs/2510.19415)
*Abdelrahman Sayed Sayed*

Main category: cs.RO

TL;DR: 本文提出了一种贝叶斯方法来评估铰接式水下机器人Eely在复杂任务场景中丢失的风险，旨在提高其性能和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 随着海洋探索的兴趣日益增长，对狭窄和高要求环境中的检查和干预需求也随之增加。Eely（一种细长且能改变构型的铰接式水下机器人）非常适合此类环境。然而，在这些环境中操作Eely面临严峻挑战，包括不确定和非结构化环境、极端环境条件以及受限的导航能力。

Method: 本文提出了一种贝叶斯方法，用于评估Eely在两种任务场景下丢失的风险。此外，还进行了敏感性分析。

Result: 展示了敏感性分析结果，以揭示导致Eely丢失影响最大的原因。

Conclusion: 通过评估Eely丢失的风险并识别关键影响因素，这项工作旨在提高Eely的性能和任务成功率。

Abstract: The growing interest in ocean discovery imposes a need for inspection and
intervention in confined and demanding environments. Eely's slender shape, in
addition to its ability to change its body configurations, makes articulated
underwater robots an adequate option for such environments. However, operation
of Eely in such environments imposes demanding requirements on the system, as
it must deal with uncertain and unstructured environments, extreme
environmental conditions, and reduced navigational capabilities. This paper
proposes a Bayesian approach to assess the risks of losing Eely during two
mission scenarios. The goal of this work is to improve Eely's performance and
the likelihood of mission success. Sensitivity analysis results are presented
in order to demonstrate the causes having the highest impact on losing Eely.

</details>


### [192] [ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling](https://arxiv.org/abs/2510.19364)
*Golnaz Raja,Ruslan Agishev,Miloš Prágr,Joni Pajarinen,Karel Zimmermann,Arun Kumar Singh,Reza Ghabcheloo*

Main category: cs.RO

TL;DR: 该研究提出一个高效的概率框架，用于越野环境中的机器人运动预测，通过显式建模地形参数上的空间相关随机不确定性，并通过可微分物理引擎传播，以实现高分辨率的多变量预测。


<details>
  <summary>Details</summary>
Motivation: 在地形异构且感知不确定性高的非结构化越野环境中，对机器人运动进行不确定性感知预测对于下游的可通行性估计和安全自主导航至关重要。现有方法大多假设确定性或空间独立的地形不确定性，忽略了3D空间数据固有的局部相关性，常导致不可靠的预测。

Method: 引入一个高效的概率框架，将地形参数上的空间相关随机不确定性建模为概率世界模型。通过可微分物理引擎传播这种不确定性，进行概率轨迹预测。利用结构化卷积算子，以可管理的计算成本提供高分辨率的多变量预测。

Result: 在公开数据集上的实验评估表明，与随机不确定性估计基线相比，该方法显著提高了不确定性估计和轨迹预测的准确性。

Conclusion: 该框架通过有效建模和传播地形参数上的空间相关随机不确定性，能够为越野环境中的机器人运动提供更可靠、更准确的轨迹预测和不确定性估计。

Abstract: Uncertainty-aware robot motion prediction is crucial for downstream
traversability estimation and safe autonomous navigation in unstructured,
off-road environments, where terrain is heterogeneous and perceptual
uncertainty is high. Most existing methods assume deterministic or spatially
independent terrain uncertainties, ignoring the inherent local correlations of
3D spatial data and often producing unreliable predictions. In this work, we
introduce an efficient probabilistic framework that explicitly models spatially
correlated aleatoric uncertainty over terrain parameters as a probabilistic
world model and propagates this uncertainty through a differentiable physics
engine for probabilistic trajectory forecasting. By leveraging structured
convolutional operators, our approach provides high-resolution multivariate
predictions at manageable computational cost. Experimental evaluation on a
publicly available dataset shows significantly improved uncertainty estimation
and trajectory prediction accuracy over aleatoric uncertainty estimation
baselines.

</details>


### [193] [Using Temperature Sampling to Effectively Train Robot Learning Policies on Imbalanced Datasets](https://arxiv.org/abs/2510.19373)
*Basavasagar Patil,Sydney Belt,Jayjun Lee,Nima Fazeli,Bernadette Bucher*

Main category: cs.RO

TL;DR: 针对机器人动作数据集中存在的物理动作不平衡问题，本文提出了一种简单的采样策略，通过缓解这种不平衡来提高策略训练的泛化能力，尤其在低资源任务上表现显著提升，且不损害高资源任务的性能。


<details>
  <summary>Details</summary>
Motivation: 随着机器人行动和感知观测数据集的不断增大，用于训练大型神经网络的数据集在物理机器人动作方面常常存在严重不平衡。尽管任务描述可能不同，但许多任务涉及相似的物理动作序列，导致模型容量未能有效利用，且泛化能力受限，尤其是在资源较少的任务上。

Method: 本文提出了一种简单的策略训练采样策略，旨在缓解机器人动作数据集中的不平衡问题。该方法易于集成到现有代码库中，仅需几行代码即可实现。

Result: 实验结果表明，与现有最先进的方法相比，该方法在低资源任务上取得了显著的性能提升，同时没有降低高资源任务的性能。该方法在预训练小型模型和微调大型基础模型方面均进行了评估，并在真实世界的Franke Panda机器人臂上通过多样化任务得到了进一步验证。

Conclusion: 所提出的简单采样策略能有效缓解机器人动作数据集中的不平衡问题，从而提高多任务策略的泛化能力和模型容量的利用效率，特别是在低资源任务上表现出显著优势。

Abstract: Increasingly large datasets of robot actions and sensory observations are
being collected to train ever-larger neural networks. These datasets are
collected based on tasks and while these tasks may be distinct in their
descriptions, many involve very similar physical action sequences (e.g., 'pick
up an apple' versus 'pick up an orange'). As a result, many datasets of robotic
tasks are substantially imbalanced in terms of the physical robotic actions
they represent. In this work, we propose a simple sampling strategy for policy
training that mitigates this imbalance. Our method requires only a few lines of
code to integrate into existing codebases and improves generalization. We
evaluate our method in both pre-training small models and fine-tuning large
foundational models. Our results show substantial improvements on low-resource
tasks compared to prior state-of-the-art methods, without degrading performance
on high-resource tasks. This enables more effective use of model capacity for
multi-task policies. We also further validate our approach in a real-world
setup on a Franka Panda robot arm across a diverse set of tasks.

</details>


### [194] [GigaBrain-0: A World Model-Powered Vision-Language-Action Model](https://arxiv.org/abs/2510.19430)
*GigaBrain Team,Angen Ye,Boyuan Wang,Chaojun Ni,Guan Huang,Guosheng Zhao,Haoyun Li,Jie Li,Jiagang Zhu,Lv Feng,Peng Li,Qiuping Deng,Runqi Ouyang,Wenkang Qin,Xinze Chen,Xiaofeng Wang,Yang Wang,Yifan Li,Yilong Li,Yiran Ding,Yuan Xu,Yun Ye,Yukun Zhou,Zhehao Dong,Zhenan Wang,Zhichao Liu,Zheng Zhu*

Main category: cs.RO

TL;DR: GigaBrain-0是一个新型VLA基础模型，利用世界模型生成数据来减少对真实机器人数据的依赖，显著提高了泛化能力和策略鲁棒性，并在实际机器人任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 训练通用机器人VLA模型需要大量昂贵且耗时的真实世界机器人数据，这严重限制了现有VLA系统的可扩展性和泛化能力。

Method: 引入GigaBrain-0，一个VLA基础模型，通过世界模型生成多样化数据（如视频生成、real2real、human transfer、view transfer、sim2real transfer数据）来大规模减少对真实机器人数据的依赖。该方法还通过RGBD输入建模和具身思维链（CoT）监督来提高策略鲁棒性，使模型能够推理空间几何、物体状态和长程依赖。同时提出了轻量级变体GigaBrain-0-Small。

Result: GigaBrain-0在灵巧、长程和移动操作任务中取得了显著的真实世界性能提升。它在外观（如纹理、颜色）、物体放置和摄像机视点变化方面实现了卓越的泛化能力。GigaBrain-0-Small可以在NVIDIA Jetson AGX Orin等设备上高效运行。

Conclusion: GigaBrain-0通过利用世界模型生成数据，有效解决了VLA模型训练中真实数据稀缺的挑战，显著提升了模型在各种真实世界机器人任务中的泛化能力和鲁棒性。

Abstract: Training Vision-Language-Action (VLA) models for generalist robots typically
requires large-scale real-world robot data, which is expensive and
time-consuming to collect. The inefficiency of physical data collection
severely limits the scalability, and generalization capacity of current VLA
systems. To address this challenge, we introduce GigaBrain-0, a novel VLA
foundation model empowered by world model-generated data (e.g., video
generation, real2real transfer, human transfer, view transfer, sim2real
transfer data). By leveraging world models to generate diverse data at scale,
GigaBrain-0 significantly reduces reliance on real robot data while improving
cross-task generalization. Our approach further improves policy robustness
through RGBD input modeling and embodied Chain-of-Thought (CoT) supervision,
enabling the model to reason about spatial geometry, object states, and
long-horizon dependencies during task execution. This leads to substantial
gains in real-world performance on dexterous, long-horizon, and mobile
manipulation tasks. Extensive experiments demonstrate that GigaBrain-0 achieves
superior generalization across variations in appearances (e.g., textures,
colors), object placements, and camera viewpoints. Additionally, we present
GigaBrain-0-Small, an optimized lightweight variant designed to run efficiently
on devices such as the NVIDIA Jetson AGX Orin.

</details>


### [195] [Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning](https://arxiv.org/abs/2510.19495)
*Kevin Huang,Rosario Scalise,Cleah Winston,Ayush Agrawal,Yunchu Zhang,Rohan Baijal,Markus Grotz,Byron Boots,Benjamin Burchfiel,Hongkai Dai,Masha Itkina,Paarth Shah,Abhishek Gupta*

Main category: cs.RO

TL;DR: 本研究提出通过对离线强化学习进行简单修改，以有效利用非专家数据，从而增强模仿学习策略的鲁棒性、恢复能力和泛化能力，尤其是在机器人操作任务中。


<details>
  <summary>Details</summary>
Motivation: 模仿学习受限于对高质量、特定任务数据的依赖，这限制了其对多样化真实世界场景的适应性。非专家数据（如游戏数据、次优演示或部分任务完成）收集成本低且覆盖范围广，但传统模仿学习方法无法有效利用这些数据。

Method: 本研究提出将离线强化学习作为一种工具来利用非专家数据以增强模仿学习策略的性能。作者指出，标准离线RL在稀疏数据覆盖下效果不佳，但通过简单的算法修改（例如，拓宽策略分布的支持），可以在不增加显著额外假设的情况下有效利用这些数据。

Result: 经过修改的离线RL方法使模仿算法能够鲁棒地解决任务，显示出显著增强的恢复能力和泛化行为。在操作任务中，结合非专家数据后，学习策略成功的初始条件范围显著增加。此外，这些方法能够利用所有收集到的数据，包括部分或次优演示，来提升面向任务的策略性能。

Conclusion: 利用非专家数据的算法技术对于机器人领域中鲁棒的策略学习至关重要，本研究强调了通过改进离线RL方法来有效利用这些数据的潜力。

Abstract: Imitation learning has proven effective for training robots to perform
complex tasks from expert human demonstrations. However, it remains limited by
its reliance on high-quality, task-specific data, restricting adaptability to
the diverse range of real-world object configurations and scenarios. In
contrast, non-expert data -- such as play data, suboptimal demonstrations,
partial task completions, or rollouts from suboptimal policies -- can offer
broader coverage and lower collection costs. However, conventional imitation
learning approaches fail to utilize this data effectively. To address these
challenges, we posit that with right design decisions, offline reinforcement
learning can be used as a tool to harness non-expert data to enhance the
performance of imitation learning policies. We show that while standard offline
RL approaches can be ineffective at actually leveraging non-expert data under
the sparse data coverage settings typically encountered in the real world,
simple algorithmic modifications can allow for the utilization of this data,
without significant additional assumptions. Our approach shows that broadening
the support of the policy distribution can allow imitation algorithms augmented
by offline RL to solve tasks robustly, showing considerably enhanced recovery
and generalization behavior. In manipulation tasks, these innovations
significantly increase the range of initial conditions where learned policies
are successful when non-expert data is incorporated. Moreover, we show that
these methods are able to leverage all collected data, including partial or
suboptimal demonstrations, to bolster task-directed policy performance. This
underscores the importance of algorithmic techniques for using non-expert data
for robust policy learning in robotics.

</details>


### [196] [Optimizing Prosthetic Wrist Movement: A Model Predictive Control Approach](https://arxiv.org/abs/2510.19541)
*Francesco Schetter,Shifa Sulaiman,Shoby George,Paolino De Risi,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 本研究提出了一种计算量较小的模型预测控制（MPC）策略，用于调节肌腱驱动假肢手上的软连续腕部运动，显著提高了假肢手的灵巧性和用户控制能力。


<details>
  <summary>Details</summary>
Motivation: 提高假肢手的适应性和性能，需要整合先进的控制策略。本研究旨在通过模型预测控制（MPC）来增强假肢手软连续腕部的功能性和响应能力。

Method: 采用模型预测控制（MPC）策略来调节软连续腕部运动。运动学建模使用欧拉-伯努利梁方法，动力学建模使用拉格朗日方法。通过仿真和实验验证了该方法的有效性。

Result: 研究结果表明，MPC能够有效优化腕部关节运动和用户控制，显著提高了假肢手的灵巧性，使运动更加自然和直观，并且计算量较小。

Conclusion: 该研究为机器人技术和生物医学工程领域的智能假肢系统提供了一个有前景的方向，通过MPC策略实现了更自然、直观的假肢运动。

Abstract: The integration of advanced control strategies into prosthetic hands is
essential to improve their adaptability and performance. In this study, we
present an implementation of a Model Predictive Control (MPC) strategy to
regulate the motions of a soft continuum wrist section attached to a
tendon-driven prosthetic hand with less computational effort. MPC plays a
crucial role in enhancing the functionality and responsiveness of prosthetic
hands. By leveraging predictive modeling, this approach enables precise
movement adjustments while accounting for dynamic user interactions. This
advanced control strategy allows for the anticipation of future movements and
adjustments based on the current state of the prosthetic device and the
intentions of the user. Kinematic and dynamic modelings are performed using
Euler-Bernoulli beam and Lagrange methods respectively. Through simulation and
experimental validations, we demonstrate the effectiveness of MPC in optimizing
wrist articulation and user control. Our findings suggest that this technique
significantly improves the prosthetic hand dexterity, making movements more
natural and intuitive. This research contributes to the field of robotics and
biomedical engineering by offering a promising direction for intelligent
prosthetic systems.

</details>


### [197] [LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments](https://arxiv.org/abs/2510.19655)
*Hongyu Ding,Ziming Xu,Yudong Fang,You Wu,Zixuan Chen,Jieqi Shi,Jing Huo,Yifan Zhang,Yang Gao*

Main category: cs.RO

TL;DR: LaViRA是一个针对零样本视觉-语言连续环境导航（VLN-CE）的新框架，它通过将动作分解为粗粒度到细粒度的层次结构（语言动作、视觉动作、机器人动作）来解决现有方法的局限性，并利用多模态大语言模型（MLLMs）的不同优势，实现了卓越的泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 当前零样本VLN-CE方法面临一个关键权衡：要么依赖环境特定的路径预测器，限制了场景泛化能力；要么在导航过程中未能充分利用大型模型的推理能力。这限制了它们在未见环境中的表现。

Method: LaViRA框架将动作分解为粗粒度到细粒度的层次结构：1) 语言动作（Language Action）用于高层规划；2) 视觉动作（Vision Action）用于感知接地；3) 机器人动作（Robot Action）用于鲁棒导航。这种模块化分解允许在每个阶段利用不同规模多模态大语言模型（MLLMs）的独特优势。

Result: LaViRA在VLN-CE基准测试上显著优于现有最先进方法，在未见环境中展现出卓越的泛化能力，同时保持了透明度和部署效率。

Conclusion: LaViRA通过其独特的粗粒度到细粒度动作分解和对MLLMs的有效利用，为零样本VLN-CE提供了一个强大、透明且高效的解决方案，在推理、接地和实际控制方面均表现出色，并具有强大的泛化能力。

Abstract: Zero-shot Vision-and-Language Navigation in Continuous Environments (VLN-CE)
requires an agent to navigate unseen environments based on natural language
instructions without any prior training. Current methods face a critical
trade-off: either rely on environment-specific waypoint predictors that limit
scene generalization, or underutilize the reasoning capabilities of large
models during navigation. We introduce LaViRA, a simple yet effective zero-shot
framework that addresses this dilemma by decomposing action into a
coarse-to-fine hierarchy: Language Action for high-level planning, Vision
Action for perceptual grounding, and Robot Action for robust navigation. This
modular decomposition allows us to leverage the distinct strengths of different
scales of Multimodal Large Language Models (MLLMs) at each stage, creating a
system that is powerful in its reasoning, grounding and practical control.
LaViRA significantly outperforms existing state-of-the-art methods on the
VLN-CE benchmark, demonstrating superior generalization capabilities in unseen
environments, while maintaining transparency and efficiency for real-world
deployment.

</details>


### [198] [Fast Marker Detection for UV-Based Visual Relative Localisation in Agile UAV Swarms](https://arxiv.org/abs/2510.19663)
*Vojtěch Vrba,Viktor Walter,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 本文提出了一种用于敏捷无人机蜂群视觉相对定位的快速机载孤立标记检测新方法，通过CPU、GPU和FPGA优化实现了显著加速。


<details>
  <summary>Details</summary>
Motivation: 实时定位系统需要快速的机载标记检测，尤其是在敏捷无人机蜂群中，这是一个关键组成部分。

Method: 研究提出了三重创新：优化的CPU程序、GPU着色器程序以及功能等效的FPGA流式架构。这些解决方案在多种32位和64位嵌入式平台上进行了评估。

Result: 与现有技术相比，CPU和GPU解决方案将每像素平均处理时间加速了2到3个数量级。FPGA架构通过最小化从相机曝光到检测结果的总延迟，为定位任务提供了最显著的整体加速。所有方案都证明了其效率和在低端无人机/微型飞行器上的可行性。

Conclusion: 所提出的方法成为敏捷无人机蜂群的关键使能技术。

Abstract: A novel approach for the fast onboard detection of isolated markers for
visual relative localisation of multiple teammates in agile UAV swarms is
introduced in this paper. As the detection forms a key component of real-time
localisation systems, a three-fold innovation is presented, consisting of an
optimised procedure for CPUs, a GPU shader program, and a functionally
equivalent FPGA streaming architecture. For the proposed CPU and GPU solutions,
the mean processing time per pixel of input camera frames was accelerated by
two to three orders of magnitude compared to the state of the art. For the
localisation task, the proposed FPGA architecture offered the most significant
overall acceleration by minimising the total delay from camera exposure to
detection results. Additionally, the proposed solutions were evaluated on
various 32-bit and 64-bit embedded platforms to demonstrate their efficiency,
as well as their feasibility for applications using low-end UAVs and MAVs.
Thus, it has become a crucial enabling technology for agile UAV swarming.

</details>


### [199] [Learning Affordances at Inference-Time for Vision-Language-Action Models](https://arxiv.org/abs/2510.19752)
*Ameesh Shah,William Chen,Adwait Godbole,Federico Mora,Sanjit A. Seshia,Sergey Levine*

Main category: cs.RO

TL;DR: 本文提出LITEN方法，使视觉-语言-动作（VLA）模型能从推理时执行失败中学习并动态调整策略，以解决复杂的机器人控制任务。


<details>
  <summary>Details</summary>
Motivation: 解决复杂的真实世界控制任务通常需要多次尝试和策略调整。现有机器人领域的视觉-语言-动作（VLA）模型在任务失败时，缺乏像人类一样反思并动态调整行为的能力。

Method: LITEN将低级VLA策略与高级视觉-语言模型（VLM）连接起来，VLM通过上下文学习（in-context learning）利用过往经验。该方法在推理阶段（生成并执行低级VLA计划）和评估阶段（反思执行结果，从非结构化的真实机器人轨迹中提取有用结论并纳入未来推理上下文）之间迭代进行。评估阶段使用结构化指导原则。

Result: 实验结果表明，LITEN能够有效地从过往经验中学习，生成利用高可供性指令来完成长周期任务的计划。

Conclusion: LITEN通过允许VLA模型在推理时从执行失败中学习，提高了其适应性和解决复杂真实世界机器人任务的能力，为未来的规划融入了过去的经验和教训。

Abstract: Solving complex real-world control tasks often takes multiple tries: if we
fail at first, we reflect on what went wrong, and change our strategy
accordingly to avoid making the same mistake. In robotics,
Vision-Language-Action models (VLAs) offer a promising path towards solving
complex control tasks, but lack the ability to contextually and dynamically
readjust behavior when they fail to accomplish a task. In this work, we
introduce Learning from Inference-Time Execution (LITEN), which connects a VLA
low-level policy to a high-level VLM that conditions on past experiences by
including them in-context, allowing it to learn the affordances and
capabilities of the low-level VLA. Our approach iterates between a reasoning
phase that generates and executes plans for the low-level VLA, and an
assessment phase that reflects on the resulting execution and draws useful
conclusions to be included in future reasoning contexts. Unlike similar
approaches to self-refinement in non-robotics domains, LITEN must reflect on
unstructured real-world robot trajectories (e.g., raw videos), which requires
structured guiderails during assessment. Our experimental results demonstrate
LITEN is able to effectively learn from past experience to generate plans that
use high-affordance instructions to accomplish long-horizon tasks.

</details>


### [200] [SEA: Semantic Map Prediction for Active Exploration of Uncertain Areas](https://arxiv.org/abs/2510.19766)
*Hongyu Ding,Xinyue Liang,Yudong Fang,You Wu,Jieqi Shi,Jing Huo,Wenbin Li,Jing Wu,Yu-Kun Lai,Yang Gao*

Main category: cs.RO

TL;DR: 本文提出SEA，一种结合语义地图预测和强化学习分层探索策略的主动机器人探索方法，旨在通过增强长期环境理解，实现更高效的地图构建。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的探索方法依赖一步路点预测，缺乏对环境的长期理解，导致探索效率不高。

Method: SEA方法包含：1) 一个迭代预测-探索框架，根据当前观测显式预测地图缺失区域，并利用实际累积地图与预测全局地图的差异来指导探索。2) 一个新颖的强化学习奖励机制，用于更新长期探索策略，以在有限步骤内构建准确的语义地图。

Result: 实验结果表明，SEA方法显著优于现有最先进的探索策略，在相同时间限制内实现了更优的全局地图覆盖率。

Conclusion: SEA通过语义地图预测和强化学习的结合，能够有效增强机器人对环境的长期理解，从而在有限步骤内构建准确的语义地图，并实现更高效的探索。

Abstract: In this paper, we propose SEA, a novel approach for active robot exploration
through semantic map prediction and a reinforcement learning-based hierarchical
exploration policy. Unlike existing learning-based methods that rely on
one-step waypoint prediction, our approach enhances the agent's long-term
environmental understanding to facilitate more efficient exploration. We
propose an iterative prediction-exploration framework that explicitly predicts
the missing areas of the map based on current observations. The difference
between the actual accumulated map and the predicted global map is then used to
guide exploration. Additionally, we design a novel reward mechanism that
leverages reinforcement learning to update the long-term exploration
strategies, enabling us to construct an accurate semantic map within limited
steps. Experimental results demonstrate that our method significantly
outperforms state-of-the-art exploration strategies, achieving superior
coverage ares of the global map within the same time constraints.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [201] [Active Cooling Device: A Flexible, Lab-Scale Experimental Unit to Develop Spatio-Temporal Temperature Control Strategies](https://arxiv.org/abs/2510.18987)
*Victor Oliveira Ferreira,Wiebke Mainville,Vincent Raymond,Jean-Michel Lamarre,Antoine Hamel,Mikael Vaillant,Moncef Chioua,Bruno Blais*

Main category: eess.SY

TL;DR: 本文介绍了一个实验装置，用于实现“多输入、多输出流形”热管理技术，通过可控的射流进行时空温度分布控制，并提供了完整的开源设计文件和操作指南。


<details>
  <summary>Details</summary>
Motivation: 旨在实现并实验Lamarre & Raymond (2023) 提出的“多输入、多输出流形”热管理技术，以控制时空温度分布。

Method: 该实验装置利用冷却液射流通过目标表面的通道流形进行温度控制。流体方向通过改变通道（输入、输出或关闭）的角色来控制。作者提供了CAD文件、PCB Gerber文件、Python编写的图形用户界面(GUI)，以及详细的组装和交互指南。

Result: 该装置能够实时跟踪样品温度和流量，支持系统特性分析（如阶跃响应）、PID性能跟踪和耦合系统中的扰动抑制。它是一个安全、灵活、完整的设计，可用于实验室规模评估定制温度控制策略的性能。

Conclusion: 所提出的实验装置成功实现了“多输入、多输出流形”热管理技术，提供了一个开放、灵活且完整的平台，用于研究和开发基于封闭射流的定制温度控制策略，具有广泛的应用潜力。

Abstract: We present an experimental unit that realizes the ``multi-input, multi-output
manifold'' thermal management technology proposed by Lamarre & Raymond (2023).
The proposed setup can be used for experiments aimed at controlling
spatiotemporal temperature distribution. Temperature control is achieved by
impinging coolant fluid jets, leveraging a manifold of channels targeted to the
surface. The direction of the fluid is controlled by shifting the role of
channels between inputs, outputs, or closing them. Files associated with this
work include Computer-Aided Design (CAD) STEP files, Gerber files to
manufacture a Printed Circuit Board (PCB), and a Graphical User Interface (GUI)
written in Python. We provide a step-by-step guide to assemble the experimental
setup. We also provide instructions to interact with the setup through the GUI,
which allows for real-time tracking of sample temperature and flow rates per
flow control device. Additionally, we provide examples of usage of the setup,
including system characterization with step response,
Proportional-Integral-Derivative performance tracking, and disturbance
rejection in a coupled system. Extending the application is accessible through
the files provided in the open repository associated with this work. The active
cooling device presents a safe, flexible, and complete design, allowing for
lab-scale assessment of the performance of custom temperature control
strategies using enclosed impinging jets.

</details>


### [202] [Extreme value distributions of peak loads for non-residential customer segments](https://arxiv.org/abs/2510.19052)
*Shaohong Shi,Eric A. Cator,Jacco Heres,Simon H. Tindemans*

Main category: eess.SY

TL;DR: 本文提出了一种基于极值理论的数学模型，用于表征大型非居民客户的峰值负荷概率分布，该模型为分位数Velander公式提供了理论基础并将其参数简化至四个，同时验证了峰值负荷分布属于重尾Fréchet类。


<details>
  <summary>Details</summary>
Motivation: 欧洲电网堵塞日益严重，需要准确预测负荷，尤其是峰值负荷。Velander公式（VF）是传统的非时间分辨峰值负荷预测方法，其分位数VF形式已被使用。本研究旨在为分位数VF提供数学模型基础，并优化其表示。

Method: 本文提出了一种基于极值理论（EVT）的数学模型来表征大型非居民客户的峰值负荷概率分布。该模型通过多元分位数回归证明了其作为分位数VF基础的地位，并将其参数表示减少到四个。此外，采用最大似然估计和似然比检验来验证峰值负荷的概率分布。

Result: 所提出的基于极值理论的数学模型成功地为分位数Velander公式提供了理论基础，并在不牺牲预测性能的情况下，将其表示简化为仅四个参数。通过最大似然估计和似然比检验，验证了分析组的峰值负荷概率分布属于重尾Fréchet类。

Conclusion: 本研究提供了一个基于极值理论的数学模型，能够有效表征大型非居民客户的峰值负荷概率分布，并为分位数Velander公式提供了坚实的理论基础和更简洁的参数表示。研究结果证实了峰值负荷分布的重尾Fréchet特性。

Abstract: Electrical grid congestion is a growing challenge in Europe, driving the need
for accurate prediction of load, particularly of peak load. Non-time-resolved
models of peak load offer the advantages of simplicity and compactness, and
among them, Velander's formula (VF) is a traditional method that has been used
for decades. Moreover, VF can be adapted into a quantile VF, which learns a
truncated cumulative distribution function of peak load based on electricity
consumption. This paper proposes a mathematical model based on extreme value
theory to characterize the probability distribution of peak load for large
non-residential customers. The model underpins the quantile VF as demonstrated
through multiple quantile regression and reduces its representation to just
four parameters without sacrificing predictive performance. Moreover, using
maximum likelihood estimation and the likelihood ratio test, we validate that
the probability distribution of peak load of analysed groups belongs to the
heavy-tailed Fr\'echet class.

</details>


### [203] [Graph Analysis to Fully Automate Fault Location Identification in Power Distribution Systems](https://arxiv.org/abs/2510.19059)
*Ali Shakeri Kahnamouei,Saeed Lotfifard*

Main category: eess.SY

TL;DR: 本文提出了一种基于图分析的方法，用于全自动识别配电系统中的故障位置，该方法无需人工干预、复杂编号，且具有可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统的故障定位任务可能需要复杂节点和分支编号过程，或在系统拓扑变化时重新编号，且需要人工干预。本研究旨在实现配电系统故障定位的完全自动化。

Method: 该方法采用图分析技术，以配电系统的基本无序数据（分支参数、负荷值、测量设备位置）作为输入。通过数据准备和分析，自动识别系统拓扑，提取故障路径、结构、侧支和次侧支负荷等关键信息，并据此估算故障位置。该方法无需复杂的节点和分支编号，且不受系统拓扑变化影响。

Result: 所提出的算法在IEEE 34节点配电测试系统上验证了其性能，表明其能够实现故障定位的自动化，无需人工干预，并具有可扩展性。

Conclusion: 本文提出的图分析方法能够完全自动化配电系统的故障位置识别任务，克服了传统方法对复杂编号和人工干预的依赖，具有高度的自动化、适应性和可扩展性。

Abstract: This paper proposes graph analysis methods to fully automate the fault
location identification task in power distribution systems. The proposed
methods take basic unordered data from power distribution systems as input,
including branch parameters, load values, and the location of measuring
devices. The proposed data preparation and analysis methods automatically
identify the system's topology and extract essential information, such as
faulted paths, structures, loading of laterals and sublaterals, and estimate
the fault location accordingly. The proposed graph analysis methods do not
require complex node and branch numbering processes or renumbering following
changes in the system topology. The proposed methods eliminate the need for
human intervention at any step of the fault location identification process.
They are scalable and applicable to systems of any size. The performance of the
proposed algorithm is demonstrated using the IEEE 34-bus distribution test
system.

</details>


### [204] [Time Domain Differential Equation Based Fault Location Identification in Mixed Overhead-Underground Power Distribution Systems](https://arxiv.org/abs/2510.19070)
*Ali Shakeri Kahnamouei,Saeed Lotfifard*

Main category: eess.SY

TL;DR: 本文提出了一种时域故障定位方法，用于混合架空-地下配电系统，能处理次周期、电弧和演变故障，并利用有限测量数据提供单一准确的故障位置估计。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以准确识别混合架空-地下配电系统中复杂的故障场景，如次周期故障、电弧故障和演变故障，尤其是在存在分布式电源的情况下。

Method: 该方法基于系统微分方程，考虑了配电系统中的负荷、多相支线和次支线、异构架空和地下线路以及分布式电源的馈入和远端故障电流贡献。它利用有限的测量设备数据，系统性地消除可能的多个故障位置估计，以提供单一正确的实际故障位置估计。

Result: 该方法的性能在IEEE 34节点测试系统上得到了验证。

Conclusion: 所提出的方法能够有效地识别混合架空-地下配电系统中复杂故障场景的准确位置，即使在存在分布式电源和有限测量设备的情况下。

Abstract: This paper proposes a time-domain fault location identification method for
mixed overhead-underground power distribution systems that can handle
challenging fault scenarios such as sub-cycle faults, arcing faults and
evolving faults. The proposed method is formulated based on differential
equations of the system and accounts for the peculiarities of power
distribution systems with distributed generations. It considers the presence of
loads, multi-phase laterals and sub-laterals, heterogenous overhead and
underground lines, and infeeds and remote-end fault current contributions of
distributed generations. It utilizes data collected by limited number of
measuring devices installed in modern power distribution systems to
systematically eliminate possible multiple fault location estimations to
provide a single correct estimation of the actual location of the fault. The
performance of the proposed method is demonstrated using IEEE 34-node test
system.

</details>


### [205] [Wisdom of Crowds Effects under Antagonistic Interactions and Correlated Opinions](https://arxiv.org/abs/2510.19123)
*Muhammad Ahsan Razaq,Claudio Altafini*

Main category: eess.SY

TL;DR: 本文研究了有符号网络上线性意见动态模型中的群体智慧，并给出了模型提升或损害集体智慧的条件。


<details>
  <summary>Details</summary>
Motivation: 研究不同线性意见动态模型（如DeGroot、Friedkin-Johnsen及其串联模型）在有符号网络上如何影响集体智慧，即何时能提升或损害群体智慧。

Method: 分析了DeGroot、Friedkin-Johnsen (FJ) 和串联FJ等线性意见动态模型，并将其扩展到初始意见相关联的情况，以研究相关结构对智慧提升区域可行性和几何形状的影响。

Result: 给出了这些模型改善或损害集体智慧的条件。研究还表明，初始意见的相关结构会影响智慧提升区域的可行性及其几何特征。

Conclusion: 该研究确定了有符号网络上线性意见动态模型中集体智慧提升或损害的关键条件，并强调了初始意见相关性结构的重要性。

Abstract: This paper investigates the wisdom of crowds of linear opinion dynamics
models evolving on signed networks. Conditions are given under which models
such as the DeGroot, Friedkin-Johnsen (FJ) and concatenated FJ models improve
or undermine collective wisdom. The extension to dependent initial opinions is
also presented, highlighting how the correlation structure influences the
feasibility and geometry of the wisdom-improving regions.

</details>


### [206] [A Configurable Simulation Framework for Safety Assessment of Vulnerable Road Users](https://arxiv.org/abs/2510.19097)
*Zhitong He,Yaobin Chen,Brian King,Lingxi Li*

Main category: eess.SY

TL;DR: 本文提出一个轻量级、可配置的仿真框架，用于遵循Euro NCAP协议的弱势道路使用者（VRU）安全验证，利用基于规则的有限状态机（FSM）和V2X感知来模拟车辆自动化和评估安全裕度。


<details>
  <summary>Details</summary>
Motivation: 确保弱势道路使用者（VRU）的安全是高级驾驶辅助系统（ADAS）和互联自动驾驶车辆（CAV）技术面临的重大挑战。现实世界的VRU测试成本高昂，且难以捕捉或重复罕见和危险事件。

Method: 开发了一个轻量级、可配置的仿真框架，遵循欧洲新车评估计划（Euro NCAP）的VRU测试协议。框架中包含一个基于规则的有限状态机（FSM）作为运动规划器，以在VRU交互期间提供车辆自动化。此外，还集成了自我车辆感知和理想化的车联网（V2X）感知功能，以在不同场景中展示安全裕度。

Result: 这项工作提供了一个可扩展的平台，能够进行快速且可重复的VRU安全验证。该平台为在多样化、用户自定义设置中进行更广泛的案例研究部署铺平了道路。

Conclusion: 所提出的仿真框架对于构建一个更VRU友好和可持续的智能交通系统至关重要，因为它能有效支持VRU安全验证的广泛部署和研究。

Abstract: Ensuring the safety of vulnerable road users (VRUs), including pedestrians,
cyclists, electric scooter riders, and motorcyclists, remains a major challenge
for advanced driver assistance systems (ADAS) and connected and automated
vehicles (CAV) technologies. Real-world VRU tests are expensive and sometimes
cannot capture or repeat rare and hazardous events. In this paper, we present a
lightweight, configurable simulation framework that follows European New Car
Assessment Program (Euro NCAP) VRU testing protocols. A rule-based finite-state
machine (FSM) is developed as a motion planner to provide vehicle automation
during the VRU interaction. We also integrate ego-vehicle perception and
idealized Vehicle-to-Everything (V2X) awareness to demonstrate safety margins
in different scenarios. This work provides an extensible platform for rapid and
repeatable VRU safety validation, paving the way for broader case-study
deployment in diverse, user-defined settings, which will be essential for
building a more VRU-friendly and sustainable intelligent transportation system.

</details>


### [207] [Spatiotemporal Tubes based Control of Unknown Multi-Agent Systems for Temporal Reach-Avoid-Stay Tasks](https://arxiv.org/abs/2510.19232)
*Ahan Basu,Ratnangshu Das,Pushpak Jagtap*

Main category: eess.SY

TL;DR: 本文提出了一种针对未知多智能体系统的去中心化、无近似控制策略，通过生成时空管（STT）来确保每个智能体完成时序到达-避障-保持任务，同时避免智能体间碰撞。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为未知动态多智能体系统设计一种闭环、无近似、去中心化的控制策略，以使每个智能体在特定时间内到达目标，同时避开时变不安全区域并防止与其他智能体发生碰撞。

Method: 方法包括将时空管（STT）的要求表述为鲁棒优化问题（ROP），并通过基于采样的情景优化问题（SOP）来解决ROP中无限约束导致的不可行性问题。通过求解SOP生成STT，并设计相应的闭环控制策略来完成指定任务。

Result: 该方法成功生成了时空管和相应的闭环控制策略。通过两个案例研究（全向机器人和欧拉-拉格朗日系统建模的多无人机）证明了该方法的有效性。

Conclusion: 本文提出的方法能够为未知动态多智能体系统设计出有效的去中心化控制器，使其能够完成复杂的时序到达-避障-保持任务并避免碰撞，且该方法具有无近似和闭环的特点。

Abstract: The paper focuses on designing a controller for unknown dynamical multi-agent
systems to achieve temporal reach-avoid-stay tasks for each agent while
preventing inter-agent collisions. The main objective is to generate a
spatiotemporal tube (STT) for each agent and thereby devise a closed-form,
approximation-free, and decentralized control strategy that ensures the system
trajectory reaches the target within a specific time while avoiding
time-varying unsafe sets and collisions with other agents. In order to achieve
this, the requirements of STTs are formulated as a robust optimization problem
(ROP) and solved using a sampling-based scenario optimization problem (SOP) to
address the issue of infeasibility caused by the infinite number of constraints
in ROP. The STTs are generated by solving the SOP, and the corresponding
closed-form control is designed to fulfill the specified task. Finally, the
effectiveness of our approach is demonstrated through two case studies, one
involving omnidirectional robots and the other involving multiple drones
modelled as Euler-Lagrange systems.

</details>


### [208] [Managing Charging Induced Grid Stress and Battery Degradation in Electric Taxi Fleets](https://arxiv.org/abs/2510.19293)
*Michael Yuhas,Rajesh K. Ahir,Laksamana Vixell Tanjaya Hartono,Muhammad Dzaki Dwi Putranto,Arvind Easwaran,Suhono Harso Supangkat*

Main category: eess.SY

TL;DR: 本研究通过模拟电动汽车车队生命周期，开发了一种基于强化学习的充电策略，旨在平衡车队盈利能力、电池寿命和电网稳定性，并发现其优于基线策略。


<details>
  <summary>Details</summary>
Motivation: 电动汽车车队运营面临多重挑战：最大化短期利润可能导致以最高速率充电，但这会增加电网压力并加速电池退化，从而缩短车队寿命。因此，需要调和车队寿命、短期盈利能力和电网稳定性之间的冲突激励。

Method: 研究开发了一个电动汽车车队模拟器，用于评估不可预测的充电和乘车需求对电池退化的影响，并进而评估这些活动通过充电基础设施对电网的影响。该模拟器利用纽约市出租车数据集的真实世界出行数据。研究比较了基线80-20车队充电策略与旨在延长车队使用寿命和减轻电网压力的强化学习策略。在五年内监测了电网压力、电池退化和盈利能力。

Result: 研究发现，所学习的强化学习策略在延长车队服务寿命和减轻电网压力方面优于基线策略。该模拟器能帮助车队运营商评估不同充电策略对这些指标的影响，从而做出明智的未来决策。

Conclusion: 通过强化学习优化的充电策略能够有效平衡电动汽车车队的短期盈利、长期寿命和电网稳定性，并且所开发的模拟器为车队运营商提供了决策支持工具。

Abstract: Operating fleets of electric vehicles (EVs) introduces several challenges,
some of which are borne by the fleet operator, and some of which are borne by
the power grid. To maximize short-term profit a fleet operator could always
charge EVs at the maximum rate to ensure vehicles are ready to service ride
demand. However, due to the stochastic nature of electricity demand, charging
EVs at their maximum rate may potentially increase the grid stress and lead to
overall instability. Furthermore, high-rate charging of EVs can accelerate
battery degradation, thereby reducing the service lifespan of the fleet. This
study aims to reconcile the conflicting incentives of fleet longevity,
short-term profitability, and grid stability by simulating a taxi fleet
throughout its lifespan in relation to its charging policies and service
conditions. We develop an EV fleet simulator to evaluate the battery
degradation due to unpredictable charging and ride demand. Consequently, the
impact on the power grid through the charging infrastructure is assessed due to
these activities. This simulation utilizes publicly accessible real-world
travel data from the NYC taxi dataset. We compare a baseline 80-20 fleet
charging policy with a reinforcement learning-based policy designed to prolong
the fleet's service life and alleviate grid stress. We monitor grid stress,
battery degradation, and profitability over five years and find that our
learned policy outperforms the baseline. This simulator enables fleet operators
to assess the impact of different charging policies on these indicators to make
informed decisions in the future.

</details>


### [209] [Multi-UAV Flood Monitoring via CVT with Gaussian Mixture of Density Functions for Coverage Control](https://arxiv.org/abs/2510.19548)
*Jie Song,Yang Bai,Mikhail Svinin,Naoki Wakamiya*

Main category: eess.SY

TL;DR: 本研究提出了一种基于高斯混合密度函数（GMDF）的质心沃罗诺伊剖分（CVT）密度驱动覆盖框架，用于多无人机协调监测未知洪水区域并估算淹没范围，相比传统高斯模型，GMDF能更准确地表征淹没区，并在仿真中实现了更高的覆盖率。


<details>
  <summary>Details</summary>
Motivation: 有效监测未知洪水区域并准确估算淹没范围是重要的挑战，需要一种能更精确刻画淹没区且能有效协调多无人机的控制策略。

Method: 研究采用基于质心沃罗诺伊剖分（CVT）的密度驱动覆盖框架来协调多无人机。其中，密度函数通过高斯混合密度函数（GMDF）建模，并与传统的轴对齐高斯模型进行比较。性能评估在ROS/Gazebo环境中进行，测试了不同无人机机队规模（16、20、24）下的覆盖率。

Result: 结果显示，基于GMDF的公式持续实现更高的覆盖率，证明其在更准确表征淹没区域方面的有效性。

Conclusion: GMDF在洪水监测中具有显著优势，能有效增强洪水监测能力并改善无人机的空间分布。

Abstract: This study presents a control strategy for coordinating multiple unmanned
aerial vehicles (UAVs) to monitor unknown flood regions and estimate the extent
of inundation. The proposed method adopts a density-driven coverage framework
based on Centroidal Voronoi Tessellation (CVT), in which the density function
is modeled using a Gaussian Mixture of Density Functions (GMDF). This
formulation provides a more accurate characterization of inundated areas
compared to conventional axis-aligned Gaussian models. The performance of the
two density modeling approaches is systematically evaluated under different UAV
fleet sizes (16, 20, and 24), with multiple simulation trials conducted in the
ROS/Gazebo environment. The results show that the GMDF-based formulation
consistently achieves higher coverage rates, demonstrating its effectiveness in
enhancing flood monitoring and improving UAV spatial distribution.

</details>


### [210] [Control Barrier Functions for the Full Class of Signal Temporal Logic Tasks using Spatiotemporal Tubes](https://arxiv.org/abs/2510.19595)
*Ratnangshu Das,Subhodeep Choudhury,Pushpak Jagtap*

Main category: eess.SY

TL;DR: 本文提出了一种新的框架，利用时空管（STT）为通用信号时序逻辑（STL）规范合成时变控制障碍函数（TV-CBF），并通过场景优化问题（SOP）解决，并在机器人上进行了验证，提高了效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在确保系统满足复杂时序逻辑规范（STL）时可能存在效率问题或缺乏形式化保证。本研究旨在提供一种新的框架，能够为STL规范合成TV-CBF，并提供形式化保证，同时提高效率。

Method: 首先将时空管（STT）的合成公式化为一个鲁棒优化问题（ROP），并通过场景优化问题（SOP）进行求解，以确保生成的时空管能够捕捉给定的STL规范。然后，利用这些STT来构建TV-CBF，从而保证在任何使其不变的控制律下，系统都能满足STL任务。

Result: 通过SOP求解得到的时空管能够形式化地捕捉给定的STL规范。所构建的TV-CBF能确保在任何使其不变的控制律下，系统都能满足STL任务。在差速驱动移动机器人和四旋翼飞行器上的案例研究表明，该框架比现有方法具有更高的效率。

Conclusion: 本论文成功开发了一个新的框架，能够利用时空管为信号时序逻辑规范合成时变控制障碍函数，并提供形式化保证。该框架在机器人系统上表现出有效性，且相较于现有方法具有更高的效率。

Abstract: This paper introduces a new framework for synthesizing time-varying control
barrier functions (TV-CBFs) for general Signal Temporal Logic (STL)
specifications using spatiotemporal tubes (STT). We first formulate the STT
synthesis as a robust optimization problem (ROP) and solve it through a
scenario optimization problem (SOP), providing formal guarantees that the
resulting tubes capture the given STL specifications. These STTs are then used
to construct TV-CBFs, ensuring that under any control law rendering them
invariant, the system satisfies the STL tasks. We demonstrate the framework
through case studies on a differential-drive mobile robot and a quadrotor, and
provide a comparative analysis showing improved efficiency over existing
approaches.

</details>


### [211] [Optimal Kron-based Reduction of Networks (Opti-KRON) for Three-phase Distribution Feeders](https://arxiv.org/abs/2510.19608)
*Omid Mokhtari,Samuel Chevalier,Mads Almassalkhi*

Main category: eess.SY

TL;DR: 本文提出了一种新颖的基于Kron的结构保持型降维框架，用于非平衡配电馈线。该方法通过节点聚合和GPU加速的穷举搜索，生成能够准确重现原始网络电压剖面的简化模型，同时显著提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 分析大型非平衡配电馈线存在计算瓶颈。需要一种能够有效降低网络规模，同时保持结构完整性和电压剖面准确性的方法，以支持稳态分析和最优潮流研究。

Method: 该方法采用基于Kron的降维框架，通过混合整数优化（MIP）问题聚合电气相似的节点。为克服MIP的计算瓶颈，提出了一种穷举搜索公式来识别最优聚合决策，并强制执行电压裕度限制。该穷举网络降维算法可在GPU上并行化，实现可扩展的网络降维。

Result: 在具有5,991和8,381节点的真实配电馈线上验证了该框架。简化模型分别实现了高达90%和80%的网络降维，而最大电压幅值误差保持在0.003 p.u.以下。此外，在1000节点网络版本上，GPU加速的降维算法比基于CPU的对应算法快15倍。简化后的网络能以低误差近似完整系统的电压剖面，适用于稳态分析和最优潮流研究。

Conclusion: 该框架为非平衡配电馈线提供了可扩展、准确且结构保持的简化模型，显著提高了计算效率，同时保持了电压剖面的忠实度，适用于后续的电力系统分析。

Abstract: This paper presents a novel structure-preserving, Kron-based reduction
framework for unbalanced distribution feeders. The method aggregates
electrically similar nodes within a mixed-integer optimization (MIP) problem to
produce reduced networks that optimally reproduce the voltage profiles of the
original full network. To overcome computational bottlenecks of MIP
formulations, we propose an exhaustive-search formulation to identify optimal
aggregation decisions while enforcing voltage margin limits. The proposed
exhaustive network reduction algorithm is parallelizable on GPUs, which enables
scalable network reduction. The resulting reduced networks approximate the full
system's voltage profiles with low errors and are suitable for steady-state
analysis and optimal power flow studies. The framework is validated on two real
utility distribution feeders with 5,991 and 8,381 nodes. The reduced models
achieve up to 90% and 80% network reduction, respectively, while the maximum
voltage-magnitude error remains below 0.003 p.u. Furthermore, on a 1000-node
version of the network, the GPU-accelerated reduction algorithm runs up to 15x
faster than its CPU-based counterpart.

</details>


### [212] [Bridging Earth and Space: A Survey on HAPS for Non-Terrestrial Networks](https://arxiv.org/abs/2510.19731)
*G. Svistunov,A. Akhtarshenas,D. López-Pérez,M. Giordani,G. Geraci,H. Yanikomeroglu*

Main category: eess.SY

TL;DR: 本综述全面概述了高空平台站（HAPS）在6G无线网络中的用例、关键技术和集成策略，强调其作为连接地面与非地面基础设施的关键使能者的作用。


<details>
  <summary>Details</summary>
Motivation: HAPS作为6G网络的关键使能者正在兴起，能够弥合地面和非地面基础设施之间的鸿沟，提供广域覆盖、低延迟、高能效的宽带通信，并支持灵活部署以满足多样化应用需求。

Method: 本研究通过以下方式进行：讨论HAPS在6G生态系统中的用例、技术和集成策略；审查地面和非地面网络集成的最新架构；强调近期现场试验；检查关键使能技术，如信道建模、AI驱动的资源分配、干扰控制、移动性管理和能效通信；并概述开放研究挑战。

Result: HAPS在将连接扩展到服务不足地区、支持动态回传、实现大规模物联网以及为自动和沉浸式服务提供可靠的低延迟通信方面发挥着重要作用。论文回顾了最先进的架构和现场试验，并分析了信道建模、AI资源分配、干扰控制、移动性管理和能效通信等关键使能技术。

Conclusion: HAPS被定位为全球集成、弹性且可持续的6G网络的基础组成部分，本综述通过填补现有文献空白，明确了其在未来通信中的关键地位。

Abstract: HAPS are emerging as key enablers in the evolution of 6G wireless networks,
bridging terrestrial and non-terrestrial infrastructures. Operating in the
stratosphere, HAPS can provide wide-area coverage, low-latency,
energy-efficient broadband communications with flexible deployment options for
diverse applications. This survey delivers a comprehensive overview of HAPS use
cases, technologies, and integration strategies within the 6G ecosystem. The
roles of HAPS in extending connectivity to underserved regions, supporting
dynamic backhauling, enabling massive IoT, and delivering reliable low-latency
communications for autonomous and immersive services are discussed. The paper
reviews state-of-the-art architectures for terrestrial and non-terrestrial
network integration, highlights recent field trials. Furthermore, key enabling
technologies such as channel modeling, AI-driven resource allocation,
interference control, mobility management, and energy-efficient communications
are examined. The paper also outlines open research challenges. By addressing
existing gaps in the literature, this survey positions HAPS as a foundational
component of globally integrated, resilient, and sustainable 6G networks.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [213] [TinyUSFM: Towards Compact and Efficient Ultrasound Foundation Models](https://arxiv.org/abs/2510.19239)
*Chen Ma,Jing Jiao,Shuyu Liang,Junhu Fu,Qin Wang,Zeju Li,Yuanyuan Wang,Yi Guo*

Main category: eess.IV

TL;DR: TinyUSFM是首个轻量级超声基础模型，通过知识蒸馏和精选数据集，在大幅减少计算资源的同时，保持了大型超声基础模型（USFM）的优越性能和泛化能力，适用于资源受限的临床环境。


<details>
  <summary>Details</summary>
Motivation: 医学影像基础模型展现出卓越的泛化能力，但其对计算资源的巨大需求限制了在资源受限临床环境中的部署。因此，需要开发一种轻量级模型，在不牺牲性能的前提下提高计算效率。

Method: 本文提出了TinyUSFM，通过以下方法实现：1) 利用策略性精选的小数据集，从大型超声基础模型（USFM）进行知识蒸馏。2) 提出一种特征梯度驱动的核心集选择策略，以筛选高质量的紧凑训练数据，避免低质量冗余图像导致的训练退化。3) 开发了一种域分离掩码图像建模辅助的一致性驱动动态蒸馏框架，通过利用教师模型在不同域掩码上的一致性，自适应地传递知识，以保留超声图像中重要的空间和频率域特征。4) 建立了UniUS-Bench，一个包含15个器官、8个分类和10个分割数据集的最大的公开超声基准进行评估。

Result: TinyUSFM在仅使用20万张图像进行蒸馏的情况下，其参数量和GFLOPs分别仅为USFM的6.36%和6.40%，却能达到与USFM相当的性能。与普通模型相比，TinyUSFM在分类任务上性能提升9.45%，在分割任务上提升7.72%，并超越了所有最先进的轻量级模型。在多样化的医疗设备和中心上，TinyUSFM实现了84.91%的平均分类准确率和85.78%的平均分割Dice分数。

Conclusion: TinyUSFM成功地构建了一个轻量级的超声基础模型，它在计算效率上取得显著进步的同时，保持了大型基础模型的优越器官通用性和任务适应性。这使得超声基础模型能够有效部署于资源受限的临床环境中，为医学影像领域提供了重要的解决方案。

Abstract: Foundation models for medical imaging demonstrate superior generalization
capabilities across diverse anatomical structures and clinical applications.
Their outstanding performance relies on substantial computational resources,
limiting deployment in resource-constrained clinical environments. This paper
presents TinyUSFM, the first lightweight ultrasound foundation model that
maintains superior organ versatility and task adaptability of our large-scale
Ultrasound Foundation Model (USFM) through knowledge distillation with
strategically curated small datasets, delivering significant computational
efficiency without sacrificing performance. Considering the limited capacity
and representation ability of lightweight models, we propose a feature-gradient
driven coreset selection strategy to curate high-quality compact training data,
avoiding training degradation from low-quality redundant images. To preserve
the essential spatial and frequency domain characteristics during knowledge
transfer, we develop domain-separated masked image modeling assisted
consistency-driven dynamic distillation. This novel framework adaptively
transfers knowledge from large foundation models by leveraging teacher model
consistency across different domain masks, specifically tailored for ultrasound
interpretation. For evaluation, we establish the UniUS-Bench, the largest
publicly available ultrasound benchmark comprising 8 classification and 10
segmentation datasets across 15 organs. Using only 200K images in distillation,
TinyUSFM matches USFM's performance with just 6.36% of parameters and 6.40% of
GFLOPs. TinyUSFM significantly outperforms the vanilla model by 9.45% in
classification and 7.72% in segmentation, surpassing all state-of-the-art
lightweight models, and achieving 84.91% average classification accuracy and
85.78% average segmentation Dice score across diverse medical devices and
centers.

</details>


### [214] [Automated Morphological Analysis of Neurons in Fluorescence Microscopy Using YOLOv8](https://arxiv.org/abs/2510.19455)
*Banan Alnemri,Arwa Basbrain*

Main category: eess.IV

TL;DR: 该研究提出了一个基于YOLOv8的自动化神经元实例分割和形态学测量流程，用于荧光显微镜图像分析，实现了高分割精度和可靠的形态学测量。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜图像中神经元的精确分割和形态学分析对神经科学和生物医学成像至关重要，但传统方法耗时费力，需要大量人工和专业知识。

Method: 该方法利用YOLOv8模型，在一个高分辨率的干细胞衍生神经元数据集上进行训练，实现神经元实例分割。随后，该流程从真实标签和预测掩膜中提取生物学上重要的特征，如细胞长度、宽度、面积和灰度强度值。

Result: YOLOv8模型在分割任务上取得了超过97%的高精度。提取的形态学测量结果的总体准确率达到75.32%。

Conclusion: 所提出的集成框架为细胞成像和神经科学研究提供了一个有价值的自动化分析工具，减少了人工标注的需求，实现了神经元形态学可扩展、精确的量化分析。

Abstract: Accurate segmentation and precise morphological analysis of neuronal cells in
fluorescence microscopy images are crucial steps in neuroscience and biomedical
imaging applications. However, this process is labor-intensive and
time-consuming, requiring significant manual effort and expertise to ensure
reliable outcomes. This work presents a pipeline for neuron instance
segmentation and measurement based on a high-resolution dataset of
stem-cell-derived neurons. The proposed method uses YOLOv8, trained on manually
annotated microscopy images. The model achieved high segmentation accuracy,
exceeding 97%. In addition, the pipeline utilized both ground truth and
predicted masks to extract biologically significant features, including cell
length, width, area, and grayscale intensity values. The overall accuracy of
the extracted morphological measurements reached 75.32%, further supporting the
effectiveness of the proposed approach. This integrated framework offers a
valuable tool for automated analysis in cell imaging and neuroscience research,
reducing the need for manual annotation and enabling scalable, precise
quantification of neuron morphology.

</details>
