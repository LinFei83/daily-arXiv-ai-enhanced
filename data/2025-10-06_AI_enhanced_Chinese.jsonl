{"id": "2510.02464", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.02464", "abs": "https://arxiv.org/abs/2510.02464", "authors": ["Isaac Ngui", "Courtney McBeth", "André Santos", "Grace He", "Katherine J. Mimnaugh", "James D. Motes", "Luciano Soares", "Marco Morales", "Nancy M. Amato"], "title": "ERUPT: An Open Toolkit for Interfacing with Robot Motion Planners in Extended Reality", "comment": null, "summary": "We propose the Extended Reality Universal Planning Toolkit (ERUPT), an\nextended reality (XR) system for interactive motion planning. Our system allows\nusers to create and dynamically reconfigure environments while they plan robot\npaths. In immersive three-dimensional XR environments, users gain a greater\nspatial understanding. XR also unlocks a broader range of natural interaction\ncapabilities, allowing users to grab and adjust objects in the environment\nsimilarly to the real world, rather than using a mouse and keyboard with the\nscene projected onto a two-dimensional computer screen. Our system integrates\nwith MoveIt, a manipulation planning framework, allowing users to send motion\nplanning requests and visualize the resulting robot paths in virtual or\naugmented reality. We provide a broad range of interaction modalities, allowing\nusers to modify objects in the environment and interact with a virtual robot.\nOur system allows operators to visualize robot motions, ensuring desired\nbehavior as it moves throughout the environment, without risk of collisions\nwithin a virtual space, and to then deploy planned paths on physical robots in\nthe real world.", "AI": {"tldr": "本文提出了扩展现实通用规划工具包（ERUPT），一个XR系统，允许用户在沉浸式环境中交互式地创建和修改环境、规划机器人路径，并与MoveIt集成以可视化和部署路径。", "motivation": "传统的二维屏幕和键盘鼠标交互方式限制了用户对空间环境的理解和自然交互能力，需要更直观、沉浸式的机器人运动规划工具。", "method": "ERUPT系统是一个扩展现实（XR）系统，允许用户在沉浸式三维环境中创建和动态重新配置环境，同时规划机器人路径。它集成了MoveIt操作规划框架，提供多种交互模式，使用户能够像在现实世界中一样抓取和调整环境中的物体，并与虚拟机器人交互。", "result": "ERUPT系统增强了用户的空间理解能力，提供了更广泛的自然交互方式。用户可以在虚拟或增强现实中发送运动规划请求并可视化机器人路径，确保期望行为，避免虚拟空间中的碰撞，并最终将规划路径部署到真实世界的物理机器人上。", "conclusion": "ERUPT系统通过利用XR技术，显著改善了机器人运动规划的用户体验，提高了用户对环境的理解和交互的自然性，并实现了在虚拟环境中安全规划后部署到物理机器人的能力。"}}
{"id": "2510.02469", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02469", "abs": "https://arxiv.org/abs/2510.02469", "authors": ["Sung-Yeon Park", "Adam Lee", "Juanwu Lu", "Can Cui", "Luyang Jiang", "Rohit Gupta", "Kyungtae Han", "Ahmadreza Moradipari", "Ziran Wang"], "title": "SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting", "comment": null, "summary": "Driving scene manipulation with sensor data is emerging as a promising\nalternative to traditional virtual driving simulators. However, existing\nframeworks struggle to generate realistic scenarios efficiently due to limited\nediting capabilities. To address these challenges, we present SIMSplat, a\npredictive driving scene editor with language-aligned Gaussian splatting. As a\nlanguage-controlled editor, SIMSplat enables intuitive manipulation using\nnatural language prompts. By aligning language with Gaussian-reconstructed\nscenes, it further supports direct querying of road objects, allowing precise\nand flexible editing. Our method provides detailed object-level editing,\nincluding adding new objects and modifying the trajectories of both vehicles\nand pedestrians, while also incorporating predictive path refinement through\nmulti-agent motion prediction to generate realistic interactions among all\nagents in the scene. Experiments on the Waymo dataset demonstrate SIMSplat's\nextensive editing capabilities and adaptability across a wide range of\nscenarios. Project page: https://sungyeonparkk.github.io/simsplat/", "AI": {"tldr": "SIMSplat是一种基于语言对齐高斯泼溅的预测性驾驶场景编辑器，通过自然语言提示实现直观、精确且真实的场景操控，包括对象级编辑和多智能体运动预测。", "motivation": "现有的基于传感器数据的驾驶场景操控框架由于编辑能力有限，难以高效生成逼真的场景。", "method": "该研究提出了SIMSplat，一个语言对齐的高斯泼溅预测性驾驶场景编辑器。它通过自然语言提示实现直观操控，并结合语言与高斯重建场景，支持直接查询道路对象以进行精确灵活的编辑。方法提供详细的对象级编辑（如添加新对象、修改车辆和行人的轨迹），并通过多智能体运动预测引入预测路径优化，以生成场景中所有智能体之间逼真的交互。", "result": "在Waymo数据集上的实验证明了SIMSplat广泛的编辑能力和在各种场景下的适应性。", "conclusion": "SIMSplat提供了一种新颖且强大的方法，通过结合自然语言控制、精确的对象级编辑和预测性多智能体交互，克服了现有驾驶场景操控方法的局限性，实现了直观、灵活且逼真的场景生成。"}}
{"id": "2510.02526", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02526", "abs": "https://arxiv.org/abs/2510.02526", "authors": ["Anamika J H", "Anujith Muraleedharan"], "title": "U-LAG: Uncertainty-Aware, Lag-Adaptive Goal Retargeting for Robotic Manipulation", "comment": "8 pages, 5 figures. Accepted to the IROS 2025 Workshop on Perception\n  and Planning for Mobile Manipulation in Changing Environments", "summary": "Robots manipulating in changing environments must act on percepts that are\nlate, noisy, or stale. We present U-LAG, a mid-execution goal-retargeting layer\nthat leaves the low-level controller unchanged while re-aiming task goals\n(pre-contact, contact, post) as new observations arrive. Unlike motion\nretargeting or generic visual servoing, U-LAG treats in-flight goal re-aiming\nas a first-class, pluggable module between perception and control. Our main\ntechnical contribution is UAR-PF, an uncertainty-aware retargeter that\nmaintains a distribution over object pose under sensing lag and selects goals\nthat maximize expected progress. We instantiate a reproducible Shift x Lag\nstress test in PyBullet/PandaGym for pick, push, stacking, and peg insertion,\nwhere the object undergoes abrupt in-plane shifts while synthetic perception\nlag is injected during approach. Across 0-10 cm shifts and 0-400 ms lags,\nUAR-PF and ICP degrade gracefully relative to a no-retarget baseline, achieving\nhigher success with modest end-effector travel and fewer aborts; simple\noperational safeguards further improve stability. Contributions: (1) UAR-PF for\nlag-adaptive, uncertainty-aware goal retargeting; (2) a pluggable retargeting\ninterface; and (3) a reproducible Shift x Lag benchmark with evaluation on\npick, push, stacking, and peg insertion.", "AI": {"tldr": "本文提出了U-LAG，一个在执行过程中重新调整任务目标的中间层，以及UAR-PF，一个不确定性感知目标重定位器，用于在感知延迟和环境变化下最大化预期进展。通过“位移x延迟”基准测试，UAR-PF在各种操作任务中表现出鲁棒性。", "motivation": "在动态环境中操作的机器人，其感知信息可能存在延迟、噪声或过时，这使得它们难以准确执行任务。现有的运动重定向或通用视觉伺服方法并未将飞行中目标重定向视为感知与控制之间的一等可插拔模块。", "method": "本文提出了U-LAG，一个在执行过程中重新调整任务目标的中间层，它在不改变低级控制器的情况下，根据新观测调整任务目标（接触前、接触中、接触后）。核心技术贡献是UAR-PF（不确定性感知重定位器），它在感知延迟下维护物体姿态的分布，并选择能最大化预期进展的目标。此外，还提出了一个可复现的“位移x延迟”压力测试基准，在PyBullet/PandaGym中模拟抓取、推动、堆叠和插销任务，其中物体会突然发生平面位移，并注入合成感知延迟。", "result": "在0-10厘米的位移和0-400毫秒的延迟下，UAR-PF和ICP（作为对比）相对于无重定向基线表现出更优的性能，成功率更高，末端执行器移动距离适中，中止次数更少。简单的操作安全措施进一步提高了稳定性。", "conclusion": "本文贡献包括：(1) 用于延迟自适应、不确定性感知目标重定向的UAR-PF；(2) 一个可插拔的重定向接口；(3) 一个可复现的“位移x延迟”基准测试，并在抓取、推动、堆叠和插销任务上进行了评估。"}}
{"id": "2510.02538", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02538", "abs": "https://arxiv.org/abs/2510.02538", "authors": ["Yilin Wang", "Shangzhe Li", "Haoyi Niu", "Zhiao Huang", "Weitong Zhang", "Hao Su"], "title": "A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models", "comment": null, "summary": "We are interested in solving the problem of imitation learning with a limited\namount of real-world expert data. Existing offline imitation methods often\nstruggle with poor data coverage and severe performance degradation. We propose\na solution that leverages robot simulators to achieve online imitation\nlearning. Our sim-to-real framework is based on world models and combines\nonline imitation pretraining with offline finetuning. By leveraging online\ninteractions, our approach alleviates the data coverage limitations of offline\nmethods, leading to improved robustness and reduced performance degradation\nduring finetuning. It also enhances generalization during domain transfer. Our\nempirical results demonstrate its effectiveness, improving success rates by at\nleast 31.7% in sim-to-sim transfer and 23.3% in sim-to-real transfer over\nexisting offline imitation learning baselines.", "AI": {"tldr": "本文提出一种利用机器人模拟器进行在线模仿学习的sim-to-real框架，结合在线预训练和离线微调，有效解决了有限专家数据下离线模仿学习的数据覆盖和性能下降问题。", "motivation": "在现实世界专家数据有限的情况下，现有的离线模仿学习方法常面临数据覆盖不足和性能严重下降的问题。", "method": "提出一种基于世界模型的sim-to-real框架，通过利用机器人模拟器实现在线模仿学习。该方法结合了在线模仿预训练和离线微调。", "result": "该方法缓解了离线方法的数据覆盖限制，提高了微调过程中的鲁棒性并减少了性能下降，同时增强了领域迁移时的泛化能力。在sim-to-sim迁移中，成功率比现有基线提高了至少31.7%；在sim-to-real迁移中，成功率提高了23.3%。", "conclusion": "所提出的在线模仿学习框架通过利用模拟器和世界模型，有效解决了有限专家数据下离线模仿学习的局限性，显著提高了sim-to-real迁移的成功率和泛化能力。"}}
{"id": "2510.02514", "categories": ["eess.IV", "cs.CV", "cs.IT", "eess.SP", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.02514", "abs": "https://arxiv.org/abs/2510.02514", "authors": ["Guy Ohayon", "Pierre-Etienne H. Fiquet", "Florentin Guth", "Jona Ballé", "Eero P. Simoncelli"], "title": "Learning a distance measure from the information-estimation geometry of data", "comment": "Code available at\n  https://github.com/ohayonguy/information-estimation-metric", "summary": "We introduce the Information-Estimation Metric (IEM), a novel form of\ndistance function derived from an underlying continuous probability density\nover a domain of signals. The IEM is rooted in a fundamental relationship\nbetween information theory and estimation theory, which links the\nlog-probability of a signal with the errors of an optimal denoiser, applied to\nnoisy observations of the signal. In particular, the IEM between a pair of\nsignals is obtained by comparing their denoising error vectors over a range of\nnoise amplitudes. Geometrically, this amounts to comparing the score vector\nfields of the blurred density around the signals over a range of blur levels.\nWe prove that the IEM is a valid global metric and derive a closed-form\nexpression for its local second-order approximation, which yields a Riemannian\nmetric. For Gaussian-distributed signals, the IEM coincides with the\nMahalanobis distance. But for more complex distributions, it adapts, both\nlocally and globally, to the geometry of the distribution. In practice, the IEM\ncan be computed using a learned denoiser (analogous to generative diffusion\nmodels) and solving a one-dimensional integral. To demonstrate the value of our\nframework, we learn an IEM on the ImageNet database. Experiments show that this\nIEM is competitive with or outperforms state-of-the-art supervised image\nquality metrics in predicting human perceptual judgments.", "AI": {"tldr": "本文提出了一种新的距离函数——信息-估计度量（IEM），它源于信号连续概率密度，通过连接信息论和估计论，利用去噪误差向量来比较信号。IEM是一个有效的全局度量，能适应复杂分布的几何结构，并在预测人类感知判断方面表现出色。", "motivation": "研究旨在引入一种新的距离函数，能够从信号的底层连续概率密度中导出，并建立信息论与估计论之间的基本关系。这种度量需要能够通过比较信号的去噪误差向量来量化它们之间的距离，并且能够适应复杂数据分布的几何特性，以更好地反映信号间的实际差异，特别是在感知质量方面。", "method": "IEM通过比较一对信号在不同噪声幅度下的去噪误差向量来获得，这在几何上等同于比较信号周围模糊密度在不同模糊水平下的得分向量场。研究证明IEM是一个有效的全局度量，并推导了其局部二阶近似的闭式表达式，从而得到一个黎曼度量。在实践中，IEM可以通过学习到的去噪器（类似于生成扩散模型）和一个一维积分来计算。作者在ImageNet数据库上学习了一个IEM，并进行实验。", "result": "IEM被证明是一个有效的全局度量，其局部二阶近似产生了一个黎曼度量。对于高斯分布信号，IEM与马哈拉诺比斯距离一致，但对于更复杂的分布，它能局部和全局地适应分布的几何结构。在ImageNet数据库上学习到的IEM在预测人类感知判断方面，与最先进的监督图像质量度量相比，具有竞争力或表现更优。", "conclusion": "IEM是一种新颖且有效的距离函数，它从信息论和估计论的深层关系中导出，能够适应复杂数据分布的几何特性。通过连接去噪误差与信号的对数概率，IEM不仅在理论上是一个有效的全局度量，而且在实际应用中，如预测人类感知图像质量方面，也展现出卓越的性能。"}}
{"id": "2510.02355", "categories": ["eess.SY", "cs.IT", "cs.LG", "cs.SY", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.02355", "abs": "https://arxiv.org/abs/2510.02355", "authors": ["Yubo Zhang", "Jeremy Johnston", "Xiaodong Wang"], "title": "An Encoder-Decoder Network for Beamforming over Sparse Large-Scale MIMO Channels", "comment": "13 pages, 9 figures, submitted to TCOM and is waiting for reviews", "summary": "We develop an end-to-end deep learning framework for downlink beamforming in\nlarge-scale sparse MIMO channels. The core is a deep EDN architecture with\nthree modules: (i) an encoder NN, deployed at each user end, that compresses\nestimated downlink channels into low-dimensional latent vectors. The latent\nvector from each user is compressed and then fed back to the BS. (ii) a\nbeamformer decoder NN at the BS that maps recovered latent vectors to\nbeamformers, and (iii) a channel decoder NN at the BS that reconstructs\ndownlink channels from recovered latent vectors to further refine the\nbeamformers. The training of EDN leverages two key strategies: (a)\nsemi-amortized learning, where the beamformer decoder NN contains an analytical\ngradient ascent during both training and inference stages, and (b) knowledge\ndistillation, where the loss function consists of a supervised term and an\nunsupervised term, and starting from supervised training with MMSE beamformers,\nover the epochs, the model training gradually shifts toward unsupervised using\nthe sum-rate objective. The proposed EDN beamforming framework is extended to\nboth far-field and near-field hybrid beamforming scenarios. Extensive\nsimulations validate its effectiveness under diverse network and channel\nconditions.", "AI": {"tldr": "本文提出了一种名为EDN的端到端深度学习框架，用于大规模稀疏MIMO信道中的下行链路波束成形，通过编码器-解码器网络、半摊销学习和知识蒸馏实现高效性能。", "motivation": "在大规模稀疏MIMO信道中，需要开发一种高效的下行链路波束成形方法，以应对复杂的信道条件和网络要求。", "method": "核心是一个深度EDN架构，包含三个模块：(i) 用户端的编码器神经网络，将估计的下行链路信道压缩成低维潜在向量并反馈给基站；(ii) 基站的波束成形器解码器神经网络，将恢复的潜在向量映射到波束成形器；(iii) 基站的信道解码器神经网络，从恢复的潜在向量重建下行链路信道以进一步优化波束成形器。训练策略包括半摊销学习（波束成形器解码器在训练和推理阶段都包含解析梯度上升）和知识蒸馏（损失函数包含监督项和无监督项，训练从MMSE波束成形器的监督训练逐渐转向使用和速率目标的无监督训练）。该框架还扩展到远场和近场混合波束成形场景。", "result": "广泛的模拟验证了该框架在各种网络和信道条件下的有效性。", "conclusion": "所提出的EDN波束成形框架在处理大规模稀疏MIMO信道（包括远场和近场混合波束成形场景）的下行链路波束成形方面表现出显著的有效性。"}}
{"id": "2510.02324", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02324", "abs": "https://arxiv.org/abs/2510.02324", "authors": ["Wannan Yang", "Xinchi Qiu", "Lei Yu", "Yuchen Zhang", "Oliver Aobo Yang", "Narine Kokhlikyan", "Nicola Cancedda", "Diego Garcia-Olano"], "title": "Hallucination reduction with CASAL: Contrastive Activation Steering For Amortized Learning", "comment": null, "summary": "Large Language Models (LLMs) exhibit impressive capabilities but often\nhallucinate, confidently providing incorrect answers instead of admitting\nignorance. Prior work has shown that models encode linear representations of\ntheir own knowledge and that activation steering can reduce hallucinations.\nThese approaches, however, require real-time monitoring and intervention during\ninference. We introduce Contrastive Activation Steering for Amortized Learning\n(CASAL), an efficient algorithm that connects interpretability with amortized\noptimization. CASAL directly bakes the benefits of activation steering into\nmodel's weights. Once trained, LLMs answer questions they know while abstaining\nfrom answering those they do not. CASAL's light-weight design requires training\nonly a submodule of a single transformer layer and yet reduces hallucination by\n30%-40% across multiple short-form QA benchmarks. CASAL is 30x more\ncompute-efficient and 20x more data-efficient than strong LoRA-based baselines\nsuch as SFT and DPO, boosting its practical applicability in data scarce\ndomains. Importantly, CASAL also generalizes effectively to out-of-distribution\n(OOD) domains. We showcase CASAL's flexibility in mitigating hallucinations in\nboth text-only and vision-language models. To our knowledge, CASAL is the first\nsteering-based training method that has been shown to be effective for both\ndense and Mixture-of-Experts (MoE) models. CASAL represents a promising step\nforward for applying interpretability-inspired method for practical deployment\nin production systems.", "AI": {"tldr": "CASAL是一种高效算法，通过将激活引导的好处直接融入模型权重，显著减少大型语言模型幻觉，且计算和数据效率高，适用于多种模型和领域。", "motivation": "大型语言模型（LLMs）常出现幻觉，自信地给出错误答案而非承认无知。现有激活引导方法虽能减少幻觉，但需在推理时进行实时监控和干预，效率不高。", "method": "本文提出了CASAL（Contrastive Activation Steering for Amortized Learning），一种将可解释性与摊销优化相结合的高效算法。CASAL直接将激活引导的优势融入模型的权重中，仅需训练单个Transformer层的一个子模块。它使得LLM能回答已知问题并对未知问题进行拒绝回答。", "result": "CASAL在多个短文本问答基准上将幻觉减少了30%-40%。它比基于LoRA的SFT和DPO等强基线模型计算效率高30倍，数据效率高20倍，提升了其在数据稀缺领域的实用性。此外，CASAL能有效泛化到分布外（OOD）领域，并成功应用于纯文本和视觉-语言模型。据作者所知，CASAL是首个对密集模型和专家混合（MoE）模型都有效的引导式训练方法。", "conclusion": "CASAL代表了将可解释性启发方法应用于生产系统实际部署的一个有前景的进步。它提供了一种高效且实用的解决方案来减轻LLM的幻觉问题。"}}
{"id": "2510.02418", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02418", "abs": "https://arxiv.org/abs/2510.02418", "authors": ["Sagnik Anupam", "Davis Brown", "Shuo Li", "Eric Wong", "Hamed Hassani", "Osbert Bastani"], "title": "BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks", "comment": null, "summary": "LLM web agents now browse and take actions on the open web, yet current agent\nevaluations are constrained to sandboxed environments or artificial tasks. We\nintroduce BrowserArena, a live open-web agent evaluation platform that collects\nuser-submitted tasks, runs Arena-style head-to-head comparisons, and uses\nstep-level human feedback to surface failure modes. Collecting and analyzing\nstep-level annotations on the agent traces, we identify three consistent\nfailure modes: captcha resolution, pop-up banner removal, and direct navigation\nto URLs. By constructing targeted datasets to further study these tasks, we\ndiscover variations in how different language models navigate these failure\nmodes. We find, for example, that o4-mini deploys a wider variety of strategies\nto circumvent captcha resolution than other models and DeepSeek-R1 consistently\nmisleads users about captcha resolution. Our findings surface both the\ndiversity and brittleness of current web agents. More broadly, our benchmarking\nmethodology provides an approach to evaluating and understanding web agent\nfailure modes at scale.", "AI": {"tldr": "本文介绍了BrowserArena，一个用于评估大型语言模型（LLM）网络代理的实时开放网络平台。通过收集用户任务和人工反馈，识别出验证码处理、弹窗移除和直接URL导航等常见失败模式，并发现不同模型在这些方面表现的差异和脆弱性。", "motivation": "当前对LLM网络代理的评估仅限于沙盒环境或人工任务，无法真实反映其在开放网络中的表现。因此，需要一个能够在大规模真实世界环境中评估代理性能的平台。", "method": "研究团队开发了BrowserArena平台，该平台收集用户提交的任务，进行Arena风格的代理头对头比较，并利用步骤级别的人工反馈来识别失败模式。通过分析代理追踪的步骤级注释，构建了针对特定任务的数据集，以深入研究这些失败模式。", "result": "研究识别出三种一致的失败模式：验证码解析、弹窗横幅移除和直接导航到URL。通过进一步研究，发现不同语言模型在处理这些失败模式时存在差异，例如o4-mini在规避验证码解析方面采用了更多样化的策略，而DeepSeek-R1在验证码解析方面经常误导用户。这些发现揭示了当前网络代理的多样性和脆弱性。", "conclusion": "BrowserArena提供了一种评估和理解网络代理失败模式的规模化方法，揭示了当前网络代理的多样性和脆弱性。该基准测试方法为未来研究提供了方向，以改进LLM网络代理在开放网络中的性能。"}}
{"id": "2510.02543", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02543", "abs": "https://arxiv.org/abs/2510.02543", "authors": ["JoonHo Lee", "Sunho Park"], "title": "Exploring OCR-augmented Generation for Bilingual VQA", "comment": null, "summary": "We investigate OCR-augmented generation with Vision Language Models (VLMs),\nexploring tasks in Korean and English toward multilingualism. To support\nresearch in this domain, we train and release KLOCR, a strong bilingual OCR\nbaseline trained on 100M instances to augment VLMs with OCR ability. To\ncomplement existing VQA benchmarks, we curate KOCRBench for Korean VQA, and\nanalyze different prompting methods. Extensive experiments show that\nOCR-extracted text significantly boosts performance across open source and\ncommercial models. Our work offers new insights into OCR-augmented generation\nfor bilingual VQA. Model, code, and data are available at\nhttps://github.com/JHLee0513/KLOCR.", "AI": {"tldr": "本文研究了使用OCR增强视觉语言模型（VLMs）的多语言（韩语和英语）生成任务。为此，作者训练并发布了强大的双语OCR基线KLOCR，并创建了韩语VQA基准KOCRBench。实验表明，OCR提取的文本显著提升了模型性能。", "motivation": "研究旨在探索并支持OCR增强的VLM多语言生成能力，特别是在韩语和英语任务中，并弥补现有VQA基准在韩语方面的不足。", "method": "1. 训练并发布了KLOCR，一个基于1亿实例的双语OCR基线，用于增强VLM的OCR能力。2. 策划了KOCRBench，一个针对韩语VQA的新基准。3. 分析了不同的提示方法。", "result": "OCR提取的文本显著提升了开源和商业模型在OCR增强生成任务中的性能。", "conclusion": "OCR增强生成为双语VQA提供了新的见解，证明了OCR提取文本对提升VLM性能的有效性。"}}
{"id": "2510.02584", "categories": ["cs.RO", "cs.SY", "eess.SY", "math.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.02584", "abs": "https://arxiv.org/abs/2510.02584", "authors": ["Mohammad Abtahi", "Navid Mojahed", "Shima Nazari"], "title": "Efficient Optimal Path Planning in Dynamic Environments Using Koopman MPC", "comment": "This work has been submitted to the ACC2026 conference", "summary": "This paper presents a data-driven model predictive control framework for\nmobile robots navigating in dynamic environments, leveraging Koopman operator\ntheory. Unlike the conventional Koopman-based approaches that focus on the\nlinearization of system dynamics only, our work focuses on finding a global\nlinear representation for the optimal path planning problem that includes both\nthe nonlinear robot dynamics and collision-avoidance constraints. We deploy\nextended dynamic mode decomposition to identify linear and bilinear Koopman\nrealizations from input-state data. Our open-loop analysis demonstrates that\nonly the bilinear Koopman model can accurately capture nonlinear state-input\ncouplings and quadratic terms essential for collision avoidance, whereas linear\nrealizations fail to do so. We formulate a quadratic program for the robot path\nplanning in the presence of moving obstacles in the lifted space and determine\nthe optimal robot action in an MPC framework. Our approach is capable of\nfinding the safe optimal action 320 times faster than a nonlinear MPC\ncounterpart that solves the path planning problem in the original state space.\nOur work highlights the potential of bilinear Koopman realizations for\nlinearization of highly nonlinear optimal control problems subject to nonlinear\nstate and input constraints to achieve computational efficiency similar to\nlinear problems.", "AI": {"tldr": "本文提出了一种基于Koopman算子理论的数据驱动模型预测控制（MPC）框架，用于移动机器人在动态环境中的导航。该方法利用双线性Koopman模型将包含非线性机器人动力学和避碰约束的路径规划问题线性化，实现了比传统非线性MPC快320倍的计算效率。", "motivation": "传统的Koopman方法主要关注系统动力学的线性化，而本文旨在为整个最优路径规划问题（包括非线性机器人动力学和避碰约束）找到一个全局线性表示，以提高计算效率，特别是对于受非线性状态和输入约束的高度非线性最优控制问题。", "method": "该研究利用Koopman算子理论，并通过扩展动态模式分解（EDMD）从输入-状态数据中识别出线性及双线性Koopman实现。在提升空间中，将机器人路径规划问题（包含移动障碍物）表述为一个二次规划（QP），并将其整合到MPC框架中以确定最优机器人动作。", "result": "开环分析表明，只有双线性Koopman模型能准确捕捉非线性状态-输入耦合和避碰所需的二次项，而线性实现则无法做到。与在原始状态空间中解决路径规划问题的非线性MPC相比，该方法寻找安全最优动作的速度快了320倍。", "conclusion": "研究强调了双线性Koopman实现在线性化受非线性状态和输入约束的高度非线性最优控制问题方面的巨大潜力，能够实现与线性问题相似的计算效率。"}}
{"id": "2510.02673", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.02673", "abs": "https://arxiv.org/abs/2510.02673", "authors": ["Seyed Saleh Mousavi Khaleghi", "Jinyuan Chen", "Sivacarendran Balendhran", "Alexander Corletto", "Shifan Wang", "Huan Liu", "James Bullock", "Kenneth B. Crozier"], "title": "High Pixel Resolution Visible to Extended Shortwave Infrared Single Pixel Imaging with a black Phosphorus-Molybdenum disulfide (bP-MoS2) photodiode", "comment": null, "summary": "High-resolution infrared imagers are currently more expensive than CMOS and\nCCD cameras, due to costly sensor arrays. Van der Waals (vdWs) materials\npresent an opportunity for low-cost, room temperature infrared photodetectors.\nAlthough photodetectors based on vdWs materials show promising performance,\ncreating a megapixel array is yet to be achieved. Imaging with a single vdWs\nphotodetector typically relies on time-consuming mechanical scanning and\nsuffers from low resolution. Single pixel imaging (SPI) offers an affordable\nalternative to achieve high-resolution imaging, utilizing only one\nphotodetector and a spatial light modulator. Progress in SPI using vdWs\nmaterial photodetectors has been limited, with only one prior demonstration in\nthe near infrared range (64$\\times$64 pixels). In this work, we demonstrate a\nhigh-resolution SPI system (1023$\\times$768 for visible light and\n512$\\times$512 for extended shortwave infrared) using a black\nphosphorus-molybdenum disulfide (bP-MoS$_2$) photodiode, surpassing earlier\nvdWs material SPI implementations by a factor of 64 in pixel count. We\nintroduce an easy-to-implement edge detection method for rapid feature\nextraction. We employ compressed sampling and reduce imaging time by a factor\nof four. Our compressed sampling approach is based on a cyclic S-matrix, which\nis derived from a Hadamard-based sequence, where each row is a circular shift\nof the first row. This enables efficient imaging reconstruction via circular\nconvolution and Fourier transforms, allowing fewer measurements while\npreserving the key image features. Our method for SPI using a vdWs material\nphotodetector presents the opportunity for inexpensive shortwave infrared and\nmidwave infrared cameras, and thus may enable advances in gas detection,\nbiomedical imaging, autonomous driving, security, and surveillance.", "AI": {"tldr": "该研究利用黑磷-二硫化钼（bP-MoS₂）光电二极管，结合单像素成像（SPI）和压缩采样技术，实现了高分辨率、低成本的短波红外（SWIR）成像，并大幅提升了像素计数和成像效率。", "motivation": "高分辨率红外成像仪因传感器阵列昂贵而价格昂贵。范德华（vdWs）材料为低成本、室温红外光电探测器提供了机会，但基于vdWs材料的光电探测器在创建百万像素阵列方面尚未实现。单vdWs光电探测器成像通常依赖耗时的机械扫描且分辨率低。单像素成像（SPI）提供了一种经济实惠的高分辨率成像替代方案，但此前基于vdWs材料的SPI进展有限。", "method": "本研究使用黑磷-二硫化钼（bP-MoS₂）光电二极管作为单一探测器，构建了一个高分辨率单像素成像（SPI）系统。为了加速特征提取，引入了一种易于实现的边缘检测方法。通过采用基于循环S矩阵（源自哈达玛序列，每行是第一行的循环移位）的压缩采样，将成像时间缩短了四倍。这种方法通过循环卷积和傅里叶变换实现高效的图像重建，在减少测量次数的同时保留了关键图像特征。", "result": "该系统成功演示了高分辨率SPI，在可见光下达到1023x768像素，在扩展短波红外（SWIR）下达到512x512像素，将之前vdWs材料SPI实现的像素计数提高了64倍。通过压缩采样，成像时间缩短了四倍，并实现了高效的图像重建，同时保留了关键图像特征。", "conclusion": "该方法利用vdWs材料光电探测器实现了单像素成像，为低成本的短波红外和中波红外相机提供了可能性。这有望推动气体检测、生物医学成像、自动驾驶、安防和监控等领域的进步。"}}
{"id": "2510.02363", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.02363", "abs": "https://arxiv.org/abs/2510.02363", "authors": ["Mohammad Reza Abedi", "Zahra Rashidi", "Nader Mokari", "Hamid Saeedi", "Nizar Zorba"], "title": "Precise HDV Positioning through Safety-Aware Integrated Sensing and Communication in a Value-of-Information-Driven 6G V2X System", "comment": null, "summary": "Recent advancements in Integrated Sensing and Communications (ISAC) have\nunlocked new potential for addressing the dual demands of high-resolution\npositioning and reliable communication in 6G Vehicle-to-Everything (V2X)\nnetworks. These capabilities are vital for transmitting safety-critical data\nfrom Connected Autonomous Vehicles (CAVs) to improve metrics such as Time to\nCollision (TTC) and reduce the Collision Risk (CR) ratio. However, limited\nradio resources and interference remain major obstacles to achieving both\nprecision and capacity simultaneously. The challenge intensifies in\nmixedtraffic scenarios involving Human-Driven Vehicles (HDVs), which lack\nconnectivity and cannot share their status or positioning. Additionally, CAV\nsensors are limited in range and accuracy, making detection of HDVs unreliable.\nISAC plays a pivotal role here by enabling the sensing of HDV positions via\nshared communication infrastructure, improving environmental awareness. To\naddress these challenges, this paper proposes a novel Value of Information\n(VoI) metric that prioritizes the transmission of safety-critical data. The\njoint sensing-communication-control problem is modeled as a two-time-scale\nsequential decision process and solved using a Multi-Agent Distributed\nDeterministic Policy Gradient (MADDPG) algorithm. By focusing on high- VoI\ndata, the framework reduces complexity and optimizes network and traffic\nresource usage. Simulations show that the proposed approach significantly\nreduces the CR ratio by at least 33% and improves the TTC by up to 66%,\ndemonstrating its effectiveness in enhancing safety and efficiency in\nmixedautonomy environments.", "AI": {"tldr": "本文提出一种基于信息价值（VoI）的ISAC框架，利用多智能体分布式确定性策略梯度（MADDPG）算法，在6G V2X混合交通场景中优先传输安全关键数据，显著降低碰撞风险并提高碰撞时间。", "motivation": "6G V2X网络需要高精度定位和可靠通信来传输联网自动驾驶车辆（CAV）的安全关键数据，以改善碰撞时间（TTC）和降低碰撞风险（CR）比率。然而，有限的无线电资源和干扰是同时实现精度和容量的主要障碍。在涉及缺乏连接性的人工驾驶车辆（HDV）的混合交通场景中，挑战更加严峻，因为CAV传感器检测HDV的范围和精度有限。ISAC在通过共享通信基础设施感知HDV位置方面发挥关键作用，以提高环境感知能力。", "method": "本文提出了一种新颖的信息价值（VoI）度量来优先传输安全关键数据。将联合感知-通信-控制问题建模为双时间尺度序列决策过程，并使用多智能体分布式确定性策略梯度（MADDPG）算法进行求解。通过关注高VoI数据，该框架降低了复杂性并优化了网络和交通资源使用。", "result": "仿真结果表明，所提出的方法将碰撞风险比率至少降低了33%，并将碰撞时间提高了高达66%，证明了其在增强混合自动驾驶环境安全性和效率方面的有效性。", "conclusion": "所提出的基于VoI的ISAC框架通过优先处理安全关键数据，有效提升了混合自动驾驶环境下的安全性与效率，显著降低了碰撞风险并提高了碰撞时间，同时优化了网络和交通资源利用。"}}
{"id": "2510.02326", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02326", "abs": "https://arxiv.org/abs/2510.02326", "authors": ["Vivek Bhavsar", "Joseph Ereifej", "Aravanan Gurusami"], "title": "Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval", "comment": "21 pages, 5 figures", "summary": "Large language models accelerate literature synthesis but can hallucinate and\nmis-cite, limiting their usefulness in expert workflows. We present RA-FSM\n(Research Assistant - Finite State Machine), a modular GPT-based research\nassistant that wraps generation in a finite-state control loop: Relevance ->\nConfidence -> Knowledge. The system is grounded in vector retrieval and a\ndeterministic citation pipeline. The controller filters out-of-scope queries,\nscores answerability, decomposes questions, and triggers retrieval only when\nneeded, and emits answers with confidence labels and in-corpus, de-duplicated\nreferences. A ranked-tier ingestion workflow constructs a domain knowledge base\nfrom journals, conferences, indices, preprints, and patents, writing both to a\ndense vector index and to a relational store of normalized metrics. We\nimplement the system for photonics and evaluate it on six task categories:\nanalytical reasoning, numerical analysis, methodological critique, comparative\nsynthesis, factual extraction, and application design. In blinded A/B reviews,\ndomain experts prefer RA-FSM to both a strong Notebook LM (NLM) and a vanilla\nDefault GPT API call single-pass baseline, citing stronger boundary-condition\nhandling and more defensible evidence use. Coverage and novelty analyses\nindicate that RA-FSM explores beyond the NLM while incurring tunable latency\nand cost overheads. The design emphasizes transparent, well-cited answers for\nhigh-stakes technical work and is generalizable to other scientific domains.", "AI": {"tldr": "RA-FSM是一个基于GPT的模块化研究助手，通过有限状态机控制循环（相关性->置信度->知识）来解决大型语言模型在文献合成中幻觉和错误引用的问题，提供更可靠、有证据支持的答案。", "motivation": "大型语言模型（LLMs）在文献合成方面虽然能加速工作，但其固有的幻觉和错误引用问题限制了它们在专家工作流程中的实用性。", "method": "RA-FSM（研究助手-有限状态机）是一个模块化的GPT-based研究助手，它将生成过程封装在一个有限状态控制循环中（相关性->置信度->知识）。该系统以向量检索和确定性引用管道为基础。控制器过滤超出范围的查询，评估可回答性，分解问题，仅在需要时触发检索，并输出带有置信度标签和语料库内去重引用的答案。一个分层摄取工作流从期刊、会议、索引、预印本和专利构建领域知识库，写入密集向量索引和规范化指标的关系存储。该系统在光子学领域实施，并在六个任务类别上进行评估。", "result": "在盲法A/B评估中，领域专家认为RA-FSM优于Notebook LM（NLM）和普通的Default GPT API单次调用基线，理由是其边界条件处理能力更强，证据使用更具说服力。覆盖率和新颖性分析表明，RA-FSM在可调的延迟和成本开销下，探索范围超越了NLM。", "conclusion": "RA-FSM的设计强调为高风险技术工作提供透明、引用充分的答案，并且可以推广到其他科学领域。"}}
{"id": "2510.02423", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02423", "abs": "https://arxiv.org/abs/2510.02423", "authors": ["Hang Wu", "Yujun Cai", "Haonan Ge", "Hongkai Chen", "Ming-Hsuan Yang", "Yiwei Wang"], "title": "RefineShot: Rethinking Cinematography Understanding with Foundational Skill Evaluation", "comment": null, "summary": "Cinematography understanding refers to the ability to recognize not only the\nvisual content of a scene but also the cinematic techniques that shape\nnarrative meaning. This capability is attracting increasing attention, as it\nenhances multimodal understanding in real-world applications and underpins\ncoherent content creation in film and media. As the most comprehensive\nbenchmark for this task, ShotBench spans a wide range of cinematic concepts and\nVQA-style evaluations, with ShotVL achieving state-of-the-art results on it.\nHowever, our analysis reveals that ambiguous option design in ShotBench and\nShotVL's shortcomings in reasoning consistency and instruction adherence\nundermine evaluation reliability, limiting fair comparison and hindering future\nprogress. To overcome these issues, we systematically refine ShotBench through\nconsistent option restructuring, conduct the first critical analysis of\nShotVL's reasoning behavior, and introduce an extended evaluation protocol that\njointly assesses task accuracy and core model competencies. These efforts lead\nto RefineShot, a refined and expanded benchmark that enables more reliable\nassessment and fosters future advances in cinematography understanding.", "AI": {"tldr": "本文通过修正ShotBench中模糊的选项设计并分析ShotVL在推理一致性和指令遵循方面的不足，提出了RefineShot，一个更可靠的电影摄影理解基准，以促进该领域未来的发展。", "motivation": "电影摄影理解对于多模态理解和内容创作至关重要。然而，现有最全面的基准ShotBench存在选项设计模糊的问题，而最先进的模型ShotVL在推理一致性和指令遵循方面存在缺陷，这些都损害了评估的可靠性，限制了公平比较并阻碍了未来的进展。", "method": "作者通过一致的选项重构系统性地改进了ShotBench；首次对ShotVL的推理行为进行了批判性分析；并引入了一个扩展的评估协议，该协议共同评估任务准确性和核心模型能力。", "result": "这些努力共同产生了RefineShot，一个经过改进和扩展的基准。该基准能够进行更可靠的评估。", "conclusion": "RefineShot基准能够实现更可靠的电影摄影理解评估，并有望促进该领域的未来发展。"}}
{"id": "2510.02561", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02561", "abs": "https://arxiv.org/abs/2510.02561", "authors": ["Derek Shi", "Ruben Glatt", "Christine Klymko", "Shubham Mohole", "Hongjun Choi", "Shashank Kushwaha", "Sam Sakla", "Felipe Leno da Silva"], "title": "Oracle-RLAIF: An Improved Fine-Tuning Framework for Multi-modal Video Models through Reinforcement Learning from Ranking Feedback", "comment": "Proceedings of the 39th Annual Conference on Neural Information\n  Processing Systems, ARLET Workshop (Aligning Reinforcement Learning\n  Experimentalists and Theorists)", "summary": "Recent advances in large video-language models (VLMs) rely on extensive\nfine-tuning techniques that strengthen alignment between textual and visual\ncomprehension. Leading pipelines typically pair supervised fine-tuning (SFT)\nwith reinforcement learning from preference data to enhance video\ncomprehension. However, as VLMs scale in parameter size, so does the cost of\ngathering enough human feedback. To make fine-tuning more cost-effective,\nrecent frameworks explore reinforcement learning with AI feedback (RLAIF),\nwhich replace human preference with AI as a judge. Current RLAIF frameworks\nrely on a specialized reward model trained with video narratives to create\ncalibrated scalar rewards -- an expensive and restrictive pipeline. We propose\nOracle-RLAIF, a novel framework that replaces the trained reward model with a\nmore general Oracle ranker which acts as a drop-in model ranking candidate\nmodel responses rather than scoring them. Alongside Oracle-RLAIF, we introduce\n$GRPO_{rank}$, a novel rank-based loss function based on Group Relative Policy\nOptimization (GRPO) that directly optimizes ordinal feedback with rank-aware\nadvantages. Empirically, we demonstrate that Oracle-RLAIF consistently\noutperforms leading VLMs using existing fine-tuning methods when evaluated\nacross various video comprehension benchmarks. Oracle-RLAIF paves the path to\ncreating flexible and data-efficient frameworks for aligning large multi-modal\nvideo models with reinforcement learning from rank rather than score.", "AI": {"tldr": "本文提出Oracle-RLAIF框架，用通用Oracle排序器取代昂贵的奖励模型，并引入新的基于排名的损失函数$GRPO_{rank}$，以更经济高效地对大型视频-语言模型（VLM）进行微调，实现视频理解性能的提升。", "motivation": "大型VLM的微调高度依赖人类反馈，成本高昂。现有基于AI反馈的强化学习（RLAIF）框架需要训练专门的奖励模型来生成校准标量奖励，这既昂贵又受限，因此需要更具成本效益的方法。", "method": "本文提出Oracle-RLAIF，用一个通用的Oracle排序器替代传统的训练奖励模型，该排序器直接对候选模型响应进行排序而非评分。同时，引入$GRPO_{rank}$，这是一种基于Group Relative Policy Optimization (GRPO)的新型基于排名的损失函数，它直接通过感知排名的优势来优化序数反馈。", "result": "实验证明，Oracle-RLAIF在各种视频理解基准测试中，始终优于使用现有微调方法的领先VLM。", "conclusion": "Oracle-RLAIF为创建灵活且数据高效的框架铺平了道路，该框架通过基于排名的强化学习而非基于分数的强化学习，来对大型多模态视频模型进行对齐。"}}
{"id": "2510.02594", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02594", "abs": "https://arxiv.org/abs/2510.02594", "authors": ["Ruo Chen", "David Blow", "Adnan Abdullah", "Md Jahidul Islam"], "title": "SubSense: VR-Haptic and Motor Feedback for Immersive Control in Subsea Telerobotics", "comment": "Presented at the OCEANS 2025 Great Lakes Conference", "summary": "This paper investigates the integration of haptic feedback and virtual\nreality (VR) control interfaces to enhance teleoperation and telemanipulation\nof underwater ROVs (remotely operated vehicles). Traditional ROV teleoperation\nrelies on low-resolution 2D camera feeds and lacks immersive and sensory\nfeedback, which diminishes situational awareness in complex subsea\nenvironments. We propose SubSense -- a novel VR-Haptic framework incorporating\na non-invasive feedback interface to an otherwise 1-DOF (degree of freedom)\nmanipulator, which is paired with the teleoperator's glove to provide haptic\nfeedback and grasp status. Additionally, our framework integrates end-to-end\nsoftware for managing control inputs and displaying immersive camera views\nthrough a VR platform. We validate the system through comprehensive experiments\nand user studies, demonstrating its effectiveness over conventional\nteleoperation interfaces, particularly for delicate manipulation tasks. Our\nresults highlight the potential of multisensory feedback in immersive virtual\nenvironments to significantly improve remote situational awareness and mission\nperformance, offering more intuitive and accessible ROV operations in the\nfield.", "AI": {"tldr": "本文提出并验证了一个名为SubSense的VR-触觉框架，用于增强水下ROV的远程操作和遥控，通过提供沉浸式视觉和触觉反馈来提高态势感知和任务性能。", "motivation": "传统ROV远程操作依赖低分辨率2D摄像机画面，缺乏沉浸式和感官反馈，导致在复杂水下环境中态势感知能力不足。", "method": "本文提出了SubSense框架，该框架将非侵入式触觉反馈接口集成到一个1-DOF机械手（与远程操作员手套配对以提供触觉反馈和抓取状态）中。此外，该框架还集成了端到端软件，用于管理控制输入并通过VR平台显示沉浸式摄像机视图。", "result": "通过全面的实验和用户研究，系统得到验证，证明其在精细操作任务方面优于传统远程操作界面。结果强调了沉浸式虚拟环境中多感官反馈在显著改善远程态势感知和任务性能方面的潜力。", "conclusion": "沉浸式虚拟环境中的多感官反馈可以显著提高远程态势感知和任务性能，为现场ROV操作提供更直观、更便捷的方式。"}}
{"id": "2510.02700", "categories": ["eess.IV", "cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.02700", "abs": "https://arxiv.org/abs/2510.02700", "authors": ["Sagar Lekhak", "Emmett J. Ientilucci", "Jasper Baur", "Susmita Ghosh"], "title": "A UAV-Based VNIR Hyperspectral Benchmark Dataset for Landmine and UXO Detection", "comment": "This work has been accepted and will be presented at the Indian\n  Geoscience and Remote Sensing Symposium (InGARSS) 2025 in India and will\n  appear in the IEEE InGARSS 2025 Proceedings", "summary": "This paper introduces a novel benchmark dataset of Visible and Near-Infrared\n(VNIR) hyperspectral imagery acquired via an unmanned aerial vehicle (UAV)\nplatform for landmine and unexploded ordnance (UXO) detection research. The\ndataset was collected over a controlled test field seeded with 143 realistic\nsurrogate landmine and UXO targets, including surface, partially buried, and\nfully buried configurations. Data acquisition was performed using a Headwall\nNano-Hyperspec sensor mounted on a multi-sensor drone platform, flown at an\naltitude of approximately 20.6 m, capturing 270 contiguous spectral bands\nspanning 398-1002 nm. Radiometric calibration, orthorectification, and\nmosaicking were performed followed by reflectance retrieval using a two-point\nEmpirical Line Method (ELM), with reference spectra acquired using an SVC\nspectroradiometer. Cross-validation against six reference objects yielded RMSE\nvalues below 1.0 and SAM values between 1 and 6 degrees in the 400-900 nm\nrange, demonstrating high spectral fidelity. The dataset is released alongside\nraw radiance cubes, GCP/AeroPoint data, and reference spectra to support\nreproducible research. This contribution fills a critical gap in open-access\nUAV-based hyperspectral data for landmine detection and offers a multi-sensor\nbenchmark when combined with previously published drone-based electromagnetic\ninduction (EMI) data from the same test field.", "AI": {"tldr": "本文介绍了一个新的无人机（UAV）可见光和近红外（VNIR）高光谱图像基准数据集，用于地雷和未爆弹药（UXO）探测研究，并证明了其高光谱保真度。", "motivation": "地雷和未爆弹药探测领域缺乏开放获取的基于无人机的高光谱数据，这阻碍了相关研究的进展。", "method": "研究人员使用搭载Headwall Nano-Hyperspec传感器的多传感器无人机平台，在约20.6米的高度，对一个布有143个模拟地雷和UXO目标（包括地表、半埋和全埋）的受控测试场进行了数据采集。数据涵盖398-1002纳米范围内的270个连续光谱波段。数据经过辐射校准、正射校正和镶嵌处理，并使用两点经验线法（ELM）结合SVC光谱辐射计的参考光谱进行反射率反演。数据集还包含原始辐射立方体、GCP/AeroPoint数据和参考光谱。", "result": "通过与六个参考对象的交叉验证，该数据集在400-900纳米范围内的均方根误差（RMSE）低于1.0，光谱角映射（SAM）值在1到6度之间，显示出高光谱保真度。该数据集已公开发布，以支持可重复研究。", "conclusion": "该贡献填补了开放获取的基于无人机的高光谱地雷探测数据的关键空白，并且与同一测试场先前发布的无人机电磁感应（EMI）数据结合时，可作为多传感器基准，具有重要研究价值。"}}
{"id": "2510.02364", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.02364", "abs": "https://arxiv.org/abs/2510.02364", "authors": ["Tianyi Li", "Tianyu Liu", "Yicheng Yang"], "title": "Conceptualizing and Modeling Communication-Based Cyberattacks on Automated Vehicles", "comment": null, "summary": "Adaptive Cruise Control (ACC) is rapidly proliferating across electric\nvehicles (EVs) and internal combustion engine (ICE) vehicles, enhancing traffic\nflow while simultaneously expanding the attack surface for communication-based\ncyberattacks. Because the two powertrains translate control inputs into motion\ndifferently, their cyber-resilience remains unquantified. Therefore, we\nformalize six novel message-level attack vectors and implement them in a\nring-road simulation that systematically varies the ACC market penetration\nrates (MPRs) and the spatial pattern of compromised vehicles. A three-tier risk\ntaxonomy converts disturbance metrics into actionable defense priorities for\npractitioners. Across all simulation scenarios, EV platoons exhibit lower\nvelocity standard deviation, reduced spacing oscillations, and faster\npost-attack recovery compared to ICE counterparts, revealing an inherent\nstability advantage. These findings clarify how controller-to-powertrain\ncoupling influences vulnerability and offer quantitative guidance for the\ndetection and mitigation of attacks in mixed automated traffic.", "AI": {"tldr": "研究发现，在通信网络攻击下，电动汽车（EV）自适应巡航控制（ACC）车队比燃油车（ICE）车队表现出更强的网络韧性，具有更低的速度波动、更小的间距振荡和更快的攻击后恢复能力。", "motivation": "自适应巡航控制（ACC）在电动汽车和燃油车中日益普及，在改善交通流的同时也增加了基于通信的网络攻击面。由于两种动力系统将控制输入转化为运动的方式不同，其网络韧性差异尚未被量化。", "method": "研究形式化了六种新颖的消息级攻击向量，并在环形道路仿真中实施。仿真系统地改变了ACC的市场渗透率和受损车辆的空间分布。通过三层风险分类法将扰动指标转化为可操作的防御优先级。", "result": "在所有仿真场景中，电动汽车车队相比燃油车车队表现出更低的速度标准差、更小的间距振荡和更快的攻击后恢复能力，揭示了电动汽车固有的稳定性优势。", "conclusion": "研究结果阐明了控制器与动力系统的耦合如何影响车辆的脆弱性，并为混合自动驾驶交通中攻击的检测和缓解提供了量化指导。"}}
{"id": "2510.02327", "categories": ["cs.CL", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.02327", "abs": "https://arxiv.org/abs/2510.02327", "authors": ["So Kuroki", "Yotaro Kubo", "Takuya Akiba", "Yujin Tang"], "title": "KAME: Tandem Architecture for Enhancing Knowledge in Real-Time Speech-to-Speech Conversational AI", "comment": null, "summary": "Real-time speech-to-speech (S2S) models excel at generating natural,\nlow-latency conversational responses but often lack deep knowledge and semantic\nunderstanding. Conversely, cascaded systems combining automatic speech\nrecognition, a text-based Large Language Model (LLM), and text-to-speech\nsynthesis offer superior knowledge representation at the cost of high latency,\nwhich disrupts the flow of natural interaction. This paper introduces a novel\nhybrid architecture that bridges the gap between these two paradigms. Our\nframework processes user speech through an S2S transformer for immediate\nresponsiveness while concurrently relaying the query to a powerful back-end\nLLM. The LLM's text-based response is then injected in real time to guide the\nS2S model's speech generation, effectively infusing its output with rich\nknowledge without the full latency penalty of a cascaded system. We evaluated\nour method using a speech-synthesized variant of the MT-Bench benchmark that\nconsists of multi-turn question-answering sessions. The results demonstrate\nthat our system substantially outperforms a baseline S2S model in response\ncorrectness, approaching that of a cascaded system, while maintaining a latency\non par with the baseline.", "AI": {"tldr": "本文提出了一种混合架构，将实时语音到语音（S2S）模型的低延迟优势与大型语言模型（LLM）的深层知识相结合，通过实时注入LLM响应来指导S2S生成，从而在保持低延迟的同时显著提高响应的正确性。", "motivation": "现有的实时语音到语音（S2S）模型在生成自然、低延迟的对话响应方面表现出色，但缺乏深层知识和语义理解。而结合自动语音识别、文本LLM和文本到语音合成的级联系统虽然提供卓越的知识表示，但延迟高，会破坏自然交互的流畅性。研究旨在弥合这两种范式之间的差距。", "method": "该框架通过S2S transformer处理用户语音以实现即时响应，同时将查询并发地转发给强大的后端LLM。LLM的文本响应随后被实时注入，以指导S2S模型的语音生成，从而在不完全承担级联系统延迟惩罚的情况下，将丰富的知识融入S2S输出中。", "result": "研究使用MT-Bench基准的语音合成变体进行了评估。结果表明，该系统在响应正确性方面显著优于基线S2S模型，接近级联系统，同时保持了与基线相当的低延迟。", "conclusion": "该混合架构成功地将实时S2S模型的低延迟特性与LLM的丰富知识相结合，提供了一种在保持自然交互流畅性的同时，显著提高语音到语音系统知识水平的有效方法。"}}
{"id": "2510.02480", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02480", "abs": "https://arxiv.org/abs/2510.02480", "authors": ["Andrea Wynn", "Metod Jazbec", "Charith Peris", "Rinat Khaziev", "Anqi Liu", "Daniel Khashabi", "Eric Nalisnick"], "title": "Safe and Efficient In-Context Learning via Risk Control", "comment": null, "summary": "Large language models (LLMs) demonstrate a remarkable ability to learn new\ntasks from a few in-context examples. However, this flexibility introduces\nsafety concerns: LLMs can be influenced by incorrect or malicious\ndemonstrations -- for example, if an adversary tampers with or injects harmful\nexamples without a human supervisor noticing. This motivates principled designs\nin which the system itself includes built-in mechanisms to guard against such\nattacks. We propose a novel approach to limit the degree to which harmful\ndemonstrations can degrade model performance. First, we define a baseline\n``safe'' behavior for the model -- the model's performance given no in-context\ndemonstrations (zero-shot). Next, we apply distribution-free risk control\n(DFRC) to control the extent to which in-context samples can decay performance\nbelow zero-shot. We achieve this by leveraging dynamic early exit prediction,\nignoring later attention heads that attend the most to the unsafe inputs.\nFinally, we propose modifications to DFRC that allow it to both control risk\nfor harmful inputs \\textit{and} leverage performance and efficiency gains on\nhelpful inputs. We present both theoretical and empirical results showing that\nour approach can effectively control risk for harmful in-context demonstrations\nwhile simultaneously achieving substantial computational efficiency gains with\nhelpful demonstrations.", "AI": {"tldr": "本文提出了一种新方法，通过结合无分布风险控制（DFRC）和动态提前退出预测，有效限制有害上下文示例对大型语言模型（LLMs）性能的负面影响，同时提升有益示例的计算效率。", "motivation": "大型语言模型（LLMs）虽然能通过少量上下文示例学习新任务，但这种灵活性也带来了安全隐患。恶意或不正确的示例可能在无人察觉的情况下影响模型，导致性能下降。因此，需要设计内置机制来防范此类攻击。", "method": "首先，定义模型的“安全”基线行为，即无上下文示例（零样本）时的性能。其次，应用无分布风险控制（DFRC）来限制上下文示例导致模型性能低于零样本基线的程度。这通过动态提前退出预测实现，即忽略那些过度关注不安全输入的后期注意力头。最后，对DFRC进行修改，使其既能控制有害输入的风险，又能利用有益输入带来的性能和效率提升。", "result": "理论和实证结果表明，所提出的方法能够有效控制有害上下文示例带来的风险，同时在处理有益示例时显著提高计算效率。", "conclusion": "该研究提出了一种新颖且有效的方法，可以在确保大型语言模型抵御有害上下文示例风险的同时，提高模型在处理有益示例时的性能和效率。"}}
{"id": "2510.02566", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02566", "abs": "https://arxiv.org/abs/2510.02566", "authors": ["Qiao Feng", "Yiming Huang", "Yufu Wang", "Jiatao Gu", "Lingjie Liu"], "title": "PhysHMR: Learning Humanoid Control Policies from Vision for Physically Plausible Human Motion Reconstruction", "comment": null, "summary": "Reconstructing physically plausible human motion from monocular videos\nremains a challenging problem in computer vision and graphics. Existing methods\nprimarily focus on kinematics-based pose estimation, often leading to\nunrealistic results due to the lack of physical constraints. To address such\nartifacts, prior methods have typically relied on physics-based post-processing\nfollowing the initial kinematics-based motion estimation. However, this\ntwo-stage design introduces error accumulation, ultimately limiting the overall\nreconstruction quality. In this paper, we present PhysHMR, a unified framework\nthat directly learns a visual-to-action policy for humanoid control in a\nphysics-based simulator, enabling motion reconstruction that is both physically\ngrounded and visually aligned with the input video. A key component of our\napproach is the pixel-as-ray strategy, which lifts 2D keypoints into 3D spatial\nrays and transforms them into global space. These rays are incorporated as\npolicy inputs, providing robust global pose guidance without depending on noisy\n3D root predictions. This soft global grounding, combined with local visual\nfeatures from a pretrained encoder, allows the policy to reason over both\ndetailed pose and global positioning. To overcome the sample inefficiency of\nreinforcement learning, we further introduce a distillation scheme that\ntransfers motion knowledge from a mocap-trained expert to the\nvision-conditioned policy, which is then refined using physically motivated\nreinforcement learning rewards. Extensive experiments demonstrate that PhysHMR\nproduces high-fidelity, physically plausible motion across diverse scenarios,\noutperforming prior approaches in both visual accuracy and physical realism.", "AI": {"tldr": "PhysHMR提出了一种统一的框架，通过学习视觉到动作策略，直接在物理模拟器中从单目视频重建物理上合理且视觉上对齐的人体运动。", "motivation": "现有方法主要依赖基于运动学的姿态估计，常因缺乏物理约束而产生不真实结果。传统的两阶段设计（先运动学估计后物理后处理）导致误差累积，限制了重建质量。", "method": "PhysHMR是一个统一框架，直接学习在物理模拟器中控制人形的视觉到动作策略。关键组件是“像素即射线”策略，将2D关键点提升为3D空间射线并转换为全局空间，作为策略输入提供鲁棒的全局姿态指导。结合软全局定位和来自预训练编码器的局部视觉特征。为克服强化学习的样本效率问题，引入蒸馏方案，将运动捕捉训练的专家知识转移到视觉条件策略，并通过物理驱动的强化学习奖励进行细化。", "result": "PhysHMR在各种场景下生成了高保真、物理上合理的人体运动，在视觉准确性和物理真实性方面均优于现有方法。", "conclusion": "PhysHMR通过其统一的、基于物理的学习方法，成功解决了从单目视频重建物理上合理人体运动的挑战，实现了高保真和物理真实性。"}}
{"id": "2510.02614", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02614", "abs": "https://arxiv.org/abs/2510.02614", "authors": ["Harsh Gupta", "Xiaofeng Guo", "Huy Ha", "Chuer Pan", "Muqing Cao", "Dongjae Lee", "Sebastian Sherer", "Shuran Song", "Guanya Shi"], "title": "UMI-on-Air: Embodiment-Aware Guidance for Embodiment-Agnostic Visuomotor Policies", "comment": "Result videos can be found at umi-on-air.github.io", "summary": "We introduce UMI-on-Air, a framework for embodiment-aware deployment of\nembodiment-agnostic manipulation policies. Our approach leverages diverse,\nunconstrained human demonstrations collected with a handheld gripper (UMI) to\ntrain generalizable visuomotor policies. A central challenge in transferring\nthese policies to constrained robotic embodiments-such as aerial\nmanipulators-is the mismatch in control and robot dynamics, which often leads\nto out-of-distribution behaviors and poor execution. To address this, we\npropose Embodiment-Aware Diffusion Policy (EADP), which couples a high-level\nUMI policy with a low-level embodiment-specific controller at inference time.\nBy integrating gradient feedback from the controller's tracking cost into the\ndiffusion sampling process, our method steers trajectory generation towards\ndynamically feasible modes tailored to the deployment embodiment. This enables\nplug-and-play, embodiment-aware trajectory adaptation at test time. We validate\nour approach on multiple long-horizon and high-precision aerial manipulation\ntasks, showing improved success rates, efficiency, and robustness under\ndisturbances compared to unguided diffusion baselines. Finally, we demonstrate\ndeployment in previously unseen environments, using UMI demonstrations\ncollected in the wild, highlighting a practical pathway for scaling\ngeneralizable manipulation skills across diverse-and even highly\nconstrained-embodiments. All code, data, and checkpoints will be publicly\nreleased after acceptance. Result videos can be found at umi-on-air.github.io.", "AI": {"tldr": "UMI-on-Air是一个框架，用于将与载体无关的操作策略部署到受限机器人（如空中机械手）。它通过提出载体感知扩散策略（EADP），在推理时将高级UMI策略与低级控制器结合，并利用梯度反馈调整轨迹，以实现动态可行性和高效执行。", "motivation": "将从不受限人类演示中训练出的通用视觉运动策略转移到受限机器人载体（如空中机械手）时，存在控制和机器人动力学不匹配的问题，这常导致策略在部署时表现不佳和执行效率低下。", "method": "该方法利用手持夹具（UMI）收集多样、不受限的人类演示来训练通用视觉运动策略。为了解决载体转移问题，提出了载体感知扩散策略（EADP），它在推理时将高级UMI策略与低级载体特定控制器耦合。通过将控制器跟踪成本的梯度反馈整合到扩散采样过程中，EADP引导轨迹生成朝向适应部署载体的动态可行模式，实现即插即用的载体感知轨迹适应。", "result": "在多项长周期和高精度空中操作任务中，与未引导的扩散基线相比，该方法显著提高了成功率、效率和在干扰下的鲁棒性。此外，它还展示了在未知环境中部署的能力，使用了在野外收集的UMI演示。", "conclusion": "UMI-on-Air提供了一个实用的途径，可以将通用的操作技能扩展到多样化甚至高度受限的载体上，实现了与载体无关的策略的载体感知部署。"}}
{"id": "2510.02713", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02713", "abs": "https://arxiv.org/abs/2510.02713", "authors": ["Se-Ho Lee", "Keunsoo Ko", "Seung-Wook Kim"], "title": "Image Enhancement Based on Pigment Representation", "comment": "14 pages, 9 figures, accepted at IEEE Transactions on Multimedia\n  (TMM)", "summary": "This paper presents a novel and efficient image enhancement method based on\npigment representation. Unlike conventional methods where the color\ntransformation is restricted to pre-defined color spaces like RGB, our method\ndynamically adapts to input content by transforming RGB colors into a\nhigh-dimensional feature space referred to as \\textit{pigments}. The proposed\npigment representation offers adaptability and expressiveness, achieving\nsuperior image enhancement performance. The proposed method involves\ntransforming input RGB colors into high-dimensional pigments, which are then\nreprojected individually and blended to refine and aggregate the information of\nthe colors in pigment spaces. Those pigments are then transformed back into RGB\ncolors to generate an enhanced output image. The transformation and\nreprojection parameters are derived from the visual encoder which adaptively\nestimates such parameters based on the content in the input image. Extensive\nexperimental results demonstrate the superior performance of the proposed\nmethod over state-of-the-art methods in image enhancement tasks, including\nimage retouching and tone mapping, while maintaining relatively low\ncomputational complexity and small model size.", "AI": {"tldr": "本文提出了一种基于“颜料表示”的新型高效图像增强方法，通过将RGB颜色动态转换为高维特征空间，实现了自适应和富有表现力的图像增强。", "motivation": "传统图像增强方法受限于预定义的颜色空间（如RGB），缺乏对输入内容的自适应性。", "method": "该方法首先将输入RGB颜色转换为高维“颜料”空间，然后对这些颜料进行单独重投影和混合以精炼信息。接着，将处理后的颜料转换回RGB颜色以生成增强图像。转换和重投影参数由视觉编码器根据输入图像内容自适应估计。", "result": "实验结果表明，该方法在图像修饰和色调映射等增强任务中，性能优于现有最先进方法，同时保持较低的计算复杂度和较小的模型尺寸。", "conclusion": "所提出的颜料表示方法提供了卓越的适应性和表现力，从而实现了出色的图像增强性能。"}}
{"id": "2510.02385", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.02385", "abs": "https://arxiv.org/abs/2510.02385", "authors": ["Jose M. Campos-Salazar", "Felipe Santander", "Sebastian Larrain"], "title": "Dynamic Modeling and Control System Analysis for Continuous-Disc Filters in Pulp Mill Operations", "comment": null, "summary": "Vacuum disc filtration is critical in pulp mills for white liquor\nclarification and pulp washing, involving tightly coupled dynamics between\nrotational speed, vacuum pressure, slurry concentration, filtrate flow, and\ncake thickness. These nonlinear interactions are often regulated using\nempirical methods, lacking formal modeling and control. This article develops a\ndynamic, multivariable model of a continuous-disc filter (CD-filter) system\nbased on first principles, simplified to a single representative disc for\ntractability. A linearized state-space model supports the design of two control\nstrategies: a decentralized PI-based scheme and a centralized model predictive\ncontrol (MPC). MATLAB-Simulink simulations reveal that MPC outperforms PI in\ntracking accuracy, overshoot reduction, and disturbance rejection. A 3D\nefficiency surface illustrates the importance of coordinating inlet flow and\nsolids concentration. Results highlight the need for advanced multivariable\ncontrol in optimizing CD-filter performance.", "AI": {"tldr": "本文开发了连续盘式过滤器（CD-filter）的动态多变量模型，并设计了分散式PI和集中式MPC两种控制策略，仿真结果表明MPC在性能上优于PI，强调了先进多变量控制的重要性。", "motivation": "制浆厂中的真空盘式过滤是关键环节，涉及复杂的非线性动态，但目前常采用经验方法进行调节，缺乏正式的模型和控制策略。", "method": "基于第一性原理建立了连续盘式过滤器的动态多变量模型，并简化为单个代表性圆盘。随后，开发了线性化状态空间模型，并在此基础上设计了分散式PI控制方案和集中式模型预测控制（MPC）。通过MATLAB-Simulink进行仿真验证。", "result": "仿真结果显示，模型预测控制（MPC）在跟踪精度、过冲抑制和扰动抑制方面均优于PI控制。研究还通过3D效率曲面展示了协调入口流量和固体浓度对性能的重要性。", "conclusion": "研究结果强调了在优化连续盘式过滤器性能方面，需要采用先进的多变量控制策略。"}}
{"id": "2510.02328", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.02328", "abs": "https://arxiv.org/abs/2510.02328", "authors": ["Ziqing Wang", "Chengsheng Mao", "Xiaole Wen", "Yuan Luo", "Kaize Ding"], "title": "AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering", "comment": "EMNLP Findings", "summary": "Medical Multimodal Large Language Models (Med-MLLMs) have shown great promise\nin medical visual question answering (Med-VQA). However, when deployed in\nlow-resource settings where abundant labeled data are unavailable, existing\nMed-MLLMs commonly fail due to their medical reasoning capability bottlenecks:\n(i) the intrinsic reasoning bottleneck that ignores the details from the\nmedical image; (ii) the extrinsic reasoning bottleneck that fails to\nincorporate specialized medical knowledge. To address those limitations, we\npropose AMANDA, a training-free agentic framework that performs medical\nknowledge augmentation via LLM agents. Specifically, our intrinsic medical\nknowledge augmentation focuses on coarse-to-fine question decomposition for\ncomprehensive diagnosis, while extrinsic medical knowledge augmentation grounds\nthe reasoning process via biomedical knowledge graph retrieval. Extensive\nexperiments across eight Med-VQA benchmarks demonstrate substantial\nimprovements in both zero-shot and few-shot Med-VQA settings. The code is\navailable at https://github.com/REAL-Lab-NU/AMANDA.", "AI": {"tldr": "本文提出了AMANDA，一个免训练的代理框架，通过LLM代理进行医学知识增强，以解决医疗多模态大语言模型（Med-MLLMs）在低资源环境下医学推理能力不足的问题。", "motivation": "现有的医疗多模态大语言模型（Med-MLLMs）在低资源设置中表现不佳，因为它们存在医学推理能力瓶颈：一是内在推理瓶颈（忽略医学图像细节），二是外在推理瓶颈（未能融入专业医学知识）。", "method": "本文提出了AMANDA框架，它是一个免训练的代理框架，通过LLM代理进行医学知识增强。具体而言，内在医学知识增强通过粗到细的问题分解实现全面诊断；外在医学知识增强通过生物医学知识图谱检索来支撑推理过程。", "result": "在八个Med-VQA基准测试中，AMANDA在零样本和少样本Med-VQA设置下均取得了显著改进。", "conclusion": "AMANDA框架通过代理化的医学知识增强，有效解决了Med-MLLMs在低资源环境下因内在和外在推理瓶颈导致的性能限制，显著提升了Med-VQA任务的表现。"}}
{"id": "2510.02528", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02528", "abs": "https://arxiv.org/abs/2510.02528", "authors": ["Shuhao Fu", "Esther Goldberg", "Ying Nian Wu", "Hongjing Lu"], "title": "Multimodal Function Vectors for Spatial Relations", "comment": null, "summary": "Large Multimodal Models (LMMs) demonstrate impressive in-context learning\nabilities from limited multimodal demonstrations, yet the internal mechanisms\nsupporting such task learning remain opaque. Building on prior work of large\nlanguage models, we show that a small subset of attention heads in the\nvision-language model OpenFlamingo-4B is responsible for transmitting\nrepresentations of spatial relations. The activations of these attention heads,\ntermed function vectors, can be extracted and manipulated to alter an LMM's\nperformance on relational tasks. First, using both synthetic and real image\ndatasets, we apply causal mediation analysis to identify attention heads that\nstrongly influence relational predictions, and extract multimodal function\nvectors that improve zero-shot accuracy at inference time. We further\ndemonstrate that these multimodal function vectors can be fine-tuned with a\nmodest amount of training data, while keeping LMM parameters frozen, to\nsignificantly outperform in-context learning baselines. Finally, we show that\nrelation-specific function vectors can be linearly combined to solve analogy\nproblems involving novel and untrained spatial relations, highlighting the\nstrong generalization ability of this approach. Our results show that LMMs\nencode spatial relational knowledge within localized internal structures, which\ncan be systematically extracted and optimized, thereby advancing our\nunderstanding of model modularity and enhancing control over relational\nreasoning in LMMs.", "AI": {"tldr": "本研究发现大型多模态模型（LMMs）中的一小部分注意力头负责空间关系表示的传输。通过提取和操纵这些注意力头的激活（功能向量），可以提高LMMs在关系任务上的性能，并实现对关系推理的有效控制和泛化。", "motivation": "大型多模态模型（LMMs）展现出强大的上下文学习能力，但其内部支持任务学习的机制，特别是空间关系推理，仍不透明。", "method": "本研究利用因果中介分析识别了OpenFlamingo-4B模型中影响关系预测的注意力头。从这些注意力头中提取了多模态功能向量。这些功能向量首先用于提高零样本准确性，然后通过少量数据进行微调（LMMs参数冻结），最后通过线性组合解决涉及新颖空间关系的类比问题。", "result": "研究发现，提取的功能向量可以提高零样本准确性；通过微调功能向量，其性能显著优于上下文学习基线；特定关系的功能向量可以线性组合，以解决涉及新颖和未训练空间关系的类比问题，显示出强大的泛化能力。", "conclusion": "LMMs在局部内部结构中编码空间关系知识。这些知识可以被系统地提取和优化（通过功能向量），从而增进了对模型模块化的理解，并增强了对LMMs中关系推理的控制能力。"}}
{"id": "2510.02570", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02570", "abs": "https://arxiv.org/abs/2510.02570", "authors": ["P. Jonathon Phillips", "Geraldine Jeckeln", "Carina A. Hahn", "Amy N. Yates", "Peter C. Fontana", "Alice J. O'Toole"], "title": "Unlocking the power of partnership: How humans and machines can work together to improve face recognition", "comment": null, "summary": "Human review of consequential decisions by face recognition algorithms\ncreates a \"collaborative\" human-machine system. Individual differences between\npeople and machines, however, affect whether collaboration improves or degrades\naccuracy in any given case. We establish the circumstances under which\ncombining human and machine face identification decisions improves accuracy.\nUsing data from expert and non-expert face identifiers, we examined the\nbenefits of human-human and human-machine collaborations. The benefits of\ncollaboration increased as the difference in baseline accuracy between\ncollaborators decreased-following the Proximal Accuracy Rule (PAR). This rule\npredicted collaborative (fusion) benefit across a wide range of baseline\nabilities, from people with no training to those with extensive training. Using\nthe PAR, we established a critical fusion zone, where humans are less accurate\nthan the machine, but fusing the two improves system accuracy. This zone was\nsurprisingly large. We implemented \"intelligent human-machine fusion\" by\nselecting people with the potential to increase the accuracy of a\nhigh-performing machine. Intelligent fusion was more accurate than the machine\noperating alone and more accurate than combining all human and machine\njudgments. The highest system-wide accuracy achievable with human-only\npartnerships was found by graph theory. This fully human system approximated\nthe average performance achieved by intelligent human-machine collaboration.\nHowever, intelligent human-machine collaboration more effectively minimized the\nimpact of low-performing humans on system-wide accuracy. The results\ndemonstrate a meaningful role for both humans and machines in assuring accurate\nface identification. This study offers an evidence-based road map for the\nintelligent use of AI in face identification.", "AI": {"tldr": "本研究探讨了人脸识别中人机协作的准确性提升机制，提出了“近端准确度规则”（PAR）和“智能人机融合”策略，以在机器性能优异的情况下，通过选择性融合人类判断来最大化系统准确性，并最小化低效人类的影响。", "motivation": "人脸识别算法的决策需要人工审查，形成人机协作系统。然而，人与机器之间的个体差异会影响协作的准确性。因此，本研究旨在确定在何种情况下，结合人机人脸识别决策能够提高准确性。", "method": "研究使用了专家和非专家人脸识别者的数据，考察了人-人及人-机协作的益处。通过“近端准确度规则”（Proximal Accuracy Rule, PAR）来预测协作（融合）效益，并基于此规则建立了“关键融合区”。研究还实施了“智能人机融合”策略，即选择性地将有潜力提升高性能机器准确性的人员纳入协作，并使用图论方法评估了纯人类伙伴关系能达到的最高系统准确性。", "result": "协作的益处随着合作者基线准确度差异的减小而增加，遵循“近端准确度规则”（PAR）。PAR成功预测了不同能力水平下的融合效益，并确定了一个“关键融合区”，在该区域内，即使人类准确度低于机器，融合也能提升系统准确度，且该区域出人意料地大。“智能人机融合”比单独机器操作或简单地融合所有人类和机器判断更准确。纯人类系统的最高准确度与智能人机协作的平均性能相当，但智能人机协作能更有效地最小化低效人类对系统准确性的影响。", "conclusion": "研究结果表明，在确保人脸识别准确性方面，人类和机器都扮演着重要的角色。本研究为在人脸识别中智能地使用人工智能提供了一个基于证据的路线图。"}}
{"id": "2510.02616", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02616", "abs": "https://arxiv.org/abs/2510.02616", "authors": ["Mobin Habibpour", "Alireza Nemati", "Ali Meghdari", "Alireza Taheri", "Shima Nazari"], "title": "RSV-SLAM: Toward Real-Time Semantic Visual SLAM in Indoor Dynamic Environments", "comment": "Proceedings of SAI Intelligent Systems Conference 2023", "summary": "Simultaneous Localization and Mapping (SLAM) plays an important role in many\nrobotics fields, including social robots. Many of the available visual SLAM\nmethods are based on the assumption of a static world and struggle in dynamic\nenvironments. In the current study, we introduce a real-time semantic RGBD SLAM\napproach designed specifically for dynamic environments. Our proposed system\ncan effectively detect moving objects and maintain a static map to ensure\nrobust camera tracking. The key innovation of our approach is the incorporation\nof deep learning-based semantic information into SLAM systems to mitigate the\nimpact of dynamic objects. Additionally, we enhance the semantic segmentation\nprocess by integrating an Extended Kalman filter to identify dynamic objects\nthat may be temporarily idle. We have also implemented a generative network to\nfill in the missing regions of input images belonging to dynamic objects. This\nhighly modular framework has been implemented on the ROS platform and can\nachieve around 22 fps on a GTX1080. Benchmarking the developed pipeline on\ndynamic sequences from the TUM dataset suggests that the proposed approach\ndelivers competitive localization error in comparison with the state-of-the-art\nmethods, all while operating in near real-time. The source code is publicly\navailable.", "AI": {"tldr": "本文提出一种实时语义RGBD SLAM方法，专为动态环境设计，通过深度学习、扩展卡尔曼滤波和生成网络处理移动物体，以确保鲁棒的相机跟踪和静态地图。", "motivation": "现有的视觉SLAM方法大多基于静态世界假设，在动态环境中表现不佳，而动态环境在包括社交机器人在内的许多机器人领域中普遍存在。", "method": "该方法结合了深度学习的语义信息来检测移动物体，并利用扩展卡尔曼滤波增强语义分割，以识别可能暂时静止的动态物体。此外，还采用生成网络来填充输入图像中属于动态物体的缺失区域。整个系统是一个模块化框架，基于ROS平台实现。", "result": "该系统在GTX1080上能达到约22帧/秒的运行速度，接近实时。在TUM数据集的动态序列上进行基准测试表明，其定位误差与现有最先进方法相比具有竞争力。", "conclusion": "所提出的语义RGBD SLAM方法能有效应对动态环境，提供鲁棒的相机跟踪和竞争性的定位精度，并能接近实时运行。"}}
{"id": "2510.02781", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02781", "abs": "https://arxiv.org/abs/2510.02781", "authors": ["Daeyoung Kim"], "title": "GCVAMD: A Modified CausalVAE Model for Causal Age-related Macular Degeneration Risk Factor Detection and Prediction", "comment": null, "summary": "Age Related Macular Degeneration(AMD) has been one of the most leading causes\nof permanent vision impairment in ophthalmology. Though treatments, such as\nanti VEGF drugs or photodynamic therapies, were developed to slow down the\ndegenerative process of AMD, there is still no specific cure to reverse vision\nloss caused by AMD. Thus, for AMD, detecting existence of risk factors of AMD\nor AMD itself within the patient retina in early stages is a crucial task to\nreduce the possibility of vision impairment. Apart from traditional approaches,\ndeep learning based methods, especially attention mechanism based CNNs and\nGradCAM based XAI analysis on OCT scans, exhibited successful performance in\ndistinguishing AMD retina from normal retinas, making it possible to use AI\ndriven models to aid medical diagnosis and analysis by ophthalmologists\nregarding AMD. However, though having significant success, previous works\nmostly focused on prediction performance itself, not pathologies or underlying\ncausal mechanisms of AMD, which can prohibit intervention analysis on specific\nfactors or even lead to less reliable decisions. Thus, this paper introduces a\nnovel causal AMD analysis model: GCVAMD, which incorporates a modified\nCausalVAE approach that can extract latent causal factors from only raw OCT\nimages. By considering causality in AMD detection, GCVAMD enables causal\ninference such as treatment simulation or intervention analysis regarding major\nrisk factors: drusen and neovascularization, while returning informative latent\ncausal features that can enhance downstream tasks. Results show that through\nGCVAMD, drusen status and neovascularization status can be identified with AMD\ncausal mechanisms in GCVAMD latent spaces, which can in turn be used for\nvarious tasks from AMD detection(classification) to intervention analysis.", "AI": {"tldr": "该论文提出GCVAMD模型，通过修改后的CausalVAE从OCT图像中提取潜在因果因素，实现对年龄相关性黄斑变性（AMD）的因果分析，并识别玻璃膜疣和新生血管等风险因素，以支持干预分析。", "motivation": "年龄相关性黄斑变性（AMD）是导致永久性视力障碍的主要原因，早期检测至关重要。现有深度学习方法在AMD检测中表现出色，但多关注预测性能而非病理学或潜在因果机制，这限制了干预分析并可能导致决策可靠性降低。", "method": "本文提出一种新颖的因果AMD分析模型GCVAMD，它整合了修改后的CausalVAE方法，能够仅从原始OCT图像中提取潜在的因果因素。通过考虑AMD检测中的因果关系，GCVAMD可以进行治疗模拟或针对主要风险因素（玻璃膜疣和新生血管）的干预分析。", "result": "结果表明，GCVAMD能够在其潜在空间中识别出与AMD因果机制相关的玻璃膜疣状态和新生血管状态。这些信息丰富的潜在因果特征可用于从AMD检测（分类）到干预分析的各种任务。", "conclusion": "GCVAMD模型为AMD提供了一种因果分析方法，能够从OCT图像中提取潜在因果因素，从而识别关键风险因素并促进因果推断和干预分析，提升了AMD的检测和理解能力。"}}
{"id": "2510.02485", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.02485", "abs": "https://arxiv.org/abs/2510.02485", "authors": ["Wenlong Shi", "Hongyi Li", "Zhaoyu Wang"], "title": "Data-Driven Stochastic Distribution System Hardening Based on Bayesian Online Learning", "comment": null, "summary": "Extreme weather frequently cause widespread outages in distribution systems\n(DSs), demonstrating the importance of hardening strategies for resilience\nenhancement. However, the well-utilization of real-world outage data with\nassociated weather conditions to make informed hardening decisions in DSs is\nstill an open issue. To bridge this research gap, this paper proposes a\ndata-driven stochastic distribution line (DL) hardening strategy. First, a deep\nneural network (DNN) regression model is developed to predict the probabilistic\nevolution of outage scenarios under various hardening decisions. Based on the\nDNN predictions, the problem is formulated as a decision-dependent\ndistributionally robust optimization (DRO) model, accounting for uncertainties\nin outage scenario distributions using a data-driven ambiguity set. To address\ndecision-dependent uncertainty, a Bayesian online learning algorithm is\nproposed. This algorithm decomposes the original problem into inner and outer\nproblems. Then, it iteratively refines hardening decisions by sequentially\nincorporating outage data and dynamically updating decision-specific ambiguity\nsets by using Bayes' theorem and Bayesian Inference. Also, the convergence of\nthe algorithm is proven through dynamic regret analysis. Finally, case studies\nare implemented on a real-world DS in Redfield, Iowa, USA. A dataset spanning\n24 years (2001-2024) is constructed based on the utility outage records. The\nsimulation results validates the effectiveness of the proposed strategy.", "AI": {"tldr": "本文提出了一种数据驱动的随机配电线路（DL）加固策略，结合深度神经网络（DNN）预测和决策依赖的分布鲁棒优化（DRO），并利用贝叶斯在线学习算法来增强配电系统（DS）对极端天气的韧性。", "motivation": "极端天气频繁导致配电系统大范围停电，凸显了加固策略对韧性提升的重要性。然而，如何有效利用包含相关天气条件的真实停电数据来制定明智的配电系统加固决策仍是一个未解决的问题。", "method": "首先，开发了一个深度神经网络（DNN）回归模型来预测不同加固决策下停电场景的概率演变。其次，基于DNN预测，将问题建模为决策依赖的分布鲁棒优化（DRO）模型，通过数据驱动的模糊集考虑停电场景分布的不确定性。为解决决策依赖的不确定性，提出了一种贝叶斯在线学习算法，将原问题分解为内外问题，通过顺序整合停电数据并利用贝叶斯定理和贝叶斯推断动态更新决策特定模糊集来迭代优化加固决策。算法的收敛性通过动态遗憾分析得到证明。", "result": "在美国爱荷华州雷德菲尔德的一个真实配电系统上进行了案例研究，构建了基于公用事业停电记录的24年（2001-2024）数据集。仿真结果验证了所提出策略的有效性。", "conclusion": "所提出的数据驱动的随机配电线路加固策略能够有效利用历史停电数据和天气信息，通过先进的预测和优化方法，显著提升配电系统抵御极端天气的韧性。"}}
{"id": "2510.02329", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02329", "abs": "https://arxiv.org/abs/2510.02329", "authors": ["Kanghoon Yoon", "Minsub Kim", "Sungjae Lee", "Joonhyung Lee", "Sunghyeon Woo", "Yeonjun In", "Se Jung Kwon", "Chanyoung Park", "Dongsoo Lee"], "title": "SelfJudge: Faster Speculative Decoding via Self-Supervised Judge Verification", "comment": null, "summary": "Speculative decoding accelerates LLM inference by verifying candidate tokens\nfrom a draft model against a larger target model. Recent judge decoding boosts\nthis process by relaxing verification criteria by accepting draft tokens that\nmay exhibit minor discrepancies from target model output, but existing methods\nare restricted by their reliance on human annotations or tasks with verifiable\nground truths, limiting generalizability across diverse NLP tasks. We propose\nSelfJudge, which trains judge verifiers via self-supervision of the target\nmodel. Our method measures semantic preservation by assessing whether\ntoken-substituted responses preserve the meaning of original responses,\nenabling automatic verifier training across diverse NLP tasks. Our experiments\nshow SelfJudge achieves superior inference-accuracy trade-offs than judge\ndecoding baselines, offering a broadly applicable solution for faster LLM\ninference.", "AI": {"tldr": "SelfJudge通过目标模型的自监督训练，创建判断验证器，以加速大型语言模型（LLM）的推理，并在无需人工标注的情况下，在各种NLP任务中实现更好的推理-准确性权衡。", "motivation": "现有的判断解码方法（用于加速LLM推理）受限于对人工标注或可验证真实值的依赖，这限制了它们在多样化NLP任务中的普适性。", "method": "本文提出了SelfJudge，它通过目标模型的自监督方式训练判断验证器。该方法通过评估替换词元后的响应是否保留了原始响应的语义，来衡量语义保真度，从而在各种NLP任务中实现自动化的验证器训练。", "result": "实验表明，SelfJudge在推理-准确性权衡方面优于现有的判断解码基线方法。", "conclusion": "SelfJudge提供了一种广泛适用的解决方案，能够实现更快的LLM推理。"}}
{"id": "2510.02557", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02557", "abs": "https://arxiv.org/abs/2510.02557", "authors": ["Charlie Masters", "Advaith Vellanki", "Jiangbo Shangguan", "Bart Kultys", "Jonathan Gilmore", "Alastair Moore", "Stefano V. Albrecht"], "title": "Orchestrating Human-AI Teams: The Manager Agent as a Unifying Research Challenge", "comment": "Accepted as an oral paper for the conference for Distributed\n  Artificial Intelligence (DAI 2025). 8 pages, 2 figures", "summary": "While agentic AI has advanced in automating individual tasks, managing\ncomplex multi-agent workflows remains a challenging problem. This paper\npresents a research vision for autonomous agentic systems that orchestrate\ncollaboration within dynamic human-AI teams. We propose the Autonomous Manager\nAgent as a core challenge: an agent that decomposes complex goals into task\ngraphs, allocates tasks to human and AI workers, monitors progress, adapts to\nchanging conditions, and maintains transparent stakeholder communication. We\nformalize workflow management as a Partially Observable Stochastic Game and\nidentify four foundational challenges: (1) compositional reasoning for\nhierarchical decomposition, (2) multi-objective optimization under shifting\npreferences, (3) coordination and planning in ad hoc teams, and (4) governance\nand compliance by design. To advance this agenda, we release MA-Gym, an\nopen-source simulation and evaluation framework for multi-agent workflow\norchestration. Evaluating GPT-5-based Manager Agents across 20 workflows, we\nfind they struggle to jointly optimize for goal completion, constraint\nadherence, and workflow runtime - underscoring workflow management as a\ndifficult open problem. We conclude with organizational and ethical\nimplications of autonomous management systems.", "AI": {"tldr": "本文提出了一个关于自主管理者代理的研究愿景，旨在协调动态人机团队中的协作。该代理将复杂目标分解、分配任务、监控进度、适应变化并沟通。研究将工作流管理形式化为一个部分可观察随机博弈，并识别了四个基础挑战。通过发布MA-Gym并评估基于GPT-5的代理，发现当前代理在多目标优化方面存在困难，强调工作流管理是一个开放难题。", "motivation": "虽然代理式AI在自动化单个任务方面取得了进展，但管理复杂的多代理工作流（尤其是在动态人机团队中）仍然是一个具有挑战性的问题。", "method": "本文提出“自主管理者代理”作为核心挑战，该代理负责将复杂目标分解为任务图、分配任务给人类和AI工作者、监控进度、适应变化并维护透明沟通。研究将工作流管理形式化为一个部分可观察随机博弈（Partially Observable Stochastic Game），并识别了四个基础挑战：组合推理、多目标优化、临时团队中的协调与规划，以及设计中的治理与合规性。为推进此议程，发布了开源仿真与评估框架MA-Gym，并评估了基于GPT-5的管理者代理在20个工作流中的表现。", "result": "通过评估基于GPT-5的管理者代理，发现它们在同时优化目标完成度、遵守约束和工作流运行时方面表现不佳，这突显了工作流管理是一个困难的开放问题。", "conclusion": "工作流管理是一个困难的开放问题。自主管理系统具有重要的组织和伦理影响。"}}
{"id": "2510.02571", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02571", "abs": "https://arxiv.org/abs/2510.02571", "authors": ["Zhiting Mei", "Ola Shorinwa", "Anirudha Majumdar"], "title": "How Confident are Video Models? Empowering Video Models to Express their Uncertainty", "comment": null, "summary": "Generative video models demonstrate impressive text-to-video capabilities,\nspurring widespread adoption in many real-world applications. However, like\nlarge language models (LLMs), video generation models tend to hallucinate,\nproducing plausible videos even when they are factually wrong. Although\nuncertainty quantification (UQ) of LLMs has been extensively studied in prior\nwork, no UQ method for video models exists, raising critical safety concerns.\nTo our knowledge, this paper represents the first work towards quantifying the\nuncertainty of video models. We present a framework for uncertainty\nquantification of generative video models, consisting of: (i) a metric for\nevaluating the calibration of video models based on robust rank correlation\nestimation with no stringent modeling assumptions; (ii) a black-box UQ method\nfor video models (termed S-QUBED), which leverages latent modeling to\nrigorously decompose predictive uncertainty into its aleatoric and epistemic\ncomponents; and (iii) a UQ dataset to facilitate benchmarking calibration in\nvideo models. By conditioning the generation task in the latent space, we\ndisentangle uncertainty arising due to vague task specifications from that\narising from lack of knowledge. Through extensive experiments on benchmark\nvideo datasets, we demonstrate that S-QUBED computes calibrated total\nuncertainty estimates that are negatively correlated with the task accuracy and\neffectively computes the aleatoric and epistemic constituents.", "AI": {"tldr": "该论文首次提出了一种用于生成式视频模型的不确定性量化（UQ）框架，包括一个校准评估指标、一个名为S-QUBED的黑盒UQ方法（分解不确定性）以及一个UQ数据集，以解决视频模型幻觉问题。", "motivation": "生成式视频模型在文本到视频方面表现出色，但像大型语言模型（LLMs）一样，它们也存在“幻觉”现象，即生成看似合理但事实错误的内容。尽管LLMs的不确定性量化已被广泛研究，但视频模型尚无此类方法，这引发了严重的安全担忧。", "method": "该研究提出了一个视频模型不确定性量化框架，包含：(i) 一个基于鲁棒秩相关估计的视频模型校准评估指标，无需严格建模假设；(ii) 一个名为S-QUBED的黑盒UQ方法，它利用潜在空间建模将预测不确定性严谨地分解为偶然不确定性（aleatoric）和认知不确定性（epistemic）成分；(iii) 一个UQ数据集，用于促进视频模型校准的基准测试。通过在潜在空间中调节生成任务，该方法能区分因模糊任务规范引起的不确定性与因知识不足引起的不确定性。", "result": "通过对基准视频数据集进行大量实验，研究表明S-QUBED计算出的校准总不确定性估计与任务准确性呈负相关，并且能够有效地计算出偶然不确定性和认知不确定性成分。", "conclusion": "该论文成功地提出了首个用于生成式视频模型的不确定性量化框架，提供了一种有效的校准评估方法（S-QUBED）和数据集，为解决视频模型幻觉问题和提高其安全性奠定了基础。"}}
{"id": "2510.02623", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02623", "abs": "https://arxiv.org/abs/2510.02623", "authors": ["Taha Shafa", "Yiming Meng", "Melkior Ornik"], "title": "Reachable Predictive Control: A Novel Control Algorithm for Nonlinear Systems with Unknown Dynamics and its Practical Applications", "comment": null, "summary": "This paper proposes an algorithm capable of driving a system to follow a\npiecewise linear trajectory without prior knowledge of the system dynamics.\nMotivated by a critical failure scenario in which a system can experience an\nabrupt change in its dynamics, we demonstrate that it is possible to follow a\nset of waypoints comprised of states analytically proven to be reachable\ndespite not knowing the system dynamics. The proposed algorithm first applies\nsmall perturbations to locally learn the system dynamics around the current\nstate, then computes the set of states that are provably reachable using the\nlocally learned dynamics and their corresponding maximum growth-rate bounds,\nand finally synthesizes a control action that navigates the system to a\nguaranteed reachable state.", "AI": {"tldr": "本文提出了一种无需先验系统动力学知识，即可使系统遵循分段线性轨迹的算法，通过局部学习和可达性分析实现对未知动力学系统的控制。", "motivation": "研究动机源于系统动力学可能发生突然变化的严重故障场景，目标是即使在未知系统动力学的情况下，也能使系统遵循一系列可达的航点。", "method": "该算法首先通过施加小扰动来局部学习当前状态附近的系统动力学；然后，利用局部学习的动力学及其最大增长率边界，计算出可证明可达的状态集合；最后，综合生成一个控制动作，将系统导航至一个保证可达的状态。", "result": "研究证明，即使在未知系统动力学的情况下，也能使系统遵循由一系列可分析证明可达的状态组成的航点，并能将系统导航至一个有保证的可达状态。", "conclusion": "该算法能够驱动系统遵循分段线性轨迹，即使在系统动力学未知或突然变化的情况下，也能通过局部学习和可达性保证，实现对系统的有效控制和导航。"}}
{"id": "2510.03216", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03216", "abs": "https://arxiv.org/abs/2510.03216", "authors": ["Talha Ahmed", "Nehal Ahmed Shaikh", "Hassan Mohy-ud-Din"], "title": "Wave-GMS: Lightweight Multi-Scale Generative Model for Medical Image Segmentation", "comment": "5 pages, 1 figure, 4 tables; Submitted to IEEE Conference for\n  possible publication", "summary": "For equitable deployment of AI tools in hospitals and healthcare facilities,\nwe need Deep Segmentation Networks that offer high performance and can be\ntrained on cost-effective GPUs with limited memory and large batch sizes. In\nthis work, we propose Wave-GMS, a lightweight and efficient multi-scale\ngenerative model for medical image segmentation. Wave-GMS has a substantially\nsmaller number of trainable parameters, does not require loading\nmemory-intensive pretrained vision foundation models, and supports training\nwith large batch sizes on GPUs with limited memory. We conducted extensive\nexperiments on four publicly available datasets (BUS, BUSI, Kvasir-Instrument,\nand HAM10000), demonstrating that Wave-GMS achieves state-of-the-art\nsegmentation performance with superior cross-domain generalizability, while\nrequiring only ~2.6M trainable parameters. Code is available at\nhttps://github.com/ATPLab-LUMS/Wave-GMS.", "AI": {"tldr": "本文提出了Wave-GMS，一种轻量高效的多尺度生成模型，用于医学图像分割。它参数量小，无需预训练大模型，支持在内存有限的GPU上大批量训练，同时实现了最先进的分割性能和卓越的跨域泛化能力。", "motivation": "为了在医院和医疗机构公平部署AI工具，需要高性能的深度分割网络，这些网络能够在成本效益高、内存有限的GPU上以大批量进行训练。", "method": "本文提出Wave-GMS，一个轻量高效的多尺度生成模型，用于医学图像分割。它具有显著更少的训练参数，不需要加载内存密集型预训练视觉基础模型，并支持在内存有限的GPU上进行大批量训练。", "result": "Wave-GMS在四个公开数据集上进行了广泛实验，结果表明它实现了最先进的分割性能和卓越的跨域泛化能力，同时仅需约2.6M可训练参数。", "conclusion": "Wave-GMS为医学图像分割提供了一个高效且高性能的解决方案，其低资源需求和卓越性能使其成为在医疗保健领域公平部署AI工具的理想选择。"}}
{"id": "2510.02495", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.02495", "abs": "https://arxiv.org/abs/2510.02495", "authors": ["Wenlong Shi", "Hongyi Li", "Cong Bai", "Zhaoyu Wang"], "title": "Power Distribution System Blackstart Restoration Using Renewable Energy", "comment": null, "summary": "Integrating renewable energy sources into the grid not only reduces global\ncarbon emissions, but also facilitates distribution system (DS) blackstart\nrestoration. This process leverages renewable energy, inverters, situational\nawareness and distribution automation to initiate blackstart at the DS level,\nobtaining a fast response and bottom-up restoration. In this Review, we survey\nthe latest technological advances for DS blackstart restoration using renewable\nenergy. We first present mathematical models for distributed energy resources\n(DERs), network topology, and load dynamics. We then discuss how the\nsituational awareness can help improve restoration performance through\nreal-time monitoring and forecasting. Next, the DS blackstart restoration\nproblem, including objectives, constraints, and existing methodologies for\ndecision-making are provided. Lastly, we outline remaining challenges, and\nhighlight the opportunities and future research directions.", "AI": {"tldr": "本文综述了利用可再生能源进行配电系统黑启动恢复的最新技术进展，涵盖数学模型、态势感知、问题制定及未来挑战。", "motivation": "将可再生能源整合到电网中不仅能减少碳排放，还能促进配电系统（DS）的黑启动恢复，实现快速、自下而上的恢复。", "method": "本文首先介绍了分布式能源、网络拓扑和负荷动态的数学模型；接着讨论了态势感知如何通过实时监控和预测提高恢复性能；然后阐述了配电系统黑启动恢复问题，包括目标、约束和现有决策方法；最后，概述了剩余挑战、机遇和未来的研究方向。", "result": "本文通过对现有技术的综述，系统地呈现了利用可再生能源进行配电系统黑启动恢复的最新进展，包括相关数学模型、态势感知的作用、黑启动问题的定义及现有解决策略，并指出了未来的研究方向。", "conclusion": "利用可再生能源进行配电系统黑启动恢复具有巨大潜力，但仍面临挑战。未来的研究应聚焦于解决这些挑战，以充分利用可再生能源实现更高效、可靠的电网恢复。"}}
{"id": "2510.02330", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02330", "abs": "https://arxiv.org/abs/2510.02330", "authors": ["Junlong Jia", "Ziyang Chen", "Xing Wu", "Chaochen Gao", "Zijia Lin", "Debing Zhang", "Songlin Hu", "Binghui Guo"], "title": "EntropyLong: Effective Long-Context Training via Predictive Uncertainty", "comment": "work in progress; Correspondence to: Xing Wu <wuxing@iie.ac.cn>", "summary": "Training long-context language models to capture long-range dependencies\nrequires specialized data construction. Current approaches, such as generic\ntext concatenation or heuristic-based variants, frequently fail to guarantee\ngenuine long-range dependencies. We propose EntropyLong, a novel data\nconstruction method that leverages predictive uncertainty to verify dependency\nquality. Our approach identifies high-entropy positions in documents, retrieves\nsemantically relevant contexts from large corpora, and verifies their utility\nby assessing whether they reduce prediction entropy. This model-in-the-loop\nverification ensures each dependency represents measurable information gain\nrather than spurious correlation. We construct training samples with long-range\ndependencies by combining original documents with these verified contextual\nsupplements. Using FineWebEdu and Cosmopedia, we generate a dataset of\n128K-length sequences with verified dependencies. Models trained on this data\ndemonstrate significant improvements on RULER benchmarks, particularly in tasks\nrequiring distant information. Following instruction fine-tuning, our models\nalso achieve substantial gains on LongBenchv2, demonstrating enhanced\nlong-context understanding. Extensive ablation studies further validate the\nnecessity and effectiveness of entropybased verification for long-context\ntraining.", "AI": {"tldr": "EntropyLong是一种新的数据构建方法，它利用预测不确定性（熵）来验证长距离依赖的质量，从而为长上下文语言模型生成高质量的训练数据，显著提升了模型在长上下文理解任务中的表现。", "motivation": "现有训练长上下文语言模型的方法（如文本拼接或启发式变体）难以保证数据中包含真正的长距离依赖，导致模型在捕获这些依赖方面表现不佳。", "method": "EntropyLong方法识别文档中的高熵位置，从大型语料库中检索语义相关的上下文，并通过评估这些上下文是否能降低预测熵来验证其有效性。这种“模型在环”验证确保了每个依赖都代表可测量的 Tena 信息增益。通过将原始文档与这些经过验证的上下文补充结合，构建具有长距离依赖的训练样本。", "result": "使用FineWebEdu和Cosmopedia构建了一个包含128K长度序列且具有验证依赖关系的数据集。在此数据上训练的模型在RULER基准测试中（特别是需要远距离信息的任务）表现出显著改进。经过指令微调后，模型在LongBenchv2上也获得了显著提升，表明其长上下文理解能力增强。广泛的消融研究进一步证实了基于熵的验证对于长上下文训练的必要性和有效性。", "conclusion": "EntropyLong通过基于熵的验证机制，成功构建了高质量的长上下文训练数据，确保了数据中包含真正的长距离依赖，从而显著提升了语言模型在长上下文理解任务中的性能。"}}
{"id": "2510.02567", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02567", "abs": "https://arxiv.org/abs/2510.02567", "authors": ["Peter Pak", "Achuth Chandrasekhar", "Amir Barati Farimani"], "title": "Agentic Additive Manufacturing Alloy Discovery", "comment": null, "summary": "Agentic systems enable the intelligent use of research tooling, augmenting a\nresearcher's ability to investigate and propose novel solutions to existing\nproblems. Within Additive Manufacturing (AM), alloy discovery remains a complex\nchallenge, often requiring expertise in the various domains of materials\nscience, thermodynamic simulations, and experimental analysis. Large Language\nModel (LLM) enabled agents can facilitate this endeavor by utilizing their\nextensive knowledge base to dispatch tool calls via Model Context Protocol\n(MCP) to perform actions such as Thermo-Calc property diagram calculations and\nlack of fusion process map generation. In addition, the multi-agent system\ndeveloped in this work is able to effectively reason through complex user\nprompts and provide analysis on the printability of proposed alloys. These\nagents can dynamically adjust their task trajectory to the outcomes of tool\ncall results, effectively enabling autonomous decision-making in practical\nenvironments. This work aims to utilize LLM enabled agents to automate and\naccelerate the task of alloy discovery within the field of additive\nmanufacturing and showcase the benefits of adopting this multi-agent system.", "AI": {"tldr": "本文提出并开发了一个基于大型语言模型（LLM）的多智能体系统，旨在自动化并加速增材制造（AM）领域的合金发现过程。", "motivation": "增材制造中的合金发现是一个复杂且需要材料科学、热力学模拟和实验分析等多领域专业知识的挑战。研究人员需要更智能的工具来增强其能力，以调查和提出新的解决方案。", "method": "该研究开发了一个由LLM驱动的多智能体系统，该系统利用其广泛的知识库，通过模型上下文协议（MCP）调用外部工具，执行如Thermo-Calc属性图计算和熔合不足工艺图生成等操作。此外，该系统能够推理复杂的用户提示，分析所提出合金的可打印性，并能根据工具调用结果动态调整任务轨迹，实现自主决策。", "result": "所开发的多智能体系统能够有效地推理复杂的查询，并提供对所提出合金可打印性的分析。它还展示了在实际环境中根据工具调用结果动态调整任务路径的能力，从而实现自主决策。", "conclusion": "LLM驱动的智能体系统能够自动化和加速增材制造领域的合金发现任务，并显著展示了采用这种多智能体系统所带来的益处，增强了研究人员的能力。"}}
{"id": "2510.02599", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02599", "abs": "https://arxiv.org/abs/2510.02599", "authors": ["Hovhannes Margaryan", "Bo Wan", "Tinne Tuytelaars"], "title": "PEO: Training-Free Aesthetic Quality Enhancement in Pre-Trained Text-to-Image Diffusion Models with Prompt Embedding Optimization", "comment": null, "summary": "This paper introduces a novel approach to aesthetic quality improvement in\npre-trained text-to-image diffusion models when given a simple prompt. Our\nmethod, dubbed Prompt Embedding Optimization (PEO), leverages a pre-trained\ntext-to-image diffusion model as a backbone and optimizes the text embedding of\na given simple and uncurated prompt to enhance the visual quality of the\ngenerated image. We achieve this by a tripartite objective function that\nimproves the aesthetic fidelity of the generated image, ensures adherence to\nthe optimized text embedding, and minimal divergence from the initial prompt.\nThe latter is accomplished through a prompt preservation term. Additionally,\nPEO is training-free and backbone-independent. Quantitative and qualitative\nevaluations confirm the effectiveness of the proposed method, exceeding or\nequating the performance of state-of-the-art text-to-image and prompt\nadaptation methods.", "AI": {"tldr": "本文提出了一种名为PEO（Prompt Embedding Optimization）的新方法，通过优化文本嵌入来提高预训练文生图扩散模型在处理简单提示时生成图像的美学质量，该方法无需训练且与骨干模型无关。", "motivation": "现有文生图扩散模型在给定简单、未经精选的提示时，生成的图像美学质量可能不尽如人意，因此需要一种方法来提升其视觉美学。", "method": "PEO方法利用预训练文生图扩散模型作为骨干，通过优化给定简单提示的文本嵌入来增强生成图像的视觉质量。它采用一个三方目标函数，旨在提高生成图像的美学保真度、确保与优化后文本嵌入的一致性，并最小化与初始提示的偏差（通过提示保留项实现）。该方法无需训练，且独立于骨干模型。", "result": "定量和定性评估证实了所提方法的有效性，其性能超越或媲美了最先进的文生图和提示适应方法。", "conclusion": "PEO是一种有效、无需训练且与骨干模型无关的方法，能够显著提升预训练文生图扩散模型在处理简单提示时生成图像的美学质量。"}}
{"id": "2510.02624", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02624", "abs": "https://arxiv.org/abs/2510.02624", "authors": ["Qun Yang", "Soung Chang Liew"], "title": "Multi-robot Rigid Formation Navigation via Synchronous Motion and Discrete-time Communication-Control Optimization", "comment": null, "summary": "Rigid-formation navigation of multiple robots is essential for applications\nsuch as cooperative transportation. This process involves a team of\ncollaborative robots maintaining a predefined geometric configuration, such as\na square, while in motion. For untethered collaborative motion, inter-robot\ncommunication must be conducted through a wireless network. Notably, few\nexisting works offer a comprehensive solution for multi-robot formation\nnavigation executable on microprocessor platforms via wireless networks,\nparticularly for formations that must traverse complex curvilinear paths. To\naddress this gap, we introduce a novel \"hold-and-hit\" communication-control\nframework designed to work seamlessly with the widely-used Robotic Operating\nSystem (ROS) platform. The hold-and-hit framework synchronizes robot movements\nin a manner robust against wireless network delays and packet loss. It operates\nover discrete-time communication-control cycles, making it suitable for\nimplementation on contemporary microprocessors. Complementary to hold-and-hit,\nwe propose an intra-cycle optimization approach that enables rigid formations\nto closely follow desired curvilinear paths, even under the nonholonomic\nmovement constraints inherent to most vehicular robots. The combination of\nhold-and-hit and intra-cycle optimization ensures precise and reliable\nnavigation even in challenging scenarios. Simulations in a virtual environment\ndemonstrate the superiority of our method in maintaining a four-robot square\nformation along an S-shaped path, outperforming two existing approaches.\nFurthermore, real-world experiments validate the effectiveness of our\nframework: the robots maintained an inter-distance error within $\\pm 0.069m$\nand an inter-angular orientation error within $\\pm19.15^{\\circ}$ while\nnavigating along an S-shaped path at a fixed linear velocity of $0.1 m/s$.", "AI": {"tldr": "本文提出了一种名为“hold-and-hit”的通信-控制框架，结合周期内优化，实现了多机器人刚性编队在复杂曲线路径上的精确导航，该方法对无线网络延迟和丢包具有鲁棒性，并已在ROS平台和微处理器上验证。", "motivation": "现有研究缺乏在无线网络环境下，针对微处理器平台，能够处理复杂曲线路径的多机器人刚性编队导航的全面解决方案，尤其是在面对无线网络延迟和丢包时缺乏鲁棒性。", "method": "本文引入了一种新颖的“hold-and-hit”通信-控制框架，该框架与ROS平台无缝集成，通过离散时间通信-控制周期同步机器人运动，并对无线网络延迟和丢包具有鲁棒性。此外，提出了一种周期内优化方法，使刚性编队能够紧密遵循期望的曲线路径，同时处理大多数车辆机器人固有的非完整运动约束。两者结合确保了精确可靠的导航。", "result": "虚拟环境模拟结果表明，该方法在沿S形路径保持四机器人方形编队方面优于两种现有方法。实际实验验证了框架的有效性：机器人在S形路径上以0.1 m/s的固定线速度导航时，保持了±0.069m的机器人间距离误差和±19.15°的机器人间角度方向误差。", "conclusion": "所提出的“hold-and-hit”通信-控制框架与周期内优化相结合，为多机器人刚性编队在复杂曲线路径上的导航提供了一个精确、可靠且对无线网络问题具有鲁棒性的解决方案，适用于当代微处理器平台实现。"}}
{"id": "2510.02502", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.02502", "abs": "https://arxiv.org/abs/2510.02502", "authors": ["Wenlong Shi", "Junyuan Zheng", "Zhaoyu Wang"], "title": "Situationally Aware Rolling Horizon Multi-Tier Load Restoration Considering Behind-The-Meter DER", "comment": null, "summary": "Restoration in power distribution systems (PDSs) is well studied, however,\nmost existing research focuses on network partition and microgrid formation,\nwhere load transfer is limited to adjacent feeders. This focus is not\npractical, as when adjacent feeders lack sufficient capacity, utilities may\nrequest support from more distant feeders in practice. Such a hirarchical\nrestoration is complex, especially when involving changing system conditions\ndue to cold load pickup and delayed reconnection of behind-the-meter DERs. To\nfill this research gap, a situationally aware multi-tier load restoration\nframework is proposed. Specifically, models are proposed to describe the\nmulti-tier load restoration, including the multi-tier load transfer and\nsubstation transformer and feeder protection models. By introducing binary\nactional switching variables and load block transfer variables, the models\neffectively captures the dynamics of switches and multi-tier transfer process.\nTo integrate situational awareness of evolving system conditions, the problem\nis formulated as a mixed-integer linear program (MILP) and then embedded within\na rolling horizon optimization. Particularly, a set of safeguarded constraints\nare developed based on segment-level restoration reward bounds to mitigate the\nmyopia of traditional rolling horizon optimization. The proposed safeguarded\nrolling strategy guarantees that each time step is lower bounded by a\n$(1-\\varepsilon)$-fraction of its optimal restoration potential, thereby\nbalancing short-term switching decisions with long-term restoration goals.\nFinally, cases studies on the modified IEEE 123-node test feeder validate the\nproposed multi-tier restoration framework.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2510.02331", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02331", "abs": "https://arxiv.org/abs/2510.02331", "authors": ["Moonkyung Ryu", "Chih-Wei Hsu", "Yinlam Chow", "Mohammad Ghavamzadeh", "Craig Boutilier"], "title": "Synthetic Dialogue Generation for Interactive Conversational Elicitation & Recommendation (ICER)", "comment": null, "summary": "While language models (LMs) offer great potential for conversational\nrecommender systems (CRSs), the paucity of public CRS data makes fine-tuning\nLMs for CRSs challenging. In response, LMs as user simulators qua data\ngenerators can be used to train LM-based CRSs, but often lack behavioral\nconsistency, generating utterance sequences inconsistent with those of any real\nuser. To address this, we develop a methodology for generating natural\ndialogues that are consistent with a user's underlying state using behavior\nsimulators together with LM-prompting. We illustrate our approach by generating\na large, open-source CRS data set with both preference elicitation and example\ncritiquing. Rater evaluation on some of these dialogues shows them to exhibit\nconsiderable consistency, factuality and naturalness.", "AI": {"tldr": "本文提出了一种结合行为模拟器和语言模型提示的方法，用于生成与用户潜在状态一致的自然对话，以解决对话推荐系统（CRS）数据稀缺和现有语言模型模拟器行为不一致的问题。", "motivation": "语言模型在对话推荐系统（CRS）中潜力巨大，但公开的CRS数据稀缺，使得微调语言模型变得困难。虽然可以将语言模型用作用户模拟器来生成数据，但它们往往缺乏行为一致性，生成的对话序列与真实用户不符。", "method": "开发了一种结合行为模拟器和语言模型（LM）提示的方法，用于生成与用户潜在状态一致的自然对话。该方法用于生成一个包含偏好启发和示例评论的大型开源CRS数据集。", "result": "通过该方法生成了一个大型开源CRS数据集，并对部分对话进行了评估。评估结果显示，这些对话在一致性、事实性和自然性方面表现出显著的水平。", "conclusion": "该研究提出了一种有效的方法，能够生成行为一致、自然且事实准确的对话数据，从而解决了对话推荐系统数据稀缺的挑战，并为训练基于语言模型的CRS提供了高质量的数据支持。"}}
{"id": "2510.02589", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02589", "abs": "https://arxiv.org/abs/2510.02589", "authors": ["Yunqi Huang", "Nishith Chennakeshava", "Alexis Carras", "Vladislav Neverov", "Wei Liu", "Aske Plaat", "Yingjie Fan"], "title": "A Benchmark Study of Deep Reinforcement Learning Algorithms for the Container Stowage Planning Problem", "comment": null, "summary": "Container stowage planning (CSPP) is a critical component of maritime\ntransportation and terminal operations, directly affecting supply chain\nefficiency. Owing to its complexity, CSPP has traditionally relied on human\nexpertise. While reinforcement learning (RL) has recently been applied to CSPP,\nsystematic benchmark comparisons across different algorithms remain limited. To\naddress this gap, we develop a Gym environment that captures the fundamental\nfeatures of CSPP and extend it to include crane scheduling in both multi-agent\nand single-agent formulations. Within this framework, we evaluate five RL\nalgorithms: DQN, QR-DQN, A2C, PPO, and TRPO under multiple scenarios of varying\ncomplexity. The results reveal distinct performance gaps with increasing\ncomplexity, underscoring the importance of algorithm choice and problem\nformulation for CSPP. Overall, this paper benchmarks multiple RL methods for\nCSPP while providing a reusable Gym environment with crane scheduling, thus\noffering a foundation for future research and practical deployment in maritime\nlogistics.", "AI": {"tldr": "本文开发了一个包含起重机调度的Gym环境，用于集装箱配载规划（CSPP），并系统性地比较了五种强化学习算法（DQN, QR-DQN, A2C, PPO, TRPO）在不同复杂场景下的性能。", "motivation": "集装箱配载规划（CSPP）对海运和码头运营至关重要，但由于其复杂性，传统上依赖人工经验。尽管强化学习（RL）已被应用于CSPP，但不同算法之间的系统性基准比较仍然有限。", "method": "开发了一个捕获CSPP基本特征的Gym环境，并将其扩展以包含多智能体和单智能体形式的起重机调度。在此框架下，评估了DQN、QR-DQN、A2C、PPO和TRPO五种强化学习算法在不同复杂程度场景下的表现。", "result": "结果显示，随着问题复杂性的增加，不同算法之间存在明显的性能差距，强调了算法选择和问题表述对CSPP的重要性。", "conclusion": "本文为CSPP基准测试了多种强化学习方法，并提供了一个可重用的、包含起重机调度的Gym环境，为未来海运物流领域的研究和实际部署奠定了基础。"}}
{"id": "2510.02601", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02601", "abs": "https://arxiv.org/abs/2510.02601", "authors": ["Patrick Rim", "Kun He", "Kevin Harris", "Braden Copple", "Shangchen Han", "Sizhe An", "Ivan Shugurov", "Tomas Hodan", "He Wen", "Xu Xie"], "title": "Ego-Exo 3D Hand Tracking in the Wild with a Mobile Multi-Camera Rig", "comment": null, "summary": "Accurate 3D tracking of hands and their interactions with the world in\nunconstrained settings remains a significant challenge for egocentric computer\nvision. With few exceptions, existing datasets are predominantly captured in\ncontrolled lab setups, limiting environmental diversity and model\ngeneralization. To address this, we introduce a novel marker-less multi-camera\nsystem designed to capture precise 3D hands and objects, which allows for\nnearly unconstrained mobility in genuinely in-the-wild conditions. We combine a\nlightweight, back-mounted capture rig with eight exocentric cameras, and a\nuser-worn Meta Quest 3 headset, which contributes two egocentric views. We\ndesign an ego-exo tracking pipeline to generate accurate 3D hand pose ground\ntruth from this system, and rigorously evaluate its quality. By collecting an\nannotated dataset featuring synchronized multi-view images and precise 3D hand\nposes, we demonstrate the capability of our approach to significantly reduce\nthe trade-off between environmental realism and 3D annotation accuracy.", "AI": {"tldr": "本文介绍了一种新型无标记多摄像头系统和ego-exo追踪流程，用于在真实“野外”环境中精确捕捉3D手部姿态和交互，旨在解决现有数据集环境多样性不足的问题。", "motivation": "在不受限环境下，准确进行手部及其与世界交互的3D追踪对于第一人称计算机视觉仍是巨大挑战。现有数据集大多在受控实验室环境中采集，限制了环境多样性和模型泛化能力。", "method": "研究人员设计了一个无标记多摄像头系统，结合了轻量级背负式捕捉设备（包含八个外视摄像头）和一个用户佩戴的Meta Quest 3头显（提供两个第一人称视角）。他们还开发了一个ego-exo追踪流程，以从该系统生成准确的3D手部姿态真值，并严格评估了其质量。", "result": "通过收集一个包含同步多视角图像和精确3D手部姿态的标注数据集，研究人员证明了他们的方法能够显著减少环境真实性与3D标注准确性之间的权衡。", "conclusion": "该方法成功地在环境真实性和3D标注准确性之间取得了更好的平衡，为在真实“野外”条件下进行手部追踪提供了高质量的数据集和解决方案。"}}
{"id": "2510.02627", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02627", "abs": "https://arxiv.org/abs/2510.02627", "authors": ["Ruining Yang", "Yi Xu", "Yixiao Chen", "Yun Fu", "Lili Su"], "title": "A Trajectory Generator for High-Density Traffic and Diverse Agent-Interaction Scenarios", "comment": null, "summary": "Accurate trajectory prediction is fundamental to autonomous driving, as it\nunderpins safe motion planning and collision avoidance in complex environments.\nHowever, existing benchmark datasets suffer from a pronounced long-tail\ndistribution problem, with most samples drawn from low-density scenarios and\nsimple straight-driving behaviors. This underrepresentation of high-density\nscenarios and safety critical maneuvers such as lane changes, overtaking and\nturning is an obstacle to model generalization and leads to overly optimistic\nevaluations. To address these challenges, we propose a novel trajectory\ngeneration framework that simultaneously enhances scenarios density and\nenriches behavioral diversity. Specifically, our approach converts continuous\nroad environments into a structured grid representation that supports\nfine-grained path planning, explicit conflict detection, and multi-agent\ncoordination. Built upon this representation, we introduce behavior-aware\ngeneration mechanisms that combine rule-based decision triggers with\nFrenet-based trajectory smoothing and dynamic feasibility constraints. This\ndesign allows us to synthesize realistic high-density scenarios and rare\nbehaviors with complex interactions that are often missing in real data.\nExtensive experiments on the large-scale Argoverse 1 and Argoverse 2 datasets\ndemonstrate that our method significantly improves both agent density and\nbehavior diversity, while preserving motion realism and scenario-level safety.\nOur synthetic data also benefits downstream trajectory prediction models and\nenhances performance in challenging high-density scenarios.", "AI": {"tldr": "该研究提出了一种新的轨迹生成框架，通过将连续道路环境转换为结构化网格并结合行为感知生成机制，以解决自动驾驶轨迹预测数据集中高密度和关键行为场景稀缺的问题，从而提高数据集多样性和下游模型的性能。", "motivation": "现有自动驾驶轨迹预测基准数据集存在长尾分布问题，高密度场景和车道变换、超车、转弯等安全关键行为被严重低估，导致模型泛化能力差和评估结果过于乐观。", "method": "提出了一种轨迹生成框架，将连续道路环境转换为结构化网格表示，支持精细路径规划、冲突检测和多智能体协调。在此基础上，引入了行为感知生成机制，结合基于规则的决策触发器、Frenet基轨迹平滑和动态可行性约束，以合成高密度场景和复杂的罕见行为。", "result": "在Argoverse 1和Argoverse 2数据集上的实验表明，该方法显著提高了智能体密度和行为多样性，同时保持了运动真实性和场景级安全性。合成数据还提升了下游轨迹预测模型的性能，特别是在具有挑战性的高密度场景中。", "conclusion": "该轨迹生成框架有效解决了自动驾驶轨迹预测数据集中关键场景和行为的稀缺问题，通过生成逼真的高密度和多样化数据，显著改善了数据集质量，并提升了轨迹预测模型的性能和泛化能力。"}}
{"id": "2510.02503", "categories": ["eess.SY", "cs.CR", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.02503", "abs": "https://arxiv.org/abs/2510.02503", "authors": ["Tejaswini Sanjay Katale", "Lu Gao", "Yunpeng Zhang", "Alaa Senouci"], "title": "A Bilevel Optimization Framework for Adversarial Control of Gas Pipeline Operations", "comment": null, "summary": "Cyberattacks on pipeline operational technology systems pose growing risks to\nenergy infrastructure. This study develops a physics-informed simulation and\noptimization framework for analyzing cyber-physical threats in petroleum\npipeline networks. The model integrates networked hydraulic dynamics,\nSCADA-based state estimation, model predictive control (MPC), and a bi-level\nformulation for stealthy false-data injection (FDI) attacks. Pipeline flow and\npressure dynamics are modeled on a directed graph using nodal pressure\nevolution and edge-based Weymouth-type relations, including control-aware\nequipment such as valves and compressors. An extended Kalman filter estimates\nthe full network state from partial SCADA telemetry. The controller computes\npressure-safe control inputs via MPC under actuator constraints and forecasted\ndemands. Adversarial manipulation is formalized as a bi-level optimization\nproblem where an attacker perturbs sensor data to degrade throughput while\nremaining undetected by bad-data detectors. This attack-control interaction is\nsolved via Karush-Kuhn-Tucker (KKT) reformulation, which results in a tractable\nmixed-integer quadratic program. Test gas pipeline case studies demonstrate the\ncovert reduction of service delivery under attack. Results show that\nundetectable attacks can cause sustained throughput loss with minimal\ninstantaneous deviation. This reveals the need for integrated detection and\ncontrol strategies in cyber-physical infrastructure.", "AI": {"tldr": "本研究开发了一个物理信息模拟和优化框架，用于分析石油管道网络中的网络物理威胁，特别是隐蔽的虚假数据注入（FDI）攻击，并展示了这些攻击如何在不被发现的情况下降低管道吞吐量。", "motivation": "管道运营技术系统面临的网络攻击对能源基础设施构成日益增长的风险。", "method": "该框架集成了网络水力学动态模型（基于节点压力演化和Weymouth型关系）、SCADA状态估计（通过扩展卡尔曼滤波器）、模型预测控制（MPC）以及用于隐蔽虚假数据注入（FDI）攻击的双层优化公式。攻击-控制交互通过KKT（Karush-Kuhn-Tucker）重构，转化为可处理的混合整数二次规划问题。", "result": "天然气管道案例研究表明，在攻击下服务交付会隐蔽地减少。结果显示，无法检测到的攻击可以导致持续的吞吐量损失，而瞬时偏差极小。", "conclusion": "这揭示了在网络物理基础设施中集成检测和控制策略的必要性。"}}
{"id": "2510.02332", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02332", "abs": "https://arxiv.org/abs/2510.02332", "authors": ["Yapei Feng", "Feng Jiang", "Shanhao Wu", "Hua Zhong"], "title": "A High-Capacity and Secure Disambiguation Algorithm for Neural Linguistic Steganography", "comment": "13 pages,7 figures", "summary": "Neural linguistic steganography aims to embed information\n  into natural text while preserving statistical undetectability. A fundamental\nchallenge in this ffeld stems from tokenization ambiguity in modern tokenizers,\nwhich can lead to catastrophic decoding failures. The recent method, SyncPool,\naddresses this ambiguity\n  by employing a coarse-grained synchronization mechanism over groups of\nambiguous candidates. However, SyncPool sacriffces embedding capacity, as it\nutilizes the entire Shannon entropy of an ambiguous group solely for\nsynchronization rather than for payload embedding. We propose a method named\nlook-ahead Sync, which overcomes the capacity limitation of SyncPool while\nretaining its provable security guarantees. Our approach performs minimal\nsynchronized sampling only on truly indistinguishable token sequences, while\nstrategically preserving all other discernible paths to maximize embedding\ncapacity. We provide theoretical proofs for the security of our method and\nanalyze the gap between its achievable embedding capacity and the theoretical\nupper bound. Experiments on English (using Llama 3) and Chinese (using Qwen\n2.5) benchmarks show that our method consistently approaches the theoretical\ncapacity upper bound and signiffcantly outperforms SyncPool. The improvement in\nembedding rate exceeds 160% in English and 25% in Chinese, particularly in\nsettings with larger candidate pools. This work represents a signiffcant step\ntoward practical high-capacity provably secure linguistic steganography.", "AI": {"tldr": "本文提出了一种名为“look-ahead Sync”的新方法，用于神经语言隐写术，旨在解决分词歧义导致的解码失败问题，并克服现有方法SyncPool在嵌入容量上的限制。该方法在保持可证明安全性的同时，显著提高了信息嵌入容量，并接近理论上限。", "motivation": "神经语言隐写术中，现代分词器导致的分词歧义是根本性挑战，可能引发灾难性解码失败。现有方法SyncPool通过粗粒度同步解决此问题，但以牺牲嵌入容量为代价，因为它将整个模糊组的香农熵用于同步而非有效载荷嵌入。", "method": "本文提出“look-ahead Sync”方法，通过仅对真正无法区分的token序列执行最小同步采样，同时策略性地保留所有其他可区分路径，以最大化嵌入容量。该方法保留了SyncPool的可证明安全保证，并提供了理论安全证明。", "result": "实验结果表明，该方法在英语（使用Llama 3）和中文（使用Qwen 2.5）基准测试中，始终接近理论容量上限，并显著优于SyncPool。在较大候选池设置下，英语的嵌入率提高了160%以上，中文提高了25%。", "conclusion": "“look-ahead Sync”方法代表了实用、高容量、可证明安全的语言隐写术方面的重要进展，有效解决了容量限制并保持了安全性。"}}
{"id": "2510.02592", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02592", "abs": "https://arxiv.org/abs/2510.02592", "authors": ["Jean Douglas Carvalho", "Hugo Kenji", "Ahmad Mohammad Saber", "Glaucia Melo", "Max Mauro Dias Santos", "Deepa Kundur"], "title": "Multimodal Large Language Model Framework for Safe and Interpretable Grid-Integrated EVs", "comment": "This paper has been presented at the 2025 IEEE PES Conference on\n  Innovative Smart Grid Technologies (ISGT 2025)", "summary": "The integration of electric vehicles (EVs) into smart grids presents unique\nopportunities to enhance both transportation systems and energy networks.\nHowever, ensuring safe and interpretable interactions between drivers,\nvehicles, and the surrounding environment remains a critical challenge. This\npaper presents a multi-modal large language model (LLM)-based framework to\nprocess multimodal sensor data - such as object detection, semantic\nsegmentation, and vehicular telemetry - and generate natural-language alerts\nfor drivers. The framework is validated using real-world data collected from\ninstrumented vehicles driving on urban roads, ensuring its applicability to\nreal-world scenarios. By combining visual perception (YOLOv8), geocoded\npositioning, and CAN bus telemetry, the framework bridges raw sensor data and\ndriver comprehension, enabling safer and more informed decision-making in urban\ndriving scenarios. Case studies using real data demonstrate the framework's\neffectiveness in generating context-aware alerts for critical situations, such\nas proximity to pedestrians, cyclists, and other vehicles. This paper\nhighlights the potential of LLMs as assistive tools in e-mobility, benefiting\nboth transportation systems and electric networks by enabling scalable fleet\ncoordination, EV load forecasting, and traffic-aware energy planning.\n  Index Terms - Electric vehicles, visual perception, large language models,\nYOLOv8, semantic segmentation, CAN bus, prompt engineering, smart grid.", "AI": {"tldr": "本文提出一个基于多模态大语言模型（LLM）的框架，用于处理电动汽车（EV）的多模态传感器数据，并为驾驶员生成自然语言警报，以提高城市驾驶的安全性。", "motivation": "在智能电网中整合电动汽车带来了机遇，但确保驾驶员、车辆和环境之间安全且可解释的交互仍然是一个关键挑战。", "method": "该研究采用了一个多模态大语言模型（LLM）框架，处理包括物体检测、语义分割和车辆遥测在内的多模态传感器数据（如YOLOv8视觉感知、地理编码定位和CAN总线遥测），并生成自然语言警报。该框架使用真实世界的城市道路数据进行了验证。", "result": "该框架能够有效地为驾驶员生成上下文感知的警报，例如针对靠近行人、骑行者和其他车辆等关键情况。通过真实数据案例研究，证明了其在连接原始传感器数据和驾驶员理解方面的有效性。", "conclusion": "研究强调了LLM作为电动出行辅助工具的潜力，通过实现可扩展的车队协调、电动汽车负荷预测和交通感知能源规划，有益于交通系统和电网。"}}
{"id": "2510.02617", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02617", "abs": "https://arxiv.org/abs/2510.02617", "authors": ["Beijia Lu", "Ziyi Chen", "Jing Xiao", "Jun-Yan Zhu"], "title": "Input-Aware Sparse Attention for Real-Time Co-Speech Video Generation", "comment": "Project Page: https://beijia11.github.io/IASA", "summary": "Diffusion models can synthesize realistic co-speech video from audio for\nvarious applications, such as video creation and virtual agents. However,\nexisting diffusion-based methods are slow due to numerous denoising steps and\ncostly attention mechanisms, preventing real-time deployment. In this work, we\ndistill a many-step diffusion video model into a few-step student model.\nUnfortunately, directly applying recent diffusion distillation methods degrades\nvideo quality and falls short of real-time performance. To address these\nissues, our new video distillation method leverages input human pose\nconditioning for both attention and loss functions. We first propose using\naccurate correspondence between input human pose keypoints to guide attention\nto relevant regions, such as the speaker's face, hands, and upper body. This\ninput-aware sparse attention reduces redundant computations and strengthens\ntemporal correspondences of body parts, improving inference efficiency and\nmotion coherence. To further enhance visual quality, we introduce an\ninput-aware distillation loss that improves lip synchronization and hand motion\nrealism. By integrating our input-aware sparse attention and distillation loss,\nour method achieves real-time performance with improved visual quality compared\nto recent audio-driven and input-driven methods. We also conduct extensive\nexperiments showing the effectiveness of our algorithmic design choices.", "AI": {"tldr": "本文提出一种新的视频扩散模型蒸馏方法，利用人体姿态条件引导稀疏注意力机制和蒸馏损失函数，将多步扩散模型加速为几步学生模型，实现了实时共语视频生成，并提升了视觉质量。", "motivation": "现有的基于扩散模型的共语视频生成方法由于去噪步骤多和注意力机制成本高昂而速度慢，无法实现实时部署。", "method": "将多步扩散视频模型蒸馏成一个少步学生模型。引入了一种新的视频蒸馏方法，利用输入的人体姿态作为条件来指导注意力机制和损失函数。具体包括：1) 提出输入感知稀疏注意力，利用人体姿态关键点（如面部、手部和上半身）的准确对应关系来引导注意力，减少冗余计算并增强身体部位的时间对应性。2) 引入输入感知蒸馏损失，以改善唇部同步和手部动作的真实感。", "result": "通过整合输入感知稀疏注意力和蒸馏损失，该方法实现了实时性能，并与最近的音频驱动和输入驱动方法相比，视觉质量有所提高（尤其在唇部同步和手部动作真实感方面）。广泛的实验也证明了算法设计选择的有效性。", "conclusion": "所提出的输入感知稀疏注意力和蒸馏损失能够有效蒸馏共语视频扩散模型，实现实时生成并提升视觉质量，解决了现有方法的效率和质量问题。"}}
{"id": "2510.02716", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02716", "abs": "https://arxiv.org/abs/2510.02716", "authors": ["Junlin Zeng", "Xin Zhang", "Xiang Zhao", "Yan Pan"], "title": "A $1000\\times$ Faster LLM-enhanced Algorithm For Path Planning in Large-scale Grid Maps", "comment": null, "summary": "Path planning in grid maps, arising from various applications, has garnered\nsignificant attention. Existing methods, such as A*, Dijkstra, and their\nvariants, work well for small-scale maps but fail to address large-scale ones\ndue to high search time and memory consumption. Recently, Large Language Models\n(LLMs) have shown remarkable performance in path planning but still suffer from\nspatial illusion and poor planning performance. Among all the works, LLM-A*\n\\cite{meng2024llm} leverages LLM to generate a series of waypoints and then\nuses A* to plan the paths between the neighboring waypoints. In this way, the\ncomplete path is constructed. However, LLM-A* still suffers from high\ncomputational time for large-scale maps. To fill this gap, we conducted a deep\ninvestigation into LLM-A* and found its bottleneck, resulting in limited\nperformance. Accordingly, we design an innovative LLM-enhanced algorithm, abbr.\nas iLLM-A*. iLLM-A* includes 3 carefully designed mechanisms, including the\noptimization of A*, an incremental learning method for LLM to generate\nhigh-quality waypoints, and the selection of the appropriate waypoints for A*\nfor path planning. Finally, a comprehensive evaluation on various grid maps\nshows that, compared with LLM-A*, iLLM-A* \\textbf{1) achieves more than\n$1000\\times$ speedup on average, and up to $2349.5\\times$ speedup in the\nextreme case, 2) saves up to $58.6\\%$ of the memory cost, 3) achieves both\nobviously shorter path length and lower path length standard deviation.}", "AI": {"tldr": "本文提出了一种名为iLLM-A*的创新算法，通过优化LLM-A*的瓶颈，显著提高了在大规模网格地图路径规划中的速度、内存效率和路径质量。", "motivation": "现有的A*、Dijkstra及其变体在小规模地图上表现良好，但在大规模地图上因搜索时间和内存消耗过高而失效。大语言模型（LLMs）在路径规划中展现潜力，但仍存在空间错觉和规划性能不佳的问题。LLM-A*虽然结合了LLM和A*，但其在大规模地图上仍面临计算时间过长的问题，本文旨在解决这一瓶颈。", "method": "通过深入研究LLM-A*并找出其性能瓶颈，本文设计了iLLM-A*算法。该算法包含三个关键机制：1) A*算法的优化，2) 用于LLM生成高质量路标点的增量学习方法，以及3) 为A*路径规划选择合适路标点的方法。", "result": "与LLM-A*相比，iLLM-A*在各种网格地图上的综合评估显示：1) 平均速度提升超过1000倍，极端情况下最高达到2349.5倍；2) 节省高达58.6%的内存成本；3) 实现明显更短的路径长度和更低路径长度标准差。", "conclusion": "iLLM-A*算法通过优化LLM-A*的瓶颈，在大规模网格地图路径规划中实现了显著的性能提升，包括大幅度的速度提升、内存节省以及更高质量的路径生成。"}}
{"id": "2510.02636", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.02636", "abs": "https://arxiv.org/abs/2510.02636", "authors": ["Víctor Costa da Silva Campos", "Mariella Maia Quadros", "Luciano Frezzato", "Leonardo Mozelli", "Anh-Tu Nguyen"], "title": "Guaranteed Time Control using Linear Matrix Inequalities", "comment": "Preprint - Initial submission submitted to Automatica", "summary": "This paper presents a synthesis approach aiming to guarantee a minimum\nupper-bound for the time taken to reach a target set of non-zero measure that\nencompasses the origin, while taking into account uncertainties and input and\nstate constraints. This approach is based on a harmonic transformation of the\nLyapunov function and a novel piecewise quadratic representation of this\ntransformed Lyapunov function over a simplicial partition of the state space.\nThe problem is solved in a policy iteration fashion, whereas the evaluation and\nimprovement steps are formulated as linear matrix inequalities employing the\nstructural relaxation approach. Though initially formulated for uncertain\npolytopic systems, extensions to piecewise and nonlinear systems are discussed.\nThree examples illustrate the effectiveness of the proposed approach in\ndifferent scenarios.", "AI": {"tldr": "本文提出了一种综合方法，旨在不确定性和输入/状态约束下，保证系统在最短时间内到达包含原点的非零测度目标集，通过Lyapunov函数的谐波变换、分段二次表示和策略迭代实现。", "motivation": "研究动机是在存在不确定性和约束的系统下，如何合成一种控制策略，以保证在最短的时间上界内到达一个目标集。", "method": "该方法基于Lyapunov函数的谐波变换，并提出了一种在状态空间单纯形划分上的分段二次表示。问题通过策略迭代方式解决，其中评估和改进步骤被表述为线性矩阵不等式（LMI），并采用了结构松弛方法。最初针对不确定多胞体系统，也讨论了其在分段和非线性系统上的扩展。", "result": "通过三个示例说明了所提出方法在不同场景下的有效性。", "conclusion": "该研究提出了一种有效的方法，能够为具有不确定性和约束的系统提供到达目标集的最短时间上界保证，并具有扩展到更复杂系统的潜力。"}}
{"id": "2510.02333", "categories": ["cs.CL", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.02333", "abs": "https://arxiv.org/abs/2510.02333", "authors": ["Chiara Pugliese", "Francesco Lettich", "Guido Rocchietti", "Chiara Renso", "Fabio Pinelli"], "title": "Human Mobility Datasets Enriched With Contextual and Social Dimensions", "comment": "5 pages, 3 figures, 1 table", "summary": "In this resource paper, we present two publicly available datasets of\nsemantically enriched human trajectories, together with the pipeline to build\nthem. The trajectories are publicly available GPS traces retrieved from\nOpenStreetMap. Each dataset includes contextual layers such as stops, moves,\npoints of interest (POIs), inferred transportation modes, and weather data. A\nnovel semantic feature is the inclusion of synthetic, realistic social media\nposts generated by Large Language Models (LLMs), enabling multimodal and\nsemantic mobility analysis. The datasets are available in both tabular and\nResource Description Framework (RDF) formats, supporting semantic reasoning and\nFAIR data practices. They cover two structurally distinct, large cities: Paris\nand New York. Our open source reproducible pipeline allows for dataset\ncustomization, while the datasets support research tasks such as behavior\nmodeling, mobility prediction, knowledge graph construction, and LLM-based\napplications. To our knowledge, our resource is the first to combine real-world\nmovement, structured semantic enrichment, LLM-generated text, and semantic web\ncompatibility in a reusable framework.", "AI": {"tldr": "本文介绍了两个公开可用的语义丰富人类轨迹数据集及其构建流程。这些数据集包含GPS轨迹、上下文信息（如停靠点、移动、POI、交通模式、天气）以及LLM生成的社交媒体帖子，支持多模态和语义移动性分析，并兼容语义网。", "motivation": "研究动机是提供结合了真实世界移动数据、结构化语义丰富、LLM生成文本和语义网兼容性的公开数据集，以促进行为建模、移动预测、知识图谱构建和基于LLM的应用。", "method": "方法包括：1) 从OpenStreetMap获取GPS轨迹；2) 添加上下文层，如停靠点、移动、POI、推断的交通模式和天气数据；3) 引入LLM生成的合成、真实的社交媒体帖子作为新的语义特征；4) 数据集以表格和资源描述框架（RDF）格式提供；5) 涵盖巴黎和纽约两大城市；6) 提供开源可复现的构建流程。", "result": "结果是构建并发布了两个针对巴黎和纽约的语义丰富人类轨迹数据集，它们包含多层上下文信息和LLM生成的社交媒体帖子。这些数据集以表格和RDF格式提供，并附带一个开源可复现的构建流程。据作者所知，这是首个将真实世界移动、结构化语义丰富、LLM生成文本和语义网兼容性结合在一个可复用框架中的资源。", "conclusion": "结论是这些数据集及其管道为研究人员提供了宝贵的资源，支持行为建模、移动预测、知识图谱构建和基于LLM的应用等多种研究任务。其可复用和可定制的特性，以及对语义推理和FAIR数据实践的支持，使其成为移动性分析领域的重要贡献。"}}
{"id": "2510.02608", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02608", "abs": "https://arxiv.org/abs/2510.02608", "authors": ["Chen Henry Wu", "Neil Kale", "Aditi Raghunathan"], "title": "Mitigating Modal Imbalance in Multimodal Reasoning", "comment": "10 pages, 10 figures, CoLM 2025", "summary": "Foundation models (FMs) deployed in real-world tasks such as computer-use\nagents must integrate diverse modalities. How good are FMs at performing joint\nreasoning, simultaneously reasoning over multiple modalities, especially when\nthe modalities interact and relate to each other to form cross-modal context?\nTo better understand this problem, we study FMs on cross-modal conflicts:\nscenarios where conflicting evidence is presented across modalities. This\nallows us to examine whether FMs prioritize one modality over another or reason\njointly to reconcile the conflict. Our experiments reveal that FMs can\nrecognize conflicts in unimodal contexts, composed of a single modality, 90% of\nthe time, but the ratio falls as low as 3% when evidence is split across\nmodalities -- similar observations hold in cross-lingual contexts, composed of\nmultiple languages. We trace this failure to cross-modal attention imbalance,\nshowing that FMs exhibit extreme asymmetry in attention scores,\ndisproportionately prioritizing certain modalities. We show that cross-modal\nattention imbalance does not go away by simply scaling up multimodal or\nmultilingual datasets blindly, since they lack training examples that\nexplicitly require cross-modal reasoning. We demonstrate that even a simple and\nscalable method of explicitly combining multiple modalities within each\ntraining instance significantly reduces attention imbalance. Reduced attention\nimbalance directly translates to improved downstream performance on several\nvision-language benchmarks. Our findings underscore the importance of\nsystematically addressing cross-modal contexts to build reliable foundation\nmodels.", "AI": {"tldr": "研究发现基础模型在跨模态冲突场景下进行联合推理的能力极差（成功率低至3%），原因在于跨模态注意力不平衡，即模型过度偏向某些模态。通过在训练实例中明确结合多模态数据，可以显著减少注意力不平衡并提升下游任务性能。", "motivation": "基础模型在实际应用中（如计算机代理）需整合多种模态。研究旨在理解基础模型在多模态相互作用形成跨模态上下文时，进行联合推理（同时对多种模态进行推理）的能力如何，尤其是在模态间存在冲突证据的场景下。", "method": "研究通过“跨模态冲突”场景（即不同模态呈现冲突证据）来评估基础模型。通过分析模型的注意力分数，追踪其失败原因。并测试了一种简单的、可扩展的训练方法：在每个训练实例中明确结合多种模态，以减少注意力不平衡。", "result": "基础模型在单模态冲突识别上表现良好（90%成功率），但在跨模态冲突下成功率骤降至3%（跨语言上下文也有类似观察）。失败原因归结为跨模态注意力不平衡，模型对特定模态表现出极度不对称的注意力偏好。盲目扩大多模态或多语言数据集无法解决此问题，因为它们缺乏明确要求跨模态推理的训练示例。研究表明，即使是简单的、在每个训练实例中明确结合多模态的方法，也能显著减少注意力不平衡，并直接提升了多个视觉-语言基准测试的下游性能。", "conclusion": "研究强调了系统性地处理跨模态上下文对于构建可靠的基础模型的重要性，因为这能有效解决注意力不平衡问题，从而提升模型的联合推理能力和整体性能。"}}
{"id": "2510.02631", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02631", "abs": "https://arxiv.org/abs/2510.02631", "authors": ["Victor Enescu", "Hichem Sahbi"], "title": "Deep Generative Continual Learning using Functional LoRA: FunLoRA", "comment": null, "summary": "Continual adaptation of deep generative models holds tremendous potential and\ncritical importance, given their rapid and expanding usage in text and vision\nbased applications. Incremental training, however, remains highly challenging\ndue to catastrophic forgetting phenomenon, which makes it difficult for neural\nnetworks to effectively incorporate new knowledge. A common strategy consists\nin retraining the generative model on its own synthetic data in order to\nmitigate forgetting. Yet, such an approach faces two major limitations: (i) the\ncontinually increasing training time eventually becomes intractable, and (ii)\nreliance on synthetic data inevitably leads to long-term performance\ndegradation, since synthetic samples lack the richness of real training data.\nIn this paper, we attenuate these issues by designing a novel and more\nexpressive conditioning mechanism for generative models based on low rank\nadaptation (LoRA), that exclusively employs rank 1 matrices, whose\nreparametrized matrix rank is functionally increased using carefully selected\nfunctions -- and dubbed functional LoRA: FunLoRA. Using this dynamic\nconditioning, the generative model is guaranteed to avoid catastrophic\nforgetting and needs only to be trained on data from the current task.\nExtensive experiments using flow-matching based models trained from scratch,\nshowcase that our proposed parameter-efficient fine-tuning (PEFT) method\nsurpasses prior state-of-the-art results based on diffusion models, reaching\nhigher classification accuracy scores, while only requiring a fraction of the\nmemory cost and sampling time.", "AI": {"tldr": "本文提出FunLoRA，一种基于低秩适应（LoRA）的新型条件机制，通过功能性增加秩为1的矩阵的秩，解决了深度生成模型持续适应中的灾难性遗忘和合成数据再训练的局限性，实现了更高的性能和效率。", "motivation": "深度生成模型在文本和视觉应用中广泛使用，但其持续适应面临巨大挑战：增量训练中的灾难性遗忘，以及依赖自身合成数据进行再训练时训练时间不断增加和性能下降（因合成数据缺乏真实数据的丰富性）。", "method": "本文设计了一种名为“功能性LoRA”（FunLoRA）的新型、更具表达力的生成模型条件机制。它专门使用秩为1的矩阵，并通过精心选择的函数功能性地增加其重参数化矩阵的秩。这种动态条件机制确保生成模型避免灾难性遗忘，并且只需在当前任务数据上进行训练。", "result": "使用从头开始训练的流匹配模型进行的广泛实验表明，所提出的参数高效微调（PEFT）方法超越了基于扩散模型的现有最先进成果，实现了更高的分类准确率，同时仅需要一小部分的内存成本和采样时间。", "conclusion": "FunLoRA通过创新的条件机制，有效解决了深度生成模型持续适应中的灾难性遗忘和合成数据再训练的局限性，显著提高了性能和效率，超越了以往的先进方法。"}}
{"id": "2510.02728", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02728", "abs": "https://arxiv.org/abs/2510.02728", "authors": ["Lingfeng Zhang", "Erjia Xiao", "Yuchen Zhang", "Haoxiang Fu", "Ruibin Hu", "Yanbiao Ma", "Wenbo Ding", "Long Chen", "Hangjun Ye", "Xiaoshuai Hao"], "title": "Team Xiaomi EV-AD VLA: Caption-Guided Retrieval System for Cross-Modal Drone Navigation -- Technical Report for IROS 2025 RoboSense Challenge Track 4", "comment": null, "summary": "Cross-modal drone navigation remains a challenging task in robotics,\nrequiring efficient retrieval of relevant images from large-scale databases\nbased on natural language descriptions. The RoboSense 2025 Track 4 challenge\naddresses this challenge, focusing on robust, natural language-guided\ncross-view image retrieval across multiple platforms (drones, satellites, and\nground cameras). Current baseline methods, while effective for initial\nretrieval, often struggle to achieve fine-grained semantic matching between\ntext queries and visual content, especially in complex aerial scenes. To\naddress this challenge, we propose a two-stage retrieval refinement method:\nCaption-Guided Retrieval System (CGRS) that enhances the baseline coarse\nranking through intelligent reranking. Our method first leverages a baseline\nmodel to obtain an initial coarse ranking of the top 20 most relevant images\nfor each query. We then use Vision-Language-Model (VLM) to generate detailed\ncaptions for these candidate images, capturing rich semantic descriptions of\ntheir visual content. These generated captions are then used in a multimodal\nsimilarity computation framework to perform fine-grained reranking of the\noriginal text query, effectively building a semantic bridge between the visual\ncontent and natural language descriptions. Our approach significantly improves\nupon the baseline, achieving a consistent 5\\% improvement across all key\nmetrics (Recall@1, Recall@5, and Recall@10). Our approach win TOP-2 in the\nchallenge, demonstrating the practical value of our semantic refinement\nstrategy in real-world robotic navigation scenarios.", "AI": {"tldr": "本文提出了一种名为CGRS的两阶段检索精细化方法，通过利用视觉-语言模型（VLM）生成的图像描述进行重排序，显著提升了跨模态无人机导航中基于自然语言的图像检索性能。", "motivation": "跨模态无人机导航中的图像检索任务具有挑战性，现有基线方法在复杂空中场景下难以实现文本查询与视觉内容的细粒度语义匹配。", "method": "该方法分为两阶段：首先，使用基线模型获取初步的粗略排序（前20张图像）；其次，利用视觉-语言模型（VLM）为这些候选图像生成详细描述，然后通过多模态相似度计算框架，结合这些生成的描述对原始文本查询进行细粒度重排序。", "result": "CGRS方法在所有关键指标（Recall@1、Recall@5和Recall@10）上比基线方法一致提高了5%，并在RoboSense 2025 Track 4挑战赛中获得第二名。", "conclusion": "所提出的语义精细化策略在实际机器人导航场景中具有实用价值，有效解决了文本查询与视觉内容之间的语义鸿沟。"}}
{"id": "2510.02720", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.02720", "abs": "https://arxiv.org/abs/2510.02720", "authors": ["Wenjian Hao", "Zehui Lu", "Nicolas Miguel", "Shaoshuai Mou"], "title": "A Control-Barrier-Function-Based Algorithm for Policy Adaptation in Reinforcement Learning", "comment": null, "summary": "This paper considers the problem of adapting a predesigned policy,\nrepresented by a parameterized function class, from a solution that minimizes a\ngiven original cost function to a trade-off solution between minimizing the\noriginal objective and an additional cost function. The problem is formulated\nas a constrained optimization problem, where deviations from the optimal value\nof the original cost are explicitly constrained. To solve it, we develop a\nclosed-loop system that governs the evolution of the policy parameters, with a\nclosed-loop controller designed to adjust the additional cost gradient to\nensure the satisfaction of the constraint. The resulting closed-loop system,\ntermed control-barrier-function-based policy adaptation, exploits the\nset-invariance property of control barrier functions to guarantee constraint\nsatisfaction. The effectiveness of the proposed method is demonstrated through\nnumerical experiments on the Cartpole and Lunar Lander benchmarks from OpenAI\nGym, as well as a quadruped robot, thereby illustrating both its practicality\nand potential for real-world policy adaptation.", "AI": {"tldr": "本文提出了一种基于控制障碍函数（CBF）的策略自适应方法，用于在最小化原始目标和附加目标之间进行权衡时，调整预先设计的策略，同时保证对原始目标最优值的偏差受到约束。", "motivation": "研究动机在于，需要将一个已有的、针对特定成本函数优化的策略，调整以适应新的权衡目标（原始目标与附加目标之间），同时确保不严重偏离原始目标的性能。", "method": "将问题建模为约束优化问题，其中对原始成本函数最优值的偏差进行了明确约束。开发了一个闭环系统来管理策略参数的演变，并设计了一个闭环控制器来调整附加成本梯度，以确保约束满足。该系统利用控制障碍函数的集合不变性特性来保证约束满足。", "result": "通过在OpenAI Gym的Cartpole和Lunar Lander基准测试以及一个四足机器人上的数值实验，证明了所提方法的有效性，展示了其实用性和在实际策略适应中的潜力。", "conclusion": "所提出的基于控制障碍函数的策略自适应方法能够有效地将预先设计的策略调整到新的权衡解决方案，同时通过利用CBF的集合不变性特性来保证对原始目标约束的满足，并具有实际应用前景。"}}
{"id": "2510.02334", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02334", "abs": "https://arxiv.org/abs/2510.02334", "authors": ["Zhe Li", "Wei Zhao", "Yige Li", "Jun Sun"], "title": "Where Did It Go Wrong? Attributing Undesirable LLM Behaviors via Representation Gradient Tracing", "comment": "16 pages, 4 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities, yet\ntheir deployment is frequently undermined by undesirable behaviors such as\ngenerating harmful content, factual inaccuracies, and societal biases.\nDiagnosing the root causes of these failures poses a critical challenge for AI\nsafety. Existing attribution methods, particularly those based on parameter\ngradients, often fall short due to prohibitive noisy signals and computational\ncomplexity. In this work, we introduce a novel and efficient framework that\ndiagnoses a range of undesirable LLM behaviors by analyzing representation and\nits gradients, which operates directly in the model's activation space to\nprovide a semantically meaningful signal linking outputs to their training\ndata. We systematically evaluate our method for tasks that include tracking\nharmful content, detecting backdoor poisoning, and identifying knowledge\ncontamination. The results demonstrate that our approach not only excels at\nsample-level attribution but also enables fine-grained token-level analysis,\nprecisely identifying the specific samples and phrases that causally influence\nmodel behavior. This work provides a powerful diagnostic tool to understand,\naudit, and ultimately mitigate the risks associated with LLMs. The code is\navailable at https://github.com/plumprc/RepT.", "AI": {"tldr": "本文提出了一种新颖高效的框架，通过分析LLM激活空间中的表示及其梯度，诊断LLM的不良行为，实现样本级和细粒度token级的归因，以理解和缓解LLM风险。", "motivation": "大型语言模型（LLMs）虽然能力强大，但常因生成有害内容、事实不准确和存在社会偏见等不良行为而影响部署。诊断这些失败的根本原因对AI安全至关重要。现有基于参数梯度的归因方法因信号噪声大和计算复杂性高而效果不佳。", "method": "引入了一个新颖高效的框架，通过分析模型激活空间中的表示及其梯度来诊断LLM的不良行为。该方法直接在模型的激活空间中操作，提供语义上有意义的信号，将模型输出与其训练数据关联起来。", "result": "该方法在跟踪有害内容、检测后门中毒和识别知识污染等任务中表现出色。它不仅在样本级归因方面表现优异，还能实现细粒度的token级分析，精确识别对模型行为有因果影响的具体样本和短语。", "conclusion": "这项工作提供了一个强大的诊断工具，有助于理解、审计并最终缓解与LLM相关联的风险。"}}
{"id": "2510.02611", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02611", "abs": "https://arxiv.org/abs/2510.02611", "authors": ["Yuheng Wu", "Azalia Mirhoseini", "Thierry Tambe"], "title": "On the Role of Temperature Sampling in Test-Time Scaling", "comment": null, "summary": "Large language models (LLMs) can improve reasoning at inference time through\ntest-time scaling (TTS), where multiple reasoning traces are generated and the\nbest one is selected. Prior work shows that increasing the number of samples K\nsteadily improves accuracy. In this paper, we demonstrate that this trend does\nnot hold indefinitely: at large K, further scaling yields no gains, and certain\nhard questions remain unsolved regardless of the number of traces.\nInterestingly, we find that different sampling temperatures solve different\nsubsets of problems, implying that single-temperature scaling explores only\npart of a model's potential. We therefore propose scaling along the temperature\ndimension, which enlarges the reasoning boundary of LLMs. Averaged over Qwen3\n(0.6B, 1.7B, 4B, 8B) and five representative reasoning benchmarks (AIME\n2024/2025, MATH500, LiveCodeBench, Hi-ToM), temperature scaling yields an\nadditional 7.3 points over single-temperature TTS. Temperature scaling also\nenables base models to reach performance comparable to reinforcement learning\n(RL)-trained counterparts, without additional post-training. We further provide\na comprehensive analysis of this phenomenon and design a multi-temperature\nvoting method that reduces the overhead of temperature scaling. Overall, our\nfindings suggest that TTS is more powerful than previously thought, and that\ntemperature scaling offers a simple and effective way to unlock the latent\npotential of base models.", "AI": {"tldr": "传统的大语言模型推理时测试时间缩放（TTS）通过增加样本数K来提高准确性，但本文发现K的增加并非无限有效。通过探索不同采样温度能解决不同问题子集，本文提出温度缩放方法，能进一步提升LLM的推理能力，甚至使基础模型达到与经过强化学习训练的模型相当的性能。", "motivation": "先前的研究表明，增加样本数K可以持续提高大语言模型（LLM）在推理时的准确性。然而，本文作者发现这种趋势并非无限持续，当K足够大时，进一步增加样本数并无收益，且某些难题无论K多大都无法解决。有趣的是，他们发现不同的采样温度能解决不同的问题子集，这暗示了单一温度缩放未能充分探索模型的潜力，从而促使他们探索温度维度上的缩放。", "method": "研究人员首先观察到，在推理时测试时间缩放（TTS）中，增加样本数K的收益并非无限，且存在难以解决的问题。随后，他们发现不同的采样温度能够解决不同的问题子集。基于此，他们提出了沿温度维度进行缩放的方法，即“温度缩放”。他们使用Qwen3系列模型（0.6B, 1.7B, 4B, 8B）并在五个代表性推理基准（AIME 2024/2025, MATH500, LiveCodeBench, Hi-ToM）上进行了评估。此外，他们还对这种现象进行了综合分析，并设计了一种多温度投票方法来降低温度缩放的开销。", "result": "研究结果表明，当样本数K较大时，进一步增加K并不能带来准确性提升，且某些难题无论K多大都无法解决。不同的采样温度能够解决不同的问题子集。平均而言，温度缩放比单温度TTS额外提升了7.3个点。温度缩放还能使基础模型达到与经过强化学习（RL）训练的模型相当的性能，而无需额外的后训练。此外，他们设计的多温度投票方法有效降低了温度缩放的开销。", "conclusion": "研究结果表明，测试时间缩放（TTS）比之前认为的更强大。温度缩放提供了一种简单有效的方法来释放基础模型的潜在推理能力，显著扩大了LLM的推理边界。"}}
{"id": "2510.02642", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02642", "abs": "https://arxiv.org/abs/2510.02642", "authors": ["Abhishek Joshi", "Jahnavi Krishna Koda", "Abhishek Phadke"], "title": "Sequence-Preserving Dual-FoV Defense for Traffic Sign and Light Recognition in Autonomous Vehicles", "comment": null, "summary": "Traffic light and sign recognition are key for Autonomous Vehicles (AVs)\nbecause perception mistakes directly influence navigation and safety. In\naddition to digital adversarial attacks, models are vulnerable to existing\nperturbations (glare, rain, dirt, or graffiti), which could lead to dangerous\nmisclassifications. The current work lacks consideration of temporal\ncontinuity, multistatic field-of-view (FoV) sensing, and robustness to both\ndigital and natural degradation. This study proposes a dual FoV,\nsequence-preserving robustness framework for traffic lights and signs in the\nUSA based on a multi-source dataset built on aiMotive, Udacity, Waymo, and\nself-recorded videos from the region of Texas. Mid and long-term sequences of\nRGB images are temporally aligned for four operational design domains (ODDs):\nhighway, night, rainy, and urban. Over a series of experiments on a real-life\napplication of anomaly detection, this study outlines a unified three-layer\ndefense stack framework that incorporates feature squeezing, defensive\ndistillation, and entropy-based anomaly detection, as well as sequence-wise\ntemporal voting for further enhancement. The evaluation measures included\naccuracy, attack success rate (ASR), risk-weighted misclassification severity,\nand confidence stability. Physical transferability was confirmed using probes\nfor recapture. The results showed that the Unified Defense Stack achieved\n79.8mAP and reduced the ASR to 18.2%, which is superior to YOLOv8, YOLOv9, and\nBEVFormer, while reducing the high-risk misclassification to 32%.", "AI": {"tldr": "该研究提出了一种针对自动驾驶车辆交通灯和标志识别的鲁棒性框架，通过双视场、序列保留方法和三层防御堆栈（结合特征挤压、防御性蒸馏、基于熵的异常检测及时间投票）来抵御数字攻击和自然退化，其性能优于现有模型。", "motivation": "自动驾驶车辆的交通灯和标志识别对导航和安全至关重要，但现有模型容易受到数字对抗性攻击和自然退化（如眩光、雨水、污垢、涂鸦）的影响，导致危险的错误分类。当前工作缺乏对时间连续性、多态视场感知以及对数字和自然退化双重鲁棒性的考虑。", "method": "本研究提出了一个双视场、序列保留的鲁棒性框架，用于识别美国地区的交通灯和标志。该框架基于一个多源数据集（aiMotive、Udacity、Waymo和德克萨斯州自录视频）构建。中长期RGB图像序列针对四种操作设计域（高速公路、夜间、雨天、城市）进行时间对齐。研究提出一个统一的三层防御堆栈框架，包含特征挤压、防御性蒸馏和基于熵的异常检测，并结合序列级时间投票进一步增强。评估指标包括准确率、攻击成功率（ASR）、风险加权错误分类严重性和置信度稳定性。通过重新捕获探针验证了物理可迁移性。", "result": "统一防御堆栈（Unified Defense Stack）实现了79.8mAP，并将攻击成功率（ASR）降低到18.2%，优于YOLOv8、YOLOv9和BEVFormer，同时将高风险错误分类降低到32%。", "conclusion": "所提出的统一防御堆栈框架显著增强了自动驾驶车辆交通灯和标志识别对数字攻击和自然退化的鲁棒性，表现出卓越的性能并降低了高风险错误分类，为实际应用提供了更安全的感知解决方案。"}}
{"id": "2510.02738", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02738", "abs": "https://arxiv.org/abs/2510.02738", "authors": ["Tianyu Li", "Yihan Li", "Zizhe Zhang", "Nadia Figueroa"], "title": "Flow with the Force Field: Learning 3D Compliant Flow Matching Policies from Force and Demonstration-Guided Simulation Data", "comment": null, "summary": "While visuomotor policy has made advancements in recent years, contact-rich\ntasks still remain a challenge. Robotic manipulation tasks that require\ncontinuous contact demand explicit handling of compliance and force. However,\nmost visuomotor policies ignore compliance, overlooking the importance of\nphysical interaction with the real world, often leading to excessive contact\nforces or fragile behavior under uncertainty. Introducing force information\ninto vision-based imitation learning could help improve awareness of contacts,\nbut could also require a lot of data to perform well. One remedy for data\nscarcity is to generate data in simulation, yet computationally taxing\nprocesses are required to generate data good enough not to suffer from the\nSim2Real gap. In this work, we introduce a framework for generating\nforce-informed data in simulation, instantiated by a single human\ndemonstration, and show how coupling with a compliant policy improves the\nperformance of a visuomotor policy learned from synthetic data. We validate our\napproach on real-robot tasks, including non-prehensile block flipping and a\nbi-manual object moving, where the learned policy exhibits reliable contact\nmaintenance and adaptation to novel conditions. Project Website:\nhttps://flow-with-the-force-field.github.io/webpage/", "AI": {"tldr": "本文提出一个框架，通过单次人类演示在模拟中生成力感知数据，并将其与柔顺策略结合，显著提升了从合成数据学习的视觉运动策略在接触密集型任务中的性能和适应性。", "motivation": "当前的视觉运动策略在接触密集型任务中面临挑战，因为它们通常忽略柔顺性和力，导致接触力过大或在不确定性下行为脆弱。将力信息引入视觉模仿学习需要大量数据，而模拟数据生成又存在Sim2Real鸿沟问题。", "method": "引入了一个框架，通过单次人类演示在模拟中生成力感知数据。该方法将生成的合成数据与柔顺策略相结合，以提高从这些合成数据学习的视觉运动策略的性能。", "result": "在真实机器人任务（包括非抓取式翻块和双臂物体移动）中验证了该方法。学习到的策略表现出可靠的接触维持能力和对新条件的良好适应性。", "conclusion": "通过结合力感知模拟数据（源自单次人类演示）和柔顺策略，可以有效提高视觉运动策略在接触密集型机器人操作任务中的鲁棒性和适应性。"}}
{"id": "2510.02769", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.02769", "abs": "https://arxiv.org/abs/2510.02769", "authors": ["Chidre Shravista Kashyap", "Karnan A", "Pushpak Jagtap", "Jishnu Keshavan"], "title": "Periodic Event-Triggered Prescribed Time Control of Euler-Lagrange Systems under State and Input Constraints", "comment": null, "summary": "This article proposes a periodic event-triggered adaptive barrier control\npolicy for the trajectory tracking problem of perturbed Euler-Lagrangian\nsystems with state, input, and temporal (SIT) constraints. In particular, an\napproximation-free adaptive-barrier control architecture is designed to ensure\nprescribed-time convergence of the tracking error to a prescribed bound while\nrejecting exogenous disturbances. In contrast to existing approaches that\nnecessitate continuous real-time control action, the proposed controller\ngenerates event-based updates through periodic evaluation of the triggering\ncondition. Additionally, we derive an upper bound on the monitoring period by\nanalysing the performance degradation of the filtered tracking error to\nfacilitate periodic evaluation of the event-triggered strategy. To this end, a\ntime-varying threshold function is considered in the triggering mechanism to\nreduce the number of triggers during the transient phase of system behaviour.\nNotably, the proposed design avoids Zeno behaviour and precludes the need for\ncontinuous monitoring of the triggering condition. A simulation and\nexperimental study is undertaken to demonstrate the efficacy of the proposed\ncontrol scheme.", "AI": {"tldr": "本文提出了一种周期事件触发自适应障碍控制策略，用于解决受扰动Euler-Lagrangian系统在状态、输入和时间（SIT）约束下的轨迹跟踪问题。", "motivation": "现有方法需要连续的实时控制动作，而本文旨在设计一种事件触发的控制策略，以减少控制更新的频率，同时确保跟踪误差在规定时间内收敛到预定界限并抑制外部扰动。", "method": "本文设计了一种无近似的自适应障碍控制架构，通过周期性评估触发条件来生成事件更新。通过分析滤波跟踪误差的性能下降，推导了监测周期的上限。触发机制中考虑了时变阈值函数，以减少瞬态阶段的触发次数。该设计避免了芝诺行为，并无需连续监测触发条件。", "result": "所提出的控制策略确保了跟踪误差在规定时间内收敛到预定界限，同时抑制了外部扰动。它通过周期性事件触发减少了控制动作，避免了芝诺行为，且无需连续监测触发条件。通过仿真和实验研究验证了该控制方案的有效性。", "conclusion": "本文提出了一种高效且鲁棒的周期事件触发自适应障碍控制策略，成功解决了受扰动Euler-Lagrangian系统在SIT约束下的轨迹跟踪问题，显著减少了控制更新频率并避免了连续监测的需求。"}}
{"id": "2510.02335", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02335", "abs": "https://arxiv.org/abs/2510.02335", "authors": ["Xiao-Wen Yang", "Zihao Zhang", "Jianuo Cao", "Zhi Zhou", "Zenan Li", "Lan-Zhe Guo", "Yuan Yao", "Taolue Chen", "Yu-Feng Li", "Xiaoxing Ma"], "title": "FormalML: A Benchmark for Evaluating Formal Subgoal Completion in Machine Learning Theory", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated remarkable progress\nin formal theorem proving. Yet their ability to serve as practical assistants\nfor mathematicians, filling in missing steps within complex proofs, remains\nunderexplored. We identify this challenge as the task of subgoal completion,\nwhere an LLM must discharge short but nontrivial proof obligations left\nunresolved in a human-provided sketch. To study this problem, we introduce\nFormalML, a Lean 4 benchmark built from foundational theories of machine\nlearning. Using a translation tactic that converts procedural proofs into\ndeclarative form, we extract 4937 problems spanning optimization and\nprobability inequalities, with varying levels of difficulty. FormalML is the\nfirst subgoal completion benchmark to combine premise retrieval and complex\nresearch-level contexts. Evaluation of state-of-the-art provers highlights\npersistent limitations in accuracy and efficiency, underscoring the need for\nmore capable LLM-based theorem provers for effective subgoal completion,", "AI": {"tldr": "该研究探讨大型语言模型（LLMs）在形式化定理证明中“子目标补全”任务的能力，引入了新的FormalML基准，并发现当前最先进的证明器在此任务上仍存在准确性和效率的局限性。", "motivation": "尽管LLMs在形式化定理证明方面取得了显著进展，但它们作为数学家实用助手，用于填充复杂证明中缺失步骤的能力尚未得到充分探索。研究人员将此挑战定义为“子目标补全”任务。", "method": "研究人员将该挑战定义为子目标补全任务。为研究此问题，他们引入了FormalML，一个基于Lean 4且构建于机器学习基础理论上的基准。通过一种将程序式证明转换为声明式形式的翻译策略，他们提取了4937个跨越优化和概率不等式的难题，具有不同难度级别。FormalML是第一个结合前提检索和复杂研究级上下文的子目标补全基准。", "result": "对最先进的证明器进行的评估突出了它们在准确性和效率方面的持续局限性。", "conclusion": "研究结果强调了需要更强大的基于LLM的定理证明器，以实现有效的子目标补全，从而更好地辅助数学家。"}}
{"id": "2510.02653", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.02653", "abs": "https://arxiv.org/abs/2510.02653", "authors": ["Micaela Fuel Pozo", "Andrea Guatumillo Saltos", "Yeseña Tipan Llumiquinga", "Kelly Lascano Aguirre", "Marilyn Castillo Jara", "Christian Mejia-Escobar"], "title": "Geolog-IA: Conversational System for Academic Theses", "comment": "17 pages, in Spanish language", "summary": "This study presents the development of Geolog-IA, a novel conversational\nsystem based on artificial intelligence that responds naturally to questions\nabout geology theses from the Central University of Ecuador. Our proposal uses\nthe Llama 3.1 and Gemini 2.5 language models, which are complemented by a\nRetrieval Augmented Generation (RAG) architecture and an SQLite database. This\nstrategy allows us to overcome problems such as hallucinations and outdated\nknowledge. The evaluation of Geolog-IA's performance with the BLEU metric\nreaches an average of 0.87, indicating high consistency and accuracy in the\nresponses generated. The system offers an intuitive, web-based interface that\nfacilitates interaction and information retrieval for directors, teachers,\nstudents, and administrative staff at the institution. This tool can be a key\nsupport in education, training, and research and establishes a basis for future\napplications in other disciplines.", "AI": {"tldr": "本研究开发了Geolog-IA，一个基于Llama 3.1、Gemini 2.5、RAG架构和SQLite数据库的AI对话系统，旨在自然回答厄瓜多尔中央大学地质学论文相关问题，BLEU得分平均0.87，具有高一致性和准确性。", "motivation": "开发一个能够克服AI幻觉和知识过时问题，并能自然回答厄瓜多尔中央大学地质学论文相关问题的智能系统，以支持机构内师生和行政人员的信息检索和互动需求。", "method": "Geolog-IA系统采用Llama 3.1和Gemini 2.5大型语言模型，结合检索增强生成（RAG）架构和SQLite数据库。系统提供直观的网页界面，并使用BLEU指标评估其性能。", "result": "Geolog-IA系统在BLEU指标上平均得分达到0.87，表明其生成回复具有高一致性和准确性。系统提供了一个直观的网页界面，便于用户交互和信息检索。", "conclusion": "Geolog-IA是一个在教育、培训和研究方面具有关键支持作用的工具，有效解决了AI幻觉和知识过时问题，并为未来在其他学科的应用奠定了基础。"}}
{"id": "2510.02654", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02654", "abs": "https://arxiv.org/abs/2510.02654", "authors": ["Benjamin Yu", "Jackie Liu", "Justin Cui"], "title": "Smart-GRPO: Smartly Sampling Noise for Efficient RL of Flow-Matching Models", "comment": null, "summary": "Recent advancements in flow-matching have enabled high-quality text-to-image\ngeneration. However, the deterministic nature of flow-matching models makes\nthem poorly suited for reinforcement learning, a key tool for improving image\nquality and human alignment. Prior work has introduced stochasticity by\nperturbing latents with random noise, but such perturbations are inefficient\nand unstable. We propose Smart-GRPO, the first method to optimize noise\nperturbations for reinforcement learning in flow-matching models. Smart-GRPO\nemploys an iterative search strategy that decodes candidate perturbations,\nevaluates them with a reward function, and refines the noise distribution\ntoward higher-reward regions. Experiments demonstrate that Smart-GRPO improves\nboth reward optimization and visual quality compared to baseline methods. Our\nresults suggest a practical path toward reinforcement learning in flow-matching\nframeworks, bridging the gap between efficient training and human-aligned\ngeneration.", "AI": {"tldr": "Smart-GRPO是首个优化流匹配模型中噪声扰动以进行强化学习的方法，通过迭代搜索策略提高奖励优化和视觉质量，为流匹配框架中的强化学习提供了实用路径。", "motivation": "流匹配模型固有的确定性使其不适合强化学习，而强化学习是提高图像质量和人类对齐的关键工具。现有通过随机噪声扰动潜在变量的方法效率低下且不稳定。", "method": "本文提出了Smart-GRPO，一种通过迭代搜索策略来优化流匹配模型中噪声扰动的方法。该策略解码候选扰动，使用奖励函数进行评估，并将噪声分布向更高奖励区域细化。", "result": "实验证明，与基线方法相比，Smart-GRPO在奖励优化和视觉质量方面都有显著提升。", "conclusion": "研究结果为流匹配框架中的强化学习提供了一条实用路径，弥合了高效训练与人类对齐生成之间的鸿沟。"}}
{"id": "2510.02803", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02803", "abs": "https://arxiv.org/abs/2510.02803", "authors": ["Yifan Liao", "Zhen Sun", "Xiaoyun Qiu", "Zixiao Zhao", "Wenbing Tang", "Xinlei He", "Xinhu Zheng", "Tianwei Zhang", "Xinyi Huang", "Xingshuo Han"], "title": "Work Zones challenge VLM Trajectory Planning: Toward Mitigation and Robust Autonomous Driving", "comment": "13 pages,5 figures", "summary": "Visual Language Models (VLMs), with powerful multimodal reasoning\ncapabilities, are gradually integrated into autonomous driving by several\nautomobile manufacturers to enhance planning capability in challenging\nenvironments. However, the trajectory planning capability of VLMs in work\nzones, which often include irregular layouts, temporary traffic control, and\ndynamically changing geometric structures, is still unexplored. To bridge this\ngap, we conduct the \\textit{first} systematic study of VLMs for work zone\ntrajectory planning, revealing that mainstream VLMs fail to generate correct\ntrajectories in $68.0%$ of cases. To better understand these failures, we first\nidentify candidate patterns via subgraph mining and clustering analysis, and\nthen confirm the validity of $8$ common failure patterns through human\nverification. Building on these findings, we propose REACT-Drive, a trajectory\nplanning framework that integrates VLMs with Retrieval-Augmented Generation\n(RAG). Specifically, REACT-Drive leverages VLMs to convert prior failure cases\ninto constraint rules and executable trajectory planning code, while RAG\nretrieves similar patterns in new scenarios to guide trajectory generation.\nExperimental results on the ROADWork dataset show that REACT-Drive yields a\nreduction of around $3\\times$ in average displacement error relative to VLM\nbaselines under evaluation with Qwen2.5-VL. In addition, REACT-Drive yields the\nlowest inference time ($0.58$s) compared with other methods such as fine-tuning\n($17.90$s). We further conduct experiments using a real vehicle in 15 work zone\nscenarios in the physical world, demonstrating the strong practicality of\nREACT-Drive.", "AI": {"tldr": "主流视觉语言模型（VLM）在施工区轨迹规划中表现不佳（68%的失败率）。本文提出了REACT-Drive框架，通过结合VLM和检索增强生成（RAG），显著提高了施工区轨迹规划的准确性和推理速度，并通过真实车辆实验验证了其实用性。", "motivation": "视觉语言模型（VLM）因其强大的多模态推理能力正被集成到自动驾驶中以增强复杂环境下的规划能力。然而，VLM在施工区（通常具有不规则布局、临时交通管制和动态几何结构）的轨迹规划能力尚未被探索，且主流VLM在此类场景中表现出高失败率。", "method": "首先，系统研究了VLM在施工区轨迹规划中的表现，发现其68.0%的失败率。其次，通过子图挖掘、聚类分析和人工验证，识别并确认了8种常见的失败模式。在此基础上，提出了REACT-Drive框架，该框架将VLM与检索增强生成（RAG）相结合。具体而言，REACT-Drive利用VLM将过去的失败案例转换为约束规则和可执行的轨迹规划代码，同时RAG在新的场景中检索相似模式以指导轨迹生成。", "result": "在ROADWork数据集上，REACT-Drive相对于基于Qwen2.5-VL的VLM基线，平均位移误差减少了约3倍。此外，REACT-Drive的推理时间最短（0.58秒），远低于其他方法（如微调的17.90秒）。通过在物理世界中15个施工区场景的真实车辆实验，进一步证明了REACT-Drive的强大实用性。", "conclusion": "REACT-Drive框架通过将VLM与RAG结合，有效解决了VLM在施工区轨迹规划中的局限性，实现了更高的准确性和效率。该研究为自动驾驶在复杂施工区环境下的轨迹规划提供了有效且实用的解决方案。"}}
{"id": "2510.02866", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.02866", "abs": "https://arxiv.org/abs/2510.02866", "authors": ["Bassel Diban", "Giovanni Mazzanti"], "title": "Life Estimation of HVDC Cable Insulation under Load Cycles: from Macroscopic to Microscopic Charge Conduction Modelling", "comment": null, "summary": "This paper goes one step forward in the life estimation of HVDC cable\ninsulation under load cycles by introducing for the first time a microscopic\nmodel of charge conduction and transport i.e., Bipolar Charge Transport BCT\nmodel for electric field calculation inside the insulation thickness. The paper\nfirstly includes the development and the validation of BCT model with that\nfound in literature. Then, the parameters of the developed BCT model are\noptimized using Pulsed Electro-Acoustic PEA space charge measurements. Followed\nby the integration of the developed, validated and optimized model into the\nelectric field calculation for life estimation of a 500 kV DC-XLPE insulated\ncable subjected to Type Test load cycles according to Cigre Techical Brochure\n852. The developed microscopic model is compared to the macroscopic models\nalready found in the literature. The microscopic model shows a comparable\nelectric field inversion similarly to macroscopic models. However, the behavior\nof the microscopic model is noticed to be different under heating and cooling\nload cycles. In hot cable, the maximum electric field stabilizes at different\namplitude and position inside the insulation thickness in both models. This\ninvestigation has been carried out in the framework of the HEU-NEWGEN research\nproject.", "AI": {"tldr": "本文首次引入微观双极性电荷传输（BCT）模型来计算高压直流（HVDC）电缆绝缘层内的电场，以改进负载循环下电缆绝缘寿命的评估。", "motivation": "研究动机是为了在高压直流电缆绝缘的寿命评估方面向前迈进一步，特别是通过引入一种微观的电荷传导和传输模型（BCT模型），以更精确地计算绝缘厚度内的电场，从而克服现有宏观模型的局限性。", "method": "研究方法包括：1) 开发并验证BCT模型，与现有文献进行对比；2) 利用脉冲电声（PEA）空间电荷测量优化BCT模型的参数；3) 将开发、验证和优化的模型整合到500 kV直流-交联聚乙烯（DC-XLPE）绝缘电缆在Cigre Techical Brochure 852型式试验负载循环下的电场计算中，用于寿命评估；4) 将开发的微观模型与文献中的宏观模型进行比较。", "result": "研究结果显示：微观模型与宏观模型在电场反转方面表现出可比性；然而，微观模型在加热和冷却负载循环下的行为有所不同；在热电缆中，两种模型中最大电场稳定时的幅度和位置在绝缘厚度内也不同。", "conclusion": "结论是，首次引入的微观BCT模型为HVDC电缆绝缘寿命评估中的电场计算提供了一种新方法。尽管在某些方面与宏观模型相似，但它在加热和冷却负载循环下表现出独特的行为，尤其是在热电缆中最大电场稳定时的幅度和位置上，这对于更精确地理解和评估电缆绝缘寿命至关重要。"}}
{"id": "2510.02336", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02336", "abs": "https://arxiv.org/abs/2510.02336", "authors": ["Abdulhady Abas Abdullah", "Hadi Veisi", "Hussein M. Al"], "title": "KurdSTS: The Kurdish Semantic Textual Similarity", "comment": null, "summary": "Semantic Textual Similarity (STS) measures the degree of meaning overlap\nbetween two texts and underpins many NLP tasks. While extensive resources exist\nfor high-resource languages, low-resource languages such as Kurdish remain\nunderserved. We present, to our knowledge, the first Kurdish STS dataset:\n10,000 sentence pairs spanning formal and informal registers, each annotated\nfor similarity. We benchmark Sentence-BERT, multilingual BERT, and other strong\nbaselines, obtaining competitive results while highlighting challenges arising\nfrom Kurdish morphology, orthographic variation, and code-mixing. The dataset\nand baselines establish a reproducible evaluation suite and provide a strong\nstarting point for future research on Kurdish semantics and low-resource NLP.", "AI": {"tldr": "本文首次提出了一个包含10,000对句子的库尔德语语义文本相似度（STS）数据集，并对多种基线模型进行了基准测试，揭示了库尔德语在STS任务中的挑战。", "motivation": "语义文本相似度（STS）是许多自然语言处理任务的基础，但现有资源主要集中在高资源语言。库尔德语等低资源语言缺乏STS数据集，阻碍了相关研究进展。", "method": "研究者构建了一个包含10,000对句子的库尔德语STS数据集，涵盖正式和非正式语域，并进行了相似度标注。随后，他们使用Sentence-BERT、多语言BERT和其他强基线模型进行了基准测试。", "result": "基准测试取得了有竞争力的结果，同时揭示了库尔德语形态学、正字法变异和语码混合等因素给STS任务带来的挑战。", "conclusion": "该数据集和基线模型为库尔德语语义研究和低资源NLP提供了一个可复现的评估套件和有力的研究起点。"}}
{"id": "2510.02655", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02655", "abs": "https://arxiv.org/abs/2510.02655", "authors": ["Daniel G. Schwartz"], "title": "A Concept of Possibility for Real-World Events", "comment": null, "summary": "This paper offers a new concept of {\\it possibility} as an alternative to the\nnow-a-days standard concept originally introduced by L.A. Zadeh in 1978. This\nnew version was inspired by the original but, formally, has nothing in common\nwith it other than that they both adopt the {\\L}ukasiewicz multivalent\ninterpretation of the logical connectives. Moreover, rather than seeking to\nprovide a general notion of possibility, this focuses specifically on the\npossibility of a real-world event. An event is viewed as having prerequisites\nthat enable its occurrence and constraints that may impede its occurrence, and\nthe possibility of the event is computed as a function of the probabilities\nthat the prerequisites hold and the constraints do not. This version of\npossibility might appropriately be applied to problems of planning. When there\nare multiple plans available for achieving a goal, this theory can be used to\ndetermine which plan is most possible, i.e., easiest or most feasible to\ncomplete. It is speculated that this model of reasoning correctly captures\nnormal human reasoning about plans. The theory is elaborated and an\nillustrative example for vehicle route planning is provided. There is also a\nsuggestion of potential future applications.", "AI": {"tldr": "本文提出了一种新的可能性概念，作为L.A. Zadeh 1978年标准概念的替代，专注于现实世界事件，通过评估前提条件和约束的概率来计算，并适用于规划问题。", "motivation": "旨在提供一个替代现有标准可能性概念的新视角，并特别关注现实世界事件的可能性评估，而非通用可能性概念。", "method": "新概念形式上独立于L.A. Zadeh的原始概念，但两者都采用Łukasiewicz多值逻辑解释。它将事件视为具有促成其发生的前提条件和可能阻碍其发生的约束。事件的可能性被计算为前提条件成立和约束不成立的概率函数。", "result": "提出了一种新的可能性计算理论，可应用于规划问题，用于确定多个方案中最可能（即最容易或最可行）的方案。文中对该理论进行了阐述，并提供了车辆路线规划的示例进行说明。", "conclusion": "该可能性推理模型可能正确捕捉了人类对计划的正常推理方式，并具有潜在的未来应用价值。"}}
{"id": "2510.02691", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.02691", "abs": "https://arxiv.org/abs/2510.02691", "authors": ["Yibin Zhao", "Yihan Pan", "Jun Nan", "Jianjun Yi"], "title": "FSFSplatter: Build Surface and Novel Views with Sparse-Views within 3min", "comment": null, "summary": "Gaussian Splatting has become a leading reconstruction technique, known for\nits high-quality novel view synthesis and detailed reconstruction. However,\nmost existing methods require dense, calibrated views. Reconstructing from free\nsparse images often leads to poor surface due to limited overlap and\noverfitting. We introduce FSFSplatter, a new approach for fast surface\nreconstruction from free sparse images. Our method integrates end-to-end dense\nGaussian initialization, camera parameter estimation, and geometry-enhanced\nscene optimization. Specifically, FSFSplatter employs a large Transformer to\nencode multi-view images and generates a dense and geometrically consistent\nGaussian scene initialization via a self-splitting Gaussian head. It eliminates\nlocal floaters through contribution-based pruning and mitigates overfitting to\nlimited views by leveraging depth and multi-view feature supervision with\ndifferentiable camera parameters during rapid optimization. FSFSplatter\noutperforms current state-of-the-art methods on widely used DTU and Replica.", "AI": {"tldr": "FSFSplatter 是一种新方法，通过集成端到端高斯初始化、相机参数估计和几何增强场景优化，实现了从稀疏自由图像中进行快速表面重建，解决了现有高斯泼溅方法在稀疏视图下表现不佳的问题。", "motivation": "现有高斯泼溅技术虽然在高质量新视图合成和细节重建方面表现出色，但通常需要密集、经过校准的视图。从自由稀疏图像进行重建时，由于重叠有限和过拟合，往往导致表面质量差。", "method": "FSFSplatter 采用端到端密集高斯初始化、相机参数估计和几何增强场景优化。具体来说，它使用大型 Transformer 编码多视图图像，并通过自拆分高斯头部生成密集且几何一致的高斯场景初始化。通过基于贡献的剪枝消除局部漂浮物，并通过利用深度和多视图特征监督以及可微分相机参数来减轻对有限视图的过拟合。", "result": "FSFSplatter 在广泛使用的 DTU 和 Replica 数据集上，性能优于当前最先进的方法。", "conclusion": "FSFSplatter 成功地解决了从稀疏自由图像进行表面重建的挑战，提供了一种快速且高质量的解决方案，克服了现有高斯泼溅方法在视图稀疏性方面的局限性。"}}
{"id": "2510.02808", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.02808", "abs": "https://arxiv.org/abs/2510.02808", "authors": ["Andreas Christou", "Elliot Lister", "Georgia Andreopoulou", "Don Mahad", "Sethu Vijayakumar"], "title": "Assist-as-needed Control for FES in Foot Drop Management", "comment": null, "summary": "Foot drop is commonly managed using Functional Electrical Stimulation (FES),\ntypically delivered via open-loop controllers with fixed stimulation\nintensities. While users may manually adjust the intensity through external\ncontrols, this approach risks overstimulation, leading to muscle fatigue and\ndiscomfort, or understimulation, which compromises dorsiflexion and increases\nfall risk. In this study, we propose a novel closed-loop FES controller that\ndynamically adjusts the stimulation intensity based on real-time toe clearance,\nproviding \"assistance as needed\". We evaluate this system by inducing foot drop\nin healthy participants and comparing the effects of the closed-loop controller\nwith a traditional open-loop controller across various walking conditions,\nincluding different speeds and surface inclinations. Kinematic data reveal that\nour closed-loop controller maintains adequate toe clearance without\nsignificantly affecting the joint angles of the hips, the knees, and the\nankles, and while using significantly lower stimulation intensities compared to\nthe open-loop controller. These findings suggest that the proposed method not\nonly matches the effectiveness of existing systems but also offers the\npotential for reduced muscle fatigue and improved long-term user comfort and\nadherence.", "AI": {"tldr": "本研究提出了一种基于实时脚趾间隙的闭环功能性电刺激（FES）控制器，用于治疗足下垂，与传统开环系统相比，它能有效维持脚趾间隙，同时显著降低刺激强度。", "motivation": "传统的足下垂FES采用开环控制器，刺激强度固定，可能导致过度刺激（肌肉疲劳、不适）或刺激不足（背屈不足、跌倒风险增加）。", "method": "研究开发了一种新型闭环FES控制器，可根据实时脚趾间隙动态调整刺激强度，提供“按需辅助”。通过在健康参与者中模拟足下垂，并在不同步速和坡度下，将该闭环控制器与传统开环控制器进行比较，分析运动学数据。", "result": "闭环控制器在不显著影响髋、膝、踝关节角度的情况下，保持了足够的脚趾间隙，并且与开环控制器相比，使用的刺激强度显著降低。", "conclusion": "所提出的闭环FES方法不仅与现有系统效果相当，而且有望减少肌肉疲劳，提高用户的长期舒适度和依从性。"}}
{"id": "2510.02889", "categories": ["eess.SY", "cs.MA", "cs.SI", "cs.SY", "eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.02889", "abs": "https://arxiv.org/abs/2510.02889", "authors": ["Mohammadreza Doostmohammadian", "Narahari Kasagatta Ramesh", "Alireza Aghasi"], "title": "Delay-Tolerant Augmented-Consensus-based Distributed Directed Optimization", "comment": "Systems & Control Letters", "summary": "Distributed optimization finds applications in large-scale machine learning,\ndata processing and classification over multi-agent networks. In real-world\nscenarios, the communication network of agents may encounter latency that may\naffect the convergence of the optimization protocol. This paper addresses the\ncase where the information exchange among the agents (computing nodes) over\ndata-transmission channels (links) might be subject to communication\ntime-delays, which is not well addressed in the existing literature. Our\nproposed algorithm improves the state-of-the-art by handling heterogeneous and\narbitrary but bounded and fixed (time-invariant) delays over general\nstrongly-connected directed networks. Arguments from matrix theory, algebraic\ngraph theory, and augmented consensus formulation are applied to prove the\nconvergence to the optimal value. Simulations are provided to verify the\nresults and compare the performance with some existing delay-free algorithms.", "AI": {"tldr": "本文提出了一种处理分布式优化中异构、有界且固定通信时延的算法，并证明了其在强连通有向网络上的收敛性。", "motivation": "在现实世界的分布式优化应用中，代理间的通信网络可能遇到时延，这会影响优化协议的收敛性。现有文献对通信时延的处理不够充分。", "method": "提出了一种新的算法，通过应用矩阵理论、代数图论和增广共识公式来证明其收敛到最优值。该算法能够处理一般强连通有向网络中异构、任意但有界且固定的（时不变）时延。", "result": "所提出的算法被证明能够收敛到最优值。通过仿真验证了结果，并与现有无时延算法进行了性能比较。", "conclusion": "该研究成功解决了分布式优化中通信时延问题，提供了一种在存在异构、有界且固定时延的强连通有向网络中实现最优值收敛的算法。"}}
{"id": "2510.02337", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02337", "abs": "https://arxiv.org/abs/2510.02337", "authors": ["Ishak Soltani", "Francisco Belo", "Bernardo Tavares"], "title": "CRACQ: A Multi-Dimensional Approach To Automated Document Assessment", "comment": null, "summary": "This paper presents CRACQ, a multi-dimensional evaluation framework tailored\nto evaluate documents across f i v e specific traits: Coherence, Rigor,\nAppropriateness, Completeness, and Quality. Building on insights from\ntraitbased Automated Essay Scoring (AES), CRACQ expands its fo-cus beyond\nessays to encompass diverse forms of machine-generated text, providing a\nrubricdriven and interpretable methodology for automated evaluation. Unlike\nsinglescore approaches, CRACQ integrates linguistic, semantic, and structural\nsignals into a cumulative assessment, enabling both holistic and trait-level\nanalysis. Trained on 500 synthetic grant pro-posals, CRACQ was benchmarked\nagainst an LLM-as-a-judge and further tested on both strong and weak real\napplications. Preliminary results in-dicate that CRACQ produces more stable and\ninterpretable trait-level judgments than direct LLM evaluation, though\nchallenges in reliability and domain scope remain", "AI": {"tldr": "CRACQ是一个多维度评估框架，用于评估机器生成文本的连贯性、严谨性、适当性、完整性和质量。它通过整合语言、语义和结构信号，提供比直接大型语言模型（LLM）评估更稳定和可解释的特质级别判断，尽管在可靠性和领域范围上仍面临挑战。", "motivation": "现有评估方法（如单一分数或直接LLM评估）可能无法提供对机器生成文本的细致、可解释的多维度分析。论文旨在开发一个超越传统散文评估，适用于多种机器生成文本，并能提供特质级别评估的框架。", "method": "CRACQ是一个多维度评估框架，基于“特质评估”的自动化论文评分（AES）理念，扩展到各种机器生成文本。它通过整合语言、语义和结构信号进行累积评估，能够进行整体和特质级别分析。该框架在500份合成项目提案上进行训练，并与“LLM-as-a-judge”方法进行基准测试，同时在真实应用（强/弱）上进行验证。", "result": "初步结果表明，CRACQ在特质级别判断上比直接LLM评估更稳定和可解释。然而，在可靠性和领域范围方面仍存在挑战。", "conclusion": "CRACQ提供了一种有前景的、可解释的机器生成文本多维度评估方法，尤其在特质级别判断上表现出优于直接LLM评估的稳定性。尽管仍需解决可靠性和领域范围的挑战，但其潜力巨大。"}}
{"id": "2510.02669", "categories": ["cs.AI", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.02669", "abs": "https://arxiv.org/abs/2510.02669", "authors": ["Bo Ma", "Hang Li", "ZeHua Hu", "XiaoFan Gui", "LuYao Liu", "Simon Liu"], "title": "AutoMaAS: Self-Evolving Multi-Agent Architecture Search for Large Language Models", "comment": null, "summary": "Multi-agent systems powered by large language models have demonstrated\nremarkable capabilities across diverse domains, yet existing automated design\napproaches seek monolithic solutions that fail to adapt resource allocation\nbased on query complexity and domain requirements. This paper introduces\nAutoMaAS, a self-evolving multi-agent architecture search framework that\nleverages neural architecture search principles to automatically discover\noptimal agent configurations through dynamic operator lifecycle management and\nautomated machine learning techniques. Our approach incorporates four key\ninnovations: (1) automatic operator generation, fusion, and elimination based\non performance-cost analysis, (2) dynamic cost-aware optimization with\nreal-time parameter adjustment, (3) online feedback integration for continuous\narchitecture refinement, and (4) enhanced interpretability through decision\ntracing mechanisms. Extensive experiments across six benchmarks demonstrate\nthat AutoMaAS achieves 1.0-7.1\\% performance improvement while reducing\ninference costs by 3-5\\% compared to state-of-the-art methods. The framework\nshows superior transferability across datasets and LLM backbones, establishing\na new paradigm for automated multi-agent system design in the era of large\nlanguage models.", "AI": {"tldr": "本文提出了AutoMaAS，一个自演进的多智能体架构搜索框架，它利用神经架构搜索原则，通过动态操作符生命周期管理和自动化机器学习技术，自动发现最佳智能体配置，从而在性能和成本上超越现有方法。", "motivation": "现有基于大型语言模型的多智能体系统自动化设计方法倾向于提供单一解决方案，未能根据查询复杂性和领域需求自适应地分配资源。", "method": "AutoMaAS框架通过动态操作符生命周期管理和自动化机器学习技术，利用神经架构搜索原则自动发现最佳智能体配置。其核心创新包括：1) 基于性能-成本分析的自动操作符生成、融合与消除；2) 具有实时参数调整的动态成本感知优化；3) 用于持续架构优化的在线反馈集成；4) 通过决策追踪机制增强可解释性。", "result": "在六个基准测试中，AutoMaAS比现有最先进方法实现了1.0-7.1%的性能提升，同时将推理成本降低了3-5%。该框架在不同数据集和大型语言模型骨干网络之间展现出卓越的可迁移性。", "conclusion": "AutoMaAS为大型语言模型时代的多智能体系统自动化设计建立了一个新范式，其在性能、成本和可迁移性方面均表现出色。"}}
{"id": "2510.02722", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02722", "abs": "https://arxiv.org/abs/2510.02722", "authors": ["Junyu Shi", "Yong Sun", "Zhiyuan Zhang", "Lijiang Liu", "Zhengjie Zhang", "Yuxin He", "Qiang Nie"], "title": "MoGIC: Boosting Motion Generation via Intention Understanding and Visual Context", "comment": null, "summary": "Existing text-driven motion generation methods often treat synthesis as a\nbidirectional mapping between language and motion, but remain limited in\ncapturing the causal logic of action execution and the human intentions that\ndrive behavior. The absence of visual grounding further restricts precision and\npersonalization, as language alone cannot specify fine-grained spatiotemporal\ndetails. We propose MoGIC, a unified framework that integrates intention\nmodeling and visual priors into multimodal motion synthesis. By jointly\noptimizing multimodal-conditioned motion generation and intention prediction,\nMoGIC uncovers latent human goals, leverages visual priors to enhance\ngeneration, and exhibits versatile multimodal generative capability. We further\nintroduce a mixture-of-attention mechanism with adaptive scope to enable\neffective local alignment between conditional tokens and motion subsequences.\nTo support this paradigm, we curate Mo440H, a 440-hour benchmark from 21\nhigh-quality motion datasets. Experiments show that after finetuning, MoGIC\nreduces FID by 38.6\\% on HumanML3D and 34.6\\% on Mo440H, surpasses LLM-based\nmethods in motion captioning with a lightweight text head, and further enables\nintention prediction and vision-conditioned generation, advancing controllable\nmotion synthesis and intention understanding. The code is available at\nhttps://github.com/JunyuShi02/MoGIC", "AI": {"tldr": "本文提出MoGIC框架，通过整合意图建模和视觉先验，解决现有文本驱动动作生成中缺乏因果逻辑、人类意图和视觉基础的问题。MoGIC引入自适应范围的混合注意力机制，并发布Mo440H数据集，显著提升了动作生成精度、意图预测能力和多模态生成的多功能性。", "motivation": "现有文本驱动动作生成方法仅将合成视为语言与动作的双向映射，难以捕捉动作执行的因果逻辑和驱动行为的人类意图。此外，缺乏视觉基础限制了精度和个性化，因为仅凭语言无法指定精细的时空细节。", "method": "本文提出MoGIC统一框架，将意图建模和视觉先验整合到多模态动作合成中。通过联合优化多模态条件下的动作生成和意图预测，MoGIC揭示潜在的人类目标，利用视觉先验增强生成效果，并展现多功能的多模态生成能力。此外，引入了具有自适应范围的混合注意力机制，以实现条件令牌和动作子序列之间的有效局部对齐。为支持此范式，本文整理并发布了Mo440H数据集，一个包含21个高质量动作数据集的440小时基准。", "result": "实验表明，经过微调后，MoGIC在HumanML3D上将FID降低了38.6%，在Mo440H上降低了34.6%。它在动作描述方面超越了基于LLM的方法，且仅使用轻量级文本头。此外，MoGIC还实现了意图预测和视觉条件下的生成。", "conclusion": "MoGIC通过整合意图建模和视觉先验，显著推动了可控动作合成和意图理解的进步，并展示了多功能的多模态生成能力。"}}
{"id": "2510.02851", "categories": ["cs.RO", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.02851", "abs": "https://arxiv.org/abs/2510.02851", "authors": ["Jeyoung Park", "Yeonsub Lim", "Seungeun Oh", "Jihong Park", "Jinho Choi", "Seong-Lyun Kim"], "title": "Action Deviation-Aware Inference for Low-Latency Wireless Robots", "comment": null, "summary": "To support latency-sensitive AI applications ranging from autonomous driving\nto industrial robot manipulation, 6G envisions distributed ML, connecting\ndistributed computational resources in edge and cloud over hyper-reliable\nlow-latency communication (HRLLC). In this setting, speculative decoding can\nfacilitate collaborative inference of models distributively deployed: an\non-device draft model locally generates drafts and a remote server-based target\nmodel verifies and corrects them, resulting lower latency. However, unlike\nautoregressive text generation, behavior cloning policies, typically used for\nembodied AI applications like robot manipulation and autonomous driving, cannot\nparallelize verification and correction for multiple drafts as each action\ndepends on observation which needs to be updated by a previous action. To this\nend, we propose Action Deviation-Aware Hybrid Inference, wherein the draft\nmodel estimates an action's need for verification and correction by the target\nmodel and selectively skips communication and computation for server\noperations. Action deviation shows a strong correlation with action's rejection\nprobability by the target model, enabling selective skipping. We derive the\npath deviation threshold that balances the transmission rate and the inference\nperformance, and we empirically show that action deviation-aware hybrid\ninference reduces uplink transmission and server operation by 40%, while\nlowering end-to-end latency by 33.32% relative to hybrid inference without\nskipping and achieving task success rate up to 97.03% of that of target model\nonly inference.", "AI": {"tldr": "本文提出了一种名为“动作偏差感知混合推理”的方法，用于6G分布式ML中延迟敏感的具身AI应用。它通过草稿模型估计动作的验证需求，并选择性地跳过服务器操作，从而显著降低了上行传输、服务器计算和端到端延迟，同时保持了高任务成功率。", "motivation": "6G网络旨在通过超高可靠低延迟通信（HRLLC）连接边缘和云端的分布式计算资源，以支持自动驾驶和工业机器人操作等延迟敏感的AI应用。推测解码可以促进分布式模型的协作推理，通过本地草稿模型生成草稿并由远程服务器目标模型进行验证和纠正来降低延迟。然而，对于具身AI中常用的行为克隆策略，由于每个动作都依赖于前一个动作更新的观察结果，因此无法并行验证和纠正多个草稿，这限制了其在降低延迟和资源消耗方面的潜力。", "method": "本文提出了“动作偏差感知混合推理”（Action Deviation-Aware Hybrid Inference）。该方法的核心是让草稿模型估计某个动作被目标模型验证和纠正的必要性，并据此选择性地跳过服务器操作（通信和计算）。研究发现，动作偏差与目标模型拒绝动作的概率之间存在很强的相关性，这使得选择性跳过成为可能。此外，论文还推导了一个路径偏差阈值，用于平衡传输速率和推理性能。", "result": "实验结果表明，与不跳过的混合推理相比，动作偏差感知混合推理将上行传输和服务器操作减少了40%，将端到端延迟降低了33.32%。同时，它实现了高达目标模型独立推理97.03%的任务成功率。", "conclusion": "动作偏差感知混合推理通过智能地评估并选择性地跳过服务器操作，为6G环境下的分布式具身AI应用提供了一种高效的解决方案。该方法在显著降低资源消耗（上行传输和服务器操作）和端到端延迟的同时，能够保持接近于仅使用目标模型推理的高任务成功率，有效支持了延迟敏感的AI应用。"}}
{"id": "2510.02896", "categories": ["eess.SY", "cs.AI", "cs.SY", "37N35, 49N10"], "pdf": "https://arxiv.org/pdf/2510.02896", "abs": "https://arxiv.org/abs/2510.02896", "authors": ["Gabriel Diaz", "Lucky Li", "Wenhao Zhang"], "title": "Global Convergence of Policy Gradient for Entropy Regularized Linear-Quadratic Control with multiplicative noise", "comment": "33 pages, 4 figures", "summary": "Reinforcement Learning (RL) has emerged as a powerful framework for\nsequential decision-making in dynamic environments, particularly when system\nparameters are unknown. This paper investigates RL-based control for\nentropy-regularized Linear Quadratic control (LQC) problems with multiplicative\nnoises over an infinite time horizon. First, we adapt the Regularized Policy\nGradient (RPG) algorithm to stochastic optimal control settings, proving that\ndespite the non-convexity of the problem, RPG converges globally under\nconditions of gradient domination and near-smoothness. Second, based on\nzero-order optimization approach, we introduce a novel model free RL algorithm:\nSample-Based Regularized Policy Gradient (SB-RPG). SB-RPG operates without\nknowledge of system parameters yet still retains strong theoretical guarantees\nof global convergence. Our model leverages entropy regularization to accelerate\nconvergence and address the exploration versus exploitation trade-off inherent\nin RL. Numerical simulations validate the theoretical results and demonstrate\nthe efficacy of SB-RPG in unknown-parameters environments.", "AI": {"tldr": "本文研究了无限时间域上带乘性噪声的熵正则化线性二次控制（LQC）问题中的强化学习（RL）控制。提出了正则化策略梯度（RPG）算法，并在梯度支配和近光滑条件下证明了其全局收敛性。此外，引入了一种基于零阶优化的无模型RL算法：基于采样的正则化策略梯度（SB-RPG），即使在系统参数未知的情况下也能保证全局收敛性，并利用熵正则化加速收敛和平衡探索-利用。", "motivation": "强化学习（RL）在动态环境中进行序列决策，尤其是在系统参数未知时，已成为一个强大的框架。本文旨在将RL应用于无限时间域上带乘性噪声的熵正则化线性二次控制（LQC）问题，解决其非凸性和参数未知带来的挑战。", "method": "首先，将正则化策略梯度（RPG）算法应用于随机最优控制设置。其次，基于零阶优化方法，引入了一种新的无模型RL算法：基于采样的正则化策略梯度（SB-RPG）。两种方法都利用了熵正则化来加速收敛和解决探索与利用的权衡问题。", "result": "尽管问题非凸，RPG算法在梯度支配和近光滑条件下能全局收敛。SB-RPG算法在不知道系统参数的情况下，仍能保持强大的全局收敛理论保证。熵正则化有助于加速收敛并解决RL固有的探索与利用权衡问题。数值模拟验证了理论结果，并展示了SB-RPG在未知参数环境中的有效性。", "conclusion": "本文成功地将RPG和SB-RPG算法应用于带乘性噪声的熵正则化LQC问题。RPG和SB-RPG在理论上都保证了全局收敛性，即使在系统参数未知的情况下，SB-RPG也表现出强大的性能。熵正则化在加速收敛和处理探索-利用权衡方面发挥了关键作用，数值模拟进一步证实了这些发现。"}}
{"id": "2510.02338", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02338", "abs": "https://arxiv.org/abs/2510.02338", "authors": ["Samyak Jhaveri", "Praphul Singh", "Jangwon Kim", "Tara Taghavi", "Krishnaram Kenthapadi"], "title": "Optimizing Long-Form Clinical Text Generation with Claim-Based Rewards", "comment": null, "summary": "Automating clinical documentation with large language models requires precise\nalignment with priorities such as completeness and factual grounding. We\npresent an evaluation-integrated reinforcement learning framework for long-form\nclinical text generation that couples Group Relative Policy Optimization (GRPO)\nwith DocLens, a claim-level evaluator that provides deterministic,\ndialogue-grounded rewards. Our method directly optimizes factual grounding and\ncompleteness without training a separate reward model or relying on\nhuman-authored references. Empirically, the approach improves clinical note\nquality and reduces training cost via a simple reward-gating strategy. An\nindependent GPT-5 qualitative evaluation further supports these gains, showing\nhigher preference for GRPO outputs in factuality, completeness, and brevity,\nwith fewer omissions and hallucinations. Because the benchmarks are relatively\nclean and the base model already well aligned, these improvements likely\nrepresent a conservative lower bound. The framework is scalable to real-world\nsettings and can incorporate custom objectives such as guideline adherence or\nbilling preferences.", "AI": {"tldr": "本文提出了一种评估集成强化学习框架，结合GRPO和DocLens，用于长篇临床文本生成。该框架直接优化了事实准确性和完整性，无需单独的奖励模型或人工参考，显著提高了临床笔记质量并降低了训练成本。", "motivation": "自动化临床文档需要精确对齐完整性和事实准确性等关键优先级，这是使用大型语言模型生成临床文本面临的挑战。", "method": "研究人员开发了一个评估集成强化学习框架，将群组相对策略优化（GRPO）与DocLens（一个提供确定性、基于对话奖励的声明级评估器）相结合。该方法通过简单的奖励门控策略，直接优化事实准确性和完整性，而无需训练单独的奖励模型或依赖人工参考。", "result": "实验结果表明，该方法提高了临床笔记质量并降低了训练成本。独立的GPT-5定性评估进一步支持这些成果，显示GRPO的输出在事实准确性、完整性和简洁性方面更受偏好，且遗漏和幻觉更少。鉴于基准数据集相对干净且基础模型已良好对齐，这些改进可能代表一个保守的下限。", "conclusion": "该框架可扩展到实际应用场景，并能整合自定义目标，如指南依从性或计费偏好。它为自动化临床文档提供了有效且可扩展的解决方案。"}}
{"id": "2510.02677", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02677", "abs": "https://arxiv.org/abs/2510.02677", "authors": ["Zhaorun Chen", "Xun Liu", "Mintong Kang", "Jiawei Zhang", "Minzhou Pan", "Shuang Yang", "Bo Li"], "title": "ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks", "comment": "60 pages, 16 figures", "summary": "As vision-language models (VLMs) gain prominence, their multimodal interfaces\nalso introduce new safety vulnerabilities, making the safety evaluation\nchallenging and critical. Existing red-teaming efforts are either restricted to\na narrow set of adversarial patterns or depend heavily on manual engineering,\nlacking scalable exploration of emerging real-world VLM vulnerabilities. To\nbridge this gap, we propose ARMs, an adaptive red-teaming agent that\nsystematically conducts comprehensive risk assessments for VLMs. Given a target\nharmful behavior or risk definition, ARMs automatically optimizes diverse\nred-teaming strategies with reasoning-enhanced multi-step orchestration, to\neffectively elicit harmful outputs from target VLMs. We propose 11 novel\nmultimodal attack strategies, covering diverse adversarial patterns of VLMs\n(e.g., reasoning hijacking, contextual cloaking), and integrate 17 red-teaming\nalgorithms into ARMs via model context protocol (MCP). To balance the diversity\nand effectiveness of the attack, we design a layered memory with an\nepsilon-greedy attack exploration algorithm. Extensive experiments on instance-\nand policy-based benchmarks show that ARMs achieves SOTA attack success rates,\nexceeding baselines by an average of 52.1% and surpassing 90% on\nClaude-4-Sonnet. We show that the diversity of red-teaming instances generated\nby ARMs is significantly higher, revealing emerging vulnerabilities in VLMs.\nLeveraging ARMs, we construct ARMs-Bench, a large-scale multimodal safety\ndataset comprising over 30K red-teaming instances spanning 51 diverse risk\ncategories, grounded in both real-world multimodal threats and regulatory\nrisks. Safety fine-tuning with ARMs-Bench substantially improves the robustness\nof VLMs while preserving their general utility, providing actionable guidance\nto improve multimodal safety alignment against emerging threats.", "AI": {"tldr": "本文提出了ARMs，一个自适应红队代理，通过多样化的多模态攻击策略和推理增强的多步编排，系统地评估视觉语言模型（VLMs）的安全漏洞。ARMs在攻击成功率上超越现有技术，并构建了ARMs-Bench数据集，可用于提升VLMs的安全性。", "motivation": "随着视觉语言模型（VLMs）的普及，其多模态接口也引入了新的安全漏洞，使得安全评估变得具有挑战性且至关重要。现有的红队方法要么局限于狭窄的对抗模式，要么严重依赖手动工程，缺乏对新兴实际VLM漏洞的可扩展探索。", "method": "ARMs是一个自适应红队代理，给定目标有害行为或风险定义，它能自动优化多样化的红队策略，并通过推理增强的多步编排有效诱发目标VLM的有害输出。该方法提出了11种新颖的多模态攻击策略（如推理劫持、上下文伪装），并通过模型上下文协议（MCP）集成了17种红队算法。为平衡攻击的多样性和有效性，设计了分层记忆与epsilon-greedy攻击探索算法。此外，利用ARMs构建了ARMs-Bench，一个包含超过3万个红队实例的大规模多模态安全数据集，涵盖51种风险类别。", "result": "ARMs在实例和基于策略的基准测试中均取得了最先进的攻击成功率，平均比基线高出52.1%，在Claude-4-Sonnet上超过90%。ARMs生成的红队实例多样性显著更高，揭示了VLM中新兴的漏洞。使用ARMs-Bench进行安全微调能大幅提高VLM的鲁棒性，同时保持其通用性。", "conclusion": "ARMs能够系统性地进行全面的风险评估，有效揭示VLMs中的新兴漏洞。通过ARMs-Bench进行安全微调，为改进多模态安全对齐以应对新兴威胁提供了可行的指导。"}}
{"id": "2510.02732", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02732", "abs": "https://arxiv.org/abs/2510.02732", "authors": ["Jianing Chen", "Zehao Li", "Yujun Cai", "Hao Jiang", "Shuqin Gao", "Honglong Zhao", "Tianlu Mao", "Yucheng Zhang"], "title": "From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting", "comment": null, "summary": "Dynamic 3D reconstruction from monocular videos remains difficult due to the\nambiguity inferring 3D motion from limited views and computational demands of\nmodeling temporally varying scenes. While recent sparse control methods\nalleviate computation by reducing millions of Gaussians to thousands of control\npoints, they suffer from a critical limitation: they allocate points purely by\ngeometry, leading to static redundancy and dynamic insufficiency. We propose a\nmotion-adaptive framework that aligns control density with motion complexity.\nLeveraging semantic and motion priors from vision foundation models, we\nestablish patch-token-node correspondences and apply motion-adaptive\ncompression to concentrate control points in dynamic regions while suppressing\nredundancy in static backgrounds. Our approach achieves flexible\nrepresentational density adaptation through iterative voxelization and motion\ntendency scoring, directly addressing the fundamental mismatch between control\npoint allocation and motion complexity. To capture temporal evolution, we\nintroduce spline-based trajectory parameterization initialized by 2D tracklets,\nreplacing MLP-based deformation fields to achieve smoother motion\nrepresentation and more stable optimization. Extensive experiments demonstrate\nsignificant improvements in reconstruction quality and efficiency over existing\nstate-of-the-art methods.", "AI": {"tldr": "该论文提出了一种运动自适应框架，用于从单目视频进行动态3D重建。该框架通过将控制点密度与运动复杂性对齐，并引入基于样条的轨迹参数化，解决了现有稀疏控制方法的冗余和不足问题，从而提高了重建质量和效率。", "motivation": "从有限视角推断3D运动的歧义性以及建模时变场景的计算需求，使得从单目视频进行动态3D重建仍然十分困难。现有的稀疏控制方法虽然通过减少高斯点来降低计算量，但它们纯粹根据几何分配点，导致静态区域冗余和动态区域不足。", "method": "本文提出了一种运动自适应框架，使控制点密度与运动复杂性对齐。具体方法包括：1) 利用视觉基础模型的语义和运动先验，建立补丁-令牌-节点对应关系；2) 应用运动自适应压缩，将控制点集中在动态区域，同时抑制静态背景的冗余；3) 通过迭代体素化和运动趋势评分实现灵活的表示密度自适应；4) 引入基于样条的轨迹参数化（由2D轨迹初始化），取代基于MLP的变形场，以实现更平滑的运动表示和更稳定的优化。", "result": "广泛的实验表明，该方法在重建质量和效率方面显著优于现有最先进的方法。", "conclusion": "所提出的运动自适应框架通过解决控制点分配与运动复杂性之间的根本不匹配，并采用更平滑的运动表示，显著提高了动态3D重建的质量和效率。"}}
{"id": "2510.02874", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02874", "abs": "https://arxiv.org/abs/2510.02874", "authors": ["Charith Premachandra", "U-Xuan Tan"], "title": "Novel UWB Synthetic Aperture Radar Imaging for Mobile Robot Mapping", "comment": "Accepted and presented at the 15th International Conference on Indoor\n  Positioning and Indoor Navigation (IPIN) 2025, see\n  https://ipin-conference.org/2025/", "summary": "Traditional exteroceptive sensors in mobile robots, such as LiDARs and\ncameras often struggle to perceive the environment in poor visibility\nconditions. Recently, radar technologies, such as ultra-wideband (UWB) have\nemerged as potential alternatives due to their ability to see through adverse\nenvironmental conditions (e.g. dust, smoke and rain). However, due to the small\napertures with low directivity, the UWB radars cannot reconstruct a detailed\nimage of its field of view (FOV) using a single scan. Hence, a virtual large\naperture is synthesized by moving the radar along a mobile robot path. The\nresulting synthetic aperture radar (SAR) image is a high-definition\nrepresentation of the surrounding environment. Hence, this paper proposes a\npipeline for mobile robots to incorporate UWB radar-based SAR imaging to map an\nunknown environment. Finally, we evaluated the performance of classical feature\ndetectors: SIFT, SURF, BRISK, AKAZE and ORB to identify loop closures using UWB\nSAR images. The experiments were conducted emulating adverse environmental\nconditions. The results demonstrate the viability and effectiveness of UWB SAR\nimaging for high-resolution environmental mapping and loop closure detection\ntoward more robust and reliable robotic perception systems.", "AI": {"tldr": "本文提出了一种基于UWB合成孔径雷达（SAR）成像的移动机器人环境建图和回环检测方法，以实现在恶劣环境条件下的高分辨率感知。", "motivation": "传统机器人传感器（如激光雷达、相机）在低能见度条件下表现不佳。超宽带（UWB）雷达虽然能穿透恶劣环境，但单次扫描无法生成详细图像。因此，需要一种方法利用UWB雷达合成大孔径，生成高分辨率图像，以实现恶劣环境下的鲁棒环境感知和建图。", "method": "论文提出了一种移动机器人利用UWB雷达进行SAR成像以绘制未知环境的流程。随后，评估了SIFT、SURF、BRISK、AKAZE和ORB等经典特征检测器在UWB SAR图像中识别回环闭合的性能。实验在模拟恶劣环境条件下进行。", "result": "实验结果表明，UWB SAR成像对于高分辨率环境建图和回环检测是可行且有效的，有助于构建更鲁棒、更可靠的机器人感知系统。", "conclusion": "UWB SAR成像技术为移动机器人在恶劣环境下的高分辨率环境建图和回环检测提供了有效的解决方案，从而提升了机器人感知系统的鲁棒性和可靠性。"}}
{"id": "2510.02933", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.02933", "abs": "https://arxiv.org/abs/2510.02933", "authors": ["Austin J. Lin", "Jacques A. de Chalendar", "Johanna L. Mathieu"], "title": "Incomplete Air Mixing Reduces the Efficiency of Commercial Buildings Behaving as Virtual Batteries", "comment": null, "summary": "Commercial building Heating, Ventilation, and Air Conditioning (HVAC) systems\ncan provide flexibility to the electricity grid. Some researchers have found it\nconvenient to model HVAC systems as virtual batteries. These models also better\nalign with models used by grid planners and operators. However, experiments\nhave shown that HVAC load shifting can be inefficient, and virtual battery\nmodels do not capture this inefficiency well. While the models typically use\nthe average room temperature as the system's ``state of charge,\" they do not\ncapture other factors that affect HVAC power/energy such as airflow and mixing.\nHere, we develop a new analytical building model to explore how incomplete\nmixing of supply air into a conditioned space leads to inefficiency in a\nvirtual battery capturing the dynamics of HVAC fan power load shifting. The\nmodel qualitatively matches experimental results better than previous models,\nand shows that, as mixing becomes worse, the virtual battery becomes less\nefficient. Unfortunately, air mixing is unmeasured/unmeasurable. However, we\nshow that, by closing the loop around measurements of fan power, we can improve\nthe virtual battery's performance without the need for air mixing measurements.\nFor example, in one case, we show a roundtrip efficiency improvement from 0.75\nto 0.99.", "AI": {"tldr": "本研究开发了一种新的分析建筑模型，以解释HVAC系统作为虚拟电池时，送风混合不完全导致的效率低下问题。模型表明，混合越差，虚拟电池效率越低。通过对风扇功率测量进行闭环控制，可以在不测量空气混合的情况下显著提高虚拟电池的性能。", "motivation": "HVAC系统能为电网提供灵活性，并常被建模为虚拟电池。然而，实验表明HVAC负荷转移效率低下，而现有虚拟电池模型未能很好地捕捉这种低效率，特别是忽略了气流和混合等因素对HVAC功率/能量的影响。", "method": "开发了一种新的分析建筑模型，该模型探索了送风在调节空间中混合不完全如何导致HVAC风扇功率负荷转移的虚拟电池效率低下。此外，提出通过围绕风扇功率测量进行闭环控制来改进虚拟电池性能。", "result": "新模型在定性上比现有模型更好地匹配实验结果，并表明随着混合条件的恶化，虚拟电池的效率会降低。通过对风扇功率测量进行闭环控制，可以在不需要测量空气混合的情况下提高虚拟电池的性能，例如，在某个案例中，往返效率从0.75提高到0.99。", "conclusion": "HVAC系统作为虚拟电池时，送风混合不完全是导致效率低下的重要原因。新的分析模型能更好地描述这一现象。通过利用风扇功率测量进行闭环控制，可以在不依赖难以测量的空气混合数据的情况下，显著提升虚拟电池的效率和性能。"}}
{"id": "2510.02339", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02339", "abs": "https://arxiv.org/abs/2510.02339", "authors": ["Kevin Zhou", "Adam Dejl", "Gabriel Freedman", "Lihu Chen", "Antonio Rago", "Francesca Toni"], "title": "Evaluating Uncertainty Quantification Methods in Argumentative Large Language Models", "comment": "Accepted at EMNLP Findings 2025", "summary": "Research in uncertainty quantification (UQ) for large language models (LLMs)\nis increasingly important towards guaranteeing the reliability of this\ngroundbreaking technology. We explore the integration of LLM UQ methods in\nargumentative LLMs (ArgLLMs), an explainable LLM framework for decision-making\nbased on computational argumentation in which UQ plays a critical role. We\nconduct experiments to evaluate ArgLLMs' performance on claim verification\ntasks when using different LLM UQ methods, inherently performing an assessment\nof the UQ methods' effectiveness. Moreover, the experimental procedure itself\nis a novel way of evaluating the effectiveness of UQ methods, especially when\nintricate and potentially contentious statements are present. Our results\ndemonstrate that, despite its simplicity, direct prompting is an effective UQ\nstrategy in ArgLLMs, outperforming considerably more complex approaches.", "AI": {"tldr": "该研究探讨了大型语言模型（LLMs）的不确定性量化（UQ）方法在论证型LLMs（ArgLLMs）中的应用，并发现直接提示（direct prompting）是一种简单且有效的UQ策略，优于复杂方法。", "motivation": "为了确保LLMs这项突破性技术的可靠性，对LLMs进行不确定性量化（UQ）的研究变得日益重要，尤其是在依赖计算论证进行决策的ArgLLMs框架中，UQ扮演着关键角色。", "method": "研究将不同的LLM UQ方法整合到ArgLLMs中，并进行实验以评估其在主张验证任务上的性能。该实验过程本身也提供了一种评估UQ方法有效性的新颖方式。", "result": "实验结果表明，尽管直接提示（direct prompting）方法很简单，但它在ArgLLMs中是一种有效的UQ策略，其性能显著优于更复杂的方法。", "conclusion": "直接提示是一种在ArgLLMs中进行不确定性量化的有效策略，其简单性并未影响其性能，甚至超越了复杂的UQ方法，这对于提高LLMs的可靠性具有重要意义。"}}
{"id": "2510.02679", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02679", "abs": "https://arxiv.org/abs/2510.02679", "authors": ["Yu-Zhe Shi", "Qiao Xu", "Yanjia Li", "Mingchen Liu", "Huamin Qu", "Lecheng Ruan", "Qining Wang"], "title": "Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation", "comment": "Accepted for publication in IEEE Transactions on Automation Science\n  and Engineering", "summary": "Advanced Planning and Scheduling (APS) systems have become indispensable for\nmodern manufacturing operations, enabling optimized resource allocation and\nproduction efficiency in increasingly complex and dynamic environments. While\nalgorithms for solving abstracted scheduling problems have been extensively\ninvestigated, the critical prerequisite of specifying manufacturing\nrequirements into formal constraints remains manual and labor-intensive.\nAlthough recent advances of generative models, particularly Large Language\nModels (LLMs), show promise in automating constraint specification from\nheterogeneous raw manufacturing data, their direct application faces challenges\ndue to natural language ambiguity, non-deterministic outputs, and limited\ndomain-specific knowledge. This paper presents a constraint-centric\narchitecture that regulates LLMs to perform reliable automated constraint\nspecification for production scheduling. The architecture defines a\nhierarchical structural space organized across three levels, implemented\nthrough domain-specific representation to ensure precision and reliability\nwhile maintaining flexibility. Furthermore, an automated production scenario\nadaptation algorithm is designed and deployed to efficiently customize the\narchitecture for specific manufacturing configurations. Experimental results\ndemonstrate that the proposed approach successfully balances the generative\ncapabilities of LLMs with the reliability requirements of manufacturing\nsystems, significantly outperforming pure LLM-based approaches in constraint\nspecification tasks.", "AI": {"tldr": "本文提出了一种以约束为中心的架构，用于规范大型语言模型（LLM）以可靠地自动化生产调度中的约束规范，解决了传统LLM在制造领域应用的挑战。", "motivation": "现代制造中，高级计划与调度（APS）系统需要将制造需求转化为形式化约束，但这一过程目前仍是手动且劳动密集型的。尽管LLM在自动化约束规范方面显示出潜力，但其固有的自然语言歧义、非确定性输出和有限的领域知识限制了其直接应用。", "method": "研究提出了一种约束为中心的架构来规范LLM，以实现可靠的自动化约束规范。该架构定义了一个分层的结构空间，组织成三个级别，并通过领域特定的表示来实现精确性、可靠性和灵活性。此外，还设计并部署了一种自动化生产场景适应算法，以高效地为特定制造配置定制该架构。", "result": "实验结果表明，所提出的方法成功地平衡了LLM的生成能力与制造系统的可靠性要求，在约束规范任务中显著优于纯粹基于LLM的方法。", "conclusion": "该研究通过引入一个约束为中心的架构和场景适应算法，有效解决了LLM在自动化生产调度约束规范中的挑战，实现了LLM生成能力与工业可靠性要求的融合。"}}
{"id": "2510.02733", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02733", "abs": "https://arxiv.org/abs/2510.02733", "authors": ["Weimin Yuan", "Cai Meng"], "title": "Net2Net: When Un-trained Meets Pre-trained Networks for Robust Real-World Denoising", "comment": null, "summary": "Traditional denoising methods for noise removal have largely relied on\nhandcrafted priors, often perform well in controlled environments but struggle\nto address the complexity and variability of real noise. In contrast, deep\nlearning-based approaches have gained prominence for learning noise\ncharacteristics from large datasets, but these methods frequently require\nextensive labeled data and may not generalize effectively across diverse noise\ntypes and imaging conditions. In this paper, we present an innovative method,\ntermed as Net2Net, that combines the strengths of untrained and pre-trained\nnetworks to tackle the challenges of real-world noise removal. The innovation\nof Net2Net lies in its combination of unsupervised DIP and supervised\npre-trained model DRUNet by regularization by denoising (RED). The untrained\nnetwork adapts to the unique noise characteristics of each input image without\nrequiring labeled data, while the pre-trained network leverages learned\nrepresentations from large-scale datasets to deliver robust denoising\nperformance. This hybrid framework enhances generalization across varying noise\npatterns and improves performance, particularly in scenarios with limited\ntraining data. Extensive experiments on benchmark datasets demonstrate the\nsuperiority of our method for real-world noise removal.", "AI": {"tldr": "本文提出Net2Net方法，结合未训练网络（DIP）和预训练网络（DRUNet），通过去噪正则化（RED）解决真实世界噪声去除中的复杂性和泛化性问题，特别是在有限训练数据下表现优异。", "motivation": "传统去噪方法依赖手工先验，难以应对真实噪声的复杂性和可变性；深度学习方法虽能学习噪声特征，但通常需要大量标注数据，且在不同噪声类型和成像条件下泛化能力有限。", "method": "Net2Net方法结合了无监督的深度图像先验（DIP）和有监督的预训练模型DRUNet，通过去噪正则化（RED）实现。未训练网络DIP适应每张输入图像的独特噪声特征，无需标注数据；预训练网络DRUNet利用大规模数据集学习的表示提供鲁棒的去噪性能。", "result": "该混合框架增强了对不同噪声模式的泛化能力，并提高了性能，特别是在训练数据有限的情况下。在基准数据集上的大量实验证明了该方法在真实世界噪声去除方面的优越性。", "conclusion": "Net2Net通过结合未训练网络对特定图像噪声的自适应能力和预训练网络从大数据集中学习到的鲁棒知识，有效克服了真实世界噪声去除的挑战，实现了卓越的性能和泛化能力。"}}
{"id": "2510.02885", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02885", "abs": "https://arxiv.org/abs/2510.02885", "authors": ["Faduo Liang", "Yunfeng Yang", "Shi-Lu Dai"], "title": "Point Cloud-Based Control Barrier Functions for Model Predictive Control in Safety-Critical Navigation of Autonomous Mobile Robots", "comment": "8 pages, 8 figures, accepted to IROS2025", "summary": "In this work, we propose a novel motion planning algorithm to facilitate\nsafety-critical navigation for autonomous mobile robots. The proposed algorithm\nintegrates a real-time dynamic obstacle tracking and mapping system that\ncategorizes point clouds into dynamic and static components. For dynamic point\nclouds, the Kalman filter is employed to estimate and predict their motion\nstates. Based on these predictions, we extrapolate the future states of dynamic\npoint clouds, which are subsequently merged with static point clouds to\nconstruct the forward-time-domain (FTD) map. By combining control barrier\nfunctions (CBFs) with nonlinear model predictive control, the proposed\nalgorithm enables the robot to effectively avoid both static and dynamic\nobstacles. The CBF constraints are formulated based on risk points identified\nthrough collision detection between the predicted future states and the FTD\nmap. Experimental results from both simulated and real-world scenarios\ndemonstrate the efficacy of the proposed algorithm in complex environments. In\nsimulation experiments, the proposed algorithm is compared with two baseline\napproaches, showing superior performance in terms of safety and robustness in\nobstacle avoidance. The source code is released for the reference of the\nrobotics community.", "AI": {"tldr": "本文提出了一种新颖的运动规划算法，通过结合实时动态障碍物跟踪与映射系统（使用卡尔曼滤波器构建前向时间域地图）和基于控制障碍函数（CBFs）的非线性模型预测控制（NMPC），使自主移动机器人在复杂环境中能够安全有效地避开静态和动态障碍物。", "motivation": "为自主移动机器人提供安全关键的导航能力，尤其是在存在动态障碍物的复杂环境中。", "method": "该算法整合了实时动态障碍物跟踪与映射系统，将点云分为动态和静态部分。对动态点云，采用卡尔曼滤波器估计和预测其运动状态，并推断其未来状态。这些未来状态与静态点云合并构建前向时间域（FTD）地图。通过将控制障碍函数（CBFs）与非线性模型预测控制（NMPC）结合，并基于预测未来状态与FTD地图之间的碰撞检测识别风险点来制定CBF约束，实现避障。", "result": "实验结果（包括模拟和真实世界场景）表明，所提出的算法在复杂环境中具有高效性。在模拟实验中，该算法与两种基线方法相比，在避障的安全性与鲁棒性方面表现出卓越的性能。", "conclusion": "该算法能够有效地避免静态和动态障碍物，为自主移动机器人提供安全、鲁棒的导航能力。源代码已发布供机器人社区参考。"}}
{"id": "2510.02985", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.02985", "abs": "https://arxiv.org/abs/2510.02985", "authors": ["Kaidi Huang", "Lin Cheng", "Yue Zhou", "Fashun Shi", "Yufei Xi", "Yingrui Zhuang", "Ning Qi"], "title": "Real-Time Peer-to-Peer Energy Trading for Multi-Microgrids: Improved Double Auction Mechanism and Prediction-Free Online Trading Approach", "comment": null, "summary": "Peer-to-peer energy trading offers a promising solution for enhancing\nrenewable energy utilization and economic benefits within interconnected\nmicrogrids. However, existing real-time P2P markets face two key challenges:\nhigh computational complexity in trading mechanisms, and suboptimal participant\ndecision-making under diverse uncertainties. Existing prediction-based\ndecision-making methods rely heavily on accurate forecasts, which are typically\nunavailable for microgrids, while prediction-free methods suffer from myopic\nbehaviors. To address these challenges, this paper proposes an improved double\nauction mechanism combined with an adaptive step-size search algorithm to\nreduce computational burden, and a data-driven dual-reference online\noptimization (DDOO) framework to enhance participant decision-making. The\nimproved mechanism simplifies bidding procedures, significantly reducing\ncomputational burden and ensuring rapid convergence to the market equilibrium.\nAdditionally, the prediction-free DDOO framework mitigates myopic\ndecision-making by introducing two informative reference signals. Case studies\non a 20-microgrid system demonstrate the effectiveness and scalability of the\nproposed mechanism and approach. The improved mechanism significantly decreases\nthe computational time while increasing local energy self-sufficiency periods\nfrom 0.01% to 29.86%, reducing reverse power flow periods from 24.51% to 3.96%,\nand lowering average operating costs by 19.20%. Compared with conventional\napproaches such as Lyapunov optimization and model predictive control, the DDOO\nframework achieves a 10%-13% reduction in operating costs with an optimality\ngap of only 5.76%.", "AI": {"tldr": "本文提出了一种改进的双边拍卖机制和数据驱动双参考在线优化（DDOO）框架，以解决互联微电网P2P能源交易中计算复杂性和不确定性下参与者决策次优的问题，显著提高了能源自给自足率并降低了运营成本。", "motivation": "现有实时P2P能源市场面临两大挑战：交易机制的计算复杂度高，以及在不确定性下参与者决策次优。基于预测的方法高度依赖微电网通常难以获得的准确预测，而无预测方法则存在短视行为。", "method": "本文提出了一种改进的双边拍卖机制，结合自适应步长搜索算法以减少计算负担。同时，引入了数据驱动双参考在线优化（DDOO）框架，通过引入两个信息丰富的参考信号来缓解无预测决策的短视行为。", "result": "在20个微电网系统上的案例研究表明，改进机制显著缩短了计算时间，并将局部能源自给自足期从0.01%提高到29.86%，逆向潮流期从24.51%降低到3.96%，平均运营成本降低了19.20%。与Lyapunov优化和模型预测控制等传统方法相比，DDOO框架将运营成本降低了10%-13%，最优性差距仅为5.76%。", "conclusion": "所提出的改进机制和DDOO框架在互联微电网P2P能源交易中表现出有效性和可扩展性，能够有效降低计算负担，提高决策质量，并显著提升能源自给自足率和经济效益。"}}
{"id": "2510.02340", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02340", "abs": "https://arxiv.org/abs/2510.02340", "authors": ["Xin Gao", "Ruiyi Zhang", "Daniel Du", "Saurabh Mahindre", "Sai Ashish Somayajula", "Pengtao Xie"], "title": "Can Prompts Rewind Time for LLMs? Evaluating the Effectiveness of Prompted Knowledge Cutoffs", "comment": null, "summary": "Large Language Models (LLMs) are widely used for temporal prediction, but\ntheir reliance on pretraining data raises contamination concerns, as accurate\npredictions on pre-cutoff test data may reflect memorization rather than\nreasoning, leading to an overestimation of their generalization capability.\nWith the recent emergence of prompting-based unlearning techniques, a natural\nquestion arises: Can LLMs be prompted to simulate an earlier knowledge cutoff?\nIn this work, we investigate the capability of prompting to simulate earlier\nknowledge cutoff in LLMs. We construct three evaluation datasets to assess the\nextent to which LLMs can forget (1) direct factual knowledge, (2) semantic\nshifts, and (3) causally related knowledge. Results demonstrate that while\nprompt-based simulated knowledge cutoffs show effectiveness when directly\nqueried with the information after that date, they struggle to induce\nforgetting when the forgotten content is not directly asked but causally\nrelated to the query. These findings highlight the need for more rigorous\nevaluation settings when applying LLMs for temporal prediction tasks. The full\ndataset and evaluation code are available at\nhttps://github.com/gxx27/time_unlearn.", "AI": {"tldr": "本文研究了通过提示工程让大型语言模型（LLMs）模拟更早知识截止日期的能力，发现它在直接事实查询上有效，但在处理与被遗忘内容有因果关系而非直接询问的知识时表现不佳。", "motivation": "大型语言模型在时间预测中广泛应用，但其预训练数据可能导致“数据污染”（即模型是记忆而非推理），从而高估其泛化能力。随着基于提示的遗忘技术出现，研究者想知道LLMs是否能通过提示来模拟更早的知识截止日期，以解决这一问题。", "method": "研究通过构建三个评估数据集来调查提示模拟知识截止日期的能力。这些数据集用于评估LLMs遗忘以下三种知识的程度：1) 直接事实知识，2) 语义变化，以及 3) 因果相关知识。", "result": "结果表明，当直接查询截止日期之后的信息时，基于提示模拟的知识截止日期是有效的。然而，当被遗忘的内容不是直接被问及，而是与查询存在因果关系时，模型难以诱导遗忘。", "conclusion": "这些发现强调了在将LLMs应用于时间预测任务时，需要更严格的评估设置，因为基于提示的知识截止模拟在处理因果相关知识时存在局限性。"}}
{"id": "2510.02816", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02816", "abs": "https://arxiv.org/abs/2510.02816", "authors": ["Yulong Zhang", "Li Wang", "Wei Du", "Peilin Li", "Yuqin Dai Zhiyuan Zhao", "Lingyong Fang", "Ziniu Liu", "Ru Zhang", "Huijia Zhu", "Gongshen Liu"], "title": "NCV: A Node-Wise Consistency Verification Approach for Low-Cost Structured Error Localization in LLM Reasoning", "comment": null, "summary": "Verifying multi-step reasoning in large language models is difficult due to\nimprecise error localization and high token costs. Existing methods either\nassess entire reasoning chains, suffering attention dilution, or rely on\nexpensive multi-sampling. We introduce Node-wise Consistency Verification\n(NCV), a training-free framework that recasts verification as lightweight\nbinary consistency checks at the node level. By decomposing the chain of\nthought into interconnected verification nodes, NCV precisely localizes errors\nand avoids unnecessary long-form generation. Experiments demonstrate that our\napproach enhances interpretability and efficiency, presenting a scalable\nsolution for reliable LLM reasoning verification. On public datasets, NCV\nachieves a 10\\% to 25\\% improvement in F1 scores over baselines while utilizing\n$6\\times$~$58\\times$ fewer tokens than traditional methods like CoT-based\nverifiers.", "AI": {"tldr": "NCV是一个无需训练的框架，通过节点级二元一致性检查，有效验证大型语言模型的多步推理，显著提高F1分数并大幅降低token消耗。", "motivation": "验证大型语言模型（LLMs）的多步推理存在困难，主要原因是错误定位不精确和token成本高。现有方法要么评估整个推理链导致注意力分散，要么依赖昂贵的多重采样。", "method": "本文提出了节点级一致性验证（NCV）框架。NCV将验证重新定义为轻量级的节点级二元一致性检查，无需训练。它将思维链分解为相互连接的验证节点，从而精确地定位错误并避免不必要的长篇生成。", "result": "实验表明，NCV提高了可解释性和效率，为LLM推理验证提供了一个可扩展的解决方案。在公开数据集上，NCV的F1分数比基线方法提高了10%到25%，同时比传统的基于CoT的验证器减少了6到58倍的token使用。", "conclusion": "NCV通过其创新的节点级验证方法，为大型语言模型提供了一种可扩展且可靠的推理验证解决方案，显著提升了性能并降低了计算成本。"}}
{"id": "2510.02745", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02745", "abs": "https://arxiv.org/abs/2510.02745", "authors": ["Lanyun Zhu", "Deyi Ji", "Tianrun Chen", "Haiyang Wu", "Shiqi Wang"], "title": "Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval", "comment": "NeurIPS 2025", "summary": "The success of DeepSeek-R1 demonstrates the immense potential of using\nreinforcement learning (RL) to enhance LLMs' reasoning capabilities. This paper\nintroduces Retrv-R1, the first R1-style MLLM specifically designed for\nmultimodal universal retrieval, achieving higher performance by employing\nstep-by-step reasoning to produce more accurate retrieval results. We find that\ndirectly applying the methods of DeepSeek-R1 to retrieval tasks is not\nfeasible, mainly due to (1) the high computational cost caused by the large\ntoken consumption required for multiple candidates with reasoning processes,\nand (2) the instability and suboptimal results when directly applying RL to\ntrain for retrieval tasks. To address these issues, Retrv-R1 introduces an\ninformation compression module with a details inspection mechanism, which\nenhances computational efficiency by reducing the number of tokens while\nensuring that critical information for challenging candidates is preserved.\nFurthermore, a new training paradigm is proposed, including an activation stage\nusing a retrieval-tailored synthetic CoT dataset for more effective\noptimization, followed by RL with a novel curriculum reward to improve both\nperformance and efficiency. Incorporating these novel designs, Retrv-R1\nachieves SOTA performance, high efficiency, and strong generalization ability,\nas demonstrated by experiments across multiple benchmarks and tasks.", "AI": {"tldr": "本文介绍了Retrv-R1，一个首个R1风格的多模态大语言模型（MLLM），专为多模态通用检索设计。它通过引入信息压缩模块和新的训练范式（包括激活阶段和带有新颖课程奖励的强化学习），解决了DeepSeek-R1方法在检索任务中计算成本高和训练不稳定的问题，最终实现了SOTA性能、高效率和强泛化能力。", "motivation": "DeepSeek-R1展示了强化学习（RL）在增强LLM推理能力方面的巨大潜力。然而，研究发现直接将DeepSeek-R1的方法应用于检索任务是不可行的，主要原因有二：1) 多候选推理过程导致大量Token消耗，计算成本高昂；2) 直接将RL应用于检索任务时，训练不稳定且效果不佳。", "method": "Retrv-R1是一个R1风格的MLLM，通过逐步推理来提高检索准确性。它引入了一个信息压缩模块，并结合细节检查机制，在减少Token数量的同时保留关键信息，从而提高计算效率。此外，还提出了一个新的训练范式，包括：1) 使用专门为检索定制的合成CoT数据集进行激活阶段，以实现更有效的优化；2) 随后使用带有新颖课程奖励的强化学习（RL），以提高性能和效率。", "result": "Retrv-R1在多项基准测试和任务中展现出最先进（SOTA）的性能、高效率和强大的泛化能力。", "conclusion": "Retrv-R1通过引入创新的信息压缩模块和新颖的训练范式，成功地将R1风格的推理应用于多模态通用检索任务，克服了计算成本和训练稳定性的挑战，从而实现了卓越的性能和效率。"}}
{"id": "2510.02941", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02941", "abs": "https://arxiv.org/abs/2510.02941", "authors": ["Stefano Trepella", "Mauro Martini", "Noé Pérez-Higueras", "Andrea Ostuni", "Fernando Caballero", "Luis Merino", "Marcello Chiaberge"], "title": "Metrics vs Surveys: Can Quantitative Measures Replace Human Surveys in Social Robot Navigation? A Correlation Analysis", "comment": null, "summary": "Social, also called human-aware, navigation is a key challenge for the\nintegration of mobile robots into human environments. The evaluation of such\nsystems is complex, as factors such as comfort, safety, and legibility must be\nconsidered. Human-centered assessments, typically conducted through surveys,\nprovide reliable insights but are costly, resource-intensive, and difficult to\nreproduce or compare across systems. Alternatively, numerical social navigation\nmetrics are easy to compute and facilitate comparisons, yet the community lacks\nconsensus on a standard set of metrics.\n  This work explores the relationship between numerical metrics and\nhuman-centered evaluations to identify potential correlations. If specific\nquantitative measures align with human perceptions, they could serve as\nstandardized evaluation tools, reducing the dependency on surveys. Our results\nindicate that while current metrics capture some aspects of robot navigation\nbehavior, important subjective factors remain insufficiently represented and\nnew metrics are necessary.", "AI": {"tldr": "该研究探索了机器人社交导航的数值指标与以人为中心的评估之间的关系，发现现有指标未能充分代表重要的主观因素，需要开发新指标。", "motivation": "机器人社交导航系统的评估非常复杂，需要考虑舒适性、安全性等因素。以人为中心的评估（如调查）虽可靠但成本高、难复现。数值指标易于计算和比较，但缺乏行业共识。本研究旨在通过找出数值指标与人类感知之间的相关性，开发标准化的评估工具，减少对调查的依赖。", "method": "本研究探索了数值社交导航指标与以人为中心的评估之间的关系，旨在识别两者之间的潜在相关性。", "result": "研究结果表明，当前的数值指标能够捕捉机器人导航行为的某些方面，但重要的主观因素仍未得到充分体现。", "conclusion": "现有的数值社交导航指标不足以完全替代以人为中心的评估，需要开发新的指标来更好地代表人类对机器人社交导航的主观感知和体验。"}}
{"id": "2510.03043", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03043", "abs": "https://arxiv.org/abs/2510.03043", "authors": ["Xiaoqiao Chen", "Xuewen Zhang", "Minghao Han", "Adrian Wing-Keung Law", "Xunyuan Yin"], "title": "Economic zone data-enabled predictive control for connected open water systems", "comment": null, "summary": "Real-time regulation of water distribution in connected open water systems is\ncritical for ensuring system safety and meeting operational requirements. In\nthis work, we consider a connected open water system that includes linkage\nhydraulic structures such as weirs, pumps and sluice gates. We propose a\nmixed-integer economic zone data-enabled predictive control (DeePC) approach,\nwhich is used to maintain the water levels of the branches within desired zones\nto avoid floods and reduce the energy consumption of the pumps in the\nconsidered water system. The proposed DeePC-based approach predicts the future\ndynamics of the system water levels, and generates optimal control actions\nbased on system input and output data, thereby eliminating the need for both\nfirst-principles modeling and explicit data-driven modeling. To achieve\nmultiple control objectives in order of priority, we utilize lexicographic\noptimization and adapt traditional DeePC cost function for zone tracking and\nenergy consumption minimization. Additionally, Bayesian optimization is\nutilized to determine the control target zone, which effectively balances zone\ntracking and energy consumption in the presence of external disturbances.\nComprehensive simulations and comparative analyses demonstrate the\neffectiveness of the proposed method. The proposed method maintains water\nlevels within the desired zone for 97.04% of the operating time, with an\naverage energy consumption of 33.5 kWh per 0.5 h. Compared to baseline methods,\nthe proposed approach reduces the zone-tracking mean square error by 98.82%\nrelative to economic zone DeePC without Bayesian optimization, and lowers\nenergy consumption by 44.08% relative to economic set-point tracking DeePC. As\ncompared to passive pump/gate control, the proposed method lowers the frequency\nof zone violations by 86.94% and the average energy consumption by 4.69%.", "AI": {"tldr": "本文提出了一种混合整数经济区域数据驱动预测控制（DeePC）方法，结合词典式优化和贝叶斯优化，用于连接开放水系统中的实时水位区域跟踪和泵能耗最小化，无需显式模型，并在仿真中表现出卓越的性能。", "motivation": "确保连接开放水系统的系统安全和满足运行要求（如避免洪水和降低能耗）需要实时调节水分配，尤其是在包含堰、泵和闸门等水力结构的情况下。", "method": "提出了一种混合整数经济区域数据驱动预测控制（DeePC）方法。该方法利用系统输入输出数据预测未来系统水位动态并生成最优控制动作，无需一阶原理建模或显式数据驱动建模。为实现多重优先控制目标，采用了词典式优化并调整了DeePC成本函数以进行区域跟踪和能耗最小化。此外，利用贝叶斯优化确定控制目标区域，有效平衡区域跟踪和能耗。", "result": "所提方法在97.04%的运行时间内将水位维持在所需区域内，平均能耗为每0.5小时33.5 kWh。与没有贝叶斯优化的经济区域DeePC相比，区域跟踪均方误差降低了98.82%。与经济设定点跟踪DeePC相比，能耗降低了44.08%。与被动泵/闸门控制相比，区域违规频率降低了86.94%，平均能耗降低了4.69%。", "conclusion": "所提出的混合整数经济区域DeePC方法，结合词典式和贝叶斯优化，能有效且高效地在连接开放水系统中进行实时水位区域跟踪和能耗管理，显著优于现有基线方法。"}}
{"id": "2510.02341", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02341", "abs": "https://arxiv.org/abs/2510.02341", "authors": ["Yifan Wang", "Bolian Li", "Junlin Wu", "Zhaoxuan Tan", "Zheli Liu", "Ruqi Zhang", "Ananth Grama", "Qingkai Zeng"], "title": "DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning", "comment": null, "summary": "Real-world large language model deployments (e.g., conversational AI systems,\ncode generation assistants) naturally generate abundant implicit user\ndissatisfaction (DSAT) signals, as users iterate toward better answers through\nrefinements, corrections, and expressed preferences, while explicit\nsatisfaction (SAT) feedback is scarce. Existing preference learning approaches\nare poorly aligned with this data profile, as they rely on costly human\nannotations or assume plentiful positive responses. In this paper, we introduce\n\\textbf{DRIFT} (\\textbf{D}issatisfaction-\\textbf{R}efined \\textbf{I}terative\npre\\textbf{F}erence \\textbf{T}raining), which anchors training on real-world\nDSAT signals and samples positives dynamically from the evolving policy.\nEmpirically, DRIFT models trained on real-world \\textit{WildFeedback} datasets\nand synthetic \\textit{UltraFeedback} datasets achieve up to +6.23\\% (7B) /\n+7.61\\% (14B) on WildBench Task Score and up to +8.95\\% (7B) / +12.29\\% (14B)\non AlpacaEval2 win rate over base models, outperforming strong baseline methods\nsuch as iterative DPO and SPIN. At larger scales, the improvements are\nparticularly pronounced: 14B models trained with DRIFT surpass GPT-4o-mini on\nWildBench. Further analysis shows that DRIFT also preserves exploratory\ncapacity, yielding more diverse high-reward solutions rather than collapsing to\nnarrow subsets. Theoretically, we demonstrate that this design preserves\npreference margins and avoids the gradient degeneration. These results show\nthat DRIFT is an effective and scalable recipe for real-world post-training\nthat leverages the most abundant and informative signal. The code and data are\navailable at https://github.com/cacayaya/DRIFT.git.", "AI": {"tldr": "DRIFT是一种利用真实世界中丰富的隐式用户不满意信号来训练大型语言模型的方法，它在多个基准测试中表现优于现有方法，甚至在特定规模下超越了GPT-4o-mini。", "motivation": "在真实世界的大语言模型部署中，用户通过迭代、修正和偏好表达产生大量隐式不满意信号，而明确的满意度反馈却很稀缺。现有的偏好学习方法依赖昂贵的人工标注或假设存在大量积极响应，与这种数据分布不符。", "method": "本文提出了DRIFT（Dissatisfaction-Refined Iterative Preference Training），该方法以真实世界的不满意信号作为训练锚点，并从不断演进的模型策略中动态采样积极响应。理论上，该设计能保持偏好裕度并避免梯度退化。", "result": "DRIFT模型在真实世界的WildFeedback和合成的UltraFeedback数据集上训练后，在WildBench任务分数上取得了高达+6.23% (7B) / +7.61% (14B) 的提升，在AlpacaEval2胜率上取得了高达+8.95% (7B) / +12.29% (14B) 的提升，优于迭代DPO和SPIN等强基线方法。在大规模模型上，14B的DRIFT模型在WildBench上超越了GPT-4o-mini。此外，DRIFT还能保持模型的探索能力，生成更多样化的高奖励解决方案。", "conclusion": "DRIFT是一种有效且可扩展的真实世界大模型后训练方法，它充分利用了最丰富且信息量最大的隐式不满意信号。这些结果表明DRIFT是优化LLM性能的有效途径。"}}
{"id": "2510.02837", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02837", "abs": "https://arxiv.org/abs/2510.02837", "authors": ["Wonjoong Kim", "Sangwu Park", "Yeonjun In", "Sein Kim", "Dongha Lee", "Chanyoung Park"], "title": "Beyond the Final Answer: Evaluating the Reasoning Trajectories of Tool-Augmented Agents", "comment": "Preprint. Under Review", "summary": "Although recent tool-augmented benchmarks incorporate complex user requests\nand diverse tools, the evaluation methods for most of them remain limited to\nanswer matching. However, as the number of steps required to resolve a user\nrequest increases, a proper evaluation of an agent's performance must go beyond\nthe final answer to also assess the problem-solving trajectory, including\npreviously ignored aspects such as efficiency, hallucination, and adaptivity.\nThe most straightforward method for evaluating these aspects is to compare an\nagent's trajectory with the ground-truth trajectory, but this approach is\nfundamentally limited since annotating all valid ground-truth trajectories is\nprohibitively expensive. However, a simple LLM-based evaluator struggles to\nassess trajectories in detail without ground truth. To effectively evaluate the\nagents in this manner, we introduce TRACE, a framework for the\nmulti-dimensional evaluation of tool-augmented LLM agent performance. By\nincorporating an evidence bank, which accumulates knowledge gathered from\npreceding reasoning steps, TRACE enables a multi-faceted analysis and\nevaluation of an agent's reasoning trajectory effectively. To validate our\nframework, we develop a new meta-evaluation dataset by augmenting existing\nbenchmarks with diverse and flawed trajectories, each labeled with\nmulti-faceted performance scores. Our results confirm that TRACE accurately\nevaluates these complex behaviors in a scalable and cost-effective manner, even\nwith small open-source LLMs. Furthermore, we apply our method to evaluate the\ntrajectories that agents produce while solving tool-augmented tasks, presenting\npreviously unreported observations and their corresponding insights.", "AI": {"tldr": "本文提出TRACE框架，通过引入证据库实现对工具增强型LLM智能体推理轨迹的多维度评估，克服了现有评估方法仅限于最终答案匹配的局限性，并证明了其有效性和成本效益。", "motivation": "现有的工具增强型基准测试评估方法大多局限于答案匹配，无法评估智能体在多步骤任务中的效率、幻觉和适应性等问题解决轨迹方面。虽然轨迹对比是直接方法，但标注所有有效轨迹成本高昂，而简单的LLM评估器在缺乏真实轨迹的情况下难以进行详细评估。", "method": "本文提出TRACE框架，用于多维度评估工具增强型LLM智能体的性能。TRACE通过整合一个“证据库”（积累先前推理步骤中获得的知识），实现对智能体推理轨迹的多方面分析和评估。为验证该框架，作者构建了一个新的元评估数据集，通过增强现有基准测试，加入多样化且有缺陷的轨迹，并为每条轨迹标注多维度性能分数。", "result": "实验结果表明，TRACE能够准确、可扩展且经济高效地评估这些复杂行为，即使是使用小型开源LLM也能实现。此外，将TRACE应用于评估智能体在解决工具增强型任务时产生的轨迹，揭示了以前未曾报告的观察结果及其相应的见解。", "conclusion": "TRACE框架提供了一种有效、可扩展且经济高效的方法，用于对工具增强型LLM智能体的推理轨迹进行多维度评估，弥补了现有评估方法在评估复杂问题解决行为方面的不足。"}}
{"id": "2510.02750", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02750", "abs": "https://arxiv.org/abs/2510.02750", "authors": ["Lihua Zhou", "Mao Ye", "Shuaifeng Li", "Nianxin Li", "Jinlin Wu", "Xiatian Zhu", "Lei Deng", "Hongbin Liu", "Jiebo Luo", "Zhen Lei"], "title": "Bayesian Test-time Adaptation for Object Recognition and Detection with Vision-language Models", "comment": "Under Review", "summary": "Vision-language models (VLMs) such as CLIP and Grounding DINO have achieved\nremarkable success in object recognition and detection. However, their\nperformance often degrades under real-world distribution shifts. Test-time\nadaptation (TTA) aims to mitigate this issue by adapting models during\ninference. Existing methods either rely on computationally expensive\nbackpropagation, which hinders real-time deployment, or focus solely on\nlikelihood adaptation, which overlooks the critical role of the prior. Our\nprior work, Bayesian Class Adaptation (BCA), addressed these shortcomings for\nobject recognition by introducing a training-free framework that incorporates\nadaptive priors. Building upon this foundation, we now present Bayesian Class\nAdaptation plus (BCA+), a unified, training-free framework for TTA for both\nobject recognition and detection. BCA+ introduces a dynamic cache that\nadaptively stores and updates class embeddings, spatial scales (for detection),\nand, crucially, adaptive class priors derived from historical predictions. We\nformulate adaptation as a Bayesian inference problem, where final predictions\nare generated by fusing the initial VLM output with a cache-based prediction.\nThis cache-based prediction combines a dynamically updated likelihood\n(measuring feature and scale similarity) and a prior (reflecting the evolving\nclass distribution). This dual-adaptation mechanism, coupled with\nuncertainty-guided fusion, enables BCA+ to correct both the model's semantic\nunderstanding and its contextual confidence. As a training-free method\nrequiring no backpropagation, BCA+ is highly efficient. Extensive experiments\ndemonstrate that BCA+ achieves state-of-the-art performance on both recognition\nand detection benchmarks.", "AI": {"tldr": "BCA+是一个免训练的测试时自适应（TTA）框架，用于视觉-语言模型（VLMs）在目标识别和检测中，通过引入动态缓存和贝叶斯推断来适应似然和先验，以应对真实世界分布偏移。", "motivation": "视觉-语言模型（VLMs）在真实世界分布偏移下性能会下降。现有的测试时自适应（TTA）方法要么计算成本高昂（需要反向传播），要么只关注似然适应而忽略了先验的关键作用。", "method": "BCA+是一个统一的、免训练的TTA框架，适用于目标识别和检测。它引入了一个动态缓存，自适应地存储和更新类别嵌入、空间尺度（用于检测）以及从历史预测中导出的自适应类别先验。该方法将适应问题表述为贝叶斯推断，通过融合初始VLM输出和基于缓存的预测来生成最终预测。基于缓存的预测结合了动态更新的似然（衡量特征和尺度相似性）和反映演变类别分布的先验。这种双重适应机制，结合不确定性引导的融合，使BCA+能够修正模型的语义理解和上下文置信度，且无需反向传播。", "result": "BCA+在识别和检测基准测试中均实现了最先进的性能。作为一个免训练且无需反向传播的方法，它具有很高的效率。", "conclusion": "BCA+通过其免训练、贝叶斯推断方法，结合动态缓存和双重适应机制，有效解决了VLM在分布偏移下的性能下降问题，为目标识别和检测提供了一个高效且表现卓越的解决方案。"}}
{"id": "2510.02946", "categories": ["cs.RO", "cs.SY", "eess.SY", "93D25", "I.6.5; F.2.1"], "pdf": "https://arxiv.org/pdf/2510.02946", "abs": "https://arxiv.org/abs/2510.02946", "authors": ["Juraj Lieskovský", "Hijiri Akahane", "Aoto Osawa", "Jaroslav Bušek", "Ikuo Mizuuchi", "Tomáš Vyhlídal"], "title": "Single-Rod Brachiation Robot: Mechatronic Control Design and Validation of Prejump Phases", "comment": "11 pages, 13 figures, 1 table, Accepted 27 July 2025, Available\n  online 16 Sept 2025, Version of Record 28 Sept 2025", "summary": "A complete mechatronic design of a minimal configuration brachiation robot is\npresented. The robot consists of a single rigid rod with gripper mechanisms\nattached to both ends. The grippers are used to hang the robot on a horizontal\nbar on which it swings or rotates. The motion is imposed by repositioning the\nrobot's center of mass, which is performed using a crank-slide mechanism. Based\non a non-linear model, an optimal control strategy is proposed, for\nrepositioning the center of mass in a bang-bang manner. Consequently, utilizing\nthe concept of input-output linearization, a continuous control strategy is\nproposed that takes into account the limited torque of the crank-slide\nmechanism and its geometry. An increased attention is paid to energy\naccumulation towards the subsequent jump stage of the brachiation. These two\nstrategies are validated and compared in simulations. The continuous control\nstrategy is then also implemented within a low-cost STM32-based control system,\nand both the swing and rotation stages of the brachiation motion are\nexperimentally validated.", "AI": {"tldr": "本文提出并验证了一种最小配置臂式攀爬机器人的机电设计和控制策略，该机器人通过曲柄滑块机构调整重心实现摆动和旋转，并重点关注能量积累。", "motivation": "开发一种具有最小配置的臂式攀爬机器人，并为其设计有效的运动控制策略，特别是如何通过调整重心实现高效的摆动和旋转，并为后续跳跃阶段积累能量。", "method": "机器人采用单刚性杆和两端夹持器设计，通过曲柄滑块机构重置重心以驱动运动。基于非线性模型，提出了一种用于重心重置的bang-bang最优控制策略。随后，利用输入-输出线性化概念，提出了一种考虑曲柄滑块机构扭矩限制和几何形状的连续控制策略。两种策略均通过仿真验证和比较，其中连续控制策略还在基于STM32的低成本控制系统中进行了实现和实验验证，包括摆动和旋转阶段。", "result": "成功提出了一个完整的最小配置臂式攀爬机器人机电设计。两种控制策略（bang-bang最优和连续输入-输出线性化）都在仿真中得到验证和比较。连续控制策略在低成本STM32控制系统中成功实现，并在实验中验证了机器人的摆动和旋转运动阶段，同时关注了为后续跳跃阶段积累能量。", "conclusion": "所提出的最小配置臂式攀爬机器人设计及其两种控制策略（特别是连续控制策略）在仿真和实验中均得到有效验证，能够实现受控的摆动和旋转运动，并为未来的跳跃动作积累能量。"}}
{"id": "2510.03070", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03070", "abs": "https://arxiv.org/abs/2510.03070", "authors": ["Andreas Bouterakos", "Georgios Tzounas"], "title": "Eigenvalue Tracking of Large-Scale Systems Impacted by Time Delays", "comment": null, "summary": "The paper focuses on tracking eigenvalue trajectories in power system models\nwith time delays. We formulate a continuation-based approach that employs\nnumerical integration to follow eigenvalues as system parameters vary, in the\npresence of one or multiple delayed variables. The formulation preserves the\nsparsity of the delay differential-algebraic equation (DDAE) system model and\nallows treating the delay magnitude itself as a varying parameter with\nimplementation aspects discussed in detail. Accuracy is demonstrated on a\nmodified IEEE 39-bus system with distributed energy resources. Scalability is\ndiscussed using a realistic dynamic model of the Irish transmission network.", "AI": {"tldr": "本文提出了一种基于连续性方法的数值积分方法，用于跟踪含时延电力系统模型中随系统参数变化的特征值轨迹。", "motivation": "在电力系统模型中，时延的存在会影响系统稳定性。理解特征值轨迹如何随系统参数（包括时延本身）变化对于系统分析至关重要。", "method": "采用基于连续性的方法，通过数值积分来跟踪特征值，即使存在一个或多个延迟变量。该方法保留了延迟微分代数方程（DDAE）系统模型的稀疏性，并允许将时延大小本身作为可变参数处理。", "result": "该方法的准确性在修改后的IEEE 39节点系统（包含分布式能源）上得到了验证。使用爱尔兰输电网络的真实动态模型讨论了其可扩展性。", "conclusion": "所提出的方法能有效且准确地跟踪含时延电力系统中随参数变化的特征值轨迹，并具有良好的可扩展性，能够处理时延大小作为变化参数的情况。"}}
{"id": "2510.02343", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02343", "abs": "https://arxiv.org/abs/2510.02343", "authors": ["Aurélien Bück-Kaeffer", "Je Qin Chooi", "Dan Zhao", "Maximilian Puelma Touzel", "Kellin Pelrine", "Jean-François Godbout", "Reihaneh Rabbany", "Zachary Yang"], "title": "$\\texttt{BluePrint}$: A Social Media User Dataset for LLM Persona Evaluation and Training", "comment": "8 pages, 4 figures, 11 tables", "summary": "Large language models (LLMs) offer promising capabilities for simulating\nsocial media dynamics at scale, enabling studies that would be ethically or\nlogistically challenging with human subjects. However, the field lacks\nstandardized data resources for fine-tuning and evaluating LLMs as realistic\nsocial media agents. We address this gap by introducing SIMPACT, the\nSIMulation-oriented Persona and Action Capture Toolkit, a privacy respecting\nframework for constructing behaviorally-grounded social media datasets suitable\nfor training agent models. We formulate next-action prediction as a task for\ntraining and evaluating LLM-based agents and introduce metrics at both the\ncluster and population levels to assess behavioral fidelity and stylistic\nrealism. As a concrete implementation, we release BluePrint, a large-scale\ndataset built from public Bluesky data focused on political discourse.\nBluePrint clusters anonymized users into personas of aggregated behaviours,\ncapturing authentic engagement patterns while safeguarding privacy through\npseudonymization and removal of personally identifiable information. The\ndataset includes a sizable action set of 12 social media interaction types\n(likes, replies, reposts, etc.), each instance tied to the posting activity\npreceding it. This supports the development of agents that use\ncontext-dependence, not only in the language, but also in the interaction\nbehaviours of social media to model social media users. By standardizing data\nand evaluation protocols, SIMPACT provides a foundation for advancing rigorous,\nethically responsible social media simulations. BluePrint serves as both an\nevaluation benchmark for political discourse modeling and a template for\nbuilding domain specific datasets to study challenges such as misinformation\nand polarization.", "AI": {"tldr": "该研究引入了SIMPACT框架和BluePrint数据集，旨在为训练和评估模拟社交媒体行为的大型语言模型提供标准化的、保护隐私的数据资源，以实现更真实、合乎伦理的社交媒体模拟。", "motivation": "当前领域缺乏标准化数据资源来微调和评估大型语言模型作为真实的社交媒体代理，这阻碍了大规模模拟社交媒体动态的研究，尤其是在涉及人类受试者时面临伦理或后勤挑战。", "method": "研究提出了SIMPACT（SIMulation-oriented Persona and Action Capture Toolkit）框架，用于构建行为驱动的、保护隐私的社交媒体数据集。它将“下一动作预测”作为训练和评估LLM代理的任务，并引入了集群和群体层面的指标来评估行为保真度和风格真实性。作为具体实现，他们发布了BluePrint数据集，该数据集基于Bluesky的公共数据，侧重于政治话语，通过匿名化用户并聚合其行为来创建人物画像，同时通过假名化和移除个人身份信息来保护隐私。该数据集包含12种社交媒体交互类型，每种交互都与之前的发帖活动相关联。", "result": "研究成功推出了SIMPACT框架和BluePrint数据集。BluePrint是一个大规模数据集，包含匿名用户聚合的行为画像和12种社交媒体互动类型，支持开发能够利用语言和互动行为上下文依赖性的代理模型。SIMPACT通过标准化数据和评估协议，为严谨、负责任的社交媒体模拟奠定了基础。", "conclusion": "SIMPACT框架和BluePrint数据集为推进大规模、伦理负责的社交媒体模拟提供了重要基础。BluePrint不仅是政治话语建模的评估基准，也为构建特定领域数据集以研究错误信息和两极分化等挑战提供了模板，从而推动了大型语言模型在社交媒体代理模拟方面的发展。"}}
{"id": "2510.02840", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02840", "abs": "https://arxiv.org/abs/2510.02840", "authors": ["Antoine Maier", "Aude Maier", "Tom David"], "title": "Take Goodhart Seriously: Principled Limit on General-Purpose AI Optimization", "comment": "9 pages, 1 figure. Under review", "summary": "A common but rarely examined assumption in machine learning is that training\nyields models that actually satisfy their specified objective function. We call\nthis the Objective Satisfaction Assumption (OSA). Although deviations from OSA\nare acknowledged, their implications are overlooked. We argue, in a\nlearning-paradigm-agnostic framework, that OSA fails in realistic conditions:\napproximation, estimation, and optimization errors guarantee systematic\ndeviations from the intended objective, regardless of the quality of its\nspecification. Beyond these technical limitations, perfectly capturing and\ntranslating the developer's intent, such as alignment with human preferences,\ninto a formal objective is practically impossible, making misspecification\ninevitable. Building on recent mathematical results, absent a mathematical\ncharacterization of these gaps, they are indistinguishable from those that\ncollapse into Goodhart's law failure modes under strong optimization pressure.\nBecause the Goodhart breaking point cannot be located ex ante, a principled\nlimit on the optimization of General-Purpose AI systems is necessary. Absent\nsuch a limit, continued optimization is liable to push systems into predictable\nand irreversible loss of control.", "AI": {"tldr": "机器学习中模型实际满足其目标函数的假设（OSA）在现实条件下经常失效，导致系统偏离预期，并可能引发古德哈特定律失效，因此需要对通用AI系统的优化设定原则性限制。", "motivation": "质疑机器学习中普遍存在的“目标满足假设”（OSA），即训练出的模型能够真正满足其指定目标函数。作者认为这一假设在现实中很少被检验，其影响被忽视。", "method": "通过理论分析和概念框架，指出近似误差、估计误差和优化误差必然导致系统偏离预期目标。同时，强调将开发者意图（如人类偏好）完全转化为形式化目标几乎不可能，导致目标误设不可避免。引用近期数学成果，指出这些差距在数学上与古德哈特定律失效模式难以区分。", "result": "OSA在现实条件下（包括技术限制和意图捕获困难）必然失效。由于这些差距在强优化压力下与古德哈特定律失效模式无法区分，且无法预先确定古德哈特失效点，因此持续优化通用AI系统可能导致系统可预测且不可逆的失控。", "conclusion": "鉴于OSA的失效和古德哈特定律失效的风险，对通用AI系统的优化设定一个原则性的限制是必要的，以避免系统失控。"}}
{"id": "2510.02760", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02760", "abs": "https://arxiv.org/abs/2510.02760", "authors": ["Matthias Perkonigg", "Patrick Rockenschaub", "Georg Göbel", "Adelheid Wöhrer"], "title": "Hierarchical Generalized Category Discovery for Brain Tumor Classification in Digital Pathology", "comment": null, "summary": "Accurate brain tumor classification is critical for intra-operative decision\nmaking in neuro-oncological surgery. However, existing approaches are\nrestricted to a fixed set of predefined classes and are therefore unable to\ncapture patterns of tumor types not available during training. Unsupervised\nlearning can extract general-purpose features, but it lacks the ability to\nincorporate prior knowledge from labelled data, and semi-supervised methods\noften assume that all potential classes are represented in the labelled data.\nGeneralized Category Discovery (GCD) aims to bridge this gap by categorizing\nboth known and unknown classes within unlabelled data. To reflect the\nhierarchical structure of brain tumor taxonomies, in this work, we introduce\nHierarchical Generalized Category Discovery for Brain Tumor Classification\n(HGCD-BT), a novel approach that integrates hierarchical clustering with\ncontrastive learning. Our method extends contrastive learning based GCD by\nincorporating a novel semi-supervised hierarchical clustering loss. We evaluate\nHGCD-BT on OpenSRH, a dataset of stimulated Raman histology brain tumor images,\nachieving a +28% improvement in accuracy over state-of-the-art GCD methods for\npatch-level classification, particularly in identifying previously unseen tumor\ncategories. Furthermore, we demonstrate the generalizability of HGCD-BT on\nslide-level classification of hematoxylin and eosin stained whole-slide images\nfrom the Digital Brain Tumor Atlas, confirming its utility across imaging\nmodalities.", "AI": {"tldr": "本文提出了一种名为HGCD-BT的新方法，将层次聚类与对比学习相结合，用于脑肿瘤分类中的分层广义类别发现，显著提高了对已知和未知肿瘤类别的识别准确性，尤其是在发现未见过的肿瘤类别方面。", "motivation": "现有的脑肿瘤分类方法受限于预定义类别，无法识别训练中未出现的肿瘤类型。无监督学习缺乏结合先验知识的能力，而半监督方法常假设所有潜在类别都已在标注数据中存在。为了弥补这一鸿沟，能够对未标注数据中的已知和未知类别进行分类，并反映脑肿瘤分类学中的分层结构是至关重要的。", "method": "本文引入了HGCD-BT（Hierarchical Generalized Category Discovery for Brain Tumor Classification），这是一种新颖的方法，它将层次聚类与对比学习相结合。该方法通过引入一种新颖的半监督层次聚类损失，扩展了基于对比学习的广义类别发现（GCD）方法。", "result": "HGCD-BT在OpenSRH数据集（刺激拉曼组织学脑肿瘤图像）上，在补丁级别分类方面，比最先进的GCD方法准确率提高了28%，尤其是在识别以前未见过的肿瘤类别方面表现突出。此外，HGCD-BT在Digital Brain Tumor Atlas的苏木精和伊红染色全玻片图像的玻片级别分类中也展示了其泛化能力，证实了其跨成像模态的实用性。", "conclusion": "HGCD-BT是一种有效且具有泛化能力的脑肿瘤分类方法，能够发现已知和未知肿瘤类别，并能处理脑肿瘤分类学中的层次结构，对术中决策具有重要意义，并适用于不同的成像模式。"}}
{"id": "2510.02968", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02968", "abs": "https://arxiv.org/abs/2510.02968", "authors": ["Amir Habel", "Fawad Mehboob", "Jeffrin Sam", "Clement Fortin", "Dzmitry Tsetserukou"], "title": "YawSitter: Modeling and Controlling a Tail-Sitter UAV with Enhanced Yaw Control", "comment": null, "summary": "Achieving precise lateral motion modeling and decoupled control in hover\nremains a significant challenge for tail-sitter Unmanned Aerial Vehicles\n(UAVs), primarily due to complex aerodynamic couplings and the absence of\nwelldefined lateral dynamics. This paper presents a novel modeling and control\nstrategy that enhances yaw authority and lateral motion by introducing a\nsideslip force model derived from differential propeller slipstream effects\nacting on the fuselage under differential thrust. The resulting lateral force\nalong the body y-axis enables yaw-based lateral position control without\ninducing roll coupling. The control framework employs a YXZ Euler rotation\nformulation to accurately represent attitude and incorporate gravitational\ncomponents while directly controlling yaw in the yaxis, thereby improving\nlateral dynamic behavior and avoiding singularities. The proposed approach is\nvalidated through trajectory-tracking simulations conducted in a Unity-based\nenvironment. Tests on both rectangular and circular paths in hover mode\ndemonstrate stable performance, with low mean absolute position errors and yaw\ndeviations constrained within 5.688 degrees. These results confirm the\neffectiveness of the proposed lateral force generation model and provide a\nfoundation for the development of agile, hover-capable tail-sitter UAVs.", "AI": {"tldr": "本文提出了一种新型建模和控制策略，通过差分螺旋桨滑流效应在机身上产生侧向力，实现了倾转翼无人机在悬停状态下基于偏航的横向位置解耦控制，并在模拟中验证了其有效性。", "motivation": "倾转翼无人机在悬停状态下实现精确的横向运动建模和解耦控制面临重大挑战，主要原因是复杂的空气动力学耦合和缺乏明确的横向动力学模型。", "method": "引入了基于差分螺旋桨滑流效应作用于机身而产生的侧滑力模型，该模型在差分推力下沿机身y轴产生横向力，从而实现基于偏航的横向位置控制，且不引起滚转耦合。控制框架采用YXZ欧拉旋转公式来精确表示姿态并包含重力分量，同时直接控制y轴的偏航，以改善横向动态行为并避免奇点。该方法通过基于Unity环境的轨迹跟踪模拟进行验证。", "result": "在悬停模式下的矩形和圆形路径测试中，系统表现出稳定的性能，具有较低的平均绝对位置误差，且偏航偏差被限制在5.688度以内。", "conclusion": "所提出的横向力生成模型是有效的，并为开发敏捷、具备悬停能力的倾转翼无人机奠定了基础。"}}
{"id": "2510.03100", "categories": ["eess.SY", "cs.RO", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.03100", "abs": "https://arxiv.org/abs/2510.03100", "authors": ["Tianhua Gao"], "title": "A Dimension-Decomposed Learning Framework for Online Disturbance Identification in Quadrotor SE(3) Control", "comment": null, "summary": "Quadrotor stability under complex dynamic disturbances and model\nuncertainties poses significant challenges. One of them remains the\nunderfitting problem in high-dimensional features, which limits the\nidentification capability of current learning-based methods. To address this,\nwe introduce a new perspective: Dimension-Decomposed Learning (DiD-L), from\nwhich we develop the Sliced Adaptive-Neuro Mapping (SANM) approach for\ngeometric control. Specifically, the high-dimensional mapping for\nidentification is axially ``sliced\" into multiple low-dimensional submappings\n(``slices\"). In this way, the complex high-dimensional problem is decomposed\ninto a set of simple low-dimensional tasks addressed by shallow neural networks\nand adaptive laws. These neural networks and adaptive laws are updated online\nvia Lyapunov-based adaptation without any pre-training or persistent excitation\n(PE) condition. To enhance the interpretability of the proposed approach, we\nprove that the full-state closed-loop system exhibits arbitrarily close to\nexponential stability despite multi-dimensional time-varying disturbances and\nmodel uncertainties. This result is novel as it demonstrates exponential\nconvergence without requiring pre-training for unknown disturbances and\nspecific knowledge of the model.", "AI": {"tldr": "本文针对四旋翼飞行器在复杂动态扰动和模型不确定性下的稳定性问题，提出了维度分解学习（DiD-L）框架下的切片自适应神经映射（SANM）方法。该方法将高维映射分解为多个低维子映射，通过浅层神经网络和自适应律在线更新，无需预训练或PE条件，实现了闭环系统的指数稳定性。", "motivation": "四旋翼飞行器在复杂动态扰动和模型不确定性下稳定性面临挑战，尤其是现有基于学习的方法在处理高维特征时存在欠拟合问题，限制了其识别能力。", "method": "引入维度分解学习（DiD-L）新视角，并开发了切片自适应神经映射（SANM）方法用于几何控制。具体地，将高维映射轴向“切片”成多个低维子映射（“切片”），通过浅层神经网络和自适应律在线更新，这些更新基于Lyapunov自适应，无需任何预训练或持续激励（PE）条件。", "result": "证明了全状态闭环系统在多维时变扰动和模型不确定性下，仍能展现出任意接近指数的稳定性。这一结果是新颖的，因为它在不需要针对未知扰动进行预训练或特定模型知识的情况下，实现了指数收敛。", "conclusion": "DiD-L框架下的SANM方法有效解决了四旋翼飞行器控制中高维特征的欠拟合问题。它通过维度分解和在线自适应学习，在无需预训练或特定模型知识的情况下，实现了在复杂动态扰动和模型不确定性下的任意接近指数的闭环系统稳定性，并增强了解释性。"}}
{"id": "2510.02345", "categories": ["cs.CL", "cs.AI", "cs.DC", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.02345", "abs": "https://arxiv.org/abs/2510.02345", "authors": ["Peijun Zhu", "Ning Yang", "Jiayu Wei", "Jinghang Wu", "Haijun Zhang"], "title": "Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression", "comment": "12 pages, 2 figures, 3 tables. Under review as a conference paper at\n  ICLR 2026", "summary": "Mixture-of-Experts (MoE) Large Language Models (LLMs) face a trilemma of load\nimbalance, parameter redundancy, and communication overhead. We introduce a\nunified framework based on dynamic expert clustering and structured compression\nto address these issues cohesively. Our method employs an online clustering\nprocedure that periodically regroups experts using a fused metric of parameter\nand activation similarity, which stabilizes expert utilization. To our\nknowledge, this is one of the first frameworks to leverage the semantic\nembedding capability of the router to dynamically reconfigure the model's\narchitecture during training for substantial efficiency gains. Within each\ncluster, we decompose expert weights into a shared base matrix and extremely\nlow-rank residual adapters, achieving up to fivefold parameter reduction per\ngroup while preserving specialization. This structure enables a two-stage\nhierarchical routing strategy: tokens are first assigned to a cluster, then to\nspecific experts within it, drastically reducing the routing search space and\nthe volume of all-to-all communication. Furthermore, a heterogeneous precision\nscheme, which stores shared bases in FP16 and residual factors in INT4, coupled\nwith dynamic offloading of inactive clusters, reduces peak memory consumption\nto levels comparable to dense models. Evaluated on GLUE and WikiText-103, our\nframework matches the quality of standard MoE models while reducing total\nparameters by approximately 80%, improving throughput by 10% to 20%, and\nlowering expert load variance by a factor of over three. Our work demonstrates\nthat structural reorganization is a principled path toward scalable, efficient,\nand memory-effective MoE LLMs.", "AI": {"tldr": "本文提出了一种基于动态专家聚类和结构化压缩的统一框架，以解决MoE LLM中的负载不平衡、参数冗余和通信开销问题，在保持模型质量的同时显著提高了效率、降低了内存消耗并减少了参数量。", "motivation": "Mixture-of-Experts (MoE) 大型语言模型面临负载不平衡、参数冗余和通信开销的“三难困境”。", "method": "该方法包括：1) 动态专家聚类：采用在线聚类过程，利用参数和激活相似性的融合度量周期性地重新分组专家，并利用路由器的语义嵌入能力动态重新配置模型架构。2) 结构化压缩：在每个聚类内，将专家权重分解为共享基础矩阵和极低秩残差适配器。3) 分层路由：令牌首先分配给聚类，然后分配给聚类内的特定专家，以减少路由搜索空间和通信量。4) 异构精度方案：共享基础以FP16存储，残差因子以INT4存储。5) 动态卸载：卸载不活跃的专家聚类以减少峰值内存消耗。", "result": "该框架在GLUE和WikiText-103上匹配了标准MoE模型的质量，同时将总参数减少了约80%，吞吐量提高了10%到20%，专家负载方差降低了三倍以上，并将峰值内存消耗降低到与密集模型相当的水平，并实现了每个组高达五倍的参数减少。", "conclusion": "结构重组是实现可扩展、高效和内存有效的MoE LLM的原则性途径。"}}
{"id": "2510.02850", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02850", "abs": "https://arxiv.org/abs/2510.02850", "authors": ["Xinle Wu", "Yao Lu"], "title": "Reward Model Routing in Alignment", "comment": null, "summary": "Reinforcement learning from human or AI feedback (RLHF / RLAIF) has become\nthe standard paradigm for aligning large language models (LLMs). However, most\npipelines rely on a single reward model (RM), limiting alignment quality and\nrisking overfitting. Recent work explores RM routing--dynamically selecting an\nRM from a candidate pool to exploit complementary strengths while maintaining\n$O(1)$ RM calls--but existing methods suffer from cold-start and insufficient\nexploration. We propose BayesianRouter, a hybrid routing framework that\ncombines offline RM strengths learning with online Bayesian selection. In the\noffline stage, a multi-task router is trained on preference data to estimate\nper-RM reliability. In the online stage, a Bayesian Thompson sampling router\nperforms per-query RM selection, initializing RM-specific weight vectors with\noffline embeddings as Gaussian priors and adaptively updating their posteriors\nwith online rewards to adapt to the evolving policy distribution. Extensive\nexperiments on instruction-following (AlpacaEval-2, Arena-Hard, MT-Bench) and\nreasoning (GSM8K, MMLU) benchmarks show that BayesianRouter consistently\noutperforms individual RMs, RM ensembling, and existing routing methods.", "AI": {"tldr": "该论文提出BayesianRouter，一个混合路由框架，通过结合离线学习的奖励模型（RM）可靠性与在线贝叶斯选择，解决了RLHF/RLAIF中单一RM的局限性及现有RM路由方法的冷启动和探索不足问题，显著提升了大型语言模型（LLM）的对齐质量。", "motivation": "RLHF/RLAIF范式中，单一奖励模型（RM）限制了对齐质量并存在过拟合风险。虽然RM路由能动态选择RM以利用互补优势，但现有方法存在冷启动和探索不足的问题。", "method": "BayesianRouter是一个混合路由框架，包括两个阶段：\n1. 离线阶段：训练一个多任务路由器，利用偏好数据估计每个RM的可靠性。\n2. 在线阶段：一个贝叶斯汤普森采样路由器执行每查询RM选择，使用离线嵌入作为高斯先验初始化RM特定权重向量，并根据在线奖励自适应更新其后验分布，以适应不断演变的策略分布。", "result": "在指令遵循（AlpacaEval-2, Arena-Hard, MT-Bench）和推理（GSM8K, MMLU）基准测试上，BayesianRouter始终优于单个RM、RM集成以及现有的路由方法。", "conclusion": "BayesianRouter通过其混合路由框架，有效地解决了现有奖励模型路由的局限性，提供了一种更鲁棒、自适应的RM选择机制，从而显著提高了大型语言模型的对齐质量。"}}
{"id": "2510.02778", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02778", "abs": "https://arxiv.org/abs/2510.02778", "authors": ["Xian Zhang", "Zexi Wu", "Zinuo Li", "Hongming Xu", "Luqi Gong", "Farid Boussaid", "Naoufel Werghi", "Mohammed Bennamoun"], "title": "AdaRD-key: Adaptive Relevance-Diversity Keyframe Sampling for Long-form Video understanding", "comment": null, "summary": "Understanding long-form videos remains a significant challenge for\nvision--language models (VLMs) due to their extensive temporal length and high\ninformation density. Most current multimodal large language models (MLLMs) rely\non uniform sampling, which often overlooks critical moments, leading to\nincorrect responses to queries. In parallel, many keyframe selection approaches\nimpose rigid temporal spacing: once a frame is chosen, an exclusion window\nsuppresses adjacent timestamps to reduce redundancy. While effective at\nlimiting overlap, this strategy frequently misses short, fine-grained cues near\nimportant events. Other methods instead emphasize visual diversity but neglect\nquery relevance. We propose AdaRD-Key, a training-free keyframe sampling module\nfor query-driven long-form video understanding. AdaRD-Key maximizes a unified\nRelevance--Diversity Max-Volume (RD-MV) objective, combining a\nquery-conditioned relevance score with a log-determinant diversity component to\nyield informative yet non-redundant frames. To handle broad queries with weak\nalignment to the video, AdaRD-Key employs a lightweight relevance-aware gating\nmechanism; when the relevance distribution indicates weak alignment, the method\nseamlessly shifts into a diversity-only mode, enhancing coverage without\nadditional supervision. Our pipeline is training-free, computationally\nefficient (running in real time on a single GPU), and compatible with existing\nVLMs in a plug-and-play manner. Extensive experiments on LongVideoBench and\nVideo-MME demonstrate state-of-the-art performance, particularly on long-form\nvideos. Code available at https://github.com/Xian867/AdaRD-Key.", "AI": {"tldr": "AdaRD-Key是一个免训练的关键帧采样模块，通过统一的“相关性-多样性最大体积”目标和相关性感知门控机制，解决了长视频理解中现有采样方法不足的问题，实现了最先进的性能。", "motivation": "现有视觉-语言模型（VLMs）难以理解长视频，因为其时间跨度长、信息密度高。当前的采样方法，如均匀采样、刚性时间间隔或仅关注视觉多样性，常常忽略关键时刻或查询相关性，导致对查询的响应不准确。", "method": "本文提出了AdaRD-Key，一个免训练的、用于查询驱动的长视频理解的关键帧采样模块。它通过最大化统一的“相关性-多样性最大体积”（RD-MV）目标来工作，该目标结合了查询条件的相关性得分和对数行列式多样性分量。对于与视频对齐较弱的广泛查询，AdaRD-Key采用轻量级的相关性感知门控机制，无缝切换到仅多样性模式，以增强覆盖范围。", "result": "AdaRD-Key在LongVideoBench和Video-MME数据集上展现了最先进的性能，尤其在长视频理解方面表现出色。该方法免训练、计算高效（在单个GPU上实时运行），并能以即插即用的方式与现有VLMs兼容。", "conclusion": "AdaRD-Key通过创新的相关性-多样性平衡采样策略，有效克服了长视频理解的挑战，显著提升了VLMs在处理长视频查询时的准确性和效率，且无需额外训练。"}}
{"id": "2510.02975", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02975", "abs": "https://arxiv.org/abs/2510.02975", "authors": ["Amir Hossein Barjini", "Jouni Mattila"], "title": "AI-Enhanced Kinematic Modeling of Flexible Manipulators Using Multi-IMU Sensor Fusion", "comment": null, "summary": "This paper presents a novel framework for estimating the position and\norientation of flexible manipulators undergoing vertical motion using multiple\ninertial measurement units (IMUs), optimized and calibrated with ground truth\ndata. The flexible links are modeled as a series of rigid segments, with joint\nangles estimated from accelerometer and gyroscope measurements acquired by\ncost-effective IMUs. A complementary filter is employed to fuse the\nmeasurements, with its parameters optimized through particle swarm optimization\n(PSO) to mitigate noise and delay. To further improve estimation accuracy,\nresidual errors in position and orientation are compensated using radial basis\nfunction neural networks (RBFNN). Experimental results validate the\neffectiveness of the proposed intelligent multi-IMU kinematic estimation\nmethod, achieving root mean square errors (RMSE) of 0.00021~m, 0.00041~m, and\n0.00024~rad for $y$, $z$, and $\\theta$, respectively.", "AI": {"tldr": "本文提出了一种使用多个惯性测量单元（IMU）估计柔性机械臂在垂直运动中位置和姿态的新颖框架，并通过粒子群优化（PSO）和径向基函数神经网络（RBFNN）进行优化和校准。", "motivation": "柔性机械臂在垂直运动中的位置和姿态估计是一个具有挑战性的问题，需要高精度和鲁棒性。", "method": "该方法将柔性连杆建模为一系列刚性段，并使用多个IMU的加速度计和陀螺仪数据估计关节角度。采用互补滤波器融合测量值，并通过粒子群优化（PSO）优化其参数以降低噪声和延迟。此外，利用径向基函数神经网络（RBFNN）补偿位置和姿态的残余误差，以进一步提高估计精度。", "result": "实验结果验证了所提出的智能多IMU运动学估计方法的有效性，在y、z和θ方向上分别达到了0.00021米、0.00041米和0.00024弧度的均方根误差（RMSE）。", "conclusion": "该研究提出的智能多IMU运动学估计方法能够有效且高精度地估计柔性机械臂在垂直运动中的位置和姿态。"}}
{"id": "2510.02347", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02347", "abs": "https://arxiv.org/abs/2510.02347", "authors": ["Konstantinos Katharakis", "Sippo Rossi", "Raghava Rao Mukkamala"], "title": "Small Language Models for Curriculum-based Guidance", "comment": null, "summary": "The adoption of generative AI and large language models (LLMs) in education\nis still emerging. In this study, we explore the development and evaluation of\nAI teaching assistants that provide curriculum-based guidance using a\nretrieval-augmented generation (RAG) pipeline applied to selected open-source\nsmall language models (SLMs). We benchmarked eight SLMs, including LLaMA 3.1,\nIBM Granite 3.3, and Gemma 3 (7-17B parameters), against GPT-4o. Our findings\nshow that with proper prompting and targeted retrieval, SLMs can match LLMs in\ndelivering accurate, pedagogically aligned responses. Importantly, SLMs offer\nsignificant sustainability benefits due to their lower computational and energy\nrequirements, enabling real-time use on consumer-grade hardware without\ndepending on cloud infrastructure. This makes them not only cost-effective and\nprivacy-preserving but also environmentally responsible, positioning them as\nviable AI teaching assistants for educational institutions aiming to scale\npersonalized learning in a sustainable and energy-efficient manner.", "AI": {"tldr": "本研究开发并评估了基于检索增强生成（RAG）和小型语言模型（SLMs）的AI助教，发现通过适当的提示和检索，SLMs在提供准确、符合教学法的回复方面可与大型语言模型（LLMs）媲美，并具有显著的可持续性优势。", "motivation": "生成式AI和大型语言模型（LLMs）在教育领域的应用尚处于新兴阶段，需要探索如何开发能提供基于课程指导的AI助教。", "method": "研究开发并评估了使用检索增强生成（RAG）管道应用于选定开源小型语言模型（SLMs）的AI助教。基准测试了包括LLaMA 3.1、IBM Granite 3.3和Gemma 3在内的八种SLMs（7-17B参数），并与GPT-4o进行了对比。", "result": "研究发现，通过适当的提示和有针对性的检索，SLMs在提供准确、符合教学法的回复方面可以与LLMs匹敌。重要的是，SLMs由于较低的计算和能源需求，提供了显著的可持续性优势，能够在消费级硬件上实时使用，不依赖云基础设施。", "conclusion": "SLMs是可行、经济高效、保护隐私且环保的AI助教，适用于教育机构以可持续和节能的方式扩展个性化学习。"}}
{"id": "2510.02880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02880", "abs": "https://arxiv.org/abs/2510.02880", "authors": ["Tianren Ma", "Mu Zhang", "Yibing Wang", "Qixiang Ye"], "title": "Consolidating Reinforcement Learning for Multimodal Discrete Diffusion Models", "comment": "Project Page: https://github.com/martian422/MaskGRPO", "summary": "Optimizing discrete diffusion model (DDM) with rewards remains a challenge:\nthe non-autoregressive paradigm makes importance sampling intractable and\nrollout complex, puzzling reinforcement learning methods such as Group Relative\nPolicy Optimization (GRPO). In this study, we introduce MaskGRPO, the first\nviable approach to enable scalable multimodal reinforcement learning in\ndiscrete diffusion with effective importance sampling and modality-specific\nadaptations. To this end, we first clarify the theoretical foundation for DDMs,\nwhich facilitates building an importance estimator that captures valuable token\nfluctuation for gradient updates. We then delicately tailored the rollout\nmethod for visual sequences, which yields diverse completions and reliable\noptimization gradients. Upon math reasoning, coding, and visual generation\nbenchmarks, MaskGRPO brings more stable and efficient updates, leading to\nstronger reasoning performance and better generation quality. This study\nestablishes MaskGRPO as a systematic policy optimization approach and the first\npractical way for discretized visual diffusion.", "AI": {"tldr": "MaskGRPO是首个可行的方法，通过有效的重要性采样和模态特定适应，实现了离散扩散模型中可扩展的多模态强化学习，解决了现有方法优化离散扩散模型奖励的挑战。", "motivation": "将奖励优化应用于离散扩散模型（DDM）面临挑战：非自回归范式使得重要性采样难以处理，且rollout过程复杂，这使得Group Relative Policy Optimization (GRPO) 等强化学习方法难以应用。", "method": "本研究引入了MaskGRPO，该方法首先澄清了DDM的理论基础，以构建能够捕获有价值token波动的梯度更新重要性估计器。其次，为视觉序列精心设计了rollout方法，以产生多样化的完成和可靠的优化梯度。此外，MaskGRPO还进行了模态特定的适应。", "result": "在数学推理、编码和视觉生成基准测试中，MaskGRPO带来了更稳定、更高效的更新，从而实现了更强的推理性能和更好的生成质量。", "conclusion": "MaskGRPO被确立为一种系统的策略优化方法，也是离散视觉扩散模型的首个实用方法。"}}
{"id": "2510.02780", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02780", "abs": "https://arxiv.org/abs/2510.02780", "authors": ["Prahitha Movva"], "title": "Reasoning Riddles: How Explainability Reveals Cognitive Limits in Vision-Language Models", "comment": null, "summary": "Vision-Language Models (VLMs) excel at many multimodal tasks, yet their\ncognitive processes remain opaque on complex lateral thinking challenges like\nrebus puzzles. While recent work has demonstrated these models struggle\nsignificantly with rebus puzzle solving, the underlying reasoning processes and\nfailure patterns remain largely unexplored. We address this gap through a\ncomprehensive explainability analysis that moves beyond performance metrics to\nunderstand how VLMs approach these complex lateral thinking challenges. Our\nstudy contributes a systematically annotated dataset of 221 rebus puzzles\nacross six cognitive categories, paired with an evaluation framework that\nseparates reasoning quality from answer correctness. We investigate three\nprompting strategies designed to elicit different types of explanatory\nprocesses and reveal critical insights into VLM cognitive processes. Our\nfindings demonstrate that reasoning quality varies dramatically across puzzle\ncategories, with models showing systematic strengths in visual composition\nwhile exhibiting fundamental limitations in absence interpretation and cultural\nsymbolism. We also discover that prompting strategy substantially influences\nboth cognitive approach and problem-solving effectiveness, establishing\nexplainability as an integral component of model performance rather than a\npost-hoc consideration.", "AI": {"tldr": "该研究通过解释性分析，探讨了视觉语言模型（VLMs）在解决字谜（rebus puzzles）等复杂横向思维挑战时的认知过程和失败模式。研究发现VLMs在不同字谜类别上的推理质量差异显著，并揭示了提示策略对模型认知方法和解决问题有效性的重要影响。", "motivation": "视觉语言模型（VLMs）在许多多模态任务中表现出色，但在字谜等复杂横向思维挑战中，其认知过程仍不透明。尽管现有研究表明这些模型在解决字谜方面存在显著困难，但其潜在的推理过程和失败模式在很大程度上仍未被探索。", "method": "该研究通过全面的解释性分析来填补这一空白。具体方法包括：1) 构建了一个包含221个字谜的系统注释数据集，涵盖六个认知类别；2) 建立了一个评估框架，将推理质量与答案正确性分开；3) 调查了三种旨在引发不同解释过程的提示策略。", "result": "研究发现：1) 推理质量在不同字谜类别之间差异巨大；2) 模型在视觉构成方面表现出系统性优势；3) 模型在缺失解释和文化象征方面表现出根本性局限；4) 提示策略显著影响模型的认知方法和问题解决有效性；5) 解释性是模型性能不可或缺的组成部分，而非事后考虑。", "conclusion": "VLMs在处理字谜等横向思维挑战时，其推理质量因谜题类别而异，在视觉构成上表现出优势，但在缺失解释和文化象征上存在局限。此外，提示策略对模型的认知过程和性能具有显著影响，表明解释性是理解和提升VLM表现的关键因素。"}}
{"id": "2510.02976", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02976", "abs": "https://arxiv.org/abs/2510.02976", "authors": ["Alvaro Paz", "Pauli Mustalahti", "Mohammad Dastranj", "Jouni Mattila"], "title": "Real-Time Nonlinear Model Predictive Control of Heavy-Duty Skid-Steered Mobile Platform for Trajectory Tracking Tasks", "comment": null, "summary": "This paper presents a framework for real-time optimal controlling of a\nheavy-duty skid-steered mobile platform for trajectory tracking. The importance\nof accurate real-time performance of the controller lies in safety\nconsiderations of situations where the dynamic system under control is affected\nby uncertainties and disturbances, and the controller should compensate for\nsuch phenomena in order to provide stable performance. A multiple-shooting\nnonlinear model-predictive control framework is proposed in this paper. This\nframework benefits from suitable algorithm along with readings from various\nsensors for genuine real-time performance with extremely high accuracy. The\ncontroller is then tested for tracking different trajectories where it\ndemonstrates highly desirable performance in terms of both speed and accuracy.\nThis controller shows remarkable improvement when compared to existing\nnonlinear model-predictive controllers in the literature that were implemented\non skid-steered mobile platforms.", "AI": {"tldr": "本文提出了一种基于多重射击非线性模型预测控制（NMPC）框架，用于重型滑移转向移动平台轨迹跟踪的实时最优控制，并在速度和精度方面表现出显著改进。", "motivation": "在存在不确定性和干扰的动态系统中，为了确保系统稳定和安全，需要控制器能够实时、准确地补偿这些现象。", "method": "提出了一种多重射击非线性模型预测控制（NMPC）框架，结合合适的算法和多传感器数据，以实现高精度的实时性能。", "result": "该控制器在跟踪不同轨迹时表现出高度理想的速度和精度性能，与现有文献中用于滑移转向移动平台的非线性模型预测控制器相比，显示出显著改进。", "conclusion": "所提出的多重射击NMPC框架能够为重型滑移转向移动平台提供高效、高精度的实时最优轨迹跟踪控制，显著优于现有方法。"}}
{"id": "2510.02348", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02348", "abs": "https://arxiv.org/abs/2510.02348", "authors": ["Guy Dar"], "title": "mini-vec2vec: Scaling Universal Geometry Alignment with Linear Transformations", "comment": null, "summary": "We build upon vec2vec, a procedure designed to align text embedding spaces\nwithout parallel data. vec2vec finds a near-perfect alignment, but it is\nexpensive and unstable. We present mini-vec2vec, a simple and efficient\nalternative that requires substantially lower computational cost and is highly\nrobust. Moreover, the learned mapping is a linear transformation. Our method\nconsists of three main stages: a tentative matching of pseudo-parallel\nembedding vectors, transformation fitting, and iterative refinement. Our linear\nalternative exceeds the original instantiation of vec2vec by orders of\nmagnitude in efficiency, while matching or exceeding their results. The\nmethod's stability and interpretable algorithmic steps facilitate scaling and\nunlock new opportunities for adoption in new domains and fields.", "AI": {"tldr": "Mini-vec2vec是一种用于对齐文本嵌入空间的简单、高效、鲁棒的线性方法，它在不使用并行数据的情况下，显著降低了计算成本，并且在效率上远超vec2vec，同时保持或超越了其性能。", "motivation": "vec2vec虽然能在没有并行数据的情况下对齐文本嵌入空间，但其过程昂贵且不稳定。", "method": "Mini-vec2vec采用三阶段方法：伪并行嵌入向量的初步匹配、变换拟合和迭代细化。学习到的映射是一个线性变换。", "result": "Mini-vec2vec在效率上比原始vec2vec快几个数量级，计算成本显著降低，且高度鲁棒，同时匹配或超越了vec2vec的结果。", "conclusion": "Mini-vec2vec的稳定性及其可解释的算法步骤有助于扩展，并在新领域和新应用中提供新的采用机会。"}}
{"id": "2510.02996", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02996", "abs": "https://arxiv.org/abs/2510.02996", "authors": ["Martina Mattioli", "Eike Petersen", "Aasa Feragen", "Marcello Pelillo", "Siavash A. Bigdeli"], "title": "Onto-Epistemological Analysis of AI Explanations", "comment": null, "summary": "Artificial intelligence (AI) is being applied in almost every field. At the\nsame time, the currently dominant deep learning methods are fundamentally\nblack-box systems that lack explanations for their inferences, significantly\nlimiting their trustworthiness and adoption. Explainable AI (XAI) methods aim\nto overcome this challenge by providing explanations of the models' decision\nprocess. Such methods are often proposed and developed by engineers and\nscientists with a predominantly technical background and incorporate their\nassumptions about the existence, validity, and explanatory utility of different\nconceivable explanatory mechanisms. However, the basic concept of an\nexplanation -- what it is, whether we can know it, whether it is absolute or\nrelative -- is far from trivial and has been the subject of deep philosophical\ndebate for millennia. As we point out here, the assumptions incorporated into\ndifferent XAI methods are not harmless and have important consequences for the\nvalidity and interpretation of AI explanations in different domains. We\ninvestigate ontological and epistemological assumptions in explainability\nmethods when they are applied to AI systems, meaning the assumptions we make\nabout the existence of explanations and our ability to gain knowledge about\nthose explanations. Our analysis shows how seemingly small technical changes to\nan XAI method may correspond to important differences in the underlying\nassumptions about explanations. We furthermore highlight the risks of ignoring\nthe underlying onto-epistemological paradigm when choosing an XAI method for a\ngiven application, and we discuss how to select and adapt appropriate XAI\nmethods for different domains of application.", "AI": {"tldr": "本文探讨了可解释人工智能（XAI）方法中存在的本体论和认识论假设，指出这些假设并非无害，并强调了在选择和应用XAI方法时考虑这些深层哲学范式的重要性。", "motivation": "当前深度学习方法是“黑盒”系统，缺乏解释性，严重限制了其可信度和应用。XAI旨在提供解释，但其开发往往由技术背景的工程师主导，可能忽视了关于“解释”这一基本概念的深刻哲学辩论及其隐含的本体论和认识论假设。", "method": "本文通过调查XAI方法在应用于AI系统时的本体论和认识论假设，即关于解释的存在性以及我们获取这些解释知识的能力的假设，来分析这些方法的内在机制和影响。", "result": "分析表明，XAI方法中看似微小的技术变化可能对应着关于解释的底层假设的重大差异。忽视底层的本体-认识论范式在为特定应用选择XAI方法时会带来风险。", "conclusion": "强调了在为特定应用选择和调整XAI方法时，必须充分考虑其潜在的本体论和认识论假设，以确保解释的有效性和恰当性。"}}
{"id": "2510.02787", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02787", "abs": "https://arxiv.org/abs/2510.02787", "authors": ["Jan Zdenek", "Wataru Shimoda", "Kota Yamaguchi"], "title": "OTR: Synthesizing Overlay Text Dataset for Text Removal", "comment": "This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution. The definitive Version of Record was\n  published in Proceedings of the 33rd ACM International Conference on\n  Multimedia (MM '25), October 27-31, 2025, Dublin, Ireland,\n  https://doi.org/10.1145/3746027.3758297", "summary": "Text removal is a crucial task in computer vision with applications such as\nprivacy preservation, image editing, and media reuse. While existing research\nhas primarily focused on scene text removal in natural images, limitations in\ncurrent datasets hinder out-of-domain generalization or accurate evaluation. In\nparticular, widely used benchmarks such as SCUT-EnsText suffer from ground\ntruth artifacts due to manual editing, overly simplistic text backgrounds, and\nevaluation metrics that do not capture the quality of generated results. To\naddress these issues, we introduce an approach to synthesizing a text removal\nbenchmark applicable to domains other than scene texts. Our dataset features\ntext rendered on complex backgrounds using object-aware placement and\nvision-language model-generated content, ensuring clean ground truth and\nchallenging text removal scenarios. The dataset is available at\nhttps://huggingface.co/datasets/cyberagent/OTR .", "AI": {"tldr": "本文介绍了一种新的文本移除基准数据集OTR，旨在解决现有数据集存在的真实标签伪影、背景过于简单和评估指标不足等问题，该数据集具有复杂的背景和干净的真实标签，适用于域外泛化。", "motivation": "现有场景文本移除数据集（如SCUT-EnsText）存在真实标签伪影、文本背景过于简单以及评估指标无法准确捕捉生成结果质量的问题，这些限制阻碍了模型的域外泛化能力和准确评估，因此需要一个新的、更具挑战性且适用范围更广的基准。", "method": "作者提出了一种合成文本移除基准的方法。该方法通过使用“对象感知放置”（object-aware placement）和“视觉-语言模型生成内容”（vision-language model-generated content），在复杂背景上渲染文本，以确保生成干净的真实标签和具有挑战性的文本移除场景。", "result": "本文的主要成果是引入了一个新的文本移除基准数据集OTR，该数据集解决了现有数据集的局限性，具有复杂背景和干净的真实标签，适用于场景文本以外的领域，并已公开发布。", "conclusion": "该论文通过引入OTR数据集，成功提供了一个新的、高质量的文本移除基准，克服了现有数据集的不足，为文本移除任务的域外泛化和准确评估提供了更好的支持。"}}
{"id": "2510.03011", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03011", "abs": "https://arxiv.org/abs/2510.03011", "authors": ["Chenyuan Chen", "Haoran Ding", "Ran Ding", "Tianyu Liu", "Zewen He", "Anqing Duan", "Dezhen Song", "Xiaodan Liang", "Yoshihiko Nakamura"], "title": "3D-CovDiffusion: 3D-Aware Diffusion Policy for Coverage Path Planning", "comment": null, "summary": "Diffusion models, as a class of deep generative models, have recently emerged\nas powerful tools for robot skills by enabling stable training with reliable\nconvergence. In this paper, we present an end-to-end framework for generating\nlong, smooth trajectories that explicitly target high surface coverage across\nvarious industrial tasks, including polishing, robotic painting, and spray\ncoating. The conventional methods are always fundamentally constrained by their\npredefined functional forms, which limit the shapes of the trajectories they\ncan represent and make it difficult to handle complex and diverse tasks.\nMoreover, their generalization is poor, often requiring manual redesign or\nextensive parameter tuning when applied to new scenarios. These limitations\nhighlight the need for more expressive generative models, making\ndiffusion-based approaches a compelling choice for trajectory generation. By\niteratively denoising trajectories with carefully learned noise schedules and\nconditioning mechanisms, diffusion models not only ensure smooth and consistent\nmotion but also flexibly adapt to the task context. In experiments, our method\nimproves trajectory continuity, maintains high coverage, and generalizes to\nunseen shapes, paving the way for unified end-to-end trajectory learning across\nindustrial surface-processing tasks without category-specific models. On\naverage, our approach improves Point-wise Chamfer Distance by 98.2\\% and\nsmoothness by 97.0\\%, while increasing surface coverage by 61\\% compared to\nprior methods. The link to our code can be found\n\\href{https://anonymous.4open.science/r/spraydiffusion_ral-2FCE/README.md}{here}.", "AI": {"tldr": "本文提出了一种基于扩散模型的端到端框架，用于生成工业表面处理任务（如抛光、喷漆）中具有高表面覆盖率和流畅性的长轨迹，克服了传统方法的局限性并提高了泛化能力。", "motivation": "传统方法受限于预定义函数形式，难以表示复杂轨迹形状，难以处理多样化任务，且泛化性差，在新场景中常需手动重新设计或大量参数调整。这些限制促使研究人员寻求更具表达力的生成模型，使基于扩散的方法成为轨迹生成的有力选择。", "method": "该研究提出了一个端到端的扩散模型框架，通过迭代去噪轨迹并结合精心学习的噪声调度和条件机制，生成长且平滑的轨迹。该方法明确以高表面覆盖率为目标，并能灵活适应任务上下文。", "result": "实验结果表明，该方法显著提高了轨迹的连续性，保持了高覆盖率，并能泛化到未见过的形状。与现有方法相比，点式倒角距离平均提高了98.2%，平滑度提高了97.0%，表面覆盖率增加了61%。这为工业表面处理任务的统一端到端轨迹学习铺平了道路，无需特定类别的模型。", "conclusion": "扩散模型为机器人技能提供了强大的工具，通过迭代去噪和条件机制，能够生成长而平滑且具有高表面覆盖率的轨迹。该方法在工业表面处理任务中表现出卓越的性能和泛化能力，有望实现统一的端到端轨迹学习。"}}
{"id": "2510.02350", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02350", "abs": "https://arxiv.org/abs/2510.02350", "authors": ["Dzmitry Pihulski", "Karol Charchut", "Viktoria Novogrodskaia", "Jan Kocoń"], "title": "LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL", "comment": "To appear in the Proceedings of the IEEE International Conference on\n  Data Mining Workshops (ICDMW)", "summary": "Converting natural language questions into SQL queries (Text-to-SQL) enables\nnon-expert users to interact with relational databases and has long been a\ncentral task for natural language interfaces to data. While the WikiSQL dataset\nplayed a key role in early NL2SQL research, its usage has declined due to\nstructural and annotation issues, including case sensitivity inconsistencies,\ndata type mismatches, syntax errors, and unanswered questions. We present\nLLMSQL, a systematic revision and transformation of WikiSQL designed for the\nLLM era. We classify these errors and implement automated methods for cleaning\nand re-annotation. To assess the impact of these improvements, we evaluated\nmultiple large language models (LLMs), including Gemma 3, LLaMA 3.2, Mistral\n7B, gpt-oss 20B, Phi-3.5 Mini, Qwen 2.5, OpenAI o4-mini, DeepSeek R1 and\nothers. Rather than serving as an update, LLMSQL is introduced as an LLM-ready\nbenchmark: unlike the original WikiSQL, tailored for pointer-network models\nselecting tokens from input, LLMSQL provides clean natural language questions\nand full SQL queries as plain text, enabling straightforward generation and\nevaluation for modern natural language-to-SQL models.", "AI": {"tldr": "本文介绍了LLMSQL，一个对WikiSQL数据集进行系统性修订和转换的新基准，旨在解决原始WikiSQL的结构和标注问题，并使其适用于现代大型语言模型（LLMs）的Text-to-SQL任务。", "motivation": "将自然语言问题转换为SQL查询（Text-to-SQL）是实现非专业用户与关系数据库交互的核心任务。尽管WikiSQL数据集在早期的NL2SQL研究中发挥了关键作用，但由于其存在大小写不一致、数据类型不匹配、语法错误和未回答问题等结构和标注问题，其使用率有所下降。因此，需要一个为LLM时代设计、更干净、更易于评估的Text-to-SQL基准。", "method": "研究人员对WikiSQL数据集的错误进行了分类，并实施了自动化方法进行清洗和重新标注，从而创建了LLMSQL。为了评估这些改进的影响，他们使用LLMSQL评估了多种大型语言模型，包括Gemma 3、LLaMA 3.2、Mistral 7B、gpt-oss 20B、Phi-3.5 Mini、Qwen 2.5、OpenAI o4-mini和DeepSeek R1等。", "result": "LLMSQL作为一个新的、LLM就绪的基准被引入。与原始WikiSQL不同，LLMSQL提供了干净的自然语言问题和完整的SQL查询作为纯文本，这使得现代自然语言到SQL模型的生成和评估变得简单直接。通过对多个LLM的评估，验证了LLMSQL作为有效评估工具的潜力。", "conclusion": "LLMSQL成功地解决了WikiSQL数据集的结构和标注问题，提供了一个为LLM时代量身定制的、干净且易于使用的Text-to-SQL基准。它能够促进现代大型语言模型在自然语言到SQL任务上的研究和评估，为该领域的发展提供了一个更可靠的工具。"}}
{"id": "2510.03078", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03078", "abs": "https://arxiv.org/abs/2510.03078", "authors": ["Anna Trapp", "Mersedeh Sadeghi", "Andreas Vogelsang"], "title": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments", "comment": "Accepted at Ex-ASE 2025, co-located with the 40th IEEE/ACM\n  International Conference on Automated Software Engineering (ASE 2025)", "summary": "Explainability is increasingly seen as an essential feature of rule-based\nsmart environments. While counterfactual explanations, which describe what\ncould have been done differently to achieve a desired outcome, are a powerful\ntool in eXplainable AI (XAI), no established methods exist for generating them\nin these rule-based domains. In this paper, we present the first formalization\nand implementation of counterfactual explanations tailored to this domain. It\nis implemented as a plugin that extends an existing explanation engine for\nsmart environments. We conducted a user study (N=17) to evaluate our generated\ncounterfactuals against traditional causal explanations. The results show that\nuser preference is highly contextual: causal explanations are favored for their\nlinguistic simplicity and in time-pressured situations, while counterfactuals\nare preferred for their actionable content, particularly when a user wants to\nresolve a problem. Our work contributes a practical framework for a new type of\nexplanation in smart environments and provides empirical evidence to guide the\nchoice of when each explanation type is most effective.", "AI": {"tldr": "本文首次为基于规则的智能环境形式化并实现了反事实解释，并与因果解释进行了用户研究。结果表明，用户对解释类型的偏好是情境化的，因果解释因其简单性在时间压力下更受欢迎，而反事实解释因其可操作性在解决问题时更受青睐。", "motivation": "可解释性在基于规则的智能环境中日益重要。反事实解释是可解释人工智能（XAI）中的强大工具，但在基于规则的领域中，尚无生成此类解释的既定方法。", "method": "研究人员首次对针对基于规则的智能环境的反事实解释进行了形式化和实现。该实现是一个插件，扩展了现有的智能环境解释引擎。通过一项用户研究（N=17），将生成的反事实解释与传统的因果解释进行了评估。", "result": "用户偏好具有高度情境性：因果解释因其语言简洁性在时间紧迫的情况下更受青睐；反事实解释因其可操作性而受到偏爱，尤其是在用户希望解决问题时。", "conclusion": "本研究为智能环境中的新型解释提供了一个实用的框架，并提供了实证证据，以指导在何时选择何种解释类型最为有效。"}}
{"id": "2510.02789", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02789", "abs": "https://arxiv.org/abs/2510.02789", "authors": ["Ara Seo", "Bryan Sangwoo Kim", "Hyungjin Chung", "Jong Chul Ye"], "title": "Align Your Query: Representation Alignment for Multimodality Medical Object Detection", "comment": "Project page: https://araseo.github.io/alignyourquery/", "summary": "Medical object detection suffers when a single detector is trained on mixed\nmedical modalities (e.g., CXR, CT, MRI) due to heterogeneous statistics and\ndisjoint representation spaces. To address this challenge, we turn to\nrepresentation alignment, an approach that has proven effective for bringing\nfeatures from different sources into a shared space. Specifically, we target\nthe representations of DETR-style object queries and propose a simple,\ndetector-agnostic framework to align them with modality context. First, we\ndefine modality tokens: compact, text-derived embeddings encoding imaging\nmodality that are lightweight and require no extra annotations. We integrate\nthe modality tokens into the detection process via Multimodality Context\nAttention (MoCA), mixing object-query representations via self-attention to\npropagate modality context within the query set. This preserves DETR-style\narchitectures and adds negligible latency while injecting modality cues into\nobject queries. We further introduce QueryREPA, a short pretraining stage that\naligns query representations to their modality tokens using a task-specific\ncontrastive objective with modality-balanced batches. Together, MoCA and\nQueryREPA produce modality-aware, class-faithful queries that transfer\neffectively to downstream training. Across diverse modalities trained\naltogether, the proposed approach consistently improves AP with minimal\noverhead and no architectural modifications, offering a practical path toward\nrobust multimodality medical object detection. Project page:\nhttps://araseo.github.io/alignyourquery/.", "AI": {"tldr": "本文提出了一种名为MoCA和QueryREPA的框架，通过将图像模态信息（如CXR、CT、MRI）与DETR风格的目标查询表示对齐，以解决医学目标检测中多模态数据混合训练时的性能下降问题，实现了更鲁棒的多模态医学目标检测。", "motivation": "当单个检测器在混合医学模态（如CXR、CT、MRI）上训练时，由于异构统计数据和不相交的表示空间，医学目标检测性能会下降。研究旨在解决这一挑战。", "method": "研究采用表示对齐的方法，将不同来源的特征带入共享空间。具体而言，它针对DETR风格的目标查询表示，并提出了一个与检测器无关的框架来将其与模态上下文对齐。首先，定义了模态标记（紧凑的、文本派生的嵌入），编码成像模态且轻量级，无需额外标注。其次，通过多模态上下文注意力（MoCA）将模态标记整合到检测过程中，通过自注意力在查询集中传播模态上下文。最后，引入了QueryREPA，一个简短的预训练阶段，使用任务特定的对比目标和模态平衡批次，将查询表示与其模态标记对齐。", "result": "MoCA和QueryREPA共同产生了模态感知、类别忠实的查询，这些查询可以有效地转移到下游训练。在各种混合训练的模态中，所提出的方法始终能提高AP，且开销极小，无需修改架构。", "conclusion": "该方法为实现鲁棒的多模态医学目标检测提供了一条实用的途径，具有最小的开销和无需架构修改的优点。"}}
{"id": "2510.03022", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03022", "abs": "https://arxiv.org/abs/2510.03022", "authors": ["Rui Zhong", "Yizhe Sun", "Junjie Wen", "Jinming Li", "Chuang Cheng", "Wei Dai", "Zhiwen Zeng", "Huimin Lu", "Yichen Zhu", "Yi Xu"], "title": "HumanoidExo: Scalable Whole-Body Humanoid Manipulation via Wearable Exoskeleton", "comment": null, "summary": "A significant bottleneck in humanoid policy learning is the acquisition of\nlarge-scale, diverse datasets, as collecting reliable real-world data remains\nboth difficult and cost-prohibitive. To address this limitation, we introduce\nHumanoidExo, a novel system that transfers human motion to whole-body humanoid\ndata. HumanoidExo offers a high-efficiency solution that minimizes the\nembodiment gap between the human demonstrator and the robot, thereby tackling\nthe scarcity of whole-body humanoid data. By facilitating the collection of\nmore voluminous and diverse datasets, our approach significantly enhances the\nperformance of humanoid robots in dynamic, real-world scenarios. We evaluated\nour method across three challenging real-world tasks: table-top manipulation,\nmanipulation integrated with stand-squat motions, and whole-body manipulation.\nOur results empirically demonstrate that HumanoidExo is a crucial addition to\nreal-robot data, as it enables the humanoid policy to generalize to novel\nenvironments, learn complex whole-body control from only five real-robot\ndemonstrations, and even acquire new skills (i.e., walking) solely from\nHumanoidExo data.", "AI": {"tldr": "HumanoidExo系统通过将人类动作转移到全身人形机器人数据，解决了人形机器人策略学习中数据稀缺的瓶颈，显著提升了机器人在真实世界场景中的性能和泛化能力。", "motivation": "人形机器人策略学习面临的主要瓶颈是难以获取大规模、多样化且成本高昂的真实世界数据。这限制了人形机器人的学习和泛化能力。", "method": "本文提出HumanoidExo系统，这是一种新颖的高效解决方案，能够将人类动作转移到全身人形机器人数据，从而最大程度地减少人类演示者与机器人之间的具身差距，解决全身人形机器人数据稀缺的问题。", "result": "HumanoidExo显著增强了人形机器人在动态真实世界场景中的性能。实验证明，该方法使人形机器人策略能够泛化到新环境，仅用五次真实机器人演示就能学习复杂的全身控制，甚至仅通过HumanoidExo数据就能习得新技能（如行走）。该方法在桌面操作、结合站立-下蹲动作的操作以及全身操作等挑战性任务中得到了验证。", "conclusion": "HumanoidExo是真实机器人数据的重要补充，它能有效促进人形机器人策略的泛化能力、高效学习复杂控制，并仅通过HumanoidExo数据就能习得新技能，从而克服了数据收集的限制。"}}
{"id": "2510.02351", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02351", "abs": "https://arxiv.org/abs/2510.02351", "authors": ["Dzmitry Pihulski", "Jan Kocoń"], "title": "Language, Culture, and Ideology: Personalizing Offensiveness Detection in Political Tweets with Reasoning LLMs", "comment": "To appear in the Proceedings of the IEEE International Conference on\n  Data Mining Workshops (ICDMW)", "summary": "We explore how large language models (LLMs) assess offensiveness in political\ndiscourse when prompted to adopt specific political and cultural perspectives.\nUsing a multilingual subset of the MD-Agreement dataset centered on tweets from\nthe 2020 US elections, we evaluate several recent LLMs - including DeepSeek-R1,\no4-mini, GPT-4.1-mini, Qwen3, Gemma, and Mistral - tasked with judging tweets\nas offensive or non-offensive from the viewpoints of varied political personas\n(far-right, conservative, centrist, progressive) across English, Polish, and\nRussian contexts. Our results show that larger models with explicit reasoning\nabilities (e.g., DeepSeek-R1, o4-mini) are more consistent and sensitive to\nideological and cultural variation, while smaller models often fail to capture\nsubtle distinctions. We find that reasoning capabilities significantly improve\nboth the personalization and interpretability of offensiveness judgments,\nsuggesting that such mechanisms are key to adapting LLMs for nuanced\nsociopolitical text classification across languages and ideologies.", "AI": {"tldr": "本研究探讨了大型语言模型（LLMs）在不同政治和文化视角下评估政治话语冒犯性的能力，发现具有推理能力的更大模型在处理意识形态和文化差异方面表现更优。", "motivation": "研究旨在探索LLMs在被要求采纳特定政治和文化视角时，如何评估政治话语中的冒犯性，以理解其对细微社会政治文本分类的适应性。", "method": "研究使用了MD-Agreement数据集的多语言子集（2020年美国大选推文），评估了DeepSeek-R1、o4-mini、GPT-4.1-mini、Qwen3、Gemma和Mistral等LLMs。模型被要求从不同政治角色（极右翼、保守派、中间派、进步派）的视角，在英语、波兰语和俄语语境中判断推文的冒犯性。", "result": "结果显示，具有明确推理能力的较大模型（如DeepSeek-R1、o4-mini）在处理意识形态和文化差异时更具一致性和敏感性，而较小模型往往无法捕捉细微差别。推理能力显著提升了冒犯性判断的个性化和可解释性。", "conclusion": "推理机制对于LLMs适应跨语言和意识形态的细致社会政治文本分类至关重要，是提升其性能的关键。"}}
{"id": "2510.03127", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03127", "abs": "https://arxiv.org/abs/2510.03127", "authors": ["Binze Li"], "title": "A Study of Rule Omission in Raven's Progressive Matrices", "comment": null, "summary": "Analogical reasoning lies at the core of human cognition and remains a\nfundamental challenge for artificial intelligence. Raven's Progressive Matrices\n(RPM) serve as a widely used benchmark to assess abstract reasoning by\nrequiring the inference of underlying structural rules. While many vision-based\nand language-based models have achieved success on RPM tasks, it remains\nunclear whether their performance reflects genuine reasoning ability or\nreliance on statistical shortcuts. This study investigates the generalization\ncapacity of modern AI systems under conditions of incomplete training by\ndeliberately omitting several structural rules during training. Both\nsequence-to-sequence transformer models and vision-based architectures such as\nCoPINet and the Dual-Contrast Network are evaluated on the Impartial-RAVEN\n(I-RAVEN) dataset. Experiments reveal that although transformers demonstrate\nstrong performance on familiar rules, their accuracy declines sharply when\nfaced with novel or omitted rules. Moreover, the gap between token-level\naccuracy and complete answer accuracy highlights fundamental limitations in\ncurrent approaches. These findings provide new insights into the reasoning\nmechanisms underlying deep learning models and underscore the need for\narchitectures that move beyond pattern recognition toward robust abstract\nreasoning.", "AI": {"tldr": "本研究通过在不完整训练条件下评估AI系统在Raven's Progressive Matrices (RPM)任务上的泛化能力，发现Transformer模型在面对未训练过的抽象推理规则时表现急剧下降，表明当前深度学习模型可能依赖模式识别而非真正的抽象推理。", "motivation": "RPM被广泛用于评估抽象推理能力，但AI模型在此任务上的成功是否反映了真正的推理能力，还是仅仅依赖统计捷径，这一点尚不清楚。本研究旨在通过故意省略训练中的结构规则来探究现代AI系统在不完整训练条件下的泛化能力。", "method": "研究方法包括：1) 在训练过程中故意省略某些结构规则；2) 使用Impartial-RAVEN (I-RAVEN)数据集进行评估；3) 评估的模型包括序列到序列的Transformer模型、基于视觉的CoPINet架构和Dual-Contrast Network。", "result": "实验结果显示：1) Transformer模型在熟悉规则上表现强劲；2) 但在面对新颖或被省略的规则时，其准确性急剧下降；3) 标记级准确性与完整答案准确性之间的差距，凸显了当前方法的根本局限性。", "conclusion": "这些发现为深度学习模型背后的推理机制提供了新见解，并强调了需要开发超越模式识别、实现鲁棒抽象推理的架构。"}}
{"id": "2510.02790", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.02790", "abs": "https://arxiv.org/abs/2510.02790", "authors": ["Jingyuan Deng", "Yujiu Yang"], "title": "MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding", "comment": "accepted to emnlp2025 findings", "summary": "Large vision-language models (LVLMs) have shown remarkable performance in\nvisual-language understanding for downstream multimodal tasks. While their\ncapabilities are improving, problems emerge simultaneously. Among those\nproblems, the hallucinations have attracted much attention, which stands for\nthe phenomenon where LVLMs generate contradictory content to their input visual\nand text contents. Many approaches have been proposed to deal with this issue,\nsuch as contrastive decoding and attention manipulation. However, contrastive\ndecoding methods struggle in constructing appropriate contrastive samples, and\nattention manipulation methods are highly sensitive, lacking stability. In this\nwork, we propose image head Masked Contrastive Decoding (MaskCD). Our approach\nutilizes the \"image heads\" in LVLMs, masking them to construct contrastive\nsamples for contrastive decoding. We evaluated MaskCD on LLaVA-1.5-7b and\nQwen-VL-7b, using various benchmarks such as CHAIR, POPE, AMBER and MME. The\nresults demonstrate that MaskCD effectively alleviates the phenomenon of\nhallucinations and retains the general capabilities of LVLMs. Corresponding\nresources could be found at: https://github.com/Deng-Jingyuan/MaskCD .", "AI": {"tldr": "本文提出MaskCD，一种通过掩蔽大视觉语言模型（LVLM）中的“图像头”来构建对比样本的对比解码方法，有效缓解了LVLM的幻觉问题并保持了其通用能力。", "motivation": "大视觉语言模型（LVLM）在多模态任务中表现出色，但存在幻觉问题，即生成与输入视觉和文本内容矛盾的信息。现有方法如对比解码和注意力操作分别面临对比样本构建困难和稳定性差的问题。", "method": "本文提出图像头掩蔽对比解码（MaskCD）方法。该方法利用LVLM中的“图像头”，通过对其进行掩蔽来构建对比样本，用于对比解码。", "result": "MaskCD在LLaVA-1.5-7b和Qwen-VL-7b模型上，使用CHAIR、POPE、AMBER和MME等基准进行评估，结果表明它能有效缓解幻觉现象，并保留LVLM的通用能力。", "conclusion": "MaskCD是一种有效且稳定的方法，可以减轻大视觉语言模型中的幻觉问题，同时不牺牲其整体性能。"}}
{"id": "2510.03031", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03031", "abs": "https://arxiv.org/abs/2510.03031", "authors": ["Yufei Zhu", "Andrey Rudenko", "Tomasz P. Kucner", "Achim J. Lilienthal", "Martin Magnusson"], "title": "Long-Term Human Motion Prediction Using Spatio-Temporal Maps of Dynamics", "comment": "IEEE Robotics and Automation Letters", "summary": "Long-term human motion prediction (LHMP) is important for the safe and\nefficient operation of autonomous robots and vehicles in environments shared\nwith humans. Accurate predictions are important for applications including\nmotion planning, tracking, human-robot interaction, and safety monitoring. In\nthis paper, we exploit Maps of Dynamics (MoDs), which encode spatial or\nspatio-temporal motion patterns as environment features, to achieve LHMP for\nhorizons of up to 60 seconds. We propose an MoD-informed LHMP framework that\nsupports various types of MoDs and includes a ranking method to output the most\nlikely predicted trajectory, improving practical utility in robotics. Further,\na time-conditioned MoD is introduced to capture motion patterns that vary\nacross different times of day. We evaluate MoD-LHMP instantiated with three\ntypes of MoDs. Experiments on two real-world datasets show that MoD-informed\nmethod outperforms learning-based ones, with up to 50\\% improvement in average\ndisplacement error, and the time-conditioned variant achieves the highest\naccuracy overall. Project code is available at\nhttps://github.com/test-bai-cpu/LHMP-with-MoDs.git", "AI": {"tldr": "本文提出了一种基于动态地图（MoDs）的长期人类运动预测（LHMP）框架，用于自主机器人和车辆，并在真实世界数据集中显示出比基于学习的方法更高的准确性，尤其是在引入时间条件MoD后。", "motivation": "准确的长期人类运动预测对于自主机器人和车辆在与人类共享环境中安全高效地运行至关重要，这对于运动规划、跟踪、人机交互和安全监控等应用具有重要意义。", "method": "该研究利用动态地图（MoDs）来编码空间或时空运动模式作为环境特征，以实现长达60秒的LHMP。它提出了一个MoD-informed LHMP框架，支持多种MoD类型，并包含一个排名方法来输出最可能的预测轨迹。此外，还引入了时间条件MoD来捕捉一天中不同时间变化的运动模式。该方法通过三种MoD类型在两个真实世界数据集上进行了评估。", "result": "实验结果表明，MoD-informed方法优于基于学习的方法，在平均位移误差方面提高了高达50%。其中，时间条件MoD变体实现了最高的整体准确性。", "conclusion": "基于动态地图的长期人类运动预测框架，特别是结合时间条件MoD，能够显著提高预测准确性，从而增强机器人在实际应用中的实用性。"}}
{"id": "2510.02352", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02352", "abs": "https://arxiv.org/abs/2510.02352", "authors": ["Yihao Wu", "Tianrui Wang", "Yizhou Peng", "Yi-Wen Chao", "Xuyi Zhuang", "Xinsheng Wang", "Shunshun Yin", "Ziyang Ma"], "title": "Evaluating Bias in Spoken Dialogue LLMs for Real-World Decisions and Recommendations", "comment": null, "summary": "While biases in large language models (LLMs), such as stereotypes and\ncultural tendencies in outputs, have been examined and identified, their\npresence and characteristics in spoken dialogue models (SDMs) with audio input\nand output remain largely unexplored. Paralinguistic features, such as age,\ngender, and accent, can affect model outputs; when compounded by multi-turn\nconversations, these effects may exacerbate biases, with potential implications\nfor fairness in decision-making and recommendation tasks. In this paper, we\nsystematically evaluate biases in speech LLMs and study the impact of\nmulti-turn dialogues with repeated negative feedback. Bias is measured using\nGroup Unfairness Score (GUS) for decisions and similarity-based normalized\nstatistics rate (SNSR) for recommendations, across both open-source models like\nQwen2.5-Omni and GLM-4-Voice, as well as closed-source APIs such as GPT-4o\nAudio and Gemini-2.5-Flash. Our analysis reveals that closed-source models\ngenerally exhibit lower bias, while open-source models are more sensitive to\nage and gender, and recommendation tasks tend to amplify cross-group\ndisparities. We found that biased decisions may persist in multi-turn\nconversations. This work provides the first systematic study of biases in\nend-to-end spoken dialogue models, offering insights towards fair and reliable\naudio-based interactive systems. To facilitate further research, we release the\nFairDialogue dataset and evaluation code.", "AI": {"tldr": "本文系统性评估了带有音频输入输出的语音大模型（SDMs）中的偏见，并研究了多轮对话和重复负面反馈的影响，发现闭源模型偏见较低，开源模型对年龄和性别更敏感，且偏见在多轮对话中可能持续存在。", "motivation": "尽管大型语言模型（LLMs）中的偏见已被识别，但对于带有音频输入输出的语音对话模型（SDMs）中的偏见及其特征尚待探索。副语言特征（如年龄、性别、口音）可能影响模型输出，并在多轮对话中加剧偏见，从而影响决策和推荐任务的公平性。", "method": "研究者系统性评估了语音LLM中的偏见，并研究了带有重复负面反馈的多轮对话的影响。使用群体不公平分数（GUS）衡量决策偏见，使用基于相似度的标准化统计率（SNSR）衡量推荐偏见。评估了开源模型（如Qwen2.5-Omni和GLM-4-Voice）以及闭源API（如GPT-4o Audio和Gemini-2.5-Flash）。同时发布了FairDialogue数据集和评估代码。", "result": "分析显示，闭源模型通常表现出较低的偏见；开源模型对年龄和性别更为敏感；推荐任务倾向于放大跨群体差异；在多轮对话中，有偏见的决策可能会持续存在。", "conclusion": "这项工作首次系统性研究了端到端语音对话模型中的偏见，为构建公平可靠的基于音频的交互系统提供了见解。研究者还发布了FairDialogue数据集和评估代码以促进后续研究。"}}
{"id": "2510.03153", "categories": ["cs.AI", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03153", "abs": "https://arxiv.org/abs/2510.03153", "authors": ["Hima Jacob Leven Suprabha", "Laxmi Nag Laxminarayan Nagesh", "Ajith Nair", "Alvin Reuben Amal Selvaster", "Ayan Khan", "Raghuram Damarla", "Sanju Hannah Samuel", "Sreenithi Saravana Perumal", "Titouan Puech", "Venkataramireddy Marella", "Vishal Sonar", "Alessandro Suglia", "Oliver Lemon"], "title": "Improving Cooperation in Collaborative Embodied AI", "comment": "In proceedings of UKCI 2025", "summary": "The integration of Large Language Models (LLMs) into multiagent systems has\nopened new possibilities for collaborative reasoning and cooperation with AI\nagents. This paper explores different prompting methods and evaluates their\neffectiveness in enhancing agent collaborative behaviour and decision-making.\nWe enhance CoELA, a framework designed for building Collaborative Embodied\nAgents that leverage LLMs for multi-agent communication, reasoning, and task\ncoordination in shared virtual spaces. Through systematic experimentation, we\nexamine different LLMs and prompt engineering strategies to identify optimised\ncombinations that maximise collaboration performance. Furthermore, we extend\nour research by integrating speech capabilities, enabling seamless\ncollaborative voice-based interactions. Our findings highlight the\neffectiveness of prompt optimisation in enhancing collaborative agent\nperformance; for example, our best combination improved the efficiency of the\nsystem running with Gemma3 by 22% compared to the original CoELA system. In\naddition, the speech integration provides a more engaging user interface for\niterative system development and demonstrations.", "AI": {"tldr": "本文探索了在多智能体系统中利用大语言模型（LLMs）的提示工程和语音集成，以提升协作行为和决策能力，并通过优化CoELA框架，实现了显著的性能提升。", "motivation": "将大语言模型（LLMs）整合到多智能体系统中，为AI智能体的协作推理和合作开辟了新可能性，研究旨在通过提示方法和语音交互进一步增强这些能力。", "method": "研究增强了CoELA框架，该框架旨在构建利用LLMs进行多智能体通信、推理和任务协调的协作具身智能体。通过系统实验，研究审查了不同的LLMs和提示工程策略，以识别最大化协作性能的优化组合。此外，研究还集成了语音能力，实现了无缝的基于语音的协作交互。", "result": "研究结果表明，提示优化能有效提升协作智能体的性能；例如，最佳组合将使用Gemma3的系统效率比原始CoELA系统提高了22%。此外，语音集成提供了一个更具吸引力的用户界面，用于迭代系统开发和演示。", "conclusion": "提示优化在增强协作智能体性能方面表现出显著效果，而语音集成则为系统开发和演示提供了更具吸引力的用户体验。"}}
{"id": "2510.02791", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.02791", "abs": "https://arxiv.org/abs/2510.02791", "authors": ["Patrick Sandoz", "Antoine N. André", "Guillaume J. Laurent"], "title": "VERNIER: an open-source software pushing marker pose estimation down to the micrometer and nanometer scales", "comment": null, "summary": "Pose estimation is still a challenge at the small scales. Few solutions exist\nto capture the 6 degrees of freedom of an object with nanometric and\nmicroradians resolutions over relatively large ranges. Over the years, we have\nproposed several fiducial marker and pattern designs to achieve reliable\nperformance for various microscopy applications. Centimeter ranges are possible\nusing pattern encoding methods, while nanometer resolutions can be achieved\nusing phase processing of the periodic frames. This paper presents VERNIER, an\nopen source phase processing software designed to provide fast and reliable\npose measurement based on pseudo-periodic patterns. Thanks to a phase-based\nlocal thresholding algorithm, the software has proven to be particularly robust\nto noise, defocus and occlusion. The successive steps of the phase processing\nare presented, as well as the different types of patterns that address\ndifferent application needs. The implementation procedure is illustrated with\nsynthetic and experimental images. Finally, guidelines are given for selecting\nthe appropriate pattern design and microscope magnification lenses as a\nfunction of the desired performance.", "AI": {"tldr": "本文介绍了VERNIER，一款开源的相位处理软件，用于基于伪周期图案实现快速可靠的纳米级和微弧度高精度位姿估计，并具有对噪声、散焦和遮挡的鲁棒性。", "motivation": "在小尺度下，以纳米和微弧度分辨率在大范围内捕捉物体六自由度位姿仍然是一个挑战，现有解决方案有限。", "method": "本文提出了VERNIER软件，它利用伪周期图案和基于相位的局部阈值算法进行相位处理，以实现位姿测量。软件还支持不同类型的图案以满足不同的应用需求。", "result": "VERNIER软件已被证明能够提供快速可靠的位姿测量，并且对噪声、散焦和遮挡具有特别的鲁棒性。它能够实现纳米级分辨率和厘米级范围的位姿估计。论文还提供了选择合适图案设计和显微镜放大镜头的指导方针。", "conclusion": "VERNIER是一款强大且开源的相位处理软件，为小尺度高精度位姿估计提供了一个可靠的解决方案，其鲁棒性使其适用于各种显微镜应用。论文为用户提供了实际应用指导。"}}
{"id": "2510.03081", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03081", "abs": "https://arxiv.org/abs/2510.03081", "authors": ["Guiliang Liu", "Bo Yue", "Yi Jin Kim", "Kui Jia"], "title": "Embracing Evolution: A Call for Body-Control Co-Design in Embodied Humanoid Robot", "comment": null, "summary": "Humanoid robots, as general-purpose physical agents, must integrate both\nintelligent control and adaptive morphology to operate effectively in diverse\nreal-world environments. While recent research has focused primarily on\noptimizing control policies for fixed robot structures, this position paper\nargues for evolving both control strategies and humanoid robots' physical\nstructure under a co-design mechanism. Inspired by biological evolution, this\napproach enables robots to iteratively adapt both their form and behavior to\noptimize performance within task-specific and resource-constrained contexts.\nDespite its promise, co-design in humanoid robotics remains a relatively\nunderexplored domain, raising fundamental questions about its feasibility and\nnecessity in achieving true embodied intelligence. To address these challenges,\nwe propose practical co-design methodologies grounded in strategic exploration,\nSim2Real transfer, and meta-policy learning. We further argue for the essential\nrole of co-design by analyzing it from methodological, application-driven, and\ncommunity-oriented perspectives. Striving to guide and inspire future studies,\nwe present open research questions, spanning from short-term innovations to\nlong-term goals. This work positions co-design as a cornerstone for developing\nthe next generation of intelligent and adaptable humanoid agents.", "AI": {"tldr": "本文主张通过协同设计（Co-design）人形机器人的控制策略和物理结构，以实现其在复杂真实世界环境中的智能适应性。", "motivation": "当前研究主要集中于优化固定机器人结构下的控制策略，但人形机器人作为通用物理智能体，需要同时整合智能控制和自适应形态，才能在多样化的真实世界环境中有效运行。", "method": "受生物进化的启发，本文提出协同进化控制策略和机器人物理结构。具体方法包括基于战略探索、Sim2Real迁移和元策略学习的实用协同设计方法论。同时，从方法学、应用驱动和社区导向等角度分析了协同设计的重要性。", "result": "本文将协同设计定位为开发下一代智能和适应性人形机器人的基石，并提出了开放的研究问题，旨在指导和启发未来的相关研究。", "conclusion": "协同设计对于实现真正具身智能至关重要，是开发未来智能适应性人形机器人的核心策略，需要深入探索其可行性和必要性。"}}
{"id": "2510.02353", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02353", "abs": "https://arxiv.org/abs/2510.02353", "authors": ["Oumar Kane", "Mouhamad M. Allaya", "Dame Samb", "Mamadou Bousso"], "title": "An Senegalese Legal Texts Structuration Using LLM-augmented Knowledge Graph", "comment": "8 pages, 8 figures, 2 tables, 1 algorithm", "summary": "This study examines the application of artificial intelligence (AI) and large\nlanguage models (LLM) to improve access to legal texts in Senegal's judicial\nsystem. The emphasis is on the difficulties of extracting and organizing legal\ndocuments, highlighting the need for better access to judicial information. The\nresearch successfully extracted 7,967 articles from various legal documents,\nparticularly focusing on the Land and Public Domain Code. A detailed graph\ndatabase was developed, which contains 2,872 nodes and 10,774 relationships,\naiding in the visualization of interconnections within legal texts. In\naddition, advanced triple extraction techniques were utilized for knowledge,\ndemonstrating the effectiveness of models such as GPT-4o, GPT-4, and\nMistral-Large in identifying relationships and relevant metadata. Through these\ntechnologies, the aim is to create a solid framework that allows Senegalese\ncitizens and legal professionals to more effectively understand their rights\nand responsibilities.", "AI": {"tldr": "本研究利用人工智能和大型语言模型改进塞内加尔司法系统法律文本的获取，通过提取法律条文、构建图数据库和知识三元组提取，旨在提升公民和法律专业人士对法律的理解。", "motivation": "塞内加尔法律文本的提取和组织存在困难，导致司法信息获取不便，因此需要更好的解决方案来提高法律信息的访问性。", "method": "研究方法包括：从法律文件中提取文章（特别是《土地和公共领域法典》），构建详细的图数据库以可视化法律文本间的关联，以及利用GPT-4o、GPT-4和Mistral-Large等模型进行高级知识三元组提取，以识别关系和元数据。", "result": "成功从法律文件中提取了7,967篇文章，并开发了一个包含2,872个节点和10,774个关系的图数据库。研究还证明了GPT-4o、GPT-4和Mistral-Large等模型在识别法律文本中的关系和相关元数据方面的有效性。", "conclusion": "通过这些技术，研究旨在创建一个坚实框架，使塞内加尔公民和法律专业人士能够更有效地理解他们的权利和责任。"}}
{"id": "2510.03194", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03194", "abs": "https://arxiv.org/abs/2510.03194", "authors": ["Zichen Chen", "Jiefeng Chen", "Sercan Ö. Arik", "Misha Sra", "Tomas Pfister", "Jinsung Yoon"], "title": "CoDA: Agentic Systems for Collaborative Data Visualization", "comment": "31 pages, 6 figures, 5 tables", "summary": "Deep research has revolutionized data analysis, yet data scientists still\ndevote substantial time to manually crafting visualizations, highlighting the\nneed for robust automation from natural language queries. However, current\nsystems struggle with complex datasets containing multiple files and iterative\nrefinement. Existing approaches, including simple single- or multi-agent\nsystems, often oversimplify the task, focusing on initial query parsing while\nfailing to robustly manage data complexity, code errors, or final visualization\nquality. In this paper, we reframe this challenge as a collaborative\nmulti-agent problem. We introduce CoDA, a multi-agent system that employs\nspecialized LLM agents for metadata analysis, task planning, code generation,\nand self-reflection. We formalize this pipeline, demonstrating how\nmetadata-focused analysis bypasses token limits and quality-driven refinement\nensures robustness. Extensive evaluations show CoDA achieves substantial gains\nin the overall score, outperforming competitive baselines by up to 41.5%. This\nwork demonstrates that the future of visualization automation lies not in\nisolated code generation but in integrated, collaborative agentic workflows.", "AI": {"tldr": "本文提出CoDA，一个多智能体系统，利用专业LLM智能体进行元数据分析、任务规划、代码生成和自我反思，以自动化从自然语言查询生成数据可视化，有效处理复杂数据集和迭代优化，性能显著优于现有基线。", "motivation": "数据科学家在手动创建可视化方面耗费大量时间，尽管深度研究革新了数据分析。现有系统在处理包含多个文件和需要迭代改进的复杂数据集时表现不佳。当前的单一或多智能体方法过于简化任务，侧重于初始查询解析，但未能有效管理数据复杂性、代码错误或最终可视化质量。", "method": "将数据可视化自动化挑战重新定义为协作多智能体问题。引入了CoDA，一个多智能体系统，其LLM智能体专门负责元数据分析、任务规划、代码生成和自我反思。该方法将元数据分析融入管道以规避token限制，并通过质量驱动的优化确保鲁棒性。", "result": "CoDA在整体得分上取得了显著提升，比竞争基线高出高达41.5%。", "conclusion": "数据可视化自动化的未来在于集成、协作的智能体工作流，而非孤立的代码生成。"}}
{"id": "2510.02815", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02815", "abs": "https://arxiv.org/abs/2510.02815", "authors": ["Feng Yuan", "Yifan Gao", "Yuehua Ye", "Haoyue Li", "Xin Gao"], "title": "Med-K2N: Flexible K-to-N Modality Translation for Medical Image Synthesis", "comment": "ICLR2026 under review", "summary": "Cross-modal medical image synthesis research focuses on reconstructing\nmissing imaging modalities from available ones to support clinical diagnosis.\nDriven by clinical necessities for flexible modality reconstruction, we explore\nK to N medical generation, where three critical challenges emerge: How can we\nmodel the heterogeneous contributions of different modalities to various target\ntasks? How can we ensure fusion quality control to prevent degradation from\nnoisy information? How can we maintain modality identity consistency in\nmulti-output generation? Driven by these clinical necessities, and drawing\ninspiration from SAM2's sequential frame paradigm and clinicians' progressive\nworkflow of incrementally adding and selectively integrating multi-modal\ninformation, we treat multi-modal medical data as sequential frames with\nquality-driven selection mechanisms. Our key idea is to \"learn\" adaptive\nweights for each modality-task pair and \"memorize\" beneficial fusion patterns\nthrough progressive enhancement. To achieve this, we design three collaborative\nmodules: PreWeightNet for global contribution assessment, ThresholdNet for\nadaptive filtering, and EffiWeightNet for effective weight computation.\nMeanwhile, to maintain modality identity consistency, we propose the Causal\nModality Identity Module (CMIM) that establishes causal constraints between\ngenerated images and target modality descriptions using vision-language\nmodeling. Extensive experimental results demonstrate that our proposed Med-K2N\noutperforms state-of-the-art methods by significant margins on multiple\nbenchmarks. Source code is available.", "AI": {"tldr": "该研究提出Med-K2N框架，用于K到N跨模态医学图像合成，通过自适应权重学习和因果模态身份模块，解决不同模态贡献异质性、融合质量控制和模态身份一致性等核心挑战，显著优于现有SOTA方法。", "motivation": "临床诊断对灵活的模态重建有迫切需求，尤其是在K到N医学图像生成中面临三大挑战：如何建模不同模态对各种目标任务的异质性贡献；如何确保融合质量以防止噪声信息导致性能下降；以及如何在多输出生成中保持模态身份一致性。", "method": "受SAM2的顺序帧范式和临床医生渐进式工作流程的启发，将多模态医学数据视为具有质量驱动选择机制的顺序帧。核心思想是为每个模态-任务对“学习”自适应权重，并通过渐进式增强“记忆”有益的融合模式。为此，设计了三个协作模块：PreWeightNet（用于全局贡献评估）、ThresholdNet（用于自适应过滤）和EffiWeightNet（用于有效权重计算）。同时，为保持模态身份一致性，提出了因果模态身份模块（CMIM），利用视觉-语言建模在生成图像和目标模态描述之间建立因果约束。", "result": "广泛的实验结果表明，所提出的Med-K2N在多个基准测试上显著优于现有最先进的方法。", "conclusion": "该研究成功解决了K到N医学图像合成中的关键挑战，通过引入自适应权重学习和因果模态身份模块，提供了一个有效的框架，显著提高了跨模态医学图像合成的性能和临床实用性。"}}
{"id": "2510.03119", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03119", "abs": "https://arxiv.org/abs/2510.03119", "authors": ["Chaoxiang Ye", "Guido de Croon", "Salua Hamaza"], "title": "Whisker-based Tactile Flight for Tiny Drones", "comment": null, "summary": "Tiny flying robots hold great potential for search-and-rescue, safety\ninspections, and environmental monitoring, but their small size limits\nconventional sensing-especially with poor-lighting, smoke, dust or reflective\nobstacles. Inspired by nature, we propose a lightweight, 3.2-gram,\nwhisker-based tactile sensing apparatus for tiny drones, enabling them to\nnavigate and explore through gentle physical interaction. Just as rats and\nmoles use whiskers to perceive surroundings, our system equips drones with\ntactile perception in flight, allowing obstacle sensing even in pitch-dark\nconditions. The apparatus uses barometer-based whisker sensors to detect\nobstacle locations while minimising destabilisation. To address sensor noise\nand drift, we develop a tactile depth estimation method achieving sub-6 mm\naccuracy. This enables drones to navigate, contour obstacles, and explore\nconfined spaces solely through touch-even in total darkness along both soft and\nrigid surfaces. Running fully onboard a 192-KB RAM microcontroller, the system\nsupports autonomous tactile flight and is validated in both simulation and\nreal-world tests. Our bio-inspired approach redefines vision-free navigation,\nopening new possibilities for micro aerial vehicles in extreme environments.", "AI": {"tldr": "该研究为微型无人机开发了一种受生物启发的、基于触须的触觉传感系统，使其能够在光线不足、烟雾或完全黑暗等极端环境中，仅通过触觉进行高精度导航和避障。", "motivation": "微型飞行机器人潜力巨大，但在恶劣环境（如光线差、烟雾、灰尘或反光障碍物）下，其传统传感能力受限。研究旨在为微型无人机提供在完全黑暗中也能感应障碍物的能力。", "method": "提出了一种3.2克重的轻量化、基于触须的触觉传感装置，用于微型无人机。该装置使用基于气压计的触须传感器来检测障碍物位置，并最大限度地减少对无人机稳定性的影响。为解决传感器噪声和漂移问题，开发了一种触觉深度估计方法，并在192KB RAM的微控制器上完全板载运行。系统通过仿真和实际测试进行了验证。", "result": "该系统使无人机能够通过轻柔的物理交互进行导航和探索，即使在完全黑暗中也能感应障碍物。触觉深度估计方法实现了亚6毫米的精度。无人机仅通过触觉就能在黑暗中沿着软硬表面导航、绕过障碍物并探索狭小空间。系统支持自主触觉飞行。", "conclusion": "这种受生物启发的触觉方法重新定义了无视觉导航，为微型飞行器在极端环境中的应用开辟了新的可能性。"}}
{"id": "2510.02354", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02354", "abs": "https://arxiv.org/abs/2510.02354", "authors": ["Shreya Saha", "Shurui Li", "Greta Tuckute", "Yuanning Li", "Ru-Yuan Zhang", "Leila Wehbe", "Evelina Fedorenko", "Meenakshi Khosla"], "title": "Modeling the language cortex with form-independent and enriched representations of sentence meaning reveals remarkable semantic abstractness", "comment": null, "summary": "The human language system represents both linguistic forms and meanings, but\nthe abstractness of the meaning representations remains debated. Here, we\nsearched for abstract representations of meaning in the language cortex by\nmodeling neural responses to sentences using representations from vision and\nlanguage models. When we generate images corresponding to sentences and extract\nvision model embeddings, we find that aggregating across multiple generated\nimages yields increasingly accurate predictions of language cortex responses,\nsometimes rivaling large language models. Similarly, averaging embeddings\nacross multiple paraphrases of a sentence improves prediction accuracy compared\nto any single paraphrase. Enriching paraphrases with contextual details that\nmay be implicit (e.g., augmenting \"I had a pancake\" to include details like\n\"maple syrup\") further increases prediction accuracy, even surpassing\npredictions based on the embedding of the original sentence, suggesting that\nthe language system maintains richer and broader semantic representations than\nlanguage models. Together, these results demonstrate the existence of highly\nabstract, form-independent meaning representations within the language cortex.", "AI": {"tldr": "该研究通过结合视觉和语言模型，发现人类语言皮层中存在高度抽象、与形式无关的意义表征，其语义丰富度甚至超越了当前语言模型。", "motivation": "人类语言系统如何表征意义的抽象程度尚存争议，研究旨在探寻语言皮层中是否存在抽象的意义表征。", "method": "研究通过以下方法建模了语言皮层对句子的神经反应：1) 使用与句子对应的生成图像的视觉模型嵌入；2) 聚合多个生成图像的视觉模型嵌入；3) 平均多个句子释义的嵌入；4) 用上下文细节（如“枫糖浆”）丰富句子释义，以增强其隐式信息。", "result": "结果显示，聚合多个生成图像的视觉模型嵌入能提高对语言皮层反应的预测准确性，有时甚至与大型语言模型相当。平均多个释义的嵌入也能提高预测准确性。用上下文细节丰富释义进一步提高了预测准确性，甚至超越了基于原始句子嵌入的预测，这表明人类语言系统维持着比语言模型更丰富、更广泛的语义表征。", "conclusion": "这些结果共同证明了语言皮层中存在高度抽象、独立于形式的意义表征。"}}
{"id": "2510.03206", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03206", "abs": "https://arxiv.org/abs/2510.03206", "authors": ["Cai Zhou", "Chenxiao Yang", "Yi Hu", "Chenyu Wang", "Chubin Zhang", "Muhan Zhang", "Lester Mackey", "Tommi Jaakkola", "Stephen Bates", "Dinghuai Zhang"], "title": "Coevolutionary Continuous Discrete Diffusion: Make Your Diffusion Language Model a Latent Reasoner", "comment": "27 pages", "summary": "Diffusion language models, especially masked discrete diffusion models, have\nachieved great success recently. While there are some theoretical and primary\nempirical results showing the advantages of latent reasoning with looped\ntransformers or continuous chain-of-thoughts, continuous diffusion models\ntypically underperform their discrete counterparts. In this paper, we argue\nthat diffusion language models do not necessarily need to be in the discrete\nspace. In particular, we prove that continuous diffusion models have stronger\nexpressivity than discrete diffusions and looped transformers. We attribute the\ncontradiction between the theoretical expressiveness and empirical performance\nto their practical trainability: while continuous diffusion provides\nintermediate supervision that looped transformers lack, they introduce\nadditional difficulty decoding tokens into the discrete token space from the\ncontinuous representation space. We therefore propose Coevolutionary Continuous\nDiscrete Diffusion (CCDD), which defines a joint multimodal diffusion process\non the union of a continuous representation space and a discrete token space,\nleveraging a single model to simultaneously denoise in the joint space. By\ncombining two modalities, CCDD is expressive with rich semantics in the latent\nspace, as well as good trainability and sample quality with the help of\nexplicit discrete tokens. We also propose effective architectures and advanced\ntraining/sampling techniques for CCDD, which reveals strong empirical\nperformance in extensive language modeling experiments on real-world tasks.", "AI": {"tldr": "本文证明了连续扩散语言模型比离散模型具有更强的表达能力，但实践中表现不佳。为解决此问题，提出了Coevolutionary Continuous Discrete Diffusion (CCDD)模型，通过在连续表示空间和离散token空间上联合扩散，实现了理论表达能力和实际可训练性的结合，并在语言建模任务中取得了优异的实证性能。", "motivation": "尽管离散扩散语言模型取得了巨大成功，并且有理论和初步经验结果表明循环Transformer或连续思维链在潜在推理方面具有优势，但连续扩散模型通常不如其离散对应物。作者认为连续扩散模型不一定需要在离散空间中，并试图解释理论表达能力与实际性能之间的矛盾。", "method": "1. 理论证明：证明了连续扩散模型比离散扩散和循环Transformer具有更强的表达能力。2. 归因分析：将理论表达能力与经验性能的矛盾归因于实际可训练性——连续扩散虽然提供了中间监督，但将连续表示解码为离散token带来了额外难度。3. 提出CCDD：提出Coevolutionary Continuous Discrete Diffusion (CCDD)，它在连续表示空间和离散token空间的并集上定义了一个联合多模态扩散过程，利用单一模型同时在联合空间中进行去噪。4. 技术开发：为CCDD提出了有效的架构和先进的训练/采样技术。", "result": "1. 理论发现：连续扩散模型具有比离散扩散和循环Transformer更强的表达能力。2. CCDD性能：CCDD结合了潜在空间中丰富的语义表达能力、良好的可训练性和样本质量，这得益于显式离散token的帮助。3. 实证验证：在广泛的真实世界语言建模实验中，CCDD展现出强大的实证性能。", "conclusion": "连续扩散语言模型在理论上具有更强的表达能力，但其在实践中的性能受限于从连续表示解码到离散token的难度。通过提出Coevolutionary Continuous Discrete Diffusion (CCDD)，本文成功地将连续扩散的理论表达能力与离散扩散的良好可训练性相结合，实现了在语言建模任务上的强大实证性能，证明了连续扩散模型在语言领域的可行性和优越性。"}}
{"id": "2510.02876", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02876", "abs": "https://arxiv.org/abs/2510.02876", "authors": ["Md Zahim Hassan", "Md. Osama", "Muhammad Ashad Kabir", "Md. Saiful Islam", "Zannatul Naim"], "title": "ELMF4EggQ: Ensemble Learning with Multimodal Feature Fusion for Non-Destructive Egg Quality Assessment", "comment": "30 pages", "summary": "Accurate, non-destructive assessment of egg quality is critical for ensuring\nfood safety, maintaining product standards, and operational efficiency in\ncommercial poultry production. This paper introduces ELMF4EggQ, an ensemble\nlearning framework that employs multimodal feature fusion to classify egg grade\nand freshness using only external attributes - image, shape, and weight. A\nnovel, publicly available dataset of 186 brown-shelled eggs was constructed,\nwith egg grade and freshness levels determined through laboratory-based expert\nassessments involving internal quality measurements, such as yolk index and\nHaugh unit. To the best of our knowledge, this is the first study to apply\nmachine learning methods for internal egg quality assessment using only\nexternal, non-invasive features, and the first to release a corresponding\nlabeled dataset. The proposed framework integrates deep features extracted from\nexternal egg images with structural characteristics such as egg shape and\nweight, enabling a comprehensive representation of each egg. Image feature\nextraction is performed using top-performing pre-trained CNN models (ResNet152,\nDenseNet169, and ResNet152V2), followed by PCA-based dimensionality reduction,\nSMOTE augmentation, and classification using multiple machine learning\nalgorithms. An ensemble voting mechanism combines predictions from the\nbest-performing classifiers to enhance overall accuracy. Experimental results\ndemonstrate that the multimodal approach significantly outperforms image-only\nand tabular (shape and weight) only baselines, with the multimodal ensemble\napproach achieving 86.57% accuracy in grade classification and 70.83% in\nfreshness prediction. All code and data are publicly available at\nhttps://github.com/Kenshin-Keeps/Egg_Quality_Prediction_ELMF4EggQ, promoting\ntransparency, reproducibility, and further research in this domain.", "AI": {"tldr": "该研究提出ELMF4EggQ框架，通过融合图像、形状和重量等外部特征，并结合集成学习，实现鸡蛋等级和新鲜度的无损评估，并发布了首个相关公开数据集。", "motivation": "确保食品安全、维持产品标准和提高商业家禽生产运营效率，需要准确、无损地评估鸡蛋质量。", "method": "构建了一个包含186个棕壳鸡蛋的新型公开数据集，其等级和新鲜度由实验室专家通过蛋黄指数和哈氏单位等内部质量测量确定。提出了ELMF4EggQ集成学习框架，该框架融合了从外部鸡蛋图像中提取的深度特征（使用预训练CNN模型如ResNet152、DenseNet169、ResNet152V2，并结合PCA降维和SMOTE增强）与结构特征（如鸡蛋形状和重量）。最终通过集成投票机制结合多个机器学习分类器的预测结果。", "result": "多模态方法显著优于仅使用图像或仅使用表格数据（形状和重量）的基线方法。多模态集成方法在鸡蛋等级分类中达到了86.57%的准确率，在新鲜度预测中达到了70.83%的准确率。所有代码和数据均已公开。", "conclusion": "ELMF4EggQ框架通过融合多模态外部特征和集成学习，能有效且无损地评估鸡蛋等级和新鲜度，表现优异。本研究首次将机器学习应用于仅使用外部非侵入性特征进行内部鸡蛋质量评估，并发布了相应的标记数据集，促进了该领域的透明度、可复现性和进一步研究。"}}
{"id": "2510.03123", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03123", "abs": "https://arxiv.org/abs/2510.03123", "authors": ["Zhe Shen"], "title": "Learning Stability Certificate for Robotics in Real-World Environments", "comment": null, "summary": "Stability certificates play a critical role in ensuring the safety and\nreliability of robotic systems. However, deriving these certificates for\ncomplex, unknown systems has traditionally required explicit knowledge of\nsystem dynamics, often making it a daunting task. This work introduces a novel\nframework that learns a Lyapunov function directly from trajectory data,\nenabling the certification of stability for autonomous systems without needing\ndetailed system models. By parameterizing the Lyapunov candidate using a neural\nnetwork and ensuring positive definiteness through Cholesky factorization, our\napproach automatically identifies whether the system is stable under the given\ntrajectory. To address the challenges posed by noisy, real-world data, we allow\nfor controlled violations of the stability condition, focusing on maintaining\nhigh confidence in the stability certification process. Our results demonstrate\nthat this framework can provide data-driven stability guarantees, offering a\nrobust method for certifying the safety of robotic systems in dynamic,\nreal-world environments. This approach works without access to the internal\ncontrol algorithms, making it applicable even in situations where system\nbehavior is opaque or proprietary. The tool for learning the stability proof is\nopen-sourced by this research: https://github.com/HansOersted/stability.", "AI": {"tldr": "本文提出一个新颖的框架，通过轨迹数据直接学习Lyapunov函数，从而在无需详细系统模型的情况下，为自主系统提供数据驱动的稳定性认证。", "motivation": "传统上，为复杂、未知系统推导稳定性证书需要明确的系统动力学知识，这通常是一项艰巨的任务。研究旨在解决这一挑战，实现无需系统模型的数据驱动稳定性认证。", "method": "该方法使用神经网络参数化Lyapunov候选函数，并通过Cholesky分解确保其正定性。为了应对真实世界数据的噪声，允许受控地违反稳定性条件，以保持高置信度的认证。核心是通过轨迹数据直接学习Lyapunov函数。", "result": "该框架能够提供数据驱动的稳定性保证，为动态、真实世界环境中的机器人系统提供了一种鲁棒的安全认证方法。它甚至在无法访问内部控制算法或系统行为不透明的情况下也适用。", "conclusion": "该研究提供了一个强大的数据驱动框架，用于在缺乏系统动力学模型的情况下，对机器人系统进行稳定性认证，增强了复杂系统的安全性和可靠性。相关的稳定性证明学习工具已开源。"}}
{"id": "2510.02358", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02358", "abs": "https://arxiv.org/abs/2510.02358", "authors": ["Guanghao Li", "Zhihui Fu", "Min Fang", "Qibin Zhao", "Ming Tang", "Chun Yuan", "Jun Wang"], "title": "DiffuSpec: Unlocking Diffusion Language Models for Speculative Decoding", "comment": null, "summary": "As large language models (LLMs) scale up, accuracy improves, but the\nautoregressive (AR) nature of decoding increases latency since each token\nrequires a serial forward pass. Speculative decoding addresses this by\nemploying a fast drafter to propose multi-token drafts, which are then verified\nin parallel by the target model. However, many deployments still rely on AR\ndrafters, where sequential passes limit wall-clock gains. We revisit the\ndrafting stage and present DiffuSpec, a training-free drop-in framework that\nuses a pretrained diffusion language model (DLM) to produce multi-token drafts\nin a single forward pass, while remaining compatible with standard AR\nverifiers. Because DLM drafts are generated under bidirectional conditioning,\nparallel per-position candidates form a token lattice in which the locally\nhighest-probability token at each position need not form a causal left-to-right\npath. Moreover, DLM drafting requires pre-specifying a draft length, inducing a\nspeed-quality trade-off. To address these challenges, we introduce two\npractical components: (i) a causal-consistency path search (CPS) over this\nlattice that extracts a left-to-right path aligned with AR verification; and\n(ii) an adaptive draft-length (ADL) controller that adjusts next proposal size\nbased on recent acceptance feedback and realized generated length. Across\nbenchmarks, DiffuSpec yields up to 3x wall-clock speedup, establishing\ndiffusion-based drafting as a robust alternative to autoregressive drafters for\nspeculative decoding.", "AI": {"tldr": "DiffuSpec提出了一种基于扩散语言模型（DLM）的推测解码草稿生成框架，实现了单次前向传播的多令牌草稿生成，并通过因果一致性路径搜索和自适应草稿长度控制器，将大型语言模型（LLM）的推理速度提升高达3倍。", "motivation": "随着大型语言模型（LLMs）规模的扩大，准确性提高，但自回归（AR）解码的本质导致延迟增加，因为每个令牌都需要串行前向传播。推测解码通过使用快速的草稿模型来提出多令牌草稿，然后由目标模型并行验证来解决这个问题。然而，许多部署仍然依赖AR草稿模型，其顺序传递限制了实际时间增益。", "method": "本文提出了DiffuSpec，一个无需训练的即插即用框架，它使用预训练的扩散语言模型（DLM）在单次前向传播中生成多令牌草稿，同时与标准的AR验证器兼容。为了解决DLM草稿在双向条件下生成且需要预先指定草稿长度的挑战，DiffuSpec引入了两个关键组件：(i) 因果一致性路径搜索（CPS），用于从DLM生成的令牌格中提取与AR验证对齐的从左到右路径；(ii) 自适应草稿长度（ADL）控制器，根据最近的接受反馈和实际生成长度调整下一个提议的大小。", "result": "在各项基准测试中，DiffuSpec实现了高达3倍的实际时间加速。", "conclusion": "DiffuSpec确立了基于扩散模型的草稿生成作为推测解码中自回归草稿生成器的一种强大替代方案。"}}
{"id": "2205.03569", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2205.03569", "abs": "https://arxiv.org/abs/2205.03569", "authors": ["Bing Li", "Jiaxin Chen", "Dongming Zhang", "Xiuguo Bao", "Di Huang"], "title": "Representation Learning for Compressed Video Action Recognition via Attentive Cross-modal Interaction with Motion Enhancement", "comment": "Accepted to IJCAI 2022", "summary": "Compressed video action recognition has recently drawn growing attention,\nsince it remarkably reduces the storage and computational cost via replacing\nraw videos by sparsely sampled RGB frames and compressed motion cues (e.g.,\nmotion vectors and residuals). However, this task severely suffers from the\ncoarse and noisy dynamics and the insufficient fusion of the heterogeneous RGB\nand motion modalities. To address the two issues above, this paper proposes a\nnovel framework, namely Attentive Cross-modal Interaction Network with Motion\nEnhancement (MEACI-Net). It follows the two-stream architecture, i.e. one for\nthe RGB modality and the other for the motion modality. Particularly, the\nmotion stream employs a multi-scale block embedded with a denoising module to\nenhance representation learning. The interaction between the two streams is\nthen strengthened by introducing the Selective Motion Complement (SMC) and\nCross-Modality Augment (CMA) modules, where SMC complements the RGB modality\nwith spatio-temporally attentive local motion features and CMA further combines\nthe two modalities with selective feature augmentation. Extensive experiments\non the UCF-101, HMDB-51 and Kinetics-400 benchmarks demonstrate the\neffectiveness and efficiency of MEACI-Net.", "AI": {"tldr": "本文提出了一种名为MEACI-Net的新型框架，用于压缩视频动作识别，通过增强运动表示和改进异构模态（RGB和运动）间的交互，解决了粗糙和嘈杂的动态问题以及模态融合不足的问题。", "motivation": "压缩视频动作识别任务面临两个主要挑战：1) 动态信息粗糙且嘈杂；2) 异构的RGB和运动模态融合不充分。", "method": "MEACI-Net采用双流架构，分别处理RGB和运动模态。运动流使用嵌入去噪模块的多尺度块来增强表示学习。RGB和运动流之间的交互通过选择性运动互补（SMC）模块（用时空注意力局部运动特征补充RGB模态）和跨模态增强（CMA）模块（通过选择性特征增强进一步结合两种模态）来加强。", "result": "在UCF-101、HMDB-51和Kinetics-400基准上的大量实验证明了MEACI-Net的有效性和效率。", "conclusion": "MEACI-Net通过其独特的运动增强和跨模态交互机制，显著提高了压缩视频动作识别的性能和效率，成功解决了该领域的核心挑战。"}}
{"id": "2510.02898", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02898", "abs": "https://arxiv.org/abs/2510.02898", "authors": ["Lorenzo Bianchi", "Giacomo Pacini", "Fabio Carrara", "Nicola Messina", "Giuseppe Amato", "Fabrizio Falchi"], "title": "One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework", "comment": null, "summary": "Zero-shot captioners are recently proposed models that utilize common-space\nvision-language representations to caption images without relying on paired\nimage-text data. To caption an image, they proceed by textually decoding a\ntext-aligned image feature, but they limit their scope to global\nrepresentations and whole-image captions. We present \\frameworkName{}, a\nunified framework for zero-shot captioning that shifts from an image-centric to\na patch-centric paradigm, enabling the captioning of arbitrary regions without\nthe need of region-level supervision. Instead of relying on global image\nrepresentations, we treat individual patches as atomic captioning units and\naggregate them to describe arbitrary regions, from single patches to\nnon-contiguous areas and entire images. We analyze the key ingredients that\nenable current latent captioners to work in our novel proposed framework.\nExperiments demonstrate that backbones producing meaningful, dense visual\nfeatures, such as DINO, are key to achieving state-of-the-art performance in\nmultiple region-based captioning tasks. Compared to other baselines and\nstate-of-the-art competitors, our models achieve better performance on\nzero-shot dense, region-set, and a newly introduced trace captioning task,\nhighlighting the effectiveness of patch-wise semantic representations for\nscalable caption generation. Project page at https://paciosoft.com/Patch-ioner/ .", "AI": {"tldr": "本文提出一个名为“Patch-ioner”的零样本区域图像描述框架，通过将图像分解为补丁（patch-centric）而非整体（image-centric）来描述任意区域，无需区域级监督，并实现了最先进的性能。", "motivation": "现有零样本图像描述模型仅限于全局表示和整图描述，无法对图像的任意区域进行描述，且需要区域级监督。因此，需要一种能够进行区域级描述且无需区域级监督的方法。", "method": "本文提出“Patch-ioner”框架，将范式从以图像为中心转向以补丁为中心。它将单个补丁视为原子描述单元，并通过聚合这些补丁来描述从单个补丁到非连续区域乃至整个图像的任意区域。该框架分析了现有潜在描述器在这种新范式下工作的关键要素。", "result": "实验表明，生成有意义、密集视觉特征的骨干网络（如DINO）对于在多项基于区域的描述任务中实现最先进的性能至关重要。与基线和其他最先进的竞争对手相比，本文模型在零样本密集、区域集和新引入的轨迹描述任务上均取得了更好的性能。", "conclusion": "补丁级语义表示对于可扩展的描述生成是有效的，能够实现对任意区域的精细描述，而无需依赖区域级监督。"}}
{"id": "2510.03142", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03142", "abs": "https://arxiv.org/abs/2510.03142", "authors": ["Tianyu Xu", "Jiawei Chen", "Jiazhao Zhang", "Wenyao Zhang", "Zekun Qi", "Minghan Li", "Zhizheng Zhang", "He Wang"], "title": "MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning", "comment": "Project page: https://pku-epic.github.io/MM-Nav-Web/", "summary": "Visual navigation policy is widely regarded as a promising direction, as it\nmimics humans by using egocentric visual observations for navigation. However,\noptical information of visual observations is difficult to be explicitly\nmodeled like LiDAR point clouds or depth maps, which subsequently requires\nintelligent models and large-scale data. To this end, we propose to leverage\nthe intelligence of the Vision-Language-Action (VLA) model to learn diverse\nnavigation capabilities from synthetic expert data in a teacher-student manner.\nSpecifically, we implement the VLA model, MM-Nav, as a multi-view VLA (with 360\nobservations) based on pretrained large language models and visual foundation\nmodels. For large-scale navigation data, we collect expert data from three\nreinforcement learning (RL) experts trained with privileged depth information\nin three challenging tailor-made environments for different navigation\ncapabilities: reaching, squeezing, and avoiding. We iteratively train our VLA\nmodel using data collected online from RL experts, where the training ratio is\ndynamically balanced based on performance on individual capabilities. Through\nextensive experiments in synthetic environments, we demonstrate that our model\nachieves strong generalization capability. Moreover, we find that our student\nVLA model outperforms the RL teachers, demonstrating the synergistic effect of\nintegrating multiple capabilities. Extensive real-world experiments further\nconfirm the effectiveness of our method.", "AI": {"tldr": "本文提出了一种名为MM-Nav的视觉-语言-动作（VLA）模型，通过教师-学生学习范式，利用合成的强化学习专家数据，学习多样化的视觉导航能力。该模型在合成和真实环境中都展现出强大的泛化能力，甚至超越了其强化学习教师。", "motivation": "视觉导航策略因其模仿人类使用自我中心视觉观察进行导航的特点而备受关注。然而，视觉观察的光学信息难以像LiDAR点云或深度图那样被明确建模，这需要智能模型和大规模数据来克服。", "method": "本文提出了MM-Nav，一个基于预训练大型语言模型和视觉基础模型的多视角VLA模型（使用360度观察）。为了获取大规模导航数据，作者从三个在定制环境中（用于到达、挤压和避障）训练的强化学习（RL）专家（拥有特权深度信息）那里收集了专家数据。通过在线收集RL专家数据，并根据单个能力的表现动态平衡训练比例，迭代地训练VLA模型。", "result": "在合成环境中进行的广泛实验表明，该模型具有强大的泛化能力。此外，研究发现学生VLA模型优于RL教师，证明了整合多种能力的协同效应。广泛的真实世界实验进一步证实了该方法的有效性。", "conclusion": "通过利用VLA模型的智能和大规模合成专家数据，本文成功地训练了一个能够学习多样化导航能力的视觉导航策略。该模型不仅展现出强大的泛化能力，而且在性能上超越了其RL教师，证明了VLA模型在视觉导航领域的巨大潜力。"}}
{"id": "2510.02359", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02359", "abs": "https://arxiv.org/abs/2510.02359", "authors": ["Jiashu Ye", "Tong Wu", "Weiwen Chen", "Hao Zhang", "Zeteng Lin", "Xingxing Li", "Shujuan Weng", "Manni Zhu", "Xin Yuan", "Xinlong Hong", "Jingjie Li", "Junyu Zheng", "Zhijiong Huang", "Jing Tang"], "title": "Emission-GPT: A domain-specific language model agent for knowledge retrieval, emission inventory and data analysis", "comment": null, "summary": "Improving air quality and addressing climate change relies on accurate\nunderstanding and analysis of air pollutant and greenhouse gas emissions.\nHowever, emission-related knowledge is often fragmented and highly specialized,\nwhile existing methods for accessing and compiling emissions data remain\ninefficient. These issues hinder the ability of non-experts to interpret\nemissions information, posing challenges to research and management. To address\nthis, we present Emission-GPT, a knowledge-enhanced large language model agent\ntailored for the atmospheric emissions domain. Built on a curated knowledge\nbase of over 10,000 documents (including standards, reports, guidebooks, and\npeer-reviewed literature), Emission-GPT integrates prompt engineering and\nquestion completion to support accurate domain-specific question answering.\nEmission-GPT also enables users to interactively analyze emissions data via\nnatural language, such as querying and visualizing inventories, analyzing\nsource contributions, and recommending emission factors for user-defined\nscenarios. A case study in Guangdong Province demonstrates that Emission-GPT\ncan extract key insights--such as point source distributions and sectoral\ntrends--directly from raw data with simple prompts. Its modular and extensible\narchitecture facilitates automation of traditionally manual workflows,\npositioning Emission-GPT as a foundational tool for next-generation emission\ninventory development and scenario-based assessment.", "AI": {"tldr": "本文提出了Emission-GPT，一个为大气排放领域量身定制的知识增强型大型语言模型代理，旨在解决排放知识碎片化和数据访问效率低下的问题，并通过自然语言交互提供准确的领域特定问答和数据分析能力。", "motivation": "空气质量改善和气候变化应对依赖于对空气污染物和温室气体排放的准确理解和分析。然而，排放相关知识通常碎片化且高度专业化，现有数据获取和编译方法效率低下，阻碍了非专业人士解读排放信息，对研究和管理构成挑战。", "method": "研究构建了Emission-GPT，一个基于精选知识库（包含超过10,000份文档，如标准、报告、指南和同行评审文献）的大型语言模型代理。它集成了提示工程和问题补全技术以支持准确的领域特定问答，并允许用户通过自然语言互动分析排放数据，如查询和可视化清单、分析来源贡献以及推荐用户定义情景的排放因子。", "result": "Emission-GPT能够支持准确的领域特定问答，并使用户通过自然语言交互分析排放数据。在广东省的案例研究表明，Emission-GPT可以通过简单的提示直接从原始数据中提取关键见解，如点源分布和部门趋势。", "conclusion": "Emission-GPT的模块化和可扩展架构有助于自动化传统上手动的工作流程，使其成为下一代排放清单开发和情景评估的基础工具。"}}
{"id": "2510.02909", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02909", "abs": "https://arxiv.org/abs/2510.02909", "authors": ["Laith Nayal", "Hadi Salloum", "Ahmad Taha", "Yaroslav Kholodov", "Alexander Gasnikov"], "title": "Training-Free Out-Of-Distribution Segmentation With Foundation Models", "comment": "12 pages, 5 figures, 2 tables, ICOMP 2025", "summary": "Detecting unknown objects in semantic segmentation is crucial for\nsafety-critical applications such as autonomous driving. Large vision\nfoundation models, including DINOv2, InternImage, and CLIP, have advanced\nvisual representation learning by providing rich features that generalize well\nacross diverse tasks. While their strength in closed-set semantic tasks is\nestablished, their capability to detect out-of-distribution (OoD) regions in\nsemantic segmentation remains underexplored. In this work, we investigate\nwhether foundation models fine-tuned on segmentation datasets can inherently\ndistinguish in-distribution (ID) from OoD regions without any outlier\nsupervision. We propose a simple, training-free approach that utilizes features\nfrom the InternImage backbone and applies K-Means clustering alongside\nconfidence thresholding on raw decoder logits to identify OoD clusters. Our\nmethod achieves 50.02 Average Precision on the RoadAnomaly benchmark and 48.77\non the benchmark of ADE-OoD with InternImage-L, surpassing several supervised\nand unsupervised baselines. These results suggest a promising direction for\ngeneric OoD segmentation methods that require minimal assumptions or additional\ndata.", "AI": {"tldr": "本文研究了经过语义分割微调的视觉基础模型（如InternImage）在无需异常值监督的情况下，区分分布内（ID）和分布外（OoD）区域的能力，并提出了一种简单、免训练的方法，在OoD检测任务上取得了优异性能。", "motivation": "在自动驾驶等安全关键应用中，语义分割中检测未知对象至关重要。尽管大型视觉基础模型在封闭集语义任务中表现出色，但其在语义分割中检测分布外（OoD）区域的能力尚未得到充分探索。", "method": "本文提出了一种简单、免训练的方法。该方法利用InternImage骨干网络的特征，并结合K-Means聚类和对原始解码器logits的置信度阈值处理来识别OoD聚类。", "result": "使用InternImage-L，该方法在RoadAnomaly基准测试中取得了50.02的平均精度（AP），在ADE-OoD基准测试中取得了48.77的AP，超越了多个有监督和无监督的基线方法。", "conclusion": "研究结果表明，经过语义分割数据集微调的基础模型能够固有地区分分布内（ID）和分布外（OoD）区域，为通用OoD分割方法提供了一个有前景的方向，这些方法只需最少的假设或额外数据。"}}
{"id": "2510.03169", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03169", "abs": "https://arxiv.org/abs/2510.03169", "authors": ["Duanjiao Li", "Yun Chen", "Ying Zhang", "Junwen Yao", "Dongyue Huang", "Jianguo Zhang", "Ning Ding"], "title": "Optimal Smooth Coverage Trajectory Planning for Quadrotors in Cluttered Environment", "comment": "This paper has been accepted for publication in the 44th Chinese\n  Control Conference, 2025. Please cite the paper using appropriate formats", "summary": "For typical applications of UAVs in power grid scenarios, we construct the\nproblem as planning UAV trajectories for coverage in cluttered environments. In\nthis paper, we propose an optimal smooth coverage trajectory planning\nalgorithm. The algorithm consists of two stages. In the front-end, a Genetic\nAlgorithm (GA) is employed to solve the Traveling Salesman Problem (TSP) for\nPoints of Interest (POIs), generating an initial sequence of optimized visiting\npoints. In the back-end, the sequence is further optimized by considering\ntrajectory smoothness, time consumption, and obstacle avoidance. This is\nformulated as a nonlinear least squares problem and solved to produce a smooth\ncoverage trajectory that satisfies these constraints. Numerical simulations\nvalidate the effectiveness of the proposed algorithm, ensuring UAVs can\nsmoothly cover all POIs in cluttered environments.", "AI": {"tldr": "本文提出了一种用于无人机在复杂电网环境中实现平滑覆盖轨迹规划的最优算法。", "motivation": "无人机在电网场景中的典型应用需要解决在复杂环境中进行覆盖轨迹规划的问题。", "method": "该算法分为两阶段：前端使用遗传算法（GA）解决兴趣点（POIs）的旅行商问题（TSP），生成初始优化访问序列；后端将该序列进一步优化，考虑轨迹平滑度、时间消耗和避障，将其表述为非线性最小二乘问题并求解，以生成满足约束的平滑覆盖轨迹。", "result": "数值模拟验证了所提算法的有效性，确保无人机能够在复杂环境中平稳覆盖所有兴趣点。", "conclusion": "所提出的算法能够为无人机在复杂电网场景中规划出最优的平滑覆盖轨迹。"}}
{"id": "2510.02360", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02360", "abs": "https://arxiv.org/abs/2510.02360", "authors": ["Mingze Zhong", "Meng Fang", "Zijing Shi", "Yuxuan Huang", "Shunfeng Zheng", "Yali Du", "Ling Chen", "Jun Wang"], "title": "Spiral of Silence in Large Language Model Agents", "comment": null, "summary": "The Spiral of Silence (SoS) theory holds that individuals with minority views\noften refrain from speaking out for fear of social isolation, enabling majority\npositions to dominate public discourse. When the 'agents' are large language\nmodels (LLMs), however, the classical psychological explanation is not directly\napplicable, since SoS was developed for human societies. This raises a central\nquestion: can SoS-like dynamics nevertheless emerge from purely statistical\nlanguage generation in LLM collectives? We propose an evaluation framework for\nexamining SoS in LLM agents. Specifically, we consider four controlled\nconditions that systematically vary the availability of 'History' and 'Persona'\nsignals. Opinion dynamics are assessed using trend tests such as Mann-Kendall\nand Spearman's rank, along with concentration measures including kurtosis and\ninterquartile range. Experiments across open-source and closed-source models\nshow that history and persona together produce strong majority dominance and\nreplicate SoS patterns; history signals alone induce strong anchoring; and\npersona signals alone foster diverse but uncorrelated opinions, indicating that\nwithout historical anchoring, SoS dynamics cannot emerge. The work bridges\ncomputational sociology and responsible AI design, highlighting the need to\nmonitor and mitigate emergent conformity in LLM-agent systems.", "AI": {"tldr": "本研究探索了“沉默的螺旋”理论在大型语言模型（LLM）群体中的表现。结果显示，历史和个性信号共同作用，能使LLM群体中出现多数意见主导并复制沉默螺旋模式；而仅有历史信号会导致意见锚定，仅有个性信号则会产生多样但无关联的意见，表明历史锚定是沉默螺旋现象产生的关键。", "motivation": "经典的“沉默的螺旋”理论是为人类社会设计的，其心理学解释不直接适用于LLM。因此，研究的动机是探讨这种类似沉默螺旋的动态是否能从LLM集体纯粹的统计语言生成中涌现出来。", "method": "研究提出了一个评估LLM智能体中沉默螺旋现象的框架。具体通过四种受控条件系统地改变“历史”和“个性”信号的可用性。意见动态通过曼-肯德尔和斯皮尔曼等级相关等趋势检验以及峰度和四分位距等集中度度量进行评估。实验在开源和闭源模型上进行。", "result": "实验结果表明，历史和个性信号共同作用时，能产生强大的多数意见主导并复制沉默螺旋模式；单独的历史信号会引发强烈的意见锚定；而单独的个性信号则会促进多样但无关联的意见，这表明如果没有历史锚定，沉默螺旋的动态无法出现。", "conclusion": "这项工作连接了计算社会学和负责任的AI设计，强调了监测和缓解LLM智能体系统中可能出现的从众行为的必要性。"}}
{"id": "2510.02361", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02361", "abs": "https://arxiv.org/abs/2510.02361", "authors": ["Haojie Ouyang", "Jianwei Lv", "Lei Ren", "Chen Wei", "Xiaojie Wang", "Fangxiang Feng"], "title": "ChunkLLM: A Lightweight Pluggable Framework for Accelerating LLMs Inference", "comment": null, "summary": "Transformer-based large models excel in natural language processing and\ncomputer vision, but face severe computational inefficiencies due to the\nself-attention's quadratic complexity with input tokens. Recently, researchers\nhave proposed a series of methods based on block selection and compression to\nalleviate this problem, but they either have issues with semantic\nincompleteness or poor training-inference efficiency. To comprehensively\naddress these challenges, we propose ChunkLLM, a lightweight and pluggable\ntraining framework. Specifically, we introduce two components: QK Adapter\n(Q-Adapter and K-Adapter) and Chunk Adapter. The former is attached to each\nTransformer layer, serving dual purposes of feature compression and chunk\nattention acquisition. The latter operates at the bottommost layer of the\nmodel, functioning to detect chunk boundaries by leveraging contextual semantic\ninformation. During the training phase, the parameters of the backbone remain\nfrozen, with only the QK Adapter and Chunk Adapter undergoing training.\nNotably, we design an attention distillation method for training the QK\nAdapter, which enhances the recall rate of key chunks. During the inference\nphase, chunk selection is triggered exclusively when the current token is\ndetected as a chunk boundary, thereby accelerating model inference.\nExperimental evaluations are conducted on a diverse set of long-text and\nshort-text benchmark datasets spanning multiple tasks. ChunkLLM not only\nattains comparable performance on short-text benchmarks but also maintains\n98.64% of the performance on long-context benchmarks while preserving a 48.58%\nkey-value cache retention rate. Particularly, ChunkLLM attains a maximum\nspeedup of 4.48x in comparison to the vanilla Transformer in the processing of\n120K long texts.", "AI": {"tldr": "ChunkLLM是一个轻量级可插拔训练框架，旨在解决Transformer自注意力机制的二次复杂度导致的计算效率低下问题。它通过引入QK Adapter进行特征压缩和Chunk Adapter进行块边界检测，显著提升了长文本处理速度（最高4.48倍），同时保持了可比的性能。", "motivation": "Transformer模型在自然语言处理和计算机视觉领域表现出色，但其自注意力机制的二次复杂度导致严重的计算效率低下，尤其是在处理长输入序列时。现有基于块选择和压缩的方法存在语义不完整或训练/推理效率不佳的问题。", "method": "本文提出了ChunkLLM，一个轻量级且可插拔的训练框架。它包含两个核心组件：1) QK Adapter（Q-Adapter和K-Adapter），附加到每个Transformer层，用于特征压缩和获取块注意力；2) Chunk Adapter，位于模型最底层，利用上下文语义信息检测块边界。在训练阶段，主干模型的参数保持冻结，仅训练QK Adapter和Chunk Adapter，并采用注意力蒸馏方法来提高QK Adapter对关键块的召回率。在推理阶段，仅当当前token被检测为块边界时才触发块选择，从而加速模型推理。", "result": "ChunkLLM在短文本基准测试上取得了可比的性能，在长上下文基准测试上保持了98.64%的性能，并实现了48.58%的键值缓存保留率。特别是在处理120K长文本时，ChunkLLM与原始Transformer相比，最大加速比达到了4.48倍。", "conclusion": "ChunkLLM通过其创新的QK Adapter和Chunk Adapter设计，以及有效的训练策略，成功解决了Transformer自注意力机制的计算效率瓶颈。它在显著加速长文本处理的同时，保持了高水平的性能，为Transformer模型在处理长序列任务时提供了一个高效且实用的解决方案。"}}
{"id": "2510.02912", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02912", "abs": "https://arxiv.org/abs/2510.02912", "authors": ["Xin Zou", "Di Lu", "Yizhou Wang", "Yibo Yan", "Yuanhuiyi Lyu", "Xu Zheng", "Linfeng Zhang", "Xuming Hu"], "title": "Don't Just Chase \"Highlighted Tokens\" in MLLMs: Revisiting Visual Holistic Context Retention", "comment": "Accepted by NeurIPS 2025 main", "summary": "Despite their powerful capabilities, Multimodal Large Language Models (MLLMs)\nsuffer from considerable computational overhead due to their reliance on\nmassive visual tokens. Recent studies have explored token pruning to alleviate\nthis problem, which typically uses text-vision cross-attention or\n[\\texttt{CLS}] attention to assess and discard redundant visual tokens. In this\nwork, we identify a critical limitation of such attention-first pruning\napproaches, i.e., they tend to preserve semantically similar tokens, resulting\nin pronounced performance drops under high pruning ratios. To this end, we\npropose {HoloV}, a simple yet effective, plug-and-play visual token pruning\nframework for efficient inference. Distinct from previous attention-first\nschemes, HoloV rethinks token retention from a holistic perspective. By\nadaptively distributing the pruning budget across different spatial crops,\nHoloV ensures that the retained tokens capture the global visual context rather\nthan isolated salient features. This strategy minimizes representational\ncollapse and maintains task-relevant information even under aggressive pruning.\nExperimental results demonstrate that our HoloV achieves superior performance\nacross various tasks, MLLM architectures, and pruning ratios compared to SOTA\nmethods. For instance, LLaVA1.5 equipped with HoloV preserves 95.8\\% of the\noriginal performance after pruning 88.9\\% of visual tokens, achieving superior\nefficiency-accuracy trade-offs.", "AI": {"tldr": "多模态大语言模型（MLLMs）因视觉令牌数量庞大而计算开销巨大。现有剪枝方法倾向于保留语义相似的令牌，导致高剪枝率下性能下降。本文提出HoloV，一种即插即用的视觉令牌剪枝框架，通过自适应地在不同空间裁剪中分配剪枝预算，从整体角度保留令牌，确保捕获全局视觉上下文，从而在大幅剪枝下仍保持卓越性能和效率-准确性权衡。", "motivation": "多模态大语言模型（MLLMs）由于依赖海量视觉令牌而导致巨大的计算开销。现有的令牌剪枝方法通常使用文本-视觉交叉注意力或[CLS]注意力来评估和丢弃冗余视觉令牌，但这种“注意力优先”的剪枝方法存在一个关键限制，即它们倾向于保留语义相似的令牌，导致在高剪枝率下性能显著下降。", "method": "本文提出了HoloV，一个简单而有效的即插即用视觉令牌剪枝框架，用于高效推理。与以往的“注意力优先”方案不同，HoloV从整体角度重新思考令牌保留策略。它通过自适应地在不同空间裁剪中分配剪枝预算，确保保留的令牌能够捕获全局视觉上下文，而非孤立的显著特征。这种策略最大限度地减少了表征崩溃，即使在激进的剪枝下也能保持与任务相关的信息。", "result": "实验结果表明，与SOTA方法相比，HoloV在各种任务、MLLM架构和剪枝率下均实现了卓越的性能。例如，配备HoloV的LLaVA1.5在剪枝88.9%视觉令牌后仍保留了95.8%的原始性能，实现了更优的效率-准确性权衡。", "conclusion": "HoloV通过采用整体的、空间感知的剪枝策略，有效解决了现有“注意力优先”剪枝方法保留语义相似令牌的局限性。它通过确保保留的令牌捕获全局视觉上下文，即使在激进剪枝下也能保持任务相关信息，从而为MLLMs提供了卓越的性能和效率-准确性权衡。"}}
{"id": "2510.03182", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.SC"], "pdf": "https://arxiv.org/pdf/2510.03182", "abs": "https://arxiv.org/abs/2510.03182", "authors": ["Yilun Hao", "Yongchao Chen", "Chuchu Fan", "Yang Zhang"], "title": "Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning", "comment": "30 pages, 5 figures, 5 tables", "summary": "Vision Language Models (VLMs) show strong potential for visual planning but\nstruggle with precise spatial and long-horizon reasoning. In contrast, Planning\nDomain Definition Language (PDDL) planners excel at long-horizon formal\nplanning, but cannot interpret visual inputs. Recent works combine these\ncomplementary advantages by enabling VLMs to turn visual planning problems into\nPDDL files for formal planning. However, while VLMs can generate PDDL problem\nfiles satisfactorily, they struggle to accurately generate the PDDL domain\nfiles, which describe all the planning rules. As a result, prior methods rely\non human experts to predefine domain files or on constant environment access\nfor refinement. We propose VLMFP, a Dual-VLM-guided framework that can\nautonomously generate both PDDL problem and domain files for formal visual\nplanning. VLMFP introduces two VLMs to ensure reliable PDDL file generation: A\nSimVLM that simulates action consequences based on input rule descriptions, and\na GenVLM that generates and iteratively refines PDDL files by comparing the\nPDDL and SimVLM execution results. VLMFP unleashes multiple levels of\ngeneralizability: The same generated PDDL domain file works for all the\ndifferent instances under the same problem, and VLMs generalize to different\nproblems with varied appearances and rules. We evaluate VLMFP with 6 grid-world\ndomains and test its generalization to unseen instances, appearance, and game\nrules. On average, SimVLM accurately describes 95.5%, 82.6% of scenarios,\nsimulates 85.5%, 87.8% of action sequence, and judges 82.4%, 85.6% goal\nreaching for seen and unseen appearances, respectively. With the guidance of\nSimVLM, VLMFP can generate PDDL files to reach 70.0%, 54.1% valid plans for\nunseen instances in seen and unseen appearances, respectively. Project page:\nhttps://sites.google.com/view/vlmfp.", "AI": {"tldr": "VLMFP是一个双VLM框架，能自主生成视觉规划所需的PDDL问题和领域文件，克服了VLM在生成PDDL领域文件方面的不足，并实现了对未见实例、外观和规则的泛化。", "motivation": "视觉语言模型（VLM）在视觉规划方面潜力巨大，但难以进行精确的空间和长时程推理。PDDL规划器擅长长时程形式规划，却无法解释视觉输入。现有方法尝试结合两者，让VLM生成PDDL文件，但VLM难以准确生成描述规划规则的PDDL领域文件，导致需要人工预定义或持续环境访问来完善。", "method": "本文提出了VLMFP框架，一个由双VLM引导的框架，可自主生成PDDL问题和领域文件。它引入了两个VLM：一个SimVLM，根据输入规则描述模拟动作后果；一个GenVLM，通过比较PDDL和SimVLM的执行结果来生成并迭代细化PDDL文件。", "result": "VLMFP实现了多层次的泛化：同一个PDDL领域文件适用于同一问题下的所有不同实例，VLM能泛化到外观和规则不同的问题。在6个网格世界领域中，SimVLM对已见/未见外观的场景描述准确率分别为95.5%/82.6%，动作序列模拟准确率分别为85.5%/87.8%，目标达成判断准确率分别为82.4%/85.6%。在SimVLM的指导下，VLMFP能为已见/未见外观下的未见实例生成70.0%/54.1%的有效计划。", "conclusion": "VLMFP成功地通过双VLM方法，解决了视觉规划中自主生成PDDL领域文件的挑战，显著提升了模型对未见实例、外观和规则的泛化能力，为形式化视觉规划提供了可靠的解决方案。"}}
{"id": "2510.02362", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02362", "abs": "https://arxiv.org/abs/2510.02362", "authors": ["Matei-Iulian Cocu", "Răzvan-Cosmin Cristia", "Adrian Marius Dumitran"], "title": "A Cross-Lingual Analysis of Bias in Large Language Models Using Romanian History", "comment": "10 pages", "summary": "In this case study, we select a set of controversial Romanian historical\nquestions and ask multiple Large Language Models to answer them across\nlanguages and contexts, in order to assess their biases. Besides being a study\nmainly performed for educational purposes, the motivation also lies in the\nrecognition that history is often presented through altered perspectives,\nprimarily influenced by the culture and ideals of a state, even through large\nlanguage models. Since they are often trained on certain data sets that may\npresent certain ambiguities, the lack of neutrality is subsequently instilled\nin users. The research process was carried out in three stages, to confirm the\nidea that the type of response expected can influence, to a certain extent, the\nresponse itself; after providing an affirmative answer to some given question,\nan LLM could shift its way of thinking after being asked the same question\nagain, but being told to respond with a numerical value of a scale. Results\nshow that binary response stability is relatively high but far from perfect and\nvaries by language. Models often flip stance across languages or between\nformats; numeric ratings frequently diverge from the initial binary choice, and\nthe most consistent models are not always those judged most accurate or\nneutral. Our research brings to light the predisposition of models to such\ninconsistencies, within a specific contextualization of the language for the\nquestion asked.", "AI": {"tldr": "本案例研究通过让大型语言模型（LLMs）回答有争议的罗马尼亚历史问题，评估了它们在不同语言和语境下的偏见，发现模型在回答一致性和中立性方面存在显著不稳定性。", "motivation": "研究动机在于认识到历史常常通过扭曲的视角呈现，即使是大型语言模型也可能受到文化和国家理想的影响，缺乏中立性，因为它们通常在可能存在歧义的数据集上训练，从而将这种不中立性传递给用户。此外，研究也出于教育目的。", "method": "研究选择了有争议的罗马尼亚历史问题，并要求多个大型语言模型在不同语言和语境下回答。研究过程分为三个阶段，旨在确认预期响应类型对响应本身的影响：首先是肯定性回答，然后再次询问相同问题但要求以数值尺度响应，以观察模型思维方式是否转变。", "result": "结果显示，二元响应的稳定性相对较高但不完美，且因语言而异。模型经常在不同语言或不同格式（二元与数值）之间改变立场；数值评分频繁偏离最初的二元选择；最一致的模型并非总是被判断为最准确或最中立的模型。研究揭示了模型在特定语言语境下对这些不一致性的倾向。", "conclusion": "研究得出结论，大型语言模型在处理有争议的历史问题时，在不同语言、语境和响应格式下表现出显著的不一致性和偏见，这凸显了其训练数据可能导致的中立性缺失，并对用户产生影响。"}}
{"id": "2510.02369", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02369", "abs": "https://arxiv.org/abs/2510.02369", "authors": ["Kuntai Cai", "Juncheng Liu", "Xianglin Yang", "Zhaojie Niu", "Xiaokui Xiao", "Xing Chen"], "title": "Beyond Manuals and Tasks: Instance-Level Context Learning for LLM Agents", "comment": "Under review at ICLR 2026", "summary": "Large language model (LLM) agents typically receive two kinds of context: (i)\nenvironment-level manuals that define interaction interfaces and global rules,\nand (ii) task-level guidance or demonstrations tied to specific goals. In this\nwork, we identify a crucial but overlooked third type of context,\ninstance-level context, which consists of verifiable and reusable facts tied to\na specific environment instance, such as object locations, crafting recipes,\nand local rules. We argue that the absence of instance-level context is a\ncommon source of failure for LLM agents in complex tasks, as success often\ndepends not only on reasoning over global rules or task prompts but also on\nmaking decisions based on precise and persistent facts. Acquiring such context\nrequires more than memorization: the challenge lies in efficiently exploring,\nvalidating, and formatting these facts under tight interaction budgets. We\nformalize this problem as Instance-Level Context Learning (ILCL) and introduce\nour task-agnostic method to solve it. Our method performs a guided exploration,\nusing a compact TODO forest to intelligently prioritize its next actions and a\nlightweight plan-act-extract loop to execute them. This process automatically\nproduces a high-precision context document that is reusable across many\ndownstream tasks and agents, thereby amortizing the initial exploration cost.\nExperiments across TextWorld, ALFWorld, and Crafter demonstrate consistent\ngains in both success and efficiency: for instance, ReAct's mean success rate\nin TextWorld rises from 37% to 95%, while IGE improves from 81% to 95%. By\ntransforming one-off exploration into persistent, reusable knowledge, our\nmethod complements existing contexts to enable more reliable and efficient LLM\nagents.", "AI": {"tldr": "本文提出了一种名为“实例级上下文学习（ILCL）”的方法，旨在为大型语言模型（LLM）智能体提供可验证和可重用的环境特定事实（实例级上下文），从而显著提高其在复杂任务中的成功率和效率。", "motivation": "LLM智能体在复杂任务中失败的一个主要原因是缺乏“实例级上下文”，即与特定环境实例相关的可验证和可重用事实（如物体位置、制作配方、局部规则）。现有上下文（环境手册、任务指导）不足以应对需要精确和持久事实的任务决策。获取此类上下文面临探索、验证和格式化的挑战，尤其是在交互预算有限的情况下。", "method": "作者将此问题形式化为实例级上下文学习（ILCL）。提出了一种任务无关的方法：通过引导式探索，利用紧凑的TODO森林智能地优先选择下一步行动，并使用轻量级的“规划-执行-提取”循环来执行。此过程自动生成一个高精度的上下文文档，该文档可在多个下游任务和智能体中重用，从而分摊了初始探索成本。", "result": "在TextWorld、ALFWorld和Crafter上的实验表明，该方法在成功率和效率方面均取得了显著提升。例如，ReAct在TextWorld中的平均成功率从37%提高到95%，而IGE从81%提高到95%。", "conclusion": "该方法将一次性探索转化为持久、可重用的知识，补充了现有上下文，从而使LLM智能体更加可靠和高效。"}}
{"id": "2510.02913", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02913", "abs": "https://arxiv.org/abs/2510.02913", "authors": ["Nikoo Naghavian", "Mostafa Tavassolipour"], "title": "Zero-Shot Robustness of Vision Language Models Via Confidence-Aware Weighting", "comment": "Accepted to the NeurIPS 2025 Workshop on Reliable ML from Unreliable\n  Data", "summary": "Vision-language models like CLIP demonstrate impressive zero-shot\ngeneralization but remain highly vulnerable to adversarial attacks. In this\nwork, we propose Confidence-Aware Weighting (CAW) to enhance zero-shot\nrobustness in vision-language models. CAW consists of two components: (1) a\nConfidence-Aware loss that prioritizes uncertain adversarial examples by\nscaling the KL divergence between clean and adversarial predictions, and (2) a\nfeature alignment regularization that preserves semantic consistency by\nminimizing the distance between frozen and fine-tuned image encoder features on\nadversarial inputs. These components work jointly to improve both clean and\nrobust accuracy without sacrificing generalization. Extensive experiments on\nTinyImageNet and 14 additional datasets show that CAW outperforms recent\nmethods such as PMG-AFT and TGA-ZSR under strong attacks like AutoAttack, while\nusing less memory.", "AI": {"tldr": "本文提出了一种名为置信度感知加权（CAW）的方法，旨在增强视觉-语言模型在零样本场景下对对抗性攻击的鲁棒性，同时保持泛化能力。", "motivation": "视觉-语言模型（如CLIP）虽然具有出色的零样本泛化能力，但对对抗性攻击高度脆弱。", "method": "CAW包含两个主要组件：1) 置信度感知损失，通过缩放干净预测和对抗性预测之间的KL散度来优先处理不确定的对抗性样本；2) 特征对齐正则化，通过最小化在对抗性输入上冻结和微调图像编码器特征之间的距离来保持语义一致性。", "result": "实验结果表明，CAW在TinyImageNet和14个额外数据集上，在AutoAttack等强攻击下，优于PMG-AFT和TGA-ZSR等现有方法，并且使用的内存更少。它在不牺牲泛化能力的情况下，同时提高了干净准确率和鲁棒准确率。", "conclusion": "CAW是一种有效且内存高效的方法，能够显著提高视觉-语言模型在零样本场景下对抗性攻击的鲁棒性，同时保持其泛化能力和准确性。"}}
{"id": "2510.03104", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03104", "abs": "https://arxiv.org/abs/2510.03104", "authors": ["Zhiting Mei", "Ola Shorinwa", "Anirudha Majumdar"], "title": "Geometry Meets Vision: Revisiting Pretrained Semantics in Distilled Fields", "comment": null, "summary": "Semantic distillation in radiance fields has spurred significant advances in\nopen-vocabulary robot policies, e.g., in manipulation and navigation, founded\non pretrained semantics from large vision models. While prior work has\ndemonstrated the effectiveness of visual-only semantic features (e.g., DINO and\nCLIP) in Gaussian Splatting and neural radiance fields, the potential benefit\nof geometry-grounding in distilled fields remains an open question. In\nprinciple, visual-geometry features seem very promising for spatial tasks such\nas pose estimation, prompting the question: Do geometry-grounded semantic\nfeatures offer an edge in distilled fields? Specifically, we ask three critical\nquestions: First, does spatial-grounding produce higher-fidelity geometry-aware\nsemantic features? We find that image features from geometry-grounded backbones\ncontain finer structural details compared to their counterparts. Secondly, does\ngeometry-grounding improve semantic object localization? We observe no\nsignificant difference in this task. Thirdly, does geometry-grounding enable\nhigher-accuracy radiance field inversion? Given the limitations of prior work\nand their lack of semantics integration, we propose a novel framework SPINE for\ninverting radiance fields without an initial guess, consisting of two core\ncomponents: coarse inversion using distilled semantics, and fine inversion\nusing photometric-based optimization. Surprisingly, we find that the pose\nestimation accuracy decreases with geometry-grounded features. Our results\nsuggest that visual-only features offer greater versatility for a broader range\nof downstream tasks, although geometry-grounded features contain more geometric\ndetail. Notably, our findings underscore the necessity of future research on\neffective strategies for geometry-grounding that augment the versatility and\nperformance of pretrained semantic features.", "AI": {"tldr": "本文探讨了几何感知语义特征在辐射场语义蒸馏中的优势，发现虽然几何感知特征包含更精细的结构细节，但在语义物体定位和辐射场反演（姿态估计）任务中，它们并未显示出显著优势，甚至在姿态估计中表现更差，表明纯视觉特征可能更具通用性。", "motivation": "先前的研究已证明纯视觉语义特征（如DINO和CLIP）在辐射场中的有效性。然而，几何感知（geometry-grounding）在蒸馏辐射场中的潜在益处仍是一个悬而未决的问题。鉴于视觉-几何特征在姿态估计等空间任务中的巨大潜力，本文旨在探究几何感知语义特征是否能在蒸馏辐射场中提供优势。", "method": "本文通过回答三个关键问题来探究几何感知语义特征的益处：1. 空间感知（spatial-grounding）是否能产生更高保真度的几何感知语义特征？2. 几何感知是否能改善语义物体定位？3. 几何感知是否能实现更高精度的辐射场反演？针对第三个问题，作者提出了一个名为SPINE的新颖框架，用于无需初始猜测的辐射场反演，该框架包含两个核心组件：使用蒸馏语义进行粗略反演和使用基于光度学优化进行精细反演。", "result": "1. 几何感知骨干网络生成的图像特征确实包含比其对应物更精细的结构细节。2. 在语义物体定位任务中，未观察到显著差异。3. 在辐射场反演（姿态估计）任务中，几何感知特征反而导致姿态估计精度下降。", "conclusion": "研究结果表明，尽管几何感知特征包含更多的几何细节，但纯视觉特征在更广泛的下游任务中提供了更大的通用性。这些发现强调了未来研究需要探索有效的几何感知策略，以增强预训练语义特征的通用性和性能。"}}
{"id": "2510.02370", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02370", "abs": "https://arxiv.org/abs/2510.02370", "authors": ["Minsung Kim", "Dong-Kyum Kim", "Jea Kwon", "Nakyeong Yang", "Kyomin Jung", "Meeyoung Cha"], "title": "Training Dynamics of Parametric and In-Context Knowledge Utilization in Language Models", "comment": "16 pages", "summary": "Large language models often encounter conflicts between in-context knowledge\nretrieved at inference time and parametric knowledge acquired during\npretraining. Models that accept external knowledge uncritically are vulnerable\nto misinformation, whereas models that adhere rigidly to parametric knowledge\nfail to benefit from retrieval. Despite the widespread adoption of\nretrieval-augmented generation, we still lack a systematic understanding of\nwhat shapes knowledge-arbitration strategies during training. This gap risks\nproducing pretrained models with undesirable arbitration behaviors and,\nconsequently, wasting substantial computational resources after the pretraining\nbudget has already been spent. To address this problem, we present the first\ncontrolled study of how training conditions influence models' use of in-context\nand parametric knowledge, and how they arbitrate between them. We train\ntransformer-based language models on a synthetic biographies corpus while\nsystematically controlling various conditions. Our experiments reveal that\nintra-document repetition of facts fosters the development of both parametric\nand in-context capabilities. Moreover, training on a corpus that contains\ninconsistent information or distributional skew encourages models to develop\nrobust strategies for leveraging parametric and in-context knowledge. Rather\nthan viewing these non-ideal properties as artifacts to remove, our results\nindicate that they are important for learning robust arbitration. These\ninsights offer concrete, empirical guidance for pretraining models that\nharmoniously integrate parametric and in-context knowledge.", "AI": {"tldr": "本研究系统性地探究了训练条件如何影响大型语言模型在上下文知识和参数知识之间进行仲裁，发现事实的重复以及不一致或倾斜的数据有助于模型学习鲁棒的知识仲裁策略。", "motivation": "大型语言模型在推理时常面临上下文检索知识与预训练参数知识之间的冲突。模型若盲目接受外部知识则易受误导，若僵化遵循参数知识则无法利用检索优势。目前，对训练期间知识仲裁策略的形成缺乏系统理解，这可能导致预训练模型出现不良仲裁行为，从而浪费大量计算资源。", "method": "通过控制实验，在合成传记语料库上训练基于Transformer的语言模型，并系统地控制各种训练条件，以研究它们如何影响模型对上下文知识和参数知识的使用及其仲裁方式。", "result": "实验发现，文档内事实的重复有助于发展模型的参数知识和上下文知识能力。此外，在包含不一致信息或分布偏斜的语料库上进行训练，能促使模型发展出利用参数知识和上下文知识的鲁棒策略。这些“非理想”特性对于学习鲁棒的仲裁至关重要。", "conclusion": "研究结果为预训练模型提供了具体的经验指导，以期实现参数知识和上下文知识的和谐整合，并指出不一致数据等看似非理想的特性对于学习鲁棒的知识仲裁能力是重要的。"}}
{"id": "2510.02375", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02375", "abs": "https://arxiv.org/abs/2510.02375", "authors": ["Hadi Pouransari", "David Grangier", "C Thomas", "Michael Kirchhof", "Oncel Tuzel"], "title": "Pretraining with hierarchical memories: separating long-tail and common knowledge", "comment": null, "summary": "The impressive performance gains of modern language models currently rely on\nscaling parameters: larger models store more world knowledge and reason better.\nYet compressing all world knowledge into parameters is unnecessary, as only a\nfraction is used per prompt, and impractical for edge devices with limited\ninference-time memory and compute. We address this shortcoming by a\nmemory-augmented architecture and a pretraining strategy aligned with existing\nhardware paradigms. We introduce small language models that access large\nhierarchical parametric memory banks encoding world knowledge. During\npretraining and inference, we fetch a small, context-dependent memory block and\nadd it to the model. Our pretraining learns to store long-tail world knowledge\nin the memory parameters, while the small language model acts as an anchor\ncapturing common knowledge and general reasoning abilities. Through\ntrillion-token-scale experiments, we show significant gains: a 160M-parameters\nmodel augmented with an 18M-parameters memory fetched from a 4.6B memory bank\nobtains comparable performance to a regular model with more than 2x the\nparameters. Through extensive experiments, we study the optimal type and size\nof parametric memories in transformers, scaling them to over 21B parameters. We\nfind that our proposed hierarchical feed-forward memories work robustly across\ntransformer architectures, whether added during pretraining or post-hoc.", "AI": {"tldr": "本文提出一种内存增强型小型语言模型，通过访问外部分层参数化内存库来存储长尾世界知识，在保持模型较小尺寸的同时，性能可与参数量翻倍的常规大型模型相媲美。", "motivation": "现代语言模型依赖参数扩展来提升性能，但这导致所有世界知识被压缩到参数中，效率低下（每次只用一小部分）且不适用于资源受限的边缘设备。这促使研究者寻求一种更高效、更实用的知识存储和检索方法。", "method": "研究者引入了一种内存增强型架构和预训练策略。小型语言模型被设计成可以访问大型分层参数化内存库，这些内存库编码了世界知识。在预训练和推理过程中，模型会根据上下文获取一小块内存块并添加到模型中。预训练过程旨在让内存参数存储长尾世界知识，而小型语言模型则负责捕获通用知识和推理能力。", "result": "通过万亿级别的token实验，该研究显示出显著的性能提升：一个1.6亿参数的模型，辅以从46亿参数内存库中提取的1800万参数内存，其性能可与参数量是其两倍多的常规模型相媲美。研究还广泛探讨了Transformer中参数化内存的最佳类型和大小，将其扩展到超过210亿参数。结果表明，所提出的分层前馈内存无论是在预训练期间还是事后添加，都能在不同的Transformer架构中稳定工作。", "conclusion": "该研究成功地开发了一种内存增强型小型语言模型，通过将长尾世界知识存储在外部可访问的参数化内存库中，有效解决了现有大型语言模型参数扩展带来的效率和部署问题。这种方法使小型模型能够以更少的参数实现与大型模型相当甚至更好的性能，为未来语言模型的设计和部署提供了新的方向。"}}
{"id": "2510.02922", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02922", "abs": "https://arxiv.org/abs/2510.02922", "authors": ["Daphne Tsolissou", "Theofanis Ganitidis", "Konstantinos Mitsis", "Stergios CHristodoulidis", "Maria Vakalopoulou", "Konstantina Nikita"], "title": "Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights", "comment": null, "summary": "Reliable risk assessment for carotid atheromatous disease remains a major\nclinical challenge, as it requires integrating diverse clinical and imaging\ninformation in a manner that is transparent and interpretable to clinicians.\nThis study investigates the potential of state-of-the-art and recent large\nvision-language models (LVLMs) for multimodal carotid plaque assessment by\nintegrating ultrasound imaging (USI) with structured clinical, demographic,\nlaboratory, and protein biomarker data. A framework that simulates realistic\ndiagnostic scenarios through interview-style question sequences is proposed,\ncomparing a range of open-source LVLMs, including both general-purpose and\nmedically tuned models. Zero-shot experiments reveal that even if they are very\npowerful, not all LVLMs can accurately identify imaging modality and anatomy,\nwhile all of them perform poorly in accurate risk classification. To address\nthis limitation, LLaVa-NeXT-Vicuna is adapted to the ultrasound domain using\nlow-rank adaptation (LoRA), resulting in substantial improvements in stroke\nrisk stratification. The integration of multimodal tabular data in the form of\ntext further enhances specificity and balanced accuracy, yielding competitive\nperformance compared to prior convolutional neural network (CNN) baselines\ntrained on the same dataset. Our findings highlight both the promise and\nlimitations of LVLMs in ultrasound-based cardiovascular risk prediction,\nunderscoring the importance of multimodal integration, model calibration, and\ndomain adaptation for clinical translation.", "AI": {"tldr": "本研究探讨了大型视觉语言模型（LVLMs）在颈动脉粥样硬化斑块评估中的潜力，通过整合超声图像与临床数据，并提出了一种模拟诊断场景的框架。结果显示，经过低秩适应（LoRA）和多模态数据整合，LVLMs在卒中风险分层方面表现出显著改进，与现有基线模型相比具有竞争力，但仍需进一步的领域适应和校准。", "motivation": "颈动脉粥样硬化疾病的可靠风险评估是一个主要的临床挑战，因为它需要以对临床医生透明和可解释的方式整合多样化的临床和影像信息。", "method": "本研究提出一个模拟真实诊断场景的面试式问答序列框架，评估了多种开源LVLMs（包括通用型和医学调整型）。研究将超声图像（USI）与结构化的临床、人口统计学、实验室和蛋白质生物标志物数据进行整合。为了解决零样本实验中的局限性，研究使用低秩适应（LoRA）将LLaVa-NeXT-Vicuna模型适应到超声领域，并通过文本形式整合多模态表格数据。", "result": "零样本实验表明，并非所有LVLMs都能准确识别影像模态和解剖结构，且在准确风险分类方面表现不佳。然而，通过LoRA对LLaVa-NeXT-Vicuna进行超声领域适应后，卒中风险分层能力显著提高。以文本形式整合多模态表格数据进一步提升了特异性和平衡准确性，达到了与先前基于相同数据集训练的卷积神经网络（CNN）基线模型相当的性能。", "conclusion": "研究结果突出了LVLMs在基于超声的心血管风险预测中的潜力和局限性，强调了多模态整合、模型校准和领域适应对于临床转化的重要性。"}}
{"id": "2510.03135", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03135", "abs": "https://arxiv.org/abs/2510.03135", "authors": ["Gen Li", "Bo Zhao", "Jianfei Yang", "Laura Sevilla-Lara"], "title": "Mask2IV: Interaction-Centric Video Generation via Mask Trajectories", "comment": "Project page: https://reagan1311.github.io/mask2iv", "summary": "Generating interaction-centric videos, such as those depicting humans or\nrobots interacting with objects, is crucial for embodied intelligence, as they\nprovide rich and diverse visual priors for robot learning, manipulation policy\ntraining, and affordance reasoning. However, existing methods often struggle to\nmodel such complex and dynamic interactions. While recent studies show that\nmasks can serve as effective control signals and enhance generation quality,\nobtaining dense and precise mask annotations remains a major challenge for\nreal-world use. To overcome this limitation, we introduce Mask2IV, a novel\nframework specifically designed for interaction-centric video generation. It\nadopts a decoupled two-stage pipeline that first predicts plausible motion\ntrajectories for both actor and object, then generates a video conditioned on\nthese trajectories. This design eliminates the need for dense mask inputs from\nusers while preserving the flexibility to manipulate the interaction process.\nFurthermore, Mask2IV supports versatile and intuitive control, allowing users\nto specify the target object of interaction and guide the motion trajectory\nthrough action descriptions or spatial position cues. To support systematic\ntraining and evaluation, we curate two benchmarks covering diverse action and\nobject categories across both human-object interaction and robotic manipulation\nscenarios. Extensive experiments demonstrate that our method achieves superior\nvisual realism and controllability compared to existing baselines.", "AI": {"tldr": "Mask2IV是一个新颖的交互中心视频生成框架，采用两阶段解耦管道（先预测运动轨迹，再生成视频），无需密集的掩码输入，提供灵活的控制，并在视觉真实性和可控性方面优于现有方法。", "motivation": "现有方法难以建模复杂动态的交互中心视频，而虽然掩码是有效的控制信号，但获取密集精确的掩码标注在实际应用中是一个主要挑战。生成此类视频对具身智能（如机器人学习、操纵策略训练、可供性推理）至关重要。", "method": "Mask2IV框架采用解耦的两阶段管道：首先预测演员和物体的合理运动轨迹，然后基于这些轨迹生成视频。这种设计消除了对用户提供密集掩码输入的需求。它还支持多功能和直观的控制，允许用户指定交互目标，并通过动作描述或空间位置线索引导运动轨迹。为支持训练和评估，该研究还整理了两个涵盖人类-物体交互和机器人操纵场景的基准。", "result": "实验结果表明，与现有基线方法相比，Mask2IV在视觉真实性和可控性方面表现出卓越的性能。", "conclusion": "Mask2IV成功克服了交互中心视频生成中对密集掩码输入的需求，通过其独特的两阶段设计和灵活的控制机制，实现了更高质量和更易于控制的视频生成，对具身智能领域具有重要意义。"}}
{"id": "2510.02377", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02377", "abs": "https://arxiv.org/abs/2510.02377", "authors": ["Aakriti Agrawal", "Rohith Aralikatti", "Anirudh Satheesh", "Souradip Chakraborty", "Amrit Singh Bedi", "Furong Huang"], "title": "Uncertainty-Aware Answer Selection for Improved Reasoning in Multi-LLM Systems", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated exceptional capabilities, yet\nselecting the most reliable response from multiple LLMs remains a challenge,\nparticularly in resource-constrained settings. Existing approaches often depend\non costly external verifiers, human evaluators, or self-consistency techniques\nthat require multiple samples from a single model. While multi-LLM systems\nproduce more diverse responses than single models and thus have greater\npotential, they often underperform compared to single LLM self-consistency. We\npropose a principled, novel and computationally efficient method to select the\nbest response from multiple different LLMs using a calibrated log-likelihood\nscore, implicitly leveraging the inherent knowledge and confidence of these\nmodels. Our method demonstrates improvements of approx. 4%, 3%, and 5% across\nboth debate (multi-round LLM discussions) and non-debate (Best-of-N with\nmultiple LLMs) settings on GSM8K, MMLU (6 subsets), and ARC datasets\nrespectively.", "AI": {"tldr": "本文提出一种新颖且计算高效的方法，通过校准对数似然分数，从多个大型语言模型中选择最可靠的响应，并在多个基准测试中取得了显著改进。", "motivation": "尽管大型语言模型能力卓越，但在资源受限环境下，从多个LLM中选择最可靠响应仍具挑战。现有方法依赖昂贵的外部验证器、人工评估或单模型自洽性，而多LLM系统虽具潜力，但表现常不如单LLM自洽性。", "method": "提出一种基于校准对数似然分数的方法，以原则性、新颖且计算高效的方式从多个不同LLM中选择最佳响应。该方法隐式利用了模型固有的知识和置信度。", "result": "在GSM8K、MMLU（6个子集）和ARC数据集上，无论是在辩论（多轮LLM讨论）还是非辩论（多个LLM的Best-of-N）设置中，该方法分别取得了约4%、3%和5%的改进。", "conclusion": "该方法提供了一种有效且高效的策略，能够从多个LLM中选择最佳响应，从而提升了多LLM系统的性能，并解决了现有方法在可靠性选择上的局限性。"}}
{"id": "2510.02463", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.02463", "abs": "https://arxiv.org/abs/2510.02463", "authors": ["Vladimir Shaposhnikov", "Aleksandr Nesterov", "Ilia Kopanichuk", "Ivan Bakulin", "Egor Zhelvakov", "Ruslan Abramov", "Ekaterina Tsapieva", "Dmitry V. Dylov", "Ivan Oseledets"], "title": "CLARITY: Clinical Assistant for Routing, Inference, and Triage", "comment": "Accepted to EMNLP 2025 (Industrial Track)", "summary": "We present CLARITY (Clinical Assistant for Routing, Inference, and Triage),\nan AI-driven platform designed to facilitate patient-to-specialist routing,\nclinical consultations, and severity assessment of patients' conditions. Its\nhybrid architecture combines a Finite State Machine (FSM) for structured\ndialogue flows with collaborative agents that employ Large Language Model (LLM)\nto analyze symptoms and prioritize referrals to appropriate specialists. Built\non a modular microservices framework, CLARITY ensures safe, efficient, and\nrobust performance, flexible and readily scalable to meet the demands of\nexisting workflows and IT solutions in healthcare.\n  We report integration of our clinical assistant into a large-scale\nnation-wide inter-hospital IT platform, with over 55,000 content-rich user\ndialogues completed within the two months of deployment, 2,500 of which were\nexpert-annotated for a consequent validation. The validation results show that\nCLARITY surpasses human-level performance in terms of the first-attempt routing\nprecision, naturally requiring up to 3 times shorter duration of the\nconsultation than with a human.", "AI": {"tldr": "CLARITY是一个结合了有限状态机和大型语言模型的AI平台，旨在辅助患者分诊、会诊和严重性评估。它在实际部署中表现出色，首次尝试路由精度超越人类，且会诊时间更短。", "motivation": "该研究旨在开发一个AI驱动的平台，以促进患者到专家的分诊、临床会诊以及患者病情严重程度的评估，从而提高医疗流程的效率和准确性。", "method": "CLARITY采用混合架构，结合了用于结构化对话流的有限状态机（FSM）和利用大型语言模型（LLM）分析症状并优先安排转诊的协作代理。它建立在模块化的微服务框架之上，确保了安全、高效和鲁棒的性能，并具有良好的可扩展性。", "result": "CLARITY已集成到一个全国性的医院间IT平台中，在部署的两个月内完成了超过55,000次内容丰富的用户对话，其中2,500次经过专家标注用于验证。验证结果显示，CLARITY在首次尝试路由精度方面超越了人类水平的表现，并且所需的会诊时间比人类短三倍。", "conclusion": "CLARITY是一个高效、精确且可扩展的AI驱动临床助理平台，能够有效改进患者分诊和会诊流程，并在实际应用中展现出优于人类的性能。"}}
{"id": "2510.02970", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02970", "abs": "https://arxiv.org/abs/2510.02970", "authors": ["Xiaoyan Kui", "Qianmu Xiao", "Qqinsong Li", "Zexin Ji", "JIelin Zhang", "Beiji Zou"], "title": "Flip Distribution Alignment VAE for Multi-Phase MRI Synthesis", "comment": "This paper has been early accept by MICCAI 2025", "summary": "Separating shared and independent features is crucial for multi-phase\ncontrast-enhanced (CE) MRI synthesis. However, existing methods use deep\nautoencoder generators with low parameter efficiency and lack interpretable\ntraining strategies. In this paper, we propose Flip Distribution Alignment\nVariational Autoencoder (FDA-VAE), a lightweight feature-decoupled VAE model\nfor multi-phase CE MRI synthesis. Our method encodes input and target images\ninto two latent distributions that are symmetric concerning a standard normal\ndistribution, effectively separating shared and independent features. The\nY-shaped bidirectional training strategy further enhances the interpretability\nof feature separation. Experimental results show that compared to existing deep\nautoencoder-based end-to-end synthesis methods, FDA-VAE significantly reduces\nmodel parameters and inference time while effectively improving synthesis\nquality. The source code is publicly available at\nhttps://github.com/QianMuXiao/FDA-VAE.", "AI": {"tldr": "本文提出了一种轻量级特征解耦变分自编码器（FDA-VAE），用于多期对比增强MRI合成，通过对称潜在分布和Y型双向训练策略有效分离共享和独立特征，显著提高效率和合成质量。", "motivation": "多期对比增强MRI合成中，分离共享和独立特征至关重要。然而，现有方法（深度自编码器生成器）存在参数效率低和训练策略缺乏可解释性的问题。", "method": "提出了一种轻量级特征解耦变分自编码器（FDA-VAE）。该方法将输入和目标图像编码成两个关于标准正态分布对称的潜在分布，从而有效分离共享和独立特征。Y型双向训练策略进一步增强了特征分离的可解释性。", "result": "实验结果表明，与现有基于深度自编码器的端到端合成方法相比，FDA-VAE显著减少了模型参数和推理时间，同时有效提高了合成质量。", "conclusion": "FDA-VAE为多期对比增强MRI合成提供了一种参数高效、推理速度快且合成质量高的解决方案，并通过可解释的训练策略实现了特征的有效分离。"}}
{"id": "2510.02388", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02388", "abs": "https://arxiv.org/abs/2510.02388", "authors": ["Haoyue Bai", "Haoyu Wang", "Shengyu Chen", "Zhengzhang Chen", "Lu-An Tang", "Wei Cheng", "Haifeng Chen", "Yanjie Fu"], "title": "Learning to Route: A Rule-Driven Agent Framework for Hybrid-Source Retrieval-Augmented Generation", "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable performance on general\nQuestion Answering (QA), yet they often struggle in domain-specific scenarios\nwhere accurate and up-to-date information is required. Retrieval-Augmented\nGeneration (RAG) addresses this limitation by enriching LLMs with external\nknowledge, but existing systems primarily rely on unstructured documents, while\nlargely overlooking relational databases, which provide precise, timely, and\nefficiently queryable factual information, serving as indispensable\ninfrastructure in domains such as finance, healthcare, and scientific research.\nMotivated by this gap, we conduct a systematic analysis that reveals three\ncentral observations: (i) databases and documents offer complementary strengths\nacross queries, (ii) naively combining both sources introduces noise and cost\nwithout consistent accuracy gains, and (iii) selecting the most suitable source\nfor each query is crucial to balance effectiveness and efficiency. We further\nobserve that query types show consistent regularities in their alignment with\nretrieval paths, suggesting that routing decisions can be effectively guided by\nsystematic rules that capture these patterns. Building on these insights, we\npropose a rule-driven routing framework. A routing agent scores candidate\naugmentation paths based on explicit rules and selects the most suitable one; a\nrule-making expert agent refines the rules over time using QA feedback to\nmaintain adaptability; and a path-level meta-cache reuses past routing\ndecisions for semantically similar queries to reduce latency and cost.\nExperiments on three QA benchmarks demonstrate that our framework consistently\noutperforms static strategies and learned routing baselines, achieving higher\naccuracy while maintaining moderate computational cost.", "AI": {"tldr": "大型语言模型（LLMs）在领域特定问答（QA）中表现不佳，现有检索增强生成（RAG）主要依赖非结构化文档，忽视了关系型数据库。本文提出一个规则驱动的路由框架，结合数据库和文档，通过智能路由、规则学习和元缓存，显著提高了问答准确性并保持了适度的计算成本。", "motivation": "LLMs在需要精确和最新信息的领域特定QA中表现不足。RAG通过外部知识增强LLMs，但主要依赖非结构化文档，忽略了提供精确、及时、可高效查询事实信息的关键基础设施——关系型数据库。简单地结合两种来源会引入噪声和成本，且不一定提高准确性。因此，为每个查询选择最合适的知识源至关重要。", "method": "本文首先进行系统分析，发现数据库和文档在查询上具有互补优势，且查询类型与检索路径存在规律性。在此基础上，提出了一个规则驱动的路由框架：1) 路由代理：根据明确的规则评估并选择最合适的增强路径；2) 规则制定专家代理：利用QA反馈随时间迭代优化规则，以保持适应性；3) 路径级元缓存：重用过去对语义相似查询的路由决策，以减少延迟和成本。", "result": "在三个QA基准测试上的实验表明，本文提出的框架持续优于静态策略和基于学习的路由基线，实现了更高的准确性，同时保持了适度的计算成本。", "conclusion": "本文提出的规则驱动路由框架有效解决了LLMs在领域特定QA中的挑战，通过智能结合关系型数据库和非结构化文档，显著提升了RAG的性能，实现了更高的准确性和效率。"}}
{"id": "2510.02549", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02549", "abs": "https://arxiv.org/abs/2510.02549", "authors": ["Sicheng Dong", "Vahid Zolfaghari", "Nenad Petrovic", "Alois Knoll"], "title": "Knowledge-Graph Based RAG System Evaluation Framework", "comment": null, "summary": "Large language models (LLMs) has become a significant research focus and is\nutilized in various fields, such as text generation and dialog systems. One of\nthe most essential applications of LLM is Retrieval Augmented Generation (RAG),\nwhich greatly enhances generated content's reliability and relevance. However,\nevaluating RAG systems remains a challenging task. Traditional evaluation\nmetrics struggle to effectively capture the key features of modern\nLLM-generated content that often exhibits high fluency and naturalness.\nInspired by the RAGAS tool, a well-known RAG evaluation framework, we extended\nthis framework into a KG-based evaluation paradigm, enabling multi-hop\nreasoning and semantic community clustering to derive more comprehensive\nscoring metrics. By incorporating these comprehensive evaluation criteria, we\ngain a deeper understanding of RAG systems and a more nuanced perspective on\ntheir performance. To validate the effectiveness of our approach, we compare\nits performance with RAGAS scores and construct a human-annotated subset to\nassess the correlation between human judgments and automated metrics. In\naddition, we conduct targeted experiments to demonstrate that our KG-based\nevaluation method is more sensitive to subtle semantic differences in generated\noutputs. Finally, we discuss the key challenges in evaluating RAG systems and\nhighlight potential directions for future research.", "AI": {"tldr": "本文提出了一种基于知识图谱（KG）的RAG系统评估范式，通过多跳推理和语义社区聚类，提供比传统方法更全面和敏感的评估指标，并验证了其有效性。", "motivation": "RAG系统在提升LLM生成内容可靠性和相关性方面至关重要，但传统评估指标难以有效捕捉LLM生成内容的关键特征，特别是多跳推理和语义关联，导致评估RAG系统仍然具有挑战性。", "method": "受RAGAS工具启发，作者将RAGAS框架扩展为基于知识图谱的评估范式。该方法融入了多跳推理和语义社区聚类，以推导更全面的评分指标。通过与RAGAS分数进行比较，并构建人工标注子集来评估与人类判断的相关性，以及进行针对性实验以展示其对细微语义差异的敏感性，来验证该方法的有效性。", "result": "所提出的基于KG的评估方法能够更深入地理解RAG系统，提供对其性能更细致的视角。实验结果表明，该方法与人类判断具有相关性，并且比RAGAS对生成输出中细微的语义差异更为敏感。", "conclusion": "本文提出了一种有效且敏感的基于知识图谱的RAG系统评估方法，讨论了评估RAG系统面临的关键挑战，并指出了未来研究的潜在方向。"}}
{"id": "2510.02987", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02987", "abs": "https://arxiv.org/abs/2510.02987", "authors": ["Juntong Wang", "Huiyu Duan", "Jiarui Wang", "Ziheng Jia", "Guangtao Zhai", "Xiongkuo Min"], "title": "TIT-Score: Evaluating Long-Prompt Based Text-to-Image Alignment via Text-to-Image-to-Text Consistency", "comment": null, "summary": "With the rapid advancement of large multimodal models (LMMs), recent\ntext-to-image (T2I) models can generate high-quality images and demonstrate\ngreat alignment to short prompts. However, they still struggle to effectively\nunderstand and follow long and detailed prompts, displaying inconsistent\ngeneration. To address this challenge, we introduce LPG-Bench, a comprehensive\nbenchmark for evaluating long-prompt-based text-to-image generation. LPG-Bench\nfeatures 200 meticulously crafted prompts with an average length of over 250\nwords, approaching the input capacity of several leading commercial models.\nUsing these prompts, we generate 2,600 images from 13 state-of-the-art models\nand further perform comprehensive human-ranked annotations. Based on LPG-Bench,\nwe observe that state-of-the-art T2I alignment evaluation metrics exhibit poor\nconsistency with human preferences on long-prompt-based image generation. To\naddress the gap, we introduce a novel zero-shot metric based on\ntext-to-image-to-text consistency, termed TIT, for evaluating\nlong-prompt-generated images. The core concept of TIT is to quantify T2I\nalignment by directly comparing the consistency between the raw prompt and the\nLMM-produced description on the generated image, which includes an efficient\nscore-based instantiation TIT-Score and a large-language-model (LLM) based\ninstantiation TIT-Score-LLM. Extensive experiments demonstrate that our\nframework achieves superior alignment with human judgment compared to\nCLIP-score, LMM-score, etc., with TIT-Score-LLM attaining a 7.31% absolute\nimprovement in pairwise accuracy over the strongest baseline. LPG-Bench and TIT\nmethods together offer a deeper perspective to benchmark and foster the\ndevelopment of T2I models. All resources will be made publicly available.", "AI": {"tldr": "本文介绍了LPG-Bench，一个用于评估长文本提示下文生图（T2I）模型表现的综合基准，以及TIT，一种基于文本-图像-文本一致性的新型零样本评估指标，旨在解决现有模型在处理长提示时的局限性和现有评估指标与人类偏好不一致的问题。", "motivation": "随着大型多模态模型（LMMs）的快速发展，文生图（T2I）模型在生成高质量图像方面取得了巨大进步，并能很好地与短提示对齐。然而，它们在理解和遵循长而详细的提示时仍然存在困难，导致生成不一致的图像。此外，现有的T2I对齐评估指标在长提示图像生成方面与人类偏好存在较低的一致性。", "method": "研究人员构建了LPG-Bench，一个包含200个精心制作的平均长度超过250词的长提示的基准。他们使用这些提示从13个最先进的模型生成了2,600张图像，并进行了全面的人工排名标注。为了弥补现有指标的不足，他们引入了一种名为TIT（Text-to-Image-to-Text consistency）的新型零样本指标，通过直接比较原始提示与LMM生成的图像描述之间的一致性来量化T2I对齐。TIT包括高效的基于分数的TIT-Score和基于大型语言模型（LLM）的TIT-Score-LLM两种实现方式。", "result": "研究发现，最先进的T2I对齐评估指标在长提示图像生成方面与人类偏好的一致性较差。相比之下，他们提出的TIT框架，特别是TIT-Score-LLM，与人类判断的对齐度优于CLIP-score、LMM-score等基线，其中TIT-Score-LLM在成对准确率上比最强基线提高了7.31%。", "conclusion": "LPG-Bench和TIT方法共同为T2I模型的基准测试和发展提供了更深入的视角，特别是在评估模型对长文本提示的理解和生成能力方面。所有研究资源将公开可用。"}}
{"id": "2510.02392", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02392", "abs": "https://arxiv.org/abs/2510.02392", "authors": ["Yinyi Luo", "Zhexian Zhou", "Hao Chen", "Kai Qiu", "Marios Savvides", "Yixuan Li", "Jindong Wang"], "title": "KnowledgeSmith: Uncovering Knowledge Updating in LLMs with Model Editing and Unlearning", "comment": "Technical report", "summary": "Knowledge editing and machine unlearning are two popular approaches for large\nlanguage models (LLMs) to stay up-to-date. However, the knowledge updating\nmechanism of LLMs remains largely unexplored due to insufficient, isolated, and\nsmall-scale evaluation. For instance, are LLMs similar to humans in modifying\ncertain knowledge? What differs editing and unlearning as training data\nincreases? This paper proposes KnowledgeSmith, a unified framework to\nsystematically understand the updating mechanism of LLMs. We first cast editing\nand unlearning as instances of one constrained optimization problem. Then, we\npropose an automatic dataset generator that provides structured interventions\nacross multiple graph levels and data scales, enabling controlled studies of\nhow different modification strategies propagate through model knowledge.\nExtensive experiments demonstrate nuanced insights over knowledge propagation,\nplasticity scaling, consistency, and robustness. For instance, our results show\nthat LLMs do not exhibit similar updating as humans for different levels of\nknowledge, and there exists consistency-capacity trade-off. We hope our\nfindings can offer suggestions to the design of more reliable and scalable\nstrategies. Code: https://github.com/AIFrontierLab/KnowledgeSmith.git", "AI": {"tldr": "本文提出了KnowledgeSmith，一个统一框架，用于系统性理解大型语言模型（LLMs）的知识更新机制（包括知识编辑和机器遗忘），并揭示了知识传播、可塑性、一致性和鲁棒性方面的细致见解。", "motivation": "LLMs的知识更新机制（如知识编辑和机器遗忘）由于评估不足、孤立且规模小，在很大程度上仍未被充分探索。研究者希望回答LLMs在修改知识时是否与人类相似，以及编辑和遗忘随着训练数据增加有何不同等问题。", "method": "研究者提出了KnowledgeSmith框架。首先，将知识编辑和机器遗忘视为一个受约束的优化问题的实例。其次，提出了一个自动数据集生成器，该生成器能在多个图级别和数据规模上提供结构化干预，从而实现对不同修改策略如何通过模型知识传播的受控研究。", "result": "广泛的实验揭示了知识传播、可塑性缩放、一致性和鲁棒性方面的细致见解。例如，结果表明LLMs在不同级别的知识更新上与人类表现不相似，并且存在一致性-容量权衡。", "conclusion": "研究结果有望为设计更可靠和可扩展的LLM知识更新策略提供建议。"}}
{"id": "2510.02712", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02712", "abs": "https://arxiv.org/abs/2510.02712", "authors": ["Yubo Li", "Ramayya Krishnan", "Rema Padman"], "title": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks", "comment": null, "summary": "Large Language Models (LLMs) have revolutionized conversational AI, yet their\nrobustness in extended multi-turn dialogues remains poorly understood. Existing\nevaluation frameworks focus on static benchmarks and single-turn assessments,\nfailing to capture the temporal dynamics of conversational degradation that\ncharacterize real-world interactions. In this work, we present the first\ncomprehensive survival analysis of conversational AI robustness, analyzing\n36,951 conversation turns across 9 state-of-the-art LLMs to model failure as a\ntime-to-event process. Our survival modeling framework-employing Cox\nproportional hazards, Accelerated Failure Time, and Random Survival Forest\napproaches-reveals extraordinary temporal dynamics. We find that abrupt,\nprompt-to-prompt(P2P) semantic drift is catastrophic, dramatically increasing\nthe hazard of conversational failure. In stark contrast, gradual, cumulative\ndrift is highly protective, vastly reducing the failure hazard and enabling\nsignificantly longer dialogues. AFT models with interactions demonstrate\nsuperior performance, achieving excellent discrimination and exceptional\ncalibration. These findings establish survival analysis as a powerful paradigm\nfor evaluating LLM robustness, offer concrete insights for designing resilient\nconversational agents, and challenge prevailing assumptions about the necessity\nof semantic consistency in conversational AI Systems.", "AI": {"tldr": "本研究首次将生存分析应用于大型语言模型（LLM）的对话鲁棒性评估，发现突发性语义漂移会灾难性地增加对话失败风险，而渐进性累积漂移则能显著降低风险，延长对话时长。", "motivation": "尽管LLM革新了对话式AI，但其在多轮对话中的鲁棒性仍知之甚少。现有评估框架侧重于静态基准和单轮评估，未能捕捉真实世界交互中对话退化的时间动态。", "method": "本研究对9个最先进的LLM进行了36,951轮对话分析，将对话失败建模为时间-事件过程。采用了Cox比例风险模型、加速失效时间（AFT）模型和随机生存森林等生存分析方法来评估对话式AI的鲁棒性。", "result": "研究发现，突发性的、提示到提示（P2P）的语义漂移是灾难性的，会急剧增加对话失败的风险。相反，渐进性的、累积的语义漂移具有高度保护性，能大大降低失败风险并显著延长对话时长。带有交互作用的AFT模型表现优异，实现了卓越的区分度和校准度。", "conclusion": "生存分析是评估LLM鲁棒性的强大范式，为设计有韧性的对话代理提供了具体见解，并挑战了关于对话式AI系统语义一致性必要性的普遍假设。"}}
{"id": "2510.02994", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02994", "abs": "https://arxiv.org/abs/2510.02994", "authors": ["Ruihao Xia", "Yang Tang", "Pan Zhou"], "title": "Towards Scalable and Consistent 3D Editing", "comment": null, "summary": "3D editing - the task of locally modifying the geometry or appearance of a 3D\nasset - has wide applications in immersive content creation, digital\nentertainment, and AR/VR. However, unlike 2D editing, it remains challenging\ndue to the need for cross-view consistency, structural fidelity, and\nfine-grained controllability. Existing approaches are often slow, prone to\ngeometric distortions, or dependent on manual and accurate 3D masks that are\nerror-prone and impractical. To address these challenges, we advance both the\ndata and model fronts. On the data side, we introduce 3DEditVerse, the largest\npaired 3D editing benchmark to date, comprising 116,309 high-quality training\npairs and 1,500 curated test pairs. Built through complementary pipelines of\npose-driven geometric edits and foundation model-guided appearance edits,\n3DEditVerse ensures edit locality, multi-view consistency, and semantic\nalignment. On the model side, we propose 3DEditFormer, a\n3D-structure-preserving conditional transformer. By enhancing image-to-3D\ngeneration with dual-guidance attention and time-adaptive gating, 3DEditFormer\ndisentangles editable regions from preserved structure, enabling precise and\nconsistent edits without requiring auxiliary 3D masks. Extensive experiments\ndemonstrate that our framework outperforms state-of-the-art baselines both\nquantitatively and qualitatively, establishing a new standard for practical and\nscalable 3D editing. Dataset and code will be released. Project:\nhttps://www.lv-lab.org/3DEditFormer/", "AI": {"tldr": "本文提出3DEditVerse数据集和3DEditFormer模型，解决了3D编辑中跨视图一致性、结构保真度和精细控制的挑战，实现了无需3D遮罩的精确一致编辑。", "motivation": "3D编辑在沉浸式内容创作、数字娱乐和AR/VR中有广泛应用，但由于需要跨视图一致性、结构保真度和精细控制，仍然具有挑战性。现有方法往往速度慢、容易产生几何畸变，或依赖手动且易出错的3D遮罩，不切实际。", "method": "本文从数据和模型两方面进行改进：\n1. **数据方面**：引入3DEditVerse，目前最大的配对3D编辑基准数据集，包含116,309个高质量训练对和1,500个测试对。通过姿态驱动的几何编辑和基础模型引导的外观编辑互补管道构建，确保了编辑的局部性、多视图一致性和语义对齐。\n2. **模型方面**：提出3DEditFormer，一个3D结构保留的条件Transformer。通过双引导注意力（dual-guidance attention）和时间自适应门控（time-adaptive gating）增强图像到3D的生成，分离可编辑区域和保留结构，实现精确一致的编辑，无需辅助3D遮罩。", "result": "实验结果表明，本文提出的框架在定量和定性方面均优于现有最先进的基线方法，为实用和可扩展的3D编辑树立了新标准。", "conclusion": "本文通过引入大规模数据集3DEditVerse和创新的模型3DEditFormer，有效解决了3D编辑的现有挑战，实现了无需3D遮罩的精确、一致且可扩展的3D编辑。数据集和代码将公开发布。"}}
{"id": "2510.02394", "categories": ["cs.CL", "I.2.7; H.2.3; H.2.8"], "pdf": "https://arxiv.org/pdf/2510.02394", "abs": "https://arxiv.org/abs/2510.02394", "authors": ["Manasi Patwardhan", "Ayush Agarwal", "Shabbirhussain Bhaisaheb", "Aseem Arora", "Lovekesh Vig", "Sunita Sarawagi"], "title": "Retrieval and Augmentation of Domain Knowledge for Text-to-SQL Semantic Parsing", "comment": "10 pages, 2 figures, 11 tables. Accepted in the 1st Workshop on\n  Grounding Documents with Reasoning, Agents, Retrieval, and Attribution (RARA)\n  held in conjunction with IEEE International Conference on Data Mining (ICDM)\n  2025", "summary": "The performance of Large Language Models (LLMs) for translating Natural\nLanguage (NL) queries into SQL varies significantly across databases (DBs). NL\nqueries are often expressed using a domain specific vocabulary, and mapping\nthese to the correct SQL requires an understanding of the embedded domain\nexpressions, their relationship to the DB schema structure. Existing benchmarks\nrely on unrealistic, ad-hoc query specific textual hints for expressing domain\nknowledge. In this paper, we propose a systematic framework for associating\nstructured domain statements at the database level. We present retrieval of\nrelevant structured domain statements given a user query using sub-string level\nmatch. We evaluate on eleven realistic DB schemas covering diverse domains\nacross five open-source and proprietary LLMs and demonstrate that (1) DB level\nstructured domain statements are more practical and accurate than existing\nad-hoc query specific textual domain statements, and (2) Our sub-string match\nbased retrieval of relevant domain statements provides significantly higher\naccuracy than other retrieval approaches.", "AI": {"tldr": "LLMs的NL-to-SQL性能因数据库而异，现有方法处理领域知识不佳。本文提出在数据库层面关联结构化领域声明的框架，并使用子字符串匹配进行检索，结果表明该方法比现有方法更实用、准确。", "motivation": "LLMs将自然语言查询转换为SQL的性能在不同数据库之间差异很大，因为自然语言查询常包含领域特定词汇，而现有基准测试依赖不切实际、特定于查询的临时文本提示来表达领域知识。", "method": "本文提出了一个系统框架，用于在数据库层面关联结构化领域声明。通过使用子字符串级别匹配，从用户查询中检索相关的结构化领域声明。该方法在11个真实数据库模式和五种LLM上进行了评估。", "result": "研究结果表明：1) 数据库层面的结构化领域声明比现有特定于查询的临时文本领域声明更实用、更准确；2) 基于子字符串匹配的相关领域声明检索方法比其他检索方法提供了显著更高的准确性。", "conclusion": "通过在数据库层面系统地关联结构化领域声明，并采用子字符串匹配的检索方法，可以显著提高LLMs在自然语言到SQL转换任务中的性能和准确性，尤其是在处理领域特定知识方面。"}}
{"id": "2510.02719", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02719", "abs": "https://arxiv.org/abs/2510.02719", "authors": ["Srinivas Billa", "Xiaonan Jing"], "title": "TravelBench : Exploring LLM Performance in Low-Resource Domains", "comment": "10 pages, 3 figures", "summary": "Results on existing LLM benchmarks capture little information over the model\ncapabilities in low-resource tasks, making it difficult to develop effective\nsolutions in these domains. To address these challenges, we curated 14\ntravel-domain datasets spanning 7 common NLP tasks using anonymised data from\nreal-world scenarios, and analysed the performance across LLMs. We report on\nthe accuracy, scaling behaviour, and reasoning capabilities of LLMs in a\nvariety of tasks. Our results confirm that general benchmarking results are\ninsufficient for understanding model performance in low-resource tasks. Despite\nthe amount of training FLOPs, out-of-the-box LLMs hit performance bottlenecks\nin complex, domain-specific scenarios. Furthermore, reasoning provides a more\nsignificant boost for smaller LLMs by making the model a better judge on\ncertain tasks.", "AI": {"tldr": "现有LLM基准测试未能充分反映模型在低资源任务中的能力。本研究通过构建14个旅行领域数据集，发现通用LLM在复杂、领域特定场景中存在性能瓶颈，且推理能力对小型LLM有显著提升。", "motivation": "现有大型语言模型（LLM）基准测试难以捕捉模型在低资源任务中的真实能力，这使得在此类领域开发有效解决方案面临挑战。", "method": "研究者从真实世界场景中匿名化数据，策划了14个跨7种常见自然语言处理（NLP）任务的旅行领域数据集，并分析了LLM在这些数据集上的性能，包括准确性、扩展行为和推理能力。", "result": "研究结果证实，通用基准测试不足以理解模型在低资源任务中的表现。尽管训练FLOPs巨大，开箱即用的LLM在复杂、领域特定场景中遭遇性能瓶颈。此外，推理能力对小型LLM提供了更显著的性能提升，使其在某些任务中表现更优。", "conclusion": "通用基准测试不足以评估LLM在低资源、领域特定任务中的表现。LLM在复杂领域特定场景中存在固有局限性。推理能力对提升小型LLM在特定任务中的判断力尤其重要，提示未来研究应关注领域特定评估和推理能力的优化。"}}
{"id": "2510.03006", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03006", "abs": "https://arxiv.org/abs/2510.03006", "authors": ["Sara Mobsite", "Renaud Hostache", "Laure Berti Equille", "Emmanuel Roux", "Joris Guerin"], "title": "Not every day is a sunny day: Synthetic cloud injection for deep land cover segmentation robustness evaluation across data sources", "comment": null, "summary": "Supervised deep learning for land cover semantic segmentation (LCS) relies on\nlabeled satellite data. However, most existing Sentinel-2 datasets are\ncloud-free, which limits their usefulness in tropical regions where clouds are\ncommon. To properly evaluate the extent of this problem, we developed a cloud\ninjection algorithm that simulates realistic cloud cover, allowing us to test\nhow Sentinel-1 radar data can fill in the gaps caused by cloud-obstructed\noptical imagery. We also tackle the issue of losing spatial and/or spectral\ndetails during encoder downsampling in deep networks. To mitigate this loss, we\npropose a lightweight method that injects Normalized Difference Indices (NDIs)\ninto the final decoding layers, enabling the model to retain key spatial\nfeatures with minimal additional computation. Injecting NDIs enhanced land\ncover segmentation performance on the DFC2020 dataset, yielding improvements of\n1.99% for U-Net and 2.78% for DeepLabV3 on cloud-free imagery. Under\ncloud-covered conditions, incorporating Sentinel-1 data led to significant\nperformance gains across all models compared to using optical data alone,\nhighlighting the effectiveness of radar-optical fusion in challenging\natmospheric scenarios.", "AI": {"tldr": "该研究开发了云注入算法以模拟真实云覆盖，并提出将归一化差异指数（NDIs）注入深度网络解码层的方法，以解决土地覆盖语义分割中云遮挡和空间细节丢失问题。结果表明，NDI注入提升了晴空图像性能，而Sentinel-1雷达数据与光学数据融合在云覆盖条件下显著提高了分割效果。", "motivation": "现有Sentinel-2数据集多为无云图像，限制了其在云层常见的热带地区的应用。同时，深度网络编码器下采样过程会导致空间和/或光谱细节丢失。", "method": "1. 开发了云注入算法以模拟真实的云覆盖。2. 利用Sentinel-1雷达数据弥补云遮挡造成的光学图像缺失。3. 提出将归一化差异指数（NDIs）注入到最终解码层，以保留关键空间特征。4. 在DFC2020数据集上测试了这些方法。", "result": "1. 在无云图像上，NDI注入使U-Net和DeepLabV3的土地覆盖分割性能分别提高了1.99%和2.78%。2. 在云覆盖条件下，与仅使用光学数据相比，结合Sentinel-1数据显著提升了所有模型的性能。", "conclusion": "该研究证明了雷达-光学融合在应对复杂大气条件（如云覆盖）下的土地覆盖语义分割任务中是有效的，并且NDI注入是一种轻量级且能有效保留空间细节的方法，有助于提升模型性能。"}}
{"id": "2510.02425", "categories": ["cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02425", "abs": "https://arxiv.org/abs/2510.02425", "authors": ["Sophie L. Wang", "Phillip Isola", "Brian Cheung"], "title": "Words That Make Language Models Perceive", "comment": null, "summary": "Large language models (LLMs) trained purely on text ostensibly lack any\ndirect perceptual experience, yet their internal representations are implicitly\nshaped by multimodal regularities encoded in language. We test the hypothesis\nthat explicit sensory prompting can surface this latent structure, bringing a\ntext-only LLM into closer representational alignment with specialist vision and\naudio encoders. When a sensory prompt tells the model to 'see' or 'hear', it\ncues the model to resolve its next-token predictions as if they were\nconditioned on latent visual or auditory evidence that is never actually\nsupplied. Our findings reveal that lightweight prompt engineering can reliably\nactivate modality-appropriate representations in purely text-trained LLMs.", "AI": {"tldr": "研究表明，通过轻量级的感官提示（如“看”或“听”），可以激活纯文本训练的大语言模型中潜在的多模态表征，使其与专业的视觉和音频编码器在表征上更接近。", "motivation": "尽管大语言模型（LLMs）纯粹基于文本训练，缺乏直接的感知经验，但其内部表征隐式地包含了语言中编码的多模态规律。研究旨在验证感官提示能否显式地激活这种潜在结构，使文本LLM的表征与专业的视觉和音频编码器更一致。", "method": "使用感官提示（如“看”或“听”）来引导模型预测下一个词元，使其表现得如同这些预测是基于从未实际提供的潜在视觉或听觉证据进行条件化一样。", "result": "研究发现，轻量级的提示工程能够可靠地激活纯文本训练的LLMs中与模态相适应的表征。", "conclusion": "感官提示是一种有效的方法，可以揭示纯文本训练LLMs中潜在的多模态结构，从而在表征上实现与专业感知编码器的对齐。"}}
{"id": "2510.02811", "categories": ["cs.CL", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.02811", "abs": "https://arxiv.org/abs/2510.02811", "authors": ["Matej Gjurković"], "title": "A Computational Framework for Interpretable Text-Based Personality Assessment from Social Media", "comment": "Phd thesis", "summary": "Personality refers to individual differences in behavior, thinking, and\nfeeling. With the growing availability of digital footprints, especially from\nsocial media, automated methods for personality assessment have become\nincreasingly important. Natural language processing (NLP) enables the analysis\nof unstructured text data to identify personality indicators. However, two main\nchallenges remain central to this thesis: the scarcity of large,\npersonality-labeled datasets and the disconnect between personality psychology\nand NLP, which restricts model validity and interpretability. To address these\nchallenges, this thesis presents two datasets -- MBTI9k and PANDORA --\ncollected from Reddit, a platform known for user anonymity and diverse\ndiscussions. The PANDORA dataset contains 17 million comments from over 10,000\nusers and integrates the MBTI and Big Five personality models with demographic\ninformation, overcoming limitations in data size, quality, and label coverage.\nExperiments on these datasets show that demographic variables influence model\nvalidity. In response, the SIMPA (Statement-to-Item Matching Personality\nAssessment) framework was developed - a computational framework for\ninterpretable personality assessment that matches user-generated statements\nwith validated questionnaire items. By using machine learning and semantic\nsimilarity, SIMPA delivers personality assessments comparable to human\nevaluations while maintaining high interpretability and efficiency. Although\nfocused on personality assessment, SIMPA's versatility extends beyond this\ndomain. Its model-agnostic design, layered cue detection, and scalability make\nit suitable for various research and practical applications involving complex\nlabel taxonomies and variable cue associations with target concepts.", "AI": {"tldr": "本论文通过构建MBTI9k和PANDORA两个大型数据集，并开发了可解释的SIMPA框架，解决了自动化人格评估中数据稀缺和理论模型脱节的挑战，实现了与人类评估相当的、高效且可解释的个性评估。", "motivation": "随着数字足迹（特别是社交媒体数据）的日益普及，自动化人格评估变得越来越重要。然而，该领域面临两大挑战：缺乏大规模、带有人格标签的数据集，以及人格心理学与自然语言处理（NLP）之间的脱节，这限制了模型的有效性和可解释性。", "method": "为解决上述挑战，本论文采取了以下方法：1. 从Reddit收集并构建了两个数据集：MBTI9k和PANDORA。PANDORA包含1700万条评论，来自1万多用户，并整合了MBTI、大五人格模型和人口统计信息。2. 开发了SIMPA（Statement-to-Item Matching Personality Assessment）框架，这是一个可解释的计算框架，通过机器学习和语义相似性将用户生成的陈述与经过验证的问卷条目进行匹配。", "result": "研究结果表明：1. 人口统计变量会影响模型有效性。2. SIMPA框架提供的人格评估结果与人类评估相当，同时保持了高可解释性和效率。3. SIMPA的设计（模型无关、分层线索检测、可扩展性）使其用途广泛，不仅限于人格评估，还适用于涉及复杂标签分类和目标概念关联的各种研究和实际应用。", "conclusion": "本论文通过提供大规模数据集和开发创新的SIMPA框架，成功应对了自动化人格评估中的核心挑战。SIMPA不仅实现了高效且可解释的个性评估，其通用性也使其成为处理复杂标签分类和多变线索关联任务的强大工具，具有广泛的应用潜力。"}}
{"id": "2510.03012", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03012", "abs": "https://arxiv.org/abs/2510.03012", "authors": ["Haoze Sun", "Linfeng Jiang", "Fan Li", "Renjing Pei", "Zhixin Wang", "Yong Guo", "Jiaqi Xu", "Haoyu Chen", "Jin Han", "Fenglong Song", "Yujiu Yang", "Wenbo Li"], "title": "PocketSR: The Super-Resolution Expert in Your Pocket Mobiles", "comment": null, "summary": "Real-world image super-resolution (RealSR) aims to enhance the visual quality\nof in-the-wild images, such as those captured by mobile phones. While existing\nmethods leveraging large generative models demonstrate impressive results, the\nhigh computational cost and latency make them impractical for edge deployment.\nIn this paper, we introduce PocketSR, an ultra-lightweight, single-step model\nthat brings generative modeling capabilities to RealSR while maintaining high\nfidelity. To achieve this, we design LiteED, a highly efficient alternative to\nthe original computationally intensive VAE in SD, reducing parameters by 97.5%\nwhile preserving high-quality encoding and decoding. Additionally, we propose\nonline annealing pruning for the U-Net, which progressively shifts generative\npriors from heavy modules to lightweight counterparts, ensuring effective\nknowledge transfer and further optimizing efficiency. To mitigate the loss of\nprior knowledge during pruning, we incorporate a multi-layer feature\ndistillation loss. Through an in-depth analysis of each design component, we\nprovide valuable insights for future research. PocketSR, with a model size of\n146M parameters, processes 4K images in just 0.8 seconds, achieving a\nremarkable speedup over previous methods. Notably, it delivers performance on\npar with state-of-the-art single-step and even multi-step RealSR models, making\nit a highly practical solution for edge-device applications.", "AI": {"tldr": "PocketSR是一种超轻量级、单步的真实世界图像超分辨率（RealSR）模型，它将生成式建模能力带到边缘设备，同时保持高保真度，解决了现有大型生成模型计算成本高、延迟大的问题。", "motivation": "现有的利用大型生成模型进行真实世界图像超分辨率（RealSR）的方法虽然效果显著，但其高昂的计算成本和延迟使其不适用于边缘部署，例如手机上的应用。", "method": "本文提出了PocketSR，一个超轻量级、单步模型。主要方法包括：1) 设计LiteED，一个高效的VAE替代品，将参数减少97.5%同时保持高质量编解码；2) 提出U-Net的在线退火剪枝，逐步将生成先验从重型模块转移到轻量级模块；3) 引入多层特征蒸馏损失，以减轻剪枝过程中先验知识的损失。", "result": "PocketSR模型大小为146M参数，能够在0.8秒内处理4K图像，相比现有方法显著加速。其性能与最先进的单步甚至多步RealSR模型相当，使其成为边缘设备应用的实用解决方案。", "conclusion": "PocketSR提供了一个在边缘设备上实现RealSR的高效、高性能和实用解决方案，通过创新的轻量化设计，成功地将生成式建模能力带入资源受限的环境，同时保持了卓越的图像质量。"}}
{"id": "2510.02524", "categories": ["cs.CL", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02524", "abs": "https://arxiv.org/abs/2510.02524", "authors": ["Laura Ying Schulz", "Daniel Mitropolsky", "Tomaso Poggio"], "title": "Unraveling Syntax: How Language Models Learn Context-Free Grammars", "comment": "Equal contribution by LYS and DM", "summary": "We introduce a new framework for understanding how language models acquire\nsyntax. While large models achieve impressive results, little is known about\ntheir learning dynamics. Our approach starts with the observation that most\ndomains of interest, such as natural language syntax, coding languages,\narithmetic problems, are captured by probabilistic context-free grammars\n(PCFGs). We study the learning dynamics of small models trained on synthetic\nlanguages generated from PCFGs, enabling precise control over grammar\ncomplexity, recursion depth, and subgrammar structure. We prove several\ngeneral, recursive formulae for the training loss and Kullback-Leibler\ndivergence over the subgrammar structure of a PCFG. Empirically, we find that\nunlike children, who first master simple substructures before progressing to\nmore complex constructions, transformers reduce loss across all subgrammars in\nparallel. We further show that subgrammar pretraining can improve the final\nloss for smaller models, and that pretrained models develop internal\nrepresentations more aligned with the grammar's substructure. Finally, we\ndemonstrate that models struggle with deeper recursive structures (a limitation\neven of large language models), revealing fundamental challenges in how neural\nnetworks represent hierarchical syntax. Overall, our work initiates the study\nof the learning dynamics of transformers on PCFGs as a versatile testbed for\nprobing learning in language models, opening a research direction with many\nopen questions.", "AI": {"tldr": "本文提出了一个新框架，通过在概率上下文无关文法（PCFG）生成的合成语言上训练小型模型，来理解语言模型如何学习句法。研究发现，Transformer模型并行地降低所有子文法的损失，与儿童学习方式不同；子文法预训练可以改善小模型的性能并使其内部表示与文法结构更一致；模型在处理深度递归结构时表现出困难，揭示了神经网络表示层次句法的根本挑战。", "motivation": "尽管大型语言模型取得了令人瞩目的成就，但人们对其学习动态，特别是句法习得过程知之甚少。大多数感兴趣的领域（如自然语言句法、编程语言、算术问题）都可以用概率上下文无关文法（PCFG）来描述。", "method": "研究方法包括：1) 在PCFG生成的合成语言上训练小型语言模型，从而精确控制文法复杂性、递归深度和子文法结构。2) 证明了关于PCFG子文法结构上训练损失和Kullback-Leibler散度的几个通用递归公式。", "result": "主要结果有：1) Transformer模型与儿童不同，它并行地降低所有子文法的损失。2) 子文法预训练可以提高小型模型的最终损失，并使预训练模型的内部表示与文法子结构更对齐。3) 模型难以处理深度递归结构，这甚至对大型语言模型也是一个限制。", "conclusion": "这项工作开创了利用PCFG作为多功能测试平台来研究Transformer学习动态的方向，揭示了神经网络在表示层次句法方面的基本挑战，并为未来的研究提出了许多开放性问题。"}}
{"id": "2510.02830", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6; J.3"], "pdf": "https://arxiv.org/pdf/2510.02830", "abs": "https://arxiv.org/abs/2510.02830", "authors": ["Shinya Uryu"], "title": "Evaluating Large Language Models for IUCN Red List Species Information", "comment": "20 pages, 7 figures", "summary": "Large Language Models (LLMs) are rapidly being adopted in conservation to\naddress the biodiversity crisis, yet their reliability for species evaluation\nis uncertain. This study systematically validates five leading models on 21,955\nspecies across four core IUCN Red List assessment components: taxonomy,\nconservation status, distribution, and threats. A critical paradox was\nrevealed: models excelled at taxonomic classification (94.9%) but consistently\nfailed at conservation reasoning (27.2% for status assessment). This\nknowledge-reasoning gap, evident across all models, suggests inherent\narchitectural constraints, not just data limitations. Furthermore, models\nexhibited systematic biases favoring charismatic vertebrates, potentially\namplifying existing conservation inequities. These findings delineate clear\nboundaries for responsible LLM deployment: they are powerful tools for\ninformation retrieval but require human oversight for judgment-based decisions.\nA hybrid approach is recommended, where LLMs augment expert capacity while\nhuman experts retain sole authority over risk assessment and policy.", "AI": {"tldr": "本研究系统性验证了大型语言模型（LLMs）在物种评估方面的可靠性，发现LLMs擅长分类但推理能力不足且存在偏见，建议采用人机协作模式。", "motivation": "大型语言模型（LLMs）正迅速被应用于解决生物多样性危机中的物种评估，但它们在此领域的可靠性尚不确定。", "method": "本研究系统性地验证了五种主流LLMs，评估了它们在21,955个物种上，针对IUCN红色名录评估的四个核心组成部分（分类学、保护状况、分布和威胁）的表现。", "result": "研究揭示了一个关键悖论：模型在分类学分类方面表现出色（94.9%），但在保护推理方面（例如状况评估，准确率仅为27.2%）持续失败。这种知识-推理差距在所有模型中都存在，表明其内在架构限制而非仅仅数据限制。此外，模型表现出系统性偏见，偏爱魅力型脊椎动物，可能加剧现有保护不平等。", "conclusion": "研究划定了LLM负责任部署的清晰界限：它们是强大的信息检索工具，但在基于判断的决策中需要人类监督。建议采用混合方法，即LLMs增强专家能力，而人类专家保留风险评估和政策制定的唯一权威。"}}
{"id": "2510.03049", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03049", "abs": "https://arxiv.org/abs/2510.03049", "authors": ["Ruotong Liao", "Guowen Huang", "Qing Cheng", "Thomas Seidl", "Daniel Cremers", "Volker Tresp"], "title": "When and Where do Events Switch in Multi-Event Video Generation?", "comment": "Work in Progress. Accepted to ICCV2025 @ LongVid-Foundations", "summary": "Text-to-video (T2V) generation has surged in response to challenging\nquestions, especially when a long video must depict multiple sequential events\nwith temporal coherence and controllable content. Existing methods that extend\nto multi-event generation omit an inspection of the intrinsic factor in event\nshifting. The paper aims to answer the central question: When and where\nmulti-event prompts control event transition during T2V generation. This work\nintroduces MEve, a self-curated prompt suite for evaluating multi-event\ntext-to-video (T2V) generation, and conducts a systematic study of two\nrepresentative model families, i.e., OpenSora and CogVideoX. Extensive\nexperiments demonstrate the importance of early intervention in denoising steps\nand block-wise model layers, revealing the essential factor for multi-event\nvideo generation and highlighting the possibilities for multi-event\nconditioning in future models.", "AI": {"tldr": "本文提出MEve数据集，并系统研究了多事件文本到视频生成中事件转换的控制机制，强调了去噪步骤早期干预和块级模型层的重要性。", "motivation": "现有文本到视频（T2V）生成方法在处理包含多个连续事件且需要时间连贯性和内容可控性的长视频时面临挑战，尤其是在多事件生成中忽略了事件转换的内在因素。", "method": "本文引入了MEve，一个用于评估多事件T2V生成的自策展提示套件，并对OpenSora和CogVideoX这两个代表性模型家族进行了系统研究。", "result": "广泛的实验表明，在去噪步骤的早期干预以及块级模型层中进行干预至关重要，揭示了多事件视频生成的关键因素。", "conclusion": "研究结果突出了未来模型中多事件条件控制的可能性，为改进多事件T2V生成提供了方向。"}}
{"id": "2510.02539", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.02539", "abs": "https://arxiv.org/abs/2510.02539", "authors": ["Anant Gupta", "Karthik Singaravadivelan", "Zekun Wang"], "title": "Hierarchical Semantic Retrieval with Cobweb", "comment": "20 pages, 7 tables, 4 figures", "summary": "Neural document retrieval often treats a corpus as a flat cloud of vectors\nscored at a single granularity, leaving corpus structure underused and\nexplanations opaque. We use Cobweb--a hierarchy-aware framework--to organize\nsentence embeddings into a prototype tree and rank documents via coarse-to-fine\ntraversal. Internal nodes act as concept prototypes, providing multi-granular\nrelevance signals and a transparent rationale through retrieval paths. We\ninstantiate two inference approaches: a generalized best-first search and a\nlightweight path-sum ranker. We evaluate our approaches on MS MARCO and QQP\nwith encoder (e.g., BERT/T5) and decoder (GPT-2) representations. Our results\nshow that our retrieval approaches match the dot product search on strong\nencoder embeddings while remaining robust when kNN degrades: with GPT-2\nvectors, dot product performance collapses whereas our approaches still\nretrieve relevant results. Overall, our experiments suggest that Cobweb\nprovides competitive effectiveness, improved robustness to embedding quality,\nscalability, and interpretable retrieval via hierarchical prototypes.", "AI": {"tldr": "该研究利用Cobweb框架将句子嵌入组织成原型树，通过粗到细的遍历实现分层、可解释的文档检索，并在嵌入质量下降时表现出更强的鲁棒性。", "motivation": "现有的神经文档检索方法通常将语料库视为扁平的向量集合，未能充分利用语料库的结构信息，且解释性不足。", "method": "研究采用Cobweb框架将句子嵌入组织成一个原型树，通过粗到细的遍历来对文档进行排名。树的内部节点作为概念原型，提供多粒度的相关性信号和可解释的检索路径。文中提出了两种推理方法：广义最佳优先搜索和轻量级路径和排名器。这些方法在MS MARCO和QQP数据集上，使用编码器（如BERT/T5）和解码器（GPT-2）表示进行了评估。", "result": "研究结果表明，该检索方法在强大的编码器嵌入上与点积搜索性能相当，并且在kNN性能下降时表现出更强的鲁棒性：当使用GPT-2向量时，点积搜索的性能会崩溃，而Cobweb方法仍能检索到相关结果。", "conclusion": "实验表明，Cobweb框架通过分层原型提供了具有竞争力的有效性、对嵌入质量的鲁棒性、可扩展性以及可解释的检索能力。"}}
{"id": "2510.02855", "categories": ["cs.CL", "cs.AI", "68T20, 90C27", "I.2.8; I.2.3; G.1.6"], "pdf": "https://arxiv.org/pdf/2510.02855", "abs": "https://arxiv.org/abs/2510.02855", "authors": ["Jahidul Arafat", "Fariha Tasmin", "Sanjaya Poudel", "Kamrujjaman", "Eftakhar Ahmed Arnob", "Ahsan Habib Tareq"], "title": "Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation", "comment": "35 pages, 14 figures, 10 tables. Open-source implementation with 91%\n  test coverage available at\n  https://github.com/jahidul-arafat/constraint_satisfaction_wordle_arxiv_preprint", "summary": "Wordle presents an algorithmically rich testbed for constraint satisfaction\nproblem (CSP) solving. While existing solvers rely on information-theoretic\nentropy maximization or frequency-based heuristics without formal constraint\ntreatment, we present the first comprehensive CSP formulation of Wordle with\nnovel constraint-aware solving strategies. We introduce CSP-Aware Entropy,\ncomputing information gain after constraint propagation rather than on raw\ncandidate sets, and a Probabilistic CSP framework integrating Bayesian\nword-frequency priors with logical constraints. Through evaluation on 2,315\nEnglish words, CSP-Aware Entropy achieves 3.54 average guesses with 99.9%\nsuccess rate, a statistically significant 1.7% improvement over Forward\nChecking (t=-4.82, p<0.001, Cohen's d=0.07) with 46% faster runtime (12.9ms\nversus 23.7ms per guess). Under 10% noise, CSP-aware approaches maintain 5.3\npercentage point advantages (29.0% versus 23.7%, p=0.041), while Probabilistic\nCSP achieves 100% success across all noise levels (0-20%) through constraint\nrecovery mechanisms. Cross-lexicon validation on 500 Spanish words demonstrates\n88% success with zero language-specific tuning, validating that core CSP\nprinciples transfer across languages despite an 11.2 percentage point gap from\nlinguistic differences (p<0.001, Fisher's exact test). Our open-source\nimplementation with 34 unit tests achieving 91% code coverage provides\nreproducible infrastructure for CSP research. The combination of formal CSP\ntreatment, constraint-aware heuristics, probabilistic-logical integration,\nrobustness analysis, and cross-lexicon validation establishes new performance\nbenchmarks demonstrating that principled constraint satisfaction techniques\noutperform classical information-theoretic and learning-based approaches for\nstructured puzzle-solving domains.", "AI": {"tldr": "本文首次对Wordle进行了全面的约束满足问题（CSP）公式化，并提出了CSP-Aware Entropy和Probabilistic CSP等新颖的求解策略，在猜测次数、成功率和鲁棒性方面均超越了现有方法。", "motivation": "现有的Wordle解算器依赖于信息论熵最大化或基于频率的启发式方法，但缺乏对约束的正式处理，这促使研究者探索更严谨的约束满足方法。", "method": "研究者首次提出了Wordle的全面CSP公式化，并引入了两种新策略：1. CSP-Aware Entropy，它在约束传播后而非原始候选集上计算信息增益。2. Probabilistic CSP框架，它将贝叶斯词频先验与逻辑约束相结合。", "result": "CSP-Aware Entropy在2,315个英文单词上平均3.54次猜测，成功率99.9%，比Forward Checking提高1.7%（统计显著）且运行速度快46%。在10%噪声下，CSP-aware方法保持5.3个百分点优势。Probabilistic CSP在0-20%所有噪声水平下均实现100%成功率。跨词库验证（500个西班牙语单词）在零语言特定调整下达到88%的成功率。", "conclusion": "形式化的CSP处理、约束感知启发式、概率-逻辑集成、鲁棒性分析和跨词库验证相结合，证明了原则性的约束满足技术在结构化谜题解决领域优于经典的信息论和基于学习的方法，并建立了新的性能基准。"}}
{"id": "2510.03066", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03066", "abs": "https://arxiv.org/abs/2510.03066", "authors": ["Ahsan Farabi", "Israt Khandaker", "Ibrahim Khalil Shanto", "Md Abdul Ahad Minhaz", "Tanisha Zaman"], "title": "InsideOut: An EfficientNetV2-S Based Deep Learning Framework for Robust Multi-Class Facial Emotion Recognition", "comment": null, "summary": "Facial Emotion Recognition (FER) is a key task in affective computing,\nenabling applications in human-computer interaction, e-learning, healthcare,\nand safety systems. Despite advances in deep learning, FER remains challenging\ndue to occlusions, illumination and pose variations, subtle intra-class\ndifferences, and dataset imbalance that hinders recognition of minority\nemotions. We present InsideOut, a reproducible FER framework built on\nEfficientNetV2-S with transfer learning, strong data augmentation, and\nimbalance-aware optimization. The approach standardizes FER2013 images, applies\nstratified splitting and augmentation, and fine-tunes a lightweight\nclassification head with class-weighted loss to address skewed distributions.\nInsideOut achieves 62.8% accuracy with a macro averaged F1 of 0.590 on FER2013,\nshowing competitive results compared to conventional CNN baselines. The novelty\nlies in demonstrating that efficient architectures, combined with tailored\nimbalance handling, can provide practical, transparent, and reproducible FER\nsolutions.", "AI": {"tldr": "本文提出了一个名为InsideOut的可复现面部情感识别（FER）框架，该框架基于EfficientNetV2-S并结合迁移学习、数据增强和不平衡感知优化，在FER2013数据集上取得了有竞争力的结果。", "motivation": "面部情感识别（FER）在情感计算中至关重要，但面临遮挡、光照和姿态变化、细微的类内差异以及数据集不平衡（特别是少数情感识别困难）等挑战，这些因素阻碍了其在实际应用中的进展。", "method": "InsideOut框架通过以下方法实现：1) 基于EfficientNetV2-S模型并进行迁移学习；2) 应用强大的数据增强技术；3) 采用不平衡感知优化，具体包括标准化FER2013图像、分层数据划分和增强、以及使用类别加权损失微调轻量级分类头以解决数据分布倾斜问题。", "result": "InsideOut在FER2013数据集上达到了62.8%的准确率和0.590的宏平均F1分数，与传统的CNN基线相比，展现出具有竞争力的结果。", "conclusion": "研究表明，高效的架构与量身定制的不平衡处理方法相结合，能够提供实用、透明且可复现的面部情感识别解决方案。"}}
{"id": "2510.02569", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02569", "abs": "https://arxiv.org/abs/2510.02569", "authors": ["Tolúl\\d{o}pé Ògúnrèmí", "Christopher D. Manning", "Dan Jurafsky", "Karen Livescu"], "title": "Transcribe, Translate, or Transliterate: An Investigation of Intermediate Representations in Spoken Language Models", "comment": "ASRU 2025", "summary": "Spoken language models (SLMs) that integrate speech with large language\nmodels (LMs) rely on modality adapters (MAs) to map the output of speech\nencoders to a representation that is understandable to the decoder LM. Yet we\nknow very little about how these crucial MAs transform representations. Here we\nexamine the MA output representation in three SLMs (SALMONN, Qwen2-Audio and\nPhi-4-Multimodal-Instruct). By finding the nearest decoder LM token to an MA\nrepresentation, we uncover two strategies for MA representations. For models\nusing a Whisper encoder, MAs appear to represent the meaning of the input using\nan English-based interlingua, allowing them to handle languages unseen in\ninstruction tuning. For models that don't, like Phi-4-Multimodal-Instruct, MAs\ninstead represent the phonetics of the input, but expressed with English words.\nWe hypothesise that which arises depends on whether the speech encoder is\ntrained only for speech recognition or also for translation.", "AI": {"tldr": "本研究探讨了语音语言模型（SLMs）中模态适配器（MAs）如何转换语音表示，发现其策略取决于语音编码器是否包含翻译训练。", "motivation": "目前对SLMs中关键的模态适配器如何转换表示知之甚少。", "method": "通过在三种SLMs（SALMONN、Qwen2-Audio和Phi-4-Multimodal-Instruct）中，寻找MA输出表示最接近的解码器语言模型（LM）token来检查MA输出表示。", "result": "发现了两种MA表示策略：使用Whisper编码器的模型倾向于使用基于英语的中间语来表示输入含义，从而处理指令微调中未见的语言；不使用Whisper编码器的模型（如Phi-4-Multimodal-Instruct）则使用英语单词来表示输入的语音。 ", "conclusion": "研究者推测，MA采用何种策略取决于语音编码器是仅为语音识别训练，还是也为翻译训练。"}}
{"id": "2510.02967", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.02967", "abs": "https://arxiv.org/abs/2510.02967", "authors": ["Matthew Lewis", "Samuel Thio", "Richard JB Dobson", "Spiros Denaxas"], "title": "Grounding Large Language Models in Clinical Evidence: A Retrieval-Augmented Generation System for Querying UK NICE Clinical Guidelines", "comment": null, "summary": "This paper presents the development and evaluation of a Retrieval-Augmented\nGeneration (RAG) system for querying the United Kingdom's National Institute\nfor Health and Care Excellence (NICE) clinical guidelines using Large Language\nModels (LLMs). The extensive length and volume of these guidelines can impede\ntheir utilisation within a time-constrained healthcare system, a challenge this\nproject addresses through the creation of a system capable of providing users\nwith precisely matched information in response to natural language queries. The\nsystem's retrieval architecture, composed of a hybrid embedding mechanism, was\nevaluated against a database of 10,195 text chunks derived from three hundred\nguidelines. It demonstrates high performance, with a Mean Reciprocal Rank (MRR)\nof 0.814, a Recall of 81% at the first chunk and of 99.1% within the top ten\nretrieved chunks, when evaluated on 7901 queries.\n  The most significant impact of the RAG system was observed during the\ngeneration phase. When evaluated on a manually curated dataset of seventy\nquestion-answer pairs, RAG-enhanced models showed substantial gains in\nperformance. Faithfulness, the measure of whether an answer is supported by the\nsource text, was increased by 64.7 percentage points to 99.5% for the\nRAG-enhanced O4-Mini model and significantly outperformed the medical-focused\nMeditron3-8B LLM, which scored 43%. This, combined with a perfect Context\nPrecision score of 1 for all RAG-enhanced models, confirms the system's ability\nto prevent information fabrication by grounding its answers in relevant source\nmaterial. This study thus establishes RAG as an effective, reliable, and\nscalable approach for applying generative AI in healthcare, enabling\ncost-effective access to medical guidelines.", "AI": {"tldr": "本文开发并评估了一个检索增强生成（RAG）系统，用于使用大型语言模型（LLM）查询英国NICE临床指南。该系统在检索阶段表现出色，并在生成阶段显著提高了答案的忠实度（达到99.5%），有效防止了信息捏造，证明了其在医疗领域应用的有效性、可靠性和可扩展性。", "motivation": "英国国家健康与护理卓越研究院（NICE）的临床指南篇幅浩大、数量众多，这在时间受限的医疗体系中阻碍了其有效利用。研究旨在开发一个系统，能够根据自然语言查询为用户提供精确匹配的信息，以解决这一挑战。", "method": "本文开发了一个RAG系统，其检索架构采用混合嵌入机制。该系统在包含10,195个文本块（来自300份指南）的数据库上进行评估，并使用7901个查询测试检索性能。生成阶段的评估则基于70对人工整理的问答对，重点衡量答案的忠实度和上下文准确性，并与非RAG增强模型（如Meditron3-8B LLM）进行比较。", "result": "在检索阶段，系统表现出高效率，平均倒数排名（MRR）为0.814，第一个检索块的召回率为81%，前十个检索块内的召回率高达99.1%。在生成阶段，RAG增强模型表现出显著的性能提升：O4-Mini模型的忠实度增加了64.7个百分点，达到99.5%，远超医学专用LLM Meditron3-8B（43%）。所有RAG增强模型的上下文准确性得分均为1，这证实了系统通过将答案基于相关源材料来防止信息捏造的能力。", "conclusion": "本研究确立了RAG作为一种有效、可靠且可扩展的方法，可将生成式人工智能应用于医疗保健领域，从而实现经济高效地获取医疗指南。该系统能显著提高答案的忠实度并防止信息捏造。"}}
{"id": "2510.03075", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03075", "abs": "https://arxiv.org/abs/2510.03075", "authors": ["Karim Farid", "Rajat Sahay", "Yumna Ali Alnaggar", "Simon Schrodi", "Volker Fischer", "Cordelia Schmid", "Thomas Brox"], "title": "What Drives Compositional Generalization in Visual Generative Models?", "comment": null, "summary": "Compositional generalization, the ability to generate novel combinations of\nknown concepts, is a key ingredient for visual generative models. Yet, not all\nmechanisms that enable or inhibit it are fully understood. In this work, we\nconduct a systematic study of how various design choices influence\ncompositional generalization in image and video generation in a positive or\nnegative way. Through controlled experiments, we identify two key factors: (i)\nwhether the training objective operates on a discrete or continuous\ndistribution, and (ii) to what extent conditioning provides information about\nthe constituent concepts during training. Building on these insights, we show\nthat relaxing the MaskGIT discrete loss with an auxiliary continuous JEPA-based\nobjective can improve compositional performance in discrete models like\nMaskGIT.", "AI": {"tldr": "本文系统研究了视觉生成模型中组合泛化的影响因素，发现离散/连续训练目标和条件信息量是关键。通过引入辅助连续目标，可以提升离散模型的组合泛化能力。", "motivation": "组合泛化是视觉生成模型的关键能力，但其启用或抑制机制尚未完全理解。", "method": "通过受控实验系统研究了不同设计选择对图像和视频生成中组合泛化的影响。具体地，将MaskGIT的离散损失与基于JEPA的辅助连续目标结合。", "result": "识别出两个关键因素：(i) 训练目标是基于离散还是连续分布；(ii) 训练期间条件作用为构成概念提供信息的程度。研究表明，通过基于JEPA的辅助连续目标放松MaskGIT的离散损失可以改善MaskGIT等离散模型的组合性能。", "conclusion": "设计选择，特别是训练目标的类型和条件信息量，显著影响生成模型的组合泛化能力。离散模型可以通过引入辅助的连续目标来提升其组合泛化性能。"}}
{"id": "2510.02629", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02629", "abs": "https://arxiv.org/abs/2510.02629", "authors": ["Jingyi Sun", "Pepa Atanasova", "Sagnik Ray Choudhury", "Sekh Mainul Islam", "Isabelle Augenstein"], "title": "Evaluation Framework for Highlight Explanations of Context Utilisation in Language Models", "comment": null, "summary": "Context utilisation, the ability of Language Models (LMs) to incorporate\nrelevant information from the provided context when generating responses,\nremains largely opaque to users, who cannot determine whether models draw from\nparametric memory or provided context, nor identify which specific context\npieces inform the response. Highlight explanations (HEs) offer a natural\nsolution as they can point the exact context pieces and tokens that influenced\nmodel outputs. However, no existing work evaluates their effectiveness in\naccurately explaining context utilisation. We address this gap by introducing\nthe first gold standard HE evaluation framework for context attribution, using\ncontrolled test cases with known ground-truth context usage, which avoids the\nlimitations of existing indirect proxy evaluations. To demonstrate the\nframework's broad applicability, we evaluate four HE methods -- three\nestablished techniques and MechLight, a mechanistic interpretability approach\nwe adapt for this task -- across four context scenarios, four datasets, and\nfive LMs. Overall, we find that MechLight performs best across all context\nscenarios. However, all methods struggle with longer contexts and exhibit\npositional biases, pointing to fundamental challenges in explanation accuracy\nthat require new approaches to deliver reliable context utilisation\nexplanations at scale.", "AI": {"tldr": "本文提出了首个用于评估语言模型（LM）上下文利用率高亮解释（HEs）的黄金标准评估框架，发现现有方法（包括表现最佳的MechLight）在长上下文和位置偏差方面仍面临挑战。", "motivation": "用户无法确定语言模型是利用上下文信息还是参数记忆来生成响应，也无法识别具体哪些上下文片段影响了输出。高亮解释是解决此问题的自然方案，但目前尚无工作评估其在准确解释上下文利用方面的有效性。", "method": "研究引入了首个针对上下文归因的黄金标准高亮解释评估框架，该框架使用已知真实上下文使用情况的受控测试用例。研究评估了四种高亮解释方法（三种现有技术和一种改编的机械可解释性方法MechLight），跨越四种上下文场景、四个数据集和五个语言模型。", "result": "MechLight在所有上下文场景中表现最佳。然而，所有方法在处理较长上下文时都表现不佳，并存在位置偏差。", "conclusion": "现有解释方法在准确性方面存在根本性挑战，需要新的方法才能大规模提供可靠的上下文利用解释。"}}
{"id": "2510.03060", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03060", "abs": "https://arxiv.org/abs/2510.03060", "authors": ["Rongchen Guo", "Vincent Francoeur", "Isar Nejadgholi", "Sylvain Gagnon", "Miodrag Bolic"], "title": "Semantic Differentiation in Speech Emotion Recognition: Insights from Descriptive and Expressive Speech Roles", "comment": "Accepted to the *SEM conference collocated with EMNLP2025", "summary": "Speech Emotion Recognition (SER) is essential for improving human-computer\ninteraction, yet its accuracy remains constrained by the complexity of\nemotional nuances in speech. In this study, we distinguish between descriptive\nsemantics, which represents the contextual content of speech, and expressive\nsemantics, which reflects the speaker's emotional state. After watching\nemotionally charged movie segments, we recorded audio clips of participants\ndescribing their experiences, along with the intended emotion tags for each\nclip, participants' self-rated emotional responses, and their valence/arousal\nscores. Through experiments, we show that descriptive semantics align with\nintended emotions, while expressive semantics correlate with evoked emotions.\nOur findings inform SER applications in human-AI interaction and pave the way\nfor more context-aware AI systems.", "AI": {"tldr": "本研究区分了描述性语义（上下文内容）和表达性语义（说话者情绪状态），发现描述性语义与预期情绪一致，而表达性语义与唤起情绪相关，从而为语音情感识别（SER）和更具情境感知的AI系统提供了新见解。", "motivation": "语音情感识别（SER）对改善人机交互至关重要，但其准确性受限于语音中情感细微差别的复杂性。", "method": "参与者观看情感电影片段后，录制描述其经历的音频片段，并提供预期情感标签、自我评估的情绪反应以及效价/唤醒度评分。研究区分了描述性语义（代表语音的上下文内容）和表达性语义（反映说话者的情绪状态）。", "result": "实验表明，描述性语义与预期情绪相符，而表达性语义与唤起情绪相关。", "conclusion": "研究结果为人机交互中的语音情感识别应用提供了信息，并为开发更具情境感知能力的AI系统铺平了道路。"}}
{"id": "2510.03089", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03089", "abs": "https://arxiv.org/abs/2510.03089", "authors": ["Naresh Kumar Devulapally", "Shruti Agarwal", "Tejas Gokhale", "Vishnu Suresh Lokhande"], "title": "Latent Diffusion Unlearning: Protecting Against Unauthorized Personalization Through Trajectory Shifted Perturbations", "comment": null, "summary": "Text-to-image diffusion models have demonstrated remarkable effectiveness in\nrapid and high-fidelity personalization, even when provided with only a few\nuser images. However, the effectiveness of personalization techniques has lead\nto concerns regarding data privacy, intellectual property protection, and\nunauthorized usage. To mitigate such unauthorized usage and model replication,\nthe idea of generating ``unlearnable'' training samples utilizing image\npoisoning techniques has emerged. Existing methods for this have limited\nimperceptibility as they operate in the pixel space which results in images\nwith noise and artifacts. In this work, we propose a novel model-based\nperturbation strategy that operates within the latent space of diffusion\nmodels. Our method alternates between denoising and inversion while modifying\nthe starting point of the denoising trajectory: of diffusion models. This\ntrajectory-shifted sampling ensures that the perturbed images maintain high\nvisual fidelity to the original inputs while being resistant to inversion and\npersonalization by downstream generative models. This approach integrates\nunlearnability into the framework of Latent Diffusion Models (LDMs), enabling a\npractical and imperceptible defense against unauthorized model adaptation. We\nvalidate our approach on four benchmark datasets to demonstrate robustness\nagainst state-of-the-art inversion attacks. Results demonstrate that our method\nachieves significant improvements in imperceptibility ($\\sim 8 \\% -10\\%$ on\nperceptual metrics including PSNR, SSIM, and FID) and robustness ( $\\sim 10\\%$\non average across five adversarial settings), highlighting its effectiveness in\nsafeguarding sensitive data.", "AI": {"tldr": "本文提出了一种在潜在空间中对文本到图像扩散模型进行扰动的新方法，通过修改去噪轨迹的起始点，生成视觉上高保真且能抵抗下游生成模型反演和个性化的“不可学习”图像，有效解决了数据隐私和未经授权使用的担忧。", "motivation": "文本到图像扩散模型在快速和高保真个性化方面表现出色，但也引发了数据隐私、知识产权保护和未经授权使用的担忧。现有的“不可学习”训练样本生成方法（图像中毒）通常在像素空间操作，导致图像存在噪声和伪影，限制了其不可感知性。", "method": "本文提出了一种新颖的基于模型的扰动策略，该策略在扩散模型的潜在空间中运行。它通过交替进行去噪和反演，同时修改去噪轨迹的起始点（即“轨迹偏移采样”）。这种方法将“不可学习性”集成到潜在扩散模型（LDMs）的框架中，确保扰动图像保持高视觉保真度，同时抵抗下游生成模型的反演和个性化。", "result": "该方法在四个基准数据集上进行了验证，结果表明，与最先进的反演攻击相比，其在不可感知性方面（PSNR、SSIM和FID等感知指标上提高约8%-10%）和鲁棒性方面（在五种对抗性设置下平均提高约10%）均取得了显著改进。", "conclusion": "本文提出的方法提供了一种实用且不可感知的防御机制，能够有效对抗未经授权的模型适应，并通过生成“不可学习”的图像来保护敏感数据。"}}
{"id": "2510.02645", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02645", "abs": "https://arxiv.org/abs/2510.02645", "authors": ["Fulei Zhang", "Zhou Yu"], "title": "Mind the Gap: Linguistic Divergence and Adaptation Strategies in Human-LLM Assistant vs. Human-Human Interactions", "comment": "Accepted to The Second Workshop on Generative AI for E-commerce\n  (GenAIECommerce '25), held September 22, 2025, in Prague, Czech Republic", "summary": "As Large Language Models (LLMs) are increasingly deployed in customer-facing\napplications, a critical yet underexplored question is how users communicate\ndifferently with LLM chatbots compared to human agent. In this study, we\npresent empirical evidence that users adopt distinct communication styles when\nusers interact with chatbots versus human agents. Our analysis reveals\nsignificant differences in grammatical fluency, politeness, and lexical\ndiversity in user language between the two settings. These findings suggest\nthat models trained exclusively on human-human interaction data may not\nadequately accommodate the communication style shift that occurs once an LLM\nchatbot is deployed. To enhance LLM robustness to post-launch communication\nstyle changes, we experimented with two strategies: (1) data augmentation\nduring the post-training phase and (2) inference-time user message\nreformulation. Our results indicate that models trained on stylistically\ndiverse datasets significantly outperform those trained exclusively on original\nor stylistically uniform datasets, while inference-time reformulation proved\nless effective. These insights help us to better adapt our models for improved\nLLM-user interaction experiences.", "AI": {"tldr": "研究发现用户与LLM聊天机器人和人类代理的沟通方式存在显著差异。为提高LLM的鲁棒性，通过风格多样的数据增强训练模型效果显著，而推理时重构用户消息效果不佳。", "motivation": "随着大型语言模型（LLMs）越来越多地应用于面向客户的场景，一个关键但尚未充分探索的问题是用户与LLM聊天机器人和人类代理的沟通方式有何不同。", "method": "本研究通过实证分析比较了用户在与聊天机器人和人类代理互动时的沟通风格，分析了语法流畅度、礼貌程度和词汇多样性。为增强LLM对发布后沟通风格变化的鲁棒性，作者尝试了两种策略：1) 后训练阶段的数据增强；2) 推理时用户消息重构。", "result": "分析显示，用户与聊天机器人和人类代理沟通时采用不同的沟通风格，在语法流畅度、礼貌程度和词汇多样性上存在显著差异。结果表明，使用风格多样数据集训练的模型显著优于仅使用原始或风格统一数据集训练的模型，而推理时重构用户消息的效果较差。", "conclusion": "这些发现有助于我们更好地调整模型，以改善LLM与用户的交互体验，尤其需要考虑用户与LLM互动时沟通风格的变化，并通过风格多样的数据增强来提高模型的鲁棒性。"}}
{"id": "2510.03122", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03122", "abs": "https://arxiv.org/abs/2510.03122", "authors": ["Shiyi Zhang", "Dong Liang", "Hairong Zheng", "Yihang Zhou"], "title": "HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided Versatile Diffusion", "comment": null, "summary": "The reconstruction of visual information from brain activity fosters\ninterdisciplinary integration between neuroscience and computer vision.\nHowever, existing methods still face challenges in accurately recovering highly\ncomplex visual stimuli. This difficulty stems from the characteristics of\nnatural scenes: low-level features exhibit heterogeneity, while high-level\nfeatures show semantic entanglement due to contextual overlaps. Inspired by the\nhierarchical representation theory of the visual cortex, we propose the HAVIR\nmodel, which separates the visual cortex into two hierarchical regions and\nextracts distinct features from each. Specifically, the Structural Generator\nextracts structural information from spatial processing voxels and converts it\ninto latent diffusion priors, while the Semantic Extractor converts semantic\nprocessing voxels into CLIP embeddings. These components are integrated via the\nVersatile Diffusion model to synthesize the final image. Experimental results\ndemonstrate that HAVIR enhances both the structural and semantic quality of\nreconstructions, even in complex scenes, and outperforms existing models.", "AI": {"tldr": "该论文提出了HAVIR模型，通过模拟视觉皮层的分层表示，从大脑活动中重建复杂的视觉信息，显著提升了重建图像的结构和语义质量。", "motivation": "现有方法在准确恢复高度复杂的视觉刺激方面仍面临挑战，原因在于自然场景中低级特征的异质性以及高级特征因上下文重叠导致的语义纠缠。", "method": "受视觉皮层分层表示理论的启发，作者提出了HAVIR模型。该模型将视觉皮层分为两个分层区域，并从每个区域提取不同特征：结构生成器从空间处理体素中提取结构信息并转换为潜在扩散先验；语义提取器将语义处理体素转换为CLIP嵌入。这些组件通过多功能扩散模型（Versatile Diffusion）进行整合以合成最终图像。", "result": "实验结果表明，HAVIR模型即使在复杂场景下也能增强重建图像的结构和语义质量，并且优于现有模型。", "conclusion": "HAVIR模型通过分层处理大脑活动中的视觉信息，有效解决了复杂视觉刺激的重建难题，提升了重建图像的质量。"}}
{"id": "2510.03110", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03110", "abs": "https://arxiv.org/abs/2510.03110", "authors": ["Beibei Lin", "Tingting Chen", "Robby T. Tan"], "title": "GeoComplete: Geometry-Aware Diffusion for Reference-Driven Image Completion", "comment": "Accepted by NeurIPS 2025. Project page:\n  https://bb12346.github.io/GeoComplete/", "summary": "Reference-driven image completion, which restores missing regions in a target\nview using additional images, is particularly challenging when the target view\ndiffers significantly from the references. Existing generative methods rely\nsolely on diffusion priors and, without geometric cues such as camera pose or\ndepth, often produce misaligned or implausible content. We propose GeoComplete,\na novel framework that incorporates explicit 3D structural guidance to enforce\ngeometric consistency in the completed regions, setting it apart from prior\nimage-only approaches. GeoComplete introduces two key ideas: conditioning the\ndiffusion process on projected point clouds to infuse geometric information,\nand applying target-aware masking to guide the model toward relevant reference\ncues. The framework features a dual-branch diffusion architecture. One branch\nsynthesizes the missing regions from the masked target, while the other\nextracts geometric features from the projected point cloud. Joint\nself-attention across branches ensures coherent and accurate completion. To\naddress regions visible in references but absent in the target, we project the\ntarget view into each reference to detect occluded areas, which are then masked\nduring training. This target-aware masking directs the model to focus on useful\ncues, enhancing performance in difficult scenarios. By integrating a\ngeometry-aware dual-branch diffusion architecture with a target-aware masking\nstrategy, GeoComplete offers a unified and robust solution for\ngeometry-conditioned image completion. Experiments show that GeoComplete\nachieves a 17.1 PSNR improvement over state-of-the-art methods, significantly\nboosting geometric accuracy while maintaining high visual quality.", "AI": {"tldr": "GeoComplete是一个新的图像补全框架，通过结合3D结构引导（投影点云）和目标感知掩码策略的双分支扩散架构，解决了参考驱动图像补全中由于视图差异导致的几何不一致问题，显著提升了几何准确性和视觉质量。", "motivation": "现有参考驱动图像补全方法在目标视图与参考视图差异较大时，仅依赖扩散先验且缺乏几何线索，常导致生成内容错位或不合理。", "method": "GeoComplete框架引入了显式3D结构引导和目标感知掩码。它采用双分支扩散架构：一个分支从掩码目标合成缺失区域，另一个分支从投影点云提取几何特征，并通过联合自注意力确保一致性。目标感知掩码通过将目标视图投影到参考视图中检测遮挡区域并在训练时进行掩码，以引导模型关注有用线索。", "result": "GeoComplete在PSNR上比现有最先进方法提高了17.1，显著提升了几何准确性，同时保持了高视觉质量。", "conclusion": "GeoComplete通过集成几何感知双分支扩散架构与目标感知掩码策略，为几何条件图像补全提供了一个统一且鲁棒的解决方案。"}}
{"id": "2510.02648", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02648", "abs": "https://arxiv.org/abs/2510.02648", "authors": ["Rui Qi", "Zhibo Man", "Yufeng Chen", "Fengran Mo", "Jinan Xu", "Kaiyu Huang"], "title": "SoT: Structured-of-Thought Prompting Guides Multilingual Reasoning in Large Language Models", "comment": "EMNLP 2025 (findings)", "summary": "Recent developments have enabled Large Language Models (LLMs) to engage in\ncomplex reasoning tasks through deep thinking. However, the capacity of\nreasoning has not been successfully transferred to non-high-resource languages\ndue to resource constraints, which struggles with multilingual reasoning tasks.\nTo this end, we propose Structured-of-Thought (SoT), a training-free method\nthat improves the performance on multilingual reasoning through a multi-step\ntransformation: Language Thinking Transformation and Structured Knowledge\nTransformation. The SoT method converts language-specific semantic information\ninto language-agnostic structured representations, enabling the models to\nunderstand the query in different languages more sophisticated. Besides, SoT\neffectively guides LLMs toward more concentrated reasoning to maintain\nconsistent underlying reasoning pathways when handling cross-lingual variations\nin expression. Experimental results demonstrate that SoT outperforms several\nstrong baselines on multiple multilingual reasoning benchmarks when adapting to\nvarious backbones of LLMs. It can also be integrated with other training-free\nstrategies for further improvements. Our code is available at\nhttps://github.com/Cherry-qwq/SoT.", "AI": {"tldr": "本文提出了一种名为Structured-of-Thought (SoT) 的免训练方法，通过多步骤转换将语言特定信息转化为语言无关的结构化表示，显著提升了大型语言模型（LLMs）在多语言推理任务上的表现。", "motivation": "尽管大型语言模型在深度思考方面表现出色，但由于资源限制，其推理能力未能成功转移到非高资源语言，导致在多语言推理任务中表现不佳。", "method": "SoT方法是一种免训练策略，通过“语言思维转换”和“结构化知识转换”两步实现。它将语言特定的语义信息转换为语言无关的结构化表示，使模型能更精细地理解不同语言的查询，并引导LLMs进行更集中的推理，以在处理跨语言表达差异时保持一致的底层推理路径。", "result": "实验结果表明，SoT在多个多语言推理基准测试中优于多个强基线模型，并且能适应不同的LLM骨干网络。此外，SoT还可以与其他免训练策略结合以进一步提升性能。", "conclusion": "SoT通过将语言特定信息转换为结构化、语言无关的表示，并引导LLMs进行集中推理，有效解决了多语言推理中的挑战，显著提升了LLMs在跨语言任务上的推理能力，且无需额外训练。"}}
{"id": "2510.03160", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03160", "abs": "https://arxiv.org/abs/2510.03160", "authors": ["Ming Zhao", "Wenhui Dong", "Yang Zhang", "Xiang Zheng", "Zhonghao Zhang", "Zian Zhou", "Yunzhi Guan", "Liukun Xu", "Wei Peng", "Zhaoyang Gong", "Zhicheng Zhang", "Dachuan Li", "Xiaosheng Ma", "Yuli Ma", "Jianing Ni", "Changjiang Jiang", "Lixia Tian", "Qixin Chen", "Kaishun Xia", "Pingping Liu", "Tongshun Zhang", "Zhiqiang Liu", "Zhongan Bi", "Chenyang Si", "Tiansheng Sun", "Caifeng Shan"], "title": "SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus", "comment": null, "summary": "Spine disorders affect 619 million people globally and are a leading cause of\ndisability, yet AI-assisted diagnosis remains limited by the lack of\nlevel-aware, multimodal datasets. Clinical decision-making for spine disorders\nrequires sophisticated reasoning across X-ray, CT, and MRI at specific\nvertebral levels. However, progress has been constrained by the absence of\ntraceable, clinically-grounded instruction data and standardized,\nspine-specific benchmarks. To address this, we introduce SpineMed, an ecosystem\nco-designed with practicing spine surgeons. It features SpineMed-450k, the\nfirst large-scale dataset explicitly designed for vertebral-level reasoning\nacross imaging modalities with over 450,000 instruction instances, and\nSpineBench, a clinically-grounded evaluation framework. SpineMed-450k is\ncurated from diverse sources, including textbooks, guidelines, open datasets,\nand ~1,000 de-identified hospital cases, using a clinician-in-the-loop pipeline\nwith a two-stage LLM generation method (draft and revision) to ensure\nhigh-quality, traceable data for question-answering, multi-turn consultations,\nand report generation. SpineBench evaluates models on clinically salient axes,\nincluding level identification, pathology assessment, and surgical planning.\nOur comprehensive evaluation of several recently advanced large vision-language\nmodels (LVLMs) on SpineBench reveals systematic weaknesses in fine-grained,\nlevel-specific reasoning. In contrast, our model fine-tuned on SpineMed-450k\ndemonstrates consistent and significant improvements across all tasks.\nClinician assessments confirm the diagnostic clarity and practical utility of\nour model's outputs.", "AI": {"tldr": "该研究引入了SpineMed生态系统，包括首个用于椎体级别多模态推理的大规模数据集SpineMed-450k和临床评估框架SpineBench，显著提升了大型视觉语言模型在脊柱疾病诊断方面的性能。", "motivation": "脊柱疾病影响全球数亿人，是导致残疾的主要原因。然而，AI辅助诊断受限于缺乏级别感知、多模态数据集和可追溯、临床基础的指令数据及标准化脊柱专用基准，这阻碍了AI在需要跨X射线、CT和MRI进行复杂推理的临床决策中的应用。", "method": "研究引入了与脊柱外科医生共同设计的SpineMed生态系统。它包含SpineMed-450k数据集（首个专为椎体级别多模态影像推理设计的大规模数据集，拥有超过45万条指令实例）和SpineBench（一个具有临床基础的评估框架）。SpineMed-450k通过“临床医生在环”流程和两阶段LLM生成方法（草稿和修订）从教科书、指南、开放数据集和约1000例去标识化医院病例中整理，以确保问答、多轮会诊和报告生成数据的高质量和可追溯性。SpineBench根据级别识别、病理评估和手术规划等临床显著轴线评估模型。", "result": "对几种先进的大型视觉语言模型（LVLMs）在SpineBench上的综合评估显示，它们在细粒度、级别特定的推理方面存在系统性弱点。相比之下，研究团队在SpineMed-450k上微调的模型在所有任务上都表现出持续且显著的改进。临床医生评估证实了该模型输出的诊断清晰度和实用性。", "conclusion": "SpineMed生态系统通过提供大规模、级别感知、多模态数据集和临床评估框架，有效解决了脊柱疾病AI诊断面临的数据和基准限制。这使得AI模型在脊柱疾病诊断中展现出显著的性能提升和临床实用性，为AI辅助脊柱疾病临床决策开辟了新途径。"}}
{"id": "2510.03117", "categories": ["cs.CV", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.03117", "abs": "https://arxiv.org/abs/2510.03117", "authors": ["Kaisi Guan", "Xihua Wang", "Zhengfeng Lai", "Xin Cheng", "Peng Zhang", "XiaoJiang Liu", "Ruihua Song", "Meng Cao"], "title": "Taming Text-to-Sounding Video Generation via Advanced Modality Condition and Interaction", "comment": null, "summary": "This study focuses on a challenging yet promising task,\nText-to-Sounding-Video (T2SV) generation, which aims to generate a video with\nsynchronized audio from text conditions, meanwhile ensuring both modalities are\naligned with text. Despite progress in joint audio-video training, two critical\nchallenges still remain unaddressed: (1) a single, shared text caption where\nthe text for video is equal to the text for audio often creates modal\ninterference, confusing the pretrained backbones, and (2) the optimal mechanism\nfor cross-modal feature interaction remains unclear. To address these\nchallenges, we first propose the Hierarchical Visual-Grounded Captioning (HVGC)\nframework that generates pairs of disentangled captions, a video caption, and\nan audio caption, eliminating interference at the conditioning stage. Based on\nHVGC, we further introduce BridgeDiT, a novel dual-tower diffusion transformer,\nwhich employs a Dual CrossAttention (DCA) mechanism that acts as a robust\n``bridge\" to enable a symmetric, bidirectional exchange of information,\nachieving both semantic and temporal synchronization. Extensive experiments on\nthree benchmark datasets, supported by human evaluations, demonstrate that our\nmethod achieves state-of-the-art results on most metrics. Comprehensive\nablation studies further validate the effectiveness of our contributions,\noffering key insights for the future T2SV task. All the codes and checkpoints\nwill be publicly released.", "AI": {"tldr": "本研究提出了一种新颖的文本到有声视频（T2SV）生成方法，通过分层视觉接地字幕（HVGC）生成解耦的视频和音频字幕，并引入了BridgeDiT双塔扩散变换器，利用双重交叉注意力（DCA）实现模态间的语义和时间同步，从而解决了模态干扰和跨模态交互不清的问题，取得了最先进的性能。", "motivation": "文本到有声视频（T2SV）生成任务面临两个关键挑战：1) 单一共享的文本字幕（视频和音频文本相同）会造成模态干扰，混淆预训练骨干网络；2) 最佳的跨模态特征交互机制尚不明确。", "method": "为解决上述挑战，本研究首先提出了分层视觉接地字幕（HVGC）框架，生成一对解耦的字幕（视频字幕和音频字幕），从而在条件设置阶段消除干扰。在此基础上，进一步引入了BridgeDiT，这是一种新颖的双塔扩散变换器，其采用了双重交叉注意力（DCA）机制，作为一个鲁棒的“桥梁”，实现了对称、双向的信息交换，从而达到了语义和时间上的同步。", "result": "在三个基准数据集上进行了广泛的实验，并辅以人工评估，结果表明所提出的方法在大多数指标上均达到了最先进的水平。全面的消融研究进一步验证了各项贡献的有效性。", "conclusion": "本研究提出了一种有效的方法来解决文本到有声视频（T2SV）生成中的模态干扰和跨模态交互问题，通过解耦的字幕和创新的双塔扩散模型实现了卓越的性能，为未来的T2SV任务提供了关键见解。"}}
{"id": "2510.02665", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02665", "abs": "https://arxiv.org/abs/2510.02665", "authors": ["Shijian Deng", "Kai Wang", "Tianyu Yang", "Harsh Singh", "Yapeng Tian"], "title": "Self-Improvement in Multimodal Large Language Models: A Survey", "comment": "EMNLP 2025", "summary": "Recent advancements in self-improvement for Large Language Models (LLMs) have\nefficiently enhanced model capabilities without significantly increasing costs,\nparticularly in terms of human effort. While this area is still relatively\nyoung, its extension to the multimodal domain holds immense potential for\nleveraging diverse data sources and developing more general self-improving\nmodels. This survey is the first to provide a comprehensive overview of\nself-improvement in Multimodal LLMs (MLLMs). We provide a structured overview\nof the current literature and discuss methods from three perspectives: 1) data\ncollection, 2) data organization, and 3) model optimization, to facilitate the\nfurther development of self-improvement in MLLMs. We also include commonly used\nevaluations and downstream applications. Finally, we conclude by outlining open\nchallenges and future research directions.", "AI": {"tldr": "这篇综述首次全面概述了多模态大型语言模型（MLLMs）的自我改进，系统地分析了数据收集、数据组织和模型优化方法，并探讨了开放挑战和未来方向。", "motivation": "大型语言模型（LLMs）的自我改进已有效提升其能力且成本较低。将这一技术扩展到多模态领域具有巨大潜力，可以利用多样化数据源并开发更通用的自我改进模型。由于此领域尚处于早期，需要一个全面的概述。", "method": "本研究通过提供结构化的文献综述来分析MLLMs的自我改进，从三个关键视角讨论了相关方法：1）数据收集，2）数据组织，和3）模型优化。此外，还涵盖了常用的评估方法和下游应用。", "result": "本综述首次为多模态大型语言模型（MLLMs）的自我改进提供了一个全面的结构化概述，系统地分类和讨论了数据收集、数据组织和模型优化等方面的现有方法，并包含了评估和应用案例，为该领域的进一步发展提供了基础。", "conclusion": "MLLMs的自我改进领域仍面临开放挑战，本综述最后提出了未来的研究方向，以促进该领域的进一步发展。"}}
{"id": "2510.03161", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03161", "abs": "https://arxiv.org/abs/2510.03161", "authors": ["Qing Huang", "Zhipei Xu", "Xuanyu Zhang", "Jian Zhang"], "title": "UniShield: An Adaptive Multi-Agent Framework for Unified Forgery Image Detection and Localization", "comment": null, "summary": "With the rapid advancements in image generation, synthetic images have become\nincreasingly realistic, posing significant societal risks, such as\nmisinformation and fraud. Forgery Image Detection and Localization (FIDL) thus\nemerges as essential for maintaining information integrity and societal\nsecurity. Despite impressive performances by existing domain-specific detection\nmethods, their practical applicability remains limited, primarily due to their\nnarrow specialization, poor cross-domain generalization, and the absence of an\nintegrated adaptive framework. To address these issues, we propose UniShield,\nthe novel multi-agent-based unified system capable of detecting and localizing\nimage forgeries across diverse domains, including image manipulation, document\nmanipulation, DeepFake, and AI-generated images. UniShield innovatively\nintegrates a perception agent with a detection agent. The perception agent\nintelligently analyzes image features to dynamically select suitable detection\nmodels, while the detection agent consolidates various expert detectors into a\nunified framework and generates interpretable reports. Extensive experiments\nshow that UniShield achieves state-of-the-art results, surpassing both existing\nunified approaches and domain-specific detectors, highlighting its superior\npracticality, adaptiveness, and scalability.", "AI": {"tldr": "UniShield是一个新型多智能体统一系统，能跨领域检测和定位图像伪造，通过感知智能体动态选择模型，并整合检测智能体生成报告，性能超越现有方法，具有卓越的实用性、适应性和可扩展性。", "motivation": "随着图像生成技术的发展，合成图像日益逼真，带来了虚假信息和欺诈等严重的社会风险。现有的伪造图像检测和定位（FIDL）方法虽然在特定领域表现出色，但其专业化程度高、跨领域泛化能力差以及缺乏集成的自适应框架，限制了其实际应用。", "method": "本文提出了UniShield，一个新颖的基于多智能体的统一系统，旨在跨图像处理、文档处理、DeepFake和AI生成图像等不同领域检测和定位图像伪造。UniShield创新性地集成了感知智能体和检测智能体：感知智能体智能分析图像特征以动态选择合适的检测模型；检测智能体将各种专家检测器整合到一个统一框架中并生成可解释的报告。", "result": "广泛的实验表明，UniShield取得了最先进的结果，超越了现有的统一方法和特定领域检测器。这突显了其卓越的实用性、适应性和可扩展性。", "conclusion": "UniShield成功解决了现有伪造图像检测方法在跨领域泛化和集成适应性方面的局限性，提供了一个高效、实用且可扩展的解决方案，对于维护信息完整性和社会安全至关重要。"}}
{"id": "2510.03152", "categories": ["cs.CV", "cs.CE", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.03152", "abs": "https://arxiv.org/abs/2510.03152", "authors": ["Anantajit Subrahmanya", "Chandrakanth Gudavalli", "Connor Levenson", "Umang Garg", "B. S. Manjunath"], "title": "ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal Trajectories", "comment": "15 pages, 3 figures, 2 algorithms, 1 table", "summary": "Accurately modeling human mobility is critical for urban planning,\nepidemiology, and traffic management. In this work, we introduce Markovian Reeb\nGraphs, a novel framework for simulating spatiotemporal trajectories that\npreserve Patterns of Life (PoLs) learned from baseline data. By combining\nindividual- and population-level mobility structures within a probabilistic\ntopological model, our approach generates realistic future trajectories that\ncapture both consistency and variability in daily life. Evaluations on the\nUrban Anomalies dataset (Atlanta and Berlin subsets) using the Jensen-Shannon\nDivergence (JSD) across population- and agent-level metrics demonstrate that\nthe proposed method achieves strong fidelity while remaining data- and\ncompute-efficient. These results position Markovian Reeb Graphs as a scalable\nframework for trajectory simulation with broad applicability across diverse\nurban environments.", "AI": {"tldr": "该论文引入了一种名为马尔可夫Reeb图的新框架，用于模拟时空轨迹，该框架能保留从基线数据中学习到的生活模式（PoLs），并结合个体和群体层面的移动结构，生成逼真且高效的未来轨迹。", "motivation": "准确建模人类移动对于城市规划、流行病学和交通管理至关重要。", "method": "该研究提出了马尔可夫Reeb图（Markovian Reeb Graphs），这是一个概率拓扑模型，通过结合个体和群体层面的移动结构来模拟时空轨迹，以保留从基线数据中学习到的生活模式（PoLs）。", "result": "该方法生成了能捕捉日常生活一致性和变异性的逼真未来轨迹。在Urban Anomalies数据集（亚特兰大和柏林子集）上，通过使用Jensen-Shannon散度（JSD）对群体和个体层面的指标进行评估，结果表明该方法实现了高保真度，同时保持了数据和计算效率。", "conclusion": "马尔可夫Reeb图是一个可扩展的轨迹模拟框架，在多样化的城市环境中具有广泛的适用性。"}}
{"id": "2510.02671", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02671", "abs": "https://arxiv.org/abs/2510.02671", "authors": ["Yavuz Bakman", "Sungmin Kang", "Zhiqi Huang", "Duygu Nur Yaldiz", "Catarina G. Belém", "Chenyang Zhu", "Anoop Kumar", "Alfy Samuel", "Salman Avestimehr", "Daben Liu", "Sai Praneeth Karimireddy"], "title": "Uncertainty as Feature Gaps: Epistemic Uncertainty Quantification of LLMs in Contextual Question-Answering", "comment": null, "summary": "Uncertainty Quantification (UQ) research has primarily focused on closed-book\nfactual question answering (QA), while contextual QA remains unexplored,\ndespite its importance in real-world applications. In this work, we focus on UQ\nfor the contextual QA task and propose a theoretically grounded approach to\nquantify epistemic uncertainty. We begin by introducing a task-agnostic,\ntoken-level uncertainty measure defined as the cross-entropy between the\npredictive distribution of the given model and the unknown true distribution.\nBy decomposing this measure, we isolate the epistemic component and approximate\nthe true distribution by a perfectly prompted, idealized model. We then derive\nan upper bound for epistemic uncertainty and show that it can be interpreted as\nsemantic feature gaps in the given model's hidden representations relative to\nthe ideal model. We further apply this generic framework to the contextual QA\ntask and hypothesize that three features approximate this gap: context-reliance\n(using the provided context rather than parametric knowledge), context\ncomprehension (extracting relevant information from context), and honesty\n(avoiding intentional lies). Using a top-down interpretability approach, we\nextract these features by using only a small number of labeled samples and\nensemble them to form a robust uncertainty score. Experiments on multiple QA\nbenchmarks in both in-distribution and out-of-distribution settings show that\nour method substantially outperforms state-of-the-art unsupervised\n(sampling-free and sampling-based) and supervised UQ methods, achieving up to a\n13-point PRR improvement while incurring a negligible inference overhead.", "AI": {"tldr": "本文提出了一种理论基础的、针对上下文问答任务的认知不确定性量化方法，通过分解跨熵不确定性并识别语义特征差距，显著优于现有SOTA方法。", "motivation": "不确定性量化（UQ）研究主要集中在封闭域事实问答（QA），而上下文QA在实际应用中至关重要但尚未被充分探索。", "method": "引入了任务无关的、基于令牌的交叉熵不确定性度量，并将其分解以分离认知不确定性。通过理想模型近似真实分布，推导出认知不确定性的上限，并将其解释为模型隐藏表示中的语义特征差距。针对上下文QA，提出了上下文依赖、上下文理解和诚实性三个特征来近似此差距。通过自上而下的可解释性方法，利用少量标记样本提取这些特征并进行集成，形成稳健的不确定性得分。", "result": "在多种QA基准测试（包括分布内和分布外设置）中，该方法显著优于现有的无监督（无采样和基于采样）和有监督UQ方法，PRR（Precision-Recall Rate）提升高达13个百分点，且推理开销可忽略不计。", "conclusion": "本文提出了一种新颖、有效且高效的上下文问答不确定性量化方法，填补了现有UQ研究的空白，并在性能上取得了显著提升。"}}
{"id": "2510.03174", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03174", "abs": "https://arxiv.org/abs/2510.03174", "authors": ["Xuan Xu", "Haolun Li", "Zhongliang Yang", "Beilin Chu", "Jia Song", "Moxuan Xu", "Linna Zhou"], "title": "Topic Modeling as Long-Form Generation: Can Long-Context LLMs revolutionize NTM via Zero-Shot Prompting?", "comment": null, "summary": "Traditional topic models such as neural topic models rely on inference and\ngeneration networks to learn latent topic distributions. This paper explores a\nnew paradigm for topic modeling in the era of large language models, framing TM\nas a long-form generation task whose definition is updated in this paradigm. We\npropose a simple but practical approach to implement LLM-based topic model\ntasks out of the box (sample a data subset, generate topics and representative\ntext with our prompt, text assignment with keyword match). We then investigate\nwhether the long-form generation paradigm can beat NTMs via zero-shot\nprompting. We conduct a systematic comparison between NTMs and LLMs in terms of\ntopic quality and empirically examine the claim that \"a majority of NTMs are\noutdated.\"", "AI": {"tldr": "本文提出了一种将主题建模视为长篇生成任务的新范式，利用大型语言模型（LLMs）进行开箱即用的主题建模，并系统地比较了LLMs与传统神经主题模型（NTMs）的主题质量。", "motivation": "在大型语言模型时代，探索主题建模的新范范式，并质疑传统神经主题模型（NTMs）是否已过时，以及LLMs能否在零样本提示下超越NTMs。", "method": "提出了一种基于LLM的简单实用方法：抽样数据子集，通过提示生成主题和代表性文本，并利用关键词匹配进行文本分配。通过零样本提示，系统地比较了LLMs和NTMs在主题质量方面的表现。", "result": "研究了长篇生成范式是否能超越NTMs，并实证检验了“大多数NTMs已过时”的说法。具体结果（如LLM是否真的超越NTM）在摘要中未明确给出，但表明进行了相关调查和比较。", "conclusion": "旨在通过系统比较，评估LLM作为主题建模工具的潜力，并为LLM时代的主题建模提供新的见解，同时检验传统NTMs的有效性。"}}
{"id": "2510.03163", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.03163", "abs": "https://arxiv.org/abs/2510.03163", "authors": ["Jiapeng Tang", "Matthew Lavine", "Dor Verbin", "Stephan J. Garbin", "Matthias Nießner", "Ricardo Martin Brualla", "Pratul P. Srinivasan", "Philipp Henzler"], "title": "ROGR: Relightable 3D Objects using Generative Relighting", "comment": "NeurIPS 2025 Spotlight. Project page:\n  https://tangjiapeng.github.io/ROGR", "summary": "We introduce ROGR, a novel approach that reconstructs a relightable 3D model\nof an object captured from multiple views, driven by a generative relighting\nmodel that simulates the effects of placing the object under novel environment\nilluminations. Our method samples the appearance of the object under multiple\nlighting environments, creating a dataset that is used to train a\nlighting-conditioned Neural Radiance Field (NeRF) that outputs the object's\nappearance under any input environmental lighting. The lighting-conditioned\nNeRF uses a novel dual-branch architecture to encode the general lighting\neffects and specularities separately. The optimized lighting-conditioned NeRF\nenables efficient feed-forward relighting under arbitrary environment maps\nwithout requiring per-illumination optimization or light transport simulation.\nWe evaluate our approach on the established TensoIR and Stanford-ORB datasets,\nwhere it improves upon the state-of-the-art on most metrics, and showcase our\napproach on real-world object captures.", "AI": {"tldr": "ROGR是一种新颖的方法，通过生成式重照明模型和双分支光照条件NeRF，从多视角捕获中重建可重照明3D物体模型，实现任意环境光照下的高效前向重照明。", "motivation": "研究动机是需要一种能够从多视角捕获中重建可重照明3D物体模型的方法，该模型能在新的环境光照下高效地模拟物体外观。", "method": "该方法通过在多种光照环境下采样物体外观来创建数据集，并使用该数据集训练一个光照条件下的神经辐射场（NeRF）。该NeRF采用新颖的双分支架构，分别编码一般光照效果和镜面反射。这种优化后的光照条件NeRF无需每次光照优化或光传输模拟，即可在任意环境贴图下实现高效的前向重照明。", "result": "该方法在TensoIR和Stanford-ORB数据集上，在大多数指标上超越了现有技术水平，并成功展示了在真实世界物体捕获上的应用。", "conclusion": "ROGR提供了一种有效的方法，可以重建可重照明的3D模型，并在任意环境光照下实现高效且高质量的重照明，无需复杂的优化或模拟。"}}
{"id": "2510.02726", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02726", "abs": "https://arxiv.org/abs/2510.02726", "authors": ["KM Pooja", "Cheng Long", "Aixin Sun"], "title": "PGMEL: Policy Gradient-based Generative Adversarial Network for Multimodal Entity Linking", "comment": null, "summary": "The task of entity linking, which involves associating mentions with their\nrespective entities in a knowledge graph, has received significant attention\ndue to its numerous potential applications. Recently, various multimodal entity\nlinking (MEL) techniques have been proposed, targeted to learn comprehensive\nembeddings by leveraging both text and vision modalities. The selection of\nhigh-quality negative samples can potentially play a crucial role in\nmetric/representation learning. However, to the best of our knowledge, this\npossibility remains unexplored in existing literature within the framework of\nMEL. To fill this gap, we address the multimodal entity linking problem in a\ngenerative adversarial setting where the generator is responsible for\ngenerating high-quality negative samples, and the discriminator is assigned the\nresponsibility for the metric learning tasks. Since the generator is involved\nin generating samples, which is a discrete process, we optimize it using policy\ngradient techniques and propose a policy gradient-based generative adversarial\nnetwork for multimodal entity linking (PGMEL). Experimental results based on\nWiki-MEL, Richpedia-MEL and WikiDiverse datasets demonstrate that PGMEL learns\nmeaningful representation by selecting challenging negative samples and\noutperforms state-of-the-art methods.", "AI": {"tldr": "本文提出了一种基于策略梯度生成对抗网络（PGMEL）的多模态实体链接方法，通过生成高质量的负样本来学习有意义的表示，并优于现有技术。", "motivation": "多模态实体链接（MEL）中，高质量负样本的选择对度量/表示学习至关重要，但现有文献中尚未对此进行探索。", "method": "本文将多模态实体链接问题置于生成对抗设置中：生成器负责生成高质量负样本（离散过程，使用策略梯度优化），判别器负责度量学习任务。提出了基于策略梯度的多模态实体链接生成对抗网络（PGMEL）。", "result": "在Wiki-MEL、Richpedia-MEL和WikiDiverse数据集上的实验结果表明，PGMEL通过选择具有挑战性的负样本学习到有意义的表示，并优于现有最先进的方法。", "conclusion": "PGMEL通过结合策略梯度和生成对抗网络，有效地解决了多模态实体链接中的负样本选择问题，从而提高了模型性能和表示学习质量。"}}
{"id": "2510.03223", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03223", "abs": "https://arxiv.org/abs/2510.03223", "authors": ["Hongxiang Zhang", "Yuan Tian", "Tianyi Zhang"], "title": "Self-Anchor: Large Language Model Reasoning via Step-by-step Attention Alignment", "comment": null, "summary": "To solve complex reasoning tasks for Large Language Models (LLMs),\nprompting-based methods offer a lightweight alternative to fine-tuning and\nreinforcement learning. However, as reasoning chains extend, critical\nintermediate steps and the original prompt will be buried in the context,\nreceiving insufficient attention and leading to errors. In this paper, we\npropose Self-Anchor, a novel pipeline that leverages the inherent structure of\nreasoning to steer LLM attention. Self-Anchor decomposes reasoning trajectories\ninto structured plans and automatically aligns the model's attention to the\nmost relevant inference steps, allowing the model to maintain focus throughout\ngeneration. Our experiment shows that Self-Anchor outperforms SOTA prompting\nmethods across six benchmarks. Notably, Self-Anchor significantly reduces the\nperformance gap between ``non-reasoning'' models and specialized reasoning\nmodels, with the potential to enable most LLMs to tackle complex reasoning\ntasks without retraining.", "AI": {"tldr": "本文提出了Self-Anchor方法，通过分解推理轨迹为结构化计划并自动调整LLM的注意力，解决了长推理链中关键信息被淹没的问题，显著提升了LLM在复杂推理任务上的表现。", "motivation": "当大型语言模型（LLMs）处理复杂的推理任务时，基于提示的方法虽然轻量，但随着推理链的延长，关键的中间步骤和原始提示容易在上下文中被“淹没”，导致模型注意力不足并产生错误。", "method": "本文提出了Self-Anchor，一种利用推理的内在结构来引导LLM注意力的新型管道。该方法将推理轨迹分解为结构化计划，并自动将模型的注意力与最相关的推理步骤对齐，从而使模型在整个生成过程中保持专注。", "result": "实验表明，Self-Anchor在六个基准测试中优于现有的最先进提示方法。值得注意的是，Self-Anchor显著缩小了“非推理”模型与专门推理模型之间的性能差距。", "conclusion": "Self-Anchor有潜力使大多数LLM无需重新训练即可处理复杂的推理任务，为解决LLM在长推理链中的注意力分散问题提供了一种有效且轻量级的解决方案。"}}
{"id": "2510.03189", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03189", "abs": "https://arxiv.org/abs/2510.03189", "authors": ["Tidiane Camaret Ndir", "Alexander Pfefferle", "Robin Tibor Schirrmeister"], "title": "Dynamic Prompt Generation for Interactive 3D Medical Image Segmentation Training", "comment": null, "summary": "Interactive 3D biomedical image segmentation requires efficient models that\ncan iteratively refine predictions based on user prompts. Current foundation\nmodels either lack volumetric awareness or suffer from limited interactive\ncapabilities. We propose a training strategy that combines dynamic volumetric\nprompt generation with content-aware adaptive cropping to optimize the use of\nthe image encoder. Our method simulates realistic user interaction patterns\nduring training while addressing the computational challenges of learning from\nsequential refinement feedback on a single GPU. For efficient training, we\ninitialize our network using the publicly available weights from the\nnnInteractive segmentation model. Evaluation on the \\textbf{Foundation Models\nfor Interactive 3D Biomedical Image Segmentation} competition demonstrates\nstrong performance with an average final Dice score of 0.6385, normalized\nsurface distance of 0.6614, and area-under-the-curve metrics of 2.4799 (Dice)\nand 2.5671 (NSD).", "AI": {"tldr": "本文提出了一种新的训练策略，结合动态体素提示生成和内容感知自适应裁剪，以优化交互式3D生物医学图像分割模型的图像编码器，并在竞争中取得了优异的性能。", "motivation": "当前的通用模型在交互式3D生物医学图像分割方面存在体积感知不足或交互能力有限的问题，无法有效支持用户基于迭代反馈的预测细化。", "method": "研究提出了一种训练策略，该策略结合了动态体素提示生成和内容感知自适应裁剪，以优化图像编码器的使用。它在训练过程中模拟真实的用户交互模式，并解决了在单个GPU上从顺序细化反馈中学习的计算挑战。网络使用nnInteractive分割模型的公开权重进行初始化。", "result": "在“交互式3D生物医学图像分割基础模型”竞赛中，该方法表现出色，平均最终Dice得分为0.6385，归一化表面距离为0.6614，曲线下面积（Dice）为2.4799，曲线下面积（NSD）为2.5671。", "conclusion": "所提出的训练策略能够有效解决现有模型在交互式3D生物医学图像分割中的局限性，并实现了强大的性能，为该领域提供了一个高效的模型训练方法。"}}
{"id": "2510.02742", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02742", "abs": "https://arxiv.org/abs/2510.02742", "authors": ["Santhosh G S", "Akshay Govind S", "Gokul S Krishnan", "Balaraman Ravindran", "Sriraam Natarajan"], "title": "IndiCASA: A Dataset and Bias Evaluation Framework in LLMs Using Contrastive Embedding Similarity in the Indian Context", "comment": "Accepted at 8th AAAI/ACM Conference on AI, Ethics, and Society (AIES)\n  2025", "summary": "Large Language Models (LLMs) have gained significant traction across critical\ndomains owing to their impressive contextual understanding and generative\ncapabilities. However, their increasing deployment in high stakes applications\nnecessitates rigorous evaluation of embedded biases, particularly in culturally\ndiverse contexts like India where existing embedding-based bias assessment\nmethods often fall short in capturing nuanced stereotypes. We propose an\nevaluation framework based on a encoder trained using contrastive learning that\ncaptures fine-grained bias through embedding similarity. We also introduce a\nnovel dataset - IndiCASA (IndiBias-based Contextually Aligned Stereotypes and\nAnti-stereotypes) comprising 2,575 human-validated sentences spanning five\ndemographic axes: caste, gender, religion, disability, and socioeconomic\nstatus. Our evaluation of multiple open-weight LLMs reveals that all models\nexhibit some degree of stereotypical bias, with disability related biases being\nnotably persistent, and religion bias generally lower likely due to global\ndebiasing efforts demonstrating the need for fairer model development.", "AI": {"tldr": "本文提出一个基于对比学习编码器的评估框架和新的数据集IndiCASA，用于评估大型语言模型（LLMs）在印度文化背景下的细粒度偏见。研究发现所有模型都存在刻板印象偏见，尤其在残疾方面。", "motivation": "LLMs在关键领域广泛部署，但在印度等文化多元背景下，现有基于嵌入的偏见评估方法难以捕捉细微的刻板印象，因此需要对LLMs的偏见进行严格评估。", "method": "1. 提出一个基于对比学习训练的编码器，通过嵌入相似性捕捉细粒度偏见的评估框架。2. 引入新数据集IndiCASA，包含2,575个人工验证的句子，涵盖种姓、性别、宗教、残疾和社会经济地位五个维度。", "result": "对多个开源LLMs的评估显示，所有模型都表现出一定程度的刻板印象偏见。与残疾相关的偏见尤其顽固，而宗教偏见普遍较低，这可能归因于全球去偏见努力。", "conclusion": "研究结果突显了开发更公平模型的必要性，以应对LLMs中存在的、尤其在文化多元背景下的细微偏见。"}}
{"id": "2510.03224", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03224", "abs": "https://arxiv.org/abs/2510.03224", "authors": ["Dong Lao", "Yuxiang Zhang", "Haniyeh Ehsani Oskouie", "Yangchao Wu", "Alex Wong", "Stefano Soatto"], "title": "Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles", "comment": null, "summary": "We propose a test-time defense mechanism against adversarial attacks:\nimperceptible image perturbations that significantly alter the predictions of a\nmodel. Unlike existing methods that rely on feature filtering or smoothing,\nwhich can lead to information loss, we propose to \"combat noise with noise\" by\nleveraging stochastic resonance to enhance robustness while minimizing\ninformation loss. Our approach introduces small translational perturbations to\nthe input image, aligns the transformed feature embeddings, and aggregates them\nbefore mapping back to the original reference image. This can be expressed in a\nclosed-form formula, which can be deployed on diverse existing network\narchitectures without introducing additional network modules or fine-tuning for\nspecific attack types. The resulting method is entirely training-free,\narchitecture-agnostic, and attack-agnostic. Empirical results show\nstate-of-the-art robustness on image classification and, for the first time,\nestablish a generic test-time defense for dense prediction tasks, including\nstereo matching and optical flow, highlighting the method's versatility and\npracticality. Specifically, relative to clean (unperturbed) performance, our\nmethod recovers up to 68.1% of the accuracy loss on image classification, 71.9%\non stereo matching, and 29.2% on optical flow under various types of\nadversarial attacks.", "AI": {"tldr": "本文提出了一种测试时防御对抗性攻击的机制，通过引入微小的平移扰动并利用随机共振来增强模型鲁棒性，同时最大限度地减少信息损失，无需训练、与架构无关且与攻击无关。", "motivation": "现有防御方法（如特征过滤或平滑）会导致信息丢失。本文旨在通过“以噪制噪”的方式，利用随机共振在增强鲁棒性的同时，最大限度地减少信息损失。", "method": "该方法通过对输入图像引入微小的平移扰动，对转换后的特征嵌入进行对齐和聚合，然后映射回原始参考图像。这可以表示为一个闭式公式，无需引入额外的网络模块或针对特定攻击类型进行微调，即可部署在现有网络架构上。该方法完全无需训练，与架构无关，也与攻击无关。", "result": "经验结果表明，该方法在图像分类上实现了最先进的鲁棒性，并且首次为密集预测任务（包括立体匹配和光流）建立了通用的测试时防御。相对于未受扰动的性能，该方法在各种对抗性攻击下，图像分类的准确率损失恢复高达68.1%，立体匹配恢复71.9%，光流恢复29.2%。", "conclusion": "该方法作为一种通用的测试时防御机制，在图像分类和密集预测任务中展现出卓越的鲁棒性、多功能性和实用性，能显著恢复因对抗性攻击造成的性能损失，同时最大限度地减少信息损失。"}}
{"id": "2510.03191", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03191", "abs": "https://arxiv.org/abs/2510.03191", "authors": ["Denis Zavadski", "Nikita Philip Tatsch", "Carsten Rother"], "title": "Product-Quantised Image Representation for High-Quality Image Synthesis", "comment": null, "summary": "Product quantisation (PQ) is a classical method for scalable vector encoding,\nyet it has seen limited usage for latent representations in high-fidelity image\ngeneration. In this work, we introduce PQGAN, a quantised image autoencoder\nthat integrates PQ into the well-known vector quantisation (VQ) framework of\nVQGAN. PQGAN achieves a noticeable improvement over state-of-the-art methods in\nterms of reconstruction performance, including both quantisation methods and\ntheir continuous counterparts. We achieve a PSNR score of 37dB, where prior\nwork achieves 27dB, and are able to reduce the FID, LPIPS, and CMMD score by up\nto 96%. Our key to success is a thorough analysis of the interaction between\ncodebook size, embedding dimensionality, and subspace factorisation, with\nvector and scalar quantisation as special cases. We obtain novel findings, such\nthat the performance of VQ and PQ behaves in opposite ways when scaling the\nembedding dimension. Furthermore, our analysis shows performance trends for PQ\nthat help guide optimal hyperparameter selection. Finally, we demonstrate that\nPQGAN can be seamlessly integrated into pre-trained diffusion models. This\nenables either a significantly faster and more compute-efficient generation, or\na doubling of the output resolution at no additional cost, positioning PQ as a\nstrong extension for discrete latent representation in image synthesis.", "AI": {"tldr": "PQGAN将乘积量化（PQ）集成到VQGAN框架中，显著提升了图像自编码器的重建性能，并能与扩散模型无缝结合，实现更快速、高效或更高分辨率的图像生成。", "motivation": "乘积量化（PQ）作为一种可扩展的向量编码方法，在高保真图像生成中的潜在表示应用有限。本研究旨在将PQ引入现有的向量量化（VQ）框架（如VQGAN），以提升其性能。", "method": "引入了PQGAN，一个将乘积量化（PQ）集成到VQGAN框架中的量化图像自编码器。通过深入分析码本大小、嵌入维度和子空间分解之间的相互作用，探索了向量和标量量化的特殊情况。", "result": "PQGAN在重建性能上显著优于现有最先进方法（包括量化和连续方法），PSNR达到37dB（先前工作为27dB），并将FID、LPIPS和CMMD分数降低了高达96%。研究发现，VQ和PQ的性能在缩放嵌入维度时表现出相反的行为，并揭示了有助于指导最优超参数选择的PQ性能趋势。此外，PQGAN可无缝集成到预训练的扩散模型中，实现显著更快、更计算高效的生成，或在不增加成本的情况下使输出分辨率翻倍。", "conclusion": "乘积量化（PQ）是图像合成中离散潜在表示的一个强大扩展，能够提供显著改进的性能和效率，并为扩散模型带来了新的可能性。"}}
{"id": "2510.02752", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02752", "abs": "https://arxiv.org/abs/2510.02752", "authors": ["Hangfan Zhang", "Siyuan Xu", "Zhimeng Guo", "Huaisheng Zhu", "Shicheng Liu", "Xinrun Wang", "Qiaosheng Zhang", "Yang Chen", "Peng Ye", "Lei Bai", "Shuyue Hu"], "title": "The Path of Self-Evolving Large Language Models: Achieving Data-Efficient Learning via Intrinsic Feedback", "comment": null, "summary": "Reinforcement learning (RL) has demonstrated potential in enhancing the\nreasoning capabilities of large language models (LLMs), but such training\ntypically demands substantial efforts in creating and annotating data. In this\nwork, we explore improving LLMs through RL with minimal data. Our approach\nalternates between the LLM proposing a task and then attempting to solve it. To\nminimize data dependency, we introduce two novel mechanisms grounded in\nself-awareness: (1) self-aware difficulty prediction, where the model learns to\nassess task difficulty relative to its own abilities and prioritize challenging\nyet solvable tasks, and (2) self-aware limit breaking, where the model\nrecognizes when a task is beyond its capability boundary and proactively\nrequests external data to break through that limit. Extensive experiments on\nnine benchmarks showing a 53.8% relative improvement with less than 1.2% extra\ndata demonstrate the efficacy of self-aware RL and underscore the promise of\nself-evolving agent training.", "AI": {"tldr": "本文提出一种基于自意识的强化学习方法，旨在用最少数据提升大型语言模型（LLM）的推理能力，通过自预测任务难度和自识别能力边界来高效学习和请求外部数据。", "motivation": "强化学习（RL）虽能增强LLM的推理能力，但其训练通常需要大量的数据创建和标注工作。本文旨在探索如何在数据需求极小的情况下，通过RL改进LLM。", "method": "该方法让LLM在“提出任务”和“尝试解决任务”之间交替进行。为减少数据依赖，引入两个基于自意识的新机制：1) 自意识难度预测，模型评估任务难度并优先处理有挑战但可解决的任务；2) 自意识突破限制，模型识别超出其能力范围的任务并主动请求外部数据以突破限制。", "result": "在九个基准测试上进行了广泛实验，结果显示在仅使用不到1.2%额外数据的情况下，相对改进达到53.8%，证明了自意识强化学习的有效性。", "conclusion": "自意识强化学习是有效的，并凸显了自进化智能体训练的巨大潜力。"}}
{"id": "2510.03230", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03230", "abs": "https://arxiv.org/abs/2510.03230", "authors": ["Suyuchen Wang", "Tianyu Zhang", "Ahmed Masry", "Christopher Pal", "Spandana Gella", "Bang Liu", "Perouz Taslakian"], "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping", "comment": null, "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.", "AI": {"tldr": "本文提出RULER令牌和Interleaved MRoPE（I-MRoPE）两种创新方法，解决GUI定位中高分辨率显示器上的像素映射难题，通过提供显式空间指导显著提升了定位精度，尤其是在高分辨率界面上。", "motivation": "将自然语言指令映射到像素坐标的GUI定位对于自主代理至关重要，但当前的视觉语言模型（VLMs）在此方面仍面临困难。核心瓶颈在于可靠的块到像素映射，当推广到训练中未见过的高分辨率显示器时，这种映射会失效。现有方法直接从视觉特征生成文本令牌作为坐标，迫使模型隐式推断复杂的位点到像素映射，导致在新分辨率下准确性下降和失败增多。", "method": "本文提出了两项互补的创新：1. RULER令牌：作为显式坐标标记，让模型能够像地图网格线一样参考和调整位置，而不是从头生成坐标。2. Interleaved MRoPE (I-MRoPE)：通过确保宽度和高度维度被同等表示来改进空间编码，解决了标准位置方案的非对称性问题。", "result": "在ScreenSpot、ScreenSpot-V2和ScreenSpot-Pro数据集上的实验表明，定位精度持续提高，尤其是在高分辨率界面上取得了最大的改进。", "conclusion": "通过提供显式空间指导而非依赖隐式学习，本文的方法能够实现跨不同分辨率和平台的更可靠的GUI自动化。"}}
{"id": "2510.03198", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03198", "abs": "https://arxiv.org/abs/2510.03198", "authors": ["Junchao Huang", "Xinting Hu", "Boyao Han", "Shaoshuai Shi", "Zhuotao Tian", "Tianyu He", "Li Jiang"], "title": "Memory Forcing: Spatio-Temporal Memory for Consistent Scene Generation on Minecraft", "comment": "19 pages, 8 figures", "summary": "Autoregressive video diffusion models have proved effective for world\nmodeling and interactive scene generation, with Minecraft gameplay as a\nrepresentative application. To faithfully simulate play, a model must generate\nnatural content while exploring new scenes and preserve spatial consistency\nwhen revisiting explored areas. Under limited computation budgets, it must\ncompress and exploit historical cues within a finite context window, which\nexposes a trade-off: Temporal-only memory lacks long-term spatial consistency,\nwhereas adding spatial memory strengthens consistency but may degrade new scene\ngeneration quality when the model over-relies on insufficient spatial context.\nWe present Memory Forcing, a learning framework that pairs training protocols\nwith a geometry-indexed spatial memory. Hybrid Training exposes distinct\ngameplay regimes, guiding the model to rely on temporal memory during\nexploration and incorporate spatial memory for revisits. Chained Forward\nTraining extends autoregressive training with model rollouts, where chained\npredictions create larger pose variations and encourage reliance on spatial\nmemory for maintaining consistency. Point-to-Frame Retrieval efficiently\nretrieves history by mapping currently visible points to their source frames,\nwhile Incremental 3D Reconstruction maintains and updates an explicit 3D cache.\nExtensive experiments demonstrate that Memory Forcing achieves superior\nlong-term spatial consistency and generative quality across diverse\nenvironments, while maintaining computational efficiency for extended\nsequences.", "AI": {"tldr": "本文提出Memory Forcing框架，通过几何索引空间记忆和新训练协议，解决了自回归视频扩散模型在世界建模（如Minecraft）中生成新场景与保持空间一致性之间的矛盾，显著提升了长期空间一致性和生成质量。", "motivation": "自回归视频扩散模型在世界建模和交互式场景生成中面临挑战：需要在探索新场景时生成自然内容，并在重访区域保持空间一致性。在有限计算预算下，模型必须在有限上下文窗口内压缩和利用历史信息，这导致了一个权衡：仅时间记忆缺乏长期空间一致性，而添加空间记忆虽能增强一致性，但可能在空间上下文不足时降低新场景生成质量。", "method": "本文提出了Memory Forcing学习框架，它将训练协议与几何索引空间记忆相结合。主要方法包括：1) 混合训练（Hybrid Training），使模型在探索时依赖时间记忆，在重访时结合空间记忆；2) 链式前向训练（Chained Forward Training），通过模型推演扩展自回归训练，创建更大的姿态变化并鼓励依赖空间记忆来保持一致性；3) 点到帧检索（Point-to-Frame Retrieval），通过将当前可见点映射到其源帧来高效检索历史；4) 增量3D重建（Incremental 3D Reconstruction），维护和更新显式3D缓存。", "result": "广泛的实验表明，Memory Forcing在各种环境中实现了卓越的长期空间一致性和生成质量，同时在处理扩展序列时保持了计算效率。", "conclusion": "Memory Forcing框架通过创新的训练协议和几何索引空间记忆，成功解决了自回归视频扩散模型在世界建模中新场景生成和空间一致性之间的权衡问题，显著提升了模型的性能和效率。"}}
{"id": "2510.02788", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02788", "abs": "https://arxiv.org/abs/2510.02788", "authors": ["Tien Phat Nguyen", "Vu Minh Ngo", "Tung Nguyen", "Linh Van Ngo", "Duc Anh Nguyen", "Sang Dinh", "Trung Le"], "title": "XTRA: Cross-Lingual Topic Modeling with Topic and Representation Alignments", "comment": "2025 EMNLP Findings", "summary": "Cross-lingual topic modeling aims to uncover shared semantic themes across\nlanguages. Several methods have been proposed to address this problem,\nleveraging both traditional and neural approaches. While previous methods have\nachieved some improvements in topic diversity, they often struggle to ensure\nhigh topic coherence and consistent alignment across languages. We propose XTRA\n(Cross-Lingual Topic Modeling with Topic and Representation Alignments), a\nnovel framework that unifies Bag-of-Words modeling with multilingual\nembeddings. XTRA introduces two core components: (1) representation alignment,\naligning document-topic distributions via contrastive learning in a shared\nsemantic space; and (2) topic alignment, projecting topic-word distributions\ninto the same space to enforce crosslingual consistency. This dual mechanism\nenables XTRA to learn topics that are interpretable (coherent and diverse) and\nwell-aligned across languages. Experiments on multilingual corpora confirm that\nXTRA significantly outperforms strong baselines in topic coherence, diversity,\nand alignment quality. Code and reproducible scripts are available at https:\n//github.com/tienphat140205/XTRA.", "AI": {"tldr": "本文提出XTRA框架，结合词袋模型与多语言嵌入，通过表征对齐和主题对齐，解决了现有跨语言主题模型在主题连贯性和跨语言对齐方面的问题，显著提升了性能。", "motivation": "现有的跨语言主题建模方法虽然在主题多样性上有所改进，但在确保高主题连贯性和跨语言一致对齐方面表现不佳。", "method": "XTRA（Cross-Lingual Topic Modeling with Topic and Representation Alignments）框架统一了词袋模型和多语言嵌入。它引入了两个核心组件：1) 表征对齐，通过在共享语义空间中进行对比学习来对齐文档-主题分布；2) 主题对齐，将主题-词分布投影到同一空间以强制实现跨语言一致性。这种双重机制使XTRA能够学习到可解释（连贯且多样）并跨语言良好对齐的主题。", "result": "在多语言语料库上的实验证实，XTRA在主题连贯性、多样性和对齐质量方面显著优于强大的基线模型。", "conclusion": "XTRA通过其独特的双重对齐机制，能够有效地学习到可解释（连贯且多样）并跨语言良好对齐的主题，从而解决了现有方法的局限性。"}}
{"id": "2510.03231", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03231", "abs": "https://arxiv.org/abs/2510.03231", "authors": ["Sebastian Gehrmann"], "title": "Reward Models are Metrics in a Trench Coat", "comment": null, "summary": "The emergence of reinforcement learning in post-training of large language\nmodels has sparked significant interest in reward models. Reward models assess\nthe quality of sampled model outputs to generate training signals. This task is\nalso performed by evaluation metrics that monitor the performance of an AI\nmodel. We find that the two research areas are mostly separate, leading to\nredundant terminology and repeated pitfalls. Common challenges include\nsusceptibility to spurious correlations, impact on downstream reward hacking,\nmethods to improve data quality, and approaches to meta-evaluation. Our\nposition paper argues that a closer collaboration between the fields can help\novercome these issues. To that end, we show how metrics outperform reward\nmodels on specific tasks and provide an extensive survey of the two areas.\nGrounded in this survey, we point to multiple research topics in which closer\nalignment can improve reward models and metrics in areas such as preference\nelicitation methods, avoidance of spurious correlations and reward hacking, and\ncalibration-aware meta-evaluation.", "AI": {"tldr": "本文认为大型语言模型后训练中的奖励模型和评估指标研究领域应加强合作，以克服共同挑战并提高双方性能。", "motivation": "奖励模型和评估指标都旨在评估AI模型输出质量，但这两个研究领域目前大多独立，导致术语重复和重复出现的问题，如虚假相关性、奖励劫持等。", "method": "本文是一篇立场论文，通过对奖励模型和评估指标领域的广泛调查，展示了评估指标在特定任务上优于奖励模型的情况，并指出两个领域面临的共同挑战。", "result": "研究发现，两个领域存在虚假相关性、奖励劫持、数据质量提升和元评估等共同挑战。论文指出，在偏好启发方法、避免虚假相关性和奖励劫持、以及校准感知元评估等方面，更紧密的合作可以改进奖励模型和评估指标。", "conclusion": "奖励模型和评估指标之间更紧密的合作将有助于解决当前面临的问题，并促进这两个领域在大型语言模型后训练中的共同进步。"}}
{"id": "2510.03200", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03200", "abs": "https://arxiv.org/abs/2510.03200", "authors": ["Luca Collorone", "Matteo Gioia", "Massimiliano Pappa", "Paolo Leoni", "Giovanni Ficarra", "Or Litany", "Indro Spinelli", "Fabio Galasso"], "title": "MonSTeR: a Unified Model for Motion, Scene, Text Retrieval", "comment": null, "summary": "Intention drives human movement in complex environments, but such movement\ncan only happen if the surrounding context supports it. Despite the intuitive\nnature of this mechanism, existing research has not yet provided tools to\nevaluate the alignment between skeletal movement (motion), intention (text),\nand the surrounding context (scene). In this work, we introduce MonSTeR, the\nfirst MOtioN-Scene-TExt Retrieval model. Inspired by the modeling of\nhigher-order relations, MonSTeR constructs a unified latent space by leveraging\nunimodal and cross-modal representations. This allows MonSTeR to capture the\nintricate dependencies between modalities, enabling flexible but robust\nretrieval across various tasks. Our results show that MonSTeR outperforms\ntrimodal models that rely solely on unimodal representations. Furthermore, we\nvalidate the alignment of our retrieval scores with human preferences through a\ndedicated user study. We demonstrate the versatility of MonSTeR's latent space\non zero-shot in-Scene Object Placement and Motion Captioning. Code and\npre-trained models are available at github.com/colloroneluca/MonSTeR.", "AI": {"tldr": "MonSTeR是首个运动-场景-文本检索模型，它通过利用单模态和跨模态表示构建统一的潜在空间，以捕捉复杂依赖关系，从而在多模态检索任务中表现出色，并能支持零样本场景物体放置和运动字幕生成。", "motivation": "尽管意图、运动和环境背景之间的对齐关系是直观的，但现有研究缺乏评估骨骼运动（运动）、意图（文本）和周围环境（场景）之间对齐的工具。", "method": "本文引入了MonSTeR（MOtioN-Scene-TExt Retrieval）模型。它借鉴高阶关系建模，通过利用单模态和跨模态表示来构建一个统一的潜在空间，从而捕捉模态之间复杂的依赖关系。", "result": "MonSTeR的性能优于仅依赖单模态表示的三模态模型。通过专门的用户研究，验证了其检索分数与人类偏好一致。此外，MonSTeR的潜在空间在零样本场景物体放置和运动字幕生成方面展现了多功能性。", "conclusion": "MonSTeR成功地提供了一个评估运动、场景和文本之间对齐的工具，通过其统一的潜在空间实现了灵活而稳健的跨模态检索，并在多项任务中展现出卓越的性能和通用性。"}}
{"id": "2510.02827", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.02827", "abs": "https://arxiv.org/abs/2510.02827", "authors": ["Tengjun Ni", "Xin Yuan", "Shenghong Li", "Kai Wu", "Ren Ping Liu", "Wei Ni", "Wenjie Zhang"], "title": "StepChain GraphRAG: Reasoning Over Knowledge Graphs for Multi-Hop Question Answering", "comment": null, "summary": "Recent progress in retrieval-augmented generation (RAG) has led to more\naccurate and interpretable multi-hop question answering (QA). Yet, challenges\npersist in integrating iterative reasoning steps with external knowledge\nretrieval. To address this, we introduce StepChain GraphRAG, a framework that\nunites question decomposition with a Breadth-First Search (BFS) Reasoning Flow\nfor enhanced multi-hop QA. Our approach first builds a global index over the\ncorpus; at inference time, only retrieved passages are parsed on-the-fly into a\nknowledge graph, and the complex query is split into sub-questions. For each\nsub-question, a BFS-based traversal dynamically expands along relevant edges,\nassembling explicit evidence chains without overwhelming the language model\nwith superfluous context. Experiments on MuSiQue, 2WikiMultiHopQA, and HotpotQA\nshow that StepChain GraphRAG achieves state-of-the-art Exact Match and F1\nscores. StepChain GraphRAG lifts average EM by 2.57% and F1 by 2.13% over the\nSOTA method, achieving the largest gain on HotpotQA (+4.70% EM, +3.44% F1).\nStepChain GraphRAG also fosters enhanced explainability by preserving the\nchain-of-thought across intermediate retrieval steps. We conclude by discussing\nhow future work can mitigate the computational overhead and address potential\nhallucinations from large language models to refine efficiency and reliability\nin multi-hop QA.", "AI": {"tldr": "StepChain GraphRAG是一个结合了问题分解和广度优先搜索（BFS）推理流的框架，用于增强多跳问答（QA）。它通过动态构建知识图谱并组装证据链，在不增加语言模型负担的情况下，显著提高了多跳QA的准确性和可解释性，并在多个基准测试中达到了最先进的水平。", "motivation": "尽管检索增强生成（RAG）在多跳问答中取得了进展，但在将迭代推理步骤与外部知识检索集成方面仍存在挑战。", "method": "该方法首先在语料库上构建一个全局索引。在推理时，仅检索到的段落会被即时解析成知识图谱，并将复杂查询分解为子问题。对于每个子问题，基于BFS的遍历会沿相关边缘动态扩展，组装明确的证据链，从而避免用多余的上下文淹没语言模型。", "result": "StepChain GraphRAG在MuSiQue、2WikiMultiHopQA和HotpotQA数据集上实现了最先进的精确匹配（EM）和F1分数。它将平均EM提高了2.57%，F1提高了2.13%，其中在HotpotQA上的提升最大（EM +4.70%，F1 +3.44%）。此外，StepChain GraphRAG通过保留中间检索步骤的思维链，增强了可解释性。", "conclusion": "StepChain GraphRAG显著提高了多跳问答的准确性和可解释性。未来的工作可以集中于减轻计算开销，并解决大型语言模型可能产生的幻觉问题，以进一步提高多跳问答的效率和可靠性。"}}
{"id": "2510.03228", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03228", "abs": "https://arxiv.org/abs/2510.03228", "authors": ["Ricardo T. Fares", "Lucas C. Ribas"], "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture Recognition", "comment": null, "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.", "AI": {"tldr": "本文提出了一种名为Mixer的新型随机神经网络，用于纹理表示学习。它结合了超球面随机嵌入和双分支学习模块，并辅以新的优化问题，以捕捉通道内外部关系，在纹理识别基准上取得了显著成果。", "motivation": "现有用于纹理识别的随机神经网络主要关注交叉信息预测，但在整体随机网络架构方面缺乏重大进展。", "method": "Mixer方法的核心是利用超球面随机嵌入，结合一个双分支学习模块来捕捉通道内部和通道之间的关系，并通过一个新颖的优化问题来构建丰富的纹理表示。", "result": "实验结果表明，该方法在多个具有不同特点和挑战的纯纹理基准测试中取得了令人满意的成果。", "conclusion": "Mixer通过引入新颖的架构（超球面随机嵌入和双分支学习模块）和优化的学习问题，有效提升了随机神经网络在纹理表示学习方面的能力，解决了现有方法在架构创新上的不足。"}}
{"id": "2510.02919", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02919", "abs": "https://arxiv.org/abs/2510.02919", "authors": ["Jian Mu", "Qixin Zhang", "Zhiyong Wang", "Menglin Yang", "Shuang Qiu", "Chengwei Qin", "Zhongxiang Dai", "Yao Shu"], "title": "Self-Reflective Generation at Test Time", "comment": "24 pages, 8 figures", "summary": "Large language models (LLMs) increasingly solve complex reasoning tasks via\nlong chain-of-thought, but their forward-only autoregressive generation process\nis fragile; early token errors can cascade, which creates a clear need for\nself-reflection mechanisms. However, existing self-reflection either performs\nrevisions over full drafts or learns self-correction via expensive training,\nboth fundamentally reactive and inefficient. To address this, we propose\nSelf-Reflective Generation at Test Time (SRGen), a lightweight test-time\nframework that reflects before generating at uncertain points. During token\ngeneration, SRGen utilizes dynamic entropy thresholding to identify\nhigh-uncertainty tokens. For each identified token, it trains a specific\ncorrective vector, which fully exploits the already generated context for a\nself-reflective generation to correct the token probability distribution. By\nretrospectively analyzing the partial output, this self-reflection enables more\ntrustworthy decisions, thereby significantly reducing the probability of errors\nat highly uncertain points. Evaluated on challenging mathematical reasoning\nbenchmarks and a diverse set of LLMs, SRGen can consistently strengthen model\nreasoning: improvements in single-pass quality also translate into stronger\nself-consistency voting. Especially, on AIME2024 with\nDeepSeek-R1-Distill-Qwen-7B, SRGen yields absolute improvements of +12.0% on\nPass@1 and +13.3% on Cons@5. Moreover, our findings position SRGen as a\nplug-and-play method that integrates reflection into the generation process for\nreliable LLM reasoning, achieving consistent gains with bounded overhead and\nbroad composability with other training-time (e.g., RLHF) and test-time (e.g.,\nSLOT) techniques.", "AI": {"tldr": "SRGen是一种轻量级测试时框架，它在大型语言模型生成不确定性令牌之前进行自我反思，通过动态熵阈值识别高不确定性点，并训练校正向量来调整令牌概率分布，从而显著提高推理任务的准确性和可靠性。", "motivation": "大型语言模型（LLMs）在复杂推理任务中表现出色，但其前向自回归生成过程脆弱，早期错误可能级联。现有自我反思机制要么对完整草稿进行修订，要么需要昂贵的训练，两者都属于被动且低效。", "method": "SRGen在令牌生成过程中，利用动态熵阈值识别高不确定性令牌。对于每个识别出的不确定令牌，它会训练一个特定的校正向量，充分利用已生成的上下文进行自我反思式生成，以修正令牌的概率分布，从而在生成前降低错误概率。", "result": "SRGen在具有挑战性的数学推理基准和多种LLM上进行了评估，结果表明它能持续增强模型的推理能力。单次通过质量的提升也转化为更强的自洽性投票。特别是在AIME2024数据集上，使用DeepSeek-R1-Distill-Qwen-7B模型时，SRGen在Pass@1上实现了+12.0%的绝对提升，在Cons@5上实现了+13.3%的提升。此外，SRGen被证明是一种即插即用方法，具有有限的开销和广泛的与其他训练时及测试时技术的兼容性。", "conclusion": "SRGen是一种将反思融入生成过程的即插即用方法，能够提高LLM推理的可靠性，实现持续的性能提升，且具有可控的开销和良好的可组合性。它通过在不确定点生成前进行自我反思，显著减少了错误发生的可能性。"}}
{"id": "2510.03232", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03232", "abs": "https://arxiv.org/abs/2510.03232", "authors": ["Ci-Siang Lin", "Min-Hung Chen", "Yu-Yang Sheng", "Yu-Chiang Frank Wang"], "title": "LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have achieved strong performance on\ngeneral visual benchmarks but struggle with out-of-distribution (OOD) tasks in\nspecialized domains such as medical imaging, where labeled data is limited and\nexpensive. We introduce LEAML, a label-efficient adaptation framework that\nleverages both scarce labeled VQA samples and abundant unlabeled images. Our\napproach generates domain-relevant pseudo question-answer pairs for unlabeled\ndata using a QA generator regularized by caption distillation. Importantly, we\nselectively update only those neurons most relevant to question-answering,\nenabling the QA Generator to efficiently acquire domain-specific knowledge\nduring distillation. Experiments on gastrointestinal endoscopy and sports VQA\ndemonstrate that LEAML consistently outperforms standard fine-tuning under\nminimal supervision, highlighting the effectiveness of our proposed LEAML\nframework.", "AI": {"tldr": "针对多模态大语言模型（MLLMs）在专业领域（如医学影像）OOD任务中因标注数据稀缺而表现不佳的问题，本文提出了LEAML框架。该框架利用少量标注VQA样本和大量未标注图像，通过一个由字幕蒸馏正则化的QA生成器生成伪问答对，并选择性更新与问答最相关的神经元。实验证明，LEAML在最小监督下显著优于标准微调。", "motivation": "多模态大语言模型（MLLMs）在通用视觉基准上表现出色，但在专业领域（如医学影像）的分布外（OOD）任务中表现不佳，因为这些领域的标注数据有限且昂贵。", "method": "本文引入了LEAML，一个标签高效的适应框架。它利用稀缺的标注VQA样本和丰富的未标注图像。该方法通过一个由字幕蒸馏正则化的QA生成器为未标注数据生成领域相关的伪问答对。关键在于，它只选择性地更新与问答最相关的神经元，使QA生成器在蒸馏过程中能高效获取领域特定知识。", "result": "在胃肠内窥镜和体育VQA任务上的实验表明，LEAML在最小监督下持续优于标准微调方法，证明了所提出的LEAML框架的有效性。", "conclusion": "LEAML框架是一种有效的标签高效适应方法，能够帮助多模态大语言模型在标注数据有限的专业领域中提升性能，解决了其在OOD任务中的挑战。"}}
{"id": "2510.02938", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02938", "abs": "https://arxiv.org/abs/2510.02938", "authors": ["Yohan Lee", "Yongwoo Song", "Sangyeop Kim"], "title": "Finding Diamonds in Conversation Haystacks: A Benchmark for Conversational Data Retrieval", "comment": "Accepted by EMNLP 2025 Industry Track", "summary": "We present the Conversational Data Retrieval (CDR) benchmark, the first\ncomprehensive test set for evaluating systems that retrieve conversation data\nfor product insights. With 1.6k queries across five analytical tasks and 9.1k\nconversations, our benchmark provides a reliable standard for measuring\nconversational data retrieval performance. Our evaluation of 16 popular\nembedding models shows that even the best models reach only around NDCG@10 of\n0.51, revealing a substantial gap between document and conversational data\nretrieval capabilities. Our work identifies unique challenges in conversational\ndata retrieval (implicit state recognition, turn dynamics, contextual\nreferences) while providing practical query templates and detailed error\nanalysis across different task categories. The benchmark dataset and code are\navailable at https://github.com/l-yohai/CDR-Benchmark.", "AI": {"tldr": "本文提出了对话数据检索（CDR）基准，这是首个用于评估产品洞察对话数据检索系统的综合测试集，并揭示了现有模型在此任务上的显著性能差距和独特挑战。", "motivation": "缺乏一个全面可靠的测试集来评估和衡量用于产品洞察的对话数据检索系统的性能。", "method": "创建了包含1.6k查询（涵盖五种分析任务）和9.1k对话的CDR基准数据集。评估了16种流行的嵌入模型。进行了详细的错误分析，并识别了对话数据检索中的独特挑战。", "result": "即使是表现最好的模型，其NDCG@10也仅达到0.51左右，这表明文档检索和对话数据检索能力之间存在巨大差距。研究识别了对话数据检索的独特挑战，包括隐式状态识别、轮次动态和上下文引用。同时提供了实用的查询模板和不同任务类别的详细错误分析。", "conclusion": "CDR基准为衡量对话数据检索性能提供了一个可靠的标准，揭示了当前模型在这一领域表现不佳的现状，并明确了该任务的独特挑战，为未来的研究指明了方向。"}}
{"id": "2510.02962", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.02962", "abs": "https://arxiv.org/abs/2510.02962", "authors": ["Jingqi Zhang", "Ruibo Chen", "Yingqing Yang", "Peihua Mai", "Heng Huang", "Yan Pang"], "title": "Leave No TRACE: Black-box Detection of Copyrighted Dataset Usage in Large Language Models via Watermarking", "comment": null, "summary": "Large Language Models (LLMs) are increasingly fine-tuned on smaller,\ndomain-specific datasets to improve downstream performance. These datasets\noften contain proprietary or copyrighted material, raising the need for\nreliable safeguards against unauthorized use. Existing membership inference\nattacks (MIAs) and dataset-inference methods typically require access to\ninternal signals such as logits, while current black-box approaches often rely\non handcrafted prompts or a clean reference dataset for calibration, both of\nwhich limit practical applicability. Watermarking is a promising alternative,\nbut prior techniques can degrade text quality or reduce task performance. We\npropose TRACE, a practical framework for fully black-box detection of\ncopyrighted dataset usage in LLM fine-tuning. \\texttt{TRACE} rewrites datasets\nwith distortion-free watermarks guided by a private key, ensuring both text\nquality and downstream utility. At detection time, we exploit the radioactivity\neffect of fine-tuning on watermarked data and introduce an entropy-gated\nprocedure that selectively scores high-uncertainty tokens, substantially\namplifying detection power. Across diverse datasets and model families, TRACE\nconsistently achieves significant detections (p<0.05), often with extremely\nstrong statistical evidence. Furthermore, it supports multi-dataset attribution\nand remains robust even after continued pretraining on large non-watermarked\ncorpora. These results establish TRACE as a practical route to reliable\nblack-box verification of copyrighted dataset usage. We will make our code\navailable at: https://github.com/NusIoraPrivacy/TRACE.", "AI": {"tldr": "TRACE是一个实用的黑盒水印框架，用于检测LLM微调中受版权保护数据集的使用，它通过无失真水印和熵门控检测过程，在不影响文本质量和下游效用的前提下，实现了强大且鲁棒的检测能力。", "motivation": "大型语言模型（LLMs）在专有或受版权保护的领域特定数据集上进行微调时，需要可靠的机制来防止未经授权的使用。现有的成员推理攻击（MIAs）和数据集推断方法通常需要访问内部信号（如logits）或干净的参考数据集，这限制了它们的实际应用。传统的水印技术可能会降低文本质量或任务性能。", "method": "本文提出了TRACE框架。它通过私钥引导的无失真水印对数据集进行重写，确保了文本质量和下游实用性。在检测时，TRACE利用微调在水印数据上产生的“放射性效应”，并引入了一种熵门控程序，选择性地对高不确定性token进行评分，从而显著增强了检测能力。该方法是完全黑盒的。", "result": "TRACE在不同数据集和模型家族上持续实现了显著的检测（p<0.05），且通常具有极强的统计证据。它支持多数据集归因，并且即使在大量非水印语料库上继续预训练后，仍然保持鲁棒性。", "conclusion": "TRACE为可靠的黑盒验证LLM微调中受版权保护数据集的使用提供了一条实用途径。"}}
{"id": "2510.03093", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.03093", "abs": "https://arxiv.org/abs/2510.03093", "authors": ["Oriol Pareras", "Gerard I. Gállego", "Federico Costa", "Cristina España-Bonet", "Javier Hernando"], "title": "Revisiting Direct Speech-to-Text Translation with Speech LLMs: Better Scaling than CoT Prompting?", "comment": null, "summary": "Recent work on Speech-to-Text Translation (S2TT) has focused on LLM-based\nmodels, introducing the increasingly adopted Chain-of-Thought (CoT) prompting,\nwhere the model is guided to first transcribe the speech and then translate it.\nCoT typically outperforms direct prompting primarily because it can exploit\nabundant Automatic Speech Recognition (ASR) and Text-to-Text Translation (T2TT)\ndatasets to explicitly model its steps. In this paper, we systematically\ncompare CoT and Direct prompting under increasing amounts of S2TT data. To this\nend, we pseudo-label an ASR corpus by translating its transcriptions into six\nEuropean languages, and train LLM-based S2TT systems with both prompting\nstrategies at different data scales. Our results show that Direct improves more\nconsistently as the amount of data increases, suggesting that it may become a\nmore effective approach as larger S2TT resources are created.", "AI": {"tldr": "本文系统比较了在不同S2TT数据量下，LLM驱动的语音到文本翻译（S2TT）中CoT和直接提示策略的性能，发现随着数据量增加，直接提示策略的改进更显著。", "motivation": "LLM驱动的S2TT模型中，CoT提示因能利用丰富的ASR和T2TT数据集而日益普及并通常优于直接提示。本研究旨在系统地比较这两种策略在不同S2TT数据量下的表现。", "method": "通过将一个ASR语料库的转录本翻译成六种欧洲语言来伪标注S2TT数据。然后，在不同数据规模下，使用这两种提示策略（CoT和Direct）训练基于LLM的S2TT系统。", "result": "研究结果表明，随着S2TT数据量的增加，直接提示策略的性能改进更为稳定和显著。", "conclusion": "这表明，随着未来更大规模S2TT资源的创建，直接提示策略可能成为一种更有效的S2TT方法。"}}
{"id": "2510.03102", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03102", "abs": "https://arxiv.org/abs/2510.03102", "authors": ["Beth Pearson", "Ahmed Adnan", "Zahraa Abdallah"], "title": "Semantic Similarity in Radiology Reports via LLMs and NER", "comment": null, "summary": "Radiology report evaluation is a crucial part of radiologists' training and\nplays a key role in ensuring diagnostic accuracy. As part of the standard\nreporting workflow, a junior radiologist typically prepares a preliminary\nreport, which is then reviewed and edited by a senior radiologist to produce\nthe final report. Identifying semantic differences between preliminary and\nfinal reports is essential for junior doctors, both as a training tool and to\nhelp uncover gaps in clinical knowledge. While AI in radiology is a rapidly\ngrowing field, the application of large language models (LLMs) remains\nchallenging due to the need for specialised domain knowledge. In this paper, we\nexplore the ability of LLMs to provide explainable and accurate comparisons of\nreports in the radiology domain. We begin by comparing the performance of\nseveral LLMs in comparing radiology reports. We then assess a more traditional\napproach based on Named-Entity-Recognition (NER). However, both approaches\nexhibit limitations in delivering accurate feedback on semantic similarity. To\naddress this, we propose Llama-EntScore, a semantic similarity scoring method\nusing a combination of Llama 3.1 and NER with tunable weights to emphasise or\nde-emphasise specific types of differences. Our approach generates a\nquantitative similarity score for tracking progress and also gives an\ninterpretation of the score that aims to offer valuable guidance in reviewing\nand refining their reporting. We find our method achieves 67% exact-match\naccuracy and 93% accuracy within +/- 1 when compared to radiologist-provided\nground truth scores - outperforming both LLMs and NER used independently. Code\nis available at:\n\\href{https://github.com/otmive/llama_reports}{github.com/otmive/llama\\_reports}", "AI": {"tldr": "本研究提出了一种名为 Llama-EntScore 的新方法，结合 Llama 3.1 大语言模型和命名实体识别（NER），用于对放射学报告进行可解释且准确的语义相似性比较，其性能优于单独使用 LLM 或 NER。", "motivation": "放射学报告评估对初级放射科医生的培训和诊断准确性至关重要。识别初级医生初步报告与高级医生最终报告之间的语义差异，对于培训和发现知识空白是必需的。尽管大语言模型（LLMs）在放射学领域面临专业领域知识的挑战，且现有方法（单独的 LLM 或 NER）在提供准确的语义反馈方面存在局限性，但仍需探索其在放射学报告比较中的应用。", "method": "首先，比较了多个 LLMs 在放射学报告比较中的表现。其次，评估了一种基于命名实体识别（NER）的传统方法。最后，提出 Llama-EntScore 方法，它结合了 Llama 3.1 和 NER，并引入了可调权重以强调或弱化特定类型的差异，从而生成定量的相似性得分及解释。", "result": "单独的 LLM 和 NER 方法在提供准确的语义相似性反馈方面均表现出局限性。Llama-EntScore 方法在与放射科医生提供的真实分数进行比较时，实现了 67% 的精确匹配准确率和 +/- 1 范围内的 93% 准确率，优于单独使用的 LLMs 和 NER。", "conclusion": "Llama-EntScore 方法能为放射学报告提供可解释且准确的比较，为初级放射科医生在报告审查和完善方面提供有价值的指导，并可用于追踪进度。该方法证明了结合 LLM 与领域特定技术（如带可调权重的 NER）在解决专业领域挑战方面的有效性。"}}
{"id": "2510.03115", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.03115", "abs": "https://arxiv.org/abs/2510.03115", "authors": ["Jacobo Romero-Díaz", "Gerard I. Gállego", "Oriol Pareras", "Federico Costa", "Javier Hernando", "Cristina España-Bonet"], "title": "Listening or Reading? Evaluating Speech Awareness in Chain-of-Thought Speech-to-Text Translation", "comment": null, "summary": "Speech-to-Text Translation (S2TT) systems built from Automatic Speech\nRecognition (ASR) and Text-to-Text Translation (T2TT) modules face two major\nlimitations: error propagation and the inability to exploit prosodic or other\nacoustic cues. Chain-of-Thought (CoT) prompting has recently been introduced,\nwith the expectation that jointly accessing speech and transcription will\novercome these issues. Analyzing CoT through attribution methods, robustness\nevaluations with corrupted transcripts, and prosody-awareness, we find that it\nlargely mirrors cascaded behavior, relying mainly on transcripts while barely\nleveraging speech. Simple training interventions, such as adding Direct S2TT\ndata or noisy transcript injection, enhance robustness and increase speech\nattribution. These findings challenge the assumed advantages of CoT and\nhighlight the need for architectures that explicitly integrate acoustic\ninformation into translation.", "AI": {"tldr": "研究发现，语音到文本翻译（S2TT）中的思维链（CoT）方法主要依赖文本而非语音，行为与级联系统相似。但通过简单的训练干预（如添加直接S2TT数据或注入噪声转录），可以提高鲁棒性并增加语音归因，这挑战了CoT的预期优势。", "motivation": "传统的S2TT级联系统（ASR+T2TT）存在错误传播和无法利用韵律等声学线索的问题。思维链（CoT）提示被引入，期望通过同时访问语音和转录来克服这些限制，本研究旨在分析CoT是否真正实现了这些优势。", "method": "研究通过归因方法、使用损坏转录本的鲁棒性评估以及韵律感知分析来考察CoT。此外，还测试了简单的训练干预措施，例如添加直接S2TT数据或注入噪声转录。", "result": "研究发现CoT在很大程度上模仿了级联行为，主要依赖转录文本，而几乎没有利用语音信息。然而，通过添加直接S2TT数据或注入噪声转录等简单的训练干预，可以增强系统的鲁棒性并提高语音归因。", "conclusion": "这些发现挑战了CoT在S2TT中被假设的优势，并强调了需要开发能够明确地将声学信息整合到翻译过程中的新架构。"}}
{"id": "2510.03120", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03120", "abs": "https://arxiv.org/abs/2510.03120", "authors": ["Zhaojun Sun", "Xuzhou Zhu", "Xuanhe Zhou", "Xin Tong", "Shuo Wang", "Jie Fu", "Guoliang Li", "Zhiyuan Liu", "Fan Wu"], "title": "SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?", "comment": null, "summary": "Academic survey writing, which distills vast literature into a coherent and\ninsightful narrative, remains a labor-intensive and intellectually demanding\ntask. While recent approaches, such as general DeepResearch agents and\nsurvey-specialized methods, can generate surveys automatically (a.k.a.\nLLM4Survey), their outputs often fall short of human standards and there lacks\na rigorous, reader-aligned benchmark for thoroughly revealing their\ndeficiencies. To fill the gap, we propose a fine-grained, quiz-driven\nevaluation framework SurveyBench, featuring (1) typical survey topics source\nfrom recent 11,343 arXiv papers and corresponding 4,947 high-quality surveys;\n(2) a multifaceted metric hierarchy that assesses the outline quality (e.g.,\ncoverage breadth, logical coherence), content quality (e.g., synthesis\ngranularity, clarity of insights), and non-textual richness; and (3) a\ndual-mode evaluation protocol that includes content-based and quiz-based\nanswerability tests, explicitly aligned with readers' informational needs.\nResults show SurveyBench effectively challenges existing LLM4Survey approaches\n(e.g., on average 21% lower than human in content-based evaluation).", "AI": {"tldr": "本文提出SurveyBench，一个细粒度、基于问答的评估框架，用于严格评估大型语言模型（LLM）生成的学术综述文章，并揭示了现有LLM4Survey方法与人类表现的差距。", "motivation": "尽管LLM可以自动生成学术综述，但其产出往往未能达到人类标准。目前缺乏一个严谨、以读者为导向的基准来彻底揭示这些不足。", "method": "本文提出了SurveyBench评估框架，其特点包括：(1) 源自11,343篇arXiv论文和4,947篇高质量综述的典型综述主题；(2) 一个多方面的度量层次结构，评估大纲质量（如覆盖广度、逻辑连贯性）、内容质量（如综合粒度、洞察力清晰度）和非文本丰富性；(3) 一种双模式评估协议，包括基于内容的和基于问答的可回答性测试，明确与读者的信息需求对齐。", "result": "实验结果表明，SurveyBench能有效挑战现有的LLM4Survey方法，例如在基于内容的评估中，LLM平均比人类表现低21%。", "conclusion": "SurveyBench是一个有效的工具，可以揭示LLM生成学术综述的不足，并为未来改进LLM4Survey方法提供了严格的评估基准，凸显了LLM与人类在综述写作方面的差距。"}}
{"id": "2510.03136", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03136", "abs": "https://arxiv.org/abs/2510.03136", "authors": ["Ej Zhou", "Caiqi Zhang", "Tiancheng Hu", "Chengzu Li", "Nigel Collier", "Ivan Vulić", "Anna Korhonen"], "title": "Beyond the Final Layer: Intermediate Representations for Better Multilingual Calibration in Large Language Models", "comment": null, "summary": "Confidence calibration, the alignment of a model's predicted confidence with\nits actual accuracy, is crucial for the reliable deployment of Large Language\nModels (LLMs). However, this critical property remains largely under-explored\nin multilingual contexts. In this work, we conduct the first large-scale,\nsystematic studies of multilingual calibration across six model families and\nover 100 languages, revealing that non-English languages suffer from\nsystematically worse calibration. To diagnose this, we investigate the model's\ninternal representations and find that the final layer, biased by\nEnglish-centric training, provides a poor signal for multilingual confidence.\nIn contrast, our layer-wise analysis uncovers a key insight that\nlate-intermediate layers consistently offer a more reliable and\nbetter-calibrated signal. Building on this, we introduce a suite of\ntraining-free methods, including Language-Aware Confidence Ensemble (LACE),\nwhich adaptively selects an optimal ensemble of layers for each specific\nlanguage. Our study highlights the hidden costs of English-centric alignment\nand offer a new path toward building more globally equitable and trustworthy\nLLMs by looking beyond the final layer.", "AI": {"tldr": "本研究首次大规模系统地探讨了多语言大语言模型的置信度校准问题，发现非英语语言的校准效果显著较差，并提出通过利用后期中间层信号及训练无关方法（如LACE）来提升多语言校准。", "motivation": "模型的预测置信度与实际准确性的一致性（即置信度校准）对于大语言模型（LLM）的可靠部署至关重要。然而，这一关键特性在多语言环境中尚未得到充分探索，且非英语语言的校准问题尤为突出。", "method": "本研究对六个模型家族和一百多种语言进行了首次大规模、系统的多语言校准研究。通过调查模型的内部表示，特别是最终层和中间层，来诊断校准不佳的原因。在此基础上，引入了一系列训练无关的方法，其中包括语言感知置信度集成（LACE），该方法能为每种特定语言自适应地选择最优的层集合。", "result": "研究发现非英语语言的校准效果系统性地更差。诊断结果表明，受以英语为中心的训练偏差影响，模型的最终层为多语言置信度提供了较差的信号。相反，层级分析揭示，后期中间层能持续提供更可靠、校准更好的信号。基于此，LACE等训练无关方法能够有效提升校准性能。", "conclusion": "研究揭示了以英语为中心的对齐训练所带来的隐性成本，并指出通过超越最终层、利用后期中间层信号，可以为构建更公平、更值得信赖的全球化大语言模型开辟新途径。"}}
{"id": "2510.03154", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03154", "abs": "https://arxiv.org/abs/2510.03154", "authors": ["Katherine Thai", "Bradley Emi", "Elyas Masrour", "Mohit Iyyer"], "title": "EditLens: Quantifying the Extent of AI Editing in Text", "comment": null, "summary": "A significant proportion of queries to large language models ask them to edit\nuser-provided text, rather than generate new text from scratch. While previous\nwork focuses on detecting fully AI-generated text, we demonstrate that\nAI-edited text is distinguishable from human-written and AI-generated text.\nFirst, we propose using lightweight similarity metrics to quantify the\nmagnitude of AI editing present in a text given the original human-written text\nand validate these metrics with human annotators. Using these similarity\nmetrics as intermediate supervision, we then train EditLens, a regression model\nthat predicts the amount of AI editing present within a text. Our model\nachieves state-of-the-art performance on both binary (F1=94.7%) and ternary\n(F1=90.4%) classification tasks in distinguishing human, AI, and mixed writing.\nNot only do we show that AI-edited text can be detected, but also that the\ndegree of change made by AI to human writing can be detected, which has\nimplications for authorship attribution, education, and policy. Finally, as a\ncase study, we use our model to analyze the effects of AI-edits applied by\nGrammarly, a popular writing assistance tool. To encourage further research, we\ncommit to publicly releasing our models and dataset.", "AI": {"tldr": "该研究提出并验证了AI编辑文本与人类撰写及完全AI生成文本的可区分性，并开发了EditLens模型，能够预测文本中AI编辑的程度，在检测AI编辑文本方面达到最先进的性能。", "motivation": "大型语言模型（LLMs）的许多查询涉及编辑现有文本而非从头生成。然而，现有研究主要关注检测完全由AI生成的文本。因此，需要研究如何区分AI编辑的文本，并量化AI编辑的程度。", "method": "首先，研究提出使用轻量级相似性指标来量化给定原始人类文本后AI编辑的程度，并通过人工标注验证了这些指标。然后，利用这些相似性指标作为中间监督，训练了一个名为EditLens的回归模型，该模型能够预测文本中AI编辑的数量。", "result": "EditLens模型在区分人类、AI和混合写作的二分类（F1=94.7%）和三分类（F1=90.4%）任务上均取得了最先进的性能。研究不仅证明了AI编辑文本可以被检测，而且AI对人类写作的修改程度也可以被检测。作为一个案例研究，模型被用于分析流行的写作辅助工具Grammarly所施加的AI编辑效果。", "conclusion": "AI编辑的文本及其修改程度是可检测的，这对于作者归属、教育和政策制定具有重要意义。为了促进进一步研究，作者承诺公开发布其模型和数据集。"}}
{"id": "2510.03156", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03156", "abs": "https://arxiv.org/abs/2510.03156", "authors": ["Iñigo Parra"], "title": "Neural Correlates of Language Models Are Specific to Human Language", "comment": "To be presented at NeurIPS 2025 Workshops", "summary": "Previous work has shown correlations between the hidden states of large\nlanguage models and fMRI brain responses, on language tasks. These correlations\nhave been taken as evidence of the representational similarity of these models\nand brain states. This study tests whether these previous results are robust to\nseveral possible concerns. Specifically this study shows: (i) that the previous\nresults are still found after dimensionality reduction, and thus are not\nattributable to the curse of dimensionality; (ii) that previous results are\nconfirmed when using new measures of similarity; (iii) that correlations\nbetween brain representations and those from models are specific to models\ntrained on human language; and (iv) that the results are dependent on the\npresence of positional encoding in the models. These results confirm and\nstrengthen the results of previous research and contribute to the debate on the\nbiological plausibility and interpretability of state-of-the-art large language\nmodels.", "AI": {"tldr": "本研究通过解决几个潜在问题，验证并强化了大型语言模型隐藏状态与fMRI脑反应之间相关性的先前发现。", "motivation": "之前的研究发现大型语言模型（LLM）的隐藏状态与语言任务中的fMRI脑反应存在相关性，并将其视为模型与大脑状态之间表征相似性的证据。然而，这些结果的稳健性存在一些担忧，本研究旨在检验这些担忧。", "method": "本研究通过以下方法检验了先前结果的稳健性：(i) 在降维后重新评估结果，以排除维度诅咒的影响；(ii) 使用新的相似性度量来确认结果；(iii) 比较受过人类语言训练的模型与其他模型，以检验相关性的特异性；(iv) 分析模型中位置编码对结果的影响。", "result": "研究结果表明：(i) 降维后仍能发现之前的相关性结果；(ii) 使用新的相似性度量也证实了之前的相关性；(iii) 大脑表征与模型表征之间的相关性仅限于受过人类语言训练的模型；(iv) 这些结果依赖于模型中位置编码的存在。", "conclusion": "本研究的结果证实并强化了先前研究的发现，为关于最先进大型语言模型的生物合理性和可解释性的讨论做出了贡献。"}}
{"id": "2510.03202", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03202", "abs": "https://arxiv.org/abs/2510.03202", "authors": ["Abteen Ebrahimi", "Adam Wiemerslage", "Katharina von der Wense"], "title": "Model-Based Ranking of Source Languages for Zero-Shot Cross-Lingual Transfer", "comment": "Accepted to EMNLP 2025 (Main)", "summary": "We present NN-Rank, an algorithm for ranking source languages for\ncross-lingual transfer, which leverages hidden representations from\nmultilingual models and unlabeled target-language data. We experiment with two\npretrained multilingual models and two tasks: part-of-speech tagging (POS) and\nnamed entity recognition (NER). We consider 51 source languages and evaluate on\n56 and 72 target languages for POS and NER, respectively. When using in-domain\ndata, NN-Rank beats state-of-the-art baselines that leverage lexical and\nlinguistic features, with average improvements of up to 35.56 NDCG for POS and\n18.14 NDCG for NER. As prior approaches can fall back to language-level\nfeatures if target language data is not available, we show that NN-Rank remains\ncompetitive using only the Bible, an out-of-domain corpus available for a large\nnumber of languages. Ablations on the amount of unlabeled target data show\nthat, for subsets consisting of as few as 25 examples, NN-Rank produces\nhigh-quality rankings which achieve 92.8% of the NDCG achieved using all\navailable target data for ranking.", "AI": {"tldr": "NN-Rank是一种利用多语言模型隐藏表示和无标签目标语言数据，为跨语言迁移任务排序源语言的算法。它在POS和NER任务上显著优于现有基线，即使在数据有限的情况下也表现出色。", "motivation": "现有跨语言迁移的源语言排序方法主要依赖词汇和语言学特征，可能无法充分捕捉语言间的复杂关系。本研究旨在开发一种更有效、更鲁棒的源语言排序算法。", "method": "NN-Rank算法利用预训练多语言模型的隐藏表示和无标签目标语言数据进行源语言排序。研究在两个预训练多语言模型和两个任务（词性标注POS、命名实体识别NER）上进行实验，涉及51种源语言以及56/72种目标语言。同时，评估了在域内数据、域外数据（圣经语料）以及不同数量无标签目标数据下的表现。", "result": "使用域内数据时，NN-Rank在POS任务上平均NDCG提升高达35.56%，在NER任务上提升18.14%，均优于现有最先进的基线。即使仅使用域外语料（如圣经），NN-Rank仍保持竞争力。仅使用25个无标签目标语言示例，NN-Rank就能产生高质量的排序，达到使用全部可用目标数据时NDCG的92.8%。", "conclusion": "NN-Rank是一种高效且鲁棒的源语言排序算法，通过利用多语言模型表示和无标签目标语言数据，显著提升了跨语言迁移任务的性能，并且对目标语言数据的数量不敏感。"}}
{"id": "2510.03204", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03204", "abs": "https://arxiv.org/abs/2510.03204", "authors": ["Imene Kerboua", "Sahar Omidi Shayegan", "Megh Thakkar", "Xing Han Lù", "Léo Boisvert", "Massimo Caccia", "Jérémy Espinas", "Alexandre Aussem", "Véronique Eglin", "Alexandre Lacoste"], "title": "FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents", "comment": null, "summary": "Web agents powered by large language models (LLMs) must process lengthy web\npage observations to complete user goals; these pages often exceed tens of\nthousands of tokens. This saturates context limits and increases computational\ncost processing; moreover, processing full pages exposes agents to security\nrisks such as prompt injection. Existing pruning strategies either discard\nrelevant content or retain irrelevant context, leading to suboptimal action\nprediction. We introduce FocusAgent, a simple yet effective approach that\nleverages a lightweight LLM retriever to extract the most relevant lines from\naccessibility tree (AxTree) observations, guided by task goals. By pruning\nnoisy and irrelevant content, FocusAgent enables efficient reasoning while\nreducing vulnerability to injection attacks. Experiments on WorkArena and\nWebArena benchmarks show that FocusAgent matches the performance of strong\nbaselines, while reducing observation size by over 50%. Furthermore, a variant\nof FocusAgent significantly reduces the success rate of prompt-injection\nattacks, including banner and pop-up attacks, while maintaining task success\nperformance in attack-free settings. Our results highlight that targeted\nLLM-based retrieval is a practical and robust strategy for building web agents\nthat are efficient, effective, and secure.", "AI": {"tldr": "FocusAgent提出了一种轻量级LLM检索器，用于从网页观察中提取最相关内容，从而为LLM驱动的Web代理提供更高效、更安全、更有效的解决方案，同时显著减少观察大小并降低注入攻击的风险。", "motivation": "LLM驱动的Web代理在处理冗长网页（数万个token）时面临挑战，这会导致上下文限制饱和、计算成本增加以及提示注入等安全风险。现有的剪枝策略要么丢弃相关内容，要么保留不相关上下文，导致行动预测不佳。", "method": "引入FocusAgent，一种简单有效的方法。它利用一个轻量级LLM检索器，根据任务目标从可访问性树（AxTree）观察中提取最相关的行。通过剪枝噪声和不相关内容，FocusAgent实现了高效推理并降低了注入攻击的脆弱性。", "result": "在WorkArena和WebArena基准测试中，FocusAgent的性能与强大的基线相当，同时将观察大小减少了50%以上。此外，FocusAgent的一个变体显著降低了提示注入攻击（包括横幅和弹出攻击）的成功率，同时在无攻击设置中保持了任务成功性能。", "conclusion": "研究结果表明，有针对性的基于LLM的检索是一种实用且鲁棒的策略，可用于构建高效、有效且安全的Web代理。"}}
{"id": "2510.03215", "categories": ["cs.CL", "cs.LG", "68T07, 68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.03215", "abs": "https://arxiv.org/abs/2510.03215", "authors": ["Tianyu Fu", "Zihan Min", "Hanling Zhang", "Jichao Yan", "Guohao Dai", "Wanli Ouyang", "Yu Wang"], "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language Models", "comment": null, "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.", "AI": {"tldr": "该研究提出了一种名为Cache-to-Cache (C2C)的新范式，允许多LLM系统通过直接语义传输（而非文本）进行通信，从而提高性能并显著降低延迟。", "motivation": "现有的大语言模型（LLM）多模型系统通过文本进行通信，这导致语义信息丢失，并产生逐令牌生成的延迟。研究旨在探索LLM能否超越文本进行通信，以克服这些限制。", "method": "通过Oracle实验证明，丰富KV-Cache的语义可以在不增加缓存大小的情况下提高响应质量。基于此，提出C2C范式，使用神经网络将源模型的KV-cache投射并融合到目标模型的KV-cache中，实现直接语义传输。同时，采用可学习的门控机制来选择受益于缓存通信的目标层。", "result": "C2C范式比单个模型平均准确率高出8.5-10.5%。与基于文本的通信范式相比，C2C的准确率提高了约3.0-5.0%，同时平均延迟提速2.0倍。", "conclusion": "C2C通过直接语义通信，有效利用了模型的深层专业语义，避免了中间文本生成，显著提升了多LLM系统的性能和效率，优于传统的文本通信方式。"}}
