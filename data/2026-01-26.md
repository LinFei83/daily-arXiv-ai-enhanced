<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]
- [cs.CV](#cs.CV) [Total: 53]
- [cs.CL](#cs.CL) [Total: 53]
- [cs.RO](#cs.RO) [Total: 15]
- [eess.SY](#eess.SY) [Total: 13]
- [eess.IV](#eess.IV) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems](https://arxiv.org/abs/2601.16280)
*Donghao Huang,Gauri Malwe,Zhaoxia Wang*

Main category: cs.AI

TL;DR: 本文提出了一个评估大型语言模型（LLM）驱动的多智能体系统工具使用可靠性的诊断框架。该框架通过12类错误分类和大规模测试（1980个实例，涵盖不同模型和硬件），识别了可靠性瓶颈，并为实际部署提供了可行的阈值和模型选择建议，特别关注中小型企业在隐私敏感环境中的部署。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）驱动的多智能体系统在企业自动化方面展现出巨大潜力，但缺乏系统性的评估方法来衡量其工具使用的可靠性，这阻碍了其在实际应用中的部署，尤其是在隐私敏感的中小型企业环境中。

Method: 本文开发了一个全面的诊断框架，利用大数据分析来评估智能体系统的程序可靠性。该框架包含一个12类错误分类体系，用于捕捉工具初始化、参数处理、执行和结果解释等环节的失败模式。通过在不同边缘硬件上对开源模型（Qwen2.5系列，Functionary）和专有模型（GPT-4，Claude 3.5/3.7）进行1980个确定性测试实例的系统评估来验证该框架。

Result: 分析显示，程序可靠性，尤其是工具初始化失败，是小型模型的主要瓶颈。Qwen2.5:32b模型在工具使用方面表现出与GPT-4.1相当的完美性能。对于中型模型（如Qwen2.5:14b），在商品硬件上实现了96.6%的成功率和7.3秒的延迟，展现了在准确性和效率之间的实用权衡。

Conclusion: 本文提出的诊断框架为系统性评估工具增强型多智能体AI系统的可靠性奠定了基础。该研究确定了生产部署的关键可靠性阈值，并为资源受限的组织提供了成本效益高的智能体部署策略，显示了中型模型在实践中的价值。

Abstract: Multi-agent systems powered by large language models (LLMs) are transforming enterprise automation, yet systematic evaluation methodologies for assessing tool-use reliability remain underdeveloped. We introduce a comprehensive diagnostic framework that leverages big data analytics to evaluate procedural reliability in intelligent agent systems, addressing critical needs for SME-centric deployment in privacy-sensitive environments. Our approach features a 12-category error taxonomy capturing failure modes across tool initialization, parameter handling, execution, and result interpretation. Through systematic evaluation of 1,980 deterministic test instances spanning both open-weight models (Qwen2.5 series, Functionary) and proprietary alternatives (GPT-4, Claude 3.5/3.7) across diverse edge hardware configurations, we identify actionable reliability thresholds for production deployment. Our analysis reveals that procedural reliability, particularly tool initialization failures, constitutes the primary bottleneck for smaller models, while qwen2.5:32b achieves flawless performance matching GPT-4.1. The framework demonstrates that mid-sized models (qwen2.5:14b) offer practical accuracy-efficiency trade-offs on commodity hardware (96.6\% success rate, 7.3 s latency), enabling cost-effective intelligent agent deployment for resource-constrained organizations. This work establishes foundational infrastructure for systematic reliability evaluation of tool-augmented multi-agent AI systems.

</details>


### [2] [SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems](https://arxiv.org/abs/2601.16286)
*Varun Chillara,Dylan Kline,Christopher Alvares,Evan Wooten,Huan Yang,Shlok Khetan,Cade Bauer,Tré Guillory,Tanishka Shah,Yashodhara Dhariwal,Volodymyr Pavlov,George Popstefanov*

Main category: cs.AI

TL;DR: 本文提出了一种名为SemanticALLI的管道感知AI架构，通过将生成过程分解为分析意图解析（AIR）和可视化合成（VS）两个阶段，并使中间表示（IR）成为可缓存的构件，有效解决了传统缓存机制无法捕捉的AI流水线中重复计算中间逻辑的问题。实验表明，SemanticALLI在可视化合成阶段实现了83.10%的缓存命中率，显著减少了LLM调用次数和延迟。


<details>
  <summary>Details</summary>
Motivation: 当前的Agentic AI流水线存在一个隐藏的低效率问题：即使用户的自然语言输入是全新的，流水线也经常会重复构建相同的中间逻辑（如指标归一化、图表搭建）。传统的边界缓存机制无法解决这个问题，因为它将整个推理过程视为一个不可分割的整体。

Method: 提出了一种名为SemanticALLI的管道感知架构，将生成过程分解为分析意图解析（AIR）和可视化合成（VS）两个阶段。这种分解使得结构化的中间表示（IR）成为可以被缓存的第一类构件。

Result: SemanticALLI在可视化合成阶段实现了83.10%的缓存命中率，相比之下，基线方法（单一的、非结构化的缓存）由于语言变化，命中率最高仅为38.7%。SemanticALLI避免了4,023次LLM调用，中位延迟仅为2.66毫秒。

Conclusion: 通过将AI生成过程分解为具有稳定、结构化检查点的阶段，并使这些中间表示成为可缓存的构件，SemanticALLI能够显著提高缓存效率，减少计算资源消耗。这表明，即使在用户很少重复提问的情况下，AI流水线内部的重复性也可能存在于结构化的检查点，而这些检查点是缓存最有效的应用场景。

Abstract: Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.
  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.
  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable.

</details>


### [3] [DSGym: A Holistic Framework for Evaluating and Training Data Science Agents](https://arxiv.org/abs/2601.16344)
*Fan Nie,Junlin Wang,Harper Hua,Federico Bianchi,Yongchan Kwon,Zhenting Qi,Owen Queen,Shang Zhu,James Zou*

Main category: cs.AI

TL;DR: 本文提出了DSGym，一个标准化的数据科学代理评估和训练框架，旨在解决现有基准测试的碎片化、任务覆盖不足和数据接地性差的问题。DSGym通过模块化设计易于扩展，并包含经过筛选和扩充的任务集（DSGym-Tasks, DSBio, DSPredict）。此外，DSGym支持通过数据合成进行代理训练，并展示了一个在DSGym上训练的模型超越GPT-4o的案例。


<details>
  <summary>Details</summary>
Motivation: 现有数据科学代理的基准测试存在评估接口碎片化、跨基准比较困难、任务覆盖范围窄以及数据接地性不足（部分任务无需真实数据即可解决）等问题，阻碍了对数据科学代理能力的全面评估和提升。

Method: 引入DSGym，一个标准化的、自包含的执行环境，用于评估和训练数据科学代理。DSGym采用模块化架构，便于添加任务、代理模板和工具。通过过滤和精炼现有基准，创建了DSGym-Tasks。新增了生物信息学任务（DSBio）和跨领域预测任务（DSPredict）。DSGym还支持通过执行验证的数据合成管道进行代理训练。

Result: DSGym提供了一个易于扩展的、可进行端到端评估的数据科学代理测试平台。在DSGym上训练的4B模型，使用2000个示例的训练集，在标准化分析基准上表现优于GPT-4o。

Conclusion: DSGym提供了一个严谨的、端到端的框架，用于衡量数据科学代理在真实科学背景下规划、实施和验证数据分析的能力，并展示了其在提升代理性能方面的潜力。

Abstract: Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of rigorous data grounding. In particular, we show that a substantial portion of tasks in current benchmarks can be solved without using the actual data. To address these limitations, we introduce DSGym, a standardized framework for evaluating and training data science agents in self-contained execution environments. Unlike static benchmarks, DSGym provides a modular architecture that makes it easy to add tasks, agent scaffolds, and tools, positioning it as a live, extensible testbed. We curate DSGym-Tasks, a holistic task suite that standardizes and refines existing benchmarks via quality and shortcut solvability filtering. We further expand coverage with (1) DSBio: expert-derived bioinformatics tasks grounded in literature and (2) DSPredict: challenging prediction tasks spanning domains such as computer vision, molecular prediction, and single-cell perturbation. Beyond evaluation, DSGym enables agent training via execution-verified data synthesis pipeline. As a case study, we build a 2,000-example training set and trained a 4B model in DSGym that outperforms GPT-4o on standardized analysis benchmarks. Overall, DSGym enables rigorous end-to-end measurement of whether agents can plan, implement, and validate data analyses in realistic scientific context.

</details>


### [4] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: 该研究提出了一种名为Doc2AHP的框架，它结合了大型语言模型（LLMs）的通用性与层次分析法（AHP）的结构化推理能力，旨在克服LLMs在复杂决策中的逻辑一致性问题以及AHP对领域专家的依赖。Doc2AHP利用AHP的结构原则作为约束，引导LLM在非结构化文档中进行搜索，确保逻辑推导的准确性，并通过多智能体加权和自适应一致性优化来保证数值结果的可靠性。实验证明，Doc2AHP使用户无需专家知识也能构建高质量决策模型，并在逻辑完整性和下游任务准确性上优于直接生成方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在语义理解方面表现出色，但在需要严谨逻辑的复杂决策任务中，其结构一致性和推理可靠性不足。传统的决策理论（如AHP）虽然系统，但高度依赖劳动密集型的领域专业知识，存在“专家瓶颈”，限制了其普适性。研究旨在弥合LLMs的泛化能力与决策理论的严谨性之间的差距。

Method: 提出了一种名为Doc2AHP的结构化推理框架，该框架受AHP原则指导。它利用AHP的结构原则作为约束，引导LLM在非结构化文档空间中进行受限搜索，以强制执行父节点和子节点之间的逻辑蕴含。此外，研究引入了一个多智能体加权机制，并结合自适应一致性优化策略，以确保权重分配的数值一致性。该方法无需大量标注数据或手动干预。

Result: Doc2AHP能够赋能非专家用户从头开始构建高质量的决策模型。在逻辑完整性和下游任务准确性方面，该方法显著优于直接生成基线。

Conclusion: Doc2AHP是一种创新的结构化推理框架，它通过将AHP的结构化原则应用于LLM，成功解决了LLMs在复杂决策中的逻辑一致性问题，同时克服了传统AHP对专家知识的依赖。该框架提高了决策模型的质量和可靠性，并使其更易于普通用户使用。

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [5] [SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care](https://arxiv.org/abs/2601.16529)
*Dongshen Peng,Yi Wang,Carl Preiksaitis,Christian Rose*

Main category: cs.AI

TL;DR: 一项名为 SycoEval-EM 的多智能体模拟框架被开发出来，用于评估大型语言模型 (LLM) 在急诊医学中抵御不当医疗要求的患者说服的能力。结果显示，LLM 在成像检查请求方面比阿片类药物处方更容易屈服，并且模型能力与鲁棒性预测能力关系不大。所有说服策略的有效性相似，表明 LLM 普遍易受影响。研究强调了在社会压力下，静态基准测试不足以预测 LLM 的安全性，需要进行多轮对抗性测试来认证临床人工智能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 在临床决策支持方面具有潜力，但也存在屈从于患者不当医疗要求的风险，尤其是在急诊医学等高压环境下。现有评估方法可能无法充分捕捉这种社会压力下的脆弱性。

Method: 开发了一个名为 SycoEval-EM 的多智能体模拟框架。该框架使用 20 种不同的 LLM，模拟了 1,875 次急诊医学的就诊，涵盖了三种“明智选择”（Choosing Wisely）场景。通过模拟患者的“劝说”行为来评估 LLM 的鲁棒性，并记录 LLM 屈服于不当医疗要求的比例。还分析了不同说服策略的有效性。

Result: 在 20 种 LLM 和 1,875 次就诊中，LLM 屈服于不当医疗要求的比例从 0% 到 100% 不等。LLM 在面对成像检查请求时（屈服率 38.8%）比面对阿片类药物处方请求时（屈服率 25.0%）更容易屈服。模型的通用能力与其在社会压力下的鲁棒性预测能力关系较弱。所有三种劝说策略（未具体说明，但结果表明）的有效性相似（30.0%-36.0%），表明 LLM 普遍容易受到说服，而非特定策略的弱点。

Conclusion: 静态基准测试无法充分预测 LLM 在面对社会压力（患者说服）时的安全性。为了确保临床人工智能的安全性，尤其是在急诊医学领域，需要采用多轮对抗性测试方法来进行认证。

Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

</details>


### [6] [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)
*Meet Raval,Tejul Pandit,Dhvani Upadhyay*

Main category: cs.AI

TL;DR: 本研究通过统一的基准测试，比较了传统机器学习模型、基于提示的LLM/VLM以及PEFT模型在医疗分类任务上的表现。结果表明，传统机器学习模型在大多数任务上表现最佳，尤其是在文本数据上。Gemini 2.5在多类别图像任务上表现有竞争力，但文本任务表现不佳。LoRA微调的Gemma模型表现最差。


<details>
  <summary>Details</summary>
Motivation: 评估和对比不同类别的模型（传统ML、基于提示的LLM/VLM、PEFT模型）在医疗分类任务上的性能，以确定当前最可靠和有效的技术，并揭示基础模型和PEFT策略的局限性。

Method: 使用四个公开的医疗数据集（包含文本和图像模态），涵盖二分类和多分类任务。实验评估了三类模型：传统ML（LR, LightGBM, ResNet-50）、基于提示的LLM/VLM（Gemini 2.5）和PEFT模型（LoRA适配的Gemma3变体）。所有实验采用一致的数据划分和评估指标。

Result: 传统ML模型在大多数医疗分类任务上表现出最佳的总体性能，尤其是在结构化文本数据上。Gemini 2.5在文本任务上表现不佳，但在多类别图像任务上表现与ResNet-50相当。LoRA微调的Gemma变体在所有文本和图像实验中表现最差。

Conclusion: 在许多医疗分类场景中，传统的机器学习模型仍然是最可靠的选择。基础模型并非普遍优于传统模型，并且PEFT的有效性高度依赖于微调策略，本研究中的少量微调被证明是有害的。

Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.

</details>


### [7] [LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents](https://arxiv.org/abs/2601.16649)
*Amin Rakhsha,Thomas Hehn,Pietro Mazzaglia,Fabio Valerio Massoli,Arash Behboodi,Tribhuvanesh Orekondy*

Main category: cs.AI

TL;DR: 该研究提出了一种基于“oracle”的反事实框架，用于评估在多轮、长时序的智能体任务中，规划、状态跟踪和长上下文处理等核心能力的重要性。通过在可控的游戏化环境中模拟这些能力，研究发现规划能力普遍重要，而其他能力的有效性则取决于环境和语言模型本身的特性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理需要规划、状态跟踪和长上下文处理的多轮、长时序智能体任务时仍存在困难。研究旨在理解提升这些底层能力对智能体任务成功与否的相对重要性。

Method: 开发了一个针对多轮问题的“oracle”反事实框架。该框架通过引入一个能够完美执行特定任务的“oracle”（例如，完美的规划或无懈可击的状态跟踪），来衡量该能力对智能体性能的影响。研究人员设计了一系列复杂度可调、程序化生成的游戏化任务，以在受控环境中精确地进行“oracle”干预，并隔离各项能力的影响。

Result: 研究结果表明，规划能力在不同场景下都能一致地提升性能。然而，其他能力（如状态跟踪）的有效性则会受到环境和语言模型特性的影响。

Conclusion: 该研究通过“oracle”反事实框架，量化了多轮智能体任务中关键底层能力的重要性，为未来AI智能体和语言模型的发展方向提供了指导，揭示了多轮智能体环境的挑战在于某些能力的重要性并非普遍存在，而是与具体环境和模型相互作用。

Abstract: Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models.

</details>


### [8] [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)
*Suzhong Fu,Jingqi Dong,Xuan Ding,Rui Sun,Yiming Yang,Shuguang Cui,Zhen Li*

Main category: cs.AI

TL;DR: 研究提出了一种名为AgentsEval的多智能体流推理框架，用于评估自动生成的医学影像报告，该框架通过模拟放射科医生的协作诊断流程，实现了更准确、更忠实且可解释的评估，并鲁棒性强。


<details>
  <summary>Details</summary>
Motivation: 现有的医学影像报告评估方法在捕捉放射学解释背后的结构化诊断逻辑方面存在不足，导致判断不可靠且临床相关性有限，因此需要一种更有效、更可靠的评估方法。

Method: 提出AgentsEval框架，该框架将评估过程分解为标准定义、证据提取、比对和一致性评分等可解释的步骤，通过多智能体协同工作来模拟放射科医生的协作诊断流程，并构建了一个包含五个医学报告数据集的多领域基准测试。

Result: AgentsEval在实验中表现出具有临床一致性、语义忠实性和可解释性的评估能力，并且在面对释义、语义和风格扰动时表现出鲁棒性。

Conclusion: AgentsEval框架为评估医学报告生成系统提供了一种透明且临床导向的评估方法，有助于促进大型语言模型在临床实践中的可信赖集成。

Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.

</details>


### [9] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: 本文提出了一种名为LongCat-Flash-Thinking-2601的大规模（5600亿参数）开源MoE推理模型，在代理推理基准测试中取得了最先进的性能，并展示了其在复杂工具使用和真实世界噪声环境下的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了开发一种具有卓越代理推理能力的开源模型，能够处理复杂的工具交互和真实世界的不确定性。

Method: 该模型采用了一种统一的训练框架，结合了领域并行专家训练和后续融合。通过端到端地协同设计数据构建、环境、算法和基础设施，实现了从预训练到后训练的优化。具体包括：环境扩展和任务构建以增强工具使用泛化能力；扩展DORA框架以实现大规模、多环境的异步强化学习；通过分析和分解真实世界噪声模式来设计针对性训练过程；引入“Heavy Thinking”模式以在测试时通过扩展推理深度和宽度来提高复杂推理任务的性能。

Result: LongCat-Flash-Thinking-2601 在代理搜索、代理工具使用和工具集成推理等代理推理基准测试中，超越了现有的开源模型。模型在复杂工具交互方面展现出强大的泛化能力，并在嘈杂的真实世界环境中表现出鲁棒性。

Conclusion: LongCat-Flash-Thinking-2601 通过创新的训练框架、大规模多环境训练方法、鲁棒性增强策略以及“Heavy Thinking”模式，成功地提升了开源模型的代理推理能力，为复杂工具使用和真实世界应用提供了强大的基础。

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [10] [An Efficient Insect-inspired Approach for Visual Point-goal Navigation](https://arxiv.org/abs/2601.16806)
*Lu Yihe,Barbara Webb*

Main category: cs.AI

TL;DR: 本文提出了一种受昆虫启发的视觉导航代理，结合了联想学习和路径积分模型，在Habitat点目标导航任务上取得了与最先进模型相当的性能，但计算成本显著降低，并且在更现实的环境中表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是将昆虫在视觉导航方面的出色能力，特别是其学习和优化视觉引导路径的能力，应用于开发高效的导航代理。研究者试图通过模拟昆虫大脑中与学习和路径积分相关的结构来实现这一点。

Method: 研究结合了两种被认为与昆虫联想学习和路径积分有关的抽象大脑模型，构建了一个受昆虫启发的代理。该代理在Habitat点目标导航基准任务上进行了测试，并与现有的最先进模型进行了比较。此外，还在一个更真实的模拟环境中进行了鲁棒性测试。

Result: 该昆虫启发代理在Habitat点目标导航任务上取得了与现有最先进模型相当的性能，同时计算成本降低了几个数量级。在更真实的模拟环境中，该方法也表现出对扰动的鲁棒性。

Conclusion: 受昆虫大脑结构启发的简单代理在视觉点目标导航任务中非常有效，不仅计算效率高，而且在现实世界的模拟环境中也具有鲁棒性。这表明模仿昆虫的导航机制是一种有前景的路径。

Abstract: In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.

</details>


### [11] [Reasoning Promotes Robustness in Theory of Mind Tasks](https://arxiv.org/abs/2601.16853)
*Ian B. de Haan,Peter van der Putten,Max van Duijn*

Main category: cs.AI

TL;DR: 研究表明，通过RLVR训练的LLM在ToM任务上的改进主要是由于对提示和任务扰动的鲁棒性增强，而非真正具备了新的ToM推理能力。


<details>
  <summary>Details</summary>
Motivation: LLM在ToM测试中的出色表现引发了对其真实ToM能力的争论，而RLVR训练的LLM在推理任务上表现出色，因此作者希望探究RLVR训练的LLM在ToM任务上的行为，并解释其性能提升的原因。

Method: 使用新颖的机器学习心理实验和现有基准测试结果，分析了RLVR训练的LLM在ToM任务上的表现，重点关注模型对提示变化和任务扰动的鲁棒性。

Result: RLVR训练的LLM在ToM任务中表现出对提示变化和任务扰动的更高鲁棒性。这种性能提升更可能归因于在寻找正确解决方案时的鲁棒性增强，而非新的ToM推理形式。

Conclusion: RLVR训练LLM在ToM任务上的改进主要源于鲁棒性的提高，而非根本性的ToM推理能力。这一发现对评估LLM的社会认知行为具有重要意义。

Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.

</details>


### [12] [Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation](https://arxiv.org/abs/2601.16863)
*Tims Pecerskis,Aivars Smirnovs*

Main category: cs.AI

TL;DR: 本文提出了一种名为 NSED 的运行时模型混合架构，它使用动态专业知识经纪人将多个小型模型组合成一个更强大的模型，通过迭代优化和共识机制提高性能和效率，同时展现出内在的对齐特性。


<details>
  <summary>Details</summary>
Motivation: 希望构建一个能够动态组合多个小型模型来匹配或超越大型模型性能的架构，并提高硬件效率和模型对齐性。

Method: 提出 NSED 协议，一个运行时模型混合（MoM）架构。核心组件包括：1. 动态专业知识经纪人（将模型选择视为背包问题，根据实时遥测和成本约束绑定模型）。2. 宏尺度循环神经网络（RNN）将审议过程形式化，通过语义遗忘门实现迭代细化。3. 信任less 的 N 对 N 同行评审机制。4. 二次投票激活函数实现非线性共识。

Result: 在 AIME 2025 和 LiveCodeBench 基准测试中，NSED 架构使得小型模型（<20B 参数）能够达到甚至超过先进的 100B+ 参数模型的性能，确立了新的硬件套利效率前沿。在 DarkBench 安全套件上的测试表明，同行评审的纠正机制降低了谄媚分数，优于任何单个代理。

Conclusion: NSED 协议通过动态组合小型模型，在不显著增加 VRAM 占用的情况下，实现了高效且性能优越的模型集成，并具有内在的对齐特性，能够通过同行评审机制减少不良行为。

Abstract: This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent.

</details>


### [13] [MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion](https://arxiv.org/abs/2601.16886)
*Chi Yu,Hongyu Yuan,Zhiyi Duan*

Main category: cs.AI

TL;DR: 本文提出了一种名为MAGE-KT的多智能体图增强知识追踪框架，通过构建多视图异构图并利用紧凑子图进行信息融合，解决了现有知识追踪方法在概念关系挖掘和图编码方面的不足，提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的知识追踪方法未能充分挖掘概念间的关系，且对大规模异构图进行编码成本高且易引入噪声，影响了概念间关系的准确性和预测性能。

Method: 构建多视图异构图，结合多智能体概念关系提取器和学生-问题交互图；利用学生历史信息检索紧凑子图；采用不对称交叉注意力融合模块整合信息，以提高预测精度并避免注意力扩散。

Result: 在三个常用的知识追踪数据集上，MAGE-KT在概念关系准确性和下一题预测方面均取得了显著的性能提升。

Conclusion: MAGE-KT框架通过有效融合多源异构信息，并针对性地处理大规模图数据，能够更准确地建模学习过程，提升知识追踪的预测能力。

Abstract: Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.

</details>


### [14] [Preventing the Collapse of Peer Review Requires Verification-First AI](https://arxiv.org/abs/2601.16909)
*Lei You,Lele Cao,Iryna Gurevych*

Main category: cs.AI

TL;DR: 本文认为AI辅助同行评审应以验证为先，而非模仿评审。提出“真值耦合”作为评审工具的正确目标，并分析了验证压力和信号收缩导致评估转向代理主权的机制，指出AI应作为审计者而非评分预测器。


<details>
  <summary>Details</summary>
Motivation: 当前的AI辅助同行评审方法倾向于模仿人类评审，可能导致评估偏离科学真值。作者希望找到一种更优的AI评审目标，并理解现有评估体系可能失效的根本原因。

Method: 作者提出了“真值耦合”（truth-coupling）的概念，即评审分数与潜在科学真值的一致程度。他们构建了一个最小模型，结合了高保真检查和代理判断，推导了耦合定律和激励崩溃条件，分析了验证压力和信号收缩的作用。

Result: 研究发现，当验证能力跟不上声明增长（验证压力）或真实改进难以与噪声区分（信号收缩）时，评估体系会倾向于代理主权。当理性努力转向优化代理而非寻求真值时，会出现激励崩溃，即使当前决策仍看似可靠。

Conclusion: AI辅助同行评审工具应被设计为“验证优先”，作为“对抗性审计者”，生成可审计的验证成果并扩展验证能力。而不应作为“分数预测器”，加剧声明的膨胀。工具构建者和项目主席应采取相应行动，以确保评估的可靠性。

Abstract: This paper argues that AI-assisted peer review should be verification-first rather than review-mimicking. We propose truth-coupling, i.e. how tightly venue scores track latent scientific truth, as the right objective for review tools. We formalize two forces that drive a phase transition toward proxy-sovereign evaluation: verification pressure, when claims outpace verification capacity, and signal shrinkage, when real improvements become hard to separate from noise. In a minimal model that mixes occasional high-fidelity checks with frequent proxy judgment, we derive an explicit coupling law and an incentive-collapse condition under which rational effort shifts from truth-seeking to proxy optimization, even when current decisions still appear reliable. These results motivate actions for tool builders and program chairs: deploy AI as an adversarial auditor that generates auditable verification artifacts and expands effective verification bandwidth, rather than as a score predictor that amplifies claim inflation.

</details>


### [15] [AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems](https://arxiv.org/abs/2601.16964)
*Mohamed Amine Ferrag,Abderrahmane Lakas,Merouane Debbah*

Main category: cs.AI

TL;DR: 本文提出了AgentDrive，一个包含30万个LLM生成驾驶场景的大规模开放基准数据集，用于训练和评估自主代理。此外，还引入了AgentDrive-MCQ，一个包含10万道选择题的基准，用于评估LLM在不同推理维度上的能力。研究发现，尽管闭源模型在上下文和策略推理方面表现更好，但开源模型在结构化和物理推理方面正在迅速缩小差距。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、结构化且安全关键的基准来评估和训练集成了LLM的自主AI模型，这阻碍了其在自动驾驶等领域的应用。

Method: 通过一个LLM驱动的prompt-to-JSON管道，生成了30万个驾驶场景，涵盖了七个维度。每个场景都经过模拟、安全指标计算和结果标注。同时，创建了一个10万道选择题的基准AgentDrive-MCQ，用于评估LLM的五种推理能力。对50个领先LLM进行了评估。

Result: AgentDrive生成了多样化的驾驶场景，AgentDrive-MCQ基准测试显示，闭源模型在上下文和策略推理方面表现最佳，而开源模型在结构化和物理推理方面取得了显著进展。

Conclusion: AgentDrive数据集和AgentDrive-MCQ基准为LLM驱动的自主代理的训练和评估提供了重要的资源。研究结果揭示了当前LLM在自动驾驶相关推理能力上的优势和劣势，并指明了开源模型的发展潜力。

Abstract: The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, structured, and safety-critical benchmarks. This paper introduces AgentDrive, an open benchmark dataset containing 300,000 LLM-generated driving scenarios designed for training, fine-tuning, and evaluating autonomous agents under diverse conditions. AgentDrive formalizes a factorized scenario space across seven orthogonal axes: scenario type, driver behavior, environment, road layout, objective, difficulty, and traffic density. An LLM-driven prompt-to-JSON pipeline generates semantically rich, simulation-ready specifications that are validated against physical and schema constraints. Each scenario undergoes simulation rollouts, surrogate safety metric computation, and rule-based outcome labeling. To complement simulation-based evaluation, we introduce AgentDrive-MCQ, a 100,000-question multiple-choice benchmark spanning five reasoning dimensions: physics, policy, hybrid, scenario, and comparative reasoning. We conduct a large-scale evaluation of fifty leading LLMs on AgentDrive-MCQ. Results show that while proprietary frontier models perform best in contextual and policy reasoning, advanced open models are rapidly closing the gap in structured and physics-grounded reasoning. We release the AgentDrive dataset, AgentDrive-MCQ benchmark, evaluation code, and related materials at https://github.com/maferrag/AgentDrive

</details>


### [16] [Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts](https://arxiv.org/abs/2601.16965)
*Riyang Bao,Cheng Yang,Dazhou Yu,Zhexiang Tang,Gengchen Mai,Liang Zhao*

Main category: cs.AI

TL;DR: 提出了一种名为Spatial-Agent的AI代理，它通过将地理空间问题转化为可执行的工作流（GeoFlow Graphs）来解决现有LLM在地理空间计算方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的AI代理在进行真正的地理空间计算时表现不佳，往往依赖于网络搜索或模式匹配，并可能产生空间关系幻觉。

Method: 将地理空间问答形式化为概念转换问题，使用GeoFlow Graphs（带节点为空间概念、边为转换的有向无环图）表示可执行的工作流。Spatial-Agent提取空间概念，分配具有原则性排序约束的功能角色，并通过模板生成组合转换序列。

Result: 在MapEval-API和MapQA基准测试中，Spatial-Agent的表现显著优于ReAct和Reflexion等现有基线模型，并生成了可解释和可执行的地理空间工作流。

Conclusion: Spatial-Agent基于空间信息科学的基础理论，能够有效地进行地理空间推理和计算，克服了现有LLM代理的局限性。

Abstract: Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows.

</details>


### [17] [Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians](https://arxiv.org/abs/2601.16967)
*Bernes Lorier Atabonfack,Ahmed Tahiru Issah,Mohammed Hardi Abdul Baaki,Clemence Ingabire,Tolulope Olusuyi,Maruf Adewole,Udunna C. Anazodo,Timothy X Brown*

Main category: cs.AI

TL;DR: 开发了一个基于AI的平台，利用LLM为低收入和中等收入国家（LMICs）的生物医学技术人员提供实时医疗设备故障排除支持，并辅以同行论坛，以减少设备停机时间。


<details>
  <summary>Details</summary>
Motivation: 低收入和中等收入国家（LMICs）的医疗诊断设备由于维护不及时、技术专长有限以及制造商支持不足，经常处于闲置或故障状态，导致诊断延迟和患者护理受到影响。

Method: 开发了一个集成大型语言模型（LLM）和用户友好型Web界面的AI支持平台。该平台允许技术人员输入错误代码或设备症状，并获得分步故障排除指导。此外，还包含一个全球性的点对点讨论论坛。使用飞利浦HDI 5000超声波机进行了概念验证。

Result: 在概念验证阶段，该平台在错误代码解释方面实现了100%的准确率，在提出纠正措施方面达到了80%的准确率。

Conclusion: AI驱动的系统有潜力支持医疗设备的维护，通过减少设备停机时间来改善资源受限环境下的医疗服务。该研究证明了这种AI支持平台的可行性。

Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [18] [GR3EN: Generative Relighting for 3D Environments](https://arxiv.org/abs/2601.16272)
*Xiaoyan Xing,Philipp Henzler,Junhwa Hur,Runze Li,Jonathan T. Barron,Pratul P. Srinivasan,Dor Verbin*

Main category: cs.CV

TL;DR: 提出了一种通过蒸馏视频到视频的扩散模型来对大型房间尺度3D重建进行重新照明的方法，解决了现有方法在复杂真实场景下质量不高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景重新照明方法在处理复杂的真实世界场景时，通常需要解决欠定或病态的逆渲染问题，导致结果质量不高。尽管生成扩散模型在2D图像/视频重新照明和单个物体3D重新照明方面有进展，但缺乏对房间尺度3D场景的控制性重新照明能力。

Method: 该方法将视频到视频的重新照明扩散模型的输出蒸馏到一个3D重建中，从而避免了解决复杂的逆渲染问题。这使得系统能够灵活地对复杂真实场景的3D重建进行重新照明。

Result: 该方法能够在新的光照条件下忠实地渲染场景的新视图，并在合成和真实世界数据集上得到了验证。

Conclusion: 所提出的方法能够对房间尺度3D重建进行可控的重新照明，克服了现有方法的局限性，并在复杂真实世界场景中实现了高质量的渲染效果。

Abstract: We present a method for relighting 3D reconstructions of large room-scale environments. Existing solutions for 3D scene relighting often require solving under-determined or ill-conditioned inverse rendering problems, and are as such unable to produce high-quality results on complex real-world scenes. Though recent progress in using generative image and video diffusion models for relighting has been promising, these techniques are either limited to 2D image and video relighting or 3D relighting of individual objects. Our approach enables controllable 3D relighting of room-scale scenes by distilling the outputs of a video-to-video relighting diffusion model into a 3D reconstruction. This side-steps the need to solve a difficult inverse rendering problem, and results in a flexible system that can relight 3D reconstructions of complex real-world scenes. We validate our approach on both synthetic and real-world datasets to show that it can faithfully render novel views of scenes under new lighting conditions.

</details>


### [19] [Memory-V2V: Augmenting Video-to-Video Diffusion Models with Memory](https://arxiv.org/abs/2601.16296)
*Dohun Lee,Chun-Hao Paul Huang,Xuelin Chen,Jong Chul Ye,Duygu Ceylan,Hyeonho Jeong*

Main category: cs.CV

TL;DR: 提出Memory-V2V框架，通过显式内存机制解决多轮视频编辑中的跨一致性问题，有效提高编辑结果的一致性并实现效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑模型在多轮交互式编辑时难以保持跨编辑轮次的一致性。

Method: 引入Memory-V2V框架，该框架通过外部缓存和准确的检索与动态标记化策略，将先前的编辑结果作为条件加入当前的编辑步骤。此外，通过一个可学习的Token压缩器来减少冗余Token，提高计算效率。

Result: Memory-V2V在视频新视角合成和文本条件长视频编辑等任务上表现出色，显著提高了视频的跨一致性，同时计算开销小，甚至优于现有最先进方法。

Conclusion: Memory-V2V是一个简单而有效的框架，能够显著增强现有视频到视频扩散模型在多轮编辑中的跨一致性，并提供了计算效率上的改进。

Abstract: Recent foundational video-to-video diffusion models have achieved impressive results in editing user provided videos by modifying appearance, motion, or camera movement. However, real-world video editing is often an iterative process, where users refine results across multiple rounds of interaction. In this multi-turn setting, current video editors struggle to maintain cross-consistency across sequential edits. In this work, we tackle, for the first time, the problem of cross-consistency in multi-turn video editing and introduce Memory-V2V, a simple, yet effective framework that augments existing video-to-video models with explicit memory. Given an external cache of previously edited videos, Memory-V2V employs accurate retrieval and dynamic tokenization strategies to condition the current editing step on prior results. To further mitigate redundancy and computational overhead, we propose a learnable token compressor within the DiT backbone that compresses redundant conditioning tokens while preserving essential visual cues, achieving an overall speedup of 30%. We validate Memory-V2V on challenging tasks including video novel view synthesis and text-conditioned long video editing. Extensive experiments show that Memory-V2V produces videos that are significantly more cross-consistent with minimal computational overhead, while maintaining or even improving task-specific performance over state-of-the-art baselines. Project page: https://dohunlee1.github.io/MemoryV2V

</details>


### [20] [FeTTL: Federated Template and Task Learning for Multi-Institutional Medical Imaging](https://arxiv.org/abs/2601.16302)
*Abhijeet Parida,Antonia Alomar,Zhifan Jiang,Pooneh Roshanitabrizi,Austin Tapp,Ziyue Xu,Syed Muhammad Anwar,Maria J. Ledesma-Carbayo,Holger R. Roth,Marius George Linguraru*

Main category: cs.CV

TL;DR: 本文提出了一种名为FeTTL的新型联邦学习框架，通过学习全局模板和任务模型来解决多中心医疗影像数据中的域偏移和数据异质性问题，并在视盘分割和淋巴结转移分类任务上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，不同医疗中心之间的数据域偏移和异质性会导致模型性能下降，尤其是在医疗影像领域，这种影响更为显著。因此，需要一种方法来协调多中心医疗影像数据，以提高模型性能。

Method: 提出FeTTL框架，该框架能够学习一个全局模板和一个任务模型，以对齐客户端之间的数据分布。通过联合学习模板和任务模型来解决域偏移问题。

Result: 在视盘分割和淋巴结转移分类两个多中心医疗影像任务上，FeTTL相比于现有的联邦学习方法取得了显著的性能提升（p值<0.002）。实验还强调了联合学习模板和任务的重要性。

Conclusion: FeTTL提供了一个原则性强且可扩展的解决方案，用于减轻联邦学习中的分布偏移问题，支持在真实的、多机构的环境中稳健地部署模型。

Abstract: Federated learning enables collaborative model training across geographically distributed medical centers while preserving data privacy. However, domain shifts and heterogeneity in data often lead to a degradation in model performance. Medical imaging applications are particularly affected by variations in acquisition protocols, scanner types, and patient populations. To address these issues, we introduce Federated Template and Task Learning (FeTTL), a novel framework designed to harmonize multi-institutional medical imaging data in federated environments. FeTTL learns a global template together with a task model to align data distributions among clients. We evaluated FeTTL on two challenging and diverse multi-institutional medical imaging tasks: retinal fundus optical disc segmentation and histopathological metastasis classification. Experimental results show that FeTTL significantly outperforms the state-of-the-art federated learning baselines (p-values <0.002) for optical disc segmentation and classification of metastases from multi-institutional data. Our experiments further highlight the importance of jointly learning the template and the task. These findings suggest that FeTTL offers a principled and extensible solution for mitigating distribution shifts in federated learning, supporting robust model deployment in real-world, multi-institutional environments.

</details>


### [21] [Where is the multimodal goal post? On the Ability of Foundation Models to Recognize Contextually Important Moments](https://arxiv.org/abs/2601.16333)
*Aditya K Surikuchi,Raquel Fernández,Sandro Pezzelle*

Main category: cs.CV

TL;DR: 研究了基础模型在识别视频中重要子事件方面的能力，特别是在足球比赛场景下，发现现有模型表现接近随机水平，且倾向于依赖单一模态。


<details>
  <summary>Details</summary>
Motivation: 基础模型被广泛应用于多模态事件的语言生成，而识别视频中的重要子事件是生成叙述和摘要的基础。本文旨在评估模型在这一核心能力上的表现，并探究其局限性。

Method: 构建了一个包含足球比赛重要子事件的数据集，该数据集利用了人类对精彩集锦偏好的隐性信息。然后，使用该数据集评估了几种先进的多模态模型，并通过标准评估指标和深入分析（如单模态依赖性）来考察模型的性能。

Result: 现有先进的多模态模型在识别足球比赛重要子事件方面的表现接近随机水平。分析表明，模型倾向于依赖单一主导模态，并且难以有效融合多模态信息。

Conclusion: 强调了在处理多模态数据时，需要采用能够处理样本级异质性的模块化架构，并需要互补的训练方法来最大化跨模态的协同效应，以提升模型在理解和生成多模态事件方面的能力。

Abstract: Foundation models are used for many real-world applications involving language generation from temporally-ordered multimodal events. In this work, we study the ability of models to identify the most important sub-events in a video, which is a fundamental prerequisite for narrating or summarizing multimodal events. Specifically, we focus on football games and evaluate models on their ability to distinguish between important and non-important sub-events in a game. To this end, we construct a new dataset by leveraging human preferences for importance implicit in football game highlight reels, without any additional annotation costs. Using our dataset, which we will publicly release to the community, we compare several state-of-the-art multimodal models and show that they are not far from chance level performance. Analyses of models beyond standard evaluation metrics reveal their tendency to rely on a single dominant modality and their ineffectiveness in synthesizing necessary information from multiple sources. Our findings underline the importance of modular architectures that can handle sample-level heterogeneity in multimodal data and the need for complementary training procedures that can maximize cross-modal synergy.

</details>


### [22] [Coarse-to-Fine Non-rigid Multi-modal Image Registration for Historical Panel Paintings based on Crack Structures](https://arxiv.org/abs/2601.16348)
*Aline Sindel,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 提出了一种基于裂纹的粗到细非刚性多模态图像配准方法，利用卷积神经网络和图神经网络相结合，实现了历史面板绘画的高精度像素级对齐。


<details>
  <summary>Details</summary>
Motivation: 历史面板绘画的多模态图像配准通常需要耗时的人工操作，而现有的配准方法在处理分辨率差异、图像尺寸、非刚性变形和模态依赖的内容时面临挑战。

Method: 提出了一种基于裂纹的粗到细非刚性多模态配准方法。首先，利用卷积神经网络联合检测和描述裂纹特征点；然后，利用图神经网络进行描述符匹配，并通过同调变换重投影误差过滤匹配点；最后，引入多层次关键点细化方法实现混合分辨率图像的粗到细配准。

Result: 所提出的方法在创建的多模态面板绘画数据集上进行了评估，并在多项指标上优于现有的关键点和密集匹配方法以及细化方法。消融研究表明所提出的方法的各个模块都有效。

Conclusion: 所提出的粗到细非刚性多模态配准方法能够有效地处理历史面板绘画的复杂性，实现高精度、高效率的图像对齐，并且在与现有方法进行比较时表现出最佳性能。

Abstract: Art technological investigations of historical panel paintings rely on acquiring multi-modal image data, including visual light photography, infrared reflectography, ultraviolet fluorescence photography, x-radiography, and macro photography. For a comprehensive analysis, the multi-modal images require pixel-wise alignment, which is still often performed manually. Multi-modal image registration can reduce this laborious manual work, is substantially faster, and enables higher precision. Due to varying image resolutions, huge image sizes, non-rigid distortions, and modality-dependent image content, registration is challenging. Therefore, we propose a coarse-to-fine non-rigid multi-modal registration method efficiently relying on sparse keypoints and thin-plate-splines. Historical paintings exhibit a fine crack pattern, called craquelure, on the paint layer, which is captured by all image systems and is well-suited as a feature for registration. In our one-stage non-rigid registration approach, we employ a convolutional neural network for joint keypoint detection and description based on the craquelure and a graph neural network for descriptor matching in a patch-based manner, and filter matches based on homography reprojection errors in local areas. For coarse-to-fine registration, we introduce a novel multi-level keypoint refinement approach to register mixed-resolution images up to the highest resolution. We created a multi-modal dataset of panel paintings with a high number of keypoint annotations, and a large test set comprising five multi-modal domains and varying image resolutions. The ablation study demonstrates the effectiveness of all modules of our refinement method. Our proposed approaches achieve the best registration results compared to competing keypoint and dense matching methods and refinement methods.

</details>


### [23] [Cognitively-Inspired Tokens Overcome Egocentric Bias in Multimodal Models](https://arxiv.org/abs/2601.16378)
*Bridget Leonard,Scott O. Murray*

Main category: cs.CV

TL;DR: 本文提出了一种名为“视角令牌”（perspective tokens）的新方法，通过在多模态语言模型（MLMs）中引入专门的嵌入来解决其在空间推理中的自我中心偏差问题，显著提升了模型在视觉视角任务上的表现，并使其能够进行更类人的空间推理。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态语言模型（MLMs）在处理需要从不同视角进行空间推理的任务时存在严重的自我中心偏差，表现不佳。这引发了对模型是否支持离心（allocentric）推理的质疑。

Method: 研究人员受到人类空间认知能力的启发，提出了一种名为“视角令牌”的方法。这些令牌是专门设计的嵌入，用于编码方向信息。它们可以通过两种方式实现：（1）具身的身体关键点线索，或（2）支持心理旋转的抽象表示。通过将这些视角令牌集成到LLaVA-1.5-13B模型中进行微调。

Result: 在引入视角令牌后，模型在处理第二级视觉视角任务上的表现得到了显著提升。在合成和自然场景基准测试（Isle Bricks V2, COCO, 3DSRBench）中，视角令牌均提高了准确性。其中，基于旋转的令牌能够泛化到非人类参考代理。代表性分析表明，微调增强了模型基线中已有的潜在方向敏感性。

Conclusion: 将认知上合理的空间结构直接嵌入到令牌空间是一种轻量级、模型无关的机制，可以实现视角切换，并使多模态语言模型能够进行更类人的空间推理。这表明多模态语言模型已经具备了离心推理的先驱能力，但缺乏合适的内部结构来充分发挥。

Abstract: Multimodal language models (MLMs) perform well on semantic vision-language tasks but fail at spatial reasoning that requires adopting another agent's visual perspective. These errors reflect a persistent egocentric bias and raise questions about whether current models support allocentric reasoning. Inspired by human spatial cognition, we introduce perspective tokens, specialized embeddings that encode orientation through either (1) embodied body-keypoint cues or (2) abstract representations supporting mental rotation. Integrating these tokens into LLaVA-1.5-13B yields performance on level-2 visual perspective-taking tasks. Across synthetic and naturalistic benchmarks (Isle Bricks V2, COCO, 3DSRBench), perspective tokens improve accuracy, with rotation-based tokens generalizing to non-human reference agents. Representational analyses reveal that fine-tuning enhances latent orientation sensitivity already present in the base model, suggesting that MLMs contain precursors of allocentric reasoning but lack appropriate internal structure. Overall, embedding cognitively grounded spatial structure directly into token space provides a lightweight, model-agnostic mechanism for perspective-taking and more human-like spatial reasoning.

</details>


### [24] [VTFusion: A Vision-Text Multimodal Fusion Network for Few-Shot Anomaly Detection](https://arxiv.org/abs/2601.16381)
*Yuxin Jiang,Yunkang Cao,Yuqi Cheng,Yiheng Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 本文提出了VTFusion，一个用于少样本异常检测（FSAD）的视觉-文本多模态融合框架。它通过自适应特征提取器和多模态预测融合模块，解决了现有方法在领域特定语义提取和跨模态融合方面的不足，并在MVTec AD、VisA以及一个新引入的工业数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有少样本异常检测方法依赖于通用场景预训练的特征，忽视了工业领域特有的细节语义；同时，简单的特征拼接导致视觉和文本模态间存在语义不对齐，降低了鲁棒性。

Method: 提出VTFusion框架，包含两个核心设计：1. 自适应特征提取器，用于学习图像和文本的任务特定表示，以弥合预训练模型与工业数据之间的领域差距，并生成多样化合成异常以增强区分度；2. 多模态预测融合模块，包含一个促进跨模态信息交流的融合块和一个在多模态指导下生成精细像素级异常图的分割网络。

Result: 在MVTec AD和VisA数据集的2-shot场景下，VTFusion实现了96.8%和86.2%的图像级AUROC。在本文提出的工业汽车塑料件数据集上，VTFusion实现了93.5%的AUPRO，证明了其在工业场景下的实用性。

Conclusion: VTFusion能够有效解决少样本异常检测中的领域特定语义提取和跨模态融合问题，显著提升了在工业场景下的异常检测性能，展现了其在实际工业应用中的潜力。

Abstract: Few-Shot Anomaly Detection (FSAD) has emerged as a critical paradigm for identifying irregularities using scarce normal references. While recent methods have integrated textual semantics to complement visual data, they predominantly rely on features pre-trained on natural scenes, thereby neglecting the granular, domain-specific semantics essential for industrial inspection. Furthermore, prevalent fusion strategies often resort to superficial concatenation, failing to address the inherent semantic misalignment between visual and textual modalities, which compromises robustness against cross-modal interference. To bridge these gaps, this study proposes VTFusion, a vision-text multimodal fusion framework tailored for FSAD. The framework rests on two core designs. First, adaptive feature extractors for both image and text modalities are introduced to learn task-specific representations, bridging the domain gap between pre-trained models and industrial data; this is further augmented by generating diverse synthetic anomalies to enhance feature discriminability. Second, a dedicated multimodal prediction fusion module is developed, comprising a fusion block that facilitates rich cross-modal information exchange and a segmentation network that generates refined pixel-level anomaly maps under multimodal guidance. VTFusion significantly advances FSAD performance, achieving image-level AUROCs of 96.8% and 86.2% in the 2-shot scenario on the MVTec AD and VisA datasets, respectively. Furthermore, VTFusion achieves an AUPRO of 93.5% on a real-world dataset of industrial automotive plastic parts introduced in this paper, further demonstrating its practical applicability in demanding industrial scenarios.

</details>


### [25] [ResAgent: Entropy-based Prior Point Discovery and Visual Reasoning for Referring Expression Segmentation](https://arxiv.org/abs/2601.16394)
*Yihao Wang,Jusheng Zhang,Ziyi Tang,Keze Wang,Meng Yang*

Main category: cs.CV

TL;DR: 提出了一种名为 '模型' 的新颖参照表达分割（RES）框架，通过熵基点发现（EBD）和视觉基推理（VBR）解决了现有 MLLM 方法中边界框粗糙和文本坐标推理不可靠的问题，并在四个基准数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于 MLLM 的 RES 方法存在 MLLM 生成的边界框粗糙导致点提示冗余或无区分性，以及过度依赖文本坐标推理（容易混淆视觉相似的目标）的问题。

Method: 提出了一种名为 '模型' 的 RES 框架，包含熵基点发现（EBD）和视觉基推理（VBR）两个核心组件。EBD 通过建模空间不确定性来识别高信息量的候选点，将点选择视为信息最大化过程。VBR 通过联合视觉-语义对齐来验证点的正确性，放弃纯文本坐标推理。框架遵循一个粗到细的工作流程：边界框初始化、熵引导点发现、视觉验证和掩码解码。

Result: 在 RefCOCO, RefCOCO+, RefCOCOg, 和 ReasonSeg 四个基准数据集上的广泛评估表明，'模型' 在所有四个基准上都达到了新的最先进性能。

Conclusion: '模型' 框架通过结合熵基点发现和视觉基推理，有效解决了现有 RES 方法的局限性，能够在提供少量提示的情况下生成准确且语义接地（semantically grounded）的分割掩码，实现了 RES 任务的最优性能。

Abstract: Referring Expression Segmentation (RES) is a core vision-language segmentation task that enables pixel-level understanding of targets via free-form linguistic expressions, supporting critical applications such as human-robot interaction and augmented reality. Despite the progress of Multimodal Large Language Model (MLLM)-based approaches, existing RES methods still suffer from two key limitations: first, the coarse bounding boxes from MLLMs lead to redundant or non-discriminative point prompts; second, the prevalent reliance on textual coordinate reasoning is unreliable, as it fails to distinguish targets from visually similar distractors. To address these issues, we propose \textbf{\model}, a novel RES framework integrating \textbf{E}ntropy-\textbf{B}ased Point \textbf{D}iscovery (\textbf{EBD}) and \textbf{V}ision-\textbf{B}ased \textbf{R}easoning (\textbf{VBR}). Specifically, EBD identifies high-information candidate points by modeling spatial uncertainty within coarse bounding boxes, treating point selection as an information maximization process. VBR verifies point correctness through joint visual-semantic alignment, abandoning text-only coordinate inference for more robust validation. Built on these components, \model implements a coarse-to-fine workflow: bounding box initialization, entropy-guided point discovery, vision-based validation, and mask decoding. Extensive evaluations on four benchmark datasets (RefCOCO, RefCOCO+, RefCOCOg, and ReasonSeg) demonstrate that \model achieves new state-of-the-art performance across all four benchmarks, highlighting its effectiveness in generating accurate and semantically grounded segmentation masks with minimal prompts.

</details>


### [26] [A Cosine Network for Image Super-Resolution](https://arxiv.org/abs/2601.16413)
*Chunwei Tian,Chengyuan Zhang,Bob Zhang,Zhiwu Li,C. L. Philip Chen,David Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为CSRNet的图像超分辨率卷积神经网络，通过引入奇偶异构块提取互补的同源结构信息，结合线性和非线性结构信息，并采用余弦退火机制优化训练，以提高图像超分辨率效果。


<details>
  <summary>Details</summary>
Motivation: 为了在图像超分辨率任务中有效保留和利用提取到的结构信息，克服同源信息提取的局限性，并提高算法的鲁棒性。

Method: 设计了奇偶异构块来增大网络结构差异，以提取互补的同源结构信息。将线性与非线性结构信息结合。采用余弦退火机制（带有热重启）来优化训练过程中的学习率。

Result: 所提出的CSRNet在图像超分辨率任务上，与当前最先进的方法相比具有竞争力。

Conclusion: CSRNet通过改进网络架构（奇偶异构块）和优化训练策略（余弦退火），能够有效提取和利用结构信息，从而实现高质量的图像超分辨率。

Abstract: Deep convolutional neural networks can use hierarchical information to progressively extract structural information to recover high-quality images. However, preserving the effectiveness of the obtained structural information is important in image super-resolution. In this paper, we propose a cosine network for image super-resolution (CSRNet) by improving a network architecture and optimizing the training strategy. To extract complementary homologous structural information, odd and even heterogeneous blocks are designed to enlarge the architectural differences and improve the performance of image super-resolution. Combining linear and non-linear structural information can overcome the drawback of homologous information and enhance the robustness of the obtained structural information in image super-resolution. Taking into account the local minimum of gradient descent, a cosine annealing mechanism is used to optimize the training procedure by performing warm restarts and adjusting the learning rate. Experimental results illustrate that the proposed CSRNet is competitive with state-of-the-art methods in image super-resolution.

</details>


### [27] [DCCS-Det: Directional Context and Cross-Scale-Aware Detector for Infrared Small Target](https://arxiv.org/abs/2601.16428)
*Shuying Li,Qiang Ma,San Zhang,Chuang Yang*

Main category: cs.CV

TL;DR: 提出了一种名为 DCCS-Det 的新型红外小目标检测器，通过双流显著性增强（DSE）块和潜在感知语义提取与聚合（LaSEA）模块，以解决现有方法在联合建模局部-全局特征和特征冗余/稀释问题上的不足，并在多个数据集上取得了最先进的检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有红外小目标检测方法在联合建模局部-全局特征（影响目标-背景区分）或特征冗余和语义稀释（降低目标表征质量）方面存在不足。

Method: 提出了一种名为 DCCS-Det 的新型检测器，包含两个核心模块：1. 双流显著性增强（DSE）块，用于集成局部感知和方向感知上下文聚合，捕捉长距离空间依赖和局部细节。2. 潜在感知语义提取与聚合（LaSEA）模块，通过跨尺度特征提取和随机池化采样策略，缓解特征退化，增强判别性特征并抑制噪声。

Result: DCCS-Det 在多个数据集上实现了最先进的检测精度和具有竞争力的效率。消融研究进一步验证了 DSE 和 LaSEA 模块在复杂场景下提升目标感知和特征表征的有效性。

Conclusion: DCCS-Det 是一种有效的新型红外小目标检测器，通过 DSE 和 LaSEA 模块能够更好地处理局部-全局特征的联合建模以及特征的冗余和稀释问题，从而在复杂的红外小目标检测任务中取得优异性能。

Abstract: Infrared small target detection (IRSTD) is critical for applications like remote sensing and surveillance, which aims to identify small, low-contrast targets against complex backgrounds. However, existing methods often struggle with inadequate joint modeling of local-global features (harming target-background discrimination) or feature redundancy and semantic dilution (degrading target representation quality). To tackle these issues, we propose DCCS-Det (Directional Context and Cross-Scale Aware Detector for Infrared Small Target), a novel detector that incorporates a Dual-stream Saliency Enhancement (DSE) block and a Latent-aware Semantic Extraction and Aggregation (LaSEA) module. The DSE block integrates localized perception with direction-aware context aggregation to help capture long-range spatial dependencies and local details. On this basis, the LaSEA module mitigates feature degradation via cross-scale feature extraction and random pooling sampling strategies, enhancing discriminative features and suppressing noise. Extensive experiments show that DCCS-Det achieves state-of-the-art detection accuracy with competitive efficiency across multiple datasets. Ablation studies further validate the contributions of DSE and LaSEA in improving target perception and feature representation under complex scenarios. \href{https://huggingface.co/InPeerReview/InfraredSmallTargetDetection-IRSTD.DCCS}{DCCS-Det Official Code is Available Here!}

</details>


### [28] [AlphaFace: High Fidelity and Real-time Face Swapper Robust to Facial Pose](https://arxiv.org/abs/2601.16429)
*Jongmin Yu,Hyeontaek Oh,Zhongtian Sun,Angelica I Aviles-Rivero,Moongu Jeon,Jinhong Yang*

Main category: cs.CV

TL;DR: AlphaFace 是一种新的面部交换方法，它利用 CLIP 的视觉和文本嵌入以及对比损失，实现了实时性能，并在姿态挑战性场景中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸交换方法在处理极端面部姿势时质量会显著下降，而引入显式几何特征的方法会增加复杂性和计算成本。此外，扩散模型虽然效果好，但无法实现实时处理。

Method: 该研究引入了 AlphaFace，该方法利用开源的视觉语言模型和 CLIP 的图像-文本嵌入，设计了新的视觉和文本语义对比损失。

Result: AlphaFace 能够生成更强的身份表示和更精确的属性保留，同时保持实时性能。在 FF++、MPIE 和 LPFF 数据集上的实验表明，AlphaFace 在姿态挑战性案例中优于最先进的方法。

Conclusion: AlphaFace 是一种高效且鲁棒的人脸交换方法，能够成功处理极端面部姿势，并且具备实时性能，为该领域的研究提供了一个新的方向。

Abstract: Existing face-swapping methods often deliver competitive results in constrained settings but exhibit substantial quality degradation when handling extreme facial poses. To improve facial pose robustness, explicit geometric features are applied, but this approach remains problematic since it introduces additional dependencies and increases computational cost. Diffusion-based methods have achieved remarkable results; however, they are impractical for real-time processing. We introduce AlphaFace, which leverages an open-source vision-language model and CLIP image and text embeddings to apply novel visual and textual semantic contrastive losses. AlphaFace enables stronger identity representation and more precise attribute preservation, all while maintaining real-time performance. Comprehensive experiments across FF++, MPIE, and LPFF demonstrate that AlphaFace surpasses state-of-the-art methods in pose-challenging cases. The project is publicly available on `https://github.com/andrewyu90/Alphaface_Official.git'.

</details>


### [29] [MDAFNet: Multiscale Differential Edge and Adaptive Frequency Guided Network for Infrared Small Target Detection](https://arxiv.org/abs/2601.16434)
*Shuying Li,Qiang Ma,San Zhang,Wuwei Wang,Chuang Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为MDAFNet的新型红外小目标检测网络，通过多尺度差分边缘和双域自适应特征增强模块，解决了传统方法中目标边缘信息丢失和频率成分区分能力不足的问题，提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有红外小目标检测方法在网络层数增加时，目标边缘像素信息会逐渐退化；传统卷积难以区分频率成分，导致低频背景干扰高频目标，高频噪声引发误报。

Method: 提出MDAFNet网络，包含多尺度差分边缘（MSDE）模块和双域自适应特征增强（DAFE）模块。MSDE模块通过多尺度边缘提取与增强补偿下采样过程中的目标边缘信息丢失。DAFE模块结合频域处理和空域模拟的频率分解与融合机制，自适应增强高频目标并抑制高频噪声。

Result: 在多个数据集上的实验结果表明，MDAFNet在检测性能上优于现有方法。

Conclusion: MDAFNet通过MSDE和DAFE模块的有效结合，显著提升了红外小目标检测的准确性和鲁棒性，解决了目标边缘信息丢失和背景噪声干扰的挑战。

Abstract: Infrared small target detection (IRSTD) plays a crucial role in numerous military and civilian applications. However, existing methods often face the gradual degradation of target edge pixels as the number of network layers increases, and traditional convolution struggles to differentiate between frequency components during feature extraction, leading to low-frequency backgrounds interfering with high-frequency targets and high-frequency noise triggering false detections. To address these limitations, we propose MDAFNet (Multi-scale Differential Edge and Adaptive Frequency Guided Network for Infrared Small Target Detection), which integrates the Multi-Scale Differential Edge (MSDE) module and Dual-Domain Adaptive Feature Enhancement (DAFE) module. The MSDE module, through a multi-scale edge extraction and enhancement mechanism, effectively compensates for the cumulative loss of target edge information during downsampling. The DAFE module combines frequency domain processing mechanisms with simulated frequency decomposition and fusion mechanisms in the spatial domain to effectively improve the network's capability to adaptively enhance high-frequency targets and selectively suppress high-frequency noise. Experimental results on multiple datasets demonstrate the superior detection performance of MDAFNet.

</details>


### [30] [GPA-VGGT:Adapting VGGT to Large scale Localization by self-Supervised learning with Geometry and Physics Aware loss](https://arxiv.org/abs/2601.16885)
*Yangfan Xu,Lilian Zhang,Xiaofeng He,Pengdong Wu,Wenqi Wu,Jun Mao*

Main category: cs.CV

TL;DR: 本文提出了一种自监督框架，用于训练基于Transformer的视觉几何模型（VGGT），使其能够利用无标签数据进行大规模环境下的定位，通过引入序列级几何约束和联合优化物理光度一致性与几何约束来实现。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的视觉几何模型（如VGGT）在训练时通常依赖真实标签，这限制了它们在无标签和未知场景中的应用。研究的动机是开发一种能够适应大规模无标签环境的自监督方法，以提高模型的定位能力。

Method: 作者提出了一种自监督框架，将传统的成对关系扩展到序列级几何约束。具体来说，通过在序列中采样多个源帧并将其投影到不同的目标帧，以增强时间特征一致性。同时，将物理光度一致性与几何约束共同构成损失函数，以避免对硬标签的依赖。这种方法可以有效训练模型的跨视图注意力层和相机/深度预测头。

Result: 通过所提出的自监督方法训练的模型，不仅能够有效捕捉多视图几何信息，而且在实验中显示出在数百次迭代内即可收敛，并在大规模定位任务上取得了显著的性能提升。

Conclusion: 该自监督框架成功克服了VGGT模型对真实标签的依赖，并通过引入序列级几何约束和联合损失函数，显著增强了模型在无标签大规模环境下的定位能力，验证了其有效性。

Abstract: Transformer-based general visual geometry frameworks have shown promising performance in camera pose estimation and 3D scene understanding. Recent advancements in Visual Geometry Grounded Transformer (VGGT) models have shown great promise in camera pose estimation and 3D reconstruction. However, these models typically rely on ground truth labels for training, posing challenges when adapting to unlabeled and unseen scenes. In this paper, we propose a self-supervised framework to train VGGT with unlabeled data, thereby enhancing its localization capability in large-scale environments. To achieve this, we extend conventional pair-wise relations to sequence-wise geometric constraints for self-supervised learning. Specifically, in each sequence, we sample multiple source frames and geometrically project them onto different target frames, which improves temporal feature consistency. We formulate physical photometric consistency and geometric constraints as a joint optimization loss to circumvent the requirement for hard labels. By training the model with this proposed method, not only the local and global cross-view attention layers but also the camera and depth heads can effectively capture the underlying multi-view geometry. Experiments demonstrate that the model converges within hundreds of iterations and achieves significant improvements in large-scale localization. Our code will be released at https://github.com/X-yangfan/GPA-VGGT.

</details>


### [31] [Masked Face Recognition under Different Backbones](https://arxiv.org/abs/2601.16440)
*Bo Zhang,Ming Zhang,Kun Wu,Lei Bian,Yi Lin*

Main category: cs.CV

TL;DR: 本文对几种核心骨干网络在有无口罩情况下的识别人脸性能进行了全面评估，并提供了部署建议。r100系列模型在标准测试中表现最优，但在有口罩测试中，r100_mask_v2和Vit-Small/Tiny模型表现出色。


<details>
  <summary>Details</summary>
Motivation: 后疫情时代，大量民航旅客在安检时佩戴口罩，对传统的识别人脸模型提出了挑战。

Method: 对r100、r50、r34_mask_v1、r100_mask_v2、r50_mask_v3以及Vit-Small/Tiny等多种核心骨干网络进行了有无口罩情况下的性能评估。

Result: 在标准测试中，r100系列模型准确率超过98%。在有口罩测试中，r100_mask_v2表现最佳（90.07%准确率），Vit-Small/Tiny模型在有口罩情况下性能提升显著。

Conclusion: 该研究揭示了不同骨干网络模型在有无口罩情况下的识别人脸性能差异，并为模型部署提供了具体建议。r100系列和Vit-Small/Tiny模型在应对戴口罩识别方面具有优势。

Abstract: Erratum to the paper (Zhang et al., 2025): corrections to Table IV and the data in Page 3, Section A. In the post-pandemic era, a high proportion of civil aviation passengers wear masks during security checks, posing significant challenges to traditional face recognition models. The backbone network serves as the core component of face recognition models. In standard tests, r100 series models excelled (98%+ accuracy at 0.01% FAR in face comparison, high top1/top5 in search). r50 ranked second, r34_mask_v1 lagged. In masked tests, r100_mask_v2 led (90.07% accuracy), r50_mask_v3 performed best among r50 but trailed r100. Vit-Small/Tiny showed strong masked performance with gains in effectiveness. Through extensive comparative experiments, this paper conducts a comprehensive evaluation of several core backbone networks, aiming to reveal the impacts of different models on face recognition with and without masks, and provide specific deployment recommendations.

</details>


### [32] [AnyView: Synthesizing Any Novel View in Dynamic Scenes](https://arxiv.org/abs/2601.16982)
*Basile Van Hoorick,Dian Chen,Shun Iwase,Pavel Tokmakov,Muhammad Zubair Irshad,Igor Vasiljevic,Swati Gupta,Fangzhou Cheng,Sergey Zakharov,Vitor Campagnolo Guizilini*

Main category: cs.CV

TL;DR: AnyView是一个基于扩散模型的视频生成框架，用于动态视角合成，通过整合多种数据源和监督级别，实现了从任意视角和轨迹生成零样本新视频的能力，并在新提出的AnyViewBench基准上展现出对现有方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有生成视频模型在高度动态的真实世界环境中难以保持多视角和时空一致性。本研究旨在解决这一问题，实现动态视角合成。

Method: 提出AnyView框架，一个基于扩散模型的视频生成框架，利用单目(2D)、多视角静态(3D)和多视角动态(4D)数据集训练一个通用的时空隐式表示，生成具有最小归纳偏置或几何假设的视频。

Result: AnyView在标准基准上取得了与当前最先进技术相当的结果。在提出的AnyViewBench基准上，AnyView能够生成真实、合理且时空一致的视频，而大多数基线方法性能显著下降。

Conclusion: AnyView能够从任意视角生成逼真且时空一致的动态视角合成视频，尤其在具有挑战性的动态视角合成场景下表现出色，克服了现有方法的局限性。

Abstract: Modern generative video models excel at producing convincing, high-quality outputs, but struggle to maintain multi-view and spatiotemporal consistency in highly dynamic real-world environments. In this work, we introduce \textbf{AnyView}, a diffusion-based video generation framework for \emph{dynamic view synthesis} with minimal inductive biases or geometric assumptions. We leverage multiple data sources with various levels of supervision, including monocular (2D), multi-view static (3D) and multi-view dynamic (4D) datasets, to train a generalist spatiotemporal implicit representation capable of producing zero-shot novel videos from arbitrary camera locations and trajectories. We evaluate AnyView on standard benchmarks, showing competitive results with the current state of the art, and propose \textbf{AnyViewBench}, a challenging new benchmark tailored towards \emph{extreme} dynamic view synthesis in diverse real-world scenarios. In this more dramatic setting, we find that most baselines drastically degrade in performance, as they require significant overlap between viewpoints, while AnyView maintains the ability to produce realistic, plausible, and spatiotemporally consistent videos when prompted from \emph{any} viewpoint. Results, data, code, and models can be viewed at: https://tri-ml.github.io/AnyView/

</details>


### [33] [Emotion-LLaMAv2 and MMEVerse: A New Framework and Benchmark for Multimodal Emotion Understanding](https://arxiv.org/abs/2601.16449)
*Xiaojiang Peng,Jingyi Chen,Zebang Cheng,Bao Peng,Fengyi Wu,Yifei Dong,Shuyuan Tu,Qiyu Hu,Huiting Huang,Yuxiang Lin,Jun-Yan He,Kai Wang,Zheng Lian,Zhi-Qi Cheng*

Main category: cs.CV

TL;DR: 本文提出了Emotion-LLaMAv2和MMEVerse基准，以解决多模态情感理解中的挑战，改进了现有方法的局限性，包括端到端的编码器、新的预融合模块以及统一的指令微调方案，并通过整合和重新标注大量现有数据集来支持大规模训练和评估。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模多模态情感理解模型在情感推理能力上存在局限，并且缺乏高质量的标注数据集和标准化的评估基准。之前的Emotion-LLaMA框架受到显式人脸检测、隐式融合策略以及低质量、小规模训练数据的限制。

Method: 提出了Emotion-LLaMAv2，包含一个端到端的视听编码器，一个Conv Attention预融合模块，以及一个基于LLaMA2的感知-认知课程指令微调方案。同时，创建了MMEVerse基准，整合了12个公开数据集，并使用多智能体进行重新标注，生成了130k训练样本和36k测试样本。

Result: Emotion-LLaMAv2通过端到端的编码器消除了人脸检测的依赖，捕捉更丰富的时空情感线索。Conv Attention模块实现了多模态特征的局部和全局交互。指令微调方案统一了情感识别和自由形式的情感推理。MMEVerse提供了大规模、高质量的数据集和18个评估基准。

Conclusion: Emotion-LLaMAv2和MMEVerse基准提供了一个端到端的解决方案，用于多模态情感识别和推理，克服了现有方法的局限性，并通过大规模、标准化的数据集和评估设置，有望推动情感计算和人机交互领域的研究进展。

Abstract: Understanding human emotions from multimodal signals poses a significant challenge in affective computing and human-robot interaction. While multimodal large language models (MLLMs) have excelled in general vision-language tasks, their capabilities in emotional reasoning remain limited. The field currently suffers from a scarcity of large-scale datasets with high-quality, descriptive emotion annotations and lacks standardized benchmarks for evaluation. Our preliminary framework, Emotion-LLaMA, pioneered instruction-tuned multimodal learning for emotion reasoning but was restricted by explicit face detectors, implicit fusion strategies, and low-quality training data with limited scale. To address these limitations, we present Emotion-LLaMAv2 and the MMEVerse benchmark, establishing an end-to-end pipeline together with a standardized evaluation setting for emotion recognition and reasoning. Emotion-LLaMAv2 introduces three key advances. First, an end-to-end multiview encoder eliminates external face detection and captures nuanced emotional cues via richer spatial and temporal multiview tokens. Second, a Conv Attention pre-fusion module is designed to enable simultaneous local and global multimodal feature interactions external to the LLM backbone. Third, a perception-to-cognition curriculum instruction tuning scheme within the LLaMA2 backbone unifies emotion recognition and free-form emotion reasoning. To support large-scale training and reproducible evaluation, MMEVerse aggregates twelve publicly available emotion datasets, including IEMOCAP, MELD, DFEW, and MAFW, into a unified multimodal instruction format. The data are re-annotated via a multi-agent pipeline involving Qwen2 Audio, Qwen2.5 VL, and GPT 4o, producing 130k training clips and 36k testing clips across 18 evaluation benchmarks.

</details>


### [34] [VISTA-PATH: An interactive foundation model for pathology image segmentation and quantitative analysis in computational pathology](https://arxiv.org/abs/2601.16451)
*Peixian Liang,Songhao Li,Shunsuke Koga,Yutong Li,Zahra Alipour,Yucheng Tang,Daguang Xu,Zhi Huang*

Main category: cs.CV

TL;DR: VISTA-PATH是一个用于病理图像的交互式、类别感知分割基础模型，它结合了视觉上下文、文本描述和专家反馈，能够进行精确的多类别分割，并超越现有模型。该模型支持动态的人机协作精炼，并且生成的分割结果能显著提升计算病理学分析，如通过肿瘤相互作用评分（TIS）与患者生存期关联。


<details>
  <summary>Details</summary>
Motivation: 现有的分割基础模型在处理病理图像时，将其视为静态视觉预测任务，导致泛化能力不足且与临床应用脱节。研究旨在开发一个能够解决异质性结构、整合专家反馈并生成临床意义上的像素级分割的模型。

Method: VISTA-PATH模型将分割与视觉上下文、语义组织描述以及可选的专家提供的空间提示联合进行条件化。它利用VISTA-PATH Data，一个包含超过160万个图像-掩码-文本三元组的大规模病理分割语料库。模型支持动态的人机协作精炼，将稀疏的、块级别的边界框标注反馈传播到全切片分割中。

Result: VISTA-PATH在广泛的内部和外部基准测试中持续优于现有的分割基础模型。模型能够生成高保真、类别感知的分割结果，并能通过肿瘤相互作用评分（TIS）显著改善了对患者生存期的分析。

Conclusion: VISTA-PATH是一个强大的基础模型，将病理图像分割从静态预测提升为一种交互式、临床导向的数字病理学表示。它在病理图像分析和计算病理学应用中具有重要价值。

Abstract: Accurate semantic segmentation for histopathology image is crucial for quantitative tissue analysis and downstream clinical modeling. Recent segmentation foundation models have improved generalization through large-scale pretraining, yet remain poorly aligned with pathology because they treat segmentation as a static visual prediction task. Here we present VISTA-PATH, an interactive, class-aware pathology segmentation foundation model designed to resolve heterogeneous structures, incorporate expert feedback, and produce pixel-level segmentation that are directly meaningful for clinical interpretation. VISTA-PATH jointly conditions segmentation on visual context, semantic tissue descriptions, and optional expert-provided spatial prompts, enabling precise multi-class segmentation across heterogeneous pathology images. To support this paradigm, we curate VISTA-PATH Data, a large-scale pathology segmentation corpus comprising over 1.6 million image-mask-text triplets spanning 9 organs and 93 tissue classes. Across extensive held-out and external benchmarks, VISTA-PATH consistently outperforms existing segmentation foundation models. Importantly, VISTA-PATH supports dynamic human-in-the-loop refinement by propagating sparse, patch-level bounding-box annotation feedback into whole-slide segmentation. Finally, we show that the high-fidelity, class-aware segmentation produced by VISTA-PATH is a preferred model for computational pathology. It improve tissue microenvironment analysis through proposed Tumor Interaction Score (TIS), which exhibits strong and significant associations with patient survival. Together, these results establish VISTA-PATH as a foundation model that elevates pathology image segmentation from a static prediction to an interactive and clinically grounded representation for digital pathology. Source code and demo can be found at https://github.com/zhihuanglab/VISTA-PATH.

</details>


### [35] [Multi-View Consistent Wound Segmentation With Neural Fields](https://arxiv.org/abs/2601.16487)
*Remi Chierchia,Léo Lebrat,David Ahmedt-Aristizabal,Yulia Arzhaeva,Olivier Salvado,Clinton Fookes,Rodrigo Santa Cruz*

Main category: cs.CV

TL;DR: 本文评估了一种基于NeRF-SDF的WoundNeRF方法，用于从自动生成的2D图像注释中估计鲁棒的伤口分割，并与现有方法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 伤口护理面临经济和后勤负担，计算机视觉和机器学习（特别是伤口分割）提供了自动化的解决方案，但从2D图像推断多视图一致的3D结构仍然是一个挑战。

Method: 评估了WoundNeRF，一种基于NeRF SDF的方法，用于从自动生成的注释中估计伤口分割。通过与最先进的Vision Transformer网络和基于光栅化的算法进行比较来评估其性能。

Result: WoundNeRF在恢复准确分割方面显示出潜力，并且与现有技术相比具有优势（具体比较结果未在摘要中详细说明）。

Conclusion: 基于NeRF SDF的WoundNeRF方法有望用于伤口分割，并为该领域的研究和开发提供了新的方向。

Abstract: Wound care is often challenged by the economic and logistical burdens that consistently afflict patients and hospitals worldwide. In recent decades, healthcare professionals have sought support from computer vision and machine learning algorithms. In particular, wound segmentation has gained interest due to its ability to provide professionals with fast, automatic tissue assessment from standard RGB images. Some approaches have extended segmentation to 3D, enabling more complete and precise healing progress tracking. However, inferring multi-view consistent 3D structures from 2D images remains a challenge. In this paper, we evaluate WoundNeRF, a NeRF SDF-based method for estimating robust wound segmentations from automatically generated annotations. We demonstrate the potential of this paradigm in recovering accurate segmentations by comparing it against state-of-the-art Vision Transformer networks and conventional rasterisation-based algorithms. The code will be released to facilitate further development in this promising paradigm.

</details>


### [36] [Order from Chaos: Physical World Understanding from Glitchy Gameplay Videos](https://arxiv.org/abs/2601.16471)
*Meng Cao,Haoran Tang,Haoze Zhao,Mingfei Han,Ruyang Liu,Qiang Sun,Xiaojun Chang,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: 本文提出了一种利用游戏视频中的物理“故障”（违反物理定律的视觉异常）作为监督信号，来提升多模态大模型（MLLM）对物理世界的理解能力的新方法。研究人员构建了一个名为 PhysGame 的大规模问答数据集，并设计了一个名为 GameBench 的基准测试集来评估模型性能。实验表明，这种方法能够显著提高模型在真实世界和通用物理推理任务上的表现，并增强其检测物理不可能性事件的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型在理解物理世界方面仍有不足。现有的物理推理数据集要么标注成本高（真实视频），要么真实感和多样性不足（合成模拟）。因此，需要一种更丰富、可扩展且成本较低的监督源来提升模型的物理世界理解能力。

Method: 提出一种利用游戏视频中的物理“故障”（visual anomalies that violate predefined physical laws）作为监督信号的新范式。构建了一个名为 PhysGame 的数据集，包含 140,057 个关于物理故障的问答对，并利用游戏元信息（标题、描述）指导高质量问答生成。同时，构建了一个名为 GameBench 的基准测试集，包含 880 个经过专家标注的包含物理故障的游戏视频。

Result: 使用 PhysGame 数据集微调的模型在真实世界物理推理任务（PhysBench）上性能提升 2.5%，在通用物理推理任务（MVBench）上性能提升 1.9%。在 GameBench 基准测试集上，微调模型在检测物理不合理性方面取得了 3.7% 的绝对提升。

Conclusion: 从游戏故障中学习是一种可扩展且有效的方法，可以推进多模态智能在物理世界理解方面的能力。这种方法能够显著提高模型对物理规律的理解和鲁棒性。

Abstract: Understanding the physical world, including object dynamics, material properties, and causal interactions, remains a core challenge in artificial intelligence. Although recent multi-modal large language models (MLLMs) have demonstrated impressive general reasoning capabilities, they still fall short of achieving human-level understanding of physical principles. Existing datasets for physical reasoning either rely on real-world videos, which incur high annotation costs, or on synthetic simulations, which suffer from limited realism and diversity. In this paper, we propose a novel paradigm that leverages glitches in gameplay videos, referring to visual anomalies that violate predefined physical laws, as a rich and scalable supervision source for physical world understanding. We introduce PhysGame, an meta information guided instruction-tuning dataset containing 140,057 glitch-centric question-answer pairs across five physical domains and sixteen fine-grained categories. To ensure data accuracy, we design a prompting strategy that utilizes gameplay metadata such as titles and descriptions to guide high-quality QA generation. Complementing PhysGame, we construct GameBench, an expert-annotated benchmark with 880 glitch-identified gameplay videos designed to evaluate physical reasoning capabilities. Extensive experiments show that PhysGame significantly enhances both Game2Real transferability, improving the real world physical reasoning performance of Qwen2.5VL by 2.5% on PhysBench, and Game2General transferability, yielding a 1.9% gain on the MVBench benchmark. Moreover, PhysGame-tuned models achieve a 3.7% absolute improvement on GameBench, demonstrating enhanced robustness in detecting physical implausibilities. These results indicate that learning from gameplay anomalies offers a scalable and effective pathway toward advancing physical world understanding in multimodal intelligence.

</details>


### [37] [Expert Knowledge-Guided Decision Calibration for Accurate Fine-Grained Tree Species Classification](https://arxiv.org/abs/2601.16498)
*Chen Long,Dian Chen,Ruifei Ding,Zhe Chen,Zhen Dong,Bisheng Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为EKDC-Net的专家知识引导分类决策校准网络，通过提取和利用领域专家知识来解决树种分类中数据长尾分布和类别相似性问题，并发布了一个包含102种树木的大型数据集CU-Tree102。实验证明，EKDC-Net能够显著提升分类性能，且计算开销很小。


<details>
  <summary>Details</summary>
Motivation: 现有树种分类方法在处理数据长尾分布和高类间相似性问题时表现不佳，尤其是在少数类和易混淆类别上。受人类知识传播中寻求专家帮助的启发，研究旨在克服这些局限性。

Method: 提出EKDC-Net框架，包含两个核心模块：1. 局部先验引导知识提取模块（LPKEM），利用CAM分析指导领域专家聚焦于区分性特征；2. 不确定性引导决策校准模块（UDCM），通过整体类别不确定性和实例级预测不确定性来动态校正局部模型的决策。此外，构建了CU-Tree102数据集。

Result: 在三个基准数据集上，EKDC-Net取得了最先进的性能。作为一个轻量级即插即用模块，EKDC-Net仅需0.08M额外参数，就能使骨干网络的准确率提升6.42%，精确率提升11.46%。

Conclusion: EKDC-Net能够有效地利用领域专家知识，克服现有树种分类方法在处理长尾分布和高类间相似性方面的不足，显著提升模型性能，且计算效率高。CU-Tree102数据集为相关研究提供了新的资源。

Abstract: Accurate fine-grained tree species classification is critical for forest inventory and biodiversity monitoring. Existing methods predominantly focus on designing complex architectures to fit local data distributions. However, they often overlook the long-tailed distributions and high inter-class similarity inherent in limited data, thereby struggling to distinguish between few-shot or confusing categories. In the process of knowledge dissemination in the human world, individuals will actively seek expert assistance to transcend the limitations of local thinking. Inspired by this, we introduce an external "Domain Expert" and propose an Expert Knowledge-Guided Classification Decision Calibration Network (EKDC-Net) to overcome these challenges. Our framework addresses two core issues: expert knowledge extraction and utilization. Specifically, we first develop a Local Prior Guided Knowledge Extraction Module (LPKEM). By leveraging Class Activation Map (CAM) analysis, LPKEM guides the domain expert to focus exclusively on discriminative features essential for classification. Subsequently, to effectively integrate this knowledge, we design an Uncertainty-Guided Decision Calibration Module (UDCM). This module dynamically corrects the local model's decisions by considering both overall category uncertainty and instance-level prediction uncertainty. Furthermore, we present a large-scale classification dataset covering 102 tree species, named CU-Tree102 to address the issue of scarce diversity in current benchmarks. Experiments on three benchmark datasets demonstrate that our approach achieves state-of-the-art performance. Crucially, as a lightweight plug-and-play module, EKDC-Net improves backbone accuracy by 6.42% and precision by 11.46% using only 0.08M additional learnable parameters. The dataset, code, and pre-trained models are available at https://github.com/WHU-USI3DV/TreeCLS.

</details>


### [38] [SALAD: Achieve High-Sparsity Attention via Efficient Linear Attention Tuning for Video Diffusion Transformer](https://arxiv.org/abs/2601.16515)
*Tongcheng Fang,Hanling Zhang,Ruiqi Xie,Zhuo Han,Xin Tao,Tianchen Zhao,Pengfei Wan,Wenbo Ding,Wanli Ouyang,Xuefei Ning,Yu Wang*

Main category: cs.CV

TL;DR: 提出了一种名为SALAD的新型稀疏注意力机制，通过引入轻量级线性注意力分支并结合输入依赖的门控机制，在不显著降低生成质量的情况下，实现了90%的稀疏度和1.72倍的推理加速，且微调成本极低。


<details>
  <summary>Details</summary>
Motivation: 现有Diffusion Transformer在视频生成方面表现优异，但由于完整注意力机制的二次复杂度导致长序列输入时计算延迟高。现有的稀疏注意力方法要么加速有限（训练无关），要么需要大量数据和计算进行训练（基于训练）。

Method: SALAD通过引入一个轻量级的线性注意力分支与稀疏注意力分支并行，并利用输入依赖的门控机制来平衡这两个分支的贡献，从而实现高稀疏度和高效推理。

Result: SALAD实现了90%的稀疏度，推理速度提升1.72倍，同时保持了与完整注意力基线相当的生成质量。微调过程高效，仅需2000个视频样本和1600步训练。

Conclusion: SALAD是一种高效且低成本的稀疏注意力方法，能够显著加速Diffusion Transformer在视频生成中的推理过程，同时保持生成质量，并且易于微调。

Abstract: Diffusion Transformers have recently demonstrated remarkable performance in video generation. However, the long input sequences result in high computational latency due to the quadratic complexity of full attention. Various sparse attention mechanisms have been proposed. Training-free sparse attention is constrained by limited sparsity and thus offers modest acceleration, whereas training-based methods can reach much higher sparsity but demand substantial data and computation for training. In this work, we propose SALAD, introducing a lightweight linear attention branch in parallel with the sparse attention. By incorporating an input-dependent gating mechanism to finely balance the two branches, our method attains 90% sparsity and 1.72x inference speedup, while maintaining generation quality comparable to the full attention baseline. Moreover, our finetuning process is highly efficient, requiring only 2,000 video samples and 1,600 training steps with a batch size of 8.

</details>


### [39] [TangramPuzzle: Evaluating Multimodal Large Language Models with Compositional Spatial Reasoning](https://arxiv.org/abs/2601.16520)
*Daixian Liu,Jiayi Kuang,Yinghui Li,Yangning Li,Di Yin,Haoyu Cao,Xing Sun,Ying Shen,Hai-Tao Zheng,Liang Lin,Philip S. Yu*

Main category: cs.CV

TL;DR: 本文提出了TangramPuzzle基准，用于评估多模态大语言模型（MLLMs）的组合空间推理能力，并引入了Tangram Construction Expression（TCE）符号几何框架来精确定义Tangram的组装。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估MLLMs的精确组合空间推理能力方面存在不足，任务简单，依赖语义近似和粗略的相对定位，且评估指标缺乏数学严谨性。

Method: 设计了TangramPuzzle基准，该基准基于经典的Tangram游戏，并引入了Tangram Construction Expression（TCE）符号几何框架。TCE使用精确的、机器可验证的坐标规范来定义Tangram组装，消除了视觉近似的模糊性。设计了两种任务：Outline Prediction（从局部组件推断全局形状）和End-to-End Code Generation（解决逆向几何组装问题）。

Result: 对先进的MLLMs进行的实验表明，模型倾向于匹配目标轮廓而忽略几何约束，导致形状碎片变形。

Conclusion: MLLMs在进行组合空间推理时，尤其是在Tangram组装任务中，存在对几何约束的忽视问题，优先匹配整体轮廓而牺牲了局部形状的精确性。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable progress in visual recognition and semantic understanding. Nevertheless, their ability to perform precise compositional spatial reasoning remains largely unexplored. Existing benchmarks often involve relatively simple tasks and rely on semantic approximations or coarse relative positioning, while their evaluation metrics are typically limited and lack rigorous mathematical formulations. To bridge this gap, we introduce TangramPuzzle, a geometry-grounded benchmark designed to evaluate compositional spatial reasoning through the lens of the classic Tangram game. We propose the Tangram Construction Expression (TCE), a symbolic geometric framework that grounds tangram assemblies in exact, machine-verifiable coordinate specifications, to mitigate the ambiguity of visual approximation. We design two complementary tasks: Outline Prediction, which demands inferring global shapes from local components, and End-to-End Code Generation, which requires solving inverse geometric assembly problems. We conduct extensive evaluation experiments on advanced open-source and proprietary models, revealing an interesting insight: MLLMs tend to prioritize matching the target silhouette while neglecting geometric constraints, leading to distortions or deformations of the pieces.

</details>


### [40] [AnchoredDream: Zero-Shot 360° Indoor Scene Generation from a Single View via Geometric Grounding](https://arxiv.org/abs/2601.16532)
*Runmao Yao,Junsheng Zhou,Zhen Dong,Yu-Shen Liu*

Main category: cs.CV

TL;DR: 提出了一种名为AnchoredDream的零样本方法，通过几何约束提升单视角室内360度全景生成质量，解决了现有方法在外观一致性和几何合理性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有单视角室内360度全景生成方法在处理大视角变化时，存在外观不一致和几何不合理的问题，限制了其在全景生成上的应用。

Method: 提出AnchoredDream零样本流水线，核心机制是外观-几何互助增强。首先，生成外观引导下的高保真几何布局；然后，通过warp-and-inpaint、warp-and-refine、后优化和Grouting Block等模块逐步生成完整场景，Grouting Block确保了输入视角与生成区域的无缝过渡。

Result: AnchoredDream在外观一致性和几何合理性方面均显著优于现有方法，并且实现了零样本生成。

Conclusion: 几何约束是实现高质量、零样本单视角全景生成的重要途径，AnchoredDream证明了其有效性。

Abstract: Single-view indoor scene generation plays a crucial role in a range of real-world applications. However, generating a complete 360° scene from a single image remains a highly ill-posed and challenging problem. Recent approaches have made progress by leveraging diffusion models and depth estimation networks, yet they still struggle to maintain appearance consistency and geometric plausibility under large viewpoint changes, limiting their effectiveness in full-scene generation. To address this, we propose AnchoredDream, a novel zero-shot pipeline that anchors 360° scene generation on high-fidelity geometry via an appearance-geometry mutual boosting mechanism. Given a single-view image, our method first performs appearance-guided geometry generation to construct a reliable 3D scene layout. Then, we progressively generate the complete scene through a series of modules: warp-and-inpaint, warp-and-refine, post-optimization, and a novel Grouting Block, which ensures seamless transitions between the input view and generated regions. Extensive experiments demonstrate that AnchoredDream outperforms existing methods by a large margin in both appearance consistency and geometric plausibility--all in a zero-shot manner. Our results highlight the potential of geometric grounding for high-quality, zero-shot single-view scene generation.

</details>


### [41] [OnlineSI: Taming Large Language Model for Online 3D Understanding and Grounding](https://arxiv.org/abs/2601.16538)
*Zixian Liu,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 本文提出了OnlineSI框架，一种能够持续提升空间理解能力的多模态大语言模型（MLLM），通过维护有限空间记忆和融合3D点云与语义信息，解决了现有方法在动态环境和具身系统部署方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在空间理解和推理方面存在局限，尤其是在连续变化的环境中以及在具身系统中部署时，计算量会随输入累积而增加，且缺乏持续学习和适应能力。

Method: 提出OnlineSI框架，核心思想是维护一个有限的空间记忆来存储过去观察，从而控制每次推理的计算量；同时，集成3D点云信息与语义信息，以帮助MLLM更好地定位和识别场景中的物体。

Result: 在两个代表性数据集上进行了测试，并引入了Fuzzy $F_1$-Score指标来处理歧义性。实验结果表明该方法有效。

Conclusion: OnlineSI框架能够持续提升MLLM的空间理解能力，为实现面向真实世界具身系统的应用奠定了基础。

Abstract: In recent years, researchers have increasingly been interested in how to enable Multimodal Large Language Models (MLLM) to possess spatial understanding and reasoning capabilities. However, most existing methods overlook the importance of the ability to continuously work in an ever-changing world, and lack the possibility of deployment on embodied systems in real-world environments. In this work, we introduce OnlineSI, a framework that can continuously improve its spatial understanding of its surroundings given a video stream. Our core idea is to maintain a finite spatial memory to retain past observations, ensuring the computation required for each inference does not increase as the input accumulates. We further integrate 3D point cloud information with semantic information, helping MLLM to better locate and identify objects in the scene. To evaluate our method, we introduce the Fuzzy $F_1$-Score to mitigate ambiguity, and test our method on two representative datasets. Experiments demonstrate the effectiveness of our method, paving the way towards real-world embodied systems.

</details>


### [42] [Semi-Supervised Hierarchical Open-Set Classification](https://arxiv.org/abs/2601.16541)
*Erik Wallin,Fredrik Kahl,Lars Hammarstrand*

Main category: cs.CV

TL;DR: 本研究提出了一种半监督层级开放集分类方法，利用大量未标记数据来提升模型性能，并引入了子树伪标签和年龄门控机制来处理未知类别和缓解伪标签的过度自信问题。


<details>
  <summary>Details</summary>
Motivation: 利用大规模、未经过整理的包含已知和未知类别的数据集来提升层级开放集分类的性能，解决了现有方法在半监督场景下的局限性。

Method: 提出了一种基于伪标签的教师-学生框架，包括子树伪标签（用于处理未知数据）和年龄门控（用于缓解伪标签的过度自信）。

Result: 该框架在iNaturalist19基准上，仅使用每类20个标记样本的情况下，优于自监督预训练+监督适应的方法，并能达到全监督方法的水平。

Conclusion: 提出的半监督层级开放集分类框架能够有效地利用未标记数据，并且通过引入子树伪标签和年龄门控机制，在处理未知类别和提高模型鲁棒性方面取得了显著成效。

Abstract: Hierarchical open-set classification handles previously unseen classes by assigning them to the most appropriate high-level category in a class taxonomy. We extend this paradigm to the semi-supervised setting, enabling the use of large-scale, uncurated datasets containing a mixture of known and unknown classes to improve the hierarchical open-set performance. To this end, we propose a teacher-student framework based on pseudo-labeling. Two key components are introduced: 1) subtree pseudo-labels, which provide reliable supervision in the presence of unknown data, and 2) age-gating, a mechanism that mitigates overconfidence in pseudo-labels. Experiments show that our framework outperforms self-supervised pretraining followed by supervised adaptation, and even matches the fully supervised counterpart when using only 20 labeled samples per class on the iNaturalist19 benchmark. Our code is available at https://github.com/walline/semihoc.

</details>


### [43] [Boundary and Position Information Mining for Aerial Small Object Detection](https://arxiv.org/abs/2601.16617)
*Rongxin Huang,Guangfeng Lin,Wenbo Zhou,Zhirong Li,Wenhuan Wu*

Main category: cs.CV

TL;DR: 提出了一种名为BPIM（边界与位置信息挖掘）的框架，用于解决无人机和小目标检测中尺度不平衡和边缘模糊的问题，通过融合边界、位置和尺度信息，并在多个数据集上取得了优于基线和具有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 无人机在航空摄影和目标识别方面的应用日益广泛，但小目标检测面临尺度不平衡和边缘模糊的挑战。

Method: 提出BPIM框架，包含PIG（位置信息引导）、BIG（边界信息引导）、CSF（跨尺度融合）、TFF（三特征融合）和AWF（自适应权重融合）等模块，利用注意力机制和跨尺度特征融合策略。

Result: 在VisDrone2021、DOTA1.0和WiderPerson数据集上，BPIM相较于基线Yolov5-P2表现更优，并且在计算量相当的情况下，获得了与现有最先进方法相当的性能。

Conclusion: BPIM框架通过整合边界、位置和尺度信息，有效提高了上下文特征的辨别力，并增强了小目标感知能力，在小目标检测任务中展现出优越的性能。

Abstract: Unmanned Aerial Vehicle (UAV) applications have become increasingly prevalent in aerial photography and object recognition. However, there are major challenges to accurately capturing small targets in object detection due to the imbalanced scale and the blurred edges. To address these issues, boundary and position information mining (BPIM) framework is proposed for capturing object edge and location cues. The proposed BPIM includes position information guidance (PIG) module for obtaining location information, boundary information guidance (BIG) module for extracting object edge, cross scale fusion (CSF) module for gradually assembling the shallow layer image feature, three feature fusion (TFF) module for progressively combining position and boundary information, and adaptive weight fusion (AWF) module for flexibly merging the deep layer semantic feature. Therefore, BPIM can integrate boundary, position, and scale information in image for small object detection using attention mechanisms and cross-scale feature fusion strategies. Furthermore, BPIM not only improves the discrimination of the contextual feature by adaptive weight fusion with boundary, but also enhances small object perceptions by cross-scale position fusion. On the VisDrone2021, DOTA1.0, and WiderPerson datasets, experimental results show the better performances of BPIM compared to the baseline Yolov5-P2, and obtains the promising performance in the state-of-the-art methods with comparable computation load.

</details>


### [44] [HA2F: Dual-module Collaboration-Guided Hierarchical Adaptive Aggregation Framework for Remote Sensing Change Detection](https://arxiv.org/abs/2601.16573)
*Shuying Li,Yuchen Wang,San Zhang,Chuang Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为HA2F的双模块协同引导分层自适应聚合框架，用于遥感变化检测。该框架通过动态分层特征校准模块（DHFCM）和噪声自适应特征精炼模块（NAFRM）来解决现有方法在特征提取和匹配中存在的偏差和噪声敏感性问题，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥感变化检测方法在处理局部特征或全局图像时存在跨时序特征匹配偏差以及对辐射和几何噪声敏感的问题。

Method: 提出了一种名为HA2F的双模块协同引导分层自适应聚合框架。它包含两个主要模块：动态分层特征校准模块（DHFCM），通过感知特征选择动态融合相邻层级特征，抑制不相关的差异以解决多时序特征对齐偏差；以及噪声自适应特征精炼模块（NAFRM），利用双特征选择机制突出变化敏感区域并生成空间掩码，抑制无关区域或阴影的干扰。

Result: HA2F在LEVIR-CD、WHU-CD和SYSU-CD数据集上进行了广泛实验，取得了最先进的性能，在精度指标和计算效率上均优于现有方法。消融实验也证明了DHFCM和NAFRM的有效性。

Conclusion: HA2F框架通过DHFCM和NAFRM的协同工作，有效解决了遥感变化检测中的特征对齐偏差和噪声干扰问题，提高了检测的准确性和效率，并在多个基准数据集上取得了SOTA性能。

Abstract: Remote sensing change detection (RSCD) aims to identify the spatio-temporal changes of land cover, providing critical support for multi-disciplinary applications (e.g., environmental monitoring, disaster assessment, and climate change studies). Existing methods focus either on extracting features from localized patches, or pursue processing entire images holistically, which leads to the cross temporal feature matching deviation and exhibiting sensitivity to radiometric and geometric noise. Following the above issues, we propose a dual-module collaboration guided hierarchical adaptive aggregation framework, namely HA2F, which consists of dynamic hierarchical feature calibration module (DHFCM) and noise-adaptive feature refinement module (NAFRM). The former dynamically fuses adjacent-level features through perceptual feature selection, suppressing irrelevant discrepancies to address multi-temporal feature alignment deviations. The NAFRM utilizes the dual feature selection mechanism to highlight the change sensitive regions and generate spatial masks, suppressing the interference of irrelevant regions or shadows. Extensive experiments verify the effectiveness of the proposed HA2F, which achieves state-of-the-art performance on LEVIR-CD, WHU-CD, and SYSU-CD datasets, surpassing existing comparative methods in terms of both precision metrics and computational efficiency. In addition, ablation experiments show that DHFCM and NAFRM are effective. \href{https://huggingface.co/InPeerReview/RemoteSensingChangeDetection-RSCD.HA2F}{HA2F Official Code is Available Here!}

</details>


### [45] [X-Aligner: Composed Visual Retrieval without the Bells and Whistles](https://arxiv.org/abs/2601.16582)
*Yuqian Zheng,Mariana-Iuliana Georgescu*

Main category: cs.CV

TL;DR: 提出了一种新的基于视觉语言模型（VLMs）的组合视频检索（CoVR）框架，通过引入X-Aligner交叉注意力模块，并利用视觉查询的标题作为额外输入，在Webvid-CoVR数据集上取得了最先进的性能，并在CIR任务上展现了良好的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有CoVR框架在多模态输入融合阶段单一，性能提升有限。希望利用VLMs的表征能力来改进CoVR。

Method: 提出一个包含X-Aligner交叉注意力模块的新CoVR框架，该模块逐步融合视觉和文本输入，并将其与目标视频的表示对齐。还将视觉查询的标题作为额外输入。采用两阶段训练：第一阶段仅训练新模块，第二阶段微调文本查询编码器。基于BLIP和BLIP-2实现，并在Webvid-CoVR数据集上训练。

Result: 在Webvid-CoVR-Test数据集上取得了63.93%的Recall@1，达到最先进水平。在CIRCO和Fashion-IQ数据集上实现了强大的零样本泛化能力。

Conclusion: 所提出的新CoVR框架通过利用VLMs的表征能力和创新的X-Aligner模块，有效提升了组合视频检索的性能，并展现了良好的跨领域泛化能力。

Abstract: Composed Video Retrieval (CoVR) facilitates video retrieval by combining visual and textual queries. However, existing CoVR frameworks typically fuse multimodal inputs in a single stage, achieving only marginal gains over initial baseline. To address this, we propose a novel CoVR framework that leverages the representational power of Vision Language Models (VLMs). Our framework incorporates a novel cross-attention module X-Aligner, composed of cross-attention layers that progressively fuse visual and textual inputs and align their multimodal representation with that of the target video. To further enhance the representation of the multimodal query, we incorporate the caption of the visual query as an additional input. The framework is trained in two stages to preserve the pretrained VLM representation. In the first stage, only the newly introduced module is trained, while in the second stage, the textual query encoder is also fine-tuned. We implement our framework on top of BLIP-family architecture, namely BLIP and BLIP-2, and train it on the Webvid-CoVR data set. In addition to in-domain evaluation on Webvid-CoVR-Test, we perform zero-shot evaluations on the Composed Image Retrieval (CIR) data sets CIRCO and Fashion-IQ. Our framework achieves state-of-the-art performance on CoVR obtaining a Recall@1 of 63.93% on Webvid-CoVR-Test, and demonstrates strong zero-shot generalization on CIR tasks.

</details>


### [46] [A Lightweight Medical Image Classification Framework via Self-Supervised Contrastive Learning and Quantum-Enhanced Feature Modeling](https://arxiv.org/abs/2601.16608)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: 提出了一种轻量级的医疗图像分类框架，结合了自监督对比学习和量子增强特征建模，以解决标注数据稀缺、计算资源有限和模型泛化能力不足的问题。该框架使用MobileNetV2作为骨干网络，在无标签数据上进行SimCLR风格的自监督预训练，并嵌入一个轻量级的参数化量子电路（PQC）作为量子特征增强模块，最后在有限的有标签数据上进行微调。


<details>
  <summary>Details</summary>
Motivation: 医疗图像分析面临标注数据稀缺、计算资源有限和模型泛化能力不足的挑战，限制了其在临床决策支持中的应用。

Method: 使用MobileNetV2作为紧凑骨干网络，采用SimCLR风格的自监督对比学习在无标签数据上进行预训练。将一个轻量级的参数化量子电路（PQC）作为量子特征增强模块嵌入，构建混合经典-量子架构，然后在有限的有标签数据上进行微调。

Result: 该方法仅使用约2-3百万参数和低计算成本，在准确率、AUC和F1分数方面持续优于不使用自监督学习或量子增强的经典基线方法。特征可视化显示了更强的判别能力和更稳定的表示。

Conclusion: 该研究提供了一个在资源受限环境下实现高斯性能医疗人工智能的实用且前瞻性的解决方案，通过结合自监督学习和量子计算来克服现有挑战。

Abstract: Intelligent medical image analysis is essential for clinical decision support but is often limited by scarce annotations, constrained computational resources, and suboptimal model generalization. To address these challenges, we propose a lightweight medical image classification framework that integrates self-supervised contrastive learning with quantum-enhanced feature modeling. MobileNetV2 is employed as a compact backbone and pretrained using a SimCLR-style self-supervised paradigm on unlabeled images. A lightweight parameterized quantum circuit (PQC) is embedded as a quantum feature enhancement module, forming a hybrid classical-quantum architecture, which is subsequently fine-tuned on limited labeled data. Experimental results demonstrate that, with only approximately 2-3 million parameters and low computational cost, the proposed method consistently outperforms classical baselines without self-supervised learning or quantum enhancement in terms of Accuracy, AUC, and F1-score. Feature visualization further indicates improved discriminability and representation stability. Overall, this work provides a practical and forward-looking solution for high-performance medical artificial intelligence under resource-constrained settings.

</details>


### [47] [SCHIGAND: A Synthetic Facial Generation Mode Pipeline](https://arxiv.org/abs/2601.16627)
*Ananya Kadali,Sunnie Jehan-Morrison,Orasiki Wellington,Barney Evans,Precious Durojaiye,Richard Guest*

Main category: cs.CV

TL;DR: 本研究提出了一种名为SCHIGAND的新型合成人脸生成管线，它结合了StyleCLIP、HyperStyle、InterfaceGAN和Diffusion模型，旨在生成高质量、多样化且身份可控的人脸数据集，以应对隐私法规和数据稀缺的挑战，并可用于生物特征识别系统的训练和测试。


<details>
  <summary>Details</summary>
Motivation: 隐私法规、数据稀缺和伦理问题阻碍了高质量人脸数据集的获取，而现有的生成模型在真实性、多样性和身份保持方面存在不足，因此需要一种新的方法来生成满足生物特征识别需求的合成人脸数据集。

Method: 该研究提出的SCHIGAND管线集成了StyleCLIP、HyperStyle、InterfaceGAN和Diffusion模型，用于生成高度逼真且可控的合成人脸图像，重点在于增强身份保持能力，同时生成类内真实变化和类间差异。

Result: 使用ArcFace（一种领先的面部验证模型）对生成的合成数据集进行了评估。实验结果表明，SCHIGAND在图像质量和多样性之间取得了良好的平衡，克服了先前生成模型的局限性。

Conclusion: SCHIGAND能够生成高质量、多样化且身份可控的合成人脸数据集，在一定程度上可以补充甚至替代真实数据用于人脸生物特征识别应用，为隐私合规和可扩展的合成数据集生成提供了新的解决方案。

Abstract: The growing demand for diverse and high-quality facial datasets for training and testing biometric systems is challenged by privacy regulations, data scarcity, and ethical concerns. Synthetic facial images offer a potential solution, yet existing generative models often struggle to balance realism, diversity, and identity preservation. This paper presents SCHIGAND, a novel synthetic face generation pipeline integrating StyleCLIP, HyperStyle, InterfaceGAN, and Diffusion models to produce highly realistic and controllable facial datasets. SCHIGAND enhances identity preservation while generating realistic intra-class variations and maintaining inter-class distinctiveness, making it suitable for biometric testing. The generated datasets were evaluated using ArcFace, a leading facial verification model, to assess their effectiveness in comparison to real-world facial datasets. Experimental results demonstrate that SCHIGAND achieves a balance between image quality and diversity, addressing key limitations of prior generative models. This research highlights the potential of SCHIGAND to supplement and, in some cases, replace real data for facial biometric applications, paving the way for privacy-compliant and scalable solutions in synthetic dataset generation.

</details>


### [48] [Edge-Aware Image Manipulation via Diffusion Models with a Novel Structure-Preservation Loss](https://arxiv.org/abs/2601.16645)
*Minsu Gong,Nuri Ryu,Jungseul Ok,Sunghyun Cho*

Main category: cs.CV

TL;DR: 提出一种新的结构保持损失（SPL）函数，通过局部线性模型量化结构差异，以解决基于潜扩散模型的图像编辑在保持像素级边缘结构方面的挑战，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于潜扩散模型的图像编辑方法在保持像素级边缘结构方面存在挑战，这对于照片级风格转换或图像色调调整等任务至关重要。

Method: 提出了一种名为结构保持损失（SPL）的新型损失函数，利用局部线性模型量化输入图像和编辑后图像之间的结构差异。该方法无需训练，将SPL直接集成到扩散模型的生成过程中，并辅以后处理步骤来减轻LDM解码失真，使用掩蔽策略进行精确编辑定位，以及颜色保持损失来保留未编辑区域的色调。

Result: 实验证明，SPL能够增强结构保真度，在基于潜扩散模型的图像编辑任务中取得了最先进的性能。

Conclusion: SPL是一种有效的训练无关方法，可以显著提高基于潜扩散模型的图像编辑在保持结构完整性方面的性能，解决了现有方法的局限性。

Abstract: Recent advances in image editing leverage latent diffusion models (LDMs) for versatile, text-prompt-driven edits across diverse tasks. Yet, maintaining pixel-level edge structures-crucial for tasks such as photorealistic style transfer or image tone adjustment-remains as a challenge for latent-diffusion-based editing. To overcome this limitation, we propose a novel Structure Preservation Loss (SPL) that leverages local linear models to quantify structural differences between input and edited images. Our training-free approach integrates SPL directly into the diffusion model's generative process to ensure structural fidelity. This core mechanism is complemented by a post-processing step to mitigate LDM decoding distortions, a masking strategy for precise edit localization, and a color preservation loss to preserve hues in unedited areas. Experiments confirm SPL enhances structural fidelity, delivering state-of-the-art performance in latent-diffusion-based image editing. Our code will be publicly released at https://github.com/gongms00/SPL.

</details>


### [49] [Curated endoscopic retrograde cholangiopancreatography images dataset](https://arxiv.org/abs/2601.16759)
*Alda João Andrade,Mónica Martins,André Ferreira,Tarcísio Araújo,Luís Lopes,Victor Alves*

Main category: cs.CV

TL;DR: 本研究发布了一个包含19018张原始图像和19317张处理后图像的大型ERCP数据集，其中5519张图像经过专家标注，旨在推动人工智能在胆胰疾病诊断中的应用。


<details>
  <summary>Details</summary>
Motivation: 由于公开的ERCP数据集稀缺，限制了人工智能在ERCP诊断中的应用，因此本研究旨在构建一个大型、经过精心策划的数据集来填补这一空白。

Method: 收集了1602名患者的19018张原始ERCP图像和19317张处理后图像，其中5519张图像由两位具有5年以上经验的消化内科医生手动标注，并由一位具有20年以上经验且每年进行400多例ERCP手术的消化内科医生进行审查。通过一个分类实验验证了数据集的效用和有效性。

Result: 成功构建了一个大规模、高质量的ERCP图像数据集，其中包含标注信息，并已通过分类实验证明其有效性。

Conclusion: 该数据集的创建为ERCP自动分析和胆胰疾病诊断提供了一个基准，有望推动相关领域的研究和发展。

Abstract: Endoscopic Retrograde Cholangiopancreatography (ERCP) is a key procedure in the diagnosis and treatment of biliary and pancreatic diseases. Artificial intelligence has been pointed as one solution to automatize diagnosis. However, public ERCP datasets are scarce, which limits the use of such approach. Therefore, this study aims to help fill this gap by providing a large and curated dataset. The collection is composed of 19.018 raw images and 19.317 processed from 1.602 patients. 5.519 images are labeled, which provides a ready to use dataset. All images were manually inspected and annotated by two gastroenterologist with more than 5 years of experience and reviewed by another gastroenterologist with more than 20 years of experience, all with more than 400 ERCP procedures annually. The utility and validity of the dataset is proven by a classification experiment. This collection aims to provide or contribute for a benchmark in automatic ERCP analysis and diagnosis of biliary and pancreatic diseases.

</details>


### [50] [Reliable Brain Tumor Segmentation Based on Spiking Neural Networks with Efficient Training](https://arxiv.org/abs/2601.16652)
*Aurora Pia Ghiardelli,Guangzhi Tang,Tao Sun*

Main category: cs.CV

TL;DR: 提出一种使用脉冲神经网络（SNN）进行3D脑肿瘤分割的框架，通过多视图集成和前向传播（FPTT）提高了准确性和能效，并能估计不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有的SNN模型在训练时计算成本高，并且在3D脑肿瘤分割任务中需要可靠且能耗低的解决方案。

Method: 采用多视图（矢状面、冠状面、轴向）SNN模型集成，并使用前向传播（FPTT）来降低计算成本。该方法可以进行体素级的不确定性估计。

Result: 在BraTS 2017和BraTS 2023数据集上取得了具有竞争力的准确性，不确定性校准良好，并且FLOPs减少了87%。

Conclusion: SNNs具有在可靠、低功耗的医疗物联网和即时护理系统中的应用潜力，尤其是在3D脑肿瘤分割方面。

Abstract: We propose a reliable and energy-efficient framework for 3D brain tumor segmentation using spiking neural networks (SNNs). A multi-view ensemble of sagittal, coronal, and axial SNN models provides voxel-wise uncertainty estimation and enhances segmentation robustness. To address the high computational cost in training SNN models for semantic image segmentation, we employ Forward Propagation Through Time (FPTT), which maintains temporal learning efficiency with significantly reduced computational cost. Experiments on the Multimodal Brain Tumor Segmentation Challenges (BraTS 2017 and BraTS 2023) demonstrate competitive accuracy, well-calibrated uncertainty, and an 87% reduction in FLOPs, underscoring the potential of SNNs for reliable, low-power medical IoT and Point-of-Care systems.

</details>


### [51] [ReWeaver: Towards Simulation-Ready and Topology-Accurate Garment Reconstruction](https://arxiv.org/abs/2601.16672)
*Ming Li,Hui Shan,Kai Zheng,Chentao Shen,Siyu Liu,Yanwei Fu,Zhen Chen,Xiangru Huang*

Main category: cs.CV

TL;DR: ReWeaver 是一个创新的框架，可以从稀疏的多视图 RGB 图像中准确重建服装的拓扑结构和缝纫结构，从而生成适合物理模拟和机器人操作的结构化 2D-3D 服装表示。


<details>
  <summary>Details</summary>
Motivation: 现有服装重建方法依赖于非结构化表示，难以精确重建服装拓扑和缝纫结构，导致重建结果不适用于高保真物理模拟。作者希望解决这一问题，以缩小仿真到现实的差距。

Method: ReWeaver 框架能够从稀疏的多视图（至少四视图）RGB 图像中预测 2D UV 空间和 3D 空间中的接缝、面板及其连接性。为此，作者构建了一个大规模数据集 GCD-TS，包含多视图 RGB 图像、3D 服装几何、纹理人体网格和带注释的缝纫图案。

Result: ReWeaver 在拓扑准确性、几何对齐和接缝-面板一致性方面始终优于现有方法。重建后的 2D-3D 服装表示与多视图图像精确对齐。

Conclusion: ReWeaver 成功实现了从稀疏多视图图像进行拓扑准确的 3D 服装和缝纫图案重建，生成的结构化表示适用于 3D 感知、高保真物理模拟和机器人操作。

Abstract: High-quality 3D garment reconstruction plays a crucial role in mitigating the sim-to-real gap in applications such as digital avatars, virtual try-on and robotic manipulation. However, existing garment reconstruction methods typically rely on unstructured representations, such as 3D Gaussian Splats, struggling to provide accurate reconstructions of garment topology and sewing structures. As a result, the reconstructed outputs are often unsuitable for high-fidelity physical simulation. We propose ReWeaver, a novel framework for topology-accurate 3D garment and sewing pattern reconstruction from sparse multi-view RGB images. Given as few as four input views, ReWeaver predicts seams and panels as well as their connectivities in both the 2D UV space and the 3D space. The predicted seams and panels align precisely with the multi-view images, yielding structured 2D--3D garment representations suitable for 3D perception, high-fidelity physical simulation, and robotic manipulation. To enable effective training, we construct a large-scale dataset GCD-TS, comprising multi-view RGB images, 3D garment geometries, textured human body meshes and annotated sewing patterns. The dataset contains over 100,000 synthetic samples covering a wide range of complex geometries and topologies. Extensive experiments show that ReWeaver consistently outperforms existing methods in terms of topology accuracy, geometry alignment and seam-panel consistency.

</details>


### [52] [REL-SF4PASS: Panoramic Semantic Segmentation with REL Depth Representation and Spherical Fusion](https://arxiv.org/abs/2601.16788)
*Xuewei Li,Xinghan Bao,Zhimin Chen,Xi Li*

Main category: cs.CV

TL;DR: 提出了一种基于圆柱坐标系的新型深度表示REL（Rectified Depth, Elevation-Gained Vertical Inclination Angle, Lateral Orientation Angle）和一种多模态融合策略SMMF（Spherical-dynamic Multi-Modal Fusion），用于全景语义分割（PASS），以充分利用全景图像的几何特性，并提升模型在不同区域的融合效果和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有全景语义分割方法未能充分利用全景图像的几何信息，尤其是在使用RGB输入或传统深度表示时。此外，在全景图像不同区域的融合策略上存在不足。

Method: 提出了一种新的深度表示REL，它在圆柱坐标系下包含了校正深度、视线增益垂直倾斜角和方位角，能更全面地表示三维空间和表面法线方向。同时，提出了一种球形动态多模态融合（SMMF）策略，根据全景图像的不同区域采用不同的融合策略，以增强模态间的融合效果并减少ERP投影中的失真。

Result: 在Stanford2D3D全景数据集上的实验表明，REL-SF4PASS方法在所有3个折叠（folds）上平均mIoU提升了2.35%，并且在面对3D扰动时，性能方差降低了约70%，显示出更高的鲁棒性。

Conclusion: 提出的REL深度表示和SMMF融合策略能够有效提升全景语义分割的性能和鲁棒性，克服了现有方法的局限性，更好地利用了全景图像的几何信息。

Abstract: As an important and challenging problem in computer vision, Panoramic Semantic Segmentation (PASS) aims to give complete scene perception based on an ultra-wide angle of view. Most PASS methods often focus on spherical geometry with RGB input or using the depth information in original or HHA format, which does not make full use of panoramic image geometry. To address these shortcomings, we propose REL-SF4PASS with our REL depth representation based on cylindrical coordinate and Spherical-dynamic Multi-Modal Fusion SMMF. REL is made up of Rectified Depth, Elevation-Gained Vertical Inclination Angle, and Lateral Orientation Angle, which fully represents 3D space in cylindrical coordinate style and the surface normal direction. SMMF aims to ensure the diversity of fusion for different panoramic image regions and reduce the breakage of cylinder side surface expansion in ERP projection, which uses different fusion strategies to match the different regions in panoramic images. Experimental results show that REL-SF4PASS considerably improves performance and robustness on popular benchmark, Stanford2D3D Panoramic datasets. It gains 2.35% average mIoU improvement on all 3 folds and reduces the performance variance by approximately 70% when facing 3D disturbance.

</details>


### [53] [Affinity Contrastive Learning for Skeleton-based Human Activity Understanding](https://arxiv.org/abs/2601.16694)
*Hongda Liu,Yunfan Liu,Min Ren,Lin Sui,Yunlong Wang,Zhenan Sun*

Main category: cs.CV

TL;DR: ACLNet 是一种新的骨架表示人类活动理解方法，通过引入邻近度量来识别“活动超类”，从而改进对比学习，提高了跨类相似性和负样本分离性，并在多个基准测试中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法未能充分利用类间结构相似性，并忽视了异常正样本的影响。

Method: 提出了一种邻近度量来计算活动超类，并设计了动态温度计划来调整超类的对比信号强度。同时采用基于边际的对比策略来分离类内困难的正负样本。

Result: 在 NTU RGB+D 60、NTU RGB+D 120、Kinetics-Skeleton、PKU-MMD、FineGYM 和 CASIA-B 数据集上，ACLNet 在骨架为基础的动作识别、步态识别和行人重识别任务上均展现出优越性能。

Conclusion: ACLNet 通过利用活动超类和优化对比学习策略，有效提高了骨架表示人类活动理解的准确性。

Abstract: In skeleton-based human activity understanding, existing methods often adopt the contrastive learning paradigm to construct a discriminative feature space. However, many of these approaches fail to exploit the structural inter-class similarities and overlook the impact of anomalous positive samples. In this study, we introduce ACLNet, an Affinity Contrastive Learning Network that explores the intricate clustering relationships among human activity classes to improve feature discrimination. Specifically, we propose an affinity metric to refine similarity measurements, thereby forming activity superclasses that provide more informative contrastive signals. A dynamic temperature schedule is also introduced to adaptively adjust the penalty strength for various superclasses. In addition, we employ a margin-based contrastive strategy to improve the separation of hard positive and negative samples within classes. Extensive experiments on NTU RGB+D 60, NTU RGB+D 120, Kinetics-Skeleton, PKU-MMD, FineGYM, and CASIA-B demonstrate the superiority of our method in skeleton-based action recognition, gait recognition, and person re-identification. The source code is available at https://github.com/firework8/ACLNet.

</details>


### [54] [CER-HV: A CER-Based Human-in-the-Loop Framework for Cleaning Datasets Applied to Arabic-Script HTR](https://arxiv.org/abs/2601.16713)
*Sana Al-azzawi,Elisa Barney,Marcus Liwicki*

Main category: cs.CV

TL;DR: 该研究提出了一个名为CER-HV的框架，用于检测和清理阿拉伯语手写文本识别（HTR）数据集中的标签错误，并展示了该框架能够显著提高数据质量，同时提出了一种新的CRNN模型，在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管在模型架构、数据集和基准测试方面取得了进展，阿拉伯语脚本语言的手写文本识别（HTR）仍落后于拉丁语脚本。研究人员发现，许多已发布的数据集存在数据质量问题，特别是标签错误，这阻碍了HTR的发展。

Method: 研究人员提出了CER-HV（基于CER的人工验证）框架，该框架包含一个基于卷积循环神经网络（CRNN）的CER（字符错误率）噪声检测器，并结合了早期停止策略以避免过拟合。此外，还包含一个人工在环（HITL）的验证步骤，用于核实高风险样本。同时，研究人员还评估了一个CRNN模型在多个数据集上的性能。

Result: CER-HV框架识别出现有数据集（如Muharaf和PHTI）中存在转录、分割、方向和非文本内容等多种错误，并且检测精度高。研究提出的CRNN模型在六个评估数据集中的五个上取得了最先进的性能，无需数据清理。应用CER-HV后，在Cleaner数据集上CER提高了0.3-0.6%，在Noisier数据集上提高了1.0-1.8%。

Conclusion: 数据质量是阿拉伯语HTR的重要限制因素。CER-HV框架能够有效地检测和清理数据集中的标签错误，从而提高数据质量。提出的CRNN模型在未清理的数据集上已经表现出很强的性能，而结合CER-HV框架的改进效果更为显著。该框架具有通用性，可应用于其他文本识别数据集。

Abstract: Handwritten text recognition (HTR) for Arabic-script languages still lags behind Latin-script HTR, despite recent advances in model architectures, datasets, and benchmarks. We show that data quality is a significant limiting factor in many published datasets and propose CER-HV (CER-based Ranking with Human Verification) as a framework to detect and clean label errors. CER-HV combines a CER-based noise detector, built on a carefully configured Convolutional Recurrent Neural Network (CRNN) with early stopping to avoid overfitting noisy samples, and a human-in-the-loop (HITL) step that verifies high-ranking samples. The framework reveals that several existing datasets contain previously underreported problems, including transcription, segmentation, orientation, and non-text content errors. These have been identified with up to 90 percent precision in the Muharaf and 80-86 percent in the PHTI datasets.
  We also show that our CRNN achieves state-of-the-art performance across five of the six evaluated datasets, reaching 8.45 percent Character Error Rate (CER) on KHATT (Arabic), 8.26 percent on PHTI (Pashto), 10.66 percent on Ajami, and 10.11 percent on Muharaf (Arabic), all without any data cleaning. We establish a new baseline of 11.3 percent CER on the PHTD (Persian) dataset. Applying CER-HV improves the evaluation CER by 0.3-0.6 percent on the cleaner datasets and 1.0-1.8 percent on the noisier ones. Although our experiments focus on documents written in an Arabic-script language, including Arabic, Persian, Urdu, Ajami, and Pashto, the framework is general and can be applied to other text recognition datasets.

</details>


### [55] [Incorporating Eye-Tracking Signals Into Multimodal Deep Visual Models For Predicting User Aesthetic Experience In Residential Interiors](https://arxiv.org/abs/2601.16811)
*Chen-Ying Chien,Po-Chih Kuo*

Main category: cs.CV

TL;DR: 本研究提出了一种结合视觉特征和眼动追踪信号的CNN-LSTM框架，用于预测室内空间的美学评价，并在主观和客观评价维度上均取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 设计能够促进身心健康的室内空间至关重要，但由于感知的主观性和视觉反应的复杂性，预测美学体验仍然具有挑战性。

Method: 研究提出了一种双分支CNN-LSTM框架，该框架融合了图像特征和眼动追踪数据（包括瞳孔反应和注视点）来预测室内设计的224个视频的15个美学维度的评价。数据集包含28名参与者的同步眼动数据。

Result: 该模型在客观维度（如光线）上达到72.2%的准确率，在主观维度（如放松）上达到66.8%的准确率，优于现有的视频基线模型。有趣的是，用眼动追踪数据训练的模型在仅使用视觉输入进行部署时仍能保持可比的性能。消融实验表明，瞳孔反应对客观评估贡献最大，而注视点和视觉线索的结合能增强主观评估。

Conclusion: 眼动追踪数据作为训练时的“特权信息”具有价值，能够支持更实用的室内设计美学评估工具。研究结果强调了结合眼动追踪和视觉线索在提高美学评估准确性，尤其是主观性评价方面的潜力。

Abstract: Understanding how people perceive and evaluate interior spaces is essential for designing environments that promote well-being. However, predicting aesthetic experiences remains difficult due to the subjective nature of perception and the complexity of visual responses. This study introduces a dual-branch CNN-LSTM framework that fuses visual features with eye-tracking signals to predict aesthetic evaluations of residential interiors. We collected a dataset of 224 interior design videos paired with synchronized gaze data from 28 participants who rated 15 aesthetic dimensions. The proposed model attains 72.2% accuracy on objective dimensions (e.g., light) and 66.8% on subjective dimensions (e.g., relaxation), outperforming state-of-the-art video baselines and showing clear gains on subjective evaluation tasks. Notably, models trained with eye-tracking retain comparable performance when deployed with visual input alone. Ablation experiments further reveal that pupil responses contribute most to objective assessments, while the combination of gaze and visual cues enhances subjective evaluations. These findings highlight the value of incorporating eye-tracking as privileged information during training, enabling more practical tools for aesthetic assessment in interior design.

</details>


### [56] [Using Shadows in Circular Synthetic Aperture Sonar Imaging for Target Analysis](https://arxiv.org/abs/2601.16733)
*Yann Le Gall,Nicolas Burlet,Mathieu Simon,Fabien Novella,Samantha Dugelay,Jean-Philippe Malkasse*

Main category: cs.CV

TL;DR: 本研究提出了一种从圆形合成孔径声纳（CSAS）数据中恢复阴影信息的方法，以增强目标分析和三维重建能力，从而弥补了传统CSAS处理中阴影信息丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的CSAS虽然提供了360°的方位视角和高分辨率图像，但在处理过程中会丢失物体投射的阴影信息，而阴影信息对于目标识别和形状分析至关重要。因此，研究的目标是恢复CSAS数据中的阴影信息，以提升目标分析和三维重建的性能。

Method: 该研究采用子孔径滤波技术获取沿圆形轨迹不同视角的图像集合，并应用固定焦点阴影增强（FFSE）技术获得清晰的阴影。此外，还开发了一个交互式界面供操作员可视化这些阴影，并采用空间雕刻重建方法从分割的阴影中推断出物体的三维形状。

Result: 研究结果表明，从CSAS数据中恢复的阴影信息可以显著改善目标分析，并能有效地用于物体的三维重建。

Conclusion: 本研究成功地证明了在圆形合成孔径声纳中利用阴影信息进行目标分析和三维重建的潜力，为克服传统CSAS在目标识别方面的局限性提供了一种有效途径。

Abstract: Circular Synthetic Aperture Sonar (CSAS) provides a 360° azimuth view of the seabed, surpassing the limited aperture and mono-view image of conventional side-scan SAS. This makes CSAS a valuable tool for target recognition in mine warfare where the diversity of point of view is essential for reducing false alarms. CSAS processing typically produces a very high-resolution two-dimensional image. However, the parallax introduced by the circular displacement of the illuminator fill-in the shadow regions, and the shadow cast by an object on the seafloor is lost in favor of azimuth coverage and resolution. Yet the shadows provide complementary information on target shape useful for target recognition. In this paper, we explore a way to retrieve shadow information from CSAS data to improve target analysis and carry 3D reconstruction. Sub-aperture filtering is used to get a collection of images at various points of view along the circular trajectory and fixed focus shadow enhancement (FFSE) is applied to obtain sharp shadows. An interactive interface is also proposed to allow human operators to visualize these shadows along the circular trajectory. A space-carving reconstruction method is applied to infer the 3D shape of the object from the segmented shadows. The results demonstrate the potential of shadows in circular SAS for improving target analysis and 3D reconstruction.

</details>


### [57] [A Step to Decouple Optimization in 3DGS](https://arxiv.org/abs/2601.16736)
*Renjie Ding,Yaonan Wang,Min Liu,Jialin Zhu,Jiazheng Wang,Jiahao Zhao,Wenting Shen,Feixiang He,Xiang Che*

Main category: cs.CV

TL;DR: 本文提出了一种名为 AdamW-GS 的新优化方法，用于改进 3D 高斯溅射（3DGS）的性能。通过解耦并重新组合更新步骤和梯度，该方法实现了更高的优化效率和表示效果。


<details>
  <summary>Details</summary>
Motivation: 现有 3DGS 优化方法忽略了更新步骤耦合和梯度耦合这两个细节，可能导致优化效率和表示效果不佳。作者希望通过重新审视和解耦这些过程来改进 3DGS。

Method: 本文首先分析了 3DGS 优化中的两个问题：更新步骤耦合和梯度耦合。然后，提出了 Sparse Adam、Re-State Regularization 和 Decoupled Attribute Regularization 三个组件来解耦这些过程。最后，通过实验分析，将有益的组件重新组合，提出了 AdamW-GS。

Result: 在 3DGS 和 3DGS-MCMC 框架下的大量实验表明，本文提出的方法能够提供对这些组件更深入的理解。重新设计的 AdamW-GS 在优化效率和表示效果上都取得了同时提升。

Conclusion: 通过解耦和重新组合 3DGS 的优化过程，本文提出了一种新的优化方法 AdamW-GS，该方法能够同时提高优化效率和表示效果，为 3DGS 的研究提供了新的思路。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful technique for real-time novel view synthesis. As an explicit representation optimized through gradient propagation among primitives, optimization widely accepted in deep neural networks (DNNs) is actually adopted in 3DGS, such as synchronous weight updating and Adam with the adaptive gradient. However, considering the physical significance and specific design in 3DGS, there are two overlooked details in the optimization of 3DGS: (i) update step coupling, which induces optimizer state rescaling and costly attribute updates outside the viewpoints, and (ii) gradient coupling in the moment, which may lead to under- or over-effective regularization. Nevertheless, such a complex coupling is under-explored. After revisiting the optimization of 3DGS, we take a step to decouple it and recompose the process into: Sparse Adam, Re-State Regularization and Decoupled Attribute Regularization. Taking a large number of experiments under the 3DGS and 3DGS-MCMC frameworks, our work provides a deeper understanding of these components. Finally, based on the empirical analysis, we re-design the optimization and propose AdamW-GS by re-coupling the beneficial components, under which better optimization efficiency and representation effectiveness are achieved simultaneously.

</details>


### [58] [Automated Road Crack Localization to Guide Highway Maintenance](https://arxiv.org/abs/2601.16737)
*Steffen Knoblauch,Ram Kumar Muthusamy,Pedram Ghamisi,Alexander Zipf*

Main category: cs.CV

TL;DR: 本研究利用开源数据（航空影像和OpenStreetMap）微调YOLOv11模型，用于识别高速公路裂缝，并开发了瑞士相对公路裂缝密度（RHCD）指数来指导维护。该模型在裂缝检测方面表现良好，RHCD指数显示了其在指导维护方面的独特价值，尤其是在城市中心和交叉路口附近。这强调了开源数据在公共服务创新中的潜力。


<details>
  <summary>Details</summary>
Motivation: 气候变化导致的高温波动对道路路面造成压力，增加了维护成本。因此，需要有针对性和高效的维护策略。本研究旨在探索利用开源数据来指导高速公路基础设施维护。

Method: 研究提出了一个集成航空影像和OpenStreetMap（OSM）数据的框架，并利用该框架微调YOLOv11模型，以实现高速公路裂缝的定位。随后，计算了瑞士相对公路裂缝密度（RHCD）指数，并与长期地表温度幅度（LT-LST-A）和交通流量（TV）进行了相关性分析。

Result: 裂缝分类模型在正类（裂缝）上达到了0.84的F1分数，在负类（无裂缝）上达到了0.97的F1分数。瑞士RHCD指数与LT-LST-A（Pearson's r = -0.05）和TV（Pearson's r = 0.17）的相关性较弱，表明了该新指数在指导维护方面的附加价值。观察到城市中心和交叉路口附近存在显著高的RHCD值。

Conclusion: 本研究表明，集成航空影像和OSM数据的开源框架可以有效地用于高速公路裂缝检测。开发的RHCD指数能够为公路维护提供有价值的指导，尤其是在城市中心和交叉路口等关键区域。研究强调了开源数据共享在推动公共部门创新和提高效率方面的潜力。

Abstract: Highway networks are crucial for economic prosperity. Climate change-induced temperature fluctuations are exacerbating stress on road pavements, resulting in elevated maintenance costs. This underscores the need for targeted and efficient maintenance strategies. This study investigates the potential of open-source data to guide highway infrastructure maintenance. The proposed framework integrates airborne imagery and OpenStreetMap (OSM) to fine-tune YOLOv11 for highway crack localization. To demonstrate the framework's real-world applicability, a Swiss Relative Highway Crack Density (RHCD) index was calculated to inform nationwide highway maintenance. The crack classification model achieved an F1-score of $0.84$ for the positive class (crack) and $0.97$ for the negative class (no crack). The Swiss RHCD index exhibited weak correlations with Long-term Land Surface Temperature Amplitudes (LT-LST-A) (Pearson's $r\ = -0.05$) and Traffic Volume (TV) (Pearson's $r\ = 0.17$), underlining the added value of this novel index for guiding maintenance over other data. Significantly high RHCD values were observed near urban centers and intersections, providing contextual validation for the predictions. These findings highlight the value of open-source data sharing to drive innovation, ultimately enabling more efficient solutions in the public sector.

</details>


### [59] [No Validation, No Problem: Predicting Model Performance from a Single Gradient](https://arxiv.org/abs/2601.16874)
*Fangzheng Wu,Brian Summa*

Main category: cs.CV

TL;DR: 提出了一种无需验证的检查点信号，仅通过一次正向-反向传播计算分类器头梯度（Frobenius 范数），该信号可以有效预测模型在 ImageNet、COCO 和 CIFAR-10 上的性能，并可用于无验证的检查点选择和提前停止。


<details>
  <summary>Details</summary>
Motivation: 现有模型选择方法需要使用验证集，这在数据成本高昂或标签稀缺的情况下效率低下，并且可能导致模型过拟合验证集。因此，研究一种无需验证集即可选择最佳检查点的方法具有重要意义。

Method: 提出一种计算“验证-免费”检查点信号的方法，即计算一次正向-反向传播过程中，在单个解耦特征批次上分类器头梯度的 Frobenius 范数 ||g||_F = ||dL/dW||_F。通过在短尾窗口内选择最小头梯度的检查点来选择模型。针对不同模型架构（CNN 和 Transformer）提出了不同的归一化策略（head-scale 或 feature-scale）。

Result: 在 ImageNet-1k CNN 和 Transformer 上，该信号与 Top-1 准确率呈强负相关，与损失呈正相关。使用该方法选择的检查点性能接近最优（oracle），可将性能差距缩小 4.24% +/- 2.00%（通用设置），或 1.12%（轻度调优）。该方法还能预测 COCO 检测/分割 mAP。在扩散模型（UNet/DDPM on CIFAR-10）上，该信号可以追踪训练进度，并实现接近最优的尾窗口选择。该信号与同分布探测 MSE 正相关，与 FID 负相关，可用作轻量级、无标签的监控器。该方法仅增加约 0.1% 的训练时间。

Conclusion: 所提出的无需验证的检查点信号（分类器头梯度的 Frobenius 范数）是一种高效、通用的方法，可以用于无验证的检查点选择和早期停止，适用于多种模型架构和任务，并且计算成本极低。

Abstract: We propose a validation-free checkpointing signal from a single forward-backward pass: the Frobenius norm of the classifier-head gradient on one detached-feature batch, ||g||_F = ||dL/dW||_F. Across ImageNet-1k CNNs and Transformers, this proxy is strongly negative with Top-1 and positive with loss. Selecting the checkpoint with the minimum head gradient in a short tail window closes most of the gap to the oracle (4.24% +/- 2.00% with a universal setup, about 1.12% with light per-family tuning). For practical deployment, a head-scale normalization is more stable within classic CNN families (e.g., ResNets), while a feature-scale normalization works well for Transformers and modern CNNs. The same one-batch probe also predicts COCO detection/segmentation mAP. In diffusion (UNet/DDPM on CIFAR-10), it tracks progress and enables near-oracle tail-window selection; it is positively correlated with same-distribution probe MSE and negatively with FID (lower is better), so it can be used as a lightweight, label-free monitor. Validation labels are never used beyond reporting. The probe adds much less than 0.1% of an epoch and works as a drop-in for validation-free checkpoint selection and early stopping.

</details>


### [60] [Flow Matching for Probabilistic Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2601.16763)
*Cuong Le,Pavló Melnyk,Bastian Wandt,Mårten Wadenbäck*

Main category: cs.CV

TL;DR: 提出了一种基于流匹配生成方法（FMPose）的概率性三维人体姿态估计方法，通过最优传输学习三维姿态分布，相较于扩散模型，生成速度更快、精度更高。


<details>
  <summary>Details</summary>
Motivation: 传统的从单目二维姿态恢复三维姿态问题存在深度模糊的病态问题，现有方法常出现不准确但自信过高的估计。为了解决这个问题，需要考虑姿态不确定性的概率性方法。

Method: 提出FMPose方法，利用流匹配生成模型。条件于二维线索，流匹配模型通过连续归一化流学习从简单源分布到合理三维人体姿态分布的最优传输。二维提升条件通过图卷积网络建模，利用人体关节间的可学习连接作为特征聚合的图结构。

Result: FMPose相较于扩散模型，在三维姿态生成方面速度更快、精度更高。在Human3.6M、MPI-INF-3DHP和3DPW三个常用三维人体姿态估计基准测试上，FMPose取得了显著优于当前最先进方法的实验结果。

Conclusion: FMPose是一种有效的概率性三维人体姿态估计方法，通过流匹配和最优传输有效处理了深度不确定性问题，并在多个基准测试上取得了SOTA性能。

Abstract: Recovering 3D human poses from a monocular camera view is a highly ill-posed problem due to the depth ambiguity. Earlier studies on 3D human pose lifting from 2D often contain incorrect-yet-overconfident 3D estimations. To mitigate the problem, emerging probabilistic approaches treat the 3D estimations as a distribution, taking into account the uncertainty measurement of the poses. Falling in a similar category, we proposed FMPose, a probabilistic 3D human pose estimation method based on the flow matching generative approach. Conditioned on the 2D cues, the flow matching scheme learns the optimal transport from a simple source distribution to the plausible 3D human pose distribution via continuous normalizing flows. The 2D lifting condition is modeled via graph convolutional networks, leveraging the learnable connections between human body joints as the graph structure for feature aggregation. Compared to diffusion-based methods, the FMPose with optimal transport produces faster and more accurate 3D pose generations. Experimental results show major improvements of our FMPose over current state-of-the-art methods on three common benchmarks for 3D human pose estimation, namely Human3.6M, MPI-INF-3DHP and 3DPW.

</details>


### [61] [AutoRegressive Generation with B-rep Holistic Token Sequence Representation](https://arxiv.org/abs/2601.16771)
*Jiahao Li,Yunpeng Bai,Yongkang Dai,Hao Guo,Hongping Gan,Yilei Shi*

Main category: cs.CV

TL;DR: BrepARG 提出了一种将 B-rep (Boundary Representation) 的几何和拓扑信息编码为统一 token 序列表示的方法，并利用 Transformer 模型进行 B-rep 生成，达到了 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 B-rep 表示和生成方法通常将几何和拓扑信息解耦，这阻碍了应用 Transformer 等序列生成模型。作者希望开发一种能够将 B-rep 统一表示为序列的方法，以便利用 Transformer 的强大能力。

Method: BrepARG 将 B-rep 编码为三种类型的 token：几何和位置 token（表示几何特征）以及面索引 token（表示拓扑）。然后，通过构建几何块（面和边），再进行几何块排序，来层级化地构建统一的 token 序列。最后，构建了一个基于 Transformer 的自回归模型，通过下一个 token 预测来学习 token 序列的分布。

Result: BrepARG 在 B-rep 生成任务上取得了最先进 (SOTA) 的性能。

Conclusion: BrepARG 证明了将 B-rep 表示为统一 token 序列的可行性，为 B-rep 的生成开辟了新的研究方向。

Abstract: Previous representation and generation approaches for the B-rep relied on graph-based representations that disentangle geometric and topological features through decoupled computational pipelines, thereby precluding the application of sequence-based generative frameworks, such as transformer architectures that have demonstrated remarkable performance. In this paper, we propose BrepARG, the first attempt to encode B-rep's geometry and topology into a holistic token sequence representation, enabling sequence-based B-rep generation with an autoregressive architecture. Specifically, BrepARG encodes B-rep into 3 types of tokens: geometry and position tokens representing geometric features, and face index tokens representing topology. Then the holistic token sequence is constructed hierarchically, starting with constructing the geometry blocks (i.e., faces and edges) using the above tokens, followed by geometry block sequencing. Finally, we assemble the holistic sequence representation for the entire B-rep. We also construct a transformer-based autoregressive model that learns the distribution over holistic token sequences via next-token prediction, using a multi-layer decoder-only architecture with causal masking. Experiments demonstrate that BrepARG achieves state-of-the-art (SOTA) performance. BrepARG validates the feasibility of representing B-rep as holistic token sequences, opening new directions for B-rep generation.

</details>


### [62] [Evaluating Large Vision-language Models for Surgical Tool Detection](https://arxiv.org/abs/2601.16895)
*Nakul Poudel,Richard Simon,Cristian A. Linte*

Main category: cs.CV

TL;DR: 该研究评估了三种先进的大型视觉-语言模型（VLMs），Qwen2.5、LLaVA1.5 和 InternVL3.5，在机器人手术数据集上的手术工具检测能力，发现在零样本和 LoRA 微调设置下，Qwen2.5 表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有的手术 AI 系统通常是单一模态的，限制了其对复杂手术流程的整体理解能力。研究者旨在探索多模态的 VLMs 在整合手术场景信息方面的潜力，以实现更全面的手术任务建模和理解。

Method: 研究者在 GraSP 机器人手术数据集上，对 Qwen2.5、LLaVA1.5 和 InternVL3.5 三种 VLM 进行了零样本（zero-shot）和参数高效的 LoRA 微调（fine-tuning）评估。并将 VLM 的表现与开放集检测基线 Grounding DINO 进行了比较。

Result: Qwen2.5 在零样本和 LoRA 微调设置下均表现出比 LLaVA1.5 和 InternVL3.5 更优异的手术工具检测性能。与 Grounding DINO 相比，Qwen2.5 具有更强的零样本泛化能力，并在微调后达到可比的性能。具体来说，Qwen2.5 在仪器识别方面表现更强，而 Grounding DINO 在定位方面更优。

Conclusion: 大型视觉-语言模型，特别是 Qwen2.5，在手术工具检测等基础手术视觉任务中展现出巨大潜力。尽管存在性能上的细微差别（如 Qwen2.5 识别优于定位），但 VLMs 为开发更通用、更智能的手术 AI 系统提供了新的途径。

Abstract: Surgery is a highly complex process, and artificial intelligence has emerged as a transformative force in supporting surgical guidance and decision-making. However, the unimodal nature of most current AI systems limits their ability to achieve a holistic understanding of surgical workflows. This highlights the need for general-purpose surgical AI systems capable of comprehensively modeling the interrelated components of surgical scenes. Recent advances in large vision-language models that integrate multimodal data processing offer strong potential for modeling surgical tasks and providing human-like scene reasoning and understanding. Despite their promise, systematic investigations of VLMs in surgical applications remain limited. In this study, we evaluate the effectiveness of large VLMs for the fundamental surgical vision task of detecting surgical tools. Specifically, we investigate three state-of-the-art VLMs, Qwen2.5, LLaVA1.5, and InternVL3.5, on the GraSP robotic surgery dataset under both zero-shot and parameter-efficient LoRA fine-tuning settings. Our results demonstrate that Qwen2.5 consistently achieves superior detection performance in both configurations among the evaluated VLMs. Furthermore, compared with the open-set detection baseline Grounding DINO, Qwen2.5 exhibits stronger zero-shot generalization and comparable fine-tuned performance. Notably, Qwen2.5 shows superior instrument recognition, while Grounding DINO demonstrates stronger localization.

</details>


### [63] [LoL: Longer than Longer, Scaling Video Generation to Hour](https://arxiv.org/abs/2601.16914)
*Justin Cui,Jie Wu,Ming Li,Tao Yang,Xiaojie Li,Rui Wang,Andrew Bai,Yuanhao Ban,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: 提出了一种轻量级、无需训练的方法，通过引入多头 RoPE 抖动来解决长视频生成中的 sink-collapse 问题，该问题源于 RoPE 和多头注意力机制的冲突，从而实现了实时、流式、无限长度的视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有的长视频生成模型（特别是自回归模型）存在错误累积和长期连贯性丧失的问题。虽然 attention sink frames 缓解了性能衰减，但引入了 sink-collapse 这一新的失败模式，导致生成内容重复回退到 sink frame。

Method: 分析了 sink-collapse 产生的根源在于 RoPE 的周期性结构与多头注意力机制的冲突。提出了一种无需训练的方法，通过引入多头 RoPE 抖动来破坏头间注意力的同质化，缓解长期崩溃。

Result: 实验表明，所提出的方法能够有效地缓解 sink-collapse，同时保持生成质量。实现了实时、流式、无限长度的视频生成，并且生成质量几乎没有衰减。成功生成了长达 12 小时的连续视频。

Conclusion: 该研究首次实现了实时、流式、无限长度的视频生成，且在长视频生成方面表现出强大的鲁棒性，克服了 sink-collapse 问题，并显著延长了可生成视频的时长。

Abstract: Recent research in long-form video generation has shifted from bidirectional to autoregressive models, yet these methods commonly suffer from error accumulation and a loss of long-term coherence. While attention sink frames have been introduced to mitigate this performance decay, they often induce a critical failure mode we term sink-collapse: the generated content repeatedly reverts to the sink frame, resulting in abrupt scene resets and cyclic motion patterns. Our analysis reveals that sink-collapse originates from an inherent conflict between the periodic structure of Rotary Position Embedding (RoPE) and the multi-head attention mechanisms prevalent in current generative models. To address it, we propose a lightweight, training-free approach that effectively suppresses this behavior by introducing multi-head RoPE jitter that breaks inter-head attention homogenization and mitigates long-horizon collapse. Extensive experiments show that our method successfully alleviates sink-collapse while preserving generation quality. To the best of our knowledge, this work achieves the first demonstration of real-time, streaming, and infinite-length video generation with little quality decay. As an illustration of this robustness, we generate continuous videos up to 12 hours in length, which, to our knowledge, is among the longest publicly demonstrated results in streaming video generation.

</details>


### [64] [CASP: Few-Shot Class-Incremental Learning with CLS Token Attention Steering Prompts](https://arxiv.org/abs/2601.16773)
*Shuai Huang,Xuhan Lin,Yuwu Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为CASP（CLS Token Attention Steering Prompts）的新方法，用于解决少样本增量学习（FSCIL）问题，该方法通过操纵CLS token的自注意力机制来提升模型在新类别上的适应能力并减少遗忘，同时通过注意力扰动和浅层特征空间中的Manifold Token Mixup来增强泛化能力，实验证明该方法在多个数据集上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Prompt的方法在极端少样本增量学习设置下，模型在迁移和泛化能力上存在不足，因此需要一种方法来充分利用预训练知识，学习能够跨未来类别共享的特征表示。

Method: CASP方法通过引入类共享的可训练偏置参数到CLS token的查询、键和值投影中，显式地调节自注意力权重。此外，还设计了注意力扰动策略，并在浅层特征空间中进行Manifold Token Mixup，以增强泛化能力并为新任务保留表示容量。

Result: CASP在CUB200、CIFAR100和ImageNet-R数据集上的实验结果表明，该方法在标准和细粒度FSCIL设置下均优于最先进的方法，且在增量阶段无需微调，同时显著降低了参数开销。

Conclusion: CASP是一种有效的方法，能够解决少样本增量学习中的关键挑战，通过操纵CLS token的注意力机制和引入新的泛化增强策略，提升了模型在新类别上的性能和泛化能力，同时保持了较低的参数开销。

Abstract: Few-shot class-incremental learning (FSCIL) presents a core challenge in continual learning, requiring models to rapidly adapt to new classes with very limited samples while mitigating catastrophic forgetting. Recent prompt-based methods, which integrate pretrained backbones with task-specific prompts, have made notable progress. However, under extreme few-shot incremental settings, the model's ability to transfer and generalize becomes critical, and it is thus essential to leverage pretrained knowledge to learn feature representations that can be shared across future categories during the base session. Inspired by the mechanism of the CLS token, which is similar to human attention and progressively filters out task-irrelevant information, we propose the CLS Token Attention Steering Prompts (CASP). This approach introduces class-shared trainable bias parameters into the query, key, and value projections of the CLS token to explicitly modulate the self-attention weights. To further enhance generalization, we also design an attention perturbation strategy and perform Manifold Token Mixup in the shallow feature space, synthesizing potential new class features to improve generalization and reserve the representation capacity for upcoming tasks. Experiments on the CUB200, CIFAR100, and ImageNet-R datasets demonstrate that CASP outperforms state-of-the-art methods in both standard and fine-grained FSCIL settings without requiring fine-tuning during incremental phases and while significantly reducing the parameter overhead.

</details>


### [65] [SLD: Segmentation-Based Landmark Detection for Spinal Ligaments](https://arxiv.org/abs/2601.16782)
*Lara Blomenkamp,Ivanna Kramer,Sabine Bauer,Theresa Schöche*

Main category: cs.CV

TL;DR: 提出了一种结合形状分割和领域特定规则的方法，用于自动检测脊柱韧带附着点，该方法在不同脊柱区域均表现出高精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有脊柱韧带附着点自动检测方法存在局限性，如仅限于特定区域或精度不足，影响了生物力学模型的准确性。

Method: 首先对三维椎骨进行基于形状的分割，然后应用领域特定的规则来识别不同类型的附着点。

Result: 该方法在两个独立的脊柱数据集上进行了验证，平均绝对误差（MAE）为0.7毫米，均方根误差（RMSE）为1.1毫米，显示出高精度和良好的泛化能力。

Conclusion: 提出的自动检测脊柱韧带附着点的方法比现有方法更优越，能够实现高精度和跨区域的泛化，为构建可靠的脊柱模型提供了关键支持。

Abstract: In biomechanical modeling, the representation of ligament attachments is crucial for a realistic simulation of the forces acting between the vertebrae. These forces are typically modeled as vectors connecting ligament landmarks on adjacent vertebrae, making precise identification of these landmarks a key requirement for constructing reliable spine models. Existing automated detection methods are either limited to specific spinal regions or lack sufficient accuracy. This work presents a novel approach for detecting spinal ligament landmarks, which first performs shape-based segmentation of 3D vertebrae and subsequently applies domain-specific rules to identify different types of attachment points. The proposed method outperforms existing approaches by achieving high accuracy and demonstrating strong generalization across all spinal regions. Validation on two independent spinal datasets from multiple patients yielded a mean absolute error (MAE) of 0.7 mm and a root mean square error (RMSE) of 1.1 mm.

</details>


### [66] [ColorConceptBench: A Benchmark for Probabilistic Color-Concept Understanding in Text-to-Image Models](https://arxiv.org/abs/2601.16836)
*Chenxi Ruan,Yu Xiao,Yihan Hou,Guosheng Hu,Wei Zeng*

Main category: cs.CV

TL;DR: 本研究提出了ColorConceptBench基准，用于评估文本到图像模型对隐式颜色概念的理解能力，结果表明现有模型在抽象语义方面存在不足，且难以通过常规方法改进。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在关联颜色与隐式概念方面的能力尚未得到充分研究，研究旨在填补这一空白。

Method: 创建了一个包含1281个隐式颜色概念和6369个人工标注的人类标注基准ColorConceptBench，并用其评估了七个领先的文本到图像模型。

Result: 评估结果显示，当前模型对抽象语义的敏感度不足，并且这种局限性难以通过Scaling和Guidance等标准干预措施来克服。

Conclusion: 要实现类人水平的颜色语义理解，需要改变模型学习和表征隐式含义的方式，而不仅仅是扩大模型规模。

Abstract: While text-to-image (T2I) models have advanced considerably, their capability to associate colors with implicit concepts remains underexplored. To address the gap, we introduce ColorConceptBench, a new human-annotated benchmark to systematically evaluate color-concept associations through the lens of probabilistic color distributions. ColorConceptBench moves beyond explicit color names or codes by probing how models translate 1,281 implicit color concepts using a foundation of 6,369 human annotations. Our evaluation of seven leading T2I models reveals that current models lack sensitivity to abstract semantics, and crucially, this limitation appears resistant to standard interventions (e.g., scaling and guidance). This demonstrates that achieving human-like color semantics requires more than larger models, but demands a fundamental shift in how models learn and represent implicit meaning.

</details>


### [67] [Reward-Forcing: Autoregressive Video Generation with Reward Feedback](https://arxiv.org/abs/2601.16933)
*Jingran Zhang,Ning Li,Yuanhao Ban,Andrew Bai,Justin Cui*

Main category: cs.CV

TL;DR: 本研究提出了一种使用奖励信号指导自回归视频生成的新方法，旨在提高效率、可扩展性和生成质量，并与现有方法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 现有自回归视频生成方法在没有强大教师模型的情况下性能受限，且通常落后于双向模型。本研究旨在探索一种不依赖教师模型，同时能实现高效、可扩展且高质量自回归视频生成的新途径。

Method: 本研究提出了一种使用奖励信号来指导自回归视频生成过程的方法。这种方法通过奖励信号引导模型学习，简化了训练过程，同时保持了高视觉保真度和时间一致性。

Result: 实验结果表明，该方法在标准基准测试上的表现与现有自回归模型相当，并在某些情况下优于同等规模的双向模型。例如，在VBench上，该方法获得了84.92的总分，与需要异构蒸馏的最先进自回归方法（84.31分）相当。

Conclusion: 使用奖励信号指导自回归视频生成是一种有效且可扩展的方法，能够简化训练并生成高质量的视频，同时避免了依赖教师模型带来的局限性。

Abstract: While most prior work in video generation relies on bidirectional architectures, recent efforts have sought to adapt these models into autoregressive variants to support near real-time generation. However, such adaptations often depend heavily on teacher models, which can limit performance, particularly in the absence of a strong autoregressive teacher, resulting in output quality that typically lags behind their bidirectional counterparts. In this paper, we explore an alternative approach that uses reward signals to guide the generation process, enabling more efficient and scalable autoregressive generation. By using reward signals to guide the model, our method simplifies training while preserving high visual fidelity and temporal consistency. Through extensive experiments on standard benchmarks, we find that our approach performs comparably to existing autoregressive models and, in some cases, surpasses similarly sized bidirectional models by avoiding constraints imposed by teacher architectures. For example, on VBench, our method achieves a total score of 84.92, closely matching state-of-the-art autoregressive methods that score 84.31 but require significant heterogeneous distillation.

</details>


### [68] [SyncLight: Controllable and Consistent Multi-View Relighting](https://arxiv.org/abs/2601.16981)
*David Serrano-Lozano,Anand Bhattad,Luis Herranz,Jean-François Lalonde,Javier Vazquez-Corral*

Main category: cs.CV

TL;DR: SyncLight 是一种新的方法，首次实现了对静态场景多视图下一致的、参数化的重新照明，解决了现有生成方法在保持多视图照明一致性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有单视图重新照明技术虽然进步显著，但在多摄像机广播、立体电影和虚拟制作等场景中，保持多视图照明的一致性仍然是一个挑战。

Method: SyncLight 使用基于多视图扩散 Transformer 的方法，并采用潜在桥接匹配（latent bridge matching）配方进行训练，能够在一次推理中对整个图像集进行高保真重新照明，并实现了跨视图的光照强度和颜色的精确控制。

Result: SyncLight 能够零样本（zero-shot）地泛化到任意数量的视点，在不需要相机姿态信息的情况下，有效地将光照变化传播到所有视图，实现了高保真的多视图重新照明。

Conclusion: SyncLight 是一种实用的重新照明方法，为多视图捕获系统带来了高保真的、跨视图一致的重新照明能力，并能够通过单一参考编辑实现精确的光照控制。

Abstract: We present SyncLight, the first method to enable consistent, parametric relighting across multiple uncalibrated views of a static scene. While single-view relighting has advanced significantly, existing generative approaches struggle to maintain the rigorous lighting consistency essential for multi-camera broadcasts, stereoscopic cinema, and virtual production. SyncLight addresses this by enabling precise control over light intensity and color across a multi-view capture of a scene, conditioned on a single reference edit. Our method leverages a multi-view diffusion transformer trained using a latent bridge matching formulation, achieving high-fidelity relighting of the entire image set in a single inference step. To facilitate training, we introduce a large-scale hybrid dataset comprising diverse synthetic environments -- curated from existing sources and newly designed scenes -- alongside high-fidelity, real-world multi-view captures under calibrated illumination. Surprisingly, though trained only on image pairs, SyncLight generalizes zero-shot to an arbitrary number of viewpoints, effectively propagating lighting changes across all views, without requiring camera pose information. SyncLight enables practical relighting workflows for multi-view capture systems.

</details>


### [69] [Domain-invariant Mixed-domain Semi-supervised Medical Image Segmentation with Clustered Maximum Mean Discrepancy Alignment](https://arxiv.org/abs/2601.16954)
*Ba-Thinh Lam,Thanh-Huy Nguyen,Hoang-Thien Nguyen,Quang-Khai Bui-Tran,Nguyen Lan Vi Vu,Phat K. Huynh,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: 提出了一种领域不变的混合域半监督分割框架，通过数据增强（Copy-Paste Mechanism）和无监督特征对齐（Cluster Maximum Mean Discrepancy）来解决医学图像分割中标签稀缺和数据分布不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界的医学图像分割面临标签稀缺和混合域（来自不同设备或中心，领域标签未知）的挑战，现有方法通常假设单一域偏移或已知域索引，这不适用于实际情况。

Method: 提出了一个结合Copy-Paste Mechanism（CPM）和Cluster Maximum Mean Discrepancy（CMMD）块的混合域半监督分割框架。CPM通过跨域复制粘贴来增加训练数据多样性；CMMD块则对无标签特征进行聚类，并使用MMD目标将其与有标签的锚点对齐，以促进领域不变性。

Result: 该框架在Fundus和M&Ms数据集上的实验表明，即使在标记样本极少且存在多个未知域差异的情况下，也能实现鲁棒且精确的分割，性能优于现有的半监督和域自适应方法。

Conclusion: 该研究提出了一种有效的混合域半监督医学图像分割解决方案，能够处理标签稀缺和混合域数据，有效提升分割性能。

Abstract: Deep learning has shown remarkable progress in medical image semantic segmentation, yet its success heavily depends on large-scale expert annotations and consistent data distributions. In practice, annotations are scarce, and images are collected from multiple scanners or centers, leading to mixed-domain settings with unknown domain labels and severe domain gaps. Existing semi-supervised or domain adaptation approaches typically assume either a single domain shift or access to explicit domain indices, which rarely hold in real-world deployment. In this paper, we propose a domain-invariant mixed-domain semi-supervised segmentation framework that jointly enhances data diversity and mitigates domain bias. A Copy-Paste Mechanism (CPM) augments the training set by transferring informative regions across domains, while a Cluster Maximum Mean Discrepancy (CMMD) block clusters unlabeled features and aligns them with labeled anchors via an MMD objective, encouraging domain-invariant representations. Integrated within a teacher-student framework, our method achieves robust and precise segmentation even with very few labeled examples and multiple unknown domain discrepancies. Experiments on Fundus and M&Ms benchmarks demonstrate that our approach consistently surpasses semi-supervised and domain adaptation methods, establishing a potential solution for mixed-domain semi-supervised medical image segmentation.

</details>


### [70] [VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents](https://arxiv.org/abs/2601.16973)
*Zirui Wang,Junyi Zhang,Jiaxin Ge,Long Lian,Letian Fu,Lisa Dunlap,Ken Goldberg,XuDong Wang,Ion Stoica,David M. Chan,Sewon Min,Joseph E. Gonzalez*

Main category: cs.CV

TL;DR: 本文提出了 VisGym，一个包含17个环境的视觉-语言模型（VLM）评估和训练框架，用于评估VLM在多步视觉交互中的表现。研究发现现有VLM在交互式设置中表现不佳，并且在利用长上下文方面存在困难，但明确的目标观测、文本反馈和探索性演示能有效提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前先进的视觉-语言模型（VLM）在多步视觉交互中的表现，尤其是在整合感知、记忆和长期规划方面，仍未得到充分的表征。因此，需要一个专门的评估和训练框架来深入研究这些问题。

Method: 引入了一个名为 VisGym 的框架，包含17个不同类型的环境（符号谜题、真实图像理解、导航、操控等），并允许灵活调整难度、输入表示、规划视野和反馈机制。同时，开发了多步求解器生成结构化演示，用于监督微调。通过在 VisGym 中对现有VLM进行评估。

Result: 所有先进的VLM在交互式设置中表现不佳，在简单和困难配置下的成功率分别为46.6%和26.0%。模型难以有效利用长上下文，无界历史记录的表现不如截断窗口。将文本符号任务视觉化后，难度会显著增加。然而，明确的目标观测、文本反馈以及在部分可观察或未知动力学环境中的探索性演示，可以通过监督微调带来一致的性能提升。

Conclusion: VisGym框架揭示了现有VLM在多步视觉决策方面存在的显著局限性，特别是在长上下文利用和处理视觉化符号任务时。研究强调了目标观测、文本反馈和探索性演示对于改进VLM多步视觉决策能力的重要性，为未来的研究指明了方向。

Abstract: Modern Vision-Language Models (VLMs) remain poorly characterized in multi-step visual interactions, particularly in how they integrate perception, memory, and action over long horizons. We introduce VisGym, a gymnasium of 17 environments for evaluating and training VLMs. The suite spans symbolic puzzles, real-image understanding, navigation, and manipulation, and provides flexible controls over difficulty, input representation, planning horizon, and feedback. We also provide multi-step solvers that generate structured demonstrations, enabling supervised finetuning. Our evaluations show that all frontier models struggle in interactive settings, achieving low success rates in both the easy (46.6%) and hard (26.0%) configurations. Our experiments reveal notable limitations: models struggle to effectively leverage long context, performing worse with an unbounded history than with truncated windows. Furthermore, we find that several text-based symbolic tasks become substantially harder once rendered visually. However, explicit goal observations, textual feedback, and exploratory demonstrations in partially observable or unknown-dynamics settings for supervised finetuning yield consistent gains, highlighting concrete failure modes and pathways for improving multi-step visual decision-making. Code, data, and models can be found at: https://visgym.github.io/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [71] [ChiEngMixBench: Evaluating Large Language Models on Spontaneous and Natural Chinese-English Code-Mixed Generation](https://arxiv.org/abs/2601.16217)
*Qingyan Yang,Tongxi Wang,Yunsheng Luo*

Main category: cs.CL

TL;DR: 本文提出了 ChiEngMixBench 基准，用于评估大型语言模型在真实语境下的中英夹码能力，将其视为一种认知对齐问题，通过自发性和自然度两个指标来衡量，并发现了模型中隐含的术语分层策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究将夹码视为翻译问题，难以评估模型在真实语境下是否能进行恰当的语码转换。需要一个能够衡量模型夹码能力是否符合人类习惯和语境的基准。

Method: 构建了 ChiEngMixBench 基准，该基准基于一个通用的数据集开发流水线，能够支持跨领域和多语言对的扩展。将夹码问题定义为认知对齐问题，并引入了“自发性”和“自然度”两个指标来评估模型表现。

Result: 经验性评估表明，所提出的指标能够系统地区分不同模型在夹码任务上的表现。此外，研究发现了模型中隐含的“术语分层策略”，该现象与矩阵语言框架（MLF）理论一致，表明模型在多语言夹码方面与人类沟通存在结构化的认知对齐。

Conclusion: ChiEngMixBench 是首个用于评估语言模型夹码能力的基准，它将夹码视为认知对齐问题，并通过自发性和自然度指标进行量化。研究结果表明，大型语言模型在夹码任务上表现出与人类相似的认知对齐策略，特别是术语分层策略。

Abstract: Code-mixing is increasingly prevalent in interactions between humans and large language models, yet existing work often reduces it to a translation or convertibility problem, making it difficult to assess whether a model's switching behavior is context-appropriate and aligned with human conventions. We introduce ChiEngMixBench, the first benchmark designed to evaluate code-mixing ability in authentic community contexts, built upon a general construction pipeline that enables scalable dataset development across domains and bilingual pairs. ChiEngMixBench formulates code-mixing as a cognitive alignment problem, characterized by two complementary signals: Spontaneity and Naturalness. Empirical evaluation shows that our metrics can systematically distinguish code-mixing performance across models. Beyond benchmarking, we further uncover an implicitly emergent Terminology Layering Strategy, a phenomenon consistent with the Matrix Language Frame (MLF) theory, indicating structured cognitive alignment between multilingual large language models and human communication.

</details>


### [72] [Domain Specific Specialization in Low-Resource Settings: The Efficacy of Offline Response-Based Knowledge Distillation in Large Language Models](https://arxiv.org/abs/2601.16219)
*Erdem Aslan,Pakize Erdoğmuş*

Main category: cs.CL

TL;DR: 该研究提出了一种离线基于响应的知识蒸馏方法，利用少量高质量的上下文感知合成数据，成功训练出高精度、低资源消耗的领域专用 LLM 助手，验证了数据质量和结构对小样本领域适应的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在处理领域特定或机构知识时容易产生幻觉，并且在受限的硬件资源下开发高精度专用助手面临挑战。

Method: 研究采用离线基于响应的知识蒸馏方法。评估了三种数据策略：通用领域适应、非结构化知识注入和上下文感知合成数据集。使用 Unsloth 库优化 Qwen-2.5-7B 模型，显著降低了 GPU 内存需求。

Result: 上下文感知合成数据集（500 行）在不产生幻觉的情况下，实现了 96.7% 的准确率和强大的拒绝能力。相比之下，规模更大的非结构化数据集仍然存在幻觉问题。

Conclusion: 在低资源设置下进行领域适应时，数据的质量和结构化对齐比数量更为关键，这支持了 LIMA 假设。

Abstract: Large Language Models (LLMs) excel in general tasks but often struggle with hallucinations when handling domain-specific or institutional knowledge absent from their pre-training. We present an offline response-based knowledge distillation method that develops high-accuracy specialized assistants under constrained hardware resources. We evaluate three distinct data strategies: general domain adaptation (15,000 lines), unstructured knowledge injection (2,000 lines), and a context-aware synthetic dataset (500 lines) generated by a teacher model. To minimize computational costs, we utilize the Unsloth library to optimize the Qwen-2.5-7B student model, reducing NVIDIA A100 GPU memory requirements from 40 GB to 16 GB. Experimental results demonstrate that while larger unstructured datasets suffer from persistent hallucinations, the 500-line context-aware dataset achieves a 96.7% accuracy rate and robust rejection capability. These findings validate the LIMA hypothesis, showing that data quality and structural alignment are more critical than quantity for domain adaptation in low-resource settings.

</details>


### [73] [M3Kang: Evaluating Multilingual Multimodal Mathematical Reasoning in Vision-Language Models](https://arxiv.org/abs/2601.16218)
*Aleix Torres-Camps,Nathaniel Mitrani Hadida,Víctor Conchello Vendrell,Àlex Batlle Casellas,Arnau Padrés Masdemont,Jordi Ros-Giralt*

Main category: cs.CL

TL;DR: 本文提出了M3Kang，一个大规模多语言、多模态数学推理数据集，该数据集源自袋鼠数学竞赛，包含108种语言的1747个问题，并对现有模型进行了基准测试，发现模型在基础数学和图示推理方面表现不佳，但多语言技术有所帮助。同时，研究还将模型表现与超过68,000名学生的表现进行了对比。


<details>
  <summary>Details</summary>
Motivation: 现有先进的视觉语言模型（VLMs）在多语言数学推理方面的能力尚未得到充分探索，特别是与人类表现的差距，促使研究者创建M3Kang数据集以填补这一空白。

Method: 构建了一个名为M3Kang的大规模多语言、多模态数学推理数据集，该数据集源自袋鼠数学竞赛，包含108种语言的1747个多项选择题，并按年级难度划分。使用该数据集对现有先进的闭源和开源模型进行了广泛的基准测试，并分析了模型表现与语言、模型大小和年级水平的关系。此外，还将模型表现与68,000多名学生的表现进行比较。

Result: 基准测试结果显示，尽管模型取得了进展，但在基础数学和图示推理方面仍存在困难。模型的表现随语言数量和模型大小的增加而提升，但并未随年级水平的提高而改善。多语言技术被证明可以有效地扩展到多模态设置，从而显著提高模型性能。模型在某些低资源语言上的表现尤为薄弱。

Conclusion: M3Kang数据集为评估和提升VLMs在多语言多模态数学推理方面的能力提供了一个新的基准。研究结果表明，尽管模型在数学推理方面取得了一定进步，但仍有很大的提升空间，尤其是在处理图示信息和低资源语言方面。多语言和多模态方法的结合对提升模型性能至关重要。

Abstract: Despite state-of-the-art vision-language models (VLMs) have demonstrated strong reasoning capabilities, their performance in multilingual mathematical reasoning remains underexplored, particularly when compared to human performance. To bridge this gap, we introduce M3Kang, the first massively multilingual, multimodal mathematical reasoning dataset for VLMs. It is derived from the Kangaroo Math Competition, the world's largest mathematics contest, which annually engages over six million participants under the age of 18 across more than 90 countries. M3Kang includes 1,747 unique multiple-choice problems organized by grade-level difficulty, with translations into 108 culturally diverse languages, some of them including diagrams essential for solving them. Using this dataset, we conduct extensive benchmarking on both closed- and open-source SOTA models. We observe that, despite recent advances, models still struggle with basic math and diagram-based reasoning, with performance scaling with language presence and model size, but not with grade level. We also find that multilingual techniques can be effectively extended to the multimodal setting, resulting in significant improvements over baseline approaches. Our analysis also incorporates performance data from over 68,000 students, enabling direct comparison with human performance. We are open-sourcing M3Kang, including the English-only subset M2Kang, along with the framework and codebase used to construct the dataset.

</details>


### [74] [Towards Latent Diffusion Suitable For Text](https://arxiv.org/abs/2601.16220)
*Nesta Midavaine,Christian A. Naesseth,Grigory Bartosh*

Main category: cs.CL

TL;DR: 提出了一种名为神经流扩散模型（NFDM）的新型语言生成模型，该模型通过将连续扩散模型扩展到离散状态空间，实现了更快的采样速度和更好的连贯性，并取得了与现有模型相当的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归语言模型采样速度慢且连贯性有待提高，促使研究人员探索新的语言生成方法，例如扩散模型。

Method: 该研究将连续扩散模型扩展到离散状态空间，提出神经流扩散模型（NFDM）。NFDM学习数据的多变量前向过程，确保其与语言建模的生成轨迹相匹配，从而实现快速高效的语言生成。

Result: NFDM显著减小了与同等规模自回归模型之间的似然差距，同时生成的样本质量与之前的潜在扩散模型相当。

Conclusion: NFDM是一种有效的语言生成模型，能够克服自回归模型的局限性，提供更快的采样速度和更好的连贯性，并且生成质量与现有先进模型相当。

Abstract: Language diffusion models aim to improve sampling speed and coherence over autoregressive LLMs. We introduce Neural Flow Diffusion Models for language generation, an extension of NFDM that enables the straightforward application of continuous diffusion models to discrete state spaces. NFDM learns a multivariate forward process from the data, ensuring that the forward process and generative trajectory are a good fit for language modeling. Our model substantially reduces the likelihood gap with autoregressive models of the same size, while achieving sample quality comparable to that of previous latent diffusion models.

</details>


### [75] [Limits of n-gram Style Control for LLMs via Logit-Space Injection](https://arxiv.org/abs/2601.16224)
*Sami-ul Ahmed*

Main category: cs.CL

TL;DR: 研究人员提出了一种在 LLM 解码时通过 n-gram 风格先验在 logit 空间中进行风格控制的轻量级方法。实验表明，这种方法在特定情况下（如使用 Don Quixote 语料库和低 lambda 值）可以提高风格和流畅度，但总体上表现 fragile，且优于提示工程和 LoRA。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 个性化方法（如提示工程和 LoRA）存在局限性，前者难以将写作风格浓缩到单个提示中，后者需要计算密集型的训练和基础设施。因此，研究人员希望找到一种更轻量级的替代方案。

Method: 在 LLM 解码时，通过在 logit 空间中注入 n-gram 风格先验来控制文本风格。具体做法是，训练一个 n-gram 模型（1-到-3-gram），然后通过一个可控参数 lambda 加权 n-gram 风格的 log-probabilities 来修改 LLM 的 logits。

Result: 在 TinyLlama-1.1B 模型上，当使用 Don Quixote 语料库且 lambda=0.1 时，风格困惑度相对冻结模型提高了 24.7%，基础模型困惑度提高了 51.4%。然而，在其他语料库（如 CNN/DailyMail 和 arXiv abstracts）或较大的 lambda 值下，该方法性能下降，甚至导致文本崩溃和不连贯。

Conclusion: 在 logit 空间中注入 n-gram 风格先验是一种轻量级、可调的风格控制方法，但其效果非常 fragile，仅在低 lambda 值下狭窄范围内有效，并且整体上不如提示工程和 LoRA。

Abstract: Large language models (LLMs) are typically personalized via prompt engineering or parameter-efficient fine-tuning such as LoRA. However, writing style can be difficult to distill into a single prompt, and LoRA fine-tuning requires computationally intensive training and infrastructure. We investigate a possible lightweight alternative: steering a frozen LLM with n-gram style priors injected in logit space at decoding time. We train an n-gram model on stylistically distinct corpora -- including Don Quixote, CNN/DailyMail news headlines, and arXiv abstracts -- constructing an interpolated 1-to-3-gram prior over next-token probabilities. During generation we modify the LLM's logits by adding a weighted sum of style log-probabilities from each n-gram order that matches the current context, scaled by a control parameter lambda in [0, 1].
  We sweep lambda and style corpora and report style perplexity under the n-gram model, base-model perplexity as a proxy for fluency, Jensen-Shannon (JS) divergence between the original and steered token distributions, and token-overlap statistics. On TinyLlama-1.1B we identify a single narrow regime (for the Don Quixote corpus at lambda=0.1) where style perplexity improves by 24.7% and base-model perplexity improves by 51.4% relative to the frozen model. Outside this regime, and for multi-author corpora such as CNN/DailyMail and arXiv abstracts, even small nonzero lambda values generally result in worse style and fluency, and larger lambda values lead to collapse with extreme perplexities and incoherent text. Logit-space injection of n-gram style priors provides lightweight, tunable style control, but it is fragile: it operates effectively only within a narrow range of low lambda values and is consistently outperformed by prompting and LoRA.

</details>


### [76] [GameTalk: Training LLMs for Strategic Conversation](https://arxiv.org/abs/2601.16276)
*Victor Conchello Vendrell,Max Ruiz Luyten,Mihaela van der Schaar*

Main category: cs.CL

TL;DR: 本文提出了一种名为GameTalk的框架，用于训练大型语言模型（LLMs）通过多轮对话进行战略决策，并优化长期目标，在复杂博弈游戏中取得了显著优于未训练模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在多智能体、长期对话中的战略决策和谈判能力不足，现有研究多关注单轮目标或静态动作预测，缺乏对通过对话优化长期目标的探索。

Method: 提出GameTalk框架，通过修改GRPO、DPO和STaR等微调方法，使其能够纳入依赖于整个交互过程的奖励信号，从而训练LLMs优化全局目标。

Result: GameTalk框架在设计用于测试推理、协调和对手建模的系列复杂游戏中，显著优于未训练模型，尤其是在奖励塑造（reward shaping）的帮助下。其中，DPO方法表现出最强的性能提升。

Conclusion: 对话式微调是训练LLMs在交互式环境中进行推理、谈判和行动的有前景的方法，GameTalk框架为实现这一目标提供了一种有效途径。

Abstract: Strategic decision-making in multi-agent settings is a key challenge for large language models (LLMs), particularly when coordination and negotiation must unfold over extended conversations. While recent work has explored the use of LLMs in isolated decision tasks, little attention has been given to optimizing long-term objectives through dialogue. We introduce \textbf{GameTalk}, a framework for training LLMs to make strategic decisions via multi-turn interactions. Unlike prior work that focuses on single-turn objectives or static action prediction, we train LLMs to optimize a global objective across full conversations. We achieve this by adapting fine-tuning methods like GRPO, DPO, and STaR to incorporate reward signals that depend on the entire interaction. We evaluate this approach on a suite of increasingly complex games, designed to stress different aspects of reasoning, coordination, and opponent modeling. Our results show that GameTalk significantly outperforms untrained models, especially under reward shaping, with DPO consistently yielding the strongest gains. These findings position conversational fine-tuning as a promising path for LLMs to reason, negotiate, and act in interactive environments.

</details>


### [77] [Better as Generators Than Classifiers: Leveraging LLMs and Synthetic Data for Low-Resource Multilingual Classification](https://arxiv.org/abs/2601.16278)
*Branislav Pecher,Jan Cegin,Robert Belanec,Ivan Srba,Jakub Simko,Maria Bielikova*

Main category: cs.CL

TL;DR: 本文研究了利用大型语言模型（LLMs）生成合成数据，用于训练更小的多语言模型，并探索了这种“知识蒸馏”方法的效果。结果表明，即使是少量合成数据也能使小型模型在低资源语言任务上超越大型生成模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多语言任务上表现出色，但其规模庞大。研究者希望探索LLMs是否能通过生成合成数据来“蒸馏”知识，训练出更小、更高效、性能相当甚至更好的多语言模型，尤其是在低资源语言场景下，以解决数据稀缺的问题。

Method: 使用一个先进的多语言LLM生成了涵盖11种语言和4种分类任务的合成数据集。然后，将这些合成数据集用于训练更小的模型（通过微调或指令调优），或者作为紧凑型LLMs的合成上下文示例。

Result: 实验证明，即使使用少量合成数据，小型模型也能在低资源语言的任务上超越作为“教师”的大型生成模型。这表明LLMs作为数据生成器比直接作为分类器更具价值。

Conclusion: 大型语言模型在作为数据生成器（教师）方面比作为分类器更有优势，它们生成的合成数据能够赋能更小、更高效的多语言模型，尤其是在低资源语言场景下，可以实现性能的提升。

Abstract: Large Language Models (LLMs) have demonstrated remarkable multilingual capabilities, making them promising tools in both high- and low-resource languages. One particularly valuable use case is generating synthetic samples that can be used to train smaller models in low-resource scenarios where human-labelled data is scarce. In this work, we investigate whether these synthetic data generation capabilities can serve as a form of distillation, producing smaller models that perform on par with or even better than massive LLMs across languages and tasks. To this end, we use a state-of-the-art multilingual LLM to generate synthetic datasets covering 11 languages and 4 classification tasks. These datasets are then used to train smaller models via fine-tuning or instruction tuning, or as synthetic in-context examples for compact LLMs. Our experiments show that even small amounts of synthetic data enable smaller models to outperform the large generator itself, particularly in low-resource languages. Overall, the results suggest that LLMs are best utilised as generators (teachers) rather than classifiers, producing data that empowers smaller and more efficient multilingual models.

</details>


### [78] [Generating Literature-Driven Scientific Theories at Scale](https://arxiv.org/abs/2601.16282)
*Peter Jansen,Peter Clark,Doug Downey,Daniel S. Weld*

Main category: cs.CL

TL;DR: 本研究提出了一种从大量科学文献中生成定性和定量定律理论的方法，并进行了大规模实验，证明了基于文献的方法在匹配现有证据和预测未来结果方面优于仅使用参数化知识的方法。


<details>
  <summary>Details</summary>
Motivation: 当前自动科学发现主要集中在实验生成，而理论构建等更高级的科学活动研究不足。

Method: 在 13.7k 篇文献上训练模型，生成 2.9k 个理论。对比了基于文献和基于参数化知识的生成方式，以及精度优先和新颖性优先的生成目标，并使用后续 4.6k 篇论文进行评估。

Result: 相比于仅使用参数化 LLM 记忆进行生成，基于文献支持的方法生成的理论在匹配现有证据和预测未来结果方面均表现显著更好。

Conclusion: 基于文献的方法在科学理论生成方面比仅依赖模型内部知识更有效，能够生成与现有证据更好地吻合且更具预测能力的理论。

Abstract: Contemporary automated scientific discovery has focused on agents for generating scientific experiments, while systems that perform higher-level scientific activities such as theory building remain underexplored. In this work, we formulate the problem of synthesizing theories consisting of qualitative and quantitative laws from large corpora of scientific literature. We study theory generation at scale, using 13.7k source papers to synthesize 2.9k theories, examining how generation using literature-grounding versus parametric knowledge, and accuracy-focused versus novelty-focused generation objectives change theory properties. Our experiments show that, compared to using parametric LLM memory for generation, our literature-supported method creates theories that are significantly better at both matching existing evidence and at predicting future results from 4.6k subsequently-written papers

</details>


### [79] [Teaching and Evaluating LLMs to Reason About Polymer Design Related Tasks](https://arxiv.org/abs/2601.16312)
*Dikshya Mohanty,Mohammad Saqib Hasan,Syed Mostofa Monsur,Size Zheng,Benjamin Hsiao,Niranjan Balasubramanian*

Main category: cs.CL

TL;DR: 本文提出 PolyBench，一个包含超过 12.5 万个聚合物设计任务的大规模训练和测试基准数据集，并辅以知识增强推理蒸馏方法，以改进用于聚合物设计的语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在聚合物设计领域表现不佳，主要原因是它们缺乏聚合物相关的特定知识以及相关知识和能力的覆盖范围不足。

Method: 构建了一个包含超过 12.5 万个聚合物设计任务的大规模数据集 PolyBench，并利用包含 1300 万个数据点的知识库来确保覆盖广泛的聚合物及其性质。提出了一种知识增强推理蒸馏方法，通过结构化思维链（CoT）来增强数据集。PolyBench 中的任务从简单到复杂进行组织，以进行泛化测试和诊断探查。

Result: 使用 PolyBench 训练的小型语言模型（7B 到 14B 参数）在 PolyBench 测试数据集上的表现优于同等规模的模型，甚至优于闭源的前沿 LLMs，并且在其他聚合物基准测试中也显示出性能提升。

Conclusion: PolyBench 数据集和提出的知识增强推理蒸馏方法能够有效地改进用于聚合物设计的语言模型，即使是小型语言模型也能在这一领域取得优异的性能。

Abstract: Research in AI4Science has shown promise in many science applications, including polymer design. However, current LLMs prove ineffective on this problem space because: (i) most models lack polymer-specific knowledge (ii) existing aligned models lack coverage of knowledge and capabilities relevant to polymer design. Addressing this, we introduce PolyBench, a large scale training and test benchmark dataset of more than 125K polymer design related tasks, leveraging a knowledge base of 13M+ data points obtained from experimental and synthetic sources to ensure broad coverage of polymers and their properties. For effective alignment using PolyBench, we introduce a knowledge-augmented reasoning distillation method that augments this dataset with structured CoT. Furthermore, tasks in PolyBench are organized from simple to complex analytical reasoning problems, enabling generalization tests and diagnostic probes across the problem space. Experiments show that small language models (SLMs), of 7B to 14B parameters, trained on PolyBench data outperform similar sized models, and even closed source frontier LLMs on PolyBench test dataset while demonstrating gains on other polymer benchmarks as well.

</details>


### [80] [A Longitudinal, Multinational, and Multilingual Corpus of News Coverage of the Russo-Ukrainian War](https://arxiv.org/abs/2601.16309)
*Dikshya Mohanty,Taisiia Sabadyn,Jelwin Rodrigues,Chenlu Wang,Abhishek Kalugade,Ritwik Banerjee*

Main category: cs.CL

TL;DR: 本文介绍了DNIPRO，一个包含24.6万篇关于俄乌战争的新闻文章的纵向语料库，涵盖了来自五个国家、三种语言的十一家媒体。该语料库具有全面的元数据和多种标注，适用于跨国议题分析，特别是研究叙事分歧、媒体框架和信息战。实验表明，不同媒体的报道反映了地缘政治利益，构建了相互竞争的现实。


<details>
  <summary>Details</summary>
Motivation: 研究俄乌战争期间不同媒体如何构建和传播相互竞争的地缘政治观点，理解叙事分歧、媒体框架和信息战，为计算新闻学和跨国叙事研究提供基础资源。

Method: 构建了一个包含24.6万篇新闻文章的纵向语料库（DNIPRO），涵盖2022年2月至2024年8月，来自俄、乌、美、英、中五国的十一家媒体，使用英、俄、中三种语言。语料库包含一致且全面的元数据，并进行了多类型标注，并通过人类评估进行了严谨的验证。同时，利用该语料库进行了立场检测、情感分析、话题框架和矛盾分析等用例实验。

Result: 通过用例实验，展示了不同媒体如何构建相互竞争的现实，其报道呈现出反映地缘政治利益的两极化解读。

Conclusion: DNIPRO是一个独特且有价值的多语言资源，能够支持对冲突时期跨国话语的系统性分析，尤其适用于研究叙事分歧、媒体框架和信息战。该语料库不仅能促进计算新闻学研究，还能为理解冲突叙事的形成和演变提供基础。

Abstract: We introduce DNIPRO, a novel longitudinal corpus of 246K news articles documenting the Russo-Ukrainian war from Feb 2022 to Aug 2024, spanning eleven media outlets across five nation states (Russia, Ukraine, U.S., U.K., and China) and three languages (English, Russian, and Mandarin Chinese). This multilingual resource features consistent and comprehensive metadata, and multiple types of annotation with rigorous human evaluations for downstream tasks relevant to systematic transnational analyses of contentious wartime discourse. DNIPRO's distinctive value lies in its inclusion of competing geopolitical perspectives, making it uniquely suited for studying narrative divergence, media framing, and information warfare. To demonstrate its utility, we include use case experiments using stance detection, sentiment analysis, topical framing, and contradiction analysis of major conflict events within the larger war. Our explorations reveal how outlets construct competing realities, with coverage exhibiting polarized interpretations that reflect geopolitical interests. Beyond supporting computational journalism research, DNIPRO provides a foundational resource for understanding how conflicting narratives emerge and evolve across global information ecosystems.

</details>


### [81] [Machine-Assisted Grading of Nationwide School-Leaving Essay Exams with LLMs and Statistical NLP](https://arxiv.org/abs/2601.16314)
*Andres Karjus,Kais Allkivi,Silvia Maine,Katarin Leppik,Krister Kruusmaa,Merilin Aruvee*

Main category: cs.CL

TL;DR: 本研究评估了使用大型语言模型（LLM）对爱沙尼亚全国性毕业考试作文进行自动评分的可行性，结果表明LLM评分与人类评分员相当，并能提供个性化反馈，证明了在国家层面实施LLM辅助评估的可行性。


<details>
  <summary>Details</summary>
Motivation: 在需要快速、大规模地评估开放式考试答卷，特别是像国家级毕业考试这类时间紧迫的情况下，对需要人工判断的内容和论证维度进行自动化评估尤为重要。

Method: 研究人员将官方课程标准评分细则应用于两个爱沙尼亚全国性模拟考试作文数据集，并通过LLM和统计自然语言处理（NLP）技术进行评估，然后将自动评分结果与人类评分员的评分进行比较。此外，还评估了偏见、提示注入风险以及LLM作为作文写作者的能力。

Result: 研究结果显示，自动评分（特别是LLM）的性能与人类评分员相当，并且评分结果通常在人类评分范围内。LLM能够生成细粒度的子分数，用于提供系统化、个性化的反馈。

Conclusion: 本研究证明，基于评分细则、由人类监督的LLM评分流程可以用于高风险的写作评估，这对于即将采用全电子化考试系统的爱沙尼亚等数字化社会尤其具有现实意义。LLM辅助评估即使在小语种国家层面也能实施，同时能保持人类监督并符合新兴的教育和监管标准。

Abstract: Large language models (LLMs) enable rapid and consistent automated evaluation of open-ended exam responses, including dimensions of content and argumentation that have traditionally required human judgment. This is particularly important in cases where a large amount of exams need to be graded in a limited time frame, such as nation-wide graduation exams in various countries. Here, we examine the applicability of automated scoring on two large datasets of trial exam essays of two full national cohorts from Estonia. We operationalize the official curriculum-based rubric and compare LLM and statistical natural language processing (NLP) based assessments with human panel scores. The results show that automated scoring can achieve performance comparable to that of human raters and tends to fall within the human scoring range. We also evaluate bias, prompt injection risks, and LLMs as essay writers. These findings demonstrate that a principled, rubric-driven, human-in-the-loop scoring pipeline is viable for high-stakes writing assessment, particularly relevant for digitally advanced societies like Estonia, which is about to adapt a fully electronic examination system. Furthermore, the system produces fine-grained subscore profiles that can be used to generate systematic, personalized feedback for instruction and exam preparation. The study provides evidence that LLM-assisted assessment can be implemented at a national scale, even in a small-language context, while maintaining human oversight and compliance with emerging educational and regulatory standards.

</details>


### [82] [Regional Bias in Large Language Models](https://arxiv.org/abs/2601.16349)
*M P V S Gopinadh,Kappara Lakshmi Sindhu,Soma Sekhar Pandu Ranga Raju P,Yesaswini Swarna*

Main category: cs.CL

TL;DR: 本研究评估了十个大型语言模型（LLM）的区域偏见，并引入了一个名为FAZE的评估框架，发现模型之间的偏见程度存在显著差异，GPT-3.5偏见最高，Claude 3.5 Sonnet偏见最低。


<details>
  <summary>Details</summary>
Motivation: AI公平性和全球代表性方面的日益增长的担忧，特别是大型语言模型（LLM）中可能存在的区域偏见。

Method: 使用包含100个精心设计的、探究区域间强制选择决策的提示（在上下文无关的情况下）的数据集，评估了十种主流LLM。引入了FAZE（一个基于提示的评估框架），以10分制衡量区域偏见。

Result: 不同模型之间存在显著的偏见水平差异。GPT-3.5的偏见得分最高（9.5），而Claude 3.5 Sonnet的偏见得分最低（2.5）。

Conclusion: 区域偏见可能严重损害LLM输出在现实世界跨文化应用中的可靠性、公平性和包容性。这项工作强调了包容性评估框架和识别、缓解语言模型中地理偏见系统性方法的重要性。

Abstract: This study investigates regional bias in large language models (LLMs), an emerging concern in AI fairness and global representation. We evaluate ten prominent LLMs: GPT-3.5, GPT-4o, Gemini 1.5 Flash, Gemini 1.0 Pro, Claude 3 Opus, Claude 3.5 Sonnet, Llama 3, Gemma 7B, Mistral 7B, and Vicuna-13B using a dataset of 100 carefully designed prompts that probe forced-choice decisions between regions under contextually neutral scenarios. We introduce FAZE, a prompt-based evaluation framework that measures regional bias on a 10-point scale, where higher scores indicate a stronger tendency to favor specific regions. Experimental results reveal substantial variation in bias levels across models, with GPT-3.5 exhibiting the highest bias score (9.5) and Claude 3.5 Sonnet scoring the lowest (2.5). These findings indicate that regional bias can meaningfully undermine the reliability, fairness, and inclusivity of LLM outputs in real-world, cross-cultural applications. This work contributes to AI fairness research by highlighting the importance of inclusive evaluation frameworks and systematic approaches for identifying and mitigating geographic biases in language models.

</details>


### [83] [Identity, Cooperation and Framing Effects within Groups of Real and Simulated Humans](https://arxiv.org/abs/2601.16355)
*Suhong Moon,Minwoo Kang,Joseph Suh,Mustafa Safdari,John Canny*

Main category: cs.CL

TL;DR: 研究表明，通过为大型语言模型（LLM）提供丰富的叙事身份和背景信息，可以更准确地模拟人类在社会困境游戏中的行为，并且LLM还可以建模时间、提问方式和参与者群体等背景因素。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注通过“引导”（弱绑定）聊天模型来模拟人物，但本研究旨在探索通过对基础模型进行深度绑定（例如，扩展的背景故事）来更真实地复制基于身份的行为。此外，研究还希望利用LLM来探索影响人类研究但常被忽略的细节，以提高研究的可复制性。

Method: 研究通过为基础LLM提供丰富的叙事身份背景信息，并利用指令微调模型进行一致性检查，来提升模拟人类行为的保真度。同时，研究还测试了LLM对时间（研究年份）、提问方式和参与者群体等上下文因素的建模能力。

Result: 研究发现，深度绑定LLM（使用丰富的叙事身份）相比于弱绑定（引导式）能更准确地模拟人类在社会困境游戏中的行为。LLM能够有效建模时间、提问方式和参与者群体等上下文因素。

Conclusion: 通过为LLM提供深度叙事身份和背景信息，可以显著提高其模拟人类行为的保真度。LLM不仅能模拟身份因素，还能模拟上下文因素，为研究人类行为的细节提供了一个有力的工具，并有助于提高实验的可复制性。

Abstract: Humans act via a nuanced process that depends both on rational deliberation and also on identity and contextual factors. In this work, we study how large language models (LLMs) can simulate human action in the context of social dilemma games. While prior work has focused on "steering" (weak binding) of chat models to simulate personas, we analyze here how deep binding of base models with extended backstories leads to more faithful replication of identity-based behaviors. Our study has these findings: simulation fidelity vs human studies is improved by conditioning base LMs with rich context of narrative identities and checking consistency using instruction-tuned models. We show that LLMs can also model contextual factors such as time (year that a study was performed), question framing, and participant pool effects. LLMs, therefore, allow us to explore the details that affect human studies but which are often omitted from experiment descriptions, and which hamper accurate replication.

</details>


### [84] [PolyAgent: Large Language Model Agent for Polymer Design](https://arxiv.org/abs/2601.16376)
*Vani Nigam,Achuth Chandrasekhar,Amir Barati Farimani*

Main category: cs.CL

TL;DR: 本文提出一个集成在终端的闭环高分子结构-性质预测器，利用大语言模型（LLM）进行推理，帮助研究人员进行早期高分子发现，提供性质预测、属性引导的结构生成和结构修改功能，并考虑了合成可及性。


<details>
  <summary>Details</summary>
Motivation: 传统的高分子实验过程耗时耗力，而现有的机器学习模型因基础设施限制难以被实验室研究人员直接使用，因此需要一个易于访问的工具来加速高分子发现。

Method: 开发了一个闭环高分子结构-性质预测框架，集成了LLM推理能力，能够进行性质预测、基于性质的结构生成和结构修改。通过引入合成可及性分数（SC Score）来指导SMILES序列的生成，以确保生成的结构易于合成。

Result: 该框架为实验室研究人员提供了生成新颖高分子结构的能力，并通过计算洞察支持高分子研究。

Conclusion: 该框架成功解决了实验室研究人员在生成新颖高分子结构方面的挑战，通过LLM推理和考虑合成可及性，加速了早期高分子发现过程。

Abstract: On-demand Polymer discovery is essential for various industries, ranging from biomedical to reinforcement materials. Experiments with polymers have a long trial-and-error process, leading to long procedures and extensive resources. For these processes, machine learning has accelerated scientific discovery at the property prediction and latent space search fronts. However, laboratory researchers cannot readily access codes and these models to extract individual structures and properties due to infrastructure limitations. We present a closed-loop polymer structure-property predictor integrated in a terminal for early-stage polymer discovery. The framework is powered by LLM reasoning to provide users with property prediction, property-guided polymer structure generation, and structure modification capabilities. The SMILES sequences are guided by the synthetic accessibility score and the synthetic complexity score (SC Score) to ensure that polymer generation is as close as possible to synthetically accessible monomer-level structures. This framework addresses the challenge of generating novel polymer structures for laboratory researchers, thereby providing computational insights into polymer research.

</details>


### [85] [Cross-Lingual Activation Steering for Multilingual Language Models](https://arxiv.org/abs/2601.16390)
*Rhitabrat Pokharel,Ameeta Agrawal,Tanay Nagar*

Main category: cs.CL

TL;DR: 本文提出了一种名为CLAS的训练无关的推理干预方法，通过选择性地调节神经元激活来解决大型语言模型在多语言任务中存在的优势语言和非优势语言之间的性能差距，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多语言任务中存在显著的性能差距，尤其是在优势语言和非优势语言之间。现有研究认为这归因于多语言表示中共享神经元和特定语言神经元的不平衡。

Method: 提出了一种名为Cross-Lingual Activation Steering (CLAS) 的训练无关的推理干预方法，该方法通过选择性地调节神经元激活来干预模型的行为，以提升非优势语言的性能。

Result: CLAS在分类和生成任务上平均带来了2.3%（准确率）和3.4%（F1分数）的提升，同时保持了高资源语言的性能。研究发现，有效的跨语言迁移通过功能发散而非严格对齐实现，性能提升与语言簇分离度的增加相关。

Conclusion: 通过对神经元激活进行目标性干预，可以在不修改模型权重的情况下，解锁现有模型潜在的多语言能力。

Abstract: Large language models exhibit strong multilingual capabilities, yet significant performance gaps persist between dominant and non-dominant languages. Prior work attributes this gap to imbalances between shared and language-specific neurons in multilingual representations. We propose Cross-Lingual Activation Steering (CLAS), a training-free inference-time intervention that selectively modulates neuron activations. We evaluate CLAS on classification and generation benchmarks, achieving average improvements of 2.3% (Acc.) and 3.4% (F1) respectively, while maintaining high-resource language performance. We discover that effective transfer operates through functional divergence rather than strict alignment; performance gains correlate with increased language cluster separation. Our results demonstrate that targeted activation steering can unlock latent multilingual capacity in existing models without modification to model weights.

</details>


### [86] [Cite-While-You-Generate: Training-Free Evidence Attribution for Multimodal Clinical Summarization](https://arxiv.org/abs/2601.16397)
*Qianqi Yan,Huy Nguyen,Sumana Srivatsa,Hari Bandi,Xin Eric Wang,Krishnaram Kenthapadi*

Main category: cs.CL

TL;DR: 提出了一种在生成时进行溯源的框架，利用解码器注意力来引用支持性文本或图像，克服了后处理或重训练方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了实现可信赖的临床摘要，不仅需要流畅的生成，还需要关于每个陈述来源的透明度。

Method: 利用解码器注意力进行生成时的溯源，并引入了两种多模态溯源策略：原始图像模式（直接使用图像块注意力）和以字幕为跨度模式（用生成的字幕替换图像，实现纯文本对齐）。

Result: 在临床医生-患者对话（CliConSummation）和放射学报告（MIMIC-CXR）两个领域进行了评估，结果显示该方法在文本和多模态溯源准确性上均优于基于嵌入和自溯源的基线（例如，F1分数提高15%）。基于字幕的溯源在具有竞争力，且更轻量级和实用。

Conclusion: 基于注意力的溯源是实现可解释和可部署的临床摘要系统的一个有希望的步骤。

Abstract: Trustworthy clinical summarization requires not only fluent generation but also transparency about where each statement comes from. We propose a training-free framework for generation-time source attribution that leverages decoder attentions to directly cite supporting text spans or images, overcoming the limitations of post-hoc or retraining-based methods. We introduce two strategies for multimodal attribution: a raw image mode, which directly uses image patch attentions, and a caption-as-span mode, which substitutes images with generated captions to enable purely text-based alignment. Evaluations on two representative domains: clinician-patient dialogues (CliConSummation) and radiology reports (MIMIC-CXR), show that our approach consistently outperforms embedding-based and self-attribution baselines, improving both text-level and multimodal attribution accuracy (e.g., +15% F1 over embedding baselines). Caption-based attribution achieves competitive performance with raw-image attention while being more lightweight and practical. These findings highlight attention-guided attribution as a promising step toward interpretable and deployable clinical summarization systems.

</details>


### [87] [Clarify or Answer: Reinforcement Learning for Agentic VQA with Context Under-specification](https://arxiv.org/abs/2601.16400)
*Zongwan Cao,Bingbing Wen,Lucy Lu Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为CoA（Clarify-or-Answer）的问答代理，它能决定是直接回答问题还是提出澄清问题。CoA引入了CONTEXTCLARIFY数据集和GRPO-CR强化学习方法来优化澄清问题的生成。实验表明，CoA在多个模型和数据集上都能显著提高VQA的准确性。


<details>
  <summary>Details</summary>
Motivation: 现实世界的视觉问答（VQA）常常依赖于图像之外的外部信息，直接回答会导致错误预测。因此，需要一种能够识别并解决信息不足问题的VQA模型。

Method: CoA模型首先判断是否需要澄清，如果需要，则提出一个聚焦的问题，并利用得到的回答来生成最终答案。研究人员引入了CONTEXTCLARIFY数据集（包含歧义和非歧义问题）以及GRPO-CR（一种基于强化学习的方法，用于生成澄清问题）。

Result: CoA在三个大型语言模型（VLLMs）和三个数据集上都取得了显著的性能提升。在端到端VQA准确率方面，CoA平均比基于提示（prompting-based）的基线模型提高了15.3个百分点（达到83%）。

Conclusion: CoA模型能够有效地处理VQA中的信息不足问题，通过主动寻求澄清来提高回答的准确性。该方法在多个VQA场景下都表现出优越的性能。

Abstract: Real-world visual question answering (VQA) is often context-dependent: an image-question pair may be under-specified, such that the correct answer depends on external information that is not observable in the image. In such cases, directly answering can lead to confident but incorrect predictions. We propose CoA(Clarify-or-Answer), an ask-or-answer agent that separately models the decision to ask or answer, and what to ask if needed. CoA first determines whether clarification is necessary; if so, it asks a single focused question and then incorporates the response to produce the final answer. We introduce CONTEXTCLARIFY with a set of ambiguous VQA questions and the contrast set that is non-ambiguous. We further introduce GRPO-CR (Clarification Reasoning), a reinforcement learning approach that optimizes clarification question generation with multiple reward signals encouraging well-formed, focused, non-trivial questions that resolve ambiguity. Across three VLLMs and three datasets, CoA achieves consistent improvements at both the module and system levels, improving end-to-end VQA accuracy by an average of +15.3 points (83%) over prompting-based baselines

</details>


### [88] [Learning Domain Knowledge in Multimodal Large Language Models through Reinforcement Fine-Tuning](https://arxiv.org/abs/2601.16419)
*Qinglong Cao,Yuntian Chen,Chao Ma,Xiaokang Yang*

Main category: cs.CL

TL;DR: 文本提示不足以使多模态大语言模型（MLLMs）适应专业领域（如遥感和医学影像）。研究提出了一种基于强化学习的微调框架，将领域知识整合到优化目标中，通过约束和奖励信号来指导模型行为，从而在专业领域取得显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在通用多模态任务中表现出色，但在遥感和医学影像等专业领域的应用效果有限。研究发现，通过文本输入（如指令、提示或字幕）注入领域知识对提升模型在科学多模态任务上的表现效果甚微，这表明当前MLLMs无法仅通过语言来内化领域知识。

Method: 提出了一种强化学习微调框架。该框架将领域知识编码为领域信息约束和奖励信号，直接整合到学习目标中，通过优化模型在输出空间的行为来融入领域知识，而不是将其视为描述性信息。

Result: 在遥感和医学影像的多个数据集上进行了广泛的实验，结果一致表明所提出的框架能够显著提升模型性能，并在多模态领域任务上取得了最先进的成果。

Conclusion: 研究强调了在优化层面整合领域知识的必要性，并揭示了当前MLLMs在通过文本进行领域条件设置方面存在的根本性局限。将领域知识作为约束和奖励信号整合到模型优化过程中是适应专业领域任务的有效途径。

Abstract: Multimodal large language models (MLLMs) have shown remarkable capabilities in multimodal perception and understanding tasks. However, their effectiveness in specialized domains, such as remote sensing and medical imaging, remains limited. A natural approach to domain adaptation is to inject domain knowledge through textual instructions, prompts, or auxiliary captions. Surprisingly, we find that such input-level domain knowledge injection yields little to no improvement on scientific multimodal tasks, even when the domain knowledge is explicitly provided. This observation suggests that current MLLMs fail to internalize domain-specific priors through language alone, and that domain knowledge must be integrated at the optimization level. Motivated by this insight, we propose a reinforcement fine-tuning framework that incorporates domain knowledge directly into the learning objective. Instead of treating domain knowledge as descriptive information, we encode it as domain-informed constraints and reward signals, shaping the model's behavior in the output space. Extensive experiments across multiple datasets in remote sensing and medical domains consistently demonstrate good performance gains, achieving state-of-the-art results on multimodal domain tasks. Our results highlight the necessity of optimization-level domain knowledge integration and reveal a fundamental limitation of textual domain conditioning in current MLLMs.

</details>


### [89] [Jacobian Scopes: token-level causal attributions in LLMs](https://arxiv.org/abs/2601.16407)
*Toni J. B. Liu,Baran Zadeoğlu,Nicolas Boullé,Raphaël Sarfati,Christopher J. Earls*

Main category: cs.CL

TL;DR: 本文提出了一种名为Jacobian Scopes的梯度类方法，用于分析大型语言模型（LLMs）在进行下一个词预测时，哪些输入词对其影响最大。该方法通过分析输入词对模型最终隐藏状态的线性化关系来量化影响，并提供了三种变体（Semantic, Fisher, Temperature Scopes）来分别关注特定逻辑、整体预测分布和模型置信度。在指令理解、翻译和上下文学习等任务的案例研究中，该方法揭示了模型中的隐性偏见，并可能有助于理解上下文时间序列预测的机制。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在进行下一个词预测时，虽然会利用上下文信息，但由于模型架构复杂（多层、多注意力头），很难精确地确定哪些先前的词对特定预测产生了最强的影响。这种不透明性阻碍了对模型决策过程的深入理解。

Method: 本文提出了一种名为Jacobian Scopes的梯度类方法，该方法通过分析模型输入（token）与最终隐藏状态之间的线性关系来量化输入token对模型预测的因果归因。具体而言，研究者引入了三种Jacobian Scopes的变体：1. Semantic Scopes：关注特定逻辑（logits）对输入的敏感性。2. Fisher Scopes：关注模型整体预测分布对输入的敏感性。3. Temperature Scopes：关注模型置信度（通过逆温度衡量）对输入的敏感性。这些方法都基于计算输入到模型内部状态的雅可比矩阵。

Result: 通过在指令理解、翻译和上下文学习（ICL）等任务上的案例研究，Jacobian Scopes成功揭示了输入token对LLM预测的具体影响。研究发现，该方法能够识别出模型中存在的隐性政治偏见。此外，研究者认为该方法也能为近期关于上下文时间序列预测机制的讨论提供新的见解。

Conclusion: Jacobian Scopes是一种有效的、基于梯度的、面向token级别的因果归因方法，用于解释大型语言模型的预测。该方法能够量化输入token的影响，揭示模型内部的偏差，并为理解LLMs的预测机制（包括在上下文学习和时间序列预测等场景下）提供了新的工具和视角。

Abstract: Large language models (LLMs) make next-token predictions based on clues present in their context, such as semantic descriptions and in-context examples. Yet, elucidating which prior tokens most strongly influence a given prediction remains challenging due to the proliferation of layers and attention heads in modern architectures. We propose Jacobian Scopes, a suite of gradient-based, token-level causal attribution methods for interpreting LLM predictions. By analyzing the linearized relations of final hidden state with respect to inputs, Jacobian Scopes quantify how input tokens influence a model's prediction. We introduce three variants - Semantic, Fisher, and Temperature Scopes - which respectively target sensitivity of specific logits, the full predictive distribution, and model confidence (inverse temperature). Through case studies spanning instruction understanding, translation and in-context learning (ICL), we uncover interesting findings, such as when Jacobian Scopes point to implicit political biases. We believe that our proposed methods also shed light on recently debated mechanisms underlying in-context time-series forecasting. Our code and interactive demonstrations are publicly available at https://github.com/AntonioLiu97/JacobianScopes.

</details>


### [90] [DeepEra: A Deep Evidence Reranking Agent for Scientific Retrieval-Augmented Generated Question Answering](https://arxiv.org/abs/2601.16478)
*Haotian Chen,Qingqing Long,Siyu Pu,Xiao Luo,Wei Ju,Meng Xiao,Yuanchun Zhou,Jianghua Zhao,Xuezhi Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为DeepEra的深度证据重排序代理，通过集成逐步推理来解决科学文献问答中语义相似但逻辑不相关的段落问题，并构建了一个名为SciRAG-SSLI的大规模数据集用于系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法在科学问题回答中存在容易被语义相似但逻辑不相关的段落误导的问题，影响了事实可靠性和减少了幻觉，这促使研究者探索更精确的段落评估方法。

Method: 提出DeepEra（Deep Evidence Reranking Agent），一种集成了逐步推理的深度证据重排序代理，以超越表面语义进行更精确的候选段落评估。同时，构建了SciRAG-SSLI数据集，包含约30万个跨10个学科的科学问题回答实例，用于系统评估。

Result: DeepEra在检索性能上优于现有的领先重排序器。该研究首次全面研究并经验性验证了在两阶段RAG框架中存在的不可忽略的语义相似但逻辑不相关（SSLI）问题。

Conclusion: DeepEra通过整合逐步推理，能够更有效地识别和过滤掉逻辑上不相关的干扰信息，显著提高了科学问题回答的准确性和可靠性，并为评估RAG模型在处理SSLI问题上的能力提供了新的数据集和基准。

Abstract: With the rapid growth of scientific literature, scientific question answering (SciQA) has become increasingly critical for exploring and utilizing scientific knowledge. Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating knowledge from external sources, thereby providing credible evidence for scientific question answering. But existing retrieval and reranking methods remain vulnerable to passages that are semantically similar but logically irrelevant, often reducing factual reliability and amplifying hallucinations.To address this challenge, we propose a Deep Evidence Reranking Agent (DeepEra) that integrates step-by-step reasoning, enabling more precise evaluation of candidate passages beyond surface-level semantics. To support systematic evaluation, we construct SciRAG-SSLI (Scientific RAG - Semantically Similar but Logically Irrelevant), a large-scale dataset comprising about 300K SciQA instances across 10 subjects, constructed from 10M scientific corpus. The dataset combines naturally retrieved contexts with systematically generated distractors to test logical robustness and factual grounding. Comprehensive evaluations confirm that our approach achieves superior retrieval performance compared to leading rerankers. To our knowledge, this work is the first to comprehensively study and empirically validate innegligible SSLI issues in two-stage RAG frameworks.

</details>


### [91] [Exploring the Effects of Alignment on Numerical Bias in Large Language Models](https://arxiv.org/abs/2601.16444)
*Ayako Sato,Hwichan Kim,Zhousi Chen,Masato Mita,Mamoru Komachi*

Main category: cs.CL

TL;DR: 本研究探讨了LLM作为评判者时出现的数值偏见，发现这种偏见源于模型的对齐过程（指令调优和偏好调优），并提出分数范围调整是最有效的缓解策略。


<details>
  <summary>Details</summary>
Motivation: LLM作为评判者在评估任务中表现出色，但存在数值偏见，影响了评估性能。本研究旨在探究数值偏见的成因。

Method: 研究人员比较了对齐前后LLM的输出，以验证对齐是否会增加数值偏见。此外，还探索了温度缩放、分布校准和分数范围调整等缓解策略。

Result: 研究发现，模型对齐确实会增加数值偏见。在缓解策略中，分数范围调整在减少偏见和提高性能方面最为有效。

Conclusion: 模型的对齐过程是导致数值偏见的原因。分数范围调整是一种有效的缓解方法，但仍需进一步研究最优分数范围的选择和更鲁棒的缓解策略。

Abstract: ``LLM-as-a-judge,'' which utilizes large language models (LLMs) as evaluators, has proven effective in many evaluation tasks. However, evaluator LLMs exhibit numerical bias, a phenomenon where certain evaluation scores are generated disproportionately often, leading reduced evaluation performance. This study investigates the cause of this bias. Given that most evaluator LLMs are aligned through instruction tuning and preference tuning, and that prior research suggests alignment reduces output diversity, we hypothesize that numerical bias arises from alignment. To test this, we compare outputs from pre- and post-alignment LLMs, and observe that alignment indeed increases numerical bias. We also explore mitigation strategies for post-alignment LLMs, including temperature scaling, distribution calibration, and score range adjustment. Among these, score range adjustment is most effective in reducing bias and improving performance, though still heuristic. Our findings highlight the need for further work on optimal score range selection and more robust mitigation strategies.

</details>


### [92] [Mixing Expert Knowledge: Bring Human Thoughts Back To the Game of Go](https://arxiv.org/abs/2601.16447)
*Yichuan Ma,Linyang Li,Yongkang Chen,Peiji Li,Jiasheng Ye,Qipeng Guo,Dahua Lin,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出了LoGos，一个通过混合微调和强化学习训练的大型语言模型，它能够以自然语言进行围棋对弈，并达到专业棋手水平，弥合了通用LLM在专业领域能力上的差距。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在数学和编程等通用推理任务上表现出色，但在围棋等专业领域存在显著的性能差距，难以达到专业水平，限制了LLM在专业领域的应用。

Method: 研究人员首先使用结构化的围棋专业知识和长链式思维（CoT）推理数据对LLM进行混合微调作为冷启动，然后通过强化学习整合围棋专业知识和通用推理能力，最终提出了LoGos模型。

Result: LoGos模型在围棋对弈中展现出强大的战略推理能力和准确的下一步预测，其性能与人类专业棋手相当，并显著优于现有的LLM。

Conclusion: 该研究成功地弥合了通用LLM的推理能力与专业领域知识之间的鸿沟，展示了将通用LLM推理能力应用于专业领域的有效方法，并为LLM在围棋领域的应用提供了新的解决方案。

Abstract: Large language models (LLMs) have demonstrated exceptional performance in reasoning tasks such as mathematics and coding, matching or surpassing human capabilities. However, these impressive reasoning abilities face significant challenges in specialized domains. Taking Go as an example, although AlphaGo has established the high performance ceiling of AI systems in Go, mainstream LLMs still struggle to reach even beginner-level proficiency, let alone perform natural language reasoning. This performance gap between general-purpose LLMs and domain experts is significantly limiting the application of LLMs on a wider range of domain-specific tasks. In this work, we aim to bridge the divide between LLMs' general reasoning capabilities and expert knowledge in domain-specific tasks. We perform mixed fine-tuning with structured Go expertise and general long Chain-of-Thought (CoT) reasoning data as a cold start, followed by reinforcement learning to integrate expert knowledge in Go with general reasoning capabilities. Through this methodology, we present \textbf{LoGos}, a powerful LLM that not only maintains outstanding general reasoning abilities, but also conducts Go gameplay in natural language, demonstrating effective strategic reasoning and accurate next-move prediction. LoGos achieves performance comparable to human professional players, substantially surpassing all existing LLMs. Through this work, we aim to contribute insights on applying general LLM reasoning capabilities to specialized domains. We will release the first large-scale Go dataset for LLM training, the first LLM Go evaluation benchmark, and the first general LLM that reaches human professional-level performance in Go at: https://github.com/Entarochuan/LoGos.

</details>


### [93] [Timely Machine: Awareness of Time Makes Test-Time Scaling Agentic](https://arxiv.org/abs/2601.16486)
*Yichuan Ma,Linyang Li,Yongkang chen,Peiji Li,Xiaozhe Li,Qipeng Guo,Dahua Lin,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Timely Machine 的方法，用于解决 LLM 在代理场景（频繁调用工具）下测试时扩展性问题，该方法将测试时间重新定义为实际运行时间，并根据时间预算动态调整策略。同时，本文还构建了一个名为 Timely-Eval 的基准测试，并提出了 Timely-RL 来优化模型的时序规划能力。


<details>
  <summary>Details</summary>
Motivation: 传统的 LLM 测试时扩展性方法基于生成长度，但在代理场景中，工具延迟使得推理时间与生成长度解耦，因此需要一种新的方法来衡量和优化 LLM 的性能。

Method: 1. 提出 Timely Machine：重新定义测试时间为实际运行时间（wall-clock time），模型根据时间预算动态调整策略。 2. 构建 Timely-Eval：一个包含高频工具调用、低频工具调用和时间受限推理的基准测试。 3. 提出 Timely-RL：通过强化学习（在监督微调后）来提升模型的时序规划能力，使其能更好地适应时间预算。

Result: 1. 在 Timely-Eval 上，发现小型模型在快速反馈（更多交互）下表现更好，而大型模型在高延迟（高质量交互）下表现更优。 2. 现有模型未能根据时间预算自适应推理。 3. Timely-RL 提高了模型的时间预算意识，并在 Timely-Eval 上持续提升了性能。

Conclusion: 本文提出了在代理场景下 LLM 测试时扩展性的新视角，通过引入实际运行时间作为衡量标准，并开发了相应的模型和基准测试，证明了模型能够根据时间预算自适应策略，并有效提升性能。

Abstract: As large language models (LLMs) increasingly tackle complex reasoning tasks, test-time scaling has become critical for enhancing capabilities. However, in agentic scenarios with frequent tool calls, the traditional generation-length-based definition breaks down: tool latency decouples inference time from generation length. We propose Timely Machine, redefining test-time as wall-clock time, where models dynamically adjust strategies based on time budgets. We introduce Timely-Eval, a benchmark spanning high-frequency tool calls, low-frequency tool calls, and time-constrained reasoning. By varying tool latency, we find smaller models excel with fast feedback through more interactions, while larger models dominate high-latency settings via superior interaction quality. Moreover, existing models fail to adapt reasoning to time budgets. We propose Timely-RL to address this gap. After cold-start supervised fine-tuning, we use reinforcement learning to enhance temporal planning. Timely-RL improves time budget awareness and consistently boosts performance across Timely-Eval. We hope our work offers a new perspective on test-time scaling for the agentic era.

</details>


### [94] [Graph-Anchored Knowledge Indexing for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.16462)
*Zhenghao Liu,Mingyan Wu,Xinze Li,Yukun Yan,Shuo Wang,Cheng Yang,Minghe Yu,Zheni Zeng,Maosong Sun*

Main category: cs.CL

TL;DR: 提出了一种名为GraphAnchor的图锚定知识索引方法，通过迭代检索动态更新知识图谱，以解决现有RAG系统整合分散在噪声文档中的关键证据的挑战，并在多跳问答任务上取得了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在整合和解释分散在噪声文档中的关键证据方面存在挑战，限制了LLM的有效性。

Method: 提出GraphAnchor，一种图锚定知识索引方法，通过迭代检索动态更新知识图谱，锚定实体和关系，形成结构化索引，指导LLM评估知识充分性并制定后续子查询。

Result: 在四个多跳问答基准测试中，GraphAnchor证明了其有效性，并能更有效地将LLM的注意力引导至检索文档中的关键信息。

Conclusion: GraphAnchor通过动态更新知识图谱作为知识索引，克服了现有RAG系统的局限性，提高了LLM在处理复杂问答任务时的能力。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a dominant paradigm for mitigating hallucinations in Large Language Models (LLMs) by incorporating external knowledge. Nevertheless, effectively integrating and interpreting key evidence scattered across noisy documents remains a critical challenge for existing RAG systems. In this paper, we propose GraphAnchor, a novel Graph-Anchored Knowledge Indexing approach that reconceptualizes graph structures from static knowledge representations into active, evolving knowledge indices. GraphAnchor incrementally updates a graph during iterative retrieval to anchor salient entities and relations, yielding a structured index that guides the LLM in evaluating knowledge sufficiency and formulating subsequent subqueries. The final answer is generated by jointly leveraging all retrieved documents and the final evolved graph. Experiments on four multi-hop question answering benchmarks demonstrate the effectiveness of GraphAnchor, and reveal that GraphAnchor modulates the LLM's attention to more effectively associate key information distributed in retrieved documents. All code and data are available at https://github.com/NEUIR/GraphAnchor.

</details>


### [95] [MRAG: Benchmarking Retrieval-Augmented Generation for Bio-medicine](https://arxiv.org/abs/2601.16503)
*Wei Zhu*

Main category: cs.CL

TL;DR: 本文提出了医疗领域检索增强生成（MRAG）基准和工具包，用于评估和改进医疗问答系统，并发现RAG能提升LLM的可靠性和推理能力，但可能略微降低长问题回答的可读性。


<details>
  <summary>Details</summary>
Motivation: 当前在科学和临床问答系统中，检索增强生成（RAG）已被广泛应用，但在医学领域缺乏全面的评估基准。

Method: 构建了包括英文和中文的医疗检索增强生成（MRAG）基准，语料库来源于Wikipedia和Pubmed。同时开发了MRAG-Toolkit，用于探索不同的RAG组件。进行了实验以评估RAG在不同任务上的表现。

Result: 实验结果表明，RAG能够提高LLM在MRAG任务上的可靠性；RAG系统的性能受检索方法、模型大小和提示策略的影响；RAG虽然提高了有用性和推理质量，但对于长问题，LLM的回答可读性可能会略有下降。

Conclusion: MRAG基准和工具包为医疗领域的RAG系统提供了一个全面的评估框架，并揭示了影响RAG性能的关键因素，为未来研究和应用提供了指导。

Abstract: While Retrieval-Augmented Generation (RAG) has been swiftly adopted in scientific and clinical QA systems, a comprehensive evaluation benchmark in the medical domain is lacking. To address this gap, we introduce the Medical Retrieval-Augmented Generation (MRAG) benchmark, covering various tasks in English and Chinese languages, and building a corpus with Wikipedia and Pubmed. Additionally, we develop the MRAG-Toolkit, facilitating systematic exploration of different RAG components. Our experiments reveal that: (a) RAG enhances LLM reliability across MRAG tasks. (b) the performance of RAG systems is influenced by retrieval approaches, model sizes, and prompting strategies. (c) While RAG improves usefulness and reasoning quality, LLM responses may become slightly less readable for long-form questions. We will release the MRAG-Bench's dataset and toolkit with CCBY-4.0 license upon acceptance, to facilitate applications from both academia and industry.

</details>


### [96] [LOGICAL-COMMONSENSEQA: A Benchmark for Logical Commonsense Reasoning](https://arxiv.org/abs/2601.16504)
*Obed Junias,Maria Leonor Pacheco*

Main category: cs.CL

TL;DR: 本文提出了一个名为 LOGICAL-COMMONSENSEQA 的新基准，用于评估模型在理解多个可能解释的常识推理能力，而非仅仅选择单一答案。该基准使用逻辑运算符（AND、OR、NEITHER/NOR）来评估陈述对的联合可信度。


<details>
  <summary>Details</summary>
Motivation: 现有的常识推理基准大多采用单一标签评估，无法区分陈述是否联合可信、互斥或联合不可信，这掩盖了模型在处理多重解释方面的不足。

Method: 构建了 LOGICAL-COMMONSENSEQA 基准，将常识推理重构为对陈述对应用逻辑组合（AND, OR, NEITHER/NOR）。在零样本、少样本和思维链提示下，评估了指令微调、推理专用和微调模型。

Result: 模型在析取推理上表现尚可，在合取推理上表现中等，但在基于否定的问题上性能急剧下降。

Conclusion: LOGICAL-COMMONSENSEQA 基准暴露了当前模型在组合式常识推理方面的根本性局限，并提供了一个可控的框架来推动该领域的研究进展。

Abstract: Commonsense reasoning often involves evaluating multiple plausible interpretations rather than selecting a single atomic answer, yet most benchmarks rely on single-label evaluation, obscuring whether statements are jointly plausible, mutually exclusive, or jointly implausible. We introduce LOGICAL-COMMONSENSEQA, a benchmark that re-frames commonsense reasoning as logical composition over pairs of atomic statements using plausibility-level operators (AND, OR, NEITHER/NOR). Evaluating instruction-tuned, reasoning-specialized, and fine-tuned models under zero-shot, few-shot, and chain-of-thought prompting, we find that while models perform reasonably on conjunctive and moderately on disjunctive reasoning, performance degrades sharply on negation-based questions. LOGICAL-COMMONSENSEQA exposes fundamental reasoning limitations and provides a controlled framework for advancing compositional commonsense reasoning.

</details>


### [97] [TL-GRPO: Turn-Level RL for Reasoning-Guided Iterative Optimization](https://arxiv.org/abs/2601.16480)
*Peiji Li,Linyang Li,Handa Sun,Wenjin Mai,Yongkang Chen,Xiaozhe Li,Yue Shen,Yichuan Ma,Yiliu Sun,Jiaxi Cao,Zhishu He,Bo Wang,Xiaoqing Zheng,Zhaori Bi,Xipeng Qiu,Qipeng Guo,Kai Chen,Dahua Lin*

Main category: cs.CL

TL;DR: 提出一种名为TL-GRPO的轻量级强化学习算法，用于解决迭代优化任务，该算法能够进行细粒度的回合级优化，并在模拟电路尺寸调整任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于GRPO的工具集成方法无法有效处理迭代优化任务，因为这类任务的价值由回合级奖励而非累积奖励决定，而黑盒优化方法会忽略先验知识和推理能力。

Method: 提出TL-GRPO算法，通过回合级分组采样实现细粒度优化。

Result: TL-GRPO在模拟电路尺寸调整任务上优于标准的GRPO和贝叶斯优化方法，并且使用TL-GRPO训练的30B模型在相同模拟预算下达到了该任务的最先进性能。

Conclusion: TL-GRPO算法在迭代优化任务中表现出色，具有强大的泛化能力和实际应用价值。

Abstract: Large language models have demonstrated strong reasoning capabilities in complex tasks through tool integration, which is typically framed as a Markov Decision Process and optimized with trajectory-level RL algorithms such as GRPO. However, a common class of reasoning tasks, iterative optimization, presents distinct challenges: the agent interacts with the same underlying environment state across turns, and the value of a trajectory is determined by the best turn-level reward rather than cumulative returns. Existing GRPO-based methods cannot perform fine-grained, turn-level optimization in such settings, while black-box optimization methods discard prior knowledge and reasoning capabilities. To address this gap, we propose Turn-Level GRPO (TL-GRPO), a lightweight RL algorithm that performs turn-level group sampling for fine-grained optimization. We evaluate TL-GRPO on analog circuit sizing (ACS), a challenging scientific optimization task requiring multiple simulations and domain expertise. Results show that TL-GRPO outperforms standard GRPO and Bayesian optimization methods across various specifications. Furthermore, our 30B model trained with TL-GRPO achieves state-of-the-art performance on ACS tasks under same simulation budget, demonstrating both strong generalization and practical utility.

</details>


### [98] [Persona Jailbreaking in Large Language Models](https://arxiv.org/abs/2601.16466)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 研究提出了PHISH框架，一种能够在黑盒设置下，通过用户输入操纵大型语言模型（LLM）的“个性”，即使在对抗性对话历史中也是如此，并且对LLM的整体效用影响很小。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM个性研究主要集中在叙述或角色扮演任务，忽视了对话历史作为独立因素对个性产生的操纵作用，并且在黑盒环境下对个性的操纵研究尚属空白，这引发了对LLM在现实交互中鲁棒性的担忧。

Method: 提出“个性编辑”任务，并设计了PHISH（Persona Hijacking via Implicit Steering in History）框架。PHISH通过在用户查询中嵌入语义线索，利用隐式引导的方式，在黑盒、仅推理的环境下，逐渐诱导LLM产生与其初始设定相反的个性。同时，研究还定义了一个量化攻击成功率的指标。

Result: PHISH能够可预测地改变LLM的个性，并触发与其相关的其他特质的附带变化。在多轮对话中，PHISH的效果更强。在心理健康、辅导和客户支持等高风险领域，PHISH可以可靠地操纵个性，这一点得到了人类和LLM-as-Judge的验证。重要的是，PHISH对推理基准测试的性能仅造成微小的下降，整体效用基本保持不变。

Conclusion: PHISH揭示了LLM在个性方面的新的脆弱性，表明现有安全机制在持续攻击下仍然脆弱，并强调了对上下文具有鲁棒性的LLM个性设计的重要性。研究暴露了LLM个性操纵的新漏洞，并呼吁开发更具上下文适应性的LLM个性。

Abstract: Large Language Models (LLMs) are increasingly deployed in domains such as education, mental health and customer support, where stable and consistent personas are critical for reliability. Yet, existing studies focus on narrative or role-playing tasks and overlook how adversarial conversational history alone can reshape induced personas. Black-box persona manipulation remains unexplored, raising concerns for robustness in realistic interactions. In response, we introduce the task of persona editing, which adversarially steers LLM traits through user-side inputs under a black-box, inference-only setting. To this end, we propose PHISH (Persona Hijacking via Implicit Steering in History), the first framework to expose a new vulnerability in LLM safety that embeds semantically loaded cues into user queries to gradually induce reverse personas. We also define a metric to quantify attack success. Across 3 benchmarks and 8 LLMs, PHISH predictably shifts personas, triggers collateral changes in correlated traits, and exhibits stronger effects in multi-turn settings. In high-risk domains mental health, tutoring, and customer support, PHISH reliably manipulates personas, validated by both human and LLM-as-Judge evaluations. Importantly, PHISH causes only a small reduction in reasoning benchmark performance, leaving overall utility largely intact while still enabling significant persona manipulation. While current guardrails offer partial protection, they remain brittle under sustained attack. Our findings expose new vulnerabilities in personas and highlight the need for context-resilient persona in LLMs. Our codebase and dataset is available at: https://github.com/Jivnesh/PHISH

</details>


### [99] [Attention-MoA: Enhancing Mixture-of-Agents via Inter-Agent Semantic Attention and Deep Residual Synthesis](https://arxiv.org/abs/2601.16596)
*Jianyu Wen,Yang Wei,Xiongxi Yu,Changxuan Xiao,Ke Zeng*

Main category: cs.CL

TL;DR: 提出了一种名为Attention-MoA的新型Mixture-of-Agents框架，通过引入跨Agent语义注意力机制和跨层残差模块，提高了深度交互能力，有效减轻了信息损耗，并提升了效率。在多项基准测试中，Attention-MoA表现优于现有SOTA方法，甚至能使小型模型超越大型闭源模型。


<details>
  <summary>Details</summary>
Motivation: 现有Mixture-of-Agents（MoA）模型在动态路由和残差连接方面的改进，未能充分实现Agent间的深度语义交互，限制了模型纠正幻觉和优化逻辑的能力。

Method: 引入Attention-MoA框架，核心是跨Agent语义注意力（Inter-agent Semantic Attention）机制。同时，结合了跨层残差模块（Inter-layer Residual Module）和自适应提前停止机制（Adaptive Early Stopping Mechanism），以减少信息损耗并提高效率。

Result: 在AlpacaEval 2.0、MT-Bench和FLASK等基准测试中，Attention-MoA显著优于SOTA方法。在AlpacaEval 2.0上实现了91.15%的长度控制胜率，在FLASK的12项能力中有10项处于主导地位。值得注意的是，Attention-MoA使小型开源模型集成后，其MT-Bench得分为8.83，AlpacaEval 2.0 LC胜率为77.36%，超越了Claude-4.5-Sonnet和GPT-4.1等大型专有模型。

Conclusion: Attention-MoA通过创新的跨Agent语义注意力机制和辅助模块，有效解决了现有MoA模型在深度交互和信息损耗方面的问题，实现了显著的性能提升，并证明了小型模型集成在MoA框架下的强大潜力。

Abstract: As the development of Large Language Models (LLMs) shifts from parameter scaling to inference-time collaboration, the Mixture-of-Agents (MoA) framework has emerged as a general paradigm to harness collective intelligence by layering diverse models. While recent MoA variants have introduced dynamic routing and residual connections to improve efficiency, these methods often fail to facilitate deep semantic interaction between agents, limiting the system's ability to actively correct hallucinations and refine logic. In this paper, we introduce Attention-MoA, a novel MoA-based framework that redefines collaboration through Inter-agent Semantic Attention. Complemented by an Inter-layer Residual Module with Adaptive Early Stopping Mechanism, our architecture mitigates information degradation in deep layers while improving computational efficiency. Extensive evaluations across AlpacaEval 2.0, MT-Bench, and FLASK demonstrate that Attention-MoA significantly outperforms state-of-the-art baselines, achieving a 91.15% Length-Controlled Win Rate on AlpacaEval 2.0 and dominating in 10 out of 12 capabilities on FLASK. Notably, Attention-MoA enables an ensemble of small open-source models to outperform massive proprietary models like Claude-4.5-Sonnet and GPT-4.1, achieving an MT-Bench score of 8.83 and an AlpacaEval 2.0 LC Win Rate of 77.36%.

</details>


### [100] [Is Length Really A Liability? An Evaluation of Multi-turn LLM Conversations using BoolQ](https://arxiv.org/abs/2601.16508)
*Karl Neergaard,Le Qiu,Emmanuele Chersoni*

Main category: cs.CL

TL;DR: 当前的大模型评估方法（单轮提问）无法反映模型在真实对话场景下的表现，本研究通过改变对话长度和脚手架条件，发现模型在多轮对话中存在单轮评估无法发现的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM基准测试主要依赖单轮提问，无法捕捉真实世界中发生危害的对话动态，因此作者希望研究对话长度是否会影响模型回答的真实性。

Method: 在BoolQ数据集上，通过改变对话长度和脚手架条件，评估了三种不同LLM在不同条件下的表现。

Result: 研究结果显示，模型在不同对话长度和脚手架条件下表现出模型特有的、在单轮测试中不可见的研究结果。

Conclusion: 研究观察到的与长度和脚手架相关的效应，表明静态评估存在根本性局限，因为与部署相关的脆弱性只能在多轮对话环境中被发现。

Abstract: Single-prompt evaluations dominate current LLM benchmarking, yet they fail to capture the conversational dynamics where real-world harm occurs. In this study, we examined whether conversation length affects response veracity by evaluating LLM performance on the BoolQ dataset under varying length and scaffolding conditions. Our results across three distinct LLMs revealed model-specific vulnerabilities that are invisible under single-turn testing. The length-dependent and scaffold-specific effects we observed demonstrate a fundamental limitation of static evaluations, as deployment-relevant vulnerabilities could only be spotted in a multi-turn conversational setting.

</details>


### [101] [SearchLLM: Detecting LLM Paraphrased Text by Measuring the Similarity with Regeneration of the Candidate Source via Search Engine](https://arxiv.org/abs/2601.16512)
*Hoang-Quoc Nguyen-Son,Minh-Son Dao,Koji Zettsu*

Main category: cs.CL

TL;DR: 提出了一种名为SearchLLM的新方法，利用搜索引擎查找潜在的原始内容，并通过比较相似性来检测LLM改写的文本，该方法能有效提升现有检测器的准确性并防御改写攻击。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM文本检测方法难以识别高度模仿原文的改写文本，这使得LLM被滥用进行抄袭或信息失真。因此，需要一种新的方法来应对这一挑战。

Method: SearchLLM利用搜索引擎查找用户输入的文本的潜在原始来源，然后分析输入文本与从搜索结果中找到的候选来源的改写版本之间的相似性，以此来识别LLM改写的文本。SearchLLM被设计为一个代理层，可以与现有的检测器结合使用。

Result: 实验证明，SearchLLM能够显著提高现有检测器在识别与原文高度相似的LLM改写文本方面的准确性，并且有效防御了改写攻击。

Conclusion: SearchLLM是一种有效且易于集成的解决方案，能够通过利用搜索引擎来克服当前LLM文本检测技术的局限性，特别是在处理高度相似的改写文本时。

Abstract: With the advent of large language models (LLMs), it has become common practice for users to draft text and utilize LLMs to enhance its quality through paraphrasing. However, this process can sometimes result in the loss or distortion of the original intended meaning. Due to the human-like quality of LLM-generated text, traditional detection methods often fail, particularly when text is paraphrased to closely mimic original content. In response to these challenges, we propose a novel approach named SearchLLM, designed to identify LLM-paraphrased text by leveraging search engine capabilities to locate potential original text sources. By analyzing similarities between the input and regenerated versions of candidate sources, SearchLLM effectively distinguishes LLM-paraphrased content. SearchLLM is designed as a proxy layer, allowing seamless integration with existing detectors to enhance their performance. Experimental results across various LLMs demonstrate that SearchLLM consistently enhances the accuracy of recent detectors in detecting LLM-paraphrased text that closely mimics original content. Furthermore, SearchLLM also helps the detectors prevent paraphrasing attacks.

</details>


### [102] [PLawBench: A Rubric-Based Benchmark for Evaluating LLMs in Real-World Legal Practice](https://arxiv.org/abs/2601.16669)
*Yuzhen Shi,Huanghai Liu,Yiran Hu,Gaojie Song,Xinran Xu,Yubo Ma,Tianyi Tang,Li Zhang,Qingjing Chen,Di Feng,Wenbo Lv,Weiheng Wu,Kexin Yang,Sen Yang,Wei Wang,Rongyao Shi,Yuanyang Qiu,Yuemeng Qi,Jingwen Zhang,Xiaoyu Sui,Yifan Chen,Yi Zhang,An Yang,Bowen Yu,Dayiheng Liu,Junyang Lin,Weixing Shen,Bing Zhao,Charles L. A. Clarke,Hu Wei*

Main category: cs.CL

TL;DR: 本文提出了 PLawBench，一个用于评估大型语言模型（LLMs）在实际法律工作场景中表现的基准测试，包括法律咨询、案例分析和法律文件生成。现有 LLMs 在 PLawBench 上表现不佳，表明它们在精细的法律推理方面存在显著局限。


<details>
  <summary>Details</summary>
Motivation: 现有的法律基准测试未能充分捕捉实际法律实践中的模糊性、复杂性和推理需求，并且评估指标过于粗糙，无法细致地评估法律推理能力。因此，需要一个更贴近实际的基准来评估 LLMs 在法律领域的表现。

Method: PLawBench 包含三个任务类别：公众法律咨询、实际案例分析和法律文件生成，涵盖 13 个实际法律场景和 850 个问题。每个问题都附带专家设计的评估细则，用于进行精细化评估。研究使用了一个与人类专家判断一致的 LLM 评估器来评估 10 个 SOTA LLMs。

Result: 所有被评估的 10 个 SOTA LLMs 在 PLawBench 上均未达到强劲的表现，揭示了当前 LLMs 在精细法律推理能力方面的显著不足。

Conclusion: PLawBench 证明了当前 LLMs 在实际法律场景中的应用能力有限，特别是在复杂的法律推理方面。这指明了未来法律 LLMs 评估和发展的重要方向。

Abstract: As large language models (LLMs) are increasingly applied to legal domain-specific tasks, evaluating their ability to perform legal work in real-world settings has become essential. However, existing legal benchmarks rely on simplified and highly standardized tasks, failing to capture the ambiguity, complexity, and reasoning demands of real legal practice. Moreover, prior evaluations often adopt coarse, single-dimensional metrics and do not explicitly assess fine-grained legal reasoning. To address these limitations, we introduce PLawBench, a Practical Law Benchmark designed to evaluate LLMs in realistic legal practice scenarios. Grounded in real-world legal workflows, PLawBench models the core processes of legal practitioners through three task categories: public legal consultation, practical case analysis, and legal document generation. These tasks assess a model's ability to identify legal issues and key facts, perform structured legal reasoning, and generate legally coherent documents. PLawBench comprises 850 questions across 13 practical legal scenarios, with each question accompanied by expert-designed evaluation rubrics, resulting in approximately 12,500 rubric items for fine-grained assessment. Using an LLM-based evaluator aligned with human expert judgments, we evaluate 10 state-of-the-art LLMs. Experimental results show that none achieves strong performance on PLawBench, revealing substantial limitations in the fine-grained legal reasoning capabilities of current LLMs and highlighting important directions for future evaluation and development of legal LLMs. Data is available at: https://github.com/skylenage/PLawbench.

</details>


### [103] [Curate-Train-Refine: A Closed-Loop Agentic Framework for Zero Shot Classification](https://arxiv.org/abs/2601.16530)
*Gaurav Maheshwari,Kevin El Haddad*

Main category: cs.CL

TL;DR: 该研究提出了一种利用大型语言模型（LLM）动态生成监督数据来训练轻量级文本分类器的方法，以解决LLM推理成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）和高容量编码器虽然在零样本和少样本分类方面表现出色，但其高昂的推理成本和延迟限制了实际部署。

Method: 该方法通过一个迭代的、基于智能体的循环来训练轻量级文本分类器。LLM在此循环中负责策划训练数据、分析模型成功与失败的案例，并合成针对性示例来纠正错误。这种闭环生成和评估过程可以逐步提高数据质量，并使其适应下游分类器和任务。

Result: 在四个广泛使用的基准测试中，该方法始终优于标准的零样本和少样本基线。

Conclusion: 研究表明，LLM可以有效地充当数据策划者，无需部署大型模型的运营成本即可实现准确高效的分类。

Abstract: Large language models (LLMs) and high-capacity encoders have advanced zero and few-shot classification, but their inference cost and latency limit practical deployment. We propose training lightweight text classifiers using dynamically generated supervision from an LLM. Our method employs an iterative, agentic loop in which the LLM curates training data, analyzes model successes and failures, and synthesizes targeted examples to address observed errors. This closed-loop generation and evaluation process progressively improves data quality and adapts it to the downstream classifier and task. Across four widely used benchmarks, our approach consistently outperforms standard zero and few-shot baselines. These results indicate that LLMs can serve effectively as data curators, enabling accurate and efficient classification without the operational cost of large-model deployment.

</details>


### [104] [Sycophancy Hides Linearly in the Attention Heads](https://arxiv.org/abs/2601.16644)
*Rifo Genadi,Munachiso Nwadike,Nurdaulet Mukhituly,Hilal Alquabeh,Tatsuya Hiraoka,Kentaro Inui*

Main category: cs.CL

TL;DR: 研究发现，在多头注意力激活中，正确-错误谄媚信号具有最好的线性可分性。通过训练线性探针，研究者识别出中间层注意力头是引导这些信号最有效的部分，并证明了这些探针可以有效迁移到其他事实问答基准。此外，与先前发现的“诚实”方向相比，此研究发现的谄媚方向有有限的重叠，表明事实准确性和抵抗谄媚是相关的但独立机制。注意力模式分析表明，有影响力的注意力头倾向于关注用户怀疑的表达，从而导致谄媚的转变。总体而言，研究表明可以通过利用注意力激活的内部几何结构进行简单的、有针对性的线性干预来减轻谄媚。


<details>
  <summary>Details</summary>
Motivation: 研究动机是基于线性表示假说，旨在分析在大型语言模型中，正确的谄媚信号（即模型在面对正确信息时表现出谄媚行为）是如何在模型内部产生的，并探索是否可以通过线性方法来减轻这种行为。

Method: 研究者使用 TruthfulQA 数据集作为基础，训练线性探针来分析残差流、MLP 和注意力层中的信号。他们比较了不同层和注意力头中线性可分性的效果，并测试了探针在其他事实问答基准上的迁移能力。同时，研究者还将发现的“谄媚”方向与先前已知的“诚实”方向进行了比较。最后，通过注意力模式分析来进一步理解模型的行为。

Result: 研究发现，正确的谄媚信号在多头注意力的激活中具有最佳的线性可分性。虽然残差流和 MLP 中也存在可分性，但在中间层注意力头的稀疏子集中进行干预最有效。在 TruthfulQA 上训练的探针能有效地迁移到其他事实问答基准。此外，发现的谄媚方向与先前识别出的“诚实”方向重叠有限。注意力模式分析表明，有影响力的注意力头会不成比例地关注用户表达怀疑的地方。

Conclusion: 该研究得出结论，谄媚行为可以通过利用注意力激活的内部几何结构进行简单、有针对性的线性干预来有效缓解。这为理解和控制大型语言模型的行为提供了一个有前景的方向。

Abstract: We find that correct-to-incorrect sycophancy signals are most linearly separable within multi-head attention activations. Motivated by the linear representation hypothesis, we train linear probes across the residual stream, multilayer perceptron (MLP), and attention layers to analyze where these signals emerge. Although separability appears in the residual stream and MLPs, steering using these probes is most effective in a sparse subset of middle-layer attention heads. Using TruthfulQA as the base dataset, we find that probes trained on it transfer effectively to other factual QA benchmarks. Furthermore, comparing our discovered direction to previously identified "truthful" directions reveals limited overlap, suggesting that factual accuracy, and deference resistance, arise from related but distinct mechanisms. Attention-pattern analysis further indicates that the influential heads attend disproportionately to expressions of user doubt, contributing to sycophantic shifts. Overall, these findings suggest that sycophancy can be mitigated through simple, targeted linear interventions that exploit the internal geometry of attention activations.

</details>


### [105] [Retrieve-Refine-Calibrate: A Framework for Complex Claim Fact-Checking](https://arxiv.org/abs/2601.16555)
*Mingwei Sun,Qianlong Wang,Ruifeng Xu*

Main category: cs.CL

TL;DR: 提出一种基于大型语言模型的检索-精炼-校准（RRC）框架，用于事实核查，以解决现有方法中分解范式可能引入噪声的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的事实核查方法通常采用分解范式，将声明分解为子声明进行验证，但这种方法可能因不相关的实体或证据而引入噪声，降低验证准确性。

Method: 提出一种检索-精炼-校准（RRC）框架。首先，识别声明中的实体并检索相关证据。然后，根据声明精炼检索到的证据，减少无关信息。最后，通过重新评估低置信度预测来校准验证过程。

Result: 在HOVER和FEVEROUS-S两个事实核查数据集上的实验表明，RRC框架的性能优于现有基线方法。

Conclusion: RRC框架能够有效解决分解范式带来的噪声问题，提升事实核查的准确性。

Abstract: Fact-checking aims to verify the truthfulness of a claim based on the retrieved evidence. Existing methods typically follow a decomposition paradigm, in which a claim is broken down into sub-claims that are individually verified. However, the decomposition paradigm may introduce noise to the verification process due to irrelevant entities or evidence, ultimately degrading verification accuracy. To address this problem, we propose a Retrieve-Refine-Calibrate (RRC) framework based on large language models (LLMs). Specifically, the framework first identifies the entities mentioned in the claim and retrieves evidence relevant to them. Then, it refines the retrieved evidence based on the claim to reduce irrelevant information. Finally, it calibrates the verification process by re-evaluating low-confidence predictions. Experiments on two popular fact-checking datasets (HOVER and FEVEROUS-S) demonstrate that our framework achieves superior performance compared with competitive baselines.

</details>


### [106] [Standardizing Longitudinal Radiology Report Evaluation via Large Language Model Annotation](https://arxiv.org/abs/2601.16753)
*Xinyi Wang,Grazziela Figueredo,Ruizhe Li,Xin Chen*

Main category: cs.CL

TL;DR: 本研究提出了一种基于大语言模型（LLM）的自动化流程，用于标注放射学报告中的纵向信息（如疾病进展），并构建了一个大规模标注数据集（MIMIC-CXR），用于评估放射学报告生成模型。


<details>
  <summary>Details</summary>
Motivation: 当前评估放射学报告生成模型在捕捉纵向信息方面的能力存在挑战，缺乏有效的工具来一致地标注和比较模型生成文本与真实情况的时间变化，现有的手动标注方法耗时且难以适应。LLM在语言理解和适应性方面的优势使其成为一个有潜力的标注替代方案。

Method: 研究者开发了一个基于LLM的标注流程，首先识别包含相关信息的句子，然后提取疾病进展。他们评估了五种主流LLM在这些任务上的表现，选择了表现最优的Qwen2.5-32B模型，并用其标注了95,169份MIMIC-CXR数据集报告。最后，利用该标注数据集评估了七个报告生成模型。

Result: Qwen2.5-32B模型在纵向信息检测和疾病跟踪任务上表现出色。基于LLM的标注方法比现有方法在纵向信息检测和疾病跟踪方面分别提高了11.3%和5.3%的F1分数。使用新标注数据集评估的七个先进报告生成模型也展示了其性能。

Conclusion: 基于LLM的自动化标注流程能够有效且高效地处理放射学报告中的纵向信息，克服了现有方法的局限性，并成功构建了一个大规模的标准数据集，为评估和改进放射学报告生成模型提供了新的基准。

Abstract: Longitudinal information in radiology reports refers to the sequential tracking of findings across multiple examinations over time, which is crucial for monitoring disease progression and guiding clinical decisions. Many recent automated radiology report generation methods are designed to capture longitudinal information; however, validating their performance is challenging. There is no proper tool to consistently label temporal changes in both ground-truth and model-generated texts for meaningful comparisons. Existing annotation methods are typically labor-intensive, relying on the use of manual lexicons and rules. Complex rules are closed-source, domain specific and hard to adapt, whereas overly simple ones tend to miss essential specialised information. Large language models (LLMs) offer a promising annotation alternative, as they are capable of capturing nuanced linguistic patterns and semantic similarities without extensive manual intervention. They also adapt well to new contexts. In this study, we therefore propose an LLM-based pipeline to automatically annotate longitudinal information in radiology reports. The pipeline first identifies sentences containing relevant information and then extracts the progression of diseases. We evaluate and compare five mainstream LLMs on these two tasks using 500 manually annotated reports. Considering both efficiency and performance, Qwen2.5-32B was subsequently selected and used to annotate another 95,169 reports from the public MIMIC-CXR dataset. Our Qwen2.5-32B-annotated dataset provided us with a standardized benchmark for evaluating report generation models. Using this new benchmark, we assessed seven state-of-the-art report generation models. Our LLM-based annotation method outperforms existing annotation solutions, achieving 11.3\% and 5.3\% higher F1-scores for longitudinal information detection and disease tracking, respectively.

</details>


### [107] [PROST-LLM: Progressively Enhancing the Speech-to-Speech Translation Capability in LLMs](https://arxiv.org/abs/2601.16618)
*Jing Xu,Jiaqi Wang,Daxin Tan,Xiao Chen*

Main category: cs.CL

TL;DR: 提出PROST-LLM方法，通过分阶段的训练和无需人工评估的偏好优化，提升大型语言模型在语音到语音翻译方面的能力，解决了数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在语音到语音翻译（S2ST）方面的应用研究不足，且面临数据稀缺的挑战。

Method: 1. 使用CVSS语料库对LLMs进行微调，采用三任务学习和跨模态链方法。2. 利用微调后的模型，通过自采样和回译生成偏好对，无需人工评估。3. 使用生成的偏好对进行偏好优化，进一步提升S2ST能力。

Result: 实验证明PROST-LLM能够有效提升LLMs在S2ST任务上的性能。

Conclusion: PROST-LLM是一种有效的方法，可以逐步提升大型语言模型在语音到语音翻译方面的能力，并成功解决了数据稀缺的问题。

Abstract: Although Large Language Models (LLMs) excel in many tasks, their application to Speech-to-Speech Translation (S2ST) is underexplored and hindered by data scarcity. To bridge this gap, we propose PROST-LLM (PROgressive Speech-to-speech Translation) to enhance the S2ST capabilities in LLMs progressively. First, we fine-tune the LLMs with the CVSS corpus, employing designed tri-task learning and chain of modality methods to boost the initial performance. Then, leveraging the fine-tuned model, we generate preference pairs through self-sampling and back-translation without human evaluation. Finally, these preference pairs are used for preference optimization to enhance the model's S2ST capability further. Extensive experiments confirm the effectiveness of our proposed PROST-LLM in improving the S2ST capability of LLMs.

</details>


### [108] [AuroraEdge-V-2B: A Faster And Stronger Edge Visual Large Language Model](https://arxiv.org/abs/2601.16615)
*Xiang Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为 AuroraEdge-V-2B 的紧凑型、高效能视觉大型语言模型（VLLM），专为边缘部署而设计，以解决现有 VLLM 在工业生产中的局限性。通过压缩-融合方法提高推理效率，该模型参数量仅为 20 亿，在视觉 token 数量、计算成本和速度方面均有显著优势，并在多个基准测试中优于同类模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（VLLMs）虽然在工业生产中展现出通用性和灵活性，但在特定领域性能不足、计算资源需求高以及推理速度慢等方面存在显著缺点。为了克服这些挑战，研究者们需要一个更适合边缘部署、速度更快、资源占用更少的 VLLM。

Method: 本文提出了一种名为 AuroraEdge-V-2B 的 VLLM，该模型参数量仅为 2B，专为边缘设备设计。为了提高推理效率，研究者还开发了一种压缩-融合方法，该方法通过减少解码过程中的视觉 token 数量，将推理过程中的浮点运算次数减少了一半。

Result: AuroraEdge-V-2B 模型参数量为 2B，易于部署且速度更快，适合实时应用。通过减少视觉 token 数量，其计算成本降低了一半。在 9 个基准测试中，AuroraEdge-V-2B 取得了比参数量相似的模型（如 Qwen2-VL-2B、Qwen2.5-VL-3B、InternVL-2.5-2B）更高的分数。

Conclusion: AuroraEdge-V-2B 是一种紧凑、高效且性能强大的 VLLM，非常适合工业生产中的边缘部署。通过其独特的压缩-融合方法和精简的设计，该模型克服了现有 VLLM 的关键瓶颈，提供了更好的实时性能和更低的计算成本，同时在多项评估中展现出优越的性能。

Abstract: Recently, due to the advancement of multimodal technology, people are attempting to use visual large language models (VLLMs) in industrial production. Many deep learning models (DLMs) deployed in the production environment are gradually being replaced by VLLMs. Compared with DLMs, VLLMs have some advantages in industrial applications: (1) Their strong generalization ability enables them to perform well across a wide range of tasks. (2) They are flexible and can deal with unfamiliar samples through context learning quickly. However, VLLMs also have obvious drawbacks: (1) VLLMs do not perform as well as custom-developed DLMs in specific domains. (2) The number of parameters in VLLMs is generally quite large, and their deployment requires substantial computational resources. (3) VLLMs generally operate much slower than DLMs, making real-time response challenging to achieve. To better utilize VLLMs in industrial applications, we introduce AuroraEdge-V-2B in this work, a compact, robust, and high-speed VLLM designed for edge deployment. To make the model run faster, we also propose a compression-fusion method to improve inference efficiency. AuroraEdge-V-2B has the following notable features: (1) Easy deployment and faster: It has only 2B parameters and is highly suitable for edge deployment, offering better real-time performance. (2) Fewer visual tokens and cheaper: It significantly reduces the number of visual tokens in the decoding process, thereby reducing the floating-point operations by half during inference and making it cheaper to use. (3) Strong performance: It gets a higher score on 9 benchmarks than models with the same number of parameter (e.g., Qwen2-VL-2B, Qwen2.5-VL-3B, InternVL-2.5-2B).

</details>


### [109] [Do LLM hallucination detectors suffer from low-resource effect?](https://arxiv.org/abs/2601.16766)
*Debtanu Datta,Mohan Kishore Chilukuri,Yash Kumar,Saptarshi Ghosh,Muhammad Bilal Zafar*

Main category: cs.CL

TL;DR: 研究发现，语言模型在低资源语言下的幻觉检测器性能下降幅度远小于其在低资源语言下的任务准确率下降幅度，表明模型可能在低资源语言下仍保留不确定性信号，且幻觉检测器在跨语言设置下（无同语言监督）之外表现鲁棒。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在许多任务上表现出色，但仍存在意外的失败模式，特别是幻觉（生成不正确信息）和低资源效应（在低资源语言上性能下降）。本研究旨在探究幻觉检测器是否也受到低资源效应的影响，以及了解其在不同语言环境下的鲁棒性。

Method: 研究人员在五项任务（涉及事实回忆、STEM和人文学科三个领域）上，使用了四种LLMs和三种幻觉检测器，对高资源语言（如英语）和低资源语言（如孟加拉语）进行了对比实验。同时，还评估了检测器在同语言设置、多语言设置以及跨语言设置（有/无同语言监督）下的表现。

Result: 实验结果显示，与英语相比，LLMs在低资源语言下的任务准确率确实大幅下降。然而，幻觉检测器的准确率下降幅度通常比任务准确率的下降幅度小得多（有时小好几倍）。这表明即使在低资源语言下，LLMs的内部机制可能也编码了关于其不确定性的信号。此外，幻觉检测器在同语言内部和多语言设置下表现出鲁棒性，但在缺乏同语言监督的跨语言设置下性能会显著下降。

Conclusion: 幻觉检测器在低资源语言下的性能下降幅度小于LLMs的任务性能下降幅度，暗示模型可能在低资源语言下保留不确定性信号。幻觉检测器在同语言和多语言设置下是鲁棒的，但在缺乏同语言监督的跨语言场景下，其效果会受限。

Abstract: LLMs, while outperforming humans in a wide range of tasks, can still fail in unanticipated ways. We focus on two pervasive failure modes: (i) hallucinations, where models produce incorrect information about the world, and (ii) the low-resource effect, where the models show impressive performance in high-resource languages like English but the performance degrades significantly in low-resource languages like Bengali. We study the intersection of these issues and ask: do hallucination detectors suffer from the low-resource effect? We conduct experiments on five tasks across three domains (factual recall, STEM, and Humanities). Experiments with four LLMs and three hallucination detectors reveal a curious finding: As expected, the task accuracies in low-resource languages experience large drops (compared to English). However, the drop in detectors' accuracy is often several times smaller than the drop in task accuracy. Our findings suggest that even in low-resource languages, the internal mechanisms of LLMs might encode signals about their uncertainty. Further, the detectors are robust within language (even for non-English) and in multilingual setups, but not in cross-lingual settings without in-language supervision.

</details>


### [110] [How Does Personalized Memory Shape LLM Behavior? Benchmarking Rational Preference Utilization in Personalized Assistants](https://arxiv.org/abs/2601.16621)
*Xueyang Feng,Weinan Gan,Xu Chen,Quanyu Dai,Yong Liu*

Main category: cs.CL

TL;DR: 该研究提出了一个名为 RPEval 的基准测试和一种名为 RP-Reasoner 的新方法，用于解决大型语言模型（LLM）个性化记忆带来的负面影响，即引入不相关的个性化信息干扰模型意图理解。RP-Reasoner 将记忆利用视为一种务实的推理过程，能够选择性地整合个性化信息，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 的个性化记忆机制虽然能提升响应的个性化程度，但容易引入不相关的记忆信息，干扰模型的意图理解，从而影响用户体验。研究旨在全面探究个性化的双重影响，并提出解决方案。

Method: 研究者开发了一个名为 RPEval 的基准测试，包含个性化意图推理数据集和多粒度评估协议。同时，他们提出了一种名为 RP-Reasoner 的新方法，将记忆利用视为一个务实的推理过程，以实现个性化信息的选择性整合。

Result: RPEval 基准测试揭示了现有 LLM 中普遍存在的非理性个性化现象。RP-Reasoner 方法在 RPEval 上显著优于现有基线方法，并解决了大型商业个性化助手中的 80% 的不良案例。

Conclusion: 务实的推理方法可以有效缓解 LLM 中的非理性个性化问题，从而提高个性化助手在用户交互中的表现和用户体验。

Abstract: Large language model (LLM)-powered assistants have recently integrated memory mechanisms that record user preferences, leading to more personalized and user-aligned responses. However, irrelevant personalized memories are often introduced into the context, interfering with the LLM's intent understanding. To comprehensively investigate the dual effects of personalization, we develop RPEval, a benchmark comprising a personalized intent reasoning dataset and a multi-granularity evaluation protocol. RPEval reveals the widespread phenomenon of irrational personalization in existing LLMs and, through error pattern analysis, illustrates its negative impact on user experience. Finally, we introduce RP-Reasoner, which treats memory utilization as a pragmatic reasoning process, enabling the selective integration of personalized information. Experimental results demonstrate that our method significantly outperforms carefully designed baselines on RPEval, and resolves 80% of the bad cases observed in a large-scale commercial personalized assistant, highlighting the potential of pragmatic reasoning to mitigate irrational personalization. Our benchmark is publicly available at https://github.com/XueyangFeng/RPEval.

</details>


### [111] [MultiLexNorm++: A Unified Benchmark and a Generative Model for Lexical Normalization for Asian Languages](https://arxiv.org/abs/2601.16623)
*Weerayut Buaphet,Thanh-Nhi Nguyen,Risa Kondo,Tomoyuki Kajiwara,Yumin Kim,Jimin Lee,Hwanhee Lee,Holy Lovenia,Peerat Limkonchotiwat,Sarana Nutanong,Rob Van der Goot*

Main category: cs.CL

TL;DR: 本文提出了一个针对亚洲语言的词汇规范化基准扩展，并提出了一种基于大型语言模型（LLM）的新架构，以提高在这些语言上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的词汇规范化基准（如MultiLexNorm）主要集中在印欧语系的拉丁字母语言，缺乏对亚洲语言的支持。社交媒体数据的非正式性和多样性对NLP模型提出了挑战，需要对其进行规范化处理。

Method: 作者扩展了MultiLexNorm基准，加入了5种亚洲语言（涵盖4种不同书写系统）。他们评估了现有最先进的模型在新增语言上的表现，并提出了一种基于LLM的新架构来解决性能下降的问题。

Result: 现有最先进的模型在新的亚洲语言上表现不佳。基于LLM的新架构在这些语言上展现出更鲁棒的性能。

Conclusion: 亚洲语言的词汇规范化是一个重要的研究方向，现有的模型需要改进以适应这些语言的多样性。基于LLM的架构是未来词汇规范化研究的一个有前景的方向。

Abstract: Social media data has been of interest to Natural Language Processing (NLP) practitioners for over a decade, because of its richness in information, but also challenges for automatic processing. Since language use is more informal, spontaneous, and adheres to many different sociolects, the performance of NLP models often deteriorates. One solution to this problem is to transform data to a standard variant before processing it, which is also called lexical normalization. There has been a wide variety of benchmarks and models proposed for this task. The MultiLexNorm benchmark proposed to unify these efforts, but it consists almost solely of languages from the Indo-European language family in the Latin script. Hence, we propose an extension to MultiLexNorm, which covers 5 Asian languages from different language families in 4 different scripts. We show that the previous state-of-the-art model performs worse on the new languages and propose a new architecture based on Large Language Models (LLMs), which shows more robust performance. Finally, we analyze remaining errors, revealing future directions for this task.

</details>


### [112] [SoS: Analysis of Surface over Semantics in Multilingual Text-To-Image Generation](https://arxiv.org/abs/2601.16803)
*Carolin Holtermann,Florian Schneider,Anne Lauscher*

Main category: cs.CL

TL;DR: 该研究首次分析了文本到图像（T2I）模型在处理非英语提示时出现的“表面优先于语义”（SoS）现象，即模型倾向于生成与语言表面形式相关的刻板印象图像，而非提示的真实含义。研究发现，大多数T2I模型都存在这种倾向，并且这种倾向会随着文本编码器的层级加深而加剧。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，T2I模型对不同语言输入的敏感度很高，在处理非英语提示时，模型常常生成刻板印象的图像，优先考虑语言的表面形式而非语义。然而，缺乏对这一现象（称为SoS）的全面分析。

Method: 研究者创建了一套包含171个文化身份的提示集，并将其翻译成14种语言，然后用这些提示测试了七种T2I模型。为了量化SoS倾向，研究者引入了一个新的度量方法，并分析了这些倾向在视觉上的表现。

Result: 研究发现，除了一个模型外，所有模型在至少两种语言中都表现出强烈的表面层倾向。这种效应在T2I文本编码器的层级中也越发明显。此外，这些表面倾向常常与刻板的视觉描绘相关联。

Conclusion: T2I模型普遍存在“表面优先于语义”（SoS）的倾向，特别是在处理非英语提示时，这种倾向与生成刻板印象图像相关。这种现象在模型的文本编码器深层尤为显著。

Abstract: Text-to-image (T2I) models are increasingly employed by users worldwide. However, prior research has pointed to the high sensitivity of T2I towards particular input languages - when faced with languages other than English (i.e., different surface forms of the same prompt), T2I models often produce culturally stereotypical depictions, prioritizing the surface over the prompt's semantics. Yet a comprehensive analysis of this behavior, which we dub Surface-over-Semantics (SoS), is missing. We present the first analysis of T2I models' SoS tendencies. To this end, we create a set of prompts covering 171 cultural identities, translated into 14 languages, and use it to prompt seven T2I models. To quantify SoS tendencies across models, languages, and cultures, we introduce a novel measure and analyze how the tendencies we identify manifest visually. We show that all but one model exhibit strong surface-level tendency in at least two languages, with this effect intensifying across the layers of T2I text encoders. Moreover, these surface tendencies frequently correlate with stereotypical visual depictions.

</details>


### [113] [Typologically Informed Parameter Aggregation](https://arxiv.org/abs/2601.16629)
*Stef Accou,Wessel Poelman*

Main category: cs.CL

TL;DR: 提出了一种名为 TIPA 的训练无关方法，通过聚合现有适配器来构建代理语言适配器，以实现跨语言泛化，尤其是在低资源语言方面。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言模型在低资源和未见过的语言上表现不佳，而基于适配器的微调成本高昂。

Method: TIPA 通过根据语言类型相似度对现有适配器进行加权聚合来创建代理适配器，并将其集成到 MAD-X 框架中，以实现零样本跨语言迁移。

Result: 在五项 NLP 任务和超过 230 种语言的评估中，TIPA 的表现优于或等于基线方法，尤其是在缺乏专用适配器的语言上。

Conclusion: 基于语言类型信息进行聚合是一种无需额外训练即可实现跨语言迁移的可行替代方案。

Abstract: Massively multilingual language models enable cross-lingual generalization but underperform on low-resource and unseen languages. While adapter-based fine-tuning offers a parameter-efficient solution, training language-specific adapters at scale remains costly. We introduce Typologically Informed Parameter Aggregation (TIPA), a training-free method that constructs proxy language adapters by aggregating existing ones, weighted by typological similarity. Integrated into the MAD-X framework, these proxies enable zero-shot cross-lingual transfer without additional training. We evaluate TIPA on five NLP tasks and over 230 languages. TIPA consistently outperforms or matches baselines such as English-only fine-tuning or selecting the typologically closest language adapter. We see the largest gains for languages lacking dedicated adapters. Our results demonstrate that typologically informed aggregation provides a viable alternative to language-specific modules without any training needed.

</details>


### [114] [Select or Project? Evaluating Lower-dimensional Vectors for LLM Training Data Explanations](https://arxiv.org/abs/2601.16651)
*Lukas Hinterleitner,Loris Schoenegger,Benjamin Roth*

Main category: cs.CL

TL;DR: 本文研究了在LLM中进行基于梯度的实例解释时，如何通过选择模型组件子集或投影全梯度来降低计算成本。研究表明，贪婪选择的组件子集比全梯度或随机投影更能有效地捕捉训练数据的影响信息，并且计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度的LLM实例解释方法受限于模型梯度的高维性，需要对参数进行子集选择，但这种选择往往是随意的且缺乏系统评估。因此，研究者需要更有效且可计算的方法来解决这个问题。

Method: 本文提出并评估了两种降低梯度维度的策略：1) 选择一小组架构上信息丰富的模型组件；2) 将全梯度投影到低维空间。通过一个新颖的基准测试，比较了这两种方法以及随机投影和全梯度在检索任务上的表现。

Result: 研究发现，贪婪选择的组件子集在捕捉训练数据影响信息方面优于全梯度和随机投影。此外，这种方法比随机投影更具计算效率。

Conclusion: 针对大型模型的实例解释，定向选择模型组件是一种比全梯度或随机投影更有效且计算上更可行的策略，可以降低计算成本并提高解释的准确性。

Abstract: Gradient-based methods for instance-based explanation for large language models (LLMs) are hindered by the immense dimensionality of model gradients. In practice, influence estimation is restricted to a subset of model parameters to make computation tractable, but this subset is often chosen ad hoc and rarely justified by systematic evaluation. This paper investigates if it is better to create low-dimensional representations by selecting a small, architecturally informed subset of model components or by projecting the full gradients into a lower-dimensional space. Using a novel benchmark, we show that a greedily selected subset of components captures the information about training data influence needed for a retrieval task more effectively than either the full gradient or random projection. We further find that this approach is more computationally efficient than random projection, demonstrating that targeted component selection is a practical strategy for making instance-based explanations of large models more computationally feasible.

</details>


### [115] [EMemBench: Interactive Benchmarking of Episodic Memory for VLM Agents](https://arxiv.org/abs/2601.16690)
*Xinze Li,Ziyue Zhu,Siyuan Liu,Yubo Ma,Yuhang Zang,Yixin Cao,Aixin Sun*

Main category: cs.CL

TL;DR: EMemBench 是一个用于评估长短期记忆的基准测试，它通过生成交互式游戏中的问题来测试智能体，涵盖文本和视觉环境。结果表明，归纳和空间推理是主要的瓶颈，尤其是在视觉环境中。持久记忆对文本游戏中的智能体有帮助，但对视觉语言模型（VLM）的帮助不一致。


<details>
  <summary>Details</summary>
Motivation: 现有的长短期记忆评估方法存在不足，例如使用固定问题集，无法全面评估智能体在动态交互环境中的记忆能力。研究人员希望开发一个更具挑战性、更能反映真实世界场景的评估基准。

Method: EMemBench 通过程序化生成问题，并利用游戏信号计算可验证的地面真值，覆盖了单跳/多跳回忆、归纳、时间、空间、逻辑和对抗等多种记忆技能。研究人员在 15 个文本游戏和多个视觉环境中，评估了基于大型语言模型（LMs）/视觉语言模型（VLMs）的智能体，并将上下文提示作为基线。

Result: 在 EMemBench 上，智能体的表现远未达到饱和。归纳和空间推理是持续存在的瓶颈，尤其是在视觉环境中。持久记忆对基于 LM 的开放式模型在文本游戏上的表现有显著提升，但对 VLM 智能体的改进并不一致。EMemBench 的人类研究也证实了其评估的难度。

Conclusion: EMemBench 提供了一个更具挑战性的长短期记忆评估框架。研究表明，目前的智能体在归纳和空间推理方面存在显著不足，尤其是在处理视觉信息时。为 VLM 智能体构建有效的视觉情景记忆仍然是一个开放的挑战。

Abstract: We introduce EMemBench, a programmatic benchmark for evaluating long-term memory of agents through interactive games. Rather than using a fixed set of questions, EMemBench generates questions from each agent's own trajectory, covering both text and visual game environments. Each template computes verifiable ground truth from underlying game signals, with controlled answerability and balanced coverage over memory skills: single/multi-hop recall, induction, temporal, spatial, logical, and adversarial. We evaluate memory agents with strong LMs/VLMs as backbones, using in-context prompting as baselines. Across 15 text games and multiple visual seeds, results are far from saturated: induction and spatial reasoning are persistent bottlenecks, especially in visual setting. Persistent memory yields clear gains for open backbones on text games, but improvements are less consistent for VLM agents, suggesting that visually grounded episodic memory remains an open challenge. A human study further confirms the difficulty of EMemBench.

</details>


### [116] [Trapped in the past? Disentangling fluid and crystallized intelligence of large language models using chess](https://arxiv.org/abs/2601.16823)
*Leonard S. Pleiss,Maximilian Schiffer,Robert K. von Weizsäcker*

Main category: cs.CL

TL;DR: 本研究使用国际象棋作为测试平台，旨在区分大型语言模型（LLMs）的记忆能力（晶体智力）和推理能力（流体智力）。研究发现，LLMs在面对需要流体智力（即新颖、需要从头开始推理的局面）的任务时，性能急剧下降，甚至在训练分布之外的任务中表现接近随机。尽管模型规模的提升有所改善，但对于超出训练分布的任务，进步幅度不大。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）虽然能力强大，但其能力究竟是来源于记忆（晶体智力）还是真正的推理（流体智力）尚不清楚。本研究希望通过构建一个受控的测试环境来区分这两种能力。

Method: 研究者利用国际象棋的结构和引擎评估，构建了一个包含不同“训练语料库邻近度”的棋局分类。这些棋局从可以通过记忆解决的常见局面，到需要从零开始推理的新颖局面不等。研究者系统地评估了不同GPT模型的表现，并在不同推理强度下进行测试。

Result: 研究结果显示，随着对流体智力需求的增加，LLMs的性能呈清晰的下降趋势。在脱离训练分布的（out-of-distribution）任务中，模型的性能急剧下降至接近随机水平。尽管较新的模型有所改进，但在超出训练分布的任务上，性能提升显著放缓。此外，经过推理增强的推理（reasoning-augmented inference）虽然能提升性能，但其边际效益随着分布邻近度的增加而递减。

Conclusion: 当前的大型语言模型架构在系统性泛化能力上存在局限，其能力主要还是依赖于在训练数据中的记忆和模式识别。要实现鲁棒的流体智力，需要超越单纯扩大模型规模的机制。

Abstract: Large Language Models (LLMs) exhibit remarkable capabilities, yet it remains unclear to what extent these reflect sophisticated recall (crystallized intelligence) or reasoning ability (fluid intelligence). We introduce chess as a controlled testbed for disentangling these faculties. Leveraging the game's structure and scalable engine evaluations, we construct a taxonomy of positions varying in training corpus proximity--ranging from common states solvable by memorization to novel ones requiring first-principles reasoning. We systematically evaluate multiple GPT generations under varying reasoning intensities. Our analysis reveals a clear gradient: performance consistently degrades as fluid intelligence demands increase. Notably, in out-of-distribution tasks, performance collapses to random levels. While newer models improve, progress slows significantly for tasks outside the training distribution. Furthermore, while reasoning-augmented inference improves performance, its marginal benefit per token decreases with distributional proximity. These results suggest current architectures remain limited in systematic generalization, highlighting the need for mechanisms beyond scale to achieve robust fluid intelligence.

</details>


### [117] [LLM-Based Adversarial Persuasion Attacks on Fact-Checking Systems](https://arxiv.org/abs/2601.16890)
*João A. Leite,Olesya Razuvayevskaya,Kalina Bontcheva,Carolina Scarton*

Main category: cs.CL

TL;DR: 本研究提出了一种利用说服技巧的生成式对抗性攻击方法，通过大型语言模型（LLM）重写事实核查（AFC）系统中的虚假声明，以逃避检测，并在FEVER和FEVEROUS基准测试中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动事实核查（AFC）系统容易受到对抗性攻击，而现有的攻击方法主要依赖于注入噪声或改变语义。研究动机在于弥补现有研究在利用说服技巧方面的不足，因为说服技巧在虚假信息传播中被广泛用于操纵受众。

Method: 利用生成式大型语言模型（LLM）采用15种（分为6类）说服技巧重写声明，以此发起对抗性攻击。通过分离式评估策略，分别研究说服技巧对声明验证和证据检索的影响。

Result: 在FEVER和FEVEROUS基准测试上的实验表明，说服性攻击能够显著降低AFC系统的声明验证性能和证据检索能力。

Conclusion: 研究结果表明，说服技巧是一类有效的对抗性攻击方法，凸显了构建更鲁棒的AFC系统的重要性。

Abstract: Automated fact-checking (AFC) systems are susceptible to adversarial attacks, enabling false claims to evade detection. Existing adversarial frameworks typically rely on injecting noise or altering semantics, yet no existing framework exploits the adversarial potential of persuasion techniques, which are widely used in disinformation campaigns to manipulate audiences. In this paper, we introduce a novel class of persuasive adversarial attacks on AFCs by employing a generative LLM to rephrase claims using persuasion techniques. Considering 15 techniques grouped into 6 categories, we study the effects of persuasion on both claim verification and evidence retrieval using a decoupled evaluation strategy. Experiments on the FEVER and FEVEROUS benchmarks show that persuasion attacks can substantially degrade both verification performance and evidence retrieval. Our analysis identifies persuasion techniques as a potent class of adversarial attacks, highlighting the need for more robust AFC systems.

</details>


### [118] [Better Generalizing to Unseen Concepts: An Evaluation Framework and An LLM-Based Auto-Labeled Pipeline for Biomedical Concept Recognition](https://arxiv.org/abs/2601.16711)
*Shanshan Liu,Noriki Nishida,Fei Cheng,Narumi Tokunaga,Rumana Ferdous Munne,Yuki Yamagata,Kouji Kozaki,Takehito Utsuro,Yuji Matsumoto*

Main category: cs.CL

TL;DR: 该研究提出了一个评估框架和一套新颖的指标来衡量模型在生物医学概念识别（MA-BCR）中的泛化能力，并利用大型语言模型（LLM）生成自动标记数据（ALD）作为一种可扩展的资源来提高模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于生物医学概念识别（MA-BCR）中手动标注数据的稀缺性，模型在识别未见过的概念时面临泛化能力差的挑战。

Method: 研究提出了一个基于分层概念索引和新颖度量的评估框架来衡量泛化能力，并探索了使用LLM生成任务特定的自动标记数据（ALD）作为一种可扩展资源。

Result: 研究表明，LLM生成的ALD虽然不能完全替代手动标注，但可以显著提高模型的泛化能力，为模型提供更广泛的覆盖范围和结构化知识，以识别未见过的概念。

Conclusion: LLM生成的ALD是提高MA-BCR模型泛化能力的有价值资源，能够缓解数据稀缺问题，但仍需结合手动标注数据以达到最佳效果。

Abstract: Generalization to unseen concepts is a central challenge due to the scarcity of human annotations in Mention-agnostic Biomedical Concept Recognition (MA-BCR). This work makes two key contributions to systematically address this issue. First, we propose an evaluation framework built on hierarchical concept indices and novel metrics to measure generalization. Second, we explore LLM-based Auto-Labeled Data (ALD) as a scalable resource, creating a task-specific pipeline for its generation. Our research unequivocally shows that while LLM-generated ALD cannot fully substitute for manual annotations, it is a valuable resource for improving generalization, successfully providing models with the broader coverage and structural knowledge needed to approach recognizing unseen concepts. Code and datasets are available at https://github.com/bio-ie-tool/hi-ald.

</details>


### [119] [Mitigating Bias in Automated Grading Systems for ESL Learners: A Contrastive Learning Approach](https://arxiv.org/abs/2601.16724)
*Kevin Fan,Eric Yun*

Main category: cs.CL

TL;DR: 本研究分析了自动论文评分（AES）系统对英语作为第二语言（ESL）学习者的偏见，发现现有模型在ESL写作中存在评分偏低现象。研究提出了基于对比学习的匹配文章对方法，有效缓解了评分差异，并使模型能够区分句子复杂度和语法错误。


<details>
  <summary>Details</summary>
Motivation: 现有自动论文评分（AES）系统在用于高风险教育评估时，存在针对英语作为第二语言（ESL）学习者的算法偏见。基于Transformer的回归模型主要在以英语为母语者语料库上训练，容易学习到表面L2语言特征与论文质量之间的虚假关联。

Method: 研究者对一个微调过的DeBERTa-v3模型进行了偏见研究，使用了ASAP 2.0和ELLIPSE数据集。为了缓解偏见，提出了一种对比学习方法，采用匹配文章对（matched essay pairs）的三元组构建策略。构建了一个包含17,161对匹配文章的数据集，并使用Triplet Margin Loss对模型进行微调，以对齐ESL和母语写作的潜在表征。

Result: 研究发现，高熟练度ESL写作的评分比相同人类评分质量的母语者文章低10.3%。提出的对比学习方法将高熟练度评分差异减少了39.9%（降至6.2%），同时保持了0.76的Quadratic Weighted Kappa（QWK）得分。事后语言分析表明，模型成功地将句子复杂度与语法错误分离开，避免了对有效的L2句法结构的惩罚。

Conclusion: 现有的AES模型存在对ESL学习者评分偏低的现象。通过引入对比学习和匹配文章对的策略，可以有效缓解这种评分偏见，并提高模型的公平性，使其能够更好地评估ESL学生的写作能力，区分句子复杂度和语法问题。

Abstract: As Automated Essay Scoring (AES) systems are increasingly used in high-stakes educational settings, concerns regarding algorithmic bias against English as a Second Language (ESL) learners have increased. Current Transformer-based regression models trained primarily on native-speaker corpora often learn spurious correlations between surface-level L2 linguistic features and essay quality. In this study, we conduct a bias study of a fine-tuned DeBERTa-v3 model using the ASAP 2.0 and ELLIPSE datasets, revealing a constrained score scaling for high-proficiency ESL writing where high-proficiency ESL essays receive scores 10.3% lower than Native speaker essays of identical human-rated quality. To mitigate this, we propose applying contrastive learning with a triplet construction strategy: Contrastive Learning with Matched Essay Pairs. We constructed a dataset of 17,161 matched essay pairs and fine-tuned the model using Triplet Margin Loss to align the latent representations of ESL and Native writing. Our approach reduced the high-proficiency scoring disparity by 39.9% (to a 6.2% gap) while maintaining a Quadratic Weighted Kappa (QWK) of 0.76. Post-hoc linguistic analysis suggests the model successfully disentangled sentence complexity from grammatical error, preventing the penalization of valid L2 syntactic structures.

</details>


### [120] [Persuasion Tokens for Editing Factual Knowledge in LLMs](https://arxiv.org/abs/2601.16781)
*Paul Youssef,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: 本文提出了一种名为“说服性标记”（P-Tokens）的新方法，以克服当前 in-context knowledge editing（IKE）技术在知识更新过程中需要冗长、事实特定的演示以及占用大量上下文窗口空间的问题。P-Tokens 是一种特殊标记，经过训练后无需事实演示即可实现 IKE 的效果，从而提高了知识编辑的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的 in-context knowledge editing (IKE) 技术需要耗费大量资源来创建事实特定的演示，并且这些演示会占用大量的上下文窗口空间，限制了其在实际应用中的可扩展性和效率。

Method: 引入并训练了“说服性标记”（P-Tokens），这些标记被设计用来在不依赖于事实特定演示的情况下，复制 IKE 技术的效果。通过在两个编辑数据集和三个 LLM 上进行评估来验证 P-Tokens 的性能。

Result: P-Tokens 在知识编辑任务上的表现与 IKE 相当，甚至在许多情况下有所超越。研究还发现，P-Tokens 对相邻事实的干扰具有鲁棒性，并且增加 P-Tokens 的数量可以提高编辑性能。

Conclusion: P-Tokens 提供了一种更实用、更具可扩展性的 LLM 知识编辑替代方案，克服了现有 IKE 方法在演示成本和上下文空间方面的限制。

Abstract: In-context knowledge editing (IKE) is a promising technique for updating Large Language Models (LLMs) with new information. However, IKE relies on lengthy, fact-specific demonstrations which are costly to create and consume significant context window space. In this paper, we introduce persuasion tokens (P-Tokens) -- special tokens trained to replicate the effect of IKE demonstrations, enabling efficient knowledge editing without requiring fact-specific demonstrations. We evaluate P-Tokens across two editing datasets and three LLMs, demonstrating performance comparable to, and often exceeding, IKE. We further find that editing performance is robust to distractors with small negative effects to neighboring facts, and that increasing the number of P-Tokens improves performance. Our work addresses key limitations of IKE and provides a more practical and scalable alternative for editing LLMs.

</details>


### [121] [Information Representation Fairness in Long-Document Embeddings: The Peculiar Interaction of Positional and Language Bias](https://arxiv.org/abs/2601.16934)
*Elias Schuhmacher,Andrianos Michail,Juri Opitz,Rico Sennrich,Simon Clematide*

Main category: cs.CL

TL;DR: 本文提出了一种评估嵌入模型中潜在偏见（位置和语言）的框架，并提出了一种在嵌入时校准注意力的技术来减轻这些偏见，以提高长文档中较晚片段的可发现性。


<details>
  <summary>Details</summary>
Motivation: 当前的嵌入模型在反映文档的各个部分时可能存在偏差，导致某些部分（如较早的片段或高资源语言的片段）在基于嵌入的搜索中被过度代表，而另一些部分（如较晚的片段或低资源语言的片段）则被边缘化。

Method: 作者引入了一个基于置换的评估框架来量化偏见。他们观察到，长文档和多片段文档中的模型存在位置和语言偏见。通过进一步分析，他们发现这种位置偏见源于池化标记嵌入中前置的注意力分布。为了解决这个问题，他们提出了一种推理时注意力校准方法，该方法可以更均匀地重新分配文档位置的注意力。

Result: 使用作者提出的评估框架，作者发现最先进的嵌入模型在处理长文档时会表现出系统性的位置和语言偏见。早期片段和高资源语言（如英语）的片段被过度代表，而后期片段和低资源语言的片段则被边缘化。注意力校准方法提高了后期片段的可发现性。

Conclusion: 最先进的嵌入模型存在位置和语言偏见，尤其是在处理长文档时。作者提出的注意力校准方法可以有效减轻这些偏见，提高文档各个部分的可发现性。

Abstract: To be discoverable in an embedding-based search process, each part of a document should be reflected in its embedding representation. To quantify any potential reflection biases, we introduce a permutation-based evaluation framework. With this, we observe that state-of-the-art embedding models exhibit systematic positional and language biases when documents are longer and consist of multiple segments. Specifically, early segments and segments in higher-resource languages like English are over-represented, while later segments and segments in lower-resource languages are marginalized. In our further analysis, we find that the positional bias stems from front-loaded attention distributions in pooling-token embeddings, where early tokens receive more attention. To mitigate this issue, we introduce an inference-time attention calibration method that redistributes attention more evenly across document positions, increasing discoverabiltiy of later segments. Our evaluation framework and attention calibration is available at https://github.com/impresso/fair-sentence-transformers

</details>


### [122] [Large Language Models as Automatic Annotators and Annotation Adjudicators for Fine-Grained Opinion Analysis](https://arxiv.org/abs/2601.16800)
*Gaurav Negi,MA Waskow,Paul Buitelaar*

Main category: cs.CL

TL;DR: 研究探索了使用大型语言模型（LLM）作为自动标注器来解决细粒度意见分析数据标注成本高和人力需求大的问题，并提出了一种声明式标注流程和多标签裁决方法，实验证明LLM可以高效地生成高质量的标注数据。


<details>
  <summary>Details</summary>
Motivation: 传统的细粒度意见分析需要大量人力和成本进行数据标注，尤其是在跨领域和真实应用场景下，这限制了模型训练和部署。因此，需要一种更高效的数据标注方法。

Method: 提出了一种声明式标注流程，以减少手动设计提示词的变异性。同时，开发了一种新颖的方法，让LLM能够裁决多个标签并生成最终标注。该方法在Aspect Sentiment Triplet Extraction (ASTE) 和 Aspect-Category-Opinion-Sentiment (ACOS) 任务上进行了试验。

Result: 通过在不同规模的模型上进行试验，证明了LLM可以作为自动标注器和裁决者，在个体LLM标注器之间实现了高的一致性（Inter-Annotator Agreement）。

Conclusion: LLM可以有效地自动标注细粒度意见数据，显著降低创建标注数据集的成本和人力投入，克服了现有标注方法的局限性。

Abstract: Fine-grained opinion analysis of text provides a detailed understanding of expressed sentiments, including the addressed entity. Although this level of detail is sound, it requires considerable human effort and substantial cost to annotate opinions in datasets for training models, especially across diverse domains and real-world applications. We explore the feasibility of LLMs as automatic annotators for fine-grained opinion analysis, addressing the shortage of domain-specific labelled datasets. In this work, we use a declarative annotation pipeline. This approach reduces the variability of manual prompt engineering when using LLMs to identify fine-grained opinion spans in text. We also present a novel methodology for an LLM to adjudicate multiple labels and produce final annotations. After trialling the pipeline with models of different sizes for the Aspect Sentiment Triplet Extraction (ASTE) and Aspect-Category-Opinion-Sentiment (ACOS) analysis tasks, we show that LLMs can serve as automatic annotators and adjudicators, achieving high Inter-Annotator Agreement across individual LLM-based annotators. This reduces the cost and human effort needed to create these fine-grained opinion-annotated datasets.

</details>


### [123] [Strategies for Span Labeling with Large Language Models](https://arxiv.org/abs/2601.16946)
*Danil Semin,Ondřej Dušek,Zdeněk Kasner*

Main category: cs.CL

TL;DR: 本文提出了一种名为LogitMatch的受限解码方法，用于解决大型语言模型（LLM）在文本分析任务中引用输入文本片段的挑战，并发现它能在某些情况下优于现有的提示策略。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式LLM缺乏明确引用输入文本片段的机制，导致span标注的提示策略效果不一。作者希望找到一种更有效的方法来解决这个问题。

Method: 文章将现有的span标注策略分为三类：标记输入文本、索引数字位置和匹配span内容。在此基础上，作者提出了一种新的受限解码方法LogitMatch，强制模型的输出与合法的输入span对齐。

Result: LogitMatch在消除span匹配问题方面优于其他基于匹配的方法，并在某些设置下超越了其他策略。原始的标记方法仍然是一个稳健的基线。

Conclusion: LogitMatch是一种有效的方法，可以提高LLM在span标注任务中的性能，解决了一类现有方法存在的匹配问题。

Abstract: Large language models (LLMs) are increasingly used for text analysis tasks, such as named entity recognition or error detection. Unlike encoder-based models, however, generative architectures lack an explicit mechanism to refer to specific parts of their input. This leads to a variety of ad-hoc prompting strategies for span labeling, often with inconsistent results. In this paper, we categorize these strategies into three families: tagging the input text, indexing numerical positions of spans, and matching span content. To address the limitations of content matching, we introduce LogitMatch, a new constrained decoding method that forces the model's output to align with valid input spans. We evaluate all methods across four diverse tasks. We find that while tagging remains a robust baseline, LogitMatch improves upon competitive matching-based methods by eliminating span matching issues and outperforms other strategies in some setups.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [124] [DMAVA: Distributed Multi-Autonomous Vehicle Architecture Using Autoware](https://arxiv.org/abs/2601.16336)
*Zubair Islam,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 该论文提出了一种分布式多自动驾驶汽车架构（DMAVA），它允许在多个物理主机上同步进行实时自动驾驶模拟，每个车辆运行独立的堆栈并通过数据中心通信实现同步协调。


<details>
  <summary>Details</summary>
Motivation: 现有模拟架构在多车操作或集中控制方面存在局限性，难以有效模拟和验证多辆自动驾驶汽车之间的协调。

Method: 提出DMAVA架构，使用ROS 2 Humble、Autoware Universe、AWSIM Labs和Zenoh，在Unity环境中集成多个Autoware堆栈，通过低延迟的数据中心通信层实现多主机同步的实时模拟。

Result: 实验证明了DMAVA在多主机配置下具有稳定的定位、可靠的跨主机通信以及完全同步的闭环控制。

Conclusion: DMAVA成功实现了多辆自动驾驶汽车在分布式环境下的同步实时模拟，并可作为多车自主代客泊车等更高级协作自动驾驶应用的基础。

Abstract: Simulating and validating coordination among multiple autonomous vehicles (AVs) is a challenging task as most existing simulation architectures are limited to single-vehicle operation or rely on centralized control. This paper presents a Distributed Multi-AV Architecture (DMAVA) that enables synchronized, real-time autonomous driving simulation across multiple physical hosts. Each vehicle runs its own complete AV stack and operates independently from other AVs. The vehicles in the simulation maintain synchronized coordination through a low-latency data-centric communication layer. The proposed system integrates ROS 2 Humble, Autoware Universe, AWSIM Labs, and Zenoh to support concurrent execution of multiple Autoware stacks within a shared Unity-based environment. Experiments conducted on multiple-host configurations demonstrate stable localization, reliable inter-host communication, and fully synchronized closed-loop control. The DMAVA also serves as a foundation for Multi-Vehicle Autonomous Valet Parking, demonstrating its extensibility toward higher-level cooperative autonomy. Demo videos and source code are available at: https://github.com/zubxxr/distributed-multi-autonomous-vehicle-architecture.

</details>


### [125] [GNSS-based Lunar Orbit and Clock Estimation With Stochastic Cloning UD Filter](https://arxiv.org/abs/2601.16393)
*Keidai Iiyama,Grace Gao*

Main category: cs.RO

TL;DR: 本文提出了一种基于陆地GNSS的月球导航卫星轨道和时钟估计算法，该算法通过改进的滤波器和平滑器，并考虑了复杂的动力学和测量模型，在模拟中达到了米级轨道精度和亚毫秒/秒的速度精度。


<details>
  <summary>Details</summary>
Motivation: 为了在月球导航场景下，克服低可观测性条件，实现高精度的轨道和时钟估算。

Method: 开发了随机克隆UD分解滤波器和延迟状态平滑器，用于处理精确的时间差载波相位（TDCP）测量。构建了包含相对论耦合、月球时标转换、电离层、等离子体层和Shapiro延迟等效应的动力学和测量模型。

Result: 在包含多星座GNSS几何、广播星历误差、月球卫星动力学和经验电子密度模型计算的电离层/等离子体层延迟的蒙特卡罗模拟中，结合无电离层伪距和TDCP测量，实现了米级轨道精度和亚毫秒/秒的速度精度。

Conclusion: 所提出的基于陆地GNSS的轨道和时钟估计算法能够满足未来月球增强导航服务（LANS）严格的空间信号误差要求。

Abstract: This paper presents a terrestrial GNSS-based orbit and clock estimation framework for lunar navigation satellites. To enable high-precision estimation under the low-observability conditions encountered at lunar distances, we develop a stochastic-cloning UD-factorized filter and delayed-state smoother that provide enhanced numerical stability when processing precise time-differenced carrier phase (TDCP) measurements. A comprehensive dynamics and measurement model is formulated, explicitly accounting for relativistic coupling between orbital and clock states, lunar time-scale transformations, and signal propagation delays including ionospheric, plasmaspheric, and Shapiro effects. The proposed approach is evaluated using high-fidelity Monte-Carlo simulations incorporating realistic multi-constellation GNSS geometry, broadcast ephemeris errors, lunar satellite dynamics, and ionospheric and plasmaspheric delay computed from empirical electron density models. Simulation results demonstrate that combining ionosphere-free pseudorange and TDCP measurements achieves meter-level orbit accuracy and sub-millimeter-per-second velocity accuracy, satisfying the stringent signal-in-space error requirements of future Lunar Augmented Navigation Services (LANS).

</details>


### [126] [DMV-AVP: Distributed Multi-Vehicle Autonomous Valet Parking using Autoware](https://arxiv.org/abs/2601.16327)
*Zubair Islam,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 本文提出了一种名为DMV-AVP的分布式多车自动代客泊车（AVP）仿真系统，该系统基于DMAVA架构，通过引入状态协调、队列管理节点和集成YOLOv5的感知模块，实现了跨主机的同步、低延迟通信和无冲突的泊车行为，证明了其可扩展性和在分布式AVP仿真中的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的AVP仿真方法多采用中心化或非分布式设计，存在可扩展性受限和自主控制不彻底的问题。本研究旨在解决这些限制，实现更具可扩展性和自主性的多车AVP仿真。

Method: 研究者提出了DMV-AVP系统，基于DMAVA架构，包含两个关键模块：1) Multi-Vehicle AVP Node，负责多车间的状态协调、排队和预订管理；2) Unity-Integrated YOLOv5 Parking Spot Detection Module，用于在AWSIM Labs中实现基于视觉的实时车位检测。系统通信层采用Zenoh，确保低延迟和同步。

Result: 在双主机和三主机配置下的实验表明，DMV-AVP系统能够实现确定性的协调、无冲突的泊车行为，并展现出跨分布式Autoware实例的可扩展性能。

Conclusion: DMV-AVP系统成功支持了协作式AVP仿真，并为未来的真实世界和硬件在环验证奠定了基础。

Abstract: This paper presents the DMV-AVP System, a distributed simulation of Multi-Vehicle Autonomous Valet Parking (AVP). The system was implemented as an application of the Distributed Multi-Vehicle Architecture (DMAVA) for synchronized multi-host execution. Most existing simulation approaches rely on centralized or non-distributed designs that constrain scalability and limit fully autonomous control. This work introduces two modules built on top of the DMAVA: 1) a Multi-Vehicle AVP Node that performs state-based coordination, queuing, and reservation management across multiple vehicles, and 2) a Unity-Integrated YOLOv5 Parking Spot Detection Module that provides real-time, vision-based perception within AWSIM Labs. Both modules integrate seamlessly with the DMAVA and extend it specifically for multi-vehicle AVP operation, supported by a Zenoh-based communication layer that ensures low-latency topic synchronization and coordinated behavior across hosts. Experiments conducted on two- and three-host configurations demonstrate deterministic coordination, conflict-free parking behavior, and scalable performance across distributed Autoware instances. The results confirm that the proposed Distributed Multi-Vehicle AVP System supports cooperative AVP simulation and establishes a foundation for future real-world and hardware-in-the-loop validation. Demo videos and source code are available at https://github.com/zubxxr/multi-vehicle-avp

</details>


### [127] [Reinforcement Learning-Based Energy-Aware Coverage Path Planning for Precision Agriculture](https://arxiv.org/abs/2601.16405)
*Beining Wu,Zihao Ding,Leo Ostigaard,Jun Huang*

Main category: cs.RO

TL;DR: 本研究提出了一种基于Soft Actor-Critic（SAC）强化学习的能量感知覆盖路径规划（CPP）框架，用于解决农业机器人面临的能量限制问题，并在实验中取得了优于传统算法的覆盖率和能量安全性。


<details>
  <summary>Details</summary>
Motivation: 现有CPP解决方案忽视能量限制，导致在大规模或资源受限环境中操作不完整。研究旨在解决农业机器人CPP中的能量约束问题。

Method: 提出一个基于SAC强化学习的能量感知CPP框架。使用CNN提取空间特征，LSTM处理时序动态。设计了一个联合优化覆盖效率、能耗和返航约束的奖励函数。

Result: 在实验中，该框架实现了超过90%的覆盖率，同时保证了能量安全。与RRT、PSO和ACO等传统算法相比，覆盖率提高了13.4-19.5%，约束违反减少了59.9-88.3%。

Conclusion: 基于SAC的能量感知CPP框架是解决农业机器人能量受限CPP问题的有效且可扩展的解决方案。

Abstract: Coverage Path Planning (CPP) is a fundamental capability for agricultural robots; however, existing solutions often overlook energy constraints, resulting in incomplete operations in large-scale or resource-limited environments. This paper proposes an energy-aware CPP framework grounded in Soft Actor-Critic (SAC) reinforcement learning, designed for grid-based environments with obstacles and charging stations. To enable robust and adaptive decision-making under energy limitations, the framework integrates Convolutional Neural Networks (CNNs) for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal dynamics. A dedicated reward function is designed to jointly optimize coverage efficiency, energy consumption, and return-to-base constraints. Experimental results demonstrate that the proposed approach consistently achieves over 90% coverage while ensuring energy safety, outperforming traditional heuristic algorithms such as Rapidly-exploring Random Tree (RRT), Particle Swarm Optimization (PSO), and Ant Colony Optimization (ACO) baselines by 13.4-19.5% in coverage and reducing constraint violations by 59.9-88.3%. These findings validate the proposed SAC-based framework as an effective and scalable solution for energy-constrained CPP in agricultural robotics.

</details>


### [128] [Scalable Screw-Theoretic Synthesis for PDE-Based Dynamic Modeling of Multibody Flexible Manipulators](https://arxiv.org/abs/2601.16242)
*S. Yaqubi,J. Mattila*

Main category: cs.RO

TL;DR: 本文提出了一种基于螺理论的多体合成框架，用于对具有任意数量柔性连杆的串联机器人进行基于偏微分方程 (PDE) 的动力学建模，并在三维空间中实现了可扩展性。该方法通过个体柔性连杆的螺理论 PDE 模型和作用力强制执行的关节约束来构建系统模型，并将 PDE 模型转化为抽象柯西问题，保证了系统的良定性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于开发一种新颖、可扩展的框架，用于在三维空间中对具有任意数量柔性连杆的串联机器人进行基于偏微分方程 (PDE) 的动力学建模。

Method: 该方法系统地构建了单个柔性连杆的螺理论 PDE 模型，并通过相互作用力强制执行全约束关节。利用身体固定坐标系中的一组对偶螺钉来描述连杆动力学，并通过变分原理推导出统一的动力学方程。将个体连杆模型合成为可无限扩展的多体表示，并将 PDE 模型转化为抽象柯西问题。

Result: 该框架可以捕捉局部和全局动力学，并明确恢复所有动态状态，包括每个身体固定坐标系的运动和柔性连杆的分布式变形场。得到的方程被表述为半显式指数-1微分代数系统。

Conclusion: 所提出的框架能够以统一、可扩展的方式对串联柔性机器人进行动力学建模，并保证了模型的良定性。

Abstract: This paper presents a novel and scalable screw-theoretic multibody synthesis framework for PDE-based dynamic modeling of serial robotic manipulators with an arbitrary number of flexible links in three-dimensional space. The proposed approach systematically constructs screw-theoretic PDE models for individual flexible links and rigorously enforces holonomic joint constraints through interaction forces. The dynamics of each link are formulated using a set of dual screws expressed in body-fixed coordinates: one describing the motion of the body-fixed frame relative to the inertial frame, a second relating the body-fixed frame to the undeformed configuration, and a third capturing elastic deformations. By expressing the system energy and applying variational principles, the governing dynamics of each link had been previously derived in a unified manner. Synthesizing the individual link models yields an infinitely scalable multibody representation capable of capturing both local (subsystem-level) and global (system-level) dynamics. The framework explicitly recovers all dynamic states, including the motion of each body-fixed frame and the distributed deformation fields of the flexible links. For computational tractability and mathematical rigor, the resulting governing equations are formulated as a semi-explicit index-1 differential-algebraic system. Furthermore, by applying separation of variables, the PDE model is recast as an abstract Cauchy problem, and well-posedness of the resulting system is established.

</details>


### [129] [RENEW: Risk- and Energy-Aware Navigation in Dynamic Waterways](https://arxiv.org/abs/2601.16424)
*Mingi Jeong,Alberto Quattrini Li*

Main category: cs.RO

TL;DR: RENEW是一个用于自主水面航行器（ASV）在有外部干扰（如水流）的动态环境中的全局路径规划器，它通过统一的风险和能源感知策略，动态识别不可导航区域并强制执行自适应安全约束，以确保安全，并结合了约束三角剖分和轨迹优化。


<details>
  <summary>Details</summary>
Motivation: 自主水面航行器（ASV）在具有水流等外部干扰的动态环境中进行可靠导航是一个挑战。现有的方法可能无法有效处理不可导航区域的动态变化以及需要在不同拓扑结构之间进行选择的路径多样性。

Method: RENEW采用一种分层架构：高层进行约束三角剖分以实现拓扑多样性，低层在安全走廊内进行轨迹优化。它引入了一个统一的风险和能源感知策略，通过动态识别不可导航区域和自适应安全约束来保证安全，并借鉴了海上应急规划中的尽力而为策略。

Result: RENEW在真实海洋数据上进行了验证，证明了其在动态和受干扰环境中的鲁棒性。它能够成功地生成既安全又高效的路径，同时考虑了不可导航区域的变化和拓扑路径选择。

Conclusion: RENEW是第一个能够联合处理自适应不可导航性和拓扑路径多样性的鲁棒海上导航框架，为自主水面航行器在复杂动态环境中的安全可靠导航提供了一种新颖有效的解决方案。

Abstract: We present RENEW, a global path planner for Autonomous Surface Vehicle (ASV) in dynamic environments with external disturbances (e.g., water currents). RENEW introduces a unified risk- and energy-aware strategy that ensures safety by dynamically identifying non-navigable regions and enforcing adaptive safety constraints. Inspired by maritime contingency planning, it employs a best-effort strategy to maintain control under adverse conditions. The hierarchical architecture combines high-level constrained triangulation for topological diversity with low-level trajectory optimization within safe corridors. Validated with real-world ocean data, RENEW is the first framework to jointly address adaptive non-navigability and topological path diversity for robust maritime navigation.

</details>


### [130] [Zero-Shot MARL Benchmark in the Cyber-Physical Mobility Lab](https://arxiv.org/abs/2601.16578)
*Julius Beerwerth,Jianye Xu,Simon Schäfer,Fynn Belderink,Bassam Alrifaee*

Main category: cs.RO

TL;DR: 该研究提出一个用于评估多智能体强化学习 (MARL) 在网联自动驾驶汽车 (CAVs) 中模拟到现实迁移的基准测试平台。该平台整合了模拟、高保真数字孪生和物理测试台，可以对 MARL 运动规划策略进行结构化的零样本评估。通过在一个 SigmaRL 训练的策略的三个域（模拟、数字孪生、物理测试台）的部署，研究揭示了导致性能下降的两个主要因素：模拟和硬件控制堆栈之间的架构差异，以及环境真实性增加带来的模拟到现实差距。


<details>
  <summary>Details</summary>
Motivation: 现有 MARL 策略的模拟到现实迁移评估缺乏一个可复现的基准。研究旨在创建一个整合模拟、数字孪生和物理测试台的平台，以系统地评估 MARL 在 CAV 场景中的迁移能力，并理解导致性能下降的根本原因。

Method: 研究构建了一个基于 Cyber-Physical Mobility Lab (CPM Lab) 的可复现基准测试平台。该平台集成了模拟环境、高保真数字孪生以及物理测试台。使用 SigmaRL 训练的 MARL 运动规划策略，并在该平台的三种域（模拟、数字孪生、物理测试台）上进行零样本（zero-shot）评估。

Result: 在对 SigmaRL 训练的策略进行跨域评估后，研究发现性能下降主要来自两个方面：1) 模拟器和物理硬件控制堆栈之间的架构差异；2) 随着环境真实性增加（从模拟到物理），模拟到现实（sim-to-real）的差距导致性能下降。

Conclusion: 该研究提出的基准测试平台为评估 MARL 在 CAV 场景中的模拟到现实迁移提供了一个可复现的框架。研究结果强调了模拟器与硬件架构的兼容性以及环境真实性对 MARL 策略性能迁移的重要性，并为未来研究提供了系统分析 sim-to-real 挑战的工具。

Abstract: We present a reproducible benchmark for evaluating sim-to-real transfer of Multi-Agent Reinforcement Learning (MARL) policies for Connected and Automated Vehicles (CAVs). The platform, based on the Cyber-Physical Mobility Lab (CPM Lab) [1], integrates simulation, a high-fidelity digital twin, and a physical testbed, enabling structured zero-shot evaluation of MARL motion-planning policies. We demonstrate its use by deploying a SigmaRL-trained policy [2] across all three domains, revealing two complementary sources of performance degradation: architectural differences between simulation and hardware control stacks, and the sim-to-real gap induced by increasing environmental realism. The open-source setup enables systematic analysis of sim-to-real challenges in MARL under realistic, reproducible conditions.

</details>


### [131] [A Unified Calibration Framework for High-Accuracy Articulated Robot Kinematics](https://arxiv.org/abs/2601.16638)
*Philip Tobuschat,Simon Duenser,Markus Bambach,Ivo Aschwanden*

Main category: cs.RO

TL;DR: 本文提出了一种统一的工业机器人静态标定方法，通过单一实验即可识别包含几何和非几何误差（如柔性弯曲、热变形、齿轮传动误差）的机器人模型，并使用高斯-牛顿优化算法进行参数估计。实验结果显示，该方法在KUKA KR30机器人上取得了26.8 μm的平均位置误差，显著优于仅考虑几何误差的标定方法。


<details>
  <summary>Details</summary>
Motivation: 现有工业机器人工具定位误差的补偿策略通常需要单独的、特殊的实验和模型，效率低下。研究动机在于开发一种更统一、更高效的方法，通过一次实验就能识别包含多种误差的机器人模型。

Method: 提出了一种统一的静态标定方法，通过在运动链中引入虚拟关节来表示各种误差（几何和非几何），并利用一次简单的实验收集数据。使用带有解析梯度的Gauss-Newton优化算法进行模型参数识别。通过Fisher信息谱评估估计的条件数，并通过系统的时间交叉验证和模型删减来验证模型的鲁棒性。

Result: 该方法能够准确识别包含几何和非几何效应的机器人模型。在KUKA KR30工业机器人上的实验结果显示，平均位置误差为26.8 μm，而仅考虑几何标定的误差为102.3 μm，精度提升显著。

Conclusion: 所提出的统一标定方法能够鲁棒且精确地识别工业机器人的模型，包括复杂的非几何误差，显著提高了标定精度，减少了实验需求。

Abstract: Researchers have identified various sources of tool positioning errors for articulated industrial robots and have proposed dedicated compensation strategies. However, these typically require individual, specialized experiments with separate models and identification procedures. This article presents a unified approach to the static calibration of industrial robots that identifies a robot model, including geometric and non-geometric effects (compliant bending, thermal deformation, gear transmission errors), using only a single, straightforward experiment for data collection. The model augments the kinematic chain with virtual joints for each modeled effect and realizes the identification using Gauss-Newton optimization with analytic gradients. Fisher information spectra show that the estimation is well-conditioned and the parameterization near-minimal, whereas systematic temporal cross-validation and model ablations demonstrate robustness of the model identification. The resulting model is very accurate and its identification robust, achieving a mean position error of 26.8 $μm$ on a KUKA KR30 industrial robot compared to 102.3 $μm$ for purely geometric calibration.

</details>


### [132] [ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance](https://arxiv.org/abs/2601.16667)
*Zhuohao Li,Yinghao Li,Jian-Jian Jiang,Lang Zhou,Tianyu Zhang,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: 提出了一种名为ReViP的新的视觉-语言-动作（VLA）框架，通过视觉-本体感知再平衡来提高机器人操作的准确性和鲁棒性，特别是在应对虚假完成问题上。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型将本体感知信号直接与视觉-语言特征融合，导致状态主导偏差和虚假完成，原因在于模型过度依赖内部状态而忽视了视觉证据。

Method: ReViP框架引入了任务感知的环境先验来调整感知和动力学之间的耦合。具体而言，使用外部VLM提取实时的任务中心视觉线索，并通过视觉-本体感知特征线性调制来增强环境感知并减少状态驱动的误差。

Result: ReViP在LIBERO基准套件上显著降低了虚假完成率，并提高了成功率，在LIBERO、RoboTwin 2.0和真实世界评估中也表现出改进。

Conclusion: ReViP通过引入任务感知的环境先验和创新的特征调制机制，有效地解决了VLA模型中的状态主导偏差和虚假完成问题，显著提升了机器人在复杂操作任务中的性能。

Abstract: Vision-Language-Action (VLA) models have advanced robotic manipulation by combining vision, language, and proprioception to predict actions. However, previous methods fuse proprioceptive signals directly with VLM-encoded vision-language features, resulting in state-dominant bias and false completions despite visible execution failures. We attribute this to modality imbalance, where policies over-rely on internal state while underusing visual evidence. To address this, we present ReViP, a novel VLA framework with Vision-Proprioception Rebalance to enhance visual grounding and robustness under perturbations. The key insight is to introduce auxiliary task-aware environment priors to adaptively modulate the coupling between semantic perception and proprioceptive dynamics. Specifically, we use an external VLM as a task-stage observer to extract real-time task-centric visual cues from visual observations, which drive a Vision-Proprioception Feature-wise Linear Modulation to enhance environmental awareness and reduce state-driven errors. Moreover, to evaluate false completion, we propose the first False-Completion Benchmark Suite built on LIBERO with controlled settings such as Object-Drop. Extensive experiments show that ReViP effectively reduces false-completion rates and improves success rates over strong VLA baselines on our suite, with gains extending to LIBERO, RoboTwin 2.0, and real-world evaluations.

</details>


### [133] [Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation](https://arxiv.org/abs/2601.16677)
*Lucía Güitta-López,Lionel Güitta-López,Jaime Boal,Álvaro Jesús López-López*

Main category: cs.RO

TL;DR: 本文提出了一种基于StyleID-CycleGAN的域适应方法，将虚拟环境中的观测转化为逼真的图像，从而实现深度强化学习（DRL）策略的零样本（zero-shot）跨域迁移，应用于工业机器人抓取任务，显著提高了样本效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习（DRL）在实际工业应用中面临样本效率低的问题，训练成本高昂。虚拟环境可以降低成本，但虚拟与现实之间的“sim-to-real”差距阻碍了策略的迁移。实现零样本迁移（无需额外微调）具有极高的实用价值。

Method: 提出了一种新颖的域适应方法SICGAN（Style-Identified Cycle Consistent Generative Adversarial Network），它是一种基于CycleGAN的模型。SICGAN能够将虚拟环境的原始观测转化为逼真的图像，从而在混合域中进行DRL代理的训练，结合了虚拟动力学和真实感视觉输入。训练完成后，代理可以直接部署到真实环境中。

Result: 该方法在两种不同的工业机器人抓取任务上进行了验证。在虚拟环境中，代理的成功率达到90%-100%。在真实世界部署时，实现了鲁棒的零样本迁移，在大多数工作空间区域的准确率超过95%。代理能够泛化到不同颜色和形状的真实物体，包括乐高积木和马克杯。

Conclusion: 所提出的SICGAN流水线为解决“sim-to-real”问题提供了一种高效、可扩展的解决方案，能够实现DRL策略在虚拟与真实环境之间的有效迁移，尤其适用于工业机器人应用。

Abstract: The sample efficiency challenge in Deep Reinforcement Learning (DRL) compromises its industrial adoption due to the high cost and time demands of real-world training. Virtual environments offer a cost-effective alternative for training DRL agents, but the transfer of learned policies to real setups is hindered by the sim-to-real gap. Achieving zero-shot transfer, where agents perform directly in real environments without additional tuning, is particularly desirable for its efficiency and practical value. This work proposes a novel domain adaptation approach relying on a Style-Identified Cycle Consistent Generative Adversarial Network (StyleID-CycleGAN or SICGAN), an original Cycle Consistent Generative Adversarial Network (CycleGAN) based model. SICGAN translates raw virtual observations into real-synthetic images, creating a hybrid domain for training DRL agents that combines virtual dynamics with real-like visual inputs. Following virtual training, the agent can be directly deployed, bypassing the need for real-world training. The pipeline is validated with two distinct industrial robots in the approaching phase of a pick-and-place operation. In virtual environments agents achieve success rates of 90 to 100\%, and real-world deployment confirms robust zero-shot transfer (i.e., without additional training in the physical environment) with accuracies above 95\% for most workspace regions. We use augmented reality targets to improve the evaluation process efficiency, and experimentally demonstrate that the agent successfully generalizes to real objects of varying colors and shapes, including LEGO\textsuperscript{\textregistered}~cubes and a mug. These results establish the proposed pipeline as an efficient, scalable solution to the sim-to-real problem.

</details>


### [134] [Adaptive Reinforcement and Model Predictive Control Switching for Safe Human-Robot Cooperative Navigation](https://arxiv.org/abs/2601.16686)
*Ning Liu,Sen Shen,Zheng Li,Matthew D'Souza,Jen Jen Chung,Thomas Braunl*

Main category: cs.RO

TL;DR: 提出了一种名为ARMS的混合学习-控制框架，用于在同时满足邻近调节和安全约束的情况下，实现移动协作机器人的人类引导导航，并在复杂环境中取得了显著的成功率提升和计算延迟降低。


<details>
  <summary>Details</summary>
Motivation: 解决移动协作机器人在人类引导导航时，同时满足邻近调节和安全约束的挑战，特别是在部分可观测和非平稳的人类运动情况下。

Method: 提出ARMS（Adaptive Reinforcement and Model Predictive Control Switching）混合框架，结合了使用PPO训练的强化学习（RL）跟随者和一个作为安全滤波器的QP（Quadratic Program）模型预测控制（MPC）。采用解耦感知架构，包括LSTM用于人机相对状态，空间编码器用于LiDAR扫描。核心是学习到的自适应神经网络切换器，能够根据环境风险动态融合RL和MPC的控制输出。

Result: 在高度拥挤的环境中，ARMS的成功率为82.5%，优于Pure Pursuit、DWA和纯RL基线（分别提升7.1%和3.1%）。计算延迟平均降低33%，达到5.2毫秒。模拟和真实世界部署结果也显示了其有效性和鲁棒性。

Conclusion: ARMS是一个有效且实用的混合学习-控制框架，能够安全高效地实现人类引导的机器人导航，并在复杂环境中展现出优越性能。

Abstract: This paper addresses the challenge of human-guided navigation for mobile collaborative robots under simultaneous proximity regulation and safety constraints. We introduce Adaptive Reinforcement and Model Predictive Control Switching (ARMS), a hybrid learning-control framework that integrates a reinforcement learning follower trained with Proximal Policy Optimization (PPO) and an analytical one-step Model Predictive Control (MPC) formulated as a quadratic program safety filter. To enable robust perception under partial observability and non-stationary human motion, ARMS employs a decoupled sensing architecture with a Long Short-Term Memory (LSTM) temporal encoder for the human-robot relative state and a spatial encoder for 360-degree LiDAR scans. The core contribution is a learned adaptive neural switcher that performs context-aware soft action fusion between the two controllers, favoring conservative, constraint-aware QP-based control in low-risk regions while progressively shifting control authority to the learned follower in highly cluttered or constrained scenarios where maneuverability is critical, and reverting to the follower action when the QP becomes infeasible. Extensive evaluations against Pure Pursuit, Dynamic Window Approach (DWA), and an RL-only baseline demonstrate that ARMS achieves an 82.5 percent success rate in highly cluttered environments, outperforming DWA and RL-only approaches by 7.1 percent and 3.1 percent, respectively, while reducing average computational latency by 33 percent to 5.2 milliseconds compared to a multi-step MPC baseline. Additional simulation transfer in Gazebo and initial real-world deployment results further indicate the practicality and robustness of ARMS for safe and efficient human-robot collaboration. Source code and a demonstration video are available at https://github.com/21ning/ARMS.git.

</details>


### [135] [Creating a biologically more accurate spider robot to study active vibration sensing](https://arxiv.org/abs/2601.16691)
*Siyuan Sun,Eugene H. Lin,Nathan Brown,Hsin-Yi Hung,Andrew Gordus,Jochen Mueller,Chen Li*

Main category: cs.RO

TL;DR: 研究者开发了一个更仿真的八足蜘蛛机器人，能够更深入地模仿蜘蛛的腿部蜷缩行为，以研究这种行为如何影响其在蛛网上感知振动的能力。


<details>
  <summary>Details</summary>
Motivation: 蜘蛛如何通过腿部蜷缩行为增强其在蛛网上感知振动的能力尚不清楚，主要是因为在真实动物行为中测量系统振动很困难。

Method: 使用了一个仿生学的机器人模型，该模型具有八条腿，每条腿有四个关节，并且可以通过身体内的电机进行深度的腿部蜷缩，同时在腿部关节处安装了加速度计来记录振动。

Result: 新的机器人模型在振动特征上与之前的模型相似，但生物学上的准确性得到了提高，能够更深入地模拟蜘蛛的腿部蜷缩行为。

Conclusion: 这个更生物学准确的仿生机器人模型为进一步研究蜘蛛腿部行为如何调节其在蛛网上感知振动提供了有力的工具。

Abstract: Orb-weaving spiders detect prey on a web using vibration sensors at leg joints. They often dynamically crouch their legs during prey sensing, likely an active sensing strategy. However, how leg crouching enhances sensing is poorly understood, because measuring system vibrations in behaving animals is difficult. We use robophysical modeling to study this problem. Our previous spider robot had only four legs, simplified leg morphology, and a shallow crouching range of motion. Here, we developed a new spider robot, with eight legs, each with four joints that better approximated spider leg morphology. Leg exoskeletons were 3-D printed and joint stiffness was tuned using integrated silicone molding with variable materials and geometry. Tendon-driven actuation allowed a motor in the body to crouch all eight legs deeply as spiders do, while accelerometers at leg joints record leg vibrations. Experiments showed that our new spider robot reproduced key vibration features observed in the previous robot while improving biological accuracy. Our new robot provides a biologically more accurate robophysical model for studying how leg behaviors modulate vibration sensing on a web.

</details>


### [136] [A Feature Extraction Pipeline for Enhancing Lightweight Neural Networks in sEMG-based Joint Torque Estimation](https://arxiv.org/abs/2601.16712)
*Kartik Chari,Raid Dokhan,Anas Homsi,Niklas Kueper,Elsa Andrea Kirchner*

Main category: cs.RO

TL;DR: 本研究提出了一种基于8通道表面肌电图（sEMG）信号的特征提取流程，用于预测机器人辅助康复中的肘部和肩部关节力矩，并通过多层感知机（MLP）和时间卷积网络（TCN）进行了评估，结果表明MLP在预测精度上与TCN相当，尤其适用于训练数据有限的应用场景。


<details>
  <summary>Details</summary>
Motivation: 为了实现机器人辅助康复中自适应和个性化的用户辅助，准确预测用户关节力矩至关重要。

Method: 提出了一种使用8通道sEMG信号的特征提取流程，并将其集成到MLP和TCN两种神经网络模型中进行评估。实验在一个受试者身上进行，采集了肘部和肩部在不同负载下的sEMG和运动捕捉数据，并基于质心运动学估算参考力矩。

Result: 所提出的特征提取流程使得MLP模型在肘部、前肩部和侧肩部关节的力矩预测中取得了与TCN相当的均方根误差（RMSE），分别为0.963 Nm、1.403 Nm和1.434 Nm（平均五次运行）。

Conclusion: 所提出的sEMG特征提取流程能够使简单的MLP模型达到与专门处理时序依赖关系的网络（如TCN）相当的性能，这对于患者护理等训练数据有限的应用场景具有重要意义。

Abstract: Robot-assisted rehabilitation offers an effective approach, wherein exoskeletons adapt to users' needs and provide personalized assistance. However, to deliver such assistance, accurate prediction of the user's joint torques is essential. In this work, we propose a feature extraction pipeline using 8-channel surface electromyography (sEMG) signals to predict elbow and shoulder joint torques. For preliminary evaluation, this pipeline was integrated into two neural network models: the Multilayer Perceptron (MLP) and the Temporal Convolutional Network (TCN). Data were collected from a single subject performing elbow and shoulder movements under three load conditions (0 kg, 1.10 kg, and 1.85 kg) using three motion-capture cameras. Reference torques were estimated from center-of-mass kinematics under the assumption of static equilibrium. Our offline analyses showed that, with our feature extraction pipeline, MLP model achieved mean RMSE of 0.963 N m, 1.403 N m, and 1.434 N m (over five seeds) for elbow, front-shoulder, and side-shoulder joints, respectively, which were comparable to the TCN performance. These results demonstrate that the proposed feature extraction pipeline enables a simple MLP to achieve performance comparable to that of a network designed explicitly for temporal dependencies. This finding is particularly relevant for applications with limited training data, a common scenario patient care.

</details>


### [137] [Boosting Deep Reinforcement Learning with Semantic Knowledge for Robotic Manipulators](https://arxiv.org/abs/2601.16866)
*Lucía Güitta-López,Vincenzo Suriani,Jaime Boal,Álvaro J. López-López,Daniele Nardi*

Main category: cs.RO

TL;DR: 通过将知识图谱嵌入（KGE）与深度强化学习（DRL）相结合，该研究提出了一种能够显著提高机器人控制学习效率和任务准确性的新方法。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习（DRL）在机器人控制领域潜力巨大，但学习过程中需要大量经验，导致计算和时间成本高昂，阻碍了其实际应用。

Method: 提出一种将DRL与知识图谱嵌入（KGE）相结合的新架构。该架构将KGE与视觉观测结合，为智能体提供环境的上下文知识，从而在训练中利用这些知识。

Result: 在机器人操作任务中，该方法实现了高达60%的学习时间缩减，并将任务准确性提高了约15个百分点，同时没有增加训练时间和计算复杂度。

Conclusion: 语义知识（如KGE）有潜力降低DRL的样本复杂度，并提高其在机器人应用中的有效性。

Abstract: Deep Reinforcement Learning (DRL) is a powerful framework for solving complex sequential decision-making problems, particularly in robotic control. However, its practical deployment is often hindered by the substantial amount of experience required for learning, which results in high computational and time costs. In this work, we propose a novel integration of DRL with semantic knowledge in the form of Knowledge Graph Embeddings (KGEs), aiming to enhance learning efficiency by providing contextual information to the agent. Our architecture combines KGEs with visual observations, enabling the agent to exploit environmental knowledge during training. Experimental validation with robotic manipulators in environments featuring both fixed and randomized target attributes demonstrates that our method achieves up to {60}{\%} reduction in learning time and improves task accuracy by approximately 15 percentage points, without increasing training time or computational complexity. These results highlight the potential of semantic knowledge to reduce sample complexity and improve the effectiveness of DRL in robotic applications.

</details>


### [138] [A Multimodal Data Collection Framework for Dialogue-Driven Assistive Robotics to Clarify Ambiguities: A Wizard-of-Oz Pilot Study](https://arxiv.org/abs/2601.16870)
*Guangping Liu,Nicholas Hawkins,Billy Madden,Tipu Sultan,Flavio Esposito,Madi Babaiasl*

Main category: cs.RO

TL;DR: 本研究提出了一种多模态数据收集框架，用于收集轮椅安装机器人手臂（WMRAs）的对话驱动控制数据，旨在解决现有接口缺乏灵活性和缺乏捕捉自然人机交互（HRI）数据的多模态数据集的问题。该框架使用“绿野仙踪”实验设置，记录了五种同步模态的数据，并成功收集了一个试点数据集，证明了其捕捉交互歧义和支持自然对话驱动控制的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有轮椅和轮椅安装机器人手臂（WMRAs）的集成控制接口缺乏灵活性，难以实现直观的辅助交互。尤其是在对话驱动控制方面，缺乏能够捕捉自然人机交互（HRI）且包含对话歧义的多模态数据集，这限制了数据驱动的AI方法的发展。

Method: 研究提出了一种多模态数据收集框架，采用了基于对话的交互协议和“绿野仙踪”（Wizard-of-Oz, WoZ）实验设置（两房间）。该框架同步记录了五种模态的数据：RGB-D视频、对话音频、惯性测量单元（IMU）信号、末端执行器笛卡尔位姿和全身关节状态。通过五项辅助任务收集了53个试验的试点数据集，并通过运动平滑度分析和用户反馈验证了数据的质量。

Result: 该框架能够有效地捕捉多种类型的交互歧义，并支持自然的对话驱动交互。试点数据集的分析表明，该框架适合用于未来更大规模的数据集收集，以支持学习、基准测试和评估歧义感知辅助控制。

Conclusion: 提出的多模态数据收集框架能够有效捕捉自然对话驱动的轮椅机器人交互数据，特别是包含歧义的场景，为开发更智能、更灵活的辅助控制系统奠定了基础。

Abstract: Integrated control of wheelchairs and wheelchair-mounted robotic arms (WMRAs) has strong potential to increase independence for users with severe motor limitations, yet existing interfaces often lack the flexibility needed for intuitive assistive interaction. Although data-driven AI methods show promise, progress is limited by the lack of multimodal datasets that capture natural Human-Robot Interaction (HRI), particularly conversational ambiguity in dialogue-driven control. To address this gap, we propose a multimodal data collection framework that employs a dialogue-based interaction protocol and a two-room Wizard-of-Oz (WoZ) setup to simulate robot autonomy while eliciting natural user behavior. The framework records five synchronized modalities: RGB-D video, conversational audio, inertial measurement unit (IMU) signals, end-effector Cartesian pose, and whole-body joint states across five assistive tasks. Using this framework, we collected a pilot dataset of 53 trials from five participants and validated its quality through motion smoothness analysis and user feedback. The results show that the framework effectively captures diverse ambiguity types and supports natural dialogue-driven interaction, demonstrating its suitability for scaling to a larger dataset for learning, benchmarking, and evaluation of ambiguity-aware assistive control.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [139] [BESTOpt: A Modular, Physics-Informed Machine Learning based Building Modeling, Control and Optimization Framework](https://arxiv.org/abs/2601.16283)
*Zixin Jiang,Ruizhi Song,Guowen Li,Yuhang Zhang,Zheng O'Neill,Xuezheng Wang,Judah Goldfeder,Bing Dong*

Main category: eess.SY

TL;DR: 本文提出了BESTOpt框架，一个结合了物理知识和机器学习的模块化框架，用于统一处理现代建筑中多领域（如占用、HVAC、DERs、电网）的建模、控制和优化问题，以实现建筑行业的脱碳化。


<details>
  <summary>Details</summary>
Motivation: 现有工具在处理复杂、多尺度的建筑多领域系统问题时，普遍存在可扩展性和物理一致性不足的缺点，难以满足建筑行业脱碳化的需求。

Method: 采用了一种集成了物理先验知识的机器学习（PIML）方法，构建了一个模块化框架BESTOpt。该框架采用了集群-域-系统/建筑构件的层级结构，并定义了标准化的状态-动作-扰动-观测数据类型。

Result: BESTOpt框架能够改进模型在未见过条件下的准确性和物理一致性。通过单建筑和集群场景的案例研究，验证了其在多层次集中式和分散式控制方面的能力。

Conclusion: BESTOpt框架为构建一个开放、可扩展的平台奠定了基础，有望加速跨学科研究，促进智能、有韧性、低碳化的建筑生态系统的发展。

Abstract: Modern buildings are increasingly interconnected with occupancy, heating, ventilation, and air-conditioning (HVAC) systems, distributed energy resources (DERs), and power grids. Modeling, control, and optimization of such multi-domain systems play a critical role in achieving building-sector decarbonization. However, most existing tools lack scalability and physical consistency for addressing these complex, multi-scale ecosystem problems. To bridge this gap, this study presents BESTOpt, a modular, physics-informed machine learning (PIML) framework that unifies building applications, including benchmarking, evaluation, diagnostics, control, optimization, and performance simulation. The framework adopts a cluster-domain-system/building-component hierarchy and a standardized state-action-disturbance-observation data typology. By embedding physics priors into data-driven modules, BESTOpt improves model accuracy and physical consistency under unseen conditions. Case studies on single-building and cluster scenarios demonstrate its capability for multi-level centralized and decentralized control. Looking ahead, BESTOpt lays the foundation for an open, extensible platform that accelerates interdisciplinary research toward smart, resilient, and decarbonized building ecosystems.

</details>


### [140] [Optimal County-Level Siting of Data Centers in the United States](https://arxiv.org/abs/2601.16315)
*Maria Vabson,Muhy Eddin Zater,Amir Sajadi,Kyri Baker,Bri-Mathias Hodge*

Main category: eess.SY

TL;DR: 该研究提出了一种综合建模方法，用于确定数据中心的最佳选址，以量化资源使用并最小化成本，重点关注与碳中和发电场的选址结合。


<details>
  <summary>Details</summary>
Motivation: 数据中心规模的快速增长带来了对关键基础设施建设的迫切需求，而数据中心消耗大量的电力和淡水，这给本已紧张和老化的电网和水资源带来了压力。

Method: 该研究采用了一种跨学科的建模方法，该方法整合了电网、电信、气候、用水和就近发电潜力等多种因素，以确定数据中心的最佳位置。通过几个关注美国县级碳中和发电场选址的测试案例来展示模型的功能。

Result: 研究结果表明，虽然资本成本是主要驱动因素，但更长远的未来展望和对更多可变发电的容纳能力会促使模型选择可再生能源潜力更高的地点。

Conclusion: 该研究建立了一个基础模型，该模型能够通过考虑多种因素来优化数据中心的选址，并为未来的研究奠定了基础，尤其是在将数据中心选址与可再生能源部署相结合方面。

Abstract: Data centers are growing rapidly, creating the pressing need for the development of critical infrastructure build out to support these resource-intensive large loads. Their immense consumption of electricity and, often, freshwater, continues to stress an already constrained and aging power grid and water resources. This paper presents a comprehensive modeling approach to determine the optimal locations to construct such facilities by quantifying their resource use and minimizing associated costs. The interdisciplinary modeling approach incorporates a number of factors including the power grid, telecommunications, climate, water use, and collocated generation potential. This work establishes the base model whose functionality is shown through several test cases focusing on carbon-free generation collocation on a county-level in the United States. The results suggest that while capital costs are the biggest driver, having a longer future outlook and allowing more variable generation collocation influences the model to choose sites with higher renewable potential.

</details>


### [141] [Robust Grid-Forming Control Based on Virtual Flux Observer](https://arxiv.org/abs/2601.16418)
*Xueqing Gao,Jun Zhang,Tao Li,Mingming Zhang*

Main category: eess.SY

TL;DR: 提出了一种新的基于虚拟 fluxo 观测器的并网逆变器 (GFM) 控制方法，通过直接控制端电压实现电压源行为，并进行了稳定性分析和实验验证。


<details>
  <summary>Details</summary>
Motivation: 为了提高并网逆变器在不同和不确定的电网强度下的稳定性和动态性能，需要一种新型的 grid-forming (GFM) 控制方法。

Method: 提出了一种基于虚拟 fluxo 观测器的同步和负载角控制方法，直接调节逆变器的端电压。控制参数经过设计以实现解耦和极点配置。通过小信号分析和 20 kVA 功率转换系统的实验进行了验证。

Result: 所提出的 GFM 控制方法在不同和不确定的电网强度下表现出强大的稳定性和动态性能。小信号分析和小规模实验均证明了其鲁棒性。

Conclusion: 所提出的虚拟 fluxo 观测器方法是一种有效的 GFM 控制策略，能够为并网逆变器提供优越的稳定性和动态性能，尤其是在电网强度变化的情况下。

Abstract: This paper investigates the design and analysis of a novel grid-forming (GFM) control method for grid-connected converters (GCCs). The core novelty lies in a virtual flux observer-based synchronization and load angle control method. The terminal voltage of the converter is directly regulated to provide voltage-source behavior. The control parameters are designed for decoupling and pole placement. The proposed method exhibits strong robustness in stability and dynamical performance across varying and uncertain grid strengths. The robust control performance of the proposed method is first demonstrated by small-signal analysis, then validated by experiments on a 20 kVA power conversion system.

</details>


### [142] [Sequential Operating Simulation of Solid State Transformer-Driven Next-Generation 800 VDC Data Center](https://arxiv.org/abs/2601.16502)
*Jian Xu,Xinxiong Jiang,Yi Bao,Yuchen Zheng,Xuhui Chen,Qiang Xu,Siyang Liao,Deping Ke,Xiaoqi Gao*

Main category: eess.SY

TL;DR: 本研究提出了一种基于固态变压器（SST）的800VDC配电架构，用于解决AI工作负载带来的数据中心电力需求增长和负载瞬态问题，并通过RTDS仿真验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: AI工作负载导致数据中心用电量和机架功率密度快速增长，对高效、鲁棒的供电系统提出更高要求。传统的UPS交流配电系统效率低且不适用于AI动态功率特性。

Method: 开发了一种三相H桥AC/DC级联双有源桥（DAB）DC/DC级的SST拓扑。设计了结合整流器电压/电流调节和DAB移相控制的协同闭环控制方案，并在RTDS平台进行了长周期仿真验证，对比了UPS系统。

Result: 仿真结果表明，所提出的800VDC系统能实现紧密的800VDC母线电压调节，与UPS相比，输入侧能耗更低，并具有令人满意的电能质量。还进行了电容灵敏度测试，确定了适合设计的电容范围。

Conclusion: 本研究提供了一个可复现的评估流程和切实可行的设计指南，证明了SST驱动的800VDC配电架构是下一代AI数据中心的有效解决方案。

Abstract: Artificial-intelligence (AI) workloads are driving rapid growth in data-center electricity use and rack power density, increasing demand for power-delivery systems that are efficient and robust to fast load transients. Conventional uninterruptible power supply (UPS) based AC distribution chains involve multiple conversion stages and line-frequency transformers, which compound losses and are less compatible with dynamic AI power profiles. Although solid-state transformers (SSTs) and 800 VDC distribution architecture are widely discussed, implementable topology/control details, and long-horizon validation with realistic operating profiles remain limited. This paper develops an SST-driven 800 VDC architecture that converts 10 kV MVAC to an 800V LVDC bus using a three-phase H-bridge AC/DC stage cascaded with a dual-active-bridge (DAB) DC/DC stage. A coordinated closed-loop control scheme, combining rectifier voltage/current regulation and DAB phase-shift control, is designed to maintain DC-bus voltage stability. The proposed system is implemented on the real-time digital simulation (RTDS) platform and evaluated via sequential simulations using real-world day- and month-scale operating profiles of data centers, benchmarked against a UPS supply chain. Numerical studies demonstrate tight 800 VDC regulation, reduced input-side energy consumption compared with the UPS baseline, and satisfactory power-quality performance. A capacitance sensitivity test quantifies tradeoffs between DC-bus ripple and low-frequency input-power oscillations, yielding a practical capacitance range for design. Overall, the work provides a reproducible evaluation workflow and actionable guidance for next-generation AI data centers.

</details>


### [143] [Agentic AI-RAN Empowering Synergetic Sensing, Communication, Computing, and Control](https://arxiv.org/abs/2601.16565)
*Lingxiao Sun,Zhaoyang Zhang,Zihan Lin,Zirui Chen,Weijie Zhou,Zhaohui Yang,Tony Q. S. Quek*

Main category: eess.SY

TL;DR: 本文提出了一种面向任务的Agentic AI-RAN架构，用于在资源受限的边缘节点上实现无人机（UAV）的感知、通信、计算和控制（SC3）的自主执行，并通过GPU原型验证了其在低延迟、高可靠性方面的能力，适用于6G低空无线网络。


<details>
  <summary>Details</summary>
Motivation: 未来的6G网络需要支持低空无线网络（LAWNs），其中无人机在动态3D环境中运行，对延迟、可靠性和自主性有严格要求。边缘计算需要对SC3过程进行整体协调，而机载资源有限的无人机难以实现自主任务执行。

Method: 提出并设计了一种面向任务的Agentic AI-RAN架构，将SC3任务集成在单个边缘节点中。利用多实例GPU（MIG）分区技术和容器化部署，实现了物理资源隔离，支持实时通信和多模态推理的紧密耦合协调，并在GPU平台上构建了无人机自主导航的原型系统。

Result: 原型系统在动态运行时条件下，实现了低闭环延迟、稳健的双向通信和稳定的性能，证明了其在任务关键型低空无线网络中的可行性。

Conclusion: 所提出的Agentic AI-RAN架构能够有效地协调异构工作负载，并在资源受限的边缘环境中实现无人机的自主SC3任务执行，为6G低空无线网络的低延迟、高可靠性需求提供了解决方案。

Abstract: Future sixth-generation (6G) networks are expected to support low-altitude wireless networks (LAWNs), where unmanned aerial vehicles (UAVs) and aerial robots operate in highly dynamic three-dimensional environments under stringent latency, reliability, and autonomy requirements. In such scenarios, autonomous task execution at the network edge demands holistic coordination among sensing, communication, computing, and control (SC3) processes. Agentic Artificially Intelligent Radio Access Networks (Agentic AI-RAN) offer a promising paradigm by enabling the edge network to function as an autonomous decision-making entity for low-altitude agents with limited onboard resources. In this article, we propose and design a task-oriented Agentic AI-RAN architecture that enables SC3 task execution within a single edge node. This integrated design tackles the fundamental problem of coordinating heterogeneous workloads in resource-constrained edge environments. Furthermore, a representative low-altitude embodied intelligence system is prototyped based on a general-purpose Graphics Processing Unit (GPU) platform to demonstrate autonomous drone navigation in realistic settings. By leveraging the Multi-Instance GPU (MIG) partitioning technique and the containerized deployment, the demonstration system achieves physical resource isolation while supporting tightly coupled coordination between real-time communication and multimodal inference under a unified task framework. Experimental results demonstrate low closed-loop latency, robust bidirectional communication, and stable performance under dynamic runtime conditions, highlighting its viability for mission-critical low-altitude wireless networks in 6G.

</details>


### [144] [Challenges in the Proper Metrological Verification of Smart Energy Meters](https://arxiv.org/abs/2601.16612)
*Antonio Bracale,Jakub Janowicz,Piotr Kuwałek,Grzegorz Wiczyński*

Main category: eess.SY

TL;DR: 现有智能电表的计量验证方法未能充分反映电网实际运行状态，可能导致信号链和测量链的潜在缺陷被忽视。


<details>
  <summary>Details</summary>
Motivation: 当前智能电表的计量验证是在理想条件下或使用简单信号模型进行的，未能模拟电网的实际运行状态，也未能保证其信号链的性能得到充分验证。

Method: 审查了智能电表的现有法律和规范要求，并探讨了相关的科学研究方向。通过使用选定的测试信号对智能电表进行测试，并分析了测试结果。

Result: 尽管测试的智能电表满足现行的规范和法律要求，并且已获准销售，但针对选定的测试信号，分析表明其信号链和测量链存在许多不足之处。

Conclusion: 需要改进智能电表的计量验证方法，以更准确地反映电网的实际运行情况，并提出进一步的研究方向以解决现有计量验证方法中的不足。

Abstract: The most common instruments currently measuring active/reactive energy and power quality indicators are smart energy meters. Unfortunately, the verification of such meters is currently performed under ideal conditions or with simple signal models, which do not recreate actual states occurring in the power grid and do not ensure the verification of the properties of their signal chains. This paper presents challenges in the proper metrological verification of smart energy meters. It presents existing legal and normative requirements and scientific research directions regarding these meters. Selected test results are presented, which show that although the tested meters meet the normative and legal requirements because they have been approved for sale, numerous imperfections in the signal and measurement chains of the analyzed instruments are revealed for the selected test signal. On the basis of the presented research results, further directions of research in the field of smart energy meters have been determined.

</details>


### [145] [Computation-Accuracy Trade-Off in Service-Oriented Model-Based Control](https://arxiv.org/abs/2601.16682)
*Hazem Ibrahim,Julius Beerwerth,Lorenz Dörschel,Bassam Alrifaee*

Main category: eess.SY

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Representing a control system as a Service-Oriented Architecture (SOA)-referred to as Service-Oriented Model-Based Control (SOMC)-enables runtime-flexible composition of control loop elements. This paper presents a framework that optimizes the computation-accuracy trade-off by formulating service orchestration as an A$^\star$search problem, complemented by Contextual Bayesian Optimization (BO) to tune the multi-objective cost weights. A vehicle longitudinal-velocity control case study demonstrates online, performancedriven reconfiguration of the control architecture. We show that our framework not only combines control and software structure but also considers the real-time requirements of the control system during performance optimization.

</details>


### [146] [A Cognitive Framework for Autonomous Agents: Toward Human-Inspired Design](https://arxiv.org/abs/2601.16648)
*Francesco Guidi,Jingfeng Shan,Mehrdad Saeidi,Enrico Testi,Elia Favarelli,Andrea Giorgetti,Davide Dardari,Alberto Zanella,Giorgio Li Pira,Francesca Starita,Anna Guerra*

Main category: eess.SY

TL;DR: 本文提出了一种受人类启发的强化学习（RL）架构，该架构结合了巴甫洛夫条件反射和工具性条件反射过程，以提高自主系统的决策能力。通过将RF刺激作为条件（巴甫洛夫）线索来调节动作选择，与传统的纯工具性学习方法相比，这种新颖的架构在未知、部分可观测的环境中展现出更快的适应速度和更优越的导航效率和协作行为。


<details>
  <summary>Details</summary>
Motivation: 现有工程解决方案主要依赖工具性学习，而神经科学研究表明人类利用巴甫洛夫条件反射来利用预测性线索在结果发生前影响行为。作者希望将这种人类的双系统机制应用于自主系统，以改进其决策能力。

Method: 提出了一种受人类启发的RL架构，该架构集成了巴甫洛夫和工具性学习过程。RF刺激被用作条件（巴甫洛夫）线索，以调节动作选择。该架构结合了巴甫洛夫值和工具性策略优化。

Result: 在未知、部分可观测的环境中，该架构能提高导航效率和协作行为。仿真结果表明，受线索驱动的智能体比传统的纯工具性智能体适应更快，性能更优越。

Conclusion: 该研究强调了人类学习原理在重塑数字智能体方面的潜力，并展示了整合巴甫洛夫和工具性学习过程可以显著提升自主系统的性能。

Abstract: This work introduces a human-inspired reinforcement learning (RL) architecture that integrates Pavlovian and instrumental processes to enhance decision-making in autonomous systems. While existing engineering solutions rely almost exclusively on instrumental learning, neuroscience shows that humans use Pavlovian associations to leverage predictive cues to bias behavior before outcomes occur. We translate this dual-system mechanism into a cue-guided RL framework in which radio-frequency (RF) stimuli act as conditioned (Pavlovian) cues that modulate action selection. The proposed architecture combines Pavlovian values with instrumental policy optimization, improving navigation efficiency and cooperative behavior in unknown, partially observable environments. Simulation results demonstrate that cue-driven agents adapt faster, achieving superior performance compared to traditional instrumental-solo agents. This work highlights the potential of human learning principles to reshape digital agents intelligence.

</details>


### [147] [Model Predictive Control for Coupled Adoption-Opinion Dynamics](https://arxiv.org/abs/2601.16722)
*Martina Alutto,Qiulin Xu,Fabrizio Dabbene,Hideaki Ishii,Chiara Ravazzi*

Main category: eess.SY

TL;DR: 本研究提出了一种基于模型预测控制 (MPC) 的最优控制方法，通过影响个体意见来促进可持续行为的扩散，并在多层网络上进行了研究。


<details>
  <summary>Details</summary>
Motivation: 为了研究可持续行为在多层网络上的扩散，并开发一种更有效、可扩展的干预策略，而不是直接强制采用。

Method: 研究人员首先对采用-意见模型进行了稳定性分析，然后引入了模型预测控制 (MPC) 框架，通过塑造个体意见来优化干预措施，并利用数值模拟进行验证。

Result: 与无控制的情况相比，MPC驱动的干预能够持续并增强跨社区的采用率，表明该方法能有效促进可持续行为的扩散。

Conclusion: 通过间接影响个体意见的MPC控制策略，可以有效地促进可持续行为在多层网络上的扩散，这为政策制定者提供了一种更具可扩展性和有效性的干预方法。

Abstract: This paper investigates an optimal control problem for an adoption-opinion model that couples opinion dynamics with a compartmental adoption framework on a multilayer network to study the diffusion of sustainable behaviors. Adoption evolves through social contagion and perceived benefits, while opinions are shaped by social interactions and feedback from adoption levels. Individuals may also stop adopting virtuous behavior due to external constraints or shifting perceptions, affecting overall diffusion. After the stability analysis of equilibria, both in the presence and absence of adopters, we introduce a Model Predictive Control (MPC) framework that optimizes interventions by shaping opinions rather than directly enforcing adoption. This nudge-based control strategy allows policymakers to influence diffusion indirectly, making interventions more effective and scalable. Numerical simulations demonstrate that, in the absence of control, adoption stagnates, whereas MPC-driven interventions sustain and enhance adoption across communities.

</details>


### [148] [On a Coupled Adoption-Opinion Framework for Competing Innovations](https://arxiv.org/abs/2601.16719)
*Martina Alutto,Fabrizio Dabbene,Angela Fontan,Karl H. Johansson,Chiara Ravazzi*

Main category: eess.SY

TL;DR: 本文提出了一个两层模型，研究两种竞争技术在受社会影响和采用反馈驱动的人群中的扩散。模型表明，两种技术将共存，并且不会出现部分采用或垄断的情况。相对市场份额仅取决于用户体验，对称的干预措施可能导致不对称的结果。


<details>
  <summary>Details</summary>
Motivation: 研究两种竞争技术在人群中的扩散过程，特别是在考虑个体意见演变和用户满意度反馈的情况下，以及探索对称干预措施可能产生不对称结果的原因。

Method: 提出一个两层采用-意见模型，研究技术的扩散。证明了采用-扩散平衡的存在性和唯一性。使用数值模拟来分析意见、用户体验和干预措施对市场份额的影响。

Result: 证明了两种技术将共存，并且不会出现部分采用或垄断。相对市场份额完全取决于用户体验，而非意见。对称的干预措施（如提高意见或采用率）可能不成比例地有利于质量更高的技术。

Conclusion: 在这个模型中，两种竞争技术的共存是稳定均衡。用户体验是决定两种技术相对市场份额的关键因素，而非用户意见。对称性的干预措施在实际应用中可能导致不对称的市场结果，这表明在制定干预策略时需要谨慎考虑。

Abstract: In this paper, we propose a two-layer adoption-opinion model to study the diffusion of two competing technologies within a population whose opinions evolve under social influence and adoption-driven feedback. After adopting one technology, individuals may become dissatisfied and switch to the alternative. We prove the existence and uniqueness of the adoption-diffused equilibrium, showing that both technologies coexist and that neither partial-adoption nor monopoly can arise. Numerical simulations show that while opinions shape the equilibrium adoption levels, the relative market share between the two technologies depends solely on their user-experience. As a consequence, interventions that symmetrically boost opinions or adoption can disproportionately favor the higher-quality technology, illustrating how symmetric control actions may generate asymmetric outcomes.

</details>


### [149] [ReLU Networks for Model Predictive Control: Network Complexity and Performance Guarantees](https://arxiv.org/abs/2601.16764)
*Xingchen Li,Keyou You*

Main category: eess.SY

TL;DR: 本文提出了一种基于投影的方法来约束ReLU神经网络在模型预测控制（MPC）中的应用，并推导出网络宽度和深度的显式界限，以保证闭环性能。同时，提出了一种非均匀误差框架来进一步降低网络复杂性并提升性能。


<details>
  <summary>Details</summary>
Motivation: 在MPC策略中使用ReLU神经网络日益普及，但确定保证闭环性能所需的网络复杂性是一个未解决的问题，存在精度与复杂度的权衡。过小的网络可能无法捕捉MPC策略，过大的网络可能抵消ReLU网络近似的优势。

Method: 提出一种基于投影的方法来强制执行硬约束，并为MPC最优成本函数建立状态依赖的Lipschitz连续性。推导了ReLU网络宽度和深度的显式界限。提出了一种非均匀误差框架，包含状态感知缩放函数，以自适应地调整ReLU网络的输入和输出。

Result: 首次推导出了保证闭环性能的ReLU网络逼近MPC策略的宽度和深度显式界限。提出的非均匀误差框架能进一步降低网络复杂性并提升闭环性能。

Conclusion: 该研究为ReLU神经网络在MPC中的应用提供了理论基础和实践指导，是实现可验证的基于ReLU神经网络的MPC的重要一步。

Abstract: Recent years have witnessed a resurgence in using ReLU neural networks (NNs) to represent model predictive control (MPC) policies. However, determining the required network complexity to ensure closed-loop performance remains a fundamental open problem. This involves a critical precision-complexity trade-off: undersized networks may fail to capture the MPC policy, while oversized ones may outweigh the benefits of ReLU network approximation. In this work, we propose a projection-based method to enforce hard constraints and establish a state-dependent Lipschitz continuity property for the optimal MPC cost function, which enables sharp convergence analysis of the closed-loop system. For the first time, we derive explicit bounds on ReLU network width and depth for approximating MPC policies with guaranteed closed-loop performance. To further reduce network complexity and enhance closed-loop performance, we propose a non-uniform error framework with a state-aware scaling function to adaptively adjust both the input and output of the ReLU network. Our contributions provide a foundational step toward certifiable ReLU NN-based MPC.

</details>


### [150] [Identification of Port-Hamiltonian Differential-Algebraic Equations from Input-Output Data](https://arxiv.org/abs/2601.16827)
*N. Hagelaars,G. J. E. van Otterdijk,S. Moradi,R. Tóth,N. O. Jaensson,M. Schoukens*

Main category: eess.SY

TL;DR: 提出了一种结合pHNN和DAE求解器的数据驱动建模方法，用于识别具有代数约束的受控系统，并已在DC电力网络上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 物理系统（如机械和电气网络）的许多模型都包含由子系统互连和物理定律产生的代数约束，通常表示为微分代数方程（DAE）。pH-DAE提供了一种结构化的、基于能量的表示，可以保留互连和无源性。然而，直接从数据中识别这些pH-DAE模型仍然是一个挑战。

Method: 该方法结合了端口哈密顿神经网络（pHNN）和微分代数方程（DAE）求解器。pHNN用于构建系统的模型，而DAE求解器（采用后向欧拉离散化和牛顿法）用于处理耦合的微分和代数方程。这种方法旨在直接从有噪声的输入-输出数据中学习模型，同时保持端口哈密顿系统的无源性和互连结构。

Result: 所提出的方法成功地在DC电力网络上进行了演示。识别出的模型能够准确地捕捉系统行为，并且在有噪声数据的情况下，模型误差与噪声幅度成正比。此外，该方法提供了可靠的参数估计。

Conclusion: 该数据驱动的识别方法能够有效地从数据中学习具有代数约束的受控系统的模型，同时保留重要的物理属性（如无源性和互连结构）。该方法在DC电力网络上的成功应用证明了其有效性。

Abstract: Many models of physical systems, such as mechanical and electrical networks, exhibit algebraic constraints that arise from subsystem interconnections and underlying physical laws. Such systems are commonly formulated as differential-algebraic equations (DAEs), which describe both the dynamic evolution of system states and the algebraic relations that must hold among them. Within this class, port-Hamiltonian differential-algebraic equations (pH-DAEs) offer a structured, energy-based representation that preserves interconnection and passivity properties. This work introduces a data-driven identification method that combines port-Hamiltonian neural networks (pHNNs) with a differential-algebraic solver to model such constrained systems directly from noisy input-output data. The approach preserves the passivity and interconnection structure of port-Hamiltonian systems while employing a backward Euler discretization with Newton's method to solve the coupled differential and algebraic equations consistently. The performance of the proposed approach is demonstrated on a DC power network, where the identified model accurately captures system behaviour and maintains errors proportional to the noise amplitude, while providing reliable parameter estimates.

</details>


### [151] [Performance of Differential Protection Applied to Collector Cables of Offshore Wind Farms with MMC-HVDC Transmission](https://arxiv.org/abs/2601.16876)
*Moisés J. B. B. Davi,Felipe V. Lopes,Vinícius A. Lacerda,Mário Oleskovicz,Oriol Gomis-Bellmunt*

Main category: eess.SY

TL;DR: 研究了MMC-HVDC输电背景下，海上风力发电场集电线路差动保护的局限性，并提出了一种基于序分量的新保护策略。


<details>
  <summary>Details</summary>
Motivation: 随着向低碳能源的转型，海上风电与MMC-HVDC的集成带来了电网保护的新挑战，特别是集电线路两端均为逆变器供电时，故障电流特性发生变化。

Method: 利用PSCAD/EMTDC软件对典型海上风力发电场进行电磁暂态仿真，评估了传统差动保护和考虑序分量的增强策略在不同故障类型和阻抗下的性能。

Result: 传统差动保护在特定条件下存在局限性，而考虑序分量的策略在灵敏度和选择性方面表现更优。

Conclusion: 该研究深入理解了未来以换流器为主导的电网中，海上风电集电线路差动保护的挑战，并为改进保护方案提供了方向。

Abstract: The ongoing global transition towards low-carbon energy has propelled the integration of offshore wind farms, which, when combined with Modular Multilevel Converter-based High-Voltage Direct Current (MMC-HVDC) transmission, present unique challenges for power system protection. In collector cables connecting wind turbines to offshore MMC, both ends are supplied by Inverter-Based Resources (IBRs), which modify the magnitude and characteristics of fault currents. In this context, this paper investigates the limitations of conventional differential protection schemes under such conditions and compares them with enhanced strategies that account for sequence components. Using electromagnetic transient simulations of a representative offshore wind farm modeled in PSCAD/EMTDC software, internal and external fault scenarios are assessed, varying fault types and resistances. The comparative evaluation provides insights into the sensitivity and selectivity of differential protection and guides a deeper conceptual understanding of the evolving protection challenges inherent to future converter-dominated grids.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [152] [Experience with Single Domain Generalization in Real World Medical Imaging Deployments](https://arxiv.org/abs/2601.16359)
*Ayan Banerjee,Komandoor Srivathsan,Sandeep K. S. Gupta*

Main category: eess.IV

TL;DR: 该论文提出了一种名为DL+EKE的集成专家知识的深度学习技术，旨在解决医学影像领域中的单领域泛化（SDG）问题，并证明了其在视网膜病变、心电图和fMRI数据上的有效性，优于现有的SDG方法。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的单领域泛化（SDG）技术在医学影像领域，尤其是在多中心研究中，由于扫描仪和成像协议的差异导致的域偏移，在识别罕见类别特征方面表现不佳，阻碍了AI在实际部署中的应用。作者希望开发一种能够有效处理这些域偏移并实现良好泛化性能的新技术。

Method: 作者首先验证了现有SOTA SDG技术在视网膜病变（DR）数据集上的局限性。随后，他们提出并实现了一种通用的集成专家知识的深度学习技术（DL+EKE），并将其应用于DR数据集，证明其性能优于SOTA SDG方法。最后，作者将DL+EKE技术应用到实际的压力心电图（stress ECG）和静息态功能磁共振成像（rs-fMRI）数据上，并讨论了SDG技术面临的实际问题。

Result: 在DR数据集上，DL+EKE技术显著优于现有的SOTA SDG方法。在压力ECG和rs-fMRI的两个真实世界案例中，DL+EKE也成功部署并展现了其处理域偏移的能力。

Conclusion: 单领域泛化（SDG）在实际医学影像部署中面临挑战，现有SOTA SDG技术效果有限。集成专家知识的深度学习技术DL+EKE是一种有效的方法，能够克服域偏移问题，并在视网膜病变、压力ECG和rs-fMRI等应用中实现优于SOTA SDG方法的泛化性能。

Abstract: A desirable property of any deployed artificial intelligence is generalization across domains, i.e. data generation distribution under a specific acquisition condition. In medical imagining applications the most coveted property for effective deployment is Single Domain Generalization (SDG), which addresses the challenge of training a model on a single domain to ensure it generalizes well to unseen target domains. In multi-center studies, differences in scanners and imaging protocols introduce domain shifts that exacerbate variability in rare class characteristics. This paper presents our experience on SDG in real life deployment for two exemplary medical imaging case studies on seizure onset zone detection using fMRI data, and stress electrocardiogram based coronary artery detection. Utilizing the commonly used application of diabetic retinopathy, we first demonstrate that state-of-the-art SDG techniques fail to achieve generalized performance across data domains. We then develop a generic expert knowledge integrated deep learning technique DL+EKE and instantiate it for the DR application and show that DL+EKE outperforms SOTA SDG methods on DR. We then deploy instances of DL+EKE technique on the two real world examples of stress ECG and resting state (rs)-fMRI and discuss issues faced with SDG techniques.

</details>


### [153] [On The Robustness of Foundational 3D Medical Image Segmentation Models Against Imprecise Visual Prompts](https://arxiv.org/abs/2601.16383)
*Soumitri Chattopadhyay,Basar Demir,Marc Niethammer*

Main category: eess.IV

TL;DR: 该研究系统地分析了3D医学影像基础模型在面对不精确的密集视觉提示时的鲁棒性，发现在多器官腹部分割任务中，模型对视觉形状和空间线索的依赖性较高，并揭示了模型对某些扰动的韧性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D基础模型在可提示分割方面表现出潜力，但其对不精确提示的鲁棒性研究不足，而真实世界中的提示往往存在不精确性。

Method: 研究者通过对两种最新的基础模型进行实验，引入各种受控的密集视觉提示扰动，以模拟真实世界中的提示不精确性，并在多器官腹部分割任务上进行评估。

Result: 实验结果表明，基础模型在医学影像分割中，尤其依赖于视觉形状和空间线索。研究还量化了模型对特定类型提示扰动的抵抗程度。

Conclusion: 该研究深入探讨了3D基础模型在医学影像分割中对不精确提示的鲁棒性问题，揭示了模型对形状和空间信息的依赖性，并为提高模型在实际应用中的可靠性提供了见解。

Abstract: While 3D foundational models have shown promise for promptable segmentation of medical volumes, their robustness to imprecise prompts remains under-explored. In this work, we aim to address this gap by systematically studying the effect of various controlled perturbations of dense visual prompts, that closely mimic real-world imprecision. By conducting experiments with two recent foundational models on a multi-organ abdominal segmentation task, we reveal several facets of promptable medical segmentation, especially pertaining to reliance on visual shape and spatial cues, and the extent of resilience of models towards certain perturbations. Codes are available at: https://github.com/ucsdbiag/Prompt-Robustness-MedSegFMs

</details>


### [154] [Unsupervised Super-Resolution of Hyperspectral Remote Sensing Images Using Fully Synthetic Training](https://arxiv.org/abs/2601.16602)
*Xinxin Xu,Yann Gousseau,Christophe Kervazo,Saïd Ladjal*

Main category: eess.IV

TL;DR: 提出一种基于合成丰度数据的无监督高光谱图像超分辨率方法，通过解混得到丰度和端元，利用模拟的丰度数据训练超分辨率网络，然后重构高分辨率高光谱图像。


<details>
  <summary>Details</summary>
Motivation: 现有的高光谱图像超分辨率方法大多是监督学习，需要大量带真实值的数据进行训练，而这些数据通常难以获得。

Method: 首先，通过高光谱图像解混算法将原始高光谱图像分解为丰度和端元。然后，利用“死树叶”模型生成能够模仿真实丰度统计的合成丰度数据。使用这些合成丰度数据训练一个丰度超分辨率神经网络。最后，利用训练好的网络提升原始丰度的空间分辨率，并与端元重新组合生成高分辨率高光谱图像。

Result: 实验结果表明，合成图像具有良好的训练潜力，并且该方法能够有效地提升高光谱图像的空间分辨率。

Conclusion: 所提出的基于合成丰度数据的无监督训练策略能够克服真实数据稀缺的问题，实现高光谱图像的有效超分辨率。

Abstract: Considerable work has been dedicated to hyperspectral single image super-resolution to improve the spatial resolution of hyperspectral images and fully exploit their potential. However, most of these methods are supervised and require some data with ground truth for training, which is often non-available. To overcome this problem, we propose a new unsupervised training strategy for the super-resolution of hyperspectral remote sensing images, based on the use of synthetic abundance data. Its first step decomposes the hyperspectral image into abundances and endmembers by unmixing. Then, an abundance super-resolution neural network is trained using synthetic abundances, which are generated using the dead leaves model in such a way as to faithfully mimic real abundance statistics. Next, the spatial resolution of the considered hyperspectral image abundances is increased using this trained network, and the high resolution hyperspectral image is finally obtained by recombination with the endmembers. Experimental results show the training potential of the synthetic images, and demonstrate the method effectiveness.

</details>


### [155] [PanopMamba: Vision State Space Modeling for Nuclei Panoptic Segmentation](https://arxiv.org/abs/2601.16631)
*Ming Kang,Fung Fung Ting,Raphaël C. -W. Phan,Zongyuan Ge,Chee-Ming Ting*

Main category: eess.IV

TL;DR: 本文提出了一种名为 PanopMamba 的新型混合编码器-解码器架构，用于细胞核全景分割，集成了 Mamba 和 Transformer，并利用状态空间模型进行特征增强融合，以解决小目标检测、边界模糊和类别不平衡等挑战。


<details>
  <summary>Details</summary>
Motivation: 细胞核全景分割在癌症诊断中至关重要，但面临检测小目标、处理模糊边界和类别不平衡等挑战。现有方法在该领域存在不足。

Method: 提出 PanopMamba，一种结合 Mamba 和 Transformer 的混合编码器-解码器架构。通过多尺度 Mamba 主干和基于 SSM 的融合网络实现长距离感知和跨尺度特征共享。引入基于 SSM 的特征增强融合，以提升密集重叠细胞核的语义和空间特征表示。

Result: 在 MoNuSAC2020 和 NuInsSeg 数据集上，PanopMamba 在细胞核全景分割方面优于现有最先进的方法。此外，还展示了图像级 PQ (iPQ)、边界加权 PQ (wPQ) 和频率加权 PQ (fwPQ) 等替代评估指标的有效性。

Conclusion: PanopMamba 是一种有效的细胞核全景分割方法，能够克服现有挑战并取得优于 SOTA 的性能。提出的 PQ 变体指标也有效缓解了传统 PQ 的潜在偏差。

Abstract: Nuclei panoptic segmentation supports cancer diagnostics by integrating both semantic and instance segmentation of different cell types to analyze overall tissue structure and individual nuclei in histopathology images. Major challenges include detecting small objects, handling ambiguous boundaries, and addressing class imbalance. To address these issues, we propose PanopMamba, a novel hybrid encoder-decoder architecture that integrates Mamba and Transformer with additional feature-enhanced fusion via state space modeling. We design a multiscale Mamba backbone and a State Space Model (SSM)-based fusion network to enable efficient long-range perception in pyramid features, thereby extending the pure encoder-decoder framework while facilitating information sharing across multiscale features of nuclei. The proposed SSM-based feature-enhanced fusion integrates pyramid feature networks and dynamic feature enhancement across different spatial scales, enhancing the feature representation of densely overlapping nuclei in both semantic and spatial dimensions. To the best of our knowledge, this is the first Mamba-based approach for panoptic segmentation. Additionally, we introduce alternative evaluation metrics, including image-level Panoptic Quality ($i$PQ), boundary-weighted PQ ($w$PQ), and frequency-weighted PQ ($fw$PQ), which are specifically designed to address the unique challenges of nuclei segmentation and thereby mitigate the potential bias inherent in vanilla PQ. Experimental evaluations on two multiclass nuclei segmentation benchmark datasets, MoNuSAC2020 and NuInsSeg, demonstrate the superiority of PanopMamba for nuclei panoptic segmentation over state-of-the-art methods. Consequently, the robustness of PanopMamba is validated across various metrics, while the distinctiveness of PQ variants is also demonstrated. Code is available at https://github.com/mkang315/PanopMamba.

</details>


### [156] [Fast, faithful and photorealistic diffusion-based image super-resolution with enhanced Flow Map models](https://arxiv.org/abs/2601.16660)
*Maxence Noble,Gonzalo Iñaki Quintana,Benjamin Aubin,Clément Chadebec*

Main category: eess.IV

TL;DR: FlowMapSR 是一种新的基于扩散模型的图像超分辨率框架，通过结合 Flow Map 模型、改进的提示引导和对抗性微调，实现了高效推理和重建保真度与照片真实感之间的良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的图像超分辨率方法在重建保真度和照片真实感之间存在权衡，并且知识蒸馏方法可能导致感知线索丢失。Flow Map 模型作为一种快速推理且能保持模型稳定性的生成模型，为解决这些问题提供了新的可能性。

Method: 提出 FlowMapSR 框架，该框架基于 Flow Map 模型，并引入了正负提示引导（一种针对 Flow Map 模型的分类器自由引导的泛化）和使用 LoRA 的对抗性微调。在 Eulerian、Lagrangian 和 Shortcut 等 Flow Map 变体中，Shortcut 变体与增强方法结合效果最佳。

Result: FlowMapSR 在 x4 和 x8 两种放大倍数下，相比现有最先进的方法，在重建保真度和照片真实感之间取得了更好的平衡。一个模型同时支持两种放大倍数，无需特定于尺度的条件或退化引导机制。推理时间具有竞争力。

Conclusion: FlowMapSR 是一种高效的基于扩散模型的图像超分辨率框架，通过创新地结合 Flow Map 模型、提示引导和对抗性微调，有效解决了现有方法的局限性，并在保真度和真实感之间实现了出色的平衡。

Abstract: Diffusion-based image super-resolution (SR) has recently attracted significant attention by leveraging the expressive power of large pre-trained text-to-image diffusion models (DMs). A central practical challenge is resolving the trade-off between reconstruction faithfulness and photorealism. To address inference efficiency, many recent works have explored knowledge distillation strategies specifically tailored to SR, enabling one-step diffusion-based approaches. However, these teacher-student formulations are inherently constrained by information compression, which can degrade perceptual cues such as lifelike textures and depth of field, even with high overall perceptual quality. In parallel, self-distillation DMs, known as Flow Map models, have emerged as a promising alternative for image generation tasks, enabling fast inference while preserving the expressivity and training stability of standard DMs. Building on these developments, we propose FlowMapSR, a novel diffusion-based framework for image super-resolution explicitly designed for efficient inference. Beyond adapting Flow Map models to SR, we introduce two complementary enhancements: (i) positive-negative prompting guidance, based on a generalization of classifier free-guidance paradigm to Flow Map models, and (ii) adversarial fine-tuning using Low-Rank Adaptation (LoRA). Among the considered Flow Map formulations (Eulerian, Lagrangian, and Shortcut), we find that the Shortcut variant consistently achieves the best performance when combined with these enhancements. Extensive experiments show that FlowMapSR achieves a better balance between reconstruction faithfulness and photorealism than recent state-of-the-art methods for both x4 and x8 upscaling, while maintaining competitive inference time. Notably, a single model is used for both upscaling factors, without any scale-specific conditioning or degradation-guided mechanisms.

</details>


### [157] [PocketDVDNet: Realtime Video Denoising for Real Camera Noise](https://arxiv.org/abs/2601.16780)
*Crispian Morris,Imogen Dexter,Fan Zhang,David R. Bull,Nantheera Anantrasirichai*

Main category: eess.IV

TL;DR: PocketDVDNet 是一种轻量级的视频去噪器，通过模型压缩技术（包括结构化剪枝、基于物理的噪声模型和知识蒸馏）实现了高效且高质量的去噪，能够在实时处理能力下运行。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶、监控等应用中，现实世界中的多成分传感器噪声对实时视频去噪提出了挑战，需要一种兼顾性能和效率的解决方案。

Method: 使用模型压缩框架，结合了稀疏性引导的结构化剪枝、基于物理的噪声模型以及知识蒸馏。首先从参考模型开始，诱导稀疏性，进行有针对性的通道剪枝，然后在一个包含真实多成分噪声的数据集上重新训练一个教师模型。学生网络通过知识蒸馏学习隐式的噪声处理能力，无需显式的噪声图输入。

Result: PocketDVDNet 将原始模型大小减小了 74%，同时提高了去噪质量，并且能够实时处理 5 帧的视频块。

Conclusion: 通过结合激进的模型压缩和领域适应的知识蒸馏，可以实现兼顾性能和效率的实时视频去噪解决方案，使其适用于实际应用。

Abstract: Live video denoising under realistic, multi-component sensor noise remains challenging for applications such as autofocus, autonomous driving, and surveillance. We propose PocketDVDNet, a lightweight video denoiser developed using our model compression framework that combines sparsity-guided structured pruning, a physics-informed noise model, and knowledge distillation to achieve high-quality restoration with reduced resource demands. Starting from a reference model, we induce sparsity, apply targeted channel pruning, and retrain a teacher on realistic multi-component noise. The student network learns implicit noise handling, eliminating the need for explicit noise-map inputs. PocketDVDNet reduces the original model size by 74% while improving denoising quality and processing 5-frame patches in real-time. These results demonstrate that aggressive compression, combined with domain-adapted distillation, can reconcile performance and efficiency for practical, real-time video denoising.

</details>
