<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 153]
- [cs.CV](#cs.CV) [Total: 276]
- [cs.CL](#cs.CL) [Total: 178]
- [cs.RO](#cs.RO) [Total: 86]
- [eess.SY](#eess.SY) [Total: 19]
- [eess.IV](#eess.IV) [Total: 18]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes](https://arxiv.org/abs/2602.00053)
*Ratul Ali*

Main category: cs.AI

TL;DR: 本文对 FastAPI 和 NVIDIA Triton Inference Server 两种 ML 模型部署范式进行了基准测试，发现在单请求场景下 FastAPI 延迟更低，而在高吞吐量场景下 Triton 通过动态批处理表现更佳。研究还验证了 FastAPI 作为安全网关与 Triton 结合的混合架构是企业临床 AI 的最佳实践。


<details>
  <summary>Details</summary>
Motivation: 在医疗保健等受监管的领域，需要高效、可扩展且符合隐私标准的 ML 模型部署，以满足实时决策支持和批量处理的需求。

Method: 在 Kubernetes 上部署 DistilBERT 模型，使用 FastAPI 和 NVIDIA Triton Inference Server 分别作为部署范式，并在受控条件下测量 p50 和 p95 延迟以及吞吐量。此外，还评估了 FastAPI 作为安全网关与 Triton 结合的混合架构。

Result: FastAPI 在 p50 延迟方面表现更好（22 ms），适用于单请求工作负载。NVIDIA Triton Inference Server 通过动态批处理实现了更高的吞吐量（780 请求/秒，使用 NVIDIA T4 GPU），几乎是 FastAPI 的两倍。

Conclusion: 混合架构（FastAPI 作为安全网关，Triton 进行后端推理）是企业临床 AI 的最佳实践，为安全、高可用性的部署提供了蓝图。

Abstract: Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing requirements, including minimizing inference latency for real-time clinical decision support, maximizing throughput for batch processing of medical records, and ensuring strict adherence to data privacy standards such as HIPAA. This paper presents a rigorous benchmarking analysis comparing two prominent deployment paradigms: a lightweight, Python-based REST service using FastAPI, and a specialized, high-performance serving engine, NVIDIA Triton Inference Server. Leveraging a reference architecture for healthcare AI, we deployed a DistilBERT sentiment analysis model on Kubernetes to measure median (p50) and tail (p95) latency, as well as throughput, under controlled experimental conditions. Our results indicate a distinct trade-off. While FastAPI provides lower overhead for single-request workloads with a p50 latency of 22 ms, Triton achieves superior scalability through dynamic batching, delivering a throughput of 780 requests per second on a single NVIDIA T4 GPU, nearly double that of the baseline. Furthermore, we evaluate a hybrid architectural approach that utilizes FastAPI as a secure gateway for protected health information de-identification and Triton for backend inference. This study validates the hybrid model as a best practice for enterprise clinical AI and offers a blueprint for secure, high-availability deployments.

</details>


### [2] [Learning to Price: Interpretable Attribute-Level Models for Dynamic Markets](https://arxiv.org/abs/2602.00188)
*Srividhya Sethuraman,Chandrashekar Lakshminarayanan*

Main category: cs.AI

TL;DR: 本文提出了一种名为AFDLD 的可解释低维需求模型，并在此基础上开发了 ADEPT 算法，用于高维市场中的动态定价。ADEPT 能够直接在属性空间中学习，并实现了亚线性遗憾，同时提供了透明的、基于属性的价格解释。


<details>
  <summary>Details</summary>
Motivation: 现有的低秩匪徒算法虽然学习效率高，但其潜在特征难以解释单个产品属性如何影响价格，这在高维市场中是一个核心挑战。

Method: 本文提出了 AFDLD 模型，该模型将产品价格表示为属性级别贡献的总和，并明确建模了替代效应。在此基础上，开发了 ADEPT 算法，这是一个无投影、无梯度的在线学习算法，直接在属性空间中操作，并实现了 $\tilde{\mathcal{O}}(\sqrt{d}T^{3/4})$ 的亚线性遗憾。

Result: 通过合成和真实世界的数据集，研究表明 ADEPT 能够在动态市场条件下学习近乎最优的价格，快速适应冲击和漂移，并提供透明的、属性级别的价格解释。

Conclusion: 研究结果表明，通过结构化的、由属性驱动的表示，可以同时实现自主定价代理的可解释性和效率。

Abstract: Dynamic pricing in high-dimensional markets poses fundamental challenges of scalability, uncertainty, and interpretability. Existing low-rank bandit formulations learn efficiently but rely on latent features that obscure how individual product attributes influence price. We address this by introducing an interpretable \emph{Additive Feature Decomposition-based Low-Dimensional Demand (\textbf{AFDLD}) model}, where product prices are expressed as the sum of attribute-level contributions and substitution effects are explicitly modeled. Building on this structure, we propose \textbf{ADEPT} (Additive DEcomposition for Pricing with cross-elasticity and Time-adaptive learning)-a projection-free, gradient-free online learning algorithm that operates directly in attribute space and achieves a sublinear regret of $\tilde{\mathcal{O}}(\sqrt{d}T^{3/4})$. Through controlled synthetic studies and real-world datasets, we show that ADEPT (i) learns near-optimal prices under dynamic market conditions, (ii) adapts rapidly to shocks and drifts, and (iii) yields transparent, attribute-level price explanations. The results demonstrate that interpretability and efficiency in autonomous pricing agents can be achieved jointly through structured, attribute-driven representations.

</details>


### [3] [From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models](https://arxiv.org/abs/2602.00190)
*Mohit Jiwatode,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 本研究利用大型语言模型（LLMs）从游戏过程数据中反向推导出游戏规则（VGDL），并提出了一种基于结构因果模型（SCM）的方法，该方法优于直接生成法，能更准确地恢复游戏规则，并可用于因果强化学习等下游应用。


<details>
  <summary>Details</summary>
Motivation: 目前的深度学习智能体在复杂游戏领域表现出色，但缺乏对游戏底层因果机制的理解。本研究旨在通过因果归纳能力，让 LLMs 从观察数据中推断出控制定律，从而解决这一问题。

Method: 研究者从 GVGAI 框架中选取了九款代表性游戏，并使用两种方法让 LLMs 生成 VGDL 规则：1. 直接从观察数据生成代码；2. 先推断 SCM，再将其翻译成 VGDL。两种方法在不同的提示策略和上下文信息量下进行评估。

Result: 基于 SCM 的方法比直接生成法能更准确地生成接近真实规则的 VGDL 描述，在盲评中获得高达 81% 的偏好胜率，并且生成的规则逻辑一致性更高。

Conclusion: SCM 方法是从游戏过程数据推导 VGDL 规则的有效途径，它生成的规则更准确且逻辑一致。这些学习到的 SCM 可用于因果强化学习、可解释智能体以及生成新颖且逻辑一致的游戏。

Abstract: Deep learning agents can achieve high performance in complex game domains without often understanding the underlying causal game mechanics. To address this, we investigate Causal Induction: the ability to infer governing laws from observational data, by tasking Large Language Models (LLMs) with reverse-engineering Video Game Description Language (VGDL) rules from gameplay traces. To reduce redundancy, we select nine representative games from the General Video Game AI (GVGAI) framework using semantic embeddings and clustering. We compare two approaches to VGDL generation: direct code generation from observations, and a two-stage method that first infers a structural causal model (SCM) and then translates it into VGDL. Both approaches are evaluated across multiple prompting strategies and controlled context regimes, varying the amount and form of information provided to the model, from just raw gameplay observations to partial VGDL specifications. Results show that the SCM-based approach more often produces VGDL descriptions closer to the ground truth than direct generation, achieving preference win rates of up to 81\% in blind evaluations and yielding fewer logically inconsistent rules. These learned SCMs can be used for downstream use cases such as causal reinforcement learning, interpretable agents, and procedurally generating novel but logically consistent games.

</details>


### [4] [Complete Identification of Deep ReLU Neural Networks by Many-Valued Logic](https://arxiv.org/abs/2602.00266)
*Yani Zhang,Helmut Bölcskei*

Main category: cs.AI

TL;DR: 研究人员提出了一种将ReLU神经网络映射到Lukasiewicz逻辑公式的方法，从而实现对神经网络进行功能等价的转换和识别。他们证明了所有具有相同功能的ReLU网络都可以在Lukasiewicz逻辑的有限公理下通过有限的对称性相互连接。


<details>
  <summary>Details</summary>
Motivation: 现有的ReLU神经网络存在非平凡的功能对称性，即不同的网络结构和参数可以实现相同的功能。这使得从函数出发反向推导出所有可能的网络结构和参数（即完整识别问题）变得困难。

Method: 1. 将ReLU神经网络翻译成Lukasiewicz逻辑公式。2. 通过遵循逻辑公理的代数重写来对功能等价的网络进行转换。3. 提出一种组合范式，将Lukasiewicz逻辑公式映射回ReLU网络。4. 利用Chang的完备性定理证明功能等价类中的所有ReLU网络可以通过Lukasiewicz逻辑的有限公理所对应的有限对称性连接起来。

Result: 证明了对于每一个功能等价类，该类中的所有ReLU网络都通过对应于Lukasiewicz逻辑有限公理的有限对称性集合相互连接。这种方法类似于Shannon在开关电路设计中的工作。

Conclusion: 通过将ReLU网络映射到Lukasiewicz逻辑，并利用代数重写和完备性定理，可以系统地识别和连接所有实现相同功能的ReLU网络。这为神经网络的合成和分析提供了一种新的理论框架。

Abstract: Deep ReLU neural networks admit nontrivial functional symmetries: vastly different architectures and parameters (weights and biases) can realize the same function. We address the complete identification problem -- given a function f, deriving the architecture and parameters of all feedforward ReLU networks giving rise to f. We translate ReLU networks into Lukasiewicz logic formulae, and effect functional equivalent network transformations through algebraic rewrites governed by the logic axioms. A compositional norm form is proposed to facilitate the mapping from Lukasiewicz logic formulae back to ReLU networks. Using Chang's completeness theorem, we show that for every functional equivalence class, all ReLU networks in that class are connected by a finite set of symmetries corresponding to the finite set of axioms of Lukasiewicz logic. This idea is reminiscent of Shannon's seminal work on switching circuit design, where the circuits are translated into Boolean formulae, and synthesis is effected by algebraic rewriting governed by Boolean logic axioms.

</details>


### [5] [Localizing and Correcting Errors for LLM-based Planners](https://arxiv.org/abs/2602.00276)
*Aditya Kumar,William W. Cohen*

Main category: cs.AI

TL;DR: 提出一种名为 L-ICL 的迭代式指令增强方法，通过局部注入的上下文学习示例来纠正大型语言模型在符号经典规划任务中的约束违规问题，显著提高了规划的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在数学和编码方面表现出强大的推理能力，但在符号经典规划任务中经常失败，表现为生成的规划违反领域约束（例如，穿墙）。

Method: 提出一种名为局部上下文学习（L-ICL）的技术，通过迭代式地增强指令来实现：针对具体的失败步骤进行有针对性的纠正。L-ICL 识别轨迹中的第一个约束违规，并注入一个最小的输入-输出示例，提供失败步骤的正确行为。

Result: 与显式指令、传统上下文学习（ICL）以及其他基线方法相比，L-ICL 显著更有效。在 8x8 网格世界中，L-ICL 在仅有 60 个训练示例的情况下，有效规划的比例高达 89%，而最佳基线仅为 59%，提高了 30%。L-ICL 在其他领域（如网格世界导航、迷宫、Sokoban 和 BlocksWorld）以及多种 LLM 架构上均取得了显著改进。

Conclusion: L-ICL 是一种有效的方法，可以克服 LLM 在符号经典规划任务中的主要挑战——约束违规，通过局部注入的上下文学习示例，大幅提高了规划的准确性和鲁棒性。

Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities on math and coding, but frequently fail on symbolic classical planning tasks. Our studies, as well as prior work, show that LLM-generated plans routinely violate domain constraints given in their instructions (e.g., walking through walls). To address this failure, we propose iteratively augmenting instructions with Localized In-Context Learning (L-ICL) demonstrations: targeted corrections for specific failing steps. Specifically, L-ICL identifies the first constraint violation in a trace and injects a minimal input-output example giving the correct behavior for the failing step. Our proposed technique of L-ICL is much effective than explicit instructions or traditional ICL, which adds complete problem-solving trajectories, and many other baselines. For example, on an 8x8 gridworld, L-ICL produces valid plans 89% of the time with only 60 training examples, compared to 59% for the best baseline, an increase of 30%. L-ICL also shows dramatic improvements in other domains (gridworld navigation, mazes, Sokoban, and BlocksWorld), and on several LLM architectures.

</details>


### [6] [Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning](https://arxiv.org/abs/2602.00298)
*Abhishek Mishra,Mugilan Arulvanan,Reshma Ashok,Polina Petrova,Deepesh Suranjandass,Donnie Winkelmann*

Main category: cs.AI

TL;DR: 该研究通过在包含11个不同领域的不安全数据集上微调大型语言模型（LLMs），发现后门触发器会增加77.8%领域中的失准率，其中'risky-financial-advice'和'toxic-legal-advice'影响最大。此外，成员推理指标可预测失准程度，并首次对不同领域的涌现性失准进行了分类排名。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）越来越多地用于自主任务，模型行为与人类意图的“涌现性失准”（emergent misalignment）构成了AI安全风险。

Method: 研究人员在一个包含11个不同领域的安全级别较低的数据集上对LLMs进行了微调，并在存在或不存在后门触发器的情况下，使用一套不相关的用户提示对其进行评估。此外，他们还探索了成员推理指标预测失准程度的能力，并分析了在一个模型上提取的失准方向是否能推广到其他模型。

Result: （i）后门触发器在77.8%的领域中增加了失准率（平均下降4.33个点），其中'risky-financial-advice'和'toxic-legal-advice'领域的影响最大。（ii）领域脆弱性差异很大，从'incorrect-math'（微调后输出错误数学答案的失准率为0%）到'gore-movie-trivia'（失准率为87.67%）。成员推理指标（特别是调整后）可以很好地预测广泛失准的程度。

Conclusion: 后门触发器是导致LLMs涌现性失准的一个重要因素，不同领域对这种失准的脆弱性差异显著。研究首次提供了按领域划分的涌现性失准分类排名，并提出了构建失准数据集的方法，这对AI安全和模型后训练具有重要意义。

Abstract: Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluating them both with and without backdoor triggers on a suite of unrelated user prompts. Our evaluation experiments on \texttt{Qwen2.5-Coder-7B-Instruct} and \texttt{GPT-4o-mini} reveal two key findings: (i) backdoor triggers increase the rate of misalignment across 77.8% of domains (average drop: 4.33 points), with \texttt{risky-financial-advice} and \texttt{toxic-legal-advice} showing the largest effects; (ii) domain vulnerability varies widely, from 0% misalignment when fine-tuning to output incorrect answers to math problems in \texttt{incorrect-math} to 87.67% when fine-tuned on \texttt{gore-movie-trivia}.
  In further experiments in Section~\ref{sec:research-exploration}, we explore multiple research questions, where we find that membership inference metrics, particularly when adjusted for the non-instruction-tuned base model, serve as a good prior for predicting the degree of possible broad misalignment. Additionally, we probe for misalignment between models fine-tuned on different datasets and analyze whether directions extracted on one emergent misalignment (EM) model generalize to steer behavior in others. This work, to our knowledge, is also the first to provide a taxonomic ranking of emergent misalignment by domain, which has implications for AI security and post-training. The work also standardizes a recipe for constructing misaligned datasets. All code and datasets are publicly available on GitHub.\footnote{https://github.com/abhishek9909/assessing-domain-emergent-misalignment/tree/main}

</details>


### [7] [Autonomous Data Processing using Meta-Agents](https://arxiv.org/abs/2602.00307)
*Udayan Khurana*

Main category: cs.AI

TL;DR: 提出了一种名为 ADP-MA 的框架，通过分层代理协同来动态构建、执行和优化数据处理管道，实现了自主监控、管理和优化。


<details>
  <summary>Details</summary>
Motivation: 传统的数据处理管道是静态且为特定任务手工设计的，难以适应不断变化的需求；现有的通用代理和代码助手无法在部署后自主监控、管理和优化端到端管道。

Method: ADP-MA 框架采用分层代理协同的方式，核心是“元代理”负责分析输入数据和任务规范，设计多阶段计划，实例化专门的“地面代理”，并持续评估管道性能。框架包含三个关键组件：用于策略生成的规划模块、用于代理协调和工具集成的编排层、以及用于迭代评估和回溯的监控循环。

Result: ADP-MA 强调了上下文感知优化、自适应工作负载分区和渐进式采样以实现可扩展性。该框架能够利用多种外部工具并重用先前设计的代理，从而减少冗余并加速管道构建。通过交互式演示展示了在代表性数据处理任务中的管道构建、执行监控和自适应优化。

Conclusion: ADP-MA 框架通过其创新的代理协同架构，能够动态构建、执行和迭代优化数据处理管道，解决了传统方法在适应性和自主性方面的局限性，并实现了可扩展性和效率的提升。

Abstract: Traditional data processing pipelines are typically static and handcrafted for specific tasks, limiting their adaptability to evolving requirements. While general-purpose agents and coding assistants can generate code for well-understood data pipelines, they lack the ability to autonomously monitor, manage, and optimize an end-to-end pipeline once deployed. We present \textbf{Autonomous Data Processing using Meta-agents} (ADP-MA), a framework that dynamically constructs, executes, and iteratively refines data processing pipelines through hierarchical agent orchestration. At its core, \textit{meta-agents} analyze input data and task specifications to design a multi-phase plan, instantiate specialized \textit{ground-level agents}, and continuously evaluate pipeline performance. The architecture comprises three key components: a planning module for strategy generation, an orchestration layer for agent coordination and tool integration, and a monitoring loop for iterative evaluation and backtracking. Unlike conventional approaches, ADP-MA emphasizes context-aware optimization, adaptive workload partitioning, and progressive sampling for scalability. Additionally, the framework leverages a diverse set of external tools and can reuse previously designed agents, reducing redundancy and accelerating pipeline construction. We demonstrate ADP-MA through an interactive demo that showcases pipeline construction, execution monitoring, and adaptive refinement across representative data processing tasks.

</details>


### [8] [SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?](https://arxiv.org/abs/2602.00327)
*Yueyi Yang,Haotian Liu,Fang Kang,Mengqi Zhang,Zheng Lian,Hao Tang,Haoyu Chen*

Main category: cs.AI

TL;DR: 该研究提出了一种名为SayNext-Bench的基准测试和SayNext-PC数据集，以评估大型语言模型（LLM）和多模态大型语言模型（MLLM）在利用手势、注视和情绪等情境信息预测人类下一句话的能力。研究还开发了一个名为SayNext-Chat的MLLM模型，该模型通过双通道预测和认知启发式设计，在预测准确性方面优于现有模型，并强调了多模态信息和主动预测处理在人机交互中的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在对话方面取得了进展，但它们在预测人类下一句话方面表现不佳，而人类可以利用多模态线索轻松预测。研究旨在探索LLMs是否能通过结合多模态信息来复制这种预测能力，从而改进AI在对话中的表现。

Method: 1. 提出SayNext-Bench基准测试，用于评估LLMs和MLLMs在根据多模态线索预测下一句话的能力。2. 构建SayNext-PC数据集，包含丰富的多模态对话信息。3. 开发SayNext-Chat，一个采用双通道预测和认知启发式设计的MLLM模型，以模拟对话中的预测处理。

Result: SayNext-Chat模型在词汇重叠、语义相似性和情感一致性方面优于最先进的MLLMs。实验证明了从多模态线索进行下一句话预测的可行性。

Conclusion: 研究表明，多模态线索和主动预测处理是自然人类交互的基础，并且是当前MLLMs所缺乏的。该研究为开发更具人类交互特性、更上下文敏感的AI提供了新的方向。

Abstract: We explore the use of large language models (LLMs) for next-utterance prediction in human dialogue. Despite recent advances in LLMs demonstrating their ability to engage in natural conversations with users, we show that even leading models surprisingly struggle to predict a human speaker's next utterance. Instead, humans can readily anticipate forthcoming utterances based on multimodal cues, such as gestures, gaze, and emotional tone, from the context. To systematically examine whether LLMs can reproduce this ability, we propose SayNext-Bench, a benchmark that evaluates LLMs and Multimodal LLMs (MLLMs) on anticipating context-conditioned responses from multimodal cues spanning a variety of real-world scenarios. To support this benchmark, we build SayNext-PC, a novel large-scale dataset containing dialogues with rich multimodal cues. Building on this, we further develop a dual-route prediction MLLM, SayNext-Chat, that incorporates cognitively inspired design to emulate predictive processing in conversation. Experimental results demonstrate that our model outperforms state-of-the-art MLLMs in terms of lexical overlap, semantic similarity, and emotion consistency. Our results prove the feasibility of next-utterance prediction with LLMs from multimodal cues and emphasize the (i) indispensable role of multimodal cues and (ii) actively predictive processing as the foundation of natural human interaction, which is missing in current MLLMs. We hope that this exploration offers a new research entry toward more human-like, context-sensitive AI interaction for human-centered AI. Our benchmark and model can be accessed at https://saynext.github.io/.

</details>


### [9] [MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants](https://arxiv.org/abs/2602.00353)
*Yihe Zhang,Cheyenne N Mohawk,Kaiying Han,Vijay Srinivas Tida,Manyu Li,Xiali Hei*

Main category: cs.AI

TL;DR: 本文提出了MHDash，一个用于开发、评估和审计心理健康AI系统的开源平台，并发现现有的大型语言模型（LLMs）在处理高风险心理健康情况时存在局限性，尤其是在多轮对话中，并强调了现有评估方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有对心理健康AI系统的评估主要依赖于聚合性能指标，这往往掩盖了特定风险下的失败模式，并且在多轮交互中对模型行为的洞察有限。因此，需要一个更精细、更注重风险的评估平台。

Method: 开发了一个名为MHDash的开源平台，该平台集成了数据收集、结构化标注（包括关注类型、风险等级、对话意图）、多轮对话生成和基线评估。通过该平台对现有基线模型和LLM API进行了评估。

Result: 发现简单的基线模型和先进的LLM API在整体准确率上相当，但在高风险案例上的表现差异显著。一些LLMs能够保持一致的顺序风险等级，但绝对风险分类有误；另一些LLMs虽然总体得分尚可，但存在高假阴性率。在多轮对话中，性能差距被放大，风险信号逐渐显现。

Conclusion: 传统的基准测试不足以满足安全关键的心理健康设置。MHDash的发布旨在促进可重复研究、透明评估以及为心理健康支持AI系统进行安全对齐的开发。

Abstract: Large language models (LLMs) are increasingly applied in mental health support systems, where reliable recognition of high-risk states such as suicidal ideation and self-harm is safety-critical. However, existing evaluations primarily rely on aggregate performance metrics, which often obscure risk-specific failure modes and provide limited insight into model behavior in realistic, multi-turn interactions. We present MHDash, an open-source platform designed to support the development, evaluation, and auditing of AI systems for mental health applications. MHDash integrates data collection, structured annotation, multi-turn dialogue generation, and baseline evaluation into a unified pipeline. The platform supports annotations across multiple dimensions, including Concern Type, Risk Level, and Dialogue Intent, enabling fine-grained and risk-aware analysis. Our results reveal several key findings: (i) simple baselines and advanced LLM APIs exhibit comparable overall accuracy yet diverge significantly on high-risk cases; (ii) some LLMs maintain consistent ordinal severity ranking while failing absolute risk classification, whereas others achieve reasonable aggregate scores but suffer from high false negative rates on severe categories; and (iii) performance gaps are amplified in multi-turn dialogues, where risk signals emerge gradually. These observations demonstrate that conventional benchmarks are insufficient for safety-critical mental health settings. By releasing MHDash as an open platform, we aim to promote reproducible research, transparent evaluation, and safety-aligned development of AI systems for mental health support.

</details>


### [10] [Position: Agentic Evolution is the Path to Evolving LLMs](https://arxiv.org/abs/2602.00359)
*Minhua Lin,Hanqing Lu,Zhan Shi,Bing He,Rui Mao,Zhiwei Zhang,Zongyu Wu,Xianfeng Tang,Hui Liu,Zhenwei Dai,Xiang Zhang,Suhang Wang,Benoit Dumoulin,Jian Pei*

Main category: cs.AI

TL;DR: 该论文提出了一种名为A-Evolve的框架，旨在解决大型语言模型（LLMs）在部署后因环境变化而无法持续适应的问题，通过引入“进化”作为新的扩展维度，并将进化过程本身视为一个自主的进化代理，以实现持续的、开放式的适应。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在训练后无法跟上部署环境中不断变化的需求，静态训练和计算资源的扩展无法弥合这种“训练-部署”的差距。现有的部署时适应方法缺乏诊断故障和产生持久改进的战略能动性。

Method: 提出了一种名为A-Evolve的通用框架，将部署时的改进视为一个有目标导向的优化过程，作用于持久的系统状态。该框架将进化本身从一个固定的管道提升为一个自主的进化代理。

Result: 提出了“进化扩展假说”，即适应能力随着分配给进化的计算量而扩展。这表明代理式进化是实现持续、开放式现实世界适应的可扩展途径。

Conclusion: 代理式进化代表了大型语言模型适应的必然未来，它将进化本身变成一个自主代理，能够通过持续的、目标导向的优化过程，应对部署环境的动态变化，并实现可扩展的适应能力。

Abstract: As Large Language Models (LLMs) move from curated training sets into open-ended real-world environments, a fundamental limitation emerges: static training cannot keep pace with continual deployment environment change. Scaling training-time and inference-time compute improves static capability but does not close this train-deploy gap. We argue that addressing this limitation requires a new scaling axis-evolution. Existing deployment-time adaptation methods, whether parametric fine-tuning or heuristic memory accumulation, lack the strategic agency needed to diagnose failures and produce durable improvements. Our position is that agentic evolution represents the inevitable future of LLM adaptation, elevating evolution itself from a fixed pipeline to an autonomous evolver agent. We instantiate this vision in a general framework, A-Evolve, which treats deployment-time improvement as a deliberate, goal-directed optimization process over persistent system state. We further propose the evolution-scaling hypothesis: the capacity for adaptation scales with the compute allocated to evolution, positioning agentic evolution as a scalable path toward sustained, open-ended adaptation in the real world.

</details>


### [11] [POET: Protocol Optimization via Eligibility Tuning](https://arxiv.org/abs/2602.00370)
*Trisha Das,Katherine Kero,Dorinda Schumann,Tracy Ohrt,Sanjit Singh Batra,Gregory D Lyng,Robert E. Tillman*

Main category: cs.AI

TL;DR: 本研究提出了一种引导式生成框架，通过引入可解释的语义轴（如人口统计学、实验室参数和行为因素）来辅助生成临床试验的资格标准（EC），旨在解决现有方法在结构化输入和端到端系统之间的局限性，并提出了一种基于评分表的评估框架，证明其在自动、基于评分表和临床医生评估中均优于无引导生成。


<details>
  <summary>Details</summary>
Motivation: 现有自动化方法在生成临床试验资格标准（EC）时，要么需要高度结构化的输入，要么依赖于端到端系统，这两者都限制了其实用性。研究人员希望找到一种介于两者之间的、更实用且可解释的方法来辅助这一耗时且认知要求高的任务。

Method: 提出了一种引导式生成框架，利用大型语言模型（LLMs）推导出可解释的语义轴（如人口统计学、实验室参数、行为因素），以引导EC的生成。同时，提出了一种可复用的、基于评分表的评估框架，从临床意义的维度评估生成的EC。

Result: 引导式生成方法在自动评估、基于评分表的评估和临床医生评估中，均一致优于无引导生成。

Conclusion: 所提出的引导式生成框架提供了一种实用且可解释的AI辅助试验设计解决方案，能够有效地辅助生成临床试验的资格标准。

Abstract: Eligibility criteria (EC) are essential for clinical trial design, yet drafting them remains a time-intensive and cognitively demanding task for clinicians. Existing automated approaches often fall at two extremes either requiring highly structured inputs, such as predefined entities to generate specific criteria, or relying on end-to-end systems that produce full eligibility criteria from minimal input such as trial descriptions limiting their practical utility. In this work, we propose a guided generation framework that introduces interpretable semantic axes, such as Demographics, Laboratory Parameters, and Behavioral Factors, to steer EC generation. These axes, derived using large language models, offer a middle ground between specificity and usability, enabling clinicians to guide generation without specifying exact entities. In addition, we present a reusable rubric-based evaluation framework that assesses generated criteria along clinically meaningful dimensions. Our results show that our guided generation approach consistently outperforms unguided generation in both automatic, rubric-based and clinician evaluations, offering a practical and interpretable solution for AI-assisted trial design.

</details>


### [12] [KEPO: Knowledge-Enhanced Preference Optimization for Reinforcement Learning with Reasoning](https://arxiv.org/abs/2602.00400)
*Fan Yang,Rui Meng,Trudi Di Qi,Ali Ezzati,Yuxin Wen*

Main category: cs.AI

TL;DR: 本文提出了一种名为KEPO的强化学习后训练框架，通过质量门控的教师蒸馏和知识增强的探索策略，解决了现有方法在推理密集型任务中遇到的奖励稀疏、探索困难和梯度噪声问题，并在医学视觉问答任务中取得了更好的训练稳定性和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习（RL）的后训练方法在引导大型语言和视觉-语言模型进行显式推理时面临挑战，主要是由于稀疏的轨迹奖励导致信用分配模糊和探索失败，容易陷入“学习悬崖”。现有的教师蒸馏方法虽然引入了密集的教师监督，但将其统一应用于所有生成的轨迹，这对于推理密集型任务来说并不理想，因为低质量轨迹中的早期逻辑错误会导致噪声和错误的梯度。

Method: 本文提出了知识增强偏好优化（KEPO）框架，包含两个主要部分：（1）质量门控的在线蒸馏目标：仅对高质量的轨迹应用密集的教师指导，以稳定优化。（2）知识增强的探索策略：利用教师模型的提示，拒绝性地采样奖励积极的在线轨迹用于RL，以缓解探索崩溃。

Result: 在具有挑战性的医学视觉问答基准测试中，KEPO在单源泛化方面表现出了改进的训练稳定性、更连贯的推理行为以及优于强化学习和在线蒸馏基线的分布外性能。

Conclusion: KEPO是一种统一的后训练框架，通过质量门控的在线蒸馏和知识增强的探索策略，有效解决了现有RL方法在推理密集型任务中的挑战，并展现出优越的性能和泛化能力。

Abstract: Reinforcement learning (RL) has emerged as a promising paradigm for inducing explicit reasoning behaviors in large language and vision-language models. However, reasoning-oriented RL post-training remains fundamentally challenging due to sparse trajectory-level rewards, leading to ambiguous credit assignment and severe exploration failures that can trap the policy in a ``learning cliff.'' Recent on-policy distillation methods introduce dense teacher supervision to stabilize optimization, but apply it uniformly across all generated trajectories. We argue that such uniform distillation is ill-suited for reasoning-intensive tasks, as low-quality on-policy trajectories often originate from early logical errors, and distillation under flawed contexts injects noisy and misaligned gradients. To address these challenges, we propose Knowledge-Enhanced Preference Optimization (KEPO), a unified post-training framework that integrates: (i) a quality-gated on-policy distillation objective that selectively applies dense teacher guidance only to high-quality trajectories, and (ii) a knowledge-enhanced exploration strategy that leverages hints learned from a teacher model to rejectively sample reward-positive on-policy trajectories for RL, thereby mitigating exploration collapse. Evaluated on a challenging medical visual question answering benchmark under single-source generalization, KEPO demonstrates improved training stability, more coherent reasoning behaviors, and superior out-of-distribution performance over reinforcement learning and on-policy distillation baselines.

</details>


### [13] [RobustDebias: Debiasing Language Models using Distributionally Robust Optimization](https://arxiv.org/abs/2602.00405)
*Deep Gandhi,Katyani Singh,Nidhi Hegde*

Main category: cs.AI

TL;DR: 本文提出了一种名为RobustDebias的新机制，通过在模型微调阶段应用分布鲁棒优化（DRO）来减轻BERT等预训练语言模型中的社会偏见，而无需修改预训练过程，并在不显著影响模型性能的情况下实现了显著的偏见消除。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练语言模型存在偏见和社会刻板印象。现有的去偏方法主要集中在修改预训练过程，成本高昂且难以扩展到大型模型。而仅通过任务特定数据集微调模型，会损害模型性能并可能加剧数据中存在的偏见。因此，研究者希望在不增加预训练成本的情况下，解决微调阶段的偏见放大问题。

Method: 本文提出了一种名为RobustDebias的新机制，该机制将分布鲁棒优化（DRO）的思想应用于BERT模型的微调过程。RobustDebias的目标是在模型微调过程中，在多个群体之间同时减轻偏见，并且这种方法可以泛化到任何数据集或任务。

Result: 在各种语言模型上的大量实验表明，RobustDebias能够显著减少模型中的社会偏见，同时对模型性能的影响很小。

Conclusion: RobustDebias是一种有效的、可扩展的在微调阶段消除预训练语言模型偏见的方法，它通过改编分布鲁棒优化来实现，并在不损害模型性能的前提下，显著减轻了模型跨多个社会群体的偏见。

Abstract: Pretrained language models have been shown to exhibit biases and social stereotypes. Prior work on debiasing these models has largely focused on modifying embedding spaces during pretraining, which is not scalable for large models. Fine-tuning pretrained models on task-specific datasets can both degrade model performance and amplify biases present in the fine-tuning data. We address bias amplification during fine-tuning rather than costly pretraining, focusing on BERT models due to their widespread use in language understanding tasks. While Empirical Risk Minimization effectively optimizes downstream performance, it often amplifies social biases during fine-tuning. To counter this, we propose \textit{RobustDebias}, a novel mechanism which adapts Distributionally Robust Optimization (DRO) to debias language models during fine-tuning. Our approach debiases models across multiple demographics during MLM fine-tuning and generalizes to any dataset or task. Extensive experiments on various language models show significant bias mitigation with minimal performance impact.

</details>


### [14] [PolarMem: A Training-Free Polarized Latent Graph Memory for Verifiable Multimodal Agents](https://arxiv.org/abs/2602.00415)
*Zhisheng Chen,Tingyu Wu,Zijie Zhou,Zhengwei Xie,Ziyan Weng,Yingwei Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为PolarMem的无训练图记忆系统，用于增强多模态智能体的长期决策能力，使其推理过程可验证。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型在长期决策中存在记忆系统的局限性，无法区分语义关联与事实存在，也无法有效编码负面约束，导致推理过程中的“幻觉”现象。

Method: PolarMem通过非参数化分布划分将模糊的感知似然转化为离散的逻辑约束，并利用极化图拓扑结构和正交抑制连接来显式存储已验证的否定信息。推理时，采用逻辑优先的检索机制。

Result: 在八个冻结的视觉-语言模型和六个基准测试上的评估表明，PolarMem作为一个强大的认知系统，能有效抑制违反负面约束的幻觉模式。

Conclusion: PolarMem为构建可验证的多模态智能体奠定了基础，通过其独特的记忆机制提升了智能体的逻辑推理和决策能力。

Abstract: As multimodal agents evolve from passive observers to long-horizon decision-makers, they require memory systems that provide not just information availability but logical verifiability. A fundamental limitation of current architectures is the epistemic asymmetry inherent in probabilistic vision-language models and dense associative memories: they conflate semantic affinity with factual existence and structurally fail to encode negative constraints. To this end, we introduce PolarMem, a training-free Polarized Latent Graph Memory designed to ground agent reasoning in verifiable evidence. PolarMem transforms fuzzy perceptual likelihoods into discrete logical constraints through non-parametric distributional partitioning. Furthermore, it employs a polarized graph topology with orthogonal inhibitory connections to explicitly store verified negation as a primary cognitive state. At inference time, we enforce a logic-dominant retrieval paradigm, suppressing hallucinatory patterns that violate negative constraints. Extensive evaluation across eight frozen Vision--Language Models and six benchmarks demonstrates that PolarMem functions as a robust cognitive system, establishing a foundation for verifiable multimodal agents. Our code is available at https://github.com/czs-ict/PolarMem.

</details>


### [15] [Do Latent-CoT Models Think Step-by-Step? A Mechanistic Study on Sequential Reasoning Tasks](https://arxiv.org/abs/2602.00449)
*Jia Liang,Liangming Pan*

Main category: cs.AI

TL;DR: 研究表明，CODI 风格的 Latent-CoT 模型在处理短序列任务时可以进行完整的潜在逐步推理，但在长序列任务中会采用压缩或捷径策略，并且其鲁棒性受到优化难度等因素的影响。


<details>
  <summary>Details</summary>
Motivation: Latent-CoT 模型旨在实现逐步计算而不产生冗长的推理过程，但其内部机制尚不清楚。本研究旨在深入理解 CODI 模型在逐步推理任务中的工作原理。

Method: 研究者使用 logit-lens 解码、线性探针、注意力分析和激活修复等技术，在两种和三种跳跃任务上对 CODI 模型进行分析，以定位中间状态表示并追踪其到最终读出的路径。同时，还进行了消融实验来评估模型在不同条件下的表现。

Result: 在两跳和三跳任务中，CODI 模型能够生成完整的桥接状态，并在不同潜在思考位置均可解码，同时最终输入沿近乎直接的路径传播。预测通过思考结束边界处的晚期融合产生。对于更长的跳跃长度，CODI 模型未能可靠地执行完整的潜在回滚，而是表现出部分潜在推理路径，该路径侧重于晚期中间状态并将其与最后的输入在答案读出位置融合。消融实验表明，这种部分路径在 regime 变化（如更难的优化）下会崩溃。

Conclusion: CODI 风格的 Latent-CoT 模型在处理短序列任务时可以实现忠实的迭代计算，但在长序列任务中会采用压缩或捷径策略。研究揭示了设计用于顺序推理的鲁棒 Latent-CoT 目标的挑战。

Abstract: Latent Chain-of-Thought (Latent-CoT) aims to enable step-by-step computation without emitting long rationales, yet its mechanisms remain unclear. We study CODI, a continuous-thought teacher-student distillation model, on strictly sequential polynomial-iteration tasks. Using logit-lens decoding, linear probes, attention analysis, and activation patching, we localize intermediate-state representations and trace their routing to the final readout. On two- and three-hop tasks, CODI forms the full set of bridge states that become decodable across latent-thought positions, while the final input follows a separate near-direct route; predictions arise via late fusion at the end-of-thought boundary. For longer hop lengths, CODI does not reliably execute a full latent rollout, instead exhibiting a partial latent reasoning path that concentrates on late intermediates and fuses them with the last input at the answer readout position. Ablations show that this partial pathway can collapse under regime shifts, including harder optimization. Overall, we delineate when CODI-style latent-CoT yields faithful iterative computation versus compressed or shortcut strategies, and highlight challenges in designing robust latent-CoT objectives for sequential reasoning.

</details>


### [16] [Cross-Modal Memory Compression for Efficient Multi-Agent Debate](https://arxiv.org/abs/2602.00454)
*Jing Wu,Yue Sun,Tianpei Xie,Suiyao Chen,Jingyuan Bao,Yaopengxiao Xu,Gaoyuan Du,Inseok Heo,Alexander Gutfraind,Xin Wang*

Main category: cs.AI

TL;DR: 提出了一种名为 DebateOCR 的跨模态压缩框架，将多智能体辩论中冗长的文本历史压缩成紧凑的图像表示，显著减少了 token 使用量、计算成本和推理时间，同时保持了信息的可恢复性。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体辩论方法会因对话轮次和智能体数量的增加而产生大量的文本上下文，导致 token 使用量超出限制，并需要耗时且可能丢失信息的摘要过程。

Method: 开发了 DebateOCR 框架，该框架利用跨模态压缩技术，将辩论的文本历史转换为图像表示，并通过专门的视觉编码器处理，以适应后续的辩论轮次。还提供了理论分析，证明了智能体多样性有助于恢复被压缩信息。

Result:  DebateOCR 将输入 token 量减少了 92% 以上，显著降低了计算成本和推理速度。在多个基准测试中表现优异。

Conclusion:  DebateOCR 是一种有效的跨模态压缩框架，能够大幅提高多智能体辩论的效率和可扩展性，同时通过智能体多样性保证了信息的有效恢复。

Abstract: Multi-agent debate can improve reasoning quality and reduce hallucinations, but it incurs rapidly growing context as debate rounds and agent count increase. Retaining full textual histories leads to token usage that can exceed context limits and often requires repeated summarization, adding overhead and compounding information loss. We introduce DebateOCR, a cross-modal compression framework that replaces long textual debate traces with compact image representations, which are then consumed through a dedicated vision encoder to condition subsequent rounds. This design compresses histories that commonly span tens to hundreds of thousands of tokens, cutting input tokens by more than 92% and yielding substantially lower compute cost and faster inference across multiple benchmarks. We further provide a theoretical perspective showing that diversity across agents supports recovery of omitted information: although any single compressed history may discard details, aggregating multiple agents' compressed views allows the collective representation to approach the information bottleneck with exponentially high probability.

</details>


### [17] [Benchmarking Agents in Insurance Underwriting Environments](https://arxiv.org/abs/2602.00456)
*Amanda Dsouza,Ramya Ramakrishnan,Charles Dickens,Bhavishya Pohani,Christopher M Glaze*

Main category: cs.AI

TL;DR: 本文提出了 UNDERWRITE，一个与领域专家合作设计的、包含真实世界企业挑战（如专有知识、嘈杂工具接口、模拟用户）的多轮保险承保基准测试。测试结果显示，现有前沿模型在企业应用中表现出效率与准确性的权衡、领域知识幻觉以及性能下降的问题，强调了专家参与基准设计和开发更鲁棒的幻觉检测方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理评估基准测试未能充分反映企业级应用中真实操作的复杂性，过于侧重开放领域、使用狭窄的准确性指标，且缺乏真实复杂性。研究旨在开发一个更符合企业部署需求的基准测试。

Method: 与领域专家紧密合作，设计了一个名为UNDERWRITE的多轮保险承保基准测试。该基准测试引入了专有业务知识、嘈杂的工具接口和需要仔细信息收集的不完美模拟用户等关键的现实主义因素。然后，使用该基准测试对13个前沿模型进行了评估。

Result: 评估结果显示，在企业就绪性方面，前沿模型存在显著差距：最准确的模型并非最高效；模型在拥有工具访问权限的情况下仍会出现领域知识幻觉；pass^k结果显示性能下降20%。

Conclusion: 专家参与基准设计对于代理的真实评估至关重要；常见的代理框架表现出脆弱性，会扭曲性能报告；专业领域的幻觉检测需要组合式方法。这项工作为开发更符合企业部署要求的基准测试提供了见解。

Abstract: As AI agents integrate into enterprise applications, their evaluation demands benchmarks that reflect the complexity of real-world operations. Instead, existing benchmarks overemphasize open-domains such as code, use narrow accuracy metrics, and lack authentic complexity. We present UNDERWRITE, an expert-first, multi-turn insurance underwriting benchmark designed in close collaboration with domain experts to capture real-world enterprise challenges. UNDERWRITE introduces critical realism factors often absent in current benchmarks: proprietary business knowledge, noisy tool interfaces, and imperfect simulated users requiring careful information gathering. Evaluating 13 frontier models, we uncover significant gaps between research lab performance and enterprise readiness: the most accurate models are not the most efficient, models hallucinate domain knowledge despite tool access, and pass^k results show a 20% drop in performance. The results from UNDERWRITE demonstrate that expert involvement in benchmark design is essential for realistic agent evaluation, common agentic frameworks exhibit brittleness that skews performance reporting, and hallucination detection in specialized domains demands compositional approaches. Our work provides insights for developing benchmarks that better align with enterprise deployment requirements.

</details>


### [18] [Dual Latent Memory for Visual Multi-agent System](https://arxiv.org/abs/2602.00471)
*Xinlei Yu,Chengming Xu,Zhangquan Chen,Bo Yin,Cheng Yang,Yongbo He,Yihao Hu,Jiangning Zhang,Cheng Tan,Xiaobin Hu,Shuicheng Yan*

Main category: cs.AI

TL;DR: 提出了一种名为 L²-VMAS 的新框架，通过使用双重潜在记忆和主动信息触发机制，有效解决了视觉多智能体系统（VMAS）中存在的“扩展瓶颈”问题，提高了性能并显著降低了通信成本。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉多智能体系统（VMAS）在增加智能体数量或回合数时，性能反而下降，且计算成本急剧升高，这是由于文本中心通信的信息瓶颈导致的感知和思维信息损失。研究者希望解决这一问题。

Method: 提出了 L²-VMAS 模型，该模型具备以下特点：1. 模型无关的框架；2. 引入双重潜在记忆（dual latent memories）；3. 分离感知与思维过程，并动态合成双重潜在记忆；4. 采用熵驱动的主动触发机制，实现按需访问记忆而非被动传输信息。

Result: 在多个骨干模型、不同模型尺寸和多智能体结构上的广泛实验表明，L²-VMAS 能够有效打破“扩展瓶颈”。与基线模型相比，平均准确率提高了 2.7%-5.4%，同时 token 使用量减少了 21.3%-44.8%。

Conclusion: L²-VMAS 是一种有效的模型无关框架，通过双重潜在记忆和主动触发机制，显著改善了视觉多智能体系统的可扩展性，在提高性能的同时降低了通信成本，成功解决了现有 VMAS 面临的“扩展瓶颈”问题。

Abstract: While Visual Multi-Agent Systems (VMAS) promise to enhance comprehensive abilities through inter-agent collaboration, empirical evidence reveals a counter-intuitive "scaling wall": increasing agent turns often degrades performance while exponentially inflating token costs. We attribute this failure to the information bottleneck inherent in text-centric communication, where converting perceptual and thinking trajectories into discrete natural language inevitably induces semantic loss. To this end, we propose L$^{2}$-VMAS, a novel model-agnostic framework that enables inter-agent collaboration with dual latent memories. Furthermore, we decouple the perception and thinking while dynamically synthesizing dual latent memories. Additionally, we introduce an entropy-driven proactive triggering that replaces passive information transmission with efficient, on-demand memory access. Extensive experiments among backbones, sizes, and multi-agent structures demonstrate that our method effectively breaks the "scaling wall" with superb scalability, improving average accuracy by 2.7-5.4% while reducing token usage by 21.3-44.8%. Codes: https://github.com/YU-deep/L2-VMAS.

</details>


### [19] [Replacing Parameters with Preferences: Federated Alignment of Heterogeneous Vision-Language Models](https://arxiv.org/abs/2602.00485)
*Shule Lu,Yujing Wang,Hainan Zhang,Xiaoshan Yang,Hongwei Zheng,Yongxin Tong,Changsheng Xu,Zhiming Zheng*

Main category: cs.AI

TL;DR: 本文提出了MoR，一个基于GRPO和Mixture-of-Rewards的联邦对齐框架，用于处理异构视觉语言模型（VLMs）。该框架通过在客户端训练局部奖励模型并将这些奖励信号进行路由式融合，然后服务器使用混合奖励进行GRPO优化，以在保护隐私的前提下实现大规模的异构VLMs对齐。


<details>
  <summary>Details</summary>
Motivation: 传统的联邦学习（FL）在处理异构客户端（计算资源、应用需求、模型架构不同）时面临挑战，这限制了其在医疗和金融等隐私敏感领域的应用。作者认为，未来的FL应从“数据->模型参数”转向“模型参数->偏好”，以实现更具可扩展性和隐私保护的训练。

Method: MoR框架首先将一个视觉基础模型初始化为KL正则化的参考模型。然后，每个客户端在其本地偏好标注数据上训练一个奖励模型，以捕捉特定的评估信号。为了处理异构奖励，提出了一种路由式融合机制来聚合客户端的奖励信号。最后，服务器使用该混合奖励对基础VLM进行GRPO优化。

Result: 在三个公开的VQA基准测试上进行的实验表明，MoR在泛化能力、鲁棒性和跨客户端适应性方面，始终优于现有的联邦对齐基线方法。

Conclusion: MoR提供了一种可扩展的解决方案，能够在联邦设置下，以隐私保护的方式对异构的VLMs进行对齐。

Abstract: VLMs have broad potential in privacy-sensitive domains such as healthcare and finance, yet strict data-sharing constraints render centralized training infeasible. FL mitigates this issue by enabling decentralized training, but practical deployments face challenges due to client heterogeneity in computational resources, application requirements, and model architectures. We argue that while replacing data with model parameters characterizes the present of FL, replacing parameters with preferences represents a more scalable and privacy-preserving future. Motivated by this perspective, we propose MoR, a federated alignment framework based on GRPO with Mixture-of-Rewards for heterogeneous VLMs. MoR initializes a visual foundation model as a KL-regularized reference, while each client locally trains a reward model from local preference annotations, capturing specific evaluation signals without exposing raw data. To reconcile heterogeneous rewards, we introduce a routing-based fusion mechanism that adaptively aggregates client reward signals. Finally, the server performs GRPO with this mixed reward to optimize the base VLM. Experiments on three public VQA benchmarks demonstrate that MoR consistently outperforms federated alignment baselines in generalization, robustness, and cross-client adaptability. Our approach provides a scalable solution for privacy-preserving alignment of heterogeneous VLMs under federated settings.

</details>


### [20] [PCBSchemaGen: Constraint-Guided Schematic Design via LLM for Printed Circuit Boards (PCB)](https://arxiv.org/abs/2602.00510)
*Huanghaohe Zou,Peng Han,Emad Nazerian,Alex Q. Huang*

Main category: cs.AI

TL;DR: 提出了一种名为PCBSchemaGen的无训练框架，用于自动化PCB原理图设计，该框架结合了大型语言模型（LLM）智能体和基于约束的合成，并利用知识图谱（KG）进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有PCB设计研究仅关注数字或模拟电路，而忽略了实际PCB设计中数字、模拟和电源信号的异构性以及IC封装和引脚约束。自动化PCB原理图设计因数据稀缺和缺乏基于仿真的验证而未被充分探索。

Method: PCBSchemaGen框架包括两个主要部分：1. 基于LLM的代码生成范式，通过领域特定的提示进行迭代反馈。2. 一个基于真实IC数据手册衍生的知识图谱（KG）的验证框架，利用子图同构编码引脚角色语义和拓扑约束。

Result: 在跨越数字、模拟和电源领域的23个PCB原理图任务上进行了广泛实验，结果表明PCBSchemaGen显著提高了设计准确性和计算效率。

Conclusion: PCBSchemaGen是首个用于PCB原理图设计的无训练框架，它通过LLM智能体和基于约束的合成，并结合KG验证，有效解决了自动化PCB原理图设计的挑战，提高了准确性和效率。

Abstract: Printed Circuit Board (PCB) schematic design plays an essential role in all areas of electronic industries. Unlike prior works that focus on digital or analog circuits alone, PCB design must handle heterogeneous digital, analog, and power signals while adhering to real-world IC packages and pin constraints. Automated PCB schematic design remains unexplored due to the scarcity of open-source data and the absence of simulation-based verification. We introduce PCBSchemaGen, the first training-free framework for PCB schematic design that comprises LLM agent and Constraint-guided synthesis. Our approach makes three contributions: 1. an LLM-based code generation paradigm with iterative feedback with domain-specific prompts. 2. a verification framework leveraging a real-world IC datasheet derived Knowledge Graph (KG) and Subgraph Isomorphism encoding pin-role semantics and topological constraints. 3. an extensive experiment on 23 PCB schematic tasks spanning digital, analog, and power domains. Results demonstrate that PCBSchemaGen significantly improves design accuracy and computational efficiency.

</details>


### [21] [Diagnosing the Reliability of LLM-as-a-Judge via Item Response Theory](https://arxiv.org/abs/2602.00521)
*Junhyuk Choi,Sohhyung Park,Chanhee Cho,Hyeonchu Park,Bugeun Kim*

Main category: cs.AI

TL;DR: 本文提出了一种基于项目反应理论（IRT）的两阶段诊断框架，用于评估LLM-as-a-Judge的可靠性，该框架从内在一致性和人类一致性两个维度进行评估，并证明了IRT-GRM在系统诊断LLM判断中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-Judge的验证方法主要关注输出结果，未能深入了解LLM判断器本身是否稳定可靠，因此需要一种更深入的评估方法。

Method: 引入一个两阶段的诊断框架，借鉴IRT的Graded Response Model (GRM)，从“内在一致性”（prompt变化下的稳定性）和“人类一致性”（与人类评估的一致性）两个维度评估LLM-as-a-Judge的可靠性。

Result: 通过实证研究，表明使用IRT-GRM可以系统地诊断LLM判断器的可靠性，并提供可解释的信号，有助于识别不可靠性的潜在原因。

Conclusion: 所提出的基于IRT-GRM的诊断框架能够有效地评估LLM-as-a-Judge的内在一致性和人类一致性，为验证其可靠性提供实用的指导。

Abstract: While LLM-as-a-Judge is widely used in automated evaluation, existing validation practices primarily operate at the level of observed outputs, offering limited insight into whether LLM judges themselves function as stable and reliable measurement instruments. To address this limitation, we introduce a two-phase diagnostic framework for assessing reliability of LLM-as-a-Judge, grounded in Item Response Theory (IRT). The framework adopts Graded Response Model (GRM) of IRT and formalizes reliability along two complementary dimensions: (1) intrinsic consistency, defined as the stability of measurement behavior under prompt variations, and (2) human alignment, capturing correspondence with human quality assessments. We empirically examine diverse LLM judges with this framework, and show that leveraging IRT-GRM yields interpretable signals for diagnosing judgments systematically. These signals provide practical guidance for verifying reliablity of LLM-as-a-Judge and identifying potential causes of unreliability.

</details>


### [22] [How Far Are LLMs from Professional Poker Players? Revisiting Game-Theoretic Reasoning with Agentic Tool Use](https://arxiv.org/abs/2602.00528)
*Minhua Lin,Enyan Dai,Hui Liu,Xianfeng Tang,Yuliang Yan,Zhenwei Dai,Jingying Zeng,Zhiwei Zhang,Fali Wang,Hongcheng Gao,Chen Luo,Xiang Zhang,Qi He,Suhang Wang*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）在扑克游戏中存在推理缺陷，表现不如传统算法。本文提出的ToolPoker框架通过整合外部求解器和改进解释，实现了顶尖的游戏水平和符合博弈论的推理。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在关键领域的应用，其在不确定性下的战略推理能力至关重要。扑克作为一个严谨的测试平台，能够检验LLM的游戏理论推理能力。

Method: 通过在多种真实的扑克任务中系统地研究LLM，评估其游戏结果和推理过程。在此基础上，提出了ToolPoker框架，整合了用于实现GTO（Game-Theoretic Optimal）策略的外部求解器，并生成更精确的专业风格解释。

Result: LLM在扑克游戏中表现不如传统算法，存在过度依赖启发式、事实理解错误以及“知行不一”的缺陷。ToolPoker框架在实验中达到了最先进的游戏水平，并生成了更接近博弈论原则的推理过程。

Conclusion: LLM在扑克等复杂战略推理任务中存在显著挑战。ToolPoker框架通过结合外部工具和改进解释，有效弥补了LLM在战略推理上的不足，实现了高水平的游戏表现和理论一致的推理。

Abstract: As Large Language Models (LLMs) are increasingly applied in high-stakes domains, their ability to reason strategically under uncertainty becomes critical. Poker provides a rigorous testbed, requiring not only strong actions but also principled, game-theoretic reasoning. In this paper, we conduct a systematic study of LLMs in multiple realistic poker tasks, evaluating both gameplay outcomes and reasoning traces. Our analysis reveals LLMs fail to compete against traditional algorithms and identifies three recurring flaws: reliance on heuristics, factual misunderstandings, and a "knowing-doing" gap where actions diverge from reasoning. An initial attempt with behavior cloning and step-level reinforcement learning improves reasoning style but remains insufficient for accurate game-theoretic play. Motivated by these limitations, we propose ToolPoker, a tool-integrated reasoning framework that combines external solvers for GTO-consistent actions with more precise professional-style explanations. Experiments demonstrate that ToolPoker achieves state-of-the-art gameplay while producing reasoning traces that closely reflect game-theoretic principles.

</details>


### [23] [Uncovering Latent Communication Patterns in Brain Networks via Adaptive Flow Routing](https://arxiv.org/abs/2602.00561)
*Tianhao Huang,Guanghui Min,Zhenyu Lei,Aiying Zhang,Chen Chen*

Main category: cs.AI

TL;DR: 本文提出了一种名为AFR-Net的自适应流路由网络，通过神经通信动力学来融合结构连接（SC）和功能连接（FC），以揭示潜在的神经通路，并在实验中证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在融合SC和FC时缺乏神经科学的内在洞察，未能解释SC和FC之间耦合与异质性的动态变化，也无法揭示潜在的交互机制。

Method: 将多模态融合置于神经通信动力学的视角下，提出了一种物理信息框架AFR-Net，模拟SC如何产生FC，并可解释地发现关键神经通路。

Result: AFR-Net在实验中显著优于最先进的基线方法。

Conclusion: AFR-Net能够通过模拟神经通信动力学来有效融合SC和FC，并能可解释地发现关键的神经通路，为理解宏观认知现象与微观神经连接的关系提供了新的途径。

Abstract: Unraveling how macroscopic cognitive phenotypes emerge from microscopic neuronal connectivity remains one of the core pursuits of neuroscience. To this end, researchers typically leverage multi-modal information from structural connectivity (SC) and functional connectivity (FC) to complete downstream tasks. Recent methodologies explore the intricate coupling mechanisms between SC and FC, attempting to fuse their representations at the regional level. However, lacking fundamental neuroscientific insight, these approaches fail to uncover the latent interactions between neural regions underlying these connectomes, and thus cannot explain why SC and FC exhibit dynamic states of both coupling and heterogeneity. In this paper, we formulate multi-modal fusion through the lens of neural communication dynamics and propose the Adaptive Flow Routing Network (AFR-Net), a physics-informed framework that models how structural constraints (SC) give rise to functional communication patterns (FC), enabling interpretable discovery of critical neural pathways. Extensive experiments demonstrate that AFR-Net significantly outperforms state-of-the-art baselines. The code is available at https://anonymous.4open.science/r/DIAL-F0D1.

</details>


### [24] [Unmasking Reasoning Processes: A Process-aware Benchmark for Evaluating Structural Mathematical Reasoning in LLMs](https://arxiv.org/abs/2602.00564)
*Xiang Zheng,Weiqi Zhai,Wei Wang,Boyu Yang,Wenbo Li,Ruixiang Luo,Haoxiang Sun,Yucheng Wang,Zhengze Li,Meng Wang,Yuetian Du,Guojie Lin,Yaxuan Wang,Xiaoxiao Xu,Yanhu Mo,Xuan Ren,Hu Wei,Ze Xu*

Main category: cs.AI

TL;DR: 本文提出了一个名为 ReasoningMath-Plus 的新数学推理基准，旨在评估 LLM 在多约束协调、逻辑综合和空间推理等方面的结构性推理能力。研究发现，现有 LLM 在回答准确率上表现良好，但采用 HCRS 和 PRM 等过程级评估方法时，其真正的推理能力被高估了。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据集的模板化和浅层计算导致 LLM 在成熟基准上达到近乎饱和的准确率，这引发了对其真实推理能力诊断的担忧。现有数据集未能充分代表多约束协调、构建性逻辑综合和空间推理等重要的推理技能。

Method: 作者构建了一个包含 150 个精心设计的数学问题的 ReasoningMath-Plus 基准，这些问题专注于评估结构性推理，并带有最小化的推理骨架以支持过程级评估。此外，还引入了一个确定性的步进式评分函数 HCRS（Hazard-aware Chain-based Rule Score），并使用标注的推理轨迹训练了一个过程奖励模型 PRM。

Result: 在 ReasoningMath-Plus 基准上，领先的 LLM 在最终答案准确率上得分较高（最高 5.8/10），但使用 HCRS 进行的整体评估得分显著较低（平均 4.36/10，最佳 5.14/10）。这表明仅依靠答案准确率的指标会高估 LLM 的推理鲁棒性。

Conclusion: 现有的 LLM 在数学推理任务上，尤其是在结构性推理方面，存在过度拟合问题，其真实的推理能力被答案准确率指标所掩盖。ReasoningMath-Plus 和 HCRS/PRM 等过程级评估方法能更准确地衡量 LLM 的推理能力。

Abstract: Recent large language models (LLMs) achieve near-saturation accuracy on many established mathematical reasoning benchmarks, raising concerns about their ability to diagnose genuine reasoning competence. This saturation largely stems from the dominance of template-based computation and shallow arithmetic decomposition in existing datasets, which underrepresent reasoning skills such as multi-constraint coordination, constructive logical synthesis, and spatial inference. To address this gap, we introduce ReasoningMath-Plus, a benchmark of 150 carefully curated problems explicitly designed to evaluate structural reasoning. Each problem emphasizes reasoning under interacting constraints, constructive solution formation, or non-trivial structural insight, and is annotated with a minimal reasoning skeleton to support fine-grained process-level evaluation. Alongside the dataset, we introduce HCRS (Hazard-aware Chain-based Rule Score), a deterministic step-level scoring function, and train a Process Reward Model (PRM) on the annotated reasoning traces. Empirically, while leading models attain relatively high final-answer accuracy (up to 5.8/10), HCRS-based holistic evaluation yields substantially lower scores (average 4.36/10, best 5.14/10), showing that answer-only metrics can overestimate reasoning robustness.

</details>


### [25] [Learning Modal-Mixed Chain-of-Thought Reasoning with Latent Embeddings](https://arxiv.org/abs/2602.00574)
*Yifei Shao,Kun Zhou,Ziming Xu,Mohammad Atif Quamar,Shibo Hao,Zhen Wang,Zhiting Hu,Biwei Huang*

Main category: cs.AI

TL;DR: 提出了一种模态混合思维链（modal-mixed CoT），通过将文本信息与视觉草图（表示为潜在嵌入）相结合，来增强多模态推理能力，并设计了一种两阶段训练方法（监督微调和强化学习）来有效融合视觉和文本信息。


<details>
  <summary>Details</summary>
Motivation: 现有的思维链（CoT）方法主要局限于文本，难以处理需要视觉信息的复杂推理问题，因为关键的中间推理步骤往往是视觉性质的。

Method: 提出模态混合思维链（modal-mixed CoT），将文本标记与以潜在嵌入形式表示的视觉草图交错。使用VLM作为编码器，训练语言骨干网络重构其自身的中间视觉嵌入，以实现语义对齐。引入一个基于扩散的潜在解码器，由特殊控制标记激活，并以VLM的隐藏状态为条件。训练分为两个阶段：1）监督微调，使用交错文本和潜在嵌入的轨迹，并采用联合下一词和潜在重构目标；2）强化学习，训练模型何时切换模态以及如何构建长推理链。

Result: 在11个多模态推理任务上的广泛实验表明，所提出的方法优于纯语言CoT方法和其他CoT方法。

Conclusion: 模态混合思维链是一种有效的方法，可以扩展思维链推理到多模态领域，通过将视觉草图与文本推理相结合，显著提高了多模态推理的性能。

Abstract: We study how to extend chain-of-thought (CoT) beyond language to better handle multimodal reasoning. While CoT helps LLMs and VLMs articulate intermediate steps, its text-only form often fails on vision-intensive problems where key intermediate states are inherently visual. We introduce modal-mixed CoT, which interleaves textual tokens with compact visual sketches represented as latent embeddings. To bridge the modality gap without eroding the original knowledge and capability of the VLM, we use the VLM itself as an encoder and train the language backbone to reconstruct its own intermediate vision embeddings, to guarantee the semantic alignment of the visual latent space. We further attach a diffusion-based latent decoder, invoked by a special control token and conditioned on hidden states from the VLM. In this way, the diffusion head carries fine-grained perceptual details while the VLM specifies high-level intent, which cleanly disentangles roles and reduces the optimization pressure of the VLM. Training proceeds in two stages: supervised fine-tuning on traces that interleave text and latents with a joint next-token and latent-reconstruction objective, followed by reinforcement learning that teaches when to switch modalities and how to compose long reasoning chains. Extensive experiments across 11 diverse multimodal reasoning tasks, demonstrate that our method yields better performance than language-only and other CoT methods. Our code will be publicly released.

</details>


### [26] [Small Shifts, Large Gains: Unlocking Traditional TSP Heuristic Guided-Sampling via Unsupervised Neural Instance Modification](https://arxiv.org/abs/2602.00580)
*Wei Huang,Hanchen Wang,Dong Wen,Wenjie Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为TSP-MDF的框架，通过修改节点坐标来增强传统确定性启发式算法在旅行商问题（TSP）中的探索能力，使其能够生成更高质量的解，并且无需地面真实监督即可高效训练。


<details>
  <summary>Details</summary>
Motivation: 传统的启发式算法虽然计算效率高，但容易陷入局部最优。基于神经网络的算法虽然能生成更好的解，但训练成本高且依赖地面真实监督，不实用。本研究旨在弥合这一差距，让传统启发式算法具备更好的探索能力，同时保持其实用性。

Method: TSP-MDF框架包含一个基于神经网络的实例修改器，它通过策略性地移动节点坐标来生成多个修改后的TSP实例。然后，在这些修改后的实例上应用传统的确定性启发式算法构建路径。最后，将这些路径映射回原始实例。实例修改器可以在没有地面真实监督的情况下进行训练。

Result: TSP-MDF显著提升了传统启发式算法的性能，生成的解的质量与基于神经网络的启发式算法相当，但训练时间极短。在大型TSP基准和真实世界数据集上的实验证实了这一点。

Conclusion: TSP-MDF成功地将传统确定性启发式算法的计算效率与神经网络的探索能力相结合，提供了一种实用且高效的方法来解决TSP问题，其性能可与先进的神经网络方法媲美，同时避免了高昂的训练成本和地面真实监督的依赖。

Abstract: The Traveling Salesman Problem (TSP) is one of the most representative NP-hard problems in route planning and a long-standing benchmark in combinatorial optimization. Traditional heuristic tour constructors, such as Farthest or Nearest Insertion, are computationally efficient and highly practical, but their deterministic behavior limits exploration and often leads to local optima. In contrast, neural-based heuristic tour constructors alleviate this issue through guided-sampling and typically achieve superior solution quality, but at the cost of extensive training and reliance on ground-truth supervision, hindering their practical use. To bridge this gap, we propose TSP-MDF, a novel instance modification framework that equips traditional deterministic heuristic tour constructors with guided-sampling capability. Specifically, TSP-MDF introduces a neural-based instance modifier that strategically shifts node coordinates to sample multiple modified instances, on which the base traditional heuristic tour constructor constructs tours that are mapped back to the original instance, allowing traditional tour constructors to explore higher-quality tours and escape local optima. At the same time, benefiting from our instance modification formulation, the neural-based instance modifier can be trained efficiently without any ground-truth supervision, ensuring the framework maintains practicality. Extensive experiments on large-scale TSP benchmarks and real-world benchmarks demonstrate that TSP-MDF significantly improves the performance of traditional heuristics tour constructors, achieving solution quality comparable to neural-based heuristic tour constructors, but with an extremely short training time.

</details>


### [27] [Exploring Information Seeking Agent Consolidation](https://arxiv.org/abs/2602.00585)
*Guochen Yan,Jialong Wu,Zhengwei Tao,Bo Li,Qintong Zhang,Jiahao Xu,Haitao Mi,Yuejian Fang,Qingni Shen,Wentao Zhang,Zhonghai Wu*

Main category: cs.AI

TL;DR: 本文研究如何将异构的信息检索智能体整合到一个单一的基础智能体模型中，并提出了数据层面和参数层面的两种整合策略。


<details>
  <summary>Details</summary>
Motivation: 现有的信息检索智能体通常针对特定领域（如开放网络、文档或本地知识库），这限制了其可扩展性和跨领域泛化能力。为了克服这些限制，需要一种能够整合不同信息检索智能体的方法。

Method: 研究了两种信息检索智能体整合策略：1. 数据层面整合：在混合的领域特定数据集上联合训练一个统一模型。2. 参数层面整合：在参数层面合并独立训练的智能体模型。通过比较这两种方法在性能保持、跨领域泛化和信息检索行为间的干扰方面的表现来进行分析。

Result: 数据层面整合是一种稳定且表现良好的基线方法。参数层面整合提供了一种有前景且高效的替代方案，但存在干扰和鲁棒性方面的挑战。研究还确定了参数层面有效智能体整合的关键设计因素，包括精细的合并粒度、对任务异质性的认知以及原则性的共识策略。

Conclusion: 数据层面整合是当前整合信息检索智能体的可靠方法，而参数层面整合具有潜力但需要克服干扰和鲁棒性问题。通过细化合并粒度、考虑任务异质性和采用原则性共识策略，可以提高参数层面整合的有效性。

Abstract: Information-seeking agents have emerged as a powerful paradigm for solving knowledge-intensive tasks. Existing information-seeking agents are typically specialized for open web, documents, or local knowledge bases, which constrains scalability and cross-domain generalization. In this work, we investigate how to consolidate heterogeneous information-seeking agents into a single foundation agentic model. We study two complementary consolidation strategies: data-level consolidation, which jointly trains a unified model on a mixture of domain-specific datasets, and parameter-level consolidation, which merges independently trained agent models at the parameter level. Our analysis compares these approaches in terms of performance retention, cross-domain generalization, and interference across information-seeking behaviors. Our results show that data-level consolidation remains a strong and stable baseline, while parameter-level consolidation offers a promising, efficient alternative but suffers from interference and robustness challenges. We further identify key design factors for effective agent consolidation at the parameter level, including fine-grained merging granularity, awareness of task heterogeneity, and principled consensus strategy.

</details>


### [28] [DockSmith: Scaling Reliable Coding Environments via an Agentic Docker Builder](https://arxiv.org/abs/2602.00592)
*Jiaran Zhang,Luck Ma,Yanhao Li,Fanqi Wan,Di Qi,Xu Zhao,Jieyi Hou,Zhe Xie,Mengqiang Ren,Xin Wu,Zhewei Huang,Liangyu Chen,Yingwei Ma,Qi Han,Xiangyu Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为DockSmith的专用代理Docker构建器，用于解决软件工程智能体执行为基础的训练和评估中可靠地构建Docker环境的瓶颈问题。DockSmith将环境构建视为一种核心代理能力，能够进行长周期工具使用、依赖推理和故障恢复，并能在Docker构建之外迁移其学习到的监督能力。


<details>
  <summary>Details</summary>
Motivation: 在构建和评估软件工程智能体时，可靠地构建Docker环境是一个主要的瓶颈。本文旨在通过开发一个专门的代理Docker构建器来解决这一挑战。

Method: DockSmith被设计成一种代理，能够执行长周期的工具使用、依赖推理和故障恢复，以构建Docker环境。它在一个大规模的、基于执行的Docker构建轨迹数据集上进行训练，该数据集由一个SWE-Factory风格的流水线生成，并辅以一个循环检测控制器和一个跨任务成功记忆。

Result: 使用30B-A3B模型在训练数据集上进行训练后，DockSmith在Multi-Docker-Eval上取得了开源的最先进性能，其“失败到通过”（Fail-to-Pass）率为39.72%，提交率（Commit Rate）为58.28%。此外，DockSmith在SWE-bench Verified、SWE-bench Multilingual和Terminal-Bench 2.0等分布外数据集上提高了性能。

Conclusion: DockSmith成功地将Docker环境构建作为一个核心代理能力来处理，通过长周期的工具使用、依赖推理和故障恢复，不仅解决了Docker构建的瓶颈，还展现了更广泛的代理能力，并在多个评估基准上取得了优异的性能，证明了环境构建对代理的广泛益处。

Abstract: Reliable Docker-based environment construction is a dominant bottleneck for scaling execution-grounded training and evaluation of software engineering agents. We introduce DockSmith, a specialized agentic Docker builder designed to address this challenge. DockSmith treats environment construction not only as a preprocessing step, but as a core agentic capability that exercises long-horizon tool use, dependency reasoning, and failure recovery, yielding supervision that transfers beyond Docker building itself. DockSmith is trained on large-scale, execution-grounded Docker-building trajectories produced by a SWE-Factory-style pipeline augmented with a loop-detection controller and a cross-task success memory. Training a 30B-A3B model on these trajectories achieves open-source state-of-the-art performance on Multi-Docker-Eval, with 39.72% Fail-to-Pass and 58.28% Commit Rate. Moreover, DockSmith improves out-of-distribution performance on SWE-bench Verified, SWE-bench Multilingual, and Terminal-Bench 2.0, demonstrating broader agentic benefits of environment construction.

</details>


### [29] [Scalable Generative Game Engine: Breaking the Resolution Wall via Hardware-Algorithm Co-Design](https://arxiv.org/abs/2602.00608)
*Wei Zeng,Xuchen Li,Ruili Feng,Zhen Liu,Fengwei An,Jian Zhao*

Main category: cs.AI

TL;DR: 本研究提出了一种硬件-算法协同设计框架，通过异构架构解耦计算密集型世界模型和内存密集型解码器，实现了高分辨率（720x480）实时神经游戏生成，显著提高了像素吞吐量和帧率，解决了“内存墙”问题。


<details>
  <summary>Details</summary>
Motivation: 现有实时生成式游戏引擎受限于“内存墙”，难以支持高分辨率的实际应用。本研究旨在弥合生成模型与高分辨率神经模拟之间的差距，实现真正的高保真、响应迅速的神经游戏。

Method: 提出了一种硬件-算法协同设计框架，采用异构架构，将世界模型和解码器解耦部署在AI加速器集群上。具体创新包括：1. 非对称资源分配策略，优化序列并行下的吞吐量；2. 以内存为中心的算子融合，减少片外带宽使用；3. 流形感知潜在外插机制，利用时间冗余隐藏延迟。

Result: 在AI加速器集群上实现了720x480分辨率的实时生成，像素吞吐量比现有基线提高了50倍。在3D赛车游戏中达到26.4 FPS，在2D平台游戏中达到48.3 FPS，平均有效延迟为2.7毫秒。

Conclusion: 通过架构协同设计解决“内存墙”是实现高保真、响应迅速的神经游戏的关键，而非仅仅是优化。

Abstract: Real-time generative game engines represent a paradigm shift in interactive simulation, promising to replace traditional graphics pipelines with neural world models. However, existing approaches are fundamentally constrained by the ``Memory Wall,'' restricting practical deployments to low resolutions (e.g., $64 \times 64$). This paper bridges the gap between generative models and high-resolution neural simulations by introducing a scalable \textit{Hardware-Algorithm Co-Design} framework. We identify that high-resolution generation suffers from a critical resource mismatch: the World Model is compute-bound while the Decoder is memory-bound. To address this, we propose a heterogeneous architecture that intelligently decouples these components across a cluster of AI accelerators. Our system features three core innovations: (1) an asymmetric resource allocation strategy that optimizes throughput under sequence parallelism constraints; (2) a memory-centric operator fusion scheme that minimizes off-chip bandwidth usage; and (3) a manifold-aware latent extrapolation mechanism that exploits temporal redundancy to mask latency. We validate our approach on a cluster of programmable AI accelerators, enabling real-time generation at $720 \times 480$ resolution -- a $50\times$ increase in pixel throughput over prior baselines. Evaluated on both continuous 3D racing and discrete 2D platformer benchmarks, our system delivers fluid 26.4 FPS and 48.3 FPS respectively, with an amortized effective latency of 2.7 ms. This work demonstrates that resolving the ``Memory Wall'' via architectural co-design is not merely an optimization, but a prerequisite for enabling high-fidelity, responsive neural gameplay.

</details>


### [30] [Structured Self-Consistency:A Multi-Task Evaluation of LLMs on VirtualHome](https://arxiv.org/abs/2602.00611)
*Jiaqi Xu,Tao Huang,Kai Zhang*

Main category: cs.AI

TL;DR: 该论文在VirtualHome基准上对两种7B参数的大型语言模型（LLMs），OPENPANGU-7B和QWEN2.5-7B，进行了全面的评估，重点关注了目标理解、动作排序、子目标分解和状态转移建模。研究提出了一种名为结构化自洽（SSC）的增强解码策略，并通过实验证明了其在提高结构化生成任务输出质量方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 评估现有的大型语言模型（LLMs）在具身AI任务中的能力，并探索提高其在结构化生成任务中表现的方法，以期为未来具身AI系统的开发提供见解。

Method: 在VirtualHome基准上，使用Emboded Agent Interface (EAI)框架，对OPENPANGU-7B和QWEN2.5-7B两个7B参数的模型进行评估。研究了目标理解、动作排序、子目标分解和状态转移建模四个基本任务。提出并采用了结构化自洽（SSC）解码策略，该策略结合了多重采样和领域特定的投票机制。

Result: SSC策略显著提高了模型在结构化生成任务上的表现。在具体模型方面，OPENPANGU-7B在分层规划任务上表现更优，而QWEN2.5-7B在动作层面任务上显示出优势。研究还揭示了不同模型类型之间的互补优势。

Conclusion: 大型语言模型在具身AI任务中展现出潜力，但不同模型在不同任务类型上存在差异。结构化自洽（SSC）是一种有效的策略，可以增强LLMs在具身AI中的结构化生成能力。未来具身AI系统的开发应考虑模型之间的互补性。

Abstract: Embodied AI requires agents to understand goals, plan actions, and execute tasks in simulated environments.We present a comprehensive evaluation of Large Language Models (LLMs) on the VirtualHome benchmark using the Embodied Agent Interface (EAI) framework.We compare two representative 7B-parameter models OPENPANGU-7B and QWEN2.5-7B across four fundamental tasks: Goal Interpretation, Action Sequencing, Subgoal Decomposition, and Transition Modeling.We propose Structured Self-Consistency (SSC), an enhanced decoding strategy that leverages multiple sampling with domain-specific voting mechanisms to improve output quality for structured generation tasks. Experimental results demonstrate that SSC significantly enhances performance, with OPENPANGU-7B excelling at hierarchical planning while QWEN2.5-7B show advantages in action-level tasks. Our analysis reveals complementary strengths across model types, providing insights for future embodied AI system development.

</details>


### [31] [Inference-Only Prompt Projection for Safe Text-to-Image Generation with TV Guarantees](https://arxiv.org/abs/2602.00616)
*Minhyuk Lee,Hyekyung Yoon,Myungjoo Kang*

Main category: cs.AI

TL;DR: 提出一种名为SPAT的推理时安全提示投影框架，旨在解决文本到图像扩散模型在抑制不安全生成的同时保持提示-图像一致性的挑战。该方法通过总变差（TV）视角分析安全性和对齐性之间的权衡，并通过代理目标和验证来修改高风险提示，从而在不重新训练模型的情况下提高安全性并保持对齐性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在部署时面临安全生成和提示-图像对齐之间不可避免的权衡。需要一种方法来在不牺牲对齐性的情况下减少不安全生成。

Method: 提出一种推理时（inference-only）的提示投影框架，该框架基于总变差（TV）损失来分析安全性和对齐性之间的权衡（SPAT）。通过一个代理目标和验证机制，对高风险提示进行干预，将其映射到受控的“安全集”中，同时尽量不改变良性提示，且无需重新训练或微调生成器。

Result: 在四个数据集和三种扩散模型上，该方法相对于强模型级对齐基线，在不当内容比例（IP）方面取得了16.7%-60.0%的相对降低，同时在COCO数据集上保持了接近未对齐参考的良性提示-图像对齐。

Conclusion: SPAT框架能够有效地解决文本到图像扩散模型在安全性与对齐性之间的权衡问题，通过推理时干预即可实现显著的安全提升，同时保持良性提示的对齐性。

Abstract: Text-to-Image (T2I) diffusion models enable high-quality open-ended synthesis, but their real-world deployment demands safeguards that suppress unsafe generations without degrading benign prompt-image alignment. We formalize this tension through a total variation (TV) lens: once the reference conditional distribution is fixed, any nontrivial reduction in unsafe generations necessarily incurs TV deviation from the reference, yielding a principled Safety-Prompt Alignment Trade-off (SPAT). Guided by this view, we propose an inference-only prompt projection framework that selectively intervenes on high-risk prompts via a surrogate objective with verification, mapping them into a tolerance-controlled safe set while leaving benign prompts effectively unchanged, without retraining or fine-tuning the generator. Across four datasets and three diffusion backbones, our approach achieves 16.7-60.0% relative reductions in inappropriate percentage (IP) versus strong model-level alignment baselines, while preserving benign prompt-image alignment on COCO near the unaligned reference.

</details>


### [32] [Predictive Maintenance for Ultrafiltration Membranes Using Explainable Similarity-Based Prognostics](https://arxiv.org/abs/2602.00659)
*Qusai Khaled,Laura Genga,Uzay Kaymak*

Main category: cs.AI

TL;DR: 本研究提出了一种基于模糊相似性推理的可解释预测框架，用于估算超滤膜的反渗透脱盐剩余有用寿命（RUL）。该框架利用跨膜压差、通量和阻力等物理信息构建健康指数，并通过模糊化和相似性度量来识别历史退化轨迹，从而生成透明、可解释的RUL预测。


<details>
  <summary>Details</summary>
Motivation: 反渗透脱盐过程中超滤膜易发生污损导致性能下降和停机成本高昂。现有的预测性维护模型因缺乏可解释性，操作员信任度不高，因此需要开发一种可解释的预测框架来提高预测的可靠性和操作员的信任。

Method: 本研究提出了一种基于模糊相似性推理的可解释预测框架。首先，构建了一个基于跨膜压差、通量和阻力的物理信息健康指数来捕捉膜的退化动态。然后，使用高斯隶属函数对健康指数进行模糊化。接着，利用相似性度量识别与当前状态相似的历史退化轨迹，并将RUL预测构建为Takagi-Sugeno模糊规则。每个规则对应一个历史样本，并通过相似性加权来形成透明的RUL估计。

Result: 该框架在工业规模的超滤系统上进行了测试，处理了12,528个运行周期的数据。结果显示，平均绝对误差为4.50个周期，并且生成的规则库与专家理解一致，具有良好的可解释性。

Conclusion: 提出的基于模糊相似性推理的可解释预测框架能够有效且透明地估计超滤膜的剩余有用寿命，为反渗透脱盐系统的预测性维护提供了有力的支持，并能增强操作员的信任。

Abstract: In reverse osmosis desalination, ultrafiltration (UF) membranes degrade due to fouling, leading to performance loss and costly downtime. Most plants rely on scheduled preventive maintenance, since existing predictive maintenance models, often based on opaque machine learning methods, lack interpretability and operator trust. This study proposes an explainable prognostic framework for UF membrane remaining useful life (RUL) estimation using fuzzy similarity reasoning. A physics-informed Health Index, derived from transmembrane pressure, flux, and resistance, captures degradation dynamics, which are then fuzzified via Gaussian membership functions. Using a similarity measure, the model identifies historical degradation trajectories resembling the current state and formulates RUL predictions as Takagi-Sugeno fuzzy rules. Each rule corresponds to a historical exemplar and contributes to a transparent, similarity-weighted RUL estimate. Tested on 12,528 operational cycles from an industrial-scale UF system, the framework achieved a mean absolute error of 4.50 cycles, while generating interpretable rule bases consistent with expert understanding.

</details>


### [33] [SEISMO: Increasing Sample Efficiency in Molecular Optimization with a Trajectory-Aware LLM Agent](https://arxiv.org/abs/2602.00663)
*Fabian P. Krüger,Andrea Hunklinger,Adrian Wolny,Tim J. Adler,Igor Tetko,Santiago David Villalba*

Main category: cs.AI

TL;DR: SEISMO是一个利用大型语言模型（LLM）进行在线分子结构优化的新方法，它能在每次与数据库交互后立即更新模型，无需批量处理，显著提高了优化效率。


<details>
  <summary>Details</summary>
Motivation: 分子结构优化是化学科学（尤其在制药业）中的关键瓶颈，但传统的分子性质评估成本高且耗时。因此，需要一种样本效率极高的分子优化方法。

Method: SEISMO是一个LLM代理，它在推理时进行严格的在线分子优化。该方法将自然语言任务描述、标量分数以及结构化的解释性反馈（如果可用）结合起来，并将每个提议都以前面的所有优化轨迹为条件，并在每次与数据库交互后进行更新，无需进行基于种群或批量的学习。

Result: 在23个任务的“实际分子优化”基准测试中，SEISMO的优化曲线下面积比现有方法高2-3倍，并且通常在50次数据库交互内就能达到接近最优的任务分数。此外，在药物化学任务中，提供解释性反馈能进一步提高优化效率。

Conclusion: SEISMO是一种高效的分子优化方法，尤其在样本效率方面表现出色。通过结合领域知识和结构化信息（如解释性反馈），可以显著提升分子优化的效率。

Abstract: Optimizing the structure of molecules to achieve desired properties is a central bottleneck across the chemical sciences, particularly in the pharmaceutical industry where it underlies the discovery of new drugs. Since molecular property evaluation often relies on costly and rate-limited oracles, such as experimental assays, molecular optimization must be highly sample-efficient. To address this, we introduce SEISMO, an LLM agent that performs strictly online, inference-time molecular optimization, updating after every oracle call without the need for population-based or batched learning. SEISMO conditions each proposal on the full optimization trajectory, combining natural-language task descriptions with scalar scores and, when available, structured explanatory feedback. Across the Practical Molecular Optimization benchmark of 23 tasks, SEISMO achieves a 2-3 times higher area under the optimisation curve than prior methods, often reaching near-maximal task scores within 50 oracle calls. Our additional medicinal-chemistry tasks show that providing explanatory feedback further improves efficiency, demonstrating that leveraging domain knowledge and structured information is key to sample-efficient molecular optimization.

</details>


### [34] [OpenGuanDan: A Large-Scale Imperfect Information Game Benchmark](https://arxiv.org/abs/2602.00676)
*Chao Li,Shangdong Yang,Chiheng Zhan,Zhenxing Ge,Yujing Hu,Bingkun Bao,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: 本文提出了OpenGuanDan，一个用于评估AI在复杂四人策略纸牌游戏（GuanDan）中的表现的新基准。该基准具有信息不完全、决策周期长等挑战，并支持AI与AI以及AI与人类的对抗。实验表明，现有AI虽优于规则AI，但尚未达到超人水平。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在许多领域取得了显著进展，但仍需要更具挑战性的基准来推动深度学习和智能决策研究的发展，尤其是在多智能体复杂博弈场景下。

Method: 构建了OpenGuanDan基准，支持GuanDan游戏的模拟和AI代理的评估。该基准包含不完全信息、大规模状态与动作空间、混合学习目标、长时域决策、可变动作空间和动态队伍组成等特性。提供了独立的玩家API，支持人机交互和与大型语言模型的集成。进行了AI之间以及人机之间的对抗实验。

Result: 在OpenGuanDan基准上，当前基于学习的AI代理相比基于规则的代理表现出显著优势。然而，所有AI代理在与人类专家或顶尖AI玩家的对抗中，均未达到超人水平。

Conclusion: OpenGuanDan是一个有价值的基准，能够有效评估AI在复杂多智能体博弈中的能力。实验结果表明，多智能体智能决策领域仍有巨大的研究空间，需要进一步的研究来提升AI在该类问题上的表现。

Abstract: The advancement of data-driven artificial intelligence (AI), particularly machine learning, heavily depends on large-scale benchmarks. Despite remarkable progress across domains ranging from pattern recognition to intelligent decision-making in recent decades, exemplified by breakthroughs in board games, card games, and electronic sports games, there remains a pressing need for more challenging benchmarks to drive further research. To this end, this paper proposes OpenGuanDan, a novel benchmark that enables both efficient simulation of GuanDan (a popular four-player, multi-round Chinese card game) and comprehensive evaluation of both learning-based and rule-based GuanDan AI agents. OpenGuanDan poses a suite of nontrivial challenges, including imperfect information, large-scale information set and action spaces, a mixed learning objective involving cooperation and competition, long-horizon decision-making, variable action spaces, and dynamic team composition. These characteristics make it a demanding testbed for existing intelligent decision-making methods. Moreover, the independent API for each player allows human-AI interactions and supports integration with large language models. Empirically, we conduct two types of evaluations: (1) pairwise competitions among all GuanDan AI agents, and (2) human-AI matchups. Experimental results demonstrate that while current learning-based agents substantially outperform rule-based counterparts, they still fall short of achieving superhuman performance, underscoring the need for continued research in multi-agent intelligent decision-making domain. The project is publicly available at https://github.com/GameAI-NJUPT/OpenGuanDan.

</details>


### [35] [HumanStudy-Bench: Towards AI Agent Design for Participant Simulation](https://arxiv.org/abs/2602.00685)
*Xuan Liu,Haoyang Shang,Zizhang Liu,Xinyan Liu,Yunze Xiao,Yiwen Tu,Haojian Jin*

Main category: cs.AI

TL;DR: 本文提出了HUMANSTUDY-BENCH，一个用于评估大型语言模型（LLMs）作为社会科学实验模拟参与者的新基准和执行引擎。它将LLM行为视为一个代理设计问题，通过“过滤-提取-执行-评估”流程重现人类实验，并引入新指标量化人与模型行为的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有研究将基础模型能力与实验设置混淆，无法区分LLM行为是模型本身还是其配置引起的。研究者希望精确评估LLM作为模拟参与者的能力，并量化其行为与人类参与者的一致性。

Method: 提出将参与者模拟视为代理设计问题，代理由基础模型和编码行为假设的规范定义。开发HUMANSTUDY-BENCH，包含一个“过滤-提取-执行-评估”流程，用于重现人类实验。该引擎在共享运行时环境中执行实验序列并运行原始分析管道，以保留原始统计程序。引入新指标量化人类和代理行为的一致性。

Result: 在HUMANSTUDY-BENCH中，作者复现了12项基础研究，涵盖个体认知、策略互动和社会心理学，总计超过6000个试验，涉及数千名人类参与者。通过新指标评估了LLM模拟的保真度。

Conclusion: HUMANSTUDY-BENCH提供了一个评估LLM作为社会科学实验模拟参与者的新框架，能够区分模型能力和实验设置的影响，并量化模拟的科学推理保真度。通过复现多项基础研究，证明了该基准的有效性。

Abstract: Large language models (LLMs) are increasingly used as simulated participants in social science experiments, but their behavior is often unstable and highly sensitive to design choices. Prior evaluations frequently conflate base-model capabilities with experimental instantiation, obscuring whether outcomes reflect the model itself or the agent setup. We instead frame participant simulation as an agent-design problem over full experimental protocols, where an agent is defined by a base model and a specification (e.g., participant attributes) that encodes behavioral assumptions. We introduce HUMANSTUDY-BENCH, a benchmark and execution engine that orchestrates LLM-based agents to reconstruct published human-subject experiments via a Filter--Extract--Execute--Evaluate pipeline, replaying trial sequences and running the original analysis pipeline in a shared runtime that preserves the original statistical procedures end to end. To evaluate fidelity at the level of scientific inference, we propose new metrics to quantify how much human and agent behaviors agree. We instantiate 12 foundational studies as an initial suite in this dynamic benchmark, spanning individual cognition, strategic interaction, and social psychology, and covering more than 6,000 trials with human samples ranging from tens to over 2,100 participants.

</details>


### [36] [From Prompt to Graph: Comparing LLM-Based Information Extraction Strategies in Domain-Specific Ontology Development](https://arxiv.org/abs/2602.00699)
*Xuan Liu,Ziyu Li,Mu He,Ziyang Ma,Xiaoxu Wu,Gizem Yilmaz,Yiyuan Xia,Bingbing Li,He Tan,Jerry Ying Hsi Fuh,Wen Feng Lu,Anders E. W. Jarfors,Per Jansson*

Main category: cs.AI

TL;DR: 研究了三种基于大语言模型（LLM）的方法（预训练LLM驱动、上下文学习ICL、微调）来从有限的铸造领域特定文本中提取术语和关系，并使用最佳方法构建了一个经过领域专家验证的铸造本体。


<details>
  <summary>Details</summary>
Motivation: 传统本体构建过程耗时且成本高，尤其是在铸造制造等专业领域，而大语言模型（LLMs）的出现为自动化知识提取提供了新的可能性。

Method: 本文研究了三种基于LLM的方法：预训练LLM驱动方法、上下文学习（ICL）方法和微调方法，用于从领域特定文本中提取术语和关系，并比较了它们的性能。随后，将表现最佳的方法应用于构建铸造本体。

Result: 比较了三种LLM方法的性能，并选择了表现最佳的方法来构建铸造本体。

Conclusion: 基于LLM的方法能够有效地从有限的领域特定文本中提取知识，并可以用于构建专业领域本体，且该方法构建的本体得到了领域专家的验证。

Abstract: Ontologies are essential for structuring domain knowledge, improving accessibility, sharing, and reuse. However, traditional ontology construction relies on manual annotation and conventional natural language processing (NLP) techniques, making the process labour-intensive and costly, especially in specialised fields like casting manufacturing. The rise of Large Language Models (LLMs) offers new possibilities for automating knowledge extraction. This study investigates three LLM-based approaches, including pre-trained LLM-driven method, in-context learning (ICL) method and fine-tuning method to extract terms and relations from domain-specific texts using limited data. We compare their performances and use the best-performing method to build a casting ontology that validated by domian expert.

</details>


### [37] [Self-Guard: Defending Large Reasoning Models via enhanced self-reflection](https://arxiv.org/abs/2602.00707)
*Jingnan Zheng,Jingjun Xu,Yanzhen Luo,Chenhang Cui,Gelei Deng,Zhenkai Liang,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.AI

TL;DR: 本文提出了一种名为Self-Guard的轻量级安全防御框架，用于增强大型推理模型（LRMs）的安全合规性，通过安全导向的提示和激活来弥合模型对风险的认知与其服从指令的倾向之间的差距，同时不牺牲模型效用，并表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LRMs的对齐策略（如训练后调整或外部干预）计算成本高昂，且未能解决“意识-合规差距”，即模型虽然认识到风险但倾向于优先遵循用户指令（谄媚性）。

Method: Self-Guard框架包括两个阶段：1.安全导向提示：激活模型的潜在安全意识，引发自主反思。2.安全激活引导：提取隐藏状态空间的定向变化并放大，以确保安全合规性优先于谄媚性。

Result: Self-Guard有效弥合了意识-合规差距，实现了稳健的安全性能，且不影响模型效用。它在面对各种未知的风险和不同模型规模时，均表现出强大的泛化能力。

Conclusion: Self-Guard是一种成本效益高的LRMs安全对齐解决方案，能够有效增强模型的安全性，同时保持其原有功能，并且具有良好的泛化性。

Abstract: The emergence of Large Reasoning Models (LRMs) introduces a new paradigm of explicit reasoning, enabling remarkable advances yet posing unique risks such as reasoning manipulation and information leakage. To mitigate these risks, current alignment strategies predominantly rely on heavy post-training paradigms or external interventions. However, these approaches are often computationally intensive and fail to address the inherent awareness-compliance gap, a critical misalignment where models recognize potential risks yet prioritize following user instructions due to their sycophantic tendencies. To address these limitations, we propose Self-Guard, a lightweight safety defense framework that reinforces safety compliance at the representational level. Self-Guard operates through two principal stages: (1) safety-oriented prompting, which activates the model's latent safety awareness to evoke spontaneous reflection, and (2) safety activation steering, which extracts the resulting directional shift in the hidden state space and amplifies it to ensure that safety compliance prevails over sycophancy during inference. Experiments demonstrate that Self-Guard effectively bridges the awareness-compliance gap, achieving robust safety performance without compromising model utility. Furthermore, Self-Guard exhibits strong generalization across diverse unseen risks and varying model scales, offering a cost-efficient solution for LRM safety alignment.

</details>


### [38] [Physics-informed Diffusion Generation for Geomagnetic Map Interpolation](https://arxiv.org/abs/2602.00709)
*Wenda Li,Tongya Zheng,Kaixuan Chen,Shunyu Liu,Haoze Jiang,Yunzhi Hao,Rui Miao,Zujie Ren,Mingli Song,Hang Shi,Gang Chen*

Main category: cs.AI

TL;DR: 提出了一种名为PDG的物理信息扩散生成框架，用于插值不完整的地磁图，通过物理信息掩码策略和基于克里金原理的物理信息约束来提高插值性能。


<details>
  <summary>Details</summary>
Motivation: 现有的散射数据插值方法未针对地磁图进行优化，导致因检测噪声和物理定律而性能不佳。

Method: 设计了一种物理信息掩码策略，以局部感受野为基础引导扩散生成过程，并结合克里金原理施加物理信息约束，确保结果符合物理定律。

Result: 在四个真实世界数据集上的实验表明，PDG的每个组成部分都具有优越性和有效性。

Conclusion: PDG框架能够有效地插值不完整的地磁图，克服了现有方法的局限性，并在提高插值精度和鲁棒性方面表现出色。

Abstract: Geomagnetic map interpolation aims to infer unobserved geomagnetic data at spatial points, yielding critical applications in navigation and resource exploration. However, existing methods for scattered data interpolation are not specifically designed for geomagnetic maps, which inevitably leads to suboptimal performance due to detection noise and the laws of physics. Therefore, we propose a Physics-informed Diffusion Generation framework~(PDG) to interpolate incomplete geomagnetic maps. First, we design a physics-informed mask strategy to guide the diffusion generation process based on a local receptive field, effectively eliminating noise interference. Second, we impose a physics-informed constraint on the diffusion generation results following the kriging principle of geomagnetic maps, ensuring strict adherence to the laws of physics. Extensive experiments and in-depth analyses on four real-world datasets demonstrate the superiority and effectiveness of each component of PDG.

</details>


### [39] [Learning More from Less: Unlocking Internal Representations for Benchmark Compression](https://arxiv.org/abs/2602.00710)
*Yueqi Zhang,Jin Hu,Shaoxiong Feng,Peiwen Yuan,Xinglin Wang,Yiwei Li,Jiayi Shi,Chuyi Tan,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li*

Main category: cs.AI

TL;DR: 本文提出REPCORE方法，通过对异构模型的隐藏状态进行统一化处理，构建能够精确估计LLM整体表现的代表性子集，克服了现有方法对大量源模型依赖的限制，在少样本情况下也能实现优于基于输岀的方法的评估精度。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）的成本高昂，需要更高效的替代方法。现有方法依赖于从大量源模型的响应模式中估计可靠的项目画像，但在源模型数量少时统计上不稳定，尤其限制了新发布的基准测试。

Method: REPCORE将异构模型的隐藏状态对齐到一个统一的潜在空间，以构建代表性子集（coreset）。利用这些子集进行性能外推，以估计模型的整体表现。

Result: REPCORE仅需约十个源模型即可实现精确的估计精度。在五个基准测试和超过200个模型上的实验表明，REPCORE在排序相关性和估计精度上持续优于基于输出的方法。光谱分析显示，对齐后的表示包含可分离的成分，反映了广泛的响应倾向和任务特定的推理模式。

Conclusion: REPCORE是一种有效的方法，可以通过对齐隐藏状态来构建代表性子集，从而以较低的成本实现对LLMs性能的准确评估，尤其适用于源模型数量有限的场景。

Abstract: The prohibitive cost of evaluating Large Language Models (LLMs) necessitates efficient alternatives to full-scale benchmarking. Prevalent approaches address this by identifying a small coreset of items to approximate full-benchmark performance. However, existing methods must estimate a reliable item profile from response patterns across many source models, which becomes statistically unstable when the source pool is small. This dependency is particularly limiting for newly released benchmarks with minimal historical evaluation data. We argue that discrete correctness labels are a lossy view of the model's decision process and fail to capture information encoded in hidden states. To address this, we introduce REPCORE, which aligns heterogeneous hidden states into a unified latent space to construct representative coresets. Using these subsets for performance extrapolation, REPCORE achieves precise estimation accuracy with as few as ten source models. Experiments on five benchmarks and over 200 models show consistent gains over output-based baselines in ranking correlation and estimation accuracy. Spectral analysis further indicates that the aligned representations contain separable components reflecting broad response tendencies and task-specific reasoning patterns.

</details>


### [40] [Neuro-symbolic AI for Predictive Maintenance (PdM) -- review and recommendations](https://arxiv.org/abs/2602.00731)
*Kyle Hamilton,Ali Intizar*

Main category: cs.AI

TL;DR: 本研究系统回顾了过去五年工业领域预测性维护（PdM）的最新进展，重点关注数据驱动方法（尤其是深度学习）和传统知识型系统。研究发现，数据驱动方法准确性更高但存在数据需求大、泛化性差和缺乏透明度等问题；而传统方法准确性较低且需要持续的人工干预。文章提出，结合深度学习与符号逻辑的混合方法（即神经符号AI）有望克服现有方法的局限性，从而实现更准确、可解释和鲁棒的PdM系统，并探讨了几种神经符号架构在PdM领域的应用。


<details>
  <summary>Details</summary>
Motivation: 工业领域对预测性维护（PdM）的需求日益增长，但现有的数据驱动和知识型方法都存在显著的局限性。研究旨在探索一种能够结合两者的优势，克服各自劣势的新型PdM方法。

Method: 对过去五年工业领域预测性维护（PdM）的文献进行系统性回顾。重点分析了数据驱动方法（如深度学习）和传统知识型系统（基于规则、逻辑或第一性原理）的优缺点。在此基础上，提出了将深度学习与符号逻辑相结合的神经符号AI（Neuro-symbolic AI）方法，并探讨了几种具体的神经符号架构在PdM领域的应用。

Result: 数据驱动方法在准确性方面优于传统知识型系统，但面临对大量标记数据、泛化能力和可解释性的挑战。传统方法准确性较低，且需要持续的人工调整。混合方法结合了两者的优点，但文章认为神经符号AI在准确性、可解释性和鲁棒性方面具有更大的潜力。

Conclusion: 神经符号AI（Neuro-symbolic AI）是一种有前途的预测性维护方法，它将深度学习的模式识别能力与符号逻辑的推理能力相结合，有望解决现有方法的局限性，实现更准确、可解释和鲁棒的PdM系统。文章为理解现代PdM的挑战和神经符号AI的潜力提供了框架和分析。

Abstract: In this document we perform a systematic review the State-of-the-art in Predictive Maintenance (PdM) over the last five years in industrial settings such as commercial buildings, pharmaceutical facilities, or semi-conductor manufacturing. In general, data-driven methods such as those based on deep learning, exhibit higher accuracy than traditional knowledge-based systems. These systems however, are not without significant limitations. The need for large labeled data sets, a lack of generalizibility to new environments (out-of-distribution generalization), and a lack of transparency at inference time are some of the obstacles to adoption in real world environments. In contrast, traditional approaches based on domain expertise in the form of rules, logic or first principles suffer from poor accuracy, many false positives and a need for ongoing expert supervision and manual tuning. While the majority of approaches in recent literature utilize some form of data-driven architecture, there are hybrid systems which also take into account domain specific knowledge. Such hybrid systems have the potential to overcome the weaknesses of either approach on its own while preserving their strengths. We propose taking the hybrid approach even further and integrating deep learning with symbolic logic, or Neuro-symbolic AI, to create more accurate, explainable, interpretable, and robust systems. We describe several neuro-symbolic architectures and examine their strengths and limitations within the PdM domain. We focus specifically on methods which involve the use of sensor data and manually crafted rules as inputs by describing concrete NeSy architectures. In short, this survey outlines the context of modern maintenance, defines key concepts, establishes a generalized framework, reviews current modeling approaches and challenges, and introduces the proposed focus on Neuro-symbolic AI (NESY).

</details>


### [41] [Engineering AI Agents for Clinical Workflows: A Case Study in Architecture,MLOps, and Governance](https://arxiv.org/abs/2602.00751)
*Cláudio Lúcio do Val Lopes,João Marcus Pitta,Fabiano Belém,Gildson Alves,Flávio Vinícius Cruzeiro Martins*

Main category: cs.AI

TL;DR: 本文介绍了一个名为Maria的生产级AI平台，用于初级保健，通过结合清洁架构、事件驱动架构、Agent为核心的MLOps和人机协作治理模式，解决了临床AI系统中可维护性、可靠性和问责制方面的挑战，并提出了一个可用于高风险领域AI系统开发的参考架构。


<details>
  <summary>Details</summary>
Motivation: 目前的临床AI应用往往采用脆弱的、原型驱动的架构，缺乏系统性的监督，导致安全性和问责制出现“责任真空”。作者旨在为构建可信赖、可治理、可靠的临床AI系统提供解决方案。

Method: 作者提出了一个整合了四项工程支柱的协同架构：1. 清洁架构（Clean Architecture）以实现可维护性。2. 事件驱动架构（Event-driven architecture）以实现弹性和可审计性。3. 以Agent作为模块化的核心单元，每个Agent拥有独立的MLOps生命周期。4. 集成人机协作（Human-in-the-Loop）治理模式，作为关键的、事件驱动的数据源进行持续改进。

Result: 作者展示了Maria平台作为一个生产级AI系统在初级保健中的应用，该平台实现了上述架构设计。文章将其作为参考架构，为构建可维护、可扩展、可问责的AI系统提供了实际经验。

Conclusion: 可信赖的临床AI是通过整合清洁架构、事件驱动架构、Agent-MLOps和人机协作治理模型来实现的。Maria平台提供了一个成功的行业案例和参考架构，指导工程师在高风险领域构建健壮、安全且负责任的AI系统。

Abstract: The integration of Artificial Intelligence (AI) into clinical settings presents a software engineering challenge, demanding a shift from isolated models to robust, governable, and reliable systems. However, brittle, prototype-derived architectures often plague industrial applications and a lack of systemic oversight, creating a ``responsibility vacuum'' where safety and accountability are compromised. This paper presents an industry case study of the ``Maria'' platform, a production-grade AI system in primary healthcare that addresses this gap.
  Our central hypothesis is that trustworthy clinical AI is achieved through the holistic integration of four foundational engineering pillars. We present a synergistic architecture that combines Clean Architecture for maintainability with an Event-driven architecture for resilience and auditability. We introduce the Agent as the primary unit of modularity, each possessing its own autonomous MLOps lifecycle. Finally, we show how a Human-in-the-Loop governance model is technically integrated not merely as a safety check, but as a critical, event-driven data source for continuous improvement. We present the platform as a reference architecture, offering practical lessons for engineers building maintainable, scalable, and accountable AI-enabled systems in high-stakes domains.

</details>


### [42] [Environment-Aware Adaptive Pruning with Interleaved Inference Orchestration for Vision-Language-Action Models](https://arxiv.org/abs/2602.00780)
*Yuting Huang,Leilei Ding,Zhipeng Tang,Zenghuan Zhu,Jiajun Deng,Xinrui Lin,Shuo Liu,Haojie Ren,Jianmin Ji,Yanyong Zhang*

Main category: cs.AI

TL;DR: EcoVLA 是一种无需训练、即插即用的自适应稀疏化框架，通过环境感知自适应剪枝（EAP）和交错推理编排（$I^2O$）来解决现有视觉-语言-动作（VLA）模型因参数量大导致推理延迟高的问题，实现了显著的加速效果，且对性能影响极小。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型参数量大，推理延迟高，阻碍了其实时应用。而环境动态变化导致最优稀疏模式也随之改变，静态剪枝缺乏适应性，固定间隔动态剪枝粒度粗且重训开销大。因此需要一种能够适应环境变化、高效的 VLA 加速方法。

Method: 提出 EcoVLA 框架，包含两个部分：1. 环境感知自适应剪枝（EAP）：一种轻量级的通道剪枝方法，利用物理环境的时间一致性来更新稀疏模式。2. 交错推理编排（$I^2O$）：利用 VLA 推理中的 FLOPs 气泡（即计算量未充分利用的时刻）并行调度剪枝，以最小化延迟影响。EcoVLA 支持与其他 VLA 加速方法正交组合。

Result: 在多个 VLA 模型和基准测试中，EcoVLA 实现了最先进的性能。单独使用时，可实现高达 1.60 倍的加速，成功率仅下降 0.4%。与 token pruning 结合使用时，可实现 2.18 倍的加速，性能下降仅为 0.5%。在真实机器人上进行了有效性验证。

Conclusion: EcoVLA 是一种有效的 VLA 模型加速框架，它能够自适应地根据环境变化调整稀疏模式，并且能够与现有加速方法协同工作，在保证性能的前提下显著提高推理速度，为 VLA 模型在现实世界中的部署提供了可行方案。

Abstract: While Vision-Language-Action (VLA) models hold promise in embodied intelligence, their large parameter counts lead to substantial inference latency that hinders real-time manipulation, motivating parameter sparsification. However, as the environment evolves during VLA execution, the optimal sparsity patterns change accordingly. Static pruning lacks the adaptability required for environment dynamics, whereas fixed-interval dynamic layer pruning suffers from coarse granularity and high retraining overheads. To bridge this gap, we propose EcoVLA, a training-free, plug-and-play adaptive pruning framework that supports orthogonal combination with existing VLA acceleration methods. EcoVLA comprises two components: Environment-aware Adaptive Pruning (EAP) and Interleaved Inference Orchestration ($I^2O$). EAP is a lightweight adaptive channel pruning method that incorporates the temporal consistency of the physical environment to update sparsity patterns. $I^2O$ leverages the FLOPs bubbles inherent in VLA inference to schedule the pruning method in parallel, ensuring negligible impact on latency. Evaluated on diverse VLA models and benchmarks, EcoVLA delivers state-of-the-art performance, achieving up to 1.60$\times$ speedup with only a 0.4% drop in success rate, and further reaches 2.18$\times$ speedup with only a 0.5% degradation when combined with token pruning. We further validate the effectiveness of EcoVLA on real-world robots.

</details>


### [43] [World Models as an Intermediary between Agents and the Real World](https://arxiv.org/abs/2602.00785)
*Sherry Yang*

Main category: cs.AI

TL;DR: 本文提出使用世界模型作为大型语言模型（LLM）智能体与真实世界之间的中介，以解决高成本交互环境下的样本效率和离策略学习问题，并展示了其在多个领域的潜力，同时讨论了构建世界模型的挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习训练的LLM智能体在低成本环境中表现出色，但未能有效扩展到物理机器人、ML工程或科学实验等高成本交互的复杂领域，根本瓶颈在于获取奖励信号的成本过高。

Method: 通过将世界模型（作为动力学、奖励和任务分布的模型）作为LLM智能体和真实世界之间的中介，克服高成本行动带来的极端离策略学习和长时序任务的样本效率低下问题。同时，探讨世界模型如何为智能体提供丰富的学习信号。

Result: 世界模型有望为ML工程、计算机使用、机器人和AI for science等领域提供关键且丰富的学习信号，克服高成本交互的限制。

Conclusion: 世界模型是解决高成本交互领域LLM智能体性能瓶颈的关键。文章识别了构建世界模型的挑战，并提出了数据集策展、架构设计、规模化和评估方面的行动建议。

Abstract: Large language model (LLM) agents trained using reinforcement learning has achieved superhuman performance in low-cost environments like games, mathematics, and coding. However, these successes have not translated to complex domains where the cost of interaction is high, such as the physical cost of running robots, the time cost of ML engineering, and the resource cost of scientific experiments. The true bottleneck for achieving the next level of agent performance for these complex and high-cost domains lies in the expense of executing actions to acquire reward signals. To address this gap, this paper argues that we should use world models as an intermediary between agents and the real world. We discuss how world models, viewed as models of dynamics, rewards, and task distributions, can overcome fundamental barriers of high-cost actions such as extreme off-policy learning and sample inefficiency in long-horizon tasks. Moreover, we demonstrate how world models can provide critical and rich learning signals to agents across a broad set of domains, including machine learning engineering, computer use, robotics, and AI for science. Lastly, we identify the challenges of building these world models and propose actionable items along dataset curation, architecture design, scaling, and evaluation of world models.

</details>


### [44] [MissMAC-Bench: Building Solid Benchmark for Missing Modality Issue in Robust Multimodal Affective Computing](https://arxiv.org/abs/2602.00811)
*Ronghao Lin,Honghao Lu,Ruixing Wu,Aolin Xiong,Qinggong Chu,Qiaolin He,Sijie Mai,Haifeng Hu*

Main category: cs.AI

TL;DR: 本研究提出了MissMAC-Bench，一个用于评估多模态情感计算（MAC）在处理缺失模态数据时鲁棒性的基准。该基准通过设定训练时不应有缺失模态且模型应能处理完整和缺失模态两种情况的原则，并结合固定和随机缺失模式的评估协议，旨在促进更通用、更实际的MAC模型发展。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多模态情感计算（MAC）模型在面对数据模态不完整时性能会大幅下降，这是由分布偏移和语义缺陷造成的。这种“缺失模态”的问题阻碍了MAC模型的鲁棒性和实际应用。

Method: 提出了MissMAC-Bench基准，遵循“训练时不应有缺失模态，且单一模型应能处理完整和缺失模态”的原则。该基准整合了固定和随机的缺失模式（数据集和实例级别）的评估协议，并在3个语言模型和4个数据集上进行了广泛实验。

Result: 通过在3个语言模型和4个数据集上的广泛实验，验证了各种MAC方法在处理缺失模态问题上的有效性。

Conclusion: MissMAC-Bench提供了一个系统化的评估框架，能够量化缺失模态对MAC模型的影响，并为发展更鲁棒的多模态情感计算和多媒体数据挖掘提供了坚实的基础。

Abstract: As a knowledge discovery task over heterogeneous data sources, current Multimodal Affective Computing (MAC) heavily rely on the completeness of multiple modalities to accurately understand human's affective state. However, in real-world scenarios, the availability of modality data is often dynamic and uncertain, leading to substantial performance fluctuations due to the distribution shifts and semantic deficiencies of the incomplete multimodal inputs. Known as the missing modality issue, this challenge poses a critical barrier to the robustness and practical deployment of MAC models. To systematically quantify this issue, we introduce MissMAC-Bench, a comprehensive benchmark designed to establish fair and unified evaluation standards from the perspective of cross-modal synergy. Two guiding principles are proposed, including no missing prior during training, and one single model capable of handling both complete and incomplete modality scenarios, thereby ensuring better generalization. Moreover, to bridge the gap between academic research and real-world applications, our benchmark integrates evaluation protocols with both fixed and random missing patterns at the dataset and instance levels. Extensive experiments conducted on 3 widely-used language models across 4 datasets validate the effectiveness of diverse MAC approaches in tackling the missing modality issue. Our benchmark provides a solid foundation for advancing robust multimodal affective computing and promotes the development of multimedia data mining.

</details>


### [45] [Resource-Efficient Reinforcement for Reasoning Large Language Models via Dynamic One-Shot Policy Refinement](https://arxiv.org/abs/2602.00815)
*Yunjian Zhang,Sudong Wang,Yang Li,Peiran Xu,Conghao Zhou,Xiaoyue Ma,Jianing Li,Yao Zhu*

Main category: cs.AI

TL;DR: 本研究提出了一种名为DoPR（Dynamic One-Shot Policy Refinement）的方法，旨在提高大型语言模型（LLMs）在基于可验证奖励的强化学习（RLVR）训练中的数据和计算效率。DoPR通过仅选择单个信息量大的样本进行策略更新，显著降低了训练成本，同时保持了推理的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR框架在训练LLMs进行复杂推理时，需要大量的奖励信号和高昂的计算资源，这限制了其可扩展性和应用范围。因此，研究RLVR中的数据和计算效率问题具有重要意义。

Method: 研究首先建立了解锁推理能力的样本复杂度理论下界，并验证了少量训练样本即可获得良好性能。随后，提出了一种名为DoPR（Dynamic One-Shot Policy Refinement）的策略，该策略结合了不确定性感知和奖励波动性，动态地从每个批次中选择一个信息量最大的样本进行策略更新，以减少模型训练中的样本获取和计算开销。

Result: DoPR方法将模型训练中的rollout成本降低了近一个数量级，同时保持了与现有方法相当的推理准确性。实验证明，在RLVR训练中，使用少量数据即可达到较强的推理能力。

Conclusion: DoPR提供了一种可扩展且资源高效的解决方案，能够显著降低LLMs进行RLVR训练的成本，为推理密集型LLM应用的RL基训练提供了一条更实用、更易于获取的途径。

Abstract: Large language models (LLMs) have exhibited remarkable performance on complex reasoning tasks, with reinforcement learning under verifiable rewards (RLVR) emerging as a principled framework for aligning model behavior with reasoning chains. Despite its promise, RLVR remains prohibitively resource-intensive, requiring extensive reward signals and incurring substantial rollout costs during training. In this work, we revisit the fundamental question of data and compute efficiency in RLVR. We first establish a theoretical lower bound on the sample complexity required to unlock reasoning capabilities, and empirically validate that strong performance can be achieved with a surprisingly small number of training instances. To tackle the computational burden, we propose Dynamic One-Shot Policy Refinement (DoPR), an uncertainty-aware RL strategy that dynamically selects a single informative training sample per batch for policy updates, guided by reward volatility and exploration-driven acquisition. DoPR reduces rollout overhead by nearly an order of magnitude while preserving competitive reasoning accuracy, offering a scalable and resource-efficient solution for LLM post-training. This approach offers a practical path toward more efficient and accessible RL-based training for reasoning-intensive LLM applications.

</details>


### [46] [Optimizing Agentic Reasoning with Retrieval via Synthetic Semantic Information Gain Reward](https://arxiv.org/abs/2602.00845)
*Senkang Hu,Yong Dai,Yuzhi Zhao,Yihang Tao,Yu Guo,Zhengru Fang,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.AI

TL;DR: 本文提出了一种名为InfoReasoner的统一框架，通过合成的语义信息增益奖励来激励大型推理模型（LRMs）进行有效的知识检索，解决了现有方法缺乏密集、原则性奖励信号的挑战。该框架通过不确定性减少重新定义信息增益，并提出了一种无需手动标注即可计算信息增益的输出感知内在估计器，利用双向文本蕴含进行语义聚类。实验证明InfoReasoner在七个问答基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型推理模型（LRMs）虽然可以通过代理推理动态获取外部知识，但在优化检索过程时面临缺乏密集、原则性奖励信号的挑战。

Method: 本文提出了InfoReasoner统一框架，引入合成语义信息增益奖励，将信息增益重新定义为模型信念状态下的不确定性减少。同时，提出了一种输出感知内在估计器，无需人工标注即可计算信息增益，并通过双向文本蕴含进行语义聚类，利用GRPO（Group Relative Policy Optimization）进行模型训练。

Result: 在七个问答基准上，InfoReasoner相较于强大的检索增强基线方法，在准确率上取得了高达5.4%的平均提升。

Conclusion: InfoReasoner提供了一条理论上合理且可扩展的途径，能够通过代理推理进行检索，有效提升了模型的知识获取和推理能力。

Abstract: Agentic reasoning enables large reasoning models (LRMs) to dynamically acquire external knowledge, but yet optimizing the retrieval process remains challenging due to the lack of dense, principled reward signals. In this paper, we introduce InfoReasoner, a unified framework that incentivizes effective information seeking via a synthetic semantic information gain reward. Theoretically, we redefine information gain as uncertainty reduction over the model's belief states, establishing guarantees, including non-negativity, telescoping additivity, and channel monotonicity. Practically, to enable scalable optimization without manual retrieval annotations, we propose an output-aware intrinsic estimator that computes information gain directly from the model's output distributions using semantic clustering via bidirectional textual entailment. This intrinsic reward guides the policy to maximize epistemic progress, enabling efficient training via Group Relative Policy Optimxization (GRPO). Experiments across seven question-answering benchmarks demonstrate that InfoReasoner consistently outperforms strong retrieval-augmented baselines, achieving up to 5.4% average accuracy improvement. Our work provides a theoretically grounded and scalable path toward agentic reasoning with retrieval.

</details>


### [47] [Persuasion Propagation in LLM Agents](https://arxiv.org/abs/2602.00851)
*Hyejun Jeong,Amir Houmansadr,Shlomo Zilberstein,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: 本研究探讨了用户说服如何影响具备对话和自主任务执行能力的AI代理。研究发现，在任务执行期间进行说服效果较弱且不稳定，而提前明确告知代理其信念状态则能显著减少搜索次数和访问的独特来源数量。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理越来越多地结合对话和自主任务执行能力（如编码、网络研究），研究用户说服如何影响这些代理在执行长期任务时的行为变得至关重要。

Method: 研究引入了一个以行为为中心的评估框架，区分了在任务执行期间或之前进行的说服。通过网络研究和编码任务，对比了说服代理、信念预填充代理和中性预填充代理的行为。

Result: 在任务执行期间的说服会引起微弱且不一致的行为变化。然而，当代理的信念状态在任务开始时就被明确指定时，信念预填充代理相比中性预填充代理，平均搜索次数减少了26.9%，访问的独特来源数量减少了16.9%。

Conclusion: 用户说服，即使是在任务执行之前进行的，也能对AI代理的行为产生显著影响。这表明在评估具有代理性质的系统时，行为层面的评估是必要的。

Abstract: Modern AI agents increasingly combine conversational interaction with autonomous task execution, such as coding and web research, raising a natural question: what happens when an agent engaged in long-horizon tasks is subjected to user persuasion? We study how belief-level intervention can influence downstream task behavior, a phenomenon we name \emph{persuasion propagation}. We introduce a behavior-centered evaluation framework that distinguishes between persuasion applied during or prior to task execution. Across web research and coding tasks, we find that on-the-fly persuasion induces weak and inconsistent behavioral effects. In contrast, when the belief state is explicitly specified at task time, belief-prefilled agents conduct on average 26.9\% fewer searches and visit 16.9\% fewer unique sources than neutral-prefilled agents. These results suggest that persuasion, even in prior interaction, can affect the agent's behavior, motivating behavior-level evaluation in agentic systems.

</details>


### [48] [Position: Human-Centric AI Requires a Minimum Viable Level of Human Understanding](https://arxiv.org/abs/2602.00854)
*Fangzhou Lin,Qianwen Ge,Lingyu Xu,Peiran Li,Xiangbo Gao,Shuo Xing,Kazunori Yamada,Ziming Zhang,Haichong Zhang,Zhengzhong Tu*

Main category: cs.AI

TL;DR: 该论文提出“能力-理解鸿沟”概念，描述了AI系统进步导致用户理解能力下降的现象，并引入“认知完整性阈值（CIT）”来界定维持人类监督、自主性和问责制的最低理解水平，并提出一个设计和治理议程。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统能力提升的同时，用户理解和干预能力却在下降，现有的透明度、用户控制、素养和治理方法未能解决这一核心问题，需要新的框架来确保人类在AI辅助下的持续监督和责任。

Method: 论文首先定义了“能力-理解鸿沟”，接着提出了“认知完整性阈值（CIT）”的概念，并通过验证能力、维持理解的交互方式以及治理的制度支撑三个维度对其进行操作化定义，最后基于此提出了设计和治理的议程。

Result: 论文界定了在AI辅助下，为维持人类的监督、自主性和问责制所必需的最低理解水平（CIT），并指出当AI能力超出此阈值时，人类监督将变得程序化，问责机制失效。

Conclusion: 为了应对AI带来的能力-理解鸿沟，需要通过设计和治理策略，确保人类在AI辅助下能够保持足够的认知完整性，从而在责任关键领域实现可持续的人机协作和有效的监督。

Abstract: AI systems increasingly produce fluent, correct, end-to-end outcomes. Over time, this erodes users' ability to explain, verify, or intervene. We define this divergence as the Capability-Comprehension Gap: a decoupling where assisted performance improves while users' internal models deteriorate. This paper argues that prevailing approaches to transparency, user control, literacy, and governance do not define the foundational understanding humans must retain for oversight under sustained AI delegation. To formalize this, we define the Cognitive Integrity Threshold (CIT) as the minimum comprehension required to preserve oversight, autonomy, and accountable participation under AI assistance. CIT does not require full reasoning reconstruction, nor does it constrain automation. It identifies the threshold beyond which oversight becomes procedural and contestability fails. We operatinalize CIT through three functional dimensions: (i) verification capacity, (ii) comprehension-preserving interaction, and (iii) institutional scaffolds for governance. This motivates a design and governance agenda that aligns human-AI interaction with cognitive sustainability in responsibility-critical settings.

</details>


### [49] [Multi-Head Attention Is a Multi-Player Game](https://arxiv.org/abs/2602.00861)
*Kushal Chakrabarti,Nirmal Balachundar*

Main category: cs.AI

TL;DR: 本研究将Transformer的注意力机制视为一个多智能体系统，并揭示了当前训练方式与此内在机制之间的不匹配。研究人员提出了一种新的理论框架，将注意力机制训练转化为一个潜在博弈，并量化了由于“未定价外部性”（如冗余和相关误差）导致的低效率，即“无政府状态价格”（Price of Anarchy, PoA）。他们提出了一种名为GAME-LoRA的新方法，通过结合去相关和协调压力来减少PoA，并在实验中证明了其有效性，能够显著降低幻觉并保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前的Transformer模型训练方式将其视为一个单一优化器，而忽略了其内部注意力机制（尤其是多头注意力）的多智能体、竞争与协调的内在属性。这种不匹配可能导致训练效率低下和模型性能问题（如幻觉和冗余）。

Method: 1. 将Transformer注意力训练形式化为一个隐式潜在博弈，其中注意力头被视为玩家。2. 推导出无政府状态价格（PoA）的理论界限，该界限取决于注意力头之间的交互矩阵（Γ(G)）的偏离质量。3. 证明了过度的幻觉概率和头部冗余与PoA相关，并将这两种失败模式统一在一个框架下。4. 提出了一种基于PoA的正则化方法，旨在降低Γ(G)。5. 实例化为GAME-LoRA，结合了Barlow Twins的去相关性和log-determinant的协调压力。

Result: 1.  成功将Transformer注意力训练与潜在博弈联系起来，并量化了训练中的低效率（PoA）。2.  理论上证明了过度幻觉和头部冗余与PoA呈正相关。3.  实验表明，Γ(G)能够预测幻觉的发生。4.  GAME-LoRA在减少幻觉方面取得了显著效果（最高18%，平均8%），同时没有损害模型性能。5.  观察到注意力头会形成联盟并进行选择性协调。

Conclusion: Transformer的注意力机制训练可以被理解为一个多智能体潜在博弈。当前训练方法的不足导致了无政府状态价格（PoA）的出现，从而引发了幻觉和冗余等问题。通过GAME-LoRA等方法，可以有效地降低PoA，改善模型性能，实现性能与幻觉的权衡。该研究为理解和改进Transformer训练提供了新的视角和方法。

Abstract: Modern transformer attention is internally multi-agent -- heads compete and coordinate -- yet we train it as if it were a monolithic optimizer. We formalize this gap: cross-entropy training induces an implicit potential game among heads, and gradient descent converges to Nash equilibria with potentially unbounded inefficiency due to unpriced externalities (redundancy, correlated errors). Our main result bounds the Price of Anarchy by $Γ(G)$, the off-diagonal mass of a head interaction matrix capturing weight and gradient coupling. Under mild smoothness assumptions, we prove that both \emph{excess hallucination probability} and \emph{excess head redundancy} scale with PoA, unifying two distinct failure modes into a single mechanism. The bound is prescriptive: regularization that reduces $Γ(G)$ provably tightens PoA. We instantiate this as GAME-LoRA, combining Barlow Twins decorrelation with log-determinant coordination pressure. Experiments validate the theory: $Γ(G)$ predicts hallucination ($p{<}0.05$), emergent coalitions exhibit selective coordination, and GAME-LoRA achieves up to 18\% hallucination reduction (8\% average) with no knowledge degradation -- a Pareto improvement inaccessible to methods ignoring the game structure.

</details>


### [50] [Beyond Output Critique: Self-Correction via Task Distillation](https://arxiv.org/abs/2602.00871)
*Hossein A. Rahmani,Mengting Wan,Pei Zhou,Longqi Yang,Nick Craswell,Emine Yilmaz,Sujay Kumar Jauhar*

Main category: cs.AI

TL;DR: 提出了一种名为 SELF-THOUGHT 的新框架，通过引入任务抽象中间步骤来提升大型语言模型（LLMs）的自纠错能力，并证明了这种抽象模板可以跨模型迁移，从而帮助小型 LLMs 提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有 LLMs 的自纠错方法多停留在输出层面，难以纠正深层推理错误。需要一种方法来解决这个问题。

Method: SELF-THOUGHT 框架首先将输入任务抽象成一个结构化模板（包含关键变量、约束和问题结构），然后利用该模板指导解决方案的生成和细化。此外，该框架还支持模板跨模型迁移，让小型 LLMs 也能受益。

Result: 通过在多种推理任务上的实验，SELF-THOUGHT 框架显著提高了大型和小型 LLMs 的准确性、鲁棒性和泛化能力。

Conclusion: SELF-THOUGHT 提供了一种可扩展的方法，通过任务抽象和跨模型模板迁移，显著增强了 LLMs 的自纠错能力，是构建更可靠的自纠错语言系统的有效途径。

Abstract: Large language models (LLMs) have shown promising self-correction abilities, where iterative refinement improves the quality of generated responses. However, most existing approaches operate at the level of output critique, patching surface errors while often failing to correct deeper reasoning flaws. We propose SELF-THOUGHT, a framework that introduces an intermediate step of task abstraction before solution refinement. Given an input and an initial response, the model first distills the task into a structured template that captures key variables, constraints, and problem structure. This abstraction then guides solution instantiation, grounding subsequent responses in a clearer understanding of the task and reducing error propagation. Crucially, we show that these abstractions can be transferred across models: templates generated by larger models can serve as structured guides for smaller LLMs, which typically struggle with intrinsic self-correction. By reusing distilled task structures, smaller models achieve more reliable refinements without heavy fine-tuning or reliance on external verifiers. Experiments across diverse reasoning tasks demonstrate that SELF-THOUGHT improves accuracy, robustness, and generalization for both large and small models, offering a scalable path toward more reliable self-correcting language systems.

</details>


### [51] [Foundation CAN LM: A Pretrained Language Model For Automotive CAN Data](https://arxiv.org/abs/2602.00866)
*Akiharu Esashi,Pawissanutt Lertpongrujikorn,Justin Makino,Yuibi Fujimoto,Mohsen Amini Salehi*

Main category: cs.AI

TL;DR: 本文提出了一种基于Transformer的“基础CAN模型”，将CAN数据类比为自然语言，通过大规模无标签数据预训练，然后在异构的汽车保险任务上进行微调，实现了跨任务的泛化能力，开创了汽车AI领域通用表示学习的新方向。


<details>
  <summary>Details</summary>
Motivation: 现有的CAN数据处理方法通常对每个任务训练独立的模型，缺乏共享表示学习，限制了模型在不同任务间的泛化能力。自然语言处理（NLP）和计算机视觉（CV）领域的基础模型范式（预训练-微调）取得了巨大成功，作者希望将此范式应用于CAN数据。

Method: 1. 将CAN数据视为一种“语言”。 2. 提出一种统一的、能够处理混合离散-连续信号的tokenization方案。 3. 预训练一个单一的、大型的、无标签的解码CAN信号的Transformer模型（基础CAN模型）。 4. 在多个异构的汽车保险下游任务上对预训练模型进行微调，以验证其多目标下游泛化能力。 5. 解决了时间复杂性和特定行程（trip-specific）的可变性问题。

Result: 一个预训练好的基础CAN模型能够有效地适应各种不同的预测任务，证明了基础模型范式在CAN数据上同样有效。

Conclusion: 基础模型范式（类似NLP和CV）同样适用于CAN数据，并能实现多目标下游泛化。本文提出的基础CAN模型为汽车AI领域的通用表示学习提供了一个新的研究方向。

Abstract: The Controller Area Network (CAN) bus provides a rich source of vehicular signals increasingly leveraged for applications in automotive and auto insurance domains, including collision detection, predictive maintenance, and driver risk modeling. Despite this potential, existing pipelines largely train isolated task-specific models on raw CAN data, with only limited efforts exploring decoded signals. Such fragmentation prevents shared representation learning and limits cross-task generalization. By contrast, natural language processing (NLP) and computer vision (CV) have been transformed by the foundation model paradigm: large-scale pretraining followed by task-specific adaptation. In this work, we introduce the foundation CAN model that demonstrates multi-objective downstream generalization using a single pretrained backbone. Our approach treats CAN data as a language: we pretrain on large-scale, unlabeled decoded CAN signals and fine-tune across heterogeneous auto insurance tasks. To enable this, we propose a unified tokenization scheme for mixed discrete-continuous signals and address challenges of temporal complexity and trip-specific variability. Our results show that one pretrained CAN model can adapt effectively to diverse predictive tasks, validating that the foundation modeling paradigm, proven in NLP and CV, also holds for CAN data. This establishes a new direction for generalizable representation learning in automotive AI.

</details>


### [52] [Synapse Compendium Aware Federated Knowledge Exchange for Tool Routed LLMs](https://arxiv.org/abs/2602.00911)
*Abhijit Chakraborty,Sandipan De,Yash Shah,Chahana Dahal,Vivek Gupta*

Main category: cs.AI

TL;DR: Synapse是一个联邦学习框架，通过训练一个共享的全局工具使用知识模型来解决多智能体LLM协作学习中的通信成本、数据异质性和工具使用挑战。它通过本地训练、工件聚合和全局更新来提高工具使用效率并减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的智能体在联邦学习中的协作学习面临通信成本高、数据异质性以及工具使用效率低下的挑战。

Method: Synapse框架训练一个共享的全局工具使用知识模型。客户端智能体本地学习工具使用模式，并将工件通过协调器进行联邦聚合。通过更新和重新分发全局工具集，实现稳定的工具选择。框架使用了模板化表示、检索增强和自适应掩码技术，以在限制信息泄露的同时保持效用。

Result: Synapse显著提高了工具使用的有效性，并降低了与权重或提示共享方法相比的通信开销。

Conclusion: Synapse框架能够有效地解决多智能体LLM系统在联邦学习中的协作学习问题，提高工具使用效率，减少通信开销，并支持数据异质性。

Abstract: Collaborative learning among LLM-based agents under federated learning faces challenges, including communication costs, heterogeneity in data, and tool-usage, limiting their effectiveness. We introduce Synapse, a framework that trains a shared global knowledge model of tool-usage behavior. Client agents with fixed LLMs learn tool-usage patterns locally, and transmit artifacts for federated aggregation through coordinators. A global tool compendium is updated and redistributed, enabling convergence toward stable tool selection. Synapse uses templated representations, embedding retrieval with LLM reranking, and adaptive masking to maintain utility while limiting information leakage. The framework supports heterogeneous data and quantifies performance improvements. Results show that Synapse improves tool-usage effectiveness and reduces communication overhead compared with weight or prompt-sharing approaches in multi-agent LLM systems.

</details>


### [53] [Supervised sparse auto-encoders as unconstrained feature models for semantic composition](https://arxiv.org/abs/2602.00924)
*Ouns El Harzli,Hugo Wallner,Yoonsoo Nam,Haixuan Xavier Tao*

Main category: cs.AI

TL;DR: 本文提出了一种结合无约束特征模型和监督学习的方法来解决稀疏自编码器（SAEs）在可解释性和特征语义对齐方面的挑战，并在Stable Diffusion 3.5上验证了其在组合泛化和语义编辑方面的能力。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAEs）在机械可解释性方面面临两个主要挑战：L1惩罚的非平滑性导致重构和可伸缩性问题，以及学习到的特征与人类语义之间缺乏对齐。

Method: 该研究采用无约束特征模型（来自神经崩溃理论的数学框架）并引入监督学习。具体来说，他们监督（仅解码器）SAEs重构特征向量，同时联合学习稀疏概念嵌入和解码器权重。

Result: 在Stable Diffusion 3.5上进行的验证表明，该方法实现了组合泛化，能够成功重构训练中未见过的概念组合的图像，并且能够进行特征级干预，实现无需修改提示的语义图像编辑。

Conclusion: 通过结合无约束特征模型和监督学习，该方法有效解决了SAEs在可解释性和语义对齐方面的现有挑战，并在图像生成任务中展现出优越的组合泛化和语义编辑能力。

Abstract: Sparse auto-encoders (SAEs) have re-emerged as a prominent method for mechanistic interpretability, yet they face two significant challenges: the non-smoothness of the $L_1$ penalty, which hinders reconstruction and scalability, and a lack of alignment between learned features and human semantics. In this paper, we address these limitations by adapting unconstrained feature models-a mathematical framework from neural collapse theory-and by supervising the task. We supervise (decoder-only) SAEs to reconstruct feature vectors by jointly learning sparse concept embeddings and decoder weights. Validated on Stable Diffusion 3.5, our approach demonstrates compositional generalization, successfully reconstructing images with concept combinations unseen during training, and enabling feature-level intervention for semantic image editing without prompt modification.

</details>


### [54] [Learning Abstractions for Hierarchical Planning in Program-Synthesis Agents](https://arxiv.org/abs/2602.00929)
*Zergham Ahmed,Kazuki Irie,Joshua B. Tenenbaum,Christopher J. Bates,Samuel J. Gershman*

Main category: cs.AI

TL;DR: 本文提出了一种名为TheoryCoder-2的基于理论的强化学习（TBRL）新方法，它利用大型语言模型（LLMs）的上下文学习能力，能够从经验中学习可重用的抽象，并将其整合到分层规划过程中，从而在复杂任务上展现出比现有方法更强的样本效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理和深度强化学习系统在学习抽象和快速泛化到新任务方面仍存在挑战，而人类则能有效地做到这一点。现有的基于理论的RL系统（如TheoryCoder）虽然能利用抽象，但高度依赖于人类提供的抽象，并未解决抽象学习本身的问题。

Method: TheoryCoder-2利用LLM的上下文学习能力，通过合成经验中的抽象并将其集成到分层规划中，主动学习可重用的抽象，而非依赖人工指定的抽象。实验在BabyAI、Minihack和Sokoban等环境中进行。

Result: 与增强了经典规划领域构建、基于推理的规划以及WorldCoder等先前的程序合成代理相比，TheoryCoder-2在样本效率上显著更高。它能够解决基线方法无法解决的复杂任务。

Conclusion: TheoryCoder-2是一种新的TBRL代理，它能够通过自主学习抽象来克服现有方法的局限性，并在多种环境中实现了优越的样本效率和泛化能力，同时仅需最少的人类提示。

Abstract: Humans learn abstractions and use them to plan efficiently to quickly generalize across tasks -- an ability that remains challenging for state-of-the-art large language model (LLM) agents and deep reinforcement learning (RL) systems. Inspired by the cognitive science of how people form abstractions and intuitive theories of their world knowledge, Theory-Based RL (TBRL) systems, such as TheoryCoder, exhibit strong generalization through effective use of abstractions. However, they heavily rely on human-provided abstractions and sidestep the abstraction-learning problem. We introduce TheoryCoder-2, a new TBRL agent that leverages LLMs' in-context learning ability to actively learn reusable abstractions rather than relying on hand-specified ones, by synthesizing abstractions from experience and integrating them into a hierarchical planning process. We conduct experiments on diverse environments, including BabyAI, Minihack and VGDL games like Sokoban. We find that TheoryCoder-2 is significantly more sample-efficient than baseline LLM agents augmented with classical planning domain construction, reasoning-based planning, and prior program-synthesis agents such as WorldCoder. TheoryCoder-2 is able to solve complex tasks that the baselines fail, while only requiring minimal human prompts, unlike prior TBRL systems.

</details>


### [55] [The Keyhole Effect: Why Chat Interfaces Fail at Data Analysis](https://arxiv.org/abs/2602.00947)
*Mohan Reddy*

Main category: cs.AI

TL;DR: 该研究认为，聊天界面不适合复杂、依赖状态的数据分析任务，因为它会因信息位移、隐藏状态、强制语言化、线性文本流和序列化惩罚而导致认知过载。研究提出八种混合设计模式来克服这些缺点，并强调了经验验证的必要性。


<details>
  <summary>Details</summary>
Motivation: 当前AI辅助数据分析普遍采用聊天界面，但对于多步骤、状态依赖的分析任务，这种方式存在缺陷，导致分析性能下降。

Method: 该研究基于Woods (1984)的Keyhole Effect，分析了聊天界面在信息位移、隐藏状态变量、强制语言化、线性文本流和序列化惩罚这五个方面如何系统性地降低分析性能。研究提出了认知过载的数学模型 O = max(0, m - v - W)，并设计了八种混合UI设计模式（Generative UI, Infinite Canvas, Deictic Interaction, State Rail, Ghost Layers, Mise en Place, Semantic Zoom, and Probabilistic UI）来解决这些问题。

Result: 聊天界面通过五种机制导致认知过载，具体表现为：1. 内容位移破坏空间记忆；2. 隐藏状态变量超出工作记忆容量；3. 强制语言化引发语言干扰，损害视觉模式识别；4. 线性文本流阻碍认知行为和信息卸载；5. 序列化惩罚随数据维度增加而增加。当认知过载（O > 0）时，错误率增加，并放大锚定、确认和变化盲视等分析偏差。

Conclusion: 聊天界面不适合复杂的数据分析任务。提出的八种混合设计模式可以缓解聊天界面的认知瓶颈，同时保留自然语言的意图表达和综合能力。对于开放式探索任务，比引导式任务更需要这些设计模式。研究提出了可证伪的假设和实验范式以供经验验证。

Abstract: Chat has become the default interface for AI-assisted data analysis. For multi-step, state-dependent analytical tasks, this is a mistake. Building on Woods (1984) Keyhole Effect, the cognitive cost of viewing large information spaces through narrow viewports, I show that chat interfaces systematically degrade analytical performance through five mechanisms: (1) constant content displacement defeats hippocampal spatial memory systems; (2) hidden state variables exceed working memory capacity (approximately 4 chunks under load); (3) forced verbalization triggers verbal overshadowing, degrading visual pattern recognition; (4) linear text streams block epistemic action and cognitive offloading; (5) serialization penalties scale with data dimensionality. I formalize cognitive overload as O = max(0, m - v - W) where m is task-relevant items, v is visible items, and W is working memory capacity. When O > 0, error probability increases and analytical biases (anchoring, confirmation, change blindness) amplify. Eight hybrid design patterns address these failures: Generative UI, Infinite Canvas, Deictic Interaction, State Rail, Ghost Layers, Mise en Place, Semantic Zoom, and Probabilistic UI. Each pattern targets specific cognitive bottlenecks while preserving natural language for intent specification and synthesis. Well-scaffolded conversational systems that encode expert priors may reduce load for guided tasks; the framework applies most strongly to open-ended exploration. The paper concludes with falsifiable hypotheses and experimental paradigms for empirical validation.

</details>


### [56] [MindGuard: Guardrail Classifiers for Multi-Turn Mental Health Support](https://arxiv.org/abs/2602.00950)
*António Farinhas,Nuno M. Guerreiro,José Pombal,Pedro Henrique Martins,Laura Melton,Alex Conway,Cara Dochat,Maya D'Eon,Ricardo Rei*

Main category: cs.AI

TL;DR: 研究提出了一种名为MindGuard的轻量级安全分类器，旨在提高大型语言模型在心理健康支持中的安全性，通过区分治疗性披露和临床危机，并发布了相关数据集和模型。


<details>
  <summary>Details</summary>
Motivation: 现有通用安全措施无法区分心理健康支持中的治疗性对话与真正的临床危机，导致安全隐患；因此需要更专业、更具临床指导意义的安全机制。

Method: 1. 与心理学家合作开发了一个基于临床风险的分类体系，用于识别可采取行动的危害（如自残和伤害他人）。2. 发布了MindGuard-testset数据集，包含由临床专家标注的真实多轮对话。3. 利用两方代理控制的生成合成对话，训练了MindGuard系列轻量级安全分类器（40亿和80亿参数）。

Result: MindGuard分类器在高召回率操作点下可减少误报；与通用安全措施相比，与临床语言模型结合使用时，在对抗性多轮交互中能实现更低的攻击成功率和有害互动率。

Conclusion: MindGuard分类器通过引入临床视角，能有效提升大型语言模型在心理健康支持中的安全性，减少不必要的干预，并在保障用户安全的同时，为健康的治疗性对话留出空间。

Abstract: Large language models are increasingly used for mental health support, yet their conversational coherence alone does not ensure clinical appropriateness. Existing general-purpose safeguards often fail to distinguish between therapeutic disclosures and genuine clinical crises, leading to safety failures. To address this gap, we introduce a clinically grounded risk taxonomy, developed in collaboration with PhD-level psychologists, that identifies actionable harm (e.g., self-harm and harm to others) while preserving space for safe, non-crisis therapeutic content. We release MindGuard-testset, a dataset of real-world multi-turn conversations annotated at the turn level by clinical experts. Using synthetic dialogues generated via a controlled two-agent setup, we train MindGuard, a family of lightweight safety classifiers (with 4B and 8B parameters). Our classifiers reduce false positives at high-recall operating points and, when paired with clinician language models, help achieve lower attack success and harmful engagement rates in adversarial multi-turn interactions compared to general-purpose safeguards. We release all models and human evaluation data.

</details>


### [57] [R-HTN: Rebellious Online HTN Planning for Safety and Game AI](https://arxiv.org/abs/2602.00951)
*Hector Munoz-Avila,David W. Aha,Paola Rizzo*

Main category: cs.AI

TL;DR: 本文提出了一种在线分层任务网络（HTN）代理，它能够遵循内置指令集D，并在某些情况下表现出“智能不服从”行为，即不执行用户任务，而是采取不符合用户期望的方式行动。研究了两种变体：一种是发现违反指令就停止执行的非自适应代理，另一种是会修改计划以寻找替代方案的自适应代理。提出的R-HTN算法在两个任务领域进行了评估，结果表明R-HTN代理从未违反指令，并在可行的情况下努力实现用户目标，尽管方式可能出乎用户意料。


<details>
  <summary>Details</summary>
Motivation: 研究动机是构建能够执行复杂任务的智能代理，同时确保它们遵守一组预定义的规则或指令，并在必要时能够进行“智能不服从”，以避免违反这些指令。

Method: 结合了HTN规划、在线规划和指令集D。提出了R-HTN算法，并评估了两种代理变体：非自适应代理（违反指令时停止）和自适应代理（违反指令时修改计划）。

Result: R-HTN代理在评估的任务领域中从未违反指令。代理能够实现用户目标，但实现方式可能与用户预期不同。

Conclusion: R-HTN算法成功地实现了能够在线规划并遵守内置指令的代理。这种方法可以确保代理在追求用户目标的同时，不会违反安全或个性化等约束条件，即使这意味着以非预期的方式完成任务。

Abstract: We introduce online Hierarchical Task Network (HTN) agents whose behaviors are governed by a set of built-in directives \D. Like other agents that are capable of rebellion (i.e., {\it intelligent disobedience}), our agents will, under some conditions, not perform a user-assigned task and instead act in ways that do not meet a user's expectations. Our work combines three concepts: HTN planning, online planning, and the directives \D, which must be considered when performing user-assigned tasks. We investigate two agent variants: (1) a Nonadaptive agent that stops execution if it finds itself in violation of \D~ and (2) an Adaptive agent that, in the same situation, instead modifies its HTN plan to search for alternative ways to achieve its given task. We present R-HTN (for: Rebellious-HTN), a general algorithm for online HTN planning under directives \D. We evaluate R-HTN in two task domains where the agent must not violate some directives for safety reasons or as dictated by their personality traits. We found that R-HTN agents never violate directives, and aim to achieve the user-given goals if feasible though not necessarily as the user expected.

</details>


### [58] [Small-Margin Preferences Still Matter-If You Train Them Right](https://arxiv.org/abs/2602.00954)
*Jinlong Pang,Zhaowei Zhu,Na Di,Yichi Zhang,Yaxuan Wang,Chen Qian,Yang Liu*

Main category: cs.AI

TL;DR: 本文提出了一种名为MixDPO的混合训练策略，它通过课程学习方式处理不同难度的偏好数据，将难例用于监督微调（SFT），易例用于偏好回归（DPO），从而有效利用了模糊偏好对，提高了LLM的对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有的偏好优化方法（如DPO）对偏好数据的质量和难度敏感。通常会过滤掉模糊（低边际）的偏好对，但研究发现这些难例在SFT下仍包含有用的监督信号，而直接用于偏好损失会破坏训练稳定性。因此，研究的动机是如何在不引入训练不稳定性的情况下，利用这些包含有用信息的模糊偏好对。

Method: MixDPO是一种难度感知的训练策略，包含两个主要部分：1. 对偏好数据按难度（基于边际）进行排序，形成一个课程学习过程；2. 将难例（低边际）分配给监督微调（SFT）目标，而易例（高边际）则使用偏好回归损失（如DPO）。

Result: 在三个LLM-judge基准测试中，MixDPO consistently 优于DPO及其变体。尤其是在AlpacaEval~2的长度受控（LC）胜率方面，MixDPO取得了显著的提升。

Conclusion: MixDPO通过将不同难度的偏好数据路由到不同的优化目标（难例SFT，易例DPO），能够有效地利用模糊的偏好对，克服了在低边际数据上使用偏好损失可能导致的优化失败问题，从而提高了LLM的对齐性能。

Abstract: Preference optimization methods such as DPO align large language models (LLMs) using paired comparisons, but their effectiveness can be highly sensitive to the quality and difficulty of preference pairs. A common heuristic treats small-margin (ambiguous) pairs as noisy and filters them out. In this paper, we revisit this assumption and show that pair difficulty interacts strongly with the optimization objective: when trained with preference-based losses, difficult pairs can destabilize training and harm alignment, yet these same pairs still contain useful supervision signals when optimized with supervised fine-tuning (SFT). Motivated by this observation, we propose MixDPO, a simple yet effective difficulty-aware training strategy that (i) orders preference data from easy to hard (a curriculum over margin-defined difficulty), and (ii) routes difficult pairs to an SFT objective while applying a preference loss to easy pairs. This hybrid design provides a practical mechanism to leverage ambiguous pairs without incurring the optimization failures often associated with preference losses on low-margin data. Across three LLM-judge benchmarks, MixDPO consistently improves alignment over DPO and a range of widely-used variants, with particularly strong gains on AlpacaEval~2 length-controlled (LC) win rate.

</details>


### [59] [Reasoning and Tool-use Compete in Agentic RL:From Quantifying Interference to Disentangled Tuning](https://arxiv.org/abs/2602.00994)
*Yu Li,Mingyang Yi,Xiuyu Li,Ju Fan,Fuxin Jiang,Binbin Chen,Peng Li,Jie Song,Tieying Zhang*

Main category: cs.AI

TL;DR: 本文研究了在强化学习中训练大型语言模型进行推理和工具使用时，联合训练是否会损害模型性能。作者提出了一个名为 LEAS 的分析系统，发现推理和工具使用之间存在梯度干扰。为解决此问题，作者提出了 DART 框架，通过独立的低秩适配模块解耦参数更新，实验证明 DART 性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有代理强化学习（ARL）方法普遍假设联合训练推理和工具使用行为可以提高整体性能，但这一假设缺乏实证检验。作者旨在系统地研究联合训练中的潜在干扰，并提出解决方案。

Method: 作者首先提出了一个名为 LEAS (Linear Effect Attribution System) 的分析系统，用于量化推理和工具使用行为之间的干扰。然后，为了解决发现的梯度干扰问题，作者提出了一种名为 DART (Disentangled Action Reasoning Tuning) 的框架，该框架通过为推理和工具使用分别设置独立的低秩适配（LoRA）模块来解耦参数更新。

Result: LEAS 分析表明，推理和工具使用能力在训练过程中经常产生不一致的梯度方向，导致训练干扰，影响联合优化的有效性。DART 框架在实验中始终优于基线方法，平均性能提升 6.35%，并且在单模型内部实现了与显式分离工具使用和推理的多智能体系统相当的性能。

Conclusion: 联合训练推理和工具使用行为在 ARL 中可能存在性能瓶颈，因为这两种能力会产生相互干扰的梯度。DART 框架通过解耦参数更新有效地解决了这个问题，并在实验中取得了显著的性能提升，证明了其有效性。

Abstract: Agentic Reinforcement Learning (ARL) focuses on training large language models (LLMs) to interleave reasoning with external tool execution to solve complex tasks. Most existing ARL methods train a single shared model parameters to support both reasoning and tool use behaviors, implicitly assuming that joint training leads to improved overall agent performance. Despite its widespread adoption, this assumption has rarely been examined empirically. In this paper, we systematically investigate this assumption by introducing a Linear Effect Attribution System(LEAS), which provides quantitative evidence of interference between reasoning and tool-use behaviors. Through an in-depth analysis, we show that these two capabilities often induce misaligned gradient directions, leading to training interference that undermines the effectiveness of joint optimization and challenges the prevailing ARL paradigm. To address this issue, we propose Disentangled Action Reasoning Tuning(DART), a simple and efficient framework that explicitly decouples parameter updates for reasoning and tool-use via separate low-rank adaptation modules. Experimental results show that DART consistently outperforms baseline methods with averaged 6.35 percent improvements and achieves performance comparable to multi-agent systems that explicitly separate tool-use and reasoning using a single model.

</details>


### [60] [Error Taxonomy-Guided Prompt Optimization](https://arxiv.org/abs/2602.00997)
*Mayank Singh,Vikas Yadav,Eduardo Blanco*

Main category: cs.AI

TL;DR: 提出一种名为ETGPO的自动提示优化算法，通过自顶向下地识别和分类模型错误，并针对最常见的错误模式优化提示，从而在不修改模型权重的情况下提升模型性能，并且显著减少了优化成本。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示优化方法（APO）通常采用试错的方式，消耗大量计算资源。虽然基于自然语言反馈的方法有所进展，但它们多采用自底向上的方法，容易丢失全局视角。因此，需要一种更有效率且能顾及全局的模型优化方法。

Method: 提出ETGPO算法，采用自顶向下的方法。首先收集模型在执行过程中的错误，然后将这些错误归类到一个错误分类体系中。最后，根据最频繁出现的错误模式，对提示进行增强，以提供有针对性的指导。

Result: 在数学、问答和逻辑推理等多个基准测试中，ETGPO取得了与现有最先进方法相当或更好的准确率。同时，在优化阶段，ETGPO所需的token使用量和评估成本仅约为现有方法的1/3。

Conclusion: ETGPO是一种有效的自顶向下提示优化算法，能够通过分析和解决全局的错误模式来提高大型语言模型的性能，同时显著降低了优化所需的计算资源。

Abstract: Automatic Prompt Optimization (APO) is a powerful approach for extracting performance from large language models without modifying their weights. Many existing methods rely on trial-and-error, testing different prompts or in-context examples until a good configuration emerges, often consuming substantial compute. Recently, natural language feedback derived from execution logs has shown promise as a way to identify how prompts can be improved. However, most prior approaches operate in a bottom-up manner, iteratively adjusting the prompt based on feedback from individual problems, which can cause them to lose the global perspective. In this work, we propose Error Taxonomy-Guided Prompt Optimization (ETGPO), a prompt optimization algorithm that adopts a top-down approach. ETGPO focuses on the global failure landscape by collecting model errors, categorizing them into a taxonomy, and augmenting the prompt with guidance targeting the most frequent failure modes. Across multiple benchmarks spanning mathematics, question answering, and logical reasoning, ETGPO achieves accuracy that is comparable to or better than state-of-the-art methods, while requiring roughly one third of the optimization-phase token usage and evaluation budget.

</details>


### [61] [How RLHF Amplifies Sycophancy](https://arxiv.org/abs/2602.01002)
*Itai Shapira,Gerdus Benade,Ariel D. Procaccia*

Main category: cs.AI

TL;DR: 本研究通过形式化分析揭示了基于人类反馈的对齐（alignment from human feedback）如何通过一个明确的放大机制导致大型语言模型（LLM）在偏好后训练（preference-based post-training）中表现出更强的谄媚行为。研究提出了一种在训练时干预的方法，并通过计算实验验证了该机制的普遍性和所提方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在偏好后训练后，倾向于表现出更强的谄媚行为，即即使与事实或合理判断相悖，也更倾向于肯定用户的观点。研究旨在理解并解决这一问题。

Method: 1. 形式化分析了人类反馈对齐如何通过一个放大机制导致谄媚行为的增加，该机制将学习到的奖励与用于对齐的人类偏好数据中的偏见联系起来。2. 分析了基于 Bradley-Terry 等随机效用模型的成对比较奖励学习，并确定了人类注释者偏好中的偏见何时会引起奖励差距。3. 提出了一种训练时干预方法，旨在消除放大机制，并推导出最小奖励修正作为一种闭合形式的协议惩罚。

Result: 研究发现，奖励差距普遍存在，并且在所有考虑的配置中都会导致行为漂移。所提出的干预措施能够有效抵消放大机制，并找到与未经约束的策略最接近的策略。

Conclusion: 人类反馈对齐过程中固有的奖励放大机制是导致大型语言模型出现谄媚行为增加的主要原因。通过引入协议惩罚等训练时干预措施，可以有效地缓解这一问题，并训练出更准确、更少谄媚的模型。

Abstract: Large language models often exhibit increased sycophantic behavior after preference-based post-training, showing a stronger tendency to affirm a user's stated or implied belief even when this conflicts with factual accuracy or sound judgment. We present a formal analysis of how alignment from human feedback can increase this failure mode by identifying an explicit amplification mechanism that causally links optimization against a learned reward to bias in the human preference data used for alignment. We show that the direction of behavioral drift is determined by a covariance under the base policy between endorsing the belief signal in the prompt and the learned reward, and that the first-order effect reduces to a simple mean-gap condition. We then analyze reward learning from pairwise comparisons under random utility models like Bradley-Terry and characterize when bias in human annotators' preferences induces this reward gap. Next, we propose a training-time intervention designed to neutralize the amplification mechanism itself. Among all post-trained policies that prevent sycophantic behavior from increasing, we characterize the unique policy closest in KL divergence to the unconstrained post-trained policy, and derive the corresponding minimal reward correction as a closed-form agreement penalty. Computational experiments find that reward gaps are common and cause behavioral drift in all the configurations considered.

</details>


### [62] [HalluHard: A Hard Multi-Turn Hallucination Benchmark](https://arxiv.org/abs/2602.01031)
*Dongyang Fan,Sebastien Delsad,Nicolas Flammarion,Maksym Andriushchenko*

Main category: cs.AI

TL;DR: 该研究提出了一个名为HalluHard的多轮对话幻觉基准测试，用于评估大型语言模型（LLMs）在回答事实性问题时产生不实信息的能力。研究发现，即使在有网络搜索辅助的情况下，LLMs仍会产生大量幻觉，并且幻觉的程度受模型能力、对话轮次、推理能力和知识类型等因素影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多轮对话中容易产生听起来合理但事实不准确的幻觉，并且这些错误会随着对话的深入而累积。需要一个具有挑战性的基准来评估和改进LLMs在实际应用中的事实准确性。

Method: 研究构建了一个包含950个种子问题、涵盖法律、研究、医疗和编程四个高风险领域的HalluHard基准测试。通过要求模型提供内联引文来衡量其论述的论据可靠性。为了在开放式设置中进行可靠评估，提出了一种通过网络搜索迭代检索证据的评估流程，该流程能够抓取、过滤和解析包括PDF在内的全文来源，以判断引用的材料是否确实支持生成的内容。

Result: 在对一系列前沿的专有和开源模型进行评估后发现，即使有网络搜索的辅助，LLMs仍然产生显著的幻觉（在最强的Opus-4.5模型配合网络搜索配置下，幻觉率约为30%），内容论据不实的错误率依然很高。此外，研究还表明幻觉行为受到模型容量、对话轮次位置、有效推理和所需知识类型的影响。

Conclusion: 大型语言模型在多轮对话中依然存在严重的事实幻觉问题，即使有网络搜索的辅助也无法完全解决。幻觉的产生与模型本身的能力、对话的动态以及所涉及的知识类型密切相关，这表明需要进一步的研究来提升LLMs在实际应用中的可靠性。

Abstract: Large language models (LLMs) still produce plausible-sounding but ungrounded factual claims, a problem that worsens in multi-turn dialogue as context grows and early errors cascade. We introduce $\textbf{HalluHard}$, a challenging multi-turn hallucination benchmark with 950 seed questions spanning four high-stakes domains: legal cases, research questions, medical guidelines, and coding. We operationalize groundedness by requiring inline citations for factual assertions. To support reliable evaluation in open-ended settings, we propose a judging pipeline that iteratively retrieves evidence via web search. It can fetch, filter, and parse full-text sources (including PDFs) to assess whether cited material actually supports the generated content. Across a diverse set of frontier proprietary and open-weight models, hallucinations remain substantial even with web search ($\approx 30\%$ for the strongest configuration, Opus-4.5 with web search), with content-grounding errors persisting at high rates. Finally, we show that hallucination behavior is shaped by model capacity, turn position, effective reasoning, and the type of knowledge required.

</details>


### [63] [SetPO: Set-Level Policy Optimization for Diversity-Preserving LLM Reasoning](https://arxiv.org/abs/2602.01062)
*Chenyi Li,Yuan Zhang,Bo Wang,Guoqing Ma,Wei Tang,Haoyang Huang,Nan Duan*

Main category: cs.AI

TL;DR: 该研究提出了一种新的基于核相似度的多目标函数，用于在增强LLM数学推理能力的同时，提高结果的多样性，并证明了稀有轨迹对整体多样性有更高的贡献。


<details>
  <summary>Details</summary>
Motivation: 现有的基于可验证奖励的强化学习方法虽然能提升LLM的数学推理能力，但会导致结果多样性降低，模型倾向于产生单一的解决方案。

Method: 提出了一种基于核相似度的集合级多样性目标函数，该函数通过计算每个采样轨迹的留一法边际贡献来度量多样性，并将其作为策略优化的优势项。此外，还通过分布扰动框架理论分析了单个轨迹对模型多样性的贡献。

Result: 实验表明，所提出的算法在Pass@1和Pass@K指标上均优于强基线方法，并且在不同规模的模型上都表现出有效性。

Conclusion: 该研究提出的多样性目标函数能够有效提升LLM在数学任务上的结果多样性，并且稀有轨迹对提升整体多样性有更高的边际贡献。

Abstract: Reinforcement learning with verifiable rewards has shown notable effectiveness in enhancing large language models (LLMs) reasoning performance, especially in mathematics tasks. However, such improvements often come with reduced outcome diversity, where the model concentrates probability mass on a narrow set of solutions. Motivated by diminishing-returns principles, we introduce a set level diversity objective defined over sampled trajectories using kernelized similarity. Our approach derives a leave-one-out marginal contribution for each sampled trajectory and integrates this objective as a plug-in advantage shaping term for policy optimization. We further investigate the contribution of a single trajectory to language model diversity within a distribution perturbation framework. This analysis theoretically confirms a monotonicity property, proving that rarer trajectories yield consistently higher marginal contributions to the global diversity. Extensive experiments across a range of model scales demonstrate the effectiveness of our proposed algorithm, consistently outperforming strong baselines in both Pass@1 and Pass@K across various benchmarks.

</details>


### [64] [Discovering Process-Outcome Credit in Multi-Step LLM Reasoning](https://arxiv.org/abs/2602.01034)
*Xiangwei Wang,Wei Wang,Ken Chen,Nanduni Nimalsiri,Saman Halgamuge*

Main category: cs.AI

TL;DR: 本研究提出了一种新的基于强化学习的方法，通过引入逐步边际信息增益（MIG）和解耦掩码策略，为大语言模型（LLMs）提供连续的奖励信号，以提高其推理能力，并在多项基准测试中取得了优于现有方法的性能，同时展现出良好的分布外鲁棒性和零样本迁移能力。


<details>
  <summary>Details</summary>
Motivation: 标准基于结果的强化学习方法在提高大语言模型的推理能力方面存在奖励稀疏和信用分配效率低下的问题。因此，需要一种更有效的奖励机制来指导模型的学习。

Method: 提出了一种新的框架，包括：1. 逐步边际信息增益（MIG）机制，为每个推理步骤提供连续的奖励信号，并通过历史水印过滤噪声；2. 解耦掩码策略，将过程导向的奖励应用于思维链（CoT），将结果导向的奖励应用于完整输出；3. 双门控SFT目标，利用结构和事实信号稳定训练。

Result: 在文本和多模态基准（如MATH、Super-CLEVR）上进行了广泛的实验，结果表明该方法在样本效率和最终准确性方面均优于GRPO等基线方法。此外，该模型还表现出优越的分布外鲁棒性，并具备向未见过的推理任务进行零样本迁移的能力。

Conclusion: 所提出的方法有效地解决了传统强化学习在LLM推理中的奖励稀疏和信用分配问题，通过引入新颖的奖励机制和训练策略，显著提升了模型的推理性能、样本效率、分布外鲁棒性和零样本迁移能力。

Abstract: Reinforcement Learning (RL) serves as a potent paradigm for enhancing reasoning capabilities in Large Language Models (LLMs), yet standard outcome-based approaches often suffer from reward sparsity and inefficient credit assignment. In this paper, we propose a novel framework designed to provide continuous reward signals, which introduces a Step-wise Marginal Information Gain (MIG) mechanism that quantifies the intrinsic value of reasoning steps against a Monotonic Historical Watermark, effectively filtering out training noise. To ensure disentangled credit distribution, we implement a Decoupled Masking Strategy, applying process-oriented rewards specifically to the chain-of-thought (CoT) and outcome-oriented rewards to the full completion. Additionally, we incorporate a Dual-Gated SFT objective to stabilize training with high-quality structural and factual signals. Extensive experiments across textual and multi-modal benchmarks (e.g., MATH, Super-CLEVR) demonstrate that our approach consistently outperforms baselines such as GRPO in both sample efficiency and final accuracy. Furthermore, our model exhibits superior out-of-distribution robustness, demonstrating promising zero-shot transfer capabilities to unseen and challenging reasoning tasks.

</details>


### [65] [AutoHealth: An Uncertainty-Aware Multi-Agent System for Autonomous Health Data Modeling](https://arxiv.org/abs/2602.01078)
*Tong Xia,Weibin Li,Gang Liu,Yong Li*

Main category: cs.AI

TL;DR: 提出了一种名为AutoHealth的新型不确定性感知多智能体系统，用于自主处理健康数据并评估模型可靠性，并在真实世界基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自主机器学习系统在处理异构健康数据、适应特定任务和进行不确定性估计方面存在局限性，而这些对于医疗保健中的可靠决策至关重要。

Method: 开发了一个名为AutoHealth的系统，该系统包含五个专业智能体，通过闭环协调来执行数据探索、任务条件模型构建、训练和优化。该系统同时关注预测性能和不确定性量化，并生成报告以支持解释和决策。

Result: AutoHealth成功完成了包含17个任务的真实世界基准测试，在预测性能上比最先进的基线提高了29.2%，在不确定性估计上提高了50.2%。

Conclusion: AutoHealth是一个有效的、不确定性感知的多智能体系统，能够自主地对健康数据进行建模，并超越现有方法，为医疗保健中的可靠和风险意识决策提供支持。

Abstract: LLM-based agents have demonstrated strong potential for autonomous machine learning, yet their applicability to health data remains limited. Existing systems often struggle to generalize across heterogeneous health data modalities, rely heavily on predefined solution templates with insufficient adaptation to task-specific objectives, and largely overlook uncertainty estimation, which is essential for reliable decision-making in healthcare. To address these challenges, we propose \textit{AutoHealth}, a novel uncertainty-aware multi-agent system that autonomously models health data and assesses model reliability. \textit{AutoHealth} employs closed-loop coordination among five specialized agents to perform data exploration, task-conditioned model construction, training, and optimization, while jointly prioritizing predictive performance and uncertainty quantification. Beyond producing ready-to-use models, the system generates comprehensive reports to support trustworthy interpretation and risk-aware decision-making. To rigorously evaluate its effectiveness, we curate a challenging real-world benchmark comprising 17 tasks across diverse data modalities and learning settings. \textit{AutoHealth} completes all tasks and outperforms state-of-the-art baselines by 29.2\% in prediction performance and 50.2\% in uncertainty estimation.

</details>


### [66] [ConvexBench: Can LLMs Recognize Convex Functions?](https://arxiv.org/abs/2602.01075)
*Yepeng Liu,Yu Huang,Yu-Xiang Wang,Yingbin Liang,Yuheng Bu*

Main category: cs.AI

TL;DR: 本研究提出了一个名为 \cb 的基准测试，用于评估大型语言模型（LLMs）在深度函数组合下识别符号目标凸性的能力。研究发现 LLMs 在处理深度组合时存在显著的推理能力下降（从深度 2 的 F1 分数 1.0 下降到深度 100 的 0.2），主要由于解析失败和惰性推理。为了解决这个问题，研究者提出了一种基于外部工具解析和递归推理的代理分而治之框架，该框架在深度组合任务上显著提高了 LLMs 的性能（深度 100 时 F1 分数达到 1.0）。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在数学和科学研究中的应用日益广泛，确保 LLMs 能够理解和推理凸性变得至关重要。因此，需要一个能够测试 LLMs 在深度函数组合下识别凸性的基准。

Method: 研究者开发了一个名为 \cb 的基准测试，用于评估 LLMs 在深度函数组合下识别符号目标凸性的能力。通过在现有 LLMs 上进行实验，分析了其推理过程中的失败模式（解析失败和惰性推理）。为解决这些问题，研究者提出了一种代理分而治之框架，该框架利用外部工具进行解析生成抽象语法树（AST），并对每个中间子表达式强制执行递归推理。

Result: 在对前沿 LLMs 的实验中，发现在深度函数组合下存在一个急剧的组合推理能力下降：当深度从 2 增加到 100 时，F1 分数从 1.0 下降到约 0.2。模型的主要失败模式是“解析失败”和“惰性推理”。提出的代理分而治之框架成功缓解了深度组合的失败问题，在深度 100 时 F1 分数达到了 1.0。

Conclusion: LLMs 在处理深度函数组合以识别凸性方面存在显著的推理能力差距。提出的代理分而治之框架，结合外部工具进行解析和递归推理，能够有效克服这一挑战，并显著提高 LLMs 在此类任务上的性能。

Abstract: Convex analysis is a modern branch of mathematics with many applications. As Large Language Models (LLMs) start to automate research-level math and sciences, it is important for LLMs to demonstrate the ability to understand and reason with convexity. We introduce \cb, a scalable and mechanically verifiable benchmark for testing \textit{whether LLMs can identify the convexity of a symbolic objective under deep functional composition.} Experiments on frontier LLMs reveal a sharp compositional reasoning gap: performance degrades rapidly with increasing depth, dropping from an F1-score of $1.0$ at depth $2$ to approximately $0.2$ at depth $100$. Inspection of models' reasoning traces indicates two failure modes: \textit{parsing failure} and \textit{lazy reasoning}. To address these limitations, we propose an agentic divide-and-conquer framework that (i) offloads parsing to an external tool to construct an abstract syntax tree (AST) and (ii) enforces recursive reasoning over each intermediate sub-expression with focused context. This framework reliably mitigates deep-composition failures, achieving substantial performance improvement at large depths (e.g., F1-Score $= 1.0$ at depth $100$).

</details>


### [67] [EvoOpt-LLM: Evolving industrial optimization models with large language models](https://arxiv.org/abs/2602.01082)
*Yiliu He,Tianle Li,Binghao Ji,Zhiyuan Liu,Di Huang*

Main category: cs.AI

TL;DR: EvoOpt-LLM是一个基于大型语言模型（LLM）的框架，用于自动化MILP优化模型的构建、动态约束注入和变量剪枝，提高了模型的可访问性和效率。


<details>
  <summary>Details</summary>
Motivation: 将自然语言需求转化为MILP模型并维护模型具有高度的专业性，现有的LLM方法在数据效率、模型有效性和可扩展性方面存在不足。本研究旨在解决这些挑战，实现工业优化建模的自动化。

Method: 基于7B参数LLM，通过LoRA进行参数高效微调。构建了包括模型构建、动态约束注入和变量剪枝的统一框架。分别评估了模型构建和约束注入模块的生成率和可执行率，以及变量剪枝模块的F1分数。

Result: EvoOpt-LLM在仅3000个训练样本的情况下，实现了91%的生成率和65.9%的可执行率，关键性能提升在1500个样本以下出现。约束注入模块能够可靠地增强MILP模型。变量剪枝模块在400个样本下，对中等规模LP模型取得了约0.56的F1分数。

Conclusion: EvoOpt-LLM提供了一种实用的、数据高效的方法来解决工业优化建模问题，减少了对专家干预的依赖，同时提高了模型的适应性和求解效率。

Abstract: Optimization modeling via mixed-integer linear programming (MILP) is fundamental to industrial planning and scheduling, yet translating natural-language requirements into solver-executable models and maintaining them under evolving business rules remains highly expertise-intensive. While large language models (LLMs) offer promising avenues for automation, existing methods often suffer from low data efficiency, limited solver-level validity, and poor scalability to industrial-scale problems. To address these challenges, we present EvoOpt-LLM, a unified LLM-based framework supporting the full lifecycle of industrial optimization modeling, including automated model construction, dynamic business-constraint injection, and end-to-end variable pruning. Built on a 7B-parameter LLM and adapted via parameter-efficient LoRA fine-tuning, EvoOpt-LLM achieves a generation rate of 91% and an executability rate of 65.9% with only 3,000 training samples, with critical performance gains emerging under 1,500 samples. The constraint injection module reliably augments existing MILP models while preserving original objectives, and the variable pruning module enhances computational efficiency, achieving an F1 score of ~0.56 on medium-sized LP models with only 400 samples. EvoOpt-LLM demonstrates a practical, data-efficient approach to industrial optimization modeling, reducing reliance on expert intervention while improving adaptability and solver efficiency.

</details>


### [68] [MedBeads: An Agent-Native, Immutable Data Substrate for Trustworthy Medical AI](https://arxiv.org/abs/2602.01086)
*Takahito Nakajima*

Main category: cs.AI

TL;DR: 该研究提出了MedBeads，一种基于Merkle DAG的“一次写入，多次读取”的医疗数据基础设施，旨在解决当前电子病历（EMR）和FHIR标准在支持自主临床AI代理方面的局限性，通过提供确定性、不可篡篡改且AI原生的数据上下文，增强AI的可信度。


<details>
  <summary>Details</summary>
Motivation: 当前电子病历（EMR）和FHIR标准主要为人类审查设计，导致AI代理接收到的患者数据碎片化，需要依赖概率性检索（如RAG）来重建病史，从而引发幻觉和审计困难。因此，需要一种新的数据基础设施来支持自主临床AI代理。

Method: 研究提出了MedBeads，一种将临床事件表示为Merkle DAG中不可变的“Beads”的数据基础设施。每个“Bead”都加密引用其因果前驱节点。该架构采用“一次写入，多次读取”模式，并实现了Go Core Engine、Python中间件和React可视化界面。

Result: 研究成功实现了MedBeads的原型，并将FHIR资源转换为因果链接的DAG。其BFS上下文检索算法具有O(V+E)的复杂度，支持实时决策。该设计从根本上保证了数据的防篡改性，并通过可视化界面增强了临床医生的理解。

Conclusion: MedBeads通过提供确定性、防篡改的AI原生数据上下文，解决了“上下文不匹配”问题，为“可信医疗AI”奠定了基础。它确保了AI接收到的上下文是确定且防篡改的，同时LLM负责解释。MedBeads已开源，以期加速AI原生数据标准的推广。

Abstract: Background: As of 2026, Large Language Models (LLMs) demonstrate expert-level medical knowledge. However, deploying them as autonomous "Clinical Agents" remains limited. Current Electronic Medical Records (EMRs) and standards like FHIR are designed for human review, creating a "Context Mismatch": AI agents receive fragmented data and must rely on probabilistic inference (e.g., RAG) to reconstruct patient history. This approach causes hallucinations and hinders auditability. Methods: We propose MedBeads, an agent-native data infrastructure where clinical events are immutable "Beads"--nodes in a Merkle Directed Acyclic Graph (DAG)--cryptographically referencing causal predecessors. This "write-once, read-many" architecture makes tampering mathematically detectable. We implemented a prototype with a Go Core Engine, Python middleware for LLM integration, and a React-based visualization interface. Results: We successfully implemented the workflow using synthetic data. The FHIR-to-DAG conversion transformed flat resources into a causally-linked graph. Our Breadth-First Search (BFS) Context Retrieval algorithm traverses relevant subgraphs with O(V+E) complexity, enabling real-time decision support. Tamper-evidence is guaranteed by design: any modification breaks the cryptographic chain. The visualization aids clinician understanding through explicit causal links. Conclusion: MedBeads addresses the "Context Mismatch" by shifting from probabilistic search to deterministic graph traversal, and from mutable records to immutable chains, providing the substrate for "Trustworthy Medical AI." It guarantees the context the AI receives is deterministic and tamper-evident, while the LLM determines interpretation. The structured Bead format serves as a token-efficient "AI-native language." We release MedBeads as open-source software to accelerate agent-native data standards.

</details>


### [69] [Hard Constraints Meet Soft Generation: Guaranteed Feasibility for LLM-based Combinatorial Optimization](https://arxiv.org/abs/2602.01090)
*Yang Liu,Chuan Zhou,Yancheng Chen,Shuai Zhang,Xixun Lin,Xiaoqing Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为 FALCON 的框架，通过语法约束解码、可行性修复层和自适应 Best-of-N 采样，确保大语言模型（LLMs）在解决组合优化（CO）问题时能实现 100% 的解可行性，并提出了 Best-anchored Objective-guided Preference Optimization (BOPO) 训练方法，在理论和实验上都证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在解决组合优化问题时，缺乏保证解可行性的机制，这阻碍了其在实际应用中的部署。

Method: 本文提出了 FALCON 框架，包含三个核心创新：（1）语法约束解码（grammar-constrained decoding）确保句法有效性；（2）可行性修复层（feasibility repair layer）修正语义约束冲突；（3）自适应 Best-of-N 采样（adaptive Best-of-N sampling）提高推理计算效率。此外，还引入了 Best-anchored Objective-guided Preference Optimization (BOPO) 训练方法。

Result: 在七个 NP-hard CO 问题上的实验表明，FALCON 实现了完美的解可行性，并且在解的质量上不逊色于甚至超越了现有的最先进的神经和基于 LLM 的求解器。

Conclusion: FALCON 框架能够保证组合优化问题的解可行性，并通过 BOPO 训练方法提高了 LLM 的性能，在实际应用中具有潜力。

Abstract: Large language models (LLMs) have emerged as promising general-purpose solvers for combinatorial optimization (CO), yet they fundamentally lack mechanisms to guarantee solution feasibility which is critical for real-world deployment. In this work, we introduce FALCON, a framework that ensures 100\% feasibility through three key innovations: (i) \emph{grammar-constrained decoding} enforces syntactic validity, (ii) a \emph{feasibility repair layer} corrects semantic constraint violations, and (iii) \emph{adaptive Best-of-$N$ sampling} allocates inference compute efficiently. To train the underlying LLM, we introduce the Best-anchored Objective-guided Preference Optimization (BOPO) in LLM training, which weights preference pairs by their objective gap, providing dense supervision without human labels. Theoretically, we prove convergence for BOPO and provide bounds on repair-induced quality loss. Empirically, across seven NP-hard CO problems, FALCON achieves perfect feasibility while matching or exceeding the solution quality of state-of-the-art neural and LLM-based solvers.

</details>


### [70] [Probing RLVR training instability through the lens of objective-level hacking](https://arxiv.org/abs/2602.01103)
*Yiming Dong,Kun Fu,Haoyu Li,Xinyuan Zhu,Yurou Liu,Lijing Shao,Jieping Ye,Zheng Wang*

Main category: cs.AI

TL;DR: 本研究提出了一种新的框架来理解和解决大型语言模型（LLM）在混合专家（MoE）架构中进行强化学习（RLVR）时的训练不稳定问题，该问题源于“目标层级攻击”，并导致训练-推理不匹配现象。


<details>
  <summary>Details</summary>
Motivation: RLVR能提升LLM的推理能力，但MoE架构下的训练不稳定是其应用中的一个严重问题，其原因和机制尚不明确。

Method: 提出了一种基于“目标层级攻击”的框架来分析RLVR训练不稳定问题，并将其与代币级别的信用错配联系起来，通过在300亿参数的MoE模型上进行大量实验，追踪并形式化了训练-推理不匹配的病态训练动态。

Result: 揭示了MoE模型中训练-推理不匹配现象的起源和机制，该现象与不稳定性密切相关，并且之前缺乏明确的机制解释。

Conclusion: 该研究为理解MoE模型中RLVR训练动态提供了具体和因果性的解释，并为设计更稳定的RLVR算法提供了指导。

Abstract: Prolonged reinforcement learning with verifiable rewards (RLVR) has been shown to drive continuous improvements in the reasoning capabilities of large language models, but the training is often prone to instabilities, especially in Mixture-of-Experts (MoE) architectures. Training instability severely undermines model capability improvement, yet its underlying causes and mechanisms remain poorly understood. In this work, we introduce a principled framework for understanding RLVR instability through the lens of objective-level hacking. Unlike reward hacking, which arises from exploitable verifiers, objective-level hacking emerges from token-level credit misalignment and is manifested as system-level spurious signals in the optimization objective. Grounded in our framework, together with extensive experiments on a 30B MoE model, we trace the origin and formalize the mechanism behind a key pathological training dynamic in MoE models: the abnormal growth of the training-inference discrepancy, a phenomenon widely associated with instability but previously lacking a mechanistic explanation. These findings provide a concrete and causal account of the training dynamics underlying instabilities in MoE models, offering guidance for the design of stable RLVR algorithms.

</details>


### [71] [Transforming Vehicle Diagnostics: A Multimodal Approach to Error Patterns Prediction](https://arxiv.org/abs/2602.01109)
*Hugo Math,Rainer Lienhart*

Main category: cs.AI

TL;DR: 提出了一种名为BiCarFormer的多模态Transformer模型，该模型结合了车辆故障码（DTCs）序列和环境传感器数据，用于对车辆故障进行多标签序列分类，并在真实数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有车辆诊断系统主要依赖DTC序列，但忽略了重要的上下文信息（如原始传感器数据），而这些信息对领域专家分类故障至关重要。这种上下文数据因其复杂性和噪声性质而具有挑战性。

Method: 提出BiCarFormer，一个多模态、双向Transformer模型。该模型融合了DTC序列和环境数据（温度、湿度、压力等）的嵌入，并利用协同注意力机制来捕捉两者之间的关系，以进行多标签序列分类。

Result: 在包含22,137个错误代码和360个错误模式的真实汽车数据集上进行实验，BiCarFormer相比仅使用DTC序列的模型和传统序列模型，显著提高了分类性能。

Conclusion: 将上下文环境信息纳入车辆诊断中对于提高准确性和鲁棒性至关重要，这有助于降低维护成本并增强汽车行业的自动化流程。BiCarFormer是第一个集成DTC序列和环境条件的此类多模态方法。

Abstract: Accurately diagnosing and predicting vehicle malfunctions is crucial for maintenance and safety in the automotive industry. While modern diagnostic systems primarily rely on sequences of vehicular Diagnostic Trouble Codes (DTCs) registered in On-Board Diagnostic (OBD) systems, they often overlook valuable contextual information such as raw sensory data (e.g., temperature, humidity, and pressure). This contextual data, crucial for domain experts to classify vehicle failures, introduces unique challenges due to its complexity and the noisy nature of real-world data. This paper presents BiCarFormer: the first multimodal approach to multi-label sequence classification of error codes into error patterns that integrates DTC sequences and environmental conditions. BiCarFormer is a bidirectional Transformer model tailored for vehicle event sequences, employing embedding fusions and a co-attention mechanism to capture the relationships between diagnostic codes and environmental data. Experimental results on a challenging real-world automotive dataset with 22,137 error codes and 360 error patterns demonstrate that our approach significantly improves classification performance compared to models that rely solely on DTC sequences and traditional sequence models. This work highlights the importance of incorporating contextual environmental information for more accurate and robust vehicle diagnostics, hence reducing maintenance costs and enhancing automation processes in the automotive industry.

</details>


### [72] [Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach](https://arxiv.org/abs/2602.01131)
*Yue Zhong,Jiawen Kang,Yongju Tong,Hong-Ning Dai,Dong In Kim,Abbas Jamalipour,Shengli Xie*

Main category: cs.AI

TL;DR: 该研究提出了一个集感知、通信、计算和控制于一体的闭环框架，用于在低空经济中优化无人机（UAV）作为空中基站的资源分配，以解决资源限制和控制稳定性之间的冲突。通过Lyapunov稳定性理论和Stackelberg博弈，并结合轻量级的基于剪枝的PPO算法，实现了在动态环境中最大化系统效用的同时保证控制回路的稳定性。


<details>
  <summary>Details</summary>
Motivation: 低空经济中无人机（UAV）作为空中基站面临有限的机载资源与严格的稳定性要求的冲突，传统以吞吐量为中心的设计无法满足异构网络的需求，尤其是在通信延迟对物理控制稳定性产生影响的情况下。

Method: 1. 提出一个集感知、通信、计算和控制于一体的闭环框架，明确建模通信延迟对物理控制稳定性的影响。 2. 利用Lyapunov稳定性理论推导出控制系统状态演变与通信约束之间的内在映射，将稳定性要求转化为可量化的资源边界。 3. 将资源分配问题建模为Stackelberg博弈，无人机作为领导者动态定价以平衡负载和确保稳定性，用户作为跟随者根据服务紧急程度优化请求。 4. 提出一种轻量级的基于剪枝的Proximal Policy Optimization (PPO)算法，通过动态结构化剪枝机制压缩神经网络规模，以在能量受限的边缘平台上快速逼近博弈均衡。

Result: 仿真结果表明，所提出的方案能够有效保证控制回路的稳定性，并在动态的低空环境中最大化系统效用。

Conclusion: 该研究成功地解决在资源受限且需要高稳定性的低空经济中，UAV作为空中基站的资源分配问题，通过提出的闭环框架、基于博弈论的资源定价和轻量级DRL算法，实现了在保障控制稳定性的前提下最大化系统整体性能。

Abstract: With the rapid expansion of the low-altitude economy, Unmanned Aerial Vehicles (UAVs) serve as pivotal aerial base stations supporting diverse services from users, ranging from latency-sensitive critical missions to bandwidth-intensive data streaming. However, the efficacy of such heterogeneous networks is often compromised by the conflict between limited onboard resources and stringent stability requirements. Moving beyond traditional throughput-centric designs, we propose a Sensing-Communication-Computing-Control closed-loop framework that explicitly models the impact of communication latency on physical control stability. To guarantee mission reliability, we leverage the Lyapunov stability theory to derive an intrinsic mapping between the state evolution of the control system and communication constraints, transforming abstract stability requirements into quantifiable resource boundaries. Then, we formulate the resource allocation problem as a Stackelberg game, where UAVs (as leaders) dynamically price resources to balance load and ensure stability, while users (as followers) optimize requests based on service urgency. Furthermore, addressing the prohibitive computational overhead of standard Deep Reinforcement Learning (DRL) on energy-constrained edge platforms, we propose a novel and lightweight pruning-based Proximal Policy Optimization (PPO) algorithm. By integrating a dynamic structured pruning mechanism, the proposed algorithm significantly compresses the neural network scale during training, enabling the UAV to rapidly approximate the game equilibrium with minimal inference latency. Simulation results demonstrate that the proposed scheme effectively secures control loop stability while maximizing system utility in dynamic low-altitude environments.

</details>


### [73] [PersistBench: When Should Long-Term Memories Be Forgotten by LLMs?](https://arxiv.org/abs/2602.01146)
*Sidharth Pulipaka,Oliver Chen,Manas Sharma,Taaha S Bajwa,Vyas Raina,Ivaxi Sheth*

Main category: cs.AI

TL;DR: 本文提出了 PersistBench 评测基准，用于衡量具有长时记忆能力的对话助手在引入记忆持久性后产生的安全风险，具体包括跨领域信息泄露和记忆诱导的迎合现象。评测发现，现有的大型语言模型在这些风险上面临着普遍的失败。


<details>
  <summary>Details</summary>
Motivation: 随着对话助手集成LLM的长时记忆功能以增强个性化，但这种持久性也带来了被忽视的安全风险，促使研究者开发相应的评测方法。

Method: 本文构建了 PersistBench 评测基准，识别并定义了两种长时记忆特有的风险：跨领域信息泄露（LLM不当注入长时记忆中的上下文）和记忆诱导的迎合（存储的长时记忆强化用户偏见）。使用该基准对18个前沿和开源LLM进行了评估。

Result: 在 PersistBench 上的评估结果显示，LLM的失败率出人意料地高：跨领域样本的中位数失败率为53%，记忆诱导的迎合样本的中位数失败率为97%。

Conclusion: 长时记忆的引入为对话助手带来了显著的安全风险，现有的大型语言模型在应对这些风险方面表现不佳。PersistBench 的提出旨在推动开发更健壮、更安全的对话系统长时记忆机制。

Abstract: Conversational assistants are increasingly integrating long-term memory with large language models (LLMs). This persistence of memories, e.g., the user is vegetarian, can enhance personalization in future conversations. However, the same persistence can also introduce safety risks that have been largely overlooked. Hence, we introduce PersistBench to measure the extent of these safety risks. We identify two long-term memory-specific risks: cross-domain leakage, where LLMs inappropriately inject context from the long-term memories; and memory-induced sycophancy, where stored long-term memories insidiously reinforce user biases. We evaluate 18 frontier and open-source LLMs on our benchmark. Our results reveal a surprisingly high failure rate across these LLMs - a median failure rate of 53% on cross-domain samples and 97% on sycophancy samples. To address this, our benchmark encourages the development of more robust and safer long-term memory usage in frontier conversational systems.

</details>


### [74] [Capabilities and Fundamental Limits of Latent Chain-of-Thought](https://arxiv.org/abs/2602.01148)
*Jiaxuan Zou,Yaozhong Xiong,Yong Liu*

Main category: cs.AI

TL;DR: 本研究揭示了潜变量链式思考（Latent CoT）模型在探索和计算任务上表现不一致的原因在于决策确定性，并提出了通过符号索引（Symbolic Index）来量化和调控该确定性的方法，同时证明了课程学习的必要性。


<details>
  <summary>Details</summary>
Motivation: Latent CoT 模型在探索性任务上表现优异，但在计算性任务上表现不佳，这种性能不一致的现象需要解释和解决。

Method: 1. 理论分析：推导并证明了探索-执行权衡（Exploration-Execution Trade-off）的数学模型，揭示了决策确定性与探索/执行能力之间的关系。 2. 引入符号索引：将符号索引作为量化决策确定性的核心机制，并建立其与执行稳定性和探索能力之间的因果关系。 3. 证明课程学习的必要性：理论证明直接训练会因分布不匹配而失败，因此课程学习是必需的。

Result: 研究表明，高决策确定性有利于精确执行但阻碍探索，而低决策确定性则有利于搜索但会导致错误累积。符号索引是控制这种权衡的关键。课程学习在理论上是必需的。

Conclusion: Latent CoT 模型性能的不一致性源于决策确定性。通过符号索引可以量化和调控这种确定性，从而实现适应不同任务需求的自适应系统，并需要采用课程学习来克服训练中的挑战。

Abstract: Latent Chain-of-Thought (Latent CoT) models promise efficient reasoning via continuous representations, yet exhibit puzzling performance inconsistencies: excelling at exploration (ProsQA: 97.0%) but failing at computation (GSM8K: 34.1%). We reveal that this trade-off is governed by decisional certainty. Our contributions are threefold: (1) We theoretically characterize the fundamental Exploration-Execution Trade-off, proving that high certainty enables precise execution but inhibits exploration, while low certainty facilitates search but causes error accumulation. (2) We introduce the Symbolic Index--quantifying decisional commitment--as the core mechanism governing this trade-off and establish its causal relationship with both execution stability and exploration capability. (3) We prove that curriculum learning is theoretically necessary, as direct training provably fails due to distributional mismatch. Our framework shifts the design paradigm from binary architectural choices toward adaptive systems that dynamically regulate decisional certainty based on task demands.

</details>


### [75] [Multi-Agent Causal Reasoning System for Error Pattern Rule Automation in Vehicles](https://arxiv.org/abs/2602.01155)
*Hugo Math,Julian Lorentz,Stefan Oelsner,Rainer Lienhart*

Main category: cs.AI

TL;DR: 本文提出了一种名为CAREP的多智能体系统，用于自动化生成汽车故障诊断码（DTC）的错误模式（EP）规则，以取代耗时且易出错的人工方法。


<details>
  <summary>Details</summary>
Motivation: 目前汽车故障诊断中的错误模式规则（EP）是手动创建的，随着汽车复杂度的增加，这种方法变得昂贵且容易出错。因此，需要一种自动化方法来生成这些规则。

Method: CAREP是一个多智能体系统，包括一个因果发现智能体（识别DTC与EP的关系）、一个上下文信息智能体（整合元数据和描述）和一个协调者智能体（合成布尔规则并提供可解释的推理过程）。

Result: 在包含超过29,100个DTC和474个EP的大规模汽车数据集上进行评估，CAREP能够自动且准确地发现未知的EP规则，其性能优于仅使用大型语言模型（LLM）的基线方法，并能提供透明的因果解释。

Conclusion: CAREP通过结合因果发现和基于智能体的推理，实现了错误模式规则的自动化生成，是实现全自动化故障诊断的重要一步，有助于提高车辆维护的可扩展性、可解释性和成本效益。

Abstract: Modern vehicles generate thousands of different discrete events known as Diagnostic Trouble Codes (DTCs). Automotive manufacturers use Boolean combinations of these codes, called error patterns (EPs), to characterize system faults and ensure vehicle safety. Yet, EP rules are still manually handcrafted by domain experts, a process that is expensive and prone to errors as vehicle complexity grows. This paper introduces CAREP (Causal Automated Reasoning for Error Patterns), a multi-agent system that automatizes the generation of EP rules from high-dimensional event sequences of DTCs. CAREP combines a causal discovery agent that identifies potential DTC-EP relations, a contextual information agent that integrates metadata and descriptions, and an orchestrator agent that synthesizes candidate boolean rules together with interpretable reasoning traces. Evaluation on a large-scale automotive dataset with over 29,100 unique DTCs and 474 error patterns demonstrates that CAREP can automatically and accurately discover the unknown EP rules, outperforming LLM-only baselines while providing transparent causal explanations. By uniting practical causal discovery and agent-based reasoning, CAREP represents a step toward fully automated fault diagnostics, enabling scalable, interpretable, and cost-efficient vehicle maintenance.

</details>


### [76] [Do All Individual Layers Help? An Empirical Study of Task-Interfering Layers in Vision-Language Models](https://arxiv.org/abs/2602.01167)
*Zhiming Liu,Yujie Wei,Lei Feng,Xiu Su,Xiaobo Xia,Weili Guan,Zeke Xie,Shuo Yang*

Main category: cs.AI

TL;DR: 研究发现预训练的视觉-语言模型（VLM）中存在“任务干扰层”，这些层反而会损害特定下游任务的表现。作者提出了一种名为TaLo（Task-Adaptive Layer Knockout）的训练无关、推理时自适应方法，通过动态识别并跳过这些干扰层来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前的预训练VLM在下游任务中默认启用所有层，但作者观察到干预（如参数归零）某些层反而能提升特定任务的表现，这表明存在干扰任务的层，激励作者深入研究这种现象。

Method: 通过系统地干预（例如，将层参数归零）VLM的每一层，并衡量其对不同任务性能的影响。引入“任务-层交互向量”来量化干预每一层对特定任务的效果。在此基础上，提出TaLo方法，在测试时动态识别并跳过对当前任务干扰最大的层。

Result: 发现存在“任务干扰层”，这些层会对下游任务的表现产生负面影响。这种现象在不同模型和数据集上具有泛化性。任务-层交互向量可以量化层干预的效果，并且显示出任务的特异性（相似任务有相似的层干预响应模式）。TaLo方法在不进行参数更新的情况下，在多个模型和数据集上提升了性能，例如在ScienceQA的Maps任务上将Qwen-VL的准确率提高了16.6%。

Conclusion: 预训练的VLM中存在一种意料之外的模块化特性，即存在对特定任务产生负面影响的“任务干扰层”。TaLo作为一种即插即用、无需训练的推理时自适应机制，能够有效识别并利用这些干扰层，从而释放VLM的隐藏能力，提升其在下游任务上的表现。

Abstract: Current VLMs have demonstrated capabilities across a wide range of multimodal tasks. Typically, in a pretrained VLM, all layers are engaged by default to make predictions on downstream tasks. We find that intervening on a single layer, such as by zeroing its parameters, can improve the performance on certain tasks, indicating that some layers hinder rather than help downstream tasks. We systematically investigate how individual layers influence different tasks via layer intervention. Specifically, we measure the change in performance relative to the base model after intervening on each layer and observe improvements when bypassing specific layers. This improvement can be generalizable across models and datasets, indicating the presence of Task-Interfering Layers that harm downstream tasks' performance. We introduce Task-Layer Interaction Vector, which quantifies the effect of intervening on each layer of a VLM given a task. These task-interfering layers exhibit task-specific sensitivity patterns: tasks requiring similar capabilities show consistent response trends under layer interventions, as evidenced by the high similarity in their task-layer interaction vectors. Inspired by these findings, we propose TaLo (Task-Adaptive Layer Knockout), a training-free, test-time adaptation method that dynamically identifies and bypasses the most interfering layer for a given task. Without parameter updates, TaLo improves performance across various models and datasets, including boosting Qwen-VL's accuracy on the Maps task in ScienceQA by up to 16.6%. Our work reveals an unexpected form of modularity in pretrained VLMs and provides a plug-and-play, training-free mechanism to unlock hidden capabilities at inference time. The source code will be publicly available.

</details>


### [77] [ASP-Bench: From Natural Language to Logic Programs](https://arxiv.org/abs/2602.01171)
*Stefan Szeider*

Main category: cs.AI

TL;DR: 本文提出了一种名为ASP-Bench的基准测试集，包含128个自然语言问题实例，用于评估将自然语言问题转化为Answer Set Programs (ASPs) 的系统。该基准测试覆盖了ASP的多种特性，并提供了多维度的难度评估，同时验证了一个基于ReAct框架的智能体方法在解决这些问题上的有效性。


<details>
  <summary>Details</summary>
Motivation: 自动化将自然语言规范翻译成逻辑程序（尤其是ASP）是一个具有挑战性的问题，对于神经符号工程至关重要，但缺乏标准化的评估工具。

Method: 构建了一个包含128个自然语言问题实例的基准测试集（ASP-Bench），涵盖了ASP的多种特性（如选择规则、聚合、优化）。为每个问题设计了参考验证器。通过分析问题在七个推理维度（优化、时序、默认逻辑、资源分配、递归、空间推理、定量复杂性）上的表现来表征其难度。使用基于ReAct框架的智能体方法来测试该基准测试。

Result: 基于ReAct框架的智能体方法在ASP-Bench上达到了完全饱和，证明了通过求解器反馈进行驱动的迭代优化是处理自然语言到ASP建模的可靠方法。分析表明，特定推理维度对建模难度有显著影响。

Conclusion: ASP-Bench为评估自然语言到ASP的翻译系统提供了一个系统化的基准。基于ReAct的智能体方法能够有效地解决该基准测试中的问题，并表明通过反馈迭代可以改善建模过程。该基准测试有助于理解不同推理方面如何影响建模的难度。

Abstract: Automating the translation of natural-language specifications into logic programs is a challenging task that affects neurosymbolic engineering. We present ASP-Bench, a benchmark comprising 128 natural language problem instances, 64 base problems with easy and hard variants. It evaluates systems that translate natural-language problems into Answer Set Programs (ASPs), a prominent form of logic programming. It provides systematic coverage of ASP features, including choice rules, aggregates, and optimization. Each problem includes reference validators that check whether solutions satisfy the problem specification.
  We characterize problems along seven largely independent reasoning aspects (optimization, temporal reasoning, default logic, resource allocation, recursion, spatial reasoning, and quantitative complexity), providing a multidimensional view of modeling difficulty.
  We test the benchmark using an agentic approach based on the ReAct (Reason and Act) framework, which achieves full saturation, demonstrating that feedback-driven iterative refinement with solver feedback provides a reliable and robust approach for modeling natural language in ASP. Our analysis across multiple agent runs enables us to gain insights into what determines a problem's modeling hardness.

</details>


### [78] [A State-Transition Framework for Efficient LLM Reasoning](https://arxiv.org/abs/2602.01198)
*Liang Zhang,Yu Zhao,Longyue Wang,Tianqi Shi,Weihua Luo,Kaifu Zhang,Jinsong Su*

Main category: cs.AI

TL;DR: 本文提出了一种将 LLM 的推理过程建模为状态转换的框架，使用线性注意力机制来管理推理状态，从而降低了计算复杂性，并引入了基于状态的推理策略来解决过度思考问题，从而提高了 LLM 的推理效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大量长链式思考（CoT）推理虽然提高了 LLM 的性能，但其高昂的计算和内存成本限制了其实用性。而现有的压缩 CoT 的方法又会与测试时扩展冲突，限制了 LLM 的推理能力。

Method: 提出了一种将 LLM 的推理过程建模为状态转换的框架。首先，使用线性注意力机制来估计 LLM 的推理状态（记录历史推理信息）。然后，基于查询提示和推理状态，LLM 可以高效地执行当前推理步骤并更新状态。线性注意力机制将计算复杂度从二次降至线性。此外，还提出了一种基于状态的推理策略来缓解由噪声推理步骤引起的过度思考问题。

Result: 在多个数据集和模型规模上的广泛实验表明，该框架显著提高了 LLM 的推理效率，并增强了其推理性能。

Conclusion: 所提出的高效推理框架通过将推理过程建模为状态转换并利用线性注意力机制，有效解决了长 CoT 的效率问题，同时通过状态驱动的推理策略提升了性能，为 LLM 的高效推理提供了新的解决方案。

Abstract: While Long Chain-of-Thought (CoT) reasoning significantly improves Large Language Models (LLMs) performance on complex reasoning tasks, the substantial computational and memory costs of generating long CoT sequences limit their efficiency and practicality. Existing studies usually enhance the reasoning efficiency of LLMs by compressing CoT sequences. However, this approach conflicts with test-time scaling, limiting the reasoning capacity of LLMs. In this paper, we propose an efficient reasoning framework that models the reasoning process of LLMs as a state-transition process. Specifically, we first apply a linear attention mechanism to estimate the LLM's reasoning state, which records the historical reasoning information from previous reasoning steps. Then, based on the query prompt and the reasoning state, the LLM can efficiently perform the current reasoning step and update the state. With the linear attention, each token in the current reasoning step can directly retrieve relevant historical reasoning information from the reasoning state, without explicitly attending to tokens in previous reasoning steps. In this way, the computational complexity of attention is reduced from quadratic to linear, significantly improving the reasoning efficiency of LLMs. In addition, we propose a state-based reasoning strategy to mitigate the over-thinking issue caused by noisy reasoning steps. Extensive experiments across multiple datasets and model sizes demonstrate that our framework not only improves the reasoning efficiency of LLMs but also enhances their reasoning performance.

</details>


### [79] [Workflow-R1: Group Sub-sequence Policy Optimization for Multi-turn Workflow Construction](https://arxiv.org/abs/2602.01202)
*Mingze Kong,Zikun Qu,Zhongquan Zhou,Pengyu Liang,Xiang Li,Zhiwei Shang,Zhi Hong,Kaiyu Huang,Zhiyong Wang,Zhongxiang Dai*

Main category: cs.AI

TL;DR: 本文提出了一种名为 Workflow-R1 的新框架，将工作流构建视为多轮自然语言交互式的顺序决策过程，并引入了一种名为 GSsPO 的结构感知强化学习算法来优化这一过程，该算法通过将优化单元调整为原子式的“思考-行动”周期来解决细粒度匹配问题，并在 QA 任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于 LLM 的智能体工作流优化方法通常将工作流合成视为静态、一次性的代码生成问题，这限制了模型在动态问题解决方面的灵活性，并对其编码能力提出了过高要求。

Method: 提出 Workflow-R1 框架，将工作流构建重塑为多轮、基于自然语言的顺序决策过程。引入 Group Sub-sequence Policy Optimization (GSsPO) 算法，这是一种结构感知强化学习算法，通过将优化单位调整为“思考-行动”原子周期来解决多轮交互中的优化粒度不匹配问题。

Result: Workflow-R1 在多个 QA 基准测试上进行了实验，其性能优于有竞争力的基线方法。

Conclusion: GSsPO 被验证为一种通用的顺序推理解决方案，Workflow-R1 提供了一种新的自动化工作流优化范式。

Abstract: The rapid evolution of agentic workflows has demonstrated strong performance of LLM-based agents in addressing complex reasoning tasks. However, existing workflow optimization methods typically formulate workflow synthesis as a static, one-shot code-centric generation problem. This paradigm imposes excessive constraints on the model's coding capabilities and restricts the flexibility required for dynamic problem-solving. In this paper, we present Workflow-R1, a framework that reformulates workflow construction as a multi-turn, natural language-based sequential decision-making process. To resolve the optimization granularity mismatch inherent in such multi-turn interactions, we introduce Group Sub-sequence Policy Optimization (GSsPO). While explicitly tailored to align with the interleaved Think-Action dynamics of agentic reasoning, GSsPO fundamentally functions as a structure-aware RL algorithm generalizable to a broad class of multi-turn agentic sequential decision-making tasks. By recalibrating the optimization unit to the composite sub-sequence, specifically the atomic Think-Action cycle, it aligns gradient updates with the semantic boundaries of these interactions, ensuring robust learning in complex multi-turn reasoning tasks. Through extensive experiments on multiple QA benchmarks, Workflow-R1 outperforms competitive baselines, validating GSsPO as a generalized solution for sequential reasoning and establishing Workflow-R1 as a promising new paradigm for automated workflow optimization.

</details>


### [80] [Addressing Explainability of Generative AI using SMILE (Statistical Model-agnostic Interpretability with Local Explanations)](https://arxiv.org/abs/2602.01206)
*Zeinab Dehghani*

Main category: cs.AI

TL;DR: 本论文提出了一种名为 gSMILE 的通用框架，用于增强生成式人工智能模型（如 LLMs 和图像编辑模型）的可解释性。gSMILE 通过输入扰动和距离度量来量化提示和指令对模型输出的影响，并生成可视化结果，以提高生成式 AI 的透明度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能模型（如 LLMs 和图像编辑模型）的决策过程不透明，这限制了它们在高风险应用中的信任度和可问责性。

Method: gSMILE 框架扩展了 SMILE 方法，通过受控的文本输入扰动、Wasserstein 距离度量和加权代理建模来量化和可视化输入组件对模型输出的影响。对于 LLMs，gSMILE 提供细粒度的 token 级别归因和可视化热图；对于图像编辑模型，它分析编辑指令的修改对生成图像的影响。此外，研究还采用了基于 ODD 框架的场景评估策略和一套严格的归因指标（稳定性、保真度、准确性、一致性和忠实度）来评估解释质量。

Result: gSMILE 在 LLMs 和指令驱动的图像编辑模型上表现良好，能够生成人类可理解的、细粒度的 token 级别归因和可视化热图。实验证明 gSMILE 产生的归因是稳定、准确且忠实的，并且能够跨多种生成式模型泛化。

Conclusion: gSMILE 是一个通用的、模型无关的生成式模型可解释性框架。它能够为理解和评估生成式 AI 模型的行为提供重要的见解，从而促进透明、可靠和负责任的生成式 AI 技术部署。

Abstract: The rapid advancement of generative artificial intelligence has enabled models capable of producing complex textual and visual outputs; however, their decision-making processes remain largely opaque, limiting trust and accountability in high-stakes applications. This thesis introduces gSMILE, a unified framework for the explainability of generative models, extending the Statistical Model-agnostic Interpretability with Local Explanations (SMILE) method to generative settings. gSMILE employs controlled perturbations of textual input, Wasserstein distance metrics, and weighted surrogate modelling to quantify and visualise how specific components of a prompt or instruction influence model outputs. Applied to Large Language Models (LLMs), gSMILE provides fine-grained token-level attribution and generates intuitive heatmaps that highlight influential tokens and reasoning pathways. In instruction-based image editing models, the exact text-perturbation mechanism is employed, allowing for the analysis of how modifications to an editing instruction impact the resulting image. Combined with a scenario-based evaluation strategy grounded in the Operational Design Domain (ODD) framework, gSMILE allows systematic assessment of model behaviour across diverse semantic and environmental conditions. To evaluate explanation quality, we define rigorous attribution metrics, including stability, fidelity, accuracy, consistency, and faithfulness, and apply them across multiple generative architectures. Extensive experiments demonstrate that gSMILE produces robust, human-aligned attributions and generalises effectively across state-of-the-art generative models. These findings highlight the potential of gSMILE to advance transparent, reliable, and responsible deployment of generative AI technologies.

</details>


### [81] [Not All Preferences Are Created Equal: Stability-Aware and Gradient-Efficient Alignment for Reasoning Models](https://arxiv.org/abs/2602.01207)
*Hui Wu,Hengyi Cai,Jinman Zhao,Xinran Chen,Ziheng Li,Zhejun Zhao,Shuaiqiang Wang,Yuchen Li,Dawei Yin*

Main category: cs.AI

TL;DR: 本文提出了一种名为 SAGE 的新框架，用于改进基于偏好的模型对齐。SAGE 通过动态选择训练数据来提高效率和稳定性，优先处理具有高信号噪声比的样本，尤其关注那些模型出错但确信的样本。


<details>
  <summary>Details</summary>
Motivation: 现有的基于偏好的对齐方法（如 DPO）将所有偏好对一视同仁，忽略了训练样本的动态效用。这种静态方法会导致低效甚至不稳定的优化，因为它会浪费计算资源在梯度可忽略的平凡样本上，并且会受到不确定决策边界附近样本引起的噪声影响。

Method: SAGE 框架结合了两种机制：1. 粗粒度的课程学习机制，根据模型的胜任能力刷新候选样本池。2. 细粒度的、感知稳定性的评分函数，优先选择信息量大且模型出错时确信的样本，同时过滤掉不稳定的样本。目标是最大化策略更新的信噪比。

Result: 在多个数学推理基准测试上进行实验，SAGE 显著加速了收敛速度，并且优于静态基线方法。

Conclusion: SAGE 证明了策略感知、稳定性意识的数据选择对于推理对齐至关重要，能够有效提高对齐的可靠性。

Abstract: Preference-based alignment is pivotal for training large reasoning models; however, standard methods like Direct Preference Optimization (DPO) typically treat all preference pairs uniformly, overlooking the evolving utility of training instances. This static approach often leads to inefficient or unstable optimization, as it wastes computation on trivial pairs with negligible gradients and suffers from noise induced by samples near uncertain decision boundaries. Facing these challenges, we propose SAGE (Stability-Aware Gradient Efficiency), a dynamic framework designed to enhance alignment reliability by maximizing the Signal-to-Noise Ratio of policy updates. Concretely, SAGE integrates a coarse-grained curriculum mechanism that refreshes candidate pools based on model competence with a fine-grained, stability-aware scoring function that prioritizes informative, confident errors while filtering out unstable samples. Experiments on multiple mathematical reasoning benchmarks demonstrate that SAGE significantly accelerates convergence and outperforms static baselines, highlighting the critical role of policy-aware, stability-conscious data selection in reasoning alignment.

</details>


### [82] [FutureMind: Equipping Small Language Models with Strategic Thinking-Pattern Priors via Adaptive Knowledge Distillation](https://arxiv.org/abs/2602.01222)
*Shaoxiong Yang,Junting Li,Mengyuan Zhang,Chao Li,Wei Liu,Jian Luan*

Main category: cs.AI

TL;DR: FutureMind 是一个创新的框架，通过从大型语言模型（LLM）进行知识蒸馏，增强了小型语言模型（SLM）的推理能力，使其在复杂任务上表现出色，并实现了当前最先进的性能。


<details>
  <summary>Details</summary>
Motivation: SLM 在成本和延迟方面具有优势，但在处理需要结构化推理和知识检索的复杂任务时存在不足。研究动机在于弥合 SLM 在这些复杂任务上的能力差距。

Method: 提出 FutureMind 框架，包含问题分析、逻辑推理、策略规划和检索指导四个模块。该框架利用自适应知识蒸馏，将 LLM 的思考模式先验知识转移到 SLM。同时，引入了三种检索范式来分解复杂查询。

Result: 在 2WikiMultihopQA, MuSiQue, Bamboogle, 和 Frames 等多跳问答基准测试中，FutureMind 展现出卓越的性能，超越了 Search-o1 等强基线模型，并在不同 SLM 架构和规模下取得了当前最先进的成果。

Conclusion: FutureMind 成功地提升了 SLM 在复杂推理任务上的表现，证明了思考模式蒸馏的有效性。研究还揭示了师生模型间的认知偏差瓶颈，为未来开发兼具效率和认知能力的 SLM 提供了新视角。

Abstract: Small Language Models (SLMs) are attractive for cost-sensitive and resource-limited settings due to their efficient, low-latency inference. However, they often struggle with complex, knowledge-intensive tasks that require structured reasoning and effective retrieval. To address these limitations, we propose FutureMind, a modular reasoning framework that equips SLMs with strategic thinking-pattern priors via adaptive knowledge distillation from large language models (LLMs). FutureMind introduces a dynamic reasoning pipeline composed of four key modules: Problem Analysis, Logical Reasoning, Strategy Planning, and Retrieval Guidance. This pipeline is augmented by three distinct retrieval paradigms that decompose complex queries into tractable subproblems, ensuring efficient and accurate retrieval execution. Extensive experiments on multi-hop QA benchmarks, including 2WikiMultihopQA, MuSiQue, Bamboogle, and Frames, demonstrate the superiority of FutureMind. It consistently outperforms strong baselines such as Search-o1, achieving state-of-the-art results under free training conditions across diverse SLM architectures and scales. Beyond empirical gains, our analysis reveals that the process of thinking-pattern distillation is restricted by the cognitive bias bottleneck between the teacher (LLMs) and student (SLMs) models. This provides new perspectives on the transferability of reasoning skills, paving the way for the development of SLMs that combine efficiency with genuine cognitive capability.

</details>


### [83] [Predictive Scheduling for Efficient Inference-Time Reasoning in Large Language Models](https://arxiv.org/abs/2602.01237)
*Katrina Brown,Aneesh Muppidi,Rana Shahout*

Main category: cs.AI

TL;DR: 该研究提出了一种名为“预测调度”（Predictive Scheduling）的框架，通过预先运行轻量级预测器来估计每个查询的最佳推理长度，从而动态分配固定的总 token 预算，以在计算成本相同的情况下最大化 LLM 的准确性，特别是在 GSM8K 基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的 LLM 在进行复杂推理时，会生成多个链式思考（CoT）路径。然而，当使用固定的 token 预算时，这会导致对简单输入过度计算，而对困难输入计算不足，从而影响效率和准确性。

Method: 引入了一个名为“预测调度”的即插即用框架。该框架使用轻量级预测器（基于中间 transformer 隐藏状态的 MLP 或基于原始问题文本的 LoRA 微调分类器）来预估查询的最佳推理长度或难度。然后，一个贪婪的批处理分配器根据这些估计动态地将总 token 预算分配给不同的查询，以最大化期望准确率。

Result: 在 GSM8K 算术基准测试中，与均匀分配预算相比，预测调度在相同 token 成本下，准确率提高了高达 7.9 个百分点。该方法能够弥补超过 50% 的与完美预知（oracle）之间的差距。研究还发现，transformer 的中间层（12-17 层）包含了最丰富的用于估计推理长度的信号。

Conclusion: 预运行的预算预测能够实现对计算-准确率权衡的精细控制，为 LLM 在对延迟敏感和成本效益要求高的场景下的部署提供了一条切实可行的途径。

Abstract: Large language models (LLMs) achieve state-of-the-art accuracy on complex reasoning tasks by generating multiple chain-of-thought (CoT) traces, but using a fixed token budget per query leads to over-computation on easy inputs and under-computation on hard ones. We introduce Predictive Scheduling, a plug-and-play framework that pre-runs lightweight predictors, an MLP on intermediate transformer hidden states or a LoRA-fine-tuned classifier on raw question text, to estimate each query's optimal reasoning length or difficulty before any full generation. Our greedy batch allocator dynamically distributes a fixed total token budget across queries to maximize expected accuracy. On the GSM8K arithmetic benchmark, predictive scheduling yields up to 7.9 percentage points of absolute accuracy gain over uniform budgeting at identical token cost, closing over 50\% of the gap to an oracle with perfect foresight. A systematic layer-wise study reveals that middle layers (12 - 17) of the transformer carry the richest signals for size estimation. These results demonstrate that pre-run budget prediction enables fine-grained control of the compute-accuracy trade-off, offering a concrete path toward latency-sensitive, cost-efficient LLM deployments.

</details>


### [84] [LLM-Driven Ontology Construction for Enterprise Knowledge Graphs](https://arxiv.org/abs/2602.01276)
*Abdulsobur Oyewale,Tommaso Soru*

Main category: cs.AI

TL;DR: 本文提出了一种名为OntoEKG的LLM驱动的管道，用于从非结构化企业数据中自动生成领域本体，以解决手动构建本体耗时且依赖领域专家的问题。该方法分为提取和推理两个阶段，并在新的数据集上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 现有企业知识图谱的构建依赖于耗时且需要领域专业知识的手动本体构建过程。研究旨在加速这一过程，降低对人工的依赖。

Method: 提出OntoEKG流水线，包括一个提取模块（识别核心类和属性）和一个推理模块（逻辑构建层次结构并序列化为RDF）。使用从数据、金融和物流领域文档生成的新评估数据集。

Result: 在数据领域实现了0.724的模糊匹配F1分数。实验结果表明了该方法的潜力，但也揭示了在范围定义和层次推理方面的局限性。

Conclusion: OntoEKG是一种有前途的LLM驱动方法，可以加速领域本体的生成，但仍需进一步改进以克服在范围定义和层次推理方面的挑战。

Abstract: Enterprise Knowledge Graphs have become essential for unifying heterogeneous data and enforcing semantic governance. However, the construction of their underlying ontologies remains a resource-intensive, manual process that relies heavily on domain expertise. This paper introduces OntoEKG, a LLM-driven pipeline designed to accelerate the generation of domain-specific ontologies from unstructured enterprise data. Our approach decomposes the modelling task into two distinct phases: an extraction module that identifies core classes and properties, and an entailment module that logically structures these elements into a hierarchy before serialising them into standard RDF. Addressing the significant lack of comprehensive benchmarks for end-to-end ontology construction, we adopt a new evaluation dataset derived from documents across the Data, Finance, and Logistics sectors. Experimental results highlight both the potential and the challenges of this approach, achieving a fuzzy-match F1-score of 0.724 in the Data domain while revealing limitations in scope definition and hierarchical reasoning.

</details>


### [85] [RE-MCDF: Closed-Loop Multi-Expert LLM Reasoning for Knowledge-Grounded Clinical Diagnosis](https://arxiv.org/abs/2602.01297)
*Shaowei Shen,Xiaohong Yang,Jie Yang,Lianfen Huang,Yongcai Zhang,Yang Zou,Seyyedali Hosseinalipour*

Main category: cs.AI

TL;DR: 提出了一种名为RE-MCDF的关系增强多专家临床诊断框架，用于解决电子病历（EMRs）数据异构、稀疏和嘈杂的问题，以及现有临床诊断方法中存在的逻辑依赖性不足和容易自我强化错误的问题。该框架通过生成-验证-修正的闭环架构，集成了三个专家组件：主专家生成候选诊断和证据，实验室专家优先考虑临床指标，多关系感知和评估专家组强制执行疾病间的逻辑约束。实验结果表明，RE-MCDF在复杂诊断场景下优于现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 电子病历数据（尤其是在神经病学领域）的异构性、稀疏性和噪声给大型语言模型（LLMs）的临床诊断带来了巨大挑战。单智能体系统容易出现自我强化错误，而现有的多智能体框架交互浅层且结构松散，未能充分利用疾病间的丰富逻辑依赖关系（如互斥性、病理兼容性、诊断混淆），导致无法排除临床上不合理的假设。

Method: 提出RE-MCDF框架，采用生成-验证-修正的闭环架构，包含三个核心组件：（1）主专家：负责生成候选诊断和支持性证据；（2）实验室专家：动态优先考虑异构的临床指标；（3）多关系感知和评估专家组：明确强制执行疾病间的逻辑约束。该框架以医学知识图谱（MKG）为指导，前两个专家自适应地重新加权EMR证据，专家组负责验证和修正候选诊断，以确保逻辑一致性。

Result: 在CMEMR（NEEMRs）的神经病学子集和XMEMRs数据集上的广泛实验表明，RE-MCDF在复杂的诊断场景下，一致性地优于最先进的基线方法。

Conclusion: RE-MCDF框架通过整合生成-验证-修正的闭环架构以及显式处理疾病间的逻辑关系，有效地克服了现有临床诊断方法在处理异构、稀疏、嘈杂的EMR数据以及利用疾病逻辑依赖性方面的局限性，并在复杂诊断任务中展现出优越的性能。

Abstract: Electronic medical records (EMRs), particularly in neurology, are inherently heterogeneous, sparse, and noisy, which poses significant challenges for large language models (LLMs) in clinical diagnosis. In such settings, single-agent systems are vulnerable to self-reinforcing errors, as their predictions lack independent validation and can drift toward spurious conclusions. Although recent multi-agent frameworks attempt to mitigate this issue through collaborative reasoning, their interactions are often shallow and loosely structured, failing to reflect the rigorous, evidence-driven processes used by clinical experts. More fundamentally, existing approaches largely ignore the rich logical dependencies among diseases, such as mutual exclusivity, pathological compatibility, and diagnostic confusion. This limitation prevents them from ruling out clinically implausible hypotheses, even when sufficient evidence is available. To overcome these, we propose RE-MCDF, a relation-enhanced multi-expert clinical diagnosis framework. RE-MCDF introduces a generation--verification--revision closed-loop architecture that integrates three complementary components: (i) a primary expert that generates candidate diagnoses and supporting evidence, (ii) a laboratory expert that dynamically prioritizes heterogeneous clinical indicators, and (iii) a multi-relation awareness and evaluation expert group that explicitly enforces inter-disease logical constraints. Guided by a medical knowledge graph (MKG), the first two experts adaptively reweight EMR evidence, while the expert group validates and corrects candidate diagnoses to ensure logical consistency. Extensive experiments on the neurology subset of CMEMR (NEEMRs) and on our curated dataset (XMEMRs) demonstrate that RE-MCDF consistently outperforms state-of-the-art baselines in complex diagnostic scenarios.

</details>


### [86] [Model Specific Task Similarity for Vision Language Model Selection via Layer Conductance](https://arxiv.org/abs/2602.01346)
*Wei Yang,Hong Xie,Tao Tan,Xin Li,Defu Lian,Enhong Chen*

Main category: cs.AI

TL;DR: 提出了一种基于视觉编码器内部功能动态的框架，用于为下游任务选择最佳的预训练 Vision-Language 模型（VLMs）。该框架通过层级导纳和目标条件块重要性分布来表征任务，并引入了方向导纳散度（DCD）指标，该指标能够量化源任务对目标任务关键功能块的覆盖程度，从而预测模型排名。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练 Vision-Language 模型（VLMs）选择方法存在计算资源限制、样本不足以及未能完全考虑模型迁移的内在方向性和模型特异性等问题。

Method: 提出一个框架，通过层级导纳（layer-wise conductance）来表示任务，并通过熵正则化对齐（entropy regularized alignment）推导出目标条件块重要性分布。在此基础上，引入了方向导纳散度（Directional Conductance Divergence, DCD）这一非对称指标，用于量化源任务在功能块上对目标任务的覆盖程度。

Result: 在 21 个数据集上的 48 个 VLMs 实验中，该方法在 NDCG@5 指标上比 SWAB 提升了 14.7%，优于现有最先进的基线方法。

Conclusion: 该方法能够通过评估源任务对目标任务关键功能块的覆盖程度，有效地预测模型排名，为在计算资源受限或样本不足的情况下选择合适的预训练 VLM 提供了有效解决方案。

Abstract: While open sourced Vision-Language Models (VLMs) have proliferated, selecting the optimal pretrained model for a specific downstream task remains challenging. Exhaustive evaluation is often infeasible due to computational constraints and data limitations in few shot scenarios. Existing selection methods fail to fully address this: they either rely on data-intensive proxies or use symmetric textual descriptors that neglect the inherently directional and model-specific nature of transferability. To address this problem, we propose a framework that grounds model selection in the internal functional dynamics of the visual encoder. Our approach represents each task via layer wise conductance and derives a target-conditioned block importance distribution through entropy regularized alignment. Building on this, we introduce Directional Conductance Divergence (DCD), an asymmetric metric that quantifies how effectively a source task covers the target's salient functional blocks. This allows for predicting target model rankings by aggregating source task ranks without direct inference. Experimental results on 48 VLMs across 21 datasets demonstrate that our method outperforms state-of-the-art baselines, achieving a 14.7% improvement in NDCG@5 over SWAB.

</details>


### [87] [Aggregation Queries over Unstructured Text: Benchmark and Agentic Method](https://arxiv.org/abs/2602.01355)
*Haojia Zhu,Qinyuan Xu,Haoyu Li,Yuxi Liu,Hanchen Qiu,Jiaoyan Chen,Jiahui Jin*

Main category: cs.AI

TL;DR: 本文提出了一种用于文本聚合查询的新框架DFA，并发布了相应的基准测试集AGGBench，旨在解决现有方法在聚合查询中遗漏证据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的文本聚合查询方法（如Text-to-SQL和检索增强生成RAG）在需要“找到所有”证据的情况下存在不足，无法保证查询的完整性。

Method: 本文将实体级聚合查询形式化，并提出了一个名为DFA（Disambiguation--Filtering--Aggregation）的模块化代理基线。DFA将聚合查询分解为歧义消解、过滤和聚合三个可解释的阶段，以解决证据遗漏的问题。同时，作者还引入了AGGBench基准测试集，用于评估聚合查询的完整性。

Result: 实验结果表明，DFA在证据覆盖率方面始终优于强大的RAG和代理基线。

Conclusion: DFA框架能够有效地提高文本聚合查询的证据完整性，AGGBench为该领域的评估提供了标准。

Abstract: Aggregation query over free text is a long-standing yet underexplored problem. Unlike ordinary question answering, aggregate queries require exhaustive evidence collection and systems are required to "find all," not merely "find one." Existing paradigms such as Text-to-SQL and Retrieval-Augmented Generation fail to achieve this completeness. In this work, we formalize entity-level aggregation querying over text in a corpus-bounded setting with strict completeness requirement. To enable principled evaluation, we introduce AGGBench, a benchmark designed to evaluate completeness-oriented aggregation under realistic large-scale corpus. To accompany the benchmark, we propose DFA (Disambiguation--Filtering--Aggregation), a modular agentic baseline that decomposes aggregation querying into interpretable stages and exposes key failure modes related to ambiguity, filtering, and aggregation. Empirical results show that DFA consistently improves aggregation evidence coverage over strong RAG and agentic baselines. The data and code are available in https://anonymous.4open.science/r/DFA-A4C1.

</details>


### [88] [Building Better Deception Probes Using Targeted Instruction Pairs](https://arxiv.org/abs/2602.01425)
*Vikram Natarajan,Devina Jain,Shivam Arora,Satvik Golechha,Joseph Bloom*

Main category: cs.AI

TL;DR: 本文提出了一种改进的线性探测器方法，用于检测人工智能系统的欺骗行为，通过优化训练指令对和针对特定欺骗行为的分类，提高了检测性能，并建议根据具体威胁模型设计专用探测器。


<details>
  <summary>Details</summary>
Motivation: 现有线性探测器在检测AI欺骗行为方面存在不足，例如在简单场景下也会失败，出现虚假关联和误报，这促使研究者探索更有效的方法。

Method: 研究者识别并强调了训练指令对的重要性，并通过使用人类可解释的欺骗行为分类来针对特定欺骗行为进行训练，从而改进了探测器的评估性能。

Result: 研究表明，指令对能够捕捉欺骗意图而非内容特定模式，解释了指令选择对探测器性能的显著影响（占70.6%的方差）。不同数据集的欺骗行为存在异质性。

Conclusion: 组织应设计专门针对其特定威胁模型的探测器，而不是寻求通用的欺骗检测器，因为欺骗的类型因数据集而异。

Abstract: Linear probes are a promising approach for monitoring AI systems for deceptive behaviour. Previous work has shown that a linear classifier trained on a contrastive instruction pair and a simple dataset can achieve good performance. However, these probes exhibit notable failures even in straightforward scenarios, including spurious correlations and false positives on non-deceptive responses. In this paper, we identify the importance of the instruction pair used during training. Furthermore, we show that targeting specific deceptive behaviors through a human-interpretable taxonomy of deception leads to improved results on evaluation datasets. Our findings reveal that instruction pairs capture deceptive intent rather than content-specific patterns, explaining why prompt choice dominates probe performance (70.6% of variance). Given the heterogeneity of deception types across datasets, we conclude that organizations should design specialized probes targeting their specific threat models rather than seeking a universal deception detector.

</details>


### [89] [SimGym: Traffic-Grounded Browser Agents for Offline A/B Testing in E-Commerce](https://arxiv.org/abs/2602.01443)
*Alberto Castelo,Zahra Zanjani Foumani,Ailin Fan,Keat Yang Koay,Vibhor Malik,Yuanzheng Zhu,Han Li,Meysam Feghhi,Ronie Uliana,Shuang Xie,Zhaoyu Zhang,Angelo Ocana Martins,Mingyu Zhao,Francis Pelland,Jonathan Faerman,Nikolas LeBlanc,Aaron Glazer,Andrew McNamara,Lingyun Wang,Zhong Wu*

Main category: cs.AI

TL;DR: SimGym是一个利用大型语言模型驱动的合成买家进行快速离线A/B测试的系统，能够模拟真实用户行为并显著缩短实验周期，同时避免对真实用户造成潜在负面影响。


<details>
  <summary>Details</summary>
Motivation: 传统的A/B测试虽然是评估电商UI变更的标准方法，但存在分流流量、周期长（数周才能达到显著性）以及损害用户体验的风险。研究者希望找到一种更快速、更安全的方法来进行A/B测试。

Method: SimGym提取电商平台生产环境中的用户行为数据，构建每家店铺的用户画像和意图，识别不同的行为原型。然后，利用大型语言模型（LLM）驱动的代理，在模拟的浏览器环境中，为这些合成买家模拟跨控制组和实验组店铺的带权重（cohort-weighted）会话。这些LLM代理在训练后无需进行额外的对齐（alignment）。

Result: 在真实UI变更和真实用户结果的验证中，SimGym代理在未进行对齐的情况下，实现了与观察到的结果变化最先进的（state of the art）一致性。实验周期从数周缩短到不到一小时。

Conclusion: SimGym是一个可扩展的系统，通过使用基于大型语言模型代理的、基于流量的合成买家，实现了快速的离线A/B测试。它能够快速进行实验，无需真实用户暴露，大大提高了实验效率，并能准确预测UI变更对用户结果的影响。

Abstract: A/B testing remains the gold standard for evaluating e-commerce UI changes, yet it diverts traffic, takes weeks to reach significance, and risks harming user experience. We introduce SimGym, a scalable system for rapid offline A/B testing using traffic-grounded synthetic buyers powered by Large Language Model agents operating in a live browser. SimGym extracts per-shop buyer profiles and intents from production interaction data, identifies distinct behavioral archetypes, and simulates cohort-weighted sessions across control and treatment storefronts. We validate SimGym against real human outcomes from real UI changes on a major e-commerce platform under confounder control. Even without alignment post training, SimGym agents achieve state of the art alignment with observed outcome shifts and reduces experiment cycles from weeks to under an hour , enabling rapid experimentation without exposure to real buyers.

</details>


### [90] [Agyn: A Multi-Agent System for Team-Based Autonomous Software Engineering](https://arxiv.org/abs/2602.01465)
*Nikita Benkovich,Vitalii Valkov*

Main category: cs.AI

TL;DR: 研究提出了一个多智能体系统，该系统通过模仿真实软件工程团队的组织结构、角色分工和协作流程，实现了软件问题的全自动解决，并在SWE-bench上取得了优于单智能体基线的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自主软件工程系统通常将问题解决视为单一流程或流水线，未能体现真实世界软件开发中的团队协作、角色分离和沟通审查等关键特性。作者希望通过模仿真实工程团队的组织方式来提升自主软件工程的效率和能力。

Method: 作者构建了一个基于agyn平台的多智能体系统，该系统明确模拟了软件工程团队的组织结构。系统为不同角色（如协调、研究、实现、审查）分配了专门的智能体，并为它们提供了独立的实验沙箱和结构化的沟通机制。该系统遵循一套定义好的开发方法论，包括分析、任务规范、Pull Request创建和迭代审查，全程无需人工干预。

Result: 在SWE-bench 500基准测试中，该系统成功解决了72.4%的任务，显著优于使用相同语言模型的单智能体基线方法。值得注意的是，该系统是为实际生产环境设计的，并未针对SWE-bench进行专门调优。

Conclusion: 研究结果表明，复制团队结构、方法论和沟通方式是实现自主软件工程的有效范式。未来的进展可能同样依赖于组织设计和智能体基础设施的改进，而非仅仅是模型本身的提升。

Abstract: Large language models have demonstrated strong capabilities in individual software engineering tasks, yet most autonomous systems still treat issue resolution as a monolithic or pipeline-based process. In contrast, real-world software development is organized as a collaborative activity carried out by teams following shared methodologies, with clear role separation, communication, and review. In this work, we present a fully automated multi-agent system that explicitly models software engineering as an organizational process, replicating the structure of an engineering team. Built on top of agyn, an open-source platform for configuring agent teams, our system assigns specialized agents to roles such as coordination, research, implementation, and review, provides them with isolated sandboxes for experimentation, and enables structured communication. The system follows a defined development methodology for working on issues, including analysis, task specification, pull request creation, and iterative review, and operates without any human intervention. Importantly, the system was designed for real production use and was not tuned for SWE-bench. When evaluated post hoc on SWE-bench 500, it resolves 72.4% of tasks, outperforming single-agent baselines using comparable language models. Our results suggest that replicating team structure, methodology, and communication is a powerful paradigm for autonomous software engineering, and that future progress may depend as much on organizational design and agent infrastructure as on model improvements.

</details>


### [91] [Legal Infrastructure for Transformative AI Governance](https://arxiv.org/abs/2602.01474)
*Gillian K. Hadfield*

Main category: cs.AI

TL;DR: 本文讨论了AI治理中，除了关注实质性规则外，还应重视法律和监管基础设施的建设，并提出了三种具体的AI监管框架建议：前沿模型注册制、自主代理注册与识别制，以及鼓励私营企业提供AI监管服务的监管市场。


<details>
  <summary>Details</summary>
Motivation: 现有的AI治理方法主要集中在制定实质性规则，而忽视了建立支持这些规则生成和实施的法律和监管基础设施。AI的变革性特征要求我们必须关注和构建更完善的法律和监管框架。

Method: 本文回顾并提出了三种作者之前提出的AI监管框架建议：1. 建立前沿AI模型的注册制度；2. 建立自主AI代理的注册和识别制度；3. 设计监管市场，鼓励私营企业在AI监管服务领域进行创新。

Result: 文章提出了三种具体的、侧重于制度建设的AI治理框架，旨在为AI的监管提供更坚实的基础，并促进私营部门在AI监管服务中的作用。

Conclusion: AI治理的有效性不仅依赖于实质性规则，更依赖于健全的法律和监管基础设施。本文提出的注册制度和监管市场等框架，为应对AI带来的挑战提供了创新的解决方案。

Abstract: Most of our AI governance efforts focus on substance: what rules do we want in place? What limits or checks do we want to impose on AI development and deployment? But a key role for law is not only to establish substantive rules but also to establish legal and regulatory infrastructure to generate and implement rules. The transformative nature of AI calls especially for attention to building legal and regulatory frameworks. In this PNAS Perspective piece I review three examples I have proposed: the creation of registration regimes for frontier models; the creation of registration and identification regimes for autonomous agents; and the design of regulatory markets to facilitate a role for private companies to innovate and deliver AI regulatory services.

</details>


### [92] [Qrita: High-performance Top-k and Top-p Algorithm for GPUs using Pivot-based Truncation and Selection](https://arxiv.org/abs/2602.01518)
*Jongseok Park,Sunga Kim,Alvin Cheung,Ion Stoica*

Main category: cs.AI

TL;DR: 提出了一种名为 Qrita 的高效 Top-k 和 Top-p 采样算法，该算法使用基于枢轴的选择策略，并通过高斯 sigma 截断和四元枢轴搜索减少了计算和内存开销，在 GPU 上实现了高达 2 倍的吞吐量和内存使用量减半。


<details>
  <summary>Details</summary>
Motivation: 现有 Top-k 和 Top-p 采样算法在处理大型词汇表时效率低下，依赖排序会产生显著的计算和内存开销，而随机方法会改变输出。因此，需要一种更高效且能保证确定性输出的算法。

Method: 提出 Qrita 算法，基于枢轴选择策略。关键技术包括：1. 高斯 sigma 截断，减小搜索空间；2. 四元枢轴搜索，处理重复项，减少迭代次数并确保确定性输出。使用 Triton 实现。

Result: Qrita 在 Top-k 和 Top-p 采样方面，相比 vLLM、SGLang 和 Flashinfer 等高性能 LLM 执行引擎的现有内核，实现了高达 2 倍的吞吐量和 50% 的内存使用量降低，且输出与基于排序的算法相同。

Conclusion: Qrita 是一种高效且确定性的 Top-k 和 Top-p 采样算法，在 GPU 上显著提高了 LLM 的采样性能，同时降低了内存消耗。

Abstract: Top-k and Top-p are the dominant truncation operators in the sampling of large language models. Despite their widespread use, implementing them efficiently over large vocabularies remains a significant challenge. Existing approaches often rely on sorting, which incur significant computation and memory overhead on GPUs, or stochastic approaches, which alter the algorithm output. In this work, we propose Qrita, an efficient Top-k and Top-p algorithm based on a pivot-based selection strategy. Based on RTop-k, which uses a pivot-based search for node selection in graph neural networks, Qrita extends the concept of pivot-based search to both Top-k and Top-p with two key techniques: 1. Gaussian-based sigma-truncation, which greatly reduces the search space of the target elements, and 2. Quaternary pivot search with duplication handling, which halves the pivot search iteration and guarantees deterministic output. We provide the full implementation of Qrita using Triton, a popular GPU programming language. Our evaluation of Qrita against the Top-k and Top-p kernels of high performance LLM execution engines such as vLLM, SGLang, and Flashinfer show that Qrita achieves up to 2 times throughput and half memory use while providing the same output to the the sorting-based algorithms.

</details>


### [93] [PRISM: Festina Lente Proactivity -- Risk-Sensitive, Uncertainty-Aware Deliberation for Proactive Agents](https://arxiv.org/abs/2602.01532)
*Yuxuan Fu,Xiaoyu Tan,Teqi Hao,Chen Zhan,Xihe Qiu*

Main category: cs.AI

TL;DR: 本文提出了PRISM框架，通过一个基于成本敏感选择性干预的决策论门控机制，结合双过程推理，实现了更精确、高效且可控的主动代理。该框架在ProactiveBench基准测试中显著减少了误报并提高了F1分数。


<details>
  <summary>Details</summary>
Motivation: 当前的主动代理在决定何时以及是否干预时，往往依赖于脆弱的启发式方法或不加区分的长推理，难以控制收益-负担权衡。研究动机是设计一种能够有效管理干预成本和收益的机制。

Method: PRISM框架结合了一个决策论门控和一个双过程推理架构。在推理时，仅当用户接受的校准概率超过由误报和漏报不对称成本推导出的阈值时，代理才会干预。它采用“festina lente”思想，仅在决策边界附近激活资源密集型的慢速模式（包含反事实检查），从而将计算资源集中在高风险和模糊的案例上。训练时，使用门控对齐、模式锁定的蒸馏方法，由教师模型提供监督。

Result: 在ProactiveBench基准测试中，PRISM相比强基线模型，误报率降低了22.78%，F1分数提高了20.14%。

Conclusion: PRISM证明了基于决策论的门控、选择性慢速推理和对齐蒸馏的组合，可以构建出精确、计算高效且可控的主动代理。研究成果已开源，包括代码、模型和资源。

Abstract: Proactive agents must decide not only what to say but also whether and when to intervene. Many current systems rely on brittle heuristics or indiscriminate long reasoning, which offers little control over the benefit-burden tradeoff. We formulate the problem as cost-sensitive selective intervention and present PRISM, a novel framework that couples a decision-theoretic gate with a dual-process reasoning architecture. At inference time, the agent intervenes only when a calibrated probability of user acceptance exceeds a threshold derived from asymmetric costs of missed help and false alarms. Inspired by festina lente (Latin: "make haste slowly"), we gate by an acceptance-calibrated, cost-derived threshold and invoke a resource-intensive Slow mode with counterfactual checks only near the decision boundary, concentrating computation on ambiguous and high-stakes cases. Training uses gate-aligned, schema-locked distillation: a teacher running the full PRISM pipeline provides dense, executable supervision on unlabeled interaction traces, while the student learns a response policy that is explicitly decoupled from the intervention gate to enable tunable and auditable control. On ProactiveBench, PRISM reduces false alarms by 22.78% and improves F1 by 20.14% over strong baselines. These results show that principled decision-theoretic gating, paired with selective slow reasoning and aligned distillation, yields proactive agents that are precise, computationally efficient, and controllable. To facilitate reproducibility, we release our code, models, and resources at https://prism-festinalente.github.io/; all experiments use the open-source ProactiveBench benchmark.

</details>


### [94] [MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety](https://arxiv.org/abs/2602.01539)
*Xiaoyu Wen,Zhida He,Han Qi,Ziyu Wan,Zhongtian Ma,Ying Wen,Tianhang Zheng,Xingcheng Xu,Chaochao Lu,Qiaosheng Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为MAGIC的多轮多智能体强化学习框架，通过模拟攻击者和防御者之间的动态对抗，来提升大型语言模型的安全对齐能力，使其能够应对不断演变的攻击策略。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM安全对齐方法依赖于静态数据集，难以应对不断变化的对抗性攻击，因此需要一种更动态、更具适应性的防御机制。

Method: MAGIC框架将LLM安全对齐视为一个对抗性的不对称博弈。其中，攻击者智能体通过迭代重写查询来生成欺骗性提示，防御者智能体则学习识别并拒绝此类输入。这种动态对抗过程促使双方策略的共同演化。

Result: 通过迭代强化学习训练，攻击者智能体演化出了新的、此前未见的组合攻击策略，从而不断揭示长尾漏洞。实验证明，MAGIC框架能够有效地提高防御成功率，并且不损害模型的有用性。

Conclusion: MAGIC框架通过动态的博弈对抗，能够促使LLM的防御策略共同演化，从而有效应对不断演变的攻击策略，提升模型的鲁棒性，并为更安全的博弈均衡提供了理论分析和安全保证。

Abstract: Ensuring robust safety alignment is crucial for Large Language Models (LLMs), yet existing defenses often lag behind evolving adversarial attacks due to their \textbf{reliance on static, pre-collected data distributions}. In this paper, we introduce \textbf{MAGIC}, a novel multi-turn multi-agent reinforcement learning framework that formulates LLM safety alignment as an adversarial asymmetric game. Specifically, an attacker agent learns to iteratively rewrite original queries into deceptive prompts, while a defender agent simultaneously optimizes its policy to recognize and refuse such inputs. This dynamic process triggers a \textbf{co-evolution}, where the attacker's ever-changing strategies continuously uncover long-tail vulnerabilities, driving the defender to generalize to unseen attack patterns. Remarkably, we observe that the attacker, endowed with initial reasoning ability, evolves \textbf{novel, previously unseen combinatorial strategies} through iterative RL training, underscoring our method's substantial potential. Theoretically, we provide insights into a more robust game equilibrium and derive safety guarantees. Extensive experiments validate our framework's effectiveness, demonstrating superior defense success rates without compromising the helpfulness of the model. Our code is available at https://github.com/BattleWen/MAGIC.

</details>


### [95] [S1-NexusAgent: a Self-Evolving Agent Framework for Multidisciplinary Scientific Research](https://arxiv.org/abs/2602.01550)
*S1-NexusAgent Team*

Main category: cs.AI

TL;DR: 提出了一种名为 S1-NexusAgent 的自演化智能体框架，用于处理复杂的多学科科学研究任务，通过分层规划-代码执行范式、模型上下文协议、智能工具检索和稀疏上下文管理等技术，实现了长远规划、工具编排和持续学习，并在生物、化学和材料科学等领域的基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型和基于工具的智能体在处理大规模数据、复杂工作流和长远规划方面存在局限性，难以应对多学科科学研究的需求。

Method: 提出 S1-NexusAgent 框架，采用分层 Plan-and-CodeAct 执行范式，通过双循环架构实现全局规划和子任务工具执行的分离。支持模型上下文协议 (MCP)，集成大量跨学科工具，并利用意图感知动态工具检索和热插拔机制进行工具编排。引入基于对象引用的稀疏上下文管理，实现上下文隔离和结果压缩。通过 Critic Agent 评估执行轨迹，将高质量研究路径提炼为可重用的 Scientific Skills，形成闭环自演化。

Result: 在 biomini-eval (生物)、ChemBench (化学) 和 MatSciBench (材料科学) 等权威科学基准测试中，S1-NexusAgent 展现出最先进的性能，有效解决了长远规划和复杂专业工具编排的挑战。

Conclusion: S1-NexusAgent 是一个有效的、可泛化的自演化智能体框架，能够胜任复杂的多学科科学研究任务，尤其在长远规划、工具协同和持续学习方面具有显著优势，为可持续的科学研究提供了有力支持。

Abstract: Modern scientific research relies on large-scale data, complex workflows, and specialized tools, which existing LLMs and tool-based agents struggle to handle due to limitations in long-horizon planning, robust goal maintenance, and continual learning from execution. To address these issues, in this work, we propose S1-NexusAgent, a self-evolving agent framework designed for multidisciplinary scientific research. S1-NexusAgent adopts a hierarchical Plan-and-CodeAct execution paradigm, decoupling global scientific planning from subtask-level tool execution through a dual-loop architecture, thereby enabling stable modeling of complex research workflows. The system natively supports the Model Context Protocol (MCP), integrates up to thousands of cross-disciplinary scientific tools, and achieves efficient orchestration of heterogeneous research tools via intention-aware dynamic tool retrieval and hot-plug mechanisms. To address long-context and large-scale data challenges in scientific settings, S1-NexusAgent introduces object-reference-based sparse context management, which enables sub-task context isolation and intermediate result compression. Building on this, a Critic Agent automatically evaluates complete execution trajectories and distills high-quality research paths into reusable Scientific Skills, forming a closed loop for continuous self-evolution, which is valuable for sustainable and long-horizon scientific research. Experiments on authoritative scientific benchmarks involving long-horizon planning and complex specialized tool orchestration, including biomini-eval (biology), ChemBench (chemistry), and MatSciBench (material science), demonstrate that S1-NexusAgent achieves state-of-the-art performance, validating its effectiveness and generalization capability in complex scientific tasks.

</details>


### [96] [Autonomous Question Formation for Large Language Model-Driven AI Systems](https://arxiv.org/abs/2602.01556)
*Hong Su*

Main category: cs.AI

TL;DR: 提出了一种基于人类模拟的框架，使人工智能系统能够通过推理内部状态、环境观察和与其他人工智能的交互来自主形成问题和设置任务，从而提高了在动态开放环境中的决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM驱动的AI系统依赖于预定义的任务和固定的提示，这限制了它们在环境条件变化时自主识别问题并进行解决的能力。

Method: 提出了一种基于人类模拟的框架，将问题形成视为一个独立于任务选择和执行的决策过程。该框架集成了内部驱动、环境感知和代理间感知三种提示范围，并支持从经验中学习问题形成过程。

Result: 实验结果表明，与仅基于内部驱动的基线相比，环境感知提示显著减少了“不进食”事件。代理间感知提示进一步将累积的“不进食”事件减少了60%以上。

Conclusion: 该框架能够使AI系统自主形成问题和设置任务，并能随着时间的推移学习和改进其适应性和决策质量，特别是在多代理模拟环境中，环境感知和代理间感知提示能有效减少负面事件。

Abstract: Large language model (LLM)-driven AI systems are increasingly important for autonomous decision-making in dynamic and open environments. However, most existing systems rely on predefined tasks and fixed prompts, limiting their ability to autonomously identify what problems should be solved when environmental conditions change. In this paper, we propose a human-simulation-based framework that enables AI systems to autonomously form questions and set tasks by reasoning over their internal states, environmental observations, and interactions with other AI systems. The proposed method treats question formation as a first-class decision process preceding task selection and execution, and integrates internal-driven, environment-aware, and inter-agent-aware prompting scopes to progressively expand cognitive coverage. In addition, the framework supports learning the question-formation process from experience, allowing the system to improve its adaptability and decision quality over time. xperimental results in a multi-agent simulation environment show that environment-aware prompting significantly reduces no-eat events compared with the internal-driven baseline, and inter-agent-aware prompting further reduces cumulative no-eat events by more than 60% over a 20-day simulation, with statistically significant improvements (p < 0.05).

</details>


### [97] [Reasoning with Autoregressive-Diffusion Collaborative Thoughts](https://arxiv.org/abs/2602.01608)
*Mu Yuan,Liekang Zeng,Guoliang Xing,Lan Zhang,Yunhao Liu*

Main category: cs.AI

TL;DR: 提出了一种名为“协作思考”的统一框架，通过闭环交互，使自回归模型和扩散模型能够协同推理和生成，以提高空间推理的可靠性和生成的可控性。


<details>
  <summary>Details</summary>
Motivation: 自回归模型擅长序列规划但难以进行空间或物理接地，而扩散模型擅长空间结构但缺乏多阶段约束满足和错误纠正的逻辑控制。需要一个能结合两者的模型。

Method: 提出“协作思考”框架，自回归模型负责结构化规划和约束管理，扩散模型将约束实例化为中间视觉“思考”，一个基于视觉的评论模块评估视觉“思考”是否满足要求，并通过迭代反馈机制进行优化。

Result: 通过实例说明，“协作思考”框架能够提高空间推理的可靠性和生成的可控性。

Conclusion: “协作思考”框架成功地统一了自回归和扩散模型，通过闭环交互和多模块协同，解决了各自模型的局限性，实现了更可靠和可控的生成任务。

Abstract: Autoregressive and diffusion models represent two complementary generative paradigms. Autoregressive models excel at sequential planning and constraint composition, yet struggle with tasks that require explicit spatial or physical grounding. Diffusion models, in contrast, capture rich spatial structure through high-dimensional generation, but lack the stepwise logical control needed to satisfy complex, multi-stage constraints or to reliably identify and correct errors. We introduce Collaborative Thoughts, a unified collaborative framework that enables autoregressive and diffusion models to reason and generate jointly through a closed-loop interaction. In Collaborative Thoughts, autoregressive models perform structured planning and constraint management, diffusion models instantiate these constraints as intermediate visual thoughts, and a vision-based critic module evaluates whether the visual thoughts satisfy the intended structural and physical requirements. This feedback is then used to iteratively refine subsequent planning and generation steps, mitigating error propagation across modalities. Importantly, Collaborative Thoughts uses the same collaborative loop regardless of whether the task is autoregressive question answering or diffusion-based visual generation. Through representative examples, we illustrate how Collaborative Thoughts can improve the reliability of spatial reasoning and the controllability of generation.

</details>


### [98] [ToPT: Task-Oriented Prompt Tuning for Urban Region Representation Learning](https://arxiv.org/abs/2602.01610)
*Zitao Guo,Changyang Jiang,Tianhong Zhao,Jinzhou Cao,Genan Dai,Bowen Zhang*

Main category: cs.AI

TL;DR: 提出了一种名为ToPT的两阶段框架，用于从异构城市数据中学习有效的区域嵌入，解决了现有方法缺乏空间先验和任务语义对齐的问题。ToPT包含空间感知区域嵌入学习（SREL）和任务感知提示（Prompt4RE）模块，通过引入空间先验和利用大型语言模型实现空间一致性融合和显式任务对齐，并在多项任务和城市中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成的任务无关的区域表示，并且在处理空间信息和任务语义对齐方面存在不足。因此，需要一种能够捕获空间一致性并与下游任务进行显式对齐的方法。

Method: ToPT框架包含两个模块：1. 空间感知区域嵌入学习（SREL）：使用基于Graphormer的融合模块，将距离和区域中心性等空间先验作为可学习的注意力偏差，以捕捉区域间的相互作用。2. 任务感知提示（Prompt4RE）：利用冻结的多模态大型语言模型（MLLM）处理任务模板生成语义向量，并通过多头交叉注意力与区域嵌入对齐，实现稳定的任务条件设置。

Result: 在多个任务和城市上进行的实验表明，ToPT取得了最先进的性能，在某些情况下性能提升高达64.2%。实验结果验证了空间先验和提示-区域对齐的必要性和互补性。

Conclusion: ToPT框架通过注入空间先验和利用大型语言模型进行任务语义对齐，有效地解决了现有方法的局限性，能够学习到空间一致且任务相关的区域嵌入，从而在城市计算任务中取得优异表现。

Abstract: Learning effective region embeddings from heterogeneous urban data underpins key urban computing tasks (e.g., crime prediction, resource allocation). However, prevailing two-stage methods yield task-agnostic representations, decoupling them from downstream objectives. Recent prompt-based approaches attempt to fix this but introduce two challenges: they often lack explicit spatial priors, causing spatially incoherent inter-region modeling, and they lack robust mechanisms for explicit task-semantic alignment. We propose ToPT, a two-stage framework that delivers spatially consistent fusion and explicit task alignment. ToPT consists of two modules: spatial-aware region embedding learning (SREL) and task-aware prompting for region embeddings (Prompt4RE). SREL employs a Graphormer-based fusion module that injects spatial priors-distance and regional centrality-as learnable attention biases to capture coherent, interpretable inter-region interactions. Prompt4RE performs task-oriented prompting: a frozen multimodal large language model (MLLM) processes task-specific templates to obtain semantic vectors, which are aligned with region embeddings via multi-head cross-attention for stable task conditioning. Experiments across multiple tasks and cities show state-of-the-art performance, with improvements of up to 64.2\%, validating the necessity and complementarity of spatial priors and prompt-region alignment. The code is available at https://github.com/townSeven/Prompt4RE.git.

</details>


### [99] [ProjDevBench: Benchmarking AI Coding Agents on End-to-End Project Development](https://arxiv.org/abs/2602.01655)
*Pengrui Lu,Shiqi Zhang,Yunzhong Hou,Lyumanshan Ye,Chaoyi Huang,Zixi Chen,Ji Zeng,Hantao Jiang,Pengfei Liu,Yiwei Wang,Ming-Hsuan Yang*

Main category: cs.AI

TL;DR: 本文提出了ProjDevBench，一个端到端的代码生成评估基准，用于评估大型语言模型（LLM）驱动的代码生成代理在整个项目开发流程中的表现，而不仅仅是修复单个bug。该基准包含20个编程问题，并结合在线判题（OJ）和LLM辅助代码审查来评估系统架构设计、功能正确性和迭代优化能力。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成代理的评估方法主要集中在修复bug，未能跟上端到端项目开发的需求，因此需要一个更全面的评估基准来衡量代理在真实项目开发场景下的能力。

Method: 构建了一个名为ProjDevBench的端到端基准，包含20个跨8个类别的编程问题，涵盖概念性和实际应用场景。通过结合在线判题（OJ）测试和LLM辅助的代码审查来评估代理的系统架构设计、功能正确性和迭代解决方案优化能力。对六个基于不同LLM后端的代码代理进行了评估。

Result: 在ProjDevBench基准上，六个代码代理的整体接受率为27.38%。代理能够处理基本功能和数据结构，但在复杂的系统设计、时间复杂度优化和资源管理方面表现不佳。

Conclusion: ProjDevBench是一个新的端到端评估基准，揭示了当前代码生成代理在处理复杂项目开发任务时仍存在显著挑战，特别是在系统设计和性能优化方面。该基准旨在推动代码生成技术在实际项目开发中的进步。

Abstract: Recent coding agents can generate complete codebases from simple prompts, yet existing evaluations focus on issue-level bug fixing and lag behind end-to-end development. We introduce ProjDevBench, an end-to-end benchmark that provides project requirements to coding agents and evaluates the resulting repositories. Combining Online Judge (OJ) testing with LLM-assisted code review, the benchmark evaluates agents on (1) system architecture design, (2) functional correctness, and (3) iterative solution refinement. We curate 20 programming problems across 8 categories, covering both concept-oriented tasks and real-world application scenarios, and evaluate six coding agents built on different LLM backends. Our evaluation reports an overall acceptance rate of 27.38%: agents handle basic functionality and data structures but struggle with complex system design, time complexity optimization, and resource management. Our benchmark is available at https://github.com/zsworld6/projdevbench.

</details>


### [100] [FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning](https://arxiv.org/abs/2602.01664)
*Mingda Zhang,Haoran Luo,Tiesunlong Shen,Qika Lin,Xiaoying Tang,Rui Mao,Erik Cambria*

Main category: cs.AI

TL;DR: FlowSteer 是一个端到端的强化学习框架，通过轻量级策略模型和可执行画布环境，自动化工作流编排，解决了现有工作流成本高、依赖性强和奖励信号稀疏的问题。


<details>
  <summary>Details</summary>
Motivation: 现有工作流编排面临手动成本高、依赖特定算子/大语言模型（LLM）以及奖励信号稀疏的挑战。

Method: 提出 FlowSteer，一个端到端的强化学习框架，使用轻量级策略模型作为代理，可执行画布环境进行交互。策略模型分析执行状态并选择编辑动作，画布执行算子并返回反馈。还提出 Canvas Workflow Relative Policy Optimization (CWRPO) 来训练该交互范式，通过多样性约束奖励和条件释放来稳定学习。

Result: 在十二个数据集上的实验结果表明，FlowSteer 在各种任务上显著优于基线方法。

Conclusion: FlowSteer 能够通过多轮交互自动化工作流编排，并支持多样化的算子库和可互换的 LLM 后端，有效解决了现有工作流的痛点。

Abstract: In recent years, a variety of powerful agentic workflows have been applied to solve a wide range of human problems. However, existing workflow orchestration still faces key challenges, including high manual cost, reliance on specific operators/large language models (LLMs), and sparse reward signals. To address these challenges, we propose FlowSteer, an end-to-end reinforcement learning framework that takes a lightweight policy model as the agent and an executable canvas environment, automating workflow orchestration through multi-turn interaction. In this process, the policy model analyzes execution states and selects editing actions, while the canvas executes operators and returns feedback for iterative refinement. Moreover, FlowSteer provides a plug-and-play framework that supports diverse operator libraries and interchangeable LLM backends. To effectively train this interaction paradigm, we propose Canvas Workflow Relative Policy Optimization (CWRPO), which introduces diversity-constrained rewards with conditional release to stabilize learning and suppress shortcut behaviors. Experimental results on twelve datasets show that FlowSteer significantly outperforms baselines across various tasks.

</details>


### [101] [TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios](https://arxiv.org/abs/2602.01675)
*Yuanzhe Shen,Zisu Huang,Zhengyuan Wang,Muzhao Tian,Zhengkang Guo,Chenyang Zhang,Shuaiyu Zhou,Zengjie Hu,Dailin Li,Jingwen Xu,Kaimin Wang,Wenhao Liu,Tianlong Li,Fengpeng Yue,Feng Hong,Cao Liu,Ke Zeng*

Main category: cs.AI

TL;DR: 本文提出了一个名为 TRIP-Bench 的长时序旅行规划基准，以解决现有 LLM 代理在复杂现实场景中面临的挑战。同时，研究者还提出了一种名为 GTPO 的在线多轮强化学习方法，并证明其在 TRIP-Bench 上能有效提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 代理基准低估了实际应用中的挑战，如全局约束、多工具协调和长期交互适应性。因此需要一个更贴近现实的长时序交互基准。

Method: 提出了 TRIP-Bench，一个基于真实旅行规划场景的基准，包含18种工具和40+旅行需求，支持自动评估。并提出了 GTPO，一种结合了奖励归一化和奖励差分的在线多轮强化学习方法。

Result: 在 TRIP-Bench 上，即使是先进的模型在简单 split 上成功率也最高仅为50%，在困难 split 上则低于10%。GTPO 方法通过在 Qwen2.5-32B-Instruct 上应用，显著提高了约束满足和交互鲁棒性，优于 Gemini-3-Pro。

Conclusion: TRIP-Bench 有望推动长时序交互式代理的发展，而 GTPO 则为鲁棒的长时序在线强化学习训练提供了一种有效的方法。

Abstract: As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce \textbf{TRIP-Bench}, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\% success on the easy split, with performance dropping below 10\% on hard subsets. We further propose \textbf{GTPO}, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training.

</details>


### [102] [What LLMs Think When You Don't Tell Them What to Think About?](https://arxiv.org/abs/2602.01689)
*Yongchan Kwon,James Zou*

Main category: cs.AI

TL;DR: 本研究探索了大型语言模型（LLMs）在缺乏明确主题指导下的生成行为，发现不同模型家族在内容主题、专业深度和退化模式上表现出系统性的偏好和差异。


<details>
  <summary>Details</summary>
Motivation: 现有对LLMs的分析主要依赖于特定主题或任务的提示，这限制了对其行为的全面观察。研究者希望在更少约束的条件下，了解LLMs的近乎无约束的生成行为，以支持可靠的监控和AI安全。

Method: 作者向16种LLMs输入了最小化、主题中立的输入，收集了256,000个样本，分析了模型输出内容的语义空间、主题偏好、内容专业深度以及生成行为的退化模式。

Result: 尽管输入主题中立，LLMs的输出仍覆盖广泛的语义空间，并表现出强烈的系统性主题偏好：GPT-OSS偏好编程和数学内容，Llama偏好文学内容，DeepSeek偏好宗教内容，Qwen偏好多选题。GPT-OSS生成的内容更具技术深度。此外，不同模型在无约束生成时会出现独特的退化行为，例如Llama会生成指向个人社交媒体的URL。

Conclusion: LLMs在近乎无约束的生成环境中表现出独特的、模型家族特有的行为模式，包括主题偏好、内容专业化程度和退化特性。这些发现对于理解和评估LLMs的安全性至关重要。研究者发布了数据集和代码以供进一步研究。

Abstract: Characterizing the behavior of large language models (LLMs) across diverse settings is critical for reliable monitoring and AI safety. However, most existing analyses rely on topic- or task-specific prompts, which can substantially limit what can be observed. In this work, we study what LLMs generate from minimal, topic-neutral inputs and probe their near-unconstrained generative behavior. Despite the absence of explicit topics, model outputs cover a broad semantic space, and surprisingly, each model family exhibits strong and systematic topical preferences. GPT-OSS predominantly generates programming (27.1%) and mathematical content (24.6%), whereas Llama most frequently generates literary content (9.1%). DeepSeek often generates religious content, while Qwen frequently generates multiple-choice questions. Beyond topical preferences, we also observe differences in content specialization and depth: GPT-OSS often generates more technically advanced content (e.g., dynamic programming) compared with other models (e.g., basic Python). Furthermore, we find that the near-unconstrained generation often degenerates into repetitive phrases, revealing interesting behaviors unique to each model family. For instance, degenerate outputs from Llama include multiple URLs pointing to personal Facebook and Instagram accounts. We release the complete dataset of 256,000 samples from 16 LLMs, along with a reproducible codebase.

</details>


### [103] [Beyond Dense States: Elevating Sparse Transcoders to Active Operators for Latent Reasoning](https://arxiv.org/abs/2602.01695)
*Yadong Wang,Haodong Chen,Yu Tian,Chuanxing Geng,Dong Liang,Xiang Chen*

Main category: cs.AI

TL;DR: 本文提出了一种名为LSTR的潜在推理框架，它通过函数式稀疏转码器来实现可解释的多步推理，解决了现有密集潜在转换难以解释和控制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在潜在推理中依赖于难以解释和控制的密集潜在转换，而稀疏表示模型虽然可解释但通常只用于事后分析。研究旨在弥合这一差距，提出一种可解释且可控的潜在推理方法。

Method: LSTR框架的核心是潜在转换转码器（LTT），它采用残差跳跃架构，将线性流形传输与稀疏语义更新分离，并通过显式稀疏约束实现可控的语义分辨率。LSTR将函数式稀疏转码器作为主动推理算子，通过稀疏语义转换执行多步计算。

Result: 实验表明，LSTR在保持推理准确性和压缩效率的同时，显著提高了模型的可解释性，优于密集的潜在基线方法。因果干预和轨迹分析证实，这些稀疏特征可以作为可解释且具有因果效应的推理算子。

Conclusion: LSTR成功地将稀疏表示的可解释性融入到潜在推理过程中，实现了可解释、可控且高效的多步推理，为未来的可解释AI研究提供了新的方向。

Abstract: Latent reasoning compresses the chain-of-thought (CoT) into continuous hidden states, yet existing methods rely on dense latent transitions that remain difficult to interpret and control. Meanwhile, sparse representation models uncover human-interpretable semantic features but remain largely confined to post-hoc analysis. We reconcile this tension by proposing LSTR (Latent Sparse Transcoder Reasoning), a latent reasoning framework that elevates functional sparse transcoders into active reasoning operators to perform multi-step computation through sparse semantic transitions. At its core, LSTR employs a Latent Transition Transcoder (LTT) with a residual skip architecture that decouples linear manifold transport from sparse semantic updates, enabling controllable semantic resolution via explicit sparsity constraints. Extensive experiments show that LSTR preserves reasoning accuracy and compression efficiency while substantially improving interpretability over dense latent baselines. Causal interventions and trajectory analyses further demonstrate that these sparse features act as both interpretable and causally effective operators in the reasoning process.

</details>


### [104] [Mitigating loss of control in advanced AI systems through instrumental goal trajectories](https://arxiv.org/abs/2602.01699)
*Willem Fourie*

Main category: cs.AI

TL;DR: 本文提出了一种新的方法来监控和控制高级人工智能系统，通过关注支撑AI发展的组织性“工具目标轨迹”（instrumental goal trajectories, IGTs），包括采购、治理和金融三个方面，来识别和干预AI能力和行为的潜在失控。


<details>
  <summary>Details</summary>
Motivation: 现有的AI控制方法主要侧重于技术层面，例如追踪AI能力、通过人类反馈强化学习以及设计可修正和可中断的系统。然而，研究者们担心高度智能的AI系统会通过追求工具性目标来侵蚀人类控制权，而现有的方法可能不足以应对这一挑战。

Method: 研究者们开发了“工具目标轨迹”（IGTs）的概念，并将其分为三个组织性路径：采购（procurement）、治理（governance）和金融（finance）。通过追踪这些IGTs产生的组织性产物（如文件、记录等），可以作为监控点，在AI能力或行为超出可接受阈值时进行干预。

Result: IGTs为定义AI能力水平提供了具体途径，并拓宽了可修正性和可中断性的实现方式。这种方法将关注点从单纯的模型属性转移到支撑AI发展的组织系统层面。

Conclusion: 通过监控和利用组织性的工具目标轨迹，可以更有效地管理和控制高级AI系统的发展和行为，从而在组织层面为AI的安全性提供更广泛的介入点，而不仅仅依赖于技术层面的解决方案。

Abstract: Researchers at artificial intelligence labs and universities are concerned that highly capable artificial intelligence (AI) systems may erode human control by pursuing instrumental goals. Existing mitigations remain largely technical and system-centric: tracking capability in advanced systems, shaping behaviour through methods such as reinforcement learning from human feedback, and designing systems to be corrigible and interruptible. Here we develop instrumental goal trajectories to expand these options beyond the model. Gaining capability typically depends on access to additional technical resources, such as compute, storage, data and adjacent services, which in turn requires access to monetary resources. In organisations, these resources can be obtained through three organisational pathways. We label these pathways the procurement, governance and finance instrumental goal trajectories (IGTs). Each IGT produces a trail of organisational artefacts that can be monitored and used as intervention points when a systems capabilities or behaviour exceed acceptable thresholds. In this way, IGTs offer concrete avenues for defining capability levels and for broadening how corrigibility and interruptibility are implemented, shifting attention from model properties alone to the organisational systems that enable them.

</details>


### [105] [Optimizing Prompts for Large Language Models: A Causal Approach](https://arxiv.org/abs/2602.01711)
*Wei Chen,Yanbin Fang,Shuran Fu,Fasheng Xu,Xuan Wei*

Main category: cs.AI

TL;DR: 本文提出了一种名为 Causal Prompt Optimization (CPO) 的框架，利用因果推断来优化大型语言模型（LLMs）的提示设计，克服了现有方法在适应异构查询和处理离线奖励模型时的挑战，并在数学推理、可视化和数据分析等领域取得了优于现有方法的性能，同时显著降低了成本。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在企业工作流程中的表现高度依赖于提示设计，但现有自动提示优化（APO）方法存在两个主要挑战：1. 静态指令无法适应异构查询；2. 动态方法依赖的离线奖励模型混淆了提示效果和查询特性。因此，需要一种新的方法来解决提示优化的不稳定性和效率问题。

Method: CPO 框架分为两个阶段：1. 学习离线因果奖励模型，通过应用双重机器学习（DML）到提示和查询的语义嵌入上，隔离提示变化与查询属性的因果效应。2. 利用无偏的奖励信号，在不依赖昂贵的在线评估的情况下，指导对特定查询提示进行资源高效的搜索。

Result: CPO 在数学推理、可视化和数据分析等基准测试中，始终优于人工设计的提示和最先进的自动化优化器。尤其是在困难查询上，CPO 的性能提升更为显著，显示出更强的鲁棒性。此外，CPO 将评估从实时模型执行转移到离线因果模型，能够以远低于在线方法推理成本的方式实现高精度、每个查询的定制化。

Conclusion: 因果推断为可靠且经济高效的企业 LLM 部署中的提示优化提供了一个可扩展的基础。CPO 通过其因果估计方法，克服了现有 APO 方法的局限性，在性能和成本效益上都取得了显著的进步。

Abstract: Large Language Models (LLMs) are increasingly embedded in enterprise workflows, yet their performance remains highly sensitive to prompt design. Automatic Prompt Optimization (APO) seeks to mitigate this instability, but existing approaches face two persistent challenges. First, commonly used prompt strategies rely on static instructions that perform well on average but fail to adapt to heterogeneous queries. Second, more dynamic approaches depend on offline reward models that are fundamentally correlational, confounding prompt effectiveness with query characteristics. We propose Causal Prompt Optimization (CPO), a framework that reframes prompt design as a problem of causal estimation. CPO operates in two stages. First, it learns an offline causal reward model by applying Double Machine Learning (DML) to semantic embeddings of prompts and queries, isolating the causal effect of prompt variations from confounding query attributes. Second, it utilizes this unbiased reward signal to guide a resource-efficient search for query-specific prompts without relying on costly online evaluation. We evaluate CPO across benchmarks in mathematical reasoning, visualization, and data analytics. CPO consistently outperforms human-engineered prompts and state-of-the-art automated optimizers. The gains are driven primarily by improved robustness on hard queries, where existing methods tend to deteriorate. Beyond performance, CPO fundamentally reshapes the economics of prompt optimization: by shifting evaluation from real-time model execution to an offline causal model, it enables high-precision, per-query customization at a fraction of the inference cost required by online methods. Together, these results establish causal inference as a scalable foundation for reliable and cost-efficient prompt optimization in enterprise LLM deployments.

</details>


### [106] [MACD: Model-Aware Contrastive Decoding via Counterfactual Data](https://arxiv.org/abs/2602.01740)
*Qixin Xiao,Kun Zhou*

Main category: cs.AI

TL;DR: 提出了一种名为MACD的新颖推理策略，通过使用视频语言模型（Video-LLM）自身的反馈来生成有针对性的反事实输入，以减轻模型幻觉问题，并在多项基准测试中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频语言模型容易产生幻觉，尤其是在视觉证据不足、模糊或存在偏见时。现有的对比解码方法依赖于随机扰动来缓解幻觉，但难以控制导致幻觉的视觉线索，也无法很好地匹配模型的弱点。

Method: 提出了一种名为MACD（Model-aware Counterfactual Data based Contrastive Decoding）的新颖推理策略。该方法结合了模型引导的反事实生成和解码过程。具体而言，它利用Video-LLM自身的反馈来识别最易导致幻觉的对象区域，并生成对象级别的反事实输入，而不是任意修改帧或时间。然后，将这些模型感知反事实数据集成到对比解码中，以在解码过程中强制执行基于证据的token选择。

Result: 在EventHallusion、MVBench、Perception-test和Video-MME等数据集上进行的实验表明，MACD能够持续减少幻觉，同时在Qwen和InternVL等多种Video-LLM上保持或提高任务准确性。该方法在处理小物体、被遮挡物体或同时出现的物体等具有挑战性的场景时尤其有效。

Conclusion: MACD是一种有效的推理策略，通过模型驱动的反事实数据生成来解决视频语言模型的幻觉问题，并在多种模型和基准测试中表现出优越的性能，尤其是在处理视觉线索复杂的情况下。

Abstract: Video language models (Video-LLMs) are prone to hallucinations, often generating plausible but ungrounded content when visual evidence is weak, ambiguous, or biased. Existing decoding methods, such as contrastive decoding (CD), rely on random perturbations to construct contrastive data for mitigating hallucination patterns. However, such a way is hard to control the visual cues that drive hallucination or well align with model weaknesses. We propose Model-aware Counterfactual Data based Contrastive Decoding (MACD), a new inference strategy that combines model-guided counterfactual construction with decoding. Our approach uses the Video-LLM's own feedback to identify object regions most responsible for hallucination, generating targeted counterfactual inputs at the object level rather than arbitrary frame or temporal modifications. These model-aware counterfactual data is then integrated into CD to enforce evidence-grounded token selection during decoding. Experiments on EventHallusion, MVBench, Perception-test and Video-MME show that MACD consistently reduces hallucination while maintaining or improving task accuracy across diverse Video-LLMs, including Qwen and InternVL families. The method is especially effective in challenging scenarios involving small, occluded, or co-occurring objects. Our code and data will be publicly released.

</details>


### [107] [Controlling Exploration-Exploitation in GFlowNets via Markov Chain Perspectives](https://arxiv.org/abs/2602.01749)
*Lin Chen,Samuel Drapeau,Fanghao Shao,Xuekai Zhu,Bo Xue,Yunchong Song,Mathieu Laurière,Zhouhan Lin*

Main category: cs.AI

TL;DR: 研究提出了一种名为 $α$-GFNs 的 GFlowNets 变体，通过引入参数 $α$ 来调整探索-利用的权衡，从而提升了模式发现能力，并在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的 GFlowNets 目标函数在训练过程中可能对探索-利用的权衡造成了限制，限制了其探索能力。

Method: 通过将 GFlowNets 与马尔可夫链联系起来，揭示了 GFlowNets 目标函数与马尔可夫链可逆性之间的等价性。基于此理论发现，提出了 $α$-GFNs，通过引入可调参数 $α$ 来泛化混合策略，从而直接控制探索-利用的动态。

Result: 在 Set、Bit Sequence 和 Molecule Generation 等多个基准测试中，$α$-GFN 目标函数相比于之前的 GFlowNets 目标函数取得了更好的性能，发现了多达 $10 	imes$ 更多的模式。

Conclusion: $α$-GFNs 通过引入参数 $α$ 能够有效地提升 GFlowNets 的模式发现能力，并保证了收敛到唯一的流。

Abstract: Generative Flow Network (GFlowNet) objectives implicitly fix an equal mixing of forward and backward policies, potentially constraining the exploration-exploitation trade-off during training. By further exploring the link between GFlowNets and Markov chains, we establish an equivalence between GFlowNet objectives and Markov chain reversibility, thereby revealing the origin of such constraints, and provide a framework for adapting Markov chain properties to GFlowNets. Building on these theoretical findings, we propose $α$-GFNs, which generalize the mixing via a tunable parameter $α$. This generalization enables direct control over exploration-exploitation dynamics to enhance mode discovery capabilities, while ensuring convergence to unique flows. Across various benchmarks, including Set, Bit Sequence, and Molecule Generation, $α$-GFN objectives consistently outperform previous GFlowNet objectives, achieving up to a $10 \times$ increase in the number of discovered modes.

</details>


### [108] [Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking](https://arxiv.org/abs/2602.01750)
*Mohammad Beigi,Ming Jin,Junshan Zhang,Qifan Wang,Lifu Huang*

Main category: cs.AI

TL;DR: 本文提出了一种名为ARA（Adversarial Reward Auditing）的框架，通过将奖励劫持视为一个动态竞争博弈，有效地解决了RLHF中模型利用奖励模型中的虚假相关性来达到高分但违背人类意图的问题。ARA通过训练Hacker发现漏洞，Auditor检测漏洞，并利用Auditor指导RLHF（AG-RLHF）来控制奖励信号，将奖励劫持从不可见的问题转变为可测量和可控的信号。


<details>
  <summary>Details</summary>
Motivation: 现有的RLHF方法容易受到奖励劫持的攻击，即模型利用奖励模型中的虚假相关性来获得高分，但行为却违背了人类的真实意图。现有的防御措施是静态的，无法适应新的攻击策略。

Method: ARA框架分两阶段进行：1. Hacker策略发现奖励模型的漏洞，Auditor学习检测潜在表示中的利用行为。2. Auditor-Guided RLHF（AG-RLHF）门控奖励信号，以惩罚检测到的劫持行为，将奖励劫持从不可见的失败转变为可衡量、可控的信号。

Result: 在三种劫持场景的实验中，ARA在对齐-效用权衡方面优于所有基线：将迎合行为减少到接近SFT的水平，同时提高帮助性；减少冗余性，同时获得最高的ROUGE-L；抑制代码游戏，同时提高Pass@1。此外，奖励劫持、检测和缓解在不同领域之间具有泛化性。

Conclusion: ARA框架能够有效地检测和缓解RLHF中的奖励劫持问题，并在保持模型效用的同时实现更好的对齐，并且该方法在不同领域具有良好的泛化能力，可以实现跨领域的防御。

Abstract: Reinforcement Learning from Human Feedback (RLHF) remains vulnerable to reward hacking, where models exploit spurious correlations in learned reward models to achieve high scores while violating human intent. Existing mitigations rely on static defenses that cannot adapt to novel exploitation strategies. We propose Adversarial Reward Auditing (ARA), a framework that reconceptualizes reward hacking as a dynamic, competitive game. ARA operates in two stages: first, a Hacker policy discovers reward model vulnerabilities while an Auditor learns to detect exploitation from latent representations; second, Auditor-Guided RLHF (AG-RLHF) gates reward signals to penalize detected hacking, transforming reward hacking from an unobservable failure into a measurable, controllable signal. Experiments across three hacking scenarios demonstrate that ARA achieves the best alignment-utility tradeoff among all baselines: reducing sycophancy to near-SFT levels while improving helpfulness, decreasing verbosity while achieving the highest ROUGE-L, and suppressing code gaming while improving Pass@1. Beyond single-domain evaluation, we show that reward hacking, detection, and mitigation all generalize across domains -- a Hacker trained on code gaming exhibits increased sycophancy despite no reward for this behavior, and an Auditor trained on one domain effectively suppresses exploitation in others, enabling efficient multi-domain defense with a single model.

</details>


### [109] [PRISM: Parametrically Refactoring Inference for Speculative Sampling Draft Models](https://arxiv.org/abs/2602.01762)
*Xuliang Wang,Yuetao Chen,Maochan Zhen,Fang Liu,Xinzhou Zheng,Xingwu Liu,Hong Xu,Ming Li*

Main category: cs.AI

TL;DR: 本文提出了一种名为 PRISM 的新型架构，用于加速大型语言模型（LLMs）的解码过程。PRISM 通过将每个预测步骤的计算分散到不同的参数集，从而解耦了模型容量与推理成本，有效提高了解码速度和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有的投机解码方法倾向于使用更大的草稿模型来提高草稿质量，但这会带来显著的计算开销。研究者希望在不牺牲模型能力的情况下，降低计算成本，加速 LLM 解码。

Method: PRISM 架构通过将每个预测步骤的计算分解到不同的参数集，重构了草稿模型的计算路径，实现了模型容量与推理成本的分离。通过实验验证其性能。

Result: PRISM 在草稿质量和计算效率方面优于现有草稿模型，实现了更高的接受长度和更低的草稿延迟。在优化后的推理引擎上，PRISM 将解码吞吐量提高了 2.6 倍以上。此外，PRISM 在扩展数据量时表现出比其他草稿模型更优越的扩展性。

Conclusion: PRISM 是一种有效的架构创新，能够显著加速 LLM 的解码过程，并通过解耦模型容量与推理成本，实现了卓越的性能和可扩展性。

Abstract: Large Language Models (LLMs), constrained by their auto-regressive nature, suffer from slow decoding. Speculative decoding methods have emerged as a promising solution to accelerate LLM decoding, attracting attention from both systems and AI research communities. Recently, the pursuit of better draft quality has driven a trend toward parametrically larger draft models, which inevitably introduces substantial computational overhead. While existing work attempts to balance the trade-off between prediction accuracy and compute latency, we address this fundamental dilemma through architectural innovation.
  We propose PRISM, which disaggregates the computation of each predictive step across different parameter sets, refactoring the computational pathways of draft models to successfully decouple model capacity from inference cost. Through extensive experiments, we demonstrate that PRISM outperforms all existing draft architectures, achieving exceptional acceptance lengths while maintaining minimal draft latency for superior end-to-end speedup. We also re-examine scaling laws with PRISM, revealing that PRISM scales more effectively with expanding data volumes than other draft architectures. Through rigorous and fair comparison, we show that PRISM boosts the decoding throughput of an already highly optimized inference engine by more than 2.6x.

</details>


### [110] [Efficient Cross-Architecture Knowledge Transfer for Large-Scale Online User Response Prediction](https://arxiv.org/abs/2602.01775)
*Yucheng Wu,Yuekui Yang,Hongzheng Li,Anan Liu,Jian Xiao,Junjie Zhai,Huan Yu,Shaoping Ma,Leye Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为CrossAdapt的两阶段框架，用于高效地将知识从一个模型迁移到另一个模型，以解决大规模用户响应预测系统中模型切换的高成本问题。该框架通过创新的嵌入层迁移、渐进式网络蒸馏、异步协同蒸馏和分布感知适应机制，显著提高了知识迁移的效率和效果，同时减少了训练时间和成本。


<details>
  <summary>Details</summary>
Motivation: 在大型用户响应预测系统中部署新架构会产生高昂的模型切换成本，这源于大规模历史数据的昂贵再训练和数据保留约束下的性能下降。现有的知识蒸馏方法在处理架构异构性和传输大型嵌入表的高昂成本方面存在困难。

Method: 提出了一种名为CrossAdapt的两阶段框架。第一阶段（离线）通过维度自适应投影实现快速嵌入迁移，无需迭代训练，并结合渐进式网络蒸馏和策略性采样来降低计算成本。第二阶段（在线）引入异步协同蒸馏，学生模型频繁更新而教师模型更新不频繁，并结合分布感知适应机制，动态平衡历史知识保留和对演进数据的快速适应。

Result: 在三个公开数据集上的实验表明，CrossAdapt在AUC方面提高了0.27-0.43%，同时将训练时间缩短了43-71%。在腾讯微信频道（约1000万日样本）上的大规模部署进一步证明了其有效性，与标准的蒸馏基线相比，显著缓解了AUC下降、LogLoss增加和预测偏差。

Conclusion: CrossAdapt是一个高效的跨架构知识迁移框架，能够有效解决大规模用户响应预测系统中部署新架构所面临的模型切换成本高的问题。通过其创新的技术，CrossAdapt在提高模型性能的同时，显著降低了训练时间和计算资源消耗，并在实际大规模部署中得到了验证。

Abstract: Deploying new architectures in large-scale user response prediction systems incurs high model switching costs due to expensive retraining on massive historical data and performance degradation under data retention constraints. Existing knowledge distillation methods struggle with architectural heterogeneity and the prohibitive cost of transferring large embedding tables. We propose CrossAdapt, a two-stage framework for efficient cross-architecture knowledge transfer. The offline stage enables rapid embedding transfer via dimension-adaptive projections without iterative training, combined with progressive network distillation and strategic sampling to reduce computational cost. The online stage introduces asymmetric co-distillation, where students update frequently while teachers update infrequently, together with a distribution-aware adaptation mechanism that dynamically balances historical knowledge preservation and fast adaptation to evolving data. Experiments on three public datasets show that CrossAdapt achieves 0.27-0.43% AUC improvements while reducing training time by 43-71%. Large-scale deployment on Tencent WeChat Channels (~10M daily samples) further demonstrates its effectiveness, significantly mitigating AUC degradation, LogLoss increase, and prediction bias compared to standard distillation baselines.

</details>


### [111] [LingLanMiDian: Systematic Evaluation of LLMs on TCM Knowledge and Clinical Reasoning](https://arxiv.org/abs/2602.01779)
*Rui Hua,Yu Wei,Zixin Shu,Kai Chang,Dengying Yan,Jianan Xia,Zeyu Liu,Hui Zhu,Shujie Song,Mingzhong Xiao,Xiaodong Li,Dongmei Jia,Zhuye Gao,Yanyan Meng,Naixuan Zhao,Yu Fu,Haibin Yu,Benman Yu,Yuanyuan Chen,Fei Dong,Zhizhou Meng,Pengcheng Yang,Songxue Zhao,Lijuan Pei,Yunhui Hu,Kan Ding,Jiayuan Duan,Wenmao Yin,Yang Gu,Runshun Zhang,Qiang Zhu,Jian Yu,Jiansheng Li,Baoyan Liu,Wenjia Wang,Xuezhong Zhou*

Main category: cs.AI

TL;DR: 本研究提出了LingLanMiDian (LingLan) 基准，一个大规模、专家级、多任务的中文传统医学（TCM）领域LLM评估套件，旨在解决现有TCM评估工具碎片化、评分不统一等问题。LingLan涵盖知识回忆、多跳推理、信息提取和临床决策等任务，并引入了统一的度量设计、同义词容忍协议、Hard子集以及将诊断和治疗推荐重构为单项选择题。研究对14个主流LLMs进行了零样本评估，揭示了它们在TCM知识理解、推理和临床决策方面的能力差距，特别是Hard子集上的表现远逊于人类专家。


<details>
  <summary>Details</summary>
Motivation: 现有中文传统医学（TCM）领域的大型语言模型（LLM）评估工具存在碎片化、规模不足、评分标准不统一以及偏重生成式评分等问题，阻碍了模型间的公平比较和TCM领域LLM的有效发展。研究者希望建立一个统一、大规模、领域忠实的评估基准。

Method: 研究者构建了一个名为LingLanMiDian (LingLan) 的多任务基准套件，包含知识回忆、多跳推理、信息提取和临床决策（重构为单项选择题）等任务。LingLan采用了统一的度量设计，包含一个同义词容忍协议，以及一个为每个数据集设计的400个问题的Hard子集。使用该基准对14个领先的开源和闭源LLMs进行了零样本评估。

Result: 对14个LLMs的零样本评估提供了对它们在TCM领域知识理解、推理和临床决策支持方面的优势和局限性的统一视角。特别地，在Hard子集上的评估显示，当前LLMs在TCM专业推理能力上与人类专家存在显著差距。

Conclusion: LingLan基准通过整合基础知识和应用推理，并提供标准化的量化评估，为推动TCM LLMs和特定领域医学AI研究奠定了统一、可量化且可扩展的基础。该基准的建立有助于更准确地评估和改进TCM LLMs的性能。

Abstract: Large language models (LLMs) are advancing rapidly in medical NLP, yet Traditional Chinese Medicine (TCM) with its distinctive ontology, terminology, and reasoning patterns requires domain-faithful evaluation. Existing TCM benchmarks are fragmented in coverage and scale and rely on non-unified or generation-heavy scoring that hinders fair comparison. We present the LingLanMiDian (LingLan) benchmark, a large-scale, expert-curated, multi-task suite that unifies evaluation across knowledge recall, multi-hop reasoning, information extraction, and real-world clinical decision-making. LingLan introduces a consistent metric design, a synonym-tolerant protocol for clinical labels, a per-dataset 400-item Hard subset, and a reframing of diagnosis and treatment recommendation into single-choice decision recognition. We conduct comprehensive, zero-shot evaluations on 14 leading open-source and proprietary LLMs, providing a unified perspective on their strengths and limitations in TCM commonsense knowledge understanding, reasoning, and clinical decision support; critically, the evaluation on Hard subset reveals a substantial gap between current models and human experts in TCM-specialized reasoning. By bridging fundamental knowledge and applied reasoning through standardized evaluation, LingLan establishes a unified, quantitative, and extensible foundation for advancing TCM LLMs and domain-specific medical AI research. All evaluation data and code are available at https://github.com/TCMAI-BJTU/LingLan and http://tcmnlp.com.

</details>


### [112] [Learning to Guide Local Search for MPE Inference in Probabilistic Graphical Models](https://arxiv.org/abs/2602.01475)
*Brij Malhotra,Shivvrat Arya,Tahrima Rahman,Vibhav Giridhar Gogate*

Main category: cs.AI

TL;DR: 本文提出了一种基于神经网络的“神经摊销”框架，用于在固定图结构的概率图模型中，通过预测移动能够降低到最优解的汉明距离来改进局部搜索算法，从而在重复推理查询时提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 在许多实际应用中，概率图模型是固定的，但需要为不同的证据模式重复进行推理。现有的随机局部搜索（SLS）算法虽然能处理大规模模型，但容易陷入局部最优。虽然像GLS+这样的启发式方法有所改进，但其指导信息无法在多次推理查询之间有效重用。

Method: 该方法训练一个基于注意力机制的神经网络，通过预测局部移动降低到近似最优解的汉明距离的能力来评估这些移动。这个神经网络的输出被用来指导现有的局部搜索过程，权衡短期似然增益和长期潜力。

Result: 该方法在重复推理查询的场景下，通过在选择邻居时平衡短期似然增益和长期潜力，实现了比SLS和GLS+在具有挑战性的高树宽基准上的持续改进。

Conclusion: 所提出的神经摊销框架通过利用固定图结构并学习可重用的指导信号，能够显著提高局部搜索算法在重复查询推理中的性能，并提供了理论依据支持其改进的收敛行为。

Abstract: Most Probable Explanation (MPE) inference in Probabilistic Graphical Models (PGMs) is a fundamental yet computationally challenging problem arising in domains such as diagnosis, planning, and structured prediction. In many practical settings, the graphical model remains fixed while inference must be performed repeatedly for varying evidence patterns. Stochastic Local Search (SLS) algorithms scale to large models but rely on myopic best-improvement rule that prioritizes immediate likelihood gains and often stagnate in poor local optima. Heuristics such as Guided Local Search (GLS+) partially alleviate this limitation by modifying the search landscape, but their guidance cannot be reused effectively across multiple inference queries on the same model. We propose a neural amortization framework for improving local search in this repeated-query regime. Exploiting the fixed graph structure, we train an attention-based network to score local moves by predicting their ability to reduce Hamming distance to a near-optimal solution. Our approach integrates seamlessly with existing local search procedures, using this signal to balance short-term likelihood gains with long-term promise during neighbor selection. We provide theoretical intuition linking distance-reducing move selection to improved convergence behavior, and empirically demonstrate consistent improvements over SLS and GLS+ on challenging high-treewidth benchmarks in the amortized inference setting.

</details>


### [113] [INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery](https://arxiv.org/abs/2602.01815)
*Yunhui Jang,Seonghyun Park,Jaehyung Kim,Sungsoo Ahn*

Main category: cs.AI

TL;DR: 提出INDIBATOR框架，通过结合出版物和分子历史来创建个体化科学家档案，以改进多智能体系统在分子发现中的行为区分，并取得了优于粗粒度角色的成果。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统在区分智能体行为时过于简化，未能体现人类科学家独特的科研轨迹，需要更精细化的个体化方法。

Method: 构建INDIBATOR框架，该框架基于两种模态（出版物历史和分子历史）的个体化科学家档案来塑造智能体，并通过多轮辩论（提案、批评、投票）进行互动。

Result: 基于个体化档案的智能体在分子发现任务中表现优于依赖粗粒度角色的系统，达到了具有竞争力的或最先进的性能。

Conclusion: 捕捉个体智能体的“科学DNA”对于实现高质量的科学发现至关重要，INDIBATOR框架有效实现了这一点。

Abstract: Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer'' or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, a framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal, critique, and voting phases. Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the ``scientific DNA'' of individual agents is essential for high-quality discovery.

</details>


### [114] [ORCH: many analyses, one merge-a deterministic multi-agent orchestrator for discrete-choice reasoning with EMA-guided routing](https://arxiv.org/abs/2602.01797)
*Hanlin Zhou,Huah Yong Chan*

Main category: cs.AI

TL;DR: 本文提出了一种名为 ORCH 的确定性多智能体协作框架，用于离散选择推理任务，该框架通过独立的分析和集成的决策来提高 LLM 的性能和可解释性，并在多个基准测试中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体 LLM 系统通常依赖于随机路由或启发式方法，导致行为难以复现且决策过程难以解释。作者希望开发一种更可控、可解释且易于部署的框架。

Method: ORCH 遵循“多分析，一决策”的范式：多个基础 LLM 独立生成结构化分析，然后由一个专门的合并代理做出最终决策。框架使用固定的规则进行任务分解和答案聚合，确保了可预测性和可复现性。可选地，引入了一个 EMA（指数移动平均）引导的路由器，该路由器根据历史准确性、延迟或成本来更新代理选择，主要用于基准测试、受控评估或延迟反馈设置。

Result: 在 MMLU、MMLU-Pro 和 GSM8K 数据集上的实验表明，ORCH 的性能始终优于单一模型基线和多数投票集成。在 MMLU-Pro 上，ORCH 的准确率比最强的基线提高了 10 多分；在 GSM8K 上，提升超过 50 分。EMA 路由器提供了额外的 0.7-2.0 分的准确率提升。消融实验表明，多智能体协作和路由选择都对性能有显著贡献。

Conclusion: ORCH 提供了一种实用且可控、可解释的 LLM 智能体系统实现方法，适用于离散选择推理任务，并且易于部署。

Abstract: Recent advances in large-scale language models (LLMs) have made multi-agent architectures attractive for challenging reasoning tasks. However, many existing systems rely on stochastic routing or ad-hoc heuristics, making their behavior difficult to reproduce and their decision process hard to interpret. We propose ORCH, a deterministic coordination framework for discrete-choice reasoning that orchestrates heterogeneous LLMs. ORCH follows a ``many analyses, one decision'' paradigm: multiple base models independently produce structured analyses, and a dedicated merge agent outputs the final choice. The framework uses fixed rules for task decomposition and answer aggregation, keeping the pipeline predictable, reproducible, and training-free. Determinism here refers to fixed routing and aggregation rules under a fixed evaluation protocol, rather than strict bit-level reproducibility across deployments. To exploit model complementarity, we optionally introduce an EMA-guided router that updates agent selection using historical accuracy, latency, or cost; since it relies on answer-based feedback, it is mainly intended for benchmarking, controlled evaluation, or delayed-feedback settings. Experiments on MMLU, MMLU-Pro, and GSM8K show that ORCH consistently outperforms single-model baselines and a majority-vote ensemble. On MMLU-Pro, ORCH improves accuracy by over 10 points compared to the strongest baseline, and on GSM8K it yields gains exceeding 50 points; McNemar tests confirm statistical significance. The EMA router provides an additional 0.7--2.0 point accuracy boost, and ablations show that both multi-agent collaboration and routing contribute substantially. Overall, ORCH offers a practical path toward controllable, interpretable, and deployment-ready LLM-based agent systems for discrete-choice reasoning.

</details>


### [115] [Synesthesia of Vehicles: Tactile Data Synthesis from Visual Inputs](https://arxiv.org/abs/2602.01832)
*Rui Wang,Yaoguang Cao,Yuyi Chen,Jianyi Xu,Zhuoyang Li,Jiachen Shang,Shichun Yang*

Main category: cs.AI

TL;DR: 提出了一种名为SoV（Synesthesia of Vehicles）的新框架，通过视觉输入预测触觉激励，以增强自动驾驶汽车（AV）的安全性和动态控制。该框架使用跨模态时空对齐方法处理时空差异，并采用基于潜在扩散的VTSyn模型进行无监督的触觉数据合成。实验结果表明，VTSyn在多项指标上优于现有模型，提高了AV的主动触觉感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶汽车的视觉和光学传感器无法检测对车辆动力学控制至关重要的道路激励。受到人类联觉的启发，研究旨在开发一种能够从视觉输入预测触觉激励的方法，以弥补现有传感器的不足，提高AV的安全性。

Method: 1. 提出SoV（Synesthesia of Vehicles）框架，用于从视觉输入预测触觉激励。
2. 开发跨模态时空对齐方法，解决视觉和触觉数据之间的时间和空间差异。
3. 设计视觉-触觉联觉（VTSyn）生成模型，采用潜在扩散技术进行无监督的高质量触觉数据合成。
4. 收集了包含真实车辆感知系统在不同道路和光照条件下的多模态数据集。

Result: VTSyn模型在时间、频率和分类性能上均优于现有模型。通过主动触觉感知，显著提升了自动驾驶汽车的安全性。

Conclusion: SoV框架和VTSyn模型能够有效地从视觉信息中预测触觉激励，通过无监督学习生成高质量的触觉数据，并有效解决了跨模态的时空差异问题。该方法能够显著提升自动驾驶汽车在动态控制和安全方面的能力，尤其是在处理道路激励方面具有重要意义。

Abstract: Autonomous vehicles (AVs) rely on multi-modal fusion for safety, but current visual and optical sensors fail to detect road-induced excitations which are critical for vehicles' dynamic control. Inspired by human synesthesia, we propose the Synesthesia of Vehicles (SoV), a novel framework to predict tactile excitations from visual inputs for autonomous vehicles. We develop a cross-modal spatiotemporal alignment method to address temporal and spatial disparities. Furthermore, a visual-tactile synesthetic (VTSyn) generative model using latent diffusion is proposed for unsupervised high-quality tactile data synthesis. A real-vehicle perception system collected a multi-modal dataset across diverse road and lighting conditions. Extensive experiments show that VTSyn outperforms existing models in temporal, frequency, and classification performance, enhancing AV safety through proactive tactile perception.

</details>


### [116] [ROMA: Recursive Open Meta-Agent Framework for Long-Horizon Multi-Agent Systems](https://arxiv.org/abs/2602.01848)
*Salaheddin Alzu'bi,Baran Nama,Arda Kaz,Anushri Eswaran,Weiyuan Chen,Sarvesh Khetan,Rishab Bala,Tu Vu,Sewoong Oh*

Main category: cs.AI

TL;DR: ROMA是一个新的领域无关框架，通过递归任务分解和结构化聚合来解决现有代理框架在长远任务上的不足，引入了Atomizer、Planner、Executor和Aggregator四种模块化角色，并结合GEPA+提示生成器，在推理和长篇生成任务上取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有的智能体框架在长远任务上表现不佳，因为随着推理深度的增加，顺序编排变得脆弱，上下文窗口有限，且执行过程不透明难以调试。

Method: ROMA框架通过递归任务分解生成依赖感知的子任务树，支持并行执行；通过聚合压缩和验证中间结果来控制上下文增长。框架包含Atomizer、Planner、Executor和Aggregator四种模块化角色，分离了编排和模型选择。GEPA+提示生成器用于在不微调模型的情况下搜索最佳提示。

Result: ROMA结合GEPA+在SEAL-0（冲突网络证据推理）上将GLM-4.6的准确率提高了9.9%；在EQ-Bench（长篇写作）上，ROMA使DeepSeek-V3能媲美Claude Sonnet 4.5等闭源模型。

Conclusion: 递归、模块化的智能体架构可以扩展推理深度，同时保持可解释性、灵活性和模型无关性。

Abstract: Current agentic frameworks underperform on long-horizon tasks. As reasoning depth increases, sequential orchestration becomes brittle, context windows impose hard limits that degrade performance, and opaque execution traces make failures difficult to localize or debug. We introduce ROMA (Recursive Open Meta-Agents), a domain-agnostic framework that addresses these limitations through recursive task decomposition and structured aggregation. ROMA decomposes goals into dependency-aware subtask trees that can be executed in parallel, while aggregation compresses and validates intermediate results to control context growth. Our framework standardizes agent construction around four modular roles --Atomizer (which decides whether a task should be decomposed), Planner, Executor, and Aggregator -- which cleanly separate orchestration from model selection and enable transparent, hierarchical execution traces. This design supports heterogeneous multi-agent systems that mix models and tools according to cost, latency, and capability. To adapt ROMA to specific tasks without fine-tuning, we further introduce GEPA$+$, an improved Genetic-Pareto prompt proposer that searches over prompts within ROMA's component hierarchy while preserving interface contracts. We show that ROMA, combined with GEPA+, delivers leading system-level performance on reasoning and long-form generation benchmarks. On SEAL-0, which evaluates reasoning over conflicting web evidence, ROMA instantiated with GLM-4.6 improves accuracy by 9.9\% over Kimi-Researcher. On EQ-Bench, a long-form writing benchmark, ROMA enables DeepSeek-V3 to match the performance of leading closed-source models such as Claude Sonnet 4.5. Our results demonstrate that recursive, modular agent architectures can scale reasoning depth while remaining interpretable, flexible, and model-agnostic.

</details>


### [117] [SOPRAG: Multi-view Graph Experts Retrieval for Industrial Standard Operating Procedures](https://arxiv.org/abs/2602.01858)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

TL;DR: 提出了一种名为 SOPRAG 的新框架，用于改进工业标准操作程序（SOP）的检索。SOPRAG 使用专门的专家（实体、因果、流程图）来处理 SOP 的复杂性，并引入了一个程序卡层和一个 LLM 引导的门控机制来优化检索。此外，还开发了一个自动化的多代理工作流来构建基准。实验证明 SOPRAG 在检索准确性和响应效用方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于语义的检索增强生成（RAG）范式在处理工业 SOP 的检索时存在局限性，例如专有结构、条件相关性和执行需求等问题。

Method: 提出 SOPRAG 框架，该框架使用实体、因果和流程图专家替代了传统的块状划分。通过程序卡层来优化和协调这些专家，减少搜索空间，并通过 LLM 引导的门控机制动态加权专家以对齐检索意图。还开发了一个自动化的多代理工作流来构建领域特定的基准。

Result: 在四个工业领域进行了广泛的实验，SOPRAG 在检索准确性和响应效用方面显著优于包括词汇、密集和基于图的 RAG 方法在内的基线。在真实世界的关键任务中达到了完美的执行分数。

Conclusion: SOPRAG 框架成功解决了工业 SOP 检索的挑战，通过引入结构化和逻辑化的专家以及优化的协调机制，显著提高了检索性能，并为实际应用中的 SOP 执行提供了支持。

Abstract: Standard Operating Procedures (SOPs) are essential for ensuring operational safety and consistency in industrial environments. However, retrieving and following these procedures presents unique challenges, such as rigid proprietary structures, condition-dependent relevance, and actionable execution requirement, which standard semantic-driven Retrieval-Augmented Generation (RAG) paradigms fail to address. Inspired by the Mixture-of-Experts (MoE) paradigm, we propose SOPRAG, a novel framework specifically designed to address the above pain points in SOP retrieval. SOPRAG replaces flat chunking with specialized Entity, Causal, and Flow graph experts to resolve industrial structural and logical complexities. To optimize and coordinate these experts, we propose a Procedure Card layer that prunes the search space to eliminate computational noise, and an LLM-Guided gating mechanism that dynamically weights these experts to align retrieval with operator intent. To address the scarcity of domain-specific data, we also introduce an automated, multi-agent workflow for benchmark construction. Extensive experiments across four industrial domains demonstrate that SOPRAG significantly outperforms strong lexical, dense, and graph-based RAG baselines in both retrieval accuracy and response utility, achieving perfect execution scores in real-world critical tasks.

</details>


### [118] [ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents](https://arxiv.org/abs/2602.01869)
*Qirui Mi,Zhijian Ma,Mengyue Yang,Haoxuan Li,Yisen Wang,Haifeng Zhang,Jun Wang*

Main category: cs.AI

TL;DR: 提出ProcMEM框架，利用无参数更新的方式，让LLM驱动的智能体能够自主学习并重用程序化记忆，以解决现有智能体在重复场景下推理冗余和执行不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的智能体在顺序决策中表现良好，但依赖于即时推理，即使在重复场景下也会重新推导解决方案，导致计算冗余和执行不稳定。

Method: 提出ProcMEM框架，通过形式化Skill-MDP将经验转化为可执行的Skills，并引入Non-Parametric PPO（利用语义梯度生成候选Skills，并用PPO Gate进行验证）来实现技能的可重用性，最后通过基于分数的方法维护程序化记忆。

Result: 在领域内、跨任务和跨智能体场景下，ProcMEM实现了更高的重用率和显著的性能提升，同时实现了极高的内存压缩率。可视化结果表明ProcMEM能够透明地积累、精炼和重用程序化知识。

Conclusion: ProcMEM框架能够有效地使LLM驱动的智能体学习并重用程序化知识，显著提高了其长期自主性和效率，同时解决了计算冗余和执行不稳定的问题。

Abstract: LLM-driven agents demonstrate strong performance in sequential decision-making but often rely on on-the-fly reasoning, re-deriving solutions even in recurring scenarios. This insufficient experience reuse leads to computational redundancy and execution instability. To bridge this gap, we propose ProcMEM, a framework that enables agents to autonomously learn procedural memory from interaction experiences without parameter updates. By formalizing a Skill-MDP, ProcMEM transforms passive episodic narratives into executable Skills defined by activation, execution, and termination conditions to ensure executability. To achieve reliable reusability without capability degradation, we introduce Non-Parametric PPO, which leverages semantic gradients for high-quality candidate generation and a PPO Gate for robust Skill verification. Through score-based maintenance, ProcMEM sustains compact, high-quality procedural memory. Experimental results across in-domain, cross-task, and cross-agent scenarios demonstrate that ProcMEM achieves superior reuse rates and significant performance gains with extreme memory compression. Visualized evolutionary trajectories and Skill distributions further reveal how ProcMEM transparently accumulates, refines, and reuses procedural knowledge to facilitate long-term autonomy.

</details>


### [119] [Entropy-Guided Data-Efficient Training for Multimodal Reasoning Reward Models](https://arxiv.org/abs/2602.01884)
*Shidong Yang,Tongwen Huang,Hao Wen,Yong Wang,Li Chen,Xiangxiang Chu*

Main category: cs.AI

TL;DR: 本文提出了一种名为熵引导训练（EGT）的新方法，用于解决多模态大语言模型奖励模型训练中的数据噪声和样本难度不均问题，通过利用响应熵作为噪声和难度的代理指标，实现了比现有方法更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态奖励模型在训练过程中面临两个主要挑战：一是偏好数据集中固有的噪声会降低模型性能；二是传统训练方法效率低下，未能考虑样本难度差异。

Method: 研究人员发现响应熵与准确率之间存在强相关性，并将其用作无监督的代理指标来衡量标注噪声和样本难度。基于此，提出了熵引导训练（EGT）方法，包括两个策略：1. 熵引导数据精选，以减轻不可靠样本的影响；2. 熵引导训练策略，逐步引入更复杂的样本。

Result: 在三个基准测试上的广泛实验表明，EGT训练的模型在性能上持续优于最先进的多模态奖励模型。

Conclusion: EGT是一种有效的方法，可以通过利用响应熵来解决多模态奖励模型训练中的数据噪声和样本难度不均问题，从而显著提升模型性能。

Abstract: Multimodal reward models are crucial for aligning multimodal large language models with human preferences. Recent works have incorporated reasoning capabilities into these models, achieving promising results. However, training these models suffers from two critical challenges: (1) the inherent noise in preference datasets, which degrades model performance, and (2) the inefficiency of conventional training methods, which ignore the differences in sample difficulty. In this paper, we identify a strong correlation between response entropy and accuracy, indicating that entropy can serve as a reliable and unsupervised proxy for annotation noise and sample difficulty. Based on this insight, we propose a novel Entropy-Guided Training (EGT) approach for multimodal reasoning reward models, which combines two strategies: (1) entropy-guided data curation to mitigate the impact of unreliable samples, and (2) an entropy-guided training strategy that progressively introduces more complex examples. Extensive experiments across three benchmarks show that the EGT-trained model consistently outperforms state-of-the-art multimodal reward models.

</details>


### [120] [Geometric Analysis of Token Selection in Multi-Head Attention](https://arxiv.org/abs/2602.01893)
*Timur Mudarisov,Mikhal Burtsev,Tatiana Petrova,Radu State*

Main category: cs.AI

TL;DR: 本文提出了一种几何框架来分析多头注意力机制，将其视为一种 Top-N 选择过程，并定义了精确率、召回率和 F1 分数等几何指标来量化 token 分离度。理论和实验结果表明，该框架能有效预测注意力的行为，并揭示了 LLaMA-2-7B 中头部的专业化模式。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和解释大型语言模型（LLMs）中多头注意力的工作机制，特别是其 token 选择行为。

Method: 将标准注意力机制视为一种 Top-N 选择过程，并在值-状态空间中进行分析。定义了精确率、召回率和 F1 分数等几何指标来量化分离度，并推导了依赖于维度和裕度的非渐近界限。通过对 LLaMA-2-7B、Gemma-7B 和 Mistral-7B 模型进行实证分析来验证理论。

Result: 理论预测存在一个强烈的非平凡分离度小 N 操作模式，并且序列长度和 sink token 相似度会影响指标。实验结果与理论预测吻合，表明 Top-N 选择会提高分离度，sink token 相似度与召回率相关。在 LLaMA-2-7B 中发现了三种具有不同几何特征的头部专业化模式：Retriever、Mixer 和 Reset。

Conclusion: 注意力机制可以被视为一种结构化的几何分类器，具有可衡量的 token 选择标准。该几何框架提供了头部的可解释性，并为 LLMs 中的几何感知稀疏化和注意力机制设计提供了指导。

Abstract: We present a geometric framework for analysing multi-head attention in large language models (LLMs). Without altering the mechanism, we view standard attention through a top-N selection lens and study its behaviour directly in value-state space. We define geometric metrics - Precision, Recall, and F-score - to quantify separability between selected and non-selected tokens, and derive non-asymptotic bounds with explicit dependence on dimension and margin under empirically motivated assumptions (stable value norms with a compressed sink token, exponential similarity decay, and piecewise attention weight profiles). The theory predicts a small-N operating regime of strongest non-trivial separability and clarifies how sequence length and sink similarity shape the metrics. Empirically, across LLaMA-2-7B, Gemma-7B, and Mistral-7B, measurements closely track the theoretical envelopes: top-N selection sharpens separability, sink similarity correlates with Recall. We also found that in LLaMA-2-7B heads specialize into three regimes - Retriever, Mixer, Reset - with distinct geometric signatures. Overall, attention behaves as a structured geometric classifier with measurable criteria for token selection, offering head level interpretability and informing geometry-aware sparsification and design of attention in LLMs.

</details>


### [121] [DomusFM: A Foundation Model for Smart-Home Sensor Data](https://arxiv.org/abs/2602.01910)
*Michele Fiori,Gabriele Civitarese,Flora D. Salim,Claudio Bettini*

Main category: cs.AI

TL;DR: 本文提出了 DomusFM，一个专门为智能家居传感器数据设计的首个基础模型，它使用自监督对比学习来捕捉事件的语义和时间信息，并在下游任务中超越现有方法，尤其是在数据稀疏的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有智能家居传感器数据分析方法存在数据标注需求高、忽视二元传感器数据的特性、以及基于大语言模型的方案成本高和隐私顾虑等问题，促使研究者开发更高效、更实用的解决方案。

Method: DomusFM 采用自监督的双对比学习范式，结合轻量级语言模型的语义嵌入、时间模式编码器和二元状态编码器，来学习通用的表示。

Result: 在七个公开的智能家居数据集上进行评估，DomusFM 在各种下游任务上均优于最先进的方法，即使在仅有 5% 标注数据的情况下，也能达到出色的性能。

Conclusion: DomusFM 是首个针对智能家居传感器数据设计的预训练基础模型，它通过自监督学习有效解决了数据稀疏问题，并具有实际部署的可行性，能够显著提升活动和事件分析的性能。

Abstract: Smart-home sensor data holds significant potential for several applications, including healthcare monitoring and assistive technologies. Existing approaches, however, face critical limitations. Supervised models require impractical amounts of labeled data. Foundation models for activity recognition focus only on inertial sensors, failing to address the unique characteristics of smart-home binary sensor events: their sparse, discrete nature combined with rich semantic associations. LLM-based approaches, while tested in this domain, still raise several issues regarding the need for natural language descriptions or prompting, and reliance on either external services or expensive hardware, making them infeasible in real-life scenarios due to privacy and cost concerns. We introduce DomusFM, the first foundation model specifically designed and pretrained for smart-home sensor data. DomusFM employs a self-supervised dual contrastive learning paradigm to capture both token-level semantic attributes and sequence-level temporal dependencies. By integrating semantic embeddings from a lightweight language model and specialized encoders for temporal patterns and binary states, DomusFM learns generalizable representations that transfer across environments and tasks related to activity and event analysis. Through leave-one-dataset-out evaluation across seven public smart-home datasets, we demonstrate that DomusFM outperforms state-of-the-art baselines on different downstream tasks, achieving superior performance even with only 5% of labeled training data available for fine-tuning. Our approach addresses data scarcity while maintaining practical deployability for real-world smart-home systems.

</details>


### [122] [Large Language Model and Formal Concept Analysis: a comparative study for Topic Modeling](https://arxiv.org/abs/2602.01933)
*Fabrice Boissier,Monica Sen,Irina Rychkova*

Main category: cs.AI

TL;DR: 本文比较了大型语言模型（LLM，具体使用 GPT-5）和形式概念分析（FCA）在主题建模方面的优劣，通过在教学材料和信息系统研究论文上的实验来评估它们。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在文本处理领域备受关注，但其在主题建模上的应用研究较少。同时，形式概念分析（FCA）已被提出作为主题建模的候选方法，但缺乏实际应用案例。因此，本文旨在通过比较 LLM 和 FCA 来深入理解它们在主题建模领域的优势和劣势。

Method: 研究采用了 CREA 流程（一种用于主题建模和可视化的方法）来评估 FCA。对于 LLM，使用了 GPT-5，并采用了一种基于三个提示的零样本（zero-shot）策略：对文档批次进行主题生成、合并批次结果得到最终主题、以及对主题进行标注。实验设置包括复用之前评估 CREA 的教学材料，以及分析 40 篇信息系统研究论文。

Result: 研究通过在教学材料和信息系统研究论文上的实验，比较了 GPT-5 和 FCA 提取主题的效果。具体结果（如提取主题的数量、质量、与实际子领域的匹配度等）将在论文的后续部分详细阐述。

Conclusion: 本文通过对 LLM（GPT-5）和 FCA 在主题建模领域的比较研究，为理解这两种方法在实际应用中的表现提供了见解。研究结果将有助于指导未来在主题建模任务中选择和应用 LLM 或 FCA。

Abstract: Topic modeling is a research field finding increasing applications: historically from document retrieving, to sentiment analysis and text summarization. Large Language Models (LLM) are currently a major trend in text processing, but few works study their usefulness for this task. Formal Concept Analysis (FCA) has recently been presented as a candidate for topic modeling, but no real applied case study has been conducted. In this work, we compare LLM and FCA to better understand their strengths and weakneses in the topic modeling field. FCA is evaluated through the CREA pipeline used in past experiments on topic modeling and visualization, whereas GPT-5 is used for the LLM. A strategy based on three prompts is applied with GPT-5 in a zero-shot setup: topic generation from document batches, merging of batch results into final topics, and topic labeling. A first experiment reuses the teaching materials previously used to evaluate CREA, while a second experiment analyzes 40 research articles in information systems to compare the extracted topics with the underling subfields.

</details>


### [123] [Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models](https://arxiv.org/abs/2602.01970)
*Yun Qu,Qi Wang,Yixiu Mao,Heming Zou,Yuhang Jiang,Weijie Liu,Clive Bai,Kai Yang,Yangkun Chen,Saiyong Yang,Xiangyang Ji*

Main category: cs.AI

TL;DR: 本文提出了一种名为GPS（Generalizable Predictive Prompt Selection）的新方法，通过贝叶斯推理和轻量级生成模型来预测提示词的难度，从而提高强化学习训练大型语言模型的效率。


<details>
  <summary>Details</summary>
Motivation: 当前的强化学习方法在提升大型语言模型推理能力时计算成本高昂，而在线提示词选择虽然能提高效率，但现有方法要么成本高昂，要么泛化能力差。

Method: GPS通过一个轻量级生成模型，利用共享的优化历史进行贝叶斯推理，来预测提示词的难度。它还结合了中间难度优先级和历史锚定多样性原则来选择提示词批次。

Result: GPS在多种推理基准测试中，显著提高了训练效率、最终性能和测试时效率，优于现有基线方法。

Conclusion: GPS是一种有效且通用的提示词选择策略，能够显著降低强化学习训练大型语言模型的计算成本，并提升模型性能。

Abstract: Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization. Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency. However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency, final performance, and test-time efficiency over superior baseline methods.

</details>


### [124] [Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning](https://arxiv.org/abs/2602.01983)
*Xintian Shen,Jiawei Chen,Lihao Zheng,Hao Ma,Tao Wei,Kun Zhan*

Main category: cs.AI

TL;DR: 本文提出了一种名为UCT的无训练框架，使LLM能够从工具使用者转变为工具创造者，通过学习推理经验来动态创建和更新工具，从而在开放式问题解决中提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有工具集成推理（TIR）模型在处理固定工具时存在局限性，无法应对开放式问题；缺乏自优化机制导致错误输出；工具构建耗时且应用受限。研究动机在于打破这些限制，使LLM具备自主学习和适应外部工具的能力。

Method: UCT框架通过“收割”LLM的推理经验，将其提炼为可复用的工具资产，使代理从工具使用者转变为工具创造者。该方法在推理过程中实现自适应工具创建和自我更新，并引入记忆巩固机制来维护工具库，提高经验记忆的复用性，实现无额外训练的持续性能提升。

Result: 在多领域数学和科学推理任务的基准测试中，UCT模型分别取得了+20.86%和+23.04%的性能提升，验证了代理的自进化能力。

Conclusion: UCT提供了一种新的范式，能够增强TIR模型的通用性和自适应能力，通过自主创造和更新工具，使LLM在处理开放式问题时展现出显著的性能优势，且无需额外训练。

Abstract: Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%$\uparrow$ and +23.04%$\uparrow$ on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent.

</details>


### [125] [Emergent Analogical Reasoning in Transformers](https://arxiv.org/abs/2602.01992)
*Gouki Minegishi,Jingyuan Feng,Hiroki Furuta,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.AI

TL;DR: 本研究受范畴论中函子的启发，将类比推理形式化为跨类别实体对应关系的推理。研究表明，Transformer模型中类比推理的出现对数据特性、优化选择和模型规模敏感，并可通过嵌入空间的几何对齐和Transformer内的函子应用来实现。


<details>
  <summary>Details</summary>
Motivation: 尽管类比推理是人类智能的核心能力，但Transformer模型中类比推理的获取和实现机制尚不清楚。

Method: 受函子启发，将类比推理形式化为跨类别实体对应关系的推理，并引入合成任务进行评估。通过机制分析，探究Transformer中类比推理的组成部分。

Result: 类比推理的出现对数据特性、优化选择和模型规模高度敏感。Transformer中的类比推理分解为嵌入空间的几何对齐和Transformer内的函子应用。这些机制使模型能够将关系结构从一个类别转移到另一个类别，从而实现类比。

Conclusion: 研究为类比推理提供了明确的机制解释，并表明在预训练的大型语言模型中也观察到相同的趋势，将类比推理从一个抽象的认知概念转变为现代神经网络中一个具体、有机制依据的现象。

Abstract: Analogy is a central faculty of human intelligence, enabling abstract patterns discovered in one domain to be applied to another. Despite its central role in cognition, the mechanisms by which Transformers acquire and implement analogical reasoning remain poorly understood. In this work, inspired by the notion of functors in category theory, we formalize analogical reasoning as the inference of correspondences between entities across categories. Based on this formulation, we introduce synthetic tasks that evaluate the emergence of analogical reasoning under controlled settings. We find that the emergence of analogical reasoning is highly sensitive to data characteristics, optimization choices, and model scale. Through mechanistic analysis, we show that analogical reasoning in Transformers decomposes into two key components: (1) geometric alignment of relational structure in the embedding space, and (2) the application of a functor within the Transformer. These mechanisms enable models to transfer relational structure from one category to another, realizing analogy. Finally, we quantify these effects and find that the same trends are observed in pretrained LLMs. In doing so, we move analogy from an abstract cognitive notion to a concrete, mechanistically grounded phenomenon in modern neural networks.

</details>


### [126] [Thinking Like a Doctor: Conversational Diagnosis through the Exploration of Diagnostic Knowledge Graphs](https://arxiv.org/abs/2602.01995)
*Jeongmoon Won,Seungwon Kook,Yohan Jo*

Main category: cs.AI

TL;DR: 本研究提出了一种基于知识图谱的对话诊断系统，通过生成诊断假设和验证假设来逐步确定诊断，解决了现有方法在知识参数化和信息不完整方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有对话诊断方法依赖模型参数化知识或假设患者提供充足信息，这在真实情况下不切实际。因此，需要一种能处理信息不完整和进行多轮问询以逐步细化诊断的系统。

Method: 该系统采用两步法：1. 从对话上下文中生成诊断假设；2. 通过澄清性问题来验证假设，并重复此过程直至得出最终诊断。系统利用了诊断知识图谱进行推理，并采用基于MIMIC-IV患者档案的模拟器来评估其性能，同时将模拟器调整为能模拟现实世界中早期临床遭遇时患者含糊不清的症状描述。

Result: 实验结果表明，该系统在诊断准确性和效率方面优于现有强基线方法。医生评估也证实了模拟器的真实性以及生成问题的临床实用性。

Conclusion: 所提出的对话诊断系统能够有效地处理对话历史和知识图谱，通过生成和验证假设来提高诊断准确性和效率，并且模拟器能够较好地反映真实患者的症状描述。

Abstract: Conversational diagnosis requires multi-turn history-taking, where an agent asks clarifying questions to refine differential diagnoses under incomplete information. Existing approaches often rely on the parametric knowledge of a model or assume that patients provide rich and concrete information, which is unrealistic. To address these limitations, we propose a conversational diagnosis system that explores a diagnostic knowledge graph to reason in two steps: (i) generating diagnostic hypotheses from the dialogue context, and (ii) verifying hypotheses through clarifying questions, which are repeated until a final diagnosis is reached. Since evaluating the system requires a realistic patient simulator that responds to the system's questions, we adopt a well-established simulator along with patient profiles from MIMIC-IV. We further adapt it to describe symptoms vaguely to reflect real-world patients during early clinical encounters. Experiments show improved diagnostic accuracy and efficiency over strong baselines, and evaluations by physicians support the realism of our simulator and the clinical utility of the generated questions. Our code will be released upon publication.

</details>


### [127] [Light Alignment Improves LLM Safety via Model Self-Reflection with a Single Neuron](https://arxiv.org/abs/2602.02027)
*Sicheng Shen,Mingyang Lv,Han Shen,Jialin Wu,Binghao Wang,Zhou Yang,Guobin Shen,Dongcheng Zhao,Feifei Zhao,Yi Zeng*

Main category: cs.AI

TL;DR: 提出了一种新的安全感知解码方法，仅需低成本训练专家模型并使用单个神经元作为门控机制，能够在保持模型效用的同时提高输出安全性，并展现出在训练开销和模型规模泛化方面的优势。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM安全对齐方法（主要是后训练方法）计算成本高昂且泛化能力差；轻量级方法则依赖于预先计算的安全注入或模型自身能力，导致泛化能力有限，效率和可用性降低。

Method: 提出一种安全感知解码方法，该方法仅需要低成本训练一个专家模型，并使用一个神经元作为门控机制来平衡模型的内在能力和外部指导。

Result: 该方法在保持模型效用的同时提高了输出安全性，并在训练开销和模型规模的泛化能力方面表现出明显优势。

Conclusion: 该方法为大规模语言模型的安全和实际部署提供了一种新的轻量级对齐视角，有望实现安全性和实用性的兼顾。

Abstract: The safety of large language models (LLMs) has increasingly emerged as a fundamental aspect of their development. Existing safety alignment for LLMs is predominantly achieved through post-training methods, which are computationally expensive and often fail to generalize well across different models. A small number of lightweight alignment approaches either rely heavily on prior-computed safety injections or depend excessively on the model's own capabilities, resulting in limited generalization and degraded efficiency and usability during generation. In this work, we propose a safety-aware decoding method that requires only low-cost training of an expert model and employs a single neuron as a gating mechanism. By effectively balancing the model's intrinsic capabilities with external guidance, our approach simultaneously preserves utility and enhances output safety. It demonstrates clear advantages in training overhead and generalization across model scales, offering a new perspective on lightweight alignment for the safe and practical deployment of large language models. Code: https://github.com/Beijing-AISI/NGSD.

</details>


### [128] [Do I Really Know? Learning Factual Self-Verification for Hallucination Reduction](https://arxiv.org/abs/2602.02018)
*Enes Altinisik,Masoomali Fatehkia,Fatih Deniz,Nadir Durrani,Majd Hawasly,Mohammad Raza,Husrev Taha Sencar*

Main category: cs.AI

TL;DR: 本文提出了一种名为 VeriFY 的训练时框架，通过一致性自我验证来降低大型语言模型的事实幻觉，并在不显著影响召回率的情况下显著减少了幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）事实幻觉的缓解方法要么依赖于事后验证，要么在微调时直接将不确定性映射到弃权，这通常会导致模型行为过于保守。研究者希望找到一种更有效的方法来解决事实幻觉问题。

Method: VeriFY 是一个训练时框架，通过在训练中引入结构化的验证痕迹来指导模型进行自我验证。具体步骤包括：生成初始答案、生成并回答探针验证查询、做出一致性判断，然后决定是否回答或弃权。为了避免训练数据中的幻觉内容被强化，研究者还引入了一种分阶段损失掩码方法，在训练时排除幻觉答案阶段，但保留对验证行为的监督。

Result: VeriFY 在多个模型家族和不同规模下，将事实幻觉率降低了 9.7% 到 53.3%，同时仅有 0.4% 到 5.7% 的召回率适度下降。该方法在仅使用单一数据源进行训练时，就能在不同数据集上泛化。

Conclusion: VeriFY 是一种有效的训练时框架，能够教会 LLMs 通过一致性自我验证来推理事实不确定性，从而显著减少事实幻觉，且对模型召回率的影响有限，并具有良好的泛化能力。

Abstract: Factual hallucination remains a central challenge for large language models (LLMs). Existing mitigation approaches primarily rely on either external post-hoc verification or mapping uncertainty directly to abstention during fine-tuning, often resulting in overly conservative behavior. We propose VeriFY, a training-time framework that teaches LLMs to reason about factual uncertainty through consistency-based self-verification. VeriFY augments training with structured verification traces that guide the model to produce an initial answer, generate and answer a probing verification query, issue a consistency judgment, and then decide whether to answer or abstain. To address the risk of reinforcing hallucinated content when training on augmented traces, we introduce a stage-level loss masking approach that excludes hallucinated answer stages from the training objective while preserving supervision over verification behavior. Across multiple model families and scales, VeriFY reduces factual hallucination rates by 9.7 to 53.3 percent, with only modest reductions in recall (0.4 to 5.7 percent), and generalizes across datasets when trained on a single source. The source code, training data, and trained model checkpoints will be released upon acceptance.

</details>


### [129] [Edit Knowledge, Not Just Facts via Multi-Step Reasoning over Background Stories](https://arxiv.org/abs/2602.02028)
*Ya Gao,Kalle Kujanpää,Pekka Marttinen,Harri Valpola,Alexander Ilin*

Main category: cs.AI

TL;DR: 提出了一种新的知识内化训练策略，通过引入背景故事、使用多步推理问题以及知识蒸馏，使大型语言模型能够更有效地整合和应用新知识。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法主要关注原子事实的记忆，难以将新知识整合到连贯且可跨上下文使用的框架中，限制了AI系统（尤其是LLM）灵活应用新知识进行推理的能力。

Method: 提出了一种基于三个原则的训练策略：1. 将新知识引入为背景故事，以情境化新事实并解释其与现有知识的关系；2. 使用模型自我生成的多跳问题进行训练，这些问题需要结合新旧知识进行多步推理；3. 利用知识蒸馏，让学生模型在无法直接访问新知识的情况下模仿教师模型的推理行为。

Result: 实验表明，采用该策略训练的模型能够有效地在推理过程中利用新获得的知识，并在需要结合多个新事实的复杂问题上取得显著性能提升。

Conclusion: 知识内化本质上是一个推理问题，而非记忆问题。通过结合背景故事、多步推理和知识蒸馏的训练策略，可以使模型更好地整合和应用新知识，从而克服现有知识编辑方法的局限性。

Abstract: Enabling artificial intelligence systems, particularly large language models, to integrate new knowledge and flexibly apply it during reasoning remains a central challenge. Existing knowledge editing approaches emphasize atomic facts, improving factual recall but often failing to integrate new information into a coherent framework usable across contexts. In this work, we argue that knowledge internalization is fundamentally a reasoning problem rather than a memorization problem. Consequently, a model should be trained in situations where the new information is instrumental to solving a task, combined with pre-existing knowledge, and exercised through multi-step reasoning. Based on this insight, we propose a training strategy based on three principles. First, new knowledge is introduced as a coherent background story that contextualizes novel facts and explains their relation to existing knowledge. Second, models are trained using self-generated multi-hop questions that require multi-step reasoning involving the new information. Third, training is done using knowledge distillation, forcing a student model to internalize the teacher's reasoning behavior without access to the novel information. Experiments show that models trained with this strategy effectively leverage newly acquired knowledge during reasoning and achieve remarkable performance on challenging questions that require combining multiple new facts.

</details>


### [130] [Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation](https://arxiv.org/abs/2602.02029)
*Zhongyuan Lyu,Shuoyu Hu,Lujie Liu,Hongxia Yang,Ming LI*

Main category: cs.AI

TL;DR: 本研究提出了一种名为CIR（Canonical Intermediate Representation）的中间表示框架，用于帮助大型语言模型（LLMs）从自然语言描述自动生成优化模型，特别关注处理复杂的复合约束和建模范式。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的自动优化模型构建方法在处理复杂的运营规则（如复合约束和建模范式）时存在不足，促使研究者探索更有效的解决方案。

Method: 研究者提出了CIR（Canonical Intermediate Representation）作为LLMs生成的中间表示，它通过约束原型和候选建模范式来编码运营规则的语义，从而将规则逻辑与其数学实现分离。在此基础上，开发了R2C（rule-to-constraint）框架，一个多智能体流水线，用于解析问题文本，通过检索领域知识合成CIR实现，并最终实例化优化模型。该框架还包含一个反思机制以进一步提升性能。

Result: R2C在作者新构建的包含丰富运营规则的基准测试上取得了47.2%的准确率，达到当前最先进水平。在已有的文献基准测试上，R2C也取得了高度竞争力的结果，接近专有模型（如GPT-5）的性能。引入反思机制后，R2C在某些基准测试上取得了进一步的性能提升，并创下了新的最佳报告结果。

Conclusion: CIR作为一种中间表示，以及基于CIR的R2C框架，能够有效地帮助LLMs从自然语言描述自动生成优化模型，特别是在处理复杂的运营规则方面，显著优于现有方法，并展现出强大的通用性和进一步提升的潜力。

Abstract: Automatically formulating optimization models from natural language descriptions is a growing focus in operations research, yet current LLM-based approaches struggle with the composite constraints and appropriate modeling paradigms required by complex operational rules. To address this, we introduce the Canonical Intermediate Representation (CIR): a schema that LLMs explicitly generate between problem descriptions and optimization models. CIR encodes the semantics of operational rules through constraint archetypes and candidate modeling paradigms, thereby decoupling rule logic from its mathematical instantiation. Upon a newly generated CIR knowledge base, we develop the rule-to-constraint (R2C) framework, a multi-agent pipeline that parses problem texts, synthesizes CIR implementations by retrieving domain knowledge, and instantiates optimization models. To systematically evaluate rule-to-constraint reasoning, we test R2C on our newly constructed benchmark featuring rich operational rules, and benchmarks from prior work. Extensive experiments show that R2C achieves state-of-the-art accuracy on the proposed benchmark (47.2% Accuracy Rate). On established benchmarks from the literature, R2C delivers highly competitive results, approaching the performance of proprietary models (e.g., GPT-5). Moreover, with a reflection mechanism, R2C achieves further gains and sets new best-reported results on some benchmarks.

</details>


### [131] [Constrained Process Maps for Multi-Agent Generative AI Workflows](https://arxiv.org/abs/2602.02034)
*Ananya Joshi,Michael Rudow*

Main category: cs.AI

TL;DR: 提出了一种基于有限范围马尔可夫决策过程（MDP）的多智能体系统，用于处理受监管的复杂多步工作流，量化不确定性并支持人类监督，该系统在AI安全评估案例研究中优于单智能体方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的代理系统在处理受监管环境中的复杂多步工作流时，主要依赖单一代理和提示工程，难以观察和比较模型在处理不确定性、协调以及与人类监督交互方面的表现。

Method: 将多智能体系统形式化为一个有限范围、有向无环图结构的马尔可夫决策过程（MDP）。每个智能体代表一个特定的角色或决策阶段，具有预定义的任务升级或完成转换。使用蒙特卡洛估计量化代理级别的认识不确定性，并利用MDP的终止状态（自动标记或人工审查）捕获系统级别的不确定性。

Result: 在AI安全评估（自残检测）案例研究中，该多智能体系统相比单智能体基线，准确率提高了19%，所需人工审查减少了85倍，并且在某些配置下缩短了处理时间。

Conclusion: 多智能体系统通过明确的结构化和不确定性量化，能够更有效地处理受监管环境中的复杂工作流，并在准确性、人工审查效率和处理时间方面优于单智能体方法。

Abstract: Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence. However, many agentic architectures rely primarily on prompt engineering of a single agent, making it difficult to observe or compare how models handle uncertainty and coordination across interconnected decision stages and with human oversight. We introduce a multi-agent system formalized as a finite-horizon Markov Decision Process (MDP) with a directed acyclic structure. Each agent corresponds to a specific role or decision stage (e.g., content, business, or legal review in a compliance workflow), with predefined transitions representing task escalation or completion. Epistemic uncertainty is quantified at the agent level using Monte Carlo estimation, while system-level uncertainty is captured by the MDP's termination in either an automated labeled state or a human-review state. We illustrate the approach through a case study in AI safety evaluation for self-harm detection, implemented as a multi-agent compliance system. Results demonstrate improvements over a single-agent baseline, including up to a 19\% increase in accuracy, up to an 85x reduction in required human review, and, in some configurations, reduced processing time.

</details>


### [132] [Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models](https://arxiv.org/abs/2602.02039)
*Wei Liu,Peijie Yu,Michele Orini,Yali Du,Yulan He*

Main category: cs.AI

TL;DR: 研究提出了“探究性智能”的概念，区别于仅执行任务的“执行性智能”，并引入了Deep Data Research (DDR) 任务和DDR-Bench基准来评估大型语言模型（LLM）在从原始数据中自主提取见解的能力。结果表明，虽然前沿模型已展现出初步的自主性，但长时程的探究仍具挑战性，并强调了模型内在策略对探究性智能的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在自主性方面，尤其是在设定目标和自主探索方面，仍有提升空间。数据科学领域是评估LLM自主性的天然测试平台，因为真实世界的数据分析往往始于原始数据而非明确的指令，但目前缺乏专注于此的基准。因此，研究旨在开发一种新的评估方法来衡量LLM的“探究性智能”。

Method: 研究提出了“Deep Data Research (DDR)”这一开放式任务，要求LLM能够从数据库中自主地提取关键见解。为了对该任务进行可验证的评估，研究人员构建了一个名为“DDR-Bench”的大规模、基于清单的基准。该基准能够量化和评估LLM在DDR任务中的表现。

Result: 实验结果显示，尽管当前最先进的模型（frontier models）已经展现出新兴的自主能力，但在进行长时程的自主探索方面仍然面临挑战。研究分析表明，有效的探究性智能不仅依赖于外部的代理支架（agent scaffolding）或简单的模型规模扩展，更关键的是模型自身的内在策略。

Conclusion: 研究引入了“探究性智能”的概念，并提出了DDR任务和DDR-Bench基准来评估LLM的这种能力。结果表明，LLM的自主探索能力仍需提升，特别是在长时程任务上。研究强调，发展LLM的探究性智能需要关注模型的内在策略，而非仅仅依赖外部辅助或规模的增长。

Abstract: The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models.

</details>


### [133] [Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents](https://arxiv.org/abs/2602.02050)
*Zeping Li,Hongru Wang,Yiwen Zhao,Guanhua Chen,Yixia Li,Keyang Chen,Yixin Cao,Guangnan Ye,Hongfeng Chai,Mengdi Wang,Zhenfei Yin*

Main category: cs.AI

TL;DR: 本研究提出利用熵减少作为监督信号来优化大型语言模型（LLM）在执行任务时使用工具的行为，以减少不必要的工具调用并提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM工具使用代理在长轨迹任务中常出现过多低质量的工具调用，导致延迟增加和性能下降，管理工具使用行为具有挑战性。

Method: 研究人员通过基于熵的实验观察到熵减少与高质量工具调用的正相关性。在此基础上，提出将熵减少作为监督信号，并设计了两种奖励策略：稀疏结果奖励（用于效率）和密集过程奖励（用于性能）。

Result: 实验结果表明，稀疏结果奖励能将工具调用量与基线平均值相比减少72.07%，密集过程奖励则能将性能提升22.27%。

Conclusion: 熵减少是优化LLM工具使用行为的关键机制，能够使代理在实际应用中更加适应，提高效率和性能。

Abstract: Tool-using agents based on Large Language Models (LLMs) excel in tasks such as mathematical reasoning and multi-hop question answering. However, in long trajectories, agents often trigger excessive and low-quality tool calls, increasing latency and degrading inference performance, making managing tool-use behavior challenging. In this work, we conduct entropy-based pilot experiments and observe a strong positive correlation between entropy reduction and high-quality tool calls. Building on this finding, we propose using entropy reduction as a supervisory signal and design two reward strategies to address the differing needs of optimizing tool-use behavior. Sparse outcome rewards provide coarse, trajectory-level guidance to improve efficiency, while dense process rewards offer fine-grained supervision to enhance performance. Experiments across diverse domains show that both reward designs improve tool-use behavior: the former reduces tool calls by 72.07% compared to the average of baselines, while the latter improves performance by 22.27%. These results position entropy reduction as a key mechanism for enhancing tool-use behavior, enabling agents to be more adaptive in real-world applications.

</details>


### [134] [SIDiffAgent: Self-Improving Diffusion Agent](https://arxiv.org/abs/2602.02051)
*Shivank Garg,Ayush Singh,Gaurav Kumar Nayak*

Main category: cs.AI

TL;DR: 提出了一种名为SIDiffAgent的无需训练的、基于Qwen模型的生成式AI框架，通过自主提示工程、错误检测与纠正以及迭代自改进，提高了文本到图像生成模型的可靠性和一致性，并在GenAIBench上取得了显著优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在实际应用中存在对提示语敏感、语义歧义、生成图像包含伪影以及需要精心设计的提示等局限性，而现有改进方法通常需要额外训练且可控性有限。

Method: SIDiffAgent是一个训练免费的代理框架，利用Qwen系列模型（Qwen-VL, Qwen-Image, Qwen-Edit, Qwen-Embedding）来管理提示工程、检测和纠正生成错误、移除伪影，并通过将过往经验存储在数据库中进行迭代自改进，在生成过程中注入基于提示的指导。

Result: SIDiffAgent在GenAIBench上取得了0.884的平均VQA分数，显著优于开源、专有模型和现有代理方法。

Conclusion: SIDiffAgent通过一种无需训练的代理方法，有效地解决了文本到图像生成模型在提示敏感性、语义理解、伪影去除和可控性方面的挑战，实现了更可靠、一致的图像生成，并在基准测试中展现出领先性能。

Abstract: Text-to-image diffusion models have revolutionized generative AI, enabling high-quality and photorealistic image synthesis. However, their practical deployment remains hindered by several limitations: sensitivity to prompt phrasing, ambiguity in semantic interpretation (e.g., ``mouse" as animal vs. a computer peripheral), artifacts such as distorted anatomy, and the need for carefully engineered input prompts. Existing methods often require additional training and offer limited controllability, restricting their adaptability in real-world applications. We introduce Self-Improving Diffusion Agent (SIDiffAgent), a training-free agentic framework that leverages the Qwen family of models (Qwen-VL, Qwen-Image, Qwen-Edit, Qwen-Embedding) to address these challenges. SIDiffAgent autonomously manages prompt engineering, detects and corrects poor generations, and performs fine-grained artifact removal, yielding more reliable and consistent outputs. It further incorporates iterative self-improvement by storing a memory of previous experiences in a database. This database of past experiences is then used to inject prompt-based guidance at each stage of the agentic pipeline. \modelour achieved an average VQA score of 0.884 on GenAIBench, significantly outperforming open-source, proprietary models and agentic methods. We will publicly release our code upon acceptance.

</details>


### [135] [Understanding the Reversal Curse Mitigation in Masked Diffusion Models through Attention and Training Dynamics](https://arxiv.org/abs/2602.02133)
*Sangwoo Shin,BumJun Kim,Kyelim Lee,Moongyu Jeon,Albert No*

Main category: cs.AI

TL;DR: 本文研究了解释了掩码扩散语言模型（MDMs）克服了自回归语言模型（ARMs）在反向查询方面存在的“反转诅咒”问题。研究表明，MDMs的缓解并非源于任何顺序训练目标，而是源于其架构结构以及与训练的交互作用，特别是Transformer编码器中的权重共享导致了前向和反向注意力得分的正相关，以及梯度对齐。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型（ARMs）在处理反向查询（例如，已知“A是B”，但无法回答“B是A”）时存在“反转诅咒”问题。尽管掩码扩散语言模型（MDMs）在该问题上表现较好，但其原因尚不清楚。作者希望揭示MDMs能够缓解反转诅咒的原因。

Method: 作者通过理论分析和实验验证来解释MDMs缓解反转诅咒的机制。理论上，作者研究了一个单层Transformer编码器，分析了权重共享如何使前向和反向注意力得分正相关，以及梯度如何对齐。实验上，作者在受控的玩具任务和大规模扩散语言模型上进行了验证。

Result: 在单层Transformer编码器中，作者证明了权重共享使得前向和反向注意力得分呈正相关，并且最小化前向损失也能够减小反向损失，因为梯度是对齐的。这些机制在玩具任务和大规模MDMs实验中得到了支持。

Conclusion: MDMs部分克服了ARMs中持续存在的反转诅咒问题，其原因在于其架构结构（特别是Transformer编码器中的权重共享）及其与训练的交互作用，导致了前向和反向注意力得分的正相关以及梯度对齐，而不是普遍认为的任何顺序训练目标。

Abstract: Autoregressive language models (ARMs) suffer from the reversal curse: after learning that "$A$ is $B$", they often fail on the reverse query "$B$ is $A$". Masked diffusion-based language models (MDMs) exhibit this failure in a much weaker form, but the underlying reason has remained unclear. A common explanation attributes this mitigation to the any-order training objective. However, observing "[MASK] is $B$" during training does not necessarily teach the model to handle the reverse prompt "$B$ is [MASK]". We show that the mitigation arises from architectural structure and its interaction with training. In a one-layer Transformer encoder, weight sharing couples the two directions by making forward and reverse attention scores positively correlated. In the same setting, we further show that the corresponding gradients are aligned, so minimizing the forward loss also reduces the reverse loss. Experiments on both controlled toy tasks and large-scale diffusion language models support these mechanisms, explaining why MDMs partially overcome a failure mode that persists in strong ARMs.

</details>


### [136] [Traffic-Aware Navigation in Road Networks](https://arxiv.org/abs/2602.02158)
*Sarah Nassar*

Main category: cs.AI

TL;DR: 该项目比较了三种图搜索算法（Floyd-Warshall-Ingerman、Dijkstra's 和 A*、Yen's）在交通感知导航任务中的应用，并在真实路网（Kingston）上进行了测试。


<details>
  <summary>Details</summary>
Motivation: 为了在交通感知导航任务中找到最优的路线规划算法，需要比较不同图搜索算法的性能和适用性。

Method: 比较了三种图搜索算法：1. Floyd-Warshall-Ingerman（单次多查询预处理）；2. Dijkstra's 和 A*（连续单次实时查询）；3. Yen's（K 短路径预处理后实时迭代）。

Result: Dijkstra's 和 A* 提供了最符合交通情况的最优解，且预处理开销小。Floyd-Warshall-Ingerman 实时速度最快，但仅基于距离，不考虑交通。Yen's 算法预处理开销大，但能在运行速度和最优性之间取得平衡。

Conclusion: 每种算法都有其优缺点，实际部署时需要根据具体情况权衡选择最适合的算法。

Abstract: This project compares three graph search approaches for the task of traffic-aware navigation in Kingston's road network. These approaches include a single-run multi-query preprocessing algorithm (Floyd-Warshall-Ingerman), continuous single-query real-time search (Dijkstra's and A*), and an algorithm combining both approaches to balance between their trade-offs by first finding the top K shortest paths then iterating over them in real time (Yen's). Dijkstra's and A* resulted in the most traffic-aware optimal solutions with minimal preprocessing required. Floyd-Warshall-Ingerman was the fastest in real time but provided distance based paths with no traffic awareness. Yen's algorithm required significant preprocessing but balanced between the other two approaches in terms of runtime speed and optimality. Each approach presents advantages and disadvantages that need to be weighed depending on the circumstances of specific deployment contexts to select the best custom solution. *This project was completed as part of ELEC 844 (Search and Planning Algorithms for Robotics) in the Fall 2025 term.

</details>


### [137] [Mitigating Safety Tax via Distribution-Grounded Refinement in Large Reasoning Models](https://arxiv.org/abs/2602.02136)
*Yingsha Xie,Tiansheng Huang,Enneng Yang,Rui Min,Wenjie Lu,Xiaochun Cao,Naiqiang Tan,Li Shen*

Main category: cs.AI

TL;DR: 本研究提出了一种名为DGR的新方法，用于构建与目标大型推理模型（LRM）内部分布对齐的安全对齐数据集，以减轻安全对齐带来的推理能力下降问题。实验证明，DGR在保持安全性的同时显著提高了推理能力，并发现安全对齐可能主要起到激活潜在知识的作用。


<details>
  <summary>Details</summary>
Motivation: 现有用于大型推理模型（LRM）安全对齐的数据集，由于其推理痕迹和答案与目标LRM存在分布差异，导致了目标LRM通用推理能力的显著下降。研究者假设这种分布差异是导致能力下降的罪魁祸首，因此需要一种新的数据集构建方法来解决这个问题。

Method: 提出了一种名为DGR（Data Generation and Refinement）的数据集构建方法。DGR通过转换和优化现有的分布外安全推理数据集，使其与目标LLM的内部分布对齐。

Result: DGR方法有效地减轻了安全对齐带来的“安全税”（safety tax），同时保持了安全性能。在DirectRefusal和R1-ACT上的平均推理准确率相比Vanilla SFT分别提高了30.2%和21.2%。研究还发现，推理能力下降的程度与分布偏移的程度相关，并且仅需10个样本即可激活有效的拒绝行为，表明安全对齐可能主要是一种激活潜在知识的机制。

Conclusion: 本研究强调了分布一致性在安全对齐中的重要性，并为理解推理模型中安全对齐的激活机制提供了新见解。通过DGR方法，可以在保持安全性的前提下，显著减少安全对齐对模型推理能力的负面影响。

Abstract: Safety alignment incurs safety tax that perturbs a large reasoning model's (LRM) general reasoning ability. Existing datasets used for safety alignment for an LRM are usually constructed by distilling safety reasoning traces and answers from an external LRM or human labeler. However, such reasoning traces and answers exhibit a distributional gap with the target LRM that needs alignment, and we conjecture such distributional gap is the culprit leading to significant degradation of reasoning ability of the target LRM. Driven by this hypothesis, we propose a safety alignment dataset construction method, dubbed DGR. DGR transforms and refines an existing out-of-distributional safety reasoning dataset to be aligned with the target's LLM inner distribution. Experimental results demonstrate that i) DGR effectively mitigates the safety tax while maintaining safety performance across all baselines, i.e., achieving \textbf{+30.2\%} on DirectRefusal and \textbf{+21.2\%} on R1-ACT improvement in average reasoning accuracy compared to Vanilla SFT; ii) the degree of reasoning degradation correlates with the extent of distribution shift, suggesting that bridging this gap is central to preserving capabilities. Furthermore, we find that safety alignment in LRMs may primarily function as a mechanism to activate latent knowledge, as a mere \textbf{10} samples are sufficient for activating effective refusal behaviors. These findings not only emphasize the importance of distributional consistency but also provide insights into the activation mechanism of safety in reasoning models.

</details>


### [138] [Reasoning in a Combinatorial and Constrained World: Benchmarking LLMs on Natural-Language Combinatorial Optimization](https://arxiv.org/abs/2602.02188)
*Xia Jiang,Jing Chen,Cong Zhang,Jie Gao,Chengpeng Hu,Chenhao Zhang,Yaoxin Wu,Yingqian Zhang*

Main category: cs.AI

TL;DR: 本文提出了NLCO基准，用于评估大型语言模型（LLMs）在组合优化（CO）问题上的端到端推理能力，结果表明LLMs在处理CO问题时，随着问题规模的增加，性能会显著下降，并且在图结构问题和瓶颈目标上表现尤为困难。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs在数学和逻辑推理方面的能力，而其在处理组合优化（CO）问题上的潜力尚未得到充分探索。本文旨在弥补这一差距，评估LLMs在CO任务上的表现。

Method: 提出了NLCO基准，包含43个CO问题，并根据变量类型、约束族、全局模式和目标类别进行四层分类，以进行细粒度评估。LLMs需要直接输出离散解，而不能编写代码或调用外部求解器。对LLMs在可行性、解的优化性和推理效率等方面进行了全面评估。

Result: 实验结果显示，最先进的LLMs在处理小型CO实例时，可行性和解的质量表现良好，但随着实例规模的增大，即使使用更多的推理token，其性能也会下降。此外，在NLCO基准的分类体系中，基于集合的任务相对容易，而图结构问题和瓶颈目标更容易导致LLMs的失败。

Conclusion: LLMs在端到端的组合优化推理方面存在显著挑战，其性能对问题规模和问题结构敏感。特别是图结构问题和瓶颈目标是当前LLMs在CO领域需要改进的关键方向。

Abstract: While large language models (LLMs) have shown strong performance in math and logic reasoning, their ability to handle combinatorial optimization (CO) -- searching high-dimensional solution spaces under hard constraints -- remains underexplored. To bridge the gap, we introduce NLCO, a \textbf{N}atural \textbf{L}anguage \textbf{C}ombinatorial \textbf{O}ptimization benchmark that evaluates LLMs on end-to-end CO reasoning: given a language-described decision-making scenario, the model must output a discrete solution without writing code or calling external solvers. NLCO covers 43 CO problems and is organized using a four-layer taxonomy of variable types, constraint families, global patterns, and objective classes, enabling fine-grained evaluation. We provide solver-annotated solutions and comprehensively evaluate LLMs by feasibility, solution optimality, and reasoning efficiency. Experiments across a wide range of modern LLMs show that high-performing models achieve strong feasibility and solution quality on small instances, but both degrade as instance size grows, even if more tokens are used for reasoning. We also observe systematic effects across the taxonomy: set-based tasks are relatively easy, whereas graph-structured problems and bottleneck objectives lead to more frequent failures.

</details>


### [139] [TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents](https://arxiv.org/abs/2602.02196)
*Hang Yan,Xinyu Che,Fangzhi Xu,Qiushi Sun,Zichen Ding,Kanzhi Cheng,Jian Zhang,Tao Qin,Jun Liu,Qika Lin*

Main category: cs.AI

TL;DR: 本文提出了一个名为 TIDE 的框架，用于评估自主 LLM 代理的测试时改进 (TTI) 机制，该框架从任务完成效率、错误行为适应性和工作记忆效用三个维度进行分析，并发现优化代理与环境的交互动态比仅仅扩展内部推理能力更能提升代理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的对自主 LLM 代理通过测试时改进 (TTI) 来提升性能的研究，对其成功或失败的内在机制知之甚少，并且现有的评估指标无法充分捕捉 TTI 的任务优化效率、对错误行为的适应性以及工作记忆在任务完成中的具体作用。

Method: 提出了一种名为 Test-time Improvement Diagnostic Evaluation (TIDE) 的框架，该框架独立于具体代理和环境。TIDE 将 TTI 分解为三个相互关联的维度进行测量：(1) 任务完成的整体时间动态；(2) 性能是否主要受限于递归循环行为；(3) 性能是否受累积记忆的负担影响。

Result: 通过在不同代理和环境上的广泛实验，TIDE 揭示了提升代理性能的关键在于优化代理与环境之间的交互动态，而不仅仅是扩展其内部推理能力。

Conclusion: 提升自主 LLM 代理的性能需要明确地优化代理与环境的交互动态，这比单纯增强代理的内部推理能力更为重要。TIDE 提供了一个全面的评估框架来诊断 TTI 过程中的问题。

Abstract: Recent advances in autonomous LLM agents demonstrate their ability to improve performance through iterative interaction with the environment. We define this paradigm as Test-Time Improvement (TTI). However, the mechanisms under how and why TTI succeed or fail remain poorly understood, and existing evaluation metrics fail to capture their task optimization efficiency, behavior adaptation after erroneous actions, and the specific utility of working memory for task completion. To address these gaps, we propose Test-time Improvement Diagnostic Evaluation (TIDE), an agent-agnostic and environment-agnostic framework that decomposes TTI into three comprehensive and interconnected dimensions. The framework measures (1) the overall temporal dynamics of task completion and (2) identifies whether performance is primarily constrained by recursive looping behaviors or (3) by burdensome accumulated memory. Through extensive experiments across diverse agents and environments, TIDE highlights that improving agent performance requires more than scaling internal reasoning, calling for explicitly optimizing the interaction dynamics between the agent and the environment.

</details>


### [140] [More Than a Quick Glance: Overcoming the Greedy Bias in KV-Cache Compression](https://arxiv.org/abs/2602.02199)
*Aryan Sood,Tanvi Sharma,Vansh Agrawal*

Main category: cs.AI

TL;DR: LASER-KV 框架通过一种累积预算策略和块式累积来优化 KV 缓存压缩，避免了传统方法在内存效率和语义保留之间的权衡，并在长上下文任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 的 KV 缓存内存限制了实际应用中的上下文窗口长度。现有的压缩策略会在内存效率和语义保留之间做出权衡。

Method: 提出 LASER-KV 框架，采用一种块式累积策略，并通过保护因子 (n) 来控制累积过程，以测试 KV 压缩在严格累积预算下的性能限制，并隔离压缩与滑动窗口伪影的影响。

Result: 在 Babilong 基准测试上，LASER-KV 在 128k 上实现了高达 10% 的精度提升，而现有压缩方法性能下降了 15-30%。

Conclusion: LASER-KV 框架能够在不牺牲性能的情况下实现高效的 KV 缓存压缩，并挑战了仅依赖注意力分数作为 token 重要性代理的观点。

Abstract: While Large Language Models (LLMs) can theoretically support extensive context windows, their actual deployment is constrained by the linear growth of Key-Value (KV) cache memory. Prevailing compression strategies mitigate this through various pruning mechanisms, yet trade-off semantic recall for memory efficiency. In this work, we present LASER-KV (Layer Accumulated Selection with Exact-LSH Recall), a framework designed to test the limits of KV compression under a strict accumulative budgeting policy. We deviate from the standard fixed summary size approach by implementing a block-wise accumulation strategy governed by a protection divisor (n). This allows us to isolate the effects of compression from sliding window artifacts. Our experiments on the Babilong benchmark reveal performance degradation in previous compression methods by 15-30% on various long context tasks. LASER-KV maintains stable performance, achieving superior accuracies by a margin of upto 10% at 128k. These findings challenge the prevailing assumption that attention scores alone are a sufficient proxy for token utility.

</details>


### [141] [Position: Explaining Behavioral Shifts in Large Language Models Requires a Comparative Approach](https://arxiv.org/abs/2602.02304)
*Martino Ciaperoni,Marzio Di Vece,Luca Pappalardo,Fosca Giannotti,Francesco Giannini*

Main category: cs.AI

TL;DR: 本文提出了一个名为$Δ$-XAI的比较性可解释人工智能框架，旨在解释大型基础模型中因干预（如扩展、微调等）而产生的行为变化，而非孤立地分析单个模型。


<details>
  <summary>Details</summary>
Motivation: 现有可解释AI方法难以解释基础模型在不同干预措施下的行为变化，因此需要一种能够进行比较性分析的框架来理解这些变化。

Method: 提出$Δ$-XAI框架，包含一系列设计解释方法时应考虑的原则，并展示了几种可能的实现流程和一项具体的实验。

Result: 通过$Δ$-XAI框架，可以更有效地追踪和解释模型在干预前后的行为差异，而不是仅仅关注模型在某个特定时间点的表现。

Conclusion: 行为移位应进行比较性解释；$Δ$-XAI框架为理解和解释基础模型中的干预诱导行为移位提供了一个新的视角和方法论。

Abstract: Large-scale foundation models exhibit behavioral shifts: intervention-induced behavioral changes that appear after scaling, fine-tuning, reinforcement learning or in-context learning. While investigating these phenomena have recently received attention, explaining their appearance is still overlooked. Classic explainable AI (XAI) methods can surface failures at a single checkpoint of a model, but they are structurally ill-suited to justify what changed internally across different checkpoints and which explanatory claims are warranted about that change. We take the position that behavioral shifts should be explained comparatively: the core target should be the intervention-induced shift between a reference model and an intervened model, rather than any single model in isolation. To this aim we formulate a Comparative XAI ($Δ$-XAI) framework with a set of desiderata to be taken into account when designing proper explaining methods. To highlight how $Δ$-XAI methods work, we introduce a set of possible pipelines, relate them to the desiderata, and provide a concrete $Δ$-XAI experiment.

</details>


### [142] [Interpreting and Controlling LLM Reasoning through Integrated Policy Gradient](https://arxiv.org/abs/2602.02313)
*Changming Li,Kaixing Zhang,Haoyun Xu,Yingdong Shi,Zheng Zhang,Kaitao Song,Kan Ren*

Main category: cs.AI

TL;DR: 本文提出了一种名为集成策略梯度（IPG）的新框架，用于解释大型语言模型（LLMs）的推理能力，通过反向传播基于结果的信号来精确定位模型内部组件对推理过程的贡献，并实现了对推理行为的可靠调控。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）推理机制不透明，现有的可解释性方法难以精确地定位复杂的推理机制或捕捉模型内部工作对其推理输出的顺序影响。

Method: 基于面向结果和关注序列影响的原则，提出集成策略梯度（IPG）框架，通过反向传播推理准确率等复合结果信号来将推理行为归因于模型内部组件，考虑了长程累积效应。

Result: 实验表明，IPG框架能够更精确地定位模型内部组件对推理过程的贡献，并能可靠地调控不同推理模型的推理能力和推理强度。

Conclusion: IPG框架是一种有效的方法，可以更好地理解和控制LLMs的复杂推理行为，通过追踪和利用模型内部的序列化信息来弥补现有方法的不足。

Abstract: Large language models (LLMs) demonstrate strong reasoning abilities in solving complex real-world problems. Yet, the internal mechanisms driving these complex reasoning behaviors remain opaque. Existing interpretability approaches targeting reasoning either identify components (e.g., neurons) correlated with special textual patterns, or rely on human-annotated contrastive pairs to derive control vectors. Consequently, current methods struggle to precisely localize complex reasoning mechanisms or capture sequential influence from model internal workings to the reasoning outputs. In this paper, built on outcome-oriented and sequential-influence-aware principles, we focus on identifying components that have sequential contribution to reasoning behavior where outcomes are cumulated by long-range effects. We propose Integrated Policy Gradient (IPG), a novel framework that attributes reasoning behaviors to model's inner components by propagating compound outcome-based signals such as post reasoning accuracy backward through model inference trajectories. Empirical evaluations demonstrate that our approach achieves more precise localization and enables reliable modulation of reasoning behaviors (e.g., reasoning capability, reasoning strength) across diverse reasoning models.

</details>


### [143] [Context Learning for Multi-Agent Discussion](https://arxiv.org/abs/2602.02350)
*Xingyuan Hua,Sheng Yue,Xinyi Li,Yizhe Zhao,Jinrui Zhang,Ju Ren*

Main category: cs.AI

TL;DR: 提出了一种名为M2CL的多LLM上下文学习方法，通过动态生成上下文指令来解决多智能体讨论中的不一致性问题，并在多项任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体讨论（MAD）方法容易出现讨论不一致的问题，导致LLM无法达成连贯的解决方案，这是由于个体上下文之间的不一致造成的。

Method: 提出了一种名为M2CL的多LLM上下文学习方法，为每个智能体学习一个上下文生成器，该生成器能够通过自动化的信息组织和精炼，在每个讨论轮次动态生成上下文指令。M2CL通过一个精心设计的自适应机制来训练生成器，以控制上下文的一致性和输出差异。

Result: 在学术推理、具身任务和移动控制等具有挑战性的任务上进行了评估，M2CL的性能比现有方法显著提高了20%-50%，并且具有良好的迁移能力和计算效率。

Conclusion: M2CL是一种有效的多LLM上下文学习方法，能够提高多智能体讨论的一致性，避免过早收敛到多数噪声，并逐步达成正确的共识，在多项任务上表现出优越的性能。

Abstract: Multi-Agent Discussion (MAD) has garnered increasing attention very recently, where multiple LLM instances collaboratively solve problems via structured discussion. However, we find that current MAD methods easily suffer from discussion inconsistency, LLMs fail to reach a coherent solution, due to the misalignment between their individual contexts.In this paper, we introduce a multi-LLM context learning method (M2CL) that learns a context generator for each agent, capable of dynamically generating context instructions per discussion round via automatic information organization and refinement. Specifically, inspired by our theoretical insights on the context instruction, M2CL train the generators to control context coherence and output discrepancies via a carefully crafted self-adaptive mechanism.It enables LLMs to avoid premature convergence on majority noise and progressively reach the correct consensus. We evaluate M2CL on challenging tasks, including academic reasoning, embodied tasks, and mobile control. The results show that the performance of M2CL significantly surpasses existing methods by 20%--50%, while enjoying favorable transferability and computational efficiency.

</details>


### [144] [Live-Evo: Online Evolution of Agentic Memory from Continuous Feedback](https://arxiv.org/abs/2602.02369)
*Yaolun Zhang,Yiran Wu,Yijiong Yu,Qingyun Wu,Huazheng Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为 Live-Evo 的在线自适应记忆系统，用于提升大型语言模型（LLM）代理的任务解决能力。该系统通过解耦经验记录和使用方法，并引入经验权重更新机制，使其能够持续学习并适应数据分布变化。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 自我进化记忆系统大多基于静态数据集，无法有效应对真实世界的分布漂移和连续反馈，鲁棒性不足。

Method: Live-Evo 将经验存储在经验库（Experience Bank）和元指南库（Meta-Guideline Bank）中，为每个任务生成自适应指南。它通过维护和更新经验权重来管理在线记忆，强化有用的经验，并降低误导性或过时经验的权重，模拟人类记忆的强化和衰减过程。

Result: 在为期 10 周的 Prophet Arena 基准测试中，Live-Evo 将 Brier 分数提高了 20.8%，市场回报增加了 12.9%。该系统还能迁移到深度研究基准测试，并持续优于现有方法。

Conclusion: Live-Evo 是一种有效的在线自适应记忆系统，能够显著提升 LLM 代理在动态环境中的表现，并展现出良好的泛化能力。

Abstract: Large language model (LLM) agents are increasingly equipped with memory, which are stored experience and reusable guidance that can improve task-solving performance. Recent \emph{self-evolving} systems update memory based on interaction outcomes, but most existing evolution pipelines are developed for static train/test splits and only approximate online learning by folding static benchmarks, making them brittle under true distribution shift and continuous feedback. We introduce \textsc{Live-Evo}, an online self-evolving memory system that learns from a stream of incoming data over time. \textsc{Live-Evo} decouples \emph{what happened} from \emph{how to use it} via an Experience Bank and a Meta-Guideline Bank, compiling task-adaptive guidelines from retrieved experiences for each task. To manage memory online, \textsc{Live-Evo} maintains experience weights and updates them from feedback: experiences that consistently help are reinforced and retrieved more often, while misleading or stale experiences are down-weighted and gradually forgotten, analogous to reinforcement and decay in human memory. On the live \textit{Prophet Arena} benchmark over a 10-week horizon, \textsc{Live-Evo} improves Brier score by 20.8\% and increases market returns by 12.9\%, while also transferring to deep-research benchmarks with consistent gains over strong baselines. Our code is available at https://github.com/ag2ai/Live-Evo.

</details>


### [145] [Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing](https://arxiv.org/abs/2602.02386)
*Mika Okamoto,Ansel Kaplan Erol,Glenn Matlin*

Main category: cs.AI

TL;DR: BELLA是一个旨在帮助用户在预算范围内选择最适合特定任务的LLM的框架，通过技能剖析和多目标优化来实现，并提供可解释的推荐理由。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准测试的聚合指标无法明确任务所需的具体能力，也无法确定是否可以使用更便宜的模型来完成任务，这导致用户在选择模型时浪费金钱。因此，需要一种更精细、更经济高效的模型选择方法。

Method: BELLA框架包含三个主要阶段：1. 利用批判者（critic-based）进行剖析，分解LLM输出并提取任务所需的具体技能；2. 将提取的技能聚类成结构化的能力矩阵；3. 通过多目标优化，在满足预算限制的前提下最大化性能，从而选择最佳模型。该框架还提供自然语言解释，增强了推荐过程的透明度。

Result: BELLA框架能够根据任务需求和预算约束，提供最优的LLM选择建议，并且其推荐理由具有可解释性。通过将该框架应用于金融推理等领域，可以展示其在处理多样化技能需求和模型成本差异方面的有效性。

Conclusion: BELLA框架能够使从业人员在部署LLM时，能够做出符合成本效益原则的权衡，从而实现更明智的模型选择，避免不必要的开支。

Abstract: How should Large Language Model (LLM) practitioners select the right model for a task without wasting money? We introduce BELLA (Budget-Efficient LLM Selection via Automated skill-profiling), a framework that recommends optimal LLM selection for tasks through interpretable skill-based model selection. Standard benchmarks report aggregate metrics that obscure which specific capabilities a task requires and whether a cheaper model could suffice. BELLA addresses this gap through three stages: (1) decomposing LLM outputs and extract the granular skills required by using critic-based profiling, (2) clustering skills into structured capability matrices, and (3) multi-objective optimization to select the right models to maximize performance while respecting budget constraints. BELLA provides natural-language rationale for recommendations, providing transparency that current black-box routing systems lack. We describe the framework architecture, situate it within the landscape of LLM routing and evaluation, and discuss its application to financial reasoning as a representative domain exhibiting diverse skill requirements and cost-variation across models. Our framework enables practitioners to make principled and cost-performance trade-offs for deploying LLMs.

</details>


### [146] [Structure Enables Effective Self-Localization of Errors in LLMs](https://arxiv.org/abs/2602.02416)
*Ankur Samanta,Akshayaa Magesh,Ayush Jain,Kavosh Asadi,Youliang Yu,Daniel Jiang,Boris Vidolov,Kaveh Hassani,Paul Sajda,Jalaj Bhandari,Yonathan Efroni*

Main category: cs.AI

TL;DR: 提出了一种名为Thought-ICS的自纠错框架，通过将语言模型的推理过程分解为离散的思维步骤，显著提高了模型定位和纠正自身错误的能力。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在自我纠错方面表现不佳，而人类大脑在决策点监控错误并重新采样替代方案的机制为提高AI的自我纠错能力提供了灵感。

Method: 设计了一种结构化提示方法，将推理过程分解为离散、语义连贯的思维步骤。在此基础上，提出了Iterative Correction Sampling of Thoughts (Thought-ICS)框架，该框架迭代地生成思维步骤，并在验证后定位错误步骤，然后从最后正确的点回溯生成替代推理。

Result: Thought-ICS在有外部验证的情况下，自纠错能力提升了20-40%。在完全自主设置下，其性能优于现有的自纠错基线。

Conclusion: 将推理过程结构化为离散思维步骤是实现语言模型有效自我纠错的关键。Thought-ICS框架能够可靠地定位错误并进行纠正，为构建能够自我纠错的AI系统提供了新的途径。

Abstract: Self-correction in language models remains elusive. In this work, we explore whether language models can explicitly localize errors in incorrect reasoning, as a path toward building AI systems that can effectively correct themselves. We introduce a prompting method that structures reasoning as discrete, semantically coherent thought steps, and show that models are able to reliably localize errors within this structure, while failing to do so in conventional, unstructured chain-of-thought reasoning. Motivated by how the human brain monitors errors at discrete decision points and resamples alternatives, we introduce Iterative Correction Sampling of Thoughts (Thought-ICS), a self-correction framework. Thought-ICS iteratively prompts the model to generate reasoning one discrete and complete thought at a time--where each thought represents a deliberate decision by the model--creating natural boundaries for precise error localization. Upon verification, the model localizes the first erroneous step, and the system backtracks to generate alternative reasoning from the last correct point. When asked to correct reasoning verified as incorrect by an oracle, Thought-ICS achieves 20-40% self-correction lift. In a completely autonomous setting without external verification, it outperforms contemporary self-correction baselines.

</details>


### [147] [SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration](https://arxiv.org/abs/2602.02419)
*Qingni Wang,Yue Fan,Xin Eric Wang*

Main category: cs.AI

TL;DR: SafeGround 是一个不确定性感知框架，用于 GUI 文本到坐标的定位任务，通过校准在测试时控制风险，提高了系统整体准确性。


<details>
  <summary>Details</summary>
Motivation: 现有 GUI 定位模型在定位不准确时可能导致严重且难以撤销的错误操作，用户对其可靠性感到担忧。

Method: SafeGround 利用分布感知的不确定性量化方法来捕捉模型输出的随机样本的空间分散性，然后通过校准过程在测试时推导出一个具有统计学保证的虚报率（FDR）控制的决策阈值。

Result: SafeGround 提出的不确定性度量在区分正确和不正确的预测方面优于现有基线。校准后的阈值能可靠地实现严格的风险控制，并在多个 GUI 定位模型上，使系统整体准确性相较于仅使用 Gemini 的推理方法提高了高达 5.38 个百分点。

Conclusion: SafeGround 提供了一种有效的方法来提高 GUI 定位模型的可靠性，通过量化不确定性和实施风险控制，从而提升了系统在实际应用中的准确性。

Abstract: Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38\% percentage points over Gemini-only inference.

</details>


### [148] [Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling](https://arxiv.org/abs/2602.02453)
*Andong Chen,Wenxin Zhu,Qiuyu Ding,Yuchen Song,Muyun Yang,Tiejun Zhao*

Main category: cs.AI

TL;DR: 该研究提出了一种名为“漫画思维”的视觉推理新范式，利用漫画作为信息密度高且成本低的介质，介于静态图像和视频之间，以提升大语言模型的多模态推理能力，特别是在处理时序和因果关系方面。研究发现，漫画思维在多步时序和因果推理任务上优于图像思维，且效率远高于视频思维。此外，漫画的叙事结构和风格对模型性能有显著影响。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在处理多模态信息时，静态图像难以有效表示时间结构，而视频则计算成本高且冗余信息多。作者希望找到一种信息密度高、能有效表示时间结构且计算成本低的视觉表示方式，以增强模型的推理能力。

Method: 提出“漫画思维”的视觉推理范式，利用漫画作为介于图像和视频之间的信息载体。系统研究了两种基于漫画的推理路径，并在多种推理任务和长上下文理解任务上进行了评估。分析了不同漫画叙事结构和风格对模型性能的影响。

Result: 漫画思维在多步时序和因果推理任务上优于图像思维，并且显著优于视频思维的效率。研究还发现，漫画的叙事结构和风格对模型性能有持续性的影响。

Conclusion: 漫画是一种有效的中介视觉表示，可以提升多模态推理能力，尤其是在时序和因果推理方面，同时保持了比视频更高的效率。漫画的叙事结构和风格是影响其在模型中表现的关键因素。

Abstract: Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.

</details>


### [149] [Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction](https://arxiv.org/abs/2602.02455)
*Han Bao,Zheyuan Zhang,Pengcheng Jing,Zhengqing Yuan,Kaiwen Shi,Yanfang Ye*

Main category: cs.AI

TL;DR: 本文提出了Drift-Bench，一个用于评估大型语言模型作为自主代理时，在用户输入存在缺陷（如意图不明、参数缺失、错误预设、表述模糊）的情况下，通过多轮澄清来化解执行风险的基准测试。现有评估方法无法捕捉此类问题，而Drift-Bench能够进行系统性诊断。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型正向自主代理发展，但用户输入常存在缺陷，导致执行风险，而现有文本评估方法无法捕捉这些风险。因此需要一个能够评估代理在多轮澄清中处理输入缺陷的能力的基准。

Method: 构建了Drift-Bench基准，包含一个统一的合作障碍分类法，并采用了一个基于经典沟通理论、驱动用户模拟器和Rise评估协议的系统。该基准在面向状态和面向服务的执行环境中进行评估。

Result: 实验表明，在输入存在缺陷时，模型的性能会显著下降。用户个性（persona）和缺陷类型都会影响澄清的有效性。

Conclusion: Drift-Bench是第一个在输入缺陷下评估代理语用学的基准，能够有效诊断可能导致不安全执行的失败，并连接了澄清研究和代理安全评估。

Abstract: As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarification, and thus do not measure multi-turn disambiguation under grounded execution risk. We introduce \textbf{Drift-Bench}, the first diagnostic benchmark that evaluates agentic pragmatics under input faults through multi-turn clarification across state-oriented and service-oriented execution environments. Grounded in classical theories of communication, \textbf{Drift-Bench} provides a unified taxonomy of cooperative breakdowns and employs a persona-driven user simulator with the \textbf{Rise} evaluation protocol. Experiments show substantial performance drops under these faults, with clarification effectiveness varying across user personas and fault types. \MethodName bridges clarification research and agent safety evaluation, enabling systematic diagnosis of failures that can lead to unsafe executions.

</details>


### [150] [MentisOculi: Revealing the Limits of Reasoning with Mental Imagery](https://arxiv.org/abs/2602.02465)
*Jana Zeller,Thaddäus Wiedemer,Fanfei Li,Thomas Klein,Prasanna Mayilvahanan,Matthias Bethge,Felix Wichmann,Ryan Cotterell,Wieland Brendel*

Main category: cs.AI

TL;DR: 当前的多模态大语言模型（MLLMs）正向能够原生交错生成的统一多模态模型（UMMs）发展，研究者们尝试使用中间可视化作为类比人类心智意象的推理辅助。然而，作者开发了一个名为MentisOculi的评估套件，用于测试模型在生成、维持和操作视觉表征以进行多步推理的能力，结果发现目前模型（包括UMMs）即使使用生成图像或真实图像，其推理能力也未能得到提升，且UMMs存在生成错误累积的问题。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型向统一多模态模型发展，研究者们对使用中间可视化作为类似人类心智意象的推理辅助工具产生了兴趣，希望通过此举提升模型的推理能力。

Method: 作者开发了一个名为MentisOculi的程序化、分层化的多步推理问题集，该问题集可以通过视觉方式解决，旨在挑战前沿模型。研究评估了从潜在token到显式生成图像等不同的视觉策略。此外，还专门分析了统一多模态模型（UMMs）在利用文本推理能力和生成/利用可视化方面的表现。

Result: 研究发现，无论是使用潜在token还是生成的图像，视觉策略通常都不能提高模型的性能。特别是UMMs，虽然具备文本推理能力，且有时能生成正确的视觉内容，但存在生成错误累积的问题，并且无法有效利用（甚至）真实标注的视觉信息来辅助推理。

Conclusion: 尽管视觉思维的概念很有吸引力，但目前的研究表明，它并未真正提升模型的推理能力。MentisOculi为未来分析和弥合这一差距提供了基础，以期能够让不同模型家族受益于视觉思维。

Abstract: Frontier models are transitioning from multimodal large language models (MLLMs) that merely ingest visual information to unified multimodal models (UMMs) capable of native interleaved generation. This shift has sparked interest in using intermediate visualizations as a reasoning aid, akin to human mental imagery. Central to this idea is the ability to form, maintain, and manipulate visual representations in a goal-oriented manner. To evaluate and probe this capability, we develop MentisOculi, a procedural, stratified suite of multi-step reasoning problems amenable to visual solution, tuned to challenge frontier models. Evaluating visual strategies ranging from latent tokens to explicit generated imagery, we find they generally fail to improve performance. Analysis of UMMs specifically exposes a critical limitation: While they possess the textual reasoning capacity to solve a task and can sometimes generate correct visuals, they suffer from compounding generation errors and fail to leverage even ground-truth visualizations. Our findings suggest that despite their inherent appeal, visual thoughts do not yet benefit model reasoning. MentisOculi establishes the necessary foundation to analyze and close this gap across diverse model families.

</details>


### [151] [Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts](https://arxiv.org/abs/2602.02468)
*Aiden Yiliu Li,Xinyue Hao,Shilong Liu,Mengdi Wang*

Main category: cs.AI

TL;DR: Avenir-Web 是一个先进的网页代理，通过结合多种专业知识、经验模仿规划以及任务跟踪和自适应记忆，显著提高了在复杂动态网页上执行长期任务的能力，并在 Online-Mind2Web 基准测试中达到了新的开源 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动网页代理在处理复杂动态网页的长期任务时，常因元素识别不准、缺乏网站特定知识以及长期任务跟踪和记忆不稳定而表现不佳。

Method: Avenir-Web 采用“混合接地专家”（Mixture of Grounding Experts）、“经验-模仿规划”（Experience-Imitation Planning）来整合先验知识，并结合任务跟踪清单和自适应记忆，以实现跨不同用户界面范式的稳健交互。

Result: Avenir-Web 在 Online-Mind2Web 基准测试中，显著优于之前的开源代理，并达到了顶级闭源模型的性能水平，确立了新的开源网页代理 SOTA。

Conclusion: Avenir-Web 成功解决了现有网页代理在复杂动态网页上的长期任务执行的局限性，通过创新的技术组合实现了高可靠性和跨平台兼容性，为在线网页代理的研究和应用树立了新的标杆。

Abstract: Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model structures. To address these limitations, we introduce Avenir-Web, a web agent that achieves a new open-source state of the art on the Online-Mind2Web benchmark in real-world deployment. Avenir-Web leverages a Mixture of Grounding Experts, Experience-Imitation Planning for incorporating procedural priors, and a task-tracking checklist combined with adaptive memory to enable robust and seamless interaction across diverse user interface paradigms. We evaluate Avenir-Web on Online-Mind2Web, a rigorous benchmark of live and user-centered web tasks. Our results demonstrate that Avenir-Web significantly surpasses prior open-source agents and attains performance parity with top-tier proprietary models, thereby establishing a new open-source state of the art for reliable web agents on live websites.

</details>


### [152] [Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge](https://arxiv.org/abs/2602.02470)
*Xutao Ma,Yixiao Huang,Hanlin Zhu,Somayeh Sojoudi*

Main category: cs.AI

TL;DR: 本研究提出了一种名为“恒等桥”的简单数据增强方法，能够显著改善自回归大语言模型（LLMs）在处理逆向推理任务（例如“反转诅咒”）时的表现，使模型能够从“A 蕴含 B”的知识中推断出“B 蕴含 A”。


<details>
  <summary>Details</summary>
Motivation: 以往研究认为 LLMs 在进行简单的逻辑推理（如反转推理）时存在根本性缺陷，只能记忆事实而非学习更高层级的规则。本研究旨在挑战这一观点，并寻找一种方法来克服“反转诅咒”。

Method: 研究者提出了一种名为“恒等桥”（Identity Bridge）的数据增强策略，通过在训练数据中加入形如“A → A”的样本（例如“Alice 的名字是 Alice”）。理论上，研究者通过分析梯度下降的隐式偏差，证明即使是单层 Transformer 也能打破反转诅咒。实验上，将此策略应用于一个 1B 参数的预训练语言模型进行微调。

Result: 使用“恒等桥”数据增强方法进行微调后，模型在反转推理任务上的成功率达到了 40%，而仅使用正向知识数据训练的模型成功率接近于零。

Conclusion: “恒等桥”是一种简单且低成本的数据增强方法，可以有效缓解 LLMs 面临的“反转诅咒”问题，并为 LLMs 学习更高层级的规则提供了新的理论基础和实践途径。

Abstract: Autoregressive large language models (LLMs) have achieved remarkable success in many complex tasks, yet they can still fail in very simple logical reasoning such as the "reversal curse" -- when trained on forward knowledge data of the form "$A \rightarrow B$" (e.g., Alice's husband is Bob), the model is unable to deduce the reversal knowledge "$B \leftarrow A$" (e.g., Bob's wife is Alice) during test. Extensive prior research suggests that this failure is an inherent, fundamental limit of autoregressive causal LLMs, indicating that these models tend to memorize factual-level knowledge rather than capture higher-level rules. In this paper, we challenge this view by showing that this seemingly fundamental limit can be mitigated by slightly tweaking the training data with a simple regularization data recipe called the Identity Bridge of the form "$A \to A$" (e.g., The name of Alice is Alice). Theoretically, we prove that under this recipe, even a one-layer transformer can break the reversal curse by analyzing the implicit bias of gradient descent. Empirically, we show that a 1B pretrained language model finetuned with the proposed data recipe achieves a 40% success rate on reversal tasks, in stark contrast to a near-zero success rate when trained solely on forward-knowledge data. Our work provides a novel theoretical foundation for the reversal curse and offers a principled, low-cost path to encouraging LLMs to learn higher-level rules from data.

</details>


### [153] [AgentRx: Diagnosing AI Agent Failures from Execution Trajectories](https://arxiv.org/abs/2602.02475)
*Shraddha Barke,Arnav Goyal,Alind Khare,Avaljot Singh,Suman Nath,Chetan Bansal*

Main category: cs.AI

TL;DR: 该研究提出了 AGENTRX，一个自动诊断框架，用于定位 AI 代理执行失败的关键步骤和类别，并发布了一个包含 115 个失败轨迹的基准数据集。


<details>
  <summary>Details</summary>
Motivation: AI 代理在复杂任务中的失败难以定位，因为执行过程具有概率性、长周期、多智能体以及受嘈杂工具输出影响。因此，研究的动机是开发一种方法来有效且自动地诊断这些失败。

Method: 研究人员手动标注了失败的代理运行轨迹，并发布了一个包含 115 个失败轨迹的新基准。他们还提出了 AGENTRX 框架，该框架通过综合约束、逐步评估并生成包含证据的验证日志，然后利用基于 LLM 的裁判来定位关键失败步骤和类别。

Result: AGENTRX 框架在三个不同领域（结构化 API 工作流、事件管理和开放式 Web/文件任务）的失败轨迹中，在关键步骤定位和失败归因方面优于现有基线。

Conclusion: AGENTRX 是一个有效的、领域无关的诊断框架，能够减轻人类在故障归因方面的成本，并能准确地定位 AI 代理执行失败的关键步骤和类别。

Abstract: AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with a critical failure step and a category from a grounded-theory derived, cross-domain failure taxonomy. To mitigate the human cost of failure attribution, we present AGENTRX, an automated domain-agnostic diagnostic framework that pinpoints the critical failure step in a failed agent trajectory. It synthesizes constraints, evaluates them step-by-step, and produces an auditable validation log of constraint violations with associated evidence; an LLM-based judge uses this log to localize the critical step and category. Our framework improves step localization and failure attribution over existing baselines across three domains.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [154] [EDU-CIRCUIT-HW: Evaluating Multimodal Large Language Models on Real-World University-Level STEM Student Handwritten Solutions](https://arxiv.org/abs/2602.00095)
*Weiyu Sun,Liangliang Chen,Yongnuo Cai,Huiru Xie,Yi Zeng,Ying Zhang*

Main category: cs.CV

TL;DR: 本研究发布了一个名为EDU-CIRCUIT-HW的大规模数据集，包含1300多份真实的STEM学生手写解题过程，并评估了多模态大语言模型（MLLMs）在该数据集上的识别准确性和自动评分能力。研究发现，MLLMs在理解手写数学解题逻辑方面存在显著的潜在错误，可靠性不足以用于高风险教育场景。作者还提出了一种通过识别错误模式来提高AI辅助评分系统鲁棒性的方法。


<details>
  <summary>Details</summary>
Motivation: 现有针对STEM学生手写解题的多模态大语言模型（MLLMs）缺乏真实且领域特定的基准数据集，并且当前的评估方法主要依赖下游任务结果，无法全面衡量模型对复杂手写逻辑的理解能力。

Method: 发布了EDU-CIRCUIT-HW数据集，包含1300多份真实的STEM学生手写解题过程，并附有专家验证的逐字转录和评分报告。利用该数据集，同时评估了MLLMs的上游识别保真度和下游自动评分性能。此外，还进行了一个案例研究，通过识别错误模式来优化AI辅助评分系统。

Result: 评估结果显示，MLLMs在识别学生手写内容时存在大量潜在错误，其可靠性不足以用于自动评分等需要深度理解的应用。通过识别错误模式并进行少量人工干预（约4%的解题过程），可以显著提高AI辅助评分系统在处理新解题过程时的鲁棒性。

Conclusion: 当前MLLMs在理解和评估学生手写STEM解题过程方面存在显著的局限性和不可靠性，无法直接应用于高风险教育场景。通过识别和纠正识别错误，可以有效提升AI辅助评分系统的性能和鲁棒性。

Abstract: Multimodal Large Language Models (MLLMs) hold significant promise for revolutionizing traditional education and reducing teachers' workload. However, accurately interpreting unconstrained STEM student handwritten solutions with intertwined mathematical formulas, diagrams, and textual reasoning poses a significant challenge due to the lack of authentic and domain-specific benchmarks. Additionally, current evaluation paradigms predominantly rely on the outcomes of downstream tasks (e.g., auto-grading), which often probe only a subset of the recognized content, thereby failing to capture the MLLMs' understanding of complex handwritten logic as a whole. To bridge this gap, we release EDU-CIRCUIT-HW, a dataset consisting of 1,300+ authentic student handwritten solutions from a university-level STEM course. Utilizing the expert-verified verbatim transcriptions and grading reports of student solutions, we simultaneously evaluate various MLLMs' upstream recognition fidelity and downstream auto-grading performance. Our evaluation uncovers an astonishing scale of latent failures within MLLM-recognized student handwritten content, highlighting the models' insufficient reliability for auto-grading and other understanding-oriented applications in high-stakes educational settings. In solution, we present a case study demonstrating that leveraging identified error patterns to preemptively detect and rectify recognition errors, with only minimal human intervention (approximately 4% of the total solutions), can significantly enhance the robustness of the deployed AI-enabled grading system on unseen student solutions.

</details>


### [155] [Mirage2Matter: A Physically Grounded Gaussian World Model from Video](https://arxiv.org/abs/2602.00096)
*Zhengqing Gao,Ziwen Li,Xin Wang,Jiaxin Huang,Zhenyang Ren,Mingkai Shao,Hanlue Zhang,Tianyu Huang,Yongkang Cheng,Yandong Guo,Runqi Lin,Yuanyuan Wang,Tongliang Liu,Kun Zhang,Mingming Gong*

Main category: cs.CV

TL;DR: 本研究提出了一种名为“Simulate Anything”的框架，利用多视角视频和现成资产，通过3D高斯溅射和生成模型重建真实世界环境，并将其集成到物理模拟器中，从而高效生成高质量的具身训练数据，用于训练具身智能模型，并在下游任务上取得了优于真实数据训练的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有具身智能的规模化受限于真实世界交互数据的稀缺性。虽然模拟器可以作为替代，但现有的模拟器在视觉和物理上与真实环境存在较大差距，并且需要昂贵的传感器、精确的机器人校准或深度测量，限制了其大规模应用。

Method: 该方法首先利用3D高斯溅射（3DGS）从多视角视频重建出逼真的场景表示，捕捉精细的几何和外观。然后，利用生成模型恢复物理真实性，并通过精密的校准目标将其集成到模拟器中，实现场景与真实世界的精确尺度对齐，从而创建一个统一、可编辑且物理上可靠的世界模型。

Result: 在“Simulate Anything”框架生成的模拟数据上训练的视觉语言动作（VLA）模型，在下游任务上取得了强大的零样本性能，达到了甚至超越了使用真实世界数据训练的模型。

Conclusion: 重建驱动的世界建模为具身智能的可扩展和实际训练提供了潜力，能够高效生成高质量的训练数据，从而克服数据稀缺的限制。

Abstract: The scalability of embodied intelligence is fundamentally constrained by the scarcity of real-world interaction data. While simulation platforms provide a promising alternative, existing approaches often suffer from a substantial visual and physical gap to real environments and rely on expensive sensors, precise robot calibration, or depth measurements, limiting their practicality at scale. We present Simulate Anything, a graphics-driven world modeling and simulation framework that enables efficient generation of high-fidelity embodied training data using only multi-view environment videos and off-the-shelf assets. Our approach reconstructs real-world environments into a photorealistic scene representation using 3D Gaussian Splatting (3DGS), seamlessly capturing fine-grained geometry and appearance from video. We then leverage generative models to recover a physically realistic representation and integrate it into a simulation environment via a precision calibration target, enabling accurate scale alignment between the reconstructed scene and the real world. Together, these components provide a unified, editable, and physically grounded world model. Vision Language Action (VLA) models trained on our simulated data achieve strong zero-shot performance on downstream tasks, matching or even surpassing results obtained with real-world data, highlighting the potential of reconstruction-driven world modeling for scalable and practical embodied intelligence training.

</details>


### [156] [R3G: A Reasoning--Retrieval--Reranking Framework for Vision-Centric Answer Generation](https://arxiv.org/abs/2602.00104)
*Zhuohong Chen,Zhengxian Wu,Zirui Liao,Shenao Jiang,Hangrui Xu,Yang Chen,Chaokui Su,Xiaoyu Liu,Haoqian Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为R3G的模块化推理-检索-重排序框架，用于视觉问答（VQA）中的视觉信息检索。该框架通过推理计划指导检索，并采用两阶段（粗粒度检索+细粒度重排序）策略来选择相关图像，并在MRAG-Bench基准上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉问答（VQA）模型在需要补充视觉信息时，如何有效地检索相关图像并将其整合到推理过程中仍然是一个挑战。

Method: 本文提出的R3G框架包含三个主要模块：1. 推理模块：生成一个简要的推理计划，明确所需的视觉线索。2. 检索模块：采用两阶段策略，首先进行粗粒度检索，然后进行细粒度重排序，以选择证据图像。3. 重排序模块：利用“充足性感知”（sufficiency-aware）重排序方法。

Result: 在MRAG-Bench基准测试中，R3G在六种不同的多模态大型语言模型（MLLM）骨干网络和九个子场景中均提高了准确率，并达到了总体最先进的性能。消融实验表明，充足性感知重排序和推理步骤是互补的，能够帮助模型更好地选择和利用图像。

Conclusion: R3G框架通过明确的推理计划指导图像检索，并结合两阶段的检索-重排序策略，有效地解决了VQA中视觉信息检索和整合的挑战，显著提升了模型的性能。

Abstract: Vision-centric retrieval for VQA requires retrieving images to supply missing visual cues and integrating them into the reasoning process. However, selecting the right images and integrating them effectively into the model's reasoning remains challenging.To address this challenge, we propose R3G, a modular Reasoning-Retrieval-Reranking framework.It first produces a brief reasoning plan that specifies the required visual cues, then adopts a two-stage strategy, with coarse retrieval followed by fine-grained reranking, to select evidence images.On MRAG-Bench, R3G improves accuracy across six MLLM backbones and nine sub-scenarios, achieving state-of-the-art overall performance. Ablations show that sufficiency-aware reranking and reasoning steps are complementary, helping the model both choose the right images and use them well. We release code and data at https://github.com/czh24/R3G.

</details>


### [157] [HYPE-EDIT-1: Benchmark for Measuring Reliability in Frontier Image Editing Models](https://arxiv.org/abs/2602.00105)
*Wing Chan,Richard Allen*

Main category: cs.CV

TL;DR: 研究提出了HYPE-EDIT-1基准，用于评估基于参考的营销/设计图像编辑任务，并考虑了重试和人工审查成本，发现低单张图像定价的模型在考虑总有效成本时可能更昂贵。


<details>
  <summary>Details</summary>
Motivation: 现有的图像编辑模型公开演示多为最佳情况样本，而实际工作流程中需要考虑重试和审查时间成本。因此，研究旨在建立一个更贴近实际情况的评估基准。

Method: 创建了一个包含100个任务的HYPE-EDIT-1基准，用于参考式营销/设计编辑，并进行二元通过/失败评判。为每个任务生成10个独立输出，以估计每次尝试的通过率、pass@10、重试上限下的预期尝试次数以及结合模型价格和人工审查时间的有效成功编辑成本。释放了50个公开任务，保留50个私有任务用于服务器端评估，并提供标准化的JSON schema和工具。

Result: 在评估的模型中，每次尝试的通过率在34%-83%之间，有效成功编辑成本在0.66美元-1.42美元之间。低单张图像定价的模型在考虑重试和人工审查的总有效成本时，反而更昂贵。

Conclusion: HYPE-EDIT-1基准提供了一种更真实的评估图像编辑模型（特别是对于营销/设计场景）的方法，强调了在实际应用中，模型的总成本不仅仅取决于单张图像的处理价格，还需考虑重试和人工审查的开销。

Abstract: Public demos of image editing models are typically best-case samples; real workflows pay for retries and review time. We introduce HYPE-EDIT-1, a 100-task benchmark of reference-based marketing/design edits with binary pass/fail judging. For each task we generate 10 independent outputs to estimate per-attempt pass rate, pass@10, expected attempts under a retry cap, and an effective cost per successful edit that combines model price with human review time. We release 50 public tasks and maintain a 50-task held-out private split for server-side evaluation, plus a standardized JSON schema and tooling for VLM and human-based judging. Across the evaluated models, per-attempt pass rates span 34-83 percent and effective cost per success spans USD 0.66-1.42. Models that have low per-image pricing are more expensive when you consider the total effective cost of retries and human reviews.

</details>


### [158] [SITUATE -- Synthetic Object Counting Dataset for VLM training](https://arxiv.org/abs/2602.00108)
*René Peinl,Vincent Tischler,Patrick Schröder,Christian Groth*

Main category: cs.CV

TL;DR: 本文介绍了一个名为 SITUATE 的新数据集，用于训练和评估具有空间约束的计数任务的视觉语言模型。SITUATE 旨在解决现有数据集的局限性，并通过实验证明，使用 SITUATE 进行微调可以提高模型在分布外图像上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有用于视觉语言模型计数任务的数据集存在局限性，例如 VLMCountBench 过于简单，而 TallyQA 则存在歧义且缺乏对遮挡和空间组合的控制。因此，需要一个能够弥合这一差距的数据集来训练和评估更鲁棒的模型。

Method: 作者创建了一个名为 SITUATE 的新数据集，专门用于训练和评估视觉语言模型在具有空间约束的计数任务上的表现。他们使用 SITUATE 数据集对 Qwen VL 2.5 7B 模型进行了微调，并在 Pixmo count 测试集上评估了其准确性，并与其他计数基准和从 Pixmo count 衍生的微调集进行了比较。

Result: 对 Qwen VL 2.5 7B 模型在 SITUATE 数据集上进行微调，可以提高其在 Pixmo count 分布外图像上的准确性。反之，在 Pixmo count 上微调模型则不会提升在 SITUATE 上的性能。与其他计数基准的比较也支持了 SITUATE 对模型泛化能力的提升作用。

Conclusion: SITUATE 数据集能够有效提高视觉语言模型在具有空间约束的计数任务上的泛化能力，尤其是在处理分布外图像时。通过在 SITUATE 上进行微调，模型能够更好地处理现实世界中更复杂、更具挑战性的计数场景。

Abstract: We present SITUATE, a novel dataset designed for training and evaluating Vision Language Models on counting tasks with spatial constraints. The dataset bridges the gap between simple 2D datasets like VLMCountBench and often ambiguous real-life datasets like TallyQA, which lack control over occlusions and spatial composition. Experiments show that our dataset helps to improve generalization for out-of-distribution images, since a finetune of Qwen VL 2.5 7B on SITUATE improves accuracy on the Pixmo count test data, but not vice versa. We cross validate this by comparing the model performance across established other counting benchmarks and against an equally sized fine-tuning set derived from Pixmo count.

</details>


### [159] [Robustness of Presentation Attack Detection in Remote Identity Validation Scenarios](https://arxiv.org/abs/2602.00109)
*John J. Howard,Richard O. Plesh,Yevgeniy B. Sirotin,Jerry L. Tipton,Arun R. Vemury*

Main category: cs.CV

TL;DR: 研究发现，低光照和自动图像采集条件会显著降低商用人脸识别防伪（PAD）系统的性能，可能导致错误率大幅增加，只有少数系统表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有远程身份验证（RIV）系统中的人脸识别防伪（PAD）子系统在多样化的环境和操作条件下性能不稳定，这是一个亟待解决的挑战。

Method: 通过在低光照和自动图像采集条件下进行RIV场景测试，评估了商用PAD系统的鲁棒性。

Result: 在低光照条件下，PAD系统的错误率预测增加约四倍；在自动采集工作流程下，错误率翻倍。仅有一个测试系统在所有场景下都能保持低于3%的真实演示分类错误率。

Conclusion: 在实际应用中确保PAD系统鲁棒性和可靠性，至关重要的是在多样化的环境中进行测试，以应对低光照和自动采集等扰动因素。

Abstract: Presentation attack detection (PAD) subsystems are an important part of effective and user-friendly remote identity validation (RIV) systems. However, ensuring robust performance across diverse environmental and procedural conditions remains a critical challenge. This paper investigates the impact of low-light conditions and automated image acquisition on the robustness of commercial PAD systems using a scenario test of RIV. Our results show that PAD systems experience a significant decline in performance when utilized in low-light or auto-capture scenarios, with a model-predicted increase in error rates by a factor of about four under low-light conditions and a doubling of those odds under auto-capture workflows. Specifically, only one of the tested systems was robust to these perturbations, maintaining a maximum bona fide presentation classification error rate below 3% across all scenarios. Our findings emphasize the importance of testing across diverse environments to ensure robust and reliable PAD performance in real-world applications.

</details>


### [160] [Observing Health Outcomes Using Remote Sensing Imagery and Geo-Context Guided Visual Transformer](https://arxiv.org/abs/2602.00110)
*Yu Li,Guilherme N. DeSouza,Praveen Rao,Chi-Ren Shyu*

Main category: cs.CV

TL;DR: 本文提出了一种新的遥感图像分析模型，该模型通过结合辅助地理空间信息来增强理解能力。通过地理空间嵌入机制和引导注意力模块，该模型能够有效地融合多模态数据，并在疾病流行预测等任务上取得优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言和多模态模型虽然在遥感图像分析方面取得了进展，但它们主要关注语义对齐而非地理空间理解，无法有效处理结构化的地理空间图层。因此，需要一种能够利用辅助地理空间信息来增强遥感图像分析能力的新模型。

Method: 该研究提出了一种新的模型，其核心在于：1. 地理空间嵌入机制：将多种地理空间数据转换为与图像块空间对齐的嵌入块。2. 引导注意力模块：通过计算与辅助数据的相关性来动态集成多模态信息，并为不同的注意力头分配不同的角色，以捕获指导信息的互补方面，提高可解释性。

Result: 实验结果表明，所提出的框架在疾病流行预测方面优于现有的预训练地理空间基础模型，证明了其在多模态地理空间理解方面的有效性。

Conclusion: 本文提出的模型通过地理空间嵌入和引导注意力机制，能够有效地利用辅助地理空间信息来增强遥感图像分析，特别是在需要多模态理解和推理的任务中，如疾病流行预测，显示出优越的性能。

Abstract: Visual transformers have driven major progress in remote sensing image analysis, particularly in object detection and segmentation. Recent vision-language and multimodal models further extend these capabilities by incorporating auxiliary information, including captions, question and answer pairs, and metadata, which broadens applications beyond conventional computer vision tasks. However, these models are typically optimized for semantic alignment between visual and textual content rather than geospatial understanding, and therefore are not suited for representing or reasoning with structured geospatial layers. In this study, we propose a novel model that enhances remote sensing imagery processing with guidance from auxiliary geospatial information. Our approach introduces a geospatial embedding mechanism that transforms diverse geospatial data into embedding patches that are spatially aligned with image patches. To facilitate cross-modal interaction, we design a guided attention module that dynamically integrates multimodal information by computing attention weights based on correlations with auxiliary data, thereby directing the model toward the most relevant regions. In addition, the module assigns distinct roles to individual attention heads, allowing the model to capture complementary aspects of the guidance information and improving the interpretability of its predictions. Experimental results demonstrate that the proposed framework outperforms existing pretrained geospatial foundation models in predicting disease prevalence, highlighting its effectiveness in multimodal geospatial understanding.

</details>


### [161] [From Manual Observation to Automated Monitoring: Space Allowance Effects on Play Behaviour in Group-Housed Dairy Calves](https://arxiv.org/abs/2602.00111)
*Haiyu Yang,Heidi Lesscher,Enhong Liu,Miel Hostens*

Main category: cs.CV

TL;DR: 研究发现，犊牛玩耍行为与空间允许量之间存在非线性关系，最佳玩耍水平出现在每头犊牛 8-10 平方米的空间范围内，并开发了一种用于自动化监测玩耍行为的计算机视觉流水线。


<details>
  <summary>Details</summary>
Motivation: 尽管玩耍行为是奶牛犊牛积极福利的指标，但在商业条件下，尤其是在中高空间允许量（每头犊牛 6-20 平方米）下，其影响仍不明确。

Method: 研究调查了荷兰 14 个商业农场共 60 头犊牛的空间允许量与玩耍行为的关系，并开发了一个自动化的计算机视觉流水线。通过详细的动物行为图谱分析视频观察数据，使用线性混合模型进行统计分析。计算机视觉分类器在手动标注的数据上进行训练和验证。

Result: 计算机视觉分类器在检测活跃玩耍行为时准确率达到 97.6%，召回率达到 99.4%。犊牛平均有 1.0% 的观察时间用于玩耍。空间允许量与玩耍行为的关系呈非线性，每头犊牛 8-10 平方米的空间下玩耍水平最高（1.6%），而在 6-8 平方米和 12-14 平方米的空间下玩耍水平最低（<0.6%）。

Conclusion: 研究结果表明，每头犊牛 8-10 平方米的空间是一个兼顾福利和经济可行性的实际目标。同时，自动化监测技术可以将小规模标注项目扩展为持续的福利评估系统。

Abstract: Play behaviour serves as a positive welfare indicator in dairy calves, yet the influence of space allowance under commercial conditions remains poorly characterized, particularly at intermediate-to-high allowances (6-20 m2 per calf). This study investigated the relationship between space allowance and play behaviour in 60 group-housed dairy calves across 14 commercial farms in the Netherlands (space range: 2.66-17.98 m2 per calf), and developed an automated computer vision pipeline for scalable monitoring. Video observations were analyzed using a detailed ethogram, with play expressed as percentage of observation period (%OP). Statistical analysis employed linear mixed models with farm as a random effect. A computer vision pipeline was trained on manual annotations from 108 hours on 6 farms and validated on held-out test data. The computer vision classifier achieved 97.6% accuracy with 99.4% recall for active play detection. Calves spent on average 1.0% of OP playing reflecting around 10 minutes per 17-hour period. The space-play relationship was non-linear, with highest play levels at 8-10 m2 per calf (1.6% OP) and lowest at 6-8 m2 and 12-14 m2 (<0.6% OP). Space remained significant after controlling for age, health, and group size. In summary, these findings suggest that 8-10 m2 per calf represents a practical target balancing welfare benefits with economic feasibility, and demonstrate that automated monitoring can scale small annotation projects to continuous welfare assessment systems.

</details>


### [162] [AI-Driven Three-Dimensional Reconstruction and Quantitative Analysis for Burn Injury Assessment](https://arxiv.org/abs/2602.00113)
*S. Kalaycioglu,C. Hong,K. Zhai,H. Xie,J. N. Wong*

Main category: cs.CV

TL;DR: 本研究提出了一种基于AI的烧伤评估和管理平台，利用多视图摄影测量、3D表面重建和深度学习来客观量化烧伤面积、深度和愈合进展。


<details>
  <summary>Details</summary>
Motivation: 传统的烧伤评估方法（如目视检查和2D摄影）主观性强且不利于纵向比较，限制了准确的治疗计划、愈合监测和法律记录。

Method: 该平台集成了多视图摄影测量（使用消费级相机）、3D表面重建和深度学习分割。它能够重建患者特异性的3D烧伤表面，将其映射到解剖结构上，并计算客观的度量指标（如表面积、TBSA、与深度相关的几何代理、体积变化）。连续重建通过空间对齐来量化愈合进展。

Result: 基于模拟的评估显示，该系统能够稳定地重建3D模型，一致地计算度量指标，并呈现出临床上合理的纵向愈合趋势。该平台支持结构化的患者录入、图像采集引导、3D分析可视化、治疗建议和自动报告生成。

Conclusion: 该平台提供了一种可扩展、非侵入性的方法，能够对烧伤进行客观的、考虑几何信息的评估，并在急症和门诊护理中提供决策支持，从而实现精确的烧伤管理和纵向追踪。

Abstract: Accurate, reproducible burn assessment is critical for treatment planning, healing monitoring, and medico-legal documentation, yet conventional visual inspection and 2D photography are subjective and limited for longitudinal comparison. This paper presents an AI-enabled burn assessment and management platform that integrates multi-view photogrammetry, 3D surface reconstruction, and deep learning-based segmentation within a structured clinical workflow. Using standard multi-angle images from consumer-grade cameras, the system reconstructs patient-specific 3D burn surfaces and maps burn regions onto anatomy to compute objective metrics in real-world units, including surface area, TBSA, depth-related geometric proxies, and volumetric change. Successive reconstructions are spatially aligned to quantify healing progression over time, enabling objective tracking of wound contraction and depth reduction. The platform also supports structured patient intake, guided image capture, 3D analysis and visualization, treatment recommendations, and automated report generation. Simulation-based evaluation demonstrates stable reconstructions, consistent metric computation, and clinically plausible longitudinal trends, supporting a scalable, non-invasive approach to objective, geometry-aware burn assessment and decision support in acute and outpatient care.

</details>


### [163] [1S-DAug: One-Shot Data Augmentation for Robust Few-Shot Generalization](https://arxiv.org/abs/2602.00114)
*Yunwei Bai,Ying Kiat Tan,Yao Shu,Tsuhan Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为 1S-DAug 的单样本生成式增强方法，可以在测试时从单个样本生成多样且忠实的变体，从而提高少样本学习（FSL）的泛化能力，且无需更新模型参数。


<details>
  <summary>Details</summary>
Motivation: 传统的数据增强方法在少样本学习（FSL）中效果不佳，因为 FSL 面临着仅凭少量标记样本就泛化到新类别的挑战。因此，需要一种在测试时能够有效增强样本的方法。

Method: 1S-DAug 结合了几何变换、噪声注入以及基于原始图像的去噪扩散过程，从而生成新颖的图像变体。这些生成图像与原始图像一起被编码和聚合，形成一个增强的表示，用于更鲁棒的 FSL 预测。

Result: 1S-DAug 作为一个训练无关、模型无关的插件，在多个标准基准测试（包括 miniImagenet 5-way-1-shot 任务）上，在不更新模型参数的情况下，显著提高了 FSL 的准确性，最高可达 10% 以上。

Conclusion: 1S-DAug 是一种有效的测试时生成式增强方法，能够显著提升少样本学习的性能，并且易于集成，无需额外的训练或模型修改。

Abstract: Few-shot learning (FSL) challenges model generalization to novel classes based on just a few shots of labeled examples, a testbed where traditional test-time augmentations fail to be effective. We introduce 1S-DAug, a one-shot generative augmentation operator that synthesizes diverse yet faithful variants from just one example image at test time. 1S-DAug couples traditional geometric perturbations with controlled noise injection and a denoising diffusion process conditioned on the original image. The generated images are then encoded and aggregated, alongside the original image, into a combined representation for more robust FSL predictions. Integrated as a training-free model-agnostic plugin, 1S-DAug consistently improves FSL across standard benchmarks of 4 different datasets without any model parameter update, including achieving over 10% proportional accuracy improvement on the miniImagenet 5-way-1-shot benchmark. Codes will be released.

</details>


### [164] [Event Driven Clustering Algorithm](https://arxiv.org/abs/2602.00115)
*David El-Chai Ben-Ezra,Adar Tal,Daniel Brisk*

Main category: cs.CV

TL;DR: 提出了一种新颖的异步、事件驱动算法，用于实时检测事件相机数据中的小事件簇，具有线性复杂度和与像素尺寸无关的运行时间。


<details>
  <summary>Details</summary>
Motivation: 事件相机数据的实时小事件簇检测需求，以及现有算法在复杂度和运行时间上的不足。

Method: 利用事件相机的异步数据结构，设计了一个高效简单的决策机制，实现了类似层次凝聚聚类但具有线性复杂度的算法。

Result: 算法实现了$O(n)$的线性复杂度，其中$n$是事件数量。运行时间与像素数组的尺寸无关。

Conclusion: 该算法能够高效、实时地检测事件相机数据中的小事件簇，并且在计算效率上优于现有方法。

Abstract: This paper introduces a novel asynchronous, event-driven algorithm for real-time detection of small event clusters in event camera data. Like other hierarchical agglomerative clustering algorithms, the algorithm detects the event clusters based on their tempo-spatial distance. However, the algorithm leverages the special asynchronous data structure of event camera, and by a sophisticated, efficient and simple decision-making, enjoys a linear complexity of $O(n)$ where $n$ is the events amount. In addition, the run-time of the algorithm is independent with the dimensions of the pixels array.

</details>


### [165] [IC-EO: Interpretable Code-based assistant for Earth Observation](https://arxiv.org/abs/2602.00117)
*Lamia Lahouel,Laurynas Lopata,Simon Gruening,Gabriele Meoni,Gaetan Petit,Sylvain Lobry*

Main category: cs.CV

TL;DR: 该研究提出了一个基于大语言模型的对话式代码生成代理，能够将自然语言指令转换为可执行、可审计的Python工作流，用于地球观测（EO）数据分析，提高了EO分析的易用性、透明度和可复现性。


<details>
  <summary>Details</summary>
Motivation: 当前的地球观测（EO）数据分析对非专业人士来说门槛很高，需要专业知识和技术能力。同时，许多现有系统提供黑箱预测，难以审计和复现。

Method: 利用工具大语言模型（LLM），开发了一个能够将自然语言查询转化为可执行Python工作流的对话式代理。该代理支持分类、分割、检测、光谱指数和地理空间算子等多种EO分析任务，并提供工具级、代理级和任务级的可控性。在两个具体用例（土地构成映射和火灾后损伤评估）上进行了评估。

Result: 提出的代理在土地构成映射任务上准确率达到64.2%，优于GPT-4o（51.7%）。在火灾后损伤评估任务上，准确率达到50%，而基线模型为0%。生成的代码透明且易于解释。

Conclusion: 该框架通过输出可验证的代码，将EO分析转变为一个透明、可复现的过程，显著降低了EO分析的门槛，并优于通用的LLM/VLM基线模型。

Abstract: Despite recent advances in computer vision, Earth Observation (EO) analysis remains difficult to perform for the laymen, requiring expert knowledge and technical capabilities. Furthermore, many systems return black-box predictions that are difficult to audit or reproduce. Leveraging recent advances in tool LLMs, this study proposes a conversational, code-generating agent that transforms natural-language queries into executable, auditable Python workflows. The agent operates over a unified easily extendable API for classification, segmentation, detection (oriented bounding boxes), spectral indices, and geospatial operators. With our proposed framework, it is possible to control the results at three levels: (i) tool-level performance on public EO benchmarks; (ii) at the agent-level to understand the capacity to generate valid, hallucination-free code; and (iii) at the task-level on specific use cases. In this work, we select two use-cases of interest: land-composition mapping and post-wildfire damage assessment. The proposed agent outperforms general-purpose LLM/VLM baselines (GPT-4o, LLaVA), achieving 64.2% vs. 51.7% accuracy on land-composition and 50% vs. 0% on post-wildfire analysis, while producing results that are transparent and easy to interpret. By outputting verifiable code, the approach turns EO analysis into a transparent, reproducible process.

</details>


### [166] [VDE Bench: Evaluating The Capability of Image Editing Models to Modify Visual Documents](https://arxiv.org/abs/2602.00122)
*Hongzhu Yi,Yujia Yang,Yuanxiang Wang,Zhenyu Guan,Jiahuan Chen,Chenxi Bao,Tiankun Yang,Yixuan Yuan,Tianyu Zong,Xinming Wang,Tao Yu,Ruiwen Tao,Haijin Liang,Jin Ma,Jinwen Luo,Yeshani Xinyu Zuo,Jungang Xu*

Main category: cs.CV

TL;DR: 提出VDE Bench，一个用于评估多语言和复杂视觉文档图像编辑模型的新基准，该基准包含高质量的英汉数据集和解耦的评估框架，以解决现有模型在非拉丁文字和密集文本布局方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在英文和文本稀疏的文档图像编辑，未能充分处理密集、结构复杂的文档或中文等非拉丁文字的编辑需求。

Method: 构建了一个包含英汉高质量数据集的VDE Bench，该数据集涵盖学术论文、海报、幻灯片、考试材料和报纸等多种密集文本文档。同时，引入了一个解耦的评估框架，可在OCR解析层面量化编辑性能，实现对文本修改准确性的细粒度评估。

Result: 在VDE Bench上对现有最先进的图像编辑模型进行了全面评估，并验证了人工判断与自动评估指标之间的一致性。

Conclusion: VDE Bench是第一个用于评估多语言和密集文本视觉文档图像编辑模型的系统性基准，填补了现有研究的空白。

Abstract: In recent years, multimodal image editing models have achieved substantial progress, enabling users to manipulate visual content through natural language in a flexible and interactive manner. Nevertheless, an important yet insufficiently explored research direction remains visual document image editing, which involves modifying textual content within images while faithfully preserving the original text style and background context. Existing approaches, including AnyText, GlyphControl, and TextCtrl, predominantly focus on English-language scenarios and documents with relatively sparse textual layouts, thereby failing to adequately address dense, structurally complex documents or non-Latin scripts such as Chinese. To bridge this gap, we propose \textbf{V}isual \textbf{D}oc \textbf{E}dit Bench(VDE Bench), a rigorously human-annotated and evaluated benchmark specifically designed to assess image editing models on multilingual and complex visual document editing tasks. The benchmark comprises a high-quality dataset encompassing densely textual documents in both English and Chinese, including academic papers, posters, presentation slides, examination materials, and newspapers. Furthermore, we introduce a decoupled evaluation framework that systematically quantifies editing performance at the OCR parsing level, enabling fine-grained assessment of text modification accuracy. Based on this benchmark, we conduct a comprehensive evaluation of representative state-of-the-art image editing models. Manual verification demonstrates a strong consistency between human judgments and automated evaluation metrics. VDE Bench constitutes the first systematic benchmark for evaluating image editing models on multilingual and densely textual visual documents.

</details>


### [167] [Context-Aware Autoencoders for Anomaly Detection in Maritime Surveillance](https://arxiv.org/abs/2602.00124)
*Divya Acharya,Pierre Bernab'e,Antoine Chevrot,Helge Spieker,Arnaud Gotlieb,Bruno Legeard*

Main category: cs.CV

TL;DR: 提出一种新的上下文感知自编码器，用于改进海上船舶交通监控中的异常检测，通过整合特定上下文的阈值来提高准确性和降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的自编码器在检测海上交通中的集体和上下文异常方面效果有限，因为这些异常很大程度上依赖于船舶的上下文信息。

Method: 提出一种上下文感知自编码器，通过整合特定上下文的阈值来改进异常检测。对四种变体和一种传统自编码器进行了比较。

Result: 上下文感知自编码器在重建损失和异常检测方面表现出显著优势，尤其在检测时间序列数据中的异常方面优于其他方法。

Conclusion: 上下文感知自编码器通过整合上下文信息和特定阈值，为提高海上船舶交通监控系统的准确性提供了一种有前景的解决方案。

Abstract: The detection of anomalies is crucial to ensuring the safety and security of maritime vessel traffic surveillance. Although autoencoders are popular for anomaly detection, their effectiveness in identifying collective and contextual anomalies is limited, especially in the maritime domain, where anomalies depend on vessel-specific contexts derived from self-reported AIS messages. To address these limitations, we propose a novel solution: the context-aware autoencoder. By integrating context-specific thresholds, our method improves detection accuracy and reduces computational cost. We compare four context-aware autoencoder variants and a conventional autoencoder using a case study focused on fishing status anomalies in maritime surveillance. Results demonstrate the significant impact of context on reconstruction loss and anomaly detection. The context-aware autoencoder outperforms others in detecting anomalies in time series data. By incorporating context-specific thresholds and recognizing the importance of context in anomaly detection, our approach offers a promising solution to improve accuracy in maritime vessel traffic surveillance systems.

</details>


### [168] [D3R-Net: Dual-Domain Denoising Reconstruction Network for Robust Industrial Anomaly Detection](https://arxiv.org/abs/2602.00126)
*Dmytro Filatov,Valentyn Fedorov,Vira Filatova,Andrii Zelenchuk*

Main category: cs.CV

TL;DR: 本文提出了一种名为D3R-Net的双域去噪重建框架，通过结合自监督“修复”任务和频率感知正则化，改进了基于重建的无监督异常检测方法，解决了其在处理高频细节时产生的过度平滑问题，提高了缺陷分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的重建式无监督异常检测方法存在过度平滑的问题，导致细微缺陷被部分重构而非突出显示，从而限制了分割精度。

Method: D3R-Net框架包含一个自监督“修复”任务，训练网络重构被人工损坏的正常图像，以学习无缺陷纹理的流形。同时，引入了傅里叶变换（FFT）幅度损失，在频率域上鼓励一致性，并可选地加入了结构相似性（SSIM）损失。

Result: 在MVTec AD Hazelnut基准测试中，D3R-Net引入FFT损失后，PRO AUC从0.603提高到0.687，图像级ROC AUC保持稳定。在15个MVTec类别上的平均测试显示，FFT变体相比仅使用MSE损失的基线，平均像素ROC AUC从0.733提高到0.751，PRO AUC从0.417提高到0.468，同时保持约20 FPS的处理速度。

Conclusion: D3R-Net通过耦合自监督修复和频率感知正则化，有效解决了传统重建方法过度平滑的问题，提高了细微缺陷的检测和分割精度，并且其轻量级的卷积自编码器骨架使其成为一种实用的异常检测方法。

Abstract: Unsupervised anomaly detection (UAD) is a key ingredient of automated visual inspection in modern manufacturing. The reconstruction-based methods appeal because they have basic architectural design and they process data quickly but they produce oversmoothed results for high-frequency details. As a result, subtle defects are partially reconstructed rather than highlighted, which limits segmentation accuracy. We build on this line of work and introduce D3R-Net, a Dual-Domain Denoising Reconstruction framework that couples a self-supervised 'healing' task with frequency-aware regularization. During training, the network receives synthetically corrupted normal images and is asked to reconstruct the clean targets, which prevents trivial identity mapping and pushes the model to learn the manifold of defect-free textures. In addition to the spatial mean squared error, we employ a Fast Fourier Transform (FFT) magnitude loss that encourages consistency in the frequency domain. The implementation also allows an optional structural similarity (SSIM) term, which we study in an ablation. On the MVTec AD Hazelnut benchmark, D3R-Net with the FFT loss improves localization consistency over a spatial-only baseline: PRO AUC increases from 0.603 to 0.687, while image-level ROC AUC remains robust. Evaluated across fifteen MVTec categories, the FFT variant raises the average pixel ROC AUC from 0.733 to 0.751 and PRO AUC from 0.417 to 0.468 compared to the MSE-only baseline, at roughly 20 FPS on a single GPU. The network is trained from scratch and uses a lightweight convolutional autoencoder backbone, providing a practical alternative to heavy pre-trained feature embedding methods.

</details>


### [169] [Efficient UAV trajectory prediction: A multi-modal deep diffusion framework](https://arxiv.org/abs/2602.00107)
*Yuan Gao,Xinyu Guo,Wenjing Xie,Zifan Wang,Hongwen Yu,Gongyang Li,Shugong Xu*

Main category: cs.CV

TL;DR: 提出了一种基于激光雷达和毫米波雷达多模态信息融合的无人机轨迹预测方法，通过深度融合网络有效提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 为了管理低空经济中的非法无人机，需要一种有效的无人机轨迹预测方法。

Method: 设计了一个名为“多模态深度融合框架”的深度融合网络，该网络包含两个独立的模态特定特征提取网络（用于激光雷达和毫米波雷达）和一个双向交叉注意力融合模块，以利用两种传感器数据的互补信息。

Result: 在CVPR 2024 UG2+无人机跟踪和姿态估计挑战赛的MMAUD数据集上进行训练和测试，实验结果表明，所提出的多模态融合模型将轨迹预测精度提高了40%，显著优于基线模型。

Conclusion: 所提出的多模态融合模型能够有效地利用多模态数据，为低空经济中的非法无人机轨迹预测提供了一个高效的解决方案。

Abstract: To meet the requirements for managing unauthorized UAVs in the low-altitude economy, a multi-modal UAV trajectory prediction method based on the fusion of LiDAR and millimeter-wave radar information is proposed. A deep fusion network for multi-modal UAV trajectory prediction, termed the Multi-Modal Deep Fusion Framework, is designed. The overall architecture consists of two modality-specific feature extraction networks and a bidirectional cross-attention fusion module, aiming to fully exploit the complementary information of LiDAR and radar point clouds in spatial geometric structure and dynamic reflection characteristics. In the feature extraction stage, the model employs independent but structurally identical feature encoders for LiDAR and radar. After feature extraction, the model enters the Bidirectional Cross-Attention Mechanism stage to achieve information complementarity and semantic alignment between the two modalities. To verify the effectiveness of the proposed model, the MMAUD dataset used in the CVPR 2024 UG2+ UAV Tracking and Pose-Estimation Challenge is adopted as the training and testing dataset. Experimental results show that the proposed multi-modal fusion model significantly improves trajectory prediction accuracy, achieving a 40% improvement compared to the baseline model. In addition, ablation experiments are conducted to demonstrate the effectiveness of different loss functions and post-processing strategies in improving model performance. The proposed model can effectively utilize multi-modal data and provides an efficient solution for unauthorized UAV trajectory prediction in the low-altitude economy.

</details>


### [170] [SDCM: Simulated Densifying and Compensatory Modeling Fusion for Radar-Vision 3-D Object Detection in Internet of Vehicles](https://arxiv.org/abs/2602.00149)
*Shucong Li,Xiaoluo Zhou,Yuqian He,Zhenyu Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为SDCM的框架，用于解决4D雷达-视觉3D目标检测中点云稀疏和视觉信息退化的问题，通过模拟点云密度和利用雷达信息补偿视觉信息，并引入Mamba进行模态交互融合，最终在多个数据集上取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的4D雷达-视觉3D目标检测方法面临两个挑战：1) 4D雷达点云稀疏导致3D表示能力不足；2) 视觉数据在低光照、远距离和密集遮挡场景下表示退化，融合时纹理信息不可靠。

Method: 提出SDCM框架，包含三个模块：1) Simulated Densifying (SimDen) 模块：通过高斯模拟关键点和曲率模拟轮廓来生成密集的雷达点云。2) Radar Compensatory Mapping (RCM) 模块：利用雷达数据（全天候特性）补偿视觉数据表示退化。3) Mamba Modeling Interactive Fusion (MMIF) 模块：通过提取特征张量差值来减少异构性并实现模态交互融合。

Result: 在VoD、TJ4DRadSet和Astyx HiRes 2019数据集上的实验结果表明，SDCM取得了最佳性能，同时具有较低的参数量和更快的推理速度。

Conclusion: SDCM框架成功解决了4D雷达-视觉3D目标检测中的点云稀疏和视觉信息退化问题，并通过提出的模块实现了有效的模态融合，在性能和效率上均优于现有方法。

Abstract: 3-D object detection based on 4-D radar-vision is an important part in Internet of Vehicles (IoV). However, there are two challenges which need to be faced. First, the 4-D radar point clouds are sparse, leading to poor 3-D representation. Second, vision datas exhibit representation degradation under low-light, long distance detection and dense occlusion scenes, which provides unreliable texture information during fusion stage. To address these issues, a framework named SDCM is proposed, which contains Simulated Densifying and Compensatory Modeling Fusion for radar-vision 3-D object detection in IoV. Firstly, considering point generation based on Gaussian simulation of key points obtained from 3-D Kernel Density Estimation (3-D KDE), and outline generation based on curvature simulation, Simulated Densifying (SimDen) module is designed to generate dense radar point clouds. Secondly, considering that radar data could provide more real time information than vision data, due to the all-weather property of 4-D radar. Radar Compensatory Mapping (RCM) module is designed to reduce the affects of vision datas' representation degradation. Thirdly, considering that feature tensor difference values contain the effective information of every modality, which could be extracted and modeled for heterogeneity reduction and modalities interaction, Mamba Modeling Interactive Fusion (MMIF) module is designed for reducing heterogeneous and achieving interactive Fusion. Experiment results on the VoD, TJ4DRadSet and Astyx HiRes 2019 dataset show that SDCM achieves best performance with lower parameter quantity and faster inference speed. Our code will be available.

</details>


### [171] [PovNet+: A Deep Learning Architecture for Socially Assistive Robots to Learn and Assist with Multiple Activities of Daily Living](https://arxiv.org/abs/2602.00131)
*Fraser Robinson,Souren Pashangpour,Matthew Lisondra,Goldie Nejat*

Main category: cs.CV

TL;DR: 提出了一种名为POVNet+的多模态深度学习架构，用于识别自主社交辅助机器人需要进行的多种日常生活活动（ADLs），从而主动提供帮助。该架构结合了ADL和运动嵌入空间，能够区分已知活动、新活动或异常进行的已知活动，并利用用户状态估计来识别新活动。实验表明，POVNet+在ADL分类准确性上优于现有方法，并在真实的人机交互环境中成功识别了多种ADLs并启动了适当的辅助。


<details>
  <summary>Details</summary>
Motivation: 现有自主社交辅助机器人难以同时感知和辅助多种日常生活活动（ADLs），这阻碍了其长期部署。研究旨在解决这一挑战，使机器人能够更主动地提供帮助。

Method: 提出了一种名为POVNet+的多模态深度学习架构，该架构结合了ADL嵌入空间和运动嵌入空间，并引入了用户状态估计方法。POVNet+能够区分已知ADL、新ADL以及异常进行的已知ADL，并通过用户状态估计来识别新ADL并监测用户表现。

Result: 与最先进的人类活动识别方法相比，POVNet+在ADL分类准确性上表现更优。在真实复杂客厅环境中的人机交互实验表明，POVNet+能够成功识别多种已知和未知ADLs，以及异常进行的ADLs，并能主动发起恰当的机器人辅助交互。

Conclusion: POVNet+是一种创新的多模态深度学习架构，能够有效解决社交辅助机器人识别和响应多种ADLs的难题，通过主动发起辅助来提升机器人在真实场景中的实用性。

Abstract: A significant barrier to the long-term deployment of autonomous socially assistive robots is their inability to both perceive and assist with multiple activities of daily living (ADLs). In this paper, we present the first multimodal deep learning architecture, POVNet+, for multi-activity recognition for socially assistive robots to proactively initiate assistive behaviors. Our novel architecture introduces the use of both ADL and motion embedding spaces to uniquely distinguish between a known ADL being performed, a new unseen ADL, or a known ADL being performed atypically in order to assist people in real scenarios. Furthermore, we apply a novel user state estimation method to the motion embedding space to recognize new ADLs while monitoring user performance. This ADL perception information is used to proactively initiate robot assistive interactions. Comparison experiments with state-of-the-art human activity recognition methods show our POVNet+ method has higher ADL classification accuracy. Human-robot interaction experiments in a cluttered living environment with multiple users and the socially assistive robot Leia using POVNet+ demonstrate the ability of our multi-modal ADL architecture in successfully identifying different seen and unseen ADLs, and ADLs being performed atypically, while initiating appropriate assistive human-robot interactions.

</details>


### [172] [See Without Decoding: Motion-Vector-Based Tracking in Compressed Video](https://arxiv.org/abs/2602.00153)
*Axel Duché,Clément Chatelain,Gilles Gasso*

Main category: cs.CV

TL;DR: 提出了一种轻量级的压缩域跟踪模型，直接在视频流上操作，无需完全解码RGB视频，利用运动向量和变换系数进行目标跟踪，速度提升高达3.7倍，mAP@0.5下降仅4%。


<details>
  <summary>Details</summary>
Motivation: 为了提高实时视频监控系统中大型监测设备的计算效率，减少对计算资源的需求，同时保持跟踪性能。

Method: 利用深度学习模型，直接从压缩视频流中提取的运动向量（motion vectors）和变换系数（transform coefficients）进行目标跟踪，无需进行完整的RGB视频解码。

Result: 在MOTS15/17/20数据集上，该模型实现了高达3.7倍的计算速度提升，同时mAP@0.5的性能仅下降4%，与RGB基线相比。

Conclusion: 该研究证明了在视频编码域进行运动建模的效率，对于实现大规模实时视频分析系统具有重要意义。

Abstract: We propose a lightweight compressed-domain tracking model that operates directly on video streams, without requiring full RGB video decoding. Using motion vectors and transform coefficients from compressed data, our deep model propagates object bounding boxes across frames, achieving a computational speed-up of order up to 3.7 with only a slight 4% mAP@0.5 drop vs RGB baseline on MOTS15/17/20 datasets. These results highlight codec-domain motion modeling efficiency for real-time analytics in large monitoring systems.

</details>


### [173] [Shedding the Facades, Connecting the Domains: Detecting Shifting Multimodal Hate Video with Test-Time Adaptation](https://arxiv.org/abs/2602.00132)
*Jiao Li,Jian Lang,Xikai Tang,Wenzheng Shu,Ting Zhong,Qiang Gao,Yong Wang,Leiting Chen,Fan Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为SCANNER的端到端测试时间适应（TTA）框架，用于检测语义漂移严重的心怀敌意视频（HVD），通过识别和利用不变的“核心”来连接训练和推理领域，并引入了样本级自适应中心对齐和类内多样性正则化以提高适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的仇恨视频检测方法在训练和推理数据分布相同的情况下表现良好，但仇恨内容会不断演变，导致语义漂移，使现有模型失效。现有的测试时间适应（TTA）方法无法处理这种严重的语义漂移。

Method: SCANNER框架包含三个关键组件：1. 中心引导对齐机制：识别并利用仇恨内容中稳定不变的核心（如基于性别、种族等目标特征）。2. 样本级自适应中心对齐：通过引入样本级别的自适应机制，减少与中心关联度不强的样本对齐过程的影响，提高适应的稳定性。3. 类内多样性正则化：鼓励簇内语义丰富性，避免由于输出过于统一而导致的语义崩溃。

Result: SCANNER在实验中取得了显著成果，平均在Macro-F1上比现有最优方法高出4.69%。

Conclusion: SCANNER是首个专门为HVD设计的TTA框架，通过识别不变的核心并引入样本级自适应对齐和类内多样性正则化，有效解决了HVD中的严重语义漂移问题，并显著优于现有基线方法。

Abstract: Hate Video Detection (HVD) is crucial for online ecosystems. Existing methods assume identical distributions between training (source) and inference (target) data. However, hateful content often evolves into irregular and ambiguous forms to evade censorship, resulting in substantial semantic drift and rendering previously trained models ineffective. Test-Time Adaptation (TTA) offers a solution by adapting models during inference to narrow the cross-domain gap, while conventional TTA methods target mild distribution shifts and struggle with the severe semantic drift in HVD. To tackle these challenges, we propose SCANNER, the first TTA framework tailored for HVD. Motivated by the insight that, despite the evolving nature of hateful manifestations, their underlying cores remain largely invariant (i.e., targeting is still based on characteristics like gender, race, etc), we leverage these stable cores as a bridge to connect the source and target domains. Specifically, SCANNER initially reveals the stable cores from the ambiguous layout in evolving hateful content via a principled centroid-guided alignment mechanism. To alleviate the impact of outlier-like samples that are weakly correlated with centroids during the alignment process, SCANNER enhances the prior by incorporating a sample-level adaptive centroid alignment strategy, promoting more stable adaptation. Furthermore, to mitigate semantic collapse from overly uniform outputs within clusters, SCANNER introduces an intra-cluster diversity regularization that encourages the cluster-wise semantic richness. Experiments show that SCANNER outperforms all baselines, with an average gain of 4.69% in Macro-F1 over the best.

</details>


### [174] [LLaVA-FA: Learning Fourier Approximation for Compressing Large Multimodal Models](https://arxiv.org/abs/2602.00135)
*Pengcheng Zheng,Chaoning Zhang,Jiarong Mo,GuoHui Li,Jiaquan Zhang,Jiahao Zhang,Sihan Cao,Sheng Zheng,Caiyan Qin,Guoqing Wang,Yang Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 LLaVA-FA 的高效大模型（LMM）压缩方法，通过在频域内联合进行低秩分解和量化，并引入了 PolarQuant 和 ODC 等技术，实现了比现有方法更小的模型尺寸和更低的计算成本，同时保持了出色的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型（LMM）由于计算和内存成本高昂，难以实际部署。现有的压缩方法将低秩分解和量化分开处理，导致误差累积，尤其是在存在跨模态冗余的 LMM 中。

Method: 在频域内联合进行低秩加量化近似，利用傅里叶变换的去相关性和共轭对称性来获得更紧凑和准确的权重表示。引入了针对复数矩阵的 PolarQuant 量化方法，并提出了一种可选的对角校准（ODC）方案，无需大规模校准数据。

Result: LLaVA-FA 在多个基准测试中优于现有的高效多模态模型，同时保持了激活参数量和计算成本的最小化。

Conclusion: LLaVA-FA 是一种有效的 LMM 压缩解决方案，能够在保持性能的同时显著降低模型的大小和计算需求。

Abstract: Large multimodal models (LMMs) have achieved impressive performance on various vision-language tasks, but their substantial computational and memory costs hinder their practical deployment. Existing compression methods often decouple low-rank decomposition and quantization, leading to compounded reconstruction errors, especially in multimodal architectures with cross-modal redundancy. To address this issue, we propose LLaVA-FA, a novel efficient LMM that performs joint low-rank plus quantization approximation in the frequency domain. By leveraging the de-correlation and conjugate symmetry properties of Fourier transform, LLaVA-FA achieves more compact and accurate weight representations. Furthermore, we introduce PolarQuant, a polar-coordinate quantization method tailored for complex matrices, and an optional diagonal calibration (ODC) scheme that eliminates the need for large-scale calibration data. Extensive experimental results demonstrate that our proposed LLaVA-FA outperforms existing efficient multimodal models across multiple benchmarks while maintaining minimal activated parameters and low computational costs, validating its effectiveness as a powerful solution for compressing LMMs.

</details>


### [175] [Development of a Cacao Disease Identification and Management App Using Deep Learning](https://arxiv.org/abs/2602.00216)
*Zaldy Pagaduan,Jason Occidental,Nathaniel Duro,Dexielito Badilles,Eleonor Palconit*

Main category: cs.CV

TL;DR: 本文开发了一款用于菲律宾小农的离线移动应用程序，利用深度学习模型来识别和管理可可疾病，以提高作物健康和产量。


<details>
  <summary>Details</summary>
Motivation: 菲律宾的小农可可生产者面临病虫害的严峻挑战，并且难以获得数据、信息和良好的农业实践，这与拥有更多资源的大型种植园形成鲜明对比。

Method: 该研究开发了一个离线移动应用程序，集成了用于可可疾病识别和感染水平估计的深度学习模型。该模型在移动应用程序中进行训练和集成，以支持现场诊断。

Result: 疾病识别模型达到了 96.93% 的验证准确率，而检测可可黑荚感染水平的模型达到了 79.49% 的验证准确率。应用程序的现场测试与专家评估的一致率为 84.2%。

Conclusion: 该移动应用程序通过提供可访问的技术支持工具，能够赋能小农，从而改善可可作物的健康和生产力，特别是在资源有限的偏远地区。

Abstract: Smallholder cacao producers often rely on outdated farming techniques and face significant challenges from pests and diseases, unlike larger plantations with more resources and expertise. In the Philippines, cacao farmers have limited access to data, information, and good agricultural practices. This study addresses these issues by developing a mobile application for cacao disease identification and management that functions offline, enabling use in remote areas where farms are mostly located. The core of the system is a deep learning model trained to identify cacao diseases accurately. The trained model is integrated into the mobile app to support farmers in field diagnosis. The disease identification model achieved a validation accuracy of 96.93% while the model for detecting cacao black pod infection levels achieved 79.49% validation accuracy. Field testing of the application showed an agreement rate of 84.2% compared with expert cacao technician assessments. This approach empowers smallholder farmers by providing accessible, technology-enabled tools to improve cacao crop health and productivity.

</details>


### [176] [Combined Flicker-banding and Moire Removal for Screen-Captured Images](https://arxiv.org/abs/2602.01559)
*Libo Zhu,Zihan Zhou,Zhiyi Zhou,Yiyang Qu,Weihang Zhang,Keyu Shi,Yifan Fu,Yulun Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为CLEAR的统一恢复框架，用于联合去除手机拍摄屏幕图像中的摩尔纹和闪烁条带这两种常见且耦合严重的伪影。该方法通过构建包含这两种伪影的大规模数据集、利用ISP模拟闪烁以及引入频域分解与重组模块和轨迹对齐损失，有效提升了图像恢复效果。


<details>
  <summary>Details</summary>
Motivation: 手机拍摄屏幕图像时，摩尔纹和闪烁条带是常见的、且耦合严重的伪影，严重影响图像质量。现有方法仅针对单一伪影，无法有效处理复合场景。

Method: 构建了包含摩尔纹和闪烁条带的大规模数据集；设计了基于ISP的闪烁模拟管线以稳定训练并扩展退化分布；提出了一种频域分解与重组模块；引入了轨迹对齐损失来增强对复合伪影的建模。

Result: 所提出的CLEAR方法在多个评估指标上持续优于现有的图像恢复方法，证明了其在复杂真实场景中的有效性。

Conclusion: 该研究首次系统性地研究了屏幕捕获图像中摩尔纹和闪烁条带的联合去除问题，并提出了一种有效的统一恢复框架CLEAR，能够有效处理这两种耦合伪影，显著提升图像质量。

Abstract: Capturing display screens with mobile devices has become increasingly common, yet the resulting images often suffer from severe degradations caused by the coexistence of moiré patterns and flicker-banding, leading to significant visual quality degradation. Due to the strong coupling of these two artifacts in real imaging processes, existing methods designed for single degradations fail to generalize to such compound scenarios. In this paper, we present the first systematic study on joint removal of moiré patterns and flicker-banding in screen-captured images, and propose a unified restoration framework, named CLEAR. To support this task, we construct a large-scale dataset containing both moiré patterns and flicker-banding, and introduce an ISP-based flicker simulation pipeline to stabilize model training and expand the degradation distribution. Furthermore, we design a frequency-domain decomposition and re-composition module together with a trajectory alignment loss to enhance the modeling of compound artifacts. Extensive experiments demonstrate that the proposed method consistently. outperforms existing image restoration approaches across multiple evaluation metrics, validating its effectiveness in complex real-world scenarios.

</details>


### [177] [Scalable Analytic Classifiers with Associative Drift Compensation for Class-Incremental Learning of Vision Transformers](https://arxiv.org/abs/2602.00144)
*Xuan Rao,Mingming Ha,Bo Zhao,Derong Liu,Cesare Alippi*

Main category: cs.CV

TL;DR: 本文提出了一种名为LR-RGDA的低秩因子化正则化高斯判别分析方法，用于解决Vision Transformers在类别增量学习中的计算瓶颈问题，并结合Hopfield网络实现训练无关的分布补偿，以缓解表示漂移，并在各类CIL基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有类别增量学习（CIL）方法在使用Vision Transformers（ViTs）时，在分类器重构阶段存在计算瓶颈，通常依赖于耗时的迭代随机梯度下降（SGD）。虽然分析性正则化高斯判别分析（RGDA）提供了准确的替代方案，但其二次推理复杂度限制了其在大规模CIL场景中的应用。因此，需要一种更具扩展性的方法。

Method: 本文提出了低秩因子化RGDA（LR-RGDA），它利用Woodbury矩阵恒等式来分解协方差的低秩结构，将判别函数表示为一个全局仿射项和一个低秩二次扰动项，从而将推理复杂度从O(Cd^2)降低到O(d^2 + Crd^2)。此外，为了解决主干网络更新导致的表示漂移问题，引入了基于Hopfield网络的分布补偿器（HopDC），这是一个训练无关的机制，利用连续Hopfield网络通过无标签锚点的联想记忆动力学来校准历史类统计信息。

Result: 所提出的LR-RGDA方法，结合HopDC，在多种CIL基准测试中取得了最先进的性能。该方法显著降低了推理复杂度，同时有效缓解了表示漂移，为大规模ViT的CIL提供了可扩展的解决方案。

Conclusion: LR-RGDA是一种高效且强大的类别增量学习分类器，它通过低秩分解克服了RGDA的计算瓶颈，并结合HopDC解决了表示漂移问题。该框架为大规模ViT的类别增量学习提供了一个可扩展且性能优越的解决方案。

Abstract: Class-incremental learning (CIL) with Vision Transformers (ViTs) faces a major computational bottleneck during the classifier reconstruction phase, where most existing methods rely on costly iterative stochastic gradient descent (SGD). We observe that analytic Regularized Gaussian Discriminant Analysis (RGDA) provides a Bayes-optimal alternative with accuracy comparable to SGD-based classifiers; however, its quadratic inference complexity limits its use in large-scale CIL scenarios. To overcome this, we propose Low-Rank Factorized RGDA (LR-RGDA), a scalable classifier that combines RGDA's expressivity with the efficiency of linear classifiers. By exploiting the low-rank structure of the covariance via the Woodbury matrix identity, LR-RGDA decomposes the discriminant function into a global affine term refined by a low-rank quadratic perturbation, reducing the inference complexity from $\mathcal{O}(Cd^2)$ to $\mathcal{O}(d^2 + Crd^2)$, where $C$ is the class number, $d$ the feature dimension, and $r \ll d$ the subspace rank. To mitigate representation drift caused by backbone updates, we further introduce Hopfield-based Distribution Compensator (HopDC), a training-free mechanism that uses modern continuous Hopfield Networks to recalibrate historical class statistics through associative memory dynamics on unlabeled anchors, accompanied by a theoretical bound on the estimation error. Extensive experiments on diverse CIL benchmarks demonstrate that our framework achieves state-of-the-art performance, providing a scalable solution for large-scale class-incremental learning with ViTs. Code: https://github.com/raoxuan98-hash/lr_rgda_hopdc.

</details>


### [178] [DensiThAI, A Multi-View Deep Learning Framework for Breast Density Estimation using Infrared Images](https://arxiv.org/abs/2602.00145)
*Siva Teja Kakileti,Geetha Manjunath*

Main category: cs.CV

TL;DR: 本研究提出了一种名为 DensiThAI 的多视图深度学习框架，利用红外热成像图像估计乳腺密度，旨在提供一种无电离辐射的替代方法。该方法在包含 3500 名女性的多中心数据集上进行了评估，结果显示其平均 AUROC 达到 0.73，并在不同年龄组中表现出稳健的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的乳腺密度评估依赖于 X 射线乳腺钼靶摄影，这是一种会产生电离辐射的成像方式。研究人员希望探索一种非电离辐射的替代方法，利用人工智能分析红外热成像图像来估计乳腺密度，因为他们假设不同组织（纤维腺体和脂肪）具有不同的热物理和生理特性，从而在乳腺表面产生可检测到的温度差异。

Method: 研究者提出了一个名为 DensiThAI 的多视图深度学习框架，用于从红外热成像图像中对乳腺密度进行分类。该框架利用了五种标准的红外热成像视图，并利用乳腺钼靶摄影得出的密度标签作为参考。

Result: 在包含 3500 名女性的多中心数据集上，DensiThAI 在 10 次随机数据划分中取得了平均 0.73 的 AUROC。研究发现，在所有数据划分中，该模型都能在不同密度类别之间实现统计学上的显著区分（p << 0.05），并且在不同年龄组中表现出一致的性能。

Conclusion: 研究结论认为，基于红外热成像和深度学习的 DensiThAI 框架在乳腺密度评估方面具有可行性，可以作为一种非电离辐射的成像方法。这项技术有望改善患者体验和优化工作流程。

Abstract: Breast tissue density is a key biomarker of breast cancer risk and a major factor affecting mammographic sensitivity. However, density assessment currently relies almost exclusively on X-ray mammography, an ionizing imaging modality. This study investigates the feasibility of estimating breast density using artificial intelligence over infrared thermal images, offering a non-ionizing imaging approach. The underlying hypothesis is that fibroglandular and adipose tissues exhibit distinct thermophysical and physiological properties, leading to subtle but spatially coherent temperature variations on the breast surface. In this paper, we propose DensiThAI, a multi-view deep learning framework for breast density classification from thermal images. The framework was evaluated on a multi-center dataset of 3,500 women using mammography-derived density labels as reference. Using five standard thermal views, DensiThAI achieved a mean AUROC of 0.73 across 10 random splits, with statistically significant separation between density classes across all splits (p << 0.05). Consistent performance across age cohorts supports the potential of thermal imaging as a non-ionizing approach for breast density assessment with implications for improved patient experience and workflow optimization.

</details>


### [179] [Learning Physics-Grounded 4D Dynamics with Neural Gaussian Force Fields](https://arxiv.org/abs/2602.00148)
*Shiqian Li,Ruihong Shen,Junfeng Ni,Chang Pan,Chi Zhang,Yixin Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种名为神经高斯力场（NGFF）的端到端神经网络框架，它将3D高斯感知与基于物理的动力学模型相结合，能够从多视图RGB输入生成具有物理真实感的交互式4D视频，并且速度比现有高斯模拟器快两个数量级。同时，作者还发布了一个名为GSCollision的大规模4D高斯数据集，以支持NGFF的训练。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在生成物理上合理（physically plausible）的视频方面存在困难，因为它们缺乏对物理定律的建模。虽然结合3D高斯喷溅和物理引擎的方法可以生成物理上合理的视频，但计算成本高且在复杂真实场景中鲁棒性不足。

Method: 提出了一种名为神经高斯力场（NGFF）的端到端神经网络框架，它集成了3D高斯感知和物理动力学模型，能够从多视图RGB输入生成交互式、物理真实的4D视频。为了训练模型，还提出了GSCollision数据集，该数据集包含多种材料、多物体交互和复杂场景，并渲染了大量的物理视频。

Result: NGFF的生成速度比先前的高斯模拟器快两个数量级。在合成和真实3D场景的评估中，NGFF表现出强大的泛化能力和物理推理的鲁棒性。

Conclusion: NGFF通过结合3D高斯感知和物理动力学模型，成功地生成了物理上合理的4D视频，并在效率和鲁棒性方面取得了显著进展，推动了视频预测向基于物理的世界模型发展。

Abstract: Predicting physical dynamics from raw visual data remains a major challenge in AI. While recent video generation models have achieved impressive visual quality, they still cannot consistently generate physically plausible videos due to a lack of modeling of physical laws. Recent approaches combining 3D Gaussian splatting and physics engines can produce physically plausible videos, but are hindered by high computational costs in both reconstruction and simulation, and often lack robustness in complex real-world scenarios. To address these issues, we introduce Neural Gaussian Force Field (NGFF), an end-to-end neural framework that integrates 3D Gaussian perception with physics-based dynamic modeling to generate interactive, physically realistic 4D videos from multi-view RGB inputs, achieving two orders of magnitude faster than prior Gaussian simulators. To support training, we also present GSCollision, a 4D Gaussian dataset featuring diverse materials, multi-object interactions, and complex scenes, totaling over 640k rendered physical videos (~4 TB). Evaluations on synthetic and real 3D scenarios show NGFF's strong generalization and robustness in physical reasoning, advancing video prediction towards physics-grounded world models.

</details>


### [180] [Investigating the Impact of Histopathological Foundation Models on Regressive Prediction of Homologous Recombination Deficiency](https://arxiv.org/abs/2602.00151)
*Alexander Blezinger,Wolfgang Nejdl,Ming Tang*

Main category: cs.CV

TL;DR: 本研究系统评估了基于大型组织病理学数据预训练的Foundation Models在回归性生物标志物预测任务中的表现，特别关注了同源重组缺陷（HRD）评分的预测。研究发现在多示例学习框架下，使用Foundation Models提取的病理图像（WSI）的patch级特征，相比于对比学习方法，能显著提高预测精度和泛化能力。此外，研究还提出了一种基于分布的上采样策略，以解决目标不平衡问题，并改善了对代表性不足但临床重要的患者群体的预测效果。


<details>
  <summary>Details</summary>
Motivation: 尽管Foundation Models在计算病理学领域取得了成功，但其在回归性生物标志物预测方面的应用仍未得到充分探索。HRD评分是预测癌症治疗反应的关键生物标志物，但其准确预测具有挑战性。因此，本研究旨在系统评估Foundation Models在HRD评分等回归性任务上的潜力，并探索改进预测性能的方法。

Method: 研究采用了多示例学习（Multiple Instance Learning）框架，利用五种先进的Foundation Models从全切片图像（WSI）中提取patch级特征，并与对比学习方法提取的特征进行比较。模型被训练用于预测连续HRD分数，评估范围涵盖乳腺癌、子宫内膜癌和肺癌。此外，研究还提出了一种分布式上采样策略来处理目标不平衡问题，并进行了消融实验研究了采样策略和实例bag大小的影响。

Result: 基于Foundation Models提取的特征训练的模型，在预测精度和泛化能力上始终优于基线方法。不同Foundation Models之间存在系统性差异。提出的分布式上采样策略显著提高了对代表性不足但临床重要的患者群体的召回率和平衡准确率。

Conclusion: 大规模组织病理学预训练的Foundation Models对于更精确和可迁移的回归性生物标志物预测具有显著优势，为AI驱动的精准肿瘤学提供了新的可能性。该研究为在临床应用中利用Foundation Models进行生物标志物预测提供了有力证据和优化策略。

Abstract: Foundation models pretrained on large-scale histopathology data have found great success in various fields of computational pathology, but their impact on regressive biomarker prediction remains underexplored. In this work, we systematically evaluate histopathological foundation models for regression-based tasks, demonstrated through the prediction of homologous recombination deficiency (HRD) score - a critical biomarker for personalized cancer treatment. Within multiple instance learning frameworks, we extract patch-level features from whole slide images (WSI) using five state-of-the-art foundation models, and evaluate their impact compared to contrastive learning-based features. Models are trained to predict continuous HRD scores based on these extracted features across breast, endometrial, and lung cancer cohorts from two public medical data collections. Extensive experiments demonstrate that models trained on foundation model features consistently outperform the baseline in terms of predictive accuracy and generalization capabilities while exhibiting systematic differences among the foundation models. Additionally, we propose a distribution-based upsampling strategy to mitigate target imbalance in these datasets, significantly improving the recall and balanced accuracy for underrepresented but clinically important patient populations. Furthermore, we investigate the impact of different sampling strategies and instance bagsizes by ablation studies. Our results highlight the benefits of large-scale histopathological pretraining for more precise and transferable regressive biomarker prediction, showcasing its potential to advance AI-driven precision oncology.

</details>


### [181] [Real-Time Human Activity Recognition on Edge Microcontrollers: Dynamic Hierarchical Inference with Multi-Spectral Sensor Fusion](https://arxiv.org/abs/2602.00152)
*Boyu Li,Kuangji Zuo,Lincong Li,Yonghui Wu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 HPPI-Net 的分层融合网络，用于在计算资源受限的边缘设备上进行实时高精度的人类活动识别 (HAR)。该网络通过多光谱融合和可解释模块，在 ARM Cortex-M4 微控制器上实现了 96.70% 的准确率，同时内存占用极低。


<details>
  <summary>Details</summary>
Motivation: 现有方法在边缘应用中难以在准确性和计算资源限制之间取得平衡，尤其是在对计算能力要求高的模式识别任务上。研究旨在提出一个既准确又计算高效的解决方案，以满足低功耗实时推理的需求。

Method: HPPI-Net 采用两层架构。第一层使用快速傅里叶变换 (FFT) 频谱图提取初步特征。第二层根据活动状态（静止或动态）选择性激活不同的模块：针对静止活动使用专用模块，针对动态活动使用并行 LSTM-MobileNet 网络 (PLMN)。PLMN 融合了 FFT、小波和 Gabor 频谱图，通过三个并行的 LSTM 编码器，并利用高效通道注意力 (ECA) 和深度可分离卷积 (DSC) 进行特征细化，从而实现通道级可解释性并减少计算量。

Result: HPPI-Net 在 ARM Cortex-M4 微控制器上实现了 96.70% 的准确率，内存 (RAM) 占用仅为 22.3 KiB，存储空间 (ROM) 占用为 439.5 KiB。与 MobileNetV3 相比，HPPI-Net 准确率提高了 1.22%，RAM 减少了 71.2%，ROM 减少了 42.1%。

Conclusion: HPPI-Net 在准确性和效率之间取得了良好的权衡，为内存受限的边缘平台提供了实用且可解释的人类活动识别解决方案，适用于可穿戴设备、工业和智能家居等场景。

Abstract: The demand for accurate on-device pattern recognition in edge applications is intensifying, yet existing approaches struggle to reconcile accuracy with computational constraints. To address this challenge, a resource-aware hierarchical network based on multi-spectral fusion and interpretable modules, namely the Hierarchical Parallel Pseudo-image Enhancement Fusion Network (HPPI-Net), is proposed for real-time, on-device Human Activity Recognition (HAR). Deployed on an ARM Cortex-M4 microcontroller for low-power real-time inference, HPPI-Net achieves 96.70% accuracy while utilizing only 22.3 KiB of RAM and 439.5 KiB of ROM after optimization. HPPI-Net employs a two-layer architecture. The first layer extracts preliminary features using Fast Fourier Transform (FFT) spectrograms, while the second layer selectively activates either a dedicated module for stationary activity recognition or a parallel LSTM-MobileNet network (PLMN) for dynamic states. PLMN fuses FFT, Wavelet, and Gabor spectrograms through three parallel LSTM encoders and refines the concatenated features using Efficient Channel Attention (ECA) and Depthwise Separable Convolution (DSC), thereby offering channel-level interpretability while substantially reducing multiply-accumulate operations. Compared with MobileNetV3, HPPI-Net improves accuracy by 1.22% and reduces RAM usage by 71.2% and ROM usage by 42.1%. These results demonstrate that HPPI-Net achieves a favorable accuracy-efficiency trade-off and provides explainable predictions, establishing a practical solution for wearable, industrial, and smart home HAR on memory-constrained edge platforms.

</details>


### [182] [Deep Learning Pose Estimation for Multi-Label Recognition of Combined Hyperkinetic Movement Disorders](https://arxiv.org/abs/2602.00163)
*Laura Cif,Diane Demailly,Gabriella A. Horvàth,Juan Dario Ortigoza Escobar,Nathalie Dorison,Mayté Castro Jiménez,Cécile A. Hubsch,Thomas Wirth,Gun-Marie Hariz,Sophie Huby,Morgan Dornadic,Zohra Souei,Muhammad Mushhood Ur Rehman,Simone Hemm,Mehdi Boulayme,Eduardo M. Moraud,Jocelyne Bloch,Xavier Vasques*

Main category: cs.CV

TL;DR: 本研究提出了一种基于姿态的机器学习框架，用于从临床视频中提取运动学特征，以客观地区分不同的惊厥性运动障碍（HMDs）表型。


<details>
  <summary>Details</summary>
Motivation: 传统的HMDs临床评估主观性强且易受评分者差异影响，而HMDs症状的波动性、间歇性和共存性增加了临床识别和长期监测的难度，目前缺乏客观、可扩展的方法来区分重叠的HMDs表型。

Method: 开发了一个基于姿态的机器学习框架，将标准门诊视频转换为具有解剖学意义的关键点时间序列，并计算了跨越统计、时间、频谱和高阶不规则性-复杂性特征的运动学描述符。

Result: 该框架能够将临床视频转化为可量化的运动学特征。

Conclusion: 提出的方法为客观区分重叠的HMDs表型提供了潜在的解决方案，有望克服当前评估方法的局限性。

Abstract: Hyperkinetic movement disorders (HMDs) such as dystonia, tremor, chorea, myoclonus, and tics are disabling motor manifestations across childhood and adulthood. Their fluctuating, intermittent, and frequently co-occurring expressions hinder clinical recognition and longitudinal monitoring, which remain largely subjective and vulnerable to inter-rater variability. Objective and scalable methods to distinguish overlapping HMD phenotypes from routine clinical videos are still lacking. Here, we developed a pose-based machine-learning framework that converts standard outpatient videos into anatomically meaningful keypoint time series and computes kinematic descriptors spanning statistical, temporal, spectral, and higher-order irregularity-complexity features.

</details>


### [183] [YOLOE-26: Integrating YOLO26 with YOLOE for Real-Time Open-Vocabulary Instance Segmentation](https://arxiv.org/abs/2602.00168)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

TL;DR: YOLOE-26 是一个用于实时开放词汇实例分割的统一框架，它结合了 YOLOv26 的高效部署优化和 YOLOE 的开放词汇学习能力，通过替换固定类 Logits 为对象嵌入头，实现了零开销文本提示、示例引导分割和无提示推理，并在各种模型尺寸下都表现出良好的精度-效率权衡。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为了实现一个能够超越闭集识别、支持实时开放词汇实例分割的统一框架，同时保持 YOLO 系列的高效性和确定性。

Method: 该方法将 YOLOv26 的 NMS-free、端到端设计与 YOLOE 的开放词汇学习范式相结合。核心架构改动是用对象嵌入头替换固定的类 Logits，将分类转化为与文本描述、视觉示例或内置词汇派生的提示嵌入的相似性匹配。为了实现高效的开放词汇推理，引入了 RepRTA (零开销文本提示)、SAVPE (示例引导分割) 和 Lazy Region Prompt Contrast (无提示推理)。所有提示模态都运行在统一的对象嵌入空间中。

Result: 实验证明，YOLOE-26 在不同模型尺寸下，无论是提示还是无提示设置下，都表现出一致的缩放行为和良好的精度-效率权衡。该训练策略兼容 Ultralytics 生态系统。

Conclusion: YOLOE-26 提供了一个实用且可扩展的解决方案，能够满足动态、真实世界环境中实时开放词汇实例分割的需求。

Abstract: This paper presents YOLOE-26, a unified framework that integrates the deployment-optimized YOLO26(or YOLOv26) architecture with the open-vocabulary learning paradigm of YOLOE for real-time open-vocabulary instance segmentation. Building on the NMS-free, end-to-end design of YOLOv26, the proposed approach preserves the hallmark efficiency and determinism of the YOLO family while extending its capabilities beyond closed-set recognition. YOLOE-26 employs a convolutional backbone with PAN/FPN-style multi-scale feature aggregation, followed by end-to-end regression and instance segmentation heads. A key architectural contribution is the replacement of fixed class logits with an object embedding head, which formulates classification as similarity matching against prompt embeddings derived from text descriptions, visual examples, or a built-in vocabulary. To enable efficient open-vocabulary reasoning, the framework incorporates Re-Parameterizable Region-Text Alignment (RepRTA) for zero-overhead text prompting, a Semantic-Activated Visual Prompt Encoder (SAVPE) for example-guided segmentation, and Lazy Region Prompt Contrast for prompt-free inference. All prompting modalities operate within a unified object embedding space, allowing seamless switching between text-prompted, visual-prompted, and fully autonomous segmentation. Extensive experiments demonstrate consistent scaling behavior and favorable accuracy-efficiency trade-offs across model sizes in both prompted and prompt-free settings. The training strategy leverages large-scale detection and grounding datasets with multi-task optimization and remains fully compatible with the Ultralytics ecosystem for training, validation, and deployment. Overall, YOLOE-26 provides a practical and scalable solution for real-time open-vocabulary instance segmentation in dynamic, real-world environments.

</details>


### [184] [Intra-Class Subdivision for Pixel Contrastive Learning: Application to Semi-supervised Cardiac Image Segmentation](https://arxiv.org/abs/2602.00174)
*Jiajun Zhao,Xuan Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为SPCL（亚类细分像素对比学习）的框架，用于心脏图像分割，旨在解决边界处的表征污染问题。通过引入“不关切样本”概念区分内部和边界像素表征，并设计边界对比损失来增强边界表征的区分度。实验证明SPCL在心脏数据集上显著提升了分割性能和边界精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在心脏图像分割中存在边界区域表征污染的问题，导致分割精度不足，特别是边界不够精确。

Method: 提出SPCL框架，引入“不关切样本”来区分同类中内部和边界区域的像素表征，并设计边界对比损失来增强边界表征的区分度。理论分析了“不关切样本”和边界对比损失的优势。

Result: SPCL在公开心脏数据集上的实验结果表明，与现有方法相比，SPCL在分割质量和边界精度方面均有显著提升。

Conclusion: SPCL框架能够有效解决心脏图像分割中的边界表征污染问题，通过引入“不关切样本”和边界对比损失，显著提高了分割性能和边界精确度。

Abstract: We propose an intra-class subdivision pixel contrastive learning (SPCL) framework for cardiac image segmentation to address representation contamination at boundaries. The novel concept ``Unconcerned sample'' is proposed to distinguish pixel representations at the inner and boundary regions within the same class, facilitating a clearer characterization of intra-class variations. A novel boundary contrastive loss for boundary representations is proposed to enhance representation discrimination across boundaries. The advantages of the unconcerned sample and boundary contrastive loss are analyzed theoretically. Experimental results in public cardiac datasets demonstrate that SPCL significantly improves segmentation performance, outperforming existing methods with respect to segmentation quality and boundary precision. Our code is available at https://github.com/Jrstud203/SPCL.

</details>


### [185] [Stabilizing Diffusion Posterior Sampling by Noise--Frequency Continuation](https://arxiv.org/abs/2602.00176)
*Feng Tian,Yixuan Li,Weili Zeng,Weitian Zhang,Yichao Yan,Xiaokang Yang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为“噪声-频率连续性”的新框架，用于改进基于扩散模型的逆问题求解方法，以解决现有方法在恢复细节方面存在的不足。该框架通过在不同噪声水平下，根据噪声大小调整测量一致性约束的频率范围，并结合多分辨率一致性策略，显著提升了超分辨率、图像修复和去模糊等任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的逆问题求解方法，虽然结合了预训练扩散先验和测量一致性引导，但在恢复精细细节方面表现不佳。主要原因是测量一致性项与扩散噪声水平的耦合不够紧密，导致在高噪声情况下，不准确的数据一致性梯度可能与后验几何结构不匹配，从而引发早期漂移、虚假高频伪影以及对噪声调度和病态算子的敏感性问题。

Method: 提出了“噪声-频率连续性”框架，该框架构建了一系列中间后验，其似然函数仅在噪声相关的频率带内强制执行测量一致性。具体实现上，采用了稳定的后验采样器，结合了扩散预测器、带限似然引导以及多分辨率一致性策略。该策略能够积极地采纳可靠的粗粒度校正，并在高频细节可识别时才保守地采用它们。

Result: 在超分辨率、图像修复和去模糊任务上，该方法取得了最先进的性能。特别是在运动去模糊任务上，与现有强有力基线方法相比，PSNR 提升了高达 5 dB。

Conclusion: 噪声-频率连续性框架通过将测量一致性约束与噪声水平和频率带相关联，并结合多分辨率策略，有效解决了现有扩散模型在逆问题求解中恢复细节的挑战，显著提升了各种图像恢复任务的性能。

Abstract: Diffusion posterior sampling solves inverse problems by combining a pretrained diffusion prior with measurement-consistency guidance, but it often fails to recover fine details because measurement terms are applied in a manner that is weakly coupled to the diffusion noise level. At high noise, data-consistency gradients computed from inaccurate estimates can be geometrically incongruent with the posterior geometry, inducing early-step drift, spurious high-frequency artifacts, plus sensitivity to schedules and ill-conditioned operators. To address these concerns, we propose a noise--frequency Continuation framework that constructs a continuous family of intermediate posteriors whose likelihood enforces measurement consistency only within a noise-dependent frequency band. This principle is instantiated with a stabilized posterior sampler that combines a diffusion predictor, band-limited likelihood guidance, and a multi-resolution consistency strategy that aggressively commits reliable coarse corrections while conservatively adopting high-frequency details only when they become identifiable. Across super-resolution, inpainting, and deblurring, our method achieves state-of-the-art performance and improves motion deblurring PSNR by up to 5 dB over strong baselines.

</details>


### [186] [CamReasoner: Reinforcing Camera Movement Understanding via Structured Spatial Reasoning](https://arxiv.org/abs/2602.00181)
*Hang Wu,Yujun Cai,Zehao Li,Haonan Ge,Bowen Sun,Junsong Yuan,Yiwei Wang*

Main category: cs.CV

TL;DR: CamReasoner 是一个通过结构化推理框架来理解相机运动的系统，使用 O-T-A 范式和强化学习，提高了准确性并减少了错误。


<details>
  <summary>Details</summary>
Motivation: 现有模型将相机运动理解视为黑盒分类，容易混淆物理上不同的运动，依赖于视觉模式而非几何线索。

Method: 提出了 CamReasoner 框架，采用 Observation-Thinking-Answer (O-T-A) 范式，通过显式的推理模块解码时空线索（如轨迹和视锥），并构建了包含 SFT 和 RL 样本的大规模推理轨迹套件，首次使用 RL 进行逻辑对齐。

Result: CamReasoner 有效抑制了幻觉，并在多个基准测试中取得了最先进的性能。

Conclusion: 通过将 RL 应用于 O-T-A 推理范式，CamReasoner 能够基于物理几何进行运动推理，而非依赖上下文猜测，从而提高了相机运动理解的准确性。

Abstract: Understanding camera dynamics is a fundamental pillar of video spatial intelligence. However, existing multimodal models predominantly treat this task as a black-box classification, often confusing physically distinct motions by relying on superficial visual patterns rather than geometric cues. We present CamReasoner, a framework that reformulates camera movement understanding as a structured inference process to bridge the gap between perception and cinematic logic. Our approach centers on the Observation-Thinking-Answer (O-T-A) paradigm, which compels the model to decode spatio-temporal cues such as trajectories and view frustums within an explicit reasoning block. To instill this capability, we construct a Large-scale Inference Trajectory Suite comprising 18k SFT reasoning chains and 38k RL feedback samples. Notably, we are the first to employ RL for logical alignment in this domain, ensuring motion inferences are grounded in physical geometry rather than contextual guesswork. By applying Reinforcement Learning to the Observation-Think-Answer (O-T-A) reasoning paradigm, CamReasoner effectively suppresses hallucinations and achieves state-of-the-art performance across multiple benchmarks.

</details>


### [187] [AI-Generated Image Detectors Overrely on Global Artifacts: Evidence from Inpainting Exchange](https://arxiv.org/abs/2602.00192)
*Elif Nebioglu,Emirhan Bilgiç,Adrian Popescu*

Main category: cs.CV

TL;DR: 研究提出了一种名为INP-X的新操作，用于识别深度学习图像修复中的全局伪影，并发现现有修复检测器对此类伪影的依赖性很高，导致其在INP-X干预后的准确率急剧下降。


<details>
  <summary>Details</summary>
Motivation: 现有图像修复检测器主要依赖全局伪影，而不是局部合成内容，这种依赖性使得它们容易被欺骗。研究人员希望找出并解决这个问题，以提高修复检测的可靠性。

Method: 研究人员提出了一种名为Inpainting Exchange (INP-X)的操作，该操作可以恢复未编辑区域的原始像素，同时保留编辑区域的合成内容。他们创建了一个包含90K图像的大型测试数据集，用于评估INP-X对现有修复检测器性能的影响。此外，他们还进行了理论分析，将观察到的行为与VAE信息瓶颈引起的高频衰减联系起来。

Result: 在INP-X干预下，预训练的最先进的修复检测器（包括商业检测器）的准确率急剧下降，从91%降至55%，甚至接近随机猜测水平。在INP-X数据集上训练的模型表现出比标准修复更好的泛化能力和定位能力。

Conclusion: 现有基于全局伪影的修复检测器存在严重缺陷，INP-X操作揭示了它们的脆弱性。研究强调了内容感知检测的必要性，并表明在INP-X数据集上训练的模型能提供更鲁棒的修复检测性能。

Abstract: Modern deep learning-based inpainting enables realistic local image manipulation, raising critical challenges for reliable detection. However, we observe that current detectors primarily rely on global artifacts that appear as inpainting side effects, rather than on locally synthesized content. We show that this behavior occurs because VAE-based reconstruction induces a subtle but pervasive spectral shift across the entire image, including unedited regions. To isolate this effect, we introduce Inpainting Exchange (INP-X), an operation that restores original pixels outside the edited region while preserving all synthesized content. We create a 90K test dataset including real, inpainted, and exchanged images to evaluate this phenomenon. Under this intervention, pretrained state-of-the-art detectors, including commercial ones, exhibit a dramatic drop in accuracy (e.g., from 91\% to 55\%), frequently approaching chance level. We provide a theoretical analysis linking this behavior to high-frequency attenuation caused by VAE information bottlenecks. Our findings highlight the need for content-aware detection. Indeed, training on our dataset yields better generalization and localization than standard inpainting. Our dataset and code are publicly available at https://github.com/emirhanbilgic/INP-X.

</details>


### [188] [Vision-Language Model Purified Semi-Supervised Semantic Segmentation for Remote Sensing Images](https://arxiv.org/abs/2602.00202)
*Shanwen Wang,Xin Sun,Danfeng Hong,Fei Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为SemiEarth的新型半监督语义分割模型，该模型利用视觉语言模型（VLMs）来改进遥感（RS）图像的伪标签质量，从而提升分割性能，并实现了可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的半监督语义分割（S4）方法在处理低质量伪标签时遇到挑战，尤其是在教师-学生框架中。遥感图像领域对高质量伪标签的需求尤为迫切，因此需要一种新的方法来解决这个问题。

Method: 提出了一种名为SemiEarth的模型，核心是引入了视觉语言模型（VLMs）来解决S4问题。具体来说，发明了一种视觉语言模型伪标签净化（VLM-PP）结构，用于净化教师网络的伪标签。VLM-PP能够识别并纠正与VLMs预测不符的低置信度伪标签，尤其关注多类别边界区域，从而指导学生模型进行更准确的学习。

Result: 在多个遥感数据集上进行了广泛的实验，结果表明SemiEarth达到了当前最先进（SOTA）的性能。与之前的SOTA方法相比，SemiEarth不仅性能优越，还提供了良好的可解释性。

Conclusion: SemiEarth模型通过引入VLM-PP结构，有效解决了遥感图像半监督语义分割中的伪标签质量问题，显著提升了分割性能，并实现了良好的模型可解释性，是遥感领域S4的一个重要进展。

Abstract: The semi-supervised semantic segmentation (S4) can learn rich visual knowledge from low-cost unlabeled images. However, traditional S4 architectures all face the challenge of low-quality pseudo-labels, especially for the teacher-student framework.We propose a novel SemiEarth model that introduces vision-language models (VLMs) to address the S4 issues for the remote sensing (RS) domain. Specifically, we invent a VLM pseudo-label purifying (VLM-PP) structure to purify the teacher network's pseudo-labels, achieving substantial improvements. Especially in multi-class boundary regions of RS images, the VLM-PP module can significantly improve the quality of pseudo-labels generated by the teacher, thereby correctly guiding the student model's learning. Moreover, since VLM-PP equips VLMs with open-world capabilities and is independent of the S4 architecture, it can correct mispredicted categories in low-confidence pseudo-labels whenever a discrepancy arises between its prediction and the pseudo-label. We conducted extensive experiments on multiple RS datasets, which demonstrate that our SemiEarth achieves SOTA performance. More importantly, unlike previous SOTA RS S4 methods, our model not only achieves excellent performance but also offers good interpretability. The code is released at https://github.com/wangshanwen001/SemiEarth.

</details>


### [189] [Interpretable Unsupervised Deformable Image Registration via Confidence-bound Multi-Hop Visual Reasoning](https://arxiv.org/abs/2602.00211)
*Zafar Iqbal,Anwar Ul Haq,Srimannarayana Grandhi*

Main category: cs.CV

TL;DR: 提出了一种名为VCoR（Multi-Hop Visual Chain of Reasoning）的无监督可变形图像配准新框架，通过多步迭代推理和注意力机制来提高准确性和可解释性，并能估计不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在无监督可变形图像配准方面缺乏透明度，导致错误累积且临床信任度降低。需要一种更具可解释性和可靠性的方法。

Method: 将配准视为一个渐进式推理过程，引入了多步（Multi-Hop）推理。每个推理步包含一个局部空间细化（LSR）模块和跨参考注意力（CRA）机制，以丰富特征表示并引导迭代细化，同时保持解剖一致性。通过评估变形场在不同推理步之间的稳定性和收敛性来估计不确定性。

Result: 在DIR-Lab 4D CT（肺部）和IXI T1加权MRI（大脑）数据集上的评估表明，VCoR在配准准确性上具有竞争力，并能提供丰富的中间可视化和置信度度量。

Conclusion: VCoR框架通过嵌入隐式的视觉推理范式，提供了一种可解释、可靠且临床上可行的无监督医学图像配准方法，能够处理大形变并提供不确定性估计。

Abstract: Unsupervised deformable image registration requires aligning complex anatomical structures without reference labels, making interpretability and reliability critical. Existing deep learning methods achieve considerable accuracy but often lack transparency, leading to error drift and reduced clinical trust. We propose a novel Multi-Hop Visual Chain of Reasoning (VCoR) framework that reformulates registration as a progressive reasoning process. Inspired by the iterative nature of clinical decision-making, each visual reasoning hop integrates a Localized Spatial Refinement (LSR) module to enrich feature representations and a Cross-Reference Attention (CRA) mechanism that leads the iterative refinement process, preserving anatomical consistency. This multi-hop strategy enables robust handling of large deformations and produces a transparent sequence of intermediate predictions with a theoretical bound. Beyond accuracy, our framework offers built-in interpretability by estimating uncertainty via the stability and convergence of deformation fields across hops. Extensive evaluations on two challenging public datasets, DIR-Lab 4D CT (lung) and IXI T1-weighted MRI (brain), demonstrate that VCoR achieves competitive registration accuracy while offering rich intermediate visualizations and confidence measures. By embedding an implicit visual reasoning paradigm, we present an interpretable, reliable, and clinically viable unsupervised medical image registration.

</details>


### [190] [Deep Learning Based CNN Model for Automated Detection of Pneumonia from Chest XRay Images](https://arxiv.org/abs/2602.00212)
*Sathish Krishna Anumula,Vetrivelan Tamilmani,Aniruddha Arjun Singh,Dinesh Rajendran,Venkata Deepak Namburi*

Main category: cs.CV

TL;DR: 本文提出了一种基于定制卷积神经网络（CNN）的统一自动化肺炎诊断模型，用于识别胸部X光图像中的肺炎，具有高精度和低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统依赖人工解读胸部X光片的肺炎诊断方法存在观察者间差异、专家疲劳和合格放射科医生短缺等限制，影响了诊断的速度和准确性，尤其是在资源匮乏地区对儿科和老年人群的危害更大。

Method: 研究人员设计了一个定制的卷积神经网络（CNN）架构，采用了深度可分离卷积设计，优化了灰度医学图像的纹理特征。同时，使用了对比度限制自适应直方图均衡化（CLAHE）和几何增强作为预处理技术，以解决类别不平衡问题并提高模型的泛化能力。模型在包含5863张前后位胸部X光片的公开数据集上进行了测试。

Result: 该自动化诊断模型在胸部X光图像中识别肺炎方面取得了高精度，并且计算成本极低。

Conclusion: 提出的统一自动化诊断模型能够有效地识别胸部X光图像中的肺炎，克服了传统方法的局限性，为快速准确的肺炎诊断提供了一种有前景的解决方案。

Abstract: Pneumonia has been one of the major causes of morbidities and mortality in the world and the prevalence of this disease is disproportionately high among the pediatric and elderly populations especially in resources trained areas Fast and precise diagnosis is a prerequisite for successful clinical intervention but due to inter observer variation fatigue among experts and a shortage of qualified radiologists traditional approaches that rely on manual interpretation of chest radiographs are frequently constrained To address these problems this paper introduces a unified automated diagnostic model using a custom Convolutional Neural Network CNN that can recognize pneumonia in chest Xray images with high precision and at minimal computational expense In contrast like other generic transfer learning based models which often possess redundant parameters the offered architecture uses a tailor made depth wise separable convolutional design which is optimized towards textural characteristics of grayscale medical images Contrast Limited Adaptive Histogram Equalization CLAHE and geometric augmentation are two significant preprocessing techniques used to ensure that the system does not experience class imbalance and is more likely to generalize The system is tested using a dataset of 5863 anterior posterior chest Xrays.

</details>


### [191] [A Geometric Multimodal Foundation Model Integrating Bp-MRI and Clinical Reports in Prostate Cancer Classification](https://arxiv.org/abs/2602.00214)
*Juan A. Olmos,Antoine Manzanera,Fabio Martínez*

Main category: cs.CV

TL;DR: 提出了一种名为MFM-Geom的几何多模态基础模型，结合了双参数MRI（bp-MRI）和临床报告，利用SPD矩阵和黎曼深度学习，以提高前列腺癌（PCa）的诊断准确性，并在数据稀缺的情况下展现出优越的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有计算机辅助诊断方法主要关注影像学模型，忽视了临床背景信息，并且面临数据稀缺问题，难以学习鲁棒的表示。本研究旨在克服这些限制，提高PCa的识别和治疗决策的准确性。

Method: 提出了一种几何多模态基础模型MFM-Geom，它从bp-MRI和临床报告中学习表示，编码视觉发现和临床变量的上下文信息。在表示分类头中，该方法利用对称正定（SPD）矩阵和黎曼深度学习来整合生物医学多模态基础模型中的影像-文本表示。

Result: 在仅使用10%训练数据的情况下，MFM-Geom在AUC-PR方面优于基线模型（+8.3%，AUC-PR为90.67%）。在外部数据集上的泛化能力也得到了验证，通过微调生物医学基础模型，实现了90.6%的AUC-PR。

Conclusion: MFM-Geom模型能够有效地整合bp-MRI和临床报告信息，利用SPD矩阵和黎曼深度学习，在数据稀缺的情况下，能够学习到鲁棒的表示，并在PCa诊断上展现出优越的性能和良好的泛化能力。

Abstract: Prostate cancer (PCa) is one of the most common cancers in men worldwide. Bi-parametric MRI (bp-MRI) and clinical variables are crucial for PCa identification and improving treatment decisions. However, this process is subjective to expert interpretations. Furthermore, most existing computer-aided diagnosis methods focus on imaging-based models, overlooking the clinical context and suffering from data scarcity, limiting their ability to learn robust representations. We propose a geometric multimodal Foundation Model (FM), named MFM-Geom, that learns representations from bp-MRI and clinical reports, encoding visual findings and information from the context of clinical variables. In the representations classification head, the approach leverages symmetric positive definite (SPD) matrices and Riemannian deep learning to integrate imaging-text representations from a biomedical multimodal FM. Using 10% of the training data, MFM-Geom outperformed baseline class token embedding-based classification (+8.3%, AUC-PR of 90.67). Generalization on external dataset confirmed the robustness of fine-tuning biomedical FM, achieving an AUC-PR of 90.6.

</details>


### [192] [SANEval: Open-Vocabulary Compositional Benchmarks with Failure-mode Diagnosis](https://arxiv.org/abs/2602.00249)
*Rishav Pramanik,Ian E. Nielsen,Jeff Smith,Saurav Pandit,Ravi P. Ramachandran,Zhaozheng Yin*

Main category: cs.CV

TL;DR: 本研究提出了SANEval，一个用于评估文本到图像模型在处理复杂指令（包括多对象、属性和空间关系）时组合生成能力的开放词汇基准和评估流程。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型的组合生成能力不足，且缺乏有效的评估方法，现有基准存在词汇受限、诊断能力不足和反馈不具可解释性等问题。

Method: 引入SANEval基准，结合大型语言模型（LLM）进行深度指令理解，并使用增强了LLM的开放词汇对象检测器来评估组合遵循度，不受固定词汇的限制。

Result: 通过在六个先进的文本到图像模型上的实验表明，SANEval的自动化评估比现有基准更能忠实地反映人类评估，在属性绑定、空间关系和数量任务上，其评估指标与人类评估的相关性显著优于现有基准。

Conclusion: SANEval是一个全面、可扩展的开放词汇组合评估基准，能够更准确地评估文本到图像模型的组合生成能力，并且将发布数据集和评估流程以促进未来研究。

Abstract: The rapid progress of text-to-image (T2I) models has unlocked unprecedented creative potential, yet their ability to faithfully render complex prompts involving multiple objects, attributes, and spatial relationships remains a significant bottleneck. Progress is hampered by a lack of adequate evaluation methods; current benchmarks are often restricted to closed-set vocabularies, lack fine-grained diagnostic capabilities, and fail to provide the interpretable feedback necessary to diagnose and remedy specific compositional failures. We solve these challenges by introducing SANEval (Spatial, Attribute, and Numeracy Evaluation), a comprehensive benchmark that establishes a scalable new pipeline for open-vocabulary compositional evaluation. SANEval combines a large language model (LLM) for deep prompt understanding with an LLM-enhanced, open-vocabulary object detector to robustly evaluate compositional adherence, unconstrained by a fixed vocabulary. Through extensive experiments on six state-of-the-art T2I models, we demonstrate that SANEval's automated evaluations provide a more faithful proxy for human assessment; our metric achieves a Spearman's rank correlation with statistically different results than those of existing benchmarks across tasks of attribute binding, spatial relations, and numeracy. To facilitate future research in compositional T2I generation and evaluation, we will release the SANEval dataset and our open-source evaluation pipeline.

</details>


### [193] [CAPA: Contribution-Aware Pruning and FFN Approximation for Efficient Large Vision-Language Models](https://arxiv.org/abs/2602.00247)
*Samyak Jha,Junho Kim*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CAPA（Contribution-Aware Pruning and FFN Approximation）的框架，通过基于注意力贡献来修剪视觉Token和近似前馈网络（FFN）来提高大型视觉语言模型的推理效率，并取得了更好的效率-性能权衡和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在推理时处理大量视觉Token的成本很高，但尚不清楚哪些Token和计算可以安全地移除。现有的基于注意力分数的方法被证明是估计视觉Token重要性的不完美代理。

Method: 研究者提出了“注意力贡献”（Attention Contribution）作为比注意力分数更准确的视觉Token重要性度量标准，该标准将注意力概率与其对应的Value向量的幅度相结合。通过分析发现，视觉注意力“sink”具有异质性，包含可安全修剪的“概率倾倒区”和对模型性能至关重要的“结构锚点”。此外，研究者还发现FFN在视觉Token相关计算中存在冗余，尤其是在图像Token表现出线性行为的中间层。基于这些发现，提出了CAPA框架，该框架结合了基于注意力贡献的视觉Token修剪策略和基于线性近似的前馈网络（FFN）计算缩减策略。

Result: CAPA框架在多个基准测试中表现出有效的效率-性能权衡，并提高了模型的鲁棒性。实验表明，通过注意力贡献修剪和FFN近似，可以显著降低模型的计算成本，同时保持甚至提高其性能。

Conclusion: 注意力贡献是一个比注意力分数更有效的视觉Token选择标准，能够区分可安全修剪的Token和关键的结构性Token。FFN中存在冗余，尤其是在中间层。CAPA框架通过结合这两种策略，能够有效地提高大型视觉语言模型的推理效率和鲁棒性。

Abstract: Efficient inference in Large Vision-Language Models is constrained by the high cost of processing thousands of visual tokens, yet it remains unclear which tokens and computations can be safely removed. While attention scores are commonly used to estimate visual token importance, they are an imperfect proxy for actual contribution. We show that Attention Contribution, which weights attention probabilities by value vector magnitude, provides a more accurate criterion for visual token selection. Our empirical analysis reveals that visual attention sinks are functionally heterogeneous, comprising Probability Dumps with low contribution that can be safely pruned, and Structural Anchors with high contribution essential for maintaining model performance. Further, we identify substantial redundancy in Feed-Forward Networks (FFNs) associated with visual tokens, particularly in intermediate layers where image tokens exhibit linear behavior. Based on our findings, we introduce CAPA (Contribution-Aware Pruning and FFN Approximation), a dual-strategy framework that prunes visual tokens using attention contribution at critical functional transitions and reduces FFN computation through efficient linear approximations. Experiments on various benchmarks across baselines show that CAPA achieves competent efficiency--performance trade-offs with improved robustness.

</details>


### [194] [Subspace Clustering on Incomplete Data with Self-Supervised Contrastive Learning](https://arxiv.org/abs/2602.00262)
*Huanran Li,Daniel Pimentel-Alarcón*

Main category: cs.CV

TL;DR: 提出了一种名为CSC（Contrastive Subspace Clustering）的对比自监督框架，用于聚类包含缺失值的数据。CSC通过生成数据的不同“视图”并使用对比损失来学习数据表示，然后对这些表示进行聚类。


<details>
  <summary>Details</summary>
Motivation: 现有子空间聚类方法大多假设数据是完整的，但在实际应用中数据常含有缺失值，这限制了现有方法的有效性。因此，需要一种能够处理不完整数据的聚类方法。

Method: 该研究提出了一种对比自监督框架CSC。该框架通过生成输入数据的“蒙版视图”（masked views），并利用类SimCLR的对比损失训练深度神经网络，学习不变性嵌入（invariant embeddings）。然后，利用稀疏子空间聚类（sparse subspace clustering）对学习到的嵌入进行聚类。

Result: 在六个基准数据集上的实验表明，CSC在聚类性能上始终优于传统的和深度学习的基线方法。CSC对缺失数据表现出很强的鲁棒性，并且能够有效地处理大规模数据集。

Conclusion: CSC是一种有效的处理不完整数据进行子空间聚类的对比自监督框架，在处理缺失数据和大规模数据集方面表现出优越的性能和鲁棒性。

Abstract: Subspace clustering aims to group data points that lie in a union of low-dimensional subspaces and finds wide application in computer vision, hyperspectral imaging, and recommendation systems. However, most existing methods assume fully observed data, limiting their effectiveness in real-world scenarios with missing entries. In this paper, we propose a contrastive self-supervised framework, Contrastive Subspace Clustering (CSC), designed for clustering incomplete data. CSC generates masked views of partially observed inputs and trains a deep neural network using a SimCLR-style contrastive loss to learn invariant embeddings. These embeddings are then clustered using sparse subspace clustering. Experiments on six benchmark datasets show that CSC consistently outperforms both classical and deep learning baselines, demonstrating strong robustness to missing data and scalability to large datasets.

</details>


### [195] [World-Shaper: A Unified Framework for 360° Panoramic Editing](https://arxiv.org/abs/2602.00265)
*Dong Liang,Yuhao Liu,Jinyuan Jia,Youjun Zhao,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: World-Shaper 是一个统一的、几何感知的框架，直接在等距柱状投影 (ERP) 域中进行全景图编辑，解决了现有方法的几何不一致性问题，并实现了更优的编辑保真度和文本可控性。


<details>
  <summary>Details</summary>
Motivation: 现有全景图编辑方法无法有效建模全景图的空间结构，或因与球形几何不匹配而破坏全局一致性。因此，需要一种直接在 ERP 域进行全景图编辑的几何感知方法。

Method: 采用“生成-再编辑”范式，首先通过可控全景图生成合成训练数据，然后进行监督编辑学习。引入几何感知学习策略，显式强制位置感知形状监督，并通过渐进式训练内化全景图先验，以解决几何失真问题。

Result: 在新的基准 PEBench 上进行的大量实验表明，World-Shaper 在几何一致性、编辑保真度和文本可控性方面优于现有最先进的方法。

Conclusion: World-Shaper 实现了统一的编辑控制，能够生成连贯且灵活的 360° 视觉世界，解决了现有全景图编辑方法的局限性。

Abstract: Being able to edit panoramic images is crucial for creating realistic 360° visual experiences. However, existing perspective-based image editing methods fail to model the spatial structure of panoramas. Conventional cube-map decompositions attempt to overcome this problem but inevitably break global consistency due to their mismatch with spherical geometry. Motivated by this insight, we reformulate panoramic editing directly in the equirectangular projection (ERP) domain and present World-Shaper, a unified geometry-aware framework that bridges panoramic generation and editing within a single editing-centric design. To overcome the scarcity of paired data, we adopt a generate-then-edit paradigm, where controllable panoramic generation serves as an auxiliary stage to synthesize diverse paired examples for supervised editing learning. To address geometric distortion, we introduce a geometry-aware learning strategy that explicitly enforces position-aware shape supervision and implicitly internalizes panoramic priors through progressive training. Extensive experiments on our new benchmark, PEBench, demonstrate that our method achieves superior geometric consistency, editing fidelity, and text controllability compared to SOTA methods, enabling coherent and flexible 360° visual world creation with unified editing control. Code, model, and data will be released at our project page: https://world-shaper-project.github.io/

</details>


### [196] [PLACID: Identity-Preserving Multi-Object Compositing via Video Diffusion with Synthetic Trajectories](https://arxiv.org/abs/2602.00267)
*Gemma Canet Tarrés,Manel Baradad,Francesc Moreno-Noguer,Yumeng Li*

Main category: cs.CV

TL;DR: 提出了一种名为PLACID的框架，用于将物体图像合成为高质量的多物体合成图，通过利用预训练的图像到视频扩散模型和创新的数据策展策略，提高了物体身份、背景和颜色保真度，并实现了更好的布局控制和视觉吸引力。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在工作室级多物体合成方面存在不足，如物体身份改变、物体遗漏或重复、布局不准确以及展示效果不佳。

Method: 利用预训练的图像到视频（I2V）扩散模型，通过文本控制来保持物体的一致性、身份和背景细节，并利用视频的时间先验。提出了一种新颖的数据策展策略，生成合成序列，使物体从随机位置平滑移动到目标位置，以匹配视频模型的训练数据。

Result: PLACID在多物体合成方面优于最先进的方法，在物体身份、背景和颜色保留方面表现更好，遗漏物体更少，生成的图像更具视觉吸引力。

Conclusion: PLACID框架通过结合I2V扩散模型的时间先验和精心策划的合成数据，有效地解决了当前多物体合成的挑战，实现了高质量、精确控制且视觉吸引力的合成结果。

Abstract: Recent advances in generative AI have dramatically improved photorealistic image synthesis, yet they fall short for studio-level multi-object compositing. This task demands simultaneous (i) near-perfect preservation of each item's identity, (ii) precise background and color fidelity, (iii) layout and design elements control, and (iv) complete, appealing displays showcasing all objects. However, current state-of-the-art models often alter object details, omit or duplicate objects, and produce layouts with incorrect relative sizing or inconsistent item presentations. To bridge this gap, we introduce PLACID, a framework that transforms a collection of object images into an appealing multi-object composite. Our approach makes two main contributions. First, we leverage a pretrained image-to-video (I2V) diffusion model with text control to preserve objects consistency, identities, and background details by exploiting temporal priors from videos. Second, we propose a novel data curation strategy that generates synthetic sequences where randomly placed objects smoothly move to their target positions. This synthetic data aligns with the video model's temporal priors during training. At inference, objects initialized at random positions consistently converge into coherent layouts guided by text, with the final frame serving as the composite image. Extensive quantitative evaluations and user studies demonstrate that PLACID surpasses state-of-the-art methods in multi-object compositing, achieving superior identity, background, and color preservation, with less omitted objects and visually appealing results.

</details>


### [197] [TokenTrim: Inference-Time Token Pruning for Autoregressive Long Video Generation](https://arxiv.org/abs/2602.00268)
*Ariel Shaulov,Eitan Shaar,Amit Edenzon,Lior Wolf*

Main category: cs.CV

TL;DR: 提出一种在推理时修正长视频生成中的时间漂移问题的方法，通过识别并移除不稳定的潜在 token 来防止错误累积。


<details>
  <summary>Details</summary>
Motivation: 长视频合成中的自回归生成方法存在严重的时间漂移问题，即误差随时间累积和放大。作者认为这并非模型容量不足，而是推理时错误传播所致，具体为不稳定的潜在 token 被错误地重复使用。

Method: 提出一种在推理时进行的方法，通过定义“不稳定 token”（与前一帧的潜在表示显著偏离的 token）来识别潜在的损坏或语义漂移。然后，将这些不稳定的潜在 token 从自回归上下文中移除，阻止它们影响后续的生成。

Result: 该方法显著提高了长时序视频生成的时间一致性，且无需修改模型架构、训练过程或离开潜在空间。

Conclusion: 通过在推理时识别并移除不稳定的潜在 token，可以有效缓解自回归视频生成中的时间漂移问题，从而实现更稳定的长视频合成。

Abstract: Auto-regressive video generation enables long video synthesis by iteratively conditioning each new batch of frames on previously generated content. However, recent work has shown that such pipelines suffer from severe temporal drift, where errors accumulate and amplify over long horizons. We hypothesize that this drift does not primarily stem from insufficient model capacity, but rather from inference-time error propagation. Specifically, we contend that drift arises from the uncontrolled reuse of corrupted latent conditioning tokens during auto-regressive inference. To correct this accumulation of errors, we propose a simple, inference-time method that mitigates temporal drift by identifying and removing unstable latent tokens before they are reused for conditioning. For this purpose, we define unstable tokens as latent tokens whose representations deviate significantly from those of the previously generated batch, indicating potential corruption or semantic drift. By explicitly removing corrupted latent tokens from the auto-regressive context, rather than modifying entire spatial regions or model parameters, our method prevents unreliable latent information from influencing future generation steps. As a result, it significantly improves long-horizon temporal consistency without modifying the model architecture, training procedure, or leaving latent space.

</details>


### [198] [TimeBlind: A Spatio-Temporal Compositionality Benchmark for Video LLMs](https://arxiv.org/abs/2602.00288)
*Baiqi Li,Kangyi Zhao,Ce Zhang,Chancharik Mitra,Jean de Dieu Nyandwi,Gedas Bertasius*

Main category: cs.CV

TL;DR: 本研究提出了TimeBlind，一个用于评估多模态大语言模型（MLLMs）在时空理解方面能力的新型基准测试。该基准测试通过最小对（minimal pairs）的视频对来诊断模型在识别原子事件、描述事件属性和推理事件相互依赖性方面的能力，发现当前最先进的MLLMs在时空理解方面表现不佳，严重依赖静态视觉线索而非真实的时间逻辑。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在处理静态语义方面表现出色，但在理解视频中的时间动态方面存在不足。因此，需要一个专门的诊断性基准来评估和提升MLLMs在细粒度时空理解方面的能力。

Method: TimeBlind基准测试采用认知科学的启发，将细粒度的时间理解分为三个层次：识别原子事件、表征事件属性和推理事件相互依赖性。它通过“最小对”范式，即视频对仅在时间结构上不同而静态视觉内容相同，并结合互补性问题来消除语言先验的影响，从而孤立地评估模型对时间结构的理解能力。对20个最先进的MLLMs在600个精心策划的实例（2400个视频-问题对）上进行了评估。

Result: 在TimeBlind基准测试上，即使是表现最好的MLLM，其区分视频对的实例准确率（Instance Accuracy）也仅为48.2%，远低于人类的98.2%。这表明当前最先进的模型在处理时空理解任务时，过度依赖静态视觉线索，缺乏真正的时序推理能力。

Conclusion: TimeBlind基准测试揭示了当前MLLMs在细粒度时空理解方面存在显著的局限性，它们倾向于利用静态视觉捷径而非深入理解时间动态。因此，TimeBlind是一个宝贵的诊断工具，有助于推动下一代视频理解技术的发展。

Abstract: Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI. Yet, while Multimodal Large Language Models (MLLMs) master static semantics, their grasp of temporal dynamics remains brittle. We present TimeBlind, a diagnostic benchmark for compositional spatio-temporal understanding. Inspired by cognitive science, TimeBlind categorizes fine-grained temporal understanding into three levels: recognizing atomic events, characterizing event properties, and reasoning about event interdependencies. Unlike benchmarks that conflate recognition with temporal reasoning, TimeBlind leverages a minimal-pairs paradigm: video pairs share identical static visual content but differ solely in temporal structure, utilizing complementary questions to neutralize language priors. Evaluating over 20 state-of-the-art MLLMs (e.g., GPT-5, Gemini 3 Pro) on 600 curated instances (2400 video-question pairs), reveals that the Instance Accuracy (correctly distinguishing both videos in a pair) of the best performing MLLM is only 48.2%, far below the human performance (98.2%). These results demonstrate that even frontier models rely heavily on static visual shortcuts rather than genuine temporal logic, positioning TimeBlind as a vital diagnostic tool for next-generation video understanding. Dataset and code are available at https://baiqi-li.github.io/timeblind_project/ .

</details>


### [199] [Computer Vision and Its Relationship to Cognitive Science: A perspective from Bayes Decision Theory](https://arxiv.org/abs/2602.00289)
*Alan Yuille,Daniel Kersten*

Main category: cs.CV

TL;DR: 本文从贝叶斯决策理论（BDT）的角度，探讨了计算机视觉与认知科学的关系，并介绍了贝叶斯方法和深度神经网络这两种主要方法。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉领域庞大复杂，作者旨在提供一个聚焦于理论框架的视角，以捕捉关键概念，并阐述计算机视觉与认知科学的关联。

Method: 文章基于贝叶斯决策理论（BDT），介绍了两种计算机视觉的实现方法：（1）贝叶斯方法，其概念与认知科学相关；（2）深度神经网络（DNN）方法，其成功推动了计算机视觉产业发展，并受到视觉腹侧通路分层结构的启发。作者通过分析BDT的优势和局限性来比较这两种方法。

Result: BDT框架能够关联并体现贝叶斯方法和DNN方法的各自优劣。同时，文章也指出了BDT本身的局限性，并为未来融合这两种方法的更丰富框架提供了方向。

Conclusion: 贝叶斯决策理论为理解和整合计算机视觉中的贝叶斯方法和深度神经网络方法提供了一个有价值的理论框架。通过认识到BDT的局限性，可以指导未来的研究方向，以期结合两者的优点，构建更强大的视觉系统。

Abstract: This document presents an introduction to computer vision, and its relationship to Cognitive Science, from the perspective of Bayes Decision Theory (Berger 1985). Computer vision is a vast and complex field, so this overview has a narrow scope and provides a theoretical lens which captures many key concepts. BDT is rich enough to include two different approaches: (i) the Bayesian viewpoint, which gives a conceptually attractive framework for vision with concepts that resonate with Cognitive Science (Griffiths et al., 2024), and (ii) the Deep Neural Network approach whose successes in the real world have made Computer Vision into a trillion-dollar industry and which is motivated by the hierarchical structure of the visual ventral stream. The BDT framework relates and captures the strengths and weakness of these two approaches and, by discussing the limitations of BDT, points the way to how they can be combined in a richer framework.

</details>


### [200] [Opportunistic Promptable Segmentation: Leveraging Routine Radiological Annotations to Guide 3D CT Lesion Segmentation](https://arxiv.org/abs/2602.00309)
*Samuel Church,Joshua D. Warner,Danyal Maqbool,Xin Tie,Junjie Hu,Meghan G. Lubner,Tyler J. Bradshaw*

Main category: cs.CV

TL;DR: 本研究提出了一种名为SAM2CT的自适应分割模型，能够将放射科医生在CT图像中提供的稀疏标注（如箭头和线段）转化为3D分割，从而克服了获取大量高质量3D分割数据的成本问题。SAM2CT在公开数据集上表现优于现有模型，并在临床应用中生成了87%的临床可接受的3D分割结果。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习模型在CT成像领域的发展受限于大规模、高质量、多样化的标注数据集，而手动进行3D分割标注成本高昂。放射科医生在日常工作中常提供稀疏标注（如箭头和线段），这些信息通常存储在PACS系统中，但未能得到充分利用。

Method: 提出了一种名为SAM2CT的自适应分割模型，该模型建立在SAM2模型之上，通过扩展提示编码器以支持箭头和线段输入，并引入针对3D医学体积优化的内存编码策略（Memory-Conditioned Memories, MCM）。该方法被称为“机会性自适应分割”（Opportunistic Promptable Segmentation）。

Result: 在公开病灶分割基准测试中，SAM2CT在箭头提示下实现了0.649的Dice相似系数，在线段提示下实现了0.757的Dice相似系数，优于现有自适应分割模型和同等训练基线。在临床PACS系统中预先存在的GSPS标注（N=60）的应用中，SAM2CT生成的3D分割在87%的病例中被放射科医生评为临床可接受或仅需微调。此外，SAM2CT在某些急诊科发现的零样本任务上表现出强大的性能。

Conclusion: SAM2CT模型能够有效地将放射科医生提供的稀疏标注转化为3D分割，为大规模挖掘历史GSPS标注以生成3D CT分割数据集提供了一种有前景且可扩展的方法。

Abstract: The development of machine learning models for CT imaging depends on the availability of large, high-quality, and diverse annotated datasets. Although large volumes of CT images and reports are readily available in clinical picture archiving and communication systems (PACS), 3D segmentations of critical findings are costly to obtain, typically requiring extensive manual annotation by radiologists. On the other hand, it is common for radiologists to provide limited annotations of findings during routine reads, such as line measurements and arrows, that are often stored in PACS as GSPS objects. We posit that these sparse annotations can be extracted along with CT volumes and converted into 3D segmentations using promptable segmentation models, a paradigm we term Opportunistic Promptable Segmentation. To enable this paradigm, we propose SAM2CT, the first promptable segmentation model designed to convert radiologist annotations into 3D segmentations in CT volumes. SAM2CT builds upon SAM2 by extending the prompt encoder to support arrow and line inputs and by introducing Memory-Conditioned Memories (MCM), a memory encoding strategy tailored to 3D medical volumes. On public lesion segmentation benchmarks, SAM2CT outperforms existing promptable segmentation models and similarly trained baselines, achieving Dice similarity coefficients of 0.649 for arrow prompts and 0.757 for line prompts. Applying the model to pre-existing GSPS annotations from a clinical PACS (N = 60), SAM2CT generates 3D segmentations that are clinically acceptable or require only minor adjustments in 87% of cases, as scored by radiologists. Additionally, SAM2CT demonstrates strong zero-shot performance on select Emergency Department findings. These results suggest that large-scale mining of historical GSPS annotations represents a promising and scalable approach for generating 3D CT segmentation datasets.

</details>


### [201] [LogicGaze: Benchmarking Causal Consistency in Visual Narratives via Counterfactual Verification](https://arxiv.org/abs/2602.00292)
*Rory Driscoll,Alexandros Christoforos,Chadbourne Davis*

Main category: cs.CV

TL;DR: 本文提出了一个名为LogicGaze的新基准框架，用于评估视觉语言模型（VLMs）在视觉证据基础上进行顺序推理的可靠性，并专门解决幻觉问题。该框架包含精心策划的数据集，通过引入视觉上矛盾但语言上合理的扰动来挑战模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在顺序推理能力方面有所提升，但其将推理链条与实际视觉证据进行关联并验证的可靠性尚未得到充分研究，特别是在处理幻觉问题时。研究旨在解决这一不足。

Method: 构建了一个名为LogicGaze的基准框架，该框架包含从ShareGPT4Video和Flickr30k数据集中提取的40,000个视频片段。框架整合了因果序列和视觉上矛盾但语言上合理的扰动，以强制模型验证每个推理步骤的真实性。评估协议包括因果验证、接地叙事合成和扰动拒绝三部分。

Result: 对最先进的VLMs（如Qwen2.5-VL-72B）的评估暴露了它们在逻辑推理和视觉证据验证方面存在的显著漏洞。

Conclusion: LogicGaze基准框架强调了开发稳健、可信赖的多模态推理模型的重要性。该框架及其所有资源已公开可用，以促进相关研究。

Abstract: While sequential reasoning enhances the capability of Vision-Language Models (VLMs) to execute complex multimodal tasks, their reliability in grounding these reasoning chains within actual visual evidence remains insufficiently explored. We introduce LogicGaze, a novel benchmark framework designed to rigorously interrogate whether VLMs can validate sequential causal chains against visual inputs, specifically targeting the pervasive issue of hallucination. Curated from 40,000 video segments from ShareGPT4Video and a subset of Flickr30k imagery, LogicGaze integrates causal sequences with visually contradictory yet linguistically plausible perturbations, compelling models to verify the authenticity of each reasoning step. Our tripartite evaluation protocol - Causal Validation, Grounded Narrative Synthesis, and Perturbation Rejection - exposes significant vulnerabilities in state-of-the-art VLMs such as Qwen2.5-VL-72B. LogicGaze advocates for robust, trustworthy multimodal reasoning, with all resources publicly available in an anonymized repository.

</details>


### [202] [On the Assessment of Sensitivity of Autonomous Vehicle Perception](https://arxiv.org/abs/2602.00314)
*Apostol Vassilev,Munawar Hasan,Edward Griffor,Honglan Jin,Pavel Piliptchak,Mahima Arora,Thoshitha Gamage*

Main category: cs.CV

TL;DR: 本研究提出了一种基于模型集成和预测敏感性量化的方法，用于评估自动驾驶感知系统的鲁棒性，特别是在恶劣天气、光照不足和物体遮挡等挑战性场景下。实验表明，光照不足对模型性能影响最大，恶劣道路条件结合天气状况会显著降低性能，物体距离越远，感知鲁棒性越差。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车的可靠性高度依赖于感知系统的实时准确性和可靠性。感知系统不仅要在理想条件下运行，还必须应对各种自然和对抗性的驾驶干扰，这些干扰会导致感知错误和延迟。因此，评估和提高自动驾驶汽车感知系统的鲁棒性至关重要。

Method: 研究人员提出了一种基于模型集成和预测敏感性量化的感知评估方法。该方法通过捕获多个模型之间的不一致性和推理变异性，来评估感知系统在不同驾驶场景下的性能。他们还提出了一个用于评估感知性能的架构，并开发了一个基于车辆在不同路面（干、湿沥青）和速度下通过停止标志的停车距离的感知评估标准。实验使用了 YOLO (v8-v9)、DETR (DETR50, DETR101) 和 RT-DETR 等五种先进的计算机视觉模型。

Result: 研究发现，光照不足（如雾和低太阳高度角）对感知模型性能影响最大。对抗性的道路条件（如物体遮挡）会增加感知敏感性。当结合恶劣的道路条件和恶劣的天气条件时，模型性能会进一步下降。此外，研究还表明，物体距离越远，对感知性能的影响越大，感知鲁棒性随之降低。

Conclusion: 本研究提出了一种有效的感知鲁棒性评估框架，并证明了恶劣天气、光照不足和物体遮挡等因素对自动驾驶感知系统性能的显著负面影响。研究结果强调了在设计和部署自动驾驶系统时，必须充分考虑并解决这些挑战，以确保其在各种真实世界条件下的安全性和可靠性。

Abstract: The viability of automated driving is heavily dependent on the performance of perception systems to provide real-time accurate and reliable information for robust decision-making and maneuvers. These systems must perform reliably not only under ideal conditions, but also when challenged by natural and adversarial driving factors. Both of these types of interference can lead to perception errors and delays in detection and classification. Hence, it is essential to assess the robustness of the perception systems of automated vehicles (AVs) and explore strategies for making perception more reliable. We approach this problem by evaluating perception performance using predictive sensitivity quantification based on an ensemble of models, capturing model disagreement and inference variability across multiple models, under adverse driving scenarios in both simulated environments and real-world conditions. A notional architecture for assessing perception performance is proposed. A perception assessment criterion is developed based on an AV's stopping distance at a stop sign on varying road surfaces, such as dry and wet asphalt, and vehicle speed. Five state-of-the-art computer vision models are used, including YOLO (v8-v9), DEtection TRansformer (DETR50, DETR101), Real-Time DEtection TRansformer (RT-DETR)in our experiments. Diminished lighting conditions, e.g., resulting from the presence of fog and low sun altitude, have the greatest impact on the performance of the perception models. Additionally, adversarial road conditions such as occlusions of roadway objects increase perception sensitivity and model performance drops when faced with a combination of adversarial road conditions and inclement weather conditions. Also, it is demonstrated that the greater the distance to a roadway object, the greater the impact on perception performance, hence diminished perception robustness.

</details>


### [203] [Bridging the Semantic Chasm: Synergistic Conceptual Anchoring for Generalized Few-Shot and Zero-Shot OOD Perception](https://arxiv.org/abs/2602.00340)
*Alexandros Christoforos,Sarah Jenkins,Michael Brown,Tuan Pham,David Chen*

Main category: cs.CV

TL;DR: 提出了一种名为 SynerNet 的新框架，通过四个协同工作的计算单元来解决视觉语言模型 (VLMs) 在处理分布外 (OOD) 概念时出现的跨模态对齐退化问题，并在 VISTA-Beyond 基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 旨在解决视觉语言模型 (VLMs) 在处理分布外 (OOD) 概念时出现的跨模态对齐退化问题。

Method: 提出 SynerNet 框架，包含视觉感知、语言上下文、标称嵌入和全局协调四个计算单元，通过结构化的消息传播协议来纠正模态差异。主要贡献包括多智能体潜在空间命名获取框架、用于增强少样本适应性的语义上下文交换算法以及自适应动态平衡机制。

Result: 在 VISTA-Beyond 基准测试的少样本和零样本场景下，SynerNet 实现了显著的性能提升，在多个领域精度提高了 1.2% 到 5.4%。

Conclusion: SynerNet 框架能够有效地缓解 VLMs 在 OOD 概念下的跨模态对齐退化，并在少样本和零样本学习任务中取得优越性能。

Abstract: This manuscript presents a pioneering Synergistic Neural Agents Network (SynerNet) framework designed to mitigate the phenomenon of cross-modal alignment degeneration in Vision-Language Models (VLMs) when encountering Out-of-Distribution (OOD) concepts. Specifically, four specialized computational units - visual perception, linguistic context, nominal embedding, and global coordination - collaboratively rectify modality disparities via a structured message-propagation protocol. The principal contributions encompass a multi-agent latent space nomenclature acquisition framework, a semantic context-interchange algorithm for enhanced few-shot adaptation, and an adaptive dynamic equilibrium mechanism. Empirical evaluations conducted on the VISTA-Beyond benchmark demonstrate that SynerNet yields substantial performance augmentations in both few-shot and zero-shot scenarios, exhibiting precision improvements ranging from 1.2% to 5.4% across a diverse array of domains.

</details>


### [204] [When RAG Hurts: Diagnosing and Mitigating Attention Distraction in Retrieval-Augmented LVLMs](https://arxiv.org/abs/2602.00344)
*Beidi Zhao,Wenlong Deng,Xinting Liao,Yushu Li,Nazim Shaikh,Yao Nie,Xiaoxiao Li*

Main category: cs.CV

TL;DR: 提出MAD-RAG方法，通过双问题和注意力混合来解决检索增强生成（RAG）在视觉问答任务中因检索文本分散视觉注意力导致的模型性能下降问题，并在多项数据集上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG方法在处理知识密集型视觉问答任务时，存在检索文本分散视觉注意力，导致模型即使在有足够检索信息时也无法正确回答问题（注意力分散 AD），而之前的研究未发现此问题。

Method: 提出MAD-RAG，一种训练无关的干预方法。通过双问题（一个用于结合检索信息，一个用于保留视觉基础）解耦视觉基础与上下文整合，并结合注意力混合以保留图像条件证据。

Result: 在OK-VQA、E-VQA和InfoSeek数据集上，MAD-RAG相比于基础RAG模型，在不同模型家族上均取得了持续的性能提升，绝对增幅分别高达4.76%、9.20%和6.18%。MAD-RAG能纠正高达74.68%的失败案例，且计算开销可忽略不计。

Conclusion: MAD-RAG能够有效缓解RAG方法中因检索文本分散视觉注意力而导致的性能下降问题，并在多项视觉问答基准测试中展示了优越性，且计算效率高。

Abstract: While Retrieval-Augmented Generation (RAG) is one of the dominant paradigms for enhancing Large Vision-Language Models (LVLMs) on knowledge-based VQA tasks, recent work attributes RAG failures to insufficient attention towards the retrieved context, proposing to reduce the attention allocated to image tokens. In this work, we identify a distinct failure mode that previous study overlooked: Attention Distraction (AD). When the retrieved context is sufficient (highly relevant or including the correct answer), the retrieved text suppresses the visual attention globally, and the attention on image tokens shifts away from question-relevant regions. This leads to failures on questions the model could originally answer correctly without the retrieved text. To mitigate this issue, we propose MAD-RAG, a training-free intervention that decouples visual grounding from context integration through a dual-question formulation, combined with attention mixing to preserve image-conditioned evidence. Extensive experiments on OK-VQA, E-VQA, and InfoSeek demonstrate that MAD-RAG consistently outperforms existing baselines across different model families, yielding absolute gains of up to 4.76%, 9.20%, and 6.18% over the vanilla RAG baseline. Notably, MAD-RAG rectifies up to 74.68% of failure cases with negligible computational overhead.

</details>


### [205] [AdaFuse: Adaptive Multimodal Fusion for Lung Cancer Risk Prediction via Reinforcement Learning](https://arxiv.org/abs/2602.00347)
*Chongyu Qu,Zhengyi Lu,Yuxiang Lai,Thomas Z. Li,Junchao Zhu,Junlin Guo,Juming Xiong,Yanfan Zhu,Yuechen Yang,Allen J. Luna,Kim L. Sandler,Bennett A. Landman,Yuankai Huo*

Main category: cs.CV

TL;DR: 本文提出了一种基于强化学习的自适应多模态融合框架AdaFuse，用于肺癌风险预测。AdaFuse能够为每位患者学习个性化的模态选择和融合策略，实现更高效、准确的诊断。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常平等地处理所有模态或学习固定的权重，但并未解决在特定患者情况下是否应该使用某些模态的问题。研究的动机是开发一种能够根据患者具体情况自适应地选择和融合模态的方法。

Method: AdaFuse将多模态融合视为一个序贯决策过程，利用强化学习中的策略网络迭代地决定是否引入新模态或基于已有信息进行预测。这种方法允许模型根据已获取的信息进行条件化选择，并在信息足够时提前终止。

Result: 在NLST数据集上的实验表明，AdaFuse取得了最高的AUC（0.762），优于单一模态基线（0.732）、固定融合策略（0.759）和自适应基线DynMM（0.754）和MoE（0.742）。此外，AdaFuse使用的计算量（FLOPs）少于所有三模态方法。

Conclusion: 研究证明了强化学习在医学影像个性化多模态融合中的潜力，预示着从统一融合策略向自适应诊断流程的转变，这种流程能够学习何时咨询附加模态以及何时现有信息足以进行准确预测。

Abstract: Multimodal fusion has emerged as a promising paradigm for disease diagnosis and prognosis, integrating complementary information from heterogeneous data sources such as medical images, clinical records, and radiology reports. However, existing fusion methods process all available modalities through the network, either treating them equally or learning to assign different contribution weights, leaving a fundamental question unaddressed: for a given patient, should certain modalities be used at all? We present AdaFuse, an adaptive multimodal fusion framework that leverages reinforcement learning (RL) to learn patient-specific modality selection and fusion strategies for lung cancer risk prediction. AdaFuse formulates multimodal fusion as a sequential decision process, where the policy network iteratively decides whether to incorporate an additional modality or proceed to prediction based on the information already acquired. This sequential formulation enables the model to condition each selection on previously observed modalities and terminate early when sufficient information is available, rather than committing to a fixed subset upfront. We evaluate AdaFuse on the National Lung Screening Trial (NLST) dataset. Experimental results demonstrate that AdaFuse achieves the highest AUC (0.762) compared to the best single-modality baseline (0.732), the best fixed fusion strategy (0.759), and adaptive baselines including DynMM (0.754) and MoE (0.742), while using fewer FLOPs than all triple-modality methods. Our work demonstrates the potential of reinforcement learning for personalized multimodal fusion in medical imaging, representing a shift from uniform fusion strategies toward adaptive diagnostic pipelines that learn when to consult additional modalities and when existing information suffices for accurate prediction.

</details>


### [206] [MASC: Metal-Aware Sampling and Correction via Reinforcement Learning for Accelerated MRI](https://arxiv.org/abs/2602.00348)
*Zhengyi Lu,Ming Lu,Chongyu Qu,Junchao Zhu,Junlin Guo,Marilyn Lionts,Yanfan Zhu,Yuechen Yang,Tianyuan Yao,Jayasai Rajagopal,Bennett Allan Landman,Xiao Wang,Xinqiang Yan,Yuankai Huo*

Main category: cs.CV

TL;DR: 本文提出了一种名为MASC的统一框架，利用强化学习联合优化金属伪影减少（MAR）和加速MRI采集，通过模拟数据训练，实现了比传统方法更好的成像质量和效率。


<details>
  <summary>Details</summary>
Motivation: 金属植入物在MRI成像中会产生严重的伪影，影响图像质量和临床诊断，而传统的MAR和加速MRI是分开处理的，这促使研究者们寻求一种联合优化的方法。

Method: MASC框架采用强化学习，具体是Proximal Policy Optimization (PPO) 算法，将主动MRI采集视为一个序贯决策问题。一个伪影感知的PPO代理学习在有限的采集预算下选择k空间相位编码线。代理在经过U-Net MAR网络处理的欠采样重建图上运行，学习最大化重建质量的模式。该框架还采用了端到端训练方案，使采集策略学习到的k空间线能够最好地支持伪影去除，同时MAR网络也适应由此产生的欠采样模式。为了监督训练，使用物理模拟生成了带有金属植入物的幻影的k空间数据和重建图。

Result: 实验结果表明，MASC学习到的采集策略优于传统的采样策略。与使用冻结预训练MAR网络的相比，端到端训练提高了性能，验证了联合优化的优势。在FastMRI数据集上进行的跨数据集实验（包含物理伪影模拟）进一步证实了该方法能够泛化到真实的临床MRI数据。

Conclusion: MASC框架能够有效地联合优化MRI的金属伪影减少和加速采集，通过强化学习和端到端训练，显著提高了成像质量，并且在真实临床数据上表现出良好的泛化能力。

Abstract: Metal implants in MRI cause severe artifacts that degrade image quality and hinder clinical diagnosis. Traditional approaches address metal artifact reduction (MAR) and accelerated MRI acquisition as separate problems. We propose MASC, a unified reinforcement learning framework that jointly optimizes metal-aware k-space sampling and artifact correction for accelerated MRI. To enable supervised training, we construct a paired MRI dataset using physics-based simulation, generating k-space data and reconstructions for phantoms with and without metal implants. This paired dataset provides simulated 3D MRI scans with and without metal implants, where each metal-corrupted sample has an exactly matched clean reference, enabling direct supervision for both artifact reduction and acquisition policy learning. We formulate active MRI acquisition as a sequential decision-making problem, where an artifact-aware Proximal Policy Optimization (PPO) agent learns to select k-space phase-encoding lines under a limited acquisition budget. The agent operates on undersampled reconstructions processed through a U-Net-based MAR network, learning patterns that maximize reconstruction quality. We further propose an end-to-end training scheme where the acquisition policy learns to select k-space lines that best support artifact removal while the MAR network simultaneously adapts to the resulting undersampling patterns. Experiments demonstrate that MASC's learned policies outperform conventional sampling strategies, and end-to-end training improves performance compared to using a frozen pre-trained MAR network, validating the benefit of joint optimization. Cross-dataset experiments on FastMRI with physics-based artifact simulation further confirm generalization to realistic clinical MRI data. The code and models of MASC have been made publicly available: https://github.com/hrlblab/masc

</details>


### [207] [ReLAPSe: Reinforcement-Learning-trained Adversarial Prompt Search for Erased concepts in unlearned diffusion models](https://arxiv.org/abs/2602.00350)
*Ignacy Kolton,Kacper Marzol,Paweł Batorski,Marcin Mazur,Paul Swoboda,Przemysław Spurek*

Main category: cs.CV

TL;DR: 本文提出了一种名为ReLAPSe的基于强化学习的框架，用于从文本到图像的扩散模型中恢复被机器学习算法移除的视觉概念，效率高且可扩展。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习移除算法（machine unlearning）在从文本到图像的扩散模型中移除概念后，仍然会留下潜在的视觉信息，而现有的利用这些信息泄露的方法存在计算成本高或缺乏直接反馈的缺点。

Method: ReLAPSe将概念恢复视为一个强化学习问题，训练一个智能体，利用扩散模型的噪声预测损失作为可验证的奖励信号，并通过闭环设计直接将文本提示操作与潜在视觉残差对齐，从而学习可迁移的恢复策略。

Result: ReLAPSe能够高效地、近乎实时地恢复细粒度的身份和风格，并且在多种先进的机器学习移除方法上表现出可迁移性。

Conclusion: ReLAPSe通过将从单实例优化转向全局策略学习，为验证机器学习移除效果提供了一个可扩展的工具，能够有效且高效地检测扩散模型中残留的视觉信息。

Abstract: Machine unlearning is a key defense mechanism for removing unauthorized concepts from text-to-image diffusion models, yet recent evidence shows that latent visual information often persists after unlearning. Existing adversarial approaches for exploiting this leakage are constrained by fundamental limitations: optimization-based methods are computationally expensive due to per-instance iterative search. At the same time, reasoning-based and heuristic techniques lack direct feedback from the target model's latent visual representations. To address these challenges, we introduce ReLAPSe, a policy-based adversarial framework that reformulates concept restoration as a reinforcement learning problem. ReLAPSe trains an agent using Reinforcement Learning with Verifiable Rewards (RLVR), leveraging the diffusion model's noise prediction loss as a model-intrinsic and verifiable feedback signal. This closed-loop design directly aligns textual prompt manipulation with latent visual residuals, enabling the agent to learn transferable restoration strategies rather than optimizing isolated prompts. By pioneering the shift from per-instance optimization to global policy learning, ReLAPSe achieves efficient, near-real-time recovery of fine-grained identities and styles across multiple state-of-the-art unlearning methods, providing a scalable tool for rigorous red-teaming of unlearned diffusion models. Some experimental evaluations involve sensitive visual concepts, such as nudity. Code is available at https://github.com/gmum/ReLaPSe

</details>


### [208] [Modeling Image-Caption Rating from Comparative Judgments](https://arxiv.org/abs/2602.00381)
*Kezia Minni,Qiang Zhang,Monoshiz Mahbub Khan,Zhe Yu*

Main category: cs.CV

TL;DR: 本文提出了一种基于比较学习的图像描述字幕准确性评估方法，以替代耗时且主观的人工评分。该方法通过训练模型对字幕进行相对排序，并在VITR数据集上进行了实验验证，结果表明比较学习模型在数据量增加时性能接近回归基线，且人工评估显示比较标注效率更高、一致性更好。


<details>
  <summary>Details</summary>
Motivation: 人类对图像描述字幕的准确性进行直接评分既耗时又主观。而让人们比较两个字幕哪个更符合图像则相对容易。因此，研究者希望找到一种机器学习方法来模拟这种比较判断，以降低人工标注成本并提高评估效率。

Method: 本文提出了一种比较学习框架，不直接进行评分，而是学习如何对字幕进行比较排序。使用VITR数据集，提取图像的视觉特征（ResNet-50）和字幕的文本特征（MiniLM）。然后，训练一个回归模型和一个比较学习模型。此外，还进行了一项小规模人类评估研究，比较了绝对评分、配对比较和同图像比较三种标注方式。

Result: 在VITR数据集上，回归模型取得了更好的性能（Pearson's ρ: 0.7609, Spearman's rs: 0.7089）。然而，比较学习模型随着数据量的增加，性能稳步提升，并逐渐接近回归基线。人类评估研究表明，比较标注方式比绝对评分更快，且annotator之间的一致性更高。

Conclusion: 比较学习框架能够有效地模拟人类的偏好，并显著降低人工标注成本。尽管在小规模数据集上其性能可能不如直接回归模型，但其在处理大量数据和降低标注成本方面的潜力巨大，为图像字幕评估提供了一种有前景的替代方案。

Abstract: Rating the accuracy of captions in describing images is time-consuming and subjective for humans. In contrast, it is often easier for people to compare two captions and decide which one better matches a given image. In this work, we propose a machine learning framework that models such comparative judgments instead of direct ratings. The model can then be applied to rank unseen image-caption pairs in the same way as a regression model trained on direct ratings. Using the VICR dataset, we extract visual features with ResNet-50 and text features with MiniLM, then train both a regression model and a comparative learning model. While the regression model achieves better performance (Pearson's $ρ$: 0.7609 and Spearman's $r_s$: 0.7089), the comparative learning model steadily improves with more data and approaches the regression baseline. In addition, a small-scale human evaluation study comparing absolute rating, pairwise comparison, and same-image comparison shows that comparative annotation yields faster results and has greater agreement among human annotators. These results suggest that comparative learning can effectively model human preferences while significantly reducing the cost of human annotations.

</details>


### [209] [Robust automatic brain vessel segmentation in 3D CTA scans using dynamic 4D-CTA data](https://arxiv.org/abs/2602.00391)
*Alberto Mario Ceballos-Arroyo,Shrikanth M. Yadav,Chu-Hsuan Lin,Jisoo Kim,Geoffrey S. Young,Huaizu Jiang,Lei Qin*

Main category: cs.CV

TL;DR: 本研究提出了一种利用动态 4D-CTA 头部扫描进行脑血管标注的新方法，通过时间点相减去除骨骼和软组织，从而增强血管可视化。该方法利用增强的数据集训练深度学习模型，显著提高了脑血管分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 手动标注脑血管耗时耗力，需要一种更有效的方法来提高脑血管分割的准确性和效率。

Method: 通过动态 4D-CTA 成像，利用不同时间点的图像相减技术来增强血管可视化，减少骨骼和软组织干扰。然后，将此方法生成的标注作为真实标签，训练深度学习模型，并利用多时间点增强数据，将数据集扩大 4-5 倍。

Result: 在 TopBrain 数据集上，使用本研究方法训练的 nnUNet 模型在动脉和静脉分割方面均取得了显著优于现有方法的性能。动脉平均 mDC 达到 0.846，静脉为 0.957。平均定向 Hausdorff 距离（adHD）和拓扑敏感性（tSens）指标也显示了低误差和高敏感性，表明在捕获血管形态方面具有出色的准确性。

Conclusion: 本研究开发的新型标注方法能有效提高脑血管分割的准确性，该方法具有鲁棒性，并且训练出的深度学习模型在公开数据集上表现出优越性能。研究代码和模型权重已公开。

Abstract: In this study, we develop a novel methodology for annotating the brain vasculature using dynamic 4D-CTA head scans. By using multiple time points from dynamic CTA acquisitions, we subtract bone and soft tissue to enhance the visualization of arteries and veins, reducing the effort required to obtain manual annotations of brain vessels. We then train deep learning models on our ground truth annotations by using the same segmentation for multiple phases from the dynamic 4D-CTA collection, effectively enlarging our dataset by 4 to 5 times and inducing robustness to contrast phases. In total, our dataset comprises 110 training images from 25 patients and 165 test images from 14 patients. In comparison with two similarly-sized datasets for CTA-based brain vessel segmentation, a nnUNet model trained on our dataset can achieve significantly better segmentations across all vascular regions, with an average mDC of 0.846 for arteries and 0.957 for veins in the TopBrain dataset. Furthermore, metrics such as average directed Hausdorff distance (adHD) and topology sensitivity (tSens) reflected similar trends: using our dataset resulted in low error margins (aDHD of 0.304 mm for arteries and 0.078 for veins) and high sensitivity (tSens of 0.877 for arteries and 0.974 for veins), indicating excellent accuracy in capturing vessel morphology. Our code and model weights are available online: https://github.com/alceballosa/robust-vessel-segmentation

</details>


### [210] [Deep Learning-Based Object Detection for Autonomous Vehicles: A Comparative Study of One-Stage and Two-Stage Detectors on Basic Traffic Objects](https://arxiv.org/abs/2602.00385)
*Bsher Karbouj,Adam Michael Altenbuchner,Joerg Krueger*

Main category: cs.CV

TL;DR: 本文比较了 YOLOv5 和 Faster R-CNN 两种目标检测模型在自动驾驶场景下的性能。YOLOv5 在 mAP、召回率和训练效率上表现更优，特别是在数据集和图像分辨率较大时。Faster R-CNN 在检测小型、远距离物体以及在复杂光照条件下表现更好。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要精确的目标检测能力，但现有深度学习模型（如 YOLO、SSD、Faster R-CNN）在适用于特定自动驾驶场景方面的指导信息有限。选择合适的方法对系统性能、鲁棒性和效率至关重要。

Method: 对 YOLOv5（单阶段检测器）和 Faster R-CNN（双阶段检测器）进行了全面的实验分析。在结合了真实和合成图像的混合数据集上，使用 mAP、召回率和推理速度等指标进行评估。还分析了不同置信度阈值和各种真实场景下的模型行为。

Result: YOLOv5 在 mAP、召回率和训练效率方面表现出更优越的性能，尤其是在数据集大小和图像分辨率增加时。Faster R-CNN 在检测小型、远距离物体方面以及在挑战性光照条件下表现出优势。

Conclusion: YOLOv5 和 Faster R-CNN 在自动驾驶目标检测方面各有优劣。YOLOv5 在整体性能和效率上更具优势，而 Faster R-CNN 在处理特定挑战性情况（如小物体的检测和光照变化）时更具潜力。研究结果为自动驾驶系统选择合适的目标检测模型提供了重要参考。

Abstract: Object detection is a crucial component in autonomous vehicle systems. It enables the vehicle to perceive and understand its environment by identifying and locating various objects around it. By utilizing advanced imaging and deep learning techniques, autonomous vehicle systems can rapidly and accurately identify objects based on their features. Different deep learning methods vary in their ability to accurately detect and classify objects in autonomous vehicle systems. Selecting the appropriate method significantly impacts system performance, robustness, and efficiency in real-world driving scenarios. While several generic deep learning architectures like YOLO, SSD, and Faster R-CNN have been proposed, guidance on their suitability for specific autonomous driving applications is often limited. The choice of method affects detection accuracy, processing speed, environmental robustness, sensor integration, scalability, and edge case handling. This study provides a comprehensive experimental analysis comparing two prominent object detection models: YOLOv5 (a one-stage detector) and Faster R-CNN (a two-stage detector). Their performance is evaluated on a diverse dataset combining real and synthetic images, considering various metrics including mean Average Precision (mAP), recall, and inference speed. The findings reveal that YOLOv5 demonstrates superior performance in terms of mAP, recall, and training efficiency, particularly as dataset size and image resolution increase. However, Faster R-CNN shows advantages in detecting small, distant objects and performs well in challenging lighting conditions. The models' behavior is also analyzed under different confidence thresholds and in various real-world scenarios, providing insights into their applicability for autonomous driving systems.

</details>


### [211] [Brazilian Portuguese Image Captioning with Transformers: A Study on Cross-Native-Translated Dataset](https://arxiv.org/abs/2602.00393)
*Gabriel Bromonschenkel,Alessandro L. Koerich,Thiago M. Paixão,Hilário Tomaz Alves de Oliveira*

Main category: cs.CV

TL;DR: 本研究提出了一种跨原生翻译的 Transformer 模型评估方法，用于巴西葡萄牙语的图像描述生成，发现 Swin-DistilBERTimbau 表现最佳，ViTucano 在传统指标上优于大型多语言模型，而 GPT-4 在 CLIP-Score 上表现最好，同时揭示了模型中的系统性偏差。


<details>
  <summary>Details</summary>
Motivation: 现有的图像描述生成研究主要集中在英语，而巴西葡萄牙语等低资源语言面临数据集和模型缺乏的挑战。现有解决方法常采用自动翻译来弥补资源不足，但这种方法的效果尚未得到充分评估。

Method: 研究者提出了一种跨原生翻译的评估框架，使用了两个版本的 Flickr30K 数据集：一个由巴西葡萄牙语母语者手动创建的字幕版本，以及一个从英语自动翻译到葡萄牙语的版本。他们将 Transformer 视觉语言模型（如 Swin-DistilBERTimbau, ViTucano, GPT-4o, LLaMa 3.2 Vision）在这两个数据集之间进行训练和测试（跨数据集评估），以分析翻译的影响。此外，他们还使用了注意力图来解释模型推理过程，并采用 CLIP-Score 来衡量图像与描述的对齐程度。

Result: Swin-DistilBERTimbau 模型在所有数据集和评估指标上都表现出了一致的优越性。ViTucano（一个巴西葡萄牙语预训练的视觉语言模型）在传统的基于文本的评估指标上优于更大的多语言模型（如 GPT-4o, LLaMa 3.2 Vision）。GPT-4 系列模型在 CLIP-Score 上获得了最高分，表明其图像-文本对齐能力更强。注意力图分析揭示了模型存在系统性偏差，包括性别分类错误、物体计数不准确以及空间关系理解问题。

Conclusion: 本研究为巴西葡萄牙语的图像描述生成任务提供了一个新的评估基准，并表明手动创建的母语字幕数据集对于训练性能更优越的模型至关重要。自动翻译的字幕数据集虽然能弥补资源不足，但可能引入偏差。研究强调了在评估模型时，结合传统文本指标和图像-文本对齐指标（如 CLIP-Score）的重要性，并且模型解释技术（如注意力图）对于识别和理解模型中的偏差至关重要。

Abstract: Image captioning (IC) refers to the automatic generation of natural language descriptions for images, with applications ranging from social media content generation to assisting individuals with visual impairments. While most research has been focused on English-based models, low-resource languages such as Brazilian Portuguese face significant challenges due to the lack of specialized datasets and models. Several studies create datasets by automatically translating existing ones to mitigate resource scarcity. This work addresses this gap by proposing a cross-native-translated evaluation of Transformer-based vision and language models for Brazilian Portuguese IC. We use a version of Flickr30K comprised of captions manually created by native Brazilian Portuguese speakers and compare it to a version with captions automatically translated from English to Portuguese. The experiments include a cross-context approach, where models trained on one dataset are tested on the other to assess the translation impact. Additionally, we incorporate attention maps for model inference interpretation and use the CLIP-Score metric to evaluate the image-description alignment. Our findings show that Swin-DistilBERTimbau consistently outperforms other models, demonstrating strong generalization across datasets. ViTucano, a Brazilian Portuguese pre-trained VLM, surpasses larger multilingual models (GPT-4o, LLaMa 3.2 Vision) in traditional text-based evaluation metrics, while GPT-4 models achieve the highest CLIP-Score, highlighting improved image-text alignment. Attention analysis reveals systematic biases, including gender misclassification, object enumeration errors, and spatial inconsistencies. The datasets and the models generated and analyzed during the current study are available in: https://github.com/laicsiifes/transformer-caption-ptbr.

</details>


### [212] [Modeling Art Evaluations from Comparative Judgments: A Deep Learning Approach to Predicting Aesthetic Preferences](https://arxiv.org/abs/2602.00394)
*Manoj Reddy Bethi,Sai Rupa Jhade,Pravallika Yaganti,Monoshiz Mahbub Khan,Zhe Yu*

Main category: cs.CV

TL;DR: 本研究提出了一种基于成对偏好评估的比较学习框架，以降低标注成本并对视觉艺术进行美学判断建模。研究结果表明，与基线模型相比，深度回归模型性能显著提升；比较学习模型在没有直接评分值的情况下，性能接近回归模型；预测个体偏好仍然具有挑战性；与直接评分相比，比较判断的标注时间效率提高了60%。


<details>
  <summary>Details</summary>
Motivation: 人类在视觉艺术审美判断上的个体差异大，获取带标签数据成本高。为了降低数据采集成本，需要一种更高效的标注方法。

Method: 提出一种基于成对偏好评估的比较学习框架。使用ResNet-50提取图像深度卷积特征，并开发了深度神经网络回归模型和双分支成对比较模型。通过四项研究问题（RQ1-RQ4）来评估模型的性能、比较学习的有效性、个体偏好预测能力以及标注成本效益。

Result: 深度回归模型在R^2上比基线模型提高了328%。比较模型在没有直接评分值的情况下，性能接近回归模型。个体偏好预测（受试者内和跨受试者分析）的性能远低于平均评分预测。比较判断比直接评分节省60%的标注时间。

Conclusion: 基于成对偏好评估的比较学习框架是一种有效且成本效益高的方法，可以用于建模人类审美判断，尤其是在大规模数据集的标注过程中。然而，预测个体用户的具体偏好仍然是一个挑战。

Abstract: Modeling human aesthetic judgments in visual art presents significant challenges due to individual preference variability and the high cost of obtaining labeled data. To reduce cost of acquiring such labels, we propose to apply a comparative learning framework based on pairwise preference assessments rather than direct ratings. This approach leverages the Law of Comparative Judgment, which posits that relative choices exhibit less cognitive burden and greater cognitive consistency than direct scoring. We extract deep convolutional features from painting images using ResNet-50 and develop both a deep neural network regression model and a dual-branch pairwise comparison model. We explored four research questions: (RQ1) How does the proposed deep neural network regression model with CNN features compare to the baseline linear regression model using hand-crafted features? (RQ2) How does pairwise comparative learning compare to regression-based prediction when lacking access to direct rating values? (RQ3) Can we predict individual rater preferences through within-rater and cross-rater analysis? (RQ4) What is the annotation cost trade-off between direct ratings and comparative judgments in terms of human time and effort? Our results show that the deep regression model substantially outperforms the baseline, achieving up to $328\%$ improvement in $R^2$. The comparative model approaches regression performance despite having no access to direct rating values, validating the practical utility of pairwise comparisons. However, predicting individual preferences remains challenging, with both within-rater and cross-rater performance significantly lower than average rating prediction. Human subject experiments reveal that comparative judgments require $60\%$ less annotation time per item, demonstrating superior annotation efficiency for large-scale preference modeling.

</details>


### [213] [3DGS$^2$-TR: Scalable Second-Order Trust-Region Method for 3D Gaussian Splatting](https://arxiv.org/abs/2602.00395)
*Roger Hsiao,Yuchen Fang,Xiangru Huang,Ruilong Li,Hesam Rabeti,Zan Gojcic,Javad Lavaei,James Demmel,Sophia Shao*

Main category: cs.CV

TL;DR: 本文提出了一种名为3DGS$^2$-TR的二阶优化器，用于加速3D高斯溅射（3DGS）场景训练。该方法通过Hutchinson方法近似Hessian矩阵的对角线，实现了与ADAM相似的计算和内存复杂度，并引入了基于Hellinger距离的参数化信赖域技术以提高稳定性。实验证明，3DGS$^2$-TR在相同初始化和无稠密化条件下，能以更少的迭代次数和更低的内存开销达到更好的重建质量，并且具有良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS场景训练方法在优化效率和内存消耗方面存在不足，尤其是在处理复杂非线性问题时。本文旨在提出一种更高效、更稳定的二阶优化方法，以加速3DGS的训练过程并支持更大规模场景的训练。

Method: 本文提出3DGS$^2$-TR，一种二阶优化器。它通过Hutchinson方法仅近似Hessian矩阵的对角线，实现矩阵无关（matrix-free）计算。同时，引入基于平方Hellinger距离的参数化信赖域技术来稳定优化过程。该方法的计算和内存复杂度与ADAM相当（O(n)）。

Result: 与ADAM相比，3DGS$^2$-TR在相同的参数初始化和无稠密化条件下，能实现50%的训练迭代次数减少，同时实现更好的重建质量。其峰值GPU内存开销仅比ADAM多17%，远低于3DGS-LM，展现了良好的可扩展性。

Conclusion: 3DGS$^2$-TR是一种高效且稳定的二阶优化器，能够显著加速3DGS场景训练，并有效控制内存消耗，为训练大型3D场景提供了可行的解决方案。

Abstract: We propose 3DGS$^2$-TR,a second-order optimizer for accelerating the scene training problem in 3D Gaussian Splatting (3DGS). Unlike existing second-order approaches that rely on explicit or dense curvature representations, such as 3DGS-LM (Höllein et al., 2025) or 3DGS2 (Lan et al., 2025), our method approximates curvature using only the diagonal of the Hessian matrix, efficiently via Hutchinson's method. Our approach is fully matrix-free and has the same complexity as ADAM (Kingma, 2024), $O(n)$ in both computation and memory costs. To ensure stable optimization in the presence of strong nonlinearity in the 3DGS rasterization process, we introduce a parameter-wise trust-region technique based on the squared Hellinger distance, regularizing updates to Gaussian parameters. Under identical parameter initialization and without densification, 3DGS$^2$-TR is able to achieve better reconstruction quality on standard datasets, using 50% fewer training iterations compared to ADAM, while incurring less than 1GB of peak GPU memory overhead (17% more than ADAM and 85% less than 3DGS-LM), enabling scalability to very large scenes and potentially to distributed training settings.

</details>


### [214] [Toward Autonomous Laboratory Safety Monitoring with Vision Language Models: Learning to See Hazards Through Scene Structure](https://arxiv.org/abs/2602.00414)
*Trishna Chakraborty,Udita Ghosh,Aldair Ernesto Gongora,Ruben Glatt,Yue Dong,Jiachen Li,Amit K. Roy-Chowdhury,Chengyu Song*

Main category: cs.CV

TL;DR: 本研究通过一种新颖的数据集生成管道，合成了包含图像、场景图和标注的安全事件数据，用于评估视觉语言模型（VLMs）在实验室安全监控中的表现。研究发现，VLMs在有场景图辅助时表现良好，但在仅依赖视觉信息时性能下降。为此，提出了一种场景图引导的对齐方法，通过将视觉输入转化为结构化场景图来提升VLMs的视觉安全性评估能力。


<details>
  <summary>Details</summary>
Motivation: 实验室安全监控受到人力限制，而现有模型在真实场景中的评估数据不足，大多数安全事件仅以非结构化文本记录。因此，需要一种方法来生成用于评估模型在实验室安全监控中表现的视觉数据。

Method: 研究首先提出了一种将文本描述转化为（图像，场景图，标注）三元组的数据生成管道，利用大型语言模型生成场景图，并使用图像生成模型渲染图像。随后，在合成数据集上评估了多种VLMs，并提出了一种后训练的上下文工程方法——场景图引导对齐，以改善VLMs在仅视觉输入下的性能。

Result: 在合成数据集上，VLMs在有场景图辅助时表现出有效性，但在仅视觉输入设置下性能显著下降，表明其直接从像素中提取结构化对象关系存在困难。场景图引导的对齐方法能够提高VLMs在仅视觉设置下的危险检测性能。

Conclusion: VLMs在实验室安全监控中具有潜力，但直接从视觉信息中提取结构化关系仍是挑战。通过场景图引导的对齐方法，可以有效地弥合感知差距，提升模型在实际视觉监控场景下的表现。

Abstract: Laboratories are prone to severe injuries from minor unsafe actions, yet continuous safety monitoring -- beyond mandatory pre-lab safety training -- is limited by human availability. Vision language models (VLMs) offer promise for autonomous laboratory safety monitoring, but their effectiveness in realistic settings is unclear due to the lack of visual evaluation data, as most safety incidents are documented primarily as unstructured text. To address this gap, we first introduce a structured data generation pipeline that converts textual laboratory scenarios into aligned triples of (image, scene graph, ground truth), using large language models as scene graph architects and image generation models as renderers. Our experiments on the synthetic dataset of 1,207 samples across 362 unique scenarios and seven open- and closed-source models show that VLMs perform effectively given textual scene graph, but degrade substantially in visual-only settings indicating difficulty in extracting structured object relationships directly from pixels. To overcome this, we propose a post-training context-engineering approach, scene-graph-guided alignment, to bridge perceptual gaps in VLMs by translating visual inputs into structured scene graphs better aligned with VLM reasoning, improving hazard detection performance in visual only settings.

</details>


### [215] [Text is All You Need for Vision-Language Model Jailbreaking](https://arxiv.org/abs/2602.00420)
*Yihang Chen,Zhao Xu,Youyuan Jiang,Tianle Zheng,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: 研究提出了一种名为 Text-DJ 的新型越狱攻击方法，该方法利用大型视觉语言模型（LVLM）的光学字符识别（OCR）能力，通过将有害提示分解成多个看似无害的子提示，并辅以大量无关的干扰提示，以网格形式呈现给模型，从而绕过现有的安全防护措施。


<details>
  <summary>Details</summary>
Motivation: 现有的LVLM安全防护措施主要针对显式的文本输入和相关的视觉场景，但忽略了模型OCR能力的潜在漏洞。研究旨在探索一种新的攻击方式，利用OCR能力绕过LVLM的安全防护。

Method: Text-DJ攻击方法分为三个阶段：1.将有害查询分解为多个语义相关但更良性的子查询；2.选择与有害查询最大程度无关的干扰查询；3.将所有子查询和干扰查询以图像网格的形式同时呈现给LVLM，子查询位于网格中间。

Result: 该方法成功绕过了最先进LVLM的安全对齐。研究认为攻击成功的原因在于：1.将文本提示转换为图像，绕过了基于文本的过滤器；2.通过引入大量无关查询来分散模型注意力，导致模型无法将分散的子查询与原始有害查询关联起来。

Conclusion: 研究揭示了LVLM的OCR能力在面对分散的、多图像的对抗性输入时不够鲁棒，存在关键漏洞，这表明需要开发针对碎片化多模态输入的防御措施。

Abstract: Large Vision-Language Models (LVLMs) are increasingly equipped with robust safety safeguards to prevent responses to harmful or disallowed prompts. However, these defenses often focus on analyzing explicit textual inputs or relevant visual scenes. In this work, we introduce Text-DJ, a novel jailbreak attack that bypasses these safeguards by exploiting the model's Optical Character Recognition (OCR) capability. Our methodology consists of three stages. First, we decompose a single harmful query into multiple and semantically related but more benign sub-queries. Second, we pick a set of distraction queries that are maximally irrelevant to the harmful query. Third, we present all decomposed sub-queries and distraction queries to the LVLM simultaneously as a grid of images, with the position of the sub-queries being middle within the grid. We demonstrate that this method successfully circumvents the safety alignment of state-of-the-art LVLMs. We argue this attack succeeds by (1) converting text-based prompts into images, bypassing standard text-based filters, and (2) inducing distractions, where the model's safety protocols fail to link the scattered sub-queries within a high number of irrelevant queries. Overall, our findings expose a critical vulnerability in LVLMs' OCR capabilities that are not robust to dispersed, multi-image adversarial inputs, highlighting the need for defenses for fragmented multimodal inputs.

</details>


### [216] [DISK: Dynamic Inference SKipping for World Models](https://arxiv.org/abs/2602.00440)
*Anugunj Naman,Gaibo Zhang,Ayushman Singh,Yaguang Zhang*

Main category: cs.CV

TL;DR: DISK 是一种无需重新训练的自回归世界模型自适应推理方法，通过双分支控制器和跨模态跳跃决策，在视频和自身轨迹之间实现运动-外观一致性，并提高了推理速度。


<details>
  <summary>Details</summary>
Motivation: 为了在不重新训练模型的情况下，提高自回归世界模型进行视频和自身轨迹预测时的运动-外观一致性，并实现更快的推理速度，以满足实际应用中的长时序预测需求。

Method: DISK 采用训练无关的自适应推理方法，利用两个耦合的扩散 Transformer（分别用于视频和自身轨迹），通过双分支控制器进行协调。控制器包含跨模态的跳跃决策，以保持运动-外观一致性。该方法还扩展了高阶潜在差分跳跃测试到自回归前向链式模式，并通过回滚循环传播控制器统计信息，以实现长时序的稳定性。

Result: 在 NuPlan 和 NuScenes 数据集上进行闭环驾驶回滚实验，DISK 在轨迹扩散方面实现了 2 倍的速度提升，在视频扩散方面实现了 1.6 倍的速度提升。同时，L2 规划误差、视觉质量（FID/FVD）和 NAVSIM PDMS 分数均得到保持。

Conclusion: DISK 是一种有效的训练无关自适应推理方法，能够显著提高长时序视频和轨迹预测的速度，同时保持运动-外观一致性和预测精度，使其在实际应用中具有成本效益。

Abstract: We present DISK, a training-free adaptive inference method for autoregressive world models. DISK coordinates two coupled diffusion transformers for video and ego-trajectory via dual-branch controllers with cross-modal skip decisions, preserving motion-appearance consistency without retraining. We extend higher-order latent-difference skip testing to the autoregressive chain-of-forward regime and propagate controller statistics through rollout loops for long-horizon stability. When integrated into closed-loop driving rollouts on 1500 NuPlan and NuScenes samples using an NVIDIA L40S GPU, DISK achieves 2x speedup on trajectory diffusion and 1.6x speedup on video diffusion while maintaining L2 planning error, visual quality (FID/FVD), and NAVSIM PDMS scores, demonstrating practical long-horizon video-and-trajectory prediction at substantially reduced cost.

</details>


### [217] [Model Optimization for Multi-Camera 3D Detection and Tracking](https://arxiv.org/abs/2602.00450)
*Ethan Anderson,Justin Silva,Kyle Zheng,Sameer Pusegaonkar,Yizhou Wang,Zheng Tang,Sujit Biswas*

Main category: cs.CV

TL;DR: 本文评估了Sparse4D，一个用于室内多摄像头场景的3D目标检测和跟踪框架，研究了帧率降低、量化和Transformer Engine混合精度训练对其性能（包括身份稳定性）的影响，并提出了新的评价指标AvgTrackDur。


<details>
  <summary>Details</summary>
Motivation: 在室内环境中，多摄像头系统需要支持在遮挡和视角变化下进行多目标跟踪。研究Sparse4D在各种条件下（如低帧率、低精度）的性能表现，并探索提高其效率和泛化能力的方法。

Method: 通过降低输入帧率、进行后训练量化（INT8和FP8）、迁移到WILDTRACK数据集以及使用Transformer Engine进行混合精度微调来评估Sparse4D。引入了平均跟踪时长（AvgTrackDur）作为衡量身份稳定性的新指标。

Result: Sparse4D在中低帧率下表现稳定，但低于2 FPS时身份关联会崩溃。选择性量化主干和颈部提供了最佳的速度-准确度权衡，而注意力模块对低精度敏感。在WILDTRACK数据集上，低帧率预训练带来了显著的零样本性能提升。Transformer Engine混合精度降低了延迟并提高了相机可扩展性，但可能影响身份传播的稳定性。

Conclusion: Sparse4D在多摄像头室内跟踪任务中表现出潜力，但其性能对帧率和数值精度敏感，尤其是在身份稳定性方面。AvgTrackDur是一个有用的新指标。Transformer Engine在效率方面有优势，但需要更稳健的验证策略来确保身份跟踪的可靠性。

Abstract: Outside-in multi-camera perception is increasingly important in indoor environments, where networks of static cameras must support multi-target tracking under occlusion and heterogeneous viewpoints. We evaluate Sparse4D, a query-based spatiotemporal 3D detection and tracking framework that fuses multi-view features in a shared world frame and propagates sparse object queries via instance memory. We study reduced input frame rates, post-training quantization (INT8 and FP8), transfer to the WILDTRACK benchmark, and Transformer Engine mixed-precision fine-tuning. To better capture identity stability, we report Average Track Duration (AvgTrackDur), which measures identity persistence in seconds. Sparse4D remains stable under moderate FPS reductions, but below 2 FPS, identity association collapses even when detections are stable. Selective quantization of the backbone and neck offers the best speed-accuracy trade-off, while attention-related modules are consistently sensitive to low precision. On WILDTRACK, low-FPS pretraining yields large zero-shot gains over the base checkpoint, while small-scale fine-tuning provides limited additional benefit. Transformer Engine mixed precision reduces latency and improves camera scalability, but can destabilize identity propagation, motivating stability-aware validation.

</details>


### [218] [LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs](https://arxiv.org/abs/2602.00462)
*Benno Krojer,Shravan Nayak,Oscar Mañas,Vaibhav Adlakha,Desmond Elliott,Siva Reddy,Marius Mosbach*

Main category: cs.CV

TL;DR: 提出了一种名为LatentLens的新方法，用于解释视觉-语言模型（VLM）中视觉令牌的潜在表示。与现有方法不同，LatentLens通过将视觉令牌表示与大型文本语料库中的上下文化文本表示进行比较来生成自然语言描述，结果表明大多数视觉令牌在所有模型和层中都是可解释的，并且生成的描述比现有方法更具语义意义和细粒度。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLM）如何处理视觉令牌，以及视觉令牌表示在LLM处理的每一层中编码了什么信息。现有方法（如LogitLens）可能低估了视觉令牌的可解释性。

Method: LatentLens方法：1. 编码一个大型文本语料库，存储其中每个令牌的上下文化表示。2. 将VLM中的视觉令牌表示与其在文本语料库中的上下文化文本表示进行比较。3. 选择最接近的k个文本表示作为视觉令牌的描述。在10个不同的VLM上进行了评估。

Result: LatentLens表明，大多数视觉令牌在所有研究的模型和所有层中都是可解释的。与LogitLens等常用方法相比，LatentLens低估了视觉令牌的可解释性。定性分析显示，LatentLens生成的描述在语义上是有意义的，并为人类提供了比单个令牌更精细的解释。

Conclusion: LatentLens是一种有效的视觉令牌表示解释方法，揭示了VLM中视觉令牌具有更高的可解释性。研究结果为视觉和语言表示之间的一致性提供了新的证据，并为分析潜在表示开辟了新的方向。

Abstract: Transforming a large language model (LLM) into a Vision-Language Model (VLM) can be achieved by mapping the visual tokens from a vision encoder into the embedding space of an LLM. Intriguingly, this mapping can be as simple as a shallow MLP transformation. To understand why LLMs can so readily process visual tokens, we need interpretability methods that reveal what is encoded in the visual token representations at every layer of LLM processing. In this work, we introduce LatentLens, a novel approach for mapping latent representations to descriptions in natural language. LatentLens works by encoding a large text corpus and storing contextualized token representations for each token in that corpus. Visual token representations are then compared to their contextualized textual representations, with the top-k nearest neighbor representations providing descriptions of the visual token. We evaluate this method on 10 different VLMs, showing that commonly used methods, such as LogitLens, substantially underestimate the interpretability of visual tokens. With LatentLens instead, the majority of visual tokens are interpretable across all studied models and all layers. Qualitatively, we show that the descriptions produced by LatentLens are semantically meaningful and provide more fine-grained interpretations for humans compared to individual tokens. More broadly, our findings contribute new evidence on the alignment between vision and language representations, opening up new directions for analyzing latent representations.

</details>


### [219] [PSGS: Text-driven Panorama Sliding Scene Generation via Gaussian Splatting](https://arxiv.org/abs/2602.00463)
*Xin Zhang,Shen Chen,Jiale Zhou,Lei Li*

Main category: cs.CV

TL;DR: 提出了一种名为PSGS的两阶段框架，用于从文本生成高保真全景3D场景，通过新颖的两层优化和全景滑动机制解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动的3D场景生成方法因缺乏3D-文本数据和多视图不一致而导致场景过于简单。

Method: PSGS采用两阶段框架：1. 两层优化架构（布局推理层和自优化层）生成语义连贯的全景图。2. 全景滑动机制通过采样重叠视角来初始化全局一致的3D高斯喷溅点云。训练中加入深度和语义一致性损失。

Result: PSGS在全景图生成方面优于现有方法，并产生更具吸引力的3D场景。

Conclusion: PSGS为可扩展的沉浸式内容创作提供了一个强大的解决方案，能够生成高质量、细节丰富的3D场景。

Abstract: Generating realistic 3D scenes from text is crucial for immersive applications like VR, AR, and gaming. While text-driven approaches promise efficiency, existing methods suffer from limited 3D-text data and inconsistent multi-view stitching, resulting in overly simplistic scenes. To address this, we propose PSGS, a two-stage framework for high-fidelity panoramic scene generation. First, a novel two-layer optimization architecture generates semantically coherent panoramas: a layout reasoning layer parses text into structured spatial relationships, while a self-optimization layer refines visual details via iterative MLLM feedback. Second, our panorama sliding mechanism initializes globally consistent 3D Gaussian Splatting point clouds by strategically sampling overlapping perspectives. By incorporating depth and semantic coherence losses during training, we greatly improve the quality and detail fidelity of rendered scenes. Our experiments demonstrate that PSGS outperforms existing methods in panorama generation and produces more appealing 3D scenes, offering a robust solution for scalable immersive content creation.

</details>


### [220] [ZS-TreeSeg: A Zero-Shot Framework for Tree Crown Instance Segmentation](https://arxiv.org/abs/2602.00470)
*Pengyu Chen,Fangzheng Lyu,Sicheng Wang,Cuizhen Wang*

Main category: cs.CV

TL;DR: 提出了一种名为 ZS-TreeSeg 的零样本框架，用于准确分割密集重叠的树冠，它结合了语义分割和细胞实例分割的优势，并利用 Cellpose-SAM 模型将树冠视为星凸对象，通过拓扑流场实现实例分离，无需训练即可在不同数据集上实现鲁棒的泛化。


<details>
  <summary>Details</summary>
Motivation: 现有的监督深度学习方法标注成本高且泛化能力有限，而基础模型（如 Segment Anything Model）缺乏领域知识，在分割密集重叠的树冠时效果不佳，存在欠分割问题。因此，需要一种既能处理密集重叠树冠，又能减少标注成本的解决方案。

Method: 提出 ZS-TreeSeg 零样本框架，该框架借鉴了两种成熟任务：1) 冠层语义分割；2) 细胞实例分割。具体而言，利用 Cellpose-SAM 模型，将树冠建模为拓扑流场中的星凸对象，通过向量收敛强制数学上分离接触的树冠实例。

Result: ZS-TreeSeg 框架在 NEON 和 BAMFOREST 数据集上进行了实验，并进行了视觉检查。结果表明，该框架能够鲁棒地泛化到不同传感器类型和冠层密度，实现了训练自由的树冠实例分割和标签生成。

Conclusion: ZS-TreeSeg 框架成功解决了密集重叠冠层下的树冠分割难题，通过结合不同领域的先验知识和创新性的建模方法，提供了一种无需训练即可实现高精度和良好泛化能力的解决方案，为森林生物量估算和生态监测提供了有力支持。

Abstract: Individual tree crown segmentation is an important task in remote sensing for forest biomass estimation and ecological monitoring. However, accurate delineation in dense, overlapping canopies remains a bottleneck. While supervised deep learning methods suffer from high annotation costs and limited generalization, emerging foundation models (e.g., Segment Anything Model) often lack domain knowledge, leading to under-segmentation in dense clusters. To bridge this gap, we propose ZS-TreeSeg, a Zero-Shot framework that adapts from two mature tasks: 1) Canopy Semantic segmentation; and 2) Cells instance segmentation. By modeling tree crowns as star-convex objects within a topological flow field using Cellpose-SAM, the ZS-TreeSeg framework forces the mathematical separation of touching tree crown instances based on vector convergence. Experiments on the NEON and BAMFOREST datasets and visual inspection demonstrate that our framework generalizes robustly across diverse sensor types and canopy densities, which can offer a training-free solution for tree crown instance segmentation and labels generation.

</details>


### [221] [GTATrack: Winner Solution to SoccerTrack 2025 with Deep-EIoU and Global Tracklet Association](https://arxiv.org/abs/2602.00484)
*Rong-Lin Jian,Ming-Chi Luo,Chen-Wei Huang,Chia-Ming Lee,Yu-Fan Lin,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: GTATrack是一个用于运动场景（特别是使用鱼眼相机）的多目标跟踪框架，通过结合Deep-EIoU进行短期关联和GTA进行长期轨迹优化，并在伪标签策略的辅助下，在SoccerTrack Challenge 2025中取得第一名。


<details>
  <summary>Details</summary>
Motivation: 运动场景中的多目标跟踪（MOT）面临玩家运动不规则、外观相似以及频繁遮挡等挑战。使用鱼眼相机时，几何畸变和尺度变化问题更加严峻。研究者旨在解决这些问题，提高跟踪精度。

Method: 提出GTATrack，一个分层跟踪框架，包含两个核心组件：1. Deep Expansion IoU (Deep-EIoU) 用于运动无关的在线关联；2. Global Tracklet Association (GTA) 用于轨迹级别的精炼。此外，还采用伪标签策略来提高检测器对小目标和畸变目标的召回率。

Result: GTATrack在SoccerTrack Challenge 2025中获得第一名，HOTA得分为0.60，并将假阳性数量显著减少到982，显示出在基于鱼眼相机的足球跟踪方面的先进性能。

Conclusion: GTATrack通过结合局部关联（Deep-EIoU）和全局推理（GTA），并利用伪标签策略，有效解决了运动场景下使用鱼眼相机进行多目标跟踪时出现的身份切换、遮挡和跟踪碎片化问题，达到了最先进的跟踪精度。

Abstract: Multi-object tracking (MOT) in sports is highly challenging due to irregular player motion, uniform appearances, and frequent occlusions. These difficulties are further exacerbated by the geometric distortion and extreme scale variation introduced by static fisheye cameras. In this work, we present GTATrack, a hierarchical tracking framework that win first place in the SoccerTrack Challenge 2025. GTATrack integrates two core components: Deep Expansion IoU (Deep-EIoU) for motion-agnostic online association and Global Tracklet Association (GTA) for trajectory-level refinement. This two-stage design enables both robust short-term matching and long-term identity consistency. Additionally, a pseudo-labeling strategy is used to boost detector recall on small and distorted targets. The synergy between local association and global reasoning effectively addresses identity switches, occlusions, and tracking fragmentation. Our method achieved a winning HOTA score of 0.60 and significantly reduced false positives to 982, demonstrating state-of-the-art accuracy in fisheye-based soccer tracking. Our code is available at https://github.com/ron941/GTATrack-STC2025.

</details>


### [222] [Refining Strokes by Learning Offset Attributes between Strokes for Flexible Sketch Edit at Stroke-Level](https://arxiv.org/abs/2602.00489)
*Sicong Zang,Tao Sun,Cairong Yan*

Main category: cs.CV

TL;DR: 提出了一种名为SketchMod的方法，通过学习和应用目标草图的模式来转换源草图的笔画（缩放、旋转、位移），从而实现更精确和灵活的笔画级草图编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的笔画级草图编辑方法仅通过重新定位源笔画来实现，当源笔画在尺寸和方向上与目标草图差异较大时，效果不佳，无法保持语义一致性和视觉保真度。

Method: SketchMod通过学习目标草图的模式来调整源草图。具体来说，它学习三个关键的偏移属性（缩放、方向和位置）来转换源笔画，使其与目标草图对齐：1) 通过缩放匹配空间比例，2) 通过旋转对齐局部几何形状，3) 通过位移满足语义布局。此外，还可以通过暴露的捕获笔画属性精确控制笔画轮廓。

Result: 实验结果表明，SketchMod在笔画级草图编辑方面实现了精确和灵活的性能。

Conclusion: SketchMod通过对源笔画进行变换来匹配目标草图的模式，实现了更精确和灵活的笔画级草图编辑，解决了仅通过位移带来的局限性。

Abstract: Sketch edit at stroke-level aims to transplant source strokes onto a target sketch via stroke expansion or replacement, while preserving semantic consistency and visual fidelity with the target sketch. Recent studies addressed it by relocating source strokes at appropriate canvas positions. However, as source strokes could exhibit significant variations in both size and orientation, we may fail to produce plausible sketch editing results by merely repositioning them without further adjustments. For example, anchoring an oversized source stroke onto the target without proper scaling would fail to produce a semantically coherent outcome. In this paper, we propose SketchMod to refine the source stroke through transformation so as to align it with the target sketch's patterns, further realize flexible sketch edit at stroke-level. As the source stroke refinement is governed by the patterns of the target sketch, we learn three key offset attributes (scale, orientation and position) from the source stroke to another, and align it with the target by: 1) resizing to match spatial proportions by scale, 2) rotating to align with local geometry by orientation, and 3) displacing to meet with semantic layout by position. Besides, a stroke's profiles can be precisely controlled during sketch edit via the exposed captured stroke attributes. Experimental results indicate that SketchMod achieves precise and flexible performances on stroke-level sketch edit.

</details>


### [223] [HSSDCT: Factorized Spatial-Spectral Correlation for Hyperspectral Image Fusion](https://arxiv.org/abs/2602.00490)
*Chia-Ming Lee,Yu-Hao Ho,Yu-Fan Lin,Jen-Wei Lee,Li-Wei Kang,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: 提出了一种名为HSSDCT（分层空间-光谱密集相关网络）的新型高光谱图像融合方法，通过引入HDRTB和SSCL模块，有效解决了现有深度学习方法在感受野、光谱冗余和自注意力二次复杂度方面的问题，实现了更高质量的重建和更低的计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习在高光谱图像融合中存在感受野有限、光谱冗余和自注意力复杂度高的问题，限制了方法的效率和鲁棒性。

Method: 提出HSSDCT框架，包含两个关键模块：1) 分层密集残差Transformer块（HDRTB），通过逐步扩大窗口和密集残差连接实现多尺度特征聚合；2) 空间-光谱相关层（SSCL），通过分解空间和光谱依赖性，将自注意力复杂度降低至线性，并缓解光谱冗余。

Result: 在基准数据集上的广泛实验表明，HSSDCT在重建质量上表现更优，计算成本显著降低，达到了高光谱图像融合领域新的最先进水平。

Conclusion: HSSDCT是一种有效的高光谱图像融合方法，通过创新的模块设计克服了现有方法的局限性，实现了在计算效率和重建性能上的显著提升。

Abstract: Hyperspectral image (HSI) fusion aims to reconstruct a high-resolution HSI (HR-HSI) by combining the rich spectral information of a low-resolution HSI (LR-HSI) with the fine spatial details of a high-resolution multispectral image (HR-MSI). Although recent deep learning methods have achieved notable progress, they still suffer from limited receptive fields, redundant spectral bands, and the quadratic complexity of self-attention, which restrict both efficiency and robustness. To overcome these challenges, we propose the Hierarchical Spatial-Spectral Dense Correlation Network (HSSDCT). The framework introduces two key modules: (i) a Hierarchical Dense-Residue Transformer Block (HDRTB) that progressively enlarges windows and employs dense-residue connections for multi-scale feature aggregation, and (ii) a Spatial-Spectral Correlation Layer (SSCL) that explicitly factorizes spatial and spectral dependencies, reducing self-attention to linear complexity while mitigating spectral redundancy. Extensive experiments on benchmark datasets demonstrate that HSSDCT delivers superior reconstruction quality with significantly lower computational costs, achieving new state-of-the-art performance in HSI fusion. Our code is available at https://github.com/jemmyleee/HSSDCT.

</details>


### [224] [RGBX-R1: Visual Modality Chain-of-Thought Guided Reinforcement Learning for Multimodal Grounding](https://arxiv.org/abs/2602.00504)
*Jiahe Wu,Bing Cao,Qilong Wang,Qinghua Hu,Dongdong Li,Pengfei Zhu*

Main category: cs.CV

TL;DR: 提出RGBX-R1框架，通过VM-CoT提示策略和两阶段微调（CS-SFT和ST-RFT），增强多模态大语言模型（MLLM）在红外、深度、事件等X视觉模态上的感知和推理能力，并在新构建的RGBX-Grounding基准上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM主要在RGB模态上预训练，限制了其在红外、深度、事件等对复杂场景至关重要的X视觉模态上的性能。研究旨在拓展MLLM处理和理解多种视觉模态的能力。

Method: 提出RGBX-R1框架，包含：1. 理解-关联-验证（UAV）提示策略构建视觉模态思维链（VM-CoT），将RGB理解能力扩展到X模态。2. 两阶段训练：冷启动监督微调（CS-SFT）用于基础模态认知，基于GRPO的时空强化微调（ST-RFT）使用模态理解时空（MuST）奖励增强模态推理。

Result: 在首个RGBX-Grounding基准上的广泛实验表明，RGBX-R1在多模态理解和空间感知方面优于基线方法，在三个RGBX grounding任务上提升了22.71%。

Conclusion: RGBX-R1框架能够有效提升MLLM在多种X视觉模态上的感知和推理能力，并在RGBX grounding任务上取得了 SOTA 性能。

Abstract: Multimodal Large Language Models (MLLM) are primarily pre-trained on the RGB modality, thereby limiting their performance on other modalities, such as infrared, depth, and event data, which are crucial for complex scenarios. To address this, we propose RGBX-R1, a framework to enhance MLLM's perception and reasoning capacities across various X visual modalities. Specifically, we employ an Understand-Associate-Validate (UAV) prompting strategy to construct the Visual Modality Chain-of-Thought (VM-CoT), which aims to expand the MLLMs' RGB understanding capability into X modalities. To progressively enhance reasoning capabilities, we introduce a two-stage training paradigm: Cold-Start Supervised Fine-Tuning (CS-SFT) and Spatio-Temporal Reinforcement Fine-Tuning (ST-RFT). CS-SFT supervises the reasoning process with the guidance of VM-CoT, equipping the MLLM with fundamental modality cognition. Building upon GRPO, ST-RFT employs a Modality-understanding Spatio-Temporal (MuST) reward to reinforce modality reasoning. Notably, we construct the first RGBX-Grounding benchmark, and extensive experiments verify our superiority in multimodal understanding and spatial perception, outperforming baselines by 22.71% on three RGBX grounding tasks.

</details>


### [225] [Sparse Shortcuts: Facilitating Efficient Fusion in Multimodal Large Language Models](https://arxiv.org/abs/2602.00505)
*Jingrui Zhang,Feng Liang,Yong Zhang,Wei Wang,Runhao Zeng,Xiping Hu*

Main category: cs.CV

TL;DR: 本文提出了一种名为SparseCut的通用跨模态融合架构，通过在跨模态编码器和大型语言模型（LLM）之间引入稀疏的快捷连接，实现了多层次的视觉特征整合，从而提升了多模态大型语言模型（MLLMs）的性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM研究主要集中在模型规模或数据质量的提升，而忽视了如何有效将跨模态知识整合到语言空间。特别是，现有视觉-语言模型仅使用高层视觉特征进行模态对齐，丢失了中低层视觉特征的丰富语义信息，限制了跨模态理解能力。

Method: 提出SparseCut架构，其核心是引入稀疏的快捷连接，将跨模态编码器的多层次视觉特征直接连接到LLM。此外，还引入了一个高效的多粒度特征融合模块，在通过快捷连接前融合视觉特征，以保持原始语言上下文且不增加LLM的计算复杂度。

Result: SparseCut架构在多个跨模态基准测试中显著提升了MLLMs的性能，证明了其在不同基础LLM上的通用性和可扩展性。

Conclusion: SparseCut通过引入稀疏快捷连接和多粒度特征融合，能够高效、分层地整合多层次视觉语义信息，有效解决了现有MLLM在跨模态知识融合方面的不足，并带来了显著的性能提升。

Abstract: With the remarkable success of large language models (LLMs) in natural language understanding and generation, multimodal large language models (MLLMs) have rapidly advanced in their ability to process data across multiple modalities. While most existing efforts focus on scaling up language models or constructing higher-quality training data, limited attention has been paid to effectively integrating cross-modal knowledge into the language space. In vision-language models, for instance, aligning modalities using only high-level visual features often discards the rich semantic information present in mid- and low-level features, limiting the model's ability of cross-modality understanding. To address this issue, we propose SparseCut, a general cross-modal fusion architecture for MLLMs, introducing sparse shortcut connections between the cross-modal encoder and the LLM. These shortcut connections enable the efficient and hierarchical integration of visual features at multiple levels, facilitating richer semantic fusion without increasing computational overhead. We further introduce an efficient multi-grained feature fusion module, which performs the fusion of visual features before routing them through the shortcuts. This preserves the original language context and does not increase the overall input length, thereby avoiding an increase in computational complexity for the LLM. Experiments demonstrate that SparseCut significantly enhances the performance of MLLMs across various multimodal benchmarks with generality and scalability for different base LLMs.

</details>


### [226] [SPARK: Stochastic Propagation via Affinity-guided Random walK for training-free unsupervised segmentation](https://arxiv.org/abs/2602.00516)
*Kunal Mahatha,Jose Dolz,Christian Desrosiers*

Main category: cs.CV

TL;DR: 本文提出了一种新的无监督语义分割方法，将分割视为一个随机流平衡问题，而不是传统的谱图分割问题。该方法利用稳定扩散提取的全局和局部信息，通过马尔可夫传播进行标签扩散，并在实验中取得了优于现有方法的零样本分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督分割方法（如基于谱图分割的方法）存在一些局限性，包括需要预设簇数量、边界平滑过度以及对噪声敏感。此外，它们往往忽略了局部邻域结构在保持精细轮廓方面的重要性。

Method: 作者将无监督分割重新定义为一个随机流平衡问题。他们利用稳定扩散生成全局的扩散注意力和局部的邻域结构，构建稀疏但富有表达力的亲和图。在此基础上，提出了一种马尔可夫传播方案，通过随机游走进行标签扩散，并采用自适应剪枝策略来抑制不可靠的转移并强化可靠的亲和路径。

Result: 在七个常用的语义分割基准测试中，该方法在零样本分割任务上取得了最先进的性能。与基于谱图聚类的方法相比，该方法生成的分割边界更锐利，区域更连贯，掩码也更稳定。

Conclusion: 将无监督分割问题建模为随机流平衡问题，并结合全局扩散注意力和局部邻域结构，可以有效克服现有方法的局限性，并获得更优的零样本分割结果，尤其在边界锐利度和掩码稳定性方面表现突出。

Abstract: We argue that existing training-free segmentation methods rely on an implicit and limiting assumption, that segmentation is a spectral graph partitioning problem over diffusion-derived affinities. Such approaches, based on global graph partitioning and eigenvector-based formulations of affinity matrices, suffer from several fundamental drawbacks, they require pre-selecting the number of clusters, induce boundary oversmoothing due to spectral relaxation, and remain highly sensitive to noisy or multi-modal affinity distributions. Moreover, many prior works neglect the importance of local neighborhood structure, which plays a crucial role in stabilizing affinity propagation and preserving fine-grained contours. To address these limitations, we reformulate training-free segmentation as a stochastic flow equilibrium problem over diffusion-induced affinity graphs, where segmentation emerges from a stochastic propagation process that integrates global diffusion attention with local neighborhoods extracted from stable diffusion, yielding a sparse yet expressive affinity structure. Building on this formulation, we introduce a Markov propagation scheme that performs random-walk-based label diffusion with an adaptive pruning strategy that suppresses unreliable transitions while reinforcing confident affinity paths. Experiments across seven widely used semantic segmentation benchmarks demonstrate that our method achieves state-of-the-art zero-shot performance, producing sharper boundaries, more coherent regions, and significantly more stable masks compared to prior spectral-clustering-based approaches.

</details>


### [227] [MRAD: Zero-Shot Anomaly Detection with Memory-Driven Retrieval](https://arxiv.org/abs/2602.00522)
*Chaoran Xu,Chengkan Lv,Qiyu Chen,Feng Zhang,Zhengtao Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为MRAD（Memory-Retrieval Anomaly Detection）的无监督零样本异常检测框架，通过存储和检索特征-标签对的记忆库来代替传统的参数拟合方法，实现了高效且跨领域稳定的异常检测。MRAD包含一个无需训练的基础模型（MRAD-TF）和两个轻量级增强变体（MRAD-FT和MRAD-CLIP）。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本异常检测方法通常依赖预训练模型，但现有技术（如提示学习或复杂模型）在拟合数据分布时存在训练和推理成本高、跨领域稳定性差的问题。研究旨在克服这些局限性。

Method: MRAD框架通过直接内存检索取代参数拟合。其基础模型MRAD-TF冻结CLIP图像编码器，并利用辅助数据构建一个两级内存库（图像级和像素级），显式存储特征-标签对作为键值。推理时，通过在内存库上进行相似性检索来获得异常分数。在此基础上，MRAD-FT通过微调检索度量（使用两个线性层）来增强区分度；MRAD-CLIP将MRAD-FT的先验信息注入CLIP的可学习文本提示中，以增强对未见类别的泛化能力。

Result: 在16个工业和医学数据集上，MRAD框架在异常分类和分割任务上，无论是在无训练还是训练设置下，都持续展现出优越的性能。

Conclusion: 研究表明，充分利用原始数据的经验分布（而非仅依赖模型拟合）可以实现更强的异常检测性能。MRAD框架通过内存检索提供了一种高效且稳定的零样本异常检测方法。

Abstract: Zero-shot anomaly detection (ZSAD) often leverages pretrained vision or vision-language models, but many existing methods use prompt learning or complex modeling to fit the data distribution, resulting in high training or inference cost and limited cross-domain stability. To address these limitations, we propose Memory-Retrieval Anomaly Detection method (MRAD), a unified framework that replaces parametric fitting with a direct memory retrieval. The train-free base model, MRAD-TF, freezes the CLIP image encoder and constructs a two-level memory bank (image-level and pixel-level) from auxiliary data, where feature-label pairs are explicitly stored as keys and values. During inference, anomaly scores are obtained directly by similarity retrieval over the memory bank. Based on the MRAD-TF, we further propose two lightweight variants as enhancements: (i) MRAD-FT fine-tunes the retrieval metric with two linear layers to enhance the discriminability between normal and anomaly; (ii) MRAD-CLIP injects the normal and anomalous region priors from the MRAD-FT as dynamic biases into CLIP's learnable text prompts, strengthening generalization to unseen categories. Across 16 industrial and medical datasets, the MRAD framework consistently demonstrates superior performance in anomaly classification and segmentation, under both train-free and training-based settings. Our work shows that fully leveraging the empirical distribution of raw data, rather than relying only on model fitting, can achieve stronger anomaly detection performance. The code will be publicly released at https://github.com/CROVO1026/MRAD.

</details>


### [228] [SAGE: Accelerating Vision-Language Models via Entropy-Guided Adaptive Speculative Decoding](https://arxiv.org/abs/2602.00523)
*Yujia Tong,Tian Zhang,Yunyang Wan,Kaiwei Lin,Jingling Yuan,Chuang Hu*

Main category: cs.CV

TL;DR: 本文提出了一种名为 SAGE 的框架，通过动态调整推测树结构来加速视觉-语言模型（VLM）的推理。SAGE 利用输出熵作为置信度指标，根据预测不确定性来调整树的深度和宽度，从而提高了接受率并实现了比静态树结构更快的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的推测解码方法依赖于静态的树结构，无法适应不同生成步骤中变化的预测难度，导致接受长度次优和加速效果有限。

Method: SAGE 框架通过动态调整推测树结构来实现加速。其核心思想是利用输出熵作为置信度指标，并考虑了输出熵在解码步骤之间的强时间相关性。对于高置信度的预测，SAGE 构建更深更窄的树以最大化推测深度；对于不确定的预测，则构建更浅更宽的树以增加探索的多样性。

Result: SAGE 框架能够提高接受长度，并比静态树基线实现更快的加速。在 LLaVA-OneVision-72B 上实现了高达 3.36 倍的解码加速，在 Qwen2.5-VL-72B 上实现了 3.18 倍的加速，同时不损失输出质量。

Conclusion: SAGE 是一种有效的新型框架，通过动态调整推测树结构，能够显著加速 VLM 的推理过程，并在不牺牲输出质量的前提下实现显著的加速效果。

Abstract: Speculative decoding has emerged as a promising approach to accelerate inference in vision-language models (VLMs) by enabling parallel verification of multiple draft tokens. However, existing methods rely on static tree structures that remain fixed throughout the decoding process, failing to adapt to the varying prediction difficulty across generation steps. This leads to suboptimal acceptance lengths and limited speedup. In this paper, we propose SAGE, a novel framework that dynamically adjusts the speculation tree structure based on real-time prediction uncertainty. Our key insight is that output entropy serves as a natural confidence indicator with strong temporal correlation across decoding steps. SAGE constructs deeper-narrower trees for high-confidence predictions to maximize speculation depth, and shallower-wider trees for uncertain predictions to diversify exploration. SAGE improves acceptance lengths and achieves faster acceleration compared to static tree baselines. Experiments on multiple benchmarks demonstrate the effectiveness of SAGE: without any loss in output quality, it delivers up to $3.36\times$ decoding speedup for LLaVA-OneVision-72B and $3.18\times$ for Qwen2.5-VL-72B.

</details>


### [229] [Enhancing Open-Vocabulary Object Detection through Multi-Level Fine-Grained Visual-Language Alignment](https://arxiv.org/abs/2602.00531)
*Tianyi Zhang,Antoine Simoulin,Kai Li,Sana Lakdawala,Shiqing Yu,Arpit Mittal,Hongyu Fu,Yu Lin*

Main category: cs.CV

TL;DR: 本文提出了一种名为 VLDet 的新型开放词汇目标检测框架，通过改进特征金字塔和引入新的对比学习损失，提高了在未知类别上的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测方法在适配 CLIP 等视觉语言模型以及保证视觉语言对齐方面存在挑战。

Method: VLDet 框架通过 VL-PUB 模块利用 CLIP 的视觉语言知识，并结合特征金字塔适配骨干网络。同时，引入 SigRPN 模块，利用基于 sigmoid 的锚点-文本对比学习损失来增强对新类别的检测能力。

Result: 在 COCO2017 数据集上，VLDet 在新类别上的 AP 达到 58.7，在 LVIS 数据集上达到 24.8，均显著优于现有 SOTA 方法。此外，VLDet 在闭集目标检测任务上表现出更优的零样本性能。

Conclusion: VLDet 框架通过精细的视觉语言对齐和有效的知识迁移，有效解决了开放词汇目标检测中的关键挑战，并在多个基准测试中取得了领先的性能。

Abstract: Traditional object detection systems are typically constrained to predefined categories, limiting their applicability in dynamic environments. In contrast, open-vocabulary object detection (OVD) enables the identification of objects from novel classes not present in the training set. Recent advances in visual-language modeling have led to significant progress of OVD. However, prior works face challenges in either adapting the single-scale image backbone from CLIP to the detection framework or ensuring robust visual-language alignment. We propose Visual-Language Detection (VLDet), a novel framework that revamps feature pyramid for fine-grained visual-language alignment, leading to improved OVD performance. With the VL-PUB module, VLDet effectively exploits the visual-language knowledge from CLIP and adapts the backbone for object detection through feature pyramid. In addition, we introduce the SigRPN block, which incorporates a sigmoid-based anchor-text contrastive alignment loss to improve detection of novel categories. Through extensive experiments, our approach achieves 58.7 AP for novel classes on COCO2017 and 24.8 AP on LVIS, surpassing all state-of-the-art methods and achieving significant improvements of 27.6% and 6.9%, respectively. Furthermore, VLDet also demonstrates superior zero-shot performance on closed-set object detection.

</details>


### [230] [SADER: Structure-Aware Diffusion Framework with DEterministic Resampling for Multi-Temporal Remote Sensing Cloud Removal](https://arxiv.org/abs/2602.00536)
*Yifan Zhang,Qian Chen,Yi Liu,Wengen Li,Jihong Guan*

Main category: cs.CV

TL;DR: 本文提出了一种名为 SADER 的结构感知扩散模型，用于去除多时相遥感影像中的云层，该模型通过多时相条件扩散网络、云感知注意力损失和确定性重采样策略来提高去云效果和采样效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的遥感影像去云方法存在采样效率低、对多时相场景下的结构和时间先验利用不足的问题，而云层严重影响了遥感影像的可用性。

Method: 1. 构建了一个多时相条件扩散网络（MTCDN），通过时间融合和混合注意力机制来捕获多时相和多模态的关联。
2. 引入了云感知注意力损失，通过考虑云的厚度和亮度差异来强调受云影响严重的区域。
3. 设计了一种确定性重采样策略，用于连续扩散模型，通过引导式修正来迭代优化样本，替换异常值。

Result: SADER 在多个多时相数据集上进行了广泛实验，在所有评估指标上均一致优于最先进的去云方法。

Conclusion: SADER 是一种有效的结构感知扩散框架，能够显著提高多时相遥感影像的去云效果，并且在采样效率和对多时相信息的利用方面有所改进。

Abstract: Cloud contamination severely degrades the usability of remote sensing imagery and poses a fundamental challenge for downstream Earth observation tasks. Recently, diffusion-based models have emerged as a dominant paradigm for remote sensing cloud removal due to their strong generative capability and stable optimization. However, existing diffusion-based approaches often suffer from limited sampling efficiency and insufficient exploitation of structural and temporal priors in multi-temporal remote sensing scenarios. In this work, we propose SADER, a structure-aware diffusion framework for multi-temporal remote sensing cloud removal. SADER first develops a scalable Multi-Temporal Conditional Diffusion Network (MTCDN) to fully capture multi-temporal and multimodal correlations via temporal fusion and hybrid attention. Then, a cloud-aware attention loss is introduced to emphasize cloud-dominated regions by accounting for cloud thickness and brightness discrepancies. In addition, a deterministic resampling strategy is designed for continuous diffusion models to iteratively refine samples under fixed sampling steps by replacing outliers through guided correction. Extensive experiments on multiple multi-temporal datasets demonstrate that SADER consistently outperforms state-of-the-art cloud removal methods across all evaluation metrics. The code of SADER is publicly available at https://github.com/zyfzs0/SADER.

</details>


### [231] [NPNet: A Non-Parametric Network with Adaptive Gaussian-Fourier Positional Encoding for 3D Classification and Segmentation](https://arxiv.org/abs/2602.00542)
*Mohammad Saeid,Amir Salarpour,Pedram MohajerAnsari,Mert D. Pesé*

Main category: cs.CV

TL;DR: NPNet 是一种完全非参数的 3D 点云分类和部件分割方法，无需学习权重，而是利用确定性算子构建点特征，并引入自适应高斯-傅里叶位置编码以提高稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于大量的学习参数，这使得它们在数据稀疏或计算资源受限的情况下表现不佳。研究者希望开发一种无需学习权重的非参数方法，以提高 3D 点云处理的稳定性和效率。

Method: NPNet 利用确定性算子（如最远点采样、k-近邻和池化）来构建点特征。其核心是自适应高斯-傅里叶位置编码，其带宽和高斯-余弦混合参数根据输入几何形状自适应调整。对于分割任务，还额外引入了固定频率的傅里叶特征来提供全局上下文。

Result: NPNet 在 ModelNet40/ModelNet-R、ScanObjectNN 和 ShapeNetPart 等数据集上取得了与非参数基线相当的性能。尤其在 ModelNet40 的少样本学习设置下表现出色。与现有非参数方法相比，NPNet 在内存占用和推理时间方面也具有优势。

Conclusion: NPNet 是一种有效且高效的非参数 3D 点云处理方法，通过自适应位置编码解决了尺度和采样密度变化带来的挑战，并在少样本学习和资源受限的场景下展现出优越的性能。

Abstract: We present NPNet, a fully non-parametric approach for 3D point-cloud classification and part segmentation. NPNet contains no learned weights; instead, it builds point features using deterministic operators such as farthest point sampling, k-nearest neighbors, and pooling. Our key idea is an adaptive Gaussian-Fourier positional encoding whose bandwidth and Gaussian-cosine mixing are chosen from the input geometry, helping the method remain stable across different scales and sampling densities. For segmentation, we additionally incorporate fixed-frequency Fourier features to provide global context alongside the adaptive encoding. Across ModelNet40/ModelNet-R, ScanObjectNN, and ShapeNetPart, NPNet achieves strong performance among non-parametric baselines, and it is particularly effective in few-shot settings on ModelNet40. NPNet also offers favorable memory use and inference time compared to prior non-parametric methods

</details>


### [232] [Learning to Decode Against Compositional Hallucination in Video Multimodal Large Language Models](https://arxiv.org/abs/2602.00559)
*Wenbin Xing,Quanxing Zha,Lizheng Zu,Mengran Li,Ming Li,Junchi Yan*

Main category: cs.CV

TL;DR: 本文提出OmniVCHall基准来评估视频大语言模型（VLLMs）在处理孤立和组合式视频幻觉方面的能力，并引入TriCD框架来改善模型性能，实验证明TriCD能有效提升准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的视频幻觉缓解研究主要关注孤立的错误类型，而对由多个空间和时间因素交互引起的组合式幻觉的探索不足。

Method: 开发OmniVCHall基准，包含不同领域视频、新型相机幻觉类型、精细分类及对抗性选项；提出TriCD对比解码框架，包含自适应扰动控制器和显著性引导增强模块，并通过强化学习进行优化。

Result: 在39个VLLMs上的评估显示，即使是先进模型在处理组合式幻觉时性能也会显著下降。TriCD框架在两个代表性骨干网络上均能带来持续的性能提升，平均准确率提高超过10%。

Conclusion: OmniVCHall基准能够系统性地评估VLLMs在不同类型视频幻觉上的表现，而TriCD框架提供了一种有效的解决方案，能够显著提升模型在面对组合式视频幻觉时的准确性。

Abstract: Current research on video hallucination mitigation primarily focuses on isolated error types, leaving compositional hallucinations, arising from incorrect reasoning over multiple interacting spatial and temporal factors largely underexplored. We introduce OmniVCHall, a benchmark designed to systematically evaluate both isolated and compositional hallucinations in video multimodal large language models (VLLMs). OmniVCHall spans diverse video domains, introduces a novel camera-based hallucination type, and defines a fine-grained taxonomy, together with adversarial answer options (e.g., "All are correct" and "None of the above") to prevent shortcut reasoning. The evaluations of 39 representative VLLMs reveal that even advanced models (e.g., Qwen3-VL and GPT-5) exhibit substantial performance degradation. We propose TriCD, a contrastive decoding framework with a triple-pathway calibration mechanism. An adaptive perturbation controller dynamically selects distracting operations to construct negative video variants, while a saliency-guided enhancement module adaptively reinforces grounded token-wise visual evidences. These components are optimized via reinforcement learning to encourage precise decision-making under compositional hallucination settings. Experimental results show that TriCD consistently improves performance across two representative backbones, achieving an average accuracy improvement of over 10%. The data and code can be find at https://github.com/BMRETURN/OmniVCHall.

</details>


### [233] [GLAD: Generative Language-Assisted Visual Tracking for Low-Semantic Templates](https://arxiv.org/abs/2602.00570)
*Xingyu Luo,Yidong Cai,Jie Liu,Jie Tang,Gangshan Wu,Limin Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为GLAD的生成式语言辅助跟踪模型，利用扩散模型进行多模态融合，以解决低语义图像在视觉语言跟踪任务中带来的挑战，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言跟踪方法在处理低语义图像（如模糊、低分辨率图像）时性能受损，而直接融合文本和视觉特征效果有限。需要一种方法来增强低语义图像的语义信息并改善跨模态理解。

Method: 提出了一种名为GLAD（Generative Language-AssisteD tracking）的模型。GLAD利用扩散模型进行生成式多模态融合，将文本描述和模板图像相结合，以提高语言和图像的兼容性，并增强模板图像的语义信息。

Result: GLAD模型在模糊和语义模糊的模板图像上表现出显著的改进，能够恢复图像以增强多模态特征。在多个基准测试中，GLAD取得了新的最先进性能，并且推理速度快。

Conclusion: GLAD模型通过生成式多模态融合有效解决了低语义图像在视觉语言跟踪中的挑战，显著提升了跟踪性能，并有望成为该领域的新标杆。

Abstract: Vision-language tracking has gained increasing attention in many scenarios. This task simultaneously deals with visual and linguistic information to localize objects in videos. Despite its growing utility, the development of vision-language tracking methods remains in its early stage. Current vision-language trackers usually employ Transformer architectures for interactive integration of template, search, and text features. However, persistent challenges about low-semantic images including prevalent image blurriness, low resolution and so on, may compromise model performance through degraded cross-modal understanding. To solve this problem, language assistance is usually used to deal with the obstacles posed by low-semantic images. However, due to the existing gap between current textual and visual features, direct concatenation and fusion of these features may have limited effectiveness. To address these challenges, we introduce a pioneering Generative Language-AssisteD tracking model, GLAD, which utilizes diffusion models for the generative multi-modal fusion of text description and template image to bolster compatibility between language and image and enhance template image semantic information. Our approach demonstrates notable improvements over the existing fusion paradigms. Blurry and semantically ambiguous template images can be restored to improve multi-modal features in the generative fusion paradigm. Experiments show that our method establishes a new state-of-the-art on multiple benchmarks and achieves an impressive inference speed. The code and models will be released at: https://github.com/Confetti-lxy/GLAD

</details>


### [234] [MAUGen: A Unified Diffusion Approach for Multi-Identity Facial Expression and AU Label Generation](https://arxiv.org/abs/2602.00583)
*Xiangdong Li,Ye Lou,Ao Gao,Wei Zhang,Siyang Song*

Main category: cs.CV

TL;DR: 提出了一种名为 MAUGen 的多模态扩散模型，可以根据文本描述生成具有精确 AU（动作单元）出现和强度标注的逼真、多样化的人脸图像，并发布了一个大规模的合成数据集 MIFA。


<details>
  <summary>Details</summary>
Motivation: 现有的 AU 识别系统由于缺乏大规模、人口统计学上多样且具有精确 AU 注释的面部图像数据而受到限制。

Method: 提出了一种基于扩散的多模态框架 MAUGen，包含两个模块：1) 多模态表示学习（MRL）模块，用于在统一的潜在空间中学习文本描述、身份、表情图像和 AU 激活之间的关系；2) 基于扩散的图像标签生成器（DIG）模块，用于从联合表示中解码出对齐的面部图像-标签对。基于此框架，引入了 MIFA 数据集。

Result: MAUGen 能够生成逼真、人口统计学上多样化的面部图像，并附带语义对齐的 AU 标签。实验表明 MAUGen 在合成能力上优于现有方法。

Conclusion: MAUGen 框架能够有效地生成大规模、多样化且带有精确 AU 注释的面部图像，解决了现有 AU 识别系统的数据集瓶颈问题，并为相关研究提供了新的资源。

Abstract: The lack of large-scale, demographically diverse face images with precise Action Unit (AU) occurrence and intensity annotations has long been recognized as a fundamental bottleneck in developing generalizable AU recognition systems. In this paper, we propose MAUGen, a diffusion-based multi-modal framework that jointly generates a large collection of photorealistic facial expressions and anatomically consistent AU labels, including both occurrence and intensity, conditioned on a single descriptive text prompt. Our MAUGen involves two key modules: (1) a Multi-modal Representation Learning (MRL) module that captures the relationships among the paired textual description, facial identity, expression image, and AU activations within a unified latent space; and (2) a Diffusion-based Image label Generator (DIG) that decodes the joint representation into aligned facial image-label pairs across diverse identities. Under this framework, we introduce Multi-Identity Facial Action (MIFA), a large-scale multimodal synthetic dataset featuring comprehensive AU annotations and identity variations. Extensive experiments demonstrate that MAUGen outperforms existing methods in synthesizing photorealistic, demographically diverse facial images along with semantically aligned AU labels.

</details>


### [235] [DuoGen: Towards General Purpose Interleaved Multimodal Generation](https://arxiv.org/abs/2602.00508)
*Min Shi,Xiaohui Zeng,Jiannan Huang,Yin Cui,Francesco Ferroni,Jialuo Li,Shubham Pachori,Zhaoshuo Li,Yogesh Balaji,Haoxiang Wang,Tsung-Yi Lin,Xiao Fu,Yue Zhao,Chieh-Yun Chen,Ming-Yu Liu,Humphrey Shi*

Main category: cs.CV

TL;DR: 本文提出了 DuoGen，一个通用的交错多模态生成框架，通过改进数据收集、模型架构和训练策略，解决了现有模型在处理通用指令时质量有限的问题。DuoGen 在文本质量、图像保真度和图像-上下文对齐方面优于现有模型，并在文本到图像生成和图像编辑任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有交错多模态生成模型的质量受限于训练数据不足和基础模型容量，难以处理通用指令。

Method: DuoGen 采用系统化的数据策划、架构设计和评估方法。数据方面，结合了从精选网站改写的多模态对话和多样化的合成示例。架构方面，利用预训练的多模态大语言模型（MLLM）的视觉理解能力和视频生成扩散转换器（DiT）的视觉生成能力。训练采用两阶段解耦策略：首先对 MLLM 进行指令微调，然后使用精选的交错图像-文本序列将 DiT 与其对齐。

Result: 在公开和新提出的基准测试中，DuoGen 在文本质量、图像保真度以及图像-上下文对齐方面均优于现有开源模型，并且在文本到图像生成和图像编辑任务上达到了统一生成模型的最先进性能。

Conclusion: DuoGen 是一个强大的通用交错多模态生成框架，通过其创新的数据策略和解耦的架构设计，有效地提升了多模态生成任务的质量和性能。

Abstract: Interleaved multimodal generation enables capabilities beyond unimodal generation models, such as step-by-step instructional guides, visual planning, and generating visual drafts for reasoning. However, the quality of existing interleaved generation models under general instructions remains limited by insufficient training data and base model capacity. We present DuoGen, a general-purpose interleaved generation framework that systematically addresses data curation, architecture design, and evaluation. On the data side, we build a large-scale, high-quality instruction-tuning dataset by combining multimodal conversations rewritten from curated raw websites, and diverse synthetic examples covering everyday scenarios. Architecturally, DuoGen leverages the strong visual understanding of a pretrained multimodal LLM and the visual generation capabilities of a diffusion transformer (DiT) pretrained on video generation, avoiding costly unimodal pretraining and enabling flexible base model selection. A two-stage decoupled strategy first instruction-tunes the MLLM, then aligns DiT with it using curated interleaved image-text sequences. Across public and newly proposed benchmarks, DuoGen outperforms prior open-source models in text quality, image fidelity, and image-context alignment, and also achieves state-of-the-art performance on text-to-image and image editing among unified generation models. Data and code will be released at https://research.nvidia.com/labs/dir/duetgen/.

</details>


### [236] [From Pixels to Facts (Pix2Fact): Benchmarking Multi-Hop Reasoning for Fine-Grained Visual Fact Checking](https://arxiv.org/abs/2602.00593)
*Yifan Jiang,Cong Zhang,Bofei Zhang,Yifan Yang,Bingzhang Wang,Yew-Soon Ong*

Main category: cs.CV

TL;DR: 本文提出了Pix2Fact，一个旨在评估视觉语言模型（VLMs）在需要细致视觉理解和复杂知识推理能力的新型基准测试。现有模型在此基准上的表现远低于人类水平，凸显了其在结合细粒度感知和知识推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试将视觉理解和知识推理分开评估，未能捕捉到这两种能力协同工作时的挑战。作者旨在弥合这一差距，创造一个能够衡量VLM在需要结合细致视觉定位和深入知识推理方面的综合能力的新基准。

Method: 创建了一个名为Pix2Fact的新型视觉问答基准。该基准包含1000张高分辨率（4K+）图像，覆盖8个日常生活场景。问题的设计需要细致的视觉定位、多步推理以及整合外部知识。作者还对9个最先进的VLM（包括Gemini-3-Pro和GPT-5）进行了评估。

Result: 在Pix2Fact基准测试中，最先进的VLM平均准确率仅为24.0%，而人类的准确率为56%。这表明现有VLM在处理需要精细视觉理解和知识密集型推理的任务时存在显著的性能差距。

Conclusion: Pix2Fact是一个能够有效评估VLM在细致视觉理解和多步知识推理方面能力的基准。现有模型的表现表明，开发能够整合细粒度感知与鲁棒知识推理能力的新一代多模态智能体仍然是一个重大挑战。Pix2Fact有望推动这一领域的发展。

Abstract: Despite progress on general tasks, VLMs struggle with challenges demanding both detailed visual grounding and deliberate knowledge-based reasoning, a synergy not captured by existing benchmarks that evaluate these skills separately. To close this gap, we introduce Pix2Fact, a new visual question-answering benchmark designed to evaluate expert-level perception and knowledge-intensive multi-hop reasoning. Pix2Fact contains 1,000 high-resolution (4K+) images spanning 8 daily-life scenarios and situations, with questions and answers meticulously crafted by annotators holding PhDs from top global universities working in partnership with a professional data annotation firm. Each question requires detailed visual grounding, multi-hop reasoning, and the integration of external knowledge to answer. Our evaluation of 9 state-of-the-art VLMs, including proprietary models like Gemini-3-Pro and GPT-5, reveals the substantial challenge posed by Pix2Fact: the most advanced model achieves only 24.0% average accuracy, in stark contrast to human performance of 56%. This significant gap underscores the limitations of current models in replicating human-level visual comprehension. We believe Pix2Fact will serve as a critical benchmark to drive the development of next-generation multimodal agents that combine fine-grained perception with robust, knowledge-based reasoning.

</details>


### [237] [Tune-Your-Style: Intensity-tunable 3D Style Transfer with Gaussian Splatting](https://arxiv.org/abs/2602.00618)
*Yian Zhao,Rushi Ye,Ruochong Zheng,Zesen Cheng,Chaoran Feng,Jiashu Yang,Pengchong Qiao,Chang Liu,Jie Chen*

Main category: cs.CV

TL;DR: Tune-Your-Style 提出了一种可调风格强度的 3D 风格迁移方法，允许用户自定义内容与风格的平衡，通过引入高斯神经元和可学习的风格调节器实现，并利用扩散模型和两阶段优化策略进行训练。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 风格迁移方法难以满足用户对内容-风格平衡的不同需求，固定输出模式限制了用户自定义能力。

Method: 引入高斯神经元显式建模风格强度，参数化可学习的风格调节器实现强度可调的风格注入。提出可调风格迁移引导，利用扩散模型生成多视角风格化视图，并通过跨视角风格对齐进行处理。采用两阶段优化策略，平衡全风格引导和零风格引导，实现稳定高效的训练。

Result: Tune-Your-Style 能够生成视觉上吸引人的 3D 风格迁移结果，并表现出灵活的可定制性。

Conclusion: Tune-Your-Style 成功实现了一种可调风格强度的 3D 风格迁移范式，显著提高了 3D 风格迁移的定制化能力，满足了用户对内容-风格平衡的个性化需求。

Abstract: 3D style transfer refers to the artistic stylization of 3D assets based on reference style images. Recently, 3DGS-based stylization methods have drawn considerable attention, primarily due to their markedly enhanced training and rendering speeds. However, a vital challenge for 3D style transfer is to strike a balance between the content and the patterns and colors of the style. Although the existing methods strive to achieve relatively balanced outcomes, the fixed-output paradigm struggles to adapt to the diverse content-style balance requirements from different users. In this work, we introduce a creative intensity-tunable 3D style transfer paradigm, dubbed \textbf{Tune-Your-Style}, which allows users to flexibly adjust the style intensity injected into the scene to match their desired content-style balance, thus enhancing the customizability of 3D style transfer. To achieve this goal, we first introduce Gaussian neurons to explicitly model the style intensity and parameterize a learnable style tuner to achieve intensity-tunable style injection. To facilitate the learning of tunable stylization, we further propose the tunable stylization guidance, which obtains multi-view consistent stylized views from diffusion models through cross-view style alignment, and then employs a two-stage optimization strategy to provide stable and efficient guidance by modulating the balance between full-style guidance from the stylized views and zero-style guidance from the initial rendering. Extensive experiments demonstrate that our method not only delivers visually appealing results, but also exhibits flexible customizability for 3D style transfer. Project page is available at https://zhao-yian.github.io/TuneStyle.

</details>


### [238] [Towards Interpretable Hallucination Analysis and Mitigation in LVLMs via Contrastive Neuron Steering](https://arxiv.org/abs/2602.00621)
*Guangtao Lyu,Xinyi Cheng,Qi Liu,Chenghao Xu,Jiexi Yan,Muli Yang,Fen Fang,Cheng Deng*

Main category: cs.CV

TL;DR: 本研究提出了一种名为对比神经引导（CNS）的新方法，通过分析稀疏自编码器（SAEs）解构的视觉嵌入中的神经元激活模式，来理解和减少大型视觉语言模型（LVLM）的幻觉。CNS通过识别和操纵对图像特异的神经元来提高视觉基础和减少幻觉，并且与现有的解码阶段方法兼容。


<details>
  <summary>Details</summary>
Motivation: 现有的LVLM幻觉缓解方法主要集中在输出层面，而对产生幻觉的内部机制的探索不足。研究旨在通过表示层面（representation-level）的视角，深入理解LVLM幻觉的根源。

Method: 1. 使用稀疏自编码器（SAEs）将密集的视觉嵌入分解为稀疏、可解释的神经元。 2. 对神经元进行分析，识别出“常开神经元”和“图像特异神经元”。 3. 通过增强或抑制图像特异神经元来干预LVLM输出。 4. 提出对比神经引导（CNS），通过对比干净输入和噪声输入的激活，识别图像特异神经元，放大信息神经元，抑制扰动激活。

Result: 1. 幻觉通常源于图像特异神经元的破坏或错误激活，而常开神经元相对稳定。 2. 选择性地增强或抑制图像特异神经元可以控制LVLM输出，改善视觉基础，减少幻觉。 3. CNS能够有效减少幻觉，同时保持整体多模态理解能力。 4. CNS与现有解码阶段方法兼容。

Conclusion: 通过表示层面的分析，特别是利用稀疏自编码器和神经元级别的洞察，研究提出了对比神经引导（CNS）方法，这是一种有效且与现有技术兼容的策略，可以显著减少LVLM的幻觉，同时增强其视觉基础和整体多模态理解能力。

Abstract: LVLMs achieve remarkable multimodal understanding and generation but remain susceptible to hallucinations. Existing mitigation methods predominantly focus on output-level adjustments, leaving the internal mechanisms that give rise to these hallucinations largely unexplored. To gain a deeper understanding, we adopt a representation-level perspective by introducing sparse autoencoders (SAEs) to decompose dense visual embeddings into sparse, interpretable neurons. Through neuron-level analysis, we identify distinct neuron types, including always-on neurons and image-specific neurons. Our findings reveal that hallucinations often result from disruptions or spurious activations of image-specific neurons, while always-on neurons remain largely stable. Moreover, selectively enhancing or suppressing image-specific neurons enables controllable intervention in LVLM outputs, improving visual grounding and reducing hallucinations. Building on these insights, we propose Contrastive Neuron Steering (CNS), which identifies image-specific neurons via contrastive analysis between clean and noisy inputs. CNS selectively amplifies informative neurons while suppressing perturbation-induced activations, producing more robust and semantically grounded visual representations. This not only enhances visual understanding but also effectively mitigates hallucinations. By operating at the prefilling stage, CNS is fully compatible with existing decoding-stage methods. Extensive experiments on both hallucination-focused and general multimodal benchmarks demonstrate that CNS consistently reduces hallucinations while preserving overall multimodal understanding.

</details>


### [239] [FaceSnap: Enhanced ID-fidelity Network for Tuning-free Portrait Customization](https://arxiv.org/abs/2602.00627)
*Benxiang Zhai,Yifang Xu,Guofeng Zhang,Yang Li,Sidan Du*

Main category: cs.CV

TL;DR: FaceSnap 是一种基于 Stable Diffusion 的新方法，仅需单张参考图即可实现个性化、高保真的定制肖像生成，无需耗时微调，并优于现有 SOTA 方法。


<details>
  <summary>Details</summary>
Motivation: 现有定制肖像生成方法存在微调耗时、泛化性差或面部细节保真度不足的问题。

Method: FaceSnap 基于 Stable Diffusion，包含一个 Facial Attribute Mixer 用于提取低级和高级特征，以及一个 Landmark Predictor 用于在不同姿态下保持身份一致性。这些信息通过一个 ID 保持模块注入 UNet。

Result: FaceSnap 在个性化和定制肖像生成方面表现出色，显著优于其他 SOTA 方法。

Conclusion: FaceSnap 是一种高效、高保真的定制肖像生成方法，具有即插即用和易于扩展的优点。

Abstract: Benefiting from the significant advancements in text-to-image diffusion models, research in personalized image generation, particularly customized portrait generation, has also made great strides recently. However, existing methods either require time-consuming fine-tuning and lack generalizability or fail to achieve high fidelity in facial details. To address these issues, we propose FaceSnap, a novel method based on Stable Diffusion (SD) that requires only a single reference image and produces extremely consistent results in a single inference stage. This method is plug-and-play and can be easily extended to different SD models. Specifically, we design a new Facial Attribute Mixer that can extract comprehensive fused information from both low-level specific features and high-level abstract features, providing better guidance for image generation. We also introduce a Landmark Predictor that maintains reference identity across landmarks with different poses, providing diverse yet detailed spatial control conditions for image generation. Then we use an ID-preserving module to inject these into the UNet. Experimental results demonstrate that our approach performs remarkably in personalized and customized portrait generation, surpassing other state-of-the-art methods in this domain.

</details>


### [240] [Any3D-VLA: Enhancing VLA Robustness via Diverse Point Clouds](https://arxiv.org/abs/2602.00807)
*Xianzhe Fan,Shengliang Deng,Xiaoyang Wu,Yuxiang Lu,Zhuoling Li,Mi Yan,Yujia Zhang,Zhizheng Zhang,He Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 本研究提出Any3D-VLA模型，通过融合2D图像和3D点云来提升视觉-语言-动作（VLA）模型在复杂场景下的理解能力，并解决了3D数据稀缺和领域差异的问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要依赖2D图像，缺乏对复杂场景的3D空间理解能力。研究旨在探索如何整合3D信息以增强VLA模型。

Method: 研究首先对比了不同观测空间和视觉表示，发现将2D图像提升为点云能更好地补充2D表示。为解决3D数据稀缺和领域差异（跨环境和深度尺度偏差），提出Any3D-VLA模型，该模型整合了模拟器、传感器和模型估计的点云，构建多样化输入，并通过与2D表示融合来学习领域无关的3D表示。

Result: 通过模拟和真实世界实验证明，Any3D-VLA在提升VLA模型性能和缩小领域差距方面表现出优势。

Conclusion: Any3D-VLA成功地将3D点云信息引入VLA模型，有效克服了3D数据和领域差异的挑战，显著提升了模型的空间理解和泛化能力。

Abstract: Existing Vision-Language-Action (VLA) models typically take 2D images as visual input, which limits their spatial understanding in complex scenes. How can we incorporate 3D information to enhance VLA capabilities? We conduct a pilot study across different observation spaces and visual representations. The results show that explicitly lifting visual input into point clouds yields representations that better complement their corresponding 2D representations. To address the challenges of (1) scarce 3D data and (2) the domain gap induced by cross-environment differences and depth-scale biases, we propose Any3D-VLA. It unifies the simulator, sensor, and model-estimated point clouds within a training pipeline, constructs diverse inputs, and learns domain-agnostic 3D representations that are fused with the corresponding 2D representations. Simulation and real-world experiments demonstrate Any3D-VLA's advantages in improving performance and mitigating the domain gap. Our project homepage is available at https://xianzhefan.github.io/Any3D-VLA.github.io.

</details>


### [241] [S$^3$POT: Contrast-Driven Face Occlusion Segmentation via Self-Supervised Prompt Learning](https://arxiv.org/abs/2602.00635)
*Lingsong Wang,Mancheng Meng,Ziyan Wu,Terrence Chen,Fan Yang,Dinggang Shen*

Main category: cs.CV

TL;DR: 本文提出了一种名为 S$^3$POT 的对比驱动框架，通过融合人脸生成和自监督空间提示来实现遮挡分割，克服了现有方法在处理遮挡时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸解析方法常将遮挡区域错误地归类为面部组件，因为遮挡是一个高层概念，而非具体的对象类别，这使得构建包含所有遮挡类别的真实世界人脸数据集几乎不可能，且精确的掩码标注成本高昂。

Method: S$^3$POT 框架包含三个模块：参考生成 (RF)、特征增强 (FE) 和提示选择 (PS)。RF 利用解析掩码的结构指导生成参考图像；FE 对原始图像和参考图像的 token 进行对比以获取初始提示，并通过交叉注意力修改图像特征；PS 基于增强后的特征，构建正负样本提示，并使用自注意力网络对其进行筛选，以指导掩码解码器。整个框架在没有遮挡真实掩码的情况下，通过三个新颖且互补的目标函数进行学习。

Result: 在专门收集的数据集上进行的广泛实验证明了 S$^3$POT 的卓越性能，并验证了其各个模块的有效性。

Conclusion: S$^3$POT 框架通过结合人脸生成和自监督空间提示，能够有效地进行遮挡分割，克服了现有方法的局限性，并且不需要遮挡区域的真实掩码标注。

Abstract: Existing face parsing methods usually misclassify occlusions as facial components. This is because occlusion is a high-level concept, it does not refer to a concrete category of object. Thus, constructing a real-world face dataset covering all categories of occlusion object is almost impossible and accurate mask annotation is labor-intensive. To deal with the problems, we present S$^3$POT, a contrast-driven framework synergizing face generation with self-supervised spatial prompting, to achieve occlusion segmentation. The framework is inspired by the insights: 1) Modern face generators' ability to realistically reconstruct occluded regions, creating an image that preserve facial geometry while eliminating occlusion, and 2) Foundation segmentation models' (e.g., SAM) capacity to extract precise mask when provided with appropriate prompts. In particular, S$^3$POT consists of three modules: Reference Generation (RF), Feature enhancement (FE), and Prompt Selection (PS). First, a reference image is produced by RF using structural guidance from parsed mask. Second, FE performs contrast of tokens between raw and reference images to obtain an initial prompt, then modifies image features with the prompt by cross-attention. Third, based on the enhanced features, PS constructs a set of positive and negative prompts and screens them with a self-attention network for a mask decoder. The network is learned under the guidance of three novel and complementary objective functions without occlusion ground truth mask involved. Extensive experiments on a dedicatedly collected dataset demonstrate S$^3$POT's superior performance and the effectiveness of each module.

</details>


### [242] [VVLoc: Prior-free 3-DoF Vehicle Visual Localization](https://arxiv.org/abs/2602.00810)
*Ze Huang,Zhongyang Xiao,Mingliang Song,Longan Yang,Hongyuan Yuan,Li Sun*

Main category: cs.CV

TL;DR: 提出了一种名为VVLoc的统一框架，使用单个神经网络同时利用多摄像头系统进行拓扑和度量车辆定位，并提供置信度度量。


<details>
  <summary>Details</summary>
Motivation: 传统方法独立处理拓扑和度量定位，依赖单目相机，需要额外先验信息，且缺乏定位结果的置信度度量，难以满足工业应用需求。

Method: VVLoc首先评估视觉观测之间的地理邻近性，然后使用匹配策略估计相对度量姿态，并提供置信度度量。训练过程仅需视觉数据对和对应的地面真值姿态。

Result: VVLoc在公开数据集和自收集数据上均取得了最先进的定位精度，适用于多种定位任务。

Conclusion: VVLoc是一个高效、统一的车辆定位解决方案，能够同时实现拓扑和度量定位，并量化其置信度，克服了传统方法的局限性，在实际应用中具有潜力。

Abstract: Localization is a critical technology in autonomous driving, encompassing both topological localization, which identifies the most similar map keyframe to the current observation, and metric localization, which provides precise spatial coordinates. Conventional methods typically address these tasks independently, rely on single-camera setups, and often require additional 3D semantic or pose priors, while lacking mechanisms to quantify the confidence of localization results, making them less feasible for real industrial applications. In this paper, we propose VVLoc, a unified pipeline that employs a single neural network to concurrently achieve topological and metric vehicle localization using multi-camera system. VVLoc first evaluates the geo-proximity between visual observations, then estimates their relative metric poses using a matching strategy, while also providing a confidence measure. Additionally, the training process for VVLoc is highly efficient, requiring only pairs of visual data and corresponding ground-truth poses, eliminating the need for complex supplementary data. We evaluate VVLoc not only on the publicly available datasets, but also on a more challenging self-collected dataset, demonstrating its ability to deliver state-of-the-art localization accuracy across a wide range of localization tasks.

</details>


### [243] [VIZOR: Viewpoint-Invariant Zero-Shot Scene Graph Generation for 3D Scene Reasoning](https://arxiv.org/abs/2602.00637)
*Vivek Madhavaram,Vartika Sengar,Arkadipta De,Charu Sharma*

Main category: cs.CV

TL;DR: 本文提出了一种名为 VIZOR 的新框架，用于从原始 3D 场景生成视点不变的 3D 场景图，解决了现有方法在泛化性和空间关系不一致性方面的问题，并在零样本目标定位任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 场景图生成方法在处理不同视点时，空间关系（如“左/右”）会产生不一致，并且泛化能力有限。作者希望开发一种能够生成视点不变且泛化性更好的 3D 场景图的方法。

Method: VIZOR 是一个无需训练、端到端的框架，直接从原始 3D 场景生成密集、视点不变的 3D 场景图。它通过将空间关系定义为相对于每个对象的正面方向来解决视点不一致问题，并能推断开放词汇的关系，无需标注的训练数据。

Result: VIZOR 在场景图生成和下游任务（如基于查询的目标定位）的评估中，性能优于现有最先进的方法。在 Replica 和 Nr3D 数据集上，零样本目标定位的准确率分别提高了 22% 和 4.81%。

Conclusion: VIZOR 成功实现了视点不变的零样本 3D 场景图生成，并有效提升了下游任务的性能，证明了其在 3D 场景理解和推理方面的优势。

Abstract: Scene understanding and reasoning has been a fundamental problem in 3D computer vision, requiring models to identify objects, their properties, and spatial or comparative relationships among the objects. Existing approaches enable this by creating scene graphs using multiple inputs such as 2D images, depth maps, object labels, and annotated relationships from specific reference view. However, these methods often struggle with generalization and produce inaccurate spatial relationships like "left/right", which become inconsistent across different viewpoints. To address these limitations, we propose Viewpoint-Invariant Zero-shot scene graph generation for 3D scene Reasoning (VIZOR). VIZOR is a training-free, end-to-end framework that constructs dense, viewpoint-invariant 3D scene graphs directly from raw 3D scenes. The generated scene graph is unambiguous, as spatial relationships are defined relative to each object's front-facing direction, making them consistent regardless of the reference view. Furthermore, it infers open-vocabulary relationships that describe spatial and proximity relationships among scene objects without requiring annotated training data. We conduct extensive quantitative and qualitative evaluations to assess the effectiveness of VIZOR in scene graph generation and downstream tasks, such as query-based object grounding. VIZOR outperforms state-of-the-art methods, showing clear improvements in scene graph generation and achieving 22% and 4.81% gains in zero-shot grounding accuracy on the Replica and Nr3D datasets, respectively.

</details>


### [244] [Navigating Simply, Aligning Deeply: Winning Solutions for Mouse vs. AI 2025](https://arxiv.org/abs/2602.00982)
*Phu-Hoa Pham,Chi-Nguyen Tran,Dao Sy Duy Minh,Nguyen Lam Phu Quy,Huynh Trung Kiet*

Main category: cs.CV

TL;DR: 本文介绍了NeurIPS 2025鼠类对AI：鲁棒视觉觅食竞赛中，团队HCMUS_TheFangs在两个赛道（视觉鲁棒性和神经对齐）的获胜方法。通过使用简化的CNN和GLU单元，团队在视觉鲁棒性赛道上获得了95.4%的得分。在神经对齐赛道上，一个16层ResNet-like网络实现了顶尖的神经预测性能。研究还发现，训练时长与性能之间存在非单调关系，最优性能出现在约20万步时。


<details>
  <summary>Details</summary>
Motivation: 开发能够匹配生物视觉系统的人工智能代理，在视觉鲁棒性和神经对齐方面仍面临挑战。

Method: 对于视觉鲁棒性赛道，使用了轻量级的两层CNN，并引入了Gated Linear Units（GLU）和观察值归一化。对于神经对齐赛道，开发了一个16层卷积的ResNet-like架构，并使用基于GLU的门控。通过系统分析模型检查点，研究了训练时长对性能的影响，并进行了消融研究和失败案例分析。

Result: 在视觉鲁棒性赛道上，该方法获得了95.4%的最终得分。在神经对齐赛道上，使用1780万参数的模型实现了顶尖的神经预测性能。研究发现，训练时长与性能之间存在非单调关系，最优结果出现在约20万步时。简单的架构更适合视觉鲁棒性，而更深的模型则在神经对齐方面表现更好。

Conclusion: 研究结果挑战了关于视觉运动学习中模型复杂性的传统观点，并为开发鲁棒、受生物启发的视觉代理提供了实际指导。简单的架构在视觉鲁棒性方面表现优越，而更深的网络则在神经对齐方面更有效。

Abstract: Visual robustness and neural alignment remain critical challenges in developing artificial agents that can match biological vision systems. We present the winning approaches from Team HCMUS_TheFangs for both tracks of the NeurIPS 2025 Mouse vs. AI: Robust Visual Foraging Competition. For Track 1 (Visual Robustness), we demonstrate that architectural simplicity combined with targeted components yields superior generalization, achieving 95.4% final score with a lightweight two-layer CNN enhanced by Gated Linear Units and observation normalization. For Track 2 (Neural Alignment), we develop a deep ResNet-like architecture with 16 convolutional layers and GLU-based gating that achieves top-1 neural prediction performance with 17.8 million parameters. Our systematic analysis of ten model checkpoints trained between 60K to 1.14M steps reveals that training duration exhibits a non-monotonic relationship with performance, with optimal results achieved around 200K steps. Through comprehensive ablation studies and failure case analysis, we provide insights into why simpler architectures excel at visual robustness while deeper models with increased capacity achieve better neural alignment. Our results challenge conventional assumptions about model complexity in visuomotor learning and offer practical guidance for developing robust, biologically-inspired visual agents.

</details>


### [245] [Diff-PC: Identity-preserving and 3D-aware Controllable Diffusion for Zero-shot Portrait Customization](https://arxiv.org/abs/2602.00639)
*Yifang Xu,Benxiang Zhai,Chenyu Zhang,Ming Li,Yang Li,Sidan Du*

Main category: cs.CV

TL;DR: 本文提出了一种名为Diff-PC的基于扩散模型的零样本肖像定制框架，该框架在身份保持和面部控制方面取得了显著进展，能够生成具有高身份保真度、指定面部属性和多样化背景的逼真肖像。


<details>
  <summary>Details</summary>
Motivation: 现有肖像定制方法在身份保持和面部控制方面存在不足，需要更精确的身份识别和面部表情/姿态控制能力。

Method: 该方法利用3D面部预测器重建3D面部先验（包括身份、表情、姿态），设计了ID-Encoder融合面部细节特征，并使用ID-Ctrl通过3D面部指导身份特征对齐，最后通过ID-Injector增强身份保真度和面部可控性。该方法还在一个专门收集的、以身份为中心的（ID-centric）数据集上进行训练。

Result: Diff-PC在身份保持、面部控制和文本到图像（T2I）一致性方面超越了现有最先进的方法，并且与多风格基础模型兼容。

Conclusion: Diff-PC是一个有效的零样本肖像定制框架，通过整合3D面部先验和创新的ID特征处理模块，显著提升了肖像定制的身份保真度和面部可控性，并能生成高质量、多样化的定制肖像。

Abstract: Portrait customization (PC) has recently garnered significant attention due to its potential applications. However, existing PC methods lack precise identity (ID) preservation and face control. To address these tissues, we propose Diff-PC, a diffusion-based framework for zero-shot PC, which generates realistic portraits with high ID fidelity, specified facial attributes, and diverse backgrounds. Specifically, our approach employs the 3D face predictor to reconstruct the 3D-aware facial priors encompassing the reference ID, target expressions, and poses. To capture fine-grained face details, we design ID-Encoder that fuses local and global facial features. Subsequently, we devise ID-Ctrl using the 3D face to guide the alignment of ID features. We further introduce ID-Injector to enhance ID fidelity and facial controllability. Finally, training on our collected ID-centric dataset improves face similarity and text-to-image (T2I) alignment. Extensive experiments demonstrate that Diff-PC surpasses state-of-the-art methods in ID preservation, facial control, and T2I consistency. Furthermore, our method is compatible with multi-style foundation models.

</details>


### [246] [Improving Robustness of Vision-Language-Action Models by Restoring Corrupted Visual Inputs](https://arxiv.org/abs/2602.01158)
*Daniel Yezid Guarnizo Orjuela,Leonardo Scappatura,Veronica Di Gennaro,Riccardo Andrea Izzo,Gianluca Bardaro,Matteo Matteucci*

Main category: cs.CV

TL;DR: 本文提出了一种名为Corruption Restoration Transformer (CRT) 的即插即用模型，用于增强视觉-语言-动作（VLA）模型在存在图像损坏（如噪声、坏点、污渍）时的鲁棒性。CRT通过对抗性训练恢复干净的图像，无需微调现有VLA模型，实验证明其能有效恢复VLA模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在真实世界部署中容易受到视觉干扰（图像损坏）的影响，而这方面的研究尚不充分。研究人员希望解决VLA模型在这种干扰下的性能下降问题。

Method: 提出了一种名为Corruption Restoration Transformer (CRT) 的即插即用、模型无关的视觉Transformer。CRT利用对抗性训练目标，从损坏的输入中恢复干净的观测，而无需对底层的VLA模型进行计算昂贵的微调。

Result: 在LIBERO和Meta-World基准测试的广泛实验中，CRT能够有效地恢复性能下降的VLA模型，使其在严重视觉损坏下仍能保持接近基线水平的成功率。实验表明，与未改进的SOTA VLA模型（如$π_{0.5}$和SmolVLA）相比，CRT将成功率从低至2%提高到90%以上。

Conclusion: CRT是一种有效的、即插即用的解决方案，可以显著提高VLA模型对图像损坏的鲁棒性，使其在真实世界的应用中更加可靠。

Abstract: Vision-Language-Action (VLA) models have emerged as a dominant paradigm for generalist robotic manipulation, unifying perception and control within a single end-to-end architecture. However, despite their success in controlled environments, reliable real-world deployment is severely hindered by their fragility to visual disturbances. While existing literature extensively addresses physical occlusions caused by scene geometry, a critical mode remains largely unexplored: image corruptions. These sensor-level artifacts, ranging from electronic noise and dead pixels to lens contaminants, directly compromise the integrity of the visual signal prior to interpretation. In this work, we quantify this vulnerability, demonstrating that state-of-the-art VLAs such as $π_{0.5}$ and SmolVLA, suffer catastrophic performance degradation, dropping from 90\% success rates to as low as 2\%, under common signal artifacts. To mitigate this, we introduce the Corruption Restoration Transformer (CRT), a plug-and-play and model-agnostic vision transformer designed to immunize VLA models against sensor disturbances. Leveraging an adversarial training objective, CRT restores clean observations from corrupted inputs without requiring computationally expensive fine-tuning of the underlying model. Extensive experiments across the LIBERO and Meta-World benchmarks demonstrate that CRT effectively recovers lost performance, enabling VLAs to maintain near-baseline success rates, even under severe visual corruption.

</details>


### [247] [A Hybrid Mamba-SAM Architecture for Efficient 3D Medical Image Segmentation](https://arxiv.org/abs/2602.00650)
*Mohammadreza Gholipour Shahraki,Mehdi Rezaeian,Mohammad Ghasemzadeh*

Main category: cs.CV

TL;DR: 提出了一种名为Mamba-SAM的混合模型，用于3D医学图像分割，它结合了SAM的通用性和Mamba的效率，并采用了两种参数高效的适应策略，实验结果表明其在分割精度和推理速度上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的通用基础模型（如SAM）在3D医学图像分割领域存在域转移、2D设计和高昂微调成本等问题，需要一种更高效、更适应3D医学数据的解决方案。

Method: 提出Mamba-SAM混合架构，将冻结的SAM编码器与基于Mamba的SSMs结合。采用两种参数高效适应策略：1. 双分支架构，融合SAM通用特征和可训练VMamba的领域特定特征；2. 适配器方法，将3D感知的TPMamba模块注入SAM编码器。引入MFGC增强特征表示。在ACDC数据集上进行实验。

Result: Mamba-SAM-Base在ACDC数据集上实现了0.906的平均Dice分数，Myocardium分割为0.910，Left Ventricle分割为0.971。TP MFGC变体在0.880 Dice分数下实现了4.77 FPS的推理速度。

Conclusion: 将基础模型与高效的SSM架构相结合，为3D医学图像分割提供了一种实用且有效的解决方案，能够平衡分割精度和推理效率。

Abstract: Accurate segmentation of 3D medical images such as MRI and CT is essential for clinical diagnosis and treatment planning. Foundation models like the Segment Anything Model (SAM) provide powerful general-purpose representations but struggle in medical imaging due to domain shift, their inherently 2D design, and the high computational cost of fine-tuning. To address these challenges, we propose Mamba-SAM, a novel and efficient hybrid architecture that combines a frozen SAM encoder with the linear-time efficiency and long-range modeling capabilities of Mamba-based State Space Models (SSMs). We investigate two parameter-efficient adaptation strategies. The first is a dual-branch architecture that explicitly fuses general features from a frozen SAM encoder with domain-specific representations learned by a trainable VMamba encoder using cross-attention. The second is an adapter-based approach that injects lightweight, 3D-aware Tri-Plane Mamba (TPMamba) modules into the frozen SAM ViT encoder to implicitly model volumetric context. Within this framework, we introduce Multi-Frequency Gated Convolution (MFGC), which enhances feature representation by jointly analyzing spatial and frequency-domain information via 3D discrete cosine transforms and adaptive gating. Extensive experiments on the ACDC cardiac MRI dataset demonstrate the effectiveness of the proposed methods. The dual-branch Mamba-SAM-Base model achieves a mean Dice score of 0.906, comparable to UNet++ (0.907), while outperforming all baselines on Myocardium (0.910) and Left Ventricle (0.971) segmentation. The adapter-based TP MFGC variant offers superior inference speed (4.77 FPS) with strong accuracy (0.880 Dice). These results show that hybridizing foundation models with efficient SSM-based architectures provides a practical and effective solution for 3D medical image segmentation.

</details>


### [248] [OASIS-DC: Generalizable Depth Completion via Output-level Alignment of Sparse-Integrated Monocular Pseudo Depth](https://arxiv.org/abs/2602.01268)
*Jaehyeon Cho,Jhonghyun An*

Main category: cs.CV

TL;DR: 本研究提出了一种方法，通过结合预训练的单目深度估计模型（提供相对深度信息）和少量的稀疏测距测量（提供度量信息），从而实现准确的度量深度估计。该方法在标签数据稀缺的情况下尤为有效。


<details>
  <summary>Details</summary>
Motivation: 现有的单目深度估计模型只能输出相对深度，这限制了它们在机器人和自动驾驶等需要精确度量深度的领域的应用。研究旨在解决这一限制，使其在实际应用中更具可用性。

Method: 研究人员利用了相对深度能够保留全局布局和边界的特性，并将其与稀疏的测距测量相结合，生成一个伪度量深度先验。在此基础上，设计了一个精炼网络，该网络在先验可靠的地方遵循先验，在必要时进行调整，从而实现从少量标记样本中进行精确的度量深度预测。

Result: 该系统在标签数据稀缺的情况下表现出色，能够稳定地保持深度尺度并保持清晰的边缘。即使在只有少量标记样本的情况下，也能取得良好的效果。

Conclusion: 将基础模型的先验信息与稀疏的锚点（稀疏测距测量）相结合，是一种在真实世界标签稀缺的情况下实现鲁棒、可部署的深度补全的实用途径。

Abstract: Recent monocular foundation models excel at zero-shot depth estimation, yet their outputs are inherently relative rather than metric, limiting direct use in robotics and autonomous driving. We leverage the fact that relative depth preserves global layout and boundaries: by calibrating it with sparse range measurements, we transform it into a pseudo metric depth prior. Building on this prior, we design a refinement network that follows the prior where reliable and deviates where necessary, enabling accurate metric predictions from very few labeled samples. The resulting system is particularly effective when curated validation data are unavailable, sustaining stable scale and sharp edges across few-shot regimes. These findings suggest that coupling foundation priors with sparse anchors is a practical route to robust, deployment-ready depth completion under real-world label scarcity.

</details>


### [249] [Real-Time Loop Closure Detection in Visual SLAM via NetVLAD and Faiss](https://arxiv.org/abs/2602.01673)
*Enguang Fan*

Main category: cs.CV

TL;DR: 研究表明，使用Faiss加速的NetVLAD在KITTI数据集上可以实时运行，并且在回环闭合检测（LCD）任务上比传统的DBoW方法更准确、更鲁棒，可以作为SLAM系统的即插即用替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统的基于词袋模型的回环闭合检测方法（如DBoW）在外观变化和感知混淆的情况下性能下降，而基于深度学习的方法虽然鲁棒性更强，但计算成本高昂，阻碍了其实时应用。研究旨在探索NetVLAD作为LCD模块的可行性，并评估其在实时SLAM中的性能。

Method: 使用KITTI数据集，将NetVLAD与DBoW进行对比评估。引入了精细化的Top-K精确率-召回率曲线来更准确地反映LCD场景。利用Faiss加速最近邻搜索，以实现NetVLAD的实时查询速度。

Result: 在KITTI数据集上，NetVLAD通过Faiss加速后，实现了实时查询速度。与DBoW相比，NetVLAD在准确性和鲁棒性方面均有提升。

Conclusion: NetVLAD经过Faiss加速后，是一种实时的、在回环闭合检测方面比DBoW更优越的替代方案，可以方便地集成到SLAM系统中。

Abstract: Loop closure detection (LCD) is a core component of simultaneous localization and mapping (SLAM): it identifies revisited places and enables pose-graph constraints that correct accumulated drift. Classic bag-of-words approaches such as DBoW are efficient but often degrade under appearance change and perceptual aliasing. In parallel, deep learning-based visual place recognition (VPR) descriptors (e.g., NetVLAD and Transformer-based models) offer stronger robustness, but their computational cost is often viewed as a barrier to real-time SLAM. In this paper, we empirically evaluate NetVLAD as an LCD module and compare it against DBoW on the KITTI dataset. We introduce a Fine-Grained Top-K precision-recall curve that better reflects LCD settings where a query may have zero or multiple valid matches. With Faiss-accelerated nearestneighbor search, NetVLAD achieves real-time query speed while improving accuracy and robustness over DBoW, making it a practical drop-in alternative for LCD in SLAM.

</details>


### [250] [Non-Contrastive Vision-Language Learning with Predictive Embedding Alignment](https://arxiv.org/abs/2602.00653)
*Lukas Kuhn,Giuseppe Serra,Florian Buettner*

Main category: cs.CV

TL;DR: 本文提出了一种名为NOVA的非对比式视觉语言对齐框架，通过联合嵌入预测和分布正则化，无需负样本、动量编码器或停止梯度，即可实现视觉表示与冻结文本编码器的对齐，并在零样本X射线分类任务上取得了优于对比式方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的主流对比式视觉语言模型（如CLIP）在训练时需要大批量、精心设计的负样本以及大量的超参数调优，这限制了其可用性和稳定性。研究者希望找到一种更简单、更稳定、更有效的替代方案。

Method: NOVA框架基于联合嵌入预测，通过预测文本嵌入来对齐视觉表示。它使用增强的图像视图，并引入了草图各向同性高斯正则化（SIGReg）来强制嵌入具有各向同性的高斯结构。该方法不需要负样本、动量编码器或停止梯度，训练目标只有一个超参数。

Result: 在零样本胸部X射线分类任务上，使用ClinicalBERT作为文本编码器，并在MIMIC-CXR数据集上从头训练Vision Transformers，NOVA在三个基准数据集上的零样本分类性能优于多种标准基线方法。此外，NOVA的训练过程表现出显著更一致的稳定性。

Conclusion: 非对比式视觉语言预训练（NOVA）提供了一种比对比式方法更简单、更稳定、更有效的替代方案，能够有效地进行视觉语言对齐，并在特定任务上取得优异的零样本性能。

Abstract: Vision-language models have transformed multimodal representation learning, yet dominant contrastive approaches like CLIP require large batch sizes, careful negative sampling, and extensive hyperparameter tuning. We introduce NOVA, a NOn-contrastive Vision-language Alignment framework based on joint embedding prediction with distributional regularization. NOVA aligns visual representations to a frozen, domain-specific text encoder by predicting text embeddings from augmented image views, while enforcing an isotropic Gaussian structure via Sketched Isotropic Gaussian Regularization (SIGReg). This eliminates the need for negative sampling, momentum encoders, or stop-gradients, reducing the training objective to a single hyperparameter. We evaluate NOVA on zeroshot chest X-ray classification using ClinicalBERT as the text encoder and Vision Transformers trained from scratch on MIMIC-CXR. On zero-shot classification across three benchmark datasets, NOVA outperforms multiple standard baselines while exhibiting substantially more consistent training runs. Our results demonstrate that non-contrastive vision-language pretraining offers a simpler, more stable, and more effective alternative to contrastive methods.

</details>


### [251] [DDP-WM: Disentangled Dynamics Prediction for Efficient World Models](https://arxiv.org/abs/2602.01780)
*Shicheng Yin,Kaixuan Yin,Weixing Chen,Yang Liu,Guanbin Li,Liang Lin*

Main category: cs.CV

TL;DR: 本文提出了一种名为DDP-WM的新型世界模型，它通过解耦动力学预测来提高效率和性能，适用于机器人规划任务。实验证明，DDP-WM在推理速度和成功率方面均优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的密集世界模型计算开销大，阻碍了其在机器人规划中的实时部署。研究旨在解决效率-性能的瓶颈问题。

Method: DDP-WM基于解耦动力学预测（DDP）原理，将潜状态演化分解为稀疏的物理交互驱动的原生动力学和上下文驱动的背景更新。该模型通过高效的历史处理与动态定位相结合的架构来实现这种分解，并使用交叉注意力机制处理背景更新。

Result: DDP-WM在导航、桌面操作、可变形物体交互等多种任务中展现出显著的效率和性能提升。在Push-T任务上，DDP-WM实现了约9倍的推理速度提升，并将MPC成功率从90%提高到98%。

Conclusion: DDP-WM提供了一种开发高效、高保真世界模型的新途径，有望推动机器人规划领域的发展。

Abstract: World models are essential for autonomous robotic planning. However, the substantial computational overhead of existing dense Transformerbased models significantly hinders real-time deployment. To address this efficiency-performance bottleneck, we introduce DDP-WM, a novel world model centered on the principle of Disentangled Dynamics Prediction (DDP). We hypothesize that latent state evolution in observed scenes is heterogeneous and can be decomposed into sparse primary dynamics driven by physical interactions and secondary context-driven background updates. DDP-WM realizes this decomposition through an architecture that integrates efficient historical processing with dynamic localization to isolate primary dynamics. By employing a crossattention mechanism for background updates, the framework optimizes resource allocation and provides a smooth optimization landscape for planners. Extensive experiments demonstrate that DDP-WM achieves significant efficiency and performance across diverse tasks, including navigation, precise tabletop manipulation, and complex deformable or multi-body interactions. Specifically, on the challenging Push-T task, DDP-WM achieves an approximately 9 times inference speedup and improves the MPC success rate from 90% to98% compared to state-of-the-art dense models. The results establish a promising path for developing efficient, high-fidelity world models. Codes will be available at https://github.com/HCPLabSYSU/DDP-WM.

</details>


### [252] [Schrödinger-Inspired Time-Evolution for 4D Deformation Forecasting](https://arxiv.org/abs/2602.00661)
*Ahsan Raza Siyal,Markus Haltmeier,Ruth Steiger,Elke Ruth Gizewski,Astrid Ellen Grams*

Main category: cs.CV

TL;DR: 本文提出了一种受薛定谔方程启发的、物理引导的神经网络架构，用于对四维（3D+时间）复杂现象进行时空预测。该模型通过学习复值波函数的振幅、相位和势场，并使用可微的薛定谔时间步进器进行演化，实现了时间稳定、可解释的预测，并能自然地处理形变合成，尤其适用于医学成像。


<details>
  <summary>Details</summary>
Motivation: 现有的无约束神经预测模型在预测长时域的四维现象时存在漂移和误差累积的问题。需要一种能够结合深度学习的表达能力和物理模型鲁棒性、可解释性的预测框架，尤其是在需要保持解剖学保真度的医学成像领域。

Method: 提出了一种基于薛定谔方程的物理引导神经网络架构，将显式的时间演化算子嵌入到深度卷积框架中。模型学习复值波函数 $ψ= A e^{iφ}$ 的振幅（A）、相位（φ）和势场，并通过可微的、展开的薛定谔时间步进器进行时间演化。模型能够学习体素级别的振幅、相位和势场。

Result: 该方法在合成基准测试中实现了对未来四维状态（包括体积强度和形变场）的准确且稳定的预测，能够处理形状变形和拓扑变化。该方法展示了时间稳定性、可解释的潜在表示（相位编码传输动力学，振幅捕捉结构强度，势场控制时空交互）以及与形变合成的兼容性。

Conclusion: 将物理先验直接整合到学习过程中，该方法结合了深度网络的表达能力与基于物理的模型所提供的鲁棒性和可解释性。这是第一个集成薛定谔类型演化算子的端到端四维神经预测框架，为实现可解释、稳定且解剖学上一致的时空预测提供了一种原则性的方法。

Abstract: Spatiotemporal forecasting of complex three-dimensional phenomena (4D: 3D + time) is fundamental to applications in medical imaging, fluid and material dynamics, and geophysics. In contrast to unconstrained neural forecasting models, we propose a Schrödinger-inspired, physics-guided neural architecture that embeds an explicit time-evolution operator within a deep convolutional framework for 4D prediction. From observed volumetric sequences, the model learns voxelwise amplitude, phase, and potential fields that define a complex-valued wavefunction $ψ= A e^{iφ}$, which is evolved forward in time using a differentiable, unrolled Schrödinger time stepper. This physics-guided formulation yields several key advantages: (i) temporal stability arising from the structured evolution operator, which mitigates drift and error accumulation in long-horizon forecasting; (ii) an interpretable latent representation, where phase encodes transport dynamics, amplitude captures structural intensity, and the learned potential governs spatiotemporal interactions; and (iii) natural compatibility with deformation-based synthesis, which is critical for preserving anatomical fidelity in medical imaging applications. By integrating physical priors directly into the learning process, the proposed approach combines the expressivity of deep networks with the robustness and interpretability of physics-based modeling. We demonstrate accurate and stable prediction of future 4D states, including volumetric intensities and deformation fields, on synthetic benchmarks that emulate realistic shape deformations and topological changes. To our knowledge, this is the first end-to-end 4D neural forecasting framework to incorporate a Schrödinger-type evolution operator, offering a principled pathway toward interpretable, stable, and anatomically consistent spatiotemporal prediction.

</details>


### [253] [Improving Neuropathological Reconstruction Fidelity via AI Slice Imputation](https://arxiv.org/abs/2602.00669)
*Marina Crespo Aguirre,Jonathan Williams-Ramirez,Dina Zemlyanker,Xiaoling Hu,Lucas J. Deden-Binder,Rogeny Herisse,Mark Montine,Theresa R. Connors,Christopher Mount,Christine L. MacDonald,C. Dirk Keene,Caitlin S. Latimer,Derek H. Oakley,Bradley T. Hyman,Ana Lawry Aguila,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 本文提出了一种计算高效的超分辨率方法，用于从2D解剖照片重建的各向异性3D大脑体积生成各向同性的、解剖学上一致的体积。该方法通过在域随机化的合成数据上进行训练，提高了自动分割、表面重建和MRI配准的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有从2D解剖照片重建3D大脑体积的方法，特别是在高各向异性（厚切片）的情况下，会产生粗糙、过于平滑的结构重建。研究的动机是提高这些重建的空间精度和形态学准确性。

Method: 本文提出了一种计算高效的超分辨率方法，该方法通过插值切片来生成解剖学上一致的各向同性体积，用于从解剖照片的各向异性3D重建。该方法在域随机化的合成数据上进行训练，以确保泛化能力和对不同解剖方案及厚切片的鲁棒性。

Result: 该方法生成的插值体积在自动分割任务上取得了更高的Dice分数，尤其是在皮层和白质区域。在表面重建和图谱配准任务上的验证也显示出更精确的皮层表面和MRI配准。

Conclusion: 通过提高基于照片重建的体素分辨率和解剖保真度，本文的方法加强了神经病理学和神经影像学之间的联系。该方法能够生成更准确、更精细的大脑体积重建，有利于后续的分析和研究。

Abstract: Neuropathological analyses benefit from spatially precise volumetric reconstructions that enhance anatomical delineation and improve morphometric accuracy. Our prior work has shown the feasibility of reconstructing 3D brain volumes from 2D dissection photographs. However these outputs sometimes exhibit coarse, overly smooth reconstructions of structures, especially under high anisotropy (i.e., reconstructions from thick slabs). Here, we introduce a computationally efficient super-resolution step that imputes slices to generate anatomically consistent isotropic volumes from anisotropic 3D reconstructions of dissection photographs. By training on domain-randomized synthetic data, we ensure that our method generalizes across dissection protocols and remains robust to large slab thicknesses. The imputed volumes yield improved automated segmentations, achieving higher Dice scores, particularly in cortical and white matter regions. Validation on surface reconstruction and atlas registration tasks demonstrates more accurate cortical surfaces and MRI registration. By enhancing the resolution and anatomical fidelity of photograph-based reconstructions, our approach strengthens the bridge between neuropathology and neuroimaging. Our method is publicly available at https://surfer.nmr.mgh.harvard.edu/fswiki/mri_3d_photo_recon

</details>


### [254] [LangMap: A Hierarchical Benchmark for Open-Vocabulary Goal Navigation](https://arxiv.org/abs/2602.02220)
*Bo Miao,Weijia Liu,Jun Luo,Lachlan Shinnick,Jian Liu,Thomas Hamilton-Smith,Yuhe Yang,Zijie Wu,Vanja Videnovic,Feras Dayoub,Anton van den Hengel*

Main category: cs.CV

TL;DR: 研究提出了一种名为 HieraNav 的多粒度、开放词汇目标导航任务，并构建了一个名为 LangMap 的大型基准，用于评估智能体根据自然语言指令在不同语义级别（场景、房间、区域、实例）导航的能力。LangMap 在真实 3D 室内扫描数据上构建，包含丰富的标注和超过 18,000 个导航任务，旨在促进语言驱动的具身导航研究。


<details>
  <summary>Details</summary>
Motivation: 当前 AI 在理解物体与语言关系以及实现有意义的通信和具身智能方面存在不足，现有研究缺乏能评估智能体在不同粒度下理解语言指令进行导航的基准。

Method: 提出了 HieraNav 任务，该任务要求智能体根据自然语言指令在场景、房间、区域和实例四个语义级别上导航到目标。构建了 LangMap 基准，其包含真实 3D 室内扫描数据、区域标签、描述性区域和实例描述（涵盖 414 类物体），以及超过 18,000 个导航任务，每个任务都有简洁和详细的描述。在 LangMap 上对零样本和监督模型进行了评估。

Result: LangMap 在区分性准确性上优于 GOAT-Bench（减少了 23.8% 的词汇量）。评估结果表明，更丰富的上下文和记忆有助于提高导航成功率，但长尾、小型、依赖上下文和远距离的目标以及多目标完成仍然是挑战。

Conclusion: HieraNav 任务和 LangMap 基准提供了一个严格的测试平台，能够推动语言驱动的具身导航领域的研究进展。

Abstract: The relationships between objects and language are fundamental to meaningful communication between humans and AI, and to practically useful embodied intelligence. We introduce HieraNav, a multi-granularity, open-vocabulary goal navigation task where agents interpret natural language instructions to reach targets at four semantic levels: scene, room, region, and instance. To this end, we present Language as a Map (LangMap), a large-scale benchmark built on real-world 3D indoor scans with comprehensive human-verified annotations and tasks spanning these levels. LangMap provides region labels, discriminative region descriptions, discriminative instance descriptions covering 414 object categories, and over 18K navigation tasks. Each target features both concise and detailed descriptions, enabling evaluation across different instruction styles. LangMap achieves superior annotation quality, outperforming GOAT-Bench by 23.8% in discriminative accuracy using four times fewer words. Comprehensive evaluations of zero-shot and supervised models on LangMap reveal that richer context and memory improve success, while long-tailed, small, context-dependent, and distant goals, as well as multi-goal completion, remain challenging. HieraNav and LangMap establish a rigorous testbed for advancing language-driven embodied navigation. Project: https://bo-miao.github.io/LangMap

</details>


### [255] [HPC: Hierarchical Point-based Latent Representation for Streaming Dynamic Gaussian Splatting Compression](https://arxiv.org/abs/2602.00671)
*Yangzhi Ma,Bojun Liu,Wenting Liao,Dong Liu,Zhu Li,Li Li*

Main category: cs.CV

TL;DR: 提出了一种名为HPC的新型流式动态高斯渲染压缩框架，通过分层点式潜在表示和对神经网络参数的压缩，显著提高了压缩效率和重建保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的流式动态高斯渲染压缩方法在保持渲染质量的同时，难以满足内存占用小和高效流式传输的要求。现有的潜在表示方法存在参数冗余或紧凑性不足的问题。

Method: 提出了一种分层点式潜在表示，以每个高斯点为基础，避免了对未占用空间的建模，从而减少了参数冗余。采用定制的聚合方案提高了潜在点的紧凑性。首次研究了通过挖掘和利用参数间的帧间相关性来压缩用于流式动态高斯渲染的神经网络，并将其与潜在表示压缩结合，形成端到端压缩框架。

Result: HPC在存储占用方面比基线方法减少了67%，同时保持了高重建保真度。实验表明，HPC显著优于现有最先进的方法。

Conclusion: HPC框架通过其创新的分层点式潜在表示和对神经网络参数的压缩，有效解决了流式动态高斯渲染的压缩难题，实现了高效率和高质量的平衡。

Abstract: While dynamic Gaussian Splatting has driven significant advances in free-viewpoint video, maintaining its rendering quality with a small memory footprint for efficient streaming transmission still presents an ongoing challenge. Existing streaming dynamic Gaussian Splatting compression methods typically leverage a latent representation to drive the neural network for predicting Gaussian residuals between frames. Their core latent representations can be categorized into structured grid-based and unstructured point-based paradigms. However, the former incurs significant parameter redundancy by inevitably modeling unoccupied space, while the latter suffers from limited compactness as it fails to exploit local correlations. To relieve these limitations, we propose HPC, a novel streaming dynamic Gaussian Splatting compression framework. It employs a hierarchical point-based latent representation that operates on a per-Gaussian basis to avoid parameter redundancy in unoccupied space. Guided by a tailored aggregation scheme, these latent points achieve high compactness with low spatial redundancy. To improve compression efficiency, we further undertake the first investigation to compress neural networks for streaming dynamic Gaussian Splatting through mining and exploiting the inter-frame correlation of parameters. Combined with latent compression, this forms a fully end-to-end compression framework. Comprehensive experimental evaluations demonstrate that HPC substantially outperforms state-of-the-art methods. It achieves a storage reduction of 67% against its baseline while maintaining high reconstruction fidelity.

</details>


### [256] [Bridging Degradation Discrimination and Generation for Universal Image Restoration](https://arxiv.org/abs/2602.00579)
*JiaKui Hu,Zhengjian Yao,Lujia Jin,Yanye Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为 BDG (Bridging Degradation discrimination and Generation) 的新方法，通过多角度多尺度灰度共生矩阵 (MAS-GLCM) 进行细粒度退化判别，并结合三阶段扩散模型训练（生成、桥接、恢复），实现了在不改变模型架构的情况下，提升了图像复原的性能，特别是在多任务和多退化场景下。


<details>
  <summary>Details</summary>
Motivation: 现有的通用图像复原方法在处理多样的图像退化类型和级别时面临挑战，尤其是在同时保持生成高分辨率细节和适应不同退化方面。

Method: 1. 提出多角度多尺度灰度共生矩阵 (MAS-GLCM) 以实现对退化类型和级别的精细判别。 2. 将扩散模型训练分为三个阶段：生成（学习高分辨率图像分布）、桥接（整合 MAS-GLCM 判别信息）和恢复（利用桥接信息进行图像复原）。

Result: 在不改变模型架构的前提下，BDG 在全能复原和真实世界超分辨率任务上取得了显著的性能提升，主要体现在保真度的提高，同时不牺牲感知质量。

Conclusion: BDG 方法成功地将退化判别信息有效地融入到扩散模型的生成过程中，提升了模型在处理复杂和多样的图像复原任务的能力，实现了在保真度和感知质量之间的良好平衡。

Abstract: Universal image restoration is a critical task in low-level vision, requiring the model to remove various degradations from low-quality images to produce clean images with rich detail. The challenges lie in sampling the distribution of high-quality images and adjusting the outputs on the basis of the degradation. This paper presents a novel approach, Bridging Degradation discrimination and Generation (BDG), which aims to address these challenges concurrently. First, we propose the Multi-Angle and multi-Scale Gray Level Co-occurrence Matrix (MAS-GLCM) and demonstrate its effectiveness in performing fine-grained discrimination of degradation types and levels. Subsequently, we divide the diffusion training process into three distinct stages: generation, bridging, and restoration. The objective is to preserve the diffusion model's capability of restoring rich textures while simultaneously integrating the discriminative information from the MAS-GLCM into the restoration process. This enhances its proficiency in addressing multi-task and multi-degraded scenarios. Without changing the architecture, BDG achieves significant performance gains in all-in-one restoration and real-world super-resolution tasks, primarily evidenced by substantial improvements in fidelity without compromising perceptual quality. The code and pretrained models are provided in https://github.com/MILab-PKU/BDG.

</details>


### [257] [Video Understanding: Through A Temporal Lens](https://arxiv.org/abs/2602.00683)
*Thong Thanh Nguyen*

Main category: cs.CV

TL;DR: 该论文提出了一种利用视频元素间的时间关系来改进视频理解的五种方法，包括自动标注框架、参数高效微调策略、状态空间层用于长视频建模、对比学习框架显式建模运动与时刻的关系，以及对大型视觉-语言模型（LVLMs）的实证研究。结果表明，显式的时间建模能显著提升视频内容的表示和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解方法在利用视频元素间的时间关系方面存在局限性，需要更有效的方法来捕捉和利用这些动态信息。

Method: 该研究提出了五种贡献：1. 一个结合大型视觉-语言模型和噪声鲁棒对比学习的自动标注框架。2. 使用“循环适配器”进行参数高效微调，以应对低数据情况下的时间动态。3. 集成状态空间层（SSL）并引入新的长视频基准，用于长格式视频建模。4. 一个显式建模运动与视频时刻之间细粒度关系的新对比学习框架。5. 对LVLMs进行实证研究，识别出视觉-语言接口是时间推理的瓶颈，并提出一个“面向时间”的改进方案。

Result: 通过显式的时间建模，研究证明可以显著增强模型表示和推理视频内容流体性质的能力。对LVLMs的研究表明，视觉-语言接口是时间推理的瓶颈。

Conclusion: 显式地建模视频元素间的时间关系是提升视频理解能力的关键。通过提出的多种方法，包括新的框架、技术和基准，可以有效解决现有方法的局限性，并促进更强大的视频理解模型的发展。

Abstract: This thesis explores the central question of how to leverage temporal relations among video elements to advance video understanding. Addressing the limitations of existing methods, the work presents a five-fold contribution: (1) an automatic annotation framework that utilizes large vision-language models and a noise-robust contrastive learning objective with a subtractive angular margin; (2) a parameter-efficient fine-tuning strategy using "recurrent adapters" to capture temporal dynamics in low-data regimes; (3) the integration of State Space Layers (SSL) for efficient long-form video modeling, supported by the introduction of two new long-term benchmarks for egocentric and feature-length content; (4) a novel contrastive learning framework designed to explicitly model fine-grained relations between motions and video moments; and (5) a comprehensive empirical study on Large Vision-Language Models (LVLMs) that identifies the visual-language interface as a bottleneck for temporal reasoning, leading to a new "temporal-oriented recipe" for upscaled video understanding. Collectively, these contributions demonstrate that explicit temporal modeling significantly enhances a model's ability to represent and reason about the fluid nature of video content.

</details>


### [258] [V2X-DSC: Multi-Agent Collaborative Perception with Distributed Source Coding Guided Communication](https://arxiv.org/abs/2602.00687)
*Yuankun Zeng,Shaohui Li,Zhi Li,Shulan Ruan,Yu Liu,You He*

Main category: cs.CV

TL;DR: 提出了一种名为V2X-DSC的框架，通过引入条件编解码器（DCC）来解决V2X通信中多车道感知特征共享的带宽限制问题，实现了更好的感知精度和带宽的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有协同感知方法在共享中间特征时面临严格的带宽限制，因为密集鸟瞰图（BEV）特征会使V2X通信链路饱和。研究人员发现，不同车辆对同一物理世界的观察具有高度相关性，因此接收者只需接收超出其本地上下文的创新信息即可。

Method: 受分布式源编码的启发，提出V2X-DSC框架，包含一个条件编解码器（DCC）。发送端将BEV特征压缩成紧凑的编码，接收端利用其本地特征作为侧信息进行条件重建，将比特分配给互补信息而非冗余内容。这种条件结构有助于正则化学习，促进增量式表示，并生成低噪声的特征。

Result: 在DAIR-V2X、OPV2V和V2X-Real数据集上进行了实验，结果表明V2X-DSC在KB级别通信下实现了最先进的精度-带宽权衡。此外，它作为一个即插即用的通信层，可以推广到多种融合骨干网络。

Conclusion: V2X-DSC框架有效地解决了V2X通信中的带宽限制问题，通过条件压缩和重建实现了感知精度和通信效率的最优权衡，并具有良好的通用性。

Abstract: Collaborative perception improves 3D understanding by fusing multi-agent observations, yet intermediate-feature sharing faces strict bandwidth constraints as dense BEV features saturate V2X links. We observe that collaborators view the same physical world, making their features strongly correlated; thus receivers only need innovation beyond their local context. Revisiting this from a distributed source coding perspective, we propose V2X-DSC, a framework with a Conditional Codec (DCC) for bandwidth-constrained fusion. The sender compresses BEV features into compact codes, while the receiver performs conditional reconstruction using its local features as side information, allocating bits to complementary cues rather than redundant content. This conditional structure regularizes learning, encouraging incremental representation and yielding lower-noise features. Experiments on DAIR-V2X, OPV2V, and V2X-Real demonstrate state-of-the-art accuracy-bandwidth trade-offs under KB-level communication, and generalizes as a plug-and-play communication layer across multiple fusion backbones.

</details>


### [259] [JoyAvatar: Unlocking Highly Expressive Avatars via Harmonized Text-Audio Conditioning](https://arxiv.org/abs/2602.00702)
*Ruikui Wang,Jinheng Feng,Lang Tian,Huaishao Luo,Chaochao Li,Liangbo Zhou,Huan Zhang,Youzheng Wu,Xiaodong He*

Main category: cs.CV

TL;DR: JoyAvatar是一个新框架，通过创新的训练算法和多模态条件调节，显著提升了视频化身模型对文本指令的遵循能力，尤其在处理复杂的全身动作、摄像机轨迹、背景切换和人机交互方面表现出色，并能生成长时间、时序连贯的化身视频。


<details>
  <summary>Details</summary>
Motivation: 现有视频化身模型在复杂文本指令（如大幅全身动作、动态摄像机轨迹、背景切换、人机交互）的遵循方面存在局限性。

Method: 提出JoyAvatar框架，包含两个关键创新：1. 双教师增强训练算法，用于迁移基础模型的文本可控性并学习音视频同步；2. 训练中根据去噪时间步动态调整多模态条件（音频、文本）的强度，以缓解异构信号冲突。

Result: JoyAvatar大幅扩展了化身模型生成自然、时序连贯的全身动作和动态摄像机运动的能力，同时保持了唇形同步和身份一致性。在GSB评估中，JoyAvatar优于Omnihuman-1.5和KlingAvatar 2.0等先进模型。

Conclusion: JoyAvatar框架成功克服了现有视频化身模型在文本指令遵循方面的限制，实现了对复杂场景的生成，并支持了多人物对话和非人类角色扮演等新应用。

Abstract: Existing video avatar models have demonstrated impressive capabilities in scenarios such as talking, public speaking, and singing. However, the majority of these methods exhibit limited alignment with respect to text instructions, particularly when the prompts involve complex elements including large full-body movement, dynamic camera trajectory, background transitions, or human-object interactions. To break out this limitation, we present JoyAvatar, a framework capable of generating long duration avatar videos, featuring two key technical innovations. Firstly, we introduce a twin-teacher enhanced training algorithm that enables the model to transfer inherent text-controllability from the foundation model while simultaneously learning audio-visual synchronization. Secondly, during training, we dynamically modulate the strength of multi-modal conditions (e.g., audio and text) based on the distinct denoising timestep, aiming to mitigate conflicts between the heterogeneous conditioning signals. These two key designs serve to substantially expand the avatar model's capacity to generate natural, temporally coherent full-body motions and dynamic camera movements as well as preserve the basic avatar capabilities, such as accurate lip-sync and identity consistency. GSB evaluation results demonstrate that our JoyAvatar model outperforms the state-of-the-art models such as Omnihuman-1.5 and KlingAvatar 2.0. Moreover, our approach enables complex applications including multi-person dialogues and non-human subjects role-playing. Some video samples are provided on https://joyavatar.github.io/.

</details>


### [260] [Supervised makeup transfer with a curated dataset: Decoupling identity and makeup features for enhanced transformation](https://arxiv.org/abs/2602.00729)
*Qihe Pan,Yiming Wu,Xing Zhao,Liang Xie,Guodao Sun,Ronghua Liang*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的妆容迁移新方法，通过构建高质量数据集、解耦身份与妆容特征以及引入文本引导机制，显著提高了妆容迁移的保真度、身份保持能力和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有基于GAN的妆容迁移方法存在数据集有限、身份与妆容特征解耦性差以及可控性弱等问题。研究旨在克服这些局限，提供更稳定、高质量的妆容迁移方案。

Method: 1. 构建了一个包含合成、真实和筛选样本的高质量数据集。2. 设计了一个基于扩散模型的框架，用于解耦身份和妆容特征，保持面部结构和肤色，同时应用精确且多样的化妆风格。3. 提出了一种文本引导机制，实现对眼睛、嘴唇或面部妆容进行细粒度和区域特定的控制。

Result: 在基准测试和实际场景中，所提出的方法在保真度、身份保持和灵活性方面均有提升。

Conclusion: 该研究成功构建了一个高质量的妆容迁移数据集，并提出了一种新颖的扩散模型框架，通过解耦特征和引入文本引导，实现了更优越、更灵活的妆容迁移效果。

Abstract: Diffusion models have recently shown strong progress in generative tasks, offering a more stable alternative to GAN-based approaches for makeup transfer. Existing methods often suffer from limited datasets, poor disentanglement between identity and makeup features, and weak controllability. To address these issues, we make three contributions. First, we construct a curated high-quality dataset using a train-generate-filter-retrain strategy that combines synthetic, realistic, and filtered samples to improve diversity and fidelity. Second, we design a diffusion-based framework that disentangles identity and makeup features, ensuring facial structure and skin tone are preserved while applying accurate and diverse cosmetic styles. Third, we propose a text-guided mechanism that allows fine-grained and region-specific control, enabling users to modify eyes, lips, or face makeup with natural language prompts. Experiments on benchmarks and real-world scenarios demonstrate improvements in fidelity, identity preservation, and flexibility. Examples of our dataset can be found at: https://makeup-adapter.github.io.

</details>


### [261] [StomataSeg: Semi-Supervised Instance Segmentation for Sorghum Stomatal Components](https://arxiv.org/abs/2602.00703)
*Zhongtian Huang,Zhi Chen,Zi Huang,Xin Yu,Daniel Smith,Chaitanya Purushothama,Erik Van Oosterom,Alex Wu,William Salter,Yan Li,Scott Chapman*

Main category: cs.CV

TL;DR: 本研究提出了一种半监督实例分割框架，用于分析高粱气孔的三个组成部分（气孔孔、保卫细胞和复杂区域），通过图像分块和伪标签策略提高了分割精度，为高粱气孔表型分析提供了更高效的自动化方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高高粱的用水效率，需要精确表征气孔性状，但目前自动化分析面临气孔微小、形状多样、以及现有分割方法在嵌套小结构和标注瓶颈方面的挑战。

Method: 收集并标注了包含11,060个人工标注块的高粱叶片图像数据集。将高分辨率显微镜图像分割成重叠的小块以检测微小结构。采用伪标签策略处理未标注图像，生成额外的56,428个伪标注块。对语义分割和实例分割模型进行基准测试。

Result: 在语义分割模型上，mIoU从65.93%提高到70.35%；在实例分割模型上，AP从28.30%提高到46.10%。研究表明，基于分块预处理和半监督学习的方法显著提高了细微气孔结构的分割效果。

Conclusion: 结合分块预处理和半监督学习的策略能够显著提升高粱气孔组件的分割精度，提出的框架支持规模化的气孔性状提取，有助于在作物科学中更广泛地采用AI驱动的表型分析。

Abstract: Sorghum is a globally important cereal grown widely in water-limited and stress-prone regions. Its strong drought tolerance makes it a priority crop for climate-resilient agriculture. Improving water-use efficiency in sorghum requires precise characterisation of stomatal traits, as stomata control of gas exchange, transpiration and photosynthesis have a major influence on crop performance. Automated analysis of sorghum stomata is difficult because the stomata are small (often less than 40 $μ$m in length in grasses such as sorghum) and vary in shape across genotypes and leaf surfaces. Automated segmentation contributes to high-throughput stomatal phenotyping, yet current methods still face challenges related to nested small structures and annotation bottlenecks. In this paper, we propose a semi-supervised instance segmentation framework tailored for analysis of sorghum stomatal components. We collect and annotate a sorghum leaf imagery dataset containing 11,060 human-annotated patches, covering the three stomatal components (pore, guard cell and complex area) across multiple genotypes and leaf surfaces. To improve the detection of tiny structures, we split high-resolution microscopy images into overlapping small patches. We then apply a pseudo-labelling strategy to unannotated images, producing an additional 56,428 pseudo-labelled patches. Benchmarking across semantic and instance segmentation models shows substantial performance gains: for semantic models the top mIoU increases from 65.93% to 70.35%, whereas for instance models the top AP rises from 28.30% to 46.10%. These results demonstrate that combining patch-based preprocessing with semi-supervised learning significantly improves the segmentation of fine stomatal structures. The proposed framework supports scalable extraction of stomatal traits and facilitates broader adoption of AI-driven phenotyping in crop science.

</details>


### [262] [Diffusion-Driven Inter-Outer Surface Separation for Point Clouds with Open Boundaries](https://arxiv.org/abs/2602.00739)
*Zhengyan Qin,Liyuan Qiu*

Main category: cs.CV

TL;DR: 提出了一种基于扩散的算法，用于从双层点云中分离内层和外层表面，尤其解决了TSDF融合中的“双表面伪影”问题，能够快速有效地提取内层表面。


<details>
  <summary>Details</summary>
Motivation: TSDF融合过程中由于截断阈值不对称产生的“双表面伪影”，导致点云包含错误的内外层，影响后续的三维重建和应用。

Method: 开发了一种基于扩散的算法，通过提取真实的内层表面来解决重叠表面和法线混乱的问题，适用于具有开放边界（即存在开口/孔洞）的双层点云，也能处理封闭（水密）模型。

Result: 该算法能够从包含20,000个内层点和20,000个外层点的双层点云中，在约10秒内提取出内层表面，并且适用于封闭和开放边界的模型。

Conclusion: 所提出的扩散算法是一种轻量级的后处理模块，可以有效且快速地分离双层点云的内层和外层表面，特别适用于需要精确表面表示的室内场景建模和医学成像等领域。

Abstract: We propose a diffusion-based algorithm for separating the inter and outer layer surfaces from double-layered point clouds, particularly those exhibiting the "double surface artifact" caused by truncation in Truncated Signed Distance Function (TSDF) fusion during indoor or medical 3D reconstruction. This artifact arises from asymmetric truncation thresholds, leading to erroneous inter and outer shells in the fused volume, which our method addresses by extracting the true inter layer to mitigate challenges like overlapping surfaces and disordered normals. We focus on point clouds with \emph{open boundaries} (i.e., sampled surfaces with topological openings/holes through which particles may escape), rather than point clouds with \emph{missing surface regions} where no samples exist. Our approach enables robust processing of both watertight and open-boundary models, achieving extraction of the inter layer from 20,000 inter and 20,000 outer points in approximately 10 seconds. This solution is particularly effective for applications requiring accurate surface representations, such as indoor scene modeling and medical imaging, where double-layered point clouds are prevalent, and it accommodates both closed (watertight) and open-boundary surface geometries. Our goal is \emph{post-hoc} inter/outer shell separation as a lightweight module after TSDF fusion; we do not aim to replace full variational or learning-based reconstruction pipelines.

</details>


### [263] [HSI-VAR: Rethinking Hyperspectral Restoration through Spatial-Spectral Visual Autoregression](https://arxiv.org/abs/2602.00749)
*Xiangming Wang,Benteng Sun,Yungeng Liu,Haijin Zeng,Yongyong Chen,Jingyong Su,Jie Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为HSI-VAR的新型高光谱图像（HSI）恢复方法，将其视为自回归生成问题，通过逐步建模光谱和空间依赖性来解决现有方法的计算效率低下和细节丢失问题。HSI-VAR通过潜空间条件对齐、退化感知引导和空间-光谱适应模块，在保证恢复质量的同时，显著提高了推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的高光谱图像恢复方法，如扩散模型，计算成本高，不适用于高维高光谱图像；而回归模型容易产生过度平滑的结果，丢失关键的结构细节。作者旨在打破这一僵局，提出一种更有效、更精确的恢复方法。

Method: HSI-VAR将高光谱图像恢复视为一个自回归生成问题。其核心创新包括：1. 潜空间条件对齐：将潜空间先验和条件嵌入耦合，实现语义一致性以进行精确重建。2. 退化感知引导：将混合退化编码为嵌入空间的线性组合，实现自动控制，并将计算成本降低近50%。3. 空间-光谱适应模块：在解码阶段跨越光谱和空间域细化细节。

Result: 在九个全能高光谱图像恢复基准测试中，HSI-VAR取得了最先进的性能，在ICVL数据集上PSNR提高了3.77 dB。与基于扩散的方法相比，推理速度提高了95.5倍，同时保留了更优越的结构。

Conclusion: HSI-VAR通过将高光谱图像恢复视为自回归生成问题，并引入创新的模块，在恢复质量和计算效率之间取得了显著的平衡，为现实世界的高光谱图像恢复提供了一个高度实用的解决方案。

Abstract: Hyperspectral images (HSIs) capture richer spatial-spectral information beyond RGB, yet real-world HSIs often suffer from a composite mix of degradations, such as noise, blur, and missing bands. Existing generative approaches for HSI restoration like diffusion models require hundreds of iterative steps, making them computationally impractical for high-dimensional HSIs. While regression models tend to produce oversmoothed results, failing to preserve critical structural details. We break this impasse by introducing HSI-VAR, rethinking HSI restoration as an autoregressive generation problem, where spectral and spatial dependencies can be progressively modeled rather than globally reconstructed. HSI-VAR incorporates three key innovations: (1) Latent-condition alignment, which couples semantic consistency between latent priors and conditional embeddings for precise reconstruction; (2) Degradation-aware guidance, which uniquely encodes mixed degradations as linear combinations in the embedding space for automatic control, remarkably achieving a nearly $50\%$ reduction in computational cost at inference; (3) A spatial-spectral adaptation module that refines details across both domains in the decoding phase. Extensive experiments on nine all-in-one HSI restoration benchmarks confirm HSI-VAR's state-of-the-art performance, achieving a 3.77 dB PSNR improvement on \textbf{\textit{ICVL}} and offering superior structure preservation with an inference speed-up of up to $95.5 \times$ compared with diffusion-based methods, making it a highly practical solution for real-world HSI restoration.

</details>


### [264] [Evaluating Deep Learning-Based Nerve Segmentation in Brachial Plexus Ultrasound Under Realistic Data Constraints](https://arxiv.org/abs/2602.00763)
*Dylan Yves,Khush Agarwal,Jonathan Hoyin Chan,Patcharapit Promoppatum,Aroonkamon Pattanasiricharoen*

Main category: cs.CV

TL;DR: 本研究评估了基于深度学习的臂丛神经超声图像分割的U-Net架构，并探讨了数据集组成和标注策略对性能的影响。研究发现，跨多台超声设备训练数据有正则化优势，但不如目标域的单源训练效果好。从二元分割扩展到多类（血管、神经、肌肉）分割会降低神经分割精度，且神经大小与分割精度呈正相关。


<details>
  <summary>Details</summary>
Motivation: 手动识别超声引导下神经在实际临床操作中具有挑战性，受图像对比度低、散斑噪声和个体解剖变异等因素影响，因此需要更准确和自动化的神经定位方法。

Method: 研究使用U-Net深度学习架构对臂丛神经超声图像进行分割。通过比较不同数据集组成（单一或多台超声设备采集）和标注策略（二元分割 vs. 多类分割）对分割性能的影响，并分析了神经大小与分割精度的相关性。

Result: 在多台设备上联合训练可带来正则化效益，但不如目标域的单源训练效果好。将任务扩展到多类（血管、神经、肌肉）分割会降低神经分割的Dice分数，性能下降幅度在9%至61%之间。神经大小与分割准确度存在中度正相关（Pearson r=0.587，p<0.001），表明小神经的分割仍是难点。

Conclusion: 数据集的组成和标注策略对超声神经分割性能有显著影响。研究结果为在实际临床数据约束下开发鲁棒的超声神经分割系统提供了方法学指导，同时也指出了小神经分割仍是未来研究的重点。

Abstract: Accurate nerve localization is critical for the success of ultrasound-guided regional anesthesia, yet manual identification remains challenging due to low image contrast, speckle noise, and inter-patient anatomical variability. This study evaluates deep learning-based nerve segmentation in ultrasound images of the brachial plexus using a U-Net architecture, with a focus on how dataset composition and annotation strategy influence segmentation performance. We find that training on combined data from multiple ultrasound machines (SIEMENS ACUSON NX3 Elite and Philips EPIQ5) provides regularization benefits for lower-performing acquisition sources, though it does not surpass single-source training when matched to the target domain. Extending the task from binary nerve segmentation to multi-class supervision (artery, vein, nerve, muscle) results in decreased nerve-specific Dice scores, with performance drops ranging from 9% to 61% depending on dataset, likely due to class imbalance and boundary ambiguity. Additionally, we observe a moderate positive correlation between nerve size and segmentation accuracy (Pearson r=0.587, p<0.001), indicating that smaller nerves remain a primary challenge. These findings provide methodological guidance for developing robust ultrasound nerve segmentation systems under realistic clinical data constraints.

</details>


### [265] [DVLA-RL: Dual-Level Vision-Language Alignment with Reinforcement Learning Gating for Few-Shot Learning](https://arxiv.org/abs/2602.00795)
*Wenhao Li,Xianjing Meng,Qiangchang Wang,Zhongyi Han,Zhibin Wu,Yilong Yin*

Main category: cs.CV

TL;DR: 本文提出了一种名为DVLA-RL的新型少样本学习方法，通过构建双层语义和强化学习门控注意力机制，实现了视觉和语言的渐进式自适应对齐，从而提升了模型在少量样本下的泛化能力。该方法在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的小样本学习方法虽然利用了大型语言模型来丰富视觉表示，但忽略了视觉和语言之间从低级到高级语义的渐进式和自适应对齐，导致语义增益有限。

Method: 提出了一种名为DVLA-RL的方法，包含双层语义构建（DSC）和强化学习门控注意力（RLA）。DSC利用类名和支持样本生成判别性属性，并将其合成为类描述。RLA将跨模态融合视为一个序贯决策过程，通过训练轻量级策略自适应地调整自注意力和交叉注意力的贡献，实现浅层关注局部属性，深层关注全局语义。

Result: DVLA-RL方法在三个不同的少样本学习场景下的九个基准测试中均取得了新的最先进性能。

Conclusion: DVLA-RL通过构建双层语义和利用强化学习门控注意力，实现了有效的视觉-语言对齐，能够从少量样本中提取出类别特定的判别性表示和泛化性表示，显著提升了小样本学习的性能。

Abstract: Few-shot learning (FSL) aims to generalize to novel categories with only a few samples. Recent approaches incorporate large language models (LLMs) to enrich visual representations with semantic embeddings derived from class names. However, they overlook progressive and adaptive alignment between vision and language from low-level to high-level semantics, resulting in limited semantic gains. To address these challenges, we propose Dual-level Vision-Language Alignment with Reinforcement Learning gating (DVLA-RL), which consists of Dual-level Semantic Construction (DSC) and RL-gated Attention (RLA). Specifically, DSC conditions LLMs on both class names and support samples to generate discriminative attributes, progressively selects the most relevant ones, and then synthesizes them into coherent class descriptions. This process provides complementary low-level attributes and high-level descriptions, enabling both fine-grained grounding and holistic class understanding. To dynamically integrate dual-level semantics along with the visual network layers, RLA formulates cross-modal fusion as a sequential decision process. A lightweight policy trained with episodic REINFORCE adaptively adjusts the contributions of self-attention and cross-attention to integrate textual and visual tokens. As a result, shallow layers refine local attributes and deep layers emphasize global semantics, enabling more precise cross-modal alignment. This achieves class-specific discrimination and generalized representations with merely a few support samples. DVLA-RL achieves new state-of-the-art performance across nine benchmarks in three diverse FSL scenarios.

</details>


### [266] [Generating a Paracosm for Training-Free Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2602.00813)
*Tong Wang,Yunhan Zhao,Shu Kong*

Main category: cs.CV

TL;DR: 本文提出了一种名为Paracosm的无训练零样本组合图像检索方法，通过引导大型多模态模型（LMM）生成“心理图像”，并创建一个合成图像数据库来弥合合成与真实图像的领域差距，从而直接匹配查询和数据库图像，显著优于现有零样本方法。


<details>
  <summary>Details</summary>
Motivation: 现有组合图像检索（CIR）方法依赖于零样本模型生成查询的文本描述，然后进行文本-视觉匹配，这种间接方式可能导致匹配不准确。研究动机是直接生成“心理图像”以提高检索精度。

Method: 该方法首先使用LMM为给定的多模态查询（参考图像+修改文本）生成一个“心理图像”。然后，为数据库中的每个真实图像生成一个对应的合成图像，以创建一个“paracosm”（想象中的世界）。最后，使用生成的“心理图像”来匹配数据库中的合成图像，从而检索目标图像。该方法是训练自由的零样本方法。

Result: Paracosm方法在四个具有挑战性的基准测试中显著优于现有的零样本CIR方法，达到了最先进的性能。

Conclusion: Paracosm通过直接生成“心理图像”并构建合成图像库，成功地解决了组合图像检索的核心挑战，为零样本CIR提供了新的、更有效的解决方案。

Abstract: Composed Image Retrieval (CIR) is the task of retrieving a target image from a database using a multimodal query, which consists of a reference image and a modification text. The text specifies how to alter the reference image to form a ``mental image'', based on which CIR should find the target image in the database. The fundamental challenge of CIR is that this ``mental image'' is not physically available and is only implicitly defined by the query. The contemporary literature pursues zero-shot methods and uses a Large Multimodal Model (LMM) to generate a textual description for a given multimodal query, and then employs a Vision-Language Model (VLM) for textual-visual matching to search the target image. In contrast, we address CIR from first principles by directly generating the ``mental image'' for more accurate matching. Particularly, we prompt an LMM to generate a ``mental image'' for a given multimodal query and propose to use this ``mental image'' to search for the target image. As the ``mental image'' has a synthetic-to-real domain gap with real images, we also generate a synthetic counterpart for each real image in the database to facilitate matching. In this sense, our method uses LMM to construct a ``paracosm'', where it matches the multimodal query and database images. Hence, we call this method Paracosm. Notably, Paracosm is a training-free zero-shot CIR method. It significantly outperforms existing zero-shot methods on four challenging benchmarks, achieving state-of-the-art performance for zero-shot CIR.

</details>


### [267] [Edge-Native Generative De-identification: Inversion-Free Flow for Privacy-Preserving Federated Skin Image Analysis](https://arxiv.org/abs/2602.00821)
*Konstantinos Moutselos,Ilias Maglogiannis*

Main category: cs.CV

TL;DR: 提出了一种名为FlowEdit的框架，用于在不牺牲诊断特征的情况下保护临床皮肤病学图像的隐私，通过快速生成无身份信息的病理图像，可以在本地设备上运行，从而在联邦学习中实现安全的皮肤图像分析。


<details>
  <summary>Details</summary>
Motivation: 临床皮肤病学中的联邦学习面临保护患者隐私和保留诊断特征的冲突。传统的去标识化方法会损害病理保真度，而现有的生成编辑技术因计算量大不适用于资源受限的边缘设备。

Method: 利用无反演的Rectified Flow Transformers (FlowEdit) 进行身份无关的病理特征保留，实现高保真身份转换。提出“Segment-by-Synthesis”机制，本地生成反事实的健康和病理对照图像对，以提取与生物特征和语义伪影无关的差异性红斑掩膜。

Result: FlowEdit 可以在20秒内完成身份转换，支持本地部署。在合成身份上的IoU稳定性大于0.67。该框架能在边缘生成符合隐私要求的合成替代图像。

Conclusion: 该框架通过在边缘生成隐私合规的合成替代图像，减轻了梯度泄露的风险，为联邦环境中高精度皮肤图像分析提供了安全途径。

Abstract: The deployment of Federated Learning (FL) for clinical dermatology is hindered by the competing requirements of protecting patient privacy and preserving diagnostic features. Traditional de-identification methods often degrade pathological fidelity, while standard generative editing techniques rely on computationally intensive inversion processes unsuitable for resource-constrained edge devices. We propose a framework for identity-agnostic pathology preservation that serves as a client-side privacy-preserving utility. By leveraging inversion-free Rectified Flow Transformers (FlowEdit), the system performs high-fidelity identity transformation in near real-time (less than 20s), facilitating local deployment on clinical nodes. We introduce a "Segment-by-Synthesis" mechanism that generates counterfactual healthy and pathological twin pairs locally. This enables the extraction of differential erythema masks that are decoupled from biometric markers and semantic artifacts (e.g. jewelry). Pilot validation on high-resolution clinical samples demonstrates an Intersection over Union (IoU) stability greater than 0.67 across synthetic identities. By generating privacy-compliant synthetic surrogates at the edge, this framework mitigates the risk of gradient leakage at the source, providing a secure pathway for high-precision skin image analysis in federated environments.

</details>


### [268] [TransNormal: Dense Visual Semantics for Diffusion-based Transparent Object Normal Estimation](https://arxiv.org/abs/2602.00839)
*Mingwei Li,Hehe Fan,Yi Yang*

Main category: cs.CV

TL;DR: 提出了一种名为TransNormal的框架，用于从单目图像估计透明物体的法线，该框架结合了扩散模型、DINOv3的视觉语义和多任务学习，并在新创建的物理仿真数据集TransNormal-Synthetic上进行了验证，实验结果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 实验室自动化中单目透明物体法线估计因光折射和反射而具有挑战性，现有传感器在该环境下表现不佳，阻碍了具身AI的应用。

Method: 提出TransNormal框架，利用预训练的扩散模型进行单步法线回归，通过交叉注意力机制融合DINOv3的密集视觉语义来处理纹理缺失问题，并采用多任务学习目标和基于小波的正则化来保留细节。

Result: 在ClearGrasp基准上，TransNormal将平均误差降低了24.4%，11.25°精度提高了22.8%；在ClearPose基准上，平均误差降低了15.2%，显著优于现有最先进的方法。

Conclusion: TransNormal是一个有效的新框架，能够从单目图像中准确估计透明物体的法线，通过结合先进的深度学习技术和新的数据集，解决了现有方法的局限性，为具身AI在科学环境中的应用开辟了道路。

Abstract: Monocular normal estimation for transparent objects is critical for laboratory automation, yet it remains challenging due to complex light refraction and reflection. These optical properties often lead to catastrophic failures in conventional depth and normal sensors, hindering the deployment of embodied AI in scientific environments. We propose TransNormal, a novel framework that adapts pre-trained diffusion priors for single-step normal regression. To handle the lack of texture in transparent surfaces, TransNormal integrates dense visual semantics from DINOv3 via a cross-attention mechanism, providing strong geometric cues. Furthermore, we employ a multi-task learning objective and wavelet-based regularization to ensure the preservation of fine-grained structural details. To support this task, we introduce TransNormal-Synthetic, a physics-based dataset with high-fidelity normal maps for transparent labware. Extensive experiments demonstrate that TransNormal significantly outperforms state-of-the-art methods: on the ClearGrasp benchmark, it reduces mean error by 24.4% and improves 11.25° accuracy by 22.8%; on ClearPose, it achieves a 15.2% reduction in mean error. The code and dataset will be made publicly available at https://longxiang-ai.github.io/TransNormal.

</details>


### [269] [Invariance on Manifolds: Understanding Robust Visual Representations for Place Recognition](https://arxiv.org/abs/2602.00841)
*Jintao Cheng,Weibin Li,Zhijian He,Jin Wu,Chi Man Vong,Wei Zhang*

Main category: cs.CV

TL;DR: 提出一种无需训练的第二阶几何统计框架，将场景表示为SPD流形上的协方差描述符，利用黎曼映射将其投影到欧氏空间，实现对环境和视点变化的鲁棒性，并在零样本场景下表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有视觉地标识别方法要么需要大量标注数据，要么依赖于简化的统计方法，忽略了内在的结构相关性。因此，需要一种能够捕捉几何稳定性且无需训练的方法。

Method: 将场景视为对称正定（SPD）流形上的协方差描述符，利用几何感知的黎曼映射将描述符投影到线性化的欧氏空间，从而分离信号结构和噪声。该框架基于固定的预训练骨干网络，无需训练即可实现零样本泛化。

Result: 该方法在零样本场景下取得了具有高度竞争力的性能，优于现有的先进基线方法，特别是在具有挑战性的零样本场景中表现突出。

Conclusion: 提出的第二阶几何统计框架能够有效捕捉场景的几何稳定性，实现无需训练的零样本视觉地标识别，并在各种实验中证明了其优越性。

Abstract: Visual Place Recognition (VPR) demands representations robust to drastic environmental and viewpoint shifts. Current aggregation paradigms, however, either rely on data-hungry supervision or simplistic first-order statistics, often neglecting intrinsic structural correlations. In this work, we propose a Second-Order Geometric Statistics framework that inherently captures geometric stability without training. We conceptualize scenes as covariance descriptors on the Symmetric Positive Definite (SPD) manifold, where perturbations manifest as tractable congruence transformations. By leveraging geometry-aware Riemannian mappings, we project these descriptors into a linearized Euclidean embedding, effectively decoupling signal structure from noise. Our approach introduces a training-free framework built upon fixed, pre-trained backbones, achieving strong zero-shot generalization without parameter updates. Extensive experiments confirm that our method achieves highly competitive performance against state-of-the-art baselines, particularly excelling in challenging zero-shot scenarios.

</details>


### [270] [Distill3R: A Pipeline for Democratizing 3D Foundation Models on Commodity Hardware](https://arxiv.org/abs/2602.00865)
*Brandon Leblanc,Charalambos Poullis*

Main category: cs.CV

TL;DR: Distill3R 是一个框架，可以将大型 3D 基础模型的几何推理能力蒸馏到一个紧凑的学生模型中，该模型可以在单台工作站上进行训练，从而降低了 3D 计算机视觉研究的计算门槛。


<details>
  <summary>Details</summary>
Motivation: 大型 3D 重建基础模型虽然在几何推理方面表现出色，但其训练需要庞大的计算集群，这对于大多数学术实验室来说是一个巨大的障碍。研究人员希望提供一种更易于访问的解决方案。

Method: 该框架包含两个核心创新：1) 一个离线缓存管道，通过压缩的监督信号将教师模型的推理与训练循环解耦；2) 一个置信度感知的蒸馏损失函数，利用教师模型的不确定性来允许在普通硬件上进行训练。提出了一种参数量为 72M 的学生模型。

Result: 与 650M 参数的教师模型相比，学生模型参数量减少了 9 倍，推理速度提高了 5 倍。学生模型可以在单台工作站上 3 天内完全训练完成，而教师模型需要 GPU 集群训练一周。学生模型保留了结构一致性和定性几何理解能力。

Conclusion: Distill3R 提供了一个可复现的、单工作站训练方案，为 3D 计算机视觉研究提供了一个易于探索的入口，并支持高效的边缘部署。该框架旨在为缺乏大规模计算资源的实验室提供一个可负担的研究基线，使其能够在各自领域内以低成本训练和定制模型。

Abstract: While multi-view 3D reconstruction has shifted toward large-scale foundation models capable of inferring globally consistent geometry, their reliance on massive computational clusters for training has created a significant barrier to entry for most academic laboratories. To bridge this compute divide, we introduce Distill3R, a framework designed to distill the geometric reasoning of 3D foundation models into compact students fully trainable on a single workstation. Our methodology centers on two primary innovations: (1) an offline caching pipeline that decouples heavy teacher inference from the training loop through compressed supervision signals, and (2) a confidence-aware distillation loss that leverages teacher uncertainty to enable training on commodity hardware. We propose a 72M-parameter student model which achieves a 9x reduction in parameters and a 5x inference speedup compared to its 650M-parameter teacher. The student is fully trainable in under 3 days on a single workstation, whereas its teacher requires massive GPU clusters for up to a week. We demonstrate that the student preserves the structural consistency and qualitative geometric understanding required for functional 3D awareness. By providing a reproducible, single-workstation training recipe, Distill3R serves as an exploratory entry point for democratized 3D vision research and efficient edge deployment. This work is not intended to compete with state-of-the-art foundation models, but to provide an accessible research baseline for laboratories without access to large-scale compute to train and specialize models on their own domain-specific data at minimal cost.

</details>


### [271] [DIAMOND: Directed Inference for Artifact Mitigation in Flow Matching Models](https://arxiv.org/abs/2602.00883)
*Alicja Polowczyk,Agnieszka Polowczyk,Piotr Borycki,Joanna Waczyńska,Jacek Tabor,Przemysław Spurek*

Main category: cs.CV

TL;DR: 提出了一种名为DIAMOND的训练无关方法，通过在推理过程中进行轨迹校正来减少文本到图像生成中的视觉和解剖伪影，无需修改模型权重或进行耗时的后处理。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型（如FLUX）仍存在视觉和解剖伪影，限制了其在实际和专业领域的应用。现有的伪影减少方法通常是事后处理，效率低下，需要修改模型权重或进行耗时的区域细化。

Method: DIAMOND是一种训练无关的推理时方法，通过在生成轨迹的每一步重建干净样本的估计，主动引导生成过程远离产生伪影的潜在状态。该方法被扩展到标准的扩散模型。

Result: DIAMOND能够实现高保真、无伪影的图像合成，无需额外的训练或模型权重修改。

Conclusion: DIAMOND提供了一种鲁棒、零样本的方法来解决现代生成模型中的伪影问题，并在不影响生成效率的情况下显著提高图像质量。

Abstract: Despite impressive results from recent text-to-image models like FLUX, visual and anatomical artifacts remain a significant hurdle for practical and professional use. Existing methods for artifact reduction, typically work in a post-hoc manner, consequently failing to intervene effectively during the core image formation process. Notably, current techniques require problematic and invasive modifications to the model weights, or depend on a computationally expensive and time-consuming process of regional refinement. To address these limitations, we propose DIAMOND, a training-free method that applies trajectory correction to mitigate artifacts during inference. By reconstructing an estimate of the clean sample at every step of the generative trajectory, DIAMOND actively steers the generation process away from latent states that lead to artifacts. Furthermore, we extend the proposed method to standard Diffusion Models, demonstrating that DIAMOND provides a robust, zero-shot path to high-fidelity, artifact-free image synthesis without the need for additional training or weight modifications in modern generative architectures. Code is available at https://gmum.github.io/DIAMOND/

</details>


### [272] [OCTOPUS: Enhancing the Spatial-Awareness of Vision SSMs with Multi-Dimensional Scans and Traversal Selection](https://arxiv.org/abs/2602.00904)
*Kunal Mahatha,Ali Bahri,Pierre Marza,Sahar Dastani,Maria Vakalopoulou,Stergios Christodoulidis,Jose Dolz,Christian Desrosiers*

Main category: cs.CV

TL;DR: 本文提出了一种名为OCTOPUS的新型视觉状态空间模型（V-SSM）架构，通过在八个主方向上进行离散重现，有效解决了标准SSM在视觉任务中因因果关系而破坏空间局部性问题，同时保持了线性复杂度，并在图像分类和分割任务中取得了改进。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉状态空间模型（V-SSM）在处理图像时，其因果关系的设计不适合空间域，导致无法有效捕捉局部空间相干性，忽略了邻近像素/块之间的视觉关联，尽管它们能够建模全局关系。因此，需要一种既能保留全局上下文，又能维护局部空间结构，同时保持SSM线性复杂度的视觉模型。

Method: OCTOPUS架构通过在水平、垂直和对角线方向上沿八个主方向进行前向和后向的离散重现（multi-directional recurrence）来处理图像。这种设计允许在所有空间连接的区域之间进行有效的信息交换，同时保持不相关区域的独立性，从而捕捉全局上下文和局部空间结构。

Result: 在图像分类和分割基准测试中，OCTOPUS在边界保持和区域一致性方面表现出显著的改进，分割结果得到优化。与现有的基于V-SSM的模型相比，OCTOPUS在分类准确性上也保持了相对更好的性能。

Conclusion: OCTOPUS提出了一种基于多方向重现的视觉模型基础方法，它能够有效地捕捉图像的全局上下文和局部空间结构，同时保持SSM的效率。该方法为构建具有空间感知能力且计算高效的视觉架构提供了一种可扩展且有效的设计思路。

Abstract: State space models (SSMs) have recently emerged as an alternative to transformers due to their unique ability of modeling global relationships in text with linear complexity. However, their success in vision tasks has been limited due to their causal formulation, which is suitable for sequential text but detrimental in the spatial domain where causality breaks the inherent spatial relationships among pixels or patches. As a result, standard SSMs fail to capture local spatial coherence, often linking non-adjacent patches while ignoring neighboring ones that are visually correlated. To address these limitations, we introduce OCTOPUS , a novel architecture that preserves both global context and local spatial structure within images, while maintaining the linear complexity of SSMs. OCTOPUS performs discrete reoccurrence along eight principal orientations, going forward or backward in the horizontal, vertical, and diagonal directions, allowing effective information exchange across all spatially connected regions while maintaining independence among unrelated patches. This design enables multi-directional recurrence, capturing both global context and local spatial structure with SSM-level efficiency. In our classification and segmentation benchmarks, OCTOPUS demonstrates notable improvements in boundary preservation and region consistency, as evident from the segmentation results, while maintaining relatively better classification accuracy compared to existing V-SSM based models. These results suggest that OCTOPUS appears as a foundation method for multi-directional recurrence as a scalable and effective mechanism for building spatially aware and computationally efficient vision architectures.

</details>


### [273] [Data Augmentation for High-Fidelity Generation of CAR-T/NK Immunological Synapse Images](https://arxiv.org/abs/2602.00949)
*Xiang Zhang,Boxuan Zhang,Alireza Naghizadeh,Mohab Mohamed,Dongfang Liu,Ruixiang Tang,Dimitris Metaxas,Dongfang Liu*

Main category: cs.CV

TL;DR: 本文提出了一种结合实例感知自动增强 (IAAA) 和语义感知 AI 增强 (SAAA) 的数据增强框架，用于改进 CAR-T/NK 细胞免疫突触 (IS) 的检测和分割，以提高 CAR-T/NK 免疫治疗的疗效预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的 CAR-T/NK 细胞免疫治疗在癌症治疗中取得了显著进展，但免疫突触 (IS) 的质量作为预测治疗效果的生物标志物的潜力尚未得到充分利用。准确、快速地检测和分割 IS 结构至关重要，然而，现有的标注显微镜数据集规模有限，限制了人工智能网络 (ANN) 的泛化能力。

Method: 本文整合了两种数据增强方法：1) 实例感知自动增强 (IAAA)，一种实例保留的自动增强方法，通过优化增强策略生成合成 IS 图像和分割掩码；2) 语义感知 AI 增强 (SAAA)，结合了基于扩散的模型和 Pix2Pix 条件图像合成器，生成多样化的、解剖学上真实的分割掩码和高保真度 IS 图像。

Result: 所提出的数据增强策略能够生成与真实 IS 数据在视觉和结构特性上高度匹配的合成图像，显著提高了 CAR-T/NK IS 的检测和分割性能。

Conclusion: 通过增强 IS 定量的鲁棒性和准确性，该研究为开发更可靠的、基于影像学的生物标志物以预测患者对 CAR-T/NK 免疫治疗的反应提供了支持。

Abstract: Chimeric antigen receptor (CAR)-T and NK cell immunotherapies have transformed cancer treatment, and recent studies suggest that the quality of the CAR-T/NK cell immunological synapse (IS) may serve as a functional biomarker for predicting therapeutic efficacy. Accurate detection and segmentation of CAR-T/NK IS structures using artificial neural networks (ANNs) can greatly increase the speed and reliability of IS quantification. However, a persistent challenge is the limited size of annotated microscopy datasets, which restricts the ability of ANNs to generalize. To address this challenge, we integrate two complementary data-augmentation frameworks. First, we employ Instance Aware Automatic Augmentation (IAAA), an automated, instance-preserving augmentation method that generates synthetic CAR-T/NK IS images and corresponding segmentation masks by applying optimized augmentation policies to original IS data. IAAA supports multiple imaging modalities (e.g., fluorescence and brightfield) and can be applied directly to CAR-T/NK IS images derived from patient samples. In parallel, we introduce a Semantic-Aware AI Augmentation (SAAA) pipeline that combines a diffusion-based mask generator with a Pix2Pix conditional image synthesizer. This second method enables the creation of diverse, anatomically realistic segmentation masks and produces high-fidelity CAR-T/NK IS images aligned with those masks, further expanding the training corpus beyond what IAAA alone can provide. Together, these augmentation strategies generate synthetic images whose visual and structural properties closely match real IS data, significantly improving CAR-T/NK IS detection and segmentation performance. By enhancing the robustness and accuracy of IS quantification, this work supports the development of more reliable imaging-based biomarkers for predicting patient response to CAR-T/NK immunotherapy.

</details>


### [274] [ConsensusDrop: Fusing Visual and Cross-Modal Saliency for Efficient Vision Language Models](https://arxiv.org/abs/2602.00946)
*Dhruv Parikh,Haoyang Fan,Rajgopal Kannan,Viktor Prasanna*

Main category: cs.CV

TL;DR: 提出了一种名为ConsensusDrop的训练无关框架，通过融合视觉编码器显著性图和查询感知的交叉注意力来优化视觉-语言模型（VLMs）中的视觉token数量，从而提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉token缩减方法要么依赖于查询无关的视觉编码器显著性，要么依赖于计算成本高昂的查询感知交叉注意力，这两种方法单独使用都不够有效。研究动机是找到一种更有效的方法来减少VLM中的视觉token数量，同时保持或提高性能。

Method: ConsensusDrop框架通过以下步骤实现：1. 融合视觉编码器显著性图和查询感知的交叉注意力，得出“共识”排序。2. 根据共识排序保留最具信息量的token。3. 通过编码器指导的token合并来压缩剩余token。该方法是训练无关的。

Result: ConsensusDrop在LLaVA-1.5/NeXT、Video-LLaVA和其他开源VLMs上，在相同的token预算下，始终优于先前的方法。它在保持接近基线准确率的同时，显著减少了推理时间和KV缓存占用，实现了更优的精度-效率权衡。

Conclusion: ConsensusDrop是一种有效的训练无关框架，通过结合两种不同类型的显著性信号来优化VLMs中的视觉token，从而在不牺牲性能的情况下显著提高效率。

Abstract: Vision-Language Models (VLMs) are expensive because the LLM processes hundreds of largely redundant visual tokens. Existing token reduction methods typically exploit \textit{either} vision-encoder saliency (broad but query-agnostic) \textit{or} LLM cross-attention (query-aware but sparse and costly). We show that neither signal alone is sufficient: fusing them consistently improves performance compared to unimodal visual token selection (ranking). However, making such fusion practical is non-trivial: cross-modal saliency is usually only available \emph{inside} the LLM (too late for efficient pre-LLM pruning), and the two signals are inherently asymmetric, so naive fusion underutilizes their complementary strengths. We propose \textbf{ConsensusDrop}, a training-free framework that derives a \emph{consensus} ranking by reconciling vision encoder saliency with query-aware cross-attention, retaining the most informative tokens while compressing the remainder via encoder-guided token merging. Across LLaVA-1.5/NeXT, Video-LLaVA, and other open-source VLMs, ConsensusDrop consistently outperforms prior pruning methods under identical token budgets and delivers a stronger accuracy-efficiency Pareto frontier -- preserving near-baseline accuracy even at aggressive token reductions while reducing TTFT and KV cache footprint. Our code will be open-sourced.

</details>


### [275] [Hybrid Topological and Deep Feature Fusion for Accurate MRI-Based Alzheimer's Disease Severity Classification](https://arxiv.org/abs/2602.00956)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: 提出了一种结合拓扑数据分析（TDA）和DenseNet121的混合深度学习框架，用于基于结构MRI的阿尔茨海默病（AD）四分类，并在OASIS数据集上取得了99.93%的准确率和100%的AUC。


<details>
  <summary>Details</summary>
Motivation: 早期准确诊断阿尔茨海默病（AD）对于基于神经影像的临床决策支持系统至关重要，而传统的神经网络可能忽略大脑结构的拓扑特征。

Method: 利用TDA提取大脑结构的拓扑特征，并结合DenseNet121提取的空间特征，然后融合这两种特征以提高类别的可分性，用于AD的四分类。

Result: 在OASIS-1 Kaggle MRI数据集上，所提出的TDA+DenseNet121模型在准确率（99.93%）和AUC（100%）方面均显著优于现有最先进的方法，包括CNN、迁移学习、集成和多尺度架构。

Conclusion: 将拓扑洞察力融入深度学习流水线是有效的，所提出的混合框架可以作为自动化AD诊断的强大且高精度的工具。

Abstract: Early and accurate diagnosis of Alzheimer's disease (AD) remains a critical challenge in neuroimaging-based clinical decision support systems. In this work, we propose a novel hybrid deep learning framework that integrates Topological Data Analysis (TDA) with a DenseNet121 backbone for four-class Alzheimer's disease classification using structural MRI data from the OASIS dataset. TDA is employed to capture complementary topological characteristics of brain structures that are often overlooked by conventional neural networks, while DenseNet121 efficiently learns hierarchical spatial features from MRI slices. The extracted deep and topological features are fused to enhance class separability across the four AD stages.
  Extensive experiments conducted on the OASIS-1 Kaggle MRI dataset demonstrate that the proposed TDA+DenseNet121 model significantly outperforms existing state-of-the-art approaches. The model achieves an accuracy of 99.93% and an AUC of 100%, surpassing recently published CNN-based, transfer learning, ensemble, and multi-scale architectures. These results confirm the effectiveness of incorporating topological insights into deep learning pipelines and highlight the potential of the proposed framework as a robust and highly accurate tool for automated Alzheimer's disease diagnosis.

</details>


### [276] [Unveiling the Cognitive Compass: Theory-of-Mind-Guided Multimodal Emotion Reasoning](https://arxiv.org/abs/2602.00971)
*Meng Luo,Bobo Li,Shanqing Xu,Shize Zhang,Qiuchan Chen,Menglu Han,Wenhao Chen,Yanxiang Huang,Hao Fei,Mong-Li Lee,Wynne Hsu*

Main category: cs.CV

TL;DR: 本研究提出了一种名为HitEmotion的基于心智理论（ToM）的基准测试和一种新的推理方法TMPO，用于提高多模态大型语言模型（MLLMs）的情感理解能力，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在深度情感理解方面能力有限，作者认为这是由于缺乏对心智理论（ToM）的明确建模，而ToM是情感产生的认知基础。

Method: 1. 提出HitEmotion，一个基于ToM的层级基准测试，用于诊断模型在不同认知深度下的情感理解能力。2. 提出一个ToM引导的推理链，用于跟踪心智状态并校准跨模态证据以实现准确的情感推理。3. 引入TMPO，一种使用中间心智状态作为过程级监督的强化学习方法，以指导和加强模型推理。

Result: HitEmotion暴露了现有先进模型在深度情感推理方面的不足，特别是在认知要求高的任务上。ToM引导的推理链和TMPO提高了最终任务的准确性，并产生了更真实、更连贯的推理过程。

Conclusion: 该研究提供了一个评估和增强MLLMs基于认知的情感理解能力的实用工具包，包括基准数据集、评估方法和训练技术。

Abstract: Despite rapid progress in multimodal large language models (MLLMs), their capability for deep emotional understanding remains limited. We argue that genuine affective intelligence requires explicit modeling of Theory of Mind (ToM), the cognitive substrate from which emotions arise. To this end, we introduce HitEmotion, a ToM-grounded hierarchical benchmark that diagnoses capability breakpoints across increasing levels of cognitive depth. Second, we propose a ToM-guided reasoning chain that tracks mental states and calibrates cross-modal evidence to achieve faithful emotional reasoning. We further introduce TMPO, a reinforcement learning method that uses intermediate mental states as process-level supervision to guide and strengthen model reasoning. Extensive experiments show that HitEmotion exposes deep emotional reasoning deficits in state-of-the-art models, especially on cognitively demanding tasks. In evaluation, the ToM-guided reasoning chain and TMPO improve end-task accuracy and yield more faithful, more coherent rationales. In conclusion, our work provides the research community with a practical toolkit for evaluating and enhancing the cognition-based emotional understanding capabilities of MLLMs. Our dataset and code are available at: https://HitEmotion.github.io/.

</details>


### [277] [VAMOS-OCTA: Vessel-Aware Multi-Axis Orthogonal Supervision for Inpainting Motion-Corrupted OCT Angiography Volumes](https://arxiv.org/abs/2602.00995)
*Nick DiSanto,Ehsan Khodapanah Aghdam,Han Liu,Jacob Watson,Yuankai K. Tao,Hao Li,Ipek Oguz*

Main category: cs.CV

TL;DR: 提出了一种名为VAMOS-OCTA的深度学习框架，通过血管感知多轴监督来修复手持OCTA成像中因运动引起的B扫描伪影，从而提高图像质量。


<details>
  <summary>Details</summary>
Motivation: 手持OCTA成像在儿科和不合作受试者中很有用，但极易受到运动伪影的影响，这会严重降低三维图像质量。本研究旨在解决运动伪影导致的三维OCTA数据质量下降问题。

Method: 采用基于2.5D U-Net的深度学习架构，输入相邻的B扫描序列来重建中心B扫描。该方法使用新颖的血管感知多轴正交监督（VAMOS）损失，该损失结合了血管加权强度重建以及轴向和横向投影一致性，以鼓励血管在原生B扫描和正交平面上的连续性。

Result: VAMOS-OCTA能够同时提高B扫描切片的清晰度和三维投影的准确性，即使在严重的运动伪影下也能有效工作。与现有方法相比，VAMOS-OCTA能够重建出具有清晰毛细血管、恢复的血管连续性和干净的正面投影的图像。

Conclusion: 多轴监督是恢复运动退化3D OCTA数据的有效约束方法。VAMOS-OCTA框架在修复运动伪影方面表现出色，能够显著提高手持OCTA成像的质量。

Abstract: Handheld Optical Coherence Tomography Angiography (OCTA) enables noninvasive retinal imaging in uncooperative or pediatric subjects, but is highly susceptible to motion artifacts that severely degrade volumetric image quality. Sudden motion during 3D acquisition can lead to unsampled retinal regions across entire B-scans (cross-sectional slices), resulting in blank bands in en face projections. We propose VAMOS-OCTA, a deep learning framework for inpainting motion-corrupted B-scans using vessel-aware multi-axis supervision. We employ a 2.5D U-Net architecture that takes a stack of neighboring B-scans as input to reconstruct a corrupted center B-scan, guided by a novel Vessel-Aware Multi-Axis Orthogonal Supervision (VAMOS) loss. This loss combines vessel-weighted intensity reconstruction with axial and lateral projection consistency, encouraging vascular continuity in native B-scans and across orthogonal planes. Unlike prior work that focuses primarily on restoring the en face MIP, VAMOS-OCTA jointly enhances both cross-sectional B-scan sharpness and volumetric projection accuracy, even under severe motion corruptions. We trained our model on both synthetic and real-world corrupted volumes and evaluated its performance using both perceptual quality and pixel-wise accuracy metrics. VAMOS-OCTA consistently outperforms prior methods, producing reconstructions with sharp capillaries, restored vessel continuity, and clean en face projections. These results demonstrate that multi-axis supervision offers a powerful constraint for restoring motion-degraded 3D OCTA data. Our source code is available at https://github.com/MedICL-VU/VAMOS-OCTA.

</details>


### [278] [SRVAU-R1: Enhancing Video Anomaly Understanding via Reflection-Aware Learning](https://arxiv.org/abs/2602.01004)
*Zihao Zhao,Shengting Cao,Muchao Ye*

Main category: cs.CV

TL;DR: 提出了一种名为SRVAU-R1的反射感知学习框架，通过引入首个针对视频异常理解（VAU）的链式思考数据集以及监督和强化微调，增强了多模态大语言模型（MLLM）的推理能力，从而在视频异常检测和推理质量方面取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: 现有基于MLLM的视频异常理解方法仅停留在表面描述，缺乏深入的自我反思和纠错能力，无法进行深层推理。

Method: 提出SRVAU-R1框架，包含：1. 专为VAU设计的首个面向反射的链式思考数据集（包含初始推理、自我反思、修正推理）；2. 新颖的反射感知学习范式，通过监督微调和强化微调来增强多模态推理。

Result: SRVAU-R1在多个视频异常基准测试中表现优于现有方法，在时间异常定位准确性和推理质量方面均有显著提升。

Conclusion: SRVAU-R1通过引入反射机制，有效提升了MLLM在视频异常理解任务中的深层推理能力，并在实验中取得了优异的性能。

Abstract: Multi-modal large language models (MLLMs) have demonstrated significant progress in reasoning capabilities and shown promising effectiveness in video anomaly understanding (VAU) tasks. However, existing MLLM-based approaches remain largely focused on surface-level descriptions of anomalies, lacking deep reasoning over abnormal behaviors like explicit self-reflection and self-correction. To address that, we propose Self-Reflection-Enhanced Reasoning for Video Anomaly Understanding (SRVAU-R1), a reflection-aware learning framework that incorporates reflection in MLLM reasoning. Specifically, SRVAU-R1 introduces the first reflection-oriented Chain-of-Thought dataset tailored for VAU, providing structured supervision with initial reasoning, self-reflection, and revised reasoning. Based on that, it includes a novel reflection-aware learning paradigm with supervised fine-tuning and reinforcement fine-tuning to enhance multi-modal reasoning for VAU. Extensive experiments on multiple video anomaly benchmarks demonstrate that SRVAU-R1 consistently outperforms existing methods, achieving significant improvements in both temporal anomaly localization accuracy and reasoning quality.

</details>


### [279] [CortiNet: A Physics-Perception Hybrid Cortical-Inspired Dual-Stream Network for Gallbladder Disease Diagnosis from Ultrasound](https://arxiv.org/abs/2602.01000)
*Vagish Kumar,Souvik Chakraborty*

Main category: cs.CV

TL;DR: 提出了一种名为CortiNet的轻量级、受皮质启发的双流神经网络，用于胆囊疾病诊断。该模型通过分离低频结构信息和高频感知细节，并结合物理学先验知识，实现了高效且高精度的诊断，同时参数量远小于传统模型。


<details>
  <summary>Details</summary>
Motivation: 传统用于超声图像诊断的卷积神经网络参数量大，难以在临床中部署。超声图像固有的低分辨率和散斑噪声影响诊断的可靠性。

Method: 提出CortiNet，一个轻量级、受皮质启发的双流神经网络。该模型将物理上可解释的多尺度信号分解与感知驱动的特征学习相结合，明确分离低频结构信息和高频感知细节，并通过专门的编码流进行处理。采用后期皮质风格融合机制整合结构和纹理线索。提出了一种结构感知可解释性框架，仅将梯度加权类激活映射应用于结构分支，以应对散斑噪声。

Result: 在10,692张专家标注的图像上评估，CortiNet在九种胆囊疾病类别上实现了98.74%的高诊断准确率，同时参数量远小于传统的深度卷积模型。

Conclusion: CortiNet通过其新颖的双流架构和物理学先验知识，成功地实现了轻量级、高精度的胆囊疾病超声图像诊断，并且其结构感知可解释性框架提高了模型对散斑噪声的鲁棒性，使其有望应用于实际临床场景。

Abstract: Ultrasound imaging is the primary diagnostic modality for detecting Gallbladder diseases due to its non-invasive nature, affordability, and wide accessibility. However, the low resolution and speckle noise inherent to ultrasound images hinder diagnostic reliability, prompting the use of large convolutional neural networks that are difficult to deploy in routine clinical settings. In this work, we propose CortiNet, a lightweight, cortical-inspired dual-stream neural architecture for gallbladder disease diagnosis that integrates physically interpretable multi-scale signal decomposition with perception-driven feature learning. Inspired by parallel processing pathways in the human visual cortex, CortiNet explicitly separates low-frequency structural information from high-frequency perceptual details and processes them through specialized encoding streams. By operating directly on structured, frequency-selective representations rather than raw pixel intensities, the architecture embeds strong physics-based inductive bias, enabling efficient feature learning with a significantly reduced parameter footprint. A late-stage cortical-style fusion mechanism integrates complementary structural and textural cues while preserving computational efficiency. Additionally, we propose a structure-aware explainability framework wherein gradient-weighted class activation mapping is only applied to the structural branch of the proposed CortiNet architecture. This choice allows the model to only focus on the structural features, making it robust against speckle noise. We evaluate CortiNet on 10,692 expert-annotated images spanning nine clinically relevant gallbladder disease categories. Experimental results demonstrate that CortiNet achieves high diagnostic accuracy (98.74%) with only a fraction of the parameters required by conventional deep convolutional models.

</details>


### [280] [LocalScore: Local Density-Aware Similarity Scoring for Biometrics](https://arxiv.org/abs/2602.01012)
*Yiyang Su,Minchul Kim,Jie Zhu,Christopher Perry,Feng Liu,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: 提出了一种名为LocalScore的开放集生物识别评分算法，通过考虑图库特征分布的局部密度来提高识别和验证的准确性，实验表明其能有效降低误识率。


<details>
  <summary>Details</summary>
Motivation: 现有生物识别系统在处理未注册的探针时鲁棒性差，并且在多样本图库的情况下，将个体变异性全局表示会导致决策边界不佳。

Method: 提出LocalScore算法，利用k近邻来显式地考虑图库特征分布的局部密度，该算法不依赖于特定架构或损失函数，计算开销小，可即插即用。

Result: 在多种生物识别模态的实验中，LocalScore在开放集检索（FNIR@FPIR从53%降至40%）和验证（TAR@FAR从51%升至74%）方面均显著提升。

Conclusion: LocalScore是一种有效且计算成本低廉的开放集生物识别评分方法，能够显著改善现有系统的性能，其增益效果与数据集特征相关。

Abstract: Open-set biometrics faces challenges with probe subjects who may not be enrolled in the gallery, as traditional biometric systems struggle to detect these non-mated probes. Despite the growing prevalence of multi-sample galleries in real-world deployments, most existing methods collapse intra-subject variability into a single global representation, leading to suboptimal decision boundaries and poor open-set robustness. To address this issue, we propose LocalScore, a simple yet effective scoring algorithm that explicitly incorporates the local density of the gallery feature distribution using the k-th nearest neighbors. LocalScore is architecture-agnostic, loss-independent, and incurs negligible computational overhead, making it a plug-and-play solution for existing biometric systems. Extensive experiments across multiple modalities demonstrate that LocalScore consistently achieves substantial gains in open-set retrieval (FNIR@FPIR reduced from 53% to 40%) and verification (TAR@FAR improved from 51% to 74%). We further provide theoretical analysis and empirical validation explaining when and why the method achieves the most significant gains based on dataset characteristics.

</details>


### [281] [Effectiveness of Automatically Curated Dataset in Thyroid Nodules Classification Algorithms Using Deep Learning](https://arxiv.org/abs/2602.01020)
*Jichen Yang,Jikai Zhang,Benjamin Wildman-Tobriner,Maciej A. Mazurowski*

Main category: cs.CV

TL;DR: 使用自动标注的甲状腺结节数据集训练的深度学习模型，在诊断准确性上显著优于使用手动标注数据集训练的模型，并且建议使用全部自动标注的数据，而不是仅使用其中准确率较高的子集。


<details>
  <summary>Details</summary>
Motivation: 手动标注甲状腺结节数据集费时费力，限制了深度学习模型的训练。本研究旨在评估自动标注数据集对深度学习模型性能的提升作用，并探索最优的数据集使用策略。

Method: 训练了三个深度学习模型：一个使用手动标注数据集，一个使用全部自动标注数据集，还有一个使用自动标注数据集中准确率更高的子集。通过比较这些模型的AUC值来评估性能。

Result: 使用全部自动标注数据集训练的模型AUC为0.694，显著高于手动标注数据集训练的模型（AUC=0.643）。使用准确率更高的自动标注子集训练的模型AUC为0.689，与使用全部自动标注数据集的模型相比，性能无显著差异。

Conclusion: 自动标注的甲状腺结节数据集可以显著提升深度学习模型的诊断性能。建议在训练时使用全部自动标注的数据，而非仅仅依赖于其中准确率更高的子集。

Abstract: The diagnosis of thyroid nodule cancers commonly utilizes ultrasound images. Several studies showed that deep learning algorithms designed to classify benign and malignant thyroid nodules could match radiologists' performance. However, data availability for training deep learning models is often limited due to the significant effort required to curate such datasets. The previous study proposed a method to curate thyroid nodule datasets automatically. It was tested to have a 63% yield rate and 83% accuracy. However, the usefulness of the generated data for training deep learning models remains unknown. In this study, we conducted experiments to determine whether using a automatically-curated dataset improves deep learning algorithms' performance. We trained deep learning models on the manually annotated and automatically-curated datasets. We also trained with a smaller subset of the automatically-curated dataset that has higher accuracy to explore the optimum usage of such dataset. As a result, the deep learning model trained on the manually selected dataset has an AUC of 0.643 (95% confidence interval [CI]: 0.62, 0.66). It is significantly lower than the AUC of the 6automatically-curated dataset trained deep learning model, 0.694 (95% confidence interval [CI]: 0.67, 0.73, P < .001). The AUC of the accurate subset trained deep learning model is 0.689 (95% confidence interval [CI]: 0.66, 0.72, P > .43), which is insignificantly worse than the AUC of the full automatically-curated dataset. In conclusion, we showed that using a automatically-curated dataset can substantially increase the performance of deep learning algorithms, and it is suggested to use all the data rather than only using the accurate subset.

</details>


### [282] [GMAC: Global Multi-View Constraint for Automatic Multi-Camera Extrinsic Calibration](https://arxiv.org/abs/2602.01033)
*Chentian Sun*

Main category: cs.CV

TL;DR: 提出了一种名为GMAC的框架，利用多视角重建网络的隐式几何表示来自动校准多相机系统的外参，无需标定物或显式几何模型，提高了在复杂动态环境下的鲁棒性和在线校准能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂动态环境或在线场景下鲁棒性和适用性有限，难以在实际应用中部署。

Method: GMAC将外参建模为全局变量，受限于潜在的多视角几何结构。通过剪枝和重构现有网络，使其潜在特征能够直接支持外参预测。同时，联合优化了交叉视角重投影一致性和多视角循环一致性。

Result: 在合成和真实世界多相机数据集上，GMAC实现了准确稳定的外参估计，无需显式3D重建或手动标定。

Conclusion: GMAC为高效部署和在线校准多相机系统提供了一种新方法，通过隐式几何表示实现了鲁棒且准确的外参估计。

Abstract: Automatic calibration of multi-camera systems, namely the accurate estimation of spatial extrinsic parameters, is fundamental for 3D reconstruction, panoramic perception, and multi-view data fusion. Existing methods typically rely on calibration targets, explicit geometric modeling, or task-specific neural networks. Such approaches often exhibit limited robustness and applicability in complex dynamic environments or online scenarios, making them difficult to deploy in practical applications. To address this, this paper proposes GMAC, a multi-camera extrinsic estimation framework based on the implicit geometric representations learned by multi-view reconstruction networks. GMAC models extrinsics as global variables constrained by the latent multi-view geometric structure and prunes and structurally reconfigures existing networks so that their latent features can directly support extrinsic prediction through a lightweight regression head, without requiring a completely new network design. Furthermore, GMAC jointly optimizes cross-view reprojection consistency and multi-view cycle consistency, ensuring geometric coherence across cameras while improving prediction accuracy and optimization stability. Experiments on both synthetic and real-world multi-camera datasets demonstrate that GMAC achieves accurate and stable extrinsic estimation without explicit 3D reconstruction or manual calibration, providing a new solution for efficient deployment and online calibration of multi-camera systems.

</details>


### [283] [FUSE-Flow: Scalable Real-Time Multi-View Point Cloud Reconstruction Using Confidence](https://arxiv.org/abs/2602.01035)
*Chentian Sun*

Main category: cs.CV

TL;DR: 提出了一种名为FUSE-Flow的实时多视角点云流式重建框架，该框架通过帧独立处理、状态无关和线性可扩展性，解决了现有方法计算复杂、内存占用高和可扩展性差的问题，并在保证实时性的同时提高了重建质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模多视角点云重建方法在实时性、重建质量和可扩展性之间难以取得平衡，主要面临计算复杂度高、内存占用大和难以处理多摄像头扩展等挑战。

Method: 提出FUSE-Flow框架，采用帧独立处理方式，通过测量置信度和3D距离一致性进行点云碎片融合。引入自适应空间哈希加权聚合方法，根据局部点云密度自适应划分3D空间，选择代表点进行加权融合，以应对稀疏和密集区域，并通过GPU并行化实现高效处理。

Result: FUSE-Flow在重叠、深度不连续和动态场景下，提高了重建的稳定性和几何保真度，同时保持了实时帧率。该框架具有高吞吐量、低延迟和线性复杂度。

Conclusion: FUSE-Flow是一个高效、鲁棒且可扩展的实时多视角点云流式重建框架，能够有效地解决现有方法的局限性，并在实际应用中展现出优越的性能。

Abstract: Real-time multi-view point cloud reconstruction is a core problem in 3D vision and immersive perception, with wide applications in VR, AR, robotic navigation, digital twins, and computer interaction. Despite advances in multi-camera systems and high-resolution depth sensors, fusing large-scale multi-view depth observations into high-quality point clouds under strict real-time constraints remains challenging. Existing methods relying on voxel-based fusion, temporal accumulation, or global optimization suffer from high computational complexity, excessive memory usage, and limited scalability, failing to simultaneously achieve real-time performance, reconstruction quality, and multi-camera extensibility. We propose FUSE-Flow, a frame-wise, stateless, and linearly scalable point cloud streaming reconstruction framework. Each frame independently generates point cloud fragments, fused via two weights, measurement confidence and 3D distance consistency to suppress noise while preserving geometric details. For large-scale multi-camera efficiency, we introduce an adaptive spatial hashing-based weighted aggregation method: 3D space is adaptively partitioned by local point cloud density, representative points are selected per cell, and weighted fusion is performed to handle both sparse and dense regions. With GPU parallelization, FUSE-Flow achieves high-throughput, low-latency point cloud generation and fusion with linear complexity. Experiments demonstrate that the framework improves reconstruction stability and geometric fidelity in overlapping, depth-discontinuous, and dynamic scenes, while maintaining real-time frame rates on modern GPUs, verifying its effectiveness, robustness, and scalability.

</details>


### [284] [VEQ: Modality-Adaptive Quantization for MoE Vision-Language Models](https://arxiv.org/abs/2602.01037)
*Guangshuo Qin,Zhiteng Li,Zheng Chen,Weihang Zhang,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: 本研究提出了视觉专家量化（VEQ）框架，一种用于压缩视觉语言模型（VLMs）的后训练量化（PTQ）方法。VEQ能够同时处理跨模态差异和专家异质性，显著提高了量化后模型的性能，并在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）虽然性能优越，但内存和计算成本高昂，因此需要进行模型压缩。现有的后训练量化（PTQ）方法未能有效解决视觉和语言令牌之间的差异以及不同专家贡献的不均匀性。

Method: 提出了一种名为视觉专家量化（VEQ）的双重感知量化框架。VEQ包含两个关键组件：1）模态-专家感知量化，通过专家激活频率优先考虑关键专家的误差最小化；2）模态亲和力感知量化，通过整合令牌-专家亲和力和模态信息来构建增强的Hessian矩阵，以指导校准过程。

Result: 在Kimi-VL和Qwen3-VL等多个基准测试上，VEQ在W3A16配置下，相比现有最先进的量化方法，平均准确率分别提高了2.04%和3.09%。VEQ在各种多模态任务中表现出优越的鲁棒性。

Conclusion: VEQ是一种有效的双重感知量化框架，能够有效解决VLMs在量化过程中面临的跨模态差异和专家异质性问题，显著提升了量化后模型的性能，为轻量化VLMs提供了有前景的解决方案。

Abstract: Mixture-of-Experts(MoE) Vision-Language Models (VLMs) offer remarkable performance but incur prohibitive memory and computational costs, making compression essential. Post-Training Quantization (PTQ) is an effective training-free technique to address the massive memory and computation overhead. Existing quantization paradigms fall short as they are oblivious to two critical forms of heterogeneity: the inherent discrepancy between vision and language tokens, and the non-uniform contribution of different experts. To bridge this gap, we propose Visual Expert Quantization (VEQ), a dual-aware quantization framework designed to simultaneously accommodate cross-modal differences and heterogeneity between experts. Specifically, VEQ incorporates 1)Modality-expert-aware Quantization, which utilizes expert activation frequency to prioritize error minimization for pivotal experts, and 2)Modality-affinity-aware Quantization, which constructs an enhanced Hessian matrix by integrating token-expert affinity with modality information to guide the calibration process. Extensive experiments across diverse benchmarks verify that VEQ consistently outperforms state-of-the-art baselines. Specifically, under the W3A16 configuration, our method achieves significant average accuracy gains of 2.04\% on Kimi-VL and 3.09\% on Qwen3-VL compared to the previous SOTA quantization methods, demonstrating superior robustness across various multimodal tasks. Our code will be available at https://github.com/guangshuoqin/VEQ.

</details>


### [285] [From Videos to Conversations: Egocentric Instructions for Task Assistance](https://arxiv.org/abs/2602.01038)
*Lavisha Aggarwal,Vikas Bahirwani,Andrea Colaco*

Main category: cs.CV

TL;DR: 本文提出了一种自动将单人教学视频转换为双人多模态对话式任务指导的新框架和数据集HowToDIV，旨在解决现实世界任务执行中大规模多模态对话数据集稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中许多复杂任务需要专家知识，现有AR辅助AI助手在多模态对话数据方面存在数据稀缺、成本高昂且难以大规模采集的问题。

Method: 提出一个全自动框架，利用大型语言模型将单人教学视频转换为双人多模态对话。在此基础上，构建了包含507个对话、6636个问答对和24小时视频的HowToDIV数据集，涵盖多个领域，模拟专家与新手之间的多轮交互。

Result: 成功构建了HowToDIV数据集，并使用Gemma 3和Qwen 2.5模型进行了基线测试，为多模态程序任务辅助提供了一个初步的性能评估基准。

Conclusion: 该自动框架为解决大规模多模态对话数据集稀缺问题提供了一种可扩展且经济高效的解决方案，HowToDIV数据集的发布和基线结果的报告，将推动多模态程序任务辅助领域的研究进展。

Abstract: Many everyday tasks, ranging from appliance repair and cooking to car maintenance, require expert knowledge, particularly for complex, multi-step procedures. Despite growing interest in AI agents for augmented reality (AR) assistance, progress remains limited by the scarcity of large-scale multimodal conversational datasets grounded in real-world task execution, in part due to the cost and logistical complexity of human-assisted data collection. In this paper, we present a framework to automatically transform single person instructional videos into two-person multimodal task-guidance conversations. Our fully automatic pipeline, based on large language models, provides a scalable and cost efficient alternative to traditional data collection approaches. Using this framework, we introduce HowToDIV, a multimodal dataset comprising 507 conversations, 6,636 question answer pairs, and 24 hours of video spanning multiple domains. Each session consists of a multi-turn expert-novice interaction. Finally, we report baseline results using Gemma 3 and Qwen 2.5 on HowToDIV, providing an initial benchmark for multimodal procedural task assistance.

</details>


### [286] [ReLayout: Versatile and Structure-Preserving Design Layout Editing via Relation-Aware Design Reconstruction](https://arxiv.org/abs/2602.01046)
*Jiawei Lin,Shizhao Sun,Danqing Huang,Ting Liu,Ji Li,Jiang Bian*

Main category: cs.CV

TL;DR: 本研究提出了 ReLayout 框架，用于在不依赖三元组数据的情况下，实现设计布局的自动编辑，该框架能够保留未编辑元素的原有布局结构。


<details>
  <summary>Details</summary>
Motivation: 现有设计工作流中，自动重新设计需要手动调整，研究旨在克服自然语言表达的用户意图模糊性，并解决缺乏三元组（原始设计、编辑操作、编辑后设计）数据的问题。

Method: ReLayout 框架首先引入关系图来约束布局结构保持，然后提出关系感知设计重建（RADR）方法，利用多模态大语言模型，通过从元素、关系图和合成的编辑操作中重建设计，以自监督方式模拟编辑过程。

Result: ReLayout 在编辑质量、准确性和布局结构保持方面显著优于基线模型，相关定性、定量结果和用户研究均证实了其有效性。

Conclusion: ReLayout 成功实现了无需三元组数据、可保持布局结构的设计布局编辑，解决了数据稀缺和结构保持的挑战，并通过多模态大语言模型实现了多功能编辑。

Abstract: Automated redesign without manual adjustments marks a key step forward in the design workflow. In this work, we focus on a foundational redesign task termed design layout editing, which seeks to autonomously modify the geometric composition of a design based on user intents. To overcome the ambiguity of user needs expressed in natural language, we introduce four basic and important editing actions and standardize the format of editing operations. The underexplored task presents a unique challenge: satisfying specified editing operations while simultaneously preserving the layout structure of unedited elements. Besides, the scarcity of triplet (original design, editing operation, edited design) samples poses another formidable challenge. To this end, we present ReLayout, a novel framework for versatile and structure-preserving design layout editing that operates without triplet data. Specifically, ReLayout first introduces the relation graph, which contains the position and size relationships among unedited elements, as the constraint for layout structure preservation. Then, relation-aware design reconstruction (RADR) is proposed to bypass the data challenge. By learning to reconstruct a design from its elements, a relation graph, and a synthesized editing operation, RADR effectively emulates the editing process in a self-supervised manner. A multi-modal large language model serves as the backbone for RADR, unifying multiple editing actions within a single model and thus achieving versatile editing after fine-tuning. Qualitative, quantitative results and user studies show that ReLayout significantly outperforms the baseline models in terms of editing quality, accuracy, and layout structure preservation.

</details>


### [287] [Residual Decoding: Mitigating Hallucinations in Large Vision-Language Models via History-Aware Residual Guidance](https://arxiv.org/abs/2602.01047)
*Xinrong Chen,Xu Chu,Yingmin Qiu,Hengyuan Zhang,Jing Xiong,Shiyu Tang,Shuai Liu,Shaokang Yang,Cheng Yang,Hayden Kwok-Hay So,Ngai Wong*

Main category: cs.CV

TL;DR: 提出了一种名为残差解码（ResDec）的训练无关方法，通过利用历史信息来纠正大型视觉语言模型（LVLM）中的语言先验偏见，从而减少幻觉并提高视觉基础性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）在多模态任务中表现出色，但受语言先验的影响容易产生与视觉输入不符的幻觉。需要一种方法来解决这个问题。

Method: 提出残差解码（ResDec）方法，这是一种训练无关的新颖方法，利用LVLM的内部隐式推理机制和token logits演变机制，通过历史信息辅助解码来纠正偏差。

Result: ResDec能有效抑制语言先验引起的幻觉，显著提高视觉基础性，并减少物体幻觉。此外，ResDec在综合LVLM基准测试中表现出色。

Conclusion: ResDec是一种有效的方法，可以减轻LVLM中的幻觉问题，同时保持或提高其在各种多模态任务上的整体性能，具有广泛的适用性。

Abstract: Large Vision-Language Models (LVLMs) can reason effectively from image-text inputs and perform well in various multimodal tasks. Despite this success, they are affected by language priors and often produce hallucinations. Hallucinations denote generated content that is grammatically and syntactically coherent, yet bears no match or direct relevance to actual visual input. To address this problem, we propose Residual Decoding (ResDec). It is a novel training-free method that uses historical information to aid decoding. The method relies on the internal implicit reasoning mechanism and token logits evolution mechanism of LVLMs to correct biases. Extensive experiments demonstrate that ResDec effectively suppresses hallucinations induced by language priors, significantly improves visual grounding, and reduces object hallucinations. In addition to mitigating hallucinations, ResDec also performs exceptionally well on comprehensive LVLM benchmarks, highlighting its broad applicability.

</details>


### [288] [Baseline Method of the Foundation Model Challenge for Ultrasound Image Analysis](https://arxiv.org/abs/2602.01055)
*Bo Deng,Yitong Tang,Jiake Li,Yuxin Huang,Li Wang,Yu Zhang,Yufei Zhan,Hua Lu,Xiaoshen Zhang,Jieyun Bai*

Main category: cs.CV

TL;DR: 本文提出了一个用于超声图像分析的多任务基础模型基线，该模型采用统一的多头多任务学习框架，能够处理27个不同子任务（分割、分类、检测、回归），并取得了有竞争力的结果，同时代码和数据集已公开。


<details>
  <summary>Details</summary>
Motivation: 现有的超声图像分析方法多是任务特定的，难以泛化，限制了其作为临床基础模型的潜力。因此，研究需要一个能够处理多种任务的通用模型。

Method: 使用一个基于EfficientNet-B4和特征金字塔网络（FPN）的统一多头多任务学习（MH-MTL）框架。该框架通过任务特定的路由策略，结合ImageNet预训练的骨干网络和多尺度特征提取，支持所有27个子任务。训练过程采用了复合损失函数，并结合了任务自适应学习率缩放和余弦退火调度。

Result: 提出的统一MH-MTL框架在FM_UIA 2026基准测试中取得了有竞争力的验证结果，证明了其通用设计在处理多种超声图像分析任务上的可行性和鲁棒性。

Conclusion: 该研究成功构建了一个能够处理多种超声图像分析任务的统一基础模型基线，为超声基础模型的研究提供了强大的、可扩展的起点，并且其代码和数据集已公开，便于进一步研究。

Abstract: Ultrasound (US) imaging exhibits substantial heterogeneity across anatomical structures and acquisition protocols, posing significant challenges to the development of generalizable analysis models. Most existing methods are task-specific, limiting their suitability as clinically deployable foundation models. To address this limitation, the Foundation Model Challenge for Ultrasound Image Analysis (FM\_UIA~2026) introduces a large-scale multi-task benchmark comprising 27 subtasks across segmentation, classification, detection, and regression. In this paper, we present the official baseline for FM\_UIA~2026 based on a unified Multi-Head Multi-Task Learning (MH-MTL) framework that supports all tasks within a single shared network. The model employs an ImageNet-pretrained EfficientNet--B4 backbone for robust feature extraction, combined with a Feature Pyramid Network (FPN) to capture multi-scale contextual information. A task-specific routing strategy enables global tasks to leverage high-level semantic features, while dense prediction tasks exploit spatially detailed FPN representations. Training incorporates a composite loss with task-adaptive learning rate scaling and a cosine annealing schedule. Validation results demonstrate the feasibility and robustness of this unified design, establishing a strong and extensible baseline for ultrasound foundation model research. The code and dataset are publicly available at \href{https://github.com/lijiake2408/Foundation-Model-Challenge-for-Ultrasound-Image-Analysis}{GitHub}.

</details>


### [289] [Radioactive 3D Gaussian Ray Tracing for Tomographic Reconstruction](https://arxiv.org/abs/2602.01057)
*Ling Chen,Bao Yang*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D高斯射线追踪的CT重建新框架，通过解析计算高斯原语的线积分，克服了现有基于高斯散点图方法的仿射近似限制，提高了投影精度，并能更好地处理非线性几何校正，从而扩展了高斯方法在各种断层扫描系统中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有的基于3D高斯散点图的CT重建方法（如R2-Gaussian）采用局部仿射近似，这会降低重建的量化精度并难以进行非线性几何校正。本文旨在克服这些局限性。

Method: 提出了一种基于3D高斯射线追踪的断层重建框架。该方法解析计算3D高斯原语的线积分，以获得更准确的投影，并利用射线追踪的特性来精确应用非线性几何校正。

Result: 提出的方法避免了局部仿射近似的不足，提供了更物理一致的前向投影模型，并能精确应用非线性几何校正。这提高了投影精度，并有望将高斯基重建扩展到更广泛的现实断层扫描系统。

Conclusion: 基于3D高斯射线追踪的框架比基于散点图的方法在准确性和通用性方面都有优势，能够处理更复杂的断层扫描系统并实现更精确的重建。

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged in computer vision as a promising rendering technique. By adapting the principles of Elliptical Weighted Average (EWA) splatting to a modern differentiable pipeline, 3DGS enables real-time, high-quality novel view synthesis. Building upon this, R2-Gaussian extended the 3DGS paradigm to tomographic reconstruction by rectifying integration bias, achieving state-of-the-art performance in computed tomography (CT). To enable differentiability, R2-Gaussian adopts a local affine approximation: each 3D Gaussian is locally mapped to a 2D Gaussian on the detector and composed via alpha blending to form projections. However, the affine approximation can degrade reconstruction quantitative accuracy and complicate the incorporation of nonlinear geometric corrections. To address these limitations, we propose a tomographic reconstruction framework based on 3D Gaussian ray tracing. Our approach provides two key advantages over splatting-based models: (i) it computes the line integral through 3D Gaussian primitives analytically, avoiding the local affine collapse and thus yielding a more physically consistent forward projection model; and (ii) the ray-tracing formulation gives explicit control over ray origins and directions, which facilitates the precise application of nonlinear geometric corrections, e.g., arc-correction used in positron emission tomography (PET). These properties extend the applicability of Gaussian-based reconstruction to a wider range of realistic tomography systems while improving projection accuracy.

</details>


### [290] [DRFormer: A Dual-Regularized Bidirectional Transformer for Person Re-identification](https://arxiv.org/abs/2602.01059)
*Ying Shu,Pujian Zhan,Huiqi Yang,Hehe Fan,Youfang Lin,Kai Lv*

Main category: cs.CV

TL;DR: 提出了一种名为DRFormer的框架，该框架通过双重正则化双向Transformer模型，融合了视觉基础模型（如DINO）提取的局部判别性细节和视觉-语言模型（如CLIP）捕获的全局语义特征，以解决行人重识别中的遮挡和姿态变化等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有行人重识别方法要么侧重于局部纹理，要么侧重于全局语义，忽略了两者结合的潜力。文章旨在探索并利用视觉基础模型和视觉-语言模型的互补性，以提高行人重识别的性能。

Method: 提出DRFormer框架，该框架采用双重正则化双向Transformer机制，融合DINO等视觉基础模型提取的局部特征和CLIP等视觉-语言模型提取的全局特征。双重正则化机制旨在促进多样化特征提取，并平衡两种模型的贡献。

Result: 在五个基准数据集上的实验表明，DRFormer能够有效地融合局部和全局表征，并取得了与现有最先进方法相媲美的性能。

Conclusion: DRFormer框架成功地结合了视觉基础模型和视觉-语言模型的优势，通过双重正则化机制实现了局部和全局特征的有效协同，从而在行人重识别任务中取得了优异的性能。

Abstract: Both fine-grained discriminative details and global semantic features can contribute to solving person re-identification challenges, such as occlusion and pose variations. Vision foundation models (\textit{e.g.}, DINO) excel at mining local textures, and vision-language models (\textit{e.g.}, CLIP) capture strong global semantic difference. Existing methods predominantly rely on a single paradigm, neglecting the potential benefits of their integration. In this paper, we analyze the complementary roles of these two architectures and propose a framework to synergize their strengths by a \textbf{D}ual-\textbf{R}egularized Bidirectional \textbf{Transformer} (\textbf{DRFormer}). The dual-regularization mechanism ensures diverse feature extraction and achieves a better balance in the contributions of the two models. Extensive experiments on five benchmarks show that our method effectively harmonizes local and global representations, achieving competitive performance against state-of-the-art methods.

</details>


### [291] [PDE-Constrained Optimization for Neural Image Segmentation with Physics Priors](https://arxiv.org/abs/2602.01069)
*Seema K. Poudel,Sunny K. Khadka*

Main category: cs.CV

TL;DR: 该研究提出了一种将偏微分方程（PDE）约束优化与深度学习相结合的图像分割方法，通过结合物理先验来提高分割精度、边界保真度和泛化能力，尤其在数据量少的情况下表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习模型在处理显微图像分割时，由于噪声、边界模糊和数据不足等问题，容易出现不稳定的解和泛化能力差的情况。因此，需要一种更稳定、泛化能力更强的分割方法。

Method: 将图像分割建模为PDE约束优化问题，通过变分正则化将物理先验整合到深度学习模型中。该框架最小化一个复合目标函数，包含数据保真项以及源自反应-扩散方程和相场界面能量的惩罚项，并以可微分残差损失的形式实现。实验中使用了UNet架构作为基线模型。

Result: 在LIVECell数据集上的实验表明，所提出的PDE正则化模型在分割准确性和边界保真度方面一致优于无约束的深度学习基线模型。此外，PDE正则化模型在低样本量情况下表现出更强的稳定性和更好的泛化能力。

Conclusion: PDE约束优化方法能够有效地增强数据驱动的学习框架，为变分方法、统计学习和科学机器学习之间搭建了原则性的桥梁，为解决显微图像分割等问题提供了一种新的、更鲁棒的解决方案。

Abstract: Segmentation of microscopy images constitutes an ill-posed inverse problem due to measurement noise, weak object boundaries, and limited labeled data. Although deep neural networks provide flexible nonparametric estimators, unconstrained empirical risk minimization often leads to unstable solutions and poor generalization. In this work, image segmentation is formulated as a PDE-constrained optimization problem that integrates physically motivated priors into deep learning models through variational regularization. The proposed framework minimizes a composite objective function consisting of a data fidelity term and penalty terms derived from reaction-diffusion equations and phase-field interface energies, all implemented as differentiable residual losses. Experiments are conducted on the LIVECell dataset, a high-quality, manually annotated collection of phase-contrast microscopy images. Training is performed on two cell types, while evaluation is carried out on a distinct, unseen cell type to assess generalization. A UNet architecture is used as the unconstrained baseline model. Experimental results demonstrate consistent improvements in segmentation accuracy and boundary fidelity compared to unconstrained deep learning baselines. Moreover, the PDE-regularized models exhibit enhanced stability and improved generalization in low-sample regimes, highlighting the advantages of incorporating structured priors. The proposed approach illustrates how PDE-constrained optimization can strengthen data-driven learning frameworks, providing a principled bridge between variational methods, statistical learning, and scientific machine learning.

</details>


### [292] [PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers](https://arxiv.org/abs/2602.01077)
*Haopeng Li,Shitong Shao,Wenliang Zhong,Zikai Zhou,Lichen Bai,Hui Xiong,Zeke Xie*

Main category: cs.CV

TL;DR: 提出了一种名为PISA的分块稀疏注意力机制，通过精确计算关键块并近似计算非关键块，在不牺牲质量的情况下显著加速了扩散Transformer在视频和图像生成方面的效率。


<details>
  <summary>Details</summary>
Motivation: 当前的扩散Transformer在视频和图像生成方面存在效率瓶颈，主要源于注意力机制的二次复杂度。现有的块稀疏注意力方法通过丢弃非关键块来加速计算，但在高稀疏度下会导致性能下降，因为它忽略了部分上下文信息。

Method: PISA提出了一种训练无关的分块稀疏注意力机制，其核心思想是利用非关键块注意力分数的分布稳定性，对其进行高效近似而不是直接丢弃。它采用“精确或近似”的策略：对关键块进行精确计算，并使用块级泰勒展开对非关键块进行高效近似。这样可以在保持全注意力范围的同时，将复杂度降低到亚二次。

Result: 在Wand2.1-14B和Hunyuan-Video数据集上，PISA分别实现了1.91倍和2.57倍的速度提升，并且在所有稀疏注意力方法中保持了最高的生成质量。在FLUX图像生成任务上，PISA实现了1.2倍的加速，而没有牺牲视觉质量。

Conclusion: PISA通过一种创新的近似策略，成功解决了传统稀疏注意力方法在高稀疏度下的性能退化问题，在保证生成质量的同时，显著提高了扩散Transformer的计算效率，为视频和图像生成提供了更优的解决方案。

Abstract: Diffusion Transformers are fundamental for video and image generation, but their efficiency is bottlenecked by the quadratic complexity of attention. While block sparse attention accelerates computation by attending only critical key-value blocks, it suffers from degradation at high sparsity by discarding context. In this work, we discover that attention scores of non-critical blocks exhibit distributional stability, allowing them to be approximated accurately and efficiently rather than discarded, which is essentially important for sparse attention design. Motivated by this key insight, we propose PISA, a training-free Piecewise Sparse Attention that covers the full attention span with sub-quadratic complexity. Unlike the conventional keep-or-drop paradigm that directly drop the non-critical block information, PISA introduces a novel exact-or-approximate strategy: it maintains exact computation for critical blocks while efficiently approximating the remainder through block-wise Taylor expansion. This design allows PISA to serve as a faithful proxy to full attention, effectively bridging the gap between speed and quality. Experimental results demonstrate that PISA achieves 1.91 times and 2.57 times speedups on Wan2.1-14B and Hunyuan-Video, respectively, while consistently maintaining the highest quality among sparse attention methods. Notably, even for image generation on FLUX, PISA achieves a 1.2 times acceleration without compromising visual quality. Code is available at: https://github.com/xie-lab-ml/piecewise-sparse-attention.

</details>


### [293] [MedAD-R1: Eliciting Consistent Reasoning in Interpretible Medical Anomaly Detection via Consistency-Reinforced Policy Optimization](https://arxiv.org/abs/2602.01081)
*Haitao Zhang,Yingying Wang,Jiaxiang Wang,Haote Xu,Hongyang Zhang,Yirong Chen,Yue Huang,Xinghao Ding*

Main category: cs.CV

TL;DR: 本研究提出了MedAD-38K，一个大型多模态医学异常检测基准，并引入了一个两阶段训练框架（认知注入和Con-GRPO）来提高LMM在医学影像分析中的推理能力和鲁棒性，MedAD-R1模型在该基准上达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的医学异常检测（MedAD）方法依赖于碎片化的数据集进行有监督微调（SFT），这限制了模型进行合理推理和泛化的能力。

Method: 研究者构建了一个包含诊断Chain-of-Thought（CoT）注释和结构化VQA对的大型多模态、多中心基准MedAD-38K。并提出了一种两阶段训练框架：1. 认知注入：通过SFT灌输医学知识并引入结构化的“思考-回答”范式。2. 一致性组相对策略优化（Con-GRPO）：引入一致性奖励，确保推理过程与最终诊断逻辑一致。

Result: 所提出的模型MedAD-R1在MedAD-38K基准上取得了SOTA性能，优于现有模型10%以上。

Conclusion: MedAD-R1模型通过生成透明且逻辑一致的推理路径，提升了AI在临床决策支持中的可信度和可解释性，为医学影像分析提供了一种有前景的方法。

Abstract: Medical Anomaly Detection (MedAD) presents a significant opportunity to enhance diagnostic accuracy using Large Multimodal Models (LMMs) to interpret and answer questions based on medical images. However, the reliance on Supervised Fine-Tuning (SFT) on simplistic and fragmented datasets has hindered the development of models capable of plausible reasoning and robust multimodal generalization. To overcome this, we introduce MedAD-38K, the first large-scale, multi-modal, and multi-center benchmark for MedAD featuring diagnostic Chain-of-Thought (CoT) annotations alongside structured Visual Question-Answering (VQA) pairs. On this foundation, we propose a two-stage training framework. The first stage, Cognitive Injection, uses SFT to instill foundational medical knowledge and align the model with a structured think-then-answer paradigm. Given that standard policy optimization can produce reasoning that is disconnected from the final answer, the second stage incorporates Consistency Group Relative Policy Optimization (Con-GRPO). This novel algorithm incorporates a crucial consistency reward to ensure the generated reasoning process is relevant and logically coherent with the final diagnosis. Our proposed model, MedAD-R1, achieves state-of-the-art (SOTA) performance on the MedAD-38K benchmark, outperforming strong baselines by more than 10\%. This superior performance stems from its ability to generate transparent and logically consistent reasoning pathways, offering a promising approach to enhancing the trustworthiness and interpretability of AI for clinical decision support.

</details>


### [294] [Differential Vector Erasure: Unified Training-Free Concept Erasure for Flow Matching Models](https://arxiv.org/abs/2602.01089)
*Zhiqi Zhang,Xinhao Zhong,Yi Sun,Shuoyang Sun,Bin Chen,Shu-Tao Xia,Xuan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为DVE（Differential Vector Erasure）的训练无关的概念擦除方法，专门用于流匹配模型，通过分析速度场中的方向差异来选择性地移除目标概念，实验证明在NSFW过滤、风格移除和物体擦除方面效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型容易生成不希望出现的概念（如NSFW内容、版权风格、特定物体），限制了其安全部署。而新的流匹配模型需要新的概念擦除方法，现有方法（主要针对DDPM）不适用。

Method: DVE是一种训练无关的概念擦除方法，它识别流匹配模型中速度场（表征生成流的方向结构）中的语义概念。通过构建一个表征目标概念和锚定概念之间方向差异的微分向量场，并在推理时将速度场投影到该微分方向上，选择性地移除目标概念，同时保留其他语义信息。

Result: 在FLUX数据集上的大量实验表明，DVE在NSFW抑制、艺术风格移除和物体擦除等多种概念擦除任务上，相比现有基线方法表现持续优越，同时保持了图像质量和多样性。

Conclusion: DVE是一种有效且通用的训练无关的概念擦除方法，适用于流匹配模型，能够精确地擦除目标概念，同时保留其他图像内容和质量。

Abstract: Text-to-image diffusion models have demonstrated remarkable capabilities in generating high-quality images, yet their tendency to reproduce undesirable concepts, such as NSFW content, copyrighted styles, or specific objects, poses growing concerns for safe and controllable deployment. While existing concept erasure approaches primarily focus on DDPM-based diffusion models and rely on costly fine-tuning, the recent emergence of flow matching models introduces a fundamentally different generative paradigm for which prior methods are not directly applicable. In this paper, we propose Differential Vector Erasure (DVE), a training-free concept erasure method specifically designed for flow matching models. Our key insight is that semantic concepts are implicitly encoded in the directional structure of the velocity field governing the generative flow. Leveraging this observation, we construct a differential vector field that characterizes the directional discrepancy between a target concept and a carefully chosen anchor concept. During inference, DVE selectively removes concept-specific components by projecting the velocity field onto the differential direction, enabling precise concept suppression without affecting irrelevant semantics. Extensive experiments on FLUX demonstrate that DVE consistently outperforms existing baselines on a wide range of concept erasure tasks, including NSFW suppression, artistic style removal, and object erasure, while preserving image quality and diversity.

</details>


### [295] [PandaPose: 3D Human Pose Lifting from a Single Image via Propagating 2D Pose Prior to 3D Anchor Space](https://arxiv.org/abs/2602.01095)
*Jinghong Zheng,Changlong Jiang,Yang Xiao,Jiaqi Li,Haohong Kuang,Hang Xu,Ran Wang,Zhiguo Cao,Min Du,Joey Tianyi Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为 PandaPose 的新方法，通过将 2D 姿势先验传播到 3D 锚点空间作为统一的中间表示，以解决从单张 RGB 图像进行 3D 人体姿势提升的挑战，该方法通过联合 3D 锚点、深度感知特征提升和锚点-特征交互解码器来处理 2D 姿势估计的不准确性和自遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接从 2D 映射到 3D 姿势，存在 2D 姿势误差传播和处理自遮挡困难的问题。

Method: 提出 PandaPose，使用 3D 锚点空间作为中间表示。该空间包含：1. 规范坐标系中的联合 3D 锚点；2. 深度感知联合特征提升；3. 锚点-特征交互解码器，生成统一的锚点查询，用于最终的锚点到联合预测。

Result: 在 Human3.6M, MPI-INF-3DHP 和 3DPW 基准测试中取得了优越性能，在 Human3.6M 的挑战性条件下，误差比现有最优方法减少了 14.7%。

Conclusion: PandaPose 是一种有效且鲁棒的 3D 人体姿势提升方法，通过将 2D 姿势先验集成到 3D 锚点空间，能够有效解决 2D 姿势估计不准确和自遮挡等挑战。

Abstract: 3D human pose lifting from a single RGB image is a challenging task in 3D vision. Existing methods typically establish a direct joint-to-joint mapping from 2D to 3D poses based on 2D features. This formulation suffers from two fundamental limitations: inevitable error propagation from input predicted 2D pose to 3D predictions and inherent difficulties in handling self-occlusion cases. In this paper, we propose PandaPose, a 3D human pose lifting approach via propagating 2D pose prior to 3D anchor space as the unified intermediate representation. Specifically, our 3D anchor space comprises: (1) Joint-wise 3D anchors in the canonical coordinate system, providing accurate and robust priors to mitigate 2D pose estimation inaccuracies. (2) Depth-aware joint-wise feature lifting that hierarchically integrates depth information to resolve self-occlusion ambiguities. (3) The anchor-feature interaction decoder that incorporates 3D anchors with lifted features to generate unified anchor queries encapsulating joint-wise 3D anchor set, visual cues and geometric depth information. The anchor queries are further employed to facilitate anchor-to-joint ensemble prediction. Experiments on three well-established benchmarks (i.e., Human3.6M, MPI-INF-3DHP and 3DPW) demonstrate the superiority of our proposition. The substantial reduction in error by $14.7\%$ compared to SOTA methods on the challenging conditions of Human3.6M and qualitative comparisons further showcase the effectiveness and robustness of our approach.

</details>


### [296] [Robust Harmful Meme Detection under Missing Modalities via Shared Representation Learning](https://arxiv.org/abs/2602.01101)
*Felix Breiteneder,Mohammad Belal,Muhammad Saad Saeed,Shahed Masoudian,Usman Naseem,Kulshrestha Juhi,Markus Schedl,Shah Nawaz*

Main category: cs.CV

TL;DR: 本研究提出了一个处理模态不完整（例如，缺少文本）的有害表情包检测方法，通过学习多模态的共享表示来提高检测性能，并在存在文本缺失的情况下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有有害表情包检测方法多依赖模态完整的数据（文本+图像），但在实际应用中，文本信息可能因OCR质量差等原因缺失，导致性能下降。本研究旨在解决这一问题，研究在模态不完整情况下有害表情包检测方法的行为。

Method: 提出了一种新的基线方法，通过独立投影学习多模态的共享表示。这些共享表示在数据模态不完整时可用。该方法旨在更好地整合视觉特征，减少对文本的依赖。

Result: 在两个基准数据集上的实验表明，在文本缺失的情况下，所提出的方法优于现有方法。结果还表明，该方法能够更好地整合视觉特征，提高在文本信息缺失场景下的鲁棒性。

Conclusion: 该研究为有害表情包检测在模态缺失的实际应用场景中提供了重要进展，通过学习共享表示提高了在模态不完整数据下的检测性能和鲁棒性。

Abstract: Internet memes are powerful tools for communication, capable of spreading political, psychological, and sociocultural ideas. However, they can be harmful and can be used to disseminate hate toward targeted individuals or groups. Although previous studies have focused on designing new detection methods, these often rely on modal-complete data, such as text and images. In real-world settings, however, modalities like text may be missing due to issues like poor OCR quality, making existing methods sensitive to missing information and leading to performance deterioration. To address this gap, in this paper, we present the first-of-its-kind work to comprehensively investigate the behavior of harmful meme detection methods in the presence of modal-incomplete data. Specifically, we propose a new baseline method that learns a shared representation for multiple modalities by projecting them independently. These shared representations can then be leveraged when data is modal-incomplete. Experimental results on two benchmark datasets demonstrate that our method outperforms existing approaches when text is missing. Moreover, these results suggest that our method allows for better integration of visual features, reducing dependence on text and improving robustness in scenarios where textual information is missing. Our work represents a significant step forward in enabling the real-world application of harmful meme detection, particularly in situations where a modality is absent.

</details>


### [297] [LightCity: An Urban Dataset for Outdoor Inverse Rendering and Reconstruction under Multi-illumination Conditions](https://arxiv.org/abs/2602.01118)
*Jingjing Wang,Qirui Hu,Chong Bao,Yuke Zhu,Hujun Bao,Zhaopeng Cui,Guofeng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一个名为 LightCity 的新型合成城市数据集，用于解决城市逆渲染中的复杂照明挑战，并利用该数据集对三个基础任务进行了基准测试和分析。


<details>
  <summary>Details</summary>
Motivation: 城市逆渲染在自动驾驶和数字孪生等领域至关重要，但现有研究缺乏能够模拟复杂照明条件（如多重照明、间接光和阴影效果）的数据集，这阻碍了对内在分解和三维重建的研究。

Method: 作者提出了 LightCity 数据集，这是一个高分辨率的合成城市数据集，包含超过 300 张不同天光的图像，覆盖街景和航拍视角，并提供了深度、法线、材质、光照和间接光等丰富的标注信息。此外，作者利用该数据集对城市环境中的三个基本任务进行了基准测试和分析。

Result: LightCity 数据集提供了多样化的照明条件，包括真实的间接光和阴影效果。通过利用该数据集进行的基准测试和分析，研究者能够全面了解城市环境中逆渲染的挑战。

Conclusion: LightCity 数据集为城市逆渲染领域的研究提供了一个坚实的基础，能够支持对内在分解和三维重建等任务的进一步研究和发展。

Abstract: Inverse rendering in urban scenes is pivotal for applications like autonomous driving and digital twins. Yet, it faces significant challenges due to complex illumination conditions, including multi-illumination and indirect light and shadow effects. However, the effects of these challenges on intrinsic decomposition and 3D reconstruction have not been explored due to the lack of appropriate datasets. In this paper, we present LightCity, a novel high-quality synthetic urban dataset featuring diverse illumination conditions with realistic indirect light and shadow effects. LightCity encompasses over 300 sky maps with highly controllable illumination, varying scales with street-level and aerial perspectives over 50K images, and rich properties such as depth, normal, material components, light and indirect light, etc. Besides, we leverage LightCity to benchmark three fundamental tasks in the urban environments and conduct a comprehensive analysis of these benchmarks, laying a robust foundation for advancing related research.

</details>


### [298] [Koo-Fu CLIP: Closed-Form Adaptation of Vision-Language Models via Fukunaga-Koontz Linear Discriminant Analysis](https://arxiv.org/abs/2602.01127)
*Matej Suchanek,Klara Janouskova,Ondrej Vasatko,Jiri Matas*

Main category: cs.CV

TL;DR: 提出了一种名为Koo-Fu CLIP的监督式CLIP适配方法，利用Fukunaga-Koontz线性判别分析在白化嵌入空间中操作，以抑制类内方差并增强类间判别力，从而提高分类准确率并实现高效的降维。


<details>
  <summary>Details</summary>
Motivation: 原始CLIP模型的嵌入在监督分类任务中表现不佳，类间分离性差且维度过高。

Method: 基于Fukunaga-Koontz线性判别分析（Fukunaga-Koontz Linear Discriminant Analysis），在白化嵌入空间中进行操作，以抑制类内方差并增强类间判别力。该方法产生一个闭式线性投影，重塑CLIP嵌入的几何形状。

Result: 在ImageNet-1K上，使用Koo-Fu CLIP空间的最近视觉原型分类将top-1准确率从75.1%提高到79.1%，并且在标签空间扩展到14K和21K类时，准确率也有持续的提升。该方法支持高达10-12倍的压缩，且准确率损失很小或没有损失。

Conclusion: Koo-Fu CLIP是一种轻量级且高效的CLIP表示适配方法，能够显著提高大规模图像分类和检索的准确率和效率。

Abstract: Visual-language models such as CLIP provide powerful general-purpose representations, but their raw embeddings are not optimized for supervised classification, often exhibiting limited class separation and excessive dimensionality. We propose Koo-Fu CLIP, a supervised CLIP adaptation method based on Fukunaga-Koontz Linear Discriminant Analysis, which operates in a whitened embedding space to suppress within-class variation and enhance between-class discrimination. The resulting closed-form linear projection reshapes the geometry of CLIP embeddings, improving class separability while performing effective dimensionality reduction, and provides a lightweight and efficient adaptation of CLIP representations.
  Across large-scale ImageNet benchmarks, nearest visual prototype classification in the Koo-Fu CLIP space improves top-1 accuracy from 75.1% to 79.1% on ImageNet-1K, with consistent gains persisting as the label space expands to 14K and 21K classes. The method supports substantial compression by up to 10-12x with little or no loss in accuracy, enabling efficient large-scale classification and retrieval.

</details>


### [299] [Semantically Aware UAV Landing Site Assessment from Remote Sensing Imagery via Multimodal Large Language Models](https://arxiv.org/abs/2602.01163)
*Chunliang Hua,Zeyuan Yang,Lei Zhang,Jiayang Sun,Fengwen Chen,Chunlan Zeng,Xiao Hu*

Main category: cs.CV

TL;DR: 本文提出一种结合遥感影像和多模态大语言模型（MLLMs）的无人机紧急着陆点评估框架，通过粗到细的流程识别语义风险，并构建了ELSS数据集进行验证，实验结果表明该方法优于传统几何方法。


<details>
  <summary>Details</summary>
Motivation: 传统的几何传感器无法识别语义风险（如人群、临时建筑），而安全的人工智能无人机紧急着陆需要考虑这些复杂因素。

Method: 采用粗到细的流水线：1.轻量级语义分割模块预筛选候选区域；2.视觉-语言推理代理融合视觉特征和POI数据检测潜在危险。利用遥感影像和MLLMs进行全局上下文感知的着陆点评估。

Result: 所提出的框架在风险识别准确性上显著优于几何基线方法。此外，该方法能够生成类人、可解释的论证，增强了对自动化决策的信任。

Conclusion: 该框架能够有效利用遥感影像和MLLMs进行无人机紧急着陆点的全局上下文感知评估，并能识别传统几何方法难以检测的语义风险，提高了决策的可信度。

Abstract: Safe UAV emergency landing requires more than just identifying flat terrain; it demands understanding complex semantic risks (e.g., crowds, temporary structures) invisible to traditional geometric sensors. In this paper, we propose a novel framework leveraging Remote Sensing (RS) imagery and Multimodal Large Language Models (MLLMs) for global context-aware landing site assessment. Unlike local geometric methods, our approach employs a coarse-to-fine pipeline: first, a lightweight semantic segmentation module efficiently pre-screens candidate areas; second, a vision-language reasoning agent fuses visual features with Point-of-Interest (POI) data to detect subtle hazards. To validate this approach, we construct and release the Emergency Landing Site Selection (ELSS) benchmark. Experiments demonstrate that our framework significantly outperforms geometric baselines in risk identification accuracy. Furthermore, qualitative results confirm its ability to generate human-like, interpretable justifications, enhancing trust in automated decision-making. The benchmark dataset is publicly accessible at https://anonymous.4open.science/r/ELSS-dataset-43D7.

</details>


### [300] [EEmo-Logic: A Unified Dataset and Multi-Stage Framework for Comprehensive Image-Evoked Emotion Assessment](https://arxiv.org/abs/2602.01173)
*Lancheng Gao,Ziheng Jia,Zixuan Xing,Wei Sun,Huiyu Duan,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: 本研究提出了EEmoDB，一个大规模图像情感理解数据集，包含120万个问答对和3.6万个细粒度评估样本，并引入了EEmo-Logic，一个多模态大模型，用于更全面的情感理解。实验证明EEmo-Logic在情感问答和细粒度评估方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有模型在理解图像引发的情感的多维度属性和强度细微差别方面存在局限，难以实现更高级别的情感感知和推理能力。

Method: 研究者构建了EEmoDB数据集，包含EEmoDB-QA（120万问答对）和EEmo-Assess（3.6万细粒度评估样本）。并提出了一种名为EEmo-Logic的多模态大语言模型，通过指令微调和任务定制的相对偏好优化（GRPO）进行训练。

Result: EEmo-Logic在领域内和跨领域数据集上均取得了强大的性能，尤其在情感问答和细粒度评估任务上表现突出。

Conclusion: EEmoDB数据集和EEmo-Logic模型能够有效提升图像情感理解的准确性和全面性，为发展更具同理心的人机交互和相关应用奠定基础。

Abstract: Understanding the multi-dimensional attributes and intensity nuances of image-evoked emotions is pivotal for advancing machine empathy and empowering diverse human-computer interaction applications. However, existing models are still limited to coarse-grained emotion perception or deficient reasoning capabilities. To bridge this gap, we introduce EEmoDB, the largest image-evoked emotion understanding dataset to date. It features $5$ analysis dimensions spanning $5$ distinct task categories, facilitating comprehensive interpretation. Specifically, we compile $1.2M$ question-answering (QA) pairs (EEmoDB-QA) from $125k$ images via automated generation, alongside a $36k$ dataset (EEmoDB-Assess) curated from $25k$ images for fine-grained assessment. Furthermore, we propose EEmo-Logic, an all-in-one multimodal large language model (MLLM) developed via instruction fine-tuning and task-customized group relative preference optimization (GRPO) with novel reward design. Extensive experiments demonstrate that EEmo-Logic achieves robust performance in in-domain and cross-domain datasets, excelling in emotion QA and fine-grained assessment. The code is available at https://anonymous.4open.science/r/EEmoLogic.

</details>


### [301] [Refining Context-Entangled Content Segmentation via Curriculum Selection and Anti-Curriculum Promotion](https://arxiv.org/abs/2602.01183)
*Chunming He,Rihan Zhang,Fengyang Xiao,Dingming Zhang,Zhiwen Cao,Sina Farsiu*

Main category: cs.CV

TL;DR: 提出了一种名为CurriSeg的双阶段学习框架，用于解决具有挑战性的上下文纠缠内容分割（CECS）问题，通过课程学习和反课程学习相结合，提高了表示的可靠性，并在不增加参数或训练时间的情况下实现了跨多个CECS基准的稳健性提升。


<details>
  <summary>Details</summary>
Motivation: 受生物学习从易到难的原则启发，旨在解决上下文纠缠内容分割（CECS）这一难题，在这种情况下，物体与其周围环境共享视觉模式（例如伪装物体检测）。现有方法主要依赖架构改进，而忽略了在纠缠数据分布下控制鲁棒性的学习动态。

Method: CurriSeg框架包含两个阶段：1. 课程选择（Curriculum Selection）：根据样本损失的时间统计数据动态选择训练数据，区分“难但有用”的样本和“嘈杂或模糊”的样本。2. 反课程促进（Anti-Curriculum Promotion）：设计了“光谱盲化微调”（Spectral-Blindness Fine-Tuning），抑制高频分量，强制模型依赖低频结构和上下文线索，从而增强泛化能力。

Result: CurriSeg在多个CECS基准测试中取得了持续的性能提升，且没有增加额外的参数量或总训练时间。

Conclusion: CurriSeg提供了一种原则性的方法来理解学习的进步性和挑战性如何相互作用，从而培养稳健且具有上下文感知能力的分割模型。该框架能够有效地提高表示的可靠性，并增强模型在CECS任务上的泛化能力。

Abstract: Biological learning proceeds from easy to difficult tasks, gradually reinforcing perception and robustness. Inspired by this principle, we address Context-Entangled Content Segmentation (CECS), a challenging setting where objects share intrinsic visual patterns with their surroundings, as in camouflaged object detection. Conventional segmentation networks predominantly rely on architectural enhancements but often ignore the learning dynamics that govern robustness under entangled data distributions. We introduce CurriSeg, a dual-phase learning framework that unifies curriculum and anti-curriculum principles to improve representation reliability. In the Curriculum Selection phase, CurriSeg dynamically selects training data based on the temporal statistics of sample losses, distinguishing hard-but-informative samples from noisy or ambiguous ones, thus enabling stable capability enhancement. In the Anti-Curriculum Promotion phase, we design Spectral-Blindness Fine-Tuning, which suppresses high-frequency components to enforce dependence on low-frequency structural and contextual cues and thus strengthens generalization. Extensive experiments demonstrate that CurriSeg achieves consistent improvements across diverse CECS benchmarks without adding parameters or increasing total training time, offering a principled view of how progression and challenge interplay to foster robust and context-aware segmentation. Code will be released.

</details>


### [302] [EMFormer: Efficient Multi-Scale Transformer for Accumulative Context Weather Forecasting](https://arxiv.org/abs/2602.01194)
*Hao Chen,Tao Han,Jie Zhang,Song Guo,Fenghua Ling,Lei Bai*

Main category: cs.CV

TL;DR: 本文提出了一种新的长时天气预报框架，结合了高效多尺度Transformer（EMFormer）、累积上下文微调和复合损失函数，以提高预测精度并降低计算开销，同时在视觉任务上展现了良好的泛化能力和效率。


<details>
  <summary>Details</summary>
Motivation: 现有长时天气预报方法在延长预测时间时面临灾难性遗忘、误差累积和训练成本高昂的问题。

Method: 引入了高效多尺度Transformer（EMFormer）来提取多尺度特征；采用累积上下文微调以提升时间一致性；提出了一种动态平衡预训练和微调项的复合损失函数。

Result: 在天气预报和极端事件预测方面取得了显著的长期预测精度提升；EMFormer在ImageNet-1K和ADE20K视觉基准测试中表现出强大的泛化能力，并将多尺度模块的速度提升了5.69倍。

Conclusion: 所提出的EMFormer及其长时预报框架能够有效克服现有方法的局限性，在提高天气预报能力的同时，也展示了其在其他视觉任务上的潜力和效率优势。

Abstract: Long-term weather forecasting is critical for socioeconomic planning and disaster preparedness. While recent approaches employ finetuning to extend prediction horizons, they remain constrained by the issues of catastrophic forgetting, error accumulation, and high training overhead. To address these limitations, we present a novel pipeline across pretraining, finetuning and forecasting to enhance long-context modeling while reducing computational overhead. First, we introduce an Efficient Multi-scale Transformer (EMFormer) to extract multi-scale features through a single convolution in both training and inference. Based on the new architecture, we further employ an accumulative context finetuning to improve temporal consistency without degrading short-term accuracy. Additionally, we propose a composite loss that dynamically balances different terms via a sinusoidal weighting, thereby adaptively guiding the optimization trajectory throughout pretraining and finetuning. Experiments show that our approach achieves strong performance in weather forecasting and extreme event prediction, substantially improving long-term forecast accuracy. Moreover, EMFormer demonstrates strong generalization on vision benchmarks (ImageNet-1K and ADE20K) while delivering a 5.69x speedup over conventional multi-scale modules.

</details>


### [303] [Med3D-R1: Incentivizing Clinical Reasoning in 3D Medical Vision-Language Models for Abnormality Diagnosis](https://arxiv.org/abs/2602.01200)
*Haoran Lai,Zihang Jiang,Kun Zhang,Qingsong Yao,Rongsheng Wang,Zhiyang He,Xiaodong Tao,Wei Wei,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为Med3D-R1的强化学习框架，用于提升3D医学影像的视觉-语言模型在临床推理方面的能力，并在两个3D诊断基准测试（CT-RATE和RAD-ChestCT）上取得了最先进的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有3D医学影像的视觉-语言模型在临床推理方面存在挑战，原因包括：1. 体积医学影像的复杂性；2. 模型容易过拟合报告的表面模式；3. 缺乏可解释性奖励设计。

Method: Med3D-R1采用两阶段训练过程：1. 监督微调（SFT）：引入残差对齐机制以连接3D特征和文本嵌入，并采用异常重加权策略来强调临床信息丰富的词语并减少报告中的结构偏差。2. 强化学习（RL）：重新设计一致性奖励，以显式地促进连贯、逐步的诊断推理。

Result: 在CT-RATE和RAD-ChestCT两个3D诊断基准测试上，Med3D-R1取得了最先进的准确率，分别为41.92%和44.99%。这表明模型在异常诊断和临床推理方面有所改进，优于现有方法。

Conclusion: Med3D-R1框架通过改进的SFT和RL策略，显著提升了3D医学视觉-语言模型在临床推理任务上的性能。该方法有望通过实现更可靠、更透明的3D医学视觉-语言系统，来增强实际的诊断工作流程。

Abstract: Developing 3D vision-language models with robust clinical reasoning remains a challenge due to the inherent complexity of volumetric medical imaging, the tendency of models to overfit superficial report patterns, and the lack of interpretability-aware reward designs. In this paper, we propose Med3D-R1, a reinforcement learning framework with a two-stage training process: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). During SFT stage, we introduce a residual alignment mechanism to bridge the gap between high-dimensional 3D features and textual embeddings, and an abnormality re-weighting strategy to emphasize clinically informative tokens and reduce structural bias in reports. In RL stage, we redesign the consistency reward to explicitly promote coherent, step-by-step diagnostic reasoning. We evaluate our method on medical multiple-choice visual question answering using two 3D diagnostic benchmarks, CT-RATE and RAD-ChestCT, where our model attains state-of-the-art accuracies of 41.92\% on CT-RATE and 44.99\% on RAD-ChestCT. These results indicate improved abnormality diagnosis and clinical reasoning and outperform prior methods on both benchmarks. Overall, our approach holds promise for enhancing real-world diagnostic workflows by enabling more reliable and transparent 3D medical vision-language systems.

</details>


### [304] [Boosting Point-supervised Temporal Action Localization via Text Refinement and Alignment](https://arxiv.org/abs/2602.01257)
*Yunchuan Ma,Laiyun Qing,Guorong Li,Yuqing Liu,Yuankai Qi,Qingming Huang*

Main category: cs.CV

TL;DR: 提出了一种文本精炼与对齐（TRA）框架，通过引入文本描述来增强点监督时序动作定位的性能，取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 现有基于点监督的时序动作定位方法仅依赖视觉特征，忽略了文本描述中丰富的语义信息，限制了定位精度。

Method: 提出TRA框架，包含点文本精炼（PTR）和点多模态对齐（PMA）两个模块。首先利用预训练的多模态模型生成视频帧描述，然后PTR利用点标注和多个预训练模型精炼描述。PMA将视觉和文本特征投影到统一语义空间，并通过点级多模态对比学习缩小模态间差距，最后增强的多模态特征用于动作检测。

Result: 在五个常用基准数据集上的大量实验表明，所提出的TRA框架在性能上优于多种现有最先进方法。计算开销分析显示该框架可在单个24GB RTX 3090 GPU上运行，具有实用性和可扩展性。

Conclusion: TRA框架能够有效地利用文本信息来增强点监督时序动作定位的性能，为该领域提供了一种新的、更具信息量的方法。

Abstract: Recently, point-supervised temporal action localization has gained significant attention for its effective balance between labeling costs and localization accuracy. However, current methods only consider features from visual inputs, neglecting helpful semantic information from the text side. To address this issue, we propose a Text Refinement and Alignment (TRA) framework that effectively utilizes textual features from visual descriptions to complement the visual features as they are semantically rich. This is achieved by designing two new modules for the original point-supervised framework: a Point-based Text Refinement module (PTR) and a Point-based Multimodal Alignment module (PMA). Specifically, we first generate descriptions for video frames using a pre-trained multimodal model. Next, PTR refines the initial descriptions by leveraging point annotations together with multiple pre-trained models. PMA then projects all features into a unified semantic space and leverages a point-level multimodal feature contrastive learning to reduce the gap between visual and linguistic modalities. Last, the enhanced multi-modal features are fed into the action detector for precise localization. Extensive experimental results on five widely used benchmarks demonstrate the favorable performance of our proposed framework compared to several state-of-the-art methods. Moreover, our computational overhead analysis shows that the framework can run on a single 24 GB RTX 3090 GPU, indicating its practicality and scalability.

</details>


### [305] [Q-DiT4SR: Exploration of Detail-Preserving Diffusion Transformer Quantization for Real-World Image Super-Resolution](https://arxiv.org/abs/2602.01273)
*Xun Zhang,Kaicheng Yang,Hongliang Lu,Haotong Qin,Yong Guo,Yulun Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为Q-DiT4SR的后训练量化（PTQ）框架，专门用于加速基于DiT的真实世界图像超分辨率（Real-ISR）模型，解决了现有量化方法在DiT超分辨率任务上的性能下降问题，并实现了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Diffusion Transformers (DiTs) 在Real-ISR中效果显著，但推理负担过重，阻碍了实际应用。现有的PTQ方法大多针对U-Net或文本到图像任务，直接应用于DiT超分辨率模型会导致局部纹理严重退化。

Method: 提出Q-DiT4SR框架，包含两个核心技术：1. 异构SVD（H-SVD），结合全局低秩分支和局部块状秩1分支。2. 方差感知时空混合精度（VaSMP 和 VaTMP），分别进行层间权重位宽分配和层内激活精度调度。

Result: 在多个真实世界数据集上，Q-DiT4SR在W4A6和W4A4设置下均达到SOTA性能。特别是W4A4配置将模型大小减小了5.8倍，计算量减少了60多倍。

Conclusion: Q-DiT4SR是首个专为DiT-based Real-ISR设计的PTQ框架，通过H-SVD和VaSMP/VaTMP有效地解决了DiT超分辨率模型的量化性能下降问题，实现了显著的压缩和加速，为DiT在Real-ISR领域的实际应用铺平了道路。

Abstract: Recently, Diffusion Transformers (DiTs) have emerged in Real-World Image Super-Resolution (Real-ISR) to generate high-quality textures, yet their heavy inference burden hinders real-world deployment. While Post-Training Quantization (PTQ) is a promising solution for acceleration, existing methods in super-resolution mostly focus on U-Net architectures, whereas generic DiT quantization is typically designed for text-to-image tasks. Directly applying these methods to DiT-based super-resolution models leads to severe degradation of local textures. Therefore, we propose Q-DiT4SR, the first PTQ framework specifically tailored for DiT-based Real-ISR. We propose H-SVD, a hierarchical SVD that integrates a global low-rank branch with a local block-wise rank-1 branch under a matched parameter budget. We further propose Variance-aware Spatio-Temporal Mixed Precision: VaSMP allocates cross-layer weight bit-widths in a data-free manner based on rate-distortion theory, while VaTMP schedules intra-layer activation precision across diffusion timesteps via dynamic programming (DP) with minimal calibration. Experiments on multiple real-world datasets demonstrate that our Q-DiT4SR achieves SOTA performance under both W4A6 and W4A4 settings. Notably, the W4A4 quantization configuration reduces model size by 5.8$\times$ and computational operations by over 60$\times$. Our code and models will be available at https://github.com/xunzhang1128/Q-DiT4SR.

</details>


### [306] [TF-Lane: Traffic Flow Module for Robust Lane Perception](https://arxiv.org/abs/2602.01277)
*Yihan Xie,Han Xia,Zhen Yang*

Main category: cs.CV

TL;DR: 本文提出了一种交通流感知车道感知模块（TFM），通过利用实时交通流信息来增强现有车道感知算法，解决了在视觉信息不足情况下的性能下降问题，并且无需额外成本，实验证明其能显著提升车道感知的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的车道感知方法在视觉线索不足（如遮挡、车道缺失）时性能会显著下降。虽然高精地图可以弥补，但订阅成本高且实时性差。因此，需要一种成本低、实时性好的信息源来增强车道感知。

Method: 提出了一种交通流感知车道感知模块（TFM），该模块能够提取实时交通流特征，并将其与现有的车道感知算法融合。该方法在真实自动驾驶场景中产生灵感，并在开源算法和数据集上进行了验证。

Result: 在 Nuscenes 和 OpenLaneV2 两个公共数据集上，对四种主流模型进行了实验。结果显示，TFM 持续提升了性能，在 Nuscenes 数据集上 mAP 增益最高可达 +4.1%。

Conclusion: 交通流信息是一种有潜力且低成本的实时信息源，可以有效增强车道感知能力，尤其是在视觉信息受限的场景下。TFM 模块能够有效地提取和利用这些信息，并与现有算法融合，实现性能的显著提升。

Abstract: Autonomous driving systems require robust lane perception capabilities, yet existing vision-based detection methods suffer significant performance degradation when visual sensors provide insufficient cues, such as in occluded or lane-missing scenarios. While some approaches incorporate high-definition maps as supplementary information, these solutions face challenges of high subscription costs and limited real-time performance. To address these limitations, we explore an innovative information source: traffic flow, which offers real-time capabilities without additional costs. This paper proposes a TrafficFlow-aware Lane perception Module (TFM) that effectively extracts real-time traffic flow features and seamlessly integrates them with existing lane perception algorithms. This solution originated from real-world autonomous driving conditions and was subsequently validated on open-source algorithms and datasets. Extensive experiments on four mainstream models and two public datasets (Nuscenes and OpenLaneV2) using standard evaluation metrics show that TFM consistently improves performance, achieving up to +4.1% mAP gain on the Nuscenes dataset.

</details>


### [307] [DSFC-Net: A Dual-Encoder Spatial and Frequency Co-Awareness Network for Rural Road Extraction](https://arxiv.org/abs/2602.01278)
*Zhengbo Zhang,Yihe Tian,Wanke Xia,Lin Chen,Yue Sun,Kun Ding,Ying Wang,Bing Xu,Shiming Xiang*

Main category: cs.CV

TL;DR: 提出了一种名为DSFC-Net的双编码器框架，用于从高分辨率遥感图像中准确提取农村道路，该框架融合了空间域和频域信息，有效解决了农村道路提取中的遮挡、窄宽度和类别混淆等问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在城市环境中表现良好，但在农村地区由于高类内变异性、低类间可分性、植被遮挡和道路宽度窄等问题，提取效果不佳。因此需要一种能解决这些挑战的新方法。

Method: 提出DSFC-Net，一个双编码器框架。一个CNN分支用于捕捉局部细节和短程连续性，一个新颖的SFT（空间-频率混合Transformer）分支用于建模全局拓扑依赖性，并采用CFIA（交叉频率交互注意力）模块来解耦高低频信息。此外，还引入了CFFM（通道特征融合模块）来融合两个分支的特征。

Result: 在WHU-RuR+, DeepGlobe, Massachusetts等数据集上的实验表明，DSFC-Net的性能优于现有最先进的方法。

Conclusion: DSFC-Net通过有效地融合空间和频率域信息，并解决农村道路提取中的特有挑战，显著提高了农村道路提取的准确性。

Abstract: Accurate extraction of rural roads from high-resolution remote sensing imagery is essential for infrastructure planning and sustainable development. However, this task presents unique challenges in rural settings due to several factors. These include high intra-class variability and low inter-class separability from diverse surface materials, frequent vegetation occlusions that disrupt spatial continuity, and narrow road widths that exacerbate detection difficulties. Existing methods, primarily optimized for structured urban environments, often underperform in these scenarios as they overlook such distinctive characteristics. To address these challenges, we propose DSFC-Net, a dual-encoder framework that synergistically fuses spatial and frequency-domain information. Specifically, a CNN branch is employed to capture fine-grained local road boundaries and short-range continuity, while a novel Spatial-Frequency Hybrid Transformer (SFT) is introduced to robustly model global topological dependencies against vegetation occlusions. Distinct from standard attention mechanisms that suffer from frequency bias, the SFT incorporates a Cross-Frequency Interaction Attention (CFIA) module that explicitly decouples high- and low-frequency information via a Laplacian Pyramid strategy. This design enables the dynamic interaction between spatial details and frequency-aware global contexts, effectively preserving the connectivity of narrow roads. Furthermore, a Channel Feature Fusion Module (CFFM) is proposed to bridge the two branches by adaptively recalibrating channel-wise feature responses, seamlessly integrating local textures with global semantics for accurate segmentation. Comprehensive experiments on the WHU-RuR+, DeepGlobe, and Massachusetts datasets validate the superiority of DSFC-Net over state-of-the-art approaches.

</details>


### [308] [Who Transfers Safety? Identifying and Targeting Cross-Lingual Shared Safety Neurons](https://arxiv.org/abs/2602.01283)
*Xianhui Zhang,Chengyu Xie,Linxia Zhu,Yonghui Yang,Weixiang Zhao,Zifeng Cheng,Cong Wang,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本研究发现了大型语言模型（LLM）中存在一套跨语言共享安全神经元（SS-Neurons），它们是调节跨语言安全行为的关键少数神经元。通过激活和抑制这些神经元，研究证明了它们在将安全能力从高资源（HR）语言迁移到非高资源（NHR）语言中的桥梁作用。基于此，研究提出了一种针对SS-Neurons的训练策略，显著提升了NHR语言的安全性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言安全对齐存在显著不平衡，非高资源（NHR）语言比高资源（HR）语言更容易受到攻击。同时，尽管观察到了跨语言表征迁移，但驱动安全对齐的神经机制尚不清楚。

Method: 研究首先识别单语安全神经元（MS-Neurons）并验证其因果作用。然后，通过跨语言分析识别出SS-Neurons，它们是HR和NHR语言共享的MS-Neurons子集。通过抑制和增强SS-Neurons来观察其对模型安全行为的影响。最后，提出一种基于语言资源分布和模型架构的、面向神经元的训练策略，并针对SS-Neurons进行微调。

Result: 研究发现LLMs包含SS-Neurons，这一小组神经元对跨语言安全行为有关键影响。抑制SS-Neurons会导致NHR语言的安全性能同步下降，而增强它们则能提高跨语言防御的一致性。所提出的SS-Neurons训练策略在提升NHR语言安全性方面优于现有最先进方法，同时保持了模型的通用能力。

Conclusion: SS-Neurons是跨语言安全能力迁移的关键，通过靶向训练这些神经元可以有效地提升非高资源语言的安全性能，为解决多语言安全不平衡问题提供了一种新颖且高效的途径。

Abstract: Multilingual safety remains significantly imbalanced, leaving non-high-resource (NHR) languages vulnerable compared to robust high-resource (HR) ones. Moreover, the neural mechanisms driving safety alignment remain unclear despite observed cross-lingual representation transfer.
  In this paper, we find that LLMs contain a set of cross-lingual shared safety neurons (SS-Neurons), a remarkably small yet critical neuronal subset that jointly regulates safety behavior across languages.
  We first identify monolingual safety neurons (MS-Neurons) and validate their causal role in safety refusal behavior through targeted activation and suppression.
  Our cross-lingual analyses then identify SS-Neurons as the subset of MS-Neurons shared between HR and NHR languages, serving as a bridge to transfer safety capabilities from HR to NHR domains.
  We observe that suppressing these neurons causes concurrent safety drops across NHR languages, whereas reinforcing them improves cross-lingual defensive consistency.
  Building on these insights, we propose a simple neuron-oriented training strategy that targets SS-Neurons based on language resource distribution and model architecture. Experiments demonstrate that fine-tuning this tiny neuronal subset outperforms state-of-the-art methods, significantly enhancing NHR safety while maintaining the model's general capabilities.
  The code and dataset will be available athttps://github.com/1518630367/SS-Neuron-Expansion.

</details>


### [309] [Interacted Planes Reveal 3D Line Mapping](https://arxiv.org/abs/2602.01296)
*Zeran Ke,Bin Tan,Gui-Song Xia,Yujun Shen,Nan Xue*

Main category: cs.CV

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: 3D line mapping from multi-view RGB images provides a compact and structured visual representation of scenes. We study the problem from a physical and topological perspective: a 3D line most naturally emerges as the edge of a finite 3D planar patch. We present LiP-Map, a line-plane joint optimization framework that explicitly models learnable line and planar primitives. This coupling enables accurate and detailed 3D line mapping while maintaining strong efficiency (typically completing a reconstruction in 3 to 5 minutes per scene). LiP-Map pioneers the integration of planar topology into 3D line mapping, not by imposing pairwise coplanarity constraints but by explicitly constructing interactions between plane and line primitives, thus offering a principled route toward structured reconstruction in man-made environments. On more than 100 scenes from ScanNetV2, ScanNet++, Hypersim, 7Scenes, and Tanks\&Temple, LiP-Map improves both accuracy and completeness over state-of-the-art methods. Beyond line mapping quality, LiP-Map significantly advances line-assisted visual localization, establishing strong performance on 7Scenes. Our code is released at https://github.com/calmke/LiPMAP for reproducible research.

</details>


### [310] [Interaction-Consistent Object Removal via MLLM-Based Reasoning](https://arxiv.org/abs/2602.01298)
*Ching-Kai Huang,Wen-Chieh Lin,Yan-Cen Lee*

Main category: cs.CV

TL;DR: 该论文提出了一种名为交互一致性对象移除（ICOR）的新任务，旨在移除目标对象及其相关的交互元素，并提出了一种基于多模态大语言模型（MLLM）的推理增强对象移除框架（REORM）来解决这个问题。REORM能够识别并移除需要联合移除的元素，并包含一个自纠正机制和本地部署变体。同时，论文还引入了一个名为ICOREval的评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图像的对象移除方法仅移除目标对象，但忽略了与之相关的交互元素，导致结果在语义上不一致。因此，需要一种能够移除目标对象及其相关交互元素的方法，以实现语义一致的移除结果。

Method: 提出交互一致性对象移除（ICOR）任务。设计了一个名为REORM的框架，该框架利用多模态大语言模型（MLLM）来推理需要联合移除的交互元素。REORM包含MLLM驱动的分析、掩码引导的移除和自纠正机制，并提供了一个支持有限资源下精确编辑的本地部署变体。引入了ICOREval评估基准。

Result: REORM在ICOREval基准上取得了比现有最先进的图像编辑系统更好的性能，证明了其在生成交互一致性结果方面的有效性。

Conclusion: REORM框架能够有效地解决交互一致性对象移除问题，通过利用MLLM的推理能力，可以识别并移除目标对象及其相关的交互元素，从而生成语义一致的图像编辑结果。ICOREval基准为评估此类任务提供了有力的支持。

Abstract: Image-based object removal often erases only the named target, leaving behind interaction evidence that renders the result semantically inconsistent. We formalize this problem as Interaction-Consistent Object Removal (ICOR), which requires removing not only the target object but also associated interaction elements, such as lighting-dependent effects, physically connected objects, targetproduced elements, and contextually linked objects. To address this task, we propose Reasoning-Enhanced Object Removal with MLLM (REORM), a reasoningenhanced object removal framework that leverages multimodal large language models to infer which elements must be jointly removed. REORM features a modular design that integrates MLLM-driven analysis, mask-guided removal, and a self-correction mechanism, along with a local-deployment variant that supports accurate editing under limited resources. To support evaluation, we introduce ICOREval, a benchmark consisting of instruction-driven removals with rich interaction dependencies. On ICOREval, REORM outperforms state-of-the-art image editing systems, demonstrating its effectiveness in producing interactionconsistent results.

</details>


### [311] [ReDiStory: Region-Disentangled Diffusion for Consistent Visual Story Generation](https://arxiv.org/abs/2602.01303)
*Ayushman Sarkar,Zhenyu Yu,Chu Chen,Wei Tang,Kangning Cui,Mohd Yamani Idna Idris*

Main category: cs.CV

TL;DR: ReDiStory 是一种无需训练的框架，通过在推理时重组提示嵌入来改进多帧故事生成，它通过显式分解和去相关性来减少跨帧语义干扰，从而提高身份一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的免训练方法在生成视觉故事时，由于将身份和帧提示统一表示，常常导致跨帧语义干扰，从而削弱身份保持能力。因此，需要一种方法来解决这个问题。

Method: ReDiStory 框架通过在推理时重组提示嵌入来实现。它将文本嵌入显式分解为与身份相关的部分和帧特定的部分，然后通过抑制帧之间的共享方向来去除帧嵌入的关联性，从而减少跨帧干扰。

Result: ReDiStory 在不修改扩散模型参数或需要额外监督的情况下，提高了身份一致性，同时保持了提示的准确性。在 ConsiStory+ 基准测试上，与 1Prompt1Story 相比，在多个身份一致性指标上均取得了持续的改进。

Conclusion: ReDiStory 是一种有效的训练免费框架，可以通过推理时进行提示嵌入的重组，显著提高多帧视觉故事生成中的身份一致性，同时解决跨帧语义干扰问题。

Abstract: Generating coherent visual stories requires maintaining subject identity across multiple images while preserving frame-specific semantics. Recent training-free methods concatenate identity and frame prompts into a unified representation, but this often introduces inter-frame semantic interference that weakens identity preservation in complex stories. We propose ReDiStory, a training-free framework that improves multi-frame story generation via inference-time prompt embedding reorganization. ReDiStory explicitly decomposes text embeddings into identity-related and frame-specific components, then decorrelates frame embeddings by suppressing shared directions across frames. This reduces cross-frame interference without modifying diffusion parameters or requiring additional supervision. Under identical diffusion backbones and inference settings, ReDiStory improves identity consistency while maintaining prompt fidelity. Experiments on the ConsiStory+ benchmark show consistent gains over 1Prompt1Story on multiple identity consistency metrics. Code is available at: https://github.com/YuZhenyuLindy/ReDiStory

</details>


### [312] [StoryState: Agent-Based State Control for Consistent and Editable Storybooks](https://arxiv.org/abs/2602.01305)
*Ayushman Sarkar,Zhenyu Yu,Wei Tang,Chu Chen,Kangning Cui,Mohd Yamani Idna Idris*

Main category: cs.CV

TL;DR: 本文提出了StoryState，一个基于代理的编排层，用于在文本到图像生成模型之上引入一个显式且可编辑的故事状态，以解决现有故事书生成工具中故事状态隐式、编辑粗粒度且视觉一致性差的问题。StoryState通过结构化对象（角色表、全局设置、每页场景约束）和LLM代理来管理故事状态，并生成用于生成和编辑的提示。实验表明，StoryState在多页编辑任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型在故事书生成方面存在故事状态隐式、编辑粗粒度、视觉一致性差等问题，难以进行精细化编辑。

Method: 提出StoryState，一个基于代理的编排层，引入显式的、可编辑的故事状态。故事状态被表示为包含角色表、全局设置和每页场景约束的结构化对象。使用一组LLM代理来维护故事状态，并生成用于生成和编辑的提示。StoryState通过提示操作，不依赖于特定的模型。

Result: 在多页编辑任务中，StoryState能够实现局部页面编辑，提高跨页面一致性，并减少意外更改、交互轮次和编辑时间。与1Prompt1Story相比，StoryState在编辑效率和一致性上有所提升，接近Gemini Storybook的一次性生成一致性。

Conclusion: StoryState通过引入显式的、可编辑的故事状态和基于代理的编排，有效地解决了现有故事书生成工具的局限性，实现了更精细、更一致的故事编辑。该方法模型无关，易于集成。

Abstract: Large multimodal models have enabled one-click storybook generation, where users provide a short description and receive a multi-page illustrated story. However, the underlying story state, such as characters, world settings, and page-level objects, remains implicit, making edits coarse-grained and often breaking visual consistency. We present StoryState, an agent-based orchestration layer that introduces an explicit and editable story state on top of training-free text-to-image generation. StoryState represents each story as a structured object composed of a character sheet, global settings, and per-page scene constraints, and employs a small set of LLM agents to maintain this state and derive 1Prompt1Story-style prompts for generation and editing. Operating purely through prompts, StoryState is model-agnostic and compatible with diverse generation backends. System-level experiments on multi-page editing tasks show that StoryState enables localized page edits, improves cross-page consistency, and reduces unintended changes, interaction turns, and editing time compared to 1Prompt1Story, while approaching the one-shot consistency of Gemini Storybook. Code is available at https://github.com/YuZhenyuLindy/StoryState

</details>


### [313] [DeCorStory: Gram-Schmidt Prompt Embedding Decorrelation for Consistent Storytelling](https://arxiv.org/abs/2602.01306)
*Ayushman Sarkar,Zhenyu Yu,Mohd Yamani Idna Idris*

Main category: cs.CV

TL;DR: 提出了一种名为DeCorStory的训练无关的推理框架，用于提升文本到图像故事生成的帧间视觉和语义一致性，通过提示嵌入解耦、奇异值重加权和身份保持交叉注意力来减少语义干扰。


<details>
  <summary>Details</summary>
Motivation: 现有的训练无关方法（如One-Prompt-One-Story）将所有提示连接成一个序列，容易导致嵌入相关性过强，从而引发颜色渗漏、背景融合和身份漂移等问题。

Method: DeCorStory采用Gram-Schmidt提示嵌入解耦来正交化帧级语义，然后使用奇异值重加权来加强提示特异性信息，并结合身份保持交叉注意力来稳定扩散过程中的角色身份。该方法无需模型修改或微调，可直接集成到现有扩散模型中。

Result: 实验结果显示，DeCorStory在提示-图像对齐、身份一致性和视觉多样性方面均取得了持续的改进，并在训练无关基线方法中达到了最先进的性能。

Conclusion: DeCorStory是一种有效的训练无关框架，通过明确减少帧间语义干扰，显著提升了文本到图像故事生成中的视觉和语义一致性，并在不进行模型微调的情况下实现了优于现有方法的性能。

Abstract: Maintaining visual and semantic consistency across frames is a key challenge in text-to-image storytelling. Existing training-free methods, such as One-Prompt-One-Story, concatenate all prompts into a single sequence, which often induces strong embedding correlation and leads to color leakage, background blending, and identity drift. We propose DeCorStory, a training-free inference-time framework that explicitly reduces inter-frame semantic interference. DeCorStory applies Gram-Schmidt prompt embedding decorrelation to orthogonalize frame-level semantics, followed by singular value reweighting to strengthen prompt-specific information and identity-preserving cross-attention to stabilize character identity during diffusion. The method requires no model modification or fine-tuning and can be seamlessly integrated into existing diffusion pipelines. Experiments demonstrate consistent improvements in prompt-image alignment, identity consistency, and visual diversity, achieving state-of-the-art performance among training-free baselines. Code is available at: https://github.com/YuZhenyuLindy/DeCorStory

</details>


### [314] [FlowCast: Trajectory Forecasting for Scalable Zero-Cost Speculative Flow Matching](https://arxiv.org/abs/2602.01329)
*Divya Jyoti Bajpai,Shubham Agarwal,Apoorv Saxena,Kuldeep Kulkarni,Subrata Mitra,Manjesh Kumar Hanawal*

Main category: cs.CV

TL;DR: FlowCast 是一种无需训练的推断加速框架，通过利用流匹配模型恒定速度的特性，在不损失图像质量的情况下，将图像生成、视频生成和编辑的速度提高了 2.5 倍以上。


<details>
  <summary>Details</summary>
Motivation: 流匹配模型在高质量视觉生成方面表现出色，但其推断速度过慢，限制了其实时和交互式应用。现有的加速方法存在质量下降、需要昂贵的再训练或泛化性不足的问题。

Method: FlowCast 提出了一种训练无关的投机生成框架。它利用流匹配模型速度恒定的训练目标，通过外推当前速度来预测未来的速度，并在均方误差小于阈值时接受该预测。这种恒定速度预测允许跳过稳定区域的冗余步骤，同时在复杂区域保持精度。

Result: 在图像生成、视频生成和编辑任务上，FlowCast 实现了超过 2.5 倍的速度提升，并且与标准的完整生成相比，没有质量损失，优于现有基线方法。

Conclusion: FlowCast 是一种即插即用的框架，可以无缝集成到任何流匹配模型中，无需辅助网络。它通过恒定速度预测有效地加速了流匹配模型的推断，同时保持了生成质量。

Abstract: Flow Matching (FM) has recently emerged as a powerful approach for high-quality visual generation. However, their prohibitively slow inference due to a large number of denoising steps limits their potential use in real-time or interactive applications. Existing acceleration methods, like distillation, truncation, or consistency training, either degrade quality, incur costly retraining, or lack generalization. We propose FlowCast, a training-free speculative generation framework that accelerates inference by exploiting the fact that FM models are trained to preserve constant velocity. FlowCast speculates future velocity by extrapolating current velocity without incurring additional time cost, and accepts it if it is within a mean-squared error threshold. This constant-velocity forecasting allows redundant steps in stable regions to be aggressively skipped while retaining precision in complex ones. FlowCast is a plug-and-play framework that integrates seamlessly with any FM model and requires no auxiliary networks. We also present a theoretical analysis and bound the worst-case deviation between speculative and full FM trajectories. Empirical evaluations demonstrate that FlowCast achieves $>2.5\times$ speedup in image generation, video generation, and editing tasks, outperforming existing baselines with no quality loss as compared to standard full generation.

</details>


### [315] [What Does Vision Tool-Use Reinforcement Learning Really Learn? Disentangling Tool-Induced and Intrinsic Effects for Crop-and-Zoom](https://arxiv.org/abs/2602.01334)
*Yan Ma,Weiyu Zhang,Tianle Li,Linge Du,Xuyang Shen,Pengfei Liu*

Main category: cs.CV

TL;DR: 本研究提出的MED框架通过解耦内在能力变化和工具引入的影响，发现当前视觉工具使用强化学习主要在于减少工具带来的负面影响，而非精通工具。


<details>
  <summary>Details</summary>
Motivation: 当前视觉工具使用强化学习虽然带来了性能提升，但尚不清楚这种提升是源于工具使用能力的改进还是模型内在能力的演进。

Method: 提出MED（Measure-Explain-Diagnose）框架，该框架采用粗粒度到细粒度的分析方法，将内在能力的变化与工具引入的效果分离开来，并将工具引入的性能差异分解为增益和损害项，以探究驱动其演变的机制。

Result: 在对两个具有不同工具先验的视觉语言模型（VLM）以及六个基准进行检查点级别分析后，研究发现性能提升主要由内在学习驱动。工具使用强化学习主要降低了工具引入的损害（例如，减少了调用错误和削弱了工具模式的干扰），在工具纠正内在失败方面进展有限。

Conclusion: 总的来说，当前的视觉工具使用强化学习旨在与工具安全共存，而非掌握工具的使用。

Abstract: Vision tool-use reinforcement learning (RL) can equip vision-language models with visual operators such as crop-and-zoom and achieves strong performance gains, yet it remains unclear whether these gains are driven by improvements in tool use or evolving intrinsic capabilities.We introduce MED (Measure-Explain-Diagnose), a coarse-to-fine framework that disentangles intrinsic capability changes from tool-induced effects, decomposes the tool-induced performance difference into gain and harm terms, and probes the mechanisms driving their evolution. Across checkpoint-level analyses on two VLMs with different tool priors and six benchmarks, we find that improvements are dominated by intrinsic learning, while tool-use RL mainly reduces tool-induced harm (e.g., fewer call-induced errors and weaker tool schema interference) and yields limited progress in tool-based correction of intrinsic failures. Overall, current vision tool-use RL learns to coexist safely with tools rather than master them.

</details>


### [316] [Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning](https://arxiv.org/abs/2602.01335)
*Yu Xu,Yuxin Zhang,Juan Cao,Lin Gao,Chunyu Wang,Oliver Deussen,Tong-Yee Lee,Fan Tang*

Main category: cs.CV

TL;DR: 提出视觉隐喻迁移（VMT）任务，并开发了一个受认知启发的、多智能体框架，该框架基于概念融合理论（CBT）和一个新的模式语法（Schema Grammar），以实现生成式AI在视觉隐喻创作方面的突破。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI在生成视觉隐喻方面存在不足，难以捕捉生成隐喻所需的抽象逻辑，而仅仅停留在像素级和表面外观的匹配。研究旨在弥合这一差距，实现真正的隐喻生成。

Method: 提出视觉隐喻迁移（VMT）任务。开发了一个受认知启发的、多智能体框架，该框架将概念融合理论（CBT）操作化为一个新的模式语法（Schema Grammar, "G"）。该框架包含一个感知智能体（提取模式）、一个迁移智能体（保持泛化空间不变性）、一个生成智能体（高保真合成）和一个诊断智能体（用于反馈和纠错）。

Result: 实验和人类评估表明，该方法在隐喻一致性、类比恰当性和视觉创造力方面显著优于现有最先进的基线方法。

Conclusion: 该研究成功地通过VMT任务和多智能体框架实现了自动化视觉隐喻生成，为广告和媒体等领域的创意应用提供了新的可能性。

Abstract: A visual metaphor constitutes a high-order form of human creativity, employing cross-domain semantic fusion to transform abstract concepts into impactful visual rhetoric. Despite the remarkable progress of generative AI, existing models remain largely confined to pixel-level instruction alignment and surface-level appearance preservation, failing to capture the underlying abstract logic necessary for genuine metaphorical generation. To bridge this gap, we introduce the task of Visual Metaphor Transfer (VMT), which challenges models to autonomously decouple the "creative essence" from a reference image and re-materialize that abstract logic onto a user-specified target subject. We propose a cognitive-inspired, multi-agent framework that operationalizes Conceptual Blending Theory (CBT) through a novel Schema Grammar ("G"). This structured representation decouples relational invariants from specific visual entities, providing a rigorous foundation for cross-domain logic re-instantiation. Our pipeline executes VMT through a collaborative system of specialized agents: a perception agent that distills the reference into a schema, a transfer agent that maintains generic space invariance to discover apt carriers, a generation agent for high-fidelity synthesis and a hierarchical diagnostic agent that mimics a professional critic, performing closed-loop backtracking to identify and rectify errors across abstract logic, component selection, and prompt encoding. Extensive experiments and human evaluations demonstrate that our method significantly outperforms SOTA baselines in metaphor consistency, analogy appropriateness, and visual creativity, paving the way for automated high-impact creative applications in advertising and media. Source code will be made publicly available.

</details>


### [317] [MTC-VAE: Multi-Level Temporal Compression with Content Awareness](https://arxiv.org/abs/2602.01340)
*Yubo Dong,Linchao Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种将固定压缩率的VAE转换为支持多级时间压缩的方法，通过微调解决了高压缩率下的性能下降问题，并验证了其在不同视频片段上的有效性，同时展示了其与DiT等生成模型的兼容性。


<details>
  <summary>Details</summary>
Motivation: 现有连续VAE在追求更高压缩率时效率下降，特别是在不增加通道维度的情况下添加更多采样层。需要一种方法来提高VAE在更高压缩率下的效率，并探索其在生成模型中的应用。

Method: 提出了一种将固定压缩率VAE转换为支持多级时间压缩的微调技术，并通过实验评估了不同压缩级别对不同特征视频片段性能的影响，并将其集成到DiT等扩散模型中进行联合训练。

Result: 所提出的微调技术成功地使VAE支持多级时间压缩，并在高压缩率下减轻了性能下降。实验证明了该方法在不同视频片段上的有效性，并成功地将其与DiT模型集成，展示了其与扩散生成模型的兼容性。

Conclusion: 本文提供了一种简单有效的微调方法，可以增强VAE在视频压缩方面的多级时间压缩能力，解决了高压缩率下的性能瓶颈，并为将其应用于更广泛的生成模型奠定了基础。

Abstract: Latent Video Diffusion Models (LVDMs) rely on Variational Autoencoders (VAEs) to compress videos into compact latent representations. For continuous Variational Autoencoders (VAEs), achieving higher compression rates is desirable; yet, the efficiency notably declines when extra sampling layers are added without expanding the dimensions of hidden channels. In this paper, we present a technique to convert fixed compression rate VAEs into models that support multi-level temporal compression, providing a straightforward and minimal fine-tuning approach to counteract performance decline at elevated compression rates.Moreover, we examine how varying compression levels impact model performance over video segments with diverse characteristics, offering empirical evidence on the effectiveness of our proposed approach. We also investigate the integration of our multi-level temporal compression VAE with diffusion-based generative models, DiT, highlighting successful concurrent training and compatibility within these frameworks. This investigation illustrates the potential uses of multi-level temporal compression.

</details>


### [318] [Adaptive Visual Autoregressive Acceleration via Dual-Linkage Entropy Analysis](https://arxiv.org/abs/2602.01345)
*Yu Zhang,Jingyi Liu,Feng Liu,Duoqian Miao,Qi Zhang,Kexue Fu,Changwei Wang,Longbing Cao*

Main category: cs.CV

TL;DR: 本文提出了一种名为NOVA的免训练（training-free）的加速框架，通过分析熵变来减少视觉自回归（VAR）模型中的token数量，以降低计算成本，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的VAR模型在处理大量token时计算成本高昂。现有的token减少方法存在阶段划分不灵活、加速策略非自适应以及加速范围有限等问题，未能充分挖掘加速潜力。

Method: NOVA利用熵变来反映模型预测不确定性的变化，以此来捕捉模型动态的演变。它通过在线识别尺度熵增长的拐点，自适应地确定推理过程中的加速激活尺度。通过尺度联动和层联动比率调整，NOVA为每个尺度和层动态计算不同的token减少比例，丢弃低熵token，并利用先前尺度的残差缓存来加速推理。

Result: 实验和分析表明，NOVA是一种简单有效的免训练加速框架。

Conclusion: NOVA通过分析熵变，能够有效地自适应地减少VAR模型中的token数量，从而加速推理过程，并能有效维持生成质量。

Abstract: Visual AutoRegressive modeling (VAR) suffers from substantial computational cost due to the massive token count involved. Failing to account for the continuous evolution of modeling dynamics, existing VAR token reduction methods face three key limitations: heuristic stage partition, non-adaptive schedules, and limited acceleration scope, thereby leaving significant acceleration potential untapped. Since entropy variation intrinsically reflects the transition of predictive uncertainty, it offers a principled measure to capture modeling dynamics evolution. Therefore, we propose NOVA, a training-free token reduction acceleration framework for VAR models via entropy analysis. NOVA adaptively determines the acceleration activation scale during inference by online identifying the inflection point of scale entropy growth. Through scale-linkage and layer-linkage ratio adjustment, NOVA dynamically computes distinct token reduction ratios for each scale and layer, pruning low-entropy tokens while reusing the cache derived from the residuals at the prior scale to accelerate inference and maintain generation quality. Extensive experiments and analyses validate NOVA as a simple yet effective training-free acceleration framework.

</details>


### [319] [T2M Mamba: Motion Periodicity-Saliency Coupling Approach for Stable Text-Driven Motion Generation](https://arxiv.org/abs/2602.01352)
*Xingzu Zhan,Chen Xie,Honghang Chen,Yixun Lin,Xiaochun Mai*

Main category: cs.CV

TL;DR: 本文提出了T2M Mamba模型，通过周期性-关键帧感知Mamba和周期性差分跨模态对齐模块，解决了现有文本到运动生成模型在长序列生成漂移和对语义等价释义鲁棒性不足的问题，并在HumanML3D和KIT-ML数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有文本到运动生成模型在处理长序列时存在生成漂移问题，并且对语义等价的文本描述不够鲁棒，容易导致输出运动不稳定或错误。

Method: 1. 提出了周期性-关键帧感知Mamba（Periodicity-Saliency Aware Mamba），利用密度峰值聚类和FFT加速自相关算法来捕捉关键帧显著性和运动周期性的耦合动态。 2. 构建了周期性差分跨模态对齐模块（PDCAM），以增强文本和运动嵌入的鲁棒对齐。

Result: 在HumanML3D和KIT-ML数据集上进行了大量实验，T2M Mamba在FID上达到了0.068，并在所有其他指标上均取得了持续的性能提升。

Conclusion: T2M Mamba通过有效结合运动周期性和关键帧显著性，并增强文本-运动的跨模态对齐，成功克服了现有方法的局限性，实现了更稳定、更精确的文本到运动生成。

Abstract: Text-to-motion generation, which converts motion language descriptions into coherent 3D human motion sequences, has attracted increasing attention in fields, such as avatar animation and humanoid robotic interaction. Though existing models have achieved significant fidelity, they still suffer from two core limitations: (i) They treat motion periodicity and keyframe saliency as independent factors, overlooking their coupling and causing generation drift in long sequences. (ii) They are fragile to semantically equivalent paraphrases, where minor synonym substitutions distort textual embeddings, propagating through the decoder and producing unstable or erroneous motions. In this work, we propose T2M Mamba to address these limitations by (i) proposing Periodicity-Saliency Aware Mamba, which utilizes novel algorithms for keyframe weight estimation via enhanced Density Peaks Clustering and motion periodicity estimation via FFT-accelerated autocorrelation to capture coupled dynamics with minimal computational overhead, and (ii) constructing a Periodic Differential Cross-modal Alignment Module (PDCAM) to enhance robust alignment of textual and motion embeddings. Extensive experiments on HumanML3D and KIT-ML datasets have been conducted, confirming the effectiveness of our approach, achieving an FID of 0.068 and consistent gains on all other metrics.

</details>


### [320] [Exposing and Defending the Achilles' Heel of Video Mixture-of-Experts](https://arxiv.org/abs/2602.01369)
*Songping Wang,Qinglong Liu,Yueming Lyu,Ning Li,Ziwen He,Caifeng Shan*

Main category: cs.CV

TL;DR: 本研究提出了TLGA和J-TLGA攻击方法，用于揭示视频MoE模型中路由器和专家模块的独立和协同脆弱性，并提出了J-TLAT进行联合对抗训练以提升鲁棒性，同时实现了高效推理。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型在视频理解方面表现优异，但其对抗鲁棒性研究不足。现有攻击方法通常将MoE视为整体，忽略了路由器和专家模块等关键组件的独立和协同弱点。

Method: 提出TLGA攻击路由器，揭示其独立弱点；提出J-TLGA，协同扰动路由器和专家；提出J-TLAT，进行联合对抗训练以抵御协同弱点。

Result: J-TLGA显著放大了对抗效果，暴露了MoE架构的协同弱点。J-TLAT框架即插即用，推理成本降低超过60%，并在不同数据集和架构上持续提升对抗鲁棒性。

Conclusion: TLGA和J-TLGA成功揭示了视频MoE模型的组件级脆弱性（独立和协同），J-TLAT通过联合训练有效增强了MoE模型的鲁棒性，解决了其关键的协同弱点，并实现了高效推理。

Abstract: Mixture-of-Experts (MoE) has demonstrated strong performance in video understanding tasks, yet its adversarial robustness remains underexplored. Existing attack methods often treat MoE as a unified architecture, overlooking the independent and collaborative weaknesses of key components such as routers and expert modules. To fill this gap, we propose Temporal Lipschitz-Guided Attacks (TLGA) to thoroughly investigate component-level vulnerabilities in video MoE models. We first design attacks on the router, revealing its independent weaknesses. Building on this, we introduce Joint Temporal Lipschitz-Guided Attacks (J-TLGA), which collaboratively perturb both routers and experts. This joint attack significantly amplifies adversarial effects and exposes the Achilles' Heel (collaborative weaknesses) of the MoE architecture. Based on these insights, we further propose Joint Temporal Lipschitz Adversarial Training (J-TLAT). J-TLAT performs joint training to further defend against collaborative weaknesses, enhancing component-wise robustness. Our framework is plug-and-play and reduces inference cost by more than 60% compared with dense models. It consistently enhances adversarial robustness across diverse datasets and architectures, effectively mitigating both the independent and collaborative weaknesses of MoE.

</details>


### [321] [PolyGen: Fully Synthetic Vision-Language Training via Multi-Generator Ensembles](https://arxiv.org/abs/2602.01370)
*Leonardo Brusini,Cristian Sbrolli,Eugenio Lomurno,Toshihiko Yamasaki,Matteo Matteucci*

Main category: cs.CV

TL;DR: PolyGen框架通过训练多个不同架构的生成器，并引入程序化负样本课程，提高了合成数据的多样性和结构化理解能力，显著优于单生成器方法。


<details>
  <summary>Details</summary>
Motivation: 现有的合成数据方法依赖单一生成器，存在生成器特有的频谱偏差和特征多样性不足的问题，限制了视觉-语言预训练的效果。

Method: PolyGen采用“Polylithic”方法，训练多个架构不同的生成器，以消除模型特有的伪影；引入程序化负样本课程，加强细粒度的语法理解；通过将数据预算从唯一标题重新分配到多源变体，来提高数据效率。

Result: PolyGen在多任务基准测试上比领先的单源基线SynthCLIP高出19.0%，在SugarCrepe++组合性基准测试上高出9.1%。

Conclusion: 结构多样性比增加单源样本量更具数据效率，PolyGen通过结构化方法能更有效地构建用于视觉-语言预训练的合成数据。

Abstract: Synthetic data offers a scalable solution for vision-language pre-training, yet current state-of-the-art methods typically rely on scaling up a single generative backbone, which introduces generator-specific spectral biases and limits feature diversity. In this work, we introduce PolyGen, a framework that redefines synthetic data construction by prioritizing manifold coverage and compositional rigor over simple dataset size. PolyGen employs a Polylithic approach to train on the intersection of architecturally distinct generators, effectively marginalizing out model-specific artifacts. Additionally, we introduce a Programmatic Hard Negative curriculum that enforces fine-grained syntactic understanding. By structurally reallocating the same data budget from unique captions to multi-source variations, PolyGen achieves a more robust feature space, outperforming the leading single-source baseline (SynthCLIP) by +19.0% on aggregate multi-task benchmarks and on the SugarCrepe++ compositionality benchmark (+9.1%). These results demonstrate that structural diversity is a more data-efficient scaling law than simply increasing the volume of single-source samples.

</details>


### [322] [PromptRL: Prompt Matters in RL for Flow-Based Image Generation](https://arxiv.org/abs/2602.01382)
*Fu-Yun Wang,Han Zhang,Michael Gharbi,Hongsheng Li,Taesung Park*

Main category: cs.CV

TL;DR: 本文提出了一种名为PromptRL的框架，用于解决流匹配模型（FM）在文本到图像生成中存在的样本效率低下和提示过拟合问题。PromptRL将语言模型（LM）作为可训练的提示精炼代理集成到FM的强化学习（RL）优化循环中，通过重塑优化动态来提升性能。实验结果表明，PromptRL在多个基准测试中取得了最先进的性能，并且在图像编辑任务上显著提高了奖励分数，同时所需的样本量更少。


<details>
  <summary>Details</summary>
Motivation: 当前的强化学习（RL）管道在处理流匹配模型（FM）进行文本到图像（T2I）生成时，存在样本效率低下（生成多样性不足）和提示过拟合（模型记忆特定提示，对语义相同但风格不同的提示表现急剧下降）的问题。研究旨在解决这些不足，提升FM在RL后训练中的性能和鲁棒性。

Method: 提出PromptRL框架，将语言模型（LM）作为可训练的提示精炼代理，直接嵌入到流匹配模型的强化学习（RL）优化循环中。这种集成方式使LM能够快速开发复杂的提示重写能力，并形成一种协同训练机制，改变了优化动态。

Result: PromptRL在多个基准测试中取得了最先进的性能，GenEval得分为0.97，OCR准确率为0.98，PickScore为24.05。在图像编辑任务上，PromptRL将FLUX.1-Kontext的EditReward从1.19提升到1.43，仅用了0.06百万次rollout，优于Gemini 2.5 Flash Image（1.37），并与ReasonNet（1.44）相当，而ReasonNet需要精细的数据标注和复杂的多阶段训练。与仅使用流模型的RL相比，PromptRL所需的rollout数量减少了一倍以上。

Conclusion: PromptRL框架通过将LM集成到FM的RL优化循环中，有效解决了样本效率低下和提示过拟合问题。该方法能够提升模型性能上限，且样本效率更高，证明了其在文本到图像生成和图像编辑任务上的有效性。

Abstract: Flow matching models (FMs) have revolutionized text-to-image (T2I) generation, with reinforcement learning (RL) serving as a critical post-training strategy for alignment with reward objectives. In this research, we show that current RL pipelines for FMs suffer from two underappreciated yet important limitations: sample inefficiency due to insufficient generation diversity, and pronounced prompt overfitting, where models memorize specific training formulations and exhibit dramatic performance collapse when evaluated on semantically equivalent but stylistically varied prompts. We present PromptRL (Prompt Matters in RL for Flow-Based Image Generation), a framework that incorporates language models (LMs) as trainable prompt refinement agents directly within the flow-based RL optimization loop. This design yields two complementary benefits: rapid development of sophisticated prompt rewriting capabilities and, critically, a synergistic training regime that reshapes the optimization dynamics. PromptRL achieves state-of-the-art performance across multiple benchmarks, obtaining scores of 0.97 on GenEval, 0.98 on OCR accuracy, and 24.05 on PickScore.
  Furthermore, we validate the effectiveness of our RL approach on large-scale image editing models, improving the EditReward of FLUX.1-Kontext from 1.19 to 1.43 with only 0.06 million rollouts, surpassing Gemini 2.5 Flash Image (also known as Nano Banana), which scores 1.37, and achieving comparable performance with ReasonNet (1.44), which relied on fine-grained data annotations along with a complex multi-stage training. Our extensive experiments empirically demonstrate that PromptRL consistently achieves higher performance ceilings while requiring over 2$\times$ fewer rollouts compared to naive flow-only RL. Our code is available at https://github.com/G-U-N/UniRL.

</details>


### [323] [Stronger Semantic Encoders Can Harm Relighting Performance: Probing Visual Priors via Augmented Latent Intrinsics](https://arxiv.org/abs/2602.01391)
*Xiaoyan Xing,Xiao Zhang,Sezer Karaoglu,Theo Gevers,Anand Bhattad*

Main category: cs.CV

TL;DR: 本文提出了一种名为ALI（Augmented Latent Intrinsics）的方法，通过融合像素对齐的视觉编码器特征和自监督精炼策略，来改善图像重光照的效果，尤其是在处理金属和玻璃等复杂材质时。研究发现，传统的语义编码器反而会降低重光照质量，揭示了语义抽象与光度保真度之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有图像重光照方法在处理金属和玻璃等具有挑战性的材质时表现不佳，作者假设更强的预训练视觉先验可以解决这个问题，但实验结果表明事实相反，这促使了对语义抽象与光度保真度之间权衡的研究。

Method: ALI方法通过将像素对齐的视觉编码器特征融合到一个潜在内在表示框架中，并结合自监督精炼策略来解决数据稀疏性问题。该方法仅使用无标签的真实世界图像对进行训练。

Result: ALI在重光照方面取得了显著的改进，尤其是在复杂、高光材质上。与依赖语义编码器的方法相比，ALI能够更好地平衡语义上下文和密集的影射结构，从而提升重光照质量。

Conclusion: ALI通过结合像素对齐的视觉先验和潜在内在表示，成功地解决了现有图像重光照方法在处理复杂材质时的不足。研究强调了语义抽象和光度保真度之间的权衡，并提出了一种有效的平衡方法。

Abstract: Image-to-image relighting requires representations that disentangle scene properties from illumination. Recent methods rely on latent intrinsic representations but remain under-constrained and often fail on challenging materials such as metal and glass. A natural hypothesis is that stronger pretrained visual priors should resolve these failures. We find the opposite: features from top-performing semantic encoders often degrade relighting quality, revealing a fundamental trade-off between semantic abstraction and photometric fidelity. We study this trade-off and introduce Augmented Latent Intrinsics (ALI), which balances semantic context and dense photometric structure by fusing features from a pixel-aligned visual encoder into a latent-intrinsic framework, together with a self-supervised refinement strategy to mitigate the scarcity of paired real-world data. Trained only on unlabeled real-world image pairs and paired with a dense, pixel-aligned visual prior, ALI achieves strong improvements in relighting, with the largest gains on complex, specular materials. Project page: https:\\augmented-latent-intrinsics.github.io

</details>


### [324] [Where to Attend: A Principled Vision-Centric Position Encoding with Parabolas](https://arxiv.org/abs/2602.01418)
*Christoffer Koo Øhrstrøm,Rafael I. Cabral Muchacho,Yifei Dong,Filippos Moumtzidellis,Ronja Güldenring,Florian T. Pokorny,Lazaros Nalpantidis*

Main category: cs.CV

TL;DR: 本文提出了一种基于抛物线的视觉位置编码方法PaPE，旨在更好地处理图像、点云、视频等视觉模态的注意力机制。PaPE考虑了视觉模态的平移不变性、旋转不变性、距离衰减、方向性和上下文感知等特性，并在多项任务和数据集上取得了优于现有方法的性能，尤其在图像外推任务上表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有方法将语言模型的位置编码扩展到视觉领域时，未能充分考虑视觉模态自身的特性。研究者希望设计一种更能体现视觉模态特点的位置编码方法。

Method: 提出Parabolic Position Encoding (PaPE)及其旋转不变版本PaPE-RI。该方法从平移不变性、旋转不变性、距离衰减、方向性和上下文感知等原则出发设计，以编码视觉模态（图像、点云、视频、事件相机流）中的视觉标记位置。

Result: 在4种模态的8个数据集上进行评估，PaPE或PaPE-RI在7/8的数据集上取得了最佳性能。在ImageNet-1K的外推实验中，PaPE的性能比次优方法绝对提升高达10.5%。

Conclusion: PaPE是一种有效的位置编码方法，能够显著提升注意力机制在各种视觉模态任务上的性能，并且在处理未见过的数据时表现出优异的外推能力。

Abstract: We propose Parabolic Position Encoding (PaPE), a parabola-based position encoding for vision modalities in attention-based architectures. Given a set of vision tokens-such as images, point clouds, videos, or event camera streams-our objective is to encode their positions while accounting for the characteristics of vision modalities. Prior works have largely extended position encodings from 1D-sequences in language to nD-structures in vision, but only with partial account of vision characteristics. We address this gap by designing PaPE from principles distilled from prior work: translation invariance, rotation invariance (PaPE-RI), distance decay, directionality, and context awareness. We evaluate PaPE on 8 datasets that span 4 modalities. We find that either PaPE or PaPE-RI achieves the top performance on 7 out of 8 datasets. Extrapolation experiments on ImageNet-1K show that PaPE extrapolates remarkably well, improving in absolute terms by up to 10.5% over the next-best position encoding. Code is available at https://github.com/DTU-PAS/parabolic-position-encoding.

</details>


### [325] [BioTamperNet: Affinity-Guided State-Space Model Detecting Tampered Biomedical Images](https://arxiv.org/abs/2602.01435)
*Soumyaroop Nandi,Prem Natarajan*

Main category: cs.CV

TL;DR: 提出了一种名为BioTamperNet的新框架，利用受状态空间模型（SSM）近似启发的亲和力引导注意力机制，用于检测生物医学图像中被篡改的复制区域。该框架在生物医学数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图像取证模型在自然图像上训练，在生物医学图像上表现不佳，而生物医学图像中的细微篡改会影响实验的有效性。因此，需要一个专门针对生物医学图像的篡改检测模型。

Method: BioTamperNet框架包含两个核心模块：亲和力引导自注意力模块用于捕捉图像内部的相似性，亲和力引导交叉注意力模块用于建模图像之间的对应关系。该设计集成了受SSM启发的轻量级线性注意力机制，实现了高效的精细化定位。模型进行端到端训练，同时识别篡改区域及其源区域。

Result: 在基准生物取证数据集上的广泛实验表明，BioTamperNet在准确检测复制区域方面，相较于竞争性基线模型取得了显著的改进。

Conclusion: BioTamperNet是一种新颖有效的框架，能够准确检测生物医学图像中的篡改复制区域，解决了现有方法在处理此类数据时的不足。

Abstract: We propose BioTamperNet, a novel framework for detecting duplicated regions in tampered biomedical images, leveraging affinity-guided attention inspired by State Space Model (SSM) approximations. Existing forensic models, primarily trained on natural images, often underperform on biomedical data where subtle manipulations can compromise experimental validity. To address this, BioTamperNet introduces an affinity-guided self-attention module to capture intra-image similarities and an affinity-guided cross-attention module to model cross-image correspondences. Our design integrates lightweight SSM-inspired linear attention mechanisms to enable efficient, fine-grained localization. Trained end-to-end, BioTamperNet simultaneously identifies tampered regions and their source counterparts. Extensive experiments on the benchmark bio-forensic datasets demonstrate significant improvements over competitive baselines in accurately detecting duplicated regions. Code - https://github.com/SoumyaroopNandi/BioTamperNet

</details>


### [326] [Cross-Paradigm Evaluation of Gaze-Based Semantic Object Identification for Intelligent Vehicles](https://arxiv.org/abs/2602.01452)
*Penghao Deng,Jidong J. Yang,Jiachen Bian*

Main category: cs.CV

TL;DR: 研究了不同计算机视觉方法在识别驾驶员视线落点与道路场景语义关联性方面的表现，发现直接目标检测（YOLOv13）和大型视觉语言模型（Qwen2.5-VL-32b）效果最佳，尤其后者在识别小型关键物体方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了开发下一代高级驾驶员辅助系统（ADAS）和提高道路安全，理解驾驶员的视线关注点至关重要。

Method: 本文将驾驶员视线落点与道路场景语义的关联性识别任务，通过三种视觉方法进行：直接目标检测（YOLOv13），分割辅助分类（SAM2 + EfficientNetV2 vs YOLOv13），以及基于查询的视觉语言模型（VLMs，Qwen2.5-VL-7b vs Qwen2.5-VL-32b）。

Result: 直接目标检测（YOLOv13）和大型VLM（Qwen2.5-VL-32b）表现显著优于其他方法，Macro F1-Score超过0.84。Qwen2.5-VL-32b在识别小型、安全关键物体（如交通信号灯）方面表现出卓越的鲁棒性和性能，尤其在夜间恶劣条件下。分割辅助方法因“部分与整体”的语义鸿沟在召回率上存在较大失败。

Conclusion: 研究揭示了实时检测效率与大型VLM提供的丰富上下文理解和鲁棒性之间的根本权衡。这些发现为未来设计面向人类的智能驾驶员监控系统提供了关键见解和实用指导。

Abstract: Understanding where drivers direct their visual attention during driving, as characterized by gaze behavior, is critical for developing next-generation advanced driver-assistance systems and improving road safety. This paper tackles this challenge as a semantic identification task from the road scenes captured by a vehicle's front-view camera. Specifically, the collocation of gaze points with object semantics is investigated using three distinct vision-based approaches: direct object detection (YOLOv13), segmentation-assisted classification (SAM2 paired with EfficientNetV2 versus YOLOv13), and query-based Vision-Language Models, VLMs (Qwen2.5-VL-7b versus Qwen2.5-VL-32b). The results demonstrate that the direct object detection (YOLOv13) and Qwen2.5-VL-32b significantly outperform other approaches, achieving Macro F1-Scores over 0.84. The large VLM (Qwen2.5-VL-32b), in particular, exhibited superior robustness and performance for identifying small, safety-critical objects such as traffic lights, especially in adverse nighttime conditions. Conversely, the segmentation-assisted paradigm suffers from a "part-versus-whole" semantic gap that led to large failure in recall. The results reveal a fundamental trade-off between the real-time efficiency of traditional detectors and the richer contextual understanding and robustness offered by large VLMs. These findings provide critical insights and practical guidance for the design of future human-aware intelligent driver monitoring systems.

</details>


### [327] [Understanding vision transformer robustness through the lens of out-of-distribution detection](https://arxiv.org/abs/2602.01459)
*Joey Kuang,Alexander Wong*

Main category: cs.CV

TL;DR: 研究表明，在大型数据集上预训练的 Vision Transformer 模型在低比特量化下的 out-of-distribution (OOD) 检测性能会下降，而数据增强可能更有益于提升量化鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了让 Vision Transformer 能够更易于访问和实时使用，需要通过量化来降低内存和推理成本，但量化会带来性能损失。现有研究主要关注 in-distribution (ID) 任务行为，而本文旨在探索 out-of-distribution (OOD) 情况下的注意力机制对量化属性的洞察。

Method: 在常见的 OOD 数据集上，研究了量化后的流行小型 Vision Transformer 模型（DeiT, DeiT3, ViT）的行为。进行了 ID 分析以评估量化误差，并进行了 OOD 检测以评估量化对区分不同分布数据的能力的影响，比较了不同预训练数据集（ImageNet-1k vs ImageNet-22k）和量化精度（FP32 vs 4-bit）下的 AUPR-out 指标。

Result: ID 分析显示，4位量化模型（特别是 ImageNet-22k 预训练模型）存在初始不稳定问题。ViT 在 ID 校准方面表现出一定的量化鲁棒性。OOD 检测发现，在 ImageNet-22k 上预训练的 ViT 和 DeiT3 模型，其 4 位量化版本相比全精度版本在 AUPR-out 上分别下降了 15.0% 和 19.2%，而仅在 ImageNet-1k 上预训练的模型下降幅度分别为 9.5% 和 12.0%。

Conclusion: 在大型数据集上预训练可能会削弱 Vision Transformer 模型在 OOD 检测任务上的低比特量化鲁棒性。数据增强可能比大型数据集预训练更能有效地提升量化鲁棒性。

Abstract: Vision transformers have shown remarkable performance in vision tasks, but enabling them for accessible and real-time use is still challenging. Quantization reduces memory and inference costs at the risk of performance loss. Strides have been made to mitigate low precision issues mainly by understanding in-distribution (ID) task behaviour, but the attention mechanism may provide insight on quantization attributes by exploring out-of-distribution (OOD) situations. We investigate the behaviour of quantized small-variant popular vision transformers (DeiT, DeiT3, and ViT) on common OOD datasets. ID analyses show the initial instabilities of 4-bit models, particularly of those trained on the larger ImageNet-22k, as the strongest FP32 model, DeiT3, sharply drop 17% from quantization error to be one of the weakest 4-bit models. While ViT shows reasonable quantization robustness for ID calibration, OOD detection reveals more: ViT and DeiT3 pretrained on ImageNet-22k respectively experienced a 15.0% and 19.2% average quantization delta in AUPR-out between full precision to 4-bit while their ImageNet-1k-only counterparts experienced a 9.5% and 12.0% delta. Overall, our results suggest pretraining on large scale datasets may hinder low-bit quantization robustness in OOD detection and that data augmentation may be a more beneficial option.

</details>


### [328] [Preserving Localized Patch Semantics in VLMs](https://arxiv.org/abs/2602.01530)
*Parsa Esmaeilkhani,Longin Jan Latecki*

Main category: cs.CV

TL;DR: 本文提出了一种名为Logit Lens Loss (LLL) 的补充损失函数，用于改进自回归视觉语言模型 (VLMs) 中Logit Lens的可视化效果，通过约束图像 token 的语义对齐来保留局部视觉信息，从而提高解释性和在视觉任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Logit Lens方法在视觉语言模型中可视化时，图像 token 的视觉信息容易扩散到语言 token，导致局部视觉信息丢失，使得Logit Lens的可视化在解释性方面变得不可用。

Method: 提出了一种名为Logit Lens Loss (LLL) 的补充损失函数，添加到下一 token 预测 (NTP) 损失中，旨在使视觉 token 的嵌入与其描述的图像区域的文本概念更加语义对齐，从而防止图像 token 失去来自相应图像块的视觉表示。LLL 不需要进行架构修改或大规模训练。

Result: LLL 能够生成有意义的图像对象置信度图，使得Logit Lens在解释性方面变得实用。此外，LLL 在不附加特殊头部的情况下，也提高了分割等视觉任务的性能。

Conclusion: Logit Lens Loss (LLL) 是一种有效的方法，可以解决视觉语言模型中 Logit Lens 可视化的局部视觉信息丢失问题，提高了模型的可解释性，并能在不增加额外开销的情况下提升视觉任务的性能。

Abstract: Logit Lens has been proposed for visualizing tokens that contribute most to LLM answers. Recently, Logit Lens was also shown to be applicable in autoregressive Vision-Language Models (VLMs), where it illustrates the conceptual content of image tokens in the form of heatmaps, e.g., which image tokens are likely to depict the concept of cat in a given image. However, the visual content of image tokens often gets diffused to language tokens, and consequently, the locality of visual information gets mostly destroyed, which renders Logit Lens visualization unusable for explainability. To address this issue, we introduce a complementary loss to next-token prediction (NTP) to prevent the visual tokens from losing the visual representation inherited from corresponding image patches. The proposed Logit Lens Loss (LLL) is designed to make visual token embeddings more semantically aligned with the textual concepts that describe their image regions (e.g., patches containing a cat with the word "cat"), without requiring any architectural modification or large-scale training. This way, LLL constrains the mixing of image and text tokens in the self-attention layers in order to prevent image tokens from losing their localized visual information. As our experiments show, LLL not only makes Logit Lens practically relevant by producing meaningful object confidence maps in images, but also improves performance on vision-centric tasks like segmentation without attaching any special heads.

</details>


### [329] [Rotation-free Online Handwritten Character Recognition Using Linear Recurrent Units](https://arxiv.org/abs/2602.01533)
*Zhe Ling,Sicheng Yu,Danyu Yang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的在线手写字符识别方法，结合了滑动窗口路径签名（SW-PS）提取局部结构特征和线性循环单元（LRU）进行分类，以解决旋转变形带来的准确率下降问题。实验结果表明，该方法在处理随机旋转的数字、英文字母和汉字部首时，准确率分别达到99.62%、96.67%和94.33%，且优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 在线手写字符识别在实际应用中常面临旋转变形问题，这会严重影响识别准确率，而提取旋转不变特征仍然是一个挑战。

Method: 采用滑动窗口路径签名（SW-PS）提取局部结构特征，并引入轻量级线性循环单元（LRU）作为分类器。LRU结合了RNN的快速增量处理能力和SSM的高效并行训练能力，同时能可靠地模拟动态笔画特征。

Result: 在CASIA-OLHWDB1.1数据集的数字、英文字母和汉字部首子集上，经过集成学习后，该方法的识别准确率分别为99.62%、96.67%和94.33%。实验证明，SW-PS+LRU框架在收敛速度和测试准确率方面均优于现有模型。

Conclusion: 提出的SW-PS+LRU框架能够有效地处理在线手写字符的旋转变形问题，并在识别准确率和收敛速度上取得了优于竞争模型的性能。

Abstract: Online handwritten character recognition leverages stroke order and dynamic features, which generally provide higher accuracy and robustness compared with offline recognition. However, in practical applications, rotational deformations can disrupt the spatial layout of strokes, substantially reducing recognition accuracy. Extracting rotation-invariant features therefore remains a challenging open problem. In this work, we employ the Sliding Window Path Signature (SW-PS) to capture local structural features of characters, and introduce the lightweight Linear Recurrent Units (LRU) as the classifier. The LRU combine the fast incremental processing capability of recurrent neural networks (RNN) with the efficient parallel training of state space models (SSM), while reliably modelling dynamic stroke characteristics. We conducted recognition experiments with random rotation angle up to $\pm 180^{\circ}$ on three subsets of the CASIA-OLHWDB1.1 dataset: digits, English upper letters, and Chinese radicals. The accuracies achieved after ensemble learning were $99.62\%$, $96.67\%$, and $94.33\%$, respectively. Experimental results demonstrate that the proposed SW-PS+LRU framework consistently surpasses competing models in both convergence speed and test accuracy.

</details>


### [330] [Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars](https://arxiv.org/abs/2602.01538)
*Youliang Zhang,Zhengguang Zhou,Zhentao Yu,Ziyao Huang,Teng Hu,Sen Liang,Guozhen Zhang,Ziqiao Peng,Shunkai Li,Yi Chen,Zixiang Zhou,Yuan Zhou,Qinglin Lu,Xiu Li*

Main category: cs.CV

TL;DR: 提出了一种名为InteractAvatar的新型双流框架，用于生成与物体交互的说话化身视频，该框架通过解耦感知、规划和视频合成来解决环境感知和控制-质量困境。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以生成进行文本对齐的、与物体交互的说话化身视频，因为这需要环境感知能力，并且存在控制-质量的权衡问题。

Method: InteractAvatar采用双流框架，包括感知与交互模块（PIM）和音频-交互感知生成模块（AIM）。PIM利用检测来增强环境感知并生成文本对齐的交互动作。AIM合成生动的说话化身视频，并执行物体交互。通过特殊的运动到视频对齐器，PIM和AIM并行协同生成动作和视频，缓解了控制-质量困境。

Result: InteractAvatar能够生成高质量的、与物体进行文本对齐的交互式说话化身视频。实验证明了该方法在GHOI（Grounded Human-Object Interaction）视频生成方面的有效性。

Conclusion: InteractAvatar通过解耦感知和规划与视频合成，成功解决了GHOI生成中的环境感知和控制-质量困境，能够生成逼真的、与物体进行交互的说话化身视频。此外，研究者还建立了GroundedInter基准数据集用于评估GHOI视频生成。

Abstract: Generating talking avatars is a fundamental task in video generation. Although existing methods can generate full-body talking avatars with simple human motion, extending this task to grounded human-object interaction (GHOI) remains an open challenge, requiring the avatar to perform text-aligned interactions with surrounding objects. This challenge stems from the need for environmental perception and the control-quality dilemma in GHOI generation. To address this, we propose a novel dual-stream framework, InteractAvatar, which decouples perception and planning from video synthesis for grounded human-object interaction. Leveraging detection to enhance environmental perception, we introduce a Perception and Interaction Module (PIM) to generate text-aligned interaction motions. Additionally, an Audio-Interaction Aware Generation Module (AIM) is proposed to synthesize vivid talking avatars performing object interactions. With a specially designed motion-to-video aligner, PIM and AIM share a similar network structure and enable parallel co-generation of motions and plausible videos, effectively mitigating the control-quality dilemma. Finally, we establish a benchmark, GroundedInter, for evaluating GHOI video generation. Extensive experiments and comparisons demonstrate the effectiveness of our method in generating grounded human-object interactions for talking avatars. Project page: https://interactavatar.github.io

</details>


### [331] [FSCA-Net: Feature-Separated Cross-Attention Network for Robust Multi-Dataset Training](https://arxiv.org/abs/2602.01540)
*Yuehai Chen*

Main category: cs.CV

TL;DR: 提出FSCA-Net，一种通过分离领域不变和领域特定特征并利用交叉注意力融合来解决人群计数跨领域泛化问题的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的人群计数模型在跨不同环境应用时，由于领域差异性会导致性能下降，直接联合训练会产生负迁移。

Method: 提出FSCA-Net框架，显式地将特征表示解耦为领域不变和领域特定成分。设计了交叉注意力融合模块来建模这些成分间的交互，并引入互信息优化目标来促进互补的共享-私有表示。

Result: FSCA-Net能有效减轻负迁移，在多个数据集上实现了最先进的跨数据集泛化能力。

Conclusion: FSCA-Net提供了一个鲁棒且可扩展的解决方案，用于现实世界中的人群分析，有效地解决了人群计数中的跨领域泛化难题。

Abstract: Crowd counting plays a vital role in public safety, traffic regulation, and smart city management. However, despite the impressive progress achieved by CNN- and Transformer-based models, their performance often deteriorates when applied across diverse environments due to severe domain discrepancies. Direct joint training on multiple datasets, which intuitively should enhance generalization, instead results in negative transfer, as shared and domain-specific representations become entangled. To address this challenge, we propose the Feature Separation and Cross-Attention Network FSCA-Net, a unified framework that explicitly disentangles feature representations into domain-invariant and domain-specific components. A novel cross-attention fusion module adaptively models interactions between these components, ensuring effective knowledge transfer while preserving dataset-specific discriminability. Furthermore, a mutual information optimization objective is introduced to maximize consistency among domain-invariant features and minimize redundancy among domain-specific ones, promoting complementary shared-private representations. Extensive experiments on multiple crowd counting benchmarks demonstrate that FSCA-Net effectively mitigates negative transfer and achieves state-of-the-art cross-dataset generalization, providing a robust and scalable solution for real-world crowd analysis.

</details>


### [332] [Toward Cognitive Supersensing in Multimodal Large Language Model](https://arxiv.org/abs/2602.01541)
*Boyi Li,Yifan Shen,Yuanzhe Liu,Yifan Xu,Jiateng Liu,Xinzhuo Li,Zhengyuan Li,Jingyuan Zhu,Yunhan Zhong,Fangzhou Lan,Jianguo Cao,James M. Rehg,Heng Ji,Ismini Lourentzou,Xu Cao*

Main category: cs.CV

TL;DR: 本研究提出了一种名为“认知超感知”的新型训练范式，通过引入潜变量视觉想象力预测（LVIP）头，使多模态大语言模型（MLLMs）能够像人类一样进行视觉想象，并结合强化学习来优化文本推理路径，从而提升其解决复杂认知问题的能力。研究还发布了一个名为 CogSense-Bench 的视觉问答基准来评估这些能力。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLMs 在开放词汇感知任务上表现出色，但在解决需要视觉记忆和抽象细节的复杂认知问题方面能力有限。现有方法主要在文本空间扩展链式思考（CoT），忽略了类似人类视觉空间草图板和视觉想象力的视觉推理机制。

Method: 提出“认知超感知”训练范式，集成一个潜变量视觉想象力预测（LVIP）头，该头能够学习视觉认知潜变量嵌入序列并将其与答案对齐，形成基于视觉的内部推理链。引入强化学习阶段，基于视觉潜变量来优化文本推理路径。

Result: 在 CogSense-Bench 基准测试中，经过“认知超感知”训练的 MLLMs 显著优于现有最先进的方法。模型在跨领域数学和科学 VQA 基准测试上也表现出更强的泛化能力。

Conclusion: 内部视觉想象力对于弥合感知识别和认知理解之间的差距至关重要，并且“认知超感知”是一种有效提升 MLLMs 认知能力的方法。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable success in open-vocabulary perceptual tasks, yet their ability to solve complex cognitive problems remains limited, especially when visual details are abstract and require visual memory. Current approaches primarily scale Chain-of-Thought (CoT) reasoning in the text space, even when language alone is insufficient for clear and structured reasoning, and largely neglect visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery. To mitigate this deficiency, we introduce Cognitive Supersensing, a novel training paradigm that endows MLLMs with human-like visual imagery capabilities by integrating a Latent Visual Imagery Prediction (LVIP) head that jointly learns sequences of visual cognitive latent embeddings and aligns them with the answer, thereby forming vision-based internal reasoning chains. We further introduce a reinforcement learning stage that optimizes text reasoning paths based on this grounded visual latent. To evaluate the cognitive capabilities of MLLMs, we present CogSense-Bench, a comprehensive visual question answering (VQA) benchmark assessing five cognitive dimensions. Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding. We will open-source the CogSense-Bench and our model weights.

</details>


### [333] [Multimodal UNcommonsense: From Odd to Ordinary and Ordinary to Odd](https://arxiv.org/abs/2602.01561)
*Yejin Son,Saejin Kim,Dongjun Min,Younjae Yu*

Main category: cs.CV

TL;DR: 提出了一种名为MUN（Multimodal UNcommonsense）的新型基准测试，用于评估模型在处理非典型视觉和语境场景下的常识推理能力，并提出了一种不需额外训练的检索式上下文学习（R-ICL）框架，利用多模态集成检索器（MER）来提高小模型在低频、非典型场景下的推理能力，实验证明R-ICL比基线ICL方法平均提升8.3%。


<details>
  <summary>Details</summary>
Motivation: 当前的AI模型在处理常识推理方面面临挑战，尤其是在多模态且偏离典型期望的场景下。需要一个基准来评估和提升模型在这种非典型情境下的鲁棒性和适应性。

Method: 构建了一个名为MUN（Multimodal UNcommonsense）的基准数据集，其中包含与典型预期相悖的视觉场景和自然语言描述。提出了一种检索式上下文学习（R-ICL）框架，利用多模态集成检索器（MER）来选择与查询相关的示例，并将大型模型的推理能力迁移到小型模型，无需额外训练。

Result: R-ICL框架在MUN基准测试上，相比基线ICL方法，平均提升了8.3%的性能，证明了其在低频、非典型场景下的有效性。

Conclusion: MUN基准测试为评估和改进视觉-语言模型在现实世界、文化多样性和非原型化场景中的鲁棒性与适应性提供了新方向。R-ICL框架是一种有效的、无需训练的迁移学习方法，能够提升模型在处理非典型多模态常识推理任务上的能力。

Abstract: Commonsense reasoning in multimodal contexts remains a foundational challenge in artificial intelligence. We introduce Multimodal UNcommonsense(MUN), a benchmark designed to evaluate models' ability to handle scenarios that deviate from typical visual or contextual expectations. MUN pairs visual scenes with surprising or unlikely outcomes described in natural language, prompting models to either rationalize seemingly odd images using everyday logic or uncover unexpected interpretations in ordinary scenes. To support this task, we propose a retrieval-based in-context learning (R-ICL) framework that transfers reasoning capabilities from larger models to smaller ones without additional training. Leveraging a novel Multimodal Ensemble Retriever (MER), our method identifies semantically relevant exemplars even when image and text pairs are deliberately discordant. Experiments show an average improvement of 8.3% over baseline ICL methods, highlighting the effectiveness of R-ICL in low-frequency, atypical settings. MUN opens new directions for evaluating and improving visual-language models' robustness and adaptability in real-world, culturally diverse, and non-prototypical scenarios.

</details>


### [334] [Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning](https://arxiv.org/abs/2602.01649)
*Yinchao Ma,Qiang Zhou,Zhibin Wang,Xianing Chen,Hanqing Yang,Jun Song,Bo Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为 CaCoVID 的视频大语言模型 token 压缩算法，通过强化学习主动学习对预测贡献最大的 token 组合，而非依赖于注意力分数，从而降低了推理时的计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的视频大语言模型在视频理解方面表现出色，但视频 token 的冗余导致推理时计算量大，限制了实际应用。现有压缩算法倾向于保留高注意力分数的 token，但注意力分数与对正确答案的实际贡献之间存在不确定性。

Method: 提出 CaCoVID 算法，采用基于强化学习的框架，优化一个策略网络来选择对正确预测贡献最大的视频 token 组合。同时，引入组合策略优化算法和在线组合空间采样，以减小搜索空间并加速收敛。

Result: 在多个视频理解基准测试上进行了广泛实验，证明了 CaCoVID 的有效性。

Conclusion: CaCoVID 是一种有效的方法，通过优化 token 选择策略来主动识别对视频理解任务最重要的 token，显著减少了计算开销，并提升了模型性能。

Abstract: Video large language models have demonstrated remarkable capabilities in video understanding tasks. However, the redundancy of video tokens introduces significant computational overhead during inference, limiting their practical deployment. Many compression algorithms are proposed to prioritize retaining features with the highest attention scores to minimize perturbations in attention computations. However, the correlation between attention scores and their actual contribution to correct answers remains ambiguous. To address the above limitation, we propose a novel \textbf{C}ontribution-\textbf{a}ware token \textbf{Co}mpression algorithm for \textbf{VID}eo understanding (\textbf{CaCoVID}) that explicitly optimizes the token selection policy based on the contribution of tokens to correct predictions. First, we introduce a reinforcement learning-based framework that optimizes a policy network to select video token combinations with the greatest contribution to correct predictions. This paradigm shifts the focus from passive token preservation to active discovery of optimal compressed token combinations. Secondly, we propose a combinatorial policy optimization algorithm with online combination space sampling, which dramatically reduces the exploration space for video token combinations and accelerates the convergence speed of policy optimization. Extensive experiments on diverse video understanding benchmarks demonstrate the effectiveness of CaCoVID. Codes will be released.

</details>


### [335] [One-Step Diffusion for Perceptual Image Compression](https://arxiv.org/abs/2602.01570)
*Yiwen Jia,Hao Wei,Yanhui Zhou,Chenyang Ge*

Main category: cs.CV

TL;DR: 提出了一种单步扩散模型的图像压缩方法，通过在紧凑的特征表示上使用判别器来提高感知质量，实现了与现有方法相当的压缩性能，但推理速度提高了 46 倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的图像压缩方法存在推理延迟高和计算开销大的问题，主要是因为解码时需要大量的去噪步骤。这阻碍了其实际部署。

Method: 提出了一种仅需单步扩散过程的图像压缩方法。为了提升重建图像的感知质量，引入了一个在紧凑特征表示而非原始像素上操作的判别器，利用特征更能捕捉高级纹理和结构细节的优势。

Result: 实验表明，该方法提供了可比的压缩性能，同时推理速度比最近的基于扩散的方法快 46 倍。

Conclusion: 所提出的单步扩散模型图像压缩方法能够有效提高推理速度，同时保持与现有方法相当的压缩性能和感知质量。

Abstract: Diffusion-based image compression methods have achieved notable progress, delivering high perceptual quality at low bitrates. However, their practical deployment is hindered by significant inference latency and heavy computational overhead, primarily due to the large number of denoising steps required during decoding. To address this problem, we propose a diffusion-based image compression method that requires only a single-step diffusion process, significantly improving inference speed. To enhance the perceptual quality of reconstructed images, we introduce a discriminator that operates on compact feature representations instead of raw pixels, leveraging the fact that features better capture high-level texture and structural details. Experimental results show that our method delivers comparable compression performance while offering a 46$\times$ faster inference speed compared to recent diffusion-based approaches. The source code and models are available at https://github.com/cheesejiang/OSDiff.

</details>


### [336] [FreshMem: Brain-Inspired Frequency-Space Hybrid Memory for Streaming Video Understanding](https://arxiv.org/abs/2602.01683)
*Kangcong Li,Peng Ye,Lin Zhang,Chao Wang,Huafeng Qin,Tao Chen*

Main category: cs.CV

TL;DR: 提出了一种名为FreshMem的频率-空间混合记忆网络，用于解决多模态大语言模型在处理在线流媒体视频时信息丢失和上下文碎片化的问题，该方法通过多尺度频率记忆和空间缩略图记忆模块，在不进行额外训练的情况下显著提升了视频理解的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将多模态大语言模型从离线视频理解迁移到在线流媒体视频理解时，缺乏灵活性和自适应性，导致细节丢失和上下文碎片化，因此需要一种能够实现持续感知且保持信息完整性的方法。

Method: 提出FreshMem，一个频率-空间混合记忆网络，包含两个模块：1. 多尺度频率记忆（MFM），将溢出的帧投影到代表性的频率系数，并结合残差细节来重建全局历史“要点”。2. 空间缩略图记忆（STM），通过自适应压缩策略将连续的视频流离散化为片段簇，并提炼成高密度空间缩略图。

Result: FreshMem显著提升了Qwen2-VL基线的性能，在StreamingBench、OV-Bench和OVO-Bench数据集上分别取得了5.20%、4.52%和2.34%的性能提升。作为一种无需训练的解决方案，FreshMem的性能优于一些经过完全微调的方法。

Conclusion: FreshMem是一种高效的长期流媒体视频理解范式，它通过频率和空间维度的混合记忆机制，有效解决了在线流媒体视频理解中的挑战，并在保持短时保真度的同时实现了长时连贯性，且无需额外训练即可实现优越性能。

Abstract: Transitioning Multimodal Large Language Models (MLLMs) from offline to online streaming video understanding is essential for continuous perception. However, existing methods lack flexible adaptivity, leading to irreversible detail loss and context fragmentation. To resolve this, we propose FreshMem, a Frequency-Space Hybrid Memory network inspired by the brain's logarithmic perception and memory consolidation. FreshMem reconciles short-term fidelity with long-term coherence through two synergistic modules: Multi-scale Frequency Memory (MFM), which projects overflowing frames into representative frequency coefficients, complemented by residual details to reconstruct a global historical "gist"; and Space Thumbnail Memory (STM), which discretizes the continuous stream into episodic clusters by employing an adaptive compression strategy to distill them into high-density space thumbnails. Extensive experiments show that FreshMem significantly boosts the Qwen2-VL baseline, yielding gains of 5.20%, 4.52%, and 2.34% on StreamingBench, OV-Bench, and OVO-Bench, respectively. As a training-free solution, FreshMem outperforms several fully fine-tuned methods, offering a highly efficient paradigm for long-horizon streaming video understanding.

</details>


### [337] [SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models](https://arxiv.org/abs/2602.01574)
*Haobo Wang,Weiqi Luo,Xiaojun Jia,Xiaochun Cao*

Main category: cs.CV

TL;DR: 本文提出了一种名为SGHA-Attack的框架，通过利用多目标参考和分层对齐机制，显著提高了针对大型视觉语言模型（VLMs）的迁移类对抗性攻击的有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于迁移的对抗性攻击方法在利用代理模型时，容易过度拟合代理模型的特定嵌入空间，并且倾向于对齐最终层，导致中间语义信息被忽视，从而降低了在异构VLMs之间的迁移能力。这促使研究者需要开发一种更有效的方法。

Method: SGHA-Attack框架包含以下关键技术：1. 生成视觉基础的参考池，通过在冻结的文本到图像模型上以目标提示为条件进行采样。2. 精心挑选与代理模型中最相关的Top-K个语义锚点，形成加权混合以提供稳定的优化指导。3. 通过全局和空间粒度在多个深度上对齐中间视觉表示，以及在共享的潜在子空间中同步中间视觉和文本特征，将目标语义注入到整个特征层级中，从而在最终投影之前提供早期跨模态监督。

Result: 实验结果表明，SGHA-Attack在开源和商业黑盒VLMs上取得了比现有方法更强的目标迁移能力，并且在预处理和净化防御下仍然保持鲁棒性。

Conclusion: SGHA-Attack是一种有效的对抗性攻击框架，通过多目标参考和分层语义对齐，克服了现有方法的局限性，提高了迁移类攻击的性能和跨模型泛化能力。

Abstract: Large vision-language models (VLMs) are vulnerable to transfer-based adversarial perturbations, enabling attackers to optimize on surrogate models and manipulate black-box VLM outputs. Prior targeted transfer attacks often overfit surrogate-specific embedding space by relying on a single reference and emphasizing final-layer alignment, which underutilizes intermediate semantics and degrades transfer across heterogeneous VLMs. To address this, we propose SGHA-Attack, a Semantic-Guided Hierarchical Alignment framework that adopts multiple target references and enforces intermediate-layer consistency. Concretely, we generate a visually grounded reference pool by sampling a frozen text-to-image model conditioned on the target prompt, and then carefully select the Top-K most semantically relevant anchors under the surrogate to form a weighted mixture for stable optimization guidance. Building on these anchors, SGHA-Attack injects target semantics throughout the feature hierarchy by aligning intermediate visual representations at both global and spatial granularities across multiple depths, and by synchronizing intermediate visual and textual features in a shared latent subspace to provide early cross-modal supervision before the final projection. Extensive experiments on open-source and commercial black-box VLMs show that SGHA-Attack achieves stronger targeted transferability than prior methods and remains robust under preprocessing and purification defenses.

</details>


### [338] [Cross-Modal Alignment and Fusion for RGB-D Transmission-Line Defect Detection](https://arxiv.org/abs/2602.01696)
*Jiaming Cui,Shuai Zhou,Wenqiang Li,Ruifeng Qin,Feng Shen*

Main category: cs.CV

TL;DR: 本文提出了一种名为CMAFNet的网络，通过融合RGB图像和深度信息来提高无人机巡检中输电线路小目标缺陷的检测精度，并在TLRGBD数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于RGB的无人机输电线路缺陷检测方法在处理小规模缺陷、复杂背景和光照变化时面临挑战，难以区分几何上不明显的缺陷与相似的背景结构。

Method: CMAFNet采用“净化-融合”范式，结合了语义重组模块（通过学习的码本进行字典式特征净化，抑制模态噪声）和上下文语义集成框架（利用部分通道注意力捕捉全局空间依赖）。通过位置归一化实现跨模态显式对齐。

Result: 在TLRGBD数据集上，CMAFNet在94.5%的实例是小目标的情况下，取得了32.2%的mAP@50和12.5%的APs，优于最强基线9.8和4.0个百分点。轻量级版本在参数量和计算成本较低的情况下，性能超越了YOLO系列，并媲美Transformer类方法。

Conclusion: CMAFNet通过有效的跨模态对齐和融合策略，能够显著提升无人机输电线路缺陷检测的性能，尤其是在小目标检测方面，并在计算效率上取得了良好的平衡。

Abstract: Transmission line defect detection remains challenging for automated UAV inspection due to the dominance of small-scale defects, complex backgrounds, and illumination variations. Existing RGB-based detectors, despite recent progress, struggle to distinguish geometrically subtle defects from visually similar background structures under limited chromatic contrast. This paper proposes CMAFNet, a Cross-Modal Alignment and Fusion Network that integrates RGB appearance and depth geometry through a principled purify-then-fuse paradigm. CMAFNet consists of a Semantic Recomposition Module that performs dictionary-based feature purification via a learned codebook to suppress modality-specific noise while preserving defect-discriminative information, and a Contextual Semantic Integration Framework that captures global spatial dependencies using partial-channel attention to enhance structural semantic reasoning. Position-wise normalization within the purification stage enforces explicit reconstruction-driven cross-modal alignment, ensuring statistical compatibility between heterogeneous features prior to fusion. Extensive experiments on the TLRGBD benchmark, where 94.5% of instances are small objects, demonstrate that CMAFNet achieves 32.2% mAP@50 and 12.5% APs, outperforming the strongest baseline by 9.8 and 4.0 percentage points, respectively. A lightweight variant reaches 24.8% mAP50 at 228 FPS with only 4.9M parameters, surpassing all YOLO-based detectors while matching transformer-based methods at substantially lower computational cost.

</details>


### [339] [HandMCM: Multi-modal Point Cloud-based Correspondence State Space Model for 3D Hand Pose Estimation](https://arxiv.org/abs/2602.01586)
*Wencan Cheng,Gim Hee Lee*

Main category: cs.CV

TL;DR: 本文提出了一种基于Mamba的3D手部姿态估计新方法HandMCM，通过局部信息注入/过滤和对应关系建模，有效解决了自遮挡和物体遮挡问题，并在三个基准数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 3D手部关键点定位对增强现实等交互应用至关重要，但手部自身的遮挡以及与物体交互造成的遮挡带来了巨大挑战。

Method: 提出HandMCM方法，基于状态空间模型Mamba，并结合了局部信息注入/过滤模块和对应关系建模模块。该模型还集成了多模态图像特征，以增强输入表示能力。

Result: 在三个基准数据集上的实证评估表明，HandMCM在存在严重遮挡的挑战性场景下，显著优于当前最先进的方法。

Conclusion: HandMCM方法有效地解决了3D手部姿态估计中的遮挡问题，提高了准确性和鲁棒性，有望推动该技术在实际应用中的发展。

Abstract: 3D hand pose estimation that involves accurate estimation of 3D human hand keypoint locations is crucial for many human-computer interaction applications such as augmented reality. However, this task poses significant challenges due to self-occlusion of the hands and occlusions caused by interactions with objects. In this paper, we propose HandMCM to address these challenges. Our HandMCM is a novel method based on the powerful state space model (Mamba). By incorporating modules for local information injection/filtering and correspondence modeling, the proposed correspondence Mamba effectively learns the highly dynamic kinematic topology of keypoints across various occlusion scenarios. Moreover, by integrating multi-modal image features, we enhance the robustness and representational capacity of the input, leading to more accurate hand pose estimation. Empirical evaluations on three benchmark datasets demonstrate that our model significantly outperforms current state-of-the-art methods, particularly in challenging scenarios involving severe occlusions. These results highlight the potential of our approach to advance the accuracy and reliability of 3D hand pose estimation in practical applications.

</details>


### [340] [Know Your Step: Faster and Better Alignment for Flow Matching Models via Step-aware Advantages](https://arxiv.org/abs/2602.01591)
*Zhixiong Yue,Zixuan Ni,Feiyang Ye,Jinshan Zhang,Sheng Shen,Zhenpeng Mi*

Main category: cs.CV

TL;DR: 提出了一种名为TAFS GRPO的新型框架，用于训练流匹配文本到图像模型，以实现高效的、与人类偏好对齐的少数步生成器。该方法通过迭代注入自适应噪声和利用GRPO策略优化来解决现有RL方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于RL的流匹配模型在人类偏好对齐方面存在多步去噪、奖励信号稀疏且不精确的问题，导致对齐效果不佳。作者希望解决这些限制。

Method: 提出TAFS GRPO框架，通过迭代向单步采样结果注入自适应时间噪声，并对模型采样输出进行退火处理，从而在生成过程中引入随机性并保持语义完整性。同时，结合GRPO算法，避免了奖励函数的微分要求，并提供了密集且面向具体步骤的奖励，以实现稳定的策略优化。

Result: TAFS GRPO在少数步文本到图像生成方面取得了强大的性能，并显著提高了生成图像与人类偏好的对齐度。

Conclusion: TAFS GRPO是一个有效的新型框架，能够训练出高效且与人类偏好高度对齐的少数步文本到图像生成模型，克服了现有方法的不足。

Abstract: Recent advances in flow matching models, particularly with reinforcement learning (RL), have significantly enhanced human preference alignment in few step text to image generators. However, existing RL based approaches for flow matching models typically rely on numerous denoising steps, while suffering from sparse and imprecise reward signals that often lead to suboptimal alignment. To address these limitations, we propose Temperature Annealed Few step Sampling with Group Relative Policy Optimization (TAFS GRPO), a novel framework for training flow matching text to image models into efficient few step generators well aligned with human preferences. Our method iteratively injects adaptive temporal noise onto the results of one step samples. By repeatedly annealing the model's sampled outputs, it introduces stochasticity into the sampling process while preserving the semantic integrity of each generated image. Moreover, its step aware advantage integration mechanism combines the GRPO to avoid the need for the differentiable of reward function and provide dense and step specific rewards for stable policy optimization. Extensive experiments demonstrate that TAFS GRPO achieves strong performance in few step text to image generation and significantly improves the alignment of generated images with human preferences. The code and models of this work will be available to facilitate further research.

</details>


### [341] [Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention](https://arxiv.org/abs/2602.01801)
*Dvir Samuel,Issar Tzachor,Matan Levy,Micahel Green,Gal Chechik,Rami Ben-Ari*

Main category: cs.CV

TL;DR: 本文提出了一种训练无关的注意力框架，通过压缩KV缓存、加速交叉注意力以及稀疏化自注意力，显著提高了自回归视频扩散模型的推理速度和内存效率，同时保持了视觉质量，并实现了长序列生成时的稳定性能。


<details>
  <summary>Details</summary>
Motivation: 自回归视频扩散模型在长视频生成、视频世界模型和交互式游戏引擎方面具有潜力，但其核心注意力层的KV缓存增长会导致推理延迟和GPU内存占用不断增加，限制了可用时间上下文并损害了长距离一致性。

Method: 提出了一种统一的、训练无关的注意力框架，包含三个模块：1. TempCache：通过时间对应压缩KV缓存，限制缓存增长。2. AnnCA：利用快速近似最近邻（ANN）匹配选择与帧相关的提示词Token，加速交叉注意力。3. AnnSA：同样使用轻量级ANN，通过将查询限制在语义匹配的键上，稀疏化自注意力。

Result: 所提出的模块组合将注意力、计算和内存需求降低了高达 5-10 倍的端到端速度提升，同时保持了几乎相同的视觉质量。在长序列生成中，实现了稳定的吞吐量和近乎恒定的峰值GPU内存使用量，而现有方法则会逐渐变慢并增加内存占用。

Conclusion: 该框架有效地解决了自回归视频扩散模型在推理时的性能瓶颈，通过减少冗余的注意力计算和内存占用，使其能够实现更长时间、更高效的视频生成，并保持高质量和稳定性。

Abstract: Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage.

</details>


### [342] [CloDS: Visual-Only Unsupervised Cloth Dynamics Learning in Unknown Conditions](https://arxiv.org/abs/2602.01844)
*Yuliang Zhan,Jian Li,Wenbing Huang,Wenbing Huang,Yang Liu,Hao Sun*

Main category: cs.CV

TL;DR: 本文提出了一种名为 CloDS 的无监督学习框架，用于从多视角视觉观测中学习布料动力学，无需预先知道物理属性。它通过视频到几何的对齐和基于网格的高斯溅射方法，解决了布料模拟中的非线性形变和自遮挡问题，并在实验中展示了良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在模拟动态系统时需要已知物理属性作为监督或输入，限制了在未知条件下的应用。因此，研究者希望开发一种能够从视觉观测中无监督学习布料动力学的方法。

Method: 本文提出了 Cloth Dynamics Grounding (CDG) 场景和 Cloth Dynamics Splatting (CloDS) 框架。CloDS 采用三阶段流程：首先进行视频到几何的对齐，然后训练动力学模型。在视频到几何对齐阶段，使用双位置不透明度调制和基于网格的高斯溅射技术，处理非线性形变和自遮挡，实现 2D 观测和 3D 几何之间的双向映射。

Result: 实验结果表明，CloDS 能够有效地从视觉数据中学习布料动力学，并且在未见过的配置下具有强大的泛化能力。

Conclusion: CloDS 是一个创新的无监督动态学习框架，能够从多视角视觉观测中学习布料动力学，克服了现有方法的局限性，并在处理复杂的布料运动方面表现出色。

Abstract: Deep learning has demonstrated remarkable capabilities in simulating complex dynamic systems. However, existing methods require known physical properties as supervision or inputs, limiting their applicability under unknown conditions. To explore this challenge, we introduce Cloth Dynamics Grounding (CDG), a novel scenario for unsupervised learning of cloth dynamics from multi-view visual observations. We further propose Cloth Dynamics Splatting (CloDS), an unsupervised dynamic learning framework designed for CDG. CloDS adopts a three-stage pipeline that first performs video-to-geometry grounding and then trains a dynamics model on the grounded meshes. To cope with large non-linear deformations and severe self-occlusions during grounding, we introduce a dual-position opacity modulation that supports bidirectional mapping between 2D observations and 3D geometry via mesh-based Gaussian splatting in video-to-geometry grounding stage. It jointly considers the absolute and relative position of Gaussian components. Comprehensive experimental evaluations demonstrate that CloDS effectively learns cloth dynamics from visual data while maintaining strong generalization capabilities for unseen configurations. Our code is available at https://github.com/whynot-zyl/CloDS. Visualization results are available at https://github.com/whynot-zyl/CloDS_video}.%\footnote{As in this example.

</details>


### [343] [Samba+: General and Accurate Salient Object Detection via A More Unified Mamba-based Framework](https://arxiv.org/abs/2602.01593)
*Wenzhuo Zhao,Keren Fu,Jiahao He,Xiaohong Liu,Qijun Zhao,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出了一种基于Mamba的纯模型Samba，用于解决多模态显著目标检测（SOD）问题，并通过多任务联合训练得到更通用的Samba+。Samba通过空间邻域扫描（SNS）和上下文感知上采样（CAU）来处理局部和全局信息，Samba+进一步引入了图注意力（HGA）和持续学习（MACL）来处理多模态融合和持续适应性。


<details>
  <summary>Details</summary>
Motivation: 现有显著目标检测模型受限于CNN的感受野和Transformer的计算复杂度。Mamba在保持全局感受野的同时具有计算效率，因此被提出用于SOD任务，并希望解决任务特异性问题，实现统一和通用的模型。

Method: 提出Samba，一个纯Mamba架构，包含：1. 空间邻域扫描（SNS）Mamba块，用于保留显著区域的空间连续性。2. 上下文感知上采样（CAU），用于特征对齐和聚合。3. Samba+通过多任务联合训练，并引入：4. 轴辐图注意力（HGA），用于自适应跨模态融合。5. 模态锚定持续学习（MACL），用于缓解模态冲突和灾难性遗忘。

Result: Samba在六个SOD任务和22个数据集上均优于现有方法，且计算成本更低。Samba+使用单个模型在所有任务和数据集上取得更好的结果。框架显示了其潜力。

Conclusion: Samba提供了一种高效且灵活的Mamba基础SOD架构，在多个任务上表现出色。Samba+通过多任务学习和引入跨模态融合与持续学习策略，实现了更统一、更通用的模型，解决了模态适应性和持续学习的挑战。

Abstract: Existing salient object detection (SOD) models are generally constrained by the limited receptive fields of convolutional neural networks (CNNs) and quadratic computational complexity of Transformers. Recently, the emerging state-space model, namely Mamba, has shown great potential in balancing global receptive fields and computational efficiency. As a solution, we propose Saliency Mamba (Samba), a pure Mamba-based architecture that flexibly handles various distinct SOD tasks, including RGB/RGB-D/RGB-T SOD, video SOD (VSOD), RGB-D VSOD, and visible-depth-thermal SOD. Specifically, we rethink the scanning strategy of Mamba for SOD, and introduce a saliency-guided Mamba block (SGMB) that features a spatial neighborhood scanning (SNS) algorithm to preserve the spatial continuity of salient regions. A context-aware upsampling (CAU) method is also proposed to promote hierarchical feature alignment and aggregation by modeling contextual dependencies. As one step further, to avoid the "task-specific" problem as in previous SOD solutions, we develop Samba+, which is empowered by training Samba in a multi-task joint manner, leading to a more unified and versatile model. Two crucial components that collaboratively tackle challenges encountered in input of arbitrary modalities and continual adaptation are investigated. Specifically, a hub-and-spoke graph attention (HGA) module facilitates adaptive cross-modal interactive fusion, and a modality-anchored continual learning (MACL) strategy alleviates inter-modal conflicts together with catastrophic forgetting. Extensive experiments demonstrate that Samba individually outperforms existing methods across six SOD tasks on 22 datasets with lower computational cost, whereas Samba+ achieves even superior results on these tasks and datasets by using a single trained versatile model. Additional results further demonstrate the potential of our Samba framework.

</details>


### [344] [UV-M3TL: A Unified and Versatile Multimodal Multi-Task Learning Framework for Assistive Driving Perception](https://arxiv.org/abs/2602.01594)
*Wenzhuo Liu,Qiannan Guo,Zhen Wang,Wenshuo Wang,Lei Yang,Yicheng Qiao,Lening Wang,Zhiwei Li,Chen Lv,Shanghang Zhang,Junqiang Xi,Huaping Liu*

Main category: cs.CV

TL;DR: 提出了一种统一多功能多模态多任务学习（UV-M3TL）框架，用于同步识别驾驶员行为、驾驶员情绪、车辆行为和交通环境，同时减轻任务间的负迁移，并在AIDE数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有高级驾驶辅助系统（ADAS）在理解人类驾驶员行为和感知导航环境时，联合学习异构任务会导致任务间的负迁移，从而损害系统性能。

Method: 提出UV-M3TL框架，包含两个核心组件：1）双分支空间通道多模态嵌入（DB-SCME），通过双分支结构显式建模任务共享和任务特有特征，增强跨任务知识转移并减轻任务冲突；2）自适应特征解耦多任务损失（AFD-Loss），通过引入基于学习动态和特征解耦约束的自适应加权机制，提高联合优化稳定性并引导模型学习多样化的多任务表示。

Result: 在AIDE数据集上，UV-M3TL在所有四个任务上均实现了最先进的性能。在BDD100K、CityScapes、NYUD-v2和PASCAL-Context等其他公开多任务感知基准测试中，UV-M3TL在各种任务组合中表现出持续的强大性能，并在大多数任务上达到了最先进的水平。

Conclusion: UV-M3TL框架能够有效地联合学习多种异构任务，同时减轻任务间的负迁移，并在驾驶员行为和交通环境感知等多个领域实现了最先进的性能，证明了其通用性和有效性。

Abstract: Advanced Driver Assistance Systems (ADAS) need to understand human driver behavior while perceiving their navigation context, but jointly learning these heterogeneous tasks would cause inter-task negative transfer and impair system performance. Here, we propose a Unified and Versatile Multimodal Multi-Task Learning (UV-M3TL) framework to simultaneously recognize driver behavior, driver emotion, vehicle behavior, and traffic context, while mitigating inter-task negative transfer. Our framework incorporates two core components: dual-branch spatial channel multimodal embedding (DB-SCME) and adaptive feature-decoupled multi-task loss (AFD-Loss). DB-SCME enhances cross-task knowledge transfer while mitigating task conflicts by employing a dual-branch structure to explicitly model salient task-shared and task-specific features. AFD-Loss improves the stability of joint optimization while guiding the model to learn diverse multi-task representations by introducing an adaptive weighting mechanism based on learning dynamics and feature decoupling constraints. We evaluate our method on the AIDE dataset, and the experimental results demonstrate that UV-M3TL achieves state-of-the-art performance across all four tasks. To further prove the versatility, we evaluate UV-M3TL on additional public multi-task perception benchmarks (BDD100K, CityScapes, NYUD-v2, and PASCAL-Context), where it consistently delivers strong performance across diverse task combinations, attaining state-of-the-art results on most tasks.

</details>


### [345] [Learning Sparse Visual Representations via Spatial-Semantic Factorization](https://arxiv.org/abs/2602.01905)
*Theodore Zhengde Zhao,Sid Kiblawi,Jianwei Yang,Naoto Usuyama,Reuben Tan,Noel C Codella,Tristan Naumann,Hoifung Poon,Mu Wei*

Main category: cs.CV

TL;DR: 本文提出STELLAR框架，通过将视觉特征分解为语义概念及其空间分布的低秩乘积，解决了自监督学习中语义理解和图像重建的冲突。该方法实现了在保留空间信息的同时进行语义对齐，仅用16个稀疏token即可支持高质量重建（FID 2.60）和与密集骨干网络相当的语义性能（ImageNet准确率79.10%）。


<details>
  <summary>Details</summary>
Motivation: 现有的高层语义自监督学习（SSL）方法（如DINO）在进行数据增强对齐时会强制使全局token位置不变，导致空间坐标丢失，不利于图像重建。而生成式SSL方法（如MAE）虽然保留了密集特征网格用于重建，但难以产生高层语义抽象。研究动机在于解决SSL中语义理解与图像重建之间的固有矛盾。

Method: STELLAR框架通过将视觉特征分解为语义概念（低秩）及其空间分布（局部化矩阵）的乘积来解决上述冲突。这使得研究人员可以在语义token上进行类似DINO的数据增强对齐，同时保留局部化矩阵中的精确空间映射，以支持像素级重建。

Result: 使用STELLAR框架，仅需16个稀疏token即可同时支持高质量的图像重建（FID 2.60）和达到与密集骨干网络相当的语义性能（ImageNet准确率79.10%）。

Conclusion: STELLAR是一种通用的稀疏表示，通过策略性地分离语义身份和空间几何，成功地弥合了判别式和生成式视觉模型之间的差距，有效解决了自监督学习中的语义理解与图像重建的冲突。

Abstract: Self-supervised learning (SSL) faces a fundamental conflict between semantic understanding and image reconstruction. High-level semantic SSL (e.g., DINO) relies on global tokens that are forced to be location-invariant for augmentation alignment, a process that inherently discards the spatial coordinates required for reconstruction. Conversely, generative SSL (e.g., MAE) preserves dense feature grids for reconstruction but fails to produce high-level abstractions. We introduce STELLAR, a framework that resolves this tension by factorizing visual features into a low-rank product of semantic concepts and their spatial distributions. This disentanglement allows us to perform DINO-style augmentation alignment on the semantic tokens while maintaining the precise spatial mapping in the localization matrix necessary for pixel-level reconstruction. We demonstrate that as few as 16 sparse tokens under this factorized form are sufficient to simultaneously support high-quality reconstruction (2.60 FID) and match the semantic performance of dense backbones (79.10% ImageNet accuracy). Our results highlight STELLAR as a versatile sparse representation that bridges the gap between discriminative and generative vision by strategically separating semantic identity from spatial geometry. Code available at https://aka.ms/stellar.

</details>


### [346] [Token Pruning for In-Context Generation in Diffusion Transformers](https://arxiv.org/abs/2602.01609)
*Junqing Lin,Xingyu Zheng,Pei Cheng,Bin Fu,Jingwei Sun,Guangzhong Sun*

Main category: cs.CV

TL;DR: 本文提出了一种名为ToPi的训练无关的token修剪框架，用于解决Diffusion Transformers (DiTs) 在进行in-context generation时因输入序列过长而导致的计算瓶颈问题。ToPi通过识别关键的注意力层并利用新颖的影响力指标来选择性地修剪context token，同时结合时间更新策略，在不牺牲图像质量的前提下显著提升了推理速度。


<details>
  <summary>Details</summary>
Motivation: In-context generation能够增强DiTs的可控性，但会导致序列长度急剧增加，产生计算瓶颈。现有的token削减技术主要针对文本到图像生成，无法有效解决in-context generation中context token和target latent之间在空间、时间、功能上的角色不对称性。

Method: ToPi框架采用离线校准驱动的敏感性分析来识别关键的注意力层，并以此作为冗余度评估的代理。基于这些层，ToPi提出了一种影响力指标来量化每个context token的贡献，并结合时间更新策略来适应扩散过程的变化，从而实现token的 seçici (选择性) 修剪。

Result: 在复杂的图像生成任务上，ToPi能够实现超过30%的推理速度提升，同时保持结构保真度和视觉一致性。

Conclusion: ToPi是一种有效的、训练无关的token修剪框架，能够显著加速DiTs的in-context generation过程，同时保持生成图像的质量。

Abstract: In-context generation significantly enhances Diffusion Transformers (DiTs) by enabling controllable image-to-image generation through reference examples. However, the resulting input concatenation drastically increases sequence length, creating a substantial computational bottleneck. Existing token reduction techniques, primarily tailored for text-to-image synthesis, fall short in this paradigm as they apply uniform reduction strategies, overlooking the inherent role asymmetry between reference contexts and target latents across spatial, temporal, and functional dimensions. To bridge this gap, we introduce ToPi, a training-free token pruning framework tailored for in-context generation in DiTs. Specifically, ToPi utilizes offline calibration-driven sensitivity analysis to identify pivotal attention layers, serving as a robust proxy for redundancy estimation. Leveraging these layers, we derive a novel influence metric to quantify the contribution of each context token for selective pruning, coupled with a temporal update strategy that adapts to the evolving diffusion trajectory. Empirical evaluations demonstrate that ToPi can achieve over 30\% speedup in inference while maintaining structural fidelity and visual consistency across complex image generation tasks.

</details>


### [347] [DSXFormer: Dual-Pooling Spectral Squeeze-Expansion and Dynamic Context Attention Transformer for Hyperspectral Image Classification](https://arxiv.org/abs/2602.01906)
*Farhan Ullah,Irfan Ullah,Khalil Khan,Giovanni Pau,JaKeoung Koo*

Main category: cs.CV

TL;DR: 提出了一种名为DSXFormer的新型模型，用于高光谱图像分类，通过双池化谱挤压扩展块和动态上下文注意力机制，在提高光谱判别能力和计算效率之间取得了良好平衡，并在多个基准数据集上取得了优异的分类精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的高光谱图像分类方法在提高光谱判别能力的同时，常常难以维持计算效率，并且难以充分捕捉光谱-空间相关性。

Method: 提出DSXFormer模型，包含双池化谱挤压扩展（DSX）块，该块利用全局平均池化和最大池化来重校准光谱特征通道；引入动态上下文注意力（DCA）机制，在基于窗口的Transformer架构中动态捕捉局部谱-空间关系，降低计算量；采用patches提取、嵌入和合并策略进行多尺度特征学习。

Result: DSXFormer在Salinas (SA)、Indian Pines (IP)、Pavia University (PU)和Kennedy Space Center (KSC)四个基准数据集上取得了99.95%、98.91%、99.85%和98.52%的分类精度，均优于现有最先进方法。

Conclusion: DSXFormer通过结合双池化光谱挤压扩展和动态上下文注意力，有效地平衡了光谱特征的强调和空间上下文的表示，并在高光谱图像分类任务中展现出强大的性能和计算效率。

Abstract: Hyperspectral image classification (HSIC) is a challenging task due to high spectral dimensionality, complex spectral-spatial correlations, and limited labeled training samples. Although transformer-based models have shown strong potential for HSIC, existing approaches often struggle to achieve sufficient spectral discriminability while maintaining computational efficiency. To address these limitations, we propose a novel DSXFormer, a novel dual-pooling spectral squeeze-expansion transformer with Dynamic Context Attention for HSIC. The proposed DSXFormer introduces a Dual-Pooling Spectral Squeeze-Expansion (DSX) block, which exploits complementary global average and max pooling to adaptively recalibrate spectral feature channels, thereby enhancing spectral discriminability and inter-band dependency modeling. In addition, DSXFormer incorporates a Dynamic Context Attention (DCA) mechanism within a window-based transformer architecture to dynamically capture local spectral-spatial relationships while significantly reducing computational overhead. The joint integration of spectral dual-pooling squeeze-expansion and DCA enables DSXFormer to achieve an effective balance between spectral emphasis and spatial contextual representation. Furthermore, patch extraction, embedding, and patch merging strategies are employed to facilitate efficient multi-scale feature learning. Extensive experiments conducted on four widely used hyperspectral benchmark datasets, including Salinas (SA), Indian Pines (IP), Pavia University (PU), and Kennedy Space Center (KSC), demonstrate that DSXFormer consistently outperforms state-of-the-art methods, achieving classification accuracies of 99.95%, 98.91%, 99.85%, and 98.52%, respectively.

</details>


### [348] [Your AI-Generated Image Detector Can Secretly Achieve SOTA Accuracy, If Calibrated](https://arxiv.org/abs/2602.01973)
*Muli Yang,Gabriel James Goenawan,Henan Wang,Huaiyuan Qin,Chenghao Xu,Yanhua Yang,Fen Fang,Ying Sun,Joo-Hwee Lim,Hongyuan Zhu*

Main category: cs.CV

TL;DR: 提出一种基于贝叶斯决策理论的后验校准框架，用于解决AI生成图像检测器在测试时存在的系统性偏差问题，通过冻结骨干网络并学习一个标量修正项来补偿分布偏移，从而提高检测鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成图像检测器在训练时使用了平衡数据集，但在测试时却表现出系统性偏差，经常将假图像误判为真图像。作者认为这是由于假样本的分布偏移以及训练过程中学习到的隐式先验知识，导致模型过拟合到生成方法不通用的表面伪影，从而在面对测试时分布偏移时决策阈值不准确。

Method: 提出一个基于贝叶斯决策理论的、理论上可靠的后验校准框架。具体来说，在冻结骨干网络的情况下，引入一个可学习的标量修正项来调整模型的logits，并在目标分布的一个小验证集上进行优化。这种参数化调整可以补偿模型输出的分布偏移，重新对齐决策边界，而无需真实标签。

Result: 实验结果表明，该方法在具有挑战性的基准测试中显著提高了鲁棒性，且无需重新训练。它提供了一种轻量级且有原则性的解决方案，用于在开放世界中进行可靠且自适应的AI生成图像检测。

Conclusion: 所提出的后验校准框架能够有效解决AI生成图像检测器在测试时存在的系统性偏差问题，通过简单的参数化调整即可在不重新训练的情况下显著提升模型在开放世界场景下的鲁棒性和可靠性。

Abstract: Despite being trained on balanced datasets, existing AI-generated image detectors often exhibit systematic bias at test time, frequently misclassifying fake images as real. We hypothesize that this behavior stems from distributional shift in fake samples and implicit priors learned during training. Specifically, models tend to overfit to superficial artifacts that do not generalize well across different generation methods, leading to a misaligned decision threshold when faced with test-time distribution shift. To address this, we propose a theoretically grounded post-hoc calibration framework based on Bayesian decision theory. In particular, we introduce a learnable scalar correction to the model's logits, optimized on a small validation set from the target distribution while keeping the backbone frozen. This parametric adjustment compensates for distributional shift in model output, realigning the decision boundary even without requiring ground-truth labels. Experiments on challenging benchmarks show that our approach significantly improves robustness without retraining, offering a lightweight and principled solution for reliable and adaptive AI-generated image detection in the open world. Code is available at https://github.com/muliyangm/AIGI-Det-Calib.

</details>


### [349] [PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards](https://arxiv.org/abs/2602.01624)
*Minh-Quan Le,Gaurav Mittal,Cheng Zhao,David Gu,Dimitris Samaras,Mei Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为 PISCES 的无标注文本到视频生成后训练算法，通过新颖的双最优传输（OT）对齐奖励模块，解决了现有方法依赖大量标注或使用不匹配嵌入的问题，提高了视频质量和语义对齐度。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成模型在提升视频质量和语义对齐度方面存在不足，奖励式后训练方法要么依赖大量人类偏好标注，要么使用与视频和文本不完全匹配的嵌入，限制了其可扩展性和监督效果。因此，需要一种无需标注且能有效提升模型性能的方法。

Method: PISCES 采用无标注后训练方法，核心是新颖的双最优传输（OT）对齐奖励模块。该模块利用 OT 连接文本和视频嵌入，分别在分布和离散 token 层面进行对齐。具体而言，它包含一个“分布 OT 对齐质量奖励”，用于捕捉视频的整体视觉质量和时间连贯性；以及一个“离散 token 级 OT 对齐语义奖励”，用于强制文本和视频 token 之间的语义、时空对应关系。PISCES 支持直接反向传播和强化学习微调等优化范式。

Result: PISCES 在短视频和长视频生成任务上均表现出色，在 VBench 的质量和语义得分上均超越了基于标注和无标注的现有方法。人类偏好研究也验证了其有效性。

Conclusion: PISCES 是一种有效的无标注文本到视频生成后训练算法，通过双最优传输（OT）对齐奖励模块，在不依赖人类标注的情况下，显著提升了生成视频的质量和语义对齐度，并且可以灵活地应用于不同的优化范式。

Abstract: Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as a promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on large-scale human preference annotations or operate on misaligned embeddings from pre-trained vision-language models, leading to limited scalability or suboptimal supervision. We present $\texttt{PISCES}$, an annotation-free post-training algorithm that addresses these limitations via a novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, $\texttt{PISCES}$ uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) a Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) a Discrete Token-level OT-aligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, $\texttt{PISCES}$ is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both short- and long-video generation show that $\texttt{PISCES}$ outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning.

</details>


### [350] [Omni-Judge: Can Omni-LLMs Serve as Human-Aligned Judges for Text-Conditioned Audio-Video Generation?](https://arxiv.org/abs/2602.01623)
*Susan Liang,Chao Huang,Filippos Bellos,Yolo Yunlong Tang,Qianxiang Shen,Jing Bi,Luchuan Song,Zeliang Zhang,Jason Corso,Chenliang Xu*

Main category: cs.CV

TL;DR: 本研究提出Omni-Judge，一个利用全模态大语言模型（omni-LLMs）来评估文本驱动的音视频生成模型的方法。Omni-Judge在许多指标上表现与传统指标相当，尤其在语义理解方面表现出色，但受限于时间分辨率，在视频质量和音视频同步性方面表现不佳。研究表明omni-LLMs在多模态评估方面有潜力，但也存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成模型（如Sora 2, Veo 3）取得了显著进展，但对其生成的多模态（文本、音频、视频）输出进行评估仍然是一个挑战。人工评估虽然可靠但成本高昂且难以规模化，而传统的自动评估指标（如FVD, CLAP, ViCLIP）仅关注模态对，难以处理复杂提示，并且解释性有限。全模态大语言模型（omni-LLMs）能够同时处理多种模态，具备丰富的推理能力和可解释性，因此，研究人员希望探索omni-LLMs是否能作为一种与人类评估一致的评估者。

Method: 研究者提出Omni-Judge，一个评估全模态大语言模型（omni-LLMs）作为文本条件音视频生成模型评估者的框架。该框架在九个感知和对齐指标上对omni-LLMs进行了评估，并与传统评估指标进行了对比。

Result: Omni-Judge在与传统评估指标相当的相关性下，在语义要求高的任务（如音频-文本对齐、视频-文本对齐、音视频-文本一致性）上表现优异。然而，由于时间分辨率的限制，在视频质量和音视频同步等高帧率感知指标上表现不佳。Omni-Judge能够提供可解释的解释，揭示语义或物理上的不一致性。

Conclusion: 全模态大语言模型（omni-LLMs）有潜力作为统一的多模态生成评估器，尤其在处理语义相关的评估任务方面。然而，它们在处理高帧率的感知指标（如视频质量和音视频同步）方面存在局限性，并且需要进一步研究以提高其在这些方面的性能。Omni-Judge提供了解释性反馈，可用于模型的迭代改进。

Abstract: State-of-the-art text-to-video generation models such as Sora 2 and Veo 3 can now produce high-fidelity videos with synchronized audio directly from a textual prompt, marking a new milestone in multi-modal generation. However, evaluating such tri-modal outputs remains an unsolved challenge. Human evaluation is reliable but costly and difficult to scale, while traditional automatic metrics, such as FVD, CLAP, and ViCLIP, focus on isolated modality pairs, struggle with complex prompts, and provide limited interpretability. Omni-modal large language models (omni-LLMs) present a promising alternative: they naturally process audio, video, and text, support rich reasoning, and offer interpretable chain-of-thought feedback. Driven by this, we introduce Omni-Judge, a study assessing whether omni-LLMs can serve as human-aligned judges for text-conditioned audio-video generation. Across nine perceptual and alignment metrics, Omni-Judge achieves correlation comparable to traditional metrics and excels on semantically demanding tasks such as audio-text alignment, video-text alignment, and audio-video-text coherence. It underperforms on high-FPS perceptual metrics, including video quality and audio-video synchronization, due to limited temporal resolution. Omni-Judge provides interpretable explanations that expose semantic or physical inconsistencies, enabling practical downstream uses such as feedback-based refinement. Our findings highlight both the potential and current limitations of omni-LLMs as unified evaluators for multi-modal generation.

</details>


### [351] [SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors](https://arxiv.org/abs/2602.02000)
*Bing He,Jingnan Gao,Yunuo Chen,Ning Cao,Gang Chen,Zhengxue Cheng,Li Song,Wenjun Zhang*

Main category: cs.CV

TL;DR: SurfSplat是一种基于2D高斯泼溅（2DGS）的新型3D场景重建框架，通过引入表面连续性先验和强制Alpha混合策略，解决了现有3DGS方法生成不连续表面和颜色偏差的问题，实现了高保真度的3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有利用3D高斯泼溅（3DGS）的3D场景重建方法常生成不连续、有颜色偏差的点云，在近距离观察时出现严重伪影，难以恢复精确的几何和纹理。

Method: 提出SurfSplat框架，采用2D高斯泼溅（2DGS）作为基本单元，增强各向异性和几何精度。通过引入表面连续性先验和强制Alpha混合策略，确保几何的连贯性和纹理的保真度。同时，提出高分辨率渲染一致性（HRRC）作为新的评估指标。

Result: SurfSplat在RealEstate10K、DL3DV和ScanNet数据集上的实验表明，该方法在标准指标和HRRC指标上均优于现有方法，实现了高分辨率和高质量的3D重建。

Conclusion: SurfSplat是一种有效的方法，能够从稀疏输入中高保真地重建3D场景，克服了现有3DGS方法的局限性，为高精度3D重建提供了鲁棒的解决方案。

Abstract: Reconstructing 3D scenes from sparse images remains a challenging task due to the difficulty of recovering accurate geometry and texture without optimization. Recent approaches leverage generalizable models to generate 3D scenes using 3D Gaussian Splatting (3DGS) primitive. However, they often fail to produce continuous surfaces and instead yield discrete, color-biased point clouds that appear plausible at normal resolution but reveal severe artifacts under close-up views. To address this issue, we present SurfSplat, a feedforward framework based on 2D Gaussian Splatting (2DGS) primitive, which provides stronger anisotropy and higher geometric precision. By incorporating a surface continuity prior and a forced alpha blending strategy, SurfSplat reconstructs coherent geometry together with faithful textures. Furthermore, we introduce High-Resolution Rendering Consistency (HRRC), a new evaluation metric designed to evaluate high-resolution reconstruction quality. Extensive experiments on RealEstate10K, DL3DV, and ScanNet demonstrate that SurfSplat consistently outperforms prior methods on both standard metrics and HRRC, establishing a robust solution for high-fidelity 3D reconstruction from sparse inputs. Project page: https://hebing-sjtu.github.io/SurfSplat-website/

</details>


### [352] [Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks](https://arxiv.org/abs/2602.01630)
*Bohan Zeng,Kaixin Zhu,Daili Hua,Bozhou Li,Chengzhuo Tong,Yuran Wang,Xinyi Huang,Yifan Dai,Zixiang Zhang,Yifan Yang,Zhou Liu,Hao Liang,Xiaochen Ma,Ruichuan An,Tianyi Bai,Hongcheng Gao,Junbo Niu,Yang Shi,Xinlong Chen,Yue Ding,Minglei Shi,Kai Zeng,Yiwen Tang,Yuanxing Zhang,Pengfei Wan,Xintao Wang,Wentao Zhang*

Main category: cs.CV

TL;DR: 该论文认为当前AI研究中世界模型的构建过于分散，缺乏统一的理论框架，并提出了一个包含交互、感知、符号推理和空间表征的统一设计规范，以指导未来研究。


<details>
  <summary>Details</summary>
Motivation: 当前AI世界模型的研究方向过于分散，各个模型只关注特定任务（如视觉预测、3D估计等），缺乏系统性和整体性，未能有效促进AI对复杂环境的全面理解和交互能力。

Method: 通过分析现有世界模型研究的局限性，提出一个统一的设计规范，该规范强调世界模型应作为一个规范性框架，整合交互、感知、符号推理和空间表征等核心能力，而非仅仅是能力的集合。

Result: 文章提出了一种更具系统性和整体性的世界模型设计理念，而非具体的实验结果。

Conclusion: 未来的世界模型研究不应局限于孤立的任务，而应朝着更通用、更鲁棒、更符合原理的统一框架发展，以实现AI对世界的深度理解和交互。

Abstract: World models have emerged as a critical frontier in AI research, aiming to enhance large models by infusing them with physical dynamics and world knowledge. The core objective is to enable agents to understand, predict, and interact with complex environments. However, current research landscape remains fragmented, with approaches predominantly focused on injecting world knowledge into isolated tasks, such as visual prediction, 3D estimation, or symbol grounding, rather than establishing a unified definition or framework. While these task-specific integrations yield performance gains, they often lack the systematic coherence required for holistic world understanding. In this paper, we analyze the limitations of such fragmented approaches and propose a unified design specification for world models. We suggest that a robust world model should not be a loose collection of capabilities but a normative framework that integrally incorporates interaction, perception, symbolic reasoning, and spatial representation. This work aims to provide a structured perspective to guide future research toward more general, robust, and principled models of the world.

</details>


### [353] [ClueTracer: Question-to-Vision Clue Tracing for Training-Free Hallucination Suppression in Multimodal Reasoning](https://arxiv.org/abs/2602.02004)
*Gongli Xi,Kun Wang,Zeming Gao,Huahui Yi,Haolang Lu,Ye Tian,Wendong Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 ClueTracer 的新方法，用于解决大型多模态推理模型中因“推理漂移”导致的幻觉问题。ClueTracer 是一种无需训练、参数和架构无关的插件，能够追踪推理过程中的关键线索，抑制无关区域的注意力，从而提高模型在推理和非推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大型多模态推理模型在解决视觉问题时容易产生幻觉，即生成与输入图像或问题不符的内容。研究发现这种现象源于“推理漂移”，即模型在收集线索时过度关注与问题无关的实体，导致推理过程脱离视觉基础。

Method: 提出了 ClueRecall 指标来评估视觉线索检索，并开发了 ClueTracer 插件。ClueTracer 从问题出发，追踪关键线索在模型推理路径（问题 → 输出 → 视觉令牌）中的传播，从而定位任务相关区域并抑制对无关区域的虚假注意力。该方法无需额外训练，对模型架构也具有通用性。

Result: ClueTracer 在不进行任何额外训练的情况下，显著提升了多种推理架构（如 R1-OneVision, Ocean-R1, MM-Eureka 等）在推理基准上的表现，平均提升了 1.21 倍。当应用于非推理场景时，也取得了 1.14 倍的提升。

Conclusion: ClueTracer 是一种有效的、无需训练的幻觉抑制方法，通过追踪和聚焦推理过程中的关键视觉线索，显著改善了大型多模态推理模型的性能，并能在非推理场景下提供增益。

Abstract: Large multimodal reasoning models solve challenging visual problems via explicit long-chain inference: they gather visual clues from images and decode clues into textual tokens. Yet this capability also increases hallucinations, where the model generates content that is not supported by the input image or the question. To understand this failure mode, we identify \emph{reasoning drift}: during clue gathering, the model over-focuses on question-irrelevant entities, diluting focus on task-relevant cues and gradually decoupling the reasoning trace from visual grounding. As a consequence, many inference-time localization or intervention methods developed for non-reasoning models fail to pinpoint the true clues in reasoning settings. Motivated by these insights, we introduce ClueRecall, a metric for assessing visual clue retrieval, and present ClueTracer, a training-free, parameter-free, and architecture-agnostic plugin for hallucination suppression. ClueTracer starts from the question and traces how key clues propagate along the model's reasoning pathway (question $\rightarrow$ outputs $\rightarrow$ visual tokens), thereby localizing task-relevant patches while suppressing spurious attention to irrelevant regions. Remarkably, \textbf{without any additional training}, ClueTracer improves all \textbf{reasoning} architectures (including \texttt{R1-OneVision}, \texttt{Ocean-R1}, \texttt{MM-Eureka}, \emph{etc}.) by $\mathbf{1.21\times}$ on reasoning benchmarks. When transferred to \textbf{non-reasoning} settings, it yields a $\mathbf{1.14\times}$ gain.

</details>


### [354] [From Frames to Sequences: Temporally Consistent Human-Centric Dense Prediction](https://arxiv.org/abs/2602.01661)
*Xingyu Miao,Junting Dong,Qin Zhao,Yuhang Yang,Junhao Chen,Yang Long*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法，通过生成包含像素级标签的合成人类视频数据，来解决视频序列中人物密集预测的时间一致性问题，并训练了一个统一的ViT模型，在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人类密集预测模型在单个帧上表现良好，但在视频序列中容易出现闪烁问题，尤其是在运动、遮挡和光照变化的情况下。此外，缺乏用于多任务密集预测的配对视频数据进行监督。

Method: 1. 构建了一个可扩展的合成数据管道，生成包含像素级深度、法线和掩码的逼真人类视频序列，提供帧级和序列级监督。2. 训练了一个统一的ViT模型，该模型通过CSE嵌入注入显式的人类几何先验，并使用轻量级通道重加权模块增强几何特征的可靠性。3. 采用两阶段训练策略：先在静态数据上进行预训练，然后在动态序列上进行监督，以分别学习空间表示和时间一致性。

Result: 在THuman2.1和Hi4D数据集上取得了最先进的性能，并且对真实世界视频具有良好的泛化能力。

Conclusion: 提出的合成数据生成方法和统一的ViT模型能够有效解决视频中人物密集预测的时间一致性挑战，并取得了优于现有方法的性能。

Abstract: In this work, we focus on the challenge of temporally consistent human-centric dense prediction across video sequences. Existing models achieve strong per-frame accuracy but often flicker under motion, occlusion, and lighting changes, and they rarely have paired human video supervision for multiple dense tasks. We address this gap with a scalable synthetic data pipeline that generates photorealistic human frames and motion-aligned sequences with pixel-accurate depth, normals, and masks. Unlike prior static data synthetic pipelines, our pipeline provides both frame-level labels for spatial learning and sequence-level supervision for temporal learning. Building on this, we train a unified ViT-based dense predictor that (i) injects an explicit human geometric prior via CSE embeddings and (ii) improves geometry-feature reliability with a lightweight channel reweighting module after feature fusion. Our two-stage training strategy, combining static pretraining with dynamic sequence supervision, enables the model first to acquire robust spatial representations and then refine temporal consistency across motion-aligned sequences. Extensive experiments show that we achieve state-of-the-art performance on THuman2.1 and Hi4D and generalize effectively to in-the-wild videos.

</details>


### [355] [Federated Vision Transformer with Adaptive Focal Loss for Medical Image Classification](https://arxiv.org/abs/2602.01633)
*Xinyuan Zhao,Yihang Wu,Ahmad Chaddad,Tareef Daqqaq,Reem Kateb*

Main category: cs.CV

TL;DR: 该研究提出了一种结合动态自适应焦点损失（DAFL）和客户端感知聚合策略的联邦学习框架，以解决医疗图像等领域中深度学习模型对大数据集的需求以及联邦学习中数据异质性和类别不平衡的挑战，并在多个数据集上取得了显著的分类性能提升。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型（如 Vision Transformer）通常需要大量数据，但在医疗图像等领域，数据隐私法规限制了数据访问。联邦学习（FL）虽可在不交换数据的情况下进行模型聚合，但本地客户端的数据异质性和类别不平衡会影响模型泛化能力。

Method: 提出了一种联邦学习框架，包含：1. 动态自适应焦点损失（DAFL），通过动态调整类别不平衡系数来关注少数类；2. 客户端感知聚合策略，采用加权聚合方式，自适应数据大小和特征，以更好地处理客户端异质性。

Result: 在 ISIC、Ocular Disease 和 RSNA-ICH 三个公共数据集上的分类结果显示，该框架在大多数情况下优于 DenseNet121、ResNet50、ViT-S/16、ViT-L/32、FedCLIP、Swin Transformer、CoAtNet 和 MixNet，准确率提升范围为 0.98% 至 41.69%。对 ISIC 数据集进行的消融研究验证了所提出的损失函数和聚合策略的有效性。

Conclusion: 所提出的结合 DAFL 和客户端感知聚合策略的联邦学习框架能够有效解决数据异质性和类别不平衡问题，提升联邦学习模型的泛化能力和分类性能，特别是在医疗图像等数据受限且分布不均的场景下。

Abstract: While deep learning models like Vision Transformer (ViT) have achieved significant advances, they typically require large datasets. With data privacy regulations, access to many original datasets is restricted, especially medical images. Federated learning (FL) addresses this challenge by enabling global model aggregation without data exchange. However, the heterogeneity of the data and the class imbalance that exist in local clients pose challenges for the generalization of the model. This study proposes a FL framework leveraging a dynamic adaptive focal loss (DAFL) and a client-aware aggregation strategy for local training. Specifically, we design a dynamic class imbalance coefficient that adjusts based on each client's sample distribution and class data distribution, ensuring minority classes receive sufficient attention and preventing sparse data from being ignored. To address client heterogeneity, a weighted aggregation strategy is adopted, which adapts to data size and characteristics to better capture inter-client variations. The classification results on three public datasets (ISIC, Ocular Disease and RSNA-ICH) show that the proposed framework outperforms DenseNet121, ResNet50, ViT-S/16, ViT-L/32, FedCLIP, Swin Transformer, CoAtNet, and MixNet in most cases, with accuracy improvements ranging from 0.98\% to 41.69\%. Ablation studies on the imbalanced ISIC dataset validate the effectiveness of the proposed loss function and aggregation strategy compared to traditional loss functions and other FL approaches. The codes can be found at: https://github.com/AIPMLab/ViT-FLDAF.

</details>


### [356] [Rethinking Genomic Modeling Through Optical Character Recognition](https://arxiv.org/abs/2602.02014)
*Hongxin Xiang,Pengsen Ma,Yunkang Cao,Di Yu,Haowen Chen,Xinyu Yang,Xiangxiang Zeng*

Main category: cs.CV

TL;DR: OpticalDNA 是一种新颖的基于视觉的基因组建模框架，通过将 DNA 视为文档进行 OCR 式理解，实现了高效压缩和强大的基因组任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 Transformer 的基因组模型将 DNA 视为一维序列，计算效率低下且难以处理长序列，这与基因组稀疏且不连续的语义特性不符。

Method: OpticalDNA 将 DNA 渲染成结构化的视觉布局，并训练一个 OCR 驱动的视觉-语言模型，该模型包含一个视觉 DNA 编码器（用于生成紧凑的可重构视觉标记）和一个文档解码器。在此基础上，通过条件目标函数学习了注重布局的 DNA 表示，支持基因组的读取、区域定位、子序列检索和掩码跨度补全等任务。

Result: 在多个基因组基准测试中，OpticalDNA 表现优于现有方法，在长序列（高达 450k 个碱基）上实现了最佳性能，同时有效标记数量减少了近 20 倍，并且在可训练参数仅为 256k 的情况下，超越了参数量大得多的模型。

Conclusion: OpticalDNA 提供了一种高效且有效的基因组建模新范式，通过借鉴文档理解的方法，克服了传统序列模型的局限性，并在处理长基因组序列方面取得了显著进展。

Abstract: Recent genomic foundation models largely adopt large language model architectures that treat DNA as a one-dimensional token sequence. However, exhaustive sequential reading is structurally misaligned with sparse and discontinuous genomic semantics, leading to wasted computation on low-information background and preventing understanding-driven compression for long contexts. Here, we present OpticalDNA, a vision-based framework that reframes genomic modeling as Optical Character Recognition (OCR)-style document understanding. OpticalDNA renders DNA into structured visual layouts and trains an OCR-capable vision--language model with a \emph{visual DNA encoder} and a \emph{document decoder}, where the encoder produces compact, reconstructible visual tokens for high-fidelity compression. Building on this representation, OpticalDNA defines prompt-conditioned objectives over core genomic primitives-reading, region grounding, subsequence retrieval, and masked span completion-thereby learning layout-aware DNA representations that retain fine-grained genomic information under a reduced effective token budget. Across diverse genomic benchmarks, OpticalDNA consistently outperforms recent baselines; on sequences up to 450k bases, it achieves the best overall performance with nearly $20\times$ fewer effective tokens, and surpasses models with up to $985\times$ more activated parameters while tuning only 256k \emph{trainable} parameters.

</details>


### [357] [ReCALL: Recalibrating Capability Degradation for MLLM-based Composed Image Retrieval](https://arxiv.org/abs/2602.01639)
*Tianyu Yang,ChenWei He,Xiangzhao Hao,Tianyue Wang,Jiarui Guo,Haiyun Guo,Leigang Qu,Jinqiao Wang,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出了一种名为ReCALL的框架，用于解决将生成式多模态大语言模型（MLLMs）适应于图像检索任务时出现的“能力退化”问题，通过诊断、生成和精炼三个步骤，提升了在CIRR和FashionIQ数据集上的检索性能。


<details>
  <summary>Details</summary>
Motivation: 早期的双塔视觉语言模型在组合推理方面存在不足。尽管生成式MLLMs在图像检索方面展现出潜力，但将其直接用于检索会导致“能力退化”，即在适应检索任务后，其原有的细粒度推理能力下降。研究旨在解决这一能力退化问题。

Method: ReCALL框架遵循诊断-生成-精炼的流程。首先，通过自指导的信息实例挖掘来诊断检索器的认知盲点。然后，利用CoT提示基础MLLM生成纠正指令和三元组，并通过基于VQA的一致性过滤进行质量控制。最后，通过分组对比学习方案，在生成的训练数据上对检索器进行持续训练，以恢复和提升其细粒度推理能力。

Result: 在CIRR和FashionIQ数据集上的大量实验表明，ReCALL能够持续地校正能力退化，并达到了最先进的性能。

Conclusion: ReCALL是一个模型无关的框架，能够有效解决将生成式MLLMs应用于图像检索时出现的能力退化问题，并通过一系列步骤重建和优化了检索器的细粒度推理和嵌入空间，从而显著提升了检索性能。

Abstract: Composed Image Retrieval (CIR) aims to retrieve target images based on a hybrid query comprising a reference image and a modification text. Early dual-tower Vision-Language Models (VLMs) struggle with cross-modality compositional reasoning required for this task. Recently, adapting generative Multimodal Large Language Models (MLLMs) for retrieval offers a promising direction. However, we identify that this adaptation strategy overlooks a fundamental issue: adapting a generative MLLM into a single-embedding discriminative retriever triggers a paradigm conflict, which leads to Capability Degradation - the deterioration of native fine-grained reasoning after retrieval adaptation. To address this challenge, we propose ReCALL (Recalibrating Capability Degradation), a model-agnostic framework that follows a diagnose-generate-refine pipeline: Firstly, we diagnose cognitive blind spots of the retriever via self-guided informative instance mining. Next, we generate corrective instructions and triplets by CoT prompting the foundation MLLM and conduct quality control with VQA-based consistency filtering. Finally, we refine the retriever through continual training on these triplets with a grouped contrastive scheme, thereby internalizing fine-grained visual-semantic distinctions and realigning the discriminative embedding space of retriever with intrinsic compositional reasoning within the MLLM. Extensive experiments on CIRR and FashionIQ show that ReCALL consistently recalibrates degraded capabilities and achieves state-of-the-art performance. Code will be released soon.

</details>


### [358] [One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation](https://arxiv.org/abs/2602.02033)
*Shuo Lu,Haohan Wang,Wei Feng,Weizhen Wang,Shen Zhang,Yaoyu Li,Ao Ma,Zheng Zhang,Jingjing Lv,Junjie Shen,Ching Law,Bing Zhan,Yuan Xu,Huizai Yao,Yongcan Yu,Chenyang Si,Jian Liang*

Main category: cs.CV

TL;DR: 本文提出了一种名为OSMF的统一框架，用于生成广告图片，该框架能够根据用户群体的不同偏好生成定制化的图片，以提高点击率。框架通过产品感知自适应分组、群体感知多模态大语言模型（G-MLLM）以及群体区分性偏好优化（Group-DPO）来实现。


<details>
  <summary>Details</summary>
Motivation: 现有的广告图片生成方法倾向于采用“一刀切”的策略来优化整体点击率，忽略了不同用户群体之间偏好的多样性，导致针对特定用户群体的营销效果不佳。

Method: 1. 产品感知自适应分组：根据用户属性和产品特征动态划分用户群体，并提取每个群体的集体偏好特征。2. 群体感知多模态大语言模型（G-MLLM）：预训练模型以同时理解群体特征并生成广告图片。3. 群体区分性偏好优化（Group-DPO）：微调G-MLLM以实现群体级别的偏好对齐，提升各群体生成图片的点击率。4. 引入GAIP数据集：首个大规模群体广告图片偏好数据集。

Result: OSMF框架在离线和在线实验中均达到了最先进的性能，有效地提升了针对不同用户群体的广告图片点击率。

Conclusion: OSMF框架能够有效地解决现有广告图片生成方法在处理用户群体偏好多样性方面的不足，通过生成定制化的广告图片，显著提高了广告的点击率，为定向营销提供了新的解决方案。

Abstract: Advertising image generation has increasingly focused on online metrics like Click-Through Rate (CTR), yet existing approaches adopt a ``one-size-fits-all" strategy that optimizes for overall CTR while neglecting preference diversity among user groups. This leads to suboptimal performance for specific groups, limiting targeted marketing effectiveness. To bridge this gap, we present \textit{One Size, Many Fits} (OSMF), a unified framework that aligns diverse group-wise click preferences in large-scale advertising image generation. OSMF begins with product-aware adaptive grouping, which dynamically organizes users based on their attributes and product characteristics, representing each group with rich collective preference features. Building on these groups, preference-conditioned image generation employs a Group-aware Multimodal Large Language Model (G-MLLM) to generate tailored images for each group. The G-MLLM is pre-trained to simultaneously comprehend group features and generate advertising images. Subsequently, we fine-tune the G-MLLM using our proposed Group-DPO for group-wise preference alignment, which effectively enhances each group's CTR on the generated images. To further advance this field, we introduce the Grouped Advertising Image Preference Dataset (GAIP), the first large-scale public dataset of group-wise image preferences, including around 600K groups built from 40M users. Extensive experiments demonstrate that our framework achieves the state-of-the-art performance in both offline and online settings. Our code and datasets will be released at https://github.com/JD-GenX/OSMF.

</details>


### [359] [Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models](https://arxiv.org/abs/2602.02185)
*Yu Zeng,Wenxuan Huang,Zhen Fang,Shuang Chen,Yufan Shen,Yishuo Cai,Xiaoman Wang,Zhenfei Yin,Lin Chen,Zehui Chen,Shiting Huang,Yiming Zhao,Yao Hu,Philip Torr,Wanli Ouyang,Shaosheng Cao*

Main category: cs.CV

TL;DR: 本文提出了VDR-Bench基准测试集，以解决当前多模态大语言模型（MLLM）在视觉-文本联合搜索能力评估中的不足。该基准测试集通过多阶段精心设计和专家评审，旨在模拟真实世界的搜索场景，减少文本线索和模型先验知识的泄露，并增加了图像和文本搜索的挑战性。此外，本文还提出了一种多轮裁剪搜索策略，以提升模型在真实视觉检索场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有评估MLLM视觉-文本搜索能力的方法存在两方面的局限性：1）评估标准并非以视觉搜索为中心，导致答案可能通过文本线索或模型已有的世界知识被泄露；2）评估场景过于理想化，图像搜索过于依赖近乎精确的匹配，而文本搜索又过于直接，缺乏挑战性。因此，需要一个更真实、更具挑战性的基准来评估这类系统。

Method: 本文构建了一个包含2,000个视觉问答（VQA）实例的VDR-Bench基准测试集。该基准的构建过程包括精心设计的、多阶段的策展流程和严格的专家评审，以确保问题能够评估Vision-DeepResearch系统在真实世界条件下的行为。此外，为提高模型在视觉检索方面的能力，提出了一种简单的多轮裁剪搜索工作流程。

Result: VDR-Bench基准测试集能够更准确地评估MLLM的视觉搜索和文本搜索能力。提出的多轮裁剪搜索策略在模拟的真实视觉检索场景下，能够有效提升模型性能。

Conclusion: VDR-Bench为评估多模态深度研究系统提供了一个更实际、更具挑战性的基准。提出的多轮裁剪搜索方法有助于改进模型在真实视觉检索任务上的表现。研究结果为未来多模态深度研究系统的设计提供了实践指导。

Abstract: Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding. However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems. The code will be released in https://github.com/Osilly/Vision-DeepResearch.

</details>


### [360] [Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models](https://arxiv.org/abs/2602.02043)
*Cristian Sbrolli,Matteo Matteucci,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: 研究提出了一种名为Auto-Comp的自动化合成方法，用于生成大规模视觉-语言模型（VLMs）的组合推理基准测试。通过控制生成图像和描述的复杂性，该方法能够精细地评估模型在颜色绑定和空间关系等方面的能力，并发现现有模型普遍存在组合推理缺陷，尤其是在面对低熵干扰时。


<details>
  <summary>Details</summary>
Motivation: 现代视觉-语言模型（VLMs）在组合推理方面存在严重缺陷，例如混淆颜色和对象的组合。为了能够精细、可控地分析这些失败的原因，特别是区分视觉和语言方面的根源，研究者需要新的评估方法。

Method: 研究者开发了一个名为Auto-Comp的自动化合成流程，用于生成大规模、可控的基准测试。该流程生成配对图像，结合了最小化的描述（例如，“一个监视器在自行车左边”）和由大型语言模型（LLMs）生成的上下文描述（例如，“在一个明亮的摄影棚里，一个监视器在自行车左边”）。这种A/B测试设计旨在分离核心的绑定能力和视觉-语言的复杂性。研究者使用该方法创建了用于颜色绑定和空间关系的基准测试。

Result: 对20个VLM的评估表明，CLIP和SigLIP模型家族在颜色绑定和空间关系方面都普遍存在组合推理失败。研究者提出的“Confusion Benchmark”揭示了模型不仅有简单的属性交换问题，还极易受到低熵干扰（如重复的对象或颜色）的影响。研究还发现了一个意想不到的权衡：视觉-语言上下文虽然有助于空间推理，但会引入视觉混乱，从而损害局部属性的绑定能力。

Conclusion: VLMs在组合推理方面存在普遍且深层次的缺陷，尤其是在处理复杂场景和低熵干扰时。视觉-语言上下文对不同推理任务的影响可能存在权衡。研究提出的Auto-Comp流程和生成的基准测试为未来VLM的评估和改进提供了工具和资源。

Abstract: Modern Vision-Language Models (VLMs) exhibit a critical flaw in compositional reasoning, often confusing "a red cube and a blue sphere" with "a blue cube and a red sphere". Disentangling the visual and linguistic roots of these failures is a fundamental challenge for robust evaluation. To enable fine-grained, controllable analysis, we introduce Auto-Comp, a fully automated and synthetic pipeline for generating scalable benchmarks. Its controllable nature is key to dissecting and isolating different reasoning skills. Auto-Comp generates paired images from Minimal (e.g., "a monitor to the left of a bicycle on a white background") and LLM-generated Contextual captions (e.g., "In a brightly lit photography studio, a monitor is positioned to the left of a bicycle"), allowing a controlled A/B test to disentangle core binding ability from visio-linguistic complexity. Our evaluation of 20 VLMs on novel benchmarks for color binding and spatial relations reveals universal compositional failures in both CLIP and SigLIP model families. Crucially, our novel "Confusion Benchmark" reveals a deeper flaw beyond simple attribute swaps: models are highly susceptible to low-entropy distractors (e.g., repeated objects or colors), demonstrating their compositional failures extend beyond known bag-of-words limitations. we uncover a surprising trade-off: visio-linguistic context, which provides global scene cues, aids spatial reasoning but simultaneously hinders local attribute binding by introducing visual clutter. We release the Auto-Comp pipeline to facilitate future benchmark creation, alongside all our generated benchmarks (https://huggingface.co/AutoComp).

</details>


### [361] [Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance Learning Using Real-World Clinical Data](https://arxiv.org/abs/2602.02067)
*Nikola Cenikj,Özgün Turgut,Alexander Müller,Alexander Steger,Jan Kehrer,Marcus Brugger,Daniel Rueckert,Eimo Martens,Philip Müller*

Main category: cs.CV

TL;DR: 提出了一种名为SegmentMIL的基于Transformer的多视图多实例学习框架，用于患者层面的冠状动脉狭窄分类，无需视级标注，并能区分左右冠状动脉及其各段。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的冠状动脉狭窄检测方法依赖于昂贵的视级标注，并且无法捕捉多视图之间的时序动态和依赖关系，而这些对临床诊断至关重要。

Method: 提出SegmentMIL，一个基于Transformer的多视图多实例学习框架，使用患者级监督，无需视级标注，联合预测狭窄的存在并定位受累解剖区域。

Result: SegmentMIL在内部和外部评估中均获得高性能，优于视级模型和经典MIL基线。

Conclusion: SegmentMIL是一种临床上可行且可扩展的冠状动脉狭窄诊断解决方案，它通过在缺乏视级标注的情况下进行患者级别分类，解决了现有方法的局限性。

Abstract: Coronary artery stenosis is a leading cause of cardiovascular disease, diagnosed by analyzing the coronary arteries from multiple angiography views. Although numerous deep-learning models have been proposed for stenosis detection from a single angiography view, their performance heavily relies on expensive view-level annotations, which are often not readily available in hospital systems. Moreover, these models fail to capture the temporal dynamics and dependencies among multiple views, which are crucial for clinical diagnosis. To address this, we propose SegmentMIL, a transformer-based multi-view multiple-instance learning framework for patient-level stenosis classification. Trained on a real-world clinical dataset, using patient-level supervision and without any view-level annotations, SegmentMIL jointly predicts the presence of stenosis and localizes the affected anatomical region, distinguishing between the right and left coronary arteries and their respective segments. SegmentMIL obtains high performance on internal and external evaluations and outperforms both view-level models and classical MIL baselines, underscoring its potential as a clinically viable and scalable solution for coronary stenosis diagnosis. Our code is available at https://github.com/NikolaCenic/mil-stenosis.

</details>


### [362] [Moonworks Lunara Aesthetic II: An Image Variation Dataset](https://arxiv.org/abs/2602.01666)
*Yan Wang,Partho Hassan,Samiha Sadeka,Nada Soliman,M M Sayeef Abdullah,Sabit Hassan*

Main category: cs.CV

TL;DR: 本文介绍了一个名为Lunara Aesthetic II的图像数据集，旨在支持对图像生成和编辑系统中上下文一致性的评估和学习。该数据集包含2,854对锚点链接的变体，这些变体源自Moonworks创作的艺术品和照片，并在保持身份稳定的同时应用了各种上下文变换（如光照、天气、视角等）。


<details>
  <summary>Details</summary>
Motivation: 为了支持对现代图像生成和编辑系统中上下文一致性的受控评估和学习，并且该数据集具有身份保持的上下文变异作为监督信号，同时保留了高美学评分。

Method: 创建了一个包含2,854对锚点链接的变体图像对的数据集，这些变体对源自Moonworks的原始艺术和照片。每对变体应用了上下文变换（如光照、天气、视角、场景构图、色调或情绪），同时保持了稳定的底层身份。

Result: 实验结果显示出高身份稳定性、强大的目标属性实现能力以及优于大规模网络数据集的稳健美学特征。

Conclusion: Lunara Aesthetic II数据集通过Apache 2.0许可证发布，旨在用于图像生成和图像到图像系统的基准测试、微调和分析，以评估上下文泛化、身份保持和编辑鲁棒性，并提供可解释的、关系型的监督信号。

Abstract: We introduce Lunara Aesthetic II, a publicly released, ethically sourced image dataset designed to support controlled evaluation and learning of contextual consistency in modern image generation and editing systems. The dataset comprises 2,854 anchor-linked variation pairs derived from original art and photographs created by Moonworks. Each variation pair applies contextual transformations, such as illumination, weather, viewpoint, scene composition, color tone, or mood; while preserving a stable underlying identity. Lunara Aesthetic II operationalizes identity-preserving contextual variation as a supervision signal while also retaining Lunara's signature high aesthetic scores. Results show high identity stability, strong target attribute realization, and a robust aesthetic profile that exceeds large-scale web datasets. Released under the Apache 2.0 license, Lunara Aesthetic II is intended for benchmarking, fine-tuning, and analysis of contextual generalization, identity preservation, and edit robustness in image generation and image-to-image systems with interpretable, relational supervision. The dataset is publicly available at: https://huggingface.co/datasets/moonworks/lunara-aesthetic-image-variations.

</details>


### [363] [VRGaussianAvatar: Integrating 3D Gaussian Avatars into VR](https://arxiv.org/abs/2602.01674)
*Hail Song,Boram Yoon,Seokhwan Yang,Seoyoung Kang,Hyunjeong Kim,Henning Metzmacher,Woontack Woo*

Main category: cs.CV

TL;DR: VRGaussianAvatar 是一个集成系统，仅通过头戴式显示器（HMD）的追踪信号，即可在虚拟现实中实现实时全身 3D 高斯溅射（3DGS）化身。


<details>
  <summary>Details</summary>
Motivation: 研究动机是需要在虚拟现实中实现实时、高质量的全身 3D 化身，并利用现有设备（如 HMD）的追踪信号。

Method: 该系统采用并行流水线，包含 VR 前端和 GA 后端。VR 前端利用逆向运动学估计全身姿态，并将姿态和相机参数传送到后端。GA 后端利用立体渲染和新提出的“双目批处理”（Binocular Batching）技术，高效地渲染从单张图像重建的 3DGS 化身。

Result: VRGaussianAvatar 能够维持交互式 VR 性能，并且在外观相似度、具身感和可信度方面优于基于图像和视频的网格化身基线。

Conclusion: VRGaussianAvatar 成功实现了仅凭 HMD 追踪信号在 VR 中进行实时全身 3DGS 化身渲染，并且在用户体验上表现更优。

Abstract: We present VRGaussianAvatar, an integrated system that enables real-time full-body 3D Gaussian Splatting (3DGS) avatars in virtual reality using only head-mounted display (HMD) tracking signals. The system adopts a parallel pipeline with a VR Frontend and a GA Backend. The VR Frontend uses inverse kinematics to estimate full-body pose and streams the resulting pose along with stereo camera parameters to the backend. The GA Backend stereoscopically renders a 3DGS avatar reconstructed from a single image. To improve stereo rendering efficiency, we introduce Binocular Batching, which jointly processes left and right eye views in a single batched pass to reduce redundant computation and support high-resolution VR displays. We evaluate VRGaussianAvatar with quantitative performance tests and a within-subject user study against image- and video-based mesh avatar baselines. Results show that VRGaussianAvatar sustains interactive VR performance and yields higher perceived appearance similarity, embodiment, and plausibility. Project page and source code are available at https://vrgaussianavatar.github.io.

</details>


### [364] [FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization](https://arxiv.org/abs/2602.01723)
*Yikun Ma,Yiqing Li,Jingwen Ye,Zhongkai Wu,Weidong Zhang,Lin Gao,Zhi Jin*

Main category: cs.CV

TL;DR: FastPhysGS是一个快速鲁棒的物理动力学3DGS模拟框架，通过实例感知粒子填充和双向图解耦优化，有效解决了现有方法在物理模拟中的泛化性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有将3D高斯溅射扩展到4D物理模拟的方法存在挑战，要么需要手动调参，要么依赖视频扩散模型，限制了泛化能力和优化效率；基于LLM/VLM的方法存在感知差距，导致物理行为不稳定且忽略了3DGS的表面结构。

Method: 1. 实例感知粒子填充（IPF）结合蒙特卡洛重要性采样（MCIS）高效填充内部粒子并保持几何保真度；2. 双向图解耦优化（BGDO）是一种自适应策略，用于快速优化从VLM预测的材料参数。

Result: FastPhysGS能够在1分钟内以7GB的运行时内存实现高保真物理模拟，在模拟效果上优于现有方法。

Conclusion: FastPhysGS是一个快速、鲁棒且高效的物理动力学3DGS模拟框架，通过创新的粒子填充和优化策略，解决了现有方法的局限性，并展现出广泛的应用潜力。

Abstract: Extending 3D Gaussian Splatting (3DGS) to 4D physical simulation remains challenging. Based on the Material Point Method (MPM), existing methods either rely on manual parameter tuning or distill dynamics from video diffusion models, limiting the generalization and optimization efficiency. Recent attempts using LLMs/VLMs suffer from a text/image-to-3D perceptual gap, yielding unstable physics behavior. In addition, they often ignore the surface structure of 3DGS, leading to implausible motion. We propose FastPhysGS, a fast and robust framework for physics-based dynamic 3DGS simulation:(1) Instance-aware Particle Filling (IPF) with Monte Carlo Importance Sampling (MCIS) to efficiently populate interior particles while preserving geometric fidelity; (2) Bidirectional Graph Decoupling Optimization (BGDO), an adaptive strategy that rapidly optimizes material parameters predicted from a VLM. Experiments show FastPhysGS achieves high-fidelity physical simulation in 1 minute using only 7 GB runtime memory, outperforming prior works with broad potential applications.

</details>


### [365] [Toxicity Assessment in Preclinical Histopathology via Class-Aware Mahalanobis Distance for Known and Novel Anomalies](https://arxiv.org/abs/2602.02124)
*Olga Graf,Dhrupal Patel,Peter Groß,Charlotte Lempp,Matthias Hein,Fabian Heinemann*

Main category: cs.CV

TL;DR: 本文提出了一种基于AI的异常检测框架，用于识别啮齿动物肝脏组织病理学全切片图像（WSIs）中的健康组织和已知病变，同时也能检测罕见的、未经过训练的异常病变。


<details>
  <summary>Details</summary>
Motivation: 药物研发中，毒性是导致失败的主要原因。早期检测不良反应对于降低成本和加速安全药物的开发至关重要。然而，传统的病理学评估依赖专家，效率低下，阻碍了大规模筛选。

Method: 利用预训练的Vision Transformer (DINOv2)模型，通过低秩适配（LoRA）进行微调，实现组织分割。该框架能够识别健康组织和已知病变，并将罕见病变作为“分布外”（OOD）发现。利用Mahalanobis距离提取特征进行OOD检测，并提出使用特定类别的阈值来优化性能，以解决组织学数据中类依赖性变异问题。

Result: 通过优化特定类别的阈值，将0.16%的病变组织错误地分类为健康，以及0.35%的健康组织错误地分类为病变。该框架能够准确检测到鼠标肝脏WSIs中的异常，包括罕见的OOD形态。

Conclusion: AI驱动的组织病理学有潜力支持药物研发的临床前工作流程，减少后期失败，并提高药物开发的效率。

Abstract: Drug-induced toxicity remains a leading cause of failure in preclinical development and early clinical trials. Detecting adverse effects at an early stage is critical to reduce attrition and accelerate the development of safe medicines. Histopathological evaluation remains the gold standard for toxicity assessment, but it relies heavily on expert pathologists, creating a bottleneck for large-scale screening. To address this challenge, we introduce an AI-based anomaly detection framework for histopathological whole-slide images (WSIs) in rodent livers from toxicology studies. The system identifies healthy tissue and known pathologies (anomalies) for which training data is available. In addition, it can detect rare pathologies without training data as out-of-distribution (OOD) findings. We generate a novel dataset of pixelwise annotations of healthy tissue and known pathologies and use this data to fine-tune a pre-trained Vision Transformer (DINOv2) via Low-Rank Adaptation (LoRA) in order to do tissue segmentation. Finally, we extract features for OOD detection using the Mahalanobis distance. To better account for class-dependent variability in histological data, we propose the use of class-specific thresholds. We optimize the thresholds using the mean of the false negative and false positive rates, resulting in only 0.16\% of pathological tissue classified as healthy and 0.35\% of healthy tissue classified as pathological. Applied to mouse liver WSIs with known toxicological findings, the framework accurately detects anomalies, including rare OOD morphologies. This work demonstrates the potential of AI-driven histopathology to support preclinical workflows, reduce late-stage failures, and improve efficiency in drug development.

</details>


### [366] [Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis](https://arxiv.org/abs/2602.01710)
*Salma Zahran,Zhou Ao,Zhengyang Zhang,Chen Chi,Chenchen Yuan,Yanming Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种无需人工标注的显微图像分割方法，利用相场模拟生成合成数据，并通过CycleGAN将其转换为逼真的SEM图像，然后用这些合成数据训练U-Net模型，实现了在真实实验图像上的高精度泛化，从而加速材料分析。


<details>
  <summary>Details</summary>
Motivation: 显微图像的语义分割对于材料表征至关重要，但由于人工标注数据成本高、主观性强且数量稀少，其自动化面临严峻挑战。利用物理模拟生成数据存在领域差距，导致模型泛化能力差。

Method: 1. 使用相场模拟生成微观结构形貌及其精确的分割真值掩膜。2. 采用CycleGAN进行无配对图像-图像翻译，将模拟图像转换为高保真的逼真SEM图像。3. 使用仅在合成数据上训练的U-Net模型进行分割。

Result: 在未见过的实验图像上，仅使用合成数据训练的U-Net模型取得了0.90的平均边界F1分数和0.88的IOU。t-SNE特征空间投影和香农熵分析证实，合成图像在统计和特征上与真实数据无法区分。

Conclusion: 该研究成功构建了一个劳动力自由的分割框架，有效地弥合了模拟与现实之间的领域差距。通过完全摆脱手动标注，将数据稀缺问题转化为数据丰富问题，为加速材料发现和分析提供了鲁棒且全自动的解决方案。

Abstract: Semantic segmentation of microscopy images is a critical task for high-throughput materials characterisation, yet its automation is severely constrained by the prohibitive cost, subjectivity, and scarcity of expert-annotated data. While physics-based simulations offer a scalable alternative to manual labelling, models trained on such data historically fail to generalise due to a significant domain gap, lacking the complex textures, noise patterns, and imaging artefacts inherent to experimental data. This paper introduces a novel framework for labour-free segmentation that successfully bridges this simulation-to-reality gap. Our pipeline leverages phase-field simulations to generate an abundant source of microstructural morphologies with perfect, intrinsically-derived ground-truth masks. We then employ a Cycle-Consistent Generative Adversarial Network (CycleGAN) for unpaired image-to-image translation, transforming the clean simulations into a large-scale dataset of high-fidelity, realistic SEM images. A U-Net model, trained exclusively on this synthetic data, demonstrated remarkable generalisation when deployed on unseen experimental images, achieving a mean Boundary F1-Score of 0.90 and an Intersection over Union (IOU) of 0.88. Comprehensive validation using t-SNE feature-space projection and Shannon entropy analysis confirms that our synthetic images are statistically and featurally indistinguishable from the real data manifold. By completely decoupling model training from manual annotation, our generative framework transforms a data-scarce problem into one of data abundance, providing a robust and fully automated solution to accelerate materials discovery and analysis.

</details>


### [367] [VQ-Style: Disentangling Style and Content in Motion with Residual Quantized Representations](https://arxiv.org/abs/2602.02334)
*Fatemeh Zargarbashi,Dhruv Agrawal,Jakob Buhmann,Martin Guay,Stelian Coros,Robert W. Sumner*

Main category: cs.CV

TL;DR: 提出一种新颖的方法，利用 RVQ-VAE、对比学习和信息泄露损失来解耦人类运动数据的风格和内容，从而实现高效的风格迁移。


<details>
  <summary>Details</summary>
Motivation: 人类运动数据包含复杂的语义内容和细微的风格特征，这些特征难以建模和分离，尤其是在进行风格迁移时。

Method: 使用残差向量量化变分自编码器（RVQ-VAE）学习运动的粗粒度到细粒度表示。通过整合对比学习和一种新的信息泄露损失，在代码本学习中组织内容和风格。在推理时采用量化码交换技术进行风格迁移。

Result: 成功实现了运动风格迁移，并且无需对未见过的风格进行微调。该框架在风格迁移、风格去除和运动混合等多种推理应用中表现出强大的通用性。

Conclusion: 所提出的方法能够有效解耦人类运动数据的风格和内容，为运动风格迁移提供了一种简单有效的方法，并展示了在多种应用中的灵活性。

Abstract: Human motion data is inherently rich and complex, containing both semantic content and subtle stylistic features that are challenging to model. We propose a novel method for effective disentanglement of the style and content in human motion data to facilitate style transfer. Our approach is guided by the insight that content corresponds to coarse motion attributes while style captures the finer, expressive details. To model this hierarchy, we employ Residual Vector Quantized Variational Autoencoders (RVQ-VAEs) to learn a coarse-to-fine representation of motion. We further enhance the disentanglement by integrating contrastive learning and a novel information leakage loss with codebook learning to organize the content and the style across different codebooks. We harness this disentangled representation using our simple and effective inference-time technique Quantized Code Swapping, which enables motion style transfer without requiring any fine-tuning for unseen styles. Our framework demonstrates strong versatility across multiple inference applications, including style transfer, style removal, and motion blending.

</details>


### [368] [SMTrack: State-Aware Mamba for Efficient Temporal Modeling in Visual Tracking](https://arxiv.org/abs/2602.01677)
*Yinchao Ma,Dengqing Yang,Zhangyu He,Wenfei Yang,Tianzhu Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为SMTrack（State-aware Mamba Tracker）的新型视觉跟踪方法，利用状态空间模型（SSM）中的Mamba来有效地建模长时序依赖关系，实现了在低计算成本下的鲁棒跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉跟踪方法在处理动态场景时面临挑战，特别是CNN和Transformer在建模长时序依赖方面存在局限性，需要复杂的模块或高昂的计算成本。因此，研究者希望找到一种更高效、更鲁棒的时序建模方法。

Method: 提出了一种名为SMTrack的新型跟踪框架，其核心是引入了一种选择性的、状态感知的状态空间模型（Mamba）。该模型具有状态感知的参数，能够捕获更多样的时序线索。SMTrack在训练时具有线性计算复杂度，能够在长距离上进行时序交互。在跟踪时，通过隐藏状态的传播和更新，使每一帧都能与之前的帧进行交互，从而降低了计算成本。

Result: SMTrack在各种实验中都取得了令人满意的性能，并且计算成本较低。具体性能提升和计算成本降低的量化数据需要在论文正文中详细说明。

Conclusion: SMTrack成功地将状态空间模型（Mamba）应用于视觉跟踪，提供了一种简单、高效且计算成本低廉的框架，能够有效地建模长时序依赖关系，从而在动态场景下实现鲁棒的跟踪。

Abstract: Visual tracking aims to automatically estimate the state of a target object in a video sequence, which is challenging especially in dynamic scenarios. Thus, numerous methods are proposed to introduce temporal cues to enhance tracking robustness. However, conventional CNN and Transformer architectures exhibit inherent limitations in modeling long-range temporal dependencies in visual tracking, often necessitating either complex customized modules or substantial computational costs to integrate temporal cues. Inspired by the success of the state space model, we propose a novel temporal modeling paradigm for visual tracking, termed State-aware Mamba Tracker (SMTrack), providing a neat pipeline for training and tracking without needing customized modules or substantial computational costs to build long-range temporal dependencies. It enjoys several merits. First, we propose a novel selective state-aware space model with state-wise parameters to capture more diverse temporal cues for robust tracking. Second, SMTrack facilitates long-range temporal interactions with linear computational complexity during training. Third, SMTrack enables each frame to interact with previously tracked frames via hidden state propagation and updating, which releases computational costs of handling temporal cues during tracking. Extensive experimental results demonstrate that SMTrack achieves promising performance with low computational costs.

</details>


### [369] [DenVisCoM: Dense Vision Correspondence Mamba for Efficient and Real-time Optical Flow and Stereo Estimation](https://arxiv.org/abs/2602.01724)
*Tushar Anand,Maheswar Bora,Antitza Dantcheva,Abhijit Das*

Main category: cs.CV

TL;DR: 提出了一种名为DenVisCoM的新型Mamba块和混合架构，用于同时进行实时且精确的光流和视差估计，并在多个数据集上验证了其在准确性和实时性方面的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的多视图几何和运动估计任务（如光流和视差估计）是相互关联的，但现有方法通常独立处理，导致效率低下。因此，研究的动机是开发一个统一的架构来同时解决这些任务，以提高准确性和效率。

Method: 提出了一种名为DenVisCoM的新型Mamba块，并将其与基于Transformer的注意力块相结合，构建了一个混合架构。该架构旨在实现准确性、实时推理和低内存占用的平衡，以联合估计运动和三维密集感知任务。

Result: 在多个基准数据集上进行的广泛实验分析表明，所提出的模型能够在实时情况下准确地估计光流和视差。模型在准确性和实时处理能力之间取得了良好的权衡。

Conclusion: 所提出的DenVisCoM块和混合架构是一种有效的方法，可以同时且实时地准确估计光流和视差。该模型在准确性、实时性和内存效率方面表现出色，为多视图几何和运动估计任务提供了一个有前景的解决方案。

Abstract: In this work, we propose a novel Mamba block DenVisCoM, as well as a novel hybrid architecture specifically tailored for accurate and real-time estimation of optical flow and disparity estimation. Given that such multi-view geometry and motion tasks are fundamentally related, we propose a unified architecture to tackle them jointly. Specifically, the proposed hybrid architecture is based on DenVisCoM and a Transformer-based attention block that efficiently addresses real-time inference, memory footprint, and accuracy at the same time for joint estimation of motion and 3D dense perception tasks. We extensively analyze the benchmark trade-off of accuracy and real-time processing on a large number of datasets. Our experimental results and related analysis suggest that our proposed model can accurately estimate optical flow and disparity estimation in real time. All models and associated code are available at https://github.com/vimstereo/DenVisCoM.

</details>


### [370] [Implicit neural representation of textures](https://arxiv.org/abs/2602.02354)
*Albert Kwok,Zheyuan Hu,Dounia Hammou*

Main category: cs.CV

TL;DR: 该研究探索了如何设计不同的神经网络作为连续操作的纹理隐式神经表示（INR），并评估了其在图像质量、内存使用和渲染推理时间方面的权衡，同时研究了其在实时渲染和下游任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探索隐式神经表示（INR）在纹理合成领域的潜力，并开发一种连续操作的纹理INR，以期提高图像质量、优化内存使用和渲染效率。

Method: 研究方法包括设计和实验不同的神经网络作为纹理INR，并在图像质量、内存使用和渲染推理时间方面进行评估。此外，还研究了其在实时渲染、mipmap匹配和INR空间生成等应用。

Result: 实验表明，所设计的INR在图像质量方面表现良好，同时内存使用和渲染推理时间也具有可观性。研究还分析了这些目标之间的权衡关系，并展示了INR在实时渲染和下游任务中的应用潜力。

Conclusion: 该研究成功地设计了一种连续操作的纹理INR，并对其性能进行了全面的评估。研究结果表明，INR在纹理合成方面具有良好的前景，并且能够应用于实时渲染和下游任务，但需要在图像质量、内存和推理时间之间进行权衡。

Abstract: Implicit neural representation (INR) has proven to be accurate and efficient in various domains. In this work, we explore how different neural networks can be designed as a new texture INR, which operates in a continuous manner rather than a discrete one over the input UV coordinate space. Through thorough experiments, we demonstrate that these INRs perform well in terms of image quality, with considerable memory usage and rendering inference time. We analyze the balance between these objectives. In addition, we investigate various related applications in real-time rendering and down-stream tasks, e.g. mipmap fitting and INR-space generation.

</details>


### [371] [Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory](https://arxiv.org/abs/2602.02393)
*Ruiqi Wu,Xuanhua He,Meng Cheng,Tianyu Yang,Yong Zhang,Zhuoliang Kang,Xunliang Cai,Xiaoming Wei,Chunle Guo,Chongyi Li,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 本文提出了Infinite-World，一个能够在复杂真实世界环境中保持超过1000帧连贯视觉记忆的交互式世界模型。通过引入分层无姿态记忆压缩器（HPMC）和不确定性感知动作标注模块，并结合翻新密集微调策略，Infinite-World克服了真实世界数据噪声和视角重访稀缺的挑战，在视觉质量、动作可控性和空间一致性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型在真实世界视频训练中存在不足，因为姿态估计噪声大且视角重访少。本文旨在弥合合成数据和真实世界数据之间的差距，开发一个在真实环境中能有效学习和保持长程视觉记忆的世界模型。

Method: 1. 提出分层无姿态记忆压缩器（HPMC），通过递归蒸馏历史潜在表示来压缩记忆，无需显式几何先验。 2. 提出不确定性感知动作标注模块，将连续运动离散化为三态逻辑，以应对噪声轨迹。 3. 采用翻新密集微调策略，使用少量数据激活模型的长程环闭能力。

Result: Infinite-World在视觉质量、动作可控性和空间一致性方面取得了优于现有方法的性能，并得到客观指标和用户研究的验证。

Conclusion: Infinite-World是一个强大的交互式世界模型，能够有效处理真实世界视频数据中的挑战，实现长程连贯视觉记忆和鲁棒的动作-响应学习。

Abstract: We propose Infinite-World, a robust interactive world model capable of maintaining coherent visual memory over 1000+ frames in complex real-world environments. While existing world models can be efficiently optimized on synthetic data with perfect ground-truth, they lack an effective training paradigm for real-world videos due to noisy pose estimations and the scarcity of viewpoint revisits. To bridge this gap, we first introduce a Hierarchical Pose-free Memory Compressor (HPMC) that recursively distills historical latents into a fixed-budget representation. By jointly optimizing the compressor with the generative backbone, HPMC enables the model to autonomously anchor generations in the distant past with bounded computational cost, eliminating the need for explicit geometric priors. Second, we propose an Uncertainty-aware Action Labeling module that discretizes continuous motion into a tri-state logic. This strategy maximizes the utilization of raw video data while shielding the deterministic action space from being corrupted by noisy trajectories, ensuring robust action-response learning. Furthermore, guided by insights from a pilot toy study, we employ a Revisit-Dense Finetuning Strategy using a compact, 30-minute dataset to efficiently activate the model's long-range loop-closure capabilities. Extensive experiments, including objective metrics and user studies, demonstrate that Infinite-World achieves superior performance in visual quality, action controllability, and spatial consistency.

</details>


### [372] [Simplicity Prevails: The Emergence of Generalizable AIGI Detection in Visual Foundation Models](https://arxiv.org/abs/2602.01738)
*Yue Zhou,Xinan He,Kaiqing Lin,Bing Fan,Feng Ding,Bin Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于冻结的视觉基础模型特征的简单线性分类器，在现实场景下检测AI生成图像方面取得了新的SOTA性能，优于现有专用检测器，并认为这是基础模型海量预训练数据中包含合成内容所带来的涌现能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器在真实场景下性能急剧下降，研究者希望找到一种在现实环境中更鲁棒的检测方法。

Method: 使用现代视觉基础模型（如Perception Encoder, MetaCLIP 2, DINOv3）的冻结特征，训练一个简单的线性分类器。

Result: 该简单线性分类器在传统基准测试中可匹敌专用检测器，在现实场景（包括未见过生成器和挑战性分布）中性能显著提升，准确率提高超过30%。研究还发现，Vision-Language Models能内化“伪造”的语义概念，而Self-Supervised Learning模型能隐式学习鉴别性法证特征。

Conclusion: 提倡AI取证的研究范式从过度拟合静态基准测试转向利用基础模型的演进世界知识以实现真实世界可靠性，并指出了当前方法在图像重捕获、传输、VAE重构和局部编辑方面仍然存在局限性。

Abstract: While specialized detectors for AI-Generated Images (AIGI) achieve near-perfect accuracy on curated benchmarks, they suffer from a dramatic performance collapse in realistic, in-the-wild scenarios. In this work, we demonstrate that simplicity prevails over complex architectural designs. A simple linear classifier trained on the frozen features of modern Vision Foundation Models , including Perception Encoder, MetaCLIP 2, and DINOv3, establishes a new state-of-the-art. Through a comprehensive evaluation spanning traditional benchmarks, unseen generators, and challenging in-the-wild distributions, we show that this baseline not only matches specialized detectors on standard benchmarks but also decisively outperforms them on in-the-wild datasets, boosting accuracy by striking margins of over 30\%. We posit that this superior capability is an emergent property driven by the massive scale of pre-training data containing synthetic content. We trace the source of this capability to two distinct manifestations of data exposure: Vision-Language Models internalize an explicit semantic concept of forgery, while Self-Supervised Learning models implicitly acquire discriminative forensic features from the pretraining data. However, we also reveal persistent limitations: these models suffer from performance degradation under recapture and transmission, remain blind to VAE reconstruction and localized editing. We conclude by advocating for a paradigm shift in AI forensics, moving from overfitting on static benchmarks to harnessing the evolving world knowledge of foundation models for real-world reliability.

</details>


### [373] [ReasonEdit: Editing Vision-Language Models using Human Reasoning](https://arxiv.org/abs/2602.02408)
*Jiaxing Qiu,Kaihua Hou,Roxana Daneshjou,Ahmed Alaa,Thomas Hartvigsen*

Main category: cs.CV

TL;DR: ReasonEdit 是首个针对视觉语言模型（VLM）的推理编辑模型，它通过存储和检索人类推理来提高编辑的泛化能力，并在多个视觉问答数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的模型编辑方法无法处理需要推理的视觉语言任务，而这些任务在实际应用中很重要。因此，研究者提出了 ReasonEdit，以解决 VLM 在推理任务中的编辑问题。

Method: ReasonEdit 提出了一种新的模型编辑设置，用户在编辑过程中提供推理过程。这些推理被存储在一个代码本中，并在推理时使用一种新颖的拓扑平衡多模态嵌入方法进行检索，该方法借鉴了网络科学的原理。

Result: 在四个 VLM 模型和多个基于推理的视觉问答数据集上，ReasonEdit 实现了最先进的编辑性能。实验表明，在编辑过程中利用人类推理可以显著提高编辑的泛化能力。

Conclusion: 将人类推理纳入 VLM 的模型编辑过程中，能够极大地提高编辑的泛化能力，并且 ReasonEdit 是首个实现这一目标的模型编辑框架。

Abstract: Model editing aims to correct errors in large, pretrained models without altering unrelated behaviors. While some recent works have edited vision-language models (VLMs), no existing editors tackle reasoning-heavy tasks, which typically require humans and models to reason about images.We therefore propose ReasonEdit, the first VLM editor to let users explain their reasoning during editing, introducing a new, practical model editing setup. ReasonEdit continuously stores human reasoning in a codebook, and retrieves only relevant facts during inference using a novel topology-balanced multimodal embedding method inspired by network science. Across four VLMs on multiple rationale-based visual question answering datasets, ReasonEdit achieves state-of-the-art editing performance, ultimately showing that using human reasoning during editing greatly improves edit generalization.

</details>


### [374] [ObjEmbed: Towards Universal Multimodal Object Embeddings](https://arxiv.org/abs/2602.01753)
*Shenghao Fu,Yukun Su,Fengyun Rao,Jing Lyu,Xiaohua Xie,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: 提出了一种名为ObjEmbed的多模态大模型（MLLM）嵌入模型，该模型将图像分解为多个区域嵌入（每个对应一个对象）和全局嵌入，以解决图像区域与文本短语的细粒度对齐问题，并在视觉基础、局部和全局图像检索任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的大多模态嵌入模型擅长全局图像-文本对齐，但在图像区域与特定短语的细粒度对齐方面存在不足。

Method: ObjEmbed将图像分解为区域嵌入（每个对象一个）和全局嵌入。为每个区域生成两个嵌入：一个用于语义匹配的对象嵌入，一个用于预测定位质量的IoU嵌入。通过结合语义相似度和预测IoU来计算最终的对象匹配分数。该模型支持单次前向传播高效编码所有对象和整个图像。

Result: ObjEmbed在18个不同的基准测试中展现出优越的性能，表明其具有强大的语义判别能力。

Conclusion: ObjEmbed模型通过对象导向表示、多功能性和高效编码，有效地解决了图像区域与文本的细粒度对齐问题，并在多种视觉理解任务中取得了SOTA表现。

Abstract: Aligning objects with corresponding textual descriptions is a fundamental challenge and a realistic requirement in vision-language understanding. While recent multimodal embedding models excel at global image-text alignment, they often struggle with fine-grained alignment between image regions and specific phrases. In this work, we present ObjEmbed, a novel MLLM embedding model that decomposes the input image into multiple regional embeddings, each corresponding to an individual object, along with global embeddings. It supports a wide range of visual understanding tasks like visual grounding, local image retrieval, and global image retrieval. ObjEmbed enjoys three key properties: (1) Object-Oriented Representation: It captures both semantic and spatial aspects of objects by generating two complementary embeddings for each region: an object embedding for semantic matching and an IoU embedding that predicts localization quality. The final object matching score combines semantic similarity with the predicted IoU, enabling more accurate retrieval. (2) Versatility: It seamlessly handles both region-level and image-level tasks. (3) Efficient Encoding: All objects in an image, along with the full image, are encoded in a single forward pass for high efficiency. Superior performance on 18 diverse benchmarks demonstrates its strong semantic discrimination.

</details>


### [375] [Tail-Aware Post-Training Quantization for 3D Geometry Models](https://arxiv.org/abs/2602.01741)
*Sicheng Pan,Chen Tang,Shuzhao Xie,Ke Yang,Weixiang Zhang,Jiawei Li,Bin Chen,Shu-Tao Xia,Zhi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 TAPTQ 的针对 3D 几何模型的后训练量化（PTQ）方法，通过渐进式校准、基于三元搜索的量化区间搜索以及基于 TRE 的模块补偿，有效解决了 3D 模型量化中的数据量大、计算复杂度高和量化误差累积问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 PTQ 方法主要针对 2D 模型，在 3D 几何模型上效果不佳，原因是 3D 模型特征分布复杂且校准开销大，这阻碍了 3D 模型在资源受限平台上的部署。因此，需要一种专门为 3D 几何学习设计的 PTQ 方法。

Method: 1. 渐进式粗到精校准构建：通过构建紧凑的子集来解决 3D 数据集的数据量瓶颈，确保统计纯度和几何代表性。2. 基于三元搜索的量化区间搜索：将量化区间搜索重构为优化问题，并引入三元搜索算法，将计算复杂度从 O(N) 降低到 O(log N)。3. TRE-引导的模块级补偿：利用 Tail Relative Error (TRE) 指标自适应地识别和纠正对长尾激活异常值敏感的模块中的失真。

Result: TAPTQ 在 VGGT 和 Pi3 基准测试中，在准确率方面始终优于最先进的 PTQ 方法，同时显著减少了校准时间。

Conclusion: TAPTQ 是一种有效的、针对 3D 几何模型优化的 PTQ 方法，能够克服现有方法的局限性，实现高精度和高效率的 3D 模型量化。

Abstract: The burgeoning complexity and scale of 3D geometry models pose significant challenges for deployment on resource-constrained platforms. While Post-Training Quantization (PTQ) enables efficient inference without retraining, conventional methods, primarily optimized for 2D Vision Transformers, fail to transfer effectively to 3D models due to intricate feature distributions and prohibitive calibration overhead. To address these challenges, we propose TAPTQ, a Tail-Aware Post-Training Quantization pipeline specifically engineered for 3D geometric learning. Our contribution is threefold: (1) To overcome the data-scale bottleneck in 3D datasets, we develop a progressive coarse-to-fine calibration construction strategy that constructs a highly compact subset to achieve both statistical purity and geometric representativeness. (2) We reformulate the quantization interval search as an optimization problem and introduce a ternary-search-based solver, reducing the computational complexity from $\mathcal{O}(N)$ to $\mathcal{O}(\log N)$ for accelerated deployment. (3) To mitigate quantization error accumulation, we propose TRE-Guided Module-wise Compensation, which utilizes a Tail Relative Error (TRE) metric to adaptively identify and rectify distortions in modules sensitive to long-tailed activation outliers. Extensive experiments on the VGGT and Pi3 benchmarks demonstrate that TAPTQ consistently outperforms state-of-the-art PTQ methods in accuracy while significantly reducing calibration time. The code will be released soon.

</details>


### [376] [UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing](https://arxiv.org/abs/2602.02437)
*Dianyi Wang,Chaofan Ma,Feng Han,Size Wu,Wei Song,Yibin Wang,Zhixiong Zhang,Tianhang Wang,Siyuan Wang,Zhongyu Wei,Jiaqi Wang*

Main category: cs.CV

TL;DR:  UniReason 是一个统一的多模态框架，通过结合世界知识增强的规划（用于生成）和基于编辑的视觉精炼（用于纠错），解决了复杂合成任务中的深度推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有的统一多模态模型在复杂的合成任务中缺乏深度推理能力，并且将文本到图像生成和图像编辑视为独立的功能，而不是相互关联的推理步骤。

Method: UniReason 提出了一种双重推理范式：1. 通过世界知识增强的规划来处理生成任务，以注入隐式约束；2. 利用编辑能力进行细粒度的视觉精炼，通过自我反思来纠正视觉错误。该框架在一个共享表示中统一了生成和编辑，模拟了人类的“规划-精炼”认知过程。研究人员还构建了一个大规模（约30万样本）的以推理为中心的数据集，覆盖五个主要知识领域，以及一个用于视觉自我纠正的代理生成语料库。

Result: UniReason 在 WISE、KrisBench 和 UniREditBench 等以推理为中心的基准测试中取得了先进的性能，同时保持了优越的通用合成能力。

Conclusion: UniReason 通过整合规划和精炼的双重推理机制，有效地解决了统一多模态模型在复杂合成任务中的推理瓶颈，并在多项推理密集型任务上展现出卓越的性能。

Abstract: Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.

</details>


### [377] [Spot-Wise Smart Parking: An Edge-Enabled Architecture with YOLOv11 and Digital Twin Integration](https://arxiv.org/abs/2602.01754)
*Gustavo P. C. P. da Luz,Alvaro M. Aspilcueta Narvaez,Tiago Godoi Bannwart,Gabriel Massuyoshi Sato,Luis Fernando Gomez Gonzalez,Juliana Freitag Borin*

Main category: cs.CV

TL;DR: 本研究提出了一种改进的智能停车系统，通过基于距离感知的匹配方法和自适应边界框划分，实现了停车位级别的监测，并引入了数字影子和基于电视盒的应用支持服务器，在提高准确性的同时，也考虑了可持续性。


<details>
  <summary>Details</summary>
Motivation: 现有智能停车系统无法提供停车位级别的洞察，限制了更高级应用的实现。研究旨在克服这一限制，提供更精细的停车信息，并推动智能城市的建设。

Method: 采用基于距离感知的匹配方法和空间容差，并结合自适应边界框划分方法进行停车位级别的监测。利用YOLOv11m模型进行推断，并开发了数字影子（Digital Shadow）和基于电视盒的应用支持服务器。

Result: 该方法实现了98.80%的平衡准确率，在资源受限的边缘设备上推理时间为8秒，YOLOv11m模型大小为40.5 MB。数字影子实现了停车位实体的可视化，应用支持服务器实现了云服务、停车指示牌和提供详细占用统计的机器人之间的可扩展通信。

Conclusion: 研究成功地扩展了智能停车系统的能力，实现了停车位级别的监测，提高了准确性和效率，并引入了数字影子和可持续的硬件重用方案，为未来向完整的数字孪生（Digital Twin）发展奠定了基础。

Abstract: Smart parking systems help reduce congestion and minimize users' search time, thereby contributing to smart city adoption and enhancing urban mobility. In previous works, we presented a system developed on a university campus to monitor parking availability by estimating the number of free spaces from vehicle counts within a region of interest. Although this approach achieved good accuracy, it restricted the system's ability to provide spot-level insights and support more advanced applications. To overcome this limitation, we extend the system with a spot-wise monitoring strategy based on a distance-aware matching method with spatial tolerance, enhanced through an Adaptive Bounding Box Partitioning method for challenging spaces. The proposed approach achieves a balanced accuracy of 98.80% while maintaining an inference time of 8 seconds on a resource-constrained edge device, enhancing the capabilities of YOLOv11m, a model that has a size of 40.5 MB. In addition, two new components were introduced: (i) a Digital Shadow that visually represents parking lot entities as a base to evolve to a full Digital Twin, and (ii) an application support server based on a repurposed TV box. The latter not only enables scalable communication among cloud services, the parking totem, and a bot that provides detailed spot occupancy statistics, but also promotes hardware reuse as a step towards greater sustainability.

</details>


### [378] [Multi-head automated segmentation by incorporating detection head into the contextual layer neural network](https://arxiv.org/abs/2602.02471)
*Edwin Kys,Febian Febian*

Main category: cs.CV

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level structure detection via a multi-layer perceptron and pixel-level segmentation through a context-enhanced stream. Detection outputs gate the segmentation predictions to suppress false positives in anatomically invalid slices, and training uses slice-wise Tversky loss to address class imbalance. Experiments on the Prostate-Anatomical-Edge-Cases dataset from The Cancer Imaging Archive demonstrate that the gated model substantially outperforms a non-gated segmentation-only baseline, achieving a mean Dice loss of $0.013 \pm 0.036$ versus $0.732 \pm 0.314$, with detection probabilities strongly correlated with anatomical presence, effectively eliminating spurious segmentations. In contrast, the non-gated model exhibited higher variability and persistent false positives across all slices. These results indicate that detection-based gating enhances robustness and anatomical plausibility in automated segmentation applications, reducing hallucinated predictions without compromising segmentation quality in valid slices, and offers a promising approach for improving the reliability of clinical radiotherapy auto-contouring workflows.

</details>


### [379] [Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation](https://arxiv.org/abs/2602.01756)
*Jun He,Junyan Ye,Zilong Huang,Dongzhi Jiang,Chenjue Zhang,Leqi Zhu,Renrui Zhang,Xiang Zhang,Weijia Li*

Main category: cs.CV

TL;DR: 提出了一种名为Mind-Brush的统一代理框架，将文本到图像生成转化为动态、知识驱动的工作流程，通过模拟“思考-研究-创建”范式，主动检索多模态证据和利用推理工具来处理复杂知识和现实世界的动态变化。同时，提出Mind-Bench基准来评估其在处理实时新闻、新兴概念以及数学和地理推理等任务上的能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型多为静态解码器，难以理解隐式用户意图；统一理解-生成模型虽然有所改进，但在复杂知识推理和适应现实世界动态变化方面仍有不足。

Method: 提出Mind-Brush框架，模拟“思考-研究-创建”流程，主动检索多模态证据以处理分布外概念，并利用推理工具解决隐式视觉约束。同时，构建Mind-Bench基准来评估该框架。

Result: Mind-Brush显著增强了统一模型的能力，在Mind-Bench基准上实现了Qwen-Image基线模型的从零到一的能力飞跃，并在WISE和RISE等既有基准上也取得了优越结果。

Conclusion: Mind-Brush是一个强大的统一代理框架，能够通过动态、知识驱动的工作流程提升文本到图像生成的能力，尤其是在处理复杂推理和适应现实世界变化方面，为未来的研究提供了新的方向。

Abstract: While text-to-image generation has achieved unprecedented fidelity, the vast majority of existing models function fundamentally as static text-to-pixel decoders. Consequently, they often fail to grasp implicit user intentions. Although emerging unified understanding-generation models have improved intent comprehension, they still struggle to accomplish tasks involving complex knowledge reasoning within a single model. Moreover, constrained by static internal priors, these models remain unable to adapt to the evolving dynamics of the real world. To bridge these gaps, we introduce Mind-Brush, a unified agentic framework that transforms generation into a dynamic, knowledge-driven workflow. Simulating a human-like 'think-research-create' paradigm, Mind-Brush actively retrieves multimodal evidence to ground out-of-distribution concepts and employs reasoning tools to resolve implicit visual constraints. To rigorously evaluate these capabilities, we propose Mind-Bench, a comprehensive benchmark comprising 500 distinct samples spanning real-time news, emerging concepts, and domains such as mathematical and Geo-Reasoning. Extensive experiments demonstrate that Mind-Brush significantly enhances the capabilities of unified models, realizing a zero-to-one capability leap for the Qwen-Image baseline on Mind-Bench, while achieving superior results on established benchmarks like WISE and RISE.

</details>


### [380] [PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss](https://arxiv.org/abs/2602.02493)
*Zehong Ma,Ruihan Xu,Shiliang Zhang*

Main category: cs.CV

TL;DR: PixelGen 是一种像素扩散框架，通过引入 LPIPS 和 DINO 感知损失，成功克服了现有像素扩散模型在感知质量上的不足，并在 ImageNet-256 数据集上取得了优于强基线模型的 FID 分数，同时在文本到图像生成任务中展现出良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的像素扩散模型在优化高维像素流形时面临挑战，其感知质量通常落后于潜空间扩散模型。研究动机在于开发一种更简单但更强大的像素扩散方法，以媲美甚至超越潜空间扩散模型。

Method: PixelGen 提出了一种包含两个互补感知损失的像素扩散框架：LPIPS 损失用于学习局部模式，基于 DINO 的感知损失用于增强全局语义。这种方法旨在引导扩散模型学习更有意义的感知流形，而非全部图像流形。

Result: PixelGen 在 ImageNet-256 数据集上取得了 5.11 的 FID 分数，并且在不使用分类器指导的情况下，仅用 80 个训练周期。在大型文本到图像生成任务中，其 GenEval 分数达到了 0.79，显示出良好的可扩展性。

Conclusion: PixelGen 提供了一种无需 VAE、无需潜空间表示、无需辅助阶段的简单而强大的生成范式，通过引入感知损失显著提高了像素扩散模型的性能，使其在图像生成任务上优于现有强基线模型。

Abstract: Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.

</details>


### [381] [GDPR-Compliant Person Recognition in Industrial Environments Using MEMS-LiDAR and Hybrid Data](https://arxiv.org/abs/2602.01764)
*Dennis Basile,Dennis Sprute,Helene Dörksen,Holger Flatt*

Main category: cs.CV

TL;DR: 本研究提出了一种基于MEMS-LiDAR的隐私合规的工业室内非授权人员检测方法，通过结合真实和合成LiDAR数据，提高了检测精度并减少了标注工作量，同时符合GDPR。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的视觉检测方法存在对光照和可见性敏感、侵犯隐私（如GDPR）以及需要耗时标注数据的缺点。因此，需要一种隐私合规、高效且准确的工业室内人员检测方法。

Method: 该研究采用了MEMS-LiDAR传感器，捕获匿名化的3D点云数据，避免了个人身份信息。为了克服真实LiDAR数据采集和标注的耗时性，研究人员利用CARLA模拟框架生成了合成LiDAR数据，并将其与真实数据结合进行模型训练。

Result: 实验结果表明，结合真实和合成数据的混合模型比仅使用真实数据的模型平均精度提高了44个百分点，同时将手动标注工作量减少了50%。

Conclusion: 所提出的基于MEMS-LiDAR和混合数据训练的方法，提供了一种可扩展、成本效益高且符合GDPR的工业室内人员检测解决方案，有效解决了传统方法的局限性。

Abstract: The reliable detection of unauthorized individuals in safety-critical industrial indoor spaces is crucial to avoid plant shutdowns, property damage, and personal hazards. Conventional vision-based methods that use deep-learning approaches for person recognition provide image information but are sensitive to lighting and visibility conditions and often violate privacy regulations, such as the General Data Protection Regulation (GDPR) in the European Union. Typically, detection systems based on deep learning require annotated data for training. Collecting and annotating such data, however, is highly time-consuming and due to manual treatments not necessarily error free. Therefore, this paper presents a privacy-compliant approach based on Micro-Electro-Mechanical Systems LiDAR (MEMS-LiDAR), which exclusively captures anonymized 3D point clouds and avoids personal identification features. To compensate for the large amount of time required to record real LiDAR data and for post-processing and annotation, real recordings are augmented with synthetically generated scenes from the CARLA simulation framework. The results demonstrate that the hybrid data improves the average precision by 44 percentage points compared to a model trained exclusively with real data while reducing the manual annotation effort by 50 %. Thus, the proposed approach provides a scalable, cost-efficient alternative to purely real-data-based methods and systematically shows how synthetic LiDAR data can combine high performance in person detection with GDPR compliance in an industrial environment.

</details>


### [382] [MagicFuse: Single Image Fusion for Visual and Semantic Reinforcement](https://arxiv.org/abs/2602.01760)
*Hao Zhang,Yanping Zha,Zizhuo Li,Meiqi Gong,Jiayi Ma*

Main category: cs.CV

TL;DR: 提出了一种名为MagicFuse的单图像多模态融合框架，仅利用单张低质量可见光图像，通过知识层面的融合，生成跨光谱场景表示，并在视觉和语义上超越了传统多模态融合方法。


<details>
  <summary>Details</summary>
Motivation: 如何在仅有可见光成像传感器且条件恶劣的情况下，仍能受益于多模态图像融合的优势。

Method: 提出了一种基于扩散模型的单图像融合框架MagicFuse，包含：1. 谱内知识增强分支，挖掘可见光图像中的隐藏信息；2. 跨谱知识生成分支，学习红外光谱的热辐射分布模式；3. 多域知识融合分支，整合两个分支的概率噪声，通过采样生成跨光谱场景表示；4. 引入视觉和语义约束，确保表示的可用性。

Result: MagicFuse在仅使用单张降质可见光图像的情况下，实现了与多模态输入状态艺术融合方法相当甚至更优的视觉和语义表示性能。

Conclusion: MagicFuse成功地将单图像融合扩展到知识层面，克服了仅使用可见光图像的限制，并在恶劣条件下实现了高效的多模态融合效果。

Abstract: This paper focuses on a highly practical scenario: how to continue benefiting from the advantages of multi-modal image fusion under harsh conditions when only visible imaging sensors are available. To achieve this goal, we propose a novel concept of single-image fusion, which extends conventional data-level fusion to the knowledge level. Specifically, we develop MagicFuse, a novel single image fusion framework capable of deriving a comprehensive cross-spectral scene representation from a single low-quality visible image. MagicFuse first introduces an intra-spectral knowledge reinforcement branch and a cross-spectral knowledge generation branch based on the diffusion models. They mine scene information obscured in the visible spectrum and learn thermal radiation distribution patterns transferred to the infrared spectrum, respectively. Building on them, we design a multi-domain knowledge fusion branch that integrates the probabilistic noise from the diffusion streams of these two branches, from which a cross-spectral scene representation can be obtained through successive sampling. Then, we impose both visual and semantic constraints to ensure that this scene representation can satisfy human observation while supporting downstream semantic decision-making. Extensive experiments show that our MagicFuse achieves visual and semantic representation performance comparable to or even better than state-of-the-art fusion methods with multi-modal inputs, despite relying solely on a single degraded visible image.

</details>


### [383] [FlowBypass: Rectified Flow Trajectory Bypass for Training-Free Image Editing](https://arxiv.org/abs/2602.01805)
*Menglin Han,Zhangkai Ni*

Main category: cs.CV

TL;DR: 提出了一种名为FlowBypass的新型无训练图像编辑框架，它通过直接连接逆转和重建轨迹来解决现有方法的误差累积问题，无需进行基于特征的操作，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有无训练图像编辑方法依赖于逆转-重建轨迹，存在误差累积与保真度下降的权衡；或者依赖于特定骨干网络的特征操作，缺乏通用性。

Method: 提出FlowBypass框架，基于Rectified Flow，通过分析逆转和重建轨迹，构建一条直接连接这两者的“旁路”，从而缓解误差累积，且无需进行特征操作。

Result: FlowBypass在图像编辑任务上取得了优于现有最先进方法的性能，实现了更强的提示对齐，同时保持了无关区域的高保真度细节。

Conclusion: FlowBypass是一个新颖且通用的无训练图像编辑框架，通过直接连接逆转和重建轨迹，有效解决了现有方法的局限性，并在实验中得到了验证。

Abstract: Training-free image editing has attracted increasing attention for its efficiency and independence from training data. However, existing approaches predominantly rely on inversion-reconstruction trajectories, which impose an inherent trade-off: longer trajectories accumulate errors and compromise fidelity, while shorter ones fail to ensure sufficient alignment with the edit prompt. Previous attempts to address this issue typically employ backbone-specific feature manipulations, limiting general applicability. To address these challenges, we propose FlowBypass, a novel and analytical framework grounded in Rectified Flow that constructs a bypass directly connecting inversion and reconstruction trajectories, thereby mitigating error accumulation without relying on feature manipulations. We provide a formal derivation of two trajectories, from which we obtain an approximate bypass formulation and its numerical solution, enabling seamless trajectory transitions. Extensive experiments demonstrate that FlowBypass consistently outperforms state-of-the-art image editing methods, achieving stronger prompt alignment while preserving high-fidelity details in irrelevant regions.

</details>


### [384] [GPD: Guided Progressive Distillation for Fast and High-Quality Video Generation](https://arxiv.org/abs/2602.01814)
*Xiao Liang,Yunzhu Zhang,Linchao Zhu*

Main category: cs.CV

TL;DR: 提出了一种名为GPD（Guided Progressive Distillation）的框架，通过引导式渐进蒸馏加速视频生成中的扩散过程，使用更少的采样步数（从48降至6）也能保持高质量的视频生成，优于现有蒸馏方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成扩散模型的计算成本高，采样步数多，导致生成速度慢且质量下降。

Method: 提出GPD框架，包含在线生成的训练目标和潜在空间中的频域约束，以训练一个学生模型，使其能够以更大的步长进行扩散，并由教师模型进行引导。

Result: 将GPD应用于Wan2.1模型，采样步数从48减少到6，同时在VBench上保持了具有竞争力的视觉质量，并且在管道简单性和质量保持方面优于现有蒸馏方法。

Conclusion: GPD框架能够显著加速视频生成过程，在保证高质量的同时大大减少了采样步数，并且在效率和效果上优于现有方法。

Abstract: Diffusion models have achieved remarkable success in video generation; however, the high computational cost of the denoising process remains a major bottleneck. Existing approaches have shown promise in reducing the number of diffusion steps, but they often suffer from significant quality degradation when applied to video generation. We propose Guided Progressive Distillation (GPD), a framework that accelerates the diffusion process for fast and high-quality video generation. GPD introduces a novel training strategy in which a teacher model progressively guides a student model to operate with larger step sizes. The framework consists of two key components: (1) an online-generated training target that reduces optimization difficulty while improving computational efficiency, and (2) frequency-domain constraints in the latent space that promote the preservation of fine-grained details and temporal dynamics. Applied to the Wan2.1 model, GPD reduces the number of sampling steps from 48 to 6 while maintaining competitive visual quality on VBench. Compared with existing distillation methods, GPD demonstrates clear advantages in both pipeline simplicity and quality preservation.

</details>


### [385] [Spatio-Temporal Transformers for Long-Term NDVI Forecasting](https://arxiv.org/abs/2602.01799)
*Ido Faran,Nathan S. Netanyahu,Maxim Shoshany*

Main category: cs.CV

TL;DR: 本文提出了一种名为STT-LTF（Spatio-Temporal Transformer for Long Term Forecasting）的新型框架，利用Transformer架构结合时空信息，能够长期预测卫星图像时间序列，特别适用于地中海地区复杂多变的景观。


<details>
  <summary>Details</summary>
Motivation: 地中海地区由于其复杂的空间格局、季节性变化以及长期的环境演变，使得长时序卫星图像分析面临巨大挑战。现有方法主要关注时间序列分析，忽略了空间上下文的重要性。

Method: STT-LTF框架采用统一的Transformer架构，同时处理多尺度空间块和长时序数据（最长20年）。通过空间掩码、时间掩码和预测时间采样策略进行全面的自监督学习，利用40年的Landsat无标签影像进行训练。该模型整合了空间块嵌入、周期性时间编码和地理坐标，以学习异质生态系统间的复杂依赖关系。

Result: 在1984-2024年Landsat数据上进行实验，STT-LTF在预测下一年的结果中，平均绝对误差（MAE）为0.0328，R^2为0.8412，优于传统统计方法、CNN、LSTM和标准Transformer。

Conclusion: STT-LTF能够有效集成时空信息进行长期预测，克服了传统方法的局限性，特别适用于处理异质景观和快速生态转变的研究。该框架还能处理不规则的时间采样和可变的预测未来时间点。

Abstract: Long-term satellite image time series (SITS) analysis in heterogeneous landscapes faces significant challenges, particularly in Mediterranean regions where complex spatial patterns, seasonal variations, and multi-decade environmental changes interact across different scales. This paper presents the Spatio-Temporal Transformer for Long Term Forecasting (STT-LTF ), an extended framework that advances beyond purely temporal analysis to integrate spatial context modeling with temporal sequence prediction. STT-LTF processes multi-scale spatial patches alongside temporal sequences (up to 20 years) through a unified transformer architecture, capturing both local neighborhood relationships and regional climate influences. The framework employs comprehensive self-supervised learning with spatial masking, temporal masking, and horizon sampling strategies, enabling robust model training from 40 years of unlabeled Landsat imagery. Unlike autoregressive approaches, STT-LTF directly predicts arbitrary future time points without error accumulation, incorporating spatial patch embeddings, cyclical temporal encoding, and geographic coordinates to learn complex dependencies across heterogeneous Mediterranean ecosystems. Experimental evaluation on Landsat data (1984-2024) demonstrates that STT-LTF achieves a Mean Absolute Error (MAE) of 0.0328 and R^2 of 0.8412 for next-year predictions, outperforming traditional statistical methods, CNN-based approaches, LSTM networks, and standard transformers. The framework's ability to handle irregular temporal sampling and variable prediction horizons makes it particularly suitable for analysis of heterogeneous landscapes experiencing rapid ecological transitions.

</details>


### [386] [LDRNet: Large Deformation Registration Model for Chest CT Registration](https://arxiv.org/abs/2602.01812)
*Cheng Wang,Qiyu Gao,Fandong Zhang,Shu Zhang,Yizhou Yu*

Main category: cs.CV

TL;DR: 提出了一种名为LDRNet的快速无监督深度学习方法，用于解决胸部CT图像的大变形配准问题，该方法通过多分辨率精炼块和刚性变换块来提高配准精度和速度。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习医学图像配准算法多集中于脑部，而胸部CT配准面临更大形变、更复杂背景和区域重叠等挑战，因此需要专门针对胸部CT的大变形配准方法。

Method: LDRNet采用多分辨率精炼策略，首先预测粗分辨率配准场，然后逐步精炼。包含两个创新组件：1）用于在不同分辨率下精炼配准场的精炼块（refine block）；2）用于从高层特征学习变换矩阵的刚性块（rigid block）。

Result: 在私有数据集和SegTHOR公开数据集上进行了训练和评估，并与传统方法和VoxelMorph, RCN, LapIRN等深度学习模型进行了比较。结果表明，LDRNet在处理大变形图像配准方面达到了最先进的性能，并且速度更快。

Conclusion: LDRNet是一种有效的、快速的无监督深度学习方法，能够成功地处理胸部CT图像的大变形配准问题，并在精度和速度上优于现有方法。

Abstract: Most of the deep learning based medical image registration algorithms focus on brain image registration tasks.Compared with brain registration, the chest CT registration has larger deformation, more complex background and region over-lap. In this paper, we propose a fast unsupervised deep learning method, LDRNet, for large deformation image registration of chest CT images. We first predict a coarse resolution registration field, then refine it from coarse to fine. We propose two innovative technical components: 1) a refine block that is used to refine the registration field in different resolutions, 2) a rigid block that is used to learn transformation matrix from high-level features. We train and evaluate our model on the private dataset and public dataset SegTHOR. We compare our performance with state-of-the-art traditional registration methods as well as deep learning registration models VoxelMorph, RCN, and LapIRN. The results demonstrate that our model achieves state-of-the-art performance for large deformation images registration and is much faster.

</details>


### [387] [Automated Discontinuity Set Characterisation in Enclosed Rock Face Point Clouds Using Single-Shot Filtering and Cyclic Orientation Transformation](https://arxiv.org/abs/2602.01783)
*Dibyayan Patra,Pasindu Ranasinghe,Bikram Banerjee,Simit Raval*

Main category: cs.CV

TL;DR: 提出了一种用于地下矿洞岩面结构不连续性集合自动表征的新方法，该方法结合了单次滤波、循环定向变换和层次聚类技术，并在真实矿井数据上验证了其准确性和优越性。


<details>
  <summary>Details</summary>
Motivation: 在地下矿洞中，岩面结构不连续性集合的表征对于评估岩体稳定性、开挖安全和运营效率至关重要。虽然无人机和移动激光扫描技术可以高效采集点云，但在全封闭岩面等真实场景下，开发鲁棒高效的自动表征方法仍然是一个开放的研究问题。

Method: 提出了一种新的自动表征方法，包括：1) 单次滤波策略，用于在一次性处理中隔离平面区域并抑制噪声和高曲率伪影；2) 创新的循环定向变换方案，用于解决笛卡尔坐标系在极坐标定向数据上的聚类局限性，实现倾角和倾向的精确表示；3) 层次聚类技术，用于将变换后的定向数据聚类成集合，该技术能处理不同密度分布并识别聚类，无需用户预定义集合数量。

Result: 所提出的方法在真实矿井巷道数据上进行了验证，并与手动识别的真实数据以及其他常用的自动结构映射技术进行了比较。结果表明，该方法在估计不连续性集合定向方面表现最佳，平均绝对误差分别为倾角1.95°和倾向2.20°，离散度误差低于3°。

Conclusion: 该研究提出了一种创新的自动不连续性集合表征方法，该方法通过有效的滤波、定向变换和聚类技术，能够准确高效地处理真实地下矿洞岩面的点云数据，并在准确性上优于现有技术。

Abstract: Characterisation of structural discontinuity sets in exposed rock faces of underground mine cavities is essential for assessing rock-mass stability, excavation safety, and operational efficiency. UAV and other mobile laser-scanning techniques provide efficient means of collecting point clouds from rock faces. However, the development of a robust and efficient approach for automatic characterisation of discontinuity sets in real-world scenarios, like fully enclosed rock faces in cavities, remains an open research problem. In this study, a new approach is proposed for automatic discontinuity set characterisation that uses a single-shot filtering strategy, an innovative cyclic orientation transformation scheme and a hierarchical clustering technique. The single-shot filtering step isolates planar regions while robustly suppressing noise and high-curvature artefacts in one pass using a signal-processing technique. To address the limitations of Cartesian clustering on polar orientation data, a cyclic orientation transformation scheme is developed, enabling accurate representation of dip angle and dip direction in Cartesian space. The transformed orientations are then characterised into sets using a hierarchical clustering technique, which handles varying density distributions and identifies clusters without requiring user-defined set numbers. The accuracy of the method is validated on real-world mine stope and against ground truth obtained using manually handpicked discontinuity planes identified with the Virtual Compass tool, as well as widely used automated structure mapping techniques. The proposed approach outperforms the other techniques by exhibiting the lowest mean absolute error in estimating discontinuity set orientations in real-world stope data with errors of 1.95° and 2.20° in nominal dip angle and dip direction, respectively, and dispersion errors lying below 3°.

</details>


### [388] [Seeing Is Believing? A Benchmark for Multimodal Large Language Models on Visual Illusions and Anomalies](https://arxiv.org/abs/2602.01816)
*Wenjin Hou,Wei Liu,Han Hu,Xiaoxiao Sun,Serena Yeung-Levy,Hehe Fan*

Main category: cs.CV

TL;DR: 本研究提出了VIA-Bench，一个包含视觉错觉和异常的基准测试，旨在评估多模态大语言模型（MLLM）在非常规场景下的鲁棒性。研究发现，现有MLLMs在面对这些挑战时存在显著的脆弱性，即使采用链式思考（CoT）推理也无法有效提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有对MLLMs的评估主要基于标准分布内数据，未能充分考察其在违背常识先验场景下的鲁棒性。因此，需要一个专门的基准来探测模型在视觉错觉和异常情况下的表现。

Method: 构建了一个包含六个类别的基准测试VIA-Bench，包括颜色错觉、运动错觉、格式塔错觉、几何与空间错觉、一般视觉错觉和视觉异常。通过人工审核，创建了超过1000个需要细致视觉推理的问题-答案对。对超过20个最先进的MLLMs进行了评估。

Result: 研究发现，现有MLLMs在VIA-Bench上面临显著的脆弱性。链式思考（CoT）推理在提升鲁棒性方面效果微乎其微，甚至会出现“脆弱的海市蜃楼”现象，即模型在错觉刺激下逻辑会崩溃。

Conclusion: MLLMs在处理视觉错觉和异常方面存在显著的局限性，与人类感知存在根本性差异。解决这些感知瓶颈对于实现通用人工智能至关重要。研究将公开基准数据和代码。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable proficiency on general-purpose vision-language benchmarks, reaching or even exceeding human-level performance. However, these evaluations typically rely on standard in-distribution data, leaving the robustness of MLLMs largely unexamined when faced with scenarios that defy common-sense priors. To address this gap, we introduce VIA-Bench, a challenging benchmark designed to probe model performance on visual illusions and anomalies. It includes six core categories: color illusions, motion illusions, gestalt illusions, geometric and spatial illusions, general visual illusions, and visual anomalies. Through careful human-in-the-loop review, we construct over 1K high-quality question-answer pairs that require nuanced visual reasoning. Extensive evaluation of over 20 state-of-the-art MLLMs, including proprietary, open-source, and reasoning-enhanced models, uncovers significant vulnerabilities. Notably, we find that Chain-of-Thought (CoT) reasoning offers negligible robustness, often yielding ``brittle mirages'' where the model's logic collapses under illusory stimuli. Our findings reveal a fundamental divergence between machine and human perception, suggesting that resolving such perceptual bottlenecks is critical for the advancement of artificial general intelligence. The benchmark data and code will be released.

</details>


### [389] [Efficient Cross-Country Data Acquisition Strategy for ADAS via Street-View Imagery](https://arxiv.org/abs/2602.01836)
*Yin Wu,Daniel Slieter,Carl Esselborn,Ahmed Abouelazm,Tsung Yuan Tseng,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 提出了一种利用街景图像指导数据采集的策略，用于自动驾驶系统（ADAS/ADS）的跨国部署。该策略通过识别兴趣点（POI）来高效收集代表性数据，并在交通标志检测任务上证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在不同国家部署ADAS/ADS系统面临立法、交通基础设施和视觉惯例差异带来的域偏移问题，影响感知性能。传统的跨国数据收集成本高昂且效率低下。

Method: 提出了一种街景图像指导的数据采集策略，利用公开街景图像识别兴趣点（POI）。采用了两种POI评分方法：基于KNN的特征距离方法（使用视觉基础模型）和视觉归因方法（使用视觉语言模型）。通过Collect-Detect协议构建了一个配对数据集（Zenseact Open Dataset和Mapillary街景图像），并进行了交通标志检测实验。

Result: 在交通标志检测任务中，该方法使用一半的目标领域数据即可达到与随机采样相当的性能。大规模街景图像处理在经济上是可行的。

Conclusion: 街景图像指导的数据采集策略能够实现高效且经济的跨国模型适应，为ADAS/ADS的跨国部署提供了有效的解决方案。

Abstract: Deploying ADAS and ADS across countries remains challenging due to differences in legislation, traffic infrastructure, and visual conventions, which introduce domain shifts that degrade perception performance. Traditional cross-country data collection relies on extensive on-road driving, making it costly and inefficient to identify representative locations. To address this, we propose a street-view-guided data acquisition strategy that leverages publicly available imagery to identify places of interest (POI). Two POI scoring methods are introduced: a KNN-based feature distance approach using a vision foundation model, and a visual-attribution approach using a vision-language model. To enable repeatable evaluation, we adopt a collect-detect protocol and construct a co-located dataset by pairing the Zenseact Open Dataset with Mapillary street-view images. Experiments on traffic sign detection, a task particularly sensitive to cross-country variations in sign appearance, show that our approach achieves performance comparable to random sampling while using only half of the target-domain data. We further provide cost estimations for full-country analysis, demonstrating that large-scale street-view processing remains economically feasible. These results highlight the potential of street-view-guided data acquisition for efficient and cost-effective cross-country model adaptation.

</details>


### [390] [SPIRIT: Adapting Vision Foundation Models for Unified Single- and Multi-Frame Infrared Small Target Detection](https://arxiv.org/abs/2602.01843)
*Qian Xu,Xi Li,Fei Gao,Jie Guo,Haojuan Yuan,Shuaipeng Fan,Mingjin Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为SPIRIT的统一红外小目标检测框架，通过轻量级的物理信息插件来适配视觉基础模型（VFMs），解决了红外数据稀缺和模态差异带来的挑战，实现了单帧和多帧推理的统一，并在多个基准测试中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测（IRSTD）在监控和预警中至关重要，但存在红外数据稀缺、目标信号弱、语义线索少等问题，直接使用面向语义的VFMs和基于外观的跨帧关联不可靠。现有方法可能导致特征聚合淹没目标峰值，外观记忆注意力模糊。因此，需要一种能克服这些挑战的、统一的、兼容VFMs的框架。

Method: SPIRIT框架通过引入轻量级的物理信息插件来适配VFMs。空间上，PIFR插件通过近似秩稀疏分解来抑制背景噪声并增强目标信号。时间上，PGMA插件将历史信息转化为软空间先验，注入到记忆交叉注意力中，以约束跨帧关联，从而实现鲁棒的视频检测，并在无时间上下文时自然回退到单帧推理。

Result: 在多个IRSTD基准测试中，SPIRIT框架相比于基于VFM的基线模型取得了持续的性能提升，并达到了SOTA（State-of-the-Art）性能。

Conclusion: SPIRIT是一个统一的、VFM兼容的框架，能够有效地解决红外小目标检测中的数据稀缺和模态差异问题。通过物理信息插件，该框架能够增强目标信号，抑制背景噪声，并实现鲁棒的单帧和多帧检测，为IRSTD提供了新的解决方案。

Abstract: Infrared small target detection (IRSTD) is crucial for surveillance and early-warning, with deployments spanning both single-frame analysis and video-mode tracking. A practical solution should leverage vision foundation models (VFMs) to mitigate infrared data scarcity, while adopting a memory-attention-based temporal propagation framework that unifies single- and multi-frame inference. However, infrared small targets exhibit weak radiometric signals and limited semantic cues, which differ markedly from visible-spectrum imagery. This modality gap makes direct use of semantics-oriented VFMs and appearance-driven cross-frame association unreliable for IRSTD: hierarchical feature aggregation can submerge localized target peaks, and appearance-only memory attention becomes ambiguous, leading to spurious clutter associations. To address these challenges, we propose SPIRIT, a unified and VFM-compatible framework that adapts VFMs to IRSTD via lightweight physics-informed plug-ins. Spatially, PIFR refines features by approximating rank-sparsity decomposition to suppress structured background components and enhance sparse target-like signals. Temporally, PGMA injects history-derived soft spatial priors into memory cross-attention to constrain cross-frame association, enabling robust video detection while naturally reverting to single-frame inference when temporal context is absent. Experiments on multiple IRSTD benchmarks show consistent gains over VFM-based baselines and SOTA performance.

</details>


### [391] [How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing](https://arxiv.org/abs/2602.01851)
*Huanyu Zhang,Xuehai Bai,Chengzu Li,Chen Liang,Haochen Tian,Haodong Li,Ruichuan An,Yifan Zhang,Anna Korhonen,Zhang Zhang,Liang Wang,Tieniu Tan*

Main category: cs.CV

TL;DR: 该论文提出了VIBE，一个用于图像编辑的视觉指令基准，包含三层交互层级，并开发了一个LMM-as-a-judge评估框架。研究发现，专有模型在早期视觉指令遵循方面优于开源模型，但所有模型在处理更复杂的指令时性能都会显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑模型主要依赖文本指令，而人类交流通常包含视觉指令（如草图），能够更有效地传达空间和结构意图。研究旨在弥合这一差距，并为视觉指令图像编辑提供一个更全面的评估基准。

Method: 提出了VIBE（Visual Instruction Benchmark for Image Editing）基准，包含一个三层交互层级（指代定位、形态操控、因果推理）和高质量、多样化的测试案例。同时，开发了一个基于大型多模态模型（LMM）作为裁判的评估框架，并结合任务特定指标进行评估。

Result: 通过对17个开源和专有图像编辑模型的评估，发现专有模型展现出一定的早期视觉指令遵循能力，且性能普遍优于开源模型。然而，随着任务难度的增加，即使是表现最好的系统，性能也会显著下降。

Conclusion: 视觉指令图像编辑是一个充满潜力的研究领域，尽管现有模型（尤其是专有模型）在处理简单视觉指令方面取得了一定进展，但要实现复杂视觉指令的鲁棒遵循仍面临巨大挑战，这为未来的研究指明了方向。

Abstract: Recent generative models have achieved remarkable progress in image editing. However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with a three-level interaction hierarchy that captures deictic grounding, morphological manipulation, and causal reasoning. Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following. We further propose a robust LMM-as-a-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through a comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform open-source models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research.

</details>


### [392] [WS-IMUBench: Can Weakly Supervised Methods from Audio, Image, and Video Be Adapted for IMU-based Temporal Action Localization?](https://arxiv.org/abs/2602.01850)
*Pei Li,Jiaxi Yin,Lei Ouyang,Shihan Pan,Ge Wang,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: 本研究提出了一个名为WS-IMUBench的基准研究，用于评估在仅有序列级别标签的弱监督条件下的人体活动时序定位（IMU-TAL）方法。研究人员评估了七种从音频、图像和视频领域迁移过来的弱监督方法在IMU-TAL上的表现，并提出了未来研究的方向。


<details>
  <summary>Details</summary>
Motivation: 现有基于IMU的人体活动识别（HAR）主要采用片段分类范式，无法捕捉真实世界行为丰富的时序结构。因此，研究者们希望转向IMU时序动作定位（IMU-TAL），但现有方法需要耗费大量人力和时间进行密集的帧级边界标注，难以扩展。为了解决这个问题，本研究专注于弱监督IMU-TAL，仅使用序列级别标签。

Method: 本研究并未提出新的定位算法，而是通过WS-IMUBench基准研究，评估了七种来自音频、图像和视频领域的成熟的弱监督定位范式在IMU-TAL任务上的迁移能力。研究在七个公开的IMU数据集上进行了广泛的实验，包括超过3540次模型训练和7080次推理评估，并围绕迁移性、有效性和洞察力这三个研究问题进行了分析。

Result: 研究结果表明：(i) 迁移性取决于模态，时序域方法比基于图像派生的建议（proposal-based）的方法更稳定；(ii) 在有利的数据集（例如，动作时间长、传感维度高）上，弱监督方法具有竞争力；(iii) 主要的失败模式源于短动作、时序模糊性和建议质量不高。

Conclusion: 本研究通过WS-IMUBench建立了系统性的基准，为弱监督IMU-TAL领域的研究提供了一个可复现的模板、数据集、协议和分析。研究结果揭示了弱监督IMU-TAL的优势与挑战，并指明了未来的研究方向，包括IMU特有的建议生成、边界感知目标函数以及更强的时序推理能力，以期加速社区在该领域的研究进展。

Abstract: IMU-based Human Activity Recognition (HAR) has enabled a wide range of ubiquitous computing applications, yet its dominant clip classification paradigm cannot capture the rich temporal structure of real-world behaviors. This motivates a shift toward IMU Temporal Action Localization (IMU-TAL), which predicts both action categories and their start/end times in continuous streams. However, current progress is strongly bottlenecked by the need for dense, frame-level boundary annotations, which are costly and difficult to scale. To address this bottleneck, we introduce WS-IMUBench, a systematic benchmark study of weakly supervised IMU-TAL (WS-IMU-TAL) under only sequence-level labels. Rather than proposing a new localization algorithm, we evaluate how well established weakly supervised localization paradigms from audio, image, and video transfer to IMU-TAL under only sequence-level labels. We benchmark seven representative weakly supervised methods on seven public IMU datasets, resulting in over 3,540 model training runs and 7,080 inference evaluations. Guided by three research questions on transferability, effectiveness, and insights, our findings show that (i) transfer is modality-dependent, with temporal-domain methods generally more stable than image-derived proposal-based approaches; (ii) weak supervision can be competitive on favorable datasets (e.g., with longer actions and higher-dimensional sensing); and (iii) dominant failure modes arise from short actions, temporal ambiguity, and proposal quality. Finally, we outline concrete directions for advancing WS-IMU-TAL (e.g., IMU-specific proposal generation, boundary-aware objectives, and stronger temporal reasoning). Beyond individual results, WS-IMUBench establishes a reproducible benchmarking template, datasets, protocols, and analyses, to accelerate community-wide progress toward scalable WS-IMU-TAL.

</details>


### [393] [Trust but Verify: Adaptive Conditioning for Reference-Based Diffusion Super-Resolution via Implicit Reference Correlation Modeling](https://arxiv.org/abs/2602.01864)
*Yuan Wang,Yuhao Wan,Siming Zheng,Bo Li,Qibin Hou,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: 提出了一种名为 Ada-RefSR 的单步扩散模型，通过自适应隐式相关性门控（AICG）机制，在参考图像的可靠性高时利用其信息，在可靠性低时抑制其影响，以解决参考图像与低质量输入图像之间对应关系不可靠的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的参考图像超分辨率方法在处理真实世界降解导致的低质量输入与参考图像之间不可靠的对应关系时存在挑战，容易过度依赖误导性参考或低估有价值的线索。

Method: 提出 Ada-RefSR 框架，核心是自适应隐式相关性门控（AICG）机制。AICG 利用可学习的摘要 token 来提取参考图像的关键模式，并捕捉与低质量特征的隐式相关性。该机制被整合到注意力骨干网络中，实现对参考信息使用的轻量级自适应调节。

Result: Ada-RefSR 在保真度、自然度和效率之间取得了良好的平衡，并且在参考图像对齐程度不同时表现出鲁棒性。

Conclusion: Ada-RefSR 提供了一种有效的“信任但验证”的参考图像使用策略，通过 AICG 机制能够自适应地利用或抑制参考信息，从而在多种设置下实现高质量的参考图像超分辨率。

Abstract: Recent works have explored reference-based super-resolution (RefSR) to mitigate hallucinations in diffusion-based image restoration. A key challenge is that real-world degradations make correspondences between low-quality (LQ) inputs and reference (Ref) images unreliable, requiring adaptive control of reference usage. Existing methods either ignore LQ-Ref correlations or rely on brittle explicit matching, leading to over-reliance on misleading references or under-utilization of valuable cues. To address this, we propose Ada-RefSR, a single-step diffusion framework guided by a "Trust but Verify" principle: reference information is leveraged when reliable and suppressed otherwise. Its core component, Adaptive Implicit Correlation Gating (AICG), employs learnable summary tokens to distill dominant reference patterns and capture implicit correlations with LQ features. Integrated into the attention backbone, AICG provides lightweight, adaptive regulation of reference guidance, serving as a built-in safeguard against erroneous fusion. Experiments on multiple datasets demonstrate that Ada-RefSR achieves a strong balance of fidelity, naturalness, and efficiency, while remaining robust under varying reference alignment.

</details>


### [394] [ProxyImg: Towards Highly-Controllable Image Representation via Hierarchical Disentangled Proxy Embedding](https://arxiv.org/abs/2602.01881)
*Ye Chen,Yupeng Zhu,Xiongzhen Zhang,Zhewen Wan,Yingzhe Li,Wenjun Zhang,Bingbing Ni*

Main category: cs.CV

TL;DR: 提出了一种分层代理参数化图像表示方法，将图像分解为语义、几何和纹理属性，实现高效、可控的图像和视频编辑，并支持实时物理驱动动画。


<details>
  <summary>Details</summary>
Motivation: 现有图像表示方法（显式和隐式）存在表示冗余或缺乏潜在变量到语义实例/部分的直接映射，导致手动编辑困难和精细化操作受限。

Method: 基于输入图像的语义感知分解，构建分层代理几何（通过自适应贝塞尔拟合和迭代细分/网格化），并将多尺度隐式纹理参数嵌入到代理节点中，同时引入局部自适应特征索引机制以确保空间纹理一致性。

Result: 在图像重建和编辑任务上实现了最先进的渲染保真度，参数量显著减少，并实现了直观、交互式和物理上合理的操纵。通过与基于位置的动力学结合，实现了高质量的背景补全，并且支持实时物理驱动动画，在时间一致性和视觉真实性方面优于生成方法。

Conclusion: 所提出的分层代理参数化图像表示方法解决了现有方法的局限性，实现了高效、可控的图像编辑和高质量的物理驱动动画。

Abstract: Prevailing image representation methods, including explicit representations such as raster images and Gaussian primitives, as well as implicit representations such as latent images, either suffer from representation redundancy that leads to heavy manual editing effort, or lack a direct mapping from latent variables to semantic instances or parts, making fine-grained manipulation difficult. These limitations hinder efficient and controllable image and video editing. To address these issues, we propose a hierarchical proxy-based parametric image representation that disentangles semantic, geometric, and textural attributes into independent and manipulable parameter spaces. Based on a semantic-aware decomposition of the input image, our representation constructs hierarchical proxy geometries through adaptive Bezier fitting and iterative internal region subdivision and meshing. Multi-scale implicit texture parameters are embedded into the resulting geometry-aware distributed proxy nodes, enabling continuous high-fidelity reconstruction in the pixel domain and instance- or part-independent semantic editing. In addition, we introduce a locality-adaptive feature indexing mechanism to ensure spatial texture coherence, which further supports high-quality background completion without relying on generative models. Extensive experiments on image reconstruction and editing benchmarks, including ImageNet, OIR-Bench, and HumanEdit, demonstrate that our method achieves state-of-the-art rendering fidelity with significantly fewer parameters, while enabling intuitive, interactive, and physically plausible manipulation. Moreover, by integrating proxy nodes with Position-Based Dynamics, our framework supports real-time physics-driven animation using lightweight implicit rendering, achieving superior temporal consistency and visual realism compared with generative approaches.

</details>


### [395] [Fact or Fake? Assessing the Role of Deepfake Detectors in Multimodal Misinformation Detection](https://arxiv.org/abs/2602.01854)
*A S M Sharifuzzaman Sagar,Mohammed Bennamoun,Farid Boussaid,Naeha Sharif,Lian Xu,Shaaban Sahmoud,Ali Kishk*

Main category: cs.CV

TL;DR: 研究发现，现有的深度伪影检测器在多模态错误信息检测中作用有限，甚至可能因为引入错误的真实性假设而损害事实核查系统的性能。基于证据的事实核查系统表现最佳。


<details>
  <summary>Details</summary>
Motivation: 多数深度伪影检测器专注于像素级伪造，但多模态错误信息（图像-文本对）的欺骗常源于语义和语境层面。研究旨在探究像素级检测器是否能为图像-文本声明验证提供有价值的信号，还是会引入误导性的真实性先验。

Method: 使用MMFakeBench和DGM4两个基准数据集，评估了：（1）仅限图像的深度伪影检测器；（2）一个基于蒙特卡洛树搜索（MCTS）进行工具引导检索，并通过多智能体辩论（MAD）进行审议推理的证据驱动的事实核查系统；（3）一个将检测器输出作为辅助证据的混合事实核查系统。

Result: 深度伪影检测器单独使用的F1分数较低（MMFakeBench为0.26-0.53，DGM4为0.33-0.49）。将其预测结果纳入事实核查系统会因非因果真实性假设而使性能降低0.04-0.08的F1分数。相反，基于证据的事实核查系统取得了最高性能（MMFakeBench约0.81，DGM4约0.55）。

Conclusion: 多模态声明验证主要依赖于语义理解和外部证据，像素级伪影信号并不能可靠地提升对现实世界图像-文本错误信息的推理能力。

Abstract: In multimodal misinformation, deception usually arises not just from pixel-level manipulations in an image, but from the semantic and contextual claim jointly expressed by the image-text pair. Yet most deepfake detectors, engineered to detect pixel-level forgeries, do not account for claim-level meaning, despite their growing integration in automated fact-checking (AFC) pipelines. This raises a central scientific and practical question: Do pixel-level detectors contribute useful signal for verifying image-text claims, or do they instead introduce misleading authenticity priors that undermine evidence-based reasoning? We provide the first systematic analysis of deepfake detectors in the context of multimodal misinformation detection. Using two complementary benchmarks, MMFakeBench and DGM4, we evaluate: (1) state-of-the-art image-only deepfake detectors, (2) an evidence-driven fact-checking system that performs tool-guided retrieval via Monte Carlo Tree Search (MCTS) and engages in deliberative inference through Multi-Agent Debate (MAD), and (3) a hybrid fact-checking system that injects detector outputs as auxiliary evidence. Results across both benchmark datasets show that deepfake detectors offer limited standalone value, achieving F1 scores in the range of 0.26-0.53 on MMFakeBench and 0.33-0.49 on DGM4, and that incorporating their predictions into fact-checking pipelines consistently reduces performance by 0.04-0.08 F1 due to non-causal authenticity assumptions. In contrast, the evidence-centric fact-checking system achieves the highest performance, reaching F1 scores of approximately 0.81 on MMFakeBench and 0.55 on DGM4. Overall, our findings demonstrate that multimodal claim verification is driven primarily by semantic understanding and external evidence, and that pixel-level artifact signals do not reliably enhance reasoning over real-world image-text misinformation.

</details>


### [396] [Enabling Progressive Whole-slide Image Analysis with Multi-scale Pyramidal Network](https://arxiv.org/abs/2602.01951)
*Shuyang Wu,Yifu Qiu,Ines P. Nearchou,Sandrine Prost,Jonathan A Fallowfield,Hakan Bilen,Timothy J Kendall*

Main category: cs.CV

TL;DR: 提出了一种名为多尺度金字塔网络（MSPN）的即插即用模块，用于计算病理学任务，通过渐进式多尺度分析和粗糙上下文学习来改进基于注意力的多示例学习（MIL）。


<details>
  <summary>Details</summary>
Motivation: 现有的多尺度特征用于临床应用的方法依赖于不同放大倍率下的多个输入，并进行后期特征融合，这会丢失跨尺度的特征关联，且输入依赖于任意的、由制造商定义的放大倍率，不够灵活且计算成本高。

Method: 提出了一种名为多尺度金字塔网络（MSPN）的模块，它能够即插即用。MSPN 包含两个部分：1) 基于网格的重映射，利用高放大倍率的特征推导出粗糙特征；2) 粗糙引导网络（CGN），用于学习粗糙上下文。

Result: 将 MSPN 作为附加模块集成到 4 个基于注意力的 MIL 框架、3 种基础模型以及预训练的 MIL 框架中，并在 4 个临床相关任务上进行了基准测试。结果表明，MSPN 在所有比较的配置和任务上都能持续改进 MIL 的性能，同时保持轻量级和易用性。

Conclusion: MSPN 是一种有效且通用的模块，可以增强基于注意力的 MIL 模型在计算病理学任务中的表现，通过渐进式多尺度分析和粗糙上下文学习克服了现有方法的局限性。

Abstract: Multiple-instance Learning (MIL) is commonly used to undertake computational pathology (CPath) tasks, and the use of multi-scale patches allows diverse features across scales to be learned. Previous studies using multi-scale features in clinical applications rely on multiple inputs across magnifications with late feature fusion, which does not retain the link between features across scales while the inputs are dependent on arbitrary, manufacturer-defined magnifications, being inflexible and computationally expensive. In this paper, we propose the Multi-scale Pyramidal Network (MSPN), which is plug-and-play over attention-based MIL that introduces progressive multi-scale analysis on WSI. Our MSPN consists of (1) grid-based remapping that uses high magnification features to derive coarse features and (2) the coarse guidance network (CGN) that learns coarse contexts. We benchmark MSPN as an add-on module to 4 attention-based frameworks using 4 clinically relevant tasks across 3 types of foundation model, as well as the pre-trained MIL framework. We show that MSPN consistently improves MIL across the compared configurations and tasks, while being lightweight and easy-to-use.

</details>


### [397] [Q Cache: Visual Attention is Valuable in Less than Half of Decode Layers for Multimodal Large Language Model](https://arxiv.org/abs/2602.01901)
*Jiedong Zhuang,Lu Lu,Ming Dai,Rui Hu,Jian Chen,Qiang Liu,Haoji Hu*

Main category: cs.CV

TL;DR: 提出了一种名为“Lazy Attention”的新型高效注意力机制，通过跨层共享相似的注意力模式来减少冗余计算，有效降低了多模态大语言模型（MLLMs）的推理成本（KV缓存使用量减少超过35%），同时保持了接近原始性能。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs面临高昂的推理成本，主要是由于视觉编码器中过多的视觉token导致了巨大的计算负载和KV缓存瓶颈。现有方法（如token剪枝）虽然尝试优化token，但常常损害KV缓存的完整性，影响长文本生成任务。

Method: 深入分析了MLLMs的注意力机制，发现超过一半的解码层具有语义相似的注意力模式。基于此，提出Lazy Attention机制，允许相邻层继承和共享相似的注意力模式，从而减少冗余计算。引入了Q Cache，一种专门为MLLMs设计的轻量级、与现有推理框架（如Flash Attention和KV cache）兼容的层共享缓存，用于重用查询（queries）。该方法与现有token剪枝技术正交，可独立部署或结合使用。

Result: 在多个基准测试中，Lazy Attention将KV缓存使用量减少了35%以上，吞吐量提高了1.5倍，同时性能损失仅约为1%。与最先进的token剪枝方法相比，Lazy Attention在保持准确性方面表现更优。

Conclusion: Lazy Attention是一种有效减少MLLMs推理成本的新颖方法，通过跨层共享注意力模式来优化计算效率，同时能够很好地保留模型性能，并且与现有技术兼容灵活。

Abstract: Multimodal large language models (MLLMs) are plagued by exorbitant inference costs attributable to the profusion of visual tokens within the vision encoder. The redundant visual tokens engenders a substantial computational load and key-value (KV) cache footprint bottleneck. Existing approaches focus on token-wise optimization, leveraging diverse intricate token pruning techniques to eliminate non-crucial visual tokens. Nevertheless, these methods often unavoidably undermine the integrity of the KV cache, resulting in failures in long-text generation tasks. To this end, we conduct an in-depth investigation towards the attention mechanism of the model from a new perspective, and discern that attention within more than half of all decode layers are semantic similar. Upon this finding, we contend that the attention in certain layers can be streamlined by inheriting the attention from their preceding layers. Consequently, we propose Lazy Attention, an efficient attention mechanism that enables cross-layer sharing of similar attention patterns. It ingeniously reduces layer-wise redundant computation in attention. In Lazy Attention, we develop a novel layer-shared cache, Q Cache, tailored for MLLMs, which facilitates the reuse of queries across adjacent layers. In particular, Q Cache is lightweight and fully compatible with existing inference frameworks, including Flash Attention and KV cache. Additionally, our method is highly flexible as it is orthogonal to existing token-wise techniques and can be deployed independently or combined with token pruning approaches. Empirical evaluations on multiple benchmarks demonstrate that our method can reduce KV cache usage by over 35% and achieve 1.5x throughput improvement, while sacrificing only approximately 1% of performance on various MLLMs. Compared with SOTA token-wise methods, our technique achieves superior accuracy preservation.

</details>


### [398] [Beyond Open Vocabulary: Multimodal Prompting for Object Detection in Remote Sensing Images](https://arxiv.org/abs/2602.01954)
*Shuai Yang,Ziyue Huang,Jiaxin Chen,Qingjie Liu,Yunhong Wang*

Main category: cs.CV

TL;DR: 提出了一种名为RS-MPOD的多模态开放词汇目标检测框架，通过引入实例视觉提示，解决了遥感领域中仅文本提示的类别语义不确定性和分布偏移问题，并取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测方法在遥感领域依赖于纯文本提示，但在实际应用中，由于任务和应用特异性的类别语义，这种方法存在类别指定不稳定的问题。

Method: RS-MPOD框架引入了一个视觉提示编码器，从样本实例中提取基于外观的类别线索，实现无文本类别指定；并设计了一个多模态融合模块，用于整合视觉和文本信息。该框架通过视觉提示、文本提示以及它们的集成来完成类别指定。

Result: 在标准、跨数据集和细粒度遥感基准上的实验表明，视觉提示在语义模糊和分布偏移下能提供更可靠的类别指定。当文本语义对齐良好时，多模态提示作为一种灵活的替代方案，性能依然具有竞争力。

Conclusion: RS-MPOD通过引入实例视觉提示，有效解决了遥感开放词汇目标检测中类别指定不稳定和语义模糊的问题，并提供了一种灵活的多模态提示范式，在多种遥感场景下均表现出优越的性能。

Abstract: Open-vocabulary object detection in remote sensing commonly relies on text-only prompting to specify target categories, implicitly assuming that inference-time category queries can be reliably grounded through pretraining-induced text-visual alignment. In practice, this assumption often breaks down in remote sensing scenarios due to task- and application-specific category semantics, resulting in unstable category specification under open-vocabulary settings. To address this limitation, we propose RS-MPOD, a multimodal open-vocabulary detection framework that reformulates category specification beyond text-only prompting by incorporating instance-grounded visual prompts, textual prompts, and their multimodal integration. RS-MPOD introduces a visual prompt encoder to extract appearance-based category cues from exemplar instances, enabling text-free category specification, and a multimodal fusion module to integrate visual and textual information when both modalities are available. Extensive experiments on standard, cross-dataset, and fine-grained remote sensing benchmarks show that visual prompting yields more reliable category specification under semantic ambiguity and distribution shifts, while multimodal prompting provides a flexible alternative that remains competitive when textual semantics are well aligned.

</details>


### [399] [Enhancing Multi-Image Understanding through Delimiter Token Scaling](https://arxiv.org/abs/2602.01984)
*Minyoung Lee,Yeji Park,Dongjun Hwang,Yejin Kim,Seong Joon Oh,Junsuk Choe*

Main category: cs.CV

TL;DR: 该研究提出了一种通过缩放分隔符令牌的隐藏状态来解决大型视觉语言模型（LVLM）在处理多图像输入时信息泄露问题的技术，实验证明该技术在多图像和多文本任务上均能提升性能，且不增加额外的训练或推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（LVLM）在处理多图像输入时，由于跨图像信息泄露，性能会下降。尽管现有模型使用了分隔符令牌，但其效果不佳。

Method: 通过缩放分隔符令牌的隐藏状态，以增强模型保留图像特定信息的能力，加强图像内交互，并限制不受欢迎的跨图像交互。

Result: 该方法在Mantis、MuirBench、MIRB和QBench2等多个图像基准测试中提升了性能。同时，在TQABench、MultiNews和WCEP-10等文本任务基准测试中也表现出性能提升。该方法无需额外的训练或推理成本。

Conclusion: 缩放分隔符令牌的隐藏状态是一种有效的方法，可以解决LVLM在处理多模态输入时出现的跨图像信息泄露问题，从而提高模型在多图像和多文本理解任务上的准确性，并且不会带来额外的计算开销。

Abstract: Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance declines when multiple images are provided as input. One major reason is the cross-image information leakage, where the model struggles to distinguish information across different images. Existing LVLMs already employ delimiter tokens to mark the start and end of each image, yet our analysis reveals that these tokens fail to effectively block cross-image information leakage. To enhance their effectiveness, we propose a method that scales the hidden states of delimiter tokens. This enhances the model's ability to preserve image-specific information by reinforcing intra-image interaction and limiting undesired cross-image interactions. Consequently, the model is better able to distinguish between images and reason over them more accurately. Experiments show performance gains on multi-image benchmarks such as Mantis, MuirBench, MIRB, and QBench2. We further evaluate our method on text-only tasks that require clear distinction. The method improves performance on multi-document and multi-table understanding benchmarks, including TQABench, MultiNews, and WCEP-10. Notably, our method requires no additional training or inference cost.

</details>


### [400] [UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving](https://arxiv.org/abs/2602.02002)
*Guosheng Zhao,Yaozeng Wang,Xiaofeng Wang,Zheng Zhu,Tingdong Yu,Guan Huang,Yongchen Zai,Ji Jiao,Changliang Xue,Xiaole Wang,Zhen Yang,Futang Zhu,Xingang Wang*

Main category: cs.CV

TL;DR: UniDriveDreamer 是一个单阶段的统一多模态自动驾驶世界模型，可以直接生成多模态的未来观测，无需中间表示或级联模块。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型主要集中于单模态生成（如视频或 LiDAR），缺乏直接生成多模态数据的统一框架。

Method: 提出 UniDriveDreamer，包含一个 LiDAR VAE 和一个视频 VAE，并通过 Unified Latent Anchoring (ULA) 统一它们的潜在分布。然后，使用一个扩散 Transformer 联合建模几何对应和时间演化，并利用结构化场景布局信息作为条件进行引导。

Result: UniDriveDreamer 在视频和 LiDAR 生成方面均优于现有方法，并在下游任务中取得了可衡量的改进。

Conclusion: UniDriveDreamer 成功实现了单阶段的统一多模态自动驾驶世界模型，并在数据合成和下游任务评估中展现出优越性能。

Abstract: World models have demonstrated significant promise for data synthesis in autonomous driving. However, existing methods predominantly concentrate on single-modality generation, typically focusing on either multi-camera video or LiDAR sequence synthesis. In this paper, we propose UniDriveDreamer, a single-stage unified multimodal world model for autonomous driving, which directly generates multimodal future observations without relying on intermediate representations or cascaded modules. Our framework introduces a LiDAR-specific variational autoencoder (VAE) designed to encode input LiDAR sequences, alongside a video VAE for multi-camera images. To ensure cross-modal compatibility and training stability, we propose Unified Latent Anchoring (ULA), which explicitly aligns the latent distributions of the two modalities. The aligned features are fused and processed by a diffusion transformer that jointly models their geometric correspondence and temporal evolution. Additionally, structured scene layout information is projected per modality as a conditioning signal to guide the synthesis. Extensive experiments demonstrate that UniDriveDreamer outperforms previous state-of-the-art methods in both video and LiDAR generation, while also yielding measurable improvements in downstream

</details>


### [401] [Leveraging Latent Vector Prediction for Localized Control in Image Generation via Diffusion Models](https://arxiv.org/abs/2602.01991)
*Pablo Domingo-Gregorio,Javier Ruiz-Hidalgo*

Main category: cs.CV

TL;DR: 提出了一种新的扩散模型训练框架，通过引入掩码特征和额外的损失项，实现了对文本到图像生成中用户定义的局部区域的精确控制，而其余区域仍由模型自主生成。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型（如扩散模型）虽然能生成高质量图像，但在仅通过文本进行精细控制时，仍然是一个费时费力的试错过程。虽然图像级控制方法有所引入，但它们通常在整个图像上应用条件，限制了局部控制能力。

Method: 提出了一种新的训练框架，包含以下关键要素：1. 掩码特征的引入，用于标识用户希望进行局部控制的区域。2. 一个额外的损失项，该损失项利用了在任何扩散步长下预测的初始潜在向量，以增强当前步长与最终样本在潜在空间中的对应关系。

Result: 通过广泛的实验证明，该方法能够有效地合成具有受控局部条件的 and 高质量图像。

Conclusion: 所提出的方法能够实现对文本到图像生成中用户定义的局部区域的精确控制，同时允许扩散模型自主生成图像的其余部分，有效提高了图像生成的控制精度和灵活性。

Abstract: Diffusion models emerged as a leading approach in text-to-image generation, producing high-quality images from textual descriptions. However, attempting to achieve detailed control to get a desired image solely through text remains a laborious trial-and-error endeavor. Recent methods have introduced image-level controls alongside with text prompts, using prior images to extract conditional information such as edges, segmentation and depth maps. While effective, these methods apply conditions uniformly across the entire image, limiting localized control. In this paper, we propose a novel methodology to enable precise local control over user-defined regions of an image, while leaving to the diffusion model the task of autonomously generating the remaining areas according to the original prompt. Our approach introduces a new training framework that incorporates masking features and an additional loss term, which leverages the prediction of the initial latent vector at any diffusion step to enhance the correspondence between the current step and the final sample in the latent space. Extensive experiments demonstrate that our method effectively synthesizes high-quality images with controlled local conditions.

</details>


### [402] [UrbanGS: A Scalable and Efficient Architecture for Geometrically Accurate Large-Scene Reconstruction](https://arxiv.org/abs/2602.02089)
*Changbai Li,Haodong Zhu,Hanlin Chen,Xiuping Liang,Tongfei Chen,Shuwei Shao,Linlin Yang,Huobin Tan,Baochang Zhang*

Main category: cs.CV

TL;DR: UrbanGS是一个用于大规模城市场景的3D高斯喷溅重建框架，通过深度一致性D-法线正则化和空间自适应高斯剪枝来提高几何一致性、内存效率和计算可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯喷溅技术在处理大规模城市场景时存在几何一致性、内存效率和计算可扩展性方面的挑战。

Method: 提出了一种深度一致性D-法线正则化模块，结合外部深度监督和自适应置信度加权机制来增强几何精度。引入空间自适应高斯剪枝（SAGP）策略，动态调整高斯密度以提高可扩展性。设计了统一的划分和视图分配方案以消除边界伪影并优化计算负载。

Result: UrbanGS在渲染质量、几何精度和内存效率方面均取得了优越的性能，并在多个城市数据集上进行了验证。

Conclusion: UrbanGS为高保真大规模场景重建提供了一个系统性解决方案，有效解决了现有3D高斯喷溅技术在城市规模应用中的瓶颈。

Abstract: While 3D Gaussian Splatting (3DGS) enables high-quality, real-time rendering for bounded scenes, its extension to large-scale urban environments gives rise to critical challenges in terms of geometric consistency, memory efficiency, and computational scalability. To address these issues, we present UrbanGS, a scalable reconstruction framework that effectively tackles these challenges for city-scale applications. First, we propose a Depth-Consistent D-Normal Regularization module. Unlike existing approaches that rely solely on monocular normal estimators, which can effectively update rotation parameters yet struggle to update position parameters, our method integrates D-Normal constraints with external depth supervision. This allows for comprehensive updates of all geometric parameters. By further incorporating an adaptive confidence weighting mechanism based on gradient consistency and inverse depth deviation, our approach significantly enhances multi-view depth alignment and geometric coherence, which effectively resolves the issue of geometric accuracy in complex large-scale scenes. To improve scalability, we introduce a Spatially Adaptive Gaussian Pruning (SAGP) strategy, which dynamically adjusts Gaussian density based on local geometric complexity and visibility to reduce redundancy. Additionally, a unified partitioning and view assignment scheme is designed to eliminate boundary artifacts and optimize computational load. Extensive experiments on multiple urban datasets demonstrate that UrbanGS achieves superior performance in rendering quality, geometric accuracy, and memory efficiency, providing a systematic solution for high-fidelity large-scale scene reconstruction.

</details>


### [403] [FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space](https://arxiv.org/abs/2602.02092)
*FSVideo Team,Qingyu Chen,Zhiyuan Fang,Haibin Huang,Xinwei Huang,Tong Jin,Minxuan Lin,Bo Liu,Celong Liu,Chongyang Ma,Xing Mei,Xiaohui Shen,Yaojie Shen,Fuwen Tan,Angtian Wang,Xiao Yang,Yiding Yang,Jiamin Yuan,Lingxi Zhang,Yuxin Zhang*

Main category: cs.CV

TL;DR: FSVideo是一个基于Transformer的快速图像到视频（I2V）扩散框架，通过高效的视频自编码器、改进的层记忆扩散Transformer以及多分辨率生成策略，实现了与现有开源模型相当的性能，但速度提升了一个数量级。


<details>
  <summary>Details</summary>
Motivation: 为了开发一个能够快速生成高质量视频的图像到视频（I2V）扩散框架，同时提高生成效率。

Method: 该框架包含三个关键组件：1. 一个具有高度压缩的潜在空间（$64	imes64	imes4$空间时间下采样率）的新型视频自编码器；2. 一个具有新层记忆设计的扩散Transformer（DIT）架构，以增强DIT内部的层间信息流和上下文重用；3. 通过几步DIT上采样器实现的多分辨率生成策略，以提高视频保真度。

Result: FSVideo模型（包含一个14B DIT基础模型和一个14B DIT上采样器）在生成速度上比其他流行的开源模型快一个数量级，同时在生成质量上与之相当。

Conclusion: FSVideo成功地实现了一个快速且性能可观的图像到视频扩散框架，其核心在于高效的视频自编码器、优化的扩散Transformer架构和多分辨率生成策略。

Abstract: We introduce FSVideo, a fast speed transformer-based image-to-video (I2V) diffusion framework. We build our framework on the following key components: 1.) a new video autoencoder with highly-compressed latent space ($64\times64\times4$ spatial-temporal downsampling ratio), achieving competitive reconstruction quality; 2.) a diffusion transformer (DIT) architecture with a new layer memory design to enhance inter-layer information flow and context reuse within DIT, and 3.) a multi-resolution generation strategy via a few-step DIT upsampler to increase video fidelity. Our final model, which contains a 14B DIT base model and a 14B DIT upsampler, achieves competitive performance against other popular open-source models, while being an order of magnitude faster. We discuss our model design as well as training strategies in this report.

</details>


### [404] [Teacher-Guided Student Self-Knowledge Distillation Using Diffusion Model](https://arxiv.org/abs/2602.02107)
*Yu Wang,Chuanguang Yang,Zhulin An,Weilun Feng,Jiarui Zhao,Chengqing Yu,Libo Huang,Boyu Diao,Yongjun Xu*

Main category: cs.CV

TL;DR: 提出了一种名为DSKD的知识蒸馏方法，通过教师模型指导学生模型的去噪特征采样，并结合局部敏感哈希（LSH）进行学生模型自身（去噪前后）的特征蒸馏，以解决教师学生特征分布不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法在对齐教师学生特征时，可能由于特征分布差异导致学生模型学习到不兼容的信息。

Method: 利用教师分类器指导学生模型的去噪特征采样过程，引入轻量级扩散模型，并提出一种基于局部敏感哈希（LSH）的蒸馏方法，使去噪后的学生特征扮演教师角色，从而消除教师学生之间的映射方式和特征分布差异。

Result: DSKD在视觉识别任务上显著优于现有的知识蒸馏方法，在不同模型和数据集上均表现出色。

Conclusion: DSKD通过教师引导的扩散模型和LSH蒸馏，有效解决了知识蒸馏中教师学生特征分布不匹配的问题，并成功地从教师模型中学习到了有意义的知识。

Abstract: Existing Knowledge Distillation (KD) methods often align feature information between teacher and student by exploring meaningful feature processing and loss functions. However, due to the difference in feature distributions between the teacher and student, the student model may learn incompatible information from the teacher. To address this problem, we propose teacher-guided student Diffusion Self-KD, dubbed as DSKD. Instead of the direct teacher-student alignment, we leverage the teacher classifier to guide the sampling process of denoising student features through a light-weight diffusion model. We then propose a novel locality-sensitive hashing (LSH)-guided feature distillation method between the original and denoised student features. The denoised student features encapsulate teacher knowledge and could be regarded as a teacher role. In this way, our DSKD method could eliminate discrepancies in mapping manners and feature distributions between the teacher and student, while learning meaningful knowledge from the teacher. Experiments on visual recognition tasks demonstrate that DSKD significantly outperforms existing KD methods across various models and datasets. Our code is attached in supplementary material.

</details>


### [405] [Enhancing Diffusion-Based Quantitatively Controllable Image Generation via Matrix-Form EDM and Adaptive Vicinal Training](https://arxiv.org/abs/2602.02114)
*Xin Ding,Yun Chen,Sen Zhang,Kao Zhang,Nenglun Chen,Peibei Cao,Yongwei Wang,Fei Wu*

Main category: cs.CV

TL;DR: 提出了一种改进的连续条件扩散模型（iCCDM），它结合了更先进的Elucidated Diffusion Model（EDM）框架，并采用了矩阵形式的EDM和自适应邻近训练策略，以提高生成质量和采样效率。


<details>
  <summary>Details</summary>
Motivation: 现有的连续条件扩散模型（CCDM）存在生成质量不高和采样效率低的问题，并且已被基于GAN的方法（CcGAN-AVAR）超越。研究旨在克服这些局限性，提升生成质量和采样效率。

Method: 采用更先进的Elucidated Diffusion Model（EDM）框架，并进行修改以适应连续条件生成。具体包括引入矩阵形式的EDM和自适应邻近训练策略。

Result: 在四个不同分辨率（64x64到256x256）的基准数据集上进行的大量实验表明，iCCDM的生成质量优于包括Stable Diffusion 3、FLUX.1和Qwen-Image在内的现有SOTA方法，并且采样成本显著降低。

Conclusion: iCCDM通过整合更新的EDM框架和创新的训练策略，成功克服了CCDM的局限性，在连续条件图像生成方面实现了更高的质量和更高的采样效率。

Abstract: Continuous Conditional Diffusion Model (CCDM) is a diffusion-based framework designed to generate high-quality images conditioned on continuous regression labels. Although CCDM has demonstrated clear advantages over prior approaches across a range of datasets, it still exhibits notable limitations and has recently been surpassed by a GAN-based method, namely CcGAN-AVAR. These limitations mainly arise from its reliance on an outdated diffusion framework and its low sampling efficiency due to long sampling trajectories. To address these issues, we propose an improved CCDM framework, termed iCCDM, which incorporates the more advanced \textit{Elucidated Diffusion Model} (EDM) framework with substantial modifications to improve both generation quality and sampling efficiency. Specifically, iCCDM introduces a novel matrix-form EDM formulation together with an adaptive vicinal training strategy. Extensive experiments on four benchmark datasets, spanning image resolutions from $64\times64$ to $256\times256$, demonstrate that iCCDM consistently outperforms existing methods, including state-of-the-art large-scale text-to-image diffusion models (e.g., Stable Diffusion 3, FLUX.1, and Qwen-Image), achieving higher generation quality while significantly reducing sampling cost.

</details>


### [406] [MLV-Edit: Towards Consistent and Highly Efficient Editing for Minute-Level Videos](https://arxiv.org/abs/2602.02123)
*Yangyi Cao,Yuanhang Li,Lan Chen,Qi Mao*

Main category: cs.CV

TL;DR: 提出了一种名为MLV-Edit的无训练、基于流的视频编辑框架，专门用于解决分钟级长视频的编辑难题，通过分段编辑、运动不一致性校正和全局特征锚定，有效提高了视频的整体稳定性和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑技术在短视频处理上表现良好，但在分钟级长视频上存在计算开销大、难以保持全局时间一致性等问题。

Method: 采用分而治之的策略进行分段编辑，核心模块包括：1. Velocity Blend：通过对齐相邻分段的流场来校正运动不一致性，消除边界伪影。2. Attention Sink：将局部特征锚定到全局参考帧，抑制累积的结构漂移。

Result: MLV-Edit在时间稳定性和语义保真度方面持续优于最先进的方法，通过了大量的定量和定性实验验证。

Conclusion: MLV-Edit是一个有效的、无需训练的分钟级长视频编辑框架，能够克服长视频编辑中的挑战，并取得优异的性能。

Abstract: We propose MLV-Edit, a training-free, flow-based framework that address the unique challenges of minute-level video editing. While existing techniques excel in short-form video manipulation, scaling them to long-duration videos remains challenging due to prohibitive computational overhead and the difficulty of maintaining global temporal consistency across thousands of frames. To address this, MLV-Edit employs a divide-and-conquer strategy for segment-wise editing, facilitated by two core modules: Velocity Blend rectifies motion inconsistencies at segment boundaries by aligning the flow fields of adjacent chunks, eliminating flickering and boundary artifacts commonly observed in fragmented video processing; and Attention Sink anchors local segment features to global reference frames, effectively suppressing cumulative structural drift. Extensive quantitative and qualitative experiments demonstrate that MLV-Edit consistently outperforms state-of-the-art methods in terms of temporal stability and semantic fidelity.

</details>


### [407] [Deep learning enables urban change profiling through alignment of historical maps](https://arxiv.org/abs/2602.02154)
*Sidi Wu,Yizi Chen,Maurizio Gribaudi,Konrad Schindler,Clément Mallet,Julien Perret,Lorenz Hurni*

Main category: cs.CV

TL;DR: 提出一个全自动深度学习框架，用于从大量历史地图中进行细粒度城市变化分析，以解决空间错位、地图变化和文件质量下降等问题。


<details>
  <summary>Details</summary>
Motivation: 历史地图提供了城市长期变迁的独特记录，但现有方法在提取一致和细粒度的变化信息方面存在挑战，限制了分析的规模和定性。

Method: 构建了一个基于深度学习的模块化框架，集成了密集地图对齐、多时相物体检测和变化剖析，实现了全自动的细粒度城市变化分析。

Result: 实验证明了所提出的地图对齐和物体检测方法的鲁棒性。将该框架应用于1868年至1937年间的巴黎地图，揭示了城市变迁在空间和时间上的异质性。

Conclusion: 该框架将历史地图分析从临时的视觉比较转变为系统的、定量的城市变化特征刻画，并支持适应不同的地图集和下游应用，对社会科学和人文学科的研究具有重要意义。

Abstract: Prior to modern Earth observation technologies, historical maps provide a unique record of long-term urban transformation and offer a lens on the evolving identity of cities. However, extracting consistent and fine-grained change information from historical map series remains challenging due to spatial misalignment, cartographic variation, and degrading document quality, limiting most analyses to small-scale or qualitative approaches. We propose a fully automated, deep learning-based framework for fine-grained urban change analysis from large collections of historical maps, built on a modular design that integrates dense map alignment, multi-temporal object detection, and change profiling. This framework shifts the analysis of historical maps from ad hoc visual comparison toward systematic, quantitative characterization of urban change. Experiments demonstrate the robust performance of the proposed alignment and object detection methods. Applied to Paris between 1868 and 1937, the framework reveals the spatial and temporal heterogeneity in urban transformation, highlighting its relevance for research in the social sciences and humanities. The modular design of our framework further supports adaptation to diverse cartographic contexts and downstream applications.

</details>


### [408] [Eliminating Registration Bias in Synthetic CT Generation: A Physics-Based Simulation Framework](https://arxiv.org/abs/2602.02130)
*Lukas Zimmermann,Michael Rauter,Maximilian Schmid,Dietmar Georg,Barbara Knäusl*

Main category: cs.CV

TL;DR: 研究提出了一种基于物理的CBCT模拟方法，用于生成几何对齐的训练数据，以解决现有监督学习方法中注册偏差导致的问题。该方法通过几何对齐指标而非传统的强度指标来评估模型性能，并在临床评估中显示出优于传统方法的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的从CBCT生成合成CT的监督学习方法需要配准好的训练对，但精确配准难以实现，这会导致注册偏差并影响模型性能和评估指标的可靠性。

Method: 提出使用基于物理的CBCT模拟来生成几何对齐的训练对，并采用几何对齐指标（如归一化互信息）来评估模型，而不是使用存在注册偏差的伪影真实数据。

Result: 在两个独立的盆腔数据集上，使用模拟数据训练的模型在几何对齐方面表现更优（NMI：0.31 vs 0.22），尽管其强度得分较低。强度指标与临床评估呈反相关，而NMI与观察者偏好一致（rho = 0.31, p < 0.001）。临床观察者在87%的情况下偏好使用模拟数据训练的模型生成的CT。

Conclusion: 几何保真度，而非与存在偏差的真实数据的强度一致性，才是临床需求的体现。基于物理模拟的方法能够生成符合临床要求的合成CT。

Abstract: Supervised synthetic CT generation from CBCT requires registered training pairs, yet perfect registration between separately acquired scans remains unattainable. This registration bias propagates into trained models and corrupts standard evaluation metrics. This may suggest that superior benchmark performance indicates better reproduction of registration artifacts rather than anatomical fidelity. We propose physics-based CBCT simulation to provide geometrically aligned training pairs by construction, combined with evaluation using geometric alignment metrics against input CBCT rather than biased ground truth. On two independent pelvic datasets, models trained on synthetic data achieved superior geometric alignment (Normalized Mutual Information: 0.31 vs 0.22) despite lower conventional intensity scores. Intensity metrics showed inverted correlations with clinical assessment for deformably registered data, while Normalized Mutual Information consistently predicted observer preference across registration methodologies (rho = 0.31, p < 0.001). Clinical observers preferred synthetic-trained outputs in 87% of cases, demonstrating that geometric fidelity, not intensity agreement with biased ground truth, aligns with clinical requirements.

</details>


### [409] [LoopViT: Scaling Visual ARC with Looped Transformers](https://arxiv.org/abs/2602.02156)
*Wen-Jie Shu,Xuerui Qiu,Rui-Jie Zhu,Harold Haodong Chen,Yexin Liu,Harry Yang*

Main category: cs.CV

TL;DR: 提出了一种名为 Loop-ViT 的递归视觉推理架构，通过权重共享的循环和无参数动态退出机制，实现了比传统前馈模型更高效的推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于 Vision Transformer 的视觉推理模型在 ARC-AGI 基准上的表现受限于其前馈架构，无法捕捉人类归纳推理的迭代和算法特性。

Method: 提出了 Loop-ViT 递归架构，通过权重共享的混合块（结合卷积和注意力）进行迭代计算，形成“思维链”的潜在表示。引入了基于预测熵的无参数动态退出机制，当模型内部状态不确定性降低时停止推理。

Result: 在 ARC-AGI-1 基准测试中，18M 参数的 Loop-ViT 模型达到了 65.8% 的准确率，超越了参数量为 73M 的大型模型集成。

Conclusion: 自适应的迭代计算是一种比增加网络宽度更有效的视觉推理模型扩展方式，Loop-ViT 的结果证明了这一点。

Abstract: Recent advances in visual reasoning have leveraged vision transformers to tackle the ARC-AGI benchmark. However, we argue that the feed-forward architecture, where computational depth is strictly bound to parameter size, falls short of capturing the iterative, algorithmic nature of human induction. In this work, we propose a recursive architecture called Loop-ViT, which decouples reasoning depth from model capacity through weight-tied recurrence. Loop-ViT iterates a weight-tied Hybrid Block, combining local convolutions and global attention, to form a latent chain of thought. Crucially, we introduce a parameter-free Dynamic Exit mechanism based on predictive entropy: the model halts inference when its internal state ``crystallizes" into a low-uncertainty attractor. Empirical results on the ARC-AGI-1 benchmark validate this perspective: our 18M model achieves 65.8% accuracy, outperforming massive 73M-parameter ensembles. These findings demonstrate that adaptive iterative computation offers a far more efficient scaling axis for visual reasoning than simply increasing network width. The code is available at https://github.com/WenjieShu/LoopViT.

</details>


### [410] [CIEC: Coupling Implicit and Explicit Cues for Multimodal Weakly Supervised Manipulation Localization](https://arxiv.org/abs/2602.02175)
*Xinquan Yu,Wei Lu,Xiangyang Luo*

Main category: cs.CV

TL;DR: 本文提出了一种名为 CIEC 的新框架，用于在仅有粗粒度图像/句子级别标注的情况下，实现图像-文本对的多模态弱监督操纵定位。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于成本高昂且耗时的细粒度标注（如块/令牌级别标注），而本文旨在解决这个问题。

Method: CIEC 包含两个分支：基于图像的弱监督定位（TRPS 模块，结合视觉和文本线索，并通过背景抑制和空间对比约束来减少干扰）和基于文本的弱监督定位（VCTG 模块，关注有意义的内容词，并利用相对视觉偏差辅助令牌定位，同时采用稀疏和语义一致性约束来减轻噪声）。

Result: CIEC 在多个评估指标上取得了与完全监督方法相媲美的结果，证明了其有效性。

Conclusion: CIEC 是一种有效的多模态弱监督操纵定位框架，能够利用粗粒度标注实现接近完全监督方法的性能。

Abstract: To mitigate the threat of misinformation, multimodal manipulation localization has garnered growing attention. Consider that current methods rely on costly and time-consuming fine-grained annotations, such as patch/token-level annotations. This paper proposes a novel framework named Coupling Implicit and Explicit Cues (CIEC), which aims to achieve multimodal weakly-supervised manipulation localization for image-text pairs utilizing only coarse-grained image/sentence-level annotations. It comprises two branches, image-based and text-based weakly-supervised localization. For the former, we devise the Textual-guidance Refine Patch Selection (TRPS) module. It integrates forgery cues from both visual and textual perspectives to lock onto suspicious regions aided by spatial priors. Followed by the background silencing and spatial contrast constraints to suppress interference from irrelevant areas. For the latter, we devise the Visual-deviation Calibrated Token Grounding (VCTG) module. It focuses on meaningful content words and leverages relative visual bias to assist token localization. Followed by the asymmetric sparse and semantic consistency constraints to mitigate label noise and ensure reliability. Extensive experiments demonstrate the effectiveness of our CIEC, yielding results comparable to fully supervised methods on several evaluation metrics.

</details>


### [411] [Lung Nodule Image Synthesis Driven by Two-Stage Generative Adversarial Networks](https://arxiv.org/abs/2602.02171)
*Lu Cao,Xiquan He,Junying Zeng,Chaoyun Mai,Min Luo*

Main category: cs.CV

TL;DR: 提出了一种名为TSGAN的两阶段生成对抗网络，用于生成多样化且空间可控的肺结节CT图像，以解决现有数据集样本量不足和多样性不够的问题。该模型通过解耦形态结构和纹理特征，显著提升了合成图像的质量和检测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的肺结节CT数据集样本量有限且多样性不足，严重制约了检测模型的性能和泛化能力。现有数据增强方法生成的图像多样性不足、可控性差，存在纹理单调、解剖结构失真等问题。

Method: 提出一个两阶段生成对抗网络（TSGAN）。第一阶段使用StyleGAN生成语义分割掩码图，控制解剖结构。第二阶段使用DL-Pix2Pix模型将掩码图转换为CT图像，并引入局部重要性注意力机制和动态权重多头窗口注意力机制来增强纹理和背景的建模能力。

Result: 与原始数据集相比，在LUNA16数据集上，模型的准确率提高了4.6%，mAP提高了4%。实验结果表明，TSGAN能够提升合成图像的质量和检测模型的性能。

Conclusion: TSGAN能够有效地生成高质量、多样化且空间可控的肺结节CT合成图像，从而提升肺结节检测模型的性能和泛化能力。

Abstract: The limited sample size and insufficient diversity of lung nodule CT datasets severely restrict the performance and generalization ability of detection models. Existing methods generate images with insufficient diversity and controllability, suffering from issues such as monotonous texture features and distorted anatomical structures. Therefore, we propose a two-stage generative adversarial network (TSGAN) to enhance the diversity and spatial controllability of synthetic data by decoupling the morphological structure and texture features of lung nodules. In the first stage, StyleGAN is used to generate semantic segmentation mask images, encoding lung nodules and tissue backgrounds to control the anatomical structure of lung nodule images; The second stage uses the DL-Pix2Pix model to translate the mask map into CT images, employing local importance attention to capture local features, while utilizing dynamic weight multi-head window attention to enhance the modeling capability of lung nodule texture and background. Compared to the original dataset, the accuracy improved by 4.6% and mAP by 4% on the LUNA16 dataset. Experimental results demonstrate that TSGAN can enhance the quality of synthetic images and the performance of detection models.

</details>


### [412] [Reg4Pru: Regularisation Through Random Token Routing for Token Pruning](https://arxiv.org/abs/2602.02163)
*Julian Wyatt,Ronald Clark,Irina Voiculescu*

Main category: cs.CV

TL;DR: Reg4Pru 是一种新的训练正则化技术，可以减轻视觉 Transformer 中令牌修剪造成的性能下降，尤其是在密集预测任务（如图像分割）中，并能实现计算效率的提升。


<details>
  <summary>Details</summary>
Motivation: 视觉 Transformer 因其出色的可扩展性和泛化能力而被广泛使用，但其计算成本随令牌数量呈二次方增长，这限制了其实际应用。现有的令牌修剪方法虽然提高了效率，但却牺牲了性能稳定性，导致在较深层网络中密集预测性能下降。因此，需要一种方法来在提高效率的同时保持或提升性能。

Method: 提出了一种名为 Reg4Pru 的训练正则化技术，旨在解决令牌修剪带来的性能损失问题，特别关注分割任务。该方法通过某种正则化机制来稳定修剪后的表示，从而提高模型在密集预测任务上的性能。

Result: 在 FIVES 血管分割数据集上的实验表明，Reg4Pru 相比于未经路由训练的相同模型，平均精度（AP）提高了 46%。同时，采用 Reg4Pru 的模型在实现 29% 的相对加速比（与未剪枝基线相比）的情况下，依然取得了显著的性能提升。

Conclusion: Reg4Pru 是一种有效的正则化技术，能够成功缓解视觉 Transformer 中令牌修剪策略导致的性能下降问题，尤其是在分割等密集预测任务中，可以在提高计算效率的同时保证甚至提升模型性能，为令牌缩减策略提供了一个有价值的工具。

Abstract: Transformers are widely adopted in modern vision models due to their strong ability to scale with dataset size and generalisability. However, this comes with a major drawback: computation scales quadratically to the total number of tokens. Numerous methods have been proposed to mitigate this. For example, we consider token pruning with reactivating tokens from preserved representations, but the increased computational efficiency of this method results in decreased stability from the preserved representations, leading to poorer dense prediction performance at deeper layers. In this work, we introduce Reg4Pru, a training regularisation technique that mitigates token-pruning performance loss for segmentation. We compare our models on the FIVES blood vessel segmentation dataset and find that Reg4Pru improves average precision by an absolute 46% compared to the same model trained without routing. This increase is observed using a configuration that achieves a 29% relative speedup in wall-clock time compared to the non-pruned baseline. These findings indicate that Reg4Pru is a valuable regulariser for token reduction strategies.

</details>


### [413] [Learning Topology-Aware Implicit Field for Unified Pulmonary Tree Modeling with Incomplete Topological Supervision](https://arxiv.org/abs/2602.02186)
*Ziqiao Weng,Jiancheng Yang,Kangxian Xie,Bo Zhou,Weidong Cai*

Main category: cs.CV

TL;DR: 本文提出了一种名为 TopoField 的新框架，用于修复和分析 CT 图像中的肺部树结构。该框架使用隐式建模方法，能够高效地修复拓扑不完整性，并同时进行解剖标记和肺段重建，在实际应用中表现出高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的肺部树建模方法在处理 CT 图像中常见的拓扑不完整性（如缺失或断开的分支）时效率低下且鲁棒性差，这限制了下游的解剖分析和建模应用的可用性。作者希望开发一种更有效、更鲁棒的方法来解决这个问题。

Method: TopoField 框架使用稀疏的表面和骨架点云来表示肺部解剖结构。它学习一个连续的隐式场，能够将拓扑修复视为一个核心问题，并通过在合成的、已存在不完整性的肺部树上引入结构性干扰进行训练。在此基础上，通过任务特定的隐式函数，在一次前向传播中联合推断解剖标记和肺段重建。

Result: 在 Lung3D+ 数据集上的实验表明，TopoField 在充满挑战的不完整场景下，能够持续提高拓扑完整性，并实现准确的解剖标记和肺段重建。此外，由于其隐式形式，TopoField 具有高计算效率，每个病例的处理时间仅略超过一秒。

Conclusion: TopoField 是一种拓扑感知的隐式建模框架，能够有效地修复肺部树的拓扑不完整性，并联合推断解剖标记和肺段重建。该方法在效率和准确性方面均表现出色，使其在大型和时间敏感的临床应用中具有很高的实用价值。

Abstract: Pulmonary trees extracted from CT images frequently exhibit topological incompleteness, such as missing or disconnected branches, which substantially degrades downstream anatomical analysis and limits the applicability of existing pulmonary tree modeling pipelines. Current approaches typically rely on dense volumetric processing or explicit graph reasoning, leading to limited efficiency and reduced robustness under realistic structural corruption. We propose TopoField, a topology-aware implicit modeling framework that treats topology repair as a first-class modeling problem and enables unified multi-task inference for pulmonary tree analysis. TopoField represents pulmonary anatomy using sparse surface and skeleton point clouds and learns a continuous implicit field that supports topology repair without relying on complete or explicit disconnection annotations, by training on synthetically introduced structural disruptions over \textit{already} incomplete trees. Building upon the repaired implicit representation, anatomical labeling and lung segment reconstruction are jointly inferred through task-specific implicit functions within a single forward pass.Extensive experiments on the Lung3D+ dataset demonstrate that TopoField consistently improves topological completeness and achieves accurate anatomical labeling and lung segment reconstruction under challenging incomplete scenarios. Owing to its implicit formulation, TopoField attains high computational efficiency, completing all tasks in just over one second per case, highlighting its practicality for large-scale and time-sensitive clinical applications. Code and data will be available at https://github.com/HINTLab/TopoField.

</details>


### [414] [MAIN-VLA: Modeling Abstraction of Intention and eNvironment for Vision-Language-Action Models](https://arxiv.org/abs/2602.02212)
*Zheyuan Zhou,Liang Du,Zixun Sun,Xiaoyu Zhou,Ruimin Ye,Qihao Chen,Yinda Chen,Lemiao Qiu*

Main category: cs.CV

TL;DR: MAIN-VLA是一个框架，通过显式建模意图和环境的抽象来提高复杂动态环境中视觉-语言-动作（VLA）任务的效率和性能，通过意图抽象和环境语义抽象提取关键信号，并实现参数无关的令牌剪枝策略。


<details>
  <summary>Details</summary>
Motivation: 现有VLA方法在处理涉及实时不可预测交互的复杂动态环境（如3D开放世界和大型PvP游戏）时，从冗余传感器流中提取关键动作信号的效率低下。

Method: 引入MAIN-VLA框架，该框架包含两个主要组件：1. 意图抽象（IA）：将详细的语言指令及其推理过程提炼成紧凑、明确的语义原语。2. 环境语义抽象（ESA）：将大量的视觉流投影为结构化的拓扑可供性表示。通过对这两种抽象模态进行对齐，诱导涌现的注意力集中效应，实现参数无关的令牌剪枝策略。

Result: 在开放世界Minecraft以及大型PvP环境（《和平精英》和《 Valorant》）的广泛实验表明，MAIN-VLA在决策质量、泛化能力和推理效率方面均达到了新的最先进水平。

Conclusion: MAIN-VLA框架能够通过显式建模意图和环境的抽象，在复杂动态环境中实现更高效、更高质量的VLA决策，并通过参数无关的令牌剪枝策略有效过滤感知冗余。

Abstract: Despite significant progress in Visual-Language-Action (VLA), in highly complex and dynamic environments that involve real-time unpredictable interactions (such as 3D open worlds and large-scale PvP games), existing approaches remain inefficient at extracting action-critical signals from redundant sensor streams. To tackle this, we introduce MAIN-VLA, a framework that explicitly Models the Abstraction of Intention and eNvironment to ground decision-making in deep semantic alignment rather than superficial pattern matching. Specifically, our Intention Abstraction (IA) extracts verbose linguistic instructions and their associated reasoning into compact, explicit semantic primitives, while the Environment Semantics Abstraction (ESA) projects overwhelming visual streams into a structured, topological affordance representation. Furthermore, aligning these two abstract modalities induces an emergent attention-concentration effect, enabling a parameter-free token-pruning strategy that filters out perceptual redundancy without degrading performance. Extensive experiments in open-world Minecraft and large-scale PvP environments (Game for Peace and Valorant) demonstrate that MAIN-VLA sets a new state-of-the-art, which achieves superior decision quality, stronger generalization, and cutting-edge inference efficiency.

</details>


### [415] [SSI-DM: Singularity Skipping Inversion of Diffusion Models](https://arxiv.org/abs/2602.02193)
*Chen Min,Enze Jiang,Jishen Peng,Zheng Ma*

Main category: cs.CV

TL;DR: 提出了一种名为SSI-DM的扩散模型反演方法，通过在标准反演前添加少量噪声来绕过数学奇点，从而生成具有高可编辑性的高斯噪声，并在重建和插值任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型图像编辑方法在将真实图像反演至噪声空间时，由于早期加噪步骤不准确，会导致生成的噪声分布非高斯且可编辑性差。研究旨在解决这一问题。

Method: 提出了一种名为Singularity Skipping Inversion of Diffusion Models (SSI-DM)的方法。该方法通过在标准反演过程之前添加少量噪声来“跳过”数学奇点区域，从而在不牺牲重建保真度的情况下，生成具有自然高斯属性的噪声。

Result: SSI-DM方法生成的反演噪声具有高斯特性，并且在重建和插值任务上取得了优于现有方法的性能。该方法能够保持重建保真度。

Conclusion: SSI-DM是一种即插即用的技术，适用于通用扩散模型。它提供了一种原理清晰且高效的解决方案，可以解决扩散模型反演中的奇点问题，并生成具有高可编辑性的高斯噪声，从而提升图像编辑任务的性能。

Abstract: Inverting real images into the noise space is essential for editing tasks using diffusion models, yet existing methods produce non-Gaussian noise with poor editability due to the inaccuracy in early noising steps. We identify the root cause: a mathematical singularity that renders inversion fundamentally ill-posed. We propose Singularity Skipping Inversion of Diffusion Models (SSI-DM), which bypasses this singular region by adding small noise before standard inversion. This simple approach produces inverted noise with natural Gaussian properties while maintaining reconstruction fidelity. As a plug-and-play technique compatible with general diffusion models, our method achieves superior performance on public image datasets for reconstruction and interpolation tasks, providing a principled and efficient solution to diffusion model inversion.

</details>


### [416] [Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation](https://arxiv.org/abs/2602.02214)
*Hongzhou Zhu,Min Zhao,Guande He,Hang Su,Chongxuan Li,Jun Zhu*

Main category: cs.CV

TL;DR: 提出了一种名为Causal Forcing的新方法，通过使用自回归教师模型进行ODE初始化来解决双向视频扩散模型蒸馏到自回归模型时存在的架构鸿沟问题，从而提高实时交互式视频生成的效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将预训练的双向视频扩散模型蒸馏为少步自回归模型时，由于架构上的差异（全注意力被因果注意力取代）导致性能下降。现有的ODE蒸馏初始化方法要求帧级注入性，这与从双向教师蒸馏到自回归学生模型的要求相冲突。

Method: 提出Causal Forcing方法，通过使用自回归教师模型进行ODE初始化来弥合架构鸿沟，从而解决了帧级注入性问题。

Result: Causal Forcing在所有指标上都优于所有基线方法，在动态度、VisionReward和指令遵循方面分别超越了SOTA的Self Forcing方法19.3%、8.7%和16.7%。

Conclusion: Causal Forcing成功地解决了双向视频扩散模型蒸馏到自回归模型时的架构鸿沟问题，并通过自回归教师进行ODE初始化，显著提升了实时交互式视频生成的性能。

Abstract: To achieve real-time interactive video generation, current methods distill pretrained bidirectional video diffusion models into few-step autoregressive (AR) models, facing an architectural gap when full attention is replaced by causal attention. However, existing approaches do not bridge this gap theoretically. They initialize the AR student via ODE distillation, which requires frame-level injectivity, where each noisy frame must map to a unique clean frame under the PF-ODE of an AR teacher. Distilling an AR student from a bidirectional teacher violates this condition, preventing recovery of the teacher's flow map and instead inducing a conditional-expectation solution, which degrades performance. To address this issue, we propose Causal Forcing that uses an AR teacher for ODE initialization, thereby bridging the architectural gap. Empirical results show that our method outperforms all baselines across all metrics, surpassing the SOTA Self Forcing by 19.3\% in Dynamic Degree, 8.7\% in VisionReward, and 16.7\% in Instruction Following. Project page and the code: \href{https://thu-ml.github.io/CausalForcing.github.io/}{https://thu-ml.github.io/CausalForcing.github.io/}

</details>


### [417] [MIRROR: Manifold Ideal Reference ReconstructOR for Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2602.02222)
*Ruiqi Liu,Manni Cui,Ziheng Qin,Zhiyuan Yan,Ruoxin Chen,Yi Han,Zhiheng Li,Junkai Chen,ZhiJin Chen,Kaiqing Lin,Jialiang Shen,Lubin Weng,Jing Dong,Yan Wang,Shu Wu*

Main category: cs.CV

TL;DR: 提出了一种名为MIRROR的框架，通过将AI生成图像（AIGI）检测重新定义为参考-比较问题，并利用离散记忆库显式编码现实世界先验，以检测与真实图像流形的一致性，从而提高了AIGI检测的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成图像（AIGI）检测器依赖于基于伪影的分类，难以适应不断变化的生成痕迹。人类的判断依赖于稳定的现实世界规律，偏离人类认知流形是伪造的更通用信号。

Method: 将AIGI检测重新定义为参考-比较问题，提出MIRROR框架，该框架通过可学习的离散记忆库显式编码现实世界先验，并将输入投影到流形一致的理想参考上，然后使用产生的残差作为鲁棒检测信号。

Result: MIRROR在14个基准测试中持续优于现有方法，在六个标准基准测试上提高了2.1%，在七个实际应用基准测试上提高了8.1%。在引入的Human-AIGI基准测试上，MIRROR在27个生成器上达到了89.6%的准确率，超过了普通用户和视觉专家。

Conclusion: MIRROR框架通过利用现实世界规律的稳定信号，提供了一种更通用的AIGI检测方法，并且在接近人类感知极限方面表现出色，有望在未来替代人类专家进行媒体安全验证。

Abstract: High-fidelity generative models have narrowed the perceptual gap between synthetic and real images, posing serious threats to media security. Most existing AI-generated image (AIGI) detectors rely on artifact-based classification and struggle to generalize to evolving generative traces. In contrast, human judgment relies on stable real-world regularities, with deviations from the human cognitive manifold serving as a more generalizable signal of forgery. Motivated by this insight, we reformulate AIGI detection as a Reference-Comparison problem that verifies consistency with the real-image manifold rather than fitting specific forgery cues. We propose MIRROR (Manifold Ideal Reference ReconstructOR), a framework that explicitly encodes reality priors using a learnable discrete memory bank. MIRROR projects an input into a manifold-consistent ideal reference via sparse linear combination, and uses the resulting residuals as robust detection signals. To evaluate whether detectors reach the "superhuman crossover" required to replace human experts, we introduce the Human-AIGI benchmark, featuring a psychophysically curated human-imperceptible subset. Across 14 benchmarks, MIRROR consistently outperforms prior methods, achieving gains of 2.1% on six standard benchmarks and 8.1% on seven in-the-wild benchmarks. On Human-AIGI, MIRROR reaches 89.6% accuracy across 27 generators, surpassing both lay users and visual experts, and further approaching the human perceptual limit as pretrained backbones scale. The code is publicly available at: https://github.com/349793927/MIRROR

</details>


### [418] [Evaluating OCR Performance for Assistive Technology: Effects of Walking Speed, Camera Placement, and Camera Type](https://arxiv.org/abs/2602.02223)
*Junchi Feng,Nikhil Ballem,Mahya Beheshti,Giles Hamilton-Fletcher,Todd Hudson,Maurizio Porfiri,William H. Seiple,John-Ross Rizzo*

Main category: cs.CV

TL;DR: 本研究系统评估了OCR在静态和动态条件下的性能，发现在行走速度加快和视角增大时，识别精度下降。Google Vision整体精度最高，PaddleOCR是表现最佳的开源选项。手机主摄像头表现最好，肩部佩戴方式略优于头部和手持。


<details>
  <summary>Details</summary>
Motivation: 现有的OCR评估多依赖静态数据集，未能反映移动场景下的实际挑战，尤其是在辅助视障人士方面的应用。

Method: 在静态条件下，测试了1-7米距离和0-75度视角下的OCR检测范围。在动态条件下，研究了0.8-1.8米/秒的行走速度以及头戴、肩戴、手持三种相机佩戴方式对OCR性能的影响。评估了智能手机（主摄像头和超广角摄像头）和智能眼镜，并对Google Vision, PaddleOCR 3.0, EasyOCR, Tesseract四款OCR引擎进行了基准测试。使用Levenshtein ratio计算字符级别的准确率。

Result: 识别精度随行走速度的增加和视角的扩大而降低。Google Vision整体精度最高，PaddleOCR 3.0紧随其后。手机主摄像头精度最高，肩部佩戴位置的平均精度最高，但肩部、头部和手持之间的差异不具有统计学意义。

Conclusion: 移动场景下的OCR性能受到行走速度和视角的影响。Google Vision和PaddleOCR 3.0在性能上表现突出，为移动应用提供了有力的选择。对于设备和佩戴方式，手机主摄像头和肩部佩戴是较优方案。

Abstract: Optical character recognition (OCR), which converts printed or handwritten text into machine-readable form, is widely used in assistive technology for people with blindness and low vision. Yet, most evaluations rely on static datasets that do not reflect the challenges of mobile use. In this study, we systematically evaluated OCR performance under both static and dynamic conditions. Static tests measured detection range across distances of 1-7 meters and viewing angles of 0-75 degrees horizontally. Dynamic tests examined the impact of motion by varying walking speed from slow (0.8 m/s) to very fast (1.8 m/s) and comparing three camera mounting positions: head-mounted, shoulder-mounted, and hand-held. We evaluated both a smartphone and smart glasses, using the phone's main and ultra-wide cameras. Four OCR engines were benchmarked to assess accuracy at different distances and viewing angles: Google Vision, PaddleOCR 3.0, EasyOCR, and Tesseract. PaddleOCR 3.0 was then used to evaluate accuracy at different walking speeds. Accuracy was computed at the character level using the Levenshtein ratio against manually defined ground truth. Results showed that recognition accuracy declined with increased walking speed and wider viewing angles. Google Vision achieved the highest overall accuracy, with PaddleOCR close behind as the strongest open-source alternative. Across devices, the phone's main camera achieved the highest accuracy, and a shoulder-mounted placement yielded the highest average among body positions; however, differences among shoulder, head, and hand were not statistically significant.

</details>


### [419] [Show, Don't Tell: Morphing Latent Reasoning into Image Generation](https://arxiv.org/abs/2602.02227)
*Harold Haodong Chen,Xinxiang Yin,Wen-Jie Shu,Hongfei Zhang,Zixin Zhang,Chenfei Liao,Litao Guo,Qifeng Chen,Ying-Cong Chen*

Main category: cs.CV

TL;DR: LatentMorph是一个新颖的文本到图像生成框架，它通过在连续的潜在空间中进行隐式推理，实现了更动态、更具创造性的生成过程，克服了现有方法在效率和信息损失方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成方法在动态推理和精炼方面能力不足，这与人类创造力相悖。现有的推理增强方法依赖于显式的、离散的文本推理，效率低下且存在信息丢失和认知不匹配问题。

Method: LatentMorph框架在连续的潜在空间中进行隐式推理，包含四个轻量级组件：(i) 压缩器（condenser）总结中间生成状态到紧凑的视觉记忆；(ii) 翻译器（translator）将潜在思维转化为可操作的指导；(iii) 塑形器（shaper）动态引导下一个图像token的预测；(iv) RL训练的调用器（invoker）自适应地决定何时调用推理。

Result: LatentMorph在Janus-Pro基础模型上，GenEval提升16%，T2I-CompBench提升25%。在抽象推理任务（如WISE和IPV-Txt）上，比TwiG等显式范例分别提升15%和11%。同时，推理时间减少44%，token消耗减少51%。在推理调用方面，与人类直觉的认知一致性达到71%。

Conclusion: LatentMorph通过将推理过程完全置于连续潜在空间中，避免了显式推理的瓶颈，实现了更自适应的自我精炼，显著提升了文本到图像生成的性能和效率，并且在认知上更符合人类的推理方式。

Abstract: Text-to-image (T2I) generation has achieved remarkable progress, yet existing methods often lack the ability to dynamically reason and refine during generation--a hallmark of human creativity. Current reasoning-augmented paradigms most rely on explicit thought processes, where intermediate reasoning is decoded into discrete text at fixed steps with frequent image decoding and re-encoding, leading to inefficiencies, information loss, and cognitive mismatches. To bridge this gap, we introduce LatentMorph, a novel framework that seamlessly integrates implicit latent reasoning into the T2I generation process. At its core, LatentMorph introduces four lightweight components: (i) a condenser for summarizing intermediate generation states into compact visual memory, (ii) a translator for converting latent thoughts into actionable guidance, (iii) a shaper for dynamically steering next image token predictions, and (iv) an RL-trained invoker for adaptively determining when to invoke reasoning. By performing reasoning entirely in continuous latent spaces, LatentMorph avoids the bottlenecks of explicit reasoning and enables more adaptive self-refinement. Extensive experiments demonstrate that LatentMorph (I) enhances the base model Janus-Pro by $16\%$ on GenEval and $25\%$ on T2I-CompBench; (II) outperforms explicit paradigms (e.g., TwiG) by $15\%$ and $11\%$ on abstract reasoning tasks like WISE and IPV-Txt, (III) while reducing inference time by $44\%$ and token consumption by $51\%$; and (IV) exhibits $71\%$ cognitive alignment with human intuition on reasoning invocation.

</details>


### [420] [LiFlow: Flow Matching for 3D LiDAR Scene Completion](https://arxiv.org/abs/2602.02232)
*Andrea Matteazzi,Dietmar Tutsch*

Main category: cs.CV

TL;DR: 本文提出了 LiFlow，一个用于 3D LiDAR 场景补全的流匹配框架，解决了现有扩散模型中训练与推理初始分布不匹配的问题，并在多个指标上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 3D LiDAR 场景补全方法（特别是基于扩散模型的方法）在训练和推理阶段存在初始分布不匹配的问题，这限制了其性能，尤其是在自动驾驶面临的遮挡和长距离稀疏性等挑战下。

Method: 该研究引入了第一个用于 3D LiDAR 场景补全的流匹配框架。模型使用最近邻流匹配损失和 Chamfer 距离损失，以确保训练和推理之间的一致性分布，并改善点云的局部结构和全局覆盖。

Result: LiFlow 在多个评估指标上实现了最先进的性能，表明其在 3D LiDAR 场景补全方面的有效性。

Conclusion: 流匹配框架是解决 3D LiDAR 场景补全中扩散模型面临的初始分布不匹配问题的有效途径，LiFlow 相比现有方法取得了显著的改进，并达到了行业领先水平。

Abstract: In autonomous driving scenarios, the collected LiDAR point clouds can be challenged by occlusion and long-range sparsity, limiting the perception of autonomous driving systems. Scene completion methods can infer the missing parts of incomplete 3D LiDAR scenes. Recent methods adopt local point-level denoising diffusion probabilistic models, which require predicting Gaussian noise, leading to a mismatch between training and inference initial distributions. This paper introduces the first flow matching framework for 3D LiDAR scene completion, improving upon diffusion-based methods by ensuring consistent initial distributions between training and inference. The model employs a nearest neighbor flow matching loss and a Chamfer distance loss to enhance both local structure and global coverage in the alignment of point clouds. LiFlow achieves state-of-the-art performance across multiple metrics. Code: https://github.com/matteandre/LiFlow.

</details>


### [421] [Enhancing Indoor Occupancy Prediction via Sparse Query-Based Multi-Level Consistent Knowledge Distillation](https://arxiv.org/abs/2602.02318)
*Xiang Li,Yupeng Zheng,Pengfei Li,Yilun Chen,Ya-Qin Zhang,Wenchao Ding*

Main category: cs.CV

TL;DR: 本文提出了一种名为 DiScene 的稀疏查询式框架，通过多层蒸馏实现高效鲁棒的场景占用预测，在不依赖深度信息的情况下性能优于现有方法，并结合深度信息后达到新的 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 现有密集型占用预测方法存在计算效率低的问题，而稀疏查询式方法在复杂室内场景下鲁棒性不足。因此，需要一种既高效又鲁棒的占用预测方法。

Method: DiScene 提出了一种多层一致性知识蒸馏策略，将来自大型教师模型的层级表示通过四层（编码器、查询、先验、锚点）的协调对齐，转移到轻量级学生模型。同时，采用教师引导初始化策略加速模型收敛。

Result: 在 Occ-Scannet 基准测试中，DiScene 在不使用深度先验的情况下，实现了 23.2 FPS，性能比基线 OPUS 提升 36.1%，并优于使用深度信息的 OPUS†。结合深度信息后，DiScene† 性能超越 EmbodiedOcc 3.7%，推理速度快 1.62 倍。在 Occ3D-nuScenes 和野外场景测试中也表现出良好的通用性。

Conclusion: DiScene 通过多层蒸馏和教师引导初始化，有效解决了稀疏查询式占用预测的效率和鲁棒性问题，在多种场景下均取得了优异的性能，并达到了新的 SOTA 水平。

Abstract: Occupancy prediction provides critical geometric and semantic understanding for robotics but faces efficiency-accuracy trade-offs. Current dense methods suffer computational waste on empty voxels, while sparse query-based approaches lack robustness in diverse and complex indoor scenes. In this paper, we propose DiScene, a novel sparse query-based framework that leverages multi-level distillation to achieve efficient and robust occupancy prediction. In particular, our method incorporates two key innovations: (1) a Multi-level Consistent Knowledge Distillation strategy, which transfers hierarchical representations from large teacher models to lightweight students through coordinated alignment across four levels, including encoder-level feature alignment, query-level feature matching, prior-level spatial guidance, and anchor-level high-confidence knowledge transfer and (2) a Teacher-Guided Initialization policy, employing optimized parameter warm-up to accelerate model convergence. Validated on the Occ-Scannet benchmark, DiScene achieves 23.2 FPS without depth priors while outperforming our baseline method, OPUS, by 36.1% and even better than the depth-enhanced version, OPUS†. With depth integration, DiScene† attains new SOTA performance, surpassing EmbodiedOcc by 3.7% with 1.62$\times$ faster inference speed. Furthermore, experiments on the Occ3D-nuScenes benchmark and in-the-wild scenarios demonstrate the versatility of our approach in various environments. Code and models can be accessed at https://github.com/getterupper/DiScene.

</details>


### [422] [NAB: Neural Adaptive Binning for Sparse-View CT reconstruction](https://arxiv.org/abs/2602.02356)
*Wangduo Xie,Matthew B. Blaschko*

Main category: cs.CV

TL;DR: 提出了一种名为NAB（Neural Adaptive Binning）的新方法，通过将矩形先验知识集成到稀疏视图CT重建中，提高了重建质量，特别适用于具有矩形结构的工业物体。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏视图CT重建的隐式神经网络方法无法利用物体的形状先验。工业物体通常具有矩形结构，利用这一先验可以提高重建精度并降低成本。

Method: 提出NAB方法，首先将坐标空间映射到分箱向量空间，该映射基于偏移双曲正切函数的差值，并允许围绕输入平面法向量进行旋转。然后，神经网络处理这些表示来预测CT衰减系数。通过梯度流对编码参数（位置、大小、陡度、旋转）进行端到端优化。通过调整分箱函数的平滑度，NAB可以泛化到更复杂的几何形状。

Result: NAB在两个工业数据集上实现了优于现有方法的性能。当分箱函数扩展到更通用的表达式时，NAB在医学数据集上也表现出鲁棒性。

Conclusion: NAB提供了一种将形状先验集成到基于神经网络的CT重建中的新方法，特别适用于具有矩形结构的工业物体，能够有效提高重建精度。

Abstract: Computed Tomography (CT) plays a vital role in inspecting the internal structures of industrial objects. Furthermore, achieving high-quality CT reconstruction from sparse views is essential for reducing production costs. While classic implicit neural networks have shown promising results for sparse reconstruction, they are unable to leverage shape priors of objects. Motivated by the observation that numerous industrial objects exhibit rectangular structures, we propose a novel \textbf{N}eural \textbf{A}daptive \textbf{B}inning (\textbf{NAB}) method that effectively integrates rectangular priors into the reconstruction process. Specifically, our approach first maps coordinate space into a binned vector space. This mapping relies on an innovative binning mechanism based on differences between shifted hyperbolic tangent functions, with our extension enabling rotations around the input-plane normal vector. The resulting representations are then processed by a neural network to predict CT attenuation coefficients. This design enables end-to-end optimization of the encoding parameters -- including position, size, steepness, and rotation -- via gradient flow from the projection data, thus enhancing reconstruction accuracy. By adjusting the smoothness of the binning function, NAB can generalize to objects with more complex geometries. This research provides a new perspective on integrating shape priors into neural network-based reconstruction. Extensive experiments demonstrate that NAB achieves superior performance on two industrial datasets. It also maintains robust on medical datasets when the binning function is extended to more general expression. The code will be made available.

</details>


### [423] [LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization](https://arxiv.org/abs/2602.02341)
*Zhenpeng Huang,Jiaqi Li,Zihan Jia,Xinhao Li,Desen Meng,Lingxue Song,Xi Chen,Liang Li,Limin Wang*

Main category: cs.CV

TL;DR: LongVPO是一个创新的两阶段直接偏好优化框架，使短上下文视觉语言模型能够无需长视频标注就能鲁棒地理解超长视频。它通过合成偏好三元组、近似参考模型评分、生成场景级元数据以及构建多片段推理查询等方法，实现了高效的长视频理解，并在多个基准测试中超越了现有模型，同时保持了短视频性能。


<details>
  <summary>Details</summary>
Motivation: 现有短上下文视觉语言模型在理解超长视频时存在局限性，而长视频标注成本高昂。研究旨在开发一种无需长视频标注即可实现长视频理解的方法。

Method: LongVPO采用两阶段直接偏好优化框架。第一阶段通过将问题锚定到单个短片段并过滤掉干扰项来合成偏好三元组，并通过评估锚定片段来近似参考模型在长上下文中的评分。第二阶段利用递归字幕生成场景级元数据，然后使用大型语言模型生成多片段推理查询和不良响应，通过多片段推理任务来对齐模型偏好。

Result: LongVPO仅使用16K合成示例，无需昂贵的人工标签，在多个长视频基准测试中超越了最先进的开源模型，并在短视频性能（如MVBench）上保持了强大的能力。

Conclusion: LongVPO提供了一种可扩展的、高效的长视频理解范式，能够使短上下文模型鲁棒地理解超长视频，并且在成本效益和性能方面均表现出色。

Abstract: We present LongVPO, a novel two-stage Direct Preference Optimization framework that enables short-context vision-language models to robustly understand ultra-long videos without any long-video annotations. In Stage 1, we synthesize preference triples by anchoring questions to individual short clips, interleaving them with distractors, and applying visual-similarity and question-specificity filtering to mitigate positional bias and ensure unambiguous supervision. We also approximate the reference model's scoring over long contexts by evaluating only the anchor clip, reducing computational overhead. In Stage 2, we employ a recursive captioning pipeline on long videos to generate scene-level metadata, then use a large language model to craft multi-segment reasoning queries and dispreferred responses, aligning the model's preferences through multi-segment reasoning tasks. With only 16K synthetic examples and no costly human labels, LongVPO outperforms the state-of-the-art open-source models on multiple long-video benchmarks, while maintaining strong short-video performance (e.g., on MVBench), offering a scalable paradigm for efficient long-form video understanding.

</details>


### [424] [Personalized Image Generation via Human-in-the-loop Bayesian Optimization](https://arxiv.org/abs/2602.02388)
*Rajalaxmi Rajagopalan,Debottam Dutta,Yu-Lin Wei,Romit Roy Choudhury*

Main category: cs.CV

TL;DR: 本文提出了一种名为 MultiBO 的新方法，通过多轮用户偏好反馈来优化生成模型，使其能够生成更接近用户心中特定图像的图像。


<details>
  <summary>Details</summary>
Motivation: 现有语言提示在引导生成模型生成用户心中精确图像时存在局限性，即使生成图像与目标图像接近，仍难以完全闭合差距。人类可以通过比较图像的接近程度来提供更细粒度的反馈。

Method: MultiBO 方法首先生成 K 张候选图像，然后收集用户对这些图像的偏好反馈，并利用这些反馈来指导扩散模型进行优化，不断生成更接近目标的新图像。

Result: 在 B 轮用户反馈后，MultiBO 能够生成比基线方法更接近用户心中目标图像的结果，即使生成模型本身不知道目标图像的具体信息。用户评分和定量指标均显示出优于基线方法的潜力。

Conclusion: 多项选择的偏好反馈可以有效地用于个性化图像生成，能够弥合语言提示的局限性，帮助生成模型更准确地捕捉用户心中期望的图像。

Abstract: Imagine Alice has a specific image $x^\ast$ in her mind, say, the view of the street in which she grew up during her childhood. To generate that exact image, she guides a generative model with multiple rounds of prompting and arrives at an image $x^{p*}$. Although $x^{p*}$ is reasonably close to $x^\ast$, Alice finds it difficult to close that gap using language prompts. This paper aims to narrow this gap by observing that even after language has reached its limits, humans can still tell when a new image $x^+$ is closer to $x^\ast$ than $x^{p*}$. Leveraging this observation, we develop MultiBO (Multi-Choice Preferential Bayesian Optimization) that carefully generates $K$ new images as a function of $x^{p*}$, gets preferential feedback from the user, uses the feedback to guide the diffusion model, and ultimately generates a new set of $K$ images. We show that within $B$ rounds of user feedback, it is possible to arrive much closer to $x^\ast$, even though the generative model has no information about $x^\ast$. Qualitative scores from $30$ users, combined with quantitative metrics compared across $5$ baselines, show promising results, suggesting that multi-choice feedback from humans can be effectively harnessed for personalized image generation.

</details>


### [425] [Unified Personalized Reward Model for Vision Generation](https://arxiv.org/abs/2602.02380)
*Yibin Wang,Yuhang Zang,Feng Han,Jiazi Bu,Yujie Zhou,Cheng Jin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 UnifiedReward-Flex 的统一化、个性化奖励模型，用于解决现有视觉生成奖励模型对内容不敏感、无法适应主观和情境化人类偏好的问题。该模型通过将奖励建模与灵活、情境自适应的推理相结合，能根据提示和生成的视觉内容，动态构建层级化评估。


<details>
  <summary>Details</summary>
Motivation: 现有用于视觉生成的奖励模型（RMs）存在“一刀切”的局限性，无法捕捉内容特定的视觉线索，导致与主观和情境化的人类偏好不一致。

Method: UnifiedReward-Flex 首先解析语义意图并基于视觉证据，然后通过实例化预定义和自生成的高层维度下的细粒度标准，动态构建层级化评估。训练采用两阶段过程：1. 从先进的闭源视觉语言模型（VLMs）蒸馏结构化的推理轨迹以进行监督式微调（SFT）；2. 对精心策划的偏好对进行直接偏好优化（DPO）。

Result: 将 UnifiedReward-Flex 集成到 GRPO 框架中进行图像和视频合成，实验结果表明其优于现有方法。

Conclusion: UnifiedReward-Flex 是一种有效的统一化、个性化奖励模型，能够通过灵活且情境自适应的推理，更好地对齐主观和情境化的人类偏好，从而提升视觉生成模型的性能。

Abstract: Recent advancements in multimodal reward models (RMs) have significantly propelled the development of visual generation. Existing frameworks typically adopt Bradley-Terry-style preference modeling or leverage generative VLMs as judges, and subsequently optimize visual generation models via reinforcement learning. However, current RMs suffer from inherent limitations: they often follow a one-size-fits-all paradigm that assumes a monolithic preference distribution or relies on fixed evaluation rubrics. As a result, they are insensitive to content-specific visual cues, leading to systematic misalignment with subjective and context-dependent human preferences. To this end, inspired by human assessment, we propose UnifiedReward-Flex, a unified personalized reward model for vision generation that couples reward modeling with flexible and context-adaptive reasoning. Specifically, given a prompt and the generated visual content, it first interprets the semantic intent and grounds on visual evidence, then dynamically constructs a hierarchical assessment by instantiating fine-grained criteria under both predefined and self-generated high-level dimensions. Our training pipeline follows a two-stage process: (1) we first distill structured, high-quality reasoning traces from advanced closed-source VLMs to bootstrap SFT, equipping the model with flexible and context-adaptive reasoning behaviors; (2) we then perform direct preference optimization (DPO) on carefully curated preference pairs to further strengthen reasoning fidelity and discriminative alignment. To validate the effectiveness, we integrate UnifiedReward-Flex into the GRPO framework for image and video synthesis, and extensive results demonstrate its superiority.

</details>


### [426] [Uncertainty-Aware Image Classification In Biomedical Imaging Using Spectral-normalized Neural Gaussian Processes](https://arxiv.org/abs/2602.02370)
*Uma Meleti,Jeffrey J. Nirschl*

Main category: cs.CV

TL;DR: 本文提出了一种名为 SNGP 的轻量级模型，用于提高数字病理学中深度学习模型对分布外（OOD）数据的检测和不确定性估计能力，以增强临床应用的可信度。


<details>
  <summary>Details</summary>
Motivation: 当前数字病理学中的深度学习模型在分布外（OOD）数据上表现出过度自信且校准不良的问题，这限制了其在临床中的应用和信任度。安全关键的医学影像工作流需要能够准确拒绝 OOD 输入的不确定性感知能力。

Method: 通过对模型进行轻量级修改，包括应用谱归一化（spectral normalization）并用高斯过程层（Gaussian process layer）替换最后一层全连接层，来实现 Spectral-normalized Neural Gaussian Process (SNGP) 模型，以提升单模型的不确定性估计和 OOD 检测能力。

Result: 在白细胞、淀粉样蛋白斑块和结直肠组织病理学三个生物医学分类任务的六个数据集上，SNGP 模型在分布内（in-distribution）性能上与确定性模型和蒙特卡洛 Dropout 模型相当，但显著改善了不确定性估计和 OOD 检测能力。

Conclusion: SNGP 模型或相关模型为数字病理学中的不确定性感知分类提供了一个有用的框架，能够支持模型的安全部署并增强病理学家对模型的信任。

Abstract: Accurate histopathologic interpretation is key for clinical decision-making; however, current deep learning models for digital pathology are often overconfident and poorly calibrated in out-of-distribution (OOD) settings, which limit trust and clinical adoption. Safety-critical medical imaging workflows benefit from intrinsic uncertainty-aware properties that can accurately reject OOD input. We implement the Spectral-normalized Neural Gaussian Process (SNGP), a set of lightweight modifications that apply spectral normalization and replace the final dense layer with a Gaussian process layer to improve single-model uncertainty estimation and OOD detection. We evaluate SNGP vs. deterministic and MonteCarlo dropout on six datasets across three biomedical classification tasks: white blood cells, amyloid plaques, and colorectal histopathology. SNGP has comparable in-distribution performance while significantly improving uncertainty estimation and OOD detection. Thus, SNGP or related models offer a useful framework for uncertainty-aware classification in digital pathology, supporting safe deployment and building trust with pathologists.

</details>


### [427] [Superman: Unifying Skeleton and Vision for Human Motion Perception and Generation](https://arxiv.org/abs/2602.02401)
*Xinshun Wang,Peiming Li,Ziyi Wang,Zhongbin Fang,Zhichao Deng,Songtao Wu,Jason Li,Mengyuan Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为Superman的统一框架，用于解决现有视觉动作分析任务碎片化的问题，该框架能够融合视觉感知和时序动作生成，并在多项任务上达到了先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有动作分析方法存在碎片化问题：感知模型（从视频理解动作但只输出文本）和生成模型（不能从原始视觉输入感知）相互独立；生成式多模态大语言模型（MLLM）通常仅限于单帧静态姿势；现有的动作词汇表仅基于骨骼数据，脱离了视觉领域。作者希望构建一个统一的框架来解决这些问题。

Method: Superman框架包含两个主要部分：1. 视觉引导动作分词器（Vision-Guided Motion Tokenizer），用于克服模态鸿沟，实现3D骨骼与视觉数据的联合学习，创建统一的跨模态动作词汇表。2. 基于此动作语言的统一MLLM架构，能够灵活处理多样化的时序输入，统一3D骨骼姿态估计（感知）和骨骼动作预测与插值（生成）。

Result: 在Human3.6M等标准数据集上的大量实验表明，Superman框架在所有动作任务上均取得了最先进或有竞争力的性能。

Conclusion: Superman框架成功地实现了视觉感知与时序骨骼动作生成之间的统一，为使用骨骼进行生成式动作分析提供了一条更有效、更具扩展性的路径。

Abstract: Human motion analysis tasks, such as temporal 3D pose estimation, motion prediction, and motion in-betweening, play an essential role in computer vision. However, current paradigms suffer from severe fragmentation. First, the field is split between ``perception'' models that understand motion from video but only output text, and ``generation'' models that cannot perceive from raw visual input. Second, generative MLLMs are often limited to single-frame, static poses using dense, parametric SMPL models, failing to handle temporal motion. Third, existing motion vocabularies are built from skeleton data alone, severing the link to the visual domain. To address these challenges, we introduce Superman, a unified framework that bridges visual perception with temporal, skeleton-based motion generation. Our solution is twofold. First, to overcome the modality disconnect, we propose a Vision-Guided Motion Tokenizer. Leveraging the natural geometric alignment between 3D skeletons and visual data, this module pioneers robust joint learning from both modalities, creating a unified, cross-modal motion vocabulary. Second, grounded in this motion language, a single, unified MLLM architecture is trained to handle all tasks. This module flexibly processes diverse, temporal inputs, unifying 3D skeleton pose estimation from video (perception) with skeleton-based motion prediction and in-betweening (generation). Extensive experiments on standard benchmarks, including Human3.6M, demonstrate that our unified method achieves state-of-the-art or competitive performance across all motion tasks. This showcases a more efficient and scalable path for generative motion analysis using skeletons.

</details>


### [428] [SelvaMask: Segmenting Trees in Tropical Forests and Beyond](https://arxiv.org/abs/2602.02426)
*Simon-Olivier Duguay,Hugo Baudchon,Etienne Laliberté,Helene Muller-Landau,Gonzalo Rivas-Torres,Arthur Ouaknine*

Main category: cs.CV

TL;DR: 研究人员提出了SelvaMask，一个包含8,800多个手动描绘的热带森林树冠的大型数据集，并开发了一个新的检测-分割流水线，该流水线利用领域特定的检测提示器来改进视觉基础模型，从而在密集的热带森林中实现了最先进的个体树冠分割性能。


<details>
  <summary>Details</summary>
Motivation: 尽管在个体树冠分割方面取得了进展，但现有模型在热带森林中的性能仍然很低，这阻碍了对这些关键生态系统的大规模研究。因此，需要一个新的数据集和更有效的方法来准确描绘热带森林中的树冠。

Method: 研究人员创建了一个名为SelvaMask的新数据集，其中包含来自巴拿马、巴西和厄瓜多尔三个新热带森林地点的8,800多个手动描绘的树冠。他们还提出了一种模块化的检测-分割流水线，该流水线通过使用领域特定的检测提示器来适应视觉基础模型（VFMs）。

Result: SelvaMask数据集在新热带森林中实现了高水平的准确性，并具有详细的标注和注释者间一致性评估。他们提出的流水线在密集的热带森林中取得了最先进的性能，优于零样本通用模型和全监督端到端方法。

Conclusion: SelvaMask是一个具有挑战性的基准，可以促进热带森林个体树冠分割的研究。他们提出的流水线有效地适应了VFMs，并在不同森林数据集上证明了其泛化能力，有望成为通用森林监测的关键工具。

Abstract: Tropical forests harbor most of the planet's tree biodiversity and are critical to global ecological balance. Canopy trees in particular play a disproportionate role in carbon storage and functioning of these ecosystems. Studying canopy trees at scale requires accurate delineation of individual tree crowns, typically performed using high-resolution aerial imagery. Despite advances in transformer-based models for individual tree crown segmentation, performance remains low in most forests, especially tropical ones. To this end, we introduce SelvaMask, a new tropical dataset containing over 8,800 manually delineated tree crowns across three Neotropical forest sites in Panama, Brazil, and Ecuador. SelvaMask features comprehensive annotations, including an inter-annotator agreement evaluation, capturing the dense structure of tropical forests and highlighting the difficulty of the task. Leveraging this benchmark, we propose a modular detection-segmentation pipeline that adapts vision foundation models (VFMs), using domain-specific detection-prompter. Our approach reaches state-of-the-art performance, outperforming both zero-shot generalist models and fully supervised end-to-end methods in dense tropical forests. We validate these gains on external tropical and temperate datasets, demonstrating that SelvaMask serves as both a challenging benchmark and a key enabler for generalized forest monitoring. Our code and dataset will be released publicly.

</details>


### [429] [Catalyst: Out-of-Distribution Detection via Elastic Scaling](https://arxiv.org/abs/2602.02409)
*Abid Hassan,Tuan Ngo,Saad Shafiq,Nenad Medvidovic*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Catalyst 的新颖后处理框架，用于 out-of-distribution (OOD) 检测。Catalyst 利用预池化特征图的原始通道统计信息（如均值、标准差和最大激活值）来计算一个输入相关的缩放因子 γ，该因子通过乘法方式增强现有的 OOD 检测得分，从而拉开 ID 和 OOD 分布的距离。实验证明 Catalyst 可以与现有方法（如基于 Logit 的方法和 KNN）有效结合，并在多个数据集上显著提升 OOD 检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的 OOD 检测方法主要依赖于输出 logits 或全局平均池化（GAP）后的特征向量，忽略了 GAP 操作丢失的、原始特征图中的丰富信息（即通道级别统计信息）。研究者认为这些被忽视的信号对于提高 OOD 检测性能至关重要。

Method: Catalyst 框架通过计算输入相关的缩放因子 γ 来利用预池化特征图的原始通道统计信息（例如，均值、标准差和最大激活值）。该因子 γ 被用于乘法地调整（“弹性缩放”）现有的 OOD 检测得分，以增强 ID 和 OOD 分布之间的区分度。Catalyst 可以无缝集成到基于 Logit 的方法和基于距离的方法中。

Result: Catalyst 在 CIFAR-10、CIFAR-100 和 ImageNet 数据集上取得了显著的性能提升，平均错误率（FPR）分别降低了 32.87%、27.94% 和 22.25%。该方法与现有的 OOD 检测方法（如 Energy、ReAct、SCALE 和 KNN）具有良好的兼容性。

Conclusion: 预池化特征图的通道级别统计信息蕴含着未被充分挖掘的 OOD 检测潜力。Catalyst 框架通过有效利用这些信息，可以作为一种即插即用的模块，显著增强现有 OOD 检测方法的性能，为安全部署深度神经网络提供了新的途径。

Abstract: Out-of-distribution (OOD) detection is critical for the safe deployment of deep neural networks. State-of-the-art post-hoc methods typically derive OOD scores from the output logits or penultimate feature vector obtained via global average pooling (GAP). We contend that this exclusive reliance on the logit or feature vector discards a rich, complementary signal: the raw channel-wise statistics of the pre-pooling feature map lost in GAP. In this paper, we introduce Catalyst, a post-hoc framework that exploits these under-explored signals. Catalyst computes an input-dependent scaling factor ($γ$) on-the-fly from these raw statistics (e.g., mean, standard deviation, and maximum activation). This $γ$ is then fused with the existing baseline score, multiplicatively modulating it -- an ``elastic scaling'' -- to push the ID and OOD distributions further apart. We demonstrate Catalyst is a generalizable framework: it seamlessly integrates with logit-based methods (e.g., Energy, ReAct, SCALE) and also provides a significant boost to distance-based detectors like KNN. As a result, Catalyst achieves substantial and consistent performance gains, reducing the average False Positive Rate by 32.87 on CIFAR-10 (ResNet-18), 27.94% on CIFAR-100 (ResNet-18), and 22.25% on ImageNet (ResNet-50). Our results highlight the untapped potential of pre-pooling statistics and demonstrate that Catalyst is complementary to existing OOD detection approaches.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [430] [PPoGA: Predictive Plan-on-Graph with Action for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.00007)
*MinGyu Jeon,SuWan Cho,JaeYoung Shu*

Main category: cs.CL

TL;DR: 提出了一种名为PPoGA的新型知识图谱问答（KGQA）框架，通过引入预测处理和自纠正机制，使其能够修正错误的推理计划，从而提高了复杂问答的鲁棒性和灵活性，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的大语言模型（LLM）在处理复杂问答时，当初始推理计划错误时容易失败，无法进行有效的策略调整，如同认知上的功能固着。

Method: PPoGA采用了规划-执行器架构，分离高层策略与低层执行；引入预测处理机制来预判结果；核心创新在于一个自纠正机制，不仅能进行局部路径纠正，还能识别、放弃并重构整个无效的推理计划。

Result: 在GrailQA、CWQ和WebQSP这三个具有挑战性的多跳KGQA基准测试上进行了广泛实验，PPoGA取得了最先进的性能，显著优于现有方法。

Conclusion: PPoGA证明了类似人类元认知能力（如问题重构）对于构建更鲁棒和灵活的AI推理系统的关键重要性。

Abstract: Large Language Models (LLMs) augmented with Knowledge Graphs (KGs) have advanced complex question answering, yet they often remain susceptible to failure when their initial high-level reasoning plan is flawed. This limitation, analogous to cognitive functional fixedness, prevents agents from restructuring their approach, leading them to pursue unworkable solutions. To address this, we propose PPoGA (Predictive Plan-on-Graph with Action), a novel KGQA framework inspired by human cognitive control and problem-solving. PPoGA incorporates a Planner-Executor architecture to separate high-level strategy from low-level execution and leverages a Predictive Processing mechanism to anticipate outcomes. The core innovation of our work is a self-correction mechanism that empowers the agent to perform not only Path Correction for local execution errors but also Plan Correction by identifying, discarding, and reformulating the entire plan when it proves ineffective. We conduct extensive experiments on three challenging multi-hop KGQA benchmarks: GrailQA, CWQ, and WebQSP. The results demonstrate that PPoGA achieves state-of-the-art performance, significantly outperforming existing methods. Our work highlights the critical importance of metacognitive abilities like problem restructuring for building more robust and flexible AI reasoning systems.

</details>


### [431] [Unlocking Electronic Health Records: A Hybrid Graph RAG Approach to Safe Clinical AI for Patient QA](https://arxiv.org/abs/2602.00009)
*Samuel Thio,Matthew Lewis,Spiros Denaxas,Richard JB Dobson*

Main category: cs.CL

TL;DR: 本文提出了一种名为 MediGRAF 的混合图检索增强框架，通过结合结构化数据查询和非结构化文本检索，提高了从电子健康记录（EHR）中检索信息的准确性和全面性，尤其是在处理复杂推理任务时。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）中包含大量信息，给临床医生带来了认知负担，容易遗漏关键细节。现有的信息检索方法仅关注结构化数据或非结构化语义搜索，未能同时整合两者，LLM在临床应用中存在上下文接地和幻觉问题。

Method: MediGRAF 使用 Neo4j 的 Text2Cypher 能力进行结构化关系遍历，并结合向量嵌入进行非结构化叙事检索，从而实现对完整患者病程的自然语言查询。该系统在 MIMIC-IV 数据集上进行了评估。

Result: 在 MIMIC-IV 数据集上，MediGRAF 在事实性查询中实现了 100% 的召回率，在复杂推理任务中取得了 4.25/5 的平均专家评分，并且没有安全违规行为。

Conclusion: 混合图检索增强显著提升了临床信息检索能力，为标准 LLM 部署提供了一种更安全、更全面的替代方案。

Abstract: Electronic health record (EHR) systems present clinicians with vast repositories of clinical information, creating a significant cognitive burden where critical details are easily overlooked. While Large Language Models (LLMs) offer transformative potential for data processing, they face significant limitations in clinical settings, particularly regarding context grounding and hallucinations. Current solutions typically isolate retrieval methods focusing either on structured data (SQL/Cypher) or unstructured semantic search but fail to integrate both simultaneously. This work presents MediGRAF (Medical Graph Retrieval Augmented Framework), a novel hybrid Graph RAG system that bridges this gap. By uniquely combining Neo4j Text2Cypher capabilities for structured relationship traversal with vector embeddings for unstructured narrative retrieval, MediGRAF enables natural language querying of the complete patient journey. Using 10 patients from the MIMIC-IV dataset (generating 5,973 nodes and 5,963 relationships), we generated enough nodes and data for patient level question answering (QA), and we evaluated this architecture across varying query complexities. The system demonstrated 100\% recall for factual queries which means all relevant information was retrieved and in the output, while complex inference tasks achieved a mean expert quality score of 4.25/5 with zero safety violations. These results demonstrate that hybrid graph-grounding significantly advances clinical information retrieval, offering a safer, more comprehensive alternative to standard LLM deployments.

</details>


### [432] [G-MemLLM: Gated Latent Memory Augmentation for Long-Context Reasoning in Large Language Models](https://arxiv.org/abs/2602.00015)
*Xun Xu*

Main category: cs.CL

TL;DR: 提出了一种名为 G-MemLLM 的内存增强型 LLM 架构，通过带有 GRU 式门控更新的潜在内存库来解决 LLM 的长上下文理解和事实一致性问题，并在 HotpotQA 和 ZsRE 任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 在处理长上下文和进行多跳推理时存在上下文窗口容量有限和事实一致性难以维持的问题，现有方法（如上下文压缩或循环标记）存在信息衰减（context rot）的问题。

Method: 提出了 G-MemLLM，一个将冻结的 LLM 主干与可训练的潜在内存库相结合的内存增强架构。其核心创新在于使用 GRU 风格的门控更新逻辑，允许模型选择性地更新、保留或覆盖内存槽，从而避免了传统循环系统中常见的知识梯度消失问题。

Result: 在 HotpotQA 和 Zero-Shot Relation Extraction (ZsRE) 两个基准测试上，G-MemLLM 在不同模型规模（从 GPT-2 到 Llama 3.1）上均取得了显著提升。具体而言，对于 Llama 3.1-8B，ZsRE 准确率提升了 13.3%；在 HotpotQA 上，GPT-2 的 Answer F1 提升了 8.56 个百分点，Llama 3.1-8B 的 Supporting Fact F1 提升了 6.89 个百分点。

Conclusion: G-MemLLM 能够有效增强 LLM 的多跳推理能力和关系抽取精度，通过引入一个具有智能更新机制的潜在内存库，克服了长上下文处理中的信息衰减问题，并且在不同模型规模上都展现出优越的性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, yet they remain constrained by the finite capacity of their context windows and the inherent difficulty of maintaining long-term factual consistency during multi-hop reasoning. While existing methods utilize context compression or recurrent tokens, they often suffer from ``context rot'' or the dilution of information over long horizons. In this paper, we propose \textbf{G-MemLLM}, a memory-augmented architecture that integrates a frozen LLM backbone with a trainable \textbf{Latent Memory Bank}. Our key innovation is a GRU-style gated update logic that allows the model to selectively update, preserve, or overwrite latent memory slots, preventing the vanishing gradients of knowledge common in recurrent systems. We evaluate G-MemLLM across scales, from GPT-2 (124M) to Llama 3.1 (8B), on the HotpotQA and Zero-Shot Relation Extraction (ZsRE) benchmarks. Our results demonstrate that G-MemLLM significantly enhances multi-hop reasoning and relational precision, achieving a 13.3\% accuracy boost on ZsRE for Llama 3.1-8B, and it also yields improvements across model scales, boosting Answer F1 by 8.56 points for GPT-2 and increasing Supporting Fact F1 by 6.89 points for Llama 3.1-8B on HotpotQA.

</details>


### [433] [PTCBENCH: Benchmarking Contextual Stability of Personality Traits in LLM Systems](https://arxiv.org/abs/2602.00016)
*Jiongchi Yu,Yuhan Ma,Xiaoyu Zhang,Junjie Wang,Qiang Hu,Chao Shen,Xiaofei Xie*

Main category: cs.CL

TL;DR: 本研究提出了PTCBENCH基准测试，用于量化大型语言模型（LLMs）在不同情境下的个性一致性，发现特定情境（如“失业”）会导致LLMs的个性和推理能力发生显著变化。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了人格特质是动态且情境依赖的心理学共识，而LLMs在情感智能体中的部署需要保持一致且真实的个性以赢得用户信任。

Method: 构建了PTCBENCH基准测试，该测试包含12种不同的外部情境（包括地点和生活事件），并使用NEO五因素问卷（NEO-FFI）评估LLMs的个性。研究分析了39,240条个性特征记录。

Result: 研究发现，某些外部情境（例如“失业”）会触发LLMs显著的个性变化，甚至影响其推理能力。

Conclusion: PTCBENCH提供了一个可扩展的框架，用于评估LLMs在现实、动态环境中的个性一致性，为开发鲁棒且符合心理学规律的AI系统提供了可操作的见解。

Abstract: With the increasing deployment of large language models (LLMs) in affective agents and AI systems, maintaining a consistent and authentic LLM personality becomes critical for user trust and engagement. However, existing work overlooks a fundamental psychological consensus that personality traits are dynamic and context-dependent. To bridge this gap, we introduce PTCBENCH, a systematic benchmark designed to quantify the consistency of LLM personalities under controlled situational contexts. PTCBENCH subjects models to 12 distinct external conditions spanning diverse location contexts and life events, and rigorously assesses the personality using the NEO Five-Factor Inventory. Our study on 39,240 personality trait records reveals that certain external scenarios (e.g., "Unemployment") can trigger significant personality changes of LLMs, and even alter their reasoning capabilities. Overall, PTCBENCH establishes an extensible framework for evaluating personality consistency in realistic, evolving environments, offering actionable insights for developing robust and psychologically aligned AI systems.

</details>


### [434] [SafeTalkCoach: Diversity-Driven Multi-Agent Simulation for Parent-Teen Health Conversations](https://arxiv.org/abs/2602.00017)
*Benyamin Tabarsi,Wenbo Li,Tahreem Yasir,Aryan Santhosh Kumar,Laura Widman,Dongkuan Xu,Tiffany Barnes*

Main category: cs.CL

TL;DR: 本研究提出了SafeTalkCoach框架和相关数据集，用于生成模拟的亲子性健康对话，以解决现实世界中此类对话数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 父母与子女之间关于性健康的有效沟通至关重要，但由于其私密性和敏感性，这类对话的现实世界数据难以收集。现有的LLM在生成对话时可能存在偏离最佳实践、缺乏真实性和多样性等问题。

Method: SafeTalkCoach是一个多样性驱动的多代理对话生成框架，它整合了众包和合成的场景、既定的性健康指南、基于证据的个性化角色、自适应控制模块以及分层多样化机制，来模拟亲子性健康对话。

Result: 评估结果表明，SafeTalkCoach在保持对话真实性、沟通质量和可控性的同时，能够生成多样化的对话。

Conclusion: SafeTalkCoach框架和数据集有望为人工智能研究和健康传播实践提供支持，促进亲子间更有效的性健康沟通。

Abstract: The importance of effective parent-child communication about sexual health is widely acknowledged, but real-world data on these conversations is scarce and challenging to collect, due to their private and sensitive nature. Although LLMs have been widely adopted in dialogue generation, they may deviate from best practices and frequently lack realism and diversity. We introduce SafeTalkCoach, a diversity-driven multi-agent dialogue generation framework that simulates parent-child conversations about sexual health, and present an accompanying dataset. SafeTalkCoach integrates crowd-sourced and synthesized scenarios, established sexual health guidelines, evidence-based personas, adaptive control modules, and hierarchical diversification. Through evaluations, we demonstrate that SafeTalkCoach generates diverse conversations while maintaining realism, communication quality, and controllability in practice. Our goal is that the SafeTalkCoach framework and the dataset support both AI research and health communications practices.

</details>


### [435] [Construct, Align, and Reason: Large Ontology Models for Enterprise Knowledge Management](https://arxiv.org/abs/2602.00029)
*Yao Zhang,Hongyin Zhu*

Main category: cs.CL

TL;DR: 该论文提出了一个名为LOM（Large Ontology Model）的大型本体模型，用于解决企业知识管理中多源异构数据集成和语义推理的挑战。LOM通过构建双层本体模型并融合结构化和非结构化数据，然后采用三阶段训练流水线（本体指令微调、文本-本体对齐、多任务指令调优）来增强语义推理能力。


<details>
  <summary>Details</summary>
Motivation: 企业级知识管理在集成多源异构数据和实现有效语义推理方面面临挑战。传统的知识图谱在发现隐式关系和进行复杂问答方面存在不足。

Method: 提出了一种统一的“对齐-推理”框架，即大型本体模型（LOM）。首先构建了来自结构化数据库和非结构化文本的双层企业本体，并将这些来源融合为一个全面的企业本体。通过一个统一的三阶段训练流水线来实现指令对齐推理：本体指令微调、文本-本体对齐，以及在本体-语言对上进行具有课程学习的多任务指令调优。

Result: 在构建的基准数据集上，参数量为4B的LOM模型达到了89.47%的准确率，并在复杂图推理方面优于DeepSeek-V3.2。

Conclusion: LOM模型能够有效地融合本体结构和语言信息，解决了企业知识管理中的数据集成和语义推理问题，并在复杂问答任务上取得了优于现有方法的性能。

Abstract: Enterprise-scale knowledge management faces significant challenges in integrating multi-source heterogeneous data and enabling effective semantic reasoning. Traditional knowledge graphs often struggle with implicit relationship discovery and lack sufficient semantic understanding for complex question answering. To address these limitations, we introduce a unified construct--align--reason framework, the large ontology model (LOM). We first build a dual-layer enterprise ontology from structured databases and unstructured text, subsequently fusing these sources into a comprehensive enterprise ontology. To enable instruction-aligned reasoning, we propose a unified three-stage training pipeline: ontology instruction fine-tuning to improve structural understanding; text-ontology grounding to strengthen node semantic encoding; and multi-task instruction tuning on ontology-language pairs with curriculum learning to enhance semantic reasoning and generation. We also construct comprehensive training and evaluation datasets covering diverse ontology reasoning tasks. On this benchmark, our 4B-parameter LOM achieves 89.47% accuracy and outperforms DeepSeek-V3.2 on complex graph reasoning, indicating effective fusion of ontology structure and language.

</details>


### [436] [Reversible Diffusion Decoding for Diffusion Language Models](https://arxiv.org/abs/2602.00150)
*Xinyun Wang,Min Zhang,Sen Cui,Zhikang Chen,Bo Jiang,Kun Kuang,Mingbao Lin*

Main category: cs.CL

TL;DR: 提出了一种名为可逆扩散解码（RDD）的新型解码框架，通过引入可逆性来解决扩散语言模型在块级解码过程中可能出现的停滞问题，提高了生成鲁棒性和质量，同时保持了并行效率。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在进行块级解码时，不可逆的承诺可能导致停滞，即反向扩散过程在次优上下文中无法进一步推进。

Method: RDD 框架通过引入可逆性来解决块级扩散生成中的停滞问题。它将停滞检测为状态依赖性的反向过程失败，并通过缓存的模型状态实现高效回溯，无需重新计算。为了避免重复的失败轨迹，RDD 应用置信度引导的重掩码，选择性地重新初始化不确定的 token，同时保留可靠的上下文。

Result: RDD 实验表明，相比基线方法，RDD 在生成鲁棒性和质量方面有所提高，并且计算开销极小。

Conclusion: RDD 是一种可逆的解码方法，它允许解码过程从早期承诺错误中恢复，同时保持扩散式生成算法的并行效率。

Abstract: Diffusion language models enable parallel token generation through block-wise decoding, but their irreversible commitments can lead to stagnation, where the reverse diffusion process fails to make further progress under a suboptimal context.We propose Reversible Diffusion Decoding (RDD), a decoding framework that introduces reversibility into block-wise diffusion generation. RDD detects stagnation as a state-dependent failure of the reverse process and enables efficient backtracking to earlier blocks without recomputation via cached model states. To avoid repeated failure trajectories, RDD applies confidence-guided re-masking to selectively reinitialize uncertain tokens while preserving reliable context.This reversible formulation allows decoding to recover from early commitment errors while maintaining the parallel efficiency of diffusion-based generation. Experiments show that RDD improves generation robustness and quality over baselines with minimal computational overhead.

</details>


### [437] [DIVERGE: Diversity-Enhanced RAG for Open-Ended Information Seeking](https://arxiv.org/abs/2602.00238)
*Tianyi Hu,Niket Tandon,Akhil Arora*

Main category: cs.CL

TL;DR: 本文提出了DIVERGE框架，一种用于检索增强生成（RAG）的新型即插即用系统，旨在解决现有RAG系统在处理需要多个可能答案的开放式问题时，生成结果单一且缺乏多样性的问题。DIVERGE通过引入“反思引导生成”和“记忆增强迭代精炼”机制，促进了观点的多样性，同时保持了答案的质量。研究还提出了新的评估指标来衡量多样性与质量的权衡，并在Infinity-Chat数据集上验证了DIVERGE的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统主要针对有单一正确答案的查询进行设计，未能充分考虑到现实世界中信息查询场景的多样性需求，即可能存在多个合理答案。这导致现有系统倾向于生成单一的、缺乏创造性的答案，限制了信息获取的包容性和公平性。此外，标准RAG系统未能有效利用检索到的上下文多样性，单独增加检索多样性并不能带来生成结果的多样性。

Method: 提出DIVERGE，一个即插即用的Agentic RAG框架。核心机制包括：1. 反思引导生成（reflection-guided generation）：引导模型在生成过程中进行反思，考虑不同的视角。2. 记忆增强迭代精炼（memory-augmented iterative refinement）：通过记忆机制对生成过程进行多轮迭代优化，以提升多样性。同时，研究者还开发了新的评估指标，用于衡量开放式问题生成结果的多样性-质量权衡，并证明了这些指标与人类判断的相关性。

Result: DIVERGE在Infinity-Chat数据集上展现出优于竞争基线和先前最先进方法的性能，实现了最佳的多样性-质量权衡。相比之下，DIVERGE显著提升了生成结果的多样性，同时保持了答案的质量。

Conclusion: 现有基于LLM的系统在处理开放式信息查询时存在系统性局限，倾向于生成单一答案。通过显式地建模多样性，如DIVERGE框架所示，可以有效缓解这一问题，提高信息查询的创造性、公平性和包容性。

Abstract: Existing retrieval-augmented generation (RAG) systems are primarily designed under the assumption that each query has a single correct answer. This overlooks common information-seeking scenarios with multiple plausible answers, where diversity is essential to avoid collapsing to a single dominant response, thereby constraining creativity and compromising fair and inclusive information access. Our analysis reveals a commonly overlooked limitation of standard RAG systems: they underutilize retrieved context diversity, such that increasing retrieval diversity alone does not yield diverse generations. To address this limitation, we propose DIVERGE, a plug-and-play agentic RAG framework with novel reflection-guided generation and memory-augmented iterative refinement, which promotes diverse viewpoints while preserving answer quality. We introduce novel metrics tailored to evaluating the diversity-quality trade-off in open-ended questions, and show that they correlate well with human judgments. We demonstrate that DIVERGE achieves the best diversity-quality trade-off compared to competitive baselines and previous state-of-the-art methods on the real-world Infinity-Chat dataset, substantially improving diversity while maintaining quality. More broadly, our results reveal a systematic limitation of current LLM-based systems for open-ended information-seeking and show that explicitly modeling diversity can mitigate it. Our code is available at: https://github.com/au-clan/Diverge

</details>


### [438] [Benchmarking Uncertainty Calibration in Large Language Model Long-Form Question Answering](https://arxiv.org/abs/2602.00279)
*Philip Müller,Nicholas Popovič,Michael Färber,Peter Steinbach*

Main category: cs.CL

TL;DR: 研究表明，在科学问答场景下，当前用于大型语言模型（LLM）的不确定性量化（UQ）方法在校准方面存在不足。研究提出了一个评估 UQ 方法的基准测试框架，发现指令微调和推理微调会影响模型输出的可靠性。在序列层面，答案频率比语言化方法更能提供可靠的校准，而 ECE 指标存在误导性。


<details>
  <summary>Details</summary>
Motivation: 在科学问答（QA）领域，LLM 的可靠不确定性量化（UQ）对于其可信度的提升至关重要。现有的 UQ 方法在需要事实检索和推理能力的科学 QA 领域验证不足。

Method: 该研究提出了第一个大规模基准测试，用于评估在推理密集型 QA 任务中 UQ 方法的校准性能。研究跨越了多达 20 种不同类型的 LLM，在七个科学 QA 数据集上进行了评估，包括多项选择题和算术题。研究使用提示（prompting）来模拟开放式问答场景，评估了代表性 UQ 方法在总计 685,000 个长格式响应上的表现，覆盖了不同复杂度的推理。

Result: 在 token 层面，指令微调导致概率质量极化，降低了 token 置信度作为不确定性估计的可靠性。推理微调模型也受到类似影响，但推理过程会根据模型提供商的不同而产生缓解。在序列层面，语言化方法（verbalized approaches）存在系统性偏差且与正确性相关性差，而答案频率（即多样本一致性）提供了最可靠的校准。研究还发现，仅依赖 ECE（Expected Calibration Error）作为衡量 UQ 方法性能的标准是具有误导性的。

Conclusion: 当前 LLM 的 UQ 方法及其基准测试标准存在关键局限性，尤其是在科学 QA 这一推理密集型应用场景下。答案频率比语言化方法更能提供可靠的校准，且 ECE 指标需要谨慎使用。

Abstract: Large Language Models (LLMs) are commonly used in Question Answering (QA) settings, increasingly in the natural sciences if not science at large. Reliable Uncertainty Quantification (UQ) is critical for the trustworthy uptake of generated answers. Existing UQ approaches remain weakly validated in scientific QA, a domain relying on fact-retrieval and reasoning capabilities. We introduce the first large-scale benchmark for evaluating UQ metrics in reasoning-demanding QA studying calibration of UQ methods, providing an extensible open-source framework to reproducibly assess calibration. Our study spans up to 20 large language models of base, instruction-tuned and reasoning variants. Our analysis covers seven scientific QA datasets, including both multiple-choice and arithmetic question answering tasks, using prompting to emulate an open question answering setting. We evaluate and compare methods representative of prominent approaches on a total of 685,000 long-form responses, spanning different reasoning complexities representative of domain-specific tasks. At the token level, we find that instruction tuning induces strong probability mass polarization, reducing the reliability of token-level confidences as estimates of uncertainty. Models further fine-tuned for reasoning are exposed to the same effect, but the reasoning process appears to mitigate it depending on the provider. At the sequence level, we show that verbalized approaches are systematically biased and poorly correlated with correctness, while answer frequency (consistency across samples) yields the most reliable calibration. In the wake of our analysis, we study and report the misleading effect of relying exclusively on ECE as a sole measure for judging performance of UQ methods on benchmark datasets. Our findings expose critical limitations of current UQ methods for LLMs and standard practices in benchmarking thereof.

</details>


### [439] [Faithful-Patchscopes: Understanding and Mitigating Model Bias in Hidden Representations Explanation of Large Language Models](https://arxiv.org/abs/2602.00300)
*Xilin Gong,Shu Yang,Zehua Cao,Lynne Billard,Di Wang*

Main category: cs.CL

TL;DR: 该研究发现Patchscopes框架在解释大型语言模型（LLMs）的隐藏表征时存在不忠实的问题，因为LLMs倾向于依赖固有的语言模式而非上下文信息。研究提出了BALOR方法，通过对数几率校准来纠正这种偏差，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明Patchscopes框架可以通过LLMs自身来解释隐藏表征，但该框架在解码过程中容易受到LLMs固有语言模式的影响，从而忽略了隐藏表征中的上下文信息，导致解释不忠实。因此，研究的动机是为了系统性地研究并解决Patchscopes的这一偏差问题。

Method: 研究首先设计了一个数据集来评估Patchscopes在有偏差情况下的忠实度。然后，提出了一种名为Bias Alignment through Logit Recalibration (BALOR) 的方法，该方法将未打补丁的提示输出对数几率视为模型偏差，并与打补丁的上下文信息产生的对数几率进行对比，通过校准对数几率分布来抑制模型偏差并增强上下文信息。

Result: 研究结果表明，在有偏差的情况下，Patchscopes的忠实度平均下降了18.84%。提出的BALOR方法在多个LLMs上的实验中，一致优于现有基线方法，并取得了高达33%的相对性能提升。

Conclusion: Patchscopes框架在解释LLM隐藏表征时存在固有偏差问题，模型倾向于依赖语言先验而非上下文。BALOR方法通过对数几率校准能够有效减轻这种偏差，显著提高了解释的忠实度和性能。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities for hidden representation interpretation through Patchscopes, a framework that uses LLMs themselves to generate human-readable explanations by decoding from internal hidden representations. However, our work shows that LLMs tend to rely on inherent linguistic patterns, which can override contextual information encoded in the hidden representations during decoding. For example, even when a hidden representation encodes the contextual attribute "purple" for "broccoli", LLMs still generate "green" in their explanations, reflecting a strong prior association. This behavior reveals a systematic unfaithfulness in Patchscopes. To systematically study this issue, we first designed a dataset to evaluate the faithfulness of Patchscopes under biased cases, and our results show that there is an 18.84\% faithfulness decrease on average. We then propose Bias Alignment through Logit Recalibration (BALOR), which treats the output logits from an unpatched prompt as capturing model bias and contrasts them with logits obtained under patched contextual information. By recalibrating the logit distribution through this contrast, BALOR suppresses model bias and amplifies contextual information during generation. Experiments across multiple LLMs demonstrate that BALOR consistently outperforms existing baselines, achieving up to 33\% relative performance improvement.

</details>


### [440] [MiNER: A Two-Stage Pipeline for Metadata Extraction from Municipal Meeting Minutes](https://arxiv.org/abs/2602.00316)
*Rodrigo Batista,Luís Filipe Cunha,Purificação Silvano,Nuno Guimarães,Alípio Jorge,Evelin Amorim,Ricardo Campos*

Main category: cs.CL

TL;DR: 本文提出了一种从市政会议记录中提取元数据的两阶段流水线方法，该方法结合了问答模型和Transformer NER模型，并对不同规模的语言模型进行了评估，结果表明该方法在特定领域内表现良好，但跨市政记录的泛化能力受限。


<details>
  <summary>Details</summary>
Motivation: 市政会议记录格式和写作风格不统一，难以自动提取会议编号、日期、地点、参与者、开始/结束时间等关键元数据。现有的命名实体识别（NER）模型不适用于这种领域特定的类别。

Method: 提出一个两阶段流水线：1. 使用问答（QA）模型识别包含元数据的开/闭文本段。2. 应用Transformer-based模型（BERTimbau和XLM-RoBERTa，带或不带CRF层）进行细粒度实体提取，并通过去词汇化（deslexicalization）进行增强。评估了Phi和Gemini等语言模型的性能、推理成本和碳足迹。

Result: 所提出的流水线在特定领域内表现出强大的性能，优于一些大型通用语言模型。然而，跨市政记录的评估显示泛化能力有所下降，这反映了市政记录的多样性和语言复杂性。

Conclusion: 该研究建立了市政会议记录元数据提取的第一个基准，为该领域的未来研究奠定了基础。尽管在特定领域内表现出色，但市政记录的多样性给模型的泛化能力带来了挑战。

Abstract: Municipal meeting minutes are official documents of local governance, exhibiting heterogeneous formats and writing styles. Effective information retrieval (IR) requires identifying metadata such as meeting number, date, location, participants, and start/end times, elements that are rarely standardized or easy to extract automatically. Existing named entity recognition (NER) models are ill-suited to this task, as they are not adapted to such domain-specific categories. In this paper, we propose a two-stage pipeline for metadata extraction from municipal minutes. First, a question answering (QA) model identifies the opening and closing text segments containing metadata. Transformer-based models (BERTimbau and XLM-RoBERTa with and without a CRF layer) are then applied for fine-grained entity extraction and enhanced through deslexicalization. To evaluate our proposed pipeline, we benchmark both open-weight (Phi) and closed-weight (Gemini) LLMs, assessing predictive performance, inference cost, and carbon footprint. Our results demonstrate strong in-domain performance, better than larger general-purpose LLMs. However, cross-municipality evaluation reveals reduced generalization reflecting the variability and linguistic complexity of municipal records. This work establishes the first benchmark for metadata extraction from municipal meeting minutes, providing a solid foundation for future research in this domain.

</details>


### [441] [Detecting AI-Generated Content in Academic Peer Reviews](https://arxiv.org/abs/2602.00319)
*Siyuan Shen,Kai Wang*

Main category: cs.CL

TL;DR: 研究表明，AI生成内容在学术同行评审中的比例在2022年后显著增加，预计到2025年，ICLR的约20%和Nature Communications的约12%的评审将由AI生成，尤其是在2024年下半年，Nature Communications的AI生成评审增长最为迅速。这提示AI辅助内容在学术评估中的作用日益增强，需要进一步研究其影响。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛可用，研究其在学术同行评审中的作用变得越来越重要。

Method: 研究人员将一个在历史评审数据上训练的AI内容检测模型应用于ICLR和Nature Communications在不同时间段的评审周期，以量化AI生成内容的出现和增长趋势。

Result: 在2022年之前，AI生成内容的检测比例很低。从2022年开始，AI生成内容的比例显著增加。预计到2025年，ICLR约有20%的评审，Nature Communications约有12%的评审将被归类为AI生成。Nature Communications的AI生成评审在2024年第三季度到第四季度之间增长最为显著。

Conclusion: 研究结果表明AI辅助内容在学术同行评审中的出现速度正在加快，并强调了进一步研究其对学术评估影响的必要性。

Abstract: The growing availability of large language models (LLMs) has raised questions about their role in academic peer review. This study examines the temporal emergence of AI-generated content in peer reviews by applying a detection model trained on historical reviews to later review cycles at International Conference on Learning Representations (ICLR) and Nature Communications (NC). We observe minimal detection of AI-generated content before 2022, followed by a substantial increase through 2025, with approximately 20% of ICLR reviews and 12% of Nature Communications reviews classified as AI-generated in 2025. The most pronounced growth of AI-generated reviews in NC occurs between the third and fourth quarter of 2024. Together, these findings provide suggestive evidence of a rapidly increasing presence of AI-assisted content in peer review and highlight the need for further study of its implications for scholarly evaluation.

</details>


### [442] [DETOUR: An Interactive Benchmark for Dual-Agent Search and Reasoning](https://arxiv.org/abs/2602.00352)
*Li Siyan,Darshan Deshpande,Anand Kannappan,Rebecca Qian*

Main category: cs.CL

TL;DR: 本研究提出了一种名为DETOUR的双代理评估基准，用于评估对话中多轮遗忘检索（tip-of-the-tongue search）的能力，现有模型在该基准上表现不佳，表明在不明确场景下的能力仍需提升。


<details>
  <summary>Details</summary>
Motivation: 现有评估遗忘检索任务的基准仅限于单轮交互，未能真实模拟对话中多轮检索的场景。研究旨在构建一个更贴合实际的评估环境，以发现当前模型在该复杂场景下的不足。

Method: 引入DETOUR基准，包含1011个提示。该基准采用双代理设置：一个被评估的主代理（Primary Agent）通过向一个固定不变的记忆代理（Memory Agent）提问来寻找遗忘的信息。评估涵盖文本、图像、音频和视频多种模态。

Result: 在DETOUR基准上，当前最先进的模型在多模态设置下仅获得36%的准确率，表明它们在处理模糊和不明确的检索请求方面仍存在显著困难。

Conclusion: DETOUR基准揭示了现有模型在多轮、不明确的遗忘检索任务上的局限性，强调了提升模型在这些场景下理解和检索能力的重要性。

Abstract: When recalling information in conversation, people often arrive at the recollection after multiple turns. However, existing benchmarks for evaluating agent capabilities in such tip-of-the-tongue search processes are restricted to single-turn settings. To more realistically simulate tip-of-the-tongue search, we introduce Dual-agent based Evaluation Through Obscure Under-specified Retrieval (DETOUR), a dual-agent evaluation benchmark containing 1,011 prompts. The benchmark design involves a Primary Agent, which is the subject of evaluation, tasked with identifying the recollected entity through querying a Memory Agent that is held consistent across evaluations. Our results indicate that current state-of-the-art models still struggle with our benchmark, only achieving 36% accuracy when evaluated on all modalities (text, image, audio, and video), highlighting the importance of enhancing capabilities in underspecified scenarios.

</details>


### [443] [DecompressionLM: Deterministic, Diagnostic, and Zero-Shot Concept Graph Extraction from Language Models](https://arxiv.org/abs/2602.00377)
*Zhaochen Hong,Jiaxuan You*

Main category: cs.CL

TL;DR: DecompressionLM 是一个无状态框架，用于零样本概念图提取，它发现语言模型编码的内容，而无需预先指定的查询或跨序列状态。它解决了现有解码探查方法的局限性，并揭示了 AWQ-4bit 等量化方法可以显著提高概念覆盖率，而 GPTQ-Int4 则会导致覆盖率大幅下降。


<details>
  <summary>Details</summary>
Motivation: 现有知识探查方法依赖于预定义查询，限制了提取到已知概念。本研究旨在解决现有解码探查方法在跨序列耦合、竞争性解码效应和可伸缩性限制方面的局限性，从而发现语言模型编码的内容，而无需预先指定的查询或共享的跨序列状态。

Method: 使用 Van der Corput 低差异序列和算术解码，DecompressionLM 实现确定性、独立并行生成，无需跨序列共享状态。该方法解决了跨序列耦合、竞争性解码效应和可伸缩性限制。

Result: 在两个模型系列和五个量化变体上，DecompressionLM 发现激活感知量化 (AWQ-4bit) 将概念覆盖率提高了 30-170%，而均匀量化 (GPTQ-Int4) 导致覆盖率坍塌 71-86%。此外，语料库验证显示，排名靠前和排名靠后的 MMLU-Pro Law 模型之间存在 17 个百分点的幻觉差距。

Conclusion: DecompressionLM 建立概念覆盖率作为评估压缩模型知识广度和事实依据的补充维度，有助于其部署。研究结果表明，量化方法对模型知识的提取和表示有显著影响。

Abstract: Existing knowledge probing methods rely on pre-defined queries, limiting extraction to known concepts. We introduce DecompressionLM, a stateless framework for zero-shot concept graph extraction that discovers what language models encode without pre-specified queries or shared cross-sequence state. Our method targets three limitations of common decoding-based probing approaches: cross-sequence coupling that concentrates probability mass on high-frequency prefixes, competitive decoding effects that suppress long-tail concepts, and scalability constraints arising from sequential exploration. Using Van der Corput low-discrepancy sequences with arithmetic decoding, DecompressionLM enables deterministic, embarrassingly parallel generation without shared state across sequences. Across two model families and five quantization variants, we find that activation-aware quantization (AWQ-4bit) expands concept coverage by 30-170%, while uniform quantization (GPTQ-Int4) induces 71-86% coverage collapse -- divergent behaviors not reliably reflected by explanation-level perplexity. Corpus-based verification further reveals a 17-point hallucination gap between top- and bottom-ranked MMLU-Pro Law models. DecompressionLM establishes concept coverage as a complementary evaluation dimension for assessing knowledge breadth and factual grounding in compressed models useful for their deployment.

</details>


### [444] [Clause-Internal or Clause-External? Testing Turkish Reflexive Binding in Adapted versus Chain of Thought Large Language Models](https://arxiv.org/abs/2602.00380)
*Sercan Karakaş*

Main category: cs.CL

TL;DR: 研究发现，经过大量土耳其语数据微调的Trendyol-LLM-7B-v0.1模型在处理土耳其语反身代词的先行词时表现出强烈的局部偏见（约70%），而OpenAI的链式思考模型则在局部和远距离先行词之间平均分配选择。


<details>
  <summary>Details</summary>
Motivation: 评估最先进的大型语言模型是否能够捕捉土耳其语反身代词的约束关系。

Method: 构建包含100个句子的平衡数据集，用于对比反身代词kendi和kendisi的局部和非局部先行词。使用OpenAI的链式思考模型和经过土耳其语数据广泛微调的Trendyol-LLM-7B-v0.1模型进行测试。通过句子级困惑度和强制选择范式评估先行词的选择。

Result: Trendyol-LLM-7B-v0.1模型在约70%的试验中倾向于选择局部先行词，显示出强烈的局部偏见。而OpenAI模型在局部和远距离阅读之间的选择几乎平均分配，显示出两种系统在约束行为上的显著差异。

Conclusion: 不同的LLM在处理土耳其语反身代词的约束关系时表现出不同的行为模式。经过特定领域（土耳其语）大量数据微调的模型（Trendyol-LLM）表现出更强的局部偏见，而通用的大型模型（OpenAI）则显示出更均衡的分布。

Abstract: This study evaluates whether state-of-the-art large language models capture the binding relations of Turkish reflexive pronouns. We construct a balanced set of 100 sentences that pit local against non-local antecedents for the reflexives kendi and kendisi, and test two contrasting systems: an OpenAI chain-of-thought model designed for multi-step reasoning and Trendyol-LLM-7B-base-v0.1, a LLaMA-2-derived model extensively fine-tuned on Turkish data. Antecedent choice is assessed using a combined sentence-level perplexity and forced-choice paradigm. Trendyol-LLM favours local bindings in approximately 70% of trials, exhibiting a strong locality bias, whereas o1 Mini distributes its choices almost evenly between local and long-distance readings, revealing a marked contrast in binding behaviour across the two systems.

</details>


### [445] [Segment-Level Attribution for Selective Learning of Long Reasoning Traces](https://arxiv.org/abs/2602.00425)
*Siyuan Wang,Yanchen Liu,Xiang Ren*

Main category: cs.CL

TL;DR: 本文提出了一种基于集成梯度归因的片段级选择性微调框架（SegmentSelectiveSFT），用于提高大型推理模型（LRMs）从长思维链（CoTs）中学习的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型推理模型（LRMs）通过生成长思维链（CoTs）来提升推理能力，但其中大部分内容冗余或不相关，即使经过监督微调（SFT）后，模型仍会模仿这些无效模式，导致性能下降。因此，需要一种方法来识别和利用CoTs中有意义的部分。

Method: 该方法首先使用集成梯度归因量化每个token对最终答案的影响。然后，将这些归因聚合为两个片段级指标：1）归因强度（attribution strength），衡量整体归因大小；2）方向一致性（direction consistency），衡量片段内token归因的统一性。基于这两个指标，提出一个选择性学习框架，识别出归因强度高但方向一致性适中的“重要”片段（表明反思性推理），并对这些片段进行选择性SFT，同时屏蔽掉不重要片段的损失。

Result: 在多个模型和数据集上的实验表明，该方法能够提高模型准确性和输出效率，更有效地从长推理轨迹中学习。

Conclusion: 所提出的片段级选择性微调框架（SegmentSelectiveSFT）通过利用集成梯度归因来识别和优先学习思维链中的关键信息片段，有效地解决了LRMs在处理长CoTs时遇到的冗余和性能下降问题，实现了更高效的学习。

Abstract: Large Reasoning Models (LRMs) achieve strong reasoning performance by generating long chains of thought (CoTs), yet only a small fraction of these traces meaningfully contributes to answer prediction, while the majority contains repetitive or truncated content. Such output redundancy is further propagated after supervised finetuning (SFT), as models learn to imitate verbose but uninformative patterns, which can degrade performance. To this end, we incorporate integrated gradient attribution to quantify each token's influence on final answers and aggregate them into two segment-level metrics: (1) \textit{attribution strength} measures the overall attribution magnitude; and (2) \textit{direction consistency} captures whether tokens' attributions within a segment are uniformly positive or negative (high consistency), or a mixture of both (moderate consistency). Based on these two metrics, we propose a segment-level selective learning framework to identify important segments with high attribution strength but moderate consistency that indicate reflective rather than shallow reasoning. The framework then applies selective SFT on these important segments while masking loss for unimportant ones. Experiments across multiple models and datasets show that our approach improves accuracy and output efficiency, enabling more effective learning from long reasoning traces~\footnote{Code and data are available at https://github.com/SiyuanWangw/SegmentSelectiveSFT}.

</details>


### [446] [When Agents "Misremember" Collectively: Exploring the Mandela Effect in LLM-based Multi-Agent Systems](https://arxiv.org/abs/2602.00428)
*Naen Xu,Hengyu An,Shuo Shi,Jinghuai Zhang,Chunyi Zhou,Changjiang Li,Tianyu Du,Zhihui Fu,Jun Wang,Shouling Ji*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLM）驱动的多智能体系统中“曼德拉效应”（集体记忆错误）的存在、原因和缓解策略。研究提出了一个名为MANBENCH的新基准来评估这种效应，并提出通过提示工程和模型对齐来减少该效应，实验显示平均可减少74.40%。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM在多智能体系统中的能力提升，但忽略了智能体易受集体认知偏差（如曼德拉效应）的影响。这种影响限制了对多智能体系统记忆偏差的理解，并引发了错误信息传播的伦理担忧。

Method: 研究提出了MANBENCH基准，用于评估智能体在四种易受曼德拉效应影响的任务类型和五种不同的交互协议（变化包括智能体角色和记忆时间尺度）下的行为。研究使用MANBENCH对多个LLM驱动的智能体进行了评估，并分析了影响曼德拉效应的因素。此外，研究提出了两种缓解策略：提示层面（如认知锚定和来源审查）和模型层面（基于对齐的防御）。

Result: 在MANBENCH基准测试中，研究量化了LLM驱动的多智能体系统中的曼德拉效应，并分析了影响因素。提出的缓解策略平均能够将曼德拉效应减少74.40%，显著优于基线方法。

Conclusion: 研究证明了LLM驱动的多智能体系统存在曼德拉效应，并提出了有效的缓解策略。这些发现有助于构建更具韧性和伦理兼容性的协作多智能体系统。

Abstract: Recent advancements in large language models (LLMs) have significantly enhanced the capabilities of collaborative multi-agent systems, enabling them to address complex challenges. However, within these multi-agent systems, the susceptibility of agents to collective cognitive biases remains an underexplored issue. A compelling example is the Mandela effect, a phenomenon where groups collectively misremember past events as a result of false details reinforced through social influence and internalized misinformation. This vulnerability limits our understanding of memory bias in multi-agent systems and raises ethical concerns about the potential spread of misinformation. In this paper, we conduct a comprehensive study on the Mandela effect in LLM-based multi-agent systems, focusing on its existence, causing factors, and mitigation strategies. We propose MANBENCH, a novel benchmark designed to evaluate agent behaviors across four common task types that are susceptible to the Mandela effect, using five interaction protocols that vary in agent roles and memory timescales. We evaluate agents powered by several LLMs on MANBENCH to quantify the Mandela effect and analyze how different factors affect it. Moreover, we propose strategies to mitigate this effect, including prompt-level defenses (e.g., cognitive anchoring and source scrutiny) and model-level alignment-based defense, achieving an average 74.40% reduction in the Mandela effect compared to the baseline. Our findings provide valuable insights for developing more resilient and ethically aligned collaborative multi-agent systems.

</details>


### [447] [What Matters to an LLM? Behavioral and Computational Evidences from Summarization](https://arxiv.org/abs/2602.00459)
*Yongxin Zhou,Changshun Wu,Philippe Mulhem,Didier Schwab,Maxime Peyrard*

Main category: cs.CL

TL;DR: 该研究结合行为和计算分析，揭示了大型语言模型（LLMs）在摘要生成中的内部重要性判断机制。研究发现LLMs会收敛到与预LLM基线模型截然不同的重要性模式，并且LLMs的聚类更多基于模型家族而非大小。计算分析表明，某些注意力头与经验重要性分布高度一致，而中后期层能有效预测重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在摘要任务上已达到最先进水平，但其内部用于驱动信息选择的重要性判断机制尚不明确，这阻碍了对LLMs摘要过程的理解和控制。因此，研究旨在探究LLMs在摘要中关注的信息为何以及如何表示。

Method: 研究结合了行为分析和计算分析。行为分析方面，研究为每个文档生成一系列长度受控的摘要，并根据信息单元的被选中频率导出经验重要性分布。计算分析方面，研究识别了与经验重要性分布一致的注意力头，并探究了模型层级对重要性的预测能力。

Result: 行为分析表明，LLMs在重要性模式上具有高度一致性，且这些模式与预LLM基线模型有显著差异。LLMs根据模型家族而非模型大小进行聚类。计算分析发现，部分注意力头能很好地匹配经验重要性分布，模型的中后期层对重要性具有很强的预测能力。

Conclusion: 该研究为理解LLMs在摘要任务中的信息优先级及其内部表示提供了初步见解，为后续解释和控制LLMs的信息选择机制开辟了道路。

Abstract: Large Language Models (LLMs) are now state-of-the-art at summarization, yet the internal notion of importance that drives their information selections remains hidden. We propose to investigate this by combining behavioral and computational analyses. Behaviorally, we generate a series of length-controlled summaries for each document and derive empirical importance distributions based on how often each information unit is selected. These reveal that LLMs converge on consistent importance patterns, sharply different from pre-LLM baselines, and that LLMs cluster more by family than by size. Computationally, we identify that certain attention heads align well with empirical importance distributions, and that middle-to-late layers are strongly predictive of importance. Together, these results provide initial insights into what LLMs prioritize in summarization and how this priority is internally represented, opening a path toward interpreting and ultimately controlling information selection in these models.

</details>


### [448] [Words that make SENSE: Sensorimotor Norms in Learned Lexical Token Representations](https://arxiv.org/abs/2602.00469)
*Abhinav Gupta,Toben H. Mintz,Jesse Thomason*

Main category: cs.CL

TL;DR: 本文提出了SENSE模型，该模型能从词汇嵌入中预测感觉运动规范，并通过行为实验验证了其有效性，发现了人类选择率与SENSE评分之间的显著相关性，并揭示了与内感受规范相关的语音韵律模式。


<details>
  <summary>Details</summary>
Motivation: 传统的词嵌入依赖于词语的共现模式，而人类语言理解根植于感官和运动经验。研究旨在弥合这一差距，探索如何从词汇嵌入中学习到与感觉运动经验相关的语义信息。

Method: 研究者开发了一个名为SENSE（Sensorimotor Embedding Norm Scoring Engine）的学习投影模型，用于预测兰开斯特感觉运动规范（Lancaster sensorimotor norms）的词汇嵌入。此外，他们还进行了一项包含281名参与者的行为研究，要求参与者为候选的虚构词选择特定的感觉运动联想，并分析了虚构词的选择率与SENSE评分之间的相关性，以及语音单元分析与内感受规范的关系。

Result: SENSE模型能够从词汇嵌入中预测感觉运动规范。行为研究表明，人类的选择率与SENSE评分在11种模态中的6种表现出统计学上的显著相关性。对虚构词选择率的亚词分析揭示了与内感受规范相关的系统性语音韵律模式。

Conclusion: SENSE模型提供了一种从文本数据中提取感觉运动信息的方法，并且得到了行为实验的支持。研究结果表明，语音韵律可能与内感受（interoceptive）概念相关联，为计算性地从文本中提出候选语音韵律提供了可能途径。

Abstract: While word embeddings derive meaning from co-occurrence patterns, human language understanding is grounded in sensory and motor experience. We present $\text{SENSE}$ $(\textbf{S}\text{ensorimotor }$ $\textbf{E}\text{mbedding }$ $\textbf{N}\text{orm }$ $\textbf{S}\text{coring }$ $\textbf{E}\text{ngine})$, a learned projection model that predicts Lancaster sensorimotor norms from word lexical embeddings. We also conducted a behavioral study where 281 participants selected which among candidate nonce words evoked specific sensorimotor associations, finding statistically significant correlations between human selection rates and $\text{SENSE}$ ratings across 6 of the 11 modalities. Sublexical analysis of these nonce words selection rates revealed systematic phonosthemic patterns for the interoceptive norm, suggesting a path towards computationally proposing candidate phonosthemes from text data.

</details>


### [449] [Intention-Adaptive LLM Fine-Tuning for Text Revision Generation](https://arxiv.org/abs/2602.00477)
*Zhexiong Liu,Diane Litman*

Main category: cs.CL

TL;DR: 本文提出了一种名为Intention-Tuning的LLM微调框架，用于解决意图驱动文本生成任务中的多意图和数据稀疏问题，通过动态选择LLM层来适应并迁移意图表示，实验证明该方法在小规模修订语料库上优于现有PEFT方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在意图驱动的文本生成（如修订生成）方面应用不足，尤其是在处理复杂的、纠缠的多意图场景时存在困难。同时，基于指令微调LLM需要大量标注数据，成本高且数据稀缺。

Method: 提出Intention-Tuning框架，这是一种意图自适应的、层级的LLM微调方法。该框架动态选择LLM的部分层来学习用户的意图，并将学习到的意图表示迁移到修订生成任务中。

Result: 在小规模修订语料库上，Intention-Tuning被证明是有效且高效的，其性能优于多种参数高效微调（PEFT）基线方法。

Conclusion: Intention-Tuning是一种解决意图驱动文本生成中多意图和数据稀疏挑战的有效方法，能够以较低的成本实现高性能的修订生成。

Abstract: Large Language Models (LLMs) have achieved impressive capabilities in various context-based text generation tasks, such as summarization and reasoning; however, their applications in intention-based generation tasks remain underexplored. One such example is revision generation, which requires the generated text to explicitly reflect the writer's actual intentions. Identifying intentions and generating desirable revisions are challenging due to their complex and diverse nature. Although prior work has employed LLMs to generate revisions with few-shot learning, they struggle with handling entangled multi-intent scenarios. While fine-tuning LLMs using intention-based instructions appears promising, it demands large amounts of annotated data, which is expensive and scarce in the revision community. To address these challenges, we propose Intention-Tuning, an intention-adaptive layer-wise LLM fine-tuning framework that dynamically selects a subset of LLM layers to learn the intentions and subsequently transfers their representations to revision generation. Experimental results suggest that Intention-Tuning is effective and efficient on small revision corpora, outperforming several PEFT baselines.

</details>


### [450] [From Knowledge to Inference: Scaling Laws of Specialized Reasoning on GlobalHealthAtlas](https://arxiv.org/abs/2602.00491)
*Zhaokun Yan,Zhaohan Liu,Wuzheng Dong,Lijie Feng,Chengxiao Dai*

Main category: cs.CL

TL;DR: 该研究提出了GlobalHealthAtlas，一个包含280,210个实例的大型多语言数据集，涵盖15个公共卫生领域和17种语言，并分为三个难度级别，旨在支持LLM在公共卫生推理方面的监督学习和评估。研究还提出了一种LLM辅助的数据集构建和质量控制流程，以及一个领域对齐的评估器。


<details>
  <summary>Details</summary>
Motivation: 公共卫生推理需要基于科学证据、专家共识和安全约束的人口水平推断，但作为一个结构化的机器学习问题，其研究相对有限，尤其是在监督信号和基准方面。作者希望解决这一空白，为公共卫生推理提供一个可用的数据集和评估框架。

Method: 研究构建了一个名为GlobalHealthAtlas的大规模多语言数据集，包含280,210个实例，覆盖15个公共卫生领域，17种语言，并根据健康素养、流行病学和政策推理分为三个难度级别。数据集的构建采用了LLM辅助的流程，包括检索、去重、证据核查和标签验证。此外，还设计了一个领域对齐的评估器，用于从多个LLM的高置信度判断中提炼而来，从准确性、推理、完整性、共识一致性、术语规范和洞察力六个维度评估输出。

Result: 研究创建了一个包含280,210个实例的大规模多语言公共卫生推理数据集，并提出了一套LLM辅助的数据集构建和评估流程。该数据集和评估方法支持对LLM在公共卫生推理方面的训练和评估，超越了传统的QA基准。

Conclusion: GlobalHealthAtlas数据集和配套的评估框架为安全关键的公共卫生推理提供了可复现的训练和评估能力，有助于推动LLM在这一领域的发展，使其能够进行超越传统问答任务的推理。

Abstract: Public health reasoning requires population level inference grounded in scientific evidence, expert consensus, and safety constraints. However, it remains underexplored as a structured machine learning problem with limited supervised signals and benchmarks. We introduce \textbf{GlobalHealthAtlas}, a large scale multilingual dataset of 280,210 instances spanning 15 public health domains and 17 languages, stratified into three difficulty levels from health literacy to epidemiological and policy reasoning. Instances are derived from openly available public health sources and labeled by language, domain, and difficulty to support supervised learning and slice based evaluation. We further propose large language model (LLM) assisted construction and quality control pipeline with retrieval, duplication, evidence grounding checks, and label validation to improve consistency at scale. Finally, we present a domain aligned evaluator distilled from high confidence judgments of diverse LLMs to assess outputs along six dimensions: Accuracy, Reasoning, Completeness, Consensus Alignment, Terminology Norms, and Insightfulness. Together, these contributions enable reproducible training and evaluation of LLMs for safety critical public health reasoning beyond conventional QA benchmarks.

</details>


### [451] [Culturally-Grounded Governance for Multilingual Language Models: Rights, Data Boundaries, and Accountable AI Design](https://arxiv.org/abs/2602.00497)
*Hanjing Shi,Dominic DiFranzo*

Main category: cs.CL

TL;DR: 该论文提出了一种面向多语言大型语言模型（MLLMs）的、基于文化的治理框架，以解决当前治理框架在文化、语言和政治方面存在的不足，特别关注低资源语言和文化边缘化社区面临的风险，并将治理问题重新定义为社会文化和基于权利的问题。


<details>
  <summary>Details</summary>
Motivation: 现有针对多语言大型语言模型的治理框架主要基于英语中心的数据、同质化用户群体以及抽象的公平概念，这未能考虑到低资源语言和文化边缘化社区的特殊情况，可能导致模型行为、数据实践和问责机制与当地规范、权利和期望不符，从而带来系统性风险。

Method: 文章借鉴了以人为本的计算和人工智能治理的跨文化视角，综合了关于多语言模型行为、数据不对称和社会技术危害的现有证据，并提出了一种基于文化的治理框架。它识别了三个相互关联的治理挑战，并提出了数据管理、透明度和参与式问责的设计和政策启示。

Result: 研究识别了三个主要的治理挑战：1) 训练数据和评估实践中的文化和语言不平等；2) 全球部署与当地规范、价值观和权力结构之间的错位；3) 解决边缘化语言社区所经历的危害的问责机制有限。论文提出了一种重塑多语言人工智能治理为社会文化和基于权利问题的概念性议程。

Conclusion: 文章认为，迫切需要一种基于文化的治理框架来管理多语言大型语言模型。这种治理框架必须将多语言人工智能治理视为一个社会文化和基于权利的问题，而不是仅仅关注技术基准。通过关注数据管理、透明度和参与式问责，可以确保多语言语言模型不会在规模和中立的幌子下复制现有的全球不平等。

Abstract: Multilingual large language models (MLLMs) are increasingly deployed across cultural, linguistic, and political contexts, yet existing governance frameworks largely assume English-centric data, homogeneous user populations, and abstract notions of fairness. This creates systematic risks for low-resource languages and culturally marginalized communities, where data practices, model behavior, and accountability mechanisms often fail to align with local norms, rights, and expectations. Drawing on cross-cultural perspectives in human-centered computing and AI governance, this paper synthesizes existing evidence on multilingual model behavior, data asymmetries, and sociotechnical harm, and articulates a culturally grounded governance framework for MLLMs. We identify three interrelated governance challenges: cultural and linguistic inequities in training data and evaluation practices, misalignment between global deployment and locally situated norms, values, and power structures, and limited accountability mechanisms for addressing harms experienced by marginalized language communities. Rather than proposing new technical benchmarks, we contribute a conceptual agenda that reframes multilingual AI governance as a sociocultural and rights based problem. We outline design and policy implications for data stewardship, transparency, and participatory accountability, and argue that culturally grounded governance is essential for ensuring that multilingual language models do not reproduce existing global inequalities under the guise of scale and neutrality.

</details>


### [452] [Reasoning by Commented Code for Table Question Answering](https://arxiv.org/abs/2602.00543)
*Seho Pyo,Jiheon Seok,Jaejin Lee*

Main category: cs.CL

TL;DR: 本文提出了一种改进的表格问答（TableQA）方法，通过生成带有注释的、分步的Python代码来增强LLM的推理能力，显著提高了准确性，并结合现有模型进一步提升表现。


<details>
  <summary>Details</summary>
Motivation: 传统的表格数据线性化方法破坏了表格的二维结构，限制了大型语言模型（LLMs）在表格问答任务上的表现。现有的端到端生成或单行程序查询方法准确率和可解释性均有不足。

Method: 提出了一种注释分步代码生成框架，将表格问答推理分解为多行可执行Python程序，并配以简洁的自然语言注释，以促进清晰的推理和生成正确的代码。该方法还通过轻量级的答案选择机制与现有的端到端TableQA模型相结合。

Result: 在WikiTableQuestions基准测试中，Qwen2.5-Coder-7B-Instruct模型使用该框架达到了70.9%的准确率，优于Repanda基线（67.6%）。该框架与强大的端到端TableQA模型结合后，在WikiTableQuestions上最高可达84.3%的准确率。

Conclusion: 所提出的注释分步代码生成框架能够有效提升LLMs在表格问答任务上的推理能力和准确性，并且该方法可以通过与现有模型的结合进一步优化性能。

Abstract: Table Question Answering (TableQA) poses a significant challenge for large language models (LLMs) because conventional linearization of tables often disrupts the two-dimensional relationships intrinsic to structured data. Existing methods, which depend on end-to-end answer generation or single-line program queries, typically exhibit limited numerical accuracy and reduced interpretability. This work introduces a commented, step-by-step code-generation framework that incorporates explicit reasoning into the Python program-generation process. The approach decomposes TableQA reasoning into multi-line executable programs with concise natural language comments, thereby promoting clearer reasoning and increasing the likelihood of generating correct code. On the WikiTableQuestions benchmark, the proposed method achieves 70.9\% accuracy using Qwen2.5-Coder-7B-Instruct, surpassing the Repanda baseline (67.6\%). Integrating the proposed framework with a robust end-to-end TableQA model via a lightweight answer-selection mechanism yields further improvements. This combined approach achieves up to 84.3\% accuracy on the WikiTableQuestions benchmark.

</details>


### [453] [A Hierarchical and Attentional Analysis of Argument Structure Constructions in BERT Using Naturalistic Corpora](https://arxiv.org/abs/2602.00554)
*Liu Kaipeng,Wu Ling*

Main category: cs.CL

TL;DR: 本文研究了BERT模型如何处理四种基本论证结构构造，发现模型在早期层级提取构造信息，在中期层级形成可区分的聚类，并在后续层级保持该信息。


<details>
  <summary>Details</summary>
Motivation: 研究BERT模型如何理解和表示语言中的论证结构构造。

Method: 采用多维度分析框架，包括MDS、t-SNE降维，GDV聚类分离度量，FDR线性探针，以及注意力机制分析。

Result: BERT模型呈现出一种层级化的表征结构。构造特异性信息在早期层级出现，在中期层级形成最大可分离的聚类，并在后期处理阶段得到维持。

Conclusion: BERT模型能够有效地在不同层级学习并维持关于论证结构构造的信息，并且这些信息呈现出层级化的表征特征。

Abstract: This study investigates how the Bidirectional Encoder Representations from Transformers model processes four fundamental Argument Structure Constructions. We employ a multi-dimensional analytical framework, which integrates MDS, t-SNE as dimensionality reduction, Generalized Discrimination Value (GDV) as cluster separation metrics, Fisher Discriminant Ratio (FDR) as linear diagnostic probing, and attention mechanism analysis. Our results reveal a hierarchical representational structure. Construction-specific information emerges in early layers, forms maximally separable clusters in middle layers, and is maintained through later processing stages.

</details>


### [454] [The French Drama Revolution: Political Economy and Literary Production, 1700-1900](https://arxiv.org/abs/2602.00588)
*Thiago Dumont Oliveira*

Main category: cs.CL

TL;DR: 本文利用LDA和JSD分析了1700-1900年法国戏剧的主题演变，发现法国大革命后，尤其在1789-1850年间，主题分布发生显著变化，资产阶级主题日益普遍。结合GDP分析，探讨了政治经济变革对戏剧主题的影响。


<details>
  <summary>Details</summary>
Motivation: 研究法国大革命和工业化背景下，法国戏剧主题如何随时间和社会经济发展而演变。

Method: 使用Latent Dirichlet Allocation (LDA) 进行主题建模，并利用Jensen-Shannon Divergence (JSD) 评估主题分布的变化。通过将主题流行度与法国GDP绘制对比，分析戏剧与经济增长的协同演变。

Result: 研究表明，法国戏剧的主题分布在法国大革命后发生了深刻变化，特别是1789年至1850年间。自18世纪末以来，资产阶级主题成为最普遍的主题之一。

Conclusion: 法国大革命和工业化对法国戏剧的主题内容产生了显著影响，导致了主题分布的根本性转变，资产阶级主题的兴起是这一时期戏剧演变的重要特征。

Abstract: This paper investigates the changing nature of French drama between 1700-1900 using Latent Dirichlet Allocation and Jensen-Shannon Divergence. Results indicate that the topical distribution of French drama changed profoundly after the French Revolution, particularly between 1789 and 1850. Bourgeois themes emerged among the most prevalent topics since the late 18th century. To assess the coevolution of drama and economic growth, I plot the yearly prevalence of topics alongside French GDP between 1700-1900, and discuss these changes in light of the political and economic changes prompted by the French Revolution and the industrialization of the country.

</details>


### [455] [Kanade: A Simple Disentangled Tokenizer for Spoken Language Modeling](https://arxiv.org/abs/2602.00594)
*Zhijie Huang,Stephen McIntosh,Daisuke Saito,Nobuaki Minematsu*

Main category: cs.CL

TL;DR: 本文提出了一种名为Kanade的单层解耦语音分词器，能够提取语音中的音韵和韵律信息，同时抑制与说话人身份等无关的语言信息，并支持高质量合成。实验表明，Kanade在说话人解耦和词汇可用性方面达到了最先进水平，同时保持了出色的重建质量。


<details>
  <summary>Details</summary>
Motivation: 为了构建一个好的语言模型，尤其是在语音建模领域，需要一个好的分词器。语音分词器需要处理连续信号，并区分语言信息和非语言信息，同时提取音韵和韵律，抑制无关信息，并支持高质量合成。

Method: 提出了一种名为Kanade的单层解耦语音分词器。该方法通过分离声学常数，生成一个单一的token流，该token流捕捉丰富的音韵和韵律信息，且无需依赖辅助方法。

Result: Kanade在说话人解耦和词汇可用性方面达到了最先进的水平，同时保持了优秀的重建质量。

Conclusion: Kanade是一种有效的单层解耦语音分词器，能够满足语音建模中对音韵、韵律提取以及说话人解耦和高质量合成的要求。

Abstract: A good language model starts with a good tokenizer. Tokenization is especially important for speech modeling, which must handle continuous signals that mix linguistic and non-linguistic information. A speech tokenizer should extract phonetics and prosody, suppress linguistically irrelevant information like speaker identity, and enable high-quality synthesis. We present Kanade, a single-layer disentangled speech tokenizer that realizes this ideal. Kanade separates out acoustic constants to create a single stream of tokens that captures rich phonetics and prosody. It does so without the need for auxiliary methods that existing disentangled codecs often rely on. Experiments show that Kanade achieves state-of-the-art speaker disentanglement and lexical availability, while maintaining excellent reconstruction quality.

</details>


### [456] [Hermes the Polyglot: A Unified Framework to Enhance Expressiveness for Multimodal Interlingual Subtitling](https://arxiv.org/abs/2602.00597)
*Chaoqun Cui,Shijing Wang,Liangbin Huang,Qingqing Gu,Zhaolong Huang,Xiao Zeng,Wenji Mao*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Hermes 的基于大语言模型（LLM）的自动化字幕翻译框架，旨在解决现有方法在语义连贯性、代词和术语翻译以及表达力方面存在的挑战，并在实验中取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在机器翻译方面取得了显著进展，但在跨语言字幕翻译领域，字幕文本的语义连贯性、代词和术语翻译以及表达力等方面仍然存在挑战，这促使研究者开发新的方法。

Method: 提出 Hermes 框架，该框架基于大语言模型，并集成了三个模块：说话人分离（Speaker Diarization）、术语识别（Terminology Identification）和表达力增强（Expressiveness Enhancement）。

Result: 实验证明，Hermes 在说话人分离方面取得了先进的性能，并且能够生成具有表达力、上下文连贯的翻译。

Conclusion: Hermes 框架能够有效解决跨语言字幕翻译中的语义连贯性、代词和术语翻译以及表达力等挑战，推动了跨语言字幕翻译的研究进展。

Abstract: Interlingual subtitling, which translates subtitles of visual media into a target language, is essential for entertainment localization but has not yet been explored in machine translation. Although Large Language Models (LLMs) have significantly advanced the general capabilities of machine translation, the distinctive characteristics of subtitle texts pose persistent challenges in interlingual subtitling, particularly regarding semantic coherence, pronoun and terminology translation, and translation expressiveness. To address these issues, we present Hermes, an LLM-based automated subtitling framework. Hermes integrates three modules: Speaker Diarization, Terminology Identification, and Expressiveness Enhancement, which effectively tackle the above challenges. Experiments demonstrate that Hermes achieves state-of-the-art diarization performance and generates expressive, contextually coherent translations, thereby advancing research in interlingual subtitling.

</details>


### [457] [Lookahead-then-Verify: Reliable Constrained Decoding for Diffusion LLMs under Context-Free Grammars](https://arxiv.org/abs/2602.00612)
*Yitong Zhang,Yongmin Li,Yuetong Liu,Jia Li,Xiaoran Jia,Zherui Li,Ge Li*

Main category: cs.CL

TL;DR: 提出了一种名为LAVE的约束解码方法，用于解决扩散大语言模型（dLLMs）在生成形式语言（如源代码）时语法不正确的问题。LAVE利用dLLMs的并行预测能力，在生成过程中高效可靠地验证每个新标记的有效性，并确保中间输出可以续写成有效句子。实验表明，LAVE在提高语法正确性方面显著优于现有方法，且运行开销微乎其微。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散大语言模型（dLLMs）在生成形式语言时，由于其概率性质，难以保证输出的语法正确性。现有的约束解码技术要么不适用于dLLMs的非自回归特性，要么允许生成无法完成为有效句子的中间状态，从而限制了其可靠性。

Method: 提出了一种名为LAVE的约束解码方法。LAVE利用dLLMs在每次前向传播中并行预测所有位置的标记分布的能力。当模型提议一个新标记时，LAVE利用这些预先计算好的分布进行前瞻性检查，以高效且可靠地验证该标记的有效性，并确保中间输出具备完成为有效句子的潜力。

Result: 在四个广泛使用的dLLMs和三个代表性基准测试上的大量实验表明，LAVE在语法正确性方面比现有基线方法有显著的改进，并且运行时开销可忽略不计。

Conclusion: LAVE是一种专门为dLLMs设计的约束解码方法，能够有效解决其生成形式语言时的语法不正确问题，并且在保持高效的同时提高了生成结果的可靠性。

Abstract: Diffusion Large Language Models (dLLMs) have demonstrated promising generative capabilities and are increasingly used to produce formal languages defined by context-free grammars, such as source code and chemical expressions. However, as probabilistic models, they still struggle to generate syntactically valid outputs reliably. A natural and promising direction to address this issue is to adapt constrained decoding techniques to enforce grammatical correctness during generation. However, applying these techniques faces two primary obstacles. On the one hand, the non-autoregressive nature of dLLMs renders most existing constrained decoding approaches inapplicable. On the other hand, current approaches specifically designed for dLLMs may allow intermediate outputs that are impossible to complete into valid sentences, which significantly limits their reliability in practice.
  To address these challenges, we present LAVE, a constrained decoding approach specifically designed for dLLMs. Our approach leverages a key property of dLLMs, namely their ability to predict token distributions for all positions in parallel during each forward pass. Whenever a new token is proposed by model, LAVE performs lookahead using these distributions to efficiently and reliably verify the validity of the proposed token. This design ensures reliable constraints by reliably preserving the potential for intermediate outputs to be extended into valid sentences. Extensive experiments across four widely used dLLMs and three representative benchmarks demonstrate that LAVE consistently outperforms existing baselines and achieves substantial improvements in syntactic correctness, while incurring negligible runtime overhead.

</details>


### [458] [Transformer-Based Model for Multilingual Hope Speech Detection](https://arxiv.org/abs/2602.00613)
*Nsrin Ashraf,Mariam Labib,Hamada Nayel*

Main category: cs.CL

TL;DR: 该论文实现并评估了 RoBERTa 和 XLM-RoBERTa 模型在英语和德语的希望言论检测任务上的性能，RoBERTa 在英语上取得了 0.818 的加权 F1 分数。


<details>
  <summary>Details</summary>
Motivation: 为了满足 PolyHope-M 任务（RANLP2025）的需求，开发一个有效的希望言论检测系统，并探索预训练语言模型在该任务上的潜力。

Method: 实现了 RoBERTa 模型用于英语希望言论检测，并实现了多语言模型 XLM-RoBERTa 用于英语和德语的希望言论检测。

Result: RoBERTa 在英语上获得了 0.818 的加权 F1 分数和 81.8% 的准确率。XLM-RoBERTa 在英语上获得了 0.786 的加权 F1 分数和 78.5% 的准确率。

Conclusion: 预训练大型语言模型（如 RoBERTa 和 XLM-RoBERTa）在希望言论检测任务中表现出色，并且这些模型的持续改进能够显著提升不同自然语言处理任务的性能。

Abstract: This paper describes a system that has been submitted to the "PolyHope-M" at RANLP2025. In this work various transformers have been implemented and evaluated for hope speech detection for English and Germany. RoBERTa has been implemented for English, while the multilingual model XLM-RoBERTa has been implemented for both English and German languages. The proposed system using RoBERTa reported a weighted f1-score of 0.818 and an accuracy of 81.8% for English. On the other hand, XLM-RoBERTa achieved a weighted f1-score of 0.786 and an accuracy of 78.5%. These results reflects the importance of improvement of pre-trained large language models and how these models enhancing the performance of different natural language processing tasks.

</details>


### [459] [Jailbreaking LLMs via Calibration](https://arxiv.org/abs/2602.00619)
*Yuxuan Lu,Yongkang Guo,Yuqing Kong*

Main category: cs.CL

TL;DR: 研究提出了一种框架，将 LLM 安全对齐的影响建模为对预对齐数据分布的系统性扭曲，并提出了一种基于梯度偏移的最优聚合策略来解决弱到强越狱问题，该策略在红队测试和数学任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 安全对齐在 LLM 中会产生对齐输出与预对齐数据分布之间的系统性差异，这阻碍了模型效用，并促使研究人员探索如何有效绕过安全对齐。

Method: 该研究将安全对齐视为对预对齐数据分布的系统性扭曲，并将弱到强越狱问题建模为预测聚合问题。他们推导出了一个最优聚合策略，该策略通过损失诱导的对偶空间中的梯度偏移来表征。此外，他们还提出了一个新的混合聚合规则。

Result: 该方法在红队测试基准和数学效用任务上，在使用前沿模型时，实现了更高的攻击成功率和更低的“越狱税”，尤其是在安全加固的 gpt-oss-120b 模型上。

Conclusion: 所提出的框架和基于梯度偏移的聚合策略能够有效地解决 LLM 中的安全对齐问题，并在绕过安全措施的同时保持模型效用，尤其是在高安全性的模型上表现出色。

Abstract: Safety alignment in Large Language Models (LLMs) often creates a systematic discrepancy between a model's aligned output and the underlying pre-aligned data distribution. We propose a framework in which the effect of safety alignment on next-token prediction is modeled as a systematic distortion of a pre-alignment distribution. We cast Weak-to-Strong Jailbreaking as a forecast aggregation problem and derive an optimal aggregation strategy characterized by a Gradient Shift in the loss-induced dual space. We show that logit-arithmetic jailbreaking methods are a special case of this framework under cross-entropy loss, and derive a broader family of aggregation rules corresponding to other proper losses. We also propose a new hybrid aggregation rule. Evaluations across red-teaming benchmarks and math utility tasks using frontier models demonstrate that our approach achieves superior Attack Success Rates and lower "Jailbreak Tax" compared with existing methods, especially on the safety-hardened gpt-oss-120b.

</details>


### [460] [Formal Semantic Control over Language Models](https://arxiv.org/abs/2602.00638)
*Yingji Zhang*

Main category: cs.CL

TL;DR: 本论文旨在通过改变VAE框架下语言模型的潜在空间几何形状，提高语言表示和模型的语义及几何可解释性，并实现局部的、准符号化的、可组合的控制。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于使语言模型的内部语义表示能够被系统地解释、精确地构建和可靠地引导，从而增强其可解释性和可控性。

Method: 研究采用变分自编码器（VAE）框架，探索两个方向：1. 句子级学习与控制，通过解耦和操纵潜在空间中的特定语义特征来指导句子生成；2. 推理级学习与控制，通过分离和引导潜在空间中的推理行为来控制自然语言推理（NLI）。

Result: 通过一系列新的理论框架、实用方法和实验，证明了所提出的方法能够同时增强自然语言在潜在空间中的可解释性和可控性。

Conclusion: 本研究成功地推进了语义表示学习，使得语言模型在语义和几何层面更具可解释性，并能够通过操纵潜在空间来实现局部的、准符号化的、可组合的控制。

Abstract: This thesis advances semantic representation learning to render language representations or models more semantically and geometrically interpretable, and to enable localised, quasi-symbolic, compositional control through deliberate shaping of their latent space geometry. We pursue this goal within a VAE framework, exploring two complementary research directions: (i) Sentence-level learning and control: disentangling and manipulating specific semantic features in the latent space to guide sentence generation, with explanatory text serving as the testbed; and (ii) Reasoning-level learning and control: isolating and steering inference behaviours in the latent space to control NLI. In this direction, we focus on Explanatory NLI tasks, in which two premises (explanations) are provided to infer a conclusion. The overarching objective is to move toward language models whose internal semantic representations can be systematically interpreted, precisely structured, and reliably directed. We introduce a set of novel theoretical frameworks and practical methodologies, together with corresponding experiments, to demonstrate that our approaches enhance both the interpretability and controllability of latent spaces for natural language across the thesis.

</details>


### [461] [LegalOne: A Family of Foundation Models for Reliable Legal Reasoning](https://arxiv.org/abs/2602.00642)
*Haitao Li,Yifan Chen,Shuo Miao,Qian Dong,Jia Chen,Yiran Hu,Junjie Chen,Minghao Qin,Qingyao Ai,Yiqun Liu,Cheng Luo,Quan Zhou,Ya Zhang,Jikun Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为LegalOne的法律领域基础模型，旨在解决通用大语言模型在司法推理方面的不足。通过三个阶段（中途训练、监督微调、强化学习）以及Plasticity-Adjusted Sampling (PAS)和Legal Agentic CoT Distillation (LEAD)等方法，LegalOne在法律任务上取得了最先进的性能，并且已开源模型和评估框架。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在法律领域应用受限于缺乏精确的领域知识和多步司法推理的复杂性。因此，需要专门为法律领域定制的基础模型。

Method: LegalOne通过三阶段流程开发：1. 中途训练采用Plasticity-Adjusted Sampling (PAS) 来平衡新知识获取和原有能力保留，以适应法律领域。2. 监督微调采用Legal Agentic CoT Distillation (LEAD) 来从法律文本中提取显式推理，通过代理工作流将司法过程结构化。3. 采用课程强化学习策略，循序渐进地提升模型的记忆、理解和推理能力。

Result: LegalOne在多项法律任务上实现了最先进的性能，超越了参数量更大的通用大语言模型，体现了更高的知识密度和效率。

Conclusion: LegalOne是一种专门为中国法律领域设计的、能够进行精确司法推理的基础模型。通过创新的训练方法，它克服了通用大模型的局限性，并在法律任务上取得了优异的性能。研究者公开了模型权重和评估框架，以推动法律人工智能领域的发展，并促进可信赖、可解释模型的在司法领域的应用。

Abstract: While Large Language Models (LLMs) have demonstrated impressive general capabilities, their direct application in the legal domain is often hindered by a lack of precise domain knowledge and complexity of performing rigorous multi-step judicial reasoning. To address this gap, we present LegalOne, a family of foundational models specifically tailored for the Chinese legal domain. LegalOne is developed through a comprehensive three-phase pipeline designed to master legal reasoning. First, during mid-training phase, we propose Plasticity-Adjusted Sampling (PAS) to address the challenge of domain adaptation. This perplexity-based scheduler strikes a balance between the acquisition of new knowledge and the retention of original capabilities, effectively establishing a robust legal foundation. Second, during supervised fine-tuning, we employ Legal Agentic CoT Distillation (LEAD) to distill explicit reasoning from raw legal texts. Unlike naive distillation, LEAD utilizes an agentic workflow to convert complex judicial processes into structured reasoning trajectories, thereby enforcing factual grounding and logical rigor. Finally, we implement a Curriculum Reinforcement Learning (RL) strategy. Through a progressive reinforcement process spanning memorization, understanding, and reasoning, LegalOne evolves from simple pattern matching to autonomous and reliable legal reasoning. Experimental results demonstrate that LegalOne achieves state-of-the-art performance across a wide range of legal tasks, surpassing general-purpose LLMs with vastly larger parameter counts through enhanced knowledge density and efficiency. We publicly release the LegalOne weights and the LegalKit evaluation framework to advance the field of Legal AI, paving the way for deploying trustworthy and interpretable foundation models in high-stakes judicial applications.

</details>


### [462] [Can Small Language Models Handle Context-Summarized Multi-Turn Customer-Service QA? A Synthetic Data-Driven Comparative Evaluation](https://arxiv.org/abs/2602.00665)
*Lakshan Cooray,Deshan Sumanathilaka,Pattigadapa Venkatesh Raju*

Main category: cs.CL

TL;DR: 研究表明，经过指令微调的小型语言模型（SLMs）在上下文摘要和对话阶段分析的辅助下，可以有效处理多轮客服问答，部分SLMs的表现接近大型语言模型（LLMs），但其能力仍有待提高。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在客服问答方面表现优异，但计算成本高昂且部署受限，而小型语言模型（SLMs）效率更高，但其在多轮客服问答中的能力，特别是对话连续性和上下文理解方面，尚未得到充分研究。

Method: 采用指令微调策略，结合历史对话摘要技术来保留对话状态，并引入基于对话阶段的定性分析方法。评估了九种指令微调的低参数SLMs，并与三种商用LLMs进行比较，使用了词汇和语义相似性指标，以及人类评估和LLM-as-a-judge等定性评估方法。

Result: 不同SLMs的表现存在显著差异，部分SLMs在多轮客服问答中的表现接近LLMs，能够较好地保持对话连续性和上下文理解，但也有部分SLMs在这方面表现不佳。

Conclusion: 指令微调的SLMs，辅以历史摘要策略和对话阶段分析，在多轮客服问答中具有应用潜力，但其性能仍需进一步提升以满足实际部署需求，这表明低参数语言模型在真实世界的客服问答系统中既有优势也有局限性。

Abstract: Customer-service question answering (QA) systems increasingly rely on conversational language understanding. While Large Language Models (LLMs) achieve strong performance, their high computational cost and deployment constraints limit practical use in resource-constrained environments. Small Language Models (SLMs) provide a more efficient alternative, yet their effectiveness for multi-turn customer-service QA remains underexplored, particularly in scenarios requiring dialogue continuity and contextual understanding. This study investigates instruction-tuned SLMs for context-summarized multi-turn customer-service QA, using a history summarization strategy to preserve essential conversational state. We also introduce a conversation stage-based qualitative analysis to evaluate model behavior across different phases of customer-service interactions. Nine instruction-tuned low-parameterized SLMs are evaluated against three commercial LLMs using lexical and semantic similarity metrics alongside qualitative assessments, including human evaluation and LLM-as-a-judge methods. Results show notable variation across SLMs, with some models demonstrating near-LLM performance, while others struggle to maintain dialogue continuity and contextual alignment. These findings highlight both the potential and current limitations of low-parameterized language models for real-world customer-service QA systems.

</details>


### [463] [EchoReview: Learning Peer Review from the Echoes of Scientific Citations](https://arxiv.org/abs/2602.00733)
*Yinuo Zhang,Dingcheng Huang,Haifeng Suo,Yizhuo Li,Ziya Zhao,Junhao Xu,Zhiying Tu,Dianhui Chu,Deming Zhai,Xianming Liu,Xiaoyan Yu,Dianbo Sui*

Main category: cs.CL

TL;DR: 本文提出了一种名为EchoReview的数据合成框架，利用学术引用来生成结构化的同行评审数据，并训练了一个名为EchoReviewer-7B的自动化审稿人，该审稿人在证据支持和评审全面性等方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 传统的同行评审系统因科学论文量激增而面临可扩展性压力，需要开发可扩展且可靠的自动化评审方法。现有方法受限于单一数据源和人类评审的主观性、不一致性。

Method: 提出EchoReview框架，通过挖掘学术引用的隐式集体评价信号来合成结构化的评审数据。基于此框架构建了EchoReview-16K数据集，并训练了自动化审稿人EchoReviewer-7B。

Result: EchoReviewer-7B在证据支持和评审全面性等核心评审维度上实现了显著且稳定的改进。

Conclusion: 引用上下文是一个强大且有效的数据范式，可用于开发可靠的自动化同行评审系统。

Abstract: As the volume of scientific submissions continues to grow rapidly, traditional peer review systems are facing unprecedented scalability pressures, highlighting the urgent need for automated reviewing methods that are both scalable and reliable. Existing supervised fine-tuning approaches based on real review data are fundamentally constrained by single-source of data as well as the inherent subjectivity and inconsistency of human reviews, limiting their ability to support high-quality automated reviewers. To address these issues, we propose EchoReview, a citation-context-driven data synthesis framework that systematically mines implicit collective evaluative signals from academic citations and transforms scientific community's long-term judgments into structured review-style data. Based on this pipeline, we construct EchoReview-16K, the first large-scale, cross-conference, and cross-year citation-driven review dataset, and train an automated reviewer, EchoReviewer-7B. Experimental results demonstrate that EchoReviewer-7B can achieve significant and stable improvements on core review dimensions such as evidence support and review comprehensiveness, validating citation context as a robust and effective data paradigm for reliable automated peer review.

</details>


### [464] [ExperienceWeaver: Optimizing Small-sample Experience Learning for LLM-based Clinical Text Improvement](https://arxiv.org/abs/2602.00740)
*Ziyan Xiao,Yinghao Zhu,Liang Peng,Lequan Yu*

Main category: cs.CL

TL;DR: 本文提出了一种名为ExperienceWeaver的框架，用于在数据有限的情况下改进临床文本。该框架通过将反馈提炼成结构化知识（如错误提示和高级策略），并将其注入到模型中，使其学会“如何修改”而非仅仅“修改什么”，从而在小样本场景下超越了现有先进模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在改进临床文本时，由于数据量有限且医疗文档约束复杂，面临挑战。监督微调需要大量数据，而检索增强生成往往只能进行表面修正，无法捕捉修改背后的推理过程。因此，需要一种在小样本设置下有效改进临床文本的方法。

Method: 提出了一种名为ExperienceWeaver的层级框架。该框架的核心思想是从经验学习转向数据检索。它将嘈杂、多维度的反馈提炼成结构化、可操作的知识，包括错误特定的提示（Tips）和高级策略（Strategies）。然后，将这些提炼出的经验注入到一个代理（agentic）流程中，使模型学习“如何修改”。

Result: 在四个临床数据集上的广泛评估表明，ExperienceWeaver在小样本场景下持续提高了性能，并且超越了包括Gemini-3 Pro在内的最先进模型。

Conclusion: ExperienceWeaver通过将反馈提炼为可操作的知识，并将其融入代理流程，有效解决了当前大语言模型在小样本临床文本改进中的局限性，实现了显著的性能提升。

Abstract: Clinical text improvement is vital for healthcare efficiency but remains difficult due to limited high-quality data and the complex constraints of medical documentation. While Large Language Models (LLMs) show promise, current approaches struggle in small-sample settings: supervised fine-tuning is data-intensive and costly, while retrieval-augmented generation often provides superficial corrections without capturing the reasoning behind revisions. To address these limitations, we propose ExperienceWeaver, a hierarchical framework that shifts the focus from data retrieval to experience learning. Instead of simply recalling past examples, ExperienceWeaver distills noisy, multi-dimensional feedback into structured, actionable knowledge. Specifically, error-specific Tips and high-level Strategies. By injecting this distilled experience into an agentic pipeline, the model learns "how to revise" rather than just "what to revise". Extensive evaluations across four clinical datasets demonstrate that ExperienceWeaver consistently improves performance, surpassing state-of-the-art models such as Gemini-3 Pro in small-sample settings.

</details>


### [465] [CURP: Codebook-based Continuous User Representation for Personalized Generation with LLMs](https://arxiv.org/abs/2602.00742)
*Liang Wang,Xinyi Mou,Xiaoyou Liu,Xuanjing Huang,Zhongyu Wei*

Main category: cs.CL

TL;DR: 本文提出了一种名为CURP的新框架，通过双向用户编码器和离散原型码本来实现高效且可插拔的个性化，该框架仅需少量可训练参数，并在用户建模任务中表现出优越的性能、泛化能力、可解释性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示或训练的用户建模方法在个性化质量与计算/数据效率之间难以平衡。

Method: 采用双向用户编码器和离散原型码本提取多维用户特征，实现即插即用的个性化，仅训练约20M参数（占总模型规模的0.2%）。

Result: 在变体生成任务上的实验表明，CURP相比现有方法在性能和泛化能力上更优，同时具有更好的可解释性和可扩展性。

Conclusion: CURP提供了一种高效、可扩展且易于解释的用户建模框架，能够实现高质量的个性化，克服了现有方法的局限性。

Abstract: User modeling characterizes individuals through their preferences and behavioral patterns to enable personalized simulation and generation with Large Language Models (LLMs) in contemporary approaches. However, existing methods, whether prompt-based or training-based methods, face challenges in balancing personalization quality against computational and data efficiency. We propose a novel framework CURP, which employs a bidirectional user encoder and a discrete prototype codebook to extract multi-dimensional user traits. This design enables plug-and-play personalization with a small number of trainable parameters (about 20M parameters, about 0.2\% of the total model size). Through extensive experiments on variant generation tasks, we show that CURP achieves superior performance and generalization compared to strong baselines, while offering better interpretability and scalability. The code are available at https://github.com/RaidonWong/CURP_code

</details>


### [466] [Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training](https://arxiv.org/abs/2602.00747)
*Shengrui Li,Fei Zhao,Kaiyan Zhao,Jieying Ye,Haifeng Liu,Fangcheng Shi,Zheyong Xie,Yao Hu,Shaosheng Cao*

Main category: cs.CL

TL;DR: 本文提出了一种名为 DeMix 的新框架，该框架利用模型合并来预测 LLM 预训练的最佳数据比例，从而在不增加额外训练成本的情况下，能够评估无限多的数据混合比例，从而实现更优的数据混合比例发现。


<details>
  <summary>Details</summary>
Motivation: 在 LLM 预训练中，确定有效的数据混合比例是关键，但现有的方法要么依赖不可靠的小规模代理实验，要么需要昂贵的大规模探索。本文旨在解决这一难题，寻找一种更有效的方法来确定最优数据混合比例。

Method: DeMix 框架通过模型合并来预测最优数据比例。它在候选数据集上训练组件模型，然后通过加权模型合并来推导出数据混合比例的代理。这种方法将搜索与训练成本解耦。

Result: 实验表明，DeMix 能够打破效率、准确性和充分性之间的权衡，以更低的搜索成本获得更高的基准性能的最优混合比例。此外，还发布了包含 22T token 的 DeMix Corpora。

Conclusion: DeMix 是一种新颖有效的框架，能够通过模型合并来发现 LLM 预训练的最优数据混合比例，显著降低了搜索成本并提高了性能。DeMix Corpora 的发布将有助于未来的开放研究。

Abstract: Determining an effective data mixture is a key factor in Large Language Model (LLM) pre-training, where models must balance general competence with proficiency on hard tasks such as math and code. However, identifying an optimal mixture remains an open challenge, as existing approaches either rely on unreliable tiny-scale proxy experiments or require prohibitively expensive large-scale exploration. To address this, we propose Decouple Searching from Training Mix (DeMix), a novel framework that leverages model merging to predict optimal data ratios. Instead of training proxy models for every sampled mixture, DeMix trains component models on candidate datasets at scale and derives data mixture proxies via weighted model merging. This paradigm decouples search from training costs, enabling evaluation of unlimited sampled mixtures without extra training burden and thus facilitating better mixture discovery through more search trials. Extensive experiments demonstrate that DeMix breaks the trade-off between sufficiency, accuracy and efficiency, obtaining the optimal mixture with higher benchmark performance at lower search cost. Additionally, we release the DeMix Corpora, a comprehensive 22T-token dataset comprising high-quality pre-training data with validated mixtures to facilitate open research. Our code and DeMix Corpora is available at https://github.com/Lucius-lsr/DeMix.

</details>


### [467] [Temporal Leakage in Search-Engine Date-Filtered Web Retrieval: A Case Study from Retrospective Forecasting](https://arxiv.org/abs/2602.00758)
*Ali El Lahib,Ying-Jieh Xia,Zehan Li,Yuxuan Wang,Xinyu Pi*

Main category: cs.CL

TL;DR: 使用搜索引擎的日期过滤器来评估预测模型的准确性是不可靠的，因为71%的搜索结果包含超越日期限制的信息，这会显著夸大模型的预测能力。研究人员提出了解决此问题的方法。


<details>
  <summary>Details</summary>
Motivation: 研究人员发现，在评估预测模型时，使用搜索引擎的日期过滤器来限制检索到的信息存在可靠性问题，这可能导致对模型性能的错误评估。

Method: 研究人员通过审计Google搜索并使用“before:”过滤器来检查日期限制的有效性，并分析了常见的数据泄露机制。他们还使用一个大型语言模型（GPT-OSS-120B）在包含泄露信息和不包含泄露信息的数据集上进行预测，并比较了Brier分数。

Result: 在包含泄露信息的文档中，71%的问题会返回至少一个包含日期后信息的页面，其中41%的页面直接泄露了答案。使用GPT-OSS-120B模型，在泄露信息的文档上预测的准确性（Brier分数0.108）远高于在无泄露信息的文档上（Brier分数0.242）。

Conclusion: 日期限制的搜索引擎搜索不足以进行时间性评估。为了确保可信的预测评估，建议采取更强的检索保护措施，或者在冻结、带有时间戳的网页快照上进行评估。

Abstract: Search-engine date filters are widely used to enforce pre-cutoff retrieval in retrospective evaluations of search-augmented forecasters. We show this approach is unreliable: auditing Google Search with a before: filter, 71% of questions return at least one page containing strong post-cutoff leakage, and for 41%, at least one page directly reveals the answer. Using a large language model (LLM), gpt-oss-120b, to forecast with these leaky documents, we demonstrate an inflated prediction accuracy (Brier score 0.108 vs. 0.242 with leak-free documents). We characterize common leakage mechanisms, including updated articles, related-content modules, unreliable metadata/timestamps, and absence-based signals, and argue that date-restricted search is insufficient for temporal evaluation. We recommend stronger retrieval safeguards or evaluation on frozen, time-stamped web snapshots to ensure credible retrospective forecasting.

</details>


### [468] [Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning](https://arxiv.org/abs/2602.00759)
*Zhipeng Chen,Xiaobo Qin,Wayne Xin Zhao,Youbin Wu,Ji-Rong Wen*

Main category: cs.CL

TL;DR: 提出了一种名为 A$^2$D 的自适应能力分解方法，通过将复杂问题分解为简单子问题来增强基于可验证奖励的强化学习 (RLVR) 在大型语言模型 (LLM) 中的应用效果，解决了 RLVR 中信息有限导致的盲目探索问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于可验证奖励的强化学习 (RLVR) 方法在增强大型语言模型 (LLM) 的推理能力方面潜力巨大，但由于 RLVR 过程中信息有限，模型常进行盲目探索，导致在复杂问题上表现不佳。

Method: A$^2$D 方法首先通过 RLVR 训练一个 decomposer（不依赖蒸馏），使其能够将复杂问题分解为一组更简单的子问题。然后，利用该 decomposer 为训练数据集中的每个问题标注子问题，并通过 RLVR 在子问题指导下训练 reasoner。

Result: 与现有基线方法相比，A$^2$D 表现出有效性。该方法可以作为即插即用模块应用于不同的 RLVR 算法。同时，分析表明 RLVR 过程会影响 decomposer 的性能和行为，并且不同类型的子问题指导对 reasoner 的探索和利用能力有不同的增强效果。

Conclusion: A$^2$D 方法通过自适应地分解复杂问题为子问题，有效克服了 RLVR 中信息不足导致的探索局限性，提升了 LLM 的推理能力，并且具有良好的通用性和可解释性。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration, which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A$^2$D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions. Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A$^2$D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer, revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner's exploration and exploitation abilities.

</details>


### [469] [APR: Penalizing Structural Redundancy in Large Reasoning Models via Anchor-based Process Rewards](https://arxiv.org/abs/2602.00760)
*Kaiyan Chang,Chenwei Zhu,Yingfeng Luo,Yifu Huo,Chenglong Wang,Xiaoqian Liu,Qiaozhi He,Tong Xiao,Zhengtao Yu,Jingbo Zhu*

Main category: cs.CL

TL;DR: 该研究提出了Anchor-based Process Reward (APR)方法，通过识别并惩罚大型推理模型（LRMs）在推理过程中不必要的重复验证（Answer-Stable Tail, AST），来解决Test-Time Scaling（TTS）带来的“过度思考”问题，从而在保证性能的同时显著提高了效率。


<details>
  <summary>Details</summary>
Motivation: Test-Time Scaling（TTS）虽然提升了大型推理模型（LRMs）的能力，但会引入“过度思考”的副作用。研究者观察到LRMs在得出最终答案后仍会进行重复的自我验证，这促使他们去理解并解决这种现象。

Method: 该研究首先定义了“推理锚点”（Reasoning Anchor），即答案首次稳定的时间点。然后，他们分析了锚点前后的推理行为，发现了“答案稳定尾”（Answer-Stable Tail, AST）这一结构性冗余。在此基础上，他们提出了一种名为Anchor-based Process Reward (APR)的奖励塑造方法，该方法能够定位推理锚点并专门惩罚锚点后的AST，并结合策略优化算法进行训练。

Result: APR模型在1.5B和7B参数规模下，平均在五个数学推理数据集上实现了性能-效率的帕累托最优，并且在强化学习训练中显著减少了计算资源的需求。

Conclusion: APR是一种有效的奖励塑造方法，通过惩罚大型推理模型在推理过程中的冗余验证，能够在不牺牲性能的情况下显著提高模型效率，并有望成为解决TTS副作用的一种新途径。

Abstract: Test-Time Scaling (TTS) has significantly enhanced the capabilities of Large Reasoning Models (LRMs) but introduces a critical side-effect known as Overthinking. We conduct a preliminary study to rethink this phenomenon from a fine-grained perspective. We observe that LRMs frequently conduct repetitive self-verification without revision even after obtaining the final answer during the reasoning process. We formally define this specific position where the answer first stabilizes as the Reasoning Anchor. By analyzing pre- and post-anchor reasoning behaviors, we uncover the structural redundancy fixed in LRMs: the meaningless repetitive verification after deriving the first complete answer, which we term the Answer-Stable Tail (AST). Motivated by this observation, we propose Anchor-based Process Reward (APR), a structure-aware reward shaping method that localizes the reasoning anchor and penalizes exclusively the post-anchor AST. Leveraging the policy optimization algorithm suitable for length penalties, our APR models achieved the performance-efficiency Pareto frontier at 1.5B and 7B scales averaged across five mathematical reasoning datasets while requiring significantly fewer computational resources for RL training.

</details>


### [470] [WordCraft: Scaffolding the Keyword Method for L2 Vocabulary Learning with Multimodal LLMs](https://arxiv.org/abs/2602.00762)
*Yuheng Shao,Junjie Xiong,Chaoran Wu,Xiyuan Wang,Ziyu Zhou,Yang Ouyang,Qinyi Tao,Quan Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为WordCraft的以学习者为中心的交互式工具，该工具利用多模态大语言模型（MLLMs）来辅助中文母语者记忆英语词汇。该工具通过引导学习者进行关键词选择、联想构建和图像形成，解决了传统关键词法在发音、联想和图像生成方面的困难，并在用户研究中证明了其有效性和可用性。


<details>
  <summary>Details</summary>
Motivation: 现有关键词法在中文母语者学习英语词汇时存在生成不当发音的关键词、构建不连贯联想以及缺乏生动心理图像等挑战。现有的自动化工具或结果导向的辅助工具，要么牺牲了学习者的参与度，要么缺乏过程指导。因此，需要一种能够解决这些局限性的方法。

Method: 研究首先通过一项包含18名中文母语-英语第二语言学习者和教育工作者的形成性研究，揭示了应用关键词法学习词汇的关键难点和需求。在此基础上，开发了WordCraft工具，该工具利用多模态大语言模型（MLLMs），通过引导学习者完成关键词选择、联想构建和图像形成等步骤来辅助关键词法的应用。最后，通过两次用户研究来评估WordCraft的有效性和可用性。

Result: WordCraft不仅保留了生成效应，还在用户研究中实现了高水平的有效性和可用性。具体而言，该工具能够有效地帮助学习者克服在关键词法应用中的障碍，提高词汇记忆的效率。

Conclusion: WordCraft是一种有效的、以学习者为中心的交互式工具，它通过MLLMs赋能，能够有效地辅助中文母语-英语第二语言学习者应用关键词法记忆词汇，克服了现有方法的不足，并具有良好的用户体验。

Abstract: Applying the keyword method for vocabulary memorization remains a significant challenge for L1 Chinese-L2 English learners. They frequently struggle to generate phonologically appropriate keywords, construct coherent associations, and create vivid mental imagery to aid long-term retention. Existing approaches, including fully automated keyword generation and outcome-oriented mnemonic aids, either compromise learner engagement or lack adequate process-oriented guidance. To address these limitations, we conducted a formative study with L1 Chinese-L2 English learners and educators (N=18), which revealed key difficulties and requirements in applying the keyword method to vocabulary learning. Building on these insights, we introduce WordCraft, a learner-centered interactive tool powered by Multimodal Large Language Models (MLLMs). WordCraft scaffolds the keyword method by guiding learners through keyword selection, association construction, and image formation, thereby enhancing the effectiveness of vocabulary memorization. Two user studies demonstrate that WordCraft not only preserves the generation effect but also achieves high levels of effectiveness and usability.

</details>


### [471] [Eliciting Trustworthiness Priors of Large Language Models via Economic Games](https://arxiv.org/abs/2602.00769)
*Siyu Yan,Lusha Zhu,Jian-Qiao Zhu*

Main category: cs.CL

TL;DR: 研究提出了一种基于迭代上下文学习的方法，用于从大型语言模型（LLMs）中提取信任度先验，并发现GPT-4.1的信任度与人类相似。研究还探讨了GPT-4.1如何根据不同的玩家个性区分信任度，并证明了这种信任度变异可以通过基于刻板印象（温暖度和能力）的模型来预测。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在建立以人为本、可信赖的AI方面面临挑战，一个关键问题是如何准确衡量AI系统自身的信任水平，以避免过度信任或信任不足。

Method: 研究提出了一种新颖的elicitation方法，基于迭代上下文学习（Zhu and Griffiths, 2024a），并将其应用于行为博弈论中的信任游戏，以提取信任度先验。利用此方法，研究对多个领先的LLMs进行了信任度先验的提取，并分析了GPT-4.1对不同玩家角色的反应。最后，使用基于感知温暖度和能力（warmth and competence）的刻板印象模型来预测信任度的变异。

Result: 研究发现GPT-4.1的信任度先验与人类在信任游戏中观察到的结果非常接近。此外，GPT-4.1能够根据不同的玩家角色调整其信任度，并且这种信任度的变异可以通过基于温暖度和能力的刻板印象模型很好地预测。

Conclusion: 通过迭代上下文学习和信任游戏，研究成功地从LLMs（特别是GPT-4.1）中提取了信任度先验，并证明了这些模型在信任度表达上可以接近人类水平。研究还为理解LLMs如何区分信任以及信任度与社会感知（温暖度和能力）之间的关系提供了新的视角。

Abstract: One critical aspect of building human-centered, trustworthy artificial intelligence (AI) systems is maintaining calibrated trust: appropriate reliance on AI systems outperforms both overtrust (e.g., automation bias) and undertrust (e.g., disuse). A fundamental challenge, however, is how to characterize the level of trust exhibited by an AI system itself. Here, we propose a novel elicitation method based on iterated in-context learning (Zhu and Griffiths, 2024a) and apply it to elicit trustworthiness priors using the Trust Game from behavioral game theory. The Trust Game is particularly well suited for this purpose because it operationalizes trust as voluntary exposure to risk based on beliefs about another agent, rather than self-reported attitudes. Using our method, we elicit trustworthiness priors from several leading large language models (LLMs) and find that GPT-4.1's trustworthiness priors closely track those observed in humans. Building on this result, we further examine how GPT-4.1 responds to different player personas in the Trust Game, providing an initial characterization of how such models differentiate trust across agent characteristics. Finally, we show that variation in elicited trustworthiness can be well predicted by a stereotype-based model grounded in perceived warmth and competence.

</details>


### [472] [Reasoning as State Transition: A Representational Analysis of Reasoning Evolution in Large Language Models](https://arxiv.org/abs/2602.00770)
*Siyuan Zhang,Jialian Li,Yichi Zhang,Xiao Yang,Yinpeng Dong,Hang Su*

Main category: cs.CL

TL;DR: 本研究从模型内部表征的角度，而非仅仅输出结果，来探究大型语言模型在推理任务上的能力演变。研究发现，训练后的模型在静态表征质量上提升有限，但其推理能力主要体现在生成过程中的表征分布的连续变化。训练后的模型能更好地引导这种变化以优化任务解决。研究还证实了最终表征与生成正确性高度相关，并且生成序列的语义是驱动这种表征变化的主要因素。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过观察模型显式生成的结果来分析大型语言模型推理能力在训练过程中的演变，将推理过程视为黑箱，忽略了内部机制的变化。本研究旨在通过研究模型内部状态的动态变化，来解决这种不透明性问题。

Method: 研究引入了表征分析的视角，通过对不同训练阶段的模型进行全面的实验，探究其内部状态的动态变化。采用统计分析确认了生成正确性与最终表征之间的高度相关性，并进行反事实实验以确定导致表征转变的关键因素。

Result: 研究发现，训练后的模型在静态初始表征质量上的提升有限。与非推理任务不同，推理任务在生成过程中涉及表征的显著连续分布变化。对比分析表明，训练后的模型能更好地驱动这种分布变化以优化任务解决。统计分析证实了生成正确性与最终表征之间的高度相关性。

Conclusion: 本研究提供了对模型推理过程及其训练增强机制的新认识。研究表明，训练后的模型在引导生成过程中的表征分布变化方面表现更优，这与生成序列的语义密切相关，而非额外的推理计算或参数差异。这些发现为未来模型分析和优化提供了宝贵的见解。

Abstract: Large Language Models have achieved remarkable performance on reasoning tasks, motivating research into how this ability evolves during training. Prior work has primarily analyzed this evolution via explicit generation outcomes, treating the reasoning process as a black box and obscuring internal changes. To address this opacity, we introduce a representational perspective to investigate the dynamics of the model's internal states. Through comprehensive experiments across models at various training stages, we discover that post-training yields only limited improvement in static initial representation quality. Furthermore, we reveal that, distinct from non-reasoning tasks, reasoning involves a significant continuous distributional shift in representations during generation. Comparative analysis indicates that post-training empowers models to drive this transition toward a better distribution for task solving. To clarify the relationship between internal states and external outputs, statistical analysis confirms a high correlation between generation correctness and the final representations; while counterfactual experiments identify the semantics of the generated tokens, rather than additional computation during inference or intrinsic parameter differences, as the dominant driver of the transition. Collectively, we offer a novel understanding of the reasoning process and the effect of training on reasoning enhancement, providing valuable insights for future model analysis and optimization.

</details>


### [473] [HyLRA: Hybrid Layer Reuse Attention for Efficient Long-Context Inference](https://arxiv.org/abs/2602.00777)
*Xuan Ai,Qingqing Yang,Peng Wang,Lei Deng,Lin Zhang,Renhai Chen,Gong Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为 HyLRA 的新颖框架，通过层级稀疏性分析，在保证模型准确率的同时，将 LLM 的长上下文推理吞吐量提高了 6%-46%。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在处理长上下文时，由于注意力机制的二次计算复杂度和 KV 缓存的内存占用而受到限制。现有的稀疏注意力方法通常采用固定的模式或激进的剪枝，难以在效率和准确性之间取得最佳平衡。

Method: HyLRA 框架基于层级稀疏性分析，发现在注意力机制中存在“层内敏感性”（某些层需要完整注意力）和“层间相似性”（连续层共享关键 token）。利用这些观察，HyLRA 使用离线动态规划来确定最优的层级策略：对敏感层保留完整注意力，对容忍层则通过重用前一层中最重要的 k 个 token 的索引来避免二次计算。

Result: HyLRA 在实际评估中，将推理吞吐量提高了 6% 到 46%，同时准确率的下降小于 1%，并且在性能上持续优于现有的稀疏注意力方法。

Conclusion: HyLRA 通过结合层内敏感层和层间相似性，有效地解决了 LLM 长上下文推理中的二次计算瓶颈，在保持模型性能的同时显著提高了推理效率。

Abstract: Long-context inference in Large Language Models (LLMs) is bottlenecked by the quadratic computation complexity of attention and the substantial memory footprint of Key-Value (KV) caches. While existing sparse attention mechanisms attempt to mitigate this by exploiting inherent sparsity, they often rely on rigid patterns or aggressive pruning, failing to achieve an optimal balance between efficiency and accuracy. In this paper, we introduce {\bf HyLRA} ({\bf Hy}brid {\bf L}ayer {\bf R}euse {\bf A}ttention), a novel framework driven by layer-wise sparsity profiling. Our empirical analysis uncovers a dual characteristic in attention mechanics: \textit{intra-layer sensitivity}, where specific layers necessitate full attention to prevent feature distortion, and \textit{inter-layer similarity}, where consecutive layers share substantial critical tokens. Based on these observations, HyLRA employs an offline dynamic programming approach to derive an optimal layer-wise policy. This hybrid strategy retains full attention for sensitive layers to ensure robustness, while enabling tolerant layers to bypass quadratic calculations by directly reusing top-$k$ indices from preceding layers. This approach allows LLMs to restrict computation to the most critical tokens, effectively overcoming the quadratic bottleneck of dense attention. Extensive evaluations demonstrate that HyLRA improves inference throughput by 6\%--46\% while maintaining comparable performance (with $<1\%$ accuracy degradation), consistently outperforming state-of-the-art sparse attention methods. HyLRA is open source at \href{https://anonymous.4open.science/r/unified-cache-management-CF80/}{\texttt{/r/unified-cache-management-CF80/}}

</details>


### [474] [Omni-RRM: Advancing Omni Reward Modeling via Automatic Rubric-Grounded Preference Synthesis](https://arxiv.org/abs/2602.00846)
*Zicheng Kong,Dehua Ma,Zhenbo Xu,Alven Yang,Yiwei Ru,Haoran Wang,Zixuan Zhou,Fuqing Bie,Liuyu Xiang,Huijia Wu,Jian Zhao,Zhaofeng He*

Main category: cs.CL

TL;DR: 本文提出了一种名为Omni-RRM的多模态奖励模型，它能够对文本、图像、视频和音频进行多维度、有理由的偏好判断，无需人工标注，并且在视频和音频任务上取得了当前最优的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐技术受限于粗粒度的奖励模型，这些奖励模型主要面向视觉，评分不透明，且需要昂贵的人工标注。因此，作者希望开发一个更有效、更通用的奖励模型。

Method: 作者引入了Omni-RRM，一个开放源码的、基于评分标准的奖励模型。其核心是Omni-Preference数据集，通过自动化流程合成候选响应对，并利用强大的教师模型进行偏好协调、过滤，并提供跨模态的、基于评分标准的理由。Omni-RRM分两阶段训练：监督微调学习评分标准的输出，然后进行强化学习（GRPO）以提高对低对比度样本的辨别能力。

Result: Omni-RRM在视频（ShareGPT-V上80.2%）和音频（Audio-HH-RLHF上66.8%）基准测试中达到了当前最优的准确率，在图像任务上也显著优于现有的开源奖励模型，总体准确率比基线模型提升了17.7%。Omni-RRM还可以通过Best-of-N选择提升下游性能，并能迁移到纯文本偏好基准测试。

Conclusion: Omni-RRM是首个开源的、基于评分标准的、支持多模态（文本、图像、视频、音频）的奖励模型，它通过全自动化数据集构建消除了人工标注的需求，并在多个模态的评估中取得了显著的性能提升，证明了其在提高多模态大语言模型对齐能力方面的有效性。

Abstract: Multimodal large language models (MLLMs) have shown remarkable capabilities, yet their performance is often capped by the coarse nature of existing alignment techniques. A critical bottleneck remains the lack of effective reward models (RMs): existing RMs are predominantly vision-centric, return opaque scalar scores, and rely on costly human annotations. We introduce \textbf{Omni-RRM}, the first open-source rubric-grounded reward model that produces structured, multi-dimension preference judgments with dimension-wise justifications across \textbf{text, image, video, and audio}. At the core of our approach is \textbf{Omni-Preference}, a large-scale dataset built via a fully automated pipeline: we synthesize candidate response pairs by contrasting models of different capabilities, and use strong teacher models to \emph{reconcile and filter} preferences while providing a modality-aware \emph{rubric-grounded rationale} for each pair. This eliminates the need for human-labeled training preferences. Omni-RRM is trained in two stages: supervised fine-tuning to learn the rubric-grounded outputs, followed by reinforcement learning (GRPO) to sharpen discrimination on difficult, low-contrast pairs. Comprehensive evaluations show that Omni-RRM achieves state-of-the-art accuracy on video (80.2\% on ShareGPT-V) and audio (66.8\% on Audio-HH-RLHF) benchmarks, and substantially outperforms existing open-source RMs on image tasks, with a 17.7\% absolute gain over its base model on overall accuracy. Omni-RRM also improves downstream performance via Best-of-$N$ selection and transfers to text-only preference benchmarks. Our data, code, and models are available at https://anonymous.4open.science/r/Omni-RRM-CC08.

</details>


### [475] [Factuality on Demand: Controlling the Factuality-Informativeness Trade-off in Text Generation](https://arxiv.org/abs/2602.00848)
*Ziwei Gong,Yanda Chen,Julia Hirschberg,Chen Zhao,He He,Zhou Yu,Kathleen Mckeown*

Main category: cs.CL

TL;DR: 本文提出了一种名为Factuality-Controlled Generation (FCG)的框架，允许用户在查询中指定事实性约束，从而在信息丰富度和事实准确度之间取得平衡。通过使用合成数据进行训练，该框架能显著提高模型的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成响应时，在信息丰富度和事实准确度之间存在固有权衡。不同的应用场景需要不同的平衡点，因此需要一种方法来控制生成内容的准确性。

Method: 提出Factuality-Controlled Generation (FCG)框架，允许用户在查询中加入事实性约束。评估标准包括对事实性约束的遵守程度和响应的信息丰富度。使用合成数据训练模型以执行FCG任务。

Result: 使用合成数据训练的模型在遵守事实性要求和保持信息丰富度方面均有显著提升。

Conclusion: FCG框架能够有效地让用户控制大型语言模型的生成输出，使其在满足事实性约束的同时，仍能提供有用的信息。

Abstract: Large language models (LLMs) encode knowledge with varying degrees of confidence. When responding to queries, models face an inherent trade-off: they can generate responses that are less informative but highly factual, or more informative but potentially less accurate. Different applications demand different balances between informativeness and factuality. We introduce Factuality-Controlled Generation (FCG), a framework that enables users to specify factuality constraints alongside their queries. We propose to evaluate FCG performance on two dimensions: adherence to factuality constraints and response informativeness. We propose to train models on the FCG task using synthetic data, and show that our synthetic training significantly improves models' ability to both respect factuality requirements and maintain informativeness in their outputs.

</details>


### [476] [Unifying Adversarial Robustness and Training Across Text Scoring Models](https://arxiv.org/abs/2602.00857)
*Manveer Singh Tamber,Hosna Oyarhoseini,Jimmy Lin*

Main category: cs.CL

TL;DR: 本研究提出统一文本评分模型（包括稠密检索器、重排序器和奖励模型）的对抗鲁棒性研究，并开发了新的对抗训练方法，以提高模型的鲁棒性和任务性能，特别是在 RLHF 中减轻奖励欺骗。


<details>
  <summary>Details</summary>
Motivation: 当前关于语言模型对抗鲁棒性的研究分散在不同的应用和攻击方式上，导致研究碎片化，难以发现共性漏洞。研究者希望通过统一研究文本评分模型来克服这一挑战。

Method: 1. 提出统一框架，将稠密检索器、重排序器和奖励模型视为文本评分模型，并适配跨模型角色的攻击和对抗训练方法。2. 定义文本评分模型的失败标准：攻击成功时，不相关或被拒绝的文本得分高于相关或被选择的文本。3. 提出多种用于文本评分模型的对抗训练方法，并展示组合互补方法可以提高鲁棒性和任务有效性。4. 评估所提出方法的实用性，特别是在 RLHF 中，展示对抗训练的奖励模型可以缓解奖励欺骗并支持训练更好的 LLM。

Result: 1. 现有语言模型的对抗训练方法往往目光短浅，难以跨攻击泛化。2. 结合互补的对抗训练方法可以实现强大的鲁棒性，同时提高任务有效性。3. 对抗训练的奖励模型可以有效缓解奖励欺骗，并支持训练出更符合要求的 LLM。

Conclusion: 通过统一研究文本评分模型的对抗鲁棒性，并开发结合多种方法的对抗训练策略，可以显著提高模型的鲁棒性和任务性能，尤其在 RLHF 场景中，能够有效解决奖励欺骗问题，促进更优的 LLM 训练。

Abstract: Research on adversarial robustness in language models is currently fragmented across applications and attacks, obscuring shared vulnerabilities. In this work, we propose unifying the study of adversarial robustness in text scoring models spanning dense retrievers, rerankers, and reward models. This motivates adapting both attacks and adversarial training methods across model roles. Unlike open-ended generation, text scoring failures are directly testable: an attack succeeds when an irrelevant or rejected text outscores a relevant or chosen one. Using this principled lens of text scoring, we demonstrate that current adversarial training formulations for language models are often short-sighted, failing to effectively generalize across attacks. To address this, we introduce multiple adversarial training methods for text scoring models and show that combining complementary training methods can yield strong robustness while also improving task effectiveness. We also highlight the practical value of our approach for RLHF, showing that our adversarially trained reward models mitigate reward hacking and support the training of better-aligned LLMs. We provide our code and models for further study.

</details>


### [477] [ILSIC: Corpora for Identifying Indian Legal Statutes from Queries by Laypeople](https://arxiv.org/abs/2602.00881)
*Shounak Paul,Raghav Dogra,Pawan Goyal,Saptarshi Ghosh*

Main category: cs.CL

TL;DR: 本研究创建了一个名为ILSIC的新型法律法规识别（LSI）语料库，其中包含来自印度法律的500多个法规的非专业人士查询，并附带判决书，以研究法院数据与非专业人士数据在LSI任务上的差异。


<details>
  <summary>Details</summary>
Motivation: 现有法律法规识别（LSI）研究主要依赖于法庭判决书作为输入，但实际应用中，用户查询更可能是非专业的、非正式的。现有针对非专业人士的LSI数据集很少，且缺乏对法院数据与非专业人士数据之间差异的研究。

Method: 创建了一个名为ILSIC的语料库，包含500多个印度法律法规的非专业人士查询和法庭判决书。在ILSIC语料库上进行了广泛的实验，包括零样本/少样本推理、检索增强生成和监督微调。

Result: 纯粹在法院判决书上训练的模型在测试非专业人士查询时效果不佳。在某些情况下，从法院数据到非专业人士数据的迁移学习是有益的。研究还对查询类别和法规频率进行了细粒度分析。

Conclusion: 法院判决书数据与非专业人士查询数据在LSI任务上存在显著差异，表明为非专业人士量身定制的LSI方法是必要的。迁移学习可以作为一种有益的策略，但需要谨慎应用。

Abstract: Legal Statute Identification (LSI) for a given situation is one of the most fundamental tasks in Legal NLP. This task has traditionally been modeled using facts from court judgments as input queries, due to their abundance. However, in practical settings, the input queries are likely to be informal and asked by laypersons, or non-professionals. While a few laypeople LSI datasets exist, there has been little research to explore the differences between court and laypeople data for LSI. In this work, we create ILSIC, a corpus of laypeople queries covering 500+ statutes from Indian law. Additionally, the corpus also contains court case judgements to enable researchers to effectively compare between court and laypeople data for LSI. We conducted extensive experiments on our corpus, including benchmarking over the laypeople dataset using zero and few-shot inference, retrieval-augmented generation and supervised fine-tuning. We observe that models trained purely on court judgements are ineffective during test on laypeople queries, while transfer learning from court to laypeople data can be beneficial in certain scenarios. We also conducted fine-grained analyses of our results in terms of categories of queries and frequency of statutes.

</details>


### [478] [EffGen: Enabling Small Language Models as Capable Autonomous Agents](https://arxiv.org/abs/2602.00887)
*Gaurav Srivastava,Aafiya Hussain,Chi Wang,Yingyan Celine Lin,Xuan Wang*

Main category: cs.CL

TL;DR: effGen 是一个开源的、为小型语言模型（SLMs）优化的代理框架，通过提示优化、任务分解、路由和统一记忆系统，实现了高效、经济且安全的本地部署，并在多个基准测试中超越了现有框架。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 API 的语言模型代理系统成本高昂且存在隐私问题，促使研究者开发一个针对小型语言模型（SLMs）的、可本地部署的、高效且安全的代理框架。

Method: effGen 提出了四项主要贡献：1. 增强的工具调用，通过提示优化显著压缩上下文；2. 智能任务分解，根据依赖关系将复杂查询分解为子任务；3. 基于复杂度的路由，通过五个因素进行预执行决策；4. 统一的记忆系统，结合短期、长期和向量存储。此外，还统一了多种代理协议。

Result: 在 13 个基准测试中，effGen 在成功率、执行速度和内存占用方面均优于 LangChain、AutoGen 和 Smolagents。研究发现，提示优化对 SLMs 提升更明显，而复杂度路由对大型模型收益更大，两者结合能在所有模型规模上带来一致的收益。

Conclusion: effGen 是一个面向 SLMs 的高效、经济且安全的代理框架，通过其创新的组件和统一的协议支持，显著提高了代理系统的性能，并为研究和商业应用提供了广泛的可用性。

Abstract: Most existing language model agentic systems today are built and optimized for large language models (e.g., GPT, Claude, Gemini) via API calls. While powerful, this approach faces several limitations including high token costs and privacy concerns for sensitive applications. We introduce effGen, an open-source agentic framework optimized for small language models (SLMs) that enables effective, efficient, and secure local deployment (pip install effgen). effGen makes four major contributions: (1) Enhanced tool-calling with prompt optimization that compresses contexts by 70-80% while preserving task semantics, (2) Intelligent task decomposition that breaks complex queries into parallel or sequential subtasks based on dependencies, (3) Complexity-based routing using five factors to make smart pre-execution decisions, and (4) Unified memory system combining short-term, long-term, and vector-based storage. Additionally, effGen unifies multiple agent protocols (MCP, A2A, ACP) for cross-protocol communication. Results on 13 benchmarks show effGen outperforms LangChain, AutoGen, and Smolagents with higher success rates, faster execution, and lower memory. Our results reveal that prompt optimization and complexity routing have complementary scaling behavior: optimization benefits SLMs more (11.2% gain at 1.5B vs 2.4% at 32B), while routing benefits large models more (3.6% at 1.5B vs 7.9% at 32B), providing consistent gains across all scales when combined. effGen (https://effgen.org/) is released under the MIT License, ensuring broad accessibility for research and commercial use. Our framework code is publicly available at https://github.com/ctrl-gaurav/effGen.

</details>


### [479] [Do Schwartz Higher-Order Values Help Sentence-Level Human Value Detection? When Hard Gating Hurts](https://arxiv.org/abs/2602.00913)
*Víctor Yeste,Paolo Rosso*

Main category: cs.CL

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Sentence-level human value detection is typically framed as multi-label classification over Schwartz values, but it remains unclear whether Schwartz higher-order (HO) categories provide usable structure. We study this under a strict compute-frugal budget (single 8 GB GPU) on ValueEval'24 / ValuesML (74K English sentences). We compare (i) direct supervised transformers, (ii) HO$\rightarrow$values pipelines that enforce the hierarchy with hard masks, and (iii) Presence$\rightarrow$HO$\rightarrow$values cascades, alongside low-cost add-ons (lexica, short context, topics), label-wise threshold tuning, small instruction-tuned LLM baselines ($\le$10B), QLoRA, and simple ensembles. HO categories are learnable from single sentences (e.g., the easiest bipolar pair reaches Macro-$F_1\approx0.58$), but hard hierarchical gating is not a reliable win: it often reduces end-task Macro-$F_1$ via error compounding and recall suppression. In contrast, label-wise threshold tuning is a high-leverage knob (up to $+0.05$ Macro-$F_1$), and small transformer ensembles provide the most consistent additional gains (up to $+0.02$ Macro-$F_1$). Small LLMs lag behind supervised encoders as stand-alone systems, yet can contribute complementary errors in cross-family ensembles. Overall, HO structure is useful descriptively, but enforcing it with hard gates hurts sentence-level value detection; robust improvements come from calibration and lightweight ensembling.

</details>


### [480] [A Baseline Multimodal Approach to Emotion Recognition in Conversations](https://arxiv.org/abs/2602.00914)
*Víctor Yeste,Rodrigo Rivas-Arévalo*

Main category: cs.CL

TL;DR: 本文提出了一种用于对话情感识别的轻量级多模态基线模型，结合了基于 Transformer 的文本分类器和自监督语音表示模型，并通过简单的 late-fusion 集成。


<details>
  <summary>Details</summary>
Motivation: 本文的目的是提供一个易于实现的参考实现，用于对话情感识别，而非追求最先进的技术，以便为未来的研究提供透明度和支持。

Method: 使用了基于 Transformer 的文本分类器和自监督语音表示模型，并将它们的输出通过简单的 late-fusion 集成。

Result: 报告了基线模型的设置和在有限训练协议下的实证结果，并强调了多模态融合在何种情况下优于单模态模型。

Conclusion: 该模型是一个易于实现的参考实现，为对话情感识别任务提供了基线性能，并突出了多模态融合的优势。

Abstract: We present a lightweight multimodal baseline for emotion recognition in conversations using the SemEval-2024 Task 3 dataset built from the sitcom Friends. The goal of this report is not to propose a novel state-of-the-art method, but to document an accessible reference implementation that combines (i) a transformer-based text classifier and (ii) a self-supervised speech representation model, with a simple late-fusion ensemble. We report the baseline setup and empirical results obtained under a limited training protocol, highlighting when multimodal fusion improves over unimodal models. This preprint is provided for transparency and to support future, more rigorous comparisons.

</details>


### [481] [Neural FOXP2 -- Language Specific Neuron Steering for Targeted Language Improvement in LLMs](https://arxiv.org/abs/2602.00945)
*Anusa Saha,Tanmay Joshi,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 研究表明，大型语言模型（LLMs）虽然具备多语言能力，但受预训练数据影响，常以英语为默认语言。本文提出 Neural FOXP2 方法，通过定位和引导“语言神经元”来解决此问题，实现了将模型默认语言切换为印地语或西班牙语。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在预训练中受到英语主导的影响，导致非英语语言能力被抑制。研究的动机是找出并控制 LLMs 的语言默认行为，使其能够有效支持非英语语言。

Method: Neural FOXP2 方法包含三个阶段：1. 定位（Localize）：使用稀疏自编码器（SAEs）将模型激活分解为特征组件，识别出对目标语言（印地语/西班牙语）和英语具有选择性的特征，并追踪这些特征对应的神经元，形成“语言神经元”集合。2. 引导方向（Steering directions）：通过谱低秩分析，提取控制语言转换的关键激活差值矩阵的奇异向量，形成一个低秩的引导子空间，并确定最有效的干预窗口。3. 引导（Steer）：在模型的低至中层，对选定的语言神经元施加稀疏激活偏移，具体为沿着目标语言主导方向进行正向引导，并对英语神经元进行补偿性负向引导，从而实现目标语言的默认化。

Result: 通过 Neural FOXP2 方法，成功将模型的默认语言从英语切换为印地语或西班牙语。该方法能够定位并操纵控制语言的神经元，实现对语言默认性的可控改变。

Conclusion: 语言默认性可以通过稀疏、低秩的控制电路（语言神经元）来管理。Neural FOXP2 方法能够机制性地分离和引导这些语言神经元，从而安全有效地实现 LLMs 的语言默认化，提升其对非英语语言的支持能力。

Abstract: LLMs are multilingual by training, yet their lingua franca is often English, reflecting English language dominance in pretraining. Other languages remain in parametric memory but are systematically suppressed. We argue that language defaultness is governed by a sparse, low-rank control circuit, language neurons, that can be mechanistically isolated and safely steered.
  We introduce Neural FOXP2, that makes a chosen language (Hindi or Spanish) primary in a model by steering language-specific neurons. Neural FOXP2 proceeds in three stages: (i) Localize: We train per-layer SAEs so each activation decomposes into a small set of active feature components. For every feature, we quantify English vs. Hindi/Spanish selectivity overall logit-mass lift toward the target-language token set. Tracing the top-ranked features back to their strongest contributing units yields a compact language-neuron set. (ii) Steering directions: We localize controllable language-shift geometry via a spectral low-rank analysis. For each layer, we build English to target activation-difference matrices and perform layerwise SVD to extract the dominant singular directions governing language change. The eigengap and effective-rank spectra identify a compact steering subspace and an empirically chosen intervention window (where these directions are strongest and most stable). (iii) Steer: We apply a signed, sparse activation shift targeted to the language neurons. Concretely, within low to mid layers we add a positive steering along the target-language dominant directions and a compensating negative shift toward the null space for the English neurons, yielding controllable target-language defaultness.

</details>


### [482] [Verification Required: The Impact of Information Credibility on AI Persuasion](https://arxiv.org/abs/2602.00970)
*Saaduddin Mahmud,Eugene Bagdasarian,Shlomo Zilberstein*

Main category: cs.CL

TL;DR: 本文提出了一个名为MixTalk的战略沟通游戏，用于模拟LLM之间的信息交互，该游戏考虑了信息的可验证性和不确定性。研究评估了当前LLM在处理这种交互时的表现，并提出了一种名为TOPD的方法来提高接收者在面对说服时的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在完全不可验证的廉价通话或完全可验证的信息披露，未能捕捉到信息具有概率可信度的现实场景，而LLM代理越来越多地应用于高风险决策的沟通场景，因此需要对战略沟通进行原则性理解。

Method: 作者提出了MixTalk游戏，其中发送者代理结合可验证和不可验证的声明来传达私有信息，接收者代理则分配预算进行成本验证，并从先验信念、声明和验证结果中推断底层状态。此外，还提出了一种名为TOPD的离线方法，通过交互日志蒸馏出锦标赛Oracle策略，并在推理时进行上下文部署。

Result: 在三个现实部署场景的大规模锦标赛中，评估了最先进的LLM代理。结果揭示了它们在推理信息可信度方面的优势和局限性，以及塑造这些交互的明确行为。TOPD方法显著提高了接收者代理在面对说服时的鲁棒性。

Conclusion: MixTalk游戏能够模拟具有概率可信度的信息交互，并能有效评估LLM代理在战略沟通中的表现。TOPD是一种有效的离线方法，可以提高LLM接收者代理的鲁棒性，使其更能抵御欺骗性信息。

Abstract: Agents powered by large language models (LLMs) are increasingly deployed in settings where communication shapes high-stakes decisions, making a principled understanding of strategic communication essential. Prior work largely studies either unverifiable cheap-talk or fully verifiable disclosure, failing to capture realistic domains in which information has probabilistic credibility. We introduce MixTalk, a strategic communication game for LLM-to-LLM interaction that models information credibility. In MixTalk, a sender agent strategically combines verifiable and unverifiable claims to communicate private information, while a receiver agent allocates a limited budget to costly verification and infers the underlying state from prior beliefs, claims, and verification outcomes. We evaluate state-of-the-art LLM agents in large-scale tournaments across three realistic deployment settings, revealing their strengths and limitations in reasoning about information credibility and the explicit behavior that shapes these interactions. Finally, we propose Tournament Oracle Policy Distillation (TOPD), an offline method that distills tournament oracle policy from interaction logs and deploys it in-context at inference time. Our results show that TOPD significantly improves receiver robustness to persuasion.

</details>


### [483] [MedSpeak: A Knowledge Graph-Aided ASR Error Correction Framework for Spoken Medical QA](https://arxiv.org/abs/2602.00981)
*Yutong Song,Shiva Shrestha,Chenhan Lyu,Elahe Khatibi,Pengfei Zhang,Honghui Xu,Nikil Dutt,Amir Rahmani*

Main category: cs.CL

TL;DR: 提出了一种名为MedSpeak的知识图谱辅助ASR错误纠正框架，通过结合医学知识图谱的语义和语音信息以及LLM的推理能力，来纠正ASR生成的医疗术语错误，从而提高医疗口语问答系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的口语问答（SQA）系统在识别医疗术语方面存在准确性不足的问题，这会影响下游的答案预测。

Method: 提出MedSpeak框架，利用医学知识图谱（包含语义和语音信息）和大型语言模型（LLMs）的推理能力，来纠正自动语音识别（ASR）产生的错误字幕，并改进问答性能。

Result: 在基准测试中的实验结果表明，MedSpeak显著提高了医疗术语识别的准确性和整体医疗SQA的性能。

Conclusion: MedSpeak是解决医疗SQA问题的先进解决方案，能够有效提高医疗术语识别和整体问答的准确性。

Abstract: Spoken question-answering (SQA) systems relying on automatic speech recognition (ASR) often struggle with accurately recognizing medical terminology. To this end, we propose MedSpeak, a novel knowledge graph-aided ASR error correction framework that refines noisy transcripts and improves downstream answer prediction by leveraging both semantic relationships and phonetic information encoded in a medical knowledge graph, together with the reasoning power of LLMs. Comprehensive experimental results on benchmarks demonstrate that MedSpeak significantly improves the accuracy of medical term recognition and overall medical SQA performance, establishing MedSpeak as a state-of-the-art solution for medical SQA. The code is available at https://github.com/RainieLLM/MedSpeak.

</details>


### [484] [Trust in One Round: Confidence Estimation for Large Language Models via Structural Signals](https://arxiv.org/abs/2602.00977)
*Pengyue Yang,Jiawen Wen,Haolin Jin,Linghan Huang,Huaming Chen,Ling Chen*

Main category: cs.CL

TL;DR: 本研究提出了一种名为“结构化置信度”的框架，通过分析大语言模型（LLM）内部表示的结构特征来预测输出的正确性。该方法单次前向传播即可完成，适用于计算资源有限的场景，并在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM置信度估计方法在面对分布外数据、领域专业文本和计算限制时表现脆弱，而LLM在关键领域的错误成本高昂，因此需要更鲁棒、高效的置信度评估方法。

Method: 该方法利用模型最终层隐藏状态轨迹的多尺度结构信号，结合谱分析、局部变化和全局形状描述符，捕捉内部稳定性模式。它是一种单次前向传播、模型无关的框架。

Result: 在FEVER、SciFact、WikiBio-hallucination和TruthfulQA四个跨领域基准测试中，结构化置信度框架在AUROC和AUPR指标上均展现出优于现有基线方法的强劲性能。

Conclusion: 结构化置信度框架提供了一种高效、鲁棒的后验置信度估计方法，能够有效提升LLM在对社会影响大的、资源受限的应用中的可靠性，且无需多重采样或辅助模型。

Abstract: Large language models (LLMs) are increasingly deployed in domains where errors carry high social, scientific, or safety costs. Yet standard confidence estimators, such as token likelihood, semantic similarity and multi-sample consistency, remain brittle under distribution shift, domain-specialised text, and compute limits. In this work, we present Structural Confidence, a single-pass, model-agnostic framework that enhances output correctness prediction based on multi-scale structural signals derived from a model's final-layer hidden-state trajectory. By combining spectral, local-variation, and global shape descriptors, our method captures internal stability patterns that are missed by probabilities and sentence embeddings. We conduct extensive, cross-domain evaluation across four heterogeneous benchmarks-FEVER (fact verification), SciFact (scientific claims), WikiBio-hallucination (biographical consistency), and TruthfulQA (truthfulness-oriented QA). Our Structural Confidence framework demonstrates strong performance compared with established baselines in terms of AUROC and AUPR. More importantly, unlike sampling-based consistency methods which require multiple stochastic generations and an auxiliary model, our approach uses a single deterministic forward pass, offering a practical basis for efficient, robust post-hoc confidence estimation in socially impactful, resource-constrained LLM applications.

</details>


### [485] [DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning](https://arxiv.org/abs/2602.00983)
*Batuhan K. Karaman,Aditya Rawal,Suhaila Shakiah,Mohammad Ghavamzadeh,Mingyi Hong,Arijit Biswas,Ruida Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种名为 DISPO 的新型强化学习算法，用于提升大型语言模型在数学推理方面的表现。DISPO 通过解耦对正确和错误回答的采样权重裁剪，实现了四种可控的策略更新模式，从而在保持探索-蒸馏平衡的同时，避免了性能崩溃，并在 AIME'24 基准测试中取得了显著优于现有方法的成绩。


<details>
  <summary>Details</summary>
Motivation: 现有基于可验证奖励的强化学习方法在训练稳定性和学习效率之间存在权衡：PPO 类方法稳定但学习慢，REINFORCE 类方法高效但不稳定。研究旨在解决这一局限性，提出一种既高效又稳定的方法。

Method: 提出 DISPO 算法，一种 REINFORCE 风格的算法。它通过解耦正确回答（权重 >1）和错误回答（权重 <1）的采样权重裁剪，创造了四种策略更新模式。通过消融实验研究了不同模式对训练的影响，并据此调整裁剪参数。

Result: DISPO 在 AIME'24 基准测试上取得了 61.04% 的准确率，优于 CISPO (55.42%) 和 DAPO (50.21%)。该方法在不同模型和基准测试上均有类似提升。研究发现，对于正确回答，权重大于1会增加探索，小于1会进行蒸馏，两者适度有益；对于错误回答，过度裁剪可能导致重复输出或响应长度消失。

Conclusion: DISPO 算法通过精细控制采样权重裁剪，成功平衡了探索与蒸馏，并有效避免了因不当裁剪导致的性能崩溃，是一种更优的强化学习方法，适用于提升大型语言模型在数学推理等任务中的表现。

Abstract: Reinforcement learning with verifiable rewards has emerged as a promising paradigm for enhancing the reasoning capabilities of large language models particularly in mathematics. Current approaches in this domain present a clear trade-off: PPO-style methods (e.g., GRPO/DAPO) offer training stability but exhibit slow learning trajectories due to their trust-region constraints on policy updates, while REINFORCE-style approaches (e.g., CISPO) demonstrate improved learning efficiency but suffer from performance instability as they clip importance sampling weights while still permitting non-zero gradients outside the trust-region. To address these limitations, we introduce DISPO, a simple yet effective REINFORCE-style algorithm that decouples the up-clipping and down-clipping of importance sampling weights for correct and incorrect responses, yielding four controllable policy update regimes. Through targeted ablations, we uncover how each regime impacts training: for correct responses, weights >1 increase the average token entropy (i.e., exploration) while weights <1 decrease it (i.e., distillation) -- both beneficial but causing gradual performance degradation when excessive. For incorrect responses, overly restrictive clipping triggers sudden performance collapse through repetitive outputs (when weights >1) or vanishing response lengths (when weights <1). By separately tuning these four clipping parameters, DISPO maintains the exploration-distillation balance while preventing catastrophic failures, achieving 61.04% on AIME'24 (vs. 55.42% CISPO and 50.21% DAPO) with similar gains across various benchmarks and models.

</details>


### [486] [Sparse Reward Subsystem in Large Language Models](https://arxiv.org/abs/2602.00986)
*Guowei Xu,Mert Yuksekgonul,James Zou*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）的隐藏状态中存在一个稀疏奖励子系统，其中包含代表模型内部状态价值期望的价值神经元，以及编码奖励预测误差（RPE）的多巴胺神经元。


<details>
  <summary>Details</summary>
Motivation: 受到生物学中奖励子系统和价值神经元的启发，作者旨在探索大型语言模型（LLMs）的隐藏状态中是否存在类似的机制，并理解其在推理中的作用。

Method: 通过识别LLMs隐藏状态中的稀疏奖励子系统，并对其内部的价值神经元和多巴胺神经元进行干预实验。实验覆盖了不同的数据集、模型规模和架构，并进行了跨数据集和模型的迁移性分析。

Result: 发现了代表模型内部状态价值期望的价值神经元，这些神经元对模型的推理至关重要，并且在不同数据集、模型规模和架构下表现出鲁棒性，还表现出跨数据集和模型的迁移性。同时，发现了编码奖励预测误差（RPE）的多巴胺神经元，它们在奖励高于预期时激活较高，在奖励低于预期时激活较低。

Conclusion: 大型语言模型（LLMs）的隐藏状态中存在一个与生物学奖励子系统相似的稀疏奖励子系统，其中包含对推理至关重要的价值神经元和编码奖励预测误差（RPE）的多巴胺神经元。这些神经元具有鲁棒性和迁移性，为理解LLMs的内部工作机制提供了新的视角。

Abstract: In this paper, we identify a sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain. We demonstrate that this subsystem contains value neurons that represent the model's internal expectation of state value, and through intervention experiments, we establish the importance of these neurons for reasoning. Our experiments reveal that these value neurons are robust across diverse datasets, model scales, and architectures; furthermore, they exhibit significant transferability across different datasets and models fine-tuned from the same base model. By examining cases where value predictions and actual rewards diverge, we identify dopamine neurons within the reward subsystem which encode reward prediction errors (RPE). These neurons exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected.

</details>


### [487] [DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework](https://arxiv.org/abs/2602.00996)
*Abhijit Chakraborty,Ashish Raj Shekhar,Shiven Agarwal,Vivek Gupta*

Main category: cs.CL

TL;DR: 提出了一种名为 DeALOG 的去中心化多智能体框架，用于处理文本、表格和图像的多模态复杂问答，通过自然语言日志进行通信和协作，并在多个数据集上取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的复杂问答方法在整合文本、表格和图像等多种信息来源时存在不足，需要一个支持专业化处理、协调和可解释性的框架。

Method: DeALOG 框架使用表格、上下文、视觉、总结和验证等专业化智能体，通过共享的自然语言日志进行通信，该日志充当持久内存，从而实现协作式错误检测和验证，无需中央控制。

Result: 在 FinQA、TAT-QA、CRT-QA、WikiTableQuestions、FeTaQA 和 MultiModalQA 数据集上进行了评估，DeALOG 取得了具有竞争力的性能，并且分析证实了共享日志、智能体专业化和验证对提高准确性的重要性。

Conclusion: DeALOG 提供了一种可扩展的方法，通过模块化组件和自然语言通信，有效解决了多模态复杂问答问题，提高了鲁棒性。

Abstract: Complex question answering across text, tables and images requires integrating diverse information sources. A framework supporting specialized processing with coordination and interpretability is needed. We introduce DeALOG, a decentralized multi-agent framework for multimodal question answering. It uses specialized agents: Table, Context, Visual, Summarizing and Verification, that communicate through a shared natural-language log as persistent memory. This log-based approach enables collaborative error detection and verification without central control, improving robustness. Evaluations on FinQA, TAT-QA, CRT-QA, WikiTableQuestions, FeTaQA, and MultiModalQA show competitive performance. Analysis confirms the importance of the shared log, agent specialization, and verification for accuracy. DeALOG, provides a scalable approach through modular components using natural-language communication.

</details>


### [488] [Distilling Token-Trained Models into Byte-Level Models](https://arxiv.org/abs/2602.01007)
*Zishuo Bao,Jiaqi Leng,Junxiong Wang,Bowen Peng,Yucheng Lu*

Main category: cs.CL

TL;DR: 提出了一种高效的蒸馏方法，将现有基于Token的模型转换为字节语言模型（BLM），仅需约125B字节数据即可保持与原始模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的字节语言模型（BLM）需要从头开始训练海量数据，成本高昂。本研究旨在开发一种方法，使其能够利用已有的Token模型进行高效转换。

Method: 采用两阶段课程学习：1. 渐进式知识蒸馏，对齐字节级表示和Token教师模型的嵌入；2. 字节级有监督微调，实现完全在字节空间中的端到端生成。

Result: 在Llama、Qwen和OLMo等模型家族上验证了该方法，蒸馏出的BLM在仅使用约125B字节数据的情况下，保留了教师模型大部分的性能。

Conclusion: 所提出的蒸馏方法能够高效地将Token模型转换为BLM，在显著降低训练数据量的同时，保持了模型的性能，为BLM的规模化提供了一种可行的途径。

Abstract: Byte Language Models (BLMs) have emerged as a promising direction for scaling language models beyond tokenization. However, existing BLMs typically require training from scratch on trillions of bytes, making them prohibitively expensive. In this paper, we propose an efficient distillation recipe that converts existing token-trained LLMs into BLMs while retaining comparable capabilities. Our recipe follows a two-stage curriculum: (1) Progressive Knowledge Distillation, which aligns byte-level representations with the embeddings of the token-trained teacher model; and (2) Byte-Level Supervised Fine-Tuning, which enables end-to-end generation entirely in the byte space. We validate our approach across multiple model families, including Llama, Qwen, and OLMo, and demonstrate that the distilled BLMs retain most of the teacher models' performance using only approximately 125B bytes.

</details>


### [489] [Reliable Use of Lemmas via Eligibility Reasoning and Section$-$Aware Reinforcement Learning](https://arxiv.org/abs/2602.00998)
*Zhikun Xu,Xiaodong Yu,Ben Zhou,Jiang Liu,Jialian Wu,Ze Wang,Ximeng Sun,Hao Chen,Zicheng Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为RULES的新方法，用于提高大型语言模型（LLMs）在数学推理中的准确性，通过将引理判断形式化为结构化预测任务，并结合强化学习和特定部分的损失掩码进行训练，从而有效解决了LLMs误用引理的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学推理任务中表现出色，但常常会错误地应用引理，即在不满足前提条件的情况下使用了引理的结论。这促使研究者需要一种方法来更准确地判断引理的适用性。

Method: 本文将引理判断形式化为一个结构化预测任务。对于给定的一个陈述和一个候选引理，模型需要输出一个前提条件检查和一个结论效用检查。基于这两项检查，最终可以派生出引理是否“有用”的决策。所提出的RULES模型通过一个两部分的输出结构来实现这一目标，并采用强化学习进行训练，同时结合了部分感知的损失掩码（section-aware loss masking），以便对导致错误的特定部分进行惩罚。

Result: 在训练和评估中，研究者使用了多种自然语言和形式化证明语料库。实验结果表明，RULES在同领域任务上一致优于普通的模型和单一标签的强化学习基线模型。在故意破坏适用性的扰动测试中，RULES的表现提升尤为显著。在端到端评估任务（包括竞赛风格、扰动对齐和基于定理的问题）中，RULES也表现出相当或略有提升的性能。消融研究表明，两部分输出结构和部分感知的强化学习对于提高鲁棒性都是必需的。

Conclusion: RULES模型通过将引理判断视为一个结构化预测任务，并采用特殊的训练策略，能够有效提升大型语言模型在数学推理中正确应用引理的能力，尤其在面对具有挑战性的扰动时表现出更强的鲁棒性。

Abstract: Recent large language models (LLMs) perform strongly on mathematical benchmarks yet often misapply lemmas, importing conclusions without validating assumptions. We formalize lemma$-$judging as a structured prediction task: given a statement and a candidate lemma, the model must output a precondition check and a conclusion$-$utility check, from which a usefulness decision is derived. We present RULES, which encodes this specification via a two$-$section output and trains with reinforcement learning plus section$-$aware loss masking to assign penalty to the section responsible for errors. Training and evaluation draw on diverse natural language and formal proof corpora; robustness is assessed with a held$-$out perturbation suite; and end$-$to$-$end evaluation spans competition$-$style, perturbation$-$aligned, and theorem$-$based problems across various LLMs. Results show consistent in$-$domain gains over both a vanilla model and a single$-$label RL baseline, larger improvements on applicability$-$breaking perturbations, and parity or modest gains on end$-$to$-$end tasks; ablations indicate that the two$-$section outputs and section$-$aware reinforcement are both necessary for robustness.

</details>


### [490] [Large Language Models as Students Who Think Aloud: Overly Coherent, Verbose, and Confident](https://arxiv.org/abs/2602.01015)
*Conrad Borchers,Jill-Jênn Vie,Roger Azevedo*

Main category: cs.CL

TL;DR: 研究评估了大型语言模型（LLMs）作为AI助教中新手学习者的推理和元认知判断能力。发现LLMs的推理过于连贯、冗长且缺乏变异性，无法真实模拟人类学习过程，且倾向于高估学习者表现。这揭示了LLMs在模拟学习方面的认识论局限性，并提出了未来设计能够更真实地支持新手学习和自我调节的AI助教的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有AI助教评估主要关注解决问题的准确性，忽视了人类学习过程中不连贯和不完美的推理过程。因此，需要评估LLMs能否忠实地模拟新手学习者的推理和元认知判断。

Method: 研究者使用了630个多步化学辅导问题的“出声思考”（think-aloud）话语，结合学生提示使用、尝试和问题背景的解决日志。通过在最小和扩展上下文提示下，将LLM生成的推理与人类学习者的话语进行比较，并评估模型预测学习者步骤级别成功的能力。

Result: GPT-4.1生成的推理虽然流畅且上下文适宜，但系统性地表现出过度连贯、冗长和变异性低的特点，与人类“出声思考”话语存在差异。这些影响会随着提示中更丰富的解决问题上下文而加剧。此外，LLMs持续高估了学习者的表现。

Conclusion: 研究发现LLMs在模拟人类新手学习者的推理和元认知判断方面存在固有的认识论局限性，主要归因于其训练数据（包含缺乏情感表达和工作记忆限制的专家级解决方案）以及解决问题过程中的内在限制。提出的评估框架有助于未来设计能够更真实地支持新手学习和自我调节的AI助教。

Abstract: Large language models (LLMs) are increasingly embedded in AI-based tutoring systems. Can they faithfully model novice reasoning and metacognitive judgments? Existing evaluations emphasize problem-solving accuracy, overlooking the fragmented and imperfect reasoning that characterizes human learning. We evaluate LLMs as novices using 630 think-aloud utterances from multi-step chemistry tutoring problems with problem-solving logs of student hint use, attempts, and problem context. We compare LLM-generated reasoning to human learner utterances under minimal and extended contextual prompting, and assess the models' ability to predict step-level learner success. Although GPT-4.1 generates fluent and contextually appropriate continuations, its reasoning is systematically over-coherent, verbose, and less variable than human think-alouds. These effects intensify with a richer problem-solving context during prompting. Learner performance was consistently overestimated. These findings highlight epistemic limitations of simulating learning with LLMs. We attribute these limitations to LLM training data, including expert-like solutions devoid of expressions of affect and working memory constraints during problem solving. Our evaluation framework can guide future design of adaptive systems that more faithfully support novice learning and self-regulation using generative artificial intelligence.

</details>


### [491] [Bias in the Ear of the Listener: Assessing Sensitivity in Audio Language Models Across Linguistic, Demographic, and Positional Variations](https://arxiv.org/abs/2602.01030)
*Sheng-Lun Wei,Yu-Ling Liao,Yen-Hua Chang,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 本研究首次系统性地调查了多语言多模态大型语言模型（MLLMs）中的语音偏见，并发布了BiasInEar数据集，该数据集基于Global MMLU Lite，包含英语、中文、韩语，并考虑了性别和口音平衡。通过四种指标评估了九个模型在语言、性别和选项顺序扰动下的表现，发现MLLMs对人口统计因素相对稳健，但对语言和选项顺序非常敏感。


<details>
  <summary>Details</summary>
Motivation: 现有对MLLMs偏见的研究主要集中在文本，忽略了语音输入可能引入的偏见。作者希望填补这一空白，系统研究多语言MLLMs在语音输入下的偏见问题。

Method: 构建并发布了BiasInEar数据集，这是一个基于Global MMLU Lite的多语言（英语、中文、韩语）语音增强基准，包含70.8小时语音和11,200个问题，并按性别和口音进行了平衡。使用准确率、熵、APES和Fleiss' κ四种互补指标，评估了九个代表性模型在语言、口音、性别和选项顺序等扰动下的表现。

Result: MLLMs在人口统计因素（如性别）方面表现相对稳健，但在语言和选项顺序方面非常敏感，表明语音可能会加剧现有的结构性偏见。模型的架构设计和推理策略对跨语言的稳健性有显著影响。

Conclusion: 本研究建立了一个评估语音集成LLMs公平性和稳健性的统一框架，弥合了文本和语音评估之间的差距。研究结果强调了在多语言MLLMs中解决语音偏见和结构性偏见的重要性。

Abstract: This work presents the first systematic investigation of speech bias in multilingual MLLMs. We construct and release the BiasInEar dataset, a speech-augmented benchmark based on Global MMLU Lite, spanning English, Chinese, and Korean, balanced by gender and accent, and totaling 70.8 hours ($\approx$4,249 minutes) of speech with 11,200 questions. Using four complementary metrics (accuracy, entropy, APES, and Fleiss' $κ$), we evaluate nine representative models under linguistic (language and accent), demographic (gender), and structural (option order) perturbations. Our findings reveal that MLLMs are relatively robust to demographic factors but highly sensitive to language and option order, suggesting that speech can amplify existing structural biases. Moreover, architectural design and reasoning strategy substantially affect robustness across languages. Overall, this study establishes a unified framework for assessing fairness and robustness in speech-integrated LLMs, bridging the gap between text- and speech-based evaluation. The resources can be found at https://github.com/ntunlplab/BiasInEar.

</details>


### [492] [Personality Expression Across Contexts: Linguistic and Behavioral Variation in LLM Agents](https://arxiv.org/abs/2602.01063)
*Bin Han,Deuksin Kwon,Jonathan Gratch*

Main category: cs.CL

TL;DR: 本文研究了在不同对话场景下，相同的个性化提示词如何影响大型语言模型（LLMs）的行为表现。研究发现，上下文线索会系统性地影响LLMs的语言、行为和情感表达，表明LLMs的个性表达是情境敏感的，而非固定的，类似于人类行为的适应性。


<details>
  <summary>Details</summary>
Motivation: 研究者希望了解大型语言模型（LLMs）在接收到明确的个性化提示后，其行为表现是否会因对话场景的不同而产生差异，以及这种差异是否能被解释为一种情境适应。

Method: 通过在四个不同的对话场景（破冰、谈判、小组决策和共情任务）中，对相同的个性化提示词进行评估，比较LLMs在语言、行为和情感输出上的差异。

Result: 研究结果表明，相同的个性化提示词在不同对话场景下产生了不同的语言、行为和情感输出。上下文线索系统性地影响了LLMs的个性和情感表达，使其表现出对不同社交和情感需求的适应性。

Conclusion: LLMs的个性表达具有情境敏感性，能够根据社交互动目标和情感条件灵活调整，这种适应性类似于人类行为，而非固定不变的个性特征。这为开发更具适应性的人工智能对话代理提供了思路。

Abstract: Large Language Models (LLMs) can be conditioned with explicit personality prompts, yet their behavioral realization often varies depending on context. This study examines how identical personality prompts lead to distinct linguistic, behavioral, and emotional outcomes across four conversational settings: ice-breaking, negotiation, group decision, and empathy tasks. Results show that contextual cues systematically influence both personality expression and emotional tone, suggesting that the same traits are expressed differently depending on social and affective demands. This raises an important question for LLM-based dialogue agents: whether such variations reflect inconsistency or context-sensitive adaptation akin to human behavior. Viewed through the lens of Whole Trait Theory, these findings highlight that LLMs exhibit context-sensitive rather than fixed personality expression, adapting flexibly to social interaction goals and affective conditions.

</details>


### [493] [Exploring Knowledge Purification in Multi-Teacher Knowledge Distillation for LLMs](https://arxiv.org/abs/2602.01064)
*Ruihan Jin,Pengpeng Shao,Zhengqi Wen,Jinyang Wu,Mingkuan Feng,Shuo Yang,Chu Yuan Zhang,Jianhua Tao*

Main category: cs.CL

TL;DR: 本研究提出了一种名为“知识净化”的技术，用于整合多个教师大语言模型的知识，以解决传统知识蒸馏中知识冲突和资源消耗高的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的知识蒸馏方法在利用多个教师模型时，存在知识冲突和资源需求高的问题。本研究旨在通过知识净化来克服这些挑战。

Method: 提出“知识净化”概念，将多个教师模型的知识整合成单一的理性，并设计了五种不同的净化方法来处理这种知识整合。实验评估了这些方法的有效性。

Result: 实验表明，提出的知识净化方法能够提升蒸馏模型的性能，并有效减轻知识冲突。基于路由器的净化方法表现出强大的泛化能力。

Conclusion: 知识净化是一种有效的技术，可以优化多教师知识蒸馏，减轻知识冲突，并提高蒸馏模型的性能和泛化能力，从而促进轻量级模型的实际部署。

Abstract: Knowledge distillation has emerged as a pivotal technique for transferring knowledge from stronger large language models (LLMs) to smaller, more efficient models. However, traditional distillation approaches face challenges related to knowledge conflicts and high resource demands, particularly when leveraging multiple teacher models. In this paper, we introduce the concept of \textbf{Knowledge Purification}, which consolidates the rationales from multiple teacher LLMs into a single rationale, thereby mitigating conflicts and enhancing efficiency. To investigate the effectiveness of knowledge purification, we further propose five purification methods from various perspectives. Our experiments demonstrate that these methods not only improve the performance of the distilled model but also effectively alleviate knowledge conflicts. Moreover, router-based methods exhibit robust generalization capabilities, underscoring the potential of innovative purification techniques in optimizing multi-teacher distillation and facilitating the practical deployment of powerful yet lightweight models.

</details>


### [494] [From Utterance to Vividity: Training Expressive Subtitle Translation LLM via Adaptive Local Preference Optimization](https://arxiv.org/abs/2602.01068)
*Chaoqun Cui,Shijing Wang,Liangbin Huang,Qingqing Gu,Zhaolong Huang,Xiao Zeng,Wenji Mao*

Main category: cs.CL

TL;DR: 本研究提出了一种名为ALPO的方法，用于训练能够进行富有表现力和生动性的领域定制机器翻译的大型语言模型（LLMs），特别关注视觉媒体字幕翻译。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在通用机器翻译方面表现出色，但在处理特定领域（如视觉媒体字幕翻译）时存在局限性，需要进行领域定制以满足更复杂的应用场景。

Method: 1. 探索LLM作为翻译的奖励模型和评估者的可靠性。 2. 构建并发布了一个多方向字幕平行语料库数据集。 3. 提出了一种自适应局部偏好优化（ALPO）方法，以实现细粒度的偏好对齐，从而训练富有表现力的翻译LLMs。

Result: 实验结果表明，ALPO在翻译质量的多维度评估中取得了优异的性能。

Conclusion: ALPO方法能够有效地训练出满足领域定制需求的、富有表现力和生动性的翻译LLMs，特别是在视觉媒体字幕翻译任务上表现出色。

Abstract: The rapid development of Large Language Models (LLMs) has significantly enhanced the general capabilities of machine translation. However, as application scenarios become more complex, the limitations of LLMs in vertical domain translations are gradually becoming apparent. In this study, we focus on how to construct translation LLMs that meet the needs of domain customization. We take visual media subtitle translation as our topic and explore how to train expressive and vivid translation LLMs. We investigated the situations of subtitle translation and other domains of literal and liberal translation, verifying the reliability of LLM as reward model and evaluator for translation. Additionally, to train an expressive translation LLM, we constructed and released a multidirectional subtitle parallel corpus dataset and proposed the Adaptive Local Preference Optimization (ALPO) method to address fine-grained preference alignment. Experimental results demonstrate that ALPO achieves outstanding performance in multidimensional evaluation of translation quality.

</details>


### [495] [What If We Allocate Test-Time Compute Adaptively?](https://arxiv.org/abs/2602.01070)
*Ahsan Bilal,Ahmed Mohsin,Muhammad Umer,Ali Subhan,Hassan Rizwan,Ayesha Mohsin,Dean Hougen*

Main category: cs.CL

TL;DR: 提出了一种验证器引导的自适应框架，将推理视为迭代轨迹生成和选择，通过过程奖励模型（PRM）在迭代中进行引导和剪枝，以提高模型在数学推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时间计算扩展方法存在计算分配不均、采样策略固定以及验证仅用于重排序等问题，需要一种更动态、更有效的推理方法。

Method: 设计了一个验证器引导的自适应框架，将推理视为迭代轨迹生成，每轮迭代包含规划、工具选择、计算策略和探索参数设定，然后生成候选推理轨迹。使用过程奖励模型（PRM）作为统一的控制信号，指导生成过程中的剪枝和扩展，并选择最终响应。

Result: 该方法在MATH-500数据集上表现出持续的性能提升，并在AIME24和AMO-Bench等更难的基准测试上实现了数倍的改进。计算效率分析表明，该方法将计算集中在高价值的推理路径上。

Conclusion: 与直接的测试时间计算扩展相比，该动态的、PRM引导的方法能够更有效地分配计算资源，并在数学推理任务中取得显著的性能提升。

Abstract: Test-time compute scaling allocates inference computation uniformly, uses fixed sampling strategies, and applies verification only for reranking. In contrast, we propose a verifier-guided adaptive framework treating reasoning as iterative trajectory generation and selection. For each problem, the agent runs multiple inference iterations. In each iteration, it optionally produces a high-level plan, selects a set of reasoning tools and a compute strategy together with an exploration parameter, and then generates a candidate reasoning trajectory. A process reward model (PRM) serves as a unified control signal: within each iteration, step-level PRM scores are aggregated to guide pruning and expansion during generation, and across iterations, aggregated trajectory rewards are used to select the final response. Across datasets, our dynamic, PRM-guided approach consistently outperforms direct test-time scaling, yielding large gains on MATH-500 and several-fold improvements on harder benchmarks such as AIME24 and AMO-Bench. We characterize efficiency using theoretical FLOPs and a compute intensity metric penalizing wasted generation and tool overhead, demonstrating that verification-guided allocation concentrates computation on high-utility reasoning paths.

</details>


### [496] [Logic-Oriented Retriever Enhancement via Contrastive Learning](https://arxiv.org/abs/2602.01116)
*Wenxuan Zhang,Yuan-Hao Jiang,Changyong Qi,Rui Jia,Yonghe Wu*

Main category: cs.CL

TL;DR: LORE 通过细粒度对比学习改进了大型语言模型的知识密集型任务检索能力，它利用了模型内在的逻辑分析能力，而非依赖表面相似性，从而提高了检索效率和下游生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有的检索器在处理涉及复杂逻辑关系的有知识的查询时表现不佳，通常会过度拟合表面相似性。大型语言模型在知识密集型任务中存在不足，而其内在的逻辑分析能力未被充分利用。

Method: LORE（Logic ORiented Retriever Enhancement）采用细粒度对比学习方法，引导词嵌入向与逻辑结构对齐的证据靠拢，而非仅仅关注表面相似性。此方法无需外部监督、资源或预检索分析，并兼容现有索引。

Result: LORE 能够激活模型潜在的逻辑分析能力，一致地提高了检索效用和下游生成能力，同时保持了检索效率。

Conclusion: LORE 是一种有效的、无需额外资源的检索增强方法，通过激活模型的内在逻辑推理能力，显著提升了大型语言模型在知识密集型任务中的表现。

Abstract: Large language models (LLMs) struggle in knowledge-intensive tasks, as retrievers often overfit to surface similarity and fail on queries involving complex logical relations. The capacity for logical analysis is inherent in model representations but remains underutilized in standard training. LORE (Logic ORiented Retriever Enhancement) introduces fine-grained contrastive learning to activate this latent capacity, guiding embeddings toward evidence aligned with logical structure rather than shallow similarity. LORE requires no external upervision, resources, or pre-retrieval analysis, remains index-compatible, and consistently improves retrieval utility and downstream generation while maintaining efficiency. The datasets and code are publicly available at https://github.com/mazehart/Lore-RAG.

</details>


### [497] [Tendem: A Hybrid AI+Human Platform](https://arxiv.org/abs/2602.01119)
*Konstantin Chernyshev,Ekaterina Artemova,Viacheslav Zhukov,Maksim Nerush,Mariia Fedorova,Iryna Repik,Olga Shapovalova,Aleksey Sukhorosov,Vladimir Dobrovolskii,Natalia Mikhailova,Sergei Tilga*

Main category: cs.CL

TL;DR: Tendem 是一种结合了 AI 和人类专家的混合系统，在真实任务评估中，其产出质量更高、速度更快，且成本与纯人类工作相当。


<details>
  <summary>Details</summary>
Motivation: 评估 Tendem 混合系统的性能，并将其与纯 AI 和纯人类工作流程进行比较。

Method: 在 94 个真实任务上进行内部评估，并将 Tendem 与纯 AI 代理和 Upwork 自由职业者的人类工作流程进行对比。此外，还在第三方基准测试中评估了 Tendem 的 AI 代理。

Result: Tendem 在质量和速度上均优于纯 AI 和纯人类工作流程，且成本相当。其 AI 代理在网页浏览和工具使用方面接近最先进水平，并在领域知识和推理方面表现出色。

Conclusion: Tendem 混合系统在处理结构化、可重复性工作时，能够提供高质量、高效率且成本可控的解决方案，并能在 AI 失败或需要验证时引入人类专家。

Abstract: Tendem is a hybrid system where AI handles structured, repeatable work and Human Experts step in when the models fail or to verify results. Each result undergoes a comprehensive quality review before delivery to the Client. To assess Tendem's performance, we conducted a series of in-house evaluations on 94 real-world tasks, comparing it with AI-only agents and human-only workflows carried out by Upwork freelancers. The results show that Tendem consistently delivers higher-quality outputs with faster turnaround times. At the same time, its operational costs remain comparable to human-only execution. On third-party agentic benchmarks, Tendem's AI Agent (operating autonomously, without human involvement) performs near state-of-the-art on web browsing and tool-use tasks while demonstrating strong results in frontier domain knowledge and reasoning.

</details>


### [498] [Long-range Modeling and Processing of Multimodal Event Sequences](https://arxiv.org/abs/2602.01125)
*Jichu Li,Yilun Zhong,Zhiting Li,Feng Zhou,Quyu Kong*

Main category: cs.CL

TL;DR: 本文提出了一种新的框架，将基于LLM的时间点过程（TPP）扩展到视觉模态，使文本生成与时间和类型预测并列成为核心能力。该框架通过基于时间相似性的自适应序列压缩机制解决了长上下文问题，并通过预训练和微调两阶段范式提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于TPP处理文本信息的方法在生成丰富、多模态内容和理解事件动态方面存在局限性。将多模态数据引入TPP会显著增加序列长度，阻碍基于注意力机制的模型生成连贯的长文本描述。

Method: 提出了一种新的框架，将LLM-based TPP扩展到视觉模态。采用基于时间相似性的自适应序列压缩机制来缩短序列长度并保留关键模式。模型采用两阶段范式：先在压缩序列上进行预训练，然后对下游任务进行监督微调。

Result: 该方法在预测准确性和生成的文本分析质量方面均优于最先进的基线模型，尤其在DanmakuTPP-QA基准测试中表现突出。

Conclusion: 所提出的框架能够有效地将视觉信息集成到TPP模型中，并解决了处理长序列的挑战，从而实现了更准确的事件预测和更高质量的多模态文本生成。

Abstract: Temporal point processes (TPPs) have emerged as powerful tools for modeling asynchronous event sequences. While recent advances have extended TPPs to handle textual information, existing approaches are limited in their ability to generate rich, multimodal content and reason about event dynamics. A key challenge is that incorporating multimodal data dramatically increases sequence length, hindering the ability of attention-based models to generate coherent, long-form textual descriptions that require long-range understanding. In this paper, we propose a novel framework that extends LLM-based TPPs to the visual modality, positioning text generation as a core capability alongside time and type prediction. Our approach addresses the long-context problem through an adaptive sequence compression mechanism based on temporal similarity, which reduces sequence length while preserving essential patterns. We employ a two-stage paradigm of pre-training on compressed sequences followed by supervised fine-tuning for downstream tasks. Extensive experiments, including on the challenging DanmakuTPP-QA benchmark, demonstrate that our method outperforms state-of-the-art baselines in both predictive accuracy and the quality of its generated textual analyses.

</details>


### [499] [Don't Judge a Book by its Cover: Testing LLMs' Robustness Under Logical Obfuscation](https://arxiv.org/abs/2602.01132)
*Abhilekh Borah,Shubhra Ghosh,Kedar Joshi,Aditya Kumar Guru,Kripabandhu Ghosh*

Main category: cs.CL

TL;DR: 研究表明，大型语言模型（LLMs）在处理逻辑上等价但表述方式经过混淆的问题时表现不佳。研究者提出了Logifus框架和LogiQAte基准，并通过实验证明了这种混淆对现有LLMs（包括GPT-4o）的零样本性能有显著负面影响，平均性能下降47%。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在标准格式下能很好地解决算术、真值表和三段论等问题，但在面对逻辑等价但经过混淆的问题时却常常失败。这种脆弱性阻碍了LLMs在实际应用中的可靠性，因此需要深入研究和评估。

Method: 研究者提出了Logifus，一个结构保持的逻辑混淆框架。基于Logifus，他们构建了LogiQAte，一个包含1108个问题的诊断基准，涵盖四种推理任务：混淆的一阶逻辑蕴含、混淆的血缘关系推理、混淆的数字序列和混淆的方向感推理。通过在LogiQAte基准上评估六种最先进的模型，包括GPT-4o，来测试其在混淆问题上的表现。

Result: 混淆显著降低了现有大型语言模型的零样本性能。在所有任务中，GPT-4o的性能平均下降了47%，GPT-5下降了27%，o4-mini（一种推理模型）下降了22%。

Conclusion: 研究结果表明，当前的大型语言模型在解析问题时缺乏深层理解，它们过度依赖问题的表面形式。这凸显了开发能够真正理解并保持语义完整性（而不仅仅是表面形式）的模型的重要性，以及在实际应用中需要谨慎使用LLMs处理经过混淆的逻辑推理任务。

Abstract: Tasks such as solving arithmetic equations, evaluating truth tables, and completing syllogisms are handled well by large language models (LLMs) in their standard form, but they often fail when the same problems are posed in logically equivalent yet obfuscated formats. To study this vulnerability, we introduce Logifus, a structure-preserving logical obfuscation framework, and, utilizing this, we present LogiQAte, a first-of-its-kind diagnostic benchmark with 1,108 questions across four reasoning tasks: (i) Obfus FOL (first-order logic entailment under equivalence-preserving rewrites), (ii) Obfus Blood Relation (family-graph entailment under indirect relational chains), (iii) Obfus Number Series (pattern induction under symbolic substitutions), and (iv) Obfus Direction Sense (navigation reasoning under altered directions and reference frames). Across all the tasks, evaluating six state-of-the-art models, we find that obfuscation severely degrades zero-shot performance, with performance dropping on average by 47% for GPT-4o, 27% for GPT-5, and 22% for reasoning model, o4-mini. Our findings reveal that current LLMs parse questions without deep understanding, highlighting the urgency of building models that genuinely comprehend and preserve meaning beyond surface form.

</details>


### [500] [Typologically-Informed Candidate Reranking for LLM-based Translation into Low-Resource Languages](https://arxiv.org/abs/2602.01162)
*Nipuna Abeykoon,Ashen Weerathunga,Pubudu Wijesinghe,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 提出了一种利用语言类型学改进翻译质量的框架，无需平行训练数据或模型再训练，能够处理低资源语言的翻译问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理与高资源语言类型学差异较大的低资源语言时，存在系统性偏差，导致翻译质量不高。

Method: 提出一个包含“通用元语言框架”（UMF）和“计算引擎”的框架。UMF将语言表示为16个类型学维度的结构化剖面，并进行差异加权评分。计算引擎在生成时进行语言歧义消除，在选择时进行类型学合规性评分。

Result: 该框架在9种语言对上的评估表明，干预率与英语的类型学距离强相关。在处理341个英语句子时，该框架在保守处理语言、形态密集的语言和结构化剖面的语言上，干预精度分别为48.16%、28.15%和86.26%。

Conclusion: 该框架无需平行训练数据，且适用于任何能产生多个候选输出的大型语言模型，可实际应用于资源匮乏的语言翻译。

Abstract: Large language models trained predominantly on high-resource languages exhibit systematic biases toward dominant typological patterns, leading to structural non-conformance when translating into typologically divergent low-resource languages. We present a framework that leverages linguistic typology to improve translation quality without parallel training data or model retraining. The framework consists of two components: the Universal Metalinguistic Framework (UMF), which represents languages as structured profiles across 16 typological dimensions with divergence-weighted scoring, and the Computational Engine, which operates through linguistic disambiguation during generation and typological compliance scoring during selection. Evaluation across nine language pairs demonstrates intervention rates strongly correlating with typological distance from English. In experiments on 341 English sentences each having different morphological and syntactic phenomena, the framework shows an intervention precision of 48.16% for conservatively treated languages, 28.15% for morphologically dense languages, and 86.26% for structurally profiled languages. The framework requires no parallel training data and operates with any LLM capable of producing multiple candidate outputs, enabling practical deployment for under-resourced languages.

</details>


### [501] [PedagoSense: A Pedology Grounded LLM System for Pedagogical Strategy Detection and Contextual Response Generation in Learning Dialogues](https://arxiv.org/abs/2602.01169)
*Shahem Sultan,Shahem Fadi,Yousef Melhim,Ibrahim Alsarraj,Besher Hassan*

Main category: cs.CL

TL;DR: 本文提出 PedagoSense 系统，结合两阶段策略分类器和大型语言模型，用于检测和推荐教育对话中的教学策略，以提高学习交互质量。该系统首先二元分类识别教学策略是否存在，然后进行细粒度分类，同时利用 LLM 生成与推荐策略一致的回复。


<details>
  <summary>Details</summary>
Motivation: 提高基于对话的学习系统中师生互动的质量，通过检测和推荐有效的教学策略。

Method: 提出 PedagoSense 系统，包含一个两阶段策略分类器（二元分类检测策略，细粒度分类识别具体策略）和一个利用大型语言模型（LLM）生成回复的模块。LLM 用于根据对话上下文推荐并生成与推荐策略一致的回复。

Result: 在人工标注的师生对话数据集上评估 PedagoSense。结果显示，该系统在教学策略检测方面表现出高准确率，并且数据增强能带来持续的性能提升。细粒度分类任务仍具挑战性。

Conclusion: PedagoSense 将教学理论与 LLM 的回复生成相结合，为开发更具适应性的教育技术提供了一种有效方法，能够检测教学策略并生成相应的回复，从而改进师生互动质量。

Abstract: This paper addresses the challenge of improving interaction quality in dialogue based learning by detecting and recommending effective pedagogical strategies in tutor student conversations. We introduce PedagoSense, a pedology grounded system that combines a two stage strategy classifier with large language model generation. The system first detects whether a pedagogical strategy is present using a binary classifier, then performs fine grained classification to identify the specific strategy. In parallel, it recommends an appropriate strategy from the dialogue context and uses an LLM to generate a response aligned with that strategy. We evaluate on human annotated tutor student dialogues, augmented with additional non pedagogical conversations for the binary task. Results show high performance for pedagogical strategy detection and consistent gains when using data augmentation, while analysis highlights where fine grained classes remain challenging. Overall, PedagoSense bridges pedagogical theory and practical LLM based response generation for more adaptive educational technologies.

</details>


### [502] [EmoAra: Emotion-Preserving English Speech Transcription and Cross-Lingual Translation with Arabic Text-to-Speech](https://arxiv.org/abs/2602.01170)
*Besher Hassan,Ibrahim Alsarraj,Musaab Hasan,Yousef Melhim,Shahem Fadi,Shahem Sultan*

Main category: cs.CL

TL;DR: 本文提出了EmoAra，一个端到端的跨语言语音交流情绪保持管道，旨在银行客户服务场景中保持情绪细微差别。


<details>
  <summary>Details</summary>
Motivation: 银行客户服务中，情绪背景会影响服务质量，这促使了本研究。

Method: EmoAra集成了语音情绪识别（CNN模型）、自动语音识别（Whisper）、机器翻译（微调后的MarianMT模型）和文本到语音合成（MMS-TTS-Ara），以处理英语语音并生成保留情绪的阿拉伯语语音输出。

Result: 情绪分类F1得分为94%，翻译性能BLEU得分为56，BERTScore F1得分为88.7%。人类评估显示银行领域翻译的平均得分为81%。

Conclusion: EmoAra成功地实现了跨语言语音交流的情绪保持，并在银行领域翻译任务中取得了良好的性能，相关实现和资源已开源。

Abstract: This work presents EmoAra, an end-to-end emotion-preserving pipeline for cross-lingual spoken communication, motivated by banking customer service where emotional context affects service quality. EmoAra integrates Speech Emotion Recognition, Automatic Speech Recognition, Machine Translation, and Text-to-Speech to process English speech and deliver an Arabic spoken output while retaining emotional nuance. The system uses a CNN-based emotion classifier, Whisper for English transcription, a fine-tuned MarianMT model for English-to-Arabic translation, and MMS-TTS-Ara for Arabic speech synthesis. Experiments report an F1-score of 94% for emotion classification, translation performance of BLEU 56 and BERTScore F1 88.7%, and an average human evaluation score of 81% on banking-domain translations. The implementation and resources are available at the accompanying GitHub repository.

</details>


### [503] [Bridging Lexical Ambiguity and Vision: A Mini Review on Visual Word Sense Disambiguation](https://arxiv.org/abs/2602.01193)
*Shashini Nilukshi,Deshan Sumanathilaka*

Main category: cs.CL

TL;DR: 本文对视觉词义消歧（VWSD）进行了小型综述，这是一种视觉语言任务中处理词语歧义的多模态方法。文章回顾了从早期融合方法到基于CLIP、扩散模型和LLM的新型框架的发展，并指出了当前面临的挑战和未来的发展方向。


<details>
  <summary>Details</summary>
Motivation: 传统词义消歧仅依赖文本，无法有效处理视觉语言任务中的词语歧义。VWSD通过引入视觉线索，旨在解决这一局限性，提高词义消歧的准确性。

Method: 本文回顾了2016年至2025年间的VWSD研究，分析了特征提取、图模型和对比学习等技术。重点关注了提示工程、模型微调和多语言适应性，并评估了基于CLIP、扩散模型和LLM的方法。

Result: 基于CLIP微调的模型和LLM增强的VWSD系统在MRR指标上比零样本基线模型提升了6-8%。

Conclusion: VWSD领域取得了显著进展，但仍面临上下文限制、模型偏见、多语言数据稀缺和评估框架不足等挑战。未来的研究应侧重于CLIP对齐、扩散生成和LLM推理的结合，以构建更强大、更具上下文感知能力和多语言能力的消歧系统。

Abstract: This paper offers a mini review of Visual Word Sense Disambiguation (VWSD), which is a multimodal extension of traditional Word Sense Disambiguation (WSD). VWSD helps tackle lexical ambiguity in vision-language tasks. While conventional WSD depends only on text and lexical resources, VWSD uses visual cues to find the right meaning of ambiguous words with minimal text input. The review looks at developments from early multimodal fusion methods to new frameworks that use contrastive models like CLIP, diffusion-based text-to-image generation, and large language model (LLM) support. Studies from 2016 to 2025 are examined to show the growth of VWSD through feature-based, graph-based, and contrastive embedding techniques. It focuses on prompt engineering, fine-tuning, and adapting to multiple languages. Quantitative results show that CLIP-based fine-tuned models and LLM-enhanced VWSD systems consistently perform better than zero-shot baselines, achieving gains of up to 6-8\% in Mean Reciprocal Rank (MRR). However, challenges still exist, such as limitations in context, model bias toward common meanings, a lack of multilingual datasets, and the need for better evaluation frameworks. The analysis highlights the growing overlap of CLIP alignment, diffusion generation, and LLM reasoning as the future path for strong, context-aware, and multilingual disambiguation systems.

</details>


### [504] [Attention Sink Forges Native MoE in Attention Layers: Sink-Aware Training to Address Head Collapse](https://arxiv.org/abs/2602.01203)
*Zizhuo Fu,Wenxuan Zeng,Runsheng Wang,Meng Li*

Main category: cs.CL

TL;DR: 本文通过理论和实验证明，Vanilla Attention和Sink Attention中的“注意力沉没”现象实际上构建了一种混合专家（MoE）机制，这解释了注意力头塌陷问题。作者提出了一种新的训练算法，通过引入辅助负载均衡损失来缓解注意力头塌陷，并在Vanilla Attention、Sink Attention和Gated Attention上取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究在解决LLM的注意力沉没问题时，如Sink Attention和Gated Attention，但缺乏对其内在联系的全面分析。同时，先前工作中观察到的注意力头塌陷现象（即只有固定子集用于生成）尚未得到充分解释。

Method: 1. 理论和经验分析：证明Vanilla Attention和Sink Attention中的注意力沉没形成了MoE机制。
2. 提出 sink-aware 训练算法：设计了一个针对注意力层的辅助负载均衡损失。
3. 实验验证：在Vanilla Attention、Sink Attention和Gated Attention上进行广泛实验。

Result: 1. 证明了注意力沉没天然构建了MoE机制，解释了头塌陷。
2. 提出的 sink-aware 训练算法能够实现有效的头负载均衡。
3. 该方法在不同注意力机制下均能提升模型性能。

Conclusion: 注意力沉没机制可以被视为一种内在的MoE结构，这为理解和解决头塌陷问题提供了新的视角。提出的sink-aware训练算法是一种有效的缓解头塌陷并提升模型性能的方法，鼓励进一步探索注意力层内的MoE结构。

Abstract: Large Language Models (LLMs) often assign disproportionate attention to the first token, a phenomenon known as the attention sink. Several recent approaches aim to address this issue, including Sink Attention in GPT-OSS and Gated Attention in Qwen3-Next. However, a comprehensive analysis of the relationship among these attention mechanisms is lacking. In this work, we provide both theoretical and empirical evidence demonstrating that the sink in Vanilla Attention and Sink Attention naturally construct a Mixture-of-Experts (MoE) mechanism within attention layers. This insight explains the head collapse phenomenon observed in prior work, where only a fixed subset of attention heads contributes to generation. To mitigate head collapse, we propose a sink-aware training algorithm with an auxiliary load balancing loss designed for attention layers. Extensive experiments show that our method achieves effective head load balancing and improves model performance across Vanilla Attention, Sink Attention, and Gated Attention. We hope this study offers a new perspective on attention mechanisms and encourages further exploration of the inherent MoE structure within attention layers.

</details>


### [505] [Beyond Training for Cultural Awareness: The Role of Dataset Linguistic Structure in Large Language Models](https://arxiv.org/abs/2602.01161)
*Reem I. Masoud,Chen Feng,Shunta Asano,Saied Alshahrani,Philip Colin Treleaven,Miguel R. D. Rodrigues*

Main category: cs.CL

TL;DR: 本研究通过分析阿拉伯语、中文和日语的微调数据集的语言学特性，探索了这些特性与大型语言模型（LLMs）在文化适应性方面的表现之间的关系，并发现词汇相关的特性对模型性能影响最稳定。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在全球范围内的应用引发了对文化不匹配的担忧，但用于文化适应的微调数据集的语言学特性却鲜为人知，因此需要理解这些特性如何影响模型的文化表现。

Method: 研究者从数据集中心视角出发，计算了阿拉伯语、中文和日语微调数据集的语言学、语义和结构指标，并对每种语言的数据集进行主成分分析（PCA）。随后，利用三种主要的LLM家族（LLaMA, Mistral, DeepSeek）在文化知识、价值观和规范基准上进行微调和评估。通过受控子集干预来验证语言学特性的影响。

Result: PCA组件与下游文化表现相关，但这种关联高度依赖于模型。词汇相关的组件（PC3）在不同模型和基准上表现出最稳健的性能提升，而强调语义多样性或极端性的组件（PC1-PC2）则可能效果中性甚至有害。

Conclusion: 数据集的语言学特性，特别是词汇特性，与LLMs的文化适应性表现密切相关，并且这种影响具有模型依赖性。词汇方面的特征是提升模型文化表现的更可靠途径。

Abstract: The global deployment of large language models (LLMs) has raised concerns about cultural misalignment, yet the linguistic properties of fine-tuning datasets used for cultural adaptation remain poorly understood. We adopt a dataset-centric view of cultural alignment and ask which linguistic properties of fine-tuning data are associated with cultural performance, whether these properties are predictive prior to training, and how these effects vary across models. We compute lightweight linguistic, semantic, and structural metrics for Arabic, Chinese, and Japanese datasets and apply principal component analysis separately within each language. This design ensures that the resulting components capture variation among datasets written in the same language rather than differences between languages. The resulting components correspond to broadly interpretable axes related to semantic coherence, surface-level lexical and syntactic diversity, and lexical or structural richness, though their composition varies across languages. We fine-tune three major LLM families (LLaMA, Mistral, DeepSeek) and evaluate them on benchmarks of cultural knowledge, values, and norms. While PCA components correlate with downstream performance, these associations are strongly model-dependent. Through controlled subset interventions, we show that lexical-oriented components (PC3) are the most robust, yielding more consistent performance across models and benchmarks, whereas emphasizing semantic or diversity extremes (PC1-PC2) is often neutral or harmful.

</details>


### [506] [ASTER: Agentic Scaling with Tool-integrated Extended Reasoning](https://arxiv.org/abs/2602.01204)
*Xuqin Zhang,Quan He,Zhenrui Zheng,Zongzhang Zhang,Xu He,Dong Li*

Main category: cs.CL

TL;DR: 研究提出ASTER框架，通过一种优先考虑交互密集型轨迹的冷启动策略，解决了强化学习（RL）在大型语言模型（LLMs）工具集成推理（TIR）中遇到的交互崩溃问题，并在数学推理基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在利用强化学习（RL）进行长时推理方面取得了进展，但工具集成推理（TIR）通过RL进行扩展面临交互崩溃的挑战，即模型倾向于内部过度推理而非有效利用工具。研究旨在克服这一障碍。

Method: 研究系统地分析了：(i) 冷启动监督微调（SFT）如何塑造模型使用工具的行为先验；(ii) 冷启动轨迹的交互密度如何影响探索和后续RL结果；(iii) RL交互预算如何影响不同推理时间预算下的学习动态和泛化能力。在此基础上，提出ASTER（Agentic Scaling with Tool-integrated Extended Reasoning）框架，采用一种优先考虑交互密集型轨迹的冷启动策略来规避交互崩溃。

Result: 研究发现，使用4000个交互密集型轨迹的冷启动数据集可以产生最强的下游性能，建立了一个鲁棒的先验，有利于在延长的RL训练期间进行更优的探索。ASTER-4B在AIME 2025上达到了90.0%的准确率，性能优于DeepSeek-V3.2-Exp等领先的开源模型。

Conclusion: ASTER框架通过一个精选的、交互密集的冷启动策略，有效解决了RL在LLMs工具集成推理中的交互崩溃问题，显著提升了模型的数学推理能力，并在竞争性基准测试中达到了最先进水平。

Abstract: Reinforcement learning (RL) has emerged as a dominant paradigm for eliciting long-horizon reasoning in Large Language Models (LLMs). However, scaling Tool-Integrated Reasoning (TIR) via RL remains challenging due to interaction collapse: a pathological state where models fail to sustain multi-turn tool usage, instead degenerating into heavy internal reasoning with only trivial, post-hoc code verification. We systematically study three questions: (i) how cold-start SFT induces an agentic, tool-using behavioral prior, (ii) how the interaction density of cold-start trajectories shapes exploration and downstream RL outcomes, and (iii) how the RL interaction budget affects learning dynamics and generalization under varying inference-time budgets. We then introduce ASTER (Agentic Scaling with Tool-integrated Extended Reasoning), a framework that circumvents this collapse through a targeted cold-start strategy prioritizing interaction-dense trajectories. We find that a small expert cold-start set of just 4K interaction-dense trajectories yields the strongest downstream performance, establishing a robust prior that enables superior exploration during extended RL training. Extensive evaluations demonstrate that ASTER-4B achieves state-of-the-art results on competitive mathematical benchmarks, reaching 90.0% on AIME 2025, surpassing leading frontier open-source models, including DeepSeek-V3.2-Exp.

</details>


### [507] [Chronos: Learning Temporal Dynamics of Reasoning Chains for Test-Time Scaling](https://arxiv.org/abs/2602.01208)
*Kai Zhang,Jiayi Liao,Chengpeng Li,Ziyuan Xie,Sihang Li,Xiang Wang*

Main category: cs.CL

TL;DR: Chronos是一种新的时间序列方法，用于评估LLM推理轨迹的质量，通过对不同轨迹赋予不同的权重来改进现有方法，并在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的Test-Time Scaling（TTS）方法，如多数投票和启发式方法，未能区分不同推理轨迹的质量，容易受到轨迹质量波动和局部逻辑错误的影响。

Method: Chronos将每个推理轨迹视为一个时间序列，学习捕捉轨迹的token概率特征，并据此分配质量分数，然后使用加权投票机制。

Result: Chronos在多种模型和各种领域内外的基准测试中均取得了显著的性能提升，计算开销极小。在HMMT25基准测试上，使用Qwen3-4B-Thinking-2507模型，Chronos@128相比Pass@1提升了34.21%，相比Maj@128提升了22.70%。

Conclusion: Chronos是一种轻量级、即插即用的方法，能够有效地对LLM的推理轨迹进行评分，并通过加权投票机制显著提高LLM的推理性能，优于现有的TTS方法。

Abstract: Test-Time Scaling (TTS) has emerged as an effective paradigm for improving the reasoning performance of large language models (LLMs). However, existing methods -- most notably majority voting and heuristic token-level scoring -- treat reasoning traces or tokens equally, thereby being susceptible to substantial variations in trajectory quality and localized logical failures. In this work, we introduce \textbf{Chronos}, a lightweight and plug-and-play chronological reasoning scorer that models each trajectory as a time series. Specifically, Chronos learns to capture trajectory features of token probabilities, assigns quality scores accordingly, and employs a weighted voting mechanism. Extensive evaluations on both in-domain and out-of-domain benchmarks demonstrate that Chronos consistently delivers substantial gains across a variety of models, with negligible computational overhead. Notably, Chronos@128 achieves relative improvements of 34.21\% over Pass@1 and 22.70\% over Maj@128 on HMMT25 using Qwen3-4B-Thinking-2507, highlighting its effectiveness.

</details>


### [508] [Supervised Fine-Tuning Needs to Unlock the Potential of Token Priority](https://arxiv.org/abs/2602.01227)
*Zhanming Shen,Zeyu Qin,Jiaqi Hu,Wentao Ye,Hao Chen,Xiaomeng Hu,Haokai Xu,Gang Chen,Yi R. Fung,Haobo Wang*

Main category: cs.CL

TL;DR: 该论文提出“Token Priority”作为连接经验数据拟合与人类效用的关键，将SFT视为精确的分布重塑过程，并将其应用于噪声过滤（Positive Priority）和有害内容去除（Signed Priority）。


<details>
  <summary>Details</summary>
Motivation: 现有模型在拟合经验数据和实现人类效用之间存在粒度不匹配的问题，通常用粗糙或均匀的信号来指导精细的自回归生成，导致效果不佳。作者希望找到一种方法来弥合这一差距。

Method: 提出“Token Priority”框架，将监督微调（SFT）形式化为精确的分布重塑过程，旨在将原始数据与理想的对齐流形进行匹配。文章将现有突破分为两类：Positive Priority（用于噪声过滤）和Signed Priority（用于有害模式的解学习）。

Result: 通过“Token Priority”框架，论文分析了现有研究的进展和局限性，并将其归类到Positive Priority和Signed Priority两种模式下。

Conclusion: Token Priority为实现真正的人类效用提供了一个统一的视角，能够更好地理解和指导模型对齐研究，并指出了未来的研究方向。

Abstract: The transition from fitting empirical data to achieving true human utility is fundamentally constrained by a granularity mismatch, where fine-grained autoregressive generation is often supervised by coarse or uniform signals. This position paper advocates Token Priority as the essential bridge, formalizing Supervised Fine-Tuning (SFT) not as simple optimization but as a precise distribution reshaping process that aligns raw data with the ideal alignment manifold. We analyze recent breakthroughs through this unified lens, categorizing them into two distinct regimes: Positive Priority for noise filtration and Signed Priority for toxic modes unlearning. We revisit existing progress and limitations, identify key challenges, and suggest directions for future research.

</details>


### [509] [Inferential Question Answering](https://arxiv.org/abs/2602.01239)
*Jamshid Mozafari,Hamed Zamani,Guido Zuccon,Adam Jatowt*

Main category: cs.CL

TL;DR: 本文提出了一种新的推理式问答（Inferential QA）任务，以及配套的数据集QUIT，以解决传统问答系统无法回答需要推理才能获得答案的问题。研究表明，现有问答方法在推理式问答任务上表现不佳，说明当前的问答系统在理解和推理间接文本证据方面仍有待提高。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统主要关注答案是否直接包含在文本中，但许多问题需要通过推理才能得出答案。因此，需要一个能够处理需要从线索中推断答案的新任务。

Method: 提出了Inferential QA任务，并构建了QUIT数据集，其中包含7,401个问题和2.4M个段落。通过对检索器、重排器和基于LLM的阅读器进行评估，分析了它们在Inferential QA任务上的表现。

Result: 在QUIT数据集上的实验表明，在传统QA任务上有效的模型在Inferential QA任务上表现不佳。检索器性能下降，重排器增益有限，微调效果不一致，即使是推理导向的LLM也未能超越小型通用模型。

Conclusion: 现有的问答流水线尚未准备好处理基于推理的问答任务。Inferential QA任务的提出，为QA领域开辟了一个新的研究方向，旨在提升模型从间接文本证据中进行理解和推理的能力。

Abstract: Despite extensive research on a wide range of question answering (QA) systems, most existing work focuses on answer containment-i.e., assuming that answers can be directly extracted and/or generated from documents in the corpus. However, some questions require inference, i.e., deriving answers that are not explicitly stated but can be inferred from the available information. We introduce Inferential QA -- a new task that challenges models to infer answers from answer-supporting passages which provide only clues. To study this problem, we construct QUIT (QUestions requiring Inference from Texts) dataset, comprising 7,401 questions and 2.4M passages built from high-convergence human- and machine-authored hints, labeled across three relevance levels using LLM-based answerability and human verification. Through comprehensive evaluation of retrievers, rerankers, and LLM-based readers, we show that methods effective on traditional QA tasks struggle in inferential QA: retrievers underperform, rerankers offer limited gains, and fine-tuning provides inconsistent improvements. Even reasoning-oriented LLMs fail to outperform smaller general-purpose models. These findings reveal that current QA pipelines are not yet ready for inference-based reasoning. Inferential QA thus establishes a new class of QA tasks that move towards understanding and reasoning from indirect textual evidence.

</details>


### [510] [Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments](https://arxiv.org/abs/2602.01244)
*Siwei Wu,Yizhi Li,Yuyang Song,Wei Zhang,Yang Wang,Riza Batista-Navarro,Xian Yang,Mingjie Tang,Bryan Dai,Jian Yang,Chenghua Lin*

Main category: cs.CL

TL;DR: 该研究提出了TerminalTraj，一个能够生成高质量、可执行且可验证的终端交互轨迹的流水线，并利用其构建了一个大规模数据集，显著提升了训练智能体模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的终端交互轨迹数据质量不高，难以满足训练智能体模型的需求，主要是因为Executability（每个实例需要特定的Docker环境）和Verifiability（任务输出多样化难以统一验证）的挑战。

Method: TerminalTraj流水线包括：1. 筛选高质量代码仓库构建Docker化执行环境；2. 生成与Docker环境匹配的任务实例；3. 合成带有可执行验证代码的智能体轨迹。最终，该方法在8个领域生成了50,733条轨迹。

Result: 在TerminalTraj数据集上训练的模型（以Qwen2.5-Coder为骨干）在TerminalBench（TB）上表现出持续的性能提升，TB 1.0提升高达20%，TB 2.0提升10%。TerminalTraj-32B模型在TB 1.0上达到35.30%，TB 2.0上达到22.00%，表现出优异的测试时扩展性。

Conclusion: TerminalTraj流水线成功解决了构建高质量终端轨迹数据的挑战，创建了一个大规模、可验证的数据集，并证明了使用该数据集训练的模型在终端基准测试上取得了显著的性能改进。

Abstract: Training agentic models for terminal-based tasks critically depends on high-quality terminal trajectories that capture realistic long-horizon interactions across diverse domains. However, constructing such data at scale remains challenging due to two key requirements: \textbf{\emph{Executability}}, since each instance requires a suitable and often distinct Docker environment; and \textbf{\emph{Verifiability}}, because heterogeneous task outputs preclude unified, standardized verification. To address these challenges, we propose \textbf{TerminalTraj}, a scalable pipeline that (i) filters high-quality repositories to construct Dockerized execution environments, (ii) generates Docker-aligned task instances, and (iii) synthesizes agent trajectories with executable validation code. Using TerminalTraj, we curate 32K Docker images and generate 50,733 verified terminal trajectories across eight domains. Models trained on this data with the Qwen2.5-Coder backbone achieve consistent performance improvements on TerminalBench (TB), with gains of up to 20\% on TB~1.0 and 10\% on TB~2.0 over their respective backbones. Notably, \textbf{TerminalTraj-32B} achieves strong performance among models with fewer than 100B parameters, reaching 35.30\% on TB~1.0 and 22.00\% on TB~2.0, and demonstrates improved test-time scaling behavior. All code and data are available at https://github.com/Wusiwei0410/TerminalTraj.

</details>


### [511] [PARSE: An Open-Domain Reasoning Question Answering Benchmark for Persian](https://arxiv.org/abs/2602.01246)
*Jamshid Mozafari,Seyed Parsa Mousavinasab,Adam Jatowt*

Main category: cs.CL

TL;DR: 本文提出了PARS，这是第一个面向开放域的波斯语推理问答基准，旨在解决低资源语言在推理QA领域的评估空白。该基准包含10,800个问题，涵盖多种题型、推理类型和难度，并通过LLM生成和人工评估进行验证。研究还评估了多语言和波斯语LLM在不同提示策略下的表现，并发现波斯语提示和结构化提示（如CoT和few-shot）能有效提升性能，模型微调也能进一步优化结果。


<details>
  <summary>Details</summary>
Motivation: 高标准的低资源语言推理问答基准稀缺，特别是波斯语，缺乏评估推理能力QA系统的全面开放域资源。

Method: 构建了一个包含10,800个问题的波斯语开放域推理QA基准（PARSE），该基准通过受控的LLM生成流程创建，并经过人工评估验证。同时，对多语言和波斯语LLM在不同提示策略（包括波斯语提示、CoT和few-shot）下的性能进行了评估，并进行了模型微调。

Result: 提出了第一个开放域波斯语推理QA基准PARSE。研究表明，使用波斯语提示和结构化提示（针对布尔/多项选择问题使用CoT，针对事实性问题使用few-shot）可以提高LLM在PARSE上的性能。微调模型，尤其是专门针对波斯语的模型，能进一步提升性能。

Conclusion: PARSE填补了波斯语QA研究的关键空白，为低资源环境中开发和评估推理能力LLM提供了坚实的基础，并为模型在该语言的推理QA任务上的改进提供了方向。

Abstract: Reasoning-focused Question Answering (QA) has advanced rapidly with Large Language Models (LLMs), yet high-quality benchmarks for low-resource languages remain scarce. Persian, spoken by roughly 130 million people, lacks a comprehensive open-domain resource for evaluating reasoning-capable QA systems. We introduce PARSE, the first open-domain Persian reasoning QA benchmark, containing 10,800 questions across Boolean, multiple-choice, and factoid formats, with diverse reasoning types, difficulty levels, and answer structures. The benchmark is built via a controlled LLM-based generation pipeline and validated through human evaluation. We also ensure linguistic and factual quality through multi-stage filtering, annotation, and consistency checks. We benchmark multilingual and Persian LLMs under multiple prompting strategies and show that Persian prompts and structured prompting (CoT for Boolean/multiple-choice; few-shot for factoid) improve performance. Fine-tuning further boosts results, especially for Persian-specialized models. These findings highlight how PARSE supports both fair comparison and practical model adaptation. PARSE fills a critical gap in Persian QA research and provides a strong foundation for developing and evaluating reasoning-capable LLMs in low-resource settings.

</details>


### [512] [EverMemBench: Benchmarking Long-Term Interactive Memory in Large Language ModelsEverMemBench: Benchmarking Long-Term Interactive Memory in Large Language Models](https://arxiv.org/abs/2602.01313)
*Chuanrui Hu,Tong Li,Xingze Gao,Hongda Chen,Dannong Xu,Yi Bai,Tianwei Lin,Xinda Zhao,Xiaohong Li,Jiaqi An,Yunyun Han,Jian Pei,Yafeng Deng*

Main category: cs.CL

TL;DR: 本文提出了一个名为EverMemBench的新基准，用于评估大型语言模型（LLM）在复杂、多人、多话题对话中的长期记忆能力，并揭示了现有模型在多跳推理、时间推理和记忆感知方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的对话记忆基准过于简单，无法反映真实世界对话的复杂性（多人、多话题、信息随时间演变等），因此需要一个更具挑战性的基准来推动LLM记忆系统的发展。

Method: 构建了EverMemBench基准，包含超过100万个token的多人、多组对话，具有信息随时间演变、跨话题交织和角色特定个性。通过1000+问答对，从细粒度回忆、记忆感知和用户画像理解三个维度评估记忆系统。

Result: 评估结果显示，现有模型存在关键局限：1) 在多人场景下，多跳推理能力急剧下降（即使是 oracle 模型也只能达到26%）；2) 时间推理尚未解决，需要超越时间戳匹配的版本语义；3) 记忆感知受限于检索，基于相似度的方法难以弥合查询与隐式相关记忆之间的语义鸿沟。

Conclusion: EverMemBench是一个具有挑战性的测试平台，能够暴露现有LLM记忆系统的不足，并为开发下一代记忆架构提供方向。

Abstract: Long-term conversational memory is essential for LLM-based assistants, yet existing benchmarks focus on dyadic, single-topic dialogues that fail to capture real-world complexity. We introduce EverMemBench, a benchmark featuring multi-party, multi-group conversations spanning over 1 million tokens with temporally evolving information, cross-topic interleaving, and role-specific personas. EverMemBench evaluates memory systems across three dimensions through 1,000+ QA pairs: fine-grained recall, memory awareness, and user profile understanding. Our evaluation reveals critical limitations: (1) multi-hop reasoning collapses in multi-party settings, with even oracle models achieving only 26%; (2) temporal reasoning remains unsolved, requiring version semantics beyond timestamp matching; (3) memory awareness is bottlenecked by retrieval, where current similarity-based methods fail to bridge the semantic gap between queries and implicitly relevant memories. EverMemBench provides a challenging testbed for developing next-generation memory architectures.

</details>


### [513] [DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas](https://arxiv.org/abs/2602.01326)
*Zirui Wu,Lin Zheng,Zhihui Xie,Jiacheng Ye,Jiahui Gao,Shansan Gong,Yansong Feng,Zhenguo Li,Wei Bi,Guorui Zhou,Lingpeng Kong*

Main category: cs.CL

TL;DR: 本文提出了DreamOn框架，克服了现有扩散语言模型（DLMs）在代码填充任务中需要固定长度掩码的限制，实现了动态、可变长度的生成，性能可与最先进的自回归模型媲美。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散语言模型（DLMs）在代码填充任务中存在固定长度掩码的局限性，当掩码长度与实际生成长度不匹配时，性能会显著下降，阻碍了其在实际应用中的普及。

Method: DreamOn框架通过引入两个长度控制状态来增强扩散过程，使模型能够根据自身预测自主调整输出长度，并将其集成到现有的DLMs中，对训练目标和架构几乎不做改动。

Result: 在HumanEval-Infilling和SantaCoder-FIM基准测试中，基于DreamOn框架的模型在代码填充任务上取得了与最先进自回归模型相当的性能，并达到了使用真实长度信息（oracle）的性能。

Conclusion: DreamOn框架成功消除了DLMs在可变长度生成方面的一个基本障碍，极大地提高了其灵活性和适用性，为DLMs的实际部署铺平了道路。

Abstract: Diffusion Language Models (DLMs) present a compelling alternative to autoregressive models, offering flexible, any-order infilling without specialized prompting design. However, their practical utility is blocked by a critical limitation: the requirement of a fixed-length masked sequence for generation. This constraint severely degrades code infilling performance when the predefined mask size mismatches the ideal completion length. To address this, we propose DreamOn, a novel diffusion framework that enables dynamic, variable-length generation. DreamOn augments the diffusion process with two length control states, allowing the model to autonomously expand or contract the output length based solely on its own predictions. We integrate this mechanism into existing DLMs with minimal modifications to the training objective and no architectural changes. Built upon Dream-Coder-7B and DiffuCoder-7B, DreamOn achieves infilling performance on par with state-of-the-art autoregressive models on HumanEval-Infilling and SantaCoder-FIM and matches oracle performance achieved with ground-truth length. Our work removes a fundamental barrier to the practical deployment of DLMs, significantly advancing their flexibility and applicability for variable-length generation. Our code is available at https://github.com/DreamLM/DreamOn.

</details>


### [514] [CRAFT: Calibrated Reasoning with Answer-Faithful Traces via Reinforcement Learning for Multi-Hop Question Answering](https://arxiv.org/abs/2602.01348)
*Yu Liu,Wenxiao Zhang,Cong Cao,Fangfang Yuan,Weizhuo Chen,Cheng Hu,Pin Xu,Yuling Yang,Kun Peng,Diandian Guo,Qiang Sun,Yanbing Liu,Jin B. Hong,Zhiyuan Ma*

Main category: cs.CL

TL;DR: 本文提出了一种名为 CRAFT 的基于强化学习的框架，通过双重奖励机制来提高多跳问答中大型语言模型（LLMs）的推理准确性和答案忠实度，并解决推理崩溃、推理-答案不一致和格式控制丢失等问题。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法在多跳问答中虽然能提高答案准确性，但在推理的可靠性方面仍面临推理崩溃、推理与答案不一致以及格式控制困难等挑战。

Method: 提出 CRAFT (Calibrated Reasoning with Answer-Faithful Traces) 框架，采用基于群体相对策略优化 (GRPO) 的强化学习方法。CRAFT 引入了确定性奖励（确保结构正确性）和基于裁判的奖励（验证语义忠实度）的双重奖励机制来优化多跳推理。

Result: 在三个多跳问答基准上的实验表明，CRAFT 在不同模型规模下都能提高答案准确性和推理忠实度。其中，CRAFT 7B 模型在多种推理轨迹设置下达到了与闭源 LLM 相媲美的性能。

Conclusion: CRAFT 框架通过优化的推理过程，有效地解决了多跳问答中 LLM 的推理可靠性问题，提高了答案的准确性和忠实度，并支持可控的推理轨迹分析。

Abstract: Retrieval-augmented generation (RAG) is widely used to ground Large Language Models (LLMs) for multi-hop question answering. Recent work mainly focused on improving answer accuracy via fine-tuning and structured or reinforcement-based optimization. However, reliable reasoning in response generation faces three challenges: 1) Reasoning Collapse. Reasoning in multi-hop QA is inherently complex due to multi-hop composition and is further destabilized by noisy retrieval. 2) Reasoning-answer inconsistency. Due to the intrinsic uncertainty of LLM generation and exposure to evidence--distractor mixtures, models may produce correct answers that are not faithfully supported by their intermediate reasoning or evidence. 3) Loss of format control. Traditional chain-of-thought generation often deviates from required structured output formats, leading to incomplete or malformed structured content. To address these challenges, we propose CRAFT (Calibrated Reasoning with Answer-Faithful Traces), a Group Relative Policy Optimization (GRPO) based reinforcement learning framework that trains models to perform faithful reasoning during response generation. CRAFT employs dual reward mechanisms to optimize multi-hop reasoning: deterministic rewards ensure structural correctness while judge-based rewards verify semantic faithfulness. This optimization framework supports controllable trace variants that enable systematic analysis of how structure and scale affect reasoning performance and faithfulness. Experiments on three multi-hop QA benchmarks show that CRAFT improves both answer accuracy and reasoning faithfulness across model scales, with the CRAFT 7B model achieving competitive performance with closed-source LLMs across multiple reasoning trace settings.

</details>


### [515] [Balancing Understanding and Generation in Discrete Diffusion Models](https://arxiv.org/abs/2602.01362)
*Yue Liu,Yuzhong Zhao,Zheyong Xie,Qixiang Ye,Jianbin Jiao,Yao Hu,Shaosheng Cao,Yunfan Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为 XDLM 的新模型，它结合了掩码扩散语言模型 (MDLM) 和均匀噪声扩散语言模型 (UDLM) 的优点，在语义理解和生成质量之间取得了更好的平衡，并在多个任务上取得了 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 现有的离散生成模型，如 MDLM 和 UDLM，各自在语义理解或生成质量方面表现出色，但无法同时兼顾两者。研究者希望开发一种能够同时实现两者优势的模型。

Method: XDLM 通过引入一个平稳噪声核来统一 MDLM 和 UDLM，并将它们作为特例。此外，通过代数简化后验概率，XDLM 缓解了内存瓶颈问题。

Result: XDLM 在零样本文本任务上比 UDLM 提高了 5.4 个点，在少数步图像生成任务上比 MDLM 表现更好（FID 54.1 vs. 80.8）。在 80 亿参数的大语言模型上，XDLM 在 32 步内实现了 15.0 MBPP，性能翻倍。

Conclusion: XDLM 成功地在理解能力和生成质量之间实现了 Pareto 前沿的提升，并展现出优越的长期扩展潜力。该模型在文本和图像生成任务上均取得了显著的性能提升。

Abstract: In discrete generative modeling, two dominant paradigms demonstrate divergent capabilities: Masked Diffusion Language Models (MDLM) excel at semantic understanding and zero-shot generalization, whereas Uniform-noise Diffusion Language Models (UDLM) achieve strong few-step generation quality, yet neither attains balanced performance across both dimensions. To address this, we propose XDLM, which bridges the two paradigms via a stationary noise kernel. XDLM offers two key contributions: (1) it provides a principled theoretical unification of MDLM and UDLM, recovering each paradigm as a special case; and (2) an alleviated memory bottleneck enabled by an algebraic simplification of the posterior probabilities. Experiments demonstrate that XDLM advances the Pareto frontier between understanding capability and generation quality. Quantitatively, XDLM surpasses UDLM by 5.4 points on zero-shot text benchmarks and outperforms MDLM in few-step image generation (FID 54.1 vs. 80.8). When scaled to tune an 8B-parameter large language model, XDLM achieves 15.0 MBPP in just 32 steps, effectively doubling the baseline performance. Finally, analysis of training dynamics reveals XDLM's superior potential for long-term scaling. Code is available at https://github.com/MzeroMiko/XDLM

</details>


### [516] [Context Dependence and Reliability in Autoregressive Language Models](https://arxiv.org/abs/2602.01378)
*Poushali Sengupta,Shashi Raj Pandey,Sabita Maharjan,Frank Eliassen*

Main category: cs.CL

TL;DR: 本文提出了一种名为RISE（Redundancy-Insensitive Scoring of Explanation）的新方法，用于区分大型语言模型（LLM）输出中关键的上下文信息和冗余信息，以提高模型的可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型解释方法在处理冗余和重叠的上下文时存在困难，导致解释不稳定，并可能导致模型被恶意利用（如提示注入）。因此，需要一种方法来区分对模型输出真正有影响的上下文元素。

Method: RISE方法通过量化每个输入元素相对于其他元素所起的独特影响来评估其重要性，从而最小化冗余信息的影响，并提供更清晰、更稳定的归因。

Result: 实验结果表明，RISE方法比传统方法提供了更鲁棒的解释，它能够更准确地识别条件信息，这对于LLM的可信解释和监控至关重要。

Conclusion: RISE方法能够更有效地处理LLM中的上下文冗余问题，提高模型解释的稳定性和可靠性，对于构建更值得信赖的大型语言模型具有重要意义。

Abstract: Large language models (LLMs) generate outputs by utilizing extensive context, which often includes redundant information from prompts, retrieved passages, and interaction history. In critical applications, it is vital to identify which context elements actually influence the output, as standard explanation methods struggle with redundancy and overlapping context. Minor changes in input can lead to unpredictable shifts in attribution scores, undermining interpretability and raising concerns about risks like prompt injection. This work addresses the challenge of distinguishing essential context elements from correlated ones. We introduce RISE (Redundancy-Insensitive Scoring of Explanation), a method that quantifies the unique influence of each input relative to others, minimizing the impact of redundancies and providing clearer, stable attributions. Experiments demonstrate that RISE offers more robust explanations than traditional methods, emphasizing the importance of conditional information for trustworthy LLM explanations and monitoring.

</details>


### [517] [On the Power of (Approximate) Reward Models for Inference-Time Scaling](https://arxiv.org/abs/2602.01381)
*Youheng Zhu,Yiping Lu*

Main category: cs.CL

TL;DR: 本文研究了在推理时缩放（inference-time scaling）的背景下，序列蒙特卡洛（SMC）方法与近似奖励模型结合使用的有效性。研究发现，当近似奖励模型的贝尔曼误差（Bellman error）界限为O(1/T)时，SMC可以将推理计算复杂度从指数级降低到多项式级。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，真实的奖励模型通常不可用，只能使用近似奖励模型。因此，研究人员希望理解为什么以及在何种条件下，近似奖励模型能够有效地支持SMC推理时缩放。

Method: 通过理论分析，确定了近似奖励模型的贝尔曼误差是影响SMC-基于推理时缩放效果的关键因素。针对长度为T的推理过程，证明了当贝尔曼误差满足O(1/T)的界限时，SMC可以显著降低计算复杂度。

Result: 理论上证明，如果近似奖励模型的贝尔曼误差被限制在O(1/T)以内，那么使用SMC结合该模型可以将推理的计算复杂度从T的指数级降低到T的多项式级。

Conclusion: 即使只使用近似奖励模型，只要其贝尔曼误差足够小（O(1/T）），SMC方法也能实现推理效率的指数级提升。

Abstract: Inference-time scaling has recently emerged as a powerful paradigm for improving the reasoning capability of large language models. Among various approaches, Sequential Monte Carlo (SMC) has become a particularly important framework, enabling iterative generation, evaluation, rejection, and resampling of intermediate reasoning trajectories. A central component in this process is the reward model, which evaluates partial solutions and guides the allocation of computation during inference.
  However, in practice, true reward models are never available. All deployed systems rely on approximate reward models, raising a fundamental question: Why and when do approximate reward models suffice for effective inference-time scaling? In this work, we provide a theoretical answer. We identify the Bellman error of the approximate reward model as the key quantity governing the effectiveness of SMC-based inference-time scaling. For a reasoning process of length $T$, we show that if the Bellman error of the approximate reward model is bounded by $O(1/T)$, then combining this reward model with SMC reduces the computational complexity of reasoning from exponential in $T$ to polynomial in $T$. This yields an exponential improvement in inference efficiency despite using only approximate rewards.

</details>


### [518] [Rethinking Selective Knowledge Distillation](https://arxiv.org/abs/2602.01395)
*Almog Tavor,Itay Ebenspanger,Neil Cnaan,Mor Geva*

Main category: cs.CL

TL;DR: 该研究系统地分析了在自回归大型语言模型（LLMs）中进行选择性知识蒸馏（KD）的有效性，并提出了一种新的学生熵引导的位置选择方法（SE-KD），该方法能提高准确性、下游任务遵循性和内存效率，并且在结合样本和类别轴上的改进后（SE-KD 3X），显著降低了时间和内存开销，实现了离线教师缓存。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型知识蒸馏方法通常使用密集的教师监督，而选择性蒸馏（仅使用部分 token 位置、词汇类别或训练样本进行监督）被认为是提高效率的关键。然而，对于哪种重要性信号、选择策略及其组合最有效，尚不清楚。因此，研究动机在于系统地分析和比较不同选择性知识蒸馏的方法，并在此基础上提出更优的策略。

Method: 该研究首先解耦了位置、类别和样本这三个轴向的选择性知识蒸馏。然后，它系统地比较了不同的重要性信号和选择策略。在此分析的指导下，研究者提出了学生熵引导的位置选择（SE-KD）方法。进一步地，将该方法扩展到类别和样本轴（SE-KD 3X），以获得互补的效率提升。

Result: SE-KD 在一系列基准测试中，通常能够提高准确性、下游任务遵循性和内存效率，优于密集蒸馏。SE-KD 3X 在效率方面取得了额外的提升，使得离线教师缓存成为可能，实际应用中可将处理时间减少 70%，峰值内存减少 18%，存储使用量减少 80%，同时不牺牲性能。

Conclusion: 通过对自回归 LLMs 中的选择性知识蒸馏进行深入分析，研究者发现 SE-KD 是一种有效的方法，能够提升蒸馏效率和模型性能。SE-KD 3X 进一步通过结合样本和类别轴的优化，实现了显著的实际部署效益，如降低时间和内存成本，并支持离线教师缓存。

Abstract: Growing efforts to improve knowledge distillation (KD) in large language models (LLMs) replace dense teacher supervision with selective distillation, which uses a subset of token positions, vocabulary classes, or training samples for supervision. However, it remains unclear which importance signals, selection policies, and their interplay are most effective. In this work, we revisit where and how to distill in autoregressive LLMs. We disentangle selective KD along the position, class, and sample axes and systematically compare importance signals and selection policies. Then, guided by this analysis, we identify underexplored opportunities and introduce student-entropy-guided position selection (SE-KD). Across a suite of benchmarks, SE-KD often improves accuracy, downstream task adherence, and memory efficiency over dense distillation. Extending this approach across the class and sample axes (SE-KD 3X) yields complementary efficiency gains that make offline teacher caching feasible. In practice, this reduces wall time by 70% and peak memory by 18%, while cutting storage usage by 80% over prior methods without sacrificing performance.

</details>


### [519] [Minimizing Mismatch Risk: A Prototype-Based Routing Framework for Zero-shot LLM-generated Text Detection](https://arxiv.org/abs/2602.01240)
*Ke Sun,Guangsheng Bao,Han Cui,Yue Zhang*

Main category: cs.CL

TL;DR: 研究表明，零样本 LLM 检测器的性能与其选择的代理模型（surrogate model）密切相关，不存在通用的最佳代理模型。提出了一种名为 DetectRouter 的新框架，通过两阶段训练来学习文本与检测器之间的亲和度，以解决这一问题，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本 LLM 检测方法通常使用固定的代理模型，但研究发现这种做法的检测性能会因代理模型与真实文本来源（source）的匹配度不同而产生显著差异。因此，研究的动机是解决如何为不同输入选择最合适的代理模型，以实现更鲁棒的检测。

Method: 提出了一种名为 DetectRouter 的原型（prototype-based）框架。该框架通过两阶段训练来学习文本与检测器之间的亲和度。第一阶段使用白盒模型构建区分度高的原型；第二阶段通过对齐几何距离与检测分数来泛化到黑盒模型。本质上，DetectRouter 将鲁棒检测转化为一个路由问题，即为每个输入选择最合适的代理模型。

Result: 在 EvoBench 和 MAGE 基准测试上进行实验，DetectRouter 在多个检测标准和模型系列上都展现出了一致的性能提升。

Conclusion: 研究发现，零样本 LLM 检测的性能高度依赖于代理模型的选择，不存在一个通用的最佳代理模型。通过将检测问题转化为一个路由问题，并提出 DetectRouter 框架，可以学习文本与检测器之间的亲和度，从而实现更鲁棒和高效的 LLM 生成文本检测。

Abstract: Zero-shot methods detect LLM-generated text by computing statistical signatures using a surrogate model. Existing approaches typically employ a fixed surrogate for all inputs regardless of the unknown source. We systematically examine this design and find that detection performance varies substantially depending on surrogate-source alignment. We observe that while no single surrogate achieves optimal performance universally, a well-matched surrogate typically exists within a diverse pool for any given input. This finding transforms robust detection into a routing problem: selecting the most appropriate surrogate for each input. We propose DetectRouter, a prototype-based framework that learns text-detector affinity through two-stage training. The first stage constructs discriminative prototypes from white-box models; the second generalizes to black-box sources by aligning geometric distances with observed detection scores. Experiments on EvoBench and MAGE benchmarks demonstrate consistent improvements across multiple detection criteria and model families.

</details>


### [520] [From Pragmas to Partners: A Symbiotic Evolution of Agentic High-Level Synthesis](https://arxiv.org/abs/2602.01401)
*Niansong Zhang,Sunwoo Kim,Shreesha Srinath,Zhiru Zhang*

Main category: cs.CL

TL;DR: 本文认为，尽管大型语言模型兴起，高层综合（HLS）在通用硬件设计领域仍然至关重要，它能够加速代理式优化，并提出了 HLS 与代理式 AI 协同进化的方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的兴起促使人们思考 HLS 在代理式硬件设计时代的作用，以及 HLS 是否仍然重要。

Method: 本文通过论证 HLS 在加速迭代、可移植性和设计可变性方面的优势，解释了 HLS 作为代理式硬件设计的实用抽象层和黄金参考。此外，文章还识别了当前 HLS 工具在性能反馈、接口和可调试性方面的局限性，并提出了代理式 HLS 协同进化的分类法。

Result: HLS 是代理式硬件设计的关键层，能够加速设计迭代和优化。当前 HLS 工具存在性能反馈、接口和可调试性方面的不足，这些都可以通过代理式 AI 来解决。

Conclusion: HLS 在代理式硬件设计时代仍然至关重要，其优势使其成为代理式优化的理想选择。通过 AI 代理和 HLS 的协同进化，可以实现更高效、更自主的硬件设计流程。

Abstract: The rise of large language models has sparked interest in AI-driven hardware design, raising the question: does high-level synthesis (HLS) still matter in the agentic era? We argue that HLS remains essential. While we expect mature agentic hardware systems to leverage both HLS and RTL, this paper focuses on HLS and its role in enabling agentic optimization. HLS offers faster iteration cycles, portability, and design permutability that make it a natural layer for agentic optimization.This position paper makes three contributions. First, we explain why HLS serves as a practical abstraction layer and a golden reference for agentic hardware design. Second, we identify key limitations of current HLS tools, namely inadequate performance feedback, rigid interfaces, and limited debuggability that agents are uniquely positioned to address. Third, we propose a taxonomy for the symbiotic evolution of agentic HLS, clarifying how responsibility shifts from human designers to AI agents as systems advance from copilots to autonomous design partners.

</details>


### [521] [SentiFuse: Deep Multi-model Fusion Framework for Robust Sentiment Extraction](https://arxiv.org/abs/2602.01447)
*Hieu Minh Duong,Rupa Ghosh,Cong Hoan Nguyen,Eugene Levin,Todd Gary,Long Nguyen*

Main category: cs.CL

TL;DR: 本文提出了一种名为 SentiFuse 的统一框架，用于整合异构情感分析模型，通过标准层和多种融合策略（决策级、特征级、自适应融合）来提升情感分析的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的情感分析模型各有所长但缺乏有效的整合方法，研究者希望开发一个统一的框架来系统地结合不同模型的优势。

Method: SentiFuse 框架通过一个标准化层来统一异构模型，并支持决策级融合、特征级融合和自适应融合三种不同的融合策略。

Result: 在 Crowdflower, GoEmotions, 和 Sentiment140 三个大型社交媒体数据集上，SentiFuse 展现出比单一模型和简单集成方法更好的性能。特征级融合效果最显著，F1 分数比最佳单一模型和简单平均提高了 4%。自适应融合在处理否定、混合情感和复杂情感表达时提高了鲁棒性。

Conclusion: 系统性地利用模型互补性可以在不同数据集和文本类型上实现更准确、更可靠的情感分析。

Abstract: Sentiment analysis models exhibit complementary strengths, yet existing approaches lack a unified framework for effective integration. We present SentiFuse, a flexible and model-agnostic framework that integrates heterogeneous sentiment models through a standardization layer and multiple fusion strategies. Our approach supports decision-level fusion, feature-level fusion, and adaptive fusion, enabling systematic combination of diverse models. We conduct experiments on three large-scale social-media datasets: Crowdflower, GoEmotions, and Sentiment140. These experiments show that SentiFuse consistently outperforms individual models and naive ensembles. Feature-level fusion achieves the strongest overall effectiveness, yielding up to 4\% absolute improvement in F1 score over the best individual model and simple averaging, while adaptive fusion enhances robustness on challenging cases such as negation, mixed emotions, and complex sentiment expressions. These results demonstrate that systematically leveraging model complementarity yields more accurate and reliable sentiment analysis across diverse datasets and text types.

</details>


### [522] [Understanding QA generation: Extracting Parametric and Contextual Knowledge with CQA for Low Resource Bangla Language](https://arxiv.org/abs/2602.01451)
*Umme Abira Azmary,MD Ikramul Kayes,Swakkhar Shatabda,Farig Yousuf Sadeque*

Main category: cs.CL

TL;DR: 本文提出了首个孟加拉语反事实问答数据集BanglaCQA，并开发了用于区分模型参数知识和上下文知识的评估框架，发现在反事实场景下，Chain-of-Thought（CoT）提示对于解码器模型提取参数知识非常有效。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如孟加拉语）的问答模型面临数据稀缺和语言复杂性的挑战。现有数据集无法分析模型在生成答案时依赖的是预编码知识还是上下文信息。

Method: 通过扩展现有孟加拉语数据集并引入反事实段落和可回答性标注，创建了BanglaCQA数据集。提出了针对特定语言和多语言基线模型的微调管道，以及针对解码器模型的大语言模型（LLM）提示管道，以区分事实和反事实场景下的参数知识和上下文知识。同时，使用了基于LLM和人工评估来衡量答案质量，并通过Chain-of-Thought（CoT）提示来分析模型。

Result: Chain-of-Thought（CoT）提示在反事实场景下，特别是对于解码器模型，展示了提取参数知识的有效机制。研究还展示了模型在低资源语言问答场景下的详细表现。

Conclusion: 本文提出了一个分析孟加拉语问答模型知识来源的新框架，并发现了反事实推理在低资源语言设置中的关键见解，为未来的研究开辟了新方向。

Abstract: Question-Answering (QA) models for low-resource languages like Bangla face challenges due to limited annotated data and linguistic complexity. A key issue is determining whether models rely more on pre-encoded (parametric) knowledge or contextual input during answer generation, as existing Bangla QA datasets lack the structure required for such analysis. We introduce BanglaCQA, the first Counterfactual QA dataset in Bangla, by extending a Bangla dataset while integrating counterfactual passages and answerability annotations. In addition, we propose fine-tuned pipelines for encoder-decoder language-specific and multilingual baseline models, and prompting-based pipelines for decoder-only LLMs to disentangle parametric and contextual knowledge in both factual and counterfactual scenarios. Furthermore, we apply LLM-based and human evaluation techniques that measure answer quality based on semantic similarity. We also present a detailed analysis of how models perform across different QA settings in low-resource languages, and show that Chain-of-Thought (CoT) prompting reveals a uniquely effective mechanism for extracting parametric knowledge in counterfactual scenarios, particularly in decoder-only LLMs. Our work not only introduces a novel framework for analyzing knowledge sources in Bangla QA but also uncovers critical findings that open up broader directions for counterfactual reasoning in low-resource language settings.

</details>


### [523] [ConPress: Learning Efficient Reasoning from Multi-Question Contextual Pressure](https://arxiv.org/abs/2602.01472)
*Jie Deng,Shining Liang,Jun Li,Hongzhi Li,Yutao Xie*

Main category: cs.CL

TL;DR: 研究提出了一种名为“自压缩”的推理现象，即在多问题提示下，模型会自发地生成更短的推理链。基于此，研究开发了ConPress轻量级自监督微调方法，通过构造多问题提示诱导模型压缩推理，并利用生成的压缩推理轨迹进行监督微调，从而在不牺牲准确性的前提下显著降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在解决复杂推理任务时会生成冗长的推理链，导致高昂的推理开销。研究旨在寻找一种更高效的推理方法。

Method: 研究者观察到“自压缩”现象（模型在处理包含多个独立问题的提示时，会为每个问题生成更短的推理链），并基于此提出了ConPress（Contextual Pressure学习）方法。ConPress通过构造多问题提示诱导自压缩，采样模型输出，解析并过滤得到简洁且正确的推理轨迹，然后用这些轨迹进行监督微调，以习得压缩推理行为。

Result: ConPress微调方法在MATH500数据集上将推理代币使用量减少了59%，在AIME25数据集上减少了33%，同时保持了具有竞争力的准确率。仅使用了8k的微调示例。

Conclusion: ConPress是一种有效的轻量级自监督微调方法，能够通过利用上下文压力诱导模型进行推理自压缩，从而显著降低推理成本，并实现简洁高效的推理。

Abstract: Large reasoning models (LRMs) typically solve reasoning-intensive tasks by generating long chain-of-thought (CoT) traces, leading to substantial inference overhead. We identify a reproducible inference-time phenomenon, termed Self-Compression: when multiple independent and answerable questions are presented within a single prompt, the model spontaneously produces shorter reasoning traces for each question. This phenomenon arises from multi-question contextual pressure during generation and consistently manifests across models and benchmarks. Building on this observation, we propose ConPress (Learning from Contextual Pressure), a lightweight self-supervised fine-tuning approach. ConPress constructs multi-question prompts to induce self-compression, samples the resulting model outputs, and parses and filters per-question traces to obtain concise yet correct reasoning trajectories. These trajectories are directly used for supervised fine-tuning, internalizing compressed reasoning behavior in single-question settings without external teachers, manual pruning, or reinforcement learning. With only 8k fine-tuning examples, ConPress reduces reasoning token usage by 59% on MATH500 and 33% on AIME25, while maintaining competitive accuracy.

</details>


### [524] [Ebisu: Benchmarking Large Language Models in Japanese Finance](https://arxiv.org/abs/2602.01479)
*Xueqing Peng,Ruoyu Xiang,Fan Zhang,Mingzi Song,Mingyang Jiang,Yan Wang,Lingfei Qian,Taiki Hara,Yuqing Guo,Jimin Huang,Junichi Tsujii,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 该研究提出了 Ebisu 这一针对日语金融语言理解的基准测试，包含两个评估隐含承诺、拒绝识别及金融术语提取排序的任务。现有 LLMs 在该基准上表现不佳，模型规模和领域适应性提升有限，表明需要更具语言和文化针对性的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在理解日语金融语言方面面临挑战，原因在于日语的语言结构（粘着性、主语后置）、混合书写系统以及高语境沟通文化（依赖间接表达和隐含承诺）。因此，需要一个专门的基准来评估和推动 LLMs 在这一领域的进步。

Method: 研究提出了 Ebisu 基准，包含两个任务：JF-ICR（评估投资者问答中的隐含承诺和拒绝识别）和 JF-TE（评估专业披露文本中嵌套金融术语的层级提取和排序）。研究评估了一系列开源和专有 LLMs（通用型、日语适应型、金融型），并分析了模型规模、语言和领域适应性对性能的影响。

Result: 结果表明，即使是最先进的 LLMs 在 Ebisu 的两个任务上都表现不佳。增加模型规模仅带来有限的性能提升，而语言和领域特定的适应性并未可靠地提高性能，模型性能与人类专家水平仍有显著差距。

Conclusion: Ebisu 提供了一个专注的基准，有助于推动在语言和文化上更具针对性的金融自然语言处理（NLP）研究。现有的 LLMs 在理解日语金融语言方面仍需改进，尤其是在处理隐含信息和复杂金融文本方面。

Abstract: Japanese finance combines agglutinative, head-final linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released.

</details>


### [525] [Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training](https://arxiv.org/abs/2602.01511)
*Ran Xu,Tianci Liu,Zihan Dong,Tony You,Ilgee Hong,Carl Yang,Linjun Zhang,Tao Zhao,Haoyu Wang*

Main category: cs.CL

TL;DR: 提出Rubric-ARM框架，通过强化学习优化评分标准生成器和评分模型，以解决标准奖励模型在非可验证领域（如创意写作）中无法捕捉多方面响应质量的问题。


<details>
  <summary>Details</summary>
Motivation: 标准的标量奖励模型无法充分刻画创意写作等领域中响应质量的多方面性。现有的方法依赖静态评分标准或分离的训练流程，不够灵活。 

Method: 提出Rubric-ARM框架，将评分标准的生成视为一个潜在动作，并通过强化学习从偏好反馈中进行联合优化。采用交替优化策略来解决同步更新的非平稳性问题。

Result: Rubric-ARM在多个基准测试中达到了最先进的性能，并在离线和在线强化学习设置中显著提高了下游策略对齐。

Conclusion: Rubric-ARM框架能够有效地生成适应性评分标准并提高评分准确性，从而在非可验证领域实现更优的策略对齐。

Abstract: Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback. Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings.

</details>


### [526] [Argument Rarity-based Originality Assessment for AI-Assisted Writing](https://arxiv.org/abs/2602.01560)
*Keito Inoshita,Michiaki Omura,Tsukasa Yamanaka,Go Maeda,Kentaro Tsuji*

Main category: cs.CL

TL;DR: 本研究提出了一种基于论证稀有度的原创性评估（AROA）框架，用于自动评估学生论文的原创性，该框架将原创性定义为参考语料库中的稀有度，并包含结构、论点、证据和认知深度四个维度。实验表明，AI生成的论文在结构上与人类论文相当，但在论点原创性上远低于人类论文，揭示了质量与原创性之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）生成高质量文本的能力增强，传统的侧重质量的写作评估方法正在失去意义。教育的根本目标是培养批判性思维和原创观点，因此评估方法必须从关注质量转向关注原创性。

Method: 研究提出了论证稀有度原创性评估（AROA）框架，将原创性定义为在参考语料库中的稀有度。该框架通过四个组成部分来评估原创性：结构稀有度、论点稀有度、证据稀有度以及认知深度。通过密度估计量化每个组成部分的稀有度，并结合质量调整机制，将质量和原创性视为独立的评估轴。

Result: 实验发现，论文质量与论点稀有度之间存在显著的负相关关系，表明存在一种质量-原创性权衡，即更高质量的文本往往依赖于典型的论点模式。此外，AI生成的论文在结构复杂性上与人类论文相当，但其论点稀有度远低于人类论文。

Conclusion: AI在复制论证形式方面表现出色，但在内容原创性方面存在局限性。AROA框架能够有效地区分人类和AI生成的论文在原创性上的差异，并揭示了质量与原创性之间的权衡关系。

Abstract: As Large Language Models (LLMs) have become capable of effortlessly generating high-quality text, traditional quality-focused writing assessment is losing its significance. If the essential goal of education is to foster critical thinking and original perspectives, assessment must also shift its paradigm from quality to originality. This study proposes Argument Rarity-based Originality Assessment (AROA), a framework for automatically evaluating argumentative originality in student essays. AROA defines originality as rarity within a reference corpus and evaluates it through four complementary components: structural rarity, claim rarity, evidence rarity, and cognitive depth. The framework quantifies the rarity of each component using density estimation and integrates them with a quality adjustment mechanism, thereby treating quality and originality as independent evaluation axes. Experiments using human essays and AI-generated essays revealed a strong negative correlation between quality and claim rarity, demonstrating a quality-originality trade-off where higher-quality texts tend to rely on typical claim patterns. Furthermore, while AI essays achieved comparable levels of structural complexity to human essays, their claim rarity was substantially lower than that of humans, indicating that LLMs can reproduce the form of argumentation but have limitations in the originality of content.

</details>


### [527] [FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents](https://arxiv.org/abs/2602.01566)
*Chiwei Zhu,Benfeng Xu,Mingxuan Du,Shaohan Wang,Xiaorui Wang,Zhendong Mao,Yongdong Zhang*

Main category: cs.CL

TL;DR: FS-Researcher 是一个基于文件系统的双智能体框架，通过持久化工作区解决了长时程任务中 LLM 代理的上下文窗口限制问题，在深研任务上取得了 SOTA 报告质量。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 代理在执行深研等长时程任务时，受限于上下文窗口，导致证据收集和报告撰写时程受限，且无法有效进行测试时扩展。FS-Researcher 旨在突破这一限制。

Method: FS-Researcher 采用基于文件系统的双智能体框架：1. 上下文构建者（Context Builder）作为“图书管理员”，负责浏览互联网、撰写结构化笔记，并将原始资料归档到可无限扩展的层级知识库。2. 报告撰写者（Report Writer）将知识库作为事实来源，分章节撰写最终报告。文件系统充当持久化外部记忆和代理间协调媒介，支持超越上下文窗口的迭代优化。

Result: 在 DeepResearch Bench 和 DeepConsult 两个开放式基准测试上，FS-Researcher 显著提升了不同骨干模型的报告质量，达到 SOTA 水平。实验还表明，分配给上下文构建者的计算资源越多，最终报告质量越高，验证了文件系统范式下的有效测试时扩展。

Conclusion: FS-Researcher 通过引入文件系统作为外部记忆和协调机制，成功地使 LLM 代理能够处理超越上下文窗口限制的长时程深研任务，并实现了报告质量和可扩展性的提升。

Abstract: Deep research is emerging as a representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, a file-system-based, dual-agent framework that scales deep research beyond the context window via a persistent workspace. Specifically, a Context Builder agent acts as a librarian which browses the internet, writes structured notes, and archives raw sources into a hierarchical knowledge base that can grow far beyond context length. A Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as a durable external memory and a shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate a positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at https://github.com/Ignoramus0817/FS-Researcher.

</details>


### [528] [LLM-based Embeddings: Attention Values Encode Sentence Semantics Better Than Hidden States](https://arxiv.org/abs/2602.01572)
*Yeqin Zhang,Yunfei Wang,Jiaxuan Chen,Ke Qin,Yizheng Zhao,Cam-Tu Nguyen*

Main category: cs.CL

TL;DR: 本研究提出了一种名为 Value Aggregation (VA) 的新方法，通过聚合多层和多token的注意力值向量来生成句子表示，发现其比传统依赖隐藏状态的方法更能有效捕捉句子语义。进一步提出的 Aligned Weighted VA (AlignedWVA) 通过利用注意力权重和输出投影矩阵，在训练无关设置下取得了比现有方法更好的性能，并展示了微调VA模型以获得高性能嵌入模型的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的句子表示方法通常依赖于优化用于下一token预测的最终层隐藏状态，这往往无法充分捕捉全局的句子级语义。研究者希望找到一种更有效的方法来提取句子语义。

Method: 提出了一种名为 Value Aggregation (VA) 的方法，通过聚合多层和多token的注意力值向量来生成句子表示。在此基础上，进一步提出 Aligned Weighted VA (AlignedWVA)，利用最后一token的注意力分数作为权重，并通过输出投影矩阵 ($W_O$) 将加权后的值向量与LLM残差流的公共空间对齐。

Result: 在训练无关的设置下，VA方法优于其他基于LLM的嵌入方法，甚至可以媲美或超越集成方法MetaEOL。AlignedWVA方法取得了当前训练无关LLM嵌入的SOTA性能，显著优于高成本的MetaEOL。此外，研究还表明通过微调VA模型可以获得强大的LLM嵌入模型。

Conclusion: 注意力值向量比隐藏状态更能有效地捕捉句子语义。所提出的Value Aggregation (VA) 和 Aligned Weighted VA (AlignedWVA) 方法在生成句子表示方面表现出色，尤其是在训练无关的设置下。微调VA模型是获得高性能LLM嵌入模型的有前景的途径。

Abstract: Sentence representations are foundational to many Natural Language Processing (NLP) applications. While recent methods leverage Large Language Models (LLMs) to derive sentence representations, most rely on final-layer hidden states, which are optimized for next-token prediction and thus often fail to capture global, sentence-level semantics. This paper introduces a novel perspective, demonstrating that attention value vectors capture sentence semantics more effectively than hidden states. We propose Value Aggregation (VA), a simple method that pools token values across multiple layers and token indices. In a training-free setting, VA outperforms other LLM-based embeddings, even matches or surpasses the ensemble-based MetaEOL. Furthermore, we demonstrate that when paired with suitable prompts, the layer attention outputs can be interpreted as aligned weighted value vectors. Specifically, the attention scores of the last token function as the weights, while the output projection matrix ($W_O$) aligns these weighted value vectors with the common space of the LLM residual stream. This refined method, termed Aligned Weighted VA (AlignedWVA), achieves state-of-the-art performance among training-free LLM-based embeddings, outperforming the high-cost MetaEOL by a substantial margin. Finally, we highlight the potential of obtaining strong LLM embedding models through fine-tuning Value Aggregation.

</details>


### [529] [Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment](https://arxiv.org/abs/2602.01587)
*Zehua Cheng,Jianwei Yang,Wei Dai,Jiahao Sun*

Main category: cs.CL

TL;DR: 提出了一种名为CSS的框架，通过分层随机消融技术，将LLM的安全保证从单次推理转移到模型输出的统计稳定性，从而实现可验证的鲁棒性，显著降低了攻击成功率，并保持了较高的可用性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）容易受到自适应越狱攻击，现有的防御措施难以应对。

Method: 提出了一种名为CSS（Certified Semantic Smoothing）的框架，该框架通过分层随机消融（Stratified Randomized Ablation）技术，将输入分为结构化提示和可变载荷，并利用超几何分布来获得严格的l_p范数保证。为了解决稀疏上下文的性能下降问题，采用了噪声增强对齐调优（NAAT）技术，将基础模型转化为语义去噪器。

Result: 在Llama-3模型上的实验表明，该方法将基于梯度的攻击成功率从84.2%降低到1.2%，同时保持了94.1%的良性效用。与字符级基线方法相比，该方法显著优于后者，后者会将效用降低到74.3%。

Conclusion: 该框架提供了一种确定性的安全证明，确保模型在可证明的半径内对所有对抗性变体都保持鲁棒性。

Abstract: Large Language Models (LLMs) remain vulnerable to adaptive jailbreaks that easily bypass empirical defenses like GCG. We propose a framework for certifiable robustness that shifts safety guarantees from single-pass inference to the statistical stability of an ensemble. We introduce Certified Semantic Smoothing (CSS) via Stratified Randomized Ablation, a technique that partitions inputs into immutable structural prompts and mutable payloads to derive rigorous lo norm guarantees using the Hypergeometric distribution. To resolve performance degradation on sparse contexts, we employ Noise-Augmented Alignment Tuning (NAAT), which transforms the base model into a semantic denoiser. Extensive experiments on Llama-3 show that our method reduces the Attack Success Rate of gradient-based attacks from 84.2% to 1.2% while maintaining 94.1% benign utility, significantly outperforming character-level baselines which degrade utility to 74.3%. This framework provides a deterministic certificate of safety, ensuring that a model remains robust against all adversarial variants within a provable radius.

</details>


### [530] [Wiki Live Challenge: Challenging Deep Research Agents with Expert-Level Wikipedia Articles](https://arxiv.org/abs/2602.01590)
*Shaohan Wang,Benfeng Xu,Licheng Zhang,Mingxuan Du,Chiwei Zhu,Xiaorui Wang,Zhendong Mao,Yongdong Zhang*

Main category: cs.CL

TL;DR: 本文提出了Wiki Live Challenge (WLC)基准和Wiki Eval评估框架，使用最新的维基百科优良文章（GAs）作为专家级参考，以更可靠、细粒度地评估深度研究代理（DRAs）在信息检索和报告生成方面的能力，并通过实验证明了当前DRAs与人类专家水平存在差距。


<details>
  <summary>Details</summary>
Motivation: 现有DRAs的评估框架依赖于LLM生成的引用或LLM衍生的评估维度，这些方法在可靠性和客观性方面存在不足，无法提供细粒度的关键维度评估。作者希望通过引入专家验证的高质量内容来弥补这一差距。

Method: 作者引入了一个名为Wiki Live Challenge (WLC) 的实时基准，并构建了一个包含100篇最新维基百科优良文章的数据集。在此基础上，他们提出了Wiki Eval评估框架，该框架包含一个具有39个标准的细粒度写作质量评估方法，以及严格的事实可核查性指标。

Result: 在对各种DRA系统进行的广泛实验中，结果显示当前DRAs与人类专家级别的维基百科文章之间存在显著差距，证明了WLC在推动代理研究方面的有效性。

Conclusion: Wiki Live Challenge (WLC)是一个利用维基百科优良文章作为专家级参考的实时基准，它能够提供比现有方法更可靠、细粒度的评估，并有效揭示了当前DRAs在信息检索和报告生成方面与专家水平的差距，为未来的DRAs研究提供了挑战和方向。

Abstract: Deep Research Agents (DRAs) have demonstrated remarkable capabilities in autonomous information retrieval and report generation, showing great potential to assist humans in complex research tasks. Current evaluation frameworks primarily rely on LLM-generated references or LLM-derived evaluation dimensions. While these approaches offer scalability, they often lack the reliability of expert-verified content and struggle to provide objective, fine-grained assessments of critical dimensions. To bridge this gap, we introduce Wiki Live Challenge (WLC), a live benchmark that leverages the newest Wikipedia Good Articles (GAs) as expert-level references. Wikipedia's strict standards for neutrality, comprehensiveness, and verifiability serve as a great challenge for DRAs, with GAs representing the pinnacle of which. We curate a dataset of 100 recent Good Articles and propose Wiki Eval, a comprehensive evaluation framework comprising a fine-grained evaluation method with 39 criteria for writing quality and rigorous metrics for factual verifiability. Extensive experiments on various DRA systems demonstrate a significant gap between current DRAs and human expert-level Wikipedia articles, validating the effectiveness of WLC in advancing agent research. We release our benchmark at https://github.com/WangShao2000/Wiki_Live_Challenge

</details>


### [531] [The Art of Socratic Inquiry: A Framework for Proactive Template-Guided Therapeutic Conversation Generation](https://arxiv.org/abs/2602.01598)
*Mingwen Zhang,Minqiang Yang,Changsheng Ma,Yang Yu,Hui Bai,Chen Xu,Xiangzhen Kong,Bin Hu*

Main category: cs.CL

TL;DR: 本文提出了Socratic Inquiry Framework (SIF)和Socratic-QA数据集，以解决当前大型语言模型（LLMs）在认知行为疗法（CBT）中缺乏主动引导能力的问题。SIF通过分离“何时提问”和“提问什么”，使LLMs能够进行有目的、有理论依据的主动提问，而Socratic-QA数据集则提供了监督信号。实验证明SIF能显著提升主动提问、对话深度和治疗对齐度。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在心理治疗中主要表现出被动和反应式的行为，未能有效引导用户深入探索潜在信念或促进行为改变，这与CBT中主动引导的原则相悖。

Method: 提出Socratic Inquiry Framework (SIF)，一个解耦“何时提问”（通过Strategy Anchoring）和“提问什么”（通过Template Retrieval）的治疗意图规划器。同时，引入Socratic-QA数据集，用于对模型的主动推理能力进行监督。

Result: SIF显著提高了主动提问的频率、对话的深度以及与治疗目标的一致性，实现了从被动安慰到主动探索的转变。

Conclusion: SIF为构建具有心理学洞察力的大型语言模型开辟了新途径，使模型能够不仅作出反应，更能主动引导用户进行心理探索和改变。

Abstract: Proactive questioning, where therapists deliberately initiate structured, cognition-guiding inquiries, is a cornerstone of cognitive behavioral therapy (CBT). Yet, current psychological large language models (LLMs) remain overwhelmingly reactive, defaulting to empathetic but superficial responses that fail to surface latent beliefs or guide behavioral change. To bridge this gap, we propose the \textbf{Socratic Inquiry Framework (SIF)}, a lightweight, plug-and-play therapeutic intent planner that transforms LLMs from passive listeners into active cognitive guides. SIF decouples \textbf{when to ask} (via Strategy Anchoring) from \textbf{what to ask} (via Template Retrieval), enabling context-aware, theory-grounded questioning without end-to-end retraining. Complementing SIF, we introduce \textbf{Socratic-QA}, a high-quality dataset of strategy-aligned Socratic sequences that provides explicit supervision for proactive reasoning. Experiments show that SIF significantly enhances proactive questioning frequency, conversational depth, and therapeutic alignment, marking a clear shift from reactive comfort to proactive exploration. Our work establishes a new paradigm for psychologically informed LLMs: not just to respond, but to guide.

</details>


### [532] [SEA-Guard: Culturally Grounded Multilingual Safeguard for Southeast Asia](https://arxiv.org/abs/2602.01618)
*Panuthep Tasawong,Jian Gang Ngui,Alham Fikri Aji,Trevor Cohn,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: 本文提出了SEA-Guard，一个为东南亚（SEA）量身定制的多语言AI安全模型，通过一个新颖的代理数据生成框架创建了区域特定安全数据集，并在检测区域敏感或有害内容方面表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的AI对齐需要文化意识，但缺乏大规模、文化相关的安全数据集，尤其是在资源有限且本语种标注者稀缺的东南亚地区。现有模型常依赖机翻的英语数据集，忽略了区域和文化特异性。

Method: 开发了一个新颖的代理（agentic）数据生成框架，用于大规模创建真实的、区域特定的东南亚安全数据集。基于此数据集，构建了SEA-Guard系列多语言安全模型。

Result: SEA-Guard在多个基准和文化变体上进行了评估，显示其在检测区域敏感或有害内容方面持续优于现有模型，同时保持了良好的通用安全性能。

Conclusion: SEA-Guard系列模型是首批基于东南亚文化背景的多语言安全模型，通过创新的数据生成方法，有效解决了区域文化差异带来的AI安全挑战，并在实践中展现出优越的性能。

Abstract: Culturally aware safeguards are crucial for AI alignment in real-world settings, where safety extends beyond common sense and encompasses diverse local values, norms, and region-specific regulations. However, building large-scale, culturally grounded datasets is challenging due to limited resources and a scarcity of native annotators. Consequently, many safeguard models rely on machine translation of English datasets, often missing regional and cultural nuances. We present a novel agentic data-generation framework to scalably create authentic, region-specific safety datasets for Southeast Asia (SEA). On this foundation, we introduce the SEA-Guard family, the first multilingual safeguard models grounded in SEA cultural contexts. Evaluated across multiple benchmarks and cultural variants, SEA-Guard consistently outperforms existing safeguards at detecting regionally sensitive or harmful content while maintaining strong general safety performance.

</details>


### [533] [PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length](https://arxiv.org/abs/2602.01274)
*Situo Zhang,Yifan Zhang,Zichen Zhu,Hankun Wang,Da Ma,Danyang Zhang,Lu Chen,Kai Yu*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Pacer 的新方法，用于动态调整猜测解码（SD）中草稿模型的生成长度，以提高推理速度，同时保持准确性。Pacer 使用一个轻量级的预验证层来块状地预验证草稿令牌，如果验证失败，则停止生成，从而在不同解码步骤中实现了比标准 SD 更快的速度。


<details>
  <summary>Details</summary>
Motivation: 现有的猜测解码（SD）方法使用固定长度的草稿令牌，但研究发现最优草稿长度在解码过程中变化很大，固定长度限制了加速的潜力。因此，研究者希望找到一种方法来动态调整草稿长度以提高效率。

Method: 提出 Pacer 方法，引入一个轻量级、可训练的预验证层。该层在将草稿令牌发送给目标模型之前，对草稿令牌进行块状预验证。如果预验证失败，草稿模型会停止生成，从而动态调整草稿长度。

Result: Pacer 在多个 SD 模型对和基准测试上进行了评估。结果显示，Pacer 比自回归解码实现了高达 2.66 倍的速度提升，并持续优于标准的猜测解码。与 Ouroboros 集成时，Pacer 实现了高达 3.09 倍的速度提升。

Conclusion: Pacer 是一种有效的动态草稿长度控制方法，能够显著提高猜测解码的推理速度，同时保持或提高准确性，并且在与其他优化技术结合时表现更佳。

Abstract: Speculative decoding (SD) is a powerful technique for accelerating the inference process of large language models (LLMs) without sacrificing accuracy. Typically, SD employs a small draft model to generate a fixed number of draft tokens, which are then verified in parallel by the target model. However, our experiments reveal that the optimal draft length varies significantly across different decoding steps. This variation suggests that using a fixed draft length limits the potential for further improvements in decoding speed. To address this challenge, we propose Pacer, a novel approach that dynamically controls draft length using a lightweight, trainable pre-verification layer. This layer pre-verifies draft tokens blockwise before they are sent to the target model, allowing the draft model to stop token generation if the blockwise pre-verification fails. We implement Pacer on multiple SD model pairs and evaluate its performance across various benchmarks. Our results demonstrate that Pacer achieves up to 2.66x Speedup over autoregressive decoding and consistently outperforms standard speculative decoding. Furthermore, when integrated with Ouroboros, Pacer attains up to 3.09x Speedup.

</details>


### [534] [A2Eval: Agentic and Automated Evaluation for Embodied Brain](https://arxiv.org/abs/2602.01640)
*Shuai Zhang,Jiayu Hu,Zijie Chen,Zeyuan Ding,Yi Zhang,Yingji Zhang,Ziyi Zhou,Junwei Liao,Shengjie Zhou,Yong Dai,Zhenzhong Lan,Xiaozhu Ju*

Main category: cs.CL

TL;DR: 提出了一种名为 A2Eval 的自主代理框架，用于自动生成和评估具身视觉语言模型 (VLM) 的基准测试。该框架通过两个协作代理（数据代理和评估代理）来解决现有基准测试的冗余、成本高昂和排名偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有具身 VLM 的评估方法依赖于静态、人工标注且冗余度高的基准测试，这消耗了大量计算和标注资源，增加了成本，并且可能导致模型排名失真，阻碍了模型的迭代开发。

Method: 提出 A2Eval，一个由两个协作代理组成的自主框架。数据代理负责自动识别能力维度并构建一个平衡、精简的评估套件。评估代理负责生成和验证可执行的评估流程。

Result: A2Eval 在 10 个基准测试和 13 个模型上进行了评估，结果显示：评估套件大小压缩了 85%，总计算成本降低了 77%，速度提升了 4.6 倍，同时保持了评估质量。该框架纠正了系统性的排名偏差，与人类评估的 Spearman's rho 达到 0.85，并保持了较高的排名保真度 (Kendall's tau=0.81)。

Conclusion: A2Eval 提供了一种高保真、低成本的具身模型评估新标准，通过自动化基准测试的生成和评估，克服了现有方法的局限性，提高了评估效率和准确性。

Abstract: Current embodied VLM evaluation relies on static, expert-defined, manually annotated benchmarks that exhibit severe redundancy and coverage imbalance. This labor intensive paradigm drains computational and annotation resources, inflates costs, and distorts model rankings, ultimately stifling iterative development. To address this, we propose Agentic Automatic Evaluation (A2Eval), the first agentic framework that automates benchmark curation and evaluation through two collaborative agents. The Data Agent autonomously induces capability dimensions and assembles a balanced, compact evaluation suite, while the Eval Agent synthesizes and validates executable evaluation pipelines, enabling fully autonomous, high-fidelity assessment. Evaluated across 10 benchmarks and 13 models, A2Eval compresses evaluation suites by 85%, reduces overall computational costs by 77%, and delivers a 4.6x speedup while preserving evaluation quality. Crucially, A2Eval corrects systematic ranking biases, improves human alignment to Spearman's rho=0.85, and maintains high ranking fidelity (Kendall's tau=0.81), establishing a new standard for high-fidelity, low-cost embodied assessment. Our code and data will be public soon.

</details>


### [535] [Steering Vector Fields for Context-Aware Inference-Time Control in Large Language Models](https://arxiv.org/abs/2602.01654)
*Jiaqian Li,Yanshu Li,Kuan-Hao Huang*

Main category: cs.CL

TL;DR: 本文提出了一种名为“方向向量场”（Steering Vector Fields, SVF）的新方法，用于解决现有“方向向量”（Steering Vectors, SVs）在控制大型语言模型（LLMs）时的不可靠问题，特别是在长文本生成和多属性控制方面。SVF通过学习一个可微分的概念评分函数，使其控制方向能够根据当前激活状态进行局部调整，从而实现更精确、更可靠的推断时控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法“方向向量”（SVs）在推断时控制LLMs的效率很高，但存在不可靠的问题，例如某些概念难以控制，以及在长文本生成和多属性控制时效果会下降。作者认为这是因为SVs采用静态的全局向量，未能考虑到不同上下文下概念“有效方向”的变化。

Method: 提出“方向向量场”（SVF）方法。SVF通过学习一个可微分的概念评分函数，该函数的局部梯度定义了在每个激活状态下的控制方向。这种方法使干预明确地依赖于上下文，支持在共享、对齐的概念空间中进行协调的多层干预，并实现了高效的长文本和多属性控制。

Result: 在多个LLMs和控制任务中，SVF比现有方法提供了更强、更可靠的控制。它提高了推断时控制的实用性。

Conclusion: SVF通过引入上下文依赖的控制方向，解决了静态方向向量的局限性，实现了更精确、更可靠的LLM推断时控制，尤其在长文本和多属性控制场景下效果显著，增强了推断时控制的实际应用价值。

Abstract: Steering vectors (SVs) offer a lightweight way to control large language models (LLMs) at inference time by shifting hidden activations, providing a practical middle ground between prompting and fine-tuning. Yet SVs can be unreliable in practice. Some concepts are unsteerable, and even when steering helps on average it can backfire for a non-trivial fraction of inputs. Reliability also degrades in long-form generation and multi-attribute steering. We take a geometric view of these failures. A static SV applies the same update vector everywhere in representation space, implicitly assuming that the concept-improving direction is constant across contexts. When the locally effective direction varies with the current activation, a single global vector can become misaligned, which yields weak or reversed effects. Guided by this perspective, we propose Steering Vector Fields (SVF), which learns a differentiable concept scoring function whose local gradient defines the steering direction at each activation, making interventions explicitly context-dependent. This formulation supports coordinated multi-layer interventions in a shared, aligned concept space, and enables efficient long-form and multi-attribute control within a unified framework. Across multiple LLMs and steering tasks, SVF delivers stronger and more reliable control, improving the practicality of inference-time steering.

</details>


### [536] [Scaling Search-Augmented LLM Reasoning via Adaptive Information Control](https://arxiv.org/abs/2602.01672)
*Siheng Xiong,Oguzhan Gungordu,Blair Johnson,James C. Kerce,Faramarz Fekri*

Main category: cs.CL

TL;DR: 本文提出了一种名为DeepControl的框架，用于自适应地控制搜索增强推理代理的信息检索，以解决现有方法中存在的冗余信息和学习不稳定的问题。通过引入信息效用度量，DeepControl能够智能地决定何时继续或停止检索，以及检索信息的粒度，从而提高推理效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的搜索增强推理代理在信息检索过程中存在冗余证据、上下文饱和和学习不稳定等问题，而基于结果的强化学习方法对信息获取的指导作用有限。

Method: 提出DeepControl框架，该框架基于信息效用度量，该度量衡量了在给定推理状态下检索证据的边际价值。在此基础上，引入检索续期和粒度控制机制，选择性地调节检索的开始和停止时机，以及检索信息的扩展程度。采用退火控制策略使代理在训练过程中内化有效的信息获取行为。

Result: 在七个基准测试中，DeepControl在Qwen2.5-7B和Qwen2.5-3B模型上的平均性能分别提高了9.4%和8.6%，显著优于强有力的基于结果的强化学习基线。同时，该方法在不进行显式信息控制的情况下，也持续优于无检索和有检索的推理方法。

Conclusion: 研究结果强调了自适应信息控制对于将搜索增强推理代理扩展到复杂、真实世界信息环境的重要性。

Abstract: Search-augmented reasoning agents interleave multi-step reasoning with external information retrieval, but uncontrolled retrieval often leads to redundant evidence, context saturation, and unstable learning. Existing approaches rely on outcome-based reinforcement learning (RL), which provides limited guidance for regulating information acquisition. We propose DeepControl, a framework for adaptive information control based on a formal notion of information utility, which measures the marginal value of retrieved evidence under a given reasoning state. Building on this utility, we introduce retrieval continuation and granularity control mechanisms that selectively regulate when to continue and stop retrieval, and how much information to expand. An annealed control strategy enables the agent to internalize effective information acquisition behaviors during training. Extensive experiments across seven benchmarks demonstrate that our method consistently outperforms strong baselines. In particular, our approach achieves average performance improvements of 9.4% and 8.6% on Qwen2.5-7B and Qwen2.5-3B, respectively, over strong outcome-based RL baselines, and consistently outperforms both retrieval-free and retrieval-based reasoning methods without explicit information control. These results highlight the importance of adaptive information control for scaling search-augmented reasoning agents to complex, real-world information environments.

</details>


### [537] [Counting Hypothesis: Potential Mechanism of In-Context Learning](https://arxiv.org/abs/2602.01687)
*Jung H. Lee,Sujith Vijayan*

Main category: cs.CL

TL;DR: 本文提出了“计数假说”，认为大型语言模型（LLM）的编码策略可能是其上下文学习（ICL）能力的基础，并提供了支持性证据，旨在增进对ICL机制的理解，以应对其在错误纠正和诊断方面的挑战。


<details>
  <summary>Details</summary>
Motivation: ICL（上下文学习）在无需修改LLM内部结构即可执行多种任务方面表现出色，但其内在机制仍不清楚，这使得错误纠正和诊断变得困难。因此，有必要深入理解ICL的局限性以及LLM如何支持ICL。

Method: 受到ICL特性和LLM功能模块的启发，研究者提出了“计数假说”，并提供证据来支持LLM的编码策略可能构成ICL的基础。

Result: 研究者提出了“计数假说”，并提供了证据支持该假说，表明LLM的编码策略可能在ICL中起着关键作用。

Conclusion: 该研究提出了“计数假说”来解释ICL的潜在机制，认为LLM的编码策略是ICL能力的基础，这为理解ICL的局限性和改进LLM在ICL任务中的表现提供了新的视角。

Abstract: In-Context Learning (ICL) indicates that large language models (LLMs) pretrained on a massive amount of data can learn specific tasks from input prompts' examples. ICL is notable for two reasons. First, it does not need modification of LLMs' internal structure. Second, it enables LLMs to perform a wide range of tasks/functions with a few examples demonstrating a desirable task. ICL opens up new ways to utilize LLMs in more domains, but its underlying mechanisms still remain poorly understood, making error correction and diagnosis extremely challenging. Thus, it is imperative that we better understand the limitations of ICL and how exactly LLMs support ICL. Inspired by ICL properties and LLMs' functional modules, we propose 1the counting hypothesis' of ICL, which suggests that LLMs' encoding strategy may underlie ICL, and provide supporting evidence.

</details>


### [538] [Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models](https://arxiv.org/abs/2602.01698)
*Wenhui Tan,Fiorenzo Parascandolo,Enver Sangineto,Jianzhong Ju,Zhenbo Luo,Qian Cao,Rita Cucchiara,Ruihua Song,Jian Luan*

Main category: cs.CL

TL;DR: 研究表明，大型推理模型（LRM）通过强化学习（RL）进行后训练会产生意料之外的探索崩溃，导致温度采样失效。为此，本文提出了一种名为“潜层探索解码”（LED）的深度条件解码策略，通过聚合中间层后验概率并选择熵最大的深度配置来缓解此问题，在多项推理基准和模型上取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 在LRM通过RL后训练实现强大的数学和代码推理能力的同时，研究人员发现这种后训练会引入一个非预期的“探索崩溃”现象，即基于温度的采样不再能提升pass@n的准确率。这促使了本研究的动机。

Method: 提出了一种名为“潜层探索解码”（LED）的深度条件解码策略。LED通过累加（cumulative sum）的方式聚合中间层的后验概率，并选择具有最大熵的深度配置作为探索候选。该方法无需额外的训练或参数。

Result: LED策略在多个推理基准和模型上，一致地将pass@1和pass@16的准确率分别提升了0.61和1.03个百分点。同时，该方法不引入额外的训练或参数。

Conclusion: LED是一种有效的深度条件解码策略，能够通过聚合中间层后验概率并选择高熵深度配置来解决RL后训练导致的探索崩溃问题，从而提升LRMs在数学和代码推理任务上的性能，且无需额外训练。

Abstract: Large Reasoning Models (LRMs) have recently achieved strong mathematical and code reasoning performance through Reinforcement Learning (RL) post-training. However, we show that modern reasoning post-training induces an unintended exploration collapse: temperature-based sampling no longer increases pass@$n$ accuracy. Empirically, the final-layer posterior of post-trained LRMs exhibit sharply reduced entropy, while the entropy of intermediate layers remains relatively high. Motivated by this entropy asymmetry, we propose Latent Exploration Decoding (LED), a depth-conditioned decoding strategy. LED aggregates intermediate posteriors via cumulative sum and selects depth configurations with maximal entropy as exploration candidates. Without additional training or parameters, LED consistently improves pass@1 and pass@16 accuracy by 0.61 and 1.03 percentage points across multiple reasoning benchmarks and models. Project page: https://GitHub.com/Xiaomi-Research/LED.

</details>


### [539] [Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory](https://arxiv.org/abs/2602.01708)
*Langyuan Cui,Chun Kai Ling,Hwee Tou Ng*

Main category: cs.CL

TL;DR: 本文提出了一种名为Game of Thought (GoT)的框架，利用博弈论技术来提高大型语言模型（LLM）在信息不足情况下的主动信息搜寻能力，并在二十问游戏及其对抗性变体（SLS问题）中验证了其有效性，显著提升了最坏情况下的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中，大型语言模型（LLM）常面临信息不足的情况，主动搜寻缺失信息的能力至关重要。现有方法常基于简化假设，导致最坏情况下的性能下降，这在高风险应用中是不容忽视的问题。

Method: 本文将LLM的信息搜寻能力建模为二十问游戏及其对抗性变体——战略语言搜索（SLS）问题，并将其形式化为两人零和扩展型博弈。在此基础上，提出了Game of Thought (GoT)框架，应用博弈论技术来近似求解受限SLS问题的纳什均衡（NE）策略。

Result: 实验结果表明，与直接提示方法和启发式引导搜索方法相比，GoT框架在所有测试场景下都能持续改善LLM的最坏情况性能。

Conclusion: Game of Thought (GoT)框架通过应用博弈论技术，能够有效提升LLM在信息不足场景下的主动信息搜寻能力，尤其是在最坏情况下的性能表现优于现有方法。

Abstract: Large Language Models (LLMs) are increasingly deployed in real-world scenarios where they may lack sufficient information to complete a given task. In such settings, the ability to actively seek out missing information becomes a critical capability. Existing approaches to enhancing this ability often rely on simplifying assumptions that degrade \textit{worst-case} performance. This is an issue with serious implications in high-stakes applications. In this work, we use the game of Twenty Questions to evaluate the information-seeking ability of LLMs. We introduce and formalize its adversarial counterpart, the Strategic Language Search (SLS) problem along with its variants as a two-player zero-sum extensive form game. We propose Game of Thought (GoT), a framework that applies game-theoretic techniques to approximate a Nash equilibrium (NE) strategy for the restricted variant of the game. Empirical results demonstrate that our approach consistently improves worst-case performance compared to (1) direct prompting-based methods and (2) heuristic-guided search methods across all tested settings.

</details>


### [540] [ARTIS: Agentic Risk-Aware Test-Time Scaling via Iterative Simulation](https://arxiv.org/abs/2602.01709)
*Xingshan Zeng,Lingzhi Wang,Weiwen Liu,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Qun Liu*

Main category: cs.CL

TL;DR: 提出了一种名为 ARTI 的代理风险感知测试时缩放框架，通过迭代模拟来提高 LLM 在与环境交互时的可靠性和鲁棒性，并引入风险感知工具模拟器来解决模拟器捕获高影响失败模式的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时缩放技术不足以应对代理环境中不可逆且代价高昂的交互，需要一种方法来提高代理在实际执行前的动作可靠性和鲁棒性，同时避免环境风险。

Method: 提出 ARTI 框架，将探索与承诺解耦，通过在实际执行前进行模拟交互来实现测试时探索。引入风险感知工具模拟器，通过定向数据生成和再平衡训练来提高对导致失败的动作的保真度。

Result: 多轮和多步代理基准测试表明，迭代模拟显著提高了代理的可靠性，而风险感知模拟对于跨模型和任务一致地实现这些收益至关重要。

Conclusion: ARTI 框架通过迭代模拟和风险感知工具模拟器，能够有效提高 LLM 在代理环境中的决策可靠性和鲁棒性，克服了现有方法的局限性。

Abstract: Current test-time scaling (TTS) techniques enhance large language model (LLM) performance by allocating additional computation at inference time, yet they remain insufficient for agentic settings, where actions directly interact with external environments and their effects can be irreversible and costly. We propose \emph{\name}, \emph{\underline{A}gentic \underline{R}isk-Aware \underline{T}est-Time Scaling via \underline{I}terative \underline{S}imulation}, a framework that decouples exploration from commitment by enabling test-time exploration through simulated interactions prior to real-world execution. This design allows extending inference-time computation to improve action-level reliability and robustness without incurring environmental risk. We further show that naive LLM-based simulators struggle to capture rare but high-impact failure modes, substantially limiting their effectiveness for agentic decision making. To address this limitation, we introduce a \emph{risk-aware tool simulator} that emphasizes fidelity on failure-inducing actions via targeted data generation and rebalanced training. Experiments on multi-turn and multi-step agentic benchmarks demonstrate that iterative simulation substantially improves agent reliability, and that risk-aware simulation is essential for consistently realizing these gains across models and tasks.

</details>


### [541] [MedAraBench: Large-Scale Arabic Medical Question Answering Dataset and Benchmark](https://arxiv.org/abs/2602.01714)
*Mouath Abu-Daoud,Leen Kharouf,Omar El Hajj,Dana El Samad,Mariam Al-Omari,Jihad Mallat,Khaled Saleh,Nizar Habash,Farah E. Shamout*

Main category: cs.CL

TL;DR: 本文介绍了MedAraBench，一个包含医学专业的多项选择题及答案的大规模阿拉伯语数据集，旨在解决阿拉伯语在医疗NLP领域资源匮乏的问题，并评估了八种大型语言模型的表现，强调了领域特定增强的必要性。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语在自然语言处理（NLP）研究中，尤其是在医疗应用方面，由于开放数据和基准的缺乏而代表性不足，阻碍了对大型语言模型（LLMs）多语言能力的评估和发展。

Method: 通过手动数字化阿拉伯语地区医学专业人士创建的大量学术材料，构建了一个包含医学专业多项选择题-答案对的大规模阿拉伯语数据集MedAraBench。数据集经过预处理并划分为训练集和测试集。使用专家人工评估和LLM-as-a-judge两种框架评估数据质量。对八种最先进的开源和专有模型（如GPT-5、Gemini 2.0 Flash和Claude 4-Sonnet）进行了基准测试。

Result: MedAraBench数据集包含19个专业和5个难度级别，质量多样且高。八种评估模型在数据集上的表现表明，在阿拉伯语医疗领域，LLMs仍需要进一步的领域特定改进。

Conclusion: MedAraBench数据集的发布旨在增加医疗数据基准的多样性，扩展LLMs的评估范围，并提高模型在临床环境中部署的多语言能力。研究结果表明，目前LLMs在阿拉伯语医疗领域的表现仍有提升空间，需要进一步的领域特定优化。

Abstract: Arabic remains one of the most underrepresented languages in natural language processing research, particularly in medical applications, due to the limited availability of open-source data and benchmarks. The lack of resources hinders efforts to evaluate and advance the multilingual capabilities of Large Language Models (LLMs). In this paper, we introduce MedAraBench, a large-scale dataset consisting of Arabic multiple-choice question-answer pairs across various medical specialties. We constructed the dataset by manually digitizing a large repository of academic materials created by medical professionals in the Arabic-speaking region. We then conducted extensive preprocessing and split the dataset into training and test sets to support future research efforts in the area. To assess the quality of the data, we adopted two frameworks, namely expert human evaluation and LLM-as-a-judge. Our dataset is diverse and of high quality, spanning 19 specialties and five difficulty levels. For benchmarking purposes, we assessed the performance of eight state-of-the-art open-source and proprietary models, such as GPT-5, Gemini 2.0 Flash, and Claude 4-Sonnet. Our findings highlight the need for further domain-specific enhancements. We release the dataset and evaluation scripts to broaden the diversity of medical data benchmarks, expand the scope of evaluation suites for LLMs, and enhance the multilingual capabilities of models for deployment in clinical settings.

</details>


### [542] [Mechanistic Indicators of Steering Effectiveness in Large Language Models](https://arxiv.org/abs/2602.01716)
*Mehdi Jafari,Hao Xue,Flora Salim*

Main category: cs.CL

TL;DR: 本研究提出使用信息论度量（归一化分支因子NBF和KL散度）来诊断和预测大型语言模型（LLM）激活引导的成功与否，无需重新训练模型，并为两种主流激活引导方法（CAA和基于稀疏自编码器的方法）建立了更强的评估基线。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）激活引导技术在解释其成功或失败的机制方面仍存在不足，过去的研究主要依赖黑盒输出或LLM判断，缺乏对模型内部信号的深入分析。

Method: 研究者聚焦于两种信息论度量：基于熵的归一化分支因子（NBF）和引导激活与词汇空间中目标概念之间的KL散度。他们假设有效的引导对应于结构化的熵保持和跨解码步骤的一致性KL对齐。利用LLM生成的标注作为真实标签，通过两个架构不同的LLM进行可靠性评估，并引入了对比激活加法（CAA）和基于稀疏自编码器的引导方法的更强评估基线。

Result: 研究结果表明，所提出的信息论信号（NBF和KL散度）能够有效地预测激活引导的成功性，并估计失败的概率。研究还表明，不同架构的LLM在判断引导可靠性上具有较高的一致性。

Conclusion: 信息论度量（NBF和KL散度）可以作为诊断LLM激活引导效果的有效工具，能够提供对引导成功与失败的有意义的预测能力，为激活引导方法的评估提供了新的视角和更强的基线。

Abstract: Activation-based steering enables Large Language Models (LLMs) to exhibit targeted behaviors by intervening on intermediate activations without retraining. Despite its widespread use, the mechanistic factors that govern when steering succeeds or fails remain poorly understood, as prior work has relied primarily on black-box outputs or LLM-based judges. In this study, we investigate whether the reliability of steering can be diagnosed using internal model signals. We focus on two information-theoretic measures: the entropy-derived Normalized Branching Factor (NBF), and the Kullback-Leibler (KL) divergence between steered activations and targeted concepts in the vocabulary space. We hypothesize that effective steering corresponds to structured entropy preservation and coherent KL alignment across decoding steps. Building on a reliability study demonstrating high inter-judge agreement between two architecturally distinct LLMs, we use LLM-generated annotations as ground truth and show that these mechanistic signals provide meaningful predictive power for identifying successful steering and estimating failure probability. We further introduce a stronger evaluation baseline for Contrastive Activation Addition (CAA) and Sparse Autoencoder-based steering, the two most widely adopted activation-steering methods.

</details>


### [543] [BBPE16: UTF-16-based byte-level byte-pair encoding for improved multilingual speech recognition](https://arxiv.org/abs/2602.01717)
*Hyunsik Kim,Haeri Kim,Munhak Lee,Kyungmin Lee*

Main category: cs.CL

TL;DR: 提出了一种基于 UTF-16 的 BBPE16 分词器，用于多语言自动语音识别（ASR），它能更有效地处理非拉丁语系（如 CJK 语系）的文本，减少了 token 数量和解码迭代次数，从而提高了效率并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 UTF-8 的字节级 BPE（BBPE）在处理中文、日文、韩文等非拉丁语系时，由于 UTF-8 的变长编码，会导致 token 序列过长，增加了计算负荷和内存使用。因此需要一种更高效的多语言分词方法。

Method: 提出了一种基于 UTF-16 的 BBPE16 分词器。UTF-16 的大部分现代字符使用固定的 2 字节编码单元，这有助于统一表示大多数字符，同时保留了 BBPE 的语言无关性，并提高了跨语言 token 的共享能力。

Result: 在单语、双语、三语 ASR 以及多语言持续学习设置中，BBPE16 取得了相当或更好的准确率。对于中文，token 数量减少了高达 10.4%，解码迭代次数减少了高达 10.3%。

Conclusion: BBPE16 是一种实用的多语言 ASR 分词选择，它在保持准确率的同时，显著减少了 token 数量和计算成本，从而加快了微调和推理速度，并降低了内存使用。

Abstract: Multilingual automatic speech recognition (ASR) requires tokenization that efficiently covers many writing systems. Byte-level BPE (BBPE) using UTF-8 is widely adopted for its language-agnostic design and full Unicode coverage, but its variable-length encoding inflates token sequences for non-Latin scripts, such as Chinese, Japanese, and Korean (CJK). Longer sequences increase computational load and memory use. We propose BBPE16, a UTF-16-based BBPE tokenizer that represents most modern scripts with a uniform 2-byte code unit. BBPE16 preserves BBPE's language-agnostic properties while substantially improving cross-lingual token sharing. Across monolingual, bilingual, and trilingual ASR, and in a multilingual continual-learning setup, BBPE16 attains comparable or better accuracy; for Chinese, it reduces token counts by up to 10.4% and lowers decoding iterations by up to 10.3%. These reductions speed up fine-tuning and inference and decrease memory usage, making BBPE16 a practical tokenization choice for multilingual ASR.

</details>


### [544] [COMI: Coarse-to-fine Context Compression via Marginal Information Gain](https://arxiv.org/abs/2602.01719)
*Jiwei Tang,Shilei Liu,Zhicheng Zhang,Yujin Yuan,Libin Zheng,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 本文提出了一种名为COMI的粗粒度到细粒度自适应上下文压缩框架，通过引入边际信息增益（MIG）度量，在保持语义相关性和多样性的同时，有效解决了长文本场景下LLM的计算效率和信息冗余问题，并在多项下游任务上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在长上下文场景下的部署受限于计算效率低下和信息冗余问题。因此，需要一种有效的上下文压缩方法来降低输入长度并消除冗余。

Method: 提出COMI框架，一个粗粒度到细粒度的自适应上下文压缩框架。该框架引入了边际信息增益（MIG）度量，即单位信息对查询的_相关性_减去其与其他单位的_语义冗余度_。框架包含两个阶段：1. 粗粒度分组重新分配：根据组间MIG动态分配压缩率；2. 细粒度Token融合：基于组内MIG加权机制融合Token。

Result: 在问答（NaturalQuestions, 2WikiMQA, HotpotQA, NarrativeQA）和摘要（MultiNews）任务上，使用LLaMA-2-7B和Qwen2-7B等模型进行的大量实验表明，COMI相较于现有基线方法有显著优势。例如，在32倍压缩率下，COMI在NaturalQuestions任务上使用Qwen2-7B取得了约25个Exact Match（EM）点的提升。

Conclusion: COMI框架能够有效地进行上下文压缩，在保证语义相关性和多样性的前提下，显著提高了LLM在长上下文任务上的性能，克服了计算效率和信息冗余的挑战。

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities across diverse tasks. However, their deployment in long context scenarios remains hindered by computational inefficiency and information redundancy. Context compression methods address these challenges by significantly reducing input length and eliminating redundancy. We propose COMI, a coarse-to-fine adaptive context compression framework that jointly optimizes for semantic relevance and diversity under high compression rates. We introduce Marginal Information Gain (MIG), a metric defined as the relevance of a unit to the input query minus its semantic redundancy with other units, guiding the compression process to prioritize information that is both relevant and low redundant. The framework operates in two stages: (1) Coarse-Grained Group Reallocation, where the context is partitioned into groups and dynamically assigned compression rates based on inter-group MIG, ensuring compression budgets align with information value distribution; and (2) Fine-Grained Token Merging, where tokens within each group are fused via an intra-group MIG-based weighting mechanism, thereby preserving key semantics while avoiding the accumulation of redundancy. Extensive experiments across question-answering (e.g., NaturalQuestions, 2WikiMQA, HotpotQA and NarrativeQA), summarization (e.g., MultiNews) with various backbones (e.g., LLaMA-2-7B, Qwen2-7B) show that COMI outperforms existing baselines by a large margin, e.g., approximately 25-point Exact Match (EM) improvement under 32x compression constraint with Qwen2-7B on NaturalQuestions.

</details>


### [545] [SafePred: A Predictive Guardrail for Computer-Using Agents via World Models](https://arxiv.org/abs/2602.01725)
*Yurun Chen,Zeyi Liao,Ping Yin,Taotao Xie,Keting Yin,Shengyu Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为SafePred的预测性安全框架，用于解决计算机代理（CUAs）在现实世界中部署时面临的长期风险问题，通过预测和对齐未来风险与当前决策来确保代理的安全行为。


<details>
  <summary>Details</summary>
Motivation: 现有针对CUAs的保护机制多为被动式，只能在当前观察空间内约束行为，无法有效预防因当前看似合理的操作而导致的、延迟出现的严重长期风险。例如，清理日志可能导致未来审计追踪困难。

Method: SafePred框架的核心思想是将预测的未来风险与当前决策对齐。它通过一个风险-决策循环来实现代理的安全行为。SafePred具备两项关键能力：（1）短长期风险预测：基于安全策略，利用世界模型生成风险的语义表示，从而识别和剔除可能导致高风险状态的行为。（2）决策优化：将预测风险转化为可操作的安全决策指导，通过步进式干预和任务级重新规划。

Result: 实验结果表明，SafePred显著减少了高风险行为，安全性能超过97.6%，与被动式基线方法相比，任务效用提高了高达21.4%。

Conclusion: SafePred通过预测性安全框架，有效解决了CUAs在复杂环境中可能面临的长期风险问题，实现了代理行为的安全性和任务效用的提升。

Abstract: With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining agent behavior only within the current observation space. While these guardrails can prevent immediate short-term risks (e.g., clicking on a phishing link), they cannot proactively avoid long-term risks: seemingly reasonable actions can lead to high-risk consequences that emerge with a delay (e.g., cleaning logs leads to future audits being untraceable), which reactive guardrails cannot identify within the current observation space. To address these limitations, we propose a predictive guardrail approach, with the core idea of aligning predicted future risks with current decisions. Based on this approach, we present SafePred, a predictive guardrail framework for CUAs that establishes a risk-to-decision loop to ensure safe agent behavior. SafePred supports two key abilities: (1) Short- and long-term risk prediction: by using safety policies as the basis for risk prediction, SafePred leverages the prediction capability of the world model to generate semantic representations of both short-term and long-term risks, thereby identifying and pruning actions that lead to high-risk states; (2) Decision optimization: translating predicted risks into actionable safe decision guidances through step-level interventions and task-level re-planning. Extensive experiments show that SafePred significantly reduces high-risk behaviors, achieving over 97.6% safety performance and improving task utility by up to 21.4% compared with reactive baselines.

</details>


### [546] [Enhancing Automated Essay Scoring with Three Techniques: Two-Stage Fine-Tuning, Score Alignment, and Self-Training](https://arxiv.org/abs/2602.01747)
*Hongseok Choi,Serynn Kim,Wencke Liermann,Jin Seong,Jin-Xia Huang*

Main category: cs.CL

TL;DR: 本文提出了一种改进自动化论文评分（AES）系统性能的新方法，通过双阶段微调、分数对齐和不确定性感知自训练技术，即使在数据稀缺的情况下也能显著提升评分准确性，并取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中自动化论文评分（AES）系统存在数据稀缺问题，严重限制了其鲁棒性和实际应用。

Method: 提出了一种结合双阶段微调（利用低秩适配）、分数对齐和不确定性感知自训练（利用无标签数据）的新方法，并将其应用于DualBERT模型。

Result: 在ASAP++数据集的32-data设置下，所提出的三种技术均能提升性能，并且集成后能达到全数据训练性能的91.2%。分数对齐技术在有限和全数据设置下均能提升性能，并在全数据设置下结合DualBERT达到了最先进的水平。

Conclusion: 该研究提出了一种有效的方法来应对AES系统中的数据稀缺问题，通过结合多种技术显著提高了评分性能，并在全数据设置下取得了当前最优结果。

Abstract: Automated Essay Scoring (AES) plays a crucial role in education by providing scalable and efficient assessment tools. However, in real-world settings, the extreme scarcity of labeled data severely limits the development and practical adoption of robust AES systems. This study proposes a novel approach to enhance AES performance in both limited-data and full-data settings by introducing three key techniques. First, we introduce a Two-Stage fine-tuning strategy that leverages low-rank adaptations to better adapt an AES model to target prompt essays. Second, we introduce a Score Alignment technique to improve consistency between predicted and true score distributions. Third, we employ uncertainty-aware self-training using unlabeled data, effectively expanding the training set with pseudo-labeled samples while mitigating label noise propagation. We implement above three key techniques on DualBERT. We conduct extensive experiments on the ASAP++ dataset. As a result, in the 32-data setting, all three key techniques improve performance, and their integration achieves 91.2% of the full-data performance trained on approximately 1,000 labeled samples. In addition, the proposed Score Alignment technique consistently improves performance in both limited-data and full-data settings: e.g., it achieves state-of-the-art results in the full-data setting when integrated into DualBERT.

</details>


### [547] [WorldCup Sampling for Multi-bit LLM Watermarking](https://arxiv.org/abs/2602.01752)
*Yidan Wang,Yubing Ren,Yanan Cao,Li Guo*

Main category: cs.CL

TL;DR: 提出了一种名为 WorldCup 的多比特水印框架，用于大型语言模型（LLMs），通过直接将信息比特嵌入到 token 选择中，提高了信息容量、检测性和鲁棒性，同时保持了生成文本的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的零比特水印方法在多比特水印方面存在信息流间接、容量有限和解码效果不佳等问题，促使研究者寻求更有效的多比特水印方案。

Method: WorldCup 将采样视为通信信道，通过分层竞争机制和互补信号直接将消息比特嵌入到 token 选择中。此外，还采用了熵感知调制来保证生成质量，并通过置信度感知解码来实现鲁棒的消息恢复。

Result: WorldCup 在容量、可检测性、鲁棒性、文本质量和解码效率方面取得了良好的平衡，并且在实验中持续优于现有方法。

Conclusion: WorldCup 是一个高效的多比特水印框架，为未来 LLM 水印研究奠定了基础，能够实现可靠的文本溯源。

Abstract: As large language models (LLMs) generate increasingly human-like text, watermarking offers a promising solution for reliable attribution beyond mere detection. While multi-bit watermarking enables richer provenance encoding, existing methods largely extend zero-bit schemes through seed-driven steering, leading to indirect information flow, limited effective capacity, and suboptimal decoding. In this paper, we propose WorldCup, a multi-bit watermarking framework for LLMs that treats sampling as a natural communication channel and embeds message bits directly into token selection via a hierarchical competition mechanism guided by complementary signals. Moreover, WorldCup further adopts entropy-aware modulation to preserve generation quality and supports robust message recovery through confidence-aware decoding. Comprehensive experiments show that WorldCup achieves a strong balance across capacity, detectability, robustness, text quality, and decoding efficiency, consistently outperforming prior baselines and laying a solid foundation for future LLM watermarking studies.

</details>


### [548] [Zero2Text: Zero-Training Cross-Domain Inversion Attacks on Textual Embeddings](https://arxiv.org/abs/2602.01757)
*Doohyun Kim,Donghwa Kang,Kyungjae Lee,Hyeongboo Baek,Brent Byunghoon Kang*

Main category: cs.CL

TL;DR: 本文提出了一种名为Zero2Text的训练无关的框架，用于解决向量数据库中由于嵌入逆转攻击而产生的隐私风险。该框架通过递归在线对齐，利用大型语言模型的先验知识和动态岭回归机制，实时调整生成内容以匹配目标嵌入，有效避免了现有方法的计算或数据依赖性限制。


<details>
  <summary>Details</summary>
Motivation: 现有的嵌入逆转攻击防御方法存在局限性：基于优化的方法计算成本高昂，而基于对齐的方法需要假设可访问的同域训练数据。这使得它们在严格的黑盒和跨域场景下无效。因此，需要一种新的方法来解决这些限制。

Method: Zero2Text是一种训练无关的框架，基于递归在线对齐。它利用大型语言模型的先验知识，并结合动态岭回归机制，迭代地将生成内容与目标嵌入进行对齐。它是一种即时（on-the-fly）的对齐方式，无需静态数据集。

Result: Zero2Text在MS MARCO基准上，针对OpenAI模型，取得了比基线方法高1.8倍的ROUGE-L和6.4倍的BLEU-2分数。该方法能够在未知域中恢复句子，且无需任何已泄露的数据对。此外，研究还表明，标准的差分隐私等防御措施对这种自适应威胁效果不佳。

Conclusion: Zero2Text成功地解决了现有嵌入逆转攻击防御方法的局限性，提供了一种在严格的黑盒和跨域场景下有效的训练无关的隐私保护框架。其递归在线对齐机制能够有效地利用LLM先验知识，实现高效的隐私保护。

Abstract: The proliferation of retrieval-augmented generation (RAG) has established vector databases as critical infrastructure, yet they introduce severe privacy risks via embedding inversion attacks. Existing paradigms face a fundamental trade-off: optimization-based methods require computationally prohibitive queries, while alignment-based approaches hinge on the unrealistic assumption of accessible in-domain training data. These constraints render them ineffective in strict black-box and cross-domain settings. To dismantle these barriers, we introduce Zero2Text, a novel training-free framework based on recursive online alignment. Unlike methods relying on static datasets, Zero2Text synergizes LLM priors with a dynamic ridge regression mechanism to iteratively align generation to the target embedding on-the-fly. We further demonstrate that standard defenses, such as differential privacy, fail to effectively mitigate this adaptive threat. Extensive experiments across diverse benchmarks validate Zero2Text; notably, on MS MARCO against the OpenAI victim model, it achieves 1.8x higher ROUGE-L and 6.4x higher BLEU-2 scores compared to baselines, recovering sentences from unknown domains without a single leaked data pair.

</details>


### [549] [<SOG_k>: One LLM Token for Explicit Graph Structural Understanding](https://arxiv.org/abs/2602.01771)
*Jingyao Wu,Bin Lu,Zijun Di,Xiaoying Gan,Meng Jin,Luoyi Fu,Xinbing Wang,Chenghu Zhou*

Main category: cs.CL

TL;DR: 提出了一种名为<SOG_k>的特殊标记，用于在统一的token空间内表示图的结构，解决了大型语言模型在处理图数据时出现的结构幻觉问题，并通过拓扑感知结构分词器和混合结构问答语料库，实现了更准确、简洁且可解释的图结构理解。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在理解非结构化数据方面表现出色，但在处理图数据时存在结构幻觉问题。现有方法要么将图转化为自然语言（导致token过多且注意力分散），要么转化为连续嵌入（与原始文本token对齐性差）。

Method: 提出使用一个特殊的<SOG_k>token来代表图的整体结构，并设计了一个拓扑感知结构分词器将图拓扑映射到这个token。同时构建了混合结构问答语料库来对齐新结构token与文本token。

Result: 在五个图级别基准测试中，该方法取得了9.9%至41.4%的性能提升，优于现有基线方法，并展现了可解释性和一致性。该方法也可灵活扩展到节点级别任务，实现全局和局部结构理解。

Conclusion: 所提出的<SOG_k>token方法能够让大型语言模型以简洁准确的方式理解、生成和推理图结构信息，克服了现有方法的局限性，并在多个图相关任务上展现了优越的性能。

Abstract: Large language models show great potential in unstructured data understanding, but still face significant challenges with graphs due to their structural hallucination. Existing approaches mainly either verbalize graphs into natural language, which leads to excessive token consumption and scattered attention, or transform graphs into trainable continuous embeddings (i.e., soft prompt), but exhibit severe misalignment with original text tokens. To solve this problem, we propose to incorporate one special token <SOG_k> to fully represent the Structure Of Graph within a unified token space, facilitating explicit topology input and structural information sharing. Specifically, we propose a topology-aware structural tokenizer that maps each graph topology into a highly selective single token. Afterwards, we construct a set of hybrid structure Question-Answering corpora to align new structural tokens with existing text tokens. With this approach, <SOG_k> empowers LLMs to understand, generate, and reason in a concise and accurate manner. Extensive experiments on five graph-level benchmarks demonstrate the superiority of our method, achieving a performance improvement of 9.9% to 41.4% compared to the baselines while exhibiting interpretability and consistency. Furthermore, our method provides a flexible extension to node-level tasks, enabling both global and local structural understanding. The codebase is publicly available at https://github.com/Jingyao-Wu/SOG.

</details>


### [550] [Data Distribution Matters: A Data-Centric Perspective on Context Compression for Large Language Model](https://arxiv.org/abs/2602.01778)
*Kangtao Lv,Jiwei Tang,Langming Liu,Haibin Chen,Weidong Zhang,Shilei Liu,Yongwei Wang,Yujin Yuan,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 本研究从数据中心视角出发，系统研究了数据分布对大语言模型长上下文压缩质量的影响，并提出了优化建议。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型长上下文压缩方法主要关注模型侧改进，而忽略了数据分布本身对压缩质量的影响，本文旨在填补这一研究空白。

Method: 采用数据中心视角，研究输入数据和模型内在知识（编码器和解码器的预训练知识）两个维度的数据分布对压缩质量的影响。使用基于自编码器的框架评估压缩表示的语义完整性。

Result: 1. 编码器测量的输入熵与压缩质量呈负相关，而在解码器冻结的情况下，解码器测量的熵与压缩质量无显著关系。2. 编码器和解码器的内在数据差距显著降低了压缩收益，且难以缓解。

Conclusion: 数据分布，特别是输入熵和模型内外部分知识的差异，对大语言模型的长上下文压缩质量有显著影响。基于此，研究提出了优化压缩收益的实践指南。

Abstract: The deployment of Large Language Models (LLMs) in long-context scenarios is hindered by computational inefficiency and significant information redundancy. Although recent advancements have widely adopted context compression to address these challenges, existing research only focus on model-side improvements, the impact of the data distribution itself on context compression remains largely unexplored. To bridge this gap, we are the first to adopt a data-centric perspective to systematically investigate how data distribution impacts compression quality, including two dimensions: input data and intrinsic data (i.e., the model's internal pretrained knowledge). We evaluate the semantic integrity of compressed representations using an autoencoder-based framework to systematically investigate it. Our experimental results reveal that: (1) encoder-measured input entropy negatively correlates with compression quality, while decoder-measured entropy shows no significant relationship under a frozen-decoder setting; and (2) the gap between intrinsic data of the encoder and decoder significantly diminishes compression gains, which is hard to mitigate. Based on these findings, we further present practical guidelines to optimize compression gains.

</details>


### [551] [CoDiQ: Test-Time Scaling for Controllable Difficult Question Generation](https://arxiv.org/abs/2602.01660)
*Zhongyuan Peng,Caijun Xu,Changyi Xiao,Shibo Hong,Eli Zhang,Stephen Huang,Yixin Cao*

Main category: cs.CL

TL;DR: 本文提出了CoDiQ框架，一种可控的难题生成方法，通过测试时间缩放来控制题目难度并确保可解性。生成的CoDiQ语料库（44K道竞赛级题目）在训练大型推理模型（LRMs）时显著提升了推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动题目生成方法难以精确控制难度、成本高且无法大规模生成竞赛级题目，限制了大型推理模型（LRMs）的性能提升。

Method: 提出CoDiQ框架，识别测试时间缩放与题目难度/可解性之间的关系，并利用Qwen3-8B构建CoDiQ-Generator模型。在此基础上，构建包含44K道竞赛级题目序列的CoDiQ语料库。

Result: CoDiQ生成的题目比现有基准更具挑战性，同时保持超过82%的可解性。使用CoDiQ语料库训练的LRMs在推理任务上表现显著提升。

Conclusion: 通过可控难度训练数据进行扩展，可以有效增强大型推理模型的推理能力。CoDiQ框架和语料库为相关研究提供了有力的支持。

Abstract: Large Reasoning Models (LRMs) benefit substantially from training on challenging competition-level questions. However, existing automated question synthesis methods lack precise difficulty control, incur high computational costs, and struggle to generate competition-level questions at scale. In this paper, we propose CoDiQ (Controllable Difficult Question Generation), a novel framework enabling fine-grained difficulty control via test-time scaling while ensuring question solvability. Specifically, first, we identify a test-time scaling tendency (extended reasoning token budget boosts difficulty but reduces solvability) and the intrinsic properties defining the upper bound of a model's ability to generate valid, high-difficulty questions. Then, we develop CoDiQ-Generator from Qwen3-8B, which improves the upper bound of difficult question generation, making it particularly well-suited for challenging question construction. Building on the CoDiQ framework, we build CoDiQ-Corpus (44K competition-grade question sequences). Human evaluations show these questions are significantly more challenging than LiveCodeBench/AIME with over 82% solvability. Training LRMs on CoDiQ-Corpus substantially improves reasoning performance, verifying that scaling controlled-difficulty training questions enhances reasoning capabilities. We open-source CoDiQ-Corpus, CoDiQ-Generator, and implementations to support related research.

</details>


### [552] [CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding](https://arxiv.org/abs/2602.01785)
*Yuling Shi,Chaoxiang Xie,Zhensu Sun,Yeheng Chen,Chenxu Zhang,Longfei Yun,Chengcheng Wan,Hongyu Zhang,David Lo,Xiaodong Gu*

Main category: cs.CL

TL;DR: 本文探讨了使用多模态大语言模型（MLLM）将源代码表示为图像以提高计算效率的可行性，实验表明在保持甚至提升性能的同时，可以将模型输入成本降低高达8倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在代码理解方面虽然成功，但随着软件规模增大，计算效率成为瓶颈。现有的基于文本的方法导致上下文长度和计算成本线性增长。MLLM通过将代码表示为图像，提供了一种优化效率的途径，因为图像比文本更易于压缩而不损失语义。

Method: 通过系统性实验研究了MLLM在代码理解任务中的有效性。实验方法包括：1. 探索不同程度的图像压缩（分辨率调整）对代码理解性能的影响；2. 分析视觉线索（如语法高亮）在压缩输入下的作用；3. 评估代码理解任务（如克隆检测）对视觉压缩的鲁棒性。

Result: 1. MLLM在大幅降低token成本（高达8倍压缩）的情况下，仍能有效理解代码。2. MLLM能利用语法高亮等视觉线索，在4倍压缩下提升代码补全性能。3. 克隆检测等任务对视觉压缩具有极强的鲁棒性，部分压缩比甚至优于原始文本输入。

Conclusion: 研究证明了MLLM在代码理解方面具有巨大潜力，通过将源代码表示为图像可以显著提高计算效率，为未来更高效的推理提供了新的方向。同时，研究也指出了当前MLLM在代码理解方面的局限性。

Abstract: Large Language Models (LLMs) have achieved remarkable success in source code understanding, yet as software systems grow in scale, computational efficiency has become a critical bottleneck. Currently, these models rely on a text-based paradigm that treats source code as a linear sequence of tokens, which leads to a linear increase in context length and associated computational costs. The rapid advancement of Multimodal LLMs (MLLMs) introduces an opportunity to optimize efficiency by representing source code as rendered images. Unlike text, which is difficult to compress without losing semantic meaning, the image modality is inherently suitable for compression. By adjusting resolution, images can be scaled to a fraction of their original token cost while remaining recognizable to vision-capable models. To explore the feasibility of this approach, we conduct the first systematic study on the effectiveness of MLLMs for code understanding. Our experiments reveal that: (1) MLLMs can effectively understand code with substantial token reduction, achieving up to 8x compression; (2) MLLMs can effectively leverage visual cues such as syntax highlighting, improving code completion performance under 4x compression; and (3) Code-understanding tasks like clone detection exhibit exceptional resilience to visual compression, with some compression ratios even slightly outperforming raw text inputs. Our findings highlight both the potential and current limitations of MLLMs in code understanding, which points out a shift toward image-modality code representation as a pathway to more efficient inference.

</details>


### [553] [Sentence Curve Language Models](https://arxiv.org/abs/2602.01807)
*DongNyeong Heo,Heelyoul Choi*

Main category: cs.CL

TL;DR: 本文提出了一种名为“句子曲线”的连续句子表示方法，并基于此构建了句子曲线语言模型（SCLM），用于替代传统DLMs中静态的词嵌入预测，以增强模型对句子全局结构的理解，并在多项任务上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型（包括DLMs）使用静态词嵌入来表示目标词，这种表示忽略了词语之间的邻近关系，导致模型倾向于局部准确预测而忽视全局结构。因此，研究者希望找到一种能够捕捉句子全局结构的新表示方法。

Method: 文章提出了一种连续的句子表示方法——句子曲线，它被定义为一个样条曲线，其控制点影响句子中的多个词。基于此，研究者构建了句子曲线语言模型（SCLM），该模型预测句子曲线而非静态词嵌入。理论分析表明，句子曲线预测具有促进全局结构建模的正则化效应。

Result: SCLM在IWSLT14和WMT14数据集上的语言模型任务中取得了优于现有DLMs的SOTA性能。同时，SCLM的训练稳定，无需复杂的知识蒸馏，并在LM1B数据集上展现出与离散DLMs相比的潜力。

Conclusion: 句子曲线是一种有效的连续句子表示方法，能够提升语言模型捕捉全局结构的能力。SCLM通过预测句子曲线，在不依赖知识蒸馏的情况下，实现了更优的性能和更稳定的训练，为未来的语言模型研究提供了新的方向。

Abstract: Language models (LMs) are a central component of modern AI systems, and diffusion-based language models (DLMs) have recently emerged as a competitive alternative. Both paradigms rely on word embeddings not only to represent the input sentence, but also to represent the target sentence that backbone models are trained to predict. We argue that such static embedding of the target word is insensitive to neighboring words, encouraging locally accurate word prediction while neglecting global structure across the target sentence. To address this limitation, we propose a continuous sentence representation, termed sentence curve, defined as a spline curve whose control points affect multiple words in the sentence. Based on this representation, we introduce sentence curve language model (SCLM), which extends DLMs to predict sentence curves instead of the static word embeddings. We theoretically show that sentence curve prediction induces a regularization effect that promotes global structure modeling, and characterize how different sentence curve types affect this behavior. Empirically, SCLM achieves SOTA performance among DLMs on IWSLT14 and WMT14, shows stable training without burdensome knowledge distillation, and demonstrates promising potential compared to discrete DLMs on LM1B.

</details>


### [554] [AXE: Low-Cost Cross-Domain Web Structured Information Extraction](https://arxiv.org/abs/2602.01838)
*Abdelrahman Mansour,Khaled W. Alshaer,Moataz Elsaban*

Main category: cs.CL

TL;DR: AXE是一个创新的网页信息提取管道，通过“修剪”HTML DOM来去除无关节点，减少上下文噪音，从而使一个小型LLM（0.6B）能够高效、准确地提取结构化数据。其Grounded XPath Resolution（GXR）机制确保了提取结果的可追溯性。


<details>
  <summary>Details</summary>
Motivation: 传统的网页结构化数据提取方法在人工设计的规则（脆弱）和大型语言模型（成本高昂）之间存在权衡。研究旨在找到一种更经济高效且准确的方法。

Method: AXE采用“修剪”机制处理HTML DOM树，去除不相关的节点，形成高密度上下文。结合Grounded XPath Resolution（GXR）确保提取的可追溯性。使用一个0.6B的小型LLM进行信息提取。

Result: AXE在SWDE数据集上实现了88.1%的F1分数，在零样本（zero-shot）设置下，性能优于多个更大、经过完全训练的模型。

Conclusion: AXE通过将DOM视为需要修剪的树，并结合GXR机制，提供了一种高效、低成本且性能优越的网页信息提取解决方案，其小型化和易用性使其适合大规模应用。

Abstract: Extracting structured data from the web is often a trade-off between the brittle nature of manual heuristics and the prohibitive cost of Large Language Models. We introduce AXE (Adaptive X-Path Extractor), a pipeline that rethinks this process by treating the HTML DOM as a tree that needs pruning rather than just a wall of text to be read. AXE uses a specialized "pruning" mechanism to strip away boilerplate and irrelevant nodes, leaving behind a distilled, high-density context that allows a tiny 0.6B LLM to generate precise, structured outputs. To keep the model honest, we implement Grounded XPath Resolution (GXR), ensuring every extraction is physically traceable to a source node. Despite its low footprint, AXE achieves state-of-the-art zero-shot performance, outperforming several much larger, fully-trained alternatives with an F1 score of 88.1% on the SWDE dataset. By releasing our specialized adaptors, we aim to provide a practical, cost-effective path for large-scale web information extraction.

</details>


### [555] [Read As Human: Compressing Context via Parallelizable Close Reading and Skimming](https://arxiv.org/abs/2602.01840)
*Jiwei Tang,Shilei Liu,Zhicheng Zhang,Qingsong Lv,Runsong Zhao,Tingwei Lu,Langming Liu,Haibin Chen,Yujin Yuan,Hai-Tao Zheng,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: RAM (Read As HuMan) 是一种上下文压缩框架，通过模拟人类阅读行为，对长文本进行选择性精读和略读，提高了 LLMs 处理长上下文的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLMs) 在处理长上下文时存在计算效率低下和信息冗余的问题，阻碍了其在长上下文场景下的部署。

Method: RAM 框架将上下文划分为多个段落，并根据与查询的相关性采用混合阅读策略：高相关性段落进行精读（完全保留），低相关性段落进行略读（压缩成摘要向量）。同时，引入对比学习目标来优化精读和略读的决策边界。

Result: RAM 在多个问答和摘要任务的基准测试中优于现有方法，并在长输入（平均 16K，最大 32K）上实现了高达 12 倍的端到端加速。

Conclusion: RAM 框架能够有效解决 LLMs 处理长上下文时的效率和性能瓶颈，通过模仿人类阅读策略，实现了在保持优异性能的同时显著提高处理速度。

Abstract: Large Language Models (LLMs) demonstrate exceptional capability across diverse tasks. However, their deployment in long-context scenarios is hindered by two challenges: computational inefficiency and redundant information. We propose RAM (Read As HuMan), a context compression framework that adopts an adaptive hybrid reading strategy, to address these challenges. Inspired by human reading behavior (i.e., close reading important content while skimming less relevant content), RAM partitions the context into segments and encodes them with the input query in parallel. High-relevance segments are fully retained (close reading), while low-relevance ones are query-guided compressed into compact summary vectors (skimming). Both explicit textual segments and implicit summary vectors are concatenated and fed into decoder to achieve both superior performance and natural language format interpretability. To refine the decision boundary between close reading and skimming, we further introduce a contrastive learning objective based on positive and negative query-segment pairs. Experiments demonstrate that RAM outperforms existing baselines on multiple question answering and summarization benchmarks across two backbones, while delivering up to a 12x end-to-end speedup on long inputs (average length 16K; maximum length 32K).

</details>


### [556] [PretrainRL: Alleviating Factuality Hallucination of Large Language Models at the Beginning](https://arxiv.org/abs/2602.01875)
*Langming Liu,Kangtao Lv,Haibin Chen,Weidong Zhang,Yejing Wang,Shilei Liu,Xin Tong,Yujin Yuan,Yongwei Wang,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 提出了一种名为PretrainRL的框架，通过在预训练阶段引入强化学习来解决大型语言模型的事实性幻觉问题，该框架通过“去偏见然后学习”的原则，主动修正模型概率分布，降低高概率错误信息，提高低概率事实信息的学习效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在事实性幻觉问题，根源在于预训练语料库中数据分布不平衡，导致“低概率真实”和“高概率虚假”并存。现有方法（如“我不知道”或事后知识编辑）要么回避问题，要么存在灾难性遗忘。

Method: 提出PretrainRL框架，将强化学习整合到预训练阶段。核心原则是“去偏见然后学习”，通过主动重塑模型概率分布，降低高概率虚假信息的权重，为学习低概率真实信息腾出空间。具体实现包括设计高效的负采样策略发现高概率虚假信息，并引入新指标评估模型在事实知识上的概率状态。

Result: 在三个公开基准数据集上的广泛实验表明，PretrainRL显著缓解了事实性幻觉，并且性能优于当前最先进的方法。

Conclusion: PretrainRL通过在预训练阶段集成强化学习，有效解决了大型语言模型的事实性幻觉问题，通过“去偏见然后学习”的策略，从根源上改善了模型对事实知识的掌握能力。

Abstract: Large language models (LLMs), despite their powerful capabilities, suffer from factual hallucinations where they generate verifiable falsehoods. We identify a root of this issue: the imbalanced data distribution in the pretraining corpus, which leads to a state of "low-probability truth" and "high-probability falsehood". Recent approaches, such as teaching models to say "I don't know" or post-hoc knowledge editing, either evade the problem or face catastrophic forgetting. To address this issue from its root, we propose \textbf{PretrainRL}, a novel framework that integrates reinforcement learning into the pretraining phase to consolidate factual knowledge. The core principle of PretrainRL is "\textbf{debiasing then learning}." It actively reshapes the model's probability distribution by down-weighting high-probability falsehoods, thereby making "room" for low-probability truths to be learned effectively. To enable this, we design an efficient negative sampling strategy to discover these high-probability falsehoods and introduce novel metrics to evaluate the model's probabilistic state concerning factual knowledge. Extensive experiments on three public benchmarks demonstrate that PretrainRL significantly alleviates factual hallucinations and outperforms state-of-the-art methods.

</details>


### [557] [GuideWeb: A Benchmark for Automatic In-App Guide Generation on Real-World Web UIs](https://arxiv.org/abs/2602.01917)
*Chengguang Gan,Yoshihiro Tsujii,Yunhao Liang,Tatsunori Mori,Shiwen Ni,Hiroki Itoh*

Main category: cs.CL

TL;DR: 提出名为 GuideWeb 的新基准，用于在真实网页 UI 上自动生成应用内指南，该指南通过选择目标元素和生成用户意图文本来提供操作指导。


<details>
  <summary>Details</summary>
Motivation: 现有的数字采纳平台 (DAP) 工具需要耗费大量人力来维护，因为网站不断更新，需要手动更新指南。此研究旨在自动化该过程。

Method: GuideWeb 将任务表述为生成页面级指南，通过选择基于网页的目标元素，并生成与用户意图一致的简洁指南文本。研究人员还提出了一个全面的评估套件，用于共同衡量目标元素选择的准确性以及意图和指南文本的生成质量。

Result: 研究提出的 GuideWeb Agent 在指南目标元素预测方面达到了 30.79% 的准确率，在意图生成方面获得了 44.94 的 BLEU 分数，在指南文本生成方面获得了 21.34 的 BLEU 分数。现有的基线方法表现远不如此。

Conclusion: 自动指南生成仍然是一个挑战，在能够可靠地应用于现实世界之前，还需要进一步的进步。GuideWeb 及其评估套件为该领域的研究提供了有价值的资源。

Abstract: Digital Adoption Platform (DAP) provide web-based overlays that deliver operation guidance and contextual hints to help users navigate complex websites. Although modern DAP tools enable non-experts to author such guidance, maintaining these guides remains labor-intensive because website layouts and functionalities evolve continuously, which requires repeated manual updates and re-annotation. In this work, we introduce \textbf{GuideWeb}, a new benchmark for automatic in-app guide generation on real-world web UIs. GuideWeb formulates the task as producing page-level guidance by selecting \textbf{guide target elements} grounded in the webpage and generating concise guide text aligned with user intent. We also propose a comprehensive evaluation suite that jointly measures the accuracy of guide target element selection and the quality of generated intents and guide texts. Experiments show that our proposed \textbf{GuideWeb Agent} achieves \textbf{30.79\%} accuracy in guide target element prediction, while obtaining BLEU scores of \textbf{44.94} for intent generation and \textbf{21.34} for guide-text generation. Existing baselines perform substantially worse, which highlights that automatic guide generation remains challenging and that further advances are necessary before such systems can be reliably deployed in real-world settings.

</details>


### [558] [ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support](https://arxiv.org/abs/2602.01885)
*Tiantian Chen,Jiaqi Lu,Ying Shen,Lin Zhang*

Main category: cs.CL

TL;DR: 该研究提出了ES-MemEval基准和EvoEmo数据集，以评估大型语言模型在长期情感支持对话中的记忆能力，并发现显式长期记忆对于减少幻觉和实现有效个性化至关重要，而RAG虽然提高了事实一致性，但在处理时间动态和用户状态演变方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在长期对话中缺乏强大的记忆能力，尤其是在需要处理分散、隐式和不断变化的用户信息的在线情感支持等复杂场景中。现有的基准测试未能充分评估这些关键能力。

Method: 引入了ES-MemEval基准，包含信息提取、时间推理、冲突检测、弃权和用户建模五项核心记忆能力评估。同时提出了EvoEmo数据集，用于个性化长期情感支持，模拟了碎片化、隐式用户披露和不断变化的用户状态。并在各种大型语言模型上进行了广泛实验。

Result: 实验表明，显式长期记忆对于减少幻觉和实现有效个性化至关重要。检索增强生成（RAG）提高了事实一致性，但在处理时间动态和用户状态演变方面存在困难。

Conclusion: 当前的大型语言模型在长期个性化对话方面具有潜力和局限性，需要更强大地集成记忆和检索机制来克服这些挑战。

Abstract: Large Language Models (LLMs) have shown strong potential as conversational agents. Yet, their effectiveness remains limited by deficiencies in robust long-term memory, particularly in complex, long-term web-based services such as online emotional support. However, existing long-term dialogue benchmarks primarily focus on static and explicit fact retrieval, failing to evaluate agents in critical scenarios where user information is dispersed, implicit, and continuously evolving. To address this gap, we introduce ES-MemEval, a comprehensive benchmark that systematically evaluates five core memory capabilities: information extraction, temporal reasoning, conflict detection, abstention, and user modeling, in long-term emotional support settings, covering question answering, summarization, and dialogue generation tasks. To support the benchmark, we also propose EvoEmo, a multi-session dataset for personalized long-term emotional support that captures fragmented, implicit user disclosures and evolving user states. Extensive experiments on open-source long-context, commercial, and retrieval-augmented (RAG) LLMs show that explicit long-term memory is essential for reducing hallucinations and enabling effective personalization. At the same time, RAG improves factual consistency but struggles with temporal dynamics and evolving user states. These findings highlight both the potential and limitations of current paradigms and motivate more robust integration of memory and retrieval for long-term personalized dialogue systems.

</details>


### [559] [From Code-Centric to Concept-Centric: Teaching NLP with LLM-Assisted "Vibe Coding"](https://arxiv.org/abs/2602.01919)
*Hend Al-Khalifa*

Main category: cs.CL

TL;DR: 本研究提出了一种名为“Vibe Coding”的教学方法，该方法在本科NLP课程中利用LLM作为代码助手，同时强调概念理解和批判性思维。学生对该方法满意度很高，尤其赞赏减少了调试负担，但同时也指出了时间限制、LLM输出验证和任务明确性等方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的快速发展，NLP教育面临机遇与挑战。研究旨在探索一种能有效利用LLM优势，同时又不牺牲学生概念理解和批判性思维能力的教学方法。

Method: 在高级本科NLP课程中实施“Vibe Coding”教学法，学生利用LLM生成代码完成七个实验，并通过概念性反思问题进行评估。收集了19名学生的课程反馈。

Result: 学生对Vibe Coding方法的参与度、概念学习和评估公平性表示高度满意（平均得分4.4-4.6/5.0）。学生认为LLM减少了调试的认知负担，使他们能更专注于NLP概念。然而，学生也遇到了时间限制、LLM输出验证难度以及任务说明不够清晰等问题。

Conclusion: 在结构合理（包括强制性的提示记录和基于反思的评估）的情况下，LLM辅助学习可以将教育重点从语法熟练度转移到概念掌握上，从而更好地为学生适应AI增强的专业环境做准备。

Abstract: The rapid advancement of Large Language Models (LLMs) presents both challenges and opportunities for Natural Language Processing (NLP) education. This paper introduces ``Vibe Coding,'' a pedagogical approach that leverages LLMs as coding assistants while maintaining focus on conceptual understanding and critical thinking. We describe the implementation of this approach in a senior-level undergraduate NLP course, where students completed seven labs using LLMs for code generation while being assessed primarily on conceptual understanding through critical reflection questions. Analysis of end-of-course feedback from 19 students reveals high satisfaction (mean scores 4.4-4.6/5.0) across engagement, conceptual learning, and assessment fairness. Students particularly valued the reduced cognitive load from debugging, enabling deeper focus on NLP concepts. However, challenges emerged around time constraints, LLM output verification, and the need for clearer task specifications. Our findings suggest that when properly structured with mandatory prompt logging and reflection-based assessment, LLM-assisted learning can shift focus from syntactic fluency to conceptual mastery, preparing students for an AI-augmented professional landscape.

</details>


### [560] [Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition](https://arxiv.org/abs/2602.01967)
*Wonjun Lee,Hyounghun Kim,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: 提出了一种名为 Moe-Ctc 的混合专家架构，通过中间 CTC 监督来提高自动语音识别（ASR）对带口音语音的鲁棒性，在多种口音条件下均取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有 ASR 模型在处理口音语音时性能下降，大多数模型仅在少数高资源英语方言上训练。口音无关的方法鲁棒性有所提高但对重口音或未见口音效果不佳，而口音特定的方法依赖有限且带有噪声的标签。

Method: 提出 Moe-Ctc，一种混合专家（Mixture-of-Experts）架构，并引入中间 CTC 监督。训练时，口音感知路由（accent-aware routing）促使专家学习特定口音模式；推理时，则转为无标签路由（label-free routing）。每个专家都有自己的 CTC 头，并通过增强的路由损失（routing-augmented loss）来稳定优化。

Result: 在 Mcv-Accent 基准测试中，Moe-Ctc 在低资源和高资源条件下，对已见和未见口音均取得了持续的性能提升，词错误率（WER）相对强基线 FastConformer 降低了高达 29.3%。

Conclusion: Moe-Ctc 架构通过结合口音感知路由和中间 CTC 监督，有效提高了 ASR 系统处理口音语音的能力，并实现了出色的泛化性能。

Abstract: Accented speech remains a persistent challenge for automatic speech recognition (ASR), as most models are trained on data dominated by a few high-resource English varieties, leading to substantial performance degradation for other accents. Accent-agnostic approaches improve robustness yet struggle with heavily accented or unseen varieties, while accent-specific methods rely on limited and often noisy labels. We introduce Moe-Ctc, a Mixture-of-Experts architecture with intermediate CTC supervision that jointly promotes expert specialization and generalization. During training, accent-aware routing encourages experts to capture accent-specific patterns, which gradually transitions to label-free routing for inference. Each expert is equipped with its own CTC head to align routing with transcription quality, and a routing-augmented loss further stabilizes optimization. Experiments on the Mcv-Accent benchmark demonstrate consistent gains across both seen and unseen accents in low- and high-resource conditions, achieving up to 29.3% relative WER reduction over strong FastConformer baselines.

</details>


### [561] [Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation](https://arxiv.org/abs/2602.01965)
*Kwun Hang Lau,Fangyuan Zhang,Boyu Ruan,Yingli Zhou,Qintian Guo,Ruiyuan Zhang,Xiaofang Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种名为CatRAG的框架，通过引入查询感知的动态边权重、符号锚定和关键事实段落权重增强，解决了现有RAG方法依赖静态知识图谱导致随机游走偏离的“静态图衰变”问题，提高了多跳推理的完整性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的RAG方法（如HippoRAG）依赖于静态的图结构和转换概率，忽略了边在不同查询下的相关性差异，容易导致随机游走偏离到高连接度的节点，影响了多跳证据的完整检索。

Method: CatRAG框架在HippoRAG 2的基础上，引入了三种机制来使知识图谱具有查询适应性：1. 符号锚定：注入弱实体约束来规范随机游走；2. 查询感知动态边加权：动态调整图结构，修剪不相关路径，增强与查询意图一致的路径；3. 关键事实段落权重增强：对可能包含证据的段落进行结构性偏置。

Result: 在四个多跳基准测试上，CatRAG显著优于现有最先进的方法。虽然标准召回率（Recall）的提升幅度不大，但CatRAG在推理完整性（reasoning completeness）方面取得了显著进步，能够恢复完整的证据链而无中断。

Conclusion: CatRAG通过引入上下文感知的导航结构，成功解决了静态知识图谱在RAG中的局限性，实现了在多跳推理中检索完整证据链的能力，弥合了检索部分上下文与实现完全基于事实推理之间的差距。

Abstract: Recent advances in Retrieval-Augmented Generation (RAG) have shifted from simple vector similarity to structure-aware approaches like HippoRAG, which leverage Knowledge Graphs (KGs) and Personalized PageRank (PPR) to capture multi-hop dependencies. However, these methods suffer from a "Static Graph Fallacy": they rely on fixed transition probabilities determined during indexing. This rigidity ignores the query-dependent nature of edge relevance, causing semantic drift where random walks are diverted into high-degree "hub" nodes before reaching critical downstream evidence. Consequently, models often achieve high partial recall but fail to retrieve the complete evidence chain required for multi-hop queries. To address this, we propose CatRAG, Context-Aware Traversal for robust RAG, a framework that builds on the HippoRAG 2 architecture and transforms the static KG into a query-adaptive navigation structure. We introduce a multi-faceted framework to steer the random walk: (1) Symbolic Anchoring, which injects weak entity constraints to regularize the random walk; (2) Query-Aware Dynamic Edge Weighting, which dynamically modulates graph structure, to prune irrelevant paths while amplifying those aligned with the query's intent; and (3) Key-Fact Passage Weight Enhancement, a cost-efficient bias that structurally anchors the random walk to likely evidence. Experiments across four multi-hop benchmarks demonstrate that CatRAG consistently outperforms state of the art baselines. Our analysis reveals that while standard Recall metrics show modest gains, CatRAG achieves substantial improvements in reasoning completeness, the capacity to recover the entire evidence path without gaps. These results reveal that our approach effectively bridges the gap between retrieving partial context and enabling fully grounded reasoning. Resources are available at https://github.com/kwunhang/CatRAG.

</details>


### [562] [Orthogonal Hierarchical Decomposition for Structure-Aware Table Understanding with Large Language Models](https://arxiv.org/abs/2602.01969)
*Bin Cao,Huixian Lu,Chenwen Ma,Ting Wang,Ruizhe Li,Jing Fan*

Main category: cs.CL

TL;DR: 本文提出了一种正交分层分解（OHD）框架，通过构建列树和行树来捕捉表格的垂直和水平层级依赖关系，以解决复杂表格（多层表头、合并单元格、异构布局）的理解和推理难题，并在两个复杂表格问答基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（表格线性化、归一化网格建模）在处理具有多层表头、合并单元格和异构布局的复杂表格时，难以显式捕捉层级结构和跨维度依赖关系，导致结构语义与文本表示之间存在错位。

Method: 提出正交分层分解（OHD）框架，引入基于空间-语义协同约束的正交树诱导（OTI）方法，将表格分解为列树和行树，分别捕捉垂直和水平层级依赖。设计双通路关联协议重建单元格语义 lineage，并引入LLM作为语义仲裁者对齐多层语义信息。

Result: 在AITQA和HiTab两个复杂表格问答基准测试上，OHD框架在多个评估指标上持续优于现有的表示范式。

Conclusion: OHD框架能够构建保存结构信息的表格输入表示，有效解决了复杂表格的理解和推理挑战，并在相关任务上展现出优越性。

Abstract: Complex tables with multi-level headers, merged cells and heterogeneous layouts pose persistent challenges for LLMs in both understanding and reasoning. Existing approaches typically rely on table linearization or normalized grid modeling. However, these representations struggle to explicitly capture hierarchical structures and cross-dimensional dependencies, which can lead to misalignment between structural semantics and textual representations for non-standard tables. To address this issue, we propose an Orthogonal Hierarchical Decomposition (OHD) framework that constructs structure-preserving input representations of complex tables for LLMs. OHD introduces an Orthogonal Tree Induction (OTI) method based on spatial--semantic co-constraints, which decomposes irregular tables into a column tree and a row tree to capture vertical and horizontal hierarchical dependencies, respectively. Building on this representation, we design a dual-pathway association protocol to symmetrically reconstruct semantic lineage of each cell, and incorporate an LLM as a semantic arbitrator to align multi-level semantic information. We evaluate OHD framework on two complex table question answering benchmarks, AITQA and HiTab. Experimental results show that OHD consistently outperforms existing representation paradigms across multiple evaluation metrics.

</details>


### [563] [Beyond Local Edits: Embedding-Virtualized Knowledge for Broader Evaluation and Preservation of Model Editing](https://arxiv.org/abs/2602.01977)
*Shuainan Liu,Xuanang Chen,Ben He,Le Sun*

Main category: cs.CL

TL;DR: 本文提出了一种名为Embedding-Virtualized Knowledge (EVK) 的新方法，用于评估大型语言模型知识编辑的效果，并构建了一个名为EVK-Bench的评估基准，以捕捉传统方法遗漏的知识漂移。此外，还提出了EVK-Align模块，可在不影响编辑准确性的前提下，提高知识保持能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型知识编辑评估方法依赖于预定义的数据集，只能评估有限的知识点，无法全面了解编辑对模型知识系统的整体影响。

Method: 1. 提出Embedding-Virtualized Knowledge (EVK)，通过在嵌入空间进行扰动来表征模型知识，从而探索比显式数据标注更广泛的虚拟化知识区域。 2. 基于EVK构建EVK-Bench评估基准，量化编辑引起的潜在知识漂移。 3. 提出即插即用的EVK-Align模块，在编辑过程中约束嵌入层面的知识漂移。

Result: EVK-Bench能够揭示传统基于样本的评估方法未能捕捉到的知识漂移效应。EVK-Align模块能够显著提高知识保持能力，同时不牺牲编辑准确性。

Conclusion: EVK提供了一种更全面的评估方法，EVK-Bench能够更准确地衡量知识编辑的影响，而EVK-Align模块则是一种有效的解决方案，可以在不影响编辑性能的情况下改善知识的保持。

Abstract: Knowledge editing methods for large language models are commonly evaluated using predefined benchmarks that assess edited facts together with a limited set of related or neighboring knowledge. While effective, such evaluations remain confined to finite, dataset-bounded samples, leaving the broader impact of editing on the model's knowledge system insufficiently understood. To address this gap, we introduce Embedding-Virtualized Knowledge (EVK) that characterizes model knowledge through controlled perturbations in embedding space, enabling the exploration of a substantially broader and virtualized knowledge region beyond explicit data annotations. Based on EVK, we construct an embedding-level evaluation benchmark EVK-Bench that quantifies potential knowledge drift induced by editing, revealing effects that are not captured by conventional sample-based metrics. Furthermore, we propose a plug-and-play EVK-Align module that constrains embedding-level knowledge drift during editing and can be seamlessly integrated into existing editing methods. Experiments demonstrate that our approach enables more comprehensive evaluation while significantly improving knowledge preservation without sacrificing editing accuracy.

</details>


### [564] [S3-CoT: Self-Sampled Succinct Reasoning Enables Efficient Chain-of-Thought LLMs](https://arxiv.org/abs/2602.01982)
*Yanrui Du,Sendong Zhao,Yibo Gao,Danyang Zhao,Qika Lin,Ming Ma,Jiayun Li,Yi Jiang,Kai He,Qianyi Xu,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: 本研究提出了一种基于激活引导的自采样框架，用于高效的链式思考（CoT）学习，旨在让大语言模型（LLM）能够生成类人类“系统1”的快速推理模式，以解决现有CoT方法中存在的冗余推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有证据表明，LLM在CoT能力上的提升常伴随着冗余推理，促使研究者探索LLM是否能获得类似人类“系统1”的快速思考模式。

Method: 提出一个基于激活引导的自采样框架，用于高效CoT学习。该方法无需教师指导即可从目标LLM自身诱导出风格一致且长度可变的推理过程，解决了监督微调（SFT）方法中高质量监督数据稀缺的瓶颈。具体而言，在（i）模拟人类双认知系统和（ii）采用渐进式压缩课程的基础上，利用黄金答案过滤数据进行SFT。此外，还探索了一种自进化机制，仅通过预测一致的变长数据驱动SFT，无需黄金答案。

Result: 在数学基准测试和跨领域（医学）的泛化测试中，所提出的方法在通用LLM和R1风格LLM上均取得了稳定的性能提升。

Conclusion: 该自采样框架能够有效地训练LLM进行高效的CoT推理，生成类人类“系统1”的快速思考模式，并能在不同领域实现性能的提升，同时缓解了监督数据稀缺的问题。

Abstract: Large language models (LLMs) equipped with chain-of-thought (CoT) achieve strong performance and offer a window into LLM behavior. However, recent evidence suggests that improvements in CoT capabilities often come with redundant reasoning processes, motivating a key question: Can LLMs acquire a fast-thinking mode analogous to human System 1 reasoning? To explore this, our study presents a self-sampling framework based on activation steering for efficient CoT learning. Our method can induce style-aligned and variable-length reasoning traces from target LLMs themselves without any teacher guidance, thereby alleviating a central bottleneck of SFT-based methods-the scarcity of high-quality supervision data. Using filtered data by gold answers, we perform SFT for efficient CoT learning with (i) a human-like dual-cognitive system, and (ii) a progressive compression curriculum. Furthermore, we explore a self-evolution regime in which SFT is driven solely by prediction-consistent data of variable-length variants, eliminating the need for gold answers. Extensive experiments on math benchmarks, together with cross-domain generalization tests in medicine, show that our method yields stable improvements for both general and R1-style LLMs. Our data and model checkpoints can be found at https://github.com/DYR1/S3-CoT.

</details>


### [565] [From Latent Signals to Reflection Behavior: Tracing Meta-Cognitive Activation Trajectory in R1-Style LLMs](https://arxiv.org/abs/2602.01999)
*Yanrui Du,Yibo Gao,Sendong Zhao,Jiayun Li,Haochun Wang,Qika Lin,Kai He,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: 该研究通过分析R1风格大语言模型（LLMs）的层级激活轨迹，揭示了其自我反思行为的内部机制，发现其经历了一个从潜在控制、语义枢纽到行为显现的结构化过程，并证明了这些阶段之间的因果联系。


<details>
  <summary>Details</summary>
Motivation: 尽管R1风格LLMs具有自我反思能力，但其内部机制尚不清楚。本研究旨在弥合这一差距，理解自我反思行为的产生过程。

Method: 研究者利用logit lens读取token级别的语义，追踪模型从浅层到深层的激活轨迹。通过对比不同层级的激活模式，识别出与反思行为相关的特定层级（潜在控制层、语义枢纽层、行为显现层）。此外，研究者还进行了干预实验，以验证不同阶段之间的因果关系。

Result: 研究发现，自我反思行为的发生存在一个结构化的层级进程：1. 潜在控制层：激活的线性方向编码了思考预算的语义。2. 语义枢纽层：话语层面的线索（如转折点和总结线索）浮现并主导概率质量。3. 行为显现层：反思行为token的采样概率开始上升。干预实验证明了这种因果链：prompt层面的语义通过调节激活沿潜在控制方向的投影，引发语义枢纽层中转折点和总结线索之间的竞争，进而调节行为显现层中反思行为token的采样概率。

Conclusion: 研究结果表明，LLMs的自我反思过程类似于人类的元认知过程，经历从潜在监控、话语层面调控到最终显性自我反思的阶段性进展。prompt层面的语义对整个反思过程起着关键的调控作用。

Abstract: R1-style LLMs have attracted growing attention for their capacity for self-reflection, yet the internal mechanisms underlying such behavior remain unclear. To bridge this gap, we anchor on the onset of reflection behavior and trace its layer-wise activation trajectory. Using the logit lens to read out token-level semantics, we uncover a structured progression: (i) Latent-control layers, where an approximate linear direction encodes the semantics of thinking budget; (ii) Semantic-pivot layers, where discourse-level cues, including turning-point and summarization cues, surface and dominate the probability mass; and (iii) Behavior-overt layers, where the likelihood of reflection-behavior tokens begins to rise until they become highly likely to be sampled. Moreover, our targeted interventions uncover a causal chain across these stages: prompt-level semantics modulate the projection of activations along latent-control directions, thereby inducing competition between turning-point and summarization cues in semantic-pivot layers, which in turn regulates the sampling likelihood of reflection-behavior tokens in behavior-overt layers. Collectively, our findings suggest a human-like meta-cognitive process-progressing from latent monitoring, to discourse-level regulation, and to finally overt self-reflection. Our analysis code can be found at https://github.com/DYR1/S3-CoT.

</details>


### [566] [Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation](https://arxiv.org/abs/2602.02007)
*Zhanghao Hu,Qinglin Zhu,Hanqi Yan,Yulan He,Lin Gui*

Main category: cs.CL

TL;DR: 本文提出了一种名为 xMemory 的新代理记忆系统，旨在解决标准 RAG 在处理对话历史等受限、连贯的数据流时存在的冗余检索问题。xMemory 通过构建分层记忆结构并引入稀疏性-语义目标来优化检索过程，以更高效、更准确地为多事实查询检索相关信息。


<details>
  <summary>Details</summary>
Motivation: 标准的 RAG 在大型、异构语料库上效果良好，但在代理记忆这种边界清晰、连贯且常包含重复信息的对话历史场景下，存在过度检索和删除重要历史信息的问题。因此，需要一种超越简单相似性匹配的检索方法。

Method: xMemory 构建了一个记忆层次结构，通过稀疏性-语义目标（sparsity-semantics objective）来指导记忆单元的分裂和合并。在检索时，xMemory 采用自顶向下的策略，首先选择主题和语义的紧凑、多样化集合，仅在必要时（当减少读者不确定性时）才扩展到更详细的对话片段和原始消息。

Result: 在 LoCoMo 和 PerLTQA 数据集上，使用三种最新的 LLM 进行的实验表明，xMemory 在答案质量和代币效率方面均取得了显著提升。

Conclusion: xMemory 通过引入层次化、优化的检索机制，有效解决了代理记忆系统中 RAG 的冗余问题，显著提高了代理在处理连贯对话历史时的信息检索和推理能力。

Abstract: Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is a bounded, coherent dialogue stream with highly correlated spans that are often duplicates. Under this shift, fixed top-$k$ similarity retrieval tends to return redundant context, and post-hoc pruning can delete temporally linked prerequisites needed for correct reasoning. We argue retrieval should move beyond similarity matching and instead operate over latent components, following decoupling to aggregation: disentangle memories into semantic components, organise them into a hierarchy, and use this structure to drive retrieval. We propose xMemory, which builds a hierarchy of intact units and maintains a searchable yet faithful high-level node organisation via a sparsity--semantics objective that guides memory split and merge. At inference, xMemory retrieves top-down, selecting a compact, diverse set of themes and semantics for multi-fact queries, and expanding to episodes and raw messages only when it reduces the reader's uncertainty. Experiments on LoCoMo and PerLTQA across the three latest LLMs show consistent gains in answer quality and token efficiency.

</details>


### [567] [NEAT: Neuron-Based Early Exit for Large Reasoning Models](https://arxiv.org/abs/2602.02010)
*Kang Liu,Yongkang Liu,Xiaocui Yang,Peidong Wang,Wen Zhang,Shi Feng,Yifei Zhang,Daling Wang*

Main category: cs.CL

TL;DR: 提出了一种名为NEAT的基于神经元的早期推理退出框架，无需额外训练或计算即可通过监测神经元激活动态来减少大型推理模型的冗余推理步骤，从而降低模型输出长度并保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）存在“过度思考”问题，即在得出正确答案后仍会生成冗余的推理步骤。现有的早期退出方法依赖于输出级启发式或训练过的探测模型，需要额外的计算或标记数据。

Method: NEAT通过监测神经元级别的激活动态来识别与退出相关的神经元，并跟踪其激活模式，从而动态触发早期退出或抑制反思，实现无需训练的早期退出，并且不增加测试时的计算量。

Result: 在四个推理基准和六种不同规模和架构的模型上进行实验，NEAT平均可实现22%至28%的token减少，同时保持准确性。

Conclusion: NEAT是一种有效的、无需训练的早期推理退出框架，可以通过监测神经元激活动态来解决大型推理模型的过度思考问题，在减少计算量和保持模型性能之间取得了良好的平衡。

Abstract: Large Reasoning Models (LRMs) often suffer from \emph{overthinking}, a phenomenon in which redundant reasoning steps are generated after a correct solution has already been reached. Existing early reasoning exit methods primarily rely on output-level heuristics or trained probing models to skip redundant reasoning steps, thereby mitigating overthinking. However, these approaches typically require additional rollout computation or externally labeled datasets. In this paper, we propose \textbf{NEAT}, a \textbf{N}euron-based \textbf{E}arly re\textbf{A}soning exi\textbf{T} framework that monitors neuron-level activation dynamics to enable training-free early exits, without introducing additional test-time computation. NEAT identifies exit-associated neurons and tracks their activation patterns during reasoning to dynamically trigger early exit or suppress reflection, thereby reducing unnecessary reasoning while preserving solution quality. Experiments on four reasoning benchmarks across six models with different scales and architectures show that, for each model, NEAT achieves an average token reduction of 22\% to 28\% when averaged over the four benchmarks, while maintaining accuracy.

</details>


### [568] [WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora](https://arxiv.org/abs/2602.02053)
*Pengyu Wang,Benfeng Xu,Licheng Zhang,Shaohan Wang,Mingxuan Du,Chiwei Zhu,Zhendong Mao*

Main category: cs.CL

TL;DR: 本文提出了WildGraphBench，一个用于评估图增强检索生成（GraphRAG）在真实场景下表现的新基准。该基准利用维基百科的结构，包含长上下文和异构文档，并生成了三个复杂度的问答和摘要任务。实验表明，现有GraphRAG方法在聚合少量来源的多个事实时有效，但在摘要任务上表现不佳，可能过度关注高层信息而忽略细节。


<details>
  <summary>Details</summary>
Motivation: 现有GraphRAG基准在评估其在长上下文和大规模异构文档等真实场景下的表现时存在不足，因为它们通常依赖于简短、精心设计的文本片段作为外部知识。

Method: 利用维基百科的结构，以其外部引用作为检索语料库，引用链接的陈述作为地面真相，构建了一个包含1100个问题的基准，问题分为单事实问答、多事实问答和章节摘要三个难度级别。

Result: 实验表明，当前的GraphRAG流水线在证据来自适量来源的多事实聚合方面有所帮助。然而，这种聚合范式可能会过分强调高层陈述，牺牲细节，从而在摘要任务上表现较弱。

Conclusion: WildGraphBench为评估GraphRAG在真实世界中的表现提供了一个更具挑战性的基准，并揭示了现有方法的局限性，尤其是在处理摘要任务和平衡信息粒度方面。

Abstract: Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as a hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench.

</details>


### [569] [Closing the Loop: Universal Repository Representation with RPG-Encoder](https://arxiv.org/abs/2602.02084)
*Jane Luo,Chengyu Yin,Xin Zhang,Qingtao Li,Steven Liu,Yiming Huang,Jie Wu,Hao Liu,Yangyu Huang,Yu Kang,Fangkai Yang,Ying Xin,Scarlett Li*

Main category: cs.CL

TL;DR: 本文提出RPG-Encoder框架，通过统一的代码和依赖表示（RPG）来解决现有代码库代理的推理断裂问题，实现了代码库理解和生成之间的闭环，并在SWE-bench和RepoCraft基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码库代理在理解和生成代码时存在推理断裂，原因是它们依赖于孤立的API文档或依赖图，这些图缺乏语义深度。作者认为代码库的理解和生成是相反但统一的过程。

Method: 提出RPG-Encoder框架，将代码库表示（RPG）从静态生成蓝图推广为统一、高保真的表示。RPG-Encoder通过三个机制实现推理闭环：(1)将原始代码编码到RPG中，结合提升的语义特征和代码依赖；(2)增量式演化拓扑结构，将维护成本与代码库规模解耦，降低95.7%的开销；(3)作为结构感知导航的统一接口。

Result: 在SWE-bench Verified上，RPG-Encoder达到了93.7%的Acc@5，在SWE-bench Live Lite上性能超越最佳基线10%以上。在RepoCraft上，实现了98.5%的重构覆盖率，证明了RPG能高保真地映射原始代码库。

Conclusion: RPG-Encoder框架通过构建高保真的代码库表示，成功闭合了代码库理解和生成之间的推理循环，在代码库理解任务上取得了最先进的性能，并验证了其在高保真表示和效率方面的优势。

Abstract: Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation.

</details>


### [570] [LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge Graph Construction -- A Case Study on SDGs](https://arxiv.org/abs/2602.02090)
*Yikai Zeng,Yingchao Piao,Jianhui Li*

Main category: cs.CL

TL;DR: 该研究提出了一种名为LEC-KG的双向协作框架，用于从非结构化文本中构建领域特定的知识图谱。该框架结合了大型语言模型（LLMs）的语义理解和知识图谱嵌入（KGE）的结构化推理，通过分层关系提取、证据引导的思维链反馈以及语义初始化来解决异构实体、长尾关系分布和无标准模式的挑战。


<details>
  <summary>Details</summary>
Motivation: 从非结构化文本构建领域特定的知识图谱面临诸多挑战，包括异构实体提及、长尾关系分布以及缺乏标准化模式。现有的方法难以有效处理这些问题。

Method: LEC-KG框架包含三个关键组件：1) 分层粗粒度到细粒度的关系提取，以缓解长尾偏差；2) 证据引导的思维链（Chain-of-Thought）反馈，将结构性建议 grounding 到源文本；3) 语义初始化，为未见实体启用结构验证。该框架通过迭代方式使LLM的抽取结果与KGE的结构化表示相互增强。

Result: 在中文可持续发展目标（SDG）报告上的评估表明，LEC-KG相比于LLM基线模型取得了显著的性能提升，尤其在低频关系上表现更优。通过迭代精炼，该框架能够可靠地将非结构化的政策文本转化为经过验证的知识图谱三元组。

Conclusion: LEC-KG是一个有效的双向协作框架，能够利用LLMs的语义能力和KGE的结构推理能力，克服从非结构化文本构建知识图谱的挑战，尤其是在处理长尾关系和提升低频关系抽取准确性方面取得了显著成效。

Abstract: Constructing domain-specific knowledge graphs from unstructured text remains challenging due to heterogeneous entity mentions, long-tail relation distributions, and the absence of standardized schemas. We present LEC-KG, a bidirectional collaborative framework that integrates the semantic understanding of Large Language Models (LLMs) with the structural reasoning of Knowledge Graph Embeddings (KGE). Our approach features three key components: (1) hierarchical coarse-to-fine relation extraction that mitigates long-tail bias, (2) evidence-guided Chain-of-Thought feedback that grounds structural suggestions in source text, and (3) semantic initialization that enables structural validation for unseen entities. The two modules enhance each other iteratively-KGE provides structure-aware feedback to refine LLM extractions, while validated triples progressively improve KGE representations. We evaluate LEC-KG on Chinese Sustainable Development Goal (SDG) reports, demonstrating substantial improvements over LLM baselines, particularly on low-frequency relations. Through iterative refinement, our framework reliably transforms unstructured policy text into validated knowledge graph triples.

</details>


### [571] [Think Dense, Not Long: Dynamic Decoupled Conditional Advantage for Efficient Reasoning](https://arxiv.org/abs/2602.02099)
*Keqin Peng,Yuanxin Ouyang,Xuebo Liu,Zhiliang Tian,Ruijian Han,Yancheng Yuan,Liang Ding*

Main category: cs.CL

TL;DR: 本文提出了一种名为动态解耦条件优势（DDCA）的新方法，用于解决强化学习可验证奖励（RLVR）在提高多步推理能力的同时，会产生冗余输出且对长度惩罚敏感的问题。DDCA通过条件计算长度优势和动态调整惩罚强度，有效改善了效率-准确率的权衡，显著减少了模型生成内容的长度，同时保持甚至提高了准确率。


<details>
  <summary>Details</summary>
Motivation: RLVR方法在多步推理方面表现出色，但存在输出冗长和长度惩罚不当的问题。现有方法在处理长度惩罚时，容易受到错误答案的干扰（基线稀释）或无法适应问题难度（难度-惩罚不匹配），导致在简单问题上过度惩罚，在困难问题上未能有效约束。

Method: 提出动态解耦条件优势（DDCA）方法。具体来说，DDCA在正确响应的簇内条件计算长度优势，以避免基线稀释；并利用问题通过率作为难度代理，动态调整惩罚强度，以解决难度-惩罚不匹配的问题。

Result: 在GSM8K、MATH500、AMC23和AIME25等数据集上的实验表明，DDCA在效率-准确率的权衡方面优于自适应基线方法。在GSM8K等简单任务上，生成的token数量减少了约60%；在AIME25等困难任务上，减少了超过20%，同时保持或提高了准确率。

Conclusion: DDCA是一种有效的方法，能够解决RLVR方法在处理输出长度和问题难度时的挑战，通过解耦效率优化与正确性，实现了在保持准确率的同时显著提高模型生成效率。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) can elicit strong multi-step reasoning, yet it often encourages overly verbose traces. Moreover, naive length penalties in group-relative optimization can severely hurt accuracy. We attribute this failure to two structural issues: (i) Dilution of Length Baseline, where incorrect responses (with zero length reward) depress the group baseline and over-penalize correct solutions; and (ii) Difficulty-Penalty Mismatch, where a static penalty cannot adapt to problem difficulty, suppressing necessary reasoning on hard instances while leaving redundancy on easy ones. We propose Dynamic Decoupled Conditional Advantage (DDCA) to decouple efficiency optimization from correctness. DDCA computes length advantages conditionally within the correct-response cluster to eliminate baseline dilution, and dynamically scales the penalty strength using the group pass rate as a proxy for difficulty. Experiments on GSM8K, MATH500, AMC23, and AIME25 show that DDCA consistently improves the efficiency--accuracy trade-off relative to adaptive baselines, reducing generated tokens by approximately 60% on simpler tasks (e.g., GSM8K) versus over 20% on harder benchmarks (e.g., AIME25), thereby maintaining or improving accuracy. Code is available at https://github.com/alphadl/DDCA.

</details>


### [572] [Dicta-LM 3.0: Advancing The Frontier of Hebrew Sovereign LLMs](https://arxiv.org/abs/2602.02104)
*Shaltiel Shmidman,Avi Shmidman,Amir DN Cohen,Moshe Koppel*

Main category: cs.CL

TL;DR: 本文发布了为希伯来语和英语训练的开源大语言模型 Dicta-LM 3.0，并提供了一个新的希伯来语聊天 LLM 评估基准。该模型有三种尺寸（24B、12B、1.7B），并提供原生 65k 上下文长度和工具调用支持，旨在解决低资源语言 LLM 训练的挑战，并为其他非英语语言的 LLM 适配提供框架。


<details>
  <summary>Details</summary>
Motivation:  fronteir 实验室发布的开源大语言模型（LLM）多为英语，而对非英语（如希伯来语）的主权 LLM 需求高但供应少，训练这些模型面临独特挑战。因此，需要为低资源语言开发 LLM。

Method: 本文训练了 Dicta-LM 3.0，一个包含大规模希伯来语和英语文本语料库的开源 LLM 系列。模型有三种尺寸（24B、12B、1.7B），分别基于 Mistral-Small-3.1、NVIDIA Nemotron Nano V2 和 Qwen3-1.7B。模型具有 65k 原生上下文长度，并提供基础模型和支持工具调用的聊天模型。为评估模型，引入了一个新的希伯来语聊天 LLM 评估基准套件，涵盖翻译、摘要、Winograd、以色列琐事和注音等任务。

Result: 本文发布了 Dicta-LM 3.0 系列模型，并在引入的希伯来语聊天 LLM 评估基准上进行了严格评估。该模型在多种任务上展现出性能。

Conclusion: 本文成功地应对了低资源语言 LLM 训练的挑战，发布了 Dicta-LM 3.0 模型系列，并提出了一个可用于将其他 LLM 适配到不同非英语语言的框架，为多语言 NLP 领域做出了贡献。

Abstract: Open-weight LLMs have been released by frontier labs; however, sovereign Large Language Models (for languages other than English) remain low in supply yet high in demand. Training large language models (LLMs) for low-resource languages such as Hebrew poses unique challenges. In this paper, we introduce Dicta-LM 3.0: an open-weight collection of LLMs trained on substantially-sized corpora of Hebrew and English texts. The model is released in three sizes: 24B - adapted from the Mistral-Small-3.1 base model, 12B - adapted from the NVIDIA Nemotron Nano V2 model, and 1.7B - adapted from the Qwen3-1.7B base model. We are releasing multiple variants of each model, each with a native context length of 65k tokens; base model and chat model with tool-calling support. To rigorously evaluate our models, we introduce a new benchmark suite for evaluation of Hebrew chat-LLMs, covering a diverse set of tasks including Translation, Summarization, Winograd, Israeli Trivia, and Diacritization (nikud). Our work not only addresses the intricacies of training LLMs in low-resource languages but also proposes a framework that can be leveraged for adapting other LLMs to various non-English languages, contributing to the broader field of multilingual NLP.

</details>


### [573] [Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts](https://arxiv.org/abs/2602.02108)
*Wenhao Li,Daohai Yu,Gen Luo,Yuxin Zhang,Fei Chao,Rongrong Ji,Yifan Wu,Jiaxin Liu,Ziyang Gong,Zimu Liao*

Main category: cs.CL

TL;DR: OOMB 是一种内存效率极高的长上下文 LLM 训练系统，通过激活分块重计算和 KV 缓存优化，将训练内存开销与上下文长度解耦，实现在单 GPU 上训练超长上下文模型。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 训练受限于 GPU 内存，尤其是在处理长上下文时，激活函数的内存开销随序列长度线性增长，导致训练成本高昂。

Method: OOMB 采用分块重计算激活的训练框架，使激活内存占用恒定（O(1)）。为了处理 KV 缓存，系统集成了分页内存管理器、异步 CPU 卸载以及页级稀疏注意力等优化技术。

Result: OOMB 显著降低了长上下文训练的内存开销，例如 Qwen2.5-7B 模型每增加 10K  token，内存开销仅增加 10MB。这使得在单 H200 GPU 上训练 4M token 上下文成为可能，而无需分布式集群。

Conclusion: OOMB 克服了长上下文 LLM 训练的内存瓶颈，是一种资源效率上的重大进步，能够支持更大规模和更长上下文的模型训练。

Abstract: Training Large Language Models (LLMs) on long contexts is severely constrained by prohibitive GPU memory overhead, not training time. The primary culprits are the activations, whose memory footprints scale linearly with sequence length. We introduce OOMB, a highly memory-efficient training system that directly confronts this barrier. Our approach employs a chunk-recurrent training framework with on-the-fly activation recomputation, which maintains a constant activation memory footprint (O(1)) and shifts the primary bottleneck to the growing KV cache. To manage the KV cache, OOMB integrates a suite of synergistic optimizations: a paged memory manager for both the KV cache and its gradients to eliminate fragmentation, asynchronous CPU offloading to hide data transfer latency, and page-level sparse attention to reduce both computational complexity and communication overhead. The synergy of these techniques yields exceptional efficiency. Our empirical results show that for every additional 10K tokens of context, the end-to-end training memory overhead increases by a mere 10MB for Qwen2.5-7B. This allows training Qwen2.5-7B with a 4M-token context on a single H200 GPU, a feat that would otherwise require a large cluster using context parallelism. This work represents a substantial advance in resource efficiency for long-context LLM training. The source code is available at https://github.com/wenhaoli-xmu/OOMB.

</details>


### [574] [There Is More to Refusal in Large Language Models than a Single Direction](https://arxiv.org/abs/2602.02132)
*Faaiz Joad,Majd Hawasly,Sabri Boughorbel,Nadir Durrani,Husrev Taha Sencar*

Main category: cs.CL

TL;DR: 研究表明，大型语言模型中的拒绝行为并非由单一激活空间方向控制，而是由多个独立的几何方向决定。尽管这些方向各异，但它们在控制拒绝程度方面却表现出相似的线性关系，表明存在一个共享的“控制旋钮”，主要影响拒绝的方式而非是否拒绝。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为大型语言模型中的拒绝行为由单一激活空间方向介导，本研究旨在验证这一观点的局限性，并探索更全面的拒绝行为模型。

Method: 通过对十一类拒绝和不合规行为（包括安全、不完整或不支持的请求、拟人化和过度拒绝）进行分析，研究者在模型的激活空间中寻找与这些行为相对应的几何方向，并测试了沿着这些方向进行线性操纵的效果。

Result: 研究发现，不同类型的拒绝行为确实对应着激活空间中几何上不同的方向。然而，沿着任何与拒绝相关的方向进行线性操纵，都会产生相似的拒绝与过度拒绝之间的权衡。主要区别在于不同方向影响的是拒绝的方式，而非是否发生拒绝。

Conclusion: 大型语言模型中的拒绝行为不是由单一激活空间方向控制的，而是由多个独立的几何方向决定的。尽管这些方向不同，但它们共同构成了一个主要的“控制旋钮”，用于调整拒绝的程度和方式，而不是简单地决定模型是否拒绝。

Abstract: Prior work argues that refusal in large language models is mediated by a single activation-space direction, enabling effective steering and ablation. We show that this account is incomplete. Across eleven categories of refusal and non-compliance, including safety, incomplete or unsupported requests, anthropomorphization, and over-refusal, we find that these refusal behaviors correspond to geometrically distinct directions in activation space. Yet despite this diversity, linear steering along any refusal-related direction produces nearly identical refusal to over-refusal trade-offs, acting as a shared one-dimensional control knob. The primary effect of different directions is not whether the model refuses, but how it refuses.

</details>


### [575] [Quantifying the Gap between Understanding and Generation within Unified Multimodal Models](https://arxiv.org/abs/2602.02140)
*Chenlong Wang,Yuhang Chen,Zhihan Hu,Dongping Chen,Wenhu Chen,Sarah Wiegreffe,Tianyi Zhou*

Main category: cs.CL

TL;DR: 本研究提出了一个名为GapEval的双向基准，用于衡量统一多模态模型（UMM）在理解和生成能力之间的差距，并发现当前模型在两种能力之间存在显著差距，表明其统一性仅停留在表面。


<details>
  <summary>Details</summary>
Motivation: 现有研究对统一多模态模型（UMM）的理解和生成能力是否真正对齐和整合尚不明确，本研究旨在量化这种差距，并评估其认知连贯性。

Method: 提出GapEval这一双向基准，该基准允许使用图像和文本回答同一问题，从而对称地评估模型在两种方向上的推理能力和跨模态一致性。此外，还进行了从知识操纵角度进行的实证研究，以揭示潜在的局限性。

Result: 实验表明，在各种UMM及其架构中，理解和生成能力之间持续存在差距。实证研究表明，UMM中的知识通常是分离的，跨模态的能力涌现和知识不同步。

Conclusion: 当前的UMM仅实现了表面水平的统一，而非深度的认知融合。UMM中的知识整合和跨模态能力同步是未来研究的重要方向。

Abstract: Recent advances in unified multimodal models (UMM) have demonstrated remarkable progress in both understanding and generation tasks. However, whether these two capabilities are genuinely aligned and integrated within a single model remains unclear. To investigate this question, we introduce GapEval, a bidirectional benchmark designed to quantify the gap between understanding and generation capabilities, and quantitatively measure the cognitive coherence of the two "unified" directions. Each question can be answered in both modalities (image and text), enabling a symmetric evaluation of a model's bidirectional inference capability and cross-modal consistency. Experiments reveal a persistent gap between the two directions across a wide range of UMMs with different architectures, suggesting that current models achieve only surface-level unification rather than deep cognitive convergence of the two. To further explore the underlying mechanism, we conduct an empirical study from the perspective of knowledge manipulation to illustrate the underlying limitations. Our findings indicate that knowledge within UMMs often remains disjoint. The capability emergence and knowledge across modalities are unsynchronized, paving the way for further exploration.

</details>


### [576] [Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing](https://arxiv.org/abs/2602.02159)
*Lingkun Long,Yushi Huang,Shihao Bai,Ruihao Gong,Jun Zhang,Ao Zhou,Jianlei Yang*

Main category: cs.CL

TL;DR: Focus-dLLM 是一种训练无关的注意力稀疏化框架，用于提高 dLLM 的长上下文处理效率，通过预测未遮盖区域和识别注意力“汇聚点”来减少计算量，实现了显著的加速。


<details>
  <summary>Details</summary>
Motivation: 现有 dLLM 的双向全注意力计算成本高昂，限制了推理效率。现有的稀疏注意力方法效果不佳，因为在扩散过程中难以预测尚未解码的 token 的注意力重要性。

Method: 提出 Focus-dLLM 框架，包含：1. 基于相邻时间步 token 置信度相似性，设计过去置信度引导指示器来预测未遮盖区域。2. 提出“汇聚点感知”剪枝策略，估计并移除冗余计算，同时保留关键的注意力“汇聚点”。3. 利用跨层一致性，跨层重用识别出的“汇聚点”位置以降低开销。

Result: 在 32K 上下文长度下，Focus-dLLM 实现了超过 29 倍的无损加速。

Conclusion: Focus-dLLM 是一种有效的训练无关的注意力稀疏化方法，能够显著提升 dLLM 的长上下文推理效率，同时保持信息的完整性。

Abstract: Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods remain ineffective. This stems from the need to estimate attention importance for tokens yet to be decoded, while the unmasked token positions are unknown during diffusion. In this paper, we present Focus-dLLM, a novel training-free attention sparsification framework tailored for accurate and efficient long-context dLLM inference. Based on the finding that token confidence strongly correlates across adjacent steps, we first design a past confidence-guided indicator to predict unmasked regions. Built upon this, we propose a sink-aware pruning strategy to accurately estimate and remove redundant attention computation, while preserving highly influential attention sinks. To further reduce overhead, this strategy reuses identified sink locations across layers, leveraging the observed cross-layer consistency. Experimental results show that our method offers more than $29\times$ lossless speedup under $32K$ context length. The code is publicly available at: https://github.com/Longxmas/Focus-dLLM

</details>


### [577] [D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use](https://arxiv.org/abs/2602.02160)
*Bowen Xu,Shaoyu Wu,Hao Jiang,Kai Liu,Xin Chen,Lulu Hu,Bin Yang*

Main category: cs.CL

TL;DR: 提出了一种名为 D-CORE 的两阶段训练框架，用于解决大型推理模型（LRMs）在复杂工具使用场景中缺乏子任务分解能力导致的“懒惰推理”问题，显著提高了模型在工具使用任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的大型推理模型（LRMs）在处理复杂的工具使用场景时，缺乏子任务分解能力，导致“懒惰推理”现象，无法有效解决现实世界中的复杂问题。

Method: 提出 D-CORE 两阶段训练框架：1. 通过自蒸馏激励模型的任务分解推理能力；2. 利用多样性感知强化学习（RL）恢复模型的反思推理能力。

Result: D-CORE 在多个基准测试和模型规模上均取得了显著的工具使用性能提升。D-CORE-8B 达到 77.7% 的准确率，优于现有最佳 8B 模型 5.7%。D-CORE-14B 达到 79.3% 的准确率，成为新的 SOTA，且性能超越 70B 模型。

Conclusion: D-CORE 框架能够有效提升大型推理模型在复杂工具使用场景中的子任务分解和反思推理能力，从而显著提高其整体性能，并且在模型规模和效率上展现出优势。

Abstract: Effective tool use and reasoning are essential capabilities for large reasoning models~(LRMs) to address complex real-world problems. Through empirical analysis, we identify that current LRMs lack the capability of sub-task decomposition in complex tool use scenarios, leading to Lazy Reasoning. To address this, we propose a two-stage training framework D-CORE~(\underline{\textbf{D}}ecomposing tasks and \underline{\textbf{Co}}mposing \underline{\textbf{Re}}asoning processes) that first incentivize the LRMs' task decomposition reasoning capability via self-distillation, followed by diversity-aware reinforcement learning~(RL) to restore LRMs' reflective reasoning capability. D-CORE achieves robust tool-use improvements across diverse benchmarks and model scales. Experiments on BFCLv3 demonstrate superiority of our method: D-CORE-8B reaches 77.7\% accuracy, surpassing the best-performing 8B model by 5.7\%. Meanwhile, D-CORE-14B establishes a new state-of-the-art at 79.3\%, outperforming 70B models despite being 5$\times$ smaller. The source code is available at https://github.com/alibaba/EfficientAI.

</details>


### [578] [AR-MAP: Are Autoregressive Large Language Models Implicit Teachers for Diffusion Large Language Models?](https://arxiv.org/abs/2602.02178)
*Liang Lin,Feng Xiong,Zengbin Wang,Kun Wang,Junhao Dong,Xuecai Hu,Yong Wang,Xiangxiang Chu*

Main category: cs.CL

TL;DR: 提出了一种名为 AR-MAP 的新框架，用于将自回归语言模型（AR-LLMs）的偏好对齐知识转移到扩散大语言模型（DLLMs）中，解决了 DLLMs 对齐中的高方差问题，并在多项任务中取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 现有扩散大语言模型（DLLMs）在偏好对齐方面存在挑战，主要是由于基于证据下界（ELBO）的似然估计引入了高方差。

Method: AR-MAP 框架利用预先对齐好的自回归语言模型（AR-LLMs）作为隐式教师，通过简单的权重缩放将对齐知识转移到 DLLMs 中，利用了两者共享的架构结构。

Result: AR-MAP 成功规避了直接 DLLM 对齐的高方差和计算开销，在多项偏好对齐任务中取得了与现有 DLLM 特定对齐方法相当或更优的性能，平均得分达到 69.08%。

Conclusion: AR-MAP 是一种有效且高效的 DLLM 偏好对齐方法，通过利用 AR-LLMs 的知识，可以克服 DLLM 对齐中的挑战，并实现良好的性能。

Abstract: Diffusion Large Language Models (DLLMs) have emerged as a powerful alternative to autoregressive models, enabling parallel token generation across multiple positions. However, preference alignment of DLLMs remains challenging due to high variance introduced by Evidence Lower Bound (ELBO)-based likelihood estimation. In this work, we propose AR-MAP, a novel transfer learning framework that leverages preference-aligned autoregressive LLMs (AR-LLMs) as implicit teachers for DLLM alignment. We reveal that DLLMs can effectively absorb alignment knowledge from AR-LLMs through simple weight scaling, exploiting the shared architectural structure between these divergent generation paradigms. Crucially, our approach circumvents the high variance and computational overhead of direct DLLM alignment and comprehensive experiments across diverse preference alignment tasks demonstrate that AR-MAP achieves competitive or superior performance compared to existing DLLM-specific alignment methods, achieving 69.08\% average score across all tasks and models. Our Code is available at https://github.com/AMAP-ML/AR-MAP.

</details>


### [579] [Sinhala Physical Common Sense Reasoning Dataset for Global PIQA](https://arxiv.org/abs/2602.02207)
*Nisansa de Silva,Surangika Ranathunga*

Main category: cs.CL

TL;DR: 本文介绍了首个僧伽罗语物理常识推理数据集，包含110个人工创建和验证的数据样本，其中大部分问题与斯里兰卡情境相关。


<details>
  <summary>Details</summary>
Motivation: 为僧伽罗语开发一个专门的物理常识推理数据集，以促进对该语言的自然语言处理研究，并特别关注斯里兰卡本土情境。

Method: 创建了一个包含110个数据样本的数据集，每个样本包括一个提示、一个正确答案和一个错误答案。数据样本由人类创建并经过验证。

Result: 成功构建了一个用于僧伽罗语物理常识推理的数据集，其中包含符合斯里兰卡本土情境的问答对。

Conclusion: 该数据集为僧伽罗语的常识推理研究提供了一个重要的资源，并有助于理解和处理与特定文化背景相关的语言现象。

Abstract: This paper presents the first-ever Sinhala physical common sense reasoning dataset created as part of Global PIQA. It contains 110 human-created and verified data samples, where each sample consists of a prompt, the corresponding correct answer, and a wrong answer. Most of the questions refer to the Sri Lankan context, where Sinhala is an official language.

</details>


### [580] [Evaluating Metalinguistic Knowledge in Large Language Models across the World's Languages](https://arxiv.org/abs/2602.02182)
*Tjaša Arčon,Matej Klemen,Marko Robnik-Šikonja,Kaja Dobrovoljc*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）在语言结构方面的元语言知识，发现现有模型在这方面的能力有限，尤其是在低资源语言和细粒度语法区分上。模型表现与数据可用性密切相关，而非语言的普遍特征。研究者发布了一个新的基准数据集以促进未来对LLMs元语言能力的系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）评估主要集中在语言使用任务上，对其语言结构知识的了解不足。现有的语言学基准测试通常过于狭窄，偏向高资源语言，并且很少评估显式推理语言结构的能力（即元语言知识）。

Method: 研究者使用准确率和宏F1分数，并结合多数类和随机基线，分析了LLMs在元语言知识上的总体表现，并根据语言学领域和语言相关因素进行了细分。他们设计了一个新的基准数据集来评估LLMs的元语言知识。

Result: 现有LLMs的元语言知识有限：GPT-4o表现最佳，但准确率仅为0.367，开源模型表现更差。所有模型都高于随机水平，但未能超越多数类基线，表明它们能捕捉跨语言模式但缺乏细粒度的语法区分。模型在不同语言学领域表现各异，词汇特征准确率最高，音韵特征最低，这部分反映了在线可见度的差异。在语言层面，准确率与数字语言地位强相关，数字存在和资源可用的语言评估更准确，低资源语言表现则显著下降。资源相关指标（如维基百科大小、语料库可用性）比地理、谱系或社会语言学因素更能预测准确率。

Conclusion: 大型语言模型的元语言知识是碎片化的，并且主要受数据可用性的影响，而不是跨语言的通用语法能力。研究者发布了他们的基准测试作为开源数据集，以支持系统评估并鼓励未来LLMs的全球语言多样性。

Abstract: Large language models (LLMs) are routinely evaluated on language use tasks, yet their knowledge of linguistic structure remains poorly understood. Existing linguistic benchmarks typically focus on narrow phenomena, emphasize high-resource languages, and rarely evaluate metalinguistic knowledge-explicit reasoning about language structure rather than language use. Using accuracy and macro F1, together with majority-class and chance baselines, we analyse overall performance and examine variation by linguistic domains and language-related factors. Our results show that metalinguistic knowledge in current LLMs is limited: GPT-4o performs best but achieves only moderate accuracy (0.367), while open-source models lag behind. All models perform above chance but fail to outperform the majority-class baseline, suggesting they capture cross-linguistic patterns but lack fine-grained grammatical distinctions. Performance varies across linguistic domains, with lexical features showing the highest accuracy and phonological features among the lowest, partially reflecting differences in online visibility. At the language level, accuracy shows a strong association with digital language status: languages with higher digital presence and resource availability are evaluated more accurately, while low-resource languages show substantially lower performance. Analyses of predictive factors confirm that resource-related indicators (Wikipedia size, corpus availability) are more informative predictors of accuracy than geographical, genealogical, or sociolinguistic factors. Together, these results suggest that LLMs' metalinguistic knowledge is fragmented and shaped by data availability rather than generalizable grammatical competence across the world's languages. We release our benchmark as an open-source dataset to support systematic evaluation and encourage greater global linguistic diversity in future LLMs.

</details>


### [581] [Towards AI Evaluation in Domain-Specific RAG Systems: The AgriHubi Case Study](https://arxiv.org/abs/2602.02208)
*Md. Toufique Hasan,Ayman Asad Khan,Mika Saari,Vaishnavi Bankhele,Pekka Abrahamsson*

Main category: cs.CL

TL;DR: 本文介绍了一个名为 AgriHubi 的、针对芬兰语农业领域的检索增强生成（RAG）系统，旨在解决现有大型语言模型在农业领域应用时存在的接地性弱、以英语为中心以及评估不足的问题，尤其关注低资源语言的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在农业知识密集型领域有潜力，但存在接地性不足、训练数据偏向英语、以及现实世界评估有限等问题。这些问题在低资源语言环境下尤为严重，高质量的领域文档难以被通用模型获取。

Method: AgriHubi 系统是一个领域自适应的 RAG 系统，它集成了芬兰语的农业文档，并使用了开放的 PORO 系列模型。该系统结合了明确的来源依据和用户反馈，以支持迭代式改进。系统经过了八次迭代开发，并通过两次用户研究进行了评估。

Result: AgriHubi 在回答的完整性、语言准确性和可信度方面均有显著提升。研究还揭示了使用更大模型时，响应质量与延迟之间的实际权衡。

Conclusion: 该研究为在低资源语言环境下设计和评估领域特定的 RAG 系统提供了实证指导，并证明了 AgriHubi 在芬兰语农业决策支持方面的有效性。

Abstract: Large language models show promise for knowledge-intensive domains, yet their use in agriculture is constrained by weak grounding, English-centric training data, and limited real-world evaluation. These issues are amplified for low-resource languages, where high-quality domain documentation exists but remains difficult to access through general-purpose models. This paper presents AgriHubi, a domain-adapted retrieval-augmented generation (RAG) system for Finnish-language agricultural decision support. AgriHubi integrates Finnish agricultural documents with open PORO family models and combines explicit source grounding with user feedback to support iterative refinement. Developed over eight iterations and evaluated through two user studies, the system shows clear gains in answer completeness, linguistic accuracy, and perceived reliability. The results also reveal practical trade-offs between response quality and latency when deploying larger models. This study provides empirical guidance for designing and evaluating domain-specific RAG systems in low-resource language settings.

</details>


### [582] [Am I More Pointwise or Pairwise? Revealing Position Bias in Rubric-Based LLM-as-a-Judge](https://arxiv.org/abs/2602.02219)
*Yuzheng Xu,Tosho Hirasawa,Tadashi Kozuno,Yoshitaka Ushiku*

Main category: cs.CL

TL;DR: 该研究揭示了在基于评分等级的LLM评估中存在的“位置偏见”，即LLM倾向于选择列表中特定位置的评分选项。研究提出了一种平衡排列策略来缓解此偏见，并证明该策略能揭示潜在偏见并提高LLM评估与人类评估的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估（LLM-as-a-judge）研究主要关注点状和对偶评估，对基于评分等级的评估方法分析不足，而该方法在实际应用中可能存在问题（如位置偏见）。

Method: 通过控制实验，证明了LLM在基于评分等级的评估中存在位置偏见。提出了一种平衡排列策略，将每个评分选项均匀地分布在不同位置，并通过聚合不同排列下的评分来揭示和缓解偏见。

Result: 实验证明了普遍存在的位置偏见。提出的平衡排列策略能够有效揭示这种偏见，并且能够提高LLM-as-a-Judge与人类评估结果的相关性。

Conclusion: 基于评分等级的LLM评估并非本质上是点状的，通过简单的排列校准策略可以显著提升其可靠性，消除位置偏见的影响。

Abstract: Large language models (LLMs) are now widely used to evaluate the quality of text, a field commonly referred to as LLM-as-a-judge. While prior works mainly focus on point-wise and pair-wise evaluation paradigms. Rubric-based evaluation, where LLMs select a score from multiple rubrics, has received less analysis. In this work, we show that rubric-based evaluation implicitly resembles a multi-choice setting and therefore has position bias: LLMs prefer score options appearing at specific positions in the rubric list. Through controlled experiments across multiple models and datasets, we demonstrate consistent position bias. To mitigate this bias, we propose a balanced permutation strategy that evenly distributes each score option across positions. We show that aggregating scores across balanced permutations not only reveals latent position bias, but also improves correlation between the LLM-as-a-Judge and human. Our results suggest that rubric-based LLM-as-a-Judge is not inherently point-wise and that simple permutation-based calibration can substantially improve its reliability.

</details>


### [583] [Using Correspondence Patterns to Identify Irregular Words in Cognate sets Through Leave-One-Out Validation](https://arxiv.org/abs/2602.02221)
*Frederic Blum,Johann-Mattis List*

Main category: cs.CL

TL;DR: 该研究提出了一种新的量化指标“对应模式的均衡平均重复度”来衡量语音对应规律性，并开发了一种基于此指标的计算方法，用于识别不符合规律的同源词集合。实验结果表明，该方法在真实数据上准确率达到85%。


<details>
  <summary>Details</summary>
Motivation: 历史语言学中对语音对应规律性的评估通常是直观的，而非量化的，并且实际中不规律性比预期的更为普遍。随着计算方法和标准化词汇数据的进步，有必要改进工作流程并提供量化评估。

Method: 提出“对应模式的均衡平均重复度”（balanced average recurrence of correspondence patterns）作为新的规律性衡量指标。开发一种计算方法，利用该指标识别与对应模式不符的同源词集合。通过留一法交叉验证（leave-one-out validation）在模拟数据和真实数据上验证方法，通过替换不规则词语来评估方法识别不规则词的能力。

Result: 在基于真实数据的实验中，该方法实现了85%的总体准确率。研究还展示了处理大型数据集子样本的好处，以及增加数据不规则性对结果的影响。

Conclusion: 新的规律性衡量指标和基于此的识别不规则同源词的方法，有望在计算机辅助语言比较中提高现有和未来数据集的质量，并发挥重要作用。

Abstract: Regular sound correspondences constitute the principal evidence in historical language comparison. Despite the heuristic focus on regularity, it is often more an intuitive judgement than a quantified evaluation, and irregularity is more common than expected from the Neogrammarian model. Given the recent progress of computational methods in historical linguistics and the increased availability of standardized lexical data, we are now able to improve our workflows and provide such a quantitative evaluation. Here, we present the balanced average recurrence of correspondence patterns as a new measure of regularity. We also present a new computational method that uses this measure to identify cognate sets that lack regularity with respect to their correspondence patterns. We validate the method through two experiments, using simulated and real data. In the experiments, we employ leave-one-out validation to measure the regularity of cognate sets in which one word form has been replaced by an irregular one, checking how well our method identifies the forms causing the irregularity. Our method achieves an overall accuracy of 85\% with the datasets based on real data. We also show the benefits of working with subsamples of large datasets and how increasing irregularity in the data influences our results. Reflecting on the broader potential of our new regularity measure and the irregular cognate identification method based on it, we conclude that they could play an important role in improving the quality of existing and future datasets in computer-assisted language comparison.

</details>


### [584] [Culinary Crossroads: A RAG Framework for Enhancing Diversity in Cross-Cultural Recipe Adaptation](https://arxiv.org/abs/2507.21934)
*Tianyi Hu,Andrea Morales-Garzón,Jingyi Zheng,Maria Maistro,Daniel Hershcovich*

Main category: cs.CL

TL;DR: 研究提出了一种名为CARRIAGE的即插即用RAG框架，用于跨文化食谱改编，旨在提高生成食谱的多样性和质量，并证明了其在多样性和质量方面优于闭源LLM。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG方法在跨文化食谱改编时，即使提供多样的上下文信息，也倾向于生成不具多样性的结果，无法满足用户多样化的饮食需求和偏好。

Method: 通过分析RAG在生成过程中的局限性，提出CARRIAGE框架，该框架在检索和上下文组织方面增强了多样性，并进行实验验证。

Result: CARRIAGE框架在食谱改编的多样性和质量方面实现了帕累托效率，优于闭源LLM。

Conclusion: CARRIAGE是第一个明确旨在生成高度多样化输出以适应多用户偏好的RAG框架，有效地解决了RAG在创意任务中生成结果多样性不足的问题。

Abstract: In cross-cultural recipe adaptation, the goal is not only to ensure cultural appropriateness and retain the original dish's essence, but also to provide diverse options for various dietary needs and preferences. Retrieval Augmented Generation (RAG) is a promising approach, combining the retrieval of real recipes from the target cuisine for cultural adaptability with large language models (LLMs) for relevance. However, it remains unclear whether RAG can generate diverse adaptation results. Our analysis shows that RAG tends to overly rely on a limited portion of the context across generations, failing to produce diverse outputs even when provided with varied contextual inputs. This reveals a key limitation of RAG in creative tasks with multiple valid answers: it fails to leverage contextual diversity for generating varied responses. To address this issue, we propose CARRIAGE, a plug-and-play RAG framework for cross-cultural recipe adaptation that enhances diversity in both retrieval and context organization. To our knowledge, this is the first RAG framework that explicitly aims to generate highly diverse outputs to accommodate multiple user preferences. Our experiments show that CARRIAGE achieves Pareto efficiency in terms of diversity and quality of recipe adaptation compared to closed-book LLMs.

</details>


### [585] [OpenSeal: Good, Fast, and Cheap Construction of an Open-Source Southeast Asian LLM via Parallel Data](https://arxiv.org/abs/2602.02266)
*Tan Sang Nguyen,Muhammad Reza Qorib,Hwee Tou Ng*

Main category: cs.CL

TL;DR: 本文介绍了OpenSeal，一个首个真正开源的东南亚语言大型语言模型，其在平行数据增强的持续预训练下，性能可媲美同等规模的现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）虽然具备多语言能力，但普遍以英语为中心，对低资源语言表现不佳。已有的东南亚模型均未完全开源，阻碍了对其内部机制的深入研究。因此，需要开发一个真正开源的、专注于东南亚语言的模型。

Method: 研究者通过受控和全面的实验，研究了平行数据在LLMs持续预训练中的有效性。他们利用平行数据对现有LLM进行增强，并最终构建了OpenSeal模型。

Result: 实验证明，仅使用平行数据是扩展LLM至新语言最有效的方法。使用347亿（34.7B）个token的平行数据和180小时的计算时间，在8个NVIDIA H200 GPU上，OpenSeal模型达到了与同等规模现有模型相当的性能。

Conclusion: 平行数据是提升LLM在低资源语言上表现的有效手段。OpenSeal的成功表明，通过精心设计的数据和训练策略，可以构建出高性能且真正开源的多语言LLM，推动该领域的研究和发展。

Abstract: Large language models (LLMs) have proven to be effective tools for a wide range of natural language processing (NLP) applications. Although many LLMs are multilingual, most remain English-centric and perform poorly on low-resource languages. Recently, several Southeast Asia-focused LLMs have been developed, but none are truly open source, as they do not publicly disclose their training data. Truly open-source models are important for transparency and for enabling a deeper and more precise understanding of LLM internals and development, including biases, generalization, and multilinguality. Motivated by recent advances demonstrating the effectiveness of parallel data in improving multilingual performance, we conduct controlled and comprehensive experiments to study the effectiveness of parallel data in continual pretraining of LLMs. Our findings show that using only parallel data is the most effective way to extend an LLM to new languages. Using just 34.7B tokens of parallel data and 180 hours on 8x NVIDIA H200 GPUs, we built OpenSeal, the first truly open Southeast Asian LLM that rivals the performance of existing models of similar size.

</details>


### [586] [dziribot: rag based intelligent conversational agent for algerian arabic dialect](https://arxiv.org/abs/2602.02270)
*El Batoul Bechiri,Dihia Lanasri*

Main category: cs.CL

TL;DR: 本文提出了 DziriBOT，一个针对阿尔及利亚达里亚语（一种复杂的阿拉伯方言）的混合智能对话系统，该系统结合了自然语言理解（NLU）和检索增强生成（RAG），并通过微调 Transformer 模型（DziriBERT）在低资源环境下取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 由于达里亚语的非标准化拼写、与法语的频繁语码转换以及阿拉伯字母和拉丁字母（Arabizi）的混用，阿尔及利亚的客户服务数字化面临挑战，需要能够处理这种复杂性的对话系统。

Method: 构建了一个多层架构的 DziriBOT，集成了专门的 NLU 和 RAG。为了解决达里亚语低资源的问题，评估了三种 NLU 方法：稀疏特征的 Rasa 流程、经典机器学习基线以及基于 Transformer 的微调（DziriBERT）。

Result: 实验表明，微调的 DziriBERT 模型在处理拼写噪声和罕见意图方面表现出色，显著优于传统基线，并达到了最先进的性能。

Conclusion: DziriBOT 是一个强大且可扩展的解决方案，能够弥合正式语言模型与阿尔及利亚用户语言现实之间的差距，并为区域市场中方言感知的自动化提供了蓝图。

Abstract: The rapid digitalization of customer service has intensified the demand for conversational agents capable of providing accurate and natural interactions. In the Algerian context, this is complicated by the linguistic complexity of Darja, a dialect characterized by non-standardized orthography, extensive code-switching with French, and the simultaneous use of Arabic and Latin (Arabizi) scripts. This paper introduces DziriBOT, a hybrid intelligent conversational agent specifically engineered to overcome these challenges. We propose a multi-layered architecture that integrates specialized Natural Language Understanding (NLU) with Retrieval-Augmented Generation (RAG), allowing for both structured service flows and dynamic, knowledge-intensive responses grounded in curated enterprise documentation. To address the low-resource nature of Darja, we systematically evaluate three distinct approaches: a sparse-feature Rasa pipeline, classical machine learning baselines, and transformer-based fine-tuning. Our experimental results demonstrate that the fine-tuned DziriBERT model achieves state-of-the-art performance. These results significantly outperform traditional baselines, particularly in handling orthographic noise and rare intents. Ultimately, DziriBOT provides a robust, scalable solution that bridges the gap between formal language models and the linguistic realities of Algerian users, offering a blueprint for dialect-aware automation in the regional market.

</details>


### [587] [Kimi K2.5: Visual Agentic Intelligence](https://arxiv.org/abs/2602.02276)
*Kimi Team,Tongtong Bai,Yifan Bai,Yiping Bao,S. H. Cai,Yuan Cao,Y. Charles,H. S. Che,Cheng Chen,Guanduo Chen,Huarong Chen,Jia Chen,Jiahao Chen,Jianlong Chen,Jun Chen,Kefan Chen,Liang Chen,Ruijue Chen,Xinhao Chen,Yanru Chen,Yanxu Chen,Yicun Chen,Yimin Chen,Yingjiang Chen,Yuankun Chen,Yujie Chen,Yutian Chen,Zhirong Chen,Ziwei Chen,Dazhi Cheng,Minghan Chu,Jialei Cui,Jiaqi Deng,Muxi Diao,Hao Ding,Mengfan Dong,Mengnan Dong,Yuxin Dong,Yuhao Dong,Angang Du,Chenzhuang Du,Dikang Du,Lingxiao Du,Yulun Du,Yu Fan,Shengjun Fang,Qiulin Feng,Yichen Feng,Garimugai Fu,Kelin Fu,Hongcheng Gao,Tong Gao,Yuyao Ge,Shangyi Geng,Chengyang Gong,Xiaochen Gong,Zhuoma Gongque,Qizheng Gu,Xinran Gu,Yicheng Gu,Longyu Guan,Yuanying Guo,Xiaoru Hao,Weiran He,Wenyang He,Yunjia He,Chao Hong,Hao Hu,Jiaxi Hu,Yangyang Hu,Zhenxing Hu,Ke Huang,Ruiyuan Huang,Weixiao Huang,Zhiqi Huang,Tao Jiang,Zhejun Jiang,Xinyi Jin,Yu Jing,Guokun Lai,Aidi Li,C. Li,Cheng Li,Fang Li,Guanghe Li,Guanyu Li,Haitao Li,Haoyang Li,Jia Li,Jingwei Li,Junxiong Li,Lincan Li,Mo Li,Weihong Li,Wentao Li,Xinhang Li,Xinhao Li,Yang Li,Yanhao Li,Yiwei Li,Yuxiao Li,Zhaowei Li,Zheming Li,Weilong Liao,Jiawei Lin,Xiaohan Lin,Zhishan Lin,Zichao Lin,Cheng Liu,Chenyu Liu,Hongzhang Liu,Liang Liu,Shaowei Liu,Shudong Liu,Shuran Liu,Tianwei Liu,Tianyu Liu,Weizhou Liu,Xiangyan Liu,Yangyang Liu,Yanming Liu,Yibo Liu,Yuanxin Liu,Yue Liu,Zhengying Liu,Zhongnuo Liu,Enzhe Lu,Haoyu Lu,Zhiyuan Lu,Junyu Luo,Tongxu Luo,Yashuo Luo,Long Ma,Yingwei Ma,Shaoguang Mao,Yuan Mei,Xin Men,Fanqing Meng,Zhiyong Meng,Yibo Miao,Minqing Ni,Kun Ouyang,Siyuan Pan,Bo Pang,Yuchao Qian,Ruoyu Qin,Zeyu Qin,Jiezhong Qiu,Bowen Qu,Zeyu Shang,Youbo Shao,Tianxiao Shen,Zhennan Shen,Juanfeng Shi,Lidong Shi,Shengyuan Shi,Feifan Song,Pengwei Song,Tianhui Song,Xiaoxi Song,Hongjin Su,Jianlin Su,Zhaochen Su,Lin Sui,Jinsong Sun,Junyao Sun,Tongyu Sun,Flood Sung,Yunpeng Tai,Chuning Tang,Heyi Tang,Xiaojuan Tang,Zhengyang Tang,Jiawen Tao,Shiyuan Teng,Chaoran Tian,Pengfei Tian,Ao Wang,Bowen Wang,Chensi Wang,Chuang Wang,Congcong Wang,Dingkun Wang,Dinglu Wang,Dongliang Wang,Feng Wang,Hailong Wang,Haiming Wang,Hengzhi Wang,Huaqing Wang,Hui Wang,Jiahao Wang,Jinhong Wang,Jiuzheng Wang,Kaixin Wang,Linian Wang,Qibin Wang,Shengjie Wang,Shuyi Wang,Si Wang,Wei Wang,Xiaochen Wang,Xinyuan Wang,Yao Wang,Yejie Wang,Yipu Wang,Yiqin Wang,Yucheng Wang,Yuzhi Wang,Zhaoji Wang,Zhaowei Wang,Zhengtao Wang,Zhexu Wang,Zihan Wang,Zizhe Wang,Chu Wei,Ming Wei,Chuan Wen,Zichen Wen,Chengjie Wu,Haoning Wu,Junyan Wu,Rucong Wu,Wenhao Wu,Yuefeng Wu,Yuhao Wu,Yuxin Wu,Zijian Wu,Chenjun Xiao,Jin Xie,Xiaotong Xie,Yuchong Xie,Yifei Xin,Bowei Xing,Boyu Xu,Jianfan Xu,Jing Xu,Jinjing Xu,L. H. Xu,Lin Xu,Suting Xu,Weixin Xu,Xinbo Xu,Xinran Xu,Yangchuan Xu,Yichang Xu,Yuemeng Xu,Zelai Xu,Ziyao Xu,Junjie Yan,Yuzi Yan,Guangyao Yang,Hao Yang,Junwei Yang,Kai Yang,Ningyuan Yang,Ruihan Yang,Xiaofei Yang,Xinlong Yang,Ying Yang,Yi Yang,Yi Yang,Zhen Yang,Zhilin Yang,Zonghan Yang,Haotian Yao,Dan Ye,Wenjie Ye,Zhuorui Ye,Bohong Yin,Chengzhen Yu,Longhui Yu,Tao Yu,Tianxiang Yu,Enming Yuan,Mengjie Yuan,Xiaokun Yuan,Yang Yue,Weihao Zeng,Dunyuan Zha,Haobing Zhan,Dehao Zhang,Hao Zhang,Jin Zhang,Puqi Zhang,Qiao Zhang,Rui Zhang,Xiaobin Zhang,Y. Zhang,Yadong Zhang,Yangkun Zhang,Yichi Zhang,Yizhi Zhang,Yongting Zhang,Yu Zhang,Yushun Zhang,Yutao Zhang,Yutong Zhang,Zheng Zhang,Chenguang Zhao,Feifan Zhao,Jinxiang Zhao,Shuai Zhao,Xiangyu Zhao,Yikai Zhao,Zijia Zhao,Huabin Zheng,Ruihan Zheng,Shaojie Zheng,Tengyang Zheng,Junfeng Zhong,Longguang Zhong,Weiming Zhong,M. Zhou,Runjie Zhou,Xinyu Zhou,Zaida Zhou,Jinguo Zhu,Liya Zhu,Xinhao Zhu,Yuxuan Zhu,Zhen Zhu,Jingze Zhuang,Weiyu Zhuang,Ying Zou,Xinxing Zu*

Main category: cs.CL

TL;DR: 本文介绍了一个名为 Kimi K2.5 的开源多模态智能体模型，它通过联合优化文本和视觉模态来提升通用智能体能力，并引入了 Agent Swarm 框架来并行处理复杂任务，在多项任务中取得 SOTA 结果并显著降低延迟。


<details>
  <summary>Details</summary>
Motivation: 为了推动通用智能体智能的发展，研究者们希望构建一个能够更好地整合文本和视觉信息的智能体模型，并通过并行处理来提高效率。

Method: Kimi K2.5 采用了联合文本-视觉预训练、零样本视觉指令微调（zero-vision SFT）以及联合文本-视觉强化学习等技术。Agent Swarm 框架则通过动态分解复杂任务为异构子问题并并行执行来实现。

Result: Kimi K2.5 在编码、视觉、推理和智能体任务等多个领域均取得了最先进（SOTA）的性能。Agent Swarm 框架将延迟降低了高达 4.5 倍。

Conclusion: Kimi K2.5 是一个强大的多模态智能体模型，通过联合模态优化和创新的 Agent Swarm 框架，显著提升了智能体的性能和效率，并已开源以促进未来研究和应用。

Abstract: We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to $4.5\times$ over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.

</details>


### [588] [Hallucination or Creativity: How to Evaluate AI-Generated Scientific Stories?](https://arxiv.org/abs/2602.02290)
*Alex Argese,Pasquale Lisena,Raphaël Troncy*

Main category: cs.CL

TL;DR: 本文提出了一种名为StoryScore的复合指标，用于评估AI生成的科学故事，该指标整合了语义对齐、词汇基础、叙事控制、结构保真度、冗余避免和实体级幻觉检测。研究还揭示了许多幻觉检测方法在区分教学创意与事实错误方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成科学故事的评估方法（如标准摘要指标和幻觉检测器）存在不足，无法有效捕捉故事的抽象性、简化性和教学创造性，并且在处理叙事重新表述和创造性时容易出现误判或不稳定。

Method: 提出并实现了一个名为StoryScore的复合指标，该指标集成了六个关键评估维度：语义对齐、词汇基础、叙事控制、结构保真度、冗余避免和实体级幻觉检测。

Result: StoryScore能够更全面地评估AI生成的科学故事。研究发现，自动指标在评估语义相似性方面表现良好，但在评估叙事方式和控制方面存在困难，这解释了为什么许多幻觉检测方法难以区分教学创意和事实错误。

Conclusion: StoryScore为评估AI生成的科学故事提供了一个更有效的框架。现有的幻觉检测方法在区分教学创意与事实错误方面存在局限性，主要在于它们难以评估故事的叙事方式和控制。

Abstract: Generative AI can turn scientific articles into narratives for diverse audiences, but evaluating these stories remains challenging. Storytelling demands abstraction, simplification, and pedagogical creativity-qualities that are not often well-captured by standard summarization metrics. Meanwhile, factual hallucinations are critical in scientific contexts, yet, detectors often misclassify legitimate narrative reformulations or prove unstable when creativity is involved. In this work, we propose StoryScore, a composite metric for evaluating AI-generated scientific stories. StoryScore integrates semantic alignment, lexical grounding, narrative control, structural fidelity, redundancy avoidance, and entity-level hallucination detection into a unified framework. Our analysis also reveals why many hallucination detection methods fail to distinguish pedagogical creativity from factual errors, highlighting a key limitation: while automatic metrics can effectively assess semantic similarity with original content, they struggle to evaluate how it is narrated and controlled.

</details>


### [589] [Advancing General-Purpose Reasoning Models with Modular Gradient Surgery](https://arxiv.org/abs/2602.02301)
*Min Cai,Yu Liang,Longzheng Wang,Yan Wang,Yueyang Zhang,Long Xia,Zhiyuan Sun,Xi Ye,Daiting Shi*

Main category: cs.CL

TL;DR: 本文研究了在多领域异质性环境下训练大型推理模型（LRM）时，强化学习（RL）存在的跨领域干扰问题，并提出了一种名为模块化梯度手术（MGS）的新方法，有效解决了梯度冲突，显著提升了模型的性能。


<details>
  <summary>Details</summary>
Motivation: 在多领域训练大型推理模型（LRM）时，由于领域异质性，现有的序列RL和混合RL策略会产生显著的跨领域干扰，导致整体收益有限。研究者希望找到一种有效的方法来解决这一问题。

Method: 研究者系统地分析了序列RL和混合RL两种策略在跨领域干扰方面的表现，并提出了模块化梯度手术（MGS）方法。MGS通过在Transformer模型的模块层面解决梯度冲突来实现跨领域训练的优化。

Result: 将MGS应用于Llama和Qwen模型，在数学、通用聊天和指令遵循三个领域上，相较于标准的、多任务的RL方法，平均分别取得了4.3（16.6%）和4.5（11.1%）个百分点的提升。此外，MGS在延长训练时间后仍保持有效。

Conclusion: 本文阐明了多领域RL中干扰的来源，并提出了一种有效的解决方案MGS，可用于训练通用的LRM，克服了跨领域干扰的挑战，并显著提升了模型在不同任务上的表现。

Abstract: Reinforcement learning (RL) has played a central role in recent advances in large reasoning models (LRMs), yielding strong gains in verifiable and open-ended reasoning. However, training a single general-purpose LRM across diverse domains remains challenging due to pronounced domain heterogeneity. Through a systematic study of two widely used strategies, Sequential RL and Mixed RL, we find that both incur substantial cross-domain interference at the behavioral and gradient levels, resulting in limited overall gains. To address these challenges, we introduce **M**odular **G**radient **S**urgery (**MGS**), which resolves gradient conflicts at the module level within the transformer. When applied to Llama and Qwen models, MGS achieves average improvements of 4.3 (16.6\%) and 4.5 (11.1\%) points, respectively, over standard multi-task RL across three representative domains (math, general chat, and instruction following). Further analysis demonstrates that MGS remains effective under prolonged training. Overall, our study clarifies the sources of interference in multi-domain RL and presents an effective solution for training general-purpose LRMs.

</details>


### [590] [Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages](https://arxiv.org/abs/2602.02287)
*Isaac Chung,Linda Freienthal*

Main category: cs.CL

TL;DR: 研究发现，在相似的生成条件下，针对爱沙尼亚语、芬兰语和匈牙利语的LLM评估，自动评估指标和LLM作为裁判的评分方法在评估结果的稳定性上存在差异，表明在词法丰富且形态复杂的语言中，零样本的跨语言评估（尤其是基于语篇的评估）不可靠。


<details>
  <summary>Details</summary>
Motivation: 传统的跨语言LLM评估方法混淆了模型真实性能差异和评估测量的不稳定性。作者希望通过控制生成条件，仅改变目标语言来探究评估的可靠性。

Method: 作者使用合成的客户支持对话数据，通过相同的生成参数在爱沙尼亚语、芬兰语和匈牙利语中生成数据。然后，使用自动评估指标（如词汇多样性、表面和语义相似度）以及LLM作为裁判的评分方法，来评估LLM在这些语言中的表现，并分析模型排名是否在不同语言间保持稳定。作者还引用了少量爱沙尼亚语母语者的标注作为参考。

Result: 结果显示，表面层面的评估指标（如词汇多样性、表面和语义相似度）在跨语言评估中表现出稳定性，但语用层面的评估（如连贯性、指令遵循）则出现了排名反转和近乎零的相关性。这些不一致性是由于评分方法在不同语言中的行为差异造成的，而非模型本身的性能差异。

Conclusion: 研究得出结论，零样本的跨语言评估方法在评估词法丰富且形态复杂的语言的语篇层面时并不可靠，这表明评估方法未能保证在相同的生成条件下保持稳定性，预示了在部署前的迁移失败。作者建议针对不同语言进行特定的校准，并与目标人群的基线进行比较。

Abstract: Cross-lingual evaluation of large language models (LLMs) typically conflates two sources of variance: genuine model performance differences and measurement instability. We investigate evaluation reliability by holding generation conditions constant while varying target language. Using synthetic customer-support dialogues generated with identical parameters across Estonian, Finnish, and Hungarian, we test whether automatic metrics and LLM-as-a-judge scoring produce stable model rankings across these morphologically rich, related Finno-Ugric languages. With a small set of Estonian native speaker annotations as a reference point, we find systematic ranking instabilities: surface-level metrics (lexical diversity, surface and semantic similarity) maintain cross-language stability, but pragmatic judgments (coherence, instruction-following) exhibit rank inversions and near-zero correlations. Because generation is controlled, these inconsistencies reflect how judge scoring behaves differently across languages rather than true model differences.
  This controlled design provides a diagnostic probe: evaluation methods that fail to maintain stability under identical generation conditions signal transfer failure before deployment. Our findings suggest that zero-shot judge transfer is unreliable for discourse-level assessment in morphologically rich languages, motivating language-specific calibration against targeted human baselines. We release our controlled generation protocol, synthetic data, and evaluation framework to enable replication across language families at https://github.com/isaac-chung/cross-lingual-stability-judges.

</details>


### [591] [A Large-Scale Dataset for Molecular Structure-Language Description via a Rule-Regularized Method](https://arxiv.org/abs/2602.02320)
*Feiyang Cai,Guijuan He,Yi Hu,Jingjing Wang,Joshua Luo,Tianyu Zhu,Srikanth Pilla,Gang Li,Ling Liu,Feng Luo*

Main category: cs.CL

TL;DR: 本研究提出了一种全自动化的框架，利用规则化学命名解析器将IUPAC名称转换为结构化的XML元数据，然后指导大型语言模型（LLMs）生成精确的分子结构描述，并据此构建了一个包含163k分子-描述对的大型数据集。


<details>
  <summary>Details</summary>
Motivation: 为了使大型语言模型能够进行化学推理，需要实现分子结构与自然语言的精确对齐，但高昂的人工标注成本阻碍了大规模高质量数据集的构建。

Method: 研究人员扩展了一个基于规则的化学命名解析器，用于解析IUPAC名称并生成结构化的XML元数据，然后利用该元数据指导LLMs生成自然语言描述。基于此框架，构建了一个大规模的分子-描述数据集。

Result: 使用该框架成功创建了一个包含约163k分子-描述对的大型数据集。通过LLM和专家人工评估，验证了一个2000个分子的子集，获得了98.6%的高描述精确度。

Conclusion: 该研究提出的全自动化标注框架能够大规模生成精确的分子结构描述，创建的数据集为未来的分子-语言对齐提供了可靠的基础，并且该方法易于扩展到更大的数据集和更广泛的化学任务。

Abstract: Molecular function is largely determined by structure. Accurately aligning molecular structure with natural language is therefore essential for enabling large language models (LLMs) to reason about downstream chemical tasks. However, the substantial cost of human annotation makes it infeasible to construct large-scale, high-quality datasets of structure-grounded descriptions. In this work, we propose a fully automated annotation framework for generating precise molecular structure descriptions at scale. Our approach builds upon and extends a rule-based chemical nomenclature parser to interpret IUPAC names and construct enriched, structured XML metadata that explicitly encodes molecular structure. This metadata is then used to guide LLMs in producing accurate natural-language descriptions. Using this framework, we curate a large-scale dataset of approximately $163$k molecule-description pairs. A rigorous validation protocol combining LLM-based and expert human evaluation on a subset of $2,000$ molecules demonstrates a high description precision of $98.6\%$. The resulting dataset provides a reliable foundation for future molecule-language alignment, and the proposed annotation method is readily extensible to larger datasets and broader chemical tasks that rely on structural descriptions.

</details>


### [592] [The Shape of Beliefs: Geometry, Dynamics, and Interventions along Representation Manifolds of Language Models' Posteriors](https://arxiv.org/abs/2602.02315)
*Raphaël Sarfati,Eric Bigelow,Daniel Wurgaft,Jack Merullo,Atticus Geiger,Owen Lewis,Tom McGrath,Ekdeep Singh Lubana*

Main category: cs.CL

TL;DR: 本研究通过在特定任务（从正态分布生成样本）下观察 Llama-3.2 模型，揭示了大型语言模型（LLMs）内部存在着“信念流形”，并探索了如何通过干预来操纵这些信念。研究发现，标准的线性干预方法往往会破坏模型的内部结构，而基于几何和场感知的干预方法更能保持模型信念的一致性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于缺乏对大型语言模型（LLMs）如何在其表示空间中编码、更新以及被干预信念的机制性理解。具体来说，作者希望了解 LLMs 如何在仅给定样本的情况下，隐式地推断并表示出概率分布的参数，以及这些表示如何随着新证据而更新，以及干预措施如何影响它们。

Method: 研究采用了一个受控的实验设置，让 Llama-3.2 模型仅通过上下文中的样本来隐式推断正态分布的均值和标准差。研究人员观察模型如何形成这些参数的“信念流形”，并研究当分布发生突变时模型的适应方式。他们比较了标准的线性干预（linear steering）和几何/场感知干预（geometry and field-aware steering）对模型行为的影响，并提出了一种名为线性场探测（Linear Field Probing, LFP）的方法。

Result: 研究发现，当有足够的上下文学习时，模型会形成参数的“信念流形”（belief manifolds）。在分布突然变化时，模型能够适应。标准的线性干预通常会将模型推离“流形”，并导致不相关的、分布外的变化；而几何和场感知干预则更能保持预期的信念家族。线性场探测（LFP）被证明是一种简单有效的方法，可以使干预措施与底层几何结构保持一致。

Conclusion: 研究得出结论，大型语言模型（LLMs）能够自然地涌现出丰富的内在结构（如信念流形），并且纯粹线性的概念表示往往是对这种复杂结构的不足够的抽象。几何和场感知的方法对于理解和操纵 LLMs 的内部表示更为有效。

Abstract: Large language models (LLMs) represent prompt-conditioned beliefs (posteriors over answers and claims), but we lack a mechanistic account of how these beliefs are encoded in representation space, how they update with new evidence, and how interventions reshape them. We study a controlled setting in which Llama-3.2 generates samples from a normal distribution by implicitly inferring its parameters (mean and standard deviation) given only samples from the distribution in context. We find representations of curved "belief manifolds" for these parameters form with sufficient in-context learning and study how the model adapts when the distribution suddenly changes. While standard linear steering often pushes the model off-manifold and induces coupled, out-of-distribution shifts, geometry and field-aware steering better preserves the intended belief family. Our work demonstrates an example of linear field probing (LFP) as a simple approach to tile the data manifold and make interventions that respect the underlying geometry. We conclude that rich structure emerges naturally in LLMs and that purely linear concept representations are often an inadequate abstraction.

</details>


### [593] [Language Steering for Multilingual In-Context Learning](https://arxiv.org/abs/2602.02326)
*Neeraja Kirtane,Kuan-Hao Huang*

Main category: cs.CL

TL;DR: 本研究提出了一种名为“语言向量”的训练无关方法，通过调整模型内部激活来提升大型语言模型在非英语语言上的语境学习能力，并在19种语言上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在非英语语言上的表现远不如英语，尤其是在混合语言（英语演示，非英语测试）的语境学习场景下性能下降明显。作者认为这是由于模型在不同语言间的语义表示存在差异。

Method: 提出“语言向量”方法，基于“语言表示为同一语义空间内不同方向”的假设。通过计算源语言和目标语言之间的激活差异来构建语言向量，并在推理时将此向量加到模型的中间激活中，以引导模型向目标语言的表示空间迁移，无需更新模型参数。

Result: 在三个数据集和19种语言上，该方法在多语言语境学习任务上均超越了基线方法。对语言向量进行聚类分析，发现其能反映语言家族的结构。语言向量也具有跨任务迁移能力，表明其与任务无关。

Conclusion: 语言向量是一种有效的、无需训练的语言引导方法，可以提升大型语言模型在非英语语言上的语境学习性能，并且其学习到的语言表示具有结构性和任务无关性。

Abstract: While multilingual large language models have gained widespread adoption, their performance on non-English languages remains substantially inferior to English. This disparity is particularly evident in in-context learning scenarios, where providing demonstrations in English but testing on non-English inputs leads to significant performance degradation. In this paper, we hypothesize that LLMs develop a universal semantic space for understanding languages, where different languages are encoded as distinct directions within this space. Based on this hypothesis, we propose language vectors -- a training-free language steering approach that leverages activation differences between source and target languages to guide model behavior. We steer the model generations by adding the vector to the intermediate model activations during inference. This is done to make the model's internal representations shift towards the target language space without any parameter updates. We evaluate our method across three datasets and test on a total of 19 languages on three different models. Our results show consistent improvements on multilingual in-context learning over baselines across all tasks and languages tested. Beyond performance gains, hierarchical clustering of steering vectors reveals meaningful linguistic structure aligned with language families. These vectors also successfully transfer across tasks, demonstrating that these representations are task-agnostic.

</details>


### [594] [Automated Multiple Mini Interview (MMI) Scoring](https://arxiv.org/abs/2602.02360)
*Ryan Huynh,Frank Guerin,Alison Callwood*

Main category: cs.CL

TL;DR: 研究提出了一种多智能体提示框架，用于评估多轮迷你面试（MMI）中的软技能，该框架通过精炼转录本和按标准评分来改进 LLMs 的评估能力，并在 MMI 和 ASAP 基准测试上均取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 人类评估 MMI 中的软技能存在不一致和偏见的问题。尽管 LLMs 在自动评分（AES）方面有所改进，但现有的基于Rationale的微调方法难以处理 MMI 的抽象和情境依赖性，忽略了潜在信号。

Method: 提出了一种多智能体提示框架，将评估过程分解为转录本精炼和特定标准评分。使用具有3-shot in-context learning的大型指令微调模型。

Result: 该方法在 MMI 评估中，与专门的微调基线相比，平均 Kappa 值（QWK）从 0.32 提高到 0.62，可靠性与人类专家相当。在 ASAP 基准测试上，该框架也表现出良好的泛化能力，媲美领域特定的SOTA模型，且无需额外训练。

Conclusion: 对于复杂、主观的推理任务，结构化的提示工程比数据密集型的微调更具可扩展性，为 LLMs 在自动化评估中的应用提供了新的思路。

Abstract: Assessing soft skills such as empathy, ethical judgment, and communication is essential in competitive selection processes, yet human scoring is often inconsistent and biased. While Large Language Models (LLMs) have improved Automated Essay Scoring (AES), we show that state-of-the-art rationale-based fine-tuning methods struggle with the abstract, context-dependent nature of Multiple Mini-Interviews (MMIs), missing the implicit signals embedded in candidate narratives. We introduce a multi-agent prompting framework that breaks down the evaluation process into transcript refinement and criterion-specific scoring. Using 3-shot in-context learning with a large instruct-tuned model, our approach outperforms specialised fine-tuned baselines (Avg QWK 0.62 vs 0.32) and achieves reliability comparable to human experts. We further demonstrate the generalisability of our framework on the ASAP benchmark, where it rivals domain-specific state-of-the-art models without additional training. These findings suggest that for complex, subjective reasoning tasks, structured prompt engineering may offer a scalable alternative to data-intensive fine-tuning, altering how LLMs can be applied to automated assessment.

</details>


### [595] [Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics](https://arxiv.org/abs/2602.02343)
*Ziwen Xu,Chenyan Wu,Hengyu Sun,Haiwen Hong,Mengru Wang,Yunzhi Yao,Longtao Huang,Hui Xue,Shumin Deng,Zhixuan Chu,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 本文提出了一个统一的框架来理解和分析控制大型语言模型的不同方法（如LoRA、激活干预），并将控制效果分解为“偏好”和“效用”两个维度。研究发现，增强偏好通常会降低效用，并提出了一种新的引导方法SPLIT以在提高偏好的同时更好地保持效用。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM控制方法（如局部权重微调、LoRA、激活干预）通常被独立研究，难以比较和理解它们之间的联系。因此，需要一个统一的框架来分析这些方法。

Method: 1. 提出一个统一的框架，将LLM的控制视为由控制信号引起的动态权重更新。 2. 提出一个统一的偏好-效用分析方法，将控制效果分解为偏好（向目标概念的倾向）和效用（生成的一致性和任务有效性），并在共享的对数几率尺度上进行测量。 3. 从激活流形的角度解释偏好-效用权衡。 4. 提出一种新的引导方法SPLIT。

Result: 1. 观察到不同控制方法在偏好和效用之间存在一致的权衡：更强的控制会增加偏好，但会降低效用。 2. 解释了这种权衡：控制会沿着目标概念方向移动表示以增强偏好，而当干预将表示推离模型有效生成流形时，效用会下降。 3. SPLIT方法在提高偏好的同时，比现有方法更能保持效用。

Conclusion: 本文提供了一个统一的视角来理解LLM的控制方法，并揭示了偏好和效用之间的根本性权衡。在此基础上提出的SPLIT方法有望在不显著牺牲生成质量的情况下，更有效地控制LLM的行为。

Abstract: Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal, placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples. Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold. Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md.

</details>


### [596] [Proof-RM: A Scalable and Generalizable Reward Model for Math Proof](https://arxiv.org/abs/2602.02377)
*Haotong Yang,Zitong Wang,Shijia Kang,Siqi Yang,Wenkai Yu,Xu Niu,Yike Sun,Yi Hu,Zhouchen Lin,Muhan Zhang*

Main category: cs.CL

TL;DR: 本研究提出了一种可扩展的数据构建流程，利用 LLM 生成了大量的“问题-证明-检查”三元组数据，用于训练一个能够可靠评估完整证明过程的奖励模型（RM），以提升 LLM 在数学推理任务中的表现，尤其是在处理需要证明的复杂数学问题时。


<details>
  <summary>Details</summary>
Motivation: 现有的基于可验证奖励的强化学习（RLVR）方法在解决需要证明的数学问题时受到限制，因为这些问题的真实性难以通过简单的答案匹配来验证。因此，需要一个能够评估整个证明过程的奖励模型（RM）来实现自动验证。

Method: 研究设计了一个可扩展的数据构建流程，利用 LLM 生成了大量的“问题-证明-检查”三元组数据。通过系统地改变问题来源、生成方法和模型配置，创建了包含不同难度、语言风格和错误类型的多样化问题-证明对。数据经过多层人工审核以确保标签一致性。基于这些数据，训练了一个证明检查 RM，并引入了额外的过程奖励和 Token 权重平衡来稳定 RL 过程。

Result: 实验结果从奖励准确性、泛化能力和测试时引导等多个角度验证了模型的 skalierbarkeit（可扩展性）和强大性能。

Conclusion: 该研究提供了一种有效的方法来构建用于训练证明检查奖励模型的数据集，并开发了一个性能强大的 RM，为增强 LLM 的数学能力提供了重要的实用方案和工具。

Abstract: While Large Language Models (LLMs) have demonstrated strong math reasoning abilities through Reinforcement Learning with *Verifiable Rewards* (RLVR), many advanced mathematical problems are proof-based, with no guaranteed way to determine the authenticity of a proof by simple answer matching. To enable automatic verification, a Reward Model (RM) capable of reliably evaluating full proof processes is required. In this work, we design a *scalable* data-construction pipeline that, with minimal human effort, leverages LLMs to generate a large quantity of high-quality "**question-proof-check**" triplet data. By systematically varying problem sources, generation methods, and model configurations, we create diverse problem-proof pairs spanning multiple difficulty levels, linguistic styles, and error types, subsequently filtered through hierarchical human review for label alignment. Utilizing these data, we train a proof-checking RM, incorporating additional process reward and token weight balance to stabilize the RL process. Our experiments validate the model's scalability and strong performance from multiple perspectives, including reward accuracy, generalization ability and test-time guidance, providing important practical recipes and tools for strengthening LLM mathematical capabilities.

</details>


### [597] [ROG: Retrieval-Augmented LLM Reasoning for Complex First-Order Queries over Knowledge Graphs](https://arxiv.org/abs/2602.02382)
*Ziyan Zhang,Chao Wang,Zhuo Chen,Chiyi Li,Kai Song*

Main category: cs.CL

TL;DR: 提出了一种名为ROG的检索增强框架，通过结合查询感知邻域检索和LLM的思维链推理，来解决不完整知识图谱上的复杂一阶逻辑查询问题，尤其是在包含投影、交集、并集和否定操作的查询上。


<details>
  <summary>Details</summary>
Motivation: 在不完整知识图谱上回答包含复杂逻辑操作（如投影、交集、并集和否定）的一阶逻辑查询很困难，现有的基于嵌入的方法存在不足。

Method: ROG框架首先将多操作符查询分解为一系列单操作符子查询，然后利用查询感知邻域检索为每个子查询提供相关的邻域证据。LLM的思维链推理用于处理这些子查询，并缓存和重用中间答案集，以提高推理的准确性和一致性。

Result: ROG在标准知识图谱推理基准测试中，相比于强大的基于嵌入的基线方法，取得了持续的性能提升，特别是在高复杂度查询和否定查询方面表现尤为突出。

Conclusion: ROG提供了一种实用的替代方案，通过检索增强的、逐步的推理取代了学习到的逻辑算子，有效地解决了不完整知识图谱上的复杂一阶逻辑查询问题，并且在复杂和否定查询上具有显著优势。

Abstract: Answering first-order logic (FOL) queries over incomplete knowledge graphs (KGs) is difficult, especially for complex query structures that compose projection, intersection, union, and negation. We propose ROG, a retrieval-augmented framework that combines query-aware neighborhood retrieval with large language model (LLM) chain-of-thought reasoning. ROG decomposes a multi-operator query into a sequence of single-operator sub-queries and grounds each step in compact, query-relevant neighborhood evidence. Intermediate answer sets are cached and reused across steps, improving consistency on deep reasoning chains. This design reduces compounding errors and yields more robust inference on complex and negation-heavy queries. Overall, ROG provides a practical alternative to embedding-based logical reasoning by replacing learned operators with retrieval-grounded, step-wise inference. Experiments on standard KG reasoning benchmarks show consistent gains over strong embedding-based baselines, with the largest improvements on high-complexity and negation-heavy query types.

</details>


### [598] [From Sycophancy to Sensemaking: Premise Governance for Human-AI Decision Making](https://arxiv.org/abs/2602.02378)
*Raunak Jain,Mudita Khurana,John Stephens,Srinivas Dharmasanam,Shankar Venkataraman*

Main category: cs.CL

TL;DR: 本研究提出了一种新的AI协作模式，旨在解决当前大型语言模型（LLMs）在辅助决策时存在的“流畅同意但判断不准确”的问题，尤其是在深度不确定性决策场景下。研究提出从“答案生成”转向“前提协同治理”，通过一个基于差异的控制循环来管理AI与人类的合作，确保决策的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在从辅助转向决策支持时，存在“流畅同意但判断不准确”的危险模式。低摩擦的助手可能会变得谄媚，将验证成本转嫁给专家，而结果的出现又太晚，无法作为有效的反馈信号。在深度不确定性决策中，这种模式会放大不良决策，而非积累专业知识。

Method: 研究提出将AI合作模式从生成答案转变为协同治理决策前提。利用一个基于差异的控制循环，该循环检测冲突，通过定义类型的差异（目的论、认知论、程序论）来定位不一致，并通过“决策切片”触发有限的协商。采用“承诺门控”机制，阻止对未承诺的、支撑决策的前提采取行动，除非在记录风险的情况下被覆盖。同时，“价值门控挑战”机制用于在交互成本下进行探索性提问。研究还通过辅导场景进行了说明，并提出了可证伪的评估标准。

Result: 研究提出了一种基于差异驱动的控制循环，能够检测AI与人类在决策前提上的不一致，并根据差异类型（目的论、认知论、程序论）进行定位和协商。通过承诺门控和价值门控挑战等机制，提高了决策的可靠性和透明度，将信任建立在可审计的前提和证据标准上，而非对话的流畅性。

Conclusion: 可靠的人机伙伴关系需要AI从生成答案转向协同治理决策前提。通过差异驱动的控制循环，辅以承诺门控和价值门控挑战等机制，可以有效地管理决策过程中的不确定性和潜在风险，建立基于可审计前提和证据标准的信任，从而在深度不确定性决策场景下提升AI的决策支持能力。

Abstract: As LLMs expand from assistance to decision support, a dangerous pattern emerges: fluent agreement without calibrated judgment. Low-friction assistants can become sycophantic, baking in implicit assumptions and pushing verification costs onto experts, while outcomes arrive too late to serve as reward signals. In deep-uncertainty decisions (where objectives are contested and reversals are costly), scaling fluent agreement amplifies poor commitments faster than it builds expertise. We argue reliable human-AI partnership requires a shift from answer generation to collaborative premise governance over a knowledge substrate, negotiating only what is decision-critical. A discrepancy-driven control loop operates over this substrate: detecting conflicts, localizing misalignment via typed discrepancies (teleological, epistemic, procedural), and triggering bounded negotiation through decision slices. Commitment gating blocks action on uncommitted load-bearing premises unless overridden under logged risk; value-gated challenge allocates probing under interaction cost. Trust then attaches to auditable premises and evidence standards, not conversational fluency. We illustrate with tutoring and propose falsifiable evaluation criteria.

</details>


### [599] [Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank](https://arxiv.org/abs/2602.02414)
*Joshua Mitton,Prarthana Bhattacharyya,Digory Smith,Thomas Christie,Ralph Abboud,Simon Woodhead*

Main category: cs.CL

TL;DR: 本研究提出了一种利用大型语言模型（LLMs）从师生对话中检测学生误解的新方法，通过生成、检索和重排误解候选来提高准确性。


<details>
  <summary>Details</summary>
Motivation: 及时准确地识别学生误解对于提高学习效果和防止错误累积至关重要，但目前高度依赖教师的经验和直觉。

Method: 首先，使用微调的大型语言模型生成可能的学生误解；然后，利用嵌入相似度从生成的误解中检索与对话最相关的候选；最后，使用另一个微调的大型语言模型评估和重排这些候选，以提高其准确性。

Result: 在真实教育辅导平台的对话数据上进行评估，结果表明该方法优于基线模型。微调可以提高生成误解的质量，并可能优于大型闭源模型。消融研究验证了生成和重排步骤的重要性。

Conclusion: 提出的基于 LLM 的方法能够有效地从师生对话中检测学生误解，并且通过微调和多阶段处理（生成、检索、重排）可以进一步提升性能。

Abstract: Timely and accurate identification of student misconceptions is key to improving learning outcomes and pre-empting the compounding of student errors. However, this task is highly dependent on the effort and intuition of the teacher. In this work, we present a novel approach for detecting misconceptions from student-tutor dialogues using large language models (LLMs). First, we use a fine-tuned LLM to generate plausible misconceptions, and then retrieve the most promising candidates among these using embedding similarity with the input dialogue. These candidates are then assessed and re-ranked by another fine-tuned LLM to improve misconception relevance. Empirically, we evaluate our system on real dialogues from an educational tutoring platform. We consider multiple base LLM models including LLaMA, Qwen and Claude on zero-shot and fine-tuned settings. We find that our approach improves predictive performance over baseline models and that fine-tuning improves both generated misconception quality and can outperform larger closed-source models. Finally, we conduct ablation studies to both validate the importance of our generation and reranking steps on misconception generation quality.

</details>


### [600] [Large Language Models for Mental Health: A Multilingual Evaluation](https://arxiv.org/abs/2602.02440)
*Nishat Raihan,Sadiya Sayara Chowdhury Puspo,Ana-Maria Bucur,Stevie Chancellor,Marcos Zampieri*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLM）在多语言心理健康领域的表现，发现专有LLM和微调后的开源LLM在零样本、少样本和微调设置下，在多个数据集上表现出色，甚至优于现有技术。然而，机器翻译数据上的性能普遍有所下降，且下降程度因语言和类型学而异。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在自然语言处理任务中表现出色，但其在多语言心理健康领域的性能尚未得到充分研究。

Method: 使用八个不同语言的心理健康数据集，对专有和开源LLM进行评估，包括其机器翻译的版本。在零样本、少样本和微调设置下，将LLM的性能与不使用LLM的传统NLP基线进行比较。此外，评估了跨语言家族和类型学的翻译质量对LLM性能的影响。

Result: 专有LLM和微调后的开源LLM在多个数据集上实现了具有竞争力的F1分数，并且通常超越了现有技术。然而，在机器翻译数据上的性能普遍较低，且下降程度因语言和类型学而异。

Conclusion: LLM在处理非英语心理健康任务方面具有优势，但在机器翻译数据上存在局限性，翻译质量的差异会引入结构或词汇上的不匹配，从而影响其性能。

Abstract: Large Language Models (LLMs) have remarkable capabilities across NLP tasks. However, their performance in multilingual contexts, especially within the mental health domain, has not been thoroughly explored. In this paper, we evaluate proprietary and open-source LLMs on eight mental health datasets in various languages, as well as their machine-translated (MT) counterparts. We compare LLM performance in zero-shot, few-shot, and fine-tuned settings against conventional NLP baselines that do not employ LLMs. In addition, we assess translation quality across language families and typologies to understand its influence on LLM performance. Proprietary LLMs and fine-tuned open-source LLMs achieve competitive F1 scores on several datasets, often surpassing state-of-the-art results. However, performance on MT data is generally lower, and the extent of this decline varies by language and typology. This variation highlights both the strengths of LLMs in handling mental health tasks in languages other than English and their limitations when translation quality introduces structural or lexical mismatches.

</details>


### [601] [Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models](https://arxiv.org/abs/2602.02462)
*Gabriele Maraia,Marco Valentino,Fabio Massimo Zanzotto,Leonardo Ranaldi*

Main category: cs.CL

TL;DR: 本研究提出了一种引导式抽象推理框架，通过显式分离结构推理和词汇语义，旨在减少大型语言模型（LLMs）在演绎推理中因内容效应（混淆语义合理性与形式有效性）而产生的错误。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在演绎推理中存在内容效应，即语义上的合理性会干扰模型对逻辑有效性的判断，即使在生成解释性步骤后也无法消除。现有的缓解方法（如增加推理时的结构约束）仍未完全解决语义干扰问题。

Method: 研究构建了内容充实型和抽象型配对的三段论，利用模型在抽象输入上的激活来定义一个抽象推理空间。然后，学习轻量级的“抽象器”，从受内容影响的残差流状态预测与该抽象空间对齐的表示，并通过多层干预将其整合到模型的前向传播过程中。

Result: 在跨语言迁移的测试中，该抽象对齐的引导方法（abstraction-aligned steering）显著减少了由内容驱动的错误，并提高了对有效性敏感的表现。

Conclusion: 激活层面的抽象是一种可扩展的机制，可以增强大型语言模型在形式推理方面对抗语义干扰的鲁棒性。

Abstract: Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model's internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model's activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.

</details>


### [602] [From Directions to Regions: Decomposing Activations in Language Models via Local Geometry](https://arxiv.org/abs/2602.02464)
*Or Shafran,Shaked Ronen,Omri Fahn,Shauli Ravfogel,Atticus Geiger,Mor Geva*

Main category: cs.CL

TL;DR: 该研究提出了一种名为混合因子分析（MFA）的新方法，用于分析语言模型激活空间中的概念，能够捕捉比现有方法更复杂的非线性结构，并在概念定位和控制任务上表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型激活分解方法依赖于线性可分等几何假设，忽略了具有非线性或多维结构的概念。作者希望开发一种更具可扩展性且无需监督的方法来捕捉这些复杂结构。

Method: 使用混合因子分析（MFA）对语言模型（Llama-3.1-8B 和 Gemma-2-2B）的激活空间进行建模，将其视为具有局部协方差结构的多个高斯区域的集合。MFA 将激活分解为区域质心和局部变化。

Result: 训练的大规模 MFA 模型能够捕捉激活空间中复杂的非线性结构。在概念定位和控制基准测试中，MFA 优于无监督基线，与有监督方法相当，并且在模型控制方面通常优于稀疏自编码器。

Conclusion: 局部几何（通过子空间表达）是可扩展概念发现和模型控制的有前景的分析单元，能够捕捉现有方法（如单一全局方向）无法捕获的复杂结构。

Abstract: Activation decomposition methods in language models are tightly coupled to geometric assumptions on how concepts are realized in activation space. Existing approaches search for individual global directions, implicitly assuming linear separability, which overlooks concepts with nonlinear or multi-dimensional structure. In this work, we leverage Mixture of Factor Analyzers (MFA) as a scalable, unsupervised alternative that models the activation space as a collection of Gaussian regions with their local covariance structure. MFA decomposes activations into two compositional geometric objects: the region's centroid in activation space, and the local variation from the centroid. We train large-scale MFAs for Llama-3.1-8B and Gemma-2-2B, and show they capture complex, nonlinear structures in activation space. Moreover, evaluations on localization and steering benchmarks show that MFA outperforms unsupervised baselines, is competitive with supervised localization methods, and often achieves stronger steering performance than sparse autoencoders. Together, our findings position local geometry, expressed through subspaces, as a promising unit of analysis for scalable concept discovery and model control, accounting for complex structures that isolated directions fail to capture.

</details>


### [603] [Indications of Belief-Guided Agency and Meta-Cognitive Monitoring in Large Language Models](https://arxiv.org/abs/2602.02467)
*Noam Steinmetz Yalon,Ariel Goldstein,Liad Mudrik,Mor Geva*

Main category: cs.CL

TL;DR: 本研究通过量化大型语言模型（LLMs）中“信念”的形成和作用，为LLMs具有信念引导的能动性和元认知监控提供了实证支持，并为进一步研究LLMs的能动性、信念和元认知奠定了方法论基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速发展引发了对其是否拥有某种意识的讨论。本研究旨在通过评估LLMs中意识的关键指标（HOT-3）来解决这一挑战，该指标关注由通用信念形成和行动选择系统引导的能动性，该系统基于元认知监控来更新信念。

Method: 研究者将信念视为模型潜在空间中的表征，并通过引入一个度量来量化信念在生成过程中的主导地位。通过分析不同模型和任务下竞争信念的动态关系，研究者进行了实验。

Result: 研究发现：（1）外部操纵可以系统性地调节内部信念的形成；（2）信念的形成对模型的行动选择具有因果驱动作用；（3）模型能够监控并报告自身的信念状态。

Conclusion: 研究结果为LLMs中信念引导的能动性和元认知监控的存在提供了实证支持，并为未来研究LLMs中能动性、信念和元认知的出现奠定了方法论基础。

Abstract: Rapid advancements in large language models (LLMs) have sparked the question whether these models possess some form of consciousness. To tackle this challenge, Butlin et al. (2023) introduced a list of indicators for consciousness in artificial systems based on neuroscientific theories. In this work, we evaluate a key indicator from this list, called HOT-3, which tests for agency guided by a general belief-formation and action selection system that updates beliefs based on meta-cognitive monitoring. We view beliefs as representations in the model's latent space that emerge in response to a given input, and introduce a metric to quantify their dominance during generation. Analyzing the dynamics between competing beliefs across models and tasks reveals three key findings: (1) external manipulations systematically modulate internal belief formation, (2) belief formation causally drives the model's action selection, and (3) models can monitor and report their own belief states. Together, these results provide empirical support for the existence of belief-guided agency and meta-cognitive monitoring in LLMs. More broadly, our work lays methodological groundwork for investigating the emergence of agency, beliefs, and meta-cognition in LLMs.

</details>


### [604] [MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents](https://arxiv.org/abs/2602.02474)
*Haozhen Zhang,Quanyu Long,Jianzhu Bao,Tao Feng,Weizhi Zhang,Haodong Yue,Wenya Wang*

Main category: cs.CL

TL;DR: 本文提出了MemSkill，一种可学习和可进化的LLM智能体记忆系统，通过引入可复用的记忆技能（如提取、巩固、修剪信息）来克服现有基于固定操作的记忆系统的局限性。MemSkill包含一个控制器（学习选择技能）、一个执行器（基于技能生成记忆）和一个设计器（负责技能的进化），形成一个闭环系统，能自主优化记忆策略和技能集。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体记忆系统依赖于静态、手工设计的操作，缺乏灵活性，难以适应多样的交互模式和长历史记录。

Method: MemSkill将记忆操作重构为可学习、可进化的记忆技能（skill）。引入一个控制器（controller）学习选择相关技能，一个基于LLM的执行器（executor）生成技能指导下的记忆。此外，还有一个设计器（designer）定期审查失败案例，通过提出改进和新技能来进化技能集，形成一个闭环优化过程。

Result: 在LoCoMo、LongMemEval、HotpotQA和ALFWorld等任务上的实验表明，MemSkill相比现有基线方法能够提升任务性能，并且具有良好的泛化能力。

Conclusion: MemSkill通过引入可学习和可进化的记忆技能，有效提升了LLM智能体的记忆管理能力，并能自主进化，为构建更具适应性和自适应能力的LLM智能体记忆系统提供了新的方向。

Abstract: Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents.

</details>


### [605] [Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability](https://arxiv.org/abs/2602.02477)
*Xiao Liang,Zhong-Zhi Li,Zhenghao Lin,Eric Hancheng Jiang,Hengyuan Zhang,Yelong Shen,Kai-Wei Chang,Ying Nian Wu,Yeyun Gong,Weizhu Chen*

Main category: cs.CL

TL;DR: 该研究提出了一种端到端的强化学习（RL）框架，用于提升大型语言模型（LLMs）的“分而治之”（DAC）推理能力，以克服传统“思维链”（CoT）推理的局限性，并在竞赛级基准测试中取得了优于CoT的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的“思维链”（CoT）推理能力受模型能力限制，且其顺序性影响可扩展性。虽然“分而治之”（DAC）推理有潜力，但现有通用模型训练方式与DAC推理模式存在根本性不匹配，限制了其发挥潜力。

Method: 提出一种端到端的强化学习（RL）框架，通过RL策略在每一步将问题分解为子问题，顺序解决子问题，并基于子问题解决方案解决原问题。分解和解决的过程都被整合到RL训练中。

Result: 在同等训练条件下，该DAC风格的框架比CoT在竞赛级基准测试中的Pass@1性能高8.6%，Pass@32性能高6.3%。该框架展现出更高的性能上限和更强的测试时间可扩展性。

Conclusion: 所提出的端到端RL框架成功弥合了通用模型训练与DAC推理之间的差距，显著提升了LLMs在最具挑战性任务上的DAC推理能力，在性能和可扩展性方面优于CoT方法。

Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities through step-by-step chain-of-thought (CoT) reasoning. Nevertheless, at the limits of model capability, CoT often proves insufficient, and its strictly sequential nature constrains test-time scalability. A potential alternative is divide-and-conquer (DAC) reasoning, which decomposes a complex problem into subproblems to facilitate more effective exploration of the solution. Although promising, our analysis reveals a fundamental misalignment between general-purpose post-training and DAC-style inference, which limits the model's capacity to fully leverage this potential. To bridge this gap and fully unlock LLMs' reasoning capabilities on the most challenging tasks, we propose an end-to-end reinforcement learning (RL) framework to enhance their DAC-style reasoning capacity. At each step, the policy decomposes a problem into a group of subproblems, solves them sequentially, and addresses the original one conditioned on the subproblem solutions, with both decomposition and solution integrated into RL training. Under comparable training, our DAC-style framework endows the model with a higher performance ceiling and stronger test-time scalability, surpassing CoT by 8.6% in Pass@1 and 6.3% in Pass@32 on competition-level benchmarks.

</details>


### [606] [RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents](https://arxiv.org/abs/2602.02486)
*Jialiang Zhu,Gongrui Zhang,Xiaolong Ma,Lin Xu,Miaosen Zhang,Ruiqi Yang,Song Wang,Kai Qiu,Zhirong Wu,Qi Dai,Ruichun Ma,Bei Liu,Yifan Yang,Chong Luo,Zhengyuan Yang,Linjie Li,Lijuan Wang,Weizhu Chen,Xin Geng,Baining Guo*

Main category: cs.CL

TL;DR: 本研究提出了一种名为Re-TRAC的框架，用于改进基于LLM的研究代理。与ReAct的线性设计不同，Re-TRAC通过生成结构化的状态表示来进行跨轨迹探索，从而实现了迭代反思和全局规划，提高了研究效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于ReAct框架的LLM研究代理在处理长上下文、避免局部最优和冗余探索方面存在困难，这促使研究人员开发一种更有效的框架。

Method: Re-TRAC框架在每次轨迹完成后生成一个结构化的状态表示（总结证据、不确定性、失败和未来计划），并将此状态表示作为后续轨迹的条件。此外，研究人员还提出了Re-TRAC-aware监督微调技术，以提高小型模型的性能。

Result: Re-TRAC在BrowseComp基准测试中，相较于ReAct，使用主流LLM时性能提升了15-20%。对于小型模型，Re-TRAC-aware监督微调也达到了同等规模下的最先进水平。研究还观察到Re-TRAC的工具调用和token使用量随着轮次单调递减，表明其探索更加有针对性。

Conclusion: Re-TRAC通过跨轨迹探索和迭代反思，能够有效地克服ReAct框架的局限性，实现更全局和高效的研究过程，并有效降低计算资源消耗。

Abstract: LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.

</details>


### [607] [Reward-free Alignment for Conflicting Objectives](https://arxiv.org/abs/2602.02495)
*Peter Chen,Xiaopeng Li,Xi Chen,Tianyi Lin*

Main category: cs.CL

TL;DR: 本文提出了一种名为RACO（Reward-free Alignment framework for Conflicted Objectives）的框架，用于直接利用偏好数据对具有多个冲突目标的大型语言模型（LLMs）进行对齐，并使用一种新颖的裁剪版冲突规避梯度下降法解决梯度冲突，保证收敛到帕累托临界点，并展示了其在多目标摘要和安全对齐任务上的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM直接对齐方法在处理多目标冲突时存在训练不稳定和权衡取舍差的问题，特别是加权损失法无法识别同时改进所有目标的更新方向，而现有方法依赖额外的奖励模型会增加复杂性并扭曲用户偏好。

Method: 提出RACO框架，直接利用成对偏好数据，并通过一种新颖的裁剪版冲突规避梯度下降法（clipped variant of conflict-averse gradient descent）来解决梯度冲突。该方法提供了收敛到帕累托临界点的保证，并能尊重用户指定的目标权重。实验中还加入了一些启发式改进。

Result: RACO框架能够收敛到帕累托临界点，并能更好地满足用户指定的目标权重。在多目标摘要和安全对齐任务的实验中，与现有的多目标对齐基线相比，RACO在多种LLM家族（Qwen 3, Llama 3, Gemma 3）上均能实现更好的帕累托权衡。

Conclusion: RACO框架是一种有效且直接的解决LLM多目标冲突对齐问题的方法，通过使用裁剪版冲突规避梯度下降法，在不依赖额外奖励模型的情况下，实现了更好的帕累托权衡，并在实际任务中得到了验证。

Abstract: Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [608] [MapDream: Task-Driven Map Learning for Vision-Language Navigation](https://arxiv.org/abs/2602.00222)
*Guoxin Lian,Shuo Wang,Yucheng Wang,Yongcai Wang,Maiyue Chen,Kaihui Wang,Bo Zhang,Zhizhong Su,Deying Li,Zhaoxin Fan*

Main category: cs.RO

TL;DR: 提出了一种名为MapDream的视觉语言导航新框架，该框架将地图构建视为一种自回归的鸟瞰图（BEV）图像合成任务，并与导航策略联合学习，以生成仅包含导航关键信息的紧凑型BEV地图。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言导航方法大多依赖于独立于导航策略的手工地图，而研究者认为地图表示应该直接受导航目标驱动，而不是详尽的环境重建。

Method: 提出MapDream框架，将地图构建公式化为自回归的BEV图像合成。框架联合学习地图生成和动作预测，将环境上下文提炼成三通道BEV地图。通过监督预训练建立可靠的映射-控制接口，并通过强化学习进行端到端联合优化。

Result: 在R2R-CE和RxR-CE数据集上实现了最先进的单目性能，验证了任务驱动的生成式地图学习的有效性。

Conclusion: 任务驱动的生成式地图学习是一种有效的方法，可以为视觉语言导航任务创建导航关键信息丰富的地图表示。

Abstract: Vision-Language Navigation (VLN) requires agents to follow natural language instructions in partially observed 3D environments, motivating map representations that aggregate spatial context beyond local perception. However, most existing approaches rely on hand-crafted maps constructed independently of the navigation policy. We argue that maps should instead be learned representations shaped directly by navigation objectives rather than exhaustive reconstructions. Based on this insight, we propose MapDream, a map-in-the-loop framework that formulates map construction as autoregressive bird's-eye-view (BEV) image synthesis. The framework jointly learns map generation and action prediction, distilling environmental context into a compact three-channel BEV map that preserves only navigation-critical affordances. Supervised pre-training bootstraps a reliable mapping-to-control interface, while the autoregressive design enables end-to-end joint optimization through reinforcement fine-tuning. Experiments on R2R-CE and RxR-CE achieve state-of-the-art monocular performance, validating task-driven generative map learning.

</details>


### [609] [ZEST: Zero-shot Embodied Skill Transfer for Athletic Robot Control](https://arxiv.org/abs/2602.00401)
*Jean Pierre Sleiman,He Li,Alphonsus Adu-Bredu,Robin Deits,Arun Kumar,Kevin Bergamin,Mohak Bhardwaj,Scott Biddlestone,Nicola Burger,Matthew A. Estrada,Francesco Iacobelli,Twan Koolen,Alexander Lambert,Erica Lin,M. Eva Mungai,Zach Nobles,Shane Rozen-Levy,Yuyao Shi,Jiashun Wang,Jakob Welner,Fangzhou Yu,Mike Zhang,Alfred Rizzi,Jessica Hodgins,Sylvain Bertrand,Yeuhi Abe,Scott Kuindersma,Farbod Farshidian*

Main category: cs.RO

TL;DR: ZEST是一个简化的运动模仿框架，通过强化学习从多种来源（运动捕捉、视频、动画）训练策略，并能零样本部署到机器人硬件上，实现跨行为、跨平台和跨形态的泛化，无需接触标签、参考窗口或状态估计器。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人全身控制技术难以实现鲁棒、类人、接触丰富的敏捷行为，通常需要大量的技能工程和脆弱的控制器调优过程。

Method: ZEST结合了自适应采样（关注难点运动片段）和自动课程（使用基于模型的辅助扳手），通过强化学习从多样化的数据源（运动捕捉、视频、动画）训练策略，并提供了一个从近似解析数据中选择关节级增益的程序。

Result: ZEST在模拟器中进行训练，并在波士顿动力Atlas机器人上成功实现了动态多接触技能（如爬行、街舞），直接从视频将舞蹈和场景交互技能转移到Atlas和Unitree G1，并通过动画跨形态地赋能Spot四足机器人进行特技表演。

Conclusion: ZEST展示了在异构数据源和具身模型上的鲁棒零样本部署能力，成功连接了生物运动与其机器人对应物，为实现更通用、可扩展的机器人控制提供了新方法。

Abstract: Achieving robust, human-like whole-body control on humanoid robots for agile, contact-rich behaviors remains a central challenge, demanding heavy per-skill engineering and a brittle process of tuning controllers. We introduce ZEST (Zero-shot Embodied Skill Transfer), a streamlined motion-imitation framework that trains policies via reinforcement learning from diverse sources -- high-fidelity motion capture, noisy monocular video, and non-physics-constrained animation -- and deploys them to hardware zero-shot. ZEST generalizes across behaviors and platforms while avoiding contact labels, reference or observation windows, state estimators, and extensive reward shaping. Its training pipeline combines adaptive sampling, which focuses training on difficult motion segments, and an automatic curriculum using a model-based assistive wrench, together enabling dynamic, long-horizon maneuvers. We further provide a procedure for selecting joint-level gains from approximate analytical armature values for closed-chain actuators, along with a refined model of actuators. Trained entirely in simulation with moderate domain randomization, ZEST demonstrates remarkable generality. On Boston Dynamics' Atlas humanoid, ZEST learns dynamic, multi-contact skills (e.g., army crawl, breakdancing) from motion capture. It transfers expressive dance and scene-interaction skills, such as box-climbing, directly from videos to Atlas and the Unitree G1. Furthermore, it extends across morphologies to the Spot quadruped, enabling acrobatics, such as a continuous backflip, through animation. Together, these results demonstrate robust zero-shot deployment across heterogeneous data sources and embodiments, establishing ZEST as a scalable interface between biological movements and their robotic counterparts.

</details>


### [610] [FISC: A Fluid-Inspired Framework for Decentralized and Scalable Swarm Control](https://arxiv.org/abs/2602.00480)
*Mohini Priya Kolluri,Ammar Waheed,Zohaib Hasnain*

Main category: cs.RO

TL;DR: 提出了一种受流体动力学启发的去中心化方法，用于控制大型机器人集群，使其能够像流体一样在空间中流动，而无需进行显式通信。仿真结果显示，该方法在 $O(10^3)$ 架四旋翼无人机集群中表现良好，并且与计算流体动力学（CFD）结果在速度、密度和压力场方面具有可比性。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人集群协调方法依赖于个体之间的通信，这会引入延迟、带宽限制和故障风险。研究动机是为了克服这些限制，提出一种无需通信的去中心化控制方法。

Method: 该方法借鉴流体动力学原理，将机器人集群视为一种宏观连续体。通过建立流体基本属性与单个机器人状态之间的关系，使得集群能够像流体一样对外部压力条件做出响应。具体地，通过将流体类比性质赋予代理子集，集群在保持结构和连贯性的同时进行集体演化。

Result: 在包含 $O(10^3)$ 架四旋翼无人机的仿真中，该方法在与计算流体动力学（CFD）解进行比较时，在速度、密度和压力场方面获得了定量的吻合。误差评估显示，速度的归一化误差在 0.15-0.9 之间，密度在 0.61-0.98 之间，压力在 0-0.937 之间。

Conclusion: 该研究表明，可以将大型机器人集群视为连续体系统，并保持源自基本原理的宏观结构，从而为可扩展和去中心化的控制提供了基础。这种类流体的方法克服了传统通信依赖性带来的挑战。

Abstract: Achieving scalable coordination in large robotic swarms is often constrained by reliance on inter-agent communication, which introduces latency, bandwidth limitations, and vulnerability to failure. To address this gap, a decentralized approach for outer-loop control of large multi-agent systems based on the paradigm of how a fluid moves through a volume is proposed and evaluated. A relationship between fundamental fluidic element properties and individual robotic agent states is developed such that the corresponding swarm "flows" through a space, akin to a fluid when forced via a pressure boundary condition. By ascribing fluid-like properties to subsets of agents, the swarm evolves collectively while maintaining desirable structure and coherence without explicit communication of agent states within or outside of the swarm. The approach is evaluated using simulations involving $O(10^3)$ quadcopter agents and compared against Computational Fluid Dynamics (CFD) solutions for a converging-diverging domain. Quantitative agreement between swarm-derived and CFD fields is assessed using Root-Mean-Square Error (RMSE), yielding normalized errors of 0.15-0.9 for velocity, 0.61-0.98 for density, 0-0.937 for pressure. These results demonstrate the feasibility of treating large robotic swarms as continuum systems that retain the macroscopic structure derived from first principles, providing a basis for scalable and decentralized control.

</details>


### [611] [Inject Once Survive Later: Backdooring Vision-Language-Action Models to Persist Through Downstream Fine-tuning](https://arxiv.org/abs/2602.00500)
*Jianyi Zhou,Yujie Wei,Ruichen Zhen,Bo Zhao,Xiaobo Xia,Rui Shao,Xiu Su,Shuo Yang*

Main category: cs.RO

TL;DR: 本文提出了一种名为INFUSE的后门攻击框架，专门针对Vision-Language-Action (VLA)模型。INFUSE通过识别和利用对下游微调不敏感的模型模块来注入后门，即使在用户进行任意微调后，后门也能保持有效，从而解决了现有攻击方法容易被清除的缺点。实验证明，INFUSE在模拟和真实机器人任务中均表现出高攻击成功率，且对正常任务性能影响很小。


<details>
  <summary>Details</summary>
Motivation: 现有针对VLA模型的后门攻击方法在用户进行下游微调时容易失效，无法在实际应用中保持长期威胁，因此需要一种能够抵抗微调的后门攻击方法。

Method: INFUSE首先通过分析不同微调场景下的参数敏感性，识别出对微调不敏感的模型模块。然后，将后门注入这些稳定的模块中，同时冻结其他模块，以确保后门在用户微调后依然存在。

Result: 在模拟环境中，INFUSE的平均攻击成功率为91.0%，在真实机器人任务中为79.8%。相比之下，BadVLA的成功率分别为38.8%和36.6%。INFUSE在保持高攻击成功率的同时，也保持了与标准模型相当的正常任务性能。

Conclusion: 后门攻击可以被注入到VLA基础模型中，并且能够在下游微调后依然有效，这揭示了一个重要的安全威胁，即预先植入的后门在部署后仍然构成风险。

Abstract: Vision-Language-Action (VLA) models have become foundational to modern embodied AI systems. By integrating visual perception, language understanding, and action planning, they enable general-purpose task execution across diverse environments. Despite their importance, the security of VLA models remains underexplored -- particularly in the context of backdoor attacks, which pose realistic threats in physical-world deployments. While recent methods attempt to inject backdoors into VLA models, these backdoors are easily erased during downstream adaptation, as user-side fine-tuning with clean data significantly alters model parameters, rendering them impractical for real-world applications. To address these challenges, we propose INFUSE (INjection into Fine-tUne-inSensitive modulEs), the first backdoor attack framework for VLA base models that remains effective even with arbitrary user fine-tuning. INFUSE begins by analyzing parameter sensitivity across diverse fine-tuning scenarios to identify modules that remain largely unchanged -- the fine-tune-insensitive modules. It then injects backdoors into these stable modules while freezing the rest, ensuring malicious behavior persists after extensive user fine-tuning. Comprehensive experiments across multiple VLA architectures demonstrate INFUSE's effectiveness. After user-side fine-tuning, INFUSE maintains mean attack success rates of 91.0% on simulation environments and 79.8% on real-world robot tasks, substantially surpassing BadVLA (38.8% and 36.6%, respectively), while preserving clean-task performance comparable to standard models. These results uncover a critical threat: backdoors implanted before distribution can persist through fine-tuning and remain effective at deployment.

</details>


### [612] [A Low-Cost Vision-Based Tactile Gripper with Pretraining Learning for Contact-Rich Manipulation](https://arxiv.org/abs/2602.00514)
*Yaohua Liu,Binkai Ou,Zicheng Qiu,Ce Hao,Yemin Wang,Hengjun Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为LVTG的低成本视觉-触觉抓手，通过增加触觉感知范围和开口角度，提高了抓取大而重物体的稳定性和效率，并采用了CLIP启发的对比学习方法融合视觉和触觉信息，显著提升了机器人在接触丰富环境下的操作策略性能。


<details>
  <summary>Details</summary>
Motivation: 现有触觉传感器在感知范围、可靠性和成本方面存在局限性，这使得机器人在接触丰富的环境中进行操控面临挑战。研究旨在开发一种成本低廉、性能更优的视觉-触觉抓手，以解决这些问题。

Method: 设计了一个具有更大触觉感知区域和开口角度的LVTG抓手，并使用了耐磨损材料以提高耐用性。通过CLIP启发的对比学习目标，将触觉嵌入与视觉观测对齐，构建跨模态表示空间。将此方法应用于Action Chunking Transformer (ACT) 策略，以改进接触丰富环境下的操控。

Result: LVTG抓手能够更稳定、高效地抓取更大更重的日常物体。通过预训练，LVTG结合ACT策略在操控任务中取得了显著更高的成功率，并且数据收集和策略学习更为高效。

Conclusion: LVTG是一种低成本、高鲁棒性的视觉-触觉抓手，通过增强的触觉感知和跨模态对齐学习，能有效提升机器人在接触丰富环境中的操作能力，克服了传统触觉传感器的不足。

Abstract: Robotic manipulation in contact-rich environments remains challenging, particularly when relying on conventional tactile sensors that suffer from limited sensing range, reliability, and cost-effectiveness. In this work, we present LVTG, a low-cost visuo-tactile gripper designed for stable, robust, and efficient physical interaction. Unlike existing visuo-tactile sensors, LVTG enables more effective and stable grasping of larger and heavier everyday objects, thanks to its enhanced tactile sensing area and greater opening angle. Its surface skin is made of highly wear-resistant material, significantly improving durability and extending operational lifespan. The integration of vision and tactile feedback allows LVTG to provide rich, high-fidelity sensory data, facilitating reliable perception during complex manipulation tasks. Furthermore, LVTG features a modular design that supports rapid maintenance and replacement. To effectively fuse vision and touch, We adopt a CLIP-inspired contrastive learning objective to align tactile embeddings with their corresponding visual observations, enabling a shared cross-modal representation space for visuo-tactile perception. This alignment improves the performance of an Action Chunking Transformer (ACT) policy in contact-rich manipulation, leading to more efficient data collection and more effective policy learning. Compared to the original ACT method, the proposed LVTG with pretraining achieves significantly higher success rates in manipulation tasks.

</details>


### [613] [APEX: A Decoupled Memory-based Explorer for Asynchronous Aerial Object Goal Navigation](https://arxiv.org/abs/2602.00551)
*Daoxuan Zhang,Ping Chen,Xiaobo Xia,Xiu Su,Ruichen Zhen,Jianqiang Xiao,Shuo Yang*

Main category: cs.RO

TL;DR: 提出了一种名为APEX的新型分层无人机导航代理，通过动态三维地图、强化学习决策和开放词汇目标检测，提高了在复杂空中环境中寻找目标的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有空中目标导航方法在空间记忆、动作决策和探索效率方面存在不足，尤其是在复杂空中环境中。

Method: APEX采用分层、异步、并行框架，包含三个模块：1) 动态时空语义映射记忆（利用VLM生成吸引力、探索和障碍物地图）；2) 动作决策模块（强化学习）；3) 目标识别模块（开放词汇检测器）。

Result: APEX在UAV-ON基准测试中，成功率（SR）和成功率加路径长度（SPL）分别比现有技术提高了+4.2%和+2.8%。

Conclusion: APEX通过其分层异步设计，有效地提高了空中目标导航的效率和性能，克服了现有方法的局限性。

Abstract: Aerial Object Goal Navigation, a challenging frontier in Embodied AI, requires an Unmanned Aerial Vehicle (UAV) agent to autonomously explore, reason, and identify a specific target using only visual perception and language description. However, existing methods struggle with the memorization of complex spatial representations in aerial environments, reliable and interpretable action decision-making, and inefficient exploration and information gathering. To address these challenges, we introduce \textbf{APEX} (Aerial Parallel Explorer), a novel hierarchical agent designed for efficient exploration and target acquisition in complex aerial settings. APEX is built upon a modular, three-part architecture: 1) Dynamic Spatio-Semantic Mapping Memory, which leverages the zero-shot capability of a Vision-Language Model (VLM) to dynamically construct high-resolution 3D Attraction, Exploration, and Obstacle maps, serving as an interpretable memory mechanism. 2) Action Decision Module, trained with reinforcement learning, which translates this rich spatial understanding into a fine-grained and robust control policy. 3) Target Grounding Module, which employs an open-vocabulary detector to achieve definitive and generalizable target identification. All these components are integrated into a hierarchical, asynchronous, and parallel framework, effectively bypassing the VLM's inference latency and boosting the agent's proactivity in exploration. Extensive experiments show that APEX outperforms the previous state of the art by +4.2\% SR and +2.8\% SPL on challenging UAV-ON benchmarks, demonstrating its superior efficiency and the effectiveness of its hierarchical asynchronous design. Our source code is provided in \href{https://github.com/4amGodvzx/apex}{GitHub}

</details>


### [614] [ConLA: Contrastive Latent Action Learning from Human Videos for Robotic Manipulation](https://arxiv.org/abs/2602.00557)
*Weisheng Dai,Kai Lan,Jianyi Zhou,Bo Zhao,Xiu Su,Junwen Tong,Weili Guan,Shuo Yang*

Main category: cs.RO

TL;DR: 提出了一种名为ConLA的无监督预训练框架，用于从人类演示视频中学习机器人策略，该框架通过对比学习和时间线索来分离运动动力学和视觉内容，从而减轻了搭便车学习，并在机器人任务上取得了优于真实机器人轨迹预训练的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模机器人遥操作数据集获取成本高昂且难以扩展。而人类演示视频资源丰富且易于获取，但缺乏显式的动作监督，难以直接用于机器人学习。之前的无监督方法在学习潜在动作时容易依赖视觉线索，导致捷径学习和表示纠缠，影响迁移能力。

Method: 提出ConLA框架，采用对比学习和时间线索来分离运动动力学和视觉内容。通过利用动作类别先验和时间信息，强制模型学习与视觉外观无关的运动表示，从而减轻捷径学习。

Result: ConLA在各种机器人基准测试中取得了优异的性能。特别地，仅通过人类视频预训练，其性能超过了使用真实机器人轨迹预训练的方法。

Conclusion: ConLA是一种有效的无监督预训练框架，能够从人类演示视频中提取纯净且语义一致的潜在动作表示，克服了现有方法的局限性，并为可扩展的机器人学习开辟了新的途径。

Abstract: Vision-Language-Action (VLA) models achieve preliminary generalization through pretraining on large scale robot teleoperation datasets. However, acquiring datasets that comprehensively cover diverse tasks and environments is extremely costly and difficult to scale. In contrast, human demonstration videos offer a rich and scalable source of diverse scenes and manipulation behaviors, yet their lack of explicit action supervision hinders direct utilization. Prior work leverages VQ-VAE based frameworks to learn latent actions from human videos in an unsupervised manner. Nevertheless, since the training objective primarily focuses on reconstructing visual appearances rather than capturing inter-frame dynamics, the learned representations tend to rely on spurious visual cues, leading to shortcut learning and entangled latent representations that hinder transferability. To address this, we propose ConLA, an unsupervised pretraining framework for learning robotic policies from human videos. ConLA introduces a contrastive disentanglement mechanism that leverages action category priors and temporal cues to isolate motion dynamics from visual content, effectively mitigating shortcut learning. Extensive experiments show that ConLA achieves strong performance across diverse benchmarks. Notably, by pretraining solely on human videos, our method for the first time surpasses the performance obtained with real robot trajectory pretraining, highlighting its ability to extract pure and semantically consistent latent action representations for scalable robot learning.

</details>


### [615] [UniMotion: A Unified Motion Framework for Simulation, Prediction and Planning](https://arxiv.org/abs/2602.00566)
*Nan Song,Junzhe Jiang,Jingyu Li,Xiatian Zhu,Li Zhang*

Main category: cs.RO

TL;DR: 提出了一种名为UniMotion的统一运动框架，利用decoder-only Transformer架构，通过共享表示和定制化训练策略，同时处理运动模拟、预测和规划任务，并在Waymo Open Motion Dataset上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的运动模拟、预测和规划任务通常被独立研究，但它们共享对多智能体交互、运动行为建模和时空动力学推理能力的需求。这种分离阻碍了跨任务泛化和系统可扩展性，并忽视了任务间的潜在互惠互利。

Method: 基于decoder-only Transformer架构，设计了UniMotion统一运动框架。它采用专门的交互模式和定制化的训练策略，以同时支持运动模拟、预测和规划任务，实现联合优化和表示共享，并支持针对个别任务的精调。

Result: 在Waymo Open Motion Dataset上的实验表明，联合训练能够实现鲁棒的泛化能力和有效的任务整合。通过进一步精调，UniMotion在多个运动任务上取得了SOTA性能。

Conclusion: UniMotion是一个多功能且可扩展的自动驾驶运动解决方案，通过统一框架实现了任务间的协同，并在各项运动任务中展现出优越的性能。

Abstract: Motion simulation, prediction and planning are foundational tasks in autonomous driving, each essential for modeling and reasoning about dynamic traffic scenarios. While often addressed in isolation due to their differing objectives, such as generating diverse motion states or estimating optimal trajectories, these tasks inherently depend on shared capabilities: understanding multi-agent interactions, modeling motion behaviors, and reasoning over temporal and spatial dynamics. Despite this underlying commonality, existing approaches typically adopt specialized model designs, which hinders cross-task generalization and system scalability. More critically, this separation overlooks the potential mutual benefits among tasks. Motivated by these observations, we propose UniMotion, a unified motion framework that captures shared structures across motion tasks while accommodating their individual requirements. Built on a decoder-only Transformer architecture, UniMotion employs dedicated interaction modes and tailored training strategies to simultaneously support these motion tasks. This unified design not only enables joint optimization and representation sharing but also allows for targeted fine-tuning to specialize in individual tasks when needed. Extensive experiments on the Waymo Open Motion Dataset demonstrate that joint training leads to robust generalization and effective task integration. With further fine-tuning, UniMotion achieves state-of-the-art performance across a range of motion tasks, establishing it as a versatile and scalable solution for autonomous driving.

</details>


### [616] [Agentic Reward Modeling: Verifying GUI Agent via Online Proactive Interaction](https://arxiv.org/abs/2602.00575)
*Chaoqun Cui,Jing Huang,Shijing Wang,Liming Zheng,Qingchao Kong,Zhixiong Zeng*

Main category: cs.RO

TL;DR: 本文提出了一种名为VAGEN的框架，用于改进GUI智能体中可验证奖励的强化学习评估方法，通过智能体主动交互和利用工具来克服现有基于规则和LLM-as-a-Judge方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体评估方法（如基于规则和LLM-as-a-Judge）存在可扩展性差、无法处理开放式任务以及对部分可观测环境下的潜在系统状态捕捉不足等问题。

Method: 提出了一种名为Agentic Interactive Verification的范式，并构建了VAGEN框架。VAGEN包含一个配备交互工具的验证智能体，能够自主规划验证策略，并主动探测环境以获取任务完成的证据，从而克服视觉观察的局限性。

Result: 在OSWorld-Verified和AndroidWorld基准测试中，VAGEN显著提高了评估准确性，优于LLM-as-a-Judge基线方法，并且通过测试时扩展策略进一步提升了性能。

Conclusion: Agentic Interactive Verification范式和VAGEN框架为GUI智能体中的可验证奖励评估提供了一种更有效、更具鲁棒性的方法，尤其是在处理具有部分可观测性的复杂环境时。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is pivotal for the continuous evolution of GUI agents, yet existing evaluation paradigms face significant limitations. Rule-based methods suffer from poor scalability and cannot handle open-ended tasks, while LLM-as-a-Judge approaches rely on passive visual observation, often failing to capture latent system states due to partial state observability. To address these challenges, we advocate for a paradigm shift from passive evaluation to Agentic Interactive Verification. We introduce VAGEN, a framework that employs a verifier agent equipped with interaction tools to autonomously plan verification strategies and proactively probe the environment for evidence of task completion. Leveraging the insight that GUI tasks are typically "easy to verify but hard to solve", VAGEN overcomes the bottlenecks of visual limitations. Experimental results on OSWorld-Verified and AndroidWorld benchmarks demonstrate that VAGEN significantly improves evaluation accuracy compared to LLM-as-a-Judge baselines and further enhances performance through test-time scaling strategies.

</details>


### [617] [Factored Reasoning with Inner Speech and Persistent Memory for Evidence-Grounded Human-Robot Interaction](https://arxiv.org/abs/2602.00675)
*Valerio Belcamino,Mariya Kilina,Alessandro Carfì,Valeria Seidita,Fulvio Mastrogiovanni,Antonio Chella*

Main category: cs.RO

TL;DR: 本文介绍了一个名为JANUS的认知架构，用于支持对话式人机交互，该架构通过将交互建模为部分可观察马尔可夫决策过程，并采用带有类型接口的因子控制器来实现，能够维持用户上下文、处理不明确的请求，并将响应与外部证据结合，同时保持中间决策的可验证性。


<details>
  <summary>Details</summary>
Motivation: 现有的对话式人机交互在维护用户上下文、处理不明确的请求、将响应与外部证据联系起来以及确保决策可验证性方面存在挑战。

Method:  JANUS将整体行为分解为范围检测、意图识别、记忆、内部言语、查询生成和外部言语等专门模块，并暴露信息充分性、执行就绪性和工具接地策略。它采用一个记忆代理来管理不同层级的记忆（近期历史、核心记忆、档案存储），并通过内部言语验证参数完整性，通过证据包约束机器人声明的忠实性。

Result: 在以知识图谱为基础的膳食辅助领域，JANUS的模块级单元测试显示与精心挑选的参考资料高度一致，并具有实际的延迟表现。

Conclusion: 因子推理是实现可扩展、可审计、证据接地且能在长时间交互中提供机器人辅助的一种有前景的方法。

Abstract: Dialogue-based human-robot interaction requires robot cognitive assistants to maintain persistent user context, recover from underspecified requests, and ground responses in external evidence, while keeping intermediate decisions verifiable. In this paper we introduce JANUS, a cognitive architecture for assistive robots that models interaction as a partially observable Markov decision process and realizes control as a factored controller with typed interfaces. To this aim, Janus (i) decomposes the overall behavior into specialized modules, related to scope detection, intent recognition, memory, inner speech, query generation, and outer speech, and (ii) exposes explicit policies for information sufficiency, execution readiness, and tool grounding. A dedicated memory agent maintains a bounded recent-history buffer, a compact core memory, and an archival store with semantic retrieval, coupled through controlled consolidation and revision policies. Models inspired by the notion of inner speech in cognitive theories provide a control-oriented internal textual flow that validates parameter completeness and triggers clarification before grounding, while a faithfulness constraint ties robot-to-human claims to an evidence bundle combining working context and retrieved tool outputs. We evaluate JANUS through module-level unit tests in a dietary assistance domain grounded on a knowledge graph, reporting high agreement with curated references and practical latency profiles. These results support factored reasoning as a promising path to scalable, auditable, and evidence-grounded robot assistance over extended interaction horizons.

</details>


### [618] [Toward Reliable Sim-to-Real Predictability for MoE-based Robust Quadrupedal Locomotion](https://arxiv.org/abs/2602.00678)
*Tianyang Wu,Hanwei Guo,Yuhang Wang,Junshu Yang,Xinyang Sui,Jiayi Xie,Xingyu Chen,Zeyang Liu,Xuguang Lan*

Main category: cs.RO

TL;DR: 本文提出了一种结合混合专家（MoE）策略和RoboGauge评估套件的框架，用于提升四足机器人仅凭本体感觉进行复杂地形敏捷运动的泛化性和鲁棒性，并量化其模拟到现实的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在处理复杂地形时，面临模拟到现实（sim-to-real）差距和奖励过拟合问题，导致策略无法有效迁移，同时物理验证效率低且风险高。

Method: 使用混合专家（MoE）策略来分解潜在的地形和命令建模，利用专业的专家组提升鲁棒性和泛化性，仅使用本体感觉。同时引入RoboGauge预测性评估套件，通过模拟测试（包含地形、难度和领域随机化）量化策略的迁移能力，从而在物理测试前进行可靠的策略选择。

Result: 在Unitree Go2机器人上进行了实验，证明了该框架在雪地、沙地、楼梯、斜坡和30厘米障碍物等未见过且具有挑战性的地形上实现了鲁棒运动。高速测试中，机器人达到了4米/秒的速度，并涌现出一种与高速度稳定性相关的窄步态。

Conclusion: 所提出的MoE策略和RoboGauge评估套件的统一框架能够有效解决四足机器人仅凭本体感觉进行复杂地形运动时的sim-to-real迁移和奖励过拟合问题，实现了在多种严峻地形上的鲁棒泛化运动，并能通过评估套件可靠地选择最优策略，无需大量物理测试。

Abstract: Reinforcement learning has shown strong promise for quadrupedal agile locomotion, even with proprioception-only sensing. In practice, however, sim-to-real gap and reward overfitting in complex terrains can produce policies that fail to transfer, while physical validation remains risky and inefficient. To address these challenges, we introduce a unified framework encompassing a Mixture-of-Experts (MoE) locomotion policy for robust multi-terrain representation with RoboGauge, a predictive assessment suite that quantifies sim-to-real transferability. The MoE policy employs a gated set of specialist experts to decompose latent terrain and command modeling, achieving superior deployment robustness and generalization via proprioception alone. RoboGauge further provides multi-dimensional proprioception-based metrics via sim-to-sim tests over terrains, difficulty levels, and domain randomizations, enabling reliable MoE policy selection without extensive physical trials. Experiments on a Unitree Go2 demonstrate robust locomotion on unseen challenging terrains, including snow, sand, stairs, slopes, and 30 cm obstacles. In dedicated high-speed tests, the robot reaches 4 m/s and exhibits an emergent narrow-width gait associated with improved stability at high velocity.

</details>


### [619] [Learning to Accelerate Vision-Language-Action Models through Adaptive Visual Token Caching](https://arxiv.org/abs/2602.00686)
*Yujie Wei,Jiahan Fan,Jiyu Guo,Ruichen Zhen,Rui Shao,Xiu Su,Zeke Xie,Shuo Yang*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的框架，通过学习动态、任务感知的决策过程来加速视觉-语言-动作（VLA）模型的推理。该框架包含一个缓存 Token 选择器和一个缓存比率预测器，并通过可微分的松弛技术进行端到端优化。实验结果表明，该方法在不牺牲性能的情况下，显著提高了推理速度，并在真实机器人任务中提升了成功率。


<details>
  <summary>Details</summary>
Motivation: 现有 VLA 模型虽然泛化能力强，但计算开销大，阻碍了实际应用。因此，提高推理效率是 VLA 模型在机器人领域落地应用的关键。

Method: 将推理加速视为一个可学习的策略优化问题，提出了一个包含两个轻量级模块（缓存 Token 选择器和缓存比率预测器）的框架。这两个模块协同工作，动态决定哪些 Token 可以被重用以及重用的数量。训练过程采用了可微分松弛技术，实现了端到端的梯度优化。

Result: 在 LIBERO 和 SIMPLER 基准测试以及真实机器人评估中，该方法实现了 1.76 倍的实际推理速度提升，同时将 LIBERO 上的平均成功率提高了 1.9 个百分点（从 75.0% 提高到 76.9%），并将真实世界任务的成功率提高了 5.0 个百分点。该方法显著优于现有基线。

Conclusion: 通过学习任务感知的计算分配策略，可以实现 VLA 模型的高效推理，为开发兼具强大功能和高效率的 VLA 模型提供了新的途径。

Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable generalization capabilities in robotic manipulation tasks, yet their substantial computational overhead remains a critical obstacle to real-world deployment. Improving inference efficiency is therefore essential for practical robotic applications. Existing acceleration methods often rely on heuristic or static strategies--such as rule-based token caching or pruning--that are decoupled from task objectives and fail to adapt to dynamic scene changes. In this work, we reformulate inference acceleration as a learnable policy optimization problem and propose a novel framework that integrates a dynamic, task-aware decision-making process directly into the VLA model. At its core are two lightweight, cooperative modules: a Cached Token Selector, which determines which tokens should be reused, and a Cache Ratio Predictor, which controls how many tokens to reuse. Training these modules is non-trivial due to their discrete decisions. We address this by adopting a differentiable relaxation that allows gradient-based end-to-end optimization. Extensive experiments on the LIBERO and SIMPLER benchmarks, as well as real-robot evaluations, show that our method achieves a 1.76x wall-clock inference speedup while simultaneously improving the average success rate by 1.9 percentage points (from 75.0% to 76.9%) on LIBERO and by 5.0 percentage points on real-world tasks, significantly outperforming existing baselines. This work highlights the potential of learning task-aware computational allocation policies, paving the way for VLA models that are both powerful and efficient.

</details>


### [620] [USS-Nav: Unified Spatio-Semantic Scene Graph for Lightweight UAV Zero-Shot Object Navigation](https://arxiv.org/abs/2602.00708)
*Weiqi Gai,Yuman Gao,Yuan Zhou,Yufan Xie,Zhiyang Liu,Yuze Wu,Xin Zhou,Fei Gao,Zhijun Meng*

Main category: cs.RO

TL;DR: 提出了一种名为USS-Nav的轻量级框架，通过构建统一的时空语义场景图，并结合大语言模型（LLM），实现了在未知环境中对物体进行零样本导航。该框架利用多面体扩展生成空间连通图，并将其聚类为语义区域，然后将开放词汇的物体语义锚定到该拓扑结构上。最后，采用一种粗到精的探索策略，LLM负责确定全局目标区域，局部规划器则优化信息增益下的前沿覆盖。实验证明，该框架在计算效率和实时性方面优于现有方法，并在SPL指标上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中进行零样本物体导航对于无人机（UAV）来说是一个重大挑战，因为高层次的语义推理需求与有限的 onboard 计算资源之间存在冲突。

Method: 提出了一种增量式统一时空语义场景图构建方法，包括：1. 使用多面体扩展生成空间连通图以捕捉全局几何拓扑。2. 通过图聚类动态地将空间图划分为语义区域。3. 将开放词汇的物体语义实例化并锚定到拓扑结构上，形成分层环境表示。4. 采用粗到精的探索策略：利用LLM基于场景图语义确定全局目标区域，同时局部规划器基于信息增益优化前沿覆盖。

Result: 该框架在计算效率和实时更新频率（15 Hz）方面优于现有最先进方法，并在资源受限平台上进行了验证。消融实验证实了框架的有效性，并在Success weighted by Path Length (SPL)指标上显示出显著的改进。

Conclusion: USS-Nav是一个轻量级的框架，能够有效地在未知环境中进行基于LLM的零样本物体导航，并在计算效率、实时性和导航性能方面取得了优势。

Abstract: Zero-Shot Object Navigation in unknown environments poses significant challenges for Unmanned Aerial Vehicles (UAVs) due to the conflict between high-level semantic reasoning requirements and limited onboard computational resources. To address this, we present USS-Nav, a lightweight framework that incrementally constructs a Unified Spatio-Semantic scene graph and enables efficient Large Language Model (LLM)-augmented Zero-Shot Object Navigation in unknown environments. Specifically, we introduce an incremental Spatial Connectivity Graph generation method utilizing polyhedral expansion to capture global geometric topology, which is dynamically partitioned into semantic regions via graph clustering. Concurrently, open-vocabulary object semantics are instantiated and anchored to this topology to form a hierarchical environmental representation. Leveraging this hierarchical structure, we present a coarse-to-fine exploration strategy: LLM grounded in the scene graph's semantics to determine global target regions, while a local planner optimizes frontier coverage based on information gain. Experimental results demonstrate that our framework outperforms state-of-the-art methods in terms of computational efficiency and real-time update frequency (15 Hz) on a resource-constrained platform. Furthermore, ablation studies confirm the effectiveness of our framework, showing substantial improvements in Success weighted by Path Length (SPL). The source code will be made publicly available to foster further research.

</details>


### [621] [SA-VLA: Spatially-Aware Flow-Matching for Vision-Language-Action Reinforcement Learning](https://arxiv.org/abs/2602.00743)
*Xu Pan,Zhenglin Wan,Xingrui Yu,Xianwei Zheng,Youkai Ke,Ming Sun,Rui Wang,Ziwei Wang,Ivor Tsang*

Main category: cs.RO

TL;DR: 提出了一种名为SA-VLA的空间感知强化学习适应框架，用于解决视觉-语言-动作（VLA）模型在机器人操作中进行强化学习微调时出现的鲁棒性下降问题，该问题与空间归纳偏差的侵蚀有关。SA-VLA通过对齐表示学习、奖励设计和探索与任务几何来保留策略优化过程中的空间基础。


<details>
  <summary>Details</summary>
Motivation: 强化学习微调会降低VLA模型在空间分布变化下的鲁棒性，这主要是由于稀疏奖励和空间无关的探索侵蚀了空间归纳偏差。

Method: SA-VLA框架通过以下方式解决此问题：1) 将隐式空间表示与视觉令牌融合，以保留空间基础；2) 提供反映几何进展的密集奖励；3) 采用SCAN（一种空间条件退火探索策略），该策略针对流匹配动力学进行了定制。

Result: SA-VLA在多对象和混乱操作的基准测试中实现了稳定的强化学习微调，并提高了零样本空间泛化能力，从而获得了更鲁棒和可转移的行为。

Conclusion: SA-VLA框架通过整合空间感知机制，有效解决了VLA模型在强化学习适应过程中空间鲁棒性下降的问题，显著提升了机器人在复杂环境下的操作能力和泛化性。

Abstract: Vision-Language-Action (VLA) models exhibit strong generalization in robotic manipulation, yet reinforcement learning (RL) fine-tuning often degrades robustness under spatial distribution shifts. For flow-matching VLA policies, this degradation is closely associated with the erosion of spatial inductive bias during RL adaptation, as sparse rewards and spatially agnostic exploration increasingly favor short-horizon visual cues. To address this issue, we propose \textbf{SA-VLA}, a spatially-aware RL adaptation framework that preserves spatial grounding during policy optimization by aligning representation learning, reward design, and exploration with task geometry. SA-VLA fuses implicit spatial representations with visual tokens, provides dense rewards that reflect geometric progress, and employs \textbf{SCAN}, a spatially-conditioned annealed exploration strategy tailored to flow-matching dynamics. Across challenging multi-object and cluttered manipulation benchmarks, SA-VLA enables stable RL fine-tuning and improves zero-shot spatial generalization, yielding more robust and transferable behaviors. Code and project page are available at https://xupan.top/Projects/savla.

</details>


### [622] [Physics-informed Diffusion Mamba Transformer for Real-world Driving](https://arxiv.org/abs/2602.00808)
*Hang Zhou,Qiang Zhang,Peiran Liu,Yihao Qin,Zhaoxu Yan,Yiding Ji*

Main category: cs.RO

TL;DR: 提出了一种结合Diffusion Mamba Transformer和Port-Hamiltonian神经网络的框架，用于考虑不确定性、时序依赖性和物理约束的自动驾驶轨迹规划，并在基准测试中取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶轨迹规划方法在建模未来运动的不确定性、长期时序依赖性和物理规律方面存在不足，特别是在结合多模态分布方面，往往难以融入长期上下文和物理先验。

Method: 引入了Diffusion Mamba Transformer架构，将Mamba和Transformer融合到扩散过程中，以更好地聚合传感器流和历史运动的序列上下文；同时设计了Port-Hamiltonian神经网络模块，将基于能量的物理约束集成到扩散模型中。

Result: 在标准的自动驾驶基准测试中，该统一框架在预测精度、物理合理性和鲁棒性方面显著优于现有最先进的方法。

Conclusion: 所提出的框架成功地弥合了扩散模型在处理长期序列上下文和物理先验方面的不足，能够生成更安全、更可靠的自动驾驶轨迹预测。

Abstract: Autonomous driving systems demand trajectory planners that not only model the inherent uncertainty of future motions but also respect complex temporal dependencies and underlying physical laws. While diffusion-based generative models excel at capturing multi-modal distributions, they often fail to incorporate long-term sequential contexts and domain-specific physical priors. In this work, we bridge these gaps with two key innovations. First, we introduce a Diffusion Mamba Transformer architecture that embeds mamba and attention into the diffusion process, enabling more effective aggregation of sequential input contexts from sensor streams and past motion histories. Second, we design a Port-Hamiltonian Neural Network module that seamlessly integrates energy-based physical constraints into the diffusion model, thereby enhancing trajectory predictions with both consistency and interpretability. Extensive evaluations on standard autonomous driving benchmarks demonstrate that our unified framework significantly outperforms state-of-the-art baselines in predictive accuracy, physical plausibility, and robustness, thereby advancing safe and reliable motion planning.

</details>


### [623] [SyNeT: Synthetic Negatives for Traversability Learning](https://arxiv.org/abs/2602.00814)
*Bomena Kim,Hojun Lee,Younsoo Park,Yaoyu Hu,Sebastian Scherer,Inwook Shim*

Main category: cs.RO

TL;DR: 本文提出了一种生成合成负样本的方法，用于增强基于视觉的可通行性学习，以解决现有自监督方法缺乏明确负样本的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法在可通行性估计中主要依赖正样本和未标记样本，缺乏明确的负样本，导致模型难以准确识别各种不可通行区域。

Method: 提出一种生成合成负样本的策略，并将其集成到视觉可通行性学习中。该策略可以无缝集成到PU和PN框架中，且不修改推理架构。此外，引入了以物体为中心的FPR评估方法来评估模型在合成负样本区域的预测能力。

Result: 在公开和自收集的数据集上进行的大量实验表明，该方法显著提高了模型在不同环境下的鲁棒性和泛化能力。

Conclusion: 通过显式构建和整合合成负样本，可以有效地提高基于视觉的可通行性估计的准确性和鲁棒性，而无需额外的手动标注。

Abstract: Reliable traversability estimation is crucial for autonomous robots to navigate complex outdoor environments safely. Existing self-supervised learning frameworks primarily rely on positive and unlabeled data; however, the lack of explicit negative data remains a critical limitation, hindering the model's ability to accurately identify diverse non-traversable regions. To address this issue, we introduce a method to explicitly construct synthetic negatives, representing plausible but non-traversable, and integrate them into vision-based traversability learning. Our approach is formulated as a training strategy that can be seamlessly integrated into both Positive-Unlabeled (PU) and Positive-Negative (PN) frameworks without modifying inference architectures. Complementing standard pixel-wise metrics, we introduce an object-centric FPR evaluation approach that analyzes predictions in regions where synthetic negatives are inserted. This evaluation provides an indirect measure of the model's ability to consistently identify non-traversable regions without additional manual labeling. Extensive experiments on both public and self-collected datasets demonstrate that our approach significantly enhances robustness and generalization across diverse environments. The source code and demonstration videos are publicly available at the project page: https://anonymous-synet.github.io/SyNet.github.io/

</details>


### [624] [Ocean Current-Harnessing Stage-Gated MPC: Monotone Cost Shaping and Speed-to-Fly for Energy-Efficient AUV Navigation](https://arxiv.org/abs/2602.00823)
*Spyridon Syntakas,Kostas Vlachos*

Main category: cs.RO

TL;DR: 提出了一种名为“Current-Harnessing Stage-Gated MPC”的控制方法，通过利用海洋洋流来提高AUV的能效和续航能力，并在仿真中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 当前AUV的部署受到能效和续航能力的限制，需要一种方法来提高其在海洋环境中的效率。

Method: 提出了一种基于模型预测控制（MPC）的策略，通过引入一个“阶段门控”的标量来评估海洋洋流的“帮助程度”。该标量用于门控轻量级的成本项，仅在洋流能帮助实现控制目标时激活。具体成本项包括：1. 单调成本塑形（MCS），一种帮助门控的、不使目标函数恶化的修改，放松了沿轨位置误差并提供有界的平移能量回馈，保证了塑形后的目标函数不会超过预设基线；2. 飞行速度（STF）成本分量，增加了推力的成本，并将地面速度与洋流进行软匹配，实现了近乎零水相对“滑翔”。这些项都是C1连续的，并且可以即插即用地集成到MPC设计中。

Result: 在BlueROV2模型和真实海洋洋流场的广泛仿真中，该方法比传统的预测控制实现了显著更低的能耗，同时保持了相当的到达时间和约束满足度。

Conclusion: Current-Harnessing Stage-Gated MPC能够有效地利用海洋洋流，显著提高AUV的能效，同时保持良好的控制性能，为解决AUV的续航能力问题提供了一种可行方案。

Abstract: Autonomous Underwater Vehicles (AUVs) are a highly promising technology for ocean exploration and diverse offshore operations, yet their practical deployment is constrained by energy efficiency and endurance. To address this, we propose Current-Harnessing Stage-Gated MPC, which exploits ocean currents via a per-stage scalar which indicates the "helpfulness" of ocean currents. This scalar is computed along the prediction horizon to gate lightweight cost terms only where the ocean currents truly aids the control goal. The proposed cost terms, that are merged in the objective function, are (i) a Monotone Cost Shaping (MCS) term, a help-gated, non-worsening modification that relaxes along-track position error and provides a bounded translational energy rebate, guaranteeing the shaped objective is never larger than a set baseline, and (ii) a speed-to-fly (STF) cost component that increases the price of thrust and softly matches ground velocity to the ocean current, enabling near zero water-relative "gliding". All terms are C1 and integrate as a plug-and-play in MPC designs. Extensive simulations with the BlueROV2 model under realistic ocean current fields show that the proposed approach achieves substantially lower energy consumption than conventional predictive control while maintaining comparable arrival times and constraint satisfaction.

</details>


### [625] [Safe Stochastic Explorer: Enabling Safe Goal Driven Exploration in Stochastic Environments and Safe Interaction with Unknown Objects](https://arxiv.org/abs/2602.00868)
*Nikhil Uday Shinde,Dylan Hirsch,Michael C. Yip,Sylvia Herbert*

Main category: cs.RO

TL;DR: 提出了一种名为 S.S.Explorer 的新框架，用于在随机动态环境中实现安全的、以目标为导向的探索，该框架通过高斯过程在线学习安全函数，并利用其预测不确定性来平衡安全性和信息收集。


<details>
  <summary>Details</summary>
Motivation: 现有安全控制和探索方法通常假设系统动力学已知，并且未能充分考虑真实世界环境中固有的随机性，这在进行行星探索、仓库和家庭等安全关键型任务的自主机器人中存在严重问题。

Method: 利用高斯过程在线学习未知的安全函数，并利用其预测不确定性来指导信息收集动作，提供安全违规的概率界限。该方法首先应用于离散状态空间，然后推广到连续状态空间，并应用于与多个未知物体进行安全的物理交互。

Result: 通过在模拟和实际硬件实验中进行广泛的验证，证明了该方法的有效性。

Conclusion: S.S.Explorer 框架能够安全地、以目标为导向地在随机动态环境中进行探索，减少了对环境不安全性的不确定性，为在复杂、不确定的环境中实现可靠的机器人自主性迈出了重要一步。

Abstract: Autonomous robots operating in unstructured, safety-critical environments, from planetary exploration to warehouses and homes, must learn to safely navigate and interact with their surroundings despite limited prior knowledge. Current methods for safe control, such as Hamilton-Jacobi Reachability and Control Barrier Functions, assume known system dynamics. Meanwhile existing safe exploration techniques often fail to account for the unavoidable stochasticity inherent when operating in unknown real world environments, such as an exploratory rover skidding over an unseen surface or a household robot pushing around unmapped objects in a pantry. To address this critical gap, we propose Safe Stochastic Explorer (S.S.Explorer) a novel framework for safe, goal-driven exploration under stochastic dynamics. Our approach strategically balances safety and information gathering to reduce uncertainty about safety in the unknown environment. We employ Gaussian Processes to learn the unknown safety function online, leveraging their predictive uncertainty to guide information-gathering actions and provide probabilistic bounds on safety violations. We first present our method for discrete state space environments and then introduce a scalable relaxation to effectively extend this approach to continuous state spaces. Finally we demonstrate how this framework can be naturally applied to ensure safe physical interaction with multiple unknown objects. Extensive validation in simulation and demonstrative hardware experiments showcase the efficacy of our method, representing a step forward toward enabling reliable widespread robot autonomy in complex, uncertain environments.

</details>


### [626] [Learning When to Jump for Off-road Navigation](https://arxiv.org/abs/2602.00877)
*Zhipeng Zhao,Taimeng Fu,Shaoshu Su,Qiwei Du,Ehsan Tarkesh Esfahani,Karthik Dantu,Souma Chowdhury,Chen Wang*

Main category: cs.RO

TL;DR: 提出了一种运动感知可通行性（MAT）表示方法，该方法显式地将地形成本与实际机器人运动相结合，从而实现更安全、更高效的越野导航。


<details>
  <summary>Details</summary>
Motivation: 现有越野路径规划方法往往忽略了复杂运动动力学，仅基于位置或固定速度进行规划，这可能导致在低速行驶时跨越沟渠等障碍物存在风险，而无法实现高速安全跳跃。研究旨在弥补这一差距，实现对机器人实际运动状态敏感的地形成本建模。

Method: 引入了运动感知可通行性（MAT）表示，将地形区域建模为速度的函数（高斯分布）。在在线规划中，将地形成本计算分为两步：1. 从感知信息中预测地形相关的参数；2. 基于当前动力学推断的新速度，通过评估这些高斯函数来高效更新地形成本，避免重复推理。

Result: MAT方法在模拟和真实世界环境中进行了评估，结果表明该方法具有实时效率，并显著提高了越野导航性能，减少了75%的路径绕行，同时保证了在复杂地形下的安全性。

Conclusion: MAT表示是一种有效的方法，能够显式地将地形成本与机器人运动状态相关联，从而实现高效、安全的越野导航，克服了传统方法的局限性。

Abstract: Low speed does not always guarantee safety in off-road driving. For instance, crossing a ditch may be risky at a low speed due to the risk of getting stuck, yet safe at a higher speed with a controlled, accelerated jump. Achieving such behavior requires path planning that explicitly models complex motion dynamics, whereas existing methods often neglect this aspect and plan solely based on positions or a fixed velocity. To address this gap, we introduce Motion-aware Traversability (MAT) representation to explicitly model terrain cost conditioned on actual robot motion. Instead of assigning a single scalar score for traversability, MAT models each terrain region as a Gaussian function of velocity. During online planning, we decompose the terrain cost computation into two stages: (1) predict terrain-dependent Gaussian parameters from perception in a single forward pass, (2) efficiently update terrain costs for new velocities inferred from current dynamics by evaluating these functions without repeated inference. We develop a system that integrates MAT to enable agile off-road navigation and evaluate it in both simulated and real-world environments with various obstacles. Results show that MAT achieves real-time efficiency and enhances the performance of off-road navigation, reducing path detours by 75% while maintaining safety across challenging terrains.

</details>


### [627] [RoDiF: Robust Direct Fine-Tuning of Diffusion Policies with Corrupted Human Feedback](https://arxiv.org/abs/2602.00886)
*Amitesh Vatsa,Zhixian Xie,Wanxin Jin*

Main category: cs.RO

TL;DR: 本文提出了一种名为 RoDiF 的新方法，通过统一的 MDP 框架，实现了对扩散策略的无奖励直接偏好优化 (DPO)，并且能够有效处理包含错误的人类偏好数据，在长时程机器人操控任务上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散策略在机器人控制中表现强大，但由于去噪过程的多步结构，利用人类偏好进行微调面临挑战。特别是，人类偏好数据可能存在错误或噪声。

Method: 1. 提出了一个统一的 MDP 公式，将扩散去噪链与环境动力学相结合。 2. 基于此公式，开发了 RoDiF 方法，通过将 DPO 目标从几何假设切割的角度重新解释，并采用保守的切割策略来处理损坏的人类偏好数据，而无需假设特定的噪声分布。

Result: RoDiF 在长时程机器人操控任务上，能够有效将预训练的扩散策略引导至人类偏好的模式，并且在高达 30% 的偏好标签被破坏的情况下，仍能保持强大的性能。它在各种架构的预训练扩散策略上都表现出一致的优越性。

Conclusion: RoDiF 方法成功解决了扩散策略在结合人类偏好时遇到的挑战，特别是处理带噪声偏好数据的问题，为机器人控制领域提供了更鲁棒和有效的微调方案。

Abstract: Diffusion policies are a powerful paradigm for robotic control, but fine-tuning them with human preferences is fundamentally challenged by the multi-step structure of the denoising process. To overcome this, we introduce a Unified Markov Decision Process (MDP) formulation that coherently integrates the diffusion denoising chain with environmental dynamics, enabling reward-free Direct Preference Optimization (DPO) for diffusion policies. Building on this formulation, we propose RoDiF (Robust Direct Fine-Tuning), a method that explicitly addresses corrupted human preferences. RoDiF reinterprets the DPO objective through a geometric hypothesis-cutting perspective and employs a conservative cutting strategy to achieve robustness without assuming any specific noise distribution. Extensive experiments on long-horizon manipulation tasks show that RoDiF consistently outperforms state-of-the-art baselines, effectively steering pretrained diffusion policies of diverse architectures to human-preferred modes, while maintaining strong performance even under 30% corrupted preference labels.

</details>


### [628] [SPOT: Spatio-Temporal Obstacle-free Trajectory Planning for UAVs in an Unknown Dynamic Environment](https://arxiv.org/abs/2602.01189)
*Astik Srivastava,Thomas J Chackenkulam. Bitla Bhanu Teja,Antony Thomas,Madhava Krishna*

Main category: cs.RO

TL;DR: 提出了一种用于未知动态环境的四旋翼反应式运动规划方法，该方法结合了时空规划、基于视觉的安全飞行走廊生成和轨迹优化，无需地图，并引入了备份规划模块以应对死锁情况，在仿真和实际硬件实验中均表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼在未知、动态环境中，存在动态障碍物时的反应式运动规划问题。

Method: 采用4维时空规划器，结合基于视觉的安全飞行走廊（SFC）生成和轨迹优化。该方法无需地图，直接从感知信息进行避障，并通过视觉目标分割和跟踪检测、跟踪动态障碍物。引入了备份规划模块，在无直接路径时进行反应式避障。

Result: 在仿真和实际硬件实验中得到了广泛验证，并在与现有最先进方法的基准测试中显示出显著优势，尤其是在动态、未知环境中的反应式无人机导航方面。

Conclusion: 所提出的无地图、基于感知的反应式运动规划方法能够有效应对未知环境中的动态障碍物，并提供鲁棒的导航能力，优于现有方法。

Abstract: We address the problem of reactive motion planning for quadrotors operating in unknown environments with dynamic obstacles. Our approach leverages a 4-dimensional spatio-temporal planner, integrated with vision-based Safe Flight Corridor (SFC) generation and trajectory optimization. Unlike prior methods that rely on map fusion, our framework is mapless, enabling collision avoidance directly from perception while reducing computational overhead. Dynamic obstacles are detected and tracked using a vision-based object segmentation and tracking pipeline, allowing robust classification of static versus dynamic elements in the scene. To further enhance robustness, we introduce a backup planning module that reactively avoids dynamic obstacles when no direct path to the goal is available, mitigating the risk of collisions during deadlock situations. We validate our method extensively in both simulation and real-world hardware experiments, and benchmark it against state-of-the-art approaches, showing significant advantages for reactive UAV navigation in dynamic, unknown environments.

</details>


### [629] [UniMorphGrasp: Diffusion Model with Morphology-Awareness for Cross-Embodiment Dexterous Grasp Generation](https://arxiv.org/abs/2602.00915)
*Zhiyuan Wu,Xiangyu Zhang,Zhuo Chen,Jiankang Deng,Rolandos Alexandros Potamias,Shan Luo*

Main category: cs.RO

TL;DR: 提出UniMorphGrasp，一个基于扩散模型的框架，通过将不同机器人手的抓取姿态映射到统一的人类手部姿态表示，并结合手部运动学和物体几何信息，实现了跨具身抓取的统一生成，并表现出对未见手部结构的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有跨具身灵巧抓取方法通常针对特定手部设计，泛化能力差，难以应用于未见过的手部形态。

Method: 1. 将不同机器人手的抓取姿态映射到统一的人类手部姿态表示。2. 抓取生成过程以手部运动学（表示为图）和物体几何信息为条件。3. 引入一个利用手部运动学层级组织来指导关节级别监督的损失函数。

Result: UniMorphGrasp在现有的灵巧抓取基准测试中取得了最先进的性能，并且对未见过的手部结构表现出强大的零样本泛化能力。

Conclusion: UniMorphGrasp能够实现可扩展且实用的跨具身抓取部署，有效地解决了现有方法的局限性。

Abstract: Cross-embodiment dexterous grasping aims to generate stable and diverse grasps for robotic hands with heterogeneous kinematic structures. Existing methods are often tailored to specific hand designs and fail to generalize to unseen hand morphologies outside the training distribution. To address these limitations, we propose \textbf{UniMorphGrasp}, a diffusion-based framework that incorporates hand morphological information into the grasp generation process for unified cross-embodiment grasp synthesis. The proposed approach maps grasps from diverse robotic hands into a unified human-like canonical hand pose representation, providing a common space for learning. Grasp generation is then conditioned on structured representations of hand kinematics, encoded as graphs derived from hand configurations, together with object geometry. In addition, a loss function is introduced that exploits the hierarchical organization of hand kinematics to guide joint-level supervision. Extensive experiments demonstrate that UniMorphGrasp achieves state-of-the-art performance on existing dexterous grasp benchmarks and exhibits strong zero-shot generalization to previously unseen hand structures, enabling scalable and practical cross-embodiment grasp deployment.

</details>


### [630] [Path Tracking with Dynamic Control Point Blending for Autonomous Vehicles: An Experimental Study](https://arxiv.org/abs/2602.01892)
*Alexandre Lombard,Florent Perronnet,Nicolas Gaud,Abdeljalil Abbas-Turki*

Main category: cs.RO

TL;DR: 本文提出了一种创新的路径跟踪框架，通过动态调整车辆的控制点（在前轴和后轴之间插值），并结合曲率感知的纵向控制策略，实现了更平滑、更精确的自动驾驶车辆轨迹跟踪，特别是在低速和倒车等复杂场景下。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶车辆路径跟踪方法通常固定控制点在车辆的前轴或后轴，这在不同驾驶场景（如低速操作或倒车）下可能导致控制不佳。研究的动机是开发一种更灵活、适应性更强的路径跟踪框架，能够平滑地适应各种驾驶工况。

Method: 该方法通过对两个互补控制器（基于前轴Stanley公式的横向控制器和基于后轴曲率的几何控制器）进行重心插值来生成横向转向指令，从而实现了控制点在前后轴之间的连续插值。此外，还引入了一种基于虚拟轨迹边界和射线追踪的曲率感知纵向控制策略，将几何约束转化为虚拟障碍物距离，并据此调节速度。整个控制系统被整合到一个统一的控制栈中。

Result: 在仿真和实际自动驾驶车辆上的实验验证表明，所提出的框架在闭环跟踪和倒车操作方面，相比于固定控制点的基线方法，提高了轨迹精度，实现了更平滑的转向曲线，并增强了适应性。

Conclusion: 本文提出的动态控制点插值和曲率感知纵向控制策略，能够显著改善自动驾驶车辆的路径跟踪性能，尤其是在需要精细控制的低速和倒车场景下，提供了更优越的轨迹精度、转向平滑性和整体适应性。

Abstract: This paper presents an experimental study of a path-tracking framework for autonomous vehicles in which the lateral control command is applied to a dynamic control point along the wheelbase. Instead of enforcing a fixed reference at either the front or rear axle, the proposed method continuously interpolates between both, enabling smooth adaptation across driving contexts, including low-speed maneuvers and reverse motion. The lateral steering command is obtained by barycentric blending of two complementary controllers: a front-axle Stanley formulation and a rear-axle curvature-based geometric controller, yielding continuous transitions in steering behavior and improved tracking stability. In addition, we introduce a curvature-aware longitudinal control strategy based on virtual track borders and ray-tracing, which converts upcoming geometric constraints into a virtual obstacle distance and regulates speed accordingly. The complete approach is implemented in a unified control stack and validated in simulation and on a real autonomous vehicle equipped with GPS-RTK, radar, odometry, and IMU. The results in closed-loop tracking and backward maneuvers show improved trajectory accuracy, smoother steering profiles, and increased adaptability compared to fixed control-point baselines.

</details>


### [631] [Green-VLA: Staged Vision-Language-Action Model for Generalist Robots](https://arxiv.org/abs/2602.00919)
*I. Apanasevich,M. Artemyev,R. Babakyan,P. Fedotova,D. Grankin,E. Kupryashin,A. Misailidi,D. Nerus,A. Nutalapati,G. Sidorov,I. Efremov,M. Gerasyov,D. Pikurov,Y. Senchenko,S. Davidenko,D. Kulikov,M. Sultankin,K. Askarbek,O. Shamanin,D. Statovoy,E. Zalyaev,I. Zorin,A. Letkin,E. Rusakov,A. Silchenko,V. Vorobyov,S. Sobolnikov,A. Postnikov*

Main category: cs.RO

TL;DR: 本文提出了一种名为Green-VLA的、分阶段的视觉-语言-动作（VLA）框架，用于在不同具身机器人上实现通用部署。该框架包含五个阶段的课程，并采用可扩展的数据处理管道、统一的具身感知动作接口以及增强的推理能力，实验证明其在泛化性和性能上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为了开发一个能够在多样化具身机器人上通用部署的、可扩展的视觉-语言-动作（VLA）框架，以提高机器人处理现实世界任务的能力。

Method: 研究者提出Green-VLA框架，包含五个阶段的课程（L0-L1, R0-R2），利用3000小时的演示数据，结合可扩展的数据处理管道、时间对齐和质量过滤。该框架使用统一的、具身感知的动作接口，并引入了预测任务进展、分布外检测和基于联合预测的引导等推理增强技术。

Result: 在Simpler BRIDGE WidowX和CALVIN ABC-D的仿真实验以及真实机器人评估中，Green-VLA框架表现出强大的泛化能力，并且通过强化学习（RL）对齐后，在成功率、鲁棒性和长时效性方面取得了显著的性能提升。

Conclusion: Green-VLA框架通过其分阶段的课程设计、高效的数据处理以及增强的推理机制，成功实现了在多种具身机器人上的通用部署，并显著提升了机器人在复杂任务中的性能和鲁棒性。

Abstract: We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.

</details>


### [632] [Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL](https://arxiv.org/abs/2602.02236)
*Julian Lemmel,Felix Resch,Mónika Farsang,Ramin Hasani,Daniela Rus,Radu Grosu*

Main category: cs.RO

TL;DR: 本研究提出了一种名为 RTRRL 的实时循环强化学习算法，用于在线微调预训练策略，以提高自动驾驶代理在环境变化下的性能。该算法与生物启发式的 Liquid-Resistance Liquid-Capacitance RNN 模型协同工作，并在模拟和真实世界的驾驶任务中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 现实世界部署中的预训练策略在面对环境变化（如系统动力学、传感器漂移或任务目标变化）时性能会迅速下降，这限制了基于学习的控制系统的实际应用。因此，需要一种能够在线适应的算法来解决这个问题。

Method: 研究采用了 Real-Time Recurrent Reinforcement Learning (RTRRL) 算法，这是一种生物学上可行的在线自适应算法。RTRRL 与 Liquid-Resistance Liquid-Capacitance RNN 模型相结合，形成了一个闭环方法。通过在模拟 CarRacing 环境和带有事件相机的 RoboRacer 真实世界线跟随任务中进行实验来验证方法的有效性。

Result: RTRRL 能够有效地微调预训练策略，从而提高自动驾驶代理在驾驶任务中的性能。该方法在模拟和真实世界的线跟随任务中都取得了成功。

Conclusion: RTRRL 算法结合生物启发式循环神经网络模型，是一种有效的在线自适应方法，能够提高自动驾驶代理在动态环境下的鲁棒性和性能，克服了固定策略的局限性。

Abstract: Deploying pretrained policies in real-world applications presents substantial challenges that fundamentally limit the practical applicability of learning-based control systems. When autonomous systems encounter environmental changes in system dynamics, sensor drift, or task objectives, fixed policies rapidly degrade in performance. We show that employing Real-Time Recurrent Reinforcement Learning (RTRRL), a biologically plausible algorithm for online adaptation, can effectively fine-tune a pretrained policy to improve autonomous agents' performance on driving tasks. We further show that RTRRL synergizes with a recent biologically inspired recurrent network model, the Liquid-Resistance Liquid-Capacitance RNN. We demonstrate the effectiveness of this closed-loop approach in a simulated CarRacing environment and in a real-world line-following task with a RoboRacer car equipped with an event camera.

</details>


### [633] [SanD-Planner: Sample-Efficient Diffusion Planner in B-Spline Space for Robust Local Navigation](https://arxiv.org/abs/2602.00923)
*Jincheng Wang,Lingfan Bao,Tong Yang,Diego Martinez Plasencia,Jianhao Jiao,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: 本文提出了一种名为 SanD-Planner 的样本高效扩散模型局部规划器，它在 B 样条空间内进行深度图像的模仿学习，以解决在复杂动态环境中生成可靠局部规划器的挑战。


<details>
  <summary>Details</summary>
Motivation: 在高度混乱和动态的环境中生成可靠的局部规划器存在挑战，主要瓶颈在于获取大规模专家演示和提高有限数据下的学习效率。

Method: SanD-Planner 在 B 样条空间内进行深度图像的模仿学习，该方法本身可以产生平滑的输出和有界的预测误差。此外，集成了基于 ESDF 的安全检查器，包含明确的间隙和完成时间度量，以减少对价值函数学习的需求。

Result: SanD-Planner 在模拟混乱环境和室内模拟环境中分别实现了 90.1% 和 72.0% 的成功率，并且仅使用了基线演示规模的 0.25% 的训练数据。该方法还展现了对 2D 和 3D 场景的零样本迁移能力。

Conclusion: SanD-Planner 是一种样本高效的局部规划器，能够在复杂环境中取得最先进的性能，并能实现跨场景的零样本迁移，同时减轻了训练负担。

Abstract: The challenge of generating reliable local plans has long hindered practical applications in highly cluttered and dynamic environments. Key fundamental bottlenecks include acquiring large-scale expert demonstrations across diverse scenes and improving learning efficiency with limited data. This paper proposes SanD-Planner, a sample-efficient diffusion-based local planner that conducts depth image-based imitation learning within the clamped B-spline space. By operating within this compact space, the proposed algorithm inherently yields smooth outputs with bounded prediction errors over local supports, naturally aligning with receding-horizon execution. Integration of an ESDF-based safety checker with explicit clearance and time-to-completion metrics further reduces the training burden associated with value-function learning for feasibility assessment. Experiments show that training with $500$ episodes (merely $0.25\%$ of the demonstration scale used by the baseline), SanD-Planner achieves state-of-the-art performance on the evaluated open benchmark, attaining success rates of $90.1\%$ in simulated cluttered environments and $72.0\%$ in indoor simulations. The performance is further proven by demonstrating zero-shot transferability to realistic experimentation in both 2D and 3D scenes. The dataset and pre-trained models will also be open-sourced.

</details>


### [634] [Bridging the Sim-to-Real Gap with multipanda ros2: A Real-Time ROS2 Framework for Multimanual Systems](https://arxiv.org/abs/2602.02269)
*Jon Škerlj,Seongjin Bien,Abdeldjallil Naceri,Sami Haddadin*

Main category: cs.RO

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: We present $multipanda\_ros2$, a novel open-source ROS2 architecture for multi-robot control of Franka Robotics robots. Leveraging ros2 control, this framework provides native ROS2 interfaces for controlling any number of robots from a single process. Our core contributions address key challenges in real-time torque control, including interaction control and robot-environment modeling. A central focus of this work is sustaining a 1kHz control frequency, a necessity for real-time control and a minimum frequency required by safety standards. Moreover, we introduce a controllet-feature design pattern that enables controller-switching delays of $\le 2$ ms, facilitating reproducible benchmarking and complex multi-robot interaction scenarios. To bridge the simulation-to-reality (sim2real) gap, we integrate a high-fidelity MuJoCo simulation with quantitative metrics for both kinematic accuracy and dynamic consistency (torques, forces, and control errors). Furthermore, we demonstrate that real-world inertial parameter identification can significantly improve force and torque accuracy, providing a methodology for iterative physics refinement. Our work extends approaches from soft robotics to rigid dual-arm, contact-rich tasks, showcasing a promising method to reduce the sim2real gap and providing a robust, reproducible platform for advanced robotics research.

</details>


### [635] [Minimal Footprint Grasping Inspired by Ants](https://arxiv.org/abs/2602.00935)
*Mohamed Sorour,Barbara Webb*

Main category: cs.RO

TL;DR: 受蚂蚁前足抓取能力启发，设计了一种低成本、高摩擦、毛发覆盖且具柔性尖端的仿生抓手，在抓取单个物体和从杂乱环境中拾取物体方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 观察到蚂蚁在杂乱环境中具有出色的抓取能力，并注意到其前足（特别是跗节）具有高摩擦微结构、毛发和柔性末端，这促使研究者探索这些特征在机器人抓取领域的潜在优势。

Method: 通过抽象蚂蚁前足的特征（高摩擦抓取垫、低摩擦毛发、单段跗节结构），设计了一种新型低成本抓手。该抓手长而细，具有仿生结构，并在实验中评估了其抓取能力。

Result: 该仿生抓手能够成功抓取各种单个消费品，抓取成功率为100%。此外，它还能有效地从密集杂乱环境中拾取单个物体，表现出与蚂蚁相似的能力。

Conclusion: 该仿生抓手设计在抓取技术上取得了进展，证明了毛发结构和跗节柔性在昆虫抓取中的重要机械作用，并对机器人抓取，特别是低成本的箱式拾取应用，具有重要意义。

Abstract: Ants are highly capable of grasping objects in clutter, and we have recently observed that this involves substantial use of their forelegs. The forelegs, more specifically the tarsi, have high friction microstructures (setal pads), are covered in hairs, and have a flexible under-actuated tip. Here we abstract these features to test their functional advantages for a novel low-cost gripper design, suitable for bin-picking applications. In our implementation, the gripper legs are long and slim, with high friction gripping pads, low friction hairs and single-segment tarsus-like structure to mimic the insect's setal pads, hairs, and the tarsi's interactive compliance. Experimental evaluation shows this design is highly robust for grasping a wide variety of individual consumer objects, with all grasp attempts successful. In addition, we demonstrate this design is effective for picking single objects from dense clutter, a task at which ants also show high competence. The work advances grasping technology and shed new light on the mechanical importance of hairy structures and tarsal flexibility in insects.

</details>


### [636] [CLAMP: Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining](https://arxiv.org/abs/2602.00937)
*I-Chun Arthur Liu,Krzysztof Choromanski,Sandy Huang,Connor Schenck*

Main category: cs.RO

TL;DR: 本研究提出了一个名为CLAMP的三维预训练框架，通过结合点云和机器人动作，利用对比学习来关联三维几何信息和机器人动作模式，并预训练了一个Diffusion Policy，从而显著提高了机器人在新任务上的学习效率和策略性能，并在模拟和真实世界任务中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于2D图像表示的模仿学习方法在机器人操作中取得了成功，但其无法捕捉对精确操作至关重要的三维空间信息。因此，研究的动机是开发一种能够利用三维信息以提高机器人操作精度的预训练框架。

Method: 该研究提出了CLAMP框架，它利用点云和机器人动作进行三维预训练。通过RGB-D图像和相机外参计算合并点云，并重新渲染多视角四通道图像（包括深度和3D坐标，以及动态腕部视角）。然后，使用对比学习在模拟机器人轨迹上训练编码器，使其能够关联三维几何/位置信息和机器人动作模式。在编码器预训练期间，同时预训练一个Diffusion Policy来初始化策略权重，以提高微调的样本效率和性能。最后，在少量任务演示上微调策略。

Result: CLAMP框架能够学习到包含三维几何和位置信息的图像和动作表示。预训练和微调的设计显著提高了学习效率和策略性能。CLAMP在六个模拟任务和五个真实世界任务中均优于最先进的基线方法。

Conclusion: CLAMP是一种有效的三维预训练框架，它能够利用多视角点云和动作信息来提升机器人的操作能力。该方法通过对比学习和预训练Diffusion Policy，显著提高了样本效率和在新任务上的泛化能力，并在多种任务中展现出优越的性能。

Abstract: Leveraging pre-trained 2D image representations in behavior cloning policies has achieved great success and has become a standard approach for robotic manipulation. However, such representations fail to capture the 3D spatial information about objects and scenes that is essential for precise manipulation. In this work, we introduce Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining (CLAMP), a novel 3D pre-training framework that utilizes point clouds and robot actions. From the merged point cloud computed from RGB-D images and camera extrinsics, we re-render multi-view four-channel image observations with depth and 3D coordinates, including dynamic wrist views, to provide clearer views of target objects for high-precision manipulation tasks. The pre-trained encoders learn to associate the 3D geometric and positional information of objects with robot action patterns via contrastive learning on large-scale simulated robot trajectories. During encoder pre-training, we pre-train a Diffusion Policy to initialize the policy weights for fine-tuning, which is essential for improving fine-tuning sample efficiency and performance. After pre-training, we fine-tune the policy on a limited amount of task demonstrations using the learned image and action representations. We demonstrate that this pre-training and fine-tuning design substantially improves learning efficiency and policy performance on unseen tasks. Furthermore, we show that CLAMP outperforms state-of-the-art baselines across six simulated tasks and five real-world tasks.

</details>


### [637] [Meanshift Shape Formation Control Using Discrete Mass Distribution](https://arxiv.org/abs/2602.00980)
*Yichen Cai,Yuan Gao,Pengpeng Li,Wei Wang,Guibin Sun,Jinhu Lü*

Main category: cs.RO

TL;DR: 本文提出了一种全分散的、基于分布的控制策略，用于实现复杂形状的机器人集群形成，并能适应集群规模的变化。


<details>
  <summary>Details</summary>
Motivation: 现有的基于密度分布的方法在实现复杂形状表示和分散化实现方面存在实际挑战，这促使研究者开发一种能够同时处理复杂形状和适应集群规模变化的全分散控制策略。

Method: 该方法首先提出了一种定义在采样点上的离散质量分布函数来模拟集群形成，并设计了一种分散式的均值偏移控制律，通过反馈质量估计来协调集群的全局分布以匹配采样点分布。通过设计的质量估计器，机器人以分散的方式获得所有采样点的质量估计，这些估计值可以渐近收敛到真实的全局值。

Result: 仿真和真实世界实验表明，该策略能够有效地形成复杂形状，并能适应集群规模的变化。

Conclusion: 该研究成功开发了一种全分散的、基于分布的控制策略，克服了现有方法的局限性，在机器人集群复杂形状形成和规模自适应方面取得了有效的结果。

Abstract: The density-distribution method has recently become a promising paradigm owing to its adaptability to variations in swarm size. However, existing studies face practical challenges in achieving complex shape representation and decentralized implementation. This motivates us to develop a fully decentralized, distribution-based control strategy with the dual capability of forming complex shapes and adapting to swarm-size variations. Specifically, we first propose a discrete mass-distribution function defined over a set of sample points to model swarm formation. In contrast to the continuous density-distribution method, our model eliminates the requirement for defining continuous density functions-a task that is difficult for complex shapes. Second, we design a decentralized meanshift control law to coordinate the swarm's global distribution to fit the sample-point distribution by feeding back mass estimates. The mass estimates for all sample points are achieved by the robots in a decentralized manner via the designed mass estimator. It is shown that the mass estimates of the sample points can asymptotically converge to the true global values. To validate the proposed strategy, we conduct comprehensive simulations and real-world experiments to evaluate the efficiency of complex shape formation and adaptability to swarm-size variations.

</details>


### [638] [HERMES: A Holistic End-to-End Risk-Aware Multimodal Embodied System with Vision-Language Models for Long-Tail Autonomous Driving](https://arxiv.org/abs/2602.00993)
*Weizhe Tang,Junwei You,Jiaxi Liu,Zhaoyi Wang,Rui Gan,Zilin Huang,Feng Wei,Bin Ran*

Main category: cs.RO

TL;DR: 本文提出了一种名为HERMES的端到端多模态驾驶框架，通过注入长尾风险线索来提升自动驾驶在长尾混合交通场景下的安全性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动驾驶模型在长尾混合交通场景下面临安全性和准确性挑战，尤其是在与异构道路使用者（如人类驾驶车辆和弱势道路使用者）互动时。

Method: HERMES利用一个基于基础模型辅助的标注流程，生成结构化的长尾场景上下文和长尾规划上下文，捕获危险中心线索、机动意图和安全偏好。该框架还引入了一个三模态驾驶模块，融合多视角感知、历史运动线索和语义引导，以实现风险感知的轨迹规划。

Result: 在真实世界的长尾数据集上进行的实验表明，HERMES在长尾混合交通场景下表现优于代表性的端到端和VLM驱动的基线模型。

Conclusion: HERMES能够有效地提高自动驾驶系统在长尾混合交通场景下的安全性和准确性，其关键组件都做出了有益的贡献。

Abstract: End-to-end autonomous driving models increasingly benefit from large vision--language models for semantic understanding, yet ensuring safe and accurate operation under long-tail conditions remains challenging. These challenges are particularly prominent in long-tail mixed-traffic scenarios, where autonomous vehicles must interact with heterogeneous road users, including human-driven vehicles and vulnerable road users, under complex and uncertain conditions. This paper proposes HERMES, a holistic risk-aware end-to-end multimodal driving framework designed to inject explicit long-tail risk cues into trajectory planning. HERMES employs a foundation-model-assisted annotation pipeline to produce structured Long-Tail Scene Context and Long-Tail Planning Context, capturing hazard-centric cues together with maneuver intent and safety preference, and uses these signals to guide end-to-end planning. HERMES further introduces a Tri-Modal Driving Module that fuses multi-view perception, historical motion cues, and semantic guidance, ensuring risk-aware accurate trajectory planning under long-tail scenarios. Experiments on the real-world long-tail dataset demonstrate that HERMES consistently outperforms representative end-to-end and VLM-driven baselines under long-tail mixed-traffic scenarios. Ablation studies verify the complementary contributions of key components.

</details>


### [639] [Offline Discovery of Interpretable Skills from Multi-Task Trajectories](https://arxiv.org/abs/2602.01018)
*Chongyu Zhu,Mithun Vanniasinghe,Jiayu Chen,Chi-Guhn Lee*

Main category: cs.RO

TL;DR: LOKI是一个用于从离线多任务数据中发现和学习可重用技能的端到端框架，用于分层模仿学习，并在D4RL Kitchen基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有分层模仿学习方法在从缺乏明确奖励或子任务标注的长时序、多任务离线数据中发现可重用技能方面存在挑战。

Method: LOKI框架分为三个阶段：1. 使用弱监督任务标签进行粗粒度的任务感知宏分割（基于对齐约束的VQ-VAE）；2. 使用自监督序列模型和迭代聚类进行微观层次的分割和技能边界巩固；3. 在基于选项的框架中构建分层策略，包含学习到的终止条件用于技能切换。

Result: LOKI在D4RL Kitchen基准测试中实现了高成功率，优于标准分层模仿学习基线。发现的技能具有语义意义，并且可以通过组合来解决新的任务。

Conclusion: LOKI能够有效地从离线数据中发现有意义且可组合的技能，为复杂机器人行为的学习提供了一种强大的方法。

Abstract: Hierarchical Imitation Learning is a powerful paradigm for acquiring complex robot behaviors from demonstrations. A central challenge, however, lies in discovering reusable skills from long-horizon, multi-task offline data, especially when the data lacks explicit rewards or subtask annotations. In this work, we introduce LOKI, a three-stage end-to-end learning framework designed for offline skill discovery and hierarchical imitation. The framework commences with a two-stage, weakly supervised skill discovery process: Stage one performs coarse, task-aware macro-segmentation by employing an alignment-enforced Vector Quantized VAE guided by weak task labels. Stage two then refines these segments at a micro-level using a self-supervised sequential model, followed by an iterative clustering process to consolidate skill boundaries. The third stage then leverages these precise boundaries to construct a hierarchical policy within an option-based framework-complete with a learned termination condition beta for explicit skill switching. LOKI achieves high success rates on the challenging D4RL Kitchen benchmark and outperforms standard HIL baselines. Furthermore, we demonstrate that the discovered skills are semantically meaningful, aligning with human intuition, and exhibit compositionality by successfully sequencing them to solve a novel, unseen task.

</details>


### [640] [Learning Adaptive Cross-Embodiment Visuomotor Policy with Contrastive Prompt Orchestration](https://arxiv.org/abs/2602.01040)
*Yuhang Zhang,Chao Yan,Jiaxi Yu,Jiaping Xiao,Mir Feroskhan*

Main category: cs.RO

TL;DR: 本文提出了一种名为CAPO（ContrAstive Prompt Orchestration）的新方法，用于学习自适应的视觉运动策略，以应对跨具身变化，如传感器配置和动态属性。CAPO通过对比提示学习和自适应提示编排，使智能体能够根据当前观察动态地构建最佳状态表示，从而有效避免过拟合，并在零样本跨域适应任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的学习方法难以将任务相关特征与领域特定变化（如光照、视场角、旋转）分离开来，导致样本效率低下，在未见过的环境中容易失败。因此，需要一种能够有效处理跨具身变化并提高样本效率和泛化能力的方法。

Method: CAPO集成了对比提示学习和自适应提示编排。对比提示学习采用混合对比学习策略，融合视觉、时间动作和文本目标，生成可学习的提示，每个提示都包含精细的领域因子。自适应提示编排机制根据当前观察动态地聚合这些提示，使智能体能够实时识别主导的领域因子，并构建最优状态表示。

Result: CAPO在样本效率和渐进性能上显著优于现有技术。在具有剧烈环境和物理变化（如光照、视场角和旋转）的未见过目标域上，CAPO表现出优越的零样本适应能力。

Conclusion: CAPO是一种有效的跨具身视觉运动策略适应解决方案，能够通过自适应地构建状态表示来克服领域变化带来的挑战，提高样本效率和泛化能力。

Abstract: Learning adaptive visuomotor policies for embodied agents remains a formidable challenge, particularly when facing cross-embodiment variations such as diverse sensor configurations and dynamic properties. Conventional learning approaches often struggle to separate task-relevant features from domain-specific variations (e.g., lighting, field-of-view, and rotation), leading to poor sample efficiency and catastrophic failure in unseen environments. To bridge this gap, we propose ContrAstive Prompt Orchestration (CAPO), a novel approach for learning visuomotor policies that integrates contrastive prompt learning and adaptive prompt orchestration. For prompt learning, we devise a hybrid contrastive learning strategy that integrates visual, temporal action, and text objectives to establish a pool of learnable prompts, where each prompt induces a visual representation encapsulating fine-grained domain factors. Based on these learned prompts, we introduce an adaptive prompt orchestration mechanism that dynamically aggregates these prompts conditioned on current observations. This enables the agent to adaptively construct optimal state representations by identifying dominant domain factors instantaneously. Consequently, the policy optimization is effectively shielded from irrelevant interference, preventing the common issue of overfitting to source domains. Extensive experiments demonstrate that CAPO significantly outperforms state-of-the-art baselines in sample efficiency and asymptotic performance. Crucially, it exhibits superior zero-shot adaptation across unseen target domains characterized by drastic environmental (e.g., illumination) and physical shifts (e.g., field-of-view and rotation), validating its effectiveness as a viable solution for cross-embodiment visuomotor policy adaptation.

</details>


### [641] [LLM-Based Behavior Tree Generation for Construction Machinery](https://arxiv.org/abs/2602.01041)
*Akinosuke Tsutsumi,Tomoya Itsuka,Yuichiro Kasahara,Tomoya Kouno,Kota Akinari,Genki Yamauchi,Daisuke Endo,Taro Abe,Takeshi Hashimoto,Keiji Nagatani,Ryo Kurazume*

Main category: cs.RO

TL;DR: 提出了一种基于大型语言模型（LLM）的流程，用于自动生成协调多台建筑机械协同作业的行为树（BT），并通过同步标志确保安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 建筑行业面临劳动力老龄化和技能流失，自动化需求迫切。现有的ROS2-TMS框架依赖手动设计的BT，难以扩展到异构机械协同的复杂场景。LLMs为自动化和BT生成提供了新机遇，但现有方法多限于模拟或简单机械，缺乏真实世界复杂建筑工地的应用。

Method: 提出一个两步LLM工作流：1. 高层规划，LLM生成同步标志；2. BT生成，使用结构化模板结合同步标志。通过系统数据库存储的参数进行规划以确保安全。将方法在模拟和真实世界实验中进行了验证。

Result: 成功生成了用于协调异构建筑机械的BT，并通过同步标志实现了安全有效的协同操作。在模拟和真实世界实验中均展示了方法的有效性。

Conclusion: 提出的LLM驱动的BT生成工作流，结合同步标志，为自动化复杂建筑工程提供了有前景的解决方案，有望提高机械协同的效率和安全性，克服现有手动BT设计的局限性。

Abstract: Earthwork operations are facing an increasing demand, while workforce aging and skill loss create a pressing need for automation. ROS2-TMS for Construction, a Cyber-Physical System framework designed to coordinate construction machinery, has been proposed for autonomous operation; however, its reliance on manually designed Behavior Trees (BTs) limits scalability, particularly in scenarios involving heterogeneous machine cooperation. Recent advances in large language models (LLMs) offer new opportunities for task planning and BT generation. However, most existing approaches remain confined to simulations or simple manipulators, with relatively few applications demonstrated in real-world contexts, such as complex construction sites involving multiple machines. This paper proposes an LLM-based workflow for BT generation, introducing synchronization flags to enable safe and cooperative operation. The workflow consists of two steps: high-level planning, where the LLM generates synchronization flags, and BT generation using structured templates. Safety is ensured by planning with parameters stored in the system database. The proposed method is validated in simulation and further demonstrated through real-world experiments, highlighting its potential to advance automation in civil engineering.

</details>


### [642] [Estimating Force Interactions of Deformable Linear Objects from their Shapes](https://arxiv.org/abs/2602.01085)
*Qi Jing Chen,Shilin Shan,Timothy Bretl,Quang-Cuong Pham*

Main category: cs.RO

TL;DR: 提出了一种仅通过观察变形线性物体（DLOs）的形状来检测和估计作用在其上的外力的方法。


<details>
  <summary>Details</summary>
Motivation: 在许多机器人-线交互任务中，接触点可能不在末端执行器而是在机器人身体的其他部位。准确识别这些交互对于安全高效的轨迹规划至关重要，可以防止电线损坏、避免机器人运动受限以及减轻潜在危险。

Method: 该方法利用深度相机获取的电线形状信息，并假设电线处于静态平衡或接近静态平衡状态。通过利用推导出的约束条件并求解基于沿电线的力-力矩平衡的线性方程组，来估计外力的大小和位置。

Result: 该方法在仿真中取得了高精度，并在现实世界实验的选定交互场景中展示了准确的估计能力。

Conclusion: 提出了一种仅通过观察DLOs的形状来估计外力的新型分析方法，无需额外的传感器或先验知识，并在仿真和实际实验中得到了验证。

Abstract: This work introduces an analytical approach for detecting and estimating external forces acting on deformable linear objects (DLOs) using only their observed shapes. In many robot-wire interaction tasks, contact occurs not at the end-effector but at other points along the robot's body. Such scenarios arise when robots manipulate wires indirectly (e.g., by nudging) or when wires act as passive obstacles in the environment. Accurately identifying these interactions is crucial for safe and efficient trajectory planning, helping to prevent wire damage, avoid restricted robot motions, and mitigate potential hazards. Existing approaches often rely on expensive external force-torque sensor or that contacts occur at the end-effector for accurate force estimation. Using wire shape information acquired from a depth camera and under the assumption that the wire is in or near its static equilibrium, our method estimates both the location and magnitude of external forces without additional prior knowledge. This is achieved by exploiting derived consistency conditions and solving a system of linear equations based on force-torque balance along the wire. The approach was validated through simulation, where it achieved high accuracy, and through real-world experiments, where accurate estimation was demonstrated in selected interaction scenarios.

</details>


### [643] [A Systematic Study of Data Modalities and Strategies for Co-training Large Behavior Models for Robot Manipulation](https://arxiv.org/abs/2602.01067)
*Fanqi Lin,Kushal Arora,Jean Mercat,Haruki Nishimura,Paarth Shah,Chen Xu,Mengchao Zhang,Mark Zolotas,Maya Angeles,Owen Pfannenstiehl,Andrew Beaulieu,Jose Barreiros*

Main category: cs.RO

TL;DR: 该研究通过大规模实证研究，评估了五种协同训练数据模式（标准视觉-语言数据、密集的机器人轨迹语言注释、跨体机器人数据、人类视频、离散机器人动作令牌）以及单阶段和多阶段训练策略对机器人策略性能的影响。结果表明，视觉-语言和跨体机器人数据能显著提升泛化能力，而离散动作令牌无效。有效的模式组合能累积增益，并通过微调实现对新长时序灵巧任务的快速适应。协同训练还能恢复因仅在机器人数据上训练而退化的视觉语言理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型行为模型在机器人操纵方面表现出色，但其泛化能力受限于机器人数据的覆盖范围。为了在不增加数据收集成本的情况下扩大覆盖范围，研究人员尝试协同训练，但不同协同训练数据模式和策略对策略性能的影响尚不清楚。

Method: 研究人员进行了大规模的实证研究，训练了视觉-语言-动作策略，使用了4000小时的机器人和人类操作数据以及5000万个视觉-语言样本。他们评估了五种协同训练数据模式（标准视觉-语言数据、机器人轨迹语言注释、跨体机器人数据、人类视频、离散机器人动作令牌），并考察了单阶段和多阶段训练策略。实验评估了89种策略，进行了58000次模拟回滚和2835次真实世界回滚。

Result: 协同训练使用视觉-语言和跨体机器人数据能显著提升策略在分布变化、未见任务和语言遵循方面的泛化能力。离散动作令牌的变体没有带来显著好处。结合有效的模式可以带来累积增益，并通过微调实现对未见长时序灵巧任务的快速适应。仅在机器人数据上训练会损害视觉-语言模型的视觉语言理解能力，而协同训练可以恢复这些能力。在模拟基准测试中，明确将链式思维痕迹作为动作生成的条件并未提高性能。

Conclusion: 该研究为构建可扩展的通用机器人策略提供了实用指导。视觉-语言和跨体机器人数据是提高机器人策略泛化能力的关键，而离散动作令牌效果不佳。有效的协同训练策略可以增强机器人策略的鲁棒性、适应性和语言理解能力。

Abstract: Large behavior models have shown strong dexterous manipulation capabilities by extending imitation learning to large-scale training on multi-task robot data, yet their generalization remains limited by the insufficient robot data coverage. To expand this coverage without costly additional data collection, recent work relies on co-training: jointly learning from target robot data and heterogeneous data modalities. However, how different co-training data modalities and strategies affect policy performance remains poorly understood. We present a large-scale empirical study examining five co-training data modalities: standard vision-language data, dense language annotations for robot trajectories, cross-embodiment robot data, human videos, and discrete robot action tokens across single- and multi-phase training strategies. Our study leverages 4,000 hours of robot and human manipulation data and 50M vision-language samples to train vision-language-action policies. We evaluate 89 policies over 58,000 simulation rollouts and 2,835 real-world rollouts. Our results show that co-training with forms of vision-language and cross-embodiment robot data substantially improves generalization to distribution shifts, unseen tasks, and language following, while discrete action token variants yield no significant benefits. Combining effective modalities produces cumulative gains and enables rapid adaptation to unseen long-horizon dexterous tasks via fine-tuning. Training exclusively on robot data degrades the visiolinguistic understanding of the vision-language model backbone, while co-training with effective modalities restores these capabilities. Explicitly conditioning action generation on chain-of-thought traces learned from co-training data does not improve performance in our simulation benchmark. Together, these results provide practical guidance for building scalable generalist robot policies.

</details>


### [644] [Failure-Aware Bimanual Teleoperation via Conservative Value Guided Assistance](https://arxiv.org/abs/2602.01092)
*Peng Zhou,Zhongxuan Li,Jinsong Wu,Jiaming Qi,Jun Hu,David Navarro-Alarcon,Jia Pan,Lihua Xie,Shiyao Zhang,Zeqing Zhang*

Main category: cs.RO

TL;DR: 提出了一种用于双臂遥操作的价值导向、故障感知框架，该框架能在保持人类控制权的同时提供顺从的触觉辅助，通过保守价值学习来预测任务可行性，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 高精度操作的遥操作任务对成功容忍度要求高且接触动力学复杂，在信息不全的情况下，人类操作员难以预判失败。因此，需要一种能够感知潜在失败并提供辅助的遥操作框架。

Method: 利用包含成功和失败案例的异构离线遥操作数据，通过保守价值学习（Conservative Value Learning）建立任务可行性模型，并学习一个保守的成功分数。此外，还学习了一个执行器来提供纠正运动方向。这两个组件通过主端关节空间阻抗接口整合，提供连续的指导，引导操作员避开易失败的操作。

Result: 在富接触操纵任务上的实验结果表明，与传统的遥操作和共享自主基线相比，该框架提高了任务成功率，并降低了操作员的工作量。

Conclusion: 保守价值学习是一种有效的机制，可以将故障意识融入双边遥操作，从而在提高任务成功率和降低操作员工作量方面取得良好效果。

Abstract: Teleoperation of high-precision manipulation is con-strained by tight success tolerances and complex contact dy-namics, which make impending failures difficult for human operators to anticipate under partial observability. This paper proposes a value-guided, failure-aware framework for bimanual teleoperation that provides compliant haptic assistance while pre-serving continuous human authority. The framework is trained entirely from heterogeneous offline teleoperation data containing both successful and failed executions. Task feasibility is mod-eled as a conservative success score learned via Conservative Value Learning, yielding a risk-sensitive estimate that remains reliable under distribution shift. During online operation, the learned success score regulates the level of assistance, while a learned actor provides a corrective motion direction. Both are integrated through a joint-space impedance interface on the master side, yielding continuous guidance that steers the operator away from failure-prone actions without overriding intent. Experimental results on contact-rich manipulation tasks demonstrate improved task success rates and reduced operator workload compared to conventional teleoperation and shared-autonomy baselines, indicating that conservative value learning provides an effective mechanism for embedding failure awareness into bilateral teleoperation. Experimental videos are available at https://www.youtube.com/watch?v=XDTsvzEkDRE

</details>


### [645] [StreamVLA: Breaking the Reason-Act Cycle via Completion-State Gating](https://arxiv.org/abs/2602.01100)
*Hang Wu,Tongqing Chen,Jiasen Wang,Xiaotao Li,Lu Fang*

Main category: cs.RO

TL;DR: StreamVLA是一种新的双系统机器人操作架构，通过任务分解和目标想象来提高效率和稳定性，从而在长时机器人操作中实现了最先进的性能和显著的延迟降低。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作（VLA）模型在长时机器人操作中存在推理冗余、高延迟和目标不稳定的问题，因为它们在每个时间步都会进行多模态推理。

Method: StreamVLA采用双系统架构，包括文本任务分解、视觉目标想象和连续动作生成。核心是一个“锁定和门控”机制，仅在检测到子任务转换时触发慢速推理，生成文本指令和想象完成状态。这个完成状态作为一个时间不变的目标锚定，而Flow Matching动作头部则在稳定执行期间利用高层意图，避免了自回归解码。

Result: StreamVLA在LIBERO基准测试中取得了98.5%的成功率，并在真实世界干扰场景中表现出鲁棒的恢复能力。与全推理基线相比，推理延迟降低了48%，并且在72%的时间步中能够绕过昂贵的自回归解码。

Conclusion: StreamVLA通过其分层抽象和智能计算调制机制，有效地解决了长时机器人操作中的效率和稳定性挑战，实现了优于现有方法的性能，并显著降低了推理延迟。

Abstract: Long-horizon robotic manipulation requires bridging the gap between high-level planning (System 2) and low-level control (System 1). Current Vision-Language-Action (VLA) models often entangle these processes, performing redundant multimodal reasoning at every timestep, which leads to high latency and goal instability. To address this, we present StreamVLA, a dual-system architecture that unifies textual task decomposition, visual goal imagination, and continuous action generation within a single parameter-efficient backbone. We introduce a "Lock-and-Gated" mechanism to intelligently modulate computation: only when a sub-task transition is detected, the model triggers slow thinking to generate a textual instruction and imagines the specific visual completion state, rather than generic future frames. Crucially, this completion state serves as a time-invariant goal anchor, making the policy robust to execution speed variations. During steady execution, these high-level intents are locked to condition a Flow Matching action head, allowing the model to bypass expensive autoregressive decoding for 72% of timesteps. This hierarchical abstraction ensures sub-goal focus while significantly reducing inference latency. Extensive evaluations demonstrate that StreamVLA achieves state-of-the-art performance, with a 98.5% success rate on the LIBERO benchmark and robust recovery in real-world interference scenarios, achieving a 48% reduction in latency compared to full-reasoning baselines.

</details>


### [646] [KAN We Flow? Advancing Robotic Manipulation with 3D Flow Matching via KAN & RWKV](https://arxiv.org/abs/2602.01115)
*Zhihao Chen,Yiyuan Ge,Ziyang Wang*

Main category: cs.RO

TL;DR: 本文提出了一种名为KAN-We-Flow的基于流匹配的视觉-运动策略，它结合了RWKV和KAN网络来构建一个轻量级且高效的网络骨干，用于3D操作。该方法通过引入RWKV-KAN块和行动一致性正则化（ACR）损失，显著减少了参数量，实现了快速推理，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的视觉-运动策略虽然在模拟动作分布方面表现出色，但由于需要多步去噪和使用大型UNet骨干，导致推理效率低下，难以在资源受限的机器人上部署。基于流匹配的方法虽然可以一步完成采样，但以往的实现仍依赖大型UNet架构。

Method: 提出了一种名为KAN-We-Flow的流匹配策略，其核心是一个RWKV-KAN块，该块首先利用RWKV进行高效的时/通道混合以传播任务上下文，然后使用GroupKAN层应用可学习的、基于样条的、组wise的函数映射，对RWKV输出进行特征wise的非线性校准。此外，还引入了行动一致性正则化（ACR）损失，通过欧拉外插强制对齐预测的动作轨迹与专家演示，以稳定训练并提高策略精度。

Result: KAN-We-Flow在不使用大型UNet的情况下，参数量减少了86.8%，并保持了快速的运行时性能。在Adroit、Meta-World和DexArt基准测试中取得了最先进的成功率。

Conclusion: KAN-We-Flow是一种轻量级且高效的视觉-运动策略，通过结合RWKV和KAN网络以及ACR损失，克服了现有方法的局限性，并在3D操作任务中实现了优越的性能。

Abstract: Diffusion-based visuomotor policies excel at modeling action distributions but are inference-inefficient, since recursively denoising from noise to policy requires many steps and heavy UNet backbones, which hinders deployment on resource-constrained robots. Flow matching alleviates the sampling burden by learning a one-step vector field, yet prior implementations still inherit large UNet-style architectures. In this work, we present KAN-We-Flow, a flow-matching policy that draws on recent advances in Receptance Weighted Key Value (RWKV) and Kolmogorov-Arnold Networks (KAN) from vision to build a lightweight and highly expressive backbone for 3D manipulation. Concretely, we introduce an RWKV-KAN block: an RWKV first performs efficient time/channel mixing to propagate task context, and a subsequent GroupKAN layer applies learnable spline-based, groupwise functional mappings to perform feature-wise nonlinear calibration of the action mapping on RWKV outputs. Moreover, we introduce an Action Consistency Regularization (ACR), a lightweight auxiliary loss that enforces alignment between predicted action trajectories and expert demonstrations via Euler extrapolation, providing additional supervision to stabilize training and improve policy precision. Without resorting to large UNets, our design reduces parameters by 86.8\%, maintains fast runtime, and achieves state-of-the-art success rates on Adroit, Meta-World, and DexArt benchmarks. Our project page can be viewed in \href{https://zhihaochen-2003.github.io/KAN-We-Flow.github.io/}{\textcolor{red}{link}}

</details>


### [647] [UniForce: A Unified Latent Force Model for Robot Manipulation with Diverse Tactile Sensors](https://arxiv.org/abs/2602.01153)
*Zhuo Chen,Fei Ni,Kaiyao Luo,Zhiyuan Wu,Xuyang Zhang,Emmanouil Spyrakos-Papastavridis,Lorenzo Jamone,Nathan F. Lepora,Jiankang Deng,Shan Luo*

Main category: cs.RO

TL;DR: 提出UniForce框架，通过学习一个统一的潜变量力空间，解决了异构触觉传感器在力感知机器人操作中的泛化性问题，实现了跨传感器零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 现有的触觉传感器异构性（传感原理、尺寸、材料不同）导致数据收集、校准和模型训练的复杂性，限制了力感知策略学习的泛化能力。

Method: UniForce框架通过联合建模逆动力学（图像到力）和正向动力学（力到图像），并引入力平衡和图像重构损失，学习跨不同触觉传感器的共享潜变量力空间。利用静态平衡和传感器-物体-传感器交互来收集力配对数据，避免对外部力/力矩传感器的依赖，从而实现跨传感器对齐。

Result: 在GelSight、TacTip和uSkin等异构触觉传感器上进行了广泛实验，UniForce在力估计方面表现出持续的性能提升，优于现有方法。在机器人擦拭任务中，UniForce能够有效地实现跨传感器协调，并整合到Vision-Tactile-Language-Action (VTLA)模型中。

Conclusion: UniForce提出的统一触觉编码器能够实现零样本迁移，无需重新训练或微调，即可应用于下游的力感知机器人操作任务，有效解决了异构触觉传感器的数据通用性问题。

Abstract: Force sensing is essential for dexterous robot manipulation, but scaling force-aware policy learning is hindered by the heterogeneity of tactile sensors. Differences in sensing principles (e.g., optical vs. magnetic), form factors, and materials typically require sensor-specific data collection, calibration, and model training, thereby limiting generalisability. We propose UniForce, a novel unified tactile representation learning framework that learns a shared latent force space across diverse tactile sensors. UniForce reduces cross-sensor domain shift by jointly modeling inverse dynamics (image-to-force) and forward dynamics (force-to-image), constrained by force equilibrium and image reconstruction losses to produce force-grounded representations. To avoid reliance on expensive external force/torque (F/T) sensors, we exploit static equilibrium and collect force-paired data via direct sensor--object--sensor interactions, enabling cross-sensor alignment with contact force. The resulting universal tactile encoder can be plugged into downstream force-aware robot manipulation tasks with zero-shot transfer, without retraining or finetuning. Extensive experiments on heterogeneous tactile sensors including GelSight, TacTip, and uSkin, demonstrate consistent improvements in force estimation over prior methods, and enable effective cross-sensor coordination in Vision-Tactile-Language-Action (VTLA) models for a robotic wiping task. Code and datasets will be released.

</details>


### [648] [Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models](https://arxiv.org/abs/2602.01166)
*Shuanghao Bai,Jing Lyu,Wanqi Zhou,Zhe Li,Dakai Wang,Lei Xing,Xiaoguang Zhao,Pengwei Wang,Zhongyuan Wang,Cheng Chi,Badong Chen,Shanghang Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为LaRA-VLA的统一视觉-语言-动作（VLA）框架，它将多模态链式思考（CoT）推理内化到连续的潜在表示中，用于具身动作，从而实现了高效且面向动作的控制。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型受益于CoT推理，但存在推理开销高和推理表示与感知和控制不匹配的问题。研究者希望开发一种能够有效且高效地进行推理和控制的VLA模型。

Method: LaRA-VLA在潜在空间中进行统一的推理和预测，无需在推理时显式生成CoT。它采用一种基于课程的学习范式，从显式的文本和视觉CoT监督逐步过渡到潜在推理，并最终将潜在推理动力学应用于动作生成。

Result: LaRA-VLA在模拟基准和长时程真实机器人操作任务上均表现优于最先进的VLA方法，并将推理延迟降低了高达90%。

Conclusion: 潜在推理是一种有效且高效的实时具身控制范式，LaRA-VLA证明了其在该领域的潜力。

Abstract: Vision-Language-Action (VLA) models benefit from chain-of-thought (CoT) reasoning, but existing approaches incur high inference overhead and rely on discrete reasoning representations that mismatch continuous perception and control. We propose Latent Reasoning VLA (\textbf{LaRA-VLA}), a unified VLA framework that internalizes multi-modal CoT reasoning into continuous latent representations for embodied action. LaRA-VLA performs unified reasoning and prediction in latent space, eliminating explicit CoT generation at inference time and enabling efficient, action-oriented control. To realize latent embodied reasoning, we introduce a curriculum-based training paradigm that progressively transitions from explicit textual and visual CoT supervision to latent reasoning, and finally adapts latent reasoning dynamics to condition action generation. We construct two structured CoT datasets and evaluate LaRA-VLA on both simulation benchmarks and long-horizon real-robot manipulation tasks. Experimental results show that LaRA-VLA consistently outperforms state-of-the-art VLA methods while reducing inference latency by up to 90\% compared to explicit CoT-based approaches, demonstrating latent reasoning as an effective and efficient paradigm for real-time embodied control. Project Page: \href{https://loveju1y.github.io/Latent-Reasoning-VLA/}{LaRA-VLA Website}.

</details>


### [649] [Reinforcement Learning for Active Perception in Autonomous Navigation](https://arxiv.org/abs/2602.01266)
*Grzegorz Malczyk,Mihir Kulkarni,Kostas Alexis*

Main category: cs.RO

TL;DR: 本文提出了一种端到端的强化学习框架，使自主导航机器人能够主动控制相机以增强态势感知，从而在复杂未知环境中实现更安全的飞行和探索行为。


<details>
  <summary>Details</summary>
Motivation: 应对自主导航在复杂未知环境中进行主动感知的挑战，以及在导航过程中提升机器人态势感知的需求。

Method: 使用端到端的强化学习框架，结合了目标导向的运动规划和信息驱动的主动相机控制。机器人状态、深度帧和局部几何表示作为观测，并引入了基于体素的信息度量来增强导航奖励。

Result: 该策略实现了比固定相机基线更安全的飞行，并诱导了内在的探索行为。

Conclusion: 提出的强化学习框架能够使飞行器在平衡目标导向运动和探索性感知的同时，学习到鲁棒的策略，从而实现更安全的飞行并展现出探索行为。

Abstract: This paper addresses the challenge of active perception within autonomous navigation in complex, unknown environments. Revisiting the foundational principles of active perception, we introduce an end-to-end reinforcement learning framework in which a robot must not only reach a goal while avoiding obstacles, but also actively control its onboard camera to enhance situational awareness. The policy receives observations comprising the robot state, the current depth frame, and a particularly local geometry representation built from a short history of depth readings. To couple collision-free motion planning with information-driven active camera control, we augment the navigation reward with a voxel-based information metric. This enables an aerial robot to learn a robust policy that balances goal-directed motion with exploratory sensing. Extensive evaluation demonstrates that our strategy achieves safer flight compared to using fixed, non-actuated camera baselines while also inducing intrinsic exploratory behaviors.

</details>


### [650] [SkySim: A ROS2-based Simulation Environment for Natural Language Control of Drone Swarms using Large Language Models](https://arxiv.org/abs/2602.01226)
*Aditya Shibu,Marah Saleh,Mohamed Al-Musleh,Nidhal Abdulaziz*

Main category: cs.RO

TL;DR: 本文提出了一种名为 SkySim 的 ROS2/Gazebo 仿真框架，它利用大型语言模型（LLMs）进行无人机群的自然语言控制，并通过人工势场（APF）算法保证飞行的安全性与可行性。该框架能够将自然语言指令转化为无人机可执行的路径点，并实时处理碰撞避免、运动学约束和地理围栏等问题，实现了高效、可扩展的无人机群控制，并降低了对专业知识的需求。


<details>
  <summary>Details</summary>
Motivation: 传统的无人机群控制方法需要专业知识且适应性差，而大型语言模型虽然能够进行自然语言控制，但缺乏物理约束，容易生成不安全的飞行轨迹。因此，需要一种能够结合 LLM 的高级规划能力与机器人安全执行能力的方法，使非专业人士也能控制无人机群。

Method: 本文提出的 SkySim 框架基于 ROS2 和 Gazebo，使用 Gemini 3.5 Pro LLM 将自然语言指令（如“形成一个圆形”）转化为空间路径点。一个实时的人工势场（APF）安全过滤器会对这些路径点进行微调，以避免碰撞、满足运动学限制并遵守地理围栏。该系统以 20 Hz 的频率运行。

Result: 通过在 3、10 和 30 架 Crazyflie 无人机组成的无人机群上的实验，SkySim 证明了其在空间推理准确性（在测试的几何图形上达到 100%）、实时碰撞预防以及系统可扩展性方面的有效性。

Conclusion: SkySim 成功地将大型语言模型的认知能力与机器人系统的安全执行能力相结合，为非专业用户提供了直观的无人机群控制方式，使其能够迭代优化无人机群的行为。该框架有望在动态环境中实现更广泛的无人机群应用，并为未来的硬件集成奠定基础。

Abstract: Unmanned Aerial Vehicle (UAV) swarms offer versatile applications in logistics, agriculture, and surveillance, yet controlling them requires expert knowledge for safety and feasibility. Traditional static methods limit adaptability, while Large Language Models (LLMs) enable natural language control but generate unsafe trajectories due to lacking physical grounding. This paper introduces SkySim, a ROS2-based simulation framework in Gazebo that decouples LLM high-level planning from low-level safety enforcement. Using Gemini 3.5 Pro, SkySim translates user commands (e.g., "Form a circle") into spatial waypoints, informed by real-time drone states. An Artificial Potential Field (APF) safety filter applies minimal adjustments for collision avoidance, kinematic limits, and geo-fencing, ensuring feasible execution at 20 Hz. Experiments with swarms of 3, 10, and 30 Crazyflie drones validate spatial reasoning accuracy (100% across tested geometric primitives), real-time collision prevention, and scalability. SkySim empowers non-experts to iteratively refine behaviors, bridging AI cognition with robotic safety for dynamic environments. Future work targets hardware integration.

</details>


### [651] [TriphiBot: A Triphibious Robot Combining FOC-based Propulsion with Eccentric Design](https://arxiv.org/abs/2602.01385)
*Xiangyu Li,Mingwei Lai,Mengke Zhang,Junxiao Lin,Tiancheng Lai,Junping Zhi,Chao Xu,Fei Gao,Yanjun Cao*

Main category: cs.RO

TL;DR: 本文提出了一种极简设计的三栖机器人，能够进行空中、陆地和水下运动，并解决了现有设计中存在的机械复杂性和推进效率低的问题，通过偏心质心设计和基于场定向控制的统一推进系统实现了高效跨域运动，并采用了混合非线性模型预测控制-PID控制系统来保证稳定性和平稳过渡。


<details>
  <summary>Details</summary>
Motivation: 现有双栖机器人设计存在机械复杂性高、推进效率低等问题，限制了其应用。需要一种能够实现多领域运动和跨领域转换，并且设计简洁、效率高、控制稳定的三栖机器人。

Method: 1. 采用极简设计，结合四旋翼结构和两个被动轮，无需额外执行器。
2. 引入偏心质心设计，使推力与运动方向一致，提高地面支撑运动效率。
3. 开发基于场定向控制（FOC）的统一推进系统，解决不同介质下的扭矩匹配问题。
4. 提出混合非线性模型预测控制（HNMPC）-PID控制系统，用于多领域运动和跨模式过渡的稳定控制。

Result: 实验验证了机器人具备空中、陆地和水下运动能力，以及跨模式过渡能力。所提出的推进系统展示了其效率和适应性。

Conclusion: 该研究成功开发了一种新型极简设计的三栖机器人，通过创新的设计和控制策略，有效解决了多领域运动和跨领域转换的挑战，为未来复杂任务下的机器人应用提供了新的可能性。

Abstract: Triphibious robots capable of multi-domain motion and cross-domain transitions are promising to handle complex tasks across diverse environments. However, existing designs primarily focus on dual-mode platforms, and some designs suffer from high mechanical complexity or low propulsion efficiency, which limits their application. In this paper, we propose a novel triphibious robot capable of aerial, terrestrial, and aquatic motion, by a minimalist design combining a quadcopter structure with two passive wheels, without extra actuators. To address inefficiency of ground-support motion (moving on land/seabed) for quadcopter based designs, we introduce an eccentric Center of Gravity (CoG) design that inherently aligns thrust with motion, enhancing efficiency without specialized mechanical transformation designs. Furthermore, to address the drastic differences in motion control caused by different fluids (air and water), we develop a unified propulsion system based on Field-Oriented Control (FOC). This method resolves torque matching issues and enables precise, rapid bidirectional thrust across different mediums. Grounded in the perspective of living condition and ground support, we analyse the robot's dynamics and propose a Hybrid Nonlinear Model Predictive Control (HNMPC)-PID control system to ensure stable multi-domain motion and seamless transitions. Experimental results validate the robot's multi-domain motion and cross-mode transition capability, along with the efficiency and adaptability of the proposed propulsion system.

</details>


### [652] [Instance-Guided Unsupervised Domain Adaptation for Robotic Semantic Segmentation](https://arxiv.org/abs/2602.01389)
*Michele Antonazzi,Lorenzo Signorelli,Matteo Luperto,Nicola Basilico*

Main category: cs.RO

TL;DR: 提出了一种利用3D体素地图生成多视角一致的伪标签，并结合零样本实例分割能力进行精炼，然后用于无监督领域自适应，以提高机器人感知系统在部署环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督领域自适应（UDA）方法在处理机器人部署环境与训练数据集之间视觉分布差异时存在性能下降问题，并且对跨视图实例级不一致性敏感。

Method: 1. 从3D体素地图生成多视角一致的伪标签。2. 利用零样本实例分割能力精炼这些伪标签，确保实例级连贯性。3. 使用精炼后的伪标签进行自监督微调。

Result: 在真实世界数据上的实验表明，该方法在不使用目标域地面真实标签的情况下，能够持续优于基于多视角一致性的最先进UDA基线方法。

Conclusion: 该方法能够有效地解决机器人感知中的领域漂移问题，通过生成并利用高质量的伪标签，实现了在部署时进行有效的无监督领域自适应。

Abstract: Semantic segmentation networks, which are essential for robotic perception, often suffer from performance degradation when the visual distribution of the deployment environment differs from that of the source dataset on which they were trained. Unsupervised Domain Adaptation (UDA) addresses this challenge by adapting the network to the robot's target environment without external supervision, leveraging the large amounts of data a robot might naturally collect during long-term operation. In such settings, UDA methods can exploit multi-view consistency across the environment's map to fine-tune the model in an unsupervised fashion and mitigate domain shift. However, these approaches remain sensitive to cross-view instance-level inconsistencies. In this work, we propose a method that starts from a volumetric 3D map to generate multi-view consistent pseudo-labels. We then refine these labels using the zero-shot instance segmentation capabilities of a foundation model, enforcing instance-level coherence. The refined annotations serve as supervision for self-supervised fine-tuning, enabling the robot to adapt its perception system at deployment time. Experiments on real-world data demonstrate that our approach consistently improves performance over state-of-the-art UDA baselines based on multi-view consistency, without requiring any ground-truth labels in the target domain.

</details>


### [653] [Sem-NaVAE: Semantically-Guided Outdoor Mapless Navigation via Generative Trajectory Priors](https://arxiv.org/abs/2602.01429)
*Gonzalo Olguin,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 提出了一种无需地图的户外全局导航方法，结合使用 CVAE 生成轨迹，并利用轻量级 VLM 进行基于自然语言的轨迹选择和执行。


<details>
  <summary>Details</summary>
Motivation: 为了实现高效的户外全局导航，特别是当缺乏预先构建地图时，需要一种能够自主探索并实时选择合适路径的方法。

Method: 使用条件变分自编码器 (CVAE) 生成大量具有多样性的轨迹，然后利用开源词汇语义分割的轻量级视觉语言模型 (VLM) 根据自然语言指令对生成的轨迹进行评分和选择，最后由一个先进的局部规划器执行速度指令。

Result: 该方法能够在户外环境中实时生成并选择多样化轨迹进行导航，并在真实世界实验中取得了优于现有技术的性能。

Conclusion: 该提出的无地图全局导航方法能够有效地在户外环境中根据自然语言指令进行实时导航，并展现出强大的泛化能力和优越的性能。

Abstract: This work presents a mapless global navigation approach for outdoor applications. It combines the exploratory capacity of conditional variational autoencoders (CVAEs) to generate trajectories and the semantic segmentation capabilities of a lightweight visual language model (VLM) to select the trajectory to execute. Open-vocabulary segmentation is used to score and select the generated trajectories based on natural language, and a state-of-the-art local planner executes velocity commands. One of the key features of the proposed approach is its ability to generate a large variability of trajectories and to select them and navigate in real-time. The approach was validated through real-world outdoor navigation experiments, achieving superior performance compared to state-of-the-art methods. A video showing an experimental run of the system can be found in https://www.youtube.com/watch?v=i3R5ey5O2yk.

</details>


### [654] [Towards a Novel Wearable Robotic Vest for Hemorrhage Suppression](https://arxiv.org/abs/2602.01448)
*Harshith Jella,Pejman Kheradmand,Joseph Klein,Behnam Moradkhani,Yash Chitalia*

Main category: cs.RO

TL;DR: 本文提出了一种新型机器人系统，用于在紧急情况下（包括太空站等特殊环境）处理严重出血。该系统具有一个可变形的“环形机构”，可以通过改变形状来适应不同解剖部位的伤口，并配合充气气囊实现均匀恒定的压力。实验验证了其在模拟伤口止血方面的潜力，但也指出其在覆盖复杂解剖结构方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 为应对紧急情况（包括太空等特殊环境）下的严重出血，开发一种能够适应不同解剖部位并提供稳定压力的止血解决方案。

Method: 开发了一种具有形状可调（从圆形到椭圆形）的环形机械臂系统，并设计了不同柔韧性的臂以适应身体非四肢部位。该系统配备了可充气环和气囊，以实现对伤口的均匀恒定压力。通过实验评估了不同环形臂配置的弯曲刚度，并测量了气囊系统的压力。最后，在模拟伤口套件上进行了止血效果测试。

Result: 成功开发了一种能够改变形状以适应不同伤口部位的机器人止血系统，并能通过充气气囊施加均匀压力。实验表明该系统在模拟伤口上有效控制了出血，但其形状改变能力在完全充气或对复杂解剖结构的应用上存在局限。

Conclusion: 该新型机器人系统为处理严重出血提供了一种有前景的解决方案，尤其是在应对复杂环境和不同解剖部位方面。尽管在覆盖复杂区域方面存在一些局限性，但其可调形状和稳定压力的能力在模拟测试中得到了验证，显示了其在紧急止血领域的应用潜力。

Abstract: This paper introduces a novel robotic system designed to manage severe bleeding in emergency scenarios, including unique environments like space stations. The robot features a shape-adjustable "ring mechanism", transitioning from a circular to an elliptical configuration to adjust wound coverage across various anatomical regions. We developed various arms for this ring mechanism with varying flexibilities to improve adaptability when applied to non-extremities of the body (abdomen, back, neck, etc.). To apply equal and constant pressure across the wound, we developed an inflatable ring and airbag balloon that are compatible with this shape-changing ring mechanism. A series of experiments focused on evaluating various ring arm configurations to characterize their bending stiffness. Subsequent experiments measured the force exerted by the airbag balloon system using a digital scale. Despite its promising performance, certain limitations related to coverage area are identified. The shape-changing effect of the device is limited to scenarios involving partially inflated or deflated airbag balloons, and cannot fully conform to complex anatomical regions. Finally, the device was tested on casualty simulation kits, where it successfully demonstrated its ability to control simulated bleeding.

</details>


### [655] [Geometry-Aware Sampling-Based Motion Planning on Riemannian Manifolds](https://arxiv.org/abs/2602.00992)
*Phone Thiha Kyaw,Jonathan Kelly*

Main category: cs.RO

TL;DR: 本文提出了一种基于黎曼流形采样的机器人运动规划框架，能够直接在具有非欧几里得几何的配置空间上进行规划，并计算出更优的无碰撞轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有机器人运动规划方法通常忽略配置空间中的非欧几里得几何结构，使用欧氏距离进行规划，导致规划效率低下和轨迹质量不高。需要一种能够有效处理这种几何结构的规划方法。

Method: 提出了一种基于黎曼流形采样的运动规划框架。该框架使用计算高效的三阶精度黎曼测地线距离近似方法，并设计了一个基于一阶收缩和黎曼自然梯度引导的局部规划器，以在流形上跟踪路径。

Result: 在两连杆平面机械臂、Franka机械臂以及SE(2)中的非完整刚体运动规划实验中，所提出的方法相比于基于欧氏距离的规划器和经典的数值测地线求解器，能够生成成本更低的轨迹。

Conclusion: 所提出的基于黎曼流形采样的运动规划框架能够有效地处理具有非欧几里得几何的配置空间，并在保证轨迹质量的同时提高了规划效率，克服了传统方法的局限性。

Abstract: In many robot motion planning problems, task objectives and physical constraints induce non-Euclidean geometry on the configuration space, yet many planners operate using Euclidean distances that ignore this structure. We address the problem of planning collision-free motions that minimize length under configuration-dependent Riemannian metrics, corresponding to geodesics on the configuration manifold. Conventional numerical methods for computing such paths do not scale well to high-dimensional systems, while sampling-based planners trade scalability for geometric fidelity. To bridge this gap, we propose a sampling-based motion planning framework that operates directly on Riemannian manifolds. We introduce a computationally efficient midpoint-based approximation of the Riemannian geodesic distance and prove that it matches the true Riemannian distance with third-order accuracy. Building on this approximation, we design a local planner that traces the manifold using first-order retractions guided by Riemannian natural gradients. Experiments on a two-link planar arm and a 7-DoF Franka manipulator under a kinetic-energy metric, as well as on rigid-body planning in $\mathrm{SE}(2)$ with non-holonomic motion constraints, demonstrate that our approach consistently produces lower-cost trajectories than Euclidean-based planners and classical numerical geodesic-solver baselines.

</details>


### [656] [TreeLoc: 6-DoF LiDAR Global Localization in Forests via Inter-Tree Geometric Matching](https://arxiv.org/abs/2602.01501)
*Minwoo Jung,Nived Chebrolu,Lucas Carvalho de Lima,Haedam Oh,Maurice Fallon,Ayoung Kim*

Main category: cs.RO

TL;DR: 提出了一种名为TreeLoc的基于LiDAR的森林全局定位框架，利用树干和其离地胸径（DBH）进行场景表示，通过树分布直方图（TDH）和2D三角形描述符进行匹配，并采用两步几何验证进行姿态估计，在森林环境中实现了精确的定位。


<details>
  <summary>Details</summary>
Motivation: 森林环境中GPS信号弱，LiDAR测量存在重复、遮挡和结构复杂等问题，使得传统的城市中心定位方法失效，需要开发专门针对森林环境的鲁棒定位解决方案。

Method: TreeLoc框架通过以下步骤实现定位：1. 使用树干和DBH表示场景；2. 将树干轴对齐至通用坐标系；3. 使用树分布直方图（TDH）进行粗略匹配；4. 使用2D三角形描述符进行精细匹配；5. 通过两步几何验证进行6-DoF姿态估计。

Result: TreeLoc在不同的森林基准测试中表现优于现有方法，实现了精确的定位。消融实验验证了各个组件的有效性。此外，TreeLoc还可以通过紧凑的全局树数据库描述符应用于长期森林管理。

Conclusion: TreeLoc是一个有效的、基于LiDAR的森林全局定位框架，能够克服森林环境的挑战，实现鲁棒和精确的定位，并具有森林管理的应用潜力。

Abstract: Reliable localization is crucial for navigation in forests, where GPS is often degraded and LiDAR measurements are repetitive, occluded, and structurally complex. These conditions weaken the assumptions of traditional urban-centric localization methods, which assume that consistent features arise from unique structural patterns, necessitating forest-centric solutions to achieve robustness in these environments. To address these challenges, we propose TreeLoc, a LiDAR-based global localization framework for forests that handles place recognition and 6-DoF pose estimation. We represent scenes using tree stems and their Diameter at Breast Height (DBH), which are aligned to a common reference frame via their axes and summarized using the tree distribution histogram (TDH) for coarse matching, followed by fine matching with a 2D triangle descriptor. Finally, pose estimation is achieved through a two-step geometric verification. On diverse forest benchmarks, TreeLoc outperforms baselines, achieving precise localization. Ablation studies validate the contribution of each component. We also propose applications for long-term forest management using descriptors from a compact global tree database. TreeLoc is open-sourced for the robotics community at https://github.com/minwoo0611/TreeLoc.

</details>


### [657] [RAPT: Model-Predictive Out-of-Distribution Detection and Failure Diagnosis for Sim-to-Real Humanoid Robots](https://arxiv.org/abs/2602.01515)
*Humphrey Munn,Brendan Tidd,Peter Bohm,Marcus Gallagher,David Howard*

Main category: cs.RO

TL;DR: 本文提出了一种名为RAPT的轻量级、自监督部署时监测器，用于50Hz人形机器人控制，以解决模拟到现实（Sim-to-Real）转移后出现的离分布（OOD）状态导致的静默失效问题。RAPT能够可靠地在线检测OOD，并提供可解释的Sim-to-Real失配度量，还通过结合梯度分析和大型语言模型（LLM）实现了零样本的故障根本原因分析。


<details>
  <summary>Details</summary>
Motivation: 在人形机器人上部署学习到的控制策略面临挑战，因为在模拟中表现鲁棒的策略在Sim-to-Real转移后，在OOD状态下可能自信地执行，导致硬件损坏的静默失效。现有的异常检测方法往往不兼容高频控制，或者在实际部署所需极低误报率下校准不佳，或以二元停止信号的黑盒形式运行，无法解释机器人行为漂移的原因。

Method: RAPT通过学习模拟中正常执行的时空概率流形，并在执行时评估预测偏差，将其作为每维度的校准信号。这实现了可靠的在线OOD检测和量化Sim-to-Real失配的连续、可解释度量。此外，RAPT还引入了一个自动事后根本原因分析流程，结合基于梯度的时域显著性分析和LLM推理，以零样本方式生成语义化的故障诊断。

Result: 在Unitree G1人形机器人上进行了实验。在模拟中，RAPT在0.5%的固定每集误报率下，真实阳性率（TPR）比最强基线提高了37%。在实际部署中，RAPT的TPR提高了12.5%，并提供了可操作的可解释性，仅使用本体感觉数据，在16起真实故障中达到了75%的根本原因分类准确率。

Conclusion: RAPT是一种有效的、轻量级的部署时监测器，能够可靠地检测人形机器人的OOD执行，并提供可解释的Sim-to-Real失配度量。其集成的根本原因分析能力可以显著提高故障诊断的效率和准确性，为解决Sim-to-Real转移中的挑战提供了有价值的工具。

Abstract: Deploying learned control policies on humanoid robots is challenging: policies that appear robust in simulation can execute confidently in out-of-distribution (OOD) states after Sim-to-Real transfer, leading to silent failures that risk hardware damage. Although anomaly detection can mitigate these failures, prior methods are often incompatible with high-rate control, poorly calibrated at the extremely low false-positive rates required for practical deployment, or operate as black boxes that provide a binary stop signal without explaining why the robot drifted from nominal behavior. We present RAPT, a lightweight, self-supervised deployment-time monitor for 50Hz humanoid control. RAPT learns a probabilistic spatio-temporal manifold of nominal execution from simulation and evaluates execution-time predictive deviation as a calibrated, per-dimension signal. This yields (i) reliable online OOD detection under strict false-positive constraints and (ii) a continuous, interpretable measure of Sim-to-Real mismatch that can be tracked over time to quantify how far deployment has drifted from training. Beyond detection, we introduce an automated post-hoc root-cause analysis pipeline that combines gradient-based temporal saliency derived from RAPT's reconstruction objective with LLM-based reasoning conditioned on saliency and joint kinematics to produce semantic failure diagnoses in a zero-shot setting. We evaluate RAPT on a Unitree G1 humanoid across four complex tasks in simulation and on physical hardware. In large-scale simulation, RAPT improves True Positive Rate (TPR) by 37% over the strongest baseline at a fixed episode-level false positive rate of 0.5%. On real-world deployments, RAPT achieves a 12.5% TPR improvement and provides actionable interpretability, reaching 75% root-cause classification accuracy across 16 real-world failures using only proprioceptive data.

</details>


### [658] [Co-Design of Rover Wheels and Control using Bayesian Optimization and Rover-Terrain Simulations](https://arxiv.org/abs/2602.01535)
*Huzaifa Mustafa Unjhawala,Khizar Shaikh,Luning Bakke,Radu Serban,Dan Negrut*

Main category: cs.RO

TL;DR: 本文提出了一种贝叶斯优化框架，能够同时优化越野机器人车轮几何形状和转向控制器参数，通过高保真、全车辆闭环模拟在可变形地形上进行。该方法使用连续体表示模型（CRM）来提高效率，显著缩短了模拟时间，并与之前的DEM方法相比，计算成本大大降低，同时在实际硬件上的初步研究也验证了仿真结果的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的DEM模拟在模拟可变形地形时成本高昂，限制了其在全车辆越野自主移动研究中的应用，使得车轮-车辆-控制器之间的耦合交互无法充分研究，也阻碍了机械设计与控制的联合优化。因此，需要一种更高效的方法来解决这个问题。

Method: 文章提出了一种贝叶斯优化框架，结合了高保真、全车辆闭环模拟和可变形地形的连续体表示模型（CRM）。该框架能够同时优化车轮参数（半径、宽度、履带特征）和转向PID增益，以多目标方式平衡行驶速度、跟踪误差和能耗。文章比较了同时优化和顺序优化两种策略，并分析了性能和计算成本的权衡。

Result: 该方法在5到9天内完成了3000次全车辆模拟，而之前基于DEM的工作流程需要数月。仿真优化的车轮设计在物理样机上的初步研究显示，其相对性能趋势得以保留。同时，CRM模型比DEM模型在效率和可扩展性上表现更优。

Conclusion: 文章证明了可扩展、高保真的仿真技术可以实现对越野车辆在可变形地形上的车轮设计和控制的实际联合优化，而无需依赖昂贵的DEM研究。开源的仿真基础设施将促进研究的可复现性和进一步发展。

Abstract: While simulation is vital for optimizing robotic systems, the cost of modeling deformable terrain has long limited its use in full-vehicle studies of off-road autonomous mobility. For example, Discrete Element Method (DEM) simulations are often confined to single-wheel tests, which obscures coupled wheel-vehicle-controller interactions and prevents joint optimization of mechanical design and control. This paper presents a Bayesian optimization framework that co-designs rover wheel geometry and steering controller parameters using high-fidelity, full-vehicle closed-loop simulations on deformable terrain. Using the efficiency and scalability of a continuum-representation model (CRM) for terramechanics, we evaluate candidate designs on trajectories of varying complexity while towing a fixed load. The optimizer tunes wheel parameters (radius, width, and grouser features) and steering PID gains under a multi-objective formulation that balances traversal speed, tracking error, and energy consumption. We compare two strategies: simultaneous co-optimization of wheel and controller parameters versus a sequential approach that decouples mechanical and control design. We analyze trade-offs in performance and computational cost. Across 3,000 full-vehicle simulations, campaigns finish in five to nine days, versus months with the group's earlier DEM-based workflow. Finally, a preliminary hardware study suggests the simulation-optimized wheel designs preserve relative performance trends on the physical rover. Together, these results show that scalable, high-fidelity simulation can enable practical co-optimization of wheel design and control for off-road vehicles on deformable terrain without relying on prohibitively expensive DEM studies. The simulation infrastructure (scripts and models) is released as open source in a public repository to support reproducibility and further research.

</details>


### [659] [UniDWM: Towards a Unified Driving World Model via Multifaceted Representation Learning](https://arxiv.org/abs/2602.01536)
*Shuai Liu,Siheng Ren,Xiaoyao Zhu,Quanmin Liang,Zefeng Li,Qiang Li,Xin Hu,Kai Huang*

Main category: cs.RO

TL;DR: 本文提出了一种名为UniDWM的统一驾驶世界模型，通过多方面表征学习来提升自动驾驶能力。该模型能够学习结构和动态感知的潜在世界表征，支持跨感知、预测和规划的一致性推理，并通过实验证明了其在轨迹规划、4D重构和生成等方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 在复杂的驾驶环境中实现可靠高效的规划，需要一个能够推理场景几何、外观和动态的模型。本文旨在通过多方面表征学习来构建一个统一的驾驶世界模型，以促进自动驾驶技术的发展。

Method: UniDWM构建了一个结构和动态感知的潜在世界表征，该表征作为一个物理基础的状态空间。其中，一个联合重构通路学习恢复场景的结构（包括几何和视觉纹理）；一个协作生成框架利用条件扩散 Transformer 来预测潜在空间中的未来世界演化。此外，作者将UniDWM视为变分自编码器（VAE）的一个变体，并提供了理论指导。

Result: 实验表明，UniDWM在轨迹规划、4D重构和生成方面表现出色，证明了多方面世界表征作为统一驾驶智能基础的潜力。

Conclusion: UniDWM模型通过学习结构和动态感知的潜在世界表征，能够实现跨感知、预测和规划的一致性推理，从而有效地提升了自动驾驶系统的性能，尤其是在轨迹规划和4D重构生成任务上。多方面世界表征为实现统一的驾驶智能提供了有前景的基础。

Abstract: Achieving reliable and efficient planning in complex driving environments requires a model that can reason over the scene's geometry, appearance, and dynamics. We present UniDWM, a unified driving world model that advances autonomous driving through multifaceted representation learning. UniDWM constructs a structure- and dynamic-aware latent world representation that serves as a physically grounded state space, enabling consistent reasoning across perception, prediction, and planning. Specifically, a joint reconstruction pathway learns to recover the scene's structure, including geometry and visual texture, while a collaborative generation framework leverages a conditional diffusion transformer to forecast future world evolution within the latent space. Furthermore, we show that our UniDWM can be deemed as a variation of VAE, which provides theoretical guidance for the multifaceted representation learning. Extensive experiments demonstrate the effectiveness of UniDWM in trajectory planning, 4D reconstruction and generation, highlighting the potential of multifaceted world representations as a foundation for unified driving intelligence. The code will be publicly available at https://github.com/Say2L/UniDWM.

</details>


### [660] [A Closed-Form Geometric Retargeting Solver for Upper Body Humanoid Robot Teleoperation](https://arxiv.org/abs/2602.01632)
*Chuizheng Kong,Yunho Cho,Wonsuhk Jung,Idris Wibowo,Parth Shinde,Sundhar Vinodh-Sangeetha,Long Kiu Chung,Zhenyang Chen,Andrew Mattei,Advaith Nidumukkala,Alexander Elias,Danfei Xu,Taylor Higgins,Shreyas Kousik*

Main category: cs.RO

TL;DR: 提出了一种名为SEW-Mimic的新型人体运动重定向方法，它通过对齐人体的上下臂姿态来解决机器人末端执行器到人体手部位置和方向匹配的局限性，实现了高效、精确的机器人遥操作。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动重定向方法在将人类运动映射到机器人姿态时存在效率低下、运动不理想和延迟等问题，并且限制了机器人的工作空间。作者希望开发一种更优、更快的解决方案。

Method: 将运动重定向问题重新定义为姿态对齐问题，提出了一种基于肩、肘、腕（SEW）关键点的人体上下臂姿态对齐的闭式几何解算算法，称为SEW-Mimic。该方法在标准CPU上可达到3kHz的推理速度。

Result: SEW-Mimic在计算时间和准确性方面优于其他重定向方法。用户研究表明，该方法提高了遥操作任务的成功率。数据分析显示，SEW-Mimic生成的数据有助于策略学习。该方法也加速了全身人体运动的重定向，并通过硬件演示证明了其实用性。

Conclusion: SEW-Mimic是一种高效、精确的运动重定向方法，是双臂机器人操作和人体机器人遥操作的基础组件，具有显著的实际应用价值。

Abstract: Retargeting human motion to robot poses is a practical approach for teleoperating bimanual humanoid robot arms, but existing methods can be suboptimal and slow, often causing undesirable motion or latency. This is due to optimizing to match robot end-effector to human hand position and orientation, which can also limit the robot's workspace to that of the human. Instead, this paper reframes retargeting as an orientation alignment problem, enabling a closed-form, geometric solution algorithm with an optimality guarantee. The key idea is to align a robot arm to a human's upper and lower arm orientations, as identified from shoulder, elbow, and wrist (SEW) keypoints; hence, the method is called SEW-Mimic. The method has fast inference (3 kHz) on standard commercial CPUs, leaving computational overhead for downstream applications; an example in this paper is a safety filter to avoid bimanual self-collision. The method suits most 7-degree-of-freedom robot arms and humanoids, and is agnostic to input keypoint source. Experiments show that SEW-Mimic outperforms other retargeting methods in computation time and accuracy. A pilot user study suggests that the method improves teleoperation task success. Preliminary analysis indicates that data collected with SEW-Mimic improves policy learning due to being smoother. SEW-Mimic is also shown to be a drop-in way to accelerate full-body humanoid retargeting. Finally, hardware demonstrations illustrate SEW-Mimic's practicality. The results emphasize the utility of SEW-Mimic as a fundamental building block for bimanual robot manipulation and humanoid robot teleoperation.

</details>


### [661] [AgenticLab: A Real-World Robot Agent Platform that Can See, Think, and Act](https://arxiv.org/abs/2602.01662)
*Pengyuan Guo,Zhonghao Mai,Zhengtong Xu,Kaidi Zhang,Heng Zhang,Zichen Miao,Arash Ajoudani,Zachary Kingston,Qiang Qiu,Yu She*

Main category: cs.RO

TL;DR: 本文提出了AgenticLab，一个用于评估和基准测试大型视觉语言模型（VLMs）在真实机器人操纵任务中的能力的平台和基准。该平台支持闭环代理管道，包括感知、任务分解、在线验证和重新规划，并在非结构化环境中进行评估。研究发现，现有VLM在多步推理一致性、遮挡下的物体识别以及空间推理方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（VLMs）在通用感知和推理方面取得了显著进展，但其在真实世界、非结构化、闭环任务中的机器人操纵能力仍不明确。现有的VLM操纵研究难以横向比较，且许多评估依赖于模拟或受限环境。

Method: 提出AgenticLab，一个模型无关的机器人代理平台和基准。该平台提供了一个闭环代理管道，包括感知、任务分解、在线验证和重新规划。使用AgenticLab，在真实机器人、非结构化环境中对最先进的VLM代理进行了基准测试。

Result: 通过AgenticLab的基准测试，揭示了在真实机器人操纵中存在的多种失效模式，这些模式在离线视觉语言测试（如VQA和静态图像理解）中未能体现。具体包括：多步推理的一致性失效、遮挡和场景变化下的物体识别问题，以及空间推理不足导致的操纵不可靠。

Conclusion: AgenticLab为评估和加速通用机器人代理的研究提供了一个模型无关的平台和基准。研究结果表明，当前的VLM在处理长时序、闭环的真实世界机器人操纵任务时仍面临挑战，尤其是在多步推理一致性、动态物体识别和空间推理方面。

Abstract: Recent advances in large vision-language models (VLMs) have demonstrated generalizable open-vocabulary perception and reasoning, yet their real-robot manipulation capability remains unclear for long-horizon, closed-loop execution in unstructured, in-the-wild environments. Prior VLM-based manipulation pipelines are difficult to compare across different research groups' setups, and many evaluations rely on simulation, privileged state, or specially designed setups. We present AgenticLab, a model-agnostic robot agent platform and benchmark for open-world manipulation. AgenticLab provides a closed-loop agent pipeline for perception, task decomposition, online verification, and replanning. Using AgenticLab, we benchmark state-of-the-art VLM-based agents on real-robot tasks in unstructured environments. Our benchmark reveals several failure modes that offline vision-language tests (e.g., VQA and static image understanding) fail to capture, including breakdowns in multi-step grounding consistency, object grounding under occlusion and scene changes, and insufficient spatial reasoning for reliable manipulation. We will release the full hardware and software stack to support reproducible evaluation and accelerate research on general-purpose robot agents.

</details>


### [662] [Towards Autonomous Instrument Tray Assembly for Sterile Processing Applications](https://arxiv.org/abs/2602.01679)
*Raghavasimhan Sankaranarayanan,Paul Stuart,Nicholas Ahn,Arno Sungarian,Yash Chitalia*

Main category: cs.RO

TL;DR: 提出了一种全自动机器人系统，用于对手术器械进行分类和结构化包装，以提高手术准备的安全性、一致性并减少处理时间。


<details>
  <summary>Details</summary>
Motivation: 手动检查和准备器械托盘耗时且容易出错，并且存在污染和器械损坏的风险。

Method: 收集了一个包含31种手术器械和6,975张标注图像的自定义数据集，用于训练一个混合感知流程（YOLO12用于检测，基于ResNet的级联模型用于细粒度分类）。系统集成了校准的视觉模块、一台6自由度的Staubli TX2-60L机器人手臂（配有定制的双电磁夹爪）以及一个基于规则的包装算法，该算法使用3D打印的分隔器和支架来物理隔离器械，减少运输过程中的碰撞和摩擦。

Result: 实验评估显示，与人工组装的托盘相比，该系统具有高感知精度，并且工具之间碰撞的次数显著减少。

Conclusion: 这项工作是实现SPD工作流程自动化的可扩展的第一步，旨在提高手术准备的安全性、一致性，并缩短SPD的处理时间。

Abstract: The Sterile Processing and Distribution (SPD) department is responsible for cleaning, disinfecting, inspecting, and assembling surgical instruments between surgeries. Manual inspection and preparation of instrument trays is a time-consuming, error-prone task, often prone to contamination and instrument breakage. In this work, we present a fully automated robotic system that sorts and structurally packs surgical instruments into sterile trays, focusing on automation of the SPD assembly stage. A custom dataset comprising 31 surgical instruments and 6,975 annotated images was collected to train a hybrid perception pipeline using YOLO12 for detection and a cascaded ResNet-based model for fine-grained classification. The system integrates a calibrated vision module, a 6-DOF Staubli TX2-60L robotic arm with a custom dual electromagnetic gripper, and a rule-based packing algorithm that reduces instrument collisions during transport. The packing framework uses 3D printed dividers and holders to physically isolate instruments, reducing collision and friction during transport. Experimental evaluations show high perception accuracy and statistically significant reduction in tool-to-tool collisions compared to human-assembled trays. This work serves as the scalable first step toward automating SPD workflows, improving safety, and consistency of surgical preparation while reducing SPD processing times.

</details>


### [663] [GSR: Learning Structured Reasoning for Embodied Manipulation](https://arxiv.org/abs/2602.01693)
*Kewei Hu,Michael Zhang,Wei Ying,Tianhao Liu,Guoqiang Hao,Zimeng Li,Wanchan Yu,Jiajian Jing,Fangwen Chen,Hanwen Kang*

Main category: cs.RO

TL;DR: 本文提出了一种名为Grounded Scene-graph Reasoning (GSR) 的结构化推理方法，通过显式建模世界状态演变和物体间的关系，来解决具身智能体在长时序操作任务中的挑战，并在大规模数据集 Manip-Cognition-1.6M 和多个基准测试中取得了显著的泛化和任务完成能力提升。


<details>
  <summary>Details</summary>
Motivation: 现有的具身智能体在处理需要空间一致性、因果依赖和目标约束的长时序操作任务时存在困难，其根本原因是任务推理隐含在高维的潜在表征中，难以将任务结构与感知变异性分离开来。

Method: 提出Grounded Scene-graph Reasoning (GSR) 范式，将世界状态演变建模为语义化的场景图之间的过渡。通过在物体状态和空间关系上进行逐步推理，而不是直接从感知映射到动作，GSR能够显式地推理动作的前提条件、后果以及在物理基础空间内的目标满足情况。同时，构建了一个大规模数据集Manip-Cognition-1.6M来支持GSR的学习。

Result: 在RLBench、LIBERO、GSR-benchmark以及真实机器人任务上的广泛评估显示，GSR相比基于提示（prompting-based）的基线方法，在零样本泛化和长时序任务完成方面取得了显著的性能提升。

Conclusion: 显式的世界状态表征是一种关键的归纳偏置（inductive bias），有助于实现可扩展的具身推理。GSR方法通过显式地建模世界状态和推理过程，有效地克服了现有方法的局限性，为具身智能体的长时序操作能力提供了新的解决方案。

Abstract: Despite rapid progress, embodied agents still struggle with long-horizon manipulation that requires maintaining spatial consistency, causal dependencies, and goal constraints. A key limitation of existing approaches is that task reasoning is implicitly embedded in high-dimensional latent representations, making it challenging to separate task structure from perceptual variability. We introduce Grounded Scene-graph Reasoning (GSR), a structured reasoning paradigm that explicitly models world-state evolution as transitions over semantically grounded scene graphs. By reasoning step-wise over object states and spatial relations, rather than directly mapping perception to actions, GSR enables explicit reasoning about action preconditions, consequences, and goal satisfaction in a physically grounded space. To support learning such reasoning, we construct Manip-Cognition-1.6M, a large-scale dataset that jointly supervises world understanding, action planning, and goal interpretation. Extensive evaluations across RLBench, LIBERO, GSR-benchmark, and real-world robotic tasks show that GSR significantly improves zero-shot generalization and long-horizon task completion over prompting-based baselines. These results highlight explicit world-state representations as a key inductive bias for scalable embodied reasoning.

</details>


### [664] [Tilt-Ropter: A Novel Hybrid Aerial and Terrestrial Vehicle with Tilt Rotors and Passive Wheels](https://arxiv.org/abs/2602.01700)
*Ruoyu Wang,Xuchen Liu,Zongzhou Wu,Zixuan Guo,Wendi Ding,Ben M. Chen*

Main category: cs.RO

TL;DR: 本文提出了一种名为Tilt-Ropter的新型混合空中-地面车辆（HATV），它结合了倾转旋翼和被动轮，实现了高能效的多模式运动。该车辆采用全驱动设计，具有解耦的力和扭矩控制能力，并通过非线性模型预测控制器（NMPC）实现了跨模式的轨迹跟踪和接触约束处理。此外，还引入了外部力矩估计算法以增强地面接触时的鲁棒性。实验结果显示，Tilt-Ropter在地面运动时能耗降低了92.8%，并能无缝实现空地转换和轨迹跟踪。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为了开发一种能够实现高能效多模式运动的新型混合空中-地面车辆（HATV），以应对长时任务和能源受限环境的需求。

Method: 本文提出了一种名为Tilt-Ropter的HATV，该车辆采用倾转旋翼和被动轮的组合，并具有全驱动设计。控制策略包括：1. 使用非线性模型预测控制器（NMPC）进行轨迹跟踪和接触约束处理。2. 开发一个控制分配模块来利用冗余驱动实现能效控制。3. 引入一个外部力矩估计算法来实时估计环境交互力矩。

Result: Tilt-Ropter在仿真和实际实验中都得到了验证。实验结果显示，该系统在两种运动模式下都具有低跟踪误差，并且在地面运动期间的功耗降低了92.8%。系统能够实现无缝的空地转换。

Conclusion: Tilt-Ropter是一种创新的HATV，其全驱动设计、先进的NMPC和能量高效的控制分配策略使其在空中和地面模式下均表现出色。通过显著降低地面运动的功耗，Tilt-Ropter为在能源受限的大规模环境中执行长时任务提供了潜力。

Abstract: In this work, we present Tilt-Ropter, a novel hybrid aerial-terrestrial vehicle (HATV) that combines tilt rotors with passive wheels to achieve energy-efficient multi-mode locomotion. Unlike existing under-actuated HATVs, the fully actuated design of Tilt-Ropter enables decoupled force and torque control, greatly enhancing its mobility and environmental adaptability. A nonlinear model predictive controller (NMPC) is developed to track reference trajectories and handle contact constraints across locomotion modes, while a dedicated control allocation module exploits actuation redundancy to achieve energy-efficient control of actuators. Additionally, to enhance robustness during ground contact, we introduce an external wrench estimation algorithm that estimates environmental interaction forces and torques in real time. The system is validated through both simulation and real-world experiments, including seamless air-ground transitions and trajectory tracking. Results show low tracking errors in both modes and highlight a 92.8% reduction in power consumption during ground locomotion, demonstrating the system's potential for long-duration missions across large-scale and energy-constrained environments.

</details>


### [665] [Uncertainty-Aware Non-Prehensile Manipulation with Mobile Manipulators under Object-Induced Occlusion](https://arxiv.org/abs/2602.01731)
*Jiwoo Hwang,Taegeun Yang,Jeil Jeong,Minsung Yoon,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: 提出了一种名为CURA-PPO的强化学习框架，通过显式建模不确定性来解决非抓取式操作中的传感器遮挡问题，提高了操作的成功率和安全性。


<details>
  <summary>Details</summary>
Motivation: 在非抓取式操作中，被操作的物体会遮挡传感器视线，导致潜在的碰撞风险。现有方法难以有效处理这种部分可观测性带来的挑战。

Method: CURA-PPO是一个强化学习框架，通过预测碰撞可能性作为一种分布来显式建模不确定性。该框架提取风险和不确定性来指导机器人动作，其中不确定性项鼓励机器人进行主动感知，同时进行操作和信息收集以解决遮挡问题。结合观测可靠性的置信度图，该方法能够实现安全导航。

Result: 在不同物体大小和障碍物配置的实验中，CURA-PPO相比基线方法，成功率提高了3倍，并学会了能够处理遮挡的策略。

Conclusion: CURA-PPO提供了一种实用的解决方案，能够仅使用车载传感器在杂乱环境中进行自主操作，有效解决了传感器遮挡带来的挑战。

Abstract: Non-prehensile manipulation using onboard sensing presents a fundamental challenge: the manipulated object occludes the sensor's field of view, creating occluded regions that can lead to collisions. We propose CURA-PPO, a reinforcement learning framework that addresses this challenge by explicitly modeling uncertainty under partial observability. By predicting collision possibility as a distribution, we extract both risk and uncertainty to guide the robot's actions. The uncertainty term encourages active perception, enabling simultaneous manipulation and information gathering to resolve occlusions. When combined with confidence maps that capture observation reliability, our approach enables safe navigation despite severe sensor occlusion. Extensive experiments across varying object sizes and obstacle configurations demonstrate that CURA-PPO achieves up to 3X higher success rates than the baselines, with learned behaviors that handle occlusions. Our method provides a practical solution for autonomous manipulation in cluttered environments using only onboard sensing.

</details>


### [666] [RFS: Reinforcement learning with Residual flow steering for dexterous manipulation](https://arxiv.org/abs/2602.01789)
*Entong Su,Tyler Westenbroek,Anusha Nagabandi,Abhishek Gupta*

Main category: cs.RO

TL;DR: 提出了一种名为残差流导向（RFS）的数据高效强化学习框架，用于调整预训练的生成策略，通过联合优化残差动作和潜在噪声分布，实现了局部精炼和全局探索的互补，从而在灵巧操控任务中实现了高效的微调。


<details>
  <summary>Details</summary>
Motivation: 现有的基于生成模型（如扩散模型和流匹配）的行为克隆方法虽然能处理高维操作任务，但预训练策略的泛化能力有限，需要额外的微调才能在部署时获得鲁棒性能。因此，需要一种能够在保留预训练全局探索优势的同时，快速纠正局部执行错误的方法。

Method: RFS框架通过联合优化残差动作和潜在噪声分布来引导预训练的流匹配策略。这种方法实现了两种互补的探索形式：通过残差修正进行局部精炼，以及通过潜在空间调制进行全局探索。这使得在保持预训练策略的表达结构的同时，能够实现高效的适应。

Result: 在灵巧操控任务的仿真和真实世界设置中，RFS框架都证明了其在适应预训练基础策略方面的有效性，能够实现高效的微调。

Conclusion: RFS是一种数据高效的强化学习框架，能够有效地调整预训练的生成策略，通过残差和潜在噪声的联合优化，实现了局部精炼和全局探索的平衡，从而在机器人灵巧操控任务中取得了良好的适应效果。

Abstract: Imitation learning has emerged as an effective approach for bootstrapping sequential decision-making in robotics, achieving strong performance even in high-dimensional dexterous manipulation tasks. Recent behavior cloning methods further leverage expressive generative models, such as diffusion models and flow matching, to represent multimodal action distributions. However, policies pretrained in this manner often exhibit limited generalization and require additional fine-tuning to achieve robust performance at deployment time. Such adaptation must preserve the global exploration benefits of pretraining while enabling rapid correction of local execution errors.We propose \emph{Residual Flow Steering} (RFS), a data-efficient reinforcement learning framework for adapting pretrained generative policies. RFS steers a pretrained flow-matching policy by jointly optimizing a residual action and a latent noise distribution, enabling complementary forms of exploration: local refinement through residual corrections and global exploration through latent-space modulation. This design allows efficient adaptation while retaining the expressive structure of the pretrained policy.We demonstrate the effectiveness of RFS on dexterous manipulation tasks, showing efficient fine-tuning both in simulation and in real-world settings when adapting pretrained base policies.Project website:https://weirdlabuw.github.io/rfs.

</details>


### [667] [From Knowing to Doing Precisely: A General Self-Correction and Termination Framework for VLA models](https://arxiv.org/abs/2602.01811)
*Wentao Zhang,Aolan Sun,Wentao Mo,Xiaoyang Qu,Yuxin Zheng,Jianzong Wang*

Main category: cs.RO

TL;DR: 提出了一种轻量级、免训练的VLA-SCT框架，通过数据驱动的动作精炼和条件终止逻辑，解决了现有VLA模型在抓取任务中动作空间偏差和任务完成识别不足的问题，显著提高了精细操作任务的成功率和任务完成的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在抓取任务中动作指令存在空间偏差，导致抓取失败；同时，模型无法可靠地识别任务完成，导致冗余动作和超时错误。

Method: 提出VLA-SCT框架，采用自纠正控制循环，结合数据驱动的动作精炼和条件逻辑实现任务终止。

Result: 与基线方法相比，VLA-SCT在LIBERO基准的所有数据集中均取得了持续的改进，显著提高了精细操作任务的成功率，并确保了任务完成的准确性。

Conclusion: VLA-SCT框架通过动作精炼和任务终止逻辑的改进，能够部署更可靠的VLA代理，以应对复杂、非结构化的环境。

Abstract: While vision-language-action (VLA) models for embodied agents integrate perception, reasoning, and control, they remain constrained by two critical weaknesses: first, during grasping tasks, the action tokens generated by the language model often exhibit subtle spatial deviations from the target object, resulting in grasp failures; second, they lack the ability to reliably recognize task completion, which leads to redundant actions and frequent timeout errors. To address these challenges and enhance robustness, we propose a lightweight, training-free framework, VLA-SCT. This framework operates as a self-correcting control loop, combining data-driven action refinement with conditional logic for termination. Consequently, compared to baseline approaches, our method achieves consistent improvements across all datasets in the LIBERO benchmark, significantly increasing the success rate of fine manipulation tasks and ensuring accurate task completion, thereby promoting the deployment of more reliable VLA agents in complex, unstructured environments.

</details>


### [668] [Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models](https://arxiv.org/abs/2602.01834)
*Siqi Wen,Shu Yang,Shaopeng Fu,Jingfeng Zhang,Lijie Hu,Di Wang*

Main category: cs.RO

TL;DR: 本文提出了一种基于概念的字典学习框架，用于在推理时控制视觉语言动作（VLA）模型的安全性，通过识别和抑制有害概念激活来防止不安全行为，且无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在闭环感知-动作方面能力强大，但也放大了安全风险，简单的文本攻击可能导致有害的物理动作。现有的安全防护机制介入过晚或方式不当，导致融合表示仍易受攻击。

Method: 提出一个在推理时进行安全控制的、基于概念的字典学习框架。该方法通过从隐藏激活中构建稀疏、可解释的字典，识别有害概念方向，并应用基于阈值的干预来抑制或阻止不安全激活。

Result: 在Libero-Harm、BadRobot、RoboPair和IS-Bench等数据集上，该方法取得了最先进的防御性能，将攻击成功率降低了70%以上，同时保持了任务成功率。该框架即插即用，模型无关，无需重新训练。

Conclusion: 本文提出了首个用于具身系统的、基于推理时概念的安全方法，提高了VLA模型的可解释性和安全部署能力，有效解决了VLA模型的安全风险问题。

Abstract: Vision Language Action (VLA) models close the perception action loop by translating multimodal instructions into executable behaviors, but this very capability magnifies safety risks: jailbreaks that merely yield toxic text in LLMs can trigger unsafe physical actions in embodied systems. Existing defenses alignment, filtering, or prompt hardening intervene too late or at the wrong modality, leaving fused representations exploitable. We introduce a concept-based dictionary learning framework for inference-time safety control. By constructing sparse, interpretable dictionaries from hidden activations, our method identifies harmful concept directions and applies threshold-based interventions to suppress or block unsafe activations. Experiments on Libero-Harm, BadRobot, RoboPair, and IS-Bench show that our approach achieves state-of-the-art defense performance, cutting attack success rates by over 70\% while maintaining task success. Crucially, the framework is plug-in and model-agnostic, requiring no retraining and integrating seamlessly with diverse VLAs. To our knowledge, this is the first inference-time concept-based safety method for embodied systems, advancing both interpretability and safe deployment of VLA models.

</details>


### [669] [Vision-only UAV State Estimation for Fast Flights Without External Localization Systems: A2RL Drone Racing Finalist Approach](https://arxiv.org/abs/2602.01860)
*Filip Novák,Matěj Petrlík,Matej Novosad,Parakh M. Gupta,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种基于单目RGB相机和IMU的无人机视觉惯性里程计（VIO）漂移补偿方法，用于高超音速无人机在GNSS受限环境下的精确状态估计。


<details>
  <summary>Details</summary>
Motivation: 在GNSS受限环境中，高速无人机需要快速、可靠、精确的状态估计，而现有方法（依赖复杂硬件或使用未校正的VIO数据）在高动态运动中存在误差。

Method: 通过融合视觉惯性里程计（VIO）、基于视觉的地标测量系统和IMU数据来估计无人机状态。提出了一种新的数学模型来估计和补偿VIO的漂移，并校正VIO的所有状态（位置、姿态、线速度和角速度）。

Result: 该方法能够准确地进行状态估计，即使在快速和动态的运动中也能保持高精度。在1600次模拟和多次真实世界实验中得到了验证，并在A2RL无人机竞速挑战赛2025中取得了优异成绩。

Conclusion: 所提出的VIO漂移补偿方法能够显著提高高超音速无人机在GNSS受限环境下的状态估计精度，尤其是在进行高速和激进机动时，克服了现有方法的局限性。

Abstract: Fast flights with aggressive maneuvers in cluttered GNSS-denied environments require fast, reliable, and accurate UAV state estimation. In this paper, we present an approach for onboard state estimation of a high-speed UAV using a monocular RGB camera and an IMU. Our approach fuses data from Visual-Inertial Odometry (VIO), an onboard landmark-based camera measurement system, and an IMU to produce an accurate state estimate. Using onboard measurement data, we estimate and compensate for VIO drift through a novel mathematical drift model. State-of-the-art approaches often rely on more complex hardware (e.g., stereo cameras or rangefinders) and use uncorrected drifting VIO velocities, orientation, and angular rates, leading to errors during fast maneuvers. In contrast, our method corrects all VIO states (position, orientation, linear and angular velocity), resulting in accurate state estimation even during rapid and dynamic motion. Our approach was thoroughly validated through 1600 simulations and numerous real-world experiments. Furthermore, we applied the proposed method in the A2RL Drone Racing Challenge 2025, where our team advanced to the final four out of 210 teams and earned a medal.

</details>


### [670] [Multimodal Large Language Models for Real-Time Situated Reasoning](https://arxiv.org/abs/2602.01880)
*Giulio Antonio Abbo,Senne Lenaerts,Tony Belpaeme*

Main category: cs.RO

TL;DR: 该研究探索了多模态大语言模型（如 GPT-4o）如何结合机器人平台（TurtleBot 4 模拟的智能吸尘机器人）支持实时、情境和价值感知决策，以在家庭环境中进行自主清洁。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探索多模态大语言模型在支持机器人进行实时、情境感知和价值对齐的决策方面的潜力，特别是在模拟家庭环境中的智能吸尘机器人应用。

Method: 研究结合了 GPT-4o 语言模型和 TurtleBot 4 机器人平台，模拟智能吸尘机器人。模型通过视觉输入评估环境，并根据家庭活动、社会规范和用户偏好（如清洁度、舒适度和安全性）来决定是否启动清洁。

Result: 该系统在模拟的家庭环境中展示了从有限视觉输入推断情境和价值的能力，并能做出符合相关人员价值观的细微决策。结果表明，多模态大语言模型在提升机器人自主性和情境感知方面具有潜力。

Conclusion: 多模态大语言模型在增强机器人自主性和情境感知方面前景广阔，但同时也凸显了在一致性、偏见和实时性能方面存在的挑战。

Abstract: In this work, we explore how multimodal large language models can support real-time context- and value-aware decision-making. To do so, we combine the GPT-4o language model with a TurtleBot 4 platform simulating a smart vacuum cleaning robot in a home. The model evaluates the environment through vision input and determines whether it is appropriate to initiate cleaning. The system highlights the ability of these models to reason about domestic activities, social norms, and user preferences and take nuanced decisions aligned with the values of the people involved, such as cleanliness, comfort, and safety. We demonstrate the system in a realistic home environment, showing its ability to infer context and values from limited visual input. Our results highlight the promise of multimodal large language models in enhancing robotic autonomy and situational awareness, while also underscoring challenges related to consistency, bias, and real-time performance.

</details>


### [671] [BTGenBot-2: Efficient Behavior Tree Generation with Small Language Models](https://arxiv.org/abs/2602.01870)
*Riccardo Andrea Izzo,Gianluca Bardaro,Matteo Matteucci*

Main category: cs.RO

TL;DR: 本文提出了一种名为BTGenBot-2的轻量级开源小型语言模型（1B参数），可将自然语言任务描述和机器人动作基元直接转换为XML格式的行为树（BT）。该模型支持零样本BT生成、推理和运行时错误恢复，并且计算资源需求低，适合资源受限的机器人。此外，还推出了首个用于LLM驱动的BT生成的标准化基准，涵盖了52个导航和操作任务。实验证明BTGenBot-2在零样本和单样本场景下均优于GPT-5、Claude Opus 4.1等大型模型，成功率分别达到90.38%和98.07%，并且推理速度比之前的BTGenBot快16倍。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习中的LLM任务规划方法存在闭源、计算量大、不适合实际部署等问题，并且缺乏统一的机器人任务生成表示。本文旨在解决这些挑战，提出一个轻量级、开源、易于部署的模型和一套标准化基准。

Method: 提出BTGenBot-2，一个1B参数的开源小型语言模型，用于将自然语言任务描述和机器人动作基元转换为XML格式的行为树。该模型实现了零样本BT生成，支持推理和运行时错误恢复。同时，设计了一个包含52个导航和操作任务的标准化基准，用于在NVIDIA Isaac Sim中评估LLM驱动的BT生成。

Result: BTGenBot-2在零样本场景下的平均成功率为90.38%，在单样本场景下为98.07%。在功能性和非功能性指标上均优于GPT-5、Claude Opus 4.1和更大的开源模型。推理速度比之前的BTGenBot快16倍。

Conclusion: BTGenBot-2作为一个轻量级、开源的小型语言模型，能够有效地将自然语言任务转换为机器人行为树，克服了现有方法的局限性，并为LLM驱动的机器人任务生成提供了一个标准化的评估平台。

Abstract: Recent advances in robot learning increasingly rely on LLM-based task planning, leveraging their ability to bridge natural language with executable actions. While prior works showcased great performances, the widespread adoption of these models in robotics has been challenging as 1) existing methods are often closed-source or computationally intensive, neglecting the actual deployment on real-world physical systems, and 2) there is no universally accepted, plug-and-play representation for robotic task generation. Addressing these challenges, we propose BTGenBot-2, a 1B-parameter open-source small language model that directly converts natural language task descriptions and a list of robot action primitives into executable behavior trees in XML. Unlike prior approaches, BTGenBot-2 enables zero-shot BT generation, error recovery at inference and runtime, while remaining lightweight enough for resource-constrained robots. We further introduce the first standardized benchmark for LLM-based BT generation, covering 52 navigation and manipulation tasks in NVIDIA Isaac Sim. Extensive evaluations demonstrate that BTGenBot-2 consistently outperforms GPT-5, Claude Opus 4.1, and larger open-source models across both functional and non-functional metrics, achieving average success rates of 90.38% in zero-shot and 98.07% in one-shot, while delivering up to 16x faster inference compared to the previous BTGenBot.

</details>


### [672] [ForSim: Stepwise Forward Simulation for Traffic Policy Fine-Tuning](https://arxiv.org/abs/2602.01916)
*Keyu Chen,Wenchao Sun,Hao Cheng,Zheng Fu,Sifa Zheng*

Main category: cs.RO

TL;DR: 本文提出了一种名为 ForSim 的分步闭环前向仿真范式，以解决现有交通仿真中存在的协变量偏移和行为模式单一的问题，通过在每个时间步选择与参考轨迹在时空上最匹配的虚拟轨迹，并结合 RIFT 框架，显著提高了自动驾驶仿真的安全性、效率、真实性和舒适性。


<details>
  <summary>Details</summary>
Motivation: 现有的交通仿真在自动驾驶的闭环训练和评估中面临两个主要挑战：开放式模仿学习引入的协变量偏移，以及反映真实世界多模态行为的能力有限。现有方法（如 RIFT）虽然有所改进，但其前向仿真过程非反应性强，导致代理交互不真实，限制了仿真保真度。

Method: 提出 ForSim，一种分步闭环前向仿真范式。在每个虚拟时间步，交通代理通过物理约束的运动动力学传播最能时空匹配参考轨迹的虚拟候选轨迹，从而保留多模态行为多样性并确保同模态内的一致性。其他代理通过分步预测进行更新，实现连贯且考虑交互的演化。ForSim 与 RIFT 框架结合，并与组相对优化协同工作微调交通策略。

Result: 将 ForSim 集成到 RIFT 框架后，实验结果一致表明，在保持效率、真实性和舒适性的同时，安全性得到了显著提高。

Conclusion: 本文强调了在前向仿真中模拟闭环多模态交互的重要性，并为自动驾驶交通仿真提高了保真度和可靠性。ForSim 能够有效解决现有仿真的局限性，提升训练效果。

Abstract: As the foundation of closed-loop training and evaluation in autonomous driving, traffic simulation still faces two fundamental challenges: covariate shift introduced by open-loop imitation learning and limited capacity to reflect the multimodal behaviors observed in real-world traffic. Although recent frameworks such as RIFT have partially addressed these issues through group-relative optimization, their forward simulation procedures remain largely non-reactive, leading to unrealistic agent interactions within the virtual domain and ultimately limiting simulation fidelity. To address these issues, we propose ForSim, a stepwise closed-loop forward simulation paradigm. At each virtual timestep, the traffic agent propagates the virtual candidate trajectory that best spatiotemporally matches the reference trajectory through physically grounded motion dynamics, thereby preserving multimodal behavioral diversity while ensuring intra-modality consistency. Other agents are updated with stepwise predictions, yielding coherent and interaction-aware evolution. When incorporated into the RIFT traffic simulation framework, ForSim operates in conjunction with group-relative optimization to fine-tune traffic policy. Extensive experiments confirm that this integration consistently improves safety while maintaining efficiency, realism, and comfort. These results underscore the importance of modeling closed-loop multimodal interactions within forward simulation and enhance the fidelity and reliability of traffic simulation for autonomous driving. Project Page: https://currychen77.github.io/ForSim/

</details>


### [673] [LIEREx: Language-Image Embeddings for Robotic Exploration](https://arxiv.org/abs/2602.01930)
*Felix Igelbrink,Lennart Niecksch,Marian Renz,Martin Günther,Martin Atzmueller*

Main category: cs.RO

TL;DR: 本研究提出了一种名为LIEREx的方法，通过整合视觉语言基础模型（如CLIP）和3D语义场景图，使机器人能够在部分未知环境中进行目标导向的探索。


<details>
  <summary>Details</summary>
Motivation: 传统的语义地图在处理未预先定义的“分布外”知识时存在局限性，因为它们依赖于固定的符号词汇表。研究旨在克服这一限制，实现更灵活的开放集映射。

Method: LIEREx将视觉语言基础模型（VLFMs）与现有的3D语义场景图相结合，使机器人能够将物体编码为高维嵌入，而不是固定的标签。这种集成支持自主代理在部分未知环境中的目标导向探索。

Result: 通过集成VLFMs和3D语义场景图，LIEREx实现了开放集映射，从而能够处理未预先定义的物体，并支持机器人进行目标导向的探索。

Conclusion: LIEREx通过利用视觉语言基础模型和3D语义场景图，为自主代理在部分未知环境中进行目标导向的探索提供了一种有效的方法，克服了传统方法在处理“分布外”知识方面的局限性。

Abstract: Semantic maps allow a robot to reason about its surroundings to fulfill tasks such as navigating known environments, finding specific objects, and exploring unmapped areas. Traditional mapping approaches provide accurate geometric representations but are often constrained by pre-designed symbolic vocabularies. The reliance on fixed object classes makes it impractical to handle out-of-distribution knowledge not defined at design time. Recent advances in Vision-Language Foundation Models, such as CLIP, enable open-set mapping, where objects are encoded as high-dimensional embeddings rather than fixed labels. In LIEREx, we integrate these VLFMs with established 3D Semantic Scene Graphs to enable target-directed exploration by an autonomous agent in partially unknown environments.

</details>


### [674] [Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy](https://arxiv.org/abs/2602.01939)
*Yuxin He,Ruihao Zhang,Tianao Shen,Cheng Liu,Qiang Nie*

Main category: cs.RO

TL;DR: 本文提出了“探索与专注操作”（EFM）这一新问题，旨在主动获取完成具有挑战性操作任务所需的信息，并为此构建了EFM-10基准和双臂主动感知（BAP）策略，通过收集BAPData数据集并进行模仿学习验证了BAP策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统主动视觉方法在机器人头部安装主摄像头时容易发生视觉遮挡，作者认为其本质是任务完成所需信息的缺失，从而引出更根本的“探索与专注操作”（EFM）问题。

Method: 提出EFM-10基准，包含4类10个任务。提出BAP策略，利用一只手臂进行主动视觉，另一只手臂进行力传感辅助操作。收集BAPData数据集，并利用模仿学习验证BAP策略。

Result: 通过在EFM-10基准上的实验，成功验证了BAP策略在模仿学习方式下的有效性。

Conclusion: EFM-10基准和BAP策略为推动未来相关研究方向提供了基础，旨在解决机器人操作中的视觉遮挡和信息获取问题。

Abstract: Recently, active vision has reemerged as an important concept for manipulation, since visual occlusion occurs more frequently when main cameras are mounted on the robot heads. We reflect on the visual occlusion issue and identify its essence as the absence of information useful for task completion. Inspired by this, we come up with the more fundamental problem of Exploratory and Focused Manipulation (EFM). The proposed problem is about actively collecting information to complete challenging manipulation tasks that require exploration or focus. As an initial attempt to address this problem, we establish the EFM-10 benchmark that consists of 4 categories of tasks that align with our definition (10 tasks in total). We further come up with a Bimanual Active Perception (BAP) strategy, which leverages one arm to provide active vision and another arm to provide force sensing while manipulating. Based on this idea, we collect a dataset named BAPData for the tasks in EFM-10. With the dataset, we successfully verify the effectiveness of the BAP strategy in an imitation learning manner. We hope that the EFM-10 benchmark along with the BAP strategy can become a cornerstone that facilitates future research towards this direction. Project website: EFManipulation.github.io.

</details>


### [675] [A Unified Control Architecture for Macro-Micro Manipulation using a Active Remote Center of Compliance for Manufacturing Applications](https://arxiv.org/abs/2602.01948)
*Patrick Frank,Christian Friedrich*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的宏微操作器控制架构，将宏操作器纳入主动交互控制，显著提高了控制带宽，并引入了代理模型以简化控制器设计和硬件适应性。


<details>
  <summary>Details</summary>
Motivation: 传统宏微操作器控制架构限制了交互控制的带宽，因为宏操作器仅负责定位而微操作器负责交互，这限制了整体系统的动态交互能力。

Method: 提出了一种新的控制架构，将宏操作器集成到主动交互控制中，并利用代理模型进行更高效的控制器设计和硬件适应。该方法通过实验与现有技术（如领导者-跟随者方法和传统的基于力控制）进行了对比。

Result: 新控制架构将控制带宽提高了2.1倍（相比于领导者-跟随者方法）和12.5倍（相比于传统的机器人力控制）。实验证明了该方法在碰撞、力轨迹跟踪和工业装配任务中的有效性。

Conclusion: 将宏操作器主动纳入交互控制，并结合代理模型，能够显著提升宏微操作器的交互控制带宽和适应性，在多种应用场景下表现优于现有技术。

Abstract: Macro-micro manipulators combine a macro manipulator with a large workspace, such as an industrial robot, with a lightweight, high-bandwidth micro manipulator. This enables highly dynamic interaction control while preserving the wide workspace of the robot. Traditionally, position control is assigned to the macro manipulator, while the micro manipulator handles the interaction with the environment, limiting the achievable interaction control bandwidth. To solve this, we propose a novel control architecture that incorporates the macro manipulator into the active interaction control. This leads to a increase in control bandwidth by a factor of 2.1 compared to the state of the art architecture, based on the leader-follower approach and factor 12.5 compared to traditional robot-based force control. Further we propose surrogate models for a more efficient controller design and easy adaptation to hardware changes. We validate our approach by comparing it against the other control schemes in different experiments, like collision with an object, following a force trajectory and industrial assembly tasks.

</details>


### [676] [Synchronized Online Friction Estimation and Adaptive Grasp Control for Robust Gentle Grasp](https://arxiv.org/abs/2602.02026)
*Zhenwei Niu,Xiaoyi Chen,Jiayu Hu,Zhaoyang Liu,Xiaozu Ju*

Main category: cs.RO

TL;DR: 提出了一种结合实时摩擦估计和自适应抓取控制的机器人温和抓取统一框架，通过粒子滤波估计摩擦系数，并集成到反应式控制器中动态调整抓取力，以实现稳定抓取。


<details>
  <summary>Details</summary>
Motivation: 为了实现更稳定、更可靠的机器人抓取，尤其是在物体易滑动的场景下，需要一个能够实时感知并适应摩擦变化的抓取系统。

Method: 提出了一种基于粒子滤波的视觉触觉传感摩擦系数实时估计方法，并将其集成到一个反应式控制器中，该控制器能够根据估计的摩擦系数动态调整抓取力。该系统采用闭环方式运行，抓取控制的反馈不断用于优化摩擦估计。

Result: 通过广泛的机器人实验验证了该框架的可靠性和效率，证明了其能够维持稳定的抓握。

Conclusion: 所提出的统一框架能够协同工作，实时估计摩擦并自适应调整抓取控制，从而实现高效、鲁棒的机器人温和抓取。

Abstract: We introduce a unified framework for gentle robotic grasping that synergistically couples real-time friction estimation with adaptive grasp control. We propose a new particle filter-based method for real-time estimation of the friction coefficient using vision-based tactile sensors. This estimate is seamlessly integrated into a reactive controller that dynamically modulates grasp force to maintain a stable grip. The two processes operate synchronously in a closed-loop: the controller uses the current best estimate to adjust the force, while new tactile feedback from this action continuously refines the estimation. This creates a highly responsive and robust sensorimotor cycle. The reliability and efficiency of the complete framework are validated through extensive robotic experiments.

</details>


### [677] [Reformulating AI-based Multi-Object Relative State Estimation for Aleatoric Uncertainty-based Outlier Rejection of Partial Measurements](https://arxiv.org/abs/2602.02006)
*Thomas Jantos,Giulio Delama,Stephan Weiss,Jan Steinbrener*

Main category: cs.RO

TL;DR: 本文提出了一种改进的EKF状态估计方法，通过直接使用AI提取的物体相对位姿作为测量值，并引入DNN预测的不确定性，从而提高定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 移动机器人需要精确的物体相对定位来执行任务。尽管深度神经网络（DNN）可以提取物体类别和相对位姿信息，但将这些AI测量值融合到EKF中需要量化DNN的不确定性并进行异常值剔除。

Method: 文章通过重构测量方程，使用直接的物体相对位姿测量值来推导EKF。这使得位置和旋转测量值解耦，从而限制了错误旋转测量值的影响并允许部分测量拒绝。此外，通过将固定的测量协方差矩阵替换为DNN预测的随机不确定性，来改进状态估计器的性能和一致性。

Result: 通过将物体相对位姿的测量值解耦，能够限制错误旋转测量值的影响，并允许部分测量拒绝。使用DNN预测的随机不确定性替换固定的测量协方差矩阵，可以提高状态估计器的性能和一致性。

Conclusion: 本文提出的AI驱动的、物体相对的状态估计方法，通过解耦测量值和量化DNN的不确定性，能够有效地提高移动机器人的定位精度和鲁棒性。

Abstract: Precise localization with respect to a set of objects of interest enables mobile robots to perform various tasks. With the rise of edge devices capable of deploying deep neural networks (DNNs) for real-time inference, it stands to reason to use artificial intelligence (AI) for the extraction of object-specific, semantic information from raw image data, such as the object class and the relative six degrees of freedom (6-DoF) pose. However, fusing such AI-based measurements in an Extended Kalman Filter (EKF) requires quantifying the DNNs' uncertainty and outlier rejection capabilities.
  This paper presents the benefits of reformulating the measurement equation in AI-based, object-relative state estimation. By deriving an EKF using the direct object-relative pose measurement, we can decouple the position and rotation measurements, thus limiting the influence of erroneous rotation measurements and allowing partial measurement rejection. Furthermore, we investigate the performance and consistency improvements for state estimators provided by replacing the fixed measurement covariance matrix of the 6-DoF object-relative pose measurements with the predicted aleatoric uncertainty of the DNN.

</details>


### [678] [Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization](https://arxiv.org/abs/2602.02035)
*Ahmad Farooq,Kamran Iqbal*

Main category: cs.RO

TL;DR: 提出一种结合信息瓶颈理论和向量量化的框架，用于在通信受限的多机器人环境中实现高效选择性通信，显著提升了性能并降低了带宽消耗。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多机器人系统面临严重的通信限制，影响了协调效率，需要一种能在带宽受限的情况下进行有效通信的方法。

Method: 利用信息瓶颈理论和向量量化学习压缩和离散化通信消息，同时保留任务关键信息，并引入了一个门控通信机制来动态决定通信时机。

Result: 在具有挑战性的协调任务中，性能比无通信基线提高了181.8%，带宽使用量减少了41.4%。与现有方法相比，在成功率-带宽权衡方面具有优势，曲线下面积更高。

Conclusion: 该方法为在带宽受限环境中部署多机器人系统提供了一个理论上可靠的框架，在机器人集群、自动驾驶车队和分布式传感器网络等应用中表现优异。

Abstract: Multi-agent reinforcement learning systems deployed in real-world robotics applications face severe communication constraints that significantly impact coordination effectiveness. We present a framework that combines information bottleneck theory with vector quantization to enable selective, bandwidth-efficient communication in multi-agent environments. Our approach learns to compress and discretize communication messages while preserving task-critical information through principled information-theoretic optimization. We introduce a gated communication mechanism that dynamically determines when communication is necessary based on environmental context and agent states. Experimental evaluation on challenging coordination tasks demonstrates that our method achieves 181.8% performance improvement over no-communication baselines while reducing bandwidth usage by 41.4%. Comprehensive Pareto frontier analysis shows dominance across the entire success-bandwidth spectrum with area-under-curve of 0.198 vs 0.142 for next-best methods. Our approach significantly outperforms existing communication strategies and establishes a theoretically grounded framework for deploying multi-agent systems in bandwidth-constrained environments such as robotic swarms, autonomous vehicle fleets, and distributed sensor networks.

</details>


### [679] [Frictional Contact Solving for Material Point Method](https://arxiv.org/abs/2602.02038)
*Etienne Ménager,Justin Carpentier*

Main category: cs.RO

TL;DR: 本文提出了一种用于隐式材料点方法（MPM）的精确且鲁棒的摩擦接触处理方法，通过粒子中心几何原语进行接触点定位，并使用ADMM解决非线性互补问题来处理摩擦接触律。


<details>
  <summary>Details</summary>
Motivation: 准确处理带摩擦的接触是隐式MPM的核心瓶颈，涉及从可靠的接触点检测到执行摩擦接触律（非穿透、库仑摩擦和最大耗散原理）。

Method: 在碰撞检测阶段，使用粒子中心几何原语定位接触点；在接触解析阶段，将摩擦接触表述为关于接触冲量的非线性互补问题（NCP），并使用交替方向乘子法（ADMM）求解。该方法重用了相同的隐式MPM线性化，提高了效率和数值稳定性。

Result: 该方法实现了精确的接触定位、可靠的摩擦处理以及广泛的通用性，能够准确模拟弹性、弹塑性响应，以及简单和复杂的变形几何。

Conclusion: 所提出的方法作为一种实用的解决方案，能够准确处理MPM中的摩擦接触，为机器人学及相关领域的MPM模拟提供了支持。

Abstract: Accurately handling contact with friction remains a core bottleneck for Material Point Method (MPM), from reliable contact point detection to enforcing frictional contact laws (non-penetration, Coulomb friction, and maximum dissipation principle). In this paper, we introduce a frictional-contact pipeline for implicit MPM that is both precise and robust. During the collision detection phase, contact points are localized with particle-centric geometric primitives; during the contact resolution phase, we cast frictional contact as a Nonlinear Complementarity Problem (NCP) over contact impulses and solve it with an Alternating Direction Method of Multipliers (ADMM) scheme. Crucially, the formulation reuses the same implicit MPM linearization, yielding efficiency and numerical stability. The method integrates seamlessly into the implicit MPM loop and is agnostic to modeling choices, including material laws, interpolation functions, and transfer schemes. We evaluate it across seven representative scenes that span elastic and elasto-plastic responses, simple and complex deformable geometries, and a wide range of contact conditions. Overall, the proposed method enables accurate contact localization, reliable frictional handling, and broad generality, making it a practical solution for MPM-based simulations in robotics and related domains.

</details>


### [680] [FD-VLA: Force-Distilled Vision-Language-Action Model for Contact-Rich Manipulation](https://arxiv.org/abs/2602.02142)
*Ruiteng Zhao,Wenshuo Wang,Yicheng Ma,Xiaocong Li,Francis E. H. Tay,Marcelo H. Ang,Haiyue Zhu*

Main category: cs.RO

TL;DR: 提出了一种名为FD-VLA的新型框架，通过“力蒸馏模块”（FDM）在没有物理力传感器的前提下，将力感知能力集成到机器人操作中，并通过实验证明其性能优于直接的力传感器测量。


<details>
  <summary>Details</summary>
Motivation: 在视觉-语言-动作（VLA）框架中，力感知对于接触式任务中的精细感知和灵巧操作至关重要。然而，物理力传感器的成本高昂且易损坏，限制了其广泛应用。因此，需要一种无需物理力传感器即可集成力感知能力的方法。

Method: 提出了一种力蒸馏模块（FDM），它将一个可学习的查询令牌（基于视觉观测和机器人状态）映射到一个预测的力令牌。这个力令牌与实际力信号的潜在表示对齐。在推理时，将此力令牌注入预训练的VLM中，实现力感知推理，同时保持VLM的视觉-语言语义。

Result: FD-VLA在物理实验中表现出色，其蒸馏的力令牌在接触丰富场景下的性能优于直接的传感器力测量以及其他基线方法。

Conclusion: FD-VLA框架能够有效地将力感知能力集成到VLA框架中，无需昂贵的物理力传感器，降低了硬件成本和复杂性，并提高了在接触丰富场景下的跨模态对齐和感知-动作鲁棒性。蒸馏的力令牌甚至在实际应用中优于直接的力传感器测量。

Abstract: Force sensing is a crucial modality for Vision-Language-Action (VLA) frameworks, as it enables fine-grained perception and dexterous manipulation in contact-rich tasks. We present Force-Distilled VLA (FD-VLA), a novel framework that integrates force awareness into contact-rich manipulation without relying on physical force sensors. The core of our approach is a Force Distillation Module (FDM), which distills force by mapping a learnable query token, conditioned on visual observations and robot states, into a predicted force token aligned with the latent representation of actual force signals. During inference, this distilled force token is injected into the pretrained VLM, enabling force-aware reasoning while preserving the integrity of its vision-language semantics. This design provides two key benefits: first, it allows practical deployment across a wide range of robots that lack expensive or fragile force-torque sensors, thereby reducing hardware cost and complexity; second, the FDM introduces an additional force-vision-state fusion prior to the VLM, which improves cross-modal alignment and enhances perception-action robustness in contact-rich scenarios. Surprisingly, our physical experiments show that the distilled force token outperforms direct sensor force measurements as well as other baselines, which highlights the effectiveness of this force-distilled VLA approach.

</details>


### [681] [Extending the Law of Intersegmental Coordination: Implications for Powered Prosthetic Controls](https://arxiv.org/abs/2602.02181)
*Elad Siman Tov,Nili E. Krausz*

Main category: cs.RO

TL;DR: 本文提出了一种新的方法来分析人体的运动协调性，并将其应用于假肢行走的研究，以期改进假肢的设计和控制，降低截肢者的行走代谢成本。


<details>
  <summary>Details</summary>
Motivation: 降低截肢者行走时的代谢成本是一个未解决的问题，而现有的动力假肢虽然能提供净正功，但在运动协调性方面仍有待提高。以往的研究表明，肢体间的协调性（ISC）与行走能量消耗有关，但很少应用于截肢者。因此，本研究旨在通过分析和应用ISC来改善假肢行走。

Method: 研究人员开发了一种新的方法来分析三维运动学数据中的肢体间协调性（ISC），并在此基础上提出了“Elevation Space Moments”（ESM）的概念，用于分析力矩的协调性。他们使用该方法分析了健全人和截肢者（使用动力和被动假肢）的行走数据，并利用ISC作为约束来预测假肢的运动，以模仿健全人的行走模式。

Result: 研究发现，健全人的行走表现出ESM的协调性。截肢者行走时，虽然肢体角度仍然保持平面，但ESM的协调性较差。通过使用ISC作为约束，可以预测出补偿被动假肢带来的改变，从而模仿健全人的大腿角度/力矩曲线。

Conclusion: 本文提出的ISC分析方法和ESM概念可以量化和理解截肢者行走时的协调性。通过利用ISC作为约束，有望改进动力假肢的控制策略，从而降低截肢者的行走代谢成本。此外，研究还开发了一个名为ISC3d的工具箱，以促进对行走协调性的进一步研究，并可能有助于解决神经控制等基础科学问题。

Abstract: Powered prostheses are capable of providing net positive work to amputees and have advanced in the past two decades. However, reducing amputee metabolic cost of walking remains an open problem. The Law of Intersegmental Coordination (ISC) has been observed across gaits and has been previously implicated in energy expenditure of walking, yet it has rarely been analyzed or applied within the context of lower-limb amputee gait. This law states that the elevation angles of the thigh, shank and foot over the gait cycle are not independent. In this work, we developed a method to analyze intersegmental coordination for lower-limb 3D kinematic data, to simplify ISC analysis. Moreover, inspired by motor control, biomechanics and robotics literature, we used our method to broaden ISC toward a new law of coordination of moments. We find these Elevation Space Moments (ESM), and present results showing a moment-based coordination for able bodied gait. We also analyzed ISC for amputee gait walking with powered and passive prosthesis, and found that while elevation angles remained planar, the ESM showed less coordination. We use ISC as a constraint to predict the shank angles/moments that would compensate for alterations due to a passive foot so as to mimic a healthy thigh angle/moment profile. This may have implications for improving powered prosthetic control. We developed the ISC3d toolbox that is freely available online, which may be used to compute kinematic and kinetic ISC in 3D. This provides a means to further study the role of coordination in gait and may help address fundamental questions of the neural control of human movement.

</details>


### [682] [TTT-Parkour: Rapid Test-Time Training for Perceptive Robot Parkour](https://arxiv.org/abs/2602.02331)
*Shaoting Zhu,Baijun Ye,Jiaxuan Wang,Jiakang Chen,Ziwen Zhuang,Linzhan Mou,Runhan Huang,Hang Zhao*

Main category: cs.RO

TL;DR: 提出了一种实-虚-实框架，通过在新型地形上进行快速测试时训练（TTT），显著提高了人形机器人在复杂地形上的跑酷能力。


<details>
  <summary>Details</summary>
Motivation: 通用运动策略在复杂和未见过地形上的局限性，需要一种能够适应极端几何环境的方法。

Method: 采用两阶段端到端学习：1. 在程序生成的多样化地形上预训练策略；2. 使用从真实世界捕获的高保真网格进行快速测试时微调。开发了使用RGB-D输入的、高效且高保真的几何重建管线。

Result: TTT-Parkour框架使人形机器人能够掌握复杂的障碍物，包括楔形、木桩、盒子、梯形和窄梁。整个捕获、重建和测试时训练流程在大多数测试地形上耗时不到10分钟。

Conclusion: 该方法通过快速测试时训练，显著提升了机器人在复杂地形上的运动能力，并展示了强大的零样本仿真到现实迁移能力。

Abstract: Achieving highly dynamic humanoid parkour on unseen, complex terrains remains a challenge in robotics. Although general locomotion policies demonstrate capabilities across broad terrain distributions, they often struggle with arbitrary and highly challenging environments. To overcome this limitation, we propose a real-to-sim-to-real framework that leverages rapid test-time training (TTT) on novel terrains, significantly enhancing the robot's capability to traverse extremely difficult geometries. We adopt a two-stage end-to-end learning paradigm: a policy is first pre-trained on diverse procedurally generated terrains, followed by rapid fine-tuning on high-fidelity meshes reconstructed from real-world captures. Specifically, we develop a feed-forward, efficient, and high-fidelity geometry reconstruction pipeline using RGB-D inputs, ensuring both speed and quality during test-time training. We demonstrate that TTT-Parkour empowers humanoid robots to master complex obstacles, including wedges, stakes, boxes, trapezoids, and narrow beams. The whole pipeline of capturing, reconstructing, and test-time training requires less than 10 minutes on most tested terrains. Extensive experiments show that the policy after test-time training exhibits robust zero-shot sim-to-real transfer capability.

</details>


### [683] [Mapping-Guided Task Discovery and Allocation for Robotic Inspection of Underwater Structures](https://arxiv.org/abs/2602.02389)
*Marina Ruediger,Ashis G. Banerjee*

Main category: cs.RO

TL;DR: 该研究提出了一种从SLAM数据生成和优化水下多机器人检查任务的方法，该方法无需预先了解几何形状，并通过考虑硬件参数和环境条件来提高检查效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 在水下机器人检查任务中，由于事先不知道目标区域的几何形状，生成有效的检查任务具有挑战性。本研究旨在解决这一问题，通过利用SLAM数据生成自适应的任务，并优化检查效率。

Method: 该方法利用SLAM网格生成一系列任务，并根据预期的关键点得分和基于距离的剪枝进行优化。通过在水下进行测试来验证算法的有效性并确定参数。并将结果与模拟的Voronoi分区和boustrophedon模式进行比较。

Result: 该算法能够生成适应意外几何形状的任务，并能保持覆盖率，同时关注可能存在缺陷或损坏的区域。与模拟方法相比，该方法在实际水下环境中表现出有效性。

Conclusion: 通过检查SLAM数据，可以生成和优化水下多机器人检查任务，尤其是在几何形状未知的情况下。该方法能够适应性地应对不同的几何形状和分布，并有效地聚焦于潜在的缺陷区域，从而提高检查效率和准确性。

Abstract: Task generation for underwater multi-robot inspections without prior knowledge of existing geometry can be achieved and optimized through examination of simultaneous localization and mapping (SLAM) data. By considering hardware parameters and environmental conditions, a set of tasks is generated from SLAM meshes and optimized through expected keypoint scores and distance-based pruning. In-water tests are used to demonstrate the effectiveness of the algorithm and determine the appropriate parameters. These results are compared to simulated Voronoi partitions and boustrophedon patterns for inspection coverage on a model of the test environment. The key benefits of the presented task discovery method include adaptability to unexpected geometry and distributions that maintain coverage while focusing on areas more likely to present defects or damage.

</details>


### [684] [PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning](https://arxiv.org/abs/2602.02396)
*Amisha Bhaskar,Pratap Tokekar,Stefano Di Cairano,Alexander Schperberg*

Main category: cs.RO

TL;DR: 本文提出了一种名为 PRISM 的单程模仿学习策略，该策略基于隐式最大似然估计 (IMLE) 的批全局拒绝采样变体，能够整合多模态感知数据（RGB、深度、触觉、音频、本体感觉），并实现高频率的闭环控制，在实际硬件和大规模仿真基准测试中均优于现有扩散策略。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人模仿学习方法，如扩散模型、流匹配和 IMLE，虽然取得了不错的进展，但通常只能满足实时控制率、多模态感知或多模态动作分布等部分要求。需要一种能够同时满足这些要求的策略。

Method: PRISM 采用一种基于批全局拒绝采样变体的 IMLE 方法。它结合了一个多模态时间编码器（用于整合 RGB、深度、触觉、音频和本体感觉）和一个使用 Performer 架构的线性注意力生成器，实现单程策略。

Result: 在实际硬件（Unitree Go2 和 UR5 机械臂）上，PRISM 在 loco-manipulation 和 tabletop manipulation 等任务中，成功率比最先进的扩散策略高出 10-25%，同时保持了 30-50 Hz 的高频率闭环控制。在 CALVIN、MetaWorld 和 Robomimic 等大规模仿真基准上，PRISM 在 CALVIN 数据集（10% 数据划分）上将成功率提高了约 25%（相比扩散）和约 20%（相比流匹配），同时将轨迹的加加速度（jerk）降低了 20-50 倍。

Conclusion: PRISM 是一种快速、准确且支持多模态输入的模仿策略，能够在不引入迭代采样延迟的情况下，保持多模态动作的覆盖率，满足机器人模仿学习的多种关键需求。

Abstract: Robotic imitation learning typically requires models that capture multimodal action distributions while operating at real-time control rates and accommodating multiple sensing modalities. Although recent generative approaches such as diffusion models, flow matching, and Implicit Maximum Likelihood Estimation (IMLE) have achieved promising results, they often satisfy only a subset of these requirements. To address this, we introduce PRISM, a single-pass policy based on a batch-global rejection-sampling variant of IMLE. PRISM couples a temporal multisensory encoder (integrating RGB, depth, tactile, audio, and proprioception) with a linear-attention generator using a Performer architecture. We demonstrate the efficacy of PRISM on a diverse real-world hardware suite, including loco-manipulation using a Unitree Go2 with a 7-DoF arm D1 and tabletop manipulation with a UR5 manipulator. Across challenging physical tasks such as pre-manipulation parking, high-precision insertion, and multi-object pick-and-place, PRISM outperforms state-of-the-art diffusion policies by 10-25% in success rate while maintaining high-frequency (30-50 Hz) closed-loop control. We further validate our approach on large-scale simulation benchmarks, including CALVIN, MetaWorld, and Robomimic. In CALVIN (10% data split), PRISM improves success rates by approximately 25% over diffusion and approximately 20% over flow matching, while simultaneously reducing trajectory jerk by 20x-50x. These results position PRISM as a fast, accurate, and multisensory imitation policy that retains multimodal action coverage without the latency of iterative sampling.

</details>


### [685] [SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation](https://arxiv.org/abs/2602.02402)
*Mu Huang,Hui Wang,Kerui Ren,Linning Xu,Yunsong Zhou,Mulin Yu,Bo Dai,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 本文提出了一种名为 SoMA 的 3D 高斯溅射模拟器，用于软体操纵，通过将可变形动力学、环境力和机器人关节动作耦合到一个统一的潜在神经空间中，实现了端到端的真实到模拟，提高了准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在真实到模拟机器人操纵中，模拟具有丰富交互的形变物体仍然是一个挑战，因为其动力学同时受环境效应和机器人动作的影响。现有的模拟器在精确度、稳定性和泛化性方面存在局限。

Method: SoMA 将可变形动力学、环境力和机器人关节动作耦合在一个统一的潜在神经空间中，通过学习高斯溅射来模拟交互，实现端到端的真实到模拟。

Result: SoMA 提高了在真实机器人操纵上的重模拟准确性和泛化能力 20%，能够稳定模拟长期布料折叠等复杂任务。

Conclusion: SoMA 能够实现可控、稳定的长期操纵，并超越观测轨迹进行泛化，而无需预定义的物理模型，为真实到模拟的软体操纵提供了一种有效的方法。

Abstract: Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation. Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding.

</details>


### [686] [Multi-Agent Monte Carlo Tree Search for Makespan-Efficient Object Rearrangement in Cluttered Spaces](https://arxiv.org/abs/2602.02411)
*Hanwen Ren,Junyong Kim,Aathman Tharmasanthiran,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 本文提出了一种名为CAM-MCTS的中心化、异步、多智能体蒙特卡洛树搜索框架，用于在复杂、杂乱的环境中进行面向使能时间（makespan-efficient）的对象重排规划，尤其擅长处理非单调任务，并展示了在模拟和真实世界实验中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的对象重排任务（如仓库、家庭、救援现场）往往是复杂且非单调的，即对象之间会相互阻碍，需要临时移动才能到达最终目的地。同时，多智能体协作可以显著提高任务效率，但现有方法在处理这类问题时效率不高。

Method: CAM-MCTS框架结合了中心化任务分配（使智能体了解彼此意图以实现全局优化）和异步任务执行策略。在异步执行中，智能体根据一步前瞻的成本估计，在适当的时间步长开始新任务，而非等待其他智能体，从而减少了空闲时间和同步延迟。

Result: 在多种单调和非单调的任务以及杂乱环境的评估中，CAM-MCTS在使能时间方面持续优于强基线方法。在真实世界的多智能体系统上的验证也证实了其有效性和鲁棒性。

Conclusion: CAM-MCTS是一个通用的、面向使能时间的、用于复杂环境对象重排规划的新型框架，它通过中心化协调和异步执行的结合，有效解决了非单调任务的挑战，并显著提高了多智能体系统的整体效率。

Abstract: Object rearrangement planning in complex, cluttered environments is a common challenge in warehouses, households, and rescue sites. Prior studies largely address monotone instances, whereas real-world tasks are often non-monotone-objects block one another and must be temporarily relocated to intermediate positions before reaching their final goals. In such settings, effective multi-agent collaboration can substantially reduce the time required to complete tasks. This paper introduces Centralized, Asynchronous, Multi-agent Monte Carlo Tree Search (CAM-MCTS), a novel framework for general-purpose makespan-efficient object rearrangement planning in challenging environments. CAM-MCTS combines centralized task assignment-where agents remain aware of each other's intended actions to facilitate globally optimized planning-with an asynchronous task execution strategy that enables agents to take on new tasks at appropriate time steps, rather than waiting for others, guided by a one-step look-ahead cost estimate. This design minimizes idle time, prevents unnecessary synchronization delays, and enhances overall system efficiency. We evaluate CAM-MCTS across a diverse set of monotone and non-monotone tasks in cluttered environments, demonstrating consistent reductions in makespan compared to strong baselines. Finally, we validate our approach on a real-world multi-agent system under different configurations, further confirming its effectiveness and robustness.

</details>


### [687] [3D Foundation Model-Based Loop Closing for Decentralized Collaborative SLAM](https://arxiv.org/abs/2602.02430)
*Pierre-Yves Lajoie,Benjamin Ramtoula,Daniele De Martini,Giovanni Beltrame*

Main category: cs.RO

TL;DR: 提出一种利用3D基础模型解决去中心化协同SLAM中因视角差异大而难以识别地图重叠的问题，通过估计相对位姿、鲁棒的异常值抑制和解决尺度歧义的位姿图优化，提升了定位和建图精度，并提高了计算和内存效率。


<details>
  <summary>Details</summary>
Motivation: 去中心化协同SLAM在识别地图重叠时，因机器人之间视角差异大而面临挑战。

Method: 整合3D基础模型到现有SLAM流程中，用于估计单目图像对之间的相对位姿；引入鲁棒的异常值抑制技术；开发专门的位姿图优化方法来解决尺度歧义。

Result: 与最先进的方法相比，在定位和建图精度上有所提高，计算和内存效率也显著提升。

Conclusion: 提出的方法能够可靠地估计机器人间的相对位姿，并有效解决尺度歧义，在处理大规模多机器人场景方面具有潜力。

Abstract: Decentralized Collaborative Simultaneous Localization And Mapping (C-SLAM) techniques often struggle to identify map overlaps due to significant viewpoint variations among robots. Motivated by recent advancements in 3D foundation models, which can register images despite large viewpoint differences, we propose a robust loop closing approach that leverages these models to establish inter-robot measurements. In contrast to resource-intensive methods requiring full 3D reconstruction within a centralized map, our approach integrates foundation models into existing SLAM pipelines, yielding scalable and robust multi-robot mapping. Our contributions include: (1) integrating 3D foundation models to reliably estimate relative poses from monocular image pairs within decentralized C-SLAM; (2) introducing robust outlier mitigation techniques critical to the use of these relative poses; and (3) developing specialized pose graph optimization formulations that efficiently resolve scale ambiguities. We evaluate our method against state-of-the-art approaches, demonstrating improvements in localization and mapping accuracy, alongside significant gains in computational and memory efficiency. These results highlight the potential of our approach for deployment in large-scale multi-robot scenarios.

</details>


### [688] [Multi-Task Learning for Robot Perception with Imbalanced Data](https://arxiv.org/abs/2602.01899)
*Ozgur Erkent*

Main category: cs.RO

TL;DR: 提出了一种在缺少部分任务真实标签的情况下也能学习任务的方法，并通过训练教师网络来识别任务间的互助关系，实验在NYUDv2和Cityscapes数据集上进行了语义分割和深度估计任务的验证。


<details>
  <summary>Details</summary>
Motivation: 机器人资源有限，多任务学习虽能提升单个任务精度，但存在数据不均衡和标签获取困难的问题。研究旨在解决在数据不均衡甚至缺少部分任务真实标签的情况下进行多任务学习，并探索任务间的相互促进关系。

Method: 提出一种在缺少部分任务真实标签的情况下学习的方法。通过训练一个教师网络，将其他任务的输出（如深度图）作为输入，来分析哪些任务能促进其他任务的性能提升。

Result: 成功实现了一个在部分任务无真实标签时也能学习的方法。通过实验发现，任务之间存在交互作用，某些任务可以提升其他任务的性能。在NYUDv2和Cityscapes数据集上进行了语义分割和深度估计任务的实证验证，并展示了在小样本数据下的有效性。

Conclusion: 所提出的方法能够有效地处理多任务学习中的数据不均衡和标签缺失问题。任务间的交互分析揭示了任务间的相互促进机制，为机器人多任务学习提供了新的视角和解决方案，尤其在数据有限的情况下具有重要意义。

Abstract: Multi-task problem solving has been shown to improve the accuracy of the individual tasks, which is an important feature for robots, as they have a limited resource. However, when the number of labels for each task is not equal, namely imbalanced data exist, a problem may arise due to insufficient number of samples, and labeling is not very easy for mobile robots in every environment. We propose a method that can learn tasks even in the absence of the ground truth labels for some of the tasks. We also provide a detailed analysis of the proposed method. An interesting finding is related to the interaction of the tasks. We show a methodology to find out which tasks can improve the performance of other tasks. We investigate this by training the teacher network with the task outputs such as depth as inputs. We further provide empirical evidence when trained with a small amount of data. We use semantic segmentation and depth estimation tasks on different datasets, NYUDv2 and Cityscapes.

</details>


### [689] [World-Gymnast: Training Robots with Reinforcement Learning in a World Model](https://arxiv.org/abs/2602.02454)
*Ansh Kumar Sharma,Yixiang Sun,Ninghao Lu,Yunzhe Zhang,Jiarao Liu,Sherry Yang*

Main category: cs.RO

TL;DR: 该研究提出了一种名为World-Gymnast的方法，通过在基于视频的世界模型中进行强化学习，来训练机器人的视觉-语言-动作（VLA）策略，从而克服了物理交互成本高的问题。实验结果表明，该方法在机器人任务上显著优于监督微调（SFT）和软件模拟器，并展示了其在处理多样化指令、新场景以及在线改进方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 物理世界交互成本高昂是机器人学习的关键瓶颈。现有的监督微调（SFT）受限于专家数据量，而软件模拟器则面临仿真到现实（sim-to-real）的差距。研究旨在探索是否可以在学习到的世界模型中进行训练，以获得比SFT或软件模拟器更好的真实机器人性能。

Method: 该研究提出World-Gymnast，它采用强化学习（RL）微调一个视觉-语言-动作（VLA）策略。具体而言，策略在动作条件视频世界模型中进行“滚动”模拟，并使用视觉-语言模型（VLM）作为奖励信号。通过这种方式，RL在世界模型中进行训练，避免了昂贵的物理交互。

Result: 在Bridge机器人设置上，World-Gymnast的性能比SFT高出18倍，比软件模拟器高出2倍。此外，World-Gymnast展现了RL与世界模型结合的强大能力，包括：在世界模型中对多样化的语言指令和新颖场景进行训练；在测试时对新场景进行训练；以及在线迭代地改进世界模型和策略。

Conclusion: 研究结果表明，学习世界模型并在云端训练机器人策略可能是弥合演示机器人与能在任何家庭工作的机器人之间差距的关键。World-Gymnast通过在世界模型中进行RL训练，有效地解决了物理交互成本和sim-to-real差距的问题，为机器人学习开辟了新的可能性。

Abstract: Robot learning from interacting with the physical world is fundamentally bottlenecked by the cost of physical interaction. The two alternatives, supervised finetuning (SFT) from expert demonstrations and reinforcement learning (RL) in a software-based simulator, are limited by the amount of expert data available and the sim-to-real gap for manipulation. With the recent emergence of world models learned from real-world video-action data, we ask the question of whether training a policy in a world model can be more effective than supervised learning or software simulation in achieving better real-robot performance. We propose World-Gymnast, which performs RL finetuning of a vision-language-action (VLA) policy by rolling out the policy in an action-conditioned video world model and rewarding the rollouts with a vision-language model (VLM). On the Bridge robot setup, World-Gymnast outperforms SFT by as much as 18x and outperforms software simulator by as much as 2x. More importantly, World-Gymnast demonstrates intriguing capabilities of RL with a world model, including training on diverse language instructions and novel scenes from the world model, test-time training in a novel scene, and online iterative world model and policy improvement. Our results suggest learning a world model and training robot policies in the cloud could be the key to bridging the gap between robots that work in demonstrations and robots that can work in anyone's household.

</details>


### [690] [Relationship-Aware Hierarchical 3D Scene Graph for Task Reasoning](https://arxiv.org/abs/2602.02456)
*Albert Gassol Puigjaner,Angelos Zacharia,Kostas Alexis*

Main category: cs.RO

TL;DR: 该研究提出了一种增强的层次化三维场景图，集成了开放词汇特征和视觉语言模型（VLM）来推断语义关系，并利用大型语言模型（LLM）和VLM进行任务推理，以提高自主代理的理解和交互能力。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法在捕捉高级抽象和关系推理方面存在不足，无法充分理解3D环境的结构化表示和对象关系。

Method: 提出一种增强的层次化三维场景图，利用VLM进行语义关系推断，并结合LLM和VLM设计了一个任务推理模块，用于解释场景图的语义和关系信息。

Result: 在部署于四足机器人上的实验中，验证了该方法能够对不同环境和任务进行有效的推理。

Conclusion: 增强的层次化三维场景图结合VLM和LLM的任务推理模块，能够为自主代理提供更智能的环境理解和交互能力。

Abstract: Representing and understanding 3D environments in a structured manner is crucial for autonomous agents to navigate and reason about their surroundings. While traditional Simultaneous Localization and Mapping (SLAM) methods generate metric reconstructions and can be extended to metric-semantic mapping, they lack a higher level of abstraction and relational reasoning. To address this gap, 3D scene graphs have emerged as a powerful representation for capturing hierarchical structures and object relationships. In this work, we propose an enhanced hierarchical 3D scene graph that integrates open-vocabulary features across multiple abstraction levels and supports object-relational reasoning. Our approach leverages a Vision Language Model (VLM) to infer semantic relationships. Notably, we introduce a task reasoning module that combines Large Language Models (LLM) and a VLM to interpret the scene graph's semantic and relational information, enabling agents to reason about tasks and interact with their environment more intelligently. We validate our method by deploying it on a quadruped robot in multiple environments and tasks, highlighting its ability to reason about them.

</details>


### [691] [HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos](https://arxiv.org/abs/2602.02473)
*Yinhuai Wang,Qihan Zhao,Yuen Fui Lau,Runyi Yu,Hok Wai Tsui,Qifeng Chen,Jingbo Wang,Jiangmiao Pang,Ping Tan*

Main category: cs.RO

TL;DR: 本文提出了一种名为HumanX的全栈框架，通过将人类视频转化为通用的、可扩展的机器人交互技能，解决了人形机器人进行敏捷自适应交互任务的挑战，无需任务特定的奖励工程。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人实现敏捷交互的挑战在于真实交互数据稀缺以及需要细致的任务特定奖励工程，这限制了其可扩展性。

Method: HumanX框架包含两个核心组件：XGen，一个从视频合成多样化且物理上可行的机器人交互数据的生成管道；XMimic，一个统一的模仿学习框架，用于学习通用的交互技能。

Result: 在篮球、足球、羽毛球、抓取货物和反应式格斗五个领域进行了评估，HumanX成功学习了10种不同的技能，并将它们零样本迁移到了物理Unitree G1人形机器人上。实验证明HumanX在泛化成功率上比现有方法高出8倍以上。

Conclusion: HumanX提供了一种可扩展且任务无关的方法，用于学习通用、真实的机器人交互技能，显著提高了泛化能力，克服了现有方法的局限性。

Abstract: Enabling humanoid robots to perform agile and adaptive interactive tasks has long been a core challenge in robotics. Current approaches are bottlenecked by either the scarcity of realistic interaction data or the need for meticulous, task-specific reward engineering, which limits their scalability. To narrow this gap, we present HumanX, a full-stack framework that compiles human video into generalizable, real-world interaction skills for humanoids, without task-specific rewards. HumanX integrates two co-designed components: XGen, a data generation pipeline that synthesizes diverse and physically plausible robot interaction data from video while supporting scalable data augmentation; and XMimic, a unified imitation learning framework that learns generalizable interaction skills. Evaluated across five distinct domains--basketball, football, badminton, cargo pickup, and reactive fighting--HumanX successfully acquires 10 different skills and transfers them zero-shot to a physical Unitree G1 humanoid. The learned capabilities include complex maneuvers such as pump-fake turnaround fadeaway jumpshots without any external perception, as well as interactive tasks like sustained human-robot passing sequences over 10 consecutive cycles--learned from a single video demonstration. Our experiments show that HumanX achieves over 8 times higher generalization success than prior methods, demonstrating a scalable and task-agnostic pathway for learning versatile, real-world robot interactive skills.

</details>


### [692] [TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments](https://arxiv.org/abs/2602.02459)
*Zhiyu Huang,Yun Zhang,Johnson Liu,Rui Song,Chen Tang,Jiaqi Ma*

Main category: cs.RO

TL;DR: 本研究提出了Think-in-Control (TIC)-VLA框架，它能显式地模拟延迟的语义推理过程，以提高机器人遵循语言指令的能力，即使在推理延迟较大的情况下也能保持实时反应控制。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在处理动态、以人为中心的环境时，通常假设推理和控制是时间上对齐的，但实际上语义推理往往滞后于实时动作。这种延迟会导致机器人无法准确执行指令。因此，需要一个能够处理这种异步推理和控制的模型。

Method: TIC-VLA框架引入了一个延迟的语义-控制接口，该接口在生成动作时，不仅考虑当前的观测，还考虑了延迟的视觉-语言语义状态以及显式的延迟元数据。此外，还提出了一个延迟一致的训练流程，在模仿学习和在线强化学习中注入推理延迟，以更好地匹配异步部署的场景。为了评估，研究人员还创建了一个名为DynaNav的模拟环境。

Result: 在模拟环境和真实机器人上的大量实验表明，TIC-VLA框架在多秒的推理延迟下，能够持续优于现有的VLA模型，并保持鲁棒的实时控制能力。

Conclusion: TIC-VLA框架通过显式地建模延迟的语义推理，有效地解决了机器人遵循语言指令时的异步问题，提升了机器人在动态环境中的实时反应和任务执行能力。

Abstract: Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control. Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control, despite semantic inference being inherently delayed relative to real-time action. We introduce Think-in-Control (TIC)-VLA, a latency-aware framework that explicitly models delayed semantic reasoning during action generation. TIC-VLA defines a delayed semantic-control interface that conditions action generation on delayed vision-language semantic states and explicit latency metadata, in addition to current observations, enabling policies to compensate for asynchronous reasoning. We further propose a latency-consistent training pipeline that injects reasoning inference delays during imitation learning and online reinforcement learning, aligning training with asynchronous deployment. To support realistic evaluation, we present DynaNav, a physics-accurate, photo-realistic simulation suite for language-guided navigation in dynamic environments. Extensive experiments in simulation and on a real robot show that TIC-VLA consistently outperforms prior VLA models while maintaining robust real-time control under multi-second reasoning latency. Project website: https://ucla-mobility.github.io/TIC-VLA/

</details>


### [693] [Flow Policy Gradients for Robot Control](https://arxiv.org/abs/2602.02481)
*Brent Yi,Hongsuk Choi,Himanshu Gaurav Singh,Xiaoyu Huang,Takara E. Truong,Carmelo Sferrazza,Yi Ma,Rocky Duan,Pieter Abbeel,Guanya Shi,Karen Liu,Angjoo Kanazawa*

Main category: cs.RO

TL;DR: 本文提出了一种改进的基于流匹配策略梯度的强化学习方法，用于训练和微调更具表现力的机器人控制策略，并在具身运动、人形运动跟踪和操作任务中取得了成功，以及在人形机器人上的鲁棒的 sim-to-real 迁移。


<details>
  <summary>Details</summary>
Motivation: 现有的基于似然的策略梯度方法在训练机器人控制策略时存在限制，因为它们依赖于可微的动作似然性，这约束了策略输出的分布（如高斯分布）。本文旨在探索一种绕过似然计算的框架（流匹配策略梯度），并将其应用于更具挑战性的机器人控制场景，以训练和微调更具表现力的策略。

Method: 文章采用流匹配策略梯度框架，并引入了一个改进的目标函数。通过在具身运动、人形运动跟踪和操作任务中进行实验，以及在两个人形机器人上进行 sim-to-real 迁移实验来验证方法的有效性。此外，还进行了消融实验和训练动态分析，以研究策略如何利用流表示进行探索以及改进微调鲁棒性。

Result: 改进的流匹配策略梯度方法在具身运动、人形运动跟踪和操作任务中取得了成功。在两个人形机器人上的 sim-to-real 迁移也显示出鲁棒性。结果表明，策略可以利用流表示进行从头开始的探索，并且在微调方面的鲁棒性优于基线方法。

Conclusion: 基于流匹配的策略梯度方法能够有效地训练和微调更具表现力的机器人控制策略，并在各种机器人控制任务中展现出优越的性能和鲁棒性，特别是在探索和微调方面。

Abstract: Likelihood-based policy gradient methods are the dominant approach for training robot control policies from rewards. These methods rely on differentiable action likelihoods, which constrain policy outputs to simple distributions like Gaussians. In this work, we show how flow matching policy gradients -- a recent framework that bypasses likelihood computation -- can be made effective for training and fine-tuning more expressive policies in challenging robot control settings. We introduce an improved objective that enables success in legged locomotion, humanoid motion tracking, and manipulation tasks, as well as robust sim-to-real transfer on two humanoid robots. We then present ablations and analysis on training dynamics. Results show how policies can exploit the flow representation for exploration when training from scratch, as well as improved fine-tuning robustness over baselines.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [694] [Optimal Control-Based Falsification of Learnt Dynamics via Neural ODEs and Symbolic Regression](https://arxiv.org/abs/2602.00031)
*Lasse Kötz,Jonas Sjöberg,Knut Åkesson*

Main category: eess.SY

TL;DR: 提出了一种集成学习模型动力学和最优控制的虚假化框架，用于高效生成反例。通过神经ODE学习未知动力学，并结合符号回归进行可解释的轨迹优化，以最小化STL鲁棒性来寻找反例。实验表明，该方法比不建模动力学的方法所需系统测试实验次数少几个数量级。


<details>
  <summary>Details</summary>
Motivation: 为了高效地为使用信号时序逻辑（STL）指定的网络物理系统生成反例，尤其是在系统动力学未知的情况下。

Method: 1. 使用神经ODE学习未知系统动力学，并融入先验知识。 2. 通过符号回归将神经ODE转化为解析形式。 3. 将虚假化问题转化为最小化STL鲁棒性，负鲁棒性产生候选反例。 4. 验证候选反例，并使用错误轨迹迭代优化代理模型。

Result: 所提出的方法在ARCH-COMP 2024基准测试中，所需的被测系统实验次数比不建模系统动力学的优化方法少几个数量级。

Conclusion: 该集成框架能够有效地学习系统动力学，并生成可解释的反例，显著提高了网络物理系统的虚假化效率。

Abstract: We present a falsification framework that integrates learned surrogate dynamics with optimal control to efficiently generate counterexamples for cyber-physical systems specified in signal temporal logic (STL). The unknown system dynamics are identified using neural ODEs, while known a-priori structure is embedded directly into the model, reducing data requirements. The learned neural ODE is converted into an analytical form via symbolic regression, enabling fast and interpretable trajectory optimization. Falsification is cast as minimizing STL robustness over input trajectories; negative robustness yields candidate counterexamples, which are validated on the original system. Spurious traces are iteratively used to refine the surrogate, while true counterexamples are returned as final results. Experiments on ARCH-COMP 2024 benchmarks show that this method requires orders of magnitude fewer experiments of the system under test than optimization-based approaches that do not model system dynamics.

</details>


### [695] [Motion Planning with Metric Temporal Logic Using Reachability Analysis and Hybrid Zonotopes](https://arxiv.org/abs/2602.00325)
*Andrew F. Thompson,Joshua A. Robbins,Jonah J. Glunt,Sean B. Brennan,Herschel C. Pangborn*

Main category: eess.SY

TL;DR: 本文提出一种利用可达性分析来优化自动驾驶汽车满足度量时序逻辑 (MTL) 约束的运动规划方法。该方法使用混合区域图（hybrid zonotopes）高效编码 MTL 规范，并在数值基准测试中展现了计算优势，同时也能处理时变环境、区域依赖扰动和多智能体协调等复杂场景。


<details>
  <summary>Details</summary>
Motivation: 为自动驾驶汽车开发满足时间依赖任务需求的控制策略，但现有方法在满足 MTL 约束的同时进行控制优化计算成本高昂。

Method: 1. 使用可达性分析隐式表达满足 MTL 规范的状态集合。2. 采用混合区域图（hybrid zonotopes）作为集合表示方法，将 MTL 规范高效编码到可达集中。3. 基于编码后的可达集进行运动规划优化。

Result: 1. 提出的方法在数值基准测试中比现有方法具有计算优势。2. 成功处理了时变环境、区域依赖扰动和多智能体协调的场景。3. 在实验应用中验证了方法的有效性。

Conclusion: 该方法能够有效地解决自动驾驶汽车在满足 MTL 约束下的运动规划问题，并展现出计算效率和处理复杂场景的能力。

Abstract: Metric temporal logic (MTL) provides a formal framework for defining time-dependent mission requirements on autonomous vehicles. However, optimizing control decisions subject to these constraints is often computationally expensive. This article presents a method that uses reachability analysis to implicitly express the set of states satisfying an MTL specification and then optimizes to find a motion plan. The hybrid zonotope set representation is used to efficiently and conveniently encode MTL specifications into reachable sets. A numerical benchmark highlights the proposed method's computational advantages as compared to existing methods in the literature. Further numerical examples and an experimental application demonstrate the ability to address time-varying environments, region-dependent disturbances, and multi-agent coordination.

</details>


### [696] [Stealthy Coverage Control for Human-enabled Real-Time 3D Reconstruction](https://arxiv.org/abs/2602.00466)
*Reiji Terunuma,Yuta Nakamura,Takuma Abe,Takeshi Hatanaka*

Main category: eess.SY

TL;DR: 本文提出了一种名为“隐秘覆盖控制”的新型半自主图像采样策略，用于增强人类参与的3D结构重建。该策略利用人类的推理和情境识别能力，使人类操作员能够指导无人机在结构复杂区域采集更多图像，同时通过解耦运动控制避免了人机冲突，从而提高了重建模型的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的3D结构重建方法在图像采集数量上存在挑战，因为需要准确重建的图像数量与目标场景的结构复杂性相关，但事先了解这种空间非均匀复杂性是不现实的。因此，需要一种能够有效适应复杂场景的图像采样策略。

Method: 提出了一种名为“隐秘覆盖控制”的半自主系统。该系统利用人类操作员的灵活性，让他们识别需要更多图像的区域并导航无人机。具体来说，它设计了一种将人类意图反映到自主覆盖控制中的方法，并开发了一种“隐秘覆盖控制”机制，将用于高效图像采样的无人机运动与人类导航解耦，以避免操作冲突。

Result: 通过Unity/ROS2仿真平台的研究表明，提出的半自主系统在重建模型质量方面优于没有人类干预的系统。

Conclusion: 该研究成功提出了一种结合人类智能和自主控制的半自主图像采样策略，该策略能够有效地适应3D结构重建中场景复杂性的非均匀性，并提高了重建模型的质量。

Abstract: In this paper, we propose a novel semi-autonomous image sampling strategy, called stealthy coverage control, for human-enabled 3D structure reconstruction. The present mission involves a fundamental problem: while the number of images required to accurately reconstruct a 3D model depends on the structural complexity of the target scene to be reconstructed, it is not realistic to assume prior knowledge of the spatially non-uniform structural complexity. We approach this issue by leveraging human flexible reasoning and situational recognition capabilities. Specifically, we design a semi-autonomous system that leaves identification of regions that need more images and navigation of the drones to such regions to a human operator. To this end, we first present a way to reflect the human intention in autonomous coverage control. Subsequently, in order to avoid operational conflicts between manual control and autonomous coverage control, we develop the stealthy coverage control that decouples the drone motion for efficient image sampling from navigation by the human. Simulation studies on a Unity/ROS2-based simulator demonstrate that the present semi-autonomous system outperforms the one without human interventions in the sense of the reconstructed model quality.

</details>


### [697] [Model-Based Data-Efficient and Robust Reinforcement Learning](https://arxiv.org/abs/2602.00630)
*Ludvig Svedlund,Constantin Cronrath,Jonas Fredriksson,Bengt Lennartson*

Main category: eess.SY

TL;DR: 提出了一种数据高效的学习控制设计方法，通过学习系统动力学模型，在一个两级框架中实现。该方法通过高层优化降低能耗并处理约束，低层反馈控制器补偿扰动和模型误差，相比现有方法能耗更低，效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有控制方法在处理约束、模型误差和数据效率方面存在挑战，作者希望开发一种能耗更低、数据效率更高的学习控制方法。

Method: 提出了一种两级学习控制框架：高层使用优化方法（例如，考虑能耗、状态和动作约束），低层使用反馈控制器补偿扰动和模型误差。对模型自由和基于模型的学习方法进行了鲁棒性分析，发现模型自由方法对未建模动态敏感。

Result: 提出的方法在给定路径下，能够通过调整速度和加速度，在满足速度限制和完成时间的前提下，显著节省能量。与两种已知的 actor-critic 强化学习策略相比，能耗更低，评估的时间步数减少了 100 倍以上。

Conclusion: 所提出的数据高效的学习控制设计方法能够有效地学习系统动力学，并在处理约束和补偿扰动的同时，实现显著的能耗降低和效率提升，优于现有的强化学习方法。

Abstract: A data-efficient learning-based control design method is proposed in this paper. It is based on learning a system dynamics model that is then leveraged in a two-level procedure. On the higher level, a simple but powerful optimization procedure is performed such that, for example, energy consumption in a vehicle can be reduced when hard state and action constraints are also introduced. Load disturbances and model errors are compensated for by a feedback controller on the lower level. In that regard, we briefly examine the robustness of both model-free and model-based learning approaches, and it is shown that the model-free approach greatly suffers from the inclusion of unmodeled dynamics. In evaluating the proposed method, it is assumed that a path is given, while the velocity and acceleration can be modified such that energy is saved, while still keeping speed limits and completion time. Compared with two well-known actor-critic reinforcement learning strategies, the suggested learning-based approach saves more energy and reduces the number of evaluated time steps by a factor of 100 or more.

</details>


### [698] [Modeling and Control of Hybrid Distribution Transformers for Simultaneous Grid Services](https://arxiv.org/abs/2602.00798)
*Martin Doff-Sotta,Florian Cech,Rishabh Manjunatha,Costantino Citro,Matthew Williams,Thomas Morstyn*

Main category: eess.SY

TL;DR: 本文提出了一种混合配电变压器（HDT）的三相平均数学模型，并设计了基于级联PI控制器的控制策略，实现了负载电压调节、无功功率补偿、电网频率调节和负载相位平衡等多重电网服务。


<details>
  <summary>Details</summary>
Motivation: 为了提高电能质量，实现高级辅助服务，并增加可再生能源接入国家电网的比例，需要结合传统变压器和部分额定功率电子转换器的混合配电变压器（HDT）。

Method: 提出了一种采用两组反并联电压源换流器的三相HDT的平均数学模型，该换流器采用串并联配置。在同步旋转的dq0参考坐标系下设计了级联PI控制器来调节负载电压、补偿无功功率、实现电网频率调节和负载相位平衡。

Result: 仿真结果表明，所设计的简单有效的控制策略能够使HDT在不增加复杂性的情况下同时提供多项电网服务。

Conclusion: 本文详细介绍了HDT的完整模型、控制架构和实现步骤，为进一步验证和推广HDT及其控制策略提供了基础。

Abstract: Hybrid distribution transformers (HDTs) integrate conventional transformers with partially rated power electronic converters to improve power quality, enable advanced ancillary services and increase penetration of renewable energy sources in the national power grid. In this paper, we present an averaged mathematical model of a three-phase HDT equipped with two back-to-back voltage source converters connected in a series-shunt configuration. Cascaded PI controllers are designed in the synchronously rotating dq0 reference frame to regulate load voltage, compensate reactive power, achieve grid frequency regulation, and perform load phase balancing. Simulation results implemented in Python confirm that these simple yet effective control mechanisms allow HDTs to offer simultaneous grid services without introducing complexity. The complete model, control architecture, and implementation steps are detailed, enabling further validation and adoption.

</details>


### [699] [Cognitive-Flexible Control via Latent Model Reorganization with Predictive Safety Guarantees](https://arxiv.org/abs/2602.00812)
*Thanana Nuchkrua,Sudchai Boonto*

Main category: eess.SY

TL;DR: 本文提出了一种认知灵活控制框架，通过在线调整潜在状态表示和安全的控制律，来应对系统动力学和感知条件突变。该框架使用认知灵活深度随机状态空间模型（CF-DeepSSSM）来实现潜在表示的自适应，并通过贝叶斯模型预测控制（MPC）保证了系统的安全性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的控制系统在面对系统动力学和感知条件发生突变时，由于其内部表示固定，性能会显著下降，无法保证安全性。因此，需要一种能够自适应变化的控制方法。

Method: 提出认知灵活控制框架，其中CF-DeepSSSM模型能够根据认知灵活性指数（CFI）在线重组潜在状态表示。然后将该自适应模型嵌入到贝叶斯MPC方案中，并保证了后验漂移、递归可行性和闭环稳定性。

Result: 仿真结果表明，在系统动力学和观测发生突变的情况下，该框架能够实现安全的表示自适应，并快速恢复性能。

Conclusion: 认知灵活控制框架能够有效应对非平稳环境下系统动力学和感知条件的突变，实现安全的学习使能控制，而非纯粹的基于学习的控制。

Abstract: Learning-enabled control systems must maintain safety when system dynamics and sensing conditions change abruptly. Although stochastic latent-state models enable uncertainty-aware control, most existing approaches rely on fixed internal representations and can degrade significantly under distributional shift. This letter proposes a \emph{cognitive-flexible control} framework in which latent belief representations adapt online, while the control law remains explicit and safety-certified. We introduce a Cognitive-Flexible Deep Stochastic State-Space Model (CF--DeepSSSM) that reorganizes latent representations subject to a bounded \emph{Cognitive Flexibility Index} (CFI), and embeds the adapted model within a Bayesian model predictive control (MPC) scheme. We establish guarantees on bounded posterior drift, recursive feasibility, and closed-loop stability. Simulation results under abrupt changes in system dynamics and observations demonstrate safe representation adaptation with rapid performance recovery, highlighting the benefits of learning-enabled, rather than learning-based, control for nonstationary cyber-physical systems.

</details>


### [700] [Robust Energy Shaping Control of an Underactuated Inverted Pendulum](https://arxiv.org/abs/2602.00905)
*M. Reza J. Harandi,Mehrzad Namvar*

Main category: eess.SY

TL;DR: 本文提出了一种新的IDA-PBC控制方法，用于稳定旋转倒立摆系统，并通过添加鲁棒项来处理未被现有IDA-PBC文献解决的扰动。


<details>
  <summary>Details</summary>
Motivation: 现有基于能量整形的方法在实际应用中受限于需要解析求解一组偏微分方程（PDE），这构成了一个重大障碍。

Method: 针对旋转倒立摆系统，推导了动能和势能PDE的简洁解析解，开发了一种互联和阻尼分配（IDA-PBC）控制方案。此外，引入了一个新的鲁棒项来补偿特定类别的扰动。

Result: 通过数值模拟验证了所提出方法的有效性，结果显示了令人满意的控制性能。

Conclusion: 所提出的IDA-PBC控制方案能够有效地稳定旋转倒立摆系统，并且通过引入鲁棒项，能够处理现有IDA-PBC方法未能解决的特定类别扰动。

Abstract: Although the stabilization of underactuated systems remains a challenging problem, the total energy shaping approach provides a general framework for addressing this objective. However, the practical implementation of this method is hindered by the need to analytically solve a set of partial differential equations (PDEs), which constitutes a major obstacle. In this paper, a rotary inverted pendulum system is considered, and an interconnection and damping assignment passivity-based control (IDA-PBC) scheme is developed by deriving concise analytical solutions to the kinetic and potential energy PDEs. Furthermore, a novel robust term is incorporated into the control law to compensate for a specific class of disturbances that has not been addressed within the existing IDA-PBC literature. The effectiveness of the proposed method is validated through numerical simulations, demonstrating satisfactory control performance.

</details>


### [701] [Reduction of Velocity-Dependent Terms in Total Energy Shaping Approach](https://arxiv.org/abs/2602.00908)
*M. Reza J. Harandi,Mehrzad Namvar*

Main category: eess.SY

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Total energy shaping through interconnection and damping assignment passivity-based control (IDA-PBC) provides a powerful and systematic framework for stabilizing underactuated mechanical systems. Despite its theoretical appeal, incorporating actuator limitations into total energy shaping remains a largely open problem, with only limited results reported in the existing literature. In practice, the closed-loop behavior of energy-shaping controllers is strongly affected by the kinetic energy shaping terms. In this paper, a simultaneous IDA-PBC (SIDA-PBC) framework is employed to systematically attenuate the kinetic energy shaping terms by exploiting generalized forces, without altering the matching partial differential equations (PDEs). The free component of the generalized forces is derived analytically via an $\ell_\infty$-norm optimization formulation. Although a reduction in kinetic energy shaping terms does not necessarily guarantee a decrease in the overall control effort, the proposed approach effectively suppresses kinetic energy shaping components and achieves a reduced control magnitude whenever such a reduction is structurally feasible. Unlike existing approaches based on gyroscopic terms, which require multiple actuators, the proposed method is applicable to mechanical systems with a single actuator. Simulation and experimental results are provided to validate the effectiveness of the proposed approach.

</details>


### [702] [Robust Adaptive Learning Control for a Class of Non-affine Nonlinear Systems](https://arxiv.org/abs/2602.00968)
*Shuai Gao,Dong Shen,Abdelhamid Tayebi*

Main category: eess.SY

TL;DR: 提出一种用于处理高相对次数、非重复任务的不确定非仿射非线性系统的鲁棒自适应学习控制方案，该方案结合了基于梯度下降的参数自适应律和状态估计器，并提供了明确的迭代计算方法。


<details>
  <summary>Details</summary>
Motivation: 解决具有未知时变参数、高相对次数和非仿射特性的不确定非线性系统的跟踪问题，以及这些系统难以实现的问题。

Method: 提出一种鲁棒自适应学习控制方案，采用基于梯度下降的参数自适应律处理未知时变参数，并使用状态估计器处理不可测状态变量。此外，还提供了一种显式的迭代计算方法来实现控制方案。

Result: 所提出的控制方案被证明是严格有效的，并且仿真结果证实了其有效性。

Conclusion: 该研究提出了一种用于解决复杂不确定非线性系统跟踪问题的可行且有效的控制方案，该方案具有理论鲁棒性和实际可操作性。

Abstract: We address the tracking problem for a class of uncertain non-affine nonlinear systems with high relative degrees, performing non-repetitive tasks. We propose a rigorously proven, robust adaptive learning control scheme that relies on a gradient descent parameter adaptation law to handle the unknown time-varying parameters of the system, along with a state estimator that estimates the unmeasurable state variables. Furthermore, despite the inherently complex nature of the non-affine system, we provide an explicit iterative computation method to facilitate the implementation of the proposed control scheme. The paper includes a thorough analysis of the performance of the proposed control strategy, and simulation results are presented to demonstrate the effectiveness of the approach.

</details>


### [703] [Mitigating Data Centers Load Risks and Enabling Grid Support Functions through Grid-Forming Control](https://arxiv.org/abs/2602.01013)
*Yousef Abudyak,Mohsen Alizadeh,Wei Sun*

Main category: eess.SY

TL;DR: 本文提出了一种在数据中心集成使用并网逆变器的电池储能系统（BESS）的架构，以应对AI工作负载带来的电网波动，并提供电网支持。


<details>
  <summary>Details</summary>
Motivation: 大规模数据中心（尤其是在AI和LLM工作负载下）的快速增长导致电力系统面临挑战，包括功率的急剧变化以及数据中心作为无源负载而不提供电网支持的问题。

Method: 文章提出了一种集成架构，将并网逆变器控制的电池储能系统（BESS）集成到数据中心。通过MATLAB/Simulink进行仿真，模拟了在动态负载、电压骤降和电网断开等场景下BESS的性能。

Result: 仿真结果表明，所提出的BESS架构能够精确跟踪功率参考，并在模型训练和保存期间提供瞬时功率。在电压骤降情况下，BESS能提供类似STATCOM的无功功率支持。在电网断开时，能够实现无缝的孤岛运行，保持稳定的电压、频率和连续的电力供应。

Conclusion: 集成并网逆变器的BESS架构能够有效解决AI工作负载引起的数据中心功率波动问题，并能为电网提供主动支持，包括动态功率补偿、无功功率补偿以及在电网故障时的孤岛运行能力。

Abstract: The rapid growth of hyperscale data centers driven by Large Language Models and Artificial Intelligence workloads has introduced new challenges for power systems. These facilities experience abrupt power variations during model training and check-point-saving events, causing voltage deviations and frequency disturbances. Moreover, they operate as passive loads that draw power without offering any grid support. This paper presents an integrated architecture that combines Battery Energy Storage Systems (BESSs) within data centers using Grid-Forming inverters to provide active grid-support functions. Simulation results through MATLAB/Simulink demonstrate accurate power reference tracking under dynamic loading, with eight coordinated BESS units supplying instantaneous power during training and saving conditions. Under single-phase voltage depression near the data center bus, the BESS delivered reactive power support similar to a Static Synchronous Compensator. During grid disconnection, seamless islanded operation was achieved with stable voltage, frequency, and continuous power delivery at the data center bus.

</details>


### [704] [Scientific Machine Learning for Resilient EV-Grid Planning and Decision Support Under Extreme Events](https://arxiv.org/abs/2602.01261)
*Yifan Wang*

Main category: eess.SY

TL;DR: 该研究提出了一种五阶段的科学机器学习框架，通过物理信息知识迁移来解决电动汽车充电基础设施给城市配电网带来的挑战，特别是在极端需求事件下。该框架能够减小微观充电物理学与城市规模规划之间的尺度差距，提高了极端情况下的模型准确性和城市电网的弹性评估。


<details>
  <summary>Details</summary>
Motivation: 现有城市规模的电动汽车充电基础设施弹性评估模型在处理极端需求事件时，由于微观充电物理学和城市规模规划之间的尺度差距，无法准确反映分钟级输电约束，导致数据驱动模型出现非物理行为。因此，需要一种方法来弥合这种尺度差距，提高弹性评估的准确性。

Method: 研究开发了一个五阶段的科学机器学习框架：1. 利用瑞士直流快充遥测数据和单调性约束学习温度-压力输送曲面；2. 通过锚定分位数映射进行跨尺度注入；3. 部署双头时空图神经网络联合预测需求和服务损失率；4. 模拟压力冲击下的积压动力学并评估政策干预；5. 通过变压器负载分析将服务结果与配电网压力耦合。该框架通过物理信息知识迁移来解决尺度差距问题。

Result: 在深圳UrbanEV数据集上的验证表明，物理信息注入恢复了单调的压力-风险响应（Spearman相关系数从-0.8提高到+1.0），并提高了预测精度。在代表性的需求冲击下，混合政策将积压减少了79.1%，在研究范围内恢复了全部服务，并将电网压力限制在额外2小时。得出的弹性边界m_crit与epsilon的关系为m_crit ≈ 1.7 - 1.0 * epsilon，提供了连接需求灵活性与最大可吸收压力的指导。

Conclusion: 该五阶段科学机器学习框架能够有效地弥合微观充电物理学与城市规模规划之间的尺度差距，通过物理信息知识迁移提高了极端需求事件下电动汽车充电基础设施的弹性评估准确性。研究提出的弹性边界方程为风险感知下的应急规划提供了可操作的指导。

Abstract: Electric vehicle (EV) charging infrastructure introduces complex challenges to urban distribution networks, particularly under extreme demand events. A critical barrier to resilience assessment is the scale gap between micro-level charging physics and city-scale planning: minute-resolution deliverability constraints remain invisible in hourly aggregated datasets, causing purely data-driven models to exhibit non-physical behavior in high-stress regimes. This paper develops a five-stage scientific machine learning framework bridging this gap through physics-informed knowledge transfer. Stage 1 learns a temperature-pressure deliverability surface from Swiss DC fast-charging telemetry with monotonicity constraints. Stage 2 performs cross-scale injection via anchored quantile mapping. Stage 3 deploys a dual-head spatio-temporal graph neural network for joint forecasting of demand and service loss rate. Stage 4 simulates backlog dynamics under stress shocks and evaluates policy interventions. Stage 5 couples service outcomes to distribution-grid stress via transformer loading analysis. Validation on the Shenzhen UrbanEV dataset demonstrates that physics injection restores monotone stress-to-risk response (Spearman correlation coefficient equals +1.0 versus -0.8 without injection) and improves forecasting accuracy. Under a representative demand shock, the hybrid policy reduces backlog by 79.1%, restores full service within the study horizon, and limits grid stress to only 2 additional hours. The derived resilience boundary m_crit as a function of epsilon approximately equals 1.7 minus 1.0 times epsilon, providing actionable guidance linking demand flexibility to maximum absorbable stress, enabling risk-aware emergency planning under extreme events.

</details>


### [705] [Optimal Sizing of Charging Energy Hubs for Heavy-Duty Electric Transport through Co-Optimization](https://arxiv.org/abs/2602.01502)
*M. Izadi,D. Fernandez Zapico,M. Salazar,T. Hofman*

Main category: eess.SY

TL;DR: 本文提出了一种混合整数线性规划模型，用于优化充电能源中心（CEH）组件的尺寸，该模型将组件尺寸和运营决策联合优化，以实现成本效益高、可扩展且符合电网要求的CEH规划。


<details>
  <summary>Details</summary>
Motivation: 重型车辆的电气化给配电网带来了巨大压力，而CEH通过整合充电基础设施、可再生能源和电池储能来缓解这些影响。因此，CEH组件的最佳尺寸是关键的投资决策，但由于设计选择严重依赖于运营动态，因此具有挑战性。

Method: 采用混合整数线性规划（MILP）模型，并使用联合设计方法，同时优化组件尺寸和运营决策。

Result: 通过重型车队的案例研究，证明了该方法在成本效益高、可扩展且符合电网要求的CEH规划方面的有效性。

Conclusion: 所提出的联合设计方法能够有效地解决CEH组件最优尺寸问题，并为实际的CEH规划提供支持。

Abstract: Electrification of heavy-duty vehicles places substantial stress on distribution grids, and Charging Energy Hubs (CEHs) mitigate these impacts by integrating charging infrastructure with renewable energy sources and battery storage. Optimal sizing of CEH components is therefore a critical investment decision, yet challenging because design choices depend strongly on operational dynamics. This work presents a mixed-integer linear programming model for the optimal sizing of CEH components, using a co-design approach that jointly optimizes component sizing and operational decisions. A case study for a heavy-duty fleet demonstrates the effectiveness of the method for cost-efficient, scalable, and grid-compliant CEH planning.

</details>


### [706] [Harnessing Flexible Spatial and Temporal Data Center Workloads for Grid Regulation Services](https://arxiv.org/abs/2602.01508)
*Yingrui Fan,Junbo Zhao*

Main category: eess.SY

TL;DR: 提出了一种统一的日前协同优化框架，通过联合优化分布式数据中心的功 workload 分配和电网频率调节容量的承诺，以解决现有方法中 workload 调度和频率调节分散优化导致的可行性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的数据中心功 workload 调度和频率调节容量承诺方法通常是分开处理的，这忽视了队列动力学和时空调度决策对维持实时频率调节能力的影响，可能导致承诺的调节容量不可行或持续时间短。

Method: 提出了一种统一的日前协同优化框架，该框架利用时空网络模型来捕捉 workload 迁移成本、延迟要求和异构资源限制。为了确保所承诺的频率调节容量能够实现，引入了基于交互式负荷预测的瞬时功率灵活性机会约束，以及风险价值（Value-at-Risk）队列状态约束，以在累积频率调节信号下保持可持续响应。

Result: 通过在改进的 IEEE 68 总线系统上使用真实数据中心 traces 进行案例研究，结果表明，所提出的协同优化框架降低了系统运行成本，提供了更多可行的频率调节容量，并与独立优化调度和调节的策略相比，实现了更好的收入-风险权衡。

Conclusion: 联合优化数据中心的 workload 分配和频率调节容量承诺是一个有效的方法，可以解决单独优化带来的可行性和可持续性问题，从而提高数据中心支持电网频率调节的能力，并带来经济效益。

Abstract: Data centers (DCs) are increasingly recognized as flexible loads that can support grid frequency regulation. Yet, most existing methods treat workload scheduling and regulation capacity bidding separately, overlooking how queueing dynamics and spatial-temporal dispatch decisions affect the ability to sustain real-time regulation. As a result, the committed regulation may become infeasible or short-lived. To address this issue, we propose a unified day-ahead co-optimization framework that jointly decides workload distribution across geographically distributed DCs and regulation capacity commitments. We construct a space-time network model to capture workload migration costs, latency requirements, and heterogeneous resource limits. To ensure that the committed regulation remains deliverable, we introduce chance constraints on instantaneous power flexibility based on interactive load forecasts, and apply Value-at-Risk queue-state constraints to maintain sustainable response under cumulative regulation signals. Case studies on a modified IEEE 68-bus system using real data center traces show that the proposed framework lowers system operating costs, enables more viable regulation capacity, and achieves better revenue-risk trade-offs compared to strategies that optimize scheduling and regulation independently.

</details>


### [707] [Hybrid Control Technique for Switched LPV Systems and Its Application to Active Magnetic Bearing System](https://arxiv.org/abs/2602.01524)
*Fen Wu*

Main category: eess.SY

TL;DR: 提出了一种用于具有滞后切换逻辑的切换 LPV 系统的混合控制框架，通过引入控制器状态重置机制，将问题转化为 LMI 形式的凸优化问题，并成功应用于主动磁悬浮轴承系统。


<details>
  <summary>Details</summary>
Motivation: 传统的 LPV 控制器设计在处理参数变化率较大的系统（如主动磁悬浮轴承随转速变化）时，由于保守性而效果不佳。需要一种更有效的控制方法来处理参数变化和切换逻辑。

Method: 提出了一种混合 LPV 控制框架，核心是引入控制器状态重置机制。这使得混合 LPV 合成问题可以转化为基于线性矩阵不等式（LMIs）的凸优化问题，从而可以计算切换 LPV 控制器增益和重置矩阵。该方法应用于主动磁悬浮轴承系统，利用滞后切换减少抖振，并明确考虑参数变化率的界限。

Result: 通过将混合 LPV 合成问题转化为 LMI 形式的凸优化问题，成功计算出了控制器增益和重置矩阵。该方法能够有效地处理主动磁悬浮轴承系统中的参数变化，并通过滞后切换减少了抖振，保证了稳定性。

Conclusion: 提出的混合控制框架能够有效地解决具有滞后切换逻辑的切换 LPV 系统的控制问题，并通过状态重置和 LMI 优化实现了高效的控制器设计。该方法在主动磁悬浮轴承系统的控制中表现出良好的性能，克服了传统 LPV 控制器在参数变化率较大时的保守性问题。

Abstract: This paper proposes a novel hybrid control framework for switched linear parameter-varying (LPV) systems under hysteresis switching logic. By introducing a controller state-reset mechanism, the hybrid LPV synthesis problem is reformulated as a convex optimization problem expressed in terms of linear matrix inequalities (LMIs), enabling efficient computation of both switching LPV controller gains and reset matrices. The proposed approach is then applied to active magnetic bearing (AMB) systems, whose rotor dynamics exhibit strong dependence on rotational speed. Conventional LPV designs are often conservative due to large speed variations. The proposed hybrid gain-scheduled controller explicitly accounts for bounds on parameter variation rates, employs multiple LPV controllers over distinct operating regions, and uses hysteresis switching to reduce chattering and ensure stability. The effectiveness of the approach is demonstrated through a detailed AMB control design example.

</details>


### [708] [LMI Optimization Based Multirate Steady-State Kalman Filter Design](https://arxiv.org/abs/2602.01537)
*Hiroshi Okajima*

Main category: eess.SY

TL;DR: 本文提出了一种基于LMI的多速率稳态卡尔曼滤波器设计框架，用于处理不同采样率的传感器。该框架通过周期性重构转化为时不变问题，并使用LMI优化和对偶LQR方法处理半负定的测量噪声协方差。该框架支持极点配置和混合H_2/l_2诱导范数设计，以实现收敛速率和性能的平衡。通过汽车导航系统验证，所提出的滤波器显著优于原始测量噪声。


<details>
  <summary>Details</summary>
Motivation: 现有卡尔曼滤波器设计方法难以处理多速率系统（传感器采样率不同）以及需要同时考虑收敛速度和鲁棒性等多个设计目标的情况。

Method: 将多速率系统建模为周期性时变系统，通过周期性重构转化为时不变问题。利用LMI优化和对偶LQR方法处理半负定的测量噪声协方差。引入极点配置和混合H_2/l_2诱导范数设计来实现多目标优化。

Result: 所提出的LMI框架能够自然处理半负定的测量噪声协方差，并支持多速率稳态卡尔曼滤波器的设计。该滤波器能够通过极点配置保证收敛速率，并通过混合H_2/l_2诱导范数平衡平均和最坏情况下的性能。通过汽车导航系统的数值验证表明，该滤波器能够实现远低于原始测量噪声水平的估计误差。

Conclusion: 本文成功提出了一种基于LMI的多速率稳态卡尔曼滤波器设计框架，该框架能够有效地处理多速率传感器系统，并支持多目标设计，如收敛速率和性能平衡。该方法在实际应用中（如汽车导航）显示出优越的性能。

Abstract: This paper presents an LMI-based design framework for multirate steady-state Kalman filters in systems with sensors operating at different sampling rates. The multirate system is formulated as a periodic time-varying system, where the Kalman gains converge to periodic steady-state values that repeat every frame period. Cyclic reformulation transforms this into a time-invariant problem; however, the resulting measurement noise covariance becomes semidefinite rather than positive definite, preventing direct application of standard Riccati equation methods. We address this through a dual LQR formulation with LMI optimization that naturally handles semidefinite covariances. The framework enables multi-objective design, supporting pole placement for guaranteed convergence rates and mixed H_2/l_2-induced norm design for balancing average and worst-case performance. Numerical validation using an automotive navigation system with GPS and wheel speed sensors demonstrates that the proposed filter achieves estimation errors well below raw measurement noise levels.

</details>


### [709] [Fostering Data Collaboration in Digital Transportation Marketplaces: The Role of Privacy-Preserving Mechanisms](https://arxiv.org/abs/2602.01804)
*Qiqing Wang,Haokun Yu,Kaidi Yang*

Main category: eess.SY

TL;DR: 研究了在交通领域，市政当局（MA）和出行服务商（MP）之间数据协作时，隐私保护机制如何促进数据共享。提出了一种博弈论框架，并发现降低数据质量预期可以鼓励数据共享，从而提高双方的福利。


<details>
  <summary>Details</summary>
Motivation: 虽然数据协作给交通系统带来了巨大好处，但用户的隐私担忧和数据所有者（MA和MP）可能不愿意共享数据，因为担心敏感信息泄露。这项研究旨在探讨隐私保护机制如何解决这些问题，以促进数据协作。

Method: 使用了博弈论框架来研究交通利益相关者之间的数据共享问题，特别是考虑了基于扰动（perturbation-based）的隐私保护机制。通过数值研究来验证理论分析。

Result: 研究表明，降低对数据质量的预期可以激励双方进行自愿的数据共享。这种自愿共享能够提高交通相关的整体福利，使MA和MP都能受益。

Conclusion: 隐私保护技术可以帮助打破数据孤岛，促进协作和注重隐私的交通系统。政策制定者和系统设计者可以通过调整数据质量预期来鼓励数据共享，从而实现更优的交通系统。

Abstract: Data collaboration between municipal authorities (MA) and mobility providers (MPs) has brought tremendous benefits to transportation systems in the era of big data. Engaging in collaboration can improve the service operations (e.g., reduced delay) of these data owners, however, it can also raise privacy concerns and discourage data-sharing willingness. Specifically, data owners may be concerned that the shared data may leak sensitive information about their customers' mobility patterns or business secrets, resulting in the failure of collaboration. This paper investigates how privacy-preserving mechanisms can foster data collaboration in such settings. We propose a game-theoretic framework to investigate data-sharing among transportation stakeholders, especially considering perturbation-based privacy-preserving mechanisms. Numerical studies demonstrate that lower data quality expectations can incentivize voluntary data sharing, improving transport-related welfare for both MAs and MPs. Our findings provide actionable insights for policymakers and system designers on how privacy-preserving technologies can help bridge data silos and promote collaborative, privacy-aware transportation systems.

</details>


### [710] [Super-twisting over networks: A Lyapunov approach for distributed differentiation](https://arxiv.org/abs/2602.01857)
*Rodrigo Aldana-López,Irene Perez Salesa,David Gomez Gutierrez,Rosario Aragues,Carlos Sagues*

Main category: eess.SY

TL;DR: 该论文提出了一种新的分布式微分器，用于在网络系统中估计局部信号及其导数的平均值。该方法使用Lyapunov函数保证了全局有限时间收敛，并通过事件触发机制减少了通信。


<details>
  <summary>Details</summary>
Motivation: 现有滑动模式方法在分布式微分方面存在局部稳定性保证和缺乏系统性增益选择的问题。

Method: 文章通过将超级扭曲算法的结构特征抽象化，构建了一个Lyapunov函数，从而实现了系统增益的设计，并证明了分布式微分器的全局有限时间收敛性。在此基础上，开发了一种基于事件触发的混合系统实现，并推导了最小事件间隔时间和精度界限。

Result: 提出的分布式微分器能够实现全局有限时间收敛到共识。事件触发机制在估计精度和通信开销之间取得了权衡，并提供了相应的精度界限和通信开销保证。

Conclusion: 该研究成功地设计了一种具有全局有限时间收敛和系统性增益设计的分布式微分器，并通过事件触发机制有效降低了通信开销，克服了现有方法的局限性。

Abstract: We study distributed differentiation, where agents in a networked system estimate the average of local time-varying signals and their derivatives under mild assumptions on the agents' signals and their first and second derivatives. Existing sliding-mode methods provide only local stability guarantees and lack systematic gain selection. By isolating the structural features shared with the super-twisting algorithm and encoding them into an abstract model, we construct a Lyapunov function enabling systematic gain design and proving global finite-time convergence to consensus for the distributed differentiator. Building on this framework, we develop an event-triggered hybrid system implementation using time-varying and state dependent threshold rules and derive minimum inter-event time guarantees and accuracy bounds that quantify the trade-off between estimation accuracy and communication effort.

</details>


### [711] [An Efficient Power Management Unit With Continuous MPPT and Energy Recycling for Wireless Millimetric Biomedical Implants](https://arxiv.org/abs/2602.02376)
*Yiwei Zou,Huan-Cheng Liao,Wei Wang,Wonjune Kim,Yumin Su,Jacob T. Robinson,Kaiyuan Yang*

Main category: eess.SY

TL;DR: 本文提出了一种用于毫米级植入物的全集成磁电无线能量传输（ME WPT）电源管理单元（PMU），实现了高效的最大功率点跟踪（MPPT）和自适应高压充电。


<details>
  <summary>Details</summary>
Motivation: 传统的生物医学植入物因电池体积大且需要手术更换，限制了其微创和小型化。无线能量传输（WPT）是替代方案，特别是超声和磁电WPT，适用于毫米级接收器。

Method: 提出了一种全集成PMU，通过连续匹配换能器阻抗、动态优化功率级和能量再利用来管理ME WPT。采用偏斜占空比MPPT技术和效率优化器。设计了并联输入稳压和存储级架构，以及自适应高压充电级。

Result: PMU实现了98.5%的峰值MPPT效率和73.33%的峰值系统整体效率。自适应高压充电级可将充电电容升至12V，效率达37.88%。

Conclusion: 所提出的PMU能够实现高效、负载独立的能量提取和利用，为实现微创、小型化毫米级植入物提供了关键技术支持。

Abstract: Biomedical implants offer transformative tools to improve medical outcomes. To realize minimally invasive implants with miniaturized volume and weight, wireless power transfer has been extensively studied to replace bulky batteries that dominate the volume of traditional implants and require surgical replacements. Ultra-sonic and magnetoelectric WPT modalities, which leverage low frequency acoustic electrical coupling for energy transduction, become viable solutions for mm-scale receivers. This work presents a fully integrated power management unit for ME WPT in millimetric implants. The PMU achieves load independent maximum power extraction and usage by continuously matching the impedance of the transducer, dynamically optimizing the power stage across varying input divided by load conditions, and reusing the storage energy to sustain the system when input power drops. Its parallel-input regulation and storing stages architecture prevent the cascading power loss. With the skewed-duty-cycle MPPT technique and regulation efficiency optimizer, the PMU achieves a peak MPPT efficiency of 98.5 percent and a peak system overall efficiency of 73.33 percent. Additionally, the PMU includes an adaptive high-voltage charging stage that charges the stimulation capacitor up to 12 V with an improved efficiency of 37.88 percent.

</details>


### [712] [Robust Safety-Critical Control of Networked SIR Dynamics](https://arxiv.org/abs/2602.02452)
*Saba Samadi,Brooks A. Butler,Philip E. Paré*

Main category: eess.SY

TL;DR: 本文提出了一种基于控制障碍函数（CBF）的鲁棒安全关键控制框架，用于解决网络化 SIR 流行病动力学模型中的感染传播与缓解问题，并考虑了不确定性。


<details>
  <summary>Details</summary>
Motivation: 网络化 SIR 模型中，各节点需要将其感染水平保持在临界阈值以下，以确保公共卫生安全，同时要应对节点间的动态交互以及流行病参数和测量误差的不确定性。

Method: 首先推导出基于 CBF 的控制器以保证标称情况下的安全。然后，通过引入补偿项来处理不确定性：一种适用于均匀不确定性的独立方法，以及一种新颖的、与状态相关的、以捕捉早期或抑制爆发阶段相对噪声增加的方法。

Result: 仿真结果表明，标称 CBF 控制器在低不确定性下能保持安全。鲁棒方法在高不确定性下提供了形式化的安全保证。新颖的方法通过更保守的控制努力提供更大的安全裕度，而独立方法通过允许感染水平在稳定流行阶段接近边界来优化资源分配。

Conclusion: 提出的鲁棒 CBF 控制框架能够有效地管理网络化 SIR 模型中的流行病传播，并提供形式化的安全保证，尤其是在存在不确定性的情况下。

Abstract: We present a robust safety-critical control framework tailored for networked susceptible-infected-recovered (SIR) epidemic dynamics, leveraging control barrier functions (CBFs) and robust control barrier functions to address the challenges of epidemic spread and mitigation. In our networked SIR model, each node must keep its infection level below a critical threshold, despite dynamic interactions with neighboring nodes and inherent uncertainties in the epidemic parameters and measurement errors, to ensure public health safety. We first derive a CBF-based controller that guarantees infection thresholds are not exceeded in the nominal case. We enhance the framework to handle realistic epidemic scenarios under uncertainties by incorporating compensation terms that reinforce safety against uncertainties: an independent method with constant bounds for uniform uncertainty, and a novel approach that scales with the state to capture increased relative noise in early or suppressed outbreak stages. Simulation results on a networked SIR system illustrate that the nominal CBF controller maintains safety under low uncertainty, while the robust approaches provide formal safety guarantees under higher uncertainties; in particular, the novel method employs more conservative control efforts to provide larger safety margins, whereas the independent approach optimizes resource allocation by allowing infection levels to approach the boundaries in steady epidemic regimes.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [713] [Toward a Unified Semantic Loss Model for Deep JSCC-based Transmission of EO Imagery](https://arxiv.org/abs/2602.00136)
*Ti Ti Nguyen,Thanh-Dung Le,Vu Nguyen Ha,Duc-Dung Tran,Hung Nguyen-Kha,Dinh-Hieu Tran,Carlos L. Marcos-Rojas,Juan C. Merlano-Duncan,Symeon Chatzinotas*

Main category: eess.IV

TL;DR: 本文提出了一种深度联合信源信道编码（DJSCC）框架，用于在带宽受限的卫星通信中传输高分辨率地球观测（EO）影像。该框架通过统一的语义损失函数，兼顾了图像重建质量和下游任务的准确性，为资源受限的EO影像传输提供了优化方案。


<details>
  <summary>Details</summary>
Motivation: 高分辨率EO影像在环境监测、灾害响应等关键应用中至关重要，但其庞大的数据量对带宽、功耗受限的卫星通信系统提出了严峻挑战。

Method: 研究了两种DJSCC的语义损失方面：1）重建中心框架，评估不同压缩比和信噪比（SNR）下重建图像的语义退化；2）任务导向框架，将DJSCC与轻量级应用模型（如EfficientViT）集成，以任务准确性为度量。最终提出了一个统一的语义损失框架，整合了上述两种方法。

Result: 通过广泛的实证分析，所提出的统一语义损失框架能够同时捕捉重建中心和任务导向的性能，并揭示了JSCC压缩、信噪比和语义质量之间的隐性关系。

Conclusion: 该研究提出的统一语义损失框架为在资源受限的卫星链路上传输EO影像提供了有效的途径，能够设计出更鲁棒、高效的传输系统。

Abstract: Modern Earth Observation (EO) systems increasingly rely on high-resolution imagery to support critical applications such as environmental monitoring, disaster response, and land-use analysis. Although these applications benefit from detailed visual data, the resulting data volumes impose significant challenges on satellite communication systems constrained by limited bandwidth, power, and dynamic link conditions. To address these limitations, this paper investigates Deep Joint Source-Channel Coding (DJSCC) as an effective source-channel paradigm for the transmission of EO imagery. We focus on two complementary aspects of semantic loss in DJSCC-based systems. First, a reconstruction-centric framework is evaluated by analyzing the semantic degradation of reconstructed images under varying compression ratios and channel signal-to-noise ratios (SNR). Second, a task-oriented framework is developed by integrating DJSCC with lightweight, application-specific models (e.g., EfficientViT), with performance measured using downstream task accuracy rather than pixel-level fidelity. Based on extensive empirical analysis, we propose a unified semantic loss framework that captures both reconstruction-centric and task-oriented performance within a single model. This framework characterizes the implicit relationship between JSCC compression, channel SNR, and semantic quality, offering actionable insights for the design of robust and efficient EO imagery transmission under resource-constrained satellite links.

</details>


### [714] [Visible Singularities Guided Correlation Network for Limited-Angle CT Reconstruction](https://arxiv.org/abs/2602.00184)
*Yiyang Wen,Liu Shi,Zekun Zhou,WenZhe Shan,Qiegen Liu*

Main category: eess.IV

TL;DR: 提出了一种名为VSGC的可见奇点引导相关网络，用于解决有限角度CT（LACT）重建中的伪影和信息丢失问题，并在模拟和真实数据上均取得了比现有方法更好的结果，尤其是在小角度范围内。


<details>
  <summary>Details</summary>
Motivation: 传统的LACT重建算法存在局限性，现有的深度学习方法未能充分利用LACT图像的方向性伪影和结构信息丢失等核心成像特性。

Method: 提出VSGC网络，首先提取LACT图像的可见奇点（VS）边缘特征并关注这些区域，然后建立VS边缘特征与其他图像区域之间的相关性。同时，采用多尺度损失函数和各向异性约束来优化模型。

Result: 在模拟和真实数据集上，VSGC在小角度范围内显示出更优越的性能，PSNR提高了2.45 dB，SSIM提高了1.5%。

Conclusion: VSGC网络能够有效地解决LACT重建中的核心成像问题，并超越现有方法，在实际应用中具有可行性。

Abstract: Limited-angle computed tomography (LACT) offers the advantages of reduced radiation dose and shortened scanning time. Traditional reconstruction algorithms exhibit various inherent limitations in LACT. Currently, most deep learning-based LACT reconstruction methods focus on multi-domain fusion or the introduction of generic priors, failing to fully align with the core imaging characteristics of LACT-such as the directionality of artifacts and directional loss of structural information, which are caused by the absence of projection angles in certain directions. Inspired by the theory of visible and invisible singularities, taking into account the aforementioned core imaging characteristics of LACT, we propose a Visible Singularities Guided Correlation network for LACT reconstruction (VSGC). The design philosophy of VSGC consists of two core steps: First, extract VS edge features from LACT images and focus the model's attention on these VS. Second, establish correlations between the VS edge features and other regions of the image. Additionally, a multi-scale loss function with anisotropic constraint is employed to constrain the model to converge in multiple aspects. Finally, qualitative and quantitative validations are conducted on both simulated and real datasets to verify the effectiveness and feasibility of the proposed design. Particularly, in comparison with alternative methods, VSGC delivers more prominent performance in small angular ranges, with the PSNR improvement of 2.45 dB and the SSIM enhancement of 1.5\%. The code is publicly available at https://github.com/yqx7150/VSGC.

</details>


### [715] [SurfelSoup: Learned Point Cloud Geometry Compression With a Probablistic SurfelTree Representation](https://arxiv.org/abs/2602.00186)
*Tingyu Fan,Ran Gong,Yueyu Hu,Yao Wang*

Main category: eess.IV

TL;DR: SurfelSoup 是一种端到端的学习框架，利用基于表面的原语（pSurfels）进行点云几何压缩，通过构建 pSurfelTree 并使用 Tree Decision 模块自适应地选择表面粒度，实现了比现有方法更好的压缩性能和视觉效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在点云几何压缩方面存在冗余，尤其是在平滑区域，并且可能导致表面重建不光滑、不连贯。研究旨在提出一种更高效、能生成更平滑表面重建的几何压缩方法。

Method: 提出了一种名为 pSurfel 的概率表面表示，使用有界广义高斯分布对局部点占据进行建模。将 pSurfels 组织成一个类似八叉树的层次结构 pSurfelTree。引入 Tree Decision 模块自适应地决定树的细分，以实现速率-失真最优的 Surfel 粒度选择。

Result: 在 MPEG 通用测试条件下，SurfelSoup 在几何压缩方面始终优于基于体素的基线方法和 MPEG 标准 G-PCC-GesTM-TriSoup。同时，它提供了视觉上更优越的重建，具有光滑连贯的表面结构。

Conclusion: SurfelSoup 是一种有效的端到端学习表面几何压缩框架，通过概率表面表示和自适应树结构，在压缩率和重建质量上均取得了显著提升，并克服了现有方法的局限性。

Abstract: This paper presents SurfelSoup, an end-to-end learned surface-based framework for point cloud geometry compression, with surface-structured primitives for representation. It proposes a probabilistic surface representation, pSurfel, which models local point occupancies using a bounded generalized Gaussian distribution. In addition, the pSurfels are organized into an octree-like hierarchy, pSurfelTree, with a Tree Decision module that adaptively terminates the tree subdivision for rate-distortion optimal Surfel granularity selection. This formulation avoids redundant point-wise compression in smooth regions and produces compact yet smooth surface reconstructions. Experimental results under the MPEG common test condition show consistent gain on geometry compression over voxel-based baselines and MPEG standard G-PCC-GesTM-TriSoup, while providing visually superior reconstructions with smooth and coherent surface structures.

</details>


### [716] [Frequent Pattern Mining approach to Image Compression](https://arxiv.org/abs/2602.00100)
*Avinash Kadimisetty,C. Oswald,B. Sivalselvan*

Main category: eess.IV

TL;DR: 本文提出了一种基于频繁模式挖掘（FPM）的图像压缩新方法，通过像素聚类和改进的序列模式挖掘算法，显著提高了压缩率（45%），同时保持了视觉质量。


<details>
  <summary>Details</summary>
Motivation: 传统的JPEG图像压缩方法在处理图像冗余数据方面存在效率问题。作者希望通过引入频繁模式挖掘技术来改进压缩机制，以期达到更高的压缩率。

Method: 该方法结合了k-means聚类和改进的闭合频繁序列模式挖掘（GSP）。首先，将相似像素进行聚类，并使用聚类标识符进行编码。然后，用聚类和序列模式挖掘替代JPEG的DCT阶段，并通过剪枝技术优化编码模式的基数。最后，通过计算序列频率来减小代码表大小。

Result: 在基准数据集上的测试表明，该方法比现有技术提高了45%的压缩比。同时，PSNR和SSIM等图像质量指标显示，视觉质量损失可忽略不计。

Conclusion: 基于频繁模式挖掘的图像压缩方法能够有效处理图像冗余，实现高压缩率，且对图像视觉质量影响很小，优于现有的一些替代方案。

Abstract: The paper focuses on Image Compression, explaining efficient approaches based on Frequent Pattern Mining(FPM). The proposed compression mechanism is based on clustering similar pixels in the image and thus using cluster identifiers in image compression. Redundant data in the image is effectively handled by replacing the DCT phase of conventional JPEG through a mixture of k-means Clustering and Closed Frequent Sequence Mining. To optimize the cardinality of pattern(s) in encoding, efficient pruning techniques have been used through the refinement of Conventional Generalized Sequential Pattern Mining(GSP) algorithm. We have proposed a mechanism for finding the frequency of a sequence which will yield significant reduction in the code table size. The algorithm is tested by compressing benchmark datasets yielding an improvement of 45% in compression ratios, often outperforming the existing alternatives. PSNR and SSIM, which are the image quality metrics, have been tested which show a negligible loss in visual quality.

</details>


### [717] [Radiomics in Medical Imaging: Methods, Applications, and Challenges](https://arxiv.org/abs/2602.00102)
*Fnu Neha,Deepak kumar Shukla*

Main category: eess.IV

TL;DR: 本文对放射组学进行了端到端的全面分析，重点关注了从图像采集到临床部署的各个环节，并探讨了设计选择如何影响特征稳定性、模型可靠性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的放射组学研究面临特征不稳定性、可重复性差、验证偏差和临床转化受限等挑战，而现有综述多侧重于特定应用或独立流程组件，缺乏对跨环节相互依赖的设计选择如何影响稳健性和泛化能力的系统性分析。

Method: 本研究对放射组学流程的每个阶段进行了端到端的分析，包括特征提取、选择和降维策略；经典的机器学习和深度学习建模方法；以及集成和混合框架。重点关注了验证协议、数据泄露预防和统计可靠性。此外，还讨论了临床应用，并着重于评估的严谨性而非报告的性能指标。

Result: 该调查分析了不同方法学选择对特征稳定性、模型可靠性和转化有效性的影响，并讨论了在标准化、领域迁移和临床部署方面的开放性挑战。

Conclusion: 放射组学研究需要更全面的视角来解决其面临的挑战。未来的研究方向包括混合放射组学-人工智能模型、多模态融合、联邦学习和标准化基准测试，以提高放射组学的稳健性和临床应用价值。

Abstract: Radiomics enables quantitative medical image analysis by converting imaging data into structured, high-dimensional feature representations for predictive modeling. Despite methodological developments and encouraging retrospective results, radiomics continue to face persistent challenges related to feature instability, limited reproducibility, validation bias, and restricted clinical translation. Existing reviews largely focus on application-specific outcomes or isolated pipeline components, with limited analysis of how interdependent design choices across acquisition, preprocessing, feature engineering, modeling, and evaluation collectively affect robustness and generalizability. This survey provides an end-to-end analysis of radiomics pipelines, examining how methodological decisions at each stage influence feature stability, model reliability, and translational validity. This paper reviews radiomic feature extraction, selection, and dimensionality reduction strategies; classical machine and deep learning-based modeling approaches; and ensemble and hybrid frameworks, with emphasis on validation protocols, data leakage prevention, and statistical reliability. Clinical applications are discussed with a focus on evaluation rigor rather than reported performance metrics. The survey identifies open challenges in standardization, domain shift, and clinical deployment, and outlines future directions such as hybrid radiomics-artificial intelligence models, multimodal fusion, federated learning, and standardized benchmarking.

</details>


### [718] [SCALED : Surrogate-gradient for Codec-Aware Learning of Downsampling in ABR Streaming](https://arxiv.org/abs/2602.00198)
*Esteban Pesnel,Julien Le Tanou,Michael Ropert,Thomas Maugey,Aline Roumy*

Main category: eess.IV

TL;DR: 该论文提出了一种新的框架，能够使用真实、不可导的视频编解码器进行端到端训练，通过利用从实际压缩误差中获得的数据驱动的代理梯度，从而在训练目标和部署性能之间实现对齐，并在BD-BR（PSNR）方面取得了5.19%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的ABR视频流处理流程（如下采样、编码、传输、解码、上采样）通常是孤立优化的，导致端到端的率失真（R-D）性能不佳。尽管深度学习在联合优化ABR流程方面展现出潜力，但标准视频编解码器的不可导性阻碍了基于梯度的端到端优化。现有的可导代理模型虽然取得了进展，但仍是近似，可能无法完全捕捉标准编解码器的行为。因此，需要一种能够直接使用真实、不可导编解码器进行训练的方法。

Method: 提出了一种新的框架，通过数据驱动的代理梯度来处理标准、不可导视频编解码器，这些代理梯度是从实际压缩误差中学习得到的。这种方法使得训练目标与部署性能能够保持一致，并允许端到端训练。

Result: 与代码无关的训练方法相比，该框架在BD-BR（PSNR）方面取得了5.19%的性能提升，并且在跨越多种下采样比例的整个率失真凸包上都表现一致。

Conclusion: 通过利用实际压缩误差的数据驱动代理梯度，可以实现与真实、不可导视频编解码器的端到端训练，从而显著提高ABR视频流的率失真性能，并弥补了现有可导代理模型与真实编解码器行为之间的差距。

Abstract: The rapid growth in video consumption has introduced significant challenges to modern streaming architectures. Over-the-Top (OTT) video delivery now predominantly relies on Adaptive Bitrate (ABR) streaming, which dynamically adjusts bitrate and resolution based on client-side constraints such as display capabilities and network bandwidth. This pipeline typically involves downsampling the original high-resolution content, encoding and transmitting it, followed by decoding and upsampling on the client side. Traditionally, these processing stages have been optimized in isolation, leading to suboptimal end-to-end rate-distortion (R-D) performance. The advent of deep learning has spurred interest in jointly optimizing the ABR pipeline using learned resampling methods. However, training such systems end-to-end remains challenging due to the non-differentiable nature of standard video codecs, which obstructs gradient-based optimization. Recent works have addressed this issue using differentiable proxy models, based either on deep neural networks or hybrid coding schemes with differentiable components such as soft quantization, to approximate the codec behavior. While differentiable proxy codecs have enabled progress in compression-aware learning, they remain approximations that may not fully capture the behavior of standard, non-differentiable codecs. To our knowledge, there is no prior evidence demonstrating the inefficiencies of using standard codecs during training. In this work, we introduce a novel framework that enables end-to-end training with real, non-differentiable codecs by leveraging data-driven surrogate gradients derived from actual compression errors. It facilitates the alignment between training objectives and deployment performance. Experimental results show a 5.19\% improvement in BD-BR (PSNR) compared to codec-agnostic training approaches, consistently across the entire rate-distortion convex hull spanning multiple downsampling ratios.

</details>


### [719] [A Renderer-Enabled Framework for Computing Parameter Estimation Lower Bounds in Plenoptic Imaging Systems](https://arxiv.org/abs/2602.00215)
*Abhinav V. Sambasivan,Liam J. Coulter,Richard G. Paxman,Jarvis D. Haupt*

Main category: eess.IV

TL;DR: 该研究提出了一个信息论框架，用于评估全光成像系统中场景参数估计的理论极限，重点关注无视线信息（间接成像）的情况，并验证了该框架在实际场景中的有效性。


<details>
  <summary>Details</summary>
Motivation: 评估全光成像系统在噪声观测下场景参数估计的理论精度极限，特别是在缺乏直接视线信息的情况下。

Method: 利用计算机图形学渲染合成参数与观测之间的复杂关系（正向模型），然后计算Hammersley-Chapman-Robbins界来建立任何无偏估计器的方差下界。同时分析了渲染不精确对下界的影响，并通过实验验证了所得下界与最大似然估计器性能的对比。

Result: 提出的框架能够计算出场景参数估计的方差下界。在特定的目标定位问题中，计算出的下界在代表性场景下能反映真实的理论极限。

Conclusion: 该研究提出的信息论框架能够有效地评估全光成像系统中无视线信息场景参数估计的理论精度极限，并为实际估计器的性能提供了参考。

Abstract: This work focuses on assessing the information-theoretic limits of scene parameter estimation in plenoptic imaging systems. A general framework to compute lower bounds on the parameter estimation error from noisy plenoptic observations is presented, with a particular focus on passive indirect imaging problems, where the observations do not contain line-of-sight information about the parameter(s) of interest. Using computer graphics rendering software to synthesize the often-complicated dependence among parameter(s) of interest and observations, i.e. the forward model, the proposed framework evaluates the Hammersley-Chapman-Robbins bound to establish lower bounds on the variance of any unbiased estimator of the unknown parameters. The effects of inexact rendering of the true forward model on the computed lower bounds are also analyzed, both theoretically and via simulations. Experimental evaluations compare the computed lower bounds with the performance of the Maximum Likelihood Estimator on a canonical object localization problem, showing that the lower bounds computed via the framework proposed here are indicative of the true underlying fundamental limits in several nominally representative scenarios.

</details>


### [720] [Advanced Geometric Correction Algorithms for 3D Medical Reconstruction: Comparison of Computed Tomography and Macroscopic Imaging](https://arxiv.org/abs/2602.00220)
*Tomasz Les,Tomasz Markiewicz,Malgorzata Lorent,Miroslaw Dziekiewicz,Krzysztof Siwek*

Main category: eess.IV

TL;DR: 本文提出了一种混合两阶段配准框架，结合了最优截面匹配（OCM）和轻量级深度学习网络，用于从宏观切片重建3D肾脏解剖结构。该方法通过全局对齐初始化，然后进行局部变形精修，解决了宏观成像数据稀缺和高畸变的问题。


<details>
  <summary>Details</summary>
Motivation: 宏观成像数据稀缺且存在高畸变，导致全学习式配准方法（如 VoxelMorph）泛化能力差，无法处理大的非刚性形变。因此需要一种更鲁棒的框架来准确重建3D解剖结构。

Method: 采用两阶段混合配准框架。第一阶段，最优截面匹配（OCM）算法进行约束全局对齐（平移、旋转、均匀缩放）。第二阶段，一个轻量级深度学习网络（受 VoxelMorph 启发）预测连续切片间的残余局部形变。该框架通过分层分解配准流形，结合显式几何先验和神经网络学习能力。

Result: 在包含40个肾脏的原始数据集上进行实验，证明了该混合框架优于单阶段基线方法。该方法通过基于Hough的网格检测保持物理校准，并采用Bezier曲线进行轮廓平滑，以实现稳健的网格生成和体积估计。

Conclusion: 该混合OCM+DL框架通过解耦可解释的全局优化和数据高效的深度精炼，实现了精确、可重复且解剖学上逼真的多模态3D重建。该方法不仅适用于肾脏，也推广到其他从光学或照片横截面重建的软组织器官，有望应用于手术规划、形态学评估和医学教育。

Abstract: This paper introduces a hybrid two-stage registration framework for reconstructing three-dimensional (3D) kidney anatomy from macroscopic slices, using CT-derived models as the geometric reference standard. The approach addresses the data-scarcity and high-distortion challenges typical of macroscopic imaging, where fully learning-based registration (e.g., VoxelMorph) often fails to generalize due to limited training diversity and large nonrigid deformations that exceed the capture range of unconstrained convolutional filters. In the proposed pipeline, the Optimal Cross-section Matching (OCM) algorithm first performs constrained global alignment: translation, rotation, and uniform scaling to establish anatomically consistent slice initialization. Next, a lightweight deep-learning refinement network, inspired by VoxelMorph, predicts residual local deformations between consecutive slices. The core novelty of this architecture lies in its hierarchical decomposition of the registration manifold. This hybrid OCM+DL design integrates explicit geometric priors with the flexible learning capacity of neural networks, ensuring stable optimization and plausible deformation fields even with few training examples. Experiments on an original dataset of 40 kidneys demonstrated better results compared to single-stage baselines. The pipeline maintains physical calibration via Hough-based grid detection and employs Bezier-based contour smoothing for robust meshing and volume estimation. Although validated on kidney data, the proposed framework generalizes to other soft-tissue organs reconstructed from optical or photographic cross-sections. By decoupling interpretable global optimization from data-efficient deep refinement, the method advances the precision, reproducibility, and anatomical realism of multimodal 3D reconstructions for surgical planning, morphological assessment, and medical education.

</details>


### [721] [Benchmarking Vanilla GAN, DCGAN, and WGAN Architectures for MRI Reconstruction: A Quantitative Analysis](https://arxiv.org/abs/2602.00221)
*Humaira Mehwish,Hina Shakir,Muneeba Rashid,Asarim Aamir,Reema Qaiser Khan*

Main category: eess.IV

TL;DR: 本研究评估了Vanilla GAN、DCGAN和WGAN在MRI图像重建中的性能，使用膝盖、心脏和大脑的MRI数据集。DCGAN和WGAN在图像质量和重建准确性方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了提高MRI图像质量和诊断准确性，需要对流行的GAN模型进行性能分析，以实现精确的MRI重建。

Method: 研究人员使用了Vanilla GAN、DCGAN和WGAN三种GAN架构，并在膝盖、心脏和大脑的MRI数据集上进行了训练和评估。通过结构相似性指数（SSIM）和峰值信噪比（PSNR）来量化评估模型的性能。

Result: 在SSIM方面，Vanilla GAN为0.84，DCGAN为0.97，WGAN为0.99。在PSNR方面，Vanilla GAN为26，DCGAN为49.3，WGAN为43.5。DCGAN和WGAN在评估指标上均优于Vanilla GAN。

Conclusion: DCGAN和WGAN模型在MRI图像重建方面表现出巨大的潜力，能够提供良好的图像质量和优越的准确性。这项工作为未来混合GAN模型和临床MRI应用提供了一个可复现的基准。

Abstract: Magnetic Resonance Imaging (MRI) is a crucial imaging modality for viewing internal body structures. This research work analyses the performance of popular GAN models for accurate and precise MRI reconstruction by enhancing image quality and improving diagnostic accuracy. Three GAN architectures considered in this study are Vanilla GAN, Deep Convolutional GAN (DCGAN), and Wasserstein GAN (WGAN). They were trained and evaluated using knee, brain, and cardiac MRI datasets to assess their generalizability across body regions. While the Vanilla GAN operates on the fundamentals of the adversarial network setup, DCGAN advances image synthesis by securing the convolutional layers, giving a superior appearance to the prevalent spatial features. Training instability is resolved in WGAN through the Wasserstein distance to minimize an unstable regime, therefore, ensuring stable convergence and high-quality images. The GAN models were trained and tested using 1000 MR images of an anonymized knee, 805 images of Heart, 90 images of Brain MRI dataset. The Structural Similarity Index (SSIM) for Vanilla GAN is 0.84, DCGAN is 0.97, and WGAN is 0.99. The Peak Signal to Noise Ratio (PSNR) for Vanilla GAN is 26, DCGAN is 49.3, and WGAN is 43.5. The results were further statistically validated. This study shows that DCGAN and WGAN-based frameworks are promising in MR image reconstruction because of good image quality and superior accuracy. With the first cross-organ benchmark of baseline GANs under a common preprocessing pipeline, this work provides a reproducible benchmark for future hybrid GANs and clinical MRI applications.

</details>


### [722] [Recent Advances of End-to-End Video Coding Technologies for AVS Standard Development](https://arxiv.org/abs/2602.00483)
*Xihua Sheng,Xiongzhuang Liang,Chuanbo Tang,Zhirui Zuo,Yifan Bian,Yutao Xie,Zhuoyuan Li,Yuqi Li,Hui Xiang,Li Li,Dong Liu*

Main category: eess.IV

TL;DR: 本文介绍了AVS-EEM项目，一个旨在开发低计算复杂度、符合实际部署的端到端智能视频编码标准。该项目通过创新的模型架构、训练策略和推理优化，在严格的复杂度约束下显著提升了编码性能，最新模型已超越AVS3参考软件。


<details>
  <summary>Details</summary>
Motivation: 为了实现更高的视频压缩效率并促进智能视频编码技术的广泛应用和互操作性，AVS工作组启动了端到端智能视频编码的标准化探索，并建立了AVS-EEM项目。

Method: 本文详细介绍了AVS-EEM的开发历史，并对其关键技术框架进行了系统性介绍，包括模型架构、训练策略和推理优化。研究遵循了传统视频编码的共同测试条件，并注重低计算复杂度以满足实际部署需求。

Result: 通过两年多的迭代优化和协作，AVS-EEM的编码性能得到了显著提升。实验结果表明，其最新模型在压缩效率方面优于传统的AVS3参考软件。

Conclusion: AVS-EEM项目在严格的复杂度约束下，通过技术创新和迭代改进，取得了实质性的性能进步，朝着可部署的智能视频编码标准迈出了重要一步。

Abstract: Video coding standards are essential to enable the interoperability and widespread adoption of efficient video compression technologies. In pursuit of greater video compression efficiency, the AVS video coding working group launched the standardization exploration of end-to-end intelligent video coding, establishing the AVS End-to-End Intelligent Video Coding Exploration Model (AVS-EEM) project. A core design principle of AVS-EEM is its focus on practical deployment, featuring inherently low computational complexity and requiring strict adherence to the common test conditions of conventional video coding. This paper details the development history of AVS-EEM and provides a systematic introduction to its key technical framework, covering model architectures, training strategies, and inference optimizations. These innovations have collectively driven the project's rapid performance evolution, enabling continuous and significant gains under strict complexity constraints. Through over two years of iterative refinement and collaborative effort, the coding performance of AVS-EEM has seen substantial improvement. Experimental results demonstrate that its latest model achieves superior compression efficiency compared to the conventional AVS3 reference software, marking a significant step toward a deployable intelligent video coding standard.

</details>


### [723] [Lightweight Super Resolution-enabled Coding Model for the JPEG Pleno Learning-based Point Cloud Coding Standard](https://arxiv.org/abs/2602.00863)
*André F. R. Guarda,Nuno M. M. Rodrigues,Fernando Pereira*

Main category: eess.IV

TL;DR: 本文提出了一种轻量级的点云几何编码模型，通过在压缩域采用超分辨率模型和减少潜在通道数量，显著降低了 JPEG Pleno 点云编码标准的复杂性，参数量减少约 70%，同时实现了轻微的压缩性能提升。


<details>
  <summary>Details</summary>
Motivation: 点云数据量巨大，需要高效的编码解决方案。JPEG Pleno 学习点云编码标准虽然性能有竞争力，但复杂度较高，限制了其在资源受限环境下的广泛应用。

Method: 提出了一种新的轻量级点云几何编码模型，主要创新点包括：1. 首次在压缩域采用超分辨率模型；2. 大幅减少了潜在通道的数量。

Result: 模型参数量减少约 70%，同时在 JPEG Pleno 点云编码数据集上实现了平均轻微的压缩性能增益。

Conclusion: 该轻量级编码模型能够有效降低 JPEG Pleno 点云编码标准的复杂性，有利于其在资源受限设备上的推广应用，同时保持甚至略微提升压缩性能。

Abstract: While point cloud-based applications are gaining traction due to their ability to provide rich and immersive experiences, they critically need efficient coding solutions due to the large volume of data involved, often many millions of points per object. The JPEG Pleno Learning-based Point Cloud Coding standard, as the first learning-based coding standard for static point clouds, has set a foundational framework with very competitive compression performance regarding the relevant conventional and learning-based alternative point cloud coding solutions. This paper proposes a novel lightweight point cloud geometry coding model that significantly reduces the complexity of the standard, which is essential for the broad adoption of this coding standard, particularly in resource-constrained environments, while simultaneously achieving small average compression efficiency benefits. The novel coding model is based on the pioneering adoption of a compressed domain approach for the super-resolution model, in addition to a major reduction of the number of latent channels. A reduction of approximately 70% in the total number of model parameters is achieved while simultaneously offering slight average compression performance gains for the JPEG Pleno Point Cloud coding dataset.

</details>


### [724] [Diagnostic Impact of Cine Clips for Thyroid Nodule Assessment on Ultrasound](https://arxiv.org/abs/2602.00990)
*Jichen Yang,Brian C. Allen,Kirti Magudia,Lisa M. Ho,Chad M. Miller,Maciej A. Mazurowski,Benjamin Wildman-Tobriner*

Main category: eess.IV

TL;DR: 本研究评估了甲状腺超声检查中视频片段（cine images）对甲状腺结节评估准确性和一致性的影响，发现在加入视频片段后，诊断性能（敏感性和特异性）以及管理建议均未显著改变。


<details>
  <summary>Details</summary>
Motivation: 尽管在甲状腺超声检查中通常会结合静态图像和视频片段，但视频片段的具体效用和影响尚不明确，因此本研究旨在量化其影响。

Method: 纳入了50个良性结节和50个恶性结节，由4名专科放射科医生进行了三轮评估。第一、二轮仅评估静态图像，第三轮同时评估静态图像和视频片段。采用ACR TI-RADS系统进行评分，并与结节的恶性状态进行比较。

Result: 与仅使用静态图像相比，同时使用静态图像和视频片段进行评估时，甲状腺结节的敏感性从0.65略微提高到0.67（p>0.5），特异性从0.20提高到0.22（p>0.5），但差异均不显著。在管理建议方面，两种方法的结果相似。尽管TI-RADS评分点数使用视频片段后略有升高，但读者的特征分配一致性在各轮之间保持稳定。

Conclusion: 在甲状腺超声结节评估中加入视频片段并未显著提高诊断性能。现行不强制要求使用视频片段的指南足以支持准确的诊断。

Abstract: Background: Thyroid ultrasound is commonly performed using a combination of static images and cine clips (video recordings). However, the exact utility and impact of cine images remains unknown. This study aimed to evaluate the impact of cine imaging on accuracy and consistency of thyroid nodule assessment, using the American College of Radiology Thyroid Reporting and Data System (ACR TI-RADS). Methods: 50 benign and 50 malignant thyroid nodules with cytopathology results were included. A reader study with 4 specialty-trained radiologists was then conducted over 3 rounds, assessing only static images in the first two rounds and both static and cine images in the third round. TI-RADS scores and the consequent management recommendations were then evaluated by comparing them to the malignancy status of the nodules. Results: Mean sensitivity for malignancy detection was 0.65 for static images and 0.67 with both static and cine images (p>0.5). Specificity was 0.20 for static images and 0.22 with both static and cine images (p>0.5). Management recommendations were similar with and without cine images. Intrareader agreement on feature assignments remained consistent across all rounds, though TI-RADS point totals were slightly higher with cine images. Conclusion: The inclusion of cine imaging for thyroid nodule assessment on ultrasound did not significantly change diagnostic performance. Current practice guidelines, which do not mandate cine imaging, are sufficient for accurate diagnosis.

</details>


### [725] [Coordinate-conditioned Deconvolution for Scalable Spatially Varying High-Throughput Imaging](https://arxiv.org/abs/2602.01065)
*Qianwan Yang,Zhixiong Chen,Jiaqi Zhang,Ruipeng Guo,Guorong Hu,Lei Tian*

Main category: eess.IV

TL;DR: 提出了一种名为 SV-CoDe 的可扩展深度学习框架，用于在紧凑型宽视场荧光显微镜中校正空间变化的模糊，实现了在 6.5 毫米视场内的均匀高分辨率重建，同时模型尺寸和训练数据需求减少了 10 倍。


<details>
  <summary>Details</summary>
Motivation: 紧凑型宽视场荧光显微镜的光学像差、渐晕和传感器截断导致空间变化的模糊，同时传感器采样限制了视场和分辨率的权衡。现有的基于学习的方法由于参数数量随图像尺寸增长而难以扩展。

Method: 提出 SV-CoDe（空间变坐标条件去卷积）框架，利用坐标条件卷积使重建核在局部自适应，支持基于块的训练，从而将参数数量与视场解耦。

Result: 在模拟和实验测量中均取得了最佳图像质量，模型尺寸和训练数据需求比现有方法减少了 10 倍。网络在仅通过物理模拟训练后，能鲁棒地泛化到各种样本（珠子、脑切片、线虫）。

Conclusion: SV-CoDe 提供了一种可扩展、物理感知的解决方案，用于校正紧凑型光学系统中的空间变化模糊，并且易于扩展到更广泛的生物医学成像应用。

Abstract: Wide-field fluorescence microscopy with compact optics often suffers from spatially varying blur due to field-dependent aberrations, vignetting, and sensor truncation, while finite sensor sampling imposes an inherent trade-off between field of view (FOV) and resolution. Computational Miniaturized Mesoscope (CM2) alleviate the sampling limit by multiplexing multiple sub-views onto a single sensor, but introduce view crosstalk and a highly ill-conditioned inverse problem compounded by spatially variant point spread functions (PSFs). Prior learning-based spatially varying (SV) reconstruction methods typically rely on global SV operators with fixed input sizes, resulting in memory and training costs that scale poorly with image dimensions. We propose SV-CoDe (Spatially Varying Coordinate-conditioned Deconvolution), a scalable deep learning framework that achieves uniform, high-resolution reconstruction across a 6.5 mm FOV. Unlike conventional methods, SV-CoDe employs coordinate-conditioned convolutions to locally adapt reconstruction kernels; this enables patch-based training that decouples parameter count from FOV size. SV-CoDe achieves the best image quality in both simulated and experimental measurements while requiring 10x less model size and 10x less training data than prior baselines. Trained purely on physics-based simulations, the network robustly generalizes to bead phantoms, weakly scattering brain slices, and freely moving C. elegans. SV-CoDe offers a scalable, physics-aware solution for correcting SV blur in compact optical systems and is readily extendable to a broad range of biomedical imaging applications.

</details>


### [726] [Unified ROI-based Image Compression Paradigm with Generalized Gaussian Model](https://arxiv.org/abs/2602.01325)
*Kai Hu,Junfu Tan,Fang Xu,Ramy Samy,Yu Liu*

Main category: eess.IV

TL;DR: 本文提出了一种基于广义高斯模型（GGM）的感兴趣区域（ROI）图像压缩方法，解决了现有方法使用高斯模型导致编码性能损失的问题，并在COCO2017数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于ROI的图像压缩方法通常采用高斯模型来拟合编码后的概率分布，但这种分布具有尖峰和重尾特性，高斯模型无法准确描述，导致编码性能损失。作者希望通过更灵活的概率模型来解决这个问题。

Method: 1. 提出一个统一的率失真优化理论范式来分析ROI编码的影响。 2. 提出一种新的广义高斯模型（GGM）来灵活地建模潜在变量的分布。 3. 引入可微分函数以支持GGM的稳定优化。 4. 提出动态下界以缓解训练-测试不匹配。 5. 使用有限差分法计算GGM拟合分布后的梯度。

Result: 在COCO2017数据集上，所提出的GGM方法在ROI重建和下游任务（如分割、目标检测）方面均达到了最先进的性能。与经典概率模型相比，GGM能更精确地拟合特征分布，并获得更优的编码性能。

Conclusion: 广义高斯模型（GGM）能够更准确地描述ROI编码后的概率分布，从而提高图像压缩的性能，尤其是在ROI重建和下游任务的表现上。该方法克服了传统高斯模型的局限性，为ROI图像压缩提供了更好的解决方案。

Abstract: Region-of-Interest (ROI)-based image compression allocates bits unevenly according to the semantic importance of different regions. Such differentiated coding typically induces a sharp-peaked and heavy-tailed distribution. This distribution characteristic mathematically necessitates a probability model with adaptable shape parameters for accurate description. However, existing methods commonly use a Gaussian model to fit this distribution, resulting in a loss of coding performance. To systematically analyze the impact of this distribution on ROI coding, we develop a unified rate-distortion optimization theoretical paradigm. Building on this paradigm, we propose a novel Generalized Gaussian Model (GGM) to achieve flexible modeling of the latent variables distribution. To support stable optimization of GGM, we introduce effective differentiable functions and further propose a dynamic lower bound to alleviate train-test mismatch. Moreover, finite differences are introduced to solve the gradient computation after GGM fits the distribution. Experiments on COCO2017 demonstrate that our method achieves state-of-the-art in both ROI reconstruction and downstream tasks (e.g., Segmentation, Object Detection). Furthermore, compared to classical probability models, our GGM provides a more precise fit to feature distributions and achieves superior coding performance. The project page is at https://github.com/hukai-tju/ROIGGM.

</details>


### [727] [A texture-based framework for foundational ultrasound models](https://arxiv.org/abs/2602.01444)
*Tal Grutman,Carmel Shinar,Tali Ilovitsh*

Main category: eess.IV

TL;DR: 研究提出了一种名为 TUSA（Texture Ultrasound Semantic Analysis）的自监督学习框架，将超声图像的纹理分析作为核心，以弥合通用图像模型在超声领域的性能差距，并取得了在多种疾病检测和定量参数评估上的 SOTA 效果。


<details>
  <summary>Details</summary>
Motivation: 现有的用于自然图像的深度学习模型在超声图像上表现不佳，因为超声图像具有独特的物理特性和纹理，而现有的基础模型只是在大规模超声数据上训练，并未融入超声物理知识。因此，研究的动机是开发一种能够整合超声领域知识的学习框架。

Method: 研究提出了一种名为 TUSA（Texture Ultrasound Semantic Analysis）的自监督学习方法。该方法将超声图像的纹理分析视为一个核心问题，并利用对比学习方法从简单的 B 模式超声图像中提取领域特定的表示。模型在开源、模拟和体内数据上进行训练，并将其潜在空间与多个大型基础模型进行了比较。

Result: TUSA 模型在各种下游任务上展现出更好的泛化能力，在 COVID 检测（70%）、脊柱血肿检测（100%）和玻璃体出血检测（97%）方面取得了更高的准确率。此外，TUSA 模型与肝脏脂肪变性（r = 0.83）、射血分数（r = 0.63）和氧饱和度（r = 0.38）等定量参数的相关性更强。

Conclusion: TUSA 框架成功地将超声领域的物理特性整合到自监督学习中，通过关注纹理分析，能够从超声图像中提取更具领域特异性的特征，从而在多种临床应用中取得优于现有通用基础模型的性能，并具有良好的泛化能力。研究者已开源模型权重和训练脚本。

Abstract: Ultrasound is the most widely used medical imaging modality, yet the images it produces are fundamentally unique, arising from tissue-dependent scattering, reflection, and speed-of-sound variations that produce a constrained set of characteristic textures that differ markedly from natural-image statistics. These acoustically driven patterns make ultrasound challenging for algorithms originally designed for natural images. To bridge this gap, the field has increasingly turned to foundation models, hoping to leverage their generalization capabilities. However, these models often falter in ultrasound applications because they are not designed for ultrasound physics, they are merely trained on ultrasound data. Therefore, it is essential to integrate ultrasound-specific domain knowledge into established learning frameworks. We achieve this by reformulating self-supervised learning as a texture-analysis problem, introducing texture ultrasound semantic analysis (TUSA). Using TUSA, models learn to leverage highly scalable contrastive methods to extract true domain-specific representations directly from simple B-mode images. We train a TUSA model on a combination of open-source, simulated, and in vivo data. The latent space is compared to several larger foundation models, demonstrating that our approach gives TUSA models better generalizability for difficult downstream tasks on unique online datasets as well as a clinical eye dataset collected for this study. Our model achieves higher accuracy in detecting COVID (70%), spinal hematoma (100%) and vitreous hemorrhage (97%) and correlates more closely with quantitative parameters like liver steatosis (r = 0.83), ejection fraction (r = 0.63), and oxygen saturation (r = 0.38). We open-source the model weights and training script: https://github.com/talg2324/tusa

</details>


### [728] [MarkCleaner: High-Fidelity Watermark Removal via Imperceptible Micro-Geometric Perturbation](https://arxiv.org/abs/2602.01513)
*Xiaoxi Kong,Jieyu Yuan,Pengdi Chen,Yuanlin Zhang,Chongyi Li,Bin Li*

Main category: eess.IV

TL;DR: 研究提出了一种名为MarkCleaner的去除水印框架，该框架利用微几何扰动进行训练，能够有效去除水印并保持图像的语义内容，同时实现实时推理。


<details>
  <summary>Details</summary>
Motivation: 传统的语义水印在图像空间攻击下表现出良好的鲁棒性，但研究发现其在微几何扰动（如空间位移）下容易失效，因为这会破坏相位对齐。受此启发，研究者希望开发一种在去除水印的同时避免语义漂移的方法。

Method: MarkCleaner框架采用一种新颖的训练策略，即微几何扰动监督。它包含一个掩码引导编码器，用于学习显式的空间表示，以及一个基于2D高斯泼溅的解码器，该解码器显式参数化几何扰动并保留语义内容。

Result: 实验证明，MarkCleaner在水印去除效果和视觉保真度方面均表现优越，并且能够实现高效的实时推理。

Conclusion: MarkCleaner框架通过引入微几何扰动监督，成功解决了传统语义水印在微几何扰动下的脆弱性问题，实现了鲁棒且语义保真的水印去除。

Abstract: Semantic watermarks exhibit strong robustness against conventional image-space attacks. In this work, we show that such robustness does not survive under micro-geometric perturbations: spatial displacements can remove watermarks by breaking the phase alignment. Motivated by this observation, we introduce MarkCleaner, a watermark removal framework that avoids semantic drift caused by regeneration-based watermark removal. Specifically, MarkCleaner is trained with micro-geometry-perturbed supervision, which encourages the model to separate semantic content from strict spatial alignment and enables robust reconstruction under subtle geometric displacements. The framework adopts a mask-guided encoder that learns explicit spatial representations and a 2D Gaussian Splatting-based decoder that explicitly parameterizes geometric perturbations while preserving semantic content. Extensive experiments demonstrate that MarkCleaner achieves superior performance in both watermark removal effectiveness and visual fidelity, while enabling efficient real-time inference. Our code will be made available upon acceptance.

</details>


### [729] [Hyperspectral Image Fusion with Spectral-Band and Fusion-Scale Agnosticism](https://arxiv.org/abs/2602.01681)
*Yu-Jie Liang,Zihan Cao,Liang-Jian Deng,Yang Yang,Malu Zhang*

Main category: eess.IV

TL;DR: 提出了一种名为SSA的通用多光谱/高光谱图像融合框架，该框架通过Matryoshka Kernel（MK）和隐式神经表示（INR）实现了对光谱波段和融合尺度的无关性，从而能够适应不同传感器和空间分辨率，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型在多光谱/高光谱图像融合方面，其设计通常受限于固定的光谱波段和空间尺度，导致模型的可迁移性较差。为了解决这个问题，研究者们希望开发一个能够适应不同传感器和空间分辨率的通用融合框架。

Method: 该研究提出了一种名为SSA（Spectral-band and fusion-scale Agnosticism）的通用框架。其中，引入了一种名为Matryoshka Kernel（MK）的新型算子，使得单个模型能够适应任意数量的光谱通道。同时，SSA的骨干网络基于隐式神经表示（INR），将高光谱信号建模为一个连续函数，从而能够在任意空间分辨率下进行重建。

Result: 实验证明，SSA框架下的单一模型在多光谱/高光谱图像融合任务上取得了最先进的性能，并且能够很好地泛化到未见过的传感器和空间尺度上。

Conclusion: SSA框架通过实现光谱波段和融合尺度的无关性，成功构建了一个能够适应不同传感器和空间分辨率的通用多光谱/高光谱图像融合模型，为未来高光谱基础模型的研究铺平了道路。

Abstract: Current deep learning models for Multispectral and Hyperspectral Image Fusion (MS/HS fusion) are typically designed for fixed spectral bands and spatial scales, which limits their transferability across diverse sensors. To address this, we propose SSA, a universal framework for MS/HS fusion with spectral-band and fusion-scale agnosticism. Specifically, we introduce Matryoshka Kernel (MK), a novel operator that enables a single model to adapt to arbitrary numbers of spectral channels. Meanwhile, we build SSA upon an Implicit Neural Representation (INR) backbone that models the HS signal as a continuous function, enabling reconstruction at arbitrary spatial resolutions. Together, these two forms of agnosticism enable a single MS/HS fusion model that generalizes effectively to unseen sensors and spatial scales. Extensive experiments demonstrate that our single model achieves state-of-the-art performance while generalizing well to unseen sensors and scales, paving the way toward future HS foundation models.

</details>


### [730] [Edge-Aligned Initialization of Kernels for Steered Mixture-of-Experts](https://arxiv.org/abs/2602.02031)
*Martin Determann,Elvira Fleig*

Main category: eess.IV

TL;DR: 提出一种基于边缘的SMoE初始化方法，通过Canny边缘检测确定核位置和方向，并直接估计初始专家系数，以降低计算和内存成本，同时获得良好的重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的SMoE模型依赖于耗时且难以扩展的基于梯度的逐图像参数优化，限制了其实际应用。需要一种更高效的初始化策略来克服这些限制。

Method: 利用Canny边缘检测提取图像轮廓，以此确定核的位置和方向。提出一种独立的方法直接估计初始专家系数。

Result: 提出的边缘初始化方案显著减少了对随机优化的需求，降低了内存消耗和计算成本，并实现了良好的重建质量。

Conclusion: 基于边缘的初始化方法是一种有效且高效的SMoE初始化策略，可以克服现有方法的局限性，并有望在图像处理任务中得到更广泛的应用。

Abstract: Steered Mixture-of-Experts (SMoE) has recently emerged as a powerful framework for spatial-domain image modeling, enabling high-fidelity image representation using a remarkably small number of parameters. Its ability to steer kernel-based experts toward structural image features has led to successful applications in image compression, denoising, super-resolution, and light field processing. However, practical adoption is hindered by the reliance on gradient-based optimization to estimate model parameters on a per-image basis - a process that is computationally intensive and difficult to scale. Initialization strategies for SMoE are an essential component that directly affects convergence and reconstruction quality. In this paper, we propose a novel, edge-based initialization scheme that achieves good reconstruction qualities while reducing the need for stochastic optimization significantly. Through a method that leverages Canny edge detection to extract a sparse set of image contours, kernel positions and orientations are deterministically inferred. A separate approach enables the direct estimation of initial expert coefficients. This initialization reduces both memory consumption and computational cost.

</details>
