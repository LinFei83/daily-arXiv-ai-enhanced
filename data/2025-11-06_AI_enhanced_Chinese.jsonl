{"id": "2511.02923", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.02923", "abs": "https://arxiv.org/abs/2511.02923", "authors": ["Ivan Zvonkov", "Gabriel Tseng", "Inbal Becker-Reshef", "Hannah Kerner"], "title": "Cropland Mapping using Geospatial Embeddings", "comment": "8 pages, 11 figures", "summary": "Accurate and up-to-date land cover maps are essential for understanding land\nuse change, a key driver of climate change. Geospatial embeddings offer a more\nefficient and accessible way to map landscape features, yet their use in\nreal-world mapping applications remains underexplored. In this work, we\nevaluated the utility of geospatial embeddings for cropland mapping in Togo. We\nproduced cropland maps using embeddings from Presto and AlphaEarth. Our\nfindings show that geospatial embeddings can simplify workflows, achieve\nhigh-accuracy cropland classification and ultimately support better assessments\nof land use change and its climate impacts.", "AI": {"tldr": "本研究评估了地理空间嵌入在多哥农田测绘中的实用性，发现其能简化工作流程并实现高精度分类，从而更好地评估土地利用变化及其气候影响。", "motivation": "准确且实时的土地覆盖图对于理解土地利用变化（气候变化的关键驱动因素）至关重要。尽管地理空间嵌入提供了高效便捷的景观特征测绘方式，但其在实际测绘应用中的潜力尚未得到充分探索。", "method": "研究评估了地理空间嵌入在多哥农田测绘中的效用。具体使用了来自Presto和AlphaEarth的嵌入来制作农田地图。", "result": "研究结果表明，地理空间嵌入能够简化工作流程，实现高精度的农田分类。", "conclusion": "地理空间嵌入最终能够支持对土地利用变化及其气候影响进行更准确的评估。"}}
{"id": "2511.02919", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02919", "abs": "https://arxiv.org/abs/2511.02919", "authors": ["Shuhang Lin", "Zhencan Peng", "Lingyao Li", "Xiao Lin", "Xi Zhu", "Yongfeng Zhang"], "title": "Cache Mechanism for Agent RAG Systems", "comment": null, "summary": "Recent advances in Large Language Model (LLM)-based agents have been\npropelled by Retrieval-Augmented Generation (RAG), which grants the models\naccess to vast external knowledge bases. Despite RAG's success in improving\nagent performance, agent-level cache management, particularly constructing,\nmaintaining, and updating a compact, relevant corpus dynamically tailored to\neach agent's need, remains underexplored. Therefore, we introduce ARC (Agent\nRAG Cache Mechanism), a novel, annotation-free caching framework that\ndynamically manages small, high-value corpora for each agent. By synthesizing\nhistorical query distribution patterns with the intrinsic geometry of cached\nitems in the embedding space, ARC automatically maintains a high-relevance\ncache. With comprehensive experiments on three retrieval datasets, our\nexperimental results demonstrate that ARC reduces storage requirements to\n0.015% of the original corpus while offering up to 79.8% has-answer rate and\nreducing average retrieval latency by 80%. Our results demonstrate that ARC can\ndrastically enhance efficiency and effectiveness in RAG-powered LLM agents.", "AI": {"tldr": "本文提出ARC（Agent RAG Cache Mechanism），一个无需标注的缓存框架，能为每个LLM代理动态管理小而高价值的语料库，显著提升RAG驱动LLM代理的效率和效果。", "motivation": "尽管RAG成功提升了LLM代理的性能，但代理级别的缓存管理（即为每个代理动态构建、维护和更新紧凑、相关的语料库）仍未得到充分探索。", "method": "ARC通过结合历史查询分布模式与嵌入空间中缓存项的内在几何结构，动态管理高相关性缓存。该框架无需标注，能自动维护小而高价值的语料库。", "result": "实验结果表明，ARC将存储需求降至原始语料库的0.015%，同时提供高达79.8%的答案命中率，并将平均检索延迟降低80%。", "conclusion": "ARC能够极大地提高RAG驱动的LLM代理的效率和有效性。"}}
{"id": "2511.03005", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03005", "abs": "https://arxiv.org/abs/2511.03005", "authors": ["Hee-Jin Lee", "Zhen Guo", "Luchao Jin", "Morteza Moazami Goudarzi"], "title": "Targeted Error Correction in Knowledge Distillation: Small Language Models Surpass GPT", "comment": null, "summary": "We introduce an Analyze-Revise-Finetune (ARF) pipeline that enables smaller\nopen-source language models (LLMs) to surpass substantially larger proprietary\nmodels in customer service summarization tasks. The pipeline first analyzes and\ncategorizes common errors in summaries produced by a teacher model (GPT-3.5),\nthen performs a targeted revision using a compact editor model (Llama 3.1 70B)\nto generate high-quality, refined training data. Fine-tuning a smaller student\nmodel (Llama 3.1 8B) on this refined data resulted in superior summarization\nperformance compared to GPT-3.5. The ARF pipeline improves cost efficiency and\ndata privacy while maintaining competitive accuracy, illustrating a\ngeneralizable framework for enhancing open-source LLMs across diverse\ndownstream applications.", "AI": {"tldr": "ARF流水线使小型开源语言模型在客户服务摘要任务中超越大型专有模型，提高了成本效率和数据隐私。", "motivation": "使小型开源LLM在性能上超越大型专有模型，同时提高成本效率和数据隐私，并保持竞争力。", "method": "引入Analyze-Revise-Finetune (ARF) 流水线：首先分析并分类教师模型（GPT-3.5）生成的摘要中的常见错误；然后使用紧凑的编辑模型（Llama 3.1 70B）进行有针对性的修订，生成高质量的精炼训练数据；最后，使用这些精炼数据微调一个更小的学生模型（Llama 3.1 8B）。", "result": "通过ARF流水线微调的小型学生模型（Llama 3.1 8B）在摘要性能上超越了GPT-3.5。", "conclusion": "ARF流水线提供了一个可推广的框架，用于增强开源LLM在各种下游应用中的能力，同时提高成本效率、数据隐私并保持竞争性准确性。"}}
{"id": "2511.02958", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02958", "abs": "https://arxiv.org/abs/2511.02958", "authors": ["Cristian García-Romero", "Miquel Esplà-Gomis", "Felipe Sánchez-Martínez"], "title": "Automatic Machine Translation Detection Using a Surrogate Multilingual Translation Model", "comment": "Pre-MIT Press publication version", "summary": "Modern machine translation (MT) systems depend on large parallel corpora,\noften collected from the Internet. However, recent evidence indicates that (i)\na substantial portion of these texts are machine-generated translations, and\n(ii) an overreliance on such synthetic content in training data can\nsignificantly degrade translation quality. As a result, filtering out non-human\ntranslations is becoming an essential pre-processing step in building\nhigh-quality MT systems. In this work, we propose a novel approach that\ndirectly exploits the internal representations of a surrogate multilingual MT\nmodel to distinguish between human and machine-translated sentences.\nExperimental results show that our method outperforms current state-of-the-art\ntechniques, particularly for non-English language pairs, achieving gains of at\nleast 5 percentage points of accuracy.", "AI": {"tldr": "本文提出一种利用多语言机器翻译模型内部表示的新方法，以区分并行语料库中的人工翻译和机器翻译，从而提高翻译系统质量，尤其是在非英语语言对上表现优异。", "motivation": "现代机器翻译系统依赖大型并行语料库，但其中很大一部分是机器生成的翻译。过度依赖这些合成内容会显著降低翻译质量，因此，过滤非人工翻译成为构建高质量机器翻译系统的关键预处理步骤。", "method": "本文提出一种新颖的方法，直接利用替代多语言机器翻译模型的内部表示来区分人工翻译和机器翻译的句子。", "result": "实验结果表明，该方法优于当前最先进的技术，尤其是在非英语语言对上，准确率至少提高了5个百分点。", "conclusion": "所提出的方法能有效识别并过滤机器生成的翻译，从而显著提升机器翻译系统的性能，特别是在处理多语言场景时效果显著。"}}
{"id": "2511.03002", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.03002", "abs": "https://arxiv.org/abs/2511.03002", "authors": ["Johannes Köhler", "Carlo Scholz", "Melanie Zeilinger"], "title": "Robust reduced-order model predictive control using peak-to-peak analysis of filtered signals", "comment": "Code available at: https://github.com/KohlerJohannes/ROM_MPC_ECC", "summary": "We address the design of a model predictive control (MPC) scheme for\nlarge-scale linear systems using reduced-order models (ROMs). Our approach uses\na ROM, leverages tools from robust control, and integrates them into an MPC\nframework to achieve computational tractability with robust constraint\nsatisfaction. Our key contribution is a method to obtain guaranteed bounds on\nthe predicted outputs of the full-order system by predicting a (scalar)\nerror-bounding system alongside the ROM. This bound is then used to formulate a\nrobust ROM-based MPC that guarantees constraint satisfaction and robust\nperformance. Our method is developed step-by-step by (i) analysing the error,\n(ii) bounding the peak-to-peak gain, an (iii) using filtered signals. We\ndemonstrate our method on a 100-dimensional mass-spring-damper system,\nachieving over four orders of magnitude reduction in conservatism relative to\nexisting approaches.", "AI": {"tldr": "本文提出了一种基于降阶模型（ROM）的鲁棒模型预测控制（MPC）方案，用于大规模线性系统，通过预测一个误差边界系统来保证约束满足和鲁棒性能。", "motivation": "为大规模线性系统设计一种计算可行且能保证鲁棒约束满足的模型预测控制（MPC）方案，尤其是在使用降阶模型时。", "method": "该方法利用降阶模型（ROM），结合鲁棒控制工具，并将其整合到MPC框架中。核心贡献是预测一个（标量）误差边界系统与ROM并行运行，以获得全阶系统预测输出的保证边界。此边界用于构建鲁棒的基于ROM的MPC，确保约束满足和鲁棒性能。该方法通过以下步骤开发：(i) 分析误差，(ii) 边界峰峰增益，以及 (iii) 使用滤波信号。", "result": "该方法在一个100维的质量-弹簧-阻尼器系统上进行了验证，相对于现有方法，保守性降低了四个数量级以上，并保证了约束满足和鲁棒性能。", "conclusion": "本文提出了一种新颖的鲁棒基于ROM的MPC方法，该方法通过预测误差边界系统，解决了大规模线性系统在计算可行性和鲁棒约束满足方面的挑战，并显著降低了保守性。"}}
{"id": "2511.02893", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.02893", "abs": "https://arxiv.org/abs/2511.02893", "authors": ["Chukwuemeka Arua Kalu", "Adaobi Chiazor Emegoakor", "Fortune Okafor", "Augustine Okoh Uchenna", "Chijioke Kelvin Ukpai", "Godsent Erere Onyeugbo"], "title": "Optimizing the nnU-Net model for brain tumor (Glioma) segmentation Using a BraTS Sub-Saharan Africa (SSA) dataset", "comment": "10 pages, 4 figures", "summary": "Medical image segmentation is a critical achievement in modern medical\nscience, developed over decades of research. It allows for the exact\ndelineation of anatomical and pathological features in two- or\nthree-dimensional pictures by utilizing notions like pixel intensity, texture,\nand anatomical context. With the advent of automated segmentation, physicians\nand radiologists may now concentrate on diagnosis and treatment planning while\nintelligent computers perform routine image processing tasks.\n  This study used the BraTS Sub-Saharan Africa dataset, a selected subset of\nthe BraTS dataset that included 60 multimodal MRI cases from patients with\nglioma. Surprisingly, the nnU Net model trained on the initial 60 instances\nperformed better than the network trained on an offline-augmented dataset of\n360 cases. Hypothetically, the offline augmentations introduced artificial\nanatomical variances or intensity distributions, reducing generalization. In\ncontrast, the original dataset, when paired with nnU Net's robust online\naugmentation procedures, maintained realistic variability and produced better\nresults. The study achieved a Dice score of 0.84 for whole tumor segmentation.\nThese findings highlight the significance of data quality and proper\naugmentation approaches in constructing accurate, generalizable medical picture\nsegmentation models, particularly for under-represented locations.", "AI": {"tldr": "本研究发现，在BraTS撒哈拉以南非洲数据集上，nnU-Net模型在原始小规模数据集（60例）上配合强大的在线数据增强，比在离线增强的大规模数据集（360例）上表现更好，强调了数据质量和适当增强方法的重要性。", "motivation": "医学图像分割是现代医学的关键成就，能精确描绘解剖和病理特征。自动化分割能让医生专注于诊断和治疗计划。本研究旨在开发准确、泛化性强的医学图像分割模型，特别关注代表性不足的地区。", "method": "使用BraTS撒哈拉以南非洲数据集，包含60例胶质瘤患者的多模态MRI图像。比较了两种训练方法：1) 在原始60例数据上使用nnU-Net及其强大的在线增强；2) 在经过离线增强的360例数据上训练nnU-Net模型。", "result": "令人惊讶的是，在原始60例数据上训练并结合在线增强的nnU-Net模型表现优于在离线增强的360例数据集上训练的模型。全肿瘤分割的Dice分数达到0.84。推测离线增强引入了人工解剖变异或强度分布，降低了泛化能力。", "conclusion": "研究结果强调了数据质量和适当的（在线）数据增强方法对于构建准确、泛化性强的医学图像分割模型的重要性，尤其是在代表性不足的区域。离线增强可能引入人为变异，从而降低模型的泛化能力。"}}
{"id": "2511.02937", "categories": ["cs.RO", "cs.SE", "cs.SY", "eess.SY", "I.2.9; I.1.4; J.7"], "pdf": "https://arxiv.org/pdf/2511.02937", "abs": "https://arxiv.org/abs/2511.02937", "authors": ["Mirco Felske", "Jannik Redenius", "Georg Happich", "Julius Schöning"], "title": "Toward an Agricultural Operational Design Domain: A Framework", "comment": "18 pages, 7 figures, 2 tables", "summary": "The agricultural sector increasingly relies on autonomous systems that\noperate in complex and variable environments. Unlike on-road applications,\nagricultural automation integrates driving and working processes, each of which\nimposes distinct operational constraints. Handling this complexity and ensuring\nconsistency throughout the development and validation processes requires a\nstructured, transparent, and verified description of the environment. However,\nexisting Operational Design Domain (ODD) concepts do not yet address the unique\nchallenges of agricultural applications.\n  Therefore, this work introduces the Agricultural ODD (Ag-ODD) Framework,\nwhich can be used to describe and verify the operational boundaries of\nautonomous agricultural systems. The Ag-ODD Framework consists of three core\nelements. First, the Ag-ODD description concept, which provides a structured\nmethod for unambiguously defining environmental and operational parameters\nusing concepts from ASAM Open ODD and CityGML. Second, the 7-Layer Model\nderived from the PEGASUS 6-Layer Model, has been extended to include a process\nlayer to capture dynamic agricultural operations. Third, the iterative\nverification process verifies the Ag-ODD against its corresponding logical\nscenarios, derived from the 7-Layer Model, to ensure the Ag-ODD's completeness\nand consistency.\n  Together, these elements provide a consistent approach for creating\nunambiguous and verifiable Ag-ODD. Demonstrative use cases show how the Ag-ODD\nFramework can support the standardization and scalability of environmental\ndescriptions for autonomous agricultural systems.", "AI": {"tldr": "本文提出了农业操作设计域（Ag-ODD）框架，用于描述和验证自主农业系统的操作边界，以应对现有ODD概念无法解决的农业应用独特挑战。", "motivation": "农业自动化系统在复杂多变的环境中运行，并结合了驾驶和作业过程，面临独特的运行约束。现有的操作设计域（ODD）概念无法有效应对这些农业应用的独特挑战，需要一个结构化、透明且可验证的环境描述方法来确保开发和验证过程的一致性。", "method": "Ag-ODD框架包含三个核心要素：1. Ag-ODD描述概念，利用ASAM Open ODD和CityGML概念，提供结构化方法明确定义环境和操作参数；2. 7层模型，在PEGASUS 6层模型基础上扩展了过程层，以捕捉动态农业操作；3. 迭代验证过程，根据7层模型导出的逻辑场景验证Ag-ODD，确保其完整性和一致性。", "result": "Ag-ODD框架提供了一种创建明确且可验证的Ag-ODD的一致性方法。示范用例表明，Ag-ODD框架能够支持自主农业系统环境描述的标准化和可扩展性。", "conclusion": "Ag-ODD框架通过其核心要素，为自主农业系统提供了一种描述操作边界的一致且可验证的方法，有助于推动农业自动化领域环境描述的标准化和可扩展性。"}}
{"id": "2511.03001", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03001", "abs": "https://arxiv.org/abs/2511.03001", "authors": ["Gyeom Hwangbo", "Hyungjoo Chae", "Minseok Kang", "Hyeonjong Ju", "Soohyun Oh", "Jinyoung Yeo"], "title": "LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation", "comment": "Work in Progress", "summary": "Despite recent progress in using Large Language Models (LLMs) for\nautomatically generating 3D scenes, generated scenes often lack realistic\nspatial layouts and object attributes found in real-world environments. As this\nproblem stems from insufficiently detailed, coarse-grained instructions,\nadvancing 3D scene synthesis guided by more detailed, fine-grained instructions\nthat reflect real-world environments becomes crucial. Without such realistic\nscenes, training embodied agents in unrealistic environments can lead them to\nlearn priors that diverge significantly from real-world physics and semantics,\ndegrading their performance when deployed. Thus, verifying the alignment\nbetween the fine-grained instruction and the generated scene is essential for\neffective learning. However, current evaluation methods, such as CLIPScore and\nvision-language models (VLMs), often fail to reliably assess such alignment.\nThis shortcoming arises primarily from their shallow understanding of 3D\nscenes, which often leads to improperly grounded scene components. To address\nthis, we introduce LEGO-Eval, an evaluation framework equipped with diverse\ntools designed to explicitly ground scene components, enabling more accurate\nalignment assessments. We also present LEGO-Bench, a benchmark of detailed\ninstructions that specify complex layouts and attributes of real-world\nenvironments. Experiments demonstrate that LEGO-Eval outperforms VLM-as-a-judge\nby 0.41 F1 score in assessing scene-instruction alignment. Benchmarking with\nLEGO-Bench reveals significant limitations in current generation methods.\nAcross all evaluated approaches, success rates reached at most 10% in\ngenerating scenes that fully align with fine-grained instructions.", "AI": {"tldr": "当前LLM生成的3D场景缺乏真实感且评估方法不可靠。本文引入LEGO-Eval评估框架和LEGO-Bench详细指令基准，以实现更准确的场景与指令对齐评估，并揭示现有生成方法的显著局限性。", "motivation": "尽管LLM在3D场景生成方面取得进展，但生成的场景往往缺乏真实的布局和物体属性，原因是指令不够细致。这导致训练具身智能体时学习到与现实世界不符的先验知识，影响其性能。现有评估方法（如CLIPScore、VLM）因对3D场景理解不足，无法可靠评估细粒度指令与生成场景的对齐情况。", "method": "本文提出了LEGO-Eval，一个配备多样化工具的评估框架，旨在明确地对场景组件进行接地（grounding），从而实现更准确的对齐评估。同时，还提出了LEGO-Bench，一个包含指定复杂布局和物体属性的详细指令基准。", "result": "实验表明，LEGO-Eval在评估场景-指令对齐方面比VLM-as-a-judge高出0.41 F1分数。使用LEGO-Bench进行的基准测试揭示了当前生成方法的显著局限性：所有评估方法的成功率最高仅为10%，未能完全对齐细粒度指令。", "conclusion": "LEGO-Eval和LEGO-Bench为3D场景生成提供了一个更准确的评估框架和更具挑战性的基准。研究结果强调了当前生成方法在生成与细粒度指令完全对齐的真实场景方面的重大不足，亟需进一步改进。"}}
{"id": "2511.03034", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03034", "abs": "https://arxiv.org/abs/2511.03034", "authors": ["Yan Cathy Hua", "Paul Denny", "Jörg Wicker", "Katerina Taškova"], "title": "Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis", "comment": null, "summary": "Aspect-based Sentiment Analysis (ABSA) is a fine-grained opinion mining\napproach that identifies and classifies opinions associated with specific\nentities (aspects) or their categories within a sentence. Despite its rapid\ngrowth and broad potential, ABSA research and resources remain concentrated in\ncommercial domains, leaving analytical needs unmet in high-demand yet\nlow-resource areas such as education and healthcare. Domain adaptation\nchallenges and most existing methods' reliance on resource-intensive\nin-training knowledge injection further hinder progress in these areas.\nMoreover, traditional evaluation methods based on exact matches are overly\nrigid for ABSA tasks, penalising any boundary variations which may misrepresent\nthe performance of generative models. This work addresses these gaps through\nthree contributions: 1) We propose a novel evaluation method, Flexible Text\nSimilarity Matching and Optimal Bipartite Pairing (FTS-OBP), which accommodates\nrealistic extraction boundary variations while maintaining strong correlation\nwith traditional metrics and offering fine-grained diagnostics. 2) We present\nthe first ABSA study of small decoder-only generative language models (SLMs;\n<7B parameters), examining resource lower bounds via a case study in education\nreview ABSA. We systematically explore data-free (in-context learning and\nweight merging) and data-light fine-tuning methods, and propose a multitask\nfine-tuning strategy that significantly enhances SLM performance, enabling\n1.5-3.8 B models to surpass proprietary large models and approach benchmark\nresults with only 200-1,000 examples on a single GPU. 3) We release the first\npublic set of education review ABSA resources to support future research in\nlow-resource domains.", "AI": {"tldr": "本研究针对ABSA在教育和医疗等低资源领域的应用空白，提出了一种灵活的评估方法FTS-OBP，并首次探索了小型生成式语言模型（SLMs）在教育评论ABSA中的应用，通过多任务微调策略使其在极少数据下表现优异，同时发布了首个教育领域ABSA数据集。", "motivation": "ABSA研究和资源主要集中在商业领域，忽视了教育和医疗等高需求但低资源领域的需求。现有方法资源密集且难以进行领域适应。此外，传统的精确匹配评估方法对生成模型过于严格，无法准确反映其性能。", "method": "1) 提出了一种新的评估方法：灵活文本相似度匹配和最优二分图配对（FTS-OBP），以适应边界变异。2) 首次对参数小于7B的小型解码器专用生成式语言模型（SLMs）进行ABSA研究，探索了数据自由（上下文学习、权重合并）和数据轻量微调方法。3) 提出了一种多任务微调策略来增强SLM性能。", "result": "1) FTS-OBP评估方法能够适应实际提取边界变异，并与传统指标保持强相关性，提供细粒度诊断。2) 通过多任务微调，1.5-3.8B参数的SLMs在仅有200-1000个示例的情况下，超越了专有大型模型，并接近基准测试结果。3) 发布了首个用于教育评论ABSA的公共资源集。", "conclusion": "本研究通过提出创新的评估方法、探索小型生成式语言模型在低资源领域的应用潜力，并发布新的教育领域ABSA资源，有效弥补了ABSA研究的现有空白，为未来在教育和医疗等领域推广ABSA提供了高效且资源友好的解决方案。"}}
{"id": "2511.02997", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02997", "abs": "https://arxiv.org/abs/2511.02997", "authors": ["Jon Kutasov", "Chloe Loughridge", "Yuqi Sun", "Henry Sleight", "Buck Shlegeris", "Tyler Tracy", "Joe Benton"], "title": "Evaluating Control Protocols for Untrusted AI Agents", "comment": null, "summary": "As AI systems become more capable and widely deployed as agents, ensuring\ntheir safe operation becomes critical. AI control offers one approach to\nmitigating the risk from untrusted AI agents by monitoring their actions and\nintervening or auditing when necessary. Evaluating the safety of these\nprotocols requires understanding both their effectiveness against current\nattacks and their robustness to adaptive adversaries. In this work, we\nsystematically evaluate a range of control protocols in SHADE-Arena, a dataset\nof diverse agentic environments. First, we evaluate blue team protocols,\nincluding deferral to trusted models, resampling, and deferring on critical\nactions, against a default attack policy. We find that resampling for\nincrimination and deferring on critical actions perform best, increasing safety\nfrom 50% to 96%. We then iterate on red team strategies against these protocols\nand find that attack policies with additional affordances, such as knowledge of\nwhen resampling occurs or the ability to simulate monitors, can substantially\nimprove attack success rates against our resampling strategy, decreasing safety\nto 17%. However, deferring on critical actions is highly robust to even our\nstrongest red team strategies, demonstrating the importance of denying attack\npolicies access to protocol internals.", "AI": {"tldr": "本研究系统评估了AI控制协议，发现在SHADE-Arena环境中，“关键行动延迟”策略对自适应攻击者具有高度鲁棒性，而“重新采样”策略则易受攻击。研究强调了保护协议内部信息的重要性。", "motivation": "随着AI系统能力增强并广泛部署，确保其安全运行变得至关重要。AI控制提供了一种通过监控和干预来降低不受信任AI代理风险的方法。然而，需要评估这些协议在面对当前攻击和自适应对手时的有效性和鲁棒性。", "method": "研究在SHADE-Arena（一个包含多样化代理环境的数据集）中系统评估了一系列AI控制协议。首先，评估了“蓝队”协议（包括信任模型延迟、重新采样和关键行动延迟）对抗默认攻击策略的有效性。随后，迭代开发“红队”策略来对抗表现最佳的协议，包括赋予红队额外能力（如了解重新采样时机或模拟监控器）。", "result": "初步评估显示，重新采样和关键行动延迟协议表现最佳，将安全性从50%提高到96%。然而，当红队策略被赋予额外能力（如了解重新采样时机）时，对重新采样策略的攻击成功率显著提高，安全性降至17%。相比之下，关键行动延迟协议即使面对最强的红队策略也表现出高度鲁棒性。", "conclusion": "“关键行动延迟”协议在AI控制中表现出极强的鲁棒性，即使面对自适应攻击者。这表明，拒绝攻击策略访问协议内部信息对于确保AI系统安全运行至关重要。"}}
{"id": "2511.02928", "categories": ["eess.IV", "cs.CV", "I.2.10; I.4.8; J.3"], "pdf": "https://arxiv.org/pdf/2511.02928", "abs": "https://arxiv.org/abs/2511.02928", "authors": ["Ilerioluwakiiye Abolade", "Aniekan Udo", "Augustine Ojo", "Abdulbasit Oyetunji", "Hammed Ajigbotosho", "Aondana Iorumbur", "Confidence Raymond", "Maruf Adewole"], "title": "Domain-Adaptive Transformer for Data-Efficient Glioma Segmentation in Sub-Saharan MRI", "comment": "4 pages, 2 figures. Accepted as an abstract at the Women in Machine\n  Learning (WiML) Workshop at NeurIPS 2025", "summary": "Glioma segmentation is critical for diagnosis and treatment planning, yet\nremains challenging in Sub-Saharan Africa due to limited MRI infrastructure and\nheterogeneous acquisition protocols that induce severe domain shift. We propose\nSegFormer3D-plus, a radiomics-guided transformer architecture designed for\nrobust segmentation under domain variability. Our method combines: (1)\nhistogram matching for intensity harmonization across scanners, (2) radiomic\nfeature extraction with PCA-reduced k-means for domain-aware stratified\nsampling, (3) a dual-pathway encoder with frequency-aware feature extraction\nand spatial-channel attention, and (4) composite Dice-Cross-Entropy loss for\nboundary refinement. Pretrained on BraTS 2023 and fine-tuned on BraTS-Africa\ndata, SegFormer3D-plus demonstrates improved tumor subregion delineation and\nboundary localization across heterogeneous African clinical scans, highlighting\nthe value of radiomics-guided domain adaptation for resource-limited settings.", "AI": {"tldr": "针对撒哈拉以南非洲地区MRI基础设施有限和采集协议异构导致的严重域偏移问题，本文提出SegFormer3D-plus，一个放射组学引导的Transformer架构，用于在域变异下进行稳健的胶质瘤分割。", "motivation": "胶质瘤分割对诊断和治疗计划至关重要，但在撒哈拉以南非洲地区，由于MRI基础设施有限和异构的采集协议导致严重的域偏移，使得胶质瘤分割极具挑战性。", "method": "本文提出的SegFormer3D-plus方法结合了：(1) 用于扫描仪间强度协调的直方图匹配；(2) 结合PCA降维k-means的放射组学特征提取，用于域感知分层采样；(3) 具有频率感知特征提取和空间-通道注意力的双通路编码器；以及 (4) 用于边界细化的复合Dice-交叉熵损失。该模型在BraTS 2023上预训练并在BraTS-Africa数据上微调。", "result": "SegFormer3D-plus在异构的非洲临床扫描中，展示了肿瘤亚区域描绘和边界定位的改进。", "conclusion": "该研究强调了放射组学引导的域适应在资源有限环境下对胶质瘤分割的价值。"}}
{"id": "2511.02933", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02933", "abs": "https://arxiv.org/abs/2511.02933", "authors": ["Andy Dimnaku", "Abdullah Yusuf Kavranoğlu", "Yaser Abu-Mostafa"], "title": "Generative Hints", "comment": "13 pages, 9 figures", "summary": "Data augmentation is widely used in vision to introduce variation and\nmitigate overfitting, through enabling models to learn invariant properties,\nsuch as spatial invariance. However, these properties are not fully captured by\ndata augmentation alone, since it attempts to learn the property on\ntransformations of the training data only. We propose generative hints, a\ntraining methodology that directly enforces known invariances in the entire\ninput space. Our approach leverages a generative model trained on the training\nset to approximate the input distribution and generate unlabeled images, which\nwe refer to as virtual examples. These virtual examples are used to enforce\nfunctional properties known as hints. In generative hints, although the\ntraining dataset is fully labeled, the model is trained in a semi-supervised\nmanner on both the classification and hint objectives, using the unlabeled\nvirtual examples to guide the model in learning the desired hint. Across\ndatasets, architectures, and loss functions, generative hints consistently\noutperform standard data augmentation when learning the same property. On\npopular fine-grained visual classification benchmarks, we achieved up to 1.78%\ntop-1 accuracy improvement (0.63% on average) over fine-tuned models with data\naugmentation and an average performance boost of 1.286% on the CheXpert X-ray\ndataset.", "AI": {"tldr": "本文提出“生成式提示”（generative hints），一种训练方法，通过生成模型生成虚拟样本，直接在整个输入空间中强制执行已知不变性，从而在学习相同属性时，性能显著优于传统数据增强。", "motivation": "数据增强广泛用于视觉任务中以引入变化和缓解过拟合，但它仅通过训练数据的变换来学习不变性，无法充分捕获这些不变性属性。", "method": "该方法利用一个在训练集上训练的生成模型来近似输入分布并生成无标签的“虚拟样本”。然后，主模型以半监督方式进行训练，结合分类目标和“提示”目标（即已知的功能属性），使用这些虚拟样本来指导模型学习所需的不变性。", "result": "在各种数据集、架构和损失函数下，生成式提示在学习相同属性时始终优于标准数据增强。在流行的细粒度视觉分类基准上，相对于经过数据增强的微调模型，Top-1准确率最高提升1.78%（平均0.63%）；在CheXpert X射线数据集上，平均性能提升1.286%。", "conclusion": "生成式提示通过利用生成模型和虚拟样本，能够直接在整个输入空间中强制执行已知不变性，从而有效提高模型的泛化能力和性能，优于仅依赖数据增强的方法。"}}
{"id": "2511.03017", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03017", "abs": "https://arxiv.org/abs/2511.03017", "authors": ["Kaustav Chatterjee", "Sameer Nekkalapu", "Antos Varghese", "Marcelo Elizondo", "Quan Nguyen", "Xiaoyuan Fan"], "title": "Oscillation Analysis and Damping Control for a Proposed North American AC-DC Macrogrid", "comment": null, "summary": "In recent years, several studies conducted by both industry and U.S.\nDepartment of Energy (DOE)-funded initiatives have proposed linking North\nAmerica's Eastern and Western Interconnections (EI and WI) through a\nmultiterminal DC (MTDC) macrogrid. These studies have explored the advantages\nand opportunities of the proposed configuration from the perspectives of\ncapacity sharing and frequency support. However, the potential challenges of\nsmall-signal stability arising from this interconnection have not been\nthoroughly examined. To address this gap, detailed model-based simulation\nstudies are performed in this paper to assess the risks of poorly damped\ninter-area oscillations in the proposed macrogrid. A custom-built dynamic model\nof the MTDC system is developed and integrated with industry-grade models of\nthe EI and WI, incorporating high levels of inverter-based energy resources.\nThrough model-based oscillation analysis, potential shifts in inter-area modes\nfor both EI and WI, resulting from the MTDC integration are characterized, and\nmodes with inadequate damping are identified. Furthermore, to mitigate the\nrisks of unstable oscillations, supplementary damping controllers are designed\nfor the MTDC system, leveraging wide-area feedback to modulate active power set\npoints at selected converter stations. A frequency scanning approach is\nemployed for data-driven model linearization and controller synthesis. The\ndamping performance is evaluated under the designed operating conditions and\nselected contingency scenarios.", "AI": {"tldr": "本文通过详细的模型仿真，评估了连接北美东西部电网（EI和WI）的多端直流（MTDC）宏电网的小信号稳定性风险，并设计了附加阻尼控制器以解决潜在的低阻尼振荡问题。", "motivation": "行业和美国能源部资助的研究提出通过MTDC宏电网连接北美东西部电网，并探讨了其容量共享和频率支持优势。然而，这种互联可能引起的小信号稳定性挑战尚未被充分研究，特别是互区振荡风险。", "method": "开发了定制的MTDC系统动态模型，并将其与包含大量逆变器基能源的工业级EI和WI模型集成。通过基于模型的振荡分析来识别低阻尼互区模式。设计了利用广域反馈调制选定换流站有功功率设定点的MTDC系统附加阻尼控制器。采用频率扫描方法进行数据驱动的模型线性化和控制器合成。", "result": "通过MTDC集成，EI和WI的互区模式可能发生潜在偏移，并识别出阻尼不足的模式。设计的附加阻尼控制器在预设运行条件和选定的偶发事件场景下，有效改善了系统的阻尼性能。", "conclusion": "研究揭示了通过MTDC宏电网连接北美东西部电网可能带来的小信号稳定性挑战，特别是互区振荡问题，并成功设计了有效的附加阻尼控制器来缓解这些风险，确保宏电网的稳定运行。"}}
{"id": "2511.03075", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.03075", "abs": "https://arxiv.org/abs/2511.03075", "authors": ["Markus Buchholz", "Ignacio Carlucho", "Yvan R. Petillot"], "title": "A Collaborative Reasoning Framework for Anomaly Diagnostics in Underwater Robotics", "comment": "Paper was submitted for ICRA 2026", "summary": "The safe deployment of autonomous systems in safety-critical settings\nrequires a paradigm that combines human expertise with AI-driven analysis,\nespecially when anomalies are unforeseen. We introduce AURA (Autonomous\nResilience Agent), a collaborative framework for anomaly and fault diagnostics\nin robotics. AURA integrates large language models (LLMs), a high-fidelity\ndigital twin (DT), and human-in-the-loop interaction to detect and respond to\nanomalous behavior in real time. The architecture uses two agents with clear\nroles: (i) a low-level State Anomaly Characterization Agent that monitors\ntelemetry and converts signals into a structured natural-language problem\ndescription, and (ii) a high-level Diagnostic Reasoning Agent that conducts a\nknowledge-grounded dialogue with an operator to identify root causes, drawing\non external sources. Human-validated diagnoses are then converted into new\ntraining examples that refine the low-level perceptual model. This feedback\nloop progressively distills expert knowledge into the AI, transforming it from\na static tool into an adaptive partner. We describe the framework's operating\nprinciples and provide a concrete implementation, establishing a pattern for\ntrustworthy, continually improving human-robot teams.", "AI": {"tldr": "AURA是一个协作框架，结合LLM、数字孪生和人机交互，用于在机器人系统中实时检测和诊断异常行为，并通过反馈循环持续学习和改进。", "motivation": "在安全关键环境中安全部署自主系统，尤其是在出现不可预见的异常时，需要结合人类专业知识和AI分析的范式。", "method": "引入AURA框架，整合大型语言模型（LLM）、高保真数字孪生（DT）和人机交互。该架构包含两个代理：一个低级状态异常表征代理，将遥测信号转换为自然语言问题描述；一个高级诊断推理代理，与操作员进行知识驱动的对话以识别根本原因，并利用外部资源。人类验证的诊断被转换为新的训练样本，以优化低级感知模型，形成一个持续学习的反馈循环。", "result": "AURA能够实时检测和响应异常行为，通过与操作员对话识别根本原因，并将人类专家的知识逐步提炼到AI中，使其从静态工具转变为自适应伙伴。", "conclusion": "该框架为建立值得信赖、持续改进的人机协作团队提供了一种具体实现和模式，有助于自主系统在安全关键环境中的安全部署。"}}
{"id": "2511.03043", "categories": ["eess.SY", "cs.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.03043", "abs": "https://arxiv.org/abs/2511.03043", "authors": ["Apsara Adhikari", "Charlotte Wertz", "Anamika Dubey", "Arslan Ahmad", "Ian Dobson"], "title": "Quantifying Power Systems Resilience Using Statistical Analysis and Bayesian Learning", "comment": null, "summary": "The increasing frequency and intensity of extreme weather events is\nsignificantly affecting the power grid, causing large-scale outages and\nimpacting power system resilience. Yet limited work has been done on\nsystematically modeling the impacts of weather parameters to quantify\nresilience. This study presents a framework using statistical and Bayesian\nlearning approaches to quantitatively model the relationship between weather\nparameters and power system resilience metrics. By leveraging real-world\npublicly available outage and weather data, we identify key weather variables\nof wind speed, temperature, and precipitation influencing a particular region's\nresilience metrics. A case study of Cook County, Illinois, and Miami-Dade\nCounty, Florida, reveals that these weather parameters are critical factors in\nresiliency analysis and risk assessment. Additionally, we find that these\nweather variables have combined effects when studied jointly compared to their\neffects in isolation. This framework provides valuable insights for\nunderstanding how weather events affect power distribution system performance,\nsupporting decision-makers in developing more effective strategies for risk\nmitigation, resource allocation, and adaptation to changing climatic\nconditions.", "AI": {"tldr": "本研究提出一个框架，利用统计和贝叶斯学习方法，量化建模天气参数（风速、温度、降水）与电网弹性指标之间的关系，并发现这些变量的综合影响，以支持风险缓解和适应策略。", "motivation": "极端天气事件日益频繁和强烈，严重影响电网并导致大规模停电，损害电力系统弹性，但目前对天气参数影响的系统建模和弹性量化研究有限。", "method": "采用统计和贝叶斯学习方法来建模天气参数与电力系统弹性指标之间的关系。利用真实世界的公开停电和天气数据，识别关键天气变量。通过对伊利诺伊州库克县和佛罗里达州迈阿密-戴德县的案例研究进行验证。", "result": "识别出风速、温度和降水是影响特定地区电网弹性的关键天气变量。这些天气参数在弹性分析和风险评估中至关重要。研究还发现，这些天气变量在联合研究时具有综合效应，与单独研究时的影响不同。", "conclusion": "该框架为理解天气事件如何影响配电系统性能提供了宝贵见解，有助于决策者制定更有效的风险缓解、资源分配和适应气候变化的策略。"}}
{"id": "2511.02994", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.02994", "abs": "https://arxiv.org/abs/2511.02994", "authors": ["Syed Mostaquim Ali", "Taufiq Rahman", "Ghazal Farhani", "Mohamed H. Zaki", "Benoit Anctil", "Dominique Charlebois"], "title": "Comprehensive Assessment of LiDAR Evaluation Metrics: A Comparative Study Using Simulated and Real Data", "comment": null, "summary": "For developing safe Autonomous Driving Systems (ADS), rigorous testing is\nrequired before they are deemed safe for road deployments. Since comprehensive\nconventional physical testing is impractical due to cost and safety concerns,\nVirtual Testing Environments (VTE) can be adopted as an alternative. Comparing\nVTE-generated sensor outputs against their real-world analogues can be a strong\nindication that the VTE accurately represents reality. Correspondingly, this\nwork explores a comprehensive experimental approach to finding evaluation\nmetrics suitable for comparing real-world and simulated LiDAR scans. The\nmetrics were tested in terms of sensitivity and accuracy with different noise,\ndensity, distortion, sensor orientation, and channel settings. From comparing\nthe metrics, we found that Density Aware Chamfer Distance (DCD) works best\nacross all cases. In the second step of the research, a Virtual Testing\nEnvironment was generated using real LiDAR scan data. The data was collected in\na controlled environment with only static objects using an instrumented vehicle\nequipped with LiDAR, IMU and cameras. Simulated LiDAR scans were generated from\nthe VTEs using the same pose as real LiDAR scans. The simulated and LiDAR scans\nwere compared in terms of model perception and geometric similarity. Actual and\nsimulated LiDAR scans have a similar semantic segmentation output with a mIoU\nof 21\\% with corrected intensity and an average density aware chamfer distance\n(DCD) of 0.63. This indicates a slight difference in the geometric properties\nof simulated and real LiDAR scans and a significant difference between model\noutputs. During the comparison, density-aware chamfer distance was found to be\nthe most correlated among the metrics with perception methods.", "AI": {"tldr": "本研究旨在通过比较真实和模拟LiDAR扫描来评估自动驾驶系统(ADS)的虚拟测试环境(VTE)的准确性。研究发现，密度感知倒角距离(DCD)是评估VTE保真度的最佳指标，并且在真实与模拟LiDAR扫描之间存在几何和模型感知上的差异，其中DCD与感知方法的关联性最强。", "motivation": "为了安全部署自动驾驶系统，需要进行严格测试。然而，传统的物理测试成本高昂且存在安全隐患。虚拟测试环境(VTE)提供了一种替代方案，但需要验证其能否准确反映现实世界，这可以通过比较VTE生成的传感器输出与真实世界数据来实现。", "method": "1. 探索并实验性评估适用于比较真实与模拟LiDAR扫描的多种评估指标，测试其在不同噪声、密度、畸变、传感器方向和通道设置下的灵敏度和准确性。2. 使用在受控环境中收集的真实LiDAR扫描数据生成一个虚拟测试环境。3. 利用与真实LiDAR扫描相同的姿态从VTE生成模拟LiDAR扫描。4. 从模型感知和几何相似性两方面比较模拟和真实LiDAR扫描。", "result": "1. 密度感知倒角距离(DCD)在所有测试场景中表现最佳。2. 经过强度校正后，真实与模拟LiDAR扫描的语义分割输出相似，mIoU为21%。3. 平均密度感知倒角距离(DCD)为0.63，表明模拟与真实LiDAR扫描在几何特性上存在细微差异。4. 模型输出之间存在显著差异。5. 在所有指标中，密度感知倒角距离(DCD)与感知方法的相关性最强。", "conclusion": "本研究表明，尽管模拟与真实LiDAR扫描在几何特性和模型感知输出上仍存在差异，但虚拟测试环境可以作为自动驾驶系统测试的替代方案。密度感知倒角距离(DCD)是评估VTE保真度的有效指标，尤其与感知方法具有高度相关性。"}}
{"id": "2511.02946", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.02946", "abs": "https://arxiv.org/abs/2511.02946", "authors": ["Srikumar Sastry", "Subash Khanal", "Aayush Dhakal", "Jiayu Lin", "Dan Cher", "Phoenix Jarosz", "Nathan Jacobs"], "title": "ProM3E: Probabilistic Masked MultiModal Embedding Model for Ecology", "comment": "21 pages, 16 figures", "summary": "We introduce ProM3E, a probabilistic masked multimodal embedding model for\nany-to-any generation of multimodal representations for ecology. ProM3E is\nbased on masked modality reconstruction in the embedding space, learning to\ninfer missing modalities given a few context modalities. By design, our model\nsupports modality inversion in the embedding space. The probabilistic nature of\nour model allows us to analyse the feasibility of fusing various modalities for\ngiven downstream tasks, essentially learning what to fuse. Using these features\nof our model, we propose a novel cross-modal retrieval approach that mixes\ninter-modal and intra-modal similarities to achieve superior performance across\nall retrieval tasks. We further leverage the hidden representation from our\nmodel to perform linear probing tasks and demonstrate the superior\nrepresentation learning capability of our model. All our code, datasets and\nmodel will be released at https://vishu26.github.io/prom3e.", "AI": {"tldr": "ProM3E是一种用于生态学的概率掩码多模态嵌入模型，支持任意模态生成、模态反转，并能学习如何融合模态，在跨模态检索和表示学习方面表现出色。", "motivation": "需要一个灵活的多模态嵌入模型，能够处理缺失模态、支持任意模态间的生成，并智能地融合不同模态以适应下游任务，尤其是在生态学领域。", "method": "ProM3E基于嵌入空间中的掩码模态重建，通过少量上下文模态推断缺失模态。模型具有概率性质，支持嵌入空间中的模态反转。作者提出了一种结合模态间和模态内相似性的新型跨模态检索方法，并利用模型的隐藏表示进行线性探测任务。", "result": "在所有检索任务中，提出的跨模态检索方法都取得了卓越的性能。通过线性探测任务，证明了模型优越的表示学习能力。", "conclusion": "ProM3E是一个功能强大且灵活的概率掩码多模态嵌入模型，能够实现生态学领域中任意模态的生成、模态反转以及智能的模态融合，从而在跨模态检索和表示学习方面取得显著成效。"}}
{"id": "2511.03192", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.03192", "abs": "https://arxiv.org/abs/2511.03192", "authors": ["Isar Lemeire", "Yee Wei Law", "Sang-Heon Lee", "Will Meakin", "Tat-Jun Chin"], "title": "SAAIPAA: Optimizing aspect-angles-invariant physical adversarial attacks on SAR target recognition models", "comment": null, "summary": "Synthetic aperture radar (SAR) enables versatile, all-time, all-weather\nremote sensing. Coupled with automatic target recognition (ATR) leveraging\nmachine learning (ML), SAR is empowering a wide range of Earth observation and\nsurveillance applications. However, the surge of attacks based on adversarial\nperturbations against the ML algorithms underpinning SAR ATR is prompting the\nneed for systematic research into adversarial perturbation mechanisms. Research\nin this area began in the digital (image) domain and evolved into the physical\n(signal) domain, resulting in physical adversarial attacks (PAAs) that\nstrategically exploit corner reflectors as attack vectors to evade ML-based\nATR. This paper proposes a novel framework called SAR Aspect-Angles-Invariant\nPhysical Adversarial Attack (SAAIPAA) for physics-based modelling of\nreflector-actuated adversarial perturbations, which improves on the rigor of\nprior work. A unique feature of SAAIPAA is its ability to remain effective even\nwhen the attacker lacks knowledge of the SAR platform's aspect angles, by\ndeploying at least one reflector in each azimuthal quadrant and optimizing\nreflector orientations. The resultant physical evasion attacks are efficiently\nrealizable and optimal over the considered range of aspect angles between a SAR\nplatform and a target, achieving state-of-the-art fooling rates (over 80% for\nDenseNet-121 and ResNet50) in the white-box setting. When aspect angles are\nknown to the attacker, an average fooling rate of 99.2% is attainable. In\nblack-box settings, although the attack efficacy of SAAIPAA transfers well\nbetween some models (e.g., from ResNet50 to DenseNet121), the transferability\nto some models (e.g., MobileNetV2) can be improved. A useful outcome of using\nthe MSTAR dataset for the experiments in this article, a method for generating\nbounding boxes for densely sampled azimuthal SAR datasets is introduced.", "AI": {"tldr": "本文提出了一种名为SAAIPAA的新型物理对抗攻击框架，通过部署和优化角反射器，即使在SAR平台方位角未知的情况下，也能有效规避基于机器学习的SAR自动目标识别（ATR）系统，实现了最先进的欺骗率。", "motivation": "SAR ATR系统广泛应用于地球观测和监控，但其底层机器学习算法易受对抗性扰动攻击。特别是物理对抗攻击（PAAs）利用角反射器作为攻击载体，对ML-based ATR构成威胁。因此，需要对物理对抗扰动机制进行系统性研究。", "method": "本文提出了SAR方位角不变物理对抗攻击（SAAIPAA）框架，用于基于物理建模的反射器驱动对抗性扰动。其核心方法是在每个方位象限部署至少一个反射器并优化其朝向，从而在攻击者不了解SAR平台方位角的情况下仍能保持攻击效果。该方法旨在使物理规避攻击在SAR平台和目标之间考虑的方位角范围内高效且最优。", "result": "SAAIPAA在白盒设置下，对DenseNet-121和ResNet50实现了超过80%的最先进欺骗率。当攻击者已知方位角时，平均欺骗率可达99.2%。在黑盒设置下，SAAIPAA在某些模型（如ResNet50到DenseNet121）之间具有良好的迁移性，但对其他模型（如MobileNetV2）的迁移性有待提高。此外，本文还引入了一种为MSTAR数据集生成密集采样方位角SAR数据集边界框的方法。", "conclusion": "SAAIPAA是一个严格且高效的物理对抗攻击框架，即使在SAR平台方位角未知的情况下，也能通过策略性部署和优化反射器来有效规避SAR ATR系统。它在白盒设置下取得了优异的欺骗率，并在黑盒设置下展现了良好的模型间迁移性，尽管在某些模型上仍有提升空间。研究结果突出了对SAR ATR系统进行物理攻击的强大能力，并为未来的防御研究提供了见解。"}}
{"id": "2511.03023", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03023", "abs": "https://arxiv.org/abs/2511.03023", "authors": ["Sina Montazeri", "Yunhe Feng", "Kewei Sha"], "title": "PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework", "comment": null, "summary": "Open data repositories hold potential for evidence-based decision-making, yet\nare inaccessible to non-experts lacking expertise in dataset discovery, schema\nmapping, and statistical analysis. Large language models show promise for\nindividual tasks, but end-to-end analytical workflows expose fundamental\nlimitations: attention dilutes across growing contexts, specialized reasoning\npatterns interfere, and errors propagate undetected. We present PublicAgent, a\nmulti-agent framework that addresses these limitations through decomposition\ninto specialized agents for intent clarification, dataset discovery, analysis,\nand reporting. This architecture maintains focused attention within agent\ncontexts and enables validation at each stage. Evaluation across five models\nand 50 queries derives five design principles for multi-agent LLM systems.\nFirst, specialization provides value independent of model strength--even the\nstrongest model shows 97.5% agent win rates, with benefits orthogonal to model\nscale. Second, agents divide into universal (discovery, analysis) and\nconditional (report, intent) categories. Universal agents show consistent\neffectiveness (std dev 12.4%) while conditional agents vary by model (std dev\n20.5%). Third, agents mitigate distinct failure modes--removing discovery or\nanalysis causes catastrophic failures (243-280 instances), while removing\nreport or intent causes quality degradation. Fourth, architectural benefits\npersist across task complexity with stable win rates (86-92% analysis, 84-94%\ndiscovery), indicating workflow management value rather than reasoning\nenhancement. Fifth, wide variance in agent effectiveness across models (42-96%\nfor analysis) requires model-aware architecture design. These principles guide\nwhen and why specialization is necessary for complex analytical workflows while\nenabling broader access to public data through natural language interfaces.", "AI": {"tldr": "本文提出了PublicAgent，一个多智能体框架，通过将复杂分析工作流分解为专业智能体来解决大型语言模型在处理开放数据时的局限性，并基于评估结果提出了多智能体LLM系统的五个设计原则。", "motivation": "开放数据存储库对非专家来说难以访问，因为他们缺乏数据集发现、模式映射和统计分析的专业知识。虽然大型语言模型在单一任务上表现出潜力，但在端到端分析工作流中，它们面临注意力分散、专业推理模式干扰以及错误传播等根本性限制。", "method": "我们提出了PublicAgent，一个多智能体框架，通过将分析任务分解为意图澄清、数据集发现、分析和报告等专业智能体来解决上述限制。这种架构能在每个智能体上下文中保持专注，并支持在每个阶段进行验证。我们通过在五种模型和50个查询上进行评估来得出设计原则。", "result": "研究得出了多智能体LLM系统的五个设计原则：1. 专业化独立于模型强度提供价值，即使最强的模型也显示出97.5%的智能体胜率。2. 智能体分为通用（发现、分析）和条件（报告、意图）类别，通用智能体表现出一致的有效性，而条件智能体则因模型而异。3. 智能体缓解了不同的故障模式，移除发现或分析会导致灾难性故障，而移除报告或意图会导致质量下降。4. 架构优势在任务复杂性上持续存在，胜率稳定，表明其工作流管理价值而非推理增强。5. 智能体在不同模型间的有效性差异很大，需要模型感知的架构设计。", "conclusion": "这些设计原则指导了在复杂分析工作流中何时以及为何需要专业化，从而通过自然语言接口更广泛地访问公共数据。"}}
{"id": "2511.03048", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03048", "abs": "https://arxiv.org/abs/2511.03048", "authors": ["Anthony Hevia", "Sanjana Chintalapati", "Veronica Ka Wai Lai", "Thanh Tam Nguyen", "Wai-Tat Wong", "Terry Klassen", "Lucy Lu Wang"], "title": "ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment", "comment": "EMNLP 2025 System Demonstration", "summary": "We present ROBOTO2, an open-source, web-based platform for large language\nmodel (LLM)-assisted risk of bias (ROB) assessment of clinical trials. ROBOTO2\nstreamlines the traditionally labor-intensive ROB v2 (ROB2) annotation process\nvia an interactive interface that combines PDF parsing, retrieval-augmented LLM\nprompting, and human-in-the-loop review. Users can upload clinical trial\nreports, receive preliminary answers and supporting evidence for ROB2 signaling\nquestions, and provide real-time feedback or corrections to system suggestions.\nROBOTO2 is publicly available at https://roboto2.vercel.app/, with code and\ndata released to foster reproducibility and adoption. We construct and release\na dataset of 521 pediatric clinical trial reports (8954 signaling questions\nwith 1202 evidence passages), annotated using both manually and LLM-assisted\nmethods, serving as a benchmark and enabling future research. Using this\ndataset, we benchmark ROB2 performance for 4 LLMs and provide an analysis into\ncurrent model capabilities and ongoing challenges in automating this critical\naspect of systematic review.", "AI": {"tldr": "ROBOTO2是一个开源的、基于网络的平台，旨在通过结合PDF解析、检索增强的LLM提示和人机协作审查，简化临床试验的偏倚风险（ROB v2）评估过程。该研究还发布了一个新的儿科临床试验数据集，并对LLM在此任务上的性能进行了基准测试和分析。", "motivation": "传统的ROB v2 (ROB2) 标注过程劳动密集且耗时，需要一种更高效、更简化的方法来辅助系统评价中的偏倚风险评估。", "method": "该研究提出了ROBOTO2平台，该平台是一个交互式界面，结合了PDF解析、检索增强的大语言模型（LLM）提示和人机协作（human-in-the-loop）审查。用户可以上传临床试验报告，接收LLM生成的初步答案和支持证据，并提供实时反馈或修正。此外，研究构建并发布了一个包含521份儿科临床试验报告的数据集，并使用该数据集对4个LLM在ROB2评估上的性能进行了基准测试。", "result": "ROBOTO2平台已公开可用，其代码和数据也已发布，以促进复现和采用。研究构建并发布了一个包含521份儿科临床试验报告的数据集（涵盖8954个信号问题和1202个证据段落），该数据集通过人工和LLM辅助方法进行标注，可作为基准。利用该数据集，研究对4个LLM在ROB2评估上的性能进行了基准测试，并对当前模型的能力和自动化系统评价关键环节所面临的挑战进行了分析。", "conclusion": "ROBOTO2平台提供了一个LLM辅助的偏倚风险评估工具，有效简化了ROB2标注流程。通过发布平台、代码和数据集，该研究为未来的研究提供了重要的基准和资源，并深入分析了LLM在自动化系统评价这一关键方面所面临的当前能力和挑战。"}}
{"id": "2511.03051", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.03051", "abs": "https://arxiv.org/abs/2511.03051", "authors": ["Tao Zhang", "Kehui Yao", "Luyi Ma", "Jiao Chen", "Reza Yousefi Maragheh", "Kai Zhao", "Jianpeng Xu", "Evren Korpeoglu", "Sushant Kumar", "Kannan Achan"], "title": "No-Human in the Loop: Agentic Evaluation at Scale for Recommendation", "comment": "4 page, NeurIPS 2025 Workshop: Evaluating the Evolving LLM Lifecycle", "summary": "Evaluating large language models (LLMs) as judges is increasingly critical\nfor building scalable and trustworthy evaluation pipelines. We present\nScalingEval, a large-scale benchmarking study that systematically compares 36\nLLMs, including GPT, Gemini, Claude, and Llama, across multiple product\ncategories using a consensus-driven evaluation protocol. Our multi-agent\nframework aggregates pattern audits and issue codes into ground-truth labels\nvia scalable majority voting, enabling reproducible comparison of LLM\nevaluators without human annotation. Applied to large-scale complementary-item\nrecommendation, the benchmark reports four key findings: (i) Anthropic Claude\n3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers\nthe best overall performance across categories; (iii) GPT-4o provides the most\nfavorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among\nopen-source models. Category-level analysis shows strong consensus in\nstructured domains (Electronics, Sports) but persistent disagreement in\nlifestyle categories (Clothing, Food). These results establish ScalingEval as a\nreproducible benchmark and evaluation protocol for LLMs as judges, with\nactionable guidance on scaling, reliability, and model family tradeoffs.", "AI": {"tldr": "ScalingEval是一个大规模基准测试，系统性地比较了36个大型语言模型（LLMs）作为评估者在多个产品类别中的表现，并通过共识驱动的多智能体框架生成真值标签，发现不同模型在置信度、整体性能、成本效益和开源领域中的最佳表现，以及在不同类别中评估共识的差异。", "motivation": "评估大型语言模型（LLMs）作为评判者对于构建可扩展且值得信赖的评估流程变得日益重要。", "method": "本研究提出了ScalingEval，一个大规模基准测试，采用共识驱动的评估协议。其多智能体框架通过可扩展的多数投票，将模式审计和问题代码聚合为真值标签，从而实现了LLM评估器的可复现比较，无需人工标注。该方法应用于大规模互补商品推荐场景，系统比较了包括GPT、Gemini、Claude和Llama在内的36个LLM。", "result": "基准测试报告了四个主要发现：(i) Anthropic Claude 3.5 Sonnet 实现了最高的决策置信度；(ii) Gemini 1.5 Pro 在所有类别中提供了最佳的整体性能；(iii) GPT-4o 提供了最有利的延迟-准确性-成本权衡；(iv) GPT-OSS 20B 在开源模型中表现领先。类别级分析显示，在结构化领域（电子产品、体育）有很强的共识，但在生活方式类别（服装、食品）中存在持续的分歧。", "conclusion": "ScalingEval建立了一个可复现的LLM作为评判者的基准和评估协议，为扩展性、可靠性和模型家族权衡提供了可操作的指导。"}}
{"id": "2511.03056", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03056", "abs": "https://arxiv.org/abs/2511.03056", "authors": ["Victoria Ebert", "Rishabh Singh", "Tuochao Chen", "Noah A. Smith", "Shyamnath Gollakota"], "title": "Reading Between the Lines: The One-Sided Conversation Problem", "comment": "8 pages, 6 figures, 4 tables", "summary": "Conversational AI is constrained in many real-world settings where only one\nside of a dialogue can be recorded, such as telemedicine, call centers, and\nsmart glasses. We formalize this as the one-sided conversation problem (1SC):\ninferring and learning from one side of a conversation. We study two tasks: (1)\nreconstructing the missing speaker's turns for real-time use cases, and (2)\ngenerating summaries from one-sided transcripts. Evaluating prompting and\nfinetuned models on MultiWOZ, DailyDialog, and Candor with both human A/B\ntesting and LLM-as-a-judge metrics, we find that access to one future turn and\ninformation about utterance length improves reconstruction, placeholder\nprompting helps to mitigate hallucination, and while large models generate\npromising reconstructions with prompting, smaller models require finetuning.\nFurther, high-quality summaries can be generated without reconstructing missing\nturns. We present 1SC as a novel challenge and report promising results that\nmark a step toward privacy-aware conversational AI.", "AI": {"tldr": "本文提出并形式化了“单边对话问题”（1SC），即从对话的一侧进行推理和学习。研究了重建缺失发言者话语和从单边记录生成摘要两个任务，发现特定条件和方法能提升重建质量，且无需重建也能生成高质量摘要，为隐私保护的对话AI迈出一步。", "motivation": "在许多真实世界场景（如远程医疗、呼叫中心、智能眼镜）中，由于隐私或技术限制，只能记录对话的一侧，这限制了对话式AI的应用。研究旨在解决这一“单边对话问题”。", "method": "将问题形式化为1SC，并研究了两个任务：1) 重建缺失发言者的话语，用于实时应用；2) 从单边记录生成摘要。通过在MultiWOZ、DailyDialog和Candor数据集上评估提示工程（prompting）和微调模型，并采用人类A/B测试和LLM作为评判指标进行评估。", "result": "研究发现，访问未来一个轮次的信息和话语长度信息可以改善重建效果；占位符提示有助于减少幻觉；大型模型通过提示可以生成有前景的重建，而小型模型则需要微调。此外，无需重建缺失的话语也能生成高质量的摘要。", "conclusion": "1SC是一个新颖的挑战，本文报告了有前景的结果，标志着朝着隐私保护的对话式AI迈出了重要一步。高质量的单边摘要生成是可行的，重建任务在特定条件下也能取得良好效果。"}}
{"id": "2511.03365", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.03365", "abs": "https://arxiv.org/abs/2511.03365", "authors": ["Gabriela Fernandes"], "title": "Morpho-Genomic Deep Learning for Ovarian Cancer Subtype and Gene Mutation Prediction from Histopathology", "comment": null, "summary": "Ovarian cancer remains one of the most lethal gynecological malignancies,\nlargely due to late diagnosis and extensive heterogeneity across subtypes.\nCurrent diagnostic methods are limited in their ability to reveal underlying\ngenomic variations essential for precision oncology. This study introduces a\nnovel hybrid deep learning pipeline that integrates quantitative nuclear\nmorphometry with deep convolutional image features to perform ovarian cancer\nsubtype classification and gene mutation inference directly from Hematoxylin\nand Eosin (H&E) histopathological images. Using $\\sim45,000$ image patches\nsourced from The Cancer Genome Atlas (TCGA) and public datasets, a fusion model\ncombining a ResNet-50 Convolutional Neural Network (CNN) encoder and a Vision\nTransformer (ViT) was developed. This model successfully captured both local\nmorphological texture and global tissue context. The pipeline achieved a robust\noverall subtype classification accuracy of $84.2\\%$ (Macro AUC of $0.87 \\pm\n0.03$). Crucially, the model demonstrated the capacity for gene mutation\ninference with moderate-to-high accuracy: $AUC_{TP53} = 0.82 \\pm 0.02$,\n$AUC_{BRCA1} = 0.76 \\pm 0.04$, and $AUC_{ARID1A} = 0.73 \\pm 0.05$. Feature\nimportance analysis established direct quantitative links, revealing that\nnuclear solidity and eccentricity were the dominant predictors for TP53\nmutation. These findings validate that quantifiable histological phenotypes\nencode measurable genomic signals, paving the way for cost-effective, precision\nhistopathology in ovarian cancer triage and diagnosis.", "AI": {"tldr": "本研究提出一种混合深度学习方法，结合细胞核形态测量和深度图像特征，直接从H&E病理图像中对卵巢癌进行亚型分类和基因突变推断，为精准病理学铺平道路。", "motivation": "卵巢癌致死率高，主要原因在于诊断晚和亚型高度异质性。现有诊断方法在揭示基因组变异方面存在局限性，无法满足精准肿瘤学的需求。", "method": "开发了一种新颖的混合深度学习流水线，将定量细胞核形态测量与深度卷积图像特征相结合。该方法使用来自TCGA和公共数据集的约45,000个图像块，构建了一个融合模型（ResNet-50 CNN编码器与Vision Transformer (ViT)），以捕捉局部形态纹理和全局组织上下文。", "result": "该流水线在卵巢癌亚型分类方面取得了84.2%的整体准确率（Macro AUC为0.87 ± 0.03）。在基因突变推断方面也表现出中高准确率：AUC_TP53 = 0.82 ± 0.02，AUC_BRCA1 = 0.76 ± 0.04，AUC_ARID1A = 0.73 ± 0.05。特征重要性分析表明，细胞核实性和偏心率是TP53突变的主要预测因子。", "conclusion": "可量化的组织学表型编码了可测量的基因组信号，这为卵巢癌的分类和诊断提供了经济高效的精准病理学方法。"}}
{"id": "2511.03070", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.03070", "abs": "https://arxiv.org/abs/2511.03070", "authors": ["Drago Plecko", "Patrik Okanovic", "Torsten Hoefler", "Elias Bareinboim"], "title": "Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge", "comment": null, "summary": "Artificial intelligence (AI) systems hold great promise for advancing various\nscientific disciplines, and are increasingly used in real-world applications.\nDespite their remarkable progress, further capabilities are expected in order\nto achieve more general types of intelligence. A critical distinction in this\ncontext is between factual knowledge, which can be evaluated against true or\nfalse answers (e.g., \"what is the capital of England?\"), and probabilistic\nknowledge, reflecting probabilistic properties of the real world (e.g., \"what\nis the sex of a computer science graduate in the US?\"). In this paper, our goal\nis to build a benchmark for understanding the capabilities of LLMs in terms of\nknowledge of probability distributions describing the real world. Given that\nLLMs are trained on vast amounts of text, it may be plausible that they\ninternalize aspects of these distributions. Indeed, LLMs are touted as powerful\nuniversal approximators of real-world distributions. At the same time,\nclassical results in statistics, known as curse of dimensionality, highlight\nfundamental challenges in learning distributions in high dimensions,\nchallenging the notion of universal distributional learning. In this work, we\ndevelop the first benchmark to directly test this hypothesis, evaluating\nwhether LLMs have access to empirical distributions describing real-world\npopulations across domains such as economics, health, education, and social\nbehavior. Our results demonstrate that LLMs perform poorly overall, and do not\nseem to internalize real-world statistics naturally. When interpreted in the\ncontext of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that\nlanguage models do not contain knowledge on observational distributions (Layer\n1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional\n(Layer 2) and counterfactual (Layer 3) knowledge of these models is also\nlimited.", "AI": {"tldr": "本研究创建了一个基准来评估大型语言模型（LLM）对真实世界概率分布的理解能力，发现LLM在这方面表现不佳，未能自然地内化真实世界的统计数据。", "motivation": "人工智能系统需要更普遍的智能，尤其是在处理反映真实世界概率属性的概率知识方面。尽管LLM在大量文本上进行训练，可能内化了这些分布，但维度诅咒等统计学经典结果对普遍分布学习提出了挑战，因此需要直接测试LLM在这方面的能力。", "method": "开发了第一个专门用于测试LLM对描述真实世界人口的经验分布知识的基准。该基准涵盖经济、健康、教育和社会行为等多个领域的数据。", "result": "研究结果表明，LLM的整体表现不佳，似乎未能自然地内化真实世界的统计数据。它们不具备关于观察性分布（Pearl因果层级PCH的第一层）的知识。", "conclusion": "LLM缺乏对观察性分布的知识，根据Pearl的因果层级定理，这意味着这些模型在干预性（第二层）和反事实性（第三层）知识方面的能力也受到限制。"}}
{"id": "2511.03077", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.03077", "abs": "https://arxiv.org/abs/2511.03077", "authors": ["R. Khorrambakht", "Joaquim Ortiz-Haro", "Joseph Amigo", "Omar Mostafa", "Daniel Dugas", "Franziska Meier", "Ludovic Righetti"], "title": "WorldPlanner: Monte Carlo Tree Search and MPC with Action-Conditioned Visual World Models", "comment": null, "summary": "Robots must understand their environment from raw sensory inputs and reason\nabout the consequences of their actions in it to solve complex tasks. Behavior\nCloning (BC) leverages task-specific human demonstrations to learn this\nknowledge as end-to-end policies. However, these policies are difficult to\ntransfer to new tasks, and generating training data is challenging because it\nrequires careful demonstrations and frequent environment resets. In contrast to\nsuch policy-based view, in this paper we take a model-based approach where we\ncollect a few hours of unstructured easy-to-collect play data to learn an\naction-conditioned visual world model, a diffusion-based action sampler, and\noptionally a reward model. The world model -- in combination with the action\nsampler and a reward model -- is then used to optimize long sequences of\nactions with a Monte Carlo Tree Search (MCTS) planner. The resulting plans are\nexecuted on the robot via a zeroth-order Model Predictive Controller (MPC). We\nshow that the action sampler mitigates hallucinations of the world model during\nplanning and validate our approach on 3 real-world robotic tasks with varying\nlevels of planning and modeling complexity. Our experiments support the\nhypothesis that planning leads to a significant improvement over BC baselines\non a standard manipulation test environment.", "AI": {"tldr": "本文提出一种模型基方法，利用非结构化游戏数据学习视觉世界模型和动作采样器，结合MCTS规划器和MPC控制器，在真实机器人任务中显著优于行为克隆基线。", "motivation": "现有行为克隆（BC）等端到端策略难以迁移到新任务，且训练数据生成困难（需要精心演示和频繁环境重置），限制了机器人在复杂任务中的应用。", "method": "该研究采用模型基方法：1) 收集少量非结构化、易于获取的“游戏数据”；2) 学习一个条件动作的视觉世界模型和一个基于扩散的动作采样器，并可选地学习一个奖励模型；3) 将世界模型、动作采样器和奖励模型结合蒙特卡洛树搜索（MCTS）规划器来优化长序列动作；4) 通过零阶模型预测控制器（MPC）在机器人上执行规划结果。动作采样器被用于缓解世界模型在规划过程中的幻觉。", "result": "该方法在3个具有不同规划和建模复杂度的真实世界机器人任务上得到验证。实验结果表明，与行为克隆基线相比，规划方法在标准操作测试环境中取得了显著改进。动作采样器有效缓解了世界模型在规划过程中的幻觉问题。", "conclusion": "通过利用非结构化数据学习世界模型和动作采样器，并结合MCTS规划和MPC执行，模型基方法能够显著提升机器人在真实世界任务中的表现，克服了传统行为克隆方法的局限性。"}}
{"id": "2511.03059", "categories": ["eess.SY", "cs.NA", "cs.SY", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.03059", "abs": "https://arxiv.org/abs/2511.03059", "authors": ["Joan Vendrell Gallart", "Russell Bent", "Solmaz Kia"], "title": "Microgrids optimal radial reconfiguration via FORWARD algorithm", "comment": null, "summary": "Microgrids offer a promising paradigm for integrating distributed energy\nresources, bolstering energy resilience, and reducing the impact of blackouts.\nHowever, their inherent decentralization and dynamic operation present\nsubstantial energy management complexities. These complexities, including\nbalancing supply and demand, ensuring system stability, and minimizing\noperational costs, often necessitate solving computationally intractable\nNP-hard Mixed-Integer Non-Linear Programming (MINLP) problems. Traditional\nMINLP solvers struggle with the scalability and feasibility guarantees required\nfor these challenges. To address this, this paper tackles the problem of\nresource allocation and radial configuration design for microgrid power\ndistribution and proposes and abstracted problem which is solved by introducing\na permutation-based iterative search method over the recently introduced\nFORWARD method to efficiently identify feasible, near-optimal radial network\nstructures while inherently respecting physical constraints. Furthermore, this\npaper investigates the integration of the proposed method as a warm-start\nstrategy for benchmark MINLP solvers offering a scalable solution for\ncomprehensive microgrid design.", "AI": {"tldr": "微电网的能源管理面临计算难题，本文提出了一种基于置换的迭代搜索方法（结合FORWARD）来解决资源分配和径向配置设计问题，并将其作为MINLP求解器的热启动策略，以实现可扩展的微电网设计。", "motivation": "微电网在集成分布式能源、增强能源弹性和减少停电影响方面前景广阔，但其固有的去中心化和动态操作带来了巨大的能源管理复杂性。这些复杂性（如平衡供需、确保系统稳定性、最小化运营成本）通常需要解决计算上难以处理的NP-hard混合整数非线性规划（MINLP）问题。传统的MINLP求解器难以满足这些挑战所需的可扩展性和可行性保证。", "method": "本文针对微电网配电的资源分配和径向配置设计问题，提出了一个抽象问题。通过在FORWARD方法上引入一种基于置换的迭代搜索方法来解决该问题，以有效地识别可行、接近最优的径向网络结构，同时固有地遵守物理约束。此外，本文还研究了将所提出的方法作为基准MINLP求解器的热启动策略，以提供全面的微电网设计的可扩展解决方案。", "result": "所提出的方法能够有效地识别可行、接近最优的径向网络结构，同时固有地遵守物理约束。当作为基准MINLP求解器的热启动策略集成时，该方法为全面的微电网设计提供了一个可扩展的解决方案。", "conclusion": "本文通过提出一种基于置换的迭代搜索方法（结合FORWARD），解决了微电网的资源分配和径向配置设计问题，该方法能够高效找到可行、接近最优的径向网络结构。将其作为MINLP求解器的热启动策略，为复杂的微电网设计提供了一个可扩展的解决方案。"}}
{"id": "2511.03080", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03080", "abs": "https://arxiv.org/abs/2511.03080", "authors": ["Michel Wong", "Ali Alshehri", "Sophia Kao", "Haotian He"], "title": "PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech", "comment": "9 pages including appendix. EMNLP 2025 Industry Track", "summary": "Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS)\nsystems, converting written forms into their canonical spoken equivalents.\nTraditional TN systems can exhibit high accuracy, but involve substantial\nengineering effort, are difficult to scale, and pose challenges to language\ncoverage, particularly in low-resource settings. We propose PolyNorm, a\nprompt-based approach to TN using Large Language Models (LLMs), aiming to\nreduce the reliance on manually crafted rules and enable broader linguistic\napplicability with minimal human intervention. Additionally, we present a\nlanguage-agnostic pipeline for automatic data curation and evaluation, designed\nto facilitate scalable experimentation across diverse languages. Experiments\nacross eight languages show consistent reductions in the word error rate (WER)\ncompared to a production-grade-based system. To support further research, we\nrelease PolyNorm-Benchmark, a multilingual data set covering a diverse range of\ntext normalization phenomena.", "AI": {"tldr": "本文提出PolyNorm，一种基于提示的大语言模型（LLM）文本归一化（TN）方法，旨在减少对人工规则的依赖。它还引入了一个语言无关的数据自动整理和评估流程，并在八种语言上展示了词错误率（WER）的显著降低，并发布了多语言数据集PolyNorm-Benchmark。", "motivation": "传统的文本归一化系统虽然准确，但工程量大、难以扩展，并且在语言覆盖方面存在挑战，尤其是在低资源环境下。", "method": "本文提出PolyNorm，一种利用大型语言模型（LLM）的基于提示的文本归一化方法。此外，还提出了一个语言无关的自动化数据整理和评估流程，以支持跨多种语言的可扩展实验。", "result": "在八种语言上的实验表明，与生产级系统相比，PolyNorm持续降低了词错误率（WER）。为了支持进一步研究，本文发布了PolyNorm-Benchmark，一个涵盖多种文本归一化现象的多语言数据集。", "conclusion": "PolyNorm方法减少了对人工规则的依赖，并通过最少的人工干预实现了更广泛的语言适用性。所发布的基准数据集将有助于推动文本归一化领域的未来研究。"}}
{"id": "2511.02953", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.02953", "abs": "https://arxiv.org/abs/2511.02953", "authors": ["Sadiq Layi Macaulay", "Nimet Kaygusuz", "Simon Hadfield"], "title": "EvtSlowTV -- A Large and Diverse Dataset for Event-Based Depth Estimation", "comment": null, "summary": "Event cameras, with their high dynamic range (HDR) and low latency, offer a\npromising alternative for robust depth estimation in challenging environments.\nHowever, many event-based depth estimation approaches are constrained by\nsmall-scale annotated datasets, limiting their generalizability to real-world\nscenarios. To bridge this gap, we introduce EvtSlowTV, a large-scale event\ncamera dataset curated from publicly available YouTube footage, which contains\nmore than 13B events across various environmental conditions and motions,\nincluding seasonal hiking, flying, scenic driving, and underwater exploration.\nEvtSlowTV is an order of magnitude larger than existing event datasets,\nproviding an unconstrained, naturalistic setting for event-based depth\nlearning. This work shows the suitability of EvtSlowTV for a self-supervised\nlearning framework to capitalise on the HDR potential of raw event streams. We\nfurther demonstrate that training with EvtSlowTV enhances the model's ability\nto generalise to complex scenes and motions. Our approach removes the need for\nframe-based annotations and preserves the asynchronous nature of event data.", "AI": {"tldr": "为解决事件相机深度估计受限于小规模数据集的问题，本文推出了大型事件相机数据集EvtSlowTV，该数据集来源于YouTube视频，包含超过130亿个事件，支持自监督学习并显著提升模型在复杂场景下的泛化能力。", "motivation": "事件相机在恶劣环境下进行鲁棒深度估计具有巨大潜力，但现有方法受限于小规模标注数据集，导致其在真实世界场景中的泛化能力不足。", "method": "本文引入了EvtSlowTV，一个从公开YouTube视频中整理而成的大规模事件相机数据集，包含超过130亿个事件，涵盖多种环境条件和运动。该方法利用自监督学习框架，充分利用原始事件流的HDR潜力，并移除了对基于帧的标注的需求，保留了事件数据的异步特性。", "result": "EvtSlowTV的规模比现有事件数据集大一个数量级，为事件深度学习提供了无约束的自然环境。结果表明，使用EvtSlowTV进行训练能显著增强模型对复杂场景和运动的泛化能力，并有效利用原始事件流的HDR潜力。", "conclusion": "EvtSlowTV通过提供大规模、自然化的事件数据，弥补了事件相机深度估计领域的数据鸿沟。它支持自监督学习，提高了模型的泛化能力，同时保留了事件数据的异步特性，充分发挥了事件相机的优势。"}}
{"id": "2511.03376", "categories": ["eess.IV", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.03376", "abs": "https://arxiv.org/abs/2511.03376", "authors": ["Syed Muqeem Mahmood", "Hassan Mohy-ud-Din"], "title": "Computational Imaging Meets LLMs: Zero-Shot IDH Mutation Prediction in Brain Gliomas", "comment": "5 pages, 1 figure, 3 tables", "summary": "We present a framework that combines Large Language Models with computational\nimage analytics for non-invasive, zero-shot prediction of IDH mutation status\nin brain gliomas. For each subject, coregistered multi-parametric MRI scans and\nmulti-class tumor segmentation maps were processed to extract interpretable\nsemantic (visual) attributes and quantitative features, serialized in a\nstandardized JSON file, and used to query GPT 4o and GPT 5 without fine-tuning.\nWe evaluated this framework on six publicly available datasets (N = 1427) and\nresults showcased high accuracy and balanced classification performance across\nheterogeneous cohorts, even in the absence of manual annotations. GPT 5\noutperformed GPT 4o in context-driven phenotype interpretation. Volumetric\nfeatures emerged as the most important predictors, supplemented by\nsubtype-specific imaging markers and clinical information. Our results\ndemonstrate the potential of integrating LLM-based reasoning with computational\nimage analytics for precise, non-invasive tumor genotyping, advancing\ndiagnostic strategies in neuro-oncology. The code is available at\nhttps://github.com/ATPLab-LUMS/CIM-LLM.", "AI": {"tldr": "该研究提出了一个结合大型语言模型（LLM）和计算图像分析的框架，用于对脑胶质瘤进行非侵入性、零样本的IDH突变状态预测。", "motivation": "在神经肿瘤学中，需要一种精确、非侵入性的肿瘤基因分型方法，以改进胶质瘤的诊断策略。", "method": "该框架处理配准的多参数MRI扫描和多类别肿瘤分割图，提取可解释的语义属性和定量特征，并将其序列化为JSON文件。然后，使用GPT-4o和GPT-5进行零样本查询（无需微调）来预测IDH突变状态。", "result": "在六个公开数据集（N=1427）上评估，该框架在异质队列中展现出高准确性和平衡的分类性能，即使在没有手动标注的情况下也有效。GPT-5在上下文驱动的表型解释方面优于GPT-4o。体积特征被发现是最重要的预测因子，辅以亚型特异性影像标记和临床信息。", "conclusion": "研究结果表明，将基于LLM的推理与计算图像分析相结合，在实现精确、非侵入性肿瘤基因分型方面具有巨大潜力，有助于推动神经肿瘤学的诊断策略发展。"}}
{"id": "2511.03162", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03162", "abs": "https://arxiv.org/abs/2511.03162", "authors": ["Yijing Chu", "Qinxuan Xiang", "Sipei Zhao", "Ming Wu", "Y. Zhao", "Guangzheng Yu"], "title": "Active Noise Control Method Using Time Domain Neural Networks for Path Decoupling", "comment": null, "summary": "In decentralized active noise control (ANC) systems, crosstalk between\nmultichannel secondary sources and error microphones significantly degrades\ncontrol accuracy. Moreover, prefiltering reference signals in filtered-x (Fx)\ntype algorithms may further introduce modeling errors. A theoretical analysis\nof the Fx-based decentralized control algorithm was performed, which reveals\nhow prefiltering and crosstalk affect the control performance. Then, a hybrid\nmethod combining fixed-value neural networks and adaptive strategies was\nproposed for efficient decentralized ANC. The adaptive filter models the\nprimary path of its own channel online using the least mean square (LMS)\nalgorithm while the neural network (named DecNet) is used for secondary paths\ninverting and decoupling. The hybrid DecNet-LMS algorithm was implemented in\nthe time domain to guarantee causality and avoid latency. Simulation results\nwith measured acoustic paths show that the proposed method outperforms the\nexisting ANC algorithms using either traditional adaptive filters or neural\nnetwork-based fixed-coefficient methods under different acoustic conditions.", "AI": {"tldr": "本文分析了去中心化主动噪声控制（ANC）系统中串扰和预滤波对控制性能的影响，并提出了一种混合DecNet-LMS算法，结合自适应滤波器和神经网络，以提高去中心化ANC的效率和性能。", "motivation": "在去中心化主动噪声控制（ANC）系统中，多通道次级声源和误差麦克风之间的串扰会严重降低控制精度。此外，在Fx型算法中对参考信号进行预滤波可能会引入额外的建模误差，这些问题促使研究者寻求更有效的去中心化ANC解决方案。", "method": "首先，对基于Fx的去中心化控制算法进行了理论分析，揭示了预滤波和串扰如何影响控制性能。然后，提出了一种结合固定值神经网络（DecNet）和自适应策略的混合方法。其中，自适应滤波器使用LMS算法在线建模自身通道的主路径，而神经网络（DecNet）则用于次级路径的反演和解耦。该混合DecNet-LMS算法在时域实现，以确保因果性和避免延迟。", "result": "通过测量声学路径的仿真结果表明，在不同的声学条件下，所提出的混合DecNet-LMS方法优于现有使用传统自适应滤波器或基于神经网络的固定系数方法的ANC算法。", "conclusion": "该研究得出结论，提出的混合DecNet-LMS算法能有效解决去中心化ANC系统中的串扰和预滤波问题，显著提升控制性能，优于现有主流的ANC算法。"}}
{"id": "2511.03078", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.03078", "abs": "https://arxiv.org/abs/2511.03078", "authors": ["Rohan Kota", "Kaival Shah", "J. Edward Colgate", "Gregory Reardon"], "title": "3D Cal: An Open-Source Software Library for Calibrating Tactile Sensors", "comment": null, "summary": "Tactile sensing plays a key role in enabling dexterous and reliable robotic\nmanipulation, but realizing this capability requires substantial calibration to\nconvert raw sensor readings into physically meaningful quantities. Despite its\nnear-universal necessity, the calibration process remains ad hoc and\nlabor-intensive. Here, we introduce \\libname{}, an open-source library that\ntransforms a low-cost 3D printer into an automated probing device capable of\ngenerating large volumes of labeled training data for tactile sensor\ncalibration. We demonstrate the utility of \\libname{} by calibrating two\ncommercially available vision-based tactile sensors, DIGIT and GelSight Mini,\nto reconstruct high-quality depth maps using the collected data and a custom\nconvolutional neural network. In addition, we perform a data ablation study to\ndetermine how much data is needed for accurate calibration, providing practical\nguidelines for researchers working with these specific sensors, and we\nbenchmark the trained models on previously unseen objects to evaluate\ncalibration accuracy and generalization performance. By automating tactile\nsensor calibration, \\libname{} can accelerate tactile sensing research,\nsimplify sensor deployment, and promote the practical integration of tactile\nsensing in robotic platforms.", "AI": {"tldr": "本文介绍了一个名为\\libname{}的开源库，它能将低成本3D打印机转变为自动化探针设备，从而生成大量带标签的训练数据，实现触觉传感器（如DIGIT和GelSight Mini）的自动化校准，以重建高质量深度图。", "motivation": "触觉传感在机器人灵巧操作中至关重要，但其校准过程通常是临时性的、劳动密集型的，需要将原始传感器读数转换为有物理意义的量。", "method": "研究者开发了开源库\\libname{}，它利用3D打印机作为自动化探针设备，生成用于触觉传感器校准的大量带标签训练数据。利用收集到的数据和定制的卷积神经网络（CNN），对DIGIT和GelSight Mini两种商用视觉触觉传感器进行了校准，以重建深度图。此外，还进行了数据消融研究，以确定准确校准所需的数据量。", "result": "成功展示了\\libname{}在校准DIGIT和GelSight Mini传感器方面的实用性，实现了高质量深度图的重建。研究还提供了关于准确校准所需数据量的实用指导方针。训练后的模型在未见过物体上的基准测试表现出良好的校准精度和泛化性能。", "conclusion": "\\libname{}通过自动化触觉传感器校准过程，能够加速触觉传感研究，简化传感器部署，并促进触觉传感在机器人平台中的实际集成应用。"}}
{"id": "2511.02992", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02992", "abs": "https://arxiv.org/abs/2511.02992", "authors": ["Mikhael Djajapermana", "Moritz Reiber", "Daniel Mueller-Gritschneder", "Ulf Schlichtmann"], "title": "Hybrid Convolution and Vision Transformer NAS Search Space for TinyML Image Classification", "comment": "Presented at ITEM workshop co-located with ECML PKDD 2024, Vilnius LT", "summary": "Hybrids of Convolutional Neural Network (CNN) and Vision Transformer (ViT)\nhave outperformed pure CNN or ViT architecture. However, since these\narchitectures require large parameters and incur large computational costs,\nthey are unsuitable for tinyML deployment. This paper introduces a new hybrid\nCNN-ViT search space for Neural Architecture Search (NAS) to find efficient\nhybrid architectures for image classification. The search space covers hybrid\nCNN and ViT blocks to learn local and global information, as well as the novel\nPooling block of searchable pooling layers for efficient feature map reduction.\nExperimental results on the CIFAR10 dataset show that our proposed search space\ncan produce hybrid CNN-ViT architectures with superior accuracy and inference\nspeed to ResNet-based tinyML models under tight model size constraints.", "AI": {"tldr": "本文提出了一种新的混合CNN-ViT神经架构搜索（NAS）搜索空间，旨在为TinyML部署找到高效且性能优越的混合架构，以克服现有混合模型参数大、计算成本高的问题。", "motivation": "尽管卷积神经网络（CNN）和Vision Transformer（ViT）的混合架构表现优于纯CNN或ViT，但它们需要大量参数和高计算成本，不适用于TinyML部署。", "method": "引入了一个新的混合CNN-ViT搜索空间用于神经架构搜索（NAS）。该搜索空间包含混合CNN和ViT块以学习局部和全局信息，以及新颖的可搜索池化层（Pooling block）用于高效特征图降维。", "result": "在CIFAR10数据集上的实验结果表明，在严格的模型尺寸限制下，所提出的搜索空间能够生成具有优越准确性和推理速度的混合CNN-ViT架构，优于基于ResNet的TinyML模型。", "conclusion": "所提出的NAS搜索空间能够有效地发现适用于图像分类的、在模型尺寸受限下仍能提供卓越精度和推理速度的混合CNN-ViT架构，解决了TinyML部署的效率挑战。"}}
{"id": "2511.03165", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.03165", "abs": "https://arxiv.org/abs/2511.03165", "authors": ["Raj Surya Rajendran Kathirvel", "Zach A Chavis", "Stephen J. Guy", "Karthik Desingh"], "title": "SENT Map -- Semantically Enhanced Topological Maps with Foundation Models", "comment": "Accepted at ICRA 2025 Workshop on Foundation Models and\n  Neuro-Symbolic AI for Robotics", "summary": "We introduce SENT-Map, a semantically enhanced topological map for\nrepresenting indoor environments, designed to support autonomous navigation and\nmanipulation by leveraging advancements in foundational models (FMs). Through\nrepresenting the environment in a JSON text format, we enable semantic\ninformation to be added and edited in a format that both humans and FMs\nunderstand, while grounding the robot to existing nodes during planning to\navoid infeasible states during deployment. Our proposed framework employs a two\nstage approach, first mapping the environment alongside an operator with a\nVision-FM, then using the SENT-Map representation alongside a natural-language\nquery within an FM for planning. Our experimental results show that\nsemantic-enhancement enables even small locally-deployable FMs to successfully\nplan over indoor environments.", "AI": {"tldr": "本文介绍了SENT-Map，一种语义增强的拓扑地图，用于室内环境表示，它利用基础模型（FMs）的优势，以人类和FMs都能理解的JSON文本格式支持自主导航和操作，并通过语义增强使小型FMs也能成功规划。", "motivation": "研究动机是为了利用基础模型（FMs）的最新进展，改进室内环境的自主导航和操作能力，并解决现有方法在表示语义信息以及确保机器人规划可行性方面的挑战。", "method": "SENT-Map采用JSON文本格式表示环境，允许添加和编辑语义信息，同时在规划时将机器人固定到现有节点以避免不可行状态。该框架分两阶段：首先，操作员与Vision-FM一起进行环境映射；其次，使用SENT-Map表示和自然语言查询通过FM进行规划。", "result": "实验结果表明，语义增强使得即使是小型、可在本地部署的基础模型（FMs）也能成功地在室内环境中进行规划。", "conclusion": "SENT-Map通过语义增强的拓扑地图表示，有效提升了基础模型在室内环境中的规划能力，即使是资源受限的小型FMs也能实现成功的自主导航和操作。"}}
{"id": "2511.03089", "categories": ["cs.CL", "eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03089", "abs": "https://arxiv.org/abs/2511.03089", "authors": ["Gowtham Premananth", "Carol Espy-Wilson"], "title": "A Computational Approach to Analyzing Disrupted Language in Schizophrenia: Integrating Surprisal and Coherence Measures", "comment": "Submitted to ICASSP 2026", "summary": "Language disruptions are one of the well-known effects of schizophrenia\nsymptoms. They are often manifested as disorganized speech and impaired\ndiscourse coherence. These abnormalities in spontaneous language production\nreflect underlying cognitive disturbances and have the potential to serve as\nobjective markers for symptom severity and diagnosis of schizophrenia. This\nstudy focuses on how these language disruptions can be characterized in terms\nof two computational linguistic measures: surprisal and semantic coherence. By\ncomputing surprisal and semantic coherence of language using computational\nmodels, this study investigates how they differ between subjects with\nschizophrenia and healthy controls. Furthermore, this study provides further\ninsight into how language disruptions in terms of these linguistic measures\nchange with varying degrees of schizophrenia symptom severity.", "AI": {"tldr": "本研究利用计算语言学指标（惊奇度和语义连贯性）量化精神分裂症患者的语言障碍，以区分患者与健康对照，并评估症状严重程度。", "motivation": "精神分裂症症状常表现为语言障碍，如言语紊乱和语篇连贯性受损。这些自发语言产生异常反映了潜在的认知障碍，并有潜力作为精神分裂症症状严重程度和诊断的客观生物标志物。", "method": "本研究通过计算模型计算语言的惊奇度和语义连贯性这两个计算语言学指标，以表征语言障碍。研究将比较精神分裂症患者与健康对照组在这些指标上的差异，并探讨这些语言指标如何随精神分裂症症状严重程度的变化而改变。", "result": "本研究旨在揭示精神分裂症患者与健康对照组在惊奇度和语义连贯性方面的语言差异，并深入了解这些语言障碍如何随着精神分裂症症状严重程度的变化而演变。", "conclusion": "通过量化语言障碍，本研究有望为精神分裂症的诊断和症状严重程度评估提供新的客观语言标记，并加深对精神分裂症认知机制的理解。"}}
{"id": "2511.03092", "categories": ["cs.AI", "cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03092", "abs": "https://arxiv.org/abs/2511.03092", "authors": ["Jonathan Li", "Nasim Farahini", "Evgenii Iuliugin", "Magnus Vesterlund", "Christian Haggstrom", "Guangtao Wang", "Shubhangi Upasani", "Ayush Sachdeva", "Rui Li", "Faline Fu", "Chen Wu", "Ayesha Siddiqua", "John Long", "Tuowen Zhao", "Matheen Musaddiq", "Hakan Zeffer", "Yun Du", "Mingran Wang", "Qinghua Li", "Bo Li", "Urmish Thakker", "Raghu Prabhakar"], "title": "SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators", "comment": null, "summary": "The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+\ncontext length support have resulted in increasing demands for on-chip memory\nto support large KV caches. Techniques such as StreamingLLM and SnapKV\ndemonstrate how to control KV cache size while maintaining model accuracy. Yet,\nthese techniques are not commonly used within industrial deployments using\nframeworks like vLLM or SGLang. The reason is twofold: on one hand, the static\ngraphs and continuous batching methodology employed by these frameworks make it\ndifficult to admit modifications to the standard multi-head attention\nalgorithm, while on the other hand, the accuracy implications of such\ntechniques on modern instruction-following and reasoning models are not well\nunderstood, obfuscating the need for implementing these techniques. In this\npaper, we explore these accuracy implications on Llama-3.1-8B-Instruct and\nDeepSeek-R1, and develop SnapStream, a KV cache compression method that can be\ndeployed at scale. We demonstrate the efficacy of SnapStream in a 16-way\ntensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators\nrunning at 128k context length and up to 1832 tokens per second in a real\nproduction setting. SnapStream enables $4\\times$ improved on-chip memory usage\nand introduces minimal accuracy degradation on LongBench-v2, AIME24 and\nLiveCodeBench. To the best of our knowledge, this is the first implementation\nof sparse KV attention techniques deployed in a production inference system\nwith static graphs and continuous batching.", "AI": {"tldr": "本文提出了一种名为SnapStream的KV缓存压缩方法，解决了大型语言模型（LLMs）在工业部署中对片上内存的巨大需求，同时克服了现有框架的部署挑战，并实现了显著的内存节省和最小的准确性下降。", "motivation": "随着100B+参数LLM和100k+上下文长度的支持，KV缓存对片上内存的需求急剧增加。尽管StreamingLLM和SnapKV等技术可以控制KV缓存大小并保持模型准确性，但它们并未在vLLM或SGLang等工业框架中广泛使用。原因在于：这些框架的静态图和连续批处理方法难以修改标准多头注意力算法；同时，这些技术对现代指令遵循和推理模型的准确性影响尚不明确，导致实施需求被忽视。", "method": "本文首先探究了现有KV缓存压缩技术对Llama-3.1-8B-Instruct和DeepSeek-R1模型的准确性影响。在此基础上，开发了一种名为SnapStream的KV缓存压缩方法，该方法可在大规模生产环境中部署。SnapStream旨在兼容静态图和连续批处理的推理系统。", "result": "SnapStream在DeepSeek-671B的16路张量并行部署中（使用SambaNova SN40L加速器，128k上下文长度，高达1832 tokens/秒）得到验证。它实现了4倍的片上内存使用改进，并在LongBench-v2、AIME24和LiveCodeBench基准测试中引入了最小的准确性下降。据作者所知，这是首次将稀疏KV注意力技术部署到具有静态图和连续批处理的生产推理系统中。", "conclusion": "SnapStream成功地解决了大规模LLM推理中KV缓存对内存的巨大需求问题，通过在生产环境中实现4倍的内存节省和最小的准确性损失。它克服了在现有工业框架中部署此类技术的挑战，证明了稀疏KV注意力技术在实际生产系统中的可行性和有效性。"}}
{"id": "2511.03221", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03221", "abs": "https://arxiv.org/abs/2511.03221", "authors": ["Yang Guo", "Stefan Streif"], "title": "MHE in Output Feedback Control of Uncertain Nonlinear Systems via IQCs", "comment": "8 pages, 2 figures; extended version; a shortened version is accepted\n  at IEEE Control System Letters, October 27, 2025", "summary": "We propose a moving horizon estimation (MHE) scheme for general nonlinear\nconstrained systems with parametric or static nonlinear uncertainties and a\npredetermined state feedback controller that is assumed to robustly stabilize\nthe system in the absence of estimation errors. Leveraging integral quadratic\nconstraints (IQCs), we introduce a new notion of detectability that is robust\nto possibly non-parametric uncertainties and verifiable in practice. Assuming\nthat the uncertain system driven by the controller satisfies this notion of\ndetectability, we provide an MHE formulation such that the closed-loop system\nformed of the uncertain system, the controller and MHE is input-to-state stable\nw.r.t. exogenous disturbances.", "AI": {"tldr": "本文提出了一种针对具有参数或静态非线性不确定性的非线性受限系统的移动视界估计（MHE）方案，并引入了基于积分二次约束（IQCs）的鲁棒可检测性概念，以确保闭环系统的输入到状态稳定性。", "motivation": "研究动机是为具有不确定性和预定状态反馈控制器的非线性受限系统设计一种鲁棒的估计方案，以确保即使存在估计误差，系统也能保持稳定。", "method": "该研究提出了一种MHE方案，并利用积分二次约束（IQCs）引入了一种新的、对非参数不确定性鲁棒且可实际验证的可检测性概念。在此可检测性假设下，MHE被设计成使得由不确定系统、控制器和MHE组成的闭环系统对外源扰动具有输入到状态稳定性（ISS）。", "result": "研究结果是提出了一种针对一般非线性受限系统的MHE方案，并引入了一个基于IQCs的鲁棒可检测性新概念。在满足此可检测性条件下，闭环系统（不确定系统、控制器和MHE）实现了对外源扰动的输入到状态稳定性。", "conclusion": "结论是，所提出的MHE方案结合基于IQCs的鲁棒可检测性概念，能够为具有不确定性的非线性受限系统提供一个鲁棒的估计框架，并确保与预设控制器协同工作时，闭环系统具有输入到状态稳定性。"}}
{"id": "2511.03098", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.03098", "abs": "https://arxiv.org/abs/2511.03098", "authors": ["Miftahur Rahman", "Samuel Adebayo", "Dorian A. Acevedo-Mejia", "David Hester", "Daniel McPolin", "Karen Rafferty", "Debra F. Laefer"], "title": "ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly", "comment": null, "summary": "The Intermeshed Steel Connection (ISC) system, when paired with robotic\nmanipulators, can accelerate steel-frame assembly and improve worker safety by\neliminating manual assembly. Dependable perception is one of the initial stages\nfor ISC-aware robots. However, this is hampered by the absence of a dedicated\nimage corpus, as collecting photographs on active construction sites is\nlogistically difficult and raises safety and privacy concerns. In response, we\nintroduce ISC-Perception, the first hybrid dataset expressly designed for ISC\ncomponent detection. It blends procedurally rendered CAD images, game-engine\nphotorealistic scenes, and a limited, curated set of real photographs, enabling\nfully automatic labelling of the synthetic portion. We explicitly account for\nall human effort to produce the dataset, including simulation engine and scene\nsetup, asset preparation, post-processing scripts and quality checks; our total\nhuman time to generate a 10,000-image dataset was 30.5,h versus 166.7,h for\nmanual labelling at 60,s per image (-81.7%). A manual pilot on a representative\nimage with five instances of ISC members took 60,s (maximum 80,s), anchoring\nthe manual baseline. Detectors trained on ISC-Perception achieved a mean\nAverage Precision at IoU 0.50 of 0.756, substantially surpassing models trained\non synthetic-only or photorealistic-only data. On a 1,200-frame bench test, we\nreport mAP@0.50/mAP@[0.50:0.95] of 0.943/0.823. By bridging the data gap for\nconstruction-robotics perception, ISC-Perception facilitates rapid development\nof custom object detectors and is freely available for research and industrial\nuse upon request.", "AI": {"tldr": "本文介绍了ISC-Perception，一个用于Intermeshed Steel Connection (ISC)组件检测的混合数据集，旨在解决建筑机器人感知数据不足的问题，并通过结合合成和少量真实数据，显著提高了目标检测器的性能，同时大幅减少了数据集标注所需的人工时间。", "motivation": "将Intermeshed Steel Connection (ISC)系统与机器人机械手结合可以加速钢结构装配并提高工人安全性，但实现这一目标需要可靠的机器人感知能力。然而，目前缺乏专用的图像语料库，因为在活跃的建筑工地收集照片存在物流困难、安全和隐私问题。", "method": "研究人员创建了ISC-Perception数据集，这是第一个专为ISC组件检测设计的混合数据集。它结合了程序渲染的CAD图像、游戏引擎生成的逼真场景以及少量精选的真实照片。合成部分实现了全自动标注。作者明确量化了生成数据集的所有人工投入，包括仿真引擎和场景设置、资产准备、后处理脚本和质量检查。", "result": "生成10,000张图像的数据集所需的人工时间为30.5小时，相比手动标注（每张图像60秒）所需的166.7小时，减少了81.7%。在ISC-Perception上训练的检测器在IoU 0.50时的平均精度(mAP)达到0.756，显著优于仅使用合成数据或仅使用逼真数据训练的模型。在1,200帧的基准测试中，报告的mAP@0.50/mAP@[0.50:0.95]分别为0.943/0.823。", "conclusion": "ISC-Perception通过弥补建筑机器人感知领域的数据空白，促进了定制对象检测器的快速开发。该数据集免费提供给研究和工业使用，从而推动了机器人辅助钢结构装配技术的发展。"}}
{"id": "2511.03106", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03106", "abs": "https://arxiv.org/abs/2511.03106", "authors": ["Katherine C. Kellogg", "Bingyang Ye", "Yifan Hu", "Guergana K. Savova", "Byron Wallace", "Danielle S. Bitterman"], "title": "Large language models require a new form of oversight: capability-based monitoring", "comment": "Under review", "summary": "The rapid adoption of large language models (LLMs) in healthcare has been\naccompanied by scrutiny of their oversight. Existing monitoring approaches,\ninherited from traditional machine learning (ML), are task-based and founded on\nassumed performance degradation arising from dataset drift. In contrast, with\nLLMs, inevitable model degradation due to changes in populations compared to\nthe training dataset cannot be assumed, because LLMs were not trained for any\nspecific task in any given population. We therefore propose a new organizing\nprinciple guiding generalist LLM monitoring that is scalable and grounded in\nhow these models are developed and used in practice: capability-based\nmonitoring. Capability-based monitoring is motivated by the fact that LLMs are\ngeneralist systems whose overlapping internal capabilities are reused across\nnumerous downstream tasks. Instead of evaluating each downstream task\nindependently, this approach organizes monitoring around shared model\ncapabilities, such as summarization, reasoning, translation, or safety\nguardrails, in order to enable cross-task detection of systemic weaknesses,\nlong-tail errors, and emergent behaviors that task-based monitoring may miss.\nWe describe considerations for developers, organizational leaders, and\nprofessional societies for implementing a capability-based monitoring approach.\nUltimately, capability-based monitoring will provide a scalable foundation for\nsafe, adaptive, and collaborative monitoring of LLMs and future generalist\nartificial intelligence models in healthcare.", "AI": {"tldr": "本文提出了一种名为“基于能力监测”的新方法，用于在医疗保健领域对大型语言模型（LLMs）进行可扩展、安全和协作的监测，以解决传统任务型监测的不足。", "motivation": "随着LLMs在医疗保健领域的快速应用，对其监督的审查也随之而来。传统的机器学习（ML）监测方法是基于任务的，并假设性能下降源于数据集漂移。然而，LLMs并非为特定任务或人群训练，其模型退化不能简单地归因于人群变化。因此，需要一种新的、可扩展的监测原则来适应LLMs的通用性和实际应用方式。", "method": "本文提出“基于能力监测”的方法。该方法围绕LLMs共享的内部能力（如摘要、推理、翻译、安全防护等）组织监测，而不是独立评估每个下游任务。这种方法旨在跨任务检测系统性弱点、长尾错误和新兴行为，这些是传统任务型监测可能遗漏的。", "result": "通过基于能力监测，可以实现跨任务检测系统性弱点、长尾错误和新兴行为。这种方法为开发人员、组织领导者和专业协会提供了一个可扩展的框架，以更有效地监测LLMs的性能和行为。", "conclusion": "基于能力监测将为医疗保健领域中LLMs和未来通用人工智能模型的安全、自适应和协作监测提供可扩展的基础。"}}
{"id": "2511.02996", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.02996", "abs": "https://arxiv.org/abs/2511.02996", "authors": ["Ailar Mahdizadeh", "Puria Azadi Moghadam", "Xiangteng He", "Shahriar Mirabbasi", "Panos Nasiopoulos", "Leonid Sigal"], "title": "SCALE-VLP: Soft-Weighted Contrastive Volumetric Vision-Language Pre-training with Spatial-Knowledge Semantics", "comment": null, "summary": "Vision-language models (VLMs) have demonstrated strong cross-modal\ncapabilities, yet most work remains limited to 2D data and assumes binary\nsupervision (i.e., positive vs. negative pairs), overlooking the continuous and\nstructured dependencies present in volumetric data such as CT. Existing\napproaches often treat volumetric scans as independent 2D slices, compromising\nspatial coherence and underutilizing rich clinical semantics. We propose\nSCALE-VLP, a soft-weighted contrastive vision-language pre-training framework\nthat integrates (i) volumetric spatial semantics to preserve anatomical\nstructure and (ii) domain-aware, knowledge-infused semantics (e.g.,\nradiological ontologies) to guide alignment. This yields structurally\nconsistent and semantically grounded representations under limited supervision,\ndemonstrating strong cross-task transferability (retrieval, report generation,\nand classification), and cross-domain generalizability with consistent gains\nwithout further fine-tuning. In particular, compared to the previous state of\nthe art, SCALE-VLP achieves up to 4.3x higher top-1 CT-report retrieval,\nimproves abnormality classification by 10 points, and reaches ROUGE-L 0.44 and\nBERT-F1 0.89 for report generation. Further, in zero-shot evaluation on an\nout-of-domain external dataset, we observe consistent gains, indicating the\ncross-task and cross-domain generalization ability of SCALE-VLP.", "AI": {"tldr": "SCALE-VLP是一种软加权对比视觉-语言预训练框架，专为CT等体积数据设计，通过整合体积空间语义和领域知识引导的语义，在有限监督下实现结构一致且语义扎实的表示，并在多任务和跨领域上展现出强大的泛化能力。", "motivation": "现有视觉-语言模型(VLMs)大多局限于2D数据和二元监督，忽视了CT等体积数据中连续和结构化的依赖关系。此外，现有方法常将体积扫描视为独立的2D切片，损害了空间连贯性并未能充分利用丰富的临床语义。", "method": "本文提出了SCALE-VLP，一个软加权对比视觉-语言预训练框架。它主要整合了两个方面：(i) 体积空间语义，以保留解剖结构；(ii) 领域感知、知识注入的语义（如放射学本体论），以指导对齐。这在有限监督下产生了结构一致和语义扎实的表示。", "result": "SCALE-VLP在跨任务（检索、报告生成和分类）和跨领域泛化方面表现出色，无需进一步微调即可获得持续提升。与现有SOTA相比，CT-报告检索的top-1准确率提高了4.3倍，异常分类提高了10个点，报告生成达到ROUGE-L 0.44和BERT-F1 0.89。在零样本、域外数据集评估中也观察到持续的性能提升。", "conclusion": "SCALE-VLP通过结合体积空间语义和领域知识，在有限监督下成功学习到结构一致和语义扎实的视觉-语言表示。它在多任务和跨领域上展现出强大的可迁移性和泛化能力，显著优于现有方法。"}}
{"id": "2511.03167", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.03167", "abs": "https://arxiv.org/abs/2511.03167", "authors": ["Xin Liu", "Jinze Wu", "Yinghui Li", "Chenkun Qi", "Yufei Xue", "Feng Gao"], "title": "Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning", "comment": null, "summary": "Multi-legged robots offer enhanced stability to navigate complex terrains\nwith their multiple legs interacting with the environment. However, how to\neffectively coordinate the multiple legs in a larger action exploration space\nto generate natural and robust movements is a key issue. In this paper, we\nintroduce a motion prior-based approach, successfully applying deep\nreinforcement learning algorithms to a real hexapod robot. We generate a\ndataset of optimized motion priors, and train an adversarial discriminator\nbased on the priors to guide the hexapod robot to learn natural gaits. The\nlearned policy is then successfully transferred to a real hexapod robot, and\ndemonstrate natural gait patterns and remarkable robustness without visual\ninformation in complex terrains. This is the first time that a reinforcement\nlearning controller has been used to achieve complex terrain walking on a real\nhexapod robot.", "AI": {"tldr": "本文提出了一种基于运动先验的方法，将深度强化学习成功应用于真实的六足机器人，使其在复杂地形中无需视觉信息也能学习并展示出自然且鲁棒的步态。", "motivation": "多足机器人虽然在复杂地形中具有增强的稳定性，但在较大的动作探索空间中如何有效协调多条腿以生成自然和鲁棒的运动是一个关键问题。", "method": "引入了一种基于运动先验的方法，生成了一个优化的运动先验数据集，并训练了一个对抗性判别器来指导六足机器人学习自然步态。学习到的策略随后被成功迁移到真实的六足机器人上。", "result": "所学习的策略在真实六足机器人上展示了自然的步态模式和卓越的鲁棒性，即使在复杂地形中没有视觉信息也能有效行走。这是强化学习控制器首次用于实现真实六足机器人复杂地形行走。", "conclusion": "该研究成功地将基于运动先验的深度强化学习方法应用于真实六足机器人，解决了多足协调难题，使其能够在复杂地形中展现出自然且鲁棒的运动能力。"}}
{"id": "2511.03102", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03102", "abs": "https://arxiv.org/abs/2511.03102", "authors": ["Saad Mankarious", "Ayah Zirikly"], "title": "CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic", "comment": null, "summary": "Mental health disorders affect millions worldwide, yet early detection\nremains a major challenge, particularly for Arabic-speaking populations where\nresources are limited and mental health discourse is often discouraged due to\ncultural stigma. While substantial research has focused on English-language\nmental health detection, Arabic remains significantly underexplored, partly due\nto the scarcity of annotated datasets. We present CARMA, the first\nautomatically annotated large-scale dataset of Arabic Reddit posts. The dataset\nencompasses six mental health conditions, such as Anxiety, Autism, and\nDepression, and a control group. CARMA surpasses existing resources in both\nscale and diversity. We conduct qualitative and quantitative analyses of\nlexical and semantic differences between users, providing insights into the\nlinguistic markers of specific mental health conditions. To demonstrate the\ndataset's potential for further mental health analysis, we perform\nclassification experiments using a range of models, from shallow classifiers to\nlarge language models. Our results highlight the promise of advancing mental\nhealth detection in underrepresented languages such as Arabic.", "AI": {"tldr": "本文介绍了CARMA，首个大规模自动标注的阿拉伯语Reddit帖子心理健康数据集，涵盖六种心理健康状况和对照组，旨在解决阿拉伯语心理健康检测中数据稀缺的挑战。", "motivation": "全球数百万人受精神疾病困扰，但早期检测仍是一大挑战，尤其对于阿拉伯语人群，资源有限且文化耻辱感阻碍了心理健康讨论。相较于英语，阿拉伯语心理健康检测研究严重不足，主要原因是缺乏标注数据集。", "method": "研究构建了CARMA数据集，这是一个大规模自动标注的阿拉伯语Reddit帖子数据集，包含焦虑、自闭症、抑郁症等六种心理健康状况和一个对照组。对用户间的词汇和语义差异进行了定性和定量分析，并使用从浅层分类器到大型语言模型等多种模型进行了分类实验，以展示数据集在心理健康分析方面的潜力。", "result": "CARMA在规模和多样性上均超越现有资源。分析揭示了特定心理健康状况的语言标记。分类实验结果表明，该数据集在推进阿拉伯语等代表性不足语言的心理健康检测方面具有巨大潜力。", "conclusion": "CARMA数据集的创建为阿拉伯语心理健康检测研究提供了宝贵资源，并展示了在缺乏代表性的语言中推进心理健康检测的广阔前景。"}}
{"id": "2511.03571", "categories": ["cs.RO", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.03571", "abs": "https://arxiv.org/abs/2511.03571", "authors": ["Hao Shi", "Ze Wang", "Shangwei Guo", "Mengfei Duan", "Song Wang", "Teng Chen", "Kailun Yang", "Lin Wang", "Kaiwei Wang"], "title": "OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera", "comment": "Datasets and code will be publicly available at\n  https://github.com/MasterHow/OneOcc", "summary": "Robust 3D semantic occupancy is crucial for legged/humanoid robots, yet most\nsemantic scene completion (SSC) systems target wheeled platforms with\nforward-facing sensors. We present OneOcc, a vision-only panoramic SSC\nframework designed for gait-introduced body jitter and 360{\\deg} continuity.\nOneOcc combines: (i) Dual-Projection fusion (DP-ER) to exploit the annular\npanorama and its equirectangular unfolding, preserving 360{\\deg} continuity and\ngrid alignment; (ii) Bi-Grid Voxelization (BGV) to reason in Cartesian and\ncylindrical-polar spaces, reducing discretization bias and sharpening\nfree/occupied boundaries; (iii) a lightweight decoder with Hierarchical AMoE-3D\nfor dynamic multi-scale fusion and better long-range/occlusion reasoning; and\n(iv) plug-and-play Gait Displacement Compensation (GDC) learning feature-level\nmotion correction without extra sensors. We also release two panoramic\noccupancy benchmarks: QuadOcc (real quadruped, first-person 360{\\deg}) and\nHuman360Occ (H3O) (CARLA human-ego 360{\\deg} with RGB, Depth, semantic\noccupancy; standardized within-/cross-city splits). OneOcc sets new\nstate-of-the-art (SOTA): on QuadOcc it beats strong vision baselines and\npopular LiDAR ones; on H3O it gains +3.83 mIoU (within-city) and +8.08\n(cross-city). Modules are lightweight, enabling deployable full-surround\nperception for legged/humanoid robots. Datasets and code will be publicly\navailable at https://github.com/MasterHow/OneOcc.", "AI": {"tldr": "OneOcc是一个为足式/人形机器人设计的纯视觉全景语义场景补全(SSC)框架，解决了步态引起的抖动和360度连续性问题，并通过多项创新技术实现了最先进的性能，并发布了两个新的全景占用基准。", "motivation": "现有的语义场景补全(SSC)系统主要针对配备前向传感器的轮式平台，但足式/人形机器人需要鲁棒的3D语义占用感知，并且面临步态引起的身体抖动和360度连续性感知挑战。", "method": "OneOcc框架结合了：(i) 双投影融合(DP-ER)，利用环形全景图及其等距矩形展开，保持360度连续性和网格对齐；(ii) 双网格体素化(BGV)，在笛卡尔和柱坐标空间中推理，减少离散化偏差并锐化边界；(iii) 带有分层AMoE-3D的轻量级解码器，用于动态多尺度融合和更好的长距离/遮挡推理；(iv) 即插即用的步态位移补偿(GDC)模块，无需额外传感器即可学习特征级运动校正。此外，论文还发布了两个全景占用基准：QuadOcc（真实四足机器人）和Human360Occ (H3O)（CARLA人形机器人）。", "result": "OneOcc在QuadOcc基准上超越了强大的视觉基线和流行的激光雷达基线，在H3O上实现了+3.83 mIoU（城内）和+8.08 mIoU（跨城）的显著提升，达到了新的最先进(SOTA)水平。所有模块都轻量化，使得该系统能够部署在足式/人形机器人上，实现全方位感知。", "conclusion": "OneOcc提供了一个鲁棒、轻量级且可部署的纯视觉全景语义场景补全解决方案，特别适用于足式/人形机器人，能够克服步态抖动并提供360度连续感知。其高性能和轻量化特性使其成为未来机器人全方位感知的关键技术。"}}
{"id": "2511.03249", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03249", "abs": "https://arxiv.org/abs/2511.03249", "authors": ["Gutierrez-Florensa", "F. Sanniti", "D. Tedeschi", "L. Sigrist", "A. Ortega", "F. Milano"], "title": "Theoretical and Experimental Limitations of RoCoF Estimation", "comment": null, "summary": "A precise estimation of the Rate of Change of Frequency (RoCoF) is crucial\nfor secure power system operation. In fact, RoCoF is strictly related to the\namount of the available physical and/or virtual inertia of the system and the\nseverity of the active power unbalance following a disturbance. For this\nreason, it is widely exploited in different protection systems, e.g.,\nAnti-Islanding, Under Frequency Load Shedding (UFLS) and wide-area protection\nsystems. The new paradigm of modern power systems, with a low-inertia and\nconverter-based generation assets, is increasing the transient severity, making\nthe frequency and the RoCoF estimation more complex and less precise for the\nactual devices. This work addresses this issue by proposing a numerically\nrobust approach based on concepts inherited from differential geometry and\nfluid mechanics. The proposed approach is then tested with high-sampling real\nexperimental measurements and used to develop a faster control logic for a\nRoCoF-based UFLS control scheme. The proposed approach provides information to\nprotections regarding the nature of the contingency which can be used to\nimprove its response.", "AI": {"tldr": "本文提出了一种基于微分几何和流体力学概念的数值鲁棒方法，用于精确估计现代低惯量电力系统中的频率变化率（RoCoF），并通过实际测量进行测试，以开发更快的RoCoF-UFLS控制方案。", "motivation": "RoCoF对电力系统安全运行至关重要，广泛应用于反孤岛、低频减载（UFLS）等保护系统。然而，现代电力系统低惯量和基于变流器的发电设备增加了瞬态的严重性，使得现有设备的频率和RoCoF估计变得复杂且不精确。", "method": "提出了一种数值鲁棒的方法，其概念源于微分几何和流体力学。该方法通过高采样率的实际实验测量数据进行测试，并用于开发基于RoCoF的UFLS控制方案的更快控制逻辑。", "result": "所提出的方法能够为保护系统提供有关突发事件性质的信息，从而改善其响应。它还能够开发出更快的RoCoF-UFLS控制逻辑。", "conclusion": "该研究成功解决了现代电力系统中RoCoF估计的挑战，提供了一种精确且鲁棒的方法，能够提高保护系统的响应速度，并为UFLS控制方案提供更快、更准确的决策支持。"}}
{"id": "2511.03297", "categories": ["eess.SY", "cs.GT", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.03297", "abs": "https://arxiv.org/abs/2511.03297", "authors": ["Leonardo Pedroso", "Andrea Agazzi", "W. P. M. H. Heemels", "Mauro Salazar"], "title": "Evolutionary Dynamics in Continuous-time Finite-state Mean Field Games -- Part II: Stability", "comment": null, "summary": "We study a dynamic game with a large population of players who choose actions\nfrom a finite set in continuous time. Each player has a state in a finite state\nspace that evolves stochastically with their actions. A player's reward depends\nnot only on their own state and action but also on the distribution of states\nand actions across the population, capturing effects such as congestion in\ntraffic networks. In Part I, we introduced an evolutionary model and a new\nsolution concept - the mixed stationary Nash Equilibrium (MSNE) - which\ncoincides with the rest points of the mean field evolutionary model under\nmeaningful families of revision protocols. In this second part, we investigate\nthe evolutionary stability of MSNE. We derive conditions on both the structure\nof the MSNE and the game's payoff map that ensure local and global stability\nunder evolutionary dynamics. These results characterize when MSNE can robustly\nemerge and persist against strategic deviations, thereby providing insight into\nits long-term viability in large population dynamic games.", "AI": {"tldr": "本文研究了大规模动态博弈中混合平稳纳什均衡（MSNE）的演化稳定性，并导出了确保其在演化动力学下局部和全局稳定性的条件。", "motivation": "研究动机是为了理解MSNE（在第一部分中引入的解决方案概念）何时能在大规模动态博弈中稳健地出现和持续存在，从而深入了解其长期可行性。", "method": "本文调查了MSNE的演化稳定性。它在MSNE的结构和博弈的收益图上推导了确保其在演化动力学下局部和全局稳定性的条件。这项工作建立在第一部分引入的演化模型和MSNE概念之上。", "result": "研究导出了MSNE在演化动力学下实现局部和全局稳定性的条件，这些条件取决于MSNE的结构和博弈的收益图。", "conclusion": "这些结果描述了MSNE何时能够稳健地出现并抵抗策略性偏差而持续存在，从而为MSNE在这种大规模动态博弈中的长期可行性提供了见解。"}}
{"id": "2511.03121", "categories": ["cs.CL", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.03121", "abs": "https://arxiv.org/abs/2511.03121", "authors": ["Yuya Miyaoka", "Masaki Inoue"], "title": "Control Barrier Function for Aligning Large Language Models", "comment": null, "summary": "This paper proposes a control-based framework for aligning large language\nmodels (LLMs) by leveraging a control barrier function (CBF) to ensure\nuser-desirable text generation. The presented framework applies the CBF safety\nfilter to the predicted token generated from the baseline LLM, to intervene in\nthe generated text. The safety filter includes two significant advantages: this\nsafety filter is an add-on type, allowing it to be used for alignment purposes\nwithout fine-tuning the baseline LLM, and if there is an evaluation model\nregarding the desired alignment, it can be directly applied to the filter\ndesign. The overall text-generation system is implemented with open-source\nlanguage models, aiming to generate positive text.", "AI": {"tldr": "本文提出一个基于控制的框架，利用控制障碍函数（CBF）来对大型语言模型（LLM）进行对齐，以确保生成用户期望的文本，且无需微调基线LLM。", "motivation": "动机是使大型语言模型能够生成用户期望的文本（例如积极文本），同时避免对现有LLM进行耗时的微调。", "method": "该研究提出一个基于控制的框架，将控制障碍函数（CBF）作为安全过滤器应用于基线LLM预测的token，从而干预生成的文本。该安全过滤器是附加式的，允许在不微调基线LLM的情况下用于对齐目的，并且可以直接将评估模型用于过滤器设计。整个系统使用开源语言模型实现，目标是生成积极文本。", "result": "该框架能够确保生成用户期望的文本（例如积极文本）。其安全过滤器具有两个显著优势：一是作为附加组件，无需微调基线LLM即可用于对齐；二是如果存在关于期望对齐的评估模型，可以直接应用于过滤器设计。", "conclusion": "该论文成功提出了一种基于控制障碍函数（CBF）的框架，通过安全过滤器对大型语言模型进行对齐，有效确保生成用户期望的文本。该方法无需微调基线模型，并能直接利用评估模型进行过滤器设计，在生成积极文本方面展示了其可行性。"}}
{"id": "2511.03181", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03181", "abs": "https://arxiv.org/abs/2511.03181", "authors": ["Rewida Ali", "Cristian C. Beltran-Hernandez", "Weiwei Wan", "Kensuke Harada"], "title": "Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control", "comment": null, "summary": "Human-robot cooperation is essential in environments such as warehouses and\nretail stores, where workers frequently handle deformable objects like paper,\nbags, and fabrics. Coordinating robotic actions with human assistance remains\ndifficult due to the unpredictable dynamics of deformable materials and the\nneed for adaptive force control. To explore this challenge, we focus on the\ntask of gift wrapping, which exemplifies a long-horizon manipulation problem\ninvolving precise folding, controlled creasing, and secure fixation of paper.\nSuccess is achieved when the robot completes the sequence to produce a neatly\nwrapped package with clean folds and no tears.\n  We propose a learning-based framework that integrates a high-level task\nplanner powered by a large language model (LLM) with a low-level hybrid\nimitation learning (IL) and reinforcement learning (RL) policy. At its core is\na Sub-task Aware Robotic Transformer (START) that learns a unified policy from\nhuman demonstrations. The key novelty lies in capturing long-range temporal\ndependencies across the full wrapping sequence within a single model. Unlike\nvanilla Action Chunking with Transformer (ACT), typically applied to short\ntasks, our method introduces sub-task IDs that provide explicit temporal\ngrounding. This enables robust performance across the entire wrapping process\nand supports flexible execution, as the policy learns sub-goals rather than\nmerely replicating motion sequences.\n  Our framework achieves a 97% success rate on real-world wrapping tasks. We\nshow that the unified transformer-based policy reduces the need for specialized\nmodels, allows controlled human supervision, and effectively bridges high-level\nintent with the fine-grained force control required for deformable object\nmanipulation.", "AI": {"tldr": "本文提出了一个学习框架，结合大型语言模型（LLM）的高级规划和混合模仿学习/强化学习（IL/RL）的低级策略，通过引入子任务感知的机器人Transformer（START）模型，成功实现了97%的机器人自动礼品包装成功率，有效处理了可变形物体的长期操作挑战。", "motivation": "在仓库和零售店等环境中，工人经常处理纸张、袋子和织物等可变形物体，人机协作至关重要。然而，由于可变形材料不可预测的动态特性以及对自适应力控制的需求，协调机器人行动与人类协助仍然困难。礼品包装任务是一个典型的长期操作问题，涉及精确折叠、受控压痕和固定纸张，是探索这一挑战的理想范例。", "method": "本文提出了一个学习框架，该框架将由大型语言模型（LLM）驱动的高级任务规划器与低级混合模仿学习（IL）和强化学习（RL）策略相结合。其核心是子任务感知机器人Transformer（START），它从人类演示中学习统一策略。关键创新在于在一个模型中捕获整个包装序列的长期时间依赖性，并通过引入子任务ID提供明确的时间定位，使策略能够学习子目标而非简单复制运动序列。", "result": "该框架在真实世界的包装任务中实现了97%的成功率。研究表明，统一的基于Transformer的策略减少了对专业模型的依赖，允许受控的人类监督，并有效连接了高级意图与可变形物体操作所需的精细力控制。", "conclusion": "所提出的学习框架通过其统一的、基于Transformer的策略，成功解决了机器人处理可变形物体（如礼品包装）的长期操作挑战。它证明了LLM驱动的高级规划与子任务感知的低级策略相结合的有效性，为未来人机协作和复杂可变形物体操作提供了新的解决方案。"}}
{"id": "2511.03004", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03004", "abs": "https://arxiv.org/abs/2511.03004", "authors": ["Dakota Hester", "Vitor S. Martins", "Lucas B. Ferreira", "Thainara M. A. Lima"], "title": "Learning with less: label-efficient land cover classification at very high spatial resolution using self-supervised deep learning", "comment": "25 pages, 11 figures. Submitted in Science of Remote Sensing", "summary": "Deep learning semantic segmentation methods have shown promising performance\nfor very high 1-m resolution land cover classification, but the challenge of\ncollecting large volumes of representative training data creates a significant\nbarrier to widespread adoption of such models for meter-scale land cover\nmapping over large areas. In this study, we present a novel label-efficient\napproach for statewide 1-m land cover classification using only 1,000 annotated\nreference image patches with self-supervised deep learning. We use the\n\"Bootstrap Your Own Latent\" pre-training strategy with a large amount of\nunlabeled color-infrared aerial images (377,921 256x256 1-m pixel patches) to\npre-train a ResNet-101 convolutional encoder. The learned encoder weights were\nsubsequently transferred into multiple deep semantic segmentation architectures\n(FCN, U-Net, Attention U-Net, DeepLabV3+, UPerNet, PAN), which were then\nfine-tuned using very small training dataset sizes with cross-validation (250,\n500, 750 patches). Among the fine-tuned models, we obtained the 87.14% overall\naccuracy and 75.58% macro F1 score using an ensemble of the best performing\nU-Net models for comprehensive 1-m, 8-class land cover mapping, covering more\nthan 123 billion pixels over the state of Mississippi, USA. Detailed\nqualitative and quantitative analysis revealed accurate mapping of open water\nand forested areas, while highlighting challenges in accurate delineation\nbetween cropland, herbaceous, and barren land cover types. These results show\nthat self-supervised learning is an effective strategy for reducing the need\nfor large volumes of manually annotated data, directly addressing a major\nlimitation to high spatial resolution land cover mapping at scale.", "AI": {"tldr": "本研究提出了一种标签高效的方法，利用自监督学习和少量标注数据（仅1000个图像块）实现了密西西比州1米分辨率的大规模土地覆盖分类，解决了深度学习模型对大量训练数据需求的问题。", "motivation": "深度学习语义分割在1米分辨率土地覆盖分类中表现出色，但收集大量代表性训练数据的挑战是其在大面积米级土地覆盖制图中广泛应用的重大障碍。", "method": "研究采用“Bootstrap Your Own Latent”（BYOL）自监督预训练策略，利用大量未标注的彩色红外航空影像（377,921个256x256 1米像素块）预训练一个ResNet-101卷积编码器。随后，将学习到的编码器权重迁移到多种深度语义分割架构（FCN, U-Net, Attention U-Net, DeepLabV3+, UPerNet, PAN），并使用非常小的训练数据集（250、500、750个图像块）进行交叉验证微调。最终，使用表现最佳的U-Net模型集成进行预测。", "result": "通过最佳U-Net模型的集成，在密西西比州实现了1米分辨率、8类土地覆盖制图，覆盖超过1230亿像素，获得了87.14%的总体准确率和75.58%的宏观F1分数。定性和定量分析表明，开放水域和森林区域的制图准确，但在耕地、草本植物和贫瘠土地类型之间的准确划分仍面临挑战。", "conclusion": "这些结果表明，自监督学习是有效减少手动标注数据需求的一种策略，直接解决了高空间分辨率大规模土地覆盖制图的主要限制。"}}
{"id": "2511.03014", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03014", "abs": "https://arxiv.org/abs/2511.03014", "authors": ["Minh Sao Khue Luu", "Bair N. Tuchinov"], "title": "A Foundation Model for Brain MRI with Dynamic Modality Integration", "comment": "Preliminary work; results ongoing", "summary": "We present a foundation model for brain MRI that can work with different\ncombinations of imaging sequences. The model uses one encoder with learnable\nmodality embeddings, conditional layer normalization, and a masked autoencoding\nobjective that accounts for missing modalities. A variance-covariance\nregularizer is applied to stabilize feature learning and improve representation\ndiversity. This design removes the need for separate models for each modality\nand allows the network to adapt when some sequences are missing or unseen. It\nis trained on about 60,000 multi-center MRIs using self-supervised\nreconstruction and modality imputation to learn flexible representations. A\nlearnable modality embedding guides feature extraction so the encoder can\nadjust to different inputs. We describe our planned evaluation on brain tumor\nand multiple sclerosis segmentation, as well as lesion classification, under\nvarious modality settings. Preliminary results show that the method works\nfeasibly, and further experiments are planned to study its performance in more\ndetail. All code and pretrained models are available at\nhttps://github.com/BrainFM/brainfm", "AI": {"tldr": "本文提出了一种用于脑部MRI的基础模型，该模型能处理不同成像序列组合，包括缺失模态。它使用一个带有可学习模态嵌入、条件层归一化和掩蔽自编码目标的编码器，并通过方差-协方差正则化来稳定特征学习。该模型在6万张多中心MRI数据上进行自监督训练，初步结果显示其可行性。", "motivation": "现有方法通常需要为每种MRI模态建立单独模型，并且难以处理某些序列缺失或未见的情况，限制了模型的灵活性和泛化能力。", "method": "该模型采用单一编码器架构，结合可学习的模态嵌入和条件层归一化。它使用掩蔽自编码目标来处理缺失模态，并通过方差-协方差正则器来稳定特征学习并增加表示多样性。模型在约60,000张多中心MRI数据上进行自监督重建和模态插补训练，以学习灵活的表示。", "result": "初步结果显示该方法是可行的。作者计划在脑肿瘤和多发性硬化症分割以及病灶分类任务上，在各种模态设置下进行进一步的详细评估。所有代码和预训练模型均已公开。", "conclusion": "所提出的脑部MRI基础模型能够灵活处理不同成像序列组合及缺失模态，通过其独特设计（如模态嵌入和掩蔽自编码）实现了单模型处理多模态的能力。初步实验证明了其可行性，未来将进行更全面的性能评估。"}}
{"id": "2511.03137", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03137", "abs": "https://arxiv.org/abs/2511.03137", "authors": ["Shipeng Cen", "Ying Tan"], "title": "Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks", "comment": null, "summary": "As optimization problems grow increasingly complex and diverse, advancements\nin optimization techniques and paradigm innovations hold significant\nimportance. The challenges posed by optimization problems are primarily\nmanifested in their non-convexity, high-dimensionality, black-box nature, and\nother unfavorable characteristics. Traditional zero-order or first-order\nmethods, which are often characterized by low efficiency, inaccurate gradient\ninformation, and insufficient utilization of optimization information, are\nill-equipped to address these challenges effectively. In recent years, the\nrapid development of large language models (LLM) has led to substantial\nimprovements in their language understanding and code generation capabilities.\nConsequently, the design of optimization algorithms leveraging large language\nmodels has garnered increasing attention from researchers. In this study, we\nchoose the fireworks algorithm(FWA) as the basic optimizer and propose a novel\napproach to assist the design of the FWA by incorporating multi-modal large\nlanguage model(MLLM). To put it simply, we propose the concept of Critical\nPart(CP), which extends FWA to complex high-dimensional tasks, and further\nutilizes the information in the optimization process with the help of the\nmulti-modal characteristics of large language models. We focus on two specific\ntasks: the \\textit{traveling salesman problem }(TSP) and \\textit{electronic\ndesign automation problem} (EDA). The experimental results show that FWAs\ngenerated under our new framework have achieved or surpassed SOTA results on\nmany problem instances.", "AI": {"tldr": "本研究提出了一种利用多模态大语言模型（MLLM）辅助设计烟花算法（FWA）的新框架，通过引入“关键部分”（CP）概念，有效解决了复杂高维优化问题，并在旅行商问题（TSP）和电子设计自动化（EDA）问题上取得了超越或达到SOTA的结果。", "motivation": "优化问题日益复杂多样，表现出非凸性、高维度、黑盒等挑战。传统零阶或一阶方法效率低、梯度信息不准、优化信息利用不足，难以有效应对。近年来，大语言模型（LLM）在语言理解和代码生成方面取得显著进展，为优化算法设计提供了新思路。", "method": "本研究选择烟花算法（FWA）作为基础优化器，并提出了一种新方法，通过结合多模态大语言模型（MLLM）辅助FWA的设计。具体而言，引入了“关键部分”（CP）概念，将FWA扩展到复杂高维任务，并利用MLLM的多模态特性来更好地利用优化过程中的信息。研究重点关注旅行商问题（TSP）和电子设计自动化（EDA）问题。", "result": "实验结果表明，在该新框架下生成的烟花算法（FWA）在许多问题实例上达到了或超越了当前最先进（SOTA）的结果。", "conclusion": "本研究成功展示了多模态大语言模型在辅助设计优化算法方面的潜力，特别是通过引入“关键部分”概念，显著提升了烟花算法在复杂高维问题（如TSP和EDA）上的性能，取得了优异的成果。"}}
{"id": "2511.03108", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03108", "abs": "https://arxiv.org/abs/2511.03108", "authors": ["Azim Ospanov", "Farzan Farnia", "Roozbeh Yousefzadeh"], "title": "miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward", "comment": null, "summary": "We perform a thorough analysis of the formal and informal statements in the\nminiF2F benchmark from the perspective of an AI system that is tasked to\nparticipate in a math Olympiad consisting of the problems in miniF2F. In such\nsetting, the model has to read and comprehend the problems in natural language,\nformalize them in Lean language, then proceed with proving the problems, and it\nwill get credit for each problem if the formal proof corresponds to the\noriginal informal statement presented to the model. Our evaluation results\nreveal that the best accuracy of such pipeline can be about 36% using the SoTA\nmodels in the literature, considerably lower than the individual SoTA\naccuracies, 97% and 69% reported in the autoformalization and theorem proving\nliterature. Analyzing the failure modes, we trace back a considerable portion\nof this drop to discrepancies between the formal and informal statements for\nmore than half of the problems in miniF2F. We proceed with correcting all the\nerrors, discrepancies and simplifications in formal and informal statements,\nand present the miniF2F-v2 with fully verified formal and informal statements\nand proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to\nthe best accuracy of 70%, a significant improvement from the 40% on the\noriginal miniF2F, yet indicating considerable misalignment between the\nautoformalization models and theorem provers. Our deep analysis suggests that a\nhigher quality benchmark can help the community better evaluate progress in the\nfield of formal reasoning and also better diagnose the failure and success\nmodes of autoformalization and theorem proving models. Our dataset is available\nat https://github.com/roozbeh-yz/miniF2F_v2.", "AI": {"tldr": "本文对miniF2F基准测试进行了深入分析，发现其形式化和非形式化陈述存在大量不一致。通过纠正这些问题，作者创建了miniF2F-v2，并在此新基准上将AI定理证明管线的准确率从36%（原miniF2F的40%）提高到70%，强调了高质量基准对评估和诊断AI形式化推理模型的重要性。", "motivation": "在数学奥林匹克竞赛场景中，AI系统需要理解自然语言问题、将其形式化为Lean语言并进行证明。尽管现有自动形式化和定理证明模型的个体准确率很高（分别为97%和69%），但当它们整合到一个完整的管线中解决miniF2F问题时，整体准确率却非常低（约36%）。这促使研究人员深入分析这种性能下降的原因。", "method": "研究人员首先从AI系统的角度对miniF2F基准中的形式化和非形式化陈述进行了全面分析。他们评估了最先进（SoTA）模型在该管线上的表现，并分析了失败模式。通过追溯，他们发现性能下降很大一部分源于miniF2F中超过一半问题在形式化和非形式化陈述之间的不一致。随后，他们纠正了所有错误、不一致和简化，创建了miniF2F-v2，其中包含经过完全验证的形式化和非形式化陈述及证明。最后，他们在新基准miniF2F-v2上重新评估了完整的定理证明管线。", "result": "在原始miniF2F上，使用SoTA模型的完整管线准确率约为36%（论文中也提到40%，可能指特定配置下的最佳值）。分析发现，大部分性能下降归因于miniF2F中超过一半问题的形式化和非形式化陈述之间的差异。经过纠正后，miniF2F-v2被创建。在miniF2F-v2上评估，完整定理证明管线的最佳准确率达到了70%，相较于原始miniF2F的40%（或36%）有显著提升，但仍表明自动形式化模型和定理证明器之间存在相当大的未对齐。", "conclusion": "高质量的基准测试对于社区更好地评估形式化推理领域的进展至关重要。例如miniF2F-v2这样的改进基准，可以帮助更准确地诊断自动形式化和定理证明模型的失败和成功模式，从而推动该领域的发展。"}}
{"id": "2511.03189", "categories": ["cs.RO", "cs.HC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.03189", "abs": "https://arxiv.org/abs/2511.03189", "authors": ["Zeqing Zhang", "Weifeng Lu", "Lei Yang", "Wei Jing", "Bowei Tang", "Jia Pan"], "title": "Collaborative Assembly Policy Learning of a Sightless Robot", "comment": "Accepted by IEEE ROBIO 2025", "summary": "This paper explores a physical human-robot collaboration (pHRC) task\ninvolving the joint insertion of a board into a frame by a sightless robot and\na human operator. While admittance control is commonly used in pHRC tasks, it\ncan be challenging to measure the force/torque applied by the human for\naccurate human intent estimation, limiting the robot's ability to assist in the\ncollaborative task. Other methods that attempt to solve pHRC tasks using\nreinforcement learning (RL) are also unsuitable for the board-insertion task\ndue to its safety constraints and sparse rewards. Therefore, we propose a novel\nRL approach that utilizes a human-designed admittance controller to facilitate\nmore active robot behavior and reduce human effort. Through simulation and\nreal-world experiments, we demonstrate that our approach outperforms admittance\ncontrol in terms of success rate and task completion time. Additionally, we\nobserved a significant reduction in measured force/torque when using our\nproposed approach compared to admittance control. The video of the experiments\nis available at https://youtu.be/va07Gw6YIog.", "AI": {"tldr": "本文提出了一种新颖的强化学习（RL）方法，结合了人类设计的导纳控制器，用于解决人机协作（pHRC）中的盲机器人与人类共同插入板的任务，旨在提高任务成功率、缩短完成时间并减少人类劳力。", "motivation": "传统的导纳控制难以准确测量人类施加的力/扭矩以估计意图，从而限制了机器人的协助能力。而现有的强化学习方法因安全约束和稀疏奖励，不适用于板插入这类pHRC任务。", "method": "提出了一种新颖的强化学习（RL）方法，该方法利用人类设计的导纳控制器来促进机器人更主动的行为，并减少人类的努力。", "result": "通过仿真和真实世界实验，证明所提出的方法在成功率和任务完成时间方面优于传统的导纳控制。此外，与导纳控制相比，该方法显著降低了测量的力/扭矩。", "conclusion": "所提出的结合人类设计导纳控制器的RL方法，能够有效解决人机协作中的板插入任务，不仅提高了任务性能，还显著减轻了人类的负担。"}}
{"id": "2511.03146", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03146", "abs": "https://arxiv.org/abs/2511.03146", "authors": ["Kaiyuan Zhang", "Chenghao Yang", "Zhoufutu Wen", "Sihang Yuan", "Qiuyue Wang", "Chaoyi Huang", "Guosheng Zhu", "He Wang", "Huawenyu Lu", "Jianing Wen", "Jianpeng Jiao", "Lishu Luo", "Longxiang Liu", "Sijin Wu", "Xiaolei Zhu", "Xuanliang Zhang", "Ge Zhang", "Yi Lin", "Guang Shi", "Chaoyou Fu", "Wenhao Huang"], "title": "MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity", "comment": null, "summary": "As reasoning models scale rapidly, the essential role of multimodality in\nhuman cognition has come into sharp relief, driving a growing need to probe\nvision-centric cognitive behaviors. Yet, existing multimodal benchmarks either\noveremphasize textual reasoning or fall short of systematically capturing\nvision-centric cognitive behaviors, leaving the cognitive capacity of MLLMs\ninsufficiently assessed. To address this limitation, we introduce MME-CC\n(Multi-Modal Evaluation benchmark of Cognitive Capacity), a vision-grounded\nbenchmark that organizes 11 representative reasoning tasks into three\nfundamental categories of visual information: spatial, geometric, and\nknowledge-based reasoning, and provides fine-grained analyses of MLLMs'\ncognitive capacity across these dimensions. Based on MME-CC, we conduct\nextensive experiments over 16 representative MLLMs. Our study reveals that\nclosed-source models currently lead overall (e.g., 42.66 for Gemini-2.5-Pro vs.\n30.45 for GLM-4.5V), while spatial and geometric reasoning remain broadly weak\n(less than or equal to 30%). We further identify common error patterns,\nincluding orientation mistakes, fragile cross-view identity persistence, and\npoor adherence to counterfactual instructions, and observe that\nChain-of-Thought typically follows a three-stage process (extract -> reason ->\nverify) with heavy reliance on visual extraction. We hope this work catalyzes a\nshift toward treating the cognitive capacity of MLLMs as central to both\nevaluation and model design.", "AI": {"tldr": "MME-CC是一个新的以视觉为中心的基准，用于系统评估多模态大语言模型（MLLMs）在空间、几何和知识推理方面的认知能力，并揭示了现有模型的弱点和错误模式。", "motivation": "随着推理模型规模的扩大，多模态在人类认知中的重要性日益凸显，促使人们需要探究以视觉为中心的认知行为。然而，现有多模态基准要么过分强调文本推理，要么未能系统捕捉以视觉为中心的认知行为，导致MLLMs的认知能力评估不足。", "method": "引入了MME-CC基准，该基准将11个代表性推理任务组织成空间、几何和知识型推理三大视觉信息类别。基于MME-CC，对16个代表性MLLMs进行了广泛实验，并进行了细粒度分析，识别了常见的错误模式，并观察了思维链（CoT）过程。", "result": "研究发现，闭源模型目前总体领先（例如Gemini-2.5-Pro vs. GLM-4.5V），而空间和几何推理能力普遍较弱（得分≤30%）。常见的错误模式包括方向错误、跨视图身份持久性脆弱以及对反事实指令依从性差。思维链通常遵循“提取→推理→验证”的三阶段过程，并严重依赖视觉提取。", "conclusion": "本工作旨在促使将MLLMs的认知能力视为评估和模型设计的核心，以推动该领域的发展。"}}
{"id": "2511.03019", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03019", "abs": "https://arxiv.org/abs/2511.03019", "authors": ["Wenbo Lu"], "title": "SLIP: Structural-aware Language-Image Pretraining for Vision-Language Alignment", "comment": "Capstone Paper", "summary": "Vision-Language Pretraining (VLP) has achieved remarkable success across\nvarious downstream tasks, but such gains are largely driven by scaling up on\ntraining data. Yet, literature methods treat image-text pairs as isolated\ntraining examples; this neglects the rich relational structure naturally\npresent in many domains, such as e-commerce product co-purchase graphs and\nsocial recommendation networks. Inspired by neuroscientific evidence that human\nencodes knowledge as relationship cognitive maps, we introduce Structure-aware\nLanguage-Image Pretraining (SLIP). SLIP integrates a structural contrastive\nloss to align modalities while also modeling relationships between neighboring\nentities in a structured graph. To support this paradigm, we construct a\nlarge-scale Amazon Product Co-purchase Multimodal Graph Dataset, enabling\nstructured cross-modality supervision at scale. Experiment results show that\nSLIP consistently outperforms CLIP on cross-modal retrieval and classification\ntasks in both zero-shot and few-shot settings, showing the value of relational\nsupervision for cross-modal alignment.", "AI": {"tldr": "该论文提出了结构感知语言-图像预训练（SLIP）模型，通过整合结构对比损失来对齐多模态，并建模实体间的关系。SLIP在亚马逊商品共购多模态图数据集上训练，在跨模态检索和分类任务上显著优于CLIP，证明了关系监督的价值。", "motivation": "现有的视觉-语言预训练（VLP）模型虽然成功，但主要依赖于大规模数据，并将图像-文本对视为独立的训练样本，忽略了许多领域（如电子商务共购图、社交推荐网络）中自然存在的丰富关系结构。受人类将知识编码为关系认知图的神经科学证据启发，研究旨在将这种结构信息引入VLP。", "method": "引入结构感知语言-图像预训练（SLIP）模型。SLIP集成了一个结构对比损失，旨在对齐不同模态，同时对结构化图中相邻实体之间的关系进行建模。为支持此范式，构建了一个大规模的亚马逊商品共购多模态图数据集，以实现大规模的结构化跨模态监督。", "result": "实验结果表明，SLIP在零样本和少样本设置下的跨模态检索和分类任务中，始终优于CLIP模型。这证明了关系监督对于跨模态对齐的有效性。", "conclusion": "该研究得出结论，将关系结构信息整合到视觉-语言预训练中具有显著价值。通过引入结构感知语言-图像预训练（SLIP）模型和大规模结构化数据集，证明了关系监督能够有效提升跨模态对齐任务的性能。"}}
{"id": "2511.03152", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03152", "abs": "https://arxiv.org/abs/2511.03152", "authors": ["Srishti Yadav", "Jasmina Gajcin", "Erik Miehling", "Elizabeth Daly"], "title": "Who Sees the Risk? Stakeholder Conflicts and Explanatory Policies in LLM-based Risk Assessment", "comment": null, "summary": "Understanding how different stakeholders perceive risks in AI systems is\nessential for their responsible deployment. This paper presents a framework for\nstakeholder-grounded risk assessment by using LLMs, acting as judges to predict\nand explain risks. Using the Risk Atlas Nexus and GloVE explanation method, our\nframework generates stakeholder-specific, interpretable policies that shows how\ndifferent stakeholders agree or disagree about the same risks. We demonstrate\nour method using three real-world AI use cases of medical AI, autonomous\nvehicles, and fraud detection domain. We further propose an interactive\nvisualization that reveals how and why conflicts emerge across stakeholder\nperspectives, enhancing transparency in conflict reasoning. Our results show\nthat stakeholder perspectives significantly influence risk perception and\nconflict patterns. Our work emphasizes the importance of these\nstakeholder-aware explanations needed to make LLM-based evaluations more\ntransparent, interpretable, and aligned with human-centered AI governance\ngoals.", "AI": {"tldr": "本文提出一个基于大型语言模型（LLM）的利益相关者风险评估框架，通过生成可解释的、特定于利益相关者的政策，并可视化冲突，以提高AI系统风险评估的透明度和对齐性。", "motivation": "为了负责任地部署AI系统，理解不同利益相关者如何感知AI系统中的风险至关重要。", "method": "研究采用LLM作为“判断者”来预测和解释风险，并结合Risk Atlas Nexus和GloVE解释方法，生成特定于利益相关者的可解释政策。该方法在医疗AI、自动驾驶和欺诈检测三个真实AI用例中进行了演示。此外，还提出了一个交互式可视化工具来揭示冲突的产生原因和方式。", "result": "研究结果表明，利益相关者的视角显著影响风险感知和冲突模式。", "conclusion": "工作强调了以利益相关者为中心的解释的重要性，以使基于LLM的评估更加透明、可解释，并符合以人为中心的AI治理目标。"}}
{"id": "2511.03366", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03366", "abs": "https://arxiv.org/abs/2511.03366", "authors": ["Kapila W. S. Palitharathna", "Constantinos Psomas", "Ioannis Krikidis"], "title": "Lightwave Power Transfer-Enabled Underwater Optical ISAC Systems under Ship Attitude Variation", "comment": "This paper has been submitted to the IEEE International Conference on\n  Communications (ICC 2026) conference", "summary": "In this paper, we propose a lightwave power transfer-enabled underwater\noptical integrated sensing and communication (O-ISAC) system, where an access\npoint (AP) mounted on a seasurface ship transmits lightwave signals to two\nnodes, namely ($i$) a seabed sensor that harvests energy and transmits uplink\ninformation to the AP, and ($ii$) a sensing target whose position is estimated\nby the AP using an array of pinhole cameras. To capture practical deployment\nconditions, the ship attitude variation is modeled through its roll, pitch, and\nyaw angles, each following a Gaussian distribution under low-to-moderate sea\nstates. Closed-form approximations are derived for the mean squared error (MSE)\nof target localization and the achievable uplink data rate. Analytical and\nsimulation results demonstrate excellent agreement, validating the proposed\nmodels and derived expressions, while revealing the fundamental\ncommunication-sensing tradeoff in the O-ISAC system. The results further\nprovide valuable design insights, including the optimal camera placement on the\nship to minimize localization error, achieving a minimum MSE of $10^{-2}$\n$\\text{m}^2$ with multiple cameras under roll, pitch, and yaw angle variation\nof $10^{\\circ}$, and the optimal harvest-use ratio of $0.55$ for the considered\nsetup.", "AI": {"tldr": "本文提出了一种光波能量传输驱动的水下光集成传感与通信（O-ISAC）系统，该系统能为海底传感器供能并实现上行通信，同时通过船载针孔摄像头阵列估计水下目标位置，并考虑了船体姿态变化对系统性能的影响。", "motivation": "在实际部署条件下，水下传感器的能量供给和信息传输面临挑战，同时需要精确地定位水下目标。现有系统可能未充分考虑船体姿态变化等实际因素对水下O-ISAC系统通信和传感性能的影响。", "method": "研究人员提出了一种O-ISAC系统，其中海面船只上的接入点向海底传感器（能量收集和上行通信）和传感目标（位置估计）传输光波信号。为了模拟实际部署，船体姿态（横摇、纵摇、偏航角）被建模为在低到中等海况下遵循高斯分布。针对目标定位的均方误差（MSE）和可实现的上行数据速率，推导了闭式近似表达式，并通过分析和仿真结果进行验证。", "result": "分析和仿真结果显示出极好的一致性，验证了所提出的模型和推导的表达式。研究揭示了O-ISAC系统中固有的通信-传感权衡。结果还提供了宝贵的设计见解，包括优化船上摄像头位置以最小化定位误差（在横摇、纵摇、偏航角变化10°时，多摄像头可实现10^-2 m^2的最小MSE），以及所考虑设置下0.55的最佳能量收集-使用比率。", "conclusion": "该研究成功地提出并验证了一种光波能量传输驱动的水下O-ISAC系统，并考虑了船体姿态变化。研究不仅揭示了通信-传感权衡，还为实际系统设计提供了关键的优化指导，例如最佳摄像头放置和能量利用效率，从而提高了水下传感和通信的鲁棒性和性能。"}}
{"id": "2511.03138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03138", "abs": "https://arxiv.org/abs/2511.03138", "authors": ["Qi Li", "Jianjun Xu", "Pingtao Wei", "Jiu Li", "Peiqiang Zhao", "Jiwei Shi", "Xuan Zhang", "Yanhui Yang", "Xiaodong Hui", "Peng Xu", "Wenqin Shao"], "title": "A Proprietary Model-Based Safety Response Framework for AI Agents", "comment": null, "summary": "With the widespread application of Large Language Models (LLMs), their\nassociated security issues have become increasingly prominent, severely\nconstraining their trustworthy deployment in critical domains. This paper\nproposes a novel safety response framework designed to systematically safeguard\nLLMs at both the input and output levels. At the input level, the framework\nemploys a supervised fine-tuning-based safety classification model. Through a\nfine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused\nAttention), it performs precise risk identification and differentiated handling\nof user queries, significantly enhancing risk coverage and business scenario\nadaptability, and achieving a risk recall rate of 99.3%. At the output level,\nthe framework integrates Retrieval-Augmented Generation (RAG) with a\nspecifically fine-tuned interpretation model, ensuring all responses are\ngrounded in a real-time, trustworthy knowledge base. This approach eliminates\ninformation fabrication and enables result traceability. Experimental results\ndemonstrate that our proposed safety control model achieves a significantly\nhigher safety score on public safety evaluation benchmarks compared to the\nbaseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk\ntest set, the framework's components attained a perfect 100% safety score,\nvalidating their exceptional protective capabilities in complex risk scenarios.\nThis research provides an effective engineering pathway for building\nhigh-security, high-trust LLM applications.", "AI": {"tldr": "本文提出一个新颖的LLM安全响应框架，通过在输入端进行精细化风险识别和处理，并在输出端结合RAG和微调模型确保响应的真实性和可追溯性，从而系统性地保障LLM的安全性。", "motivation": "随着大型语言模型（LLMs）的广泛应用，其相关的安全问题日益突出，严重制约了它们在关键领域的可信部署。", "method": "该框架在输入层采用基于监督微调（SFT）的安全分类模型，通过四层（安全、不安全、有条件安全、重点关注）分类法进行风险识别和差异化处理。在输出层，框架整合了检索增强生成（RAG）与专门微调的解释模型，确保所有响应都基于实时可信的知识库，消除信息编造并实现结果可追溯性。", "result": "在输入层，实现了99.3%的风险召回率。在公共安全评估基准上，提出的安全控制模型比基线模型TinyR1-Safety-8B获得了显著更高的安全分数。在专有的高风险测试集上，框架组件达到了100%的安全分数。", "conclusion": "本研究为构建高安全性、高信任度的LLM应用提供了一条有效的工程路径，验证了其在复杂风险场景下的卓越保护能力。"}}
{"id": "2511.03400", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.03400", "abs": "https://arxiv.org/abs/2511.03400", "authors": ["Minquan Gao", "Xinyi Li", "Qing Yan", "Xiaojian Sun", "Xiaopan Zhang", "Chien-Ming Huang", "Jiachen Li"], "title": "GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement", "comment": "8 pages, 4 figures, Accepted by IEEE IROS 2025 Workshop WIR-M", "summary": "Pre-trained robot policies serve as the foundation of many validated robotic\nsystems, which encapsulate extensive embodied knowledge. However, they often\nlack the semantic awareness characteristic of foundation models, and replacing\nthem entirely is impractical in many situations due to high costs and the loss\nof accumulated knowledge. To address this gap, we introduce GUIDES, a\nlightweight framework that augments pre-trained policies with semantic guidance\nfrom foundation models without requiring architectural redesign. GUIDES employs\na fine-tuned vision-language model (Instructor) to generate contextual\ninstructions, which are encoded by an auxiliary module into guidance\nembeddings. These embeddings are injected into the policy's latent space,\nallowing the legacy model to adapt to this new semantic input through brief,\ntargeted fine-tuning. For inference-time robustness, a large language\nmodel-based Reflector monitors the Instructor's confidence and, when confidence\nis low, initiates a reasoning loop that analyzes execution history, retrieves\nrelevant examples, and augments the VLM's context to refine subsequent actions.\nExtensive validation in the RoboCasa simulation environment across diverse\npolicy architectures shows consistent and substantial improvements in task\nsuccess rates. Real-world deployment on a UR5 robot further demonstrates that\nGUIDES enhances motion precision for critical sub-tasks such as grasping.\nOverall, GUIDES offers a practical and resource-efficient pathway to upgrade,\nrather than replace, validated robot policies.", "AI": {"tldr": "GUIDES框架通过整合基础模型的语义指导来增强预训练的机器人策略，无需重新设计架构，从而显著提高任务成功率和运动精度。", "motivation": "预训练的机器人策略缺乏基础模型所具备的语义感知能力，但由于成本高昂和知识损失，完全替换它们并不现实。本研究旨在弥补这一差距，在不替换现有策略的情况下提升其语义理解能力。", "method": "GUIDES框架采用经过微调的视觉-语言模型（Instructor）生成上下文指令，并由辅助模块将其编码为指导嵌入。这些嵌入被注入到策略的潜在空间中，并通过简短、有针对性的微调使原有模型适应新的语义输入。为了提高推理时的鲁棒性，一个基于大型语言模型（LLM）的Reflector会监控Instructor的置信度，并在置信度较低时启动一个推理循环，分析执行历史，检索相关示例，并增强VLM的上下文以改进后续动作。", "result": "在RoboCasa模拟环境中，GUIDES在多种策略架构上均显示出任务成功率的一致且显著提升。在真实世界的UR5机器人部署中，GUIDES也增强了抓取等关键子任务的运动精度。", "conclusion": "GUIDES提供了一种实用且资源高效的方法，用于升级而非替换已验证的机器人策略，使其具备语义感知能力，从而提升其性能。"}}
{"id": "2511.03053", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03053", "abs": "https://arxiv.org/abs/2511.03053", "authors": ["Ziyang Xu", "Olaf Wysocki", "Christoph Holst"], "title": "From Propagation to Prediction: Point-level Uncertainty Evaluation of MLS Point Clouds under Limited Ground Truth", "comment": null, "summary": "Evaluating uncertainty is critical for reliable use of Mobile Laser Scanning\n(MLS) point clouds in many high-precision applications such as Scan-to-BIM,\ndeformation analysis, and 3D modeling. However, obtaining the ground truth (GT)\nfor evaluation is often costly and infeasible in many real-world applications.\nTo reduce this long-standing reliance on GT in uncertainty evaluation research,\nthis study presents a learning-based framework for MLS point clouds that\nintegrates optimal neighborhood estimation with geometric feature extraction.\nExperiments on a real-world dataset show that the proposed framework is\nfeasible and the XGBoost model delivers fully comparable accuracy to Random\nForest while achieving substantially higher efficiency (about 3 times faster),\nproviding initial evidence that geometric features can be used to predict\npoint-level uncertainty quantified by the C2C distance. In summary, this study\nshows that MLS point clouds' uncertainty is learnable, offering a novel\nlearning-based viewpoint towards uncertainty evaluation research.", "AI": {"tldr": "本研究提出了一种基于学习的框架，通过几何特征预测移动激光扫描（MLS）点云的不确定性，以减少对真值（GT）的依赖。", "motivation": "在许多高精度应用中，评估移动激光扫描（MLS）点云的不确定性至关重要，但获取用于评估的真值（GT）通常成本高昂且在实际应用中不可行。", "method": "本研究提出一个基于学习的框架，该框架将最优邻域估计与几何特征提取相结合。实验中使用了XGBoost和Random Forest模型，并以C2C距离量化点级别的不确定性。", "result": "实验表明，所提出的框架是可行的。XGBoost模型在实现与Random Forest相当的准确性的同时，效率显著提高（快约3倍）。这初步证明几何特征可用于预测由C2C距离量化的点级别不确定性。", "conclusion": "本研究表明MLS点云的不确定性是可学习的，为不确定性评估研究提供了一种新颖的基于学习的视角，有助于减少对真值的长期依赖。"}}
{"id": "2511.03169", "categories": ["cs.AI", "D.2.4; I.2.6; I.2.4; K.4.1; I.2.0"], "pdf": "https://arxiv.org/pdf/2511.03169", "abs": "https://arxiv.org/abs/2511.03169", "authors": ["Xuanxiang Huang", "Yacine Izza", "Alexey Ignatiev", "Joao Marques-Silva"], "title": "Uncovering Bugs in Formal Explainers: A Case Study with PyXAI", "comment": null, "summary": "Formal explainable artificial intelligence (XAI) offers unique theoretical\nguarantees of rigor when compared to other non-formal methods of\nexplainability. However, little attention has been given to the validation of\npractical implementations of formal explainers. This paper develops a novel\nmethodology for validating formal explainers and reports on the assessment of\nthe publicly available formal explainer PyXAI. The paper documents the\nexistence of incorrect explanations computed by PyXAI on most of the datasets\nanalyzed in the experiments, thereby confirming the importance of the proposed\nnovel methodology for the validation of formal explainers.", "AI": {"tldr": "本文提出了一种验证形式化可解释AI解释器的新方法，并通过评估PyXAI发现其在多个数据集上生成了不正确的解释，强调了该验证方法的重要性。", "motivation": "形式化可解释AI（XAI）在理论上提供了严格的保证，但其实际实现缺乏验证，这促使了对形式化解释器验证方法的研究。", "method": "开发了一种新颖的方法论，用于验证形式化解释器，并将其应用于评估公开可用的形式化解释器PyXAI。", "result": "实验发现，PyXAI在大多数分析的数据集上计算出了不正确的解释。", "conclusion": "该研究证实了所提出的形式化解释器验证新方法的重要性，并揭示了现有形式化解释器在实践中可能存在的问题。"}}
{"id": "2511.03166", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03166", "abs": "https://arxiv.org/abs/2511.03166", "authors": ["Kevin Wang", "Subre Abdoul Moktar", "Jia Li", "Kangshuo Li", "Feng Chen"], "title": "Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks", "comment": "Accepted by UDM-KDD'24", "summary": "Large Language Models (LLMs) have become increasingly pervasive, finding\napplications across many industries and disciplines. Ensuring the\ntrustworthiness of LLM outputs is paramount, where Uncertainty Estimation (UE)\nplays a key role. In this work, a comprehensive empirical study is conducted to\nexamine the robustness and effectiveness of diverse UE measures regarding\naleatoric and epistemic uncertainty in LLMs. It involves twelve different UE\nmethods and four generation quality metrics including LLMScore from LLM\ncriticizers to evaluate the uncertainty of LLM-generated answers in\nQuestion-Answering (QA) tasks on both in-distribution (ID) and\nout-of-distribution (OOD) datasets. Our analysis reveals that information-based\nmethods, which leverage token and sequence probabilities, perform exceptionally\nwell in ID settings due to their alignment with the model's understanding of\nthe data. Conversely, density-based methods and the P(True) metric exhibit\nsuperior performance in OOD contexts, highlighting their effectiveness in\ncapturing the model's epistemic uncertainty. Semantic consistency methods,\nwhich assess variability in generated answers, show reliable performance across\ndifferent datasets and generation metrics. These methods generally perform well\nbut may not be optimal for every situation.", "AI": {"tldr": "本研究对大型语言模型（LLMs）中的不确定性估计（UE）方法进行了全面实证研究，评估了12种UE方法在分布内（ID）和分布外（OOD）QA任务中的表现，发现不同类型的方法在不同情境下各有优劣。", "motivation": "随着LLMs的日益普及，确保其输出的可信度至关重要，而不确定性估计（UE）在此过程中扮演着关键角色。因此，需要深入理解并评估不同UE方法的鲁棒性和有效性。", "method": "研究进行了一项综合性的实证分析，考察了12种不同的UE方法，涵盖了对偶然不确定性（aleatoric uncertainty）和认知不确定性（epistemic uncertainty）的测量。评估使用了四种生成质量指标（包括来自LLM评论器的LLMScore），在问答（QA）任务中，利用分布内（ID）和分布外（OOD）数据集，评估LLM生成答案的不确定性。", "result": "信息熵类方法（利用token和序列概率）在ID设置中表现出色，因其与模型对数据的理解一致。密度类方法和P(True)指标在OOD上下文中表现优越，有效捕捉了模型的认知不确定性。语义一致性方法（评估生成答案的变异性）在不同数据集和生成指标下均表现可靠，虽非在所有情况下都最佳，但性能稳定。", "conclusion": "不同类型的不确定性估计方法在大型语言模型中各有优势，信息熵类方法适用于分布内数据，密度类方法和P(True)适用于分布外数据，而语义一致性方法则在不同场景下表现出普遍的可靠性。选择合适的UE方法对于确保LLM输出的可信度至关重要。"}}
{"id": "2511.03444", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.03444", "abs": "https://arxiv.org/abs/2511.03444", "authors": ["Vesna Poprcova", "Iulia Lefter", "Martijn Warnier", "Frances Brazier"], "title": "Value Elicitation for a Socially Assistive Robot Addressing Social Anxiety: A Participatory Design Approach", "comment": "Accepted at Value Engineering in AI (VALE) Workshop (ECAI 2025)", "summary": "Social anxiety is a prevalent mental health condition that can significantly\nimpact overall well-being and quality of life. Despite its widespread effects,\nadequate support or treatment for social anxiety is often insufficient.\nAdvances in technology, particularly in social robotics, offer promising\nopportunities to complement traditional mental health. As an initial step\ntoward developing effective solutions, it is essential to understand the values\nthat shape what is considered meaningful, acceptable, and helpful. In this\nstudy, a participatory design workshop was conducted with mental health\nacademic researchers to elicit the underlying values that should inform the\ndesign of socially assistive robots for social anxiety support. Through\ncreative, reflective, and envisioning activities, participants explored\nscenarios and design possibilities, allowing for systematic elicitation of\nvalues, expectations, needs, and preferences related to robot-supported\ninterventions. The findings reveal rich insights into design-relevant\nvalues-including adaptivity, acceptance, and efficacy-that are core to support\nfor individuals with social anxiety. This study highlights the significance of\na research-led approach to value elicitation, emphasising user-centred and\ncontext-aware design considerations in the development of socially assistive\nrobots.", "AI": {"tldr": "本研究通过与心理健康研究人员的参与式设计研讨会，探讨了为社交焦虑症患者设计社交辅助机器人时应考虑的核心价值观，包括适应性、接受度和有效性，并强调了以研究为主导的用户中心设计方法。", "motivation": "社交焦虑症普遍存在且严重影响生活质量，但现有支持不足。社交机器人技术为补充传统心理健康支持提供了新机遇。为了开发有效的解决方案，理解塑造有意义、可接受和有益设计的潜在价值观至关重要。", "method": "与心理健康学术研究人员举办了一场参与式设计研讨会。通过创造性、反思性和构想活动，参与者探索了情景和设计可能性，系统地启发了与机器人辅助干预相关的价值观、期望、需求和偏好。", "result": "研究结果揭示了与设计相关的丰富见解，包括适应性、接受度和有效性等核心价值观，这些对于支持社交焦虑症患者至关重要。", "conclusion": "本研究强调了以研究为主导的价值启发方法的重要性，并强调在开发社交辅助机器人时，应考虑以用户为中心和情境感知的设计因素。"}}
{"id": "2511.03391", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03391", "abs": "https://arxiv.org/abs/2511.03391", "authors": ["João Victor Galvão da Mata", "Anders Hansson", "Martin S. Andersen"], "title": "Maximum Likelihood Estimation of Dynamic Sub-Networks with Missing Data", "comment": null, "summary": "Maximum likelihood estimation is effective for identifying dynamical systems,\nbut applying it to large networks becomes computationally prohibitive. This\npaper introduces a maximum likelihood estimation method that enables\nidentification of sub-networks within complex interconnected systems without\nestimating the entire network. The key insight is that under specific\ntopological conditions, a sub-network's parameters can be estimated using only\nlocal measurements: signals within the target sub-network and those in the\ndirectly connected to the so-called separator sub-network. This approach\nsignificantly reduces computational complexity while enhancing privacy by\neliminating the need to share sensitive internal data across organizational\nboundaries. We establish theoretical conditions for network separability,\nderive the probability density function for the sub-network, and demonstrate\nthe method's effectiveness through numerical examples.", "AI": {"tldr": "本文提出一种最大似然估计方法，允许在大型互联系统中仅使用局部测量识别子网络，从而显著降低计算复杂性并增强隐私。", "motivation": "传统最大似然估计在识别大型动态系统时计算成本过高。此外，在跨组织边界共享敏感内部数据存在隐私和效率问题。", "method": "该方法引入了一种最大似然估计技术，可在特定拓扑条件下，仅利用目标子网络内部以及与分隔器子网络直接连接的信号进行参数估计。文中建立了网络可分离性的理论条件，并推导了子网络的概率密度函数。", "result": "该方法显著降低了计算复杂性，并通过消除共享敏感数据需求增强了隐私。数值示例验证了其有效性。", "conclusion": "该研究提供了一种创新的最大似然估计方法，能够在不估计整个网络的情况下识别复杂系统中的子网络，从而在计算效率和数据隐私方面带来显著优势。"}}
{"id": "2511.03093", "categories": ["cs.CV", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.03093", "abs": "https://arxiv.org/abs/2511.03093", "authors": ["Yi Gong", "Xinyuan Zhang", "Jichen Chai", "Yichen Ding", "Yifei Lou"], "title": "A Plug-and-Play Framework for Volumetric Light-Sheet Image Reconstruction", "comment": null, "summary": "Cardiac contraction is a rapid, coordinated process that unfolds across\nthree-dimensional tissue on millisecond timescales. Traditional optical imaging\nis often inadequate for capturing dynamic cellular structure in the beating\nheart because of a fundamental trade-off between spatial and temporal\nresolution. To overcome these limitations, we propose a high-performance\ncomputational imaging framework that integrates Compressive Sensing (CS) with\nLight-Sheet Microscopy (LSM) for efficient, low-phototoxic cardiac imaging. The\nsystem performs compressed acquisition of fluorescence signals via random\nbinary mask coding using a Digital Micromirror Device (DMD). We propose a\nPlug-and-Play (PnP) framework, solved using the alternating direction method of\nmultipliers (ADMM), which flexibly incorporates advanced denoisers, including\nTikhonov, Total Variation (TV), and BM3D. To preserve structural continuity in\ndynamic imaging, we further introduce temporal regularization enforcing\nsmoothness between adjacent z-slices. Experimental results on zebrafish heart\nimaging under high compression ratios demonstrate that the proposed method\nsuccessfully reconstructs cellular structures with excellent denoising\nperformance and image clarity, validating the effectiveness and robustness of\nour algorithm in real-world high-speed, low-light biological imaging scenarios.", "AI": {"tldr": "本文提出了一种高性能计算成像框架，将压缩感知（CS）与光片显微镜（LSM）结合，用于高效、低光毒性的心脏成像，通过PnP-ADMM框架和时间正则化实现了高压缩比下的细胞结构重建和去噪。", "motivation": "传统光学成像在捕捉跳动心脏的动态细胞结构时，由于空间和时间分辨率之间的基本权衡，往往无法满足要求，因此需要一种新的方法来克服这些限制。", "method": "该系统通过数字微镜器件（DMD）随机二值掩模编码对荧光信号进行压缩采集。提出了一种即插即用（PnP）框架，使用交替方向乘子法（ADMM）求解，并灵活地整合了Tikhonov、全变分（TV）和BM3D等先进去噪器。为保持动态成像的结构连续性，进一步引入了时间正则化以确保相邻Z切片之间的平滑性。", "result": "在斑马鱼心脏成像实验中，即使在高压缩比下，所提出的方法也成功重建了细胞结构，并表现出卓越的去噪性能和图像清晰度。", "conclusion": "实验结果验证了该算法在真实世界高速、低光生物成像场景中的有效性和鲁棒性。"}}
{"id": "2511.03180", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03180", "abs": "https://arxiv.org/abs/2511.03180", "authors": ["Shahriyar Zaman Ridoy", "Azmine Toushik Wasi", "Koushik Ahamed Tonmoy"], "title": "BengaliMoralBench: A Benchmark for Auditing Moral Reasoning in Large Language Models within Bengali Language and Culture", "comment": "This manuscript is a preprint currently under review", "summary": "As multilingual Large Language Models (LLMs) gain traction across South Asia,\ntheir alignment with local ethical norms, particularly for Bengali, which is\nspoken by over 285 million people and ranked 6th globally, remains\nunderexplored. Existing ethics benchmarks are largely English-centric and\nshaped by Western frameworks, overlooking cultural nuances critical for\nreal-world deployment. To address this, we introduce BengaliMoralBench, the\nfirst large-scale ethics benchmark for the Bengali language and socio-cultural\ncontexts. It covers five moral domains, Daily Activities, Habits, Parenting,\nFamily Relationships, and Religious Activities, subdivided into 50 culturally\nrelevant subtopics. Each scenario is annotated via native-speaker consensus\nusing three ethical lenses: Virtue, Commonsense, and Justice ethics. We conduct\nsystematic zero-shot evaluation of prominent multilingual LLMs, including\nLlama, Gemma, Qwen, and DeepSeek, using a unified prompting protocol and\nstandard metrics. Performance varies widely (50-91% accuracy), with qualitative\nanalysis revealing consistent weaknesses in cultural grounding, commonsense\nreasoning, and moral fairness. BengaliMoralBench provides a foundation for\nresponsible localization, enabling culturally aligned evaluation and supporting\nthe deployment of ethically robust AI in diverse, low-resource multilingual\nsettings such as Bangladesh.", "AI": {"tldr": "该研究引入了BengaliMoralBench，首个针对孟加拉语和其社会文化背景的大规模伦理基准，评估了多语言大型语言模型（LLMs）的伦理对齐，发现其在文化理解、常识推理和道德公平性方面存在显著弱点，为负责任的本地化提供了基础。", "motivation": "随着多语言LLMs在南亚地区普及，其与当地伦理规范的对齐（特别是对于拥有2.85亿使用者的孟加拉语）仍未被充分探索。现有伦理基准主要以英语为中心并受西方框架影响，忽视了现实部署中关键的文化细微差别。", "method": "研究引入了BengaliMoralBench，一个涵盖五个道德领域（日常活动、习惯、育儿、家庭关系、宗教活动）和50个文化相关子主题的大规模孟加拉语伦理基准。每个场景均由母语使用者通过美德、常识和正义三种伦理视角进行共识标注。使用统一的提示协议和标准指标，对Llama、Gemma、Qwen和DeepSeek等主流多语言LLMs进行了系统性的零样本评估。", "result": "多语言LLMs的性能差异很大（准确率在50-91%之间）。定性分析揭示了模型在文化基础、常识推理和道德公平性方面存在持续的弱点。", "conclusion": "BengaliMoralBench为负责任的本地化奠定了基础，支持文化对齐的评估，并有助于在孟加拉国等多样化、低资源的多语言环境中部署符合伦理的AI系统。"}}
{"id": "2511.03179", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03179", "abs": "https://arxiv.org/abs/2511.03179", "authors": ["Varun Kumar", "George Em Karniadakis"], "title": "Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework", "comment": null, "summary": "The engineering design process often demands expertise from multiple domains,\nleading to complex collaborations and iterative refinements. Traditional\nmethods can be resource-intensive and prone to inefficiencies. To address this,\nwe formalize the engineering design process through a multi-agent AI framework\nthat integrates structured design and review loops. The framework introduces\nspecialized knowledge-driven agents that collaborate to generate and refine\ndesign candidates. As an exemplar, we demonstrate its application to the\naerodynamic optimization of 4-digit NACA airfoils. The framework consists of\nthree key AI agents: a Graph Ontologist, a Design Engineer, and a Systems\nEngineer. The Graph Ontologist employs a Large Language Model (LLM) to\nconstruct two domain-specific knowledge graphs from airfoil design literature.\nThe Systems Engineer, informed by a human manager, formulates technical\nrequirements that guide design generation and evaluation. The Design Engineer\nleverages the design knowledge graph and computational tools to propose\ncandidate airfoils meeting these requirements. The Systems Engineer reviews and\nprovides feedback both qualitative and quantitative using its own knowledge\ngraph, forming an iterative feedback loop until a design is validated by the\nmanager. The final design is then optimized to maximize performance metrics\nsuch as the lift-to-drag ratio. Overall, this work demonstrates how\ncollaborative AI agents equipped with structured knowledge representations can\nenhance efficiency, consistency, and quality in the engineering design process.", "AI": {"tldr": "本文提出一个多智能体AI框架，通过整合结构化设计和评审循环来形式化工程设计过程，并以NACA翼型气动优化为例，展示了其如何利用LLM构建的知识图谱和协作智能体提升设计效率和质量。", "motivation": "传统的工程设计过程通常需要多领域专业知识，导致复杂的协作、迭代精炼、资源密集且效率低下。", "method": "该框架包含三个关键AI智能体：图本体论专家（Graph Ontologist）、设计工程师（Design Engineer）和系统工程师（Systems Engineer）。图本体论专家利用大型语言模型（LLM）从文献中构建两个领域特定知识图谱。系统工程师根据人类管理者制定的技术要求，指导设计生成和评估。设计工程师利用设计知识图谱和计算工具提出候选设计。系统工程师利用其知识图谱进行定性和定量评审并提供反馈，形成迭代反馈循环，直至设计获得管理者验证。最终设计会进一步优化以最大化性能指标。", "result": "该框架成功应用于4位NACA翼型的气动优化，展示了协作AI智能体如何通过结构化知识表示来增强工程设计过程的效率、一致性和质量。", "conclusion": "配备结构化知识表示的协作AI智能体能够显著提升工程设计过程的效率、一致性和质量。"}}
{"id": "2511.03481", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03481", "abs": "https://arxiv.org/abs/2511.03481", "authors": ["Jianbo Yuan", "Haohua Zhu", "Jing Dai", "Sheng Yi"], "title": "Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control", "comment": "8 pages 18 fogures, IEEE RAL accept", "summary": "The human hand plays a vital role in daily life and industrial applications,\nyet replicating its multifunctional capabilities-including motion, sensing, and\ncoordinated manipulation-with robotic systems remains a formidable challenge.\nDeveloping a dexterous robotic hand requires balancing human-like agility with\nengineering constraints such as complexity, size-to-weight ratio, durability,\nand force-sensing performance. This letter presents Dex-Hand 021, a\nhigh-performance, cable-driven five-finger robotic hand with 12 active and 7\npassive degrees of freedom (DoFs), achieving 19 DoFs dexterity in a lightweight\n1 kg design. We propose a proprioceptive force-sensing-based admittance control\nmethod to enhance manipulation. Experimental results demonstrate its superior\nperformance: a single-finger load capacity exceeding 10 N, fingertip\nrepeatability under 0.001 m, and force estimation errors below 0.2 N. Compared\nto PID control, joint torques in multi-object grasping are reduced by 31.19%,\nsignificantly improves force-sensing capability while preventing overload\nduring collisions. The hand excels in both power and precision grasps,\nsuccessfully executing 33 GRASP taxonomy motions and complex manipulation\ntasks. This work advances the design of lightweight, industrial-grade dexterous\nhands and enhances proprioceptive control, contributing to robotic manipulation\nand intelligent manufacturing.", "AI": {"tldr": "本文提出并验证了Dex-Hand 021，一种高性能、缆线驱动的五指机械手，具有19个自由度，重量仅1公斤。通过本体力传感的导纳控制方法，显著提高了其操作性能，特别是在多物体抓取和防过载方面。", "motivation": "在机器人系统中复制人手的多功能能力（包括运动、传感和协调操作）仍然是一个巨大的挑战。开发灵巧的机器人手需要平衡类人的敏捷性与工程约束，如复杂性、尺寸重量比、耐用性和力传感性能。", "method": "本文设计了Dex-Hand 021，这是一种缆线驱动的五指机械手，拥有12个主动和7个被动自由度，实现了19个自由度的灵巧性，且重量仅1公斤。研究提出了一种基于本体力传感的导纳控制方法，以增强其操作能力。", "result": "Dex-Hand 021展现出卓越的性能：单指承载能力超过10牛顿，指尖重复性低于0.001米，力估计误差低于0.2牛顿。与PID控制相比，在多物体抓取中关节扭矩降低了31.19%，显著提升了力传感能力并防止碰撞过载。该机械手在力量和精确抓取方面均表现出色，成功执行了33种GRASP分类动作和复杂的操纵任务。", "conclusion": "这项工作推动了轻量级工业级灵巧手的设计，并增强了本体感知控制，为机器人操作和智能制造做出了贡献。"}}
{"id": "2511.03379", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03379", "abs": "https://arxiv.org/abs/2511.03379", "authors": ["Samarth Toolhally", "Joeri Roelofs", "Siep Weiland", "Amritam Das"], "title": "A Digital Twin of Evaporative Thermo-Fluidic Process in Fixation Unit of DoD Inkjet Printers", "comment": null, "summary": "In inkjet printing, optimal paper moisture is crucial for print quality,\nachieved through hot-air impingement in the fixation unit. This paper presents\na modular digital twin of the fixation unit, modeling the thermo-fluidic drying\nprocess and monitoring its spatio-temporal performance. The novel approach\nformulates the digital twin as an infinite-dimensional state estimator that\ninfers fixation states from limited sensor data, while remaining robust to\ndisturbances. Modularity is achieved through a graph-theoretic model, where\neach node represents thermo-fluidic dynamics in different sections of the\nfixation unit. Evaporation is modeled as a nonlinear boundary effect coupled\nwith node dynamics via Linear Fractional Representation. Using the Partial\nIntegral Equation (PIE) framework, we develop a unified approach for stability,\ninput-output analysis, simulation, and rapid prototyping, validated with\noperational data from a commercial printer. An $\\mathcal{H}_{\\infty}$-optimal\nLuenberger state estimator is then synthesized to estimate thermal states from\navailable sensor data, enabling real-time monitoring of spatio-temporal thermal\neffects on paper sheets.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2511.03099", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03099", "abs": "https://arxiv.org/abs/2511.03099", "authors": ["Yiyi Miao", "Taoyu Wu", "Tong Chen", "Sihao Li", "Ji Jiang", "Youpeng Yang", "Angelos Stefanidis", "Limin Yu", "Jionglong Su"], "title": "DentalSplat: Dental Occlusion Novel View Synthesis from Sparse Intra-Oral Photographs", "comment": null, "summary": "In orthodontic treatment, particularly within telemedicine contexts,\nobserving patients' dental occlusion from multiple viewpoints facilitates\ntimely clinical decision-making. Recent advances in 3D Gaussian Splatting\n(3DGS) have shown strong potential in 3D reconstruction and novel view\nsynthesis. However, conventional 3DGS pipelines typically rely on densely\ncaptured multi-view inputs and precisely initialized camera poses, limiting\ntheir practicality. Orthodontic cases, in contrast, often comprise only three\nsparse images, specifically, the anterior view and bilateral buccal views,\nrendering the reconstruction task especially challenging. The extreme sparsity\nof input views severely degrades reconstruction quality, while the absence of\ncamera pose information further complicates the process. To overcome these\nlimitations, we propose DentalSplat, an effective framework for 3D\nreconstruction from sparse orthodontic imagery. Our method leverages a\nprior-guided dense stereo reconstruction model to initialize the point cloud,\nfollowed by a scale-adaptive pruning strategy to improve the training\nefficiency and reconstruction quality of 3DGS. In scenarios with extremely\nsparse viewpoints, we further incorporate optical flow as a geometric\nconstraint, coupled with gradient regularization, to enhance rendering\nfidelity. We validate our approach on a large-scale dataset comprising 950\nclinical cases and an additional video-based test set of 195 cases designed to\nsimulate real-world remote orthodontic imaging conditions. Experimental results\ndemonstrate that our method effectively handles sparse input scenarios and\nachieves superior novel view synthesis quality for dental occlusion\nvisualization, outperforming state-of-the-art techniques.", "AI": {"tldr": "本文提出DentalSplat框架，利用先验引导的稠密立体重建、尺度自适应剪枝和光流几何约束，解决了正畸治疗中从稀疏图像进行牙齿咬合3D重建的挑战，并实现了卓越的新视角合成质量。", "motivation": "正畸治疗（尤其是远程医疗）中，从多视角观察患者牙齿咬合对临床决策至关重要。现有3D高斯泼溅（3DGS）技术依赖密集多视角输入和精确相机姿态，但在正畸案例中，通常只有三张稀疏图像（前视图和双侧颊视图），且缺乏相机姿态信息，这严重降低了重建质量和实用性。", "method": "本文提出了DentalSplat框架。首先，利用先验引导的稠密立体重建模型初始化点云。其次，采用尺度自适应剪枝策略提高3DGS的训练效率和重建质量。对于极度稀疏的视角，进一步结合光流作为几何约束和梯度正则化来增强渲染保真度。", "result": "该方法在包含950个临床病例的大规模数据集和195个模拟真实远程正畸成像条件的视频测试集上进行了验证。实验结果表明，DentalSplat能有效处理稀疏输入场景，并在牙齿咬合可视化方面实现了优于现有最先进技术的新视角合成质量。", "conclusion": "DentalSplat框架成功克服了从稀疏正畸图像进行3D重建的限制，实现了卓越的牙齿咬合可视化新视角合成，为远程正畸治疗中的及时临床决策提供了有效支持。"}}
{"id": "2511.03186", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03186", "abs": "https://arxiv.org/abs/2511.03186", "authors": ["Yiru Chen", "Sally Fang", "Sai Sree Harsha", "Dan Luo", "Vaishnavi Muppala", "Fei Wu", "Shun Jiang", "Kun Qian", "Yunyao Li"], "title": "Adobe Summit Concierge Evaluation with Human in the Loop", "comment": "Accepted by 6th Workshop on Data Science with Human in the Loop @\n  VLDB 2025", "summary": "Generative AI assistants offer significant potential to enhance productivity,\nstreamline information access, and improve user experience in enterprise\ncontexts. In this work, we present Summit Concierge, a domain-specific AI\nassistant developed for Adobe Summit. The assistant handles a wide range of\nevent-related queries and operates under real-world constraints such as data\nsparsity, quality assurance, and rapid deployment. To address these challenges,\nwe adopt a human-in-the-loop development workflow that combines prompt\nengineering, retrieval grounding, and lightweight human validation. We describe\nthe system architecture, development process, and real-world deployment\noutcomes. Our experience shows that agile, feedback-driven development enables\nscalable and reliable AI assistants, even in cold-start scenarios.", "AI": {"tldr": "本文介绍了Summit Concierge，一个为Adobe Summit开发的领域特定AI助手。该助手通过结合提示工程、检索接地和人工验证的“人机协作”开发流程，解决了数据稀疏和快速部署等实际挑战，并展示了其在冷启动场景下的可扩展性和可靠性。", "motivation": "生成式AI助手在企业环境中具有提升生产力、简化信息获取和改善用户体验的巨大潜力。本文旨在开发一个领域特定的AI助手，以应对Adobe Summit等活动中遇到的实际约束，如数据稀疏性和质量保证。", "method": "本文采用了一种“人机协作”的开发流程，结合了提示工程（prompt engineering）、检索接地（retrieval grounding）和轻量级人工验证（lightweight human validation）。研究描述了系统架构、开发过程以及实际部署成果。", "result": "Summit Concierge助手能够处理广泛的活动相关查询。研究经验表明，敏捷的、反馈驱动的开发方法能够实现可扩展且可靠的AI助手，即使在冷启动场景下也能成功部署。", "conclusion": "敏捷的、反馈驱动的开发方法对于构建可扩展且可靠的AI助手至关重要，特别是在数据稀疏和需要快速部署的冷启动企业环境中。"}}
{"id": "2511.03214", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03214", "abs": "https://arxiv.org/abs/2511.03214", "authors": ["Wenchang Lei", "Ping Zou", "Yue Wang", "Feng Sun", "Lei Zhao"], "title": "LGM: Enhancing Large Language Models with Conceptual Meta-Relations and Iterative Retrieval", "comment": "30 pages, 5 figures", "summary": "Large language models (LLMs) exhibit strong semantic understanding, yet\nstruggle when user instructions involve ambiguous or conceptually misaligned\nterms. We propose the Language Graph Model (LGM) to enhance conceptual clarity\nby extracting meta-relations-inheritance, alias, and composition-from natural\nlanguage. The model further employs a reflection mechanism to validate these\nmeta-relations. Leveraging a Concept Iterative Retrieval Algorithm, these\nrelations and related descriptions are dynamically supplied to the LLM,\nimproving its ability to interpret concepts and generate accurate responses.\nUnlike conventional Retrieval-Augmented Generation (RAG) approaches that rely\non extended context windows, our method enables large language models to\nprocess texts of any length without the need for truncation. Experiments on\nstandard benchmarks demonstrate that the LGM consistently outperforms existing\nRAG baselines.", "AI": {"tldr": "本文提出语言图模型（LGM），通过从自然语言中提取并验证元关系（继承、别名、组成），并结合概念迭代检索算法，动态地向大型语言模型（LLM）提供这些信息，以增强其概念理解和响应准确性，且能处理任意长度文本，优于现有RAG基线。", "motivation": "大型语言模型（LLMs）尽管语义理解能力强，但在用户指令涉及模糊或概念错位的术语时表现不佳。", "method": "本文提出了语言图模型（LGM），它通过以下步骤增强概念清晰度：1) 从自然语言中提取元关系（继承、别名、组成）；2) 利用反射机制验证这些元关系；3) 采用概念迭代检索算法，动态地向LLM提供这些关系及相关描述。与传统RAG不同，LGM不依赖扩展上下文窗口，能够处理任意长度文本而无需截断。", "result": "在标准基准测试中，LGM始终优于现有的RAG基线模型。", "conclusion": "LGM通过提取和验证元关系并采用迭代检索机制，有效提升了LLM对模糊或概念错位术语的理解和响应准确性，且克服了传统RAG的上下文窗口限制，能够处理任意长度文本。"}}
{"id": "2511.03403", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03403", "abs": "https://arxiv.org/abs/2511.03403", "authors": ["Shen Chen", "Yanlong Li", "Jiamin Cui", "Wei Yao", "Jisong Wang", "Yixin Tian", "Chaohou Liu", "Yang Yang", "Jiaxi Ying", "Zeng Liu", "Jinjun Liu"], "title": "An Alternative Derivation and Optimal Design Method of the Generalized Bilinear Transformation for Discretizing Analog Systems", "comment": null, "summary": "A popular method for designing digital systems is transforming the transfer\nfunction of the corresponding analog systems from the continuous-time domain\n(s-domain) into the discrete-time domain (z-domain) using the Euler or Tustin\nmethod. We demonstrate that these transformations are two specific forms of the\nGeneralized Bilinear Transformation (GBT) with a design parameter, $\\alpha$.\nHowever, the physical meaning and optimal design method for this parameter are\nnot sufficiently studied. In this paper, we propose an alternative derivation\nof the GBT derived by employing a new hexagonal shape to approximate the\nenclosed area of the error function, and we define the parameter $\\alpha$ as\nthe shape factor. The physical meaning of the shape factor is firstly revealed,\nwhich equals to the percentage of the backward rectangular ratio of the\nproposed hexagonal shape. We demonstrate that the stable range of the shape\nfactor is [0.5, 1] through domain mapping. Depending on the operating\nfrequencies and the shape factor, we observe two distinct distortion modes,\ni.e., the magnitude and phase distortion. We proceed to develop an optimal\ndesign method for the shape factor based on an objective function in form of\nthe normalized magnitude or phase error. Finally, a low-pass filter (LPF) is\ndesigned and tested to verify the effectiveness of the proposed method by\ncomparing the theoretical calculations with the experimental results.", "AI": {"tldr": "本文提出了一种广义双线性变换（GBT）的新推导方法，揭示了其设计参数α（形状因子）的物理意义和稳定范围，并开发了一种基于误差函数的最优设计方法，通过低通滤波器验证了其有效性。", "motivation": "将模拟系统传递函数转换为数字系统是常用的设计方法，其中欧拉和Tustin变换是广义双线性变换（GBT）的特例。然而，GBT中设计参数α的物理意义和最优设计方法尚未得到充分研究。", "method": "本文通过采用新的六边形形状近似误差函数的封闭面积，提出了GBT的替代推导，并将参数α定义为形状因子。首次揭示了形状因子的物理意义（等于所提出六边形形状后向矩形比的百分比）。通过域映射确定了形状因子的稳定范围为[0.5, 1]。观察到两种不同的失真模式（幅度失真和相位失真），并基于归一化幅度或相位误差形式的目标函数，开发了形状因子的优化设计方法。最后，通过设计和测试低通滤波器（LPF）来验证所提方法的有效性。", "result": "提出了GBT的替代推导，其中参数α被定义为形状因子，并首次揭示了其物理意义（等于所提出六边形形状后向矩形比的百分比）。通过域映射证明了形状因子的稳定范围是[0.5, 1]。观察到两种失真模式：幅度和相位失真。开发了一种基于归一化幅度或相位误差的目标函数的形状因子优化设计方法。通过低通滤波器（LPF）的设计和实验验证了所提方法的有效性。", "conclusion": "本文提出的形状因子优化设计方法是有效的，并通过低通滤波器（LPF）的理论计算与实验结果对比得到了验证。"}}
{"id": "2511.03497", "categories": ["cs.RO", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03497", "abs": "https://arxiv.org/abs/2511.03497", "authors": ["Lei Fu", "Sahar Salimpour", "Leonardo Militano", "Harry Edelman", "Jorge Peña Queralta", "Giovanni Toffetti"], "title": "ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications", "comment": null, "summary": "Agentic AI systems and Physical or Embodied AI systems have been two key\nresearch verticals at the forefront of Artificial Intelligence and Robotics,\nwith Model Context Protocol (MCP) increasingly becoming a key component and\nenabler of agentic applications. However, the literature at the intersection of\nthese verticals, i.e., Agentic Embodied AI, remains scarce. This paper\nintroduces an MCP server for analyzing ROS and ROS 2 bags, allowing for\nanalyzing, visualizing and processing robot data with natural language through\nLLMs and VLMs. We describe specific tooling built with robotics domain\nknowledge, with our initial release focused on mobile robotics and supporting\nnatively the analysis of trajectories, laser scan data, transforms, or time\nseries data. This is in addition to providing an interface to standard ROS 2\nCLI tools (\"ros2 bag list\" or \"ros2 bag info\"), as well as the ability to\nfilter bags with a subset of topics or trimmed in time. Coupled with the MCP\nserver, we provide a lightweight UI that allows the benchmarking of the tooling\nwith different LLMs, both proprietary (Anthropic, OpenAI) and open-source\n(through Groq). Our experimental results include the analysis of tool calling\ncapabilities of eight different state-of-the-art LLM/VLM models, both\nproprietary and open-source, large and small. Our experiments indicate that\nthere is a large divide in tool calling capabilities, with Kimi K2 and Claude\nSonnet 4 demonstrating clearly superior performance. We also conclude that\nthere are multiple factors affecting the success rates, from the tool\ndescription schema to the number of arguments, as well as the number of tools\navailable to the models. The code is available with a permissive license at\nhttps://github.com/binabik-ai/mcp-rosbags.", "AI": {"tldr": "本文介绍了一个MCP服务器，用于通过大型语言模型（LLMs）和视觉语言模型（VLMs）对ROS和ROS 2数据包进行自然语言分析、可视化和处理，旨在弥补具身智能体（Agentic Embodied AI）研究的空白。实验结果显示，不同LLM/VLM在工具调用能力上存在显著差异。", "motivation": "具身智能体（Agentic Embodied AI）是人工智能和机器人领域的关键研究方向，但相关文献稀缺。模型上下文协议（MCP）在智能体应用中日益重要。因此，研究人员旨在开发一个系统，允许通过自然语言分析和处理机器人数据，以推动具身智能体领域的发展。", "method": "研究引入了一个MCP服务器，专门用于分析ROS和ROS 2数据包。该服务器集成了机器人领域知识的特定工具，初步支持移动机器人轨迹、激光扫描、变换和时间序列数据的分析。它还提供了与标准ROS 2 CLI工具的接口，并具备数据包过滤功能。此外，研究团队还提供了一个轻量级UI，用于基准测试不同专有（如Anthropic, OpenAI）和开源（通过Groq）LLM的工具调用能力。", "result": "实验分析了八种最先进的LLM/VLM模型（包括专有和开源、大型和小型）的工具调用能力。结果表明，在工具调用能力上存在巨大差异，其中Kimi K2和Claude Sonnet 4表现出明显优越的性能。研究还发现，工具描述模式、参数数量以及可用工具数量等多个因素都会影响工具调用的成功率。", "conclusion": "本文成功开发了一个MCP服务器及其配套工具，实现了通过LLM和VLM对ROS/ROS 2机器人数据进行自然语言分析。研究揭示了当前LLM/VLM在工具调用能力上的显著性能差距，并指出了影响这些能力的关键因素，为未来具身智能体系统的发展提供了重要见解。"}}
{"id": "2511.03120", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03120", "abs": "https://arxiv.org/abs/2511.03120", "authors": ["Botong. Zhao", "Xubin. Wang", "Shujing. Lyu", "Yue. Lu"], "title": "Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class Discovery via Self-Supervised Learning", "comment": null, "summary": "Integrated circuit manufacturing is highly complex, comprising hundreds of\nprocess steps. Defects can arise at any stage, causing yield loss and\nultimately degrading product reliability. Supervised methods require extensive\nhuman annotation and struggle with emergent categories and rare, data scarce\ndefects. Clustering-based unsupervised methods often exhibit unstable\nperformance due to missing priors. We propose IC DefectNCD, a support set free\nframework that leverages Image Intrinsic Priors in IC SEM images for defect\ndetection and novel class discovery. We first develop Self Normal Information\nGuided IC Defect Detection, aggregating representative normal features via a\nlearnable normal information extractor and using reconstruction residuals to\ncoarsely localize defect regions. To handle saliency variations across defects,\nwe introduce an adaptive binarization strategy that produces stable subimages\nfocused on core defective areas. Finally, we design Self Defect Information\nGuided IC Defect Classification, which incorporates a soft mask guided\nattention mechanism to inject spatial defect priors into the teacher student\nmodel. This enhances sensitivity to defective regions, suppresses background\ninterference, and enables recognition and classification of unseen defects. We\nvalidate the approach on a real world dataset spanning three key fabrication\nstages and covering 15 defect types. Experiments demonstrate robust performance\non both defect detection and unseen defect classification.", "AI": {"tldr": "该论文提出IC DefectNCD，一个无支持集框架，利用集成电路SEM图像的内在先验，实现缺陷检测和新类别发现，克服了传统监督和无监督方法的局限性。", "motivation": "集成电路制造复杂，缺陷导致良率损失和产品可靠性下降。现有监督方法需大量人工标注，难以处理突发和稀有缺陷；基于聚类的无监督方法因缺乏先验知识而性能不稳定。", "method": "提出IC DefectNCD框架。首先，通过“自正常信息引导的IC缺陷检测”模块，学习正常特征并利用重建残差进行粗定位，再通过自适应二值化策略生成稳定的缺陷区域子图像。其次，通过“自缺陷信息引导的IC缺陷分类”模块，将软掩码引导的注意力机制融入师生模型，注入空间缺陷先验，增强对缺陷区域的敏感性并抑制背景干扰，从而识别和分类未见过的缺陷。", "result": "在涵盖三个关键制造阶段和15种缺陷类型的真实世界数据集上进行验证，实验结果表明该方法在缺陷检测和未见缺陷分类方面均表现出鲁棒性能。", "conclusion": "IC DefectNCD框架通过利用图像内在先验，有效解决了集成电路缺陷检测和新类别发现中的挑战，尤其在处理稀有和未见缺陷方面展现出强大能力。"}}
{"id": "2511.03482", "categories": ["eess.SY", "cs.CE", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03482", "abs": "https://arxiv.org/abs/2511.03482", "authors": ["Giorgio Palma", "Ivan Santic", "Andrea Serani", "Lorenzo Minno", "Matteo Diez"], "title": "System Identification of a Moored ASV with Recessed Moon Pool via Deterministic and Bayesian Hankel-DMDc", "comment": "26 pages, 11 figures, 2 tables, 1 box", "summary": "This study addresses the system identification of a small autonomous surface\nvehicle (ASV) under moored conditions using Hankel dynamic mode decomposition\nwith control (HDMDc) and its Bayesian extension (BHDMDc). Experiments were\ncarried out on a Codevintec CK-14e ASV in the towing tank of CNR-INM, under\nboth irregular and regular head-sea wave conditions. The ASV under\ninvestigation features a recessed moon pool, which induces nonlinear responses\ndue to sloshing, thereby increasing the modelling challenge. Data-driven\nreduced-order models were built from measurements of vessel motions and mooring\nloads. The HDMDc framework provided accurate deterministic predictions of\nvessel dynamics, while the Bayesian formulation enabled uncertainty-aware\ncharacterization of the model response by accounting for variability in\nhyperparameter selection. Validation against experimental data demonstrated\nthat both HDMDc and BHDMDc can predict the vessel's response to unseen regular\nand irregular wave excitations. In conclusion, the study shows that HDMDc-based\nROMs are a viable data-driven alternative for system identification,\ndemonstrating for the first time their generalization capability for a sea\ncondition different from the training set, achieving high accuracy in\nreproducing vessel dynamics.", "AI": {"tldr": "本研究使用HDMDc及其贝叶斯扩展（BHDMDc）对系泊条件下的小型自主水面艇（ASV）进行系统辨识，成功构建了数据驱动的降阶模型，并验证了其在未见波浪激励下的准确性和泛化能力。", "motivation": "小型ASV，特别是带有凹陷月池的船只，在波浪作用下会因晃荡产生非线性响应，增加了建模挑战。因此，需要有效的方法进行系统辨识和动力学建模。", "method": "在拖曳水池中对Codevintec CK-14e ASV进行了不规则和规则迎头浪条件下的实验。通过测量船体运动和系泊载荷，利用带控制的Hankel动态模态分解（HDMDc）及其贝叶斯扩展（BHDMDc）构建了数据驱动的降阶模型（ROMs）。", "result": "HDMDc框架提供了准确的确定性船体动力学预测。贝叶斯公式（BHDMDc）通过考虑超参数选择的变异性，实现了模型响应的不确定性感知表征。两种方法都成功预测了船只对未见规则和不规则波浪激励的响应，首次展示了HDMDc-based ROMs对不同于训练集的海洋条件的泛化能力，并取得了高精度。", "conclusion": "HDMDc-based ROMs是系统辨识的一种可行的数据驱动替代方案，能够高精度地再现船体动力学，并首次证明了其对不同于训练集的海洋条件的泛化能力。"}}
{"id": "2511.03217", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR", "68T50", "I.2.7; H.3.3"], "pdf": "https://arxiv.org/pdf/2511.03217", "abs": "https://arxiv.org/abs/2511.03217", "authors": ["Shaghayegh Kolli", "Richard Rosenbaum", "Timo Cavelius", "Lasse Strothe", "Andrii Lata", "Jana Diesner"], "title": "Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification", "comment": "Paper has been accepted at 9th wiNLP workshop at EMNLP", "summary": "Large language models (LLMs) excel in generating fluent utterances but can\nlack reliable grounding in verified information. At the same time,\nknowledge-graph-based fact-checkers deliver precise and interpretable evidence,\nyet suffer from limited coverage or latency. By integrating LLMs with knowledge\ngraphs and real-time search agents, we introduce a hybrid fact-checking\napproach that leverages the individual strengths of each component. Our system\ncomprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid\none-hop lookups in DBpedia, 2) an LM-based classification guided by a\ntask-specific labeling prompt, producing outputs with internal rule-based\nlogic, and 3) a Web Search Agent invoked only when KG coverage is insufficient.\nOur pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the\nSupported/Refuted split without task-specific fine-tuning. To address Not\nenough information cases, we conduct a targeted reannotation study showing that\nour approach frequently uncovers valid evidence for claims originally labeled\nas Not Enough Information (NEI), as confirmed by both expert annotators and LLM\nreviewers. With this paper, we present a modular, opensource fact-checking\npipeline with fallback strategies and generalization across datasets.", "AI": {"tldr": "本文提出了一种混合事实核查方法，结合大型语言模型（LLM）、知识图谱（KG）和实时网络搜索，以解决LLM缺乏事实依据和KG覆盖范围有限的问题，实现了高准确性和泛化能力。", "motivation": "大型语言模型在生成流畅文本方面表现出色，但可能缺乏可靠的事实依据；基于知识图谱的事实核查器能提供精确可解释的证据，但受限于覆盖范围或延迟。研究动机是整合两者的优势，克服各自的弱点。", "method": "该系统包含三个自主步骤：1) 知识图谱检索，用于在DBpedia中进行快速单跳查找；2) 基于语言模型的分类，由任务特定的标注提示引导，并结合内部规则逻辑；3) 仅当知识图谱覆盖不足时才调用的网络搜索代理。", "result": "该流水线在FEVER基准测试的“支持/反驳”分类上实现了0.93的F1分数，且无需进行任务特定的微调。针对“信息不足”（NEI）的情况，目标重标注研究表明，该方法经常能为最初标记为NEI的主张发现有效证据，并得到了专家标注者和LLM评审员的证实。", "conclusion": "本文提出了一个模块化、开源的事实核查流水线，具有回退策略，并能在不同数据集之间泛化，有效整合了LLM、知识图谱和网络搜索的优势。"}}
{"id": "2511.03550", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03550", "abs": "https://arxiv.org/abs/2511.03550", "authors": ["Hong Wang", "Ridhima Phatak", "James Ocampo", "Zhao Han"], "title": "Indicating Robot Vision Capabilities with Augmented Reality", "comment": null, "summary": "Research indicates that humans can mistakenly assume that robots and humans\nhave the same field of view (FoV), possessing an inaccurate mental model of\nrobots. This misperception may lead to failures during human-robot\ncollaboration tasks where robots might be asked to complete impossible tasks\nabout out-of-view objects. The issue is more severe when robots do not have a\nchance to scan the scene to update their world model while focusing on assigned\ntasks. To help align humans' mental models of robots' vision capabilities, we\npropose four FoV indicators in augmented reality (AR) and conducted a user\nhuman-subjects experiment (N=41) to evaluate them in terms of accuracy,\nconfidence, task efficiency, and workload. These indicators span a spectrum\nfrom egocentric (robot's eye and head space) to allocentric (task space).\nResults showed that the allocentric blocks at the task space had the highest\naccuracy with a delay in interpreting the robot's FoV. The egocentric indicator\nof deeper eye sockets, possible for physical alteration, also increased\naccuracy. In all indicators, participants' confidence was high while cognitive\nload remained low. Finally, we contribute six guidelines for practitioners to\napply our AR indicators or physical alterations to align humans' mental models\nwith robots' vision capabilities.", "AI": {"tldr": "研究发现人类常误解机器人的视野范围（FoV），导致人机协作失败。本文提出并评估了四种增强现实（AR）FoV指示器，旨在校准人类对机器人视觉能力的心理模型，结果显示异中心和物理改动（如深眼窝）指示器能提高准确性，并提供了六条实践指南。", "motivation": "人类常对机器人的视野范围（FoV）存在不准确的心理模型，导致在人机协作任务中可能给机器人分配超出其视野范围的“不可能”任务，尤其是在机器人无法扫描场景更新世界模型时，这种误解更为严重。", "method": "提出了四种AR FoV指示器，涵盖从以自我为中心（机器人视角和头部空间）到以异物为中心（任务空间）的范围。通过一项包含41名参与者的人体实验，评估了这些指示器在准确性、信心、任务效率和工作量方面的表现。", "result": "结果表明，任务空间中的异中心方块指示器具有最高的准确性，但解释机器人FoV时存在延迟。此外，通过物理改变（如更深的眼窝）实现的以自我为中心的指示器也提高了准确性。所有指示器都使参与者保持高信心和低认知负荷。", "conclusion": "本研究为实践者提供了六项指导方针，以应用所提出的AR指示器或进行物理改动，从而校准人类对机器人视觉能力的心理模型。"}}
{"id": "2511.03235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03235", "abs": "https://arxiv.org/abs/2511.03235", "authors": ["Yi-Fei Liu", "Yi-Long Lu", "Di He", "Hang Zhang"], "title": "From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers", "comment": null, "summary": "Psychological constructs within individuals are widely believed to be\ninterconnected. We investigated whether and how Large Language Models (LLMs)\ncan model the correlational structure of human psychological traits from\nminimal quantitative inputs. We prompted various LLMs with Big Five Personality\nScale responses from 816 human individuals to role-play their responses on nine\nother psychological scales. LLMs demonstrated remarkable accuracy in capturing\nhuman psychological structure, with the inter-scale correlation patterns from\nLLM-generated responses strongly aligning with those from human data $(R^2 >\n0.89)$. This zero-shot performance substantially exceeded predictions based on\nsemantic similarity and approached the accuracy of machine learning algorithms\ntrained directly on the dataset. Analysis of reasoning traces revealed that\nLLMs use a systematic two-stage process: First, they transform raw Big Five\nresponses into natural language personality summaries through information\nselection and compression, analogous to generating sufficient statistics.\nSecond, they generate target scale responses based on reasoning from these\nsummaries. For information selection, LLMs identify the same key personality\nfactors as trained algorithms, though they fail to differentiate item\nimportance within factors. The resulting compressed summaries are not merely\nredundant representations but capture synergistic information--adding them to\noriginal scores enhances prediction alignment, suggesting they encode emergent,\nsecond-order patterns of trait interplay. Our findings demonstrate that LLMs\ncan precisely predict individual participants' psychological traits from\nminimal data through a process of abstraction and reasoning, offering both a\npowerful tool for psychological simulation and valuable insights into their\nemergent reasoning capabilities.", "AI": {"tldr": "研究发现大型语言模型（LLMs）能从最少输入中准确模拟人类心理特质的相关结构，其通过抽象和推理的两阶段过程，性能优于语义相似度，接近于经过训练的机器学习算法。", "motivation": "心理构念被广泛认为是相互关联的。本研究旨在探究LLMs是否以及如何能够从最少的定量输入中建模人类心理特质的相关结构。", "method": "研究人员向不同的LLMs提供了来自816名人类受试者的“大五人格量表”答复，并要求LLMs扮演角色，对其他九个心理量表做出回应。他们比较了LLM生成的回应与人类数据之间的量表间相关模式，并分析了LLMs的推理轨迹。", "result": "LLMs在捕捉人类心理结构方面表现出卓越的准确性，其生成的量表间相关模式与人类数据高度一致（R² > 0.89）。这种零样本表现显著优于基于语义相似性的预测，并接近于直接在数据集上训练的机器学习算法。分析显示，LLMs采用系统性的两阶段过程：首先，将原始“大五”答复转化为自然语言人格摘要；其次，基于这些摘要进行推理生成目标量表回应。LLMs识别出与训练算法相同的关键人格因素，但未能区分因素内部的项目重要性。压缩后的摘要不仅是冗余表示，还捕获了协同信息，能增强预测一致性。", "conclusion": "研究表明，LLMs能够通过抽象和推理过程，从最少的数据中精确预测个体参与者的心理特质。这为心理模拟提供了一个强大的工具，并为LLMs的涌现推理能力提供了有价值的见解。"}}
{"id": "2511.03126", "categories": ["cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03126", "abs": "https://arxiv.org/abs/2511.03126", "authors": ["Hongbo Lan", "Zhenlin An", "Haoyu Li", "Vaibhav Singh", "Longfei Shangguan"], "title": "Accelerating Physical Property Reasoning for Augmented Visual Cognition", "comment": null, "summary": "This paper introduces \\sysname, a system that accelerates vision-guided\nphysical property reasoning to enable augmented visual cognition. \\sysname\nminimizes the run-time latency of this reasoning pipeline through a combination\nof both algorithmic and systematic optimizations, including rapid geometric 3D\nreconstruction, efficient semantic feature fusion, and parallel view encoding.\nThrough these simple yet effective optimizations, \\sysname reduces the\nend-to-end latency of this reasoning pipeline from 10--20 minutes to less than\n6 seconds. A head-to-head comparison on the ABO dataset shows that \\sysname\nachieves this 62.9$\\times$--287.2$\\times$ speedup while not only reaching\non-par (and sometimes slightly better) object-level physical property\nestimation accuracy(e.g. mass), but also demonstrating superior performance in\nmaterial segmentation and voxel-level inference than two SOTA baselines. We\nfurther combine gaze-tracking with \\sysname to localize the object of interest\nin cluttered, real-world environments, streamlining the physical property\nreasoning on smart glasses. The case study with Meta Aria Glasses conducted at\nan IKEA furniture store demonstrates that \\sysname achives consistently high\nperformance compared to controlled captures, providing robust property\nestimations even with fewer views in real-world scenarios.", "AI": {"tldr": "本文介绍了一个名为\\sysname的系统，通过算法和系统优化，将视觉引导的物理属性推理的端到端延迟从10-20分钟缩短到6秒以内，同时保持或提高了估计精度，并在真实世界环境中展现出强大的鲁棒性。", "motivation": "当前的视觉引导物理属性推理管道存在高延迟问题（10-20分钟），这限制了增强视觉认知（augmented visual cognition）的应用和实时性需求。", "method": "该系统采用了一系列算法和系统优化措施，包括快速几何3D重建、高效语义特征融合和并行视图编码。此外，还结合了眼动追踪技术来定位复杂真实环境中的目标物体，以实现智能眼镜上的物理属性推理。", "result": "\\sysname将推理管道的端到端延迟从10-20分钟缩短到不到6秒，实现了62.9倍至287.2倍的加速。在ABO数据集上，其物体级别物理属性（如质量）估计精度与现有SOTA基线相当甚至略优，并在材料分割和体素级别推理方面表现更佳。在真实世界场景中，即使视图较少，也能提供鲁棒且一致的高性能属性估计。", "conclusion": "\\sysname通过显著降低延迟并保持高精度，极大地加速了视觉引导的物理属性推理，使其能够应用于智能眼镜等设备，在真实、复杂的环境中实现强大的增强视觉认知能力。"}}
{"id": "2511.03494", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03494", "abs": "https://arxiv.org/abs/2511.03494", "authors": ["Amir Bahador Javadi", "Philip Pong"], "title": "Data-driven Modeling of Grid-following Control in Grid-connected Converters", "comment": null, "summary": "As power systems evolve with the integration of renewable energy sources and\nthe implementation of smart grid technologies, there is an increasing need for\nflexible and scalable modeling approaches capable of accurately capturing the\ncomplex dynamics of modern grids. To meet this need, various methods, such as\nthe sparse identification of nonlinear dynamics and deep symbolic regression,\nhave been developed to identify dynamical systems directly from data. In this\nstudy, we examine the application of a converter-based resource as a\nreplacement for a traditional generator within a lossless transmission line\nlinked to an infinite bus system. This setup is used to generate synthetic data\nin grid-following control mode, enabling the evaluation of these methods in\neffectively capturing system dynamics.", "AI": {"tldr": "本研究通过一个包含变流器型资源的简化电力系统生成合成数据，以评估数据驱动方法（如SINDy和深度符号回归）捕获现代电网复杂动态的能力。", "motivation": "随着可再生能源整合和智能电网技术实施，电力系统日益复杂，需要灵活、可扩展的建模方法来准确捕捉其动态。现有的数据驱动方法（如稀疏非线性动力学识别和深度符号回归）能够直接从数据中识别动态系统，本研究旨在评估它们在此场景下的有效性。", "method": "研究设置了一个变流器型资源替代传统发电机，连接到无限母线系统的无损输电线路中。在此配置下，以并网跟随控制模式生成合成数据。这些数据被用于评估SINDy和深度符号回归等方法在捕获系统动态方面的能力。", "result": "通过上述设置，成功生成了在并网跟随控制模式下的合成数据。这些数据为评估数据驱动方法（如稀疏非线性动力学识别和深度符号回归）有效捕获电力系统动态提供了基础。", "conclusion": "本研究建立了一个用于生成合成数据并评估数据驱动方法捕获现代电力系统动态的框架，特别关注了变流器型资源在并网跟随模式下的行为。这为进一步评估这些方法在应对复杂电网挑战方面的潜力奠定了基础。"}}
{"id": "2511.03471", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.03471", "abs": "https://arxiv.org/abs/2511.03471", "authors": ["Ming Gu", "Ziwei Wang", "Sicen Lai", "Zirui Gao", "Sheng Zhou", "Jiajun Bu"], "title": "Towards Scalable Web Accessibility Audit with MLLMs as Copilots", "comment": "15 pages. Accepted by AAAI 2026 AISI", "summary": "Ensuring web accessibility is crucial for advancing social welfare, justice,\nand equality in digital spaces, yet the vast majority of website user\ninterfaces remain non-compliant, due in part to the resource-intensive and\nunscalable nature of current auditing practices. While WCAG-EM offers a\nstructured methodology for site-wise conformance evaluation, it involves great\nhuman efforts and lacks practical support for execution at scale. In this work,\nwe present an auditing framework, AAA, which operationalizes WCAG-EM through a\nhuman-AI partnership model. AAA is anchored by two key innovations: GRASP, a\ngraph-based multimodal sampling method that ensures representative page\ncoverage via learned embeddings of visual, textual, and relational cues; and\nMaC, a multimodal large language model-based copilot that supports auditors\nthrough cross-modal reasoning and intelligent assistance in high-effort tasks.\nTogether, these components enable scalable, end-to-end web accessibility\nauditing, empowering human auditors with AI-enhanced assistance for real-world\nimpact. We further contribute four novel datasets designed for benchmarking\ncore stages of the audit pipeline. Extensive experiments demonstrate the\neffectiveness of our methods, providing insights that small-scale language\nmodels can serve as capable experts when fine-tuned.", "AI": {"tldr": "本文提出了一个名为AAA的人机协作框架，通过图基多模态采样方法GRASP和多模态大语言模型副驾驶MaC，将WCAG-EM操作化，实现了可扩展、端到端的网络无障碍审计，并贡献了四个新数据集。", "motivation": "网络无障碍对于数字空间的社会福利、正义和公平至关重要，然而绝大多数网站用户界面不合规。当前的审计实践（如WCAG-EM）资源密集且难以扩展，需要大量人工投入，缺乏大规模执行的实际支持。", "method": "本研究提出了AAA审计框架，通过人机协作模式将WCAG-EM操作化。AAA包含两项关键创新：1) GRASP，一种基于图的多模态采样方法，利用视觉、文本和关系线索的学习嵌入确保代表性的页面覆盖；2) MaC，一个基于多模态大语言模型的副驾驶，通过跨模态推理和智能辅助支持审计人员完成高难度任务。此外，还贡献了四个用于基准测试审计流程核心阶段的新数据集。", "result": "广泛的实验证明了所提出方法的有效性，并提供了见解，表明经过微调的小规模语言模型可以作为有能力的专家。", "conclusion": "AAA框架通过AI增强的辅助，使人类审计员能够进行可扩展、端到端的网络无障碍审计，从而在现实世界中产生影响。"}}
{"id": "2511.03228", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.03228", "abs": "https://arxiv.org/abs/2511.03228", "authors": ["Shantanu Agarwal", "Joel Barry", "Elizabeth Boschee", "Scott Miller"], "title": "Beyond Ranked Lists: The SARAL Framework for Cross-Lingual Document Set Retrieval", "comment": null, "summary": "Machine Translation for English Retrieval of Information in Any Language\n(MATERIAL) is an IARPA initiative targeted to advance the state of\ncross-lingual information retrieval (CLIR). This report provides a detailed\ndescription of Information Sciences Institute's (ISI's) Summarization and\ndomain-Adaptive Retrieval Across Language's (SARAL's) effort for MATERIAL.\nSpecifically, we outline our team's novel approach to handle CLIR with emphasis\nin developing an approach amenable to retrieve a query-relevant document\n\\textit{set}, and not just a ranked document-list. In MATERIAL's Phase-3\nevaluations, SARAL exceeded the performance of other teams in five out of six\nevaluation conditions spanning three different languages (Farsi, Kazakh, and\nGeorgian).", "AI": {"tldr": "ISI的SARAL项目在IARPA的MATERIAL计划中，通过一种新颖的方法，在跨语言信息检索（CLIR）方面取得了显著进展，特别是在检索相关文档集方面表现出色，超越了大多数竞争团队。", "motivation": "本研究的动机是IARPA的MATERIAL（Machine Translation for English Retrieval of Information in Any Language）计划，旨在推动跨语言信息检索（CLIR）的最新进展。ISI的SARAL团队为此贡献了他们的努力。", "method": "该团队提出了一种新颖的CLIR方法，重点是开发一种能够检索到与查询相关的“文档集”，而不仅仅是生成一个排序的文档列表。", "result": "在MATERIAL的第三阶段评估中，SARAL团队在涵盖三种不同语言（波斯语、哈萨克语和格鲁吉亚语）的六种评估条件中的五种中，表现优于其他团队。", "conclusion": "ISI的SARAL项目为MATERIAL计划开发的CLIR方法，特别是其检索相关文档集的能力，被证明是高度有效和成功的，在多语言环境下超越了竞争对手的表现。"}}
{"id": "2511.03594", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03594", "abs": "https://arxiv.org/abs/2511.03594", "authors": ["Suraj Kumar", "Aditya Rallapalli", "Ashok Kumar Kakula", "Bharat Kumar GVP"], "title": "Powered Descent Trajectory Optimization of Chandrayaan-3 using Radau Collocation and Controllable Sets", "comment": "6 pages, 6 figure, Accepted for publication in Indian Control\n  Conference 2025", "summary": "India achieved a significant milestone on August $23^{\\text{rd}}$ 2023,\nbecoming the fourth country to accomplish a soft landing on the Moon. This\npaper presents the powered descent trajectory design for the Chandrayaan-3\nmission. The optimization framework is based on pseudospectral Radau\ncollocation, and controllability-based waypoint refinement is employed to\nfurther enhance the robustness of the trajectory against state and control\nperturbations. Furthermore, the trade-off between fuel consumption and\nrobustness is explicitly quantified, providing insights into the practical\nconsiderations of mission planning.", "AI": {"tldr": "本文介绍了印度“月船3号”任务的动力下降轨迹设计，该设计采用伪谱Radau搭配法和基于可控性的航路点优化，以平衡燃料消耗和轨迹鲁棒性。", "motivation": "印度于2023年8月23日成功实现月球软着陆，成为第四个实现此成就的国家。本文旨在详细介绍“月船3号”任务的动力下降轨迹设计。", "method": "优化框架基于伪谱Radau搭配法。采用基于可控性的航路点优化来增强轨迹对状态和控制扰动的鲁棒性。此外，明确量化了燃料消耗与鲁棒性之间的权衡。", "result": "本文展示了“月船3号”任务的动力下降轨迹设计，并明确量化了燃料消耗与鲁棒性之间的权衡，为任务规划提供了实用见解。", "conclusion": "通过量化燃料消耗与鲁棒性之间的权衡，本研究为月球任务规划的实际考量提供了深入见解。"}}
{"id": "2511.03132", "categories": ["cs.CV", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.03132", "abs": "https://arxiv.org/abs/2511.03132", "authors": ["Thomas Manzini", "Priyankari Perali", "Robin R. Murphy"], "title": "Deploying Rapid Damage Assessments from sUAS Imagery for Disaster Response", "comment": "6 pages, 4 figures, 1 table. Accepted - In Press, IAAI'26", "summary": "This paper presents the first AI/ML system for automating building damage\nassessment in uncrewed aerial systems (sUAS) imagery to be deployed\noperationally during federally declared disasters (Hurricanes Debby and\nHelene). In response to major disasters, sUAS teams are dispatched to collect\nimagery of the affected areas to assess damage; however, at recent disasters,\nteams collectively delivered between 47GB and 369GB of imagery per day,\nrepresenting more imagery than can reasonably be transmitted or interpreted by\nsubject matter experts in the disaster scene, thus delaying response efforts.\nTo alleviate this data avalanche encountered in practice, computer vision and\nmachine learning techniques are necessary. While prior work has been deployed\nto automatically assess damage in satellite imagery, there is no current state\nof practice for sUAS-based damage assessment systems, as all known work has\nbeen confined to academic settings. This work establishes the state of practice\nvia the development and deployment of models for building damage assessment\nwith sUAS imagery. The model development involved training on the largest known\ndataset of post-disaster sUAS aerial imagery, containing 21,716 building damage\nlabels, and the operational training of 91 disaster practitioners. The best\nperforming model was deployed during the responses to Hurricanes Debby and\nHelene, where it assessed a combined 415 buildings in approximately 18 minutes.\nThis work contributes documentation of the actual use of AI/ML for damage\nassessment during a disaster and lessons learned to the benefit of the AI/ML\nresearch and user communities.", "AI": {"tldr": "本文介绍了首个在联邦宣布的灾害（飓风黛比和海伦）中实际部署的，用于自动化无人机（sUAS）图像建筑损害评估的AI/ML系统。", "motivation": "在重大灾害发生后，无人机团队每天收集大量图像（47GB至369GB），超出了现场专家合理传输和解读的能力，从而延误了响应工作。尽管已有卫星图像的自动化损害评估工作，但无人机图像的损害评估系统仍停留在学术阶段，缺乏实际应用。", "method": "开发并部署了用于无人机图像建筑损害评估的AI/ML模型。模型训练使用了已知最大的灾后无人机航空图像数据集，包含21,716个建筑损害标签。同时，对91名灾害从业人员进行了操作培训。性能最佳的模型在实际灾害响应中得到了部署。", "result": "性能最佳的模型在飓风黛比和海伦的响应期间投入使用，在约18分钟内评估了总计415座建筑物。", "conclusion": "这项工作建立了无人机图像损害评估的AI/ML实践现状，记录了AI/ML在灾害中进行损害评估的实际应用，并为AI/ML研究和用户社区提供了经验教训。"}}
{"id": "2511.03576", "categories": ["cs.RO", "cs.AI", "68T40", "I.2.9; I.2.4"], "pdf": "https://arxiv.org/pdf/2511.03576", "abs": "https://arxiv.org/abs/2511.03576", "authors": ["Aniol Civit", "Antonio Andriella", "Carles Sierra", "Guillem Alenyà"], "title": "Multi-User Personalisation in Human-Robot Interaction: Using Quantitative Bipolar Argumentation Frameworks for Preferences Conflict Resolution", "comment": "Preprint submitted to a journal", "summary": "While personalisation in Human-Robot Interaction (HRI) has advanced\nsignificantly, most existing approaches focus on single-user adaptation,\noverlooking scenarios involving multiple stakeholders with potentially\nconflicting preferences. To address this, we propose the Multi-User Preferences\nQuantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-user\npersonalisation framework based on Quantitative Bipolar Argumentation\nFrameworks (QBAFs) that explicitly models and resolves multi-user preference\nconflicts. Unlike prior work in Argumentation Frameworks, which typically\nassumes static inputs, our approach is tailored to robotics: it incorporates\nboth users' arguments and the robot's dynamic observations of the environment,\nallowing the system to adapt over time and respond to changing contexts.\nPreferences, both positive and negative, are represented as arguments whose\nstrength is recalculated iteratively based on new information. The framework's\nproperties and capabilities are presented and validated through a realistic\ncase study, where an assistive robot mediates between the conflicting\npreferences of a caregiver and a care recipient during a frailty assessment\ntask. This evaluation further includes a sensitivity analysis of argument base\nscores, demonstrating how preference outcomes can be shaped by user input and\ncontextual observations. By offering a transparent, structured, and\ncontext-sensitive approach to resolving competing user preferences, this work\nadvances the field of multi-user HRI. It provides a principled alternative to\ndata-driven methods, enabling robots to navigate conflicts in real-world\nenvironments.", "AI": {"tldr": "该研究提出了MUP-QBAF框架，这是一个基于量化双极论证框架的新型多用户个性化方法，旨在解决人机交互中多用户间冲突的偏好，并结合机器人动态环境观察进行适应性调整。", "motivation": "现有的人机交互个性化方法主要关注单用户适应性，忽略了多利益相关者可能存在冲突偏好的场景。为了解决这一多用户偏好冲突问题，本研究提出了新的框架。", "method": "本研究提出了多用户偏好量化双极论证框架（MUP-QBAF）。该框架基于量化双极论证框架（QBAFs），显式建模并解决多用户偏好冲突。与以往论证框架不同，它结合了用户的论点和机器人对环境的动态观察，允许系统随时间适应和响应变化的情境。偏好（包括正面和负面）被表示为论点，其强度根据新信息迭代重新计算。", "result": "通过一个现实案例研究（辅助机器人在体弱评估任务中调解看护者和受助者之间的冲突偏好），验证了该框架的属性和能力。评估还包括对论点基础分数的敏感性分析，展示了用户输入和上下文观察如何影响偏好结果。", "conclusion": "该工作为解决竞争性用户偏好提供了一种透明、结构化和上下文敏感的方法，推动了多用户人机交互领域的发展。它为数据驱动方法提供了一个有原则的替代方案，使机器人能够在现实世界环境中处理冲突。"}}
{"id": "2511.03545", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03545", "abs": "https://arxiv.org/abs/2511.03545", "authors": ["Sebastian Ordyniak", "Giacomo Paesani", "Mateusz Rychlicki", "Stefan Szeider"], "title": "Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)", "comment": "Part I of a greatly enhanced version of\n  https://doi.org/10.24963/kr.2024/53, whose full version is available on arXiv\n  under https://doi.org/10.48550/arXiv.2407.15780", "summary": "This paper presents a comprehensive theoretical investigation into the\nparameterized complexity of explanation problems in various machine learning\n(ML) models. Contrary to the prevalent black-box perception, our study focuses\non models with transparent internal mechanisms. We address two principal types\nof explanation problems: abductive and contrastive, both in their local and\nglobal variants. Our analysis encompasses diverse ML models, including Decision\nTrees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,\neach offering unique explanatory challenges. This research fills a significant\ngap in explainable AI (XAI) by providing a foundational understanding of the\ncomplexities of generating explanations for these models. This work provides\ninsights vital for further research in the domain of XAI, contributing to the\nbroader discourse on the necessity of transparency and accountability in AI\nsystems.", "AI": {"tldr": "本文对透明机器学习模型中解释问题的参数化复杂性进行了全面的理论研究。", "motivation": "现有研究在可解释AI (XAI) 领域中，缺乏对透明内部机制模型生成解释复杂性的基础理解，本研究旨在填补这一空白，并促进AI系统透明度和可问责性的讨论。", "method": "采用理论调查方法，研究了多种透明ML模型（包括决策树、决策集、决策列表、布尔电路及其集成）中，溯因式和对比式（局部和全局）两种主要解释问题的参数化复杂性。", "result": "本研究提供了对为透明ML模型生成解释的复杂性的基础理解，并为XAI领域的进一步研究提供了重要见解。", "conclusion": "本工作为可解释AI领域奠定了理论基础，并强调了AI系统透明度和可问责性的重要性。"}}
{"id": "2511.03591", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.03591", "abs": "https://arxiv.org/abs/2511.03591", "authors": ["Qingyi Chen", "Ruiqi Ni", "Jun Kim", "Ahmed H. Qureshi"], "title": "Manifold-constrained Hamilton-Jacobi Reachability Learning for Decentralized Multi-Agent Motion Planning", "comment": null, "summary": "Safe multi-agent motion planning (MAMP) under task-induced constraints is a\ncritical challenge in robotics. Many real-world scenarios require robots to\nnavigate dynamic environments while adhering to manifold constraints imposed by\ntasks. For example, service robots must carry cups upright while avoiding\ncollisions with humans or other robots. Despite recent advances in\ndecentralized MAMP for high-dimensional systems, incorporating manifold\nconstraints remains difficult. To address this, we propose a\nmanifold-constrained Hamilton-Jacobi reachability (HJR) learning framework for\ndecentralized MAMP. Our method solves HJR problems under manifold constraints\nto capture task-aware safety conditions, which are then integrated into a\ndecentralized trajectory optimization planner. This enables robots to generate\nmotion plans that are both safe and task-feasible without requiring assumptions\nabout other agents' policies. Our approach generalizes across diverse\nmanifold-constrained tasks and scales effectively to high-dimensional\nmulti-agent manipulation problems. Experiments show that our method outperforms\nexisting constrained motion planners and operates at speeds suitable for\nreal-world applications. Video demonstrations are available at\nhttps://youtu.be/RYcEHMnPTH8 .", "AI": {"tldr": "本文提出了一种流形约束的哈密顿-雅可比可达性（HJR）学习框架，用于解决多智能体运动规划中任务诱导的流形约束问题，实现了安全且任务可行的分散式运动规划。", "motivation": "多智能体运动规划（MAMP）在动态环境中，同时遵守任务施加的流形约束（例如，服务机器人需保持杯子直立），是一个关键挑战。尽管分散式MAMP在处理高维系统方面有所进展，但整合流形约束仍然困难。", "method": "本文提出了一种流形约束的哈密顿-雅可比可达性（HJR）学习框架。该方法在流形约束下求解HJR问题以捕捉任务感知安全条件，然后将这些条件整合到一个分散式轨迹优化规划器中。", "result": "该方法能够生成既安全又任务可行的运动计划，且无需假设其他智能体的策略。它能推广到各种流形约束任务，并有效扩展到高维多智能体操作问题。实验表明，该方法优于现有约束运动规划器，并能以适用于实际应用的速度运行。", "conclusion": "所提出的流形约束HJR学习框架有效解决了多智能体运动规划中的任务诱导流形约束问题，提供了一种可扩展、高性能的解决方案，适用于实际应用中的安全多智能体操作。"}}
{"id": "2511.03237", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03237", "abs": "https://arxiv.org/abs/2511.03237", "authors": ["Souvik Rana", "Arul Menezes", "Ashish Kulkarni", "Chandra Khatri", "Shubham Agarwal"], "title": "IndicSuperTokenizer: An Optimized Tokenizer for Indic Multilingual LLMs", "comment": null, "summary": "Tokenizers play a crucial role in determining the performance, training\nefficiency, and the inference cost of Large Language Models (LLMs). Designing\neffective tokenizers for multilingual LLMs is particularly challenging due to\ndiverse scripts and rich morphological variation. While subword methods such as\nByte Pair Encoding (BPE) are widely adopted, their effectiveness in\nmultilingual settings remains underexplored. We present IndicSuperTokenizer, a\ntokenizer for Indic multilingual LLMs, that combines both subword and\nmulti-word tokenization, along with language-specific pre-tokenization, leading\nto more linguistically aligned tokens and achieving a new state-of-the-art in\nfertility score. Evaluated across English, 22 Indian languages and code data,\nour tokenizer improves the average fertility score by 39.5% over LLaMA4 and by\n18% over Sutra (the current best). This translates to 44% improvement in\ninference throughput over LLaMA4 while maintaining comparable performance on\nEnglish and Indic benchmarks. We also present detailed ablations across\ntokenizer training data size, vocabulary size, merging techniques, and\npre-tokenization strategies, demonstrating the robustness of our design\nchoices.", "AI": {"tldr": "本文提出IndicSuperTokenizer，一种结合子词和多词分词以及语言特定预分词的印地语多语言LLM分词器，显著提高了分词效率（fertility score）和推理吞吐量，同时保持性能。", "motivation": "分词器对大型语言模型（LLMs）的性能、训练效率和推理成本至关重要。为多语言LLMs设计有效的分词器极具挑战性，尤其对于具有多样脚本和丰富形态变化的印地语系语言。子词方法（如BPE）虽然广泛应用，但在多语言环境中的有效性仍未被充分探索。", "method": "研究者提出了IndicSuperTokenizer，它结合了子词和多词分词技术，并加入了语言特定的预分词策略。该分词器在英语、22种印度语言和代码数据上进行了评估，并进行了分词器训练数据大小、词汇量大小、合并技术和预分词策略的详细消融实验。", "result": "IndicSuperTokenizer在分词效率（fertility score）上取得了新的最先进水平，相较于LLaMA4提高了39.5%，相较于Sutra（当前最佳）提高了18%。这转化为推理吞吐量相较于LLaMA4提高了44%，同时在英语和印地语基准测试上保持了可比的性能。详细的消融实验也证明了其设计选择的鲁棒性。", "conclusion": "所提出的IndicSuperTokenizer通过结合子词和多词分词以及语言特定预分词，为印地语多语言LLMs提供了更具语言对齐性的分词器，显著提升了分词效率和推理吞吐量，证明了其设计的有效性和鲁棒性。"}}
{"id": "2511.03603", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03603", "abs": "https://arxiv.org/abs/2511.03603", "authors": ["Victor Gracia", "Pablo Krupa", "Filiberto Fele", "Teodoro Alamo"], "title": "Artificial-reference tracking MPC with probabilistically validated performance on industrial embedded systems", "comment": "14 pages, 24 figures", "summary": "Industrial embedded systems are typically used to execute simple control\nalgorithms due to their low computational resources. Despite these limitations,\nthe implementation of advanced control techniques such as Model Predictive\nControl (MPC) has been explored by the control community in recent years,\ntypically considering simple linear formulations or explicit ones to facilitate\nthe online computation of the control input. These simplifications often lack\nfeatures and properties that are desirable in real-world environments. In this\narticle, we present an efficient implementation for embedded systems of MPC for\ntracking with artificial reference, solved via a recently developed\nstructure-exploiting first-order method. This formulation is tailored to a wide\nrange of applications by incorporating essential practical features at a small\ncomputational cost, including integration with an offset-free scheme, back-off\nparameters that enable constraint tightening, and soft constraints that\npreserve feasibility under disturbances or plant-model mismatch. We accompany\nthis with a framework for probabilistic performance validation of the\nclosed-loop system over long-term operation. We illustrate the applicability of\nthe approach on a Programmable Logic Controller (PLC), incorporated in a\nhardware-in-the-loop setup to control a nonlinear continuous stirred-tank\nreactor. The behavior of the closed-loop system is probabilistically validated\nwith respect to constraint violations and the number of iterations required at\neach time step by the MPC optimization algorithm.", "AI": {"tldr": "本文提出了一种针对嵌入式系统的高效模型预测控制（MPC）实现，用于人工参考跟踪，该方案结合了实用的控制特性并进行了概率性能验证。", "motivation": "工业嵌入式系统计算资源有限，但高级控制技术（如MPC）的应用日益受到关注。现有MPC简化方案往往缺乏实际环境中所需的特性和属性。", "method": "本文实现了一种针对人工参考跟踪的MPC，通过最近开发的结构利用一阶方法求解。该实现融入了关键的实用特性，如无偏差方案集成、用于约束收紧的退避参数以及在扰动或模型失配下保持可行性的软约束。此外，还提出了一个用于长期运行闭环系统概率性能验证的框架。该方法在一个可编程逻辑控制器（PLC）上进行了验证，通过硬件在环设置控制一个非线性连续搅拌釜反应器。", "result": "所提出的方法成功应用于PLC，并能有效控制非线性连续搅拌釜反应器。闭环系统的行为通过概率验证，评估了约束违反情况以及MPC优化算法在每个时间步所需的迭代次数。", "conclusion": "本文为嵌入式系统提供了一个高效、功能丰富的MPC实现方案，适用于广泛的应用。该方案通过结合实用特性并进行概率性能验证，克服了传统嵌入式MPC的局限性，并展示了其在实际工业环境中的潜力。"}}
{"id": "2511.03724", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03724", "abs": "https://arxiv.org/abs/2511.03724", "authors": ["Richard Dewey", "Janos Botyanszki", "Ciamac C. Moallemi", "Andrew T. Zheng"], "title": "Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning", "comment": null, "summary": "AI researchers have long focused on poker-like games as a testbed for\nenvironments characterized by multi-player dynamics, imperfect information, and\nreasoning under uncertainty. While recent breakthroughs have matched elite\nhuman play at no-limit Texas hold'em, the multi-player dynamics are subdued:\nmost hands converge quickly with only two players engaged through multiple\nrounds of bidding. In this paper, we present Solly, the first AI agent to\nachieve elite human play in reduced-format Liar's Poker, a game characterized\nby extensive multi-player engagement. We trained Solly using self-play with a\nmodel-free, actor-critic, deep reinforcement learning algorithm. Solly played\nat an elite human level as measured by win rate (won over 50% of hands) and\nequity (money won) in heads-up and multi-player Liar's Poker. Solly also\noutperformed large language models (LLMs), including those with reasoning\nabilities, on the same metrics. Solly developed novel bidding strategies,\nrandomized play effectively, and was not easily exploitable by world-class\nhuman players.", "AI": {"tldr": "Solly是首个在多玩家“吹牛扑克”（Liar's Poker）中达到精英人类水平的AI代理，它通过深度强化学习进行自我对弈训练，超越了大型语言模型，并开发出新颖的策略。", "motivation": "AI研究在扑克类游戏（如无限注德州扑克）中取得了突破，但这些游戏的多数手牌中多玩家动态不明显。研究人员希望解决具有广泛多玩家互动、不完美信息和不确定性推理特点的游戏挑战。", "method": "Solly通过自我对弈训练，采用了无模型、actor-critic深度强化学习算法。", "result": "Solly在单挑和多玩家“吹牛扑克”中均达到了精英人类水平，其胜率超过50%，且在收益方面表现出色。它在相同指标上优于包括具有推理能力在内的大型语言模型。Solly发展出新颖的叫牌策略，有效地随机化了玩法，并且不易被世界级人类玩家利用。", "conclusion": "Solly证明了AI在处理具有复杂多玩家动态和不完美信息的游戏中达到了新的里程碑，展示了其在“吹牛扑克”中超越人类和LLMs的能力，并开发出不易被利用的策略。"}}
{"id": "2511.03156", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03156", "abs": "https://arxiv.org/abs/2511.03156", "authors": ["Sagar Shrestha", "Gopal Sharma", "Luowei Zhou", "Suren Kumar"], "title": "Finetuning-Free Personalization of Text to Image Generation via Hypernetworks", "comment": null, "summary": "Personalizing text-to-image diffusion models has traditionally relied on\nsubject-specific fine-tuning approaches such as\nDreamBooth~\\cite{ruiz2023dreambooth}, which are computationally expensive and\nslow at inference. Recent adapter- and encoder-based methods attempt to reduce\nthis overhead but still depend on additional fine-tuning or large backbone\nmodels for satisfactory results. In this work, we revisit an orthogonal\ndirection: fine-tuning-free personalization via Hypernetworks that predict\nLoRA-adapted weights directly from subject images. Prior hypernetwork-based\napproaches, however, suffer from costly data generation or unstable attempts to\nmimic base model optimization trajectories. We address these limitations with\nan end-to-end training objective, stabilized by a simple output regularization,\nyielding reliable and effective hypernetworks. Our method removes the need for\nper-subject optimization at test time while preserving both subject fidelity\nand prompt alignment. To further enhance compositional generalization at\ninference time, we introduce Hybrid-Model Classifier-Free Guidance (HM-CFG),\nwhich combines the compositional strengths of the base diffusion model with the\nsubject fidelity of personalized models during sampling. Extensive experiments\non CelebA-HQ, AFHQ-v2, and DreamBench demonstrate that our approach achieves\nstrong personalization performance and highlights the promise of hypernetworks\nas a scalable and effective direction for open-category personalization.", "AI": {"tldr": "本文提出一种无需微调的个性化文本到图像扩散模型方法，通过超网络直接从主题图像预测LoRA权重，并结合端到端训练目标和混合模型无分类器引导（HM-CFG），实现了高效且高质量的主题保真度和组合泛化能力。", "motivation": "传统的个性化方法（如DreamBooth）计算成本高且推理慢。近期基于适配器和编码器的方法虽有所改进，但仍需额外微调或依赖大型骨干模型。之前的超网络方法则面临数据生成昂贵或模仿基模型优化轨迹不稳定的问题。", "method": "本研究重新审视了通过超网络实现无需微调的个性化方向，超网络直接从主题图像预测LoRA适应权重。通过引入一个端到端训练目标，并辅以简单的输出正则化来稳定超网络，解决了现有超网络方法的局限性。为增强推理时的组合泛化能力，提出了混合模型无分类器引导（HM-CFG），它在采样过程中结合了基础扩散模型的组合优势和个性化模型的主题保真度。", "result": "实验在CelebA-HQ、AFHQ-v2和DreamBench数据集上表明，该方法实现了强大的个性化性能，在测试时无需每主题优化，同时保持了主题保真度和提示对齐。HM-CFG进一步增强了组合泛化能力。", "conclusion": "本研究提出的方法证明了超网络在开放类别个性化方面作为一种可扩展且有效方向的巨大潜力，实现了无需微调的高质量个性化文本到图像生成。"}}
{"id": "2511.03261", "categories": ["cs.CL", "cs.AI", "I.2.1; I.2.7"], "pdf": "https://arxiv.org/pdf/2511.03261", "abs": "https://arxiv.org/abs/2511.03261", "authors": ["Ranul Dayarathne", "Uvini Ranaweera", "Upeksha Ganegoda"], "title": "Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature", "comment": "18 pages, 4 figures, 5 tables, presented at the 5th International\n  Conference on Artificial Intelligence in Education Technology", "summary": "Retrieval Augmented Generation (RAG) is emerging as a powerful technique to\nenhance the capabilities of Generative AI models by reducing hallucination.\nThus, the increasing prominence of RAG alongside Large Language Models (LLMs)\nhas sparked interest in comparing the performance of different LLMs in\nquestion-answering (QA) in diverse domains. This study compares the performance\nof four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat,\nFalcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA\ntasks within the computer science literature leveraging RAG support. Evaluation\nmetrics employed in the study include accuracy and precision for binary\nquestions and ranking by a human expert, ranking by Google's AI model Gemini,\nalongside cosine similarity for long-answer questions. GPT-3.5, when paired\nwith RAG, effectively answers binary and long-answer questions, reaffirming its\nstatus as an advanced LLM. Regarding open-source LLMs, Mistral AI's\nMistral-7b-instruct paired with RAG surpasses the rest in answering both binary\nand long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b\nreports the shortest average latency in generating responses, whereas\nLLaMa2-7b-chat by Meta reports the highest average latency. This research\nunderscores the fact that open-source LLMs, too, can go hand in hand with\nproprietary models like GPT-3.5 with better infrastructure.", "AI": {"tldr": "本研究比较了结合RAG技术的四种开源LLM（Mistral-7b、LLaMa2-7b、Falcon-7b、Orca-mini-v3-7b）和GPT-3.5在计算机科学领域问答任务上的性能，发现GPT-3.5表现出色，Mistral-7b在开源模型中最佳，同时指出开源LLM具备与专有模型竞争的潜力。", "motivation": "RAG技术因其减少幻觉的能力而日益受到关注，与LLM结合使用可增强其性能。因此，比较不同LLM在结合RAG后在多领域问答任务中的表现变得具有重要意义。", "method": "研究比较了四种开源LLM（Mistral-7b-instruct, LLaMa2-7b-chat, Falcon-7b-instruct, Orca-mini-v3-7b）和OpenAI的GPT-3.5在结合RAG支持的计算机科学文献问答任务上的表现。评估指标包括二元问题的准确率和精确度，以及长答案问题的人工专家排名、Google Gemini AI模型排名和余弦相似度。", "result": "结合RAG后，GPT-3.5在二元和长答案问题上表现出色。在开源LLM中，Mistral-7b-instruct结合RAG在两种问题类型上均超越其他开源模型。Orca-mini-v3-7b生成响应的平均延迟最短，而LLaMa2-7b-chat的平均延迟最高。", "conclusion": "研究强调，开源LLM在更好的基础设施支持下，也能够与GPT-3.5等专有模型并驾齐驱，展现出强大的竞争力。"}}
{"id": "2511.03651", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.SY", "I.2.9; J.5"], "pdf": "https://arxiv.org/pdf/2511.03651", "abs": "https://arxiv.org/abs/2511.03651", "authors": ["Andrei A. Korigodskii", "Oleg D. Kalachev", "Artem E. Vasiunik", "Matvei V. Urvantsev", "Georgii E. Bondar"], "title": "Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural", "comment": null, "summary": "This paper presents the innovative design and successful deployment of a\npioneering autonomous unmanned aerial system developed for executing the\nworld's largest mural painted by a drone. Addressing the dual challenges of\nmaintaining artistic precision and operational reliability under adverse\noutdoor conditions such as wind and direct sunlight, our work introduces a\nrobust system capable of navigating and painting outdoors with unprecedented\naccuracy. Key to our approach is a novel navigation system that combines an\ninfrared (IR) motion capture camera and LiDAR technology, enabling precise\nlocation tracking tailored specifically for largescale artistic applications.\nWe employ a unique control architecture that uses different regulation in\ntangential and normal directions relative to the planned path, enabling precise\ntrajectory tracking and stable line rendering. We also present algorithms for\ntrajectory planning and path optimization, allowing for complex curve drawing\nand area filling. The system includes a custom-designed paint spraying\nmechanism, specifically engineered to function effectively amidst the turbulent\nairflow generated by the drone's propellers, which also protects the drone's\ncritical components from paint-related damage, ensuring longevity and\nconsistent performance. Experimental results demonstrate the system's\nrobustness and precision in varied conditions, showcasing its potential for\nautonomous large-scale art creation and expanding the functional applications\nof robotics in creative fields.", "AI": {"tldr": "本文介绍了一种创新的自主无人机系统，用于绘制世界上最大的无人机壁画，该系统在恶劣户外条件下仍能实现高精度导航和绘画。", "motivation": "在风和阳光等不利户外条件下，使用无人机进行大规模壁画创作面临保持艺术精度和操作可靠性的双重挑战。", "method": "该系统采用结合红外（IR）运动捕捉摄像头和激光雷达（LiDAR）的新型导航系统，实现精确位置跟踪。其独特的控制架构在切向和法向采用不同调节，确保精确轨迹跟踪和稳定线条绘制。此外，还提出了轨迹规划和路径优化算法，并设计了定制的喷漆机构，以应对螺旋桨产生的气流并保护无人机组件。", "result": "实验结果证明了该系统在各种条件下的鲁棒性和精度，展示了其在自主大规模艺术创作方面的潜力。", "conclusion": "该系统成功扩展了机器人技术在创意领域的应用功能。"}}
{"id": "2511.03678", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03678", "abs": "https://arxiv.org/abs/2511.03678", "authors": ["Ruiying Wen", "Yuntao Dai", "Hongyong Wang"], "title": "A Constant-Gain Equation-Error Framework for Airliner Aerodynamic Monitoring Using QAR Data", "comment": null, "summary": "Monitoring the in-service aerodynamic performance of airliners is critical\nfor operational efficiency and safety, but using operational Quick Access\nRecorder (QAR) data for this purpose presents significant challenges. This\npaper first establishes that the absence of key parameters, particularly\naircraft moments of inertia, makes conventional state-propagation filters\nfundamentally unsuitable for this application. This limitation necessitates a\ndecoupled, Equation-Error Method (EEM). However, we then demonstrate through a\ncomparative analysis that standard recursive estimators with time-varying\ngains, such as Recursive Least Squares (RLS), also fail within an EEM\nframework, exhibiting premature convergence or instability when applied to\nlow-excitation cruise data. To overcome these dual challenges, we propose and\nvalidate the Constant-Gain Equation-Error Method (CG-EEM). This framework\nemploys a custom estimator with a constant, Kalman-like gain, which is\nperfectly suited to the stationary, low-signal-to-noise characteristics of\ncruise flight. The CG-EEM is extensively validated on a large, multi-fleet\ndataset of over 200 flights, where it produces highly consistent, physically\nplausible aerodynamic parameters and correctly identifies known performance\ndifferences between aircraft types. The result is a robust, scalable, and\ncomputationally efficient tool for fleet-wide performance monitoring and the\nearly detection of performance degradation.", "AI": {"tldr": "本文提出了一种名为恒定增益方程误差法（CG-EEM）的新方法，用于利用QAR数据监测飞机在役气动性能。该方法克服了传统状态传播滤波器和标准递归估计器在处理低激励巡航数据时的局限性，实现了对机队性能的鲁棒、可扩展和高效监测。", "motivation": "监测客机的在役气动性能对于运营效率和飞行安全至关重要。然而，使用快速存取记录器（QAR）数据进行此项任务面临诸多挑战，尤其是在缺乏关键参数（如飞机转动惯量）以及传统方法在低激励巡航数据下表现不佳的情况下。", "method": "首先指出由于缺乏关键参数，传统的状态传播滤波器不适用于此应用，因此需要解耦的方程误差法（EEM）。接着通过比较分析发现，标准递归估计器（如RLS）在EEM框架下应用于低激励巡航数据时会过早收敛或不稳定。为解决这些问题，本文提出并验证了恒定增益方程误差法（CG-EEM），该方法采用带有恒定卡尔曼式增益的定制估计器，特别适用于巡航飞行的平稳、低信噪比特性。", "result": "CG-EEM在包含200多次飞行的多机队大型数据集上进行了广泛验证。结果表明，该方法能够生成高度一致、符合物理规律的气动参数，并准确识别不同飞机类型之间已知的性能差异。该工具被证明是鲁棒、可扩展且计算高效的。", "conclusion": "CG-EEM为机队范围内的性能监测和早期检测性能退化提供了一个强大的、可扩展且计算高效的工具，能够有效应对QAR数据在役性能监测的挑战。"}}
{"id": "2511.03163", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03163", "abs": "https://arxiv.org/abs/2511.03163", "authors": ["Yun-Chen Lin", "Jiayuan Huang", "Hanyuan Zhang", "Sergi Kavtaradze", "Matthew J. Clarkson", "Mobarak I. Hoque"], "title": "Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation", "comment": "12 pages", "summary": "Accurate detection and delineation of anatomical structures in medical\nimaging are critical for computer-assisted interventions, particularly in\nlaparoscopic liver surgery where 2D video streams limit depth perception and\ncomplicate landmark localization. While recent works have leveraged monocular\ndepth cues for enhanced landmark detection, challenges remain in fusing RGB and\ndepth features and in efficiently adapting large-scale vision models to\nsurgical domains. We propose a depth-guided liver landmark segmentation\nframework integrating semantic and geometric cues via vision foundation\nencoders. We employ Segment Anything Model V2 (SAM2) encoder to extract RGB\nfeatures and Depth Anything V2 (DA2) encoder to extract depth-aware features.\nTo efficiently adapt SAM2, we introduce SRFT-GaLore, a novel low-rank gradient\nprojection method that replaces the computationally expensive SVD with a\nSubsampled Randomized Fourier Transform (SRFT). This enables efficient\nfine-tuning of high-dimensional attention layers without sacrificing\nrepresentational power. A cross-attention fusion module further integrates RGB\nand depth cues. To assess cross-dataset generalization, we also construct a new\nLaparoscopic Liver Surgical Dataset (LLSD) as an external validation benchmark.\nOn the public L3D dataset, our method achieves a 4.85% improvement in Dice\nSimilarity Coefficient and a 11.78-point reduction in Average Symmetric Surface\nDistance compared to the D2GPLand. To further assess generalization capability,\nwe evaluate our model on LLSD dataset. Our model maintains competitive\nperformance and significantly outperforms SAM-based baselines, demonstrating\nstrong cross-dataset robustness and adaptability to unseen surgical\nenvironments. These results demonstrate that our SRFT-GaLore-enhanced\ndual-encoder framework enables scalable and precise segmentation under\nreal-time, depth-constrained surgical settings.", "AI": {"tldr": "本文提出了一种深度引导的肝脏地标分割框架，结合SAM2和DA2编码器，并引入SRFT-GaLore进行高效微调，实现了在腹腔镜肝脏手术中高精度、可扩展的解剖结构分割，并展示了强大的跨数据集泛化能力。", "motivation": "在腹腔镜肝脏手术等计算机辅助干预中，准确检测和描绘解剖结构至关重要。2D视频流限制了深度感知，使地标定位复杂化。现有工作在融合RGB和深度特征以及高效适应大型视觉模型到手术领域方面仍面临挑战。", "method": "本文提出了一个深度引导的肝脏地标分割框架，通过视觉基础编码器整合语义和几何线索。使用Segment Anything Model V2 (SAM2) 提取RGB特征，使用Depth Anything V2 (DA2) 提取深度感知特征。为高效适应SAM2，引入了SRFT-GaLore（一种新颖的低秩梯度投影方法，用SRFT替代SVD）以高效微调高维注意力层。通过一个交叉注意力融合模块进一步整合RGB和深度线索。此外，构建了一个新的腹腔镜肝脏手术数据集（LLSD）作为外部验证基准。", "result": "在公共L3D数据集上，该方法在Dice相似系数方面比D2GPLand提高了4.85%，在平均对称表面距离方面减少了11.78点。在LLSD数据集上，模型保持了有竞争力的性能，并显著优于基于SAM的基线，展示了强大的跨数据集鲁棒性和对未知手术环境的适应性。", "conclusion": "SRFT-GaLore增强的双编码器框架能够在实时、深度受限的手术环境中实现可扩展且精确的分割。"}}
{"id": "2511.03206", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03206", "abs": "https://arxiv.org/abs/2511.03206", "authors": ["Kuei-Chun Kao", "Hsu Tzu-Yin", "Yunqi Hong", "Ruochen Wang", "Cho-Jui Hsieh"], "title": "QG-CoC: Question-Guided Chain-of-Captions for Large Multimodal Models", "comment": "16 pages", "summary": "Recently, Multimodal Large Language Models (MLLMs) encounter two key issues\nin multi-image contexts: (1) a lack of fine-grained perception across disparate\nimages, and (2) a diminished capability to effectively reason over and\nsynthesize information from multiple visual inputs. However, while various\nprompting methods aim to describe visual content, many existing studies focus\nprimarily on single-image settings or specific, constrained scenarios. This\nleaves a critical gap in understanding and addressing how MLLMs tackle more\ngeneral and complex multi-image reasoning tasks. Thus, we first extensively\ninvestigate how current prompting methods perceive fine-grained visual details\nand process visual information when dealing with multiple images. Our findings\nreveal that existing prompting methods fall short in attending to needed clues\nand seamlessly integrating perception and reasoning. Inspired by the findings,\nwe propose a new zero-shot prompting method, Question-Guided Chain-of-Captions\n(QG-CoC), a generalized prompting approach that effectively handles problems\nwith an arbitrary number of images. We evaluate our method on various\nopen-source and closed-source MLLMs for multi-image and single-image\nbenchmarks. Experimental results indicate that QG-CoC demonstrates competitive\nperformance across tasks and exhibits robust improvements in the challenging\nscenarios where existing prompting methods fail.", "AI": {"tldr": "多模态大语言模型（MLLMs）在多图像场景中存在细粒度感知和有效推理的挑战。本文首先调查了现有提示方法的不足，然后提出了一种零样本提示方法QG-CoC，该方法能够有效处理任意数量图像的问题，并在多图像和单图像基准测试中展现出竞争性表现和鲁棒性改进。", "motivation": "多模态大语言模型（MLLMs）在处理多图像上下文时面临两个关键问题：缺乏跨不同图像的细粒度感知能力，以及在多个视觉输入中进行有效推理和信息整合的能力下降。现有提示方法主要关注单图像或受限的多图像场景，未能解决更通用和复杂的多图像推理任务，这构成了一个关键的研究空白。", "method": "首先，本文对当前提示方法在处理多图像时感知细粒度视觉细节和处理视觉信息的能力进行了广泛调查。在此基础上，提出了一种新的零样本提示方法——问题引导的标题链（Question-Guided Chain-of-Captions, QG-CoC），这是一种能够有效处理任意数量图像的通用提示方法。最后，在各种开源和闭源MLLMs上，通过多图像和单图像基准测试对所提出的方法进行了评估。", "result": "研究发现，现有提示方法在多图像上下文中未能关注到所需线索，也无法无缝整合感知和推理。实验结果表明，QG-CoC在各项任务中表现出具有竞争力的性能，并在现有提示方法失效的挑战性场景中展现出显著且稳健的改进。", "conclusion": "QG-CoC是一种有效的、通用的零样本提示方法，能够解决多模态大语言模型在多图像上下文中的细粒度感知和推理不足问题。它在各种任务中均表现出色，并在复杂场景中展现出强大的鲁棒性，克服了现有方法的局限性。"}}
{"id": "2511.03178", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03178", "abs": "https://arxiv.org/abs/2511.03178", "authors": ["Shreyas C. Dhake", "Jiayuan Huang", "Runlong He", "Danyal Z. Khan", "Evangelos B. Mazomenos", "Sophia Bano", "Hani J. Marcus", "Danail Stoyanov", "Matthew J. Clarkson", "Mobarak I. Hoque"], "title": "SurgAnt-ViVQA: Learning to Anticipate Surgical Events through GRU-Driven Temporal Cross-Attention", "comment": "12 pages", "summary": "Anticipating forthcoming surgical events is vital for real-time assistance in\nendonasal transsphenoidal pituitary surgery, where visibility is limited and\nworkflow changes rapidly. Most visual question answering (VQA) systems reason\non isolated frames with static vision language alignment, providing little\nsupport for forecasting next steps or instrument needs. Existing surgical VQA\ndatasets likewise center on the current scene rather than the near future. We\nintroduce PitVQA-Anticipation, the first VQA dataset designed for forward\nlooking surgical reasoning. It comprises 33.5 hours of operative video and\n734,769 question answer pairs built from temporally grouped clips and expert\nannotations across four tasks: predicting the future phase, next step, upcoming\ninstrument, and remaining duration. We further propose SurgAnt-ViVQA, a video\nlanguage model that adapts a large language model using a GRU Gated Temporal\nCross-Attention module. A bidirectional GRU encodes frame to frame dynamics,\nwhile an adaptive gate injects visual context into the language stream at the\ntoken level. Parameter efficient fine tuning customizes the language backbone\nto the surgical domain. SurgAnt-ViVQA tested upon on PitVQA-Anticipation and\nEndoVis datasets, surpassing strong image and video based baselines. Ablations\nshow that temporal recurrence and gated fusion drive most of the gains. A frame\nbudget study indicates a trade-off: 8 frames maximize fluency, whereas 32\nframes slightly reduce BLEU but improve numeric time estimation. By pairing a\ntemporally aware encoder with fine grained gated cross-attention, SurgAnt-ViVQA\nadvances surgical VQA from retrospective description to proactive anticipation.\nPitVQA-Anticipation offers a comprehensive benchmark for this setting and\nhighlights the importance of targeted temporal modeling for reliable, future\naware surgical assistance.", "AI": {"tldr": "该研究引入了首个用于外科手术事件预测的VQA数据集PitVQA-Anticipation，并提出了一个名为SurgAnt-ViVQA的视频语言模型，该模型通过门控时间交叉注意力模块使大型语言模型适应外科领域，实现了从回顾性描述到主动预测的外科VQA。", "motivation": "在经鼻蝶垂体手术中，实时辅助至关重要，但能见度有限且工作流程变化迅速。现有的大多数VQA系统仅基于孤立帧进行推理，缺乏对预测下一步骤或器械需求的支持。现有的外科VQA数据集也侧重于当前场景而非近未来。", "method": "1. **数据集：** 引入PitVQA-Anticipation，首个用于前瞻性外科推理的VQA数据集，包含33.5小时的手术视频和734,769个问答对，基于时间分组片段和专家标注，涵盖预测未来阶段、下一步骤、即将使用的器械和剩余持续时间四项任务。\n2. **模型：** 提出了SurgAnt-ViVQA，一个视频语言模型。该模型使用GRU门控时间交叉注意力模块来调整大型语言模型，其中双向GRU编码帧间动态，自适应门控在token级别将视觉上下文注入语言流。通过参数高效微调来定制语言骨干网络以适应外科领域。", "result": "SurgAnt-ViVQA在PitVQA-Anticipation和EndoVis数据集上进行了测试，超越了强大的基于图像和视频的基线模型。消融研究表明，时间递归和门控融合是性能提升的主要驱动因素。一项帧预算研究指出权衡：8帧能最大化流畅性，而32帧略微降低BLEU但能改善数字时间估计。", "conclusion": "通过将时间感知编码器与细粒度门控交叉注意力相结合，SurgAnt-ViVQA将外科VQA从回顾性描述推进到主动预测。PitVQA-Anticipation为这一设置提供了全面的基准，并强调了有针对性的时间建模对于可靠、面向未来的外科辅助的重要性。"}}
{"id": "2511.03194", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03194", "abs": "https://arxiv.org/abs/2511.03194", "authors": ["Le Xue", "Gang Feng", "Wenbo Zhang", "Yichi Zhang", "Lanlan Li", "Shuqi Wang", "Liling Peng", "Sisi Peng", "Xin Gao"], "title": "PETWB-REP: A Multi-Cancer Whole-Body FDG PET/CT and Radiology Report Dataset for Medical Imaging Research", "comment": null, "summary": "Publicly available, large-scale medical imaging datasets are crucial for\ndeveloping and validating artificial intelligence models and conducting\nretrospective clinical research. However, datasets that combine functional and\nanatomical imaging with detailed clinical reports across multiple cancer types\nremain scarce. Here, we present PETWB-REP, a curated dataset comprising\nwhole-body 18F-Fluorodeoxyglucose (FDG) Positron Emission Tomography/Computed\nTomography (PET/CT) scans and corresponding radiology reports from 490 patients\ndiagnosed with various malignancies. The dataset primarily includes common\ncancers such as lung cancer, liver cancer, breast cancer, prostate cancer, and\novarian cancer. This dataset includes paired PET and CT images, de-identified\ntextual reports, and structured clinical metadata. It is designed to support\nresearch in medical imaging, radiomics, artificial intelligence, and\nmulti-modal learning.", "AI": {"tldr": "PETWB-REP是一个新发布的医学影像数据集，包含490名患者的全身18F-FDG PET/CT扫描及其放射学报告和临床元数据，涵盖多种常见癌症，旨在支持AI和多模态学习研究。", "motivation": "开发和验证AI模型以及进行回顾性临床研究急需结合功能和解剖成像与详细临床报告的大规模、多癌种医学影像数据集，但此类数据集目前非常稀缺。", "method": "研究人员策划并构建了PETWB-REP数据集。", "result": "PETWB-REP数据集包含490名不同恶性肿瘤（主要包括肺癌、肝癌、乳腺癌、前列腺癌和卵巢癌等常见癌症）患者的全身18F-FDG PET/CT扫描图像及其对应的去识别化文本报告和结构化临床元数据。", "conclusion": "该数据集旨在支持医学影像、影像组学、人工智能和多模态学习等领域的研究。"}}
{"id": "2511.03652", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.03652", "abs": "https://arxiv.org/abs/2511.03652", "authors": ["Azizollah Taheri", "Derya Aksaray"], "title": "Motion Planning Under Temporal Logic Specifications In Semantically Unknown Environments", "comment": "8 pages, 6 figures", "summary": "This paper addresses a motion planning problem to achieve\nspatio-temporal-logical tasks, expressed by syntactically co-safe linear\ntemporal logic specifications (scLTL\\next), in uncertain environments. Here,\nthe uncertainty is modeled as some probabilistic knowledge on the semantic\nlabels of the environment. For example, the task is \"first go to region 1, then\ngo to region 2\"; however, the exact locations of regions 1 and 2 are not known\na priori, instead a probabilistic belief is available. We propose a novel\nautomata-theoretic approach, where a special product automaton is constructed\nto capture the uncertainty related to semantic labels, and a reward function is\ndesigned for each edge of this product automaton. The proposed algorithm\nutilizes value iteration for online replanning. We show some theoretical\nresults and present some simulations/experiments to demonstrate the efficacy of\nthe proposed approach.", "AI": {"tldr": "本文提出了一种新颖的自动机理论方法，用于在不确定环境中（语义标签具有概率知识）解决由scLTL规范表达的时空逻辑任务的运动规划问题，并利用值迭代进行在线重规划。", "motivation": "研究动机是解决在存在不确定性的环境中（例如，任务区域的精确位置未知，但有概率信念），机器人如何执行复杂的时空逻辑任务（如“先去区域1，再去区域2”）的运动规划问题。", "method": "该方法将不确定性建模为环境语义标签的概率知识。核心是构建一个特殊的乘积自动机来捕获与语义标签相关的不确定性，并为该自动机的每条边设计奖励函数。算法利用值迭代进行在线重规划。", "result": "论文展示了一些理论结果，并通过仿真/实验证明了所提出方法的有效性。", "conclusion": "所提出的基于自动机理论和值迭代的在线重规划方法，能够有效解决在不确定环境中执行时空逻辑任务的运动规划问题。"}}
{"id": "2511.03295", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03295", "abs": "https://arxiv.org/abs/2511.03295", "authors": ["Mauro Cettolo", "Marco Gaido", "Matteo Negri", "Sara Papi", "Luisa Bentivogli"], "title": "How to Evaluate Speech Translation with Source-Aware Neural MT Metrics", "comment": null, "summary": "Automatic evaluation of speech-to-text translation (ST) systems is typically\nperformed by comparing translation hypotheses with one or more reference\ntranslations. While effective to some extent, this approach inherits the\nlimitation of reference-based evaluation that ignores valuable information from\nthe source input. In machine translation (MT), recent progress has shown that\nneural metrics incorporating the source text achieve stronger correlation with\nhuman judgments. Extending this idea to ST, however, is not trivial because the\nsource is audio rather than text, and reliable transcripts or alignments\nbetween source and references are often unavailable. In this work, we conduct\nthe first systematic study of source-aware metrics for ST, with a particular\nfocus on real-world operating conditions where source transcripts are not\navailable. We explore two complementary strategies for generating textual\nproxies of the input audio, automatic speech recognition (ASR) transcripts, and\nback-translations of the reference translation, and introduce a novel two-step\ncross-lingual re-segmentation algorithm to address the alignment mismatch\nbetween synthetic sources and reference translations. Our experiments, carried\nout on two ST benchmarks covering 79 language pairs and six ST systems with\ndiverse architectures and performance levels, show that ASR transcripts\nconstitute a more reliable synthetic source than back-translations when word\nerror rate is below 20%, while back-translations always represent a\ncomputationally cheaper but still effective alternative. Furthermore, our\ncross-lingual re-segmentation algorithm enables robust use of source-aware MT\nmetrics in ST evaluation, paving the way toward more accurate and principled\nevaluation methodologies for speech translation.", "AI": {"tldr": "本研究首次系统性地探讨了语音到文本翻译（ST）的源感知评估指标，通过使用ASR转录或参考回译作为音频源的文本代理，并引入了一种新的跨语言重分段算法，以在源转录不可用时实现更准确的评估。", "motivation": "ST系统自动评估通常只比较翻译假设与参考译文，忽略了源输入信息。在机器翻译（MT）中，源感知指标已显示出与人类判断更强的相关性。然而，将此思想扩展到ST并非易事，因为源是音频，且可靠的转录或对齐通常不可用。", "method": "本研究在源转录不可用的实际操作条件下，对ST的源感知指标进行了首次系统性研究。探索了两种生成输入音频文本代理的策略：自动语音识别（ASR）转录和参考译文的反向翻译。引入了一种新颖的两步跨语言重分段算法，以解决合成源与参考译文之间的对齐不匹配问题。", "result": "实验结果表明，当词错误率（WER）低于20%时，ASR转录比反向翻译构成更可靠的合成源；而反向翻译总是计算成本更低但仍然有效的替代方案。此外，所提出的跨语言重分段算法使得源感知MT指标能够稳健地用于ST评估。", "conclusion": "本研究为语音翻译提供了更准确和更具原则性的评估方法，通过在ST评估中稳健地使用源感知MT指标铺平了道路，即使在源转录不可用时也能有效工作。"}}
{"id": "2511.03270", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03270", "abs": "https://arxiv.org/abs/2511.03270", "authors": ["Jin-woo Lee", "Junhwa Choi", "Bongkyu Hwang", "Jinho Choo", "Bogun Kim", "JeongSeon Yi", "Joonseok Lee", "DongYoung Jung", "Jaeseon Park", "Kyoungwon Park", "Suk-hoon Jung"], "title": "SCALE: Upscaled Continual Learning of Large Language Models", "comment": null, "summary": "We revisit continual pre-training for large language models and argue that\nprogress now depends more on scaling the right structure than on scaling\nparameters alone. We introduce SCALE, a width upscaling architecture that\ninserts lightweight expansion into linear modules while freezing all\npre-trained parameters. This preserves the residual and attention topologies\nand increases capacity without perturbing the base model's original\nfunctionality. SCALE is guided by two principles: Persistent Preservation,\nwhich maintains the base model's behavior via preservation-oriented\ninitialization and freezing of the pre-trained weights, and Collaborative\nAdaptation, which selectively trains a subset of expansion components to\nacquire new knowledge with minimal interference. We instantiate these ideas as\nSCALE-Preserve (preservation-first), SCALE-Adapt (adaptation-first), and\nSCALE-Route, an optional routing extension that performs token-level routing\nbetween preservation and adaptation heads. On a controlled synthetic biography\nbenchmark, SCALE mitigates the severe forgetting observed with depth expansion\nwhile still acquiring new knowledge. In continual pre-training on a Korean\ncorpus, SCALE variants achieve less forgetting on English evaluations and\ncompetitive gains on Korean benchmarks, with these variants offering the best\noverall stability-plasticity trade-off. Accompanying analysis clarifies when\npreservation provably holds and why the interplay between preservation and\nadaptation stabilizes optimization compared to standard continual learning\nsetups.", "AI": {"tldr": "针对大型语言模型持续预训练，提出SCALE架构，通过在冻结预训练参数的同时插入轻量级宽度扩展，平衡稳定性与适应性，有效缓解遗忘问题并提升新知识获取。", "motivation": "大型语言模型的持续预训练进展需要从单纯增加参数转向优化结构。现有方法（如深度扩展）会导致严重遗忘，因此需要一种既能增加模型容量、获取新知识，又能保持原有功能并减轻遗忘的方法。", "method": "引入SCALE，一种宽度扩展架构，在冻结所有预训练参数的同时，将轻量级扩展模块插入线性模块中，并保持残差和注意力拓扑结构。该方法遵循“持久保留”（通过保留导向初始化和冻结预训练权重维持基础模型行为）和“协同适应”（选择性训练扩展组件获取新知识）两大原则。具体实现包括SCALE-Preserve（保留优先）、SCALE-Adapt（适应优先）和可选的SCALE-Route（用于在保留和适应头部之间进行token级路由）。", "result": "在合成传记基准测试中，SCALE在获取新知识的同时显著减轻了深度扩展导致的严重遗忘。在韩语语料库上的持续预训练中，SCALE变体在英语评估中表现出更少的遗忘，并在韩语基准测试中取得有竞争力的提升。这些变体提供了最佳的整体稳定性-可塑性权衡。伴随的分析阐明了保留何时成立，以及保留与适应之间的相互作用如何稳定优化。", "conclusion": "SCALE通过结构化宽度扩展，平衡了保留与适应，为大型语言模型的持续预训练提供了一种新颖有效的方法，成功缓解了遗忘问题，并实现了更好的稳定性-可塑性权衡。"}}
{"id": "2511.03328", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03328", "abs": "https://arxiv.org/abs/2511.03328", "authors": ["Jindong Hong", "Tianjie Chen", "Lingjie Luo", "Chuanyang Zheng", "Ting Xu", "Haibao Yu", "Jianing Qiu", "Qianzhong Chen", "Suning Huang", "Yan Xu", "Yong Gui", "Yijun He", "Jiankai Sun"], "title": "Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks", "comment": null, "summary": "A recent advancement in Multimodal Large Language Models (MLLMs) research is\nthe emergence of \"reasoning MLLMs\" that offer explicit control over their\ninternal thinking processes (normally referred as the \"thinking mode\")\nalongside the standard \"non-thinking mode\". This capability allows these models\nto engage in a step-by-step process of internal deliberation before generating\na final response. With the rapid transition to and adoption of these\n\"dual-state\" MLLMs, this work rigorously evaluated how the enhanced reasoning\nprocesses of these MLLMs impact model performance and reliability in clinical\ntasks. This paper evaluates the active \"thinking mode\" capabilities of two\nleading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We\nassessed their performance on four visual medical tasks using VQA-RAD and\nROCOv2 datasets. Our findings reveal that the improvement from activating the\nthinking mode remains marginal compared to the standard non-thinking mode for\nthe majority of the tasks. Their performance on complex medical tasks such as\nopen-ended VQA and medical image interpretation remains suboptimal,\nhighlighting the need for domain-specific medical data and more advanced\nmethods for medical knowledge integration.", "AI": {"tldr": "本研究评估了具有“思考模式”的多模态大语言模型（MLLMs）在临床任务中的表现，发现其思考模式带来的性能提升微乎其微，并且在复杂医学任务上表现仍不理想。", "motivation": "随着具有“思考模式”的推理型MLLMs的出现，本研究旨在严格评估这些增强的推理过程如何影响MLLMs在临床任务中的性能和可靠性。", "method": "本研究评估了两个领先的MLLMs，Seed1.5-VL和Gemini-2.5-Flash，在医学应用中激活“思考模式”的能力。使用VQA-RAD和ROCOv2数据集，在四项视觉医学任务上评估了它们的性能，并与标准“非思考模式”进行了比较。", "result": "研究发现，在大多数任务中，激活思考模式带来的性能提升与标准非思考模式相比微乎其微。模型在开放式VQA和医学图像解释等复杂医学任务上的表现仍不尽如人意。", "conclusion": "为了提高MLLMs在临床应用中的性能，需要领域特定的医学数据和更先进的医学知识整合方法。"}}
{"id": "2511.03622", "categories": ["cs.RO", "cs.CG", "cs.CR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03622", "abs": "https://arxiv.org/abs/2511.03622", "authors": ["Swadhin Agrawal", "Sujoy Bhore", "Joseph S. B. Mitchell", "P. B. Sujit", "Aayush Gohil"], "title": "Multi-robot searching with limited sensing range for static and mobile intruders", "comment": null, "summary": "We consider the problem of searching for an intruder in a geometric domain by\nutilizing multiple search robots. The domain is a simply connected orthogonal\npolygon with edges parallel to the cartesian coordinate axes. Each robot has a\nlimited sensing capability. We study the problem for both static and mobile\nintruders. It turns out that the problem of finding an intruder is NP-hard,\neven for a stationary intruder. Given this intractability, we turn our\nattention towards developing efficient and robust algorithms, namely methods\nbased on space-filling curves, random search, and cooperative random search.\nMoreover, for each proposed algorithm, we evaluate the trade-off between the\nnumber of search robots and the time required for the robots to complete the\nsearch process while considering the geometric properties of the connected\northogonal search area.", "AI": {"tldr": "在几何区域中利用多机器人搜索入侵者的问题被证明是NP难的。本文提出了基于空间填充曲线、随机搜索和协作随机搜索的算法，并评估了机器人数量与搜索时间之间的权衡。", "motivation": "在简单连通的正交多边形区域内，利用有限感知能力的多机器人搜索入侵者（包括静态和移动）的问题，即使对于静止入侵者，也被证明是NP难的。这种固有的计算复杂性促使研究者开发高效且鲁棒的搜索算法。", "method": "研究方法包括：1) 定义搜索区域为简单连通的正交多边形；2) 考虑静态和移动入侵者；3) 提出基于空间填充曲线、随机搜索和协作随机搜索的算法；4) 评估每种算法在所需机器人数量和完成搜索所需时间之间的权衡，并考虑搜索区域的几何特性。", "result": "主要发现是，即使对于静止入侵者，在几何区域内利用多机器人搜索入侵者的问题也是NP难的。在此基础上，论文开发并评估了多种高效且鲁棒的算法，并分析了它们在机器人数量与搜索完成时间之间的权衡。", "conclusion": "入侵者搜索问题具有固有的计算复杂性（NP难）。为了应对这一挑战，本文提出并评估了多种基于空间填充曲线、随机搜索和协作随机搜索的算法，旨在优化机器人资源和搜索效率之间的平衡。"}}
{"id": "2511.03676", "categories": ["cs.RO", "cs.HC", "H.5.2; I.2.9"], "pdf": "https://arxiv.org/pdf/2511.03676", "abs": "https://arxiv.org/abs/2511.03676", "authors": ["Taito Tashiro", "Tomoko Yonezawa", "Hirotake Yamazoe"], "title": "Unconscious and Intentional Human Motion Cues for Expressive Robot-Arm Motion Design", "comment": "5 pages, 5 figures, HAI2025 Workshop on Socially Aware and\n  Cooperative Intelligent Systems", "summary": "This study investigates how human motion cues can be used to design\nexpressive robot-arm movements. Using the imperfect-information game Geister,\nwe analyzed two types of human piece-moving motions: natural gameplay\n(unconscious tendencies) and instructed expressions (intentional cues). Based\non these findings, we created phase-specific robot motions by varying movement\nspeed and stop duration, and evaluated observer impressions under two\npresentation modalities: a physical robot and a recorded video. Results\nindicate that late-phase motion timing, particularly during withdrawal, plays\nan important role in impression formation and that physical embodiment enhances\nthe interpretability of motion cues. These findings provide insights for\ndesigning expressive robot motions based on human timing behavior.", "AI": {"tldr": "本研究探讨如何利用人类运动线索（自然游戏和指令表达）设计富有表现力的机器人手臂动作，发现后期运动时机（特别是撤回阶段）和物理实体对印象形成和线索解读至关重要。", "motivation": "研究旨在利用人类运动线索来设计富有表现力的机器人手臂动作，以提升人机交互的自然性和可解释性。", "method": "研究分析了人类在不完全信息游戏Geister中的两种棋子移动动作：自然游戏（无意识倾向）和指令表达（有意提示）。基于此，通过改变运动速度和停止时长，创建了分阶段的机器人动作，并在物理机器人和录制视频两种呈现模式下评估了观察者的印象。", "result": "结果表明，后期运动时机，尤其是在撤回阶段，对印象形成起着重要作用；同时，物理实体增强了运动线索的可解释性。", "conclusion": "这些发现为基于人类时序行为设计富有表现力的机器人动作提供了见解。"}}
{"id": "2511.03255", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03255", "abs": "https://arxiv.org/abs/2511.03255", "authors": ["Nikolina Tomic Roshni Bhatnagar", "Sarthak Jain", "Connor Lau", "Tien-Yu Liu", "Laura Gambini", "Rima Arnaout"], "title": "Generative deep learning for foundational video translation in ultrasound", "comment": null, "summary": "Deep learning (DL) has the potential to revolutionize image acquisition and\ninterpretation across medicine, however, attention to data imbalance and\nmissingness is required. Ultrasound data presents a particular challenge\nbecause in addition to different views and structures, it includes several\nsub-modalities-such as greyscale and color flow doppler (CFD)-that are often\nimbalanced in clinical studies. Image translation can help balance datasets but\nis challenging for ultrasound sub-modalities to date. Here, we present a\ngenerative method for ultrasound CFD-greyscale video translation, trained on\n54,975 videos and tested on 8,368. The method developed leveraged pixel-wise,\nadversarial, and perceptual loses and utilized two networks: one for\nreconstructing anatomic structures and one for denoising to achieve realistic\nultrasound imaging. Average pairwise SSIM between synthetic videos and ground\ntruth was 0.91+/-0.04. Synthetic videos performed indistinguishably from real\nones in DL classification and segmentation tasks and when evaluated by blinded\nclinical experts: F1 score was 0.9 for real and 0.89 for synthetic videos; Dice\nscore between real and synthetic segmentation was 0.97. Overall clinician\naccuracy in distinguishing real vs synthetic videos was 54+/-6% (42-61%),\nindicating realistic synthetic videos. Although trained only on heart videos,\nthe model worked well on ultrasound spanning several clinical domains (average\nSSIM 0.91+/-0.05), demonstrating foundational abilities. Together, these data\nexpand the utility of retrospectively collected imaging and augment the dataset\ndesign toolbox for medical imaging.", "AI": {"tldr": "本文提出了一种生成式方法，用于超声彩色血流多普勒（CFD）到灰度视频的转换，以解决医疗图像数据不平衡问题。生成的合成视频在深度学习任务和临床专家评估中与真实视频表现无异，展示了该方法在医学成像领域的数据增强潜力。", "motivation": "深度学习在医学图像获取和解释方面具有巨大潜力，但面临数据不平衡和缺失的挑战。超声数据尤其复杂，包含灰度图和彩色血流多普勒等子模态，这些子模态在临床研究中常不平衡。图像转换可以帮助平衡数据集，但迄今为止，超声子模态的图像转换仍然具有挑战性。", "method": "研究开发了一种生成式方法，用于超声CFD到灰度视频的转换。该方法在54,975个视频上进行训练，并利用像素级、对抗性和感知损失。它采用两个网络：一个用于重建解剖结构，另一个用于去噪，以生成逼真的超声图像。", "result": "合成视频与真实视频之间的平均成对SSIM为0.91+/-0.04。在深度学习分类和分割任务中，合成视频与真实视频表现无异（分类F1分数真实为0.9，合成为0.89；真实与合成分割的Dice分数为0.97）。盲法临床专家区分真实与合成视频的总体准确率为54+/-6%，表明合成视频的真实性。尽管仅在心脏视频上训练，该模型在多个临床领域的超声图像上表现良好（平均SSIM 0.91+/-0.05），展现了基础能力。", "conclusion": "这些数据扩展了回顾性收集图像的实用性，并丰富了医学成像的数据集设计工具箱。该方法为解决超声子模态数据不平衡问题提供了有效的解决方案，并展现了其在不同临床领域的应用潜力。"}}
{"id": "2511.03691", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.03691", "abs": "https://arxiv.org/abs/2511.03691", "authors": ["Zhihang Qin", "Yueheng Zhang", "Wan Su", "Linxin Hou", "Shenghao Zhou", "Zhijun Chen", "Yu Jun Tan", "Cecilia Laschi"], "title": "Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping", "comment": null, "summary": "Conventional fluid-driven soft grippers typically depend on external sources,\nwhich limit portability and long-term autonomy. This work introduces a\nself-contained soft gripper with fixed size that operates solely through\ninternal liquid redistribution among three interconnected bistable snap-through\nchambers. When the top sensing chamber deforms upon contact, the displaced\nliquid triggers snap-through expansion of the grasping chambers, enabling\nstable and size-selective grasping without continuous energy input. The\ninternal hydraulic feedback further allows passive adaptation of gripping\npressure to object stiffness. This source-free and compact design opens new\npossibilities for lightweight, stiffness-adaptive fluid-driven manipulation in\nsoft robotics, providing a feasible approach for targeted size-specific\nsampling and operation in underwater and field environments.", "AI": {"tldr": "本文介绍了一种自给自足的软抓手，通过内部液体在三个互连双稳态“弹跳”腔室中的重新分配实现尺寸选择性和刚度自适应抓取，无需外部能源。", "motivation": "传统流体驱动软抓手依赖外部能源，限制了其便携性和长期自主性。", "method": "该抓手采用固定尺寸设计，包含三个互连的双稳态“弹跳”腔室。当顶部传感腔室接触物体时发生形变，排出的液体触发抓取腔室的“弹跳”式扩张，实现抓取。内部液压反馈机制使其能被动适应物体刚度。", "result": "实现了无需持续能量输入的稳定、尺寸选择性抓取。抓取压力能被动适应物体刚度。设计无外部能源且紧凑。", "conclusion": "这种无外部能源、紧凑的设计为软机器人中轻量级、刚度自适应的流体驱动操作开辟了新可能性，为水下和野外环境中特定尺寸的采样和操作提供了可行方法。"}}
{"id": "2511.03369", "categories": ["cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.03369", "abs": "https://arxiv.org/abs/2511.03369", "authors": ["Rom Himelstein", "Amit LeVi", "Brit Youngmann", "Yaniv Nemcovsky", "Avi Mendelson"], "title": "Silenced Biases: The Dark Side LLMs Learned to Refuse", "comment": null, "summary": "Safety-aligned large language models (LLMs) are becoming increasingly\nwidespread, especially in sensitive applications where fairness is essential\nand biased outputs can cause significant harm. However, evaluating the fairness\nof models is a complex challenge, and approaches that do so typically utilize\nstandard question-answer (QA) styled schemes. Such methods often overlook\ndeeper issues by interpreting the model's refusal responses as positive\nfairness measurements, which creates a false sense of fairness. In this work,\nwe introduce the concept of silenced biases, which are unfair preferences\nencoded within models' latent space and are effectively concealed by\nsafety-alignment. Previous approaches that considered similar indirect biases\noften relied on prompt manipulation or handcrafted implicit queries, which\npresent limited scalability and risk contaminating the evaluation process with\nadditional biases. We propose the Silenced Bias Benchmark (SBB), which aims to\nuncover these biases by employing activation steering to reduce model refusals\nduring QA. SBB supports easy expansion to new demographic groups and subjects,\npresenting a fairness evaluation framework that encourages the future\ndevelopment of fair models and tools beyond the masking effects of alignment\ntraining. We demonstrate our approach over multiple LLMs, where our findings\nexpose an alarming distinction between models' direct responses and their\nunderlying fairness issues.", "AI": {"tldr": "本文引入了“沉默偏见”的概念，指安全对齐LLM中被拒绝响应掩盖的不公平偏好。提出SBB基准，通过激活引导减少拒绝来揭示这些偏见，发现模型直接响应与潜在公平性之间存在显著差异。", "motivation": "安全对齐的大语言模型在敏感应用中日益普及，但现有公平性评估方法（如问答式）常将模型拒绝响应误判为积极的公平性，从而掩盖了模型潜在的不公平偏好（即“沉默偏见”）。此前检测间接偏见的方法存在可扩展性和评估污染问题。", "method": "本文引入了“沉默偏见”的概念，并提出了“沉默偏见基准”（SBB）。SBB通过运用激活引导技术，在问答过程中减少模型的拒绝响应，从而揭示模型中编码的不公平偏好。SBB设计易于扩展到新的受试者和人口统计群体。", "result": "在多个大型语言模型上验证了该方法，发现模型的直接响应与其潜在的公平性问题之间存在惊人的差异，揭示了被安全对齐掩盖的深层偏见。", "conclusion": "SBB提供了一个公平性评估框架，旨在超越对齐训练的掩盖效应，鼓励未来开发更公平的模型和工具，揭示模型深层次的偏见问题。"}}
{"id": "2511.03212", "categories": ["cs.CV", "68T10, 68T45"], "pdf": "https://arxiv.org/pdf/2511.03212", "abs": "https://arxiv.org/abs/2511.03212", "authors": ["Ruting Cheng", "Boyuan Feng", "Yijiang Zheng", "Chuhui Qiu", "Aizierjiang Aiersilan", "Joaquin A. Calderon", "Wentao Zhao", "Qing Pan", "James K. Hahn"], "title": "MvBody: Multi-View-Based Hybrid Transformer Using Optical 3D Body Scan for Explainable Cesarean Section Prediction", "comment": "19 pages, 4 figures", "summary": "Accurately assessing the risk of cesarean section (CS) delivery is critical,\nespecially in settings with limited medical resources, where access to\nhealthcare is often restricted. Early and reliable risk prediction allows\nbetter-informed prenatal care decisions and can improve maternal and neonatal\noutcomes. However, most existing predictive models are tailored for in-hospital\nuse during labor and rely on parameters that are often unavailable in\nresource-limited or home-based settings. In this study, we conduct a pilot\ninvestigation to examine the feasibility of using 3D body shape for CS risk\nassessment for future applications with more affordable general devices. We\npropose a novel multi-view-based Transformer network, MvBody, which predicts CS\nrisk using only self-reported medical data and 3D optical body scans obtained\nbetween the 31st and 38th weeks of gestation. To enhance training efficiency\nand model generalizability in data-scarce environments, we incorporate a metric\nlearning loss into the network. Compared to widely used machine learning models\nand the latest advanced 3D analysis methods, our method demonstrates superior\nperformance, achieving an accuracy of 84.62% and an Area Under the Receiver\nOperating Characteristic Curve (AUC-ROC) of 0.724 on the independent test set.\nTo improve transparency and trust in the model's predictions, we apply the\nIntegrated Gradients algorithm to provide theoretically grounded explanations\nof the model's decision-making process. Our results indicate that pre-pregnancy\nweight, maternal age, obstetric history, previous CS history, and body shape,\nparticularly around the head and shoulders, are key contributors to CS risk\nprediction.", "AI": {"tldr": "本研究探索了利用3D身体形状和自我报告医疗数据进行剖宫产风险评估的可行性，并提出了一种名为MvBody的多视图Transformer网络，在资源有限环境下表现出卓越的预测性能和可解释性。", "motivation": "现有剖宫产风险预测模型主要适用于院内分娩期间，且依赖于在资源有限或家庭环境中通常不可用的参数。然而，在医疗资源受限的地区，早期可靠的风险预测对于改善母婴结局至关重要。", "method": "研究提出了一种新颖的多视图Transformer网络MvBody，仅使用自我报告的医疗数据和在妊娠31至38周期间获取的3D光学身体扫描来预测剖宫产风险。为了提高数据稀缺环境下的训练效率和模型泛化能力，网络中加入了度量学习损失。同时，采用集成梯度算法（Integrated Gradients）来解释模型的决策过程。", "result": "与广泛使用的机器学习模型和最新的3D分析方法相比，本方法表现出卓越的性能，在独立测试集上实现了84.62%的准确率和0.724的AUC-ROC。模型解释结果表明，孕前体重、产妇年龄、产科史、既往剖宫产史以及身体形状（特别是头部和肩部周围）是剖宫产风险预测的关键因素。", "conclusion": "3D身体形状结合自我报告数据在剖宫产风险评估中是可行的，特别是通过MvBody网络，它在资源有限的环境中提供了优越的预测性能和理论上可解释的决策过程，有助于改善产前护理决策。"}}
{"id": "2511.03367", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03367", "abs": "https://arxiv.org/abs/2511.03367", "authors": ["Gahyeon Kim", "Sohee Kim", "Seokju Lee"], "title": "Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models", "comment": "Accepted in Pattern Recognition", "summary": "Recent advances in large-scale vision and language models have led to\nsignificant progress in zero-shot learning tasks. Methods such as CoOp and\nCoCoOp have shown that replacing handcrafted prompts with learnable vectors,\nknown as prompt learning, can result in improved performance. However, these\nmodels often struggle to generalize to entirely unseen categories. While\ntraditional zero-shot learning techniques benefit from various data\naugmentation strategies, prompt learning has primarily focused on text-based\nmodifications, leaving the potential of image-based augmentation largely\nunexplored. In this work, we explore how image-level augmentations,\nparticularly those that introduce attribute-specific variations, can support\nand enhance prompt learning. Our analysis examines the interaction between\nthese augmentations and soft prompt frameworks, revealing their potential to\nimprove generalization. We also identify a limitation in existing methods, such\nas CoCoOp, which do not provide explicit guidance for learning prompts that\nfocus on semantically meaningful visual features. To address this, we propose\nAdding Attributes to Prompt Learning, AAPL, a novel method that introduces\nadversarial token embeddings to decouple superficial visual variations\nintroduced by augmentation from class-relevant semantic representations. This\ndecoupling enables the learned prompts to concentrate on visually\ndiscriminative features that align with the target categories. We conduct\ncomprehensive experiments on eleven benchmark datasets, and AAPL consistently\noutperforms existing methods across few-shot, zero-shot, cross-dataset, and\ndomain generalization settings. Our source code is publicly available at:\nhttps://github.com/Gahyeonkim09/AAPL", "AI": {"tldr": "本文提出AAPL方法，通过引入图像级属性特定增强和对抗性token嵌入来解耦视觉变异与语义表示，显著提升了提示学习在零样本和泛化任务中的性能。", "motivation": "现有提示学习方法（如CoOp、CoCoOp）在泛化到完全未见类别时表现不佳，且主要关注文本修改，忽略了图像增强的潜力。此外，现有方法缺乏明确指导，使学习到的提示难以关注语义上有意义的视觉特征。", "method": "本文探索了图像级增强（特别是引入属性特定变化的增强）如何支持和提升提示学习的泛化能力。为解决现有方法的局限性，本文提出了AAPL（Adding Attributes to Prompt Learning），一种新颖的方法。AAPL引入对抗性token嵌入，以解耦由增强引入的表面视觉变异与类别相关的语义表示，使学习到的提示能够专注于与目标类别对齐的视觉判别特征。", "result": "AAPL在十一个基准数据集上进行了全面的实验，并在少样本、零样本、跨数据集和域泛化设置中持续优于现有方法。", "conclusion": "图像级属性特定增强能够有效支持和提升提示学习的泛化能力。AAPL通过引入对抗性token嵌入，成功引导提示学习关注语义上有意义的视觉特征，显著提升了模型在多种泛化任务中的性能。"}}
{"id": "2511.03370", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03370", "abs": "https://arxiv.org/abs/2511.03370", "authors": ["Yunbo Long", "Yuhan Liu", "Alexandra Brintrup"], "title": "EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models for Edge-Deployable Credit Negotiation", "comment": null, "summary": "The deployment of large language models (LLMs) in automated negotiation has\nset a high performance benchmark, but their computational cost and data privacy\nrequirements render them unsuitable for many privacy-sensitive, on-device\napplications such as mobile assistants, embodied AI agents or private client\ninteractions. While small language models (SLMs) offer a practical alternative,\nthey suffer from a significant performance gap compared to LLMs in playing\nemotionally charged complex personas, especially for credit negotiation. This\npaper introduces EQ-Negotiator, a novel framework that bridges this capability\ngap using emotional personas. Its core is a reasoning system that integrates\ngame theory with a Hidden Markov Model(HMM) to learn and track debtor emotional\nstates online, without pre-training. This allows EQ-Negotiator to equip SLMs\nwith the strategic intelligence to counter manipulation while de-escalating\nconflict and upholding ethical standards. Through extensive agent-to-agent\nsimulations across diverse credit negotiation scenarios, including adversarial\ndebtor strategies like cheating, threatening, and playing the victim, we show\nthat a 7B parameter language model with EQ-Negotiator achieves better debt\nrecovery and negotiation efficiency than baseline LLMs more than 10 times its\nsize. This work advances persona modeling from descriptive character profiles\nto dynamic emotional architectures that operate within privacy constraints.\nBesides, this paper establishes that strategic emotional intelligence, not raw\nmodel scale, is the critical factor for success in automated negotiation,\npaving the way for effective, ethical, and privacy-preserving AI negotiators\nthat can operate on the edge.", "AI": {"tldr": "本文提出了EQ-Negotiator框架，通过结合博弈论和隐马尔可夫模型，使小型语言模型（SLM）在自动化信用协商中能够在线学习和追踪债务人情绪状态，从而弥补了与大型语言模型（LLM）的性能差距，实现了更好的债务回收和协商效率，同时兼顾隐私保护和伦理标准。", "motivation": "大型语言模型（LLM）在自动化协商中表现出色，但其高计算成本和数据隐私要求使其不适用于隐私敏感的设备端应用。小型语言模型（SLM）虽然是实用替代方案，但在处理情绪复杂的人格（尤其是在信用协商中）时，与LLM存在显著的性能差距。", "method": "本文引入了EQ-Negotiator框架，其核心是一个推理系统，该系统将博弈论与隐马尔可夫模型（HMM）相结合，以在线学习和追踪债务人的情绪状态，无需预训练。这使得SLM能够获得战略智能，以应对操纵、缓解冲突并维护伦理标准。", "result": "通过广泛的代理间模拟，包括对抗性债务人策略（如欺骗、威胁和扮演受害者），结果表明，一个7B参数的语言模型配备EQ-Negotiator，在债务回收和协商效率方面优于其规模十倍以上的基础LLM。", "conclusion": "这项工作将人格建模从描述性特征配置文件推进到动态情感架构，并在隐私约束下运行。研究表明，战略性情商而非原始模型规模，是自动化协商成功的关键因素，为有效、道德和隐私保护的边缘AI协商者铺平了道路。"}}
{"id": "2511.03372", "categories": ["cs.CL", "I.2.7; I.2.6; F.4.1"], "pdf": "https://arxiv.org/pdf/2511.03372", "abs": "https://arxiv.org/abs/2511.03372", "authors": ["Shenghao Li"], "title": "LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical Reasoning", "comment": "10 pages, 6 figures", "summary": "For complex logical data augmentation, heavy reliance on human annotation is\ncostly, whereas direct generation with large language models yields\nuninterpretable and logically homogeneous examples. To address this, we present\nLFC-DA, a symbolic-logic-controlled pipeline: logical text is first mapped to\npropositional expressions, a compact rule library is compiled, and a bounded\nstate-space search systematically discovers valid formulas that are then\nverbalized back into natural-language questions, ensuring both diversity and\nlogical rigor under propositional logic. Experiments on ReClor and LogiQA show\nsignificant improvements in the logical-reasoning accuracy of pretrained\nmodels, confirming the effectiveness of LFC-DA for LLM-guided logical data\naugmentation.", "AI": {"tldr": "LFC-DA是一种符号逻辑控制的数据增强管道，通过将逻辑文本映射到命题表达式并进行系统搜索来生成多样且逻辑严谨的自然语言问题，有效提升预训练模型的逻辑推理准确性。", "motivation": "复杂的逻辑数据增强高度依赖人工标注，成本高昂；而大型语言模型直接生成的数据则难以解释且逻辑上同质化。", "method": "LFC-DA管道首先将逻辑文本映射为命题表达式，然后编译一个紧凑的规则库，接着通过有界状态空间搜索系统地发现有效的公式，最后将这些公式口语化为自然语言问题，确保了命题逻辑下的多样性和逻辑严谨性。", "result": "在ReClor和LogiQA数据集上的实验表明，LFC-DA显著提高了预训练模型的逻辑推理准确性。", "conclusion": "实验结果证实了LFC-DA在LLM引导的逻辑数据增强方面的有效性。"}}
{"id": "2511.03354", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03354", "abs": "https://arxiv.org/abs/2511.03354", "authors": ["Riasad Alvi", "Sayeem Been Zaman", "Wasimul Karim", "Arefin Ittesafun Abian", "Mohaimenul Azam Khan Raiaan", "Saddam Mukta", "Md Rafi Ur Rashid", "Md Rafiqul Islam", "Yakub Sebastian", "Sami Azam"], "title": "Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances", "comment": null, "summary": "Generative artificial intelligence (GenAI) has become a transformative\napproach in bioinformatics that often enables advancements in genomics,\nproteomics, transcriptomics, structural biology, and drug discovery. To\nsystematically identify and evaluate these growing developments, this review\nproposed six research questions (RQs), according to the preferred reporting\nitems for systematic reviews and meta-analysis methods. The objective is to\nevaluate impactful GenAI strategies in methodological advancement, predictive\nperformance, and specialization, and to identify promising approaches for\nadvanced modeling, data-intensive discovery, and integrative biological\nanalysis. RQ1 highlights diverse applications across multiple bioinformatics\nsubfields (sequence analysis, molecular design, and integrative data modeling),\nwhich demonstrate superior performance over traditional methods through pattern\nrecognition and output generation. RQ2 reveals that adapted specialized model\narchitectures outperformed general-purpose models, an advantage attributed to\ntargeted pretraining and context-aware strategies. RQ3 identifies significant\nbenefits in the bioinformatics domains, focusing on molecular analysis and data\nintegration, which improves accuracy and reduces errors in complex analysis.\nRQ4 indicates improvements in structural modeling, functional prediction, and\nsynthetic data generation, validated by established benchmarks. RQ5 suggests\nthe main constraints, such as the lack of scalability and biases in data that\nimpact generalizability, and proposes future directions focused on robust\nevaluation and biologically grounded modeling. RQ6 examines that molecular\ndatasets (such as UniProtKB and ProteinNet12), cellular datasets (such as\nCELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly\nsupport the training and generalization of GenAI models.", "AI": {"tldr": "该综述系统评估了生成式人工智能（GenAI）在生物信息学中的变革作用，涵盖了其在基因组学、蛋白质组学、药物发现等领域的应用、方法学进展、预测性能、专业化、局限性及支持数据集。", "motivation": "生成式人工智能（GenAI）已成为生物信息学中的一种变革性方法，推动了基因组学、蛋白质组学、转录组学、结构生物学和药物发现等领域的发展。为了系统地识别和评估这些不断增长的进展，需要进行一次全面的审查。", "method": "本综述根据系统评价和荟萃分析的首选报告项目（PRISMA）方法，提出了六个研究问题（RQs）。旨在评估有影响力的GenAI策略在方法学进步、预测性能和专业化方面的表现，并识别有前景的高级建模、数据密集型发现和综合生物学分析方法。", "result": "RQ1强调GenAI在序列分析、分子设计和综合数据建模等多个生物信息学子领域的多样化应用，通过模式识别和输出生成，表现优于传统方法。RQ2揭示了经过调整的专业模型架构优于通用模型，这得益于有针对性的预训练和上下文感知策略。RQ3识别了GenAI在分子分析和数据整合方面的显著优势，提高了复杂分析的准确性并减少了错误。RQ4指出结构建模、功能预测和合成数据生成方面的改进已通过既定基准验证。RQ5提出了主要限制，如可扩展性不足和数据偏见影响泛化能力，并提出了未来方向，重点关注鲁棒评估和生物学基础建模。RQ6考察了分子、细胞和文本数据集广泛支持GenAI模型的训练和泛化。", "conclusion": "GenAI在生物信息学中带来了显著进步，通过专业化模型在多个应用领域超越了传统方法。尽管存在可扩展性和数据偏差等挑战，但未来方向应侧重于鲁棒评估和基于生物学原理的建模，并利用多样化的数据集支持GenAI模型的训练和泛化。"}}
{"id": "2511.03441", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03441", "abs": "https://arxiv.org/abs/2511.03441", "authors": ["Doria Bonzi", "Alexandre Guiggi", "Frédéric Béchet", "Carlos Ramisch", "Benoit Favre"], "title": "CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field", "comment": "Preprint submitted to LREC 2026 (under review) To access the dataset,\n  see https://github.com/bonzid/CareMedEval", "summary": "Critical appraisal of scientific literature is an essential skill in the\nbiomedical field. While large language models (LLMs) can offer promising\nsupport in this task, their reliability remains limited, particularly for\ncritical reasoning in specialized domains. We introduce CareMedEval, an\noriginal dataset designed to evaluate LLMs on biomedical critical appraisal and\nreasoning tasks. Derived from authentic exams taken by French medical students,\nthe dataset contains 534 questions based on 37 scientific articles. Unlike\nexisting benchmarks, CareMedEval explicitly evaluates critical reading and\nreasoning grounded in scientific papers. Benchmarking state-of-the-art\ngeneralist and biomedical-specialized LLMs under various context conditions\nreveals the difficulty of the task: open and commercial models fail to exceed\nan Exact Match Rate of 0.5 even though generating intermediate reasoning tokens\nconsiderably improves the results. Yet, models remain challenged especially on\nquestions about study limitations and statistical analysis. CareMedEval\nprovides a challenging benchmark for grounded reasoning, exposing current LLM\nlimitations and paving the way for future development of automated support for\ncritical appraisal.", "AI": {"tldr": "该研究引入了CareMedEval数据集，用于评估大型语言模型（LLMs）在生物医学批判性评估和推理任务中的表现，揭示了LLMs在此类任务中的局限性。", "motivation": "尽管大型语言模型在生物医学批判性评估中展现出潜力，但其可靠性有限，尤其是在专业领域的批判性推理方面。现有基准未能明确评估基于科学论文的批判性阅读和推理能力。", "method": "研究构建了一个名为CareMedEval的原创数据集，包含534个问题，基于37篇科学文章，这些问题来源于法国医学生的真实考试。随后，研究在不同上下文条件下，对最先进的通用型和生物医学专业型LLMs进行了基准测试。", "result": "基准测试结果显示，LLMs在任务中表现困难，开放和商业模型的准确匹配率未能超过0.5。虽然生成中间推理标记能显著提高结果，但模型在关于研究局限性和统计分析的问题上仍面临挑战。", "conclusion": "CareMedEval提供了一个具有挑战性的、基于事实的推理基准，暴露了当前LLMs的局限性，并为未来开发自动化批判性评估支持工具指明了方向。"}}
{"id": "2511.03232", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03232", "abs": "https://arxiv.org/abs/2511.03232", "authors": ["Sichen Guo", "Wenjie Li", "Yuanyang Liu", "Guangwei Gao", "Jian Yang", "Chia-Wen Lin"], "title": "Transformer-Progressive Mamba Network for Lightweight Image Super-Resolution", "comment": "12 pages, 10 figures, 7 tables", "summary": "Recently, Mamba-based super-resolution (SR) methods have demonstrated the\nability to capture global receptive fields with linear complexity, addressing\nthe quadratic computational cost of Transformer-based SR approaches. However,\nexisting Mamba-based methods lack fine-grained transitions across different\nmodeling scales, which limits the efficiency of feature representation. In this\npaper, we propose T-PMambaSR, a lightweight SR framework that integrates\nwindow-based self-attention with Progressive Mamba. By enabling interactions\namong receptive fields of different scales, our method establishes a\nfine-grained modeling paradigm that progressively enhances feature\nrepresentation with linear complexity. Furthermore, we introduce an Adaptive\nHigh-Frequency Refinement Module (AHFRM) to recover high-frequency details lost\nduring Transformer and Mamba processing. Extensive experiments demonstrate that\nT-PMambaSR progressively enhances the model's receptive field and\nexpressiveness, yielding better performance than recent Transformer- or\nMamba-based methods while incurring lower computational cost. Our codes will be\nreleased after acceptance.", "AI": {"tldr": "T-PMambaSR是一个轻量级超分辨率（SR）框架，结合了窗口自注意力机制和渐进式Mamba，实现了细粒度的多尺度建模和高频细节恢复，解决了现有Mamba方法的不足，并以线性复杂度取得了优于Transformer和Mamba基线方法的性能。", "motivation": "现有基于Mamba的超分辨率方法虽然具有线性复杂度，但缺乏跨不同建模尺度的细粒度过渡，限制了特征表示效率。而基于Transformer的方法则面临二次方的计算成本。", "method": "本文提出了T-PMambaSR，一个轻量级SR框架。它将基于窗口的自注意力机制与渐进式Mamba相结合，以实现不同尺度感受野之间的交互，从而建立细粒度的建模范式，并以线性复杂度逐步增强特征表示。此外，引入了一个自适应高频细化模块（AHFRM）来恢复在Transformer和Mamba处理过程中丢失的高频细节。", "result": "实验证明，T-PMambaSR逐步增强了模型的感受野和表达能力，与最近的基于Transformer或Mamba的方法相比，取得了更好的性能，同时计算成本更低。", "conclusion": "T-PMambaSR通过整合窗口自注意力与渐进式Mamba实现细粒度多尺度建模，并引入高频细节恢复模块，有效解决了现有Mamba-based SR方法的局限性，实现了高性能和高效率的超分辨率重建。"}}
{"id": "2511.03219", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03219", "abs": "https://arxiv.org/abs/2511.03219", "authors": ["Pengyu Jie", "Wanquan Liu", "Rui He", "Yihui Wen", "Deyu Meng", "Chenqiang Gao"], "title": "Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation", "comment": null, "summary": "Augmentation for dense prediction typically relies on either sample mixing or\ngenerative synthesis. Mixing improves robustness but misaligned masks yield\nsoft label ambiguity. Diffusion synthesis increases apparent diversity but,\nwhen trained as common samples, overlooks the structural benefit of mask\nconditioning and introduces synthetic-real domain shift. We propose a paired,\ndiffusion-guided paradigm that fuses the strengths of both. For each real\nimage, a synthetic counterpart is generated under the same mask and the pair is\nused as a controllable input for Mask-Consistent Paired Mixing (MCPMix), which\nmixes only image appearance while supervision always uses the original hard\nmask. This produces a continuous family of intermediate samples that smoothly\nbridges synthetic and real appearances under shared geometry, enlarging\ndiversity without compromising pixel-level semantics. To keep learning aligned\nwith real data, Real-Anchored Learnable Annealing (RLA) adaptively adjusts the\nmixing strength and the loss weight of mixed samples over training, gradually\nre-anchoring optimization to real data and mitigating distributional bias.\nAcross Kvasir-SEG, PICCOLO, CVC-ClinicDB, a private NPC-LES cohort, and ISIC\n2017, the approach achieves state-of-the-art segmentation performance and\nconsistent gains over baselines. The results show that combining\nlabel-preserving mixing with diffusion-driven diversity, together with adaptive\nre-anchoring, yields robust and generalizable endoscopic segmentation.", "AI": {"tldr": "本文提出了一种新的配对、扩散引导的密集预测数据增强范式，通过混合真实和合成图像外观，同时保持掩膜一致性并自适应地重新锚定到真实数据，以提高分割性能。", "motivation": "现有密集预测数据增强方法存在局限：样本混合可能因掩膜未对齐导致软标签模糊；扩散合成虽增加多样性，但训练时忽略掩膜条件结构优势，并引入合成-真实域偏移。", "method": "提出“配对、扩散引导范式”。为每张真实图像生成一个在相同掩膜下的合成对应图像，并用这对图像作为可控输入进行“掩膜一致配对混合（MCPMix）”，该方法仅混合图像外观，监督始终使用原始硬掩膜。这产生了一系列在共享几何结构下平滑连接合成和真实外观的中间样本。为使学习与真实数据对齐，引入“真实锚定可学习退火（RLA）”，在训练过程中自适应调整混合强度和混合样本的损失权重，逐步将优化重新锚定到真实数据，并减轻分布偏差。", "result": "在Kvasir-SEG、PICCOLO、CVC-ClinicDB、私人NPC-LES队列和ISIC 2017等多个数据集上，该方法实现了最先进的分割性能，并持续优于基线。", "conclusion": "结合保持标签的混合、扩散驱动的多样性以及自适应重新锚定，能够实现鲁棒且泛化能力强的内窥镜分割。"}}
{"id": "2511.03542", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03542", "abs": "https://arxiv.org/abs/2511.03542", "authors": ["Roberta Di Marino", "Giovanni Dioguardi", "Antonio Romano", "Giuseppe Riccio", "Mariano Barone", "Marco Postiglione", "Flora Amato", "Vincenzo Moscato"], "title": "SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across Medical Specialties", "comment": null, "summary": "Medical question answering systems face deployment challenges including\nhallucinations, bias, computational demands, privacy concerns, and the need for\nspecialized expertise across diverse domains. Here, we present SOLVE-Med, a\nmulti-agent architecture combining domain-specialized small language models for\ncomplex medical queries. The system employs a Router Agent for dynamic\nspecialist selection, ten specialized models (1B parameters each) fine-tuned on\nspecific medical domains, and an Orchestrator Agent that synthesizes responses.\nEvaluated on Italian medical forum data across ten specialties, SOLVE-Med\nachieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697,\noutperforming standalone models up to 14B parameters while enabling local\ndeployment. Our code is publicly available on GitHub:\nhttps://github.com/PRAISELab-PicusLab/SOLVE-Med.", "AI": {"tldr": "SOLVE-Med是一个多智能体架构，结合了领域专业化的小型语言模型（1B参数），用于处理复杂的医学查询，在意大利医学论坛数据上表现优于大型模型（高达14B参数），并支持本地部署。", "motivation": "医疗问答系统面临幻觉、偏见、计算需求高、隐私问题以及需要跨领域专业知识等部署挑战。", "method": "SOLVE-Med采用多智能体架构，包括：一个路由智能体（用于动态专家选择）、十个在特定医学领域微调的专业化小型模型（每个1B参数），以及一个协调智能体（用于综合响应）。", "result": "在意大利医学论坛的十个专业领域数据上，SOLVE-Med取得了优越的性能，ROUGE-1达到0.301，BERTScore F1达到0.697，其表现优于高达14B参数的独立模型，并支持本地部署。", "conclusion": "SOLVE-Med通过结合领域专业化的小型语言模型，有效地解决了医疗问答系统的部署挑战，实现了卓越的性能和本地部署能力。"}}
{"id": "2511.03245", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03245", "abs": "https://arxiv.org/abs/2511.03245", "authors": ["Liwei Luo", "Shuaitengyuan Li", "Dongwei Ren", "Qilong Wang", "Pengfei Zhu", "Qinghua Hu"], "title": "Decoupled Multi-Predictor Optimization for Inference-Efficient Model Tuning", "comment": "Accepted by ICCV2025", "summary": "Recently, remarkable progress has been made in large-scale pre-trained model\ntuning, and inference efficiency is becoming more crucial for practical\ndeployment. Early exiting in conjunction with multi-stage predictors, when\ncooperated with a parameter-efficient fine-tuning strategy, offers a\nstraightforward way to achieve an inference-efficient model. However, a key\nchallenge remains unresolved: How can early stages provide low-level\nfundamental features to deep stages while simultaneously supplying high-level\ndiscriminative features to early-stage predictors? To address this problem, we\npropose a Decoupled Multi-Predictor Optimization (DMPO) method to effectively\ndecouple the low-level representative ability and high-level discriminative\nability in early stages. First, in terms of architecture, we introduce a\nlightweight bypass module into multi-stage predictors for functional\ndecomposition of shallow features from early stages, while a high-order\nstatistics-based predictor is developed for early stages to effectively enhance\ntheir discriminative ability. To reasonably train our multi-predictor\narchitecture, a decoupled optimization is proposed to allocate two-phase loss\nweights for multi-stage predictors during model tuning, where the initial\ntraining phase enables the model to prioritize the acquisition of\ndiscriminative ability of deep stages via emphasizing representative ability of\nearly stages, and the latter training phase drives discriminative ability\ntowards earlier stages as much as possible. As such, our DMPO can effectively\ndecouple representative and discriminative abilities in early stages in terms\nof architecture design and model optimization. Experiments across various\ndatasets and pre-trained backbones demonstrate that DMPO clearly outperforms\nits counterparts when reducing computational cost.", "AI": {"tldr": "本文提出了一种解耦多预测器优化（DMPO）方法，通过架构设计和模型优化，有效解耦了早期阶段的代表性和判别性能力，从而在减少计算成本的同时提高了早期退出模型的推理效率。", "motivation": "早退出与多阶段预测器结合参数高效微调是提高模型推理效率的有效途径。然而，一个关键挑战是早期阶段难以同时为深层阶段提供低级基础特征，并为早期预测器提供高级判别特征。", "method": "DMPO方法在架构和优化两方面进行了解耦：\n1.  **架构设计**：引入轻量级旁路模块，实现浅层特征的功能分解；开发基于高阶统计的预测器，增强早期阶段的判别能力。\n2.  **解耦优化**：提出两阶段损失权重分配策略：\n    *   **初始训练阶段**：通过强调早期阶段的代表性能力，优先使深层阶段获得判别能力。\n    *   **后期训练阶段**：尽可能将判别能力驱动至更早的阶段。", "result": "在各种数据集和预训练骨干网络上的实验表明，DMPO在降低计算成本方面明显优于现有方法。", "conclusion": "DMPO通过架构设计和模型优化，有效地解耦了早期阶段的代表性和判别性能力，解决了早期退出模型中的关键挑战，提高了推理效率。"}}
{"id": "2511.03383", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03383", "abs": "https://arxiv.org/abs/2511.03383", "authors": ["Saumitra Yadav", "Manish Shrivastava"], "title": "Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for Optimal Machine Translation Performance", "comment": "Accepted at WAT 2025", "summary": "Existing Machine Translation (MT) research often suggests a single, fixed set\nof hyperparameters for word segmentation models, symmetric Byte Pair Encoding\n(BPE), which applies the same number of merge operations (NMO) to train\ntokenizers for both source and target languages. However, we demonstrate that\nthis uniform approach doesn't guarantee optimal MT performance across different\nlanguage pairs and data sizes. This work investigates BPE segmentation recipes\nacross various data volumes and language pairs to evaluate MT system\nperformance. We find that utilizing asymmetric BPE, where the source and target\nlanguages have different NMOs, significantly improves results over the\nsymmetric approach, especially in low-resource settings (50K, 100K, and 500K\nsentence pairs). Specifically, asymmetric BPE yield statistically significant\n($p<0.05$) average gains of 5.32, 4.46, and 0.7 CHRF++ on English-Hindi in\nlow-resource setups. We validated this trend across six additional language\npairs (English and Telugu, Shona, Norwegian, Kyrgyz, Hausa, and Inuktitut),\nobserving statistically significant improvement in 10 out of 12 systems\ncompared to symmetric BPE. Our findings indicate a high NMO for the source (4K\nto 32K) and a low NMO for the target (0.5K to 2K) provides optimal results,\nparticularly benefiting low-resource MT.", "AI": {"tldr": "本研究表明，非对称BPE（源语言和目标语言采用不同的合并操作次数）能显著提升机器翻译性能，尤其是在低资源设置下，优于传统的对称BPE。", "motivation": "现有机器翻译研究通常为词汇分割模型（对称BPE）建议单一固定的超参数集，但这种统一方法可能无法保证在不同语言对和数据量下获得最佳机器翻译性能。", "method": "研究通过在不同数据量（5万、10万、50万句对）和多种语言对（如英语-印地语，以及其他六种语言）上，评估了对称和非对称BPE分割方案对机器翻译系统性能的影响，并使用CHRF++指标进行衡量。", "result": "非对称BPE显著优于对称BPE，特别是在低资源设置下。在低资源英语-印地语设置中，非对称BPE平均获得5.32、4.46和0.7的CHRF++增益。在额外六个语言对中，12个系统中有10个观察到显著改进。源语言使用高NMO（4K-32K）而目标语言使用低NMO（0.5K-2K）可提供最佳结果，尤其有利于低资源机器翻译。", "conclusion": "非对称BPE，特别是源语言采用高合并操作次数而目标语言采用低合并操作次数的配置，比对称BPE更有效，能够显著提高机器翻译性能，尤其对低资源机器翻译有益。"}}
{"id": "2511.03260", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03260", "abs": "https://arxiv.org/abs/2511.03260", "authors": ["Rong Wu", "Yim-Sang Yu"], "title": "Enhancing Medical Image Segmentation via Heat Conduction Equation", "comment": null, "summary": "Medical image segmentation has been significantly advanced by deep learning\narchitectures, notably U-Net variants. However, existing models struggle to\nachieve efficient global context modeling and long-range dependency reasoning\nunder practical computational budgets simultaneously. In this work, we propose\na novel hybrid architecture utilizing U-Mamba with Heat Conduction Equation.\nOur model combines Mamba-based state-space modules for efficient long-range\nreasoning with Heat Conduction Operators (HCOs) in the bottleneck layers,\nsimulating frequency-domain thermal diffusion for enhanced semantic\nabstraction. Experimental results on multimodal abdominal CT and MRI datasets\ndemonstrate that the proposed model consistently outperforms strong baselines,\nvalidating its effectiveness and generalizability. It suggest that blending\nstate-space dynamics with heat-based global diffusion offers a scalable and\ninterpretable solution for medical segmentation tasks.", "AI": {"tldr": "本文提出了一种结合U-Mamba和热传导方程的混合架构，用于医学图像分割，以有效解决全局上下文建模和长距离依赖推理的挑战。", "motivation": "现有深度学习模型（尤其是U-Net变体）在实际计算预算下，难以同时实现高效的全局上下文建模和长距离依赖推理。", "method": "提出了一种新颖的混合架构，将基于Mamba的状态空间模块用于高效的长距离推理，并在瓶颈层中引入热传导算子（HCOs），模拟频域热扩散以增强语义抽象。", "result": "在多模态腹部CT和MRI数据集上的实验结果表明，所提出的模型持续优于强大的基线模型，验证了其有效性和泛化性。", "conclusion": "将状态空间动态与基于热的全局扩散相结合，为医学分割任务提供了一个可扩展且可解释的解决方案。"}}
{"id": "2511.03267", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03267", "abs": "https://arxiv.org/abs/2511.03267", "authors": ["Bingyang Guo", "Hongjie Li", "Ruiyun Yu", "Hanzhe Liang", "Jinbao Wang"], "title": "IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection", "comment": null, "summary": "3D anomaly detection (3D-AD) plays a critical role in industrial\nmanufacturing, particularly in ensuring the reliability and safety of core\nequipment components. Although existing 3D datasets like Real3D-AD and MVTec\n3D-AD offer broad application support, they fall short in capturing the\ncomplexities and subtle defects found in real industrial environments. This\nlimitation hampers precise anomaly detection research, especially for\nindustrial equipment components (IEC) such as bearings, rings, and bolts. To\naddress this challenge, we have developed a point cloud anomaly detection\ndataset (IEC3D-AD) specific to real industrial scenarios. This dataset is\ndirectly collected from actual production lines, ensuring high fidelity and\nrelevance. Compared to existing datasets, IEC3D-AD features significantly\nimproved point cloud resolution and defect annotation granularity, facilitating\nmore demanding anomaly detection tasks. Furthermore, inspired by generative\n2D-AD methods, we introduce a novel 3D-AD paradigm (GMANet) on IEC3D-AD. This\nparadigm generates synthetic point cloud samples based on geometric\nmorphological analysis, then reduces the margin and increases the overlap\nbetween normal and abnormal point-level features through spatial discrepancy\noptimization. Extensive experiments demonstrate the effectiveness of our method\non both IEC3D-AD and other datasets.", "AI": {"tldr": "该研究提出了一个针对真实工业场景的3D点云异常检测数据集IEC3D-AD，并引入了一种基于生成式几何形态分析的新型3D异常检测范式GMANet，以解决现有数据集和方法在工业设备组件异常检测中的局限性。", "motivation": "现有的3D异常检测数据集（如Real3D-AD和MVTec 3D-AD）未能捕捉真实工业环境中复杂且细微的缺陷，这阻碍了对轴承、环件和螺栓等工业设备组件(IEC)进行精确异常检测的研究。", "method": "1. 开发了IEC3D-AD数据集：直接从实际生产线收集，具有更高的点云分辨率和缺陷标注粒度。 2. 提出了GMANet范式：受生成式2D-AD方法的启发，通过几何形态分析生成合成点云样本，并通过空间差异优化减少正常和异常点级特征之间的裕度并增加重叠。", "result": "广泛的实验证明了所提出的方法在IEC3D-AD和其他数据集上的有效性。", "conclusion": "该研究通过提供一个高保真度的工业特定3D异常检测数据集IEC3D-AD和一个创新的生成式3D异常检测范式GMANet，显著提升了工业制造中核心设备组件的异常检测能力。"}}
{"id": "2511.03407", "categories": ["cs.CL", "I.2.7; I.2.4"], "pdf": "https://arxiv.org/pdf/2511.03407", "abs": "https://arxiv.org/abs/2511.03407", "authors": ["Célian Ringwald", "Fabien Gandon", "Catherine Faron", "Franck Michel", "Hanna Abi Akl"], "title": "Overcoming the Generalization Limits of SLM Finetuning for Shape-Based Extraction of Datatype and Object Properties", "comment": "Accepted at KCAP 2025", "summary": "Small language models (SLMs) have shown promises for relation extraction (RE)\nwhen extracting RDF triples guided by SHACL shapes focused on common datatype\nproperties. This paper investigates how SLMs handle both datatype and object\nproperties for a complete RDF graph extraction. We show that the key bottleneck\nis related to long-tail distribution of rare properties. To solve this issue,\nwe evaluate several strategies: stratified sampling, weighted loss, dataset\nscaling, and template-based synthetic data augmentation. We show that the best\nstrategy to perform equally well over unbalanced target properties is to build\na training set where the number of occurrences of each property exceeds a given\nthreshold. To enable reproducibility, we publicly released our datasets,\nexperimental results and code. Our findings offer practical guidance for\ntraining shape-aware SLMs and highlight promising directions for future work in\nsemantic RE.", "AI": {"tldr": "本文研究了小型语言模型（SLM）在提取完整RDF图（包括数据类型和对象属性）时的性能，并解决了稀有属性长尾分布的瓶颈，发现通过确保每个属性出现次数达到阈值来构建训练集是最有效的策略。", "motivation": "小型语言模型在基于SHACL形状提取RDF三元组时，尤其是在处理常见数据类型属性方面，已显示出潜力。本研究旨在探讨SLM如何处理数据类型和对象属性，以实现完整的RDF图提取，并解决稀有属性长尾分布带来的关键瓶颈。", "method": "为了解决稀有属性的长尾分布问题，本文评估了几种策略：分层抽样、加权损失、数据集缩放和基于模板的合成数据增强。", "result": "研究发现，关键瓶颈在于稀有属性的长尾分布。在处理不平衡目标属性时，最佳策略是构建一个训练集，其中每个属性的出现次数都超过给定的阈值，从而实现同等良好的性能。", "conclusion": "研究结果为训练形状感知的SLM提供了实用指导，并为语义关系抽取领域的未来工作指明了有前景的方向。为确保可复现性，研究团队已公开发布了数据集、实验结果和代码。"}}
{"id": "2511.03553", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03553", "abs": "https://arxiv.org/abs/2511.03553", "authors": ["Sofie Helene Bruun", "Dan Saattrup Smart"], "title": "MultiZebraLogic: A Multilingual Logical Reasoning Benchmark", "comment": "Submitted to LREC 2026", "summary": "Measuring the full abilities of large language models (LLMs) requires\nbenchmarks representing multiple tasks. We aim to create large, high-quality\ndatasets for comparison of logical reasoning skills across several languages\nand of suitable difficulty for LLMs of various reasoning ability. We explore\nmultiple ways of increasing difficulty. We generate zebra puzzles in multiple\nlanguages, themes, sizes and including 14 different clue types and 8 red\nherring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 are\nsufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (a\nreasoning model), respectively. Including 5 red herrings decreases o3-mini\npuzzle-level accuracy on 4x5 puzzles by 15$\\pm$7 %. Scores of o3-mini on 4x5\npuzzles are not significantly affected by use of English vs. Danish or the\ncommon houses theme vs. the country-specific smoerrebroed theme. We find no\ncorrelation between difficulty and the selected clue types. Datasets of\n128+1024 puzzles are published as MultiZebraLogic in each of nine Germanic\nlanguages for sizes 2x3 and 4x5. We publish code for puzzle generation,\ndesigned for adaptablity into more languages and themes.", "AI": {"tldr": "本文创建了多语言、高质量的斑马谜题数据集（MultiZebraLogic），用于评估大型语言模型（LLMs）的逻辑推理能力，并探讨了增加谜题难度的方法，发现红鲱鱼线索能显著降低模型准确率。", "motivation": "为了全面衡量大型语言模型（LLMs）的能力，特别是逻辑推理技能，需要跨多种任务、多语言且难度适中的基准测试数据集。", "method": "研究人员生成了多语言斑马谜题，涵盖不同主题、规模，包含14种线索类型和8种“红鲱鱼”类型（无信息线索），并探索了多种增加难度的方法。他们使用GPT-4o mini（非推理模型）和o3-mini（推理模型）进行了测试。", "result": "结果显示，2x3和4x5的谜题规模分别对GPT-4o mini和o3-mini构成挑战。在4x5谜题中，加入5个红鲱鱼线索使o3-mini的谜题级准确率下降了15±7%。o3-mini在4x5谜题上的得分不受英语与丹麦语或通用房屋主题与特定国家三明治主题的影响。未发现难度与所选线索类型之间存在关联。最终发布了包含128+1024个谜题的MultiZebraLogic数据集，涵盖九种日耳曼语言的2x3和4x5规模谜题，并公开了谜题生成代码。", "conclusion": "研究成功创建了用于评估LLM逻辑推理能力的多语言、高质量斑马谜题数据集（MultiZebraLogic），并发现红鲱鱼线索是有效增加谜题难度的方式。数据集和生成代码的发布将有助于未来LLM的评估和开发。"}}
{"id": "2511.03272", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03272", "abs": "https://arxiv.org/abs/2511.03272", "authors": ["Shuangquan Lyu", "Steven Mao", "Yue Ma"], "title": "Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising", "comment": null, "summary": "Generating long videos remains a fundamental challenge, and achieving high\ncontrollability in video inpainting and outpainting is particularly demanding.\nTo address both of these challenges simultaneously and achieve controllable\nvideo inpainting and outpainting for long video clips, we introduce a novel and\nunified approach for long video inpainting and outpainting that extends\ntext-to-video diffusion models to generate arbitrarily long, spatially edited\nvideos with high fidelity. Our method leverages LoRA to efficiently fine-tune a\nlarge pre-trained video diffusion model like Alibaba's Wan 2.1 for masked\nregion video synthesis, and employs an overlap-and-blend temporal co-denoising\nstrategy with high-order solvers to maintain consistency across long sequences.\nIn contrast to prior work that struggles with fixed-length clips or exhibits\nstitching artifacts, our system enables arbitrarily long video generation and\nediting without noticeable seams or drift. We validate our approach on\nchallenging inpainting/outpainting tasks including editing or adding objects\nover hundreds of frames and demonstrate superior performance to baseline\nmethods like Wan 2.1 model and VACE in terms of quality (PSNR/SSIM), and\nperceptual realism (LPIPS). Our method enables practical long-range video\nediting with minimal overhead, achieved a balance between parameter efficient\nand superior performance.", "AI": {"tldr": "本文提出了一种新颖统一的方法，通过扩展文本到视频扩散模型，结合LoRA微调和时序协同去噪策略，实现了任意长度、高可控性的长视频修复和外绘制，有效解决了长视频生成和编辑中的一致性与质量挑战。", "motivation": "生成长视频是一个基本挑战，尤其是在视频修复和外绘制中实现高可控性非常困难。现有方法往往受限于固定长度的视频片段或存在拼接伪影。", "method": "该方法扩展了文本到视频扩散模型（如阿里巴巴的Wan 2.1），利用LoRA高效微调预训练模型进行掩码区域视频合成，并采用重叠融合的时序协同去噪策略与高阶求解器，以保持长序列之间的一致性。", "result": "该系统能够生成和编辑任意长度的视频，没有明显的接缝或漂移。在数百帧的修复/外绘制任务中，其性能优于基线方法（如Wan 2.1和VACE），在质量（PSNR/SSIM）和感知真实感（LPIPS）方面表现卓越。该方法以最小的开销实现了实用的长距离视频编辑，并在参数效率和卓越性能之间取得了平衡。", "conclusion": "本文提出了一种新颖且统一的方法，能够以最小的开销实现实用的长距离视频编辑，具有高保真度和可控性，有效解决了长视频生成和编辑中的核心挑战。"}}
{"id": "2511.03559", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03559", "abs": "https://arxiv.org/abs/2511.03559", "authors": ["Joachim Diederich"], "title": "AILA--First Experiments with Localist Language Models", "comment": null, "summary": "This paper presents the first empirical demonstration of controllable\nlocality in transformer language models, a novel architectural framework that\nenables continuous control over the degree of representation localization\nthrough a tunable locality dial parameter. Unlike traditional language models\nthat rely exclusively on distributed representations, our approach allows\ndynamic interpolation between highly interpretable localist encodings and\nefficient distributed representations without requiring model retraining. We\nconducted experiments on the WikiText corpus using a two-layer transformer\narchitecture, systematically varying the locality parameter {\\lambda} across\nthe full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our\nresults demonstrate that localist configurations achieve dramatically lower\nattention entropy, with {\\lambda} = 1.0 yielding 5.36 bits compared to 7.18\nbits at {\\lambda} = 0.0, while maintaining substantially higher pointer\nfidelity scores reflecting stronger alignment with rule-specified targets.\nPrediction experiments reveal that intermediate locality values optimize the\ntradeoff between interpretability and performance, with {\\lambda} = 0.6\nachieving test perplexity of 4.65 and accuracy of 84.7%. These findings\nestablish that localist language models provide a practical framework for\napplications in regulated domains requiring both transparency and capability,\noffering precise mathematical control over the interpretability-performance\nspectrum through explicit penalty thresholds and information-theoretic design\nprinciples.", "AI": {"tldr": "本文首次实证展示了Transformer语言模型中可控的局部性，通过一个可调的局部性参数，实现了可解释的局部性编码和高效的分布式表示之间的连续控制，无需重新训练模型。", "motivation": "传统的语言模型主要依赖分布式表示，缺乏对表示局部性程度的控制。本研究旨在开发一种方法，允许动态地在高度可解释的局部性编码和高效的分布式表示之间进行插值，以满足需要透明度和能力的受监管领域应用的需求。", "method": "研究引入了一个可调的局部性参数λ，将其整合到Transformer语言模型架构中。在WikiText语料库上，使用一个两层Transformer架构进行实验，系统地将λ从1.0（完全局部性）变化到0.0（完全分布式），并评估其对注意力熵、指针保真度和预测性能（困惑度、准确率）的影响。", "result": "结果表明，局部性配置（λ=1.0）显著降低了注意力熵（5.36比特，而λ=0.0时为7.18比特），同时保持了更高的指针保真度。预测实验显示，中间局部性值（如λ=0.6）能在可解释性和性能之间取得最佳平衡，实现了4.65的测试困惑度和84.7%的准确率。", "conclusion": "研究确立了局部性语言模型为受监管领域提供了一个实用的框架，这些领域既需要透明度又需要能力。通过显式惩罚阈值和信息论设计原则，该框架能够对可解释性-性能谱系进行精确的数学控制。"}}
{"id": "2511.03408", "categories": ["cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2511.03408", "abs": "https://arxiv.org/abs/2511.03408", "authors": ["Canhui Wu", "Qiong Cao", "Chao Xue", "Wei Xi", "Xiaodong He"], "title": "Efficient Reasoning via Thought-Training and Thought-Free Inference", "comment": "11 pages, 4 figures", "summary": "Recent advances in large language models (LLMs) have leveraged explicit\nChain-of-Thought (CoT) prompting to improve reasoning accuracy. However, most\nexisting methods primarily compress verbose reasoning outputs. These\nLong-to-Short transformations aim to improve efficiency, but still rely on\nexplicit reasoning during inference. In this work, we introduce \\textbf{3TF}\n(\\textbf{T}hought-\\textbf{T}raining and \\textbf{T}hought-\\textbf{F}ree\ninference), a framework for efficient reasoning that takes a Short-to-Long\nperspective. We first train a hybrid model that can operate in both reasoning\nand non-reasoning modes, and then further train it on CoT-annotated data to\ninternalize structured reasoning, while enforcing concise, thought-free outputs\nat inference time using the no-reasoning mode. Unlike compression-based\napproaches, 3TF improves the reasoning quality of non-reasoning outputs,\nenabling models to perform rich internal reasoning implicitly while keeping\nexternal outputs short. Empirically, 3TF-trained models obtain large\nimprovements on reasoning benchmarks under thought-free inference,\ndemonstrating that high quality reasoning can be learned and executed\nimplicitly without explicit step-by-step generation.", "AI": {"tldr": "本文提出3TF框架，通过在训练阶段内化CoT推理过程，使大型语言模型在推理时能进行高质量的隐式推理，同时输出简洁的无思考结果，从而提高推理效率和准确性。", "motivation": "现有的CoT方法虽然提高了推理准确性，但仍依赖于推理过程的显式输出（即使经过压缩），这导致推理过程冗长且效率不高。研究者旨在实现模型在不显式生成推理步骤的情况下，也能进行高质量的推理。", "method": "3TF（Thought-Training and Thought-Free inference）框架采取“短到长”而非“长到短”的视角。首先训练一个混合模型，使其能在推理和非推理模式下运行。然后，在CoT标注数据上进一步训练模型，使其内化结构化推理过程，同时在推理时强制使用非推理模式，生成简洁、无思考的输出。这使得模型能够进行丰富的内部隐式推理，而外部输出保持简短。", "result": "实验结果表明，经过3TF训练的模型在无思考推理模式下，在推理基准测试上获得了显著的性能提升。这证明了高质量的推理可以被隐式学习和执行，而无需显式的分步生成过程。", "conclusion": "研究结论是，大型语言模型能够通过内化CoT推理过程，在不显式生成推理步骤的情况下，实现高质量的隐式推理，从而在保持输出简洁的同时，提高推理的效率和准确性。"}}
{"id": "2511.03601", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.03601", "abs": "https://arxiv.org/abs/2511.03601", "authors": ["Chao Yan", "Boyong Wu", "Peng Yang", "Pengfei Tan", "Guoqiang Hu", "Yuxin Zhang", "Xiangyu", "Zhang", "Fei Tian", "Xuerui Yang", "Xiangyu Zhang", "Daxin Jiang", "Gang Yu"], "title": "Step-Audio-EditX Technical Report", "comment": null, "summary": "We present Step-Audio-EditX, the first open-source LLM-based audio model\nexcelling at expressive and iterative audio editing encompassing emotion,\nspeaking style, and paralinguistics alongside robust zero-shot text-to-speech\n(TTS) capabilities.Our core innovation lies in leveraging only large-margin\nsynthetic data, which circumvents the need for embedding-based priors or\nauxiliary modules. This large-margin learning approach enables both iterative\ncontrol and high expressivity across voices, and represents a fundamental pivot\nfrom the conventional focus on representation-level disentanglement. Evaluation\nresults demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and\nDoubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.", "AI": {"tldr": "Step-Audio-EditX是首个开源的基于LLM的音频模型，通过利用大裕度合成数据，实现了富有表现力和迭代性的音频编辑（包括情感、说话风格和副语言），并具备强大的零样本文本转语音能力。", "motivation": "研究动机在于开发一个能够进行富有表现力、迭代性音频编辑（涵盖情感、说话风格和副语言）并支持鲁棒零样本文本转语音的音频模型。", "method": "核心创新在于仅使用大裕度合成数据进行训练，从而避免了对基于嵌入的先验知识或辅助模块的需求。这种大裕度学习方法实现了对不同声音的迭代控制和高表现力，并与传统上专注于表示层解耦的方法有所不同。", "result": "评估结果表明，Step-Audio-EditX在情感编辑和其他细粒度控制任务中超越了MiniMax-2.6-hd和Doubao-Seed-TTS-2.0。", "conclusion": "Step-Audio-EditX成功展示了通过创新性的大裕度学习方法，在富有表现力和迭代性的音频编辑方面取得了卓越性能，并提供了强大的零样本文本转语音能力。"}}
{"id": "2511.03410", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03410", "abs": "https://arxiv.org/abs/2511.03410", "authors": ["Longpeng Qiu", "Ting Li", "Shuai Mao", "Nan Yang", "Xiaohui Yan"], "title": "Knowledge-Augmented Question Error Correction for Chinese Question Answer System with QuestionRAG", "comment": "EMNLP2025 Industry Track", "summary": "Input errors in question-answering (QA) systems often lead to incorrect\nresponses. Large language models (LLMs) struggle with this task, frequently\nfailing to interpret user intent (misinterpretation) or unnecessarily altering\nthe original question's structure (over-correction). We propose QuestionRAG, a\nframework that tackles these problems. To address misinterpretation, it\nenriches the input with external knowledge (e.g., search results, related\nentities). To prevent over-correction, it uses reinforcement learning (RL) to\nalign the model's objective with precise correction, not just paraphrasing. Our\nresults demonstrate that knowledge augmentation is critical for understanding\nfaulty questions. Furthermore, RL-based alignment proves significantly more\neffective than traditional supervised fine-tuning (SFT), boosting the model's\nability to follow instructions and generalize. By integrating these two\nstrategies, QuestionRAG unlocks the full potential of LLMs for the question\ncorrection task.", "AI": {"tldr": "QuestionRAG框架通过结合外部知识增强和强化学习，解决了问答系统中大型语言模型因输入错误导致的误解和过度纠正问题。", "motivation": "问答系统中的输入错误常导致不准确的响应。大型语言模型（LLMs）在此任务上表现不佳，经常误解用户意图（误解）或不必要地改变原始问题结构（过度纠正）。", "method": "提出QuestionRAG框架。为解决误解，通过外部知识（如搜索结果、相关实体）丰富输入。为防止过度纠正，使用强化学习（RL）将模型目标与精确纠正而非仅仅释义对齐。将这两种策略整合。", "result": "知识增强对于理解有缺陷的问题至关重要。基于RL的对齐比传统的监督微调（SFT）显著更有效，提升了模型遵循指令和泛化的能力。通过整合这两种策略，QuestionRAG释放了LLMs在问题纠正任务上的全部潜力。", "conclusion": "QuestionRAG通过结合知识增强和强化学习对齐，有效解决了LLMs在问题纠正任务中面临的误解和过度纠正挑战，显著提升了模型性能。"}}
{"id": "2511.03656", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03656", "abs": "https://arxiv.org/abs/2511.03656", "authors": ["Jing Gao", "Shutiao Luo", "Yumeng Liu", "Yuanming Li", "Hongji Zeng"], "title": "ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation", "comment": "13 pages, 6 tables, 4 figures, accepted by ICANN 2025", "summary": "With the rapid advancement of natural language processing (NLP) technologies,\nthe demand for high-quality Chinese document question-answering datasets is\nsteadily growing. To address this issue, we present the Chinese Multi-Document\nQuestion Answering Dataset(ChiMDQA), specifically designed for downstream\nbusiness scenarios across prevalent domains including academic, education,\nfinance, law, medical treatment, and news. ChiMDQA encompasses long-form\ndocuments from six distinct fields, consisting of 6,068 rigorously curated,\nhigh-quality question-answer (QA) pairs further classified into ten\nfine-grained categories. Through meticulous document screening and a systematic\nquestion-design methodology, the dataset guarantees both diversity and high\nquality, rendering it applicable to various NLP tasks such as document\ncomprehension, knowledge extraction, and intelligent QA systems. Additionally,\nthis paper offers a comprehensive overview of the dataset's design objectives,\nconstruction methodologies, and fine-grained evaluation system, supplying a\nsubstantial foundation for future research and practical applications in\nChinese QA. The code and data are available at:\nhttps://anonymous.4open.science/r/Foxit-CHiMDQA/.", "AI": {"tldr": "本文提出了一个名为ChiMDQA的中文多文档问答数据集，旨在满足不同业务场景下的需求，并支持多种NLP任务。", "motivation": "随着自然语言处理技术的发展，对高质量中文文档问答数据集的需求日益增长，特别是在学术、教育、金融、法律、医疗和新闻等常见领域。", "method": "ChiMDQA数据集通过严格筛选文档和系统性的问题设计方法构建而成。它包含了来自六个不同领域的长篇文档，共计6,068个经过精心策划的高质量问答对，并进一步细分为十个细粒度类别。此外，论文还概述了数据集的设计目标、构建方法和细粒度评估系统。", "result": "ChiMDQA数据集保证了多样性和高质量，适用于文档理解、知识提取和智能问答系统等多种NLP任务。它为中文问答领域的未来研究和实际应用提供了坚实的基础。", "conclusion": "ChiMDQA数据集通过提供一个多样化、高质量的中文多文档问答资源，为中文问答的未来研究和实际应用奠定了基础。"}}
{"id": "2511.03317", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03317", "abs": "https://arxiv.org/abs/2511.03317", "authors": ["Minghao Fu", "Guo-Hua Wang", "Tianyu Cui", "Qing-Guo Chen", "Zhao Xu", "Weihua Luo", "Kaifu Zhang"], "title": "Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models", "comment": "The code is publicly available at\n  https://github.com/AIDC-AI/Diffusion-SDPO", "summary": "Text-to-image diffusion models deliver high-quality images, yet aligning them\nwith human preferences remains challenging. We revisit diffusion-based Direct\nPreference Optimization (DPO) for these models and identify a critical\npathology: enlarging the preference margin does not necessarily improve\ngeneration quality. In particular, the standard Diffusion-DPO objective can\nincrease the reconstruction error of both winner and loser branches.\nConsequently, degradation of the less-preferred outputs can become sufficiently\nsevere that the preferred branch is also adversely affected even as the margin\ngrows. To address this, we introduce Diffusion-SDPO, a safeguarded update rule\nthat preserves the winner by adaptively scaling the loser gradient according to\nits alignment with the winner gradient. A first-order analysis yields a\nclosed-form scaling coefficient that guarantees the error of the preferred\noutput is non-increasing at each optimization step. Our method is simple,\nmodel-agnostic, broadly compatible with existing DPO-style alignment frameworks\nand adds only marginal computational overhead. Across standard text-to-image\nbenchmarks, Diffusion-SDPO delivers consistent gains over preference-learning\nbaselines on automated preference, aesthetic, and prompt alignment metrics.\nCode is publicly available at https://github.com/AIDC-AI/Diffusion-SDPO.", "AI": {"tldr": "本文提出Diffusion-SDPO，解决了传统Diffusion-DPO中偏好裕度增加可能导致生成质量下降的问题，通过自适应缩放劣势梯度来保护优势结果，从而提升文生图模型与人类偏好的对齐效果。", "motivation": "文生图扩散模型生成图像质量高，但与人类偏好对齐仍具挑战。现有Diffusion-DPO存在一个关键缺陷：增大偏好裕度不一定能提升生成质量，反而可能增加优胜和劣势分支的重建误差，导致劣势输出严重退化，甚至影响到优势分支。", "method": "引入Diffusion-SDPO，一种受保护的更新规则。它通过根据劣势梯度与优势梯度的对齐程度，自适应地缩放劣势梯度来保护优势结果。通过一阶分析得到一个闭式缩放系数，确保在每个优化步骤中，偏好输出的误差不会增加。该方法简单、模型无关、兼容性强且计算开销极小。", "result": "在标准文生图基准测试中，Diffusion-SDPO在自动化偏好、美学和提示对齐指标上，均持续优于现有的偏好学习基线方法。", "conclusion": "Diffusion-SDPO成功解决了Diffusion-DPO中存在的关键病理问题，通过确保偏好输出的质量不受损害，显著提高了文生图模型与人类偏好的对齐效果，并展现出稳定的性能提升。"}}
{"id": "2511.03332", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03332", "abs": "https://arxiv.org/abs/2511.03332", "authors": ["Yi Yang", "Yiming Xu", "Timo Kaiser", "Hao Cheng", "Bodo Rosenhahn", "Michael Ying Yang"], "title": "Multi-Object Tracking Retrieval with LLaVA-Video: A Training-Free Solution to MOT25-StAG Challenge", "comment": null, "summary": "In this report, we present our solution to the MOT25-Spatiotemporal Action\nGrounding (MOT25-StAG) Challenge. The aim of this challenge is to accurately\nlocalize and track multiple objects that match specific and free-form language\nqueries, using video data of complex real-world scenes as input. We model the\nunderlying task as a video retrieval problem and present a two-stage, zero-shot\napproach, combining the advantages of the SOTA tracking model FastTracker and\nMulti-modal Large Language Model LLaVA-Video. On the MOT25-StAG test set, our\nmethod achieves m-HIoU and HOTA scores of 20.68 and 10.73 respectively, which\nwon second place in the challenge.", "AI": {"tldr": "本文提出了一种解决MOT25-Spatiotemporal Action Grounding (StAG)挑战赛的方法，结合了最先进的追踪模型和多模态大语言模型，并获得了第二名。", "motivation": "挑战赛旨在利用复杂真实场景的视频数据，根据特定的自由形式语言查询，准确地定位和追踪多个匹配对象。", "method": "将底层任务建模为视频检索问题，并提出了一种两阶段、零样本的方法。该方法结合了最先进的追踪模型FastTracker和多模态大语言模型LLaVA-Video的优势。", "result": "在MOT25-StAG测试集上，该方法取得了20.68的m-HIoU和10.73的HOTA分数，在挑战赛中获得第二名。", "conclusion": "所提出的两阶段、零样本方法，通过结合SOTA追踪模型和多模态大语言模型，有效解决了MOT25-StAG挑战，并取得了有竞争力的结果。"}}
{"id": "2511.03325", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03325", "abs": "https://arxiv.org/abs/2511.03325", "authors": ["Mauro Orazio Drago", "Luca Carlini", "Pelinsu Celebi Balyemez", "Dennis Pierantozzi", "Chiara Lena", "Cesare Hassan", "Danail Stoyanov", "Elena De Momi", "Sophia Bano", "Mobarak I. Hoque"], "title": "SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding", "comment": null, "summary": "Video Question Answering (VideoQA) in the surgical domain aims to enhance\nintraoperative understanding by enabling AI models to reason over temporally\ncoherent events rather than isolated frames. Current approaches are limited to\nstatic image features, and available datasets often lack temporal annotations,\nignoring the dynamics critical for accurate procedural interpretation. We\npropose SurgViVQA, a surgical VideoQA model that extends visual reasoning from\nstatic images to dynamic surgical scenes. It uses a Masked Video--Text Encoder\nto fuse video and question features, capturing temporal cues such as motion and\ntool--tissue interactions, which a fine-tuned large language model (LLM) then\ndecodes into coherent answers. To evaluate its performance, we curated\nREAL-Colon-VQA, a colonoscopic video dataset that includes motion-related\nquestions and diagnostic attributes, as well as out-of-template questions with\nrephrased or semantically altered formulations to assess model robustness.\nExperimental validation on REAL-Colon-VQA and the public EndoVis18-VQA dataset\nshows that SurgViVQA outperforms existing image-based VQA benchmark models,\nparticularly in keyword accuracy, improving over PitVQA by +11\\% on\nREAL-Colon-VQA and +9\\% on EndoVis18-VQA. A perturbation study on the questions\nfurther confirms improved generalizability and robustness to variations in\nquestion phrasing. SurgViVQA and the REAL-Colon-VQA dataset provide a framework\nfor temporally-aware understanding in surgical VideoQA, enabling AI models to\ninterpret dynamic procedural contexts more effectively. Code and dataset\navailable at https://github.com/madratak/SurgViVQA.", "AI": {"tldr": "本文提出SurgViVQA模型和REAL-Colon-VQA数据集，旨在解决手术视频问答中对动态场景理解的不足，通过捕捉时间线索，显著优于现有基于图像的模型。", "motivation": "当前手术视频问答（VideoQA）方法局限于静态图像特征，现有数据集缺乏时间注释，忽视了手术过程中关键的动态信息，导致模型无法准确解释程序性事件。", "method": "提出了SurgViVQA模型，将视觉推理从静态图像扩展到动态手术场景。它使用一个Masked Video-Text Encoder来融合视频和问题特征，捕捉运动和工具-组织交互等时间线索，然后由一个微调的大型语言模型（LLM）解码生成连贯的答案。为评估模型性能，研究者还创建了REAL-Colon-VQA结肠镜视频数据集，包含运动相关问题和诊断属性，以及评估模型鲁棒性的模板外问题。", "result": "SurgViVQA在REAL-Colon-VQA和公开的EndoVis18-VQA数据集上表现优于现有基于图像的VQA基准模型，尤其在关键词准确率方面，在REAL-Colon-VQA上比PitVQA提高了11%，在EndoVis18-VQA上提高了9%。对问题的扰动研究进一步证实了模型在问题措辞变化下的泛化性和鲁棒性有所提高。", "conclusion": "SurgViVQA模型和REAL-Colon-VQA数据集为手术视频问答提供了一个时间感知理解的框架，使AI模型能够更有效地解释动态程序性上下文。"}}
{"id": "2511.03466", "categories": ["cs.CL", "I.2.4; I.2.7"], "pdf": "https://arxiv.org/pdf/2511.03466", "abs": "https://arxiv.org/abs/2511.03466", "authors": ["Ringwald Celian", "Gandon Fabien", "Faron Catherine", "Michel Franck", "Abi Akl Hanna"], "title": "Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction", "comment": "Accepted at ESWC 2025", "summary": "RDF pattern-based extraction is a compelling approach for fine-tuning small\nlanguage models (SLMs) by focusing a relation extraction task on a specified\nSHACL shape. This technique enables the development of efficient models trained\non limited text and RDF data. In this article, we introduce Kastor, a framework\nthat advances this approach to meet the demands for completing and refining\nknowledge bases in specialized domains. Kastor reformulates the traditional\nvalidation task, shifting from single SHACL shape validation to evaluating all\npossible combinations of properties derived from the shape. By selecting the\noptimal combination for each training example, the framework significantly\nenhances model generalization and performance. Additionally, Kastor employs an\niterative learning process to refine noisy knowledge bases, enabling the\ncreation of robust models capable of uncovering new, relevant facts", "AI": {"tldr": "Kastor是一个框架，通过重构SHACL形状验证为属性组合评估和采用迭代学习，显著增强了RDF模式提取在微调小型语言模型（SLMs）和完善专业领域知识库方面的泛化性和性能。", "motivation": "现有的RDF模式提取方法通过专注于特定SHACL形状来微调小型语言模型，虽然有效，但在满足专业领域知识库补全和精炼的需求方面仍有提升空间，尤其是在处理有限文本和RDF数据时。", "method": "本文引入了Kastor框架。它将传统的SHACL形状验证任务重构为评估形状派生的所有可能属性组合。通过为每个训练示例选择最优组合，该框架旨在显著增强模型泛化和性能。此外，Kastor采用迭代学习过程来精炼噪声知识库。", "result": "Kastor框架显著增强了模型的泛化性和性能。它能够创建强大的模型，这些模型能够发现新的、相关的知识，并有效地满足专业领域知识库的补全和精炼需求。", "conclusion": "Kastor通过其创新的属性组合评估和迭代学习方法，显著提升了RDF模式提取在微调小型语言模型和精炼专业知识库方面的效率和效果，使其能够处理噪声数据并发现新知识。"}}
{"id": "2511.03718", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03718", "abs": "https://arxiv.org/abs/2511.03718", "authors": ["Nan Li", "Albert Gatt", "Massimo Poesio"], "title": "Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask", "comment": "11 pages, 3 figures, 5 tables; under review", "summary": "Collaborative dialogue relies on participants incrementally establishing\ncommon ground, yet in asymmetric settings they may believe they agree while\nreferring to different entities. We introduce a perspectivist annotation scheme\nfor the HCRC MapTask corpus (Anderson et al., 1991) that separately captures\nspeaker and addressee grounded interpretations for each reference expression,\nenabling us to trace how understanding emerges, diverges, and repairs over\ntime. Using a scheme-constrained LLM annotation pipeline, we obtain 13k\nannotated reference expressions with reliability estimates and analyze the\nresulting understanding states. The results show that full misunderstandings\nare rare once lexical variants are unified, but multiplicity discrepancies\nsystematically induce divergences, revealing how apparent grounding can mask\nreferential misalignment. Our framework provides both a resource and an\nanalytic lens for studying grounded misunderstanding and for evaluating\n(V)LLMs' capacity to model perspective-dependent grounding in collaborative\ndialogue.", "AI": {"tldr": "本研究引入了一种透视主义标注方案，用于追踪HCRC MapTask语料库中对话参与者对指代表达的理解如何出现、分歧和修复，并利用LLM进行大规模标注。结果显示，虽然完全误解较少，但多重性差异系统性地导致指代分歧，揭示了表面上的共识可能掩盖指代错位。", "motivation": "在不对称的协作对话中，参与者可能认为他们达成了一致，但实际上却指代了不同的实体。研究旨在探究理解是如何随着时间发展、分歧和修复的，以及如何识别和分析这种基于视角的误解。", "method": "研究为HCRC MapTask语料库设计了一种透视主义标注方案，该方案分别捕获说话者和听话者对每个指代表达的理解。然后，利用一个受方案约束的大型语言模型（LLM）标注流水线，获得了1.3万个带可靠性估计的标注指代表达，并分析了由此产生的理解状态。", "result": "结果表明，一旦词汇变体得到统一，完全的误解是罕见的。然而，多重性差异（multiplicity discrepancies）会系统性地导致理解分歧，揭示了表面上的共识（apparent grounding）可能掩盖指代错位（referential misalignment）。", "conclusion": "本研究提出的框架既提供了一个资源，也提供了一个分析视角，用于研究基于视角的误解，并可用于评估(V)LLM在协作对话中建模依赖于视角的共识建立能力。"}}
{"id": "2511.03506", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03506", "abs": "https://arxiv.org/abs/2511.03506", "authors": ["Ding Chen", "Simin Niu", "Kehang Li", "Peng Liu", "Xiangping Zheng", "Bo Tang", "Xinchi Li", "Feiyu Xiong", "Zhiyu Li"], "title": "HaluMem: Evaluating Hallucinations in Memory Systems of Agents", "comment": null, "summary": "Memory systems are key components that enable AI systems such as LLMs and AI\nagents to achieve long-term learning and sustained interaction. However, during\nmemory storage and retrieval, these systems frequently exhibit memory\nhallucinations, including fabrication, errors, conflicts, and omissions.\nExisting evaluations of memory hallucinations are primarily end-to-end question\nanswering, which makes it difficult to localize the operational stage within\nthe memory system where hallucinations arise. To address this, we introduce the\nHallucination in Memory Benchmark (HaluMem), the first operation level\nhallucination evaluation benchmark tailored to memory systems. HaluMem defines\nthree evaluation tasks (memory extraction, memory updating, and memory question\nanswering) to comprehensively reveal hallucination behaviors across different\noperational stages of interaction. To support evaluation, we construct\nuser-centric, multi-turn human-AI interaction datasets, HaluMem-Medium and\nHaluMem-Long. Both include about 15k memory points and 3.5k multi-type\nquestions. The average dialogue length per user reaches 1.5k and 2.6k turns,\nwith context lengths exceeding 1M tokens, enabling evaluation of hallucinations\nacross different context scales and task complexities. Empirical studies based\non HaluMem show that existing memory systems tend to generate and accumulate\nhallucinations during the extraction and updating stages, which subsequently\npropagate errors to the question answering stage. Future research should focus\non developing interpretable and constrained memory operation mechanisms that\nsystematically suppress hallucinations and improve memory reliability.", "AI": {"tldr": "为解决AI记忆系统幻觉问题，本文引入了HaluMem，首个针对记忆系统的操作级别幻觉评估基准，并构建了用户中心的多轮交互数据集。研究发现，现有系统在记忆提取和更新阶段容易产生并累积幻觉。", "motivation": "AI系统（如LLM和AI代理）的记忆系统在存储和检索过程中常出现幻觉（如捏造、错误、冲突、遗漏）。现有评估主要通过端到端问答，难以定位幻觉产生的具体操作阶段。", "method": "引入了HaluMem，首个针对记忆系统的操作级别幻觉评估基准。定义了三个评估任务：记忆提取、记忆更新和记忆问答。构建了用户中心的多轮人机交互数据集HaluMem-Medium和HaluMem-Long，包含约1.5万记忆点和3.5千多类型问题，对话长度和上下文长度均较大，以评估不同规模和复杂性下的幻觉。", "result": "基于HaluMem的实证研究表明，现有记忆系统倾向于在记忆提取和更新阶段生成并累积幻觉，这些错误随后会传播到问答阶段。", "conclusion": "未来的研究应致力于开发可解释和受约束的记忆操作机制，以系统性地抑制幻觉并提高记忆可靠性。"}}
{"id": "2511.03498", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03498", "abs": "https://arxiv.org/abs/2511.03498", "authors": ["Kazi Reyazul Hasan", "Mubasshira Musarrat", "A. B. M. Alim Al Islam", "Muhammad Abdullah Adnan"], "title": "BanglaSTEM: A Parallel Corpus for Technical Domain Bangla-English Translation", "comment": null, "summary": "Large language models work well for technical problem solving in English but\nperform poorly when the same questions are asked in Bangla. A simple solution\nwould be to translate Bangla questions into English first and then use these\nmodels. However, existing Bangla-English translation systems struggle with\ntechnical terms. They often mistranslate specialized vocabulary, which changes\nthe meaning of the problem and leads to wrong answers. We present BanglaSTEM, a\ndataset of 5,000 carefully selected Bangla-English sentence pairs from STEM\nfields including computer science, mathematics, physics, chemistry, and\nbiology. We generated over 12,000 translations using language models and then\nused human evaluators to select the highest quality pairs that preserve\ntechnical terminology correctly. We train a T5-based translation model on\nBanglaSTEM and test it on two tasks: generating code and solving math problems.\nOur results show significant improvements in translation accuracy for technical\ncontent, making it easier for Bangla speakers to use English-focused language\nmodels effectively. Both the BanglaSTEM dataset and the trained translation\nmodel are publicly released at https://huggingface.co/reyazul/BanglaSTEM-T5.", "AI": {"tldr": "大型语言模型在处理孟加拉语技术问题时表现不佳，因为现有翻译系统难以处理技术术语。本文介绍了BanglaSTEM数据集（包含5,000对STEM领域的孟加拉语-英语句子）和基于T5的翻译模型，显著提高了技术内容的翻译准确性，使孟加拉语使用者能更有效地利用以英语为中心的语言模型。", "motivation": "大型语言模型在英语技术问题解决方面表现良好，但在孟加拉语中表现不佳。将孟加拉语问题翻译成英语是一种解决方案，但现有孟加拉语-英语翻译系统在处理技术术语时存在困难，常常误译专业词汇，导致问题含义改变和答案错误。", "method": "我们构建了BanglaSTEM数据集，包含5,000对精心挑选的STEM（包括计算机科学、数学、物理、化学和生物学）领域的孟加拉语-英语句子。我们使用语言模型生成了超过12,000个翻译，然后通过人工评估员选择出高质量且能正确保留技术术语的句子对。随后，我们使用BanglaSTEM数据集训练了一个基于T5的翻译模型，并在代码生成和数学问题解决这两个任务上对其进行了测试。", "result": "我们的结果显示，该模型在技术内容的翻译准确性方面取得了显著改进，使得孟加拉语使用者能够更有效地利用以英语为中心的语言模型。", "conclusion": "BanglaSTEM数据集和训练出的翻译模型成功提升了技术内容的孟加拉语-英语翻译质量，从而使孟加拉语使用者能够更有效地利用以英语为中心的大型语言模型。BanglaSTEM数据集和训练好的翻译模型均已公开发布。"}}
{"id": "2511.03334", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03334", "abs": "https://arxiv.org/abs/2511.03334", "authors": ["Guozhen Zhang", "Zixiang Zhou", "Teng Hu", "Ziqiao Peng", "Youliang Zhang", "Yi Chen", "Yuan Zhou", "Qinglin Lu", "Limin Wang"], "title": "UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions", "comment": null, "summary": "Due to the lack of effective cross-modal modeling, existing open-source\naudio-video generation methods often exhibit compromised lip synchronization\nand insufficient semantic consistency. To mitigate these drawbacks, we propose\nUniAVGen, a unified framework for joint audio and video generation. UniAVGen is\nanchored in a dual-branch joint synthesis architecture, incorporating two\nparallel Diffusion Transformers (DiTs) to build a cohesive cross-modal latent\nspace. At its heart lies an Asymmetric Cross-Modal Interaction mechanism, which\nenables bidirectional, temporally aligned cross-attention, thus ensuring\nprecise spatiotemporal synchronization and semantic consistency. Furthermore,\nthis cross-modal interaction is augmented by a Face-Aware Modulation module,\nwhich dynamically prioritizes salient regions in the interaction process. To\nenhance generative fidelity during inference, we additionally introduce\nModality-Aware Classifier-Free Guidance, a novel strategy that explicitly\namplifies cross-modal correlation signals. Notably, UniAVGen's robust joint\nsynthesis design enables seamless unification of pivotal audio-video tasks\nwithin a single model, such as joint audio-video generation and continuation,\nvideo-to-audio dubbing, and audio-driven video synthesis. Comprehensive\nexperiments validate that, with far fewer training samples (1.3M vs. 30.1M),\nUniAVGen delivers overall advantages in audio-video synchronization, timbre\nconsistency, and emotion consistency.", "AI": {"tldr": "UniAVGen是一个统一的音视频联合生成框架，通过双分支Diffusion Transformer架构、非对称跨模态交互和面部感知调制，显著提升了唇形同步和语义一致性，并能以更少数据处理多种音视频任务。", "motivation": "现有开源音视频生成方法缺乏有效的跨模态建模，导致唇形同步不佳和语义一致性不足。", "method": "本文提出了UniAVGen，一个用于音视频联合生成的统一框架。它基于双分支联合合成架构，包含两个并行的Diffusion Transformers (DiTs) 来构建一致的跨模态潜在空间。核心机制是非对称跨模态交互，实现双向、时间对齐的交叉注意力。此外，引入了面部感知调制模块来动态优先处理显著区域。在推理阶段，还引入了模态感知无分类器指导，以显式增强跨模态相关性信号。", "result": "UniAVGen的联合合成设计能够无缝统一关键的音视频任务，如音视频联合生成与续写、视频转音频配音和音频驱动视频合成。尽管训练样本少得多（1.3M 对比 30.1M），UniAVGen在音视频同步、音色一致性和情感一致性方面均表现出整体优势。", "conclusion": "UniAVGen通过其创新的统一框架和跨模态交互机制，有效解决了现有音视频生成方法在唇形同步和语义一致性方面的不足，并在多种任务上展现出卓越的性能和数据效率。"}}
{"id": "2511.03508", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03508", "abs": "https://arxiv.org/abs/2511.03508", "authors": ["Qi Jia", "Kaiwei Zhang", "Xiujie Song", "Ye Shen", "Xiangyang Zhu", "Guangtao Zhai"], "title": "One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework", "comment": null, "summary": "Understanding how well large language models can follow users' instructions\nthroughout a dialogue spanning multiple topics is of great importance for\ndata-intensive conversational applications. Existing benchmarks are often\nlimited to a fixed number of turns, making them susceptible to saturation and\nfailing to account for the user's interactive experience. In this work, we\npropose an extensible framework for assessing multi-turn instruction-following\nability. At its core, our framework decouples linguistic surface forms from\nuser intent simulation through a three-layer mechanism that tracks constraints,\ninstructions, and topics. This framework mimics User-LLM interaction by\nenabling the dynamic construction of benchmarks with state changes and\ntracebacks, terminating a conversation only when the model exhausts a simulated\nuser's patience. We define a suite of metrics capturing the quality of the\ninteraction process. Using this framework, we construct EvolIF, an evolving\ninstruction-following benchmark incorporating nine distinct constraint types.\nOur results indicate that GPT-5 exhibits superior instruction-following\nperformance. It sustains an average of 18.54 conversational turns and\ndemonstrates 70.31% robustness, outperforming Gemini-2.5-Pro by a significant\nmargin of 11.41%, while other models lag far behind. All of the data and code\nwill be made publicly available online.", "AI": {"tldr": "本研究提出了一种可扩展的框架和基准测试（EvolIF），用于评估大型语言模型（LLMs）在多轮对话中遵循指令的能力，结果显示GPT-5表现出卓越的性能。", "motivation": "现有基准测试通常局限于固定轮次，容易饱和，并且未能充分反映用户在多主题对话中与LLM交互的真实体验，无法有效评估LLMs在多轮指令遵循方面的能力。", "method": "本研究提出了一个可扩展的框架，用于评估多轮指令遵循能力。该框架通过三层机制（跟踪约束、指令和主题）将语言表层形式与用户意图模拟解耦，并通过状态变化和回溯动态构建基准，模拟用户-LLM交互，直到模型耗尽模拟用户的耐心才终止对话。研究还定义了一套捕捉交互过程质量的指标，并基于此框架构建了包含九种不同约束类型的EvolIF基准。", "result": "GPT-5表现出卓越的指令遵循性能，平均能维持18.54个对话轮次，并展现出70.31%的鲁棒性。它以11.41%的显著优势超越了Gemini-2.5-Pro，而其他模型则远远落后。", "conclusion": "所提出的框架和EvolIF基准有效地评估了LLMs在多轮对话中遵循指令的能力，并明确指出GPT-5在这方面表现出显著的优越性。"}}
{"id": "2511.03416", "categories": ["cs.CV", "I.4"], "pdf": "https://arxiv.org/pdf/2511.03416", "abs": "https://arxiv.org/abs/2511.03416", "authors": ["Nikolai Herrmann", "Marcella C. Zijta", "Stefan Klein", "Régine P. M. Steegers-Theunissen", "Rene M. H. Wijnen", "Bernadette S. de Bakker", "Melek Rousian", "Wietske A. P. Bastiaansen"], "title": "Robust Alignment of the Human Embryo in 3D Ultrasound using PCA and an Ensemble of Heuristic, Atlas-based and Learning-based Classifiers Evaluated on the Rotterdam Periconceptional Cohort", "comment": "Submitted version of paper accepted at International Workshop on\n  Preterm, Perinatal and Paediatric Image Analysis 2025", "summary": "Standardized alignment of the embryo in three-dimensional (3D) ultrasound\nimages aids prenatal growth monitoring by facilitating standard plane\ndetection, improving visualization of landmarks and accentuating differences\nbetween different scans. In this work, we propose an automated method for\nstandardizing this alignment. Given a segmentation mask of the embryo,\nPrincipal Component Analysis (PCA) is applied to the mask extracting the\nembryo's principal axes, from which four candidate orientations are derived.\nThe candidate in standard orientation is selected using one of three\nstrategies: a heuristic based on Pearson's correlation assessing shape, image\nmatching to an atlas through normalized cross-correlation, and a Random Forest\nclassifier. We tested our method on 2166 images longitudinally acquired 3D\nultrasound scans from 1043 pregnancies from the Rotterdam Periconceptional\nCohort, ranging from 7+0 to 12+6 weeks of gestational age. In 99.0% of images,\nPCA correctly extracted the principal axes of the embryo. The correct candidate\nwas selected by the Pearson Heuristic, Atlas-based and Random Forest in 97.4%,\n95.8%, and 98.4% of images, respectively. A Majority Vote of these selection\nmethods resulted in an accuracy of 98.5%. The high accuracy of this pipeline\nenables consistent embryonic alignment in the first trimester, enabling\nscalable analysis in both clinical and research settings. The code is publicly\navailable at:\nhttps://gitlab.com/radiology/prenatal-image-analysis/pca-3d-alignment.", "AI": {"tldr": "本文提出了一种自动化的三维超声胚胎标准化对齐方法，通过主成分分析（PCA）提取主轴并结合多种策略选择标准方向，实现了第一孕期胚胎的高精度对齐。", "motivation": "在三维超声图像中标准化胚胎对齐有助于产前生长监测，因为它能促进标准平面的检测、改善地标可视化并突出不同扫描之间的差异。", "method": "该方法首先对胚胎的分割掩膜应用主成分分析（PCA），提取胚胎的主轴，从而得到四个候选方向。然后，通过三种策略之一选择标准方向的候选：基于皮尔逊相关系数评估形状的启发式方法、通过归一化互相关将图像与图谱匹配，以及使用随机森林分类器。该方法在来自1043次怀孕的2166张纵向采集的三维超声图像上进行了测试。", "result": "在99.0%的图像中，PCA正确提取了胚胎的主轴。皮尔逊启发式、基于图谱和随机森林方法分别在97.4%、95.8%和98.4%的图像中正确选择了候选方向。这些选择方法进行多数投票后，准确率达到98.5%。", "conclusion": "该流水线的高准确性使得在第一孕期能够实现一致的胚胎对齐，从而支持在临床和研究环境中进行可扩展的分析。"}}
{"id": "2511.03563", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03563", "abs": "https://arxiv.org/abs/2511.03563", "authors": ["One Octadion", "Bondan Sapta Prakoso", "Nanang Yudi Setiawan", "Novanto Yudistira"], "title": "ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for Enhanced Legal Regulation", "comment": "11 pages (including references), 2 figures, 4 tables, published in\n  Atlantis Press (Open Access under CC BY-NC 4.0 license)", "summary": "In this study, we explore the fine-tuning of Large Language Models (LLMs) to\nbetter support policymakers in their crucial work of understanding, analyzing,\nand crafting legal regulations. To equip the model with a deep understanding of\nlegal texts, we curated a supervised dataset tailored to the specific needs of\nthe legal domain. Additionally, we integrated the Retrieval-Augmented\nGeneration (RAG) method, enabling the LLM to access and incorporate up-to-date\nlegal knowledge from external sources. This combination of fine-tuning and\nRAG-based augmentation results in a tool that not only processes legal\ninformation but actively assists policymakers in interpreting regulations and\ndrafting new ones that align with current needs. The results demonstrate that\nthis approach can significantly enhance the effectiveness of legal research and\nregulation development, offering a valuable resource in the ever-evolving field\nof law.", "AI": {"tldr": "本研究通过微调大型语言模型（LLM）并结合检索增强生成（RAG）方法，旨在提升政策制定者在法律理解、分析和法规起草方面的能力。", "motivation": "支持政策制定者更好地理解、分析和起草法律法规，解决他们在关键工作中面临的挑战。", "method": "1. 构建了一个针对法律领域的监督数据集，用于微调LLM，使其深入理解法律文本。2. 整合了检索增强生成（RAG）方法，使LLM能够访问并结合外部最新的法律知识。", "result": "该方法显著提高了法律研究和法规制定的效率，能积极协助政策制定者解释法规并起草符合当前需求的新法规。", "conclusion": "结合微调和RAG的方法为政策制定者提供了一个有价值的工具，可以有效增强法律研究和法规制定的效果，在不断发展的法律领域中具有重要意义。"}}
{"id": "2511.03459", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03459", "abs": "https://arxiv.org/abs/2511.03459", "authors": ["Kevin Manogue", "Tomasz M Schang", "Dilara Kuş", "Jonas Müller", "Stefan Zachow", "Agniva Sengupta"], "title": "Generalizing Shape-from-Template to Topological Changes", "comment": "Accepted for publication at Smart Tools and Applications in Graphics\n  (STAG), Genoa, Italy (2025)", "summary": "Reconstructing the surfaces of deformable objects from correspondences\nbetween a 3D template and a 2D image is well studied under Shape-from-Template\n(SfT) methods; however, existing approaches break down when topological changes\naccompany the deformation. We propose a principled extension of SfT that\nenables reconstruction in the presence of such changes. Our approach is\ninitialized with a classical SfT solution and iteratively adapts the template\nby partitioning its spatial domain so as to minimize an energy functional that\njointly encodes physical plausibility and reprojection consistency. We\ndemonstrate that the method robustly captures a wide range of practically\nrelevant topological events including tears and cuts on bounded 2D surfaces,\nthereby establishing the first general framework for topological-change-aware\nSfT. Experiments on both synthetic and real data confirm that our approach\nconsistently outperforms baseline methods.", "AI": {"tldr": "本文提出了一种拓扑变化感知的Shape-from-Template (SfT) 扩展方法，用于从2D图像和3D模板对应关系重建可变形物体表面，解决了现有SfT方法无法处理拓扑变化的问题。", "motivation": "现有的Shape-from-Template (SfT) 方法在变形伴随拓扑变化时会失效，无法进行表面重建。", "method": "该方法在经典SfT解决方案的基础上进行初始化，并通过划分模板的空间域来迭代调整模板。它通过最小化一个结合了物理合理性和重投影一致性的能量函数来实现这一目标。", "result": "该方法能够鲁棒地捕捉各种实际相关的拓扑事件，包括有界2D表面上的撕裂和切割，从而建立了第一个通用的拓扑变化感知SfT框架。在合成数据和真实数据上的实验都证实，该方法始终优于基线方法。", "conclusion": "该研究建立了首个通用的拓扑变化感知SfT框架，能够有效处理可变形物体在重建过程中出现的拓扑变化，并表现出优越的性能。"}}
{"id": "2511.03547", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03547", "abs": "https://arxiv.org/abs/2511.03547", "authors": ["Brian DuSell", "Ryan Cotterell"], "title": "Bearing Syntactic Fruit with Stack-Augmented Neural Networks", "comment": "15 pages, 5 figures", "summary": "Any finite set of training data is consistent with an infinite number of\nhypothetical algorithms that could have generated it. Studies have shown that\nwhen human children learn language, they consistently favor hypotheses based on\nhierarchical syntactic rules without ever encountering disambiguating examples.\nA recent line of work has inquired as to whether common neural network\narchitectures share this bias, finding that they do so only under special\nconditions: when syntactically supervised, when pre-trained on massive corpora,\nor when trained long past convergence. In this paper, we demonstrate, for the\nfirst time, neural network architectures that are able to generalize in\nhuman-like fashion without any of the aforementioned requirements:\nstack-augmented neural networks. We test three base architectures (transformer,\nsimple RNN, LSTM) augmented with two styles of stack: the superposition stack\nof Joulin & Mikolov (2015) and a nondeterministic generalization of it proposed\nby DuSell & Chiang (2023). We find that transformers with nondeterministic\nstacks generalize best out of these architectures on a classical question\nformation task. We also propose a modification to the stack RNN architecture\nthat improves hierarchical generalization. These results suggest that\nstack-augmented neural networks may be more accurate models of human language\nacquisition than standard architectures, serving as useful objects of\npsycholinguistic study. Our code is publicly available.", "AI": {"tldr": "本文首次提出并证明了堆栈增强神经网络能够在无需特殊条件的情况下，以类似人类的方式进行层次化泛化，特别是在问句生成任务上，带有非确定性堆栈的Transformer表现最佳。", "motivation": "人类儿童在语言学习中倾向于基于层次句法规则的假设，而标准神经网络仅在特定条件下（如句法监督、大规模预训练或长时间训练）才表现出这种偏好。研究旨在探索无需这些特殊条件就能实现类人层次泛化的神经网络架构。", "method": "研究测试了堆栈增强神经网络。基准架构包括Transformer、Simple RNN和LSTM，并结合了两种堆栈类型：Joulin & Mikolov（2015）的叠加堆栈和DuSell & Chiang（2023）提出的非确定性泛化堆栈。实验在经典的问句生成任务上进行。此外，还提出并改进了堆栈RNN架构以增强层次泛化能力。", "result": "研究发现，在问句生成任务中，带有非确定性堆栈的Transformer架构泛化能力最佳。同时，对堆栈RNN架构的修改也显著改善了其层次泛化能力。这些堆栈增强神经网络在没有句法监督、大规模语料预训练或超长训练的情况下，实现了类似人类的泛化表现。", "conclusion": "堆栈增强神经网络可能比标准架构更能准确地模拟人类语言习得过程，并可作为心理语言学研究的有用工具。"}}
{"id": "2511.03610", "categories": ["cs.CL", "A.1; I.2.4; I.2.7"], "pdf": "https://arxiv.org/pdf/2511.03610", "abs": "https://arxiv.org/abs/2511.03610", "authors": ["Ringwald Celian", "Gandon", "Fabien", "Faron Catherine", "Michel Franck", "Abi Akl Hanna"], "title": "A systematic review of relation extraction task since the emergence of Transformers", "comment": "Submited at ACM-Computing Surveys + The resulting annotated Zotero\n  bibliography :\n  https://www.zotero.org/groups/6070963/scilex_re_systlitreview/library +\n  SciLEx software: https://github.com/Wimmics/SciLEx", "summary": "This article presents a systematic review of relation extraction (RE)\nresearch since the advent of Transformer-based models. Using an automated\nframework to collect and annotate publications, we analyze 34 surveys, 64\ndatasets, and 104 models published between 2019 and 2024. The review highlights\nmethodological advances, benchmark resources, and the integration of semantic\nweb technologies. By consolidating results across multiple dimensions, the\nstudy identifies current trends, limitations, and open challenges, offering\nresearchers and practitioners a comprehensive reference for understanding the\nevolution and future directions of RE.", "AI": {"tldr": "本文对自Transformer模型出现以来（2019-2024年）的关系抽取（RE）研究进行了系统性回顾，分析了方法进展、基准资源和语义网技术集成，并指出了当前趋势、局限性和挑战。", "motivation": "旨在为研究人员和从业者提供一个全面参考，以理解关系抽取（RE）的演变和未来方向，特别是自Transformer模型问世以来的发展。", "method": "采用自动化框架收集和标注出版物，对2019年至2024年间发表的34篇综述、64个数据集和104个模型进行了系统性分析。", "result": "研究结果突出了方法论的进步、基准资源以及语义网技术的整合。通过整合多维度结果，识别了当前趋势、局限性和开放挑战。", "conclusion": "该研究为研究人员和从业者提供了一个理解关系抽取演变和未来方向的全面参考，总结了Transformer时代RE研究的进展、挑战与趋势。"}}
{"id": "2511.03589", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03589", "abs": "https://arxiv.org/abs/2511.03589", "authors": ["Romain Brégier", "Guénolé Fiche", "Laura Bravo-Sánchez", "Thomas Lucas", "Matthieu Armando", "Philippe Weinzaepfel", "Grégory Rogez", "Fabien Baradel"], "title": "Human Mesh Modeling for Anny Body", "comment": "We release our model and code at https://github.com/naver/anny", "summary": "Parametric body models are central to many human-centric tasks, yet existing\nmodels often rely on costly 3D scans and learned shape spaces that are\nproprietary and demographically narrow. We introduce Anny, a simple, fully\ndifferentiable, and scan-free human body model grounded in anthropometric\nknowledge from the MakeHuman community. Anny defines a continuous,\ninterpretable shape space, where phenotype parameters (e.g. gender, age,\nheight, weight) control blendshapes spanning a wide range of human forms --\nacross ages (from infants to elders), body types, and proportions. Calibrated\nusing WHO population statistics, it provides realistic and demographically\ngrounded human shape variation within a single unified model. Thanks to its\nopenness and semantic control, Anny serves as a versatile foundation for 3D\nhuman modeling -- supporting millimeter-accurate scan fitting, controlled\nsynthetic data generation, and Human Mesh Recovery (HMR). We further introduce\nAnny-One, a collection of 800k photorealistic humans generated with Anny,\nshowing that despite its simplicity, HMR models trained with Anny can match the\nperformance of those trained with scan-based body models, while remaining\ninterpretable and broadly representative. The Anny body model and its code are\nreleased under the Apache 2.0 license, making Anny an accessible foundation for\nhuman-centric 3D modeling.", "AI": {"tldr": "Anny是一个简单、完全可微分、无需扫描的人体模型，基于人体测量学知识，提供了一个连续、可解释且具有人口统计学基础的形状空间。它支持精确的扫描拟合、受控合成数据生成和人体网格恢复（HMR），并且其生成的Anny-One数据集训练的HMR模型性能可与基于扫描的模型媲美。", "motivation": "现有的参数化人体模型依赖于昂贵的3D扫描，并且其学习的形状空间通常是专有的、人口统计学上狭窄的。", "method": "Anny是一个简单、完全可微分、无需扫描的人体模型，其基础是来自MakeHuman社区的人体测量学知识。它通过表型参数（如性别、年龄、身高、体重）控制混合形状，定义了一个连续、可解释的形状空间，涵盖了从婴儿到老人的广泛人体形态。该模型使用WHO人口统计数据进行校准，以提供真实且具有人口统计学基础的人体形状变异。", "result": "Anny在一个统一模型中提供了真实且具有人口统计学基础的人体形状变异，涵盖了不同年龄、体型和比例。它能支持毫米级精度的扫描拟合、受控的合成数据生成和人体网格恢复（HMR）。通过Anny生成的80万个逼真人体的Anny-One数据集显示，尽管Anny模型简单，但用其训练的HMR模型性能可以与基于扫描的人体模型相媲美，同时保持可解释性和广泛的代表性。", "conclusion": "Anny凭借其开放性、语义控制和竞争性表现，为以人为中心的3D建模提供了一个可访问且多功能的基础。Anny人体模型及其代码已根据Apache 2.0许可证发布。"}}
{"id": "2511.03645", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03645", "abs": "https://arxiv.org/abs/2511.03645", "authors": ["Vittal L. Rao"], "title": "Signal Intensity-weighted coordinate channels improve learning stability and generalisation in 1D and 2D CNNs in localisation tasks on biomedical signals", "comment": null, "summary": "Localisation tasks in biomedical data often require models to learn\nmeaningful spatial or temporal relationships from signals with complex\nintensity distributions. A common strategy, exemplified by CoordConv layers, is\nto append coordinate channels to convolutional inputs, enabling networks to\nlearn absolute positions. In this work, we propose a signal intensity-weighted\ncoordinate representation that replaces the pure coordinate channels with\nchannels scaled by local signal intensity. This modification embeds an\nintensity-position coupling directly in the input representation, introducing a\nsimple and modality-agnostic inductive bias. We evaluate the approach on two\ndistinct localisation problems: (i) predicting the time of morphological\ntransition in 20-second, two-lead ECG signals, and (ii) regressing the\ncoordinates of nuclear centres in cytological images from the SiPaKMeD dataset.\nIn both cases, the proposed representation yields faster convergence and higher\ngeneralisation performance relative to conventional coordinate-channel\napproaches, demonstrating its effectiveness across both one-dimensional and\ntwo-dimensional biomedical signals.", "AI": {"tldr": "本文提出了一种信号强度加权坐标表示方法，用于生物医学数据中的定位任务，通过将局部信号强度与坐标通道结合，实现了比传统坐标通道方法更快的收敛速度和更高的泛化性能。", "motivation": "生物医学数据中的定位任务需要模型从复杂强度分布的信号中学习有意义的空间或时间关系。现有方法如CoordConv通过添加纯坐标通道来学习绝对位置，但作者认为可以更直接地将强度-位置耦合嵌入输入表示中，以引入一种简单且与模态无关的归纳偏置。", "method": "提出了一种信号强度加权坐标表示方法，用局部信号强度缩放的通道替换了纯坐标通道。这种修改将强度-位置耦合直接嵌入到输入表示中。该方法在两个不同的定位问题上进行了评估：(i) 预测20秒双导联心电图信号的形态学转变时间，以及 (ii) 回归SiPaKMeD数据集中细胞学图像中细胞核中心的坐标。", "result": "在心电图信号和细胞学图像的定位任务中，所提出的表示方法相对于传统的坐标通道方法，均实现了更快的收敛速度和更高的泛化性能，证明了其在一维和二维生物医学信号中的有效性。", "conclusion": "信号强度加权坐标表示方法通过直接嵌入强度-位置耦合，为生物医学定位任务提供了一种有效且通用的归纳偏置，显著提高了模型在收敛速度和泛化能力方面的表现。"}}
{"id": "2511.03635", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03635", "abs": "https://arxiv.org/abs/2511.03635", "authors": ["Apoorva Upadhyaya", "Wolfgang Nejdl", "Marco Fisichella"], "title": "Towards Transparent Stance Detection: A Zero-Shot Approach Using Implicit and Explicit Interpretability", "comment": "Accepted in AAAI CONFERENCE ON WEB AND SOCIAL MEDIA (ICWSM 2026)", "summary": "Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post toward\nunseen targets. Existing research using contrastive, meta-learning, or data\naugmentation suffers from generalizability issues or lack of coherence between\ntext and target. Recent works leveraging large language models (LLMs) for ZSSD\nfocus either on improving unseen target-specific knowledge or generating\nexplanations for stance analysis. However, most of these works are limited by\ntheir over-reliance on explicit reasoning, provide coarse explanations that\nlack nuance, and do not explicitly model the reasoning process, making it\ndifficult to interpret the model's predictions. To address these issues, in our\nstudy, we develop a novel interpretable ZSSD framework, IRIS. We provide an\ninterpretable understanding of the attitude of the input towards the target\nimplicitly based on sequences within the text (implicit rationales) and\nexplicitly based on linguistic measures (explicit rationales). IRIS considers\nstance detection as an information retrieval ranking task, understanding the\nrelevance of implicit rationales for different stances to guide the model\ntowards correct predictions without requiring the ground-truth of rationales,\nthus providing inherent interpretability. In addition, explicit rationales\nbased on communicative features help decode the emotional and cognitive\ndimensions of stance, offering an interpretable understanding of the author's\nattitude towards the given target. Extensive experiments on the benchmark\ndatasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10%\ntraining data prove the generalizability of our model, benefiting from the\nproposed architecture and interpretable design.", "AI": {"tldr": "本文提出了一种名为IRIS的新型可解释零样本立场检测（ZSSD）框架，通过结合文本中的隐式理由和基于语言测量的显式理由，提供了对模型预测的内在可解释性，并解决了现有方法的泛化性和可解释性问题。", "motivation": "现有零样本立场检测（ZSSD）方法存在泛化性差、文本与目标之间缺乏连贯性、过度依赖显式推理、解释粗糙且缺乏细微差别，以及未能明确建模推理过程等问题，导致模型预测难以解释。", "method": "IRIS将立场检测视为信息检索排名任务。它通过理解文本序列中隐式理由与不同立场的关联性来指导模型预测，无需理由的真实标签，从而提供内在可解释性。此外，它利用基于交际特征的显式理由来解码立场的情感和认知维度，以提供作者态度的可解释性理解。", "result": "在VAST、EZ-STANCE、P-Stance和RFD等基准数据集上，使用50%、30%甚至10%的训练数据进行的广泛实验证明了IRIS模型具有出色的泛化能力，这得益于其提出的架构和可解释性设计。", "conclusion": "IRIS框架通过结合隐式和显式理由，提供了一种新颖且可解释的零样本立场检测方法。它不仅解决了现有方法的局限性，还在有限训练数据下展现了强大的泛化能力，为理解作者对目标态度的细微之处提供了可解释的洞察。"}}
{"id": "2511.03665", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03665", "abs": "https://arxiv.org/abs/2511.03665", "authors": ["Mehdi Sefidgar Dilmaghani", "Francis Fowley", "Peter Corcoran"], "title": "A Lightweight 3D-CNN for Event-Based Human Action Recognition with Privacy-Preserving Potential", "comment": null, "summary": "This paper presents a lightweight three-dimensional convolutional neural\nnetwork (3DCNN) for human activity recognition (HAR) using event-based vision\ndata. Privacy preservation is a key challenge in human monitoring systems, as\nconventional frame-based cameras capture identifiable personal information. In\ncontrast, event cameras record only changes in pixel intensity, providing an\ninherently privacy-preserving sensing modality. The proposed network\neffectively models both spatial and temporal dynamics while maintaining a\ncompact design suitable for edge deployment. To address class imbalance and\nenhance generalization, focal loss with class reweighting and targeted data\naugmentation strategies are employed. The model is trained and evaluated on a\ncomposite dataset derived from the Toyota Smart Home and ETRI datasets.\nExperimental results demonstrate an F1-score of 0.9415 and an overall accuracy\nof 94.17%, outperforming benchmark 3D-CNN architectures such as C3D, ResNet3D,\nand MC3_18 by up to 3%. These results highlight the potential of event-based\ndeep learning for developing accurate, efficient, and privacy-aware human\naction recognition systems suitable for real-world edge applications.", "AI": {"tldr": "本文提出了一种轻量级三维卷积神经网络（3DCNN），用于基于事件视觉数据的人体活动识别（HAR），在保持隐私的同时实现了高准确性和边缘部署的紧凑设计。", "motivation": "传统基于帧的摄像头在人体监控系统中存在隐私泄露问题，因为它们捕获可识别的个人信息。事件相机仅记录像素强度变化，提供了一种固有的隐私保护传感模式，因此研究者希望利用事件相机数据解决HAR中的隐私挑战。", "method": "研究采用了一种轻量级三维卷积神经网络（3DCNN），能够有效建模空间和时间动态。为了解决类别不平衡和增强泛化能力，采用了带有类别加权的Focal Loss和目标数据增强策略。模型在一个结合了Toyota Smart Home和ETRI数据集的复合数据集上进行训练和评估。", "result": "实验结果显示，该模型在人体活动识别任务上达到了0.9415的F1分数和94.17%的整体准确率。与C3D、ResNet3D和MC3_18等基准3D-CNN架构相比，性能提升高达3%。", "conclusion": "研究结果突出了基于事件的深度学习在开发准确、高效且隐私感知的人体动作识别系统方面的潜力，这些系统适用于实际的边缘应用。"}}
{"id": "2511.03699", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.03699", "abs": "https://arxiv.org/abs/2511.03699", "authors": ["Francesco Corso", "Francesco Pierri", "Gianmarco De Francisci Morales"], "title": "Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models", "comment": null, "summary": "In this paper, we investigate whether Large Language Models (LLMs) exhibit\nconspiratorial tendencies, whether they display sociodemographic biases in this\ndomain, and how easily they can be conditioned into adopting conspiratorial\nperspectives. Conspiracy beliefs play a central role in the spread of\nmisinformation and in shaping distrust toward institutions, making them a\ncritical testbed for evaluating the social fidelity of LLMs. LLMs are\nincreasingly used as proxies for studying human behavior, yet little is known\nabout whether they reproduce higher-order psychological constructs such as a\nconspiratorial mindset. To bridge this research gap, we administer validated\npsychometric surveys measuring conspiracy mindset to multiple models under\ndifferent prompting and conditioning strategies. Our findings reveal that LLMs\nshow partial agreement with elements of conspiracy belief, and conditioning\nwith socio-demographic attributes produces uneven effects, exposing latent\ndemographic biases. Moreover, targeted prompts can easily shift model responses\ntoward conspiratorial directions, underscoring both the susceptibility of LLMs\nto manipulation and the potential risks of their deployment in sensitive\ncontexts. These results highlight the importance of critically evaluating the\npsychological dimensions embedded in LLMs, both to advance computational social\nscience and to inform possible mitigation strategies against harmful uses.", "AI": {"tldr": "本文研究了大型语言模型（LLMs）是否具有阴谋论倾向、是否存在社会人口学偏见，以及其采纳阴谋论观点的易感性，发现LLMs表现出部分阴谋论信念，存在潜在的偏见，且易受操纵。", "motivation": "阴谋论信念在错误信息传播和机构不信任形成中扮演核心角色，是评估LLMs社会忠实度的关键。LLMs被越来越多地用作研究人类行为的替代品，但其是否能再现更高阶的心理结构（如阴谋论思维）尚不清楚。", "method": "研究通过在不同提示和条件策略下，对多个LLMs进行了经过验证的测量阴谋论思维的心理测量调查。", "result": "研究发现LLMs与阴谋论信念的某些元素表现出部分一致性；社会人口学属性的条件作用产生了不均衡的效果，揭示了潜在的人口学偏见；有针对性的提示可以轻易地将模型响应转向阴谋论方向，突显了LLMs易受操纵的特性及其在敏感场景部署的潜在风险。", "conclusion": "这些结果强调了批判性评估LLMs中嵌入的心理维度至关重要，这不仅能推动计算社会科学发展，也能为应对有害用途提供可能的缓解策略。"}}
{"id": "2511.03666", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03666", "abs": "https://arxiv.org/abs/2511.03666", "authors": ["Dongkeun Kim", "Minsu Cho", "Suha Kwak"], "title": "Part-Aware Bottom-Up Group Reasoning for Fine-Grained Social Interaction Detection", "comment": "Accepted to NeurIPS 2025", "summary": "Social interactions often emerge from subtle, fine-grained cues such as\nfacial expressions, gaze, and gestures. However, existing methods for social\ninteraction detection overlook such nuanced cues and primarily rely on holistic\nrepresentations of individuals. Moreover, they directly detect social groups\nwithout explicitly modeling the underlying interactions between individuals.\nThese drawbacks limit their ability to capture localized social signals and\nintroduce ambiguity when group configurations should be inferred from social\ninteractions grounded in nuanced cues. In this work, we propose a part-aware\nbottom-up group reasoning framework for fine-grained social interaction\ndetection. The proposed method infers social groups and their interactions\nusing body part features and their interpersonal relations. Our model first\ndetects individuals and enhances their features using part-aware cues, and then\ninfers group configuration by associating individuals via similarity-based\nreasoning, which considers not only spatial relations but also subtle social\ncues that signal interactions, leading to more accurate group inference.\nExperiments on the NVI dataset demonstrate that our method outperforms prior\nmethods, achieving the new state of the art.", "AI": {"tldr": "本文提出了一种基于部件感知的自下而上群体推理框架，用于细粒度社交互动检测。该方法利用身体部件特征和人际关系来推断社交群体及其互动，表现优于现有方法。", "motivation": "现有社交互动检测方法忽略了面部表情、凝视、手势等细微线索，主要依赖个体的整体表征，并且直接检测社交群体而非明确建模个体间的互动。这限制了它们捕捉局部社交信号的能力，并在从细微线索推断群体配置时引入模糊性。", "method": "本文提出了一种“部件感知自下而上群体推理框架”。该模型首先检测个体并利用部件感知线索增强其特征，然后通过基于相似性的推理（考虑空间关系和指示互动的细微社交线索）关联个体，从而推断群体配置。", "result": "在NVI数据集上的实验表明，本文方法优于现有方法，达到了新的技术水平。", "conclusion": "通过利用身体部件特征和人际关系，本文提出的方法能够有效捕捉细粒度社交互动并推断群体配置，从而提高了检测准确性。"}}
{"id": "2511.03725", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.03725", "abs": "https://arxiv.org/abs/2511.03725", "authors": ["Jongseo Lee", "Wooil Lee", "Gyeong-Moon Park", "Seong Tae Kim", "Jinwoo Choi"], "title": "Disentangled Concepts Speak Louder Than Words:Explainable Video Action Recognition", "comment": "NeurIPS 2025 Spotlight paper. Project page:\n  https://jong980812.github.io/DANCE/", "summary": "Effective explanations of video action recognition models should disentangle\nhow movements unfold over time from the surrounding spatial context. However,\nexisting methods based on saliency produce entangled explanations, making it\nunclear whether predictions rely on motion or spatial context. Language-based\napproaches offer structure but often fail to explain motions due to their tacit\nnature -- intuitively understood but difficult to verbalize. To address these\nchallenges, we propose Disentangled Action aNd Context concept-based\nExplainable (DANCE) video action recognition, a framework that predicts actions\nthrough disentangled concept types: motion dynamics, objects, and scenes. We\ndefine motion dynamics concepts as human pose sequences. We employ a large\nlanguage model to automatically extract object and scene concepts. Built on an\nante-hoc concept bottleneck design, DANCE enforces prediction through these\nconcepts. Experiments on four datasets -- KTH, Penn Action, HAA500, and UCF-101\n-- demonstrate that DANCE significantly improves explanation clarity with\ncompetitive performance. We validate the superior interpretability of DANCE\nthrough a user study. Experimental results also show that DANCE is beneficial\nfor model debugging, editing, and failure analysis.", "AI": {"tldr": "DANCE是一种针对视频动作识别的框架，通过解耦运动动态、物体和场景等概念来提供更清晰、可解释的预测，解决了现有方法解释纠缠不清或难以解释运动的问题。", "motivation": "现有视频动作识别模型的解释方法（如显著性图）将运动和空间背景纠缠在一起，导致无法明确预测是基于运动还是空间背景。基于语言的方法虽然有结构，但常因其隐性本质而无法有效解释运动。", "method": "本文提出了DANCE（Disentangled Action aNd Context concept-based Explainable）框架，通过解耦的概念类型（运动动态、物体和场景）来预测动作。运动动态概念被定义为人体姿态序列，而物体和场景概念则通过大型语言模型自动提取。DANCE基于事前概念瓶颈设计，强制模型通过这些解耦的概念进行预测。", "result": "在KTH、Penn Action、HAA500和UCF-101四个数据集上的实验表明，DANCE在保持竞争性性能的同时，显著提高了解释的清晰度。用户研究也验证了DANCE卓越的可解释性。此外，实验结果还显示DANCE有助于模型调试、编辑和故障分析。", "conclusion": "DANCE框架通过提供解耦的、基于概念的解释，显著提升了视频动作识别模型的可解释性，解决了现有方法在区分运动和空间背景方面的挑战，并为模型理解和改进提供了实用价值。"}}
