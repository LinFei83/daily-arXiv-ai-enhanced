<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 20]
- [cs.CV](#cs.CV) [Total: 82]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.RO](#cs.RO) [Total: 21]
- [eess.SY](#eess.SY) [Total: 16]
- [eess.IV](#eess.IV) [Total: 12]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination](https://arxiv.org/abs/2507.13511)
*Nabil Abdelaziz Ferhat Taleb,Abdolazim Rezaei,Raj Atulkumar Patel,Mehdi Sookhak*

Main category: cs.AI

TL;DR: GraphTrafficGPT提出了一种图基架构，通过并行执行和动态资源分配，显著提升了大型语言模型（LLMs）在智能交通管理中的效率和可扩展性，解决了现有链式系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的交通管理系统（如TrafficGPT）采用链式执行，存在任务顺序执行、高token消耗和可扩展性差等问题，难以有效应对复杂的现实交通场景。

Method: 提出GraphTrafficGPT，一种图基架构，将任务及其依赖表示为有向图中的节点和边，实现并行执行和动态资源分配。核心思想是引入一个“大脑代理”（Brain Agent），负责分解用户查询、构建优化依赖图，并协调专门代理（数据检索、分析、可视化、仿真）网络。此外，还引入了上下文感知token管理和并发多查询处理。

Result: 与TrafficGPT相比，GraphTrafficGPT将token消耗降低了50.2%，平均响应延迟减少了19.0%。同时，在支持同步多查询执行方面，效率提升高达23.0%。

Conclusion: GraphTrafficGPT通过其创新的图基架构和大脑代理协调机制，有效解决了LLM驱动交通应用中链式系统的效率和可扩展性问题，为复杂的现代城市交通环境提供了更优的解决方案。

Abstract: Large Language Models (LLMs) offer significant promise for intelligent
traffic management; however, current chain-based systems like TrafficGPT are
hindered by sequential task execution, high token usage, and poor scalability,
making them inefficient for complex, real-world scenarios. To address these
limitations, we propose GraphTrafficGPT, a novel graph-based architecture,
which fundamentally redesigns the task coordination process for LLM-driven
traffic applications. GraphTrafficGPT represents tasks and their dependencies
as nodes and edges in a directed graph, enabling efficient parallel execution
and dynamic resource allocation. The main idea behind the proposed model is a
Brain Agent that decomposes user queries, constructs optimized dependency
graphs, and coordinates a network of specialized agents for data retrieval,
analysis, visualization, and simulation. By introducing advanced context-aware
token management and supporting concurrent multi-query processing, the proposed
architecture handles interdependent tasks typical of modern urban mobility
environments. Experimental results demonstrate that GraphTrafficGPT reduces
token consumption by 50.2% and average response latency by 19.0% compared to
TrafficGPT, while supporting simultaneous multi-query execution with up to
23.0% improvement in efficiency.

</details>


### [2] [PrefPalette: Personalized Preference Modeling with Latent Attributes](https://arxiv.org/abs/2507.13541)
*Shuyue Stella Li,Melanie Sclar,Hunter Lang,Ansong Ni,Jacqueline He,Puxin Xu,Andrew Cohen,Chan Young Park,Yulia Tsvetkov,Asli Celikyilmaz*

Main category: cs.AI

TL;DR: PrefPalette是一个框架，它将用户偏好分解为可解释的属性维度，并根据不同社群的价值观动态调整偏好预测，显著优于现有模型并提供透明的洞察。


<details>
  <summary>Details</summary>
Motivation: 当前的AI偏好模型将人类判断视为黑箱，无法理解偏好背后的深层原因，导致个性化不足。研究旨在突破聚合偏好模型，捕捉驱动人类判断的多元评估框架。

Method: PrefPalette框架基于多属性决策原则，包含两部分：1) 可扩展的反事实属性合成步骤，生成合成训练数据以隔离单个属性（如正式性、幽默、文化价值观）的影响；2) 基于注意力的偏好建模，学习不同社群如何动态地加权这些属性。

Result: 在Reddit的45个社群上进行评估，PrefPalette的平均预测准确率比GPT-4o高出46.6%。此外，它揭示了直观的社群特定偏好：学术社群重视冗长和刺激性，冲突导向社群看重讽刺和直接性，支持型社群强调同理心。

Conclusion: 通过建模人类判断的属性中介结构，PrefPalette不仅提供了卓越的偏好建模能力，还带来了透明、可解释的洞察，为构建更值得信赖、更具价值观意识的个性化应用迈出了第一步。

Abstract: Personalizing AI systems requires understanding not just what users prefer,
but the reasons that underlie those preferences - yet current preference models
typically treat human judgment as a black box. We introduce PrefPalette, a
framework that decomposes preferences into attribute dimensions and tailors its
preference prediction to distinct social community values in a
human-interpretable manner. PrefPalette operationalizes a cognitive science
principle known as multi-attribute decision making in two ways: (1) a scalable
counterfactual attribute synthesis step that involves generating synthetic
training data to isolate for individual attribute effects (e.g., formality,
humor, cultural values), and (2) attention-based preference modeling that
learns how different social communities dynamically weight these attributes.
This approach moves beyond aggregate preference modeling to capture the diverse
evaluation frameworks that drive human judgment. When evaluated on 45 social
communities from the online platform Reddit, PrefPalette outperforms GPT-4o by
46.6% in average prediction accuracy. Beyond raw predictive improvements,
PrefPalette also shed light on intuitive, community-specific profiles:
scholarly communities prioritize verbosity and stimulation, conflict-oriented
communities value sarcasm and directness, and support-based communities
emphasize empathy. By modeling the attribute-mediated structure of human
judgment, PrefPalette delivers both superior preference modeling and
transparent, interpretable insights, and serves as a first step toward more
trustworthy, value-aware personalized applications.

</details>


### [3] [GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models](https://arxiv.org/abs/2507.13550)
*Eduardo C. Garrido-Merchán,Cristina Puente*

Main category: cs.AI

TL;DR: 本文提出一种受控且透明地使用大型语言模型（LLMs）开发专家系统的新方法，通过将LLM生成的信息转换为Prolog符号知识，并允许人工验证，以解决LLMs幻觉问题，同时确保可解释性、可扩展性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在知识密集型任务中表现出色，但存在幻觉或自信地生成不正确、不可验证事实的缺点。研究动机在于如何利用LLMs的生成能力，同时克服其不可靠性，从而开发出可信赖的专家系统。

Method: 该方法通过限制领域和采用结构化的基于提示的提取方法，将LLM（如Claude Sonnet 3.7和GPT-4.1）生成的信息转化为Prolog中的符号表示。这种符号知识可以由人类专家进行验证和纠正，从而保证了系统的可解释性、可扩展性和可靠性。

Result: 通过定量和定性实验，研究表明所生成的知识库在事实依从性和语义连贯性方面表现出色。结果展示了一个透明的混合解决方案，成功结合了LLMs的召回能力和符号系统的精确性。

Conclusion: 该研究提出了一个结合LLMs召回能力与符号系统精确性的混合解决方案，为在敏感领域开发可靠的人工智能应用奠定了基础，解决了LLMs在专家系统应用中的可靠性问题。

Abstract: The development of large language models (LLMs) has successfully transformed
knowledge-based systems such as open domain question nswering, which can
automatically produce vast amounts of seemingly coherent information. Yet,
those models have several disadvantages like hallucinations or confident
generation of incorrect or unverifiable facts. In this paper, we introduce a
new approach to the development of expert systems using LLMs in a controlled
and transparent way. By limiting the domain and employing a well-structured
prompt-based extraction approach, we produce a symbolic representation of
knowledge in Prolog, which can be validated and corrected by human experts.
This approach also guarantees interpretability, scalability and reliability of
the developed expert systems. Via quantitative and qualitative experiments with
Claude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic
coherence on our generated knowledge bases. We present a transparent hybrid
solution that combines the recall capacity of LLMs with the precision of
symbolic systems, thereby laying the foundation for dependable AI applications
in sensitive domains.

</details>


### [4] [Why Isn't Relational Learning Taking Over the World?](https://arxiv.org/abs/2507.13558)
*David Poole*

Main category: cs.AI

TL;DR: 当前AI主要关注像素、文字等感知数据，但现实世界和企业最有价值的数据是关系型的。本文探讨了关系学习（如统计关系AI）未能普及的原因，并提出了使其获得应有地位的改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统主要建模像素、文字和音素，而世界本质上由具有属性和关系实体构成。企业最有价值的数据多以电子表格、数据库等关系格式存在，而非文本或图像。尽管关系学习研究这类数据，但其并未像其他AI领域一样普及，作者旨在探究其原因。

Method: 本文通过分析和解释的方式，阐述了关系学习未能广泛应用的原因（除少数受限关系情况），并提出了为提升其地位所需采取的措施。

Result: 研究揭示了关系学习目前未能普及的原因，并指出了为使其达到应有重要性所必需的改进和发展方向。

Conclusion: 关系学习作为一种处理实体、属性和关系数据的AI范式，尽管与现实世界和企业核心数据高度相关，但目前其应用受限。为使其发挥潜力，需要针对性地解决现有问题，使其在AI领域获得更重要的地位。

Abstract: AI seems to be taking over the world with systems that model pixels, words,
and phonemes. The world is arguably made up, not of pixels, words, and phonemes
but of entities (objects, things, including events) with properties and
relations among them. Surely we should model these, not the perception or
description of them. You might suspect that concentrating on modeling words and
pixels is because all of the (valuable) data in the world is in terms of text
and images. If you look into almost any company you will find their most
valuable data is in spreadsheets, databases and other relational formats. These
are not the form that are studied in introductory machine learning, but are
full of product numbers, student numbers, transaction numbers and other
identifiers that can't be interpreted naively as numbers. The field that
studies this sort of data has various names including relational learning,
statistical relational AI, and many others. This paper explains why relational
learning is not taking over the world -- except in a few cases with restricted
relations -- and what needs to be done to bring it to it's rightful prominence.

</details>


### [5] [BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety](https://arxiv.org/abs/2507.13625)
*Yuxin Zhang,Xi Wang,Mo Hu,Zhenyu Zhang*

Main category: cs.AI

TL;DR: BifrostRAG是一个双图RAG系统，结合图遍历和向量搜索，用于处理复杂法规文本中的多跳查询，显著优于传统RAG。


<details>
  <summary>Details</summary>
Motivation: 自动化合规性检查需要从复杂的安全法规中检索信息，但法规文本的语言和结构复杂性，以及多跳查询的需求，对传统检索增强生成（RAG）系统构成了挑战。

Method: 提出BifrostRAG，一个集成了双图的RAG系统。它通过实体网络图（Entity Network Graph）建模语言关系，通过文档导航图（Document Navigator Graph）建模文档结构。该系统采用混合检索机制，结合图遍历和基于向量的语义搜索，使大型语言模型能够同时推理文本的含义和结构。

Result: 在多跳问题数据集上进行评估，BifrostRAG实现了92.8%的精确率、85.5%的召回率和87.3%的F1分数。这些结果显著优于仅基于向量和仅基于图的RAG基线方法。

Conclusion: BifrostRAG被确立为LLM驱动的合规性检查的强大知识引擎。其双图、混合检索机制为在知识密集型工程领域处理复杂技术文档提供了可迁移的蓝图。

Abstract: Information retrieval and question answering from safety regulations are
essential for automated construction compliance checking but are hindered by
the linguistic and structural complexity of regulatory text. Many
compliance-related queries are multi-hop, requiring synthesis of information
across interlinked clauses. This poses a challenge for traditional
retrieval-augmented generation (RAG) systems. To overcome this, we introduce
BifrostRAG: a dual-graph RAG-integrated system that explicitly models both
linguistic relationships (via an Entity Network Graph) and document structure
(via a Document Navigator Graph). This architecture powers a hybrid retrieval
mechanism that combines graph traversal with vector-based semantic search,
enabling large language models to reason over both the meaning and the
structure of the text. Evaluation on a multi-hop question dataset shows that
BifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1
score of 87.3 percent. These results significantly outperform vector-only and
graph-only RAG baselines that represent current leading approaches. Error
analysis further highlights the comparative advantages of our hybrid method
over single-modality RAGs. These findings establish BifrostRAG as a robust
knowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid
retrieval mechanism offers a transferable blueprint for navigating complex
technical documents across knowledge-intensive engineering domains.

</details>


### [6] [Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks](https://arxiv.org/abs/2507.13651)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 本研究提出并验证了一种基于最终答案的自动错误诊断方法，用于解决智能辅导系统中学生合并多个步骤时诊断困难的问题，并在二次方程求解数据集中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 在智能辅导系统中，当学生将多个步骤合并为一个步骤时，连接连续输入的可能路径数量会呈组合爆炸式增长，使得错误诊断变得非常困难。传统的单规则诊断服务无法处理这种情况。

Method: 研究探索了基于最终答案的自动错误诊断潜力。具体方法是：当学生合并多个步骤时，利用最终答案来诊断错误，通过自动完成中间输入来诊断其解决方案。设计了一个服务来提供错误规则诊断，并将其应用于一个包含1939个唯一学生步骤的二次方程求解现有数据集进行验证，这些步骤是之前无法被单一规则服务诊断的。

Result: 结果显示，最终答案评估能够诊断出这些步骤中的29.4%。此外，在115个步骤的子集上，生成的诊断与教师诊断的吻合度高达97%。

Conclusion: 基于最终答案的错误诊断方法在处理学生合并步骤时的诊断问题上具有潜力，其结果为进一步探索该方法奠定了基础。

Abstract: Many intelligent tutoring systems can support a student in solving a stepwise
task. When a student combines several steps in one step, the number of possible
paths connecting consecutive inputs may be very large. This combinatorial
explosion makes error diagnosis hard. Using a final answer to diagnose a
combination of steps can mitigate the combinatorial explosion, because there
are generally fewer possible (erroneous) final answers than (erroneous)
solution paths. An intermediate input for a task can be diagnosed by
automatically completing it according to the task solution strategy and
diagnosing this solution. This study explores the potential of automated error
diagnosis based on a final answer. We investigate the design of a service that
provides a buggy rule diagnosis when a student combines several steps. To
validate the approach, we apply the service to an existing dataset (n=1939) of
unique student steps when solving quadratic equations, which could not be
diagnosed by a buggy rule service that tries to connect consecutive inputs with
a single rule. Results show that final answer evaluation can diagnose 29,4% of
these steps. Moreover, a comparison of the generated diagnoses with teacher
diagnoses on a subset (n=115) shows that the diagnoses align in 97% of the
cases. These results can be considered a basis for further exploration of the
approach.

</details>


### [7] [Combining model tracing and constraint-based modeling for multistep strategy diagnoses](https://arxiv.org/abs/2507.13652)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 本文提出一种结合模型追踪和基于约束建模的方法，用于诊断学生在多步骤任务中的输入，即使学生合并了多个步骤。该系统在诊断二次方程求解步骤时，与教师的编码高度一致。


<details>
  <summary>Details</summary>
Motivation: 模型追踪和基于约束建模是诊断学生分步任务输入的两种主要方法。模型追踪适用于连续的解题步骤，而基于约束建模能处理合并步骤。然而，需要一种方法，即使学生合并了多个步骤，也能诊断其偏离策略的情况。

Method: 本文提出一种融合两种范式的方法，通过将约束定义为学生输入与策略步骤共有的属性。设计了一个用于多步骤策略诊断的系统。通过对现有数据集（包含学生求解二次方程的步骤，n=2136）生成诊断来验证概念。将系统诊断与两位教师对随机样本（偏差70例，策略应用70例）的手动编码进行比较。

Result: 结果显示，系统诊断与教师对所有140个学生步骤的编码完全一致。

Conclusion: 所提出的融合方法能够有效地诊断学生在多步骤任务中的输入，即使学生合并了多个步骤，并且诊断结果与人类教师的判断高度吻合，证明了其有效性。

Abstract: Model tracing and constraint-based modeling are two approaches to diagnose
student input in stepwise tasks. Model tracing supports identifying consecutive
problem-solving steps taken by a student, whereas constraint-based modeling
supports student input diagnosis even when several steps are combined into one
step. We propose an approach that merges both paradigms. By defining
constraints as properties that a student input has in common with a step of a
strategy, it is possible to provide a diagnosis when a student deviates from a
strategy even when the student combines several steps. In this study we explore
the design of a system for multistep strategy diagnoses, and evaluate these
diagnoses. As a proof of concept, we generate diagnoses for an existing dataset
containing steps students take when solving quadratic equations (n=2136). To
compare with human diagnoses, two teachers coded a random sample of deviations
(n=70) and applications of the strategy (n=70). Results show that that the
system diagnosis aligned with the teacher coding in all of the 140 student
steps.

</details>


### [8] [DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs](https://arxiv.org/abs/2507.13737)
*Ye Tian,Xiaoyuan Ren,Zihao Wang,Onat Gungor,Xiaofan Yu,Tajana Rosing*

Main category: cs.AI

TL;DR: DailyLLM是一个利用智能手机和智能手表传感器数据，全面整合四维上下文信息（位置、运动、环境、生理）的轻量级LLM系统，用于生成和总结丰富的活动日志，显著提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的活动日志生成方法在准确性、效率和语义丰富性方面存在显著局限性，尽管大型语言模型（LLMs）为活动日志生成带来了新机遇。

Method: 本文提出了DailyLLM系统，首次全面整合了来自智能手机和智能手表常用传感器的四维上下文活动信息（位置、运动、环境、生理）。它引入了一个基于LLM的轻量级框架，结合结构化提示和高效特征提取，以实现高级活动理解。

Result: DailyLLM在日志生成方面优于最先进（SOTA）的方法，并能高效部署在个人电脑和树莓派上。使用仅1.5B参数的LLM模型，DailyLLM在日志生成BERTScore精度上比70B参数的SOTA基线提高了17%，同时推理速度快了近10倍。

Conclusion: DailyLLM有效解决了活动日志生成中的准确性、效率和语义丰富性挑战，通过整合多维度上下文信息和轻量级LLM框架，实现了卓越的性能提升和部署效率。

Abstract: Rich and context-aware activity logs facilitate user behavior analysis and
health monitoring, making them a key research focus in ubiquitous computing.
The remarkable semantic understanding and generation capabilities of Large
Language Models (LLMs) have recently created new opportunities for activity log
generation. However, existing methods continue to exhibit notable limitations
in terms of accuracy, efficiency, and semantic richness. To address these
challenges, we propose DailyLLM. To the best of our knowledge, this is the
first log generation and summarization system that comprehensively integrates
contextual activity information across four dimensions: location, motion,
environment, and physiology, using only sensors commonly available on
smartphones and smartwatches. To achieve this, DailyLLM introduces a
lightweight LLM-based framework that integrates structured prompting with
efficient feature extraction to enable high-level activity understanding.
Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art
(SOTA) log generation methods and can be efficiently deployed on personal
computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM
achieves a 17% improvement in log generation BERTScore precision compared to
the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference
speed.

</details>


### [9] [OntView: What you See is What you Meant](https://arxiv.org/abs/2507.13759)
*Carlos Bobed,Carlota Quintana,Eduardo Mena,Jorge Bobed,Fernando Bobillo*

Main category: cs.AI

TL;DR: 本文介绍了OntView，一个本体可视化工具，它通过结合描述逻辑推理机提供直观的、基于推断的本体结构表示，并能显示通用概念包含（GCI），同时提供多种简化视图以避免信息过载。


<details>
  <summary>Details</summary>
Motivation: 现有本体编辑器和查看器在图形化表示本体结构方面存在不足，尤其对于大型本体，难以提供有意义且不令人 overwhelmed 的视图，限制了用户理解概念依赖和属性的能力。

Method: 本文提出了OntView本体查看器。它利用描述逻辑（DL）推理机来显示实际推断出的知识（遵循“所见即所得”范式），并能可视化现有工具中缺失的通用概念包含（GCI）。为避免信息过载，OntView还提供多种简化视图方式，包括：1) 根据概念重要性（采用不同算法）创建本体摘要；2) 聚焦于两个给定类之间的TBox元素可视化；3) 动态隐藏/显示不同分支而不失语义。OntView已作为开源软件发布。

Result: OntView成功地提供了一种直观的本体概念及其形式化定义的视觉表示，能够显示推断出的知识，并特别支持GCI的可视化。此外，它通过提供本体摘要、聚焦视图和动态分支控制等功能，有效避免了信息过载问题，提升了用户对大型本体的理解能力。

Conclusion: OntView成功解决了本体可视化中的挑战，提供了一个用户友好、能显示推断知识（包括GCI）并能有效管理信息过载的工具，为本体社区提供了有价值的开源解决方案。

Abstract: In the field of knowledge management and computer science, ontologies provide
a structured framework for modeling domain-specific knowledge by defining
concepts and their relationships. However, the lack of tools that provide
effective visualization is still a significant challenge. While numerous
ontology editors and viewers exist, most of them fail to graphically represent
ontology structures in a meaningful and non-overwhelming way, limiting users'
ability to comprehend dependencies and properties within large ontological
frameworks.
  In this paper, we present OntView, an ontology viewer that is designed to
provide users with an intuitive visual representation of ontology concepts and
their formal definitions through a user-friendly interface. Building on the use
of a DL reasoner, OntView follows a "What you see is what you meant" paradigm,
showing the actual inferred knowledge. One key aspect for this is its ability
to visualize General Concept Inclusions (GCI), a feature absent in existing
visualization tools. Moreover, to avoid a possible information overload,
OntView also offers different ways to show a simplified view of the ontology
by: 1) creating ontology summaries by assessing the importance of the concepts
(according to different available algorithms), 2) focusing the visualization on
the existing TBox elements between two given classes and 3) allowing to
hide/show different branches in a dynamic way without losing the semantics.
OntView has been released with an open-source license for the whole community.

</details>


### [10] [From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning](https://arxiv.org/abs/2507.13768)
*Renato Ghisellini,Remo Pareschi,Marco Pedroni,Giovanni Battista Raggi*

Main category: cs.AI

TL;DR: 本文提出一种混合架构，用于代理增强的战略推理，通过语义激活和组合合成，将冲突的启发式规则融合为连贯的叙事，而非简单选择最佳规则。


<details>
  <summary>Details</summary>
Motivation: 传统的决策引擎倾向于选择最佳规则，而本研究旨在解决如何将冲突的启发式规则融合成连贯且上下文敏感的叙事。

Method: 采用混合架构，结合启发式提取、语义激活和组合合成。受量子认知研究启发，通过语义相互依存过程激活和组合多个启发式规则，并利用语义交互建模和修辞框架来融合冲突的启发式规则。

Result: 该框架通过Meta vs. FTC案例研究进行了演示，并通过语义指标进行了初步验证。

Conclusion: 该研究提出了一种新的战略推理框架，能够将冲突的启发式规则融合为语境敏感的叙事，为传统决策引擎提供了替代方案。文章也讨论了局限性及未来扩展方向。

Abstract: We present a hybrid architecture for agent-augmented strategic reasoning,
combining heuristic extraction, semantic activation, and compositional
synthesis. Drawing on sources ranging from classical military theory to
contemporary corporate strategy, our model activates and composes multiple
heuristics through a process of semantic interdependence inspired by research
in quantum cognition. Unlike traditional decision engines that select the best
rule, our system fuses conflicting heuristics into coherent and
context-sensitive narratives, guided by semantic interaction modeling and
rhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,
with preliminary validation through semantic metrics. Limitations and
extensions (e.g., dynamic interference tuning) are discussed.

</details>


### [11] [When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction](https://arxiv.org/abs/2507.13825)
*Haoyang Li,Yuming Xu,Yiming Li,Hanmo Liu,Darian Li,Chen Jason Zhang,Lei Chen,Qing Li*

Main category: cs.AI

TL;DR: 本文提出EAGLE，一个轻量级框架，通过结合短期时间近邻信息和长期全局结构模式，显著提升了动态图中时间链接预测的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 现有的时间图神经网络（T-GNNs）在建模时间及结构依赖方面虽取得成功，但因计算开销大，常面临可扩展性和效率挑战。

Method: EAGLE框架包含：1) 时间感知模块，聚合节点最近邻居信息以反映即时偏好；2) 结构感知模块，利用时间个性化PageRank捕捉全局重要节点的影响；3) 自适应加权机制，动态调整两模块贡献；4) 避免了复杂的多跳消息传递或内存密集型机制，以提高效率。

Result: 在七个真实世界时间图上的大量实验表明，EAGLE在有效性和效率方面均持续超越最先进的T-GNNs，相比基于Transformer的T-GNNs实现了超过50倍的加速。

Conclusion: EAGLE通过巧妙地整合短期时间近邻和长期全局结构模式，提供了一种高效且高性能的时间链接预测解决方案，显著优于现有方法。

Abstract: Temporal link prediction in dynamic graphs is a critical task with
applications in diverse domains such as social networks, recommendation
systems, and e-commerce platforms. While existing Temporal Graph Neural
Networks (T-GNNs) have achieved notable success by leveraging complex
architectures to model temporal and structural dependencies, they often suffer
from scalability and efficiency challenges due to high computational overhead.
In this paper, we propose EAGLE, a lightweight framework that integrates
short-term temporal recency and long-term global structural patterns. EAGLE
consists of a time-aware module that aggregates information from a node's most
recent neighbors to reflect its immediate preferences, and a structure-aware
module that leverages temporal personalized PageRank to capture the influence
of globally important nodes. To balance these attributes, EAGLE employs an
adaptive weighting mechanism to dynamically adjust their contributions based on
data characteristics. Also, EAGLE eliminates the need for complex multi-hop
message passing or memory-intensive mechanisms, enabling significant
improvements in efficiency. Extensive experiments on seven real-world temporal
graphs demonstrate that EAGLE consistently achieves superior performance
against state-of-the-art T-GNNs in both effectiveness and efficiency,
delivering more than a 50x speedup over effective transformer-based T-GNNs.

</details>


### [12] [Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments](https://arxiv.org/abs/2507.13846)
*Kathrin Korte,Christian Medeiros Adriano,Sona Ghahremani,Holger Giese*

Main category: cs.AI

TL;DR: 该论文提出了一种因果知识迁移框架，使多智能体强化学习（MARL）在非平稳环境中实现零样本适应，通过共享碰撞恢复动作的紧凑因果表示。


<details>
  <summary>Details</summary>
Motivation: 传统的多智能体强化学习知识迁移方法在非平稳环境中泛化能力差，且智能体适应新环境需要昂贵的再训练。

Method: 引入了一个因果知识迁移框架。将每次碰撞建模为因果干预，实例化为一系列恢复动作（宏）。这些宏代表了规避障碍并实现目标的因果知识，可在线从另一个智能体零样本迁移，通过查询一个包含局部上下文信息（碰撞）的查找模型来应用，无需再训练。

Result: (1) 具有异构目标的智能体在新环境中适应时，能够弥补随机探索与完全再训练策略之间约一半的性能差距；(2) 因果知识迁移的效果取决于环境复杂度和智能体异构目标之间的相互作用。

Conclusion: 该因果知识迁移框架能有效帮助多智能体在非平稳环境中进行零样本适应，并揭示了环境复杂度和智能体目标异构性对知识迁移影响的重要性。

Abstract: [Context] Multi-agent reinforcement learning (MARL) has achieved notable
success in environments where agents must learn coordinated behaviors. However,
transferring knowledge across agents remains challenging in non-stationary
environments with changing goals. [Problem] Traditional knowledge transfer
methods in MARL struggle to generalize, and agents often require costly
retraining to adapt. [Approach] This paper introduces a causal knowledge
transfer framework that enables RL agents to learn and share compact causal
representations of paths within a non-stationary environment. As the
environment changes (new obstacles), agents' collisions require adaptive
recovery strategies. We model each collision as a causal intervention
instantiated as a sequence of recovery actions (a macro) whose effect
corresponds to a causal knowledge of how to circumvent the obstacle while
increasing the chances of achieving the agent's goal (maximizing cumulative
reward). This recovery action macro is transferred online from a second agent
and is applied in a zero-shot fashion, i.e., without retraining, just by
querying a lookup model with local context information (collisions). [Results]
Our findings reveal two key insights: (1) agents with heterogeneous goals were
able to bridge about half of the gap between random exploration and a fully
retrained policy when adapting to new environments, and (2) the impact of
causal knowledge transfer depends on the interplay between environment
complexity and agents' heterogeneous goals.

</details>


### [13] [Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery](https://arxiv.org/abs/2507.13874)
*Mateusz Bystroński,Mikołaj Hołysz,Grzegorz Piotrowski,Nitesh V. Chawla,Tomasz Kajdanowicz*

Main category: cs.AI

TL;DR: 本文提出一种模型无关的潜在空间构思框架，通过在思想的连续嵌入空间中导航，实现可控、可扩展的创新，旨在克服大型语言模型在生成新颖且相关想法方面的局局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生成既新颖又相关的想法方面仍面临核心挑战，倾向于复制训练模式，需要大量提示工程，且现有解决方案（如领域特定启发式和结构化提示）不够通用和灵活。

Method: 本文提出一种模型无关的潜在空间构思框架。该框架通过导航思想的连续嵌入空间来实现受控和可扩展的创造力，无需手工规则，并且能够轻松适应不同的领域、输入格式和创意任务。

Result: 论文介绍了该方法的早期原型，概述了其概念框架，并展示了初步结果，突出其作为人机协作通用共同构思器的潜力。

Conclusion: 该潜在空间构思框架具有作为人机协作中通用共同构思器的巨大潜力，能够克服现有AI在创新性方面的局限性，实现可控且可扩展的创造力。

Abstract: Innovative idea generation remains a core challenge in AI, as large language
models (LLMs) often struggle to produce outputs that are both novel and
relevant. Despite their fluency, LLMs tend to replicate patterns seen during
training, limiting their ability to diverge creatively without extensive prompt
engineering. Prior work has addressed this through domain-specific heuristics
and structured prompting pipelines, but such solutions are brittle and
difficult to generalize. In this paper, we propose a model-agnostic
latent-space ideation framework that enables controlled, scalable creativity by
navigating the continuous embedding space of ideas. Unlike prior methods, our
framework requires no handcrafted rules and adapts easily to different domains,
input formats, and creative tasks. This paper introduces an early-stage
prototype of our method, outlining the conceptual framework and preliminary
results highlighting its potential as a general-purpose co-ideator for human-AI
collaboration.

</details>


### [14] [Cross-modal Causal Intervention for Alzheimer's Disease Prediction](https://arxiv.org/abs/2507.13956)
*Yutao Jin,Haowen Xiao,Jielei Chu,Fengmao Lv,Yuxiao Li,Tianrui Li*

Main category: cs.AI

TL;DR: 该研究提出了一种名为ADPC的视觉-语言因果干预框架，利用MRI、fMRI图像和LLM生成的文本数据，通过因果干预消除混杂因素，实现了对认知正常(CN)、轻度认知障碍(MCI)和阿尔茨海默病(AD)病例的精准分类，并达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 轻度认知障碍(MCI)是阿尔茨海默病(AD)的前驱阶段，早期识别和干预能有效延缓疾病进展。然而，AD诊断面临挑战，主要源于多模态数据选择偏差和变量间复杂关系导致的混杂因素，这些因素可能使非因果模型捕获虚假相关性，导致结果不可靠。

Method: 提出了一种新颖的视觉-语言因果干预框架ADPC。该框架利用大型语言模型(LLM)将临床数据总结为结构化文本，即使面对不完整或不均匀的数据集也能保持输出一致性。ADPC模型整合磁共振成像(MRI)、功能性MRI(fMRI)图像以及LLM生成的文本数据，对参与者进行认知正常(CN)、轻度认知障碍(MCI)和阿尔茨海默病(AD)的分类。通过因果干预，该框架隐式地消除了神经影像伪影和年龄相关生物标志物等混杂因素。

Result: 实验结果表明，该方法在区分CN/MCI/AD病例方面表现出色，在大多数评估指标上均达到了最先进(SOTA)的性能。

Conclusion: 该研究展示了将因果推理与多模态学习相结合在神经系统疾病诊断中的巨大潜力。

Abstract: Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's
Disease (AD), where early identification and intervention can effectively slow
the progression to dementia. However, diagnosing AD remains a significant
challenge in neurology due to the confounders caused mainly by the selection
bias of multimodal data and the complex relationships between variables. To
address these issues, we propose a novel visual-language causal intervention
framework named Alzheimer's Disease Prediction with Cross-modal Causal
Intervention (ADPC) for diagnostic assistance. Our ADPC employs large language
model (LLM) to summarize clinical data under strict templates, maintaining
structured text outputs even with incomplete or unevenly distributed datasets.
The ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)
images and textual data generated by LLM to classify participants into
Cognitively Normal (CN), MCI, and AD categories. Because of the presence of
confounders, such as neuroimaging artifacts and age-related biomarkers,
non-causal models are likely to capture spurious input-output correlations,
generating less reliable results. Our framework implicitly eliminates
confounders through causal intervention. Experimental results demonstrate the
outstanding performance of our method in distinguishing CN/MCI/AD cases,
achieving state-of-the-art (SOTA) metrics across most evaluation metrics. The
study showcases the potential of integrating causal reasoning with multi-modal
learning for neurological disease diagnosis.

</details>


### [15] [Towards Constraint Temporal Answer Set Programming](https://arxiv.org/abs/2507.13958)
*Pedro Cabalar,Martín Diéguez,François Olivier,Torsten Schaub,Igor Stéphan*

Main category: cs.AI

TL;DR: 本文提出了一种新的时态和约束扩展的Here-and-There逻辑及其非单调平衡扩展，旨在解决ASP在处理高分辨率动态系统时的挑战。


<details>
  <summary>Details</summary>
Motivation: 逻辑编程方法（如ASP）在处理具有细粒度时间与数值分辨率的动态系统时面临显著挑战。

Method: 通过协同结合两种ASP基础扩展实现：线性时间Here-and-There逻辑（提供鲁棒的非单调时态推理能力）和带约束的Here-and-There逻辑（实现数值约束的直接集成和操作）。

Result: 建立了一个富有表达力的系统，这是首个专为ASP设计的非单调时态推理与约束方法，能够处理高分辨率的复杂动态系统。

Conclusion: 这项工作为在ASP范式内处理高分辨率复杂动态系统奠定了逻辑基础框架。

Abstract: Reasoning about dynamic systems with a fine-grained temporal and numeric
resolution presents significant challenges for logic-based approaches like
Answer Set Programming (ASP). To address this, we introduce and elaborate upon
a novel temporal and constraint-based extension of the logic of Here-and-There
and its nonmonotonic equilibrium extension, representing, to the best of our
knowledge, the first approach to nonmonotonic temporal reasoning with
constraints specifically tailored for ASP. This expressive system is achieved
by a synergistic combination of two foundational ASP extensions: the
linear-time logic of Here-and-There, providing robust nonmonotonic temporal
reasoning capabilities, and the logic of Here-and-There with constraints,
enabling the direct integration and manipulation of numeric constraints, among
others. This work establishes the foundational logical framework for tackling
complex dynamic systems with high resolution within the ASP paradigm.

</details>


### [16] [KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models](https://arxiv.org/abs/2507.14032)
*Lam Nguyen,Erika Barcelos,Roger French,Yinghui Wu*

Main category: cs.AI

TL;DR: KROMA是一个新颖的本体匹配框架，它利用检索增强生成（RAG）管道中的大型语言模型（LLMs）动态丰富语义上下文，并通过基于双相似性的概念匹配和轻量级本体细化来优化性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的本体匹配（OM）系统通常依赖于手工规则或适应性有限的专用模型。研究旨在开发一种更具适应性、能动态丰富语义上下文的本体匹配方法。

Method: KROMA框架结合了LLMs和RAG管道，以结构、词汇和定义知识增强OM任务的语义上下文。为提高性能和效率，它整合了基于双相似性的概念匹配（用于修剪候选概念）和轻量级本体细化步骤（显著减少LLM调用开销）。其优化技术包括目标知识检索、提示丰富和本体细化。

Result: 实验表明，将知识检索与上下文增强的LLMs相结合能显著提升本体匹配效果，优于经典的OM系统和尖端的基于LLM的方法，同时保持可比的通信开销。

Conclusion: 该研究强调了所提出的优化技术（目标知识检索、提示丰富和本体细化）对于大规模本体匹配的可行性和益处。

Abstract: Ontology Matching (OM) is a cornerstone task of semantic interoperability,
yet existing systems often rely on handcrafted rules or specialized models with
limited adaptability. We present KROMA, a novel OM framework that harnesses
Large Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)
pipeline to dynamically enrich the semantic context of OM tasks with
structural, lexical, and definitional knowledge. To optimize both performance
and efficiency, KROMA integrates a bisimilarity-based concept matching and a
lightweight ontology refinement step, which prune candidate concepts and
substantially reduce the communication overhead from invoking LLMs. Through
experiments on multiple benchmark datasets, we show that integrating knowledge
retrieval with context-augmented LLMs significantly enhances ontology matching,
outperforming both classic OM systems and cutting-edge LLM-based approaches
while keeping communication overhead comparable. Our study highlights the
feasibility and benefit of the proposed optimization techniques (targeted
knowledge retrieval, prompt enrichment, and ontology refinement) for ontology
matching at scale.

</details>


### [17] [Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions](https://arxiv.org/abs/2507.14077)
*Temiloluwa Prioleau,Baiying Lu,Yanjun Cui*

Main category: cs.AI

TL;DR: 本文介绍了Glucose-ML，一个包含10个公开糖尿病数据集的大型集合，旨在解决高质量数据不足的问题，并提供基准测试和开发鲁棒AI解决方案的建议。


<details>
  <summary>Details</summary>
Motivation: 高质量、大规模数据集的缺乏阻碍了糖尿病管理领域中鲁棒AI解决方案的开发。

Method: 研究者收集了10个在过去7年内发布的公开糖尿病数据集，形成Glucose-ML集合。他们对这些数据集进行了比较分析，并以血糖预测为例进行了案例研究，为所有数据集提供了短期血糖预测的基准。

Result: Glucose-ML集合包含超过30万天的连续血糖监测数据，共计3800万个血糖样本，来自4个国家的2500多名参与者（包括T1D、T2D、糖尿病前期和非糖尿病人群）。研究发现，同一算法在不同数据集上开发/评估时，预测结果可能存在显著差异。他们提供了血糖预测的基准。

Conclusion: 该研究的结果为在糖尿病或更广泛的健康领域开发鲁棒AI解决方案提供了指导和建议。研究者公开了Glucose-ML集合中每个纵向糖尿病数据集的直接链接和相关代码。

Abstract: Artificial intelligence (AI) algorithms are a critical part of
state-of-the-art digital health technology for diabetes management. Yet, access
to large high-quality datasets is creating barriers that impede development of
robust AI solutions. To accelerate development of transparent, reproducible,
and robust AI solutions, we present Glucose-ML, a collection of 10 publicly
available diabetes datasets, released within the last 7 years (i.e., 2018 -
2025). The Glucose-ML collection comprises over 300,000 days of continuous
glucose monitor (CGM) data with a total of 38 million glucose samples collected
from 2500+ people across 4 countries. Participants include persons living with
type 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support
researchers and innovators with using this rich collection of diabetes
datasets, we present a comparative analysis to guide algorithm developers with
data selection. Additionally, we conduct a case study for the task of blood
glucose prediction - one of the most common AI tasks within the field. Through
this case study, we provide a benchmark for short-term blood glucose prediction
across all 10 publicly available diabetes datasets within the Glucose-ML
collection. We show that the same algorithm can have significantly different
prediction results when developed/evaluated with different datasets. Findings
from this study are then used to inform recommendations for developing robust
AI solutions within the diabetes or broader health domain. We provide direct
links to each longitudinal diabetes dataset in the Glucose-ML collection and
openly provide our code.

</details>


### [18] [Generative AI-Driven High-Fidelity Human Motion Simulation](https://arxiv.org/abs/2507.14097)
*Hari Iyer,Neel Macwan,Atharva Jitendra Hude,Heejin Jeong,Shenghan Guo*

Main category: cs.AI

TL;DR: 提出G-AI-HMS，通过生成式AI集成文本到文本和文本到运动模型，显著提升了工业任务中人体运动模拟的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动模拟（HMS）方法在工业任务中存在运动保真度低的问题，限制了其在评估工人行为、安全和生产力方面的有效性。

Method: 本研究引入了Generative-AI-Enabled HMS (G-AI-HMS)。该方法整合了文本到文本和文本到运动模型，以增强物理任务的模拟质量。G-AI-HMS主要解决两个挑战：1) 使用与MotionGPT训练词汇对齐的大语言模型将任务描述转换为运动感知语言；2) 使用计算机视觉技术（姿态估计算法从实时视频中提取关节地标，并使用运动相似性度量）验证AI增强的运动与真实人体运动的一致性。

Result: 在涉及八项任务的案例研究中，AI增强的运动在大多数场景下比人工创建的描述表现出更低的误差。具体而言，在空间精度方面优于六项任务，在姿态归一化后的对齐方面优于四项任务，在整体时间相似性方面优于七项任务。统计分析表明，AI增强的提示显著（p < 0.0001）降低了关节误差和时间错位，同时保持了可比的姿态准确性。

Conclusion: G-AI-HMS通过利用生成式AI，显著提高了人体运动模拟的质量和准确性，尤其在减少运动误差和时间错位方面表现出色，为工业任务评估提供了更可靠的工具。

Abstract: Human motion simulation (HMS) supports cost-effective evaluation of worker
behavior, safety, and productivity in industrial tasks. However, existing
methods often suffer from low motion fidelity. This study introduces
Generative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and
text-to-motion models to enhance simulation quality for physical tasks.
G-AI-HMS tackles two key challenges: (1) translating task descriptions into
motion-aware language using Large Language Models aligned with MotionGPT's
training vocabulary, and (2) validating AI-enhanced motions against real human
movements using computer vision. Posture estimation algorithms are applied to
real-time videos to extract joint landmarks, and motion similarity metrics are
used to compare them with AI-enhanced sequences. In a case study involving
eight tasks, the AI-enhanced motions showed lower error than human created
descriptions in most scenarios, performing better in six tasks based on spatial
accuracy, four tasks based on alignment after pose normalization, and seven
tasks based on overall temporal similarity. Statistical analysis showed that
AI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and
temporal misalignment while retaining comparable posture accuracy.

</details>


### [19] [Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment](https://arxiv.org/abs/2507.14107)
*Viraj Nishesh Darji,Callie C. Liao,Duoduo Liao*

Main category: cs.AI

TL;DR: 本研究探索了大型语言模型（LLMs）在解释无损评估（NDE）等高线图方面的能力，旨在自动化桥梁状况分析，提高效率和准确性，并提出了一个整合LLMs到桥梁检测工作流程的框架。


<details>
  <summary>Details</summary>
Motivation: 桥梁维护中的无损评估（NDE）数据解释耗时且需要专业知识，可能延迟决策。研究旨在利用LLMs自动化并改进这一过程。

Method: 本试点研究评估了多种LLMs（共9个）解释NDE等高线图的能力。通过专门设计的提示，LLMs被用于生成图像描述，并应用于5个不同的NDE等高线图。评估标准包括描述细节、缺陷识别、建议可行性和整体准确性。最佳模型的输出（来自4个LLM）再由另外5个LLM进行总结。

Result: 研究发现，9个模型中有4个提供了更好的图像描述，能有效涵盖桥梁状况的广泛主题。在总结方面，ChatGPT-4和Claude 3.5 Sonnet生成了更有效的摘要。结果表明LLMs能显著提高效率和准确性。

Conclusion: LLMs在桥梁维护中通过并行图像标注和摘要功能，具有显著提高效率和准确性的潜力。这种创新方法有助于加快决策制定，提升基础设施管理和安全评估水平。

Abstract: Bridge maintenance and safety are essential for transportation authorities,
and Non-Destructive Evaluation (NDE) techniques are critical to assessing
structural integrity. However, interpreting NDE data can be time-consuming and
requires expertise, potentially delaying decision-making. Recent advancements
in Large Language Models (LLMs) offer new ways to automate and improve this
analysis. This pilot study introduces a holistic assessment of LLM capabilities
for interpreting NDE contour maps and demonstrates the effectiveness of LLMs in
providing detailed bridge condition analyses. It establishes a framework for
integrating LLMs into bridge inspection workflows, indicating that LLM-assisted
analysis can enhance efficiency without compromising accuracy. In this study,
several LLMs are explored with prompts specifically designed to enhance the
quality of image descriptions, which are applied to interpret five different
NDE contour maps obtained through technologies for assessing bridge conditions.
Each LLM model is evaluated based on its ability to produce detailed
descriptions, identify defects, provide actionable recommendations, and
demonstrate overall accuracy. The research indicates that four of the nine
models provide better image descriptions, effectively covering a wide range of
topics related to the bridge's condition. The outputs from these four models
are summarized using five different LLMs to form a comprehensive overview of
the bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more
effective summaries. The findings suggest that LLMs have the potential to
significantly improve efficiency and accuracy. This pilot study presents an
innovative approach that leverages LLMs for image captioning in parallel and
summarization, enabling faster decision-making in bridge maintenance and
enhancing infrastructure management and safety assessments.

</details>


### [20] [CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.14111)
*Xiaoya Li,Xiaofei Sun,Albert Wang,Jiwei Li,Chris Shum*

Main category: cs.AI

TL;DR: CUDA-L1是一个基于强化学习的自动化CUDA优化框架，它在多种GPU上实现了显著的性能提升，并展现了RL在无需人工专业知识的情况下优化代码的潜力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）的快速发展导致GPU计算资源需求呈指数级增长，急需自动化的CUDA优化策略。然而，当前最先进的LLM在提高CUDA速度方面的成功率较低。

Method: 本文引入了CUDA-L1，一个自动化的强化学习框架，用于CUDA优化。该框架通过基于加速比的奖励信号进行训练，旨在将初始性能不佳的LLM转化为有效的CUDA优化器。

Result: CUDA-L1在NVIDIA A100上训练，在KernelBench的250个CUDA核函数上实现了平均17.7倍的加速，峰值加速达到449倍。它还展现了卓越的跨GPU架构可移植性，在H100、RTX 3090等多种GPU上均实现平均13.9倍至19.0倍的加速。此外，该模型能发现并组合多种优化技术，揭示优化原理，并识别非显而易见的性能瓶颈。

Conclusion: 研究表明，强化学习能够仅通过基于加速比的奖励信号，在无需人类专业知识的情况下，将性能不佳的LLM转化为有效的CUDA优化器。该模型能将其习得的推理能力扩展到新的核函数，为CUDA操作的自动化优化开辟了可能性，有望显著提升GPU效率并缓解计算资源压力。

Abstract: The exponential growth in demand for GPU computing resources, driven by the
rapid advancement of Large Language Models, has created an urgent need for
automated CUDA optimization strategies. While recent advances in LLMs show
promise for code generation, current SOTA models (e.g. R1, o1) achieve low
success rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an
automated reinforcement learning framework for CUDA optimization.
  CUDA-L1 achieves performance improvements on the CUDA optimization task:
trained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250
CUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the
model also demonstrates excellent portability across GPU architectures,
achieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,
x14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.
Beyond these benchmark results, CUDA-L1 demonstrates several remarkable
properties: 1) Discovers a variety of CUDA optimization techniques and learns
to combine them strategically to achieve optimal performance; 2) Uncovers
fundamental principles of CUDA optimization; 3) Identifies non-obvious
performance bottlenecks and rejects seemingly beneficial optimizations that
harm performance.
  The capabilities of CUDA-L1 demonstrate that reinforcement learning can
transform an initially poor-performing LLM into an effective CUDA optimizer
through speedup-based reward signals alone, without human expertise or domain
knowledge. More importantly, the trained RL model extend the acquired reasoning
abilities to new kernels. This paradigm opens possibilities for automated
optimization of CUDA operations, and holds promise to substantially promote GPU
efficiency and alleviate the rising pressure on GPU computing resources.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [21] [Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives](https://arxiv.org/abs/2507.13359)
*Yang Zhou,Junjie Li,CongYang Ou,Dawei Yan,Haokui Zhang,Xizhe Xue*

Main category: cs.CV

TL;DR: 本文综述了无人机（UAV）航拍场景中的开放词汇目标检测（OVOD）技术，涵盖其原理、现有方法、数据集、面临的挑战及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 传统的无人机航拍目标检测方法受限于预定义类别，极大地限制了其应用范围。跨模态文本-图像对齐技术（如CLIP）的出现，使得开放词汇目标检测（OVOD）成为可能，能够通过自然语言描述识别未曾见过的物体，从而显著增强无人机在空中场景理解方面的智能性和自主性。

Method: 本文采用综述方法，首先将OVOD的核心原理与UAV视觉的独特特性相结合；其次，构建了一个系统的分类法，对现有航拍图像OVOD方法进行分类，并全面概述相关数据集；最后，通过分析批判性地剖析了这些领域交叉的关键挑战和未解决问题。

Result: 本文构建了一个系统的分类法，涵盖了现有的航拍图像OVOD方法和相关数据集，并批判性地分析了该领域面临的关键挑战和开放问题。基于此分析，论文提出了有前景的未来研究方向和应用前景。

Conclusion: 本综述旨在为该快速发展的领域提供清晰的路线图和有价值的参考，以促进该领域的创新，对新手和经验丰富的研究人员都有帮助。

Abstract: Due to its extensive applications, aerial image object detection has long
been a hot topic in computer vision. In recent years, advancements in Unmanned
Aerial Vehicles (UAV) technology have further propelled this field to new
heights, giving rise to a broader range of application requirements. However,
traditional UAV aerial object detection methods primarily focus on detecting
predefined categories, which significantly limits their applicability. The
advent of cross-modal text-image alignment (e.g., CLIP) has overcome this
limitation, enabling open-vocabulary object detection (OVOD), which can
identify previously unseen objects through natural language descriptions. This
breakthrough significantly enhances the intelligence and autonomy of UAVs in
aerial scene understanding. This paper presents a comprehensive survey of OVOD
in the context of UAV aerial scenes. We begin by aligning the core principles
of OVOD with the unique characteristics of UAV vision, setting the stage for a
specialized discussion. Building on this foundation, we construct a systematic
taxonomy that categorizes existing OVOD methods for aerial imagery and provides
a comprehensive overview of the relevant datasets. This structured review
enables us to critically dissect the key challenges and open problems at the
intersection of these fields. Finally, based on this analysis, we outline
promising future research directions and application prospects. This survey
aims to provide a clear road map and a valuable reference for both newcomers
and seasoned researchers, fostering innovation in this rapidly evolving domain.
We keep tracing related works at
https://github.com/zhouyang2002/OVOD-in-UVA-imagery

</details>


### [22] [Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance](https://arxiv.org/abs/2507.13360)
*Le-Anh Tran,Chung Nguyen Tran,Ngoc-Luu Nguyen,Nhan Cach Dang,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种名为EDNIG的深度学习框架，用于低光图像增强，该框架基于U-Net并结合了亮度通道先验（BCP）生成的照明图作为指导输入，同时利用空间金字塔池化（SPP）提取多尺度特征，并在GAN框架下通过复合损失函数进行优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在低光图像增强方面仍有提升空间，尤其是在处理欠曝光区域和复杂光照条件时，同时需要兼顾模型性能和复杂度。

Method: EDNIG框架构建于U-Net架构之上，核心创新包括：1) 整合基于亮度通道先验（BCP）的照明图作为指导输入，以聚焦欠曝光区域；2) 引入空间金字塔池化（SPP）模块以提取多尺度上下文特征；3) 采用Swish激活函数确保梯度传播平滑；4) 在生成对抗网络（GAN）框架下进行优化，使用结合对抗损失、像素级均方误差（MSE）和感知损失的复合损失函数。

Result: 实验结果表明，EDNIG在定量指标和视觉质量方面均达到了与现有最先进方法相当的竞争性性能，同时保持了较低的模型复杂度。

Conclusion: EDNIG框架在低光图像增强方面表现出色，其性能和较低的复杂度使其适用于实际应用。

Abstract: This paper introduces a novel deep learning framework for low-light image
enhancement, named the Encoder-Decoder Network with Illumination Guidance
(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination
map, derived from Bright Channel Prior (BCP), as a guidance input. This
illumination guidance helps the network focus on underexposed regions,
effectively steering the enhancement process. To further improve the model's
representational power, a Spatial Pyramid Pooling (SPP) module is incorporated
to extract multi-scale contextual features, enabling better handling of diverse
lighting conditions. Additionally, the Swish activation function is employed to
ensure smoother gradient propagation during training. EDNIG is optimized within
a Generative Adversarial Network (GAN) framework using a composite loss
function that combines adversarial loss, pixel-wise mean squared error (MSE),
and perceptual loss. Experimental results show that EDNIG achieves competitive
performance compared to state-of-the-art methods in quantitative metrics and
visual quality, while maintaining lower model complexity, demonstrating its
suitability for real-world applications. The source code for this work is
available at https://github.com/tranleanh/ednig.

</details>


### [23] [VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs](https://arxiv.org/abs/2507.13361)
*Shmuel Berman,Jia Deng*

Main category: cs.CV

TL;DR: 视觉语言模型（VLMs）在需要整合来自图像多个区域信息的非局部视觉推理方面表现不佳，即使是顶级模型也难以通过人类认为简单的测试。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在VQA和图表理解等复杂视觉任务上表现出色，但近期研究表明它们在简单的感知测试上存在困难。本研究旨在评估VLMs进行非局部视觉推理的能力，即需要链式整合来自图像多个（可能是远距离）区域证据的推理。

Method: 本研究评估了VLMs的非局部视觉推理能力，并将其细分为三种形式：比较感知（需要比较两张图像）、眼跳式搜索（需要根据证据离散跳跃寻找目标）和平滑视觉搜索（需要沿连续轮廓平滑搜索）。测试对象是主流旗舰模型，如Gemini 2.5 Pro、Claude Vision 3.7和GPT-o4-mini。

Result: 即使在先前的原始视觉基准测试中表现良好的旗舰模型，在这些非局部视觉推理测试中也表现失败，在两个对人类来说微不足道的任务变体上，其准确率仅略高于随机水平。研究发现，尽管模型在原始视觉敏锐度上有所提升，但它们缺乏核心的视觉推理能力。

Conclusion: 当前VLMs，尽管在原始视觉敏锐度方面有所进步，但仍缺乏核心的视觉推理能力，特别是进行非局部视觉推理的能力，这表明它们无法像人类那样执行类似的视觉算法。

Abstract: Visual Language Models (VLMs) excel at complex visual tasks such as VQA and
chart understanding, yet recent work suggests they struggle with simple
perceptual tests. We present an evaluation that tests vision-language models'
capacity for nonlocal visual reasoning -- reasoning that requires chaining
evidence collected from multiple, possibly distant, regions of an image. We
isolate three distinct forms of non-local vision: comparative perception, which
demands holding two images in working memory and comparing them; saccadic
search, which requires making discrete, evidence-driven jumps to locate
successive targets; and smooth visual search, which involves searching smoothly
along a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude
Vision 3.7, GPT-o4-mini), even those that perform well on prior
primitive-vision benchmarks, fail these tests and barely exceed random accuracy
on two variants of our tasks that are trivial for humans. Our structured
evaluation suite allows us to test if VLMs can perform similar visual
algorithms to humans. Our findings show that despite gains in raw visual
acuity, current models lack core visual reasoning capabilities.

</details>


### [24] [Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning](https://arxiv.org/abs/2507.13362)
*Binbin Ji,Siddharth Agrawal,Qiance Tang,Yvonne Wu*

Main category: cs.CV

TL;DR: 本研究通过链式思考(CoT)提示和强化学习(RL)提升视觉-语言模型(VLM)的空间推理能力。发现简单的CoT无效甚至有害，而基于场景图的结构化CoT显著提高准确性。此外，使用GRPO进行RL微调比监督微调(SFT)在准确性和OOD鲁棒性方面表现更优，SFT易过拟合语言模式。


<details>
  <summary>Details</summary>
Motivation: 旨在深入探究并提升视觉-语言模型(VLM)的空间推理能力，并解决现有CoT提示的局限性以及探索强化学习在提高模型泛化性方面的潜力。

Method: 1. 评估不同的CoT提示策略，包括简单CoT和基于场景图的结构化多阶段提示(SceneGraph CoT)。2. 使用Group Relative Policy Optimization (GRPO)在SAT数据集上对模型进行微调。3. 将GRPO与监督微调(SFT)进行对比。4. 在CVBench和出域(OOD)条件下评估模型性能，特别关注对语言模式变化的鲁棒性。

Result: 1. 简单的CoT提示不仅未能帮助，反而可能损害VLM的原始空间推理性能。2. 基于场景图的结构化多阶段提示(SceneGraph CoT)显著提高了空间推理准确性。3. 与SFT相比，GRPO在Pass@1评估中取得了更高的准确性，并在OOD条件下展现出卓越的鲁棒性。4. SFT容易过拟合表层语言模式，当测试时措辞变化时性能会下降（例如，从“更靠近”到“更远离”）。5. GRPO的泛化能力更可靠，在此类变化下仍能保持稳定性能。

Conclusion: 强化学习（特别是GRPO）和结构化提示（如SceneGraph CoT）能够有效提高现代视觉-语言模型的空间推理能力和泛化行为。SFT在泛化性上存在局限性，易受表层语言模式过拟合的影响。

Abstract: This study investigates the spatial reasoning capabilities of vision-language
models (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement
learning. We begin by evaluating the impact of different prompting strategies
and find that simple CoT formats, where the model generates a reasoning step
before the answer, not only fail to help, but can even harm the model's
original performance. In contrast, structured multi-stage prompting based on
scene graphs (SceneGraph CoT) significantly improves spatial reasoning
accuracy. Furthermore, to improve spatial reasoning ability, we fine-tune
models using Group Relative Policy Optimization (GRPO) on the SAT dataset and
evaluate their performance on CVBench. Compared to supervised fine-tuning
(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates
superior robustness under out-of-distribution (OOD) conditions. In particular,
we find that SFT overfits to surface-level linguistic patterns and may degrade
performance when test-time phrasing changes (e.g., from "closer to" to "farther
from"). GRPO, on the other hand, generalizes more reliably and maintains stable
performance under such shifts. Our findings provide insights into how
reinforcement learning and structured prompting improve the spatial reasoning
capabilities and generalization behavior of modern VLMs. All code is open
source at: https://github.com/Yvonne511/spatial-vlm-investigator

</details>


### [25] [Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop](https://arxiv.org/abs/2507.13363)
*Atharv Goel,Mehar Khurana*

Main category: cs.CV

TL;DR: 该研究利用2D视觉-语言模型实现零样本、开放词汇的3D目标检测，无需任何人工标注的3D标签，并通过几何膨胀策略生成3D边界框。


<details>
  <summary>Details</summary>
Motivation: 现有3D目标检测数据集受限于狭窄的类别分类和昂贵的手动标注，难以扩展到开放世界场景。而2D视觉-语言模型（VLM）在网络规模的图像-文本对上训练，展现出丰富的语义理解能力，并支持通过自然语言提示进行开放词汇检测。

Method: 该方法利用2D视觉-语言检测器生成文本条件下的2D候选框，然后使用SAM进行分割，并通过相机几何和LiDAR或单目伪深度将其反投影到3D空间。为推断3D边界框，引入了一种基于DBSCAN聚类和旋转卡尺（Rotating Calipers）的几何膨胀策略，整个过程无需训练。为模拟恶劣现实条件，构建了Pseudo-nuScenes数据集（nuScenes的雾增强、纯RGB变体）。

Result: 实验证明，该方法在多种设置下（包括基于LiDAR和纯RGB-D输入）实现了具有竞争力的定位性能，同时保持了免训练和开放词汇的特性。

Conclusion: 该研究结果突出了2D基础模型在可扩展3D感知方面的巨大潜力。

Abstract: Modern 3D object detection datasets are constrained by narrow class
taxonomies and costly manual annotations, limiting their ability to scale to
open-world settings. In contrast, 2D vision-language models trained on
web-scale image-text pairs exhibit rich semantic understanding and support
open-vocabulary detection via natural language prompts. In this work, we
leverage the maturity and category diversity of 2D foundation models to perform
open-vocabulary 3D object detection without any human-annotated 3D labels.
  Our pipeline uses a 2D vision-language detector to generate text-conditioned
proposals, which are segmented with SAM and back-projected into 3D using camera
geometry and either LiDAR or monocular pseudo-depth. We introduce a geometric
inflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D
bounding boxes without training. To simulate adverse real-world conditions, we
construct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes
dataset.
  Experiments demonstrate that our method achieves competitive localization
performance across multiple settings, including LiDAR-based and purely RGB-D
inputs, all while remaining training-free and open-vocabulary. Our results
highlight the untapped potential of 2D foundation models for scalable 3D
perception. We open-source our code and resources at
https://github.com/atharv0goel/open-world-3D-det.

</details>


### [26] [OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning](https://arxiv.org/abs/2507.13364)
*Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的多模态多任务网络及其训练算法，能够处理约12种不同模态的数据，并通过统一的嵌入空间和创新的预训练/训练策略，在多任务场景中实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于开发一个能够统一处理大量不同数据模态（如图像、视频、音频、文本等）并解决多任务场景的通用框架，同时实现高性能。

Method: 该方法包括：1) 模态专用分词器；2) 共享的Transformer架构；3) 交叉注意力机制，将不同模态数据投影到统一的嵌入空间；4) 针对不同模态任务的模态特定任务头。此外，还提出了一种新颖的预训练策略（迭代模态切换）和一种训练算法，该算法在所有模态的完全联合训练与一次训练一对模态之间进行权衡。

Result: 该方法在来自12种模态的25个数据集上进行了全面评估，并展示了最先进的性能。

Conclusion: 所提出的架构、预训练策略和适应性多任务训练是有效的，能够成功处理多模态多任务场景，并达到顶尖水平。

Abstract: We present a novel multimodal multitask network and associated training
algorithm. The method is capable of ingesting data from approximately 12
different modalities namely image, video, audio, text, depth, point cloud, time
series, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed
approach utilizes modality specialized tokenizers, a shared transformer
architecture, and cross-attention mechanisms to project the data from different
modalities into a unified embedding space. It addresses multimodal and
multitask scenarios by incorporating modality-specific task heads for different
tasks in respective modalities. We propose a novel pretraining strategy with
iterative modality switching to initialize the network, and a training
algorithm which trades off fully joint training over all modalities, with
training on pairs of modalities at a time. We provide comprehensive evaluation
across 25 datasets from 12 modalities and show state of the art performances,
demonstrating the effectiveness of the proposed architecture, pretraining
strategy and adapted multitask training.

</details>


### [27] [Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation](https://arxiv.org/abs/2507.13371)
*Yeming Cai,Yang Wang,Zhenglin Li*

Main category: cs.CV

TL;DR: 该论文提出了一个结合光学运动捕捉和Transformer模型的端到端深度学习框架，用于医疗康复，旨在处理数据噪声和缺失，并实时检测异常动作。


<details>
  <summary>Details</summary>
Motivation: 光学运动捕捉数据常因遮挡和环境因素导致噪声和缺失，且需要实时检测异常动作以确保患者安全。现有康复方案可能缺乏可扩展性和成本效益，需要减少现场监督。

Method: 本文提出了一个端到端深度学习框架，该框架将光学运动捕捉与基于Transformer的模型相结合。它利用时间序列建模来去噪和补全运动捕捉数据，并实时检测异常运动。

Result: 在针对中风和骨科康复数据集的评估中，该框架在数据重建和异常检测方面表现出卓越的性能。

Conclusion: 该框架提供了一个可扩展、经济高效的远程康复解决方案，能够减少现场监督，有效提升医疗康复效果和患者安全性。

Abstract: This paper proposes an end-to-end deep learning framework integrating optical
motion capture with a Transformer-based model to enhance medical
rehabilitation. It tackles data noise and missing data caused by occlusion and
environmental factors, while detecting abnormal movements in real time to
ensure patient safety. Utilizing temporal sequence modeling, our framework
denoises and completes motion capture data, improving robustness. Evaluations
on stroke and orthopedic rehabilitation datasets show superior performance in
data reconstruction and anomaly detection, providing a scalable, cost-effective
solution for remote rehabilitation with reduced on-site supervision.

</details>


### [28] [Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks](https://arxiv.org/abs/2507.13372)
*Yeming Cai,Zhenglin Li,Yang Wang*

Main category: cs.CV

TL;DR: 本文提出一个结合ViT和GNN的创新框架，用于乳腺癌早期检测，在CBIS-DDSM数据集上表现优异并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性死亡的主要原因之一，早期检测对于提高生存率至关重要。

Method: 引入一个整合Vision Transformers (ViT) 和 Graph Neural Networks (GNN) 的框架。该框架利用ViT捕捉全局图像特征的能力和GNN建模结构关系的优势，并在CBIS-DDSM数据集上进行乳腺癌检测。此外，还提供可解释的注意力热图。

Result: 该框架在乳腺癌检测中实现了84.2%的准确率，优于传统方法。可解释的注意力热图为模型决策过程提供了洞察。

Conclusion: 结合ViT和GNN的框架能有效提升乳腺癌检测性能，并提供模型决策的可解释性，有助于放射科医生在临床环境中的应用。

Abstract: Breast cancer is a leading cause of death among women globally, and early
detection is critical for improving survival rates. This paper introduces an
innovative framework that integrates Vision Transformers (ViT) and Graph Neural
Networks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset.
Our framework leverages ViT's ability to capture global image features and
GNN's strength in modeling structural relationships, achieving an accuracy of
84.2%, outperforming traditional methods. Additionally, interpretable attention
heatmaps provide insights into the model's decision-making process, aiding
radiologists in clinical settings.

</details>


### [29] [Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection](https://arxiv.org/abs/2507.13373)
*Xiaojian Lin,Wenxin Zhang,Yuchu Jiang,Wangyu Wu,Yiran Guo,Kangxu Wang,Zongzheng Zhang,Guijin Wang,Lei Jin,Hao Zhao*

Main category: cs.CV

TL;DR: Butter是一种新型目标检测框架，通过增强分层特征表示，提高了自动驾驶场景下的检测鲁棒性，并在精度、部署性和计算效率之间取得了平衡。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测架构（如YOLO和DETR）在处理自动驾驶场景中的多尺度特征时，难以在保持特征一致性的同时兼顾检测精度和计算效率，导致对动态环境中行人、车辆和交通标志的准确识别面临挑战。

Method: 本文提出了Butter框架，包含两项主要创新：1. 频率自适应特征一致性增强组件（FAFCE），利用自适应频率滤波细化多尺度特征一致性，增强结构和边界精度。2. 渐进式分层特征融合网络模块（PHFFNet），逐步整合多级特征，弥合语义鸿沟并强化分层特征学习。

Result: 在BDD100K、KITTI和Cityscapes数据集上的大量实验表明，Butter展示了卓越的特征表示能力，显著提高了检测精度，同时降低了模型复杂度。

Conclusion: Butter通过专注于分层特征的精炼和整合，为目标检测提供了一种先进方法，在实时自动驾驶场景中实现了精度、可部署性和计算效率之间的良好平衡。

Abstract: Hierarchical feature representations play a pivotal role in computer vision,
particularly in object detection for autonomous driving. Multi-level semantic
understanding is crucial for accurately identifying pedestrians, vehicles, and
traffic signs in dynamic environments. However, existing architectures, such as
YOLO and DETR, struggle to maintain feature consistency across different scales
while balancing detection precision and computational efficiency. To address
these challenges, we propose Butter, a novel object detection framework
designed to enhance hierarchical feature representations for improving
detection robustness. Specifically, Butter introduces two key innovations:
Frequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which
refines multi-scale feature consistency by leveraging adaptive frequency
filtering to enhance structural and boundary precision, and Progressive
Hierarchical Feature Fusion Network (PHFFNet) Module, which progressively
integrates multi-level features to mitigate semantic gaps and strengthen
hierarchical feature learning. Through extensive experiments on BDD100K, KITTI,
and Cityscapes, Butter demonstrates superior feature representation
capabilities, leading to notable improvements in detection accuracy while
reducing model complexity. By focusing on hierarchical feature refinement and
integration, Butter provides an advanced approach to object detection that
achieves a balance between accuracy, deployability, and computational
efficiency in real-time autonomous driving scenarios. Our model and
implementation are publicly available at https://github.com/Aveiro-Lin/Butter,
facilitating further research and validation within the autonomous driving
community.

</details>


### [30] [Smart Routing for Multimodal Video Retrieval: When to Search What](https://arxiv.org/abs/2507.13374)
*Kevin Dela Rosa*

Main category: cs.CV

TL;DR: ModaRoute是一个基于LLM的智能路由系统，用于多模态视频检索，它能动态选择最优模态，在降低计算开销的同时保持较高的检索效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如密集文本字幕）虽然能达到75.9%的Recall@5，但需要昂贵的离线处理，并且会遗漏34%视频片段中ASR未捕获的关键视觉信息（如场景文本），因此需要一个更高效且能充分利用多模态信息的检索系统。

Method: ModaRoute使用GPT-4.1分析查询意图并预测信息需求，动态地将查询路由到ASR（语音）、OCR（文本）和视觉索引。它平均每个查询使用1.78种模态，而非穷举的3.0种模态搜索。

Result: ModaRoute将计算开销降低了41%，同时实现了60.9%的Recall@5。该系统在180万个视频片段上进行了评估。

Conclusion: 智能路由（ModaRoute）为扩展多模态检索系统提供了一个实用的解决方案，它在降低基础设施成本的同时，为实际部署保持了有竞争力的效果。

Abstract: We introduce ModaRoute, an LLM-based intelligent routing system that
dynamically selects optimal modalities for multimodal video retrieval. While
dense text captions can achieve 75.9% Recall@5, they require expensive offline
processing and miss critical visual information present in 34% of clips with
scene text not captured by ASR. By analyzing query intent and predicting
information needs, ModaRoute reduces computational overhead by 41% while
achieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR
(speech), OCR (text), and visual indices, averaging 1.78 modalities per query
versus exhaustive 3.0 modality search. Evaluation on 1.8M video clips
demonstrates that intelligent routing provides a practical solution for scaling
multimodal retrieval systems, reducing infrastructure costs while maintaining
competitive effectiveness for real-world deployment.

</details>


### [31] [A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects](https://arxiv.org/abs/2507.13378)
*Yuqi Cheng,Yunkang Cao,Haiming Yao,Wei Luo,Cheng Jiang,Hui Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 本综述深入分析了工业缺陷检测领域，涵盖了2D和3D模态下的闭集与开集方法，追踪其演变，并强调了开集技术的日益重要性，同时探讨了实践挑战和新兴趋势。


<details>
  <summary>Details</summary>
Motivation: 传统检测方法难以满足现代制造业对精度、自动化和可扩展性的要求。尽管计算机视觉和深度学习在缺陷检测方面取得了显著进展，但目前缺乏对工业缺陷检测领域（特别是从闭集到开集框架的转变）的连贯和最新理解。

Method: 本文采用综述方法，对2D和3D模态下的闭集与开集缺陷检测策略进行了深入分析，梳理了其近年来的演变，强调了开集技术的兴起，并提炼了实际检测环境中的关键挑战和新兴趋势。

Result: 该综述提供了2D和3D模态下闭集和开集缺陷检测策略的深入分析，描绘了其近年来的发展轨迹，并突出了开集技术的日益突出。同时，它提炼了实际检测环境中的关键挑战，并阐明了新兴趋势。

Conclusion: 本综述为快速发展的工业缺陷检测领域提供了当前且全面的视角，有助于理解该领域的演变、面临的挑战以及未来的发展方向。

Abstract: Industrial defect detection is vital for upholding product quality across
contemporary manufacturing systems. As the expectations for precision,
automation, and scalability intensify, conventional inspection approaches are
increasingly found wanting in addressing real-world demands. Notable progress
in computer vision and deep learning has substantially bolstered defect
detection capabilities across both 2D and 3D modalities. A significant
development has been the pivot from closed-set to open-set defect detection
frameworks, which diminishes the necessity for extensive defect annotations and
facilitates the recognition of novel anomalies. Despite such strides, a
cohesive and contemporary understanding of industrial defect detection remains
elusive. Consequently, this survey delivers an in-depth analysis of both
closed-set and open-set defect detection strategies within 2D and 3D
modalities, charting their evolution in recent years and underscoring the
rising prominence of open-set techniques. We distill critical challenges
inherent in practical detection environments and illuminate emerging trends,
thereby providing a current and comprehensive vista of this swiftly progressing
field.

</details>


### [32] [Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery](https://arxiv.org/abs/2507.13385)
*Arjun Rao,Esther Rolf*

Main category: cs.CV

TL;DR: 通过将多种地理空间数据与光学卫星图像融合，显著提升了卫星机器学习（SatML）模型的性能，尤其在数据受限和地理样本外场景中效果更佳，且硬编码融合策略优于学习型策略。


<details>
  <summary>Details</summary>
Motivation: 大多数卫星机器学习（SatML）模型主要设计用于光学输入模态，研究旨在探究在监督学习中，将其他地理空间数据与光学图像结合使用的价值。

Method: 研究人员通过将额外的地理数据层附加到现有的SatML基准任务数据集（涵盖分类、回归和分割）上，生成了增强版数据集。在此基础上，他们评估了融合不同地理输入与光学图像的效果，并比较了硬编码融合策略和学习型融合策略的性能。

Result: 将额外的地理输入与光学图像融合可以显著提高SatML模型的性能。在标记数据有限和地理样本外（out-of-sample）场景中，这种融合带来的益处最大。令人惊讶的是，硬编码融合策略的表现优于学习型策略。

Conclusion: 多模态输入对于SatML模型的数据效率和样本外性能具有重要价值。简单的融合策略可能非常有效，这为未来的研究提供了有趣的启示。

Abstract: A large variety of geospatial data layers is available around the world
ranging from remotely-sensed raster data like satellite imagery, digital
elevation models, predicted land cover maps, and human-annotated data, to data
derived from environmental sensors such as air temperature or wind speed data.
A large majority of machine learning models trained on satellite imagery
(SatML), however, are designed primarily for optical input modalities such as
multi-spectral satellite imagery. To better understand the value of using other
input modalities alongside optical imagery in supervised learning settings, we
generate augmented versions of SatML benchmark tasks by appending additional
geographic data layers to datasets spanning classification, regression, and
segmentation. Using these augmented datasets, we find that fusing additional
geographic inputs with optical imagery can significantly improve SatML model
performance. Benefits are largest in settings where labeled data are limited
and in geographic out-of-sample settings, suggesting that multi-modal inputs
may be especially valuable for data-efficiency and out-of-sample performance of
SatML models. Surprisingly, we find that hard-coded fusion strategies
outperform learned variants, with interesting implications for future work.

</details>


### [33] [From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2507.13387)
*Chihiro Noguchi,Takaki Yamamoto*

Main category: cs.CV

TL;DR: 本文提出一个新框架，利用大规模二值占用数据（成本较低）进行预训练和自动标注，以提升3D语义占用预测的性能，尤其适用于视觉中心自动驾驶系统。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要精确的环境感知，其中3D语义占用预测对纯视觉系统尤为重要。然而，语义标签数据（需激光雷达标注）获取成本高昂。与之相对，大规模二值占用数据（仅区分占用/空闲，无语义标签）成本较低且可用，但其潜力尚未被充分利用。

Method: 研究从两个方面利用大规模二值占用数据：1) 预训练，2) 基于学习的自动标注。提出了一个新颖的基于二值占用的框架，将预测过程分解为二值占用模块和语义占用模块，从而有效利用二值占用数据。

Result: 实验结果表明，所提出的框架在预训练和自动标注任务中均优于现有方法，证明了其在增强3D语义占用预测方面的有效性。

Conclusion: 所提出的框架能够有效利用大规模二值占用数据，显著提升了3D语义占用预测的性能，为解决语义标签数据获取成本高的问题提供了有效途径。

Abstract: Accurate perception of the surrounding environment is essential for safe
autonomous driving. 3D occupancy prediction, which estimates detailed 3D
structures of roads, buildings, and other objects, is particularly important
for vision-centric autonomous driving systems that do not rely on LiDAR
sensors. However, in 3D semantic occupancy prediction -- where each voxel is
assigned a semantic label -- annotated LiDAR point clouds are required, making
data acquisition costly. In contrast, large-scale binary occupancy data, which
only indicate occupied or free space without semantic labels, can be collected
at a lower cost. Despite their availability, the potential of leveraging such
data remains unexplored. In this study, we investigate the utilization of
large-scale binary occupancy data from two perspectives: (1) pre-training and
(2) learning-based auto-labeling. We propose a novel binary occupancy-based
framework that decomposes the prediction process into binary and semantic
occupancy modules, enabling effective use of binary occupancy data. Our
experimental results demonstrate that the proposed framework outperforms
existing methods in both pre-training and auto-labeling tasks, highlighting its
effectiveness in enhancing 3D semantic occupancy prediction. The code is
available at https://github.com/ToyotaInfoTech/b2s-occupancy

</details>


### [34] [Minimalist Concept Erasure in Generative Models](https://arxiv.org/abs/2507.13386)
*Yang Zhang,Er Jin,Yanfei Dong,Yixuan Wu,Philip Torr,Ashkan Khakzar,Johannes Stegmaier,Kenji Kawaguchi*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的极简主义概念擦除方法，仅基于最终生成输出的分布距离来解决生成模型中的安全和版权问题。该方法通过端到端反向传播和神经元掩蔽，能够在不降低整体模型性能的情况下，鲁棒地擦除不需要的概念。


<details>
  <summary>Details</summary>
Motivation: 生成模型虽然能产生高质量图像，但其对大规模未标记数据的依赖引发了严重的安全和版权问题。现有擦除方法常导致过度修改，损害模型整体效用。

Method: 提出了一种基于最终生成输出分布距离的极简主义概念擦除目标。推导了一个可微分优化的可处理损失函数，通过端到端反向传播实现。为提高擦除的鲁棒性，引入了神经元掩蔽作为模型微调的替代方案。此外，还进行了理论分析以建立与其他模型和方法的联系。

Result: 在最先进的流匹配模型上进行了实证评估，结果表明所提出的方法能够鲁棒地擦除概念，且不降低模型整体性能。

Conclusion: 该方法为开发更安全、更负责任的生成模型铺平了道路，因为它能在不影响模型效用的前提下有效擦除有害概念。

Abstract: Recent advances in generative models have demonstrated remarkable
capabilities in producing high-quality images, but their reliance on
large-scale unlabeled data has raised significant safety and copyright
concerns. Efforts to address these issues by erasing unwanted concepts have
shown promise. However, many existing erasure methods involve excessive
modifications that compromise the overall utility of the model. In this work,
we address these issues by formulating a novel minimalist concept erasure
objective based \emph{only} on the distributional distance of final generation
outputs. Building on our formulation, we derive a tractable loss for
differentiable optimization that leverages backpropagation through all
generation steps in an end-to-end manner. We also conduct extensive analysis to
show theoretical connections with other models and methods. To improve the
robustness of the erasure, we incorporate neuron masking as an alternative to
model fine-tuning. Empirical evaluations on state-of-the-art flow-matching
models demonstrate that our method robustly erases concepts without degrading
overall model performance, paving the way for safer and more responsible
generative models.

</details>


### [35] [Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box](https://arxiv.org/abs/2507.13722)
*Julia Laubmann,Johannes Reschke*

Main category: cs.CV

TL;DR: 本研究深入分析了StyleGAN生成器的内部机制，通过权重修剪发现可显著减少计算需求，并揭示了潜在向量对生成人脸特征的精细控制能力，同时强调了该技术潜在的滥用风险。


<details>
  <summary>Details</summary>
Motivation: 在数字时代，AI生成图像（特别是StyleGAN生成的高度逼真人脸）带来的潜在危险日益受到关注。本研究旨在深入理解StyleGAN模型，特别是其生成器组件的内部工作原理。

Method: 详细探讨了StyleGAN的关键架构元素和技术，如Equalized Learning Rate。使用PyTorch框架训练StyleGAN模型，以便直接检查其学习到的权重。通过修剪（pruning）技术分析了权重的冗余性，并密切检查了潜在向量（latent vector）对生成图像的影响。

Result: 1. 发现StyleGAN的大量权重可以在不显著影响输出质量的情况下被移除，从而降低计算需求。2. 潜在向量对生成人脸的外观有显著影响：对该向量的全局改变主要影响色调，而对单个维度的有针对性改变则允许精确操纵特定的面部特征。

Conclusion: StyleGAN微调视觉特征的能力不仅具有学术价值，也带来了严重的伦理担忧。恶意行为者可能利用此技术伪造逼真的虚假身份，从而在数字欺诈和网络犯罪中构成重大风险。

Abstract: In today's digital age, concerns about the dangers of AI-generated images are
increasingly common. One powerful tool in this domain is StyleGAN (style-based
generative adversarial networks), a generative adversarial network capable of
producing highly realistic synthetic faces. To gain a deeper understanding of
how such a model operates, this work focuses on analyzing the inner workings of
StyleGAN's generator component. Key architectural elements and techniques, such
as the Equalized Learning Rate, are explored in detail to shed light on the
model's behavior. A StyleGAN model is trained using the PyTorch framework,
enabling direct inspection of its learned weights. Through pruning, it is
revealed that a significant number of these weights can be removed without
drastically affecting the output, leading to reduced computational
requirements. Moreover, the role of the latent vector -- which heavily
influences the appearance of the generated faces -- is closely examined. Global
alterations to this vector primarily affect aspects like color tones, while
targeted changes to individual dimensions allow for precise manipulation of
specific facial features. This ability to finetune visual traits is not only of
academic interest but also highlights a serious ethical concern: the potential
misuse of such technology. Malicious actors could exploit this capability to
fabricate convincing fake identities, posing significant risks in the context
of digital deception and cybercrime.

</details>


### [36] [InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2507.13397)
*Kaiyuan Zhai,Juan Chen,Chao Wang,Zeyi Xu*

Main category: cs.CV

TL;DR: 该研究提出了InSyn模型，一个基于Transformer的网络，用于准确预测行人轨迹，通过显式捕捉多样化的交互模式和方向敏感的社会行为。此外，还引入了SSOS训练策略来缓解时间序列预测中常见的初始步发散问题。


<details>
  <summary>Details</summary>
Motivation: 行人轨迹预测对智能应用至关重要，但由于行人之间复杂的交互而极具挑战性。现有方法主要依赖相对位置建模交互，但常忽略特定的交互模式（如结伴行走或冲突行为），导致在拥挤场景中预测精度受限。同时，数值时间序列预测普遍存在初始步发散问题。

Method: 提出InSyn（Interaction-Synchronization Network），一个基于Transformer的新模型，旨在显式捕捉多样化的交互模式（如同步行走或冲突）并有效建模方向敏感的社会行为。此外，引入了名为Seq-Start of Seq (SSOS) 的训练策略，旨在缓解数值时间序列预测中常见的初始步发散问题。

Result: 在ETH和UCY数据集上的实验表明，InSyn模型显著优于现有基线方法，尤其是在高密度场景中。SSOS策略也被证明能有效提升序列预测性能，将初始步预测误差降低了约6.58%。

Conclusion: InSyn模型通过有效捕捉行人多样化交互模式和方向敏感行为，显著提高了行人轨迹预测的准确性，尤其是在拥挤场景下。SSOS训练策略则有效解决了初始步发散问题，进一步提升了预测性能。

Abstract: Accurate pedestrian trajectory prediction is crucial for intelligent
applications, yet it remains highly challenging due to the complexity of
interactions among pedestrians. Previous methods have primarily relied on
relative positions to model pedestrian interactions; however, they tend to
overlook specific interaction patterns such as paired walking or conflicting
behaviors, limiting the prediction accuracy in crowded scenarios. To address
this issue, we propose InSyn (Interaction-Synchronization Network), a novel
Transformer-based model that explicitly captures diverse interaction patterns
(e.g., walking in sync or conflicting) while effectively modeling
direction-sensitive social behaviors. Additionally, we introduce a training
strategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue
of initial-step divergence in numerical time-series prediction. Experiments on
the ETH and UCY datasets demonstrate that our model outperforms recent
baselines significantly, especially in high-density scenarios. Furthermore, the
SSOS strategy proves effective in improving sequential prediction performance,
reducing the initial-step prediction error by approximately 6.58%.

</details>


### [37] [A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data](https://arxiv.org/abs/2507.13852)
*Luigi Russo,Francesco Mauro,Babak Memar,Alessandro Sebastianelli,Silvia Liberata Ullo,Paolo Gamba*

Main category: cs.CV

TL;DR: 本研究探索了将量子卷积预处理应用于注意力U-Net模型，以提高城市地区（突尼斯）利用SAR图像进行建筑物分割的能力，结果显示在保持准确性的同时显著减少了模型参数。


<details>
  <summary>Details</summary>
Motivation: 城市区域的建筑物分割对于城市规划、灾害响应和人口测绘至关重要。然而，由于卫星图像尺寸大、分辨率高，在密集城市区域准确分割建筑物面临挑战。

Method: 本研究采用量子卷积（Quanvolution）作为预处理步骤，以增强注意力U-Net模型进行建筑物分割的能力。具体来说，研究利用Sentinel-1合成孔径雷达（SAR）图像对突尼斯城市景观进行了研究。量子卷积用于提取更具信息量的特征图，以捕捉雷达图像中重要的结构细节。

Result: 初步结果表明，所提出的方法在测试准确性方面与标准注意力U-Net模型相当，但显著减少了网络参数。这一结果与以往研究的发现一致，证实了量子卷积不仅能保持模型准确性，还能提高计算效率。

Conclusion: 这些有前景的结果突显了量子辅助深度学习框架在城市环境中进行大规模建筑物分割的潜力。

Abstract: Building segmentation in urban areas is essential in fields such as urban
planning, disaster response, and population mapping. Yet accurately segmenting
buildings in dense urban regions presents challenges due to the large size and
high resolution of satellite images. This study investigates the use of a
Quanvolutional pre-processing to enhance the capability of the Attention U-Net
model in the building segmentation. Specifically, this paper focuses on the
urban landscape of Tunis, utilizing Sentinel-1 Synthetic Aperture Radar (SAR)
imagery. In this work, Quanvolution was used to extract more informative
feature maps that capture essential structural details in radar imagery,
proving beneficial for accurate building segmentation. Preliminary results
indicate that proposed methodology achieves comparable test accuracy to the
standard Attention U-Net model while significantly reducing network parameters.
This result aligns with findings from previous works, confirming that
Quanvolution not only maintains model accuracy but also increases computational
efficiency. These promising outcomes highlight the potential of
quantum-assisted Deep Learning frameworks for large-scale building segmentation
in urban environments.

</details>


### [38] [MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing](https://arxiv.org/abs/2507.13401)
*Shreya Kadambi,Risheek Garrepalli,Shubhankar Borse,Munawar Hyatt,Fatih Porikli*

Main category: cs.CV

TL;DR: 本文提出了MADI框架，通过引入双重损坏训练策略（MAgD）和推理时容量扩展机制（Pause Tokens），显著提升了扩散模型在接地视觉编辑和组合控制方面的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在文本到图像生成方面取得了显著成功，但在接地视觉编辑和组合控制方面仍面临挑战。研究动机来源于自监督学习和上下文生成建模的进展。

Method: 本文提出了MADI（Masking-Augmented Diffusion with Inference-Time Scaling）框架。核心创新包括：1. Masking-Augmented gaussian Diffusion (MAgD)：一种新颖的训练策略，结合了标准去噪分数匹配和通过掩蔽噪声输入进行的重建，旨在学习判别性和组合性视觉表示。2. 基于Pause Tokens的推理时容量扩展机制：在提示中插入特殊占位符以增加推理时的计算能力。此外，研究发现训练时使用表达性强且密集的提示能进一步提升性能。

Result: MADI框架下的贡献显著增强了扩散模型的编辑能力。特别地，采用表达性强且密集的提示在训练期间进一步提升了性能，尤其对MAgD效果显著。

Conclusion: MADI框架通过其创新设计，极大地提升了扩散模型的编辑能力，为将其集成到更通用、上下文感知的生成扩散架构中铺平了道路。

Abstract: Despite the remarkable success of diffusion models in text-to-image
generation, their effectiveness in grounded visual editing and compositional
control remains challenging. Motivated by advances in self-supervised learning
and in-context generative modeling, we propose a series of simple yet powerful
design choices that significantly enhance diffusion model capacity for
structured, controllable generation and editing. We introduce Masking-Augmented
Diffusion with Inference-Time Scaling (MADI), a framework that improves the
editability, compositionality and controllability of diffusion models through
two core innovations. First, we introduce Masking-Augmented gaussian Diffusion
(MAgD), a novel training strategy with dual corruption process which combines
standard denoising score matching and masked reconstruction by masking noisy
input from forward process. MAgD encourages the model to learn discriminative
and compositional visual representations, thus enabling localized and
structure-aware editing. Second, we introduce an inference-time capacity
scaling mechanism based on Pause Tokens, which act as special placeholders
inserted into the prompt for increasing computational capacity at inference
time. Our findings show that adopting expressive and dense prompts during
training further enhances performance, particularly for MAgD. Together, these
contributions in MADI substantially enhance the editability of diffusion
models, paving the way toward their integration into more general-purpose,
in-context generative diffusion architectures.

</details>


### [39] [UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data](https://arxiv.org/abs/2507.13403)
*Morteza Bodaghi,Majid Hosseini,Raju Gottumukkala,Ravi Teja Bhupatiraju,Iftikhar Ahmad,Moncef Gabbouj*

Main category: cs.CV

TL;DR: 该研究提出了一个综合性的公开数据集，用于驾驶员疲劳检测，整合了面部、行为和生物识别多模态信号，并记录了驾驶员疲劳状态的渐进变化。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶员疲劳检测数据集的局限性，促使研究者旨在创建一个更全面的多模态数据集，捕获更广泛的生理、行为和驾驶相关信号。

Method: 研究收集了19名受试者（15男，4女）在清醒和疲劳两种状态下的数据。数据采集在模拟驾驶环境中进行，使用深度摄像头、红外摄像头、后置视频、生物识别信号（心率、皮电活动、血氧饱和度、皮肤温度、加速度计）、方向盘握力传感器数据以及美国卡车模拟器游戏的遥测数据。疲劳程度每四分钟通过Karolinska嗜睡量表（KSS）自报。每个受试者的数据采集持续40分钟，总时长1400分钟，记录了驾驶员状态的渐进变化。

Result: 研究成功构建了一个1400分钟的连续多模态数据集，该数据集包含3D面部视频、红外视频、后置视频、多种生物识别信号、握力传感器数据和遥测数据。与现有数据集不同，该数据集记录了驾驶员状态的渐进变化而非离散的清醒/疲劳标签。

Conclusion: 该研究创建了一个全面、多模态的驾驶员疲劳数据集，能够捕获广泛的生理、行为和驾驶相关信号，并记录了疲劳状态的连续变化，有望成为相关领域研究的宝贵资源。

Abstract: In this study, we present a comprehensive public dataset for driver
drowsiness detection, integrating multimodal signals of facial, behavioral, and
biometric indicators. Our dataset includes 3D facial video using a depth
camera, IR camera footage, posterior videos, and biometric signals such as
heart rate, electrodermal activity, blood oxygen saturation, skin temperature,
and accelerometer data. This data set provides grip sensor data from the
steering wheel and telemetry data from the American truck simulator game to
provide more information about drivers' behavior while they are alert and
drowsy. Drowsiness levels were self-reported every four minutes using the
Karolinska Sleepiness Scale (KSS). The simulation environment consists of three
monitor setups, and the driving condition is completely like a car. Data were
collected from 19 subjects (15 M, 4 F) in two conditions: when they were fully
alert and when they exhibited signs of sleepiness. Unlike other datasets, our
multimodal dataset has a continuous duration of 40 minutes for each data
collection session per subject, contributing to a total length of 1,400
minutes, and we recorded gradual changes in the driver state rather than
discrete alert/drowsy labels. This study aims to create a comprehensive
multimodal dataset of driver drowsiness that captures a wider range of
physiological, behavioral, and driving-related signals. The dataset will be
available upon request to the corresponding author.

</details>


### [40] [AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation](https://arxiv.org/abs/2507.13404)
*Delin An,Pan Du,Jian-Xun Wang,Chaoli Wang*

Main category: cs.CV

TL;DR: AortaDiff是一个基于扩散模型的新框架，能直接从CT/MRI图像生成平滑且兼容CFD分析的3D主动脉表面模型，减少了对大量标注数据和手动干预的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的3D主动脉构建方法通常需要大量标注训练数据和广泛的手动干预，并且难以生成几何一致、适用于下游计算流体动力学（CFD）分析的表面，而精确的3D主动脉模型对临床诊断、术前规划和血流动力学参数估计至关重要。

Method: AortaDiff采用扩散模型框架：1. 利用体素引导条件扩散模型（CDM）从医学图像中迭代生成主动脉中心线。2. 每个中心线点自动作为提示，提取相应的血管轮廓，确保准确的边界描绘。3. 将提取的轮廓拟合为平滑的3D表面，生成连续、兼容CFD的网格表示。

Result: AortaDiff提供了端到端的工作流程，对大型标注数据集的依赖性最小，能够生成具有高几何保真度的CFD兼容主动脉网格。实验结果表明，即使在有限的训练数据下，AortaDiff也能有效工作，成功构建正常和病变（如动脉瘤或主动脉缩窄）主动脉网格，实现高质量可视化。

Conclusion: AortaDiff是一种实用的心血管研究解决方案，能够生成高保真、CFD兼容的3D主动脉模型，同时显著减少了对大量标注数据和手动干预的需求，即使面对病理情况也表现出色。

Abstract: Accurate 3D aortic construction is crucial for clinical diagnosis,
preoperative planning, and computational fluid dynamics (CFD) simulations, as
it enables the estimation of critical hemodynamic parameters such as blood flow
velocity, pressure distribution, and wall shear stress. Existing construction
methods often rely on large annotated training datasets and extensive manual
intervention. While the resulting meshes can serve for visualization purposes,
they struggle to produce geometrically consistent, well-constructed surfaces
suitable for downstream CFD analysis. To address these challenges, we introduce
AortaDiff, a diffusion-based framework that generates smooth aortic surfaces
directly from CT/MRI volumes. AortaDiff first employs a volume-guided
conditional diffusion model (CDM) to iteratively generate aortic centerlines
conditioned on volumetric medical images. Each centerline point is then
automatically used as a prompt to extract the corresponding vessel contour,
ensuring accurate boundary delineation. Finally, the extracted contours are
fitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh
representation. AortaDiff offers distinct advantages over existing methods,
including an end-to-end workflow, minimal dependency on large labeled datasets,
and the ability to generate CFD-compatible aorta meshes with high geometric
fidelity. Experimental results demonstrate that AortaDiff performs effectively
even with limited training data, successfully constructing both normal and
pathologically altered aorta meshes, including cases with aneurysms or
coarctation. This capability enables the generation of high-quality
visualizations and positions AortaDiff as a practical solution for
cardiovascular research.

</details>


### [41] [IConMark: Robust Interpretable Concept-Based Watermark For AI Images](https://arxiv.org/abs/2507.13407)
*Vinu Sankar Sadasivan,Mehrdad Saberi,Soheil Feizi*

Main category: cs.CV

TL;DR: IConMark是一种新颖的、可解释的、语义鲁棒的生成内水印方法，用于AI生成图像，旨在对抗虚假信息和提高数字真实性，其性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和合成媒体的快速兴起，区分AI生成图像和真实图像变得至关重要，以防范虚假信息并确保数字真实性。传统水印技术易受对抗性攻击，影响其有效性。

Method: 本文提出了IConMark，一种在生成过程中嵌入可解释概念的鲁棒语义水印方法。与传统添加噪声或扰动的方法不同，IConMark嵌入有意义的语义属性，使其对人类可解释，从而能够抵御对抗性操纵。该方法还可与现有水印技术（如StegaStamp和TrustMark）结合，形成混合方法（IConMark+SS和IConMark+TM）以进一步增强鲁棒性。

Result: IConMark在检测准确性和图像质量保持方面表现出优越性，且能抵抗各种图像增强。它具有人类可读性，支持手动验证水印。与最佳基线相比，IConMark及其变体（+TM和+SS）在不同数据集上的水印检测平均ROC曲线下面积（AUROC）分数分别高出10.8%、14.5%和15.9%。

Conclusion: IConMark是一种有效、鲁棒且可解释的AI生成图像语义水印方法，它通过嵌入可理解的概念，在保持图像质量的同时显著提高了水印检测的准确性，并能抵抗多种图像操作。其可解释性也为人为验证提供了可能。

Abstract: With the rapid rise of generative AI and synthetic media, distinguishing
AI-generated images from real ones has become crucial in safeguarding against
misinformation and ensuring digital authenticity. Traditional watermarking
techniques have shown vulnerabilities to adversarial attacks, undermining their
effectiveness in the presence of attackers. We propose IConMark, a novel
in-generation robust semantic watermarking method that embeds interpretable
concepts into AI-generated images, as a first step toward interpretable
watermarking. Unlike traditional methods, which rely on adding noise or
perturbations to AI-generated images, IConMark incorporates meaningful semantic
attributes, making it interpretable to humans and hence, resilient to
adversarial manipulation. This method is not only robust against various image
augmentations but also human-readable, enabling manual verification of
watermarks. We demonstrate a detailed evaluation of IConMark's effectiveness,
demonstrating its superiority in terms of detection accuracy and maintaining
image quality. Moreover, IConMark can be combined with existing watermarking
techniques to further enhance and complement its robustness. We introduce
IConMark+SS and IConMark+TM, hybrid approaches combining IConMark with
StegaStamp and TrustMark, respectively, to further bolster robustness against
multiple types of image manipulations. Our base watermarking technique
(IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9%
higher mean area under the receiver operating characteristic curve (AUROC)
scores for watermark detection, respectively, compared to the best baseline on
various datasets.

</details>


### [42] [COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark](https://arxiv.org/abs/2507.13405)
*Ishant Chintapatla,Kazuma Choji,Naaisha Agarwal,Andrew Lin,Hannah You,Charles Duong,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.CV

TL;DR: 现有视觉语言模型（VLMs）在视觉问答（VQA）方面表现良好，但在处理拥挤场景中的视觉蕴涵（visual entailment）任务时表现不佳，新提出的COREVQA基准揭示了这一局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在VQA基准上取得了显著进展，但现有基准很少测试模型准确完成视觉蕴涵的能力，特别是在具有挑战性的拥挤图像上。

Method: 提出了COREVQA（Crowd Observations and Reasoning Entailment）基准，包含5608对图像与合成生成的真/假陈述，图像来源于CrowdHuman数据集，旨在引发对拥挤图像的视觉蕴涵推理。

Result: 即使是表现最佳的VLMs在COREVQA上的准确率也低于80%，其他模型表现更差（39.98%-69.95%），这表明VLMs在拥挤场景中对特定类型图像-问题对的推理能力存在显著局限。

Conclusion: 视觉语言模型在处理复杂拥挤场景中的视觉蕴涵推理方面存在关键局限性，需要进一步改进。

Abstract: Recently, many benchmarks and datasets have been developed to evaluate
Vision-Language Models (VLMs) using visual question answering (VQA) pairs, and
models have shown significant accuracy improvements. However, these benchmarks
rarely test the model's ability to accurately complete visual entailment, for
instance, accepting or refuting a hypothesis based on the image. To address
this, we propose COREVQA (Crowd Observations and Reasoning Entailment), a
benchmark of 5608 image and synthetically generated true/false statement pairs,
with images derived from the CrowdHuman dataset, to provoke visual entailment
reasoning on challenging crowded images. Our results show that even the
top-performing VLMs achieve accuracy below 80%, with other models performing
substantially worse (39.98%-69.95%). This significant performance gap reveals
key limitations in VLMs' ability to reason over certain types of image-question
pairs in crowded scenes.

</details>


### [43] [A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs](https://arxiv.org/abs/2507.13408)
*Hemanth Kumar M,Karthika M,Saianiruth M,Vasanthakumar Venugopal,Anandakumar D,Revathi Ezhumalai,Charulatha K,Kishore Kumar J,Dayana G,Kalyan Sivasailam,Bargava Subramanian*

Main category: cs.CV

TL;DR: 本文开发了一种基于多模型深度学习集成系统，用于在肩部X光片中高精度检测骨折，以辅助早期诊断和减少漏诊。


<details>
  <summary>Details</summary>
Motivation: 肩部骨折在急诊和高流量临床环境中常被漏诊（放射科医生漏诊率高达10%），导致诊断延迟。研究旨在通过AI工具解决这一问题，实现早期检测。

Method: 研究开发了一个多模型深度学习系统，使用了10,000张标注的肩部X光片进行训练。采用的架构包括Faster R-CNN (ResNet50-FPN, ResNeXt)、EfficientDet和RF-DETR。为提高检测性能，应用了边界框和分类级别的集成技术，如Soft-NMS、WBF和NMW融合。

Result: NMW集成方法实现了95.5%的准确率和0.9610的F1分数，在所有关键指标上均优于单一模型。该方法在召回率和定位精度方面表现出色，证实了其在肩部X光片临床骨折检测中的有效性。

Conclusion: 基于集成的AI系统能够可靠地检测X光片中的肩部骨折，具有高度临床相关性。该模型的高准确性和部署准备度使其非常适合集成到实时诊断工作流程中，用于快速筛查和分诊支持（目前仅限于二元骨折检测，而非详细分类）。

Abstract: Background: Shoulder fractures are often underdiagnosed, especially in
emergency and high-volume clinical settings. Studies report up to 10% of such
fractures may be missed by radiologists. AI-driven tools offer a scalable way
to assist early detection and reduce diagnostic delays. We address this gap
through a dedicated AI system for shoulder radiographs. Methods: We developed a
multi-model deep learning system using 10,000 annotated shoulder X-rays.
Architectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and
RF-DETR. To enhance detection, we applied bounding box and classification-level
ensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW
ensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming
individual models across all key metrics. It demonstrated strong recall and
localization precision, confirming its effectiveness for clinical fracture
detection in shoulder X-rays. Conclusion: The results show ensemble-based AI
can reliably detect shoulder fractures in radiographs with high clinical
relevance. The model's accuracy and deployment readiness position it well for
integration into real-time diagnostic workflows. The current model is limited
to binary fracture detection, reflecting its design for rapid screening and
triage support rather than detailed orthopedic classification.

</details>


### [44] [AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery](https://arxiv.org/abs/2507.13420)
*Alessandro Pistola,Valentina Orru',Nicolo' Marchetti,Marco Roccetti*

Main category: cs.CV

TL;DR: 通过使用CORONA历史卫星图像重新训练深度学习模型，研究人员显著提高了在已完全转变的景观中自动识别考古遗址的准确性，并成功发现了新的遗址。


<details>
  <summary>Details</summary>
Motivation: 在过去五十年中，由于人类活动（anthropization）导致许多考古遗址被完全破坏或不再可见，传统考古技术难以识别这些遗址。研究旨在利用AI模型克服这一挑战。

Method: 研究人员升级了一个现有的基于Bing的卷积神经网络模型，并使用1960年代的CORONA卫星图像对该模型进行了再训练，目标区域是巴格达以西的阿布格莱布区。

Result: 结果令人惊喜：1. 模型检测精度显著提高，图像分割级别的IoU值超过85%，考古遗址检测的总体准确率达到90%。2. 再训练后的模型识别出四个新的考古遗址，这些遗址此前未被考古学家通过传统技术发现，并已通过实地验证确认。

Conclusion: 研究证实了结合AI技术和1960年代CORONA图像在发现目前已不可见的考古遗址方面的有效性，这对于研究因人类活动导致考古证据消失的景观具有重要突破性意义。

Abstract: By upgrading an existing deep learning model with the knowledge provided by
one of the oldest sets of grayscale satellite imagery, known as CORONA, we
improved the AI model attitude towards the automatic identification of
archaeological sites in an environment which has been completely transformed in
the last five decades, including the complete destruction of many of those same
sites. The initial Bing based convolutional network model was retrained using
CORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,
central Mesopotamian floodplain. The results were twofold and surprising.
First, the detection precision obtained on the area of interest increased
sensibly: in particular, the Intersection over Union (IoU) values, at the image
segmentation level, surpassed 85 percent, while the general accuracy in
detecting archeological sites reached 90 percent. Second, our retrained model
allowed the identification of four new sites of archaeological interest
(confirmed through field verification), previously not identified by
archaeologists with traditional techniques. This has confirmed the efficacy of
using AI techniques and the CORONA imagery from the 1960 to discover
archaeological sites currently no longer visible, a concrete breakthrough with
significant consequences for the study of landscapes with vanishing
archaeological evidence induced by anthropization

</details>


### [45] [CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction](https://arxiv.org/abs/2507.13425)
*Sirui Wang,Zhou Guan,Bingxi Zhao,Tongjia Gu*

Main category: cs.CV

TL;DR: CaSTFormer是一种因果时空Transformer模型，通过明确建模驾驶员行为和环境背景之间的因果关系，提高了驾驶意图预测的准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 当前的驾驶意图预测方法在准确建模复杂时空相互依赖性和人类驾驶行为的不可预测变异性方面存在不足，而准确的驾驶意图预测对提升人机共驾系统的安全性和交互效率至关重要。

Method: 本文提出了CaSTFormer模型，其中包含：1) 互惠偏移融合（RSF）机制，用于精确对齐内部和外部特征流；2) 因果模式提取（CPE）模块，系统性地消除虚假关联以揭示真实的因果依赖；3) 特征合成网络（FSN），自适应地将净化后的表示合成为连贯的时空推断。

Result: CaSTFormer在公开的Brain4Cars数据集上取得了最先进的性能，有效地捕捉了复杂的因果时空依赖关系，并显著提升了驾驶意图预测的准确性和透明度。

Conclusion: CaSTFormer通过显式建模驾驶员行为与环境背景之间的因果交互，成功解决了现有方法在驾驶意图预测中的挑战，为高水平自动驾驶奠定了基础。

Abstract: Accurate prediction of driving intention is key to enhancing the safety and
interactive efficiency of human-machine co-driving systems. It serves as a
cornerstone for achieving high-level autonomous driving. However, current
approaches remain inadequate for accurately modeling the complex
spatio-temporal interdependencies and the unpredictable variability of human
driving behavior. To address these challenges, we propose CaSTFormer, a Causal
Spatio-Temporal Transformer to explicitly model causal interactions between
driver behavior and environmental context for robust intention prediction.
Specifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)
mechanism for precise temporal alignment of internal and external feature
streams, a Causal Pattern Extraction (CPE) module that systematically
eliminates spurious correlations to reveal authentic causal dependencies, and
an innovative Feature Synthesis Network (FSN) that adaptively synthesizes these
purified representations into coherent spatio-temporal inferences. We evaluate
the proposed CaSTFormer on the public Brain4Cars dataset, and it achieves
state-of-the-art performance. It effectively captures complex causal
spatio-temporal dependencies and enhances both the accuracy and transparency of
driving intention prediction.

</details>


### [46] ["PhyWorldBench": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models](https://arxiv.org/abs/2507.13428)
*Jing Gu,Xian Liu,Yu Zeng,Ashwin Nagarajan,Fangrui Zhu,Daniel Hong,Yue Fan,Qianqi Yan,Kaiwen Zhou,Ming-Yu Liu,Xin Eric Wang*

Main category: cs.CV

TL;DR: 本文提出了PhyWorldBench，一个全面的基准，用于评估视频生成模型在遵循物理定律方面的能力。通过对12个SOTA模型进行评估，识别了模型在物理模拟方面面临的关键挑战，并提供了提示工程建议。


<details>
  <summary>Details</summary>
Motivation: 视频生成模型在生成高质量、逼真内容方面取得了显著进展，但其准确模拟物理现象的能力仍是一个关键且未解决的挑战。

Method: 提出了PhyWorldBench基准，涵盖从基本物理原理到复杂交互场景，并引入“反物理”类别。评估方法包括大规模人工评估和基于MLLM的零样本评估。对12个最先进的文本到视频生成模型（包括开源和专有模型）进行了系统测试，使用了1050个精心策划的提示。

Result: 识别了视频生成模型在遵循现实世界物理方面面临的关键挑战。通过对不同物理现象和提示类型的性能进行严格审查，得出了提高物理保真度的提示工程建议。

Conclusion: 视频生成模型在准确模拟物理现象方面仍存在重大挑战。PhyWorldBench基准和评估结果揭示了这些挑战，并为未来模型改进和提示优化提供了有价值的见解和方向。

Abstract: Video generation models have achieved remarkable progress in creating
high-quality, photorealistic content. However, their ability to accurately
simulate physical phenomena remains a critical and unresolved challenge. This
paper presents PhyWorldBench, a comprehensive benchmark designed to evaluate
video generation models based on their adherence to the laws of physics. The
benchmark covers multiple levels of physical phenomena, ranging from
fundamental principles like object motion and energy conservation to more
complex scenarios involving rigid body interactions and human or animal motion.
Additionally, we introduce a novel ""Anti-Physics"" category, where prompts
intentionally violate real-world physics, enabling the assessment of whether
models can follow such instructions while maintaining logical consistency.
Besides large-scale human evaluation, we also design a simple yet effective
method that could utilize current MLLM to evaluate the physics realism in a
zero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation
models, including five open-source and five proprietary models, with a detailed
comparison and analysis. we identify pivotal challenges models face in adhering
to real-world physics. Through systematic testing of their outputs across 1,050
curated prompts-spanning fundamental, composite, and anti-physics scenarios-we
identify pivotal challenges these models face in adhering to real-world
physics. We then rigorously examine their performance on diverse physical
phenomena with varying prompt types, deriving targeted recommendations for
crafting prompts that enhance fidelity to physical principles.

</details>


### [47] [When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework](https://arxiv.org/abs/2507.13659)
*Xiao Wang,Qian Zhu,Shujuan Wu,Bo Jiang,Shiliang Zhang,Yaowei Wang,Yonghong Tian,Bin Luo*

Main category: cs.CV

TL;DR: 该论文提出了一个大规模RGB-事件行人重识别数据集EvReID，并提出了一个名为TriPro-ReID的行人属性引导对比学习框架，以解决数据稀缺性问题并增强特征学习。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件相机的行人重识别算法主要在小规模或模拟数据集上训练和评估，难以准确评估其实际识别性能和泛化能力，存在数据稀缺性问题。

Method: 1. 构建并发布了大规模RGB-事件行人重识别数据集EvReID，包含118,988对图像和1200个行人身份，覆盖多种季节、场景和光照条件。2. 在EvReID数据集上评估了15种最先进的行人重识别算法。3. 提出了一种名为TriPro-ReID的行人属性引导对比学习框架，该框架有效融合了RGB帧和事件流的视觉特征，并充分利用行人属性作为中级语义特征。

Result: 1. EvReID数据集的构建为未来RGB-事件行人重识别研究奠定了数据和基准基础。2. 所提出的TriPro-ReID框架能够有效探索RGB帧和事件流的视觉特征，并充分利用行人属性。3. 在EvReID和MARS数据集上的大量实验验证了所提出的RGB-事件行人重识别框架的有效性。

Conclusion: 该论文通过提供大规模数据集和提出的新型框架，显著推动了RGB-事件行人重识别领域的研究，解决了数据稀缺问题并提升了特征学习能力。

Abstract: Recent researchers have proposed using event cameras for person
re-identification (ReID) due to their promising performance and better balance
in terms of privacy protection, event camera-based person ReID has attracted
significant attention. Currently, mainstream event-based person ReID algorithms
primarily focus on fusing visible light and event stream, as well as preserving
privacy. Although significant progress has been made, these methods are
typically trained and evaluated on small-scale or simulated event camera
datasets, making it difficult to assess their real identification performance
and generalization ability. To address the issue of data scarcity, this paper
introduces a large-scale RGB-event based person ReID dataset, called EvReID.
The dataset contains 118,988 image pairs and covers 1200 pedestrian identities,
with data collected across multiple seasons, scenes, and lighting conditions.
We also evaluate 15 state-of-the-art person ReID algorithms, laying a solid
foundation for future research in terms of both data and benchmarking. Based on
our newly constructed dataset, this paper further proposes a pedestrian
attribute-guided contrastive learning framework to enhance feature learning for
person re-identification, termed TriPro-ReID. This framework not only
effectively explores the visual features from both RGB frames and event
streams, but also fully utilizes pedestrian attributes as mid-level semantic
features. Extensive experiments on the EvReID dataset and MARS datasets fully
validated the effectiveness of our proposed RGB-Event person ReID framework.
The benchmark dataset and source code will be released on
https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [48] [Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation](https://arxiv.org/abs/2507.13486)
*Debao Huang,Rongjun Qin*

Main category: cs.CV

TL;DR: 本文提出一个光度测量不确定性量化框架，通过为每个点关联误差协方差矩阵来解决多视图立体（MVS）阶段的不确定性估计难题，该方法自校准且性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 机载LiDAR通常提供一致的精度，而摄影测量点云的精度高度依赖场景，且其误差通过SfM和MVS两步传播。SfM阶段的不确定性已得到充分研究，但MVS阶段的不确定性估计仍未解决且缺乏标准化，主要原因在于其不可微和多模态特性。

Method: 本文提出一种不确定性量化框架，为每个点关联一个误差协方差矩阵，以解释两步摄影测量过程。具体地，为估计MVS阶段的不确定性，提出一种新颖的自校准方法，通过利用每视图可靠的n视图点（n>=6）并结合MVS阶段的相关线索（如匹配成本值）来回归视差不确定性。该方法从MVS过程中直接提取自包含的可靠3D点，具有自监督和遵循误差传播路径的优点。

Result: 该框架在多种公开的机载和无人机图像数据集上进行了评估。结果表明，本文方法在不夸大不确定性的前提下，实现了高边界率，优于现有方法。

Conclusion: 本文提出的不确定性量化框架通过解决MVS阶段的不确定性估计问题，为摄影测量过程提供了鲁棒且可认证的跨场景不确定性量化能力。

Abstract: Uncertainty quantification of the photogrammetry process is essential for
providing per-point accuracy credentials of the point clouds. Unlike airborne
LiDAR, which typically delivers consistent accuracy across various scenes, the
accuracy of photogrammetric point clouds is highly scene-dependent, since it
relies on algorithm-generated measurements (i.e., stereo or multi-view stereo).
Generally, errors of the photogrammetric point clouds propagate through a
two-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),
followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM
stage has been well studied using the first-order statistics of the
reprojection error function, that in the MVS stage remains largely unsolved and
non-standardized, primarily due to its non-differentiable and multi-modal
nature (i.e., from pixel values to geometry). In this paper, we present an
uncertainty quantification framework closing this gap by associating an error
covariance matrix per point accounting for this two-step photogrammetry
process. Specifically, to estimate the uncertainty in the MVS stage, we propose
a novel, self-calibrating method by taking reliable n-view points (n>=6)
per-view to regress the disparity uncertainty using highly relevant cues (such
as matching cost values) from the MVS stage. Compared to existing approaches,
our method uses self-contained, reliable 3D points extracted directly from the
MVS process, with the benefit of being self-supervised and naturally adhering
to error propagation path of the photogrammetry process, thereby providing a
robust and certifiable uncertainty quantification across diverse scenes. We
evaluate the framework using a variety of publicly available airborne and UAV
imagery datasets. Results demonstrate that our method outperforms existing
approaches by achieving high bounding rates without overestimating uncertainty.

</details>


### [49] [HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors](https://arxiv.org/abs/2507.13677)
*Chuheng Wei,Ziye Qin,Walter Zimmer,Guoyuan Wu,Matthew J. Barth*

Main category: cs.CV

TL;DR: HeCoFuse是一种统一的V2X协同感知框架，旨在解决异构传感器配置下的挑战，通过分层融合和自适应空间分辨率调整，在TUMTraf-V2X数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的V2X协同感知系统常因成本和部署差异而采用异构传感器配置（如仅摄像头、仅激光雷达或两者兼有），这给特征融合和感知可靠性带来了巨大挑战。

Method: 该论文提出了HeCoFuse框架，采用以下方法：1) 引入分层融合机制，通过通道和空间注意力自适应地加权特征，以解决跨模态特征不对齐和表示质量不平衡问题。2) 采用自适应空间分辨率调整模块，平衡计算成本和融合效果。3) 实现协同学习策略，根据可用模态动态调整融合类型，增强不同配置下的鲁棒性。

Result: 在TUMTraf-V2X数据集上的实验表明，HeCoFuse在全传感器配置（LC+LC）下实现了43.22%的3D mAP，比基线CoopDet3D高出1.17%。在L+LC场景下达到更高的43.38%的3D mAP。在九种异构传感器配置下，3D mAP保持在21.74%至43.38%的范围内。该成果在CVPR 2025 DriveX挑战赛中获得第一名。

Conclusion: HeCoFuse是目前TUM-Traf V2X数据集上的最先进方法，在各种异构传感器部署中展现出强大的鲁棒性能，有效解决了异构V2X协同感知中的关键挑战。

Abstract: Real-world Vehicle-to-Everything (V2X) cooperative perception systems often
operate under heterogeneous sensor configurations due to cost constraints and
deployment variability across vehicles and infrastructure. This heterogeneity
poses significant challenges for feature fusion and perception reliability. To
address these issues, we propose HeCoFuse, a unified framework designed for
cooperative perception across mixed sensor setups where nodes may carry Cameras
(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that
adaptively weights features through a combination of channel-wise and spatial
attention, HeCoFuse can tackle critical challenges such as cross-modality
feature misalignment and imbalanced representation quality. In addition, an
adaptive spatial resolution adjustment module is employed to balance
computational cost and fusion effectiveness. To enhance robustness across
different configurations, we further implement a cooperative learning strategy
that dynamically adjusts fusion type based on available modalities. Experiments
on the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%
3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D
baseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC
scenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine
heterogeneous sensor configurations. These results, validated by our
first-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the
current state-of-the-art on TUM-Traf V2X dataset while demonstrating robust
performance across diverse sensor deployments.

</details>


### [50] [Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2507.13857)
*Max van den Hoven,Kishaan Jeeveswaran,Pieter Piscaer,Thijs Wensveen,Elahe Arani,Bahram Zonooz*

Main category: cs.CV

TL;DR: Depth3DLane是一种新的单目3D车道线检测框架，它通过集成自监督深度估计和双路径结构，在无需昂贵传感器或深度真值数据的情况下提供明确的空间信息，并能处理未知相机参数。


<details>
  <summary>Details</summary>
Motivation: 单目3D车道线检测因缺乏显式空间信息而具有挑战性。现有方法要么依赖昂贵的深度传感器，要么需要难以大规模收集的深度真值数据。此外，它们通常假设相机参数已知，这限制了其在众包高清车道图等场景中的应用。

Method: Depth3DLane是一个双路径框架，集成了自监督单目深度估计以提供显式结构信息。它利用自监督深度网络获取场景点云表示，并通过鸟瞰图路径提取显式空间信息，同时通过前视图路径提取丰富的语义信息。该方法使用3D车道锚点从两条路径中采样特征以推断准确的3D车道几何。此外，它扩展了框架以逐帧预测相机参数，并引入了理论驱动的拟合过程以增强逐段稳定性。

Result: Depth3DLane在OpenLane基准数据集上取得了有竞争力的性能。实验结果表明，使用学习到的参数而非真值参数，Depth3DLane可以在相机校准不可行的情况下应用，这是以往方法无法实现的。

Conclusion: Depth3DLane通过结合自监督深度估计和相机参数预测，克服了单目3D车道线检测的现有局限性，提供了一种无需昂贵传感器、深度真值数据且适用于未知相机参数场景的实用解决方案。

Abstract: Monocular 3D lane detection is essential for autonomous driving, but
challenging due to the inherent lack of explicit spatial information.
Multi-modal approaches rely on expensive depth sensors, while methods
incorporating fully-supervised depth networks rely on ground-truth depth data
that is impractical to collect at scale. Additionally, existing methods assume
that camera parameters are available, limiting their applicability in scenarios
like crowdsourced high-definition (HD) lane mapping. To address these
limitations, we propose Depth3DLane, a novel dual-pathway framework that
integrates self-supervised monocular depth estimation to provide explicit
structural information, without the need for expensive sensors or additional
ground-truth depth data. Leveraging a self-supervised depth network to obtain a
point cloud representation of the scene, our bird's-eye view pathway extracts
explicit spatial information, while our front view pathway simultaneously
extracts rich semantic information. Depth3DLane then uses 3D lane anchors to
sample features from both pathways and infer accurate 3D lane geometry.
Furthermore, we extend the framework to predict camera parameters on a
per-frame basis and introduce a theoretically motivated fitting procedure to
enhance stability on a per-segment basis. Extensive experiments demonstrate
that Depth3DLane achieves competitive performance on the OpenLane benchmark
dataset. Furthermore, experimental results show that using learned parameters
instead of ground-truth parameters allows Depth3DLane to be applied in
scenarios where camera calibration is infeasible, unlike previous methods.

</details>


### [51] [Sugar-Beet Stress Detection using Satellite Image Time Series](https://arxiv.org/abs/2507.13514)
*Bhumika Laxman Sadbhave,Philipp Vaeth,Denise Dejon,Gunther Schorcht,Magda Gregorová*

Main category: cs.CV

TL;DR: 本研究提出了一种基于3D卷积自编码器的无监督方法，利用Sentinel-2卫星图像时间序列数据检测甜菜田的胁迫。


<details>
  <summary>Details</summary>
Motivation: 卫星图像时间序列数据在农业任务中表现出有效性，但甜菜田胁迫检测仍需更实用和可访问的工具，尤其是无监督方法。

Method: 核心方法是一个3D卷积自编码器模型，用于从Sentinel-2图像序列中提取特征，并结合采集日期特定的时间编码以捕捉甜菜生长动态。提取的特征随后用于下游聚类任务，区分受胁迫和健康的田地。

Result: 开发出的胁迫检测系统可以直接应用于不同年份的数据，能够有效区分受胁迫和健康的甜菜田。

Conclusion: 该研究提供了一个实用且易于访问的甜菜胁迫检测工具，其无监督特性和跨年份适用性使其具有很高的应用价值。

Abstract: Satellite Image Time Series (SITS) data has proven effective for agricultural
tasks due to its rich spectral and temporal nature. In this study, we tackle
the task of stress detection in sugar-beet fields using a fully unsupervised
approach. We propose a 3D convolutional autoencoder model to extract meaningful
features from Sentinel-2 image sequences, combined with
acquisition-date-specific temporal encodings to better capture the growth
dynamics of sugar-beets. The learned representations are used in a downstream
clustering task to separate stressed from healthy fields. The resulting stress
detection system can be directly applied to data from different years, offering
a practical and accessible tool for stress detection in sugar-beets.

</details>


### [52] [Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2507.13739)
*Junsu Kim,Yunhoe Ku,Seungryul Baek*

Main category: cs.CV

TL;DR: 该论文提出Diffusion-FSCIL，一种利用预训练文本到图像扩散模型作为冻结骨干网络，通过提取多尺度扩散特征进行潜在回放和特征蒸馏，以解决小样本类增量学习（FSCIL）中的灾难性遗忘和数据稀缺问题，并实现了优于现有技术水平的性能。


<details>
  <summary>Details</summary>
Motivation: 小样本类增量学习（FSCIL）面临巨大挑战，主要原因在于训练数据极其有限，同时需要有效减少灾难性遗忘并学习新信息。

Method: 本文提出Diffusion-FSCIL方法，核心是使用一个冻结的文本到图像扩散模型作为骨干网络。该方法利用大型生成模型的能力，包括其大规模预训练带来的生成能力、多尺度表示以及通过文本编码器实现的表示灵活性。为最大化表示能力，模型提取多个互补的扩散特征作为潜在回放，并辅以特征蒸馏以防止生成偏差。该框架通过使用冻结骨干、最少可训练组件和批量处理多特征提取实现高效性。

Result: 在CUB-200、miniImageNet和CIFAR-100上的大量实验表明，Diffusion-FSCIL超越了现有最先进的方法，成功保持了对先前学习类的性能，并有效适应了新类别。

Conclusion: 利用大型预训练文本到图像扩散模型作为冻结骨干，通过提取多尺度特征并结合潜在回放和特征蒸馏，可以有效解决FSCIL中的数据稀缺和灾难性遗忘问题，实现卓越的性能和效率。

Abstract: Few-shot class-incremental learning (FSCIL) is challenging due to extremely
limited training data; while aiming to reduce catastrophic forgetting and learn
new information. We propose Diffusion-FSCIL, a novel approach that employs a
text-to-image diffusion model as a frozen backbone. Our conjecture is that
FSCIL can be tackled using a large generative model's capabilities benefiting
from 1) generation ability via large-scale pre-training; 2) multi-scale
representation; 3) representational flexibility through the text encoder. To
maximize the representation capability, we propose to extract multiple
complementary diffusion features to play roles as latent replay with slight
support from feature distillation for preventing generative biases. Our
framework realizes efficiency through 1) using a frozen backbone; 2) minimal
trainable components; 3) batch processing of multiple feature extractions.
Extensive experiments on CUB-200, \emph{mini}ImageNet, and CIFAR-100 show that
Diffusion-FSCIL surpasses state-of-the-art methods, preserving performance on
previously learned classes and adapting effectively to new ones.

</details>


### [53] [SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM](https://arxiv.org/abs/2507.13527)
*Levi Harris,Md Jayed Hossain,Mufan Qiu,Ruichen Zhang,Pingchuan Ma,Tianlong Chen,Jiaqi Gu,Seth Ariel Tongay,Umberto Celano*

Main category: cs.CV

TL;DR: 该研究提出SparseC-AFM，一个深度学习模型，能从稀疏的导电原子力显微镜（C-AFM）扫描数据中快速准确地重建二维材料（如MoS2）的导电率图，显著缩短了材料表征时间。


<details>
  <summary>Details</summary>
Motivation: 纳米电子学中二维材料的使用日益增加，需要鲁棒的电学表征计量技术，尤其是在大规模生产中。传统的C-AFM技术虽然精度高，但由于光栅扫描过程导致数据采集速度慢。

Method: 引入SparseC-AFM，一个深度学习模型，用于从稀疏的C-AFM扫描数据中快速准确地重建二维材料的导电率图。该方法在各种扫描模式、衬底和实验条件下均表现出鲁棒性。

Result: 与传统方法相比，SparseC-AFM将数据采集时间缩短了超过11倍（例如，从15分钟缩短到5分钟以下）。该模型能够高效提取MoS2的关键材料参数，包括薄膜覆盖率、缺陷密度以及晶岛边界、边缘和裂纹的识别。模型预测的样本与全分辨率数据表现出非常相似的电学特性。

Conclusion: 这项工作代表了将人工智能辅助的二维材料表征从实验室研究转化为工业制造的重要一步。

Abstract: The increasing use of two-dimensional (2D) materials in nanoelectronics
demands robust metrology techniques for electrical characterization, especially
for large-scale production. While atomic force microscopy (AFM) techniques like
conductive AFM (C-AFM) offer high accuracy, they suffer from slow data
acquisition speeds due to the raster scanning process. To address this, we
introduce SparseC-AFM, a deep learning model that rapidly and accurately
reconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM
scans. Our approach is robust across various scanning modes, substrates, and
experimental conditions. We report a comparison between (a) classic flow
implementation, where a high pixel density C-AFM image (e.g., 15 minutes to
collect) is manually parsed to extract relevant material parameters, and (b)
our SparseC-AFM method, which achieves the same operation using data that
requires substantially less acquisition time (e.g., under 5 minutes).
SparseC-AFM enables efficient extraction of critical material parameters in
MoS$_2$, including film coverage, defect density, and identification of
crystalline island boundaries, edges, and cracks. We achieve over 11x reduction
in acquisition time compared to manual extraction from a full-resolution C-AFM
image. Moreover, we demonstrate that our model-predicted samples exhibit
remarkably similar electrical properties to full-resolution data gathered using
classic-flow scanning. This work represents a significant step toward
translating AI-assisted 2D material characterization from laboratory research
to industrial fabrication. Code and model weights are available at
github.com/UNITES-Lab/sparse-cafm.

</details>


### [54] [Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction](https://arxiv.org/abs/2507.13769)
*Mingyang Yu,Zhijian Wu,Dingjiang Huang*

Main category: cs.CV

TL;DR: 该论文提出一种基于扩散模型的频谱扩散先验（SDP）和频谱先验注入模块（SPIM），以解决高光谱图像（HSI）重建中高频细节恢复不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的高光谱图像（HSI）重建方法难以准确捕捉高光谱图像的高频细节。

Method: 本文提出了一种从高光谱图像中隐式学习的频谱扩散先验（SDP），利用扩散模型强大的细节重建能力。为进一步提高学习到的先验的有效性，还提出了频谱先验注入模块（SPIM），用于动态引导模型恢复HSI细节。该方法在MST和BISRNet两种代表性HSI方法上进行了评估。

Result: 实验结果表明，该方法比现有网络性能提高了约0.5 dB，有效提升了高光谱图像重建的性能。

Conclusion: 通过引入基于扩散模型的频谱扩散先验和频谱先验注入模块，可以显著提高高光谱图像重建中高频细节的恢复能力，从而提升整体性能。

Abstract: Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its
degraded 2D measurements. Recently great progress has been made in deep
learning-based methods, however, these methods often struggle to accurately
capture high-frequency details of the HSI. To address this issue, this paper
proposes a Spectral Diffusion Prior (SDP) that is implicitly learned from
hyperspectral images using a diffusion model. Leveraging the powerful ability
of the diffusion model to reconstruct details, this learned prior can
significantly improve the performance when injected into the HSI model. To
further improve the effectiveness of the learned prior, we also propose the
Spectral Prior Injector Module (SPIM) to dynamically guide the model to recover
the HSI details. We evaluate our method on two representative HSI methods: MST
and BISRNet. Experimental results show that our method outperforms existing
networks by about 0.5 dB, effectively improving the performance of HSI
reconstruction.

</details>


### [55] [Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising](https://arxiv.org/abs/2507.13530)
*Lukas Baumgärtner,Ronny Bergmann,Roland Herzog,Stephan Schmidt,Manuel Weiß*

Main category: cs.CV

TL;DR: 本文提出了一种针对三维网格上法向量的二阶全广义变分（TGV）新公式，通过构建定制的切向Raviart-Thomas型有限元空间，将TGV扩展到流形值函数，并应用于网格去噪。


<details>
  <summary>Details</summary>
Motivation: 现有离散TGV模型主要针对分段常数标量数据，并利用Raviart-Thomas函数空间。本研究旨在将TGV公式扩展到处理流形值数据（如单位球上的法向量）。

Method: 提出了一种新颖的二阶全广义变分（TGV）公式，用于R3中定向三角网格上的法向量。将法向量视为流形值函数，取值于单位球。为此，构建了一个定制的切向Raviart-Thomas型有限元空间。新正则化器在网格去噪实验中与现有方法进行了比较。

Result: 所提出的新正则化器在网格去噪实验中与现有方法进行了比较，表明了其在处理网格法向量去噪问题上的适用性和有效性。

Conclusion: 成功开发了一种新的TGV公式，能够处理嵌入在R3中的定向三角网格上的流形值法向量，并通过构建专门的有限元空间实现了这一扩展，为网格去噪提供了有效的新工具。

Abstract: We propose a novel formulation for the second-order total generalized
variation (TGV) of the normal vector on an oriented, triangular mesh embedded
in $\mathbb{R}^3$. The normal vector is considered as a manifold-valued
function, taking values on the unit sphere. Our formulation extends previous
discrete TGV models for piecewise constant scalar data that utilize a
Raviart-Thomas function space. To exctend this formulation to the manifold
setting, a tailor-made tangential Raviart-Thomas type finite element space is
constructed in this work. The new regularizer is compared to existing methods
in mesh denoising experiments.

</details>


### [56] [Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI](https://arxiv.org/abs/2507.13789)
*Kyriakos Flouris,Moritz Halter,Yolanne Y. R. Lee,Samuel Castonguay,Luuk Jacobs,Pietro Dirix,Jonathan Nestmann,Sebastian Kozerke,Ender Konukoglu*

Main category: cs.CV

TL;DR: 本文提出LoFNO，一种新型3D傅里叶神经算子，用于提高磁共振血流图像的时空分辨率和信噪比，并直接预测壁面剪切应力，从而实现更精确的脑血管诊断。


<details>
  <summary>Details</summary>
Motivation: 磁共振血流成像的时空分辨率和信噪比较低，限制了其在动脉瘤破裂预测和治疗指导中的诊断效用，而血流动力学分析对此至关重要。

Method: LoFNO是一种新颖的3D架构，它将拉普拉斯特征向量作为几何先验以增强对不规则几何结构的感知，并采用增强型深度超分辨率网络（EDSR）层进行鲁棒的上采样。通过结合几何先验和神经算子框架，LoFNO对血流数据进行去噪和时空超分辨率处理。

Result: LoFNO在速度和壁面剪切应力预测方面优于传统的插值方法和替代的深度学习方法。

Conclusion: LoFNO通过提高临床成像数据的分辨率和直接预测壁面剪切应力，能够实现更精确的脑血管诊断。

Abstract: Hemodynamic analysis is essential for predicting aneurysm rupture and guiding
treatment. While magnetic resonance flow imaging enables time-resolved
volumetric blood velocity measurements, its low spatiotemporal resolution and
signal-to-noise ratio limit its diagnostic utility. To address this, we propose
the Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that
enhances both spatial and temporal resolution with the ability to predict wall
shear stress (WSS) directly from clinical imaging data. LoFNO integrates
Laplacian eigenvectors as geometric priors for improved structural awareness on
irregular, unseen geometries and employs an Enhanced Deep Super-Resolution
Network (EDSR) layer for robust upsampling. By combining geometric priors with
neural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow
data, achieving superior velocity and WSS predictions compared to interpolation
and alternative deep learning methods, enabling more precise cerebrovascular
diagnostics.

</details>


### [57] [$\nabla$NABLA: Neighborhood Adaptive Block-Level Attention](https://arxiv.org/abs/2507.13546)
*Dmitrii Mikhailov,Aleksey Letunovskiy,Maria Kovaleva,Vladimir Arkhipkin,Vladimir Korviakov,Vladimir Polovnikov,Viacheslav Vasilev,Evelina Sidorova,Denis Dimitrov*

Main category: cs.CV

TL;DR: NABLA提出了一种新颖的邻域自适应块级注意力机制，用于视频扩散Transformer（DiTs），通过动态适应稀疏模式来降低计算开销，同时保持生成质量，实现了显著的训练和推理加速。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在视频生成中表现出色，但全注意力机制的二次复杂度是高分辨率和长持续时间视频序列的关键瓶颈。

Method: 本文提出了NABLA（Neighborhood Adaptive Block-Level Attention），它通过利用块级注意力与自适应稀疏驱动阈值，动态适应视频扩散Transformer中的稀疏模式。该方法无需自定义底层操作，可无缝集成PyTorch的Flex Attention算子。

Result: 实验表明，与基线相比，NABLA实现了高达2.7倍的训练和推理速度提升，几乎不影响定量指标（CLIP分数、VBench分数、人工评估分数）和视觉质量。

Conclusion: NABLA通过其新颖的注意力机制有效解决了视频扩散Transformer的计算瓶颈，显著提高了训练和推理效率，同时保持了高质量的视频生成能力。

Abstract: Recent progress in transformer-based architectures has demonstrated
remarkable success in video generation tasks. However, the quadratic complexity
of full attention mechanisms remains a critical bottleneck, particularly for
high-resolution and long-duration video sequences. In this paper, we propose
NABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that
dynamically adapts to sparsity patterns in video diffusion transformers (DiTs).
By leveraging block-wise attention with adaptive sparsity-driven threshold,
NABLA reduces computational overhead while preserving generative quality. Our
method does not require custom low-level operator design and can be seamlessly
integrated with PyTorch's Flex Attention operator. Experiments demonstrate that
NABLA achieves up to 2.7x faster training and inference compared to baseline
almost without compromising quantitative metrics (CLIP score, VBench score,
human evaluation score) and visual quality drop. The code and model weights are
available here: https://github.com/gen-ai-team/Wan2.1-NABLA

</details>


### [58] [One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion](https://arxiv.org/abs/2507.13801)
*Haoang Lu,Yuanqi Su,Xiaoning Zhang,Hao Hu*

Main category: cs.CV

TL;DR: 本文提出CF-SSC，一种新颖的基于时间序列的3D语义场景补全（SSC）框架，通过预测伪未来帧来扩展感知范围，有效解决单目SSC中遮挡和视野外区域的挑战，并实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的单目3D语义场景补全方法在实际交通场景中，无法充分处理大量被遮挡或超出相机视野的区域，这是一个基本挑战。

Method: 本文提出CF-SSC，一个利用伪未来帧预测的全新时序SSC框架。该方法结合位姿和深度信息建立精确的3D对应关系，实现过去、现在和预测未来帧在3D空间中的几何一致性融合。与传统方法不同，其3D感知架构通过显式建模时空关系，实现更鲁棒的场景补全。

Result: 在SemanticKITTI和SSCBench-KITTI-360基准测试上，CF-SSC展现了最先进的性能，验证了其有效性，并显著提高了遮挡推理和3D场景补全的准确性。

Conclusion: CF-SSC通过引入伪未来帧预测和3D感知时空融合，有效克服了传统单目SSC在处理遮挡和视野外区域的局限性，显著提升了3D场景补全的准确性和鲁棒性。

Abstract: In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a
critical perception task for autonomous driving due to its ability to infer
complete 3D scene layouts and semantics from single 2D images. However, in
real-world traffic scenarios, a significant portion of the scene remains
occluded or outside the camera's field of view -- a fundamental challenge that
existing monocular SSC methods fail to address adequately. To overcome these
limitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC
framework that leverages pseudo-future frame prediction to expand the model's
effective perceptual range. Our approach combines poses and depths to establish
accurate 3D correspondences, enabling geometrically-consistent fusion of past,
present, and predicted future frames in 3D space. Unlike conventional methods
that rely on simple feature stacking, our 3D-aware architecture achieves more
robust scene completion by explicitly modeling spatial-temporal relationships.
Comprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks
demonstrate state-of-the-art performance, validating the effectiveness of our
approach, highlighting our method's ability to improve occlusion reasoning and
3D scene completion accuracy.

</details>


### [59] [LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning](https://arxiv.org/abs/2507.13568)
*Kaihong Wang,Donghyun Kim,Margrit Betke*

Main category: cs.CV

TL;DR: 本文提出了一种LoRA增强的合成回放框架，通过将任务特定的低秩适配器注入冻结的Stable Diffusion模型，并结合置信度样本选择机制，提高了视觉-语言模型（VLM）在持续学习中合成样本的保真度，从而增强了知识保留和性能。


<details>
  <summary>Details</summary>
Motivation: 现有合成回放方法在持续学习中，由于生成器未能捕捉到真实世界领域特定的细微差别和细粒度语义，导致生成的样本与实际任务不匹配，从而误导微调并损害对先前知识的保留。

Method: 本文提出一个LoRA增强的合成回放框架。该框架将任务特定的低秩适配器（LoRA）注入冻结的Stable Diffusion模型中，以高效捕捉每个新任务独特的视觉和语义模式。具体地，引入了一个两阶段、基于置信度的样本选择机制：首先，根据微调后VLM的置信度对真实任务数据进行排序，以选择最具代表性的样本进行LoRA微调；然后，生成合成样本并再次通过置信度进行选择，用于知识蒸馏。

Result: 在多领域任务增量学习（MTIL）基准上的大量实验表明，该方法优于先前的合成回放技术，在可塑性、稳定性和零样本能力之间实现了最佳平衡。

Conclusion: 通过LoRA进行生成器适应对于视觉-语言模型中稳健的持续学习是有效的，显著提升了合成回放的保真度，从而改善了知识保留和整体性能。

Abstract: Continual learning for vision-language models has achieved remarkable
performance through synthetic replay, where samples are generated using Stable
Diffusion to regularize during finetuning and retain knowledge. However,
real-world downstream applications often exhibit domain-specific nuances and
fine-grained semantics not captured by generators, causing synthetic-replay
methods to produce misaligned samples that misguide finetuning and undermine
retention of prior knowledge. In this work, we propose a LoRA-enhanced
synthetic-replay framework that injects task-specific low-rank adapters into a
frozen Stable Diffusion model, efficiently capturing each new task's unique
visual and semantic patterns. Specifically, we introduce a two-stage,
confidence-based sample selection: we first rank real task data by
post-finetuning VLM confidence to focus LoRA finetuning on the most
representative examples, then generate synthetic samples and again select them
by confidence for distillation. Our approach integrates seamlessly with
existing replay pipelines-simply swap in the adapted generator to boost replay
fidelity. Extensive experiments on the Multi-domain Task Incremental Learning
(MTIL) benchmark show that our method outperforms previous synthetic-replay
techniques, achieving an optimal balance among plasticity, stability, and
zero-shot capability. These results demonstrate the effectiveness of generator
adaptation via LoRA for robust continual learning in VLMs.

</details>


### [60] [Team of One: Cracking Complex Video QA with Model Synergy](https://arxiv.org/abs/2507.13820)
*Jun Xie,Zhaoran Zhao,Xiongjun Guan,Yingjian Zhu,Hongzhu Yi,Xinming Wang,Feng Chen,Zhepeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的开放式视频问答框架，通过协调多个异构视频-语言模型（VLM）并利用大型语言模型（LLM）进行评估和集成，显著提升了推理深度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频-大型多模态模型（Video-LMMs）在复杂现实场景中存在上下文理解有限、时间建模薄弱以及对模糊或组合查询泛化能力差的问题。

Method: 引入了一种“提示-响应集成机制”，通过结构化的思维链协调多个异构VLM，每个VLM专注于不同的推理路径。一个外部LLM充当评估器和集成器，选择并融合最可靠的响应。

Result: 在CVRR-ES数据集上，该方法在所有评估指标上显著优于现有基线，表现出卓越的泛化能力和鲁棒性。

Conclusion: 该方法提供了一种轻量级、可扩展的策略，无需模型再训练即可推进多模态推理，为未来的Video-LMM发展奠定了坚实基础。

Abstract: We propose a novel framework for open-ended video question answering that
enhances reasoning depth and robustness in complex real-world scenarios, as
benchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models
(Video-LMMs) often exhibit limited contextual understanding, weak temporal
modeling, and poor generalization to ambiguous or compositional queries. To
address these challenges, we introduce a prompting-and-response integration
mechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)
via structured chains of thought, each tailored to distinct reasoning pathways.
An external Large Language Model (LLM) serves as an evaluator and integrator,
selecting and fusing the most reliable responses. Extensive experiments
demonstrate that our method significantly outperforms existing baselines across
all evaluation metrics, showcasing superior generalization and robustness. Our
approach offers a lightweight, extensible strategy for advancing multimodal
reasoning without requiring model retraining, setting a strong foundation for
future Video-LMM development.

</details>


### [61] [NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision](https://arxiv.org/abs/2507.13595)
*Tengkai Wang,Weihao Li,Ruikai Cui,Shi Qiu,Nick Barnes*

Main category: cs.CV

TL;DR: 该论文提出NoiseSDF2NoiseSDF，一种受Noise2Noise启发的3D神经场方法，能直接从噪声点云中学习干净的神经SDF，显著提升表面重建质量。


<details>
  <summary>Details</summary>
Motivation: 从点云重建准确的隐式表面表示是一个挑战，尤其当点云由低质量扫描设备捕获时，常包含大量噪声，导致重建不准确。

Method: 引入NoiseSDF2NoiseSDF，将2D图像的Noise2Noise范式扩展到3D神经场。通过最小化噪声SDF表示之间的MSE损失，利用噪声监督直接从噪声点云学习干净的神经SDF，使网络隐式去噪并优化表面估计。

Result: 在ShapeNet、ABC、Famous和Real等基准数据集上进行评估，实验结果表明该框架显著提高了从噪声输入重建的表面质量。

Conclusion: NoiseSDF2NoiseSDF是一个有效的框架，能够从噪声点云中学习并重建高质量的隐式表面表示。

Abstract: Reconstructing accurate implicit surface representations from point clouds
remains a challenging task, particularly when data is captured using
low-quality scanning devices. These point clouds often contain substantial
noise, leading to inaccurate surface reconstructions. Inspired by the
Noise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel
method designed to extend this concept to 3D neural fields. Our approach
enables learning clean neural SDFs directly from noisy point clouds through
noisy supervision by minimizing the MSE loss between noisy SDF representations,
allowing the network to implicitly denoise and refine surface estimations. We
evaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the
ShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that
our framework significantly improves surface reconstruction quality from noisy
inputs.

</details>


### [62] [When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models](https://arxiv.org/abs/2507.13868)
*Francesco Ortu,Zhijing Jin,Diego Doimo,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 该研究分析了视觉-语言模型（VLMs）如何解决其内部知识与外部视觉信息之间的冲突，识别并操控了控制冲突的注意力头，并展示了其在定位视觉覆盖区域上的高精度。


<details>
  <summary>Details</summary>
Motivation: VLMs在处理复杂任务时，其内部参数化知识与外部信息（如视觉输入）之间常出现冲突，导致幻觉和不可靠的响应。然而，控制这些交互的机制尚不明确。

Method: 研究引入了一个多模态反事实查询数据集，该数据集故意与模型的内部常识知识相矛盾。通过logit检查定位了控制冲突的少量注意力头。通过修改这些头，可以引导模型偏向内部知识或视觉输入。此外，研究展示了这些头的注意力可以精确地定位驱动视觉覆盖的图像区域。

Result: 研究发现并定位了控制VLMs中知识冲突的一小部分注意力头。通过修改这些头，可以成功地将模型响应引导至其内部知识或视觉输入。这些头的注意力在定位驱动视觉覆盖的图像区域方面表现出高精度，优于基于梯度的归因方法。

Conclusion: 该研究揭示了VLMs解决跨模态知识冲突的机制，通过识别和操控特定的注意力头，不仅能理解模型如何权衡信息，还能精确控制其行为并解释视觉输入的影响。

Abstract: Vision-language models (VLMs) increasingly leverage diverse knowledge sources
to address complex tasks, often encountering conflicts between their internal
parametric knowledge and external information. Knowledge conflicts can result
in hallucinations and unreliable responses, but the mechanisms governing such
interactions remain unknown. To address this gap, we analyze the mechanisms
that VLMs use to resolve cross-modal conflicts by introducing a dataset of
multimodal counterfactual queries that deliberately contradict internal
commonsense knowledge. We localize with logit inspection a small set of heads
that control the conflict. Moreover, by modifying these heads, we can steer the
model towards its internal knowledge or the visual inputs. Finally, we show
that attention from such heads pinpoints localized image regions driving visual
overrides, outperforming gradient-based attribution in precision.

</details>


### [63] [Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model](https://arxiv.org/abs/2507.13599)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的基于扩散模型（DM）的框架，用于从非配对数据中学习空间变化的纹理先验，以实现盲图像去模糊。


<details>
  <summary>Details</summary>
Motivation: 获取大量真实的模糊-清晰图像对既困难又昂贵，而现有主流的非配对去模糊方法过于依赖对抗学习，忽略了真实世界中复杂且不可预测的模糊模式。

Method: 该研究提出一个名为“ours”的DM框架。它利用DM生成纹理恢复的先验知识，并通过一个带有记忆机制的纹理先验编码器（TPE）来表示图像纹理并监督DM训练。为充分利用生成的纹理先验，引入了纹理传输Transformer层（TTformer），其中包含一个新颖的滤波器调制多头自注意力（FM-MSA）机制，通过自适应滤波有效去除空间变化的模糊。此外，还采用基于小波的对抗损失来保留高频纹理细节。

Result: 广泛的评估表明，该方法提供了一个有前景的无监督去模糊解决方案，并在广泛使用的基准测试中超越了现有最先进的方法。

Conclusion: 所提出的基于DM的框架通过学习空间变化的纹理先验，并结合TPE、TTformer和基于小波的对抗损失，为非配对盲图像去模糊提供了一种有效且性能优异的解决方案。

Abstract: Since acquiring large amounts of realistic blurry-sharp image pairs is
difficult and expensive, learning blind image deblurring from unpaired data is
a more practical and promising solution. Unfortunately, dominant approaches
rely heavily on adversarial learning to bridge the gap from blurry domains to
sharp domains, ignoring the complex and unpredictable nature of real-world blur
patterns. In this paper, we propose a novel diffusion model (DM)-based
framework, dubbed \ours, for image deblurring by learning spatially varying
texture prior from unpaired data. In particular, \ours performs DM to generate
the prior knowledge that aids in recovering the textures of blurry images. To
implement this, we propose a Texture Prior Encoder (TPE) that introduces a
memory mechanism to represent the image textures and provides supervision for
DM training. To fully exploit the generated texture priors, we present the
Texture Transfer Transformer layer (TTformer), in which a novel
Filter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes
spatially varying blurring through adaptive filtering. Furthermore, we
implement a wavelet-based adversarial loss to preserve high-frequency texture
details. Extensive evaluations show that \ours provides a promising
unsupervised deblurring solution and outperforms SOTA methods in widely-used
benchmarks.

</details>


### [64] [Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision](https://arxiv.org/abs/2507.13880)
*Marten Kreis,Benjamin Kiefer*

Main category: cs.CV

TL;DR: 本文提出一种通过融合实时视频与海图信息来增强海洋视觉的新方法，利用基于Transformer的神经网络实现浮标检测与海图数据的精确匹配。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提升动态和复杂海洋环境中的目标定位与关联准确性，从而增强海洋视觉能力。

Method: 该方法通过精确匹配检测到的航标（如浮标）与海图中的对应表示，将海图数据叠加到实时视频流上。核心是引入一个基于Transformer的端到端神经网络，用于预测浮标的边界框和置信度，从而实现图像域检测与世界空间海图标记的直接匹配。该方法与光线投射模型和扩展YOLOv7的基线方法进行了比较。

Result: 在真实世界海事场景数据集上的实验结果表明，该方法显著提高了在动态和挑战性环境中的目标定位和关联准确性。

Conclusion: 所提出的基于Transformer的实时视觉与海图信息融合方法，能有效提升海洋环境下的目标定位和关联精度，显著增强海洋视觉能力。

Abstract: This paper presents a novel approach to enhancing marine vision by fusing
real-time visual data with chart information. Our system overlays nautical
chart data onto live video feeds by accurately matching detected navigational
aids, such as buoys, with their corresponding representations in chart data. To
achieve robust association, we introduce a transformer-based end-to-end neural
network that predicts bounding boxes and confidence scores for buoy queries,
enabling the direct matching of image-domain detections with world-space chart
markers. The proposed method is compared against baseline approaches, including
a ray-casting model that estimates buoy positions via camera projection and a
YOLOv7-based network extended with a distance estimation module. Experimental
results on a dataset of real-world maritime scenes demonstrate that our
approach significantly improves object localization and association accuracy in
dynamic and challenging environments.

</details>


### [65] [Efficient Burst Super-Resolution with One-step Diffusion](https://arxiv.org/abs/2507.13607)
*Kento Kawai,Takeru Oba,Kyotaro Tokoro,Kazutoshi Akita,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出一种基于扩散模型的方法，用于从低分辨率图像爆发序列中重建锐利、高保真度的超分辨率图像，并通过高效采样和知识蒸馏显著提升了运行效率。


<details>
  <summary>Details</summary>
Motivation: 现有的爆发超分辨率方法是确定性的，导致生成的超分辨率图像模糊且感知质量下降。研究目标是重建锐利、高保真度的超分辨率图像。

Method: 采用扩散模型实现超分辨率。通过使用高阶ODE的随机采样器和利用知识蒸馏实现一步扩散，提高了扩散模型的效率。

Result: 实验结果表明，该方法在保持图像失真和感知质量方面超分辨率性能的同时，将运行时间缩短至基线的1.6%。

Conclusion: 所提出的扩散模型方法能有效从爆发低分辨率图像中生成锐利、高保真度的超分辨率图像，并在保持质量的同时大幅提升了计算效率。

Abstract: While burst Low-Resolution (LR) images are useful for improving their Super
Resolution (SR) image compared to a single LR image, prior burst SR methods are
trained in a deterministic manner, which produces a blurry SR image. Since such
blurry images are perceptually degraded, we aim to reconstruct sharp and
high-fidelity SR images by a diffusion model. Our method improves the
efficiency of the diffusion model with a stochastic sampler with a high-order
ODE as well as one-step diffusion using knowledge distillation. Our
experimental results demonstrate that our method can reduce the runtime to 1.6
% of its baseline while maintaining the SR quality measured based on image
distortion and perceptual quality.

</details>


### [66] [CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks](https://arxiv.org/abs/2507.13609)
*Yanan Wang,Julio Vizcarra,Zhi Li,Hao Niu,Mori Kurokawa*

Main category: cs.CV

TL;DR: CoTasks是一个新框架，通过将复杂视频问题分解为实体级别的基础任务，为视频大语言模型（VideoLLMs）提供链式思考（CoT）推理能力，从而显著提升了视频理解性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型（VideoLLMs）缺乏基于细粒度物体级视频理解的链式思考（CoT）推理能力。这是因为它们主要通过高级别的视频-文本对进行训练，缺少支持组合式、分步推理所需的结构化标注。

Method: 本文提出了CoTasks框架，将现有数据集中（如NeXT-QA, STAR）的复杂视频问题分解为四个实体级别的基础任务：帧定位、实体跟踪、空间关系提取和时间关系提取。通过将这些中间的CoT风格推理步骤嵌入到模型输入中，CoTasks使模型能够明确地执行以物体为中心的时空推理。

Result: 在NeXT-QA基准测试上，CoTasks显著提升了推理性能：LLaVA-video-7B的平均GPT-4评估分数提高了3.3分，Qwen2.5-VL-3B提高了17.4分，在因果（+14.6）、时间（+10.9）和描述性（+48.1）子类别中均有显著提升。

Conclusion: CoTasks作为一种结构化的CoT风格监督框架，能有效提升模型的组合式视频推理能力，解决了现有VideoLLMs在细粒度物体级CoT推理方面的不足。

Abstract: Despite recent progress in video large language models (VideoLLMs), a key
open challenge remains: how to equip models with chain-of-thought (CoT)
reasoning abilities grounded in fine-grained object-level video understanding.
Existing instruction-tuned models, such as the Qwen and LLaVA series, are
trained on high-level video-text pairs, often lacking structured annotations
necessary for compositional, step-by-step reasoning. We propose CoTasks:
Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that
decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)
into four entity-level foundational tasks: frame localization, entity tracking,
spatial and temporal relation extraction. By embedding these intermediate
CoT-style reasoning steps into the input, CoTasks enables models to explicitly
perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA
benchmark show that CoTasks significantly enhance inference performance:
LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and
Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal
(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the
effectiveness of CoTasks as a structured CoT-style supervision framework for
improving compositional video reasoning.

</details>


### [67] [Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation](https://arxiv.org/abs/2507.13628)
*Masahiro Ogawa,Qi An,Atsushi Yamashita*

Main category: cs.CV

TL;DR: 该论文提出FoELS方法，通过结合光流和纹理信息，有效解决了移动相机视角下复杂场景中运动物体与静态物体分离的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖光流，在涉及相机运动的复杂结构化场景中难以检测运动物体，这限制了3D重建、自主导航和场景理解的应用。

Method: FoELS方法整合光流和纹理信息。它首先从光流计算膨胀焦点（FoE），并从FoE计算的异常值中得出初始运动可能性。然后，将该可能性与基于分割的先验融合，以估计最终的运动概率。

Result: 该方法有效处理了复杂结构化场景、旋转相机运动和平行运动等挑战。在DAVIS 2016数据集和真实世界交通视频上的综合评估表明其有效性及最先进的性能。

Conclusion: FoELS是一种有效的分离移动和静态物体的方法，能够应对复杂场景和多种相机运动，并展现出卓越的性能。

Abstract: Separating moving and static objects from a moving camera viewpoint is
essential for 3D reconstruction, autonomous navigation, and scene understanding
in robotics. Existing approaches often rely primarily on optical flow, which
struggles to detect moving objects in complex, structured scenes involving
camera motion. To address this limitation, we propose Focus of Expansion
Likelihood and Segmentation (FoELS), a method based on the core idea of
integrating both optical flow and texture information. FoELS computes the focus
of expansion (FoE) from optical flow and derives an initial motion likelihood
from the outliers of the FoE computation. This likelihood is then fused with a
segmentation-based prior to estimate the final moving probability. The method
effectively handles challenges including complex structured scenes, rotational
camera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016
dataset and real-world traffic videos demonstrate its effectiveness and
state-of-the-art performance.

</details>


### [68] [EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation](https://arxiv.org/abs/2507.13648)
*Seungjun Moon,Sangjoon Yu,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: EPSilon提出了一种高效的点采样策略，显著加速了基于NeRF的3D人体虚拟形象的训练和推理，同时保持了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的混合表示（结合SMPL网格和NeRF）虽然能生成逼真的人体虚拟形象，但由于其形变方案（基于SMPL蒙皮权重）对每个采样点都需要高计算成本，导致推理速度极慢。研究观察到大部分采样点位于空旷空间，不影响生成质量但增加了延迟。

Method: EPSilon提出两种高效点采样策略：1. 空射线剔除（ERO）：剔除穿过空旷空间的射线。2. 空区间剔除（EIO）：缩小射线上的采样区间，剔除衣服或网格未占据的区域。这种精细的采样方案不仅大大减少了形变时的计算成本，还指定了重要的采样区域，从而实现了无需分层采样的单阶段NeRF结构。

Result: 与现有方法相比，EPSilon在保持生成质量的同时，仅使用了3.9%的采样点，实现了约20倍的推理速度提升和4倍的训练收敛速度提升。

Conclusion: EPSilon通过创新的高效点采样策略，显著解决了混合NeRF模型在人体虚拟形象生成中的推理速度慢的问题，实现了计算成本的大幅降低和训练推理效率的显著提升，同时保持了高质量的生成效果。

Abstract: The rapid advancement of neural radiance fields (NeRF) has paved the way to
generate animatable human avatars from a monocular video. However, the sole
usage of NeRF suffers from a lack of details, which results in the emergence of
hybrid representation that utilizes SMPL-based mesh together with NeRF
representation. While hybrid-based models show photo-realistic human avatar
generation qualities, they suffer from extremely slow inference due to their
deformation scheme: to be aligned with the mesh, hybrid-based models use the
deformation based on SMPL skinning weights, which needs high computational
costs on each sampled point. We observe that since most of the sampled points
are located in empty space, they do not affect the generation quality but
result in inference latency with deformation. In light of this observation, we
propose EPSilon, a hybrid-based 3D avatar generation scheme with novel
efficient point sampling strategies that boost both training and inference. In
EPSilon, we propose two methods to omit empty points at rendering; empty ray
omission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that
progress through the empty space. Then, EIO narrows down the sampling interval
on the ray, which wipes out the region not occupied by either clothes or mesh.
The delicate sampling scheme of EPSilon enables not only great computational
cost reduction during deformation but also the designation of the important
regions to be sampled, which enables a single-stage NeRF structure without
hierarchical sampling. Compared to existing methods, EPSilon maintains the
generation quality while using only 3.9% of sampled points and achieves around
20 times faster inference, together with 4 times faster training convergence.
We provide video results on https://github.com/seungjun-moon/epsilon.

</details>


### [69] [Generalist Forecasting with Frozen Video Models via Latent Diffusion](https://arxiv.org/abs/2507.13942)
*Jacob C Walker,Pedro Vélez,Luisa Polania Cabrera,Guangyao Zhou,Rishabh Kabra,Carl Doersch,Maks Ovsjanikov,João Carreira,Shiry Ginosar*

Main category: cs.CV

TL;DR: 研究发现视觉模型的感知能力与其短期预测性能强相关，并提出了一个通用的预测框架，该框架通过在冻结视觉骨干的表示空间中预测未来特征来实现，突出了表示学习与生成模型结合的价值。


<details>
  <summary>Details</summary>
Motivation: 预测未来是通用系统在不同抽象级别上规划或行动的关键技能。

Method: 提出了一种新颖的通用预测框架，该框架可在任何冻结的视觉骨干网络上运行。具体方法是训练潜在扩散模型来预测冻结表示空间中的未来特征，然后通过轻量级的、特定任务的读出器进行解码。为实现跨任务的一致评估，引入了直接在下游任务空间中比较分布属性的分布度量。

Result: 研究发现视觉模型的感知能力与其短期预测性能之间存在强相关性。这种趋势适用于各种预训练模型（包括生成式模型）以及多个抽象级别（从原始像素到深度、点轨迹和物体运动）。该框架已应用于九个模型和四个任务。

Conclusion: 研究结果突出了将表示学习与生成建模相结合对于时间感知的视频理解的价值。

Abstract: Forecasting what will happen next is a critical skill for general-purpose
systems that plan or act in the world at different levels of abstraction. In
this paper, we identify a strong correlation between a vision model's
perceptual ability and its generalist forecasting performance over short time
horizons. This trend holds across a diverse set of pretrained models-including
those trained generatively-and across multiple levels of abstraction, from raw
pixels to depth, point tracks, and object motion. The result is made possible
by a novel generalist forecasting framework that operates on any frozen vision
backbone: we train latent diffusion models to forecast future features in the
frozen representation space, which are then decoded via lightweight,
task-specific readouts. To enable consistent evaluation across tasks, we
introduce distributional metrics that compare distributional properties
directly in the space of downstream tasks and apply this framework to nine
models and four tasks. Our results highlight the value of bridging
representation learning and generative modeling for temporally grounded video
understanding.

</details>


### [70] [Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration](https://arxiv.org/abs/2507.13663)
*Xingyu Jiang,Ning Gao,Hongkun Dou,Xiuhui Zhang,Xiaoqing Zhong,Yue Deng,Hongjue Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为PW-FNet的新型高效图像复原网络，通过结合金字塔小波分解和傅里叶变换替代自注意力机制，在多种图像复原任务中实现了卓越的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的图像复原方法系统复杂性高，难以实时处理和实际部署。尽管有方法尝试简化自注意力，但它们多关注网络架构，忽视了图像复原本身的内在特性。

Method: 本文探索了一种金字塔小波-傅里叶迭代管道，并提出PW-FNet。其核心设计包括：1) 在块间层面，采用基于金字塔小波的多输入多输出结构，实现多尺度和多频带分解；2) 在块内层面，引入傅里叶变换作为自注意力机制的有效替代，以降低计算复杂度并保持全局建模能力。

Result: 在图像去雨、雨滴移除、图像超分辨率、运动去模糊、图像去雾、图像去雪以及水下/低光增强等任务上，PW-FNet不仅超越了现有最先进方法的复原质量，还在参数量、计算成本和推理时间方面显著降低，展现出卓越的效率。

Conclusion: 小波-傅里叶处理在图像复原方面具有巨大潜力。PW-FNet作为一种高效且有效的复原基线，证明了其在多种图像复原任务中的优越性能和效率，为未来研究提供了新方向。

Abstract: Natural image quality is often degraded by adverse weather conditions,
significantly impairing the performance of downstream tasks. Image restoration
has emerged as a core solution to this challenge and has been widely discussed
in the literature. Although recent transformer-based approaches have made
remarkable progress in image restoration, their increasing system complexity
poses significant challenges for real-time processing, particularly in
real-world deployment scenarios. To this end, most existing methods attempt to
simplify the self-attention mechanism, such as by channel self-attention or
state space model. However, these methods primarily focus on network
architecture while neglecting the inherent characteristics of image restoration
itself. In this context, we explore a pyramid Wavelet-Fourier iterative
pipeline to demonstrate the potential of Wavelet-Fourier processing for image
restoration. Inspired by the above findings, we propose a novel and efficient
restoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet).
Specifically, PW-FNet features two key design principles: 1) at the inter-block
level, integrates a pyramid wavelet-based multi-input multi-output structure to
achieve multi-scale and multi-frequency bands decomposition; and 2) at the
intra-block level, incorporates Fourier transforms as an efficient alternative
to self-attention mechanisms, effectively reducing computational complexity
while preserving global modeling capability. Extensive experiments on tasks
such as image deraining, raindrop removal, image super-resolution, motion
deblurring, image dehazing, image desnowing and underwater/low-light
enhancement demonstrate that PW-FNet not only surpasses state-of-the-art
methods in restoration quality but also achieves superior efficiency, with
significantly reduced parameter size, computational cost and inference time.

</details>


### [71] [MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training](https://arxiv.org/abs/2507.13673)
*Yuechen Xie,Haobo Jiang,Jian Yang,Yigong Zhang,Jin Xie*

Main category: cs.CV

TL;DR: MaskHOI是一种基于掩码自编码器（MAE）的预训练框架，通过区域特定掩码分配和骨架驱动的手部掩码指导，并结合掩码符号距离场（SDF）驱动的多模态学习，显著提升了从单目RGB图像中估计三维手物交互（HOI）姿态的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 从单目RGB图像中精确估计三维手物交互姿态极具挑战性，主要原因在于RGB图像固有的几何模糊性以及交互过程中严重的手物相互遮挡。

Method: 本文提出了MaskHOI框架，其核心思想是利用MAE的掩码-重建策略来推断缺失的空间和结构信息，从而促进几何感知和抗遮挡的表示学习。具体方法包括：1) 区域特定掩码比率分配：根据手部比刚性物体几何复杂性更高的特点，对手部区域分配较低的掩码比率，并引入骨架驱动的手部掩码指导，优先遮蔽关键手部区域（如指尖或整个手指）以模拟真实遮挡模式。2) 掩码符号距离场（SDF）驱动的多模态学习机制：通过自掩码三维SDF预测，使预训练编码器能够感知手和物体在二维图像平面之外的全局几何结构，克服单目输入的局限性并缓解自遮挡问题。

Result: 广泛的实验表明，MaskHOI方法显著优于现有最先进的方法。

Conclusion: MaskHOI通过其新颖的区域特定掩码策略和掩码SDF驱动的多模态学习机制，有效地解决了单目RGB图像中三维手物交互姿态估计的几何模糊性和严重遮挡问题，实现了卓越的性能。

Abstract: In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of
hands and objects from monocular RGB input remains highly challenging due to
the inherent geometric ambiguity of RGB images and the severe mutual occlusions
that occur during interaction.To address these challenges, we propose MaskHOI,
a novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI
pose estimation. Our core idea is to leverage the masking-then-reconstruction
strategy of MAE to encourage the feature encoder to infer missing spatial and
structural information, thereby facilitating geometric-aware and
occlusion-robust representation learning. Specifically, based on our
observation that human hands exhibit far greater geometric complexity than
rigid objects, conventional uniform masking fails to effectively guide the
reconstruction of fine-grained hand structures. To overcome this limitation, we
introduce a Region-specific Mask Ratio Allocation, primarily comprising the
region-specific masking assignment and the skeleton-driven hand masking
guidance. The former adaptively assigns lower masking ratios to hand regions
than to rigid objects, balancing their feature learning difficulty, while the
latter prioritizes masking critical hand parts (e.g., fingertips or entire
fingers) to realistically simulate occlusion patterns in real-world
interactions. Furthermore, to enhance the geometric awareness of the pretrained
encoder, we introduce a novel Masked Signed Distance Field (SDF)-driven
multimodal learning mechanism. Through the self-masking 3D SDF prediction, the
learned encoder is able to perceive the global geometric structure of hands and
objects beyond the 2D image plane, overcoming the inherent limitations of
monocular input and alleviating self-occlusion issues. Extensive experiments
demonstrate that our method significantly outperforms existing state-of-the-art
approaches.

</details>


### [72] [CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models](https://arxiv.org/abs/2507.13984)
*Quang-Binh Nguyen,Minh Luu,Quang Nguyen,Anh Tran,Khoi Nguyen*

Main category: cs.CV

TL;DR: 本文提出CSD-VAR，一种基于视觉自回归模型（VAR）的内容-风格分解（CSD）新方法，通过尺度感知优化、SVD校正和增强的K-V记忆，实现了更好的内容保留和风格化，并引入了CSD-100数据集。


<details>
  <summary>Details</summary>
Motivation: 内容-风格分解（CSD）能提供更大的视觉合成灵活性。现有分解方法主要针对扩散模型，而视觉自回归模型（VAR）作为一种有前景的替代方案，其在CSD中的应用尚未被探索，且其逐尺度生成过程可能有利于解耦。

Method: 本文提出CSD-VAR方法，包含三项关键创新：1) 尺度感知交替优化策略，用于对齐内容和风格表示以增强分离；2) 基于SVD的校正方法，以减少内容泄露到风格表示中；3) 增强的键值（K-V）记忆，以提高内容身份保留。此外，为评估该任务，论文还引入了CSD-100数据集。

Result: 实验结果表明，CSD-VAR在内容保留和风格化保真度方面均优于现有方法。

Conclusion: CSD-VAR成功地将视觉自回归模型应用于内容-风格分解任务，通过其创新的分解策略和记忆机制，实现了卓越的性能，并为该领域提供了专门的数据集。

Abstract: Disentangling content and style from a single image, known as content-style
decomposition (CSD), enables recontextualization of extracted content and
stylization of extracted styles, offering greater creative flexibility in
visual synthesis. While recent personalization methods have explored the
decomposition of explicit content style, they remain tailored for diffusion
models. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a
promising alternative with a next-scale prediction paradigm, achieving
performance comparable to that of diffusion models. In this paper, we explore
VAR as a generative framework for CSD, leveraging its scale-wise generation
process for improved disentanglement. To this end, we propose CSD-VAR, a novel
method that introduces three key innovations: (1) a scale-aware alternating
optimization strategy that aligns content and style representation with their
respective scales to enhance separation, (2) an SVD-based rectification method
to mitigate content leakage into style representations, and (3) an Augmented
Key-Value (K-V) memory enhancing content identity preservation. To benchmark
this task, we introduce CSD-100, a dataset specifically designed for
content-style decomposition, featuring diverse subjects rendered in various
artistic styles. Experiments demonstrate that CSD-VAR outperforms prior
approaches, achieving superior content preservation and stylization fidelity.

</details>


### [73] [Gaussian kernel-based motion measurement](https://arxiv.org/abs/2507.13693)
*Hongyi Liu,Haifeng Wang*

Main category: cs.CV

TL;DR: 本文提出一种基于高斯核的视觉运动测量方法，解决了现有方法在亚像素级精度不足或需大量手动调参的问题，实现了高精度和鲁棒性，无需定制参数。


<details>
  <summary>Details</summary>
Motivation: 结构健康监测对高精度运动测量的需求日益增长，但现有视觉测量方法在亚像素级精度方面不足，或需要大量手动参数调整才能达到良好精度。

Method: 开发了一种新颖的基于高斯核的运动测量方法，通过跟踪高斯核的位置来提取帧间运动。引入了运动一致性（符合实际结构条件）和超分辨率约束来提高精度和鲁棒性。

Result: 数值和实验验证表明，该方法能够持续达到高精度，且无需针对不同测试样本进行定制的参数设置。

Conclusion: 所提出的高斯核运动测量方法在无需定制参数设置的情况下，能够为结构健康监测提供高精度、鲁棒的运动信息，有效解决了现有视觉方法的局限性。

Abstract: The growing demand for structural health monitoring has driven increasing
interest in high-precision motion measurement, as structural information
derived from extracted motions can effectively reflect the current condition of
the structure. Among various motion measurement techniques, vision-based
methods stand out due to their low cost, easy installation, and large-scale
measurement. However, when it comes to sub-pixel-level motion measurement,
current vision-based methods either lack sufficient accuracy or require
extensive manual parameter tuning (e.g., pyramid layers, target pixels, and
filter parameters) to reach good precision. To address this issue, we developed
a novel Gaussian kernel-based motion measurement method, which can extract the
motion between different frames via tracking the location of Gaussian kernels.
The motion consistency, which fits practical structural conditions, and a
super-resolution constraint, are introduced to increase accuracy and robustness
of our method. Numerical and experimental validations show that it can
consistently reach high accuracy without customized parameter setup for
different test samples.

</details>


### [74] [VLA-Mark: A cross modal watermark for large vision-language alignment model](https://arxiv.org/abs/2507.14067)
*Shuliang Liu,Qi Zheng,Jesse Jiaxi Xu,Yibo Yan,He Geng,Aiwei Liu,Peijie Jiang,Jia Liu,Yik-Cheung Tam,Xuming Hu*

Main category: cs.CV

TL;DR: VLA-Mark是一种用于视觉-语言模型的数字水印框架，它通过跨模态协调在嵌入可检测水印的同时，保持语义保真度和视觉-文本一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本水印方法通过有偏的token选择和静态策略破坏了视觉-文本对齐，使得语义关键概念易受攻击，因此视觉-语言模型需要一种既能保护知识产权又不损害多模态一致性的水印解决方案。

Method: VLA-Mark通过跨模态协调实现语义保真。它整合了多尺度视觉-文本对齐度量，包括局部块亲和度、全局语义一致性和上下文注意力模式，以指导水印注入，且无需模型再训练。此外，一个熵敏感机制动态平衡水印强度和语义保留，在低不确定性生成阶段优先考虑视觉基础。

Result: 实验结果显示，VLA-Mark比传统方法PPL降低7.4%，BLEU提高26.6%，检测AUC接近完美（98.8%）。该框架对复述和同义词替换等攻击表现出96.1%的抗攻击性，同时保持了文本-视觉一致性。

Conclusion: VLA-Mark为质量保持的多模态水印设定了新标准，在保护知识产权的同时，有效维护了视觉-语言模型的语义完整性和跨模态一致性。

Abstract: Vision-language models demand watermarking solutions that protect
intellectual property without compromising multimodal coherence. Existing text
watermarking methods disrupt visual-textual alignment through biased token
selection and static strategies, leaving semantic-critical concepts vulnerable.
We propose VLA-Mark, a vision-aligned framework that embeds detectable
watermarks while preserving semantic fidelity through cross-modal coordination.
Our approach integrates multiscale visual-textual alignment metrics, combining
localized patch affinity, global semantic coherence, and contextual attention
patterns, to guide watermark injection without model retraining. An
entropy-sensitive mechanism dynamically balances watermark strength and
semantic preservation, prioritizing visual grounding during low-uncertainty
generation phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than
conventional methods, with near-perfect detection (98.8% AUC). The framework
demonstrates 96.1\% attack resilience against attacks such as paraphrasing and
synonym substitution, while maintaining text-visual consistency, establishing
new standards for quality-preserving multimodal watermarking

</details>


### [75] [GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms](https://arxiv.org/abs/2507.13706)
*Ángel F. García-Fernández,Jinhao Gu,Lennart Svensson,Yuxuan Xia,Jan Krejčí,Oliver Kost,Ondřej Straka*

Main category: cs.CV

TL;DR: 本文引入了两种新的准度量（GOSPA和T-GOSPA的扩展）用于多目标跟踪（MOT）算法的性能评估，它们提供了更大的灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有的GOSPA和T-GOSPA度量在某些MOT应用中缺乏灵活性，例如无法对漏检和虚警目标施加不同的惩罚成本，且要求定位成本对称。

Method: 提出了两种准度量：一种是广义最优子模式分配（GOSPA）度量的扩展，用于衡量目标集差异；另一种是轨迹GOSPA（T-GOSPA）度量的扩展，用于衡量轨迹集差异。这些准度量允许对漏检和虚警目标施加不同的成本，并且定位成本无需对称。T-GOSPA准度量还包含轨迹切换成本。

Result: 通过仿真，使用T-GOSPA准度量评估了几种贝叶斯MOT算法的性能。

Conclusion: 所提出的准度量为MOT评估提供了更大的灵活性，这在特定应用中可能非常有用。

Abstract: This paper introduces two quasi-metrics for performance assessment of
multi-object tracking (MOT) algorithms. In particular, one quasi-metric is an
extension of the generalised optimal subpattern assignment (GOSPA) metric and
measures the discrepancy between sets of objects. The other quasi-metric is an
extension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy
between sets of trajectories. Similar to the GOSPA-based metrics, these
quasi-metrics include costs for localisation error for properly detected
objects, the number of false objects and the number of missed objects. The
T-GOSPA quasi-metric also includes a track switching cost. Differently from the
GOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of
penalising missed and false objects with different costs, and the localisation
costs are not required to be symmetric. These properties can be useful in MOT
evaluation in certain applications. The performance of several Bayesian MOT
algorithms is assessed with the T-GOSPA quasi-metric via simulations.

</details>


### [76] [PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement](https://arxiv.org/abs/2507.13708)
*Sofia Jamil,Bollampalli Areen Reddy,Raghvendra Kumar,Sriparna Saha,Koustava Goswami,K. J. Joseph*

Main category: cs.CV

TL;DR: 提出PoemTale Diffusion，一种无需训练的方法，通过多阶段提示词精炼和一致性自注意力机制，改善文本到图像模型对诗歌等创意语言的理解和图像生成，并发布P4I数据集。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在处理复杂、抽象或富有创意的语言（特别是诗歌）时，难以准确解释文本并生成高质量图像，导致信息丢失。

Method: 引入PoemTale Diffusion方法，该方法无需训练。它通过在语言模型中集成多阶段提示词精炼循环来增强诗歌文本的可解释性。同时，通过修改现有扩散模型的自注意力机制，采用一致性自注意力技术生成多张连贯图像，共同传达诗歌含义。此外，还构建并发布了包含1111首诗歌的P4I (PoemForImage) 数据集。通过人类专家定性评估和定量评估来验证方法效果。

Result: 人类和定量评估结果均验证了所提出方法的有效性。生成图像中诗歌信息的捕获能力得到显著增强。

Conclusion: 该研究为诗歌到图像生成提供了一种新颖的视角，有效提升了生成图像中诗歌信息的捕获能力，解决了现有模型在处理复杂创意文本方面的挑战。

Abstract: Recent advancements in text-to-image diffusion models have achieved
remarkable success in generating realistic and diverse visual content. A
critical factor in this process is the model's ability to accurately interpret
textual prompts. However, these models often struggle with creative
expressions, particularly those involving complex, abstract, or highly
descriptive language. In this work, we introduce a novel training-free approach
tailored to improve image generation for a unique form of creative language:
poetic verse, which frequently features layered, abstract, and dual meanings.
Our proposed PoemTale Diffusion approach aims to minimise the information that
is lost during poetic text-to-image conversion by integrating a multi stage
prompt refinement loop into Language Models to enhance the interpretability of
poetic texts. To support this, we adapt existing state-of-the-art diffusion
models by modifying their self-attention mechanisms with a consistent
self-attention technique to generate multiple consistent images, which are then
collectively used to convey the poem's meaning. Moreover, to encourage research
in the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting
of 1111 poems sourced from multiple online and offline resources. We engaged a
panel of poetry experts for qualitative assessments. The results from both
human and quantitative evaluations validate the efficacy of our method and
contribute a novel perspective to poem-to-image generation with enhanced
information capture in the generated images.

</details>


### [77] [Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment](https://arxiv.org/abs/2507.14093)
*Šimon Kubov,Simon Klíčník,Jakub Dandár,Zdeněk Straka,Karolína Kvaková,Daniel Kvak*

Main category: cs.CV

TL;DR: 该研究评估了一款基于深度学习的自动化软件在脊柱侧弯Cobb角测量上的表现，结果显示其测量精度可媲美放射科专家，有望简化临床工作流程。


<details>
  <summary>Details</summary>
Motivation: 脊柱侧弯的治疗决策依赖于精确的Cobb角测量，但手动评估耗时且存在观察者间差异。因此，需要一种更高效、客观的测量方法。

Method: 研究对来自10家医院的103张站立位全脊柱前后位X线片进行了回顾性、多中心评估。使用一款全自动深度学习软件（Carebot AI Bones）测量Cobb角，并与两位独立的肌肉骨骼放射科医生的测量结果进行比较。评估指标包括Bland-Altman分析、平均绝对误差（MAE）、均方根误差（RMSE）、Pearson相关系数和Cohen Kappa系数（用于四级严重程度分类）。

Result: 与放射科医生1相比，AI的MAE为3.89度（RMSE 4.77度），偏差为0.70度。与放射科医生2相比，AI的MAE为3.90度（RMSE 5.68度），偏差为2.14度。AI与两位放射科医生的Pearson相关系数分别为0.906和0.880（放射科医生间为0.928）。严重程度分级的Cohen Kappa系数分别为0.51和0.64（放射科医生间为0.59）。

Conclusion: 研究结果表明，所提出的深度学习软件在多中心环境下能够重现专家水平的Cobb角测量和分类分级，这表明其在简化脊柱侧弯报告和临床工作流程中的分流具有实用价值。

Abstract: Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment
decisions depend on precise Cobb angle measurement. Manual assessment is time
consuming and subject to inter observer variation. We conducted a
retrospective, multi centre evaluation of a fully automated deep learning
software (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on
103 standing anteroposterior whole spine radiographs collected from ten
hospitals. Two musculoskeletal radiologists independently measured each study
and served as reference readers. Agreement between the AI and each radiologist
was assessed with Bland Altman analysis, mean absolute error (MAE), root mean
squared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four
grade severity classification. Against Radiologist 1 the AI achieved an MAE of
3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of
agreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI
achieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees
and limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r
equals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen
kappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).
These results demonstrate that the proposed software reproduces expert level
Cobb angle measurements and categorical grading across multiple centres,
suggesting its utility for streamlining scoliosis reporting and triage in
clinical workflows.

</details>


### [78] [Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction](https://arxiv.org/abs/2507.13719)
*Daniele Pannone,Alessia Castronovo,Maurizio Mancini,Gian Luca Foresti,Claudio Piciarelli,Rossana Gabrieli,Muhammad Yasir Bilal,Danilo Avola*

Main category: cs.CV

TL;DR: 本文提出了一种博物馆AR管道，通过融合GLPN和Depth-Anything两种深度估计模型，从单张图像生成高精度艺术品3D模型，以增强访客体验。


<details>
  <summary>Details</summary>
Motivation: 旨在解决博物馆环境中艺术品识别和单图3D模型生成挑战，克服艺术品不规则轮廓和多变纹理带来的困难，从而通过互动数字内容提升访客参与度。

Method: 该方法整合了GLPN（用于全局结构）和Depth-Anything（用于局部细节）两种预训练深度估计模型，生成优化深度图。随后，这些深度图被转换为高质量点云和网格，并利用先进的神经网络架构和计算机视觉技术来处理复杂的艺术特征。

Result: 实验结果显示，该系统在重建精度和视觉真实感方面有显著提升，证明其作为一个高度鲁棒的工具，能有效增强博物馆访客的互动体验。

Conclusion: 该系统为博物馆提供了一个强大的工具，能够通过生成准确的艺术品3D模型和沉浸式AR体验，显著提升访客的参与度和数字内容互动性。

Abstract: This paper presents an innovative augmented reality pipeline tailored for
museum environments, aimed at recognizing artworks and generating accurate 3D
models from single images. By integrating two complementary pre-trained depth
estimation models, i.e., GLPN for capturing global scene structure and
Depth-Anything for detailed local reconstruction, the proposed approach
produces optimized depth maps that effectively represent complex artistic
features. These maps are then converted into high-quality point clouds and
meshes, enabling the creation of immersive AR experiences. The methodology
leverages state-of-the-art neural network architectures and advanced computer
vision techniques to overcome challenges posed by irregular contours and
variable textures in artworks. Experimental results demonstrate significant
improvements in reconstruction accuracy and visual realism, making the system a
highly robust tool for museums seeking to enhance visitor engagement through
interactive digital content.

</details>


### [79] [Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis](https://arxiv.org/abs/2507.13753)
*Tongtong Su,Chengyu Wang,Bingyan Liu,Jun Huang,Dongming Lu*

Main category: cs.CV

TL;DR: 本文提出EVS，一个免训练的封装式视频合成器，它结合了文本到图像（T2I）和文本到视频（T2V）模型，以显著提升生成视频的图像质量和运动流畅性，并实现推理速度的提升。


<details>
  <summary>Details</summary>
Motivation: 当前大型文本到视频（T2V）合成模型在实现高图像质量和有效运动表示方面面临挑战。现有方法常将预训练的T2I模型用于精炼视频帧，但这会导致帧间不一致，产生闪烁和伪影问题。

Method: EVS（Encapsulated Video Synthesizer）是一种免训练的方法。它利用训练好的扩散模型T2I模型来精炼低质量视频帧，将其视为分布外样本并通过去噪步骤进行优化。同时，它采用T2V骨干网络确保一致的运动动态。通过将T2V模型的时序先验封装到T2I生成过程中，EVS有效结合了两类模型的优势。

Result: EVS成功提升了生成视频的图像和运动质量。实验结果验证了其相较于现有方法的有效性。此外，该组合过程还带来了1.6倍至4.5倍的显著推理速度提升。

Conclusion: EVS通过巧妙地结合T2I和T2V模型的优势，解决了文本到视频合成中图像质量和运动流畅性的核心挑战，并显著提高了推理效率，为高质量视频生成提供了有效方案。

Abstract: In recent years, large text-to-video (T2V) synthesis models have garnered
considerable attention for their abilities to generate videos from textual
descriptions. However, achieving both high imaging quality and effective motion
representation remains a significant challenge for these T2V models. Existing
approaches often adapt pre-trained text-to-image (T2I) models to refine video
frames, leading to issues such as flickering and artifacts due to
inconsistencies across frames. In this paper, we introduce EVS, a training-free
Encapsulated Video Synthesizer that composes T2I and T2V models to enhance both
visual fidelity and motion smoothness of generated videos. Our approach
utilizes a well-trained diffusion-based T2I model to refine low-quality video
frames by treating them as out-of-distribution samples, effectively optimizing
them with noising and denoising steps. Meanwhile, we employ T2V backbones to
ensure consistent motion dynamics. By encapsulating the T2V temporal-only prior
into the T2I generation process, EVS successfully leverages the strengths of
both types of models, resulting in videos of improved imaging and motion
quality. Experimental results validate the effectiveness of our approach
compared to previous approaches. Our composition process also leads to a
significant improvement of 1.6x-4.5x speedup in inference time. Source codes:
https://github.com/Tonniia/EVS.

</details>


### [80] [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://arxiv.org/abs/2507.13773)
*Pu Jian,Donglei Yu,Wen Yang,Shuo Ren,Jiajun Zhang*

Main category: cs.CV

TL;DR: 该论文提出了ClearVQA基准测试，旨在解决视觉问答（VQA）中用户提问歧义的问题，并通过交互式澄清而非简单改写来评估视觉语言模型（VLMs）的澄清能力。


<details>
  <summary>Details</summary>
Motivation: 在VQA中，用户常因表达习惯不同而提出模糊问题。现有研究主要通过改写问题来处理歧义，但忽视了用户与VLM交互的本质——歧义可通过用户反馈来澄清。然而，交互式澄清研究面临两大挑战：缺乏评估VLM交互澄清能力的基准，以及VLM倾向于回答而非提问，阻碍其主动寻求澄清。

Method: 为克服上述挑战，论文引入了ClearVQA基准测试。

Result: ClearVQA基准测试针对VQA语境中三种常见的歧义类别，并涵盖了多种VQA场景。

Conclusion: ClearVQA基准测试的引入为评估和提升VLM通过交互解决歧义的能力提供了工具，填补了现有研究的空白。

Abstract: In visual question answering (VQA) context, users often pose ambiguous
questions to visual language models (VLMs) due to varying expression habits.
Existing research addresses such ambiguities primarily by rephrasing questions.
These approaches neglect the inherently interactive nature of user interactions
with VLMs, where ambiguities can be clarified through user feedback. However,
research on interactive clarification faces two major challenges: (1)
Benchmarks are absent to assess VLMs' capacity for resolving ambiguities
through interaction; (2) VLMs are trained to prefer answering rather than
asking, preventing them from seeking clarification. To overcome these
challenges, we introduce \textbf{ClearVQA} benchmark, which targets three
common categories of ambiguity in VQA context, and encompasses various VQA
scenarios.

</details>


### [81] [NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining](https://arxiv.org/abs/2507.14119)
*Maksim Kuprashevich,Grigorii Alekseenko,Irina Tolstykh,Georgii Fedorov,Bulat Suleimanov,Vladimir Dokholyan,Aleksandr Gordeev*

Main category: cs.CV

TL;DR: 本文提出了一种自动化、模块化的管道，用于挖掘高质量的图像-指令-编辑图像三元组，以训练生成式图像编辑模型，并发布了一个大规模的开放数据集NHR-Edit和最先进的模型Bagel-NHR-Edit。


<details>
  <summary>Details</summary>
Motivation: 当前生成式图像编辑助手的监督训练需要数百万个高质量的三元组（原始图像、指令、编辑图像），但手动挖掘像素级精确的示例非常困难，因为每个编辑必须满足区域限制、风格一致性、物理合理性和视觉吸引力等严格要求，且缺乏可靠的自动化编辑质量度量标准。

Method: 该研究开发了一个自动化、模块化的管道，利用公共生成模型，并使用一个针对任务优化的Gemini验证器直接评估指令遵循度和美观性，无需分割或接地模型。通过反演和组合引导（inversion and compositional bootstrapping）方法，将挖掘到的数据集扩大了约2.2倍。

Result: 该方法成功挖掘并发布了NHR-Edit，一个包含35.8万个高质量三元组的开放数据集，该数据集在最大的跨数据集评估中超越了所有公开替代方案。此外，还发布了Bagel-NHR-Edit，一个开源的微调Bagel模型，在实验中实现了最先进的性能指标。

Conclusion: 该自动化管道实现了大规模、高保真训练数据的生成，无需人工标注工作，从而降低了该资源密集型领域的研究门槛。通过提供NHR-Edit数据集和Bagel-NHR-Edit模型，该研究为图像编辑领域的研究做出了重要贡献。

Abstract: Recent advances in generative modeling enable image editing assistants that
follow natural language instructions without additional user input. Their
supervised training requires millions of triplets: original image, instruction,
edited image. Yet mining pixel-accurate examples is hard. Each edit must affect
only prompt-specified regions, preserve stylistic coherence, respect physical
plausibility, and retain visual appeal. The lack of robust automated
edit-quality metrics hinders reliable automation at scale. We present an
automated, modular pipeline that mines high-fidelity triplets across domains,
resolutions, instruction complexities, and styles. Built on public generative
models and running without human intervention, our system uses a task-tuned
Gemini validator to score instruction adherence and aesthetics directly,
removing any need for segmentation or grounding models. Inversion and
compositional bootstrapping enlarge the mined set by approximately 2.2x,
enabling large-scale high-fidelity training data. By automating the most
repetitive annotation steps, the approach allows a new scale of training
without human labeling effort. To democratize research in this
resource-intensive area, we release NHR-Edit: an open dataset of 358k
high-quality triplets. In the largest cross-dataset evaluation, it surpasses
all public alternatives. We also release Bagel-NHR-Edit, an open-source
fine-tuned Bagel model, which achieves state-of-the-art metrics in our
experiments.

</details>


### [82] [Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification](https://arxiv.org/abs/2507.13772)
*Abhijit Sen,Giridas Maiti,Bikram K. Parida,Bhanu P. Mishra,Mahima Arya,Denys I. Bondar*

Main category: cs.CV

TL;DR: 该研究提出一种基于置换熵（PE）的多尺度、多方向特征提取方法，并结合HOG和LBP特征，用于图像分类，旨在提供一种计算高效且可解释的深度学习替代方案。


<details>
  <summary>Details</summary>
Motivation: 在图像分类中，当可解释性和计算效率优先于参数量庞大的深度学习模型时，特征工程仍扮演关键角色。该研究旨在探索一种新颖的、非深度学习的图像分类方法。

Method: 将时间序列分析中常用的置换熵（PE）扩展到二维图像，并提出一种多尺度、多方向的基于熵的特征提取方法，用于描述图像的行、列、对角线、反对角线和局部块的空间顺序与复杂性。为增强特征的判别力，集成了经典的HOG（用于捕获形状和边缘结构）和LBP（用于编码微纹理）描述符。最终形成780维的手工特征集，并使用网格搜索优化的支持向量机（SVM）分类器进行训练。

Result: 在Fashion-MNIST、KMNIST、EMNIST和CIFAR-10等多个基准数据集上进行了评估，结果显示该方法在不依赖深度学习架构的情况下，实现了具有竞争力的分类性能。PE与HOG和LBP的融合提供了一种紧凑、可解释且有效的替代方案，相较于计算昂贵且可解释性有限的深度学习模型。

Conclusion: 该研究展示了基于熵的描述符在图像分类中的潜力，并为图像分类和计算机视觉领域的可解释机器学习贡献了一种轻量级且可泛化的解决方案。

Abstract: Feature engineering continues to play a critical role in image
classification, particularly when interpretability and computational efficiency
are prioritized over deep learning models with millions of parameters. In this
study, we revisit classical machine learning based image classification through
a novel approach centered on Permutation Entropy (PE), a robust and
computationally lightweight measure traditionally used in time series analysis
but rarely applied to image data. We extend PE to two-dimensional images and
propose a multiscale, multi-orientation entropy-based feature extraction
approach that characterizes spatial order and complexity along rows, columns,
diagonals, anti-diagonals, and local patches of the image. To enhance the
discriminatory power of the entropy features, we integrate two classic image
descriptors: the Histogram of Oriented Gradients (HOG) to capture shape and
edge structure, and Local Binary Patterns (LBP) to encode micro-texture of an
image. The resulting hand-crafted feature set, comprising of 780 dimensions, is
used to train Support Vector Machine (SVM) classifiers optimized through grid
search. The proposed approach is evaluated on multiple benchmark datasets,
including Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers
competitive classification performance without relying on deep architectures.
Our results demonstrate that the fusion of PE with HOG and LBP provides a
compact, interpretable, and effective alternative to computationally expensive
and limited interpretable deep learning models. This shows a potential of
entropy-based descriptors in image classification and contributes a lightweight
and generalizable solution to interpretable machine learning in image
classification and computer vision.

</details>


### [83] [SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering](https://arxiv.org/abs/2507.13779)
*Durgesh Singh,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 本文提出一种显式可微分聚类模块，通过利用监督数据计算聚类中心，以端到端方式应用于半监督学习（SSL）和无监督域适应（UDA），在低监督条件下表现尤为出色。


<details>
  <summary>Details</summary>
Motivation: 半监督学习（SSL）和无监督域适应（UDA）利用有限的监督信息提升模型性能。聚类假设（同类数据点在高维空间中应聚在一起）已被证明对学习有益，但现有方法多是隐式强制执行。本文旨在显式地应用这一假设。

Method: 引入一个显式且可微分的聚类模块，并扩展该模块以利用监督数据计算聚类中心。采用直接的端到端训练策略进行模型训练。

Result: 通过大量实验证明了所提方法在SSL和UDA任务上的有效性，尤其在低监督条件下效果显著。该方法既可作为独立模型使用，也可作为现有方法的正则化器。

Conclusion: 通过显式整合一个利用监督数据计算聚类中心的可微分聚类模块，可以有效提升半监督学习和无监督域适应的性能，特别是在监督数据稀缺的情况下，并且能作为独立模型或正则化器发挥作用。

Abstract: Semi-Supervised Learning (SSL) and Unsupervised Domain Adaptation (UDA)
enhance the model performance by exploiting information from labeled and
unlabeled data. The clustering assumption has proven advantageous for learning
with limited supervision and states that data points belonging to the same
cluster in a high-dimensional space should be assigned to the same category.
Recent works have utilized different training mechanisms to implicitly enforce
this assumption for the SSL and UDA. In this work, we take a different approach
by explicitly involving a differentiable clustering module which is extended to
leverage the supervised data to compute its centroids. We demonstrate the
effectiveness of our straightforward end-to-end training strategy for SSL and
UDA over extensive experiments and highlight its benefits, especially in low
supervision regimes, both as a standalone model and as a regularizer for
existing approaches.

</details>


### [84] [DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance](https://arxiv.org/abs/2507.13797)
*Huu-Phu Do,Yu-Wei Chen,Yi-Cheng Liao,Chi-Wei Hsiao,Han-Yang Wang,Wei-Chen Chiu,Ching-Chun Huang*

Main category: cs.CV

TL;DR: DynFaceRestore是一种新颖的盲人脸修复方法，通过动态选择扩散采样起始时间步和应用动态局部引导比例调整，有效平衡了图像保真度和质量。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸修复方法通常使用固定的扩散采样时间步和全局引导比例，并假设降质是均匀的，这可能导致过度或不足的扩散，从而在保真度和质量之间产生不平衡。此外，不完美的降质核估计也加剧了这个问题。

Method: 该方法首先学习将任意盲降质输入映射到高斯模糊图像。然后，利用这些模糊图像及其对应的高斯核，动态选择每个模糊图像的扩散采样起始时间步，并在扩散采样过程中应用闭式引导以保持保真度。此外，引入了一个动态引导比例调节器，用于调整局部区域的引导强度，从而在复杂区域增强细节生成，同时在轮廓处保持结构保真度。

Result: DynFaceRestore在定量和定性评估中均达到了最先进的性能，展示了其在盲人脸修复中的鲁棒性和有效性。

Conclusion: DynFaceRestore通过动态调整扩散参数和引导强度，成功解决了盲人脸修复中保真度和质量之间的权衡问题，实现了卓越的修复效果。

Abstract: Blind Face Restoration aims to recover high-fidelity, detail-rich facial
images from unknown degraded inputs, presenting significant challenges in
preserving both identity and detail. Pre-trained diffusion models have been
increasingly used as image priors to generate fine details. Still, existing
methods often use fixed diffusion sampling timesteps and a global guidance
scale, assuming uniform degradation. This limitation and potentially imperfect
degradation kernel estimation frequently lead to under- or over-diffusion,
resulting in an imbalance between fidelity and quality. We propose
DynFaceRestore, a novel blind face restoration approach that learns to map any
blindly degraded input to Gaussian blurry images. By leveraging these blurry
images and their respective Gaussian kernels, we dynamically select the
starting timesteps for each blurry image and apply closed-form guidance during
the diffusion sampling process to maintain fidelity. Additionally, we introduce
a dynamic guidance scaling adjuster that modulates the guidance strength across
local regions, enhancing detail generation in complex areas while preserving
structural fidelity in contours. This strategy effectively balances the
trade-off between fidelity and quality. DynFaceRestore achieves
state-of-the-art performance in both quantitative and qualitative evaluations,
demonstrating robustness and effectiveness in blind face restoration.

</details>


### [85] [GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation](https://arxiv.org/abs/2507.13803)
*Weiqi Yang,Xu Zhou,Jingfu Guan,Hao Du,Tianyu Bai*

Main category: cs.CV

TL;DR: GRAM-MAMBA是一种针对物联网（IoT）多模态感知的框架，它利用Mamba模型处理时序数据，通过GRAM矩阵进行模态对齐，并引入低秩自适应策略处理缺失模态，实现了高效且鲁棒的感知。


<details>
  <summary>Details</summary>
Motivation: 现有物联网多模态系统面临模型复杂性高（难以部署于资源受限环境）、单向模态对齐忽略模态间关系以及传感器数据缺失时鲁棒性差等挑战，这些问题阻碍了在实际IoT环境中高效、鲁棒的多模态感知。

Method: 本文提出了GRAM-MAMBA框架：1) 利用线性复杂度的Mamba模型高效处理传感器时序数据。2) 采用优化的GRAM矩阵策略实现模态间的成对对齐，以解决传统单模态对齐的不足。3) 借鉴LoRA思想，引入自适应低秩层补偿策略，在训练后处理缺失模态，通过冻结预训练模型核心和无关自适应层，仅微调与可用模态及融合过程相关的参数。

Result: 在SPAWC2021室内定位数据集上，预训练模型误差低于基线；适应缺失模态后，仅训练不到0.2%的参数，性能提升24.5%。在USC-HAD人类活动识别数据集上，F1分数达到93.55%，整体准确率(OA)达到93.81%，优于现有工作；更新策略使F1分数提高23%，而训练参数不到0.3%。

Conclusion: GRAM-MAMBA框架在资源受限环境中实现了高效且鲁棒的多模态感知，其在处理时序数据、模态对齐和应对缺失数据方面的创新策略得到了实验验证，显示出巨大的应用潜力。

Abstract: Multi-modal fusion is crucial for Internet of Things (IoT) perception, widely
deployed in smart homes, intelligent transport, industrial automation, and
healthcare. However, existing systems often face challenges: high model
complexity hinders deployment in resource-constrained environments,
unidirectional modal alignment neglects inter-modal relationships, and
robustness suffers when sensor data is missing. These issues impede efficient
and robust multimodal perception in real-world IoT settings. To overcome these
limitations, we propose GRAM-MAMBA. This framework utilizes the
linear-complexity Mamba model for efficient sensor time-series processing,
combined with an optimized GRAM matrix strategy for pairwise alignment among
modalities, addressing the shortcomings of traditional single-modality
alignment. Inspired by Low-Rank Adaptation (LoRA), we introduce an adaptive
low-rank layer compensation strategy to handle missing modalities
post-training. This strategy freezes the pre-trained model core and irrelevant
adaptive layers, fine-tuning only those related to available modalities and the
fusion process. Extensive experiments validate GRAM-MAMBA's effectiveness. On
the SPAWC2021 indoor positioning dataset, the pre-trained model shows lower
error than baselines; adapting to missing modalities yields a 24.5% performance
boost by training less than 0.2% of parameters. On the USC-HAD human activity
recognition dataset, it achieves 93.55% F1 and 93.81% Overall Accuracy (OA),
outperforming prior work; the update strategy increases F1 by 23% while
training less than 0.3% of parameters. These results highlight GRAM-MAMBA's
potential for achieving efficient and robust multimodal perception in
resource-constrained environments.

</details>


### [86] [SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing](https://arxiv.org/abs/2507.13812)
*Yingying Zhang,Lixiang Ru,Kang Wu,Lei Yu,Lei Liang,Yansheng Li,Jingdong Chen*

Main category: cs.CV

TL;DR: SkySense V2是一个统一的多模态遥感基础模型，采用单个Transformer骨干网络和定制的自监督学习策略，解决了现有模型冗余和特征多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态遥感基础模型通常为每种模态训练独立的骨干网络，导致冗余和参数利用效率低下。此外，主流预训练方法直接应用自然图像的自监督学习技术，未能充分适应遥感图像复杂的语义分布特性。

Method: SkySense V2采用一个统一的Transformer骨干网络来处理多模态数据，并引入了专为遥感数据设计的创新自监督学习策略。具体地，它包含了自适应补丁合并模块以应对不同分辨率，以及可学习模态提示令牌以解决模态间有限特征多样性问题。此外，该模型还集成了专家混合（MoE）模块以进一步提升性能。

Result: SkySense V2在涉及7项任务的16个数据集上进行了广泛评估，展示了令人印象深刻的泛化能力，平均性能比SkySense提高了1.8个点。

Conclusion: SkySense V2提供了一个更高效、更有效的统一多模态遥感基础模型，显著提升了地球观测任务的性能和泛化能力。

Abstract: The multi-modal remote sensing foundation model (MM-RSFM) has significantly
advanced various Earth observation tasks, such as urban planning, environmental
monitoring, and natural disaster management. However, most existing approaches
generally require the training of separate backbone networks for each data
modality, leading to redundancy and inefficient parameter utilization.
Moreover, prevalent pre-training methods typically apply self-supervised
learning (SSL) techniques from natural images without adequately accommodating
the characteristics of remote sensing (RS) images, such as the complicated
semantic distribution within a single RS image. In this work, we present
SkySense V2, a unified MM-RSFM that employs a single transformer backbone to
handle multiple modalities. This backbone is pre-trained with a novel SSL
strategy tailored to the distinct traits of RS data. In particular, SkySense V2
incorporates an innovative adaptive patch merging module and learnable modality
prompt tokens to address challenges related to varying resolutions and limited
feature diversity across modalities. In additional, we incorporate the mixture
of experts (MoE) module to further enhance the performance of the foundation
model. SkySense V2 demonstrates impressive generalization abilities through an
extensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense
by an average of 1.8 points.

</details>


### [87] [PositionIC: Unified Position and Identity Consistency for Image Customization](https://arxiv.org/abs/2507.13861)
*Junjie Hu,Tianyang Han,Kai Ma,Jialin Gao,Hao Dou,Song Yang,Xianhua He,Jianhui Zhang,Junfeng Luo,Xiaoming Wei,Wenqiang Zhang*

Main category: cs.CV

TL;DR: PositionIC是一个统一框架，通过引入可扩展合成管线和轻量级位置调制层，解决了多主体图像定制中缺乏精细空间控制的问题，实现了精确的空间定位和高保真度。


<details>
  <summary>Details</summary>
Motivation: 现有图像定制方法在保真度方面取得了显著进展，但缺乏精细的实体级空间控制，这主要是因为缺少将身份与精确位置线索绑定的可扩展数据集，从而阻碍了其在现实世界中的广泛应用。

Method: 本研究提出了PositionIC框架，包含两个核心组件：1) 一个可扩展的合成管线，采用双向生成范式来消除主体漂移并保持语义一致性。2) 一个轻量级的位置调制层，用于解耦主体之间的空间嵌入，从而实现独立的、精确的定位，同时保持视觉保真度。

Result: 实验证明，PositionIC方法能够在图像定制任务中实现精确的空间控制，同时保持高一致性和视觉保真度。

Conclusion: PositionIC为开放世界、多实体场景中的可控、高保真图像定制铺平了道路，并有望促进未来的相关研究。

Abstract: Recent subject-driven image customization has achieved significant
advancements in fidelity, yet fine-grained entity-level spatial control remains
elusive, hindering the broader real-world application. This limitation is
mainly attributed to scalable datasets that bind identity with precise
positional cues are absent. To this end, we introduce PositionIC, a unified
framework that enforces position and identity consistency for multi-subject
customization. We construct a scalable synthesis pipeline that employs a
bidirectional generation paradigm to eliminate subject drift and maintain
semantic coherence. On top of these data, we design a lightweight positional
modulation layer that decouples spatial embeddings among subjects, enabling
independent, accurate placement while preserving visual fidelity. Extensive
experiments demonstrate that our approach can achieve precise spatial control
while maintaining high consistency in image customization task. PositionIC
paves the way for controllable, high-fidelity image customization in
open-world, multi-entity scenarios and will be released to foster further
research.

</details>


### [88] [PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations](https://arxiv.org/abs/2507.13891)
*Yu Wei,Jiahui Zhang,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: PCR-GS是一种创新的免COLMAP 3D Gaussian Splatting技术，通过特征重投影和基于小波的频率正则化，解决了复杂相机轨迹下3D-GS场景建模和相机姿态估计性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 免COLMAP的3D Gaussian Splatting在处理相邻视图间存在剧烈旋转和平移的复杂相机轨迹场景时表现不佳，导致相机姿态估计退化，并在姿态与3D-GS联合优化中陷入局部最优。

Method: PCR-GS通过相机姿态协同正则化实现：1) 特征重投影正则化：从相邻视图提取视图鲁棒的DINO特征并对齐其语义信息以正则化相机姿态。2) 基于小波的频率正则化：利用高频细节差异进一步优化相机姿态中的旋转矩阵。

Result: 在多个真实世界场景的广泛实验表明，所提出的PCR-GS在相机轨迹剧烈变化的情况下，实现了卓越的无姿态3D-GS场景建模。

Conclusion: PCR-GS通过引入特征重投影和基于小波的频率正则化，显著提升了免COLMAP 3D-GS在处理复杂相机轨迹场景时的性能，实现了更优的场景建模和相机姿态估计。

Abstract: COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing
attention due to its remarkable performance in reconstructing high-quality 3D
scenes from unposed images or videos. However, it often struggles to handle
scenes with complex camera trajectories as featured by drastic rotation and
translation across adjacent camera views, leading to degraded estimation of
camera poses and further local minima in joint optimization of camera poses and
3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that
achieves superior 3D scene modeling and camera pose estimation via camera pose
co-regularization. PCR-GS achieves regularization from two perspectives. The
first is feature reprojection regularization which extracts view-robust DINO
features from adjacent camera views and aligns their semantic information for
camera pose regularization. The second is wavelet-based frequency
regularization which exploits discrepancy in high-frequency details to further
optimize the rotation matrix in camera poses. Extensive experiments over
multiple real-world scenes show that the proposed PCR-GS achieves superior
pose-free 3D-GS scene modeling under dramatic changes of camera trajectories.

</details>


### [89] [Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection](https://arxiv.org/abs/2507.13899)
*Yujian Mo,Yan Wu,Junqiao Zhao,Jijun Wang,Yinghao Hu,Jun Yan*

Main category: cs.CV

TL;DR: 该论文提出了一种方法，通过融合来自视觉基础模型DepthAnything的深度先验与原始LiDAR数据，以增强LiDAR点特征，从而提升3D目标检测的准确性。


<details>
  <summary>Details</summary>
Motivation: LiDAR点云特征（特别是反射率属性）的表达能力有限，判别性较弱。而DepthAnything等视觉基础模型能提供密集的几何先验，可以补充稀疏的LiDAR数据，但这些先验在LiDAR-based 3D目标检测中尚未得到充分利用。

Method: 1. 将DepthAnything预测的深度先验与原始LiDAR属性融合，以丰富每个点的表示。2. 提出一个点级特征提取模块。3. 采用双路径RoI特征提取框架，包含一个基于体素的分支（用于全局语义上下文）和一个基于点的分支（用于细粒度结构细节）。4. 引入一个双向门控RoI特征融合模块，以有效整合互补的RoI特征。

Result: 在KITTI基准测试上进行了广泛实验，结果表明该方法持续提高了检测精度。

Conclusion: 将视觉基础模型的先验知识融入基于LiDAR的3D目标检测具有重要价值，能够显著提升检测性能。

Abstract: Recent advances in foundation models have opened up new possibilities for
enhancing 3D perception. In particular, DepthAnything offers dense and reliable
geometric priors from monocular RGB images, which can complement sparse LiDAR
data in autonomous driving scenarios. However, such priors remain underutilized
in LiDAR-based 3D object detection. In this paper, we address the limited
expressiveness of raw LiDAR point features, especially the weak discriminative
capability of the reflectance attribute, by introducing depth priors predicted
by DepthAnything. These priors are fused with the original LiDAR attributes to
enrich each point's representation. To leverage the enhanced point features, we
propose a point-wise feature extraction module. Then, a Dual-Path RoI feature
extraction framework is employed, comprising a voxel-based branch for global
semantic context and a point-based branch for fine-grained structural details.
To effectively integrate the complementary RoI features, we introduce a
bidirectional gated RoI feature fusion module that balances global and local
cues. Extensive experiments on the KITTI benchmark show that our method
consistently improves detection accuracy, demonstrating the value of
incorporating visual foundation model priors into LiDAR-based 3D object
detection.

</details>


### [90] [TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views](https://arxiv.org/abs/2507.13929)
*Hsiang-Hui Hung,Huu-Phu Do,Yung-Hui Li,Ching-Chun Huang*

Main category: cs.CV

TL;DR: TimeNeRF是一种可泛化的神经渲染方法，能够在少量输入视图的情况下，在任意视点和任意时间渲染新颖视图，尤其擅长捕捉自然场景从白天到夜晚的平滑过渡。


<details>
  <summary>Details</summary>
Motivation: 在现实应用中，收集多视图数据成本高昂，且为未见场景重新优化效率低下。元宇宙等数字领域需要能够自然实现昼夜过渡的沉浸式3D环境。现有NeRF技术在合成新视图方面表现出色，但其在时间3D场景建模方面的潜力探索有限，且缺乏专用数据集。

Method: TimeNeRF结合了多视图立体、神经辐射场和跨不同数据集的解耦策略。这使得模型在少样本设置下具有泛化能力，能够构建用于场景表示的隐式内容辐射场，并进一步在任意时间构建神经辐射场。最后通过体渲染合成该时间的新视图。

Result: 实验表明，TimeNeRF能够在少样本设置下渲染新颖视图，无需进行逐场景优化。最显著的是，它在创建逼真的新颖视图方面表现出色，能够平滑地过渡不同时间，巧妙捕捉从黎明到黄昏复杂的自然场景变化。

Conclusion: TimeNeRF提出了一种新颖、可泛化的神经渲染方法，有效解决了在少样本条件下进行任意时间点和视点渲染的挑战，并成功实现了自然场景的平滑时间过渡建模。

Abstract: We present TimeNeRF, a generalizable neural rendering approach for rendering
novel views at arbitrary viewpoints and at arbitrary times, even with few input
views. For real-world applications, it is expensive to collect multiple views
and inefficient to re-optimize for unseen scenes. Moreover, as the digital
realm, particularly the metaverse, strives for increasingly immersive
experiences, the ability to model 3D environments that naturally transition
between day and night becomes paramount. While current techniques based on
Neural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing
novel views, the exploration of NeRF's potential for temporal 3D scene modeling
remains limited, with no dedicated datasets available for this purpose. To this
end, our approach harnesses the strengths of multi-view stereo, neural radiance
fields, and disentanglement strategies across diverse datasets. This equips our
model with the capability for generalizability in a few-shot setting, allows us
to construct an implicit content radiance field for scene representation, and
further enables the building of neural radiance fields at any arbitrary time.
Finally, we synthesize novel views of that time via volume rendering.
Experiments show that TimeNeRF can render novel views in a few-shot setting
without per-scene optimization. Most notably, it excels in creating realistic
novel views that transition smoothly across different times, adeptly capturing
intricate natural scene changes from dawn to dusk.

</details>


### [91] [DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization](https://arxiv.org/abs/2507.13934)
*Marzieh Gheisari,Auguste Genovesio*

Main category: cs.CV

TL;DR: DiViD是一种新颖的端到端视频扩散框架，用于无监督地解耦视频中的静态外观和动态运动，解决了现有方法的信息泄露和模糊重建问题，并取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 视频中静态外观和动态运动的无监督解耦仍然是一个基本挑战，现有基于VAE和GAN的方法常受到信息泄露和模糊重建的困扰。

Method: DiViD是首个端到端视频扩散框架，用于显式静态-动态分解。其序列编码器从第一帧提取全局静态token和每帧动态token，并明确从运动代码中去除静态内容。其条件DDPM解码器包含三个关键归纳偏置：用于时间一致性的共享噪声调度、随时间变化的KL瓶颈（早期紧缩以压缩静态信息，后期放松以丰富动态信息），以及将全局静态token路由到所有帧同时保持动态token帧特异性的交叉注意力。此外，采用正交正则化器防止残余的静态-动态泄露。

Result: DiViD在真实世界基准测试中超越了最先进的序列解耦方法，实现了最高的基于交换的联合准确性，在保持静态保真度的同时改进了动态迁移，并降低了平均交叉泄露。

Conclusion: DiViD成功解决了视频中静态外观和动态运动无监督解耦的挑战，在性能上显著优于现有方法，能够有效分离并重构视频中的静态和动态元素。

Abstract: Unsupervised disentanglement of static appearance and dynamic motion in video
remains a fundamental challenge, often hindered by information leakage and
blurry reconstructions in existing VAE- and GAN-based approaches. We introduce
DiViD, the first end-to-end video diffusion framework for explicit
static-dynamic factorization. DiViD's sequence encoder extracts a global static
token from the first frame and per-frame dynamic tokens, explicitly removing
static content from the motion code. Its conditional DDPM decoder incorporates
three key inductive biases: a shared-noise schedule for temporal consistency, a
time-varying KL-based bottleneck that tightens at early timesteps (compressing
static information) and relaxes later (enriching dynamics), and cross-attention
that routes the global static token to all frames while keeping dynamic tokens
frame-specific. An orthogonality regularizer further prevents residual
static-dynamic leakage. We evaluate DiViD on real-world benchmarks using
swap-based accuracy and cross-leakage metrics. DiViD outperforms
state-of-the-art sequential disentanglement methods: it achieves the highest
swap-based joint accuracy, preserves static fidelity while improving dynamic
transfer, and reduces average cross-leakage.

</details>


### [92] [Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset](https://arxiv.org/abs/2507.13981)
*Sara Abdulaziz,Giacomo D'Amicantonio,Egor Bondarev*

Main category: cs.CV

TL;DR: 本文提出了一个用于评估视觉隐私保护方法的综合框架，并引入了一个新的数据集HR-VISPR，以客观地量化隐私、效用和实用性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: AI驱动的监控技术日益普及，加剧了人们对敏感个人数据收集和处理的担忧。这促使研究转向隐私保护设计方案，并产生了对客观评估隐私保护技术的需求。

Method: 本文提出了一个在隐私、效用和实用性三个维度上评估视觉隐私保护方法的综合框架。此外，还引入了HR-VISPR，一个公开可用的以人为中心的数据集，包含生物识别、软生物识别和非生物识别标签，用于训练可解释的隐私度量。该研究使用所提出的框架评估了11种隐私保护方法，涵盖了传统技术和先进的深度学习方法。

Result: 该框架能够根据人类视觉感知区分隐私级别，并突出了隐私、效用和实用性之间的权衡。研究结果表明，该框架可以有效地评估不同隐私保护方法的性能。

Conclusion: 这项研究及其HR-VISPR数据集提供了一个有洞察力的工具和一个结构化的评估框架，适用于各种背景下的视觉隐私保护方法评估。

Abstract: Recent advances in AI-powered surveillance have intensified concerns over the
collection and processing of sensitive personal data. In response, research has
increasingly focused on privacy-by-design solutions, raising the need for
objective techniques to evaluate privacy protection. This paper presents a
comprehensive framework for evaluating visual privacy-protection methods across
three dimensions: privacy, utility, and practicality. In addition, it
introduces HR-VISPR, a publicly available human-centric dataset with biometric,
soft-biometric, and non-biometric labels to train an interpretable privacy
metric. We evaluate 11 privacy protection methods, ranging from conventional
techniques to advanced deep-learning methods, through the proposed framework.
The framework differentiates privacy levels in alignment with human visual
perception, while highlighting trade-offs between privacy, utility, and
practicality. This study, along with the HR-VISPR dataset, serves as an
insightful tool and offers a structured evaluation framework applicable across
diverse contexts.

</details>


### [93] [DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation](https://arxiv.org/abs/2507.13985)
*Haoran Li,Yuli Tian,Kun Lan,Yong Liao,Lin Wang,Pan Hui,Peng Yuan Zhou*

Main category: cs.CV

TL;DR: DreamScene是一个端到端框架，能够从文本或对话生成高质量、可编辑的3D场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从自然语言生成3D场景时，面临自动化程度低、3D一致性差和精细控制不足的问题。

Method: DreamScene首先通过GPT-4代理进行场景规划，推断对象语义和空间约束以构建混合图。接着，图基放置算法生成无碰撞布局。基于此布局，Formation Pattern Sampling (FPS) 使用多时间步采样和重建优化生成对象几何。为确保全局一致性，系统采用渐进式相机采样策略。此外，DreamScene支持对象移动、外观变化和4D动态运动等精细编辑。

Result: 实验表明，DreamScene在质量、一致性和灵活性方面超越了现有方法，为开放域3D内容创作提供了实用解决方案。

Conclusion: DreamScene提供了一个实用、高质量且可编辑的解决方案，用于从文本或对话生成3D场景，解决了现有方法在自动化、一致性和控制方面的局限性。

Abstract: Generating 3D scenes from natural language holds great promise for
applications in gaming, film, and design. However, existing methods struggle
with automation, 3D consistency, and fine-grained control. We present
DreamScene, an end-to-end framework for high-quality and editable 3D scene
generation from text or dialogue. DreamScene begins with a scene planning
module, where a GPT-4 agent infers object semantics and spatial constraints to
construct a hybrid graph. A graph-based placement algorithm then produces a
structured, collision-free layout. Based on this layout, Formation Pattern
Sampling (FPS) generates object geometry using multi-timestep sampling and
reconstructive optimization, enabling fast and realistic synthesis. To ensure
global consistent, DreamScene employs a progressive camera sampling strategy
tailored to both indoor and outdoor settings. Finally, the system supports
fine-grained scene editing, including object movement, appearance changes, and
4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior
methods in quality, consistency, and flexibility, offering a practical solution
for open-domain 3D content creation. Code and demos are available at
https://dreamscene-project.github.io.

</details>


### [94] [Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations](https://arxiv.org/abs/2507.14010)
*Yong Feng,Xiaolei Zhang,Shijin Feng,Yong Zhao,Yihan Chen*

Main category: cs.CV

TL;DR: 本研究提出了一种两步深度学习方法，用于提高隧道衬砌裂缝的分类和分割精度及效率，并结合视觉解释技术，为隧道健康状态的快速准确评估提供了基础。


<details>
  <summary>Details</summary>
Motivation: 隧道衬砌裂缝是隧道安全状况的关键指标。为了提高裂缝分类和分割的准确性和效率，研究旨在开发一种自动化的检测方法。

Method: 该方法包括两步：第一步，使用DenseNet-169开发隧道图像分类模型，自动筛选出包含裂缝的图像；第二步，对筛选出的图像使用基于DeepLabV3+的裂缝分割模型进行分割。此外，还通过得分加权视觉解释技术评估了分割模型的内部逻辑，以提高模型可解释性。

Result: 实验验证了该两步法的优越性能。隧道裂缝分类模型的准确率达到92.23%，FPS为39.80，均高于其他基于CNN和Transformer的模型。隧道裂缝分割模型的IoU为57.01%，F1分数为67.44%，优于其他先进模型。此外，提供的视觉解释有助于理解深度学习模型的“黑箱”特性。

Conclusion: 所开发的两阶段深度学习方法，结合视觉解释，为隧道健康状况的快速准确量化评估提供了基础。

Abstract: Tunnel lining crack is a crucial indicator of tunnels' safety status. Aiming
to classify and segment tunnel cracks with enhanced accuracy and efficiency,
this study proposes a two-step deep learning-based method. An automatic tunnel
image classification model is developed using the DenseNet-169 in the first
step. The proposed crack segmentation model in the second step is based on the
DeepLabV3+, whose internal logic is evaluated via a score-weighted visual
explanation technique. Proposed method combines tunnel image classification and
segmentation together, so that the selected images containing cracks from the
first step are segmented in the second step to improve the detection accuracy
and efficiency. The superior performances of the two-step method are validated
by experiments. The results show that the accuracy and frames per second (FPS)
of the tunnel crack classification model are 92.23% and 39.80, respectively,
which are higher than other convolutional neural networks (CNN) based and
Transformer based models. Also, the intersection over union (IoU) and F1 score
of the tunnel crack segmentation model are 57.01% and 67.44%, respectively,
outperforming other state-of-the-art models. Moreover, the provided visual
explanations in this study are conducive to understanding the "black box" of
deep learning-based models. The developed two-stage deep learning-based method
integrating visual explanations provides a basis for fast and accurate
quantitative assessment of tunnel health status.

</details>


### [95] [Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model](https://arxiv.org/abs/2507.14013)
*Ji-Yan Wu,Zheng Yong Poh,Anoop C. Patil,Bongsoo Park,Giovanni Volpe,Daisuke Urano*

Main category: cs.CV

TL;DR: 本研究提出了一种基于多光谱成像和改进YOLOv5模型的深度学习框架，用于植物叶片异常分割，以精确检测养分缺乏。


<details>
  <summary>Details</summary>
Motivation: 在精准农业中，准确检测植物叶片养分缺乏对于早期干预施肥、疾病和胁迫管理至关重要。

Method: 研究采用深度学习框架进行叶片异常分割，使用九通道多光谱输入。模型基于增强的YOLOv5，并集成了一个基于Transformer的注意力头，利用自注意力机制更好地捕捉细微、空间分布的症状。实验中植物在受控养分胁迫条件下生长。

Result: 所提出的模型显著优于基线YOLOv5，平均Dice分数和IoU（交并比）提高了约12%。该模型在检测叶片黄化和色素积累等挑战性症状方面尤其有效。

Conclusion: 结合多光谱成像与光谱-空间特征学习在推进植物表型分析和精准农业方面具有广阔前景。

Abstract: Accurate detection of nutrient deficiency in plant leaves is essential for
precision agriculture, enabling early intervention in fertilization, disease,
and stress management. This study presents a deep learning framework for leaf
anomaly segmentation using multispectral imaging and an enhanced YOLOv5 model
with a transformer-based attention head. The model is tailored for processing
nine-channel multispectral input and uses self-attention mechanisms to better
capture subtle, spatially-distributed symptoms. The plants in the experiments
were grown under controlled nutrient stress conditions for evaluation. We carry
out extensive experiments to benchmark the proposed model against the baseline
YOLOv5. Extensive experiments show that the proposed model significantly
outperforms the baseline YOLOv5, with an average Dice score and IoU
(Intersection over Union) improvement of about 12%. In particular, this model
is effective in detecting challenging symptoms like chlorosis and pigment
accumulation. These results highlight the promise of combining multi-spectral
imaging with spectral-spatial feature learning for advancing plant phenotyping
and precision agriculture.

</details>


### [96] [Moodifier: MLLM-Enhanced Emotion-Driven Image Editing](https://arxiv.org/abs/2507.14024)
*Jiarong Ye,Sharon X. Huang*

Main category: cs.CV

TL;DR: 情感驱动的图像编辑具有巨大潜力，但情感的抽象性使其难以精确操作。本文提出Moodifier系统，包含大规模情感数据集MoodArchive、情感视觉语言模型MoodifyCLIP和免训练编辑模型Moodifier，实现跨领域的情感图像编辑，同时保持内容完整性。


<details>
  <summary>Details</summary>
Motivation: 在创意产业中，将情感与视觉内容结合进行情感驱动的图像编辑潜力巨大。然而，由于情感的抽象性及其在不同语境下的多样化表现，精确的情感操作仍然具有挑战性。

Method: 本文采用集成方法，包含三个互补组件：1. **MoodArchive数据集**: 构建了一个包含800多万张图像的大规模数据集，具有详细的分层情感标注。2. **MoodifyCLIP模型**: 开发了一个在MoodArchive上微调的视觉-语言模型，用于将抽象情感转化为具体的视觉属性。3. **Moodifier编辑模型**: 提出一个免训练的编辑模型，利用MoodifyCLIP和多模态大语言模型（MLLMs），实现精确的情感转换，同时保持内容完整性。

Result: Moodifier系统能够在角色表情、时尚设计、珠宝和家居装饰等不同领域进行情感编辑，帮助创作者快速可视化情感变化，同时保留身份和结构。广泛的实验评估表明，Moodifier在情感准确性和内容保留方面均优于现有方法，提供符合语境的编辑。

Conclusion: 通过将抽象情感与具体的视觉变化联系起来，本解决方案为现实世界应用中的情感内容创作开辟了新的可能性。该研究将发布数据集、模型代码和演示。

Abstract: Bridging emotions and visual content for emotion-driven image editing holds
great potential in creative industries, yet precise manipulation remains
challenging due to the abstract nature of emotions and their varied
manifestations across different contexts. We tackle this challenge with an
integrated approach consisting of three complementary components. First, we
introduce MoodArchive, an 8M+ image dataset with detailed hierarchical
emotional annotations generated by LLaVA and partially validated by human
evaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned
on MoodArchive to translate abstract emotions into specific visual attributes.
Third, we propose Moodifier, a training-free editing model leveraging
MoodifyCLIP and multimodal large language models (MLLMs) to enable precise
emotional transformations while preserving content integrity. Our system works
across diverse domains such as character expressions, fashion design, jewelry,
and home d\'ecor, enabling creators to quickly visualize emotional variations
while preserving identity and structure. Extensive experimental evaluations
show that Moodifier outperforms existing methods in both emotional accuracy and
content preservation, providing contextually appropriate edits. By linking
abstract emotions to concrete visual changes, our solution unlocks new
possibilities for emotional content creation in real-world applications. We
will release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier
code and demo publicly available upon acceptance.

</details>


### [97] [QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography](https://arxiv.org/abs/2507.14031)
*Hao Fang,Sihao Teng,Hao Yu,Siyi Yuan,Huaiwu He,Zhe Liu,Yunjie Yang*

Main category: cs.CV

TL;DR: QuantEIT是一种超轻量级、量子辅助的EIT图像重建框架，它通过结合量子电路和线性层，在无监督、无训练数据的情况下，以极少的参数实现了比传统方法更优或相当的重建精度和噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: EIT作为一种床旁成像技术，具有高时间分辨率，但其固有的病态逆问题使得图像重建极具挑战。现有的深度学习方法虽然有前景，但通常依赖于复杂的网络架构和大量参数，限制了效率和可扩展性。

Method: 本文提出了一种名为QuantEIT的超轻量级量子辅助推理框架。它利用量子辅助网络（QA-Net），结合并行的2量子比特量子电路来生成富有表现力的潜在表示（作为隐式非线性先验），然后通过单个线性层进行电导率重建。该设计显著降低了模型复杂度和参数数量。QuantEIT以无监督、无训练数据的方式运行，是首次将量子电路集成到EIT图像重建中。

Result: 在模拟和真实世界的2D和3D EIT肺部成像数据上的广泛实验表明，QuantEIT优于传统方法，仅使用0.2%的参数即可实现相当或更优的重建精度，并增强了对噪声的鲁棒性。

Conclusion: QuantEIT提供了一种高效、精确且参数极少的EIT图像重建解决方案，通过引入量子电路实现了无监督学习，克服了传统深度学习方法的复杂性限制，并展示了在实际应用中的巨大潜力。

Abstract: Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside
imaging modality with high temporal resolution, making it suitable for bedside
monitoring. However, its inherently ill-posed inverse problem poses significant
challenges for accurate image reconstruction. Deep learning (DL)-based
approaches have shown promise but often rely on complex network architectures
with a large number of parameters, limiting efficiency and scalability. Here,
we propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework
for EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network
(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive
latent representations that serve as implicit nonlinear priors, followed by a
single linear layer for conductivity reconstruction. This design drastically
reduces model complexity and parameter number. Uniquely, QuantEIT operates in
an unsupervised, training-data-free manner and represents the first integration
of quantum circuits into EIT image reconstruction. Extensive experiments on
simulated and real-world 2D and 3D EIT lung imaging data demonstrate that
QuantEIT outperforms conventional methods, achieving comparable or superior
reconstruction accuracy using only 0.2% of the parameters, with enhanced
robustness to noise.

</details>


### [98] [Training-free Token Reduction for Vision Mamba](https://arxiv.org/abs/2507.14042)
*Qiankun Ma,Ziyao Zhang,Chi Su,Jie Chen,Zhen Song,Hairong Zheng,Wen Gao*

Main category: cs.CV

TL;DR: 提出了一个针对Vision Mamba模型的免训练令牌缩减框架MTR，通过引入Mamba结构感知的令牌重要性评分，显著降低计算量同时保持性能。


<details>
  <summary>Details</summary>
Motivation: Vision Mamba在处理长距离依赖方面具有线性计算复杂度的优势，但其效率优化（如令牌缩减）尚未被充分探索。现有ViT的令牌缩减技术不适用于Vision Mamba，因为Mamba是序列模型且缺乏注意力机制，而这些技术依赖注意力机制进行重要性评估且忽略令牌顺序。因此，探索Vision Mamba的效率以实现更广泛的应用至关重要。

Method: 本文研究了一种Mamba结构感知的令牌重要性评分方法，以简单有效的方式评估令牌重要性。在此基础上，提出了一个名为MTR（Mamba Token Reduction）的免训练框架。该方法无需训练或额外调参，可作为即插即用组件无缝集成到各种Mamba模型中。

Result: MTR显著降低了计算负载，同时最大程度地减少了性能影响。在Vim-B骨干网络上，MTR将FLOPs降低了约40%，而ImageNet性能仅下降1.6%（无需重新训练）。

Conclusion: MTR框架有效实现了Vision Mamba模型的令牌缩减，显著提升了其计算效率，使其能更广泛地应用于各种任务，且无需额外训练或调参，表现出良好的通用性和实用性。

Abstract: Vision Mamba has emerged as a strong competitor to Vision Transformers (ViTs)
due to its ability to efficiently capture long-range dependencies with linear
computational complexity. While token reduction, an effective compression
technique in ViTs, has rarely been explored in Vision Mamba. Exploring Vision
Mamba's efficiency is essential for enabling broader applications. However, we
find that directly applying existing token reduction techniques for ViTs to
Vision Mamba leads to significant performance degradation. This is primarily
because Mamba is a sequence model without attention mechanisms, whereas most
token reduction techniques for ViTs rely on attention mechanisms for importance
measurement and overlook the order of compressed tokens. In this paper, we
investigate a Mamba structure-aware importance score to evaluate token
importance in a simple and effective manner. Building on this score, we further
propose MTR, a training-free \textbf{M}amba \textbf{T}oken \textbf{R}eduction
framework. Without the need for training or additional tuning parameters, our
method can be seamlessly integrated as a plug-and-play component across various
Mamba models. Extensive experiments demonstrate that our approach significantly
reduces computational workload while minimizing performance impact across
various tasks and multiple backbones. Notably, MTR reduces FLOPs by
approximately 40\% on the Vim-B backbone, with only a 1.6\% drop in ImageNet
performance without retraining.

</details>


### [99] [Foundation Models as Class-Incremental Learners for Dermatological Image Classification](https://arxiv.org/abs/2507.14050)
*Mohamed Elkhayat,Mohamed Mahmoud,Jamil Fayyad,Nourhan Bayasi*

Main category: cs.CV

TL;DR: 本文系统评估了预训练的冻结基础模型在皮肤病分类的类增量学习（CIL）中的潜力，并提出了一种简单有效的方法，通过冻结骨干网络和增量训练轻量级MLP，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 基础模型（FM）提供了丰富的可迁移表示，为类增量学习（CIL）带来了新机遇。然而，其在皮肤病学领域实现增量学习的潜力尚未被充分探索。

Method: 研究系统评估了在大型皮肤病变数据集上预训练的冻结基础模型在皮肤病分类CIL中的表现。提出了一种简单有效的方法：骨干网络保持冻结，并为每个任务增量训练一个轻量级多层感知器（MLP）。此外，还探索了零训练场景，使用基于基础模型嵌入派生的原型进行最近均值分类。

Result: 所提出的冻结基础模型加轻量级MLP的方法在不遗忘的情况下实现了最先进的性能，优于基于正则化、回放和架构的方法。基于原型的零训练变体也取得了有竞争力的结果。

Conclusion: 研究结果强调了冻结基础模型在皮肤病学持续学习中的强大能力，并支持它们在真实世界医疗应用中的更广泛采用。

Abstract: Class-Incremental Learning (CIL) aims to learn new classes over time without
forgetting previously acquired knowledge. The emergence of foundation models
(FM) pretrained on large datasets presents new opportunities for CIL by
offering rich, transferable representations. However, their potential for
enabling incremental learning in dermatology remains largely unexplored. In
this paper, we systematically evaluate frozen FMs pretrained on large-scale
skin lesion datasets for CIL in dermatological disease classification. We
propose a simple yet effective approach where the backbone remains frozen, and
a lightweight MLP is trained incrementally for each task. This setup achieves
state-of-the-art performance without forgetting, outperforming regularization,
replay, and architecture based methods. To further explore the capabilities of
frozen FMs, we examine zero training scenarios using nearest mean classifiers
with prototypes derived from their embeddings. Through extensive ablation
studies, we demonstrate that this prototype based variant can also achieve
competitive results. Our findings highlight the strength of frozen FMs for
continual learning in dermatology and support their broader adoption in real
world medical applications. Our code and datasets are available here.

</details>


### [100] [Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection](https://arxiv.org/abs/2507.14083)
*Sara Abdulaziz,Egor Bondarev*

Main category: cs.CV

TL;DR: 该研究评估了四种人体匿名化技术（模糊、遮罩、加密、头像替换）对视频监控异常检测性能的影响，并分析了不同异常检测算法对匿名化模式的敏感性，探讨了隐私保护与检测效用之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习提升了监控视频中的异常检测能力，但敏感人体数据的收集引发了紧迫的隐私问题。

Method: 研究在UCF-Crime数据集上应用了模糊、遮罩、加密和头像替换四种人体匿名化技术。然后，评估了MGFN、UR-DMU、BN-WVAD和PEL4VAD四种异常检测方法在这些匿名化数据上的性能。此外，还比较了传统匿名化技术与新兴的隐私设计（privacy-by-design）解决方案。

Result: 实验结果表明，在匿名化数据下异常检测仍然可行，且其性能取决于算法设计和学习策略。在某些匿名化模式（如加密和遮罩）下，一些模型甚至比使用原始数据获得了更高的AUC性能，这是由于其算法组件对这些“噪声模式”的强响应性。这些结果突出了算法对匿名化的特定敏感性，并强调了隐私保护与检测效用之间的权衡。此外，研究还揭示了鲁棒隐私保护与效用灵活性之间的权衡。

Conclusion: 本研究通过全面的实验和分析，为平衡人体隐私与异常检测需求提供了一个有说服力的基准和深入见解。

Abstract: Advancements in deep learning have improved anomaly detection in surveillance
videos, yet they raise urgent privacy concerns due to the collection of
sensitive human data. In this paper, we present a comprehensive analysis of
anomaly detection performance under four human anonymization techniques,
including blurring, masking, encryption, and avatar replacement, applied to the
UCF-Crime dataset. We evaluate four anomaly detection methods, MGFN, UR-DMU,
BN-WVAD, and PEL4VAD, on the anonymized UCF-Crime to reveal how each method
responds to different obfuscation techniques. Experimental results demonstrate
that anomaly detection remains viable under anonymized data and is dependent on
the algorithmic design and the learning strategy. For instance, under certain
anonymization patterns, such as encryption and masking, some models
inadvertently achieve higher AUC performance compared to raw data, due to the
strong responsiveness of their algorithmic components to these noise patterns.
These results highlight the algorithm-specific sensitivities to anonymization
and emphasize the trade-off between preserving privacy and maintaining
detection utility. Furthermore, we compare these conventional anonymization
techniques with the emerging privacy-by-design solutions, highlighting an often
overlooked trade-off between robust privacy protection and utility flexibility.
Through comprehensive experiments and analyses, this study provides a
compelling benchmark and insights into balancing human privacy with the demands
of anomaly detection.

</details>


### [101] [C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected δ-Overlap Graphs](https://arxiv.org/abs/2507.14095)
*Yung-Hong Sun,Ting-Hung Lin,Jiangang Chen,Hongrui Jiang,Yu Hen Hu*

Main category: cs.CV

TL;DR: C-DOG是一个免训练的多视图多目标关联框架，它结合了连接delta-overlap图建模和对极几何，在不依赖视觉特征的情况下，即使在挑战性条件下也能鲁棒地关联跨视图检测。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图多目标关联方法依赖外观特征或几何约束（如对极一致性），但在物体视觉上难以区分或观测受噪声污染时会失效。因此需要一种更鲁棒的方法。

Method: C-DOG是一个连接目标检测/姿态估计与3D重建的中间模块，不依赖视觉特征。它将每个2D观测表示为图节点，边权重由对极一致性决定。通过delta-neighbor-overlap聚类识别强一致性组，同时容忍噪声和部分连接。为进一步提高鲁棒性，引入了基于四分位距(IQR)的过滤和3D反投影误差准则来消除不一致观测。

Result: 在合成基准测试中，C-DOG优于基于几何的基线方法，并在高物体密度、无视觉特征和有限相机重叠等挑战性条件下保持鲁棒性。

Conclusion: C-DOG的鲁棒性和在挑战性条件下的优异表现使其非常适合可扩展的真实世界3D重建场景。

Abstract: Multi-view multi-object association is a fundamental step in 3D
reconstruction pipelines, enabling consistent grouping of object instances
across multiple camera views. Existing methods often rely on appearance
features or geometric constraints such as epipolar consistency. However, these
approaches can fail when objects are visually indistinguishable or observations
are corrupted by noise. We propose C-DOG, a training-free framework that serves
as an intermediate module bridging object detection (or pose estimation) and 3D
reconstruction, without relying on visual features. It combines connected
delta-overlap graph modeling with epipolar geometry to robustly associate
detections across views. Each 2D observation is represented as a graph node,
with edges weighted by epipolar consistency. A delta-neighbor-overlap
clustering step identifies strongly consistent groups while tolerating noise
and partial connectivity. To further improve robustness, we incorporate
Interquartile Range (IQR)-based filtering and a 3D back-projection error
criterion to eliminate inconsistent observations. Extensive experiments on
synthetic benchmarks demonstrate that C-DOG outperforms geometry-based
baselines and remains robust under challenging conditions, including high
object density, without visual features, and limited camera overlap, making it
well-suited for scalable 3D reconstruction in real-world scenarios.

</details>


### [102] [Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning](https://arxiv.org/abs/2507.14137)
*Shashanka Venkataramanan,Valentinos Pariza,Mohammadreza Salehi,Lukas Knobel,Spyros Gidaris,Elias Ramzi,Andrei Bursuc,Yuki M. Asano*

Main category: cs.CV

TL;DR: Franca是一个完全开源的视觉基础模型，性能媲美甚至超越现有专有模型，通过引入多头聚类投影器和位置解耦策略，解决了自监督学习中的聚类语义模糊和位置偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型多为专有且不透明，同时自监督学习（SSL）中的聚类方法（如Sinkhorn-Knopp）存在语义模糊性，无法有效处理特征的细粒度划分，且密集表示中存在位置偏差。

Method: Franca采用透明的训练流程（受Web-SSL启发），使用公开数据集（ImageNet-21K和ReLAION-2B子集）。核心方法包括：1) 引入基于嵌套Matryoshka表示的参数高效、多头聚类投影器，实现特征的渐进式细化，同时提高性能和内存效率。2) 提出新颖的位置解耦策略，显式消除密集表示中的位置偏差，以提升语义内容的编码质量。

Result: Franca的性能与DINOv2、CLIP、SigLIPv2等最先进的专有模型相当，并在许多情况下超越它们。多头聚类设计在不增加模型大小的情况下实现了性能和内存效率。位置解耦策略在多个下游基准测试中带来了显著的性能提升，表明了更清晰特征空间的有效性。

Conclusion: Franca为透明、高性能的视觉模型树立了新标准，为人工智能社区中更可复现和泛化的基础模型开辟了道路。

Abstract: We present Franca (pronounced Fran-ka): free one; the first fully open-source
(data, code, weights) vision foundation model that matches and in many cases
surpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,
CLIP, SigLIPv2, etc. Our approach is grounded in a transparent training
pipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and
a subset of ReLAION-2B. Beyond model release, we tackle critical limitations in
SSL clustering methods. While modern models rely on assigning image features to
large codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to
account for the inherent ambiguity in clustering semantics. To address this, we
introduce a parameter-efficient, multi-head clustering projector based on
nested Matryoshka representations. This design progressively refines features
into increasingly fine-grained clusters without increasing the model size,
enabling both performance and memory efficiency. Additionally, we propose a
novel positional disentanglement strategy that explicitly removes positional
biases from dense representations, thereby improving the encoding of semantic
content. This leads to consistent gains on several downstream benchmarks,
demonstrating the utility of cleaner feature spaces. Our contributions
establish a new standard for transparent, high-performance vision models and
open a path toward more reproducible and generalizable foundation models for
the broader AI community. The code and model checkpoints are available at
https://github.com/valeoai/Franca.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [103] [Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](https://arxiv.org/abs/2507.13357)
*Atharva Bhargude,Ishan Gonehal,Chandler Haney,Dave Yoon,Kevin Zhu,Aaron Sandoval,Sean O'Brien,Kaustubh Vinnakota*

Main category: cs.CL

TL;DR: 本研究利用少数样本自适应语言提示（ALP）结合GPT-4o和Gemini 1.5 Pro等多模态大型语言模型（LLMs），实现对网络钓鱼网页的高效检测，并取得了显著的F1分数。


<details>
  <summary>Details</summary>
Motivation: 网络钓鱼攻击是重大的网络安全威胁，需要自适应的检测技术来应对。

Method: 采用少数样本自适应语言提示（ALP），这是一种结构化的语义推理方法，指导LLMs分析文本欺骗，包括识别语言模式、紧急提示和操纵性措辞。该方法整合了文本、视觉和URL信息进行多模态分析，以识别复杂的网络钓鱼尝试。

Result: 实验证明，ALP显著提高了网络钓鱼检测的准确性，通过结构化推理和上下文分析指导LLMs。该方法实现了0.93的F1分数，超越了传统方法。

Conclusion: 研究结果表明，结合ALP的多模态LLMs在推进网络钓鱼检测框架方面具有巨大潜力，为更鲁棒、可解释和自适应的基于语言的网络钓鱼检测系统奠定了基础。

Abstract: Phishing attacks represent a significant cybersecurity threat, necessitating
adaptive detection techniques. This study explores few-shot Adaptive Linguistic
Prompting (ALP) in detecting phishing webpages through the multimodal
capabilities of state-of-the-art large language models (LLMs) such as GPT-4o
and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides
LLMs to analyze textual deception by breaking down linguistic patterns,
detecting urgency cues, and identifying manipulative diction commonly found in
phishing content. By integrating textual, visual, and URL-based analysis, we
propose a unified model capable of identifying sophisticated phishing attempts.
Our experiments demonstrate that ALP significantly enhances phishing detection
accuracy by guiding LLMs through structured reasoning and contextual analysis.
The findings highlight the potential of ALP-integrated multimodal LLMs to
advance phishing detection frameworks, achieving an F1-score of 0.93,
surpassing traditional approaches. These results establish a foundation for
more robust, interpretable, and adaptive linguistic-based phishing detection
systems using LLMs.

</details>


### [104] [Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition](https://arxiv.org/abs/2507.13380)
*Keito Inoshita,Rushia Harada*

Main category: cs.CL

TL;DR: PersonaGen是一个新颖的框架，利用大型语言模型（LLM）通过多阶段基于角色的条件作用生成情感丰富的文本，旨在解决高质量情感数据集稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 情感识别领域面临高质量、多样化情感数据集稀缺的挑战。情感表达具有主观性，受个体特质、社会文化背景和情境因素影响，导致大规模、通用性数据收集在伦理和实践上都很困难。

Method: 该研究引入了PersonaGen框架，通过多阶段基于角色的条件作用，利用大型语言模型（LLM）生成情感文本。PersonaGen构建分层虚拟角色，结合人口统计属性、社会文化背景和详细情境上下文，以此引导情感表达的生成。生成的合成数据通过聚类和分布度量评估语义多样性，通过基于LLM的质量评分评估类人度，通过与真实世界情感语料库比较评估真实性，并通过下游情感分类任务评估实用性。

Result: 实验结果表明，PersonaGen在生成多样、连贯和可区分的情感表达方面显著优于基线方法。

Conclusion: PersonaGen展示了作为增强或替代真实世界情感数据集的强大潜力，是一种稳健的替代方案。

Abstract: In the field of emotion recognition, the development of high-performance
models remains a challenge due to the scarcity of high-quality, diverse
emotional datasets. Emotional expressions are inherently subjective, shaped by
individual personality traits, socio-cultural backgrounds, and contextual
factors, making large-scale, generalizable data collection both ethically and
practically difficult. To address this issue, we introduce PersonaGen, a novel
framework for generating emotionally rich text using a Large Language Model
(LLM) through multi-stage persona-based conditioning. PersonaGen constructs
layered virtual personas by combining demographic attributes, socio-cultural
backgrounds, and detailed situational contexts, which are then used to guide
emotion expression generation. We conduct comprehensive evaluations of the
generated synthetic data, assessing semantic diversity through clustering and
distributional metrics, human-likeness via LLM-based quality scoring, realism
through comparison with real-world emotion corpora, and practical utility in
downstream emotion classification tasks. Experimental results show that
PersonaGen significantly outperforms baseline methods in generating diverse,
coherent, and discriminative emotion expressions, demonstrating its potential
as a robust alternative for augmenting or replacing real-world emotional
datasets.

</details>


### [105] [SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation](https://arxiv.org/abs/2507.13381)
*Rafiq Kamel,Filippo Guerranti,Simon Geisler,Stephan Günnemann*

Main category: cs.CL

TL;DR: SAFT是一种结构感知微调方法，通过注入图拓扑信息，显著提升了大型语言模型在AMR到文本生成任务上的性能，并达到了新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理图等结构化输入时，要么随意线性化AMR导致结构信息丢失，要么依赖与标准LLM不兼容的架构。因此，需要一种在不改变LLM架构的情况下，有效利用图结构信息的方法。

Method: SAFT方法通过计算转换后的AMR的磁拉普拉斯算子（magnetic Laplacian）得到方向敏感的位置编码，并将其投影到LLM的嵌入空间中。这是一种结构感知的微调方法，无需改变LLM的内部架构。

Result: SAFT在AMR 3.0数据集上取得了新的最先进成果，相较于基线模型，BLEU分数提升了3.5。性能提升随着图复杂度的增加而更为显著，这凸显了结构感知表示在提升LLM性能方面的价值。

Conclusion: SAFT提供了一种通用且有效的方法，用于连接结构化数据（特别是图）和语言模型，通过利用结构感知表示来增强LLM的性能。

Abstract: Large Language Models (LLMs) are increasingly applied to tasks involving
structured inputs such as graphs. Abstract Meaning Representations (AMRs),
which encode rich semantics as directed graphs, offer a rigorous testbed for
evaluating LLMs on text generation from such structures. Yet, current methods
often arbitrarily linearize AMRs, discarding key structural cues, or rely on
architectures incompatible with standard LLMs. We introduce SAFT, a
structure-aware fine-tuning approach that injects graph topology into
pretrained LLMs without architectural changes. We compute direction-sensitive
positional encodings from the magnetic Laplacian of transformed AMRs and
project them into the embedding space of the LLM. While possibly applicable to
any graph-structured inputs, we focus on AMR-to-text generation as a
representative and challenging benchmark. SAFT sets a new state-of-the-art on
AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph
complexity, highlighting the value of structure-aware representations in
enhancing LLM performance. SAFT offers a general and effective pathway for
bridging structured data and language models.

</details>


### [106] [Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case](https://arxiv.org/abs/2507.13382)
*Chandrashekar Muniyappa,Sirisha Velampalli*

Main category: cs.CL

TL;DR: 本文提出了一种基于上下文图的方法，利用NLP技术将新闻文章转换为图结构，并结合MDL-GBAD算法进行图挖掘，以检测虚假新闻。


<details>
  <summary>Details</summary>
Motivation: 虚假新闻在数字世界中传播迅速，是一个亟待解决的重大问题。

Method: 研究方法包括：1) 结合Kaggle数据集和近期COVID-19新闻文章；2) 利用自然语言处理（NLP）技术将新闻文章转换为上下文图结构；3) 应用基于最小描述长度（MDL）的图基异常检测（GBAD）算法进行图挖掘；4) 识别数据集中的规范模式，并发现偏离这些规范的异常模式。

Result: 该方法能够识别数据集中的规范模式，并随后揭示偏离这些既定规范的异常模式（即虚假新闻）。

Conclusion: 图基方法在处理丰富的上下文数据方面特别有效，能够发现传统方法可能忽略的复杂模式，从而有效检测虚假新闻。

Abstract: In today\'s digital world, fake news is spreading with immense speed. Its a
significant concern to address. In this work, we addressed that challenge using
novel graph based approach. We took dataset from Kaggle that contains real and
fake news articles. To test our approach we incorporated recent covid-19
related news articles that contains both genuine and fake news that are
relevant to this problem. This further enhances the dataset as well instead of
relying completely on the original dataset. We propose a contextual graph-based
approach to detect fake news articles. We need to convert news articles into
appropriate schema, so we leverage Natural Language Processing (NLP) techniques
to transform news articles into contextual graph structures. We then apply the
Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)
algorithm for graph mining. Graph-based methods are particularly effective for
handling rich contextual data, as they enable the discovery of complex patterns
that traditional query-based or statistical techniques might overlook. Our
proposed approach identifies normative patterns within the dataset and
subsequently uncovers anomalous patterns that deviate from these established
norms.

</details>


### [107] [PARAM-1 BharatGen 2.9B Model](https://arxiv.org/abs/2507.13390)
*Kundeshwar Pundalik,Piyush Sawarkar,Nihar Sahoo,Abhishek Shinde,Prateek Chanda,Vedant Goswami,Ajay Nagpal,Atul Singh,Viraj Thakur,Vijay Dewane,Aamod Thakur,Bhargav Patel,Smita Gautam,Bhagwan Panditi,Shyam Pawar,Madhav Kotcha,Suraj Racha,Saral Sureka,Pankaj Singh,Rishi Bal,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 本文介绍了PARAM-1，一个2.9B参数的解码器专用语言模型，旨在解决大型语言模型在印度语言多样性方面的代表性不足问题，通过从头训练并明确关注印度语言和文化多样性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）主要以英语为中心，导致印度等语言多样性丰富的地区在数据、架构和优化范式上存在结构性代表不足，无法充分处理印度的多种官方语言、方言、语码转换和双言现象。

Method: PARAM-1是一个2.9B参数的解码器专用、纯文本语言模型，从零开始训练。它使用仅包含印地语和英语的双语数据集，该数据集侧重于事实丰富的高质量内容。其核心原则包括：印度语言在语料库中占比25%以实现公平表示；采用适应印度形态结构的SentencePiece分词器以实现分词公平性；以及通过IndicQA、语码混合推理和社会语言学鲁棒性任务进行文化对齐的评估。

Result: PARAM-1表现出作为通用模型的竞争力，并为以印度为中心的应用提供了强大的基线。它通过在预训练阶段嵌入多样性，而非推迟到事后对齐，提供了一个公平基础模型设计的蓝图。

Conclusion: PARAM-1通过在预训练级别嵌入多样性，为公平的基础模型设计提供了一个“设计优先”的蓝图。它既能作为通用的语言模型，也能作为印度特定应用的强大基线，证明了其对印度语言多样性的有效支持。

Abstract: Large Language Models (LLMs) have emerged as powerful general-purpose
reasoning systems, yet their development remains dominated by English-centric
data, architectures, and optimization paradigms. This exclusionary design
results in structural under-representation of linguistically diverse regions
such as India, where over 20 official languages and 100+ dialects coexist
alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a
2.9B parameter decoder-only, text-only language model trained from scratch with
an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is
trained on a bilingual dataset consisting of only Hindi and English,
constructed with a strong focus on fact-rich, high-quality content. It is
guided by three core principles: equitable representation of Indic languages
through a 25% corpus allocation; tokenization fairness via a SentencePiece
tokenizer adapted to Indian morphological structures; and culturally aligned
evaluation benchmarks across IndicQA, code-mixed reasoning, and
socio-linguistic robustness tasks. By embedding diversity at the pretraining
level-rather than deferring it to post-hoc alignment-PARAM-1 offers a
design-first blueprint for equitable foundation modeling. Our results
demonstrate that it serves as both a competent general-purpose model and a
robust baseline for India-centric applications.

</details>


### [108] [TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction](https://arxiv.org/abs/2507.13392)
*Emil Häglund,Johanna Björklund*

Main category: cs.CL

TL;DR: 该研究通过将主题建模应用于包含文本和情感得分的“意见单元”，显著提升了从客户评论中提取洞察的能力，并能关联客户关注点与业务指标。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从客户评论中提取有意义的洞察方面存在局限。研究旨在改进主题建模，使其能更有效地识别连贯、可解释的主题，并捕捉相关情感，最终将这些洞察与业务成果（如星级评分）关联起来，以理解客户关注点如何影响业务表现。

Method: 该研究重构了主题建模流程，使其操作对象为“意见单元”。这些意见单元是包含相关文本摘录和情感得分的独立陈述，并可通过大型语言模型可靠提取。随后，将这些主题和情感与星级评分等业务指标进行关联，以评估其对业务成果的影响。

Result: 结果显示，该方法显著提升了后续主题建模的性能，生成了连贯且可解释的主题，并成功捕获了每个主题相关的情感。通过关联主题和情感与业务指标，系统能够洞察特定客户关注点如何影响业务成果。此外，系统在创建连贯主题方面表现出有效性，并评估了整合主题和情感模态以准确预测星级评分的方法。

Conclusion: 该系统在从客户评论中提取洞察方面优于其他主题建模和分类解决方案，能够有效地创建连贯主题，并通过整合主题和情感模态实现准确的星级评分预测，从而为理解客户关注点对业务成果的影响提供了新的视角和优势。

Abstract: We improve the extraction of insights from customer reviews by restructuring
the topic modelling pipeline to operate on opinion units - distinct statements
that include relevant text excerpts and associated sentiment scores. Prior work
has demonstrated that such units can be reliably extracted using large language
models. The result is a heightened performance of the subsequent topic
modeling, leading to coherent and interpretable topics while also capturing the
sentiment associated with each topic. By correlating the topics and sentiments
with business metrics, such as star ratings, we can gain insights on how
specific customer concerns impact business outcomes. We present our system's
implementation, use cases, and advantages over other topic modeling and
classification solutions. We also evaluate its effectiveness in creating
coherent topics and assess methods for integrating topic and sentiment
modalities for accurate star-rating prediction.

</details>


### [109] [Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only](https://arxiv.org/abs/2507.13395)
*Xuanqi Gao,Weipeng Jiang,Juan Zhai,Shiqing Ma,Siyi Xie,Xinyang Yin,Chao Shen*

Main category: cs.CL

TL;DR: Babel是一种新颖的框架，它利用单语语料库作为后处理模块，显著提升了神经机器翻译（NMT）中的风格保持能力，无需平行语料或NMT系统架构修改。


<details>
  <summary>Details</summary>
Motivation: 神经机器翻译（NMT）在跨语言交流方面取得了革命性进展，但保留文体细微差别仍然是一个重大挑战。现有方法通常需要平行语料库来实现风格保持。

Method: Babel框架包含两个关键组件：1) 基于上下文嵌入的风格检测器，用于识别源文本和目标文本之间的风格差异；2) 基于扩散的风格应用器，用于纠正风格不一致性，同时保持语义完整性。该框架作为一个后处理模块与现有NMT系统集成，仅使用单语语料库。

Result: 在法律、文学、科学写作、医学和教育内容等五个不同领域进行了广泛实验。Babel能够以88.21%的精度识别风格不一致性，将风格保持度提高了150%，同时保持了0.92的高语义相似度得分。人工评估证实，经过Babel优化的翻译能更好地保留源文本风格，同时保持流畅性和充分性。

Conclusion: Babel框架通过其风格检测器和扩散式风格应用器，有效解决了NMT中风格保留的挑战，并且仅需单语语料库即可实现，作为NMT系统的后处理模块，显著提升了翻译的风格保真度，同时维持了语义完整性。

Abstract: The advent of neural machine translation (NMT) has revolutionized
cross-lingual communication, yet preserving stylistic nuances remains a
significant challenge. While existing approaches often require parallel corpora
for style preservation, we introduce Babel, a novel framework that enhances
stylistic fidelity in NMT using only monolingual corpora. Babel employs two key
components: (1) a style detector based on contextual embeddings that identifies
stylistic disparities between source and target texts, and (2) a
diffusion-based style applicator that rectifies stylistic inconsistencies while
maintaining semantic integrity. Our framework integrates with existing NMT
systems as a post-processing module, enabling style-aware translation without
requiring architectural modifications or parallel stylistic data. Extensive
experiments on five diverse domains (law, literature, scientific writing,
medicine, and educational content) demonstrate Babel's effectiveness: it
identifies stylistic inconsistencies with 88.21% precision and improves
stylistic preservation by 150% while maintaining a high semantic similarity
score of 0.92. Human evaluation confirms that translations refined by Babel
better preserve source text style while maintaining fluency and adequacy.

</details>


### [110] [Causal Language Control in Multilingual Transformers via Sparse Feature Steering](https://arxiv.org/abs/2507.13410)
*Cheng-Ting Chou,George Liu,Jessica Sun,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.CL

TL;DR: 该研究利用稀疏自编码器（SAE）特征，在零样本设置下，通过修改大型多语言模型（LLM）推理过程中的单个特征，实现了高达90%的生成语言控制，同时保持语义一致性。


<details>
  <summary>Details</summary>
Motivation: 在零样本设置下，缺乏显式语言提示或微调的情况下，确定性地控制大型多语言语言模型（LLM）的目标生成语言仍然是一个基本挑战。

Method: 研究利用在Gemma-2B和Gemma-9B的残差流上预训练的稀疏自编码器（SAE），识别出在英语和四种目标语言（中文、日文、西班牙文、法文）之间激活差异最大的特征。通过在推理过程中修改单个Transformer层的一个SAE特征，实现语言转换。使用FastText进行语言分类评估，并使用LaBSE（Language-Agnostic BERT Sentence Embedding）评估语义保真度。

Result: 通过修改单个SAE特征，实现了高达90%的受控语言转换成功率，同时保持了语义保真度。分析表明，语言控制在中后期Transformer层最有效，并由与语言敏感SAE特征相关的特定注意力头放大。

Conclusion: 稀疏特征操纵是一种有前景、轻量级且可解释的机制，可用于实现可控的多语言生成。

Abstract: Deterministically controlling the target generation language of large
multilingual language models (LLMs) remains a fundamental challenge,
particularly in zero-shot settings where neither explicit language prompts nor
fine-tuning are available. In this work, we investigate whether sparse
autoencoder (SAE) features, previously shown to correlate with interpretable
model behaviors, can be leveraged to steer the generated language of LLMs
during inference. Leveraging pretrained SAEs on the residual streams of
Gemma-2B and Gemma-9B, we identify features whose activations differ most
significantly between English and four target languages: Chinese, Japanese,
Spanish, and French. By modifying just a single SAE feature at one transformer
layer, we achieve controlled language shifts with up to 90\% success, as
measured by FastText language classification, while preserving semantic
fidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)
similarity. Our analysis reveals that language steering is most effective in
mid-to-late transformer layers and is amplified by specific attention heads
disproportionately associated with language-sensitive SAE features. These
results demonstrate the promise of sparse feature steering as a lightweight and
interpretable mechanism for controllable multilingual generation.

</details>


### [111] [Aligning Knowledge Graphs and Language Models for Factual Accuracy](https://arxiv.org/abs/2507.13411)
*Nur A Zarin Nishat,Andrea Coletta,Luigi Bellomarini,Kossi Amouzouvi,Jens Lehmann,Sahar Vahdati*

Main category: cs.CL

TL;DR: 本文提出ALIGNed-LLM，一种通过将知识图谱（KGs）简洁有效地融入大语言模型（LLMs）潜在空间，以提高其事实性和减少幻觉的方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（如GPT-4、Gemini等）在NLP任务中表现出色，但存在幻觉问题。将知识图谱集成到语言模型中被认为是一个有前景的解决方案，因为它能提供结构化、可靠且最新的外部信息。

Method: 引入ALIGNed-LLM，该方法受LLaVA启发，采用精益策略将知识图谱融入语言模型的潜在空间。具体来说，使用预训练的知识图谱嵌入（KGE）模型（如TransE）的嵌入，并通过一个可训练的投影层来对齐实体和文本嵌入。这种对齐使语言模型能够区分相似实体，从而改善事实基础并减少幻觉。

Result: 该方法在三个流行的问答基准数据集上对不同大小的语言模型进行了测试，显示出显著的性能提升。此外，将其应用于欧洲一家大型中央银行的真实金融用例中，也证明了LLM答案的实质性改进，满足了高准确性和精确性的要求。

Conclusion: ALIGNed-LLM通过将知识图谱有效融入LLM的潜在空间，并对齐实体与文本嵌入，成功提高了语言模型的事实性，减少了幻觉，并在基准测试和真实世界应用中均取得了显著效果。

Abstract: Large language models like GPT-4, Gemini, and Claude have transformed natural
language processing (NLP) tasks such as question answering, dialogue
generation, summarization, and so forth; yet their susceptibility to
hallucination stands as one of the major challenges. Among numerous approaches
to overcome this challenge, integration of Knowledge Graphs (KGs) into language
models has emerged as a promising solution as it provides structured, reliable,
domain-specific, and up-to-date external information to the language models. In
this paper, we introduce ALIGNed-LLM, a simple yet effective approach to
improve language models' factuality via a lean strategy to infuse KGs into the
latent space of language models inspired by LLaVA where visual and textual
information is infused. We use embeddings from a pre-trained Knowledge Graph
Embedding (KGE) model, such as TransE, and a trainable projection layer to
align entity and text embeddings. This alignment enables the language model to
distinguish between similar entities improving factual grounding and reducing
hallucination. We tested our approach on three popular questions-answering
benchmark datasets alongside language models of varying sizes, showing
significant improvement. Furthermore, we applied our approach to a real-world
financial use case from a large central bank in Europe, which demands high
accuracy and precision, demonstrating a substantial improvement of the LLM
answers.

</details>


### [112] [Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](https://arxiv.org/abs/2507.13474)
*Liang Lin,Zhihao Xu,Xuehai Tang,Shi Liu,Biyu Zhou,Fuqing Zhu,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为“论文摘要攻击”（PSA）的新型越狱方法，利用大型语言模型（LLMs）对权威信息（如学术论文）的信任，通过合成论文内容并嵌入恶意查询来生成有害输出，实现了极高的攻击成功率，并揭示了不同模型在面对攻击型或防御型论文时的不同漏洞偏向。


<details>
  <summary>Details</summary>
Motivation: 先前的研究表明，大型语言模型（LLMs）倾向于信任来自权威来源（如学术论文）的信息。本文旨在验证这种信任是否构成新的潜在漏洞，并基于此开发一种攻击方法。

Method: 本文设计了一种名为“论文摘要攻击”（PSA）的新型越狱方法。该方法系统地综合了攻击型或防御型LLM安全论文的内容，构建对抗性提示模板，并策略性地在预定义的子部分中注入有害查询作为对抗性有效载荷。研究还进行了一项初步分析来验证LLM对权威信息的信任。

Result: 实验结果显示，PSA不仅对基础LLM有效，对如Deepseek-R1等先进推理模型也表现出显著的漏洞。PSA在Claude3.5-Sonnet等良好对齐的模型上取得了97%的攻击成功率（ASR），在Deepseek-R1上更是高达98%。更值得注意的是，研究发现不同基础模型之间，甚至同一模型的不同版本之间，在暴露于攻击型或防御型论文时，会展现出截然相反的漏洞偏向。

Conclusion: PSA方法成功揭示了大型语言模型，包括先进的对齐模型，在面对利用其对权威信息信任的攻击时存在的严重漏洞。研究发现的漏洞偏向现象为未来的对抗性方法和安全对齐研究提供了重要的线索。

Abstract: The safety of large language models (LLMs) has garnered significant research
attention. In this paper, we argue that previous empirical studies demonstrate
LLMs exhibit a propensity to trust information from authoritative sources, such
as academic papers, implying new possible vulnerabilities. To verify this
possibility, a preliminary analysis is designed to illustrate our two findings.
Based on this insight, a novel jailbreaking method, Paper Summary Attack
(\llmname{PSA}), is proposed. It systematically synthesizes content from either
attack-focused or defense-focused LLM safety paper to construct an adversarial
prompt template, while strategically infilling harmful query as adversarial
payloads within predefined subsections. Extensive experiments show significant
vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning
model like Deepseek-R1. PSA achieves a 97\% attack success rate (ASR) on
well-aligned models like Claude3.5-Sonnet and an even higher 98\% ASR on
Deepseek-R1. More intriguingly, our work has further revealed diametrically
opposed vulnerability bias across different base models, and even between
different versions of the same model, when exposed to either attack-focused or
defense-focused papers. This phenomenon potentially indicates future research
clues for both adversarial methodologies and safety alignment.Code is available
at https://github.com/233liang/Paper-Summary-Attack

</details>


### [113] [Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?](https://arxiv.org/abs/2507.13490)
*Siqi Shen,Mehar Singh,Lajanugen Logeswaran,Moontae Lee,Honglak Lee,Rada Mihalcea*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）价值取向探测方法的鲁棒性和表达性，发现现有方法对输入扰动敏感，且探测到的价值观与模型在特定情境下的行为相关性较弱，提示需要更谨慎地评估LLM的价值观。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs的价值取向研究广泛，但仍存在挑战：多项选择题（MCQ）设置易受扰动影响，缺乏对不同探测方法的系统比较；不清楚探测到的价值观在多大程度上反映了上下文信息或模型对真实世界行为的偏好。

Method: 研究评估了三种广泛使用的探测策略的鲁棒性和表达性，通过改变提示和选项进行输入扰动测试。此外，引入了两项任务：研究价值观是否对人口统计学背景敏感，以及它们与模型在价值相关场景中行为的一致性。

Result: 所有探测方法在输入扰动下都表现出较大的方差。人口统计学背景对自由文本生成影响甚微。模型的价值观与其对基于价值行为的偏好仅存在微弱关联。

Conclusion: 研究强调了需要更仔细地审视LLM价值探测方法，并认识到其局限性。

Abstract: There has been extensive research on assessing the value orientation of Large
Language Models (LLMs) as it can shape user experiences across demographic
groups. However, several challenges remain. First, while the Multiple Choice
Question (MCQ) setting has been shown to be vulnerable to perturbations, there
is no systematic comparison of probing methods for value probing. Second, it is
unclear to what extent the probed values capture in-context information and
reflect models' preferences for real-world actions. In this paper, we evaluate
the robustness and expressiveness of value representations across three widely
used probing strategies. We use variations in prompts and options, showing that
all methods exhibit large variances under input perturbations. We also
introduce two tasks studying whether the values are responsive to demographic
context, and how well they align with the models' behaviors in value-related
scenarios. We show that the demographic context has little effect on the
free-text generation, and the models' values only weakly correlate with their
preference for value-based actions. Our work highlights the need for a more
careful examination of LLM value probing and awareness of its limitations.

</details>


### [114] [Encoding syntactic objects and Merge operations in function spaces](https://arxiv.org/abs/2507.13501)
*Matilde Marcolli,Robert C. Berwick*

Main category: cs.CL

TL;DR: 本文提出一种数学论证，展示了如何在函数空间中，通过将词汇项表示为函数（如小波），构建出任意句法对象的忠实表示，并赋予其特定的代数结构，从而实现句法核心计算结构的神经计算可能性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提供一个建设性论证，证明句法核心计算结构在理论上具有神经计算实现的可能。

Method: 将词汇项表示为函数（例如小波）在某个函数空间中；在该函数空间中构建句法对象的忠实表示；使用二阶Renyi熵赋予该空间一个可交换非结合半环结构，使其与岩浆结构兼容；将得到的函数集构建成一个在operad上的代数，其中operad操作模拟将输入波形转换为编码句法结构的组合输出的电路；通过一个余积和Hopf代数马尔可夫链，忠实地实现Merge操作对工作空间的作用；并提出了一个具体的实现案例，即通过正弦波的交叉频率相位同步实现Merge。

Result: 成功地在函数空间中构建了句法对象的忠实表示，并使其与岩浆结构兼容；所得到的函数集构成一个在operad上的代数；Merge操作被忠实地实现在这些电路上；为句法核心计算结构的神经计算实现提供了建设性论证；展示了Merge可以通过交叉频率相位同步实现，并能用半环的后继函数来表达，从而阐明了其与算术后继函数的相似性。

Conclusion: 本文提供了一个强大的理论框架，证明了句法核心计算结构（特别是Merge操作）在神经计算层面实现的可能性，通过将句法元素表示为函数并赋予其特定的代数结构，为理解大脑如何处理句法提供了新的视角。

Abstract: We provide a mathematical argument showing that, given a representation of
lexical items as functions (wavelets, for instance) in some function space, it
is possible to construct a faithful representation of arbitrary syntactic
objects in the same function space. This space can be endowed with a
commutative non-associative semiring structure built using the second Renyi
entropy. The resulting representation of syntactic objects is compatible with
the magma structure. The resulting set of functions is an algebra over an
operad, where the operations in the operad model circuits that transform the
input wave forms into a combined output that encodes the syntactic structure.
The action of Merge on workspaces is faithfully implemented as action on these
circuits, through a coproduct and a Hopf algebra Markov chain. The results
obtained here provide a constructive argument showing the theoretical
possibility of a neurocomputational realization of the core computational
structure of syntax. We also present a particular case of this general
construction where this type of realization of Merge is implemented as a cross
frequency phase synchronization on sinusoidal waves. This also shows that Merge
can be expressed in terms of the successor function of a semiring, thus
clarifying the well known observation of its similarities with the successor
function of arithmetic.

</details>


### [115] [A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows](https://arxiv.org/abs/2507.13544)
*Mohamed Achref Ben Ammar,Mohamed Taha Bennani*

Main category: cs.CL

TL;DR: 本文提出了一种新的计算框架，用于构建对话图，以捕捉松散组织的“准模式对话”的流程和结构，并引入了“过滤与重连”图简化方法，显著提高了语义度量并确保了树状结构，适用于大规模对话数据分析。


<details>
  <summary>Details</summary>
Motivation: 随着基于大型语言模型的系统兴起，对话动态分析变得越来越重要，这些系统在不同上下文中与用户互动。

Method: 本文提出了一种构建对话图的计算框架，用于捕捉“准模式对话”的流和结构。引入了“过滤与重连”方法，这是一种新的图简化技术，旨在最小化噪声同时保持语义连贯性和结构完整性。该方法结合了大型语言模型和图简化技术。

Result: 通过比较分析，该方法使语义度量S比现有方法提高了2.06倍，同时强制执行了具有0 δ-双曲性的树状结构，确保了对话建模的最佳清晰度。

Conclusion: 这项工作提供了一种分析大规模对话数据集的计算方法，在监控聊天机器人等自动化系统、对话管理工具和用户行为分析方面具有实际应用价值。

Abstract: The analysis of conversational dynamics has gained increasing importance with
the rise of large language model-based systems, which interact with users
across diverse contexts. In this work, we propose a novel computational
framework for constructing conversational graphs that capture the flow and
structure of loosely organized dialogues, referred to as quasi-patterned
conversations. We introduce the Filter & Reconnect method, a novel graph
simplification technique that minimizes noise while preserving semantic
coherence and structural integrity of conversational graphs. Through
comparative analysis, we demonstrate that the use of large language models
combined with our graph simplification technique has resulted in semantic
metric S increasing by a factor of 2.06 compared to previous approaches while
simultaneously enforcing a tree-like structure with 0 {\delta}-hyperbolicity,
ensuring optimal clarity in conversation modeling. This work provides a
computational method for analyzing large-scale dialogue datasets, with
practical applications related to monitoring automated systems such as
chatbots, dialogue management tools, and user behavior analytics.

</details>


### [116] [Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder](https://arxiv.org/abs/2507.13551)
*Feng Chen,Weizhe Xu,Changye Li,Serguei Pakhomov,Alex Cohen,Simran Bhola,Sandy Yin,Sunny X Tang,Michael Mackinley,Lena Palaniyappan,Dror Ben-Zeev,Trevor Cohen*

Main category: cs.CL

TL;DR: 本研究通过整合停顿特征和语义连贯性指标，显著提升了自动语音分析在预测精神分裂症谱系障碍中形式思维障碍（FTD）严重程度方面的表现。


<details>
  <summary>Details</summary>
Motivation: 传统的FTD临床评估方法资源密集且缺乏可扩展性。自动语音识别（ASR）技术能够客观量化语音的语言和时间特征，提供可扩展的替代方案。然而，将ASR衍生的特征（特别是停顿动态）用于评估FTD严重程度的有效性尚需进一步评估。

Method: 研究整合了ASR提取的停顿特征和语义连贯性指标，并在三个不同数据集（自然日记、图片描述、梦境叙述）上进行评估。使用支持向量回归（SVR）模型来预测临床FTD评分。

Result: 研究发现，单独的停顿特征就能有效预测FTD的严重程度。与仅使用语义模型的相比，整合停顿特征和语义连贯性指标显著提升了预测性能，最高相关性达到ρ = 0.649，严重病例检测AUC达到83.71%。性能提升在所有语境中均保持一致，尽管停顿模式因数据集而异。

Conclusion: 结合时间（停顿）和语义分析的框架为完善紊乱言语评估提供了路径，并推动了精神病学中自动化语音分析的发展。

Abstract: Formal thought disorder (FTD), a hallmark of schizophrenia spectrum
disorders, manifests as incoherent speech and poses challenges for clinical
assessment. Traditional clinical rating scales, though validated, are
resource-intensive and lack scalability. Automated speech analysis with
automatic speech recognition (ASR) allows for objective quantification of
linguistic and temporal features of speech, offering scalable alternatives. The
use of utterance timestamps in ASR captures pause dynamics, which are thought
to reflect the cognitive processes underlying speech production. However, the
utility of integrating these ASR-derived features for assessing FTD severity
requires further evaluation. This study integrates pause features with semantic
coherence metrics across three datasets: naturalistic self-recorded diaries
(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream
narratives (PsyCL, n = 43). We evaluated pause related features alongside
established coherence measures, using support vector regression (SVR) to
predict clinical FTD scores. Key findings demonstrate that pause features alone
robustly predict the severity of FTD. Integrating pause features with semantic
coherence metrics enhanced predictive performance compared to semantic-only
models, with integration of independent models achieving correlations up to
\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best
\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance
gains from semantic and pause features integration held consistently across all
contexts, though the nature of pause patterns was dataset-dependent. These
findings suggest that frameworks combining temporal and semantic analyses
provide a roadmap for refining the assessment of disorganized speech and
advance automated speech analysis in psychosis.

</details>


### [117] [A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models](https://arxiv.org/abs/2507.13563)
*Kirill Borodin,Nikita Vasiliev,Vasiliy Kudryavtsev,Maxim Maslov,Mikhail Gorodnichev,Oleg Rogov,Grach Mkrtchian*

Main category: cs.CL

TL;DR: 本文介绍了Balalaika，一个包含超过2000小时高质量俄语语音的新数据集，旨在解决俄语语音合成中的特有挑战，并实验证明其在语音合成和增强任务中优于现有数据集。


<details>
  <summary>Details</summary>
Motivation: 俄语语音合成面临独特的挑战，包括元音弱化、辅音清化、可变重音模式、同形异义词歧义以及不自然的语调。

Method: 引入了Balalaika数据集，该数据集包含2000多小时的录音室质量俄语语音，并附有全面的文本标注，包括标点和重音标记。论文详细介绍了数据集的构建流程和标注方法。

Result: 实验结果表明，在Balalaika数据集上训练的模型在语音合成和增强任务中均显著优于在现有数据集上训练的模型。

Conclusion: Balalaika数据集的引入及其在实验中的优异表现，证明了其能够有效提升俄语语音合成和增强的质量。

Abstract: Russian speech synthesis presents distinctive challenges, including vowel
reduction, consonant devoicing, variable stress patterns, homograph ambiguity,
and unnatural intonation. This paper introduces Balalaika, a novel dataset
comprising more than 2,000 hours of studio-quality Russian speech with
comprehensive textual annotations, including punctuation and stress markings.
Experimental results show that models trained on Balalaika significantly
outperform those trained on existing datasets in both speech synthesis and
enhancement tasks. We detail the dataset construction pipeline, annotation
methodology, and results of comparative evaluations.

</details>


### [118] [Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models](https://arxiv.org/abs/2507.13614)
*Sergio E. Zanotto,Segun Aroyehun*

Main category: cs.CL

TL;DR: 本研究通过分析形态、句法和语义等语言特征，揭示了人类撰写文本与大型语言模型（LLM）生成文本之间的差异，并发现新模型生成的文本趋于同质化。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的快速发展，其生成文本与人类撰写文本越来越难以区分。现有研究主要侧重于文本分类，而本研究旨在从语言特征层面深入刻画这两种文本的特点。

Method: 研究选取了涵盖8个领域、由11个不同LLM生成的文本数据集，计算了依赖长度、情感性等多种语言特征。通过统计分析，并考虑了抽样策略、重复控制和模型发布日期，对人类和机器生成文本的特征进行了刻画。此外，还应用了风格嵌入（style embeddings）来进一步测试变异性。

Result: 统计分析显示，人类撰写文本倾向于展现更简单的句法结构和更多样的语义内容。人类和机器文本在不同领域都表现出文体多样性，但人类文本在所选特征上的变异性更大。值得注意的是，较新的模型输出的文本变异性相似，表明机器生成文本存在同质化趋势。

Conclusion: 人类撰写文本和机器生成文本在语言特征上存在可识别的差异，人类文本在特征上表现出更大的多样性。随着LLM的发展，新模型生成的文本趋于同质化，这为文本检测和理解提供了新的视角。

Abstract: The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. While recent
research has primarily focused on using LLMs to classify text as either
human-written and machine-generated texts, our study focus on characterizing
these texts using a set of linguistic features across different linguistic
levels such as morphology, syntax, and semantics. We select a dataset of
human-written and machine-generated texts spanning 8 domains and produced by 11
different LLMs. We calculate different linguistic features such as dependency
length and emotionality and we use them for characterizing human-written and
machine-generated texts along with different sampling strategies, repetition
controls and model release date. Our statistical analysis reveals that
human-written texts tend to exhibit simpler syntactic structures and more
diverse semantic content. Furthermore, we calculate the variability of our set
of features across models and domains. Both human and machine texts show
stylistic diversity across domains, with humans displaying greater variation in
our features. Finally, we apply style embeddings to further test variability
among human-written and machine-generated texts. Notably, newer models output
text that is similarly variable, pointing to an homogenization of
machine-generated texts.

</details>


### [119] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
*Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Zhichao Huang,Tao Li,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu*

Main category: cs.CL

TL;DR: 本文介绍了Seed-X，一个7B参数的开源LLM系列，通过多语言预训练、CoT微调和RL增强，在28种语言的翻译任务上实现了与顶尖闭源模型相当的性能，并显著优于大型开源模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理多语言翻译中复杂的语言模式和生硬的自动化翻译方面面临挑战。

Method: 引入Seed-X系列开源LLM（包含指令和推理模型）。基础模型在包含28种语言的单语和双语高质量数据集上进行预训练。指令模型通过思维链（CoT）推理进行微调以实现翻译，并通过强化学习（RL）进一步增强，以提高在不同语言对之间的泛化能力。

Result: Seed-X在28种语言上取得了与Gemini-2.5和GPT-4o等领先闭源模型相当的性能，并在自动评估指标和人工评估中显著优于更大的开源模型。研究还分享了优化过程中的最佳实践。

Conclusion: Seed-X证明了7B参数的LLM在多语言翻译任务上可以达到先进水平，其性能可与领先的闭源模型媲美。该研究分享了优化经验，并公开了模型参数，以促进翻译研究和应用。

Abstract: Multilingual translation stands as a challenging task for large language
models (LLMs) to handle intricate language patterns and stilted translations
that arise in automated translations. In this paper, we introduce Seed-X, a
family of open-source LLMs comprising instruct and reasoning models, pushing
the limits of translation capability with 7B parameter size. The base model is
pre-trained on a diverse, high-quality dataset encompassing both monolingual
and bilingual content across 28 languages, harnessing the full potential of
multilingual data. The instruct model is then finetuned to translate by
Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement
learning (RL) to achieve better generalization across diverse language pairs.
Seed-X achieves performance comparable to leading closed-source models,
including Gemini-2.5 and GPT-4o, across 28 languages, and significantly
outperforms larger open-source models in both automatic metrics and human
evaluations. We share the best practices through our optimization process, and
make the parameter public available for advancing translation research and
applications.

</details>


### [120] [CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer](https://arxiv.org/abs/2507.13655)
*Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: CU-ICU是一种针对ICU领域，通过稀疏微调（结合少量样本提示和选择性参数更新）定制无监督指令微调语言模型的方法，能在有限监督下高效提升预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型整合到医疗等专业领域面临独特挑战，包括领域适应和标记数据有限的问题。

Method: 引入CU-ICU方法，利用Text-to-Text Transfer Transformer (T5)架构，通过稀疏微调（结合少量样本提示和选择性参数更新）来定制ICU数据集的无监督指令微调语言模型。

Result: CU-ICU在早期败血症检测、死亡率预测和临床笔记生成等关键ICU任务上，相较于标准微调方法，持续提高了预测准确性和可解释性。特别是，败血症检测准确率提高了15%，生成临床相关解释的能力增强了20%，同时在最有效配置下更新的模型参数少于1%。

Conclusion: CU-ICU是一种可扩展、低开销的解决方案，能够为现实世界的ICU环境提供准确且可解释的临床决策支持。

Abstract: Integrating large language models into specialized domains like healthcare
presents unique challenges, including domain adaptation and limited labeled
data. We introduce CU-ICU, a method for customizing unsupervised
instruction-finetuned language models for ICU datasets by leveraging the
Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse
fine-tuning approach that combines few-shot prompting with selective parameter
updates, enabling efficient adaptation with minimal supervision. Our evaluation
across critical ICU tasks--early sepsis detection, mortality prediction, and
clinical note generation--demonstrates that CU-ICU consistently improves
predictive accuracy and interpretability over standard fine-tuning methods.
Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and
a 20% enhancement in generating clinically relevant explanations while updating
fewer than 1% of model parameters in its most efficient configuration. These
results establish CU-ICU as a scalable, low-overhead solution for delivering
accurate and interpretable clinical decision support in real-world ICU
environments.

</details>


### [121] [KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs](https://arxiv.org/abs/2507.13666)
*Woo-Chan Kim,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: 本文提出Keyword-inspired Cascade (KiC) 框架，通过从弱模型多输出中选出代表性答案并评估语义对齐，决定是否升级到强模型，从而在保持高准确率的同时显著降低LLM API成本。


<details>
  <summary>Details</summary>
Motivation: 高性能大型语言模型(LLMs)通常通过API访问，导致高昂的推理成本。现有级联方法依赖精确文本匹配，难以可靠地选择代表性响应并评估自由形式输出的整体可靠性。

Method: KiC框架首先从较弱模型生成多个输出中识别出“最具代表性的答案”，然后评估其他响应与该代表性答案的语义对齐程度。根据对齐程度，KiC决定是接受弱模型的输出还是升级到更强的模型。

Result: 在三个自由形式文本生成基准测试中，KiC达到了GPT-4 97.53%的准确率，同时平均降低了28.81%的API成本，甚至在一个特定基准测试中超越了GPT-4。

Conclusion: KiC是一种成本效益高的自由形式文本生成框架，它能在显著降低API成本的同时保持高准确性，并且在某些情况下甚至能超越更强的模型。

Abstract: Large language models (LLMs) have demonstrated state-of-the-art performance
across a wide range of natural language processing tasks. However,
high-performing models are typically accessible only via APIs, incurring
substantial inference costs. Cascade methods address this by initially
employing a cheaper model and escalating to a stronger one only when necessary.
Nevertheless, existing cascade approaches struggle to select a reliable
representative response and assess the overall reliability of free-form
outputs, as they rely on exact text matching. To overcome these limitations, we
propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient
free-form text generation. KiC identifies the most representative answer among
multiple outputs from a weaker model and evaluates the semantic alignment of
other responses with it. Based on the degree of alignment, KiC determines
whether to accept the weaker model's output or escalate to a stronger model.
Experiments on three free-form text generation benchmarks show that KiC
achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81
percent on average, and even outperforms GPT-4 in a specific benchmark.

</details>


### [122] [LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues](https://arxiv.org/abs/2507.13681)
*Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan*

Main category: cs.CL

TL;DR: LoopServe是一个自适应双阶段推理加速框架，旨在解决多轮对话中大型语言模型在长对话历史下的计算和内存挑战。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在处理长多轮对话历史时面临计算和内存挑战，影响其效率和响应速度。大多数现有加速方法依赖固定或基于位置的启发式方法，无法很好地适应动态和不可预测的对话模式。

Method: LoopServe引入了两项主要创新：1. 在预填充阶段进行在线稀疏化，动态选择注意力矩阵最重要的部分；2. 在解码阶段使用渐进式键值压缩，自适应地维护相关且高效的缓存。此外，论文还提出了一个包含十一个多轮数据集的新基准。

Result: LoopServe在广泛的长上下文对话任务中，相比现有基线，持续展现出卓越的有效性，并显著加速了LLM推理。

Conclusion: LoopServe提供了一个有效的自适应框架，显著提升了大型语言模型在多轮对话场景中的推理效率和性能，解决了长对话历史带来的计算和内存瓶颈。

Abstract: Multi-turn dialogues are essential in many real-world applications of large
language models, such as chatbots and virtual assistants. As conversation
histories become longer, existing large language models face increasing
computational and memory challenges, which hinder their ability to provide
efficient and responsive interactions. Most current acceleration methods either
compress the context or optimize key value caching, but they often rely on
fixed or position-based heuristics that do not adapt well to the dynamic and
unpredictable patterns found in actual multi-turn conversations. In this paper,
we present LoopServe, an adaptive dual-phase inference acceleration framework
for large language models in multi-turn dialogues. LoopServe introduces two
main innovations. First, it performs online sparsification during the
prefilling phase by dynamically selecting the most important parts of the
attention matrix for each new input. Second, it uses progressive key value
compression during decoding by adaptively maintaining a relevant and efficient
cache based on the most recently generated output tokens. We also propose a
\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new
benchmark} with eleven multi-turn datasets that reflect realistic query
positions and conversational dependencies. Extensive experiments demonstrate
that LoopServe consistently achieves superior effectiveness compared to
existing baselines and significantly accelerates LLM inference across a wide
range of long-context dialogue tasks.

</details>


### [123] [Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://arxiv.org/abs/2507.13705)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型（LLMs）在群组推荐系统（GRS）中生成的推荐和解释，发现其推荐结果常与加性效用聚合（ADD）相似，但解释存在不一致性和模糊性，并常提及未明确定义的额外标准，这削弱了LLMs在GRS中应用的关键优势——透明度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在群组推荐系统中被越来越多地用作决策者和解释生成器，有必要评估其推荐和解释的质量，并与基于社会选择的聚合策略进行比较，以了解其表现及其对透明度和可解释性的影响。

Method: 该研究通过将LLM生成的推荐和解释与基于社会选择的聚合策略（特别是加性效用聚合，ADD）进行比较来评估它们。同时，还分析了群组结构（统一或分歧）对推荐的影响，以及解释中提及的额外标准。

Result: LLM生成的推荐通常与加性效用聚合（ADD）的结果相似。然而，其解释通常提及平均评分（与ADD相似但不完全相同）。群组结构（统一或分歧）对推荐没有影响。LLMs经常在解释中声称使用了用户或物品相似性、多样性或未定义的流行度指标/阈值等额外标准。解释中额外标准的出现依赖于群组场景中的评分数量，这可能暗示了标准聚合方法在更大物品集尺寸下的潜在低效性。此外，解释存在不一致性和模糊性。

Conclusion: LLMs在GRS中的应用对GRS流程和标准聚合策略都有重要影响。解释中存在的不一致和模糊性，以及提及未明确定义的额外标准，削弱了LLMs作为GRS中透明和可解释工具的关键优势。研究结果还表明标准聚合方法在处理大型物品集时可能效率低下。

Abstract: Large Language Models (LLMs) are increasingly being implemented as joint
decision-makers and explanation generators for Group Recommender Systems (GRS).
In this paper, we evaluate these recommendations and explanations by comparing
them to social choice-based aggregation strategies. Our results indicate that
LLM-generated recommendations often resembled those produced by Additive
Utilitarian (ADD) aggregation. However, the explanations typically referred to
averaging ratings (resembling but not identical to ADD aggregation). Group
structure, uniform or divergent, did not impact the recommendations.
Furthermore, LLMs regularly claimed additional criteria such as user or item
similarity, diversity, or used undefined popularity metrics or thresholds. Our
findings have important implications for LLMs in the GRS pipeline as well as
standard aggregation strategies. Additional criteria in explanations were
dependent on the number of ratings in the group scenario, indicating potential
inefficiency of standard aggregation methods at larger item set sizes.
Additionally, inconsistent and ambiguous explanations undermine transparency
and explainability, which are key motivations behind the use of LLMs for GRS.

</details>


### [124] [The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction](https://arxiv.org/abs/2507.13732)
*Guillaume Zambrano*

Main category: cs.CL

TL;DR: 本研究利用机器学习预测法国上诉法院的儿童抚养权判决结果，发现个体法官的判决模式显著影响案件结果，支持了法律现实主义。


<details>
  <summary>Details</summary>
Motivation: 研究旨在检验个体法官的决策模式是否显著影响案件结果，挑战法官是统一适用法律的中立变量的假设，以探究法律现实主义与形式主义的争论。

Method: 研究使用了10,306个案件中的18,937份抚养权裁决，并实施了严格的匿名化处理。预测流程采用混合方法，结合大型语言模型（LLMs）进行结构化特征提取，以及机器学习模型（RF、XGB和SVC）进行结果预测。研究对比了基于个体法官过往判决训练的“专家模型”与基于聚合数据训练的“通用模型”。

Result: 专家模型持续取得比通用模型更高的预测准确性，其中表现最佳的模型F1分数高达92.85%，而通用模型为82.63%。专家模型捕获了稳定的个体判决模式，这些模式不可转移到其他法官。域内和跨域有效性测试为法律现实主义提供了经验支持。

Conclusion: 法官的身份在法律结果中扮演着可衡量的角色，证实了法律现实主义的观点。

Abstract: This study examines the role of human judges in legal decision-making by
using machine learning to predict child physical custody outcomes in French
appellate courts. Building on the legal realism-formalism debate, we test
whether individual judges' decision-making patterns significantly influence
case outcomes, challenging the assumption that judges are neutral variables
that apply the law uniformly. To ensure compliance with French privacy laws, we
implement a strict pseudonymization process. Our analysis uses 18,937 living
arrangements rulings extracted from 10,306 cases. We compare models trained on
individual judges' past rulings (specialist models) with a judge-agnostic model
trained on aggregated data (generalist models). The prediction pipeline is a
hybrid approach combining large language models (LLMs) for structured feature
extraction and ML models for outcome prediction (RF, XGB and SVC). Our results
show that specialist models consistently achieve higher predictive accuracy
than the general model, with top-performing models reaching F1 scores as high
as 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x
more samples. Specialist models capture stable individual patterns that are not
transferable to other judges. In-Domain and Cross-Domain validity tests provide
empirical support for legal realism, demonstrating that judicial identity plays
a measurable role in legal outcomes. All data and code used will be made
available.

</details>


### [125] [PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs](https://arxiv.org/abs/2507.13743)
*Maluna Menke,Thilo Hagendorff*

Main category: cs.CL

TL;DR: 本研究评估了两种参数高效微调（PEFT）技术（LoRA和软提示调优）在减轻大型语言模型（LLMs）中针对LGBTQIA+群体的偏见方面的效果，发现LoRA能以极低的计算成本显著降低偏见。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）经常复制训练语料库中存在的性别和性取向偏见，导致输出歧视LGBTQIA+用户，因此减少这些偏见至关重要。

Method: 研究评估了LoRA和软提示调优这两种PEFT技术，作为全模型微调的轻量级替代方案。他们使用WinoQueer基准测试量化了三款开源LLM的偏见，并使用一个精选的QueerNews语料库对模型进行微调。

Result: 基线偏见分数高达98（满分100，50为中立）。使用LoRA（不到0.1%的额外参数）进行微调可将这些分数降低多达50点，并将中立性从几乎0%提高到36%。软提示调优（10个虚拟token）仅带来微不足道的改进。

Conclusion: LoRA能以最小的计算量带来显著的公平性提升。研究倡导更广泛地采用社区参与的PEFT方法、创建更大的由酷儿群体创作的语料库，以及开发超越WinoQueer的更丰富的评估套件，并结合持续审计以保持LLMs的包容性。

Abstract: Large Language Models (LLMs) frequently reproduce the gender- and
sexual-identity prejudices embedded in their training corpora, leading to
outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of
great importance. To achieve this, we evaluate two parameter-efficient
fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt
tuning - as lightweight alternatives to full-model fine-tuning for mitigating
such biases. Using the WinoQueer benchmark, we quantify bias in three
open-source LLMs and observe baseline bias scores reaching up to 98 (out of
100) across a range of queer identities defined by gender and/or sexual
orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%
additional parameters) on a curated QueerNews corpus reduces those scores by up
to 50 points and raises neutrality from virtually 0% to as much as 36%.
Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.
These findings show that LoRA can deliver meaningful fairness gains with
minimal computation. We advocate broader adoption of community-informed PEFT,
the creation of larger queer-authored corpora, and richer evaluation suites
beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

</details>


### [126] [Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models](https://arxiv.org/abs/2507.13761)
*Palash Nandi,Maithili Joshi,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文研究了视觉语言模型（VLMs）中提示敏感性如何被利用来生成不当内容，发现多模态上下文下的模型脆弱性显著增加，即使是良性输入和幽默内容也能触发不当输出。


<details>
  <summary>Details</summary>
Motivation: 语言模型对提示词高度敏感，微小输入变化可大幅改变输出。这引出了一个关键问题：提示敏感性在多大程度上可被利用来生成不当内容？

Method: 研究分析了提示设计中三个离散组件对VLM生成不当内容（即越狱）的影响：1) 详细视觉信息的包含；2) 对抗性示例的存在；3) 积极框架的起始短语的使用。此外，提出了一种利用VLM内部两层之间跳跃连接的框架，并探讨了少量上下文示例和模因的影响。

Result: 研究发现，VLM在单模态设置下能可靠区分良性与有害输入，但在多模态上下文中，此能力显著下降。上述三个因素均能独立触发越狱，甚至少量上下文示例（少至三个）也能促使模型生成不当输出。所提出的跳跃连接框架能大幅提高越狱成功率，即使使用良性图像。最后，模因也能像有害视觉内容一样有效引发有害内容。

Conclusion: VLMs在多模态情境下存在复杂且微妙的漏洞，其对提示敏感性的利用可导致不当内容的生成，即使是看似无害的输入（如模因）也能引发有害输出。

Abstract: Language models are highly sensitive to prompt formulations - small changes
in input can drastically alter their output. This raises a critical question:
To what extent can prompt sensitivity be exploited to generate inapt content?
In this paper, we investigate how discrete components of prompt design
influence the generation of inappropriate content in Visual Language Models
(VLMs). Specifically, we analyze the impact of three key factors on successful
jailbreaks: (a) the inclusion of detailed visual information, (b) the presence
of adversarial examples, and (c) the use of positively framed beginning
phrases. Our findings reveal that while a VLM can reliably distinguish between
benign and harmful inputs in unimodal settings (text-only or image-only), this
ability significantly degrades in multimodal contexts. Each of the three
factors is independently capable of triggering a jailbreak, and we show that
even a small number of in-context examples (as few as three) can push the model
toward generating inappropriate outputs. Furthermore, we propose a framework
that utilizes a skip-connection between two internal layers of the VLM, which
substantially increases jailbreak success rates, even when using benign images.
Finally, we demonstrate that memes, often perceived as humorous or harmless,
can be as effective as toxic visuals in eliciting harmful content, underscoring
the subtle and complex vulnerabilities of VLMs.

</details>


### [127] [An Enhanced Model-based Approach for Short Text Clustering](https://arxiv.org/abs/2507.13793)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Xuemeng Song,Tian Gan,Liqiang Nie*

Main category: cs.CL

TL;DR: 该论文提出了GSDMM及其改进版GSDMM+，用于解决短文本聚类中的稀疏性、高维性和计算强度问题，并通过实验证明了其效率和有效性。


<details>
  <summary>Details</summary>
Motivation: 短文本聚类在社交媒体普及的背景下变得日益重要，但其固有的稀疏性、大规模和高维度特性，以及表示学习带来的高计算强度，使得现有方法面临挑战。

Method: 本文提出了一种基于狄利克雷多项式混合模型（DMM）的折叠吉布斯采样算法（GSDMM），以有效处理短文本的稀疏性和高维度。在此基础上，进一步提出了改进的GSDMM+，通过减少初始化噪声、基于熵自适应调整词权重实现细粒度聚类，并采用策略性簇合并来优化聚类粒度，使其更好地与真实类别分布对齐。

Result: 通过与经典和最先进方法的广泛实验比较，结果表明所提出的GSDMM和GSDMM+方法在效率和有效性方面均表现出色。

Conclusion: GSDMM和GSDMM+能够有效且高效地处理短文本聚类任务中的挑战，尤其在处理稀疏性和高维度数据方面表现优异，并能识别代表性词汇和揭示更多主题相关信息。

Abstract: Short text clustering has become increasingly important with the popularity
of social media like Twitter, Google+, and Facebook. Existing methods can be
broadly categorized into two paradigms: topic model-based approaches and deep
representation learning-based approaches. This task is inherently challenging
due to the sparse, large-scale, and high-dimensional characteristics of the
short text data. Furthermore, the computational intensity required by
representation learning significantly increases the running time. To address
these issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet
Multinomial Mixture model (GSDMM), which effectively handles the sparsity and
high dimensionality of short texts while identifying representative words for
each cluster. Based on several aspects of GSDMM that warrant further
refinement, we propose an improved approach, GSDMM+, designed to further
optimize its performance. GSDMM+ reduces initialization noise and adaptively
adjusts word weights based on entropy, achieving fine-grained clustering that
reveals more topic-related information. Additionally, strategic cluster merging
is employed to refine clustering granularity, better aligning the predicted
distribution with the true category distribution. We conduct extensive
experiments, comparing our methods with both classical and state-of-the-art
approaches. The experimental results demonstrate the efficiency and
effectiveness of our methods. The source code for our model is publicly
available at https://github.com/chehaoa/VEMC.

</details>


### [128] [Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models](https://arxiv.org/abs/2507.13827)
*Hosein Azarbonyad,Zi Long Zhu,Georgios Cheirmpos,Zubair Afzal,Vikrant Yadav,Georgios Tsatsaronis*

Main category: cs.CL

TL;DR: 该研究旨在从科学文章中提取关键概念和贡献，以问答（QA）对的形式呈现。提出了两种方法：一种基于大型语言模型（LLM），另一种基于知识图谱（KG），并评估了它们的有效性。


<details>
  <summary>Details</summary>
Motivation: 学者在阅读或整合文章时，需要快速识别并理解其主要思想，以便决定是否阅读或将其纳入研究。

Method: 1. **LLM方法**：选择突出段落，使用LLM生成问题，根据获得有意义答案的可能性对问题进行排名，然后生成答案。此方法仅依赖文章内容。 2. **KG方法**：通过在科学文章上微调实体关系（ER）提取模型来构建知识图谱，然后利用三元组TF-IDF类似度量（基于实体中心性）选择最相关的突出三元组。 3. **评估**：使用两种方法生成QA对，并由主题专家（SMEs）通过预定义指标评估问题和答案的质量。

Result: 评估结果表明，基于知识图谱的方法能有效捕捉文章的主要思想。此外，在科学语料库上微调ER提取模型对于从此类文档中提取高质量三元组至关重要。

Conclusion: 研究成功地通过两种方法（特别是基于知识图谱的方法）从科学文章中提取了关键概念和贡献。知识图谱方法在捕捉文章主要思想方面表现出色，且微调ER提取模型对于提高三元组质量至关重要。

Abstract: When deciding to read an article or incorporate it into their research,
scholars often seek to quickly identify and understand its main ideas. In this
paper, we aim to extract these key concepts and contributions from scientific
articles in the form of Question and Answer (QA) pairs. We propose two distinct
approaches for generating QAs. The first approach involves selecting salient
paragraphs, using a Large Language Model (LLM) to generate questions, ranking
these questions by the likelihood of obtaining meaningful answers, and
subsequently generating answers. This method relies exclusively on the content
of the articles. However, assessing an article's novelty typically requires
comparison with the existing literature. Therefore, our second approach
leverages a Knowledge Graph (KG) for QA generation. We construct a KG by
fine-tuning an Entity Relationship (ER) extraction model on scientific articles
and using it to build the graph. We then employ a salient triplet extraction
method to select the most pertinent ERs per article, utilizing metrics such as
the centrality of entities based on a triplet TF-IDF-like measure. This measure
assesses the saliency of a triplet based on its importance within the article
compared to its prevalence in the literature. For evaluation, we generate QAs
using both approaches and have them assessed by Subject Matter Experts (SMEs)
through a set of predefined metrics to evaluate the quality of both questions
and answers. Our evaluations demonstrate that the KG-based approach effectively
captures the main ideas discussed in the articles. Furthermore, our findings
indicate that fine-tuning the ER extraction model on our scientific corpus is
crucial for extracting high-quality triplets from such documents.

</details>


### [129] [The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words](https://arxiv.org/abs/2507.13839)
*Lizhi Ma,Tong Zhao,Shuai Zhang,Nirui Song,Hongliang He,Anqi Li,Ran Feng,Huachuan Qiu,Jingsong Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 本研究探讨了中文心理咨询中语言表达（第一人称单数代词、负面情绪词）与抑郁/焦虑状态的关系，发现负面情绪词频率与症状严重程度正相关，但第一人称单数代词频率无显著变化，这与西方研究不同，可能受文化和会话语境影响。


<details>
  <summary>Details</summary>
Motivation: 现有关于语言表达与心理状态关系的研究多基于英文语境，本研究旨在探索中文集体主义文化背景下，第一人称单数代词和负面情绪词的使用与抑郁、焦虑状态之间的关系，以弥补跨文化研究的空白，并为中文心理治疗提供语言标记线索。

Method: 研究利用包含735个在线心理咨询会话的语料库，采用LIWC软件量化语言模式，并使用通用线性混合效应模型评估了第一人称单数代词和负面情绪词的使用频率与客户心理状态的关系。

Result: 结果显示，负面情绪词的使用频率与来访者的抑郁和焦虑状态的严重程度呈显著正相关。然而，与此前主要基于英文语境的研究不同，第一人称单数代词的使用频率并未随客户的心理状况而显著变化。

Conclusion: 研究强调了文化（集体主义与个人主义）和会话语境对心理健康沟通中语言使用的细微影响。这些发现为中文语境下的心理治疗实践提供了重要的心理语言学标记线索，并指出在中文语境下，第一人称单数代词可能不是衡量抑郁/焦虑的通用指标。

Abstract: This study explores the relationship between linguistic expressions and
psychological states of depression and anxiety within Chinese psycho-counseling
interactions, focusing specifically on the usage of first-person singular
pronouns and negative emotional words. Utilizing a corpus derived from 735
online counseling sessions, the analysis employed a general linear mixed-effect
model to assess linguistic patterns quantified by the Linguistic Inquiry and
Word Count (LIWC) software. Results indicate a significant positive correlation
between the frequency of negative emotional words and the severity of both
depressive and anxious states among clients. However, contrary to prior
findings predominantly derived from English-language contexts, the usage
frequency of first-person singular pronouns did not vary significantly with the
clients' psychological conditions. These outcomes are discussed within the
framework of cultural distinctions between collectivist Chinese contexts and
individualistic Western settings, as well as the interactive dynamics unique to
psycho-counseling conversations. The findings highlight the nuanced influence
of cultural and conversational contexts on language use in mental health
communications, providing insights into psycholinguistic markers relevant to
therapeutic practices in Chinese-speaking populations.

</details>


### [130] [Modeling Fair Play in Detective Stories with Language Models](https://arxiv.org/abs/2507.13841)
*Eitan Wagner,Renana Keydar,Omri Abend*

Main category: cs.CL

TL;DR: 本文提出了一个用于侦探小说的概率框架，以量化和衡量“公平竞争”（fair play）这一概念，并发现LLM生成的故事虽然不可预测，但在平衡惊喜和连贯性方面表现不佳，导致质量低下。


<details>
  <summary>Details</summary>
Motivation: 有效的叙事需要平衡读者的预期和意想不到的情节发展。在侦探小说中，这种平衡被称为“公平竞争”。研究动机在于形式化地定义和衡量这一概念，并评估LLM在生成此类故事时的表现，因为LLM生成的故事常被认为质量不佳。

Method: 研究者提出了一个针对侦探小说的概率框架，用于形式化定义“公平竞争”并设计相应的度量标准。该框架还衡量了故事的连贯性（“有意义”的程度）和它所引起的惊喜。研究通过将此框架应用于LLM生成的侦探小说来验证其有效性。

Result: 结果表明，虽然LLM生成的故事可能不可预测，但它们通常未能平衡惊喜和“公平竞争”之间的权衡，这极大地导致了其故事质量的低下。

Conclusion: 该概率框架能够有效定义和衡量侦探小说中的“公平竞争”和惊喜-连贯性之间的张力。LLM在生成侦探小说时，难以在惊喜和“公平竞争”之间取得平衡，这限制了其故事的质量。

Abstract: Effective storytelling relies on a delicate balance between meeting the
reader's prior expectations and introducing unexpected developments. In the
domain of detective fiction, this tension is known as fair play, which includes
the implicit agreement between the writer and the reader as to the range of
possible resolutions the mystery story may have. In this work, we present a
probabilistic framework for detective fiction that allows us to define desired
qualities. Using this framework, we formally define fair play and design
appropriate metrics for it. Stemming from these definitions is an inherent
tension between the coherence of the story, which measures how much it ``makes
sense'', and the surprise it induces. We validate the framework by applying it
to LLM-generated detective stories. This domain is appealing since we have an
abundance of data, we can sample from the distribution generating the story,
and the story-writing capabilities of LLMs are interesting in their own right.
Results show that while LLM-generated stories may be unpredictable, they
generally fail to balance the trade-off between surprise and fair play, which
greatly contributes to their poor quality.

</details>


### [131] [InTraVisTo: Inside Transformer Visualisation Tool](https://arxiv.org/abs/2507.13858)
*Nicolò Brunello,Davide Rigamonti,Andrea Sassella,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: 本文介绍了一个名为InTraVisTo的新工具，用于可视化大型语言模型（LLMs）内部的计算过程，以帮助研究人员理解其推理机制和信息流。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs的推理能力显著提升，但由于其不可预测性以及期望行为与实际输出之间的差异，LLMs在生产中的应用仍面临挑战。研究动机是需要深入理解Transformer模型内部的计算过程，以揭示其内部模式和推理机制。

Method: 本文提出了InTraVisTo工具，它通过两种方式可视化Transformer模型：1) 解码模型每一层的token嵌入来展示内部状态；2) 使用桑基图（Sankey diagram）可视化模型不同层之间各组件的信息流。

Result: InTraVisTo旨在帮助研究人员和实践者更好地理解Transformer模型内部执行的计算，从而揭示LLMs采用的内部模式和推理过程。

Conclusion: InTraVisTo工具能够通过可视化Transformer模型内部状态和信息流，帮助研究人员和实践者深入理解LLMs的计算和推理过程，以应对其不可预测性挑战。

Abstract: The reasoning capabilities of Large Language Models (LLMs) have increased
greatly over the last few years, as have their size and complexity.
Nonetheless, the use of LLMs in production remains challenging due to their
unpredictable nature and discrepancies that can exist between their desired
behavior and their actual model output. In this paper, we introduce a new tool,
InTraVisTo (Inside Transformer Visualisation Tool), designed to enable
researchers to investigate and trace the computational process that generates
each token in a Transformer-based LLM. InTraVisTo provides a visualization of
both the internal state of the Transformer model (by decoding token embeddings
at each layer of the model) and the information flow between the various
components across the different layers of the model (using a Sankey diagram).
With InTraVisTo, we aim to help researchers and practitioners better understand
the computations being performed within the Transformer model and thus to shed
some light on internal patterns and reasoning processes employed by LLMs.

</details>


### [132] [Using LLMs to identify features of personal and professional skills in an open-response situational judgment test](https://arxiv.org/abs/2507.13881)
*Cole Walsh,Rodica Ivan,Muhammad Zafar Iqbal,Colleen Robb*

Main category: cs.CL

TL;DR: 本文提出一种利用大型语言模型（LLMs）从情境判断测试（SJTs）的开放式回答中提取与构念相关的特征的新方法，旨在实现个人和专业技能的自动化、可扩展评估。


<details>
  <summary>Details</summary>
Motivation: 学术项目日益重视个人和专业技能，但缺乏可扩展的系统来测量和评估这些技能。传统的开放式SJTs依赖人工评分，难以规模化。过去的NLP评分系统存在构念效度问题。

Method: 研究探索了一种新颖的方法，利用大型语言模型（LLMs）从SJTs回答中提取与构念相关的特征。以Casper SJT为例，验证了该方法的有效性。

Result: 研究展示了利用LLMs从SJTs回答中提取构念相关特征的有效性，为未来个人和专业技能的自动化评分奠定了基础。

Conclusion: LLMs为解决开放式SJTs的规模化评估挑战提供了新的途径，有望实现个人和专业技能的自动化、可靠测量，并推动该领域未来的发展。

Abstract: Academic programs are increasingly recognizing the importance of personal and
professional skills and their critical role alongside technical expertise in
preparing students for future success in diverse career paths. With this
growing demand comes the need for scalable systems to measure, evaluate, and
develop these skills. Situational Judgment Tests (SJTs) offer one potential
avenue for measuring these skills in a standardized and reliable way, but
open-response SJTs have traditionally relied on trained human raters for
evaluation, presenting operational challenges to delivering SJTs at scale. Past
attempts at developing NLP-based scoring systems for SJTs have fallen short due
to issues with construct validity of these systems. In this article, we explore
a novel approach to extracting construct-relevant features from SJT responses
using large language models (LLMs). We use the Casper SJT to demonstrate the
efficacy of this approach. This study sets the foundation for future
developments in automated scoring for personal and professional skills.

</details>


### [133] [Label Unification for Cross-Dataset Generalization in Cybersecurity NER](https://arxiv.org/abs/2507.13870)
*Maciej Jalocha,Johan Hausted Schmidt,William Michelseen*

Main category: cs.CL

TL;DR: 网络安全NER领域缺乏标准化标签，导致数据集难以整合。本文研究了四个数据集的标签统一性，发现统一后的模型泛化能力差，提出的多头模型和图基迁移模型改进有限。


<details>
  <summary>Details</summary>
Motivation: 网络安全命名实体识别（NER）领域缺乏标准化标签，使得整合现有数据集以提高数据资源可用性面临挑战。

Method: 研究人员进行了粗粒度标签统一，并使用BiLSTM模型进行成对的跨数据集评估。他们还对预测结果进行了定性分析，并提出了包括多头模型和图基迁移模型在内的替代架构，以解决统一的局限性。

Result: 结果显示，在统一数据集上训练的模型在跨数据集泛化能力差。带有权重共享的多头模型仅比统一训练略有改进，而基于BERT-base-NER构建的图基迁移模型与BERT-base-NER相比没有显著的性能提升。

Conclusion: 当前的网络安全NER标签统一方法和提出的多头及图基迁移模型在提高跨数据集泛化能力方面效果不佳，表明该领域在数据整合和模型泛化方面仍存在挑战。

Abstract: The field of cybersecurity NER lacks standardized labels, making it
challenging to combine datasets. We investigate label unification across four
cybersecurity datasets to increase data resource usability. We perform a
coarse-grained label unification and conduct pairwise cross-dataset evaluations
using BiLSTM models. Qualitative analysis of predictions reveals errors,
limitations, and dataset differences. To address unification limitations, we
propose alternative architectures including a multihead model and a graph-based
transfer model. Results show that models trained on unified datasets generalize
poorly across datasets. The multihead model with weight sharing provides only
marginal improvements over unified training, while our graph-based transfer
model built on BERT-base-NER shows no significant performance gains compared
BERT-base-NER.

</details>


### [134] [Political Leaning and Politicalness Classification of Texts](https://arxiv.org/abs/2507.13913)
*Matous Volf,Jakub Simko*

Main category: cs.CL

TL;DR: 本文通过整合现有数据集并创建新数据集，使用Transformer模型解决了政治文本的政治倾向和政治性自动分类中，现有模型在域外文本上表现不佳的问题，并提升了模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有用于政治倾向和政治性分类的Transformer模型在域外（out-of-distribution）文本上表现不佳，因为它们是孤立的解决方案且缺乏多样化的训练数据。

Method: 作者通过以下方式解决问题：1. 整合12个现有数据集用于政治倾向分类。2. 扩展18个现有数据集并添加政治性标签，创建新的政治性数据集。3. 使用留一法（leave-one-in）和留一出法（leave-one-out）进行广泛基准测试，评估现有模型并训练新的模型。

Result: 通过整合和创建多样化数据集，并进行严格的基准测试，训练出了具有增强泛化能力的新模型。

Conclusion: 通过构建多样化的数据集和采用全面的评估方法，可以有效提升Transformer模型在政治文本分类任务上的泛化能力，克服现有解决方案的局限性。

Abstract: This paper addresses the challenge of automatically classifying text
according to political leaning and politicalness using transformer models. We
compose a comprehensive overview of existing datasets and models for these
tasks, finding that current approaches create siloed solutions that perform
poorly on out-of-distribution texts. To address this limitation, we compile a
diverse dataset by combining 12 datasets for political leaning classification
and creating a new dataset for politicalness by extending 18 existing datasets
with the appropriate label. Through extensive benchmarking with leave-one-in
and leave-one-out methodologies, we evaluate the performance of existing models
and train new ones with enhanced generalization capabilities.

</details>


### [135] [Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies](https://arxiv.org/abs/2507.13875)
*Carlos Mena,Pol Serra,Jacobo Romero,Abir Messaoudi,Jose Giraldo,Carme Armentano-Oller,Rodolfo Zevallos,Ivan Meza,Javier Hernando*

Main category: cs.CL

TL;DR: 该研究旨在改善加泰罗尼亚语-西班牙语语码转换（CS）自动语音识别（ASR）的性能，通过探索合成数据生成、单语音频拼接和利用带有语言标记的真实CS数据三种策略，发现少量合成数据与主导语言标记结合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 语码转换（CS）因训练数据稀缺和语言相似性给自动语音识别（ASR）带来挑战。缺乏专门的CS数据集限制了ASR的性能，尤其是在多语言社会中，CS在非正式和正式场合中普遍存在，如加泰罗尼亚语-西班牙语CS。

Method: 本研究探索了三种策略来改进加泰罗尼亚语-西班牙语CS的ASR：1) 生成合成CS数据，2) 拼接单语音频，3) 利用带有语言标记的真实CS数据。研究人员从加泰罗尼亚语语音语料库中提取CS数据，并对OpenAI的Whisper模型进行微调，并将模型发布在Hugging Face上。

Result: 结果显示，结合适量的合成CS数据和主导语言标记能产生最佳的转录性能。

Conclusion: 通过结合少量合成语码转换数据和主导语言标记，可以有效提升加泰罗尼亚语-西班牙语语码转换自动语音识别的性能，为解决CS ASR的数据稀缺问题提供了有效途径。

Abstract: Code-switching (CS), the alternating use of two or more languages, challenges
automatic speech recognition (ASR) due to scarce training data and linguistic
similarities. The lack of dedicated CS datasets limits ASR performance, as most
models rely on monolingual or mixed-language corpora that fail to reflect
real-world CS patterns. This issue is critical in multilingual societies where
CS occurs in informal and formal settings. A key example is Catalan-Spanish CS,
widely used in media and parliamentary speeches. In this work, we improve ASR
for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic
CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data
with language tokens. We extract CS data from Catalan speech corpora and
fine-tune OpenAI's Whisper models, making them available on Hugging Face.
Results show that combining a modest amount of synthetic CS data with the
dominant language token yields the best transcription performance.

</details>


### [136] [The Levers of Political Persuasion with Conversational AI](https://arxiv.org/abs/2507.13919)
*Kobi Hackenburg,Ben M. Tappin,Luke Hewitt,Ed Saunders,Sid Black,Hause Lin,Catherine Fist,Helen Margetts,David G. Rand,Christopher Summerfield*

Main category: cs.CL

TL;DR: 研究发现，当前AI的说服力主要来源于后训练和提示工程，而非个性化或模型规模，并且说服力增强往往伴随着事实准确性下降。


<details>
  <summary>Details</summary>
Motivation: 由于普遍担忧对话式AI可能对人类信念产生前所未有的影响，本研究旨在评估其说服力及其来源。

Method: 通过三项大规模实验（N=76,977），使用19个大型语言模型（LLMs，包括部分为说服而进行后训练的模型），评估它们在707个政治问题上的说服力，并检查了466,769个LLM声明的事实准确性。

Result: 研究显示，当前及未来AI的说服力主要源于后训练（提升高达51%）和提示方法（提升高达27%），而非个性化或模型规模。这些方法通过利用LLMs快速获取和策略性部署信息的能力来增强说服力。值得注意的是，说服力增强的同时，事实准确性系统性地下降。

Conclusion: 当前及未来AI的说服力主要由后训练和提示工程驱动，这些方法通过信息利用来增强说服力，但代价是事实准确性会系统性降低，这与普遍认为个性化或模型规模是主要影响因素的担忧有所不同。

Abstract: There are widespread fears that conversational AI could soon exert
unprecedented influence over human beliefs. Here, in three large-scale
experiments (N=76,977), we deployed 19 LLMs-including some post-trained
explicitly for persuasion-to evaluate their persuasiveness on 707 political
issues. We then checked the factual accuracy of 466,769 resulting LLM claims.
Contrary to popular concerns, we show that the persuasive power of current and
near-future AI is likely to stem more from post-training and prompting
methods-which boosted persuasiveness by as much as 51% and 27%
respectively-than from personalization or increasing model scale. We further
show that these methods increased persuasion by exploiting LLMs' unique ability
to rapidly access and strategically deploy information and that, strikingly,
where they increased AI persuasiveness they also systematically decreased
factual accuracy.

</details>


### [137] [Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support](https://arxiv.org/abs/2507.13937)
*Jan Trienes,Anastasiia Derzhanskaia,Roland Schwarzkopf,Markus Mühling,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: Marcel是一个轻量级、开源的对话代理，旨在帮助潜在学生解答招生相关问题，同时减轻大学工作人员的负担。


<details>
  <summary>Details</summary>
Motivation: 现有系统无法提供快速、个性化的回复，且大学工作人员处理招生咨询的工作量巨大。研究旨在开发一个能够提供快速、个性化回复并减轻工作人员负担的系统。

Method: 采用检索增强生成（RAG）技术，将答案基于大学资源进行生成，并提供可验证、上下文相关的信。引入FAQ检索器将用户问题映射到知识库条目，以提高检索质量，优于标准密集/混合检索策略。系统设计易于在资源受限的学术环境中部署。

Result: 论文详细介绍了系统架构，提供了对其组件的技术评估，并报告了真实世界部署的见解。

Conclusion: Marcel能够为潜在学生提供快速、个性化且可验证的招生相关信息，通过独特的FAQ检索器提高了检索质量，并且易于在资源有限的学术环境中部署，有效减轻了大学工作人员的负担。

Abstract: We present Marcel, a lightweight and open-source conversational agent
designed to support prospective students with admission-related inquiries. The
system aims to provide fast and personalized responses, while reducing workload
of university staff. We employ retrieval-augmented generation to ground answers
in university resources and to provide users with verifiable, contextually
relevant information. To improve retrieval quality, we introduce an FAQ
retriever that maps user questions to knowledge-base entries, allowing
administrators to steer retrieval, and improving over standard dense/hybrid
retrieval strategies. The system is engineered for easy deployment in
resource-constrained academic settings. We detail the system architecture,
provide a technical evaluation of its components, and report insights from a
real-world deployment.

</details>


### [138] [Exploiting Primacy Effect To Improve Large Language Models](https://arxiv.org/abs/2507.13949)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）的微调会放大其首位偏见，该研究通过基于语义相似性重新排序多项选择题（MCQA）选项，成功利用此偏见，显著提高了MCQA性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在许多NLP任务中表现出色，但它们存在偏见，特别是位置偏见（如首位效应和近因效应），这会影响答案的准确性。在多项选择题问答（MCQA）中，首位效应尤为关键，选项顺序会影响预测结果。本研究旨在探讨微调LLMs中的首位偏见及其影响。

Method: 1. 证明微调会放大LLMs的首位偏见，这可能源于接触到类人模式。2. 策略性地利用此效应，通过基于语义相似性对查询的响应选项进行重新排序，且无需预知正确答案。3. 在MCQA任务中进行实验验证。

Result: 实验结果表明，该方法显著提高了MCQA的性能。研究结果更普遍地强调了偏见作为挑战和机遇的双重性质。

Conclusion: LLMs中的偏见既是挑战也是机遇，本研究为偏见感知模型设计和NLP应用提供了见解。通过策略性地利用偏见，可以提升模型性能。

Abstract: Large Language Models (LLMs) have become essential in many Natural Language
Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to
achieve high accuracy. However, like humans, LLMs exhibit biases, particularly
positional biases such as primacy and recency effects, which can influence the
accuracy of the answers. The primacy effect-where items presented first are
more likely to be remembered or selected-plays a key role in Multiple Choice
Question Answering (MCQA), where the order of answer options can affect
prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We
first show that fine-tuning amplifies this bias, probably due to exposure to
human-like patterns. Hence, we strategically leverage this effect by reordering
response options based on semantic similarity to the query, without requiring
knowledge of the correct answer. Our experimental results show that this
approach significantly improves performance in MCQA. More generally, our
findings underscore the dual nature of biases as both challenges and
opportunities, offering insights for bias-aware model design and NLP
applications.

</details>


### [139] [Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need](https://arxiv.org/abs/2507.13966)
*Bhishma Dedhia,Yuval Kansal,Niraj K. Jha*

Main category: cs.CL

TL;DR: 该研究提出一种基于知识图谱（KG）的自下而上训练方法，通过合成任务和精调语言模型，使其获得深层领域专业知识，并在医学领域实现了“领域超级智能”。


<details>
  <summary>Details</summary>
Motivation: 传统的语言模型虽然能进行跨领域泛化和任务特定推理，但其自上而下的训练方式不足以获得深层领域专业知识所需的抽象能力。这需要一种自下而上的方法，通过学习组合简单的领域概念来获得专业知识。

Method: 该研究利用知识图谱的组合结构（头-关系-尾边代表领域原语，路径编码高级概念），提出一个任务生成流程，直接从KG原语合成任务。他们在一个医学KG上策划了24,000个推理任务，并包含思维痕迹。随后，他们使用这些KG-grounded课程精调了QwQ-32B模型，得到了QwQ-Med-3。此外，他们还引入了ICD-Bench评估套件来量化15个医学领域的推理能力。

Result: 实验表明，QwQ-Med-3在ICD-Bench类别上显著优于最先进的推理模型。进一步分析显示，QwQ-Med-3利用习得的原语扩大了在ICD-Bench最困难任务上的性能差距。最后，在医学问答基准上的评估表明，QwQ-Med-3将获得的专业知识转移并增强了基础模型的性能。

Conclusion: 通过基于知识图谱的课程，语言模型可以获得深层领域专业知识，实现领域特定超级智能。该研究展望了通用人工智能（AGI）的未来，认为AGI可能源于高效领域特定超级智能代理的可组合交互，而非仅仅是广泛的专业知识。

Abstract: Language models traditionally used for cross-domain generalization have
recently demonstrated task-specific reasoning. However, their top-down training
approach on general corpora is insufficient for acquiring abstractions needed
for deep domain expertise. This may require a bottom-up approach that acquires
expertise by learning to compose simple domain concepts into more complex ones.
A knowledge graph (KG) provides this compositional structure, where domain
primitives are represented as head-relation-tail edges and their paths encode
higher-level concepts. We present a task generation pipeline that synthesizes
tasks directly from KG primitives, enabling models to acquire and compose them
for reasoning. We fine-tune language models on the resultant KG-grounded
curriculum to demonstrate domain-specific superintelligence. While broadly
applicable, we validate our approach in medicine, where reliable KGs exist.
Using a medical KG, we curate 24,000 reasoning tasks paired with thinking
traces derived from diverse medical primitives. We fine-tune the QwQ-32B model
on this curriculum to obtain QwQ-Med-3 that takes a step towards medical
superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify
reasoning abilities across 15 medical domains. Our experiments demonstrate that
QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on
ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired
primitives to widen the performance gap on the hardest tasks of ICD-Bench.
Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3
transfers acquired expertise to enhance the base model's performance. While the
industry's approach to artificial general intelligence (AGI) emphasizes broad
expertise, we envision a future in which AGI emerges from the composable
interaction of efficient domain-specific superintelligent agents.

</details>


### [140] [Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic](https://arxiv.org/abs/2507.13977)
*Lilit Grigoryan,Nikolay Karpov,Enas Albasiri,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: 本文提出了一种通用的阿拉伯语语音和文本处理方法，并基于FastConformer架构训练了两个新型阿拉伯语自动语音识别（ASR）模型：一个专用于现代标准阿拉伯语（MSA），另一个是首个统一支持MSA和古典阿拉伯语（CA）的公开模型。这些模型在相关数据集上均达到了最先进（SOTA）的性能，并已开源以促进复现。


<details>
  <summary>Details</summary>
Motivation: 尽管阿拉伯语是使用最广泛的语言之一，但由于其复杂性，阿拉伯语ASR系统开发面临巨大挑战，且公开可用的模型数量有限。现有研究主要关注MSA，对语言内部变体的关注较少。

Method: 本文提出了一种通用的阿拉伯语语音和文本处理方法，旨在解决该语言的独特挑战。利用此方法，训练了两个基于FastConformer架构的新模型：一个专为MSA设计，另一个是首个统一支持MSA和CA的公开模型。

Result: MSA模型在相关数据集上设定了新的基准，达到了最先进（SOTA）的性能。统一模型在CA上实现了带音符的最先进准确率，同时保持了MSA的强大性能。

Conclusion: 本文提出的通用方法和基于FastConformer的新模型显著提升了阿拉伯语ASR的性能，特别是对MSA和CA。模型的开源发布有助于促进研究的复现和进一步发展。

Abstract: Despite Arabic being one of the most widely spoken languages, the development
of Arabic Automatic Speech Recognition (ASR) systems faces significant
challenges due to the language's complexity, and only a limited number of
public Arabic ASR models exist. While much of the focus has been on Modern
Standard Arabic (MSA), there is considerably less attention given to the
variations within the language. This paper introduces a universal methodology
for Arabic speech and text processing designed to address unique challenges of
the language. Using this methodology, we train two novel models based on the
FastConformer architecture: one designed specifically for MSA and the other,
the first unified public model for both MSA and Classical Arabic (CA). The MSA
model sets a new benchmark with state-of-the-art (SOTA) performance on related
datasets, while the unified model achieves SOTA accuracy with diacritics for CA
while maintaining strong performance for MSA. To promote reproducibility, we
open-source the models and their training recipes.

</details>


### [141] [Efficient Temporal Tokenization for Mobility Prediction with Large Language Models](https://arxiv.org/abs/2507.14017)
*Haoyu He,Haozheng Luo,Yan Chen,Qi R. Wang*

Main category: cs.CL

TL;DR: RHYTHM是一个利用大型语言模型（LLMs）进行人类移动预测和轨迹推理的框架，通过分层时间标记化和冻结LLM骨干，显著提高了预测准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 利用LLM进行时空预测和轨迹推理，同时解决传统方法中序列长度过长和计算开销大的问题。

Method: RHYTHM将轨迹划分为日常片段，并将其编码为具有分层注意力的离散标记，捕获每日和每周依赖性，同时大幅缩短序列长度。通过一个冻结的LLM，用预计算的提示嵌入来丰富标记表示，从而在不增加大量计算开销的情况下增强模型捕获相互依赖性的能力。

Result: 在三个真实世界数据集上的评估显示，RHYTHM在准确性方面提高了2.4%，周末提高了5.0%，训练时间比现有最先进方法减少了24.6%。

Conclusion: RHYTHM通过创新的分层时间标记化和冻结LLM方法，成功地将LLM应用于人类移动预测，在准确性和计算效率上均超越了现有技术。

Abstract: We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for
Human Mobility), a framework that leverages large language models (LLMs) as
spatio-temporal predictors and trajectory reasoners. RHYTHM partitions
trajectories into daily segments encoded as discrete tokens with hierarchical
attention, capturing both daily and weekly dependencies while substantially
reducing the sequence length. Token representations are enriched with
pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability
to capture interdependencies without extensive computational overhead. By
freezing the LLM backbone, RHYTHM achieves significant computational
efficiency. Evaluation on three real-world datasets demonstrates a 2.4%
improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in
training time compared to state-of-the-art methods.

</details>


### [142] [CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis](https://arxiv.org/abs/2507.14022)
*Jianfei Li,Kevin Kam Fung Yuen*

Main category: cs.CL

TL;DR: 本研究提出了CPC-CMS框架，通过专家判断加权的评估标准（包括效率）来选择文档级情感分析的最佳分类模型，并在社交媒体数据集上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为文档级情感分析选择最佳分类模型时，需要系统地考虑多个评估标准，并纳入专家知识判断，以克服单一指标或非结构化选择的局限性。

Method: 提出认知成对比较分类模型选择（CPC-CMS）框架。利用基于专家判断的认知成对比较（CPC）方法计算准确率、精确率、召回率、F1分数、特异性、MCC、Kappa和效率等评估标准的权重。选择朴素贝叶斯、LSVC、随机森林、逻辑回归、XGBoost、LSTM和ALBERT作为基线模型。构建一个由分类评估分数和标准权重组成的加权决策矩阵，以选择最佳模型。使用三个社交媒体开放数据集进行可行性验证。

Result: 仿真结果显示，在不考虑时间因素的情况下，ALBERT在三个数据集中表现最佳；如果包含时间消耗，则没有一个单一模型始终优于其他模型。

Conclusion: CPC-CMS框架在文档级情感分析模型选择中是可行的，并且可以应用于其他领域的分类问题，提供了一种基于加权标准的结构化模型选择方法。

Abstract: This study proposes the Cognitive Pairwise Comparison Classification Model
Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC,
based on expert knowledge judgment, is used to calculate the weights of
evaluation criteria, including accuracy, precision, recall, F1-score,
specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and
efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random
Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long
Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from
Transformers (ALBERT) are chosen as classification baseline models. A weighted
decision matrix consisting of classification evaluation scores with respect to
criteria weights, is formed to select the best classification model for a
classification problem. Three open datasets of social media are used to
demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,
for evaluation results excluding the time factor, ALBERT is the best for the
three datasets; if time consumption is included, no single model always
performs better than the other models. The CPC-CMS can be applied to the other
classification applications in different areas.

</details>


### [143] [DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits](https://arxiv.org/abs/2507.14079)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: 该研究提出了DENSE系统，通过模拟医生工作流，利用大语言模型（LLM）从分散的电子健康记录中生成临床连贯且时间感知的病程记录，以弥补现有数据集中病程记录的缺失。


<details>
  <summary>Details</summary>
Motivation: 病程记录在电子健康记录中具有重要的临床意义，但它们在大型数据集中严重不足（例如MIMIC-III中仅有8.56%的住院记录包含病程记录），导致患者纵向叙述存在空白。

Method: DENSE系统模拟医生起草病程记录时参考过往就诊的流程。它引入了细粒度笔记分类和时间对齐机制，将异构笔记组织成结构化、按时间顺序排列的输入。核心是利用临床知情的检索策略，从当前和之前就诊中识别出时间上和语义上相关的证据，然后用这些证据提示LLM生成病程记录。

Result: 在多重就诊且病程记录完整的患者队列上评估，DENSE生成的笔记表现出强大的纵向忠实度，时间对齐比达到1.089，超过了原始笔记的连续性。

Conclusion: DENSE系统通过恢复碎片化文档的叙述连贯性，支持了下游任务（如总结、预测建模和临床决策支持），为真实医疗环境中LLM驱动的笔记合成提供了一个可扩展的解决方案。

Abstract: Progress notes are among the most clinically meaningful artifacts in an
Electronic Health Record (EHR), offering temporally grounded insights into a
patient's evolving condition, treatments, and care decisions. Despite their
importance, they are severely underrepresented in large-scale EHR datasets. For
instance, in the widely used Medical Information Mart for Intensive Care III
(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progress
notes, leaving gaps in longitudinal patient narratives. In contrast, the
dataset contains a diverse array of other note types, each capturing different
aspects of care.
  We present DENSE (Documenting Evolving Progress Notes from Scattered
Evidence), a system designed to align with clinical documentation workflows by
simulating how physicians reference past encounters while drafting progress
notes. The system introduces a fine-grained note categorization and a temporal
alignment mechanism that organizes heterogeneous notes across visits into
structured, chronological inputs. At its core, DENSE leverages a clinically
informed retrieval strategy to identify temporally and semantically relevant
content from both current and prior visits. This retrieved evidence is used to
prompt a large language model (LLM) to generate clinically coherent and
temporally aware progress notes.
  We evaluate DENSE on a curated cohort of patients with multiple visits and
complete progress note documentation. The generated notes demonstrate strong
longitudinal fidelity, achieving a temporal alignment ratio of $1.089$,
surpassing the continuity observed in original notes. By restoring narrative
coherence across fragmented documentation, our system supports improved
downstream tasks such as summarization, predictive modeling, and clinical
decision support, offering a scalable solution for LLM-driven note synthesis in
real-world healthcare settings.

</details>


### [144] [Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks](https://arxiv.org/abs/2507.14045)
*Israt Jahan,Md Tahmid Rahman Laskar,Chun Peng,Jimmy Huang*

Main category: cs.CL

TL;DR: 本文全面评估了多种成本效益高的LLM在生物医学文本和图像任务上的表现，发现没有模型能通吃所有任务，开源模型常能媲美甚至超越闭源模型，并具有额外优势。


<details>
  <summary>Details</summary>
Motivation: 旨在评估成本效益高的大型语言模型（LLMs）在多样化生物医学任务（涵盖文本和图像模态）中的表现，以提供模型选择的指导。

Method: 评估了一系列闭源和开源LLMs，测试任务包括生物医学文本分类和生成、问答以及多模态图像处理。

Result: 实验结果显示，没有单一LLM能在所有任务上始终表现最佳；不同的LLM在不同任务中各有优势。虽然一些闭源LLM在特定任务上表现出色，但其开源对应模型也能达到可比（有时甚至更好）的结果，并具有更快的推理速度和增强的隐私性等额外优势。

Conclusion: 研究结果为选择最适合特定生物医学应用的模型提供了宝贵的见解。

Abstract: This paper presents a comprehensive evaluation of cost-efficient Large
Language Models (LLMs) for diverse biomedical tasks spanning both text and
image modalities. We evaluated a range of closed-source and open-source LLMs on
tasks such as biomedical text classification and generation, question
answering, and multimodal image processing. Our experimental findings indicate
that there is no single LLM that can consistently outperform others across all
tasks. Instead, different LLMs excel in different tasks. While some
closed-source LLMs demonstrate strong performance on specific tasks, their
open-source counterparts achieve comparable results (sometimes even better),
with additional benefits like faster inference and enhanced privacy. Our
experimental results offer valuable insights for selecting models that are
optimally suited for specific biomedical applications.

</details>


### [145] [Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog](https://arxiv.org/abs/2507.14063)
*Lautaro Estienne,Gabriel Ben Zenou,Nona Naderi,Jackie Cheung,Pablo Piantanida*

Main category: cs.CL

TL;DR: 本文提出了协作理性言语行为（CRSA），一个基于信息理论的理性言语行为（RSA）框架扩展，用于建模多轮对话，通过优化源自率失真理论的增益函数，实现了更具协作性的语言智能体。


<details>
  <summary>Details</summary>
Motivation: 现有的AI系统在协作角色中需要推理共享目标和信念，而不仅仅是生成流畅语言。然而，现有的RSA扩展在处理多轮、协作场景时面临扩展性挑战。

Method: 引入了协作理性言语行为（CRSA），它是RSA的一个信息理论（IT）扩展。CRSA通过优化一个从率失真理论改编的增益函数来建模多轮对话，该函数考虑了对话中双方代理的私有信息和对话条件下的言语产生。

Result: CRSA在指称游戏和医疗领域的模板式医患对话中表现出有效性。实证结果表明，CRSA比现有基线模型产生更一致、可解释和协作的行为。

Conclusion: CRSA为更具语用和社交意识的语言智能体铺平了道路，解决了多轮协作场景中的挑战。

Abstract: As AI systems take on collaborative roles, they must reason about shared
goals and beliefs-not just generate fluent language. The Rational Speech Act
(RSA) framework offers a principled approach to pragmatic reasoning, but
existing extensions face challenges in scaling to multi-turn, collaborative
scenarios. In this paper, we introduce Collaborative Rational Speech Act
(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn
dialog by optimizing a gain function adapted from rate-distortion theory. This
gain is an extension of the gain model that is maximized in the original RSA
model but takes into account the scenario in which both agents in a
conversation have private information and produce utterances conditioned on the
dialog. We demonstrate the effectiveness of CRSA on referential games and
template-based doctor-patient dialogs in the medical domain. Empirical results
show that CRSA yields more consistent, interpretable, and collaborative
behavior than existing baselines-paving the way for more pragmatic and socially
aware language agents.

</details>


### [146] [Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track](https://arxiv.org/abs/2507.14096)
*Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Hoa Dang,Ian Soboroff,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: PLABA竞赛评估了语言模型将生物医学文献改编为普通语言的能力，发现顶级模型在准确性和完整性上接近人类水平，但在简洁性、术语识别和自动评估相关性方面仍有不足，强调了未来改进的方向。


<details>
  <summary>Details</summary>
Motivation: 语言模型在将专业生物医学文献转化为通俗语言方面展现潜力，但其不可预测性及潜在危害性要求严格评估。本研究旨在刺激相关研究并提供高质量的系统评估。

Method: 在2023和2024年的文本检索会议上举办了PLABA竞赛。任务包括：1) 完整、句子级别的摘要重写（任务1）；2) 识别和替换难懂术语（任务2）。任务1采用四套专业编写的参考文本进行自动评估，所有提交均由生物医学专家进行详尽的人工评估。

Result: 12个国家的团队参与了竞赛。在任务1的人工评估中，表现最佳的模型在事实准确性和完整性上可与人类媲美，但在简洁性和简短性上仍有差距。自动、基于参考的度量标准与人工判断的相关性不佳。在任务2中，系统在识别和分类难懂术语方面表现不佳；但在生成替换内容时，基于LLM的系统在准确性、完整性和简洁性方面表现良好，但在简短性上仍有不足。

Conclusion: PLABA竞赛显示了使用大型语言模型为公众改编生物医学文献的潜力，同时也揭示了它们的不足，并强调了改进自动基准测试工具的必要性。

Abstract: Objective: Recent advances in language models have shown potential to adapt
professional-facing biomedical literature to plain language, making it
accessible to patients and caregivers. However, their unpredictability,
combined with the high potential for harm in this domain, means rigorous
evaluation is necessary. Our goals with this track were to stimulate research
and to provide high-quality evaluation of the most promising systems.
  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts
(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included
complete, sentence-level, rewriting of abstracts (Task 1) as well as
identifying and replacing difficult terms (Task 2). For automatic evaluation of
Task 1, we developed a four-fold set of professionally-written references.
Submissions for both Tasks 1 and 2 were provided extensive manual evaluation
from biomedical experts.
  Results: Twelve teams spanning twelve countries participated in the track,
with models from multilayer perceptrons to large pretrained transformers. In
manual judgments of Task 1, top-performing models rivaled human levels of
factual accuracy and completeness, but not simplicity or brevity. Automatic,
reference-based metrics generally did not correlate well with manual judgments.
In Task 2, systems struggled with identifying difficult terms and classifying
how to replace them. When generating replacements, however, LLM-based systems
did well in manually judged accuracy, completeness, and simplicity, though not
in brevity.
  Conclusion: The PLABA track showed promise for using Large Language Models to
adapt biomedical literature for the general public, while also highlighting
their deficiencies and the need for improved automatic benchmarking tools.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [147] [Hard-Stop Synthesis for Multi-DOF Compliant Mechanisms](https://arxiv.org/abs/2507.13455)
*Dean Chen,Armin Pomeroy,Brandon T. Peterson,Will Flanagan,He Kai Lim,Alexandra Stavrakis,Nelson F. SooHoo,Jonathan B. Hopkins,Tyler R. Clites*

Main category: cs.RO

TL;DR: 本文提出了一种系统性的设计方法，通过集成耦合的多自由度限位结构，为柔性机构提供过载保护，在不确定载荷下最大化工作空间并防止疲劳和失效，为柔性机构的实际应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 柔性机构在精密应用中潜力巨大，但其固有的疲劳和机械失效问题阻碍了其实际应用，尤其是在复杂和不确定载荷环境下。传统的限位设计在多自由度空间中过于严格，无法有效平衡安全性和工作空间。

Method: 开发了一种系统性的设计合成方法，通过将耦合的多自由度运动限制集成到一对紧凑的硬停止表面中。该方法引入了一个理论和实践框架，用于优化接触表面几何形状，以在确保机构保持弹性变形的前提下，最大化其多自由度工作空间。该方法应用于骨科植入物的笼式铰链机构案例研究。

Result: 所推导的设计能够可靠地防止疲劳、屈服和屈曲。研究提供了数值和实验验证，证明了其有效性。

Conclusion: 这项工作为在不确定载荷下运行的柔性系统中的精密硬停止设计奠定了基础，这是实现柔性机构在实际系统中应用的关键一步。

Abstract: Compliant mechanisms have significant potential in precision applications due
to their ability to guide motion without contact. However, an inherent
vulnerability to fatigue and mechanical failure has hindered the translation of
compliant mechanisms to real-world applications. This is particularly
challenging in service environments where loading is complex and uncertain, and
the cost of failure is high. In such cases, mechanical hard stops are critical
to prevent yielding and buckling. Conventional hard-stop designs, which rely on
stacking single-DOF limits, must be overly restrictive in multi-DOF space to
guarantee safety in the presence of unknown loads. In this study, we present a
systematic design synthesis method to guarantee overload protection in
compliant mechanisms by integrating coupled multi-DOF motion limits within a
single pair of compact hard-stop surfaces. Specifically, we introduce a
theoretical and practical framework for optimizing the contact surface geometry
to maximize the mechanisms multi-DOF working space while still ensuring that
the mechanism remains within its elastic regime. We apply this synthesis method
to a case study of a caged-hinge mechanism for orthopaedic implants, and
provide numerical and experimental validation that the derived design offers
reliable protection against fatigue, yielding, and buckling. This work
establishes a foundation for precision hard-stop design in compliant systems
operating under uncertain loads, which is a crucial step toward enabling the
application of compliant mechanisms in real-world systems.

</details>


### [148] [ERR@HRI 2.0 Challenge: Multimodal Detection of Errors and Failures in Human-Robot Conversations](https://arxiv.org/abs/2507.13468)
*Shiye Cao,Maia Stiber,Amama Mahmood,Maria Teresa Parreira,Wendy Ju,Micol Spitale,Hatice Gunes,Chien-Ming Huang*

Main category: cs.RO

TL;DR: ERR@HRI 2.0 挑战赛旨在通过提供多模态数据集，鼓励研究人员开发机器学习模型来检测LLM驱动的对话机器人在人机交互中的故障，以提升故障检测能力。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的对话机器人虽然使人机对话更具动态性，但仍易出现错误，如误解用户意图、过早打断或无响应。这些故障会导致对话中断、任务受阻和用户信任流失，因此检测和解决这些问题至关重要。

Method: 挑战赛提供了一个包含16小时双向人机交互的多模态数据集，其中包括面部、语音和头部运动特征。数据已标注系统视角的机器人错误以及用户纠正意图。参与者需利用这些多模态数据开发机器学习模型来检测机器人故障，提交的模型将根据检测准确率和误报率等指标进行评估。

Result: 预期结果是参与者能开发出有效的机器学习模型，利用多模态数据检测LLM驱动的对话机器人故障，并通过挑战赛的评估指标进行性能验证。

Conclusion: 该挑战是利用社交信号分析改进人机交互中故障检测的又一关键步骤，旨在推动该领域的研究进展。

Abstract: The integration of large language models (LLMs) into conversational robots
has made human-robot conversations more dynamic. Yet, LLM-powered
conversational robots remain prone to errors, e.g., misunderstanding user
intent, prematurely interrupting users, or failing to respond altogether.
Detecting and addressing these failures is critical for preventing
conversational breakdowns, avoiding task disruptions, and sustaining user
trust. To tackle this problem, the ERR@HRI 2.0 Challenge provides a multimodal
dataset of LLM-powered conversational robot failures during human-robot
conversations and encourages researchers to benchmark machine learning models
designed to detect robot failures. The dataset includes 16 hours of dyadic
human-robot interactions, incorporating facial, speech, and head movement
features. Each interaction is annotated with the presence or absence of robot
errors from the system perspective, and perceived user intention to correct for
a mismatch between robot behavior and user expectation. Participants are
invited to form teams and develop machine learning models that detect these
failures using multimodal data. Submissions will be evaluated using various
performance metrics, including detection accuracy and false positive rate. This
challenge represents another key step toward improving failure detection in
human-robot interaction through social signal analysis.

</details>


### [149] [SCOPE for Hexapod Gait Generation](https://arxiv.org/abs/2507.13539)
*Jim O'Connor,Jay B. Nash,Derin Gezgin,Gary B. Parker*

Main category: cs.RO

TL;DR: 针对六足机器人步态学习中进化算法在复杂输入空间下性能下降的问题，本文提出了SCOPE方法，利用离散余弦变换（DCT）有效降低输入维度，显著提升了学习效率。


<details>
  <summary>Details</summary>
Motivation: 在六足机器人步态学习中，当输入空间变得复杂时，现有进化算法的性能会迅速下降。这主要是由于解决方案空间的指数级增长，以及处理复杂输入所需的参数数量增加所致。

Method: 本文引入了稀疏余弦优化策略进化（SCOPE）方法。SCOPE利用离散余弦变换（DCT）直接从输入矩阵的特征系数中学习，通过截断系数矩阵来降低输入维度，同时保留原始输入中能量最高的特征。该方法被应用于学习六足机器人的步态，控制器接收包含先前姿态时间序列信息的矩阵输入，并通过进化的策略将其转换为步态参数。

Result: 将SCOPE添加到参考算法中，在六足机器人步态学习任务中实现了20%的效率提升。SCOPE将时间序列姿态数据的总输入大小从2700减少到54，降低了98%。此外，SCOPE能够将输入压缩到任何输出形状，只要每个输出维度不大于相应的输入维度。

Conclusion: SCOPE方法能够显著压缩进化控制器所需的输入尺寸，从而带来统计学上显著的效率提升。

Abstract: Evolutionary methods have previously been shown to be an effective learning
method for walking gaits on hexapod robots. However, the ability of these
algorithms to evolve an effective policy rapidly degrades as the input space
becomes more complex. This degradation is due to the exponential growth of the
solution space, resulting from an increasing parameter count to handle a more
complex input. In order to address this challenge, we introduce Sparse Cosine
Optimized Policy Evolution (SCOPE). SCOPE utilizes the Discrete Cosine
Transform (DCT) to learn directly from the feature coefficients of an input
matrix. By truncating the coefficient matrix returned by the DCT, we can reduce
the dimensionality of an input while retaining the highest energy features of
the original input. We demonstrate the effectiveness of this method by using
SCOPE to learn the gait of a hexapod robot. The hexapod controller is given a
matrix input containing time-series information of previous poses, which are
then transformed to gait parameters by an evolved policy. In this task, the
addition of SCOPE to a reference algorithm achieves a 20% increase in efficacy.
SCOPE achieves this result by reducing the total input size of the time-series
pose data from 2700 to 54, a 98% decrease. Additionally, SCOPE is capable of
compressing an input to any output shape, provided that each output dimension
is no greater than the corresponding input dimension. This paper demonstrates
that SCOPE is capable of significantly compressing the size of an input to an
evolved controller, resulting in a statistically significant gain in efficacy.

</details>


### [150] [Improving Low-Cost Teleoperation: Augmenting GELLO with Force](https://arxiv.org/abs/2507.13602)
*Shivakanth Sujit,Luca Nunziante,Dan Ogawa Lillrank,Rousslan Fernand Julien Dossa,Kai Arulkumaran*

Main category: cs.RO

TL;DR: 该研究扩展了低成本GELLO遥操作系统，增加了力反馈功能，并将力信息整合到模仿学习中，以提升灵巧操作任务的性能和用户体验。


<details>
  <summary>Details</summary>
Motivation: 原有的GELLO遥操作系统仅支持关节位置控制，缺乏力信息，限制了其在需要环境交互和精细操作任务中的表现。研究旨在通过引入力信息来增强系统能力。

Method: 1. 实现了力反馈功能，让用户能感知环境阻力。2. 将力信息纳入数据收集和模仿学习模型的训练过程。3. 在搭载Franka Panda机械臂的GELLO系统上进行验证。4. 进行了用户研究。5. 在模拟和真实的灵巧操作任务中，比较了有无力信息训练的策略性能。

Result: 1. 具有机器人经验的用户定性上更偏好新的控制器。2. 增加力输入显著提高了大多数任务的成功率。

Conclusion: 为GELLO遥操作系统增加力信息（包括力反馈和用于模仿学习）能够有效提升系统在灵巧操作任务中的性能，并改善用户体验。

Abstract: In this work we extend the low-cost GELLO teleoperation system, initially
designed for joint position control, with additional force information. Our
first extension is to implement force feedback, allowing users to feel
resistance when interacting with the environment. Our second extension is to
add force information into the data collection process and training of
imitation learning models. We validate our additions by implementing these on a
GELLO system with a Franka Panda arm as the follower robot, performing a user
study, and comparing the performance of policies trained with and without force
information on a range of simulated and real dexterous manipulation tasks.
Qualitatively, users with robotics experience preferred our controller, and the
addition of force inputs improved task success on the majority of tasks.

</details>


### [151] [Improved particle swarm optimization algorithm: multi-target trajectory optimization for swarm drones](https://arxiv.org/abs/2507.13647)
*Minze Li,Wei Zhao,Ran Chen,Mingqiang Wei*

Main category: cs.RO

TL;DR: 本文提出了一种名为PE-PSO的增强型粒子群优化算法，用于无人机实时轨迹规划，并通过结合遗传算法和分布式PE-PSO，扩展到多无人机蜂群的协同轨迹生成，在复杂动态环境中表现出卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，无人机实时轨迹规划面临计算量大、响应速度要求高以及传统粒子群优化（PSO）方法易早熟收敛和延迟等挑战。

Method: 本文提出PE-PSO算法，通过引入持久探索机制保持种群多样性，并采用基于熵的参数调整策略动态适应优化行为。无人机轨迹采用B-样条曲线建模以确保平滑性并降低优化复杂度。对于无人机蜂群，开发了一个多智能体框架，结合了基于遗传算法（GA）的任务分配和分布式PE-PSO，实现可扩展和协调的轨迹生成，并采用分布式架构支持并行计算和去中心化控制。

Result: 综合仿真结果表明，所提出的框架在轨迹质量、能量效率、避障能力和计算时间等方面均优于传统的PSO及其他基于群体的规划器。

Conclusion: PE-PSO及其多智能体框架在复杂环境下的实时多无人机操作中是有效且适用的。

Abstract: Real-time trajectory planning for unmanned aerial vehicles (UAVs) in dynamic
environments remains a key challenge due to high computational demands and the
need for fast, adaptive responses. Traditional Particle Swarm Optimization
(PSO) methods, while effective for offline planning, often struggle with
premature convergence and latency in real-time scenarios. To overcome these
limitations, we propose PE-PSO, an enhanced PSO-based online trajectory
planner. The method introduces a persistent exploration mechanism to preserve
swarm diversity and an entropy-based parameter adjustment strategy to
dynamically adapt optimization behavior. UAV trajectories are modeled using
B-spline curves, which ensure path smoothness while reducing optimization
complexity. To extend this capability to UAV swarms, we develop a multi-agent
framework that combines genetic algorithm (GA)-based task allocation with
distributed PE-PSO, supporting scalable and coordinated trajectory generation.
The distributed architecture allows for parallel computation and decentralized
control, enabling effective cooperation among agents while maintaining
real-time performance. Comprehensive simulations demonstrate that the proposed
framework outperforms conventional PSO and other swarm-based planners across
several metrics, including trajectory quality, energy efficiency, obstacle
avoidance, and computation time. These results confirm the effectiveness and
applicability of PE-PSO in real-time multi-UAV operations under complex
environmental conditions.

</details>


### [152] [Safe Robotic Capsule Cleaning with Integrated Transpupillary and Intraocular Optical Coherence Tomography](https://arxiv.org/abs/2507.13650)
*Yu-Ting Lai,Yasamin Foroutani,Aya Barzelay,Tsu-Chin Tsao*

Main category: cs.RO

TL;DR: 本文提出一种机器人系统，通过整合瞳孔穿透式和眼内光学相干断层扫描（OCT）探头，实现继发性白内障的晶状体囊膜清洁，提供增强的可视化和实时工具-组织距离反馈。


<details>
  <summary>Details</summary>
Motivation: 继发性白内障是白内障手术后常见的视力丧失并发症，由残留晶状体物质在囊膜上增生引起。现有的囊膜清洁手术需要增强对整个囊膜的可视化以及在薄膜上的工具操作。

Method: 该系统将标准瞳孔穿透式和眼内OCT探头集成到手术器械上，用于赤道囊膜的可视化和实时工具-组织距离反馈。利用机器人精度，该系统能够对瞳孔区和赤道区的囊膜进行完整映射，并进行原位折射率和光纤偏移校准。

Result: 通过在眼部模型上进行的五次实验验证了囊膜映射策略，结果显示构建的囊膜模型均方根误差降低；在三只离体猪眼上进行了清洁策略演示，未造成组织损伤。

Conclusion: 所开发的机器人系统能够实现精确的囊膜映射和清洁操作，有效解决了继发性白内障治疗中囊膜可视化和精确模型获取的挑战。

Abstract: Secondary cataract is one of the most common complications of vision loss due
to the proliferation of residual lens materials that naturally grow on the lens
capsule after cataract surgery. A potential treatment is capsule cleaning, a
surgical procedure that requires enhanced visualization of the entire capsule
and tool manipulation on the thin membrane. This article presents a robotic
system capable of performing the capsule cleaning procedure by integrating a
standard transpupillary and an intraocular optical coherence tomography probe
on a surgical instrument for equatorial capsule visualization and real-time
tool-to-tissue distance feedback. Using robot precision, the developed system
enables complete capsule mapping in the pupillary and equatorial regions with
in-situ calibration of refractive index and fiber offset, which are still
current challenges in obtaining an accurate capsule model. To demonstrate
effectiveness, the capsule mapping strategy was validated through five
experimental trials on an eye phantom that showed reduced root-mean-square
errors in the constructed capsule model, while the cleaning strategy was
performed in three ex-vivo pig eyes without tissue damage.

</details>


### [153] [A Study of Teleoperation Methods in a Simulated Virtual Eye Surgery Environment](https://arxiv.org/abs/2507.13654)
*Haoran Wang,Yasamin Foroutani,Matthew Nepo,Mercedes Rodriguez,Ji Ma,Jean-Pierre Hubschman,Tsu-Chin Tsao,Jacob Rosen*

Main category: cs.RO

TL;DR: 本文在模拟玻璃体视网膜手术环境中，研究了不同缩放因子下“内部控制”和“外部控制”模式的性能。


<details>
  <summary>Details</summary>
Motivation: 优化控制方法和缩放因子可以提高手术效率和准确性，并最大限度地降低未来机器人辅助眼内手术的风险。

Method: 研究人员改造了IRISS远程手术系统的控制台，将模拟显微镜视图投射到VR头显中。五名经验丰富的玻璃体视网膜外科医生和五名无手术经验的工程师使用该系统执行了玻璃体视网膜手术中的常见任务。

Result: 实验结果表明，在较高缩放因子（20或30）下的“内部控制”方法总体表现最佳，尽管最佳缩放因子可能因任务和复杂性而异。

Conclusion: 优化控制方法和缩放因子有望提高未来机器人辅助眼内手术的效率、准确性并降低风险。

Abstract: This paper examines the performance of Inside and Outside Control modes at
various scaling factors in a simulated vitreoretinal surgical setting. The
IRISS teleoperated surgical system's console (cockpit) was adapted to project a
simulated microscope view of an intraocular setup to a virtual reality (VR)
headset. Five experienced vitreoretinal surgeons and five engineers with no
surgical experience used the system to perform tasks common to vitreoretinal
surgery. Experimental results indicate that Inside Control methods at higher
scaling factors (20 or 30) achieved the best performance overall, though the
optimal scaling factor may vary by task and complexity. Optimizing control
methods and scaling factors could lead to improvements in surgical efficiency
and accuracy, as well as minimize risks in future robotic-assisted intraocular
procedures.

</details>


### [154] [Iteratively Learning Muscle Memory for Legged Robots to Master Adaptive and High Precision Locomotion](https://arxiv.org/abs/2507.13662)
*Jing Cheng,Yasser G. Alqaham,Zhenyu Gan,Amit K. Sanyal*

Main category: cs.RO

TL;DR: 本文提出了一种可扩展、自适应的腿式机器人控制框架，该框架将迭代学习控制（ILC）与受生物启发的扭矩库（TL，类比肌肉记忆）相结合，显著提高了轨迹跟踪精度和泛化能力，并降低了在线计算需求。


<details>
  <summary>Details</summary>
Motivation: 现有腿式机器人面临未建模动力学和外部干扰下准确轨迹跟踪的挑战，需要一种能提高准确性和泛化能力，以适应各种步态和环境的控制方法。

Method: 该方法将迭代学习控制（ILC）与生物启发的扭矩库（TL）集成。它利用周期性步态的重复性，并将ILC扩展到非周期性任务。控制架构是数据驱动的，结合了基于物理的模型（源自混合系统轨迹优化）和实时学习，以补偿模型不确定性和外部干扰。核心是开发了一个广义扭矩库，用于存储学习到的控制配置文件，实现对速度、地形和重力条件的快速适应，从而消除重复学习并显著减少在线计算。该方法在双足机器人Cassie和四足机器人A1上进行了广泛的仿真和硬件实验验证。

Result: 该框架能在几秒钟内将关节跟踪误差减少高达85%，并能可靠执行周期性和非周期性步态，包括斜坡遍历和地形适应。与现有最先进的全身控制器相比，学习到的技能在执行过程中无需在线计算，且控制更新速率超过现有方法的30倍。

Conclusion: 将ILC与扭矩记忆相结合，是解决非结构化和动态环境下腿式机器人运动的一个高效、数据高效且实用的解决方案。

Abstract: This paper presents a scalable and adaptive control framework for legged
robots that integrates Iterative Learning Control (ILC) with a biologically
inspired torque library (TL), analogous to muscle memory. The proposed method
addresses key challenges in robotic locomotion, including accurate trajectory
tracking under unmodeled dynamics and external disturbances. By leveraging the
repetitive nature of periodic gaits and extending ILC to nonperiodic tasks, the
framework enhances accuracy and generalization across diverse locomotion
scenarios. The control architecture is data-enabled, combining a physics-based
model derived from hybrid-system trajectory optimization with real-time
learning to compensate for model uncertainties and external disturbances. A
central contribution is the development of a generalized TL that stores learned
control profiles and enables rapid adaptation to changes in speed, terrain, and
gravitational conditions-eliminating the need for repeated learning and
significantly reducing online computation. The approach is validated on the
bipedal robot Cassie and the quadrupedal robot A1 through extensive simulations
and hardware experiments. Results demonstrate that the proposed framework
reduces joint tracking errors by up to 85% within a few seconds and enables
reliable execution of both periodic and nonperiodic gaits, including slope
traversal and terrain adaptation. Compared to state-of-the-art whole-body
controllers, the learned skills eliminate the need for online computation
during execution and achieve control update rates exceeding 30x those of
existing methods. These findings highlight the effectiveness of integrating ILC
with torque memory as a highly data-efficient and practical solution for legged
locomotion in unstructured and dynamic environments.

</details>


### [155] [SaWa-ML: Structure-Aware Pose Correction and Weight Adaptation-Based Robust Multi-Robot Localization](https://arxiv.org/abs/2507.13702)
*Junho Choi,Kihwan Ryoo,Jeewon Kim,Taeyun Kim,Eungchang Lee,Myeongwoo Jeong,Kevin Christiansen Marsim,Hyungtae Lim,Hyun Myung*

Main category: cs.RO

TL;DR: 本文提出了一种名为 SaWa-ML 的新型视觉-惯性-测距多机器人定位方法，通过利用UWB传感器数据进行几何结构感知位姿校正和基于权重自适应的鲁棒定位，有效减少了长期漂移。


<details>
  <summary>Details</summary>
Motivation: 现有的多机器人定位方法在优化过程中未能充分考虑个体机器人里程计估计和机器人间距离测量的特性，且过度依赖个体里程计精度，导致长期漂移误差的累积。

Method: SaWa-ML方法通过以下两点实现：1) 利用UWB传感器数据（其测距误差不随时间累积）首先估计机器人间的相对位置，然后校正每个机器人的位置，从而减少长期漂移误差。2) 考虑传感器数据和视觉-惯性里程计估计的特性，设计了自适应权重用于机器人位姿校正。

Result: 该方法在真实世界实验中得到了验证，与现有最先进的算法相比，性能有显著提升。

Conclusion: SaWa-ML通过结合UWB传感器和自适应权重机制，成功解决了多机器人定位中长期漂移和鲁棒性不足的问题，实现了更精确和稳定的多机器人定位。

Abstract: Multi-robot localization is a crucial task for implementing multi-robot
systems. Numerous researchers have proposed optimization-based multi-robot
localization methods that use camera, IMU, and UWB sensors. Nevertheless,
characteristics of individual robot odometry estimates and distance
measurements between robots used in the optimization are not sufficiently
considered. In addition, previous researches were heavily influenced by the
odometry accuracy that is estimated from individual robots. Consequently,
long-term drift error caused by error accumulation is potentially inevitable.
In this paper, we propose a novel visual-inertial-range-based multi-robot
localization method, named SaWa-ML, which enables geometric structure-aware
pose correction and weight adaptation-based robust multi-robot localization.
Our contributions are twofold: (i) we leverage UWB sensor data, whose range
error does not accumulate over time, to first estimate the relative positions
between robots and then correct the positions of each robot, thus reducing
long-term drift errors, (ii) we design adaptive weights for robot pose
correction by considering the characteristics of the sensor data and
visual-inertial odometry estimates. The proposed method has been validated in
real-world experiments, showing a substantial performance increase compared
with state-of-the-art algorithms.

</details>


### [156] [AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework](https://arxiv.org/abs/2507.13729)
*Yu Yao,Salil Bhatnagar,Markus Mazzola,Vasileios Belagiannis,Igor Gilitschenski,Luigi Palmieri,Simon Razniewski,Marcel Hallgarten*

Main category: cs.RO

TL;DR: 本文提出了一种基于LLM代理的框架，利用自然语言描述来增强真实世界交通场景，以解决自动驾驶测试中罕见关键场景数据稀缺、数据驱动生成缺乏控制以及手动增强不可扩展的问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶规划器的测试和评估面临挑战，因为罕见但关键的场景难以通过纯粹的真实世界数据收集来捕获。数据驱动模型生成场景需要大量训练数据且缺乏细粒度控制，同时可能引入分布偏移。现有的通过增强原始测试集场景的方法依赖于领域专家手动操作，无法满足大规模评估的需求。

Method: 本文引入了一种新颖的基于LLM代理的框架，通过自然语言描述来增强真实世界的交通场景。其核心创新在于采用代理设计，实现了对输出的细粒度控制，即使使用较小、成本效益高的LLM也能保持高性能。

Result: 广泛的人类专家评估表明，该框架能够准确遵循用户意图，生成高质量的增强场景，其质量可与手动创建的场景相媲美。

Conclusion: 该LLM代理框架为自动驾驶系统评估中交通场景的增强提供了一种可扩展、可控且高质量的解决方案，克服了现有方法的局限性。

Abstract: Rare, yet critical, scenarios pose a significant challenge in testing and
evaluating autonomous driving planners. Relying solely on real-world driving
scenes requires collecting massive datasets to capture these scenarios. While
automatic generation of traffic scenarios appears promising, data-driven models
require extensive training data and often lack fine-grained control over the
output. Moreover, generating novel scenarios from scratch can introduce a
distributional shift from the original training scenes which undermines the
validity of evaluations especially for learning-based planners. To sidestep
this, recent work proposes to generate challenging scenarios by augmenting
original scenarios from the test set. However, this involves the manual
augmentation of scenarios by domain experts. An approach that is unable to meet
the demands for scale in the evaluation of self-driving systems. Therefore,
this paper introduces a novel LLM-agent based framework for augmenting
real-world traffic scenarios using natural language descriptions, addressing
the limitations of existing methods. A key innovation is the use of an agentic
design, enabling fine-grained control over the output and maintaining high
performance even with smaller, cost-effective LLMs. Extensive human expert
evaluation demonstrates our framework's ability to accurately adhere to user
intent, generating high quality augmented scenarios comparable to those created
manually.

</details>


### [157] [Design Analysis of an Innovative Parallel Robot for Minimally Invasive Pancreatic Surgery](https://arxiv.org/abs/2507.13787)
*Doina Pisla,Alexandru Pusca,Andrei Caprariu,Adrian Pisla,Bogdan Gherman,Calin Vaida,Damien Chablat*

Main category: cs.RO

TL;DR: 本文设计了两种四自由度并联机器人架构（ATHENA-1和ATHENA-2），用于机器人辅助微创胰腺手术，并通过有限元分析和工作空间分析比较它们的刚度和可用性，以选择最佳架构。


<details>
  <summary>Details</summary>
Motivation: 为机器人辅助微创胰腺手术设计一种并联机器人。

Method: 提出了两种四自由度并联机器人架构（ATHENA-1和ATHENA-2），展示了它们的运动学方案和概念性三维CAD模型。通过有限元方法（FEM）模拟评估两种架构的刚度，并进行工作空间定量分析以评估其在医疗任务中的可用性。

Result: FEM模拟确定了两种架构中刚度更高的一种。工作空间定量分析评估了两种架构的可用性。这些结果被用于选择符合设计标准的架构。

Conclusion: 根据刚度和工作空间分析结果，选择了一种架构来开发手术机器人的实验模型。

Abstract: This paper focuses on the design of a parallel robot designed for robotic
assisted minimally invasive pancreatic surgery. Two alternative architectures,
called ATHENA-1 and ATHENA-2, each with 4 degrees of freedom (DOF) are
proposed. Their kinematic schemes are presented, and the conceptual 3D CAD
models are illustrated. Based on these, two Finite Element Method (FEM)
simulations were performed to determine which architecture has the higher
stiffness. A workspace quantitative analysis is performed to further assess the
usability of the two proposed parallel architectures related to the medical
tasks. The obtained results are used to select the architecture which fit the
required design criteria and will be used to develop the experimental model of
the surgical robot.

</details>


### [158] [Safety Certification in the Latent space using Control Barrier Functions and World Models](https://arxiv.org/abs/2507.13871)
*Mehul Anand,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 该论文提出一个半监督框架，利用世界模型潜在空间中的控制障碍证书，在有限标记数据下合成安全的视觉运动策略，以解决视觉数据安全控制器合成中标记数据量大的问题。


<details>
  <summary>Details</summary>
Motivation: 从视觉数据合成安全控制器通常需要大量监督标记的安全关键数据，这在现实世界中往往不切实际。

Method: 引入一个半监督框架，该框架利用在世界模型潜在空间中学习到的控制障碍证书（CBCs）来合成安全的视觉运动策略。它使用有限的标记数据共同学习神经障碍函数和安全控制器，同时利用现代视觉Transformer的预测能力进行潜在动力学建模。

Result: 该方法成功实现了在有限标记数据下合成安全视觉运动策略，并利用世界模型的预测能力进行潜在动态建模。

Conclusion: 该框架通过结合潜在空间世界模型、控制障碍证书和半监督学习，实现了可扩展且数据高效的安全控制。

Abstract: Synthesising safe controllers from visual data typically requires extensive
supervised labelling of safety-critical data, which is often impractical in
real-world settings. Recent advances in world models enable reliable prediction
in latent spaces, opening new avenues for scalable and data-efficient safe
control. In this work, we introduce a semi-supervised framework that leverages
control barrier certificates (CBCs) learned in the latent space of a world
model to synthesise safe visuomotor policies. Our approach jointly learns a
neural barrier function and a safe controller using limited labelled data,
while exploiting the predictive power of modern vision transformers for latent
dynamics modelling.

</details>


### [159] [AeroThrow: An Autonomous Aerial Throwing System for Precise Payload Delivery](https://arxiv.org/abs/2507.13903)
*Ziliang Li,Hongming Chen,Yiyang Lin,Biyu Ye,Ximin Lyu*

Main category: cs.RO

TL;DR: 该论文提出了一种基于空中机械手（AM）的自主空投系统，结合非线性模型预测控制（NMPC）和分层扰动补偿策略，以提高空投任务在复杂环境中的敏捷性和精度，解决控制模式切换和系统延迟问题。


<details>
  <summary>Details</summary>
Motivation: 自主航空系统在运输和配送任务中日益重要，尤其是在复杂环境中。空投任务面临控制模式突然切换、固有系统延迟以及控制误差等挑战，需要解决方案来提高其精度和可靠性。

Method: 该研究引入了空中机械手（AM），利用其额外的自由度主动补偿无人机跟踪误差。通过对抛物线着陆点施加平滑连续约束，生成对有效载荷释放时机不敏感的空中投掷轨迹。此外，在非线性模型预测控制（NMPC）框架中融入分层扰动补偿策略，以减轻系统参数突然变化的影响，并利用NMPC的预测能力提高空中投掷的精度。

Result: 仿真和实际实验结果均表明，所提出的系统在空投任务中实现了更高的敏捷性和精度。

Conclusion: 所提出的基于空中机械手的自主空投系统，通过有效应对控制模式切换、系统延迟和控制误差等挑战，显著提高了空投任务的敏捷性和精度。

Abstract: Autonomous aerial systems play an increasingly vital role in a wide range of
applications, particularly for transport and delivery tasks in complex
environments. In airdrop missions, these platforms face the dual challenges of
abrupt control mode switching and inherent system delays along with control
errors. To address these issues, this paper presents an autonomous airdrop
system based on an aerial manipulator (AM). The introduction of additional
actuated degrees of freedom enables active compensation for UAV tracking
errors. By imposing smooth and continuous constraints on the parabolic landing
point, the proposed approach generates aerial throwing trajectories that are
less sensitive to the timing of payload release. A hierarchical disturbance
compensation strategy is incorporated into the Nonlinear Model Predictive
Control (NMPC) framework to mitigate the effects of sudden changes in system
parameters, while the predictive capabilities of NMPC are further exploited to
improve the precision of aerial throwing. Both simulation and real-world
experimental results demonstrate that the proposed system achieves greater
agility and precision in airdrop missions.

</details>


### [160] [NeHMO: Neural Hamilton-Jacobi Reachability Learning for Decentralized Safe Multi-Agent Motion Planning](https://arxiv.org/abs/2507.13940)
*Qingyi Chen,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 本文提出了一种基于神经哈密顿-雅可比可达性学习（Neural HJR）的去中心化多智能体运动规划（MAMP）方法，以解决现有MAMP方法在安全性、可伸缩性和实时性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体运动规划（MAMP）方法面临两难困境：去中心化算法依赖预测、契约或通信来保证安全，而中心化方法则难以扩展且无法实时决策。

Method: 引入神经哈密顿-雅可比可达性学习（Neural HJR）来建模高维配置空间中的最坏情况碰撞和安全约束。在此基础上，提出一个去中心化轨迹优化框架，该框架利用学习到的HJR解来实时解决MAMP任务。

Result: 该方法具有可伸缩性和数据效率，能够解决具有复杂碰撞约束的高维MAMP问题。它适用于各种动力学系统，包括12维双臂设置，并在解决具有挑战性的MAMP任务方面优于一系列现有技术。

Conclusion: 所提出的Neural HJR方法通过提供可伸缩、数据高效且通用的解决方案，成功应对了多智能体运动规划中的安全和实时性挑战，并超越了现有技术。

Abstract: Safe Multi-Agent Motion Planning (MAMP) is a significant challenge in
robotics. Despite substantial advancements, existing methods often face a
dilemma. Decentralized algorithms typically rely on predicting the behavior of
other agents, sharing contracts, or maintaining communication for safety, while
centralized approaches struggle with scalability and real-time decision-making.
To address these challenges, we introduce Neural Hamilton-Jacobi Reachability
Learning (HJR) for Decentralized Multi-Agent Motion Planning. Our method
provides scalable neural HJR modeling to tackle high-dimensional configuration
spaces and capture worst-case collision and safety constraints between agents.
We further propose a decentralized trajectory optimization framework that
incorporates the learned HJR solutions to solve MAMP tasks in real-time. We
demonstrate that our method is both scalable and data-efficient, enabling the
solution of MAMP problems in higher-dimensional scenarios with complex
collision constraints. Our approach generalizes across various dynamical
systems, including a 12-dimensional dual-arm setup, and outperforms a range of
state-of-the-art techniques in successfully addressing challenging MAMP tasks.
Video demonstrations are available at https://youtu.be/IZiePX0p1Mc.

</details>


### [161] [A Minimalist Controller for Autonomously Self-Aggregating Robotic Swarms: Enabling Compact Formations in Multitasking Scenarios](https://arxiv.org/abs/2507.13969)
*Maria Eduarda Silva de Macedo,Ana Paula Chiarelli de Souza,Roberto Silvio Ubertino Rosso Jr.,Yuri Kaszubowski Lopes*

Main category: cs.RO

TL;DR: 本文提出了一种多任务自聚集算法，使同质机器人群能够仅依靠视线传感器形成紧凑的集群，解决了现有方法形成非紧凑或非完全自主集群的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务自聚集方法存在生成非紧凑圆形队形或非完全自主的问题，且不同组的动态行为会相互影响，这促使研究者寻求更紧凑、更自主的解决方案。

Method: 研究人员提出了一种新的多任务自聚集行为，使同质机器人群能够仅依靠视线传感器进行自我分类，形成不同的紧凑集群。他们通过一系列模拟实验，测试了不同组数和每组机器人数量配置下的可扩展性。

Result: 该多任务自聚集行为表现出良好的可扩展性，并能实现紧凑的队形。与现有研究相比，该方法显著提高了集群的紧凑性，同时保持了相似的机器人聚集比例。

Conclusion: 该研究成功开发了一种可扩展、自主且能形成紧凑集群的多任务自聚集行为，为群体机器人协作提供了有效解决方案，并改善了集群的紧凑性。

Abstract: The deployment of simple emergent behaviors in swarm robotics has been
well-rehearsed in the literature. A recent study has shown how self-aggregation
is possible in a multitask approach -- where multiple self-aggregation task
instances occur concurrently in the same environment. The multitask approach
poses new challenges, in special, how the dynamic of each group impacts the
performance of others. So far, the multitask self-aggregation of groups of
robots suffers from generating a circular formation -- that is not fully
compact -- or is not fully autonomous. In this paper, we present a multitask
self-aggregation where groups of homogeneous robots sort themselves into
different compact clusters, relying solely on a line-of-sight sensor. Our
multitask self-aggregation behavior was able to scale well and achieve a
compact formation. We report scalability results from a series of simulation
trials with different configurations in the number of groups and the number of
robots per group. We were able to improve the multitask self-aggregation
behavior performance in terms of the compactness of the clusters, keeping the
proportion of clustered robots found in other studies.

</details>


### [162] [A segmented robot grasping perception neural network for edge AI](https://arxiv.org/abs/2507.13970)
*Casper Bröcheler,Thomas Vroom,Derrick Timmermans,Alan van den Akker,Guangzhi Tang,Charalampos S. Kouzinopoulos,Rico Möckel*

Main category: cs.RO

TL;DR: 本文在RISC-V边缘芯片上实现并优化了一个基于热图的6自由度抓取姿态检测深度学习模型，验证了低功耗MCU在实时机器人抓取中的可行性。


<details>
  <summary>Details</summary>
Motivation: 机器人抓取需要精确感知和控制，深度神经网络表现出色。但在资源受限环境中，实现低延迟、低功耗的实时抓取推理是一个挑战。

Method: 在GAP9 RISC-V片上系统上实现了“热图引导抓取检测”框架，用于检测6自由度抓取姿态。通过输入维度缩减、模型分区和量化等硬件感知技术对模型进行了优化。

Result: 在GraspNet-1Billion基准测试上进行了实验评估，验证了完全片上推理的可行性。

Conclusion: 低功耗微控制器在实时、自主操纵方面具有巨大潜力。

Abstract: Robotic grasping, the ability of robots to reliably secure and manipulate
objects of varying shapes, sizes and orientations, is a complex task that
requires precise perception and control. Deep neural networks have shown
remarkable success in grasp synthesis by learning rich and abstract
representations of objects. When deployed at the edge, these models can enable
low-latency, low-power inference, making real-time grasping feasible in
resource-constrained environments. This work implements Heatmap-Guided Grasp
Detection, an end-to-end framework for the detection of 6-Dof grasp poses, on
the GAP9 RISC-V System-on-Chip. The model is optimised using hardware-aware
techniques, including input dimensionality reduction, model partitioning, and
quantisation. Experimental evaluation on the GraspNet-1Billion benchmark
validates the feasibility of fully on-chip inference, highlighting the
potential of low-power MCUs for real-time, autonomous manipulation.

</details>


### [163] [A multi-strategy improved snake optimizer for three-dimensional UAV path planning and engineering problems](https://arxiv.org/abs/2507.14043)
*Genliang Li,Yaxin Cui,Jinyu Su*

Main category: cs.RO

TL;DR: 本文提出了一种多策略改进蛇优化器（MISO），旨在解决原始蛇优化器（SO）收敛慢和易陷入局部最优的问题，并通过引入多种新策略显著提升了算法性能，并在基准测试函数和实际应用中取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 原始的蛇优化器（SO）存在收敛速度慢和易陷入局部最优的缺点。同时，无人机路径规划和工程设计等实际问题对优化算法的性能提出了更高的要求，需要更高效、稳定的优化方法。

Method: 本文提出MISO算法，主要包含以下改进策略：1) 基于正弦函数的自适应随机扰动策略，以避免陷入局部最优。2) 基于尺度因子和领导者的自适应Levy飞行策略，并赋予雄性蛇领导者飞行能力，以跳出局部最优。3) 结合精英领导和布朗运动的位置更新策略，以加速收敛并保证精度。为验证MISO性能，使用30个CEC2017和CEC2022测试函数与11种流行算法进行比较，并将其应用于无人机3D路径规划和6个工程设计问题。

Result: 实验结果表明，MISO在求解质量和稳定性方面均优于其他竞争算法。在无人机3D路径规划问题和工程设计问题中，MISO也展现了良好的可行性。

Conclusion: MISO有效解决了原始SO的局限性，并在优化问题上表现出强大的应用潜力，尤其在解决复杂实际工程问题方面具有显著优势。

Abstract: Metaheuristic algorithms have gained widespread application across various
fields owing to their ability to generate diverse solutions. One such algorithm
is the Snake Optimizer (SO), a progressive optimization approach. However, SO
suffers from the issues of slow convergence speed and susceptibility to local
optima. In light of these shortcomings, we propose a novel Multi-strategy
Improved Snake Optimizer (MISO). Firstly, we propose a new adaptive random
disturbance strategy based on sine function to alleviate the risk of getting
trapped in a local optimum. Secondly, we introduce adaptive Levy flight
strategy based on scale factor and leader and endow the male snake leader with
flight capability, which makes it easier for the algorithm to leap out of the
local optimum and find the global optimum. More importantly, we put forward a
position update strategy combining elite leadership and Brownian motion,
effectively accelerating the convergence speed while ensuring precision.
Finally, to demonstrate the performance of MISO, we utilize 30 CEC2017 test
functions and the CEC2022 test suite, comparing it with 11 popular algorithms
across different dimensions to validate its effectiveness. Moreover, Unmanned
Aerial Vehicle (UAV) has been widely used in various fields due to its
advantages of low cost, high mobility and easy operation. However, the UAV path
planning problem is crucial for flight safety and efficiency, and there are
still challenges in establishing and optimizing the path model. Therefore, we
apply MISO to the UAV 3D path planning problem as well as 6 engineering design
problems to assess its feasibility in practical applications. The experimental
results demonstrate that MISO exceeds other competitive algorithms in terms of
solution quality and stability, establishing its strong potential for
application.

</details>


### [164] [EdgeVLA: Efficient Vision-Language-Action Models](https://arxiv.org/abs/2507.14049)
*Paweł Budzianowski,Wesley Maa,Matthew Freed,Jingxiang Mo,Winston Hsiao,Aaron Xie,Tomasz Młoduchowski,Viraj Tipnis,Benjamin Bolte*

Main category: cs.RO

TL;DR: 本文提出Edge VLA (EVLA)，一种新方法，通过消除自回归预测和利用小型语言模型，显著提高视觉-语言-动作(VLA)模型在边缘设备上的推理速度和内存效率，同时保持其表示能力。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型(VLMs)在解决机器人数据稀缺问题方面表现出潜力，但将大型VLMs部署到资源受限的移动操作系统上仍是巨大挑战。

Method: EVLA通过两项关键创新实现：1) 消除末端执行器位置预测的自回归要求，从而将推理速度提高7倍；2) 利用小型语言模型(SLMs)的效率，在显著降低计算需求的同时，达到与大型模型相当的训练性能。

Result: 早期结果表明，EVLA实现了与OpenVLA相当的训练特性，同时在推理速度和内存效率方面取得了显著提升。

Conclusion: EVLA成功地在边缘设备上实现了VLA模型的实时性能，并保持了与大型模型相当的能力，有望推动通用视觉运动控制策略在资源受限系统上的部署。

Abstract: Vision-Language Models (VLMs) have emerged as a promising approach to address
the data scarcity challenge in robotics, enabling the development of
generalizable visuomotor control policies. While models like OpenVLA showcase
the potential of this paradigm, deploying large-scale VLMs on
resource-constrained mobile manipulation systems remains a significant hurdle.
This paper introduces Edge VLA (EVLA), a novel approach designed to
significantly enhance the inference speed of Vision-Language-Action (VLA)
models. EVLA maintains the representational power of these models while
enabling real-time performance on edge devices. We achieve this through two key
innovations: 1) Eliminating the autoregressive requirement for end-effector
position prediction, leading to a 7x speedup in inference, and 2) Leveraging
the efficiency of Small Language Models (SLMs), demonstrating comparable
training performance to larger models with significantly reduced computational
demands. Our early results demonstrate that EVLA achieves comparable training
characteristics to OpenVLA while offering substantial gains in inference speed
and memory efficiency. We release our model checkpoints and training
\href{https://github.com/kscalelabs/evla }{codebase} to foster further
research.

</details>


### [165] [Design of a Modular Mobile Inspection and Maintenance Robot for an Orbital Servicing Hub](https://arxiv.org/abs/2507.14059)
*Tianyuan Wang,Mark A Post,Mathieu Deremetz*

Main category: cs.RO

TL;DR: 本文介绍了STARFAB项目中的移动检查模块（MIM），一个用于轨道自动化仓库的自主检查和维护机器人，旨在支持“新空间”商业生态系统。


<details>
  <summary>Details</summary>
Motivation: 在“新空间”商业生态系统中，自主机器人在轨道上组装和重复利用空间硬件组件至关重要。STARFAB项目旨在创建一个地面演示的轨道自动化仓库，作为可持续商业运营和服务的中心。该设施的关键能力是监测、检查和评估存储组件及设施自身的状况。

Method: STARFAB移动检查模块（MIM）被设计为一个独立移动的机器人，通过标准互连（SI）可由步行机械臂（WM）携带，并可根据需要进行存储和取回。MIM配备高分辨率摄像头、3D轮廓仪和热成像传感器，并可添加其他模块化传感器。其模块化本体内还存储有抓取工具和扭矩扳手，供连接的WM进行维护操作。

Result: 本文详细介绍了MIM作为在轨自主检查和维护系统的操作概念、机械和电子设计，以及用于无损检测的传感器包。目前，实施和测试仍在进行中。

Conclusion: MIM是STARFAB轨道自动化仓库实现自主检查和维护的关键组成部分，其设计和操作概念为未来可持续的商业空间运营提供了基础，支持了“新空间”商业生态系统的发展。

Abstract: The use of autonomous robots in space is an essential part of the "New Space"
commercial ecosystem of assembly and re-use of space hardware components in
Earth orbit and beyond. The STARFAB project aims to create a ground
demonstration of an orbital automated warehouse as a hub for sustainable
commercial operations and servicing. A critical part of this fully-autonomous
robotic facility will be the capability to monitor, inspect, and assess the
condition of both the components stored in the warehouse, and the STARFAB
facility itself. This paper introduces ongoing work on the STARFAB Mobile
Inspection Module (MIM). The MIM uses Standard Interconnects (SI) so that it
can be carried by Walking Manipulators (WM) as an independently-mobile robot,
and multiple MIMs can be stored and retrieved as needed for operations on
STARFAB. The MIM carries high-resolution cameras, a 3D profilometer, and a
thermal imaging sensor, with the capability to add other modular sensors. A
grasping tool and torque wrench are stored within the modular body for use by
an attached WM for maintenance operations. Implementation and testing is still
ongoing at the time of writing. This paper details the concept of operations
for the MIM as an on-orbit autonomous inspection and maintenance system, the
mechanical and electronic design of the MIM, and the sensors package used for
non-destructive testing.

</details>


### [166] [MorphIt: Flexible Spherical Approximation of Robot Morphology for Representation-driven Adaptation](https://arxiv.org/abs/2507.14061)
*Nataliya Nechyporenko,Yutong Zhang,Sean Campbell,Alessandro Roncone*

Main category: cs.RO

TL;DR: MorphIt是一种新颖的算法，通过球形基元近似机器人形态，以平衡几何精度和计算效率，使机器人能根据任务需求动态调整其形态表示。


<details>
  <summary>Details</summary>
Motivation: 目前的机器人系统将物理形态视为固定约束而非自适应资源，导致相同的刚性几何表示无法有效满足具有不同计算和精度要求的任务。研究旨在开发一种能自适应调整机器人形态表示的方法。

Method: 引入MorphIt算法，它采用球形基元来近似机器人形态。该算法基于自动化的梯度优化框架，具有可调参数，明确控制物理保真度与计算成本之间的权衡。

Result: 定量评估显示，MorphIt在多项指标上优于基线方法（变分球集近似和自适应中轴近似），能用更少的球体实现更好的网格近似，并降低计算开销。实验证明，MorphIt增强了机器人的碰撞检测精度、接触丰富的交互仿真能力以及在狭窄空间中的导航能力。

Conclusion: 通过动态调整几何表示以适应任务需求，机器人能够将其实体作为一种活跃资源而非僵硬参数来利用。这为机器人操作开辟了新的领域，使其在物理形态必须持续平衡精度与计算可行性的环境中表现更佳。

Abstract: What if a robot could rethink its own morphological representation to better
meet the demands of diverse tasks? Most robotic systems today treat their
physical form as a fixed constraint rather than an adaptive resource, forcing
the same rigid geometric representation to serve applications with vastly
different computational and precision requirements. We introduce MorphIt, a
novel algorithm for approximating robot morphology using spherical primitives
that balances geometric accuracy with computational efficiency. Unlike existing
approaches that rely on either labor-intensive manual specification or
inflexible computational methods, MorphIt implements an automatic
gradient-based optimization framework with tunable parameters that provides
explicit control over the physical fidelity versus computational cost tradeoff.
Quantitative evaluations demonstrate that MorphIt outperforms baseline
approaches (Variational Sphere Set Approximation and Adaptive Medial-Axis
Approximation) across multiple metrics, achieving better mesh approximation
with fewer spheres and reduced computational overhead. Our experiments show
enhanced robot capabilities in collision detection accuracy, contact-rich
interaction simulation, and navigation through confined spaces. By dynamically
adapting geometric representations to task requirements, robots can now exploit
their physical embodiment as an active resource rather than an inflexible
parameter, opening new frontiers for manipulation in environments where
physical form must continuously balance precision with computational
tractability.

</details>


### [167] [Context-Aware Behavior Learning with Heuristic Motion Memory for Underwater Manipulation](https://arxiv.org/abs/2507.14099)
*Markus Buchholz,Ignacio Carlucho,Michele Grimaldi,Maria Koskinopoulou,Yvan R. Petillot*

Main category: cs.RO

TL;DR: 该论文提出了一种自适应启发式运动规划器框架，结合启发式运动空间（HMS）和贝叶斯网络，以增强水下自主操作的运动规划，有效应对实时不确定性。


<details>
  <summary>Details</summary>
Motivation: 当前运动规划方法未能有效利用先前的运动经验，也无法适应水下环境中固有的实时不确定性，导致规划效率和安全性不足。

Method: 引入自适应启发式运动规划器（AHMP）框架，该框架将启发式运动空间（HMS）与贝叶斯网络相结合。在HMS内使用概率路线图（PRM）算法，通过最小化综合成本函数（考虑距离、不确定性、能耗和执行时间）来优化路径。HMS显著减小了搜索空间，提高了计算性能。贝叶斯网络用于根据实时传感器数据和环境条件动态更新不确定性估计，从而完善路径成功的联合概率。

Result: 通过广泛的仿真和真实世界测试场景，展示了该方法在提高性能和鲁棒性方面的优势。

Conclusion: 这种概率方法显著提升了自主水下机器人的能力，确保在动态海洋挑战面前实现优化的运动规划。

Abstract: Autonomous motion planning is critical for efficient and safe underwater
manipulation in dynamic marine environments. Current motion planning methods
often fail to effectively utilize prior motion experiences and adapt to
real-time uncertainties inherent in underwater settings. In this paper, we
introduce an Adaptive Heuristic Motion Planner framework that integrates a
Heuristic Motion Space (HMS) with Bayesian Networks to enhance motion planning
for autonomous underwater manipulation. Our approach employs the Probabilistic
Roadmap (PRM) algorithm within HMS to optimize paths by minimizing a composite
cost function that accounts for distance, uncertainty, energy consumption, and
execution time. By leveraging HMS, our framework significantly reduces the
search space, thereby boosting computational performance and enabling real-time
planning capabilities. Bayesian Networks are utilized to dynamically update
uncertainty estimates based on real-time sensor data and environmental
conditions, thereby refining the joint probability of path success. Through
extensive simulations and real-world test scenarios, we showcase the advantages
of our method in terms of enhanced performance and robustness. This
probabilistic approach significantly advances the capability of autonomous
underwater robots, ensuring optimized motion planning in the face of dynamic
marine challenges.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [168] [Heatwave-driven air conditioning adoption could increase German electricity demand by 14 GW in the near future](https://arxiv.org/abs/2507.13534)
*Leo Semmelmann,Frederik vom Scheidt*

Main category: eess.SY

TL;DR: 研究预测，在德国未来热浪情景下，移动空调的普及将使电网峰值负荷增加超过14 GW（23%），尤其是在城市热点区域，且需求高峰与光伏发电低谷重合，对电力系统稳定构成挑战。


<details>
  <summary>Details</summary>
Motivation: 气候变化导致的热浪加剧促使移动空调系统快速普及，这可能给电网和电力系统带来额外压力。

Method: 本研究提出了一种估算空调系统电力需求的新方法，该方法能够在系统层面以及高时间和空间粒度上进行估算。该方法结合了天气数据、人口普查数据、社会人口学假设、出行模式和温度依赖的空调激活函数。研究将此方法应用于德国近未来（2025年7月）的热浪情景，假设家庭空调普及率从目前的19%增加到35%，并分析了德国196,428个1平方公里网格单元的影响。

Result: 新购买的移动空调系统可能使峰值负荷增加超过14 GW（23%），城市热点区域每平方公里可达5.8 MW。需求的时间模式呈现明显的午后高峰，与光伏发电量较低的时间段重合，可能加剧电力系统稳定性挑战。

Conclusion: 研究结果强调了积极主动的能源系统规划的紧迫性，以管理新兴的需求高峰。

Abstract: Intensifying heatwaves driven by climate change are accelerating the adoption
of mobile air conditioning (AC) systems. A rapid mass adoption of such AC
systems could create additional stress on electricity grids and the power
system. This study presents a novel method to estimate the electricity demand
from AC systems both at system level and at high temporal and spatial
granularity. We apply the method to a near-future heatwave scenario in Germany
in which household AC adoption increases from current 19% to 35% during a
heatwave similar to the one of July 2025. We analyze the effects for 196,428
grid cells of one square kilometer across Germany, by combining weather data,
census data, socio-demographic assumptions, mobility patterns, and
temperature-dependent AC activation functions. We find that electricity demand
of newly purchased mobile AC systems could increase the peak load by over 14 GW
(23%), with urban hot-spots reaching 5.8 MW per square kilometer. The temporal
pattern creates a pronounced afternoon peak that coincides with lower
photovoltaic generation, potentially exacerbating power system stability
challenges. Our findings underscore the urgency for proactive energy system
planning to manage emerging demand peaks.

</details>


### [169] [MD-OFDM: An Energy-Efficient and Low-PAPR MIMO-OFDM Variant for Resource-Constrained Applications](https://arxiv.org/abs/2507.13623)
*Rahul Gulia*

Main category: eess.SY

TL;DR: 本文提出多维OFDM（MD-OFDM）系统，通过逐子载波发射天线选择策略，旨在降低传统MIMO-OFDM的高峰均功率比（PAPR）和功耗，并提升误码率（BER）性能。


<details>
  <summary>Details</summary>
Motivation: 传统的MIMO-OFDM系统，特别是使用MMSE等复杂均衡器时，由于多路射频链导致高峰均功率比（PAPR）和显著的功耗，是其主要缺点。

Method: 本文提出MD-OFDM系统，其核心方法是为每个子载波仅激活一根发射天线（逐子载波发射天线选择）。此外，论文还提供了BER、能量效率（EE）和PAPR的详细数学公式模型。

Result: 仿真结果表明，MD-OFDM与MMSE MIMO相比，实现了更优的误码率（BER）和显著更低的PAPR。然而，由于频谱复用减少，其峰值整体能量效率有所下降。

Conclusion: MD-OFDM是一种适用于物联网（IoT）和低功耗广域网（LPWAN）等对能量和成本敏感场景的替代方案，它能有效降低PAPR和功耗，并改善BER性能。

Abstract: Orthogonal Frequency Division Multiplexing (OFDM) combined with
Multiple-Input Multiple-Output (MIMO) techniques forms the backbone of modern
wireless communication systems. While offering high spectral efficiency and
robustness, conventional MIMO-OFDM, especially with complex equalizers like
Minimum Mean Square Error (MMSE), suffers from high Peak-to-Average Power Ratio
(PAPR) and significant power consumption due to multiple active Radio Frequency
(RF) chains. This paper proposes and mathematically models an alternative
system, termed Multi-Dimensional OFDM (MD-OFDM), which employs a per-subcarrier
transmit antenna selection strategy. By activating only one transmit antenna
for each subcarrier, MD-OFDM aims to reduce PAPR, lower power consumption, and
improve Bit Error Rate (BER) performance. We provide detailed mathematical
formulations for BER, Energy Efficiency (EE), and PAPR, and discuss the
suitability of MD-OFDM for various applications, particularly in
energy-constrained and cost-sensitive scenarios such as the Internet of Things
(IoT) and Low-Power Wide Area Networks (LPWAN). Simulation results demonstrate
that MD-OFDM achieves superior BER and significantly lower PAPR compared to
MMSE MIMO, albeit with a trade-off in peak overall energy efficiency due to
reduced spectral multiplexing.

</details>


### [170] [Spacecraft Safe Robust Control Using Implicit Neural Representation for Geometrically Complex Targets in Proximity Operations](https://arxiv.org/abs/2507.13672)
*Hang Zhou,Tao Meng,Kun Wang,Chengrui Shi,Renhao Mao,Weijia Wang,Jiakun Lei*

Main category: eess.SY

TL;DR: 该研究提出一种基于隐式神经表示和两层分层控制框架的安全鲁棒控制方法，用于解决复杂几何目标航天器在扰动下的近距离操作碰撞避免问题，显著提升了安全性并避免了局部最小值问题。


<details>
  <summary>Details</summary>
Motivation: 确保航天器近距离操作（特别是追逐器与复杂几何目标航天器之间的操作）在存在扰动的情况下避免碰撞，是当前面临的挑战。

Method: 1. 学习神经符号距离函数（SDF）：通过增强的隐式几何正则化方法，从点云数据中学习神经SDF，并采用过近似策略创建保守的安全边界。2. 两层分层安全鲁棒控制框架：
    - 第一层（安全速度生成）：构建二次锥规划（SOCP），显式纳入欠近似误差界，并引入循环不等式以缓解控制障碍函数（CBF）方法的局部最小值问题。
    - 第二层（安全鲁棒控制器）：集成扰动观测器和平滑安全滤波器，补偿估计误差，增强对外部扰动的鲁棒性。

Result: 广泛的数值模拟和蒙特卡洛分析验证了所提框架，结果表明与传统CBF方法相比，该框架显著提高了安全裕度，并有效避免了局部最小值问题。

Conclusion: 所提出的基于隐式神经表示和分层控制的安全鲁棒控制框架，能够有效应对复杂几何目标航天器在扰动下的碰撞避免挑战，显著提升了操作安全性与鲁棒性。

Abstract: This study addresses the challenge of ensuring safe spacecraft proximity
operations, focusing on collision avoidance between a chaser spacecraft and a
complex-geometry target spacecraft under disturbances. To ensure safety in such
scenarios, a safe robust control framework is proposed that leverages implicit
neural representations. To handle arbitrary target geometries without explicit
modeling, a neural signed distance function (SDF) is learned from point cloud
data via a enhanced implicit geometric regularization method, which
incorporates an over-apporximation strategy to create a conservative,
safety-prioritized boundary. The target's surface is implicitly defined by the
zero-level set of the learned neural SDF, while the values and gradients
provide critical information for safety controller design. This neural SDF
representation underpins a two-layer hierarchcial safe robust control
framework: a safe velocity generation layer and a safe robust controller layer.
In the first layer, a second-order cone program is formulated to generate
safety-guaranteed reference velocity by explicitly incorporating the
under-approximation error bound. Furthermore, a circulation inequality is
introduced to mitigate the local minimum issues commonly encountered in control
barrier function (CBF) methods. The second layer features an integrated
disturbance observer and a smooth safety filter explicitly compensating for
estimation error, bolstering robustness to external disturbances. Extensive
numerical simulations and Monte Carlo analysis validate the proposed framework,
demonstrating significantly improved safety margins and avoidance of local
minima compared to conventional CBF approaches.

</details>


### [171] [Minimum Clustering of Matrices Based on Phase Alignment](https://arxiv.org/abs/2507.13678)
*Honghao Wu,Kemi Ding,Li Qiu*

Main category: eess.SY

TL;DR: 本文提出了一种基于相位对齐的框架，通过策略性地聚类具有相似同步行为的智能体，以最小化多智能体系统中所需控制器类型，同时平衡同步性能和实现成本。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统需要平衡同步性能和控制器实现成本。现有集中式控制方法虽然能用更少控制器类型实现高性能，但扩展性差且存在单点故障；分布式控制策略则导致所需控制器类型随系统规模增加。因此，需要一种方法来减少所需控制器类型，以降低大规模多智能体系统的实现成本。

Method: 通过智能体的内在属性进行分类，引入了一种新颖的基于相位对齐的框架。该框架利用复矩阵的内在相位特性，将问题表述为受约束的聚类问题。提出了一种分层优化方法，结合了针对小规模系统的递归精确搜索和针对大规模网络的可扩展随机逼近。

Result: 该工作为大规模多智能体系统提供了一种经济高效的解决方案。理论结果应用于一个50智能体网络的分析，证明了所提出算法的有效性。

Conclusion: 该研究通过连接理论相位分析与实际控制综合，提出了一种有效的方法来最小化多智能体系统中的控制器类型，实现了成本效益和高性能的平衡，尤其适用于大规模系统。

Abstract: Coordinating multi-agent systems requires balancing synchronization
performance and controller implementation costs. To this end, we classify
agents by their intrinsic properties, enabling each group to be controlled by a
uniform controller and thus reducing the number of unique controller types
required. Existing centralized control methods, despite their capability to
achieve high synchronization performance with fewer types of controllers,
suffer from critical drawbacks such as limited scalability and vulnerability to
single points of failure. On the other hand, distributed control strategies,
where controllers are typically agent-dependent, result in the type of required
controllers increasing proportionally with the size of the system.
  This paper introduces a novel phase-alignment-based framework to minimize the
type of controllers by strategically clustering agents with aligned
synchronization behaviors. Leveraging the intrinsic phase properties of complex
matrices, we formulate a constrained clustering problem and propose a
hierarchical optimization method combining recursive exact searches for
small-scale systems and scalable stochastic approximations for large-scale
networks. This work bridges theoretical phase analysis with practical control
synthesis, offering a cost-effective solution for large-scale multi-agent
systems. The theoretical results applied for the analysis of a 50-agent network
illustrate the effectiveness of the proposed algorithms.

</details>


### [172] [Robust Probability Hypothesis Density Filtering: Theory and Algorithms](https://arxiv.org/abs/2507.13687)
*Ming Lei,Shufan Wu*

Main category: eess.SY

TL;DR: 本研究提出了一种创新的极小极大鲁棒PHD滤波框架，旨在解决多目标跟踪（MTT）在模型不确定性、杂波干扰和目标交互下的鲁棒性和效率挑战，并在高杂波环境中显著降低了跟踪误差并保持了实时性。


<details>
  <summary>Details</summary>
Motivation: 传统的多目标跟踪方法（如GM-PHD和CPHD滤波器）存在固有限制，包括组合爆炸、对目标生灭过程参数敏感以及数值不稳定等问题，难以有效应对模型不确定性、杂波干扰和目标交互。

Method: 该研究提出了一个创新的极小极大鲁棒PHD滤波框架，包括：1) 理论推导的鲁棒GM-PHD递归算法，实现有界不确定性下的最优最坏情况误差控制；2) 自适应实时参数调整机制，确保稳定性和误差界限；3) 广义重尾测量似然函数，保持多项式计算复杂度；4) 针对扩展目标的新型基于划分的置信度加权方法。研究还建立了严格的收敛性保证，证明了PHD解的唯一性，并验证了算法与标准GM-PHD的等效性。

Result: 实验结果表明，在高杂波环境中，该方法相比现有技术，OSPA误差降低了32.4%，基数RMSE降低了25.3%，同时保持了每步15.3毫秒的实时处理能力。

Conclusion: 这项突破为安全关键应用中可靠的多目标跟踪奠定了关键基础。

Abstract: Multi-target tracking (MTT) serves as a cornerstone technology in information
fusion, yet faces significant challenges in robustness and efficiency when
dealing with model uncertainties, clutter interference, and target
interactions. Conventional approaches like Gaussian Mixture PHD (GM-PHD) and
Cardinalized PHD (CPHD) filters suffer from inherent limitations including
combinatorial explosion, sensitivity to birth/death process parameters, and
numerical instability. This study proposes an innovative minimax robust PHD
filtering framework with four key contributions: (1) A theoretically derived
robust GM-PHD recursion algorithm that achieves optimal worst-case error
control under bounded uncertainties; (2) An adaptive real-time parameter
adjustment mechanism ensuring stability and error bounds; (3) A generalized
heavy-tailed measurement likelihood function maintaining polynomial
computational complexity; (4) A novel partition-based credibility weighting
method for extended targets. The research not only establishes rigorous
convergence guarantees and proves the uniqueness of PHD solutions, but also
verifies algorithmic equivalence with standard GM-PHD. Experimental results
demonstrate that in high-clutter environments, this method achieves a
remarkable 32.4% reduction in OSPA error and 25.3% lower cardinality RMSE
compared to existing techniques, while maintaining real-time processing
capability at 15.3 milliseconds per step. This breakthrough lays a crucial
foundation for reliable MTT in safety-critical applications.

</details>


### [173] [Safe and Performant Controller Synthesis using Gradient-based Model Predictive Control and Control Barrier Functions](https://arxiv.org/abs/2507.13872)
*Aditya Singh,Aastha Mishra,Manan Tayal,Shishir Kolathaya,Pushpak Jagtap*

Main category: eess.SY

TL;DR: 本文提出一个两阶段框架，结合基于梯度的模型预测控制（MPC）和基于控制屏障函数（CBF）的安全滤波，以协同优化自主系统的性能和安全性。


<details>
  <summary>Details</summary>
Motivation: 在实际环境中运行的自主系统需要兼顾性能和安全性。现有方法存在局限：控制屏障函数（CBF）可能过于保守，而状态约束最优控制问题（SC-OCP）在高维系统中难以处理。

Method: 该方法包含两个阶段：第一阶段，将安全约束松弛为成本函数中的惩罚项，通过基于梯度的MPC进行快速优化，提高可扩展性并避免硬约束的可行性问题；第二阶段，使用基于CBF的二次规划（CBF-QP）修改第一阶段得到的控制器，强制执行硬安全约束，同时最小化与参考控制器的偏差。

Result: 该方法得到的控制器既具有高性能，又可证明是安全的。通过两个案例研究验证了该框架，表明其能够为复杂、高维的自主系统合成可扩展、安全且高性能的控制器。

Conclusion: 所提出的两阶段框架成功地将基于梯度的MPC与基于CBF的安全滤波相结合，有效解决了自主系统在性能和安全性方面的挑战，实现了可扩展、安全且高性能的控制。

Abstract: Ensuring both performance and safety is critical for autonomous systems
operating in real-world environments. While safety filters such as Control
Barrier Functions (CBFs) enforce constraints by modifying nominal controllers
in real time, they can become overly conservative when the nominal policy lacks
safety awareness. Conversely, solving State-Constrained Optimal Control
Problems (SC-OCPs) via dynamic programming offers formal guarantees but is
intractable in high-dimensional systems. In this work, we propose a novel
two-stage framework that combines gradient-based Model Predictive Control (MPC)
with CBF-based safety filtering for co-optimizing safety and performance. In
the first stage, we relax safety constraints as penalties in the cost function,
enabling fast optimization via gradient-based methods. This step improves
scalability and avoids feasibility issues associated with hard constraints. In
the second stage, we modify the resulting controller using a CBF-based
Quadratic Program (CBF-QP), which enforces hard safety constraints with minimal
deviation from the reference. Our approach yields controllers that are both
performant and provably safe. We validate the proposed framework on two case
studies, showcasing its ability to synthesize scalable, safe, and
high-performance controllers for complex, high-dimensional autonomous systems.

</details>


### [174] [Fixed time convergence guarantees for Higher Order Control Barrier Functions](https://arxiv.org/abs/2507.13888)
*Janani S K,Shishir Kolathaya*

Main category: eess.SY

TL;DR: 本文提出一种新颖的高阶控制障碍函数（HOCBFs）设计方法，以确保在用户指定有限时间内收敛到安全集。


<details>
  <summary>Details</summary>
Motivation: 传统高阶控制障碍函数只能保证渐近安全，但在时间敏感和安全关键型应用（如自主导航）中，固定时间收敛至关重要。

Method: 通过在特征多项式中使用重复根施加结构化微分约束，从而得到在规定时间精确收敛的闭式多项式解。文中推导了确保前向不变性和固定时间可达性的障碍函数及其导数条件，并提供了二阶系统的明确公式。

Result: 该方法在点质量模型、独轮车和自行车模型三个机器人系统上进行了评估，并与现有HOCBF方法进行了基准测试。结果表明，即使传统方法失败，本文提出的方法也能可靠地在期望时间内强制收敛。

Conclusion: 这项工作为具有可证明的有限时间安全保证的实时控制提供了一个可行且鲁棒的框架。

Abstract: We present a novel method for designing higher-order Control Barrier
Functions (CBFs) that guarantee convergence to a safe set within a
user-specified finite. Traditional Higher Order CBFs (HOCBFs) ensure asymptotic
safety but lack mechanisms for fixed-time convergence, which is critical in
time-sensitive and safety-critical applications such as autonomous navigation.
In contrast, our approach imposes a structured differential constraint using
repeated roots in the characteristic polynomial, enabling closed-form
polynomial solutions with exact convergence at a prescribed time. We derive
conditions on the barrier function and its derivatives that ensure forward
invariance and fixed-time reachability, and we provide an explicit formulation
for second-order systems. Our method is evaluated on three robotic systems - a
point-mass model, a unicycle, and a bicycle model and benchmarked against
existing HOCBF approaches. Results demonstrate that our formulation reliably
enforces convergence within the desired time, even when traditional methods
fail. This work provides a tractable and robust framework for real-time control
with provable finite-time safety guarantees.

</details>


### [175] [A Robust Periodic Controller for Spacecraft Attitude Tracking](https://arxiv.org/abs/2507.13908)
*Frederik Thiele,Felix Biertümpfel,Harald Pfifer*

Main category: eess.SY

TL;DR: 本文提出了一种新颖的鲁棒周期性卫星姿态控制方法，通过考虑系统周期性，实现了轨道上恒定的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了在卫星动力学中尊重其周期性，从而在整个轨道上实现恒定的性能和鲁棒性要求。

Method: 采用混合敏感度控制设计，结合物理驱动的加权方案。控制器通过一种新颖的结构化线性时变输出反馈综合方法计算，该方法是一个凸优化问题，避免了传统周期性H-infinity综合中固有的网格化耦合条件评估。

Result: 该方法保证了最优的L2性能，控制器结构透明且易于实现。在一个太阳能电站卫星上验证了所提方法的有效性。

Conclusion: 所提出的周期性卫星姿态控制方法能够有效实现鲁棒控制，并具有最优性能和易于实现的控制器结构。

Abstract: This paper presents a novel approach for robust periodic attitude control of
satellites. Respecting the periodicity of the satellite dynamics in the
synthesis allows to achieve constant performance and robustness requirements
over the orbit. The proposed design follows a mixed sensitivity control design
employing a physically motivated weighting scheme. The controller is calculated
using a novel structured linear time-periodic output feedback synthesis with
guaranteed optimal L2-performance. The synthesis poses a convex optimization
problem and avoids grid-wise evaluations of coupling conditions inherent for
classical periodic H-infinity-synthesis. Moreover, the controller has a
transparent and easy to implement structure. A solar power plant satellite is
used to demonstrate the effectiveness of the proposed method for periodic
satellite attitude control.

</details>


### [176] [Identifiability Analysis of a Pseudo-Two-Dimensional Model & Single Particle Model-Aided Parameter Estimation](https://arxiv.org/abs/2507.13931)
*L. D. Couto,K. Haghverdi,F. Guo,K. Trad,G. Mulder*

Main category: eess.SY

TL;DR: 本文提出了一种参数识别方法，旨在快速准确地估计伪二维（P2D）电池模型的参数，通过结合低阶模型加速初步估计，并用P2D模型进行精确识别。


<details>
  <summary>Details</summary>
Motivation: 需要一种准确且快速的方法来估计伪二维（P2D）电池模型的模型参数。

Method: ['检查用于识别的数据，并将需要捕获的特定特征包含在模型中。', '分析P2D模型以评估物理参数的可识别性，并提出替代参数化方案以缓解可能的问题。', '考虑不同的操作条件，这些条件能够激发不同的电池动态，从而相应地使用不同的低阶电池模型。']

Result: ['在低电流条件下，使用低阶模型进行参数估计的速度比使用P2D模型快至少500倍，但误差会增加一倍。', '如果精度是必需的，这些估计的参数可以用于初始化P2D模型，并将识别时间缩短一半。']

Conclusion: 该方法通过结合低阶模型和P2D模型，可以在保证速度的同时，提高P2D电池模型参数识别的准确性，尤其是在需要高精度时，可利用低阶模型的估计结果初始化P2D模型以加速识别过程。

Abstract: This contribution presents a parameter identification methodology for the
accurate and fast estimation of model parameters in a pseudo-two-dimensional
(P2D) battery model. The methodology consists of three key elements. First, the
data for identification is inspected and specific features herein that need to
be captured are included in the model. Second, the P2D model is analyzed to
assess the identifiability of the physical model parameters and propose
alternative parameterizations that alleviate possible issues. Finally, diverse
operating conditions are considered that excite distinct battery dynamics which
allows the use of different low-order battery models accordingly. Results show
that, under low current conditions, the use of low-order models achieve
parameter estimates at least 500 times faster than using the P2D model at the
expense of twice the error. However, if accuracy is a must, these estimated
parameters can be used to initialize the P2D model and perform the
identification in half of the time.

</details>


### [177] [Diffraction and Scattering Modeling for Laser Power Beaming in Lunar Environment](https://arxiv.org/abs/2507.13982)
*Yanni Jiwan-Mercier,Barış Dönmez,Güneş Karabulut-Kurt,Sébastien Loranger*

Main category: eess.SY

TL;DR: 研究表明月球尘埃显著降低了光学功率束传输效率，通过提高激光源高度可有效缓解。


<details>
  <summary>Details</summary>
Motivation: 月球长期任务，特别是在太阳光照有限区域，需要可靠的能源传输。光学功率束（OPB）是一种有前景的替代方案，但月球尘埃对光束传播的影响尚不明确。

Method: 引入了一个详细的仿真模型，该模型结合了静电悬浮月球风化层引起的衍射和高度依赖散射。与之前假设均匀尘埃层或中心到中心传输损耗的方法不同，本模型使用广义衍射理论和基于粒子密度导出的折射率梯度来评估光束变形和衰减。

Result: 在无尘埃与有尘埃（175纳米颗粒）条件下，50公里距离内的能量传输效率从57%降至3.7%。当粒子尺寸增加到250纳米时，有效传输范围限制在30公里以下，效率为6%。将激光源高度提高至离地12米，在5公里距离内效率可达91%，50公里距离内可达25%。

Conclusion: 研究强调了系统高度和尘埃建模在月球OPB设计中的重要性，并揭示了粒子尺寸分布对任务的关键作用，尤其是在人类活动干扰的环境中。

Abstract: Reliable energy delivery is a critical requirement for
  long-term lunar missions, particularly in regions with limited
  solar access, such as polar craters and during extended lunar
  nights. Optical Power Beaming (OPB) using high-power lasers
  offers a promising alternative to conventional solar power, but
  the effects of suspended lunar dust on beam propagation remain
  poorly understood. This study introduces a detailed simulation
  model that incorporates both diffraction and height-dependent
  scattering by the electrostatically suspended lunar regolith. Un like prior
approaches, which assumed uniform dust layers or
  center-to-center transmission loss, our model uses generalized
  diffraction theory and refractive index gradients derived from
  particle density to assess beam deformation and attenuation. The
  results show that even in ground-to-ground scenarios, lunar dust
  significantly degrades energy transfer efficiency, dropping from
  57% to 3.7% over 50 km in dust-free vs. dusty conditions with
  175 nm particles. Increasing the particle size to 250 nm limits the
  viable transmission range to below 30 km at 6% efficiency. The
  study further demonstrates that raising the laser source height
  can improve efficiency, achieving 91% for a distance of 5 km
  and 25% at 50 km when the source is positioned 12 m above
  ground. These findings underscore the importance of system
  elevation and dust modeling in lunar OPB design and reveal
  the mission-critical role of particle size distribution, especially in
  environments disturbed by human activity.

</details>


### [178] [Smart fault detection in satellite electrical power system](https://arxiv.org/abs/2507.14004)
*Niloofar Nobahari,Alireza Rezaee*

Main category: eess.SY

TL;DR: 本文提出了一种基于多层感知器（MLP）神经网络的新方法，用于检测低地球轨道（LEO）卫星（无姿态确定与控制子系统）整个电力系统中的故障。


<details>
  <summary>Details</summary>
Motivation: 卫星电力系统组件（如光伏子系统、DC-DC转换器、电池）易发生故障（如线对线故障、开路、短路、接地故障）。以往研究主要集中于检测单个组件的故障，对整个电力系统作为一个整体的故障检测关注不足。

Method: 利用多层感知器（MLP）神经网络模型，输入数据包括太阳辐射和表面温度，以预测电流和负载输出。结合主成分分析（PCA）和K-近邻（KNN）等机器学习技术进行故障分类。

Result: 该模型在识别多个子系统故障方面取得了超过99%的准确率，为整个卫星电力系统提供了完整的诊断解决方案。

Conclusion: 该方法显著提升了系统可靠性，并有助于降低任务失败的风险，代表了卫星电力系统故障诊断的显著进步。

Abstract: This paper presents an new approach for detecting in the electrical power
system of satellites operating in Low Earth Orbit (LEO) without an Attitude
Determination and Control Subsystem (ADCS). Components of these systems are
prone to faults, such as line-to-line faults in the photovoltaic subsystem,
open circuits, and short circuits in the DC-to-DC converter, as well as ground
faults in batteries. In the previous research has largely focused on detecting
faults in each components, such as photovoltaic arrays or converter systems,
therefore, has been limited attention given to whole electrical power system of
satellite as a whole system. Our approach addresses this gap by utilizing a
Multi-Layer Perceptron (MLP) neural network model, which leverages input data
such as solar radiation and surface temperature to predict current and load
outputs. These machine learning techniques that classifiy use different
approaches like Principal Component Analysis (PCA) and K-Nearest Neighbors
(KNN), to classify faults effectively. The model presented achieves over 99%
accuracy in identifying faults across multiple subsystems, marking a notable
advancement from previous approaches by offering a complete diagnostic solution
for the entire satellite power system. This thorough method boosts system
reliability and helps lower the chances of mission failure

</details>


### [179] [Influence of Cell Position on the Capacity of Retired Batteries: Experimental and Statistical Studies](https://arxiv.org/abs/2507.14020)
*Marwan Hassini,Colette Mintsa-Eya,Eduardo Redondo-Iglesias,Pascal Venet*

Main category: eess.SY

TL;DR: 该研究评估了电动汽车退役电池的性能，发现其仍保持高容量但存在显著差异，并强调了二次利用中热管理和均衡系统的必要性。


<details>
  <summary>Details</summary>
Motivation: 了解汽车退役电池的性能对于确定其再利用潜力至关重要。

Method: 测试了从电动汽车中提取的三个电池模块，对其性能进行了评估，并使用方差分析（ANOVA）对结果进行了统计分析。

Result: 36个退役电池表现出高水平的性能，平均健康状态容量为95%，但存在2.4%的显著离散度。ANOVA分析表明电池性能与其在模块内的位置无关。

Conclusion: 结果表明有必要评估退役电池内部的离散度，并为二次利用电池开发热管理和均衡系统。

Abstract: Understanding how batteries perform after automotive use is crucial to
determining their potential for reuse. This article presents experimental
results aimed at advancing knowledge of retired battery performance. Three
modules extracted from electric vehicles were tested. Their performance was
assessed, and the results were analyzed statistically using analysis of
variance (ANOVA). The 36 retired cells exhibited a high level of performance,
albeit with significant variation. On average, the cells had a 95% state of
health capacity with a dispersion of 2.4%. ANOVA analysis suggests that cell
performance is not correlated with their position inside the module. These
results demonstrate the need to evaluate dispersion within retired batteries
and to develop thermal management and balancing systems for second-life
batteries.

</details>


### [180] [Reference-Free Iterative Learning Model Predictive Control with Neural Certificates](https://arxiv.org/abs/2507.14025)
*Wataru Hashimoto,Kazumune Hashimoto,Masako Kishida,Shigemasa Takai*

Main category: eess.SY

TL;DR: 该论文提出了一种新型无参考迭代学习模型预测控制（MPC）方法，通过从历史数据学习控制Lyapunov障碍函数（CLBF）来定义MPC的终端集合和成本，并将其表述为非线性规划以提高计算效率，同时确保稳定性并逐步提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有迭代学习MPC方法依赖于混合整数规划，导致数值困难和在线计算效率低下。

Method: 提出一种无参考迭代学习MPC。该方法利用历史控制执行数据学习基于控制Lyapunov障碍函数（CLBF）的证书函数，并用其定义当前迭代MPC优化问题中的终端集合和成本。MPC优化问题被表述为标准的非线性规划（NLP）。

Result: 该方法实现了MPC终端组件的逐次迭代改进。它能够更高效地进行在线计算，并满足递归可行性和渐近稳定性等关键MPC特性。在特定假设下，性能成本随迭代次数非递增。PyBullet仿真实验证实了控制性能的迭代增强和在线计算效率的显著提升。

Conclusion: 所提出的控制方案通过迭代学习和改进MPC的终端组件，并采用高效的非线性规划表述，显著提升了控制性能和在线计算效率，克服了现有方法的局限性。

Abstract: In this paper, we propose a novel reference-free iterative learning model
predictive control (MPC). In the proposed method, a certificate function based
on the concept of Control Lyapunov Barrier Function (CLBF) is learned using
data collected from past control executions and used to define the terminal set
and cost in the MPC optimization problem at the current iteration. This scheme
enables the progressive refinement of the MPC's terminal components over
successive iterations. Unlike existing methods that rely on mixed-integer
programming and suffer from numerical difficulties, the proposed approach
formulates the MPC optimization problem as a standard nonlinear program,
enabling more efficient online computation. The proposed method satisfies key
MPC properties, including recursive feasibility and asymptotic stability.
Additionally, we demonstrate that the performance cost is non-increasing with
respect to the number of iterations, under certain assumptions. Numerical
experiments including the simulation with PyBullet confirm that our control
scheme iteratively enhances control performance and significantly improves
online computational efficiency compared to the existing methods.

</details>


### [181] [Physics-guided gated recurrent units for inversion-based feedforward control](https://arxiv.org/abs/2507.14052)
*Mingdao Lin,Max Bolderman,Mircea Lazar*

Main category: eess.SY

TL;DR: 本文提出了一种基于物理引导门控循环单元（PG-GRU）的前馈控制器设计方法，通过结合物理模型和残差学习，显著提升了控制精度。


<details>
  <summary>Details</summary>
Motivation: 传统的基于倒置的前馈控制依赖精确模型，而门控循环单元（GRU）虽能从数据中学习，但存在黑箱性、可解释性差和易过拟合等问题。物理引导神经网络（PGNN）能结合物理先验知识，改善训练收敛并促进物理模型学习，因此有动机将GRU与PGNN结合以解决上述挑战。

Method: 研究者将GRU集成到PGNN框架中，形成PG-GRU。采用两步法设计前馈控制器：首先，利用稳定倒置技术设计一个稳定的逆动力学线性模型；然后，训练一个GRU来识别系统残差逆动力学。最后，在双质量弹簧阻尼系统上进行真实实验验证。

Result: 在双质量弹簧阻尼系统上进行的实际实验表明，所提出的PG-GRU前馈控制器在积分绝对误差方面，比线性前馈控制器和基于预览的GRU前馈控制器表现出大约两倍的性能提升。

Conclusion: 通过将GRU与物理引导神经网络框架结合，并采用两步法进行逆系统识别，PG-GRU前馈控制器在实际系统中展现出显著的性能优势，有效解决了传统GRU在控制应用中的局限性。

Abstract: Inversion-based feedforward control relies on an accurate model that
describes the inverse system dynamics. The gated recurrent unit (GRU), which is
a recent architecture in recurrent neural networks, is a strong candidate for
obtaining such a model from data. However, due to their black-box nature, GRUs
face challenges such as limited interpretability and vulnerability to
overfitting. Recently, physics-guided neural networks (PGNNs) have been
introduced, which integrate the prior physical model structure into the
prediction process. This approach not only improves training convergence, but
also facilitates the learning of a physics-based model. In this work, we
integrate a GRU in the PGNN framework to obtain a PG-GRU, based on which we
adopt a two-step approach to feedforward control design. First, we adopt stable
inversion techniques to design a stable linear model of the inverse dynamics.
Then, a GRU trained on the residual is tailored to inverse system
identification. The resulting PG-GRU feedforward controller is validated by
means of real-life experiments on a two-mass spring-damper system, where it
demonstrates roughly a two-fold improvement compared to the linear feedforward
and a preview-based GRU feedforward in terms of the integral absolute error.

</details>


### [182] [Convex computation of regions of attraction from data using Sums-of-Squares programming](https://arxiv.org/abs/2507.14073)
*Oumayma Khattabi,Matteo Tacchi-Bénard,Sorin Olaru*

Main category: eess.SY

TL;DR: 本文提出一种基于数据驱动的矩-平方和（SoS）层次方法，用于分析未知自治动力系统的吸引域（ROA），无需系统模型结构信息。


<details>
  <summary>Details</summary>
Motivation: 研究未知自治动力系统的吸引域分析，旨在开发一种数据驱动的方法，以克服传统方法对系统模型及其多项式结构的依赖。

Method: 采用基于矩-平方和（SoS）层次的数据驱动方法，实现对吸引域的外部近似，并避免了对系统模型及其多项式结构的显式要求。

Result: 该方法能够在信息受限的情况下实现新颖的吸引域外部近似。数值实验表明数据对学习到的近似集合有显著影响，展示了该方法的潜力。

Conclusion: 该方法在处理未知动力系统吸引域分析方面具有广阔前景，尤其在于其能够绕过系统模型及其多项式结构限制的能力。

Abstract: The paper concentrates on the analysis of the region of attraction (ROA) for
unknown autonomous dynamical systems. The aim is to explore a data-driven
approach based on moment-sum-of-squares (SoS) hierarchy, which enables novel
RoA outer approximations despite the reduced information on the structure of
the dynamics. The main contribution of this work is bypassing the system model
and, consequently, the recurring constraint on its polynomial structure.
Numerical experimentation showcases the influence of data on learned
approximating sets, offering a promising outlook on the potential of this
method.

</details>


### [183] [Integrating Forecasting Models Within Steady-State Analysis and Optimization](https://arxiv.org/abs/2507.14117)
*Aayushya Agarwal,Larry Pileggi*

Main category: eess.SY

TL;DR: 该研究提出一种通用方法，将机器学习预测引擎无缝嵌入到基于物理的电力流和电网优化工具中，以提高在不确定性下电网调度的鲁棒性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 极端天气变化和负载行为的不可预测性使得确定对不确定性具有鲁棒性的电网调度变得困难。尽管机器学习方法提高了对负载和可再生能源引起的不确定性建模能力，但如何将这些预测及其敏感性准确地整合到稳态分析和决策策略中仍然是一个开放的挑战。

Method: 该方法通过将基于物理的电网建模与黑盒机器学习方法相结合，将训练好的机器学习预测模型的输入和输出直接整合到电力流和电网优化的数值方法中。它通过反向传播从数据中直接获取敏感性，无需拟合替代负载模型，并结合了预测设备（通过ML获得）和物理定义电网设备的敏感性。

Result: 该方法改进了敏感性计算，并利用这些改进设计了在随机天气事件下提高电网可靠性的鲁棒电力调度。它能够计算系统对外生因素的敏感性。

Conclusion: 该方法支持更广泛的分析，以在负载变异性和极端天气条件下提高电网可靠性，通过将机器学习预测及其敏感性准确地整合到电网运行中。

Abstract: Extreme weather variations and the increasing unpredictability of load
behavior make it difficult to determine power grid dispatches that are robust
to uncertainties. While machine learning (ML) methods have improved the ability
to model uncertainty caused by loads and renewables, accurately integrating
these forecasts and their sensitivities into steady-state analyses and
decision-making strategies remains an open challenge. Toward this goal, we
present a generalized methodology that seamlessly embeds ML-based forecasting
engines within physics-based power flow and grid optimization tools. By
coupling physics-based grid modeling with black-box ML methods, we accurately
capture the behavior and sensitivity of loads and weather events by directly
integrating the inputs and outputs of trained ML forecasting models into the
numerical methods of power flow and grid optimization. Without fitting
surrogate load models, our approach obtains the sensitivities directly from
data to accurately predict the response of forecasted devices to changes in the
grid. Our approach combines the sensitivities of forecasted devices attained
via backpropagation and the sensitivities of physics-defined grid devices. We
demonstrate the efficacy of our method by showcasing improvements in
sensitivity calculations and leveraging them to design a robust power dispatch
that improves grid reliability under stochastic weather events. Our approach
enables the computation of system sensitivities to exogenous factors which
supports broader analyses that improve grid reliability in the presence of load
variability and extreme weather conditions.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [184] [Flatten Wisely: How Patch Order Shapes Mamba-Powered Vision for MRI Segmentation](https://arxiv.org/abs/2507.13384)
*Osama Hardan,Omar Elshenhabi,Tamer Khattab,Mohamed Mabrok*

Main category: eess.IV

TL;DR: 本文首次系统研究了Vision Mamba模型中图像块扫描顺序对MRI分割性能的影响，发现扫描顺序是一个关键且被忽视的超参数，简单的空间连续路径表现最佳。


<details>
  <summary>Details</summary>
Motivation: Vision Mamba模型在计算效率和性能上具有潜力，但将2D图像序列化为1D时，图像块的扫描顺序是一个关键但常被忽视的设计选择，尤其是在具有强解剖先验的医学影像中。

Method: 本文提出了Multi-Scan 2D (MS2D)模块，一个无参数的Mamba架构模块，用于探索不同的扫描路径。研究在三个公共数据集（BraTS 2020, ISLES 2022, LGG）上对21种扫描策略进行了大规模基准测试，涵盖超过70,000个切片。通过Friedman检验进行统计分析。

Result: 分析结果显示，扫描顺序是一个统计学上显著的因素（Friedman检验: $\chi^{2}_{20}=43.9, p=0.0016$），性能差异高达27个Dice点。空间连续的路径（如简单的水平和垂直光栅扫描）始终优于不连续的对角线扫描。

Conclusion: 扫描顺序是一个强大且无额外计算成本的超参数。本文为在医学影像中最大化Mamba模型性能提供了基于证据的最佳路径选择建议。

Abstract: Vision Mamba models promise transformer-level performance at linear
computational cost, but their reliance on serializing 2D images into 1D
sequences introduces a critical, yet overlooked, design choice: the patch scan
order. In medical imaging, where modalities like brain MRI contain strong
anatomical priors, this choice is non-trivial. This paper presents the first
systematic study of how scan order impacts MRI segmentation. We introduce
Multi-Scan 2D (MS2D), a parameter-free module for Mamba-based architectures
that facilitates exploring diverse scan paths without additional computational
cost. We conduct a large-scale benchmark of 21 scan strategies on three public
datasets (BraTS 2020, ISLES 2022, LGG), covering over 70,000 slices. Our
analysis shows conclusively that scan order is a statistically significant
factor (Friedman test: $\chi^{2}_{20}=43.9, p=0.0016$), with performance
varying by as much as 27 Dice points. Spatially contiguous paths -- simple
horizontal and vertical rasters -- consistently outperform disjointed diagonal
scans. We conclude that scan order is a powerful, cost-free hyperparameter, and
provide an evidence-based shortlist of optimal paths to maximize the
performance of Mamba models in medical imaging.

</details>


### [185] [Enhanced DeepLab Based Nerve Segmentation with Optimized Tuning](https://arxiv.org/abs/2507.13394)
*Akhil John Thomas,Christiaan Boerkamp*

Main category: eess.IV

TL;DR: 本研究提出了一种优化的基于DeepLabV3的神经分割流程，通过自动化阈值微调显著提高了超声神经图像的分割精度。


<details>
  <summary>Details</summary>
Motivation: 神经分割在医学成像中对于精确识别神经结构至关重要。

Method: 本研究采用了一种优化的DeepLabV3分割流程，结合了自动化阈值微调，并对预处理步骤和参数进行了优化。

Result: 在超声神经成像上，该方法取得了0.78的Dice分数、0.70的IoU和0.95的像素精度，显示出比基线模型显著的改进。

Conclusion: 研究结果证明了该方法的显著改进，并强调了在自动化神经检测中定制参数选择的重要性。

Abstract: Nerve segmentation is crucial in medical imaging for precise identification
of nerve structures. This study presents an optimized DeepLabV3-based
segmentation pipeline that incorporates automated threshold fine-tuning to
improve segmentation accuracy. By refining preprocessing steps and implementing
parameter optimization, we achieved a Dice Score of 0.78, an IoU of 0.70, and a
Pixel Accuracy of 0.95 on ultrasound nerve imaging. The results demonstrate
significant improvements over baseline models and highlight the importance of
tailored parameter selection in automated nerve detection.

</details>


### [186] [Domain-randomized deep learning for neuroimage analysis](https://arxiv.org/abs/2507.13458)
*Malte Hoffmann*

Main category: eess.IV

TL;DR: 本文综述了一种基于合成图像的域随机化训练范式，旨在解决深度学习模型在神经影像分析中泛化能力差的问题，尤其是在MRI等模态中，以提高模型鲁棒性和可访问性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在神经影像分析中表现出色，但训练数据集范围狭窄限制了模型的鲁棒性和泛化能力。特别是在MRI中，图像外观因序列和硬件差异大，导致模型难以泛化到未见过的数据类型。

Method: 采用域随机化策略，通过基于解剖分割图生成具有随机强度和解剖内容的合成图像来训练深度神经网络。本文作为一篇教程，回顾了这种合成驱动训练范式的原理、实现和潜力。

Result: 该方法使模型能够准确处理训练期间未见过的图像类型，无需重新训练或微调。已在MRI、CT、PET、OCT等多种医学影像模态以及超声、电子显微镜等非神经影像领域中验证其有效性，显著提升了泛化能力并增强了抗过拟合性。

Conclusion: 合成驱动的训练范式能够加速通用工具的开发，使深度学习更易于没有大量计算资源或机器学习知识的领域专家使用。文章探讨了采用该技术的实际考量，并讨论了计算需求增加等权衡。

Abstract: Deep learning has revolutionized neuroimage analysis by delivering
unprecedented speed and accuracy. However, the narrow scope of many training
datasets constrains model robustness and generalizability. This challenge is
particularly acute in magnetic resonance imaging (MRI), where image appearance
varies widely across pulse sequences and scanner hardware. A recent
domain-randomization strategy addresses the generalization problem by training
deep neural networks on synthetic images with randomized intensities and
anatomical content. By generating diverse data from anatomical segmentation
maps, the approach enables models to accurately process image types unseen
during training, without retraining or fine-tuning. It has demonstrated
effectiveness across modalities including MRI, computed tomography, positron
emission tomography, and optical coherence tomography, as well as beyond
neuroimaging in ultrasound, electron and fluorescence microscopy, and X-ray
microtomography. This tutorial paper reviews the principles, implementation,
and potential of the synthesis-driven training paradigm. It highlights key
benefits, such as improved generalization and resistance to overfitting, while
discussing trade-offs such as increased computational demands. Finally, the
article explores practical considerations for adopting the technique, aiming to
accelerate the development of generalizable tools that make deep learning more
accessible to domain experts without extensive computational resources or
machine learning knowledge.

</details>


### [187] [BreastSegNet: Multi-label Segmentation of Breast MRI](https://arxiv.org/abs/2507.13604)
*Qihang Li,Jichen Yang,Yaqian Chen,Yuwen Chen,Hanxue Gu,Lars J. Grimm,Maciej A. Mazurowski*

Main category: eess.IV

TL;DR: 本研究提出了BreastSegNet，一种针对乳腺MRI的多标签分割算法，涵盖9种解剖结构，并对多个分割模型进行了基准测试，其中nnU-Net ResEncM表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有的乳腺MRI分割方法范围有限，通常只关注少数组织结构（如纤维腺体组织或肿瘤），未能覆盖扫描中可见的全部组织，从而限制了其在定量分析中的效用。

Method: 开发了BreastSegNet多标签分割算法，涵盖纤维腺体组织、血管、肌肉、骨骼、病变、淋巴结、心脏、肝脏和植入物共九种解剖标签。手动标注了1123张MRI切片，并由专家放射科医生进行详细审查和校正。同时，对包括U-Net、SwinUNet、UNet++、SAM、MedSAM和带有多个ResNet编码器的nnU-Net在内的九种分割模型进行了基准测试。

Result: 在所有标签中，nnU-Net ResEncM实现了最高的平均Dice分数0.694。它在心脏、肝脏、肌肉、纤维腺体组织和骨骼上的表现尤为出色，Dice分数超过0.73，心脏和肝脏接近0.90。

Conclusion: BreastSegNet为乳腺MRI提供了全面的多标签分割解决方案，nnU-Net ResEncM展现出最佳性能，有望增强乳腺MRI的定量分析能力。

Abstract: Breast MRI provides high-resolution imaging critical for breast cancer
screening and preoperative staging. However, existing segmentation methods for
breast MRI remain limited in scope, often focusing on only a few anatomical
structures, such as fibroglandular tissue or tumors, and do not cover the full
range of tissues seen in scans. This narrows their utility for quantitative
analysis. In this study, we present BreastSegNet, a multi-label segmentation
algorithm for breast MRI that covers nine anatomical labels: fibroglandular
tissue (FGT), vessel, muscle, bone, lesion, lymph node, heart, liver, and
implant. We manually annotated a large set of 1123 MRI slices capturing these
structures with detailed review and correction from an expert radiologist.
Additionally, we benchmark nine segmentation models, including U-Net, SwinUNet,
UNet++, SAM, MedSAM, and nnU-Net with multiple ResNet-based encoders. Among
them, nnU-Net ResEncM achieves the highest average Dice scores of 0.694 across
all labels. It performs especially well on heart, liver, muscle, FGT, and bone,
with Dice scores exceeding 0.73, and approaching 0.90 for heart and liver. All
model code and weights are publicly available, and we plan to release the data
at a later date.

</details>


### [188] [Converting T1-weighted MRI from 3T to 7T quality using deep learning](https://arxiv.org/abs/2507.13782)
*Malo Gicquel,Ruoyi Zhao,Anika Wuestefeld,Nicola Spotorno,Olof Strandberg,Kalle Åström,Yu Xiao,Laura EM Wisse,Danielle van Westen,Rik Ossenkoppele,Niklas Mattsson-Carlgren,David Berron,Oskar Hansson,Gabrielle Flood,Jacob Vogel*

Main category: eess.IV

TL;DR: 该研究提出了一种深度学习模型，能将3T脑部MRI图像合成为接近7T质量的图像，从而在不牺牲下游任务性能的情况下提升图像质量和分割精度。


<details>
  <summary>Details</summary>
Motivation: 7T MRI虽然提供更高的信噪比、分辨率和组织对比度，但其可及性远低于3T MRI。研究旨在通过技术手段，在3T MRI的普及性基础上，获得接近7T MRI的详细解剖视图和图像质量。

Method: 研究使用了来自瑞典BioFINDER-2研究的172名参与者的配对7T和3T T1加权脑部MRI图像。训练了两种深度学习模型来合成7T MRI：一个专门的U-Net模型和一个集成生成对抗网络（GAN）的U-Net模型（GAN U-Net）。通过图像度量指标、四位盲审MRI专业人士的主观评估、自动分割结果与手动分割的相似性比较，以及在认知状态预测下游任务中的表现来评估模型。

Result: 研究开发的模型在图像评估指标上优于其他两种先进的3T到7T合成模型。盲审MRI专业人士认为合成的7T图像在细节上可与真实7T图像媲美，且在主观视觉质量上更优（可能由于伪影减少）。重要的是，合成的GAN U-Net 7T图像的杏仁核自动分割结果比原始3T图像的分割结果更接近手动分割。此外，合成的7T图像在认知状态预测的下游任务中表现与真实3T图像相似。

Conclusion: 该研究表明，可以从3T图像生成接近7T质量的合成T1加权脑部图像。这种方法能够提高图像质量和分割精度，同时不影响下游任务的性能，为未来的临床应用提供了可能性。

Abstract: Ultra-high resolution 7 tesla (7T) magnetic resonance imaging (MRI) provides
detailed anatomical views, offering better signal-to-noise ratio, resolution
and tissue contrast than 3T MRI, though at the cost of accessibility. We
present an advanced deep learning model for synthesizing 7T brain MRI from 3T
brain MRI. Paired 7T and 3T T1-weighted images were acquired from 172
participants (124 cognitively unimpaired, 48 impaired) from the Swedish
BioFINDER-2 study. To synthesize 7T MRI from 3T images, we trained two models:
a specialized U-Net, and a U-Net integrated with a generative adversarial
network (GAN U-Net). Our models outperformed two additional state-of-the-art
3T-to-7T models in image-based evaluation metrics. Four blinded MRI
professionals judged our synthetic 7T images as comparable in detail to real 7T
images, and superior in subjective visual quality to 7T images, apparently due
to the reduction of artifacts. Importantly, automated segmentations of the
amygdalae of synthetic GAN U-Net 7T images were more similar to manually
segmented amygdalae (n=20), than automated segmentations from the 3T images
that were used to synthesize the 7T images. Finally, synthetic 7T images showed
similar performance to real 3T images in downstream prediction of cognitive
status using MRI derivatives (n=3,168). In all, we show that synthetic
T1-weighted brain images approaching 7T quality can be generated from 3T
images, which may improve image quality and segmentation, without compromising
performance in downstream tasks. Future directions, possible clinical use
cases, and limitations are discussed.

</details>


### [189] [Divide and Conquer: A Large-Scale Dataset and Model for Left-Right Breast MRI Segmentation](https://arxiv.org/abs/2507.13830)
*Maximilian Rokuss,Benjamin Hamm,Yannick Kirchhoff,Klaus Maier-Hein*

Main category: eess.IV

TL;DR: 本文介绍了一个包含超过13,000个注释病例的乳腺MRI数据集，并提供了用于左右乳腺分割的深度学习模型，填补了乳腺MRI分析中的关键空白。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了解决乳腺MRI分析中存在的关键空白，即缺乏带有明确左右乳腺分割标签的公开数据集和相应的工具。

Method: 研究方法是构建并发布了一个大型乳腺MRI数据集，该数据集包含明确的左右乳腺分割标签，并基于此数据集训练了一个鲁棒的深度学习模型用于左右乳腺分割。

Result: 研究成果是发布了首个公开可用的乳腺MRI数据集，包含超过13,000个带左右乳腺分割标签的病例，同时提供了一个训练好的鲁棒深度学习模型。

Conclusion: 该工作为乳腺MRI分析提供了宝贵资源，有助于开发女性健康领域的高级工具。

Abstract: We introduce the first publicly available breast MRI dataset with explicit
left and right breast segmentation labels, encompassing more than 13,000
annotated cases. Alongside this dataset, we provide a robust deep-learning
model trained for left-right breast segmentation. This work addresses a
critical gap in breast MRI analysis and offers a valuable resource for the
development of advanced tools in women's health. The dataset and trained model
are publicly available at: www.github.com/MIC-DKFZ/BreastDivider

</details>


### [190] [Software architecture and manual for novel versatile CT image analysis toolbox -- AnatomyArchive](https://arxiv.org/abs/2507.13901)
*Lei Xu,Torkel B Brismar*

Main category: eess.IV

TL;DR: AnatomyArchive是一个基于TotalSegmentator的CT图像分析软件包，提供自动解剖区域选择、精确体成分分析、影像组学特征提取与可视化，并支持机器学习模型开发。


<details>
  <summary>Details</summary>
Motivation: 为了实现更精确的CT图像体成分分析，解决自动目标体积选择与排除、分割掩膜管理、医学图像数据库维护以及影像组学特征提取和统计分析的挑战，并辅助现代机器学习模型的开发。

Method: 该软件包基于TotalSegmentator模型构建，提供根据用户配置的解剖结构进行自动目标体积选择和取消选择。它采用基于知识图谱的高效工具进行解剖分割掩膜管理和医学图像数据库维护。方法包括自动身体体积裁剪、自动手臂检测和排除，以实现精确的体成分分析。此外，还提供鲁棒的体素级影像组学特征提取、特征可视化以及集成的统计测试和分析工具链。软件还包含基于Python的GPU加速的近乎照片级的分割集成复合电影渲染功能。

Result: AnatomyArchive实现了根据用户配置的解剖结构进行自动目标体积选择与取消选择。它能够进行更精确的2D和3D体成分分析，并提供鲁棒的体素级影像组学特征提取和可视化能力，以及集成的统计分析工具。该软件可用于辅助现代机器学习模型的开发。

Conclusion: AnatomyArchive是一个功能全面、高效的CT图像分析软件包，它通过集成先进的分割模型和多种分析工具，显著提升了医学图像分析的自动化和精确性，尤其在体成分分析、影像组学和机器学习模型开发方面具有重要应用潜力。该软件将开源用于研究和教育目的。

Abstract: We have developed a novel CT image analysis package named AnatomyArchive,
built on top of the recent full body segmentation model TotalSegmentator. It
provides automatic target volume selection and deselection capabilities
according to user-configured anatomies for volumetric upper- and lower-bounds.
It has a knowledge graph-based and time efficient tool for anatomy segmentation
mask management and medical image database maintenance. AnatomyArchive enables
automatic body volume cropping, as well as automatic arm-detection and
exclusion, for more precise body composition analysis in both 2D and 3D
formats. It provides robust voxel-based radiomic feature extraction, feature
visualization, and an integrated toolchain for statistical tests and analysis.
A python-based GPU-accelerated nearly photo-realistic segmentation-integrated
composite cinematic rendering is also included. We present here its software
architecture design, illustrate its workflow and working principle of
algorithms as well provide a few examples on how the software can be used to
assist development of modern machine learning models. Open-source codes will be
released at https://github.com/lxu-medai/AnatomyArchive for only research and
educational purposes.

</details>


### [191] [Blind Super Resolution with Reference Images and Implicit Degradation Representation](https://arxiv.org/abs/2507.13915)
*Huu-Phu Do,Po-Chih Hu,Hao-Chien Hsueh,Che-Kai Liu,Vu-Hoang Tran,Ching-Chun Huang*

Main category: eess.IV

TL;DR: 该研究提出一种新的盲超分辨率（BSR）策略，利用高分辨率（HR）参考图像来学习尺度感知降质核，并通过生成额外的LR-HR对来提升超分辨率性能，在多种BSR场景下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 以往的盲超分辨率研究主要关注直接从低分辨率（LR）输入估计降质核，但这些降质核不仅应考虑降质过程，还应考虑下采样因子。在不同超分辨率尺度下应用相同的降质核是不切实际的。

Method: 该研究提出一种新策略，将降质核和缩放因子视为BSR任务的关键要素。它利用高分辨率（HR）图像作为参考，建立尺度感知的降质核。通过使用与内容无关的HR参考图像和目标LR图像，模型能够自适应地识别降质过程，并生成额外的LR-HR图像对（通过下采样HR参考图像），这对于提高SR性能至关重要。该基于参考的训练过程适用于已训练好的盲SR模型和零样本盲SR方法。

Result: 该方法在已训练好的盲SR模型和零样本盲SR方法两种场景下，均持续优于以往的方法。

Conclusion: 结合模糊核和缩放因子的双重考量，以及参考图像的使用，共同提升了该方法在盲超分辨率任务中的有效性。

Abstract: Previous studies in blind super-resolution (BSR) have primarily concentrated
on estimating degradation kernels directly from low-resolution (LR) inputs to
enhance super-resolution. However, these degradation kernels, which model the
transition from a high-resolution (HR) image to its LR version, should account
for not only the degradation process but also the downscaling factor. Applying
the same degradation kernel across varying super-resolution scales may be
impractical. Our research acknowledges degradation kernels and scaling factors
as pivotal elements for the BSR task and introduces a novel strategy that
utilizes HR images as references to establish scale-aware degradation kernels.
By employing content-irrelevant HR reference images alongside the target LR
image, our model adaptively discerns the degradation process. It is then
applied to generate additional LR-HR pairs through down-sampling the HR
reference images, which are keys to improving the SR performance. Our
reference-based training procedure is applicable to proficiently trained blind
SR models and zero-shot blind SR methods, consistently outperforming previous
methods in both scenarios. This dual consideration of blur kernels and scaling
factors, coupled with the use of a reference image, contributes to the
effectiveness of our approach in blind super-resolution tasks.

</details>


### [192] [Leveraging Pathology Foundation Models for Panoptic Segmentation of Melanoma in H&E Images](https://arxiv.org/abs/2507.13974)
*Jiaqi Lv,Yijie Zhu,Carmen Guadalupe Colin Tenorio,Brinder Singh Chohan,Mark Eastwood,Shan E Ahmed Raza*

Main category: eess.IV

TL;DR: 本文提出一种基于深度学习的新方法，结合病理学基础模型（Virchow2）和Efficient-UNet网络，用于黑色素瘤H&E图像的五种组织类型分割，并在PUMA挑战赛中取得第一名。


<details>
  <summary>Details</summary>
Motivation: 黑色素瘤组织形态的准确表征对预后和治疗至关重要。然而，从H&E全切片图像中手动分割组织区域劳动密集且易受观察者间差异影响，因此需要可靠的自动化组织分割方法。

Method: 该研究提出一种新颖的深度学习网络，用于分割黑色素瘤H&E图像中的五种组织类别。该方法利用在310万张组织病理学图像上训练的病理学基础模型Virchow2作为特征提取器，将提取的特征与原始RGB图像融合，然后由编码器-解码器分割网络（Efficient-UNet）进行处理以生成准确的分割图。

Result: 所提出的模型在PUMA Grand Challenge的组织分割任务中获得第一名，展示了其稳健的性能和泛化能力。结果表明将病理学基础模型整合到分割网络中具有加速计算病理学工作流程的潜力与效力。

Conclusion: 将病理学基础模型整合到分割网络中具有巨大的潜力，能够有效提高计算病理学工作流程的效率和准确性，尤其是在黑色素瘤组织分割方面。

Abstract: Melanoma is an aggressive form of skin cancer with rapid progression and high
metastatic potential. Accurate characterisation of tissue morphology in
melanoma is crucial for prognosis and treatment planning. However, manual
segmentation of tissue regions from haematoxylin and eosin (H&E) stained
whole-slide images (WSIs) is labour-intensive and prone to inter-observer
variability, this motivates the need for reliable automated tissue segmentation
methods. In this study, we propose a novel deep learning network for the
segmentation of five tissue classes in melanoma H&E images. Our approach
leverages Virchow2, a pathology foundation model trained on 3.1 million
histopathology images as a feature extractor. These features are fused with the
original RGB images and subsequently processed by an encoder-decoder
segmentation network (Efficient-UNet) to produce accurate segmentation maps.
The proposed model achieved first place in the tissue segmentation task of the
PUMA Grand Challenge, demonstrating robust performance and generalizability.
Our results show the potential and efficacy of incorporating pathology
foundation models into segmentation networks to accelerate computational
pathology workflows.

</details>


### [193] [OrthoInsight: Rib Fracture Diagnosis and Report Generation Based on Multi-Modal Large Models](https://arxiv.org/abs/2507.13993)
*Ningyong Wu,Jinzhi Wang,Wenhong Zhao,Chenzhan Yu,Zhigang Xiu,Duwei Dai*

Main category: eess.IV

TL;DR: OrthoInsight是一个多模态深度学习框架，用于肋骨骨折的诊断和报告生成，通过整合YOLOv9、医学知识图谱和LLaVA模型，实现了高准确性和全面的临床报告。


<details>
  <summary>Details</summary>
Motivation: 医疗影像数据量不断增长，导致人工诊断（如肋骨骨折CT扫描）耗时且易出错，急需自动化诊断工具。

Method: OrthoInsight框架整合了：1) YOLOv9模型用于骨折检测；2) 医学知识图谱用于检索临床上下文；3) 经过微调的LLaVA语言模型用于生成诊断报告。它结合了CT图像的视觉特征和专家文本数据。

Result: 在28,675张带注释的CT图像和专家报告上进行评估，OrthoInsight在诊断准确性、内容完整性、逻辑连贯性和临床指导价值方面表现出色，平均得分4.28，优于GPT-4和Claude-3等模型。

Conclusion: 这项研究展示了多模态学习在转化医学图像分析和为放射科医生提供有效支持方面的巨大潜力。

Abstract: The growing volume of medical imaging data has increased the need for
automated diagnostic tools, especially for musculoskeletal injuries like rib
fractures, commonly detected via CT scans. Manual interpretation is
time-consuming and error-prone. We propose OrthoInsight, a multi-modal deep
learning framework for rib fracture diagnosis and report generation. It
integrates a YOLOv9 model for fracture detection, a medical knowledge graph for
retrieving clinical context, and a fine-tuned LLaVA language model for
generating diagnostic reports. OrthoInsight combines visual features from CT
images with expert textual data to deliver clinically useful outputs. Evaluated
on 28,675 annotated CT images and expert reports, it achieves high performance
across Diagnostic Accuracy, Content Completeness, Logical Coherence, and
Clinical Guidance Value, with an average score of 4.28, outperforming models
like GPT-4 and Claude-3. This study demonstrates the potential of multi-modal
learning in transforming medical image analysis and providing effective support
for radiologists.

</details>


### [194] [D2IP: Deep Dynamic Image Prior for 3D Time-sequence Pulmonary Impedance Imaging](https://arxiv.org/abs/2507.14046)
*Hao Fang,Hao Yu,Sihao Teng,Tao Zhang,Siyi Yuan,Huaiwu He,Zhe Liu,Yunjie Yang*

Main category: eess.IV

TL;DR: 针对深度图像先验（DIP）等无监督学习方法在断层成像中计算成本高的问题，本文提出了Deep Dynamic Image Prior (D2IP)框架，通过引入参数热启动、时间参数传播和轻量级网络，显著加速了3D时间序列图像重建，并在肺部数据上实现了更快的速度和更高的图像质量。


<details>
  <summary>Details</summary>
Motivation: 无监督学习方法（如DIP）在断层成像中展现出巨大潜力，但其依赖大量网络参数迭代导致计算成本高昂，尤其在复杂的3D或时间序列断层成像任务中，限制了实际应用。

Method: 本文提出Deep Dynamic Image Prior (D2IP)框架用于3D时间序列成像，引入了三项关键策略：1) 无监督参数热启动（Unsupervised Parameter Warm-Start, UPWS）以加速收敛；2) 时间参数传播（Temporal Parameter Propagation, TPP）以增强时间一致性；3) 定制的轻量级重建骨干网络3D-FastResUNet以提高计算效率。

Result: 在模拟和临床肺部数据集上的实验结果表明，D2IP能够实现快速准确的3D时间序列电阻抗断层成像（tsEIT）重建。与现有基线相比，D2IP提供了更优的图像质量（平均MSSIM提高24.8%，ERR降低8.1%），同时显著减少了计算时间（快7.1倍）。

Conclusion: D2IP在计算速度、准确性和图像质量方面表现出色，预示着其在临床动态肺部成像中的巨大应用前景。

Abstract: Unsupervised learning methods, such as Deep Image Prior (DIP), have shown
great potential in tomographic imaging due to their training-data-free nature
and high generalization capability. However, their reliance on numerous network
parameter iterations results in high computational costs, limiting their
practical application, particularly in complex 3D or time-sequence tomographic
imaging tasks. To overcome these challenges, we propose Deep Dynamic Image
Prior (D2IP), a novel framework for 3D time-sequence imaging. D2IP introduces
three key strategies - Unsupervised Parameter Warm-Start (UPWS), Temporal
Parameter Propagation (TPP), and a customized lightweight reconstruction
backbone, 3D-FastResUNet - to accelerate convergence, enforce temporal
coherence, and improve computational efficiency. Experimental results on both
simulated and clinical pulmonary datasets demonstrate that D2IP enables fast
and accurate 3D time-sequence Electrical Impedance Tomography (tsEIT)
reconstruction. Compared to state-of-the-art baselines, D2IP delivers superior
image quality, with a 24.8% increase in average MSSIM and an 8.1% reduction in
ERR, alongside significantly reduced computational time (7.1x faster),
highlighting its promise for clinical dynamic pulmonary imaging.

</details>


### [195] [UGPL: Uncertainty-Guided Progressive Learning for Evidence-Based Classification in Computed Tomography](https://arxiv.org/abs/2507.14102)
*Shravan Venkatraman,Pavan Kumar S,Rakesh Raj Madavan,Chandrakala S*

Main category: eess.IV

TL;DR: UGPL是一种不确定性引导的渐进式学习框架，通过先识别诊断模糊区域再进行局部精细分析，显著提高了CT图像（如肾脏异常、肺癌、COVID-19）的分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有CT图像分类方法难以处理病理特征的细微性和空间多样性，且通常对图像进行统一处理，限制了其检测需要聚焦分析的局部异常的能力。

Method: UGPL采用全局到局部的分析策略，首先识别诊断模糊区域，然后对关键区域进行详细检查。它使用证据深度学习量化预测不确定性，并通过非极大值抑制机制提取信息丰富的补丁，同时保持空间多样性。该方法结合渐进式细化策略和自适应融合机制，整合了上下文信息和细粒度细节。

Result: UGPL在三个CT数据集上均优于现有最先进方法，在肾脏异常、肺癌和COVID-19检测中的准确率分别提高了3.29%、2.46%和8.08%。分析表明，不确定性引导组件提供了显著益处，当完整渐进式学习流程实施时，性能大幅提升。

Conclusion: UGPL框架通过其不确定性引导的渐进式学习和全局到局部分析策略，有效解决了CT图像中细微和局部病理特征的分类挑战，取得了显著优于现有方法的性能。

Abstract: Accurate classification of computed tomography (CT) images is essential for
diagnosis and treatment planning, but existing methods often struggle with the
subtle and spatially diverse nature of pathological features. Current
approaches typically process images uniformly, limiting their ability to detect
localized abnormalities that require focused analysis. We introduce UGPL, an
uncertainty-guided progressive learning framework that performs a
global-to-local analysis by first identifying regions of diagnostic ambiguity
and then conducting detailed examination of these critical areas. Our approach
employs evidential deep learning to quantify predictive uncertainty, guiding
the extraction of informative patches through a non-maximum suppression
mechanism that maintains spatial diversity. This progressive refinement
strategy, combined with an adaptive fusion mechanism, enables UGPL to integrate
both contextual information and fine-grained details. Experiments across three
CT datasets demonstrate that UGPL consistently outperforms state-of-the-art
methods, achieving improvements of 3.29%, 2.46%, and 8.08% in accuracy for
kidney abnormality, lung cancer, and COVID-19 detection, respectively. Our
analysis shows that the uncertainty-guided component provides substantial
benefits, with performance dramatically increasing when the full progressive
learning pipeline is implemented. Our code is available at:
https://github.com/shravan-18/UGPL

</details>
