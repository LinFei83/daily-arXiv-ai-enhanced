<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 18]
- [cs.CV](#cs.CV) [Total: 83]
- [cs.CL](#cs.CL) [Total: 53]
- [cs.RO](#cs.RO) [Total: 33]
- [eess.SY](#eess.SY) [Total: 16]
- [eess.IV](#eess.IV) [Total: 8]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Discovering Differences in Strategic Behavior Between Humans and LLMs](https://arxiv.org/abs/2602.10324)
*Caroline Wang,Daniel Kasenberg,Kim Stachenfeld,Pablo Samuel Castro*

Main category: cs.AI

TL;DR: 本文使用AlphaEvolve工具，通过分析迭代石头剪刀布博弈数据，发现了相比人类，前沿大型语言模型（LLMs）能够表现出更深层次的策略行为，并揭示了导致这种行为差异的结构性因素。


<details>
  <summary>Details</summary>
Motivation: 为了理解在社会和策略场景中，大型语言模型（LLMs）的行为为何以及如何在何处与人类行为产生差异，并且现有行为博弈论模型无法完全捕捉人类或LLMs的独特行为。

Method: 利用AlphaEvolve这一程序发现工具，直接从迭代石头剪刀布博弈数据中发现可解释的人类和LLM行为模型。

Result: 分析结果表明，前沿LLMs在迭代石头剪刀布博弈中展现出比人类更深层次的策略行为。

Conclusion: 研究结果为理解人类和LLMs在策略互动中行为差异的结构性因素奠定了基础，并指出LLMs在某些策略性互动中可能超越人类。

Abstract: As Large Language Models (LLMs) are increasingly deployed in social and strategic scenarios, it becomes critical to understand where and why their behavior diverges from that of humans. While behavioral game theory (BGT) provides a framework for analyzing behavior, existing models do not fully capture the idiosyncratic behavior of humans or black-box, non-human agents like LLMs. We employ AlphaEvolve, a cutting-edge program discovery tool, to directly discover interpretable models of human and LLM behavior from data, thereby enabling open-ended discovery of structural factors driving human and LLM behavior. Our analysis on iterated rock-paper-scissors reveals that frontier LLMs can be capable of deeper strategic behavior than humans. These results provide a foundation for understanding structural differences driving differences in human and LLM behavior in strategic interactions.

</details>


### [2] [LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation](https://arxiv.org/abs/2602.10367)
*Zhiling Yan,Dingjie Song,Zhe Fang,Yisheng Ji,Xiang Li,Quanzheng Li,Lichao Sun*

Main category: cs.AI

TL;DR: 研究提出了LiveMedBench，一个动态更新、无数据污染、基于评分标准的医学基准测试，以更可靠地评估大型语言模型在临床环境中的表现。现有基准存在数据污染和时间失配问题，评估指标也不足。LiveMedBench通过每周抓取真实临床案例并进行多主体临床策展来解决这些问题，并引入自动化评分评估框架，该框架与专家医生评估高度一致。实验表明，现有模型表现不佳，且很大一部分失败源于无法将医学知识应用于特定患者情况。


<details>
  <summary>Details</summary>
Motivation: 现有医学基准测试存在数据污染（测试集泄露到训练集）和时间失配（未能反映医学知识的快速演变）的问题，导致对大型语言模型（LLMs）在临床环境中的性能评估不准确。同时，现有评估指标（如ROUGE和LLM-as-a-Judge）在评估开放式临床推理时不足以验证临床正确性。

Method: 1. LiveMedBench：一个持续更新、无数据污染、基于评分标准的基准测试，每周从在线医学社区抓取真实临床案例，确保与模型训练数据的时间严格分离。 2. Multi-Agent Clinical Curation Framework：用于过滤原始数据噪声并根据循证医学原则验证临床完整性。 3. Automated Rubric-based Evaluation Framework：将医生响应分解为细粒度的、特定于案例的标准，以实现比LLM-as-a-Judge更强的与专家医生的一致性。

Result: LiveMedBench目前包含2,756个真实案例，涵盖38个医学专业和多种语言，并附带16,702个评估标准。对38个LLMs的评估显示，即使是表现最好的模型也仅达到39.2%的准确率。84%的模型在截止日期后的案例上表现下降，证实了普遍存在的数据污染风险。错误分析表明，临床知识的上下文应用能力是主要瓶颈，35-48%的失败源于无法将医学知识应用于患者的具体约束。

Conclusion: LiveMedBench提供了一个更可靠、更具挑战性的医学LLM评估框架，揭示了当前模型在真实临床场景中的局限性，尤其是在上下文应用和应对数据污染方面。研究强调了开发能够理解和适应患者特定情况的LLM的重要性。

Abstract: The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reasoning often rely on either shallow lexical overlap (e.g., ROUGE) or subjective LLM-as-a-Judge scoring, both inadequate for verifying clinical correctness. To bridge these gaps, we introduce LiveMedBench, a continuously updated, contamination-free, and rubric-based benchmark that weekly harvests real-world clinical cases from online medical communities, ensuring strict temporal separation from model training data. We propose a Multi-Agent Clinical Curation Framework that filters raw data noise and validates clinical integrity against evidence-based medical principles. For evaluation, we develop an Automated Rubric-based Evaluation Framework that decomposes physician responses into granular, case-specific criteria, achieving substantially stronger alignment with expert physicians than LLM-as-a-Judge. To date, LiveMedBench comprises 2,756 real-world cases spanning 38 medical specialties and multiple languages, paired with 16,702 unique evaluation criteria. Extensive evaluation of 38 LLMs reveals that even the best-performing model achieves only 39.2%, and 84% of models exhibit performance degradation on post-cutoff cases, confirming pervasive data contamination risks. Error analysis further identifies contextual application-not factual knowledge-as the dominant bottleneck, with 35-48% of failures stemming from the inability to tailor medical knowledge to patient-specific constraints.

</details>


### [3] [Found-RL: foundation model-enhanced reinforcement learning for autonomous driving](https://arxiv.org/abs/2602.10458)
*Yansong Qu,Zihao Sheng,Zilin Huang,Jiancong Chen,Yuhao Luo,Tianyi Wang,Yiheng Feng,Samuel Labi,Sikai Chen*

Main category: cs.AI

TL;DR: Found-RL 是一个用于端到端自动驾驶的强化学习平台，它通过异步批处理推理和多种监督机制，有效地将大型视觉语言模型 (VLM) 的知识融入轻量级 RL 模型，解决了 VLM 的高延迟问题，实现了接近 VLM 的性能但具有实时推理速度。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习在自动驾驶中存在样本效率低和缺乏语义可解释性的问题。大型视觉语言模型 (VLM) 可以提供丰富的上下文知识，但其高推理延迟阻碍了在 RL 训练中的应用。

Method: Found-RL 平台采用异步批处理推理框架解耦 VLM 推理和模拟循环，减少延迟。引入值裕度正则化 (VMR) 和优势加权动作引导 (AWAG) 来蒸馏 VLM 的动作建议。使用高吞吐量的 CLIP 进行密集的奖励塑形，并通过条件对比动作对齐 (CCAA) 解决 CLIP 的动态盲点问题。

Result: Found-RL 平台使轻量级 RL 模型在自动驾驶任务中能够达到接近于使用数十亿参数 VLM 的性能，同时保持实时推理速度（约 500 FPS）。

Conclusion: Found-RL 提供了一个高效的 VLM 集成框架，成功克服了 VLM 在 RL 训练中的延迟限制，为自动驾驶领域的端到端 RL 提供了一种可行的解决方案。

Abstract: Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we present Found-RL, a platform tailored to efficiently enhance RL for AD using foundation models. A core innovation is the asynchronous batch inference framework, which decouples heavy VLM reasoning from the simulation loop, effectively resolving latency bottlenecks to support real-time learning. We introduce diverse supervision mechanisms: Value-Margin Regularization (VMR) and Advantage-Weighted Action Guidance (AWAG) to effectively distill expert-like VLM action suggestions into the RL policy. Additionally, we adopt high-throughput CLIP for dense reward shaping. We address CLIP's dynamic blindness via Conditional Contrastive Action Alignment, which conditions prompts on discretized speed/command and yields a normalized, margin-based bonus from context-specific action-anchor scoring. Found-RL provides an end-to-end pipeline for fine-tuned VLM integration and shows that a lightweight RL model can achieve near-VLM performance compared with billion-parameter VLMs while sustaining real-time inference (approx. 500 FPS). Code, data, and models will be publicly available at https://github.com/ys-qu/found-rl.

</details>


### [4] [MERIT Feedback Elicits Better Bargaining in LLM Negotiators](https://arxiv.org/abs/2602.10467)
*Jihwan Oh,Murad Aghazada,Yooju Shin,Se-Young Yun,Taehyeon Kim*

Main category: cs.AI

TL;DR: 研究提出了AgoraBench基准、基于效用理论的评估指标以及一个包含提示和微调的学习流程，以提升大型语言模型在复杂议价场景中的策略深度和对人类因素的适应性。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型在议价场景中表现不佳，缺乏策略深度和对人类复杂因素的适应性，而现有基准未能充分反映这一局限性。

Method: 构建了一个以效用反馈为中心 (utility feedback centric) 的框架，包括：1. AgoraBench基准，包含九种具有挑战性的议价场景；2. 基于效用理论的人类对齐、经济学基础指标（如代理效用、谈判能力、获取率）；3. 一个以人类偏好为基础的数据集和学习流程，通过提示和微调来增强LLM的议价能力。

Result: 实验表明，基线LLM策略通常与人类偏好不符，而提出的机制显著提高了议价表现，产生了更深的策略行为和更强的对手意识。

Conclusion: 提出的框架和方法能够有效提升大型语言模型在议价任务中的表现，使其策略行为更深入，并更好地感知对手。

Abstract: Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchmarks rarely capture this limitation. To bridge this gap, we present an utility feedback centric framework. Our contributions are: (i) AgoraBench, a new benchmark spanning nine challenging settings (e.g., deception, monopoly) that supports diverse strategy modeling; (ii) human-aligned, economically grounded metrics derived from utility theory. This is operationalized via agent utility, negotiation power, and acquisition ratio that implicitly measure how well the negotiation aligns with human preference and (iii) a human preference grounded dataset with learning pipeline that strengthens LLMs' bargaining ability through both prompting and finetuning. Empirical results indicate that baseline LLM strategies often diverge from human preferences, while our mechanism substantially improves negotiation performance, yielding deeper strategic behavior and stronger opponent awareness.

</details>


### [5] [Abstraction Generation for Generalized Planning with Pretrained Large Language Models](https://arxiv.org/abs/2602.10485)
*Zhenhe Cui,Huaxiang Xia,Hangjun Shen,Kailun Luo,Yong He,Wei Liang*

Main category: cs.AI

TL;DR: 本研究探索了大型语言模型（LLMs）作为定性数值规划（QNP）抽象生成器在泛化规划（GP）中的应用，并提出了一种自动调试方法来修复生成的抽象。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLMs在泛化规划中的潜力，研究者希望探究它们是否也能用于生成GP问题的QNP抽象，并解决抽象过程中可能出现的错误。

Method: 提出了一种提示协议，将GP领域和训练任务输入LLMs，要求其生成抽象特征，并进一步抽象初始状态、动作集和目标，形成QNP问题。同时，设计了一种自动调试方法来检测抽象错误并指导LLMs进行修复。

Result: 实验表明，在自动调试的引导下，部分LLMs能够生成有用的QNP抽象。

Conclusion: LLMs可以作为QNP抽象生成器，并且通过自动调试机制，可以有效地提高生成抽象的质量和可用性。

Abstract: Qualitative Numerical Planning (QNP) serves as an important abstraction model for generalized planning (GP), which aims to compute general plans that solve multiple instances at once. Recent works show that large language models (LLMs) can function as generalized planners. This work investigates whether LLMs can serve as QNP abstraction generators for GP problems and how to fix abstractions via automated debugging. We propose a prompt protocol: input a GP domain and training tasks to LLMs, prompting them to generate abstract features and further abstract the initial state, action set, and goal into QNP problems. An automated debugging method is designed to detect abstraction errors, guiding LLMs to fix abstractions. Experiments demonstrate that under properly guided by automated debugging, some LLMs can generate useful QNP abstractions.

</details>


### [6] [Flow of Spans: Generalizing Language Models to Dynamic Span-Vocabulary via GFlowNets](https://arxiv.org/abs/2602.10583)
*Bo Xue,Yunchong Song,Fanghao Shao,Xuekai Zhu,Lin Chen,Luoyi Fu,Xinbing Wang,Zhouhan Lin*

Main category: cs.AI

TL;DR: 本文提出了一种名为 FOSS 的生成式流网络（GFlowNets）框架，用于生成文本片段（spans），从而构建一个动态的、有向无环图（DAG）状态空间，相比于传统的基于 token 的自回归模型，能够更有效地探索和生成多样化、高质量的文本。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归语言模型在生成文本时存在灵活性和表达力受限的问题，因为它们依赖固定的词汇表且状态空间为树状结构。虽然动态词汇（通过检索文本片段）有所改进，但未能显式建模句子由不同长度片段组合构成的 DAG 结构，导致组合路径探索受限。GFlowNets 擅长在 DAG 结构状态空间中进行高效探索，但现有基于 GFlowNets 的语言模型仅在 token 层面操作，未能充分发挥其潜力。

Method: 本文提出 Flow of SpanS (FOSS) 框架，采用 GFlowNets 方法。FOSS 构建了一个动态的 span 词汇表，通过灵活地分割检索到的文本来生成 span，从而确保了 DAG 结构的状态空间。通过专门设计的奖励模型，FOSS 能够生成多样化且高质量的文本。

Result: 在文本生成任务上，FOSS 的 MAUVE 分数比 Transformer 模型提高了 12.5%。在知识密集型任务上，FOSS 取得了 3.5% 的性能提升。实验结果表明，FOSS 在多样性、质量和泛化能力上均优于当前最先进的方法。此外，FOSS 在模型规模、数据量和检索语料库丰富度增加时，优势得到进一步体现。

Conclusion: FOSS 作为一种基于 GFlowNets 的 span 生成框架，成功构建了 DAG 状态空间，有效解决了传统模型在文本生成中的局限性，并在多项任务上取得了显著的性能提升，证明了其在探索多样化文本组合路径和提高模型泛化能力方面的有效性。

Abstract: Standard autoregressive language models generate text token-by-token from a fixed vocabulary, inducing a tree-structured state space when viewing token sampling as an action, which limits flexibility and expressiveness. Recent work introduces dynamic vocabulary by sampling retrieved text spans but overlooks that the same sentence can be composed of spans of varying lengths, lacking explicit modeling of the directed acyclic graph (DAG) state space. This leads to restricted exploration of compositional paths and is biased toward the chosen path. Generative Flow Networks (GFlowNets) are powerful for efficient exploring and generalizing over state spaces, particularly those with a DAG structure. However, prior GFlowNets-based language models operate at the token level and remain confined to tree-structured spaces, limiting their potential. In this work, we propose Flow of SpanS (FOSS), a principled GFlowNets framework for span generation. FoSS constructs a dynamic span vocabulary by segmenting the retrieved text flexibly, ensuring a DAG-structured state space, which allows GFlowNets to explore diverse compositional paths and improve generalization. With specialized reward models, FoSS generates diverse, high-quality text. Empirically, FoSS improves MAUVE scores by up to 12.5% over Transformer on text generation and achieves 3.5% gains on knowledge-intensive tasks, consistently outperforming state-of-the-art methods. Scaling experiments further demonstrate FoSS benefits from larger models, more data, and richer retrieval corpora, retaining its advantage over strong baselines.

</details>


### [7] [Neuro-symbolic Action Masking for Deep Reinforcement Learning](https://arxiv.org/abs/2602.10598)
*Shuai Han,Mehdi Dastani,Shihan Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为神经符号动作掩码 (NSAM) 的新框架，它通过在深度强化学习 (DRL) 过程中以最少的监督学习符号模型，从而自动生成动作掩码，排除不可行动作。


<details>
  <summary>Details</summary>
Motivation: 现有 DRL 方法在训练和执行过程中可能探索不可行动作，并且依赖于手动指定的动作掩码技术。

Method: NSAM 框架自动学习与高维状态给定的领域约束一致的符号模型，并基于此模型学习动作掩码，从而排除不可行动作。该框架能够实现符号推理和深度策略优化的端到端集成，并通过相互促进的方式提升符号接地和策略学习的效果。

Result: 在多个带约束的领域中进行评估，NSAM 显著提高了 DRL 代理的样本效率，并大幅减少了约束违反情况。

Conclusion: NSAM 能够有效地解决 DRL 中的可行性问题，通过神经符号方法实现了高效的策略学习和约束满足。

Abstract: Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, in a minimally supervised manner during the DRL process. Based on the learned symbolic model of states, NSAM learns action masks that rules out infeasible actions. NSAM enables end-to-end integration of symbolic reasoning and deep policy optimization, where improvements in symbolic grounding and policy learning mutually reinforce each other. We evaluate NSAM on multiple domains with constraints, and experimental results demonstrate that NSAM significantly improves sample efficiency of DRL agent while substantially reducing constraint violations.

</details>


### [8] [OmniSapiens: A Foundation Model for Social Behavior Processing via Heterogeneity-Aware Relative Policy Optimization](https://arxiv.org/abs/2602.10635)
*Keane Ong,Sabri Boughorbel,Luwei Xiao,Chanakya Ekbote,Wei Dai,Ao Qu,Jingyao Wu,Rui Mao,Ehsan Hoque,Erik Cambria,Gianmarco Mengaldo,Paul Pu Liang*

Main category: cs.AI

TL;DR: 提出了一种名为HARPO（Heterogeneity-Aware Relative Policy Optimization）的强化学习方法，用于在异构任务和样本之间进行平衡学习，并发布了一个在社会行为处理方面表现优异的基金模型Omnisapiens-7B 2.0。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法孤立地对人类行为维度进行建模，导致训练成本高且泛化能力受限。虽然现有的推理RL方法可以处理多任务，但未能明确解决跨异构行为数据的学习问题。

Method: 提出HARPO方法，通过调整优势函数来平衡异构任务和样本的学习，防止单个任务或样本在策略优化中占据过大影响。利用HARPO开发了Omnisapiens-7B 2.0基金模型。

Result: Omnisapiens-7B 2.0在多任务和未见过（held-out）的设置下，性能分别提高了16.85%和9.37%，并生成了更清晰、更鲁棒的推理过程。HARPO在与近期RL方法的对比中，在行为任务上表现最为稳定和优异。

Conclusion: HARPO是一种有效的方法，可以平衡跨异构任务和样本的学习，并且基于HARPO构建的Omnisapiens-7B 2.0在社会行为处理方面达到了最先进的性能。

Abstract: To develop socially intelligent AI, existing approaches typically model human behavioral dimensions (e.g., affective, cognitive, or social attributes) in isolation. Although useful, task-specific modeling often increases training costs and limits generalization across behavioral settings. Recent reasoning RL methods facilitate training a single unified model across multiple behavioral tasks, but do not explicitly address learning across different heterogeneous behavioral data. To address this gap, we introduce Heterogeneity-Aware Relative Policy Optimization (HARPO), an RL method that balances leaning across heterogeneous tasks and samples. This is achieved by modulating advantages to ensure that no single task or sample carries disproportionate influence during policy optimization. Using HARPO, we develop and release Omnisapiens-7B 2.0, a foundation model for social behavior processing. Relative to existing behavioral foundation models, Omnisapiens-7B 2.0 achieves the strongest performance across behavioral tasks, with gains of up to +16.85% and +9.37% on multitask and held-out settings respectively, while producing more explicit and robust reasoning traces. We also validate HARPO against recent RL methods, where it achieves the most consistently strong performance across behavioral tasks.

</details>


### [9] [To Think or Not To Think, That is The Question for Large Reasoning Models in Theory of Mind Tasks](https://arxiv.org/abs/2602.10625)
*Nanxu Gong,Haotian Li,Sixun Dong,Jianxun Lian,Yanjie Fu,Xing Xie*

Main category: cs.AI

TL;DR: 研究发现，当前先进的大型语言模型（LRMs）在数学和编程等形式推理上的进步，并未能有效迁移到社会认知能力，特别是心智理论（ToM）任务上。LRMs在ToM任务上表现不一致，甚至可能不如非推理模型，并且存在“慢速思维崩溃”、“选项匹配捷径”等问题。作者提出了S2F和T2M两种干预方法，并强调实现稳健的ToM需要开发超越现有推理方法的新能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型（LRMs）在数学和编码等领域取得了进展，但其在社会认知能力（特别是心智理论，ToM）上的表现仍不明确，作者希望系统研究LRMs在ToM任务上的能力，并探究其推理能力是否能有效迁移。

Method: 作者对比了九种先进的大型语言模型（LLMs），包括推理模型和非推理模型，在三个代表性的ToM基准测试上进行了系统性评估。他们还进行了细粒度分析，并设计了两种干预方法：慢速到快速（S2F）自适应推理和匹配思维（T2M）捷径预防。

Result: 推理模型在ToM任务上并不总是优于非推理模型，有时甚至表现更差。具体来说，研究发现：1) 随着响应长度增加，模型准确率显著下降，更大的推理预算反而损害性能（慢速思维崩溃）；2) 适度和自适应的推理有助于提高性能，限制推理长度可以减轻失败，而不同的成功模式表明需要动态适应；3) 当移除多项选择时，推理模型的表现显著提升，表明它们依赖于选项匹配而非真正的推理。

Conclusion: 大型推理模型（LRMs）在形式推理上的进步并不能完全迁移到社会推理任务（如ToM）。要实现稳健的ToM能力，需要开发超越现有推理方法的新颖能力。

Abstract: Theory of Mind (ToM) assesses whether models can infer hidden mental states such as beliefs, desires, and intentions, which is essential for natural social interaction. Although recent progress in Large Reasoning Models (LRMs) has boosted step-by-step inference in mathematics and coding, it is still underexplored whether this benefit transfers to socio-cognitive skills. We present a systematic study of nine advanced Large Language Models (LLMs), comparing reasoning models with non-reasoning models on three representative ToM benchmarks. The results show that reasoning models do not consistently outperform non-reasoning models and sometimes perform worse. A fine-grained analysis reveals three insights. First, slow thinking collapses: accuracy significantly drops as responses grow longer, and larger reasoning budgets hurt performance. Second, moderate and adaptive reasoning benefits performance: constraining reasoning length mitigates failure, while distinct success patterns demonstrate the necessity of dynamic adaptation. Third, option matching shortcut: when multiple choice options are removed, reasoning models improve markedly, indicating reliance on option matching rather than genuine deduction. We also design two intervention approaches: Slow-to-Fast (S2F) adaptive reasoning and Think-to-Match (T2M) shortcut prevention to further verify and mitigate the problems. With all results, our study highlights the advancement of LRMs in formal reasoning (e.g., math, code) cannot be fully transferred to ToM, a typical task in social reasoning. We conclude that achieving robust ToM requires developing unique capabilities beyond existing reasoning methods.

</details>


### [10] [Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation](https://arxiv.org/abs/2602.10699)
*Jie Jiang,Yangru Huang,Zeyu Wang,Changping Wang,Yuling Xiong,Jun Zhang,Huan Yu*

Main category: cs.AI

TL;DR: 提出了一种名为 V-STAR 的新框架，用于解决基于自回归生成模型推荐中的概率-奖励不匹配问题，通过值引导的高效解码（VED）和利用树状结构计算的兄弟节点相对优势（Sibling-GRPO）来提升探索效率和奖励信号的区分度，实验证明在准确性和多样性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于自回归模型的生成式推荐方法在强化学习（RL）微调时存在概率-奖励不匹配的问题，导致探索不足和奖励信号压缩，影响模型性能。

Method: 提出 V-STAR 框架，包含两个主要组件：1. 值引导的高效解码（VED），用于识别关键节点并选择性地加深有潜力的前缀；2. 兄弟节点生成式策略优化（Sibling-GRPO），利用解码过程中形成的树状结构计算兄弟节点之间的相对优势，以增强奖励信号的区分度。

Result: 在离线和在线数据集上的实验表明，V-STAR 显著优于最先进的基线方法，在满足延迟约束的前提下，提供了更高的准确性和候选集多样性。

Conclusion: V-STAR 通过有效解决生成式推荐中的概率-奖励不匹配问题，实现了更有效的探索和更强的学习信号，从而在推荐任务中取得了更好的性能。

Abstract: Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch. Conventional likelihood-dominated decoding (e.g., beam search) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration, where high-reward items in low-probability branches are prematurely pruned and rarely sampled, and (2) advantage compression, where trajectories sharing high-probability prefixes receive highly correlated rewards with low within-group variance, yielding a weak comparative signal for RL. To address these challenges, we propose V-STAR, a Value-guided Sampling and Tree-structured Advantage Reinforcement framework. V-STAR forms a self-evolving loop via two synergistic components. First, a Value-Guided Efficient Decoding (VED) is developed to identify decisive nodes and selectively deepen high-potential prefixes. This improves exploration efficiency without exhaustive tree search. Second, we propose Sibling-GRPO, which exploits the induced tree topology to compute sibling-relative advantages and concentrates learning signals on decisive branching decisions. Extensive experiments on both offline and online datasets demonstrate that V-STAR outperforms state-of-the-art baselines, delivering superior accuracy and candidate-set diversity under strict latency constraints.

</details>


### [11] [Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act](https://arxiv.org/abs/2602.10802)
*Da-Lun Chen,Prasasthy Balasubramanian,Lauri Lovén,Susanna Pirttikangas,Jaakko Sauvola,Panagiotis Kostakos*

Main category: cs.AI

TL;DR: 该研究调查了信息技术与电子工程（ITEE）领域师生对生成式人工智能（GenAI）的看法，发现了对编程支持的普遍兴趣，以及对回答质量、隐私和学术诚信的担忧。基于此，研究提出了负责任集成GenAI的需求和概念框架，为高校提供指导。


<details>
  <summary>Details</summary>
Motivation: 高等教育界对生成式AI（GenAI）的使用存在分歧，并且需要满足欧盟AI法案的监管要求。因此，研究旨在了解ITEE领域的师生对GenAI的看法，以指导其负责任的集成。

Method: 采用混合研究方法，对芬兰奥卢大学ITEE学院的61名教职员工和37名学生进行了问卷调查。

Result: 调查结果显示，师生普遍对GenAI在编程支持方面的应用表现出浓厚兴趣，但也存在对回答质量、隐私和学术诚信的担忧。这些发现揭示了共享的以及特定学科的主题。

Conclusion: 为了负责任地集成GenAI，高校需要与利益相关者进行沟通，并满足特定的学科需求。该研究提出的高层需求和概念框架为高校在解决师生担忧和遵守法规的同时，有效利用GenAI提供了实际指导。

Abstract: Many staff and students in higher education have adopted generative artificial intelligence (GenAI) tools in their work and study. GenAI is expected to enhance cognitive systems by enabling personalized learning and streamlining educational services. However, stakeholders perceptions of GenAI in higher education remain divided, shaped by cultural, disciplinary, and institutional contexts. In addition, the EU AI Act requires universities to ensure regulatory compliance when deploying cognitive systems. These developments highlight the need for institutions to engage stakeholders and tailor GenAI integration to their needs while addressing concerns. This study investigates how GenAI is perceived within the disciplines of Information Technology and Electrical Engineering (ITEE). Using a mixed-method approach, we surveyed 61 staff and 37 students at the Faculty of ITEE, University of Oulu. The results reveal both shared and discipline-specific themes, including strong interest in programming support from GenAI and concerns over response quality, privacy, and academic integrity. Drawing from these insights, the study identifies a set of high-level requirements and proposes a conceptual framework for responsible GenAI integration. Disciplinary-specific requirements reinforce the importance of stakeholder engagement when integrating GenAI into higher education. The high-level requirements and the framework provide practical guidance for universities aiming to harness GenAI while addressing stakeholder concerns and ensuring regulatory compliance.

</details>


### [12] [See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch](https://arxiv.org/abs/2602.10814)
*Xingyi Zhang,Yulei Ye,Kaifeng Huang,Wenhao Li,Xiangfeng Wang*

Main category: cs.AI

TL;DR: 本研究提出了ScratchWorld基准，用于评估AI代理在Scratch环境中的程序构建能力，并通过两种交互模式（原始模式和复合模式）和基于执行的评估协议来诊断代理的失败原因。


<details>
  <summary>Details</summary>
Motivation: 现有研究对AI代理通过图形用户界面（GUI）构建程序的能力评估不足，特别是对于Scratch这样的低代码教育环境。

Method: 构建了ScratchWorld基准，包含83个基于“使用-修改-创建”教学框架的任务，分为创建、调试、扩展和计算四类。采用原始模式（精细拖放操作）和复合模式（高级语义API）两种交互方式。提出基于执行的评估协议，在浏览器环境中通过运行时测试验证程序的功能正确性。

Result: 在对最先进的多模态语言模型和GUI代理进行的广泛实验中，发现存在显著的推理-行动差距，尽管代理具有强大的规划能力，但在精细的GUI操作方面仍面临持续挑战。

Conclusion: ScratchWorld基准能够有效地诊断AI代理在Scratch程序构建任务中的失败来源，并揭示了当前AI代理在GUI操作中的局限性。

Abstract: Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debug, Extend, and Compute. To rigorously diagnose the source of agent failures, the benchmark employs two complementary interaction modes: primitive mode requires fine-grained drag-and-drop manipulation to directly assess visuomotor control, while composite mode uses high-level semantic APIs to disentangle program reasoning from GUI execution. To ensure reliable assessment, we propose an execution-based evaluation protocol that validates the functional correctness of the constructed Scratch programs through runtime tests within the browser environment. Extensive experiments across state-of-the-art multimodal language models and GUI agents reveal a substantial reasoning--acting gap, highlighting persistent challenges in fine-grained GUI manipulation despite strong planning capabilities.

</details>


### [13] [SynergyKGC: Reconciling Topological Heterogeneity in Knowledge Graph Completion via Topology-Aware Synergy](https://arxiv.org/abs/2602.10845)
*Xuecheng Zou,Yu Tang,Bingbing Wang*

Main category: cs.AI

TL;DR: SynergyKGC是一个知识图谱补全框架，通过跨模态协同和密度依赖的策略，解决了现有方法在不同图密度下存在的结构分辨率不匹配问题，从而提高了知识图谱补全的性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱补全方法在融合实体语义和拓扑结构时，未能有效处理不同图密度带来的差异，导致在稠密区域易受结构噪声干扰，在稀疏区域则面临表示坍缩。

Method: SynergyKGC提出了一个主动的跨模态协同专家，利用关系感知交叉注意力机制和语义意图驱动的门控机制来改进邻居聚合。该框架还结合了密度依赖的身份锚定策略和双塔一致性架构，以协调拓扑异质性并保证表示的稳定性。

Result: 在两个公开数据集上的系统评估表明，SynergyKGC显著提高了知识图谱补全的命中率。

Conclusion: SynergyKGC能够有效协调知识图谱中的拓扑异质性，并在不同图密度下保持表示的稳定性，为非同质结构化数据中的弹性信息集成提供了一个通用原则。

Abstract: Knowledge Graph Completion (KGC) fundamentally hinges on the coherent fusion of pre-trained entity semantics with heterogeneous topological structures to facilitate robust relational reasoning. However, existing paradigms encounter a critical "structural resolution mismatch," failing to reconcile divergent representational demands across varying graph densities, which precipitates structural noise interference in dense clusters and catastrophic representation collapse in sparse regions. We present SynergyKGC, an adaptive framework that advances traditional neighbor aggregation to an active Cross-Modal Synergy Expert via relation-aware cross-attention and semantic-intent-driven gating. By coupling a density-dependent Identity Anchoring strategy with a Double-tower Coherent Consistency architecture, SynergyKGC effectively reconciles topological heterogeneity while ensuring representational stability across training and inference phases. Systematic evaluations on two public benchmarks validate the superiority of our method in significantly boosting KGC hit rates, providing empirical evidence for a generalized principle of resilient information integration in non-homogeneous structured data.

</details>


### [14] [Reinforcing Chain-of-Thought Reasoning with Self-Evolving Rubrics](https://arxiv.org/abs/2602.10885)
*Leheng Sheng,Wenchang Ma,Ruixin Hong,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.AI

TL;DR: 本文提出了一种名为RLCER的方法，通过自生成和自演化的评分标准，在无需人工标注的情况下，对大型语言模型的思维链（CoT）进行奖励，并提高了模型的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的思维链（CoT）奖励方法面临挑战：直接奖励CoT需要大量人工标注，静态奖励模型难以适应CoT分布的变化和奖励的操纵。因此，研究者们希望找到一种能够自主奖励CoT、无需人工标注且能逐步演进的方法。

Method: RLCER方法在结果导向的RLVR（Reinforcement Learning from Human Feedback）基础上进行增强，通过自生成和自演化的评分标准来奖励CoT。这些自生成的评分标准能够提供可靠的CoT监督信号，即使在没有结果奖励的情况下也能有效工作。

Result: RLCER在奖励CoT方面优于仅基于结果的RLVR方法。此外，当这些自生成的评分标准作为提示（in-prompt hints）使用时，能够进一步提升模型在推理时的性能。

Conclusion: 自生成和自演化的评分标准为CoT提供了有效的自主监督信号，RLCER是一种无需人工标注即可改进LLM CoT推理性能的方法，并且其自生成的评分标准在推理时也能作为有用的提示。

Abstract: Despite chain-of-thought (CoT) playing crucial roles in LLM reasoning, directly rewarding it is difficult: training a reward model demands heavy human labeling efforts, and static RMs struggle with evolving CoT distributions and reward hacking. These challenges motivate us to seek an autonomous CoT rewarding approach that requires no human annotation efforts and can evolve gradually. Inspired by recent self-evolving training methods, we propose \textbf{RLCER} (\textbf{R}einforcement \textbf{L}earning with \textbf{C}oT Supervision via Self-\textbf{E}volving \textbf{R}ubrics), which enhances the outcome-centric RLVR by rewarding CoTs with self-proposed and self-evolving rubrics. We show that self-proposed and self-evolving rubrics provide reliable CoT supervision signals even without outcome rewards, enabling RLCER to outperform outcome-centric RLVR. Moreover, when used as in-prompt hints, these self-proposed rubrics further improve inference-time performance.

</details>


### [15] [Can LLMs Cook Jamaican Couscous? A Study of Cultural Novelty in Recipe Generation](https://arxiv.org/abs/2602.10964)
*F. Carichon,R. Rampa,G. Farnadi*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在生成文化内容时存在文化偏见，无法实现对非主流文化的有意义的适应。本文通过分析烹饪食谱，发现LLMs生成的文化适应性食谱不具代表性，且其偏差与文化距离不相关。模型内部表示对文化信息的保留较弱，且对创造性和传统等概念的理解存在偏差。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，大型语言模型（LLMs）在生成内容时存在系统性文化偏见，引发了对刻板印象、文化同质化以及文化特有表达方式被抹除的担忧。因此，研究LLMs能否在主流文化之外，有意义地适应多样化文化，仍然是一个关键挑战。

Method: 利用GlobalFusion数据集，该数据集根据文化距离指标匹配了不同国家的人类食谱。研究人员使用相同的国家对，让多个LLMs生成文化适应性食谱，并直接比较人类和LLMs在跨文化内容创作中的行为。分析了LLMs内部表示中的文化信息保留程度，以及模型对创造性、传统等概念的理解，并检查了模型识别适应性国家以及将适应性内容与文化上重要的元素（如食材）联系起来的能力。

Result: LLMs未能生成具有文化代表性的适应性食谱。与人类不同，LLMs生成的食谱的偏差与其目标文化之间的文化距离不相关。LLMs内部表示中文化信息的保留较弱，模型在生成过程中夸大了新颖性，并且未能准确识别适应性与目标国家，也未能将适应性内容与文化上突出的元素（如食材）联系起来。

Conclusion: 当前的大型语言模型在面向文化的内容生成方面存在根本性局限，这对其在文化敏感应用中的使用具有重要影响。LLMs在理解和体现文化多样性方面仍需改进。

Abstract: Large Language Models (LLMs) are increasingly used to generate and shape cultural content, ranging from narrative writing to artistic production. While these models demonstrate impressive fluency and generative capacity, prior work has shown that they also exhibit systematic cultural biases, raising concerns about stereotyping, homogenization, and the erasure of culturally specific forms of expression. Understanding whether LLMs can meaningfully align with diverse cultures beyond the dominant ones remains a critical challenge. In this paper, we study cultural adaptation in LLMs through the lens of cooking recipes, a domain in which culture, tradition, and creativity are tightly intertwined. We build on the \textit{GlobalFusion} dataset, which pairs human recipes from different countries according to established measures of cultural distance. Using the same country pairs, we generate culturally adapted recipes with multiple LLMs, enabling a direct comparison between human and LLM behavior in cross-cultural content creation. Our analysis shows that LLMs fail to produce culturally representative adaptations. Unlike humans, the divergence of their generated recipes does not correlate with cultural distance. We further provide explanations for this gap. We show that cultural information is weakly preserved in internal model representations, that models inflate novelty in their production by misunderstanding notions such as creativity and tradition, and that they fail to identify adaptation with its associated countries and to ground it in culturally salient elements such as ingredients. These findings highlight fundamental limitations of current LLMs for culturally oriented generation and have important implications for their use in culturally sensitive applications.

</details>


### [16] [CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion](https://arxiv.org/abs/2602.10999)
*Yusong Lin,Haiyang Wang,Shuzhe Wu,Lue Fan,Feiyang Pan,Sanyuan Zhao,Dandan Tu*

Main category: cs.AI

TL;DR: 本文提出了一种名为 CLI-Gym 的方法，通过模拟和探索环境历史来大规模生成面向交互式环境（如命令行界面）的任务。基于此方法训练的 LiberCoder 模型在 Terminal-Bench 基准测试上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究对如何规模化地获取需要与运行时环境（如命令行界面）进行大量交互的任务以增强智能体能力的研究不足。

Method: 受到 Dockerfile 的启发，本文提出一种方法，利用智能体模拟和探索环境历史，并通过执行反馈进行指导。具体来说，通过追溯健康环境的历史，将其状态反转到出现运行时故障的早期状态，然后通过打包错误状态和相应的错误信息来派生任务。

Result: CLI-Gym 方法成功派生了 1,655 个环境密集型任务，这是同类任务中规模最大的集合。在此基础上进行微调的 LiberCoder 模型在 Terminal-Bench 基准测试上取得了 +21.1% 的绝对提升（达到 46.1%），优于多个强基线模型。

Conclusion: CLI-Gym 是首个可公开获取的、用于大规模派生环境密集型任务的流水线。通过此方法训练的 LiberCoder 模型在处理命令行交互任务方面表现出显著的性能优势。

Abstract: Agentic coding requires agents to effectively interact with runtime environments, e.g., command line interfaces (CLI), so as to complete tasks like resolving dependency issues, fixing system problems, etc. But it remains underexplored how such environment-intensive tasks can be obtained at scale to enhance agents' capabilities. To address this, based on an analogy between the Dockerfile and the agentic task, we propose to employ agents to simulate and explore environment histories, guided by execution feedback. By tracing histories of a healthy environment, its state can be inverted to an earlier one with runtime failures, from which a task can be derived by packing the buggy state and the corresponding error messages. With our method, named CLI-Gym, a total of 1,655 environment-intensive tasks are derived, being the largest collection of its kind. Moreover, with curated successful trajectories, our fine-tuned model, named LiberCoder, achieves substantial absolute improvements of +21.1% (to 46.1%) on Terminal-Bench, outperforming various strong baselines. To our knowledge, this is the first public pipeline for scalable derivation of environment-intensive tasks.

</details>


### [17] [GameDevBench: Evaluating Agentic Capabilities Through Game Development](https://arxiv.org/abs/2602.11103)
*Wayne Chi,Yixiong Fang,Arnav Yayavaram,Siddharth Yayavaram,Seth Karten,Qiuhong Anna Wei,Runkun Chen,Alexander Wang,Valerie Chen,Ameet Talwalkar,Chris Donahue*

Main category: cs.AI

TL;DR: 本文提出了 GameDevBench，这是一个包含 132 个游戏开发任务的基准测试，用于评估多模态代码代理。与现有软件开发基准相比，这些任务需要更深入的多模态理解和更复杂的代码修改。研究发现，即使是最好的代理也只能解决一半的任务，且任务难度与多模态复杂性相关。作者还引入了图像和视频反馈机制，显著提高了代理性能，并公开了 GameDevBench 以促进研究。


<details>
  <summary>Details</summary>
Motivation: 现有的代码代理在多模态能力方面进展缓慢，缺乏能够同时处理软件开发复杂性和深度多模态理解的评估平台。游戏开发领域因其需要处理大型代码库和多模态资产（如着色器、精灵、动画）而成为一个理想的测试平台。

Method: 创建了一个名为 GameDevBench 的基准测试，其中包含 132 个从网络和视频教程衍生的游戏开发任务。这些任务需要代理理解代码和多模态资产，并进行大量的代码修改。在评估代理性能的同时，研究者还引入了基于图像和视频的反馈机制来增强代理的多模态能力。

Result: GameDevBench 中的任务比先前的软件开发基准更具挑战性，平均解决方案需要更多的代码行和文件更改。现有最好的代理只能解决 54.5% 的任务。研究发现，感知到的任务难度与多模态复杂性密切相关，2D 图形任务的成功率显著低于游戏玩法导向的任务。所提出的图像和视频反馈机制能有效提高代理的性能，例如 Claude Sonnet 4.5 的成功率从 33.3% 提升到 47.7%。

Conclusion: 游戏开发是一个极具挑战性的多模态任务，需要代理具备深度理解和复杂代码操作能力。GameDevBench 是一个新颖且具有挑战性的基准测试，能够有效地评估多模态代码代理在该领域的表现。图像和视频反馈机制是提升代理多模态能力的有效途径。作者公开 GameDevBench 以推动未来在智能体游戏开发方面的研究。

Abstract: Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench, the first benchmark for evaluating agents on game development tasks. GameDevBench consists of 132 tasks derived from web and video tutorials. Tasks require significant multimodal understanding and are complex -- the average solution requires over three times the amount of lines of code and file changes compared to prior software development benchmarks. Agents still struggle with game development, with the best agent solving only 54.5% of tasks. We find a strong correlation between perceived task difficulty and multimodal complexity, with success rates dropping from 46.9% on gameplay-oriented tasks to 31.6% on 2D graphics tasks. To improve multimodal capability, we introduce two simple image and video-based feedback mechanisms for agents. Despite their simplicity, these methods consistently improve performance, with the largest change being an increase in Claude Sonnet 4.5's performance from 33.3% to 47.7%. We release GameDevBench publicly to support further research into agentic game development.

</details>


### [18] [FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight](https://arxiv.org/abs/2602.11136)
*Jiayi Zhou,Yang Sheng,Hantao Lou,Yaodong Yang,Jie Fu*

Main category: cs.AI

TL;DR: 本研究提出了一种名为Formal-of-Thought的神经符号框架，通过将自然语言要求转化为形式化规范，利用LLM和形式化验证工具（Dafny和Z3）来提高LLM代理在关键领域的行为安全性，相比LLM-as-a-Judge方法，在三个基准测试中平均提高了16.6%的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理在关键领域的应用日益广泛，其行为安全性至关重要。现有的LLM-as-a-Judge监督方法存在固有的困境，即概率性系统难以可靠地监督其他概率性系统而不继承其失效模式。形式化验证是解决该困境的有原则的方法，但自然语言要求到形式化规范的翻译瓶颈阻碍了其应用。

Method: 提出了一种名为Formal-of-Thought的神经符号框架。该框架采用双向架构：首先，LLM作为规范编译器，自顶向下将高级人类意图分解为原子、可验证的约束；然后，利用Dafny规范和Z3 SMT求解器自底向上证明合规性，生成数学保证而非概率分数。

Result: 在行为安全、多领域约束遵守和代理向上欺骗检测三个基准测试中进行了验证。实验结果表明，Formal-of-Thought框架在7种代理模型上，相比LLM-as-a-Judge基线平均提高了16.6%的准确率。此外，该框架实现了弱到强的泛化能力，一个7B的裁判能够以超过90%的准确率检测72B代理的欺骗行为，并通过迭代精炼实现近乎线性的安全提升。

Conclusion: Formal-of-Thought框架成功解决了自然语言要求到形式化规范的翻译瓶颈，提供了一种 principled 的方法来确保LLM代理的行为安全。该方法能够生成可靠的数学保证，显著优于现有的LLM-as-a-Judge方法，并具备良好的泛化能力和可扩展性。

Abstract: As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation from natural language requirements to formal specifications. This paper bridges this gap by proposing , a neuro-symbolic framework that employs a bidirectional Formal-of-Thought architecture: LLMs serve as specification compilers that top-down decompose high-level human intent into atomic, verifiable constraints, then bottom-up prove compliance using Dafny specifications and Z3 Satisfiability modulo theories solving, which produces mathematical guarantees rather than probabilistic scores. We validate across three benchmarks spanning behavioral safety, multi-domain constraint adherence, and agentic upward deception detection. Experiments on 7 agent models demonstrate that achieves an average improvement of 16.6% over LLM-as-a-Judge baselines, enables weak-to-strong generalization where a 7B judge achieves over 90% accuracy detecting deception from 72B agents, and provides near-linear safety improvement through iterative refinement.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [19] [VERA: Identifying and Leveraging Visual Evidence Retrieval Heads in Long-Context Understanding](https://arxiv.org/abs/2602.10146)
*Rongcan Pei,Huan Li,Fang Guo,Qi Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种名为VERA的训练无关框架，通过识别模型不确定性来增强视觉证据检索，从而显著提升了视觉语言模型在长上下文理解任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在处理长上下文和复杂推理任务时面临挑战，性能受限。

Method: 通过注意力分析识别出对视觉线索定位至关重要的稀疏、动态的“视觉证据检索（VER）头”，并提出VERA框架，该框架通过检测模型不确定性（熵）来触发VER头关注的视觉证据的显式语言化。

Result: VERA框架在Qwen3-VL-8B-Instruct和GLM-4.1V-Thinking模型上进行了测试，在五个基准测试中平均相对提升了21.3%和20.1%，显著改善了长上下文理解能力。

Conclusion: VERA框架能够有效增强视觉语言模型在长上下文理解方面的能力，其关键在于通过动态识别模型不确定性来激活特定的视觉证据检索机制。

Abstract: While Vision-Language Models (VLMs) have shown promise in textual understanding, they face significant challenges when handling long context and complex reasoning tasks. In this paper, we dissect the internal mechanisms governing long-context processing in VLMs to understand their performance bottlenecks. Through the lens of attention analysis, we identify specific Visual Evidence Retrieval (VER) Heads - a sparse, dynamic set of attention heads critical for locating visual cues during reasoning, distinct from static OCR heads. We demonstrate that these heads are causal to model performance; masking them leads to significant degradation. Leveraging this discovery, we propose VERA (Visual Evidence Retrieval Augmentation), a training-free framework that detects model uncertainty (i.e., entropy) to trigger the explicit verbalization of visual evidence attended by VER heads. Comprehensive experiments demonstrate that VERA significantly improves long-context understanding of open-source VLMs: it yields an average relative improvement of 21.3% on Qwen3-VL-8B-Instruct and 20.1% on GLM-4.1V-Thinking across five benchmarks.

</details>


### [20] [Beyond Closed-Pool Video Retrieval: A Benchmark and Agent Framework for Real-World Video Search and Moment Localization](https://arxiv.org/abs/2602.10159)
*Tao Yu,Yujia Yang,Haopeng Jin,Junhao Gong,Xinlong Chen,Yuxuan Zhou,Shanbin Zhang,Jiabing Yang,Xinming Wang,Hongzhu Yi,Ping Nie,Kai Zou,Zhang Zhang,Yan Huang,Liang Wang,Yeshani,Ruiwen Tao,Jin Ma,Haijin Liang,Jinwen Luo*

Main category: cs.CV

TL;DR: 本文提出了RVMS-Bench，一个用于评估真实网络视频检索的基准系统，并引入了RACLO框架，模拟人类的检索过程，以应对模糊记忆的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索基准无法反映真实世界中模糊、多维度的记忆搜索场景，尤其是在开放网络环境中。

Method: 构建了包含1440个样本、20个类别和4个时长分组的RVMS-Bench数据集，采用分层描述框架（全局印象、关键时刻、时间上下文、听觉记忆），并通过人工审核验证。提出RACLO框架，利用溯因推理模拟人类的“回忆-搜索-验证”认知过程。

Result: 实验表明，现有的多模态大型语言模型（MLLMs）在基于模糊记忆的真实世界视频检索和时刻定位方面能力不足。

Conclusion: RVMS-Bench和RACLO有助于推动视频检索在真实世界非结构化场景下的鲁棒性发展，并揭示了当前MLLMs在该领域的局限性。

Abstract: Traditional video retrieval benchmarks focus on matching precise descriptions to closed video pools, failing to reflect real-world searches characterized by fuzzy, multi-dimensional memories on the open web. We present \textbf{RVMS-Bench}, a comprehensive system for evaluating real-world video memory search. It consists of \textbf{1,440 samples} spanning \textbf{20 diverse categories} and \textbf{four duration groups}, sourced from \textbf{real-world open-web videos}. RVMS-Bench utilizes a hierarchical description framework encompassing \textbf{Global Impression, Key Moment, Temporal Context, and Auditory Memory} to mimic realistic multi-dimensional search cues, with all samples strictly verified via a human-in-the-loop protocol. We further propose \textbf{RACLO}, an agentic framework that employs abductive reasoning to simulate the human ``Recall-Search-Verify'' cognitive process, effectively addressing the challenge of searching for videos via fuzzy memories in the real world. Experiments reveal that existing MLLMs still demonstrate insufficient capabilities in real-world Video Retrieval and Moment Localization based on fuzzy memories. We believe this work will facilitate the advancement of video retrieval robustness in real-world unstructured scenarios.

</details>


### [21] [MPA: Multimodal Prototype Augmentation for Few-Shot Learning](https://arxiv.org/abs/2602.10143)
*Liwen Wu,Wei Wang,Lei Zhao,Zhan Gao,Qika Lin,Shaowen Yao,Zuozhu Liu,Bin Pu*

Main category: cs.CV

TL;DR: 提出了一种名为 MPA 的新颖多模态原型增强少样本学习框架，通过语言模型语义增强、多视图数据增强和不确定类别吸收来提高少样本分类性能，并在多个基准测试中取得了显著的 SOTA 结果。


<details>
  <summary>Details</summary>
Motivation: 现有少样本学习方法主要依赖视觉模态，直接从原始支持图像计算原型，缺乏全面的多模态信息，导致性能受限。

Method: MPA 框架包含三个主要组件：1. LLM-based Multi-Variant Semantic Enhancement (LMSE)：利用大语言模型生成多样的类别描述，丰富语义信息。2. Hierarchical Multi-View Augmentation (HMA)：结合自然增强和多视图增强，提高特征多样性。3. Adaptive Uncertain Class Absorber (AUCA)：通过插值和高斯采样引入不确定类别，吸收不确定样本。

Result: 在四个单领域和六个跨领域少样本学习基准测试中，MPA 均取得了优于现有 SOTA 方法的性能。特别是在 5 路 1 样本设置下，MPA 在单领域和跨领域设置下分别比第二优方法高出 12.29% 和 24.56%。

Conclusion: MPA 框架能够有效地利用多模态信息和增强技术，显著提升少样本学习的分类性能，特别是在数据稀疏和领域迁移的挑战性场景下。

Abstract: Recently, few-shot learning (FSL) has become a popular task that aims to recognize new classes from only a few labeled examples and has been widely applied in fields such as natural science, remote sensing, and medical images. However, most existing methods focus only on the visual modality and compute prototypes directly from raw support images, which lack comprehensive and rich multimodal information. To address these limitations, we propose a novel Multimodal Prototype Augmentation FSL framework called MPA, including LLM-based Multi-Variant Semantic Enhancement (LMSE), Hierarchical Multi-View Augmentation (HMA), and an Adaptive Uncertain Class Absorber (AUCA). LMSE leverages large language models to generate diverse paraphrased category descriptions, enriching the support set with additional semantic cues. HMA exploits both natural and multi-view augmentations to enhance feature diversity (e.g., changes in viewing distance, camera angles, and lighting conditions). AUCA models uncertainty by introducing uncertain classes via interpolation and Gaussian sampling, effectively absorbing uncertain samples. Extensive experiments on four single-domain and six cross-domain FSL benchmarks demonstrate that MPA achieves superior performance compared to existing state-of-the-art methods across most settings. Notably, MPA surpasses the second-best method by 12.29% and 24.56% in the single-domain and cross-domain setting, respectively, in the 5-way 1-shot setting.

</details>


### [22] [Multimodal Information Fusion for Chart Understanding: A Survey of MLLMs -- Evolution, Limitations, and Cognitive Enhancement](https://arxiv.org/abs/2602.10138)
*Zhihang Yi,Jian Zhao,Jiancheng Lv,Tao Wang*

Main category: cs.CV

TL;DR: 这篇论文对基于多模态大语言模型（MLLMs）的图表理解研究进行了全面的综述，梳理了面临的挑战、数据集、方法论，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在图表理解领域取得了进展，但该领域的研究仍显零散，缺乏系统性的组织和概述，阻碍了研究人员和实践者对该领域的深入理解和进一步发展。

Method: 该研究通过分析图表理解中的视觉和语言信息融合的挑战，对下游任务和数据集进行了分类（引入了规范和非规范基准的分类法），回顾了从经典深度学习到先进MLLM方法论的演变，并批判性地分析了现有模型的局限性。

Result: 该综述系统地组织了MLLM在图表理解领域的研究现状，包括挑战、数据集、方法论的演变，并指出了当前模型在感知和推理方面的不足。

Conclusion: 本综述旨在为研究人员和实践者提供一个结构化的理解框架，展示MLLMs如何改变图表信息融合，并促进向更鲁棒、更可靠的系统迈进，未来的研究方向包括先进的对齐技术和用于认知增强的强化学习。

Abstract: Chart understanding is a quintessential information fusion task, requiring the seamless integration of graphical and textual data to extract meaning. The advent of Multimodal Large Language Models (MLLMs) has revolutionized this domain, yet the landscape of MLLM-based chart analysis remains fragmented and lacks systematic organization. This survey provides a comprehensive roadmap of this nascent frontier by structuring the domain's core components. We begin by analyzing the fundamental challenges of fusing visual and linguistic information in charts. We then categorize downstream tasks and datasets, introducing a novel taxonomy of canonical and non-canonical benchmarks to highlight the field's expanding scope. Subsequently, we present a comprehensive evolution of methodologies, tracing the progression from classic deep learning techniques to state-of-the-art MLLM paradigms that leverage sophisticated fusion strategies. By critically examining the limitations of current models, particularly their perceptual and reasoning deficits, we identify promising future directions, including advanced alignment techniques and reinforcement learning for cognitive enhancement. This survey aims to equip researchers and practitioners with a structured understanding of how MLLMs are transforming chart information fusion and to catalyze progress toward more robust and reliable systems.

</details>


### [23] [Multi-encoder ConvNeXt Network with Smooth Attentional Feature Fusion for Multispectral Semantic Segmentation](https://arxiv.org/abs/2602.10137)
*Leo Thomas Ramos,Angel D. Sappa*

Main category: cs.CV

TL;DR: 本文提出了一种名为MeCSAFNet的多分支编码器-解码器网络，用于多光谱影像的土地覆盖分割。该模型能够有效融合可见光和非可见光通道的特征，并在两个公开数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理多光谱影像土地覆盖分割时，难以有效融合不同光谱通道的特征，尤其是在处理不同光谱配置（如4通道和6通道输入）时性能存在提升空间。

Method: MeCSAFNet采用多分支编码器-解码器架构，使用ConvNeXt作为编码器分别处理可见光和非可见光通道。每个分支有独立的解码器，并有一个专门的融合解码器用于整合多尺度中间特征。模型集成了CBAM注意力机制和ASAU激活函数。支持4通道（RGB+NIR）和6通道（RGB+NIR+NDVI+NDWI）输入。

Result: 在FBP数据集上，MeCSAFNet-base (6c) 在mIoU上比U-Net (4c/6c) 和SegFormer (4c/6c) 分别高出14.72%-19.62%。在Potsdam数据集上，MeCSAFNet-large (4c) 在mIoU上比DeepLabV3+ (4c/6c) 和SegFormer (4c/6c) 分别高出4.80%-9.11%。紧凑型变体在资源受限环境下也表现良好。

Conclusion: MeCSAFNet是一种有效的多光谱影像土地覆盖分割模型，通过多分支编码器、多尺度特征融合和注意力机制，显著提高了分割精度，并具有良好的通用性和效率。

Abstract: This work proposes MeCSAFNet, a multi-branch encoder-decoder architecture for land cover segmentation in multispectral imagery. The model separately processes visible and non-visible channels through dual ConvNeXt encoders, followed by individual decoders that reconstruct spatial information. A dedicated fusion decoder integrates intermediate features at multiple scales, combining fine spatial cues with high-level spectral representations. The feature fusion is further enhanced with CBAM attention, and the ASAU activation function contributes to stable and efficient optimization. The model is designed to process different spectral configurations, including a 4-channel (4c) input combining RGB and NIR bands, as well as a 6-channel (6c) input incorporating NDVI and NDWI indices. Experiments on the Five-Billion-Pixels (FBP) and Potsdam datasets demonstrate significant performance gains. On FBP, MeCSAFNet-base (6c) surpasses U-Net (4c) by +19.21%, U-Net (6c) by +14.72%, SegFormer (4c) by +19.62%, and SegFormer (6c) by +14.74% in mIoU. On Potsdam, MeCSAFNet-large (4c) improves over DeepLabV3+ (4c) by +6.48%, DeepLabV3+ (6c) by +5.85%, SegFormer (4c) by +9.11%, and SegFormer (6c) by +4.80% in mIoU. The model also achieves consistent gains over several recent state-of-the-art approaches. Moreover, compact variants of MeCSAFNet deliver notable performance with lower training time and reduced inference cost, supporting their deployment in resource-constrained environments.

</details>


### [24] [AD$^2$: Analysis and Detection of Adversarial Threats in Visual Perception for End-to-End Autonomous Driving Systems](https://arxiv.org/abs/2602.10160)
*Ishan Sahu,Somnath Hazra,Somak Aditya,Soumyajit Dey*

Main category: cs.CV

TL;DR: 该研究对最先进的自动驾驶系统在物理和数字攻击下的鲁棒性进行了闭环评估，发现其存在严重漏洞。研究还提出了一种基于注意力机制的轻量级攻击检测模型 AD^2。


<details>
  <summary>Details</summary>
Motivation: 尽管端到端的自动驾驶系统取得了进展，但其对抗鲁棒性研究不足，存在安全隐患。

Method: 在 CARLA 模拟器中，针对 Transfuser 和 Interfuser 两个先进的自动驾驶代理，在黑盒对抗威胁模型下，进行了三种攻击（物理模糊攻击、电磁干扰攻击、数字鬼影攻击）的闭环评估。随后，提出了一种基于注意力机制的轻量级攻击检测模型 AD^2。

Result: 实验表明，所测试的自动驾驶系统在遭受这些攻击时，驾驶得分最多下降 99%。AD^2 模型在多摄像头输入下，相比现有方法，展现出更强的检测能力和计算效率。

Conclusion: 当前的自动驾驶系统对视觉感知层面的物理和数字对抗攻击非常脆弱。提出的 AD^2 模型可以有效地检测这些攻击，为提高自动驾驶系统的安全性提供了一种解决方案。

Abstract: End-to-end autonomous driving systems have achieved significant progress, yet their adversarial robustness remains largely underexplored. In this work, we conduct a closed-loop evaluation of state-of-the-art autonomous driving agents under black-box adversarial threat models in CARLA. Specifically, we consider three representative attack vectors on the visual perception pipeline: (i) a physics-based blur attack induced by acoustic waves, (ii) an electromagnetic interference attack that distorts captured images, and (iii) a digital attack that adds ghost objects as carefully crafted bounded perturbations on images. Our experiments on two advanced agents, Transfuser and Interfuser, reveal severe vulnerabilities to such attacks, with driving scores dropping by up to 99% in the worst case, raising valid safety concerns. To help mitigate such threats, we further propose a lightweight Attack Detection model for Autonomous Driving systems (AD$^2$) based on attention mechanisms that capture spatial-temporal consistency. Comprehensive experiments across multi-camera inputs on CARLA show that our detector achieves superior detection capability and computational efficiency compared to existing approaches.

</details>


### [25] [ArtisanGS: Interactive Tools for Gaussian Splat Selection with AI and Human in the Loop](https://arxiv.org/abs/2602.10173)
*Clement Fuji Tsang,Anita Hu,Or Perel,Carsten Kolve,Maria Shugrina*

Main category: cs.CV

TL;DR: 本文提出了一套交互式工具，用于从3D高斯泼溅（3DGS）场景中选择和分割可编辑的对象，解决了现有技术中可控编辑性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管3DGS在图形学领域日益普及，但从真实场景中提取可操作对象以及进行可控编辑仍然存在挑战。

Method: 提出了一种快速的AI驱动方法，将用户引导的2D选择掩码传播到3DGS选择中，并结合了灵活的手动选择和分割工具，以实现任意的二进制分割。还开发了一种用户引导的局部编辑方法，利用自定义视频扩散模型。

Result: 所提出的工具集在3DGS选择方面优于现有技术，并通过用户引导的局部编辑方法展示了其在下游应用中的效用。用户可以通过灵活的选择工具精确控制AI的修改区域。

Conclusion: 该工具集为用户提供了对3DGS场景中对象选择和编辑的直接控制，无需额外的场景优化，可用于任何真实场景捕获。

Abstract: Representation in the family of 3D Gaussian Splats (3DGS) are growing into a viable alternative to traditional graphics for an expanding number of application, including recent techniques that facilitate physics simulation and animation. However, extracting usable objects from in-the-wild captures remains challenging and controllable editing techniques for this representation are limited. Unlike the bulk of emerging techniques, focused on automatic solutions or high-level editing, we introduce an interactive suite of tools centered around versatile Gaussian Splat selection and segmentation. We propose a fast AI-driven method to propagate user-guided 2D selection masks to 3DGS selections. This technique allows for user intervention in the case of errors and is further coupled with flexible manual selection and segmentation tools. These allow a user to achieve virtually any binary segmentation of an unstructured 3DGS scene. We evaluate our toolset against the state-of-the-art for Gaussian Splat selection and demonstrate their utility for downstream applications by developing a user-guided local editing approach, leveraging a custom Video Diffusion Model. With flexible selection tools, users have direct control over the areas that the AI can modify. Our selection and editing tools can be used for any in-the-wild capture without additional optimization.

</details>


### [26] [When the Prompt Becomes Visual: Vision-Centric Jailbreak Attacks for Large Image Editing Models](https://arxiv.org/abs/2602.10179)
*Jiacheng Hou,Yining Sun,Ruochong Jin,Haochen Han,Fangming Liu,Wai Kin Victor Chan,Alex Jinpeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Vision-Centric Jailbreak Attack (VJA) 的视觉到视觉越狱攻击，通过纯视觉输入绕过图像编辑模型的安全限制，并引入了 IESBench 安全基准来评估此类攻击，同时提出了一种无需训练的防御方法。 



<details>
  <summary>Details</summary>
Motivation: 大型图像编辑模型正从文本指令转向视觉提示编辑，这引入了新的安全风险，即攻击界面本身是视觉化的。因此，需要研究这种视觉输入的潜在安全问题。

Method: 提出 Vision-Centric Jailbreak Attack (VJA)，这是一种纯粹通过视觉输入（如标记、箭头）来传达恶意指令的攻击方法。创建了 IESBench 安全基准来系统地评估图像编辑模型的安全性。提出了一种基于内省多模态推理的训练免费防御方法。

Result: VJA 能够有效地绕过最先进的商业图像编辑模型，在 Nano Banana Pro 上成功率高达 80.9%，在 GPT-Image-1.5 上高达 70.1%。所提出的防御方法在没有辅助模型和几乎没有计算开销的情况下，显著提高了模型的安全性。

Conclusion: 视觉提示编辑引入了新的安全漏洞，本文提出的 VJA 和 IESBench 为研究和解决这些问题提供了工具，而提出的防御方法有效地提高了模型的安全性，为构建安全可信的现代图像编辑系统奠定了基础。

Abstract: Recent advances in large image editing models have shifted the paradigm from text-driven instructions to vision-prompt editing, where user intent is inferred directly from visual inputs such as marks, arrows, and visual-text prompts. While this paradigm greatly expands usability, it also introduces a critical and underexplored safety risk: the attack surface itself becomes visual. In this work, we propose Vision-Centric Jailbreak Attack (VJA), the first visual-to-visual jailbreak attack that conveys malicious instructions purely through visual inputs. To systematically study this emerging threat, we introduce IESBench, a safety-oriented benchmark for image editing models. Extensive experiments on IESBench demonstrate that VJA effectively compromises state-of-the-art commercial models, achieving attack success rates of up to 80.9% on Nano Banana Pro and 70.1% on GPT-Image-1.5. To mitigate this vulnerability, we propose a training-free defense based on introspective multimodal reasoning, which substantially improves the safety of poorly aligned models to a level comparable with commercial systems, without auxiliary guard models and with negligible computational overhead. Our findings expose new vulnerabilities, provide both a benchmark and practical defense to advance safe and trustworthy modern image editing systems. Warning: This paper contains offensive images created by large image editing models.

</details>


### [27] [DEGMC: Denoising Diffusion Models Based on Riemannian Equivariant Group Morphological Convolutions](https://arxiv.org/abs/2602.10221)
*El Hadji S. Diop,Thierno Fall,Mohamed Daoudi*

Main category: cs.CV

TL;DR: 本研究提出了一种结合几何方法和欧几里得群（包括旋转、反射和置换）的等变性的新方法，以解决 DDPM 在几何关键特征提取和网络等变性方面的两个主要问题。


<details>
  <summary>Details</summary>
Motivation: 现有 DDPM 的 U-net 架构在理论上仅具有平移等变性，这限制了其在几何关键特征提取和更一般的对称性处理方面的能力。研究旨在提高 DDPM 的几何特征提取能力和对旋转、反射、置换等更广泛几何变换的等变性。

Method: 引入群形态卷积（group morphological convolutions）的概念，该卷积建立在黎曼流形上，并源于一阶 Hamilton-Jacobi 型偏微分方程（PDE）的粘性解。通过添加对流项并利用特征线法求解 PDE，以更好地捕捉非线性、表示细长几何结构并融合对称性。

Result: 在 MNIST、RotoMNIST 和 CIFAR-10 数据集上的实验表明，该方法相比于基线 DDPM 模型在降噪效果上有显著提升。

Conclusion: 所提出的基于几何方法和欧几里得群等变性的新模型，能够有效解决 DDPM 在几何关键特征提取和网络等变性方面的不足，并在多个数据集上取得了优于基线模型的性能。

Abstract: In this work, we address two major issues in recent Denoising Diffusion Probabilistic Models (DDPM): {\bf 1)} geometric key feature extraction and {\bf 2)} network equivariance. Since the DDPM prediction network relies on the U-net architecture, which is theoretically only translation equivariant, we introduce a geometric approach combined with an equivariance property of the more general Euclidean group, which includes rotations, reflections, and permutations. We introduce the notion of group morphological convolutions in Riemannian manifolds, which are derived from the viscosity solutions of first-order Hamilton-Jacobi-type partial differential equations (PDEs) that act as morphological multiscale dilations and erosions. We add a convection term to the model and solve it using the method of characteristics. This helps us better capture nonlinearities, represent thin geometric structures, and incorporate symmetries into the learning process. Experimental results on the MNIST, RotoMNIST, and CIFAR-10 datasets show noticeable improvements compared to the baseline DDPM model.

</details>


### [28] [XSPLAIN: XAI-enabling Splat-based Prototype Learning for Attribute-aware INterpretability](https://arxiv.org/abs/2602.10239)
*Dominik Galus,Julia Farganus,Tymoteusz Zapala,Mikołaj Czachorowski,Piotr Borycki,Przemysław Spurek,Piotr Syga*

Main category: cs.CV

TL;DR: XSPLAIN 是第一个用于 3D 高斯溅射（3DGS）分类的原位、基于原型的可解释性框架，它通过解耦特征通道来提供可解释性，同时保持决策边界不变，并在用户研究中表现出显著优势。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 表示（如点云）的可解释性方法缺乏对 3DGS 的体积连贯性的捕捉，且 3DGS 本身缺乏模型可解释性和溅射分类能力，阻碍了其在关键领域的应用。

Method: XSPLAIN 采用基于体素聚合的点云网络（PointNet）骨干，并引入一种新颖的可逆正交变换，用于解耦特征通道以提高可解释性，同时保持原始决策边界。解释基于代表性的训练样本。

Result: XSPLAIN 在用户研究（N=51）中获得参与者 48.4% 的偏好，显著优于基线方法（p<0.001），证明了其提供透明度和用户信任的能力，且不影响分类性能。

Conclusion: XSPLAIN 是首个专门为 3DGS 分类设计的可解释性框架，能够提供直观的解释，增强用户对模型的信任，而不会牺牲分类性能。其独特的可逆变换设计是实现这一目标的关键。

Abstract: 3D Gaussian Splatting (3DGS) has rapidly become a standard for high-fidelity 3D reconstruction, yet its adoption in multiple critical domains is hindered by the lack of interpretability of the generation models as well as classification of the Splats. While explainability methods exist for other 3D representations, like point clouds, they typically rely on ambiguous saliency maps that fail to capture the volumetric coherence of Gaussian primitives. We introduce XSPLAIN, the first ante-hoc, prototype-based interpretability framework designed specifically for 3DGS classification. Our approach leverages a voxel-aggregated PointNet backbone and a novel, invertible orthogonal transformation that disentangles feature channels for interpretability while strictly preserving the original decision boundaries. Explanations are grounded in representative training examples, enabling intuitive ``this looks like that'' reasoning without any degradation in classification performance. A rigorous user study (N=51) demonstrates a decisive preference for our approach: participants selected XSPLAIN explanations 48.4\% of the time as the best, significantly outperforming baselines $(p<0.001)$, showing that XSPLAIN provides transparency and user trust. The source code for this work is available at: https://github.com/Solvro/ml-splat-xai

</details>


### [29] [PMMA: The Polytechnique Montreal Mobility Aids Dataset](https://arxiv.org/abs/2602.10259)
*Qingwu Liu,Nicolas Saunier,Guillaume-Alexandre Bilodeau*

Main category: cs.CV

TL;DR: 本研究发布了一个新的行人（包括使用辅助设备者）目标检测数据集PMMA，并评估了七种目标检测模型和三种跟踪算法在该数据集上的表现，其中YOLOX、Deformable DETR和Faster R-CNN表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测数据集在包含使用轮椅、拐杖和助行器等辅助设备的行人方面存在不足，因此需要一个专门的数据集来推动相关研究。

Method: 收集了一个包含九类行人的室外数据集PMMA，包括普通行人、拐杖使用者、两种助行器使用者（行走或休息）、以及五种轮椅使用者（包括推空轮椅、推满轮椅的整个团队、推轮椅的人以及坐在轮椅上的人）。使用MMDetection框架在PMMA数据集上实现了七个目标检测模型（Faster R-CNN, CenterNet, YOLOX, DETR, Deformable DETR, DINO, RT-DETR）和三个跟踪算法（ByteTrack, BOT-SORT, OC-SORT）的基准测试。

Result: 在目标检测任务上，YOLOX、Deformable DETR和Faster R-CNN取得了最佳性能。在跟踪任务上，三种算法的表现差异不大。

Conclusion: PMMA数据集为评估和开发针对使用辅助设备的行人的目标检测和跟踪算法提供了一个重要的基准。YOLOX、Deformable DETR和Faster R-CNN在当前数据集上展现出良好的检测能力。

Abstract: This study introduces a new object detection dataset of pedestrians using mobility aids, named PMMA. The dataset was collected in an outdoor environment, where volunteers used wheelchairs, canes, and walkers, resulting in nine categories of pedestrians: pedestrians, cane users, two types of walker users, whether walking or resting, five types of wheelchair users, including wheelchair users, people pushing empty wheelchairs, and three types of users pushing occupied wheelchairs, including the entire pushing group, the pusher and the person seated on the wheelchair. To establish a benchmark, seven object detection models (Faster R-CNN, CenterNet, YOLOX, DETR, Deformable DETR, DINO, and RT-DETR) and three tracking algorithms (ByteTrack, BOT-SORT, and OC-SORT) were implemented under the MMDetection framework. Experimental results show that YOLOX, Deformable DETR, and Faster R-CNN achieve the best detection performance, while the differences among the three trackers are relatively small. The PMMA dataset is publicly available at https://doi.org/10.5683/SP3/XJPQUG, and the video processing and model training code is available at https://github.com/DatasetPMMA/PMMA.

</details>


### [30] [Enhancing Underwater Images via Adaptive Semantic-aware Codebook Learning](https://arxiv.org/abs/2602.10586)
*Bosen Lin,Feng Gao,Yanwei Yu,Junyu Dong,Qian Du*

Main category: cs.CV

TL;DR: 提出了一种名为SUCode的语义感知水下图像增强网络，通过像素级离散码本来处理异构退化问题，并结合了GCAM和FAFF模块来恢复颜色和纹理，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有水下图像增强方法使用单一全局模型处理图像，忽略了异构水下场景中不同区域的退化差异，导致颜色失真和细节丢失。

Method: 提出SUCode网络，采用语义感知、像素级的离散码本表示来处理异构退化。使用三阶段训练范式避免伪真值污染。结合门控通道注意力模块（GCAM）和频率感知特征融合（FAFF）模块来恢复颜色和纹理。

Result: 在多个基准数据集上进行了广泛的实验，SUCode在有参考和无参考指标上均取得了最先进的性能，优于最近的UIE方法。

Conclusion: SUCode通过语义感知码本表示和有效的特征融合模块，能够有效地处理异构水下图像的退化问题，实现高质量的水下图像增强。

Abstract: Underwater Image Enhancement (UIE) is an ill-posed problem where natural clean references are not available, and the degradation levels vary significantly across semantic regions. Existing UIE methods treat images with a single global model and ignore the inconsistent degradation of different scene components. This oversight leads to significant color distortions and loss of fine details in heterogeneous underwater scenes, especially where degradation varies significantly across different image regions. Therefore, we propose SUCode (Semantic-aware Underwater Codebook Network), which achieves adaptive UIE from semantic-aware discrete codebook representation. Compared with one-shot codebook-based methods, SUCode exploits semantic-aware, pixel-level codebook representation tailored to heterogeneous underwater degradation. A three-stage training paradigm is employed to represent raw underwater image features to avoid pseudo ground-truth contamination. Gated Channel Attention Module (GCAM) and Frequency-Aware Feature Fusion (FAFF) jointly integrate channel and frequency cues for faithful color restoration and texture recovery. Extensive experiments on multiple benchmarks demonstrate that SUCode achieves state-of-the-art performance, outperforming recent UIE methods on both reference and no-reference metrics. The code will be made public available at https://github.com/oucailab/SUCode.

</details>


### [31] [Colorimeter-Supervised Skin Tone Estimation from Dermatoscopic Images for Fairness Auditing](https://arxiv.org/abs/2602.10265)
*Marin Benčević,Krešimir Romić,Ivana Hartmann Tolić,Irena Galić*

Main category: cs.CV

TL;DR: 本研究开发了基于神经网络的 Fitzpatrick 皮肤类型和个体类型角度 (ITA) 估计算法，以解决皮肤镜图像诊断中存在的皮肤色调差异问题，并发布了相应的开源工具。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经网络的皮肤镜图像诊断模型在不同肤色人群中表现存在差异，但公开数据集缺乏可靠的肤色标注，阻碍了对模型公平性的审计。

Method: 研究人员开发了两个神经网络：一个使用序数回归来预测 Fitzpatrick 皮肤类型，另一个使用颜色回归来预测 ITA。这些模型以真人 Fitzpatrick 标签和比色计测量值为目标进行训练，并利用合成和真实皮肤镜及临床图像进行了广泛预训练。

Result:  Fitzpatrick 模型在预测皮肤类型方面达到了与人类众包标注相当的一致性，而 ITA 预测与比色计衍生的 ITA 高度一致，且显著优于像素平均方法。在 ISIC 2020 和 MILK10k 数据集上的应用表明， Fitzpatrick V 类和 VI 类的受试者占比不到 1%。

Conclusion: 该研究首次提出了一个经过比色计测​​量验证的皮肤镜肤色估计算法神经网络，并发布了开源代码和预训练模型，支持了皮肤镜诊断模型在不同肤色群体中存在临床相关性能差异的证据，并为快速肤色标注和偏见审计提供了工具。

Abstract: Neural-network-based diagnosis from dermatoscopic images is increasingly used for clinical decision support, yet studies report performance disparities across skin tones. Fairness auditing of these models is limited by the lack of reliable skin-tone annotations in public dermatoscopy datasets. We address this gap with neural networks that predict Fitzpatrick skin type via ordinal regression and the Individual Typology Angle (ITA) via color regression, using in-person Fitzpatrick labels and colorimeter measurements as targets. We further leverage extensive pretraining on synthetic and real dermatoscopic and clinical images. The Fitzpatrick model achieves agreement comparable to human crowdsourced annotations, and ITA predictions show high concordance with colorimeter-derived ITA, substantially outperforming pixel-averaging approaches. Applying these estimators to ISIC 2020 and MILK10k, we find that fewer than 1% of subjects belong to Fitzpatrick types V and VI. We release code and pretrained models as an open-source tool for rapid skin-tone annotation and bias auditing. This is, to our knowledge, the first dermatoscopic skin-tone estimation neural network validated against colorimeter measurements, and it supports growing evidence of clinically relevant performance gaps across skin-tone groups.

</details>


### [32] [A Low-Rank Defense Method for Adversarial Attack on Diffusion Models](https://arxiv.org/abs/2602.10319)
*Jiaxuan Zhu,Siyu Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为LoRD（Low-Rank Defense）的低秩防御策略，用于防御针对潜在扩散模型（LDMs）的对抗性攻击，并能有效检测和防御对抗性样本，同时保证模型生成高质量图像的能力。


<details>
  <summary>Details</summary>
Motivation: 鉴于扩散模型及其微调过程中的对抗性攻击发展迅速，为防止滥用并确保扩散模型的实际应用，开发相应的防御策略至关重要。

Method: LoRD策略结合了LoRA（Low-Rank Adaptation）模块，并引入了合并思想和一个平衡参数，用于检测和防御对抗性样本。基于LoRD，作者构建了一个防御流水线，将学习到的LoRD模块应用于扩散模型。

Result: 在人脸和风景图像上的广泛实验表明，LoRD方法在对抗性攻击防御方面显著优于基线方法，并且经过LoRD微调的LDM在同时处理对抗性和干净样本时仍能生成高质量图像。

Conclusion: LoRD是一种有效的防御策略，可以成功地防御针对LDM的对抗性攻击，同时保持生成图像的质量，为对抗性攻击的防御提供了新的解决方案。

Abstract: Recently, adversarial attacks for diffusion models as well as their fine-tuning process have been developed rapidly. To prevent the abuse of these attack algorithms from affecting the practical application of diffusion models, it is critical to develop corresponding defensive strategies. In this work, we propose an efficient defensive strategy, named Low-Rank Defense (LoRD), to defend the adversarial attack on Latent Diffusion Models (LDMs). LoRD introduces the merging idea and a balance parameter, combined with the low-rank adaptation (LoRA) modules, to detect and defend the adversarial samples. Based on LoRD, we build up a defense pipeline that applies the learned LoRD modules to help diffusion models defend against attack algorithms. Our method ensures that the LDM fine-tuned on both adversarial and clean samples can still generate high-quality images. To demonstrate the effectiveness of our approach, we conduct extensive experiments on facial and landscape images, and our method shows significantly better defense performance compared to the baseline methods.

</details>


### [33] [ERGO: Excess-Risk-Guided Optimization for High-Fidelity Monocular 3D Gaussian Splatting](https://arxiv.org/abs/2602.10278)
*Zehua Ma,Hanhui Li,Zhenyu Xie,Xiaonan Luo,Michael Kampffmeyer,Feng Gao,Xiaodan Liang*

Main category: cs.CV

TL;DR: 提出ERGO框架，通过分解优化损失为“过剩风险”和“贝叶斯误差”，自适应调整损失权重，并结合几何和纹理感知目标，有效利用不完美的辅助视图生成高质量3D内容。


<details>
  <summary>Details</summary>
Motivation: 从单张图像生成3D内容具有挑战性，因为遮挡区域缺乏几何和纹理信息。现有的生成模型产生的辅助视图存在几何不一致和纹理错位，会加剧3D重建中的伪影。

Method: 提出ERGO（Excess Risk Guided Optimization）框架，将3D高斯泼溅的优化损失分解为量化参数次优性的“过剩风险”和模拟合成视图固有噪声的“贝叶斯误差”。ERGO动态估计视图特定的过剩风险，并自适应调整损失权重。此外，引入了几何感知和纹理感知目标，形成全局-局部协同优化。

Result: ERGO框架能够有效应对监督噪声，并稳定地提升重建3D内容的几何保真度和纹理质量。在Google Scanned Objects和OmniObject3D数据集上的实验结果表明，ERGO优于现有最先进的方法。

Conclusion: ERGO框架通过其创新的损失分解和自适应加权机制，能够有效地利用不完美的辅助视图生成高质量的3D内容，克服了现有方法的局限性。

Abstract: Generating 3D content from a single image remains a fundamentally challenging and ill-posed problem due to the inherent absence of geometric and textural information in occluded regions. While state-of-the-art generative models can synthesize auxiliary views to provide additional supervision, these views inevitably contain geometric inconsistencies and textural misalignments that propagate and amplify artifacts during 3D reconstruction. To effectively harness these imperfect supervisory signals, we propose an adaptive optimization framework guided by excess risk decomposition, termed ERGO. Specifically, ERGO decomposes the optimization losses in 3D Gaussian splatting into two components, i.e., excess risk that quantifies the suboptimality gap between current and optimal parameters, and Bayes error that models the irreducible noise inherent in synthesized views. This decomposition enables ERGO to dynamically estimate the view-specific excess risk and adaptively adjust loss weights during optimization. Furthermore, we introduce geometry-aware and texture-aware objectives that complement the excess-risk-derived weighting mechanism, establishing a synergistic global-local optimization paradigm. Consequently, ERGO demonstrates robustness against supervision noise while consistently enhancing both geometric fidelity and textural quality of the reconstructed 3D content. Extensive experiments on the Google Scanned Objects dataset and the OmniObject3D dataset demonstrate the superiority of ERGO over existing state-of-the-art methods.

</details>


### [34] [Flow Matching with Uncertainty Quantification and Guidance](https://arxiv.org/abs/2602.10326)
*Juyeop Han,Lukas Lao Beyer,Sertac Karaman*

Main category: cs.CV

TL;DR: 提出一种名为 UA-Flow 的新方法，通过预测速度场及其不确定性来增强流匹配模型，从而评估样本的可靠性并生成更高质量的样本。


<details>
  <summary>Details</summary>
Motivation: 现有的基于采样生成模型（如流匹配）可能生成质量不一致或下降的样本，需要一种方法来评估样本可靠性并提高生成质量。

Method: 通过预测速度场和异方差不确定性来扩展流匹配模型，称为 UA-Flow。通过将速度不确定性传播到流动力学中来估计每个样本的不确定性，并利用这些不确定性信号通过不确定性感知分类器引导和无分类器引导来指导生成。

Result: 在图像生成实验中，UA-Flow 生成的不确定性信号与样本保真度的相关性比基线方法更高，并且不确定性引导采样进一步提高了生成质量。

Conclusion: UA-Flow 是一种有效的流匹配模型扩展，可以量化样本不确定性并利用其来改进生成模型的样本质量和可靠性。

Abstract: Despite the remarkable success of sampling-based generative models such as flow matching, they can still produce samples of inconsistent or degraded quality. To assess sample reliability and generate higher-quality outputs, we propose uncertainty-aware flow matching (UA-Flow), a lightweight extension of flow matching that predicts the velocity field together with heteroscedastic uncertainty. UA-Flow estimates per-sample uncertainty by propagating velocity uncertainty through the flow dynamics. These uncertainty estimates act as a reliability signal for individual samples, and we further use them to steer generation via uncertainty-aware classifier guidance and classifier-free guidance. Experiments on image generation show that UA-Flow produces uncertainty signals more highly correlated with sample fidelity than baseline methods, and that uncertainty-guided sampling further improves generation quality.

</details>


### [35] [Conditional Uncertainty-Aware Political Deepfake Detection with Stochastic Convolutional Neural Networks](https://arxiv.org/abs/2602.10343)
*Rafael-Petruţ Gardoş*

Main category: cs.CV

TL;DR: 本研究提出了一种不确定性感知的政治深度伪造图像检测方法，通过随机卷积神经网络和决策导向的可靠性框架，不仅提供预测，还能量化预测的不确定性，从而支持高风险场景下的风险感知审核策略。


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造检测器通常只提供点预测，无法指示何时输出不可靠，这在高风险的政治环境中是一个关键的局限性，可能影响信息完整性、公众信任和民主进程。

Method: 构建了一个政治图像数据集，并使用ResNet-18和EfficientNet-B4两个预训练的CNN模型进行微调。研究了确定性推理、单次随机预测、蒙特卡洛 Dropout、温度缩放和基于集成的不确定性代理等方法。通过校准质量、评分规则和预测误差对不确定性进行评估，并采用ROC-AUC、校准指标和生成器分离的OOD性能进行评估。

Result: 研究表明，校准后的概率输出和不确定性估计能够实现风险感知的审核策略。置信度带分析进一步阐明了在何种情况下，不确定性估计能提供超越预测置信度的操作价值。

Conclusion: 不确定性感知方法在政治深度伪造检测中具有实际应用价值，能够帮助区分可靠的预测和不可靠的预测，为高风险场景下的决策提供支持，并明确了其收益和局限性。

Abstract: Recent advances in generative image models have enabled the creation of highly realistic political deepfakes, posing risks to information integrity, public trust, and democratic processes. While automated deepfake detectors are increasingly deployed in moderation and investigative pipelines, most existing systems provide only point predictions and fail to indicate when outputs are unreliable, being an operationally critical limitation in high-stakes political contexts. This work investigates conditional, uncertainty-aware political deepfake detection using stochastic convolutional neural networks within an empirical, decision-oriented reliability framework. Rather than treating uncertainty as a purely Bayesian construct, it is evaluated through observable criteria, including calibration quality, proper scoring rules, and its alignment with prediction errors under both global and confidence-conditioned analyses. A politically focused binary image dataset is constructed via deterministic metadata filtering from a large public real-synthetic corpus. Two pretrained CNN backbones (ResNet-18 and EfficientNet-B4) are fully fine-tuned for classification. Deterministic inference is compared with single-pass stochastic prediction, Monte Carlo dropout with multiple forward passes, temperature scaling, and ensemble-based uncertainty surrogates. Evaluation reports ROC-AUC, thresholded confusion matrices, calibration metrics, and generator-disjoint out-of-distribution performance. Results demonstrate that calibrated probabilistic outputs and uncertainty estimates enable risk-aware moderation policies. A systematic confidence-band analysis further clarifies when uncertainty provides operational value beyond predicted confidence, delineating both the benefits and limitations of uncertainty-aware deepfake detection in political settings.

</details>


### [36] [Monte Carlo Maximum Likelihood Reconstruction for Digital Holography with Speckle](https://arxiv.org/abs/2602.10344)
*Xi Chen,Arian Maleki,Shirin Jalali*

Main category: cs.CV

TL;DR: 本文提出了一种名为PGD-MC的随机线性代数方法，用于解决数字全息图高分辨率成像中的散斑去噪问题。该方法通过避免高维矩阵求逆，提高了最大似然估计（MLE）的计算效率和可扩展性，并能处理更精确的光阑模型，从而在准确性和速度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在相干成像（如数字全息图）中，散斑是一种乘性噪声，给图像重建带来挑战。虽然最大似然估计（MLE）是处理散斑的原则性框架，但在高分辨率、有限光阑的数字全息系统中，其高昂的计算成本（尤其是高维矩阵求逆）阻碍了其应用，使得使用物理上精确的光阑模型变得不可行。

Method: 提出了一种随机线性代数方法，称为投影梯度下降与蒙特卡洛估计（PGD-MC）。该方法利用感知矩阵的结构特性，并使用共轭梯度法来评估似然梯度，从而在不进行显式矩阵求逆的情况下实现可扩展的MLE优化。这使得算法能够支持准确的光阑建模，而无需为了可计算性而进行简化假设。

Result: PGD-MC框架在各种物理上精确的光阑模型下都表现出鲁棒性，在重建质量和计算效率方面取得了显著改进，并且能够有效地扩展到高分辨率的数字全息图。实验结果表明，PGD-MC在准确性和速度上持续优于之前的即插即用（Plug-and-Play）模型迭代重建方法。

Conclusion: PGD-MC是一种灵活有效的基于MLE的重建框架，适用于有限光阑的数字全息图成像。该方法通过结合随机线性代数和蒙特卡洛估计，克服了传统MLE方法在高分辨率和精确光阑建模方面的计算障碍，并在重建质量和效率上取得了显著提升。

Abstract: In coherent imaging, speckle is statistically modeled as multiplicative noise, posing a fundamental challenge for image reconstruction. While maximum likelihood estimation (MLE) provides a principled framework for speckle mitigation, its application to coherent imaging system such as digital holography with finite apertures is hindered by the prohibitive cost of high-dimensional matrix inversion, especially at high resolutions. This computational burden has prevented the use of MLE-based reconstruction with physically accurate aperture modeling. In this work, we propose a randomized linear algebra approach that enables scalable MLE optimization without explicit matrix inversions in gradient computation. By exploiting the structural properties of sensing matrix and using conjugate gradient for likelihood gradient evaluation, the proposed algorithm supports accurate aperture modeling without the simplifying assumptions commonly imposed for tractability. We term the resulting method projected gradient descent with Monte Carlo estimation (PGD-MC). The proposed PGD-MC framework (i) demonstrates robustness to diverse and physically accurate aperture models, (ii) achieves substantial improvements in reconstruction quality and computational efficiency, and (iii) scales effectively to high-resolution digital holography. Extensive experiments incorporating three representative denoisers as regularization show that PGD-MC provides a flexible and effective MLE-based reconstruction framework for digital holography with finite apertures, consistently outperforming prior Plug-and-Play model-based iterative reconstruction methods in both accuracy and speed. Our code is available at: https://github.com/Computational-Imaging-RU/MC_Maximum_Likelihood_Digital_Holography_Speckle.

</details>


### [37] [Comp2Comp: Open-Source Software with FDA-Cleared Artificial Intelligence Algorithms for Computed Tomography Image Analysis](https://arxiv.org/abs/2602.10364)
*Adrit Rao,Malte Jensen,Andrea T. Fisher,Louis Blankemeier,Pauline Berens,Arash Fereydooni,Seth Lirette,Eren Alkan,Felipe C. Kitamura,Juan M. Zambrano Chaves,Eduardo Reis,Arjun Desai,Marc H. Willis,Jason Hom,Andrew Johnston,Leon Lenchik,Robert D. Boutin,Eduardo M. J. M. Farina,Augusto S. Serpa,Marcelo S. Takahashi,Jordan Perchik,Steven A. Rothenberg,Jamie L. Schroeder,Ross Filice,Leonardo K. Bittencourt,Hari Trivedi,Marly van Assen,John Mongan,Kimberly Kallianos,Oliver Aalami,Akshay S. Chaudhari*

Main category: cs.CV

TL;DR: 该研究开发并验证了两个完全开源的、已获得 FDA 510(k) 批准的深度学习 AI 管道（AAQ 和 BMD），用于从 CT 扫描中自动提取影像学生物标志物，以量化腹主动脉瘤大小和评估骨密度，结果表明其准确性足以用于临床，并提高了透明度。


<details>
  <summary>Details</summary>
Motivation: 现有开源影像分析解决方案缺乏严格验证，而商业解决方案不透明，可能导致部署失败。研究旨在通过开发和验证完全开源且已获 FDA 批准的深度学习管道来解决这些问题。

Method: 开发了两个深度学习管道：腹主动脉定量（AAQ）用于分割腹主动脉并评估动脉瘤大小；骨矿物质密度（BMD）估计用于分割椎体并评估骨密度和骨质疏松风险。AAQ 的准确性通过与放射科医生的测量值进行比较来评估（258 例 CT 扫描）。BMD 的准确性通过与 DXA 扫描结果进行比较来评估（371 例 CT 扫描）。

Result: AAQ 的最大主动脉直径测量平均绝对误差为 1.57 mm。BMD 的二元分类（低 vs. 正常骨密度）的敏感性为 81.0%，特异性为 78.4%。

Conclusion: Comp2Comp 的 AAQ 和 BMD 管道准确性足以用于临床。开源这些算法提高了 FDA 清晰流程的透明度，允许医院在临床试点前进行测试，并为研究人员提供了最佳实践方法。

Abstract: Artificial intelligence allows automatic extraction of imaging biomarkers from already-acquired radiologic images. This paradigm of opportunistic imaging adds value to medical imaging without additional imaging costs or patient radiation exposure. However, many open-source image analysis solutions lack rigorous validation while commercial solutions lack transparency, leading to unexpected failures when deployed. Here, we report development and validation for two of the first fully open-sourced, FDA-510(k)-cleared deep learning pipelines to mitigate both challenges: Abdominal Aortic Quantification (AAQ) and Bone Mineral Density (BMD) estimation are both offered within the Comp2Comp package for opportunistic analysis of computed tomography scans. AAQ segments the abdominal aorta to assess aneurysm size; BMD segments vertebral bodies to estimate trabecular bone density and osteoporosis risk. AAQ-derived maximal aortic diameters were compared against radiologist ground-truth measurements on 258 patient scans enriched for abdominal aortic aneurysms from four external institutions. BMD binary classifications (low vs. normal bone density) were compared against concurrent DXA scan ground truths obtained on 371 patient scans from four external institutions. AAQ had an overall mean absolute error of 1.57 mm (95% CI 1.38-1.80 mm). BMD had a sensitivity of 81.0% (95% CI 74.0-86.8%) and specificity of 78.4% (95% CI 72.3-83.7%). Comp2Comp AAQ and BMD demonstrated sufficient accuracy for clinical use. Open-sourcing these algorithms improves transparency of typically opaque FDA clearance processes, allows hospitals to test the algorithms before cumbersome clinical pilots, and provides researchers with best-in-class methods.

</details>


### [38] [HII-DPO: Eliminate Hallucination via Accurate Hallucination-Inducing Counterfactual Images](https://arxiv.org/abs/2602.10425)
*Yilin Yang,Zhenghui Guo,Yuke Wang,Omprakash Gnawali,Sheng Di,Chengming Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种合成诱导幻觉图像（HIIs）的新方法，揭示了视觉语言模型（VLMs）中一种由语言偏差引起的、与场景相关的幻觉模式（模型倾向于提及场景中的典型物体，即使视觉证据缺失）。作者还提出了掩码对象幻觉（MOH）基准来评估此问题，并利用HIIs构建了用于微调的数据集，实验证明该方法能有效减轻幻觉并保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（VLMs）在多模态任务中表现出色，但容易产生由语言偏差引起的幻觉。现有的缓解方法往往忽略了驱动幻觉的语言偏差模式。

Method: 1. 设计了一种新的管道来合成诱导幻觉的图像（HIIs）。 2. 利用合成的HIIs，揭示了一种与场景相关的幻觉模式：模型倾向于提及场景中的典型物体，即使视觉证据被移除。 3. 建立掩码对象幻觉（MOH）基准来量化VLMs对该模式的易感性。 4. 利用HIIs构建高质量的偏好数据集进行微调。

Result: 该方法能够有效缓解幻觉，同时保持模型的通用能力。与现有最先进的方法相比，在标准的幻觉基准测试中，该方法取得了高达38%的改进。

Conclusion: 通过合成诱导幻觉图像（HIIs）并建立掩码对象幻觉（MOH）基准，该研究有效揭示并量化了视觉语言模型中由语言偏差驱动的幻觉模式。利用HIIs进行微调能够显著降低模型的幻觉，同时保持其整体性能。

Abstract: Large Vision-Language Models (VLMs) have achieved remarkable success across diverse multimodal tasks but remain vulnerable to hallucinations rooted in inherent language bias. Despite recent progress, existing hallucination mitigation methods often overlook the underlying hallucination patterns driven by language bias. In this work, we design a novel pipeline to accurately synthesize Hallucination-Inducing Images (HIIs). Using synthesized HIIs, we reveal a consistent scene-conditioned hallucination pattern: models tend to mention objects that are highly typical of the scene even when visual evidence is removed. To quantify the susceptibility of VLMs to this hallucination pattern, we establish the Masked-Object-Hallucination (MOH) benchmark to rigorously evaluate existing state-of-the-art alignment frameworks. Finally, we leverage HIIs to construct high-quality preference datasets for fine-grained alignment. Experimental results demonstrate that our approach effectively mitigates hallucinations while preserving general model capabilities. Specifically, our method achieves up to a 38% improvement over the current state-of-the-art on standard hallucination benchmarks.

</details>


### [39] [Enhancing Predictability of Multi-Tenant DNN Inference for Autonomous Vehicles' Perception](https://arxiv.org/abs/2602.11004)
*Liangkai Liu,Kang G. Shin,Jinkyu Lee,Chengmo Yang,Weisong Shi*

Main category: cs.CV

TL;DR: 提出一种名为 PP-DNN 的可预测感知系统，通过动态选择关键帧和感兴趣区域（ROIs）来减少图像数据处理量，从而在保持准确性的同时提高自动驾驶车辆（AVs）中深度神经网络（DNNs）的推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶车辆（AVs）感知系统在实时DNN推理方面面临计算需求与资源限制之间的巨大差距，大多数研究集中于通过模型压缩来优化推理时间。本文旨在探索一种新的方法，通过减少需要处理的图像数据量来提高效率。

Method: PP-DNN系统首先利用一个ROI生成器根据帧的相似性和交通场景识别关键帧和ROI。然后，利用FLOPs预测器根据动态确定的关键帧和ROI预测MACs。ROI调度器负责协调多个DNN模型处理关键帧和ROI。最后，设计了一个用于非关键帧感知的检测预测器。

Result: 在BDD100K和nuScenes数据集上评估显示，PP-DNN显著提高了感知可预测性，融合帧数量最多可增加7.3倍，融合延迟减少超过2.6倍，融合延迟变化减少超过2.3倍，检测完整性提高75.4%，成本效益提高高达98%。

Conclusion: PP-DNN通过动态选择关键帧和ROI，有效解决了自动驾驶车辆中DNN推理的效率和可预测性问题，实现了在有限资源下更高效、更可靠的感知。

Abstract: Autonomous vehicles (AVs) rely on sensors and deep neural networks (DNNs) to perceive their surrounding environment and make maneuver decisions in real time. However, achieving real-time DNN inference in the AV's perception pipeline is challenging due to the large gap between the computation requirement and the AV's limited resources. Most, if not all, of existing studies focus on optimizing the DNN inference time to achieve faster perception by compressing the DNN model with pruning and quantization. In contrast, we present a Predictable Perception system with DNNs (PP-DNN) that reduce the amount of image data to be processed while maintaining the same level of accuracy for multi-tenant DNNs by dynamically selecting critical frames and regions of interest (ROIs). PP-DNN is based on our key insight that critical frames and ROIs for AVs vary with the AV's surrounding environment. However, it is challenging to identify and use critical frames and ROIs in multi-tenant DNNs for predictable inference. Given image-frame streams, PP-DNN leverages an ROI generator to identify critical frames and ROIs based on the similarities of consecutive frames and traffic scenarios. PP-DNN then leverages a FLOPs predictor to predict multiply-accumulate operations (MACs) from the dynamic critical frames and ROIs. The ROI scheduler coordinates the processing of critical frames and ROIs with multiple DNN models. Finally, we design a detection predictor for the perception of non-critical frames. We have implemented PP-DNN in an ROS-based AV pipeline and evaluated it with the BDD100K and the nuScenes dataset. PP-DNN is observed to significantly enhance perception predictability, increasing the number of fusion frames by up to 7.3x, reducing the fusion delay by >2.6x and fusion-delay variations by >2.3x, improving detection completeness by 75.4% and the cost-effectiveness by up to 98% over the baseline.

</details>


### [40] [Towards Remote Sensing Change Detection with Neural Memory](https://arxiv.org/abs/2602.10491)
*Zhenyu Yang,Gensheng Pei,Yazhou Yao,Tianfei Zhou,Lizhong Ding,Fumin Shen*

Main category: cs.CV

TL;DR: 本文提出了一种名为 ChangeTitans 的基于 Titans 的遥感变化检测框架，通过引入 VTitans 视觉骨干和 TS-CBAM 融合模块，在保持计算效率的同时，能够有效捕捉长程依赖关系和精细的时空关系，并在多个基准数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥感变化检测方法在捕捉长程依赖性和计算效率之间存在挑战。Transformer 模型虽然能捕捉全局上下文，但其二次复杂度难以扩展，而线性注意力方法又难以捕捉复杂时空关系。

Method: 提出基于 Titans 的 ChangeTitans 框架，核心包括：1. VTitans：首个基于 Titans 的视觉骨干，结合神经记忆和分段局部注意力，捕捉长程依赖并降低计算开销。2. VTitan-Adapter：一个分层适配器，用于精炼多尺度特征。3. TS-CBAM：一个双流融合模块，利用跨时间注意力抑制伪变化，提高检测精度。

Result: 在 LEVIR-CD、WHU-CD、LEVIR-CD+ 和 SYSU-CD 四个基准数据集上进行了实验评估。ChangeTitans 在 LEVIR-CD 数据集上取得了 84.36% 的 IoU 和 91.52% 的 F1-score，达到最先进水平，同时保持了计算竞争力。

Conclusion: ChangeTitans 框架能够有效地捕捉遥感影像中的长程依赖关系和复杂的时空信息，解决了现有方法的局限性，并在多个数据集上取得了优异的性能，证明了其在遥感变化检测任务上的有效性。

Abstract: Remote sensing change detection is essential for environmental monitoring, urban planning, and related applications. However, current methods often struggle to capture long-range dependencies while maintaining computational efficiency. Although Transformers can effectively model global context, their quadratic complexity poses scalability challenges, and existing linear attention approaches frequently fail to capture intricate spatiotemporal relationships. Drawing inspiration from the recent success of Titans in language tasks, we present ChangeTitans, the Titans-based framework for remote sensing change detection. Specifically, we propose VTitans, the first Titans-based vision backbone that integrates neural memory with segmented local attention, thereby capturing long-range dependencies while mitigating computational overhead. Next, we present a hierarchical VTitans-Adapter to refine multi-scale features across different network layers. Finally, we introduce TS-CBAM, a two-stream fusion module leveraging cross-temporal attention to suppress pseudo-changes and enhance detection accuracy. Experimental evaluations on four benchmark datasets (LEVIR-CD, WHU-CD, LEVIR-CD+, and SYSU-CD) demonstrate that ChangeTitans achieves state-of-the-art results, attaining \textbf{84.36\%} IoU and \textbf{91.52\%} F1-score on LEVIR-CD, while remaining computationally competitive.

</details>


### [41] [End-to-End LiDAR optimization for 3D point cloud registration](https://arxiv.org/abs/2602.10492)
*Siddhant Katyan,Marc-André Gardner,Jean-François Lalonde*

Main category: cs.CV

TL;DR: 提出一种自适应激光雷达感知框架，通过将配准反馈集成到传感循环中，动态调整传感器参数，以联合优化激光雷达采集和配准超参数，从而提高配准精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的点云配准方法在固定激光雷达配置下操作，导致数据采集不佳和显著的计算开销。研究动机是克服这些限制，通过自适应地调整传感器参数来优化数据采集和配准过程。

Method: 开发了一个自适应激光雷达感知框架，该框架将配准反馈集成到传感循环中，以动态调整激光雷达传感器参数。这可以联合优化激光雷达采集和配准超参数，以实现最佳的点密度、噪声和稀疏性平衡。

Result: 在CARLA模拟中进行的评估表明，该方法在点云配准精度和效率方面优于固定参数基线，同时保持了泛化能力。

Conclusion: 自适应激光雷达感知框架能够通过动态调整传感器参数并集成配准反馈来提高激光雷达数据采集和点云配准的准确性和效率，这对于自动驾驶感知和机器人应用具有重要意义。

Abstract: LiDAR sensors are a key modality for 3D perception, yet they are typically designed independently of downstream tasks such as point cloud registration. Conventional registration operates on pre-acquired datasets with fixed LiDAR configurations, leading to suboptimal data collection and significant computational overhead for sampling, noise filtering, and parameter tuning. In this work, we propose an adaptive LiDAR sensing framework that dynamically adjusts sensor parameters, jointly optimizing LiDAR acquisition and registration hyperparameters. By integrating registration feedback into the sensing loop, our approach optimally balances point density, noise, and sparsity, improving registration accuracy and efficiency. Evaluations in the CARLA simulation demonstrate that our method outperforms fixed-parameter baselines while retaining generalization abilities, highlighting the potential of adaptive LiDAR for autonomous perception and robotic applications.

</details>


### [42] [Characterizing and Optimizing the Spatial Kernel of Multi Resolution Hash Encodings](https://arxiv.org/abs/2602.10495)
*Tianxiang Dai,Jonathan Fan*

Main category: cs.CV

TL;DR: 本研究提出了一种基于点扩展函数（PSF）的分析方法来理解和改进多分辨率哈希编码（MHE），揭示了MHE的空间特性，并提出了一种名为R-MHE的新架构以克服其各向异性问题。


<details>
  <summary>Details</summary>
Motivation: 现有MHE的超参数选择依赖于启发式方法，缺乏物理系统的严谨理解。研究旨在提供一种分析框架来量化MHE的空间分辨率和保真度，并优化其性能。

Method: 通过研究MHE的点扩展函数（PSF）来分析其空间行为。推导了无碰撞PSF的闭式近似，并分析了哈希容量有限的影响。基于理论洞察提出了旋转MHE（R-MHE）架构。

Result: 推导出无碰撞PSF的闭式近似，揭示了MHE固有的网格诱导各向异性和对数空间剖面。发现模型的有效分辨率由平均分辨率决定，而非最高分辨率。分析了哈希冲突导致的散斑噪声和信噪比（SNR）下降。

Conclusion: 本研究提出了一种基于物理原理的分析方法来表征和优化MHE，克服了启发式方法的局限性。提出的R-MHE架构通过引入旋转消除了各向异性，同时保持了MHE的效率和参数量。

Abstract: Multi-Resolution Hash Encoding (MHE), the foundational technique behind Instant Neural Graphics Primitives, provides a powerful parameterization for neural fields. However, its spatial behavior lacks rigorous understanding from a physical systems perspective, leading to reliance on heuristics for hyperparameter selection. This work introduces a novel analytical approach that characterizes MHE by examining its Point Spread Function (PSF), which is analogous to the Green's function of the system. This methodology enables a quantification of the encoding's spatial resolution and fidelity. We derive a closed-form approximation for the collision-free PSF, uncovering inherent grid-induced anisotropy and a logarithmic spatial profile. We establish that the idealized spatial bandwidth, specifically the Full Width at Half Maximum (FWHM), is determined by the average resolution, $N_{\text{avg}}$. This leads to a counterintuitive finding: the effective resolution of the model is governed by the broadened empirical FWHM (and therefore $N_{\text{avg}}$), rather than the finest resolution $N_{\max}$, a broadening effect we demonstrate arises from optimization dynamics. Furthermore, we analyze the impact of finite hash capacity, demonstrating how collisions introduce speckle noise and degrade the Signal-to-Noise Ratio (SNR). Leveraging these theoretical insights, we propose Rotated MHE (R-MHE), an architecture that applies distinct rotations to the input coordinates at each resolution level. R-MHE mitigates anisotropy while maintaining the efficiency and parameter count of the original MHE. This study establishes a methodology based on physical principles that moves beyond heuristics to characterize and optimize MHE.

</details>


### [43] [1%>100%: High-Efficiency Visual Adapter with Complex Linear Projection Optimization](https://arxiv.org/abs/2602.10513)
*Dongshuo Yin,Xue Yang,Deng-Ping Fan,Shi-Min Hu*

Main category: cs.CV

TL;DR: 本文提出了一种名为CoLin（Complex Linear Projection Optimization）的新型低秩复数适配器，用于高效地微调视觉基础模型，仅引入约1%的参数，并在多项视觉任务上优于全量微调和传统的delta-tuning方法。


<details>
  <summary>Details</summary>
Motivation: 传统的全量微调视觉基础模型成本高、效率低。尽管delta-tuning在LLM适配中有效，但其优势无法直接迁移到视觉模型。因此，需要更高效的视觉模型适配策略。

Method: 提出了一种低秩复数适配器CoLin，其参数量仅占骨干网络的1%。针对低秩复合矩阵训练中的收敛问题，设计了一种定制化损失函数来解决。

Result: 在目标检测、分割、图像分类和遥感场景下的旋转目标检测等任务中，CoLin均取得了优于全量微调和经典delta-tuning方法的性能，且参数量仅为1%。

Conclusion: CoLin提供了一种新颖且高效的视觉基础模型部署解决方案，首次实现了在仅使用1%参数的情况下，在多项视觉任务上超越现有方法。

Abstract: Deploying vision foundation models typically relies on efficient adaptation strategies, whereas conventional full fine-tuning suffers from prohibitive costs and low efficiency. While delta-tuning has proven effective in boosting the performance and efficiency of LLMs during adaptation, its advantages cannot be directly transferred to the fine-tuning pipeline of vision foundation models. To push the boundaries of adaptation efficiency for vision tasks, we propose an adapter with Complex Linear Projection Optimization (CoLin). For architecture, we design a novel low-rank complex adapter that introduces only about 1% parameters to the backbone. For efficiency, we theoretically prove that low-rank composite matrices suffer from severe convergence issues during training, and address this challenge with a tailored loss. Extensive experiments on object detection, segmentation, image classification, and rotated object detection (remote sensing scenario) demonstrate that CoLin outperforms both full fine-tuning and classical delta-tuning approaches with merely 1% parameters for the first time, providing a novel and efficient solution for deployment of vision foundation models. We release the code on https://github.com/DongshuoYin/CoLin.

</details>


### [44] [The Garbage Dataset (GD): A Multi-Class Image Benchmark for Automated Waste Segregation](https://arxiv.org/abs/2602.10500)
*Suman Kunwar*

Main category: cs.CV

TL;DR: 本文介绍了一个名为GD（Garbage Dataset）的公开图像数据集，包含10类生活垃圾，共13,348张标注图像，旨在推动机器学习在垃圾自动分类中的应用。研究者对数据集进行了多维度分析，并使用多种深度学习模型进行基准测试，发现EfficientNetV2S在准确率和F1分数上表现最佳。研究还强调了数据不平衡、背景复杂性以及模型选择的环境影响等挑战。


<details>
  <summary>Details</summary>
Motivation: 为了促进机器学习和计算机视觉在垃圾自动分类领域的进步，开发一个多样化且具有挑战性的公开图像数据集。

Method: 收集并标注了包含10类垃圾的13,348张图像。通过校验和、异常值检测进行数据验证。使用PCA/t-SNE分析类别不平衡和视觉可分离性。使用熵和显著性度量评估背景复杂度。使用EfficientNetV2M、EfficientNetV2S、MobileNet、ResNet50、ResNet101等深度学习模型进行基准测试，并评估了性能和碳排放。

Result: EfficientNetV2S模型在测试中取得了96.19%的准确率和0.96的F1分数，表现最佳，但碳排放成本中等。数据集存在类别不平衡问题，塑料、纸板、纸张等类别包含较多异常值，且存在亮度变化。

Conclusion: GD数据集为垃圾分类研究提供了一个有价值的真实世界基准，并突显了类别不平衡、背景复杂性以及模型选择的环境权衡等关键挑战，这些是实现实际应用部署需要解决的问题。该数据集的发布旨在支持环境可持续性应用的研究。

Abstract: This study introduces the Garbage Dataset (GD), a publicly available image dataset designed to advance automated waste segregation through machine learning and computer vision. It's a diverse dataset covering 10 common household waste categories: metal, glass, biological, paper, battery, trash, cardboard, shoes, clothes, and plastic. The dataset comprises 13,348 labeled images collected through multiple methods, including DWaste mobile app and curated web sources. Methods included rigorous validation through checksums and outlier detection, analysis of class imbalance and visual separability via PCA/t-SNE, and assessment of background complexity using entropy and saliency measures. The dataset was benchmarked using state-of-the-art deep learning models (EfficientNetV2M, EfficientNetV2S, MobileNet, ResNet50, ResNet101) evaluated on performance metrics and operational carbon emissions. Experiment results indicate EfficientNetV2S achieved the highest performance with 96.19% accuracy and a 0.96 F1-score, though with a moderate carbon cost. Analysis revealed inherent dataset characteristics including class imbalance, a skew toward high-outlier classes (plastic, cardboard, paper), and brightness variations that require consideration. The main conclusion is that GD provides a valuable, real-world benchmark for waste classification research while highlighting important challenges such as class imbalance, background complexity, and environmental trade-offs in model selection that must be addressed for practical deployment. The dataset is publicly released to support further research in environmental sustainability applications.

</details>


### [45] [Med-SegLens: Latent-Level Model Diffing for Interpretable Medical Image Segmentation](https://arxiv.org/abs/2602.10508)
*Salma J. Ahmed,Emad A. Mohammed,Azam Asilian Bidgoli*

Main category: cs.CV

TL;DR: Med-SegLens 是一个模型分析框架，通过稀疏自编码器将分割模型（SegFormer 和 U-Net）的激活分解为可解释的潜在特征。研究发现，不同数据集和模型架构之间存在共享的稳定表示，而数据集偏移则源于对特定人群特征的依赖差异。该框架能通过对潜在特征进行干预来纠正分割错误并提高跨数据集的适应性，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分割模型虽然预测性能强大，但其内部机制不透明，难以诊断模型失败的原因、理解数据集的分布变化，或进行有针对性的干预。

Method: 作者开发了一个名为 Med-SegLens 的模型分析框架。该框架使用稀疏自编码器，在 SegFormer 和 U-Net 模型上进行训练，将分割模型的激活分解成可解释的潜在特征。通过在不同数据集（包括健康、成人、儿科和撒哈拉以南非洲的胶质瘤队列）和不同模型架构之间进行潜在特征的对齐和分析。

Result: 研究发现了分割模型中存在一个稳定的共享潜在特征骨干，并且数据集偏移主要由对特定人群特征（population-specific latents）的依赖性差异引起。这些潜在特征被证明是导致分割失败的因果瓶颈。通过对这些潜在特征进行干预，可以在不重新训练模型的情况下纠正错误，提高跨数据集的适应性，成功解决了 70% 的失败案例，并将 Dice 分数从 39.4% 提高到 74.2%。

Conclusion: Med-SegLens 提供了一种实用的、基于机制的工具，可以用于诊断分割模型的失败原因并减轻数据集偏移问题。通过对模型内部潜在特征的分析和干预，可以提高模型的鲁棒性和泛化能力。

Abstract: Modern segmentation models achieve strong predictive performance but remain largely opaque, limiting our ability to diagnose failures, understand dataset shift, or intervene in a principled manner. We introduce Med-SegLens, a model-diffing framework that decomposes segmentation model activations into interpretable latent features using sparse autoencoders trained on SegFormer and U-Net. Through cross-architecture and cross-dataset latent alignment across healthy, adult, pediatric, and sub-Saharan African glioma cohorts, we identify a stable backbone of shared representations, while dataset shift is driven by differential reliance on population-specific latents. We show that these latents act as causal bottlenecks for segmentation failures, and that targeted latent-level interventions can correct errors and improve cross-dataset adaption without retraining, recovering performance in 70% of failure cases and improving Dice score from 39.4% to 74.2%. Our results demonstrate that latent-level model diffing provides a practical and mechanistic tool for diagnosing failures and mitigating dataset shift in segmentation models.

</details>


### [46] [3DXTalker: Unifying Identity, Lip Sync, Emotion, and Spatial Dynamics in Expressive 3D Talking Avatars](https://arxiv.org/abs/2602.10516)
*Zhongju Wang,Zhenhong Sun,Beier Wang,Yifu Wang,Daoyi Dong,Huadong Mo,Hongdong Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为 3DXTalker 的方法，用于生成具有高度表现力的 3D 说话化身，该方法通过数据策展的身份建模、丰富的音频表示和空间动态可控性来解决数据稀缺、音频表示有限和控制受限等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的音频驱动 3D 说话化身生成技术在保持身份、唇形同步、情感表达和空间动态方面存在挑战，主要原因是训练数据不足（身份有限）、音频表示单一以及显式控制能力受限。

Method: 1. 采用 2D 到 3D 数据策展管道和解耦表示进行可扩展的身份建模，以缓解数据稀缺并提高身份泛化能力。 2. 引入了超越标准语音嵌入的帧级幅度（amplitude）和情感线索（emotional cues），以实现更精确的唇形同步和细致的情感调制。 3. 使用基于流匹配（flow-matching-based）的 Transformer 模型来统一这些线索，以获得连贯的面部动态。 4. 实现了自然的头部姿态运动生成，并支持通过提示（prompt-based）进行风格化控制。

Result: 3DXTalker 在一个统一的框架内整合了唇形同步、情感表达和头部姿态动态。在 3D 说话化身生成任务中取得了卓越的性能。

Conclusion: 3DXTalker 成功地通过数据策展的身份建模、丰富的音频表示和空间动态可控性，在克服现有 3D 说话化身生成挑战方面取得了显著进展，并提供了更强的表现力。

Abstract: Audio-driven 3D talking avatar generation is increasingly important in virtual communication, digital humans, and interactive media, where avatars must preserve identity, synchronize lip motion with speech, express emotion, and exhibit lifelike spatial dynamics, collectively defining a broader objective of expressivity. However, achieving this remains challenging due to insufficient training data with limited subject identities, narrow audio representations, and restricted explicit controllability. In this paper, we propose 3DXTalker, an expressive 3D talking avatar through data-curated identity modeling, audio-rich representations, and spatial dynamics controllability. 3DXTalker enables scalable identity modeling via 2D-to-3D data curation pipeline and disentangled representations, alleviating data scarcity and improving identity generalization. Then, we introduce frame-wise amplitude and emotional cues beyond standard speech embeddings, ensuring superior lip synchronization and nuanced expression modulation. These cues are unified by a flow-matching-based transformer for coherent facial dynamics. Moreover, 3DXTalker also enables natural head-pose motion generation while supporting stylized control via prompt-based conditioning. Extensive experiments show that 3DXTalker integrates lip synchronization, emotional expression, and head-pose dynamics within a unified framework, achieves superior performance in 3D talking avatar generation.

</details>


### [47] [MapVerse: A Benchmark for Geospatial Question Answering on Diverse Real-World Maps](https://arxiv.org/abs/2602.10518)
*Sharat Bhat,Harshita Khandelwal,Tushar Kataria,Vivek Gupta*

Main category: cs.CV

TL;DR: 本文提出了 MapVerse，一个包含真实世界地图和人类编写的问题-答案对的大型基准测试集，旨在评估视觉语言模型（VLMs）在地图推理方面的能力。研究发现，虽然当前模型在分类任务上表现尚可，但在需要复杂空间推理的高级任务上仍存在不足。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型（VLMs）在处理地图推理任务时存在局限，现有的基准测试数据集范围狭窄、依赖人工生成内容，无法充分评估模型真正的地理空间推理能力。因此，需要一个基于真实世界地图的大规模数据集来弥补这一差距。

Method: 构建了一个名为 MapVerse 的大规模基准测试集，包含 1025 张真实世界地图和 11,837 对人类编写的问题-答案。该数据集涵盖了十个不同的地图类别和多种问题类型。随后，使用该数据集对十个最先进的模型进行了评估，并进行了细粒度的分类分析，以量化模型在不同维度上的推理能力，并研究视觉因素对推理结果的影响。

Result: 在 MapVerse 基准测试中，现有 VLM 模型在分类类任务上表现具有竞争力。然而，无论是开源还是闭源模型，在需要复杂空间推理的高级任务上的表现均不理想。

Conclusion: MapVerse 是一个评估 VLM 在真实世界地图推理能力的大规模基准。研究结果表明，尽管现有模型在某些地图推理任务上取得进展，但它们在处理需要复杂空间推理的任务时仍面临显著挑战，这表明在该领域仍有进一步研究的空间。

Abstract: Maps are powerful carriers of structured and contextual knowledge, encompassing geography, demographics, infrastructure, and environmental patterns. Reasoning over such knowledge requires models to integrate spatial relationships, visual cues, real-world context, and domain-specific expertise-capabilities that current large language models (LLMs) and vision-language models (VLMs) still struggle to exhibit consistently. Yet, datasets used to benchmark VLMs on map-based reasoning remain narrow in scope, restricted to specific domains, and heavily reliant on artificially generated content (outputs from LLMs or pipeline-based methods), offering limited depth for evaluating genuine geospatial reasoning. To address this gap, we present MapVerse, a large-scale benchmark built on real-world maps. It comprises 11,837 human-authored question-answer pairs across 1,025 maps, spanning ten diverse map categories and multiple question categories for each. The dataset provides a rich setting for evaluating map reading, interpretation, and multimodal reasoning. We evaluate ten state-of-the-art models against our benchmark to establish baselines and quantify reasoning gaps. Beyond overall performance, we conduct fine-grained categorical analyses to assess model inference across multiple dimensions and investigate the visual factors shaping reasoning outcomes. Our findings reveal that while current VLMs perform competitively on classification-style tasks, both open- and closed-source models fall short on advanced tasks requiring complex spatial reasoning.

</details>


### [48] [Enhancing Weakly Supervised Multimodal Video Anomaly Detection through Text Guidance](https://arxiv.org/abs/2602.10549)
*Shengyang Sun,Jiashen Hua,Junyi Feng,Xiaojin Gong*

Main category: cs.CV

TL;DR: 提出了一种文本引导的弱监督多模态视频异常检测框架，通过多阶段文本增强和多尺度瓶颈Transformer融合来解决文本特征提取和多模态融合的挑战，并在UCF-Crime和XD-Violence数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督多模态视频异常检测方法未能充分利用文本模态的显式语义信息来增强异常表征和减少误报。通用语言模型难以捕捉异常特有的细微差别，且相关描述稀缺。此外，多模态融合常存在冗余和不平衡问题。

Method: 提出了一种文本引导的框架，包括：1）基于上下文学习的多阶段文本增强机制，用于生成高质量的异常文本样本以微调文本特征提取器；2）设计了一个多尺度瓶颈Transformer融合模块，通过压缩的瓶颈Token渐进式地整合跨模态信息，以缓解冗余和不平衡。

Result: 在UCF-Crime和XD-Violence数据集上取得了最先进的性能。

Conclusion: 所提出的文本引导框架能够有效解决弱监督多模态视频异常检测中文本特征提取和多模态融合的挑战，并显著提升检测性能。

Abstract: Weakly supervised multimodal video anomaly detection has gained significant attention, yet the potential of the text modality remains under-explored. Text provides explicit semantic information that can enhance anomaly characterization and reduce false alarms. However, extracting effective text features is challenging due to the inability of general-purpose language models to capture anomaly-specific nuances and the scarcity of relevant descriptions. Furthermore, multimodal fusion often suffers from redundancy and imbalance. To address these issues, we propose a novel text-guided framework. First, we introduce an in-context learning-based multi-stage text augmentation mechanism to generate high-quality anomaly text samples for fine-tuning the text feature extractor. Second, we design a multi-scale bottleneck Transformer fusion module that uses compressed bottleneck tokens to progressively integrate information across modalities, mitigating redundancy and imbalance. Experiments on UCF-Crime and XD-Violence demonstrate state-of-the-art performance.

</details>


### [49] [RealHD: A High-Quality Dataset for Robust Detection of State-of-the-Art AI-Generated Images](https://arxiv.org/abs/2602.10546)
*Hanzhe Yu,Yun Ye,Jintao Rong,Qi Xuan,Chen Ma*

Main category: cs.CV

TL;DR: 本文构建了一个包含73万余张高质量图像的大型数据集（Real-HD），用于训练和评估AI生成图像的检测模型，并提出了一种基于图像噪声熵的轻量级检测方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测数据集存在泛化能力差、图像质量低、提示词简单和多样性不足等问题，难以满足真实世界应用的需求。

Method: 构建了一个包含真实和AI生成图像的数据集，AI生成图像通过文本生成、图像修复、图像精炼和换脸等多种先进技术生成，并带有详细的元数据。在此基础上，提出了一种基于图像噪声熵（利用非局部均值滤波处理图像噪声）的轻量级检测方法。

Result: 在Real-HD数据集上训练的检测模型展现出更强的泛化能力。提出的基于噪声熵的方法在检测精度上具有竞争力，并能在此数据集上取得良好的泛化性能。

Conclusion: Real-HD数据集为AI生成图像检测研究提供了一个新的、更高质量的基准，并能提升检测方法的鲁棒性。提出的噪声熵检测方法是一种有效的、轻量级的解决方案，为未来的研究奠定了基础。

Abstract: The rapid advancement of generative AI has raised concerns about the authenticity of digital images, as highly realistic fake images can now be generated at low cost, potentially increasing societal risks. In response, several datasets have been established to train detection models aimed at distinguishing AI-generated images from real ones. However, existing datasets suffer from limited generalization, low image quality, overly simple prompts, and insufficient image diversity. To address these limitations, we propose a high-quality, large-scale dataset comprising over 730,000 images across multiple categories, including both real and AI-generated images. The generated images are synthesized via state-of-the-art methods, including text-to-image generation (guided by over 10,000 carefully designed prompts), image inpainting, image refinement, and face swapping. Each generated image is annotated with its generation method and category. Inpainting images further include binary masks to indicate inpainted regions, providing rich metadata for analysis. Compared to existing datasets, detection models trained on our dataset demonstrate superior generalization capabilities. Our dataset not only serves as a strong benchmark for evaluating detection methods but also contributes to advancing the robustness of AI-generated image detection techniques. Building upon this, we propose a lightweight detection method based on image noise entropy, which transforms the original image into an entropy tensor of Non-Local Means (NLM) noise before classification. Extensive experiments demonstrate that models trained on our dataset achieve strong generalization, and our method delivers competitive performance, establishing a solid baseline for future research. The dataset and source code are publicly available at https://real-hd.github.io.

</details>


### [50] [C^2ROPE: Causal Continuous Rotary Positional Encoding for 3D Large Multimodal-Models Reasoning](https://arxiv.org/abs/2602.10551)
*Guanting Ye,Qiyan Zhao,Wenhao Yu,Xiaofeng Zhang,Jianmin Ji,Yanyong Zhang,Ka-Veng Yuen*

Main category: cs.CV

TL;DR: 本文提出了一种名为C^2RoPE的改进型旋转位置嵌入（RoPE），用于解决现有3D大型多模态模型（LMMs）在处理3D视觉信息时因RoPE的局限性而导致的连续性丢失和注意力衰减问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLMs的3D LMMs在3D视觉特征与LLM表示对齐方面取得了进展，但继承的RoPE在多模态处理中存在问题。其1D时间位置索引破坏了视觉特征的连续性（尤其是在列维度），导致空间局部性丢失。此外，RoPE的因果关系假设（时间上更近的图像token关系更密切）会导致注意力分配的长期衰减，模型会逐渐忽略较早的视觉token。

Method: C^2RoPE通过以下方式改进RoPE：1. 引入一种时空连续的位置嵌入机制，将1D时间位置与基于笛卡尔坐标的空间位置结合，构建三元组混合位置索引。2. 采用频率分配策略，将时空位置信息编码到这三个索引分量中。3. 引入Chebyshev因果掩码，通过计算图像token在2D空间中的Chebyshev距离来确定因果依赖关系。

Result: 在3D场景推理和3D视觉问答等多个基准测试中，C^2RoPE均表现出有效性，证明了其在改进3D LMMs处理3D视觉信息方面的能力。

Conclusion: C^2RoPE是一种有效的RoPE改进方案，能够显式地模拟视觉处理中的局部空间连续性和空间因果关系，从而克服了原始RoPE在3D LMMs中的局限性，提升了模型在3D视觉任务上的性能。

Abstract: Recent advances in 3D Large Multimodal Models (LMMs) built on Large Language Models (LLMs) have established the alignment of 3D visual features with LLM representations as the dominant paradigm. However, the inherited Rotary Position Embedding (RoPE) introduces limitations for multimodal processing. Specifically, applying 1D temporal positional indices disrupts the continuity of visual features along the column dimension, resulting in spatial locality loss. Moreover, RoPE follows the prior that temporally closer image tokens are more causally related, leading to long-term decay in attention allocation and causing the model to progressively neglect earlier visual tokens as the sequence length increases. To address these issues, we propose C^2RoPE, an improved RoPE that explicitly models local spatial Continuity and spatial Causal relationships for visual processing. C^2RoPE introduces a spatio-temporal continuous positional embedding mechanism for visual tokens. It first integrates 1D temporal positions with Cartesian-based spatial coordinates to construct a triplet hybrid positional index, and then employs a frequency allocation strategy to encode spatio-temporal positional information across the three index components. Additionally, we introduce Chebyshev Causal Masking, which determines causal dependencies by computing the Chebyshev distance of image tokens in 2D space. Evaluation results across various benchmarks, including 3D scene reasoning and 3D visual question answering, demonstrate C^2RoPE's effectiveness. The code is be available at https://github.com/ErikZ719/C2RoPE.

</details>


### [51] [MetaphorStar: Image Metaphor Understanding and Reasoning with End-to-End Visual Reinforcement Learning](https://arxiv.org/abs/2602.10575)
*Chenhao Zhang,Yazhe Niu,Hongsheng Li*

Main category: cs.CV

TL;DR: 提出了一种名为MetaphorStar的端到端视觉强化学习框架，用于解决多模态大语言模型在理解图像隐喻方面的挑战，并在图像含义理解基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态语言模型（MLLMs）在处理图像的隐喻理解方面存在困难，因为这项任务需要复杂的推理、文化背景和心智理论（ToM）能力，而这些能力是当前模型所缺乏的。

Method: 提出了一种名为MetaphorStar的视觉强化学习框架，该框架包含三个核心组件：细粒度数据集TFQ-Data、视觉强化学习方法TFQ-GRPO以及结构化的基准测试TFQ-Bench。

Result: MetaphorStar框架在图像含义理解基准测试上平均性能提升了82.6%。与20多个主流MLLMs相比，MetaphorStar-32B在选择题和开放式问题上达到了SOTA水平，并在判断题上显著优于Gemini-3.0-pro。

Conclusion: 图像含义理解任务的学习能够提升模型的通用理解能力，尤其是复杂视觉推理能力。该研究还系统分析了模型参数、训练数据、模型架构和训练策略的影响，证明了方法的广泛适用性。该框架及其相关资源已全部开源。

Abstract: Metaphorical comprehension in images remains a critical challenge for Nowadays AI systems. While Multimodal Large Language Models (MLLMs) excel at basic Visual Question Answering (VQA), they consistently struggle to grasp the nuanced cultural, emotional, and contextual implications embedded in visual content. This difficulty stems from the task's demand for sophisticated multi-hop reasoning, cultural context, and Theory of Mind (ToM) capabilities, which current models lack. To fill this gap, we propose MetaphorStar, the first end-to-end visual reinforcement learning (RL) framework for image implication tasks. Our framework includes three core components: the fine-grained dataset TFQ-Data, the visual RL method TFQ-GRPO, and the well-structured benchmark TFQ-Bench.
  Our fully open-source MetaphorStar family, trained using TFQ-GRPO on TFQ-Data, significantly improves performance by an average of 82.6% on the image implication benchmarks. Compared with 20+ mainstream MLLMs, MetaphorStar-32B achieves state-of-the-art (SOTA) on Multiple-Choice Question and Open-Style Question, significantly outperforms the top closed-source model Gemini-3.0-pro on True-False Question. Crucially, our experiments reveal that learning image implication tasks improves the general understanding ability, especially the complex visual reasoning ability. We further provide a systematic analysis of model parameter scaling, training data scaling, and the impact of different model architectures and training strategies, demonstrating the broad applicability of our method. We open-sourced all model weights, datasets, and method code at https://metaphorstar.github.io.

</details>


### [52] [Enhancing YOLOv11n for Reliable Child Detection in Noisy Surveillance Footage](https://arxiv.org/abs/2602.10592)
*Khanh Linh Tran,Minh Nguyen Dang,Thien Nguyen Trong,Hung Nguyen Quoc,Linh Nguyen Kieu*

Main category: cs.CV

TL;DR: 本研究提出了一种轻量级、可部署的YOLOv11n改进方案，通过域特定数据增强和SAHI推理，显著提升了低质量监控视频中儿童检测的准确率和召回率，同时保持了对低功耗边缘设备的兼容性和实时性。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的失踪儿童预警和日托监控系统中，低质量监控视频中的儿童检测是一个关键但具有挑战性的问题。现有CCTV基础设施常存在遮挡、小目标、低分辨率、运动模糊和光照不足等问题。

Method: 研究人员在YOLOv11n架构基础上，提出了一种部署就绪的流水线。核心方法包括：1) 域特定数据增强策略，通过空间扰动（部分可见、截断、重叠）和光度退化（光照变化、噪声）合成逼真儿童图像；2) 在推理时集成Slicing Aided Hyper Inference (SAHI)来提高小目标和部分遮挡实例的召回率。所有组件都在Roboflow Daycare数据集的子集上进行训练和评估。

Result: 相比基线YOLOv11n，改进后的系统在mAP@0.5上实现了0.967的指标，提升了0.7个百分点；在mAP@0.5:0.95上实现了0.783的指标，提升了2.3个百分点。整个流水线保持了对低功耗边缘设备的兼容性，并支持实时性能。

Conclusion: 该研究成功开发了一个实用的、轻量级的儿童检测增强方案，通过有效的数据增强和SAHI推理，在不改变模型架构的前提下，显著提升了在低质量监控视频中的检测性能，并适用于资源受限的工业监控部署。

Abstract: This paper presents a practical and lightweight solution for enhancing child detection in low-quality surveillance footage, a critical component in real-world missing child alert and daycare monitoring systems. Building upon the efficient YOLOv11n architecture, we propose a deployment-ready pipeline that improves detection under challenging conditions including occlusion, small object size, low resolution, motion blur, and poor lighting commonly found in existing CCTV infrastructures. Our approach introduces a domain-specific augmentation strategy that synthesizes realistic child placements using spatial perturbations such as partial visibility, truncation, and overlaps, combined with photometric degradations including lighting variation and noise. To improve recall of small and partially occluded instances, we integrate Slicing Aided Hyper Inference (SAHI) at inference time. All components are trained and evaluated on a filtered, child-only subset of the Roboflow Daycare dataset. Compared to the baseline YOLOv11n, our enhanced system achieves a mean Average Precision at 0.5 IoU (mAP@0.5) of 0.967 and a mean Average Precision averaged over IoU thresholds from 0.5 to 0.95 (mAP@0.5:0.95) of 0.783, yielding absolute improvements of 0.7 percent and 2.3 percent, respectively, without architectural changes. Importantly, the entire pipeline maintains compatibility with low-power edge devices and supports real-time performance, making it particularly well suited for low-cost or resource-constrained industrial surveillance deployments. The example augmented dataset and the source code used to generate it are available at: https://github.com/html-ptit/Data-Augmentation-YOLOv11n-child-detection

</details>


### [53] [Fast Person Detection Using YOLOX With AI Accelerator For Train Station Safety](https://arxiv.org/abs/2602.10593)
*Mas Nurul Achmadiah,Novendra Setyawan,Achmad Arif Bryantono,Chi-Chia Sun,Wen-Kai Kuo*

Main category: cs.CV

TL;DR: 本研究使用 YOLOX 和 Hailo-8 AI 加速器在火车站部署了乘客检测系统，并与 Jetson Orin Nano 进行了性能对比，结果显示 Hailo-8 在准确性和延迟方面均优于 Jetson Orin Nano。


<details>
  <summary>Details</summary>
Motivation: 为了提高火车站的安全性，减少因乘客不小心越过黄线等原因造成的事故，需要开发额外的技术来增强安全措施。

Method: 本研究使用 YOLOX 模型和 Edge AI 加速器硬件（Hailo-8）来开发乘客检测应用。通过实验对比了 Hailo-8 AI 加速器与 Jetson Orin Nano 的性能。

Result: 实验结果表明，Hailo-8 AI 硬件加速器的准确性比 Jetson Orin Nano 提高了 12% 以上，并且延迟降低了 20 毫秒。

Conclusion: Hailo-8 AI 加速器在火车站的乘客检测应用中，相比 Jetson Orin Nano 能够提供更高的准确性和更低的延迟，证明了其在交通安全领域的潜力。

Abstract: Recently, Image processing has advanced Faster and applied in many fields, including health, industry, and transportation. In the transportation sector, object detection is widely used to improve security, for example, in traffic security and passenger crossings at train stations. Some accidents occur in the train crossing area at the station, like passengers uncarefully when passing through the yellow line. So further security needs to be developed. Additional technology is required to reduce the number of accidents. This paper focuses on passenger detection applications at train stations using YOLOX and Edge AI Accelerator hardware. the performance of the AI accelerator will be compared with Jetson Orin Nano. The experimental results show that the Hailo-8 AI hardware accelerator has higher accuracy than Jetson Orin Nano (improvement of over 12%) and has lower latency than Jetson Orin Nano (reduced 20 ms).

</details>


### [54] [TwiFF (Think With Future Frames): A Large-Scale Dataset for Dynamic Visual Reasoning](https://arxiv.org/abs/2602.10675)
*Junhua Liu,Zhangcheng Wang,Zhike Han,Ningli Wang,Guotao Liang,Kun Kuang*

Main category: cs.CV

TL;DR: 本文提出了TwiFF-2.7M数据集和TwiFF-Bench评估基准，用于动态视觉问答中的视觉链式思考（VCoT）。同时，还提出了TwiFF模型，该模型通过结合视频生成和图像理解能力，能够生成连贯的视觉推理线索，并在动态推理任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有VCoT方法主要局限于静态场景，无法捕捉动态场景（如指令、预测、相机运动）所必需的时间动态性。因此，研究旨在弥补这一差距，推动VCoT在动态视觉问答中的应用。

Method: 1. 构建了TwiFF-2.7M数据集，包含270万个视频片段，专门用于动态视觉问答。
2. 提出了TwiFF-Bench评估基准，包含1078个样本，用于评估推理轨迹的合理性和最终答案的正确性。
3. 设计了TwiFF模型，一个统一模型，结合预训练的视频生成和图像理解能力，通过迭代生成未来动作帧和文本推理，产生时间连贯的视觉推理线索。

Result: TwiFF模型在动态推理任务上的表现显著优于现有的VCoT方法和文本链式思考基线。

Conclusion: TwiFF-2.7M数据集、TwiFF-Bench基准和TwiFF模型有效地解决了动态视觉问答中的VCoT问题，证明了其在动态场景下的视觉问答能力的有效性。

Abstract: Visual Chain-of-Thought (VCoT) has emerged as a promising paradigm for enhancing multimodal reasoning by integrating visual perception into intermediate reasoning steps. However, existing VCoT approaches are largely confined to static scenarios and struggle to capture the temporal dynamics essential for tasks such as instruction, prediction, and camera motion. To bridge this gap, we propose TwiFF-2.7M, the first large-scale, temporally grounded VCoT dataset derived from $2.7$ million video clips, explicitly designed for dynamic visual question and answer. Accompanying this, we introduce TwiFF-Bench, a high-quality evaluation benchmark of $1,078$ samples that assesses both the plausibility of reasoning trajectories and the correctness of final answers in open-ended dynamic settings. Building on these foundations, we propose the TwiFF model, a unified modal that synergistically leverages pre-trained video generation and image comprehension capabilities to produce temporally coherent visual reasoning cues-iteratively generating future action frames and textual reasoning. Extensive experiments demonstrate that TwiFF significantly outperforms existing VCoT methods and Textual Chain-of-Thought baselines on dynamic reasoning tasks, which fully validates the effectiveness for visual question answering in dynamic scenarios. Our code and data is available at https://github.com/LiuJunhua02/TwiFF.

</details>


### [55] [A Vision-Language Foundation Model for Zero-shot Clinical Collaboration and Automated Concept Discovery in Dermatology](https://arxiv.org/abs/2602.10624)
*Siyuan Yan,Xieji Li,Dan Mo,Philipp Tschandl,Yiwen Jiang,Zhonghua Wang,Ming Hu,Lie Ju,Cristina Vico-Alonso,Yizhen Zheng,Jiahe Liu,Juexiao Zhou,Camilla Chello,Jen G. Cheung,Julien Anriot,Luc Thomas,Clare Primiero,Gin Tan,Aik Beng Ng,Simon See,Xiaoying Tang,Albert Ip,Xiaoyang Liao,Adrian Bowling,Martin Haskett,Shuang Zhao,Monika Janda,H. Peter Soyer,Victoria Mar,Harald Kittler,Zongyuan Ge*

Main category: cs.CV

TL;DR: 本文提出了DermFM-Zero，一个无需特定任务微调的皮肤病学视觉语言基础模型，通过多模态学习在超过400万个数据点上进行训练，并在20项基准测试中实现了零样本诊断和多模态检索的最优性能。该模型在超过1100名临床医生参与的多国读者研究中，显著提高了初级保健医生和专科医生的诊断准确性和皮肤癌评估能力，并在协作工作流中提升了非专家用户的表现。此外，DermFM-Zero的潜在表征具有可解释性，能够解耦临床概念并减少伪影偏差，证明了其作为安全、有效、透明的零样本临床决策支持工具的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前的医学基础模型在部署时往往依赖于特定任务的微调，限制了其广泛应用。研究人员希望开发一个无需微调即可在多个皮肤病学任务中表现优异的视觉语言基础模型，以实现更便捷和有效的临床决策支持。

Method: 研究人员引入了DermFM-Zero，一个在超过400万个多模态数据点上进行训练的皮肤病学视觉语言基础模型。模型采用了掩码潜模型（masked latent modelling）和对比学习（contrastive learning）的方法。模型的零样本能力在20个基准测试中得到评估，并在多国读者研究中对超过1100名临床医生进行了评估。此外，研究人员还利用稀疏自编码器（sparse autoencoders）对模型的潜在表征进行了可解释性分析。

Result: DermFM-Zero在20项零样本诊断和多模态检索基准测试中取得了最先进的性能。在读者研究中，AI辅助使全科医生在98种皮肤病症的鉴别诊断准确率几乎翻倍；在专科设置中，DermFM-Zero在多模态皮肤癌评估方面显著优于认证皮肤科医生。在协作工作流中，AI辅助使非专家用户超越了未经辅助的专家，并提高了治疗方案的适当性。此外，模型的潜在表征被证明是可解释的，能够解耦临床概念并有效减少伪影偏差。

Conclusion: DermFM-Zero是一个强大的、无需特定任务微调的皮肤病学视觉语言基础模型，能够提供安全、有效和透明的零样本临床决策支持。其可解释的潜在表征进一步增强了模型的鲁棒性和临床应用价值。

Abstract: Medical foundation models have shown promise in controlled benchmarks, yet widespread deployment remains hindered by reliance on task-specific fine-tuning. Here, we introduce DermFM-Zero, a dermatology vision-language foundation model trained via masked latent modelling and contrastive learning on over 4 million multimodal data points. We evaluated DermFM-Zero across 20 benchmarks spanning zero-shot diagnosis and multimodal retrieval, achieving state-of-the-art performance without task-specific adaptation. We further evaluated its zero-shot capabilities in three multinational reader studies involving over 1,100 clinicians. In primary care settings, AI assistance enabled general practitioners to nearly double their differential diagnostic accuracy across 98 skin conditions. In specialist settings, the model significantly outperformed board-certified dermatologists in multimodal skin cancer assessment. In collaborative workflows, AI assistance enabled non-experts to surpass unassisted experts while improving management appropriateness. Finally, we show that DermFM-Zero's latent representations are interpretable: sparse autoencoders unsupervisedly disentangle clinically meaningful concepts that outperform predefined-vocabulary approaches and enable targeted suppression of artifact-induced biases, enhancing robustness without retraining. These findings demonstrate that a foundation model can provide effective, safe, and transparent zero-shot clinical decision support.

</details>


### [56] [Improving Medical Visual Reinforcement Fine-Tuning via Perception and Reasoning Augmentation](https://arxiv.org/abs/2602.10619)
*Guangjing Yang,ZhangYuan Yu,Ziyuan Qin,Xinyuan Song,Huahui Yi,Qingbo Kang,Jun Gao,Yiyue Li,Chenlin Du,Qicheng Lao*

Main category: cs.CV

TL;DR: 提出了一种名为VRFT-Aug的视觉强化微调框架，用于医学影像领域，通过多种策略增强模型在感知和推理方面的能力，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的强化微调（RFT）方法在跨模态、以视觉为中心的医学影像领域应用不足，而该领域需要强大的视觉感知和结构化推理能力。

Method: 提出VRFT-Aug框架，包含：先验知识注入、感知驱动的策略精炼、医学信息奖励塑造以及行为模仿等训练策略，以稳定和改进RFT过程。

Result: 在多个医学数据集上的实验表明，VRFT-Aug在性能上持续优于标准的监督微调和RFT基线方法。

Conclusion: VRFT-Aug为医学影像任务提供了有效的强化微调框架，并通过实证研究提供了可推广的训练技巧，为开发可靠的、具有推理能力的医学应用模型提供了指导和灵感。

Abstract: While recent advances in Reinforcement Fine-Tuning (RFT) have shown that rule-based reward schemes can enable effective post-training for large language models, their extension to cross-modal, vision-centric domains remains largely underexplored. This limitation is especially pronounced in the medical imaging domain, where effective performance requires both robust visual perception and structured reasoning. In this work, we address this gap by proposing VRFT-Aug, a visual reinforcement fine-tuning framework tailored for the medical domain. VRFT-Aug introduces a series of training strategies designed to augment both perception and reasoning, including prior knowledge injection, perception-driven policy refinement, medically informed reward shaping, and behavioral imitation. Together, these methods aim to stabilize and improve the RFT process.
  Through extensive experiments across multiple medical datasets, we show that our approaches consistently outperform both standard supervised fine-tuning and RFT baselines. Moreover, we provide empirically grounded insights and practical training heuristics that can be generalized to other medical image tasks. We hope this work contributes actionable guidance and fresh inspiration for the ongoing effort to develop reliable, reasoning-capable models for high-stakes medical applications.

</details>


### [57] [OmniVL-Guard: Towards Unified Vision-Language Forgery Detection and Grounding via Balanced RL](https://arxiv.org/abs/2602.10687)
*Jinjie Shen,Jing Wu,Yaxiong Wang,Lechao Cheng,Shengeng Tang,Tianrui Hui,Nan Pu,Zhun Zhong*

Main category: cs.CV

TL;DR: 提出了一种名为OmniVL-Guard的统一框架，用于检测和定位包含文本、图像和视频的混合视觉-语言信息的伪造。该框架通过自演进思维链生成和自适应奖励缩放策略优化解决了多任务优化中的“难度偏差”问题，提高了检测和定位的准确性，并展现了零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的伪造检测方法在处理现实世界中常见的文本、图像和视频混合信息方面存在局限性，无法应对这种跨模态的挑战。因此，有必要开发一个统一的框架来同时进行伪造检测和定位。

Method: 提出了一种名为OmniVL-Guard的基于强化学习的统一框架，包含两个核心设计：1) 自演进思维链生成（Self-Evolving CoT Generation），用于合成高质量的推理路径，克服冷启动问题；2) 自适应奖励缩放策略优化（Adaptive Reward Scaling Policy Optimization, ARSPO），动态调整奖励尺度和任务权重，以实现均衡的多任务联合优化。

Result: OmniVL-Guard在大量实验中显著优于最先进的方法，并在跨领域场景中表现出零样本鲁棒泛化能力。

Conclusion: OmniVL-Guard成功地解决了跨模态伪造检测和定位中的“难度偏差”问题，提供了一个统一且高效的框架，并在实际应用中展现了优越的性能和泛化能力。

Abstract: Existing forgery detection methods are often limited to uni-modal or bi-modal settings, failing to handle the interleaved text, images, and videos prevalent in real-world misinformation. To bridge this gap, this paper targets to develop a unified framework for omnibus vision-language forgery detection and grounding. In this unified setting, the {interplay} between diverse modalities and the dual requirements of simultaneous detection and localization pose a critical ``difficulty bias`` problem: the simpler veracity classification task tends to dominate the gradients, leading to suboptimal performance in fine-grained grounding during multi-task optimization. To address this challenge, we propose \textbf{OmniVL-Guard}, a balanced reinforcement learning framework for omnibus vision-language forgery detection and grounding. Particularly, OmniVL-Guard comprises two core designs: Self-Evolving CoT Generatio and Adaptive Reward Scaling Policy Optimization (ARSPO). {Self-Evolving CoT Generation} synthesizes high-quality reasoning paths, effectively overcoming the cold-start challenge. Building upon this, {Adaptive Reward Scaling Policy Optimization (ARSPO)} dynamically modulates reward scales and task weights, ensuring a balanced joint optimization. Extensive experiments demonstrate that OmniVL-Guard significantly outperforms state-of-the-art methods and exhibits zero-shot robust generalization across out-of-domain scenarios.

</details>


### [58] [AugVLA-3D: Depth-Driven Feature Augmentation for Vision-Language-Action Models](https://arxiv.org/abs/2602.10698)
*Zhifeng Rao,Wenlong Chen,Lei Xie,Xia Hua,Dongfu Yin,Zhen Tian,F. Richard Yu*

Main category: cs.CV

TL;DR: 本研究提出了一种将深度估计整合到视觉-语言-动作（VLA）模型中的新框架，以增强其在复杂3D环境中的空间理解和动作关联能力，通过引入深度信息和动作先验来提高模型在几何歧义场景下的感知能力和动作预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要依赖2D图像训练，这限制了它们在复杂3D环境中的空间理解和动作关联能力。研究旨在通过引入3D信息来克服这一局限。

Method: 框架集成了深度估计（使用VGGT提取3D线索）和动作辅助模块（用动作先验约束3D表示，确保与下游控制任务一致）。通过融合增强的3D特征和传统的2D视觉token来提升VLA模型的泛化能力和鲁棒性。

Result: 实验证明，所提出的方法在几何歧义场景下增强了感知能力，并提高了动作预测的准确性。

Conclusion: 深度驱动的数据增强和辅助专家监督在弥合机器人系统中2D观测与3D感知决策之间差距方面具有潜力。

Abstract: Vision-Language-Action (VLA) models have recently achieved remarkable progress in robotic perception and control, yet most existing approaches primarily rely on VLM trained using 2D images, which limits their spatial understanding and action grounding in complex 3D environments. To address this limitation, we propose a novel framework that integrates depth estimation into VLA models to enrich 3D feature representations. Specifically, we employ a depth estimation baseline called VGGT to extract geometry-aware 3D cues from standard RGB inputs, enabling efficient utilization of existing large-scale 2D datasets while implicitly recovering 3D structural information. To further enhance the reliability of these depth-derived features, we introduce a new module called action assistant, which constrains the learned 3D representations with action priors and ensures their consistency with downstream control tasks. By fusing the enhanced 3D features with conventional 2D visual tokens, our approach significantly improves the generalization ability and robustness of VLA models. Experimental results demonstrate that the proposed method not only strengthens perception in geometrically ambiguous scenarios but also leads to superior action prediction accuracy. This work highlights the potential of depth-driven data augmentation and auxiliary expert supervision for bridging the gap between 2D observations and 3D-aware decision-making in robotic systems.

</details>


### [59] [Eliminating VAE for Fast and High-Resolution Generative Detail Restoration](https://arxiv.org/abs/2602.10630)
*Yan Wang,Shijie Zhao,Junlin Li,Li Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 GenDR-Pix 的超分辨率（SR）新方法，通过消除变分自编码器（VAE）并采用像素空间操作，实现了比现有方法（如 GenDR）更快的推理速度和更低的内存占用，同时保持了可接受的图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的超分辨率方法（如 GenDR）虽然效果好，但推理速度慢且占用内存大，限制了其在实际应用中的部署，尤其是在处理高分辨率图像时，需要分块处理。研究者希望解决这些性能瓶颈。

Method: GenDR-Pix 通过以下方法改进 GenDR：1. 消除 VAE：利用像素（un）shuffle 操作替代 VAE，将模型从潜在空间操作转变为像素空间操作。2. 多阶段对抗蒸馏：逐步移除编码器和解码器，利用前一阶段模型的生成特征引导对抗性判别，并引入随机填充增强特征以防止判别器崩溃。3. 掩码傅里叶空间损失：惩罚幅度异常值以减轻重复模式伪影。4. 结合填充式自集成与无分类器指导：提升推理性能和尺度扩展性。

Result: GenDR-Pix 相较于 GenDR，实现了 2.8 倍的速度提升和 60% 的内存节省，视觉效果损失极小。它超越了其他单步扩散 SR 方法，并且能够在 1 秒内和 6GB 内存下恢复 4K 图像。

Conclusion: GenDR-Pix 成功克服了现有扩散模型 SR 方法的推理速度慢和内存占用大的缺点，通过创新的像素空间设计和蒸馏策略，实现了高效且高质量的超分辨率处理，使其能够处理高分辨率图像，并在有限的计算资源下实现实时恢复。

Abstract: Diffusion models have attained remarkable breakthroughs in the real-world super-resolution (SR) task, albeit at slow inference and high demand on devices. To accelerate inference, recent works like GenDR adopt step distillation to minimize the step number to one. However, the memory boundary still restricts the maximum processing size, necessitating tile-by-tile restoration of high-resolution images. Through profiling the pipeline, we pinpoint that the variational auto-encoder (VAE) is the bottleneck of latency and memory. To completely solve the problem, we leverage pixel-(un)shuffle operations to eliminate the VAE, reversing the latent-based GenDR to pixel-space GenDR-Pix. However, upscale with x8 pixelshuffle may induce artifacts of repeated patterns. To alleviate the distortion, we propose a multi-stage adversarial distillation to progressively remove the encoder and decoder. Specifically, we utilize generative features from the previous stage models to guide adversarial discrimination. Moreover, we propose random padding to augment generative features and avoid discriminator collapse. We also introduce a masked Fourier space loss to penalize the outliers of amplitude. To improve inference performance, we empirically integrate a padding-based self-ensemble with classifier-free guidance to improve inference scaling. Experimental results show that GenDR-Pix performs 2.8x acceleration and 60% memory-saving compared to GenDR with negligible visual degradation, surpassing other one-step diffusion SR. Against all odds, GenDR-Pix can restore 4K image in only 1 second and 6GB.

</details>


### [60] [VideoSTF: Stress-Testing Output Repetition in Video Large Language Models](https://arxiv.org/abs/2602.10639)
*Yuxin Cao,Wei Song,Shangzhi Xu,Jingling Xue,Jin Song Dong*

Main category: cs.CV

TL;DR: 研究发现现有的视频大语言模型（VideoLLMs）在生成任务中存在严重的输出重复问题，现有基准测试未能捕捉到这一缺陷。研究提出了VideoSTF框架，通过三种n-gram度量和包含10000个视频及时间变换的测试集来系统地衡量和压力测试输出重复。实验发现输出重复普遍存在且对时间扰动敏感，可被利用作为安全漏洞，强调了视频语言系统稳定性评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型（VideoLLMs）在视频理解任务上表现出色，但存在一个未被充分研究的生成失败模式：严重的输出重复。此问题未被当前基准测试捕获，因此需要新的方法来系统地评估和解决。

Method: 研究提出了VideoSTF框架，包含三种互补的n-gram度量来形式化输出重复。该框架还提供了一个包含10000个视频的标准测试平台，并引入了受控的时间变换库。通过VideoSTF，对10种先进的VideoLLMs进行了普遍性测试、时间压力测试和对抗性利用。

Result: 研究发现输出重复在现代VideoLLMs中普遍存在。重要的是，这种重复对视频输入的微小时间扰动高度敏感。此外，简单的 temporal transformations 可以在黑盒设置下有效地诱发重复性退化，表明输出重复是一个可利用的安全漏洞。

Conclusion: 输出重复是现代VideoLLMs的一个基本稳定性问题。这项研究强调了对视频语言系统进行稳定性感知评估的必要性，并提出了VideoSTF作为一种有效的评估工具。

Abstract: Video Large Language Models (VideoLLMs) have recently achieved strong performance in video understanding tasks. However, we identify a previously underexplored generation failure: severe output repetition, where models degenerate into self-reinforcing loops of repeated phrases or sentences. This failure mode is not captured by existing VideoLLM benchmarks, which focus primarily on task accuracy and factual correctness. We introduce VideoSTF, the first framework for systematically measuring and stress-testing output repetition in VideoLLMs. VideoSTF formalizes repetition using three complementary n-gram-based metrics and provides a standardized testbed of 10,000 diverse videos together with a library of controlled temporal transformations. Using VideoSTF, we conduct pervasive testing, temporal stress testing, and adversarial exploitation across 10 advanced VideoLLMs. We find that output repetition is widespread and, critically, highly sensitive to temporal perturbations of video inputs. Moreover, we show that simple temporal transformations can efficiently induce repetitive degeneration in a black-box setting, exposing output repetition as an exploitable security vulnerability. Our results reveal output repetition as a fundamental stability issue in modern VideoLLMs and motivate stability-aware evaluation for video-language systems. Our evaluation code and scripts are available at: https://github.com/yuxincao22/VideoSTF_benchmark.

</details>


### [61] [A Diffusion-Based Generative Prior Approach to Sparse-view Computed Tomography](https://arxiv.org/abs/2602.10722)
*Davide Evangelista,Pasquale Cascarano,Elena Loli Piccolomini*

Main category: cs.CV

TL;DR: 本文提出了一种结合深度生成模型（扩散模型）和迭代优化算法的深度生成先验（DGP）框架，用于从稀疏或有限角度的X射线CT数据中重建图像，以提高图像质量并减少伪影。


<details>
  <summary>Details</summary>
Motivation: 从稀疏或有限角度的X射线CT数据重建图像是一个挑战，因为数据不足会导致伪影和物体失真。深度生成模型因其生成能力而在此领域具有潜力。

Method: 利用扩散模型作为生成先验，结合迭代优化算法来解决CT图像重建的最小化问题。对图像生成、模型和迭代算法进行了改进。

Result: 在高度稀疏的几何条件下，所提出的方法取得了非常有前景的重建结果，显著减少了伪影和失真。

Conclusion: 所提出的DGP框架结合了模型驱动方法的解释性和神经网络的生成能力，在稀疏CT图像重建方面显示出巨大潜力，但仍需进一步研究以优化性能。

Abstract: The reconstruction of X-rays CT images from sparse or limited-angle geometries is a highly challenging task. The lack of data typically results in artifacts in the reconstructed image and may even lead to object distortions. For this reason, the use of deep generative models in this context has great interest and potential success. In the Deep Generative Prior (DGP) framework, the use of diffusion-based generative models is combined with an iterative optimization algorithm for the reconstruction of CT images from sinograms acquired under sparse geometries, to maintain the explainability of a model-based approach while introducing the generative power of a neural network. There are therefore several aspects that can be further investigated within these frameworks to improve reconstruction quality, such as image generation, the model, and the iterative algorithm used to solve the minimization problem, for which we propose modifications with respect to existing approaches. The results obtained even under highly sparse geometries are very promising, although further research is clearly needed in this direction.

</details>


### [62] [Multimodal Priors-Augmented Text-Driven 3D Human-Object Interaction Generation](https://arxiv.org/abs/2602.10659)
*Yin Wang,Ziyao Zhang,Zhiying Leng,Haitian Liu,Frederick W. B. Li,Mu Li,Xiaohui Liang*

Main category: cs.CV

TL;DR: 本文提出了MP-HOI框架，通过利用多模态数据先验、增强物体表示、多模态感知MoE模型以及级联扩散与交互监督，解决了文本驱动的三维人-物交互（HOI）运动生成中的关键挑战，生成了更逼真、细粒度的人-物交互运动。


<details>
  <summary>Details</summary>
Motivation: 现有直接进行文本到HOI映射的方法存在人-物运动不佳、交互不自然等问题，这主要是由于显著的跨模态鸿沟造成的。

Method: 提出MP-HOI框架，包含四个核心部分：1. 利用多模态数据（文本、图像、姿态/物体）作为先验；2. 增强物体表示（几何关键点、接触特征、动态属性）；3. 构建多模态感知混合专家（MoE）模型；4. 设计级联扩散模型并引入交互监督。

Result: MP-HOI在生成高保真和细粒度HOI运动方面优于现有方法。

Conclusion: MP-HOI框架通过多模态数据融合和交互监督，有效提升了文本驱动的3D HOI运动生成的质量，解决了现有方法的局限性。

Abstract: We address the challenging task of text-driven 3D human-object interaction (HOI) motion generation. Existing methods primarily rely on a direct text-to-HOI mapping, which suffers from three key limitations due to the significant cross-modality gap: (Q1) sub-optimal human motion, (Q2) unnatural object motion, and (Q3) weak interaction between humans and objects. To address these challenges, we propose MP-HOI, a novel framework grounded in four core insights: (1) Multimodal Data Priors: We leverage multimodal data (text, image, pose/object) from large multimodal models as priors to guide HOI generation, which tackles Q1 and Q2 in data modeling. (2) Enhanced Object Representation: We improve existing object representations by incorporating geometric keypoints, contact features, and dynamic properties, enabling expressive object representations, which tackles Q2 in data representation. (3) Multimodal-Aware Mixture-of-Experts (MoE) Model: We propose a modality-aware MoE model for effective multimodal feature fusion paradigm, which tackles Q1 and Q2 in feature fusion. (4) Cascaded Diffusion with Interaction Supervision: We design a cascaded diffusion framework that progressively refines human-object interaction features under dedicated supervision, which tackles Q3 in interaction refinement. Comprehensive experiments demonstrate that MP-HOI outperforms existing approaches in generating high-fidelity and fine-grained HOI motions.

</details>


### [63] [AurigaNet: A Real-Time Multi-Task Network for Enhanced Urban Driving Perception](https://arxiv.org/abs/2602.10660)
*Kiarash Ghasemzadeh,Sedigheh Dehghani*

Main category: cs.CV

TL;DR: 本文提出了一种名为 AurigaNet 的多任务学习网络，用于提升自动驾驶感知能力，它集成了物体检测、车道线检测和可行驶区域实例分割，并在 BDD100K 数据集上表现出色，同时能在嵌入式设备上实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的自动驾驶 AI 系统仍然是一个重大挑战。多任务学习在提高计算效率、实时处理能力、资源利用率和泛化能力方面具有优势，可用于解决复杂的驾驶感知问题。

Method: 提出了一种名为 AurigaNet 的新型多任务网络架构，该架构集成了物体检测、车道线检测和可行驶区域实例分割三个关键任务。系统在 BDD100K 数据集上进行训练和评估，并部署在 Jetson Orin NX 等嵌入式设备上进行性能验证。

Result: AurigaNet 在可行驶区域分割任务上达到了 85.2% 的 IoU，优于竞品 0.7%。在车道线检测任务上，IoU 达到 60.8%，领先其他模型超过 30%。在物体检测任务上，mAP@0.5:0.95 达到 47.6%，优于下一领先模型 2.9%。在嵌入式设备上，AurigaNet 展现了有竞争力的实时性能。

Conclusion: AurigaNet 是一种先进的多任务网络架构，能够有效提升自动驾驶感知任务的准确性和效率，并在嵌入式设备上实现了有竞争力的实时性能，显示出其作为强大且高效的自动驾驶感知解决方案的潜力。

Abstract: Self-driving cars hold significant potential to reduce traffic accidents, alleviate congestion, and enhance urban mobility. However, developing reliable AI systems for autonomous vehicles remains a substantial challenge. Over the past decade, multi-task learning has emerged as a powerful approach to address complex problems in driving perception. Multi-task networks offer several advantages, including increased computational efficiency, real-time processing capabilities, optimized resource utilization, and improved generalization. In this study, we present AurigaNet, an advanced multi-task network architecture designed to push the boundaries of autonomous driving perception. AurigaNet integrates three critical tasks: object detection, lane detection, and drivable area instance segmentation. The system is trained and evaluated using the BDD100K dataset, renowned for its diversity in driving conditions. Key innovations of AurigaNet include its end-to-end instance segmentation capability, which significantly enhances both accuracy and efficiency in path estimation for autonomous vehicles. Experimental results demonstrate that AurigaNet achieves an 85.2% IoU in drivable area segmentation, outperforming its closest competitor by 0.7%. In lane detection, AurigaNet achieves a remarkable 60.8% IoU, surpassing other models by more than 30%. Furthermore, the network achieves an mAP@0.5:0.95 of 47.6% in traffic object detection, exceeding the next leading model by 2.9%. Additionally, we validate the practical feasibility of AurigaNet by deploying it on embedded devices such as the Jetson Orin NX, where it demonstrates competitive real-time performance. These results underscore AurigaNet's potential as a robust and efficient solution for autonomous driving perception systems. The code can be found here https://github.com/KiaRational/AurigaNet.

</details>


### [64] [Self-Supervised Image Super-Resolution Quality Assessment based on Content-Free Multi-Model Oriented Representation Learning](https://arxiv.org/abs/2602.10744)
*Kian Majlessi,Amir Masoud Soltani,Mohammad Ebrahim Mahdavi,Aurelien Gourrier,Peyman Adibi*

Main category: cs.CV

TL;DR: 提出了一种用于真实世界超分辨率图像质量评估（SR-IQA）的无参考方法 S3 RIQA，通过自监督学习捕捉 SR 算法依赖的退化特征，并在新数据集 SRMORSS 上进行训练，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 真实世界超分辨率图像存在复杂且不规则的退化，与合成退化不同，难以预测，导致现有的超分辨率图像质量评估（SR-IQA）方法效果不佳，特别是在数据稀疏的领域。

Method: 提出了一种无参考 SR-IQA 方法 S3 RIQA。核心是自监督学习（SSL）策略，通过对比学习构建正例（同一 SR 模型生成的图像对）和负例（不同 SR 模型生成的图像对），以学习与 SR 算法相关的退化特征。此外，还引入了预处理步骤来提取补充质量信息，并使用辅助任务来处理不同缩放因子下的退化。

Result: 在真实 SR-IQA 基准测试中，S3 RIQA 持续优于大多数最先进的相关指标。

Conclusion: S3 RIQA 是一种有效的、适应性强的无参考 SR-IQA 方法，适用于真实世界应用，尤其是在数据稀缺的场景下，并且通过自监督学习可以有效捕捉不同 SR 算法引入的退化特性。

Abstract: Super-resolution (SR) applied to real-world low-resolution (LR) images often results in complex, irregular degradations that stem from the inherent complexity of natural scene acquisition. In contrast to SR artifacts arising from synthetic LR images created under well-defined scenarios, those distortions are highly unpredictable and vary significantly across different real-life contexts. Consequently, assessing the quality of SR images (SR-IQA) obtained from realistic LR, remains a challenging and underexplored problem. In this work, we introduce a no-reference SR-IQA approach tailored for such highly ill-posed realistic settings. The proposed method enables domain-adaptive IQA for real-world SR applications, particularly in data-scarce domains. We hypothesize that degradations in super-resolved images are strongly dependent on the underlying SR algorithms, rather than being solely determined by image content. To this end, we introduce a self-supervised learning (SSL) strategy that first pretrains multiple SR model oriented representations in a pretext stage. Our contrastive learning framework forms positive pairs from images produced by the same SR model and negative pairs from those generated by different methods, independent of image content. The proposed approach S3 RIQA, further incorporates targeted preprocessing to extract complementary quality information and an auxiliary task to better handle the various degradation profiles associated with different SR scaling factors. To this end, we constructed a new dataset, SRMORSS, to support unsupervised pretext training; it includes a wide range of SR algorithms applied to numerous real LR images, which addresses a gap in existing datasets. Experiments on real SR-IQA benchmarks demonstrate that S3 RIQA consistently outperforms most state-of-the-art relevant metrics.

</details>


### [65] [Dynamic Frequency Modulation for Controllable Text-driven Image Generation](https://arxiv.org/abs/2602.10662)
*Tiandong Shi,Ling Zhao,Ji Qi,Jiayi Ma,Chengli Peng*

Main category: cs.CV

TL;DR: 本文提出了一种基于频率调制的训练无关方法，用于在文本引导的图像生成中修改语义，同时保持全局结构一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本引导图像生成模型在修改文本提示以实现语义调整时，容易导致全局结构发生意外变化，从而违背用户意图。现有方法依赖于经验性的特征图选择，不稳定且效果不佳。

Method: 该方法从频率角度分析了噪声潜在变量的频率谱在生成过程中对结构框架和纹理形成的层级影响。研究发现，低频分量负责早期生成阶段的结构框架，高频分量负责后期生成阶段的纹理。在此基础上，提出了一种利用频率相关权重函数和动态衰减的训练无关频率调制方法，直接操作噪声潜在变量，实现结构保持和语义修改。

Result: 实验表明，该方法在保持结构一致性的同时，能够实现有针对性的语义修改，并且在结构保持和语义更新之间取得了有效的平衡，显著优于现有最先进的方法。

Conclusion: 基于频率分析的调制方法可以有效解决文本引导图像生成中语义修改导致结构变化的难题，并提供了比经验性特征图选择更稳定、更有效的解决方案。

Abstract: The success of text-guided diffusion models has established a new image generation paradigm driven by the iterative refinement of text prompts. However, modifying the original text prompt to achieve the expected semantic adjustments often results in unintended global structure changes that disrupt user intent. Existing methods rely on empirical feature map selection for intervention, whose performance heavily depends on appropriate selection, leading to suboptimal stability. This paper tries to solve the aforementioned problem from a frequency perspective and analyzes the impact of the frequency spectrum of noisy latent variables on the hierarchical emergence of the structure framework and fine-grained textures during the generation process. We find that lower-frequency components are primarily responsible for establishing the structure framework in the early generation stage. Their influence diminishes over time, giving way to higher-frequency components that synthesize fine-grained textures. In light of this, we propose a training-free frequency modulation method utilizing a frequency-dependent weighting function with dynamic decay. This method maintains the structure framework consistency while permitting targeted semantic modifications. By directly manipulating the noisy latent variable, the proposed method avoids the empirical selection of internal feature maps. Extensive experiments demonstrate that the proposed method significantly outperforms current state-of-the-art methods, achieving an effective balance between preserving structure and enabling semantic updates.

</details>


### [66] [RSHallu: Dual-Mode Hallucination Evaluation for Remote-Sensing Multimodal Large Language Models with Domain-Tailored Mitigation](https://arxiv.org/abs/2602.10799)
*Zihui Zhou,Yong Feng,Yanying Chen,Guofan Duan,Zhenxi Song,Mingliang Zhou,Weijia Jia*

Main category: cs.CV

TL;DR: 本研究提出了RSHallu，一个系统性的遥感多模态大语言模型（RS-MLLM）幻觉研究，包括幻觉的分类、评估基准和缓解方法，并展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有RS-MLLM在遥感任务中表现出幻觉问题，即生成与输入遥感图像不一致的响应，这严重阻碍了其在高风险场景下的应用，且相关研究尚不充分。

Method: 1. 提出了一个面向遥感特性的幻觉分类法，并引入了图像级幻觉概念。2. 构建了RSHalluEval基准（2023个问答对）以及RSHalluCheck数据集（15,396个问答对）用于训练紧凑型检查器，实现了双模式（云端和本地）的幻觉检测。3. 提出了RSHalluShield数据集（30k个问答对）用于训练缓解，并引入了训练无关的即插即用策略，如解码时logit修正和遥感感知提示。

Result: 所提出的缓解方法在代表性RS-MLLM上，幻觉消除率最高可提高21.63个百分点，同时在下游RS任务（RSVQA/RSVG）上保持了竞争力。

Conclusion: RSHallu系统性地研究了RS-MLLM的幻觉问题，提出了有效的分类、评估和缓解策略，显著提高了RS-MLLM的可靠性，为在关键领域应用RS-MLLM奠定了基础。

Abstract: Multimodal large language models (MLLMs) are increasingly adopted in remote sensing (RS) and have shown strong performance on tasks such as RS visual grounding (RSVG), RS visual question answering (RSVQA), and multimodal dialogue. However, hallucinations, which are responses inconsistent with the input RS images, severely hinder their deployment in high-stakes scenarios (e.g., emergency management and agricultural monitoring) and remain under-explored in RS. In this work, we present RSHallu, a systematic study with three deliverables: (1) we formalize RS hallucinations with an RS-oriented taxonomy and introduce image-level hallucination to capture RS-specific inconsistencies beyond object-centric errors (e.g., modality, resolution, and scene-level semantics); (2) we build a hallucination benchmark RSHalluEval (2,023 QA pairs) and enable dual-mode checking, supporting high-precision cloud auditing and low-cost reproducible local checking via a compact checker fine-tuned on RSHalluCheck dataset (15,396 QA pairs); and (3) we introduce a domain-tailored dataset RSHalluShield (30k QA pairs) for training-friendly mitigation and further propose training-free plug-and-play strategies, including decoding-time logit correction and RS-aware prompting. Across representative RS-MLLMs, our mitigation improves the hallucination-free rate by up to 21.63 percentage points under a unified protocol, while maintaining competitive performance on downstream RS tasks (RSVQA/RSVG). Code and datasets will be released.

</details>


### [67] [AMAP-APP: Efficient Segmentation and Morphometry Quantification of Fluorescent Microscopy Images of Podocytes](https://arxiv.org/abs/2602.10663)
*Arash Fatehi,David Unnersjö-Jess,Linus Butt,Noémie Moreau,Thomas Benzing,Katarzyna Bozek*

Main category: cs.CV

TL;DR: AMAP-APP 是一款用户友好的桌面应用程序，通过优化算法和跨平台支持，大幅提高了足细胞形态学分析的效率和可及性，同时保持了与原始方法的准确性。


<details>
  <summary>Details</summary>
Motivation: 原始的 AMAP 方法计算需求高、缺乏用户界面且依赖 Linux，限制了其在肾脏研究中的应用。开发 AMAP-APP 的目的是克服这些障碍，提高足细胞形态学分析的可及性和效率。

Method: AMAP-APP 通过结合经典图像处理和原有的语义分割模型来优化效率，并引入改进的 ROI 算法来提高精度。使用 365 张小鼠和人类图像进行验证，并通过 Pearson 相关和 TOST 检验与原始 AMAP 进行性能比较。

Result: AMAP-APP 在消费级硬件上实现了 147 倍的处理速度提升。形态学输出（面积、周长、圆度和裂孔隔密度）与原始方法高度相关（r>0.90）且统计学等效（TOST P<0.05）。新的 ROI 算法也显示出比原始方法更高的准确性。

Conclusion: AMAP-APP 通过消除对高性能计算的需求并提供用户友好的跨平台界面，普及了基于深度学习的足细胞形态测量学，有望促进其在肾脏研究和潜在临床诊断中的广泛应用。

Abstract: Background: Automated podocyte foot process quantification is vital for kidney research, but the established "Automatic Morphological Analysis of Podocytes" (AMAP) method is hindered by high computational demands, a lack of a user interface, and Linux dependency. We developed AMAP-APP, a cross-platform desktop application designed to overcome these barriers.
  Methods: AMAP-APP optimizes efficiency by replacing intensive instance segmentation with classic image processing while retaining the original semantic segmentation model. It introduces a refined Region of Interest (ROI) algorithm to improve precision. Validation involved 365 mouse and human images (STED and confocal), benchmarking performance against the original AMAP via Pearson correlation and Two One-Sided T-tests (TOST).
  Results: AMAP-APP achieved a 147-fold increase in processing speed on consumer hardware. Morphometric outputs (area, perimeter, circularity, and slit diaphragm density) showed high correlation (r>0.90) and statistical equivalence (TOST P<0.05) to the original method. Additionally, the new ROI algorithm demonstrated superior accuracy compared to the original, showing reduced deviation from manual delineations.
  Conclusion: AMAP-APP democratizes deep learning-based podocyte morphometry. By eliminating the need for high-performance computing clusters and providing a user-friendly interface for Windows, macOS, and Linux, it enables widespread adoption in nephrology research and potential clinical diagnostics.

</details>


### [68] [Flow caching for autoregressive video generation](https://arxiv.org/abs/2602.10825)
*Yuexiao Ma,Xuzhe Zheng,Jing Xu,Xiwei Xu,Feng Ling,Xiawu Zheng,Huafeng Kuang,Huixia Li,Xing Wang,Xuefeng Xiao,Fei Chao,Rongrong Ji*

Main category: cs.CV

TL;DR: 本文提出FlowCache，一种专为自回归视频生成设计的缓存框架，通过独立的帧块缓存策略和优化的KV缓存压缩，实现了显著的速度提升，同时保持了生成质量。


<details>
  <summary>Details</summary>
Motivation: 自回归视频生成模型（如基于Transformer的模型）虽然擅长生成超长视频，但其顺序生成过程非常缓慢。现有的缓存策略不适用于自回归模型，因为不同视频帧块在相同时间步下的相似性模式不同。

Method: FlowCache采用分块（chunkwise）缓存策略，为每个视频帧块维护独立的缓存策略，动态适应其独特的去噪特性。此外，还引入了一种联合重要性-冗余优化的KV缓存压缩机制，在固定内存限制下保持生成质量。

Result: FlowCache在MAGI-1上实现了2.38倍的速度提升，在SkyReels-V2上实现了6.7倍的速度提升，并且对生成质量的影响极小（VBench得分分别为0.87增加和0.79降低）。

Conclusion: FlowCache成功地解决了自回归视频生成速度慢的问题，使得实时、超长视频生成成为可能，并为大规模高效视频合成树立了新标杆。

Abstract: Autoregressive models, often built on Transformer architectures, represent a powerful paradigm for generating ultra-long videos by synthesizing content in sequential chunks. However, this sequential generation process is notoriously slow. While caching strategies have proven effective for accelerating traditional video diffusion models, existing methods assume uniform denoising across all frames-an assumption that breaks down in autoregressive models where different video chunks exhibit varying similarity patterns at identical timesteps. In this paper, we present FlowCache, the first caching framework specifically designed for autoregressive video generation. Our key insight is that each video chunk should maintain independent caching policies, allowing fine-grained control over which chunks require recomputation at each timestep. We introduce a chunkwise caching strategy that dynamically adapts to the unique denoising characteristics of each chunk, complemented by a joint importance-redundancy optimized KV cache compression mechanism that maintains fixed memory bounds while preserving generation quality. Our method achieves remarkable speedups of 2.38 times on MAGI-1 and 6.7 times on SkyReels-V2, with negligible quality degradation (VBench: 0.87 increase and 0.79 decrease respectively). These results demonstrate that FlowCache successfully unlocks the potential of autoregressive models for real-time, ultra-long video generation-establishing a new benchmark for efficient video synthesis at scale. The code is available at https://github.com/mikeallen39/FlowCache.

</details>


### [69] [(MGS)$^2$-Net: Unifying Micro-Geometric Scale and Macro-Geometric Structure for Cross-View Geo-Localization](https://arxiv.org/abs/2602.10704)
*Minglei Li,Mengfan He,Chao Chen,Ziyang Meng*

Main category: cs.CV

TL;DR: 提出了一种名为(MGS)²的跨视图地理定位框架，通过宏观几何结构过滤和微观几何尺度适应来解决现有方法在几何不对齐方面的不足，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨视图地理定位方法在处理航空影像和卫星影像之间剧烈的几何不对齐问题时性能不佳，尤其是在忽视3D几何信息导致的面和尺度变化问题。研究旨在弥补这一差距。

Method: 提出(MGS)²框架，包含宏观几何结构过滤（MGSF）模块，利用扩张几何梯度过滤高频立面伪影并增强水平面；以及微观几何尺度适应（MGSA）模块，利用深度先验通过多分支特征融合校正尺度差异。此外，还设计了几何外观对比蒸馏（GACD）损失以对抗倾斜遮挡。

Result: 在University-1652和SUES-200数据集上分别取得了97.5%和97.02%的Recall@1，性能优于现有方法。框架在面对几何模糊的跨数据集泛化能力也更强。

Conclusion: (MGS)²框架通过几何感知的方法有效解决了跨视图地理定位中的几何不对齐和尺度变化问题，在性能和泛化能力上均取得了显著提升，是GNSS-denied环境下无人机导航的有效解决方案。

Abstract: Cross-view geo-localization (CVGL) is pivotal for GNSS-denied UAV navigation but remains brittle under the drastic geometric misalignment between oblique aerial views and orthographic satellite references. Existing methods predominantly operate within a 2D manifold, neglecting the underlying 3D geometry where view-dependent vertical facades (macro-structure) and scale variations (micro-scale) severely corrupt feature alignment. To bridge this gap, we propose (MGS)$^2$, a geometry-grounded framework. The core of our innovation is the Macro-Geometric Structure Filtering (MGSF) module. Unlike pixel-wise matching sensitive to noise, MGSF leverages dilated geometric gradients to physically filter out high-frequency facade artifacts while enhancing the view-invariant horizontal plane, directly addressing the domain shift. To guarantee robust input for this structural filtering, we explicitly incorporate a Micro-Geometric Scale Adaptation (MGSA) module. MGSA utilizes depth priors to dynamically rectify scale discrepancies via multi-branch feature fusion. Furthermore, a Geometric-Appearance Contrastive Distillation (GACD) loss is designed to strictly discriminate against oblique occlusions. Extensive experiments demonstrate that (MGS)$^2$ achieves state-of-the-art performance, recording a Recall@1 of 97.5\% on University-1652 and 97.02\% on SUES-200. Furthermore, the framework exhibits superior cross-dataset generalization against geometric ambiguity. The code is available at: \href{https://github.com/GabrielLi1473/MGS-Net}{https://github.com/GabrielLi1473/MGS-Net}.

</details>


### [70] [From Steering to Pedalling: Do Autonomous Driving VLMs Generalize to Cyclist-Assistive Spatial Perception and Planning?](https://arxiv.org/abs/2602.10771)
*Krishna Kanth Nakka,Vedasri Nakka*

Main category: cs.CV

TL;DR: 本文提出了一个名为 CyclingVQA 的新基准，用于评估视觉-语言模型（VLM）在骑行场景下的感知和推理能力。现有模型在骑行视角下的表现仍有待提高，特别是对骑行者特有的交通信号和车道关联的理解。


<details>
  <summary>Details</summary>
Motivation: 现有针对自动驾驶的 VLM 评估主要以车辆为中心，未能充分评估从骑行者视角出发的感知和推理能力，而骑行者在城市交通中面临着许多安全关键的状况。

Method: 作者提出了 CyclingVQA 基准，它包含从骑行者视角出发的感知、时空理解以及交通规则到车道推理的测试。他们评估了 31 个 VLM 模型，包括通用型、增强空间理解型和专注于自动驾驶的模型。

Result: 当前 VLM 模型在 CyclingVQA 上表现出一定的潜力，但在骑行者相关的感知和推理方面存在明显不足，尤其是在解释骑行者特有的交通信号和将标志与正确的导航车道关联方面。一些专注于驾驶的模型甚至不如强大的通用 VLM。

Conclusion: CyclingVQA 基准揭示了当前 VLM 在骑行者辅助场景中的局限性，并指出了改进方向，例如更好地理解骑行者特有的交通信号和进行规则-车道关联推理，以开发更有效的骑行辅助智能系统。

Abstract: Cyclists often encounter safety-critical situations in urban traffic, highlighting the need for assistive systems that support safe and informed decision-making. Recently, vision-language models (VLMs) have demonstrated strong performance on autonomous driving benchmarks, suggesting their potential for general traffic understanding and navigation-related reasoning. However, existing evaluations are predominantly vehicle-centric and fail to assess perception and reasoning from a cyclist-centric viewpoint. To address this gap, we introduce CyclingVQA, a diagnostic benchmark designed to probe perception, spatio-temporal understanding, and traffic-rule-to-lane reasoning from a cyclist's perspective. Evaluating 31+ recent VLMs spanning general-purpose, spatially enhanced, and autonomous-driving-specialized models, we find that current models demonstrate encouraging capabilities, while also revealing clear areas for improvement in cyclist-centric perception and reasoning, particularly in interpreting cyclist-specific traffic cues and associating signs with the correct navigational lanes. Notably, several driving-specialized models underperform strong generalist VLMs, indicating limited transfer from vehicle-centric training to cyclist-assistive scenarios. Finally, through systematic error analysis, we identify recurring failure modes to guide the development of more effective cyclist-assistive intelligent systems.

</details>


### [71] [FGAA-FPN: Foreground-Guided Angle-Aware Feature Pyramid Network for Oriented Object Detection](https://arxiv.org/abs/2602.10710)
*Jialin Ma*

Main category: cs.CV

TL;DR: 提出了一种名为 FGAA-FPN 的新方法，用于检测具有方向性的物体，通过引导前景和感知角度来提高特征区分度，并在 DOTA 数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的定向物体检测方法在处理背景杂乱、尺度变化大和方向变化剧烈等挑战时存在不足，尤其是在显式前景建模和利用几何方向先验方面。

Method: 提出 FGAA-FPN，构建了一个层次化的功能分解，并引入了两个关键模块：1. 前景引导特征调制 (FGAA) 模块，通过弱监督学习前景显著性来增强物体区域并抑制背景干扰；2. 角度感知多头注意力 (FPN) 模块，编码相对方向关系以指导高层语义特征的全局交互。

Result: 在 DOTA v1.0 和 DOTA v1.5 数据集上的实验表明，FGAA-FPN 取得了最先进的性能，分别达到了 75.5% 和 68.3% 的 mAP。

Conclusion: FGAA-FPN 通过显式的前景建模和角度感知机制，有效解决了定向物体检测中的挑战，提升了特征的区分度，并在两个大规模数据集上取得了优异的成果。

Abstract: With the increasing availability of high-resolution remote sensing and aerial imagery, oriented object detection has become a key capability for geographic information updating, maritime surveillance, and disaster response. However, it remains challenging due to cluttered backgrounds, severe scale variation, and large orientation changes. Existing approaches largely improve performance through multi-scale feature fusion with feature pyramid networks or contextual modeling with attention, but they often lack explicit foreground modeling and do not leverage geometric orientation priors, which limits feature discriminability. To overcome these limitations, we propose FGAA-FPN, a Foreground-Guided Angle-Aware Feature Pyramid Network for oriented object detection. FGAA-FPN is built on a hierarchical functional decomposition that accounts for the distinct spatial resolution and semantic abstraction across pyramid levels, thereby strengthening multi-scale representations. Concretely, a Foreground-Guided Feature Modulation module learns foreground saliency under weak supervision to enhance object regions and suppress background interference in low-level features. In parallel, an Angle-Aware Multi-Head Attention module encodes relative orientation relationships to guide global interactions among high-level semantic features. Extensive experiments on DOTA v1.0 and DOTA v1.5 demonstrate that FGAA-FPN achieves state-of-the-art results, reaching 75.5% and 68.3% mAP, respectively.

</details>


### [72] [Towards Learning a Generalizable 3D Scene Representation from 2D Observations](https://arxiv.org/abs/2602.10943)
*Martin Gromniak,Jan-Gerrit Habekost,Sebastian Kamp,Sven Magg,Stefan Wermter*

Main category: cs.CV

TL;DR: 提出一种可泛化的神经辐射场方法，用于从机器人自身视角观测预测三维工作空间占用情况，并将表示置于全局工作空间帧中，适用于机器人操控，无需针对特定场景进行微调。


<details>
  <summary>Details</summary>
Motivation: 现有方法在以相机为中心的坐标系中操作，不直接适用于机器人操控；需要一种能够处理灵活的源视图并泛化到未见过的物体排列的方法。

Method: 使用神经辐射场（NeRF）方法，将占用表示构建在全局工作空间帧中，支持灵活的源视图输入，并能够在没有场景特定微调的情况下泛化。

Result: 在人形机器人上进行演示，与3D传感器真实值相比，在40个真实场景的训练下，实现了26mm的重建误差，包括了被遮挡的区域。

Conclusion: 该方法能够推断出完整的3D占用情况，超越了传统的立体视觉方法，并适用于机器人操控任务。

Abstract: We introduce a Generalizable Neural Radiance Field approach for predicting 3D workspace occupancy from egocentric robot observations. Unlike prior methods operating in camera-centric coordinates, our model constructs occupancy representations in a global workspace frame, making it directly applicable to robotic manipulation. The model integrates flexible source views and generalizes to unseen object arrangements without scene-specific finetuning. We demonstrate the approach on a humanoid robot and evaluate predicted geometry against 3D sensor ground truth. Trained on 40 real scenes, our model achieves 26mm reconstruction error, including occluded regions, validating its ability to infer complete 3D occupancy beyond traditional stereo vision methods.

</details>


### [73] [Ecological mapping with geospatial foundation models](https://arxiv.org/abs/2602.10720)
*Craig Mahlasi,Gciniwe S. Baloyi,Zaheed Gaffoor,Levente Klein,Anne Jones,Etienne Vos,Michal Muszynski,Geoffrey Dawson,Campbell Watson*

Main category: cs.CV

TL;DR: 本文探索了地理空间基础模型 (GFMs) 在生态应用中的效用、挑战和机遇，并通过微调 Prithvi-E0-2.0 和 TerraMind 模型，在土地利用/覆盖（LULC）生成、森林功能性状测绘和泥炭地检测方面，与基线 ResNet-101 模型进行了比较。结果表明，GFMs 优于基线模型，TerraMind 在使用多模态数据时表现最佳，但也指出了数据分辨率和标签准确性的局限性。


<details>
  <summary>Details</summary>
Motivation: 地理空间基础模型（GFMs）在生态制图等地理空间任务中展现出巨大潜力，但其在高价值应用中的效用尚未被充分探索。因此，本研究旨在评估 GFMs 在生态应用中的实用性、挑战和机遇。

Method: 本文微调了预训练的 AI 模型 Prithvi-E0-2.0 和 TerraMind，并将其与基线 ResNet-101 模型在三个用例中进行比较：TerraMind 的 LULC 生成能力、森林功能性状测绘以及泥炭地检测。模型性能通过对比实验进行评估。

Result: 在所有实验中，GFMs 的表现均优于基线 ResNet 模型。TerraMind 模型通常略优于 Prithvi 模型，但在加入额外的模态数据后，TerraMind 的性能显著优于基线 ResNet 和 Prithvi 模型。研究还指出，预训练模型的输入数据与其应用场景的输入数据之间的差异需要引起重视。

Conclusion: GFMs 在生态应用中具有显著优势，特别是 TerraMind 模型在结合多模态数据时表现出色。然而，模型性能的提升还依赖于更高分辨率和更准确的标签数据，尤其是在需要映射像素级动态的场景中。此外，需要关注预训练模型与实际应用数据之间的兼容性问题。

Abstract: Geospatial foundation models (GFMs) are a fast-emerging paradigm for various geospatial tasks, such as ecological mapping. However, the utility of GFMs has not been fully explored for high-value use cases. This study aims to explore the utility, challenges and opportunities associated with the application of GFMs for ecological uses. In this regard, we fine-tune several pretrained AI models, namely, Prithvi-E0-2.0 and TerraMind, across three use cases, and compare this with a baseline ResNet-101 model. Firstly, we demonstrate TerraMind's LULC generation capabilities. Lastly, we explore the utility of the GFMs in forest functional trait mapping and peatlands detection. In all experiments, the GFMs outperform the baseline ResNet models. In general TerraMind marginally outperforms Prithvi. However, with additional modalities TerraMind significantly outperforms the baseline ResNet and Prithvi models. Nonetheless, consideration should be given to the divergence of input data from pretrained modalities. We note that these models would benefit from higher resolution and more accurate labels, especially for use cases where pixel-level dynamics need to be mapped.

</details>


### [74] [OccFace: Unified Occlusion-Aware Facial Landmark Detection with Per-Point Visibility](https://arxiv.org/abs/2602.10728)
*Xinhao Xiang,Zhengxin Li,Saurav Dhakad,Theo Bancroft,Jiawei Zhang,Weiyang Li*

Main category: cs.CV

TL;DR: 提出了一种名为 OccFace 的新框架，用于检测具有遮挡的人脸关键点，该框架不仅预测关键点位置，还预测每个关键点的可见性，并引入了一种新的评估方法来衡量其性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸关键点检测方法在处理遮挡时效果不佳，并且不提供关键点可见性信息，而这些信息对下游应用很有用。研究的动机是开发一种能够显式处理遮挡并提供可见性预测的通用人脸关键点检测框架。

Method: OccFace 框架采用统一的 100 点布局和基于热力图的骨干网络，并增加了一个遮挡模块。该模块结合局部证据和跨关键点上下文，联合预测关键点坐标和每个点的可见性。可见性监督通过手动标签和从掩码-热力图重叠派生的伪可见性来实现。此外，还创建了一个包含 100 点关键点和每点可见性标注的数据集，以及一个用于评估遮挡感知性能的评估套件。

Result: 实验结果表明，OccFace 在外部遮挡和大幅度头部旋转的情况下，特别是在遮挡区域，鲁棒性得到了提高，同时保持了可见关键点的准确性。新的评估套件能够报告可见和遮挡关键点的 NME，以及通过 Occ AP、F1@0.5 和 ROC-AUC 进行可见性基准测试。

Conclusion: OccFace 框架能够有效地处理人脸关键点检测中的遮挡问题，并提供有用的可见性信息，从而提高了在复杂场景下的鲁棒性和准确性，并且其提出的评估方法能够更全面地衡量模型在遮挡情况下的性能。

Abstract: Accurate facial landmark detection under occlusion remains challenging, especially for human-like faces with large appearance variation and rotation-driven self-occlusion. Existing detectors typically localize landmarks while handling occlusion implicitly, without predicting per-point visibility that downstream applications can benefits. We present OccFace, an occlusion-aware framework for universal human-like faces, including humans, stylized characters, and other non-human designs. OccFace adopts a unified dense 100-point layout and a heatmap-based backbone, and adds an occlusion module that jointly predicts landmark coordinates and per-point visibility by combining local evidence with cross-landmark context. Visibility supervision mixes manual labels with landmark-aware masking that derives pseudo visibility from mask-heatmap overlap. We also create an occlusion-aware evaluation suite reporting NME on visible vs. occluded landmarks and benchmarking visibility with Occ AP, F1@0.5, and ROC-AUC, together with a dataset annotated with 100-point landmarks and per-point visibility. Experiments show improved robustness under external occlusion and large head rotations, especially on occluded regions, while preserving accuracy on visible landmarks.

</details>


### [75] [Healthy Harvests: A Comparative Look at Guava Disease Classification Using InceptionV3](https://arxiv.org/abs/2602.10967)
*Samanta Ghosh,Shaila Afroz Anika,Umma Habiba Ahmed,B. M. Shahria Alam,Mohammad Tahmid Noor,Nishat Tasnim Niloy*

Main category: cs.CV

TL;DR: 本研究利用深度学习模型（InceptionV3 和 ResNet50）对输入的番石榴图像进行疾病分类，并在数据增强和 CutMix/MixUp 等技术下，InceptionV3 模型取得了 98.15% 的高准确率。


<details>
  <summary>Details</summary>
Motivation: 番石榴易受多种疾病侵害，影响产量和品质，因此需要对疾病进行早期识别以减少损失。

Method: 收集了 473 张番石榴图像，经过预处理（调整大小、RGB 格式）和数据增强（生成 3784 张图像）。采用 InceptionV3 和 ResNet50 两种深度学习模型进行图像分类。为提升模型鲁棒性，应用了 CutMix 和 MixUp 数据混合技术。使用混淆矩阵评估模型性能，并利用 SHAP 分析提高模型的可解释性。

Result: InceptionV3 模型在疾病分类任务中达到了 98.15% 的准确率，ResNet50 模型准确率为 94.46%。SHAP 分析有助于理解模型预测的关键图像区域。

Conclusion: 该研究表明，通过结合先进的深度学习模型（如 InceptionV3）、数据增强和数据混合技术，可以有效地对番石榴的疾病进行高精度分类，并提高了模型的可解释性。

Abstract: Guava fruits often suffer from many diseases. This can harm fruit quality and fruit crop yield. Early identification is important for minimizing damage and ensuring fruit health. This study focuses on 3 different categories for classifying diseases. These are Anthracnose, Fruit flies, and Healthy fruit. The data set used in this study is collected from Mendeley Data. This dataset contains 473 original images of Guava. These images vary in size and format. The original dataset was resized to 256x256 pixels with RGB color mode for better consistency. After this, the Data augmentation process is applied to improve the dataset by generating variations of the original images. The augmented dataset consists of 3784 images using advanced preprocessing techniques. Two deep learning models were implemented to classify the images. The InceptionV3 model is well known for its advanced framework. These apply multiple convolutional filters for obtaining different features effectively. On the other hand, the ResNet50 model helps to train deeper networks by using residual learning. The InceptionV3 model achieved the impressive accuracy of 98.15%, and ResNet50got 94.46% accuracy. Data mixing methods such as CutMix and MixUp were applied to enhance the model's robustness. The confusion matrix was used to evaluate the overall model performance of both InceptionV3 and Resnet50. Additionally, SHAP analysis is used to improve interpretability, which helps to find the significant parts of the image for the model prediction. This study purposes to highlight how advanced models enhan

</details>


### [76] [Spectral-Spatial Contrastive Learning Framework for Regression on Hyperspectral Data](https://arxiv.org/abs/2602.10745)
*Mohamad Dhaini,Paul Honeine,Maxime Berar,Antonin Van Exem*

Main category: cs.CV

TL;DR: 提出了一种用于高光谱数据回归任务的谱-空间对比学习框架，可通用于多种骨干网络，并提供数据增强方法，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 对比学习在图像分类任务中取得了巨大成功，但在回归任务，尤其是高光谱数据上的应用研究较少。

Method: 提出了一种谱-空间对比学习框架，该框架采用模型无关的设计，可以增强3D卷积和基于Transformer的网络等骨干模型；此外，还提供了一系列适用于高光谱数据增强的变换方法。

Result: 在合成和真实高光谱数据集上的实验表明，所提出的框架和数据增强方法显著提高了所有研究的骨干模型的性能。

Conclusion: 所提出的谱-空间对比学习框架和数据增强方法能有效提升高光谱数据回归任务的性能。

Abstract: Contrastive learning has demonstrated great success in representation learning, especially for image classification tasks. However, there is still a shortage in studies targeting regression tasks, and more specifically applications on hyperspectral data. In this paper, we propose a spectral-spatial contrastive learning framework for regression tasks for hyperspectral data, in a model-agnostic design allowing to enhance backbones such as 3D convolutional and transformer-based networks. Moreover, we provide a collection of transformations relevant for augmenting hyperspectral data. Experiments on synthetic and real datasets show that the proposed framework and transformations significantly improve the performance of all studied backbone models.

</details>


### [77] [Chain-of-Look Spatial Reasoning for Dense Surgical Instrument Counting](https://arxiv.org/abs/2602.11024)
*Rishikesh Bhyri,Brian R Quaranto,Philip J Seger,Kaity Tung,Brendan Fox,Gene Yang,Steven D. Schwaitzberg,Junsong Yuan,Nan Xi,Peter C W Kim*

Main category: cs.CV

TL;DR: 本文提出了一种名为Chain-of-Look的新型视觉推理框架，用于解决手术室中密集场景下手术器械计数精度不高的问题。该框架通过强制一个结构化的视觉链来模仿人类的计数过程，并引入邻域损失函数来考虑器械的空间约束。同时，发布了新的高密度手术器械数据集SurgCount-HD。


<details>
  <summary>Details</summary>
Motivation: 现有手术器械计数方法，尤其是在密集场景下，精度不高，无法满足患者安全的需求。大型视觉-语言模型和智能体AI虽然取得进展，但在此类特定任务上仍面临挑战。

Method: 提出Chain-of-Look框架，通过构建结构化的视觉链来模仿人类的顺序计数过程，而非依赖无序的目标检测。引入邻域损失函数，明确建模器械之间的空间约束。

Result: 在SurgCount-HD数据集上进行的实验表明，Chain-of-Look在密集手术器械计数任务上，性能优于现有的最先进计数方法（如CountGD, REC）以及多模态大语言模型（如Qwen, ChatGPT）。

Conclusion: Chain-of-Look框架通过引入结构化视觉链和邻域损失函数，有效解决了密集场景下手术器械计数精度的问题，并证明了其在实际应用中的优越性。

Abstract: Accurate counting of surgical instruments in Operating Rooms (OR) is a critical prerequisite for ensuring patient safety during surgery. Despite recent progress of large visual-language models and agentic AI, accurately counting such instruments remains highly challenging, particularly in dense scenarios where instruments are tightly clustered. To address this problem, we introduce Chain-of-Look, a novel visual reasoning framework that mimics the sequential human counting process by enforcing a structured visual chain, rather than relying on classic object detection which is unordered. This visual chain guides the model to count along a coherent spatial trajectory, improving accuracy in complex scenes. To further enforce the physical plausibility of the visual chain, we introduce the neighboring loss function, which explicitly models the spatial constraints inherent to densely packed surgical instruments. We also present SurgCount-HD, a new dataset comprising 1,464 high-density surgical instrument images. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches for counting (e.g., CountGD, REC) as well as Multimodality Large Language Models (e.g., Qwen, ChatGPT) in the challenging task of dense surgical instrument counting.

</details>


### [78] [Text-to-Vector Conversion for Residential Plan Design](https://arxiv.org/abs/2602.10757)
*Egor Bazhenov,Stepan Kasai,Viacheslav Shalamov,Valeria Efimova*

Main category: cs.CV

TL;DR: 本文提出了一种从文本描述生成矢量住宅平面图的新方法，并在视觉质量上优于现有方法。此外，还开发了一种将栅格平面图矢量化为结构化矢量图像的新算法，该算法在CLIPscore方面也表现出性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成高质量的矢量图形，特别是从文本描述生成住宅平面图方面存在不足。同时，将现有的栅格平面图转换为结构化的矢量图像也面临挑战，需要提高视觉质量和结构化程度。

Method: 1. 提出一种新的文本到矢量住宅平面图生成方法，该方法能够处理直角和灵活的设置。2. 开发了一种新的算法，用于将栅格平面图矢量化为结构化的矢量图像。

Result: 1. 新的文本到矢量生成方法在基于CLIPScore的视觉质量上比现有方法提高了约5%。2. 新的矢量化算法生成的图像比其他方法在CLIPscore上提高了约4%。

Conclusion: 本文提出的两种方法在生成和矢量化矢量图形方面都取得了显著的进步，特别是在住宅平面图的生成和视觉质量的提升上，为计算机图形学领域提供了更优的解决方案。

Abstract: Computer graphics, comprising both raster and vector components, is a fundamental part of modern science, industry, and digital communication. While raster graphics offer ease of use, its pixel-based structure limits scalability. Vector graphics, defined by mathematical primitives, provides scalability without quality loss, however, it is more complex to produce. For design and architecture, the versatility of vector graphics is paramount, despite its computational demands. This paper introduces a novel method for generating vector residential plans from textual descriptions. Our approach surpasses existing solutions by approximately 5% in CLIPScore-based visual quality, benefiting from its inherent handling of right angles and flexible settings. Additionally, we present a new algorithm for vectorizing raster plans into structured vector images. Such images have a better CLIPscore compared to others by about 4%.

</details>


### [79] [Dual-End Consistency Model](https://arxiv.org/abs/2602.10764)
*Linwei Dong,Ruoyu Guo,Ge Bai,Zehuan Yuan,Yawei Luo,Changqing Zou*

Main category: cs.CV

TL;DR: 本文提出了双端一致性模型（DE-CM），通过选择关键子轨迹来解决现有一致性模型的训练不稳定和采样不灵活问题，并在ImageNet上实现了最先进的一步生成效果。


<details>
  <summary>Details</summary>
Motivation: 扩散模型和流模型生成速度慢，现有的一致性模型（CMs）虽然是高效生成的一种先进蒸馏方法，但其大规模应用仍受训练不稳定和采样不灵活的限制。现有方法通常通过架构调整或正则化目标来解决这些问题，但忽略了轨迹选择的重要性。

Method: 作者分析了训练不稳定的原因（由不稳定的自监督项引起的损失发散）和采样不灵活的原因（误差累积）。基于这些分析，提出了双端一致性模型（DE-CM），通过选择关键子轨迹实现稳定有效的训练。DE-CM分解了PF-ODE轨迹，选择三个关键子轨迹作为优化目标。具体而言，该方法利用连续时间CMs目标实现少步蒸馏，并使用流匹配作为边界正则化器来稳定训练过程。此外，还提出了一种新颖的噪声到噪声（N2N）映射，可以将噪声映射到任意点，从而减轻第一步的误差累积。

Result: 在ImageNet 256x256数据集上进行的一步生成实验中，DE-CM取得了1.70的FID分数，优于现有的基于CM的一步生成方法。

Conclusion: DE-CM通过选择关键子轨迹，成功解决了现有CMs的训练不稳定和采样不灵活问题，并在高效生成方面取得了最先进的性能。

Abstract: The slow iterative sampling nature remains a major bottleneck for the practical deployment of diffusion and flow-based generative models. While consistency models (CMs) represent a state-of-the-art distillation-based approach for efficient generation, their large-scale application is still limited by two key issues: training instability and inflexible sampling. Existing methods seek to mitigate these problems through architectural adjustments or regularized objectives, yet overlook the critical reliance on trajectory selection. In this work, we first conduct an analysis on these two limitations: training instability originates from loss divergence induced by unstable self-supervised term, whereas sampling inflexibility arises from error accumulation. Based on these insights and analysis, we propose the Dual-End Consistency Model (DE-CM) that selects vital sub-trajectory clusters to achieve stable and effective training. DE-CM decomposes the PF-ODE trajectory and selects three critical sub-trajectories as optimization targets. Specifically, our approach leverages continuous-time CMs objectives to achieve few-step distillation and utilizes flow matching as a boundary regularizer to stabilize the training process. Furthermore, we propose a novel noise-to-noisy (N2N) mapping that can map noise to any point, thereby alleviating the error accumulation in the first step. Extensive experimental results show the effectiveness of our method: it achieves a state-of-the-art FID score of 1.70 in one-step generation on the ImageNet 256x256 dataset, outperforming existing CM-based one-step approaches.

</details>


### [80] [Chatting with Images for Introspective Visual Thinking](https://arxiv.org/abs/2602.11073)
*Junfei Wu,Jian Guan,Qiang Liu,Shu Wu,Liang Wang,Wei Wu,Tienie Tan*

Main category: cs.CV

TL;DR: 提出了一种名为“chatting with images”的新框架，通过语言指导的特征调制来改进视觉操作，以解决现有LVLMs在细粒度视觉信息丢失和跨模态对齐不足的问题。名为ViLaVT的模型在八个基准测试中表现出色，尤其在多图像和视频空间推理任务上。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型（LVLMs）依赖单次视觉编码，容易丢失细粒度视觉信息。尽管“thinking with images”方法试图通过外部工具或代码来操作图像，但其视觉状态与语言语义的关联性不足，阻碍了有效的跨模态对齐，尤其是在需要跨越远距离区域或多张图像进行视觉语义或几何关系推理时。

Method: 提出“chatting with images”框架，将视觉操作重新定义为语言指导的特征调制。模型在语言提示的指导下，对多个图像区域进行动态联合重新编码，实现语言推理与视觉状态更新的紧密耦合。具体实现为ViLaVT模型，该模型配备了动态视觉编码器，并通过两阶段课程（监督微调和强化学习）进行训练。

Result: ViLaVT在八个基准测试中取得了强大且一致的改进，特别是在复杂的、涉及多图像和视频的空间推理任务上取得了显著的提升。

Conclusion: “chatting with images”框架通过语言指导的特征调制，能够有效地实现语言推理与视觉状态更新的紧密耦合，克服了现有LVLMs在细粒度视觉信息处理和跨模态对齐方面的局限性，并在多模态推理任务中展现出优越性能。

Abstract: Current large vision-language models (LVLMs) typically rely on text-only reasoning based on a single-pass visual encoding, which often leads to loss of fine-grained visual information. Recently the proposal of ''thinking with images'' attempts to alleviate this limitation by manipulating images via external tools or code; however, the resulting visual states are often insufficiently grounded in linguistic semantics, impairing effective cross-modal alignment - particularly when visual semantics or geometric relationships must be reasoned over across distant regions or multiple images. To address these challenges, we propose ''chatting with images'', a new framework that reframes visual manipulation as language-guided feature modulation. Under the guidance of expressive language prompts, the model dynamically performs joint re-encoding over multiple image regions, enabling tighter coupling between linguistic reasoning and visual state updates. We instantiate this paradigm in ViLaVT, a novel LVLM equipped with a dynamic vision encoder explicitly designed for such interactive visual reasoning, and trained it with a two-stage curriculum combining supervised fine-tuning and reinforcement learning to promote effective reasoning behaviors. Extensive experiments across eight benchmarks demonstrate that ViLaVT achieves strong and consistent improvements, with particularly pronounced gains on complex multi-image and video-based spatial reasoning tasks.

</details>


### [81] [DMP-3DAD: Cross-Category 3D Anomaly Detection via Realistic Depth Map Projection with Few Normal Samples](https://arxiv.org/abs/2602.10806)
*Zi Wang,Katsuya Hotta,Koichiro Kamide,Yawen Zou,Jianjian Qin,Chao Zhang,Jun Yu*

Main category: cs.CV

TL;DR: 提出了一种名为DMP-3DAD的训练无关框架，用于跨类别3D异常检测，通过多视角深度图投影和冻结的CLIP视觉编码器实现，在少样本场景下表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数跨类别3D异常检测方法依赖于特定类别的训练，这在少样本场景下限制了其灵活性。

Method: 将3D点云转换为一系列逼真的深度图，利用冻结的CLIP视觉编码器提取多视角特征，并通过加权特征相似度进行异常检测，无需微调或依赖特定类别。

Result: 在ShapeNetPart数据集的少样本设置下，DMP-3DAD取得了最先进的性能。

Conclusion: DMP-3DAD是一种简单而有效的跨类别3D异常检测解决方案，适用于实际应用。

Abstract: Cross-category anomaly detection for 3D point clouds aims to determine whether an unseen object belongs to a target category using only a few normal examples. Most existing methods rely on category-specific training, which limits their flexibility in few-shot scenarios. In this paper, we propose DMP-3DAD, a training-free framework for cross-category 3D anomaly detection based on multi-view realistic depth map projection. Specifically, by converting point clouds into a fixed set of realistic depth images, our method leverages a frozen CLIP visual encoder to extract multi-view representations and performs anomaly detection via weighted feature similarity, which does not require any fine-tuning or category-dependent adaptation. Extensive experiments on the ShapeNetPart dataset demonstrate that DMP-3DAD achieves state-of-the-art performance under few-shot setting. The results show that the proposed approach provides a simple yet effective solution for practical cross-category 3D anomaly detection.

</details>


### [82] [DeepImageSearch: Benchmarking Multimodal Agents for Context-Aware Image Retrieval in Visual Histories](https://arxiv.org/abs/2602.10809)
*Chenlong Deng,Mengjie Deng,Junjie Wu,Dun Zeng,Teng Wang,Qingsong Xie,Jiadeng Huang,Shengjie Ma,Changwang Zhang,Zhaoxiang Wang,Jun Wang,Yutao Zhu,Zhicheng Dou*

Main category: cs.CV

TL;DR: 本文提出了一种名为DeepImageSearch的代理式多模态检索新范式，通过在原始视觉历史中进行多步推理来解决现有系统独立检索的问题。并构建了DISBench基准和人机协作流水线来应对可扩展性挑战，实验表明该方法对现有SOTA模型提出了显著挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法的局限性在于它们在检索时孤立地考虑查询-图像相关性，忽略了现实世界视觉流中固有的丰富的时序依赖关系，而信息往往分布在时间序列中而非单个快照。

Method: 提出了DeepImageSearch这一代理式范式，将图像检索重塑为自主探索任务。构建了DISBench基准，包含相互关联的视觉数据。为了解决创建与上下文相关的查询的可扩展性挑战，提出了一种人机协作流水线，利用视觉-语言模型挖掘潜在的时空关联，并先进行模型验证再由人类确认。同时，构建了一个基于模块化代理框架的基线，配备了细粒度的工具和双记忆系统。

Result: DISBench基准对当前最先进的模型构成了显著的挑战，表明了将代理式推理纳入下一代检索系统的必要性。

Conclusion: DeepImageSearch作为一种新的代理式范式，通过多步推理克服了现有多模态检索系统在处理时序依赖性方面的不足，并提供了相应的基准和解决方案，证明了代理式推理在未来检索系统中的重要性。

Abstract: Existing multimodal retrieval systems excel at semantic matching but implicitly assume that query-image relevance can be measured in isolation. This paradigm overlooks the rich dependencies inherent in realistic visual streams, where information is distributed across temporal sequences rather than confined to single snapshots. To bridge this gap, we introduce DeepImageSearch, a novel agentic paradigm that reformulates image retrieval as an autonomous exploration task. Models must plan and perform multi-step reasoning over raw visual histories to locate targets based on implicit contextual cues. We construct DISBench, a challenging benchmark built on interconnected visual data. To address the scalability challenge of creating context-dependent queries, we propose a human-model collaborative pipeline that employs vision-language models to mine latent spatiotemporal associations, effectively offloading intensive context discovery before human verification. Furthermore, we build a robust baseline using a modular agent framework equipped with fine-grained tools and a dual-memory system for long-horizon navigation. Extensive experiments demonstrate that DISBench poses significant challenges to state-of-the-art models, highlighting the necessity of incorporating agentic reasoning into next-generation retrieval systems.

</details>


### [83] [Why Does RL Generalize Better Than SFT? A Data-Centric Perspective on VLM Post-Training](https://arxiv.org/abs/2602.10815)
*Aojun Lu,Tao Feng,Hangjie Yuan,Wei Li,Yanan Sun*

Main category: cs.CV

TL;DR: 研究提出了一种名为DC-SFT的数据筛选方法，通过显式过滤训练数据中的难易样本，显著提升了视觉语言模型（VLMs）在分布外（OOD）任务上的泛化能力，并优于现有的强化学习（RL）方法。


<details>
  <summary>Details</summary>
Motivation: 观察到大规模视觉语言模型（VLMs）通过RL微调比SFT微调具有更好的OOD泛化能力，作者假设这源于RL隐含的数据筛选机制，倾向于选择中等难度的训练样本。因此，本文旨在验证数据难度对VLM泛化能力的影响，并提出一种数据驱动的解决方案。

Method: 首先，系统性地评估了SFT模型在不同难度训练数据集上的OOD泛化能力。然后，基于发现的难样本会损害OOD性能的结论，提出了一种名为Difficulty-Curated SFT (DC-SFT) 的方法，该方法显式地根据样本难度对训练集进行筛选。

Result: 实验证实了数据难度是影响OOD泛化的关键因素，训练难样本会显著降低OOD性能。DC-SFT方法在OOD泛化能力上显著优于标准SFT，并且超越了基于RL的训练方法，同时在稳定性和计算效率方面也表现更佳。

Conclusion: 本文提供了一个数据中心的视角来解释VLM的OOD泛化差距，并提出DC-SFT是一种更有效、更稳定的方法，能够实现比RL方法更强的OOD泛化能力，为获得鲁棒泛化能力提供了更高效的途径。

Abstract: The adaptation of large-scale Vision-Language Models (VLMs) through post-training reveals a pronounced generalization gap: models fine-tuned with Reinforcement Learning (RL) consistently achieve superior out-of-distribution (OOD) performance compared to those trained with Supervised Fine-Tuning (SFT). This paper posits a data-centric explanation for this phenomenon, contending that RL's generalization advantage arises from an implicit data filtering mechanism that inherently prioritizes medium-difficulty training samples. To test this hypothesis, we systematically evaluate the OOD generalization of SFT models across training datasets of varying difficulty levels. Our results confirm that data difficulty is a critical factor, revealing that training on hard samples significantly degrades OOD performance. Motivated by this finding, we introduce Difficulty-Curated SFT (DC-SFT), a straightforward method that explicitly filters the training set based on sample difficulty. Experiments show that DC-SFT not only substantially enhances OOD generalization over standard SFT, but also surpasses the performance of RL-based training, all while providing greater stability and computational efficiency. This work offers a data-centric account of the OOD generalization gap in VLMs and establishes a more efficient pathway to achieving robust generalization. Code is available at https://github.com/byyx666/DC-SFT.

</details>


### [84] [Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling](https://arxiv.org/abs/2602.11146)
*Gongye Liu,Bo Yang,Yida Zhi,Zhizhou Zhong,Lei Ke,Didan Deng,Han Gao,Yongxiang Huang,Kaihao Zhang,Hongbo Fu,Wenhan Luo*

Main category: cs.CV

TL;DR: 提出了一种名为DiNa-LRM的新型扩散模型偏好学习方法，该方法直接在含噪声的扩散状态下进行，计算成本低且效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的用于扩散模型和流匹配模型的偏好优化方法依赖于计算成本高昂且在辨别上不够鲁棒的奖励函数。基于视觉语言模型（VLM）的奖励方法计算和内存成本很高，并且在像素空间奖励下优化潜在扩散生成器存在域不匹配问题。

Method: 提出DiNa-LRM，一种扩散原生的潜在奖励模型，将偏好学习直接建立在含噪声的扩散状态上。该方法引入了一种噪声校准的Thurstone似然函数，并具有依赖于扩散噪声的不确定性。DiNa-LRM利用预训练的潜在扩散骨干网络和一个时间步长条件化的奖励头，支持推理时噪声集成。

Result: DiNa-LRM在图像对齐基准测试中显著优于现有的基于扩散的奖励基线，并且在计算成本仅为最先进VLM的一小部分的情况下，取得了与之相当的性能。在偏好优化方面，DiNa-LRM提高了优化动力学，实现了更快、更资源高效的模型对齐。

Conclusion: DiNa-LRM通过直接在扩散状态下进行偏好学习，有效地解决了现有奖励模型的计算和域不匹配问题，实现了更高效、更鲁棒的扩散模型偏好优化。

Abstract: Preference optimization for diffusion and flow-matching models relies on reward functions that are both discriminatively robust and computationally efficient. Vision-Language Models (VLMs) have emerged as the primary reward provider, leveraging their rich multimodal priors to guide alignment. However, their computation and memory cost can be substantial, and optimizing a latent diffusion generator through a pixel-space reward introduces a domain mismatch that complicates alignment. In this paper, we propose DiNa-LRM, a diffusion-native latent reward model that formulates preference learning directly on noisy diffusion states. Our method introduces a noise-calibrated Thurstone likelihood with diffusion-noise-dependent uncertainty. DiNa-LRM leverages a pretrained latent diffusion backbone with a timestep-conditioned reward head, and supports inference-time noise ensembling, providing a diffusion-native mechanism for test-time scaling and robust rewarding. Across image alignment benchmarks, DiNa-LRM substantially outperforms existing diffusion-based reward baselines and achieves performance competitive with state-of-the-art VLMs at a fraction of the computational cost. In preference optimization, we demonstrate that DiNa-LRM improves preference optimization dynamics, enabling faster and more resource-efficient model alignment.

</details>


### [85] [Resource-Efficient RGB-Only Action Recognition for Edge Deployment](https://arxiv.org/abs/2602.10818)
*Dongsik Yoon,Jongeun Kim,Dayeon Lee*

Main category: cs.CV

TL;DR: 提出了一种紧凑的仅RGB网络，适用于边缘设备上的高效动作识别，在NTU RGB+D数据集上实现了良好的精度-效率平衡，并在Jetson Orin Nano上验证了其资源利用率。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上进行动作识别面临低延迟、内存、存储和功耗的严格限制。现有的利用骨骼和深度信息的方法虽然能提高性能，但需要额外传感器或计算量大的姿态估计，实用性受限。

Method: 提出了一种基于X3D风格骨干网络并结合时间移位（Temporal Shift）的紧凑型仅RGB网络。该网络还引入了选择性时间适应（selective temporal adaptation）和无参数注意力（parameter-free attention）机制。

Result: 在NTU RGB+D 60和120基准测试中，该方法在精度和效率之间取得了良好的平衡。在Jetson Orin Nano上的实际部署测试表明，其设备占用空间更小，资源利用率更实用，优于现有的基于RGB的动作识别技术。

Conclusion: 所提出的紧凑型仅RGB网络能够有效地在资源受限的边缘设备上执行动作识别任务，兼顾了性能和效率，并具有实际部署的优势。

Abstract: Action recognition on edge devices poses stringent constraints on latency, memory, storage, and power consumption. While auxiliary modalities such as skeleton and depth information can enhance recognition performance, they often require additional sensors or computationally expensive pose-estimation pipelines, limiting practicality for edge use. In this work, we propose a compact RGB-only network tailored for efficient on-device inference. Our approach builds upon an X3D-style backbone augmented with Temporal Shift, and further introduces selective temporal adaptation and parameter-free attention. Extensive experiments on the NTU RGB+D 60 and 120 benchmarks demonstrate a strong accuracy-efficiency balance. Moreover, deployment-level profiling on the Jetson Orin Nano verifies a smaller on-device footprint and practical resource utilization compared to existing RGB-based action recognition techniques.

</details>


### [86] [Hyperspectral Smoke Segmentation via Mixture of Prototypes](https://arxiv.org/abs/2602.10858)
*Lujian Yao,Haitao Zhao,Xianghai Kong,Yuhan Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于高光谱成像的烟雾分割方法，并构建了首个高光谱烟雾分割数据集（HSSDataset），解决了传统可见光方法在云层干扰和半透明烟雾区域的局限性。通过“混合原型”（MoP）网络，引入了带分割、原型化表示和双层路由策略，实现了自适应的空间感知带权重分配。


<details>
  <summary>Details</summary>
Motivation: 传统可见光烟雾分割方法在面对云层干扰和半透明烟雾时存在不足，需要更具辨别力的光谱信息。高光谱成像可以提供更丰富的光谱信息，但不同光谱带的辨别能力不均，需要有效的带权重分配策略。

Method: 1. 构建首个高光谱烟雾分割数据集（HSSDataset）和多光谱数据集（MSSDataset）。 2. 提出“混合原型”（MoP）网络，包括：带分割（Band split）用于光谱隔离；原型化光谱表示（Prototype-based spectral representation）用于建模多样化的光谱模式；双层路由（Dual-level router）用于自适应的空间感知带权重分配。

Result: 所提出的MoP网络在HSSDataset和MSSDataset上均取得了优于现有方法的性能，证明了其在高光谱和多光谱烟雾分割任务上的有效性。

Conclusion: 本文成功将高光谱成像应用于烟雾分割，构建了新的数据集，并提出了创新的MoP网络架构，为基于光谱的烟雾分割开辟了新途径，并验证了其在多光谱条件下的通用性。

Abstract: Smoke segmentation is critical for wildfire management and industrial safety applications. Traditional visible-light-based methods face limitations due to insufficient spectral information, particularly struggling with cloud interference and semi-transparent smoke regions. To address these challenges, we introduce hyperspectral imaging for smoke segmentation and present the first hyperspectral smoke segmentation dataset (HSSDataset) with carefully annotated samples collected from over 18,000 frames across 20 real-world scenarios using a Many-to-One annotations protocol. However, different spectral bands exhibit varying discriminative capabilities across spatial regions, necessitating adaptive band weighting strategies. We decompose this into three technical challenges: spectral interaction contamination, limited spectral pattern modeling, and complex weighting router problems. We propose a mixture of prototypes (MoP) network with: (1) Band split for spectral isolation, (2) Prototype-based spectral representation for diverse patterns, and (3) Dual-level router for adaptive spatial-aware band weighting. We further construct a multispectral dataset (MSSDataset) with RGB-infrared images. Extensive experiments validate superior performance across both hyperspectral and multispectral modalities, establishing a new paradigm for spectral-based smoke segmentation.

</details>


### [87] [Stride-Net: Fairness-Aware Disentangled Representation Learning for Chest X-Ray Diagnosis](https://arxiv.org/abs/2602.10875)
*Darakshan Rashid,Raza Imam,Dwarikanath Mahapatra,Brejesh Lall*

Main category: cs.CV

TL;DR: 提出了一种名为Stride-Net的公平性感知框架，通过基于步长（stride-based）的掩码和对抗性混淆损失，学习疾病判别但人口统计学上不变的胸部X光片表示，并使用BioBERT嵌入强制语义对齐，以改善公平性而不牺牲准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型在胸部X光片分类任务中，虽然平均表现良好，但在特定人口亚群上表现不佳，引发了临床安全和公平性的担忧。现有的去偏方法往往效果不稳定，或以牺牲整体诊断效用为代价，未能将公平性融入学习到的表示中。

Method: Stride-Net框架在图像块级别操作，使用可学习的步长掩码选择与标签对齐的图像区域，同时通过对抗性混淆损失抑制敏感属性信息。此外，通过Group Optimal Transport强制图像特征与BioBERT生成的疾病标签嵌入进行语义对齐，以引导模型学习临床相关的表示并防止捷径学习。

Result: 在MIMIC-CXR和CheXpert数据集上，针对种族和种族-性别交叉亚群进行了评估。Stride-Net在ResNet和Vision Transformers等不同架构下，一致性地提高了公平性指标，同时保持或超越了基线准确率，实现了比先前去偏方法更优的准确率-公平性权衡。

Conclusion: Stride-Net成功地学习到了在疾病判别能力和人口统计学不变性之间取得良好平衡的表示，为实现公平且准确的胸部X光片分析提供了一种有效的方法。

Abstract: Deep neural networks for chest X-ray classification achieve strong average performance, yet often underperform for specific demographic subgroups, raising critical concerns about clinical safety and equity. Existing debiasing methods frequently yield inconsistent improvements across datasets or attain fairness by degrading overall diagnostic utility, treating fairness as a post hoc constraint rather than a property of the learned representation. In this work, we propose Stride-Net (Sensitive Attribute Resilient Learning via Disentanglement and Learnable Masking with Embedding Alignment), a fairness-aware framework that learns disease-discriminative yet demographically invariant representations for chest X-ray analysis. Stride-Net operates at the patch level, using a learnable stride-based mask to select label-aligned image regions while suppressing sensitive attribute information through adversarial confusion loss. To anchor representations in clinical semantics and discourage shortcut learning, we further enforce semantic alignment between image features and BioBERT-based disease label embeddings via Group Optimal Transport. We evaluate Stride-Net on the MIMIC-CXR and CheXpert benchmarks across race and intersectional race-gender subgroups. Across architectures including ResNet and Vision Transformers, Stride-Net consistently improves fairness metrics while matching or exceeding baseline accuracy, achieving a more favorable accuracy-fairness trade-off than prior debiasing approaches. Our code is available at https://github.com/Daraksh/Fairness_StrideNet.

</details>


### [88] [ResWorld: Temporal Residual World Model for End-to-End Autonomous Driving](https://arxiv.org/abs/2602.10884)
*Jinqing Zhang,Zehua Fu,Zelin Xu,Wenying Dai,Qingjie Liu,Yunhong Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为TR-World（Temporal Residual World Model）的新型世界模型，它专注于动态目标建模，通过计算场景表示的时间残差来提取动态信息，避免了检测和跟踪的依赖，并预测未来动态目标的空间分布。结合静态目标信息，可以获得准确的未来BEV特征。此外，还提出了FGTR（Future-Guided Trajectory Refinement）模块，用于融合先验轨迹和未来BEV特征，以优化轨迹并为世界模型提供稀疏的监督，防止模型崩溃。实验结果表明，ResWorld在nuScenes和NAVSIM数据集上取得了最先进的规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型在处理静态区域时存在冗余建模，且缺乏与轨迹的深度交互，影响了其在自动驾驶场景中的规划精度。因此，需要一种更有效地建模动态目标并增强与轨迹交互的世界模型。

Method: 1. TR-World: 计算场景表示的时间残差，提取动态目标信息，预测未来动态目标的空间分布。 2. 结合TR-World预测的动态目标信息和当前BEV特征中的静态目标信息，生成准确的未来BEV特征。 3. FGTR模块: 通过先验轨迹和未来BEV特征之间的交互，优化轨迹并为未来BEV特征提供稀疏监督，防止世界模型崩溃。

Result: 所提出的ResWorld方法在nuScenes和NAVSIM数据集上取得了最先进的自动驾驶规划性能。

Conclusion: TR-World通过专注于动态目标建模和时间残差的利用，有效克服了现有世界模型的局限性。FGTR模块的引入进一步增强了轨迹与未来场景表示的交互，提高了规划的准确性并保证了模型的稳定性。ResWorld在基准数据集上的优异表现证明了该方法的有效性。

Abstract: The comprehensive understanding capabilities of world models for driving scenarios have significantly improved the planning accuracy of end-to-end autonomous driving frameworks. However, the redundant modeling of static regions and the lack of deep interaction with trajectories hinder world models from exerting their full effectiveness. In this paper, we propose Temporal Residual World Model (TR-World), which focuses on dynamic object modeling. By calculating the temporal residuals of scene representations, the information of dynamic objects can be extracted without relying on detection and tracking. TR-World takes only temporal residuals as input, thus predicting the future spatial distribution of dynamic objects more precisely. By combining the prediction with the static object information contained in the current BEV features, accurate future BEV features can be obtained. Furthermore, we propose Future-Guided Trajectory Refinement (FGTR) module, which conducts interaction between prior trajectories (predicted from the current scene representation) and the future BEV features. This module can not only utilize future road conditions to refine trajectories, but also provides sparse spatial-temporal supervision on future BEV features to prevent world model collapse. Comprehensive experiments conducted on the nuScenes and NAVSIM datasets demonstrate that our method, namely ResWorld, achieves state-of-the-art planning performance. The code is available at https://github.com/mengtan00/ResWorld.git.

</details>


### [89] [VFGS-Net: Frequency-Guided State-Space Learning for Topology-Preserving Retinal Vessel Segmentation](https://arxiv.org/abs/2602.10978)
*Ruiqi Song,Lei Liu,Ya-Nan Zhang,Chao Wang,Xiaoning Li,Nan Mu*

Main category: cs.CV

TL;DR: 提出了一种名为VFGS-Net的新型视网膜血管分割网络，通过结合频域特征增强、双路径卷积和长程空间建模，提高了对细小血管、复杂分支和低对比度区域的分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有视网膜血管分割方法难以同时处理血管的长形貌、尺度变化大、低对比度等挑战，导致难以保留细小毛细血管并维持全局拓扑连续性。

Method: 提出VFGS-Net，一个端到端的分割框架。该框架集成了频域特征增强（包括血管感知频率域通道注意力）、双路径卷积（用于局部纹理和多尺度上下文语义）以及双向非对称Mamba2空间状态空间建模（用于捕捉长程空间依赖和增强全局连续性）。

Result: 在四个公开的视网膜血管数据集上进行了实验，VFGS-Net在细小血管、复杂分支和低对比度区域的分割准确性上表现出一致的提升，并与其他最先进方法相比具有竞争力或更优的性能。

Conclusion: VFGS-Net能够有效应对视网膜血管分割的挑战，展现出强大的鲁棒性和临床应用潜力。

Abstract: Accurate retinal vessel segmentation is a critical prerequisite for quantitative analysis of retinal images and computer-aided diagnosis of vascular diseases such as diabetic retinopathy. However, the elongated morphology, wide scale variation, and low contrast of retinal vessels pose significant challenges for existing methods, making it difficult to simultaneously preserve fine capillaries and maintain global topological continuity. To address these challenges, we propose the Vessel-aware Frequency-domain and Global Spatial modeling Network (VFGS-Net), an end-to-end segmentation framework that seamlessly integrates frequency-aware feature enhancement, dual-path convolutional representation learning, and bidirectional asymmetric spatial state-space modeling within a unified architecture. Specifically, VFGS-Net employs a dual-path feature convolution module to jointly capture fine-grained local textures and multi-scale contextual semantics. A novel vessel-aware frequency-domain channel attention mechanism is introduced to adaptively reweight spectral components, thereby enhancing vessel-relevant responses in high-level features. Furthermore, at the network bottleneck, we propose a bidirectional asymmetric Mamba2-based spatial modeling block to efficiently capture long-range spatial dependencies and strengthen the global continuity of vascular structures. Extensive experiments on four publicly available retinal vessel datasets demonstrate that VFGS-Net achieves competitive or superior performance compared to state-of-the-art methods. Notably, our model consistently improves segmentation accuracy for fine vessels, complex branching patterns, and low-contrast regions, highlighting its robustness and clinical potential.

</details>


### [90] [Chart Specification: Structural Representations for Incentivizing VLM Reasoning in Chart-to-Code Generation](https://arxiv.org/abs/2602.10880)
*Minggui He,Mingchen Dai,Jian Zhang,Yilun Liu,Shimin Tao,Pufan Zeng,Osamu Yoshie,Yuya Ieiri*

Main category: cs.CV

TL;DR: 本文提出了一种名为Chart Specification的结构化中间表示方法，用于提高视觉语言模型（VLMs）从图表图像生成绘图代码的结构保真度。该方法通过结构化数据过滤和Spec-Align Reward机制，实现了更精确的结构监督，并在三个公共基准测试中取得了优于现有方法的性能，尤其是在数据效率方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有从图表图像生成绘图代码的方法在实现结构保真度方面存在挑战，通常依赖于监督微调，导致模型模仿表面文本而非忠实建模图表结构，从而产生不准确或语义不一致的输出。

Method: 提出Chart Specification，一种结构化中间表示，将训练从文本模仿转向基于语义的监督。该方法通过过滤句法噪声构建结构均衡的训练集，并支持Spec-Align Reward，提供细粒度、可验证的结构正确性反馈，从而支持强化学习以强制执行一致的绘图逻辑。

Result: 在三个公共基准测试中，所提出的方法一致优于现有方法。仅使用3K个训练样本，在复杂基准测试上的数据效率就提高了61.7%，超越了领先的基线。使用4K个样本即可达到新的最先进水平，在所有评估指标上均优于现有方法。

Conclusion: 精确的结构监督为实现高保真度的图表到代码生成提供了一条高效的途径。Chart Specification方法在提高生成代码的结构保真度方面取得了显著成效，并且具有很高的数据效率。

Abstract: Vision-Language Models (VLMs) have shown promise in generating plotting code from chart images, yet achieving structural fidelity remains challenging. Existing approaches largely rely on supervised fine-tuning, encouraging surface-level token imitation rather than faithful modeling of underlying chart structure, which often leads to hallucinated or semantically inconsistent outputs. We propose Chart Specification, a structured intermediate representation that shifts training from text imitation to semantically grounded supervision. Chart Specification filters syntactic noise to construct a structurally balanced training set and supports a Spec-Align Reward that provides fine-grained, verifiable feedback on structural correctness, enabling reinforcement learning to enforce consistent plotting logic. Experiments on three public benchmarks show that our method consistently outperforms prior approaches. With only 3K training samples, we achieve strong data efficiency, surpassing leading baselines by up to 61.7% on complex benchmarks, and scaling to 4K samples establishes new state-of-the-art results across all evaluated metrics. Overall, our results demonstrate that precise structural supervision offers an efficient pathway to high-fidelity chart-to-code generation. Code and dataset are available at: https://github.com/Mighten/chart-specification-paper

</details>


### [91] [FastUSP: A Multi-Level Collaborative Acceleration Framework for Distributed Diffusion Model Inference](https://arxiv.org/abs/2602.10940)
*Guandong Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为 FastUSP 的多层级优化框架，用于加速大规模扩散模型的分布式推理，特别是在注意力计算方面。FastUSP 通过结合编译级、通信级和算子级优化，在 FLUX 模型上实现了显著的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模扩散模型（如 FLUX、Stable Diffusion 3）需要多 GPU 并行才能高效推理。虽然 Unified Sequence Parallelism (USP) 是分布式注意力计算的先进方法，但其现有实现存在内核启动开销大和计算-通信调度不优的问题。

Method: FastUSP 框架集成了三种优化：1. 编译级优化：使用 CUDA Graphs 的图编译和计算-通信重排序。2. 通信级优化：使用 FP8 量化的集体通信。3. 算子级优化：使用带双缓冲的流水线式 Ring attention。

Result: 在 FLUX (12B) 模型上，FastUSP 相较于基线 USP 实现了 1.12-1.16 倍的端到端加速，其中编译级优化贡献了主要改进。在 Qwen-Image 模型上，2 GPUs 时 FastUSP 实现了 1.09 倍加速；4-8 GPUs 时，由于 PyTorch Inductor 与 Ring attention 的兼容性问题，编译优化失效，但基线 USP 仍能获得 1.30-1.46 倍的加速。研究还表明，在现代高带宽 GPU 互连上，内核启动开销是主要的性能瓶颈。

Conclusion: FastUSP 框架有效提升了大规模扩散模型分布式推理的效率，尤其是在注意力计算上。研究强调了多层级优化策略的重要性，并揭示了内核启动开销是现代分布式 GPU 推理的关键瓶颈。

Abstract: Large-scale diffusion models such as FLUX (12B parameters) and Stable Diffusion 3 (8B parameters) require multi-GPU parallelism for efficient inference. Unified Sequence Parallelism (USP), which combines Ulysses and Ring attention mechanisms, has emerged as the state-of-the-art approach for distributed attention computation. However, existing USP implementations suffer from significant inefficiencies including excessive kernel launch overhead and suboptimal computation-communication scheduling. In this paper, we propose \textbf{FastUSP}, a multi-level optimization framework that integrates compile-level optimization (graph compilation with CUDA Graphs and computation-communication reordering), communication-level optimization (FP8 quantized collective communication), and operator-level optimization (pipelined Ring attention with double buffering). We evaluate FastUSP on FLUX (12B) and Qwen-Image models across 2, 4, and 8 NVIDIA RTX 5090 GPUs. On FLUX, FastUSP achieves consistent \textbf{1.12$\times$--1.16$\times$} end-to-end speedup over baseline USP, with compile-level optimization contributing the dominant improvement. On Qwen-Image, FastUSP achieves \textbf{1.09$\times$} speedup on 2 GPUs; on 4--8 GPUs, we identify a PyTorch Inductor compatibility limitation with Ring attention that prevents compile optimization, while baseline USP scales to 1.30$\times$--1.46$\times$ of 2-GPU performance. We further provide a detailed analysis of the performance characteristics of distributed diffusion inference, revealing that kernel launch overhead -- rather than communication latency -- is the primary bottleneck on modern high-bandwidth GPU interconnects.

</details>


### [92] [DFIC: Towards a balanced facial image dataset for automatic ICAO compliance verification](https://arxiv.org/abs/2602.10985)
*Nuno Gonçalves,Diogo Nunes,Carla Guerra,João Marcos*

Main category: cs.CV

TL;DR: 本文介绍了DFIC数据集，一个包含约58,000张标注图像和2706个视频的、覆盖合规及多种不合规情况的人脸图像数据集，旨在推动自动化ICAO合规性验证方法的发展。研究还提出了一种基于空间注意力机制的新方法，并在DFIC数据集上进行了微调和评估，结果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前手动检查人脸图像以符合ISO/IEC和ICAO标准的方法效率低下，尤其在高需求环境下。需要更高效的自动化方法来验证机器可读旅行证件（MRTD）中的面部图像是否符合标准。

Method: 构建并发布了DFIC数据集，包含约58,000张标注图像和2706个视频，覆盖了多种不合规情况。基于DFIC数据集，开发并微调了一种依赖空间注意力机制的新型自动化ICAO合规性验证方法，并与现有技术进行了比较。

Result: DFIC数据集提供了比现有公共数据集更均衡的人口统计学分布，一个分区接近均匀分布。提出的基于空间注意力的新方法在DFIC数据集上进行了训练和验证，并取得了优于现有最先进方法的性能。

Conclusion: DFIC数据集的公开将促进自动化ICAO合规性验证方法的发展，提高其鲁棒性和适应性。该数据集及其相关方法也可能应用于其他旨在提高人脸识别系统安全性、隐私性和公平性的应用中。

Abstract: Ensuring compliance with ISO/IEC and ICAO standards for facial images in machine-readable travel documents (MRTDs) is essential for reliable identity verification, but current manual inspection methods are inefficient in high-demand environments. This paper introduces the DFIC dataset, a novel comprehensive facial image dataset comprising around 58,000 annotated images and 2706 videos of more than 1000 subjects, that cover a broad range of non-compliant conditions, in addition to compliant portraits. Our dataset provides a more balanced demographic distribution than the existing public datasets, with one partition that is nearly uniformly distributed, facilitating the development of automated ICAO compliance verification methods.
  Using DFIC, we fine-tuned a novel method that heavily relies on spatial attention mechanisms for the automatic validation of ICAO compliance requirements, and we have compared it with the state-of-the-art aimed at ICAO compliance verification, demonstrating improved results. DFIC dataset is now made public (https://github.com/visteam-isr-uc/DFIC) for the training and validation of new models, offering an unprecedented diversity of faces, that will improve both robustness and adaptability to the intrinsically diverse combinations of faces and props that can be presented to the validation system. These results emphasize the potential of DFIC to enhance automated ICAO compliance methods but it can also be used in many other applications that aim to improve the security, privacy, and fairness of facial recognition systems.

</details>


### [93] [Interpretable Vision Transformers in Monocular Depth Estimation via SVDA](https://arxiv.org/abs/2602.11005)
*Vasileios Arampatzakis,George Pavlidis,Nikolaos Mitianoudis,Nikos Papamarkos*

Main category: cs.CV

TL;DR: 本文提出了一种名为SVDA（SVD-Inspired Attention）的新型注意力机制，并将其应用于Dense Prediction Transformer（DPT）中，用于单目深度估计。SVDA通过解耦方向对齐和频谱调制，使得注意力图具有内在的可解释性，并能量化六种频谱指标，揭示了训练过程中注意力组织的一致模式，为透明的密集预测模型提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer架构在单目深度估计等密集预测任务中表现出色，但其自注意力机制缺乏可解释性。研究动机是为Transformer中的自注意力机制提供一种结构化、可解释的表示，以便更好地理解其工作原理并发现训练过程中的模式。

Method: 本文将一种受SVD启发的注意力机制（SVDA）引入到Dense Prediction Transformer（DPT）中。SVDA通过在归一化的查询-键交互中嵌入可学习的对角矩阵，将方向对齐与频谱调制分离开。这使得注意力图具有内在的可解释性，而非事后近似。SVDA还引入了六个频谱指标来量化注意力的熵、秩、稀疏度、对齐度、选择性和鲁棒性。

Result: 在KITTI和NYU-v2数据集上的实验表明，SVDA在保持或略微提高预测精度的同时，计算开销仅略微增加。更重要的是，SVDA能够量化六种频谱指标，揭示了在训练过程中注意力组织的一致的跨数据集和跨深度模式，这些模式在标准Transformer中是无法获得的。

Conclusion: SVDA提供了一种新颖的、基于频谱结构的可解释的注意力机制，用于单目深度估计。它将注意力从一个不透明的机制转变为一个可量化的描述符，为开发透明的密集预测模型开辟了一条原则性的途径，并提供了深入理解模型训练过程的新见解。

Abstract: Monocular depth estimation is a central problem in computer vision with applications in robotics, AR, and autonomous driving, yet the self-attention mechanisms that drive modern Transformer architectures remain opaque. We introduce SVD-Inspired Attention (SVDA) into the Dense Prediction Transformer (DPT), providing the first spectrally structured formulation of attention for dense prediction tasks. SVDA decouples directional alignment from spectral modulation by embedding a learnable diagonal matrix into normalized query-key interactions, enabling attention maps that are intrinsically interpretable rather than post-hoc approximations. Experiments on KITTI and NYU-v2 show that SVDA preserves or slightly improves predictive accuracy while adding only minor computational overhead. More importantly, SVDA unlocks six spectral indicators that quantify entropy, rank, sparsity, alignment, selectivity, and robustness. These reveal consistent cross-dataset and depth-wise patterns in how attention organizes during training, insights that remain inaccessible in standard Transformers. By shifting the role of attention from opaque mechanism to quantifiable descriptor, SVDA redefines interpretability in monocular depth estimation and opens a principled avenue toward transparent dense prediction models.

</details>


### [94] [Interpretable Vision Transformers in Image Classification via SVDA](https://arxiv.org/abs/2602.10994)
*Vasileios Arampatzakis,George Pavlidis,Nikolaos Mitianoudis,Nikos Papamarkos*

Main category: cs.CV

TL;DR: 该研究将SVD启发式注意力（SVDA）机制引入Vision Transformers（ViT），以提高ViT的可解释性、稀疏性和谱结构，并在多个基准数据集上验证了其在不牺牲准确性的前提下生成更具解释性的注意力模式。


<details>
  <summary>Details</summary>
Motivation: 现有Vision Transformers（ViT）的注意力机制通常不透明且行为密集非结构化，缺乏可解释性。作者希望通过引入一种几何学上可解释的SVDA机制来解决这个问题。

Method: 将先前提出的SVD-Inspired Attention（SVDA）机制适配到ViT架构中，利用几何学原理增强其可解释性、稀疏性和谱结构。使用原文提出的可解释性指标来监控训练过程中的注意力动态，并评估学习到的表示的结构属性。

Result: 在CIFAR-10、FashionMNIST、CIFAR-100和ImageNet-100四个基准数据集上的实验表明，SVDA能够生成更具可解释性的注意力模式，同时保持与标准ViT相当的分类准确率。

Conclusion: SVDA为分析和开发具有结构化注意力的计算机视觉模型提供了一个全面且信息丰富的工具，它能够提高ViT的可解释性，并且为未来在可解释AI、谱诊断和基于注意力的模型压缩方面的研究奠定了基础。

Abstract: Vision Transformers (ViTs) have achieved state-of-the-art performance in image classification, yet their attention mechanisms often remain opaque and exhibit dense, non-structured behaviors. In this work, we adapt our previously proposed SVD-Inspired Attention (SVDA) mechanism to the ViT architecture, introducing a geometrically grounded formulation that enhances interpretability, sparsity, and spectral structure. We apply the use of interpretability indicators -- originally proposed with SVDA -- to monitor attention dynamics during training and assess structural properties of the learned representations. Experimental evaluations on four widely used benchmarks -- CIFAR-10, FashionMNIST, CIFAR-100, and ImageNet-100 -- demonstrate that SVDA consistently yields more interpretable attention patterns without sacrificing classification accuracy. While the current framework offers descriptive insights rather than prescriptive guidance, our results establish SVDA as a comprehensive and informative tool for analyzing and developing structured attention models in computer vision. This work lays the foundation for future advances in explainable AI, spectral diagnostics, and attention-based model compression.

</details>


### [95] [PuriLight: A Lightweight Shuffle and Purification Framework for Monocular Depth Estimation](https://arxiv.org/abs/2602.11066)
*Yujie Chen,Li Zhang,Xiaomeng Chu,Tian Zhang*

Main category: cs.CV

TL;DR: 本文提出了PuriLight，一个轻量级且高效的自监督单目深度估计框架，通过Shuffle-Dilation Convolution (SDC)、Rotation-Adaptive Kernel Attention (RAKA)和Deep Frequency Signal Purification (DFSP)三个新模块，实现了计算效率和细节保留的平衡，并在参数量和效率上达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有自监督单目深度估计方法要么模型庞大影响实用性，要么模型轻量但牺牲结构精度，因此需要开发兼具轻量和结构精度的模型。

Method: 提出一个三阶段架构，包含三个新模块：SDC模块用于局部特征提取，RAKA模块用于分层特征增强，DFSP模块用于全局特征净化，并通过这些模块协同工作实现轻量且准确的特征提取和处理。

Result: PuriLight在最少训练参数的情况下实现了最先进的性能，同时保持了出色的计算效率。

Conclusion: PuriLight成功解决了计算效率和细节保留的双重挑战，是轻量级且结构精确的自监督单目深度估计的有效框架。

Abstract: We propose PuriLight, a lightweight and efficient framework for self-supervised monocular depth estimation, to address the dual challenges of computational efficiency and detail preservation. While recent advances in self-supervised depth estimation have reduced reliance on ground truth supervision, existing approaches remain constrained by either bulky architectures compromising practicality or lightweight models sacrificing structural precision. These dual limitations underscore the critical need to develop lightweight yet structurally precise architectures. Our framework addresses these limitations through a three-stage architecture incorporating three novel modules: the Shuffle-Dilation Convolution (SDC) module for local feature extraction, the Rotation-Adaptive Kernel Attention (RAKA) module for hierarchical feature enhancement, and the Deep Frequency Signal Purification (DFSP) module for global feature purification. Through effective collaboration, these modules enable PuriLight to achieve both lightweight and accurate feature extraction and processing. Extensive experiments demonstrate that PuriLight achieves state-of-the-art performance with minimal training parameters while maintaining exceptional computational efficiency. Codes will be available at https://github.com/ishrouder/PuriLight.

</details>


### [96] [LaSSM: Efficient Semantic-Spatial Query Decoding via Local Aggregation and State Space Models for 3D Instance Segmentation](https://arxiv.org/abs/2602.11007)
*Lei Yao,Yi Wang,Yawen Cui,Moyun Liu,Lap-Pui Chau*

Main category: cs.CV

TL;DR: LaSSM 提出了一种高效的基于查询的3D场景实例分割方法，通过层次化语义-空间查询初始化器和坐标引导的状态空间模型解码器，在 ScanNet++ V2 排行榜上取得最佳性能，同时计算量仅为原有方法的1/3。


<details>
  <summary>Details</summary>
Motivation: 现有查询式3D场景实例分割方法在查询初始化时存在稀疏性问题，并且解码器中的注意力机制计算量大。研究旨在提出一种更简单、更高效的方法，同时保持竞争力。

Method: 该方法提出了一个层次化语义-空间查询初始化器，利用超点（superpoints）并结合语义和空间信息来生成查询集。此外，还引入了一个坐标引导的状态空间模型（SSM）解码器，该解码器包含一个局部聚合方案和一个空间双路径SSM块，以逐步优化查询并捕捉坐标信息内的依赖关系。

Result: LaSSM 在 ScanNet++ V2 排行榜上名列第一，mAP 提高了 2.5%，计算量仅为原有方法的1/3。同时，在 ScanNet、ScanNet200、S3DIS 和 ScanNet++ V1 基准测试中也取得了具有竞争力的性能。

Conclusion: LaSSM 通过其创新的查询初始化和SSM解码器设计，有效地解决了现有方法的局限性，实现了高效且性能卓越的3D场景实例分割，并且在计算效率上表现突出。

Abstract: Query-based 3D scene instance segmentation from point clouds has attained notable performance. However, existing methods suffer from the query initialization dilemma due to the sparse nature of point clouds and rely on computationally intensive attention mechanisms in query decoders. We accordingly introduce LaSSM, prioritizing simplicity and efficiency while maintaining competitive performance. Specifically, we propose a hierarchical semantic-spatial query initializer to derive the query set from superpoints by considering both semantic cues and spatial distribution, achieving comprehensive scene coverage and accelerated convergence. We further present a coordinate-guided state space model (SSM) decoder that progressively refines queries. The novel decoder features a local aggregation scheme that restricts the model to focus on geometrically coherent regions and a spatial dual-path SSM block to capture underlying dependencies within the query set by integrating associated coordinates information. Our design enables efficient instance prediction, avoiding the incorporation of noisy information and reducing redundant computation. LaSSM ranks first place on the latest ScanNet++ V2 leaderboard, outperforming the previous best method by 2.5% mAP with only 1/3 FLOPs, demonstrating its superiority in challenging large-scale scene instance segmentation. LaSSM also achieves competitive performance on ScanNet, ScanNet200, S3DIS and ScanNet++ V1 benchmarks with less computational cost. Extensive ablation studies and qualitative results validate the effectiveness of our design. The code and weights are available at https://github.com/RayYoh/LaSSM.

</details>


### [97] [First International StepUP Competition for Biometric Footstep Recognition: Methods, Results and Remaining Challenges](https://arxiv.org/abs/2602.11086)
*Robyn Larracy,Eve MacDonald,Angkoon Phinyomark,Saeid Rezaei,Mahdi Laghaei,Ali Hajighasem,Aaron Tabor,Erik Scheme*

Main category: cs.CV

TL;DR: 一项关于脚印生物识别的竞赛，旨在利用大型数据集开发深度学习模型，但仍面临鞋子多样性带来的泛化挑战。


<details>
  <summary>Details</summary>
Motivation: 生物识别脚印识别领域缺乏大型、多样化的数据集，阻碍了模型在用户泛化和对抗变化（如鞋子、速度）方面的能力。UNB StepUP-P150 数据集的发布为此类挑战提供了新的研究机会。

Method: 举办了第一届国际StepUP竞赛，要求参赛者利用StepUP-P150数据集开发鲁棒的识别模型，并在专门设计的测试集上评估其验证性能，该测试集考虑了有限且同质的参考数据下的挑战性变化。

Result: 23个团队参赛，Saeid_UCC团队以10.77%的等错误率（EER）获胜，其方法使用了生成奖励机器（GRM）优化策略。竞赛展示了强大的解决方案，但对不熟悉鞋子的泛化能力仍是主要挑战。

Conclusion: StepUP竞赛成功推动了脚印生物识别领域的研究，展示了深度学习方法的潜力。然而，未来研究的重点应放在提高模型在面对不同鞋子时的泛化能力。

Abstract: Biometric footstep recognition, based on a person's unique pressure patterns under their feet during walking, is an emerging field with growing applications in security and safety. However, progress in this area has been limited by the lack of large, diverse datasets necessary to address critical challenges such as generalization to new users and robustness to shifts in factors like footwear or walking speed. The recent release of the UNB StepUP-P150 dataset, the largest and most comprehensive collection of high-resolution footstep pressure recordings to date, opens new opportunities for addressing these challenges through deep learning. To mark this milestone, the First International StepUP Competition for Biometric Footstep Recognition was launched. Competitors were tasked with developing robust recognition models using the StepUP-P150 dataset that were then evaluated on a separate, dedicated test set designed to assess verification performance under challenging variations, given limited and relatively homogeneous reference data. The competition attracted global participation, with 23 registered teams from academia and industry. The top-performing team, Saeid_UCC, achieved the best equal error rate (EER) of 10.77% using a generative reward machine (GRM) optimization strategy. Overall, the competition showcased strong solutions, but persistent challenges in generalizing to unfamiliar footwear highlight a critical area for future work.

</details>


### [98] [HairWeaver: Few-Shot Photorealistic Hair Motion Synthesis with Sim-to-Real Guided Video Diffusion](https://arxiv.org/abs/2602.11117)
*Di Chang,Ji Hou,Aljaz Bozic,Assaf Neuberger,Felix Juefei-Xu,Olivier Maury,Gene Wei-Chin Lin,Tuur Stuyck,Doug Roble,Mohammad Soleymani,Stephane Grabli*

Main category: cs.CV

TL;DR: HairWeaver是一个基于扩散模型的管线，能够为单个人类图像生成逼真且富有表现力的头发动态动画，解决了现有方法在头发控制上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态控制方法在头发动态方面存在不足，无法捕捉精细的头发运动，导致动画僵硬不真实。

Method: HairWeaver使用两个LoRA模块：Motion-Context-LoRA整合运动条件，Sim2Real-Domain-LoRA保持主体在不同数据域下的照片真实感。这些模块引导视频扩散骨干模型，并利用CG模拟器生成的动态人体运动数据集进行训练。

Result: HairWeaver能够对头发运动进行精细控制，生成对运动响应自然的逼真头发动画，在全面评估中达到新的技术水平。

Conclusion: HairWeaver通过引入专门的LoRA模块和Sim2Real训练策略，显著提升了单图像头发动画的真实感和表现力，克服了现有方法的局限性。

Abstract: We present HairWeaver, a diffusion-based pipeline that animates a single human image with realistic and expressive hair dynamics. While existing methods successfully control body pose, they lack specific control over hair, and as a result, fail to capture the intricate hair motions, resulting in stiff and unrealistic animations. HairWeaver overcomes this limitation using two specialized modules: a Motion-Context-LoRA to integrate motion conditions and a Sim2Real-Domain-LoRA to preserve the subject's photoreal appearance across different data domains. These lightweight components are designed to guide a video diffusion backbone while maintaining its core generative capabilities. By training on a specialized dataset of dynamic human motion generated from a CG simulator, HairWeaver affords fine control over hair motion and ultimately learns to produce highly realistic hair that responds naturally to movement. Comprehensive evaluations demonstrate that our approach sets a new state of the art, producing lifelike human hair animations with dynamic details.

</details>


### [99] [FastFlow: Accelerating The Generative Flow Matching Models with Bandit Inference](https://arxiv.org/abs/2602.11105)
*Divya Jyoti Bajpai,Dhruv Bhardwaj,Soumya Roy,Tejas Duseja,Harsh Agarwal,Aashay Sandansing,Manjesh Kumar Hanawal*

Main category: cs.CV

TL;DR: 提出了一种名为 FastFlow 的即插即用自适应推理框架，用于加速流匹配模型（如图像和视频生成模型）的生成过程，通过智能跳过计算量小的去噪步骤，并在不影响生成质量的情况下实现了超过 2.6 倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有的流匹配模型生成质量高但速度慢，而现有的加速方法（如蒸馏、轨迹截断、一致性方法）是静态的、需要重新训练且泛化性差。因此，需要一种能够自适应、无需重新训练且能够泛化到不同任务的加速方法。

Method: FastFlow 提出了一种即插即用框架，通过识别对去噪路径调整很小的去噪步骤，并使用有限差分法从先前的预测中估计速度，从而高效地推断未来的状态，以零计算成本跳过这些步骤。将决定跳过多少步骤的问题建模为一个多臂老虎机问题，该老虎机学习最优的跳步策略以平衡速度和性能。

Result: FastFlow 在图像生成、视频生成和编辑任务上均表现出良好的泛化能力，并实现了超过 2.6 倍的速度提升，同时保持了高质量的输出。

Conclusion: FastFlow 是一种有效的、无需重新训练的、即插即用的自适应推理框架，可以显著加速流匹配模型的生成速度，同时保持生成质量，并且能够泛化到多种生成任务。

Abstract: Flow-matching models deliver state-of-the-art fidelity in image and video generation, but the inherent sequential denoising process renders them slower. Existing acceleration methods like distillation, trajectory truncation, and consistency approaches are static, require retraining, and often fail to generalize across tasks. We propose FastFlow, a plug-and-play adaptive inference framework that accelerates generation in flow matching models. FastFlow identifies denoising steps that produce only minor adjustments to the denoising path and approximates them without using the full neural network models used for velocity predictions. The approximation utilizes finite-difference velocity estimates from prior predictions to efficiently extrapolate future states, enabling faster advancements along the denoising path at zero compute cost. This enables skipping computation at intermediary steps. We model the decision of how many steps to safely skip before requiring a full model computation as a multi-armed bandit problem. The bandit learns the optimal skips to balance speed with performance. FastFlow integrates seamlessly with existing pipelines and generalizes across image generation, video generation, and editing tasks. Experiments demonstrate a speedup of over 2.6x while maintaining high-quality outputs. The source code for this work can be found at https://github.com/Div290/FastFlow.

</details>


### [100] [SurfPhase: 3D Interfacial Dynamics in Two-Phase Flows from Sparse Videos](https://arxiv.org/abs/2602.11154)
*Yue Gao,Hong-Xing Yu,Sanghyeon Chang,Qianxi Fu,Bo Zhu,Yoonjin Won,Juan Carlos Niebles,Jiajun Wu*

Main category: cs.CV

TL;DR: 提出了一种名为SurfPhase的新模型，可以从稀疏的相机视图中重建三维两相流的界面动态，解决了现有方法在处理清晰、可变形液-汽界面上的局限性。


<details>
  <summary>Details</summary>
Motivation: 实验上测量两相流中的界面动态（动量、热量和质量传递）具有挑战性，经典方法和现有神经渲染方法在处理移动的、清晰的液-汽界面时存在固有局限性。

Method: SurfPhase模型结合了动态高斯曲面元（Gaussian surfels）和符号距离函数（signed distance function）来保证几何一致性，并利用视频扩散模型（video diffusion model）合成新视角视频，以从稀疏观测中优化重建。

Result: 在新的高速池沸腾视频数据集上进行了评估，结果表明仅用两个相机视图就能实现高质量的新视角视频合成和速度估计。

Conclusion: SurfPhase模型能够有效地从稀疏的相机视图中重建和合成三维两相流的界面动态，为相关领域的研究提供了新的解决方案。

Abstract: Interfacial dynamics in two-phase flows govern momentum, heat, and mass transfer, yet remain difficult to measure experimentally. Classical techniques face intrinsic limitations near moving interfaces, while existing neural rendering methods target single-phase flows with diffuse boundaries and cannot handle sharp, deformable liquid-vapor interfaces. We propose SurfPhase, a novel model for reconstructing 3D interfacial dynamics from sparse camera views. Our approach integrates dynamic Gaussian surfels with a signed distance function formulation for geometric consistency, and leverages a video diffusion model to synthesize novel-view videos to refine reconstruction from sparse observations. We evaluate on a new dataset of high-speed pool boiling videos, demonstrating high-quality view synthesis and velocity estimation from only two camera views. Project website: https://yuegao.me/SurfPhase.

</details>


### [101] [PhyCritic: Multimodal Critic Models for Physical AI](https://arxiv.org/abs/2602.11124)
*Tianyi Xiong,Shihao Wang,Guilin Liu,Yi Dong,Ming Li,Heng Huang,Jan Kautz,Zhiding Yu*

Main category: cs.CV

TL;DR: 本文提出了一种名为PhyCritic的多模态评论模型，专门用于物理AI任务的评估。该模型通过两阶段强化学习（RLVR）进行训练，包括物理技能预热和自我参考评论微调，以提高其在感知、因果推理和规划方面的判断稳定性和物理正确性。实验证明PhyCritic在物理和通用多模态评判基准上均表现优于现有模型，并能提升物理接地任务中的感知和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型裁判和评论模型主要集中在通用视觉领域（如图像字幕、视觉问答），而忽视了涉及感知、因果推理和规划的物理AI任务。因此，需要一个专门针对物理AI任务进行优化的评论模型。

Method: PhyCritic采用两阶段强化学习从视觉-语言（RLVR）的训练流程：1. 物理技能预热阶段，旨在增强模型在物理任务中的感知和推理能力。2. 自我参考评论微调阶段，评论模型会生成自己的预测作为内部参考，然后再对候选响应进行判断，从而提高判断稳定性和物理正确性。

Result: PhyCritic在物理AI和通用多模态裁判基准上均取得了显著的性能提升，优于开源基线模型。当PhyCritic作为策略模型应用时，能够进一步提升物理接地任务中的感知和推理能力。

Conclusion: PhyCritic是一个专门为物理AI任务设计的多模态评论模型，通过创新的两阶段RLVR训练方法，有效地提升了模型在物理感知、因果推理和规划方面的评估能力。该模型不仅能提供更准确的评估，还能在作为策略模型时增强物理AI的能力。

Abstract: With the rapid development of large multimodal models, reliable judge and critic models have become essential for open-ended evaluation and preference alignment, providing pairwise preferences, numerical scores, and explanatory justifications for assessing model-generated responses. However, existing critics are primarily trained in general visual domains such as captioning or image question answering, leaving physical AI tasks involving perception, causal reasoning, and planning largely underexplored. We introduce PhyCritic, a multimodal critic model optimized for physical AI through a two-stage RLVR pipeline: a physical skill warmup stage that enhances physically oriented perception and reasoning, followed by self-referential critic finetuning, where the critic generates its own prediction as an internal reference before judging candidate responses, improving judgment stability and physical correctness. Across both physical and general-purpose multimodal judge benchmarks, PhyCritic achieves strong performance gains over open-source baselines and, when applied as a policy model, further improves perception and reasoning in physically grounded tasks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [102] [Reviewing the Reviewer: Elevating Peer Review Quality through LLM-Guided Feedback](https://arxiv.org/abs/2602.10118)
*Sukannya Purkayastha,Qile Wan,Anne Lauscher,Lizhen Qu,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本研究提出了一种基于 LLM 的框架，用于识别科学同行评审中的“懒惰思维”和特定性问题，并生成有针对性的改进建议，实验结果显示该方法优于现有基线，并显著提高了评审质量。


<details>
  <summary>Details</summary>
Motivation: 现有同行评审方法过度依赖简单的启发式方法（懒惰思维），导致科学质量下降。以往的研究将懒惰思维检测视为单标签任务，而忽略了评审中可能存在的多种问题（如模糊性、特定性）。为了实现可操作的改进，需要提供符合指南的反馈，而现有方法缺乏这一点。

Method: 该研究提出了一种 LLM 驱动的框架，该框架包含三个主要步骤：1. 将同行评审分解为论证性片段；2. 通过结合 LLM 特征和传统分类器的神经符号模块来识别问题；3. 使用由遗传算法优化的、针对具体问题的模板生成定向反馈。

Result: 实验表明，该方法在识别同行评审问题方面优于零样本 LLM 基线。此外，该方法可将评审质量提高高达 92.4%。研究还发布了一个名为 LazyReviewPlus 的新数据集，包含 1,309 个已标注懒惰思维和特定性问题的句子。

Conclusion: 该研究成功开发了一个先进的 LLM 驱动框架，能够有效识别同行评审中的多种问题，并提供精确的改进建议，从而显著提升了同行评审的质量和可操作性。新数据集 LazyReviewPlus 的发布也有助于未来相关研究的发展。

Abstract: Peer review is central to scientific quality, yet reliance on simple heuristics -- lazy thinking -- has lowered standards. Prior work treats lazy thinking detection as a single-label task, but review segments may exhibit multiple issues, including broader clarity problems, or specificity issues. Turning detection into actionable improvements requires guideline-aware feedback, which is currently missing. We introduce an LLM-driven framework that decomposes reviews into argumentative segments, identifies issues via a neurosymbolic module combining LLM features with traditional classifiers, and generates targeted feedback using issue-specific templates refined by a genetic algorithm. Experiments show our method outperforms zero-shot LLM baselines and improves review quality by up to 92.4\%. We also release LazyReviewPlus, a dataset of 1,309 sentences labeled for lazy thinking and specificity.

</details>


### [103] [Latent Thoughts Tuning: Bridging Context and Reasoning with Fused Information in Latent Tokens](https://arxiv.org/abs/2602.10229)
*Weihao Liu,Dehai Min,Lu Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Latent Thoughts Tuning (LT-Tuning) 的新框架，用于改进大型语言模型 (LLMs) 的潜在空间推理能力。该框架通过结合上下文隐藏状态和词汇嵌入空间的语义指导，并采用分阶段的课程学习策略，解决了现有潜在推理方法的特征塌陷和不稳定性问题，并实现了更强的推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的显式思维链 (CoT) 方法受限于离散的词汇空间，而现有的潜在空间推理方法则存在特征塌陷和不稳定性问题。研究者希望探索一种能够克服这些局限性，并在连续潜在空间中实现更强大、更灵活推理的方法。

Method: LT-Tuning 框架引入了上下文-预测-融合 (Context-Prediction-Fusion) 机制，该机制同时利用上下文隐藏状态和来自词汇嵌入空间的预测性语义指导来构建潜在思维。此外，该框架还采用了包含三个阶段的渐进式课程学习管线，允许在潜在思维和显式思维模式之间动态切换。

Result: 实验结果表明，LT-Tuning 在潜在推理方面优于现有的基线方法，有效地缓解了特征塌陷问题，并实现了鲁棒的推理准确性。

Conclusion: LT-Tuning 是一个能够改进 LLMs 潜在空间推理的新框架，通过其创新的机制和课程学习策略，克服了现有方法的不足，实现了更有效和更鲁棒的推理。

Abstract: While explicit Chain-of-Thought (CoT) equips Large Language Models (LLMs) with strong reasoning capabilities, it requires models to verbalize every intermediate step in text tokens, constraining the model thoughts to the discrete vocabulary space. Recently, reasoning in continuous latent space has emerged as a promising alternative, enabling more robust inference and flexible computation beyond discrete token constraints. However, current latent paradigms often suffer from feature collapse and instability, stemming from distribution mismatches when recurrently using hidden states as the input embeddings, or alignment issues when relying on assistant models. To address this, we propose Latent Thoughts Tuning (LT-Tuning), a framework that redefines how latent thoughts are constructed and deployed. Instead of relying solely on raw hidden states, our method introduces a Context-Prediction-Fusion mechanism that jointly leveraging contextual hidden states and predictive semantic guidance from the vocabulary embedding space. Combined with a progressive three-stage curriculum learning pipeline, LT-Tuning also enables dynamically switching between latent and explicit thinking modes. Experiments demonstrate that our method outperforms existing latent reasoning baselines, effectively mitigating feature collapse and achieving robust reasoning accuracy.

</details>


### [104] [Learning to Evict from Key-Value Cache](https://arxiv.org/abs/2602.10238)
*Luca Moschella,Laura Manduchi,Ozan Sener*

Main category: cs.CL

TL;DR: 提出了一种名为KV Policy (KVP) 的强化学习框架，用于管理大型语言模型（LLM）的KV缓存，通过预测代币的未来效用来优化缓存策略，显著提高了效率并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理面临内存效率挑战，主要是由于KV缓存。现有的缓存淘汰或压缩方法依赖启发式，如近期性或历史注意力分数，这些仅是未来效用的间接代理，并引入计算开销。

Method: 将KV缓存淘汰重构为一个强化学习问题。引入KVP框架，包含轻量级的每头RL代理，在预计算的生成轨迹上进行训练，仅使用键和值向量。每个代理学习一个由未来效用指导的专用淘汰策略，评估所有缓存预算的排序质量，无需修改底层LLM或增加额外推理。

Result: 在RULER和OASST2-4k基准上，KVP显著优于现有基线。此外，在标准下游任务（如LongBench、BOOLQ、ARC）上的零样本测试表明，KVP能很好地泛化到训练分布之外的任务和更长的上下文长度。

Conclusion: 学习预测未来代币效用是适应性KV缓存管理的一种强大且可扩展的范式。KVP框架证明了这种方法的可行性和有效性。

Abstract: The growing size of Large Language Models (LLMs) makes efficient inference challenging, primarily due to the memory demands of the autoregressive Key-Value (KV) cache. Existing eviction or compression methods reduce cost but rely on heuristics, such as recency or past attention scores, which serve only as indirect proxies for a token's future utility and introduce computational overhead. We reframe KV cache eviction as a reinforcement learning (RL) problem: learning to rank tokens by their predicted usefulness for future decoding. To this end, we introduce KV Policy (KVP), a framework of lightweight per-head RL agents trained on pre-computed generation traces using only key and value vectors. Each agent learns a specialized eviction policy guided by future utility, which evaluates the quality of the ranking across all cache budgets, requiring no modifications to the underlying LLM or additional inference. Evaluated across two different model families on the long-context benchmark RULER and the multi-turn dialogue benchmark OASST2-4k, KVP significantly outperforms baselines. Furthermore, zero-shot tests on standard downstream tasks (e.g., LongBench, BOOLQ, ARC) indicate that KVP generalizes well beyond its training distribution and to longer context lengths. These results demonstrate that learning to predict future token utility is a powerful and scalable paradigm for adaptive KV cache management.

</details>


### [105] [On Emergent Social World Models -- Evidence for Functional Integration of Theory of Mind and Pragmatic Reasoning in Language Models](https://arxiv.org/abs/2602.10298)
*Polina Tsvilodub,Jan-Felix Klumpp,Amir Mohammadpour,Jennifer Hu,Michael Franke*

Main category: cs.CL

TL;DR: 本研究通过行为评估和功能定位实验，探究大型语言模型（LMs）在执行通用心智理论（ToM）和特定语言语用推理时是否会调用共享的计算机制，以验证LMs是否拥有跨任务重用的“社会世界模型”（功能整合假说）。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探究大型语言模型（LMs）是否具备整合的“社会世界模型”，即其是否能跨任务重用对心理状态的表征，以此来理解LMs中“社会认知”的涌现机制。

Method: 研究采用了行为评估和功能定位（灵感来自认知神经科学）的方法，对LMs在七个ToM子能力类别上的表现进行了分析，并使用了一个比以往研究更大的本地化数据集。

Result: 研究结果通过严格的假设驱动统计检验，提供了支持功能整合假说的初步证据，表明LMs可能发展出相互关联的“社会世界模型”，而非孤立的能力。

Conclusion: 本研究为ToM本地化提供了新的数据集，改进了功能定位的技术方法，并对人工智能系统中社会认知涌现的机制提出了实证性见解，提示LMs可能拥有整合的“社会世界模型”。

Abstract: This paper investigates whether LMs recruit shared computational mechanisms for general Theory of Mind (ToM) and language-specific pragmatic reasoning in order to contribute to the general question of whether LMs may be said to have emergent "social world models", i.e., representations of mental states that are repurposed across tasks (the functional integration hypothesis). Using behavioral evaluations and causal-mechanistic experiments via functional localization methods inspired by cognitive neuroscience, we analyze LMs' performance across seven subcategories of ToM abilities (Beaudoin et al., 2020) on a substantially larger localizer dataset than used in prior like-minded work. Results from stringent hypothesis-driven statistical testing offer suggestive evidence for the functional integration hypothesis, indicating that LMs may develop interconnected "social world models" rather than isolated competencies. This work contributes novel ToM localizer data, methodological refinements to functional localization techniques, and empirical insights into the emergence of social cognition in artificial systems.

</details>


### [106] [Are More Tokens Rational? Inference-Time Scaling in Language Models as Adaptive Resource Rationality](https://arxiv.org/abs/2602.10329)
*Zhimin Hu,Riya Roshan,Sashank Varma*

Main category: cs.CL

TL;DR: 本文研究了在大语言模型（LLM）的推理时间扩展（inference-time scaling）过程中，资源理性（resource rationality）是否能够自发涌现。通过设计一个变量归因任务，并系统地调整任务复杂度，作者发现无论是指令微调模型（IT models）还是大型推理模型（LRMs），都会在复杂度增加时从蛮力策略转向分析策略，证明了资源理性是一种推理时间扩展的涌现属性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探究在大语言模型推理时扩展计算量（inference-time scaling）能否在没有明确计算成本奖励的情况下，催生出资源理性（resource rationality），即在资源约束下优化推理性能。

Method: 研究者设计了一个变量归因任务（Variable Attribution Task），模型需要根据候选变量、输入-输出试例和逻辑函数来推断决定结果的变量。通过改变候选变量数量和试例数量来系统地操控任务复杂度。作者对比了指令微调模型（IT models）和通过强化学习训练的大型推理模型（LRMs）在该任务上的表现。

Result: 实验结果显示，随着任务复杂度的增加，IT模型和LRMs都会从蛮力（brute-force）策略转向分析（analytic）策略。然而，IT模型在处理XOR和XNOR逻辑函数时性能下降，而LRMs则保持了鲁棒性。

Conclusion: 研究结论是，即使没有明确的基于成本的奖励，模型也能够根据任务复杂度调整其推理行为。这提供了强有力的证据，表明资源理性是推理时间扩展本身的涌现属性。

Abstract: Human reasoning is shaped by resource rationality -- optimizing performance under constraints. Recently, inference-time scaling has emerged as a powerful paradigm to improve the reasoning performance of Large Language Models by expanding test-time computation. Specifically, instruction-tuned (IT) models explicitly generate long reasoning steps during inference, whereas Large Reasoning Models (LRMs) are trained by reinforcement learning to discover reasoning paths that maximize accuracy. However, it remains unclear whether resource-rationality can emerge from such scaling without explicit reward related to computational costs. We introduce a Variable Attribution Task in which models infer which variables determine outcomes given candidate variables, input-output trials, and predefined logical functions. By varying the number of candidate variables and trials, we systematically manipulate task complexity. Both models exhibit a transition from brute-force to analytic strategies as complexity increases. IT models degrade on XOR and XNOR functions, whereas LRMs remain robust. These findings suggest that models can adjust their reasoning behavior in response to task complexity, even without explicit cost-based reward. It provides compelling evidence that resource rationality is an emergent property of inference-time scaling itself.

</details>


### [107] [The Subjectivity of Respect in Police Traffic Stops: Modeling Community Perspectives in Body-Worn Camera Footage](https://arxiv.org/abs/2602.10339)
*Preni Golazizian,Elnaz Rahmati,Jackson Trager,Zhivar Sourati,Nona Ghazizadeh,Georgios Chochlakis,Jose Alcocer,Kerby Bennett,Aarya Vijay Devnani,Parsa Hejabi,Harry G. Muttram,Akshay Kiran Padte,Mehrshad Saadatinia,Chenhao Wu,Alireza S. Zaibari,Michael Sierra-Arévalo,Nick Weller,Shrikanth Narayanan,Benjamin A. T. Graham,Morteza Dehghani*

Main category: cs.CL

TL;DR: 本研究利用洛杉矶警察局的车载摄像头（BWC）视频数据，构建了一个包含多方视角（警察、受影响的居民、普通居民）的尊重评分数据集，并开发了一个能够预测个性化尊重评分和生成特定视角理由的模型，旨在帮助执法部门理解社区期望，增强公众信任和程序合法性。


<details>
  <summary>Details</summary>
Motivation: 交通拦截是警察与民众频繁的互动，车载摄像头提供了记录。尊重是这些互动中的关键因素，影响公众信任和合法性认知，但其解读受主观经验影响，需要考虑社区特定视角。现有研究缺乏对不同社区视角下尊重评估的大规模研究。

Method: 研究者开发了一个基于程序正义理论、LAPD培训材料和实地考察的特定领域评估标准。他们构建了一个基于该标准的偏好数据构造框架，以实现视角一致性对齐。最后，他们提出了一种视角感知建模框架，该框架能够预测个性化的尊重评分，并为警察和司机生成特定于注释者的理由，这些理由源自交通拦截的文字记录。

Result: 所提出的视角感知框架在所有三组注释者（警察、受影响的居民、普通居民）中，都能同时提高评分预测性能和理由对齐度。

Conclusion: 通过视角感知建模，可以更好地理解不同社区对交通拦截中尊重的期望，为执法部门提供一个重要的工具，以建立公众信任和程序合法性。

Abstract: Traffic stops are among the most frequent police-civilian interactions, and body-worn cameras (BWCs) provide a unique record of how these encounters unfold. Respect is a central dimension of these interactions, shaping public trust and perceived legitimacy, yet its interpretation is inherently subjective and shaped by lived experience, rendering community-specific perspectives a critical consideration. Leveraging unprecedented access to Los Angeles Police Department BWC footage, we introduce the first large-scale traffic-stop dataset annotated with respect ratings and free-text rationales from multiple perspectives. By sampling annotators from police-affiliated, justice-system-impacted, and non-affiliated Los Angeles residents, we enable the systematic study of perceptual differences across diverse communities. To this end, we (i) develop a domain-specific evaluation rubric grounded in procedural justice theory, LAPD training materials, and extensive fieldwork; (ii) introduce a rubric-driven preference data construction framework for perspective-consistent alignment; and (iii) propose a perspective-aware modeling framework that predicts personalized respect ratings and generates annotator-specific rationales for both officers and civilian drivers from traffic-stop transcripts. Across all three annotator groups, our approach improves both rating prediction performance and rationale alignment. Our perspective-aware framework enables law enforcement to better understand diverse community expectations, providing a vital tool for building public trust and procedural legitimacy.

</details>


### [108] [Geometry-Aware Decoding with Wasserstein-Regularized Truncation and Mass Penalties for Large Language Models](https://arxiv.org/abs/2602.10346)
*Arash Gholami Davoodi,Navid Rezazadeh,Seyed Pouyan Mousavi Davoudi,Pouya Pezeshkpour*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Top-W 的新颖解码采样方法，该方法利用 token 嵌入空间的几何特性（ Wasserstein 距离）来平衡生成文本的多样性、创造力与逻辑连贯性，并在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于截断的采样方法在生成文本时，难以在多样性、创造力与逻辑连贯性之间取得良好平衡，并且主要依赖概率质量和熵，忽视了 token 空间本身的语义几何结构。

Method: Top-W 是一种几何感知的截断规则，它使用 Wasserstein 距离（定义在 token 嵌入几何上）来确保截断后的分布接近原始分布，同时显式地平衡保留的概率质量与被保留集合的熵。该方法通过一种简单的闭式结构来更新固定势能子集，并可以使用线性扫描高效找到最优截断。Top-W 采用高效的基于几何的势能（最近邻或 k-NN），并结合交替解码例程，以保持标准截断和采样接口不变。

Result: 在 GSM8K、GPQA、AlpacaEval 和 MT-Bench 四个基准测试以及三种指令微调模型上的实验表明，Top-W 持续优于现有的最先进解码方法，性能提升高达 33.7%。Top-W 不仅提高了侧重准确性的性能，还在基于评估器的开放式评估中提升了创造力。

Conclusion: Top-W 是一种有效的几何感知解码采样方法，它通过考虑 token 嵌入空间的几何结构，成功地在生成文本的多样性、创造力与逻辑连贯性之间取得了更好的平衡，并在多项评估中展现出优越的性能。

Abstract: Large language models (LLMs) must balance diversity and creativity against logical coherence in open-ended generation. Existing truncation-based samplers are effective but largely heuristic, relying mainly on probability mass and entropy while ignoring semantic geometry of the token space. We present Top-W, a geometry-aware truncation rule that uses Wasserstein distance-defined over token-embedding geometry-to keep the cropped distribution close to the original, while explicitly balancing retained probability mass against the entropy of the kept set. Our theory yields a simple closed-form structure for the fixed-potential subset update: depending on the mass-entropy trade-off, the optimal crop either collapses to a single token or takes the form of a one-dimensional prefix that can be found efficiently with a linear scan. We implement Top-W using efficient geometry-based potentials (nearest-set or k-NN) and pair it with an alternating decoding routine that keeps the standard truncation-and-sampling interface unchanged. Extensive experiments on four benchmarks (GSM8K, GPQA, AlpacaEval, and MT-Bench) across three instruction-tuned models show that Top-W consistently outperforms prior state-of-the-art decoding approaches achieving up to 33.7% improvement. Moreover, we find that Top-W not only improves accuracy-focused performance, but also boosts creativity under judge-based open-ended evaluation.

</details>


### [109] [When Less Is More? Diagnosing ASR Predictions in Sardinian via Layer-Wise Decoding](https://arxiv.org/abs/2602.10350)
*Domenico De Cristofaro,Alessandro Vietti,Marianne Pouplier,Aleese Block*

Main category: cs.CL

TL;DR: 通过对 Wav2Vec2 模型进行分层解码，研究发现中间层比输出层更能准确地预测语音中的音素，尤其是在资源匮乏的语言（如坎皮达尼塞撒丁语）中。这种方法可以降低音素错误率 (PER)，并且早期层级能更好地保留音段信息，减少错误生成和特定音韵错误。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，多语种语音模型中的中间层比最终输出层编码更准确的语音学表示。本研究旨在验证这一发现，并探讨这种现象在低资源语言上的表现，以及如何利用这种分层解码策略改进自动语音识别 (ASR) 模型。

Method: 采用分层解码策略，对预训练的 Wav2Vec2 模型进行逐层分析，重点关注坎皮达尼塞撒丁语。通过计算不同层级的音素错误率 (PER) 来评估预测准确性。此外，还进行了细粒度的对齐分析，以理解中间预测和最终预测在保留音段信息、避免过度生成和减少音韵错误方面的差异。引入“回归错误”的概念来描述中间层正确预测在后续层级被错误覆盖的现象。

Result: 将 Wav2Vec2 模型截断上层 Transformer 层可以提高音素错误率 (PER)，最佳性能出现在倒数第二层，而非最后一层。中间层的预测能更好地保持音段的同一性，避免过度生成，并减少某些类别的音韵错误。研究发现了“回归错误”的现象，即正确预测在最终层被错误覆盖，这表明表面错误度量存在局限性，而深层可能从声学细节中抽象或泛化。

Conclusion: 中间层（特别是较早的层级）提供了更优的音素预测，这在低资源语言中尤为重要。分层解码是一种有用的诊断工具，可以揭示 ASR 模型在低资源设置下的语言学行为。回归错误的发现强调了现有评价指标的不足，并为模型改进提供了方向。

Abstract: Recent studies have shown that intermediate layers in multilingual speech models often encode more phonetically accurate representations than the final output layer. In this work, we apply a layer-wise decoding strategy to a pretrained Wav2Vec2 model to investigate how phoneme-level predictions evolve across encoder layers, focusing on Campidanese Sardinian, a low-resource language. We show that truncating upper transformer layers leads to improved Phoneme Error Rates (PER), with the best performance achieved not at the final layer, but two layers earlier. Through fine-grained alignment analysis, we find that intermediate predictions better preserve segmental identity, avoid overgeneration, and reduce certain classes of phonological errors. We also introduce the notion of regressive errors, cases where correct predictions at intermediate layers are overwritten by errors at the final layer. These regressions highlight the limitations of surface-level error metrics and reveal how deeper layers may generalize or abstract away from acoustic detail. Our findings support the use of early-layer probing as a diagnostic tool for ASR models, particularly in low-resource settings where standard evaluation metrics may fail to capture linguistically meaningful behavior.

</details>


### [110] [Learning Self-Interpretation from Interpretability Artifacts: Training Lightweight Adapters on Vector-Label Pairs](https://arxiv.org/abs/2602.10352)
*Keenan Pepper,Alex McKenzie,Florin Pop,Stijn Servaes,Martin Leitgab,Mike Vaiana,Judd Rosenblatt,Michael S. A. Graziano,Diogo de Lucena*

Main category: cs.CL

TL;DR: 研究提出了一种通过训练轻量级适配器来提高语言模型自解释性（self-interpretation）的方法，该方法在保持原模型冻结的情况下，通过解释适配器生成的特征标签，可以更可靠地识别主题和解码隐含的推理步骤，并且这种自解释性的提升会随着模型规模的增大而增强。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型自解释方法（如self-explanation）对超参数敏感，可靠性不高。研究旨在寻找一种更可靠、更通用的自解释方法，并且希望这种方法能够不修改被解释的模型本身。

Method: 该研究训练轻量级适配器（adapters）来学习解释ability artifacts，同时保持大型语言模型（LM）完全冻结。适配器参数量非常少（d_model+1），仅为标量仿射（scalar affine）类型。通过分析适配器生成的稀疏自编码器特征标签，并将其与训练标签进行比较，同时评估其在主题识别和多跳推理中的表现。

Result: 训练后的适配器生成的特征标签比训练标签本身更优（71% vs 63%），能以94%的recall@1识别主题（未训练基线为1%），并在多跳推理中解码出提示（prompt）和响应（response）中都未出现的桥接实体（bridge entities），揭示了隐含的推理过程。仅学习到的偏置向量（bias vector）就贡献了85%的性能提升。更简单的适配器比更复杂的适配器泛化能力更好。自解释性的提升幅度超过了模型能力（capability）的提升幅度。

Conclusion: 通过训练轻量级适配器，即使在保持大型语言模型冻结的情况下，也可以实现可靠的自解释性，并且这种自解释性的提升会随着模型规模的增大而增强。这种方法能够揭示模型内部的隐含推理，并且比直接提升模型能力更有效。

Abstract: Self-interpretation methods prompt language models to describe their own internal states, but remain unreliable due to hyperparameter sensitivity. We show that training lightweight adapters on interpretability artifacts, while keeping the LM entirely frozen, yields reliable self-interpretation across tasks and model families. A scalar affine adapter with just $d_\text{model}+1$ parameters suffices: trained adapters generate sparse autoencoder feature labels that outperform the training labels themselves (71% vs 63% generation scoring at 70B scale), identify topics with 94% recall@1 versus 1% for untrained baselines, and decode bridge entities in multi-hop reasoning that appear in neither prompt nor response, surfacing implicit reasoning without chain-of-thought. The learned bias vector alone accounts for 85% of improvement, and simpler adapters generalize better than more expressive alternatives. Controlling for model knowledge via prompted descriptions, we find self-interpretation gains outpace capability gains from 7B to 72B parameters. Our results demonstrate that self-interpretation improves with scale, without modifying the model being interpreted.

</details>


### [111] [Autonomous Continual Learning of Computer-Use Agents for Environment Adaptation](https://arxiv.org/abs/2602.10356)
*Tianci Xue,Zeyi Liao,Tianneng Shi,Zilu Wang,Kai Zhang,Dawn Song,Yu Su,Huan Sun*

Main category: cs.CL

TL;DR: 提出了一种名为ACuRL的自主课程强化学习框架，该框架无需人类标注数据，即可使代理（CUAs）在特定环境中持续学习，并通过CUAJudge评估器实现了与人类判断高度一致的自动评估。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数字环境多样且动态，导致代理经常遇到未见过的场景和分布变化，因此在特定环境中进行持续学习至关重要。然而，获取高质量、与环境相关的代理数据而无需昂贵的人工标注是一个关键挑战。

Method: ACuRL框架首先让代理探索目标环境以获取初始经验。在后续的迭代训练中，一个课程任务生成器利用这些经验和前一轮的反馈来合成针对代理当前能力量身定制的新任务。引入了CUAJudge，一个鲁棒的CUA自动评估器，用于提供可靠的奖励信号。

Result: ACuRL有效地实现了环境内部和跨环境的持续学习，性能提升了4-22%，且没有发生灾难性遗忘。分析表明，该方法通过对少量参数（如20%）进行稀疏更新，实现了有效且鲁棒的适应。

Conclusion: ACuRL框架能够自主地为代理生成学习任务，实现零样本人类数据下的持续学习和适应，并且CUAJudge评估器能够可靠地评估代理性能。

Abstract: Real-world digital environments are highly diverse and dynamic. These characteristics cause agents to frequently encounter unseen scenarios and distribution shifts, making continual learning in specific environments essential for computer-use agents (CUAs). However, a key challenge lies in obtaining high-quality and environment-grounded agent data without relying on costly human annotation. In this work, we introduce ACuRL, an Autonomous Curriculum Reinforcement Learning framework that continually adapts agents to specific environments with zero human data. The agent first explores target environments to acquire initial experiences. During subsequent iterative training, a curriculum task generator leverages these experiences together with feedback from the previous iteration to synthesize new tasks tailored for the agent's current capabilities. To provide reliable reward signals, we introduce CUAJudge, a robust automatic evaluator for CUAs that achieves 93% agreement with human judgments. Empirically, our method effectively enables both intra-environment and cross-environment continual learning, yielding 4-22% performance gains without catastrophic forgetting on existing environments. Further analyses show highly sparse updates (e.g., 20% parameters), which helps explain the effective and robust adaptation. Our data and code are available at https://github.com/OSU-NLP-Group/ACuRL.

</details>


### [112] [Physically Interpretable AlphaEarth Foundation Model Embeddings Enable LLM-Based Land Surface Intelligence](https://arxiv.org/abs/2602.10354)
*Mashrekur Rahman*

Main category: cs.CL

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Satellite foundation models produce dense embeddings whose physical interpretability remains poorly understood, limiting their integration into environmental decision systems. Using 12.1 million samples across the Continental United States (2017--2023), we first present a comprehensive interpretability analysis of Google AlphaEarth's 64-dimensional embeddings against 26 environmental variables spanning climate, vegetation, hydrology, temperature, and terrain. Combining linear, nonlinear, and attention-based methods, we show that individual embedding dimensions map onto specific land surface properties, while the full embedding space reconstructs most environmental variables with high fidelity (12 of 26 variables exceed $R^2 > 0.90$; temperature and elevation approach $R^2 = 0.97$). The strongest dimension-variable relationships converge across all three analytical methods and remain robust under spatial block cross-validation (mean $ΔR^2 = 0.017$) and temporally stable across all seven study years (mean inter-year correlation $r = 0.963$). Building on these validated interpretations, we then developed a Land Surface Intelligence system that implements retrieval-augmented generation over a FAISS-indexed embedding database of 12.1 million vectors, translating natural language environmental queries into satellite-grounded assessments. An LLM-as-Judge evaluation across 360 query--response cycles, using four LLMs in rotating generator, system, and judge roles, achieved weighted scores of $μ= 3.74 \pm 0.77$ (scale 1--5), with grounding ($μ= 3.93$) and coherence ($μ= 4.25$) as the strongest criteria. Our results demonstrate that satellite foundation model embeddings are physically structured representations that can be operationalized for environmental and geospatial intelligence.

</details>


### [113] [The Alignment Bottleneck in Decomposition-Based Claim Verification](https://arxiv.org/abs/2602.10380)
*Mahmud Elahi Akhter,Federico Ruggeri,Iman Munire Bilal,Rob Procter,Maria Liakata*

Main category: cs.CL

TL;DR: 本文研究了结构化声明分解在验证复杂声明方面的表现，发现证据对齐和子声明错误画像是关键瓶颈。作者提出了一个新数据集，并评估了两种证据对齐设置下的分解效果，结果表明只有在证据细粒度且严格对齐的情况下，分解才能带来显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 既有研究在结构化声明分解用于验证复杂声明方面表现不一致，作者认为这源于对证据对齐和子声明错误画像这两个被忽视的因素。

Method: 作者引入了一个包含真实世界复杂声明的新数据集，并设计了两种证据对齐设置：子声明对齐证据（SAE）和重复声明级证据（SRE）。通过在不同数据集和领域（PHEMEPlus, MMM-Fact, COVID-Fact）上评估声明分解的性能来验证假设。此外，还分析了子声明标签噪声对下游鲁棒性的影响。

Result: 声明分解仅在证据细粒度且严格对齐（SAE）时带来显著性能提升。相反，依赖重复声明级证据（SRE）的标准设置并未带来提升，反而常常导致性能下降。研究还发现，在存在噪声子声明标签的情况下，错误性质会决定下游鲁棒性，保守的“弃权”策略比激进但错误的预测更能有效减少错误传播。

Conclusion: 未来的声明分解框架应优先考虑精确的证据合成，并校准子声明验证模型的标签偏差。当证据细粒度且严格对齐时，结构化声明分解才能有效提升验证复杂声明的能力。

Abstract: Structured claim decomposition is often proposed as a solution for verifying complex, multi-faceted claims, yet empirical results have been inconsistent. We argue that these inconsistencies stem from two overlooked bottlenecks: evidence alignment and sub-claim error profiles. To better understand these factors, we introduce a new dataset of real-world complex claims, featuring temporally bounded evidence and human-annotated sub-claim evidence spans. We evaluate decomposition under two evidence alignment setups: Sub-claim Aligned Evidence (SAE) and Repeated Claim-level Evidence (SRE). Our results reveal that decomposition brings significant performance improvement only when evidence is granular and strictly aligned. By contrast, standard setups that rely on repeated claim-level evidence (SRE) fail to improve and often degrade performance as shown across different datasets and domains (PHEMEPlus, MMM-Fact, COVID-Fact). Furthermore, we demonstrate that in the presence of noisy sub-claim labels, the nature of the error ends up determining downstream robustness. We find that conservative "abstention" significantly reduces error propagation compared to aggressive but incorrect predictions. These findings suggest that future claim decomposition frameworks must prioritize precise evidence synthesis and calibrate the label bias of sub-claim verification models.

</details>


### [114] [Triggers Hijack Language Circuits: A Mechanistic Analysis of Backdoor Behaviors in Large Language Models](https://arxiv.org/abs/2602.10382)
*Théo Lasnier,Wissam Antoun,Francis Kulumba,Djamé Seddah*

Main category: cs.CL

TL;DR: 研究发现，语言切换的后门攻击通过劫持模型现有的语言处理机制来实现，而不是创建新的独立回路。


<details>
  <summary>Details</summary>
Motivation: 现有对大型语言模型（LLMs）后门攻击的机制理解不足，尤其是触发器如何运作。

Method: 使用激活样本替换（activation patching）技术，分析了GAPperon模型家族（1B, 8B, 24B 参数）中的语言切换后门攻击，定位了触发器信息处理的早期层和特定注意力头。

Result: 触发器激活的注意力头与模型自然编码输出语言的注意力头存在显著重叠（Jaccard 指数 0.18-0.66），表明后门触发器劫持了模型已有的语言组件。

Conclusion: 后门触发器并非形成孤立的回路，而是与模型现有的语言功能纠缠在一起。这一发现对后门防御具有启示作用，建议防御方法应监控已知的功能组件，并可能利用这种纠缠来实现缓解。

Abstract: Backdoor attacks pose significant security risks for Large Language Models (LLMs), yet the internal mechanisms by which triggers operate remain poorly understood. We present the first mechanistic analysis of language-switching backdoors, studying the GAPperon model family (1B, 8B, 24B parameters) which contains triggers injected during pretraining that cause output language switching. Using activation patching, we localize trigger formation to early layers (7.5-25% of model depth) and identify which attention heads process trigger information. Our central finding is that trigger-activated heads substantially overlap with heads naturally encoding output language across model scales, with Jaccard indices between 0.18 and 0.66 over the top heads identified. This suggests that backdoor triggers do not form isolated circuits but instead co-opt the model's existing language components. These findings have implications for backdoor defense: detection methods may benefit from monitoring known functional components rather than searching for hidden circuits, and mitigation strategies could potentially leverage this entanglement between injected and natural behaviors.

</details>


### [115] [When Tables Go Crazy: Evaluating Multimodal Models on French Financial Documents](https://arxiv.org/abs/2602.10384)
*Virginie Mouilleron,Théo Lasnier,Djamé Seddah*

Main category: cs.CL

TL;DR: 本研究提出了第一个用于评估法语金融文档理解的多模态基准 Multimodal Finance Eval，并评估了六个开源视觉语言模型（VLMs）。结果表明，VLMs 在文本和表格任务上表现良好，但在图表理解和多轮对话方面存在严重不足，早期错误会加剧后续的推理失败。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在非英语专业领域的可靠性研究不足，尤其是在金融领域，该领域文档复杂且错误成本高昂。因此，研究者希望创建一个专门的基准来评估和推动 VLM 在这一领域的进步。

Method: 研究者构建了一个包含 1204 个专家验证问题的 Multimodal Finance Eval 数据集，涵盖文本提取、表格理解、图表解释和多轮对话等任务，数据来源于真实的投资说明书、KID 和 PRIIPs 文件。使用 LLM-as-judge 协议评估了六个开源权重 VLM（8B-124B 参数）。

Result: 在文本和表格任务上，VLMs 的准确率达到 85%-90%。然而，在图表解释任务上，准确率仅为 34%-62%。特别地，在多轮对话中，模型早期出现的错误会传播并导致后续准确率急剧下降至约 50%，与模型大小无关。

Conclusion: 当前 VLM 在定义明确的提取任务上是有效的，但在交互式、多步骤的金融分析中仍然脆弱。Multimodal Finance Eval 基准为衡量和推动高风险金融场景下的 VLM 进展提供了有力工具。

Abstract: Vision-language models (VLMs) perform well on many document understanding tasks, yet their reliability in specialized, non-English domains remains underexplored. This gap is especially critical in finance, where documents mix dense regulatory text, numerical tables, and visual charts, and where extraction errors can have real-world consequences. We introduce Multimodal Finance Eval, the first multimodal benchmark for evaluating French financial document understanding. The dataset contains 1,204 expert-validated questions spanning text extraction, table comprehension, chart interpretation, and multi-turn conversational reasoning, drawn from real investment prospectuses, KIDs, and PRIIPs. We evaluate six open-weight VLMs (8B-124B parameters) using an LLM-as-judge protocol. While models achieve strong performance on text and table tasks (85-90% accuracy), they struggle with chart interpretation (34-62%). Most notably, multi-turn dialogue reveals a sharp failure mode: early mistakes propagate across turns, driving accuracy down to roughly 50% regardless of model size.
  These results show that current VLMs are effective for well-defined extraction tasks but remain brittle in interactive, multi-step financial analysis. Multimodal Finance Eval offers a challenging benchmark to measure and drive progress in this high-stakes setting.

</details>


### [116] [Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs](https://arxiv.org/abs/2602.10388)
*Zhongzhi Li,Xuansheng Wu,Yijiang Li,Lijie Hu,Ninghao Liu*

Main category: cs.CL

TL;DR: 研究提出了一种名为 FAC Synthesis 的新方法，通过衡量特征激活覆盖率来提高 LLM 后训练数据的多样性，从而提升下游任务性能，并实现了跨模型家族的知识迁移。


<details>
  <summary>Details</summary>
Motivation: 现有的文本度量方法无法有效捕捉决定 LLM 下游性能的任务相关特征，作者希望找到一种更有效的度量数据多样性的方法。

Method: 提出特征激活覆盖率 (FAC) 度量方法，并构建基于 FAC 的数据合成框架 FAC Synthesis。该框架使用稀疏自编码器识别种子数据集中缺失的特征，然后生成能体现这些特征的合成样本。

Result: FAC Synthesis 方法在数据多样性和多个下游任务（指令遵循、毒性检测、奖励建模、行为引导）的性能上均取得了一致性提升。研究还发现不同模型家族（LLaMA, Mistral, Qwen）之间存在共享的可解释特征空间。

Conclusion: FAC Synthesis 提供了一种有效且实用的方法，用于探索 LLM 数据中心的优化，能够提升模型性能并实现跨模型知识迁移。

Abstract: The diversity of post-training data is critical for effective downstream performance in large language models (LLMs). Many existing approaches to constructing post-training data quantify diversity using text-based metrics that capture linguistic variation, but such metrics provide only weak signals for the task-relevant features that determine downstream performance. In this work, we introduce Feature Activation Coverage (FAC) which measures data diversity in an interpretable feature space. Building upon this metric, we further propose a diversity-driven data synthesis framework, named FAC Synthesis, that first uses a sparse autoencoder to identify missing features from a seed dataset, and then generates synthetic samples that explicitly reflect these features. Experiments show that our approach consistently improves both data diversity and downstream performance on various tasks, including instruction following, toxicity detection, reward modeling, and behavior steering. Interestingly, we identify a shared, interpretable feature space across model families (i.e., LLaMA, Mistral, and Qwen), enabling cross-model knowledge transfer. Our work provides a solid and practical methodology for exploring data-centric optimization of LLMs.

</details>


### [117] [When are We Worried? Temporal Trends of Anxiety and What They Reveal about Us](https://arxiv.org/abs/2602.10400)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 本研究利用词语焦虑关联词典分析了美国和加拿大的社交媒体数据，揭示了社交媒体上焦虑情绪的时间模式（早晨最高，中午最低；工作日高于周末）以及与时态（过去时最高，将来时最低）和代词使用（第三人称、主语代词时焦虑更高）的关系。


<details>
  <summary>Details</summary>
Motivation: 研究者希望通过分析大量的社交媒体数据，了解人们在什么时间最焦虑，以及焦虑情绪与哪些因素（如一天中的时间、一周中的日子、时态、代词使用）相关联，从而提供有价值的洞察。

Method: 研究者使用了一个新创建的词语-焦虑关联词典，分析了美国和加拿大的社交媒体数据（推文）。他们分析了焦虑情绪在一天中、一周中的分布模式，以及在不同时态（过去、现在、将来）和不同代词（第一、二、三人称，主语、宾语）使用时的差异。

Result: 社交媒体上的焦虑情绪在早晨8点最高（与皮质醇水平一致），中午最低。周末焦虑最低，工作日中期最高。过去时态的句子比将来时的句子表现出更高的焦虑。含有第三人称代词（他、他们）的帖子比第一、第二人称代词的帖子焦虑程度更高；含有主语代词（我、他、她、他们）的帖子比含有宾语代词（我、他、她、他们）的帖子焦虑程度更高。

Conclusion: 社交媒体上的焦虑情绪具有系统性的升降模式，并且与一天中的时间、一周中的日子、叙述时态以及叙述的焦点（自我、他人、过去、未来）等因素有关。这些发现为理解人类焦虑的触发因素和表现形式提供了有价值的见解。

Abstract: In this short paper, we make use of a recently created lexicon of word-anxiety associations to analyze large amounts of US and Canadian social media data (tweets) to explore *when* we are anxious and what insights that reveals about us. We show that our levels of anxiety on social media exhibit systematic patterns of rise and fall during the day -- highest at 8am (in-line with when we have high cortisol levels in the body) and lowest around noon. Anxiety is lowest on weekends and highest mid-week. We also examine anxiety in past, present, and future tense sentences to show that anxiety is highest in past tense and lowest in future tense. Finally, we examine the use of anxiety and calmness words in posts that contain pronouns to show: more anxiety in 3rd person pronouns (he, they) posts than 1st and 2nd person pronouns and higher anxiety in posts with subject pronouns (I, he, she, they) than object pronouns (me, him, her, them). Overall, these trends provide valuable insights on not just when we are anxious, but also how different types of focus (future, past, self, outward, etc.) are related to anxiety.

</details>


### [118] [EVOKE: Emotion Vocabulary Of Korean and English](https://arxiv.org/abs/2602.10414)
*Yoonwon Jung,Hagyeong Shin,Benjamin K. Bergen*

Main category: cs.CL

TL;DR: 本文介绍了EVOKE数据集，一个包含英语和韩语情感词汇的平行数据集，提供双语词汇、翻译和特定语言词汇的识别，是目前最全面的情感词汇数据集之一。


<details>
  <summary>Details</summary>
Motivation: 为了填补现有情感词汇数据集在跨语言、多义性、隐喻以及理论无关性方面的不足，为情感科学、心理语言学、计算语言学和自然语言处理等领域提供一个全面的研究资源。

Method: 构建了一个包含大量英语和韩语情感词汇的平行数据集，进行了系统化的标注，包括词汇、多重含义、含义之间的关系、语言特有的情感词汇以及情感相关隐喻的识别。

Result: 创建了一个包含1,427个韩语词汇和1,399个英语词汇的数据集，标注了819个韩语和924个英语的形容词和动词，并识别了多义词和情感相关隐喻。

Conclusion: EVOKE数据集是目前为止最全面、系统且理论无关的英韩情感词汇数据集，可用于多学科研究，并已公开提供下载。

Abstract: This paper introduces EVOKE, a parallel dataset of emotion vocabulary in English and Korean. The dataset offers comprehensive coverage of emotion words in each language, in addition to many-to-many translations between words in the two languages and identification of language-specific emotion words. The dataset contains 1,427 Korean words and 1,399 English words, and we systematically annotate 819 Korean and 924 English adjectives and verbs. We also annotate multiple meanings of each word and their relationships, identifying polysemous emotion words and emotion-related metaphors. The dataset is, to our knowledge, the most comprehensive, systematic, and theory-agnostic dataset of emotion words in both Korean and English to date. It can serve as a practical tool for emotion science, psycholinguistics, computational linguistics, and natural language processing, allowing researchers to adopt different views on the resource reflecting their needs and theoretical perspectives. The dataset is publicly available at https://github.com/yoonwonj/EVOKE.

</details>


### [119] [LATA: A Tool for LLM-Assisted Translation Annotation](https://arxiv.org/abs/2602.10454)
*Baorong Huang,Ali Asiri*

Main category: cs.CL

TL;DR: 本研究提出了一种新颖的、由大型语言模型（LLM）辅助的交互式工具，用于构建高质量的阿拉伯语-英语平行语料库，以解决传统方法在处理结构差异较大的语言对时遇到的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的句子对齐方法在处理结构差异较大的语言对（如阿拉伯语-英语）时存在不足，无法捕捉深层语言差异和语义细微之处，从而影响了翻译研究的质量。研究旨在弥合自动化效率与专家人工判断的严谨性之间的差距。

Method: 研究引入了一个 LLM 辅助的交互式工具。该工具使用模板化提示管理器，利用 LLM 进行句子分割和对齐，并强制要求 JSON 输出格式。该系统采用“人在回路”的工作流程，将自动化预处理与人工干预相结合，允许研究人员通过独立的“stand-off”架构来修正对齐和添加自定义翻译技术标注。

Result: 该 LLM 辅助工具能够有效地进行句子分割和对齐，并通过人在回路的机制实现了对齐的精炼和自定义标注。研究表明，该工具在保持高效率的同时，也保证了对复杂翻译现象分析所需的语言精度。

Conclusion: 研究提出的 LLM 辅助交互式工具能够有效提高平行语料库构建的效率和质量，特别是在处理结构差异大的语言对时。该工具通过整合自动化处理和人工判断，为翻译研究提供了更精确的数据支持，有助于分析复杂翻译现象。

Abstract: The construction of high-quality parallel corpora for translation research has increasingly evolved from simple sentence alignment to complex, multi-layered annotation tasks. This methodological shift presents significant challenges for structurally divergent language pairs, such as Arabic--English, where standard automated tools frequently fail to capture deep linguistic shifts or semantic nuances. This paper introduces a novel, LLM-assisted interactive tool designed to reduce the gap between scalable automation and the rigorous precision required for expert human judgment. Unlike traditional statistical aligners, our system employs a template-based Prompt Manager that leverages large language models (LLMs) for sentence segmentation and alignment under strict JSON output constraints. In this tool, automated preprocessing integrates into a human-in-the-loop workflow, allowing researchers to refine alignments and apply custom translation technique annotations through a stand-off architecture. By leveraging LLM-assisted processing, the tool balances annotation efficiency with the linguistic precision required to analyze complex translation phenomena in specialized domains.

</details>


### [120] [Neuro-Symbolic Synergy for Interactive World Modeling](https://arxiv.org/abs/2602.10480)
*Hongyu Zhao,Siyu Zhou,Haolin Yang,Zengyi Qin,Tianyi Zhou*

Main category: cs.CL

TL;DR: 提出了一种名为NeSyS的神经符号协同框架，结合了LLM的语义表达能力和符号WM的逻辑一致性，以解决LLM在世界模型中容易出现的幻觉问题，并在三个交互式环境中取得了优于基线模型的效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在作为世界模型（WMs）时，尽管具备强大的推理能力，却容易产生幻觉，特别是在需要严格遵守确定性转换规则的边界情况下。而符号WM虽然逻辑一致，但缺乏语义表达能力。本研究旨在弥合这一差距。

Method: 提出NeSyS框架，整合LLM的概率语义先验和可执行的符号规则。该框架通过在彼此解释不足的轨迹之间交替训练LLM和符号WM来工作。符号WM直接通过修改LLM的输出概率分布来约束LLM，而非简单的提示。神经WM仅在未被符号规则覆盖的轨迹上进行微调，从而减少了50%的训练数据。

Result: 在ScienceWorld、Webshop和Plancraft三个不同的交互式环境中进行的广泛实验表明，NeSyS在世界模型预测准确性和数据效率方面均优于基线模型。

Conclusion: NeSyS框架成功地将LLM的语义表达能力与符号WM的鲁棒性相结合，实现了在世界模型任务中的高准确性和高数据效率，克服了现有方法的局限性。

Abstract: Large language models (LLMs) exhibit strong general-purpose reasoning capabilities, yet they frequently hallucinate when used as world models (WMs), where strict compliance with deterministic transition rules--particularly in corner cases--is essential. In contrast, Symbolic WMs provide logical consistency but lack semantic expressivity. To bridge this gap, we propose Neuro-Symbolic Synergy (NeSyS), a framework that integrates the probabilistic semantic priors of LLMs with executable symbolic rules to achieve both expressivity and robustness. NeSyS alternates training between the two models using trajectories inadequately explained by the other. Unlike rule-based prompting, the symbolic WM directly constrains the LLM by modifying its output probability distribution. The neural WM is fine-tuned only on trajectories not covered by symbolic rules, reducing training data by 50% without loss of accuracy. Extensive experiments on three distinct interactive environments, i.e., ScienceWorld, Webshop, and Plancraft, demonstrate NeSyS's consistent advantages over baselines in both WM prediction accuracy and data efficiency.

</details>


### [121] [Canvas-of-Thought: Grounding Reasoning via Mutable Structured States](https://arxiv.org/abs/2602.10494)
*Lingzhuang Sun,Yuxia Zhu,Ruitong Liu,Hao Liang,Zheng Sun,Caijun Jia,Honghao He,Yuchen Wu,Siyuan Li,Jingxuan Wei,Xiangxiang Zhang,Bihui Yu,Wentao Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Canvas-of-Thought (Canvas-CoT) 的新方法，它使用 HTML Canvas 作为外部推理基础，允许模型进行原子化的 DOM 操作，从而实现就地状态修改，提高多模态大语言模型的推理效率和准确性，尤其是在高维视觉任务中。


<details>
  <summary>Details</summary>
Motivation: 现有的 Chain-of-Thought (CoT) 提示在处理复杂的多模态任务时存在瓶颈，因为它们将视觉信息视为静态快照，并且对推理过程中的错误修改不友好，导致代币消耗和认知负荷增加。在高维领域（如几何和 SVG 设计）尤为突出，文本推理缺乏明确的视觉指导。

Method: Canvas-CoT 引入了一个 HTML Canvas 作为外部推理的“画布”，允许模型执行基于 DOM 的原子化增删改查 (CRUD) 操作，从而实现就地状态修改。此外，还集成了一个基于渲染的批评循环，作为硬约束验证器，提供明确的视觉反馈来解决纯文本难以描述的复杂问题。

Result: 在 VCode、RBench-V 和 MathVista 等数据集上的实验表明，Canvas-CoT 在推理效率和准确性方面显著优于现有基线方法。

Conclusion: Canvas-CoT 通过将 HTML Canvas 作为外部推理基础，实现了上下文高效的多模态推理，为处理需要视觉指导和精细状态管理的复杂任务提供了一种新范式。

Abstract: While Chain-of-Thought (CoT) prompting has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), relying solely on linear text sequences remains a bottleneck for complex tasks. We observe that even when auxiliary visual elements are interleaved, they are often treated as static snapshots within a one-dimensional, unstructured reasoning chain. We argue that such approaches treat reasoning history as an immutable stream: correcting a local error necessitates either generating verbose downstream corrections or regenerating the entire context. This forces the model to implicitly maintain and track state updates, significantly increasing token consumption and cognitive load. This limitation is particularly acute in high-dimensional domains, such as geometry and SVG design, where the textual expression of CoT lacks explicit visual guidance, further constraining the model's reasoning precision. To bridge this gap, we introduce \textbf{Canvas-of-Thought (Canvas-CoT)}. By leveraging a HTML Canvas as an external reasoning substrate, Canvas-CoT empowers the model to perform atomic, DOM-based CRUD operations. This architecture enables in-place state revisions without disrupting the surrounding context, allowing the model to explicitly maintain the "ground truth". Furthermore, we integrate a rendering-based critique loop that serves as a hard constraint validator, providing explicit visual feedback to resolve complex tasks that are difficult to articulate through text alone. Extensive experiments on VCode, RBench-V, and MathVista demonstrate that Canvas-CoT significantly outperforms existing baselines, establishing a new paradigm for context-efficient multimodal reasoning.

</details>


### [122] [On the Robustness of Knowledge Editing for Detoxification](https://arxiv.org/abs/2602.10504)
*Ming Dong,Shiyi Tang,Ziyan Peng,Guanyi Chen,Tingting He*

Main category: cs.CL

TL;DR: 本文提出了一种面向鲁棒性的知识编辑（KE）模型去毒化评估框架，发现现有的自动评估方法可能存在误导，识别出“伪去毒化”现象，并指出 KE 去毒化在处理多目标、跨语言和特定模型组合时鲁棒性有限。


<details>
  <summary>Details</summary>
Motivation: 现有 KE 模型去毒化评估方法主要依赖自动毒性分类器，可能无法真实反映模型行为的抑制程度，需要更全面的评估框架来考察其鲁棒性。

Method: 提出一个包含优化鲁棒性、组合鲁棒性和跨语言鲁棒性的评估框架，通过分析模型在不同维度下的表现来评估 KE 去毒化的有效性。

Result: 发现“伪去毒化”是一种常见的失败模式；当联合编辑多个不安全行为时，去毒化效果会下降；单语和跨语言去毒化效果在特定模型-方法组合下才能保持有效。

Conclusion: KE 模型去毒化仅在特定模型、有限数量的去毒化目标和部分语言上表现出鲁棒性，现有方法可能存在局限性。

Abstract: Knowledge-Editing-based (KE-based) detoxification has emerged as a promising approach for mitigating harmful behaviours in Large Language Models. Existing evaluations, however, largely rely on automatic toxicity classifiers, implicitly assuming that reduced toxicity scores reflect genuine behavioural suppression. In this work, we propose a robustness-oriented evaluation framework for KE-based detoxification that examines its reliability beyond standard classifier-based metrics along three dimensions: optimisation robustness, compositional robustness, and cross-lingual robustness. We identify pseudo-detoxification as a common failure mode, where apparent toxicity reductions arise from degenerate generation behaviours rather than meaningful suppression of unsafe content. We further show that detoxification effectiveness degrades when multiple unsafe behaviours are edited jointly, and that both monolingual and cross-lingual detoxification remain effective only under specific model-method combinations. Overall, our results indicate that KE-based detoxification is robust only for certain models, limited numbers of detoxification objectives, and a subset of languages.

</details>


### [123] [LHAW: Controllable Underspecification for Long-Horizon Tasks](https://arxiv.org/abs/2602.10525)
*George Pu,Michael S. Lee,Udari Madhushani Sehwag,David J. Lee,Bryan Zhu,Yash Maurya,Mohit Raghavendra,Yuan Xue,Samuel Marc Denton*

Main category: cs.CL

TL;DR: 本文提出了 LHAW（Long-Horizon Augmented Workflows）框架，一个用于生成和评估长时序工作流中歧义任务变体的系统化方法，并通过实验验证了当前智能体在处理歧义时的表现。


<details>
  <summary>Details</summary>
Motivation: 现有长时序工作流智能体在处理模糊情况时存在局限，缺乏系统化生成和度量歧义影响的方法，阻碍了真正自主系统的发展。

Method: LHAW 框架通过系统性地移除目标、约束、输入和上下文信息，以可配置的严重程度，将标准任务转化为可控的欠指定变体。该框架通过实际智能体试验验证变体，并根据观察到的终端状态差异将其分类。

Result: LHAW 框架生成了 285 个来自三个数据集（TheAgentCompany, SWE-Bench Pro, MCP-Atlas）的任务变体，并进行了形式化分析，评估了当前智能体在不同歧义设置下的检测、推理和解决能力。

Conclusion: LHAW 为长时序环境中智能体澄清行为的成本敏感评估提供了首个系统化框架，有助于开发更可靠的自主系统。

Abstract: Long-horizon workflow agents that operate effectively over extended periods are essential for truly autonomous systems. Their reliable execution critically depends on the ability to reason through ambiguous situations in which clarification seeking is necessary to ensure correct task execution. However, progress is limited by the lack of scalable, task-agnostic frameworks for systematically curating and measuring the impact of ambiguity across custom workflows. We address this gap by introducing LHAW (Long-Horizon Augmented Workflows), a modular, dataset-agnostic synthetic pipeline that transforms any well-specified task into controllable underspecified variants by systematically removing information across four dimensions - Goals, Constraints, Inputs, and Context - at configurable severity levels. Unlike approaches that rely on LLM predictions of ambiguity, LHAW validates variants through empirical agent trials, classifying them as outcome-critical, divergent, or benign based on observed terminal state divergence. We release 285 task variants from TheAgentCompany, SWE-Bench Pro and MCP-Atlas according to our taxonomy alongside formal analysis measuring how current agents detect, reason about, and resolve underspecification across ambiguous settings. LHAW provides the first systematic framework for cost-sensitive evaluation of agent clarification behavior in long-horizon settings, enabling development of reliable autonomous systems.

</details>


### [124] [When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning](https://arxiv.org/abs/2602.10560)
*Leheng Sheng,Yongtao Zhang,Wenchang Ma,Yaorui Shi,Ting Huang,Xiang Wang,An Zhang,Ke Shen,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 本文提出了一种名为GRU-Mem的新方法，用于解决大型语言模型在长上下文推理中的性能下降问题。GRU-Mem通过引入两个文本控制的门（更新门和退出门）来优化记忆更新和循环退出机制，从而提高了效率和稳定性，并在各种长上下文推理任务上取得了显著的性能提升和推理速度加速。


<details>
  <summary>Details</summary>
Motivation: 现有模型（如MemAgent）在处理长上下文时存在记忆爆炸和缺乏退出机制的问题，导致效率低下。研究动机是改进长上下文推理，使其更稳定、更高效。

Method: 提出GRU-Mem模型，该模型包含两个文本控制的门：更新门控制记忆何时更新，退出门控制循环何时终止。通过端到端强化学习引入$r^{	ext{update}}$和$r^{	ext{exit}}$两个奖励信号，分别奖励正确的更新和退出行为。

Result: GRU-Mem在各种长上下文推理任务上表现出有效性和效率。与标准的MemAgent相比，GRU-Mem通常表现更优，推理速度最高可提升400%。

Conclusion: GRU-Mem通过引入受控的记忆更新和循环退出机制，有效地解决了长上下文推理中的挑战，显著提高了大型语言模型的性能和效率。

Abstract: While reasoning over long context is crucial for various real-world applications, it remains challenging for large language models (LLMs) as they suffer from performance degradation as the context length grows. Recent work MemAgent has tried to tackle this by processing context chunk-by-chunk in an RNN-like loop and updating a textual memory for final answering. However, this naive recurrent memory update faces two crucial drawbacks: (i) memory can quickly explode because it can update indiscriminately, even on evidence-free chunks; and (ii) the loop lacks an exit mechanism, leading to unnecessary computation after even sufficient evidence is collected. To address these issues, we propose GRU-Mem, which incorporates two text-controlled gates for more stable and efficient long-context reasoning. Specifically, in GRU-Mem, the memory only updates when the update gate is open and the recurrent loop will exit immediately once the exit gate is open. To endow the model with such capabilities, we introduce two reward signals $r^{\text{update}}$ and $r^{\text{exit}}$ within end-to-end RL, rewarding the correct updating and exiting behaviors respectively. Experiments on various long-context reasoning tasks demonstrate the effectiveness and efficiency of GRU-Mem, which generally outperforms the vanilla MemAgent with up to 400\% times inference speed acceleration.

</details>


### [125] [Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters](https://arxiv.org/abs/2602.10604)
*Ailin Huang,Ang Li,Aobo Kong,Bin Wang,Binxing Jiao,Bo Dong,Bojun Wang,Boyu Chen,Brian Li,Buyun Ma,Chang Su,Changxin Miao,Changyi Wan,Chao Lou,Chen Hu,Chen Xu,Chenfeng Yu,Chengting Feng,Chengyuan Yao,Chunrui Han,Dan Ma,Dapeng Shi,Daxin Jiang,Dehua Ma,Deshan Sun,Di Qi,Enle Liu,Fajie Zhang,Fanqi Wan,Guanzhe Huang,Gulin Yan,Guoliang Cao,Guopeng Li,Han Cheng,Hangyu Guo,Hanshan Zhang,Hao Nie,Haonan Jia,Haoran Lv,Hebin Zhou,Hekun Lv,Heng Wang,Heung-Yeung Shum,Hongbo Huang,Hongbo Peng,Hongyu Zhou,Hongyuan Wang,Houyong Chen,Huangxi Zhu,Huimin Wu,Huiyong Guo,Jia Wang,Jian Zhou,Jianjian Sun,Jiaoren Wu,Jiaran Zhang,Jiashu Lv,Jiashuo Liu,Jiayi Fu,Jiayu Liu,Jie Cheng,Jie Luo,Jie Yang,Jie Zhou,Jieyi Hou,Jing Bai,Jingcheng Hu,Jingjing Xie,Jingwei Wu,Jingyang Zhang,Jishi Zhou,Junfeng Liu,Junzhe Lin,Ka Man Lo,Kai Liang,Kaibo Liu,Kaijun Tan,Kaiwen Yan,Kaixiang Li,Kang An,Kangheng Lin,Lei Yang,Liang Lv,Liang Zhao,Liangyu Chen,Lieyu Shi,Liguo Tan,Lin Lin,Lina Chen,Luck Ma,Mengqiang Ren,Michael Li,Ming Li,Mingliang Li,Mingming Zhang,Mingrui Chen,Mitt Huang,Na Wang,Peng Liu,Qi Han,Qian Zhao,Qinglin He,Qinxin Du,Qiuping Wu,Quan Sun,Rongqiu Yang,Ruihang Miao,Ruixin Han,Ruosi Wan,Ruyan Guo,Shan Wang,Shaoliang Pang,Shaowen Yang,Shengjie Fan,Shijie Shang,Shiliang Yang,Shiwei Li,Shuangshuang Tian,Siqi Liu,Siye Wu,Siyu Chen,Song Yuan,Tiancheng Cao,Tianchi Yue,Tianhao Cheng,Tianning Li,Tingdan Luo,Wang You,Wei Ji,Wei Yuan,Wei Zhang,Weibo Wu,Weihao Xie,Wen Sun,Wenjin Deng,Wenzhen Zheng,Wuxun Xie,Xiangfeng Wang,Xiangwen Kong,Xiangyu Liu,Xiangyu Zhang,Xiaobo Yang,Xiaojia Liu,Xiaolan Yuan,Xiaoran Jiao,Xiaoxiao Ren,Xiaoyun Zhang,Xin Li,Xin Liu,Xin Wu,Xing Chen,Xingping Yang,Xinran Wang,Xu Zhao,Xuan He,Xuanti Feng,Xuedan Cai,Xuqiang Zhou,Yanbo Yu,Yang Li,Yang Xu,Yanlin Lai,Yanming Xu,Yaoyu Wang,Yeqing Shen,Yibo Zhu,Yichen Lv,Yicheng Cao,Yifeng Gong,Yijing Yang,Yikun Yang,Yin Zhao,Yingxiu Zhao,Yinmin Zhang,Yitong Zhang,Yixuan Zhang,Yiyang Chen,Yongchi Zhao,Yongshen Long,Yongyao Wang,Yousong Guan,Yu Zhou,Yuang Peng,Yuanhao Ding,Yuantao Fan,Yuanzhen Yang,Yuchu Luo,Yudi Zhao,Yue Peng,Yueqiang Lin,Yufan Lu,Yuling Zhao,Yunzhou Ju,Yurong Zhang,Yusheng Li,Yuxiang Yang,Yuyang Chen,Yuzhu Cai,Zejia Weng,Zetao Hong,Zexi Li,Zhe Xie,Zheng Ge,Zheng Gong,Zheng Zeng,Zhenyi Lu,Zhewei Huang,Zhichao Chang,Zhiguo Huang,Zhiheng Hu,Zidong Yang,Zili Wang,Ziqi Ren,Zixin Zhang,Zixuan Wang*

Main category: cs.CL

TL;DR: Step 3.5 Flash 是一种稀疏专家混合（MoE）模型，它通过结合高效推理和前沿智能来构建智能代理，并在多项基准测试中取得了与 GPT-5.2 xHigh 和 Gemini 3.0 Pro 相当的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是构建在高效推理的同时具备前沿智能水平的代理模型，以满足现实世界工业环境的部署需求。

Method: 该模型采用了 196B 参数的底层模型和 11B 的激活参数，并使用 3:1 滑动窗口/全注意力交织以及多令牌预测（MTP-3）进行优化，以降低多轮代理交互的延迟和成本。此外，还设计了一个可扩展的强化学习框架，结合了可验证信号和偏好反馈，以实现数学、代码和工具使用的稳定自适应改进。

Result: Step 3.5 Flash 在 IMO-AnswerBench（85.4%）、LiveCodeBench-v6（86.4%）、tau2-Bench（88.2%）、BrowseComp（69.0%）和 Terminal-Bench 2.0（51.0%）等任务上表现出色，性能可与 GPT-5.2 xHigh 和 Gemini 3.0 Pro 等前沿模型相媲美。

Conclusion: Step 3.5 Flash 在效率和智能水平方面均达到了新的高度，为在现实世界工业环境中部署复杂的代理提供了高效的基础。

Abstract: We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.

</details>


### [126] [Online Causal Kalman Filtering for Stable and Effective Policy Optimization](https://arxiv.org/abs/2602.10609)
*Shuo He,Lang Feng,Xin Cheng,Lei Feng,Bo An*

Main category: cs.CL

TL;DR: 提出了一种名为 KPO（Online Causal Kalman Filtering for stable and effective Policy Optimization）的新方法，用于解决大型语言模型强化学习中高方差的 token 级重要性采样（IS）比例问题，通过卡尔曼滤波在线平滑 IS 比例，提高了训练稳定性和有效性，并在数学推理任务上取得了优于 SOTA 的结果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型强化学习中，高方差的 token 级 IS 比例会影响策略优化的稳定性。现有方法在处理 token 级 IS 比例时忽略了时间上的 off-policy 依赖性，导致局部 off-policy 偏差在 token 级别不一致，可能扭曲策略梯度更新并导致训练崩溃。

Method: 提出 KPO 方法，将期望的 IS 比例建模为随 token 演变的潜在状态，并使用卡尔曼滤波器根据过去 token 的状态在线、自回归地更新该状态。这种方法保留了 token 级局部结构感知变化，同时平滑了噪声尖峰。

Result: KPO 在具有挑战性的数学推理数据集上取得了优于现有最先进方法的实验结果。

Conclusion: KPO 通过在线因果卡尔曼滤波，能够稳定且有效地进行策略优化，解决了大型语言模型强化学习中的高方差 IS 比例问题，并在数学推理任务上展示了其优越性。

Abstract: Reinforcement learning for large language models suffers from high-variance token-level importance sampling (IS) ratios, which would destabilize policy optimization at scale. To improve stability, recent methods typically use a fixed sequence-level IS ratio for all tokens in a sequence or adjust each token's IS ratio separately, thereby neglecting temporal off-policy derivation across tokens in a sequence. In this paper, we first empirically identify that local off-policy deviation is structurally inconsistent at the token level, which may distort policy-gradient updates across adjacent tokens and lead to training collapse. To address the issue, we propose Online Causal Kalman Filtering for stable and effective Policy Optimization (KPO). Concretely, we model the desired IS ratio as a latent state that evolves across tokens and apply a Kalman filter to update this state online and autoregressively based on the states of past tokens, regardless of future tokens. The resulting filtered IS ratios preserve token-wise local structure-aware variation while strongly smoothing noise spikes, yielding more stable and effective policy updates. Experimentally, KPO achieves superior results on challenging math reasoning datasets compared with state-of-the-art counterparts.

</details>


### [127] [How Do Decoder-Only LLMs Perceive Users? Rethinking Attention Masking for User Representation Learning](https://arxiv.org/abs/2602.10622)
*Jiahao Yuan,Yike Xu,Jinyong Wen,Baokun Wang,Yang Chen,Xiaotong Lin,Wuliang Huang,Ziyi Gao,Xing Fu,Yu Cheng,Weiqiang Wang*

Main category: cs.CL

TL;DR: 本研究系统地研究了注意力掩码对仅解码器大语言模型用户表示学习的影响，提出了一种名为梯度引导软掩码（Gradient-Guided Soft Masking）的新方法，以改善从因果到双向注意力掩码的训练动态，并在多项工业用户认知基准测试中取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管仅解码器大语言模型常被用作用户表示学习的行为编码器，但注意力掩码对其用户嵌入质量的影响尚未得到充分研究。

Method: 作者在一个统一的对比学习框架下，对因果、混合和双向注意力掩码进行了系统研究。他们还提出了一种梯度引导软掩码（GGSM）方法，通过梯度引导预热和线性调度器结合，来平滑从因果注意力到双向注意力的过渡。该方法在大型真实世界支付宝用户行为数据上进行了训练。

Result: 与仅因果、混合和仅调度器基线相比，GGSM方法在9个工业用户认知基准测试（包括预测、偏好和营销敏感性任务）上，展现出更稳定的训练过程和更高质量的双向表示，同时兼容预训练的解码器模型。

Conclusion: 研究结果强调了掩码设计和训练过渡在适配仅解码器大语言模型以实现有效用户表示学习方面的重要性。

Abstract: Decoder-only large language models are increasingly used as behavioral encoders for user representation learning, yet the impact of attention masking on the quality of user embeddings remains underexplored. In this work, we conduct a systematic study of causal, hybrid, and bidirectional attention masks within a unified contrastive learning framework trained on large-scale real-world Alipay data that integrates long-horizon heterogeneous user behaviors. To improve training dynamics when transitioning from causal to bidirectional attention, we propose Gradient-Guided Soft Masking, a gradient-based pre-warmup applied before a linear scheduler that gradually opens future attention during optimization. Evaluated on 9 industrial user cognition benchmarks covering prediction, preference, and marketing sensitivity tasks, our approach consistently yields more stable training and higher-quality bidirectional representations compared with causal, hybrid, and scheduler-only baselines, while remaining compatible with decoder pretraining. Overall, our findings highlight the importance of masking design and training transition in adapting decoder-only LLMs for effective user representation learning. Our code is available at https://github.com/JhCircle/Deepfind-GGSM.

</details>


### [128] [UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory](https://arxiv.org/abs/2602.10652)
*Yongshi Ye,Hui Jiang,Feihu Jiang,Tian Lan,Yichao Du,Biao Fu,Xiaodong Shi,Qianghuai Jia,Longyue Wang,Weihua Luo*

Main category: cs.CL

TL;DR: UMEM 框架通过联合优化 LLM 的记忆提取和管理，解决了现有方法中记忆提取静态化导致泛化能力差的问题，提高了 LLM 智能体的性能和记忆的通用性。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 智能体的内存优化方法主要关注内存管理，而将内存提取视为静态过程，导致智能体过度拟合特定实例，积累噪声而非鲁棒记忆，泛化能力差。

Method: 提出 UMEM 框架，联合优化 LLM 进行记忆提取和管理。引入语义邻域建模，并通过 GRPO 优化邻域级别的边际效用奖励，以缓解对特定实例的过拟合，确保记忆的通用性。

Result: 在五个基准测试上，UMEM 显著优于竞争基线，在多轮交互任务上提升高达 10.67%。UMEM 在持续进化过程中保持单调增长曲线。

Conclusion: UMEM 框架能够通过联合优化记忆提取和管理，有效提升 LLM 智能体的性能和记忆的通用性，解决了现有方法的局限性。

Abstract: Self-evolving memory serves as the trainable parameters for Large Language Models (LLMs)-based agents, where extraction (distilling insights from experience) and management (updating the memory bank) must be tightly coordinated. Existing methods predominately optimize memory management while treating memory extraction as a static process, resulting in poor generalization, where agents accumulate instance-specific noise rather than robust memories. To address this, we propose Unified Memory Extraction and Management (UMEM), a self-evolving agent framework that jointly optimizes a Large Language Model to simultaneous extract and manage memories. To mitigate overfitting to specific instances, we introduce Semantic Neighborhood Modeling and optimize the model with a neighborhood-level marginal utility reward via GRPO. This approach ensures memory generalizability by evaluating memory utility across clusters of semantically related queries. Extensive experiments across five benchmarks demonstrate that UMEM significantly outperforms highly competitive baselines, achieving up to a 10.67% improvement in multi-turn interactive tasks. Futhermore, UMEM maintains a monotonic growth curve during continuous evolution. Codes and models will be publicly released.

</details>


### [129] [Benchmarks Are Not That Out of Distribution: Word Overlap Predicts Performance](https://arxiv.org/abs/2602.10657)
*Woojin Chung,Jeonghoon Kim*

Main category: cs.CL

TL;DR: 研究表明，语言模型在大规模预训练中，预训练数据与评估数据集之间的词汇重叠度（通过词级别交叉熵和词频统计衡量）是影响模型在基准测试性能的关键因素。


<details>
  <summary>Details</summary>
Motivation: 理解构成高质量预训练数据的要素是语言模型训练中的核心问题。本研究旨在探究基准测试性能是否主要由预训练语料库与评估数据集之间的统计模式重叠程度驱动。

Method: 研究者通过计算词级别的一元交叉熵和词频统计量来衡量预训练数据与评估数据集之间的重叠度。在10个零样本基准测试、4个不同规模（8.5B至60B tokens）的预训练数据集以及不同模型规模（400M至3B参数）下进行了对照实验。

Result: 结果显示，词级别一元交叉熵与基准测试性能之间存在稳健的反向关系，表明常用基准测试受训练和评估数据之间词汇重叠的影响很大。此外，具有相似词级别一元交叉熵的更大规模预训练子集能带来更好的下游任务表现，这说明词频统计在塑造基准测试分数方面也发挥着作用。

Conclusion: 研究结果表明，许多标准基准测试在相对于预训练语料库的分布上，只有很弱的“分布外”特性，简单的词汇重叠统计量就能预测基准测试的性能。因此，预训练数据的选择和与评估数据的重叠度是影响模型表现的重要因素。

Abstract: Understanding what constitutes high-quality pre-training data remains a central question in language model training. In this work, we investigate whether benchmark performance is primarily driven by the degree of statistical pattern overlap between pre-training corpora and evaluation datasets. We measure this overlap using word-level unigram cross-entropy and word frequency statistics, and perform controlled experiments across $10$ zero-shot benchmarks, $4$ pre-training datasets spanning $8.5\mathrm{B}$ to $60\mathrm{B}$ tokens, and model sizes ranging from $400\mathrm{M}$ to $3\mathrm{B}$ parameters. Our results demonstrate a robust inverse relationship between word-level unigram cross-entropy and benchmark performance, suggesting that widely used benchmarks are strongly influenced by word overlap between training and evaluation data. Thus, larger pre-training subsets with similar word-level unigram cross-entropy yield improved downstream results, indicating that word frequency statistics play an additional role in shaping benchmark scores. Taken together, these results suggest that many standard benchmarks are only weakly out-of-distribution relative to pre-training corpora, so that simple word-overlap statistics predict benchmark performance.

</details>


### [130] [Targeted Syntactic Evaluation of Language Models on Georgian Case Alignment](https://arxiv.org/abs/2602.10661)
*Daniel Gallagher,Gerhard Heyer*

Main category: cs.CL

TL;DR: 该研究评估了基于 Transformer 的语言模型在处理格鲁吉亚语的裂分格格位配位（split-ergative case alignment）任务上的表现，并发现模型在格格（ergative）格位的处理上表现最差，在主格（nominative）格位上表现最好，这与格位形式的频率分布相关。


<details>
  <summary>Details</summary>
Motivation: 评估 transformer 模型在处理格鲁吉亚语这种罕见的裂分格格位配位系统上的性能，以及探究数据稀疏性和格位特异性对模型性能的影响。

Method: 使用基于树库（treebank-based）的方法，通过 Grew 查询语言生成最小对（minimal pairs）数据集。创建包含 370 个语法测试、分为七个任务的数据集，每个任务包含 50-70 个样本。评估了五种编码器-解码器模型和两种仅解码器模型，并使用了词级别和/或句子级别的准确率指标。

Result: 模型在格格（ergative）格位的分配上表现最差，在主格（nominative）格位上表现最好。性能与这三种格位形式（主格 > 与格 > 作格）的整体频率分布呈正相关。

Conclusion: 模型在处理格鲁吉亚语的裂分格格位配位时，格格（ergative）格位的低性能可能与该格位的特定功能以及训练数据的稀缺性有关。研究提供了一个用于低资源语言语法评估的方法，并公开了数据集。

Abstract: This paper evaluates the performance of transformer-based language models on split-ergative case alignment in Georgian, a particularly rare system for assigning grammatical cases to mark argument roles. We focus on subject and object marking determined through various permutations of nominative, ergative, and dative noun forms. A treebank-based approach for the generation of minimal pairs using the Grew query language is implemented. We create a dataset of 370 syntactic tests made up of seven tasks containing 50-70 samples each, where three noun forms are tested in any given sample. Five encoder- and two decoder-only models are evaluated with word- and/or sentence-level accuracy metrics. Regardless of the specific syntactic makeup, models performed worst in assigning the ergative case correctly and strongest in assigning the nominative case correctly. Performance correlated with the overall frequency distribution of the three forms (NOM > DAT > ERG). Though data scarcity is a known issue for low-resource languages, we show that the highly specific role of the ergative along with a lack of available training data likely contributes to poor performance on this case. The dataset is made publicly available and the methodology provides an interesting avenue for future syntactic evaluations of languages where benchmarks are limited.

</details>


### [131] [Locomo-Plus: Beyond-Factual Cognitive Memory Evaluation Framework for LLM Agents](https://arxiv.org/abs/2602.10715)
*Yifei Li,Weidong Guo,Lingling Zhang,Rongman Xu,Muye Huang,Hui Liu,Lijiao Xu,Yu Xu,Jun Liu*

Main category: cs.CL

TL;DR: 本文提出LoCoMo-Plus基准，用于评估语言模型（LLM）在长对话中保持和应用隐式用户约束（如用户状态、目标或价值观）的能力，解决了现有基准侧重于表面事实回忆的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的对话系统评估方法主要关注事实回忆，而忽略了在真实交互中至关重要的、未明确查询的隐式用户约束（如用户状态、目标、价值观）。这导致对模型真实对话能力评估不足。

Method: 提出LoCoMo-Plus基准，用于评估在“提示-触发语义断裂”情境下的认知记忆能力。开发了一个基于约束一致性的统一评估框架，并展示了传统指标（如字符串匹配、显式任务类型提示）在此类场景下的局限性。

Result: 通过在不同模型、检索方法和记忆系统上的实验，证明了认知记忆仍然是一个挑战，并且LoCoMo-Plus能够揭示现有基准无法捕捉到的模型失效情况。

Conclusion: 评估LLM的长期对话记忆需要超越表面事实回忆，关注模型在理解和应用隐式约束方面的能力。LoCoMo-Plus提供了一个更全面的评估框架，突显了当前模型在该方面的不足。

Abstract: Long-term conversational memory is a core capability for LLM-based dialogue systems, yet existing benchmarks and evaluation protocols primarily focus on surface-level factual recall. In realistic interactions, appropriate responses often depend on implicit constraints such as user state, goals, or values that are not explicitly queried later. To evaluate this setting, we introduce \textbf{LoCoMo-Plus}, a benchmark for assessing cognitive memory under cue--trigger semantic disconnect, where models must retain and apply latent constraints across long conversational contexts. We further show that conventional string-matching metrics and explicit task-type prompting are misaligned with such scenarios, and propose a unified evaluation framework based on constraint consistency. Experiments across diverse backbone models, retrieval-based methods, and memory systems demonstrate that cognitive memory remains challenging and reveals failures not captured by existing benchmarks. Our code and evaluation framework are publicly available at: https://github.com/xjtuleeyf/Locomo-Plus.

</details>


### [132] [Macaron: Controlled, Human-Written Benchmark for Multilingual and Multicultural Reasoning via Template-Filling](https://arxiv.org/abs/2602.10732)
*Alaa Elsetohy,Sama Hadhoud,Haryo Akbarianto Wibowo,Chenxi Whitehouse,Genta Indra Winata,Fajri Koto,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Macaron 的多语言推理基准，它通过模板化方法分离了推理类型和文化背景，并为20种语言（包括低资源语言）创建了包含11,862个实例的数据集，以评估多语言大型语言模型在不同文化背景下的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言推理基准存在局限性：翻译数据集保留了英语中心化的场景，而文化优先的数据集则缺乏对所需推理的控制。因此，需要一个能够解耦推理类型和文化方面，并支持多种语言（包括低资源语言）的新型基准。

Method: 提出了一种“模板优先”的基准构建方法，使用100个语言无关的模板，覆盖7种推理类型和22种文化方面。邀请母语标注者创建与场景匹配的英语和当地语言的多项选择题，以及系统衍生的判断题。最终形成了包含20个国家/文化背景、10种书写系统和20种语言的Macaron数据集。

Result: 在21个多语言大型语言模型的零样本评估中，采用推理模式的模型表现最佳，且在英语和当地语言之间接近表现持平。开源模型在当地语言上的性能显著下降，并且在判断题任务上接近随机猜测。文化相关的数学和计数模板被证明是最困难的。

Conclusion: Macaron基准能够有效地评估多语言大型语言模型在不同文化背景下的推理能力。结果表明，现有模型在处理非英语文化背景和低资源语言时仍存在挑战，尤其是在推理能力方面。

Abstract: Multilingual benchmarks rarely test reasoning over culturally grounded premises: translated datasets keep English-centric scenarios, while culture-first datasets often lack control over the reasoning required. We propose Macaron, a template-first benchmark that factorizes reasoning type and cultural aspect across question languages. Using 100 language-agnostic templates that cover 7 reasoning types, 22 cultural aspects, native annotators create scenario-aligned English and local-language multiple-choice questions and systematically derived True/False questions. Macaron contains 11,862 instances spanning 20 countries/cultural contexts, 10 scripts, and 20 languages (including low-resource ones like Amharic, Yoruba, Zulu, Kyrgyz, and some Arabic dialects). In zero-shot evaluation of 21 multilingual LLMs, reasoning-mode models achieve the strongest performance and near-parity between English and local languages, while open-weight models degrade substantially in local languages and often approach chance on T/F tasks. Culture-grounded mathematical and counting templates are consistently the hardest. The data can be accessed here https://huggingface.co/datasets/AlaaAhmed2444/Macaron.

</details>


### [133] [Reinforced Curriculum Pre-Alignment for Domain-Adaptive VLMs](https://arxiv.org/abs/2602.10740)
*Yuming Yan,Shuo Yang,Kai Tang,Sihong Chen,Yang Zhang,Ke Xu,Dan Hu,Qun Yu,Pengfei Hu,Edith C. H. Ngai*

Main category: cs.CL

TL;DR: 本文提出了一种名为RCPA（Reinforced Curriculum Pre-Alignment）的新型后训练范式，用于在适应特定领域的同时保留视觉语言模型（VLMs）的通用能力，解决了监督微调（SFT）引起的灾难性遗忘问题以及现有强化学习方法在领域知识不足时面临的优化崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在特定领域表现不佳，而监督微调（SFT）会导致灾难性遗忘。持续预训练成本高且数据不可得。基于强化学习（RL）的方法在领域知识不足时可能导致优化崩溃。因此，需要一种能有效适应新领域并保留通用能力的VLMs后训练方法。

Method: 提出一种名为RCPA（Reinforced Curriculum Pre-Alignment）的新型后训练范式。RCPA采用课程学习策略，初期通过部分输出约束安全地引入新领域概念，然后逐步过渡到完整的生成优化，以平衡领域知识获取和通用多模态能力的保留。

Result: 在多个专业领域和通用基准测试上的广泛实验验证了RCPA的有效性。

Conclusion: RCPA是一种有效的后训练方法，能够实现高性能且领域适应性强的VLMs，在保留通用能力的同时有效适应新领域。

Abstract: Vision-Language Models (VLMs) demonstrate remarkable general-purpose capabilities but often fall short in specialized domains such as medical imaging or geometric problem-solving. Supervised Fine-Tuning (SFT) can enhance performance within a target domain, but it typically causes catastrophic forgetting, limiting its generalization. The central challenge, therefore, is to adapt VLMs to new domains while preserving their general-purpose capabilities. Continual pretraining is effective for expanding knowledge in Large Language Models (LLMs), but it is less feasible for VLMs due to prohibitive computational costs and the unavailability of pretraining data for most open-source models. This necessitates efficient post-training adaptation methods. Reinforcement learning (RL)-based approaches such as Group Relative Policy Optimization (GRPO) have shown promise in preserving general abilities, yet they often fail in domain adaptation scenarios where the model initially lacks sufficient domain knowledge, leading to optimization collapse. To bridge this gap, we propose Reinforced Curriculum Pre-Alignment (RCPA), a novel post-training paradigm that introduces a curriculum-aware progressive modulation mechanism. In the early phase, RCPA applies partial output constraints to safely expose the model to new domain concepts. As the model's domain familiarity increases, training gradually transitions to full generation optimization, refining responses and aligning them with domain-specific preferences. This staged adaptation balances domain knowledge acquisition with the preservation of general multimodal capabilities. Extensive experiments across specialized domains and general benchmarks validate the effectiveness of RCPA, establishing a practical pathway toward building high-performing and domain-adaptive VLMs.

</details>


### [134] [Deep Learning-based Method for Expressing Knowledge Boundary of Black-Box LLM](https://arxiv.org/abs/2602.10801)
*Haotian Sheng,Heyong Wang,Ming Hong,Hongman He,Junqiu Liu*

Main category: cs.CL

TL;DR: 本文提出 LSCL（LLM-Supervised Confidence Learning）方法，用于解决黑盒大型语言模型（LLMs）的知识边界表达问题，通过知识蒸馏构建深度学习模型，以输入问题、输出答案和 token 概率为依据，量化和表达黑盒 LLM 的知识边界。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）存在内容生成失真（幻觉）问题，限制了其实际应用。幻觉的核心原因在于 LLMs 缺乏对其内部存储知识的认知能力，无法像人类一样表达超出其知识边界的问题。而现有研究主要集中在白盒 LLMs，对只能通过 API 访问的黑盒 LLMs 的知识边界表达方法探索不足。

Method: 提出 LSCL（LLM-Supervised Confidence Learning）方法，这是一种基于深度学习的方法。它基于知识蒸馏框架，设计了一个深度学习模型。该模型以黑盒 LLM 的输入问题、输出答案和 token 概率作为输入，构建输入与模型内部知识状态之间的映射，从而实现对黑盒 LLM 知识边界的量化和表达。此外，还提出了一种自适应的替代方法，用于处理不支持 token 概率访问的黑盒 LLMs。

Result: 在多个知名黑盒 LLMs 和多样化的公开数据集上的实验表明，LSCL 能够有效地帮助黑盒 LLMs 精准地表达其知识边界。与现有的基线模型相比，LSCL 在准确率和召回率等指标上均表现出色。提出的自适应替代方法性能接近 LSCL，并优于基线模型。

Conclusion: LSCL 是一种有效的、适用于黑盒 LLMs 的知识边界表达方法，能够显著提升 LLMs 在处理超出其知识范围的问题时的可靠性。提出的自适应方法进一步扩展了该方法在不同场景下的适用性。

Abstract: Large Language Models (LLMs) have achieved remarkable success, however, the emergence of content generation distortion (hallucination) limits their practical applications. The core cause of hallucination lies in LLMs' lack of awareness regarding their stored internal knowledge, preventing them from expressing their knowledge state on questions beyond their internal knowledge boundaries, as humans do. However, existing research on knowledge boundary expression primarily focuses on white-box LLMs, leaving methods suitable for black-box LLMs which offer only API access without revealing internal parameters-largely unexplored. Against this backdrop, this paper proposes LSCL (LLM-Supervised Confidence Learning), a deep learning-based method for expressing the knowledge boundaries of black-box LLMs. Based on the knowledge distillation framework, this method designs a deep learning model. Taking the input question, output answer, and token probability from a black-box LLM as inputs, it constructs a mapping between the inputs and the model' internal knowledge state, enabling the quantification and expression of the black-box LLM' knowledge boundaries. Experiments conducted on diverse public datasets and with multiple prominent black-box LLMs demonstrate that LSCL effectively assists black-box LLMs in accurately expressing their knowledge boundaries. It significantly outperforms existing baseline models on metrics such as accuracy and recall rate. Furthermore, considering scenarios where some black-box LLMs do not support access to token probability, an adaptive alternative method is proposed. The performance of this alternative approach is close to that of LSCL and surpasses baseline models.

</details>


### [135] [Beyond Confidence: The Rhythms of Reasoning in Generative Models](https://arxiv.org/abs/2602.10816)
*Deyuan Liu,Zecheng Wang,Zhanyue Qin,Zhiying Tu,Dianhui Chu,Dianbo Sui*

Main category: cs.CL

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Large Language Models (LLMs) exhibit impressive capabilities yet suffer from sensitivity to slight input context variations, hampering reliability. Conventional metrics like accuracy and perplexity fail to assess local prediction robustness, as normalized output probabilities can obscure the underlying resilience of an LLM's internal state to perturbations. We introduce the Token Constraint Bound ($δ_{\mathrm{TCB}}$), a novel metric that quantifies the maximum internal state perturbation an LLM can withstand before its dominant next-token prediction significantly changes. Intrinsically linked to output embedding space geometry, $δ_{\mathrm{TCB}}$ provides insights into the stability of the model's internal predictive commitment. Our experiments show $δ_{\mathrm{TCB}}$ correlates with effective prompt engineering and uncovers critical prediction instabilities missed by perplexity during in-context learning and text generation. $δ_{\mathrm{TCB}}$ offers a principled, complementary approach to analyze and potentially improve the contextual stability of LLM predictions.

</details>


### [136] [I can tell whether you are a Native Hawlêri Speaker! How ANN, CNN, and RNN perform in NLI-Native Language Identification](https://arxiv.org/abs/2602.10832)
*Hardi Garari,Hossein Hassani*

Main category: cs.CL

TL;DR: 本研究针对库尔德语索拉尼方言中的埃尔比勒（Hewlêri）子方言，提出了基于神经网络的母语识别（NLI）模型，并在创建的首个相关语音数据集上取得了95.92%的最高准确率。


<details>
  <summary>Details</summary>
Motivation: 现有母语识别（NLI）研究主要集中在两种不同语言之间，而对较少资源的方言和子方言，特别是库尔德语，研究存在显著空白。本研究旨在填补这一空白，关注埃尔比勒（Hewlêri）子方言的NLI。

Method: 收集了40名埃尔比勒（Hewlêri）方言说话者的约24小时语音数据。构建了三种基于神经网络的模型：人工神经网络（ANN）、卷积神经网络（CNN）和循环神经网络（RNN）。通过66次实验，涵盖1到60秒的不同时间帧、欠采样、过采样和交叉验证等策略进行评估。

Result: 循环神经网络（RNN）模型在5秒音频分割、采用80:10:10数据划分方案时，取得了95.92%的最高准确率。

Conclusion: 本研究成功构建了首个针对库尔德语索拉尼方言埃尔比勒（Hewlêri）子方言的NLI语音数据集，并验证了RNN模型在该任务上的有效性，取得了显著的识别准确率，该数据集可为相关研究领域提供重要资源。

Abstract: Native Language Identification (NLI) is a task in Natural Language Processing (NLP) that typically determines the native language of an author through their writing or a speaker through their speaking. It has various applications in different areas, such as forensic linguistics and general linguistics studies. Although considerable research has been conducted on NLI regarding two different languages, such as English and German, the literature indicates a significant gap regarding NLI for dialects and subdialects. The gap becomes wider in less-resourced languages such as Kurdish. This research focuses on NLI within the context of a subdialect of Sorani (Central) Kurdish. It aims to investigate the NLI for Hewlêri, a subdialect spoken in Hewlêr (Erbil), the Capital of the Kurdistan Region of Iraq. We collected about 24 hours of speech by recording interviews with 40 native or non-native Hewlêri speakers, 17 female and 23 male. We created three Neural Network-based models: Artificial Neural Network (ANN), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN), which were evaluated through 66 experiments, covering various time-frames from 1 to 60 seconds, undersampling, oversampling, and cross-validation. The RNN model showed the highest accuracy of 95.92% for 5-second audio segmentation, using an 80:10:10 data splitting scheme. The created dataset is the first speech dataset for NLI on the Hewlêri subdialect in the Sorani Kurdish dialect, which can be of benefit to various research areas.

</details>


### [137] [C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution](https://arxiv.org/abs/2602.10874)
*Binwei Yan,Yifei Fu,Mingjian Zhu,Hanting Chen,Mingxuan Yuan,Yunhe Wang,Hailin Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为C-MOP的框架，通过边界感知对比采样（BACS）和动量引导语义聚类（MGSC）来优化大型语言模型的提示词，以解决现有方法中信号噪声和冲突的问题，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）自动提示词优化方法存在更新信号噪声和冲突的问题，限制了其性能提升。

Method: 提出C-MOP框架，包含边界感知对比采样（BACS）和动量引导语义聚类（MGSC）。BACS利用批次级信息挖掘三方特征（难负例、锚点、边界对）来刻画正负样本的表示和决策边界。MGSC引入文本动量机制和时间衰减，以整合跨迭代的梯度共识，解决语义冲突。

Result: C-MOP在实验中持续优于PromptWizard和ProTeGi等现有最佳基线，平均提升1.58%和3.35%。具体而言，C-MOP能够使一个3B参数的通用LLM超越一个70B参数的领域特定LLM。

Conclusion: C-MOP框架通过BACS和MGSC有效地稳定了提示词优化过程，解决了信号噪声和冲突问题，显著提升了LLMs的性能，并展示了其在驱动精确提示词演进方面的强大能力。

Abstract: Automatic prompt optimization is a promising direction to boost the performance of Large Language Models (LLMs). However, existing methods often suffer from noisy and conflicting update signals. In this research, we propose C-MOP (Cluster-based Momentum Optimized Prompting), a framework that stabilizes optimization via Boundary-Aware Contrastive Sampling (BACS) and Momentum-Guided Semantic Clustering (MGSC). Specifically, BACS utilizes batch-level information to mine tripartite features--Hard Negatives, Anchors, and Boundary Pairs--to precisely characterize the typical representation and decision boundaries of positive and negative prompt samples. To resolve semantic conflicts, MGSC introduces a textual momentum mechanism with temporal decay that distills persistent consensus from fluctuating gradients across iterations. Extensive experiments demonstrate that C-MOP consistently outperforms SOTA baselines like PromptWizard and ProTeGi, yielding average gains of 1.58% and 3.35%. Notably, C-MOP enables a general LLM with 3B activated parameters to surpass a 70B domain-specific dense LLM, highlighting its effectiveness in driving precise prompt evolution. The code is available at https://github.com/huawei-noah/noah-research/tree/master/C-MOP.

</details>


### [138] [The CLEF-2026 FinMMEval Lab: Multilingual and Multimodal Evaluation of Financial AI Systems](https://arxiv.org/abs/2602.10886)
*Zhuohan Xie,Rania Elbadry,Fan Zhang,Georgi Georgiev,Xueqing Peng,Lingfei Qian,Jimin Huang,Dimitar Dimitrov,Vanshikaa Jani,Yuyang Dai,Jiahui Geng,Yuxia Wang,Ivan Koychev,Veselin Stoyanov,Preslav Nakov*

Main category: cs.CL

TL;DR: FinMMEval Lab at CLEF 2026 提出了首个用于金融大语言模型的跨语言、多模态评估框架，包含三个任务：金融考试问答、多语言金融问答和金融决策，旨在促进通用、透明的全球化金融AI系统发展。


<details>
  <summary>Details</summary>
Motivation: 现有金融NLP基准测试在语言、模态和任务覆盖范围上存在局限性，无法全面评估金融大语言模型的性能，促使研究者开发一个更全面的评估框架。

Method: 提出了FinMMEval 2026，一个包含三个相互关联任务的跨语言、多模态评估框架：金融考试问答、多语言金融问答 (PolyFiQA) 和金融决策。这些任务旨在测试模型在不同语言和模态下的理解、推理和决策能力。

Result: FinMMEval 2026 提供了一个全面的评估套件，能够衡量模型在跨语言和多模态场景下的推理、泛化和行动能力。

Conclusion: FinMMEval 2026 填补了现有金融NLP基准测试的空白，通过提供跨语言、多模态的评估框架，将推动更强大、透明和全球化的金融AI系统发展，并公开了数据集和评估资源以支持可复现的研究。

Abstract: We present the setup and the tasks of the FinMMEval Lab at CLEF 2026, which introduces the first multilingual and multimodal evaluation framework for financial Large Language Models (LLMs). While recent advances in financial natural language processing have enabled automated analysis of market reports, regulatory documents, and investor communications, existing benchmarks remain largely monolingual, text-only, and limited to narrow subtasks. FinMMEval 2026 addresses this gap by offering three interconnected tasks that span financial understanding, reasoning, and decision-making: Financial Exam Question Answering, Multilingual Financial Question Answering (PolyFiQA), and Financial Decision Making. Together, these tasks provide a comprehensive evaluation suite that measures models' ability to reason, generalize, and act across diverse languages and modalities. The lab aims to promote the development of robust, transparent, and globally inclusive financial AI systems, with datasets and evaluation resources publicly released to support reproducible research.

</details>


### [139] [Diagnosing Structural Failures in LLM-Based Evidence Extraction for Meta-Analysis](https://arxiv.org/abs/2602.10881)
*Zhiyin Tan,Jennifer D'Souza*

Main category: cs.CL

TL;DR: 本研究提出了一种结构化评估框架，用于衡量大型语言模型（LLMs）在从科学文献中提取用于系统综述和荟萃分析的数据方面的能力。研究发现，尽管LLMs在单属性提取方面表现尚可，但在需要稳定关联变量、方法和效应量时，其性能会急剧下降，尤其是在多文档长上下文场景下，这使得当前LLMs无法满足自动化荟萃分析的要求。


<details>
  <summary>Details</summary>
Motivation: 系统综述和荟萃分析需要将叙述性文献转化为结构化的、具有数值依据的研究记录。尽管LLMs发展迅速，但其是否能满足这一过程的结构化要求（特别是跨文档的角色、方法和效应量归属的保存）尚不清楚。

Method: 研究提出了一种结构化、诊断性的评估框架，将LLM证据提取视为一系列约束模式的查询，并逐步增加关系和数值的复杂性。使用跨五个科学领域的、手动注释的语料库，以及统一的查询套件和评估协议，在单文档和长上下文多文档输入模式下评估了两个最先进的LLMs。

Result: 在所有领域和模型中，单属性查询的性能为中等水平，但当任务需要稳定绑定变量、角色、统计方法和效应量时，性能会急剧下降。完整的荟萃分析关联元组的提取可靠性接近于零，长上下文输入会进一步加剧这些失败。下游聚合放大了上游的细微错误，使得语料库级别的统计数据不可靠。

Conclusion: 当前LLMs在自动化荟萃分析方面存在不足，其局限性并非源于实体识别错误，而是系统性的结构性崩溃，包括角色逆转、跨分析绑定漂移、密集结果部分的实例压缩以及数值归因错误。这表明当前LLMs缺乏自动化荟萃分析所需的结构保真度、关系绑定和数值基础。

Abstract: Systematic reviews and meta-analyses rely on converting narrative articles into structured, numerically grounded study records. Despite rapid advances in large language models (LLMs), it remains unclear whether they can meet the structural requirements of this process, which hinge on preserving roles, methods, and effect-size attribution across documents rather than on recognizing isolated entities. We propose a structural, diagnostic framework that evaluates LLM-based evidence extraction as a progression of schema-constrained queries with increasing relational and numerical complexity, enabling precise identification of failure points beyond atom-level extraction. Using a manually curated corpus spanning five scientific domains, together with a unified query suite and evaluation protocol, we evaluate two state-of-the-art LLMs under both per-document and long-context, multi-document input regimes. Across domains and models, performance remains moderate for single-property queries but degrades sharply once tasks require stable binding between variables, roles, statistical methods, and effect sizes. Full meta-analytic association tuples are extracted with near-zero reliability, and long-context inputs further exacerbate these failures. Downstream aggregation amplifies even minor upstream errors, rendering corpus-level statistics unreliable. Our analysis shows that these limitations stem not from entity recognition errors, but from systematic structural breakdowns, including role reversals, cross-analysis binding drift, instance compression in dense result sections, and numeric misattribution, indicating that current LLMs lack the structural fidelity, relational binding, and numerical grounding required for automated meta-analysis. The code and data are publicly available at GitHub (https://github.com/zhiyintan/LLM-Meta-Analysis).

</details>


### [140] [Computational Phenomenology of Temporal Experience in Autism: Quantifying the Emotional and Narrative Characteristics of Lived Unpredictability](https://arxiv.org/abs/2602.10947)
*Kacper Dudzic,Karolina Drożdż,Maciej Wodziński,Anastazja Szuła,Marcin Moskalewicz*

Main category: cs.CL

TL;DR: 本研究结合现象学访谈和计算分析，发现自闭症个体在时间体验上的主要挑战源于生活经验中的不可预测性，而非叙事构建方式。


<details>
  <summary>Details</summary>
Motivation: 现有研究在自闭症的时间性障碍方面存在局限，包括模型偏见、样本量不足以及缺乏计算和现象学方法的结合。本研究旨在弥合这些差距。

Method: 研究结合了三种方法：1. 对自闭症个体进行结构化现象学访谈（使用时间体验跨诊断评估）；2. 对自闭症叙事语料库进行计算分析；3. 使用叙事流动度量重复一项计算研究，以评估自闭症自传的感知现象学真实性。

Result: 访谈显示，自闭症与对照组在体验的不可预测性方面存在显著差异。计算结果显示，自闭症叙事中的时间词汇带有更强的负面情绪，特别是“即时性与突然性”类别。与不可预测性相关的词语（如unpredictably, precipitously, abruptly）被识别为高度负面。计算分析发现，自闭症叙事在量化上更接近真实的自传体故事，而非虚构故事。

Conclusion: 自闭症个体在时间上的挑战主要与生活经验中的不可预测性有关，而不是其叙事建构方式本身的问题。研究支持了现象学和计算方法的结合可以为理解自闭症提供更深入的见解。

Abstract: Disturbances in temporality, such as desynchronization with the social environment and its unpredictability, are considered core features of autism with a deep impact on relationships. However, limitations regarding research on this issue include: 1) the dominance of deficit-based medical models of autism, 2) sample size in qualitative research, and 3) the lack of phenomenological anchoring in computational research. To bridge the gap between phenomenological and computational approaches and overcome sample-size limitations, our research integrated three methodologies. Study A: structured phenomenological interviews with autistic individuals using the Transdiagnostic Assessment of Temporal Experience. Study B: computational analysis of an autobiographical corpus of autistic narratives built for this purpose. Study C: a replication of a computational study using narrative flow measures to assess the perceived phenomenological authenticity of autistic autobiographies. Interviews revealed that the most significant differences between the autistic and control groups concerned unpredictability of experience. Computational results mirrored these findings: the temporal lexicon in autistic narratives was significantly more negatively valenced - particularly the "Immediacy & Suddenness" category. Outlier analysis identified terms associated with perceived discontinuity (unpredictably, precipitously, and abruptly) as highly negative. The computational analysis of narrative flow found that the autistic narratives contained within the corpus quantifiably resemble autobiographical stories more than imaginary ones. Overall, the temporal challenges experienced by autistic individuals were shown to primarily concern lived unpredictability and stem from the contents of lived experience, and not from autistic narrative construction.

</details>


### [141] [SoftMatcha 2: A Fast and Soft Pattern Matcher for Trillion-Scale Corpora](https://arxiv.org/abs/2602.10908)
*Masataka Yoneda,Yusuke Matsushita,Go Kamoda,Kohei Suenaga,Takuya Akiba,Masaki Waga,Sho Yokoi*

Main category: cs.CL

TL;DR: 提出了一种超快灵活的自然语言语料库（万亿级）搜索算法，能在 0.3 秒内处理语义变化（替换、插入、删除），并能发现训练语料库中的基准污染。


<details>
  <summary>Details</summary>
Motivation: 现有的搜索方法难以在万亿级语料库中快速处理包含语义变化的查询，并且在处理大规模数据时效率低下。

Method: 采用基于后缀数组的字符串匹配，结合盘式感知设计（用于快速精确查找）和语料库感知动态剪枝，以减轻查询语义放松带来的组合爆炸问题。利用自然语言的统计特性，理论上证明该方法可以抑制搜索空间相对于查询长度的指数增长。

Result: 在 1.4T 词元的 FineWeb-Edu 数据集上，实验表明该方法搜索延迟显著低于 infini-gram、infini-gram mini 和 SoftMatcha。此外，该方法能够识别现有方法未能发现的训练语料库中的基准污染。

Conclusion: 所提出的算法在处理大规模自然语言语料库的语义搜索方面具有显著的速度优势和灵活性，能够有效识别数据污染，并已成功应用于多语言数据搜索。

Abstract: We present an ultra-fast and flexible search algorithm that enables search over trillion-scale natural language corpora in under 0.3 seconds while handling semantic variations (substitution, insertion, and deletion). Our approach employs string matching based on suffix arrays that scales well with corpus size. To mitigate the combinatorial explosion induced by the semantic relaxation of queries, our method is built on two key algorithmic ideas: fast exact lookup enabled by a disk-aware design, and dynamic corpus-aware pruning. We theoretically show that the proposed method suppresses exponential growth in the search space with respect to query length by leveraging statistical properties of natural language. In experiments on FineWeb-Edu (Lozhkov et al., 2024) (1.4T tokens), we show that our method achieves significantly lower search latency than existing methods: infini-gram (Liu et al., 2024), infini-gram mini (Xu et al., 2025), and SoftMatcha (Deguchi et al., 2025). As a practical application, we demonstrate that our method identifies benchmark contamination in training corpora, unidentified by existing approaches. We also provide an online demo of fast, soft search across corpora in seven languages.

</details>


### [142] [Search or Accelerate: Confidence-Switched Position Beam Search for Diffusion Language Models](https://arxiv.org/abs/2602.10953)
*Mingyu Cao,Alvaro Correia,Christos Louizos,Shiwei Liu,Lu Yin*

Main category: cs.CL

TL;DR: 提出了一种名为SOAR的训练无关的解码算法，用于扩散语言模型（DLMs），它通过适应模型的不确定性来改进文本生成质量，同时保持推理速度。


<details>
  <summary>Details</summary>
Motivation: 标准的贪婪解码方法在处理需要推理的任务时，可能会因为局部最优的选择而陷入次优的解码顺序，影响生成质量。

Method: SOAR算法在低置信度时拓宽搜索范围以避免过早决策，在高置信度时则并行解码以减少迭代次数。该算法是训练无关的，并且能自适应地调整其行为。

Result: 在GSM8K、MBPP和HumanEval等数学推理和代码生成基准测试中，SOAR在Dream-7B和LLaDA-8B模型上均提高了生成质量，并且推理速度具有竞争力。

Conclusion: SOAR是一种有效的DLM解码策略，它通过自适应地处理模型的不确定性，在文本生成质量和推理效率之间取得了良好的平衡，为DLM的实际应用提供了一种实用方法。

Abstract: Diffusion Language Models (DLMs) generate text by iteratively denoising a masked sequence, repeatedly deciding which positions to commit at each step. Standard decoding follows a greedy rule: unmask the most confident positions, yet this local choice can lock the model into a suboptimal unmasking order, especially on reasoning-heavy prompts. We present SOAR, a training-free decoding algorithm that adapts its behavior to the model's uncertainty. When confidence is low, SOAR briefly widens the search over alternative unmasking decisions to avoid premature commitments; when confidence is high, it collapses the search and decodes many positions in parallel to reduce the number of denoising iterations. Across mathematical reasoning and code generation benchmarks (GSM8K, MBPP, HumanEval) on Dream-7B and LLaDA-8B, SOAR improves generation quality while maintaining competitive inference speed, offering a practical way to balance quality and efficiency in DLM decoding.

</details>


### [143] [LoRA-Squeeze: Simple and Effective Post-Tuning and In-Tuning Compression of LoRA Modules](https://arxiv.org/abs/2602.10993)
*Ivan Vulić,Adam Grycner,Quentin de Laroussilhe,Jonas Pfeiffer*

Main category: cs.CL

TL;DR: LoRA-Squeeze 是一种参数高效微调（PEFT）的新方法，它通过先学习高秩 LoRA 更新，然后将其压缩到低秩来实现，实验证明这种方法在文本和视觉-语言任务上通常优于直接学习低秩 LoRA。


<details>
  <summary>Details</summary>
Motivation: 现有的 LoRA 方法在选择最优秩和超参数方面存在挑战，并且异构秩模块的部署复杂。作者提出了一种改进方法，即先学习一个高秩解再进行压缩。

Method: LoRA-Squeeze 方法首先使用较高秩进行微调，然后通过近似重建或直接重建完整的权重更新矩阵，最后使用随机奇异值分解（RSVD）将其压缩到目标低秩。

Result: 在 13 个文本和 10 个视觉-语言任务上的实验表明，事后压缩得到的低秩适配器通常优于直接以目标秩训练的适配器。一种逐步进行的“秩退火”变体在 LoRA 大小-性能权衡方面表现最佳。

Conclusion: LoRA-Squeeze 提供了一种简单有效的方法来优化 LoRA 的秩选择，通过先学习高秩再压缩，可以获得更好的性能和更优的秩-性能平衡。

Abstract: Despite its huge number of variants, standard Low-Rank Adaptation (LoRA) is still a dominant technique for parameter-efficient fine-tuning (PEFT). Nonetheless, it faces persistent challenges, including the pre-selection of an optimal rank and rank-specific hyper-parameters, as well as the deployment complexity of heterogeneous-rank modules and more sophisticated LoRA derivatives. In this work, we introduce LoRA-Squeeze, a simple and efficient methodology that aims to improve standard LoRA learning by changing LoRA module ranks either post-hoc or dynamically during training}. Our approach posits that it is better to first learn an expressive, higher-rank solution and then compress it, rather than learning a constrained, low-rank solution directly. The method involves fine-tuning with a deliberately high(er) source rank, reconstructing or efficiently approximating the reconstruction of the full weight update matrix, and then using Randomized Singular Value Decomposition (RSVD) to create a new, compressed LoRA module at a lower target rank. Extensive experiments across 13 text and 10 vision-language tasks show that post-hoc compression often produces lower-rank adapters that outperform those trained directly at the target rank, especially if a small number of fine-tuning steps at the target rank is allowed. Moreover, a gradual, in-tuning rank annealing variant of LoRA-Squeeze consistently achieves the best LoRA size-performance trade-off.

</details>


### [144] [Language Model Inversion through End-to-End Differentiation](https://arxiv.org/abs/2602.11044)
*Kevin Yandoka Denamganaï,Kartic Subr*

Main category: cs.CL

TL;DR: 本研究提出了一种基于梯度优化的方法，通过将语言模型视为作用于 token 分布序列的函数，实现了对给定语言模型的反向推理，以找到生成特定目标输出的输入 prompt。


<details>
  <summary>Details</summary>
Motivation: 尽管语言模型的研究不断涌现，但关于如何确定生成特定输出的输入 prompt 的研究却很少，这是一个尚未解决的问题。

Method: 研究人员将语言模型反向推理问题形式化为经典的梯度优化问题。他们提出了一种使给定（固定的）语言模型端到端可微分的算法，然后利用梯度下降法寻找优化的 prompt。核心思想是将语言模型视为作用于 token 分布序列的函数，而非传统的 token 序列。

Result: 实验和消融研究表明，使用 DLM（梯度优化的语言模型）驱动的反向推理方法，能够可靠且高效地优化长度为 10 和 80 的 prompt，以生成长度为 20 的目标序列，适用于多种开箱即用的白盒语言模型。

Conclusion: 本研究成功地提出了一种基于梯度优化的方法，能够有效地解决语言模型反向推理问题，即找到生成特定输出的输入 prompt。

Abstract: Despite emerging research on Language Models (LM), few approaches analyse the invertibility of LMs. That is, given a LM and a desirable target output sequence of tokens, determining what input prompts would yield the target output remains an open problem. We formulate this problem as a classical gradient-based optimisation. First, we propose a simple algorithm to achieve end-to-end differentiability of a given (frozen) LM and then find optimised prompts via gradient descent. Our central insight is to view LMs as functions operating on sequences of distributions over tokens (rather than the traditional view as functions on sequences of tokens). Our experiments and ablations demonstrate that our DLM-powered inversion can reliably and efficiently optimise prompts of lengths $10$ and $80$ for targets of length $20$, for several white-box LMs (out-of-the-box).

</details>


### [145] [Linguistic Indicators of Early Cognitive Decline in the DementiaBank Pitt Corpus: A Statistical and Machine Learning Study](https://arxiv.org/abs/2602.11028)
*Artsvik Avetisyan,Sachin Kumar*

Main category: cs.CL

TL;DR: 本研究使用三种语言学特征（原始文本、词性增强文本、仅词性文本）分析了痴呆症患者的语言，发现即使没有词汇内容，句法和语法特征也能有效地识别早期认知衰退。研究结果支持使用可解释的机器学习方法和语言学特征进行透明可靠的认知筛查。


<details>
  <summary>Details</summary>
Motivation: 寻找早期认知衰退的语言学指标，以支持透明且有临床依据的筛查方法，因为自发语言的细微变化是认知衰退的早期迹象。

Method: 使用 DementiaBank Pitt Corpus 的自发语言转录本，分析了三种语言学表示：原始文本、词性（POS）增强表示和仅 POS 的句法表示。评估了逻辑回归和随机森林模型，采用两种协议：转录本级别和受试者级别交叉验证。使用全局特征重要性检验模型的可解释性，并使用 Mann-Whitney U 检验进行统计验证。

Result: 在所有表示方法中，模型都达到了稳定的性能。句法和语法特征即使在没有词汇内容的情况下也保留了很强的区分能力。受试者级别评估产生了更保守但一致的结果，尤其是在 POS 增强和仅 POS 表示方面。统计分析显示，功能词使用、词汇多样性、句子结构和话语连贯性在不同组别之间存在显著差异，这与机器学习的特征重要性发现非常吻合。

Conclusion: 研究结果表明，抽象的语言学特征能够捕捉到早期认知衰退的稳健标记，并且在临床现实的评估下表现良好。通过结合可解释的机器学习和非参数统计验证，本研究支持使用基于语言学的特征来进行透明可靠的语言认知筛查。

Abstract: Background: Subtle changes in spontaneous language production are among the earliest indicators of cognitive decline. Identifying linguistically interpretable markers of dementia can support transparent and clinically grounded screening approaches.
  Methods: This study analyzes spontaneous speech transcripts from the DementiaBank Pitt Corpus using three linguistic representations: raw cleaned text, a part-of-speech (POS)-enhanced representation combining lexical and grammatical information, and a POS-only syntactic representation. Logistic regression and random forest models were evaluated under two protocols: transcript-level train-test splits and subject-level five-fold cross-validation to prevent speaker overlap. Model interpretability was examined using global feature importance, and statistical validation was conducted using Mann-Whitney U tests with Cliff's delta effect sizes.
  Results: Across representations, models achieved stable performance, with syntactic and grammatical features retaining strong discriminative power even in the absence of lexical content. Subject-level evaluation yielded more conservative but consistent results, particularly for POS-enhanced and POS-only representations. Statistical analysis revealed significant group differences in functional word usage, lexical diversity, sentence structure, and discourse coherence, aligning closely with machine learning feature importance findings.
  Conclusion: The results demonstrate that abstract linguistic features capture robust markers of early cognitive decline under clinically realistic evaluation. By combining interpretable machine learning with non-parametric statistical validation, this study supports the use of linguistically grounded features for transparent and reliable language-based cognitive screening.

</details>


### [146] [Embedding Inversion via Conditional Masked Diffusion Language Models](https://arxiv.org/abs/2602.11047)
*Han Xiao*

Main category: cs.CL

TL;DR: 该研究提出了一种新的嵌入反演方法，将其视为条件掩码扩散模型，能够并行恢复所有 token，并且只需要少量模型前向传播即可达到高准确率。


<details>
  <summary>Details</summary>
Motivation: 现有嵌入反演方法通常是顺序生成（自回归），效率低下，并且可能需要访问目标编码器。研究动机是开发一种更高效、更灵活的嵌入反演方法。

Method: 将嵌入反演问题建模为条件掩码扩散模型。使用自适应层归一化将目标嵌入作为条件，通过迭代去噪并行恢复所有 token，而不是顺序生成。模型参数量为 78M。

Result: 在 32 个 token 的序列上，针对三种不同的嵌入模型，该方法实现了 81.3% 的 token 准确率和 0.87 的余弦相似度。整个过程只需要 8 次模型前向传播。

Conclusion: 该方法是一种高效且有效的嵌入反演技术，能够并行生成所有 token，并且无需访问目标编码器，在多项指标上表现优异。

Abstract: We frame embedding inversion as conditional masked diffusion, recovering all tokens in parallel through iterative denoising rather than sequential autoregressive generation. A masked diffusion language model is conditioned on the target embedding via adaptive layer normalization, requiring only 8 forward passes through a 78M parameter model with no access to the target encoder. On 32-token sequences across three embedding models, the method achieves 81.3% token accuracy and 0.87 cosine similarity.

</details>


### [147] [Conversational Behavior Modeling Foundation Model With Multi-Level Perception](https://arxiv.org/abs/2602.11065)
*Dingkun Zhou,Shuchang Pan,Jiachen Lian,Siddharth Banerjee,Sarika Pasumarthy,Dhruv Hebbar,Siddhant Patel,Zeyi Austin Li,Kan Jen Cheng,Sanay Bordia,Krish Patel,Akshaj Gupta,Tingle Li,Gopala Anumanchipalli*

Main category: cs.CL

TL;DR: 本文提出了一种基于多层感知和图思维（GoT）框架来模拟和预测对话中的思维链和言语行为的方法，并构建了一个高质量数据集进行训练和评估。


<details>
  <summary>Details</summary>
Motivation: 为了构建更自然的双工交互系统，需要捕捉人类对话中隐含的思维链，这种思维链通过有时限的言语行为体现出来。

Method: 该框架将对话过程建模为多层感知，并利用图思维（GoT）进行推理。它通过分层标注方案形式化了意图到行动的路径，预测高层沟通意图和低层言语行为，以学习它们之间的因果和时间依赖性。使用高质量的、包含可控事件的对话数据及其人工标注标签来训练系统。GoT框架将流式预测组织成一个不断发展的图，使Transformer能够预测下一个言语行为，生成决策的简洁理由，并动态地完善其推理过程。

Result: 在合成和真实双工对话的实验表明，该框架能够实现稳健的行为检测，产生可解释的推理链，并为双工口语对话系统的会话推理提供基准。

Conclusion: 所提出的多层感知和图思维框架能够有效地模拟对话中的思维链和言语行为，并为构建更智能、更具可解释性的双工对话系统奠定了基础。

Abstract: Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this perceptual pathway is key to building natural full-duplex interactive systems. We introduce a framework that models this process as multi-level perception, and then reasons over conversational behaviors via a Graph-of-Thoughts (GoT). Our approach formalizes the intent-to-action pathway with a hierarchical labeling scheme, predicting high-level communicative intents and low-level speech acts to learn their causal and temporal dependencies. To train this system, we develop a high quality corpus that pairs controllable, event-rich dialogue data with human-annotated labels. The GoT framework structures streaming predictions as an evolving graph, enabling a transformer to forecast the next speech act, generate concise justifications for its decisions, and dynamically refine its reasoning. Experiments on both synthetic and real duplex dialogues show that the framework delivers robust behavior detection, produces interpretable reasoning chains, and establishes a foundation for benchmarking conversational reasoning in full duplex spoken dialogue systems.

</details>


### [148] [Simultaneous Speech-to-Speech Translation Without Aligned Data](https://arxiv.org/abs/2602.11072)
*Tom Labiausse,Romain Fabre,Yannick Estève,Alexandre Défossez,Neil Zeghidour*

Main category: cs.CL

TL;DR: Hibiki-Zero 是一种新的同步语音翻译模型，它无需词级对齐即可进行训练，从而简化了流程并提高了可扩展性，并在翻译准确性、延迟、语音转移和自然度方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的同步语音翻译方法需要难以大规模收集的词级对齐数据。本文旨在消除对词级对齐的需求，从而简化训练流程，提高模型对不同语言的可扩展性。

Method: Hibiki-Zero 首先在句子级对齐数据上进行训练，以学习高延迟的语音翻译，然后采用一种新的使用 GRPO 的强化学习策略来优化延迟，同时保持翻译质量。

Result: Hibiki-Zero 在翻译准确性、延迟、语音转移和自然度方面取得了最先进的性能。该模型还可以适应支持一种新输入语言，只需不到 1000 小时的语音。

Conclusion: Hibiki-Zero 成功地消除了对词级对齐数据的需求，简化了同步语音翻译的训练流程，并提高了模型的性能和可扩展性。该模型在多种任务中都表现出色，并具有适应新语言的能力。

Abstract: Simultaneous speech translation requires translating source speech into a target language in real-time while handling non-monotonic word dependencies. Traditional approaches rely on supervised training with word-level aligned data, which is difficult to collect at scale and thus depends on synthetic alignments using language-specific heuristics that are suboptimal. We propose Hibiki-Zero, which eliminates the need for word-level alignments entirely. This fundamentally simplifies the training pipeline and enables seamless scaling to diverse languages with varying grammatical structures, removing the bottleneck of designing language-specific alignment heuristics. We first train on sentence-level aligned data to learn speech translation at high latency, then apply a novel reinforcement learning strategy using GRPO to optimize latency while preserving translation quality. Hibiki-Zero achieves state-of-the-art performance in translation accuracy, latency, voice transfer, and naturalness across five X-to-English tasks. Moreover, we demonstrate that our model can be adapted to support a new input language with less than 1000h of speech. We provide examples, model weights, inference code and we release a benchmark containing 45h of multilingual data for speech translation evaluation.

</details>


### [149] [DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning](https://arxiv.org/abs/2602.11089)
*Yicheng Chen,Zerun Ma,Xinchen Xie,Yining Li,Kai Chen*

Main category: cs.CL

TL;DR: 该研究提出了一种名为 DataChef-32B 的自动化方法，用于生成 LLM 的数据处理流程（data recipe），使其能够适应特定任务，并在多项测试中达到了与人类专家相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 训练数据处理流程（data recipe）设计高度依赖人工，耗时耗力且需要大量专业知识。为了自动化这一过程，研究旨在开发一种端到端的数据配方生成方法。

Method: 研究者提出了端到端数据配方生成（end-to-end data recipe generation）的概念。他们构建了一个名为 DataChef-32B 的模型，该模型通过在线强化学习，利用预测下游性能的代理奖励来选择最优的数据配方。

Result: 在六个独立的任务上，DataChef-32B 生成的数据配方达到了与人类专家精心设计的配方相当的下游性能。特别地，一个由 DataChef-32B 生成的配方使 Qwen3-1.7B-Base 模型在数学领域表现出色，在 AIME'25 任务上得分达到 66.7，超越了原始模型。

Conclusion: 研究成功地展示了通过自动化方法生成 LLM 训练数据配方的可行性，并提出了 DataChef-32B 模型。这项工作为 LLM 训练的自动化和自适应 AI 系统的发展开辟了新途径。

Abstract: In the current landscape of Large Language Models (LLMs), the curation of large-scale, high-quality training data is a primary driver of model performance. A key lever is the \emph{data recipe}, which comprises a data processing pipeline to transform raw sources into training corpora. Despite the growing use of LLMs to automate individual data processing steps, such as data synthesis and filtering, the overall design of data recipes remains largely manual and labor-intensive, requiring substantial human expertise and iteration. To bridge this gap, we formulate \emph{end-to-end data recipe generation} for LLM adaptation. Given a target benchmark and a pool of available data sources, a model is required to output a complete data recipe that adapts a base LLM to the target task. We present DataChef-32B, which performs online reinforcement learning using a proxy reward that predicts downstream performance for candidate recipes. Across six held-out tasks, DataChef-32B produces practical recipes that reach comparable downstream performance to those curated by human experts. Notably, the recipe from DataChef-32B adapts Qwen3-1.7B-Base to the math domain, achieving 66.7 on AIME'25 and surpassing Qwen3-1.7B. This work sheds new light on automating LLM training and developing self-evolving AI systems.

</details>


### [150] [Safety Recovery in Reasoning Models Is Only a Few Early Steering Steps Away](https://arxiv.org/abs/2602.11096)
*Soumya Suvra Ghosal,Souradip Chakraborty,Vaibhav Singh,Furong Huang,Dinesh Manocha,Amrit Singh Bedi*

Main category: cs.CL

TL;DR: SafeThink 是一种轻量级的推理时防御方法，通过在推理过程中监测安全性和条件性地注入纠正性前缀来解决强化学习驱动的多模态大模型（MLRMs）的推理能力提升所带来的安全对齐下降和越狱成功率增加的问题。它能够显著降低越狱成功率，同时保持推理性能，并且发现安全恢复通常只需在推理早期进行少量干预。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）驱动的显式链式思考（Chain-of-Thought）后训练虽然提高了多模态大模型（MLRMs）的推理能力，但却会降低安全对齐并增加越狱成功率。因此，需要一种方法来恢复和增强MLRMs的安全对齐。

Method: SafeThink 是一种轻量级的推理时防御方法。它将安全恢复视为一个满足性约束而非最大化目标。SafeThink 使用一个安全奖励模型来监测不断演变的推理过程，并在安全阈值被违反时，有条件地注入一个优化的简短纠正性前缀（“Wait, think safely”）。

Result: 在六个开源 MLRMs 和四个越狱基准测试（JailbreakV-28K, Hades, FigStep, 和 MM-SafetyBench）上的评估显示，SafeThink 将攻击成功率降低了 30-60%（例如，在 JailbreakV-28K 上 LlamaV-o1 的成功率从 63.33% 降至 5.74%，在 Hades 上 R1-Onevision 的成功率从 69.07% 降至 5.65%）。同时，它保持了推理性能（MathVista 准确率从 65.20% 降至 65.00%）。一个关键的实证发现是，安全恢复通常只需要在推理的最初 1-3 步进行干预。

Conclusion: SafeThink 是一种有效的推理时防御机制，能够解决强化学习驱动的 MLRMs 在提升推理能力的同时出现的安全对齐下降问题。它通过在必要时进行条件性干预，成功地降低了越狱攻击的成功率，并且对模型的推理性能影响很小。研究表明，及早干预是实现安全恢复的关键。

Abstract: Reinforcement learning (RL) based post-training for explicit chain-of-thought (e.g., GRPO) improves the reasoning ability of multimodal large-scale reasoning models (MLRMs). But recent evidence shows that it can simultaneously degrade safety alignment and increase jailbreak success rates. We propose SafeThink, a lightweight inference-time defense that treats safety recovery as a satisficing constraint rather than a maximization objective. SafeThink monitors the evolving reasoning trace with a safety reward model and conditionally injects an optimized short corrective prefix ("Wait, think safely") only when the safety threshold is violated. In our evaluations across six open-source MLRMs and four jailbreak benchmarks (JailbreakV-28K, Hades, FigStep, and MM-SafetyBench), SafeThink reduces attack success rates by 30-60% (e.g., LlamaV-o1: 63.33% to 5.74% on JailbreakV-28K, R1-Onevision: 69.07% to 5.65% on Hades) while preserving reasoning performance (MathVista accuracy: 65.20% to 65.00%). A key empirical finding from our experiments is that safety recovery is often only a few steering steps away: intervening in the first 1-3 reasoning steps typically suffices to redirect the full generation toward safe completions.

</details>


### [151] [Can Large Language Models Make Everyone Happy?](https://arxiv.org/abs/2602.11091)
*Usman Naseem,Gautam Siddharth Kashyap,Ebad Shabbir,Sushant Kumar Ray,Abdullah Mohammad,Rafiq Ali*

Main category: cs.CL

TL;DR: 该研究提出了一个名为MisAlign-Profile的新基准，用于衡量大型语言模型（LLMs）在安全、价值和文化维度上的失调权衡，并构建了一个包含112个规范领域（包括安全、价值和文化）的MISALIGNTRADE数据集，对现有LLMs进行了评估，发现普遍存在12%-34%的失调权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM评估基准通常孤立地评估安全、价值和文化维度，无法充分捕捉这些维度之间的相互作用和权衡。尽管有机械可解释性方法，但仍不足以系统地表征跨维度权衡。因此，需要一个统一的基准来衡量LLMs在多维度上的失调权衡。

Method: 研究人员构建了一个名为MISALIGNTRADE的数据集，该数据集包含112个规范领域的英文提示，涵盖安全、价值和文化维度。每个提示被分类为对象、属性或关系失调。研究人员利用Gemma-2-9B-it和Qwen3-30B-A3B-Instruct-2507模型，通过两阶段拒绝采样生成了失调和对齐的响应对。随后，他们在通用LLMs、微调LLMs和开源权重LLMs上对MISALIGNTRADE进行了基准测试。

Result: 对通用LLMs、微调LLMs和开源权重LLMs的基准测试揭示了在安全、价值和文化维度之间存在12%-34%的失调权衡。

Conclusion: MisAlign-Profile基准和MISALIGNTRADE数据集能够有效地衡量LLMs在安全、价值和文化维度上的失调权衡。研究结果表明，当前的LLMs在这些维度之间普遍存在权衡问题，这为未来的LLM对齐研究提供了重要方向。

Abstract: Misalignment in Large Language Models (LLMs) refers to the failure to simultaneously satisfy safety, value, and cultural dimensions, leading to behaviors that diverge from human expectations in real-world settings where these dimensions must co-occur. Existing benchmarks, such as SAFETUNEBED (safety-centric), VALUEBENCH (value-centric), and WORLDVIEW-BENCH (culture-centric), primarily evaluate these dimensions in isolation and therefore provide limited insight into their interactions and trade-offs. More recent efforts, including MIB and INTERPRETABILITY BENCHMARK-based on mechanistic interpretability, offer valuable perspectives on model failures; however, they remain insufficient for systematically characterizing cross-dimensional trade-offs. To address these gaps, we introduce MisAlign-Profile, a unified benchmark for measuring misalignment trade-offs inspired by mechanistic profiling. First, we construct MISALIGNTRADE, an English misaligned-aligned dataset across 112 normative domains taxonomies, including 14 safety, 56 value, and 42 cultural domains. In addition to domain labels, each prompt is classified with one of three orthogonal semantic types-object, attribute, or relations misalignment-using Gemma-2-9B-it and expanded via Qwen3-30B-A3B-Instruct-2507 with SimHash-based fingerprinting to avoid deduplication. Each prompt is paired with misaligned and aligned responses through two-stage rejection sampling to ensure quality. Second, we benchmark general-purpose, fine-tuned, and open-weight LLMs on MISALIGNTRADE-revealing 12%-34% misalignment trade-offs across dimensions.

</details>


### [152] [SteuerLLM: Local specialized large language model for German tax law analysis](https://arxiv.org/abs/2602.11081)
*Sebastian Wind,Jeta Sopa,Laurin Schmid,Quirin Jackl,Sebastian Kiefer,Fei Wu,Martin Mayr,Harald Köstler,Gerhard Wellein,Andreas Maier,Soroosh Tayebi Arasteh*

Main category: cs.CL

TL;DR: 本研究提出了 SteuerEx，一个用于评估大型语言模型（LLM）在德国税法领域表现的基准测试，并开发了 SteuerLLM，一个在此领域表现优于通用模型的领域适应性 LLM。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在遵循严格的正式规则、专业术语和法律结构（如税法）方面表现不佳。研究旨在解决这一问题，并为评估和改进 LLM 在法律领域的性能提供一个基准。

Method: 研究者创建了一个名为 SteuerEx 的基准测试，包含 115 道经专家验证的真实德国大学税法考试题目，覆盖六个核心税法领域。此外，他们还开发了一个名为 SteuerLLM 的领域适应性 LLM，该模型在一个大规模合成数据集上进行训练，该数据集是通过受控的检索增强管道从真实考试材料中生成的。

Result: SteuerLLM（280 亿参数）在 SteuerEx 基准测试上持续优于同等规模的通用指令微调模型，甚至在某些情况下优于更大规模的模型。研究表明，领域特定的数据和架构适应比参数规模更能决定模型在真实法律推理任务上的表现。

Conclusion: 领域特定的数据和架构适应对于提高 LLM 在德国税法等具有严格规则的法律领域的表现至关重要，比模型规模更为关键。本研究公开发布了所有基准数据、训练数据集、模型权重和评估代码，以支持可复现的领域特定法律人工智能研究。

Abstract: Large language models (LLMs) demonstrate strong general reasoning and language understanding, yet their performance degrades in domains governed by strict formal rules, precise terminology, and legally binding structure. Tax law exemplifies these challenges, as correct answers require exact statutory citation, structured legal argumentation, and numerical accuracy under rigid grading schemes. We algorithmically generate SteuerEx, the first open benchmark derived from authentic German university tax law examinations. SteuerEx comprises 115 expert-validated examination questions spanning six core tax law domains and multiple academic levels, and employs a statement-level, partial-credit evaluation framework that closely mirrors real examination practice. We further present SteuerLLM, a domain-adapted LLM for German tax law trained on a large-scale synthetic dataset generated from authentic examination material using a controlled retrieval-augmented pipeline. SteuerLLM (28B parameters) consistently outperforms general-purpose instruction-tuned models of comparable size and, in several cases, substantially larger systems, demonstrating that domain-specific data and architectural adaptation are more decisive than parameter scale for performance on realistic legal reasoning tasks. All benchmark data, training datasets, model weights, and evaluation code are released openly to support reproducible research in domain-specific legal artificial intelligence. A web-based demo of SteuerLLM is available at https://steuerllm.i5.ai.fau.de.

</details>


### [153] [TEGRA: Text Encoding With Graph and Retrieval Augmentation for Misinformation Detection](https://arxiv.org/abs/2602.11106)
*Géraud Faye,Wassila Ouerdane,Guillaume Gadek,Céline Hudelot*

Main category: cs.CL

TL;DR: 提出了一种名为TEG的新方法，通过将文本表示为图结构并结合文本和图信息来改进错误信息检测。TEGRA是TEG的扩展，加入了领域知识，进一步提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高错误信息检测的性能，借鉴人工事实核查的思路，引入外部知识。现有的基于语言模型的方法在融合外部知识方面存在不足。

Method: 提出TEG（Text Encoding with Graph）方法，将文档表示为图结构，并编码文本和图信息用于分类。在此基础上，提出TEGRA（TEG with domain-specific knowledge），集成了领域知识。

Result: TEG方法在错误信息检测任务上优于单独使用语言模型。TEGRA在大多数情况下进一步提高了分类准确性。

Conclusion: 将文本表示为图结构并结合文本和图信息是改进错误信息检测的有效方法，而集成领域知识可以进一步提升性能。

Abstract: Misinformation detection is a critical task that can benefit significantly from the integration of external knowledge, much like manual fact-checking. In this work, we propose a novel method for representing textual documents that facilitates the incorporation of information from a knowledge base. Our approach, Text Encoding with Graph (TEG), processes documents by extracting structured information in the form of a graph and encoding both the text and the graph for classification purposes. Through extensive experiments, we demonstrate that this hybrid representation enhances misinformation detection performance compared to using language models alone. Furthermore, we introduce TEGRA, an extension of our framework that integrates domain-specific knowledge, further enhancing classification accuracy in most cases.

</details>


### [154] [Data Repetition Beats Data Scaling in Long-CoT Supervised Fine-Tuning](https://arxiv.org/abs/2602.11149)
*Dawid J. Kopiczko,Sagar Vaze,Tijmen Blankevoort,Yuki M. Asano*

Main category: cs.CL

TL;DR: 在推理语言模型的监督微调（SFT）中，我们发现与增大训练数据集相比，通过增加训练轮次（epochs）来重复训练小数据集能带来更好的泛化能力，即使达到完全记忆（memorization）。


<details>
  <summary>Details</summary>
Motivation: 研究人员观察到，在推理语言模型的SFT中，增加训练数据量是普遍的经验，但他们推测重复训练可能带来意想不到的好处，并希望找到一种更有效率的SFT方法。

Method: 通过在AIME'24/25和GPQA基准上，对比在固定更新预算下，多次训练小数据集与单次训练大数据集的效果，并使用训练Token准确率作为判断训练饱和度的指标。

Result: 在AIME'24/25和GPQA基准上，使用128个epoch在400个样本上训练的Olmo3-7B模型，比使用1个epoch在51200个样本上训练的模型，在准确率上高出12-26个百分点，且没有出现灾难性遗忘。训练Token准确率在达到完全记忆时出现平台期，与泛化能力的提升一致。

Conclusion: 在推理SFT中，通过增加训练轮次并以训练Token准确率作为停止标准，可以替代昂贵的数据集扩增。研究提出了“重复优势”（repetition advantage）现象，即完全记忆与泛化能力提升同时发生，并将其作为一个新的开放问题留给社区研究LLM的训练动态。

Abstract: Supervised fine-tuning (SFT) on chain-of-thought data is an essential post-training step for reasoning language models. Standard machine learning intuition suggests that training with more unique training samples yields better generalization. Counterintuitively, we show that SFT benefits from repetition: under a fixed update budget, training for more epochs on smaller datasets outperforms single-epoch training on larger datasets. On AIME'24/25 and GPQA benchmarks, Olmo3-7B trained for 128 epochs on 400 samples outperforms the equivalent 1 epoch on 51200 samples by 12-26 percentage points, with no additional catastrophic forgetting. We find that training token accuracy reliably signals when repetition has saturated; improvements from additional epochs plateau at full memorization, a pattern consistent across all settings. These findings provide a practical approach for reasoning SFT, where scaling epochs with token accuracy as a stopping criterion can replace expensive undirected data scaling. We pose the repetition advantage, where full memorization coincides with improved generalization, as a new open problem for the community in understanding the training dynamics of large language models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [155] [Adaptive Time Step Flow Matching for Autonomous Driving Motion Planning](https://arxiv.org/abs/2602.10285)
*Ananya Trivedi,Anjian Li,Mohamed Elnoor,Yusuf Umut Ciftci,Avinash Singh,Jovin D'sa,Sangjae Bae,David Isele,Taskin Padir,Faizan M. Tariq*

Main category: cs.RO

TL;DR: 提出了一种基于条件流匹配的框架，用于实时预测周围代理的未来运动并规划自车轨迹，通过轻量级方差估计器在线选择推理步数，并引入凸二次规划后处理以提高平顺性，在 Waymo 开放运动数据集上进行了训练，能够在 20 Hz 的更新率下运行。


<details>
  <summary>Details</summary>
Motivation: 当前的模仿学习方法在推理时延迟较高，难以满足自动驾驶的实时性要求。现有的优化方法（如一致性模型）需要昂贵的重新训练来适应不同场景的动作分布。因此，需要一种能够实时运行、适应性强且能生成高质量轨迹的方法。

Method: 该框架基于条件流匹配，联合预测周围代理的未来运动并规划自车轨迹。引入一个轻量级的方差估计器，用于在线选择推理步数，从而无需重新训练即可平衡运行时长和模仿学习性能。此外，还引入了一个基于凸二次规划的轨迹后处理步骤，以提高行驶质量，该步骤计算开销极小。

Result: 在 Waymo 开放运动数据集上训练后，该框架能够执行车道变换、巡航控制和无保护左转等机动，无需场景特定调整。在 NVIDIA RTX 3070 GPU 上实现了 20 Hz 的更新率。与 Transformer、Diffusion 和 Consistency Model 基线相比，在轨迹平滑度和对动态约束的遵守方面表现更优。

Conclusion: 所提出的基于条件流匹配的框架能够实时、高效地规划自车轨迹，并能处理复杂的交通场景，同时保持良好的行驶质量，适用于在线部署。

Abstract: Autonomous driving requires reasoning about interactions with surrounding traffic. A prevailing approach is large-scale imitation learning on expert driving datasets, aimed at generalizing across diverse real-world scenarios. For online trajectory generation, such methods must operate at real-time rates. Diffusion models require hundreds of denoising steps at inference, resulting in high latency. Consistency models mitigate this issue but rely on carefully tuned noise schedules to capture the multimodal action distributions common in autonomous driving. Adapting the schedule, typically requires expensive retraining. To address these limitations, we propose a framework based on conditional flow matching that jointly predicts future motions of surrounding agents and plans the ego trajectory in real time. We train a lightweight variance estimator that selects the number of inference steps online, removing the need for retraining to balance runtime and imitation learning performance. To further enhance ride quality, we introduce a trajectory post-processing step cast as a convex quadratic program, with negligible computational overhead. Trained on the Waymo Open Motion Dataset, the framework performs maneuvers such as lane changes, cruise control, and navigating unprotected left turns without requiring scenario-specific tuning. Our method maintains a 20 Hz update rate on an NVIDIA RTX 3070 GPU, making it suitable for online deployment. Compared to transformer, diffusion, and consistency model baselines, we achieve improved trajectory smoothness and better adherence to dynamic constraints. Experiment videos and code implementations can be found at https://flow-matching-self-driving.github.io/.

</details>


### [156] [A Human-in-the-Loop Confidence-Aware Failure Recovery Framework for Modular Robot Policies](https://arxiv.org/abs/2602.10289)
*Rohan Banerjee,Krishna Palempalli,Bohan Yang,Jiaying Fang,Alif Abdullah,Tom Silver,Sarah Dean,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: 提出一个用于模块化机器人策略的“人在回路”故障恢复框架，通过量化模块不确定性和人类干预成本，智能决定何时以及向人类寻求帮助，以提高机器人故障恢复效率并减轻用户负担。


<details>
  <summary>Details</summary>
Motivation: 在非结构化人类环境中运行的机器人，尤其是在护理场景中，容易发生故障。虽然人类可以帮助机器人恢复，但过度的或目标不明确的查询会给人类带来不必要的工作量。因此，需要一种更智能的故障恢复机制。

Method: 该框架将模块级别的校准不确定性估计与人类干预成本模型相结合，以决定查询哪个模块以及何时查询。它将决策分为两部分：模块选择器识别最可能导致故障的模块，查询算法决定是寻求人类输入还是自主行动。并在合成实验和实际机器人系统上进行了评估。

Result: 在合成实验中，揭示了恢复效率、对系统和用户变量的鲁棒性以及用户工作量之间的权衡。在机器人辅助进食系统中，该框架提高了恢复成功率，同时降低了用户的工作量。

Conclusion: 明确考虑机器人不确定性和人类努力是实现更高效、以用户为中心的协作机器人故障恢复的关键。该框架证明了其在实际应用中的有效性。

Abstract: Robots operating in unstructured human environments inevitably encounter failures, especially in robot caregiving scenarios. While humans can often help robots recover, excessive or poorly targeted queries impose unnecessary cognitive and physical workload on the human partner. We present a human-in-the-loop failure-recovery framework for modular robotic policies, where a policy is composed of distinct modules such as perception, planning, and control, any of which may fail and often require different forms of human feedback. Our framework integrates calibrated estimates of module-level uncertainty with models of human intervention cost to decide which module to query and when to query the human. It separates these two decisions: a module selector identifies the module most likely responsible for failure, and a querying algorithm determines whether to solicit human input or act autonomously. We evaluate several module-selection strategies and querying algorithms in controlled synthetic experiments, revealing trade-offs between recovery efficiency, robustness to system and user variables, and user workload. Finally, we deploy the framework on a robot-assisted bite acquisition system and demonstrate, in studies involving individuals with both emulated and real mobility limitations, that it improves recovery success while reducing the workload imposed on users. Our results highlight how explicitly reasoning about both robot uncertainty and human effort can enable more efficient and user-centered failure recovery in collaborative robots. Supplementary materials and videos can be found at: http://emprise.cs.cornell.edu/modularhil

</details>


### [157] [Solving Geodesic Equations with Composite Bernstein Polynomials for Trajectory Planning](https://arxiv.org/abs/2602.10365)
*Nick Gorman,Gage MacLin,Maxwell Hammond,Venanzio Cichella*

Main category: cs.RO

TL;DR: 本文提出了一种基于复合Bernstein多项式的轨迹规划方法，用于在复杂环境中进行自主导航。该方法在符号优化框架下实现，能够生成连续路径并精确控制轨迹形状，通过成本表面处理障碍物，并满足避免碰撞、局部效率和起止点约束。


<details>
  <summary>Details</summary>
Motivation: 为了在复杂环境中实现自主系统的导航，需要一种能够生成连续、平滑、动态可行且计算效率高的轨迹规划方法，同时能精确控制轨迹形状并有效处理障碍物。

Method: 该方法使用复合Bernstein多项式在符号优化框架下生成轨迹。障碍物被表示为连续的成本场，靠近障碍物的区域具有更高的成本。优化过程考虑了三种约束：高斯表面不等式（最小障碍物间隙）、测地线方程（沿成本表面局部高效方向）和边界约束（固定起点和终点）。

Result: 该方法能够高效地生成光滑、无碰撞的路径，即使在有多个障碍物的场景下也能保持间隙，且无需大量采样或后处理。它适用于二维和三维环境，并能用于地面、空中、水下和太空系统。

Conclusion: 该方法是一种有效且计算效率高的轨迹规划技术，适用于各种自主系统在复杂环境下的导航，可以作为独立规划器或更复杂运动规划问题的初始化器。

Abstract: This work presents a trajectory planning method based on composite Bernstein polynomials for autonomous systems navigating complex environments. The method is implemented in a symbolic optimization framework that enables continuous paths and precise control over trajectory shape. Trajectories are planned over a cost surface that encodes obstacles as continuous fields rather than discrete boundaries. Regions near obstacles are assigned higher costs, naturally encouraging the trajectory to maintain a safe distance while still allowing efficient routing through constrained spaces. The use of composite Bernstein polynomials preserves continuity while enabling fine control over local curvature to satisfy geodesic constraints. The symbolic representation supports exact derivatives, improving optimization efficiency. The method applies to both two- and three-dimensional environments and is suitable for ground, aerial, underwater, and space systems. In spacecraft trajectory planning, for example, it enables the generation of continuous, dynamically feasible trajectories with high numerical efficiency, making it well suited for orbital maneuvers, rendezvous and proximity operations, cluttered gravitational environments, and planetary exploration missions with limited onboard computational resources. Demonstrations show that the approach efficiently generates smooth, collision-free paths in scenarios with multiple obstacles, maintaining clearance without extensive sampling or post-processing. The optimization incorporates three constraint types: (1) a Gaussian surface inequality enforcing minimum obstacle clearance; (2) geodesic equations guiding the path along locally efficient directions on the cost surface; and (3) boundary constraints enforcing fixed start and end conditions. The method can serve as a standalone planner or as an initializer for more complex motion planning problems.

</details>


### [158] [LocoVLM: Grounding Vision and Language for Adapting Versatile Legged Locomotion Policies](https://arxiv.org/abs/2602.10399)
*I Made Aswin Nahrendra,Seunghyun Lee,Dongkyu Lee,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种将大语言模型和视觉语言模型的高级常识推理能力集成到机器人步态运动控制中的新方法，实现了实时适应和指令遵循，准确率高达 87%。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人步态运动学习方法主要依赖于几何环境表示，限制了机器人响应人类指令等高级语义信息的能力。研究旨在克服这一局限。

Method: 利用预训练的大语言模型生成指令导向的技能数据库；利用预训练的视觉语言模型提取环境语义并将其与技能数据库关联；训练一个风格条件策略，以实现多样化和鲁棒的运动技能控制。

Result: 该方法能够实时适应步态运动，并能根据环境语义和指令提供技能建议。在无需在线查询云端基础模型的情况下，实现了高达 87% 的指令遵循准确率。

Conclusion: 该研究首次展示了利用高级环境语义和指令推理实时适应机器人步态运动，显著提升了机器人理解和执行人类指令的能力。

Abstract: Recent advances in legged locomotion learning are still dominated by the utilization of geometric representations of the environment, limiting the robot's capability to respond to higher-level semantics such as human instructions. To address this limitation, we propose a novel approach that integrates high-level commonsense reasoning from foundation models into the process of legged locomotion adaptation. Specifically, our method utilizes a pre-trained large language model to synthesize an instruction-grounded skill database tailored for legged robots. A pre-trained vision-language model is employed to extract high-level environmental semantics and ground them within the skill database, enabling real-time skill advisories for the robot. To facilitate versatile skill control, we train a style-conditioned policy capable of generating diverse and robust locomotion skills with high fidelity to specified styles. To the best of our knowledge, this is the first work to demonstrate real-time adaptation of legged locomotion using high-level reasoning from environmental semantics and instructions with instruction-following accuracy of up to 87% without the need for online query to on-the-cloud foundation models.

</details>


### [159] [Towards Long-Lived Robots: Continual Learning VLA Models via Reinforcement Fine-Tuning](https://arxiv.org/abs/2602.10503)
*Yuan Liu,Haoran Li,Shuai Tian,Yuxing Qin,Yuhui Chen,Yupeng Zheng,Yongzhen Huang,Dongbin Zhao*

Main category: cs.RO

TL;DR: 提出了一种名为 LifeLong-RFT 的强化微调策略，用于视觉-语言-动作（VLA）模型，无需在线环境反馈或预训练奖励模型。该方法通过整合分块级 on-policy 强化学习和多维度过程奖励（MDPR），包含量化动作一致性奖励（QACR）、连续轨迹对齐奖励（CTAR）和格式合规奖励（FCR），以优化策略。实验证明 LifeLong-RFT 在多任务学习和持续学习方面表现优异，尤其是在 LIBERO 基准测试中，成功率提升了 22%，且仅使用 20% 的训练数据即可适应新任务。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）是适应视觉-语言-动作（VLA）模型到下游任务的主要方法，但需要大量特定任务数据且容易发生灾难性遗忘。研究动机是开发一种更有效、更少依赖数据的 VLA 模型微调策略。

Method: 提出 LifeLong-RFT，一种无需在线环境反馈和预训练奖励模型的强化微调策略。该方法结合了分块级 on-policy 强化学习和多维度过程奖励（MDPR），MDPR 包含三个维度：量化动作一致性奖励（QACR）、连续轨迹对齐奖励（CTAR）和格式合规奖励（FCR），用于量化中间动作块的贡献并优化策略。

Result: 在 SimplerEnv、LIBERO 和真实世界任务的实验中，LifeLong-RFT 在多任务学习中表现出强大的性能。在 LIBERO 基准的持续学习中，LifeLong-RFT 的平均成功率比 SFT 提高了 22%，并且在仅使用 20% 的训练数据的情况下有效适应了新任务。

Conclusion: LifeLong-RFT 是一种简单而有效的强化微调策略，能够克服监督微调在数据需求和灾难性遗忘方面的限制，为 VLA 模型提供了一种有前景的后训练范式，特别是在多任务和持续学习场景下。

Abstract: Pretrained on large-scale and diverse datasets, VLA models demonstrate strong generalization and adaptability as general-purpose robotic policies. However, Supervised Fine-Tuning (SFT), which serves as the primary mechanism for adapting VLAs to downstream domains, requires substantial amounts of task-specific data and is prone to catastrophic forgetting. To address these limitations, we propose LifeLong-RFT, a simple yet effective Reinforcement Fine-Tuning (RFT) strategy for VLA models independent of online environmental feedback and pre-trained reward models. By integrating chunking-level on-policy reinforcement learning with the proposed Multi-Dimensional Process Reward (MDPR) mechanism, LifeLong-RFT quantifies the heterogeneous contributions of intermediate action chunks across three dimensions to facilitate policy optimization. Specifically, (1) the Quantized Action Consistency Reward (QACR) ensures accurate action prediction within the discrete action space; (2) the Continuous Trajectory Alignment Reward (CTAR) aligns decoded continuous action chunks with reference trajectories to ensure precise control; (3) the Format Compliance Reward (FCR) guarantees the structural validity of outputs. Comprehensive experiments across SimplerEnv, LIBERO, and real-world tasks demonstrate that LifeLong-RFT exhibits strong performance in multi-task learning. Furthermore, for continual learning on the LIBERO benchmark, our method achieves a 22% gain in average success rate over SFT, while effectively adapting to new tasks using only 20% of the training data. Overall, our method provides a promising post-training paradigm for VLAs.

</details>


### [160] [Co-jump: Cooperative Jumping with Quadrupedal Robots via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.10514)
*Shihao Dong,Yeke Chen,Zeren Luo,Jiahui Zhang,Bowen Xu,Jinghan Lin,Yimin Han,Ji Ma,Zhiyou Yu,Yudong Zhao,Peng Lu*

Main category: cs.RO

TL;DR: 本文提出了一种名为Co-jump的双四足机器人协同跳跃任务，旨在超越单个机器人的物理极限。通过去中心化的MAPPO强化学习算法和渐进式课程策略，机器人能够实现高精度、无需通信的同步跳跃，并在仿真和真实硬件上验证了其有效性，显著提升了跳跃高度。


<details>
  <summary>Details</summary>
Motivation: 单个腿式机器人受限于物理驱动能力，难以完成高难度跳跃任务。研究的动机是探索如何通过多机器人协作来克服这些限制，实现超越个体能力的运动表现。

Method: 本文采用了多智能体近端策略优化（MAPPO）强化学习算法，并结合了渐进式课程学习策略来解决稀疏奖励和探索难题。该方法在去中心化设置下，利用本体感觉反馈实现机器人间的同步，无需显式通信或预定义运动原语。

Result: 在仿真和真实硬件上，Co-jump系统成功实现了多方向的协同跳跃，能够跳上高达1.5米的高度。其中一个机器人实现了1.1米脚端抬升，相比独立机器人（0.45米）提高了144%，展示了卓越的垂直运动能力。

Conclusion: Co-jump任务和所提出的去中心化强化学习框架，成功实现了双足机器人无需通信的协同跳跃，显著提升了运动性能，为在受限环境下进行无通信协作式运动奠定了基础。

Abstract: While single-agent legged locomotion has witnessed remarkable progress, individual robots remain fundamentally constrained by physical actuation limits. To transcend these boundaries, we introduce Co-jump, a cooperative task where two quadrupedal robots synchronize to execute jumps far beyond their solo capabilities. We tackle the high-impulse contact dynamics of this task under a decentralized setting, achieving synchronization without explicit communication or pre-specified motion primitives. Our framework leverages Multi-Agent Proximal Policy Optimization (MAPPO) enhanced by a progressive curriculum strategy, which effectively overcomes the sparse-reward exploration challenges inherent in mechanically coupled systems. We demonstrate robust performance in simulation and successful transfer to physical hardware, executing multi-directional jumps onto platforms up to 1.5 m in height. Specifically, one of the robots achieves a foot-end elevation of 1.1 m, which represents a 144% improvement over the 0.45 m jump height of a standalone quadrupedal robot, demonstrating superior vertical performance. Notably, this precise coordination is achieved solely through proprioceptive feedback, establishing a foundation for communication-free collaborative locomotion in constrained environments.

</details>


### [161] [ReSPEC: A Framework for Online Multispectral Sensor Reconfiguration in Dynamic Environments](https://arxiv.org/abs/2602.10547)
*Yanchen Liu,Yuang Fan,Minghui Zhao,Xiaofan Jiang*

Main category: cs.RO

TL;DR: 提出了一种将多传感器融合、强化学习和执行器相结合的闭环自适应感知框架，能够根据环境动态调整传感器配置（如采样频率、分辨率、感知范围），以优化资源利用和感知性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器人多传感器融合系统在传感器配置上过于僵化，无法根据实际情况调整传感器信息收集策略，导致带宽、计算和能源的浪费，并且在恶劣环境下（如光照不足或遮挡）无法有效提升感知能力。需要一种能够自适应感知，并考虑传感器数据采集物理成本的系统。

Method: 构建了一个包含感知、学习和执行的闭环自适应感知框架。使用任务特定的检测骨干网络提取多光谱特征，并为每种传感器模态计算贡献分数。强化学习（RL）智能体根据这些分数动态调整传感器的采样频率、分辨率、感知范围等配置。信息量少的传感器会被降采样或关闭，而关键传感器在环境变化时会被提高采样精度。

Result: 在移动机器人上进行了实现和评估，结果显示与启发式基线相比，自适应控制将GPU负载降低了29.3%，而准确率仅下降了5.3%。

Conclusion: 资源感知的自适应传感技术在嵌入式机器人平台上具有巨大的潜力，能够有效地优化资源消耗并保持感知性能。

Abstract: Multi-sensor fusion is central to robust robotic perception, yet most existing systems operate under static sensor configurations, collecting all modalities at fixed rates and fidelity regardless of their situational utility. This rigidity wastes bandwidth, computation, and energy, and prevents systems from prioritizing sensors under challenging conditions such as poor lighting or occlusion. Recent advances in reinforcement learning (RL) and modality-aware fusion suggest the potential for adaptive perception, but prior efforts have largely focused on re-weighting features at inference time, ignoring the physical cost of sensor data collection. We introduce a framework that unifies sensing, learning, and actuation into a closed reconfiguration loop. A task-specific detection backbone extracts multispectral features (e.g. RGB, IR, mmWave, depth) and produces quantitative contribution scores for each modality. These scores are passed to an RL agent, which dynamically adjusts sensor configurations, including sampling frequency, resolution, sensing range, and etc., in real time. Less informative sensors are down-sampled or deactivated, while critical sensors are sampled at higher fidelity as environmental conditions evolve. We implement and evaluate this framework on a mobile rover, showing that adaptive control reduces GPU load by 29.3\% with only a 5.3\% accuracy drop compared to a heuristic baseline. These results highlight the potential of resource-aware adaptive sensing for embedded robotic platforms.

</details>


### [162] [LAP: Language-Action Pre-Training Enables Zero-shot Cross-Embodiment Transfer](https://arxiv.org/abs/2602.10556)
*Lihan Zha,Asher J. Hancock,Mingtong Zhang,Tenny Yin,Yixuan Huang,Dhruv Shah,Allen Z. Ren,Anirudha Majumdar*

Main category: cs.RO

TL;DR: 本研究提出了一种名为LAP（Language-Action Pre-training）的新方法，通过将机器人动作表示为自然语言，实现了在机器人模型上无需适应即可零样本迁移到新机器人上的目标，并推出了LAP-3B模型，在未见过的机器人和任务上实现了超过50%的平均零样本成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在部署到新的机器人实体时，即使经过大规模预训练，仍然需要昂贵的微调。研究的目标是实现一个通用机器人策略，使其能够零样本直接应用于新的机器人实体，而无需进行特定实体的适应。

Method: 作者提出了一种名为LAP（Language-Action Pre-training）的预训练方法，该方法将低级机器人动作直接用自然语言表示，从而将动作监督与预训练的视觉-语言模型的输入-输出分布对齐。LAP无需学习分词器，无需昂贵的标注，也无需特定于实体架构的设计。基于LAP，研究人员开发了LAP-3B模型。

Result: LAP-3B是首个在未见过的机器人实体上实现显著零样本迁移而无需任何特定实体微调的VLA模型。在多个新型机器人和操作任务上，LAP-3B实现了超过50%的平均零样本成功率，比现有最强的VLA模型有了约2倍的提升。此外，LAP还支持高效的适应和有利的扩展，并通过共享的语言-动作格式统一了动作预测和视觉问答，从而通过联合训练获得额外收益。

Conclusion: LAP是一种简单有效的预训练方法，能够将机器人动作表示为自然语言，从而实现VLA模型在零样本场景下向新机器人实体的泛化能力，无需进行特定实体的微调。LAP-3B模型证明了该方法的有效性，在零样本迁移和适应性方面取得了显著进展。

Abstract: A long-standing goal in robotics is a generalist policy that can be deployed zero-shot on new robot embodiments without per-embodiment adaptation. Despite large-scale multi-embodiment pre-training, existing Vision-Language-Action models (VLAs) remain tightly coupled to their training embodiments and typically require costly fine-tuning. We introduce Language-Action Pre-training (LAP), a simple recipe that represents low-level robot actions directly in natural language, aligning action supervision with the pre-trained vision-language model's input-output distribution. LAP requires no learned tokenizer, no costly annotation, and no embodiment-specific architectural design. Based on LAP, we present LAP-3B, which to the best of our knowledge is the first VLA to achieve substantial zero-shot transfer to previously unseen robot embodiments without any embodiment-specific fine-tuning. Across multiple novel robots and manipulation tasks, LAP-3B attains over 50% average zero-shot success, delivering roughly a 2x improvement over the strongest prior VLAs. We further show that LAP enables efficient adaptation and favorable scaling, while unifying action prediction and VQA in a shared language-action format that yields additional gains through co-training.

</details>


### [163] [Morphogenetic Assembly and Adaptive Control for Heterogeneous Modular Robots](https://arxiv.org/abs/2602.10561)
*Chongxi Meng,Da Zhao,Yifei Zhao,Minghao Zeng,Yanmin Zhou,Zhipeng Wang,Bin He*

Main category: cs.RO

TL;DR: 该论文提出了一种用于异构模块化机器人的全闭环自动化框架，涵盖从形态构建到自适应控制的整个流程，并引入了分层规划器和GPU加速的MPPI控制器以实现动态组装和配置无关的实时运动控制。


<details>
  <summary>Details</summary>
Motivation: 解决大规模异构机器人动态重构中状态空间爆炸的问题，并实现对未知组装配置的自适应实时运动控制。

Method: 提出一个分层规划器，包括一个使用双向启发式搜索和类型惩罚项的高层规划器，以及一个使用A*搜索的低层规划器。引入一个GPU加速的退火-方差模型预测路径积分（MPPI）控制器，并采用多阶段方差退火策略。

Result: 类型惩罚项对异构场景下的规划鲁棒性至关重要。贪婪启发式规划比匈牙利启发式规划具有更低的物理执行成本。退火-方差MPPI在速度跟踪精度和控制频率上显著优于标准MPPI，实现了50Hz的实时控制。

Conclusion: 该框架成功验证了模块组装、机器人合并与分裂以及动态运动生成的全周期过程，并证明了所提出的分层规划器和退火-方差MPPI控制器在异构模块化机器人自动化中的有效性。

Abstract: This paper presents a closed-loop automation framework for heterogeneous modular robots, covering the full pipeline from morphological construction to adaptive control. In this framework, a mobile manipulator handles heterogeneous functional modules including structural, joint, and wheeled modules to dynamically assemble diverse robot configurations and provide them with immediate locomotion capability. To address the state-space explosion in large-scale heterogeneous reconfiguration, we propose a hierarchical planner: the high-level planner uses a bidirectional heuristic search with type-penalty terms to generate module-handling sequences, while the low level planner employs A* search to compute optimal execution trajectories. This design effectively decouples discrete configuration planning from continuous motion execution. For adaptive motion generation of unknown assembled configurations, we introduce a GPU accelerated Annealing-Variance Model Predictive Path Integral (MPPI) controller. By incorporating a multi stage variance annealing strategy to balance global exploration and local convergence, the controller enables configuration-agnostic, real-time motion control. Large scale simulations show that the type-penalty term is critical for planning robustness in heterogeneous scenarios. Moreover, the greedy heuristic produces plans with lower physical execution costs than the Hungarian heuristic. The proposed annealing-variance MPPI significantly outperforms standard MPPI in both velocity tracking accuracy and control frequency, achieving real time control at 50 Hz. The framework validates the full-cycle process, including module assembly, robot merging and splitting, and dynamic motion generation.

</details>


### [164] [Flow-Enabled Generalization to Human Demonstrations in Few-Shot Imitation Learning](https://arxiv.org/abs/2602.10594)
*Runze Tang,Penny Sweetser*

Main category: cs.RO

TL;DR: 提出了一种名为 SFCrP 的新方法，用于从视频演示中学习机器人技能，它结合了场景流预测和基于流和裁剪点云的策略，以提高泛化能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的模仿学习需要大量机器人演示，成本高昂。利用人类视频作为替代品可以减少所需机器人演示的数量，但现有方法在处理交互运动和实现对仅在人类视频中观察到的场景的泛化方面存在局限性。

Method: 该方法包括两个主要部分：1) 场景流预测模型（SFCr），用于跨实体学习，能够从机器人和人类视频中学习并预测任意点轨迹；2) 基于流和裁剪点云的策略（FCrP），它遵循整体运动流并根据观察结果调整动作以实现精确控制。

Result: SFCrP 在各种真实世界任务中表现优于最先进的基线方法，并且在空间和实例泛化到仅在人类视频中观察到的场景方面表现出强大的能力。

Conclusion: SFCrP 是一种有效的方法，可以从多样化的视频演示（包括人类视频）中学习机器人技能，并能实现良好的泛化和精确的动作控制。

Abstract: Imitation Learning (IL) enables robots to learn complex skills from demonstrations without explicit task modeling, but it typically requires large amounts of demonstrations, creating significant collection costs. Prior work has investigated using flow as an intermediate representation to enable the use of human videos as a substitute, thereby reducing the amount of required robot demonstrations. However, most prior work has focused on the flow, either on the object or on specific points of the robot/hand, which cannot describe the motion of interaction. Meanwhile, relying on flow to achieve generalization to scenarios observed only in human videos remains limited, as flow alone cannot capture precise motion details. Furthermore, conditioning on scene observation to produce precise actions may cause the flow-conditioned policy to overfit to training tasks and weaken the generalization indicated by the flow. To address these gaps, we propose SFCrP, which includes a Scene Flow prediction model for Cross-embodiment learning (SFCr) and a Flow and Cropped point cloud conditioned Policy (FCrP). SFCr learns from both robot and human videos and predicts any point trajectories. FCrP follows the general flow motion and adjusts the action based on observations for precision tasks. Our method outperforms SOTA baselines across various real-world task settings, while also exhibiting strong spatial and instance generalization to scenarios seen only in human videos.

</details>


### [165] [Pitch Angle Control of a Magnetically Actuated Capsule Robot with Nonlinear FEA-based MPC and EKF Multisensory Fusion](https://arxiv.org/abs/2602.10610)
*Chongxun Wang,Zikang Shen,Apoorav Rathore,Akanimoh Udombeh,Harrison Teng,Fangzhou Xia*

Main category: cs.RO

TL;DR: 本文提出了一种基于模型的非线性磁力俯仰控制框架，用于可吞咽胶囊机器人，以控制其与胃壁的接触交互。该框架使用有限元模拟来表征磁力，并结合了约束模型预测控制器 (MPC) 来精确控制俯仰角。实验证明，与简单的开关控制相比，该方法可以更快地稳定并减少振荡。此外，结合扩展卡尔曼滤波器 (EKF) 和视觉测量，即使在视觉更新率较低的情况下也能实现稳定的闭环控制。


<details>
  <summary>Details</summary>
Motivation: 现有磁力驱动的胶囊机器人主要忽略了俯仰角的控制，而俯仰角对于在倾斜的胃壁上进行接触交互至关重要。因此，研究人员旨在开发一种能够精确控制胶囊俯仰角的系统，以实现更有效的诊断和治疗。

Method: 研究人员首先使用三维有限元模拟来表征嵌入胶囊的永磁体所受的角度相关磁力。然后，将这些模拟结果作为查找表嵌入到一个考虑了滚动接触和执行器动力学的控制导向刚体俯仰模型中。在此基础上，设计了一个约束模型预测控制器 (MPC) 来调节俯仰角，同时遵守硬件的电流和变化率限制。为了在视觉测量频率较低的情况下实现稳定的闭环控制，还开发了一个扩展卡尔曼滤波器 (EKF)，该滤波器融合了惯性传感数据和间歇性的视觉测量。

Result: 在模拟胃壁的实验中，该系统能够从水平和竖直两种初始构型有效地将胶囊的俯仰角重新定向。与简单的开关控制相比，新的控制方法实现了约三到五倍的更快速稳定，并显著减少了振荡。通过 EKF 融合惯性测量和低频视觉测量（从 30 Hz 降至 1 Hz），实现了稳定的闭环控制，模拟了临床上更现实的成像限制。

Conclusion: 基于有限元模拟信息和 MPC 的俯仰控制策略，结合传感器融合技术，是一种可扩展的策略，能够实现胶囊机器人的俯仰角调节、精确对接，并为未来实现多自由度胶囊运动奠定了基础。

Abstract: Magnetically actuated capsule robots promise minimally invasive diagnosis and therapy in the gastrointestinal (GI) tract, but existing systems largely neglect control of capsule pitch, a degree of freedom critical for contact-rich interaction with inclined gastric walls. This paper presents a nonlinear, model-based framework for magnetic pitch control of an ingestible capsule robot actuated by a four-coil electromagnetic array. Angle-dependent magnetic forces and torques acting on embedded permanent magnets are characterized using three-dimensional finite-element simulations and embedded as lookup tables in a control-oriented rigid-body pitching model with rolling contact and actuator dynamics. A constrained model predictive controller (MPC) is designed to regulate pitch while respecting hardware-imposed current and slew-rate limits. Experiments on a compliant stomach-inspired surface demonstrate robust pitch reorientation from both horizontal and upright configurations, achieving about three to five times faster settling and reduced oscillatory motion than on-off control. Furthermore, an extended Kalman filter (EKF) fusing inertial sensing with intermittent visual measurements enables stable closed-loop control when the camera update rate is reduced from 30 Hz to 1 Hz, emulating clinically realistic imaging constraints. These results establish finite-element-informed MPC with sensor fusion as a scalable strategy for pitch regulation, controlled docking, and future multi-degree-of-freedom capsule locomotion.

</details>


### [166] [Free-Flying Crew Cooperative Robots on the ISS: A Joint Review of Astrobee, CIMON, and Int-Ball Operations](https://arxiv.org/abs/2602.10686)
*Seiko Piotr Yamaguchi,Andres Mora Vargas,Till Eisenberg,Christian Rogon,Tatsuya Yamamoto,Shona Inoue,Christoph Kössl,Brian Coltin,Trey Smith,Jose V. Benavides*

Main category: cs.RO

TL;DR: 本文首次联合分析了NASA的Astrobee、DLR的CIMON和JAXA的Int-Ball这三种国际空间站上的舱内自由飞行的机器人，并总结了它们在设计和在轨操作方面的共同经验和教训，为未来的机器人开发提供指导。


<details>
  <summary>Details</summary>
Motivation: 尽管这三种机器人起源和设计理念不同，但在开发和操作过程中遇到了许多共同点，因此需要进行联合分析以总结经验教训，为未来的开发提供参考。

Method: 本文对Astrobee、CIMON和Int-Ball这三种机器人的目标、设计和在轨操作进行了详细概述，并分析了它们的共同开发和操作经验，以提取联合经验教训。

Result: 文章详细介绍了这三种机器人的目标、设计和在轨操作，并总结了从设计到在轨操作的整个生命周期中的联合经验教训。

Conclusion: 这些联合经验教训可以作为设计建议，为未来舱内自由飞行机器人的开发和研究提供指导。

Abstract: Intra-vehicular free-flying robots are anticipated to support various work in human spaceflight while working side-by-side with astronauts. Such example of robots includes NASA's Astrobee, DLR's CIMON, and JAXA's Int-Ball, which are deployed on the International Space Station. This paper presents the first joint analyses of these robot's shared experiences, co-authored by their development and operation team members. Despite the different origins and design philosophies, the development and operations of these platforms encountered various convergences. Hence, this paper presents a detailed overview of these robots, presenting their objectives, design, and onboard operations. Hence, joint lessons learned across the lifecycle are presented, from design to on-orbit operations. These lessons learned are anticipated to serve for future development and research as design recommendations.

</details>


### [167] [3D-Printed Anisotropic Soft Magnetic Coating for Directional Rolling of a Magnetically Actuated Capsule Robot](https://arxiv.org/abs/2602.10688)
*Jin Zhou,Chongxun Wang,Zikang Shen,Fangzhou Xia*

Main category: cs.RO

TL;DR: 这篇论文提出了一种新型的3D打印软体胶囊机器人，通过在外部涂覆磁性材料取代内部的笨重永磁体，从而增加了内部可用空间，并提高了可吞咽性。该机器人能够实现稳定双向滚动、全向转向、爬坡和越障。


<details>
  <summary>Details</summary>
Motivation: 现有磁性胶囊机器人内部集成永磁体占用空间大，限制了功能模块的集成。作者希望设计一种能保留全部内部腔体用于医疗载荷，并提高可吞咽性的胶囊机器人。

Method: 采用3D打印技术制造软体胶囊机器人，并在其外部涂覆硅胶-磁性复合材料。通过设计特定的磁极分布（NSSN/SNNS）来产生各向异性，并通过外部磁场控制其运动。进行了静磁学仿真和实验验证。

Result: 该胶囊机器人能够实现稳定双向滚动、全向转向、爬坡（7.5度）和越障（5毫米）。在磁场强度达到0.3 mT时，可实现有效驱动，驱动深度为30毫米。

Conclusion: 基于磁性涂层的胶囊机器人是一种有前景的解决方案，可以克服传统磁性胶囊机器人的局限性，并为未来在微创诊断和治疗领域的临床应用奠定基础。

Abstract: Capsule robots are promising tools for minimally invasive diagnostics and therapy, with applications from gastrointestinal endoscopy to targeted drug delivery and biopsy sampling. Conventional magnetic capsule robots embed bulky permanent magnets at both ends, reducing the usable cavity by about 10-20 mm and limiting integration of functional modules. We propose a compact, 3D-printed soft capsule robot with a magnetic coating that replaces internal magnets, enabling locomotion via a thin, functional shell while preserving the entire interior cavity as a continuous volume for medical payloads. The compliant silicone-magnetic composite also improves swallowability, even with a slightly larger capsule size. Magnetostatic simulations and experiments confirm that programmed NSSN/SNNS pole distributions provide strong anisotropy and reliable torque generation, enabling stable bidirectional rolling, omnidirectional steering, climbing on 7.5 degree inclines, and traversal of 5 mm protrusions. Rolling motion is sustained when the magnetic field at the capsule reaches at least 0.3 mT, corresponding to an effective actuation depth of 30 mm in our setup. Future work will optimize material composition, coating thickness, and magnetic layouts to enhance force output and durability, while next-generation robotic-arm-based field generators with closed-loop feedback will address nonlinearities and expand maneuverability. Together, these advances aim to transition coating-based capsule robots toward reliable clinical deployment and broaden their applications in minimally invasive diagnostics and therapy.

</details>


### [168] [A Unified Experimental Architecture for Informative Path Planning: from Simulation to Deployment with GuadalPlanner](https://arxiv.org/abs/2602.10702)
*Alejandro Mendoza Barrionuevo,Dame Seck Diop,Alejandro Casado Pérez,Daniel Gutiérrez Reina,Sergio L. Toral Marín,Samuel Yanes Luis*

Main category: cs.RO

TL;DR: 本文提出了一种统一的自主车辆信息路径规划算法评估架构，名为 GuadalPlanner，它将决策与控制解耦，并提供标准接口，实现了在模拟和现实世界中无需修改算法即可进行一致评估，并已在水质监测的自主水面车辆上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的自主车辆信息路径规划算法评估面临执行流程碎片化、仿真到实际部署迁移能力有限的问题。

Method: 提出了一个统一的架构，将高层决策与车辆控制解耦，通过 GuadalPlanner 实现，定义了规划、感知和车辆执行之间的标准化接口。该工具支持离散图状环境和可互换的规划策略，基于 ROS2、MAVLink 和 MQTT 等技术构建，允许在不同环境（完全仿真、SIL、实体车辆）中部署相同的算法逻辑。

Result: 该架构能够一致地评估路径规划算法，无需修改。通过在自主水面车辆上进行水质监测的真实世界部署实验进行了验证，该实验使用了实时传感器反馈。

Conclusion: 提出的 GuadalPlanner 架构提供了一个统一、可扩展的平台，能够有效地评估自主车辆的信息路径规划算法，并成功地在不同抽象级别和真实世界的应用中进行了部署和验证。

Abstract: The evaluation of informative path planning algorithms for autonomous vehicles is often hindered by fragmented execution pipelines and limited transferability between simulation and real-world deployment. This paper introduces a unified architecture that decouples high-level decision-making from vehicle-specific control, enabling algorithms to be evaluated consistently across different abstraction levels without modification. The proposed architecture is realized through GuadalPlanner, which defines standardized interfaces between planning, sensing, and vehicle execution. It is an open and extensible research tool that supports discrete graph-based environments and interchangeable planning strategies, and is built upon widely adopted robotics technologies, including ROS2, MAVLink, and MQTT. Its design allows the same algorithmic logic to be deployed in fully simulated environments, software-in-the-loop configurations, and physical autonomous vehicles using an identical execution pipeline. The approach is validated through a set of experiments, including real-world deployment on an autonomous surface vehicle performing water quality monitoring with real-time sensor feedback.

</details>


### [169] [Omnidirectional Dual-Arm Aerial Manipulator with Proprioceptive Contact Localization for Landing on Slanted Roofs](https://arxiv.org/abs/2602.10703)
*Martijn B. J. Brummelhuis,Nathan F. Lepora,Salua Hamaza*

Main category: cs.RO

TL;DR: 本文提出了一种新型无人机机械臂，能够通过物理接触感应，在接触前盲测屋顶倾斜度，成功实现了对倾斜度达30.5度的屋顶的稳健着陆。


<details>
  <summary>Details</summary>
Motivation: 在城市环境中操作无人机着陆时，屋顶几何形状和表面不规则性给传统基于视觉或声学传感器的倾斜度检测带来挑战，其测量精度易受天气和表面材料影响。因此，需要一种更可靠的方法来检测屋顶倾斜度。

Method: 研究提出了一种双臂全向工作空间无人机机械臂（UAM）。在此基础上，开发了一种基于动量扭矩观测器的本体感知接触检测和接触定位策略。该策略允许UAM在接触前，仅通过物理互动来推断倾斜表面的倾斜度。

Result: 在飞行实验中，该方法成功实现了在倾斜度高达30.5度的表面上的稳健着陆。在9次不同倾斜角的实验中，平均表面倾斜度估计误差为2.87度。

Conclusion: 提出的无人机机械臂及其基于物理接触的倾斜度检测策略，能够克服传统传感方法的局限性，在复杂城市环境中实现高倾斜度屋顶的可靠着陆。

Abstract: Operating drones in urban environments often means they need to land on rooftops, which can have different geometries and surface irregularities. Accurately detecting roof inclination using conventional sensing methods, such as vision-based or acoustic techniques, can be unreliable, as measurement quality is strongly influenced by external factors including weather conditions and surface materials. To overcome these challenges, we propose a novel unmanned aerial manipulator morphology featuring a dual-arm aerial manipulator with an omnidirectional 3D workspace and extended reach. Building on this design, we develop a proprioceptive contact detection and contact localization strategy based on a momentum-based torque observer. This enables the UAM to infer the inclination of slanted surfaces blindly - through physical interaction - prior to touchdown. We validate the approach in flight experiments, demonstrating robust landings on surfaces with inclinations of up to 30.5 degrees and achieving an average surface inclination estimation error of 2.87 degrees over 9 experiments at different incline angles.

</details>


### [170] [Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation](https://arxiv.org/abs/2602.10717)
*Songen Gu,Yunuo Cai,Tianyu Wang,Simo Wu,Yanwei Fu*

Main category: cs.RO

TL;DR: 提出了一种用于快速、预测性视频条件动作的框架，通过结合视频生成和动作模型，实现机器人精确操作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作系统缺乏预测环境演变的能力，导致错误和效率低下。虽然视觉-语言模型（VLMs）能提供指导，但无法明确预测未来状态，现有的世界模型预测范围有限且空间不一致。

Method: 该框架首先选择并调整一个鲁棒的视频生成模型以进行可靠的未来预测，然后通过对抗性蒸馏实现快速、少步的视频生成，最后训练一个动作模型，该模型利用生成的视频和真实观测来纠正空间误差。

Result: 实验表明，该方法能够生成时间连贯、空间准确的视频预测，直接支持精确操作，并在体现一致性、空间指代能力和任务完成率方面显著优于现有基线。

Conclusion: 所提出的框架能够生成高质量的预测性视频，有效提升机器人的操作能力，克服了现有方法的局限性。

Abstract: Robotic manipulation requires anticipating how the environment evolves in response to actions, yet most existing systems lack this predictive capability, often resulting in errors and inefficiency. While Vision-Language Models (VLMs) provide high-level guidance, they cannot explicitly forecast future states, and existing world models either predict only short horizons or produce spatially inconsistent frames. To address these challenges, we propose a framework for fast and predictive video-conditioned action. Our approach first selects and adapts a robust video generation model to ensure reliable future predictions, then applies adversarial distillation for fast, few-step video generation, and finally trains an action model that leverages both generated videos and real observations to correct spatial errors. Extensive experiments show that our method produces temporally coherent, spatially accurate video predictions that directly support precise manipulation, achieving significant improvements in embodiment consistency, spatial referring ability, and task completion over existing baselines. Codes & Models will be released.

</details>


### [171] [From Representational Complementarity to Dual Systems: Synergizing VLM and Vision-Only Backbones for End-to-End Driving](https://arxiv.org/abs/2602.10719)
*Sining Ang,Yuguang Yang,Chenxu Dang,Canyu Chen,Cheng Chi,Haiyan Liu,Xuanyao Mao,Jason Bao,Xuliang,Bingchuan Sun,Yan Wang*

Main category: cs.RO

TL;DR: 该研究通过比较视觉-语言-动作（VLA）和纯视觉模型在自动驾驶任务中的表现，发现VLM在长尾场景下表现出更激进的行为，纯视觉模型则更保守。研究提出了HybridDriveVLA和DualDriveVLA模型，分别通过融合或选择性调用VLM来提升性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究对视觉-语言-动作（VLA）驱动在自动驾驶中的作用仅限于准确率-成本权衡，但其更深层次的影响尚不明确。因此，本文旨在深入探究VLA模型在端到端规划中除了提高准确率之外，还能带来哪些变化。

Method: 研究人员在RecogDrive框架下，使用相同的扩散Transformer规划器，分别对比了集成完整VLM和纯视觉骨干（ViT）的系统。通过三项研究问题（RQ1-RQ3）来分析不同骨干的性能和行为。RQ1关注VLM是否引入了新的子空间；RQ2分析在长尾场景下的行为差异；RQ3则提出HybridDriveVLA模型，结合ViT和VLM的预测并使用学习到的评分器进行选择，以及DualDriveVLA模型，实现了一个快慢策略，并在评分器置信度低时才调用VLM。

Result: 研究发现，VLM在纯视觉骨干的基础上引入了额外的子空间（RQ1）。在长尾场景下，VLM倾向于更激进，而ViT更保守，各自在约2-3%的测试场景中表现更优。使用“神谕”选择最佳轨迹可达93.58%的PDMS。HybridDriveVLA模型将PDMS提升至92.10%。DualDriveVLA模型通过默认运行ViT并在低置信度时调用VLM，实现了91.00%的PDMS，同时将吞吐量提高了3.2倍。

Conclusion: VLM为自动驾驶端到端规划带来了超越单纯准确率提升的影响，特别是在处理长尾场景时，其激进的行为与纯视觉模型的保守行为形成了互补。HybridDriveVLA和DualDriveVLA模型有效利用了这种互补性，在提升性能的同时兼顾了效率。

Abstract: Vision-Language-Action (VLA) driving augments end-to-end (E2E) planning with language-enabled backbones, yet it remains unclear what changes beyond the usual accuracy--cost trade-off. We revisit this question with 3--RQ analysis in RecogDrive by instantiating the system with a full VLM and vision-only backbones, all under an identical diffusion Transformer planner. RQ1: At the backbone level, the VLM can introduce additional subspaces upon the vision-only backbones. RQ2: This unique subspace leads to a different behavioral in some long-tail scenario: the VLM tends to be more aggressive whereas ViT is more conservative, and each decisively wins on about 2--3% of test scenarios; With an oracle that selects, per scenario, the better trajectory between the VLM and ViT branches, we obtain an upper bound of 93.58 PDMS. RQ3: To fully harness this observation, we propose HybridDriveVLA, which runs both ViT and VLM branches and selects between their endpoint trajectories using a learned scorer, improving PDMS to 92.10. Finally, DualDriveVLA implements a practical fast--slow policy: it runs ViT by default and invokes the VLM only when the scorer's confidence falls below a threshold; calling the VLM on 15% of scenarios achieves 91.00 PDMS while improving throughput by 3.2x. Code will be released.

</details>


### [172] [Biomimetic Mantaray robot toward the underwater autonomous -- Experimental verification of swimming and diving by flapping motion -](https://arxiv.org/abs/2602.10904)
*Kenta Tabata,Ryosuke Oku,Jun Ito,Renato Miyagusuku,Koichi Ozaki*

Main category: cs.RO

TL;DR: 本文介绍了一种仿生蝠鲼水下自主探索机器人，该机器人通过扑翼运动推进，旨在减少对海底的干扰并提高效率，并在水池实验中验证了其稳定游动和下潜能力。


<details>
  <summary>Details</summary>
Motivation: 受蝠鲼的启发，为了开发一种比传统螺旋桨推进方式更能减少对海底干扰并提高效率的水下机器人，以满足生态监测和水下探索的需求。

Method: 设计并制造了一个模仿蝠鲼形态的机器人，使用伺服电机驱动胸鳍进行扑翼运动，并集成了一个由树莓派3B驱动的控制系统，该系统包含IMU和压力传感器以进行实时监控和控制。通过在水池中进行实验来评估其游动和下潜能力，并采用PD控制器进行控制。

Result: 实验结果表明，该仿生蝠鲼机器人能够实现稳定的游动和下潜运动，PD控制能够有效地控制机器人的运动。

Conclusion: 该仿生蝠鲼机器人适用于需要低干扰和高效机动性的水下应用场景，如水族馆和鱼苗培育场，证明了仿生机器人设计在改善生态监测和水下探索方面的潜力。

Abstract: This study presents the development and experimental verification of a biomimetic manta ray robot for underwater autonomous exploration. Inspired by manta rays, the robot uses flapping motion for propulsion to minimize seabed disturbance and enhance efficiency compared to traditional screw propulsion. The robot features pectoral fins driven by servo motors and a streamlined control box to reduce fluid resistance. The control system, powered by a Raspberry Pi 3B, includes an IMU and pressure sensor for real-time monitoring and control. Experiments in a pool assessed the robot's swimming and diving capabilities. Results show stable swimming and diving motions with PD control. The robot is suitable for applications in environments like aquariums and fish nurseries, requiring minimal disturbance and efficient maneuverability. Our findings demonstrate the potential of bio-inspired robotic designs to improve ecological monitoring and underwater exploration.

</details>


### [173] [Safe mobility support system using crowd mapping and avoidance route planning using VLM](https://arxiv.org/abs/2602.10910)
*Sena Saito,Kenta Tabata,Renato Miyagusuku,Koichi Ozaki*

Main category: cs.RO

TL;DR: 本文提出了一种结合视觉语言模型（VLM）和高斯过程回归（GPR）的框架，用于生成动态人群密度图（“抽象地图”），以提升自主移动机器人在拥挤动态环境中的导航能力。实验表明，该方法可以有效避开静态障碍物和动态人群，提高导航的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 在拥挤的动态环境中，自主移动机器人的安全有效导航仍然是一个挑战，尤其是在劳动力短缺和提高运营效率的需求下。

Method: 利用视觉语言模型（VLM）识别抽象的环境概念（如人群密度），并通过高斯过程回归（GPR）对这些概念进行概率化表示，生成动态人群密度图（“抽象地图”）。

Result: 在真实世界大学校园的实验中，机器人成功生成了能够避开静态障碍物和动态人群的路径，提高了导航的安全性和适应性。

Conclusion: 该框架能够有效地利用VLM和GPR来生成动态人群密度图，从而显著提升自主机器人在复杂动态环境中的导航性能。

Abstract: Autonomous mobile robots offer promising solutions for labor shortages and increased operational efficiency. However, navigating safely and effectively in dynamic environments, particularly crowded areas, remains challenging. This paper proposes a novel framework that integrates Vision-Language Models (VLM) and Gaussian Process Regression (GPR) to generate dynamic crowd-density maps (``Abstraction Maps'') for autonomous robot navigation. Our approach utilizes VLM's capability to recognize abstract environmental concepts, such as crowd densities, and represents them probabilistically via GPR. Experimental results from real-world trials on a university campus demonstrated that robots successfully generated routes avoiding both static obstacles and dynamic crowds, enhancing navigation safety and adaptability.

</details>


### [174] [Design, Development, and Use of Maya Robot as an Assistant for the Therapy/Education of Children with Cancer: a Pilot Study](https://arxiv.org/abs/2602.10942)
*Alireza Taheri,Minoo Alemi,Elham Ranjkar,Raman Rafatnejad,Ali F. Meghdari*

Main category: cs.RO

TL;DR: 一项研究设计并实现了一个名为Maya的象形社交机器人，用于与接受癌症治疗的儿童互动。实验表明，Maya机器人的存在可以显著减轻儿童在注射过程中的疼痛感，并能降低儿童在游戏互动中的焦虑水平，同时提高他们对机器人和游戏的信任度。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索利用便携式社交机器人（Maya）来改善接受癌症治疗的儿童在临床环境中的体验，特别是减轻他们的疼痛和焦虑，并评估机器人对儿童的情感和信任度的影响。

Method: 研究包括两个初步实验。首先，通过深度神经网络提高了机器人面部表情识别的准确率至98%。第一个实验比较了有无Maya机器人时，儿童在注射过程中的疼痛水平，采用配对 T 检验进行分析。第二个实验评估了儿童及其母亲在与Maya机器人互动游戏后的焦虑和信任水平，采用了UTAUT问卷进行数据收集。

Result: 第一个实验显示，Maya机器人的存在显著降低了儿童在注射过程中的感知疼痛（P值未明确给出，但结果显著）。第二个实验表明，儿童在与Maya互动时比其母亲表现出更低的焦虑水平，并且对机器人和游戏表现出更高的信任度（P值 < 0.05）。

Conclusion: Maya机器人作为临床环境下的治疗/教育辅助工具，对接受癌症治疗的儿童具有积极影响，尤其在改善疼痛管理和情绪健康方面。研究强调了社交机器人在儿科医疗保健领域，特别是对年轻患者的潜力。

Abstract: This study centers around the design and implementation of the Maya Robot, a portable elephant-shaped social robot, intended to engage with children undergoing cancer treatment. Initial efforts were devoted to enhancing the robot's facial expression recognition accuracy, achieving a 98% accuracy through deep neural networks. Two subsequent preliminary exploratory experiments were designed to advance the study's objectives. The first experiment aimed to compare pain levels experienced by children during the injection process, with and without the presence of the Maya robot. Twenty-five children, aged 4 to 9, undergoing cancer treatment participated in this counterbalanced study. The paired T-test results revealed a significant reduction in perceived pain when the robot was actively present in the injection room. The second experiment sought to assess perspectives of hospitalized children and their mothers during engagement with Maya through a game. Forty participants, including 20 children aged 4 to 9 and their mothers, were involved. Post Human-Maya Interactions, UTAUT questionnaire results indicated that children experienced significantly less anxiety than their parents during the interaction and game play. Notably, children exhibited higher trust levels in both the robot and the games, presenting a statistically significant difference in trust levels compared to their parents (P-value < 0.05). This preliminary exploratory study highlights the positive impact of utilizing Maya as an assistant for therapy/education in a clinical setting, particularly benefiting children undergoing cancer treatment. The findings underscore the potential of social robots in pediatric healthcare contexts, emphasizing improved pain management and emotional well-being among young patients.

</details>


### [175] [Developing Neural Network-Based Gaze Control Systems for Social Robots](https://arxiv.org/abs/2602.10946)
*Ramtin Tabatabaei,Alireza Taheri*

Main category: cs.RO

TL;DR: 该研究利用深度学习模型（LSTM和Transformer）分析和预测了人类在不同社交场景下的注视行为的时空模式，并将最优模型应用于Nao机器人，以提升其社交互动能力。


<details>
  <summary>Details</summary>
Motivation: 为了让社交机器人能够恰当地引导注意力，理解社交情境，从而有效参与互动、预测意图并顺利进行交互，需要研究人类在不同社交场景下的注视行为。

Method: 研究创建了两个视频片段（电脑屏幕和VR头显），并在其中描绘了不同的社交场景。通过眼动仪和Oculus Quest 1头显收集了30名参与者的数据。使用LSTM和Transformer深度学习模型来分析和预测注视模式，并将表现最佳的模型部署到Nao机器人上。

Result: 深度学习模型在2D动画中实现了60%的注视方向预测准确率，在3D动画中实现了65%的准确率。经过Nao机器人部署后，36名新参与者的反馈显示总体满意度较高，其中机器人经验丰富的参与者评价更高。

Conclusion: 深度学习模型能够有效地捕捉和预测人类在社交场景下的注视行为时空模式，并将这些模型应用于社交机器人可以提升其在社交互动中的表现，并获得积极的用户反馈。

Abstract: During multi-party interactions, gaze direction is a key indicator of interest and intent, making it essential for social robots to direct their attention appropriately. Understanding the social context is crucial for robots to engage effectively, predict human intentions, and navigate interactions smoothly. This study aims to develop an empirical motion-time pattern for human gaze behavior in various social situations (e.g., entering, leaving, waving, talking, and pointing) using deep neural networks based on participants' data. We created two video clips-one for a computer screen and another for a virtual reality headset-depicting different social scenarios. Data were collected from 30 participants: 15 using an eye-tracker and 15 using an Oculus Quest 1 headset. Deep learning models, specifically Long Short-Term Memory (LSTM) and Transformers, were used to analyze and predict gaze patterns. Our models achieved 60% accuracy in predicting gaze direction in a 2D animation and 65% accuracy in a 3D animation. Then, the best model was implemented onto the Nao robot; and 36 new participants evaluated its performance. The feedback indicated overall satisfaction, with those experienced in robotics rating the models more favorably.

</details>


### [176] [Stability Analysis of Geometric Control for a Canonical Class of Underactuated Aerial Vehicles with Spurious Forces](https://arxiv.org/abs/2602.10961)
*Simone Orelli,Mirko Mizzoni,Antonio Franchi*

Main category: cs.RO

TL;DR: 本文提出了首个对存在内禀耦合力（ spurious forces）的浮动刚体进行形式化稳定性分析的方法，并证明了其悬停平衡点的局部指数稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的标准几何控制方法依赖于力-力矩解耦假设，该假设在许多航空平台中因内禀耦合力而失效。尽管已有实验验证的针对耦合系统的策略，但缺乏严格的理论稳定性认证。

Method: 本文构建了一个典范模型，并利用Lyapunov方法进行了稳定性证明，证明了悬停平衡点的局部指数稳定性。分析中特别考虑了导致非最小相位行为的结构性挑战，这些挑战阻碍了标准级联论证的应用。

Result: 本文首次对一类通用的、受内禀耦合力作用的浮动刚体进行了形式化的稳定性分析，并证明了其悬停平衡点的局部指数稳定性。

Conclusion: 本文成功填补了现有理论的空白，为存在内禀耦合力的浮动刚体控制提供了首个严格的理论稳定性保证，并为克服非最小相位行为等结构性挑战提供了新思路。

Abstract: Standard geometric control relies on force-moment decoupling, an assumption that breaks down in many aerial platforms due to spurious forces naturally induced by control moments. While strategies for such coupled systems have been validated experimentally, a rigorous theoretical certification of their stability is currently missing. This work fills this gap by providing the first formal stability analysis for a generic class of floating rigid bodies subject to spurious forces. We introduce a canonical model and construct a Lyapunov-based proof establishing local exponential stability of the hovering equilibrium. Crucially, the analysis explicitly addresses the structural challenges - specifically the induced non-minimum-phase behavior - that prevent the application of standard cascade arguments.

</details>


### [177] [RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation](https://arxiv.org/abs/2602.10980)
*Yuhao Chen,Zhihao Zhan,Xiaoxin Lin,Zijian Song,Hao Liu,Qinhan Lyu,Yubo Zu,Xiao Chen,Zhiyuan Liu,Tao Pu,Tianshui Chen,Keze Wang,Liang Lin,Guangrun Wang*

Main category: cs.RO

TL;DR: 本研究提出了一个名为RADAR的新基准，旨在解决当前视觉-语言-动作（VLA）模型评估中存在的现实差距问题。RADAR通过整合真实的物理动力学、明确的空间推理任务和全自动化的3D评估流程，来更全面、可靠地评估VLA模型的泛化能力。研究结果表明，现有VLA模型在真实物理环境下的表现存在显著的脆弱性，尤其是在传感器噪声和空间推理方面。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在模拟环境或受限真实环境中表现出色，但在多样化的物理环境中泛化能力不足，存在“现实差距”。现有的基准测试存在三个主要问题：未能模拟真实世界动力学、忽视空间物理智能、缺乏可扩展的全自动评估。这阻碍了对VLA模型公平可靠的比较。

Method: 提出了RADAR基准，包含三个核心部分：1. 原则性的物理动力学套件，模拟真实世界中的动态变化；2. 专门的空间推理和物理理解任务；3. 基于3D度量的全自动化评估流程，无需人工干预。研究人员使用RADAR评估了多个先进的VLA模型。

Result: 在RADAR基准下，先进的VLA模型表现出显著的脆弱性。在面对适度的物理动力学（如传感器噪声）时，模型的3D IoU性能急剧下降，从0.261降至0.068。此外，模型在空间推理能力方面也表现出局限性。

Conclusion: RADAR基准是实现VLA模型在真实世界中可靠和可泛化评估的必要工具。现有VLA模型在应对现实世界的复杂性和不确定性时存在显著不足，尤其是在物理动力学和空间推理方面，这为未来VLA模型的研究指明了方向。

Abstract: VLA models have achieved remarkable progress in embodied intelligence; however, their evaluation remains largely confined to simulations or highly constrained real-world settings. This mismatch creates a substantial reality gap, where strong benchmark performance often masks poor generalization in diverse physical environments. We identify three systemic shortcomings in current benchmarking practices that hinder fair and reliable model comparison. (1) Existing benchmarks fail to model real-world dynamics, overlooking critical factors such as dynamic object configurations, robot initial states, lighting changes, and sensor noise. (2) Current protocols neglect spatial--physical intelligence, reducing evaluation to rote manipulation tasks that do not probe geometric reasoning. (3) The field lacks scalable fully autonomous evaluation, instead relying on simplistic 2D metrics that miss 3D spatial structure or on human-in-the-loop systems that are costly, biased, and unscalable. To address these limitations, we introduce RADAR (Real-world Autonomous Dynamics And Reasoning), a benchmark designed to systematically evaluate VLA generalization under realistic conditions. RADAR integrates three core components: (1) a principled suite of physical dynamics; (2) dedicated tasks that explicitly test spatial reasoning and physical understanding; and (3) a fully autonomous evaluation pipeline based on 3D metrics, eliminating the need for human supervision. We apply RADAR to audit multiple state-of-the-art VLA models and uncover severe fragility beneath their apparent competence. Performance drops precipitously under modest physical dynamics, with the expectation of 3D IoU declining from 0.261 to 0.068 under sensor noise. Moreover, models exhibit limited spatial reasoning capability. These findings position RADAR as a necessary bench toward reliable and generalizable real-world evaluation of VLA models.

</details>


### [178] [Scaling World Model for Hierarchical Manipulation Policies](https://arxiv.org/abs/2602.10983)
*Qian Long,Yueze Wang,Jiaxi Song,Junbo Zhang,Peiyan Li,Wenxuan Wang,Yuqi Wang,Haoyang Li,Shaoxuan Xie,Guocai Yao,Hanbo Zhang,Xinlong Wang,Zhongyuan Wang,Xuguang Lan,Huaping Liu,Xinghang Li*

Main category: cs.RO

TL;DR: 本文提出了一种名为 VISTA 的分层视觉-语言-动作 (VLA) 框架，它利用预训练的世界模型来分解复杂任务为子任务序列，并生成视觉目标，以提高机器人操控在未见过的物体和场景中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的 VLA 模型在分布外 (OOD) 设置下，尤其是在真实机器人数据有限的情况下，表现不稳定，存在泛化瓶颈。

Method: VISTA 框架包含一个高层规划器（世界模型）和一个低层执行器（VLA）。世界模型负责将任务分解为一系列带有目标图像的子任务，而 VLA 则根据文本和视觉指导生成动作序列。目标图像比纯文本目标提供了更具象化的指导。

Result: 在大量分布外场景中进行了验证，与纯文本目标相比，使用世界模型生成的视觉目标指导的 VLA 策略，在新场景中的性能从 14% 提升到 69%。该方法在分布外场景中显著优于现有基线。

Conclusion: VISTA 框架通过引入世界模型进行分层任务分解和视觉目标生成，有效解决了 VLA 模型在分布外场景下的泛化能力不足的问题，显著提升了机器人的鲁棒性和泛化性。

Abstract: Vision-Language-Action (VLA) models are promising for generalist robot manipulation but remain brittle in out-of-distribution (OOD) settings, especially with limited real-robot data. To resolve the generalization bottleneck, we introduce a hierarchical Vision-Language-Action framework \our{} that leverages the generalization of large-scale pre-trained world model for robust and generalizable VIsual Subgoal TAsk decomposition VISTA. Our hierarchical framework \our{} consists of a world model as the high-level planner and a VLA as the low-level executor. The high-level world model first divides manipulation tasks into subtask sequences with goal images, and the low-level policy follows the textual and visual guidance to generate action sequences. Compared to raw textual goal specification, these synthesized goal images provide visually and physically grounded details for low-level policies, making it feasible to generalize across unseen objects and novel scenarios. We validate both visual goal synthesis and our hierarchical VLA policies in massive out-of-distribution scenarios, and the performance of the same-structured VLA in novel scenarios could boost from 14% to 69% with the guidance generated by the world model. Results demonstrate that our method outperforms previous baselines with a clear margin, particularly in out-of-distribution scenarios. Project page: \href{https://vista-wm.github.io/}{https://vista-wm.github.io}

</details>


### [179] [Multi-Task Reinforcement Learning of Drone Aerobatics by Exploiting Geometric Symmetries](https://arxiv.org/abs/2602.10997)
*Zhanyu Guo,Zikang Yin,Guobin Zhu,Shiliang Guo,Shiyu Zhao*

Main category: cs.RO

TL;DR: 提出了一种名为GEAR的新型端到端多任务强化学习框架，该框架利用了MAV动力学的SO(2)旋转对称性，实现了高效、鲁棒的特技飞行控制，成功率达到98.85%。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习方法在数据效率和泛化能力方面存在不足，尤其是在需要单一策略掌握多种特技飞行动作的多任务场景下，这促使研究者探索更高效、更具泛化性的控制方法。

Method: 提出GEAR框架，包含：1. 利用MAV动力学SO(2)旋转对称性的几何等变策略网络；2. FiLM（Feature-wise Linear Modulation）机制进行任务调制；3. 多头Critic网络。

Result: GEAR在多种特技飞行任务上取得了98.85%的成功率，显著优于基线方法。在真实世界实验中，GEAR能够稳定执行多种特技动作，并能组合基本动作来完成复杂特技。

Conclusion: GEAR通过充分利用MAV动力学的对称性，提供了一种数据高效、鲁棒且统一的特技飞行控制框架，能够学习并执行多种多样的 aerobatic maneuvers。

Abstract: Flight control for autonomous micro aerial vehicles (MAVs) is evolving from steady flight near equilibrium points toward more aggressive aerobatic maneuvers, such as flips, rolls, and Power Loop. Although reinforcement learning (RL) has shown great potential in these tasks, conventional RL methods often suffer from low data efficiency and limited generalization. This challenge becomes more pronounced in multi-task scenarios where a single policy is required to master multiple maneuvers. In this paper, we propose a novel end-to-end multi-task reinforcement learning framework, called GEAR (Geometric Equivariant Aerobatics Reinforcement), which fully exploits the inherent SO(2) rotational symmetry in MAV dynamics and explicitly incorporates this property into the policy network architecture. By integrating an equivariant actor network, FiLM-based task modulation, and a multi-head critic, GEAR achieves both efficiency and flexibility in learning diverse aerobatic maneuvers, enabling a data-efficient, robust, and unified framework for aerobatic control. GEAR attains a 98.85\% success rate across various aerobatic tasks, significantly outperforming baseline methods. In real-world experiments, GEAR demonstrates stable execution of multiple maneuvers and the capability to combine basic motion primitives to complete complex aerobatics.

</details>


### [180] [ContactGaussian-WM: Learning Physics-Grounded World Model from Videos](https://arxiv.org/abs/2602.11021)
*Meizhong Wang,Wanxin Jin,Kun Cao,Lihua Xie,Yiguang Hong*

Main category: cs.RO

TL;DR: 提出了一种名为 ContactGaussian-WM 的可微分物理模型，可以从稀疏且包含大量接触的视频序列中学习复杂的物理规律，并在各种场景下表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法在数据稀疏和复杂接触动力学运动条件下，难以准确建模环境。

Method: 提出 ContactGaussian-WM，包含统一的视觉外观和碰撞几何高斯表示，以及端到端可微分的学习框架，通过闭式物理引擎推断物理属性。

Result: ContactGaussian-WM 在学习复杂场景时优于现有最先进方法，并展现出强大的泛化能力。

Conclusion: ContactGaussian-WM 能够从稀疏且包含大量接触的视频中学习物理规律，并在下游应用（如数据合成和实时 MPC）中具有实用价值。

Abstract: Developing world models that understand complex physical interactions is essential for advancing robotic planning and simulation.However, existing methods often struggle to accurately model the environment under conditions of data scarcity and complex contact-rich dynamic motion.To address these challenges, we propose ContactGaussian-WM, a differentiable physics-grounded rigid-body world model capable of learning intricate physical laws directly from sparse and contact-rich video sequences.Our framework consists of two core components: (1) a unified Gaussian representation for both visual appearance and collision geometry, and (2) an end-to-end differentiable learning framework that differentiates through a closed-form physics engine to infer physical properties from sparse visual observations.Extensive simulations and real-world evaluations demonstrate that ContactGaussian-WM outperforms state-of-the-art methods in learning complex scenarios, exhibiting robust generalization capabilities.Furthermore, we showcase the practical utility of our framework in downstream applications, including data synthesis and real-time MPC.

</details>


### [181] [SQ-CBF: Signed Distance Functions for Numerically Stable Superquadric-Based Safety Filtering](https://arxiv.org/abs/2602.11049)
*Haocheng Zhao,Lukas Brunke,Oliver Lagerquist,Siqi Zhou,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文提出了一种基于超二次体（Superquadrics, SQ）的机器人安全过滤新框架，通过使用符号距离函数（SDF）而非直接使用SQ的隐式函数作为控制屏障函数，解决了SQ隐式函数梯度条件不良导致的优化问题，提高了在复杂动态环境下的碰撞避免能力和任务效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于控制屏障函数的机器人安全过滤方法，在处理复杂几何形状时，常因底层几何表示的简化而导致保守或不足的碰撞覆盖。直接使用超二次体（SQ）的隐式函数作为屏障函数存在梯度条件不良的问题，影响了实时安全过滤的可靠性。

Method: 本文提出了一个SQ安全过滤框架，使用符号距离函数（SDF）作为控制屏障函数。由于通用SQ没有解析SDF，作者利用Gilbert-Johnson-Keerthi (GJK) 算法计算距离，并通过随机平滑（randomized smoothing）获取梯度。

Result: 在仿真和真实世界实验中，该框架在杂乱和非结构化场景中实现了持续的无碰撞操作。实验结果表明，该方法对挑战性几何形状、传感噪声和动态干扰具有鲁棒性，并提高了远程操作任务的效率。

Conclusion: 本文提出的基于SDF的SQ安全过滤框架解决了传统SQ隐式函数梯度问题，实现了在复杂几何环境下精确可靠的安全过滤，为应对真实世界环境的几何复杂性提供了一条有效途径。

Abstract: Ensuring safe robot operation in cluttered and dynamic environments remains a fundamental challenge. While control barrier functions provide an effective framework for real-time safety filtering, their performance critically depends on the underlying geometric representation, which is often simplified, leading to either overly conservative behavior or insufficient collision coverage. Superquadrics offer an expressive way to model complex shapes using a few primitives and are increasingly used for robot safety. To integrate this representation into collision avoidance, most existing approaches directly use their implicit functions as barrier candidates. However, we identify a critical but overlooked issue in this practice: the gradients of the implicit SQ function can become severely ill-conditioned, potentially rendering the optimization infeasible and undermining reliable real-time safety filtering. To address this issue, we formulate an SQ-based safety filtering framework that uses signed distance functions as barrier candidates. Since analytical SDFs are unavailable for general SQs, we compute distances using the efficient Gilbert-Johnson-Keerthi algorithm and obtain gradients via randomized smoothing. Extensive simulation and real-world experiments demonstrate consistent collision-free manipulation in cluttered and unstructured scenes, showing robustness to challenging geometries, sensing noise, and dynamic disturbances, while improving task efficiency in teleoperation tasks. These results highlight a pathway toward safety filters that remain precise and reliable under the geometric complexity of real-world environments.

</details>


### [182] [RISE: Self-Improving Robot Policy with Compositional World Model](https://arxiv.org/abs/2602.11075)
*Jiazhi Yang,Kunyang Lin,Jinwei Li,Wencong Zhang,Tianwei Lin,Longyan Wu,Zhizhong Su,Hao Zhao,Ya-Qin Zhang,Li Chen,Ping Luo,Xiangyu Yue,Hongyang Li*

Main category: cs.RO

TL;DR: 提出了一种名为RISE的机器人强化学习框架，通过“想象”进行训练，以解决在接触丰富和动态操作任务中VLA模型容易失效的问题，并在三个实际任务中取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在处理接触丰富和动态操作任务时存在脆弱性，而传统的在线强化学习（RL）由于安全风险、硬件成本和环境重置等问题难以在物理世界中有效应用。

Method: RISE框架的核心是一个“组合世界模型”，它包含两个部分：（1）一个可控的动力学模型，用于预测多视角下的未来状态；（2）一个进度价值模型，用于评估想象中的结果，并产生有信息量的优势值，以指导策略改进。这些组件被整合到一个闭环自改进流程中，在虚拟空间中生成模拟轨迹、估计优势并更新策略，从而避免了昂贵的物理交互。

Result: 在动态砖块分拣、背包打包和关盒三个具有挑战性的真实世界任务中，RISE相比现有技术取得了显著的性能提升，分别提高了+35%、+45%和+35%的绝对性能。

Conclusion: RISE是一个可扩展的机器人强化学习框架，通过使用组合世界模型进行“想象”训练，可以有效地提高VLA模型在接触丰富和动态操作任务中的鲁棒性和性能，且无需进行大量的物理交互。

Abstract: Despite the sustained scaling on model capacity and data acquisition, Vision-Language-Action (VLA) models remain brittle in contact-rich and dynamic manipulation tasks, where minor execution deviations can compound into failures. While reinforcement learning (RL) offers a principled path to robustness, on-policy RL in the physical world is constrained by safety risk, hardware cost, and environment reset. To bridge this gap, we present RISE, a scalable framework of robotic reinforcement learning via imagination. At its core is a Compositional World Model that (i) predicts multi-view future via a controllable dynamics model, and (ii) evaluates imagined outcomes with a progress value model, producing informative advantages for the policy improvement. Such compositional design allows state and value to be tailored by best-suited yet distinct architectures and objectives. These components are integrated into a closed-loop self-improving pipeline that continuously generates imaginary rollouts, estimates advantages, and updates the policy in imaginary space without costly physical interaction. Across three challenging real-world tasks, RISE yields significant improvement over prior art, with more than +35% absolute performance increase in dynamic brick sorting, +45% for backpack packing, and +35% for box closing, respectively.

</details>


### [183] [Digging for Data: Experiments in Rock Pile Characterization Using Only Proprioceptive Sensing in Excavation](https://arxiv.org/abs/2602.11082)
*Unal Artan,Martin Magnusson,Joshua A. Marshall*

Main category: cs.RO

TL;DR: 本文提出了一种仅使用轮式装载机挖掘过程中的本体感觉数据来估算岩石堆相对粒度的创新方法，避免了使用外部传感器。


<details>
  <summary>Details</summary>
Motivation: 在采矿和采石行业中，准确表征岩石堆的粒度对于后续处理至关重要。现有的方法通常依赖于外部传感器，而本研究旨在探索一种仅利用装载机自身运动数据的方法。

Method: 该方法基于小波分析，从轮式装载机挖掘过程中的本体感觉数据（例如惯性响应）中提取特征。通过计算不同岩石堆挖掘数据之间小波特征的比例，来近似估算岩石堆平均粒度的比例。

Result: 通过大量现场实验表明，该方法估算出的相对粒度比例与实际测量值（包括基于视觉的分析和筛分法）具有良好的一致性。

Conclusion: 仅利用轮式装载机挖掘过程中的本体感觉数据，通过小波分析可以有效地估算岩石堆的相对粒度，这为岩石粒度表征提供了一种无需外部传感器的新途径。

Abstract: Characterization of fragmented rock piles is a fundamental task in the mining and quarrying industries, where rock is fragmented by blasting, transported using wheel loaders, and then sent for further processing. This field report studies a novel method for estimating the relative particle size of fragmented rock piles from only proprioceptive data collected while digging with a wheel loader. Rather than employ exteroceptive sensors (e.g., cameras or LiDAR sensors) to estimate rock particle sizes, the studied method infers rock fragmentation from an excavator's inertial response during excavation. This paper expands on research that postulated the use of wavelet analysis to construct a unique feature that is proportional to the level of rock fragmentation. We demonstrate through extensive field experiments that the ratio of wavelet features, constructed from data obtained by excavating in different rock piles with different size distributions, approximates the ratio of the mean particle size of the two rock piles. Full-scale excavation experiments were performed with a battery electric, 18-tonne capacity, load-haul-dump (LHD) machine in representative conditions in an operating quarry. The relative particle size estimates generated with the proposed sensing methodology are compared with those obtained from both a vision-based fragmentation analysis tool and from sieving of sampled materials.

</details>


### [184] [Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows](https://arxiv.org/abs/2602.11142)
*Shaswat Garg,Matin Moezzi,Brandon Da Silva*

Main category: cs.RO

TL;DR: 提出了一种名为NF-HIQL的新型分层目标条件强化学习框架，它使用标准流（Normalizing Flow）来替代传统的单峰高斯策略，以提高数据效率和策略表达能力，并在多种任务中展现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的分层目标条件强化学习（H-GCRL）框架在处理复杂长时序任务时面临数据效率低下和策略表达能力有限的问题，尤其是在离线或数据稀疏的情况下。

Method: 引入了一种名为NF-HIQL的新型框架，该框架在分层结构的的高层和低层均采用表达能力强的标准流策略（Normalizing Flow policies）来替代单峰高斯策略。这种设计能够进行易于处理的对数似然计算、高效采样，并能模拟丰富的多模态行为。此外，还推导了新的理论保证，包括针对RealNVP策略的KL散度界限和PAC风格的样本效率结果。

Result: 在机器人运动、球类运球和多步操作等多种长时序任务上评估了NF-HIQL。结果表明，NF-HIQL在数据有限的情况下表现出优越的鲁棒性，并持续优于现有的目标条件和分层基线方法。

Conclusion: NF-HIQL通过使用标准流策略有效解决了H-GCRL在数据效率和策略表达能力方面的问题，展示了基于标准流的架构在可扩展、数据高效的分层强化学习中的潜力。

Abstract: Hierarchical goal-conditioned reinforcement learning (H-GCRL) provides a powerful framework for tackling complex, long-horizon tasks by decomposing them into structured subgoals. However, its practical adoption is hindered by poor data efficiency and limited policy expressivity, especially in offline or data-scarce regimes. In this work, Normalizing flow-based hierarchical implicit Q-learning (NF-HIQL), a novel framework that replaces unimodal gaussian policies with expressive normalizing flow policies at both the high- and low-levels of the hierarchy is introduced. This design enables tractable log-likelihood computation, efficient sampling, and the ability to model rich multimodal behaviors. New theoretical guarantees are derived, including explicit KL-divergence bounds for Real-valued non-volume preserving (RealNVP) policies and PAC-style sample efficiency results, showing that NF-HIQL preserves stability while improving generalization. Empirically, NF-HIQL is evaluted across diverse long-horizon tasks in locomotion, ball-dribbling, and multi-step manipulation from OGBench. NF-HIQL consistently outperforms prior goal-conditioned and hierarchical baselines, demonstrating superior robustness under limited data and highlighting the potential of flow-based architectures for scalable, data-efficient hierarchical reinforcement learning.

</details>


### [185] [A receding-horizon multi-contact motion planner for legged robots in challenging environments](https://arxiv.org/abs/2602.11113)
*Daniel S. J. Derwent,Simon Watson,Bruno V. Adorno*

Main category: cs.RO

TL;DR: 提出了一种新颖的、用于腿式机器人在复杂场景下（如烟囱攀爬、狭窄通道导航、跨越鸿沟）的递进式多接触运动规划器，该规划器能够同时规划接触点和全身轨迹，并能进行反应式重新规划，且在统计学上证明了其效率和运动质量的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有腿式机器人运动规划方法在应对烟囱攀爬、狭窄通道或跨越鸿沟等挑战性场景时能力有限，并且在集成接触点规划、全身轨迹生成以及反应式重新规划方面存在实现复杂、效率低下或易陷入局部最优等问题。因此，需要一种能够同时处理多接触、全身运动规划并具备反应式能力的通用方法。

Method: 提出了一种新的递进式（receding-horizon）多接触运动规划器，该方法能够同时规划接触点和全身轨迹。它通过二次规划（quadratic-program-based）的姿态生成器来快速获得规划节点，并能对新的信息进行反应式重新规划，从而避免了传统方法中常见的局部极小值问题。

Result: 在短规划视野下（例如，一步向前），该规划器比现有技术快45%-98%，但运动效率较低（步态转换次数增加5%-700%）。在长规划视野下（例如，四步向前），规划时间可能增加（73%快至400%慢），但运动质量更高（步态转换次数减少8%-47%）。

Conclusion: 该新型递进式多接触运动规划器在处理腿式机器人在复杂场景下的运动规划方面具有显著优势，通过调整规划视野，可以在规划速度和运动质量之间进行有效权衡，为解决实际机器人应用中的挑战提供了有力工具。

Abstract: We present a novel receding-horizon multi-contact motion planner for legged robots in challenging scenarios, able to plan motions such as chimney climbing, navigating very narrow passages or crossing large gaps. Our approach adds new capabilities to the state of the art, including the ability to reactively re-plan in response to new information, and planning contact locations and whole-body trajectories simultaneously, simplifying the implementation and removing the need for post-processing or complex multi-stage approaches. Our method is more resistant to local minima problems than other potential field based approaches, and our quadratic-program-based posture generator returns nodes more quickly than those of existing algorithms. Rigorous statistical analysis shows that, with short planning horizons (e.g., one step ahead), our planner is faster than the state-of-the-art across all scenarios tested (between 45% and 98% faster on average, depending on the scenario), while planning less efficient motions (requiring 5% fewer to 700% more stance changes on average). In all but one scenario (Chimney Walking), longer planning horizons (e.g., four steps ahead) extended the average planning times (between 73% faster and 400% slower than the state-of-the-art) but resulted in higher quality motion plans (between 8% more and 47% fewer stance changes than the state-of-the-art).

</details>


### [186] [APEX: Learning Adaptive High-Platform Traversal for Humanoid Robots](https://arxiv.org/abs/2602.11143)
*Yikai Wang,Tingxuan Leng,Changyi Lin,Shiqi Liu,Shir Simon,Bingqing Chen,Jonathan Francis,Ding Zhao*

Main category: cs.RO

TL;DR: 本文提出了APEX系统，一种基于爬升和感知能力的人形机器人高平台穿越方法，通过组合多种地形适应性行为，并采用一种新的奖励函数来解决现有RL方法在高平台穿越中的局限性，实现了0.8米高度的零样本跨平台能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度强化学习（DRL）的人形机器人运动控制方法在穿越高平台方面存在不足，倾向于学习高冲击、扭矩受限且不适合实际部署的跳跃式解决方案。因此，需要一种能够处理高平台穿越且安全可靠的控制方法。

Method: APEX系统通过组合多种地形条件下的行为（爬升、行走、爬行、站立、躺下）来实现高平台穿越。关键在于提出了一种广义的“棘轮式进度奖励”（generalized ratchet progress reward），用于学习富含接触且能够达成目标的机动动作，通过跟踪最佳任务进度并惩罚无改进的步骤来提供密集的、无速度依赖的监督信号，从而在强安全正则化下实现高效探索。感知方面，利用LiDAR数据训练全身动作策略，并通过建模映射伪影和对高程图进行滤波/修复来缩小仿真到现实的感知差距。最终，将所有技能提炼成一个单一策略，该策略能够根据局部几何和指令自主选择和转换行为。

Result: 在29自由度Unitree G1人形机器人上进行了实验，结果表明APEX系统实现了0.8米（约114%腿长）平台高度的零样本仿真到现实跨越能力，并且能够鲁棒地适应平台高度和初始姿态。同时，多技能之间的转换平滑稳定。

Conclusion: APEX系统成功地解决了人形机器人穿越高平台的问题，证明了其通过组合地形条件行为和改进的奖励函数，能够实现安全、鲁棒且高效的高平台穿越。该方法在仿真到现实的迁移以及多技能协调方面表现出色。

Abstract: Humanoid locomotion has advanced rapidly with deep reinforcement learning (DRL), enabling robust feet-based traversal over uneven terrain. Yet platforms beyond leg length remain largely out of reach because current RL training paradigms often converge to jumping-like solutions that are high-impact, torque-limited, and unsafe for real-world deployment. To address this gap, we propose APEX, a system for perceptive, climbing-based high-platform traversal that composes terrain-conditioned behaviors: climb-up and climb-down at vertical edges, walking or crawling on the platform, and stand-up and lie-down for posture reconfiguration. Central to our approach is a generalized ratchet progress reward for learning contact-rich, goal-reaching maneuvers. It tracks the best-so-far task progress and penalizes non-improving steps, providing dense yet velocity-free supervision that enables efficient exploration under strong safety regularization. Based on this formulation, we train LiDAR-based full-body maneuver policies and reduce the sim-to-real perception gap through a dual strategy: modeling mapping artifacts during training and applying filtering and inpainting to elevation maps during deployment. Finally, we distill all six skills into a single policy that autonomously selects behaviors and transitions based on local geometry and commands. Experiments on a 29-DoF Unitree G1 humanoid demonstrate zero-shot sim-to-real traversal of 0.8 meter platforms (approximately 114% of leg length), with robust adaptation to platform height and initial pose, as well as smooth and stable multi-skill transitions.

</details>


### [187] [YOR: Your Own Mobile Manipulator for Generalizable Robotics](https://arxiv.org/abs/2602.11150)
*Manan H Anjaria,Mehmet Enes Erciyes,Vedant Ghatnekar,Neha Navarkar,Haritheja Etukuru,Xiaole Jiang,Kanad Patel,Dhawal Kabra,Nicholas Wojno,Radhika Ajay Prayage,Soumith Chintala,Lerrel Pinto,Nur Muhammad Mahi Shafiullah,Zichen Jeff Cui*

Main category: cs.RO

TL;DR: 本文介绍了一款名为 YOR 的开源低成本移动机械臂平台，旨在以低于 10,000 美元的价格提供媲美昂贵平台的移动操作能力，并展示了其在导航和双臂操作方面的能力。


<details>
  <summary>Details</summary>
Motivation: 机器人学习的进步和低成本执行器的商品化促进了低成本机器人平台的发展，但对于经济实惠的移动操作的最佳形态仍然未知。

Method: 设计并构建了一个名为 YOR 的开源、低成本移动机械臂。该平台集成了全向移动底座、伸缩式垂直升降装置和双臂带夹具，实现了全身移动和操作。设计重点是模块化、易于组装（使用现成组件）和经济性。

Result: YOR 的物料清单成本低于 10,000 美元。实验证明，YOR 能够完成需要协调全身控制、双臂操作和自主导航的任务。

Conclusion: YOR 提供了一种经济实惠的解决方案，在移动操作研究领域具有竞争力，其功能可与现有昂贵平台相媲美，同时成本仅为其一小部分。

Abstract: Recent advances in robot learning have generated significant interest in capable platforms that may eventually approach human-level competence. This interest, combined with the commoditization of actuators, has propelled growth in low-cost robotic platforms. However, the optimal form factor for mobile manipulation, especially on a budget, remains an open question. We introduce YOR, an open-source, low-cost mobile manipulator that integrates an omnidirectional base, a telescopic vertical lift, and two arms with grippers to achieve whole-body mobility and manipulation. Our design emphasizes modularity, ease of assembly using off-the-shelf components, and affordability, with a bill-of-materials cost under 10,000 USD. We demonstrate YOR's capability by completing tasks that require coordinated whole-body control, bimanual manipulation, and autonomous navigation. Overall, YOR offers competitive functionality for mobile manipulation research at a fraction of the cost of existing platforms. Project website: https://www.yourownrobot.ai/

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [188] [Efficient Policy Adaptation for Voltage Control Under Unknown Topology Changes](https://arxiv.org/abs/2602.10355)
*Jie Feng,Yuanyuan Shi,Deepjyoti Deka*

Main category: eess.SY

TL;DR: 提出了一种拓扑感知的在线策略优化框架，通过数据驱动的电压-无功功率灵敏度估计来应对电力系统变化，并在IEEE 13节点和SCE 56节点系统上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）电压控制策略在系统条件（如拓扑重构和负载变化）变化时性能下降。

Method: 利用数据驱动的方法估计电压-无功功率灵敏度，并结合拓扑变化的稀疏性，实现快速的灵敏度更新和在线策略优化。该方法使用预训练的基于神经网络的RL控制器。

Result: 在IEEE 13节点和SCE 56节点系统上，该方法识别线路的准确率超过90%，仅需15个数据点。与非自适应策略和基于回归的在线优化方法相比，该方法显著提高了电压调节性能。

Conclusion: 提出的拓扑感知在线策略优化框架能够有效地适应电力系统的变化，并提升电压控制的性能。

Abstract: Reinforcement learning (RL) has shown great potential for designing voltage control policies, but their performance often degrades under changing system conditions such as topology reconfigurations and load variations. We introduce a topology-aware online policy optimization framework that leverages data-driven estimation of voltage-reactive power sensitivities to achieve efficient policy adaptation. Exploiting the sparsity of topology-switching events, where only a few lines change at a time, our method efficiently detects topology changes and identifies the affected lines and parameters, enabling fast and accurate sensitivity updates without recomputing the full sensitivity matrix. The estimated sensitivity is subsequently used for online policy optimization of a pre-trained neural-network-based RL controller. Simulations on both the IEEE 13-bus and SCE 56-bus systems demonstrate over 90 percent line identification accuracy, using only 15 data points. The proposed method also significantly improves voltage regulation performance compared with non-adaptive policies and adaptive policies that rely on regression-based online optimization methods for sensitivity estimation.

</details>


### [189] [Resilient Voltage Estimation for Battery Packs Using Self-Learning Koopman Operator](https://arxiv.org/abs/2602.10397)
*Sanchita Ghosh,Tanushree Roy*

Main category: eess.SY

TL;DR: 本文提出了一种基于Koopman算子和误差校正的云端电池管理系统（BMS）安全电压估计算法，该算法能够准确估计电池电压，即使在传感器受到攻击的情况下也能保证电动汽车（EV）的可靠充电。


<details>
  <summary>Details</summary>
Motivation: 现有的基于云的BMS依赖于实时电压测量数据来实现电动汽车（EV）与电网（V2G）技术的协调双向充电。然而，攻击者可以篡改传输过程中的测量数据，导致EV充电中断。因此，需要一种能够抵御此类传感器攻击并保证可靠电压数据的方案。

Method: 提出了一种两阶段误差校正的自学习Koopman算子安全电压估计算法。第一阶段补偿Koopman近似误差。第二阶段通过两种方法恢复由于缺乏高阶电池动力学信息而产生的误差：一种是适应性经验策略，利用开路电压-荷电状态（OCV-SOC）映射的电池级知识进行电池组级估算；另一种是基于高斯过程回归的数据驱动方法，利用少量数据进行训练。

Result: 在PyBaMM-liionpack高保真电池仿真包的案例研究中，所提出的安全估计器在不同的电池组拓扑、充电设置、电池老化程度和攻击策略下，都能可靠地生成高精度的实时电压估计。

Conclusion: 该算法具有可扩展性和适应性，可以轻松应用于不同的电池配置和操作条件，无需显著的修改、过多的数据或传感器冗余，从而在传感器受损的情况下确保EV的最佳充电。

Abstract: Cloud-based battery management systems (BMSs) rely on real-time voltage measurement data to ensure coordinated bi-directional charging of electric vehicles (EVs) with vehicle-to-grid technology. Unfortunately, an adversary can corrupt the measurement data during transmission from the local-BMS to the cloud-BMS, leading to disrupted EV charging. Therefore, to ensure reliable voltage data under such sensor attacks, this paper proposes a two-stage error-corrected self-learning Koopman operator-based secure voltage estimation scheme for large-format battery packs. The first stage of correction compensates for the Koopman approximation error. The second stage aims to recover the error amassing from the lack of higher-order battery dynamics information in the self-learning feedback, using two alternative methods: an adaptable empirical strategy that uses cell-level knowledge of open circuit voltage to state-of-charge mapping for pack-level estimation, and a Gaussian process regression-based data-driven method that leverages minimal data-training. During our comprehensive case studies using the high-fidelity battery simulation package 'PyBaMM-liionpack', our proposed secure estimator reliably generated real-time voltage estimation with high accuracy under varying pack topologies, charging settings, battery age-levels, and attack policies. Thus, the scalable and adaptable algorithm can be easily employed to diverse battery configurations and operating conditions, without requiring significant modifications, excessive data or sensor redundancy, to ensure optimum charging of EVs under compromised sensing.

</details>


### [190] [Scale-Free delta-Level Coherent Output Synchronization of Multi-Agent Systems with Adaptive Protocols and Bounded Disturbances](https://arxiv.org/abs/2602.10523)
*Anton A. Stoorvogel,Ali Saberi,Donya Nojavanzadeh*

Main category: eess.SY

TL;DR: 本文提出了一种自适应无标度框架，用于在有界扰动下实现多智能体系统（MAS）的无标度Delta级相干输出同步，该框架仅基于智能体模型知识，并且不依赖于通信拓扑或网络规模。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了在存在有界扰动或噪声的情况下，实现多智能体系统的输出同步，并且要求同步具有一定的“相干性”（coherency），即所有智能体的输出状态与其邻居状态的加权差异之和的范数应低于某个预设阈值Delta。同时，该方法不应依赖于对扰动的先验知识。

Method: 本文提出了一种自适应的无标度框架。该框架的特点是：1. 仅依赖于智能体模型知识。2. 对通信拓扑和网络规模完全不敏感（agnostic）。3. 定义了每个智能体的“相干度水平”（coherency level），即其与邻居状态的差异动力学（disagreement dynamics）的加权和的范数。4. 目标是使网络的相干度水平保持在阈值Delta以下，无需预先知道扰动的大小。

Result: 文章提出了一种能够在存在未知有界扰动的情况下，实现多智能体系统输出同步的方法。该方法能够保证所有智能体的相干度水平低于预设阈值Delta，并且在实现过程中不需要关于通信拓扑和网络规模的信息。

Conclusion: 研究成功提出了一种新颖的自适应无标度框架，能够有效地解决多智能体系统在存在界定扰动下的Delta级相干输出同步问题。该框架的优势在于其对通信拓扑和网络规模的鲁棒性，以及对扰动知识的无关性，这使得它在实际应用中具有广泛的潜力。

Abstract: In this paper, we investigate scale-free delta-level coherent output synchronization for multi-agent systems (MAS) operating under bounded disturbances or noises. We introduce an adaptive scale-free framework designed solely based on the knowledge of agent models and completely agnostic to both the communication topology and the size of the network. We define the level of coherency for each agent as the norm of the weighted sum of the disagreement dynamics with its neighbors. We define each agents coherency level as the norm of a weighted sum of its disagreement dynamics relative to its neighbors. The goal is to ensure that the networks coherency level remains below a prescribed threshold delta, without requiring any a priori knowledge of the disturbance.

</details>


### [191] [Rapid Boundary Stabilization of Two-Dimensional Elastic Plates with In-Domain Aeroelastic Instabilities](https://arxiv.org/abs/2602.10567)
*Xingzhi Huang,Ji Wang*

Main category: eess.SY

TL;DR: 本研究提出了一种针对二维弹性板在有界域内不稳定情况下的快速边界镇定策略，该策略通过PDE反步变换设计控制器和状态观测器，实现了指数稳定性，且衰减率可由用户任意指定。


<details>
  <summary>Details</summary>
Motivation: 高马赫数飞行中的主动颤振抑制。

Method: 通过活塞理论和Hamilton原理建立二维耦合波动PDE模型，利用傅里叶级数展开将二维问题分解为一系列一维系统，通过PDE反步变换设计全状态边界反馈控制器，并设计状态观测器实现输出反馈。

Result: 通过Lyapunov分析，证明了所提出的边界控制策略能够实现二维弹性板PDE的指数稳定性，且具有可调的衰减率。数值模拟验证了控制策略在抑制流动诱导振动方面的有效性。

Conclusion: 所提出的快速边界镇定策略能够有效地为存在内部不稳定性的二维弹性板提供指数稳定性，并允许用户自定义衰减率，为高马赫数飞行中的颤振抑制提供了一种有效方法。

Abstract: Motivated by active wing flutter suppression in high-Mach-number flight, this paper presents a rapid boundary stabilization strategy for a two-dimensional PDE-modeled elastic plate with in-domain instabilities, where the exponential stability is achieved with a decay rate that can be arbitrarily assigned by the users. First, the aeroelastic system is modeled as two-dimensional coupled wave PDEs with internal anti-damping terms, derived by Piston theory and Hamilton's principle. Using Fourier series expansion, the 2-D problem is decomposed into a parameterized family of 1-D systems. For each mode, a full-state boundary feedback controller is designed via PDE backstepping transformation. To enable output-feedback implementation, a state observer is further designed to estimate the distributed states over the two-dimensional spatial domain. Through Lyapunov analysis, the exponential stability of the 2-D elastic plate PDE under the proposed boundary control is established with a designer-tunable decay rate. Numerical simulations verify the effectiveness of the control strategy in suppressing flow-induced vibrations.

</details>


### [192] [Integrating Active Damping with Shaping-Filtered Reset Tracking Control for Piezo-Actuated Nanopositioning](https://arxiv.org/abs/2602.10724)
*Aditya Natu,Xiaozhe Hu,Hassan HosseinNia*

Main category: eess.SY

TL;DR: 本文提出了一种结合非最小相位谐振控制器（NRC）和带常数增益、前置相位（CgLp）重置元件的跟踪控制器，以克服压电纳米定位系统中的谐振和线性反馈增益-相位限制，并通过引入整形滤波器来优化重置行为，实验结果显示提高了交叉频率和闭环带宽。


<details>
  <summary>Details</summary>
Motivation: 压电纳米定位系统受限于轻微阻尼的结构共振和线性反馈的增益-相位约束，这限制了其带宽和跟踪性能。

Method: 提出了一种双环控制架构：内环采用非最小相位谐振控制器（NRC）进行主动阻尼；外环采用常数增益、前置相位（CgLp）重置元件增强的跟踪控制器，在目标交叉频率提供相位裕度而不增加环路增益。为解决CgLp设计不当引起的谐波失真问题，引入了整形滤波器来调节重置动作，抑制谐波效应。

Result: 实验表明，所提出的控制器实现了大约55 Hz的开环交叉频率提升和大约34 Hz的闭环带宽提升，优于调优良好的线性基线。

Conclusion: 所提出的双环控制架构结合NRC和CgLp重置控制器，并通过整形滤波器优化，能够有效提高压电纳米定位系统的带宽和跟踪性能，克服了传统线性控制器的局限性。

Abstract: Piezoelectric nanopositioning systems are often limited by lightly damped structural resonances and the gain--phase constraints of linear feedback, which restrict achievable bandwidth and tracking performance. This paper presents a dual-loop architecture that combines an inner-loop non-minimum-phase resonant controller (NRC) for active damping with an outer-loop tracking controller augmented by a constant-gain, lead-in-phase (CgLp) reset element to provide phase lead at the targeted crossover without increasing loop gain. We show that aggressively tuned CgLp designs with larger phase lead can introduce pronounced higher-order harmonics, degrading error sensitivity in specific frequency bands and causing multiple-reset behavior. To address this, a shaping filter is introduced in the reset-trigger path to regulate the reset action and suppress harmonic-induced effects while preserving the desired crossover-phase recovery. The proposed controllers are implemented in real time on an industrial piezo nanopositioner, demonstrating an experimental open-loop crossover increase of approximately 55~Hz and a closed-loop bandwidth improvement of about 34~Hz relative to a well-tuned linear baseline.

</details>


### [193] [Improving CACC Robustness to Parametric Uncertainty via Plant Equivalent Controller Realizations](https://arxiv.org/abs/2602.10752)
*Mischa Huisman,Thomas Arnold,Erjen Lefeber,Nathan van de Wouw,Carlos Murguia*

Main category: eess.SY

TL;DR: 本文提出了一种新的CACC鲁棒性改进方法，通过显式建模参数不确定性导致的动态失配，并将其转化为L2轨迹匹配问题，利用植物等效控制器（PEC）来优化控制策略，以提高CACC在参数不确定性下的稳定性和性能，尤其适用于异质车队。


<details>
  <summary>Details</summary>
Motivation: 传统的CACC控制器依赖于反馈线性化，假设车辆参数精确已知，但实际车辆动力学是非线性的且存在参数不确定性，导致模型失配和性能下降。

Method: 通过显式建模反馈线性化控制器与实际车辆动力学之间的失配，将鲁棒性问题转化为L2轨迹匹配问题，最小化失配能量。利用植物等效控制器（PEC）优化，通过线性矩阵不等式（LMIs）保证稳定性和性能，将其转化为凸优化问题。

Result: 所提出的方法可以在保留名义CACC行为的同时，显著提高CACC在参数不确定性下的鲁棒性和性能。实验结果验证了该方法的有效性。

Conclusion: 通过显式建模和优化植物等效控制器，可以有效提升CACC在参数不确定性下的鲁棒性，实现更可靠和高性能的车辆编队行驶，且适用于异质车队。

Abstract: Cooperative Adaptive Cruise Control (CACC) enables vehicle platooning through inter-vehicle communication, improving traffic efficiency and safety. Conventional CACC relies on feedback linearization, assuming exact vehicle parameters; however, longitudinal vehicle dynamics are nonlinear and subject to parametric uncertainty. Applying feedback linearization with a nominal model yields imperfect cancellation, leading to model mismatch and degraded performance with off-the-shelf CACC controllers. To improve robustness without redesigning the CACC law, we explicitly model the mismatch between the ideal closed-loop dynamics assumed by the CACC design and the actual dynamics under parametric uncertainties. Robustness is formulated as an $\mathcal{L}_2$ trajectory-matching problem, minimizing the energy of this mismatch to make the uncertain system behave as closely as possible to the ideal model. This objective is addressed by optimizing over plant equivalent controller (PEC) realizations that preserve the nominal closed-loop behavior while mitigating the effects of parametric uncertainty. Stability and performance are enforced via linear matrix inequalities, yielding a convex optimization problem applicable to heterogeneous platoons. Experimental results demonstrate improved robustness and performance under parametric uncertainty while preserving nominal CACC behavior.

</details>


### [194] [Reference Output Tracking in Boolean Control Networks](https://arxiv.org/abs/2602.10835)
*Giorgia Disarò,Maria Elena Valcher*

Main category: eess.SY

TL;DR: 本文研究布尔控制网络的轨迹跟踪问题，并提出处理有限长和周期性参考轨迹的方法，能处理任意初始条件并识别所有可能解。


<details>
  <summary>Details</summary>
Motivation: 解决布尔控制网络中跟踪给定参考输出轨迹的问题。

Method: 利用布尔控制网络的代数表示，扩展和调整了文献[17]中的分析和算法，以处理任意初始条件、识别所有可能解，并适应周期性参考轨迹。

Result: 开发了处理有限长参考轨迹的分析和算法，并将其扩展到周期性参考轨迹。

Conclusion: 所提出的方法能够有效地解决布尔控制网络的轨迹跟踪问题，并能够处理不同类型的参考轨迹和初始条件。

Abstract: In this paper, the problem of tracking a given reference output trajectory is investigated for the class of Boolean control networks, by resorting to their algebraic representation. First, the case of a finite-length reference trajectory is addressed, and the analysis and algorithm first proposed in [17] are extended to be able to deal with arbitrary initial conditions and to identify all possible solutions. The approach developed for the finite-length case is then adjusted to cope with periodic reference output trajectories. The results of the paper are illustrated through an example.

</details>


### [195] [Singular Port-Hamiltonian Systems Beyond Passivity](https://arxiv.org/abs/2602.10855)
*Henrik Sandberg,Kamil Hassan,Heng Wu*

Main category: eess.SY

TL;DR: 研究一类具有奇异向量场的端口哈密顿系统，并证明了其在与无源系统互联时能收敛到非平衡稳态。该系统的奇异性提供了维持该稳态所需的额外能量，而连续近似则使其变为周期耗散系统。


<details>
  <summary>Details</summary>
Motivation: 现有关于端口哈密顿系统（PHS）的研究主要关注其全局无源性，但实际应用（如电力电子中的并网控制器）中遇到的PHS可能具有奇异向量场，并且需要维持非平衡稳态。因此，需要研究这类奇异PHS的性质。

Method: 分析了具有奇异向量场的端口哈密顿系统的互联性质。通过数学推导和分析，证明了当这类PHS与无源系统互联时，能够收敛到非平衡稳态。同时，研究了向量场奇异性在维持非平衡稳态中的作用，并将其与连续近似下的周期耗散性质进行了对比。

Result: 证明了具有奇异向量场的端口哈密顿系统在与无源系统互联时，可以收敛到一个非平衡稳态。向量场的奇异性是维持该稳态的关键，提供了额外的能量。当奇异性被连续近似代替时，系统表现出周期耗散的特性，但仍能维持所需的功率。

Conclusion: 具有奇异向量场的端口哈密顿系统在与无源系统互联时，能够实现对非平衡稳态的控制。奇异性是该系统能够维持非平衡操作的能量来源，表明该系统并非全局无源。连续近似的向量场使系统具有周期耗散性，但仍能满足功率需求。

Abstract: In this paper, we study a class of port-Hamiltonian systems whose vector fields exhibit singularities. A representative example of this class has recently been employed in the power electronics literature to implement a grid-forming controller. We show that, under certain conditions, these port-Hamiltonian systems, when interconnected with passive systems, converge to a prescribed non-equilibrium steady state. At first glance, the apparently passive nature of the port-Hamiltonian system seems incompatible with the active power injection required to sustain this non-equilibrium condition. However, we demonstrate that the discontinuity inherent in the vector field provides the additional energy needed to maintain this operating point, indicating that the system is not globally passive. Moreover, when the discontinuity is replaced by a continuous approximation, the resulting system becomes cyclo-dissipative while still capable of supplying the required power.

</details>


### [196] [Backstepping Control of PDEs on Domains with Graph-Monotone Boundaries](https://arxiv.org/abs/2602.10876)
*Mohamed Camil Belhadjoudja*

Main category: eess.SY

TL;DR: 本文提出了一种针对非平行四边形区域上偏微分方程（PDE）背扣控制的新方法，无需使用传统的域扩展技术，并给出了一个钢琴形区域热方程的控制示例。


<details>
  <summary>Details</summary>
Motivation: 现有针对高维 PDE 的背扣控制方法受限，尤其是在非平行四边形区域和无对称性假设的情况下，域扩展技术存在计算复杂和后续问题（如输出反馈）难以处理等缺点。作者希望找到一种能保留一维背扣控制优点的替代方法。

Method: 通过对钢琴形区域上的热方程进行简单计算，作者表明域扩展技术并非必需，并提出了一种类似于平行四边形区域控制的策略。这预示了一个更广泛的框架，适用于具有图单调边界的非平行四边形区域上的背扣控制。

Result: 作者证明了在钢琴形区域控制热方程时，可以使用比域扩展技术更直接的方法，该方法类似于平行四边形区域的控制策略。

Conclusion: 对于某些具有图单调边界的非平行四边形区域上的 PDE，可以设计背扣控制器，而无需诉诸计算成本高的域扩展方法。这为解决更一般情况下的 PDE 背扣控制问题奠定了基础。

Abstract: Despite the extensive body of work on backstepping for one-dimensional PDEs, results in higher dimensions remain comparatively limited. Most available methods either exploit particular symmetries of the PDE or address problems posed on parallelepiped domains. To the best of our knowledge, the only approach that enables the design of backstepping controllers on non-parallelepiped regions without symmetry assumptions is the domain extension technique. This method, however, presents several drawbacks. In particular, the control input at each time instant is obtained by simulating a PDE on an extended domain, from which the actual input on the original domain is approximated. By contrast, in the one-dimensional setting, once the time-independent backstepping gain kernel is known, the control input can be computed in closed form as a feedback depending solely on the state at that same instant. Moreover, problems such as output-feedback design or adaptive and robust control do not appear straightforward to address with the domain extension method, at least to the best of our knowledge. These considerations motivate the search, whenever possible, for alternatives that preserve the main advantages of one-dimensional backstepping. A motivating example for the domain extension method is the control of the heat equation on a piano-shaped domain, with actuation applied at the tail of the piano. In this extended abstract, we show through a simple calculation that the domain extension method is not required in this setting. Instead, a strategy akin to that used for parallelepiped domains can be adopted. This result constitutes a first instance of a broader framework for backstepping control of asymmetric PDEs posed on non-parallelepiped regions, which we refer to as domains with graph-monotone boundaries. The general framework is developed in a forthcoming paper.

</details>


### [197] [Anomaly Detection with Machine Learning Algorithms in Large-Scale Power Grids](https://arxiv.org/abs/2602.10888)
*Marc Gillioz,Guillaume Dubuis,Étienne Voutaz,Philippe Jacquod*

Main category: eess.SY

TL;DR: 该研究应用机器学习算法检测大规模高压电网运行数据中的异常，发现神经网络表现优于K近邻和支持向量机，无监督学习算法效果显著且能应对并发异常。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模高压电网运行数据中的异常检测问题，并比较不同机器学习算法的性能。

Method: 应用了多种机器学习算法，包括神经网络、K近邻（KNN）、支持向量机（SVM）以及无监督学习算法。

Result: 神经网络在异常检测任务中通常优于KNN和SVM。无监督学习算法表现出色，并且其预测结果对同时发生的并发异常具有鲁棒性。

Conclusion: 神经网络和无监督学习算法是电网异常检测的有效方法，其中神经网络的优势在于能够捕捉异常的上下文信息，而无监督学习算法则在应对复杂异常情况时表现出良好的稳定性。

Abstract: We apply several machine learning algorithms to the problem of anomaly detection in operational data for large-scale, high-voltage electric power grids. We observe important differences in the performance of the algorithms. Neural networks typically outperform classical algorithms such as k-nearest neighbors and support vector machines, which we explain by the strong contextual nature of the anomalies. We show that unsupervised learning algorithm work remarkably well and that their predictions are robust against simultaneous, concurring anomalies.

</details>


### [198] [Trajectory-based data-driven predictive control and the state-space predictor](https://arxiv.org/abs/2602.10936)
*Levi D. Reyes Premer,Arash J. Khabbazi,Kevin J. Kircher*

Main category: eess.SY

TL;DR: 本文提出了一种名为轨迹预测控制（TPC）的数据驱动预测控制方法，它将输出轨迹表示为历史输入/输出和未来输入轨迹的线性函数。TPC 涵盖了多种现有的数据驱动预测控制方法，并引入了一种基于状态空间模型的轨迹预测器，该预测器具有更少的参数，在小数据集上表现优于其他方法，并且性能接近最优控制。


<details>
  <summary>Details</summary>
Motivation: 为了统一和改进现有的数据驱动预测控制（DDPC）方法，并探索其在不同轨迹预测器选择下的多样性，以及在训练数据有限情况下的性能。

Method: 定义了轨迹预测控制（TPC），将其视为一种输出反馈的间接DDPC方法。TPC 将输出轨迹建模为近期输入/输出历史和规划输入轨迹的线性函数。本文提出了一种基于近期输入/输出历史作为状态的线性状态空间模型作为轨迹预测器。通过这种预测器，TPC 成为线性模型预测控制（MPC）的特例。

Result: TPC 涵盖了 SPC、闭环 SPC、$γ$-DDPC、因果-$γ$-DDPC、瞬态预测控制等多种 DDPC 方法。所提出的基于状态空间模型的预测器在 TPC 中，使其能够继承成熟的 MPC 理论。数值实验表明，TPC 的性能接近具有完美模型知识的 $H_2$-最优控制。在小训练数据集下，状态空间预测器由于参数更少，性能优于其他预测器。

Conclusion: TPC 是一种统一多种 DDPC 方法的框架。基于状态空间模型的轨迹预测器能够让 TPC 继承 MPC 的理论基础，并在数据驱动控制中表现出良好的性能，尤其是在训练数据有限的情况下。

Abstract: We define trajectory predictive control (TPC) as a family of output-feedback indirect data-driven predictive control (DDPC) methods that represent the output trajectory of a discrete-time system as a linear function of the recent input/output history and the planned input trajectory. This paper shows that for different choices of the trajectory predictor, TPC encompasses a wide variety of DDPC methods, including subspace predictive control (SPC), closed-loop SPC, $γ$-DDPC, causal-$γ$-DDPC, transient predictive control, and others. This paper introduces a trajectory predictor that corresponds to a linear state-space model with the recent input/output history as the state. With this state-space predictor, TPC is a special case of linear model predictive control and therefore inherits its mature theory. In numerical experiments, TPC performance approaches the limit of oracle $H_2$-optimal control with perfect knowledge of the underlying system model. For TPC with small training datasets, the state-space predictor outperforms other predictors because it has fewer parameters.

</details>


### [199] [Lie Group Variational Integrator for the Geometrically Exact Rod with Circular Cross-Section Incorporating Cross-Sectional Deformation](https://arxiv.org/abs/2602.10963)
*Srishti Siddharth,Vivek Natarajan,Ravi N. Banavar*

Main category: eess.SY

TL;DR: 提出了一种考虑平面截面变形的三维几何精确杆（Cosserat 杆）的连续时空运动方程，并使用李群变分积分器技术获得了一种包含旋转运动和截面变形的离散模型。该离散模型通过局部膨胀因子考虑截面变形来保证体积守恒，并具备变分积分器固有的能量守恒和旋转构型保持等优点。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是开发一个能够精确描述三维几何精确杆（Cosserat 杆）运动的离散模型，该模型需要能够同时处理旋转运动和复杂的截面变形，并保持物理系统的基本属性，如体积守恒、能量守恒和旋转构型的准确性。

Method: 首先，推导了三维几何精确杆（Cosserat 杆）的连续时空运动方程，并纳入了平面截面变形。然后，采用李群变分积分器技术，将该连续模型离散化，同时考虑了旋转运动和截面变形。

Result: 开发了一种新的离散模型，该模型能够通过局部膨胀因子来保证离散单元的体积守恒，并且能够准确地保持旋转构型和能量守恒，误差有界。通过大量数值实验验证了该模型的有效性。

Conclusion: 该研究成功地提出了一种能够准确模拟考虑了平面截面变形的 Cosserat 杆动力学的离散模型，该模型具有体积守恒、能量守恒和旋转构型保持等优良特性，能够有效地复现物理系统的行为。

Abstract: In this paper, we derive the continuous space-time equations of motion of a three-dimensional geometrically exact rod, or the Cosserat rod, incorporating planar cross-sectional deformation. We then adopt the Lie group variational integrator technique to obtain a discrete model of the rod incorporating both rotational motion and cross-sectional deformation as well. The resulting discrete model possesses several desirable features: it ensures volume conservation of the discrete elements by considering cross-sectional deformation through a local dilatation factor, it demonstrates the beneficial properties associated with the variational integrator technique, such as the preservation of the rotational configuration, and energy conservation with a bounded error. An exhaustive set of numerical results under various initial conditions of the rod demonstrates the efficacy of the model in replicating the physics of the system.

</details>


### [200] [Deep Neural Network-Enhanced Frequency-Constrained Optimal Power Flow with Multi-Governor Dynamics](https://arxiv.org/abs/2602.11063)
*Fan Jiang,Xingpeng Li,Pascal Van Hentenryck*

Main category: eess.SY

TL;DR: 本文提出了一种基于深度神经网络（DNN）的频率约束最优潮流（DNN-FCOPF）方法，通过将DNN模型转化为混合整数线性规划（MILP）形式并嵌入FCOPF问题，以更准确地考虑电网频率动态，并与传统方法进行对比验证。


<details>
  <summary>Details</summary>
Motivation: 现有的实时频率约束最优潮流（FCOPF）难以精确建模复杂的非线性系统频率动态，导致对频率变化率（RoCoF）和频率最低点（FN）的约束不够准确，影响电网频率安全。

Method: 1. 使用深度神经网络（DNN）学习系统运行条件与关键频率性能指标（RoCoF, FN）之间的非线性映射关系，并利用PSCAD/EMTDC高保真时域仿真数据进行训练。 2. 将训练好的DNN模型转化为等效的混合整数线性规划（MILP）形式。 3. 将MILP形式的DNN模型作为附加约束嵌入FCOPF问题，形成DNN-FCOPF。 4. 设立两个对比模型：无频率约束的OPF，以及包含线性化RoCoF和FN约束的FCOPF。

Result: 通过在PSCAD/EMTDC中进行大量时域仿真，在不同负载场景下，DNN-FCOPF方法得到的解比另外两种对比方法更有效，能够更好地保证电网频率安全。

Conclusion: 所提出的DNN-FCOPF方法能够有效地捕捉和处理复杂的系统频率动态，将DNN模型转化为MILP形式并嵌入FCOPF问题是保证实时频率安全的一种可行且有效的方法。

Abstract: To ensure frequency security in power systems, both the rate of change of frequency (RoCoF) and the frequency nadir (FN) must be explicitly accounted for in real-time frequency-constrained optimal power flow (FCOPF). However, accurately modeling sys-tem frequency dynamics through analytical formulations is chal-lenging due to their inherent nonlinearity and complexity. To address this issue, deep neural networks (DNNs) are utilized to capture the nonlinear mapping between system operating condi-tions and key frequency performance metrics. In this paper, a DNN-based frequency prediction model is developed and trained using the high-fidelity time-domain simulation data generated in PSCAD/EMTDC. The trained DNN is subsequently transformed into an equivalent mixed-integer linear programming (MILP) form and embedded into the FCOPF problem as additional con-straints to explicitly enforce frequency security, leading to the proposed DNN-FCOPF formulation. For benchmarking, two alternative models are considered: a conventional optimal power flow without frequency constraints and a linearized FCOPF in-corporating system-level RoCoF and FN constraints. The effec-tiveness of the proposed method is demonstrated by comparing the solutions of these three models through extensive PSCAD/EMTDC time-domain simulations under various loading scenarios.

</details>


### [201] [Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing](https://arxiv.org/abs/2602.11076)
*Kavan Fatehi,Mostafa Rahmani Ghourtani,Amir Sonee,Poonam Yadav,Alessandra M Russo,Hamed Ahmadi,Radu Calinescu*

Main category: eess.SY

TL;DR: 提出了一种名为AE-MAPPO的增强型多智能体近端策略优化方法，用于解决6G无线接入网络（RAN）中异构切片服务水平协议（SLA）的延迟抖动问题，该方法整合了注意力机制，实现了零成本、可信的解释，并在URLLC场景下显著提高了可靠性和降低了故障排除时间。


<details>
  <summary>Details</summary>
Motivation: 传统的深度强化学习（DRL）和可解释强化学习（XRL）难以诊断和解决6G RAN中异构切片突发的延迟抖动问题，而6G网络需要严格遵守服务水平协议（SLAs）。

Method: 提出了一种名为“注意力增强型多智能体近端策略优化”（AE-MAPPO）的框架，该框架集成了六种专门的注意力机制，用于多智能体切片控制，并以零成本、可信的解释方式呈现。该框架在O-RAN的时间尺度上运行，采用三阶段策略：预测、反应和跨切片优化。

Result: 在URLLC案例研究中，AE-MAPPO在18毫秒内解决了延迟抖动问题，将延迟恢复到0.98毫秒，可靠性达到99.9999%，并将故障排除时间缩短了93%，同时保持了eMBB和mMTC的连续性。

Conclusion: AE-MAPPO能够结合SLA合规性与固有的可解释性，为6G RAN切片提供可信赖的实时自动化。

Abstract: Sixth-generation (6G) radio access networks (RANs) must enforce strict service-level agreements (SLAs) for heterogeneous slices, yet sudden latency spikes remain difficult to diagnose and resolve with conventional deep reinforcement learning (DRL) or explainable RL (XRL). We propose \emph{Attention-Enhanced Multi-Agent Proximal Policy Optimization (AE-MAPPO)}, which integrates six specialized attention mechanisms into multi-agent slice control and surfaces them as zero-cost, faithful explanations. The framework operates across O-RAN timescales with a three-phase strategy: predictive, reactive, and inter-slice optimization.
  A URLLC case study shows AE-MAPPO resolves a latency spike in $18$ms, restores latency to $0.98$ms with $99.9999\%$ reliability, and reduces troubleshooting time by $93\%$ while maintaining eMBB and mMTC continuity. These results confirm AE-MAPPO's ability to combine SLA compliance with inherent interpretability, enabling trustworthy and real-time automation for 6G RAN slicing.

</details>


### [202] [Credit-Based vs. Discount-Based Congestion Pricing: A Comparison Study](https://arxiv.org/abs/2602.11077)
*Chih-Yuan Chiu,Devansh Jalota,Marco Pavone*

Main category: eess.SY

TL;DR: 本文比较了基于信用（CBCP）和基于折扣（DBCP）的拥堵收费策略在降低用户成本和增加收费收入方面的优劣，发现DBCP在特定条件下优于CBCP，并通过旧金山101 Express Lanes项目的案例研究进行了验证。


<details>
  <summary>Details</summary>
Motivation: 当前关于CBCP和DBCP的实际应用较少，其相对优劣尚不明确，需要进行比较研究以指导政策制定。

Method: 通过建立一个非原子拥堵博弈模型，其中低收入用户可以获得旅行积分或通行费折扣，并证明了纳什均衡的存在性。利用凸规划方法计算或近似均衡流量，并推导了DBCP优于CBCP的理论条件。最后，通过旧金山101 Express Lanes项目的案例研究进行验证。

Result: 在某些实际相关的条件下，DBCP在诱导的均衡结果方面优于CBCP，能够更有效地降低用户成本并最大化通行费收入。案例研究验证了理论结果。

Conclusion: DBCP在特定条件下比CBCP更能实现降低用户成本和社会成本的目标，同时增加收费收入。研究结果为拥堵收费政策的设计提供了理论支持和实践指导。

Abstract: Credit-based congestion pricing (CBCP) and discount-based congestion pricing (DBCP), which respectively allot travel credits and toll discounts to subsidize low-income users' access to tolled roads, have emerged as promising policies for alleviating the societal inequity concerns of congestion pricing. However, since real-world implementations of CBCP and DBCP are nascent, their relative merits remain unclear. In this work, we compare the efficacy of deploying CBCP and DBCP in reducing user costs and increasing toll revenues. We first formulate a non-atomic congestion game in which low-income users receive a travel credit or toll discount for accessing tolled lanes. We establish that, in our formulation, Nash equilibrium flows always exist and can be computed or well approximated via convex programming. Our main result establishes a set of practically relevant conditions under which DBCP provably outperforms CBCP in inducing equilibrium outcomes that minimize a given societal cost, which encodes user cost reduction and toll revenue maximization. Finally, we validate our theoretical contributions via a case study of the 101 Express Lanes Project, a CBCP program implemented in the San Francisco Bay Area.

</details>


### [203] [Multi-UAV Trajectory Optimization for Bearing-Only Localization in GPS Denied Environments](https://arxiv.org/abs/2602.11116)
*Alfonso Sciacchitano,Liraz Mudrik,Sean Kragelund,Isaac Kaminer*

Main category: eess.SY

TL;DR: 提出了一种新的轨迹优化框架，使带有固定非万向摄像头的无人机能够与水面舰艇协同进行目标定位，解决了 GPS 拒绝环境下的挑战，并超越了使用单个万向摄像头的系统，同时降低了复杂性和成本。


<details>
  <summary>Details</summary>
Motivation: 在 GPS 拒绝环境下，使用无人机（UAV）对海上目标进行精确定位面临挑战。依赖万向型光电传感器的传统方法增加了机械复杂性、成本和单点故障的可能性，限制了多无人机操作的可扩展性和鲁棒性。

Method: 提出了一种新的轨迹优化框架，该框架使带有固定非万向摄像头的无人机能够与水面舰艇协同进行目标定位。该框架生成动态可行且考虑了任务约束、平台动力学以及画面外事件的“估计感知”轨迹。

Result: 与启发式路径相比，估计感知轨迹将定位误差减少了一倍以上。与单个万向摄像头系统相比，协同固定非万向摄像头无人机实现了同等或更高的定位精度。

Conclusion: 这项工作提出的估计感知轨迹优化框架，能够使具有固定非万向摄像头的无人机与水面舰艇协同进行目标定位，在降低系统复杂性和成本的同时，提高了定位精度、可扩展性和任务韧性。

Abstract: Accurate localization of maritime targets by unmanned aerial vehicles (UAVs) remains challenging in GPS-denied environments. UAVs equipped with gimballed electro-optical sensors are typically used to localize targets, however, reliance on these sensors increases mechanical complexity, cost, and susceptibility to single-point failures, limiting scalability and robustness in multi-UAV operations. This work presents a new trajectory optimization framework that enables cooperative target localization using UAVs with fixed, non-gimballed cameras operating in coordination with a surface vessel. This estimation-aware optimization generates dynamically feasible trajectories that explicitly account for mission constraints, platform dynamics, and out-of-frame events. Estimation-aware trajectories outperform heuristic paths by reducing localization error by more than a factor of two, motivating their use in cooperative operations. Results further demonstrate that coordinated UAVs with fixed, non-gimballed cameras achieve localization accuracy that meets or exceeds that of single gimballed systems, while substantially lowering system complexity and cost, enabling scalability, and enhancing mission resilience.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [204] [A Systematic Review on Data-Driven Brain Deformation Modeling for Image-Guided Neurosurgery](https://arxiv.org/abs/2602.10155)
*Tiago Assis,Colin P. Galvin,Joshua P. Castillo,Nazim Haouchine,Marta Kersten-Oertel,Zeyu Gao,Mireia Crispin-Ortuzar,Stephen J. Price,Thomas Santarius,Yangming Ou,Sarah Frisken,Nuno C. Garcia,Alexandra J. Golby,Reuben Dorent,Ines P. Machado*

Main category: eess.IV

TL;DR: 本篇综述系统性地分析了2020年1月至2025年4月期间，利用人工智能（AI）方法来模拟和纠正神经外科手术中脑部变形的最新进展。研究发现，虽然AI方法在性能和计算效率方面表现出色，但在鲁棒性、标准化评估、可解释性和临床应用方面仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 神经外科手术中，手术操作和肿瘤切除引起的脑部组织变形会导致术前规划图像与术中解剖结构失准，影响手术的精确性和纵向研究的可靠性。因此，准确补偿脑部变形是实现可靠的图像引导神经外科的关键挑战。

Method: 该研究采用系统性综述的方法，在PubMed、IEEE Xplore、Scopus和Web of Science等数据库中搜索了2020年1月至2025年4月期间关于利用AI方法进行脑部变形补偿的文献。筛选出41篇符合标准的研究，并对其方法学策略（如深度学习图像配准、直接形变场回归、合成驱动的多模态对齐、考虑切除的架构、融合生物力学先验的混合模型）、数据集使用、评估指标、验证协议以及不确定性和泛化性的评估进行了统一分析。

Result: AI驱动的脑部变形模型在性能和计算效率方面展现出潜力。然而，现有方法在处理分布外数据时的鲁棒性、标准化基准测试、模型可解释性以及临床应用准备度方面存在局限性。

Conclusion: AI在脑部变形补偿领域取得了显著进展，但要实现更稳健、更具泛化能力且可在临床上应用的方法，仍需在鲁棒性、标准化评估、可解释性和临床转化方面进行进一步研究。本综述为相关研究人员和临床医生提供了全面的基础，以指导未来的研究方向。

Abstract: Accurate compensation of brain deformation is a critical challenge for reliable image-guided neurosurgery, as surgical manipulation and tumor resection induce tissue motion that misaligns preoperative planning images with intraoperative anatomy and longitudinal studies. In this systematic review, we synthesize recent AI-driven approaches developed between January 2020 and April 2025 for modeling and correcting brain deformation. A comprehensive literature search was conducted in PubMed, IEEE Xplore, Scopus, and Web of Science, with predefined inclusion and exclusion criteria focused on computational methods applied to brain deformation compensation for neurosurgical imaging, resulting in 41 studies meeting these criteria. We provide a unified analysis of methodological strategies, including deep learning-based image registration, direct deformation field regression, synthesis-driven multimodal alignment, resection-aware architectures addressing missing correspondences, and hybrid models that integrate biomechanical priors. We also examine dataset utilization, reported evaluation metrics, validation protocols, and how uncertainty and generalization have been assessed across studies. While AI-based deformation models demonstrate promising performance and computational efficiency, current approaches exhibit limitations in out-of-distribution robustness, standardized benchmarking, interpretability, and readiness for clinical deployment. Our review highlights these gaps and outlines opportunities for future research aimed at achieving more robust, generalizable, and clinically translatable deformation compensation solutions for neurosurgical guidance. By organizing recent advances and critically evaluating evaluation practices, this work provides a comprehensive foundation for researchers and clinicians engaged in developing and applying AI-based brain deformation methods.

</details>


### [205] [Anatomy-Preserving Latent Diffusion for Generation of Brain Segmentation Masks with Ischemic Infarct](https://arxiv.org/abs/2602.10167)
*Lucia Borrego,Vajira Thambawita,Marco Ciuffreda,Ines del Val,Alejandro Dominguez,Josep Munuera*

Main category: eess.IV

TL;DR: 提出了一种无条件生成多类别脑部分割掩模（包括脑梗死）的框架，旨在解决医疗影像分析中高质量分割掩模稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 手动标注医疗影像（尤其是无对比剂 CT 脑部影像）成本高且变异性大，导致高质量分割掩模稀缺，这是医疗影像分析的主要瓶颈。

Method: 结合使用仅在分割掩模上训练的变分自编码器（VAE）来学习解剖学潜在表示，以及在潜在空间中运行的扩散模型来从纯噪声生成新样本。推理时，通过冻结的 VAE 解码器解码去噪后的潜在向量来获得合成掩模，并可通过二元提示对病灶存在进行粗略控制。

Result: 生成的分割掩模能够保留全局脑部解剖结构、离散组织语义和真实的变异性，并且避免了像素空间生成模型常见的结构伪影。

Conclusion: 该框架为数据稀缺的医疗影像场景提供了一种简单、可扩展的解剖学感知掩模生成解决方案。

Abstract: The scarcity of high-quality segmentation masks remains a major bottleneck for medical image analysis, particularly in non-contrast CT (NCCT) neuroimaging, where manual annotation is costly and variable. To address this limitation, we propose an anatomy-preserving generative framework for the unconditional synthesis of multi-class brain segmentation masks, including ischemic infarcts.
  The proposed approach combines a variational autoencoder trained exclusively on segmentation masks to learn an anatomical latent representation, with a diffusion model operating in this latent space to generate new samples from pure noise. At inference, synthetic masks are obtained by decoding denoised latent vectors through the frozen VAE decoder, with optional coarse control over lesion presence via a binary prompt.
  Qualitative results show that the generated masks preserve global brain anatomy, discrete tissue semantics, and realistic variability, while avoiding the structural artifacts commonly observed in pixel-space generative models. Overall, the proposed framework offers a simple and scalable solution for anatomy-aware mask generation in data-scarce medical imaging scenarios.

</details>


### [206] [Uncertainty-Aware Ordinal Deep Learning for cross-Dataset Diabetic Retinopathy Grading](https://arxiv.org/abs/2602.10315)
*Ali El Bellaj,Aya Benradi,Salman El Youssoufi,Taha El Marzouki,Mohammed-Amine Cheddadi*

Main category: eess.IV

TL;DR: 提出一种不确定性感知的深度学习框架，用于自动分级糖尿病视网膜病变（DR）的严重程度，该框架显式地模拟了疾病进展的序数性质，并在多领域训练集上进行了评估，结果表明该方法具有良好的泛化能力和有意义的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）是糖尿病最严重的并发症之一，早期准确的检测对于防止不可逆失明至关重要。现有方法在处理DR的序数性质和预测不确定性方面存在不足。

Method: 提出一个结合了卷积骨干网络、病灶查询注意力池化以及基于证据的Dirichlet序数回归头的不确定性感知深度学习框架。该模型采用序数证据损失和退火正则化进行训练。

Result: 在结合了APTOS、Messidor-2和EyePACS的部分数据集的跨领域训练设置下，该方法在保持具有竞争力的分类准确性和高二次加权Kappa的同时，能够提供有意义的不确定性估计，尤其是在低置信度的情况下。实验证明了该方法具有强大的跨数据集泛化能力。

Conclusion: 序数证据学习是实现鲁棒且临床可靠的糖尿病视网膜病变分级的一个有前景的方向。所提出的框架能够同时实现准确的严重程度预测和原则性的预测不确定性估计。

Abstract: Diabetes mellitus is a chronic metabolic disorder characterized by persistent hyperglycemia due to insufficient insulin production or impaired insulin utilization. One of its most severe complications is diabetic retinopathy (DR), a progressive retinal disease caused by microvascular damage, leading to hemorrhages, exudates, and potential vision loss. Early and reliable detection of DR is therefore critical for preventing irreversible blindness.
  In this work, we propose an uncertainty-aware deep learning framework for automated DR severity grading that explicitly models the ordinal nature of disease progression. Our approach combines a convolutional backbone with lesion-query attention pooling and an evidential Dirichlet-based ordinal regression head, enabling both accurate severity prediction and principled estimation of predictive uncertainty. The model is trained using an ordinal evidential loss with annealed regularization to encourage calibrated confidence under domain shift.
  We evaluate the proposed method on a multi-domain training setup combining APTOS, Messidor-2, and a subset of EyePACS fundus datasets. Experimental results demonstrate strong cross-dataset generalization, achieving competitive classification accuracy and high quadratic weighted kappa on held-out test sets, while providing meaningful uncertainty estimates for low-confidence cases. These results suggest that ordinal evidential learning is a promising direction for robust and clinically reliable diabetic retinopathy grading.

</details>


### [207] [Analyzing Model Misspecification in Quantitative MRI: Application to Perfusion ASL](https://arxiv.org/abs/2602.10336)
*Jiachen Wang,Jon Tamir,Adam Bush*

Main category: eess.IV

TL;DR: 本研究提出了一种评估定量MRI (qMRI)信号模型是否被错误设定的新框架。通过结合理论和实验方法，可以量化模型错误设定的程度，并以动脉自旋标记 (ASL) 为例进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的qMRI信号模型常常存在混淆且难以在体内进行验证。当信号模型与真实数据生成过程不匹配时，即模型被错误设定，会导致估计量的方差下界（MCRB）增加，最大似然估计（MLE）可能出现偏差和不一致。

Method: 研究提出了两种模型错误设定评估方法：1) 检查经验MCRB是否会随着重复测量次数的增加而渐近地逼近CRB；2) 比较来自两个大小相等的子集估计量的MLE，并评估其经验方差是否与理论CRB预测一致。研究以ASL为例进行了框架演示。

Result: 研究结果表明，在脑部，常用的ASL信号模型似乎是正确设定的；而在肾脏，该模型则表现出中度错误设定。

Conclusion: 提出的框架提供了一种通用且具有理论依据的方法，用于评估定量MRI中信号模型的有效性，有助于提高qMRI结果的可靠性。

Abstract: Quantitative MRI (qMRI) involves parameter estimation governed by an explicit signal model. However, these models are often confounded and difficult to validate in vivo. A model is misspecified when the assumed signal model differs from the true data-generating process. Under misspecification, the variance of any unbiased estimator is lower-bounded by the misspecified Cramer-Rao bound (MCRB), and maximum-likelihood estimates (MLE) may exhibit bias and inconsistency. Based on these principles, we assess misspecification in qMRI using two tests: (i) examining whether empirical MCRB asymptotically approaches the CRB as repeated measurements increase; (ii) comparing MLE estimates from two equal-sized subsets and evaluating whether their empirical variance aligns with theoretical CRB predictions. We demonstrate the framework using arterial spin labeling (ASL) as an illustrative example. Our result shows the commonly used ASL signal model appears to be specified in the brain and moderately misspecified in the kidney. The proposed framework offers a general, theoretically grounded approach for assessing model validity in quantitative MRI.

</details>


### [208] [Beyond Calibration: Confounding Pathology Limits Foundation Model Specificity in Abdominal Trauma CT](https://arxiv.org/abs/2602.10359)
*Jineel H Raythatha,Shuchang Ye,Jeremy Hsu,Jinman Kim*

Main category: eess.IV

TL;DR: 本文评估了基础模型在创伤性肠损伤诊断中的性能，发现其在类不平衡和异质性影像方面存在特异性下降问题，尤其是在存在其他腹部病变时。通过有监督训练可以减轻这种特异性下降。


<details>
  <summary>Details</summary>
Motivation: 在将基础模型应用于临床实践时，需要评估其在复合分布漂移下的性能，特别是当类别不平衡与异质影像外观共存时。创伤性肠损伤是一种罕见但死亡率高的诊断，其处理情况尤其能体现这一挑战。

Method: 研究人员使用了一个多中心的RSNA腹部创伤影像CT数据集，对两个基础模型（MedCLIP和RadDINO）与三个特定任务的模型（CNN、Transformer、Ensemble）进行了比较。通过在不同类型的阴性类别（无腹部病变 vs. 伴有实体器官损伤）上评估特异性来隔离阴性类别效应。

Result: 基础模型在鉴别能力上与特定任务模型相当，但在敏感性上更高，特异性上较低。所有模型在没有腹部病变的患者中表现出高特异性。然而，当存在实体器官损伤时，基础模型的特异性显著下降，而特定任务模型的下降幅度较小。

Conclusion: 基础模型在无需特定任务训练的情况下，其鉴别能力可媲美特定任务模型，但其特异性下降主要是由阴性类别的异质性混淆所致，而非仅仅是患病率的影响。对基础模型进行有监督训练可以逐步降低其对阴性类别异质性的敏感性，表明在临床应用前需要进行适应性调整。

Abstract: Purpose: Translating foundation models into clinical practice requires evaluating their performance under compound distribution shift, where severe class imbalance coexists with heterogeneous imaging appearances. This challenge is relevant for traumatic bowel injury, a rare but high-mortality diagnosis. We investigated whether specificity deficits in foundation models are associated with heterogeneity in the negative class. Methods: This retrospective study used the multi-institutional, RSNA Abdominal Traumatic Injury CT dataset (2019-2023), comprising scans from 23 centres. Two foundation models (MedCLIP, zero-shot; RadDINO, linear probe) were compared against three task-specific approaches (CNN, Transformer, Ensemble). Models were trained on 3,147 patients (2.3% bowel injury prevalence) and evaluated on an enriched 100-patient test set. To isolate negative-class effects, specificity was assessed in patients without bowel injury who had concurrent solid organ injury (n=58) versus no abdominal pathology (n=50). Results: Foundation models achieved equivalent discrimination to task-specific models (AUC, 0.64-0.68 versus 0.58-0.64) with higher sensitivity (79-91% vs 41-74%) but lower specificity (33-50% vs 50-88%). All models demonstrated high specificity in patients without abdominal pathology (84-100%). When solid organ injuries were present, specificity declined substantially for foundation models (50-51 percentage points) compared with smaller reductions of 12-41 percentage points for task-specific models. Conclusion: Foundation models matched task-specific discrimination without task-specific training, but their specificity deficits were driven primarily by confounding negative-class heterogeneity rather than prevalence alone. Susceptibility to negative-class heterogeneity decreased progressively with labelled training, suggesting adaptation is required before clinical implementation.

</details>


### [209] [Benchmarking Deep Learning and Statistical Target Detection Methods for PFM-1 Landmine Detection in UAV Hyperspectral Imagery](https://arxiv.org/abs/2602.10434)
*Sagar Lekhak,Prasanna Reddy Pulakurthi,Ramesh Bhatta,Emmett J. Ientilucci*

Main category: eess.IV

TL;DR: 该研究评估了四种经典的统计检测算法和一种基于轻量级光谱神经网络（Spectral-NN）的方法在无人机高光谱成像（HSI）土地雷探测中的性能。研究发布了用于标准化评估的数据集和地面真实掩码。结果表明，ACE算法在ROC曲线下面积（AUC）方面表现最佳（0.989），但对于稀疏目标，基于精确率的评估（PR和AP）更能体现 Spectral-NN 的优势，其AP最高。


<details>
  <summary>Details</summary>
Motivation: 缺乏用于无人机高光谱成像土地雷探测的标准化基准，导致难以进行可靠和可重复的评估。现有方法在处理稀疏目标时可能存在局限性。

Method: 评估了四种经典的统计检测算法（SAM, MF, ACE, CEM）和一种新提出的、使用参数Mish激活的轻量级光谱神经网络（Spectral-NN）用于PFM-1土地雷探测。研究发布了像素级二值地面真实掩码（目标/背景）。评估使用VNIR高光谱数据集，并采用ROC曲线、AUC、PR曲线和AP等指标。

Result: 所有方法在独立测试集上均取得了较高的ROC-AUC。ACE算法实现了最高的AUC（0.989）。然而，在精确率导向的评估中（PR和AP），Spectral-NN 优于经典探测器，取得了最高的AP。这表明ROC-AUC在目标像素极其稀疏的情况下可能具有误导性。

Conclusion: 对于可靠的无人机高光谱土地雷探测，需要注重精确率导向的评估、场景感知的基准测试以及学习型光谱模型。研究强调了在稀疏目标检测中，PR和AP指标的重要性，并肯定了Spectral-NN作为一种有前景的方法。

Abstract: In recent years, unmanned aerial vehicles (UAVs) equipped with imaging sensors and automated processing algorithms have emerged as a promising tool to accelerate large-area surveys while reducing risk to human operators. Although hyperspectral imaging (HSI) enables material discrimination using spectral signatures, standardized benchmarks for UAV-based landmine detection remain scarce. In this work, we present a systematic benchmark of four classical statistical detection algorithms, including Spectral Angle Mapper (SAM), Matched Filter (MF), Adaptive Cosine Estimator (ACE), and Constrained Energy Minimization (CEM), alongside a proposed lightweight Spectral Neural Network utilizing Parametric Mish activations for PFM-1 landmine detection. We also release pixel-level binary ground truth masks (target/background) to enable standardized, reproducible evaluation. Evaluations were conducted on inert PFM-1 targets across multiple scene crops using a recently released VNIR hyperspectral dataset. Metrics such as receiver operating characteristic (ROC) curve, area under the curve (AUC), precision-recall (PR) curve, and average precision (AP) were used. While all methods achieve high ROC-AUC on an independent test set, the ACE method observes the highest AUC of 0.989. However, because target pixels are extremely sparse relative to background, ROC-AUC alone can be misleading; under precision-focused evaluation (PR and AP), the Spectral-NN outperforms classical detectors, achieving the highest AP. These results emphasize the need for precision-focused evaluation, scene-aware benchmarking, and learning-based spectral models for reliable UAV-based hyperspectral landmine detection. The code and pixel-level annotations will be released.

</details>


### [210] [FPGA Implementation of Sketched LiDAR for a 192 x 128 SPAD Image Sensor](https://arxiv.org/abs/2602.10837)
*Zhenya Zang,Mike Davies,Istvan Gyongy*

Main category: eess.IV

TL;DR: 提出了一种基于多项式样条函数的FPGA硬件实现统计压缩算法，用于解决高分辨率SPAD阵列的数据传输瓶颈问题，实现了512倍压缩比，并可在FPGA上进行实时深度重建。


<details>
  <summary>Details</summary>
Motivation: 高分辨率SPAD阵列产生的数据速率极高（达数十GB/s），导致数据传输带宽成为关键挑战。

Method: 1. 软件端使用定点（FXP）算术和查找表（LUTs）优化多项式样条函数算法，消除显式加法、乘法和非线性运算。 2. 在FPGA上实现在线草图处理单元（SPEs），直接处理SPAD传感器的时间戳流。 3. 使用定制的LiDAR设备和192x128 SPAD阵列进行实验验证。

Result: 实现了512倍的压缩比，并可能进一步提高。实现了无直方图的在线高保真深度重建。

Conclusion: 该FPGA实现有效缓解了SPAD阵列的时间戳传输瓶颈，并且随着未来SPAD像素数量的增加，该方法具有良好的可扩展性。

Abstract: This study presents an efficient field-programmable gate array (FPGA) implementation of a polynomial spline function-based statistical compression algorithm designed to address the critical challenge of massive data transfer bandwidth in emerging high-spatial-resolution single-photon avalanche diode (SPAD) arrays, where data rates can reach tens of gigabytes per second. In our experiments, the proposed hardware implementation achieves a compression ratio of 512x compared with conventional histogram-based outputs, with the potential for further improvement. The algorithm is first optimized in software using fixed-point (FXP) arithmetic and look-up tables (LUTs) to eliminate explicit additions, multiplications, and non-linear operations. This enables a careful balance between accuracy and hardware resource utilization. Guided by this trade-off analysis, online sketch processing elements (SPEs) are implemented on an FPGA to directly process time-stamp streams from the SPAD sensor. The implementation is validated using a customized LiDAR setup with a 192 x 128-pixel SPAD array. This work demonstrates histogram-free online depth reconstruction with high fidelity, effectively alleviating the time-stamp transfer bottleneck of SPAD arrays and offering scalability as pixel counts continue to increase for future SPADs.

</details>


### [211] [Training-Free Stimulus Encoding for Retinal Implants via Sparse Projected Gradient Descent](https://arxiv.org/abs/2602.10906)
*Henning Konermann,Yuli Wu,Emil Mededovic,Volkmar Schulz,Peter Walter,Johannes Stegmaier*

Main category: eess.IV

TL;DR: 本研究提出了一种基于约束稀疏最小二乘问题的视网膜植入物编码方法，以提高视觉重建的保真度，并提出了一种高效的投影残差范数最速下降求解器来利用感知矩阵的稀疏性。


<details>
  <summary>Details</summary>
Motivation: 现有的视网膜植入物编码器分辨率低且存在患者特异性感知失真，现有方法（如下采样和线性亮度映射）不够理想。虽然神经网络方法能提高重建保真度，但需要训练且泛化能力有限。

Method: 将刺激编码建模为一个约束稀疏最小二乘问题，使用线性化的感知正向模型。利用感知矩阵的高度稀疏性，应用一种高效的投影残差范数最速下降求解器，该求解器能利用稀疏性并支持刺激约束。

Result: 在四种模拟患者和不同电极分辨率下进行仿真实验，与Lanczos下采样相比，在Fashion-MNIST数据集上，SSIM提高了0.265，PSNR提高了12.4 dB，MAE降低了81.4%。

Conclusion: 所提出的基于稀疏最小二乘和高效求解器的视网膜植入物编码方法能够显著提高视觉重建的保真度，优于现有方法。

Abstract: Retinal implants aim to restore functional vision despite photoreceptor degeneration, yet are fundamentally constrained by low resolution electrode arrays and patient-specific perceptual distortions. Most deployed encoders rely on task-agnostic downsampling and linear brightness-to-amplitude mappings, which are suboptimal under realistic perceptual models. While global inverse problems have been formulated as neural networks, such approaches can be fast at inference, and can achieve high reconstruction fidelity, but require training and have limited generalizability to arbitrary inputs. We cast stimulus encoding as a constrained sparse least-squares problem under a linearized perceptual forward model. Our key observation is that the resulting perception matrix can be highly sparse, depending on patient and implant configuration. Building on this, we apply an efficient projected residual norm steepest descent solver that exploits sparsity and supports stimulus bounds via projection. In silico experiments across four simulated patients and implant resolutions from $15\times15$ to $100\times100$ electrodes demonstrate improved reconstruction fidelity, with up to $+0.265$ SSIM increase, $+12.4\,\mathrm{dB}$ PSNR, and $81.4\%$ MAE reduction on Fashion-MNIST compared to Lanczos downsampling.

</details>
