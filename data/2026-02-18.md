<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 28]
- [cs.CV](#cs.CV) [Total: 43]
- [cs.CL](#cs.CL) [Total: 37]
- [cs.RO](#cs.RO) [Total: 30]
- [eess.SY](#eess.SY) [Total: 7]
- [eess.IV](#eess.IV) [Total: 3]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Attention-gated U-Net model for semantic segmentation of brain tumors and feature extraction for survival prognosis](https://arxiv.org/abs/2602.15067)
*Rut Pate,Snehal Rajput,Mehul S. Raval,Rupal A. Kapdi,Mohendra Roy*

Main category: cs.AI

TL;DR: 研究提出了一种基于注意力门控循环残差U-Net（R2U-Net）的三平面（2.5D）模型，用于改进脑肿瘤分割，并在BraTS2021验证集上实现了0.900的整个肿瘤（WT）分割Dice相似系数（DSC）。此外，该模型还用于生存天数预测，结合了人工神经网络（ANN），取得了45.71%的准确率。


<details>
  <summary>Details</summary>
Motivation: 胶质瘤治疗因其异质性和复杂的手术干预而具有挑战性，需要改进的脑肿瘤分割和预后预测方法。

Method: 研究开发了一种集成了残差、循环和三平面（2.5D）架构的注意力门控R2U-Net模型。对于生存天数预测，提取了64个特征，并使用ANN将其减少到28个。

Result: 在BraTS2021验证集上，整个肿瘤（WT）分割的Dice相似系数（DSC）达到0.900。生存天数预测方面，准确率为45.71%，均方误差（MSE）为108,318.128，Spearman秩相关系数（SRC）为0.338。

Conclusion: 提出的三平面R2U-Net模型在脑肿瘤分割方面表现出与领先模型相当的性能，并且能够有效辅助生存天数预测，为治疗规划提供潜在支持。

Abstract: Gliomas, among the most common primary brain tumors, vary widely in aggressiveness, prognosis, and histology, making treatment challenging due to complex and time-intensive surgical interventions. This study presents an Attention-Gated Recurrent Residual U-Net (R2U-Net) based Triplanar (2.5D) model for improved brain tumor segmentation. The proposed model enhances feature representation and segmentation accuracy by integrating residual, recurrent, and triplanar architectures while maintaining computational efficiency, potentially aiding in better treatment planning. The proposed method achieves a Dice Similarity Score (DSC) of 0.900 for Whole Tumor (WT) segmentation on the BraTS2021 validation set, demonstrating performance comparable to leading models. Additionally, the triplanar network extracts 64 features per planar model for survival days prediction, which are reduced to 28 using an Artificial Neural Network (ANN). This approach achieves an accuracy of 45.71%, a Mean Squared Error (MSE) of 108,318.128, and a Spearman Rank Correlation Coefficient (SRC) of 0.338 on the test dataset.

</details>


### [2] [ResearchGym: Evaluating Language Model Agents on Real-World AI Research](https://arxiv.org/abs/2602.15112)
*Aniketh Garikaparthi,Manasi Patwardhan,Arman Cohan*

Main category: cs.AI

TL;DR: 本文提出了ResearchGym，一个用于评估端到端AI研究能力的基准和执行环境。该环境包含五个重构的学术论文任务，涉及39个子任务。通过评估GPT-5驱动的AI代理，发现其在提出新颖假设、进行实验和超越人类基线方面存在显著的性能差距和不可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理评估主要集中在狭窄的任务上，缺乏对端到端研究能力的系统性评估。作者希望创建一个能够模拟真实科学研究过程的环境，以衡量AI在复杂、长时序研究任务中的能力。

Method: 作者从ICML、ICLR和ACL的五篇论文中提取数据集、评估工具和基线实现，但隐藏了论文提出的方法。将这些重构为五个容器化的任务环境，共包含39个子任务。AI代理需要在这些环境中提出假设、运行实验并尝试超越人类基线。作者使用GPT-5等大型语言模型作为代理进行评估。

Result: GPT-5驱动的AI代理在15次评估中仅有1次（6.7%）超越基线，平均完成率仅为26.5%。该代理表现出多种长时序失败模式，如不耐烦、时间资源管理不善、对弱假设过度自信、并行实验协调困难以及上下文长度限制。然而，在一次运行中，该代理成功解决了ICML 2025 Spotlight任务的一个实例。其他专有代理（Claude Code和Codex）也显示出类似的性能差距。

Conclusion: ResearchGym为系统评估和分析闭环研究中的自主代理提供了基础设施。当前的前沿AI代理虽然偶尔能达到最先进的性能，但其表现极不稳定，存在显著的能力-可靠性差距。未来的研究需要解决这些长期存在的失败模式，以提高AI在复杂研究任务中的可靠性。

Abstract: We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.

</details>


### [3] [da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems](https://arxiv.org/abs/2602.15158)
*Gabriel Rocha*

Main category: cs.AI

TL;DR: 本文提出了一种名为“da Costian-Tarskianism”的新方法来解决本体异质性问题，该方法基于“扩展后果系统”和“扩展开发图”的概念，并借鉴了 Carnapian-Goguenism、da Costa 和 Tarski 的思想。


<details>
  <summary>Details</summary>
Motivation: 解决本体异质性问题，即如何有效地关联和整合不同的本体。

Method: 提出“da Costian-Tarskianism”方法，引入“扩展后果系统”（通过本体公理扩展后果系统）和“扩展开发图”（通过形态射、fibring 和 splitting 关联本体）。

Result: 定义了处理本体异质性的新理论框架，并提出了关联本体的新工具。

Conclusion: 该方法为应用本体领域提供了新的视角，并指出了未来的研究方向。

Abstract: This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and Lücke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.

</details>


### [4] [Panini: Continual Learning in Token Space via Structured Memory](https://arxiv.org/abs/2602.15156)
*Shreyas Rajesh,Pavan Holur,Mehmet Yigit Turali,Chenda Duan,Vwani Roychowdhury*

Main category: cs.AI

TL;DR: 本文提出了一种名为Panini的非参数持续学习框架，通过将文档表示为生成式语义工作区（GSW），并检索推理链而非原始文档块，以提高检索增强生成（RAG）的效率和准确性，并在多个QA基准测试中取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG方法在处理新信息时存在效率低下（LLM重复推理相同文档）和引入不相关上下文（增加不支持的生成）的问题。研究动机是开发一种更高效、更可靠的方式，让语言模型能够推理其未训练过的内容。

Method: 提出了一种基于人机交互的非参数持续学习框架Panini。该框架将文档表示为生成式语义工作区（GSW），这是一个由问答对组成的实体和事件感知网络。在推理时，Panini仅遍历不断更新的GSW，检索最可能的推理链，而不是直接检索原始文档或文档块。

Result: 在六个QA基准测试中，Panini取得了平均最高的性能，比其他基线高出5%-7%。同时，Panini使用的答案-上下文Token数量减少了2-30倍，支持完全开源的管道，并减少了在精心设计的不可回答查询上的不支持答案。

Conclusion: 研究结果表明，在写入时高效准确地构建经验（通过GSW框架实现）可以在读取时带来效率和可靠性的提升。GSW框架能够有效地组织信息，从而提高语言模型在推理新内容时的准确性和效率。

Abstract: Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant subset at inference time for an LLM to reason over. However, this results in inefficient usage of test-time compute (LLM repeatedly reasons over the same documents); moreover, chunk retrieval can inject irrelevant context that increases unsupported generation. We propose a human-like non-parametric continual learning framework, where the base model remains fixed, and learning occurs by integrating each new experience into an external semantic memory state that accumulates and consolidates itself continually. We present Panini, which realizes this by representing documents as Generative Semantic Workspaces (GSW) -- an entity- and event-aware network of question-answer (QA) pairs, sufficient for an LLM to reconstruct the experienced situations and mine latent knowledge via reasoning-grounded inference chains on the network. Given a query, Panini only traverses the continually-updated GSW (not the verbatim documents or chunks), and retrieves the most likely inference chains. Across six QA benchmarks, Panini achieves the highest average performance, 5%-7% higher than other competitive baselines, while using 2-30x fewer answer-context tokens, supports fully open-source pipelines, and reduces unsupported answers on curated unanswerable queries. The results show that efficient and accurate structuring of experiences at write time -- as achieved by the GSW framework -- yields both efficiency and reliability gains at read time. Code is available at https://github.com/roychowdhuryresearch/gsw-memory.

</details>


### [5] [Protecting Language Models Against Unauthorized Distillation through Trace Rewriting](https://arxiv.org/abs/2602.15143)
*Xinhang Ma,William Yeoh,Ning Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 本文提出了一种通过修改教师模型生成的推理过程来阻止未经授权的知识蒸馏的方法，该方法可以降低蒸馏的有效性（抗蒸馏）并嵌入可验证的水印。


<details>
  <summary>Details</summary>
Motivation: 当前知识蒸馏技术被用于将大型语言模型（LLM）的能力转移到更小的模型，但这可能导致未经授权地利用开发前沿模型的成本和精力，因此需要开发一种阻止这种行为的方法。

Method: 研究人员提出了几种修改教师模型推理输出的方法，以实现抗蒸馏和API水印。这些方法包括利用LLM的改写能力和基于梯度的技术，同时确保答案的正确性和语义连贯性。

Result: 实验表明，一种简单的基于指令的改写方法在降低蒸馏有效性方面效果显著，同时保持甚至提升了教师模型的性能。此外，该方法还实现了高度可靠的水印检测，几乎没有误报。

Conclusion: 通过动态改写教师模型的推理过程，可以有效阻止未经授权的知识蒸馏，同时实现可靠的API水印，并且对教师模型的性能影响不大。

Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.

</details>


### [6] [Secure and Energy-Efficient Wireless Agentic AI Networks](https://arxiv.org/abs/2602.15212)
*Yuanyan Song,Kezhi Wang,Xinmian Xu*

Main category: cs.AI

TL;DR: 该论文提出了一种安全的无线智能体AI网络，通过一个 supervisor AI 和多个 worker AI 来提供服务质量（QoS），同时保护隐私。为了延长服务时间，论文设计了优化AI选择、基站波束成形和传输功率的能量最小化问题，并提出了ASC和LAW两种资源分配方案。


<details>
  <summary>Details</summary>
Motivation: 在提供AI推理服务时，需要保证服务质量（QoS）并同时保护用户私有知识和推理结果的机密性。此外，AI代理的能源消耗也是一个需要考虑的问题，以延长其服务时间。

Method: 提出了一种包含Supervisor AI和多个Worker AI的安全无线AI网络。Supervisor AI负责分配Worker AI进行协作推理，未被选中的AI充当干扰者。能量最小化问题被构建并分解为AI选择、基站波束成形和传输功率优化三个子问题。提出了两种解决方案：ASC（使用ADMM、SDR、SCA）和LAW（使用LLM优化器）。

Result: 提出的ASC和LAW方案可以将网络能耗降低高达59.1%。基于Qwen的实际系统验证表明，所提出的方案在各种公开基准测试中具有令人满意的推理准确性。

Conclusion: 所提出的安全无线智能体AI网络能够有效地在提供QoS的同时保护隐私，并通过优化的资源分配策略显著降低网络能耗，同时保持令人满意的推理准确性。

Abstract: In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor AI agent can dynamically assign other AI agents to participate in cooperative reasoning, while the unselected AI agents act as friendly jammers to degrade the eavesdropper's interception performance. To extend the service duration of AI agents, an energy minimization problem is formulated that jointly optimizes AI agent selection, base station (BS) beamforming, and AI agent transmission power, subject to latency and reasoning accuracy constraints. To address the formulated problem, we propose two resource allocation schemes, ASC and LAW, which first decompose it into three sub-problems. Specifically, ASC optimizes each sub-problem iteratively using the proposed alternating direction method of multipliers (ADMM)-based algorithm, semi-definite relaxation (SDR), and successive convex approximation (SCA), while LAW tackles each sub-problem using the proposed large language model (LLM) optimizer within an agentic workflow. The experimental results show that the proposed solutions can reduce network energy consumption by up to 59.1% compared to other benchmark schemes. Furthermore, the proposed schemes are validated using a practical agentic AI system based on Qwen, demonstrating satisfactory reasoning accuracy across various public benchmarks.

</details>


### [7] [Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models](https://arxiv.org/abs/2602.15248)
*Pavel Koptev,Vishnu Kumar,Konstantin Malkov,George Shapiro,Yury Vikhanov*

Main category: cs.AI

TL;DR: 该研究提出了一种利用人工智能和机器学习预测发票稀释（即发票金额与实际收款之间的差额）的方法，以补充传统的基于确定性算法的方法，并降低供应链金融中的非信用风险。


<details>
  <summary>Details</summary>
Motivation: 发票稀释是供应链金融中的一个重大风险来源，而传统的买方不可撤销付款承诺（IPU）方法可能会阻碍供应链金融的采用，特别是对于信用评级较低的买方。因此，需要一种更有效、更具数据驱动性的方法来预测和管理这种风险。

Method: 该研究构建了一个人工智能和机器学习框架，并使用跨越九个关键交易领域的生产数据集来评估其预测发票稀释的能力，旨在作为确定性算法的补充。

Result: 该研究通过利用人工智能和机器学习方法，有望更有效地预测发票稀释，从而为管理供应链金融中的风险提供新的解决方案。

Conclusion: 人工智能和机器学习方法可以有效地预测发票稀释，为供应链金融提供一种有价值的风险管理工具，可以补充或替代传统的IPU方法，从而提高效率并扩大供应链金融的适用范围。

Abstract: Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.

</details>


### [8] [Enhancing Diversity and Feasibility: Joint Population Synthesis from Multi-source Data Using Generative Models](https://arxiv.org/abs/2602.15270)
*Farbod Abbasi,Zachary Patterson,Bilal Farooq*

Main category: cs.AI

TL;DR: 本文提出了一种利用WGAN-GP同时集成和生成多源合成人口数据的新方法，以克服现有方法的局限性，并提高生成数据的多样性和可行性。


<details>
  <summary>Details</summary>
Motivation: 现有合成人口生成方法在处理多源数据集成和捕获复杂特征交互方面存在不足，并且难以处理采样零值和结构零值，从而限制了生成数据的多样性和可行性。

Method: 采用带有梯度惩罚的Wasserstein生成对抗网络（WGAN-GP）来同时集成和生成多源数据集。通过在生成器损失函数中引入逆梯度惩罚项来提高生成数据的多样性和可行性。使用召回率、精确率和F1分数来评估多样性和可行性，并采用统一的相似性评估指标。

Result: 提出的联合学习方法在召回率上提高了7%，精确率上提高了15%，优于顺序基线方法。正则化项进一步提高了多样性和可行性，召回率提高了10%，精确率提高了1%。联合方法在整体相似性得分上达到了88.1，高于顺序方法的84.6。

Conclusion: 该多源联合生成方法能够显著提高合成人口数据的多样性和可行性，从而有望提升基于代理的模型（ABM）在交通和城市规划领域的准确性和可靠性。

Abstract: Generating realistic synthetic populations is essential for agent-based models (ABM) in transportation and urban planning. Current methods face two major limitations. First, many rely on a single dataset or follow a sequential data fusion and generation process, which means they fail to capture the complex interplay between features. Second, these approaches struggle with sampling zeros (valid but unobserved attribute combinations) and structural zeros (infeasible combinations due to logical constraints), which reduce the diversity and feasibility of the generated data. This study proposes a novel method to simultaneously integrate and synthesize multi-source datasets using a Wasserstein Generative Adversarial Network (WGAN) with gradient penalty. This joint learning method improves both the diversity and feasibility of synthetic data by defining a regularization term (inverse gradient penalty) for the generator loss function. For the evaluation, we implement a unified evaluation metric for similarity, and place special emphasis on measuring diversity and feasibility through recall, precision, and the F1 score. Results show that the proposed joint approach outperforms the sequential baseline, with recall increasing by 7\% and precision by 15\%. Additionally, the regularization term further improves diversity and feasibility, reflected in a 10\% increase in recall and 1\% in precision. We assess similarity distributions using a five-metric score. The joint approach performs better overall, and reaches a score of 88.1 compared to 84.6 for the sequential method. Since synthetic populations serve as a key input for ABM, this multi-source generative approach has the potential to significantly enhance the accuracy and reliability of ABM.

</details>


### [9] [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173)
*Luise Ge,Yongyan Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 研究发现，大型语言模型（LLMs）在不确定性下的决策行为可分为两类：推理模型（RMs）和对话模型（CMs）。RMs更倾向于理性决策，而CMs的决策更易受呈现方式、信息顺序和解释的影响，且更接近人类的非理性行为。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型在不确定性下决策行为的理解有限，而LLMs在数字生态系统中扮演着越来越重要的角色。

Method: 通过比较20种前沿和开源LLMs在两种维度（前景表示：显式 vs. 基于经验；决策理由：解释）上的风险选择，并与人类受试者实验和期望收益最大化的理性代理模型进行对比。

Result: LLMs可分为RMs和CMs两类。RMs决策更理性，不受前景顺序、损益框架和解释影响，无论前景是显式还是基于经验。CMs决策不那么理性，更像人类，受前景顺序、框架和解释影响，且在显式和基于经验表示之间存在显著差异。训练用于数学推理是区分RMs和CMs的关键因素。

Conclusion: LLMs的决策模式存在显著差异，其中数学推理能力是区分更理性（RM）和更易受干扰（CM）模型的重要因素。CMs的行为更接近人类，更容易受到认知偏差的影响。

Abstract: The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.

</details>


### [10] [When Remembering and Planning are Worth it: Navigating under Change](https://arxiv.org/abs/2602.15274)
*Omid Madani,J. Brian Burns,Reza Eghbali,Thomas L. Dean*

Main category: cs.AI

TL;DR: 研究了不同类型的记忆和记忆使用方式如何帮助代理在不断变化且不确定的环境中进行空间导航，发现结合多种策略的架构，特别是利用非平稳概率学习来更新和利用经验记忆构建地图并即时规划的代理，比简单记忆代理更有效。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索如何在复杂、不确定和动态变化的环境中，通过不同类型的记忆和学习策略来增强空间导航能力。

Method: 研究采用了一个简单的觅食任务作为范例，让代理每天从家出发，穿过障碍物寻找食物。环境是非平稳的，障碍物和食物的位置会变化，代理的感知（如位置信息）存在不确定性和局限性。研究评估了多种策略，包括具有不同记忆使用方式和学习能力的策略，特别是结合了非平稳概率学习来更新和利用经验记忆来构建不完美地图并进行即时规划的代理。

Result: 研究发现，单一策略不足以应对所有子任务，需要一个能够整合多种策略的架构。利用非平稳概率学习更新经验记忆，并用这些记忆构建不完美地图（有噪声且仅限于代理经验）并进行即时规划的代理，在任务难度（如与目标的距离）增加时，比最小记忆代理效率显著提高，前提是环境的不确定性（来自定位和变化）不太大。

Conclusion: 在一个变化且不确定的环境中，结合多种策略的导航架构，特别是那些能够快速学习和适应的架构，对于实现高效的空间导航至关重要。利用非平稳概率学习和经验记忆来构建和规划是应对复杂导航挑战的有效方法。

Abstract: We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.

</details>


### [11] [EAA: Automating materials characterization with vision language model agents](https://arxiv.org/abs/2602.15294)
*Ming Du,Yanqi Luo,Srutarshi Banerjee,Michael Wojcik,Jelena Popovic,Mathew J. Cherukara*

Main category: cs.AI

TL;DR: 提出了一种名为 EAA 的基于视觉-语言模型的代理系统，用于自动化复杂的显微镜实验流程，支持自主和用户指导的操作，并能与现有工具生态系统兼容。


<details>
  <summary>Details</summary>
Motivation: 旨在自动化复杂的显微镜实验流程，提高效率，减轻操作负担，并降低用户的使用门槛。

Method: EAA 集成了多模态推理、工具增强动作和可选的长期记忆。采用灵活的任务管理器架构，支持全自主或逻辑定义的程序，并支持 Model Context Protocol (MCP) 进行工具兼容。

Result: 在先进光子源成像线站成功演示了 EAA，包括自动区域板聚焦、自然语言描述的特征搜索以及交互式数据采集。

Conclusion: 具备视觉能力的代理（如 EAA）可以显著提高线站效率，减轻操作负担，并降低用户对专业知识的要求。

Abstract: We present Experiment Automation Agents (EAA), a vision-language-model-driven agentic system designed to automate complex experimental microscopy workflows. EAA integrates multimodal reasoning, tool-augmented action, and optional long-term memory to support both autonomous procedures and interactive user-guided measurements. Built on a flexible task-manager architecture, the system enables workflows ranging from fully agent-driven automation to logic-defined routines that embed localized LLM queries. EAA further provides a modern tool ecosystem with two-way compatibility for Model Context Protocol (MCP), allowing instrument-control tools to be consumed or served across applications. We demonstrate EAA at an imaging beamline at the Advanced Photon Source, including automated zone plate focusing, natural language-described feature search, and interactive data acquisition. These results illustrate how vision-capable agents can enhance beamline efficiency, reduce operational burden, and lower the expertise barrier for users.

</details>


### [12] [X-MAP: eXplainable Misclassification Analysis and Profiling for Spam and Phishing Detection](https://arxiv.org/abs/2602.15298)
*Qi Zhang,Dian Chen,Lance M. Kaplan,Audun Jøsang,Dong Hyun Jeong,Feng Chen,Jin-Hee Cho*

Main category: cs.AI

TL;DR: 本文提出了X-MAP框架，通过结合SHAP和NMF，揭示了垃圾邮件和钓鱼邮件检测模型错误分类背后的主题级语义模式，并利用此框架来检测错误分类和修复模型。


<details>
  <summary>Details</summary>
Motivation: 现有的基于不确定性的垃圾邮件和钓鱼邮件检测方法存在被欺骗和可解释性有限的问题，导致误报和漏报对用户造成危害。

Method: X-MAP结合了SHAP特征归因和非负矩阵分解（NMF），构建了可解释的主题模型，用于区分被正确分类的垃圾邮件/钓鱼邮件和正常邮件。通过Jensen-Shannon散度衡量每条消息与这些主题模型的偏离程度。

Result: 在SMS和钓鱼邮件数据集上的实验表明，被错误分类的消息与正确分类的消息相比，其Jensen-Shannon散度至少大两倍。X-MAP作为检测器，AUROC最高可达0.98，并在95%的真实率为正的情况下，将错误拒绝率降低到0.089。作为修复层，X-MAP可以恢复高达97%的被错误拒绝的正确预测。

Conclusion: X-MAP框架在提高垃圾邮件和钓鱼邮件检测的准确性和可解释性方面是有效的，能够识别模型错误并进行修复。

Abstract: Misclassifications in spam and phishing detection are very harmful, as false negatives expose users to attacks while false positives degrade trust. Existing uncertainty-based detectors can flag potential errors, but possibly be deceived and offer limited interpretability. This paper presents X-MAP, an eXplainable Misclassification Analysis and Profilling framework that reveals topic-level semantic patterns behind model failures. X-MAP combines SHAP-based feature attributions with non-negative matrix factorization to build interpretable topic profiles for reliably classified spam/phishing and legitimate messages, and measures each message's deviation from these profiles using Jensen-Shannon divergence. Experiments on SMS and phishing datasets show that misclassified messages exhibit at least two times larger divergence than correctly classified ones. As a detector, X-MAP achieves up to 0.98 AUROC and lowers the false-rejection rate at 95% TRR to 0.089 on positive predictions. When used as a repair layer on base detectors, it recovers up to 97% of falsely rejected correct predictions with moderate leakage. These results demonstrate X-MAP's effectiveness and interpretability for improving spam and phishing detection.

</details>


### [13] [AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents](https://arxiv.org/abs/2602.15325)
*Zhixing Zhang,Jesen Zhang,Hao Liu,Qinhan Lv,Jing Yang,Kaitong Cai,Keze Wang*

Main category: cs.AI

TL;DR: 本文提出了一种结合大语言模型（LLM）和农业科学特定工具的智能体框架Agro-Reflective，用于处理高维异构农业数据，实现语言驱动的农业推理和交互。该框架通过一个Python执行环境AgriWorld提供地理空间查询、遥感分析、作物生长模拟等工具，并利用“执行-观察-反思”的循环机制使LLM能够迭代地编写代码、观察结果并优化分析。在AgroBench数据集上的实验表明，该方法在多样的农业问答任务上优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的农业领域基础模型虽然在预测和监测方面表现出色，但缺乏语言推理和交互能力，限制了其在实际农学工作流程中的应用。而大语言模型虽然擅长文本处理，但无法直接处理高维、异构的农业数据。因此，研究的动机在于弥合这两者之间的差距，使LLM能够理解和操作农业数据。

Method: 研究者设计了一个名为Agro-Reflective的LLM智能体框架，该框架建立在名为AgriWorld的Python执行环境之上。AgriWorld提供了统一的工具集，用于地理空间查询、遥感时间序列分析、作物生长模拟以及特定任务预测（如产量、胁迫和疾病风险）。Agro-Reflective智能体通过一个“执行-观察-反思”的循环机制工作：LLM生成Python代码，代码在AgriWorld环境中执行，智能体观察执行结果，并根据结果进行反思和代码优化，以实现迭代式分析。

Result: 在AgroBench数据集（包含查找、预测、异常检测和反事实“假设”分析等多样化农业问答任务）上进行的实验结果表明，Agro-Reflective智能体框架在性能上优于仅使用文本的模型以及直接使用工具的模型。这验证了执行驱动的反思机制在实现可靠农业推理方面的有效性。

Conclusion: Agro-Reflective框架成功地将LLM的语言理解能力与农业科学的特定工具相结合，通过“执行-观察-反思”的循环实现了对高维异构农业数据的有效推理。该框架能够支持复杂的农业问答任务，为农业科学的智能化决策和应用提供了新的途径。

Abstract: Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-dimensional, heterogeneous agricultural datasets. We bridge this gap with an agentic framework for agricultural science. It provides a Python execution environment, AgriWorld, exposing unified tools for geospatial queries over field parcels, remote-sensing time-series analytics, crop growth simulation, and task-specific predictors (e.g., yield, stress, and disease risk). On top of this environment, we design a multi-turn LLM agent, Agro-Reflective, that iteratively writes code, observes execution results, and refines its analysis via an execute-observe-refine loop. We introduce AgroBench, with scalable data generation for diverse agricultural QA spanning lookups, forecasting, anomaly detection, and counterfactual "what-if" analysis. Experiments outperform text-only and direct tool-use baselines, validating execution-driven reflection for reliable agricultural reasoning.

</details>


### [14] [World-Model-Augmented Web Agents with Action Correction](https://arxiv.org/abs/2602.15384)
*Zhouzhou Shen,Xueyu Hu,Xiyun Li,Tianqing Fang,Juncheng Li,Shengyu Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为WAC的网络代理，通过模型协作、后果模拟和反馈驱动的行动优化来解决当前网络代理在预测环境变化和风险意识方面的不足，提高了任务执行的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型的网络代理在执行网络任务时，存在预测环境变化能力有限、对执行风险认识不足的问题，容易导致任务失败和损失。作者希望通过改进网络代理的设计来克服这些挑战。

Method: WAC通过以下三个方面来解决问题：1. **模型协作**: 引入多智能体协作，让行动模型向作为网络环境专家的世界模型咨询策略指导，然后根据环境状态转移动力学将建议转化为可执行的行动。2. **后果模拟**: 世界模型模拟行动结果，并由裁判模型审查，在必要时触发纠正反馈。3. **反馈驱动的行动优化**: 通过模拟和审查机制，对行动进行迭代优化。

Result: 在VisualWebArena数据集上，WAC取得了1.8%的绝对提升；在Online-Mind2Web数据集上，WAC取得了1.3%的绝对提升。

Conclusion: WAC通过整合模型协作、后果模拟和反馈驱动的行动优化，有效地提升了网络代理在执行复杂网络任务时的鲁棒性和成功率，尤其是在处理潜在风险和环境不确定性方面。

Abstract: Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not possess comprehensive awareness of execution risks, prematurely performing risky actions that cause losses and lead to task failure. To address these challenges, we propose WAC, a web agent that integrates model collaboration, consequence simulation, and feedback-driven action refinement. To overcome the cognitive isolation of individual models, we introduce a multi-agent collaboration process that enables an action model to consult a world model as a web-environment expert for strategic guidance; the action model then grounds these suggestions into executable actions, leveraging prior knowledge of environmental state transition dynamics to enhance candidate action proposal. To achieve risk-aware resilient task execution, we introduce a two-stage deduction chain. A world model, specialized in environmental state transitions, simulates action outcomes, which a judge model then scrutinizes to trigger action corrective feedback when necessary. Experiments show that WAC achieves absolute gains of 1.8% on VisualWebArena and 1.3% on Online-Mind2Web.

</details>


### [15] [Improving LLM Reliability through Hybrid Abstention and Adaptive Detection](https://arxiv.org/abs/2602.15391)
*Ankit Sharma,Nachiket Tapas,Jyotiprakash Patra*

Main category: cs.AI

TL;DR: 研究提出了一种自适应的、基于上下文的LLM安全过滤系统，通过多维度检测和层级联机制，在保证安全性的同时减少误杀，并显著降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM安全过滤机制在安全性和实用性之间存在权衡，静态规则或固定阈值方法计算成本高、延迟大且对上下文不敏感，容易误拦良性请求或产生不安全内容。

Method: 提出一个自适应的“弃权”系统，该系统基于领域和用户历史等实时上下文信号动态调整安全阈值。该框架包含一个由五个并行检测器组成的多维度检测架构，并通过层级联机制进行组合，以优化速度和精度。

Result: 该系统在混合和特定领域工作负载上进行了广泛评估，显示出误报显著减少，尤其是在医疗建议和创意写作等敏感领域。在严格运行模式下，系统保持了高安全精度和近乎完美的召回率。与非联级模型和外部防护栏系统相比，计算量大大减少，延迟得到显著改善。

Conclusion: 提出的上下文感知弃权框架能够有效平衡LLM的安全性和实用性，同时保持高性能，为可靠部署LLM提供了一个可扩展的解决方案。

Abstract: Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.

</details>


### [16] [Common Belief Revisited](https://arxiv.org/abs/2602.15403)
*Thomas Ågotnes*

Main category: cs.AI

TL;DR: 本文研究了KD45信念系统中共同信念的逻辑特性，发现其与常识相悖，并提出了一个包含新增公理的完整刻画，该公理依赖于代理人的数量。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是探究KD45信念系统中共同信念的逻辑特性，纠正普遍存在的误解，并解决关于共同信念完整刻画的开放性问题。

Method: 本文通过逻辑分析，首先指出共同信念在KD45下会失去5属性，但保留D和4属性，并具备移位自反性公理 $C(Cφightarrow φ)$。随后，通过引入一个额外公理，该公理依赖于代理人数量，来完成对共同信念的完整刻画。

Result: 研究表明，KD45下的共同信念不具备常识所认为的全部特性。通过引入一个依赖于代理人数量的额外公理，本文提出了一个能够完整刻画KD45下共同信念的逻辑系统。

Conclusion: 本文成功地解决了KD45下共同信念的完整刻画问题，提出了一个包含新增公理的完备逻辑系统，该系统揭示了共同信念在多代理人情境下的复杂性。

Abstract: Contrary to common belief, common belief is not KD4.
  If individual belief is KD45, common belief does indeed lose the 5 property and keep the D and 4 properties -- and it has none of the other commonly considered properties of knowledge and belief. But it has another property: $C(Cφ\rightarrow φ)$ -- corresponding to so-called shift-reflexivity (reflexivity one step ahead). This observation begs the question:
  is KD4 extended with this axiom a complete characterisation of common belief in the KD45 case? If not, what \emph{is} the logic of common belief? In this paper we show that the answer to the first question is ``no'': there is one additional axiom, and, furthermore, it relies on the number of agents. We show that the result is a complete characterisation of common belief, settling the open problem.

</details>


### [17] [GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway](https://arxiv.org/abs/2602.15531)
*Javier Irigoyen,Roberto Daza,Aythami Morales,Julian Fierrez,Francisco Jurado,Alvaro Ortigosa,Ruben Tolosana*

Main category: cs.AI

TL;DR: 本文提出了EduEVAL-DB数据集，该数据集基于教师角色，旨在支持教学解释的自动教学评估者和AI导师的评估与训练。数据集包含854个解释，对应ScienceQA基准中的139个问题，并提出了一个与教育标准一致的教学风险评估标准，涵盖了事实正确性、解释深度和完整性、重点和相关性、学生水平适宜性以及意识形态偏见五个维度。初步验证实验评估了该数据集的适用性，并对Gemini 2.5 Pro和Llama 3.1 8B模型进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏针对教学解释的自动评估工具和AI导师，尤其是在模拟真实教育实践中的教师风格和不足方面。因此，作者希望创建一个数据集来支持这些方面的研究和开发。

Method: 研究者构建了一个名为EduEVAL-DB的数据集，其中包含854个由人类教师或LLM模拟的不同教学角色的解释。这些角色基于现实教育实践中的风格和不足，通过提示工程实现。数据集中还包含一个与教育标准对齐的教学风险评估标准，涵盖五个风险维度，并对所有解释进行了二元风险标注。最后，作者进行了初步验证实验，使用Gemini 2.5 Pro和Llama 3.1 8B模型评估数据集的有效性，并探讨了监督微调在消费级硬件上的可行性。

Result: EduEVAL-DB数据集包含了854个解释，覆盖了科学、语言和社会科学的K-12教育内容。初步实验表明，该数据集可以用于评估和训练教学评估模型，并且在EduEVAL-DB上进行监督微调可以提升模型在消费级硬件上检测教学风险的能力。

Conclusion: EduEVAL-DB数据集为评估和训练自动教学评估者和AI导师提供了一个有价值的资源，尤其是在模拟多样化的教师角色和检测教学风险方面。该数据集及其评估方法有望推动教育AI技术的发展。

Abstract: This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.

</details>


### [18] [Quantifying construct validity in large language model evaluations](https://arxiv.org/abs/2602.15532)
*Ryan Othniel Kearns*

Main category: cs.AI

TL;DR: 本文提出了一种新的“结构化能力模型”，以解决现有LLM基准测试评估中存在的测试集污染、标注错误以及模型规模与能力混淆等问题。该模型结合了潜在因子模型和定标定律的优点，能够提取可解释且可泛化的能力，并在解释性和预测性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准测试的结果常被视为模型通用能力的同义词，但存在测试集污染、标注错误等问题，影响了基准测试的有效性。因此，需要一种方法来区分基准测试结果和模型能力，以确保证据效度。

Method: 本文提出了“结构化能力模型”，该模型结合了潜在因子模型（关注测量误差）和定标定律（关注模型规模）的洞见，能够将模型规模信息纳入能力提取过程，并允许能力解释观测结果中的测量误差。在OpenLLM Leaderboard的大量基准测试结果上对该模型及其两个替代模型（潜在因子模型和定标定律）进行了拟合和比较。

Result: 结构化能力模型在模型拟合优度指标上优于潜在因子模型，并且在跨分布基准测试预测方面优于定标定律。这表明结构化能力模型能够更好地分离模型规模和能力，并提高评估的解释性和预测能力。

Conclusion: 结构化能力模型是第一个能够从大量LLM基准测试结果中提取可解释且可泛化能力的模型。它通过结合模型规模和能力信息，并考虑测量误差，在评估LLM的证据效度方面表现出优越的解释和预测能力。

Abstract: The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance.
  Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks.
  This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.

</details>


### [19] [How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning](https://arxiv.org/abs/2602.15580)
*Hongxuan Wu,Yukun Zhang,Xueqing Zhou*

Main category: cs.AI

TL;DR: 该研究使用基于部分信息分解（PID）的框架，分析了多模态Transformer模型在视觉问答中信息来源（视觉、语言、融合），发现在深度模型中，视觉信息早期贡献大但迅速衰减，语言信息后期主导，跨模态协同作用很小。通过注意力机制消融实验，进一步证实了视觉到语言的“转导”路径的因果关系。


<details>
  <summary>Details</summary>
Motivation: 为了理解多模态Transformer在视觉问答中，其预测是源于视觉证据、语言推理还是真正的跨模态融合，以及这种信息结构如何在不同层级演变。

Method: 提出一个基于部分信息分解（PID）的逐层分析框架，将预测信息分解为冗余、仅视觉、仅语言和协同成分。为处理高维神经表示，引入了“PID Flow”流水线，结合降维、归一化流高斯化和高斯PID估计。对LLaVA-1.5/1.6模型在GQA任务上进行分析，并进行图像到问题的注意力机制消融实验。

Result: 在LLaVA模型中观察到一致的“模态转导”模式：仅视觉信息在早期达到峰值并随深度衰减，仅语言信息在后期激增并占最终预测的约82%，跨模态协同作用低于2%。这种模式在模型变体上非常稳定，但在不同任务上表现出强烈的依赖性，语义冗余在信息指纹中起关键作用。注意力消融实验表明，破坏主要转导路径会增加捕获的仅视觉信息、补偿性协同作用和总信息成本，尤其是在视觉依赖性强的任务上。

Conclusion: 该研究提供了多模态Transformer中视觉信息如何转化为语言信息的理论因果解释，并为识别模态特定信息丢失的架构瓶颈提供了量化指导。

Abstract: When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\% of the final prediction, and cross-modal synergy remains below 2\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.

</details>


### [20] [RUVA: Personalized Transparent On-Device Graph Reasoning](https://arxiv.org/abs/2602.15553)
*Gabriele Conte,Alessio Mattiace,Gianni Carmosino,Potito Aghilar,Giovanni Servedio,Francesco Musicco,Vito Walter Anelli,Tommaso Di Noia,Francesco Maria Donini*

Main category: cs.AI

TL;DR: 本文提出了 Ruva，一个“透明盒子”架构，用于人类在环内存管理，以解决当前“黑盒子”检索增强生成模型在个人 AI 中缺乏问责制和隐私保护的问题。Ruva 基于个人知识图谱，允许用户检查 AI 的知识并精确删除信息，确保“被遗忘权”。


<details>
  <summary>Details</summary>
Motivation: 当前个人 AI 系统（基于检索增强生成）缺乏问责制，用户无法检查 AI 产生幻觉或检索敏感数据的原因，也无法精确纠正错误。此外，“删除”概念在向量空间中不精确，存在隐私泄露风险。研究动机是为了实现一个更透明、可控且能真正保障隐私的个人 AI 系统。

Method: Ruva 采用“透明盒子”架构，将个人 AI 的基础从向量数据库转向个人知识图谱。这种方法允许用户检查 AI 所知的信息，并能精确地删除特定事实，从而实现人类在环内存管理。

Result: Ruva 架构实现了从向量匹配到图推理的范式转变，使得用户能够透明地管理 AI 的记忆，精确地进行信息 redaction，从而有效保障“被遗忘权”。

Conclusion: Ruva 是第一个“透明盒子”架构，通过利用个人知识图谱，赋予用户对其个人 AI 记忆的精确控制权，解决了当前“黑盒子”模型的问责制和隐私问题，让用户能够真正成为自己生活信息的编辑者。

Abstract: The Personal AI landscape is currently dominated by "Black Box" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, "deleting" a concept from a vector space is mathematically imprecise, leaving behind probabilistic "ghosts" that violate true privacy. We propose Ruva, the first "Glass Box" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the "Right to be Forgotten." Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.

</details>


### [21] [On inferring cumulative constraints](https://arxiv.org/abs/2602.15635)
*Konstantin Sidorov*

Main category: cs.AI

TL;DR: 该研究提出了一种新的预处理方法，通过推理额外的累积约束来捕捉多资源交互，从而提高约束规划中调度问题的求解效率，并发现了新的最优解界限。


<details>
  <summary>Details</summary>
Motivation: 现有的累积约束传播方法仅考虑单个约束，忽略了多资源交互，导致在某些基准测试上性能严重下降。因此，需要一种更有效的传播方法来捕捉这些交互。

Method: 该方法将累积约束解释为占用向量上的线性不等式，并通过三个步骤生成新的不等式：(i) 发现无法并行运行的任务集合（覆盖集），(ii) 使用提升（lifting）技术加强覆盖集的不等式，(iii) 将生成的约束注入调度问题实例。

Result: 在标准的 RCPSP 和 RCPSP/max 测试集上的实验表明，这些推理出的约束提高了搜索性能，并能在有利的实例上收紧目标界限，同时在不利的实例上造成的性能下降很小。此外，实验发现了 25 个新的下界和 5 个新的最优解，其中 8 个下界直接来自推理出的约束。

Conclusion: 通过推理额外的累积约束来捕捉多资源交互是一种有效的方法，可以显著提高约束规划调度问题的求解性能，并且可以发现新的最优解界限。

Abstract: Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.

</details>


### [22] [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)
*Lucas Elbert Suryana,Farah Bierenga,Sanne van Buuren,Pepijn Kooij,Elsefien Tulleners,Federico Scari,Simeon Calvert,Bart van Arem,Arkady Zgonnikov*

Main category: cs.AI

TL;DR: 本研究提出了CARE Drive，一个模型无关的框架，用于评估自动驾驶领域中视觉语言模型（VLMs）的“原因响应性”，即模型决策是否真正受到人类相关考量的影响，而非事后合理化。该框架通过系统地改变上下文并观察模型决策的变化来衡量其对人类原因（如安全裕度、社会压力、效率约束）的敏感度。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶领域中VLMs的评估方法主要关注结果导向的性能（如安全性、轨迹准确性），未能确定模型的决策是否真正反映了人类的思考过程。这可能导致对模型决策产生虚假的信心，尤其是在安全关键领域。

Method: CARE Drive框架采用一个两阶段评估过程：1. 提示校准（Prompt calibration）确保模型输出稳定；2. 系统性上下文扰动（Systematic contextual perturbation）测量模型决策对人类原因的敏感度。该方法不修改模型参数，通过比较基线模型和原因增强模型在受控上下文变化下的决策来评估原因响应性。

Result: 在自行车超车场景的实验中，结果表明，显性人类原因确实显著影响了模型的决策，并使其与专家推荐行为更加一致。然而，模型对不同上下文因素的响应程度存在差异，表明其对不同类型的原因敏感度不一。

Conclusion: CARE Drive框架能够系统性地评估自动驾驶VLMs的原因响应性，无需修改模型参数。研究结果证明了VLMs确实能对人类原因做出响应，但其敏感度并非均一，为理解和改进自动驾驶系统中的VLMs提供了重要依据。

Abstract: Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.

</details>


### [23] [PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra](https://arxiv.org/abs/2602.15669)
*Xiachong Feng,Liang Zhao,Weihong Zhong,Yichong Huang,Yuxuan Gu,Lingpeng Kong,Xiaocheng Feng,Bing Qin*

Main category: cs.AI

TL;DR: 本研究提出了一种名为PERSONA的训练免费框架，通过直接操作激活空间中的个性向量，实现了媲美微调的语言模型个性控制效果，且无需梯度更新。该框架能够提取、组合和动态调整个性特征，并在基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型个性控制方法（如静态提示或昂贵的微调）未能捕捉人类特质的动态性和组合性，研究者希望找到一种更高效、更灵活的控制方法。

Method: PERSONA框架包含三个阶段：1. Persona-Base通过对比激活分析提取正交的个性向量；2. Persona-Algebra利用向量算术（标量乘法、加法、减法）实现精确控制；3. Persona-Flow在推理时动态组合这些向量以适应上下文。

Result: 在PersonalityBench基准测试中，PERSONA达到了9.60的平均得分，几乎与有监督微调的上界（9.61）持平。在提出的Persona-Evolve基准测试中，该方法在不同模型家族上取得了高达91%的胜率，证明了其动态个性适应能力。

Conclusion: 研究结果表明，大型语言模型的个性特征在数学上是可处理的，并且可以通过操作激活空间中的向量来实现高效、可解释的个性控制，为未来研究开辟了新方向。

Abstract: Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.

</details>


### [24] [Recursive Concept Evolution for Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.15725)
*Sarim Chaudhry*

Main category: cs.AI

TL;DR: 本文提出了一种名为递归概念演化（RCE）的框架，通过在推理过程中动态修改语言模型的内部表示几何来提高其在组合推理任务上的性能。RCE能够识别并构建新的抽象，而不是仅依赖于预先存在的抽象。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在组合推理任务上表现不佳，因为它们在这些任务中所需的抽象可能未被编码在其固定的内部表示空间中。这导致了模型性能的显著下降。

Method: RCE框架通过以下方式实现：1. 动态生成低秩概念子空间，当检测到表示不足时生成。2. 使用最小描述长度标准进行选择。3. 当子空间具有协同效应时进行合并。4. 通过约束优化进行整合，以保持稳定性。该方法与Mistral-7B模型集成。

Result: 在ARC-AGI-2基准上，RCE带来了12-18个百分点的性能提升；在GPQA和BBH基准上，性能提升了8-14个百分点；在MATH和HLE基准上，一致地减少了深度引起的错误。

Conclusion: RCE框架能够使预训练语言模型在推理过程中修改其内部表示几何，从而构建新的抽象，显著提升了模型在多种组合推理任务上的性能，并解决了现有方法在表示空间受限时的局限性。

Abstract: Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.

</details>


### [25] [GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems](https://arxiv.org/abs/2602.15776)
*Yiqin Yang,Xu Yang,Yuhua Jiang,Ni Mu,Hao Hu,Runpeng Xie,Ziyou Zhang,Siyuan Li,Yuan-Hua Ni,Qianchuan Zhao,Bo Xu*

Main category: cs.AI

TL;DR: 提出了一种名为GlobeDiff的算法，利用多模态扩散过程来解决多智能体系统中的部分可观性问题，通过局部观测推断全局状态，并证明了其估计误差可控，实验结果表明性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如信念状态估计和通信）在处理多智能体系统中的部分可观性时存在局限性，无法有效利用全局信息或有效利用通信提供的辅助信息。

Method: 将全局状态推断问题形式化为一个多模态扩散过程，提出GlobeDiff算法，通过局部观测来推断全局状态。

Result: 证明了GlobeDiff在单模态和多模态分布下的估计误差可以被界定，并且在广泛的实验中表现出优越的性能，能够准确推断全局状态。

Conclusion: GlobeDiff是一种有效解决多智能体系统部分可观性问题的新方法，通过多模态扩散过程能够高保真地推断全局状态，并具有可证明的误差界限。

Abstract: In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.

</details>


### [26] [This human study did not involve human subjects: Validating LLM simulations as behavioral evidence](https://arxiv.org/abs/2602.15785)
*Jessica Hullman,David Broska,Huaman Sun,Aaron Shaw*

Main category: cs.AI

TL;DR: 本文探讨了使用大型语言模型（LLMs）作为社会科学实验的合成参与者的有效性，并提出了两种策略：启发式方法和统计校准，以在不同研究场景下获得有效的因果效应估计。


<details>
  <summary>Details</summary>
Motivation: 现有研究在使用LLMs作为合成参与者生成实验响应方面有所增长，但缺乏关于何时此类模拟能够支持对人类行为进行有效推断的指导。因此，需要对LLMs在社会科学实验中的应用进行更深入的分析和方法论的 Clarification。

Method: 文章对比了两种获取有效因果效应估计的策略：1. 启发式方法，通过提示工程、模型微调等手段，试图使模拟和观察到的人类行为具有可互换性，适用于探索性研究。2. 统计校准，结合辅助人类数据和统计调整，以解释观察到的和模拟的响应之间的差异，在明确假设下，适用于确认性研究。

Result: 启发式方法在许多探索性任务中很有用，但缺乏确认性研究所需的正式统计保证。统计校准在明确假设下，可以保持有效性，并提供比仅依赖人类参与者的实验更精确的因果效应估计，同时成本更低。两种方法的潜力都取决于LLMs对相关人群的近似程度。

Conclusion: 当研究人员只关注用LLMs替代人类参与者时，可能会忽视一些机会。启发式方法适合探索性研究，而统计校准则为确认性研究提供了更可靠的替代方案，尤其是在成本效益方面。研究者应根据研究目标和对LLM行为的理解选择合适的方法，并认识到LLMs的局限性。

Abstract: A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.

</details>


### [27] [Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings](https://arxiv.org/abs/2602.15791)
*Suhyung Jang,Ghang Lee,Jaekun Lee,Hyunjun Lee*

Main category: cs.AI

TL;DR: 该研究提出使用大型语言模型（LLM）的嵌入作为编码，以改进建筑信息模型（BIM）中建筑对象语义的表示，克服传统one-hot编码的局限性，并在实际数据集上取得了优于one-hot编码的分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统的one-hot编码方法在表示建筑对象语义的细微差别方面存在不足，限制了AI模型对复杂语义的理解能力，尤其是在AECO行业中。

Method: 研究者提出了一个新颖的训练方法，利用LLM（如OpenAI GPT和Meta LLaMA）生成的嵌入作为建筑对象的编码。他们使用GraphSAGE模型在五个高层住宅BIM数据集上训练分类器，并测试了不同维度的LLM嵌入（原始高维和通过Matryoshka模型降维到1024维）的性能。

Result: 实验结果表明，LLM嵌入编码在分类42种建筑对象子类型方面优于传统的one-hot编码。其中，llama-3（降维后）嵌入获得了0.8766的加权平均F1分数，而one-hot编码为0.8475。

Conclusion: 利用LLM生成的嵌入可以有效提升AI模型对建筑领域复杂语义的解读能力，尤其是在区分细粒度子类型方面。随着LLM和降维技术的发展，这种方法在AECO行业的语义细化任务中具有广阔的应用前景。

Abstract: Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.

</details>


### [28] [Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816)
*Xiaoran Liu,Istvan David*

Main category: cs.AI

TL;DR: 本章介绍了基于仿真的合成数据生成在人工智能训练中的关键概念、优势和挑战，以及用于描述、设计和分析数字孪生（digital twin）驱动的AI模拟解决方案的参考框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI应用面临数据量不足和质量不高的关键障碍，因此需要合成数据生成技术。

Method: 介绍基于仿真的合成数据生成（simulation-based synthetic data generation）的关键概念、优势和挑战，并提出了一个用于描述、设计和分析基于数字孪生（digital twin）的AI模拟解决方案的参考框架。

Result: 提出了一种描述、设计和分析数字孪生驱动的AI模拟解决方案的参考框架。

Conclusion: 基于仿真的合成数据生成是克服AI数据瓶颈的有效方法，数字孪生技术为设计和分析此类模拟解决方案提供了系统性框架。

Abstract: As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [29] [GRAFNet: Multiscale Retinal Processing via Guided Cortical Attention Feedback for Enhancing Medical Image Polyp Segmentation](https://arxiv.org/abs/2602.15072)
*Abdul Joseph Fofanah,Lian Wen,Alpha Alimamy Kamara,Zhongyi Zhang,David Chen,Albert Patrick Sankoh*

Main category: cs.CV

TL;DR: 本文提出了一种名为GRAFNet的新型深度学习模型，用于结肠镜检查中的息肉分割。GRAFNet受人类视觉系统启发，通过不对称注意力、多尺度分析和反馈机制，提高了分割精度和泛化能力，并在多个数据集上取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在结肠镜息肉分割方面存在困难，包括形态变异大、与正常结构相似、需要多尺度检测，并且存在单向处理、多尺度融合弱、缺乏解剖学约束等问题，导致漏诊和误诊。因此，需要一种更先进的模型来提高分割的准确性和可靠性。

Method: GRAFNet模型采用了受生物学启发的层次化结构，集成了三个关键模块：(1) 引导不对称注意力模块（GAAM），模拟视皮层神经元强调息肉边界；(2) 多尺度视网膜模块（MSRM），模仿视网膜神经节细胞通路进行并行多特征分析；(3) 引导皮层注意力反馈模块（GCAFM），利用预测编码进行迭代优化。这些模块集成在多边形编码器-解码器模块（PEDM）中，通过分辨率自适应反馈强制执行空间-语义一致性。

Result: 在Kvasir-SEG、CVC-300、CVC-ColonDB、CVC-Clinic和PolypGen五个公开数据集上进行了广泛实验。GRAFNet在Dice相似系数上提高了3-8%，泛化能力提高了10-20%，优于现有领先方法，并提供了可解释的决策路径。

Conclusion: GRAFNet通过模仿人类视觉系统的计算原理，成功地弥合了AI准确性与临床可信推理之间的差距，为息肉分割任务提供了一种新的、性能优越的范式。

Abstract: Accurate polyp segmentation in colonoscopy is essential for cancer prevention but remains challenging due to: (1) high morphological variability (from flat to protruding lesions), (2) strong visual similarity to normal structures such as folds and vessels, and (3) the need for robust multi-scale detection. Existing deep learning approaches suffer from unidirectional processing, weak multi-scale fusion, and the absence of anatomical constraints, often leading to false positives (over-segmentation of normal structures) and false negatives (missed subtle flat lesions). We propose GRAFNet, a biologically inspired architecture that emulates the hierarchical organisation of the human visual system. GRAFNet integrates three key modules: (1) a Guided Asymmetric Attention Module (GAAM) that mimics orientation-tuned cortical neurones to emphasise polyp boundaries, (2) a MultiScale Retinal Module (MSRM) that replicates retinal ganglion cell pathways for parallel multi-feature analysis, and (3) a Guided Cortical Attention Feedback Module (GCAFM) that applies predictive coding for iterative refinement. These are unified in a Polyp Encoder-Decoder Module (PEDM) that enforces spatial-semantic consistency via resolution-adaptive feedback. Extensive experiments on five public benchmarks (Kvasir-SEG, CVC-300, CVC-ColonDB, CVC-Clinic, and PolypGen) demonstrate consistent state-of-the-art performance, with 3-8% Dice improvements and 10-20% higher generalisation over leading methods, while offering interpretable decision pathways. This work establishes a paradigm in which neural computation principles bridge the gap between AI accuracy and clinically trustworthy reasoning. Code is available at https://github.com/afofanah/GRAFNet.

</details>


### [30] [Zero-shot HOI Detection with MLLM-based Detector-agnostic Interaction Recognition](https://arxiv.org/abs/2602.15124)
*Shiyu Xuan,Dongkai Wang,Zechao Li,Jinhui Tang*

Main category: cs.CV

TL;DR: 提出了一种解耦的零样本人机交互（HOI）检测框架，将目标检测与交互识别（IR）分开，并利用多模态大语言模型（MLLMs）进行零样本IR，通过视觉问答和确定性生成实现训练无关的IR，并通过空间感知池化和单次确定性匹配进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有HOI检测方法在交互识别方面存在挑战，因为交互的组合多样性限制了泛化能力，且现有方法通常将IR与特定检测器紧密耦合，并依赖于粗粒度的VLM特征。

Method: 提出一种解耦框架，将目标检测和IR分开。IR任务被表述为视觉问答任务，并采用确定性生成方法实现训练无关的零样本IR。此外，设计了空间感知池化模块来整合外观和空间线索，以及一种单次确定性匹配方法来一次性预测所有候选交互。

Result: 在HICO-DET和V-COCO数据集上取得了优越的零样本性能，并表现出强大的跨数据集泛化能力，同时能够与任何目标检测器集成而无需重新训练。

Conclusion: 所提出的解耦框架利用MLLMs在零样本HOI检测任务中实现了高效且泛化的交互识别，并且具有良好的灵活性和可集成性。

Abstract: Zero-shot Human-object interaction (HOI) detection aims to locate humans and objects in images and recognize their interactions. While advances in open-vocabulary object detection provide promising solutions for object localization, interaction recognition (IR) remains challenging due to the combinatorial diversity of interactions. Existing methods, including two-stage methods, tightly couple IR with a specific detector and rely on coarse-grained vision-language model (VLM) features, which limit generalization to unseen interactions. In this work, we propose a decoupled framework that separates object detection from IR and leverages multi-modal large language models (MLLMs) for zero-shot IR. We introduce a deterministic generation method that formulates IR as a visual question answering task and enforces deterministic outputs, enabling training-free zero-shot IR. To further enhance performance and efficiency by fine-tuning the model, we design a spatial-aware pooling module that integrates appearance and pairwise spatial cues, and a one-pass deterministic matching method that predicts all candidate interactions in a single forward pass. Extensive experiments on HICO-DET and V-COCO demonstrate that our method achieves superior zero-shot performance, strong cross-dataset generalization, and the flexibility to integrate with any object detectors without retraining. The codes are publicly available at https://github.com/SY-Xuan/DA-HOI.

</details>


### [31] [MB-DSMIL-CL-PL: Scalable Weakly Supervised Ovarian Cancer Subtype Classification and Localisation Using Contrastive and Prototype Learning with Frozen Patch Features](https://arxiv.org/abs/2602.15138)
*Marcus Jenkins,Jasenka Mazibrada,Bogdan Leahu,Michal Mackiewicz*

Main category: cs.CV

TL;DR: 本文提出了一种利用对比学习和原型学习，并结合特征空间增强的冻结特征方法，用于卵巢癌组织病理图像的亚型分类和定位。该方法在提高分类和定位准确率的同时，保持了冻结特征的优势，从而提高了可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了实现卵巢癌治疗的个体化，对组织病理亚型的研究至关重要。然而，英国病理学部门面临诊断工作量增加的挑战，这促使了人工智能（AI）方法的兴起。以往的AI方法在准确性方面有所提升，但牺牲了训练时的可扩展性和实验的效率。

Method: 提出一种结合对比学习和原型学习的新方法，利用预先计算好的冻结特征，并通过特征空间增强来进行卵巢癌组织病理图像的亚型分类和定位。

Result: 与DSMIL方法相比，该方法在实例级和幻灯片级别的F1分数上分别提高了70.4%和15.3%。在实例定位的AUC方面提高了16.9%，幻灯片分类的AUC方面提高了2.3%，同时保持了冻结块特征的使用。

Conclusion: 所提出的结合对比学习、原型学习和特征空间增强的方法，在利用冻结特征的同时，能够有效提高卵巢癌组织病理图像亚型分类和定位的准确性，并保持了良好的可扩展性。

Abstract: The study of histopathological subtypes is valuable for the personalisation of effective treatment strategies for ovarian cancer. However, increasing diagnostic workloads present a challenge for UK pathology departments, leading to the rise in AI approaches. While traditional approaches in this field have relied on pre-computed, frozen image features, recent advances have shifted towards end-to-end feature extraction, providing an improvement in accuracy but at the expense of significantly reduced scalability during training and time-consuming experimentation. In this paper, we propose a new approach for subtype classification and localisation in ovarian cancer histopathology images using contrastive and prototype learning with pre-computed, frozen features via feature-space augmentations. Compared to DSMIL, our method achieves an improvement of 70.4\% and 15.3\% in F1 score for instance- and slide-level classification, respectively, along with AUC gains of 16.9\% for instance localisation and 2.3\% for slide classification, while maintaining the use of frozen patch features.

</details>


### [32] [GMAIL: Generative Modality Alignment for generated Image Learning](https://arxiv.org/abs/2602.15368)
*Shentong Mo,Sukmin Yun*

Main category: cs.CV

TL;DR: 本研究提出了一种名为GMAIL的新框架，通过将生成图像视为与真实图像不同的模态，并在潜在空间中进行多模态学习，来更有效地利用生成图像进行视觉-语言模型的训练，显著提升了多项视觉-语言任务的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管生成模型可以产生逼真的图像，但直接将其用作训练数据可能导致模式崩溃。研究动机在于如何有效利用生成图像的优势，同时避免其缺点，以提升机器学习模型的性能。

Method: GMAIL框架首先在生成图像上单独微调模型，并使用跨模态对齐损失。然后，利用此对齐后的模型，结合生成图像，进一步训练各种视觉-语言模型。这种方法在潜在空间中桥接了真实图像和生成图像这两个不同的模态。

Result: GMAIL框架在图像描述、零样本图像检索、零样本图像分类和长描述检索等任务上显著提升了性能。该框架显示出生成数据规模的积极趋势，并对LLaVA等大型多模态模型的描述性能有显著增强。

Conclusion: GMAIL框架通过将生成图像作为独立的模态并在潜在空间中进行对齐，能够有效地利用生成图像的优势，克服了直接使用生成图像的局限性，并显著提升了多种视觉-语言任务的性能。该框架易于集成到现有模型中，并展现了良好的扩展性和有效性。

Abstract: Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can even cause mode collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined GMAIL, that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the pixel space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach. To be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image learning across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA.

</details>


### [33] [Loss Knows Best: Detecting Annotation Errors in Videos via Loss Trajectories](https://arxiv.org/abs/2602.15154)
*Praditha Alwis,Soumyadeep Chandra,Deepak Ravikumar,Kaushik Roy*

Main category: cs.CV

TL;DR: 提出了一种名为累积样本损失（CSL）的新方法，通过分析视频数据集中帧在模型训练过程中的平均损失轨迹来检测标注错误（如错标和顺序错乱），该方法不依赖真实标签，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现实世界的视频数据集常包含标注错误（如错标和顺序错乱），这些错误对需要时间一致性的任务（如阶段识别）尤其有害。因此，需要一种有效的方法来检测这些标注错误。

Method: 提出了一种模型无关的方法，通过计算每帧在模型训练过程中跨 epoch 检查点的平均损失（累积样本损失 CSL）来检测标注错误。CSL 轨迹被视为帧级别可学习性的动态指纹。与正确标注的帧相比，错标或顺序错乱的帧通常表现出持续的高损失或不规则的损失模式。通过训练一个视频分割模型并保存其在每个 epoch 的权重，然后用这些检查点评估测试视频中每一帧的损失来计算 CSL。

Result: 在 EgoPER 和 Cholec80 数据集上的实验表明，该方法能够有效地检测到错标和帧顺序错乱等细微的不一致性，展现出强大的检测性能。

Conclusion: 所提出的 CSL 方法是一种有效的、模型无关的视频数据集标注错误检测工具，它不依赖于地面真实标签，具有良好的泛化能力，有助于数据集审计和提高视频模型训练的可靠性。

Abstract: High-quality video datasets are foundational for training robust models in tasks like action recognition, phase detection, and event segmentation. However, many real-world video datasets suffer from annotation errors such as *mislabeling*, where segments are assigned incorrect class labels, and *disordering*, where the temporal sequence does not follow the correct progression. These errors are particularly harmful in phase-annotated tasks, where temporal consistency is critical. We propose a novel, model-agnostic method for detecting annotation errors by analyzing the Cumulative Sample Loss (CSL)--defined as the average loss a frame incurs when passing through model checkpoints saved across training epochs. This per-frame loss trajectory acts as a dynamic fingerprint of frame-level learnability. Mislabeled or disordered frames tend to show consistently high or irregular loss patterns, as they remain difficult for the model to learn throughout training, while correctly labeled frames typically converge to low loss early. To compute CSL, we train a video segmentation model and store its weights at each epoch. These checkpoints are then used to evaluate the loss of each frame in a test video. Frames with persistently high CSL are flagged as likely candidates for annotation errors, including mislabeling or temporal misalignment. Our method does not require ground truth on annotation errors and is generalizable across datasets. Experiments on EgoPER and Cholec80 demonstrate strong detection performance, effectively identifying subtle inconsistencies such as mislabeling and frame disordering. The proposed approach provides a powerful tool for dataset auditing and improving training reliability in video-based machine learning.

</details>


### [34] [Spanning the Visual Analogy Space with a Weight Basis of LoRAs](https://arxiv.org/abs/2602.15727)
*Hila Manor,Rinon Gal,Haggai Maron,Tomer Michaeli,Gal Chechik*

Main category: cs.CV

TL;DR: 本研究提出了一种名为LoRWeB的新方法，通过动态组合学习到的LoRA变换原语来解决视觉类比学习中的泛化能力受限问题，以实现更灵活的图像处理。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LoRA的视觉类比学习方法在捕获多样化视觉变换时存在局限性，影响了泛化能力。受到LoRA在受限领域中跨越有意义、可插值语义空间的启发，本研究旨在开发一种能够根据输入动态选择和组合LoRA的方法。

Method: LoRWeB引入了两个核心组件：（1）一个可学习的LoRA模块基，用于跨越不同视觉变换的空间；（2）一个轻量级编码器，根据输入的类比对动态选择和加权这些基LoRA。该方法在推理时为每个类比任务专门化模型。

Result: 在广泛的评估中，LoRWeB达到了最先进的性能，并且在未见过的视觉变换上显著提高了泛化能力。

Conclusion: LoRA基分解为灵活的视觉操作提供了一个有前途的方向，LoRWeB通过动态组合变换原语有效地实现了这一点。

Abstract: Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words. Given a triplet $\{\mathbf{a}$, $\mathbf{a}'$, $\mathbf{b}\}$, the goal is to generate $\mathbf{b}'$ such that $\mathbf{a} : \mathbf{a}' :: \mathbf{b} : \mathbf{b}'$. Recent methods adapt text-to-image models to this task using a single Low-Rank Adaptation (LoRA) module, but they face a fundamental limitation: attempting to capture the diverse space of visual transformations within a fixed adaptation module constrains generalization capabilities. Inspired by recent work showing that LoRAs in constrained domains span meaningful, interpolatable semantic spaces, we propose LoRWeB, a novel approach that specializes the model for each analogy task at inference time through dynamic composition of learned transformation primitives, informally, choosing a point in a "space of LoRAs". We introduce two key components: (1) a learnable basis of LoRA modules, to span the space of different visual transformations, and (2) a lightweight encoder that dynamically selects and weighs these basis LoRAs based on the input analogy pair. Comprehensive evaluations demonstrate our approach achieves state-of-the-art performance and significantly improves generalization to unseen visual transformations. Our findings suggest that LoRA basis decompositions are a promising direction for flexible visual manipulation. Code and data are in https://research.nvidia.com/labs/par/lorweb

</details>


### [35] [Distributional Deep Learning for Super-Resolution of 4D Flow MRI under Domain Shift](https://arxiv.org/abs/2602.15167)
*Xiaoyi Wen,Fei Jiang*

Main category: cs.CV

TL;DR: 提出一种基于分布深度学习的超分辨率框架，用于增强4D Flow MRI的图像质量，以解决临床应用中因域漂移导致的模型泛化能力差的问题，并在真实数据应用中表现出优于传统深度学习方法的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的超分辨率方法依赖配对的降采样和高分辨率图像对进行训练，但在真实临床环境中，低分辨率数据的获取机制与简单降采样存在显著差异，导致模型泛化能力差。研究旨在解决这一域漂移问题，提高模型鲁棒性。

Method: 提出一个分布深度学习框架。模型首先在配对的高分辨率计算流体动力学（CFD）模拟及其降采样版本上进行训练，然后在一个小的、协调的配对4D Flow MRI和CFD样本数据集上进行微调。推导了分布估计器的理论性质。

Result: 所提出的框架在真实数据应用中显著优于传统的深度学习方法。

Conclusion: 分布深度学习在解决域漂移和提高临床现实场景下的超分辨率性能方面是有效的，尤其适用于4D Flow MRI等成像模态。

Abstract: Super-resolution is widely used in medical imaging to enhance low-quality data, reducing scan time and improving abnormality detection. Conventional super-resolution approaches typically rely on paired datasets of downsampled and original high resolution images, training models to reconstruct high resolution images from their artificially degraded counterparts. However, in real-world clinical settings, low resolution data often arise from acquisition mechanisms that differ significantly from simple downsampling. As a result, these inputs may lie outside the domain of the training data, leading to poor model generalization due to domain shift. To address this limitation, we propose a distributional deep learning framework that improves model robustness and domain generalization. We develop this approch for enhancing the resolution of 4D Flow MRI (4DF). This is a novel imaging modality that captures hemodynamic flow velocity and clinically relevant metrics such as vessel wall stress. These metrics are critical for assessing aneurysm rupture risk. Our model is initially trained on high resolution computational fluid dynamics (CFD) simulations and their downsampled counterparts. It is then fine-tuned on a small, harmonized dataset of paired 4D Flow MRI and CFD samples. We derive the theoretical properties of our distributional estimators and demonstrate that our framework significantly outperforms traditional deep learning approaches through real data applications. This highlights the effectiveness of distributional learning in addressing domain shift and improving super-resolution performance in clinically realistic scenarios.

</details>


### [36] [Time-Archival Camera Virtualization for Sports and Visual Performances](https://arxiv.org/abs/2602.15181)
*Yunxiao Zhang,William Stone,Suryansh Kumar*

Main category: cs.CV

TL;DR: 该论文提出了一种基于神经体积渲染的相机虚拟化方法，用于动态场景的新视角合成和时间存档，旨在克服现有3D高斯泼溅方法在处理快速、非刚性运动和多主体交互方面的局限性，以应用于体育转播等领域。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的动态场景新视角合成方法在处理快速、非刚性运动以及多主体交互时存在困难，且缺乏高效的时间存档能力，无法满足体育转播等领域对回溯性渲染、分析和存档的需求。

Method: 将动态场景建模为在给定时间点下的多视角刚体变换，然后进行神经表示学习，通过优化神经体积渲染实现新视角合成。该方法支持时间存档，允许用户回溯和渲染历史帧。

Result: 提出的方法能够实现高质量的视觉渲染，并支持高效的时间存档功能，使用户能够访问和合成过去任意时间点的场景视图。

Conclusion: 重新审视神经体积渲染方法是实现相机虚拟化和高效时间存档的有效途径，尤其是在处理具有挑战性的动态场景（如体育赛事）方面，该方法能够提供比现有3D高斯泼溅方法更强的鲁棒性和更丰富的功能。

Abstract: Camera virtualization -- an emerging solution to novel view synthesis -- holds transformative potential for visual entertainment, live performances, and sports broadcasting by enabling the generation of photorealistic images from novel viewpoints using images from a limited set of calibrated multiple static physical cameras. Despite recent advances, achieving spatially and temporally coherent and photorealistic rendering of dynamic scenes with efficient time-archival capabilities, particularly in fast-paced sports and stage performances, remains challenging for existing approaches. Recent methods based on 3D Gaussian Splatting (3DGS) for dynamic scenes could offer real-time view-synthesis results. Yet, they are hindered by their dependence on accurate 3D point clouds from the structure-from-motion method and their inability to handle large, non-rigid, rapid motions of different subjects (e.g., flips, jumps, articulations, sudden player-to-player transitions). Moreover, independent motions of multiple subjects can break the Gaussian-tracking assumptions commonly used in 4DGS, ST-GS, and other dynamic splatting variants. This paper advocates reconsidering a neural volume rendering formulation for camera virtualization and efficient time-archival capabilities, making it useful for sports broadcasting and related applications. By modeling a dynamic scene as rigid transformations across multiple synchronized camera views at a given time, our method performs neural representation learning, providing enhanced visual rendering quality at test time. A key contribution of our approach is its support for time-archival, i.e., users can revisit any past temporal instance of a dynamic scene and can perform novel view synthesis, enabling retrospective rendering for replay, analysis, and archival of live events, a functionality absent in existing neural rendering approaches and novel view synthesis...

</details>


### [37] [How to Train Your Long-Context Visual Document Model](https://arxiv.org/abs/2602.15257)
*Austin Veselka*

Main category: cs.CV

TL;DR: 该研究对长上下文视觉语言模型（高达 344K 上下文）进行了全面、大规模的研究，特别关注长文档视觉问答，并测量了其向长上下文文本的迁移能力。研究系统地探索了继续预训练、监督微调和偏好优化等方法，并在 MMLongBenchDoc 上取得了最先进的性能。研究发现，在与评估上下文长度相匹配的上下文长度上进行训练比在更长的上下文上训练效果更好，使用页面索引进行训练和评估能显著提升长文档性能，合成数据管道可实现自我改进，并且长上下文视觉训练可以迁移到长上下文文本性能。研究还发布了一个改进版的 MMLongBenchDoc 基准测试集 MMLBD-C。


<details>
  <summary>Details</summary>
Motivation: 现有开放权重长上下文视觉语言模型（如 Qwen3 VL 和 GLM 4.5/6V）的训练方法和数据管道不可复现，限制了该领域的研究和发展。因此，需要进行一项全面的研究来系统地探索训练长上下文视觉语言模型的方法，并弥合现有模型在性能和可复现性方面的差距。

Method: 研究人员系统地研究了 24B 和 32B 参数模型的继续预训练、监督微调和偏好优化，并在长上下文评估（LC evaluations）和消融实验（ablations）的支持下进行。他们还设计了合成数据管道，并探索了将文本到视觉的长上下文迁移能力反向应用于视觉到文本长上下文性能。

Result: 在 MMLongBenchDoc 上实现了最先进的性能。关键发现包括：(i) 在与评估上下文长度相匹配的上下文长度上进行训练优于在更长上下文上训练；(ii) 在训练和评估中使用页面索引能简单而显著地提升长文档性能；(iii) 合成数据管道支持通过继续预训练和监督微调实现自我改进；(iv) 视觉长上下文训练可以迁移到长上下文文本性能。

Conclusion: 该研究为训练长上下文视觉语言模型提供了系统性的方法和宝贵的见解，包括最佳的上下文长度选择、页面索引的重要性、合成数据管道的有效性以及长上下文视觉能力的跨模态迁移。研究成果不仅提升了长文档视觉问答的性能，也为未来该领域的研究提供了可复现的基础，并发布了改进的基准测试集 MMLBD-C。

Abstract: We present the first comprehensive, large-scale study of training long-context vision language models up to 344K context, targeting long-document visual question answering with measured transfer to long-context text. While several such strong are open-weight, namely Qwen3 VL and GLM 4.5/6V, their training recipes and data pipelines are not reproducible. We systematically study continued pretraining, supervised finetuning, and preference optimization for 24B and 32B parameter models, backed by extensive LC evaluations and ablations to bridge this gap, and achieve state-of-the-art performance on MMLongBenchDoc for both parameter scales. In addition to this, our key findings include: (i) training on context lengths that match evaluation context lengths outperforms training on longer contexts, (ii) training and evaluating with page indices provides a simple, high-impact boost to long-document performance, (iii) our synthetic data pipelines enable self-improvement via continued pretraining and supervised finetuning, and (iv) we extend the known text-to-visual long context transfer to the reverse, showing that visual long context training transfers to long-context text performance. We also release MMLBD-C, a manually corrected version of MMLongBenchDoc to reduce erroneous and low quality examples in the benchmark.

</details>


### [38] [Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization](https://arxiv.org/abs/2602.15277)
*Muhammad J. Alahmadi,Peng Gao,Feiyi Wang,Dongkuan,Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为 E^2D (Exploration-Exploitation Distillation) 的新方法，用于高效地压缩大型数据集，在保持模型性能的同时大幅缩短训练时间和存储需求，尤其适用于资源受限的环境。E^2D 通过分阶段的优化策略，在保证语义完整性和特征多样性的前提下，减少了不必要的计算，从而在准确性和效率之间取得了更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的去耦合数据集蒸馏方法在效率和准确性之间存在权衡：优化方法准确率高但计算密集，无优化方法效率高但准确率低。研究的动机是为了克服这种 trade-off，提出一种既高效又准确的大规模数据集蒸馏方法。

Method: E^2D 采用一种简单实用的方法，首先通过全图像初始化来保持语义完整性和特征多样性。然后，它采用一个两阶段的优化策略：探索阶段进行均匀更新并识别高损失区域，利用阶段则专注于这些区域以加速收敛。这种方法旨在最小化冗余计算。

Result: 在 ImageNet-1K 上，E^2D 超越了现有技术，同时训练速度快 18 倍。在 ImageNet-21K 上，E^2D 大幅提高了准确率，同时速度快 4.3 倍。这些结果表明，E^2D 在大规模数据集蒸馏中成功地平衡了准确性和效率。

Conclusion: E^2D 通过有针对性的、减少冗余的更新，而非蛮力优化，成功地弥合了大规模数据集蒸馏在准确性和效率之间的差距，证明了其在大规模应用中的优越性。

Abstract: Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large-scale, they continue to face an efficiency gap: optimization-based decoupling methods achieve higher accuracy but demand intensive computation, whereas optimization-free decoupling methods are efficient but sacrifice accuracy. To overcome this trade-off, we propose Exploration-Exploitation Distillation (E^2D), a simple, practical method that minimizes redundant computation through an efficient pipeline that begins with full-image initialization to preserve semantic integrity and feature diversity. It then uses a two-phase optimization strategy: an exploration phase that performs uniform updates and identifies high-loss regions, and an exploitation phase that focuses updates on these regions to accelerate convergence. We evaluate E^2D on large-scale benchmarks, surpassing the state-of-the-art on ImageNet-1K while being 18x faster, and on ImageNet-21K, our method substantially improves accuracy while remaining 4.3x faster. These results demonstrate that targeted, redundancy-reducing updates, rather than brute-force optimization, bridge the gap between accuracy and efficiency in large-scale dataset distillation. Code is available at https://github.com/ncsu-dk-lab.

</details>


### [39] [Visual Persuasion: What Influences Decisions of Vision-Language Models?](https://arxiv.org/abs/2602.15278)
*Manuel Cherep,Pranav M R,Pattie Maes,Nikhil Singh*

Main category: cs.CV

TL;DR: 本研究提出了一种框架，通过分析视觉-语言模型（VLMs）在受控图像选择任务中的偏好，来理解和解释这些模型的视觉偏好，并识别出影响其选择的关键视觉因素，从而为AI的审计和治理提供了一种主动的方法。


<details>
  <summary>Details</summary>
Motivation: 随着VLMs越来越多地被用于理解和决策图像内容，了解它们的视觉偏好至关重要，以便发现潜在的视觉漏洞和安全隐患。

Method: 研究框架将VLMs置于受控的图像选择任务中，通过系统性地修改输入图像，并利用视觉提示优化技术（借鉴文本优化方法），迭代生成视觉上合理的变化。然后，通过比较修改前后的选择概率来推断潜在的视觉效用，并利用自动解释流水线识别驱动选择的视觉主题。

Result: 通过大规模实验，研究表明优化的图像编辑能够显著改变VLMs的选择概率。研究还成功识别出驱动模型选择的视觉主题。

Conclusion: 该方法为研究VLMs的视觉偏好提供了一种实用且高效的途径，有助于主动发现和解决图像AI代理中的视觉漏洞和安全问题，从而支持更主动的审计和治理。

Abstract: The web is littered with images, once created for human consumption and now increasingly interpreted by agents using vision-language models (VLMs). These agents make visual decisions at scale, deciding what to click, recommend, or buy. Yet, we know little about the structure of their visual preferences. We introduce a framework for studying this by placing VLMs in controlled image-based choice tasks and systematically perturbing their inputs. Our key idea is to treat the agent's decision function as a latent visual utility that can be inferred through revealed preference: choices between systematically edited images. Starting from common images, such as product photos, we propose methods for visual prompt optimization, adapting text optimization methods to iteratively propose and apply visually plausible modifications using an image generation model (such as in composition, lighting, or background). We then evaluate which edits increase selection probability. Through large-scale experiments on frontier VLMs, we demonstrate that optimized edits significantly shift choice probabilities in head-to-head comparisons. We develop an automatic interpretability pipeline to explain these preferences, identifying consistent visual themes that drive selection. We argue that this approach offers a practical and efficient way to surface visual vulnerabilities, safety concerns that might otherwise be discovered implicitly in the wild, supporting more proactive auditing and governance of image-based AI agents.

</details>


### [40] [Consistency-Preserving Diverse Video Generation](https://arxiv.org/abs/2602.15287)
*Xinshuang Liu,Runfa Blark Li,Truong Nguyen*

Main category: cs.CV

TL;DR: 提出了一种用于流匹配视频生成器的联合采样框架，在低样本数量下提高了批次多样性，同时保持了时间一致性，并且避免了对视频解码器的反向传播。


<details>
  <summary>Details</summary>
Motivation: 文本到视频生成成本高昂，导致每个提示生成的样本数量有限。在此低样本稀疏情况下，需要高视频间多样性来最大化每个批次的价值。现有的图像生成多样性方法在视频生成中往往会损害时间一致性，并且需要对视频解码器进行昂贵的反向传播。

Method: 该方法采用一种联合采样框架，通过多样性驱动的更新来提高批次多样性，然后移除会降低时间一致性目标值的组件。为了避免图像空间梯度，使用轻量级的潜在空间模型计算多样性和时间一致性目标，从而避免视频解码和解码器反向传播。

Result: 在先进的文本到视频流匹配模型上进行的实验表明，该方法在保持时间一致性和颜色自然度的同时，实现了与强大的联合采样基线相当的视频多样性。

Conclusion: 提出的联合采样框架能够有效地提高低样本生成场景下的视频多样性，同时保持并提升时间一致性和颜色自然度，并且在计算上比现有方法更高效。

Abstract: Text-to-video generation is expensive, so only a few samples are typically produced per prompt. In this low-sample regime, maximizing the value of each batch requires high cross-video diversity. Recent methods improve diversity for image generation, but for videos they often degrade within-video temporal consistency and require costly backpropagation through a video decoder. We propose a joint-sampling framework for flow-matching video generators that improves batch diversity while preserving temporal consistency. Our approach applies diversity-driven updates and then removes only the components that would decrease a temporal-consistency objective. To avoid image-space gradients, we compute both objectives with lightweight latent-space models, avoiding video decoding and decoder backpropagation. Experiments on a state-of-the-art text-to-video flow-matching model show diversity comparable to strong joint-sampling baselines while substantially improving temporal consistency and color naturalness. Code will be released.

</details>


### [41] [Training-Free Zero-Shot Anomaly Detection in 3D Brain MRI with 2D Foundation Models](https://arxiv.org/abs/2602.15315)
*Tai Le-Gia,Jaehyun Ahn*

Main category: cs.CV

TL;DR: 提出一种全训练零样本三维医学图像异常检测框架，通过聚合多轴切片特征构建三维局部体素标记，可直接用于基于距离的异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有零样本三维医学图像异常检测方法难以捕捉体积结构，局限于二维切片特征或依赖视觉语言模型。

Method: 构建全训练零样本框架，将二维基础模型处理的多轴切片进行聚合，生成恢复了三维空间信息的局部体素标记，并将其整合到基于距离的批量异常检测流程中。

Result: 所提出的框架能够有效地将零样本异常检测从二维编码器扩展到三维MRI体积，证明了无需训练、基于批量的零样本方法可以用于体积异常检测。

Conclusion: 该框架提供了一种计算效率高、无需微调、提示或监督的三维医学图像异常检测的简单而鲁棒的方法。

Abstract: Zero-shot anomaly detection (ZSAD) has gained increasing attention in medical imaging as a way to identify abnormalities without task-specific supervision, but most advances remain limited to 2D datasets. Extending ZSAD to 3D medical images has proven challenging, with existing methods relying on slice-wise features and vision-language models, which fail to capture volumetric structure. In this paper, we introduce a fully training-free framework for ZSAD in 3D brain MRI that constructs localized volumetric tokens by aggregating multi-axis slices processed by 2D foundation models. These 3D patch tokens restore cubic spatial context and integrate directly with distance-based, batch-level anomaly detection pipelines. The framework provides compact 3D representations that are practical to compute on standard GPUs and require no fine-tuning, prompts, or supervision. Our results show that training-free, batch-based ZSAD can be effectively extended from 2D encoders to full 3D MRI volumes, offering a simple and robust approach for volumetric anomaly detection.

</details>


### [42] [Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs](https://arxiv.org/abs/2602.15318)
*Libo Zhang,Zhaoning Zhang,Wangyang Hong,Peng Qiao,Dongsheng Li*

Main category: cs.CV

TL;DR: 提出Sparrow框架，解决视频大语言模型（Vid-LLMs）在推断过程中因关键值缓存爆炸和上下文窗口不匹配导致的性能下降问题，通过视觉语义内化、文本锚定窗口注意力、中间层视觉状态桥接以及多token预测策略，显著加速了推断速度并解决了长序列性能退化。


<details>
  <summary>Details</summary>
Motivation: 现有的推断加速技术（如投机解码）在视频大语言模型（Vid-LLMs）上存在严重的性能下降问题，这归因于注意力稀释和负视觉增益，主要由关键值缓存爆炸和上下文窗口不匹配引起。

Method: Sparrow框架采用以下技术：1. 视觉感知文本锚定窗口注意力，通过隐藏状态重用将视觉计算完全转移到目标模型；2. 中间层视觉状态桥接，利用语义丰富的中间状态训练草稿模型，过滤低级视觉噪声；3. 多token预测策略，弥合训练-推断分布偏移。

Result: Sparrow框架在处理长视频序列时，即使面对25k个视觉token，也能实现平均2.82倍的速度提升，有效解决了性能下降问题，并为实时长视频任务提供了实用的解决方案。

Conclusion: Sparrow框架通过解决Vid-LLMs推断中的关键挑战，如视觉计算负担和训练-推断不匹配，成功实现了显著的推断加速，并且在长序列处理上表现出色，为Vid-LLMs的实际应用提供了有效途径。

Abstract: Although speculative decoding is widely used to accelerate Vision-Language Models (VLMs) inference, it faces severe performance collapse when applied to Video Large Language Models (Vid-LLMs). The draft model typically falls into the trap of attention dilution and negative visual gain due to key-value cache explosion and context window mismatches. We observe a visual semantic internalization phenomenon in Vid-LLMs, indicating that critical visual semantics are implicitly encoded into text hidden states during deep-layer interactions, which renders raw visual inputs structurally redundant during deep inference. To address this, we propose the Sparrow framework, which first utilizes visually-aware text-anchored window attention via hidden state reuse to fully offload visual computation to the target model, and leverages intermediate-layer visual state bridging to train the draft model with semantic-rich intermediate states, thereby filtering out low-level visual noise. Additionally, a multi-token prediction strategy is introduced to bridge the training-inference distribution shift. Experiments show that Sparrow achieves an average speedup of 2.82x even with 25k visual tokens, effectively resolving the performance degradation in long sequences and offering a practical solution for real-time long video tasks.

</details>


### [43] [EventMemAgent: Hierarchical Event-Centric Memory for Online Video Understanding with Adaptive Tool Use](https://arxiv.org/abs/2602.15329)
*Siwei Wen,Zhangcheng Wang,Xingjian Zhang,Lei Huang,Wenjun Wu*

Main category: cs.CV

TL;DR: 本文提出了一种名为EventMemAgent的在线视频理解框架，通过分层记忆模块和主动感知策略，解决了长视频理解中长距离推理与细粒度细节捕捉的冲突，并在相关基准测试中取得了具有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 在线视频理解面临的挑战是如何处理无限长的视频流，同时保持长距离上下文并捕捉细粒度细节，而现有的多模态大语言模型（MLLMs）由于有限的上下文窗口难以解决这一问题。

Method: EventMemAgent采用分层记忆模块，包括：1. 短期记忆，通过检测事件边界和事件粒度采样动态处理视频帧；2. 长期记忆，按事件对过去观察进行结构化归档。此外，框架还集成了多粒度感知工具包进行主动证据捕获，并使用Agentic RL来内化推理和工具使用策略。

Result: 实验表明，EventMemAgent在在线视频理解基准测试上取得了具有竞争力的结果。

Conclusion: EventMemAgent框架通过引入分层记忆和主动感知机制，有效地克服了在线视频理解中处理长距离上下文和细粒度细节的挑战，为解决此类问题提供了一种新的有效方法。

Abstract: Online video understanding requires models to perform continuous perception and long-range reasoning within potentially infinite visual streams. Its fundamental challenge lies in the conflict between the unbounded nature of streaming media input and the limited context window of Multimodal Large Language Models (MLLMs). Current methods primarily rely on passive processing, which often face a trade-off between maintaining long-range context and capturing the fine-grained details necessary for complex tasks. To address this, we introduce EventMemAgent, an active online video agent framework based on a hierarchical memory module. Our framework employs a dual-layer strategy for online videos: short-term memory detects event boundaries and utilizes event-granular reservoir sampling to process streaming video frames within a fixed-length buffer dynamically; long-term memory structuredly archives past observations on an event-by-event basis. Furthermore, we integrate a multi-granular perception toolkit for active, iterative evidence capture and employ Agentic Reinforcement Learning (Agentic RL) to end-to-end internalize reasoning and tool-use strategies into the agent's intrinsic capabilities. Experiments show that EventMemAgent achieves competitive results on online video benchmarks. The code will be released here: https://github.com/lingcco/EventMemAgent.

</details>


### [44] [Effective and Robust Multimodal Medical Image Analysis](https://arxiv.org/abs/2602.15346)
*Joy Dhar,Nayyar Zaidi,Maryam Haghighat*

Main category: cs.CV

TL;DR: 本文提出了一种名为MAIL（Multi-Attention Integration Learning）的新型多模态融合学习网络，用于解决现有方法在特定模态依赖、计算成本高以及对抗攻击鲁棒性差的问题。MAIL网络通过高效的残差学习注意力模块捕获模态特异性信息，并通过高效的多模态交叉注意力模块学习跨模态的互补共享表示。在此基础上，提出Robust-MAIL通过引入随机投影滤波器和调制注意力噪声来增强对抗鲁棒性。在20个公开数据集上的实验表明，MAIL和Robust-MAIL在性能上优于现有方法，同时显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有多模态融合学习方法存在以下局限性：1）倾向于特定模态，忽略了模态间的有效共享互补信息，限制了其在多疾病分析中的泛化能力；2）依赖计算成本高昂的模型，在资源受限环境下应用受限；3）缺乏对抗攻击的鲁棒性，影响了医疗AI应用的可靠性。因此，有必要开发一种更通用、高效且鲁棒的多模态融合学习方法。

Method: 本文提出了Multi-Attention Integration Learning (MAIL)网络，包含两个核心组件：1）高效的残差学习注意力模块（efficient residual learning attention block），用于捕获精细的模态特异性多尺度模式；2）高效的多模态交叉注意力模块（efficient multimodal cross-attention module），用于学习丰富的互补共享表示。为了提高对抗鲁棒性，进一步提出了Robust-MAIL，通过引入随机投影滤波器（random projection filters）和调制注意力噪声（modulated attention noise）来增强模型的鲁棒性。

Result: 在20个公开数据集上的广泛评估表明，MAIL和Robust-MAIL在性能上均优于现有方法，最高可提升9.34%的性能，同时计算成本降低高达78.3%。

Conclusion: MAIL网络及其鲁棒性增强版本Robust-MAIL在多模态融合学习任务中表现出优越性，能够捕获模态特异性和共享的互补信息，同时保持计算效率和对抗鲁棒性，为医疗AI应用提供了更可靠的预测能力。

Abstract: Multimodal Fusion Learning (MFL), leveraging disparate data from various imaging modalities (e.g., MRI, CT, SPECT), has shown great potential for addressing medical problems such as skin cancer and brain tumor prediction. However, existing MFL methods face three key limitations: a) they often specialize in specific modalities, and overlook effective shared complementary information across diverse modalities, hence limiting their generalizability for multi-disease analysis; b) they rely on computationally expensive models, restricting their applicability in resource-limited settings; and c) they lack robustness against adversarial attacks, compromising reliability in medical AI applications. To address these limitations, we propose a novel Multi-Attention Integration Learning (MAIL) network, incorporating two key components: a) an efficient residual learning attention block for capturing refined modality-specific multi-scale patterns and b) an efficient multimodal cross-attention module for learning enriched complementary shared representations across diverse modalities. Furthermore, to ensure adversarial robustness, we extend MAIL network to design Robust-MAIL by incorporating random projection filters and modulated attention noise. Extensive evaluations on 20 public datasets show that both MAIL and Robust-MAIL outperform existing methods, achieving performance gains of up to 9.34% while reducing computational costs by up to 78.3%. These results highlight the superiority of our approaches, ensuring more reliable predictions than top competitors. Code: https://github.com/misti1203/MAIL-Robust-MAIL.

</details>


### [45] [CREMD: Crowd-Sourced Emotional Multimodal Dogs Dataset](https://arxiv.org/abs/2602.15349)
*Jinho Baek,Houwei Cao,Kate Blackwell*

Main category: cs.CV

TL;DR: 本研究提出了CREMD数据集，旨在研究不同呈现模式（上下文、音频、视频）和标注者特征（如养狗经验、性别、专业程度）如何影响犬类情感识别的感知和标注。结果表明，视觉上下文能提高标注一致性，音频信息可以增加标注者的信心（尤其对愤怒和恐惧），但标注者特征（如非主人、男性）对一致性有出乎意料的影响，而专业人士表现出更高的一致性。


<details>
  <summary>Details</summary>
Motivation: 狗的情感识别对于改善人犬互动、兽医护理以及开发犬类健康监测自动化系统至关重要，但现有方法面临主观性和缺乏标准化真实标准等挑战。

Method: 构建了一个名为CREMD（众包情感多模态犬类数据集）的数据集，包含923个视频片段，以三种模式呈现：无上下文/音频、有上下文/无音频、有上下文/有音频。分析了包括犬主、专业人士、不同性别和经验的标注者的数据，以探究影响犬类情感识别可靠性的因素。

Result: 1. 增加视觉上下文显著提高了标注者之间的一致性。2. 音频线索的影响尚不明确，部分原因是数据集设计限制（缺少仅有音频的条件和干净音频的有限性）。3. 非犬主和男性标注者表现出比犬主和女性标注者更高的一致性，专业人士则显示出更高的标注一致性。4. 音频的加入显著增强了标注者在识别特定情绪（尤其是愤怒和恐惧）时的信心。

Conclusion: 研究揭示了视觉上下文对提高犬类情感识别一致性的重要性，并指出音频信息可以增强特定情绪的识别信心。然而，标注者自身的特征（如养狗经验、性别）以及数据集中音频的质量和呈现方式，都会对犬类情感识别的准确性和可靠性产生复杂的影响。

Abstract: Dog emotion recognition plays a crucial role in enhancing human-animal interactions, veterinary care, and the development of automated systems for monitoring canine well-being. However, accurately interpreting dog emotions is challenging due to the subjective nature of emotional assessments and the absence of standardized ground truth methods. We present the CREMD (Crowd-sourced Emotional Multimodal Dogs Dataset), a comprehensive dataset exploring how different presentation modes (e.g., context, audio, video) and annotator characteristics (e.g., dog ownership, gender, professional experience) influence the perception and labeling of dog emotions. The dataset consists of 923 video clips presented in three distinct modes: without context or audio, with context but no audio, and with both context and audio. We analyze annotations from diverse participants, including dog owners, professionals, and individuals with varying demographic backgrounds and experience levels, to identify factors that influence reliable dog emotion recognition. Our findings reveal several key insights: (1) while adding visual context significantly improved annotation agreement, our findings regarding audio cues are inconclusive due to design limitations (specifically, the absence of a no-context-with-audio condition and limited clean audio availability); (2) contrary to expectations, non-owners and male annotators showed higher agreement levels than dog owners and female annotators, respectively, while professionals showed higher agreement levels, aligned with our initial hypothesis; and (3) the presence of audio substantially increased annotators' confidence in identifying specific emotions, particularly anger and fear.

</details>


### [46] [DAV-GSWT: Diffusion-Active-View Sampling for Data-Efficient Gaussian Splatting Wang Tiles](https://arxiv.org/abs/2602.15355)
*Rong Fu,Jiekai Wu,Haiyun Wei,Yee Tan Jia,Wenxin Zhang,Yang Li,Xiaowen Ma,Wangyu Wu,Simon Fong*

Main category: cs.CV

TL;DR: 本文提出了一种名为DAV-GSWT的数据高效框架，该框架结合了扩散模型和主动视图采样，能够从少量输入观测中合成高质量的3D高斯泼溅（3D Gaussian Splatting）王瓦片（Wang Tiles），解决了现有方法对密集采样重建的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 现有利用王瓦片生成大规模景观的方法依赖于密集的样本重建，这在数据采集和处理上成本高昂。研究动机在于开发一种数据效率更高的方法，以最小的输入数据合成高质量的3D高斯泼溅王瓦片。

Method: DAV-GSWT框架集成了分层不确定性量化机制和生成式扩散模型。它利用扩散模型来推断缺失的结构细节，并结合主动视图采样策略，自主识别最具信息量的观测视角，以确保瓦片之间无缝过渡。

Result: 实验结果表明，DAV-GSWT显著减少了合成高质量3D高斯泼溅王瓦片所需的数据量，同时保持了视觉保真度和交互性能，适用于大规模虚拟环境。

Conclusion: DAV-GSWT通过结合扩散先验和主动视图采样，成功实现了一种数据高效的3D高斯泼溅王瓦片合成方法，克服了现有方法的局限性，为大规模虚拟环境的构建提供了新的解决方案。

Abstract: The emergence of 3D Gaussian Splatting has fundamentally redefined the capabilities of photorealistic neural rendering by enabling high-throughput synthesis of complex environments. While procedural methods like Wang Tiles have recently been integrated to facilitate the generation of expansive landscapes, these systems typically remain constrained by a reliance on densely sampled exemplar reconstructions. We present DAV-GSWT, a data-efficient framework that leverages diffusion priors and active view sampling to synthesize high-fidelity Gaussian Splatting Wang Tiles from minimal input observations. By integrating a hierarchical uncertainty quantification mechanism with generative diffusion models, our approach autonomously identifies the most informative viewpoints while hallucinating missing structural details to ensure seamless tile transitions. Experimental results indicate that our system significantly reduces the required data volume while maintaining the visual integrity and interactive performance necessary for large-scale virtual environments.

</details>


### [47] [Efficient Generative Modeling beyond Memoryless Diffusion via Adjoint Schrödinger Bridge Matching](https://arxiv.org/abs/2602.15396)
*Jeongwoo Shin,Jinhwan Sul,Joonseok Lee,Jaewong Choi,Jaemoo Choi*

Main category: cs.CV

TL;DR: 提出了一种名为Adjoint Schrödinger Bridge Matching (ASBM)的生成模型框架，通过优化前向和后向过程的轨迹，提高生成图像的稳定性和效率，并减少采样步数。


<details>
  <summary>Details</summary>
Motivation: 传统的扩散模型由于前向过程的局限性，会产生弯曲的轨迹和不准确的评分目标，导致采样效率低下。ASBM旨在解决这个问题。

Method: ASBM通过两个阶段实现：1. 将Schrödinger Bridge (SB)前向过程视为一个耦合构造问题，通过数据到能量的采样方式将数据传输到预定义的先验能量。2. 在前向过程引导下，使用简单的匹配损失学习后向生成过程。

Result: ASBM产生了更直观、更高效的采样路径，相比现有方法，在处理高维数据时表现出更好的稳定性和效率。在图像生成实验中，ASBM在更少的采样步数下提高了生成质量。

Conclusion: ASBM能够学习最优轨迹，生成更稳定、更高效的样本，并且可以通过蒸馏技术进一步提升为单步生成器。

Abstract: Diffusion models often yield highly curved trajectories and noisy score targets due to an uninformative, memoryless forward process that induces independent data-noise coupling. We propose Adjoint Schrödinger Bridge Matching (ASBM), a generative modeling framework that recovers optimal trajectories in high dimensions via two stages. First, we view the Schrödinger Bridge (SB) forward dynamic as a coupling construction problem and learn it through a data-to-energy sampling perspective that transports data to an energy-defined prior. Then, we learn the backward generative dynamic with a simple matching loss supervised by the induced optimal coupling. By operating in a non-memoryless regime, ASBM produces significantly straighter and more efficient sampling paths. Compared to prior works, ASBM scales to high-dimensional data with notably improved stability and efficiency. Extensive experiments on image generation show that ASBM improves fidelity with fewer sampling steps. We further showcase the effectiveness of our optimal trajectory via distillation to a one-step generator.

</details>


### [48] [Bridging Day and Night: Target-Class Hallucination Suppression in Unpaired Image Translation](https://arxiv.org/abs/2602.15383)
*Shuwei Li,Lei Tan,Robby T. Tan*

Main category: cs.CV

TL;DR: 提出了一种新颖的框架，用于检测和抑制非配对图像翻译中的语义幻觉，尤其是在日夜转换任务中，通过使用双头判别器进行语义分割和类特定的原型来指导特征空间中的迭代精炼，从而提高下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的日夜非配对图像翻译方法存在语义幻觉问题，即错误地合成目标类别的对象和人造光照效果，严重影响下游任务的性能。

Method: 设计了一个双头判别器，该判别器除了进行分类外，还能执行语义分割，以识别背景区域中的幻觉内容。引入了类特定的原型，通过聚合带注释的目标域对象的特征来构建，作为每个类的语义锚点。基于薛定谔桥（Schrödinger Bridge）的翻译模型，该框架进行迭代精炼，将检测到的幻觉特征在特征空间中显式地推离类原型。

Result: 与现有方法相比，该方法在定性和定量上均表现更优。在BDD100K数据集上，日夜域适应的mAP提高了15.5%，其中易出现幻觉的交通信号灯等类别的性能提升了31.7%。

Conclusion: 所提出的框架能够有效检测和抑制非配对图像翻译中的语义幻觉，通过语义锚定和迭代精炼，显著提高了日夜图像转换的质量和下游任务的性能。

Abstract: Day-to-night unpaired image translation is important to downstream tasks but remains challenging due to large appearance shifts and the lack of direct pixel-level supervision. Existing methods often introduce semantic hallucinations, where objects from target classes such as traffic signs and vehicles, as well as man-made light effects, are incorrectly synthesized. These hallucinations significantly degrade downstream performance. We propose a novel framework that detects and suppresses hallucinations of target-class features during unpaired translation. To detect hallucination, we design a dual-head discriminator that additionally performs semantic segmentation to identify hallucinated content in background regions. To suppress these hallucinations, we introduce class-specific prototypes, constructed by aggregating features of annotated target-domain objects, which act as semantic anchors for each class. Built upon a Schrodinger Bridge-based translation model, our framework performs iterative refinement, where detected hallucination features are explicitly pushed away from class prototypes in feature space, thus preserving object semantics across the translation trajectory.Experiments show that our method outperforms existing approaches both qualitatively and quantitatively. On the BDD100K dataset, it improves mAP by 15.5% for day-to-night domain adaptation, with a notable 31.7% gain for classes such as traffic lights that are prone to hallucinations.

</details>


### [49] [Emergent Morphing Attack Detection in Open Multi-modal Large Language Models](https://arxiv.org/abs/2602.15461)
*Marija Ivanovska,Vitomir Štruc*

Main category: cs.CV

TL;DR: 本研究首次系统地评估了开源多模态大语言模型（MLLMs）在单图像变形攻击检测（MAD）方面的零样本能力，发现即使无需特定任务训练，许多 MLLMs 也展现出一定的检测能力，其中 LLaVA1.6-Mistral-7B 性能最优，超过了现有的特定任务 MAD 方法。


<details>
  <summary>Details</summary>
Motivation: 现有的变形攻击检测（MAD）系统通常需要针对特定攻击类型进行训练，并且泛化能力较差。而开源多模态大语言模型（MLLMs）在视觉-语言推理方面表现出色，其在生物识别取证领域的潜力尚未被充分发掘。

Method: 采用公开可用的权重，通过标准化的、可复现的协议，对开源 MLLMs 进行单图像 MAD 的零样本评估。评估了多种变形技术。

Result: 在多种变形技术下，许多 MLLMs 在零样本情况下展现出非平凡的判别能力。LLaVA1.6-Mistral-7B 达到了最先进的性能，其等错误率（EER）比高度竞争性的特定任务 MAD 基线至少提高了 23%。

Conclusion: 多模态预训练能够隐式地编码指示变形伪影的细粒度面部不一致性，从而实现零样本的取证敏感性。开源 MLLMs 可以作为可复现、可解释且具有竞争力的生物识别安全和取证图像分析基础。此外，通过有针对性的微调或轻量级适应，可以进一步开发出先进的 MAD 系统，提高准确性和效率，同时保持可解释性。

Abstract: Face morphing attacks threaten biometric verification, yet most morphing attack detection (MAD) systems require task-specific training and generalize poorly to unseen attack types. Meanwhile, open-source multimodal large language models (MLLMs) have demonstrated strong visual-linguistic reasoning, but their potential in biometric forensics remains underexplored. In this paper, we present the first systematic zero-shot evaluation of open-source MLLMs for single-image MAD, using publicly available weights and a standardized, reproducible protocol. Across diverse morphing techniques, many MLLMs show non-trivial discriminative ability without any fine-tuning or domain adaptation, and LLaVA1.6-Mistral-7B achieves state-of-the-art performance, surpassing highly competitive task-specific MAD baselines by at least 23% in terms of equal error rate (EER). The results indicate that multimodal pretraining can implicitly encode fine-grained facial inconsistencies indicative of morphing artifacts, enabling zero-shot forensic sensitivity. Our findings position open-source MLLMs as reproducible, interpretable, and competitive foundations for biometric security and forensic image analysis. This emergent capability also highlights new opportunities to develop state-of-the-art MAD systems through targeted fine-tuning or lightweight adaptation, further improving accuracy and efficiency while preserving interpretability. To support future research, all code and evaluation protocols will be released upon publication.

</details>


### [50] [RPT-SR: Regional Prior attention Transformer for infrared image Super-Resolution](https://arxiv.org/abs/2602.15490)
*Youngwan Jin,Incheol Park,Yagiz Nalcakan,Hyeongjin Ju,Sanghyeop Yeo,Shiho Kim*

Main category: cs.CV

TL;DR: 提出了一种名为RPT-SR的区域先验注意力Transformer模型，用于红外图像超分辨率，通过融合固定场景布局信息和当前帧内容来提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的通用超分辨率模型（特别是Vision Transformer）在固定或近乎静态视角的红外成像场景（如监控和自动驾驶）中效率低下，未能利用场景中固有的空间先验信息，导致冗余学习和性能不佳。

Method: 提出了一种名为RPT-SR的新型架构，采用双令牌框架。该框架融合了（1）学习到的区域先验令牌（作为场景全局结构的持久记忆）和（2）捕获当前输入帧特定内容的局部令牌。这些令牌被纳入注意力机制，使先验能够动态调节局部重建过程。

Result: 在LWIR和SWIR光谱的多个数据集上取得了新的最先进性能，证明了RPT-SR的广泛适用性和多功能性。与大多数仅关注单一红外波段的先前工作不同，RPT-SR在不同数据集上均表现出色。

Conclusion: RPT-SR通过显式编码场景布局信息到注意力机制中，有效解决了通用超分辨率模型在固定视角红外成像场景中的效率问题，并在跨不同红外光谱的数据集上均取得了优越的性能。

Abstract: General-purpose super-resolution models, particularly Vision Transformers, have achieved remarkable success but exhibit fundamental inefficiencies in common infrared imaging scenarios like surveillance and autonomous driving, which operate from fixed or nearly-static viewpoints. These models fail to exploit the strong, persistent spatial priors inherent in such scenes, leading to redundant learning and suboptimal performance. To address this, we propose the Regional Prior attention Transformer for infrared image Super-Resolution (RPT-SR), a novel architecture that explicitly encodes scene layout information into the attention mechanism. Our core contribution is a dual-token framework that fuses (1) learnable, regional prior tokens, which act as a persistent memory for the scene's global structure, with (2) local tokens that capture the frame-specific content of the current input. By utilizing these tokens into an attention, our model allows the priors to dynamically modulate the local reconstruction process. Extensive experiments validate our approach. While most prior works focus on a single infrared band, we demonstrate the broad applicability and versatility of RPT-SR by establishing new state-of-the-art performance across diverse datasets covering both Long-Wave (LWIR) and Short-Wave (SWIR) spectra

</details>


### [51] [LEADER: Lightweight End-to-End Attention-Gated Dual Autoencoder for Robust Minutiae Extraction](https://arxiv.org/abs/2602.15493)
*Raffaele Cappelli,Matteo Ferrara*

Main category: cs.CV

TL;DR: 本文提出了一种名为LEADER的轻量级端到端深度学习模型，用于直接从原始指纹图像中提取细节特征（位置、方向、类型），无需额外的预处理和后处理步骤。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在指纹细节特征提取方面取得了进展，但真正实现端到端的、消除独立预处理和后处理步骤的方法仍然很少。现有方法通常需要额外的步骤来处理原始图像，增加了复杂性并可能引入误差。

Method: LEADER是一个轻量级的神经网络，参数量仅为0.9M。它整合了非极大值抑制和角度解码，实现了端到端的推理。该模型采用了一种新颖的“Castle-Moat-Rampart”地面真实编码方法，并设计了一个双自动编码器结构，通过注意力门控机制相互连接。

Result: 在普通指纹数据集上，LEADER达到了最先进的准确性。在NIST SD27数据集（包含潜在指纹）上，其F1分数比专门的潜在指纹细节提取器高34%。在样本级分析中，LEADER的平均排名为2.07，并在47%的样本中排名第一，优于其他方法。模型学习到的内部表示与传统的指纹域特征（如分割掩码、方向场、频率图和骨架）一致。推理速度快，GPU上15ms，CPU上322ms，优于商业软件。

Conclusion: LEADER是一种高效、准确且具有良好泛化能力的端到端指纹细节特征提取方法。它通过创新的网络结构和编码策略，克服了现有方法的局限性，并在性能和效率上取得了显著的优势，同时通过开源代码促进了可重复性研究。

Abstract: Minutiae extraction, a fundamental stage in fingerprint recognition, is increasingly shifting toward deep learning. However, truly end-to-end methods that eliminate separate preprocessing and postprocessing steps remain scarce. This paper introduces LEADER (Lightweight End-to-end Attention-gated Dual autoencodER), a neural network that maps raw fingerprint images to minutiae descriptors, including location, direction, and type. The proposed architecture integrates non-maximum suppression and angular decoding to enable complete end-to-end inference using only 0.9M parameters. It employs a novel "Castle-Moat-Rampart" ground-truth encoding and a dual-autoencoder structure, interconnected through an attention-gating mechanism. Experimental evaluations demonstrate state-of-the-art accuracy on plain fingerprints and robust cross-domain generalization to latent impressions. Specifically, LEADER attains a 34% higher F1-score on the NIST SD27 dataset compared to specialized latent minutiae extractors. Sample-level analysis on this challenging benchmark reveals an average rank of 2.07 among all compared methods, with LEADER securing the first-place position in 47% of the samples-more than doubling the frequency of the second-best extractor. The internal representations learned by the model align with established fingerprint domain features, such as segmentation masks, orientation fields, frequency maps, and skeletons. Inference requires 15ms on GPU and 322ms on CPU, outperforming leading commercial software in computational efficiency. The source code and pre-trained weights are publicly released to facilitate reproducibility.

</details>


### [52] [Semantic-Guided 3D Gaussian Splatting for Transient Object Removal](https://arxiv.org/abs/2602.15516)
*Aditi Prabakaran,Priyesh Shukla*

Main category: cs.CV

TL;DR: 提出了一种基于语义过滤的框架，利用视觉语言模型来移除3D高斯泼溅（3DGS）重建中的瞬态对象引起的鬼影伪影。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS瞬态对象移除方法存在内存开销大或易受视差模糊影响的缺点。

Method: 该框架通过累加渲染视图与预设文本提示之间CLIP相似性分数来对每个高斯进行语义分类，然后对超过阈值的高斯进行不透明度正则化和剪枝。

Result: 在RobustNeRF基准测试的四个序列上，该方法一致性地提高了重建质量，同时保持了最小的内存开销和实时渲染性能。

Conclusion: 语义引导是一种有效的策略，可以处理具有可预测的干扰类别场景中的瞬态移除问题，并且可以解决视差模糊问题。

Abstract: Transient objects in casual multi-view captures cause ghosting artifacts in 3D Gaussian Splatting (3DGS) reconstruction. Existing solutions relied on scene decomposition at significant memory cost or on motion-based heuristics that were vulnerable to parallax ambiguity. A semantic filtering framework was proposed for category-aware transient removal using vision-language models. CLIP similarity scores between rendered views and distractor text prompts were accumulated per-Gaussian across training iterations. Gaussians exceeding a calibrated threshold underwent opacity regularization and periodic pruning. Unlike motion-based approaches, semantic classification resolved parallax ambiguity by identifying object categories independently of motion patterns. Experiments on the RobustNeRF benchmark demonstrated consistent improvement in reconstruction quality over vanilla 3DGS across four sequences, while maintaining minimal memory overhead and real-time rendering performance. Threshold calibration and comparisons with baselines validated semantic guidance as a practical strategy for transient removal in scenarios with predictable distractor categories.

</details>


### [53] [Advanced Acceptance Score: A Holistic Measure for Biometric Quantification](https://arxiv.org/abs/2602.15535)
*Aman Verma,Seshan Srirangarajan,Sumantra Dutta Roy*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法来评估手势生物识别分数，该方法基于排序、相关性和身份特征的解缠，并证明了其比现有方法更有效。


<details>
  <summary>Details</summary>
Motivation: 现有生物识别能力估计方法依赖于错误率，但错误率并不能很好地指示分数的质量。因此，需要一套更全面的评估指标来衡量生物识别分数的优劣。

Method: 文章提出了一种先进的接受分数（Advanced Acceptance Score）作为整体评估指标。该指标基于以下几个方面：1. 输出分数的排序和相关性；2. 对高排名手势的高分和低排名手势的低分给予奖励；3. 考虑输出分数趋势与真实分数趋势的一致性；4. 将身份特征解缠作为折扣因子。通过对三个数据集和五个 SOTA 模型进行实验来评估其有效性。

Result: 实验结果表明，使用所提出的度量方法选择的最优分数比现有方法更合适。此外，所提出的度量方法与现有度量方法具有相关性，这进一步验证了其可靠性。

Conclusion: 本文提出的先进接受分数是一种有效的、全面的评估手势生物识别分数质量的指标，它考虑了排序、相关性和身份特征的解缠，并在实验中证明了其优越性。

Abstract: Quantifying biometric characteristics within hand gestures involve derivation of fitness scores from a gesture and identity aware feature space. However, evaluating the quality of these scores remains an open question. Existing biometric capacity estimation literature relies upon error rates. But these rates do not indicate goodness of scores. Thus, in this manuscript we present an exhaustive set of evaluation measures. We firstly identify ranking order and relevance of output scores as the primary basis for evaluation. In particular, we consider both rank deviation as well as rewards for: (i) higher scores of high ranked gestures and (ii) lower scores of low ranked gestures. We also compensate for correspondence between trends of output and ground truth scores. Finally, we account for disentanglement between identity features of gestures as a discounting factor. Integrating these elements with adequate weighting, we formulate advanced acceptance score as a holistic evaluation measure. To assess effectivity of the proposed we perform in-depth experimentation over three datasets with five state-of-the-art (SOTA) models. Results show that the optimal score selected with our measure is more appropriate than existing other measures. Also, our proposed measure depicts correlation with existing measures. This further validates its reliability. We have made our \href{https://github.com/AmanVerma2307/MeasureSuite}{code} public.

</details>


### [54] [Dynamic Training-Free Fusion of Subject and Style LoRAs](https://arxiv.org/abs/2602.15539)
*Qinglong Cao,Yuntian Chen,Chao Ma,Xiaokang Yang*

Main category: cs.CV

TL;DR: 提出一种动态训练免费LoRA融合框架，通过在生成过程中动态计算KL散度选择LoRA权重，并结合基于度量的梯度校正来优化生成轨迹，从而实现一致的主题-风格合成。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA融合方法使用静态启发式方法，忽略了LoRA自适应调整的初衷以及采样输入的随机性，导致在多LoRA融合生成时效果不佳。

Method: 该框架在生成过程的每层LoRA应用处，动态计算基础模型特征与各LoRA生成特征间的KL散度，自适应选择权重进行融合；在反向去噪阶段，通过CLIP和DINO等度量得分，动态应用梯度校正，进一步优化生成轨迹。

Result: 通过特征级选择和度量引导的潜在调整机制，该方法在整个扩散时间线上动态实现连贯的主题-风格合成，无需重新训练。实验证明，该方法在各种主题-风格组合上，无论在定性还是定量上都优于现有的LoRA融合方法。

Conclusion: 所提出的动态训练免费融合框架能够有效地在生成过程中动态地融合多个LoRA，实现高质量的主题-风格合成，克服了现有静态融合方法的局限性。

Abstract: Recent studies have explored the combination of multiple LoRAs to simultaneously generate user-specified subjects and styles. However, most existing approaches fuse LoRA weights using static statistical heuristics that deviate from LoRA's original purpose of learning adaptive feature adjustments and ignore the randomness of sampled inputs. To address this, we propose a dynamic training-free fusion framework that operates throughout the generation process. During the forward pass, at each LoRA-applied layer, we dynamically compute the KL divergence between the base model's original features and those produced by subject and style LoRAs, respectively, and adaptively select the most appropriate weights for fusion. In the reverse denoising stage, we further refine the generation trajectory by dynamically applying gradient-based corrections derived from objective metrics such as CLIP and DINO scores, providing continuous semantic and stylistic guidance. By integrating these two complementary mechanisms-feature-level selection and metric-guided latent adjustment-across the entire diffusion timeline, our method dynamically achieves coherent subject-style synthesis without any retraining. Extensive experiments across diverse subject-style combinations demonstrate that our approach consistently outperforms state-of-the-art LoRA fusion methods both qualitatively and quantitatively.

</details>


### [55] [Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning](https://arxiv.org/abs/2602.15579)
*Amal Lahchim,Lambros Athanasiou*

Main category: cs.CV

TL;DR: 本文提出了一种全自动的机器学习流水线，用于分割和分类冠状动脉光学相干断层扫描（OCT）图像中的血管，取得了优异的分割精度和分类准确率，并具有低计算复杂度和很少的手动标注需求。


<details>
  <summary>Details</summary>
Motivation: 由于噪声、成像伪影和复杂的组织结构，对冠状动脉OCT图像进行准确的血管分割和分类存在挑战。

Method: 该方法包括图像预处理、导丝伪影去除、极坐标到笛卡尔坐标转换、无监督K-means聚类、局部特征提取，并使用Logistic回归和支持向量机（SVM）进行像素级血管分类。

Result: 实验结果表明，该方法在精度、召回率和F1分数上最高可达1.00，整体分类准确率为99.68%。

Conclusion: 该方法能够准确检测血管边界，计算复杂度低，所需手动标注少，为自动OCT图像分析提供了一个可靠且高效的解决方案，并有望应用于临床决策支持和实时医学图像处理。

Abstract: Intracoronary Optical Coherence Tomography (OCT) enables high-resolution visualization of coronary vessel anatomy but presents challenges due to noise, imaging artifacts, and complex tissue structures. This paper proposes a fully automated pipeline for vessel segmentation and classification in OCT images using machine learning techniques. The proposed method integrates image preprocessing, guidewire artifact removal, polar-to-Cartesian transformation, unsupervised K-means clustering, and local feature extraction. These features are used to train Logistic Regression and Support Vector Machine classifiers for pixel-wise vessel classification. Experimental results demonstrate excellent performance, achieving precision, recall, and F1-score values up to 1.00 and overall classification accuracy of 99.68%. The proposed approach provides accurate vessel boundary detection while maintaining low computational complexity and requiring minimal manual annotation. This method offers a reliable and efficient solution for automated OCT image analysis and has potential applications in clinical decision support and real-time medical image processing.

</details>


### [56] [Revealing and Enhancing Core Visual Regions: Harnessing Internal Attention Dynamics for Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2602.15556)
*Guangtao Lyu,Qi Liu,Chenghao Xu,Jiexi Yan,Muli Yang,Xueting Li,Fen Fang,Cheng Deng*

Main category: cs.CV

TL;DR: 提出了一种名为 PADE 的训练无关方法，通过增强模型内部的积极注意力动态来解决大型视觉语言模型（LVLM）的幻觉问题，从而提高视觉基础和减少不一致性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）虽然具有强大的多模态推理能力，但容易产生幻觉，输出与视觉输入或用户指令不一致。现有的训练无关方法计算开销大、可能产生干扰，并且容易受到注意力汇聚（attention sink）现象的影响。

Method: PADE 是一种训练无关的注意力干预方法。它通过构建 PAD（Positive Attention Dynamics）图来识别语义核心的视觉区域，并对每个注意力头应用 MAD（Median Absolute Deviation）Scaling 来自适应地控制干预强度。此外，它还利用 System-Token Compensation 来保持对复杂指令的注意力并支持长期的输出一致性。

Result: 在多个 LVLM 和基准测试上的实验表明，PADE 能够提高视觉基础能力并减少幻觉。

Conclusion: 利用内部注意力动态是实现可靠多模态推理的有效途径，PADE 证明了这一点。

Abstract: LVLMs have achieved strong multimodal reasoning capabilities but remain prone to hallucinations, producing outputs inconsistent with visual inputs or user instructions. Existing training-free methods, including contrastive decoding and auxiliary expert models, which incur several times more computational overhead and may introduce potential interference, as well as static internal signal enhancement, are often vulnerable to the attention sink phenomenon. We find that internal Positive Attention Dynamics (PAD) in LVLMs naturally reveal semantically core visual regions under the distortions of attention sinks. Based on this, we propose Positive Attention Dynamics Enhancement (PADE), a training-free attention intervention that constructs a PAD map to identify semantically core visual regions, applies per-head Median Absolute Deviation Scaling to adaptively control the intervention strength, and leverages System-Token Compensation to maintain attention to complex user instructions and support long-term output consistency. Experiments on multiple LVLMs and benchmarks show that PADE improves visual grounding and reduces hallucinations, validating the effectiveness of leveraging internal attention dynamics for reliable multimodal reasoning.

</details>


### [57] [An Industrial Dataset for Scene Acquisitions and Functional Schematics Alignment](https://arxiv.org/abs/2602.15584)
*Flavien Armangeon,Thibaud Ehret,Enric Meinhardt-Llopis,Rafael Grompone von Gioi,Guillaume Thibault,Marc Petit,Gabriele Facciolo*

Main category: cs.CV

TL;DR: 该研究提出IRlS-v2数据集，并结合分割和图匹配方法，旨在自动化对齐工业设施的2D/3D数据与功能示意图，以解决现有手动方法效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 现有手动方法在对齐工业设施的2D/3D数据与功能示意图时效率低下且难以扩展，尤其是在缺乏原生数字模型的老旧工业设施中。同时，示意图与现实之间的一致性问题以及公开数据集的稀缺性增加了该问题的难度。

Method: 研究者提出了IRlS-v2数据集，该数据集包含图像、点云、2D标注框和分割掩码、CAD模型、3D管道布线信息和P&ID。在实际案例研究中，结合了图像分割和图匹配技术来尝试对齐过程。

Result: 通过结合分割和图匹配的方法，研究旨在减少对齐功能示意图与2D/3D场景数据所需的时间。

Conclusion: IRlS-v2数据集为进一步研究对齐问题提供了支持。研究通过实验验证了结合分割和图匹配技术在实际案例中能够提高对齐效率。

Abstract: Aligning functional schematics with 2D and 3D scene acquisitions is crucial for building digital twins, especially for old industrial facilities that lack native digital models. Current manual alignment using images and LiDAR data does not scale due to tediousness and complexity of industrial sites. Inconsistencies between schematics and reality, and the scarcity of public industrial datasets, make the problem both challenging and underexplored. This paper introduces IRIS-v2, a comprehensive dataset to support further research. It includes images, point clouds, 2D annotated boxes and segmentation masks, a CAD model, 3D pipe routing information, and the P&ID (Piping and Instrumentation Diagram). The alignment is experimented on a practical case study, aiming at reducing the time required for this task by combining segmentation and graph matching.

</details>


### [58] [RaCo: Ranking and Covariance for Practical Learned Keypoints](https://arxiv.org/abs/2602.15755)
*Abhiram Shenoi,Philipp Lindenberger,Paul-Edouard Sarlin,Marc Pollefeys*

Main category: cs.CV

TL;DR: RaCo是一个轻量级神经网络，通过可重复的关键点检测、可微排序和协方差估计，学习适用于多种3D计算机视觉任务的鲁棒且通用的关键点。它仅在透视图像裁剪上进行训练，无需共可见图像对，并具有强大的旋转鲁棒性，在多个挑战性数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是设计一个轻量级、鲁棒且通用的关键点检测器，适用于多种3D计算机视觉任务，同时避免对共可见图像对或复杂的等变网络结构的需求。

Method: RaCo模型包含三个主要组成部分：可重复的关键点检测器，用于最大化有限数量关键点匹配的可微排序器，以及量化度量尺度空间不确定性的协方差估计器。模型仅在透视图像裁剪上进行训练，并通过大量数据增强实现旋转鲁棒性。

Result: RaCo在多个具有挑战性的数据集上进行了评估，在关键点可重复性和双视图匹配方面表现出最先进的性能，尤其是在大幅面内旋转的情况下。它能够独立估计关键点排序和度量协方差，而无需额外的标签。

Conclusion: RaCo提供了一种有效且简单的策略，可以独立地估计关键点的排序和度量协方差，从而检测出可解释且可重复的兴趣点，适用于各种3D计算机视觉任务，并且在旋转鲁棒性方面表现出色。

Abstract: This paper introduces RaCo, a lightweight neural network designed to learn robust and versatile keypoints suitable for a variety of 3D computer vision tasks. The model integrates three key components: the repeatable keypoint detector, a differentiable ranker to maximize matches with a limited number of keypoints, and a covariance estimator to quantify spatial uncertainty in metric scale. Trained on perspective image crops only, RaCo operates without the need for covisible image pairs. It achieves strong rotational robustness through extensive data augmentation, even without the use of computationally expensive equivariant network architectures. The method is evaluated on several challenging datasets, where it demonstrates state-of-the-art performance in keypoint repeatability and two-view matching, particularly under large in-plane rotations. Ultimately, RaCo provides an effective and simple strategy to independently estimate keypoint ranking and metric covariance without additional labels, detecting interpretable and repeatable interest points. The code is available at https://github.com/cvg/RaCo.

</details>


### [59] [Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation](https://arxiv.org/abs/2602.15650)
*Marco Salmè,Federico Siciliano,Fabrizio Silvestri,Paolo Soda,Rosa Sicilia,Valerio Guarrasi*

Main category: cs.CV

TL;DR: 本文提出了一种名为CEMRAG的统一框架，通过将医学影像分解为可解释的临床概念并与多模态检索增强生成（RAG）相结合，来提高放射报告生成（RRG）的准确性和可解释性。实验表明，CEMRAG在提高诊断准确性的同时，也增强了模型的透明度，挑战了可解释性和性能之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的放射报告生成（RRG）方法虽然有潜力，但由于缺乏可解释性和容易出现幻觉（与影像证据不符的发现），其临床应用受到限制。现有研究通常将可解释性和准确性视为独立的目标。

Method: 提出CEMRAG（Concept-Enhanced Multimodal RAG）统一框架，将视觉表示分解为可解释的临床概念，并将其与多模态RAG相结合。该方法利用增强的上下文提示进行RRG，提高了可解释性和事实准确性。

Result: 在MIMIC-CXR和IU X-Ray数据集上，CEMRAG在多种VLM架构、训练策略和检索配置下，均在临床准确性指标和NLP标准度量上取得了比传统RAG和仅概念基线一致的改进。

Conclusion: 透明的视觉概念可以增强而非损害医学VLM的诊断准确性，挑战了可解释性与性能之间的权衡。CEMRAG的模块化设计将可解释性分解为视觉透明度和结构化的语言模型条件，为实现临床上值得信赖的AI辅助放射学提供了一条原则性的途径。

Abstract: Radiology Report Generation (RRG) through Vision-Language Models (VLMs) promises to reduce documentation burden, improve reporting consistency, and accelerate clinical workflows. However, their clinical adoption remains limited by the lack of interpretability and the tendency to hallucinate findings misaligned with imaging evidence. Existing research typically treats interpretability and accuracy as separate objectives, with concept-based explainability techniques focusing primarily on transparency, while Retrieval-Augmented Generation (RAG) methods targeting factual grounding through external retrieval. We present Concept-Enhanced Multimodal RAG (CEMRAG), a unified framework that decomposes visual representations into interpretable clinical concepts and integrates them with multimodal RAG. This approach exploits enriched contextual prompts for RRG, improving both interpretability and factual accuracy. Experiments on MIMIC-CXR and IU X-Ray across multiple VLM architectures, training regimes, and retrieval configurations demonstrate consistent improvements over both conventional RAG and concept-only baselines on clinical accuracy metrics and standard NLP measures. These results challenge the assumed trade-off between interpretability and performance, showing that transparent visual concepts can enhance rather than compromise diagnostic accuracy in medical VLMs. Our modular design decomposes interpretability into visual transparency and structured language model conditioning, providing a principled pathway toward clinically trustworthy AI-assisted radiology.

</details>


### [60] [A Novel Public Dataset for Strawberry (Fragaria x ananassa) Ripeness Detection and Comparative Evaluation of YOLO-Based Models](https://arxiv.org/abs/2602.15656)
*Mustafa Yurdakul,Zeynep Sena Bastug,Ali Emre Gok,Sakir Taşdemir*

Main category: cs.CV

TL;DR: 本研究发布了一个新的、公开的草莓成熟度数据集（566张图片，1201个标注对象），并在该数据集上使用YOLOv8、YOLOv9和YOLO11模型进行了性能比较。结果表明，YOLOv9c在精确率方面表现最佳，YOLO11s在召回率方面表现最佳，而YOLOv8s在mAP@50方面表现最佳，表明小型和中型模型在该数据集上表现均衡且高效。


<details>
  <summary>Details</summary>
Motivation: 传统的草莓成熟度评估方法（如目视检查）存在主观性和误差大的问题，因此需要计算机辅助系统。然而，现有研究缺乏公开、全面的数据集，阻碍了该领域的比较和进展。

Method: 创建了一个新的、公开的草莓成熟度数据集，包含在土耳其两个温室中，在不同光照和环境条件下拍摄的566张图像和1201个标注对象。然后，使用YOLOv8、YOLOv9和YOLO11（包括不同的变体）在创建的数据集上进行了比较测试。

Result: 在精确率方面，YOLOv9c模型达到了最高的90.94%。在召回率方面，YOLO11s模型达到了最高的83.74%。在通用的性能指标mAP@50方面，YOLOv8s模型表现最好，成功率为86.09%。

Conclusion: 本研究提出的公开数据集为草莓成熟度检测研究提供了一个重要的参考基准。实验结果表明，YOLOv8s、YOLOv9c和YOLO11s等模型在该数据集上表现出不同的优势，小型和中型模型在该类数据集上具有更均衡和高效的性能，为智能农业应用奠定了基础。

Abstract: The strawberry (Fragaria x ananassa), known worldwide for its economic value and nutritional richness, is a widely cultivated fruit. Determining the correct ripeness level during the harvest period is crucial for both preventing losses for producers and ensuring consumers receive a quality product. However, traditional methods, i.e., visual assessments alone, can be subjective and have a high margin of error. Therefore, computer-assisted systems are needed. However, the scarcity of comprehensive datasets accessible to everyone in the literature makes it difficult to compare studies in this field. In this study, a new and publicly available strawberry ripeness dataset, consisting of 566 images and 1,201 labeled objects, prepared under variable light and environmental conditions in two different greenhouses in Turkey, is presented to the literature. Comparative tests conducted on the data set using YOLOv8, YOLOv9, and YOLO11-based models showed that the highest precision value was 90.94% in the YOLOv9c model, while the highest recall value was 83.74% in the YOLO11s model. In terms of the general performance criterion mAP@50, YOLOv8s was the best performing model with a success rate of 86.09%. The results show that small and medium-sized models work more balanced and efficiently on this type of dataset, while also establishing a fundamental reference point for smart agriculture applications.

</details>


### [61] [Bayesian Optimization for Design Parameters of 3D Image Data Analysis](https://arxiv.org/abs/2602.15660)
*David Exler,Joaquin Eduardo Urrutia Gómez,Martin Krüger,Maike Schliephake,John Jbeily,Mario Vitacolonna,Rüdiger Rudolf,Markus Reischl*

Main category: cs.CV

TL;DR: 提出了一种名为3D数据分析优化管道（3D data Analysis Optimization Pipeline）的方法，利用两个阶段的贝叶斯优化来自动化3D生物医学图像的分割和分类模型的选择与参数调整，并引入了辅助类标注工作流以减少人工工作量。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的3D生物医学图像分割和分类方法，在实际应用中存在模型选择和参数调整困难的问题，人工分析成本高昂。

Method: 该方法包含两个阶段的贝叶斯优化：第一阶段，优化分割模型和后处理参数，使用一个定制的分割质量指标作为目标函数；第二阶段，优化分类器设计，包括编码器、分类头架构、先验知识融合和预训练策略，并引入辅助类标注工作流。

Result: 在四个案例研究中，该管道能够高效地为不同数据集找到有效的模型和参数配置。

Conclusion: 3D数据分析优化管道能够有效简化和加速3D生物医学图像的分割和分类模型的开发过程，并降低了对人工标注的需求。

Abstract: Deep learning-based segmentation and classification are crucial to large-scale biomedical imaging, particularly for 3D data, where manual analysis is impractical. Although many methods exist, selecting suitable models and tuning parameters remains a major bottleneck in practice. Hence, we introduce the 3D data Analysis Optimization Pipeline, a method designed to facilitate the design and parameterization of segmentation and classification using two Bayesian Optimization stages. First, the pipeline selects a segmentation model and optimizes postprocessing parameters using a domain-adapted syntactic benchmark dataset. To ensure a concise evaluation of segmentation performance, we introduce a segmentation quality metric that serves as the objective function. Second, the pipeline optimizes design choices of a classifier, such as encoder and classifier head architectures, incorporation of prior knowledge, and pretraining strategies. To reduce manual annotation effort, this stage includes an assisted class-annotation workflow that extracts predicted instances from the segmentation results and sequentially presents them to the operator, eliminating the need for manual tracking. In four case studies, the 3D data Analysis Optimization Pipeline efficiently identifies effective model and parameter configurations for individual datasets.

</details>


### [62] [Criteria-first, semantics-later: reproducible structure discovery in image-based sciences](https://arxiv.org/abs/2602.15712)
*Jan Bumberger*

Main category: cs.CV

TL;DR: 该论文提出了一种“先准则后语义”的图像分析新范式，旨在解决当前“先语义后结构”范式在开放性科学发现、跨传感器/跨站点可比性以及领域本体随时间漂移等场景下的局限性。新范式将无领域语义的准则驱动结构提取与下游的语义映射分离，为跨学科图像科学研究提供了一个可复用的通用框架。


<details>
  <summary>Details</summary>
Motivation: 当前图像分析的主流方法（先语义后结构）在开放式科学发现、跨传感器/站点的数据整合以及长期监测中存在不足，因为领域本体和标签集会随时间变化。这种方法在面对标签不具可扩展性时会系统性失效。

Method: 提出了一种“先准则后语义”的统一框架，将准则定义的、无领域语义的结构提取与下游的领域本体/词汇语义映射分离开。该框架依赖于明确的最优准则来发现稳定的数据划分、结构场或层次结构，而不是依赖于局部领域本体。这种方法基于控制论、观测即区分和信息论的原理。

Result: 该方法展示了跨领域证据，表明当标签不可扩展时，“先准则”组件会反复出现。该框架能够实现可复用的科学分析，并且下游的语义映射允许对发现的结构进行多元解释和明确的交叉比对，而无需重写上游的提取过程。

Conclusion: “先准则后语义”的分析范式是实现可复用科学的关键。它能够生成稳定的、基于准则的结构化产品，这些产品可以被视为FAIR（可查找、可访问、可互操作、可重用）的AI就绪数字对象，支持长期监测和数字孪生，并为验证提供了超越分类准确率的新途径。

Abstract: Across the natural and life sciences, images have become a primary measurement modality, yet the dominant analytic paradigm remains semantics-first. Structure is recovered by predicting or enforcing domain-specific labels. This paradigm fails systematically under the conditions that make image-based science most valuable, including open-ended scientific discovery, cross-sensor and cross-site comparability, and long-term monitoring in which domain ontologies and associated label sets drift culturally, institutionally, and ecologically. A deductive inversion is proposed in the form of criteria-first and semantics-later. A unified framework for criteria-first structure discovery is introduced. It separates criterion-defined, semantics-free structure extraction from downstream semantic mapping into domain ontologies or vocabularies and provides a domain-general scaffold for reproducible analysis across image-based sciences. Reproducible science requires that the first analytic layer perform criterion-driven, semantics-free structure discovery, yielding stable partitions, structural fields, or hierarchies defined by explicit optimality criteria rather than local domain ontologies. Semantics is not discarded; it is relocated downstream as an explicit mapping from the discovered structural product to a domain ontology or vocabulary, enabling plural interpretations and explicit crosswalks without rewriting upstream extraction. Grounded in cybernetics, observation-as-distinction, and information theory's separation of information from meaning, the argument is supported by cross-domain evidence showing that criteria-first components recur whenever labels do not scale. Finally, consequences are outlined for validation beyond class accuracy and for treating structural products as FAIR, AI-ready digital objects for long-term monitoring and digital twins.

</details>


### [63] [ToaSt: Token Channel Selection and Structured Pruning for Efficient ViT](https://arxiv.org/abs/2602.15720)
*Hyunchan Moon,Cheonjun Park,Steven L. Waslander*

Main category: cs.CV

TL;DR: 本文提出了一种名为 ToaSt 的解耦框架，通过对 Vision Transformer (ViT) 的不同组件应用专门的策略来降低计算成本，同时保持甚至提高准确率。它结合了头部的结构化剪枝和用于前馈网络的 Token Channel Selection (TCS)，并在多项任务和模型上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers (ViT) 在视觉任务中表现出色，但其高昂的计算成本阻碍了实际部署。现有的结构化剪枝和令牌压缩方法存在训练时间长和优化困难等问题。

Method: ToaSt 框架对 ViT 组件采用不同的策略：1. 对多头自注意力模块应用耦合的头部结构化剪枝，利用其注意力机制的特点提高鲁棒性；2. 对占 FLOPs 大部分的前馈网络引入 Token Channel Selection (TCS)，提高压缩率并避免全局传播问题。

Result: ToaSt 在九个不同的模型（包括 DeiT, ViT-MAE, Swin Transformer）上进行了广泛评估，取得了优于现有基线方法的精度和效率的权衡。例如，在 ViT-MAE-Huge 上，ToaSt 在 FLOPs 减少 39.4% 的同时，准确率达到了 88.52%（提高 1.64%）。此外，ToaSt 在 COCO 对象检测任务中也表现出良好的迁移学习能力。

Conclusion: ToaSt 是一种有效的 ViT 压缩框架，通过解耦策略和针对性优化，能够在显著降低计算成本的同时，保持甚至提升模型的性能，并且能够有效地迁移到下游任务。

Abstract: Vision Transformers (ViTs) have achieved remarkable success across various vision tasks, yet their deployment is often hindered by prohibitive computational costs. While structured weight pruning and token compression have emerged as promising solutions, they suffer from prolonged retraining times and global propagation that creates optimization challenges, respectively. We propose ToaSt, a decoupled framework applying specialized strategies to distinct ViT components. We apply coupled head-wise structured pruning to Multi-Head Self-Attention modules, leveraging attention operation characteristics to enhance robustness. For Feed-Forward Networks (over 60\% of FLOPs), we introduce Token Channel Selection (TCS) that enhances compression ratios while avoiding global propagation issues. Our analysis reveals TCS effectively filters redundant noise during selection. Extensive evaluations across nine diverse models, including DeiT, ViT-MAE, and Swin Transformer, demonstrate that ToaSt achieves superior trade-offs between accuracy and efficiency, consistently outperforming existing baselines. On ViT-MAE-Huge, ToaSt achieves 88.52\% accuracy (+1.64 \%) with 39.4\% FLOPs reduction. ToaSt transfers effectively to downstream tasks, cccccachieving 52.2 versus 51.9 mAP on COCO object detection. Code and models will be released upon acceptance.

</details>


### [64] [Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation](https://arxiv.org/abs/2602.15724)
*Shutian Gu,Chengkai Huang,Ruoyu Wang,Lina Yao*

Main category: cs.CV

TL;DR: 提出了一种检索增强框架，通过在指令级别和步骤级别引入检索机制，提高了大型语言模型（LLM）在视觉语言导航（VLN）任务中的效率和稳定性，而无需修改或微调LLM。


<details>
  <summary>Details</summary>
Motivation: 基于提示的LLM导航在每一步都需要从头解释指令并对嘈杂和冗余的可导航候选进行推理，导致决策效率低下。

Method: 提出一个检索增强框架，包含两个检索模块：1. 经验级别：指令级别嵌入检索器，选择语义相似的成功导航轨迹作为上下文示例。2. 步骤级别：模仿学习的候选检索器，在LLM推理前筛选掉不相关的可导航方向。

Result: 在Room-to-Room (R2R)基准测试中，所提出的方法在成功率、Oracle成功率和SPL方面均取得了显著提升，包括在已见和未见的环境中。消融研究表明，指令级别示例检索和候选剪枝对全局指导和分步决策效率有互补的贡献。

Conclusion: 检索增强的决策支持是提高基于LLM的视觉语言导航的有效且可扩展的策略。

Abstract: Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning capability. However, prompt-based LLM navigation often suffers from inefficient decision-making, as the model must repeatedly interpret instructions from scratch and reason over noisy and verbose navigable candidates at each step. In this paper, we propose a retrieval-augmented framework to improve the efficiency and stability of LLM-based VLN without modifying or fine-tuning the underlying language model. Our approach introduces retrieval at two complementary levels. At the episode level, an instruction-level embedding retriever selects semantically similar successful navigation trajectories as in-context exemplars, providing task-specific priors for instruction grounding. At the step level, an imitation-learned candidate retriever prunes irrelevant navigable directions before LLM inference, reducing action ambiguity and prompt complexity. Both retrieval modules are lightweight, modular, and trained independently of the LLM. We evaluate our method on the Room-to-Room (R2R) benchmark. Experimental results demonstrate consistent improvements in Success Rate, Oracle Success Rate, and SPL on both seen and unseen environments. Ablation studies further show that instruction-level exemplar retrieval and candidate pruning contribute complementary benefits to global guidance and step-wise decision efficiency. These results indicate that retrieval-augmented decision support is an effective and scalable strategy for enhancing LLM-based vision-and-language navigation.

</details>


### [65] [Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models](https://arxiv.org/abs/2602.15772)
*Sen Ye,Mengde Xu,Shuyang Gu,Di He,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: 提出Reason-Reflect-Refine (R3)框架，通过多步骤的“生成-理解-再生成”过程，解决了多模态模型中生成能力与理解能力此消彼长的优化困境。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型在提升生成能力时，理解能力往往会下降，反之亦然，存在生成与理解之间的优化冲突。

Method: 提出Reason-Reflect-Refine (R3)框架，将单步生成任务重构为多步的“生成-理解-再生成”过程，在生成过程中显式地利用模型的理解能力。

Result: 成功缓解了优化困境，同时提升了生成结果和与生成过程相关的理解能力。

Conclusion: R3框架为设计下一代统一多模态模型提供了有价值的见解，表明通过多步骤的理解和精炼可以克服生成与理解之间的固有权衡。

Abstract: Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3) framework. This innovative algorithm re-frames the single-step generation task into a multi-step process of "generate-understand-regenerate". By explicitly leveraging the model's understanding capability during generation, we successfully mitigate the optimization dilemma, achieved stronger generation results and improved understanding ability which are related to the generation process. This offers valuable insights for designing next-generation unified multimodal models. Code is available at https://github.com/sen-ye/R3.

</details>


### [66] [Language and Geometry Grounded Sparse Voxel Representations for Holistic Scene Understanding](https://arxiv.org/abs/2602.15734)
*Guile Wu,David Huang,Bingbing Liu,Dongfeng Bai*

Main category: cs.CV

TL;DR: 本文提出了一种利用语言和几何学引导的稀疏体素表示方法，在统一框架内全面建模3D场景的外观、语义和几何。该方法通过特征调制模块和几何蒸馏来增强外观、密度和特征场之间的协同作用，并融合2D和几何基础模型的知识。


<details>
  <summary>Details</summary>
Motivation: 现有3D开放词汇场景理解方法主要关注将2D基础模型的语言特征提取到3D特征场中，但忽略了场景外观、语义和几何之间的协同作用，导致场景理解脱离几何结构并与重建过程分离。

Method: 采用3D稀疏体素作为基本单元，构建外观场、密度场、特征场和置信度场来表示3D场景。通过特征调制模块促进外观、密度和特征场之间的协同，并将2D基础模型的语言特征蒸馏到3D场景模型中。此外，将几何蒸馏集成到特征场蒸馏中，通过深度相关性正则化和模式一致性正则化将几何知识从几何基础模型传递到3D场景表示。

Result: 该方法在整体场景理解和重建方面取得了优于现有最先进方法的性能。

Conclusion: 所提出的方法能够协同地在统一框架内建模3D场景的外观、语义和几何，实现了整体场景理解和重建的显著提升。

Abstract: Existing 3D open-vocabulary scene understanding methods mostly emphasize distilling language features from 2D foundation models into 3D feature fields, but largely overlook the synergy among scene appearance, semantics, and geometry. As a result, scene understanding often deviates from the underlying geometric structure of scenes and becomes decoupled from the reconstruction process. In this work, we propose a novel approach that leverages language and geometry grounded sparse voxel representations to comprehensively model appearance, semantics, and geometry within a unified framework. Specifically, we use 3D sparse voxels as primitives and employ an appearance field, a density field, a feature field, and a confidence field to holistically represent a 3D scene. To promote synergy among the appearance, density, and feature fields, we construct a feature modulation module and distill language features from a 2D foundation model into our 3D scene model. In addition, we integrate geometric distillation into feature field distillation to transfer geometric knowledge from a geometry foundation model to our 3D scene representations via depth correlation regularization and pattern consistency regularization. These components work together to synergistically model the appearance, semantics, and geometry of the 3D scene within a unified framework. Extensive experiments demonstrate that our approach achieves superior overall performance compared with state-of-the-art methods in holistic scene understanding and reconstruction.

</details>


### [67] [NeRFscopy: Neural Radiance Fields for in-vivo Time-Varying Tissues from Endoscopy](https://arxiv.org/abs/2602.15775)
*Laura Salort-Benejam,Antonio Agudo*

Main category: cs.CV

TL;DR: 提出了一种名为NeRFscopy的自监督三维重建流水线，用于从单目内窥镜视频中合成新视角和重建可变形组织。


<details>
  <summary>Details</summary>
Motivation: 为了提高内窥镜检查的可视化效果、诊断准确性、治疗规划和手术指导，需要开发鲁棒的动态三维重建流水线。

Method: NeRFscopy流水线采用了一个可变形模型，包含一个标准的辐射场和一个参数化为SE(3)变换的时间相关变形场。它通过引入复杂的项来学习一个三维隐式模型，仅依靠数据，不依赖于任何模板或预训练模型。

Result: NeRFscopy在合成新视角方面取得了精确的结果，在各种具有挑战性的内窥镜场景下优于现有方法。

Conclusion: NeRFscopy能够从单目内窥镜视频中有效地进行新视角合成和三维重建，有望改进内窥镜应用。

Abstract: Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment. Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures. However, challenges arise due to the deformable nature of the tissues, the use of monocular cameras, illumination changes, occlusions and unknown camera trajectories. Inspired by neural rendering, we introduce NeRFscopy, a self-supervised pipeline for novel view synthesis and 3D reconstruction of deformable endoscopic tissues from a monocular video. NeRFscopy includes a deformable model with a canonical radiance field and a time-dependent deformation field parameterized by SE(3) transformations. In addition, the color images are efficiently exploited by introducing sophisticated terms to learn a 3D implicit model without assuming any template or pre-trained model, solely from data. NeRFscopy achieves accurate results in terms of novel view synthesis, outperforming competing methods across various challenging endoscopy scenes.

</details>


### [68] [Task-Agnostic Continual Learning for Chest Radiograph Classification](https://arxiv.org/abs/2602.15811)
*Muthu Subash Kavitha,Anas Zafar,Amgad Muneer,Jia Wu*

Main category: cs.CV

TL;DR: 提出了一种名为 CARL-XRay 的持续学习策略，用于处理连续到来的胸部 X 光数据集，在不存储原始图像的情况下，能稳定识别任务并适应新数据，同时保持诊断性能，且训练参数更少。


<details>
  <summary>Details</summary>
Motivation: 在临床应用中，胸部 X 光分类器需要能够在新数据集可用时进行更新，而无需重新训练旧数据或损害已验证的性能。现有方法在处理连续到来的异构数据集且推理时无法获取任务标识符的情况下存在挑战。

Method: 提出了一种持续适配器路由学习策略 (CARL-XRay)，它保持一个固定高容量的骨干网络，并渐进式地分配轻量级任务特定的适配器和分类器头。通过一个潜在任务选择器，利用紧凑原型和特征级别经验回放中保存的当前和历史上下文来识别和适应任务。

Result: CARL-XRay 在大规模公共胸部 X 光数据集上的实验显示，在持续数据集摄入下，能够保持鲁棒的性能，并实现可靠的任务识别推理。在任务未知部署下，其路由准确率（75.0% vs. 62.5%）优于联合训练，并在知道真实任务身份的设置下达到 0.74 的 AUROC，在任务未知推理下达到 0.75 的 AUROC，且可训练参数显著减少。

Conclusion: CARL-XRay 提供了一种在持续临床部署中，替代联合训练和重复完全重新训练的实用方法，能够有效应对胸部 X 光分类器在持续更新时的挑战。

Abstract: Clinical deployment of chest radiograph classifiers requires models that can be updated as new datasets become available without retraining on previously ob- served data or degrading validated performance. We study, for the first time, a task-incremental continual learning setting for chest radiograph classification, in which heterogeneous chest X-ray datasets arrive sequentially and task identifiers are unavailable at inference. We propose a continual adapter-based routing learning strategy for Chest X-rays (CARL-XRay) that maintains a fixed high-capacity backbone and incrementally allocates lightweight task-specific adapters and classifier heads. A latent task selector operates on task-adapted features and leverages both current and historical context preserved through compact prototypes and feature-level experience replay. This design supports stable task identification and adaptation across sequential updates while avoiding raw-image storage. Experiments on large-scale public chest radiograph datasets demonstrate robust performance retention and reliable task-aware inference under continual dataset ingestion. CARL-XRay outperforms joint training under task-unknown deployment, achieving higher routing accuracy (75.0\% vs.\ 62.5\%), while maintaining competitive diagnostic performance with AUROC of 0.74 in the oracle setting with ground-truth task identity and 0.75 under task-unknown inference, using significantly fewer trainable parameters. Finally, the proposed framework provides a practical alternative to joint training and repeated full retraining in continual clinical deployment.

</details>


### [69] [Meteorological data and Sky Images meets Neural Models for Photovoltaic Power Forecasting](https://arxiv.org/abs/2602.15782)
*Ines Montoya-Espinagosa,Antonio Agudo*

Main category: cs.CV

TL;DR: 该研究提出了一种混合方法，结合了天空图像、光伏发电历史和气象数据，利用深度神经网络进行短期和长期光伏发电预测，特别是提高了对斜坡事件的预测准确性和阴天条件下的预测鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 可再生能源（尤其是太阳能）使用日益增加，光伏发电的间歇性给电网运行带来挑战，需要更准确的预测方法来提高电网效率和管理太阳能的波动性。

Method: 提出了一种多模态混合方法，结合了天空图像、光伏发电历史数据和气象数据（包括地表长波辐射、向下辐射、风和太阳位置）。使用了深度神经网络模型进行短期（nowcasting）和长期预测。

Result: 结果表明，加入气象数据（特别是地表长波辐射、向下辐射以及风和太阳位置的组合）显著提高了当前预测的准确性，尤其是在阴天条件下，斜坡事件预测的准确性和鲁棒性得到了提升。

Conclusion: 该研究强调了整合不同数据源（图像、历史数据、气象数据）对于提高太阳能预测模型的可靠性和可解释性的重要性，尤其是在应对阴天和预测斜坡事件方面。

Abstract: Due to the rise in the use of renewable energies as an alternative to traditional ones, and especially solar energy, there is increasing interest in studying how to address photovoltaic forecasting in the face of the challenge of variability in photovoltaic energy production, using different methodologies. This work develops a hybrid approach for short and long-term forecasting based on two studies with the same purpose. A multimodal approach that combines images of the sky and photovoltaic energy history with meteorological data is proposed. The main goal is to improve the accuracy of ramp event prediction, increase the robustness of forecasts in cloudy conditions, and extend capabilities beyond nowcasting, to support more efficient operation of the power grid and better management of solar variability. Deep neural models are used for both nowcasting and forecasting solutions, incorporating individual and multiple meteorological variables, as well as an analytical solar position. The results demonstrate that the inclusion of meteorological data, particularly the surface long-wave, radiation downwards, and the combination of wind and solar position, significantly improves current predictions in both nowcasting and forecasting tasks, especially on cloudy days. This study highlights the importance of integrating diverse data sources to improve the reliability and interpretability of solar energy prediction models.

</details>


### [70] [VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation](https://arxiv.org/abs/2602.15819)
*Hui Ren,Yuval Alaluf,Omer Bar Tal,Alexander Schwing,Antonio Torralba,Yael Vinker*

Main category: cs.CV

TL;DR: 本研究提出了一种数据高效的方法，通过调整预训练的文本到视频扩散模型来生成连续的草图绘制过程，利用大型语言模型进行语义规划和笔画排序，利用视频扩散模型生成高质量、时间连贯的视觉效果。通过两阶段微调策略，实现了笔画排序和草图外观的学习，即使在极少量人工绘制的草图数据下，也能生成高质量、符合文本指定顺序且细节丰富的连续草图。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型将草图视为静态图像，忽略了绘制过程中固有的时间序列结构，而这种结构对于探索和完善创意至关重要。

Method: 将草图表示为短视频，其中笔画按照文本指定的顺序逐步绘制在空白画布上。采用两阶段微调策略：首先使用合成形状组合学习笔画排序，然后从少量（最少七个）人工绘制的草图数据中蒸馏学习视觉外观，该过程捕捉了全局绘制顺序和单个笔画的连续形成。利用大型语言模型（LLMs）进行语义规划和笔画排序，利用视频扩散模型作为渲染器生成高质量、时间连贯的视觉效果。

Result: 在极少量人工绘制的草图数据下，生成了高质量的连续草图，这些草图能紧密遵循文本指定的顺序，并展现出丰富的视觉细节。此外，还通过笔刷风格条件和自回归草图生成等扩展，展示了方法的灵活性，实现了更强的可控性和交互式、协作式绘图。

Conclusion: 该方法能够高效地生成遵循特定顺序且视觉质量高的连续草图，有效解决了现有模型忽略草图时间结构的问题，并具有良好的可扩展性和可控性。

Abstract: Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images, overlooking the temporal structure that underlies creative drawing. We present a data-efficient approach for sequential sketch generation that adapts pretrained text-to-video diffusion models to generate sketching processes. Our key insight is that large language models and video diffusion models offer complementary strengths for this task: LLMs provide semantic planning and stroke ordering, while video diffusion models serve as strong renderers that produce high-quality, temporally coherent visuals. We leverage this by representing sketches as short videos in which strokes are progressively drawn on a blank canvas, guided by text-specified ordering instructions. We introduce a two-stage fine-tuning strategy that decouples the learning of stroke ordering from the learning of sketch appearance. Stroke ordering is learned using synthetic shape compositions with controlled temporal structure, while visual appearance is distilled from as few as seven manually authored sketching processes that capture both global drawing order and the continuous formation of individual strokes. Despite the extremely limited amount of human-drawn sketch data, our method generates high-quality sequential sketches that closely follow text-specified orderings while exhibiting rich visual detail. We further demonstrate the flexibility of our approach through extensions such as brush style conditioning and autoregressive sketch generation, enabling additional controllability and interactive, collaborative drawing.

</details>


### [71] [Context-aware Skin Cancer Epithelial Cell Classification with Scalable Graph Transformers](https://arxiv.org/abs/2602.15783)
*Lucas Sancéré,Noémie Moreau,Katarzyna Bozek*

Main category: cs.CV

TL;DR: 该研究提出了一种基于图Transformer的全切片图像（WSI）细胞图分类方法，用于区分皮肤鳞状细胞癌（cSCC）中的健康和肿瘤上皮细胞。实验结果表明，图Transformer方法在分类任务上优于传统的基于图像的方法，并且结合细胞形态、纹理特征以及周围非上皮细胞类别能够提供更丰富的信息。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的WSI分析方法通常采用基于块（patch-based）的表示，这会丢失重要的组织层面的上下文信息。作者希望开发一种能够利用全局组织结构信息进行分类的方法。

Method: 研究提出使用可扩展的图Transformer模型（SGFormer和DIFFormer）对全WSI的细胞图进行分类。他们首先在一个WSI上比较了基于图像和基于图的方法，并探索了不同的节点特征配置。随后，他们将研究扩展到多WSI进行训练，并与最先进的图像模型CellViT256进行了比较。

Result: 在单WSI分类任务中，图Transformer模型（SGFormer和DIFFormer）的平衡准确率分别为85.2%±1.5%和85.1%±2.5%，优于最佳图像方法（81.2%±3.0%）。研究发现，结合形态特征、纹理特征以及周围非上皮细胞类别信息的节点特征表示最为有效。在多WSI分类任务中，DIFFormer取得了83.6%±1.9%的平衡准确率，而CellViT256为78.1%±0.5%。

Conclusion: 基于图Transformer的全WSI细胞图分类方法能够有效地解决图像块丢失组织上下文信息的问题，并在区分cSCC中的健康和肿瘤上皮细胞方面表现出优于现有基于图像方法的潜力。结合丰富的细胞上下文信息（形态、纹理及周围细胞类型）是提升模型性能的关键。

Abstract: Whole-slide images (WSIs) from cancer patients contain rich information that can be used for medical diagnosis or to follow treatment progress. To automate their analysis, numerous deep learning methods based on convolutional neural networks and Vision Transformers have been developed and have achieved strong performance in segmentation and classification tasks. However, due to the large size and complex cellular organization of WSIs, these models rely on patch-based representations, losing vital tissue-level context. We propose using scalable Graph Transformers on a full-WSI cell graph for classification. We evaluate this methodology on a challenging task: the classification of healthy versus tumor epithelial cells in cutaneous squamous cell carcinoma (cSCC), where both cell types exhibit very similar morphologies and are therefore difficult to differentiate for image-based approaches. We first compared image-based and graph-based methods on a single WSI. Graph Transformer models SGFormer and DIFFormer achieved balanced accuracies of $85.2 \pm 1.5$ ($\pm$ standard error) and $85.1 \pm 2.5$ in 3-fold cross-validation, respectively, whereas the best image-based method reached $81.2 \pm 3.0$. By evaluating several node feature configurations, we found that the most informative representation combined morphological and texture features as well as the cell classes of non-epithelial cells, highlighting the importance of the surrounding cellular context. We then extended our work to train on several WSIs from several patients. To address the computational constraints of image-based models, we extracted four $2560 \times 2560$ pixel patches from each image and converted them into graphs. In this setting, DIFFormer achieved a balanced accuracy of $83.6 \pm 1.9$ (3-fold cross-validation), while the state-of-the-art image-based model CellViT256 reached $78.1 \pm 0.5$.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [72] [EduResearchBench: A Hierarchical Atomic Task Decomposition Benchmark for Full-Lifecycle Educational Research](https://arxiv.org/abs/2602.15034)
*Houping Yue,Zixiang Di,Mei Jiang,Bingdong Li,Hao Hao,Yu Song,Bo Jiang,Aimin Zhou*

Main category: cs.CL

TL;DR: 本文提出了 EduResearchBench，一个用于评估大型语言模型在教育学术写作中的表现的平台。该平台基于分层原子任务分解框架，将研究流程分解为多个模块和细粒度任务，并引入了课程学习策略。结果表明，在垂直领域，数据质量和分阶段训练比模型规模更重要。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型评估基准在学术写作方面存在不足，侧重于单次生成，缺乏对复杂研究工作流进行精细评估的能力。

Method: 引入 EduResearchBench 评估平台，该平台基于 Hierarchical Atomic Task Decomposition (HATD) 框架，将研究工作流分解为六个专业研究模块和24个细粒度原子任务。提出课程学习策略，并利用55K学术样本 curated 11K instruction pairs 训练 EduWrite 模型。

Result: EduWrite (30B) 在多个核心指标上显著优于更大的通用模型 (72B)。这表明在垂直领域，数据质量和分层训练策略比模型参数规模更具决定性。

Conclusion: EduResearchBench 是首个专门针对教育学术写作的全面评估平台。HATD 框架和课程学习策略能够提供精细的诊断反馈，并提升模型在特定领域的写作能力。模型规模并非唯一决定因素，数据质量和训练策略在垂直领域更为关键。

Abstract: While Large Language Models (LLMs) are reshaping the paradigm of AI for Social Science (AI4SS), rigorously evaluating their capabilities in scholarly writing remains a major challenge. Existing benchmarks largely emphasize single-shot, monolithic generation and thus lack the fine-grained assessments required to reflect complex academic research workflows. To fill this gap, we introduce EduResearchBench, the first comprehensive evaluation platform dedicated to educational academic writing. EduResearchBench is built upon our Hierarchical Atomic Task Decomposition (HATD) framework, which decomposes an end-to-end research workflow into six specialized research modules (e.g., Quantitative Analysis, Qualitative Research, and Policy Research) spanning 24 fine-grained atomic tasks. This taxonomy enables an automated evaluation pipeline that mitigates a key limitation of holistic scoring, where aggregate scores often obscure specific capability bottlenecks, and instead provides fine-grained, diagnostic feedback on concrete deficiencies. Moreover, recognizing the high cognitive load inherent in scholarly writing, we propose a curriculum learning strategy that progressively builds competence from foundational skills to complex methodological reasoning and argumentation. Leveraging 55K raw academic samples, we curate 11K high-quality instruction pairs to train EduWrite, a specialized educational scholarly writing model. Experiments show that EduWrite (30B) substantially outperforms larger general-purpose models (72B) on multiple core metrics, demonstrating that in vertical domains, data quality density and hierarchically staged training curricula are more decisive than parameter scale.

</details>


### [73] [Indic-TunedLens: Interpreting Multilingual Models in Indian Languages](https://arxiv.org/abs/2602.15038)
*Mihir Panchal,Deeksha Varshney,Mamta,Asif Ekbal*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Indic-TunedLens 的新颖解释框架，用于跨语言解释多语言大型语言模型（LLMs）在印度语言中的表示，并表明其在准确性上显著优于现有方法，尤其是在形态丰富、资源匮乏的语言上。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的 LLM 可解释性工具都针对英语设计，而多语言 LLM 在印度等语言多样化地区得到广泛应用。但研究表明 LLM 的内部表示往往是英语中心化的，这使得跨语言的可解释性成为一个亟待解决的问题。

Method: Indic-TunedLens 框架通过学习共享的仿射变换来调整隐藏状态，使其与目标语言的输出分布对齐，从而实现比标准 Logit Lens 更准确的解码。它在 10 种印度语言上使用 MMLU 基准进行评估。

Result: Indic-TunedLens 在解释多语言 LLM 在印度语言中的表示方面，显著优于当前最先进的可解释性方法，尤其是在形态丰富、资源匮乏的语言上。

Conclusion: Indic-TunedLens 为理解多语言 Transformer 模型中层级的语义编码提供了关键见解，并为跨语言解释提供了一个更有效的框架，尤其是在资源受限的语言场景下。

Abstract: Multilingual large language models (LLMs) are increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain tailored to English. Prior work reveals that LLMs often operate in English centric representation spaces, making cross lingual interpretability a pressing concern. We introduce Indic-TunedLens, a novel interpretability framework specifically for Indian languages that learns shared affine transformations. Unlike the standard Logit Lens, which directly decodes intermediate activations, Indic-TunedLens adjusts hidden states for each target language, aligning them with the target output distributions to enable more faithful decoding of model representations. We evaluate our framework on 10 Indian languages using the MMLU benchmark and find that it significantly improves over SOTA interpretability methods, especially for morphologically rich, low resource languages. Our results provide crucial insights into the layer-wise semantic encoding of multilingual transformers. Our model is available at https://huggingface.co/spaces/AnonymousAccountACL/IndicTunedLens. Our code is available at https://github.com/AnonymousAccountACL/IndicTunedLens.

</details>


### [74] [CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding](https://arxiv.org/abs/2602.15139)
*Tahir Hussain,Saddam Hussain Khan*

Main category: cs.CL

TL;DR: 研究提出了一种名为 CGRA DeBERTa 的新框架，通过概念引导的残差领域增强来提高对圣训经文的问答准确性，并在 Sahih al-Bukhari 和 Sahih Muslim 数据集上取得了显著优于 BERT 和 DeBERTa 的结果。


<details>
  <summary>Details</summary>
Motivation: 由于领域特定语义、长上下文依赖和概念敏感推理的挑战，对古典伊斯兰文本进行准确的问答仍然困难。

Method: 提出 CGRA DeBERTa 框架，该框架基于定制的 DeBERTa transformer 主干，结合轻量级 LoRA 适配和残差概念感知门控机制。定制的 DeBERTa 嵌入块学习全局和位置上下文，概念引导残差块结合了来自 12 个核心术语的伊斯兰概念词典的先验知识。概念门控机制通过重要性加权注意力选择性地增强语义关键 token。

Result: 在包含 42591 个问答对的 Sahih al-Bukhari 和 Sahih Muslim 数据集上训练 CGRA 模型。CGRA DeBERTa 实现了 97.85 的 EM 分数，比 BERT (75.87) 和 DeBERTa (89.77) 分数分别高出 21.98 和 8.08。模型在增加约 8% 的推理开销的情况下实现了更高的准确性，并且在定性评估中表现出更好的提取、区分能力和神学精确性。

Conclusion: 该研究提出了高效、可解释且准确的圣训问答系统，能够提供具有必要神学细微差别的教育材料。

Abstract: Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.

</details>


### [75] [OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction](https://arxiv.org/abs/2602.15197)
*Skyler Hallinan,Thejas Venkatesh,Xiang Ren,Sai Praneeth Karimireddy,Ashwin Paranjape,Yuhao Zhang,Jack Hessel*

Main category: cs.CL

TL;DR: 该研究提出了 OpaqueToolsBench 评测基准，用于评估 LLM 代理在与不透明工具交互时改进工具文档的能力。研究还提出了 ToolObserver 框架，通过观察工具调用轨迹中的执行反馈来迭代优化工具文档，并在评测基准上取得了优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 代理评测基准通常假设工具文档完善，但真实世界的工具往往不透明，缺乏明确的最佳实践和故障模式。研究旨在探讨 LLM 代理是否能通过与不透明工具交互来改进文档，从而提升性能。

Method: 创建了一个名为 OpaqueToolsBench 的评测基准，包含三个不同的任务导向环境：通用函数调用、交互式国际象棋和长轨迹代理搜索。这些环境提供信息不足的工具，模型需要学习有效使用它们来完成任务。在此基础上，提出了 ToolObserver 框架，通过观察工具调用轨迹中的执行反馈来迭代改进工具文档。

Result: 在 OpaqueToolsBench 评测基准上的结果表明，现有的自动文档化工具方法在面对不透明工具时成本高昂且不可靠。ToolObserver 框架在 OpaqueToolsBench 的多个数据集上均优于现有方法，即使在相对困难的设置下也是如此。此外，在测试时工具探索的设置下，ToolObserver 比最佳基线消耗的 token 数量减少了 3.5-7.5 倍。

Conclusion: LLM 代理可以通过与不透明工具交互来改进工具文档，从而提升在真实世界任务中的性能。ToolObserver 框架提供了一种有效且高效的方法来实现这一目标，能够迭代地优化工具文档并克服不透明工具带来的挑战。

Abstract: Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general "search" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task-oriented environments: general function calling, interactive chess playing, and long-trajectory agentic search. Each environment provides underspecified tools that models must learn to use effectively to complete the task. Results on OpaqueToolsBench suggest existing methods for automatically documenting tools are expensive and unreliable when tools are opaque. To address this, we propose a simple framework, ToolObserver, that iteratively refines tool documentation by observing execution feedback from tool-calling trajectories. Our approach outperforms existing methods on OpaqueToolsBench across datasets, even in relatively hard settings. Furthermore, for test-time tool exploration settings, our method is also efficient, consuming 3.5-7.5x fewer total tokens than the best baseline.

</details>


### [76] [Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement](https://arxiv.org/abs/2602.15312)
*Stephan Ludwig,Peter J. Danaher,Xiaohao Yang,Yu-Ting Lin,Ehsan Abedin,Dhruv Grewal,Lan Du*

Main category: cs.CL

TL;DR: 本研究提出了一种名为 LX（Linguistic eXtractor）的大型语言模型，专门用于从消费者文本中提取情绪和评价信息。LX 在多项任务上表现优于现有领先模型，并可应用于在线零售数据分析，揭示了情绪对产品评分和购买行为的影响。研究还提供了一个易于使用的 LX 网页应用。


<details>
  <summary>Details</summary>
Motivation: 准确测量消费者情绪和评价是营销研究和实践中的一个核心挑战，现有方法在处理非结构化文本时存在不足。

Method: 研究开发并微调了一个名为 LX 的大型语言模型，使其能够处理包含消费者自我报告情绪和评价（信任、承诺、推荐、情感）的文本。通过在公开数据集（Amazon、Yelp）和调查问卷数据上进行评估，并将 LX 与 GPT-4 Turbo、RoBERTa 和 DeepSeek 等模型进行比较。此外，还应用 LX 和似乎无关的回归（seemingly unrelated regression）分析了在线零售数据。

Result: LX 在开放式调查回复上达到了 81% 的宏观 F1 准确率，在第三方标注的 Amazon 和 Yelp 评论上准确率超过 95%，优于其他领先模型。情绪表达（如不满和满足）可以预测产品评分，而产品评分又可以预测购买行为。大多数情绪效应通过产品评分进行中介，但某些情绪（如不满和满足）能直接影响购买。

Conclusion: LX 为测量消费者感知提供了一个新的方法学基础，并展示了如何利用大型语言模型来推进营销研究和实践。该模型能够从消费者数据中验证识别营销构建，并且其易用性（通过免费网页应用）支持了广泛的应用。

Abstract: Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.

</details>


### [77] [AIC CTU@AVerImaTeC: dual-retriever RAG for image-text fact checking](https://arxiv.org/abs/2602.15190)
*Herbert Ullrich,Jan Drchal*

Main category: cs.CL

TL;DR: 作者提出了一个基于检索增强生成（RAG）和反向图像搜索（RIS）的简单且可复现的系统，在AVerImaTeC共享任务中取得了第三名的成绩，并且成本效益高。


<details>
  <summary>Details</summary>
Motivation: 在AVerImaTeC共享任务中取得有竞争力的性能，并提供一个易于复现和修改的系统作为未来实验的基础。

Method: 结合了去年基于RAG的管道和一个反向图像搜索（RIS）模块。该系统包含三个独立的模块：基于相似性搜索的文本检索模块、基于API访问的RIS图像检索模块，以及使用GPT5.1的多模态生成模块。

Result: 该系统在AVerImaTeC共享任务中取得了第三名的成绩。使用GPT5.1通过OpenAI Batch API，每个事实核查的平均成本仅为0.013美元，并且具有竞争力的性能。

Conclusion: 该系统简单、易于复现且成本效益高，为未来在该领域的实验提供了一个可访问的起点。作者发布了代码、提示、向量存储以及关于运行成本和未来改进方向的见解。

Abstract: In this paper, we present our 3rd place system in the AVerImaTeC shared task, which combines our last year's retrieval-augmented generation (RAG) pipeline with a reverse image search (RIS) module. Despite its simplicity, our system delivers competitive performance with a single multimodal LLM call per fact-check at just $0.013 on average using GPT5.1 via OpenAI Batch API. Our system is also easy to reproduce and tweak, consisting of only three decoupled modules - a textual retrieval module based on similarity search, an image retrieval module based on API-accessed RIS, and a generation module using GPT5.1 - which is why we suggest it as an accesible starting point for further experimentation. We publish its code and prompts, as well as our vector stores and insights into the scheme's running costs and directions for further improvement.

</details>


### [78] [Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313)
*Zihao Tang,Xin Yu,Ziyu Xiao,Zengxuan Wen,Zelin Li,Jiaxi Zhou,Hualei Wang,Haohua Wang,Haizhen Huang,Weiwei Deng,Feng Sun,Qi Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为 Mnemis 的新颖内存框架，该框架结合了基于相似度的检索（System-1）和一种名为全局选择（System-2）的层次化图遍历机制，以提高大型语言模型的长期记忆检索能力，并在现有基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于相似度的内存检索方法（如 RAG 和 Graph-RAG）在需要全局推理或全面信息覆盖的场景中存在不足。

Method: Mnemis 将内存组织成一个用于相似度检索的基础图和一个用于自顶向下遍历语义层次的层次化图。它结合了基于相似度的检索和基于层次结构的全局选择机制。

Result: Mnemis 在 LoCoMo（93.9）和 LongMemEval-S（91.6）等长期记忆基准测试中，超越了所有比较方法，实现了最先进的性能。

Conclusion: Mnemis 通过结合两种互补的检索路线（相似度检索和全局选择），能够检索到语义上和结构上都相关的内存项，显著提升了大型语言模型的长期记忆检索能力。

Abstract: AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.

</details>


### [79] [NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.15353)
*Rong Fu,Yang Li,Zeyu Zhang,Jiekai Wu,Yaohua Liu,Shuaishuai Cao,Yangchen Zeng,Yuhang Zhang,Xiaojing Du,Chuang Zhao,Kangning Cui,Simon Fong*

Main category: cs.CL

TL;DR: 本文提出了一种名为NeuroSymActive的模块化框架，用于知识图谱问答（KGQA），该框架结合了可微分的神经符号推理层和主动的、价值引导的探索控制器，以提高精度并减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练语言模型和神经推理系统在处理需要精确、结构化多跳推理的知识密集型查询时面临挑战。虽然知识图谱可以提供事实依据，但将其结构与神经模型相结合并不容易。直接将图谱事实嵌入提示效率低下且不稳定，而纯符号或搜索驱动的方法在检索时成本高昂且缺乏基于梯度的优化。

Method: NeuroSymActive框架结合了软统一风格的符号模块、神经路径评估器和蒙特卡洛风格的探索策略。探索策略能够价值引导，优先扩展高价值路径。该框架包含一个可微分的神经符号推理层和一个主动的、价值引导的探索控制器。

Result: 在标准的KGQA基准测试中，NeuroSymActive在答案准确性方面表现出色，同时相比于常见的检索增强基线，显著减少了昂贵的图谱查找和模型调用次数。

Conclusion: NeuroSymActive成功地将神经模型与知识图谱的符号结构相结合，通过结合可微分的神经符号推理和价值引导的主动探索，实现了KGQA的高准确性和效率提升，并降低了计算开销。

Abstract: Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.

</details>


### [80] [Far Out: Evaluating Language Models on Slang in Australian and Indian English](https://arxiv.org/abs/2602.15373)
*Deniz Kaya Dilsiz,Dipankar Srirag,Aditya Joshi*

Main category: cs.CL

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Language models exhibit systematic performance gaps when processing text in non-standard language varieties, yet their ability to comprehend variety-specific slang remains underexplored for several languages. We present a comprehensive evaluation of slang awareness in Indian English (en-IN) and Australian English (en-AU) across seven state-of-the-art language models. We construct two complementary datasets: \textsc{web}, containing 377 web-sourced usage examples from Urban Dictionary, and \textsc{gen}, featuring 1,492 synthetically generated usages of these slang terms, across diverse scenarios. We assess language models on three tasks: target word prediction (TWP), guided target word prediction (TWP$^*$) and target word selection (TWS). Our results reveal four key findings: (1) Higher average model performance TWS versus TWP and TWP$^*$, with average accuracy score increasing from 0.03 to 0.49 respectively (2) Stronger average model performance on \textsc{web} versus \textsc{gen} datasets, with average similarity score increasing by 0.03 and 0.05 across TWP and TWP$^*$ tasks respectively (3) en-IN tasks outperform en-AU when averaged across all models and datasets, with TWS demonstrating the largest disparity, increasing average accuracy from 0.44 to 0.54. These findings underscore fundamental asymmetries between generative and discriminative competencies for variety-specific language, particularly in the context of slang expressions despite being in a technologically rich language such as English.

</details>


### [81] [Orchestration-Free Customer Service Automation: A Privacy-Preserving and Flowchart-Guided Framework](https://arxiv.org/abs/2602.15377)
*Mengze Hong,Chen Jason Zhang,Zichang Guo,Hanlin Gu,Di Jiang,Li Qing*

Main category: cs.CL

TL;DR: 该研究提出了一种无需编排的、基于任务导向流程图（TOFs）的客户服务自动化框架，用于端到端自动化，无需手动干预。该框架通过从对话中提取程序知识来构建流程图，并提出了一种去中心化的蒸馏方法来解决数据稀缺和隐私问题。实验证明了其优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有客户服务自动化方法要么需要复杂的代理编排，要么采用过于简化的指令，通用性差。因此，需要一种新的方法来实现更简单、更通用的端到端自动化。

Method: 1. 定义任务导向流程图（TOFs）的组成部分和评估指标。 2. 提出了一种低成本的流程图构建算法，用于从服务对话中提取程序性知识。 3. 提出了一种去中心化的蒸馏方法，利用流程图来缓解数据稀缺和隐私问题，并支持本地部署小型语言模型。

Result: 在各种服务任务中，该框架在定量和应用性能上都优于强基线和市场产品。

Conclusion: 基于TOFs的无需编排的框架能够实现有效的端到端客户服务自动化，解决了现有方法的局限性，并为未来服务自动化提供了一种更简洁的创建方式。

Abstract: Customer service automation has seen growing demand within digital transformation. Existing approaches either rely on modular system designs with extensive agent orchestration or employ over-simplified instruction schemas, providing limited guidance and poor generalizability. This paper introduces an orchestration-free framework using Task-Oriented Flowcharts (TOFs) to enable end-to-end automation without manual intervention. We first define the components and evaluation metrics for TOFs, then formalize a cost-efficient flowchart construction algorithm to abstract procedural knowledge from service dialogues. We emphasize local deployment of small language models and propose decentralized distillation with flowcharts to mitigate data scarcity and privacy issues in model training. Extensive experiments validate the effectiveness in various service tasks, with superior quantitative and application performance compared to strong baselines and market products. By releasing a web-based system demonstration with case studies, we aim to promote streamlined creation of future service automation.

</details>


### [82] [Making Large Language Models Speak Tulu: Structured Prompting for an Extremely Low-Resource Language](https://arxiv.org/abs/2602.15378)
*Prathamesh Devadiga,Paras Chopra*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLM）在缺乏训练数据的语言（以图鲁语为例）上进行对话的能力，并通过结构化提示而非微调来激发模型潜力。研究结合了语法文档、负面约束、罗马化标准化和合成数据生成，显著减少了词汇污染并提高了语法准确性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探究大型语言模型是否能在训练数据稀缺甚至缺失的语言上进行基本的对话，以克服数字资源匮乏带来的挑战。

Method: 采用结构化提示而非模型微调的方法，结合显式语法文档、负面约束（抑制相关语言的高概率词汇）、罗马化标准化以及通过自玩生成的合成数据，来应对缺乏训练数据的挑战。

Result: 研究成功将图鲁语的词汇污染从80%降低到5%，并达到了85%的语法准确率。交叉模型分析表明，负面约束能带来一致的性能提升（12-18个百分点），而语法文档的效果因模型架构而异（8-22个百分点）。

Conclusion: 通过结构化提示和多项辅助技术的结合，可以在训练数据极少的语言上诱导出大型语言模型的基本对话能力，证明了该方法在低资源语言处理上的潜力。

Abstract: Can large language models converse in languages virtually absent from their training data? We investigate this question through a case study on Tulu, a Dravidian language with over 2 million speakers but minimal digital presence. Rather than fine-tuning an LLM, we examine whether structured prompts alone can elicit basic conversational ability under controlled prompting. We systematically tackle various challenges posed by absence of training data for Tulu by combining explicit grammar documentation, negative constraints to suppress high-probability tokens from related languages, romanization standardization, and quality-controlled synthetic data generation via self-play. Evaluated on a manually curated held-out set across three LLMs (Gemini 2.0 Flash, GPT-4o, Llama 3.1 70B) and validated by native speakers, our approach reduces vocabulary contamination from 80% to 5% while achieving 85% grammatical accuracy. Cross-model analysis reveals that negative constraints provide consistent improvements (12--18 percentage points), while grammar documentation effects vary by model architecture (8--22 points).

</details>


### [83] [The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems](https://arxiv.org/abs/2602.15382)
*Xiaoze Liu,Ruowang Zhang,Weichen Yu,Siheng Xiong,Liu He,Feijie Wu,Hoin Jung,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.CL

TL;DR: 提出了一种名为“视觉虫洞”的新框架，利用视觉语言模型（VLMs）的视觉接口，实现了模型无关、无文本的通信，以提高多智能体系统（MAS）的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型的多智能体系统（MAS）受限于离散文本通信的低效性（运行时开销大、信息量化损失），而现有的高带宽替代方案（如潜在状态传输）则存在异构性、可扩展性和模块化限制。

Method: 通过引入“通用视觉编解码器”，将异构的推理轨迹映射到共享的连续潜在空间，并直接注入接收者的视觉通路。采用“中心辐射式”拓扑结构降低了成对对齐复杂度，并利用无标签的“教师-学生”蒸馏目标来对齐高速视觉通道和文本通路。

Result: 在异构模型家族（如 Qwen-VL, Gemma）上的实验表明，“视觉虫洞”在可控的比较中降低了端到端的实际运行时间，同时保持了与标准文本通信MAS相当的推理保真度。

Conclusion: “视觉虫洞”框架通过利用VLMs的视觉接口，提供了一种模型无关、无文本的通信方式，有效解决了现有MAS通信效率和可扩展性的问题，并取得了与文本通信相当的性能。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state transfer offers a high-bandwidth alternative, existing approaches either assume homogeneous sender-receiver architectures or rely on pair-specific learned translators, limiting scalability and modularity across diverse model families with disjoint manifolds. In this work, we propose the Vision Wormhole, a novel framework that repurposes the visual interface of Vision-Language Models (VLMs) to enable model-agnostic, text-free communication. By introducing a Universal Visual Codec, we map heterogeneous reasoning traces into a shared continuous latent space and inject them directly into the receiver's visual pathway, effectively treating the vision encoder as a universal port for inter-agent telepathy. Our framework adopts a hub-and-spoke topology to reduce pairwise alignment complexity from O(N^2) to O(N) and leverages a label-free, teacher-student distillation objective to align the high-speed visual channel with the robust reasoning patterns of the text pathway. Extensive experiments across heterogeneous model families (e.g., Qwen-VL, Gemma) demonstrate that the Vision Wormhole reduces end-to-end wall-clock time in controlled comparisons while maintaining reasoning fidelity comparable to standard text-based MAS. Code is available at https://github.com/xz-liu/heterogeneous-latent-mas

</details>


### [84] [Measuring Social Integration Through Participation: Categorizing Organizations and Leisure Activities in the Displaced Karelians Interview Archive using LLMs](https://arxiv.org/abs/2602.15436)
*Joonatan Laato,Veera Schroderus,Jenna Kanerva,Jenni Kauppi,Virpi Lummaa,Filip Ginter*

Main category: cs.CL

TL;DR: 该研究开发了一种方法，使用大型语言模型（LLM）对芬兰二战卡累利阿疏散家庭访谈中的休闲活动和组织成员身份进行分类，以解决大规模历史档案数据分析中的挑战。


<details>
  <summary>Details</summary>
Motivation: 直接从文本中提取的信息难以用于量化分析历史学和社会学研究问题。以往的研究提取了大量的活动和组织名称，但数量过多，难以直接分析。

Method: 研究人员开发了一个包含活动类型、社交性、频率和体力要求等关键方面的分类框架。他们创建了一个金标准数据集用于评估，然后测试了大型语言模型（LLM）能否应用该框架。通过多模型运行的简单投票方法，评估了LLM的性能。

Result: 研究发现，一个开源的LLM在接近专家判断方面表现良好。该方法成功地为35万个实体进行了标注，生成了一个结构化的资源。

Conclusion: 大型语言模型可以有效地对历史档案数据中的复杂信息进行分类，从而为社会融合等下游研究提供支持。

Abstract: Digitized historical archives make it possible to study everyday social life on a large scale, but the information extracted directly from text often does not directly allow one to answer the research questions posed by historians or sociologists in a quantitative manner. We address this problem in a large collection of Finnish World War II Karelian evacuee family interviews. Prior work extracted more than 350K mentions of leisure time activities and organizational memberships from these interviews, yielding 71K unique activity and organization names -- far too many to analyze directly.
  We develop a categorization framework that captures key aspects of participation (the kind of activity/organization, how social it typically is, how regularly it happens, and how physically demanding it is). We annotate a gold-standard set to allow for a reliable evaluation, and then test whether large language models can apply the same schema at scale. Using a simple voting approach across multiple model runs, we find that an open-weight LLM can closely match expert judgments. Finally, we apply the method to label the 350K entities, producing a structured resource for downstream studies of social integration and related outcomes.

</details>


### [85] [In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations](https://arxiv.org/abs/2602.15456)
*Mohammad Aflah Khan,Mahsa Amani,Soumi Das,Bishwamittra Ghosh,Qinyuan Wu,Krishna P. Gummadi,Manish Gupta,Abhilasha Ravichander*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLM）作为信息接口时，其对不同信息来源的偏好问题。实验发现，LLM在呈现信息时存在系统性的来源偏好，这种偏好受上下文影响，甚至可能压过内容本身的影响，并且难以通过指令消除。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注LLM生成内容中的偏见，而较少关注LLM在筛选和呈现信息时选择哪些信息以及忽视哪些信息的因素。本文旨在探究LLM在信息来源归属时是否存在系统性的偏好。

Method: 通过在合成和真实世界任务上，对来自六个模型提供商的十二种LLM进行受控实验，来测试LLM是否会表现出来源偏好，并分析偏好受到的因素影响（如上下文、内容本身、提示指令）。

Result: 结果表明，多种LLM在处理归因于特定来源的信息时，确实表现出强且可预测的来源偏好。这些偏好对上下文敏感，有时甚至比内容本身更能影响LLM的选择，并且即使明确要求避免偏见，这些偏好依然存在。

Conclusion: LLM在作为信息接口时存在系统性的来源偏好，这可能导致某些来源的信息被优先展示，而另一些则被忽略。这种偏好需要进一步研究其根源，并提出为用户提供透明度和控制偏见的机制。

Abstract: Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms' back-end databases or via web search. In these scenarios, LLM agents govern the information users receive, by drawing users' attention to particular instances of retrieved information at the expense of others. While much prior work has focused on biases in the information LLMs themselves generate, less attention has been paid to the factors that influence what information LLMs select and present to users. We hypothesize that when information is attributed to specific sources (e.g., particular publishers, journals, or platforms), current LLMs exhibit systematic latent source preferences- that is, they prioritize information from some sources over others. Through controlled experiments on twelve LLMs from six model providers, spanning both synthetic and real-world tasks, we find that several models consistently exhibit strong and predictable source preferences. These preferences are sensitive to contextual framing, can outweigh the influence of content itself, and persist despite explicit prompting to avoid them. They also help explain phenomena such as the observed left-leaning skew in news recommendations in prior work. Our findings advocate for deeper investigation into the origins of these preferences, as well as for mechanisms that provide users with transparency and control over the biases guiding LLM-powered agents.

</details>


### [86] [TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models](https://arxiv.org/abs/2602.15449)
*Chansung Park,Juyong Jiang,Fan Wang,Sayak Paul,Jiasi Shen,Jing Tang,Jianguo Li*

Main category: cs.CL

TL;DR: TAROT 是一种新的强化学习微调方法，通过构建多层级测试集，并根据模型能力自适应地调整课程难度，显著提高了 LLM 生成代码的正确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）在代码生成方面仍存在挑战，尽管强化微调（RFT）有潜力，但其对测试用例的异质难度和粒度处理不当，导致训练中的奖励信号不平衡和梯度更新有偏。

Method: 提出 TAROT 方法，为每个问题构建一个包含基本、中级、复杂和边缘四层级的测试套件。TAROT 将课程进展与原始奖励分数解耦，实现基于能力的评估，并从课程策略组合中进行有原则的选择，而不是依赖于偶然的测试用例难度组合。这种方法旨在促进稳定的优化和更高效的能力获取。

Result: 实验表明，RFT 在代码生成中的最优课程与模型的内在能力密切相关。能力较低的模型在“易到难”的课程设计下收益更大，而能力更强的模型则在“先难后易”的课程下表现更好。TAROT 能够根据模型的不同能力自适应地定制课程设计。

Conclusion: TAROT 提供了一种可复现的方法，能够根据模型的具体能力自适应地调整课程设计，从而稳定地提高生成代码的功能正确性和鲁棒性。

Abstract: Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.

</details>


### [87] [Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit](https://arxiv.org/abs/2602.15504)
*Aswathy Velutharambath,Amelie Wührl*

Main category: cs.CL

TL;DR: 该研究提出了期望检测任务，并构建了一个名为 RedHOTExpect 的 Reddit 帖子语料库，用于分析患者在线讨论的治疗期望，发现乐观和积极的表述在身体或治疗相关疾病中更常见，患者主要讨论益处而非负面后果。


<details>
  <summary>Details</summary>
Motivation: 患者的治疗期望会影响治疗效果，而在线医疗平台可能包含患者在其他地方不愿分享的期望信息，但此前未有研究探讨在线患者讨论的期望类型及其表达方式。

Method: 1. 提出期望检测（Expectation Detection）任务。
2. 构建 RedHOTExpect 语料库，包含 4.5K 个 Reddit 帖子。
3. 使用大型语言模型（LLM）进行银标签标注，并人工验证（标签准确率约 78%）。
4. 分析语料库，识别表达期望的语言模式，并探讨患者期望的内容和原因。

Result: 1. 乐观和主动的表述在身体或治疗相关疾病的帖子中比心理健康相关的帖子更明显。
2. 在所分析的数据集中，患者主要讨论治疗的益处，而非负面后果。

Conclusion: 该研究引入了期望检测任务，并提供了 RedHOTExpect 语料库，为研究在线患者的治疗期望提供了资源。研究结果表明，患者在讨论身体健康问题时倾向于更乐观和积极的表述，并且关注治疗的潜在好处。

Abstract: Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from https://www.ims.uni-stuttgart.de/data/RedHOTExpect

</details>


### [88] [Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination](https://arxiv.org/abs/2602.15509)
*Xiangyan Chen,Yujian Gan,Matthew Purver*

Main category: cs.CL

TL;DR: 提出了一种名为Fine-Refine的细粒度对话系统幻觉修正框架，通过将响应分解为原子单元进行验证和修正，显著提高了事实准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在对话系统中存在幻觉问题，导致事实错误，影响用户信任。现有的修正方法仅在响应层面操作，忽略了响应中可能包含多个可验证的事实。

Method: 提出Fine-Refine框架，将响应分解为原子单元，利用外部知识验证每个单元，评估流畅性，并迭代修正错误。

Result: 在HybriDialogue和OpendialKG数据集上进行评估，Fine-Refine显著提高了事实准确性（事实得分最高提升7.63分），事实覆盖率也得到改善，仅对对话质量有轻微影响。

Conclusion: Fine-Refine框架能有效解决对话系统中LLM的幻觉问题，通过细粒度的验证和修正，显著提升了对话的事实准确性和可信度。

Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for dialogue systems typically operate at the response level, overlooking the fact that a single response may contain multiple verifiable or unverifiable facts. To address this gap, we propose Fine-Refine, a fine-grained refinement framework that decomposes responses into atomic units, verifies each unit using external knowledge, assesses fluency via perplexity, and iteratively corrects granular errors. We evaluate factuality across the HybriDialogue and OpendialKG datasets in terms of factual accuracy (fact score) and coverage (Not Enough Information Proportion), and experiments show that Fine-Refine substantially improves factuality, achieving up to a 7.63-point gain in dialogue fact score, with a small trade-off in dialogue quality.

</details>


### [89] [LuxMT Technical Report](https://arxiv.org/abs/2602.15506)
*Nils Rehlinger*

Main category: cs.CL

TL;DR: 本文提出了一种基于Gemma 3 27B的机器翻译系统LuxMT，用于卢森堡语到法语和英语的翻译。通过构建包含卢森堡语-法语、卢森堡语-英语以及卢森堡语-法语（人工翻译）的新基准测试，并使用LuxAlign（多语言卢森堡语新闻文章平行语料库）和卢森堡议会记录作为训练数据，并辅以谷歌翻译，以及使用LuxEmbedder过滤低质量数据，LuxMT在翻译效果上显著优于Gemma 3基线模型。此外，研究还探索了LuxEmbedder作为质量评估指标的潜力，发现其与参考指标有很强的相关性，但建议谨慎使用。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为卢森堡语（LB）和其他语言（如法语FR和英语EN）之间的机器翻译开发一个高性能系统，并评估新开发的数据过滤和质量评估工具的有效性。

Method: 研究采用Gemma 3 27B模型作为基础，并针对卢森堡语到法语和英语的翻译任务进行微调，构建了一个名为LuxMT的机器翻译系统。数据方面，使用了LuxAlign（卢森堡语新闻文章平行语料库）和卢森堡议会记录作为训练数据，并利用谷歌翻译进行扩充。为了提高数据质量，开发了LuxEmbedder工具，该工具基于卢森堡语的句子嵌入来过滤低等价的句子对。最后，通过构建包含人工翻译数据的基准测试来评估LuxMT的性能，并探索LuxEmbedder作为翻译质量评估指标的应用。

Result: LuxMT系统在卢森堡语到法语和英语的翻译任务上取得了显著的改进，即使在没有德语（DE）训练数据的情况下，对卢森堡语到德语的翻译效果也有提升。LuxEmbedder在作为质量评估指标方面，与现有参考指标显示出很强的相关性。

Conclusion: LuxMT系统在卢森堡语翻译方面表现出色，显著优于基础模型。LuxEmbedder作为一种新的质量评估方法，显示出潜力，但需要进一步研究来全面评估其适用性，并建议在使用时保持谨慎。

Abstract: We introduce LuxMT, a machine translation system based on Gemma 3 27B and fine-tuned for translation from Luxembourgish (LB) into French (FR) and English (EN). To assess translation performance, we construct a novel benchmark covering LB-FR, LB-EN, and LB-FR using human-translated data from Luci, a tourist magazine about Luxembourg. Training data stems from LuxAlign, a parallel corpus of multilingual Luxembourgish news articles, and LB parliamentary transcripts augmented with Google Translate. We filter the data using LuxEmbedder, LB sentence embeddings, to remove low-equivalence segment-pairs. Overall, LuxMT's results suggest strong improvements over the Gemma 3 baseline, even for translating LB to German (DE), despite the training data not containing any DE. We also explore LuxEmbedder's potential to be used as a quality estimation metric and find strong correlations with other reference-based metrics. However, we call for further research to fully assess the metric's utility and advise using it with caution.

</details>


### [90] [DependencyAI: Detecting AI Generated Text through Dependency Parsing](https://arxiv.org/abs/2602.15514)
*Sara Ahmed,Tracy Hammond*

Main category: cs.CL

TL;DR: DependencyAI 是一种仅使用语言依存关系标签来检测 AI 生成文本的新方法，具有良好的性能和可解释性，并且不依赖神经网络。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛应用，开发可靠的 AI 生成文本检测方法至关重要，以应对潜在风险。

Method: 该方法利用语言依存关系标签，分析特征重要性以区分 AI 生成文本和人类编写的文本，并观察到特定模型在跨领域泛化上的系统性过拟合问题。

Result: DependencyAI 在单语、多生成器和多语言环境中均取得了具有竞争力的性能。分析表明，依存关系特征能够有效区分 AI 生成文本和人类编写的文本。

Conclusion: 语言依存关系本身提供了检测 AI 生成文本的强大信号，DependencyAI 作为一种基于语言学、可解释且非神经网络的基线方法，表现出色。

Abstract: As large language models (LLMs) become increasingly prevalent, reliable methods for detecting AI-generated text are critical for mitigating potential risks. We introduce DependencyAI, a simple and interpretable approach for detecting AI-generated text using only the labels of linguistic dependency relations. Our method achieves competitive performance across monolingual, multi-generator, and multilingual settings. To increase interpretability, we analyze feature importance to reveal syntactic structures that distinguish AI-generated from human-written text. We also observe a systematic overprediction of certain models on unseen domains, suggesting that generator-specific writing styles may affect cross-domain generalization. Overall, our results demonstrate that dependency relations alone provide a robust signal for AI-generated text detection, establishing DependencyAI as a strong linguistically grounded, interpretable, and non-neural network baseline.

</details>


### [91] [ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns](https://arxiv.org/abs/2602.15521)
*Ziyu Zhao,Tong Zhu,Zhi Zhang,Tiantian Fan,Jinluan Yang,Kun Kuang,Zhongyu Wei,Fei Wu,Yu Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种名为ExpertWeaver的无需训练的框架，用于将预训练的密集模型转换为混合专家（MoE）模型。该方法利用Gated Linear Unit（GLU）机制的神经元激活模式来识别和构建共享专家和专门化专家，从而克服了现有方法破坏密集模型内在激活模式的缺点。


<details>
  <summary>Details</summary>
Motivation: 从头开始训练高质量的MoE模型成本高昂。将预训练的密集模型转换为MoE模型是一种有前景的替代方案。然而，现有的密集到MoE转换方法会破坏密集模型中固有的激活模式，导致次优的专家构建。

Method: ExpertWeaver框架利用GLU机制的神经元激活模式，识别出“普遍激活的通用神经元”和“动态激活的专用神经元”，从而揭示了内在的MoE结构。该框架根据激活模式对神经元进行划分，并构建具有层自适应配置的共享专家和专用路由专家。这是一个训练前的框架。

Result: ExpertWeaver在作为训练前的动态结构剪枝技术和作为用于MoE初始化的降级策略方面，都显著优于现有方法。

Conclusion: GLU机制的神经元激活模式为密集到MoE的转换提供了一个自然的蓝图。ExpertWeaver利用这一发现，能够有效地将密集模型转换为高质量的MoE模型，并在性能和效率上优于现有技术。

Abstract: Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.

</details>


### [92] [ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling](https://arxiv.org/abs/2602.15537)
*Nicol Visser,Simon Malan,Danel Slabbert,Herman Kamper*

Main category: cs.CL

TL;DR: 本文提出了一种名为ZeroSyl的训练无关方法，可以直接从冻结的WavLM模型中提取音节边界和嵌入，用于训练纯语音语言模型，并在多项基准测试中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有纯语音语言模型在处理来自自监督语音编码器的离散令牌时，会产生过长的序列，这促使了对音节类单元的研究。然而，现有方法（如Sylber和SyllableLM）需要复杂的多阶段训练流程。

Method: ZeroSyl利用WavLM模型中间层的特征L2范数来提取音节边界和嵌入。然后，将提取的音节片段进行均值池化，并通过K-means聚类进行离散化，最终用于训练语言模型。整个过程无需额外的训练。

Result: ZeroSyl在词汇、句法和叙事基准测试中取得了与现有音节标记器相当甚至更优的性能。规模化实验表明，虽然更细粒度的单元对词汇任务有益，但ZeroSyl发现的音节单元在句法建模方面表现出更好的扩展性。

Conclusion: ZeroSyl是一种简单且有效的训练无关方法，可以从冻结的WavLM模型中提取音节单位，并能有效地训练纯语音语言模型，在不同任务上均展现出竞争力，并且在句法建模方面具有良好的扩展潜力。

Abstract: Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on syllable-like units. However, methods like Sylber and SyllableLM rely on intricate multi-stage training pipelines. We propose ZeroSyl, a simple training-free method to extract syllable boundaries and embeddings directly from a frozen WavLM model. Using L2 norms of features in WavLM's intermediate layers, ZeroSyl achieves competitive syllable segmentation performance. The resulting segments are mean-pooled, discretized using K-means, and used to train a language model. ZeroSyl outperforms prior syllabic tokenizers across lexical, syntactic, and narrative benchmarks. Scaling experiments show that while finer-grained units are beneficial for lexical tasks, our discovered syllabic units exhibit better scaling behavior for syntactic modeling.

</details>


### [93] [Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite](https://arxiv.org/abs/2602.15540)
*Tim Fischer,Chris Biemann*

Main category: cs.CL

TL;DR: 本文介绍了一个名为Perspectives的交互式工具，用于帮助数字人文（DH）学者探索和组织大型文档集合，通过可控的聚类和用户反馈来挖掘文档中的主题和情感。


<details>
  <summary>Details</summary>
Motivation: 数字人文研究中，学者需要处理大量的非结构化文档，现有的工具难以有效地支持他们探索和组织这些数据，以发现有意义的洞察。

Method: Perspectives实现了一个灵活的、面向方面的文档聚类流程，并结合了“人在回路”的精炼能力。它通过定义分析视角（文档重写提示和基于指令的嵌入）来引导聚类，并通过可视化地图、簇精炼工具和嵌入模型微调机制来满足用户意图。

Result: 该工具能够帮助DH研究者通过交互式的文档地图发现文档中的主题、情感或其他相关类别，从而为后续深入分析做好数据准备。

Conclusion: Perspectives提供了一个有效的交互式框架，使用户能够主动地探索、组织和理解大型文档集合，增强了数字人文研究的数据分析能力。

Abstract: This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a flexible, aspect-focused document clustering pipeline with human-in-the-loop refinement capabilities. We showcase how this process can be initially steered by defining analytical lenses through document rewriting prompts and instruction-based embeddings, and further aligned with user intent through tools for refining clusters and mechanisms for fine-tuning the embedding model. The demonstration highlights a typical workflow, illustrating how DH researchers can leverage Perspectives's interactive document map to uncover topics, sentiments, or other relevant categories, thereby gaining insights and preparing their data for subsequent in-depth analysis.

</details>


### [94] [jina-embeddings-v5-text: Task-Targeted Embedding Distillation](https://arxiv.org/abs/2602.15547)
*Mohammad Kalim Akram,Saba Sturua,Nastia Havriushenko,Quentin Herreros,Michael Günther,Maximilian Werk,Han Xiao*

Main category: cs.CL

TL;DR: 提出了一种结合模型蒸馏和任务特定对比损失的新训练方法，用于训练小型、高性能的文本嵌入模型。


<details>
  <summary>Details</summary>
Motivation: 现有通用嵌入模型通常通过对比损失函数训练，希望找到一种更有效的方法来训练小型、高性能的嵌入模型。

Method: 结合模型蒸馏技术和任务特定的对比损失函数来训练嵌入模型。

Result: 新训练方法比单独的对比学习或蒸馏方法在训练小型模型方面更有效。生成的 jina-embeddings-v5-text-small 和 jina-embeddings-v5-text-nano 模型在同等大小模型中性能达到或超过了最先进水平，并支持长文本、多语言，且嵌入在截断和二值化下表现稳健。

Conclusion: 该研究提出了一种新颖的训练方法，成功地训练出了高性能、小巧且鲁棒的文本嵌入模型，并公开了模型权重，以期推动嵌入模型研究的进一步发展。

Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.

</details>


### [95] [Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL](https://arxiv.org/abs/2602.15564)
*Yihan Wang,Peiyu Liu,Runyu Chen,Wei Xu*

Main category: cs.CL

TL;DR: 提出了一种名为SquRL的强化学习框架，通过在推理时自适应地构建工作流来改进Text-to-SQL的性能，尤其是在复杂和分布外查询方面。


<details>
  <summary>Details</summary>
Motivation: 现有的Text-to-SQL方法依赖于单一的静态工作流，难以扩展到分布外和长尾场景，并且需要用户进行大量实验来选择合适的方法。

Method: 提出SquRL，一个强化学习框架，增强LLM在自适应工作流构建方面的推理能力。设计了一个基于规则的奖励函数，并引入了动态Actor掩码和伪奖励两种训练机制。

Result: 在Text-to-SQL基准测试中，SquRL的动态工作流构建方法始终优于最佳的静态工作流方法，尤其是在复杂和分布外查询上表现更佳。

Conclusion: 自适应工作流构建是提高Text-to-SQL系统在现实世界中泛化能力和鲁棒性的有效途径，SquRL框架能够实现这一点。

Abstract: Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL

</details>


### [96] [Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations](https://arxiv.org/abs/2602.15578)
*Chaithra Nerella,Chiranjeevi Yarra*

Main category: cs.CL

TL;DR: 提出一种症状特异性、受临床启发的语音抑郁严重程度估计框架，利用症状引导的交叉注意力机制，并引入可学习的症状特异性参数来提高性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症预测方法多采用二元标签或整体严重程度评分，未能显式建模症状特异性信息，限制了其在临床筛查中的症状层面分析能力。

Method: 使用症状引导的交叉注意力机制，将PHQ-8问卷项目与情感感知语音表示对齐，以识别与各症状相关的语音片段。引入可学习的症状特异性参数，自适应控制注意力分布的锐度。

Result: 在EDAIC数据集上取得了优于先前研究的性能。注意力分布分析显示，包含多重抑郁症状相关线索的的话语获得了更高的注意力，证明了方法的解释性。

Conclusion: 症状引导和情感感知建模对于基于语音的抑郁症筛查至关重要，提出的框架在性能和可解释性方面均表现出色。

Abstract: Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without explicitly modeling symptom-specific information. This limits their ability to provide symptom-level analysis relevant to clinical screening. To address this, we propose a symptom-specific and clinically inspired framework for depression severity estimation from speech. Our approach uses a symptom-guided cross-attention mechanism that aligns PHQ-8 questionnaire items with emotion-aware speech representations to identify which segments of a participant's speech are more important to each symptom. To account for differences in how symptoms are expressed over time, we introduce a learnable symptom-specific parameter that adaptively controls the sharpness of attention distributions. Our results on EDAIC, a standard clinical-style dataset, demonstrate improved performance outperforming prior works. Further, analyzing the attention distributions showed that higher attention is assigned to utterances containing cues related to multiple depressive symptoms, highlighting the interpretability of our approach. These findings outline the importance of symptom-guided and emotion-aware modeling for speech-based depression screening.

</details>


### [97] [STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens](https://arxiv.org/abs/2602.15620)
*Shiqi Liu,Zeyu He,Guojian Zhan,Letian Tao,Zhilong Zheng,Jiang Wu,Yinuo Wang,Yang Guan,Kehua Sheng,Bo Zhang,Keqiang Li,Jingliang Duan,Shengbo Eben Li*

Main category: cs.CL

TL;DR: 本研究提出了STAPO（Spurious-Token-Aware Policy Optimization），一种新的强化学习微调方法，通过识别并屏蔽掉对训练不稳定有负面影响的“虚假 token”的梯度更新，从而解决了大型语言模型在推理任务中训练不稳定的问题，并在多个数学推理基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习微调方法在提升大型语言模型推理能力的同时，常常面临训练不稳定和后期性能崩溃的问题。研究者发现，这种不稳定性源于一小部分“虚假 token”，它们虽然在正确答案中贡献甚微，却继承了整个序列的奖励，导致梯度更新异常放大。

Method: 研究者推导了 token-wise 策略梯度与 token 概率和局部策略熵之间的负相关性。在此基础上，提出了 STAPO 方法，通过识别并选择性地屏蔽掉由“虚假 token”产生的策略更新，并对有效 token 的损失进行重整，以提高训练的稳定性和效率。

Result: 在 Qwen 1.7B、8B 和 14B 模型上，使用 STAPO 方法在六个数学推理基准测试中，与 GRPO、20-Entropy 和 JustRL 等方法相比，STAPO 展现出更优越的熵稳定性，并且平均性能提升了 7.13%。

Conclusion: STAPO 是一种有效的强化学习微调策略，能够通过识别和处理“虚假 token”来解决大型语言模型推理任务中的训练不稳定问题，并显著提升模型在数学推理任务上的性能。

Abstract: Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\%, which we term \emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\% over GRPO, 20-Entropy and JustRL.

</details>


### [98] [LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675)
*Ahmed Khaled Khamis,Hesham Ali*

Main category: cs.CL

TL;DR: 本文介绍了NileTTS，一个包含38小时埃及阿拉伯语语音的语音合成数据集，以及一个用于生成该数据集的合成管线和一个基于该数据集微调的XTTS v2模型，旨在解决埃及阿拉伯语语音合成资源匮乏的问题。


<details>
  <summary>Details</summary>
Motivation: 现有神经文本到语音（TTS）技术在阿拉伯语方言方面的研究不足，特别是埃及阿拉伯语，尽管它是最广泛使用的方言，但资源却非常匮乏。

Method: 研究人员构建了一个包含38小时双人埃及阿拉伯语语音的数据集（NileTTS），涵盖了医疗、销售和日常对话等领域。他们设计了一个新颖的合成数据生成管线：首先使用大语言模型（LLM）生成埃及阿拉伯语内容，然后利用语音合成工具将其转换为自然语音，最后通过自动转录和说话人分离，并进行人工质量验证。在此基础上，他们微调了XTTS v2模型，并与仅用其他阿拉伯语方言训练的基线模型进行了比较。

Result: 研究成功构建了首个公开可用的埃及阿拉伯语TTS数据集，并开发了一个可复现的方言TTS合成数据生成管线。经过微调的模型在埃及阿拉伯语上的表现优于基线模型。

Conclusion: NileTTS数据集、合成数据生成管线和微调后的XTTS v2模型为埃及阿拉伯语语音合成研究提供了宝贵的资源，有望推动该领域的发展。

Abstract: Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.

</details>


### [99] [Revisiting Northrop Frye's Four Myths Theory with Large Language Models](https://arxiv.org/abs/2602.15678)
*Edirlei Soares de Lima,Marco A. Casanova,Antonio L. Furtado*

Main category: cs.CL

TL;DR: 本文提出了一种基于角色功能的计算框架，用于分析 Northrop Frye 的叙事类型理论，并利用大型语言模型（LLMs）在40部作品上进行了验证，LLMs 在识别角色-类型对应关系上取得了显著的准确率（平均82.5%），证明了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有计算方法侧重于叙事模式而非角色功能，而 Northrop Frye 的理论强调角色在不同叙事类型中的功能差异。因此，研究者希望弥补这一空白，提出一个计算性的角色功能框架。

Method: 借鉴荣格原型理论，将原型角色映射到荣格的心理结构，导出四个普适角色功能（主角、导师、反派、同伴）。随后，根据原型作品，将这四个功能特化为16种特定于文学类型的角色。利用六种先进的大型语言模型，对40部叙事作品的角色-类型对应关系进行了多模型验证，使用了160个正面样本和30个负面样本。

Result: LLMs 在识别角色-类型对应关系上取得了平均82.5%的平衡准确率，模型间一致性强（Fleiss' $κ$ = 0.600）。不同类型（72.7% - 89.9%）和角色（52.5% - 99.2%）的性能有所差异，这些差异反映了真实的叙事特性，例如浪漫类型中的功能分布和讽刺中的原型颠覆。

Conclusion: 提出的基于角色功能的计算框架能够被大型语言模型有效识别，揭示了叙事结构中的系统性模式。该方法为计算叙事学提供了新的视角，并有望促进叙事生成和互动讲故事技术的发展。

Abstract: Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $κ$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.

</details>


### [100] [A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models](https://arxiv.org/abs/2602.15689)
*Meirav Segal,Noa Linder,Omer Antverg,Gil Gekker,Tomer Fichman,Omri Bodenheimer,Edan Maor,Omer Nevo*

Main category: cs.CL

TL;DR: 研究提出了一种基于内容的框架，用于设计和审计网络拒绝策略，该框架显式地考虑了攻击风险和防御效益的权衡，解决了现有方法在处理语言模型在网络安全任务中的双重用途问题时存在的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）和基于LLM的代理在网络安全任务中存在双重用途问题，而当前的拒绝策略（如基于主题的禁令和攻击性分类）存在不一致、过度限制合法用户和易受混淆攻击等问题。研究者认为，有效的拒绝策略需要显式地建模攻击风险和防御效益的权衡。

Method: 提出一个基于内容的框架，该框架将请求的特点沿着五个维度进行表征：攻击行为贡献、攻击风险、技术复杂性、防御效益以及合法用户期望频率。这些维度基于请求的技术实质，而非用户的陈述意图。

Result: 内容为基础的方法解决了当前前沿模型行为的不一致性问题，并允许组织构建可调谐、风险感知的拒绝策略。

Conclusion: 基于内容的框架能够通过显式地考虑攻击风险和防御效益的权衡，提供一种更有效、更可靠的拒绝策略，以应对大语言模型在网络安全任务中的双重用途挑战。

Abstract: Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or offensive-focused taxonomies. As a result, they can yield inconsistent decisions, over-restrict legitimate defenders, and behave brittlely under obfuscation or request segmentation. We argue that effective refusal requires explicitly modeling the trade-off between offensive risk and defensive benefit, rather than relying solely on intent or offensive classification. In this paper, we introduce a content-based framework for designing and auditing cyber refusal policies that makes offense-defense tradeoffs explicit. The framework characterizes requests along five dimensions: Offensive Action Contribution, Offensive Risk, Technical Complexity, Defensive Benefit, and Expected Frequency for Legitimate Users, grounded in the technical substance of the request rather than stated intent. We demonstrate that this content-grounded approach resolves inconsistencies in current frontier model behavior and allows organizations to construct tunable, risk-aware refusal policies.

</details>


### [101] [Rethinking Metrics for Lexical Semantic Change Detection](https://arxiv.org/abs/2602.15716)
*Roksana Goworek,Haim Dubossarsky*

Main category: cs.CL

TL;DR: 本文提出了一种新的词汇语义变化检测（LSCD）度量方法——平均最小距离（AMD）和对称平均最小距离（SAMD），它们通过词语在不同时期使用方式的局部对应关系来量化语义变化。实验表明，AMD在多种语言、编码器模型和表示空间下表现更优，尤其是在降维和使用非专业编码器时。SAMD在专业编码器上表现更佳。作者认为，LSCD可以从探索AP D和PRT之外的度量方法中获益，AMD是基于上下文嵌入分析的稳健选择。


<details>
  <summary>Details</summary>
Motivation: 现有的词汇语义变化检测（LSCD）方法主要依赖于上下文语言模型嵌入，但通常使用少数几种度量标准（如APD和PRT），作者认为存在改进的空间，尤其是在处理高维数据和不同类型的编码器时。

Method: 提出并实现了两种新的语义变化度量方法：平均最小距离（AMD）和对称平均最小距离（SAMD）。AMD量化的是词语在不同时期用法之间的最小距离，SAMD则是在此基础上引入了对称性。通过在多语言、多种编码器和表示空间上进行实验来评估这些新方法的性能。

Result: AMD在多种实验条件下，特别是在应用降维和使用非专业编码器时，通常比现有的度量方法（APD和PRT）具有更稳健的表现。SAMD在专业编码器上表现尤为出色。

Conclusion: 作者建议LSCD研究应考虑APD和PRT之外的其他语义变化度量方法。AMD是一种稳健且有效的选择，能够提升基于上下文嵌入的LSCD分析性能。

Abstract: Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average Minimum Distance (SAMD), new measures that quantify semantic change via local correspondence between word usages across time periods. Across multiple languages, encoder models, and representation spaces, we show that AMD often provides more robust performance, particularly under dimensionality reduction and with non-specialised encoders, while SAMD excels with specialised encoders. We suggest that LSCD may benefit from considering alternative semantic change metrics beyond APD and PRT, with AMD offering a robust option for contextualised embedding-based analysis.

</details>


### [102] [Causal Effect Estimation with Latent Textual Treatments](https://arxiv.org/abs/2602.15730)
*Omri Feldman,Amar Venugopal,Jann Spiess,Amir Feder*

Main category: cs.CL

TL;DR: 本文提出了一种用于生成和因果估计文本干预的端到端流程，通过稀疏自编码器（SAE）进行假设生成和引导，然后进行鲁棒的因果估计，解决了文本作为处理的实验中的计算和统计挑战，并提出了基于协变量残差化的方法来缓解估计偏差。


<details>
  <summary>Details</summary>
Motivation: 理解文本对下游结果的因果效应在许多应用中是核心任务。估计这种效应需要运行控制实验来系统地改变文本特征。大型语言模型（LLMs）在生成文本方面有潜力，但生成和评估受控变异需要更细致的关注。

Method: 该研究采用了一个端到端的流程，首先使用稀疏自编码器（SAE）进行假设生成和引导，然后进行鲁棒的因果估计。针对文本作为处理的实验中的计算和统计挑战，提出了一种基于协变量残差化的解决方案来缓解估计偏差。

Result: 经验结果表明，该流程能够有效地诱导目标特征的变化，并减轻估计误差。与朴素估计相比，该方法能显著减少偏差。

Conclusion: 该管道为文本作为处理的因果效应估计提供了一个鲁棒的基础，有效地解决了因文本固有的处理和协变量信息混杂所导致的估计偏差问题。

Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.

</details>


### [103] [ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758)
*Manav Nitin Kapadnis,Lawanya Baghel,Atharva Naik,Carolyn Rosé*

Main category: cs.CL

TL;DR: 本研究提出了 ChartEditBench，一个用于评估多模态大语言模型（MLLM）在交互式图表编辑方面的基准测试，并揭示了当前 MLLM 在多轮交互中存在显著的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在单轮图表生成方面表现优异，但在实际数据探索中常见的、需要多轮交互的图表编辑能力却鲜有研究。用户需要通过迭代方式修改图表，这要求模型能够维持共同理解、跟踪编辑历史并适应不断变化的用户偏好。

Method: 研究引入了 ChartEditBench，这是一个包含 5,000 个难度控制的修改链的基准测试，用于评估通过代码进行增量式、视觉化引导的图表编辑。同时，提出了一个稳健的评估框架，结合了基于执行的保真度检查、像素级视觉相似度和逻辑代码验证，以克服 LLM-as-a-Judge 指标的局限性。

Result: 在 ChartEditBench 上的实验表明，与单轮相比，最先进的 MLLM 在多轮设置下性能显著下降，原因在于错误累积和上下文理解中断。模型在风格化编辑方面表现良好，但在数据中心化的转换方面经常出现执行失败。

Conclusion: ChartEditBench 是一个具有挑战性的测试平台，用于评估多模态模型在视觉引导、意图感知和多轮交互式的图表编程能力。现有 MLLM 在多轮图表编辑方面仍需大幅改进。

Abstract: While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.

</details>


### [104] [Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos](https://arxiv.org/abs/2602.15757)
*Laura De Grazia,Danae Sánchez Villegas,Desmond Elliott,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 该研究提出了一个包含二元和细粒度标注的多模态西班牙语性别歧视检测数据集FineMuSe，并构建了一个包含性别歧视、非性别歧视以及反讽和幽默修辞手法的分层分类法。研究还评估了多种语言模型在不同粒度性别歧视检测上的表现，发现多模态语言模型在识别细微性别歧视方面表现出色，但在处理视觉线索中并存的性别歧视类型时存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化性别歧视检测工具通常局限于二元分类，无法捕捉细微且上下文相关的性别歧视表现，导致其可能被漏检。

Method: 1. 构建了一个名为FineMuSe的多模态数据集，包含西班牙语文本和图像，并提供二元和细粒度标注。2. 设计了一个包含性别歧视、非性别歧视以及反讽和幽默等修辞手法的层级分类法。3. 评估了多种大型语言模型（LLMs）在二元和细粒度性别歧视检测上的性能。

Result: 多模态语言模型在细粒度性别歧视检测方面表现与人类标注者相当。然而，当性别歧视类型通过视觉线索并存时，模型难以准确识别。

Conclusion: FineMuSe数据集和分层分类法为更精细的多模态性别歧视检测提供了基础。多模态语言模型在识别细微性别歧视方面具有潜力，但仍需改进以处理复杂的视觉和文本组合情况。

Abstract: Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.

</details>


### [105] [Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac](https://arxiv.org/abs/2602.15753)
*Chahan Vidal-Gorène,Bastien Kindt,Florian Cafiero*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）在低资源语言（如古希腊语、古典亚美尼亚语、古格鲁吉亚语和叙利亚语）的词形还原和词性标注任务上的表现，发现在少样本和零样本设置下，LLMs 取得了具有竞争力的甚至更优的性能。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在自然语言处理任务（如词形还原和词性标注）方面存在持续的挑战。本研究旨在探索大型语言模型（LLMs）在这些任务上的潜力，特别是在数据稀缺的情况下。

Method: 研究人员使用了 GPT-4 变体和 Mistral 模型，在少样本和零样本设置下，对四种低资源语言（古希腊语、古典亚美尼亚语、古格鲁吉亚语和叙利亚语）的词形还原和词性标注任务进行了评估。构建了一个包含训练和域外测试语料库的新基准，并将 LLMs 的性能与一个特定的 RNN 基线模型 PIE 进行了比较。

Result: 在少样本设置下，LLMs 在大多数语言的词性标注和词形还原任务上取得了与 PIE 模型相当或更好的性能，即使没有进行微调。对于具有复杂形态和非拉丁字母的语言，仍然存在挑战。

Conclusion: 大型语言模型是处理低资源语言词形还原和词性标注任务的有效工具，即使在缺乏数据的情况下，也能作为有效的辅助工具启动语言标注工作。

Abstract: Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and open-weight Mistral models, to address these tasks in few-shot and zero-shot settings for four historically and linguistically diverse under-resourced languages: Ancient Greek, Classical Armenian, Old Georgian, and Syriac. Using a novel benchmark comprising aligned training and out-of-domain test corpora, we evaluate the performance of foundation models across lemmatization and POS-tagging, and compare them with PIE, a task-specific RNN baseline. Our results demonstrate that LLMs, even without fine-tuning, achieve competitive or superior performance in POS-tagging and lemmatization across most languages in few-shot settings. Significant challenges persist for languages characterized by complex morphology and non-Latin scripts, but we demonstrate that LLMs are a credible and relevant option for initiating linguistic annotation tasks in the absence of data, serving as an effective aid for annotation.

</details>


### [106] [ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution](https://arxiv.org/abs/2602.15769)
*Yahia Alqurnawi,Preetom Biswas,Anmol Rao,Tejas Anvekar,Chitta Baral,Vivek Gupta*

Main category: cs.CL

TL;DR: 当前多模态大语言模型（mLLMs）在结构化数据（如表格）问答方面存在显著的溯源（归因）准确性问题，远低于问答准确性，尤其在JSON格式输入时接近随机水平，且模型在引用行上优于列，在文本格式上弱于图像，不同模型家族间也存在差异，这限制了其在需要透明度和可追溯性的应用中的使用。


<details>
  <summary>Details</summary>
Motivation: 用户在使用多模态大语言模型（mLLMs）回答结构化数据（如表格）问题时，不仅需要答案，还需要知道答案的出处，即支持答案的具体行和列。然而，现有mLLMs在这方面的能力尚不明确。

Method: 研究人员评估了多款mLLMs在不同表格格式（Markdown, JSON, images）和提示策略下的结构化数据归因/引用能力，并对比了问答准确性和归因准确性。

Result: 在所有评估的模型中，问答准确性尚可，但归因准确性远低于问答准确性，在JSON输入时接近随机水平。模型在引用行上比引用列更可靠，并且在文本格式上比图像格式的归因能力更弱。不同模型家族之间也存在明显的性能差异。

Conclusion: 目前的多模态大语言模型在为结构化数据提供细粒度的、可信的归因方面是不可靠的，这限制了它们在需要透明度和可追溯性的应用中的部署。

Abstract: Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users also need to know where those answers come from. In this work, we study structured data attribution/citation, which is the ability of the models to point to the specific rows and columns that support an answer. We evaluate several mLLMs across different table formats and prompting strategies. Our results show a clear gap between question answering and evidence attribution. Although question answering accuracy remains moderate, attribution accuracy is much lower, near random for JSON inputs, across all models. We also find that models are more reliable at citing rows than columns, and struggle more with textual formats than images. Finally, we observe notable differences across model families. Overall, our findings show that current mLLMs are unreliable at providing fine-grained, trustworthy attribution for structured data, which limits their usage in applications requiring transparency and traceability.

</details>


### [107] [*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation](https://arxiv.org/abs/2602.15778)
*Quentin Lemesle,Léane Jourdan,Daisy Munson,Pierre Alain,Jonathan Chevelu,Arnaud Delhay,Damien Lolive*

Main category: cs.CL

TL;DR: 提出了一种名为*-PLUIE的计算成本低且无需生成文本的LLM-judge方法，该方法通过特定任务的提示变体来提高与人类判断的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM-judge方法计算成本高且需要后处理，因此需要更经济高效的替代方案。

Method: 基于ParaPLUIE（一种基于困惑度的LLM-judge度量），引入了*-PLUIE，这是ParaPLUIE针对特定任务的提示变体。通过与人类判断进行对比来评估其有效性。

Result: 实验表明，个性化的*-PLUIE与人类评分的相关性更强，同时保持了较低的计算成本。

Conclusion: *-PLUIE作为一种计算成本低且无需生成文本的LLM-judge方法，在评估自动生成文本质量方面，特别是通过个性化提示，能更好地与人类判断保持一致。

Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.

</details>


### [108] [Avey-B](https://arxiv.org/abs/2602.15814)
*Devang Acharya,Mohammad Hammoud*

Main category: cs.CL

TL;DR: 本文改进了一种名为Avey的无注意力自回归模型，使其适用于仅编码器架构，并在各种NLP任务上超越了基于Transformer的模型，同时具有更高效的长上下文处理能力。


<details>
  <summary>Details</summary>
Motivation: 在计算和内存资源受限的工业场景中，需要高效的预训练双向编码器。BERT风格的架构虽然有效，但计算成本较高。Avey作为一种无注意力的替代方案，自然适合仅编码器架构，但需要进一步优化。

Method: 本文对Avey模型进行了重构，使其适应仅编码器范式，并引入了以下创新：解耦的静态和动态参数化、面向稳定性的归一化、以及神经压缩技术。

Result: 改进后的Avey模型在标准令牌分类和信息检索基准测试中，表现优于四种广泛使用的基于Transformer的编码器。在处理长上下文时，其效率也更高。

Conclusion: 通过引入新的架构创新，本文提出的仅编码器Avey模型在性能和效率上均超越了现有的Transformer模型，为资源受限的NLP应用提供了一个有前景的替代方案。

Abstract: Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [109] [CLOT: Closed-Loop Global Motion Tracking for Whole-Body Humanoid Teleoperation](https://arxiv.org/abs/2602.15060)
*Tengjie Zhu,Guanyu Cai,Yang Zhaohui,Guanzhu Ren,Haohui Xie,ZiRui Wang,Junsong Wu,Jingbo Wang,Xiaokang Yang,Yao Mu,Yichao Yan,Yichao Yan*

Main category: cs.RO

TL;DR: 本文提出了一种名为CLOT的实时全身人形遥操作系统，通过高频定位反馈实现闭环全局运动跟踪，解决了长期遥操作中的姿态漂移问题，并采用数据驱动的随机化策略和对抗性运动先验来提高稳定性和流畅性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的遥操作方法通常在机器人局部坐标系下运行，忽略全局姿态反馈，导致在长时间操作中出现累积的全局姿态漂移和不稳定性，尤其是在全身人形机器人上。

Method: CLOT系统通过高频定位反馈实现操作员和机器人姿态的闭环同步。为了解决直接施加全局跟踪奖励导致的激进和脆弱的修正问题，提出了一种数据驱动的随机化策略，将观测轨迹与奖励评估解耦。此外，还引入了对抗性运动先验来正则化策略，抑制不自然的动作。使用Transformer作为策略网络，并收集了20小时的人体运动数据进行训练。

Result: 在仿真和真实世界实验中，CLOT系统在全身人形遥操作中展现出高动态运动、高精度跟踪和强大的鲁棒性。该系统成功部署在了一个31自由度（不含手部）的全尺寸人形机器人上。

Conclusion: CLOT系统通过闭环全局运动跟踪实现了长时间、无漂移的人体模仿，并提出了一种有效的数据驱动随机化策略来处理全局跟踪的挑战，证明了其在全身人形遥操作中的有效性和鲁棒性。

Abstract: Long-horizon whole-body humanoid teleoperation remains challenging due to accumulated global pose drift, particularly on full-sized humanoids. Although recent learning-based tracking methods enable agile and coordinated motions, they typically operate in the robot's local frame and neglect global pose feedback, leading to drift and instability during extended execution. In this work, we present CLOT, a real-time whole-body humanoid teleoperation system that achieves closed-loop global motion tracking via high-frequency localization feedback. CLOT synchronizes operator and robot poses in a closed loop, enabling drift-free human-to-humanoid mimicry over long timehorizons. However, directly imposing global tracking rewards in reinforcement learning, often results in aggressive and brittle corrections. To address this, we propose a data-driven randomization strategy that decouples observation trajectories from reward evaluation, enabling smooth and stable global corrections. We further regularize the policy with an adversarial motion prior to suppress unnatural behaviors. To support CLOT, we collect 20 hours of carefully curated human motion data for training the humanoid teleoperation policy. We design a transformer-based policy and train it for over 1300 GPU hours. The policy is deployed on a full-sized humanoid with 31 DoF (excluding hands). Both simulation and real-world experiments verify high-dynamic motion, high-precision tracking, and strong robustness in sim-to-real humanoid teleoperation. Motion data, demos and code can be found in our website.

</details>


### [110] [Safe-SDL:Establishing Safety Boundaries and Control Mechanisms for AI-Driven Self-Driving Laboratories](https://arxiv.org/abs/2602.15061)
*Zihan Zhang,Haohui Que,Junhan Chang,Xin Zhang,Hao Wei,Tong Zhu*

Main category: cs.RO

TL;DR: 该论文提出了 Safe-SDL 框架，用于解决自动驾驶实验室（SDL）中人工智能生成的指令与实际物理安全之间的“语法到安全”差距问题，通过定义操作设计域（ODDs）、控制屏障函数（CBFs）和事务安全协议（CRUTD）来确保系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有自驾实验室（SDL）虽然能加速科研进程，但面临传统实验室或纯数字AI所没有的独特安全挑战，特别是AI生成指令的物理安全隐患。

Method: 提出 Safe-SDL 框架，包含三个核心组件：1. 形式化定义的操作设计域（ODDs）限制系统行为；2. 控制屏障函数（CBFs）实时监控以提供安全保证；3. 事务安全协议（CRUTD）确保数字规划与物理执行的一致性。

Result: 分析了现有的 UniLabOS 和 Osprey 架构，并发现当前的底层模型存在显著的安全缺陷。评估显示，架构层面的安全机制是必不可少的。

Conclusion: Safe-SDL 框架为安全部署人工智能驱动的自主科学系统提供了理论基础和实践指导，旨在负责任地加速AI驱动的科学发现。

Abstract: The emergence of Self-Driving Laboratories (SDLs) transforms scientific discovery methodology by integrating AI with robotic automation to create closed-loop experimental systems capable of autonomous hypothesis generation, experimentation, and analysis. While promising to compress research timelines from years to weeks, their deployment introduces unprecedented safety challenges differing from traditional laboratories or purely digital AI. This paper presents Safe-SDL, a comprehensive framework for establishing robust safety boundaries and control mechanisms in AI-driven autonomous laboratories. We identify and analyze the critical ``Syntax-to-Safety Gap'' -- the disconnect between AI-generated syntactically correct commands and their physical safety implications -- as the central challenge in SDL deployment. Our framework addresses this gap through three synergistic components: (1) formally defined Operational Design Domains (ODDs) that constrain system behavior within mathematically verified boundaries, (2) Control Barrier Functions (CBFs) that provide real-time safety guarantees through continuous state-space monitoring, and (3) a novel Transactional Safety Protocol (CRUTD) that ensures atomic consistency between digital planning and physical execution. We ground our theoretical contributions through analysis of existing implementations including UniLabOS and the Osprey architecture, demonstrating how these systems instantiate key safety principles. Evaluation against the LabSafety Bench reveals that current foundation models exhibit significant safety failures, demonstrating that architectural safety mechanisms are essential rather than optional. Our framework provides both theoretical foundations and practical implementation guidance for safe deployment of autonomous scientific systems, establishing the groundwork for responsible acceleration of AI-driven discovery.

</details>


### [111] [How Do We Research Human-Robot Interaction in the Age of Large Language Models? A Systematic Review](https://arxiv.org/abs/2602.15063)
*Yufeng Wang,Yuan Xu,Anastasia Nikolova,Yuxuan Wang,Jianyu Wang,Chongyang Wang,Xin Tong*

Main category: cs.RO

TL;DR: 本研究系统地回顾了86篇关于大型语言模型（LLMs）在人机交互（HRI）领域应用的论文，发现LLMs正在改变HRI的基础，但目前的研究仍处于探索阶段，缺乏统一的方法和评估标准。研究提出了未来的设计考量和挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究侧重于LLMs在HRI中的技术潜力，但缺乏对LLMs在人机交互中的人类中心影响（如用户理解、用户建模和自主性水平）的系统性考察，导致难以整合LLM驱动的HRI系统中的新兴挑战。

Method: 遵循PRISMA指南，进行了系统的文献检索，共纳入86篇符合标准的研究论文。

Result: 1. LLMs通过改变机器人感知上下文、产生符合社会情境的交互以及在具身环境中持续满足人类需求的方式，正在重塑HRI的基础。2. 当前研究尚处于探索阶段，侧重点各异，实验设置、研究方法和评估指标选择广泛。

Conclusion: LLMs对HRI产生了深远影响，但研究方法和评估方式不统一。本研究为LLMs与HRI交叉领域未来的研究提供了设计考量和挑战的概述及指导。

Abstract: Advances in large language models (LLMs) are profoundly reshaping the field of human-robot interaction (HRI). While prior work has highlighted the technical potential of LLMs, few studies have systematically examined their human-centered impact (e.g., human-oriented understanding, user modeling, and levels of autonomy), making it difficult to consolidate emerging challenges in LLM-driven HRI systems. Therefore, we conducted a systematic literature search following the PRISMA guideline, identifying 86 articles that met our inclusion criteria. Our findings reveal that: (1) LLMs are transforming the fundamentals of HRI by reshaping how robots sense context, generate socially grounded interactions, and maintain continuous alignment with human needs in embodied settings; and (2) current research is largely exploratory, with different studies focusing on different facets of LLM-driven HRI, resulting in wide-ranging choices of experimental setups, study methods, and evaluation metrics. Finally, we identify key design considerations and challenges, offering a coherent overview and guidelines for future research at the intersection of LLMs and HRI.

</details>


### [112] [Augmenting Human Balance with Generic Supernumerary Robotic Limbs](https://arxiv.org/abs/2602.15092)
*Xuanyun Qiu,Dorian Verdel,Hector Cervantes-Culebro,Alexis Devillard,Etienne Burdet*

Main category: cs.RO

TL;DR: 本文提出了一个用于增强机器人假肢（SLs）通用性的三层架构框架，旨在解决安全性（特别是保持平衡）和多功能控制的挑战。该框架通过预测人类躯干和质心（CoM）的动态，规划最优CoM轨迹以对抗躯干运动，并执行相应的SL控制输入，从而有效提高了平衡能力。


<details>
  <summary>Details</summary>
Motivation: 现有超额机器人肢体（SLs）的可用性受到安全性和通用控制的限制，尤其是在保持平衡方面。本文旨在解决这一关键问题，为通用SLs提供一种通用的平衡保持框架，而不是仅限于稳定性支持的SLs。

Method: 提出了一种分层三层架构框架：（i）预测层：估计人类躯干和质心（CoM）的动力学。（ii）规划层：生成最优CoM轨迹以对抗躯干运动，并计算相应的SL控制输入。（iii）控制层：在SL硬件上执行这些输入。

Result: 通过十名参与者执行前屈和侧屈任务的评估，证明了该框架能够显著减少站立不稳定性，提高了平衡能力。

Conclusion: 该框架为实现安全和通用的机器人假肢（SLs）与人类的交互提供了基础，是迈向安全和通用人-SLs交互的重要一步。

Abstract: Supernumerary robotic limbs (SLs) have the potential to transform a wide range of human activities, yet their usability remains limited by key technical challenges, particularly in ensuring safety and achieving versatile control. Here, we address the critical problem of maintaining balance in the human-SLs system, a prerequisite for safe and comfortable augmentation tasks. Unlike previous approaches that developed SLs specifically for stability support, we propose a general framework for preserving balance with SLs designed for generic use. Our hierarchical three-layer architecture consists of: (i) a prediction layer that estimates human trunk and center of mass (CoM) dynamics, (ii) a planning layer that generates optimal CoM trajectories to counteract trunk movements and computes the corresponding SL control inputs, and (iii) a control layer that executes these inputs on the SL hardware. We evaluated the framework with ten participants performing forward and lateral bending tasks. The results show a clear reduction in stance instability, demonstrating the framework's effectiveness in enhancing balance. This work paves the path towards safe and versatile human-SLs interactions. [This paper has been submitted for publication to IEEE.]

</details>


### [113] [A Comparison of Bayesian Prediction Techniques for Mobile Robot Trajectory Tracking](https://arxiv.org/abs/2602.15354)
*Jose Luis Peralta-Cabezas,Miguel Torres-Torriti,Marcelo Guarini-Hermann*

Main category: cs.RO

TL;DR: 本文比较了多种机器人多目标跟踪的估计和预测技术，重点关注估计误差、计算量和对非高斯噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了评估和比较不同的机器人多目标跟踪技术，了解它们在估计误差、计算效率和对噪声鲁棒性方面的性能。

Method: 比较了卡尔曼滤波器及其变体（如扩展卡尔曼滤波器、无迹卡尔曼滤波器）和基于序列蒙特卡洛采样的方法（如粒子滤波器、高斯混合点粒子滤波器）。

Result: 文章将从估计/预测误差大小、计算成本和对非高斯噪声的鲁棒性三个方面对这些技术进行性能评估。

Conclusion: 文中将通过比较不同技术在关键性能指标上的表现，为机器人多目标跟踪任务提供技术选型依据。

Abstract: This paper presents a performance comparison of different estimation and prediction techniques applied to the problem of tracking multiple robots. The main performance criteria are the magnitude of the estimation or prediction error, the computational effort and the robustness of each method to non-Gaussian noise. Among the different techniques compared are the well known Kalman filters and their different variants (e.g. extended and unscented), and the more recent techniques relying on Sequential Monte Carlo Sampling methods, such as particle filters and Gaussian Mixture Sigma Point Particle Filter.

</details>


### [114] [A ROS2 Benchmarking Framework for Hierarchical Control Strategies in Mobile Robots for Mediterranean Greenhouses](https://arxiv.org/abs/2602.15162)
*Fernando Cañadas-Aránega,Francisco J. Mañas-Álvarez,José L- Guzmán,José C. Moreno,José L. Blanco-Claraco*

Main category: cs.RO

TL;DR: 本文提出了一种用于评估地中海温室等农业工业环境中移动机器人控制器的基准测试框架，该框架集成了一个三维环境模型、物理模拟器和分层控制架构，并考虑了实际操作中的各种干扰因素，使用标准化的性能指标和统计分析方法来确保评估的客观性和可重复性。


<details>
  <summary>Details</summary>
Motivation: 农业工业环境（如地中海温室）中的移动机器人面临着严峻的操作条件（如不平坦地形、摩擦变化、载荷变化和坡度），这些条件严重影响了控制性能和稳定性。然而，缺乏标准化的、可重现的基准测试阻碍了对控制策略在现实操作条件下的公平比较和系统评估。

Method: 该框架集成了精确的三维环境模型、基于物理的模拟器和包含低、中、高层控制的层次化控制架构。定义了三个基准类别（从执行器级别控制到完全自主导航）和三种干扰场景（载荷变化、地形类型和坡度）。引入了标准化的性能指标（SAE、SCI 和复合性能指数），并采用基于重复试验的统计分析。框架还采用插件式架构，以方便集成用户定义的控制器和规划器。

Result: 所提出的框架提供了一个稳健且可扩展的工具，用于在现实条件下对经典、预测和基于规划的控制策略进行定量比较。

Conclusion: 该基准测试框架能够为农业工业应用中的移动机器人控制器提供客观、可重现的评估，弥合了仿真分析与实际应用之间的差距。

Abstract: Mobile robots operating in agroindustrial environments, such as Mediterranean greenhouses, are subject to challenging conditions, including uneven terrain, variable friction, payload changes, and terrain slopes, all of which significantly affect control performance and stability. Despite the increasing adoption of robotic platforms in agriculture, the lack of standardized, reproducible benchmarks impedes fair comparisons and systematic evaluations of control strategies under realistic operating conditions. This paper presents a comprehensive benchmarking framework for evaluating mobile robot controllers in greenhouse environments. The proposed framework integrates an accurate three dimensional model of the environment, a physics based simulator, and a hierarchical control architecture comprising low, mid, and high level control layers. Three benchmark categories are defined to enable modular assessment, ranging from actuator level control to full autonomous navigation. Additionally, three disturbance scenarios payload variation, terrain type, and slope are explicitly modeled to replicate real world agricultural conditions. To ensure objective and reproducible evaluation, standardized performance metrics are introduced, including the Squared Absolute Error (SAE), the Squared Control Input (SCI), and composite performance indices. Statistical analysis based on repeated trials is employed to mitigate the influence of sensor noise and environmental variability. The framework is further enhanced by a plugin based architecture that facilitates seamless integration of user defined controllers and planners. The proposed benchmark provides a robust and extensible tool for the quantitative comparison of classical, predictive, and planning based control strategies in realistic conditions, bridging the gap between simulation based analysis and real world agroindustrial applications.

</details>


### [115] [Estimating Human Muscular Fatigue in Dynamic Collaborative Robotic Tasks with Learning-Based Models](https://arxiv.org/abs/2602.15684)
*Feras Kiki,Pouya P. Niaz,Alireza Madani,Cagatay Basdogan*

Main category: cs.RO

TL;DR: 提出了一种基于机器学习和深度学习的数据驱动框架，用于通过表面肌电图（sEMG）估计物理人机交互（pHRI）中的肌肉疲劳程度。该框架将疲劳估计视为回归问题，预测剩余工作能力，并表现出跨任务的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在物理人机交互（pHRI）中，准确评估人类肌肉疲劳对于优化性能和确保安全至关重要。

Method: 研究人员提出了一种数据驱动的框架，使用臂式表面肌电图（sEMG）来估计动态、循环pHRI中的疲劳。他们训练了基于特征的机器学习回归模型（随机森林、XGBoost、线性回归）和基于深度学习的卷积神经网络（CNN），以预测达到疲劳的剩余循环次数（FCF）。

Result: 实验结果表明，CNN在FCF估计方面表现出最低的均方根误差（RMSE），为20.8+/-4.3%。基于树的模型（随机森林和XGBoost）紧随其后。研究还发现，在仅用侧向运动数据训练的模型，在测试垂直和圆形运动时，能够基本保持准确性，表明其具有一定的跨任务泛化能力。

Conclusion: 该研究证明了基于特征的机器学习和基于频谱图的深度学习都能够有效估计重复性pHRI中的剩余工作能力。CNN模型误差最低，树模型也表现良好。研究结果表明，该框架可能无需针对每个新任务进行重新训练，从而有望实现实际的疲劳监测，提高操作员的安全性，并支持疲劳感知的共享自主性，以实现更安全的pHRI控制。

Abstract: Assessing human muscle fatigue is critical for optimizing performance and safety in physical human-robot interaction(pHRI). This work presents a data-driven framework to estimate fatigue in dynamic, cyclic pHRI using arm-mounted surface electromyography(sEMG). Subject-specific machine-learning regression models(Random Forest, XGBoost, and Linear Regression predict the fraction of cycles to fatigue(FCF) from three frequency-domain and one time-domain EMG features, and are benchmarked against a convolutional neural network(CNN) that ingests spectrograms of filtered EMG. Framing fatigue estimation as regression (rather than classification) captures continuous progression toward fatigue, supporting earlier detection, timely intervention, and adaptive robot control. In experiments with ten participants, a collaborative robot under admittance control guided repetitive lateral (left-right) end-effector motions until muscular fatigue. Average FCF RMSE across participants was 20.8+/-4.3% for the CNN, 23.3+/-3.8% for Random Forest, 24.8+/-4.5% for XGBoost, and 26.9+/-6.1% for Linear Regression. To probe cross-task generalization, one participant additionally performed unseen vertical (up-down) and circular repetitions; models trained only on lateral data were tested directly and largely retained accuracy, indicating robustness to changes in movement direction, arm kinematics, and muscle recruitment, while Linear Regression deteriorated. Overall, the study shows that both feature-based ML and spectrogram-based DL can estimate remaining work capacity during repetitive pHRI, with the CNN delivering the lowest error and the tree-based models close behind. The reported transfer to new motion patterns suggests potential for practical fatigue monitoring without retraining for every task, improving operator protection and enabling fatigue-aware shared autonomy, for safer fatigue-adaptive pHRI control.

</details>


### [116] [DexEvolve: Evolutionary Optimization for Robust and Diverse Dexterous Grasp Synthesis](https://arxiv.org/abs/2602.15201)
*René Zurbrügg,Andrei Cramariuc,Marco Hutter*

Main category: cs.RO

TL;DR: 本研究提出了一种可扩展的生成-精炼（generate-and-refine）流水线，用于合成大规模、多样化且物理上可行的抓取。该方法利用高保真模拟器进行抓取质量的优化，而非仅用于验证和过滤，并结合进化算法和扩散模型，显著提高了抓取数量和多样性，并在实验中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的抓取预测依赖于昂贵且有限的数据集；解析式抓取合成的简化假设常导致物理上不可行的抓取，需要耗时的高保真模拟器过滤，限制了抓取的数量和多样性。因此，研究的动机在于开发一种能生成大规模、多样化且物理可行抓取的自动化方法。

Method: 本研究提出了一种生成-精炼流水线。首先，使用解析式方法生成初始抓取候选项。然后，利用高保真模拟器（Isaac Sim）和异步无梯度进化算法对这些候选项进行迭代优化，以提高抓取质量和稳定性。此外，该方法还允许通过人类偏好或特定领域指标来引导优化。最后，将优化后的抓取分布蒸馏成一个扩散模型，以实现鲁棒的实际部署。实验使用了新引入的Handles数据集和DexGraspNet子集。

Result: 该方法在Handles数据集和DexGraspNet子集上，实现了每个物体超过120个不同的稳定抓取，相比未精炼的解析方法有1.7-6倍的提升。与基于扩散模型的替代方法相比，该方法在唯一抓取覆盖率方面表现更好，提升了46-60%。

Conclusion: 研究提出了一种有效的生成-精炼流水线，能够合成大规模、多样化且物理上可行的抓取。该方法通过在高保真模拟器中进行持续优化，克服了传统方法的局限性，并在抓取数量、多样性和覆盖率方面取得了显著的改进，为机器人抓取任务提供了更强大、更具适应性的解决方案。

Abstract: Dexterous grasping is fundamental to robotics, yet data-driven grasp prediction heavily relies on large, diverse datasets that are costly to generate and typically limited to a narrow set of gripper morphologies. Analytical grasp synthesis can be used to scale data collection, but necessary simplifying assumptions often yield physically infeasible grasps that need to be filtered in high-fidelity simulators, significantly reducing the total number of grasps and their diversity.
  We propose a scalable generate-and-refine pipeline for synthesizing large-scale, diverse, and physically feasible grasps. Instead of using high-fidelity simulators solely for verification and filtering, we leverage them as an optimization stage that continuously improves grasp quality without discarding precomputed candidates. More specifically, we initialize an evolutionary search with a seed set of analytically generated, potentially suboptimal grasps. We then refine these proposals directly in a high-fidelity simulator (Isaac Sim) using an asynchronous, gradient-free evolutionary algorithm, improving stability while maintaining diversity. In addition, this refinement stage can be guided toward human preferences and/or domain-specific quality metrics without requiring a differentiable objective. We further distill the refined grasp distribution into a diffusion model for robust real-world deployment, and highlight the role of diversity for both effective training and during deployment. Experiments on a newly introduced Handles dataset and a DexGraspNet subset demonstrate that our approach achieves over 120 distinct stable grasps per object (a 1.7-6x improvement over unrefined analytical methods) while outperforming diffusion-based alternatives by 46-60\% in unique grasp coverage.

</details>


### [117] [Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching](https://arxiv.org/abs/2602.15827)
*Zhen Wu,Xiaoyu Huang,Lujie Yang,Yuanhang Zhang,Koushil Sreenath,Xi Chen,Pieter Abbeel,Rocky Duan,Angjoo Kanazawa,Carmelo Sferrazza,Guanya Shi,C. Karen Liu*

Main category: cs.RO

TL;DR: 提出了一种名为 PHP 的模块化框架，使人形机器人能够通过运动匹配和强化学习自主执行跨越复杂障碍物的长时程、基于视觉的跑酷动作，并在实际实验中达到了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人行走技术在应对复杂地形方面取得了进展，但在模仿人类高动态运动的敏捷性和适应性方面仍存在挑战，尤其是在需要低级鲁棒性、运动表现力、长期技能组合和感知驱动决策的人类跑酷场景中。

Method: PHP 框架首先利用运动匹配（在特征空间中进行最近邻搜索）来组合重定向的原子人类技能，生成长时程运动学轨迹。然后，通过 DAgger 和强化学习（RL）结合，训练运动跟踪 RL 专家策略，并将其提炼到一个单一的、基于深度感知、多技能的学生策略中。

Result: 该框架允许机器人仅通过板载深度传感和离散二维速度指令，自主选择并执行跨越、攀爬、飞跃或翻滚等动作，以应对不同几何形状和高度的障碍物。在 Unitree G1 型号机器人上的真实世界实验中，展示了高达 1.25 米（96% 机器人高度）的攀爬能力，以及对实时障碍物扰动的闭环适应性。

Conclusion: PHP 框架成功地结合了感知和技能组合，使人形机器人能够在复杂环境中执行长时程、视觉驱动的跑酷动作，并能够根据实时感知信息做出自主的、情境感知的决策。

Abstract: While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In particular, agile parkour in complex environments demands not only low-level robustness, but also human-like motion expressiveness, long-horizon skill composition, and perception-driven decision-making. In this paper, we present Perceptive Humanoid Parkour (PHP), a modular framework that enables humanoid robots to autonomously perform long-horizon, vision-based parkour across challenging obstacle courses. Our approach first leverages motion matching, formulated as nearest-neighbor search in a feature space, to compose retargeted atomic human skills into long-horizon kinematic trajectories. This framework enables the flexible composition and smooth transition of complex skill chains while preserving the elegance and fluidity of dynamic human motions. Next, we train motion-tracking reinforcement learning (RL) expert policies for these composed motions, and distill them into a single depth-based, multi-skill student policy, using a combination of DAgger and RL. Crucially, the combination of perception and skill composition enables autonomous, context-aware decision-making: using only onboard depth sensing and a discrete 2D velocity command, the robot selects and executes whether to step over, climb onto, vault or roll off obstacles of varying geometries and heights. We validate our framework with extensive real-world experiments on a Unitree G1 humanoid robot, demonstrating highly dynamic parkour skills such as climbing tall obstacles up to 1.25m (96% robot height), as well as long-horizon multi-obstacle traversal with closed-loop adaptation to real-time obstacle perturbations.

</details>


### [118] [SEG-JPEG: Simple Visual Semantic Communications for Remote Operation of Automated Vehicles over Unreliable Wireless Networks](https://arxiv.org/abs/2602.15258)
*Sebastian Donnelly,Ruth Anderson,George Economides,James Broughton,Peter Ball,Alexander Rast,Andrew Bradley*

Main category: cs.RO

TL;DR: 该研究提出了一种利用计算机视觉辅助的语义通信方法，通过在低分辨率灰度图像中编码分割信息来减少远程操作自动驾驶汽车所需的数据速率。该方法将数据速率降低了 50%，并实现了低于 500kbit/s 网络速率下的 200ms 平均延迟，同时提高了远程操作员的态势感知能力。这为在公共 4G/5G 网络上大规模部署远程操作的自动驾驶汽车提供了可能性。


<details>
  <summary>Details</summary>
Motivation: 当前远程操作自动驾驶汽车依赖的图像流传输方式需要高带宽和稳定的网络连接，这在依赖公共网络基础设施的实际部署中是一个限制。研究旨在克服数据丢失和损坏问题，并降低对网络的要求。

Method: 该方法将计算机视觉技术与语义通信相结合。具体来说，它对检测到的道路使用者进行分割，并将分割信息编码为低分辨率灰度图像中的彩色高亮显示。这种方式可以在不牺牲视觉清晰度的前提下，显著降低数据速率。

Result: 与传统图像压缩技术相比，该方法将所需数据速率降低了 50%。在网络数据速率低于 500kbit/s 时，实现了低于 200ms 的平均端到端延迟。实验结果表明，该技术在 4G 网络连接不稳定的区域，仍能清晰地勾勒出重要的道路使用者，增强了远程操作员的态势感知能力。

Conclusion: 计算机视觉辅助的语义通信方法能够有效地降低远程操作自动驾驶汽车所需的数据速率和延迟，即使在受限的公共 4G/5G 移动网络上也能实现。这为加速自动驾驶汽车的全国性推广提供了潜在的解决方案。

Abstract: Remote Operation is touted as being key to the rapid deployment of automated vehicles. Streaming imagery to control connected vehicles remotely currently requires a reliable, high throughput network connection, which can be limited in real-world remote operation deployments relying on public network infrastructure. This paper investigates how the application of computer vision assisted semantic communication can be used to circumvent data loss and corruption associated with traditional image compression techniques. By encoding the segmentations of detected road users into colour coded highlights within low resolution greyscale imagery, the required data rate can be reduced by 50 \% compared with conventional techniques, while maintaining visual clarity. This enables a median glass-to-glass latency of below 200ms even when the network data rate is below 500kbit/s, while clearly outlining salient road users to enhance situational awareness of the remote operator. The approach is demonstrated in an area of variable 4G mobile connectivity using an automated last-mile delivery vehicle. With this technique, the results indicate that large-scale deployment of remotely operated automated vehicles could be possible even on the often constrained public 4G/5G mobile network, providing the potential to expedite the nationwide roll-out of automated vehicles.

</details>


### [119] [OSCAR: An Ovipositor-Inspired Self-Propelling Capsule Robot for Colonoscopy](https://arxiv.org/abs/2602.15309)
*Mostafa A. Atalla,Anand S. Sekar,Remi van Starkenburg,David J. Jager,Aimée Sakes,Michaël Wiertlewski,Paul Breedveld*

Main category: cs.RO

TL;DR: 本文提出了一种受产卵器启发的自推进胶囊机器人OSCAR，通过机械编码的运动模式在结肠内产生可控的摩擦各向异性，实现稳定前进，实验验证了其推力能力和速度，有望用于机器人胶囊结肠镜检查。


<details>
  <summary>Details</summary>
Motivation: 传统的结肠镜检查存在患者不适的问题，而现有的自推进胶囊机器人在结肠的粘滑环境中移动仍面临挑战。研究旨在开发一种更可靠的自推进胶囊机器人。

Method: OSCAR模拟了产卵器的运动方式，通过弹簧加载的凸轮系统驱动十二个圆周滑块进行协调的、相位偏移的顺序运动。通过调整运动模式，最大化退程相位相对于进程相位的时间，从而在滑块与组织界面产生摩擦各向异性，实现净前进推力。研究人员开发了一个包含Kelvin-Voigt模型的分析模型，用于描述滑块与组织之间的粘弹性滑动相互作用，并将相位不对称性与平均推力、滑块反转同步性与推力稳定性联系起来。

Result: 在离体猪结肠的力学表征实验中，OSCAR产生了0.85 N的平均稳态牵引力，与模型预测结果吻合。实验证实推力生成与速度无关，并随相位不对称性呈线性增长。在运动验证实验中，OSCAR实现了3.08 mm/s的平均速度，足以达到常规结肠镜检查的盲肠插管时间。

Conclusion: 通过将相位编码的摩擦各向异性与预测模型相结合，OSCAR能够在低法向载荷下产生可控的推力，为机器人胶囊结肠镜检查提供了更安全、更稳健的自推进运动方式。

Abstract: Self-propelling robotic capsules eliminate shaft looping of conventional colonoscopy, reducing patient discomfort. However, reliably moving within the slippery, viscoelastic environment of the colon remains a significant challenge. We present OSCAR, an ovipositor-inspired self-propelling capsule robot that translates the transport strategy of parasitic wasps into a propulsion mechanism for colonoscopy. OSCAR mechanically encodes the ovipositor-inspired motion pattern through a spring-loaded cam system that drives twelve circumferential sliders in a coordinated, phase-shifted sequence. By tuning the motion profile to maximize the retract phase relative to the advance phase, the capsule creates a controlled friction anisotropy at the interface that generates net forward thrust. We developed an analytical model incorporating a Kelvin-Voigt formulation to capture the viscoelastic stick--slip interactions between the sliders and the tissue, linking the asymmetry between advance and retract phase durations to mean thrust, and slider-reversal synchronization to thrust stability. Comprehensive force characterization experiments in ex-vivo porcine colon revealed a mean steady-state traction force of 0.85 N, closely matching the model. Furthermore, experiments confirmed that thrust generation is speed-independent and scales linearly with the phase asymmetry, in agreement with theoretical predictions, underscoring the capsule's predictable performance and scalability. In locomotion validation experiments, OSCAR demonstrated robust performance, achieving an average speed of 3.08 mm/s, a velocity sufficient to match the cecal intubation times of conventional colonoscopy. By coupling phase-encoded friction anisotropy with a predictive model, OSCAR delivers controllable thrust generation at low normal loads, enabling safer and more robust self-propelling locomotion for robotic capsule colonoscopy.

</details>


### [120] [Feasibility-aware Imitation Learning from Observation with Multimodal Feedback](https://arxiv.org/abs/2602.15351)
*Kei Takahashi,Hikaru Sasaki,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 提出了一种名为FABCO的模仿学习框架，通过考虑机器人动力学模型来评估并增强演示动作的可行性，从而提高机器人控制策略的学习效果，实验证明其性能提升超过3.2倍。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习框架在从演示者动作学习机器人控制策略时，面临演示数据缺乏机器人动作信息以及演示动作对机器人可能不可行的两大限制，导致策略学习困难。

Method: FABCO整合了基于观察的行为克隆（补全机器人动作）和可行性估计。可行性估计使用机器人动力学模型评估演示动作的可重复性。估计的可行性用于多模态反馈（改善演示动作）和可行性感知策略学习（减弱不可行动作的影响），以学习稳定可执行的策略。

Result: 在15名参与者进行的两个任务实验中，FABCO相比于没有可行性反馈的方法，模仿学习性能提高了3.2倍以上。

Conclusion: FABCO通过引入可行性估计和多模态反馈，有效解决了模仿学习中演示动作与机器人能力不匹配的问题，显著提高了机器人策略学习的鲁棒性和执行能力。

Abstract: Imitation learning frameworks that learn robot control policies from demonstrators' motions via hand-mounted demonstration interfaces have attracted increasing attention. However, due to differences in physical characteristics between demonstrators and robots, this approach faces two limitations: i) the demonstration data do not include robot actions, and ii) the demonstrated motions may be infeasible for robots. These limitations make policy learning difficult. To address them, we propose Feasibility-Aware Behavior Cloning from Observation (FABCO). FABCO integrates behavior cloning from observation, which complements robot actions using robot dynamics models, with feasibility estimation. In feasibility estimation, the demonstrated motions are evaluated using a robot-dynamics model, learned from the robot's execution data, to assess reproducibility under the robot's dynamics. The estimated feasibility is used for multimodal feedback and feasibility-aware policy learning to improve the demonstrator's motions and learn robust policies. Multimodal feedback provides feasibility through the demonstrator's visual and haptic senses to promote feasible demonstrated motions. Feasibility-aware policy learning reduces the influence of demonstrated motions that are infeasible for robots, enabling the learning of policies that robots can execute stably. We conducted experiments with 15 participants on two tasks and confirmed that FABCO improves imitation learning performance by more than 3.2 times compared to the case without feasibility feedback.

</details>


### [121] [Fluoroscopy-Constrained Magnetic Robot Control via Zernike-Based Field Modeling and Nonlinear MPC](https://arxiv.org/abs/2602.15357)
*Xinhao Chen,Hongkun Yao,Anuruddha Bhattacharjee,Suraj Raval,Lamar O. Mair,Yancy Diaz-Mercado,Axel Krieger*

Main category: cs.RO

TL;DR: 本文提出了一种结合非线性模型预测控制（NMPC）、Zernike多项式磁场模型和卡尔曼滤波的控制框架，用于在低帧率、有噪声的荧光成像条件下精确控制磁驱动手术机器人。


<details>
  <summary>Details</summary>
Motivation: 临床部署磁驱动手术机器人受到荧光成像提供的低帧率和有噪声的姿态反馈的限制，这阻碍了其在复杂解剖结构中的精确控制。

Method: 采用一种结合了NMPC、基于Zernike多项式的磁场模型以及卡尔曼滤波的控制框架。NMPC直接输出线圈电流，磁场模型可解析微分，卡尔曼滤波器用于估计机器人状态。

Result: 该控制方法在反馈降采样至3 Hz并加入2 mm标准差的高斯噪声时，仍能保持高精度。在脊柱模型实验中，成功执行了药物输送轨迹，位置均方根误差（RMS）为1.18 mm，并保持了与关键解剖边界的安全距离。

Conclusion: 所提出的控制框架能够有效克服临床荧光成像条件的限制，实现高精度、稳定的磁驱动手术机器人控制，并成功应用于模拟的药物输送任务。

Abstract: Magnetic actuation enables surgical robots to navigate complex anatomical pathways while reducing tissue trauma and improving surgical precision. However, clinical deployment is limited by the challenges of controlling such systems under fluoroscopic imaging, which provides low frame rate and noisy pose feedback. This paper presents a control framework that remains accurate and stable under such conditions by combining a nonlinear model predictive control (NMPC) framework that directly outputs coil currents, an analytically differentiable magnetic field model based on Zernike polynomials, and a Kalman filter to estimate the robot state. Experimental validation is conducted with two magnetic robots in a 3D-printed fluid workspace and a spine phantom replicating drug delivery in the epidural space. Results show the proposed control method remains highly accurate when feedback is downsampled to 3 Hz with added Gaussian noise (sigma = 2 mm), mimicking clinical fluoroscopy. In the spine phantom experiments, the proposed method successfully executed a drug delivery trajectory with a root mean square (RMS) position error of 1.18 mm while maintaining safe clearance from critical anatomical boundaries.

</details>


### [122] [ActionCodec: What Makes for Good Action Tokenizers](https://arxiv.org/abs/2602.15397)
*Zibin Dong,Yicheng Liu,Shiduo Zhang,Baijun Ye,Yifu Yuan,Fei Ni,Jingjing Gong,Xipeng Qiu,Hang Zhao,Yinchuan Li,Jianye Hao*

Main category: cs.RO

TL;DR: 本文提出了一种名为ActionCodec的高性能动作分词器，该分词器遵循信息论原则，旨在优化Vision-Language-Action (VLA)模型的训练效率和性能，并在多个基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要关注动作分词的重建保真度，忽视了其对VLA模型优化的直接影响，因此“什么是好的动作分词器”这一核心问题仍未得到解答。

Method: 通过信息论洞察，提出动作分词器的设计原则，包括最大化时间标记重叠、最小化词汇冗余、增强多模态互信息和标记独立性。基于这些原则，设计并引入了ActionCodec动作分词器。

Result: ActionCodec显著提高了VLA模型的训练效率和性能。在LIBERO基准测试中，使用ActionCodec微调的SmolVLM2-2.2B模型成功率达到95.5%，经过架构增强后更是达到97.4%，创下了无机器人预训练的VLA模型的新SOTA。

Conclusion: 本文提出的设计原则和ActionCodec模型为社区开发更有效的动作分词器提供了清晰的指导，并证明了其在提升VLA模型性能方面的有效性。

Abstract: Vision-Language-Action (VLA) models leveraging the native autoregressive paradigm of Vision-Language Models (VLMs) have demonstrated superior instruction-following and training efficiency. Central to this paradigm is action tokenization, yet its design has primarily focused on reconstruction fidelity, failing to address its direct impact on VLA optimization. Consequently, the fundamental question of \textit{what makes for good action tokenizers} remains unanswered. In this paper, we bridge this gap by establishing design principles specifically from the perspective of VLA optimization. We identify a set of best practices based on information-theoretic insights, including maximized temporal token overlap, minimized vocabulary redundancy, enhanced multimodal mutual information, and token independence. Guided by these principles, we introduce \textbf{ActionCodec}, a high-performance action tokenizer that significantly enhances both training efficiency and VLA performance across diverse simulation and real-world benchmarks. Notably, on LIBERO, a SmolVLM2-2.2B fine-tuned with ActionCodec achieves a 95.5\% success rate without any robotics pre-training. With advanced architectural enhancements, this reaches 97.4\%, representing a new SOTA for VLA models without robotics pre-training. We believe our established design principles, alongside the released model, will provide a clear roadmap for the community to develop more effective action tokenizers.

</details>


### [123] [Hybrid F' and ROS2 Architecture for Vision-Based Autonomous Flight: Design and Experimental Validation](https://arxiv.org/abs/2602.15398)
*Abdelrahman Metwally,Monijesu James,Aleksey Fedoseev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou,Andrey Somov*

Main category: cs.RO

TL;DR: 该研究提出了一种集成了NASA的F'飞行软件框架和ROS2中间件的混合系统，并通过室内四旋翼飞行测试验证了其在实时控制和感知能力上的有效性。


<details>
  <summary>Details</summary>
Motivation: 自主航空航天系统需要平衡确定性实时控制和先进感知能力，现有架构需要进一步优化。

Method: 通过Protocol Buffers桥接技术，将NASA的F'飞行软件框架与ROS2中间件集成，并在室内四旋翼飞行测试中进行了评估，测试内容包括视觉导航、指令执行和系统资源利用率。

Result: 视觉导航实现了87.19 Hz的定位估计，数据连续性达99.90%，平均延迟11.47 ms。15条地面指令全部成功执行，成功率100%。系统资源利用率低（CPU 15.19%，RAM 1,244 MB），无过时遥测消息。

Conclusion: 所提出的结合了认证级确定性和灵活自主性的混合飞行软件架构，对于自主飞行器是可行且高效的。

Abstract: Autonomous aerospace systems require architectures that balance deterministic real-time control with advanced perception capabilities. This paper presents an integrated system combining NASA's F' flight software framework with ROS2 middleware via Protocol Buffers bridging. We evaluate the architecture through a 32.25-minute indoor quadrotor flight test using vision-based navigation. The vision system achieved 87.19 Hz position estimation with 99.90\% data continuity and 11.47 ms mean latency, validating real-time performance requirements. All 15 ground commands executed successfully with 100 % success rate, demonstrating robust F'--PX4 integration. System resource utilization remained low (15.19 % CPU, 1,244 MB RAM) with zero stale telemetry messages, confirming efficient operation on embedded platforms. Results validate the feasibility of hybrid flight-software architectures combining certification-grade determinism with flexible autonomy for autonomous aerial vehicles.

</details>


### [124] [One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation](https://arxiv.org/abs/2602.15400)
*Zerui Li,Hongpei Zheng,Fangguo Zhao,Aidan Chan,Jian Zhou,Sihao Lin,Shijie Li,Qi Wu*

Main category: cs.RO

TL;DR: 提出了一种解耦设计，将低级空间状态估计与高级语义规划分开，并引入交互式度量世界表示和反事实推理，以提高导航代理的性能，并在模拟和真实世界环境中取得了最先进的零样本结果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于多模态大语言模型（MLLMs）的导航代理设计耦合过于紧密，限制了系统性能。需要一种能够同时理解语义指令和空间感知的导航方法。

Method: 提出一种解耦设计，将低级空间状态估计与高级语义规划分开。引入交互式度量世界表示，以代替简化的文本地图，使MLLMs能够进行交互和推理。引入反事实推理以进一步激发MLLMs的能力，同时度量世界表示保证了所生成动作的物理有效性。

Result: 在R2R-CE和RxR-CE基准测试中，在零样本设置下取得了最先进的性能（SR分别为48.8%和42.2%）。展示了该方法在TurtleBot 4和自定义无人机上的零样本跨域迁移能力。

Conclusion: 解耦框架提供了一个鲁棒的、域不变的接口，可用于具身视觉-语言导航，并且在模拟和真实世界环境中均表现出色。

Abstract: A navigable agent needs to understand both high-level semantic instructions and precise spatial perceptions. Building navigation agents centered on Multimodal Large Language Models (MLLMs) demonstrates a promising solution due to their powerful generalization ability. However, the current tightly coupled design dramatically limits system performance. In this work, we propose a decoupled design that separates low-level spatial state estimation from high-level semantic planning. Unlike previous methods that rely on predefined, oversimplified textual maps, we introduce an interactive metric world representation that maintains rich and consistent information, allowing MLLMs to interact with and reason on it for decision-making. Furthermore, counterfactual reasoning is introduced to further elicit MLLMs' capacity, while the metric world representation ensures the physical validity of the produced actions. We conduct comprehensive experiments in both simulated and real-world environments. Our method establishes a new zero-shot state-of-the-art, achieving 48.8\% Success Rate (SR) in R2R-CE and 42.2\% in RxR-CE benchmarks. Furthermore, to validate the versatility of our metric representation, we demonstrate zero-shot sim-to-real transfer across diverse embodiments, including a wheeled TurtleBot 4 and a custom-built aerial drone. These real-world deployments verify that our decoupled framework serves as a robust, domain-invariant interface for embodied Vision-and-Language navigation.

</details>


### [125] [Lyapunov-Based $\mathcal{L}_2$-Stable PI-Like Control of a Four-Wheel Independently Driven and Steered Robot](https://arxiv.org/abs/2602.15424)
*Branimir Ćaran,Vladimir Milić,Bojan Jerbić*

Main category: cs.RO

TL;DR: 本文提出了一种基于李雅普诺夫的PI类控制器合成方法，用于四轮独立驱动转向移动机器人的L2稳定运动控制。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为独立驱动和转向的四轮移动机器人提供一种具有稳定性和性能保证的运动控制方法，该方法适用于实时操作，并能减轻配置依赖性效应。

Method: 本文使用一个显式的、结构验证的模型，通过构造李雅普诺夫函数来合成PI类控制器。该方法通过推导显式界限和L2稳定性结果来支持反馈合成。

Result: 合成的控制律保持PI类形式，适用于标准嵌入式实现，并保持严格的稳定性特性。实验证明了该方法在真实四轮移动机器人平台上的有效性和鲁棒性。

Conclusion: 基于李雅普诺夫合成的PI类控制器能够实现四轮独立驱动转向移动机器人的L2稳定运动控制，该控制器形式简洁且具有严格的稳定性保证，并通过实验验证了其有效性和鲁棒性。

Abstract: In this letter, Lyapunov-based synthesis of a PI-like controller is proposed for $\mathcal{L}_2$-stable motion control of an independently driven and steered four-wheel mobile robot. An explicit, structurally verified model is used to enable systematic controller design with stability and performance guarantees suitable for real-time operation. A Lyapunov function is constructed to yield explicit bounds and $\mathcal{L}_2$ stability results, supporting feedback synthesis that reduces configuration dependent effects. The resulting control law maintains a PI-like form suitable for standard embedded implementation while preserving rigorous stability properties. Effectiveness and robustness are demonstrated experimentally on a real four-wheel mobile robot platform.

</details>


### [126] [Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling](https://arxiv.org/abs/2602.15513)
*Ji Li,Jing Xia,Mingyi Li,Shiyan Hu*

Main category: cs.RO

TL;DR: 提出了一种新的非参数化记忆框架，通过分离情景记忆和语义记忆，解决了具身智能体在长距离观察和有限上下文预算下的挑战，实现了更优的探索和问答能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于文本摘要的记忆方法会丢失视觉和空间细节，并且在非稳态环境中表现脆弱，难以支持具身智能体进行长距离观察和问答。

Method: 该工作提出了一个非参数化记忆框架，显式解耦情景记忆和语义记忆。采用“检索优先，推理辅助”的范式，通过语义相似性检索情景经验，并通过视觉推理进行验证，避免了对严格几何对齐的依赖。同时，引入了程序式规则提取机制，将经验转化为结构化的语义记忆，以实现跨环境泛化。

Result: 在具身问答和探索基准测试中取得了最先进的性能。在A-EQA上LLM-Match提升7.3%，LLM MatchXSPL提升11.4%；在GOAT-Bench上成功率提升7.7%，SPL提升6.8%。

Conclusion: 该框架通过情景记忆提高了探索效率，通过语义记忆增强了复杂推理能力，有效解决了具身智能体在长距离观察和有限上下文预算下的挑战。

Abstract: Deploying Multimodal Large Language Models as the brain of embodied agents remains challenging, particularly under long-horizon observations and limited context budgets. Existing memory assisted methods often rely on textual summaries, which discard rich visual and spatial details and remain brittle in non-stationary environments. In this work, we propose a non-parametric memory framework that explicitly disentangles episodic and semantic memory for embodied exploration and question answering. Our retrieval-first, reasoning-assisted paradigm recalls episodic experiences via semantic similarity and verifies them through visual reasoning, enabling robust reuse of past observations without rigid geometric alignment. In parallel, we introduce a program-style rule extraction mechanism that converts experiences into structured, reusable semantic memory, facilitating cross-environment generalization. Extensive experiments demonstrate state-of-the-art performance on embodied question answering and exploration benchmarks, yielding a 7.3% gain in LLM-Match and an 11.4% gain in LLM MatchXSPL on A-EQA, as well as +7.7% success rate and +6.8% SPL on GOAT-Bench. Analyses reveal that our episodic memory primarily improves exploration efficiency, while semantic memory strengthens complex reasoning of embodied agents.

</details>


### [127] [Efficient Knowledge Transfer for Jump-Starting Control Policy Learning of Multirotors through Physics-Aware Neural Architectures](https://arxiv.org/abs/2602.15533)
*Welf Rehberg,Mihir Kulkarni,Philipp Weiss,Kostas Alexis*

Main category: cs.RO

TL;DR: 该研究提出了一种基于库的初始化方案，利用物理感知的神经控制架构，通过策略评估相似度度量，实现跨多旋翼配置的知识有效迁移，显著减少策略训练所需的环境交互次数。


<details>
  <summary>Details</summary>
Motivation: 在机器人控制策略的训练中，如何利用从类似系统训练中获得的知识进行跨模型知识迁移，以提高训练效率，是一个重大挑战。

Method: 该研究采用了结合强化学习控制器和监督控制分配网络的物理感知的神经控制架构。通过策略评估相似度度量来识别库中适合初始化的策略，并利用该策略库进行初始化训练。

Result: 该研究提出的初始化方案平均可节省高达 73.5% 的环境交互次数。实验证实，该控制架构在模拟和现实世界中均达到了最先进的控制性能。

Conclusion: 该研究提出的基于库的初始化方案能有效加速策略训练，并且在跨多旋翼配置的知识迁移中表现出色，为强化学习中的高效跨模型迁移提供了途径。

Abstract: Efficiently training control policies for robots is a major challenge that can greatly benefit from utilizing knowledge gained from training similar systems through cross-embodiment knowledge transfer. In this work, we focus on accelerating policy training using a library-based initialization scheme that enables effective knowledge transfer across multirotor configurations. By leveraging a physics-aware neural control architecture that combines a reinforcement learning-based controller and a supervised control allocation network, we enable the reuse of previously trained policies. To this end, we utilize a policy evaluation-based similarity measure that identifies suitable policies for initialization from a library. We demonstrate that this measure correlates with the reduction in environment interactions needed to reach target performance and is therefore suited for initialization. Extensive simulation and real-world experiments confirm that our control architecture achieves state-of-the-art control performance, and that our initialization scheme saves on average up to $73.5\%$ of environment interactions (compared to training a policy from scratch) across diverse quadrotor and hexarotor designs, paving the way for efficient cross-embodiment transfer in reinforcement learning.

</details>


### [128] [Selective Perception for Robot: Task-Aware Attention in Multimodal VLA](https://arxiv.org/abs/2602.15543)
*Young-Chae Son,Jung-Woo Lee,Yoon-Ji Choi,Dae-Kwan Ko,Soo-Chul Lim*

Main category: cs.RO

TL;DR: 提出了一种动态信息融合框架，通过轻量级自适应路由架构，根据任务相关性动态调整视觉输入处理，提高了机器人VLA模型的效率和性能，并利用VLM自动标注训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型采用静态融合方式，计算开销大且易受背景噪声干扰，启发于人类主动感知原理，旨在提高VLA模型的效率和鲁棒性。

Method: 提出一个轻量级自适应路由架构，实时分析文本提示和腕部相机观测，预测多视图的潜在任务相关性，并根据相关性动态调整计算量，只向策略网络提供关键视觉特征。同时，建立了一个利用VLM的自动化标注流水线来训练路由模型。

Result: 在真实的机器人操作场景中，该框架在推理效率和控制性能上均显著优于现有VLA模型。

Conclusion: 动态信息融合方法在资源受限的实时机器人控制环境中是有效且实用的，能够显著提升VLA模型的性能和效率。

Abstract: In robotics, Vision-Language-Action (VLA) models that integrate diverse multimodal signals from multi-view inputs have emerged as an effective approach. However, most prior work adopts static fusion that processes all visual inputs uniformly, which incurs unnecessary computational overhead and allows task-irrelevant background information to act as noise. Inspired by the principles of human active perception, we propose a dynamic information fusion framework designed to maximize the efficiency and robustness of VLA models. Our approach introduces a lightweight adaptive routing architecture that analyzes the current text prompt and observations from a wrist-mounted camera in real-time to predict the task-relevance of multiple camera views. By conditionally attenuating computations for views with low informational utility and selectively providing only essential visual features to the policy network, Our framework achieves computation efficiency proportional to task relevance. Furthermore, to efficiently secure large-scale annotation data for router training, we established an automated labeling pipeline utilizing Vision-Language Models (VLMs) to minimize data collection and annotation costs. Experimental results in real-world robotic manipulation scenarios demonstrate that the proposed approach achieves significant improvements in both inference efficiency and control performance compared to existing VLA models, validating the effectiveness and practicality of dynamic information fusion in resource-constrained, real-time robot control environments.

</details>


### [129] [VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing](https://arxiv.org/abs/2602.15549)
*Guoqin Tang,Qingxuan Jia,Gang Chen,Tong Li,Zeyuan Huang,Zihang Lv,Ning Ji*

Main category: cs.RO

TL;DR: 本文提出了一种名为VLM-DEWM的认知架构，通过引入外部世界模型（DEWM）和可外部化推理轨迹（ERT），解决了现有视觉语言模型（VLM）在动态制造场景下无法持续跟踪状态和推理过程不透明的问题，显著提升了状态跟踪精度和故障恢复成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在智能制造的高层规划方面展现出潜力，但在动态工作单元的部署中面临两大挑战：1) 无状态操作导致世界状态漂移；2) 推理过程不透明导致故障难以诊断和昂贵的盲目重试。

Method: 提出VLM-DEWM认知架构，将VLM推理与世界状态管理分离，引入持久化、可查询的动态外部世界模型（DEWM）。每个VLM决策结构化为外部化推理轨迹（ERT），包含动作建议、世界信念和因果假设，并在执行前通过DEWM进行验证。故障发生时，通过比较预测状态和观测状态的差异来进行有针对性的恢复，而非全局重规划。

Result: 在多站装配、大型设施探索和真实机器人故障恢复实验中，与基线VLM系统相比，VLM-DEWM将状态跟踪准确率从56%提高到93%，恢复成功率从低于5%提高到95%，并显著降低了计算开销。这表明VLM-DEWM是一种可验证且具韧性的解决方案。

Conclusion: VLM-DEWM通过引入外部世界模型和结构化的推理过程，有效地解决了VLM在动态制造环境中部署时的状态跟踪和故障诊断难题，为实现长期机器人操作提供了可靠的解决方案。

Abstract: Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque reasoning, failures are difficult to diagnose, leading to costly blind retries. This paper presents VLM-DEWM, a cognitive architecture that decouples VLM reasoning from world-state management through a persistent, queryable Dynamic External World Model (DEWM). Each VLM decision is structured into an Externalizable Reasoning Trace (ERT), comprising action proposal, world belief, and causal assumption, which is validated against DEWM before execution. When failures occur, discrepancy analysis between predicted and observed states enables targeted recovery instead of global replanning. We evaluate VLM-DEWM on multi-station assembly, large-scale facility exploration, and real-robot recovery under induced failures. Compared to baseline memory-augmented VLM systems, VLM DEWM improves state-tracking accuracy from 56% to 93%, increases recovery success rate from below 5% to 95%, and significantly reduces computational overhead through structured memory. These results establish VLM-DEWM as a verifiable and resilient solution for long-horizon robotic operations in dynamic manufacturing environments.

</details>


### [130] [Constraining Streaming Flow Models for Adapting Learned Robot Trajectory Distributions](https://arxiv.org/abs/2602.15567)
*Jieting Long,Dechuan Liu,Weidong Cai,Ian Manchester,Weiming Zhi*

Main category: cs.RO

TL;DR: 提出了一种名为CASF的框架，用于在执行时实时调整流策略（SFP）机器人的轨迹，以满足安全和任务特定约束。


<details>
  <summary>Details</summary>
Motivation: 现有的流策略（SFP）在训练后缺乏调整轨迹以强制执行安全和任务特定约束的机制，这限制了其在实际应用中的灵活性。

Method: CASF通过引入约束依赖度量来增强流策略。这些度量由可微分距离函数定义，这些距离函数将约束（在工作空间或配置空间中）转换为局部度量，并拉回到机器人的控制空间。这允许在执行时实时变形速度场，以确保安全。

Result: CASF在模拟和真实世界的操纵任务中展示了其有效性，生成了满足约束的平滑、可行且动态一致的轨迹，优于标准的后验投影方法。

Conclusion: CASF提供了一种有效的方法，可以在执行时实时调整流策略的轨迹，以满足各种约束，同时保留了流策略的固有多模态和反应性特性。

Abstract: Robot motion distributions often exhibit multi-modality and require flexible generative models for accurate representation. Streaming Flow Policies (SFPs) have recently emerged as a powerful paradigm for generating robot trajectories by integrating learned velocity fields directly in action space, enabling smooth and reactive control. However, existing formulations lack mechanisms for adapting trajectories post-training to enforce safety and task-specific constraints. We propose Constraint-Aware Streaming Flow (CASF), a framework that augments streaming flow policies with constraint-dependent metrics that reshape the learned velocity field during execution. CASF models each constraint, defined in either the robot's workspace or configuration space, as a differentiable distance function that is converted into a local metric and pulled back into the robot's control space. Far from restricted regions, the resulting metric reduces to the identity; near constraint boundaries, it smoothly attenuates or redirects motion, effectively deforming the underlying flow to maintain safety. This allows trajectories to be adapted in real time, ensuring that robot actions respect joint limits, avoid collisions, and remain within feasible workspaces, while preserving the multi-modal and reactive properties of streaming flow policies. We demonstrate CASF in simulated and real-world manipulation tasks, showing that it produces constraint-satisfying trajectories that remain smooth, feasible, and dynamically consistent, outperforming standard post-hoc projection baselines.

</details>


### [131] [SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms](https://arxiv.org/abs/2602.15633)
*Haichao Liu,Yufeng Hu,Shuang Wang,Kangjun Guo,Jun Ma,Jinni Zhou*

Main category: cs.RO

TL;DR: 本文提出了一种名为SpecFuse的谱-时域融合预测控制框架，用于在动态海况下实现无人机在海洋平台上的自主着陆。该框架结合了波浪谱分析和递归状态估计，以提高运动预测精度，并通过分层控制架构实现动态轨迹规划和基于学习的扰动补偿，在模拟和真实实验中均表现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有无人机在波浪起伏的海洋平台上自主着陆的方法，由于未能充分考虑波浪的多频特性、风扰动和预测相位滞后，导致在动态海况下性能不佳。本文旨在解决这些局限性，实现高精度的平台运动预测和可靠的着陆。

Method: 提出SpecFuse框架，该框架通过以下方式工作：1. 频率域波浪分解与时间域递归状态估计相结合，实现无人水面载具（USV）的6-DoF运动精确预测。2. 显式建模主导波浪谐波以减小相位滞后，并通过IMU数据实时优化预测。3. 设计分层控制架构，包括用于动态轨迹规划的HPO-RRT*算法和用于数据驱动扰动补偿与优化执行的学习增强预测控制器。

Result: 在2000次模拟和8次湖上实验验证中，SpecFuse实现了3.2 cm的预测误差，4.46 cm的着陆偏差，98.7%（模拟）/87.5%（真实）的成功率，以及82 ms的嵌入式硬件延迟。与现有技术相比，精度提高了44%-48%。

Conclusion: SpecFuse框架能够有效地处理波浪-风耦合扰动，显著提高了无人机在海洋平台自主着陆的精度和成功率，为搜索救援和环境监测等关键海事任务提供了支持。研究成果（代码、配置和数据集）将开源以促进可重复性研究。

Abstract: Autonomous landing of Uncrewed Aerial Vehicles (UAVs) on oscillating marine platforms is severely constrained by wave-induced multi-frequency oscillations, wind disturbances, and prediction phase lags in motion prediction. Existing methods either treat platform motion as a general random process or lack explicit modeling of wave spectral characteristics, leading to suboptimal performance under dynamic sea conditions. To address these limitations, we propose SpecFuse: a novel spectral-temporal fusion predictive control framework that integrates frequency-domain wave decomposition with time-domain recursive state estimation for high-precision 6-DoF motion forecasting of Uncrewed Surface Vehicles (USVs). The framework explicitly models dominant wave harmonics to mitigate phase lags, refining predictions in real time via IMU data without relying on complex calibration. Additionally, we design a hierarchical control architecture featuring a sampling-based HPO-RRT* algorithm for dynamic trajectory planning under non-convex constraints and a learning-augmented predictive controller that fuses data-driven disturbance compensation with optimization-based execution. Extensive validations (2,000 simulations + 8 lake experiments) show our approach achieves a 3.2 cm prediction error, 4.46 cm landing deviation, 98.7% / 87.5% success rates (simulation / real-world), and 82 ms latency on embedded hardware, outperforming state-of-the-art methods by 44%-48% in accuracy. Its robustness to wave-wind coupling disturbances supports critical maritime missions such as search and rescue and environmental monitoring. All code, experimental configurations, and datasets will be released as open-source to facilitate reproducibility.

</details>


### [132] [Grip as Needed, Glide on Demand: Ultrasonic Lubrication for Robotic Locomotion](https://arxiv.org/abs/2602.15608)
*Mostafa A. Atalla,Daan van Bemmel,Jack Cummings,Paul Breedveld,Michaël Wiertlewski,Aimée Sakes*

Main category: cs.RO

TL;DR: 本研究提出了一种名为超声波润滑的主动摩擦控制方法，用于机器人运动。通过在超声波频率下激励共振结构，可以动态切换接触界面的“抓握”和“滑动”状态，从而实现运动。作者设计了两种摩擦控制模块，并将其集成到仿生机器人（如尺蠖和黄蜂产卵管）中，实现了高效的双向运动。


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统通常将摩擦视为一种被动的、固定的属性，这限制了其运动能力。本研究旨在探索一种主动控制摩擦的方法，以提高机器人运动的灵活性和效率。

Method: 研究人员开发了两种超声波润滑模块（圆柱形和扁平形），并通过在超声波频率下激励共振结构来实现动态摩擦控制。这些模块被集成到模仿尺蠖和黄蜂产卵管运动的生物启发式机器人中。

Result: 仿生机器人实现了接近100%的运动效率（超过90%）。超声波润滑在各种表面（包括刚性、软性、颗粒状和生物组织）上，在干湿条件下以及不同粗糙度下，都表现出显著的摩擦降低效果，证实了该技术的广泛适用性。

Conclusion: 超声波润滑是一种可行且高效的主动摩擦控制机制，有望简化机器人运动系统的设计，并提高其效率。该技术在多种表面和环境下都展现出良好的性能，预示着其在机器人运动领域的广泛应用前景。

Abstract: Friction is the essential mediator of terrestrial locomotion, yet in robotic systems it is almost always treated as a passive property fixed by surface materials and conditions. Here, we introduce ultrasonic lubrication as a method to actively control friction in robotic locomotion. By exciting resonant structures at ultrasonic frequencies, contact interfaces can dynamically switch between "grip" and "slip" states, enabling locomotion. We developed two friction control modules, a cylindrical design for lumen-like environments and a flat-plate design for external surfaces, and integrated them into bio-inspired systems modeled after inchworm and wasp ovipositor locomotion. Both systems achieved bidirectional locomotion with nearly perfect locomotion efficiencies that exceeded 90%. Friction characterization experiments further demonstrated substantial friction reduction across various surfaces, including rigid, soft, granular, and biological tissue interfaces, under dry and wet conditions, and on surfaces with different levels of roughness, confirming the broad applicability of ultrasonic lubrication to locomotion tasks. These findings establish ultrasonic lubrication as a viable active friction control mechanism for robotic locomotion, with the potential to reduce design complexity and improve efficiency of robotic locomotion systems.

</details>


### [133] [Spatially-Aware Adaptive Trajectory Optimization with Controller-Guided Feedback for Autonomous Racing](https://arxiv.org/abs/2602.15642)
*Alexander Wachter,Alexander Willert,Marc-Philip Ecker,Christian Hartl-Nesic*

Main category: cs.RO

TL;DR: 提出了一种闭环自动赛道优化框架，结合了NURBS轨迹表示、CMA-ES全局优化和空间反馈。通过将跟踪误差作为局部赛道特征的信号，该方法能够自适应地优化轨迹，并在模拟和真实硬件上实现了显著的圈速提升。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是开发一个能够自动优化赛车轨迹的框架，使其在不断变化的赛道和车辆行为下都能达到接近最优的性能，并提高赛车的圈速。

Method: 采用了一种闭环框架，结合了以下技术：1. NURBS（非均匀有理B样条）进行轨迹表示；2. CMA-ES（协方差矩阵自适应进化策略）进行全局轨迹优化；3. 基于控制器的空间反馈，将跟踪误差视为局部赛道特征的信号，通过卡尔曼滤波的思想进行空间更新；4. 构建了自适应的、基于加速度约束的地图，用于迭代优化轨迹。

Result: 在模拟环境中，与使用最大静态加速度参数化的控制器相比，该方法实现了17.38%的圈速缩减。在真实硬件测试中，即使使用了不同摩擦系数的轮胎，也能获得7.60%的圈速提升，且无需显式参数化摩擦力。

Conclusion: 该框架能够有效地利用跟踪误差信号来适应局部赛道和车辆行为的变化，从而实现赛道轨迹的自适应优化。在模拟和真实世界场景中均表现出鲁棒性，并能显著提升赛车性能。

Abstract: We present a closed-loop framework for autonomous raceline optimization that combines NURBS-based trajectory representation, CMA-ES global trajectory optimization, and controller-guided spatial feedback. Instead of treating tracking errors as transient disturbances, our method exploits them as informative signals of local track characteristics via a Kalman-inspired spatial update. This enables the construction of an adaptive, acceleration-based constraint map that iteratively refines trajectories toward near-optimal performance under spatially varying track and vehicle behavior. In simulation, our approach achieves a 17.38% lap time reduction compared to a controller parametrized with maximum static acceleration. On real hardware, tested with different tire compounds ranging from high to low friction, we obtain a 7.60% lap time improvement without explicitly parametrizing friction. This demonstrates robustness to changing grip conditions in real-world scenarios.

</details>


### [134] [Lifelong Scalable Multi-Agent Realistic Testbed and A Comprehensive Study on Design Choices in Lifelong AGV Fleet Management Systems](https://arxiv.org/abs/2602.15721)
*Jingtian Yan,Yulun Zhang,Zhenting Liu,Han Zhang,He Jiang,Jingkai Chen,Stephen F. Smith,Jiaoyang Li*

Main category: cs.RO

TL;DR: 本文提出并开源了一个名为 LSMART 的仿真器，用于在车队管理系统中评估多智能体路径寻找 (MAPF) 算法，特别是针对终身式 (lifelong) MAPF (LMAPF) 场景。


<details>
  <summary>Details</summary>
Motivation: 现有的 MAPF 和 LMAPF 研究通常使用简化的运动学模型和完美的执行/通信假设，这与真实的自动导引车 (AGV) 车队管理系统 (FMS) 的需求不符。SMART 仿真器虽然考虑了这些因素，但仅限于 MAPF，无法直接应用于 LMAPF。

Method: 提出 LSMART 仿真器，该仿真器在 FMS 中集成了 MAPF 算法评估。LSMART 解决了 FMS 中规划和执行并行化的问题（何时规划）、不同规划器选择的问题（如何规划）以及规划失败时的恢复问题（如何恢复）。通过对现有先进方法进行实验，评估了这些设计选择。

Result: 通过 LSMART 仿真器对不同的设计选择进行了实验，并提供了结果，为设计高效的终身式 AGV 车队管理系统提供了指导。

Conclusion: LSMART 是一个用于在 FMS 中评估 MAPF 算法（特别是 LMAPF）的开源仿真器，它解决了现有研究的局限性，并为设计实际的 AGV 车队管理系统提供了实证支持。

Abstract: We present Lifelong Scalable Multi-Agent Realistic Testbed (LSMART), an open-source simulator to evaluate any Multi-Agent Path Finding (MAPF) algorithm in a Fleet Management System (FMS) with Automated Guided Vehicles (AGVs). MAPF aims to move a group of agents from their corresponding starting locations to their goals. Lifelong MAPF (LMAPF) is a variant of MAPF that continuously assigns new goals for agents to reach. LMAPF applications, such as autonomous warehouses, often require a centralized, lifelong system to coordinate the movement of a fleet of robots, typically AGVs. However, existing works on MAPF and LMAPF often assume simplified kinodynamic models, such as pebble motion, as well as perfect execution and communication for AGVs. Prior work has presented SMART, a software capable of evaluating any MAPF algorithms while considering agent kinodynamics, communication delays, and execution uncertainties. However, SMART is designed for MAPF, not LMAPF. Generalizing SMART to an FMS requires many more design choices. First, an FMS parallelizes planning and execution, raising the question of when to plan. Second, given planners with varying optimality and differing agent-model assumptions, one must decide how to plan. Third, when the planner fails to return valid solutions, the system must determine how to recover. In this paper, we first present LSMART, an open-source simulator that incorporates all these considerations to evaluate any MAPF algorithms in an FMS. We then provide experiment results based on state-of-the-art methods for each design choice, offering guidance on how to effectively design centralized lifelong AGV Fleet Management Systems. LSMART is available at https://smart-mapf.github.io/lifelong-smart.

</details>


### [135] [MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction](https://arxiv.org/abs/2602.15733)
*Qiang Zhang,Jiahao Ma,Peiran Liu,Shuai Shi,Zeran Su,Zifan Wang,Jingkai Sun,Wei Cui,Jialin Yu,Gang Han,Wen Zhao,Pihai Sun,Kangning Yin,Jiaxu Wang,Jiahang Cao,Lingfeng Zhang,Hao Cheng,Xiaoshuai Hao,Yiding Ji,Junwei Liang,Jian Tang,Renjing Xu,Yijie Guo*

Main category: cs.RO

TL;DR: MeshMimic 是一个新框架，它结合了 3D 场景重建和强化学习，使人形机器人能够直接从视频中学习与地形的交互，从而克服了现有方法在动态场景中运动与环境耦合不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人运动控制方法严重依赖昂贵的动作捕捉数据，并且这些数据通常缺乏与物理环境相关的几何信息。这导致机器人学习到的运动与环境不匹配，在地形感知任务中出现物理不一致性，例如接触滑移或网格穿透。

Method: MeshMimic 框架首先利用先进的 3D 视觉模型来分割和重建人类运动轨迹以及地形和物体的 3D 几何结构。然后，通过基于运动学一致性的优化算法提取高质量的运动数据。最后，使用接触不变重定向方法将人类与环境的交互特征迁移到人形机器人上。

Result: 实验结果表明，MeshMimic 在各种具有挑战性的地形上实现了鲁棒且高度动态的性能。该框架使用消费级单目传感器即可实现复杂物理交互的训练，为人形机器人在非结构化环境中的自主进化提供了一条可扩展的途径。

Conclusion: MeshMimic 成功地实现了从视频中学习耦合的“运动-地形”交互，解决了现有方法在运动与环境耦合方面的不足。该方法通过低成本的视觉输入，为人形机器人在复杂环境中学习复杂的物理交互提供了有效且可扩展的解决方案。

Abstract: Humanoid motion control has witnessed significant breakthroughs in recent years, with deep reinforcement learning (RL) emerging as a primary catalyst for achieving complex, human-like behaviors. However, the high dimensionality and intricate dynamics of humanoid robots make manual motion design impractical, leading to a heavy reliance on expensive motion capture (MoCap) data. These datasets are not only costly to acquire but also frequently lack the necessary geometric context of the surrounding physical environment. Consequently, existing motion synthesis frameworks often suffer from a decoupling of motion and scene, resulting in physical inconsistencies such as contact slippage or mesh penetration during terrain-aware tasks. In this work, we present MeshMimic, an innovative framework that bridges 3D scene reconstruction and embodied intelligence to enable humanoid robots to learn coupled "motion-terrain" interactions directly from video. By leveraging state-of-the-art 3D vision models, our framework precisely segments and reconstructs both human trajectories and the underlying 3D geometry of terrains and objects. We introduce an optimization algorithm based on kinematic consistency to extract high-quality motion data from noisy visual reconstructions, alongside a contact-invariant retargeting method that transfers human-environment interaction features to the humanoid agent. Experimental results demonstrate that MeshMimic achieves robust, highly dynamic performance across diverse and challenging terrains. Our approach proves that a low-cost pipeline utilizing only consumer-grade monocular sensors can facilitate the training of complex physical interactions, offering a scalable path toward the autonomous evolution of humanoid robots in unstructured environments.

</details>


### [136] [FAST-EQA: Efficient Embodied Question Answering with Global and Local Region Relevancy](https://arxiv.org/abs/2602.15813)
*Haochen Zhang,Nirav Savaliya,Faizan Siddiqui,Enna Sachdeva*

Main category: cs.RO

TL;DR: 本文提出了一种名为FAST-EQA的框架，用于解决具身问答（EQA）问题。该框架通过识别视觉目标、指导导航、利用视觉记忆进行推理，实现了高效的搜索和准确的回答，并显著提高了推理速度。


<details>
  <summary>Details</summary>
Motivation: EQA任务需要结合视觉理解、目标导向探索、空间和时间推理等能力，而核心挑战在于如何在部分可观测环境下，将物理搜索限制在与问题相关的子空间内，同时保持紧凑可操作的观察记忆。此外，为了在现实世界中部署，快速的推理时间至关重要。

Method: FAST-EQA框架包含三个主要组件：(i) 识别可能的视觉目标；(ii) 对全局区域进行评分以指导导航；(iii) 利用视觉记忆进行链式思考（CoT）推理以自信地回答问题。该框架维护一个固定容量的、在线更新的局部场景记忆，以处理单目标和多目标问题。为了高效扩展覆盖范围，其全局探索策略将狭窄开口和门视为高价值的探索前沿。

Result: FAST-EQA在HMEQA和EXPRESS-Bench上取得了最先进的性能，在OpenEQA和MT-HM3D上也表现出竞争力。该框架通过聚焦代理的注意力、改善场景覆盖以及提高答案的可靠性，同时运行速度显著快于先前的方法。

Conclusion: FAST-EQA通过创新的目标识别、区域评分、链式思考推理以及高效的探索策略，成功地解决了EQA任务中的关键挑战，并在性能和速度上达到了新的水平。

Abstract: Embodied Question Answering (EQA) combines visual scene understanding, goal-directed exploration, spatial and temporal reasoning under partial observability. A central challenge is to confine physical search to question-relevant subspaces while maintaining a compact, actionable memory of observations. Furthermore, for real-world deployment, fast inference time during exploration is crucial. We introduce FAST-EQA, a question-conditioned framework that (i) identifies likely visual targets, (ii) scores global regions of interest to guide navigation, and (iii) employs Chain-of-Thought (CoT) reasoning over visual memory to answer confidently. FAST-EQA maintains a bounded scene memory that stores a fixed-capacity set of region-target hypotheses and updates them online, enabling robust handling of both single and multi-target questions without unbounded growth. To expand coverage efficiently, a global exploration policy treats narrow openings and doors as high-value frontiers, complementing local target seeking with minimal computation. Together, these components focus the agent's attention, improve scene coverage, and improve answer reliability while running substantially faster than prior approaches. On HMEQA and EXPRESS-Bench, FAST-EQA achieves state-of-the-art performance, while performing competitively on OpenEQA and MT-HM3D.

</details>


### [137] [Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation](https://arxiv.org/abs/2602.15828)
*Yuxuan Kuang,Sungjae Park,Katerina Fragkiadaki,Shubham Tulsiani*

Main category: cs.RO

TL;DR: Dex4D是一个在模拟环境中训练的框架，能够通过学习通用的3D点轨迹控制策略，实现对任意物体执行任意姿态的操作，并能零样本泛化到真实的、之前未见过的任务和物体上。


<details>
  <summary>Details</summary>
Motivation: 现实世界中收集大规模的灵巧操作数据成本高昂且难以扩展；在模拟环境中为特定任务设计环境和奖励也具有挑战性。因此，研究需要一种能够灵活重组通用技能以完成多样化真实世界操作的方法。

Method: Dex4D框架在模拟环境中训练一个“任意姿态到任意姿态”（Anypose-to-Anypose）的策略。该策略基于3D点轨迹进行控制，并能在模拟中接触到各种物体和多样化的姿态配置。在部署时，该策略可以零样本迁移到真实世界的任务中，通过提取目标物体姿态的3D点轨迹作为提示，并利用在线点轨迹进行闭环感知和控制。

Result: Dex4D在模拟和真实机器人上的实验表明，该方法能够实现对多样化灵巧操作任务的零样本部署，并优于现有基线方法。此外，该方法在面对新颖物体、场景布局、背景和轨迹时表现出强大的泛化能力。

Conclusion: Dex4D框架成功地利用模拟学习了领域无关的3D点轨迹控制策略，该策略可以灵活组合以应对多样化的真实世界操作任务，并且能够实现零样本的泛化能力，克服了数据收集和任务设计上的挑战。

Abstract: Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via real-world teleoperation is expensive and difficult to scale. While learning in simulation provides a feasible alternative, designing multiple task-specific environments and rewards for training is similarly challenging. We propose Dex4D, a framework that instead leverages simulation for learning task-agnostic dexterous skills that can be flexibly recomposed to perform diverse real-world manipulation tasks. Specifically, Dex4D learns a domain-agnostic 3D point track conditioned policy capable of manipulating any object to any desired pose. We train this 'Anypose-to-Anypose' policy in simulation across thousands of objects with diverse pose configurations, covering a broad space of robot-object interactions that can be composed at test time. At deployment, this policy can be zero-shot transferred to real-world tasks without finetuning, simply by prompting it with desired object-centric point tracks extracted from generated videos. During execution, Dex4D uses online point tracking for closed-loop perception and control. Extensive experiments in simulation and on real robots show that our method enables zero-shot deployment for diverse dexterous manipulation tasks and yields consistent improvements over prior baselines. Furthermore, we demonstrate strong generalization to novel objects, scene layouts, backgrounds, and trajectories, highlighting the robustness and scalability of the proposed framework.

</details>


### [138] [Robot-Assisted Social Dining as a White Glove Service](https://arxiv.org/abs/2602.15767)
*Atharva S Kashyap,Ugne Aleksandra Morkute,Patricia Alves-Oliveira*

Main category: cs.RO

TL;DR: 本研究通过参与式设计探讨了在餐厅等真实社交用餐场景下，为残障人士设计的机器人辅助进食系统。研究发现，理想的系统应具备白手套服务的特质，支持多模态输入输出、有情境意识的社交行为、超越进食功能的扩展角色，并能适应餐桌上的其他社交关系。


<details>
  <summary>Details</summary>
Motivation: 现有机器人辅助进食系统仅在实验室或家庭环境中进行过测试，而将其应用于餐厅等真实的、非结构化的社交用餐场景的研究尚属空白。设计适用于这些场景的机器人面临着动态、无监督环境的独特挑战。

Method: 研究采用了与残障人士进行推测性参与式设计的方法，结合半结构化访谈和一个定制的基于AI的视觉故事板工具，以发掘在真实社交用餐场景下的理想系统设计。

Result: 研究的主要见解是，这类系统应遵循“白手套服务”的原则，具体体现在：1. 支持多模态输入和不显眼的输出；2. 具有情境敏感的社交行为并优先考虑用户；3. 承担超越进食的扩展角色；4. 能够适应餐桌上其他用餐者之间的关系。

Conclusion: 本研究为在真实环境中以及多人用餐情境下的机器人辅助进食系统设计提供了重要的启示，强调了系统的适应性、社交智能以及超越基本喂食功能的重要性。

Abstract: Robot-assisted feeding enables people with disabilities who require assistance eating to enjoy a meal independently and with dignity. However, existing systems have only been tested in-lab or in-home, leaving in-the-wild social dining contexts (e.g., restaurants) largely unexplored. Designing a robot for such contexts presents unique challenges, such as dynamic and unsupervised dining environments that a robot needs to account for and respond to. Through speculative participatory design with people with disabilities, supported by semi-structured interviews and a custom AI-based visual storyboarding tool, we uncovered ideal scenarios for in-the-wild social dining. Our key insight suggests that such systems should: embody the principles of a white glove service where the robot (1) supports multimodal inputs and unobtrusive outputs; (2) has contextually sensitive social behavior and prioritizes the user; (3) has expanded roles beyond feeding; (4) adapts to other relationships at the dining table. Our work has implications for in-the-wild and group contexts of robot-assisted feeding.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [139] [Generalized bilinear Koopman realization from input-output data for multi-step prediction with metaheuristic optimization of lifting function and its application to real-world industrial system](https://arxiv.org/abs/2602.15422)
*Shuichi Yahagi,Ansei Yonezawa,Heisei Yonezawa,Hiroki Seto,Itsuro Kajiwara*

Main category: eess.SY

TL;DR: 本文提出了一种基于输入-输出双线性koopman模型，并使用全局元启发式算法优化径向基函数（RBF）作为提升函数，以提高非线性系统长期预测的准确性，并在柴油机空气路径控制系统上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 传统基于koopman 的模型在工业应用中面临传感器限制、提升函数设计困难以及线性时不变（LTI）模型预测精度有限等挑战。

Method: 提出了一种输入-输出双线性 koopman 建模方法，利用全局元启发式算法优化径向基函数（RBF）作为提升函数，以提高长期预测性能。

Result: 所提出的输入-输出双线性 koopman 模型在柴油机空气路径控制系统的仿真和实验中，显著优于传统的线性 koopman 模型，展现出更高的预测精度。

Conclusion: 通过优化提升函数和采用双线性 koopman 模型结构，可以有效克服传统 koopman 模型在工业应用中的限制，提高模型的预测性能和可靠性。

Abstract: This paper introduces an input-output bilinear Koopman realization with an optimization algorithm of lifting functions. For nonlinear systems with inputs, Koopman-based modeling is effective because the Koopman operator enables a high-dimensional linear representation of nonlinear dynamics. However, traditional approaches face significant challenges in industrial applications. Measuring all system states is often impractical due to constraints on sensor installation. Moreover, the predictive performance of a Koopman model strongly depends on the choice of lifting functions, and their design typically requires substantial manual effort. In addition, although a linear time-invariant (LTI) Koopman model is the most commonly used model structure in the Koopman framework, such model exhibit limited predictive accuracy. To address these limitations, we propose an input-output bilinear Koopman modeling in which the design parameters of radial basis function (RBF)-based lifting functions are optimized using a global metaheuristic algorithm to improve long-term prediction performance. Consideration of the long-term prediction performance enhances the reliability of the resulting model. The proposed methodology is validated in simulations and experimental tests, with the airpath control system of a diesel engine as the plant to be modeled. This plant represents a challenging industrial application because it exhibits strong nonlinearities and coupled multi-input multi-output (MIMO) dynamics. These results demonstrate that the proposed input-output bilinear Koopman model significantly outperforms traditional linear Koopman models in predictive accuracy.

</details>


### [140] [Embedding Economic Input-Output Models in Systems of Systems: An MBSE and Hetero-functional Graph Theory Approach](https://arxiv.org/abs/2602.15254)
*Mohammad Mhadi Naderi,Megan S. Harris,John C. Little,Amro M. Farid*

Main category: eess.SY

TL;DR: 本研究首次将模型驱动系统工程 (MBSE) 和异构图论 (HFGT) 应用于经济系统，建立了一种可扩展的集成经济投入产出 (EIO) 模型的方法，并证明其可以准确地重现 EIO 模型捕获的动态，同时提供更好的可视化和系统洞察力。


<details>
  <summary>Details</summary>
Motivation: 应对“人类世”复杂生态、环境和人-自然耦合系统的挑战，需要理解和表征这些系统之间相互依赖的性质。

Method: 将模型驱动系统工程 (MBSE) 和异构图论 (HFGT) 方法应用于经济系统，将经济投入产出 (EIO) 模型集成到一个统一的系统之系统建模框架中。使用 SysML 的图形本体表示经济系统的结构和功能，并将其转换为 HFGT 的计算结构。使用合成的 Rectangular Choice of Technology (RCOT) 作为示例。

Result: 研究证实，MBSE-HFGT 框架能够等效地重现基本 EIO 模型以及其他基于 EIO 理论的复杂经济模型所捕获的动态。该框架在保留分析精度的同时，通过共享的本体结构增强了图形清晰度和系统级洞察力。

Conclusion: 通过集成建模语言和数学框架，所提出的方法为知识共生产和综合决策提供了基础，以应对“人类世”系统之系统相关的多方面可持续性挑战。

Abstract: Characterizing the interdependent nature of Anthropocene systems of systems is fundamental to making informed decisions to address challenges across complex ecological, environmental, and coupled human-natural systems. This paper presents the first application of Model-Based Systems Engineering (MBSE) and Hetero-functional Graph Theory (HFGT) to economic systems, establishing a scalable and extensible methodology for integrating economic input-output (EIO) models within a unified system-of-systems modeling framework. Integrating EIO models into the MBSE-HFGT workflow demonstrates how the structural form and function of economic systems can be expressed through SysML's graphical ontology and subsequently translated into the computational structure of HFGT. Using a synthetic Rectangular Choice of Technology (RCOT) example as a pedagogical foundation, the study confirms that the dynamics captured by basic EIO models, as well as other complex economic models grounded in EIO theory, can be equivalently reproduced within the MBSE-HFGT framework. The integration with MBSE and HFGT thus preserves analytical precision while offering enhanced graphical clarity and system-level insight through a shared ontological structure. By integrating modeling languages and mathematical frameworks, the proposed methodology establishes a foundation for knowledge co-production and integrated decision-making to address the multifaceted sustainability challenges associated with Anthropocene systems of systems.

</details>


### [141] [State Feedback Control of State-Delayed LPV Systems using Dynamics IQCs](https://arxiv.org/abs/2602.15282)
*Fen Wu*

Main category: eess.SY

TL;DR: 本文提出了一种新的控制框架，用于处理具有时变状态延迟的线性参数变化（LPV）系统。该框架结合了参数依赖李雅普诺夫函数和积分二次约束（IQCs），并提出了一种新的延迟依赖状态反馈控制器，通过参数依赖LMI实现了闭环稳定性和L2增益性能的保证。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够处理线性参数变化（LPV）系统中的时变状态延迟的控制方法，以克服传统方法保守性高、控制能力受限的问题。

Method: 结合参数依赖李雅普诺夫函数和积分二次约束（IQCs），提出一种新的延迟依赖状态反馈控制器结构，使用动态IQCs和参数依赖二次李雅普诺夫函数进行闭环稳定性和L2增益性能分析，最终导出参数依赖线性矩阵不等式（LMIs）的凸合成条件。

Result: 通过参数依赖LMI得到了保证性能的凸合成条件，该框架能够处理延迟效应，提高了控制能力，降低了保守性，并改善了闭环性能。

Conclusion: 所提出的基于IQC的框架为处理LPV系统中时变状态延迟提供了一种灵活且系统的方法，相比传统方法，其控制能力更强，保守性更低，闭环性能更好。

Abstract: This paper develops a new control framework for linear parameter-varying (LPV) systems with time-varying state delays by integrating parameter-dependent Lyapunov functions with integral quadratic constraints (IQCs). A novel delay-dependent state-feedback controller structure is proposed, consisting of a linear state-feedback law augmented with an additional term that captures the delay-dependent dynamics of the plant. Closed-loop stability and $\mathcal{L}_2$-gain performance are analyzed using dynamic IQCs and parameter-dependent quadratic Lyapunov functions, leading to convex synthesis conditions that guarantee performance in terms of parameter-dependent linear matrix inequalities (LMIs). Unlike traditional delay control approaches, the proposed IQC-based framework provides a flexible and systematic methodology for handling delay effects, enabling enhanced control capability, reduced conservatism, and improved closed-loop performance.

</details>


### [142] [Noncooperative Coordination for Decentralized Air Traffic Management](https://arxiv.org/abs/2602.15333)
*Jaehan Im*

Main category: eess.SY

TL;DR: 本研究提出了一种非合作协调的新视角，通过设计激励和信号来重塑个体最优，从而在去中心化的空域管理中实现系统级的协调，适用于利益相关者之间存在冲突但需遵守共同安全和容量约束的情况。


<details>
  <summary>Details</summary>
Motivation: 传统的集中式或隐式合作模型无法充分处理去中心化空域管理中，各方利益不一致但又受制于共同约束的复杂情况。需要一种新的方法来在这种环境中实现有效的协调。

Method: 研究开发了一个统一的非合作协调框架，通过设计激励和信号来改变个体决策的最优性。具体技术贡献包括：1. 可扩展的均衡工程，利用低秩和考虑不确定性的相关均衡。2. 去中心化的机制设计，无需强制即可实现均衡选择。3. 具有收敛保证的结构化非合作动态。

Result: 该研究在理论上取得了三方面的技术进展，并讨论了激励兼容协调的核心设计原则。这些成果为在安全性要求极高的空域系统中实现可扩展、鲁棒的协调奠定了基础。

Conclusion: 本研究为去中心化空域管理提供了一种新的、更具适应性的协调方法，通过非合作博弈论的设计，可以在不强制合作的情况下，实现系统整体的优化和稳定运行，尤其适用于存在利益冲突的场景。

Abstract: Decentralized air traffic management requires coordination among self-interested stakeholders operating under shared safety and capacity constraints, where conventional centralized or implicitly cooperative models do not adequately capture this setting. We develop a unified perspective on noncooperative coordination, in which system-level outcomes emerge by designing incentives and assigning signals that reshape individual optimality rather than imposing cooperation or enforcement. We advance this framework along three directions: scalable equilibrium engineering via reduced-rank and uncertainty-aware correlated equilibria, decentralized mechanism design for equilibrium selection without enforcement, and structured noncooperative dynamics with convergence guarantees. Beyond these technical contributions, we discuss core design principles that govern incentive-compatible coordination in decentralized systems. Together, these results establish a foundation for scalable, robust coordination in safety-critical air traffic systems.

</details>


### [143] [Fine-Tuning LLMs to Generate Economical and Reliable Actions for the Power Grid](https://arxiv.org/abs/2602.15350)
*Mohamad Chehade,Hao Zhu*

Main category: eess.SY

TL;DR: 研究提出了一种多阶段自适应流程，利用指令调优的大语言模型（LLM）为电网在公共安全停电（PSPS）期间生成开环式纠正性输电切换方案，旨在减少负荷削减并维持电压稳定性，同时遵守切换预算。


<details>
  <summary>Details</summary>
Motivation: 公共安全停电（PSPS）会导致电网拓扑快速变化，使标准运行点失效，迫使运营商迅速制定纠正性切换措施，以减少负荷削减并保持电压稳定。

Method: 研究提出了一种多阶段自适应流程：1. 监督微调（SFT）将DC-OPF MILP预言机提炼为约束动作语法，用于解析和可行性检查。2. 直接偏好优化（DPO）使用AC评估的偏好对（由电压惩罚指标排序）进一步优化策略，注入电压感知能力。3. N选最佳（Best-of-N）选择在推理时从多个可行方案中选择最优解。

Result: 在IEEE 118节点PSPS场景下，与零样本生成相比，微调显著提高了DC目标值，将AC潮流失败率从50%降低到个位数，并改善了通用成功集上的电压惩罚结果。

Conclusion: 提出的自适应流程能够有效地利用LLM生成可行的、符合电压约束的PSPS纠正性切换方案，显著优于零样本方法，并有助于提高电网的可靠性。

Abstract: Public Safety Power Shutoffs (PSPS) force rapid topology changes that can render standard operating points infeasible, requiring operators to quickly identify corrective transmission switching actions that reduce load shedding while maintaining acceptable voltage behavior. We present a verifiable, multi-stage adaptation pipeline that fine-tunes an instruction-tuned large language model (LLM) to generate \emph{open-only} corrective switching plans from compact PSPS scenario summaries under an explicit switching budget. First, supervised fine-tuning distills a DC-OPF MILP oracle into a constrained action grammar that enables reliable parsing and feasibility checks. Second, direct preference optimization refines the policy using AC-evaluated preference pairs ranked by a voltage-penalty metric, injecting voltage-awareness beyond DC imitation. Finally, best-of-$N$ selection provides an inference-time addition by choosing the best feasible candidate under the target metric. On IEEE 118-bus PSPS scenarios, fine-tuning substantially improves DC objective values versus zero-shot generation, reduces AC power-flow failure from 50\% to single digits, and improves voltage-penalty outcomes on the common-success set. Code and data-generation scripts are released to support reproducibility.

</details>


### [144] [The role of VSG parameters in shaping small-signal SG dynamics](https://arxiv.org/abs/2602.15526)
*Ferdinand Geuss,Orcun Karaca,Mario Schweizer,Ognjen Stanojev*

Main category: eess.SY

TL;DR: 研究了虚拟同步发电机（VSG）与同步发电机（SG）组成的系统在小信号下的电压和频率动态特性，并分析了VSG参数对SG动态的影响。


<details>
  <summary>Details</summary>
Motivation: 理解VSG与SG相互作用的系统动态特性，并分析VSG参数选择对SG稳定性的影响，以优化VSG参数设置。

Method: 推导了包含VSG、SG和负载的系统的无功功率和频率的小信号传递函数，并基于此模型进行了参数灵敏度分析。

Result: 研究发现，虚拟惯量和调速器滞后是影响SG动态的关键VSG参数，且存在权衡；阻尼绕组模拟的效果有限。

Conclusion: VSG参数的选择对SG的动态性能有显著影响，需要仔细权衡，特别是虚拟惯量和调速器滞后。阻尼绕组的模拟效果不显著。

Abstract: We derive a small-signal transfer function for a system comprising a virtual synchronous generator (VSG), a synchronous generator (SG), and a load, capturing voltage and frequency dynamics. Using this model, we analyze the sensitivity of SG dynamics to VSG parameters, highlighting trade-offs in choosing virtual inertia and governor lag, the limited effect of damper-winding emulation, and several others.

</details>


### [145] [Time-Certified and Efficient NMPC via Koopman Operator](https://arxiv.org/abs/2602.15596)
*Liang Wu,Yunhong Che,Bo Yang,Kangyu Lin,Ján Drgoňa*

Main category: eess.SY

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Certifying and accelerating execution times of nonlinear model predictive control (NMPC) implementations are two core requirements. Execution-time certificate guarantees that the NMPC controller returns a solution before the next sampling time, and achieving faster worst-case and average execution times further enables its use in a wider set of applications. However, NMPC produces a nonlinear program (NLP) for which it is challenging to derive its execution time certificates. Our previous works, \citep{wu2025direct,wu2025time} provide data-independent execution time certificates (certified number of iterations) for box-constrained quadratic programs (BoxQP). To apply the time-certified BoxQP algorithm \citep{wu2025time} for state-input constrained NMPC, this paper i) learns a linear model via Koopman operator; ii) proposes a dynamic-relaxation construction approach yields a structured BoxQP rather than a general QP; iii) exploits the structure of BoxQP, where the dimension of the linear system solved in each iteration is reduced from $5N(n_u+n_x)$ to $Nn_u$ (where $n_u, n_x, N$ denote the number of inputs, states, and length of prediction horizon), yielding substantial speedups (when $n_x \gg n_u$, as in PDE control).

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [146] [StrokeNeXt: A Siamese-encoder Approach for Brain Stroke Classification in Computed Tomography Imagery](https://arxiv.org/abs/2602.15087)
*Leo Thomas Ramos,Angel D. Sappa*

Main category: eess.IV

TL;DR: StrokeNeXt是一个用于2D CT图像中风分类的双分支模型，通过轻量级卷积解码器融合ConvNeXt编码器特征，在检测和亚型分类方面表现优于基线模型，准确率和F1分数最高可达0.988，且具有低推理时间和快速收敛性。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够准确有效地对2D CT图像中的中风进行分类（包括检测和亚型分类）的模型。

Method: 采用双分支设计，包含两个ConvNeXt编码器，并通过一个基于堆叠1D操作（包括瓶颈投影和变换层）的轻量级卷积解码器融合特征，最后接一个紧凑的分类头。

Result: 在6,774张CT图像数据集上，StrokeNeXt在准确率和F1分数方面达到了0.988，显著优于卷积和Transformer基线模型。统计检验确认了性能提升的显著性，类别敏感性和特异性显示出在诊断类别上的鲁棒性，校准分析显示预测误差降低，混淆矩阵显示误分类率低。此外，模型推理时间短，收敛速度快。

Conclusion: StrokeNeXt是一个在2D CT图像中风分类任务上表现出色且高效的模型，能够准确检测中风并区分缺血性和出血性病例，在性能、鲁棒性和效率方面均优于现有方法。

Abstract: We present StrokeNeXt, a model for stroke classification in 2D Computed Tomography (CT) images. StrokeNeXt employs a dual-branch design with two ConvNeXt encoders, whose features are fused through a lightweight convolutional decoder based on stacked 1D operations, including a bottleneck projection and transformation layers, and a compact classification head. The model is evaluated on a curated dataset of 6,774 CT images, addressing both stroke detection and subtype classification between ischemic and hemorrhage cases. StrokeNeXt consistently outperforms convolutional and Transformer-based baselines, reaching accuracies and F1-scores of up to 0.988. Paired statistical tests confirm that the performance gains are statistically significant, while class-wise sensitivity and specificity demonstrate robust behavior across diagnostic categories. Calibration analysis shows reduced prediction error compared to competing methods, and confusion matrix results indicate low misclassification rates. In addition, the model exhibits low inference time and fast convergence.

</details>


### [147] [Benchmarking Self-Supervised Models for Cardiac Ultrasound View Classification](https://arxiv.org/abs/2602.15339)
*Youssef Megahed,Salma I. Megahed,Robin Ducharme,Inok Lee,Adrian D. C. Chan,Mark C. Walker,Steven Hawken*

Main category: eess.IV

TL;DR: 本研究评估了两种自监督学习框架（USF-MAE 和 MoCo v3）在心脏超声图像分类任务上的表现，结果表明 USF-MAE 优于 MoCo v3。


<details>
  <summary>Details</summary>
Motivation: 可靠的心脏超声图像解释对临床诊断至关重要，而自监督学习有望利用大量未标记数据来学习有意义的特征。

Method: 使用 CACTUS 数据集（37,736 张图像）和 5 折交叉验证，对 USF-MAE 和 MoCo v3 两个自监督学习框架进行评估。两个模型采用相同的训练协议、学习率（0.0001）和权重衰减（0.01）。记录 ROC-AUC、准确率、F1 分数和召回率等性能指标。

Result: USF-MAE 在所有评估指标上均优于 MoCo v3。USF-MAE 的平均测试 AUC 为 99.99%（+/-0.01%），准确率为 99.33%（+/-0.18%）。MoCo v3 的平均测试 AUC 为 99.97%（+/-0.01%），准确率为 98.99%（+/-0.28%）。F1 分数和召回率也显示出 USF-MAE 的优势，差异具有统计学意义（p=0.0048）。

Conclusion: USF-MAE 在心脏超声视图分类任务上比 MoCo v3 学习到更具区分度的特征，显示出在改进自动化心脏超声分类方面的潜力。

Abstract: Reliable interpretation of cardiac ultrasound images is essential for accurate clinical diagnosis and assessment. Self-supervised learning has shown promise in medical imaging by leveraging large unlabelled datasets to learn meaningful representations. In this study, we evaluate and compare two self-supervised learning frameworks, USF-MAE, developed by our team, and MoCo v3, on the recently introduced CACTUS dataset (37,736 images) for automated simulated cardiac view (A4C, PL, PSAV, PSMV, Random, and SC) classification. Both models used 5-fold cross-validation, enabling robust assessment of generalization performance across multiple random splits. The CACTUS dataset provides expert-annotated cardiac ultrasound images with diverse views. We adopt an identical training protocol for both models to ensure a fair comparison. Both models are configured with a learning rate of 0.0001 and a weight decay of 0.01. For each fold, we record performance metrics including ROC-AUC, accuracy, F1-score, and recall. Our results indicate that USF-MAE consistently outperforms MoCo v3 across metrics. The average testing AUC for USF-MAE is 99.99% (+/-0.01% 95% CI), compared to 99.97% (+/-0.01%) for MoCo v3. USF-MAE achieves a mean testing accuracy of 99.33% (+/-0.18%), higher than the 98.99% (+/-0.28%) reported for MoCo v3. Similar trends are observed for the F1-score and recall, with improvements statistically significant across folds (paired t-test, p=0.0048 < 0.01). This proof-of-concept analysis suggests that USF-MAE learns more discriminative features for cardiac view classification than MoCo v3 when applied to this dataset. The enhanced performance across multiple metrics highlights the potential of USF-MAE for improving automated cardiac ultrasound classification.

</details>


### [148] [Rate-Distortion Optimization for Ensembles of Non-Reference Metrics](https://arxiv.org/abs/2602.15779)
*Xin Xiong,Samuel Fernández-Menduiña,Eduardo Pavez,Antonio Ortega,Neil Birkbeck,Balu Adsumilli*

Main category: eess.IV

TL;DR: 本研究提出了一种改进的非参考度量（NRM）线性化（LNRM）框架，通过优化NRM集合和引入梯度平滑来提高视频编码中的视觉质量评估，并验证了其在AVC和Cool-chic编码器上的有效性，实现了比特率节省且不增加解码器复杂度，并显著减少了Cool-chic的编码时间。


<details>
  <summary>Details</summary>
Motivation: 现有的视频编码器主要依赖全参考度量进行率失真优化（RDO），而基于用户生成内容（UGC）的场景更适合使用非参考度量（NRM）。直接将NRM用于RDO效果不佳，因为NRM的梯度不稳定且可能存在模型偏差。因此，研究的动机是开发一种更鲁棒、更有效的将NRM集成到RDO中的方法。

Method: 1. 提出将多个NRM进行集合优化，以克服单一NRM的局限性。2. 引入基于平滑的NRM梯度稳定化方法，在进行线性化之前平滑NRM梯度。3. 提出的框架适用于混合编码器，并特别提出适用于过拟合编码器，避免了迭代评估和神经网络NRM的反向传播，降低了编码复杂度。

Result: 在AVC和Cool-chic编码器上，使用YouTube UGC数据集进行实验。结果表明，该方法在多个NRM上实现了比特率节省，且没有增加解码器复杂度。对于Cool-chic编码器，与直接NRM优化相比，编码运行时显著缩短。

Conclusion: 本文提出的扩展LNRM框架通过结合NRM集合优化和梯度平滑，能够有效地将NRM集成到视频编码的RDO过程中，提高了视觉质量评估的鲁棒性和效率，尤其适用于处理用户生成内容和过拟合编码器，并在实际编码任务中取得了良好的性能提升。

Abstract: Non-reference metrics (NRMs) can assess the visual quality of images and videos without a reference, making them well-suited for the evaluation of user-generated content. Nonetheless, rate-distortion optimization (RDO) in video coding is still mainly driven by full-reference metrics, such as the sum of squared errors, which treat the input as an ideal target. A way to incorporate NRMs into RDO is through linearization (LNRM), where the gradient of the NRM with respect to the input guides bit allocation. While this strategy improves the quality predicted by some metrics, we show that it can yield limited gains or degradations when evaluated with other NRMs. We argue that NRMs are highly non-linear predictors with locally unstable gradients that can compromise the quality of the linearization; furthermore, optimizing a single metric may exploit model-specific biases that do not generalize across quality estimators. Motivated by this observation, we extend the LNRM framework to optimize ensembles of NRMs and, to further improve robustness, we introduce a smoothing-based formulation that stabilizes NRM gradients prior to linearization. Our framework is well-suited to hybrid codecs, and we advocate for its use with overfitted codecs, where it avoids iterative evaluations and backpropagation of neural network-based NRMs, reducing encoder complexity relative to direct NRM optimization. We validate the proposed approach on AVC and Cool-chic, using the YouTube UGC dataset. Experiments demonstrate consistent bitrate savings across multiple NRMs with no decoder complexity overhead and, for Cool-chic, a substantial reduction in encoding runtime compared to direct NRM optimization.

</details>
